Epoch: 1| Step: 0
Training loss: 7.034646260925806
Validation loss: 5.859268418084458

Epoch: 6| Step: 1
Training loss: 6.381142144407901
Validation loss: 5.857395498961121

Epoch: 6| Step: 2
Training loss: 6.32774973569035
Validation loss: 5.855522985124496

Epoch: 6| Step: 3
Training loss: 5.2076200479999555
Validation loss: 5.853527165391874

Epoch: 6| Step: 4
Training loss: 5.395321776345921
Validation loss: 5.8516881001484755

Epoch: 6| Step: 5
Training loss: 5.573619059093791
Validation loss: 5.849676489511341

Epoch: 6| Step: 6
Training loss: 4.716708922898942
Validation loss: 5.847716075291349

Epoch: 6| Step: 7
Training loss: 6.454581107945947
Validation loss: 5.845739940387607

Epoch: 6| Step: 8
Training loss: 4.954978812564084
Validation loss: 5.843655536180503

Epoch: 6| Step: 9
Training loss: 6.3204187259305655
Validation loss: 5.841560946535943

Epoch: 6| Step: 10
Training loss: 5.8107451384242195
Validation loss: 5.839387322560201

Epoch: 6| Step: 11
Training loss: 6.28960898732019
Validation loss: 5.836999649289214

Epoch: 6| Step: 12
Training loss: 6.1034384370119215
Validation loss: 5.834748269093376

Epoch: 6| Step: 13
Training loss: 6.439190985053338
Validation loss: 5.832187031332308

Epoch: 2| Step: 0
Training loss: 5.890889533702954
Validation loss: 5.8295426540806305

Epoch: 6| Step: 1
Training loss: 5.380827472682197
Validation loss: 5.8268843106635275

Epoch: 6| Step: 2
Training loss: 6.2750036961518
Validation loss: 5.824053094436729

Epoch: 6| Step: 3
Training loss: 5.439654219521136
Validation loss: 5.820962795309715

Epoch: 6| Step: 4
Training loss: 5.238462759311025
Validation loss: 5.817920741270801

Epoch: 6| Step: 5
Training loss: 6.840506006898899
Validation loss: 5.814680449347784

Epoch: 6| Step: 6
Training loss: 5.957572977417062
Validation loss: 5.811130485397015

Epoch: 6| Step: 7
Training loss: 6.433329592425324
Validation loss: 5.807567951375774

Epoch: 6| Step: 8
Training loss: 6.217371495494562
Validation loss: 5.803705104084861

Epoch: 6| Step: 9
Training loss: 6.294743406657976
Validation loss: 5.799741874081056

Epoch: 6| Step: 10
Training loss: 6.718831474342487
Validation loss: 5.795625289740916

Epoch: 6| Step: 11
Training loss: 4.476907606952751
Validation loss: 5.7910331910217

Epoch: 6| Step: 12
Training loss: 5.103201306456444
Validation loss: 5.786570175101808

Epoch: 6| Step: 13
Training loss: 6.177114691394723
Validation loss: 5.782005879243799

Epoch: 3| Step: 0
Training loss: 5.437934945786808
Validation loss: 5.777240854567425

Epoch: 6| Step: 1
Training loss: 5.612491857442068
Validation loss: 5.772140749610407

Epoch: 6| Step: 2
Training loss: 6.012872873905942
Validation loss: 5.766738026054327

Epoch: 6| Step: 3
Training loss: 6.312041011024367
Validation loss: 5.761204238591781

Epoch: 6| Step: 4
Training loss: 6.1371566645352
Validation loss: 5.7554777286591206

Epoch: 6| Step: 5
Training loss: 6.419670227707925
Validation loss: 5.749601654407622

Epoch: 6| Step: 6
Training loss: 6.0449335495646555
Validation loss: 5.74327625843337

Epoch: 6| Step: 7
Training loss: 5.292252675847004
Validation loss: 5.736777762815542

Epoch: 6| Step: 8
Training loss: 5.324368850484145
Validation loss: 5.730085190632929

Epoch: 6| Step: 9
Training loss: 6.1549061504184595
Validation loss: 5.722983566835602

Epoch: 6| Step: 10
Training loss: 5.684509497210551
Validation loss: 5.715767365760097

Epoch: 6| Step: 11
Training loss: 4.786393932729781
Validation loss: 5.7085282601073

Epoch: 6| Step: 12
Training loss: 5.955357090567439
Validation loss: 5.70113473940886

Epoch: 6| Step: 13
Training loss: 6.506693694626585
Validation loss: 5.6934533174157105

Epoch: 4| Step: 0
Training loss: 6.33527759356289
Validation loss: 5.685459930862902

Epoch: 6| Step: 1
Training loss: 6.444982827743014
Validation loss: 5.6773687541735285

Epoch: 6| Step: 2
Training loss: 5.828661037472165
Validation loss: 5.669034528618959

Epoch: 6| Step: 3
Training loss: 6.053570965599302
Validation loss: 5.66011339745755

Epoch: 6| Step: 4
Training loss: 5.343409477225996
Validation loss: 5.651611786897161

Epoch: 6| Step: 5
Training loss: 4.733919329479282
Validation loss: 5.642786712505874

Epoch: 6| Step: 6
Training loss: 5.341224832259005
Validation loss: 5.633735062685391

Epoch: 6| Step: 7
Training loss: 5.001940541398658
Validation loss: 5.624726465426776

Epoch: 6| Step: 8
Training loss: 5.429233801019965
Validation loss: 5.615901879483197

Epoch: 6| Step: 9
Training loss: 5.900692863514525
Validation loss: 5.606660800768989

Epoch: 6| Step: 10
Training loss: 5.674955177970365
Validation loss: 5.597174081313998

Epoch: 6| Step: 11
Training loss: 5.927020009467401
Validation loss: 5.587761342467441

Epoch: 6| Step: 12
Training loss: 6.658879436812466
Validation loss: 5.578275747960294

Epoch: 6| Step: 13
Training loss: 5.422123004617035
Validation loss: 5.568459736358809

Epoch: 5| Step: 0
Training loss: 5.824210890336749
Validation loss: 5.559027570218425

Epoch: 6| Step: 1
Training loss: 5.177738979687221
Validation loss: 5.54862104703321

Epoch: 6| Step: 2
Training loss: 5.795207233557987
Validation loss: 5.539383506350877

Epoch: 6| Step: 3
Training loss: 4.844395748286429
Validation loss: 5.529721927239229

Epoch: 6| Step: 4
Training loss: 6.102201108446027
Validation loss: 5.520209146398245

Epoch: 6| Step: 5
Training loss: 4.192616766962401
Validation loss: 5.510641553745109

Epoch: 6| Step: 6
Training loss: 4.536459197589195
Validation loss: 5.501456183508002

Epoch: 6| Step: 7
Training loss: 5.676100824945869
Validation loss: 5.491830277887975

Epoch: 6| Step: 8
Training loss: 5.986046779175759
Validation loss: 5.482730803773826

Epoch: 6| Step: 9
Training loss: 6.61178768482172
Validation loss: 5.473020067267974

Epoch: 6| Step: 10
Training loss: 5.348279316218171
Validation loss: 5.463558966721696

Epoch: 6| Step: 11
Training loss: 6.022146677917399
Validation loss: 5.454151075247133

Epoch: 6| Step: 12
Training loss: 6.305140671639306
Validation loss: 5.445484744266264

Epoch: 6| Step: 13
Training loss: 5.630738785345918
Validation loss: 5.436382865881417

Epoch: 6| Step: 0
Training loss: 5.590915750413581
Validation loss: 5.428019242179721

Epoch: 6| Step: 1
Training loss: 5.572317482178522
Validation loss: 5.419571180940271

Epoch: 6| Step: 2
Training loss: 4.9485947743251835
Validation loss: 5.411337808607549

Epoch: 6| Step: 3
Training loss: 5.403442359371911
Validation loss: 5.403430857844127

Epoch: 6| Step: 4
Training loss: 5.82858773611229
Validation loss: 5.395441853622097

Epoch: 6| Step: 5
Training loss: 5.729788044842353
Validation loss: 5.387678585057638

Epoch: 6| Step: 6
Training loss: 4.841540417144098
Validation loss: 5.3799595389091435

Epoch: 6| Step: 7
Training loss: 5.713208124190165
Validation loss: 5.372772672019635

Epoch: 6| Step: 8
Training loss: 5.296220857181278
Validation loss: 5.365106452201009

Epoch: 6| Step: 9
Training loss: 6.5812232905440915
Validation loss: 5.35797557595612

Epoch: 6| Step: 10
Training loss: 5.33441953724268
Validation loss: 5.3509042005485465

Epoch: 6| Step: 11
Training loss: 5.352026525274898
Validation loss: 5.34390294263269

Epoch: 6| Step: 12
Training loss: 5.209625856873362
Validation loss: 5.3374621780806475

Epoch: 6| Step: 13
Training loss: 5.382495001521716
Validation loss: 5.331178865781783

Epoch: 7| Step: 0
Training loss: 5.777063121776348
Validation loss: 5.325065651788888

Epoch: 6| Step: 1
Training loss: 5.365171273120458
Validation loss: 5.318873214041593

Epoch: 6| Step: 2
Training loss: 5.847243952566056
Validation loss: 5.313079084362424

Epoch: 6| Step: 3
Training loss: 5.65666593423875
Validation loss: 5.307114028827918

Epoch: 6| Step: 4
Training loss: 4.972587590968461
Validation loss: 5.301160341077446

Epoch: 6| Step: 5
Training loss: 5.31950688249394
Validation loss: 5.295487693874374

Epoch: 6| Step: 6
Training loss: 5.701797790773977
Validation loss: 5.289751211804971

Epoch: 6| Step: 7
Training loss: 5.1384083337019275
Validation loss: 5.284104909222633

Epoch: 6| Step: 8
Training loss: 5.51555410885303
Validation loss: 5.27859680223269

Epoch: 6| Step: 9
Training loss: 5.251069459524412
Validation loss: 5.272835523367093

Epoch: 6| Step: 10
Training loss: 5.6872182923022105
Validation loss: 5.267227246030697

Epoch: 6| Step: 11
Training loss: 5.1727349525805435
Validation loss: 5.261553963070502

Epoch: 6| Step: 12
Training loss: 5.177715403645459
Validation loss: 5.256262087269423

Epoch: 6| Step: 13
Training loss: 5.0776430810990645
Validation loss: 5.250174776831359

Epoch: 8| Step: 0
Training loss: 4.980151835811761
Validation loss: 5.244996396122008

Epoch: 6| Step: 1
Training loss: 5.192196478019435
Validation loss: 5.239435586938126

Epoch: 6| Step: 2
Training loss: 5.390573694841903
Validation loss: 5.233713349234593

Epoch: 6| Step: 3
Training loss: 5.332641298377671
Validation loss: 5.228308993619218

Epoch: 6| Step: 4
Training loss: 4.858720054524371
Validation loss: 5.2225792517035

Epoch: 6| Step: 5
Training loss: 6.064368520444467
Validation loss: 5.216868748676154

Epoch: 6| Step: 6
Training loss: 5.010334968561721
Validation loss: 5.210874298795265

Epoch: 6| Step: 7
Training loss: 5.485471436540665
Validation loss: 5.2056431600219035

Epoch: 6| Step: 8
Training loss: 5.234326171647255
Validation loss: 5.200237706448869

Epoch: 6| Step: 9
Training loss: 5.530629613535799
Validation loss: 5.194798769683704

Epoch: 6| Step: 10
Training loss: 5.653710401094
Validation loss: 5.18952262084355

Epoch: 6| Step: 11
Training loss: 5.482815164743136
Validation loss: 5.183996005286338

Epoch: 6| Step: 12
Training loss: 4.978464287200978
Validation loss: 5.178722600499941

Epoch: 6| Step: 13
Training loss: 5.321881436821746
Validation loss: 5.173318129513872

Epoch: 9| Step: 0
Training loss: 4.914545517609265
Validation loss: 5.167910497927714

Epoch: 6| Step: 1
Training loss: 6.003986941349434
Validation loss: 5.162234168794007

Epoch: 6| Step: 2
Training loss: 5.274475809239801
Validation loss: 5.157118629732778

Epoch: 6| Step: 3
Training loss: 5.444654996956985
Validation loss: 5.15127085711669

Epoch: 6| Step: 4
Training loss: 4.937620137358645
Validation loss: 5.14589213390449

Epoch: 6| Step: 5
Training loss: 5.186919765883683
Validation loss: 5.1408481414197436

Epoch: 6| Step: 6
Training loss: 6.283356118940867
Validation loss: 5.13505340384968

Epoch: 6| Step: 7
Training loss: 5.159180519324891
Validation loss: 5.12932917102228

Epoch: 6| Step: 8
Training loss: 5.626269388019249
Validation loss: 5.123710470091303

Epoch: 6| Step: 9
Training loss: 5.548070472517232
Validation loss: 5.118656543566336

Epoch: 6| Step: 10
Training loss: 4.909548288609998
Validation loss: 5.112925875335294

Epoch: 6| Step: 11
Training loss: 4.462370046224692
Validation loss: 5.106766092031386

Epoch: 6| Step: 12
Training loss: 3.92893122226852
Validation loss: 5.10169861997966

Epoch: 6| Step: 13
Training loss: 5.474187795933428
Validation loss: 5.096141230508057

Epoch: 10| Step: 0
Training loss: 4.736011385994189
Validation loss: 5.089965490962412

Epoch: 6| Step: 1
Training loss: 5.031348944218273
Validation loss: 5.084828308067642

Epoch: 6| Step: 2
Training loss: 5.549622620820312
Validation loss: 5.078104936609003

Epoch: 6| Step: 3
Training loss: 5.236776137119357
Validation loss: 5.071817497010492

Epoch: 6| Step: 4
Training loss: 3.7738591623959814
Validation loss: 5.065081342500257

Epoch: 6| Step: 5
Training loss: 5.385913503763269
Validation loss: 5.05951316853748

Epoch: 6| Step: 6
Training loss: 5.287141482055263
Validation loss: 5.053146166610659

Epoch: 6| Step: 7
Training loss: 3.9335988413106326
Validation loss: 5.046857898789477

Epoch: 6| Step: 8
Training loss: 5.068662495451621
Validation loss: 5.040789672406863

Epoch: 6| Step: 9
Training loss: 5.8849166612712045
Validation loss: 5.03493259151204

Epoch: 6| Step: 10
Training loss: 5.6350354002794285
Validation loss: 5.028420009774251

Epoch: 6| Step: 11
Training loss: 5.383294027242078
Validation loss: 5.021712335698989

Epoch: 6| Step: 12
Training loss: 5.836776407554696
Validation loss: 5.0154429370005875

Epoch: 6| Step: 13
Training loss: 5.1754077474313895
Validation loss: 5.00890714095035

Epoch: 11| Step: 0
Training loss: 4.652953549128411
Validation loss: 5.002699600042865

Epoch: 6| Step: 1
Training loss: 4.5115382302901015
Validation loss: 4.996654726556649

Epoch: 6| Step: 2
Training loss: 5.652118164285137
Validation loss: 4.990360122559497

Epoch: 6| Step: 3
Training loss: 4.9087815283570775
Validation loss: 4.983900312662607

Epoch: 6| Step: 4
Training loss: 5.294513367218398
Validation loss: 4.9776622569118

Epoch: 6| Step: 5
Training loss: 5.150098055304195
Validation loss: 4.971868947631042

Epoch: 6| Step: 6
Training loss: 5.283757985535203
Validation loss: 4.9667292230408675

Epoch: 6| Step: 7
Training loss: 4.653645036381029
Validation loss: 4.960619177830702

Epoch: 6| Step: 8
Training loss: 4.878707649580791
Validation loss: 4.954195438405199

Epoch: 6| Step: 9
Training loss: 6.2604027196270735
Validation loss: 4.94891685683108

Epoch: 6| Step: 10
Training loss: 4.87550253600977
Validation loss: 4.943539462808921

Epoch: 6| Step: 11
Training loss: 4.971183516815822
Validation loss: 4.937819233163422

Epoch: 6| Step: 12
Training loss: 4.7128803049125505
Validation loss: 4.931789685505136

Epoch: 6| Step: 13
Training loss: 5.154460804635479
Validation loss: 4.9260262235045955

Epoch: 12| Step: 0
Training loss: 5.225285806094351
Validation loss: 4.920839166382065

Epoch: 6| Step: 1
Training loss: 5.407770373057167
Validation loss: 4.915807013063164

Epoch: 6| Step: 2
Training loss: 5.406260231317089
Validation loss: 4.9103585310051585

Epoch: 6| Step: 3
Training loss: 4.468994133956313
Validation loss: 4.904503707950194

Epoch: 6| Step: 4
Training loss: 5.022016499299687
Validation loss: 4.898319743889208

Epoch: 6| Step: 5
Training loss: 5.318694329334643
Validation loss: 4.8930577411707485

Epoch: 6| Step: 6
Training loss: 5.5083191117849974
Validation loss: 4.887179134727702

Epoch: 6| Step: 7
Training loss: 4.944545306678353
Validation loss: 4.8822232717394165

Epoch: 6| Step: 8
Training loss: 4.6455541050681175
Validation loss: 4.876843747730559

Epoch: 6| Step: 9
Training loss: 5.632232424513413
Validation loss: 4.871228968485412

Epoch: 6| Step: 10
Training loss: 3.6948698718291793
Validation loss: 4.865622410153888

Epoch: 6| Step: 11
Training loss: 4.741572080896782
Validation loss: 4.860712911857164

Epoch: 6| Step: 12
Training loss: 4.652847788016727
Validation loss: 4.856263369587251

Epoch: 6| Step: 13
Training loss: 5.1510949461534015
Validation loss: 4.852368274062313

Epoch: 13| Step: 0
Training loss: 5.2207239495235624
Validation loss: 4.847134595125677

Epoch: 6| Step: 1
Training loss: 5.350917716060745
Validation loss: 4.842508267625517

Epoch: 6| Step: 2
Training loss: 4.7019163080358455
Validation loss: 4.835871369911671

Epoch: 6| Step: 3
Training loss: 3.991040328121955
Validation loss: 4.831806149863717

Epoch: 6| Step: 4
Training loss: 5.8268360829692964
Validation loss: 4.827454225101555

Epoch: 6| Step: 5
Training loss: 4.85807954748051
Validation loss: 4.822127286549785

Epoch: 6| Step: 6
Training loss: 5.831963877917956
Validation loss: 4.817596742179611

Epoch: 6| Step: 7
Training loss: 5.392168349323516
Validation loss: 4.811836626314644

Epoch: 6| Step: 8
Training loss: 4.606187034808052
Validation loss: 4.806158106421056

Epoch: 6| Step: 9
Training loss: 3.799642174587921
Validation loss: 4.800554187889587

Epoch: 6| Step: 10
Training loss: 4.9115360236335635
Validation loss: 4.796362900295364

Epoch: 6| Step: 11
Training loss: 4.154726136290829
Validation loss: 4.79183516275234

Epoch: 6| Step: 12
Training loss: 4.821668338364383
Validation loss: 4.7876396616990124

Epoch: 6| Step: 13
Training loss: 5.198356941041526
Validation loss: 4.782325224806093

Epoch: 14| Step: 0
Training loss: 4.367149066244118
Validation loss: 4.778256362163818

Epoch: 6| Step: 1
Training loss: 5.163537626384821
Validation loss: 4.773689658772582

Epoch: 6| Step: 2
Training loss: 5.658459985108684
Validation loss: 4.767653636967287

Epoch: 6| Step: 3
Training loss: 4.502201601399426
Validation loss: 4.763127540768233

Epoch: 6| Step: 4
Training loss: 5.314289105907946
Validation loss: 4.7590205220234685

Epoch: 6| Step: 5
Training loss: 4.919866436641805
Validation loss: 4.754398267199351

Epoch: 6| Step: 6
Training loss: 4.958563192900568
Validation loss: 4.749681595955648

Epoch: 6| Step: 7
Training loss: 4.421823238433794
Validation loss: 4.744085511282291

Epoch: 6| Step: 8
Training loss: 4.914453536396633
Validation loss: 4.7390995770857165

Epoch: 6| Step: 9
Training loss: 3.922215663506989
Validation loss: 4.733875344813459

Epoch: 6| Step: 10
Training loss: 5.0359772456036085
Validation loss: 4.729809665519945

Epoch: 6| Step: 11
Training loss: 4.480955302020003
Validation loss: 4.724188123649676

Epoch: 6| Step: 12
Training loss: 4.940202190879193
Validation loss: 4.719348692650788

Epoch: 6| Step: 13
Training loss: 5.340385403958911
Validation loss: 4.714078059859364

Epoch: 15| Step: 0
Training loss: 4.896177412346679
Validation loss: 4.709255240777519

Epoch: 6| Step: 1
Training loss: 4.107590668711352
Validation loss: 4.70491767589667

Epoch: 6| Step: 2
Training loss: 4.693565005378832
Validation loss: 4.700431449512282

Epoch: 6| Step: 3
Training loss: 4.834702637610323
Validation loss: 4.69634947536652

Epoch: 6| Step: 4
Training loss: 4.343052211123523
Validation loss: 4.691401506771471

Epoch: 6| Step: 5
Training loss: 6.17350125676945
Validation loss: 4.686353721335709

Epoch: 6| Step: 6
Training loss: 4.3570990415063
Validation loss: 4.6813386223709825

Epoch: 6| Step: 7
Training loss: 4.1767444552408
Validation loss: 4.676256317675525

Epoch: 6| Step: 8
Training loss: 4.085032492313474
Validation loss: 4.671806649651122

Epoch: 6| Step: 9
Training loss: 5.385132221946975
Validation loss: 4.666403229407663

Epoch: 6| Step: 10
Training loss: 4.653327588038646
Validation loss: 4.66222058533659

Epoch: 6| Step: 11
Training loss: 5.17975912145289
Validation loss: 4.657977233997059

Epoch: 6| Step: 12
Training loss: 4.586939739555819
Validation loss: 4.653221630479081

Epoch: 6| Step: 13
Training loss: 5.327331304864295
Validation loss: 4.64821216026383

Epoch: 16| Step: 0
Training loss: 4.162181780224269
Validation loss: 4.643508785754991

Epoch: 6| Step: 1
Training loss: 5.647348217117125
Validation loss: 4.63881585576986

Epoch: 6| Step: 2
Training loss: 4.5073652392663375
Validation loss: 4.634590206692731

Epoch: 6| Step: 3
Training loss: 4.800067646821501
Validation loss: 4.628772331264278

Epoch: 6| Step: 4
Training loss: 5.2942100279981945
Validation loss: 4.624717428837157

Epoch: 6| Step: 5
Training loss: 4.916609014830437
Validation loss: 4.6196794234628005

Epoch: 6| Step: 6
Training loss: 4.023982157460996
Validation loss: 4.614494609912697

Epoch: 6| Step: 7
Training loss: 5.4640821317473325
Validation loss: 4.610584768387191

Epoch: 6| Step: 8
Training loss: 3.1822661270307155
Validation loss: 4.605231367685068

Epoch: 6| Step: 9
Training loss: 4.4639598008126695
Validation loss: 4.600389556698933

Epoch: 6| Step: 10
Training loss: 5.530669963187029
Validation loss: 4.596135287886338

Epoch: 6| Step: 11
Training loss: 4.224793576948141
Validation loss: 4.591442575311557

Epoch: 6| Step: 12
Training loss: 5.07540454473578
Validation loss: 4.587199204897271

Epoch: 6| Step: 13
Training loss: 4.416880884313706
Validation loss: 4.582357366284134

Epoch: 17| Step: 0
Training loss: 4.793960729789071
Validation loss: 4.5776520746270215

Epoch: 6| Step: 1
Training loss: 3.2147283521778163
Validation loss: 4.572747727780463

Epoch: 6| Step: 2
Training loss: 5.445707594167343
Validation loss: 4.568550104794507

Epoch: 6| Step: 3
Training loss: 4.193594070924063
Validation loss: 4.564121045454628

Epoch: 6| Step: 4
Training loss: 4.319639626059498
Validation loss: 4.559146641639813

Epoch: 6| Step: 5
Training loss: 4.58535664143748
Validation loss: 4.554962725690967

Epoch: 6| Step: 6
Training loss: 4.950851737061339
Validation loss: 4.550083107940362

Epoch: 6| Step: 7
Training loss: 4.8833446975593136
Validation loss: 4.545869801366573

Epoch: 6| Step: 8
Training loss: 5.447875548499925
Validation loss: 4.541981339125581

Epoch: 6| Step: 9
Training loss: 4.226975172278123
Validation loss: 4.537440909289036

Epoch: 6| Step: 10
Training loss: 4.032833527632485
Validation loss: 4.532348008690764

Epoch: 6| Step: 11
Training loss: 4.6705969653978485
Validation loss: 4.528205532834747

Epoch: 6| Step: 12
Training loss: 4.9019764553642355
Validation loss: 4.5233619521118165

Epoch: 6| Step: 13
Training loss: 5.273528102520293
Validation loss: 4.518756330739815

Epoch: 18| Step: 0
Training loss: 5.0124931658843295
Validation loss: 4.514366352879827

Epoch: 6| Step: 1
Training loss: 4.364985311686654
Validation loss: 4.509877807755034

Epoch: 6| Step: 2
Training loss: 4.2474110515547165
Validation loss: 4.505222274964504

Epoch: 6| Step: 3
Training loss: 3.737324208491937
Validation loss: 4.500373259711384

Epoch: 6| Step: 4
Training loss: 4.6834459193986255
Validation loss: 4.496107095344506

Epoch: 6| Step: 5
Training loss: 4.305544343885912
Validation loss: 4.491923714232019

Epoch: 6| Step: 6
Training loss: 5.047038261678204
Validation loss: 4.487229487661055

Epoch: 6| Step: 7
Training loss: 5.28575240309238
Validation loss: 4.483365254247162

Epoch: 6| Step: 8
Training loss: 5.0495129945306205
Validation loss: 4.478943320923348

Epoch: 6| Step: 9
Training loss: 4.956815962929877
Validation loss: 4.474412296283772

Epoch: 6| Step: 10
Training loss: 5.018825947530115
Validation loss: 4.469079403418613

Epoch: 6| Step: 11
Training loss: 4.247949217627489
Validation loss: 4.4650983851843415

Epoch: 6| Step: 12
Training loss: 4.358667459803109
Validation loss: 4.460619557146498

Epoch: 6| Step: 13
Training loss: 3.9519265510590933
Validation loss: 4.455931465138954

Epoch: 19| Step: 0
Training loss: 4.18977977128397
Validation loss: 4.451194085778101

Epoch: 6| Step: 1
Training loss: 5.182382656301819
Validation loss: 4.446984091318879

Epoch: 6| Step: 2
Training loss: 4.203719426774695
Validation loss: 4.443192515611281

Epoch: 6| Step: 3
Training loss: 4.192794868413401
Validation loss: 4.438245791236688

Epoch: 6| Step: 4
Training loss: 4.545468456940603
Validation loss: 4.433805942919168

Epoch: 6| Step: 5
Training loss: 3.7263573804020798
Validation loss: 4.4296155382127385

Epoch: 6| Step: 6
Training loss: 5.19713552513555
Validation loss: 4.426238406465191

Epoch: 6| Step: 7
Training loss: 4.881981569923453
Validation loss: 4.422656777584078

Epoch: 6| Step: 8
Training loss: 4.268345450895885
Validation loss: 4.416509385577378

Epoch: 6| Step: 9
Training loss: 4.454757872915073
Validation loss: 4.411978548701578

Epoch: 6| Step: 10
Training loss: 3.800644624142199
Validation loss: 4.4071097470831475

Epoch: 6| Step: 11
Training loss: 4.992556371776508
Validation loss: 4.402974419492861

Epoch: 6| Step: 12
Training loss: 4.911331752252996
Validation loss: 4.398863496811226

Epoch: 6| Step: 13
Training loss: 4.840295753585491
Validation loss: 4.39426605102573

Epoch: 20| Step: 0
Training loss: 4.287255300762483
Validation loss: 4.390384400496467

Epoch: 6| Step: 1
Training loss: 4.778216028936893
Validation loss: 4.386075614418883

Epoch: 6| Step: 2
Training loss: 3.7220756982713437
Validation loss: 4.381223375762858

Epoch: 6| Step: 3
Training loss: 4.214471300301433
Validation loss: 4.377275510936106

Epoch: 6| Step: 4
Training loss: 5.322192875076186
Validation loss: 4.372275657736589

Epoch: 6| Step: 5
Training loss: 4.711835430852972
Validation loss: 4.368286376714333

Epoch: 6| Step: 6
Training loss: 4.576822870362138
Validation loss: 4.364028798323872

Epoch: 6| Step: 7
Training loss: 4.6330479888505565
Validation loss: 4.3600020783678985

Epoch: 6| Step: 8
Training loss: 4.954354792371193
Validation loss: 4.355424373839704

Epoch: 6| Step: 9
Training loss: 4.787353409796282
Validation loss: 4.35071811667894

Epoch: 6| Step: 10
Training loss: 4.926969864273277
Validation loss: 4.345985605724247

Epoch: 6| Step: 11
Training loss: 3.947740589466176
Validation loss: 4.341503303270886

Epoch: 6| Step: 12
Training loss: 3.331836475614002
Validation loss: 4.337163180301787

Epoch: 6| Step: 13
Training loss: 4.28514022615509
Validation loss: 4.332607367422078

Epoch: 21| Step: 0
Training loss: 2.99961564462898
Validation loss: 4.3290712719939055

Epoch: 6| Step: 1
Training loss: 3.8534171260536123
Validation loss: 4.3243855504800734

Epoch: 6| Step: 2
Training loss: 4.91240718841238
Validation loss: 4.320413193957755

Epoch: 6| Step: 3
Training loss: 4.052118270187327
Validation loss: 4.3163832535857525

Epoch: 6| Step: 4
Training loss: 4.770562487692055
Validation loss: 4.312309850656284

Epoch: 6| Step: 5
Training loss: 5.2267026326505555
Validation loss: 4.308207453371224

Epoch: 6| Step: 6
Training loss: 3.879907883995889
Validation loss: 4.303842081914288

Epoch: 6| Step: 7
Training loss: 3.997817874792418
Validation loss: 4.299870541568106

Epoch: 6| Step: 8
Training loss: 4.897009244343385
Validation loss: 4.295556179298092

Epoch: 6| Step: 9
Training loss: 4.483831818012
Validation loss: 4.291926971738604

Epoch: 6| Step: 10
Training loss: 4.534316925791636
Validation loss: 4.286950838232294

Epoch: 6| Step: 11
Training loss: 4.56806710667263
Validation loss: 4.282962948312516

Epoch: 6| Step: 12
Training loss: 4.806103307025634
Validation loss: 4.278788060590996

Epoch: 6| Step: 13
Training loss: 4.551979581696585
Validation loss: 4.274338333798886

Epoch: 22| Step: 0
Training loss: 4.935520596239894
Validation loss: 4.26986040648034

Epoch: 6| Step: 1
Training loss: 4.00734536941727
Validation loss: 4.265192738896437

Epoch: 6| Step: 2
Training loss: 4.88893717443338
Validation loss: 4.260592891465247

Epoch: 6| Step: 3
Training loss: 5.162221514046352
Validation loss: 4.2558690106447825

Epoch: 6| Step: 4
Training loss: 4.313864671702361
Validation loss: 4.251685986167791

Epoch: 6| Step: 5
Training loss: 4.269975951437489
Validation loss: 4.246479745660633

Epoch: 6| Step: 6
Training loss: 4.589683341611873
Validation loss: 4.2430012053099055

Epoch: 6| Step: 7
Training loss: 2.9609015872760263
Validation loss: 4.237264944363293

Epoch: 6| Step: 8
Training loss: 4.136083797321664
Validation loss: 4.232592856358781

Epoch: 6| Step: 9
Training loss: 4.529831236670395
Validation loss: 4.229434181860234

Epoch: 6| Step: 10
Training loss: 4.115473526214292
Validation loss: 4.222930664029265

Epoch: 6| Step: 11
Training loss: 4.431195575934077
Validation loss: 4.218406437200579

Epoch: 6| Step: 12
Training loss: 4.40119330090418
Validation loss: 4.214899165861905

Epoch: 6| Step: 13
Training loss: 4.048063243673482
Validation loss: 4.210293561949979

Epoch: 23| Step: 0
Training loss: 4.383729780904861
Validation loss: 4.205760843100606

Epoch: 6| Step: 1
Training loss: 3.596518470202308
Validation loss: 4.201425428555631

Epoch: 6| Step: 2
Training loss: 4.476150893217034
Validation loss: 4.197582518701956

Epoch: 6| Step: 3
Training loss: 4.7052281135288005
Validation loss: 4.192630756047469

Epoch: 6| Step: 4
Training loss: 4.515925097145902
Validation loss: 4.188629624319895

Epoch: 6| Step: 5
Training loss: 3.69145314020318
Validation loss: 4.184389486897931

Epoch: 6| Step: 6
Training loss: 4.863232225531016
Validation loss: 4.180295126411841

Epoch: 6| Step: 7
Training loss: 4.425858607209537
Validation loss: 4.175967548664475

Epoch: 6| Step: 8
Training loss: 4.705205818239218
Validation loss: 4.171479433810906

Epoch: 6| Step: 9
Training loss: 3.639208604067101
Validation loss: 4.167350840028361

Epoch: 6| Step: 10
Training loss: 3.8614384003995927
Validation loss: 4.162893659670452

Epoch: 6| Step: 11
Training loss: 4.909062253823439
Validation loss: 4.158687651120692

Epoch: 6| Step: 12
Training loss: 4.038405108494255
Validation loss: 4.153738099351982

Epoch: 6| Step: 13
Training loss: 4.214341636637667
Validation loss: 4.149058992871335

Epoch: 24| Step: 0
Training loss: 4.414339040009982
Validation loss: 4.144892670515312

Epoch: 6| Step: 1
Training loss: 4.822381909290546
Validation loss: 4.140915002803746

Epoch: 6| Step: 2
Training loss: 4.326556751361746
Validation loss: 4.1360739979054895

Epoch: 6| Step: 3
Training loss: 4.507391898434639
Validation loss: 4.131025556583931

Epoch: 6| Step: 4
Training loss: 3.8355752498091134
Validation loss: 4.126401855700607

Epoch: 6| Step: 5
Training loss: 3.908395528942374
Validation loss: 4.121954246223877

Epoch: 6| Step: 6
Training loss: 4.989394575250494
Validation loss: 4.118368656177297

Epoch: 6| Step: 7
Training loss: 4.54967294712282
Validation loss: 4.113972208857996

Epoch: 6| Step: 8
Training loss: 3.161848485126305
Validation loss: 4.108745763683853

Epoch: 6| Step: 9
Training loss: 3.932868292090353
Validation loss: 4.104739534832129

Epoch: 6| Step: 10
Training loss: 3.3306896375388817
Validation loss: 4.100869372702451

Epoch: 6| Step: 11
Training loss: 4.074994401986425
Validation loss: 4.097067151484634

Epoch: 6| Step: 12
Training loss: 4.205333030476516
Validation loss: 4.092897360341056

Epoch: 6| Step: 13
Training loss: 4.964738101870633
Validation loss: 4.088715794574838

Epoch: 25| Step: 0
Training loss: 3.9897850257879752
Validation loss: 4.084431494098602

Epoch: 6| Step: 1
Training loss: 4.056377080916295
Validation loss: 4.0803991532018875

Epoch: 6| Step: 2
Training loss: 4.004934128732741
Validation loss: 4.076682584725777

Epoch: 6| Step: 3
Training loss: 4.367895406763288
Validation loss: 4.073100584256573

Epoch: 6| Step: 4
Training loss: 3.876005719018266
Validation loss: 4.0683630865296525

Epoch: 6| Step: 5
Training loss: 4.297706773187391
Validation loss: 4.064243275181943

Epoch: 6| Step: 6
Training loss: 4.216469607567222
Validation loss: 4.060077453557243

Epoch: 6| Step: 7
Training loss: 3.616740584313953
Validation loss: 4.055876511599404

Epoch: 6| Step: 8
Training loss: 4.054650572974309
Validation loss: 4.052161594344443

Epoch: 6| Step: 9
Training loss: 4.486658452004276
Validation loss: 4.047917608528335

Epoch: 6| Step: 10
Training loss: 4.3225870887715665
Validation loss: 4.0439022344109405

Epoch: 6| Step: 11
Training loss: 4.474771777252567
Validation loss: 4.0397596612265465

Epoch: 6| Step: 12
Training loss: 3.7892932939537074
Validation loss: 4.035101024524276

Epoch: 6| Step: 13
Training loss: 4.928146193899615
Validation loss: 4.030903981265094

Epoch: 26| Step: 0
Training loss: 3.9329177593805316
Validation loss: 4.026970259882568

Epoch: 6| Step: 1
Training loss: 4.001582786213709
Validation loss: 4.022619032093398

Epoch: 6| Step: 2
Training loss: 4.350726775042227
Validation loss: 4.0184166057559745

Epoch: 6| Step: 3
Training loss: 4.726074597106155
Validation loss: 4.014245792142566

Epoch: 6| Step: 4
Training loss: 3.6820834189542997
Validation loss: 4.010466531550874

Epoch: 6| Step: 5
Training loss: 3.959334250272803
Validation loss: 4.005813288380928

Epoch: 6| Step: 6
Training loss: 4.948893089991145
Validation loss: 4.002623988813742

Epoch: 6| Step: 7
Training loss: 3.59631176738712
Validation loss: 3.9978026871620544

Epoch: 6| Step: 8
Training loss: 3.8263188052043
Validation loss: 3.993290976988044

Epoch: 6| Step: 9
Training loss: 4.031932447760709
Validation loss: 3.9885827279669277

Epoch: 6| Step: 10
Training loss: 4.17223090893185
Validation loss: 3.9846870848658202

Epoch: 6| Step: 11
Training loss: 3.654724324445732
Validation loss: 3.980642387937931

Epoch: 6| Step: 12
Training loss: 3.605675456857301
Validation loss: 3.9763591641924227

Epoch: 6| Step: 13
Training loss: 5.009935806685489
Validation loss: 3.972230801576776

Epoch: 27| Step: 0
Training loss: 4.752971522795901
Validation loss: 3.968035115413489

Epoch: 6| Step: 1
Training loss: 4.691175926837331
Validation loss: 3.9639080277637095

Epoch: 6| Step: 2
Training loss: 4.728889535634595
Validation loss: 3.959574407801416

Epoch: 6| Step: 3
Training loss: 4.580426467630084
Validation loss: 3.954927960594533

Epoch: 6| Step: 4
Training loss: 4.392986707737171
Validation loss: 3.950589659897453

Epoch: 6| Step: 5
Training loss: 3.01509445346136
Validation loss: 3.9462339024038715

Epoch: 6| Step: 6
Training loss: 3.642933649707592
Validation loss: 3.942069696920854

Epoch: 6| Step: 7
Training loss: 4.293789730415712
Validation loss: 3.9377011848197663

Epoch: 6| Step: 8
Training loss: 3.4311773240360943
Validation loss: 3.9336092461511534

Epoch: 6| Step: 9
Training loss: 3.521074335701969
Validation loss: 3.9293325376372823

Epoch: 6| Step: 10
Training loss: 4.160446457747438
Validation loss: 3.925134082293902

Epoch: 6| Step: 11
Training loss: 3.8234682993082902
Validation loss: 3.9211770053336523

Epoch: 6| Step: 12
Training loss: 3.819674635606993
Validation loss: 3.9175238516770587

Epoch: 6| Step: 13
Training loss: 3.734892613757953
Validation loss: 3.9132792589544683

Epoch: 28| Step: 0
Training loss: 3.4712856063692494
Validation loss: 3.9092630997988995

Epoch: 6| Step: 1
Training loss: 4.111688347120046
Validation loss: 3.9052002170112434

Epoch: 6| Step: 2
Training loss: 3.588881536961109
Validation loss: 3.901429418927687

Epoch: 6| Step: 3
Training loss: 3.778435282117764
Validation loss: 3.89753091854925

Epoch: 6| Step: 4
Training loss: 4.037904909220647
Validation loss: 3.893452037271084

Epoch: 6| Step: 5
Training loss: 4.59553337513211
Validation loss: 3.889614520418699

Epoch: 6| Step: 6
Training loss: 4.236282425770685
Validation loss: 3.8858482114368105

Epoch: 6| Step: 7
Training loss: 4.078428059859966
Validation loss: 3.881654317193856

Epoch: 6| Step: 8
Training loss: 4.264285817069851
Validation loss: 3.8778711982363054

Epoch: 6| Step: 9
Training loss: 3.700110258573134
Validation loss: 3.8736238394527702

Epoch: 6| Step: 10
Training loss: 4.464414187081378
Validation loss: 3.8695382419879603

Epoch: 6| Step: 11
Training loss: 5.035839948854463
Validation loss: 3.8654312410059637

Epoch: 6| Step: 12
Training loss: 2.672233958977479
Validation loss: 3.8609051470325353

Epoch: 6| Step: 13
Training loss: 3.6868390282963057
Validation loss: 3.856849863640858

Epoch: 29| Step: 0
Training loss: 3.9497960967539347
Validation loss: 3.852795654312853

Epoch: 6| Step: 1
Training loss: 3.9870821264499483
Validation loss: 3.8486610610958976

Epoch: 6| Step: 2
Training loss: 4.219495241251302
Validation loss: 3.8447454140539863

Epoch: 6| Step: 3
Training loss: 3.474192156302817
Validation loss: 3.840792564914549

Epoch: 6| Step: 4
Training loss: 4.107521712558635
Validation loss: 3.837038854503515

Epoch: 6| Step: 5
Training loss: 3.2100209508194344
Validation loss: 3.8328541304116746

Epoch: 6| Step: 6
Training loss: 3.5391918436629
Validation loss: 3.829068842161669

Epoch: 6| Step: 7
Training loss: 3.843712411091929
Validation loss: 3.825252820471253

Epoch: 6| Step: 8
Training loss: 4.392278068203101
Validation loss: 3.821227252140871

Epoch: 6| Step: 9
Training loss: 4.292615075854475
Validation loss: 3.8170923392673286

Epoch: 6| Step: 10
Training loss: 4.006014117409812
Validation loss: 3.812945230470326

Epoch: 6| Step: 11
Training loss: 4.365998080565537
Validation loss: 3.808970333946277

Epoch: 6| Step: 12
Training loss: 4.1934078162228845
Validation loss: 3.8049333455099577

Epoch: 6| Step: 13
Training loss: 3.6672307938765787
Validation loss: 3.800870783902294

Epoch: 30| Step: 0
Training loss: 3.1546518037542093
Validation loss: 3.7966230855711776

Epoch: 6| Step: 1
Training loss: 2.6757723397433764
Validation loss: 3.7926247333021803

Epoch: 6| Step: 2
Training loss: 3.8884423196307933
Validation loss: 3.7886712255692685

Epoch: 6| Step: 3
Training loss: 4.8784333878763055
Validation loss: 3.7847875435856873

Epoch: 6| Step: 4
Training loss: 4.6813733562112025
Validation loss: 3.780687379621435

Epoch: 6| Step: 5
Training loss: 4.007186394579533
Validation loss: 3.7766764490910494

Epoch: 6| Step: 6
Training loss: 3.103895102960257
Validation loss: 3.772265034262395

Epoch: 6| Step: 7
Training loss: 4.489468011754227
Validation loss: 3.7681669991546913

Epoch: 6| Step: 8
Training loss: 3.933463555674978
Validation loss: 3.764123514392694

Epoch: 6| Step: 9
Training loss: 3.7840071785276037
Validation loss: 3.7598255076738205

Epoch: 6| Step: 10
Training loss: 4.1888846769797965
Validation loss: 3.755596509421124

Epoch: 6| Step: 11
Training loss: 3.5683089964201677
Validation loss: 3.752062315231555

Epoch: 6| Step: 12
Training loss: 4.15939602061978
Validation loss: 3.74820543370917

Epoch: 6| Step: 13
Training loss: 3.532591303396629
Validation loss: 3.743884727078967

Epoch: 31| Step: 0
Training loss: 3.7042672371415315
Validation loss: 3.7392663777092965

Epoch: 6| Step: 1
Training loss: 4.242883670791843
Validation loss: 3.7353983265727413

Epoch: 6| Step: 2
Training loss: 4.448066702939473
Validation loss: 3.7311885971392926

Epoch: 6| Step: 3
Training loss: 3.1673876962120118
Validation loss: 3.7271136096956385

Epoch: 6| Step: 4
Training loss: 3.6882148954874374
Validation loss: 3.7230949983897688

Epoch: 6| Step: 5
Training loss: 4.013848175112203
Validation loss: 3.719089481875692

Epoch: 6| Step: 6
Training loss: 4.361849175029784
Validation loss: 3.715097680089092

Epoch: 6| Step: 7
Training loss: 3.479275242982461
Validation loss: 3.7109538402532243

Epoch: 6| Step: 8
Training loss: 3.6164178214770857
Validation loss: 3.7069634611244573

Epoch: 6| Step: 9
Training loss: 4.139638876898314
Validation loss: 3.7025821464950903

Epoch: 6| Step: 10
Training loss: 3.715244468151441
Validation loss: 3.6988368577417967

Epoch: 6| Step: 11
Training loss: 4.124181955313939
Validation loss: 3.694721370889046

Epoch: 6| Step: 12
Training loss: 3.9043558640100406
Validation loss: 3.6901993004545424

Epoch: 6| Step: 13
Training loss: 2.978388829268359
Validation loss: 3.686108967974405

Epoch: 32| Step: 0
Training loss: 4.512432514224957
Validation loss: 3.682324435867477

Epoch: 6| Step: 1
Training loss: 3.348184087707942
Validation loss: 3.678041774485554

Epoch: 6| Step: 2
Training loss: 4.0896376127014795
Validation loss: 3.6738955518425382

Epoch: 6| Step: 3
Training loss: 3.4945762025878557
Validation loss: 3.6701226564399456

Epoch: 6| Step: 4
Training loss: 3.619076855381252
Validation loss: 3.6660205459629442

Epoch: 6| Step: 5
Training loss: 3.5003264138737276
Validation loss: 3.6621332898524694

Epoch: 6| Step: 6
Training loss: 4.25293585407848
Validation loss: 3.658020004085671

Epoch: 6| Step: 7
Training loss: 4.0021952327326815
Validation loss: 3.653701513531824

Epoch: 6| Step: 8
Training loss: 3.410381646152247
Validation loss: 3.6501160816563414

Epoch: 6| Step: 9
Training loss: 3.306271004565028
Validation loss: 3.646019721943381

Epoch: 6| Step: 10
Training loss: 3.6076648178041806
Validation loss: 3.641830986790917

Epoch: 6| Step: 11
Training loss: 3.6930085756443507
Validation loss: 3.6381434549880334

Epoch: 6| Step: 12
Training loss: 3.7552917019729293
Validation loss: 3.634177024830629

Epoch: 6| Step: 13
Training loss: 4.276925234590882
Validation loss: 3.630380430297202

Epoch: 33| Step: 0
Training loss: 3.7955895276848493
Validation loss: 3.626478639022306

Epoch: 6| Step: 1
Training loss: 3.472851227477699
Validation loss: 3.622506413073465

Epoch: 6| Step: 2
Training loss: 3.710308848889859
Validation loss: 3.6186264833970876

Epoch: 6| Step: 3
Training loss: 3.6432077308589514
Validation loss: 3.6148958355083654

Epoch: 6| Step: 4
Training loss: 2.9783625729119443
Validation loss: 3.6109416913776182

Epoch: 6| Step: 5
Training loss: 3.6381274648925737
Validation loss: 3.6071492387966053

Epoch: 6| Step: 6
Training loss: 4.3795255959750685
Validation loss: 3.60350967034569

Epoch: 6| Step: 7
Training loss: 4.347174961427671
Validation loss: 3.599743806588647

Epoch: 6| Step: 8
Training loss: 2.942960817201281
Validation loss: 3.595709877208121

Epoch: 6| Step: 9
Training loss: 3.975420534932805
Validation loss: 3.591682215138448

Epoch: 6| Step: 10
Training loss: 4.34273401906863
Validation loss: 3.587980421199277

Epoch: 6| Step: 11
Training loss: 3.175471629760079
Validation loss: 3.5840779499307787

Epoch: 6| Step: 12
Training loss: 3.726767096511155
Validation loss: 3.5799553644249853

Epoch: 6| Step: 13
Training loss: 3.8429289150170374
Validation loss: 3.5761306513089712

Epoch: 34| Step: 0
Training loss: 3.9156819722261904
Validation loss: 3.5721127168144062

Epoch: 6| Step: 1
Training loss: 3.480279953756386
Validation loss: 3.568353038741153

Epoch: 6| Step: 2
Training loss: 3.2628898300011
Validation loss: 3.564686667399113

Epoch: 6| Step: 3
Training loss: 3.589280508724903
Validation loss: 3.5606847231726775

Epoch: 6| Step: 4
Training loss: 3.7548809076311813
Validation loss: 3.5568081409402366

Epoch: 6| Step: 5
Training loss: 3.4293283609034835
Validation loss: 3.552968978475849

Epoch: 6| Step: 6
Training loss: 3.672812484212807
Validation loss: 3.549361467917252

Epoch: 6| Step: 7
Training loss: 3.767906415923208
Validation loss: 3.5457654945766386

Epoch: 6| Step: 8
Training loss: 4.013386499511106
Validation loss: 3.5418506275346133

Epoch: 6| Step: 9
Training loss: 3.9190908329417606
Validation loss: 3.5379320350366794

Epoch: 6| Step: 10
Training loss: 3.7378740716727727
Validation loss: 3.5339885209175437

Epoch: 6| Step: 11
Training loss: 3.1966919847532607
Validation loss: 3.5299891918906647

Epoch: 6| Step: 12
Training loss: 3.97072546146263
Validation loss: 3.5263811602580186

Epoch: 6| Step: 13
Training loss: 3.769836603160191
Validation loss: 3.522446858944003

Epoch: 35| Step: 0
Training loss: 3.8724292718623246
Validation loss: 3.518352123326577

Epoch: 6| Step: 1
Training loss: 3.6092029877335854
Validation loss: 3.514609838784125

Epoch: 6| Step: 2
Training loss: 4.105572583947996
Validation loss: 3.510785378732927

Epoch: 6| Step: 3
Training loss: 4.034510040977956
Validation loss: 3.506901929406695

Epoch: 6| Step: 4
Training loss: 3.668762186215387
Validation loss: 3.502840547018565

Epoch: 6| Step: 5
Training loss: 3.3124023998924823
Validation loss: 3.499109200240938

Epoch: 6| Step: 6
Training loss: 4.144585554250739
Validation loss: 3.4953704369895617

Epoch: 6| Step: 7
Training loss: 3.325083744457244
Validation loss: 3.4915106655829997

Epoch: 6| Step: 8
Training loss: 3.424086879216253
Validation loss: 3.487347337213965

Epoch: 6| Step: 9
Training loss: 3.6662410286742566
Validation loss: 3.483547095229955

Epoch: 6| Step: 10
Training loss: 2.9352231231048975
Validation loss: 3.4797081592564902

Epoch: 6| Step: 11
Training loss: 3.717450596084119
Validation loss: 3.4759153756777343

Epoch: 6| Step: 12
Training loss: 3.598687801691468
Validation loss: 3.472203068150566

Epoch: 6| Step: 13
Training loss: 3.231274579247969
Validation loss: 3.468457985806695

Epoch: 36| Step: 0
Training loss: 3.0665888057720623
Validation loss: 3.4648864582903127

Epoch: 6| Step: 1
Training loss: 3.505488588069981
Validation loss: 3.461310395990126

Epoch: 6| Step: 2
Training loss: 3.750409167537616
Validation loss: 3.457542654598629

Epoch: 6| Step: 3
Training loss: 3.7220380335795986
Validation loss: 3.4540214698255287

Epoch: 6| Step: 4
Training loss: 4.140748911029194
Validation loss: 3.4502427628471217

Epoch: 6| Step: 5
Training loss: 3.5356911607566817
Validation loss: 3.4465347855335895

Epoch: 6| Step: 6
Training loss: 3.7567164989868167
Validation loss: 3.442490717502066

Epoch: 6| Step: 7
Training loss: 3.6930683572053216
Validation loss: 3.4387348846876176

Epoch: 6| Step: 8
Training loss: 3.378776133242529
Validation loss: 3.4349149058026733

Epoch: 6| Step: 9
Training loss: 3.5549716039454378
Validation loss: 3.4313168258042634

Epoch: 6| Step: 10
Training loss: 3.2171383869263015
Validation loss: 3.42751161552481

Epoch: 6| Step: 11
Training loss: 3.0412987961247033
Validation loss: 3.424111945862438

Epoch: 6| Step: 12
Training loss: 3.8105153405601886
Validation loss: 3.420466209967028

Epoch: 6| Step: 13
Training loss: 3.7925903257251736
Validation loss: 3.41691546968616

Epoch: 37| Step: 0
Training loss: 3.23780162098499
Validation loss: 3.413383084570387

Epoch: 6| Step: 1
Training loss: 2.9271535265414994
Validation loss: 3.409857912767042

Epoch: 6| Step: 2
Training loss: 3.6877900348978248
Validation loss: 3.4063950020727307

Epoch: 6| Step: 3
Training loss: 3.719523373495126
Validation loss: 3.4026718010694257

Epoch: 6| Step: 4
Training loss: 2.8729937643799395
Validation loss: 3.399363354373488

Epoch: 6| Step: 5
Training loss: 3.2233277886969907
Validation loss: 3.3961850005683027

Epoch: 6| Step: 6
Training loss: 3.5343913731419216
Validation loss: 3.392723266331329

Epoch: 6| Step: 7
Training loss: 4.41414179097755
Validation loss: 3.3904389595523043

Epoch: 6| Step: 8
Training loss: 3.66398753921189
Validation loss: 3.3857683361016737

Epoch: 6| Step: 9
Training loss: 4.005909131288383
Validation loss: 3.381909773429336

Epoch: 6| Step: 10
Training loss: 3.973478129093303
Validation loss: 3.378158598340762

Epoch: 6| Step: 11
Training loss: 2.497348714681666
Validation loss: 3.374657695977888

Epoch: 6| Step: 12
Training loss: 3.176407905866034
Validation loss: 3.3713303855333447

Epoch: 6| Step: 13
Training loss: 3.981484235882525
Validation loss: 3.367899831905731

Epoch: 38| Step: 0
Training loss: 3.713864491231272
Validation loss: 3.364605827768124

Epoch: 6| Step: 1
Training loss: 3.535906936439247
Validation loss: 3.361062186562018

Epoch: 6| Step: 2
Training loss: 3.7755658009912563
Validation loss: 3.3573623424117067

Epoch: 6| Step: 3
Training loss: 3.0355159983269124
Validation loss: 3.3535554972733093

Epoch: 6| Step: 4
Training loss: 3.497111627312848
Validation loss: 3.3498970167737854

Epoch: 6| Step: 5
Training loss: 3.1138936855957158
Validation loss: 3.3461574669803467

Epoch: 6| Step: 6
Training loss: 3.5518861568610656
Validation loss: 3.3426293845327386

Epoch: 6| Step: 7
Training loss: 3.6295077479335363
Validation loss: 3.339195441368067

Epoch: 6| Step: 8
Training loss: 3.191993239173326
Validation loss: 3.3356208561654785

Epoch: 6| Step: 9
Training loss: 3.415245846211291
Validation loss: 3.3324969354965037

Epoch: 6| Step: 10
Training loss: 3.5141875316448834
Validation loss: 3.3289922978105917

Epoch: 6| Step: 11
Training loss: 3.4427970994056243
Validation loss: 3.325439969929014

Epoch: 6| Step: 12
Training loss: 3.5701784071167335
Validation loss: 3.3223247220066283

Epoch: 6| Step: 13
Training loss: 3.6784984830060132
Validation loss: 3.319023402674899

Epoch: 39| Step: 0
Training loss: 3.319361651535072
Validation loss: 3.315662793451337

Epoch: 6| Step: 1
Training loss: 2.6530445279879062
Validation loss: 3.3123263187580503

Epoch: 6| Step: 2
Training loss: 3.6569813054029146
Validation loss: 3.30909391943969

Epoch: 6| Step: 3
Training loss: 4.170492679023789
Validation loss: 3.305654890685362

Epoch: 6| Step: 4
Training loss: 4.110856981985967
Validation loss: 3.302346845796396

Epoch: 6| Step: 5
Training loss: 3.495768577754933
Validation loss: 3.298894664333495

Epoch: 6| Step: 6
Training loss: 2.8870462895095734
Validation loss: 3.2952991232699236

Epoch: 6| Step: 7
Training loss: 2.944690588093583
Validation loss: 3.2920103537526857

Epoch: 6| Step: 8
Training loss: 3.490545582358783
Validation loss: 3.2890387116672097

Epoch: 6| Step: 9
Training loss: 3.6208424897657947
Validation loss: 3.285777392729109

Epoch: 6| Step: 10
Training loss: 2.807341613513938
Validation loss: 3.2825865430383736

Epoch: 6| Step: 11
Training loss: 3.815454307693473
Validation loss: 3.2792242306055956

Epoch: 6| Step: 12
Training loss: 4.207600192930041
Validation loss: 3.2760397825655145

Epoch: 6| Step: 13
Training loss: 2.18635169270926
Validation loss: 3.2727064288965493

Epoch: 40| Step: 0
Training loss: 3.4610439998868596
Validation loss: 3.26932577553239

Epoch: 6| Step: 1
Training loss: 3.2252380756358514
Validation loss: 3.2658750204112414

Epoch: 6| Step: 2
Training loss: 3.63609903630006
Validation loss: 3.2628395089045257

Epoch: 6| Step: 3
Training loss: 3.787272047982517
Validation loss: 3.259667616205623

Epoch: 6| Step: 4
Training loss: 2.9597974207865523
Validation loss: 3.2563183206821393

Epoch: 6| Step: 5
Training loss: 4.02301414262342
Validation loss: 3.2531525287324548

Epoch: 6| Step: 6
Training loss: 2.9503396436785922
Validation loss: 3.2503080099821977

Epoch: 6| Step: 7
Training loss: 2.6713357124625836
Validation loss: 3.2469684693850076

Epoch: 6| Step: 8
Training loss: 3.4500345753581936
Validation loss: 3.243997606297749

Epoch: 6| Step: 9
Training loss: 3.2539581258057195
Validation loss: 3.240766515679771

Epoch: 6| Step: 10
Training loss: 3.4015530741626265
Validation loss: 3.2375495430630306

Epoch: 6| Step: 11
Training loss: 4.132218489476977
Validation loss: 3.234546011858856

Epoch: 6| Step: 12
Training loss: 2.9104275775359936
Validation loss: 3.2311132818993378

Epoch: 6| Step: 13
Training loss: 3.236213198585535
Validation loss: 3.227994537917711

Epoch: 41| Step: 0
Training loss: 3.471728446607312
Validation loss: 3.2246840383818713

Epoch: 6| Step: 1
Training loss: 4.32415038126282
Validation loss: 3.2214961759473613

Epoch: 6| Step: 2
Training loss: 4.043620210949637
Validation loss: 3.2180784321147784

Epoch: 6| Step: 3
Training loss: 3.213096913495249
Validation loss: 3.2144528688634733

Epoch: 6| Step: 4
Training loss: 3.749883141286302
Validation loss: 3.2107672603675605

Epoch: 6| Step: 5
Training loss: 3.1610573897204013
Validation loss: 3.2072159361233004

Epoch: 6| Step: 6
Training loss: 3.1910959043851825
Validation loss: 3.203877963753832

Epoch: 6| Step: 7
Training loss: 3.18240487770869
Validation loss: 3.200320670829489

Epoch: 6| Step: 8
Training loss: 3.0960353540674004
Validation loss: 3.196963330711349

Epoch: 6| Step: 9
Training loss: 2.986635640130783
Validation loss: 3.1937991960273715

Epoch: 6| Step: 10
Training loss: 2.4754317436878503
Validation loss: 3.190904407428623

Epoch: 6| Step: 11
Training loss: 3.487768325601115
Validation loss: 3.187913967502541

Epoch: 6| Step: 12
Training loss: 3.021982399768688
Validation loss: 3.185079216323797

Epoch: 6| Step: 13
Training loss: 3.0366496336117628
Validation loss: 3.182230689197633

Epoch: 42| Step: 0
Training loss: 3.261023094322409
Validation loss: 3.1794059310077407

Epoch: 6| Step: 1
Training loss: 3.16731362677452
Validation loss: 3.1765932966354073

Epoch: 6| Step: 2
Training loss: 3.150646561161206
Validation loss: 3.1738849529167243

Epoch: 6| Step: 3
Training loss: 2.8979529621000464
Validation loss: 3.171145250281766

Epoch: 6| Step: 4
Training loss: 3.3877911657219877
Validation loss: 3.1683952900465653

Epoch: 6| Step: 5
Training loss: 3.2308744939137397
Validation loss: 3.165805866965444

Epoch: 6| Step: 6
Training loss: 2.874662794157733
Validation loss: 3.163252713536438

Epoch: 6| Step: 7
Training loss: 3.587993489526394
Validation loss: 3.1606291427720934

Epoch: 6| Step: 8
Training loss: 3.073982045465576
Validation loss: 3.1577970030925155

Epoch: 6| Step: 9
Training loss: 3.2375035289612613
Validation loss: 3.1551014790283234

Epoch: 6| Step: 10
Training loss: 3.55319591709784
Validation loss: 3.1522089706027017

Epoch: 6| Step: 11
Training loss: 2.7990559008087086
Validation loss: 3.149420825251137

Epoch: 6| Step: 12
Training loss: 4.002225733455473
Validation loss: 3.146614348278349

Epoch: 6| Step: 13
Training loss: 3.7746513104608703
Validation loss: 3.14363114958348

Epoch: 43| Step: 0
Training loss: 3.9229588929569577
Validation loss: 3.1406420553829237

Epoch: 6| Step: 1
Training loss: 3.829728767611576
Validation loss: 3.1375976319339616

Epoch: 6| Step: 2
Training loss: 3.6094686652906867
Validation loss: 3.1346487116575954

Epoch: 6| Step: 3
Training loss: 3.5246809902988416
Validation loss: 3.1314457982534667

Epoch: 6| Step: 4
Training loss: 2.7145473400744233
Validation loss: 3.1283382768613937

Epoch: 6| Step: 5
Training loss: 3.130337239095614
Validation loss: 3.125358052404423

Epoch: 6| Step: 6
Training loss: 2.569436152905898
Validation loss: 3.122091325679826

Epoch: 6| Step: 7
Training loss: 3.4040904067301714
Validation loss: 3.119374807249886

Epoch: 6| Step: 8
Training loss: 3.109530651088063
Validation loss: 3.1164965074840825

Epoch: 6| Step: 9
Training loss: 2.838441190195378
Validation loss: 3.1137857000529254

Epoch: 6| Step: 10
Training loss: 3.407830807699204
Validation loss: 3.1112898867951975

Epoch: 6| Step: 11
Training loss: 2.460454790518225
Validation loss: 3.1084778735906453

Epoch: 6| Step: 12
Training loss: 3.625083133138876
Validation loss: 3.1059852410510507

Epoch: 6| Step: 13
Training loss: 3.134416963670985
Validation loss: 3.103223943397441

Epoch: 44| Step: 0
Training loss: 2.7099546030331374
Validation loss: 3.100615785309911

Epoch: 6| Step: 1
Training loss: 3.0876015341430603
Validation loss: 3.0980092922200217

Epoch: 6| Step: 2
Training loss: 3.63469150309801
Validation loss: 3.095616326784938

Epoch: 6| Step: 3
Training loss: 3.3638582343893946
Validation loss: 3.093189574064953

Epoch: 6| Step: 4
Training loss: 3.2806798530421615
Validation loss: 3.090681243065874

Epoch: 6| Step: 5
Training loss: 3.3151129727222903
Validation loss: 3.0879006237854996

Epoch: 6| Step: 6
Training loss: 2.8217976640853175
Validation loss: 3.0851762178646966

Epoch: 6| Step: 7
Training loss: 3.2691336587144977
Validation loss: 3.0827036850484677

Epoch: 6| Step: 8
Training loss: 3.5330781508611966
Validation loss: 3.0800488135362847

Epoch: 6| Step: 9
Training loss: 3.1274378613489864
Validation loss: 3.0772702600465736

Epoch: 6| Step: 10
Training loss: 2.9789263932942416
Validation loss: 3.0745732556645042

Epoch: 6| Step: 11
Training loss: 3.421661927718052
Validation loss: 3.0717399714956555

Epoch: 6| Step: 12
Training loss: 2.8816751029966854
Validation loss: 3.068869007959897

Epoch: 6| Step: 13
Training loss: 3.56005802450148
Validation loss: 3.066267421033771

Epoch: 45| Step: 0
Training loss: 3.46905241326736
Validation loss: 3.0634726582191076

Epoch: 6| Step: 1
Training loss: 3.520751470633613
Validation loss: 3.0608393649664887

Epoch: 6| Step: 2
Training loss: 3.5782535979637236
Validation loss: 3.0579912900432644

Epoch: 6| Step: 3
Training loss: 3.1484962628278623
Validation loss: 3.055199829741769

Epoch: 6| Step: 4
Training loss: 2.54641944227835
Validation loss: 3.052450884841242

Epoch: 6| Step: 5
Training loss: 3.133671897155316
Validation loss: 3.0499277325182614

Epoch: 6| Step: 6
Training loss: 3.5769314170279505
Validation loss: 3.0471065726677007

Epoch: 6| Step: 7
Training loss: 2.684440379295822
Validation loss: 3.0445222427199683

Epoch: 6| Step: 8
Training loss: 2.5632586402907425
Validation loss: 3.0420125390153223

Epoch: 6| Step: 9
Training loss: 2.8807625447180287
Validation loss: 3.039205448086943

Epoch: 6| Step: 10
Training loss: 3.4844012751251467
Validation loss: 3.0370443748068445

Epoch: 6| Step: 11
Training loss: 3.256742672249675
Validation loss: 3.034461087054313

Epoch: 6| Step: 12
Training loss: 2.924032139206209
Validation loss: 3.031953330227672

Epoch: 6| Step: 13
Training loss: 3.573624358235204
Validation loss: 3.0294650088753965

Epoch: 46| Step: 0
Training loss: 3.279899101101026
Validation loss: 3.027135028822131

Epoch: 6| Step: 1
Training loss: 2.990151133210239
Validation loss: 3.024441548231714

Epoch: 6| Step: 2
Training loss: 2.6904923391922524
Validation loss: 3.0217846567297846

Epoch: 6| Step: 3
Training loss: 2.9870662039082365
Validation loss: 3.0195116023534387

Epoch: 6| Step: 4
Training loss: 3.8651322268905184
Validation loss: 3.016961863776486

Epoch: 6| Step: 5
Training loss: 3.4434316609152495
Validation loss: 3.0144632371356592

Epoch: 6| Step: 6
Training loss: 3.559903989204416
Validation loss: 3.0120660471942373

Epoch: 6| Step: 7
Training loss: 3.0446910366917583
Validation loss: 3.0093282208053482

Epoch: 6| Step: 8
Training loss: 3.2490322432815746
Validation loss: 3.006865196172399

Epoch: 6| Step: 9
Training loss: 3.0221509142797025
Validation loss: 3.0042699784615077

Epoch: 6| Step: 10
Training loss: 3.2713316195680235
Validation loss: 3.001803783043476

Epoch: 6| Step: 11
Training loss: 3.2513496824219406
Validation loss: 2.9999541703008457

Epoch: 6| Step: 12
Training loss: 2.322632730918596
Validation loss: 2.9983211362893534

Epoch: 6| Step: 13
Training loss: 2.888687226600942
Validation loss: 2.994900050758965

Epoch: 47| Step: 0
Training loss: 3.255092738833
Validation loss: 2.9926360668074783

Epoch: 6| Step: 1
Training loss: 3.6282037192519323
Validation loss: 2.9903793648639017

Epoch: 6| Step: 2
Training loss: 2.623951293725877
Validation loss: 2.989001604075728

Epoch: 6| Step: 3
Training loss: 2.901762255898698
Validation loss: 2.9859230726510004

Epoch: 6| Step: 4
Training loss: 2.9536829829997835
Validation loss: 2.9834443350516815

Epoch: 6| Step: 5
Training loss: 2.6631568420841365
Validation loss: 2.981211411861517

Epoch: 6| Step: 6
Training loss: 3.5397105181593824
Validation loss: 2.9790726271150114

Epoch: 6| Step: 7
Training loss: 3.1352997987243354
Validation loss: 2.977046016159361

Epoch: 6| Step: 8
Training loss: 2.7898953260249355
Validation loss: 2.9753395698864353

Epoch: 6| Step: 9
Training loss: 2.978949763442686
Validation loss: 2.9732714971675454

Epoch: 6| Step: 10
Training loss: 3.117382836973717
Validation loss: 2.971079839044759

Epoch: 6| Step: 11
Training loss: 3.4564251212098136
Validation loss: 2.9692764886172016

Epoch: 6| Step: 12
Training loss: 2.7589537768859347
Validation loss: 2.9669376931706295

Epoch: 6| Step: 13
Training loss: 3.6232191512696885
Validation loss: 2.9646340062700167

Epoch: 48| Step: 0
Training loss: 2.774347290395676
Validation loss: 2.9622150171400077

Epoch: 6| Step: 1
Training loss: 2.754114887098999
Validation loss: 2.9596342843967234

Epoch: 6| Step: 2
Training loss: 3.0623637577814207
Validation loss: 2.957619719781434

Epoch: 6| Step: 3
Training loss: 3.268996984658378
Validation loss: 2.9553994598454265

Epoch: 6| Step: 4
Training loss: 3.397172223154065
Validation loss: 2.9532230771310446

Epoch: 6| Step: 5
Training loss: 3.0052011226433115
Validation loss: 2.951149873716729

Epoch: 6| Step: 6
Training loss: 3.330690210197603
Validation loss: 2.948775747008102

Epoch: 6| Step: 7
Training loss: 2.7652526432387186
Validation loss: 2.9466247063953284

Epoch: 6| Step: 8
Training loss: 3.1336382683706603
Validation loss: 2.9449946386291717

Epoch: 6| Step: 9
Training loss: 3.470392061890475
Validation loss: 2.9426136823077624

Epoch: 6| Step: 10
Training loss: 2.4243995552363424
Validation loss: 2.9404977017563234

Epoch: 6| Step: 11
Training loss: 3.642878019449375
Validation loss: 2.9384444051064587

Epoch: 6| Step: 12
Training loss: 2.7301618979380393
Validation loss: 2.9363586968204043

Epoch: 6| Step: 13
Training loss: 3.2422588294582075
Validation loss: 2.934190956007243

Epoch: 49| Step: 0
Training loss: 3.1170109672561495
Validation loss: 2.9321498576825706

Epoch: 6| Step: 1
Training loss: 3.0137206077961953
Validation loss: 2.929544308024098

Epoch: 6| Step: 2
Training loss: 3.066858887522235
Validation loss: 2.9271901248081047

Epoch: 6| Step: 3
Training loss: 3.5973331003926594
Validation loss: 2.9245683356958208

Epoch: 6| Step: 4
Training loss: 2.3673430036073175
Validation loss: 2.9226902659024963

Epoch: 6| Step: 5
Training loss: 3.6366830858884995
Validation loss: 2.9202963904624806

Epoch: 6| Step: 6
Training loss: 2.976582684786384
Validation loss: 2.918306616271061

Epoch: 6| Step: 7
Training loss: 2.9735986566696027
Validation loss: 2.915906212081178

Epoch: 6| Step: 8
Training loss: 2.8475728591827973
Validation loss: 2.9140512092923863

Epoch: 6| Step: 9
Training loss: 3.0255383036200953
Validation loss: 2.9118117025318417

Epoch: 6| Step: 10
Training loss: 3.3291044271584918
Validation loss: 2.909868005050855

Epoch: 6| Step: 11
Training loss: 3.3272689649709397
Validation loss: 2.9076424274453925

Epoch: 6| Step: 12
Training loss: 3.2073416890704394
Validation loss: 2.905711202685019

Epoch: 6| Step: 13
Training loss: 1.9764300516857516
Validation loss: 2.903547377121715

Epoch: 50| Step: 0
Training loss: 3.3301113451422193
Validation loss: 2.901274684859612

Epoch: 6| Step: 1
Training loss: 3.1597774924636517
Validation loss: 2.89938869445948

Epoch: 6| Step: 2
Training loss: 3.645533841865619
Validation loss: 2.8974369512220215

Epoch: 6| Step: 3
Training loss: 3.8892734125556543
Validation loss: 2.895186075194231

Epoch: 6| Step: 4
Training loss: 2.979145361195033
Validation loss: 2.892833711303867

Epoch: 6| Step: 5
Training loss: 3.2759723180921796
Validation loss: 2.8906604386640278

Epoch: 6| Step: 6
Training loss: 2.2647217100856567
Validation loss: 2.888250183042947

Epoch: 6| Step: 7
Training loss: 3.183815865286542
Validation loss: 2.8862631252822486

Epoch: 6| Step: 8
Training loss: 2.980529064603103
Validation loss: 2.884060762590668

Epoch: 6| Step: 9
Training loss: 2.8953922036363946
Validation loss: 2.882335165008296

Epoch: 6| Step: 10
Training loss: 2.5803728880993506
Validation loss: 2.88032113947136

Epoch: 6| Step: 11
Training loss: 2.4912974523148868
Validation loss: 2.8787347336172577

Epoch: 6| Step: 12
Training loss: 2.8523361201773296
Validation loss: 2.877001480348781

Epoch: 6| Step: 13
Training loss: 2.4859925768090023
Validation loss: 2.8750535987612333

Epoch: 51| Step: 0
Training loss: 2.9785825427933665
Validation loss: 2.873221607543825

Epoch: 6| Step: 1
Training loss: 2.2530333946113377
Validation loss: 2.871543727913999

Epoch: 6| Step: 2
Training loss: 2.5906268700752824
Validation loss: 2.869880541044332

Epoch: 6| Step: 3
Training loss: 2.8639233377947857
Validation loss: 2.8690358093657835

Epoch: 6| Step: 4
Training loss: 3.359340649806213
Validation loss: 2.867104843569728

Epoch: 6| Step: 5
Training loss: 3.2119100541077907
Validation loss: 2.864618902274587

Epoch: 6| Step: 6
Training loss: 3.411669697899179
Validation loss: 2.86329623813011

Epoch: 6| Step: 7
Training loss: 2.8398595334628447
Validation loss: 2.8602794752309095

Epoch: 6| Step: 8
Training loss: 2.9050487373715277
Validation loss: 2.8592957171234334

Epoch: 6| Step: 9
Training loss: 3.1753968478918604
Validation loss: 2.857400320010478

Epoch: 6| Step: 10
Training loss: 3.0802097135215423
Validation loss: 2.856555556210372

Epoch: 6| Step: 11
Training loss: 3.2648927880716907
Validation loss: 2.854312466055495

Epoch: 6| Step: 12
Training loss: 3.5109607188157748
Validation loss: 2.8527440658363643

Epoch: 6| Step: 13
Training loss: 2.3048058430950826
Validation loss: 2.8507789824373875

Epoch: 52| Step: 0
Training loss: 2.878685289285888
Validation loss: 2.8493972709841366

Epoch: 6| Step: 1
Training loss: 3.047507978370994
Validation loss: 2.847785545591881

Epoch: 6| Step: 2
Training loss: 3.3239088978683102
Validation loss: 2.8461937517413993

Epoch: 6| Step: 3
Training loss: 3.031079788934902
Validation loss: 2.8443995841242233

Epoch: 6| Step: 4
Training loss: 2.995459299166635
Validation loss: 2.842790532604008

Epoch: 6| Step: 5
Training loss: 3.1799271326893432
Validation loss: 2.8412397574830175

Epoch: 6| Step: 6
Training loss: 2.8109528418690033
Validation loss: 2.839642125335275

Epoch: 6| Step: 7
Training loss: 2.8309130335486508
Validation loss: 2.8378313954966314

Epoch: 6| Step: 8
Training loss: 2.847847805199925
Validation loss: 2.835996586908314

Epoch: 6| Step: 9
Training loss: 2.8965148306831914
Validation loss: 2.8339971484670423

Epoch: 6| Step: 10
Training loss: 3.5082249048531975
Validation loss: 2.8322198072780433

Epoch: 6| Step: 11
Training loss: 2.7932403645790966
Validation loss: 2.8307156999695247

Epoch: 6| Step: 12
Training loss: 2.8023838794345868
Validation loss: 2.829045702596003

Epoch: 6| Step: 13
Training loss: 2.6801978868047898
Validation loss: 2.8273540169525164

Epoch: 53| Step: 0
Training loss: 3.4314856887779084
Validation loss: 2.825761640046671

Epoch: 6| Step: 1
Training loss: 3.1562460719924506
Validation loss: 2.8242150074084096

Epoch: 6| Step: 2
Training loss: 3.005644257044127
Validation loss: 2.8224459791800096

Epoch: 6| Step: 3
Training loss: 3.1795808741432077
Validation loss: 2.8205479658322465

Epoch: 6| Step: 4
Training loss: 2.4180651816519103
Validation loss: 2.8189376833418285

Epoch: 6| Step: 5
Training loss: 3.070292931414262
Validation loss: 2.817142780024475

Epoch: 6| Step: 6
Training loss: 2.498356278788948
Validation loss: 2.8156475962396508

Epoch: 6| Step: 7
Training loss: 3.222715583023879
Validation loss: 2.81419294762043

Epoch: 6| Step: 8
Training loss: 3.243025705843197
Validation loss: 2.8123737730734577

Epoch: 6| Step: 9
Training loss: 2.5980024293531376
Validation loss: 2.810834462127625

Epoch: 6| Step: 10
Training loss: 2.7938949649758458
Validation loss: 2.809521956343113

Epoch: 6| Step: 11
Training loss: 2.8065552509359932
Validation loss: 2.8068993789156633

Epoch: 6| Step: 12
Training loss: 2.8852986519339816
Validation loss: 2.8070012769860404

Epoch: 6| Step: 13
Training loss: 2.9118005395634756
Validation loss: 2.805626827904212

Epoch: 54| Step: 0
Training loss: 2.755310825876526
Validation loss: 2.8032311046964513

Epoch: 6| Step: 1
Training loss: 3.026093491828873
Validation loss: 2.8026914303066985

Epoch: 6| Step: 2
Training loss: 3.1497279095075283
Validation loss: 2.7995535244788075

Epoch: 6| Step: 3
Training loss: 2.8014485563136575
Validation loss: 2.798663428874306

Epoch: 6| Step: 4
Training loss: 3.0540939495872212
Validation loss: 2.7973079523887305

Epoch: 6| Step: 5
Training loss: 3.1760328880548228
Validation loss: 2.7961516625943386

Epoch: 6| Step: 6
Training loss: 2.6434933585192995
Validation loss: 2.7949830516603864

Epoch: 6| Step: 7
Training loss: 3.171117833157194
Validation loss: 2.7938201531371627

Epoch: 6| Step: 8
Training loss: 3.0996746015506282
Validation loss: 2.792669619033769

Epoch: 6| Step: 9
Training loss: 2.571135786206092
Validation loss: 2.791606337811156

Epoch: 6| Step: 10
Training loss: 2.7452597945771324
Validation loss: 2.790095845767221

Epoch: 6| Step: 11
Training loss: 2.8987691437622494
Validation loss: 2.7883858879580083

Epoch: 6| Step: 12
Training loss: 2.866038744561411
Validation loss: 2.786889634072219

Epoch: 6| Step: 13
Training loss: 3.0942887887057595
Validation loss: 2.7852674322064135

Epoch: 55| Step: 0
Training loss: 3.0510571070565065
Validation loss: 2.7837800508820454

Epoch: 6| Step: 1
Training loss: 3.214060357686072
Validation loss: 2.782422550788114

Epoch: 6| Step: 2
Training loss: 2.315736928028835
Validation loss: 2.780231868110217

Epoch: 6| Step: 3
Training loss: 2.7368931973086053
Validation loss: 2.778812697791916

Epoch: 6| Step: 4
Training loss: 3.0274505399511624
Validation loss: 2.776970832493868

Epoch: 6| Step: 5
Training loss: 3.518676383025918
Validation loss: 2.7757460035338672

Epoch: 6| Step: 6
Training loss: 2.770458502023065
Validation loss: 2.773823298453801

Epoch: 6| Step: 7
Training loss: 2.8921145338749605
Validation loss: 2.77240270374533

Epoch: 6| Step: 8
Training loss: 2.724412830332541
Validation loss: 2.770603978313723

Epoch: 6| Step: 9
Training loss: 3.0055969797955373
Validation loss: 2.7696541784469186

Epoch: 6| Step: 10
Training loss: 3.048377972153125
Validation loss: 2.768103902045465

Epoch: 6| Step: 11
Training loss: 2.8040411159151057
Validation loss: 2.7662373240290057

Epoch: 6| Step: 12
Training loss: 2.798452944475981
Validation loss: 2.765253914975405

Epoch: 6| Step: 13
Training loss: 2.7515760587133995
Validation loss: 2.7639759269398425

Epoch: 56| Step: 0
Training loss: 2.550767042695886
Validation loss: 2.762491480496303

Epoch: 6| Step: 1
Training loss: 3.1747483641862577
Validation loss: 2.7607521189189512

Epoch: 6| Step: 2
Training loss: 2.815642487432471
Validation loss: 2.7600514488216366

Epoch: 6| Step: 3
Training loss: 3.561653170407587
Validation loss: 2.7589352549299866

Epoch: 6| Step: 4
Training loss: 2.976516202631662
Validation loss: 2.7555676366001127

Epoch: 6| Step: 5
Training loss: 3.029117738799979
Validation loss: 2.7546358481252975

Epoch: 6| Step: 6
Training loss: 1.9457474187907107
Validation loss: 2.753113530193198

Epoch: 6| Step: 7
Training loss: 2.0726521641144235
Validation loss: 2.752611726277105

Epoch: 6| Step: 8
Training loss: 2.8699053530089618
Validation loss: 2.7515818207997715

Epoch: 6| Step: 9
Training loss: 2.836008790856687
Validation loss: 2.750548568110934

Epoch: 6| Step: 10
Training loss: 2.541172688326587
Validation loss: 2.749504926218449

Epoch: 6| Step: 11
Training loss: 3.422728549635116
Validation loss: 2.747881289917895

Epoch: 6| Step: 12
Training loss: 3.2665812721249505
Validation loss: 2.746820779553885

Epoch: 6| Step: 13
Training loss: 3.0082424104287777
Validation loss: 2.7452464924235156

Epoch: 57| Step: 0
Training loss: 2.4755851670363693
Validation loss: 2.7438613840028045

Epoch: 6| Step: 1
Training loss: 2.985269462397416
Validation loss: 2.742420704662264

Epoch: 6| Step: 2
Training loss: 3.2612560195253204
Validation loss: 2.740824825435651

Epoch: 6| Step: 3
Training loss: 2.5949181373634738
Validation loss: 2.7398903581628637

Epoch: 6| Step: 4
Training loss: 2.1972740885253668
Validation loss: 2.7391640133134527

Epoch: 6| Step: 5
Training loss: 2.937006807521351
Validation loss: 2.7381511227411512

Epoch: 6| Step: 6
Training loss: 2.7047958061442996
Validation loss: 2.740192248962509

Epoch: 6| Step: 7
Training loss: 3.2257529806504546
Validation loss: 2.7411253811257295

Epoch: 6| Step: 8
Training loss: 2.8627351289488985
Validation loss: 2.73855704071926

Epoch: 6| Step: 9
Training loss: 2.88336920596466
Validation loss: 2.7336884426866326

Epoch: 6| Step: 10
Training loss: 2.3520965476688374
Validation loss: 2.7320416767465727

Epoch: 6| Step: 11
Training loss: 3.1440932827765753
Validation loss: 2.729850135038682

Epoch: 6| Step: 12
Training loss: 3.007740842287652
Validation loss: 2.7296687724725324

Epoch: 6| Step: 13
Training loss: 3.4090076447924575
Validation loss: 2.729335857320618

Epoch: 58| Step: 0
Training loss: 3.3352337347248366
Validation loss: 2.7288482179322178

Epoch: 6| Step: 1
Training loss: 2.329291646626228
Validation loss: 2.7287639485805206

Epoch: 6| Step: 2
Training loss: 3.267314419135197
Validation loss: 2.728547504068607

Epoch: 6| Step: 3
Training loss: 2.425771421452512
Validation loss: 2.72772396092396

Epoch: 6| Step: 4
Training loss: 2.942187201793167
Validation loss: 2.7266329343601026

Epoch: 6| Step: 5
Training loss: 2.586555522353008
Validation loss: 2.725589669732008

Epoch: 6| Step: 6
Training loss: 2.8310700146726355
Validation loss: 2.724859746187541

Epoch: 6| Step: 7
Training loss: 2.3034710276069057
Validation loss: 2.7231446917632267

Epoch: 6| Step: 8
Training loss: 3.0101575552934814
Validation loss: 2.7215808731389273

Epoch: 6| Step: 9
Training loss: 3.050956457286838
Validation loss: 2.7201729189613104

Epoch: 6| Step: 10
Training loss: 2.985530290129586
Validation loss: 2.7183731811833565

Epoch: 6| Step: 11
Training loss: 2.8206895063763815
Validation loss: 2.71675195755108

Epoch: 6| Step: 12
Training loss: 3.3729284074628856
Validation loss: 2.715212672938997

Epoch: 6| Step: 13
Training loss: 2.5381116759348084
Validation loss: 2.7133736781120903

Epoch: 59| Step: 0
Training loss: 2.5163190370006103
Validation loss: 2.711723250408536

Epoch: 6| Step: 1
Training loss: 3.5866635985757216
Validation loss: 2.7108531282837536

Epoch: 6| Step: 2
Training loss: 2.9268314529232464
Validation loss: 2.709036945987136

Epoch: 6| Step: 3
Training loss: 3.2108555247291326
Validation loss: 2.7076207299406403

Epoch: 6| Step: 4
Training loss: 2.482913180999264
Validation loss: 2.706091251078089

Epoch: 6| Step: 5
Training loss: 2.677853771527824
Validation loss: 2.704466073654009

Epoch: 6| Step: 6
Training loss: 2.6472547022332575
Validation loss: 2.7027235670186505

Epoch: 6| Step: 7
Training loss: 2.520923602376914
Validation loss: 2.7011895279159246

Epoch: 6| Step: 8
Training loss: 2.956375674264076
Validation loss: 2.70210912942644

Epoch: 6| Step: 9
Training loss: 2.7450773221991933
Validation loss: 2.6993034117652837

Epoch: 6| Step: 10
Training loss: 2.7542629146254103
Validation loss: 2.699879853789663

Epoch: 6| Step: 11
Training loss: 2.506439308379877
Validation loss: 2.6986420047902824

Epoch: 6| Step: 12
Training loss: 3.083092104436466
Validation loss: 2.6984939006778665

Epoch: 6| Step: 13
Training loss: 3.002717218093222
Validation loss: 2.695011111008311

Epoch: 60| Step: 0
Training loss: 2.0418030310523947
Validation loss: 2.6944271531702713

Epoch: 6| Step: 1
Training loss: 2.812201844412061
Validation loss: 2.6927382850579846

Epoch: 6| Step: 2
Training loss: 3.2179210299042
Validation loss: 2.691557652497024

Epoch: 6| Step: 3
Training loss: 2.3731552789990307
Validation loss: 2.6904569224082806

Epoch: 6| Step: 4
Training loss: 2.5978143858997407
Validation loss: 2.689618835293705

Epoch: 6| Step: 5
Training loss: 3.163221911634347
Validation loss: 2.6886568167225664

Epoch: 6| Step: 6
Training loss: 2.8128447427333083
Validation loss: 2.687719424849033

Epoch: 6| Step: 7
Training loss: 2.5646919551832514
Validation loss: 2.686853020439038

Epoch: 6| Step: 8
Training loss: 3.2054180590316927
Validation loss: 2.685576364066315

Epoch: 6| Step: 9
Training loss: 2.8231199034179735
Validation loss: 2.683713330043655

Epoch: 6| Step: 10
Training loss: 3.0486893949158484
Validation loss: 2.6835528522838095

Epoch: 6| Step: 11
Training loss: 3.059769483622535
Validation loss: 2.6822444627676063

Epoch: 6| Step: 12
Training loss: 2.699212037007752
Validation loss: 2.6802573233044997

Epoch: 6| Step: 13
Training loss: 2.934031610028675
Validation loss: 2.6801554546534048

Epoch: 61| Step: 0
Training loss: 2.64683380635351
Validation loss: 2.6798265901136666

Epoch: 6| Step: 1
Training loss: 3.4844814677715195
Validation loss: 2.6754455949896405

Epoch: 6| Step: 2
Training loss: 2.9970769947383964
Validation loss: 2.6756876165709538

Epoch: 6| Step: 3
Training loss: 2.7383476826095827
Validation loss: 2.674696906319452

Epoch: 6| Step: 4
Training loss: 3.200040346129703
Validation loss: 2.672147859616826

Epoch: 6| Step: 5
Training loss: 2.654213427536451
Validation loss: 2.671620213665384

Epoch: 6| Step: 6
Training loss: 2.5137266021201072
Validation loss: 2.671084891348564

Epoch: 6| Step: 7
Training loss: 2.8968564062746047
Validation loss: 2.6728572415658673

Epoch: 6| Step: 8
Training loss: 2.4735771019313746
Validation loss: 2.6698368471043405

Epoch: 6| Step: 9
Training loss: 2.9166730789840694
Validation loss: 2.66995348629101

Epoch: 6| Step: 10
Training loss: 2.7069317247555014
Validation loss: 2.67018311828659

Epoch: 6| Step: 11
Training loss: 1.8854869035596278
Validation loss: 2.667933451250063

Epoch: 6| Step: 12
Training loss: 2.977001247960586
Validation loss: 2.6652349761376284

Epoch: 6| Step: 13
Training loss: 2.9735226465122624
Validation loss: 2.6647140586188316

Epoch: 62| Step: 0
Training loss: 2.9558302986667893
Validation loss: 2.664764132913778

Epoch: 6| Step: 1
Training loss: 2.489164522023443
Validation loss: 2.6653247128952002

Epoch: 6| Step: 2
Training loss: 2.795019376001773
Validation loss: 2.665155240726826

Epoch: 6| Step: 3
Training loss: 3.386673554115601
Validation loss: 2.666208828922528

Epoch: 6| Step: 4
Training loss: 2.6999268769146387
Validation loss: 2.667426199829122

Epoch: 6| Step: 5
Training loss: 2.4835170968014255
Validation loss: 2.6680586777849236

Epoch: 6| Step: 6
Training loss: 2.961782048141929
Validation loss: 2.6652555805249616

Epoch: 6| Step: 7
Training loss: 2.995432237312351
Validation loss: 2.6641069335811762

Epoch: 6| Step: 8
Training loss: 2.0909936326165766
Validation loss: 2.6625222146983503

Epoch: 6| Step: 9
Training loss: 2.9384286913992788
Validation loss: 2.6610031086988233

Epoch: 6| Step: 10
Training loss: 3.105293700844714
Validation loss: 2.659665324302775

Epoch: 6| Step: 11
Training loss: 2.9009459301111957
Validation loss: 2.657547368380775

Epoch: 6| Step: 12
Training loss: 2.4021379088008143
Validation loss: 2.6557072103584884

Epoch: 6| Step: 13
Training loss: 2.7847554264853054
Validation loss: 2.653555876330511

Epoch: 63| Step: 0
Training loss: 3.1654437029214004
Validation loss: 2.6525255008949395

Epoch: 6| Step: 1
Training loss: 2.5467199734739223
Validation loss: 2.650885142044225

Epoch: 6| Step: 2
Training loss: 2.752357339514156
Validation loss: 2.6497726300902373

Epoch: 6| Step: 3
Training loss: 2.130337910958767
Validation loss: 2.6478336212157405

Epoch: 6| Step: 4
Training loss: 3.13212048885637
Validation loss: 2.648202531231956

Epoch: 6| Step: 5
Training loss: 3.171560187290546
Validation loss: 2.648908275071761

Epoch: 6| Step: 6
Training loss: 3.231514518137373
Validation loss: 2.6460702945197885

Epoch: 6| Step: 7
Training loss: 2.6926746673742166
Validation loss: 2.643463415029442

Epoch: 6| Step: 8
Training loss: 2.6210880194201978
Validation loss: 2.642960969193872

Epoch: 6| Step: 9
Training loss: 2.795183831927045
Validation loss: 2.642517284624297

Epoch: 6| Step: 10
Training loss: 2.3427726233585497
Validation loss: 2.642155792328811

Epoch: 6| Step: 11
Training loss: 2.2283295696667103
Validation loss: 2.640515206667181

Epoch: 6| Step: 12
Training loss: 2.8514166807750745
Validation loss: 2.6396556632577757

Epoch: 6| Step: 13
Training loss: 3.06315745867531
Validation loss: 2.6409752367084756

Epoch: 64| Step: 0
Training loss: 2.5503264835265513
Validation loss: 2.639071457107789

Epoch: 6| Step: 1
Training loss: 2.483070654918892
Validation loss: 2.6384677539768484

Epoch: 6| Step: 2
Training loss: 2.6917947563502946
Validation loss: 2.6382492333087564

Epoch: 6| Step: 3
Training loss: 2.9253183566567533
Validation loss: 2.6364830684116987

Epoch: 6| Step: 4
Training loss: 2.7259218179150433
Validation loss: 2.6368075282845465

Epoch: 6| Step: 5
Training loss: 3.098814393021147
Validation loss: 2.635844611803983

Epoch: 6| Step: 6
Training loss: 2.466761597103989
Validation loss: 2.63387523901935

Epoch: 6| Step: 7
Training loss: 3.1173810014444023
Validation loss: 2.6333418256485897

Epoch: 6| Step: 8
Training loss: 2.402088480467188
Validation loss: 2.634088525849062

Epoch: 6| Step: 9
Training loss: 2.9109452579740958
Validation loss: 2.631487247768349

Epoch: 6| Step: 10
Training loss: 3.1194058510338722
Validation loss: 2.636100941557898

Epoch: 6| Step: 11
Training loss: 2.5854494492888236
Validation loss: 2.6319654934146826

Epoch: 6| Step: 12
Training loss: 3.1133310273330066
Validation loss: 2.6264481863985405

Epoch: 6| Step: 13
Training loss: 2.548573120924286
Validation loss: 2.625267060636631

Epoch: 65| Step: 0
Training loss: 2.72047492368976
Validation loss: 2.6237443009560435

Epoch: 6| Step: 1
Training loss: 2.74059168796455
Validation loss: 2.623537337293203

Epoch: 6| Step: 2
Training loss: 2.3028183421064594
Validation loss: 2.6277435134721987

Epoch: 6| Step: 3
Training loss: 3.116513439906551
Validation loss: 2.6307150978905964

Epoch: 6| Step: 4
Training loss: 2.809839473768416
Validation loss: 2.63232740391297

Epoch: 6| Step: 5
Training loss: 2.402293730424389
Validation loss: 2.6405461466977185

Epoch: 6| Step: 6
Training loss: 2.715855427788983
Validation loss: 2.6437656904135243

Epoch: 6| Step: 7
Training loss: 2.738010888350399
Validation loss: 2.635549871121574

Epoch: 6| Step: 8
Training loss: 3.0100932404026906
Validation loss: 2.6269873861468174

Epoch: 6| Step: 9
Training loss: 2.123352758697012
Validation loss: 2.6221330593754084

Epoch: 6| Step: 10
Training loss: 2.8492989531165307
Validation loss: 2.6181411599876

Epoch: 6| Step: 11
Training loss: 3.076425770772194
Validation loss: 2.616453320214712

Epoch: 6| Step: 12
Training loss: 3.0889729310761043
Validation loss: 2.614056208592133

Epoch: 6| Step: 13
Training loss: 2.8875356300434647
Validation loss: 2.6126693822777334

Epoch: 66| Step: 0
Training loss: 2.7264408641889135
Validation loss: 2.6126301576354707

Epoch: 6| Step: 1
Training loss: 3.0347757186849456
Validation loss: 2.6129745964920597

Epoch: 6| Step: 2
Training loss: 2.683367368430935
Validation loss: 2.6141414243553385

Epoch: 6| Step: 3
Training loss: 2.8541599097253125
Validation loss: 2.612466735567229

Epoch: 6| Step: 4
Training loss: 2.991353289697521
Validation loss: 2.6104680587284497

Epoch: 6| Step: 5
Training loss: 2.5160330684289947
Validation loss: 2.6086446231018248

Epoch: 6| Step: 6
Training loss: 2.9137432342804233
Validation loss: 2.6075301511002107

Epoch: 6| Step: 7
Training loss: 2.6759633691444527
Validation loss: 2.606477602161597

Epoch: 6| Step: 8
Training loss: 2.540100730490588
Validation loss: 2.6112827933349094

Epoch: 6| Step: 9
Training loss: 2.5332021838254803
Validation loss: 2.607697867313342

Epoch: 6| Step: 10
Training loss: 3.0263178705343603
Validation loss: 2.6067569261015424

Epoch: 6| Step: 11
Training loss: 2.5644465240835173
Validation loss: 2.5994650907956385

Epoch: 6| Step: 12
Training loss: 2.6002850302937044
Validation loss: 2.601208682815934

Epoch: 6| Step: 13
Training loss: 2.7700466004731266
Validation loss: 2.602464078642468

Epoch: 67| Step: 0
Training loss: 3.0026668774732896
Validation loss: 2.6027284134623776

Epoch: 6| Step: 1
Training loss: 3.0584526565377326
Validation loss: 2.604144765126001

Epoch: 6| Step: 2
Training loss: 2.399640406054445
Validation loss: 2.604736423471573

Epoch: 6| Step: 3
Training loss: 2.8088625804441008
Validation loss: 2.6031498538781257

Epoch: 6| Step: 4
Training loss: 2.061750796098996
Validation loss: 2.602518015019547

Epoch: 6| Step: 5
Training loss: 2.511807785710514
Validation loss: 2.60151852560061

Epoch: 6| Step: 6
Training loss: 2.648956518038839
Validation loss: 2.6014425041927107

Epoch: 6| Step: 7
Training loss: 3.4192305148735986
Validation loss: 2.600444060698179

Epoch: 6| Step: 8
Training loss: 3.0253918858938627
Validation loss: 2.598545834226459

Epoch: 6| Step: 9
Training loss: 2.2878860731504576
Validation loss: 2.5950280376774333

Epoch: 6| Step: 10
Training loss: 2.4547904611577174
Validation loss: 2.593404034441048

Epoch: 6| Step: 11
Training loss: 2.698184752431151
Validation loss: 2.593113066513346

Epoch: 6| Step: 12
Training loss: 2.433454628973882
Validation loss: 2.592138509841201

Epoch: 6| Step: 13
Training loss: 3.1630343803686425
Validation loss: 2.5927367931585388

Epoch: 68| Step: 0
Training loss: 2.9619847360613045
Validation loss: 2.591028969332227

Epoch: 6| Step: 1
Training loss: 2.4341137179012002
Validation loss: 2.592806280566272

Epoch: 6| Step: 2
Training loss: 2.766860944368841
Validation loss: 2.5901422036162063

Epoch: 6| Step: 3
Training loss: 2.7072527465919105
Validation loss: 2.5908325363735454

Epoch: 6| Step: 4
Training loss: 2.297359700863974
Validation loss: 2.5959865471785712

Epoch: 6| Step: 5
Training loss: 2.8173683417360174
Validation loss: 2.5973613829795297

Epoch: 6| Step: 6
Training loss: 2.437432899529641
Validation loss: 2.5898889659465327

Epoch: 6| Step: 7
Training loss: 2.9215600155044457
Validation loss: 2.5860221518560778

Epoch: 6| Step: 8
Training loss: 2.5182593158756763
Validation loss: 2.585412516707154

Epoch: 6| Step: 9
Training loss: 2.9686227871592927
Validation loss: 2.584039612071801

Epoch: 6| Step: 10
Training loss: 3.303943162424594
Validation loss: 2.582666469968172

Epoch: 6| Step: 11
Training loss: 2.859639473446053
Validation loss: 2.585127474103139

Epoch: 6| Step: 12
Training loss: 2.7461821323459437
Validation loss: 2.5848168809864704

Epoch: 6| Step: 13
Training loss: 2.268227181212954
Validation loss: 2.585624852637297

Epoch: 69| Step: 0
Training loss: 2.518328049673331
Validation loss: 2.585676397105229

Epoch: 6| Step: 1
Training loss: 2.9632716980550637
Validation loss: 2.5875179382292135

Epoch: 6| Step: 2
Training loss: 3.329900849845203
Validation loss: 2.5854113025184415

Epoch: 6| Step: 3
Training loss: 2.8229219406097434
Validation loss: 2.584827457599462

Epoch: 6| Step: 4
Training loss: 2.458559273719586
Validation loss: 2.582700172377164

Epoch: 6| Step: 5
Training loss: 2.513710572983008
Validation loss: 2.5798524714091777

Epoch: 6| Step: 6
Training loss: 2.3890563206315196
Validation loss: 2.5787861756502286

Epoch: 6| Step: 7
Training loss: 2.423010184751132
Validation loss: 2.576116392103562

Epoch: 6| Step: 8
Training loss: 2.841409915127723
Validation loss: 2.57408225855859

Epoch: 6| Step: 9
Training loss: 1.9066120491785943
Validation loss: 2.573647759438474

Epoch: 6| Step: 10
Training loss: 2.995902123720351
Validation loss: 2.57335333008071

Epoch: 6| Step: 11
Training loss: 3.1423884512951306
Validation loss: 2.5727928739309074

Epoch: 6| Step: 12
Training loss: 2.654989863661905
Validation loss: 2.5712126882192163

Epoch: 6| Step: 13
Training loss: 2.8026087290815274
Validation loss: 2.5711671438360346

Epoch: 70| Step: 0
Training loss: 2.1375148482671413
Validation loss: 2.566556000078332

Epoch: 6| Step: 1
Training loss: 3.15418682083551
Validation loss: 2.565604895243085

Epoch: 6| Step: 2
Training loss: 3.359122333339737
Validation loss: 2.5703414250594707

Epoch: 6| Step: 3
Training loss: 2.7486536024537065
Validation loss: 2.565609541678778

Epoch: 6| Step: 4
Training loss: 2.97977192383555
Validation loss: 2.569015438476439

Epoch: 6| Step: 5
Training loss: 3.05010080014616
Validation loss: 2.5696723086612328

Epoch: 6| Step: 6
Training loss: 2.4845838159098697
Validation loss: 2.566909802571421

Epoch: 6| Step: 7
Training loss: 2.7955494728520858
Validation loss: 2.564948641068902

Epoch: 6| Step: 8
Training loss: 2.4934414665553013
Validation loss: 2.566663228895519

Epoch: 6| Step: 9
Training loss: 2.304574116649508
Validation loss: 2.569496713284228

Epoch: 6| Step: 10
Training loss: 1.6107524421433002
Validation loss: 2.5718353460012016

Epoch: 6| Step: 11
Training loss: 2.4987322453931475
Validation loss: 2.572074170471445

Epoch: 6| Step: 12
Training loss: 2.759019970978164
Validation loss: 2.5723204494649803

Epoch: 6| Step: 13
Training loss: 2.9730044748713347
Validation loss: 2.572693546108616

Epoch: 71| Step: 0
Training loss: 3.0606264884248695
Validation loss: 2.575218550657144

Epoch: 6| Step: 1
Training loss: 3.0708731025456713
Validation loss: 2.5742746596953086

Epoch: 6| Step: 2
Training loss: 2.849135110358088
Validation loss: 2.5742460412453805

Epoch: 6| Step: 3
Training loss: 2.4857709309743035
Validation loss: 2.5753291836292957

Epoch: 6| Step: 4
Training loss: 2.511454756702696
Validation loss: 2.5728121104341093

Epoch: 6| Step: 5
Training loss: 2.514797287766863
Validation loss: 2.5724489402090582

Epoch: 6| Step: 6
Training loss: 2.732391597206487
Validation loss: 2.5709341393176737

Epoch: 6| Step: 7
Training loss: 2.2013828613113158
Validation loss: 2.568024735110779

Epoch: 6| Step: 8
Training loss: 2.494689068579321
Validation loss: 2.5658429213176746

Epoch: 6| Step: 9
Training loss: 2.9120977492327462
Validation loss: 2.5663279033219775

Epoch: 6| Step: 10
Training loss: 2.6470201688948523
Validation loss: 2.5635448589612504

Epoch: 6| Step: 11
Training loss: 2.8643442135046375
Validation loss: 2.56127919215354

Epoch: 6| Step: 12
Training loss: 2.604856496361783
Validation loss: 2.559187228651139

Epoch: 6| Step: 13
Training loss: 2.7279327359786434
Validation loss: 2.5583962400656883

Epoch: 72| Step: 0
Training loss: 2.8490464070786037
Validation loss: 2.5593821778932306

Epoch: 6| Step: 1
Training loss: 2.3177568637753265
Validation loss: 2.5576190052703307

Epoch: 6| Step: 2
Training loss: 2.8142608216853575
Validation loss: 2.556961525132415

Epoch: 6| Step: 3
Training loss: 2.238088869145693
Validation loss: 2.558872454268809

Epoch: 6| Step: 4
Training loss: 2.980010191112732
Validation loss: 2.570342429932757

Epoch: 6| Step: 5
Training loss: 2.6765341486100147
Validation loss: 2.5772184531320956

Epoch: 6| Step: 6
Training loss: 2.9775235284216794
Validation loss: 2.572346833998107

Epoch: 6| Step: 7
Training loss: 2.522131047255723
Validation loss: 2.568285126090304

Epoch: 6| Step: 8
Training loss: 2.5915000992836954
Validation loss: 2.565238326900175

Epoch: 6| Step: 9
Training loss: 2.3856751303319004
Validation loss: 2.5629749323184234

Epoch: 6| Step: 10
Training loss: 3.0977429140915165
Validation loss: 2.558699433374175

Epoch: 6| Step: 11
Training loss: 2.70297531860125
Validation loss: 2.5589993453865363

Epoch: 6| Step: 12
Training loss: 2.9374691576048733
Validation loss: 2.558502723685937

Epoch: 6| Step: 13
Training loss: 2.444717578607814
Validation loss: 2.559931716331128

Epoch: 73| Step: 0
Training loss: 2.6597009120670676
Validation loss: 2.5612409646560765

Epoch: 6| Step: 1
Training loss: 3.180331678067483
Validation loss: 2.562492510156618

Epoch: 6| Step: 2
Training loss: 2.4089423636021734
Validation loss: 2.5632986049341686

Epoch: 6| Step: 3
Training loss: 2.707230641781881
Validation loss: 2.5644239165905724

Epoch: 6| Step: 4
Training loss: 2.6595305884779377
Validation loss: 2.565966780924473

Epoch: 6| Step: 5
Training loss: 2.7314402498724086
Validation loss: 2.5617662945618767

Epoch: 6| Step: 6
Training loss: 2.802522891901393
Validation loss: 2.5617767957180235

Epoch: 6| Step: 7
Training loss: 2.2386821500974716
Validation loss: 2.561835163988963

Epoch: 6| Step: 8
Training loss: 2.1700714087273325
Validation loss: 2.56476511513729

Epoch: 6| Step: 9
Training loss: 2.8364855864568983
Validation loss: 2.564144149803731

Epoch: 6| Step: 10
Training loss: 3.2452660341935653
Validation loss: 2.560795053985667

Epoch: 6| Step: 11
Training loss: 2.664766280212116
Validation loss: 2.5569557129833043

Epoch: 6| Step: 12
Training loss: 2.9468465599394804
Validation loss: 2.5540307899248185

Epoch: 6| Step: 13
Training loss: 2.216544761269426
Validation loss: 2.55378512778624

Epoch: 74| Step: 0
Training loss: 3.172873203700434
Validation loss: 2.55205467882743

Epoch: 6| Step: 1
Training loss: 2.7870435058680147
Validation loss: 2.5481332428516374

Epoch: 6| Step: 2
Training loss: 2.0642629082853534
Validation loss: 2.5469189973553057

Epoch: 6| Step: 3
Training loss: 2.90806801650564
Validation loss: 2.5448436007754656

Epoch: 6| Step: 4
Training loss: 1.9103085197807894
Validation loss: 2.5449301972525173

Epoch: 6| Step: 5
Training loss: 2.482195588009492
Validation loss: 2.5442761382428674

Epoch: 6| Step: 6
Training loss: 2.8887052192336844
Validation loss: 2.545906007377707

Epoch: 6| Step: 7
Training loss: 3.0316396246555657
Validation loss: 2.5439556060602286

Epoch: 6| Step: 8
Training loss: 2.6569329674031907
Validation loss: 2.543908964496607

Epoch: 6| Step: 9
Training loss: 2.9659654910240127
Validation loss: 2.5447911511697976

Epoch: 6| Step: 10
Training loss: 2.8130839271487904
Validation loss: 2.5496525041507123

Epoch: 6| Step: 11
Training loss: 2.164417334155505
Validation loss: 2.5465824138558517

Epoch: 6| Step: 12
Training loss: 2.8937117308358062
Validation loss: 2.552654394498695

Epoch: 6| Step: 13
Training loss: 2.47996907645604
Validation loss: 2.550804103030404

Epoch: 75| Step: 0
Training loss: 2.6097708761558924
Validation loss: 2.542362967205114

Epoch: 6| Step: 1
Training loss: 2.3018736132437105
Validation loss: 2.5450345119591984

Epoch: 6| Step: 2
Training loss: 2.501222883589368
Validation loss: 2.5375846748443296

Epoch: 6| Step: 3
Training loss: 3.073879354081299
Validation loss: 2.5390191020680213

Epoch: 6| Step: 4
Training loss: 2.8655825080341977
Validation loss: 2.5404571928229127

Epoch: 6| Step: 5
Training loss: 2.590896231484024
Validation loss: 2.538118298373079

Epoch: 6| Step: 6
Training loss: 2.379479650786764
Validation loss: 2.53924195266785

Epoch: 6| Step: 7
Training loss: 2.2875807200713782
Validation loss: 2.540054769050663

Epoch: 6| Step: 8
Training loss: 2.166712051307522
Validation loss: 2.5386690901149005

Epoch: 6| Step: 9
Training loss: 3.036561382937719
Validation loss: 2.5403156494141124

Epoch: 6| Step: 10
Training loss: 2.735545926745516
Validation loss: 2.5409568253989807

Epoch: 6| Step: 11
Training loss: 3.2402920617227813
Validation loss: 2.540115185175897

Epoch: 6| Step: 12
Training loss: 2.6568886381852312
Validation loss: 2.540037810977841

Epoch: 6| Step: 13
Training loss: 2.76411043064099
Validation loss: 2.5391079629593696

Epoch: 76| Step: 0
Training loss: 2.8613804522732322
Validation loss: 2.5382373740663295

Epoch: 6| Step: 1
Training loss: 2.9143632421679704
Validation loss: 2.536304732938977

Epoch: 6| Step: 2
Training loss: 2.8456258769864498
Validation loss: 2.5357155361722525

Epoch: 6| Step: 3
Training loss: 1.8878701055584903
Validation loss: 2.5340941505966055

Epoch: 6| Step: 4
Training loss: 2.428530205849595
Validation loss: 2.5364769237132085

Epoch: 6| Step: 5
Training loss: 1.768730201205996
Validation loss: 2.5338640255293545

Epoch: 6| Step: 6
Training loss: 2.260824445047798
Validation loss: 2.5334824423032583

Epoch: 6| Step: 7
Training loss: 2.7352191602918916
Validation loss: 2.5339637620257163

Epoch: 6| Step: 8
Training loss: 2.981196603356815
Validation loss: 2.532291096214273

Epoch: 6| Step: 9
Training loss: 2.65558229917984
Validation loss: 2.534041972451774

Epoch: 6| Step: 10
Training loss: 3.1569886806745484
Validation loss: 2.5333434972642825

Epoch: 6| Step: 11
Training loss: 2.8613634543467374
Validation loss: 2.535392448499788

Epoch: 6| Step: 12
Training loss: 2.4790681985058454
Validation loss: 2.5311259015592382

Epoch: 6| Step: 13
Training loss: 3.0982465337941525
Validation loss: 2.5339739471592635

Epoch: 77| Step: 0
Training loss: 3.099629066178789
Validation loss: 2.5348625071706956

Epoch: 6| Step: 1
Training loss: 2.626073708515927
Validation loss: 2.5317647355652397

Epoch: 6| Step: 2
Training loss: 2.4062527743236846
Validation loss: 2.529327981529278

Epoch: 6| Step: 3
Training loss: 2.568305533537362
Validation loss: 2.529100392293938

Epoch: 6| Step: 4
Training loss: 3.29389189499564
Validation loss: 2.527888668222357

Epoch: 6| Step: 5
Training loss: 2.3537984464403157
Validation loss: 2.5302540267853497

Epoch: 6| Step: 6
Training loss: 2.621742225167656
Validation loss: 2.5305671712797437

Epoch: 6| Step: 7
Training loss: 2.4316859229591063
Validation loss: 2.529515869400505

Epoch: 6| Step: 8
Training loss: 2.750929415308625
Validation loss: 2.5280804668287495

Epoch: 6| Step: 9
Training loss: 2.2202878109057926
Validation loss: 2.5276306083884483

Epoch: 6| Step: 10
Training loss: 2.8404280154644224
Validation loss: 2.5325952730524888

Epoch: 6| Step: 11
Training loss: 2.559949955153066
Validation loss: 2.5314525083687758

Epoch: 6| Step: 12
Training loss: 2.9108181399139905
Validation loss: 2.529470155492502

Epoch: 6| Step: 13
Training loss: 2.323567993357862
Validation loss: 2.528971836016226

Epoch: 78| Step: 0
Training loss: 2.6855361327910154
Validation loss: 2.5292020605670227

Epoch: 6| Step: 1
Training loss: 2.8006184848538505
Validation loss: 2.5290704063644833

Epoch: 6| Step: 2
Training loss: 2.0805266993578146
Validation loss: 2.5282898693921267

Epoch: 6| Step: 3
Training loss: 2.2397385890877377
Validation loss: 2.5254180348131454

Epoch: 6| Step: 4
Training loss: 2.454079023349541
Validation loss: 2.5243957558219594

Epoch: 6| Step: 5
Training loss: 2.706109488629964
Validation loss: 2.5228700737991323

Epoch: 6| Step: 6
Training loss: 2.417340371069927
Validation loss: 2.523884028087364

Epoch: 6| Step: 7
Training loss: 2.8525482564149165
Validation loss: 2.524435564413183

Epoch: 6| Step: 8
Training loss: 2.3762795866158277
Validation loss: 2.528563341287401

Epoch: 6| Step: 9
Training loss: 2.586254273342402
Validation loss: 2.534150349686675

Epoch: 6| Step: 10
Training loss: 3.0925722288610586
Validation loss: 2.5411109916194183

Epoch: 6| Step: 11
Training loss: 3.1623204839968166
Validation loss: 2.532596434112515

Epoch: 6| Step: 12
Training loss: 2.744488568493954
Validation loss: 2.5259077580670652

Epoch: 6| Step: 13
Training loss: 2.9822407225906544
Validation loss: 2.5170409046426574

Epoch: 79| Step: 0
Training loss: 2.6696456621194495
Validation loss: 2.5206270264834085

Epoch: 6| Step: 1
Training loss: 2.5789558690153296
Validation loss: 2.5254345718182907

Epoch: 6| Step: 2
Training loss: 2.391352424402161
Validation loss: 2.5292785879527138

Epoch: 6| Step: 3
Training loss: 2.43768397884028
Validation loss: 2.5329440221382886

Epoch: 6| Step: 4
Training loss: 2.7475064850471194
Validation loss: 2.5358747689602463

Epoch: 6| Step: 5
Training loss: 2.525672418932259
Validation loss: 2.5426624463254206

Epoch: 6| Step: 6
Training loss: 3.0245138613155733
Validation loss: 2.543393772935315

Epoch: 6| Step: 7
Training loss: 2.915379612645262
Validation loss: 2.5499915652665406

Epoch: 6| Step: 8
Training loss: 2.5362642332742715
Validation loss: 2.544063178301597

Epoch: 6| Step: 9
Training loss: 3.053967793552777
Validation loss: 2.5432648923355323

Epoch: 6| Step: 10
Training loss: 2.5756750314579246
Validation loss: 2.5435924634335207

Epoch: 6| Step: 11
Training loss: 2.538283102281998
Validation loss: 2.542508710198

Epoch: 6| Step: 12
Training loss: 2.6006832985553556
Validation loss: 2.543267423451521

Epoch: 6| Step: 13
Training loss: 2.6865168702777784
Validation loss: 2.5423518622624157

Epoch: 80| Step: 0
Training loss: 2.9723001234198474
Validation loss: 2.540664808924101

Epoch: 6| Step: 1
Training loss: 2.132575724108097
Validation loss: 2.54220267933927

Epoch: 6| Step: 2
Training loss: 2.7713259113326476
Validation loss: 2.5385195733633723

Epoch: 6| Step: 3
Training loss: 2.4883347150726807
Validation loss: 2.534698711501058

Epoch: 6| Step: 4
Training loss: 2.846547521856864
Validation loss: 2.530996788766412

Epoch: 6| Step: 5
Training loss: 2.342352386839367
Validation loss: 2.527036055594099

Epoch: 6| Step: 6
Training loss: 2.5099676741080033
Validation loss: 2.525149761454646

Epoch: 6| Step: 7
Training loss: 3.1506942347309113
Validation loss: 2.521158502167032

Epoch: 6| Step: 8
Training loss: 2.3065303352985818
Validation loss: 2.519703609278327

Epoch: 6| Step: 9
Training loss: 2.277648067916323
Validation loss: 2.5171011627564366

Epoch: 6| Step: 10
Training loss: 3.2256764079614983
Validation loss: 2.516928388447562

Epoch: 6| Step: 11
Training loss: 2.4547253873488417
Validation loss: 2.512909887101555

Epoch: 6| Step: 12
Training loss: 2.882515413850199
Validation loss: 2.5139856150116198

Epoch: 6| Step: 13
Training loss: 2.4563915105149032
Validation loss: 2.515332380694827

Epoch: 81| Step: 0
Training loss: 2.5558437332357986
Validation loss: 2.5111490634869957

Epoch: 6| Step: 1
Training loss: 2.0715493016693634
Validation loss: 2.5129558390117084

Epoch: 6| Step: 2
Training loss: 2.7882360949057126
Validation loss: 2.515236423722845

Epoch: 6| Step: 3
Training loss: 2.698585623699704
Validation loss: 2.5162452106964017

Epoch: 6| Step: 4
Training loss: 2.3101483321352516
Validation loss: 2.517870712147086

Epoch: 6| Step: 5
Training loss: 2.7960185012860146
Validation loss: 2.5070379691203817

Epoch: 6| Step: 6
Training loss: 2.8593299737105493
Validation loss: 2.508757226132419

Epoch: 6| Step: 7
Training loss: 2.9537356113724273
Validation loss: 2.5131823683822745

Epoch: 6| Step: 8
Training loss: 2.76611685824184
Validation loss: 2.5118789898594773

Epoch: 6| Step: 9
Training loss: 2.8909346131168197
Validation loss: 2.508768107563201

Epoch: 6| Step: 10
Training loss: 2.9495550304969202
Validation loss: 2.507176890095017

Epoch: 6| Step: 11
Training loss: 2.310228004927959
Validation loss: 2.5053390553419064

Epoch: 6| Step: 12
Training loss: 2.256241195534728
Validation loss: 2.5087127258162307

Epoch: 6| Step: 13
Training loss: 2.6203402077035083
Validation loss: 2.5080335921674797

Epoch: 82| Step: 0
Training loss: 2.5729687540030346
Validation loss: 2.5060702141309608

Epoch: 6| Step: 1
Training loss: 2.74329060595006
Validation loss: 2.509091472007896

Epoch: 6| Step: 2
Training loss: 2.7689408936148787
Validation loss: 2.5078612072295727

Epoch: 6| Step: 3
Training loss: 2.0966528511906213
Validation loss: 2.5101388379183773

Epoch: 6| Step: 4
Training loss: 2.30919658709878
Validation loss: 2.505529995026883

Epoch: 6| Step: 5
Training loss: 2.667073715455633
Validation loss: 2.511694671214855

Epoch: 6| Step: 6
Training loss: 2.762749853098079
Validation loss: 2.5106509456824364

Epoch: 6| Step: 7
Training loss: 2.4924739087115655
Validation loss: 2.506552675890039

Epoch: 6| Step: 8
Training loss: 2.8365188717321064
Validation loss: 2.5080206637081353

Epoch: 6| Step: 9
Training loss: 2.7870991097831284
Validation loss: 2.507023418822816

Epoch: 6| Step: 10
Training loss: 2.73427106387286
Validation loss: 2.5075466850957677

Epoch: 6| Step: 11
Training loss: 2.7448712119653043
Validation loss: 2.50510863636462

Epoch: 6| Step: 12
Training loss: 2.9157572463811556
Validation loss: 2.505584923771091

Epoch: 6| Step: 13
Training loss: 2.2389271920868854
Validation loss: 2.506088757738604

Epoch: 83| Step: 0
Training loss: 2.374583960784795
Validation loss: 2.512764799420152

Epoch: 6| Step: 1
Training loss: 2.6263123819240373
Validation loss: 2.5171655396242145

Epoch: 6| Step: 2
Training loss: 2.5585462260018637
Validation loss: 2.529627919963178

Epoch: 6| Step: 3
Training loss: 2.3075844354359516
Validation loss: 2.538787983457284

Epoch: 6| Step: 4
Training loss: 2.72289792798421
Validation loss: 2.539555710059988

Epoch: 6| Step: 5
Training loss: 2.7642162636037426
Validation loss: 2.521245596936526

Epoch: 6| Step: 6
Training loss: 3.0359218814936964
Validation loss: 2.522719203257588

Epoch: 6| Step: 7
Training loss: 2.2797769467517908
Validation loss: 2.519575409415984

Epoch: 6| Step: 8
Training loss: 2.4939302192904647
Validation loss: 2.51450885471725

Epoch: 6| Step: 9
Training loss: 2.763538672805892
Validation loss: 2.5081321377925545

Epoch: 6| Step: 10
Training loss: 2.6822306406924414
Validation loss: 2.5092396225759805

Epoch: 6| Step: 11
Training loss: 2.6609581006294825
Validation loss: 2.5122586664219972

Epoch: 6| Step: 12
Training loss: 2.8715215455099976
Validation loss: 2.5124264872410262

Epoch: 6| Step: 13
Training loss: 2.790800690967397
Validation loss: 2.5149394299675363

Epoch: 84| Step: 0
Training loss: 2.6746626026177203
Validation loss: 2.516779427391675

Epoch: 6| Step: 1
Training loss: 2.641814556454673
Validation loss: 2.518024382340133

Epoch: 6| Step: 2
Training loss: 3.1124883812377266
Validation loss: 2.518285604092373

Epoch: 6| Step: 3
Training loss: 2.6091544235106316
Validation loss: 2.522202731947392

Epoch: 6| Step: 4
Training loss: 2.887228460053342
Validation loss: 2.5230001064607444

Epoch: 6| Step: 5
Training loss: 2.380483420827269
Validation loss: 2.52305913554936

Epoch: 6| Step: 6
Training loss: 3.0408719910282827
Validation loss: 2.5241777812435577

Epoch: 6| Step: 7
Training loss: 2.4764816319111596
Validation loss: 2.5227616608744317

Epoch: 6| Step: 8
Training loss: 2.3528276759709668
Validation loss: 2.5216217594556105

Epoch: 6| Step: 9
Training loss: 2.762104789806688
Validation loss: 2.5209329338469

Epoch: 6| Step: 10
Training loss: 2.366022912527988
Validation loss: 2.5183038920716623

Epoch: 6| Step: 11
Training loss: 2.5925898887478893
Validation loss: 2.517952136818271

Epoch: 6| Step: 12
Training loss: 2.5081591024963026
Validation loss: 2.515808430494004

Epoch: 6| Step: 13
Training loss: 2.5804772945381544
Validation loss: 2.514217496321672

Epoch: 85| Step: 0
Training loss: 2.7144847165919592
Validation loss: 2.513803300284564

Epoch: 6| Step: 1
Training loss: 2.0215105580278974
Validation loss: 2.513009965046258

Epoch: 6| Step: 2
Training loss: 2.7326695818687363
Validation loss: 2.5118813153108657

Epoch: 6| Step: 3
Training loss: 3.090100534525788
Validation loss: 2.509456852028865

Epoch: 6| Step: 4
Training loss: 2.752735684566259
Validation loss: 2.508204349314936

Epoch: 6| Step: 5
Training loss: 2.998989888844835
Validation loss: 2.5071989043609295

Epoch: 6| Step: 6
Training loss: 2.5438069780046626
Validation loss: 2.5056195678296813

Epoch: 6| Step: 7
Training loss: 2.06255120878515
Validation loss: 2.5024015336000276

Epoch: 6| Step: 8
Training loss: 2.667149966869179
Validation loss: 2.501706033973397

Epoch: 6| Step: 9
Training loss: 2.6768609534693772
Validation loss: 2.5022767666877104

Epoch: 6| Step: 10
Training loss: 2.6799729976432456
Validation loss: 2.5000924331743395

Epoch: 6| Step: 11
Training loss: 2.6109274626013304
Validation loss: 2.5002021389938998

Epoch: 6| Step: 12
Training loss: 2.5633223539926684
Validation loss: 2.497817183277441

Epoch: 6| Step: 13
Training loss: 2.5764849445799634
Validation loss: 2.496805040941423

Epoch: 86| Step: 0
Training loss: 2.753100814453306
Validation loss: 2.499419446929802

Epoch: 6| Step: 1
Training loss: 2.761903144259676
Validation loss: 2.4984292818069087

Epoch: 6| Step: 2
Training loss: 2.922490508991686
Validation loss: 2.498839077019356

Epoch: 6| Step: 3
Training loss: 2.881695786949155
Validation loss: 2.498701847319156

Epoch: 6| Step: 4
Training loss: 2.083961493841117
Validation loss: 2.4982373381485035

Epoch: 6| Step: 5
Training loss: 2.8462273842001453
Validation loss: 2.497624389139762

Epoch: 6| Step: 6
Training loss: 2.633419068868275
Validation loss: 2.4963709240059195

Epoch: 6| Step: 7
Training loss: 2.269623693792824
Validation loss: 2.500797462430689

Epoch: 6| Step: 8
Training loss: 2.2413085916225057
Validation loss: 2.4974587876410648

Epoch: 6| Step: 9
Training loss: 2.2492423371339973
Validation loss: 2.498207848646192

Epoch: 6| Step: 10
Training loss: 2.2994631762756828
Validation loss: 2.495962029027665

Epoch: 6| Step: 11
Training loss: 2.784683765284299
Validation loss: 2.5000420884722097

Epoch: 6| Step: 12
Training loss: 3.3344504550737155
Validation loss: 2.4978582585887046

Epoch: 6| Step: 13
Training loss: 2.2891920658457328
Validation loss: 2.4952936059104696

Epoch: 87| Step: 0
Training loss: 2.562606251072269
Validation loss: 2.499259378083718

Epoch: 6| Step: 1
Training loss: 2.776332150565943
Validation loss: 2.491795085438498

Epoch: 6| Step: 2
Training loss: 2.7263196602045623
Validation loss: 2.495875962476573

Epoch: 6| Step: 3
Training loss: 2.5547642127602095
Validation loss: 2.4959310479584413

Epoch: 6| Step: 4
Training loss: 2.466150001165191
Validation loss: 2.4932033975508787

Epoch: 6| Step: 5
Training loss: 2.1104150539240147
Validation loss: 2.493074074065116

Epoch: 6| Step: 6
Training loss: 2.6100793675891825
Validation loss: 2.4970067224622134

Epoch: 6| Step: 7
Training loss: 2.8494360114759716
Validation loss: 2.49283947682689

Epoch: 6| Step: 8
Training loss: 2.640975657999797
Validation loss: 2.492850363978901

Epoch: 6| Step: 9
Training loss: 2.65191386226505
Validation loss: 2.4964252026996014

Epoch: 6| Step: 10
Training loss: 2.6829438734464732
Validation loss: 2.494435873656451

Epoch: 6| Step: 11
Training loss: 2.772290403597477
Validation loss: 2.491218577848886

Epoch: 6| Step: 12
Training loss: 2.813308345343216
Validation loss: 2.493529625049062

Epoch: 6| Step: 13
Training loss: 2.367817105705028
Validation loss: 2.4941180732760997

Epoch: 88| Step: 0
Training loss: 2.8004025851066263
Validation loss: 2.495060252555934

Epoch: 6| Step: 1
Training loss: 2.757876127984121
Validation loss: 2.4913961335953

Epoch: 6| Step: 2
Training loss: 2.053532148660813
Validation loss: 2.494866074718042

Epoch: 6| Step: 3
Training loss: 3.0001026771776327
Validation loss: 2.4981058256437647

Epoch: 6| Step: 4
Training loss: 2.4065944870914735
Validation loss: 2.497671966614652

Epoch: 6| Step: 5
Training loss: 3.0626519613127465
Validation loss: 2.4980720556529534

Epoch: 6| Step: 6
Training loss: 2.604638832520927
Validation loss: 2.4996348750192854

Epoch: 6| Step: 7
Training loss: 2.4650258814631054
Validation loss: 2.4992141283172806

Epoch: 6| Step: 8
Training loss: 2.817358440644152
Validation loss: 2.498863677224691

Epoch: 6| Step: 9
Training loss: 2.797089637746591
Validation loss: 2.4986304982552174

Epoch: 6| Step: 10
Training loss: 2.429385445515656
Validation loss: 2.500116035629595

Epoch: 6| Step: 11
Training loss: 2.6031285976279723
Validation loss: 2.4975314827768536

Epoch: 6| Step: 12
Training loss: 1.9556135879139736
Validation loss: 2.4993097385523297

Epoch: 6| Step: 13
Training loss: 2.688100614634466
Validation loss: 2.4972390824105792

Epoch: 89| Step: 0
Training loss: 2.490961903529234
Validation loss: 2.493496271162634

Epoch: 6| Step: 1
Training loss: 2.5101703718199575
Validation loss: 2.4902164553327886

Epoch: 6| Step: 2
Training loss: 2.9075419517895207
Validation loss: 2.4890908481718133

Epoch: 6| Step: 3
Training loss: 2.330687475985953
Validation loss: 2.4886505156373677

Epoch: 6| Step: 4
Training loss: 2.7501604726960633
Validation loss: 2.485738272269325

Epoch: 6| Step: 5
Training loss: 2.9302626388585766
Validation loss: 2.490566384117534

Epoch: 6| Step: 6
Training loss: 3.1309315654691923
Validation loss: 2.4867058302511453

Epoch: 6| Step: 7
Training loss: 2.0823927345448094
Validation loss: 2.4880083654095415

Epoch: 6| Step: 8
Training loss: 2.7951550016603526
Validation loss: 2.484878505011251

Epoch: 6| Step: 9
Training loss: 2.331426340751222
Validation loss: 2.490157317920325

Epoch: 6| Step: 10
Training loss: 2.3314839140917747
Validation loss: 2.490836340259087

Epoch: 6| Step: 11
Training loss: 2.118984009189586
Validation loss: 2.4896807525174327

Epoch: 6| Step: 12
Training loss: 2.7733013280831305
Validation loss: 2.488789872227385

Epoch: 6| Step: 13
Training loss: 2.7407429686051366
Validation loss: 2.491494428195244

Epoch: 90| Step: 0
Training loss: 2.8185510603235273
Validation loss: 2.4891890262774012

Epoch: 6| Step: 1
Training loss: 2.09761033105583
Validation loss: 2.4909553950055443

Epoch: 6| Step: 2
Training loss: 2.7384122852530184
Validation loss: 2.489499818260328

Epoch: 6| Step: 3
Training loss: 2.3712355242957477
Validation loss: 2.490085572428171

Epoch: 6| Step: 4
Training loss: 2.4015226620191212
Validation loss: 2.490284064302052

Epoch: 6| Step: 5
Training loss: 2.8582447924306678
Validation loss: 2.4882838210766822

Epoch: 6| Step: 6
Training loss: 2.8732536651234795
Validation loss: 2.489181794753929

Epoch: 6| Step: 7
Training loss: 2.6171342986663597
Validation loss: 2.4850496699577627

Epoch: 6| Step: 8
Training loss: 2.4483164900409617
Validation loss: 2.4879158106989663

Epoch: 6| Step: 9
Training loss: 2.7281402133023698
Validation loss: 2.4871516036457897

Epoch: 6| Step: 10
Training loss: 2.545059774180243
Validation loss: 2.4878923320799347

Epoch: 6| Step: 11
Training loss: 2.180399132508697
Validation loss: 2.484079579316893

Epoch: 6| Step: 12
Training loss: 2.7289012071250016
Validation loss: 2.484479786004573

Epoch: 6| Step: 13
Training loss: 2.877017764357854
Validation loss: 2.4851384139577664

Epoch: 91| Step: 0
Training loss: 2.4717229012668414
Validation loss: 2.4803674071427597

Epoch: 6| Step: 1
Training loss: 2.1329285307122845
Validation loss: 2.4818165879303207

Epoch: 6| Step: 2
Training loss: 2.8365299667370456
Validation loss: 2.483610167423595

Epoch: 6| Step: 3
Training loss: 2.7572246497733235
Validation loss: 2.480301129942797

Epoch: 6| Step: 4
Training loss: 2.645654256772909
Validation loss: 2.480377964551096

Epoch: 6| Step: 5
Training loss: 2.5541850771300116
Validation loss: 2.4832238943405462

Epoch: 6| Step: 6
Training loss: 2.5954137774324977
Validation loss: 2.4841803868360732

Epoch: 6| Step: 7
Training loss: 2.2032961947975305
Validation loss: 2.48638302247242

Epoch: 6| Step: 8
Training loss: 2.785408254728167
Validation loss: 2.4808745925781768

Epoch: 6| Step: 9
Training loss: 2.799833725351904
Validation loss: 2.48275638530513

Epoch: 6| Step: 10
Training loss: 3.159573759473378
Validation loss: 2.4861144368334736

Epoch: 6| Step: 11
Training loss: 2.218299605096203
Validation loss: 2.4864204671272647

Epoch: 6| Step: 12
Training loss: 1.9695026230689288
Validation loss: 2.4848140752408856

Epoch: 6| Step: 13
Training loss: 2.942226584281774
Validation loss: 2.4845384907859365

Epoch: 92| Step: 0
Training loss: 2.5406028418143607
Validation loss: 2.4850984555651174

Epoch: 6| Step: 1
Training loss: 2.6322370403998625
Validation loss: 2.4832773482862636

Epoch: 6| Step: 2
Training loss: 2.761567323410037
Validation loss: 2.4829315774769367

Epoch: 6| Step: 3
Training loss: 2.258149329803261
Validation loss: 2.486019765666358

Epoch: 6| Step: 4
Training loss: 2.5868521280100145
Validation loss: 2.4873980317550113

Epoch: 6| Step: 5
Training loss: 2.5116755598991243
Validation loss: 2.4852491076622942

Epoch: 6| Step: 6
Training loss: 2.3873510943407856
Validation loss: 2.4944469290704205

Epoch: 6| Step: 7
Training loss: 2.584542165974979
Validation loss: 2.4942254609905046

Epoch: 6| Step: 8
Training loss: 2.240522025281221
Validation loss: 2.4885556056283087

Epoch: 6| Step: 9
Training loss: 2.4825778434972463
Validation loss: 2.485037133612933

Epoch: 6| Step: 10
Training loss: 3.0490330023050762
Validation loss: 2.487303489322321

Epoch: 6| Step: 11
Training loss: 2.6783821329712696
Validation loss: 2.4800744411617193

Epoch: 6| Step: 12
Training loss: 2.914889384505245
Validation loss: 2.4806875778151714

Epoch: 6| Step: 13
Training loss: 2.6189370755403134
Validation loss: 2.4861784173484414

Epoch: 93| Step: 0
Training loss: 2.291592498503872
Validation loss: 2.4788413969738192

Epoch: 6| Step: 1
Training loss: 2.770886088468993
Validation loss: 2.4803913574961007

Epoch: 6| Step: 2
Training loss: 2.2192004109289427
Validation loss: 2.480701986245789

Epoch: 6| Step: 3
Training loss: 2.9514639891001684
Validation loss: 2.4834832564377627

Epoch: 6| Step: 4
Training loss: 2.4112465245690027
Validation loss: 2.4832772202733993

Epoch: 6| Step: 5
Training loss: 2.5749640304867913
Validation loss: 2.4828552620119897

Epoch: 6| Step: 6
Training loss: 2.3637781550820014
Validation loss: 2.4774496132262365

Epoch: 6| Step: 7
Training loss: 2.4839248729285326
Validation loss: 2.4792619628115014

Epoch: 6| Step: 8
Training loss: 2.9016971817763832
Validation loss: 2.4759382871220277

Epoch: 6| Step: 9
Training loss: 2.7668624954165106
Validation loss: 2.4764743713037585

Epoch: 6| Step: 10
Training loss: 1.858694641274013
Validation loss: 2.477939082736476

Epoch: 6| Step: 11
Training loss: 2.9294689046052897
Validation loss: 2.476328970150406

Epoch: 6| Step: 12
Training loss: 2.347911344813826
Validation loss: 2.4839499567819474

Epoch: 6| Step: 13
Training loss: 3.0674976909103346
Validation loss: 2.4800005293148253

Epoch: 94| Step: 0
Training loss: 2.624667737005066
Validation loss: 2.4821315688673407

Epoch: 6| Step: 1
Training loss: 2.8115109717996054
Validation loss: 2.4824067802380454

Epoch: 6| Step: 2
Training loss: 2.1419898366963026
Validation loss: 2.484440272851299

Epoch: 6| Step: 3
Training loss: 2.6447367961570896
Validation loss: 2.4836626291098427

Epoch: 6| Step: 4
Training loss: 3.194986266105159
Validation loss: 2.4845265596172488

Epoch: 6| Step: 5
Training loss: 2.7396833935777867
Validation loss: 2.48312010351006

Epoch: 6| Step: 6
Training loss: 2.733270214871717
Validation loss: 2.4839571875395965

Epoch: 6| Step: 7
Training loss: 2.4523448310939595
Validation loss: 2.4826480773423776

Epoch: 6| Step: 8
Training loss: 1.965833047066614
Validation loss: 2.483163566248256

Epoch: 6| Step: 9
Training loss: 2.163505620262793
Validation loss: 2.4799776006527927

Epoch: 6| Step: 10
Training loss: 3.1910002694173167
Validation loss: 2.484645468906056

Epoch: 6| Step: 11
Training loss: 2.3103413171982026
Validation loss: 2.4786215164093655

Epoch: 6| Step: 12
Training loss: 2.3556824139657557
Validation loss: 2.4784469735267494

Epoch: 6| Step: 13
Training loss: 2.4950513498835867
Validation loss: 2.479486979032988

Epoch: 95| Step: 0
Training loss: 2.711021400054816
Validation loss: 2.480495262504923

Epoch: 6| Step: 1
Training loss: 2.853045853752744
Validation loss: 2.484545335988219

Epoch: 6| Step: 2
Training loss: 2.249265338909426
Validation loss: 2.483381828585583

Epoch: 6| Step: 3
Training loss: 2.512380462383943
Validation loss: 2.481260526748479

Epoch: 6| Step: 4
Training loss: 2.6221146847968053
Validation loss: 2.4794526189025947

Epoch: 6| Step: 5
Training loss: 2.3201751154548083
Validation loss: 2.4817515342791943

Epoch: 6| Step: 6
Training loss: 2.875566178010204
Validation loss: 2.4808303849733786

Epoch: 6| Step: 7
Training loss: 2.8293376872789904
Validation loss: 2.4806706223730126

Epoch: 6| Step: 8
Training loss: 2.105823946912905
Validation loss: 2.4827102265560557

Epoch: 6| Step: 9
Training loss: 2.92284030574386
Validation loss: 2.481104523488238

Epoch: 6| Step: 10
Training loss: 2.266249997980083
Validation loss: 2.480348070468022

Epoch: 6| Step: 11
Training loss: 2.369276880935953
Validation loss: 2.4774509444834996

Epoch: 6| Step: 12
Training loss: 2.641149525209461
Validation loss: 2.4808750090228826

Epoch: 6| Step: 13
Training loss: 2.618160055713085
Validation loss: 2.4846779980416027

Epoch: 96| Step: 0
Training loss: 2.8569899654352406
Validation loss: 2.4853312173646436

Epoch: 6| Step: 1
Training loss: 2.609280430342101
Validation loss: 2.4851650525292652

Epoch: 6| Step: 2
Training loss: 2.715851213978278
Validation loss: 2.4830390969213525

Epoch: 6| Step: 3
Training loss: 3.216155552817213
Validation loss: 2.4846324667283204

Epoch: 6| Step: 4
Training loss: 2.617664714975559
Validation loss: 2.4845004579867744

Epoch: 6| Step: 5
Training loss: 2.484627380987152
Validation loss: 2.485690890007914

Epoch: 6| Step: 6
Training loss: 2.81219082298553
Validation loss: 2.4856659036541138

Epoch: 6| Step: 7
Training loss: 2.1542818236668224
Validation loss: 2.479632956199999

Epoch: 6| Step: 8
Training loss: 2.477607963665489
Validation loss: 2.4797567311818054

Epoch: 6| Step: 9
Training loss: 2.1864292248852073
Validation loss: 2.476794997091235

Epoch: 6| Step: 10
Training loss: 2.182615876677459
Validation loss: 2.480776421796779

Epoch: 6| Step: 11
Training loss: 2.4613208290552575
Validation loss: 2.4805159116251443

Epoch: 6| Step: 12
Training loss: 2.4459949065285627
Validation loss: 2.484466039241111

Epoch: 6| Step: 13
Training loss: 2.758296156879532
Validation loss: 2.483269307465394

Epoch: 97| Step: 0
Training loss: 2.8982930520146586
Validation loss: 2.4818026262764006

Epoch: 6| Step: 1
Training loss: 2.292885358031597
Validation loss: 2.4827718460534927

Epoch: 6| Step: 2
Training loss: 2.3196463608051934
Validation loss: 2.487501979552333

Epoch: 6| Step: 3
Training loss: 2.3311078721153144
Validation loss: 2.4858023583782813

Epoch: 6| Step: 4
Training loss: 2.4288760483055176
Validation loss: 2.4849935277474624

Epoch: 6| Step: 5
Training loss: 2.3113093017100472
Validation loss: 2.4837878191109586

Epoch: 6| Step: 6
Training loss: 2.889730284093505
Validation loss: 2.4860427025370027

Epoch: 6| Step: 7
Training loss: 2.779375280264859
Validation loss: 2.4822670172714645

Epoch: 6| Step: 8
Training loss: 2.4989612328620003
Validation loss: 2.4874425699323286

Epoch: 6| Step: 9
Training loss: 2.7791350820901806
Validation loss: 2.4840370284221587

Epoch: 6| Step: 10
Training loss: 2.3931168677569676
Validation loss: 2.4821521563484827

Epoch: 6| Step: 11
Training loss: 2.104980865174081
Validation loss: 2.4806834851328468

Epoch: 6| Step: 12
Training loss: 3.0917607857772125
Validation loss: 2.482537731845586

Epoch: 6| Step: 13
Training loss: 2.8130706208250484
Validation loss: 2.4821469854808638

Epoch: 98| Step: 0
Training loss: 2.4346217254461533
Validation loss: 2.478423918261695

Epoch: 6| Step: 1
Training loss: 2.595850450225614
Validation loss: 2.4711081111336677

Epoch: 6| Step: 2
Training loss: 2.594984565056852
Validation loss: 2.47106297301251

Epoch: 6| Step: 3
Training loss: 2.1174318517462494
Validation loss: 2.476214122637477

Epoch: 6| Step: 4
Training loss: 2.853112706035688
Validation loss: 2.4830621893493836

Epoch: 6| Step: 5
Training loss: 2.63692363931951
Validation loss: 2.477092634033333

Epoch: 6| Step: 6
Training loss: 2.3597314830546168
Validation loss: 2.4816953254626477

Epoch: 6| Step: 7
Training loss: 2.0901519833293287
Validation loss: 2.4742718842557347

Epoch: 6| Step: 8
Training loss: 2.349767360940911
Validation loss: 2.4799754696063516

Epoch: 6| Step: 9
Training loss: 2.312418652727524
Validation loss: 2.4773904116528898

Epoch: 6| Step: 10
Training loss: 2.9712059703962073
Validation loss: 2.477583777906657

Epoch: 6| Step: 11
Training loss: 2.5765176097135574
Validation loss: 2.475897762967206

Epoch: 6| Step: 12
Training loss: 2.646030829159922
Validation loss: 2.4774306387226672

Epoch: 6| Step: 13
Training loss: 3.3531487541388336
Validation loss: 2.4757705047846117

Epoch: 99| Step: 0
Training loss: 2.5268509869374505
Validation loss: 2.480101983296138

Epoch: 6| Step: 1
Training loss: 2.6831662033190917
Validation loss: 2.481037993706384

Epoch: 6| Step: 2
Training loss: 2.4873287467856318
Validation loss: 2.4808013132386892

Epoch: 6| Step: 3
Training loss: 2.527005062374453
Validation loss: 2.480716450656163

Epoch: 6| Step: 4
Training loss: 2.465302776753171
Validation loss: 2.4765052668459435

Epoch: 6| Step: 5
Training loss: 2.4059539216434067
Validation loss: 2.4716419230650426

Epoch: 6| Step: 6
Training loss: 3.193872701001121
Validation loss: 2.468614212357931

Epoch: 6| Step: 7
Training loss: 2.577157873763039
Validation loss: 2.471897894829243

Epoch: 6| Step: 8
Training loss: 2.4908688683100544
Validation loss: 2.4679669293135977

Epoch: 6| Step: 9
Training loss: 2.505219446951998
Validation loss: 2.471892517645068

Epoch: 6| Step: 10
Training loss: 2.5313178159318332
Validation loss: 2.4735102893611995

Epoch: 6| Step: 11
Training loss: 2.945566829153147
Validation loss: 2.4711362999303903

Epoch: 6| Step: 12
Training loss: 2.5165306972463313
Validation loss: 2.4700929795524247

Epoch: 6| Step: 13
Training loss: 2.1106843628582315
Validation loss: 2.471308360397157

Epoch: 100| Step: 0
Training loss: 2.977700323865718
Validation loss: 2.469572919996651

Epoch: 6| Step: 1
Training loss: 2.946214775486658
Validation loss: 2.4707366740043546

Epoch: 6| Step: 2
Training loss: 3.011334623586353
Validation loss: 2.471282336226571

Epoch: 6| Step: 3
Training loss: 2.5357003355506
Validation loss: 2.470325691434033

Epoch: 6| Step: 4
Training loss: 2.3819661622931014
Validation loss: 2.477230355017303

Epoch: 6| Step: 5
Training loss: 2.6270256401178633
Validation loss: 2.4777293860790053

Epoch: 6| Step: 6
Training loss: 2.496348097950556
Validation loss: 2.481620549191265

Epoch: 6| Step: 7
Training loss: 2.7070624279522195
Validation loss: 2.482096044655035

Epoch: 6| Step: 8
Training loss: 2.0459230262170967
Validation loss: 2.478065091050761

Epoch: 6| Step: 9
Training loss: 2.4322638390941655
Validation loss: 2.4802388722989406

Epoch: 6| Step: 10
Training loss: 2.447535080624225
Validation loss: 2.479827958287195

Epoch: 6| Step: 11
Training loss: 2.1362922424104127
Validation loss: 2.474462089782084

Epoch: 6| Step: 12
Training loss: 2.791312114538656
Validation loss: 2.4721751214539935

Epoch: 6| Step: 13
Training loss: 2.2559488914530816
Validation loss: 2.4725574716742003

Epoch: 101| Step: 0
Training loss: 2.5776309378043005
Validation loss: 2.4713848234043176

Epoch: 6| Step: 1
Training loss: 2.3472950890822166
Validation loss: 2.469853456373986

Epoch: 6| Step: 2
Training loss: 2.6684684229657347
Validation loss: 2.4744905294228237

Epoch: 6| Step: 3
Training loss: 3.0303132487616056
Validation loss: 2.467408552166141

Epoch: 6| Step: 4
Training loss: 2.442679550771314
Validation loss: 2.4706119324512024

Epoch: 6| Step: 5
Training loss: 2.7518017675119486
Validation loss: 2.4722991090836475

Epoch: 6| Step: 6
Training loss: 2.493303868056759
Validation loss: 2.468603234415213

Epoch: 6| Step: 7
Training loss: 2.491799638276901
Validation loss: 2.469704471648723

Epoch: 6| Step: 8
Training loss: 2.3698892314794846
Validation loss: 2.471368358854029

Epoch: 6| Step: 9
Training loss: 2.7480491307404566
Validation loss: 2.474265982254633

Epoch: 6| Step: 10
Training loss: 2.6352764790960466
Validation loss: 2.4698158409923088

Epoch: 6| Step: 11
Training loss: 2.458568195395672
Validation loss: 2.474739229869339

Epoch: 6| Step: 12
Training loss: 2.2058315020665185
Validation loss: 2.4764515503941595

Epoch: 6| Step: 13
Training loss: 2.652551297366811
Validation loss: 2.4796291422171453

Epoch: 102| Step: 0
Training loss: 2.8673130600381147
Validation loss: 2.476434425548175

Epoch: 6| Step: 1
Training loss: 2.5367661641174446
Validation loss: 2.4813480050360233

Epoch: 6| Step: 2
Training loss: 2.096345232516062
Validation loss: 2.481152425748398

Epoch: 6| Step: 3
Training loss: 1.843469113435965
Validation loss: 2.4777193305853698

Epoch: 6| Step: 4
Training loss: 2.5751799437231004
Validation loss: 2.4775315804494458

Epoch: 6| Step: 5
Training loss: 2.856508245834503
Validation loss: 2.484095735668714

Epoch: 6| Step: 6
Training loss: 2.756683896743945
Validation loss: 2.4814591800843155

Epoch: 6| Step: 7
Training loss: 2.679057767403989
Validation loss: 2.482812866185303

Epoch: 6| Step: 8
Training loss: 2.964891677087099
Validation loss: 2.4771165839664726

Epoch: 6| Step: 9
Training loss: 2.627137358490876
Validation loss: 2.480244215366993

Epoch: 6| Step: 10
Training loss: 2.877625634759192
Validation loss: 2.47995749183341

Epoch: 6| Step: 11
Training loss: 2.4911345646245975
Validation loss: 2.482432807840263

Epoch: 6| Step: 12
Training loss: 2.4745258416556752
Validation loss: 2.4764838461916114

Epoch: 6| Step: 13
Training loss: 2.0705285301499807
Validation loss: 2.4826315754484094

Epoch: 103| Step: 0
Training loss: 2.4393180522678115
Validation loss: 2.48086299616676

Epoch: 6| Step: 1
Training loss: 2.5221130863764203
Validation loss: 2.4798127836400683

Epoch: 6| Step: 2
Training loss: 2.81635461090619
Validation loss: 2.480892035144647

Epoch: 6| Step: 3
Training loss: 2.5759220768592797
Validation loss: 2.482767604760471

Epoch: 6| Step: 4
Training loss: 2.8078112195181326
Validation loss: 2.4762025044004115

Epoch: 6| Step: 5
Training loss: 2.395388277152899
Validation loss: 2.478391900267355

Epoch: 6| Step: 6
Training loss: 3.322080756173322
Validation loss: 2.4766739620633538

Epoch: 6| Step: 7
Training loss: 2.1426868393752923
Validation loss: 2.4703770519092942

Epoch: 6| Step: 8
Training loss: 2.222685533810002
Validation loss: 2.4781749221628675

Epoch: 6| Step: 9
Training loss: 2.6457350905393993
Validation loss: 2.471683401212762

Epoch: 6| Step: 10
Training loss: 2.477331770065247
Validation loss: 2.4709309871174936

Epoch: 6| Step: 11
Training loss: 2.6903557796677013
Validation loss: 2.474452358243282

Epoch: 6| Step: 12
Training loss: 2.678165815614353
Validation loss: 2.4760222622939283

Epoch: 6| Step: 13
Training loss: 1.8594639861026598
Validation loss: 2.471222070366664

Epoch: 104| Step: 0
Training loss: 2.5498053420324225
Validation loss: 2.4745979098059676

Epoch: 6| Step: 1
Training loss: 2.6417076103655623
Validation loss: 2.4808185320758516

Epoch: 6| Step: 2
Training loss: 2.8313778879953317
Validation loss: 2.4755577191130893

Epoch: 6| Step: 3
Training loss: 2.912993124935734
Validation loss: 2.4815116552186414

Epoch: 6| Step: 4
Training loss: 2.3863617025920747
Validation loss: 2.479609351077465

Epoch: 6| Step: 5
Training loss: 2.2571779831262235
Validation loss: 2.4778693809335874

Epoch: 6| Step: 6
Training loss: 2.2717042588584406
Validation loss: 2.4818542295669292

Epoch: 6| Step: 7
Training loss: 3.176880893615503
Validation loss: 2.480354430600542

Epoch: 6| Step: 8
Training loss: 1.9500777009008592
Validation loss: 2.480170524871876

Epoch: 6| Step: 9
Training loss: 2.2939329443379326
Validation loss: 2.478016166975

Epoch: 6| Step: 10
Training loss: 2.0056672863233658
Validation loss: 2.4800043747719767

Epoch: 6| Step: 11
Training loss: 3.116464631439162
Validation loss: 2.478703404801553

Epoch: 6| Step: 12
Training loss: 2.5845107092507256
Validation loss: 2.4798269968550746

Epoch: 6| Step: 13
Training loss: 2.7077405036208195
Validation loss: 2.4786971686820456

Epoch: 105| Step: 0
Training loss: 2.19318229524353
Validation loss: 2.4742300881488477

Epoch: 6| Step: 1
Training loss: 2.6979540278573846
Validation loss: 2.4755552792829585

Epoch: 6| Step: 2
Training loss: 2.942268235146774
Validation loss: 2.471050245103278

Epoch: 6| Step: 3
Training loss: 2.3658967480609445
Validation loss: 2.4695656471226273

Epoch: 6| Step: 4
Training loss: 2.924201243310206
Validation loss: 2.4746843149529423

Epoch: 6| Step: 5
Training loss: 2.9067589098907898
Validation loss: 2.4727363593536755

Epoch: 6| Step: 6
Training loss: 2.2475739221010813
Validation loss: 2.4751232790829483

Epoch: 6| Step: 7
Training loss: 2.577461110958499
Validation loss: 2.4747088662460066

Epoch: 6| Step: 8
Training loss: 2.34232378481085
Validation loss: 2.470610895056284

Epoch: 6| Step: 9
Training loss: 2.7997962570994894
Validation loss: 2.473496248692596

Epoch: 6| Step: 10
Training loss: 2.4970202808343287
Validation loss: 2.4730211001816307

Epoch: 6| Step: 11
Training loss: 2.4070882947105856
Validation loss: 2.4660561104511785

Epoch: 6| Step: 12
Training loss: 2.5227127215366463
Validation loss: 2.4678938946587605

Epoch: 6| Step: 13
Training loss: 2.178213845059656
Validation loss: 2.468026485735844

Epoch: 106| Step: 0
Training loss: 2.7187371966181106
Validation loss: 2.4673402036375207

Epoch: 6| Step: 1
Training loss: 2.197019734505394
Validation loss: 2.467609947071463

Epoch: 6| Step: 2
Training loss: 2.788955301741113
Validation loss: 2.468927602375243

Epoch: 6| Step: 3
Training loss: 2.2209350142781044
Validation loss: 2.4655597047979554

Epoch: 6| Step: 4
Training loss: 1.9873689908208465
Validation loss: 2.4675912994891385

Epoch: 6| Step: 5
Training loss: 1.9100640085489675
Validation loss: 2.470836401600297

Epoch: 6| Step: 6
Training loss: 2.097863100107343
Validation loss: 2.4750836727499625

Epoch: 6| Step: 7
Training loss: 3.082417395011635
Validation loss: 2.4680565290628618

Epoch: 6| Step: 8
Training loss: 2.3948681642566303
Validation loss: 2.469258831397043

Epoch: 6| Step: 9
Training loss: 2.986450751651702
Validation loss: 2.4723690723947493

Epoch: 6| Step: 10
Training loss: 2.6413006341416327
Validation loss: 2.4707791162195885

Epoch: 6| Step: 11
Training loss: 2.835893951165717
Validation loss: 2.4703748482402985

Epoch: 6| Step: 12
Training loss: 2.4469325150201313
Validation loss: 2.4717422250356798

Epoch: 6| Step: 13
Training loss: 3.156306351262504
Validation loss: 2.467557522529368

Epoch: 107| Step: 0
Training loss: 3.0585819015175995
Validation loss: 2.4720608525229424

Epoch: 6| Step: 1
Training loss: 2.801106070991826
Validation loss: 2.474513235936891

Epoch: 6| Step: 2
Training loss: 2.605424277227737
Validation loss: 2.4680404287187274

Epoch: 6| Step: 3
Training loss: 2.487026598945722
Validation loss: 2.4742477943667796

Epoch: 6| Step: 4
Training loss: 2.263069763942271
Validation loss: 2.479818311901358

Epoch: 6| Step: 5
Training loss: 3.3707211532756087
Validation loss: 2.4700836892821463

Epoch: 6| Step: 6
Training loss: 2.559400405105615
Validation loss: 2.4794118316558458

Epoch: 6| Step: 7
Training loss: 2.5706888868247435
Validation loss: 2.478232766141692

Epoch: 6| Step: 8
Training loss: 2.3193513568566395
Validation loss: 2.477046690579734

Epoch: 6| Step: 9
Training loss: 2.4180503917709313
Validation loss: 2.47754459583475

Epoch: 6| Step: 10
Training loss: 2.580192245743308
Validation loss: 2.4802615582297074

Epoch: 6| Step: 11
Training loss: 2.1257334172798648
Validation loss: 2.4713215291501385

Epoch: 6| Step: 12
Training loss: 2.068191997034289
Validation loss: 2.464881102716719

Epoch: 6| Step: 13
Training loss: 2.3740318734424366
Validation loss: 2.462406321581678

Epoch: 108| Step: 0
Training loss: 2.3683072202219604
Validation loss: 2.4729317285153485

Epoch: 6| Step: 1
Training loss: 2.170140513779774
Validation loss: 2.474019121460555

Epoch: 6| Step: 2
Training loss: 2.7380877765214238
Validation loss: 2.4854926548288265

Epoch: 6| Step: 3
Training loss: 2.785164467905127
Validation loss: 2.485737361080507

Epoch: 6| Step: 4
Training loss: 3.0443204685904073
Validation loss: 2.4771202093213036

Epoch: 6| Step: 5
Training loss: 2.8057602554863967
Validation loss: 2.4783272056615004

Epoch: 6| Step: 6
Training loss: 2.592879183636889
Validation loss: 2.483228054844611

Epoch: 6| Step: 7
Training loss: 2.387970391714546
Validation loss: 2.4731962348576992

Epoch: 6| Step: 8
Training loss: 2.7612069396239995
Validation loss: 2.4740663899698725

Epoch: 6| Step: 9
Training loss: 2.9075829515243616
Validation loss: 2.4819119477689924

Epoch: 6| Step: 10
Training loss: 2.1820742211240525
Validation loss: 2.4711170518250642

Epoch: 6| Step: 11
Training loss: 2.4007016904578924
Validation loss: 2.470852700833542

Epoch: 6| Step: 12
Training loss: 2.0239064030473095
Validation loss: 2.4743803822085564

Epoch: 6| Step: 13
Training loss: 2.4419255307126764
Validation loss: 2.4691552742952636

Epoch: 109| Step: 0
Training loss: 2.68591332727088
Validation loss: 2.4758462281235314

Epoch: 6| Step: 1
Training loss: 3.0524817891245495
Validation loss: 2.4748928085388515

Epoch: 6| Step: 2
Training loss: 2.2224506088621605
Validation loss: 2.478560186516091

Epoch: 6| Step: 3
Training loss: 2.166169280646596
Validation loss: 2.4766865567845793

Epoch: 6| Step: 4
Training loss: 2.637871745881002
Validation loss: 2.480068673136718

Epoch: 6| Step: 5
Training loss: 2.2328910968633604
Validation loss: 2.4795618837488957

Epoch: 6| Step: 6
Training loss: 2.580109358547228
Validation loss: 2.4810437434618584

Epoch: 6| Step: 7
Training loss: 2.5416923167284153
Validation loss: 2.4792593022411404

Epoch: 6| Step: 8
Training loss: 2.51925870618937
Validation loss: 2.4824971873666657

Epoch: 6| Step: 9
Training loss: 2.357118146114537
Validation loss: 2.475630784490643

Epoch: 6| Step: 10
Training loss: 2.767389456618286
Validation loss: 2.4755792119864672

Epoch: 6| Step: 11
Training loss: 2.4494350404771077
Validation loss: 2.4739209838189433

Epoch: 6| Step: 12
Training loss: 3.109191275684715
Validation loss: 2.4748090278596058

Epoch: 6| Step: 13
Training loss: 2.3923701480079007
Validation loss: 2.4698706228269987

Epoch: 110| Step: 0
Training loss: 3.120524444029582
Validation loss: 2.4694492138603312

Epoch: 6| Step: 1
Training loss: 2.796138389382422
Validation loss: 2.4753398905916466

Epoch: 6| Step: 2
Training loss: 2.5205428111067802
Validation loss: 2.4718656878129184

Epoch: 6| Step: 3
Training loss: 2.4712721097861094
Validation loss: 2.469493737841463

Epoch: 6| Step: 4
Training loss: 2.6757503312823614
Validation loss: 2.469706973572246

Epoch: 6| Step: 5
Training loss: 2.336055076472406
Validation loss: 2.47013164439721

Epoch: 6| Step: 6
Training loss: 1.6847941993432387
Validation loss: 2.4651704582769955

Epoch: 6| Step: 7
Training loss: 3.0755158030538525
Validation loss: 2.4654101382498936

Epoch: 6| Step: 8
Training loss: 2.317651320767065
Validation loss: 2.4654436786928224

Epoch: 6| Step: 9
Training loss: 2.4678677298220366
Validation loss: 2.469109327989685

Epoch: 6| Step: 10
Training loss: 2.2623665364559913
Validation loss: 2.465224182788047

Epoch: 6| Step: 11
Training loss: 2.5750927288062235
Validation loss: 2.4676830303869615

Epoch: 6| Step: 12
Training loss: 2.3921308574286857
Validation loss: 2.4624548538381283

Epoch: 6| Step: 13
Training loss: 2.7080059636161646
Validation loss: 2.4629643565593313

Epoch: 111| Step: 0
Training loss: 2.526617261190523
Validation loss: 2.469926963992761

Epoch: 6| Step: 1
Training loss: 2.6214402903483833
Validation loss: 2.4630336977054768

Epoch: 6| Step: 2
Training loss: 2.037573259592893
Validation loss: 2.464228856146211

Epoch: 6| Step: 3
Training loss: 2.672575652405067
Validation loss: 2.4673170445878645

Epoch: 6| Step: 4
Training loss: 2.429454044030651
Validation loss: 2.4688944713957848

Epoch: 6| Step: 5
Training loss: 2.280181634594745
Validation loss: 2.468609029229769

Epoch: 6| Step: 6
Training loss: 2.2920133039544406
Validation loss: 2.4720085786333166

Epoch: 6| Step: 7
Training loss: 2.1395688758170968
Validation loss: 2.4744475406356523

Epoch: 6| Step: 8
Training loss: 2.7219024446595084
Validation loss: 2.4680313319778557

Epoch: 6| Step: 9
Training loss: 2.874505041888054
Validation loss: 2.470967805579368

Epoch: 6| Step: 10
Training loss: 2.878144741922571
Validation loss: 2.4714173984511283

Epoch: 6| Step: 11
Training loss: 2.5115102915779874
Validation loss: 2.466233447625642

Epoch: 6| Step: 12
Training loss: 2.501031186104237
Validation loss: 2.467780610992307

Epoch: 6| Step: 13
Training loss: 2.89052354789239
Validation loss: 2.4645895204657196

Epoch: 112| Step: 0
Training loss: 3.124657421407932
Validation loss: 2.467351122780242

Epoch: 6| Step: 1
Training loss: 2.3854128797298397
Validation loss: 2.464390410232316

Epoch: 6| Step: 2
Training loss: 2.2107254843270847
Validation loss: 2.461056233120255

Epoch: 6| Step: 3
Training loss: 2.453596907983305
Validation loss: 2.4668109940713525

Epoch: 6| Step: 4
Training loss: 2.6228203579828
Validation loss: 2.465991720656465

Epoch: 6| Step: 5
Training loss: 2.3993784894468226
Validation loss: 2.465411476008156

Epoch: 6| Step: 6
Training loss: 2.280123497813924
Validation loss: 2.469396257115114

Epoch: 6| Step: 7
Training loss: 2.2621513308792647
Validation loss: 2.4681061013629133

Epoch: 6| Step: 8
Training loss: 2.6145062276912308
Validation loss: 2.4729506571961024

Epoch: 6| Step: 9
Training loss: 2.8936646022513157
Validation loss: 2.4718786446166305

Epoch: 6| Step: 10
Training loss: 3.0006191886236944
Validation loss: 2.4789145258635017

Epoch: 6| Step: 11
Training loss: 2.2610241707914844
Validation loss: 2.467426355648535

Epoch: 6| Step: 12
Training loss: 1.8620578420241023
Validation loss: 2.4683511226673267

Epoch: 6| Step: 13
Training loss: 2.956362287070397
Validation loss: 2.4667611943853682

Epoch: 113| Step: 0
Training loss: 2.4509896867987226
Validation loss: 2.4626183153829837

Epoch: 6| Step: 1
Training loss: 2.8008583728594516
Validation loss: 2.464561168112015

Epoch: 6| Step: 2
Training loss: 3.0897764639876635
Validation loss: 2.46080082912489

Epoch: 6| Step: 3
Training loss: 2.7160543473302163
Validation loss: 2.462304388626051

Epoch: 6| Step: 4
Training loss: 1.593359282227757
Validation loss: 2.4622175328991958

Epoch: 6| Step: 5
Training loss: 2.7377812558966723
Validation loss: 2.464722692355181

Epoch: 6| Step: 6
Training loss: 1.9560756520344333
Validation loss: 2.464910023680437

Epoch: 6| Step: 7
Training loss: 2.14133269035089
Validation loss: 2.4654887101701357

Epoch: 6| Step: 8
Training loss: 2.3056417267819023
Validation loss: 2.4635660171649496

Epoch: 6| Step: 9
Training loss: 2.6367847575649876
Validation loss: 2.463111409741324

Epoch: 6| Step: 10
Training loss: 3.2016365873031565
Validation loss: 2.4697871383653367

Epoch: 6| Step: 11
Training loss: 2.5395880991447948
Validation loss: 2.458201038443161

Epoch: 6| Step: 12
Training loss: 2.4075119870720285
Validation loss: 2.4628751685201786

Epoch: 6| Step: 13
Training loss: 2.4500822403787064
Validation loss: 2.4662792380536978

Epoch: 114| Step: 0
Training loss: 2.466097795340169
Validation loss: 2.4683622868617268

Epoch: 6| Step: 1
Training loss: 2.3211666294752624
Validation loss: 2.47520939297623

Epoch: 6| Step: 2
Training loss: 2.8610851406001
Validation loss: 2.4777787327823972

Epoch: 6| Step: 3
Training loss: 2.6730954244001874
Validation loss: 2.479761145879643

Epoch: 6| Step: 4
Training loss: 2.6187322356502376
Validation loss: 2.4731140355762147

Epoch: 6| Step: 5
Training loss: 2.6466456290240905
Validation loss: 2.4798310188436314

Epoch: 6| Step: 6
Training loss: 2.3414169906965547
Validation loss: 2.477301550499441

Epoch: 6| Step: 7
Training loss: 2.3523868370607666
Validation loss: 2.474586428501009

Epoch: 6| Step: 8
Training loss: 2.389884884029173
Validation loss: 2.476396244216677

Epoch: 6| Step: 9
Training loss: 2.9359547223230065
Validation loss: 2.475346544517476

Epoch: 6| Step: 10
Training loss: 2.694289568964907
Validation loss: 2.4732794596501924

Epoch: 6| Step: 11
Training loss: 2.6024935319363913
Validation loss: 2.476084906800044

Epoch: 6| Step: 12
Training loss: 2.8352934471187305
Validation loss: 2.4834744562676456

Epoch: 6| Step: 13
Training loss: 2.1077635084245787
Validation loss: 2.470376521098694

Epoch: 115| Step: 0
Training loss: 2.449739781009286
Validation loss: 2.4799208789427625

Epoch: 6| Step: 1
Training loss: 2.851898926001912
Validation loss: 2.471484540924554

Epoch: 6| Step: 2
Training loss: 2.8937611655891162
Validation loss: 2.4774714585863027

Epoch: 6| Step: 3
Training loss: 2.5429541240218794
Validation loss: 2.474192579456422

Epoch: 6| Step: 4
Training loss: 2.6290698517769475
Validation loss: 2.4763922086265433

Epoch: 6| Step: 5
Training loss: 2.7092300886672294
Validation loss: 2.4815650099391884

Epoch: 6| Step: 6
Training loss: 3.0673876315725437
Validation loss: 2.471710739433037

Epoch: 6| Step: 7
Training loss: 2.563439545863692
Validation loss: 2.476366807524552

Epoch: 6| Step: 8
Training loss: 1.5443784044784759
Validation loss: 2.4753087156273508

Epoch: 6| Step: 9
Training loss: 2.6344736897546115
Validation loss: 2.478953173337852

Epoch: 6| Step: 10
Training loss: 2.6080466904117485
Validation loss: 2.4737879858430407

Epoch: 6| Step: 11
Training loss: 2.75361655585118
Validation loss: 2.4799020515347165

Epoch: 6| Step: 12
Training loss: 2.3120797265109965
Validation loss: 2.4879625756146533

Epoch: 6| Step: 13
Training loss: 1.76617882068831
Validation loss: 2.4877584677747526

Epoch: 116| Step: 0
Training loss: 2.4950309006912224
Validation loss: 2.489193112956871

Epoch: 6| Step: 1
Training loss: 2.947019694427864
Validation loss: 2.484276039823681

Epoch: 6| Step: 2
Training loss: 1.9348690258717338
Validation loss: 2.482482061049181

Epoch: 6| Step: 3
Training loss: 2.902666405138814
Validation loss: 2.479455808132505

Epoch: 6| Step: 4
Training loss: 2.477554940731786
Validation loss: 2.4752914424090933

Epoch: 6| Step: 5
Training loss: 2.834183247566419
Validation loss: 2.47791937431554

Epoch: 6| Step: 6
Training loss: 2.2624154343792133
Validation loss: 2.472948961976356

Epoch: 6| Step: 7
Training loss: 3.157724319427274
Validation loss: 2.477471747290212

Epoch: 6| Step: 8
Training loss: 2.231904271045213
Validation loss: 2.4710794154766593

Epoch: 6| Step: 9
Training loss: 2.421010016747181
Validation loss: 2.4742423981995003

Epoch: 6| Step: 10
Training loss: 2.5644124035823435
Validation loss: 2.4734787057772607

Epoch: 6| Step: 11
Training loss: 2.8035112640062048
Validation loss: 2.469103043498582

Epoch: 6| Step: 12
Training loss: 1.9037480429065086
Validation loss: 2.4743666997803895

Epoch: 6| Step: 13
Training loss: 2.5487189609345697
Validation loss: 2.4724774529535076

Epoch: 117| Step: 0
Training loss: 2.55558728345811
Validation loss: 2.4705310947602763

Epoch: 6| Step: 1
Training loss: 2.825461803938885
Validation loss: 2.466951447449149

Epoch: 6| Step: 2
Training loss: 3.173798076780836
Validation loss: 2.4636595672933863

Epoch: 6| Step: 3
Training loss: 2.764978624230204
Validation loss: 2.4689838604477448

Epoch: 6| Step: 4
Training loss: 2.804643295917323
Validation loss: 2.468162724301703

Epoch: 6| Step: 5
Training loss: 2.6283068037256414
Validation loss: 2.466713189854796

Epoch: 6| Step: 6
Training loss: 3.174973801632424
Validation loss: 2.463510159592777

Epoch: 6| Step: 7
Training loss: 2.5178788791943445
Validation loss: 2.46639319484777

Epoch: 6| Step: 8
Training loss: 2.2826005256301274
Validation loss: 2.46557578910837

Epoch: 6| Step: 9
Training loss: 1.7670215721044122
Validation loss: 2.4663560261454673

Epoch: 6| Step: 10
Training loss: 2.294119914731247
Validation loss: 2.46327042380165

Epoch: 6| Step: 11
Training loss: 2.544897891771105
Validation loss: 2.462309423646699

Epoch: 6| Step: 12
Training loss: 1.6189391007305955
Validation loss: 2.4634142971111515

Epoch: 6| Step: 13
Training loss: 2.0962595916328435
Validation loss: 2.4637103006231116

Epoch: 118| Step: 0
Training loss: 2.756268206685456
Validation loss: 2.4655373509778706

Epoch: 6| Step: 1
Training loss: 2.6622670855303916
Validation loss: 2.464752848501172

Epoch: 6| Step: 2
Training loss: 2.4597986886375574
Validation loss: 2.466156172336281

Epoch: 6| Step: 3
Training loss: 2.658390663589076
Validation loss: 2.4597847474007

Epoch: 6| Step: 4
Training loss: 2.4252763059845104
Validation loss: 2.463791918527808

Epoch: 6| Step: 5
Training loss: 1.8977458934254563
Validation loss: 2.4669696649686985

Epoch: 6| Step: 6
Training loss: 2.5472818061444538
Validation loss: 2.4635667913874872

Epoch: 6| Step: 7
Training loss: 2.3544362906834424
Validation loss: 2.4631717611173674

Epoch: 6| Step: 8
Training loss: 2.433737761276186
Validation loss: 2.4626023892515008

Epoch: 6| Step: 9
Training loss: 2.400451709041485
Validation loss: 2.4672401897722285

Epoch: 6| Step: 10
Training loss: 2.0714096904702184
Validation loss: 2.4621632908957825

Epoch: 6| Step: 11
Training loss: 2.8175866646626013
Validation loss: 2.4634105225403378

Epoch: 6| Step: 12
Training loss: 3.386724663435581
Validation loss: 2.466473499565841

Epoch: 6| Step: 13
Training loss: 2.282534094197569
Validation loss: 2.469865860636434

Epoch: 119| Step: 0
Training loss: 2.8458867691258463
Validation loss: 2.4734710748915574

Epoch: 6| Step: 1
Training loss: 2.900313025056183
Validation loss: 2.4691840969178145

Epoch: 6| Step: 2
Training loss: 2.2212038037718704
Validation loss: 2.4676311065926515

Epoch: 6| Step: 3
Training loss: 2.5557474626366035
Validation loss: 2.462655387210092

Epoch: 6| Step: 4
Training loss: 1.860175208996858
Validation loss: 2.467295753531236

Epoch: 6| Step: 5
Training loss: 2.988079867090948
Validation loss: 2.461136114592898

Epoch: 6| Step: 6
Training loss: 2.5090333812951493
Validation loss: 2.4731615463228853

Epoch: 6| Step: 7
Training loss: 2.537141701343327
Validation loss: 2.464642612736467

Epoch: 6| Step: 8
Training loss: 1.8684208200453154
Validation loss: 2.4669482420538076

Epoch: 6| Step: 9
Training loss: 2.453094676613938
Validation loss: 2.459551999461573

Epoch: 6| Step: 10
Training loss: 2.3778905845732576
Validation loss: 2.464406897215646

Epoch: 6| Step: 11
Training loss: 2.869482135637998
Validation loss: 2.4680680246443063

Epoch: 6| Step: 12
Training loss: 2.59720225561653
Validation loss: 2.4655343371452387

Epoch: 6| Step: 13
Training loss: 2.610745464136541
Validation loss: 2.469659034345815

Epoch: 120| Step: 0
Training loss: 2.382599968108836
Validation loss: 2.4673670826792033

Epoch: 6| Step: 1
Training loss: 2.2922028232262512
Validation loss: 2.4715959908311262

Epoch: 6| Step: 2
Training loss: 2.2845461299895105
Validation loss: 2.464838655671076

Epoch: 6| Step: 3
Training loss: 1.9558732495692908
Validation loss: 2.4668527709072805

Epoch: 6| Step: 4
Training loss: 2.4432425711177395
Validation loss: 2.4584384723314057

Epoch: 6| Step: 5
Training loss: 2.1515136890512236
Validation loss: 2.4617614335621405

Epoch: 6| Step: 6
Training loss: 2.803530483623715
Validation loss: 2.457486335403364

Epoch: 6| Step: 7
Training loss: 2.4914463579472885
Validation loss: 2.459180642784922

Epoch: 6| Step: 8
Training loss: 2.9090493779035542
Validation loss: 2.458751632102912

Epoch: 6| Step: 9
Training loss: 2.6423355972410594
Validation loss: 2.457343311637632

Epoch: 6| Step: 10
Training loss: 3.356241157278563
Validation loss: 2.4636238251119305

Epoch: 6| Step: 11
Training loss: 2.4173052590800714
Validation loss: 2.4580248838551

Epoch: 6| Step: 12
Training loss: 2.7080086929204303
Validation loss: 2.462824506726746

Epoch: 6| Step: 13
Training loss: 2.4425525629172293
Validation loss: 2.4662040426977057

Epoch: 121| Step: 0
Training loss: 2.6387016921543487
Validation loss: 2.467134429960005

Epoch: 6| Step: 1
Training loss: 2.953413046054593
Validation loss: 2.4670121558840488

Epoch: 6| Step: 2
Training loss: 2.661108084747498
Validation loss: 2.467371124978297

Epoch: 6| Step: 3
Training loss: 2.4245174635755586
Validation loss: 2.469485467093968

Epoch: 6| Step: 4
Training loss: 2.525734060113898
Validation loss: 2.4690189778394402

Epoch: 6| Step: 5
Training loss: 2.813865245490888
Validation loss: 2.4713884250100717

Epoch: 6| Step: 6
Training loss: 2.3497364139856116
Validation loss: 2.46877047373334

Epoch: 6| Step: 7
Training loss: 2.6215591585977203
Validation loss: 2.4732255727199877

Epoch: 6| Step: 8
Training loss: 2.728153409515013
Validation loss: 2.47058039223426

Epoch: 6| Step: 9
Training loss: 2.045894591844536
Validation loss: 2.465097034496954

Epoch: 6| Step: 10
Training loss: 2.2597468448738853
Validation loss: 2.462687343564652

Epoch: 6| Step: 11
Training loss: 2.263073345902228
Validation loss: 2.4619586017014172

Epoch: 6| Step: 12
Training loss: 2.4506178757968464
Validation loss: 2.4643412146758528

Epoch: 6| Step: 13
Training loss: 2.445081413489397
Validation loss: 2.4669054520432225

Epoch: 122| Step: 0
Training loss: 2.345800799544539
Validation loss: 2.4681560751584066

Epoch: 6| Step: 1
Training loss: 2.434713286766498
Validation loss: 2.4705019983343894

Epoch: 6| Step: 2
Training loss: 2.759455464314235
Validation loss: 2.4769021652699506

Epoch: 6| Step: 3
Training loss: 2.7129368513767704
Validation loss: 2.485585651477922

Epoch: 6| Step: 4
Training loss: 2.4016679014705296
Validation loss: 2.488443821457447

Epoch: 6| Step: 5
Training loss: 2.049391502693186
Validation loss: 2.479166036226422

Epoch: 6| Step: 6
Training loss: 2.9774751640712527
Validation loss: 2.4756766739668654

Epoch: 6| Step: 7
Training loss: 2.1893792935393823
Validation loss: 2.4790982522794365

Epoch: 6| Step: 8
Training loss: 2.3822747295952382
Validation loss: 2.4745505390433933

Epoch: 6| Step: 9
Training loss: 2.4281542684197635
Validation loss: 2.467539679734193

Epoch: 6| Step: 10
Training loss: 3.0054982980416494
Validation loss: 2.4669176214592334

Epoch: 6| Step: 11
Training loss: 2.5097745546412153
Validation loss: 2.4649793423347393

Epoch: 6| Step: 12
Training loss: 2.58525016385823
Validation loss: 2.471556006423974

Epoch: 6| Step: 13
Training loss: 2.6492176088529225
Validation loss: 2.475331928331199

Epoch: 123| Step: 0
Training loss: 2.5598371672998264
Validation loss: 2.4718000507526243

Epoch: 6| Step: 1
Training loss: 2.369869714366959
Validation loss: 2.477437070502204

Epoch: 6| Step: 2
Training loss: 2.8067742450632265
Validation loss: 2.478964410006012

Epoch: 6| Step: 3
Training loss: 2.5366762186472935
Validation loss: 2.475703671155669

Epoch: 6| Step: 4
Training loss: 2.063659804260316
Validation loss: 2.479747861701594

Epoch: 6| Step: 5
Training loss: 2.221877566737156
Validation loss: 2.472300861003269

Epoch: 6| Step: 6
Training loss: 2.355230670492907
Validation loss: 2.4729365812130197

Epoch: 6| Step: 7
Training loss: 2.706497646215893
Validation loss: 2.4720151691907533

Epoch: 6| Step: 8
Training loss: 2.5090905851368954
Validation loss: 2.4705775293083527

Epoch: 6| Step: 9
Training loss: 2.4331908650257037
Validation loss: 2.469382064321331

Epoch: 6| Step: 10
Training loss: 2.6013968016863975
Validation loss: 2.4623752814142232

Epoch: 6| Step: 11
Training loss: 2.8243048563766853
Validation loss: 2.458130316244817

Epoch: 6| Step: 12
Training loss: 2.910655302742294
Validation loss: 2.4625075403088377

Epoch: 6| Step: 13
Training loss: 2.3537147785940777
Validation loss: 2.4569792547420146

Epoch: 124| Step: 0
Training loss: 2.483656293448104
Validation loss: 2.459118238243924

Epoch: 6| Step: 1
Training loss: 2.2465283844082418
Validation loss: 2.461025757190967

Epoch: 6| Step: 2
Training loss: 1.9474056273917475
Validation loss: 2.4613935259987363

Epoch: 6| Step: 3
Training loss: 2.564795140791423
Validation loss: 2.4674443603060547

Epoch: 6| Step: 4
Training loss: 2.1673299312199146
Validation loss: 2.4735114138964276

Epoch: 6| Step: 5
Training loss: 3.0485745898245824
Validation loss: 2.47199113768313

Epoch: 6| Step: 6
Training loss: 2.4197403883594837
Validation loss: 2.461875349298023

Epoch: 6| Step: 7
Training loss: 2.4639093771159963
Validation loss: 2.4640119451877323

Epoch: 6| Step: 8
Training loss: 2.62228252894708
Validation loss: 2.4576538461550586

Epoch: 6| Step: 9
Training loss: 2.998629733906288
Validation loss: 2.457981542427449

Epoch: 6| Step: 10
Training loss: 2.827998543119797
Validation loss: 2.4621990381402936

Epoch: 6| Step: 11
Training loss: 2.198957139711645
Validation loss: 2.4558138274846466

Epoch: 6| Step: 12
Training loss: 2.7604041525119247
Validation loss: 2.4624953733036063

Epoch: 6| Step: 13
Training loss: 2.379611707796634
Validation loss: 2.4666604965579557

Epoch: 125| Step: 0
Training loss: 2.5999329191504215
Validation loss: 2.467571041420488

Epoch: 6| Step: 1
Training loss: 3.455691665334779
Validation loss: 2.4739953824665517

Epoch: 6| Step: 2
Training loss: 2.5156169441046767
Validation loss: 2.4743016911536935

Epoch: 6| Step: 3
Training loss: 2.0157402064792698
Validation loss: 2.4749006678495498

Epoch: 6| Step: 4
Training loss: 2.008766511708011
Validation loss: 2.4702699545394164

Epoch: 6| Step: 5
Training loss: 2.2125847277608948
Validation loss: 2.467965093813035

Epoch: 6| Step: 6
Training loss: 2.6292167582226367
Validation loss: 2.471911703448917

Epoch: 6| Step: 7
Training loss: 2.686905551194541
Validation loss: 2.461127137643123

Epoch: 6| Step: 8
Training loss: 2.8797617744889275
Validation loss: 2.465944555192977

Epoch: 6| Step: 9
Training loss: 2.3393085357983843
Validation loss: 2.4688503550803222

Epoch: 6| Step: 10
Training loss: 2.4087865761561806
Validation loss: 2.4665352749841403

Epoch: 6| Step: 11
Training loss: 2.410330347237179
Validation loss: 2.4581174971233786

Epoch: 6| Step: 12
Training loss: 2.7107506063717977
Validation loss: 2.4602008665724573

Epoch: 6| Step: 13
Training loss: 2.1941979453579585
Validation loss: 2.4641534369634623

Epoch: 126| Step: 0
Training loss: 2.580102150839119
Validation loss: 2.459404038706589

Epoch: 6| Step: 1
Training loss: 2.5662460857794445
Validation loss: 2.4589188950566534

Epoch: 6| Step: 2
Training loss: 2.9881121020346897
Validation loss: 2.4629975431076105

Epoch: 6| Step: 3
Training loss: 2.3618738949387756
Validation loss: 2.4635173051743875

Epoch: 6| Step: 4
Training loss: 3.30630143527601
Validation loss: 2.4553663862970923

Epoch: 6| Step: 5
Training loss: 2.3769918421379432
Validation loss: 2.4634068770091893

Epoch: 6| Step: 6
Training loss: 2.1870332492416695
Validation loss: 2.4656032998049118

Epoch: 6| Step: 7
Training loss: 1.8240658289591594
Validation loss: 2.4597753374250155

Epoch: 6| Step: 8
Training loss: 2.375576150176644
Validation loss: 2.4590271978106193

Epoch: 6| Step: 9
Training loss: 2.280386565381677
Validation loss: 2.4643558718617578

Epoch: 6| Step: 10
Training loss: 3.0361524442011656
Validation loss: 2.457776820236458

Epoch: 6| Step: 11
Training loss: 2.3801562903882605
Validation loss: 2.460459651673819

Epoch: 6| Step: 12
Training loss: 2.5494687966956384
Validation loss: 2.4629027416506983

Epoch: 6| Step: 13
Training loss: 2.0998369244426884
Validation loss: 2.4645176272260745

Epoch: 127| Step: 0
Training loss: 2.330042618947048
Validation loss: 2.4579022293541968

Epoch: 6| Step: 1
Training loss: 3.444659181963117
Validation loss: 2.4659964903285454

Epoch: 6| Step: 2
Training loss: 2.1528818112192347
Validation loss: 2.4633101555487085

Epoch: 6| Step: 3
Training loss: 2.529079118582358
Validation loss: 2.4679989376478004

Epoch: 6| Step: 4
Training loss: 2.5063951711871755
Validation loss: 2.467774427781323

Epoch: 6| Step: 5
Training loss: 2.201490729456921
Validation loss: 2.467318638993939

Epoch: 6| Step: 6
Training loss: 2.3376477975069747
Validation loss: 2.4699658003587444

Epoch: 6| Step: 7
Training loss: 2.6976110415367334
Validation loss: 2.4641929367784257

Epoch: 6| Step: 8
Training loss: 2.4164926093549086
Validation loss: 2.4623900309889053

Epoch: 6| Step: 9
Training loss: 2.5669126896381935
Validation loss: 2.4621427299430656

Epoch: 6| Step: 10
Training loss: 3.0992573740739817
Validation loss: 2.4606817364871576

Epoch: 6| Step: 11
Training loss: 2.631230997121154
Validation loss: 2.458677370168443

Epoch: 6| Step: 12
Training loss: 2.0247056441002638
Validation loss: 2.463048959594184

Epoch: 6| Step: 13
Training loss: 2.150355034723361
Validation loss: 2.4605222886617386

Epoch: 128| Step: 0
Training loss: 1.8759770073162865
Validation loss: 2.4554859390166905

Epoch: 6| Step: 1
Training loss: 2.903659445327306
Validation loss: 2.461283938934483

Epoch: 6| Step: 2
Training loss: 2.4139669948808886
Validation loss: 2.4541452315149472

Epoch: 6| Step: 3
Training loss: 2.1071535068640013
Validation loss: 2.4569650306531674

Epoch: 6| Step: 4
Training loss: 2.3450422666274666
Validation loss: 2.459472284650847

Epoch: 6| Step: 5
Training loss: 2.949694704971866
Validation loss: 2.4668072166437516

Epoch: 6| Step: 6
Training loss: 2.678299613966681
Validation loss: 2.4633162854404405

Epoch: 6| Step: 7
Training loss: 2.6878558078590364
Validation loss: 2.46288876958218

Epoch: 6| Step: 8
Training loss: 2.68616656557699
Validation loss: 2.4708744678214662

Epoch: 6| Step: 9
Training loss: 2.3510301564049927
Validation loss: 2.468002189980457

Epoch: 6| Step: 10
Training loss: 2.920649143856343
Validation loss: 2.4751613275372204

Epoch: 6| Step: 11
Training loss: 2.777833447428339
Validation loss: 2.4692641258081593

Epoch: 6| Step: 12
Training loss: 2.267761485911255
Validation loss: 2.473303783896579

Epoch: 6| Step: 13
Training loss: 2.057126993920456
Validation loss: 2.4742002161470302

Epoch: 129| Step: 0
Training loss: 2.992624435195943
Validation loss: 2.4689128838094243

Epoch: 6| Step: 1
Training loss: 2.215586058539408
Validation loss: 2.469448650667861

Epoch: 6| Step: 2
Training loss: 2.6705424237133975
Validation loss: 2.4727148096302596

Epoch: 6| Step: 3
Training loss: 2.8266690547801074
Validation loss: 2.4665234822737423

Epoch: 6| Step: 4
Training loss: 2.695438636371425
Validation loss: 2.4679613262023397

Epoch: 6| Step: 5
Training loss: 2.0455250255887996
Validation loss: 2.4741894958648905

Epoch: 6| Step: 6
Training loss: 2.8530995028339423
Validation loss: 2.4755976067844214

Epoch: 6| Step: 7
Training loss: 3.0144670071639985
Validation loss: 2.4749778868589667

Epoch: 6| Step: 8
Training loss: 1.7010036170692269
Validation loss: 2.474757903874664

Epoch: 6| Step: 9
Training loss: 2.2469892491353805
Validation loss: 2.4676471935044755

Epoch: 6| Step: 10
Training loss: 2.6592620825636923
Validation loss: 2.4679349044631715

Epoch: 6| Step: 11
Training loss: 2.356072141375083
Validation loss: 2.465188205387196

Epoch: 6| Step: 12
Training loss: 2.579890530947459
Validation loss: 2.4648274513346577

Epoch: 6| Step: 13
Training loss: 2.3711956071421696
Validation loss: 2.4696922033375284

Epoch: 130| Step: 0
Training loss: 2.226831145560027
Validation loss: 2.464222825276589

Epoch: 6| Step: 1
Training loss: 2.997432881956815
Validation loss: 2.4618010282512217

Epoch: 6| Step: 2
Training loss: 2.187707945612908
Validation loss: 2.4621935994282143

Epoch: 6| Step: 3
Training loss: 2.5080752606454064
Validation loss: 2.459218873267305

Epoch: 6| Step: 4
Training loss: 2.137706242477197
Validation loss: 2.4632660844043426

Epoch: 6| Step: 5
Training loss: 2.864505188771957
Validation loss: 2.460797228170991

Epoch: 6| Step: 6
Training loss: 2.4855780417745303
Validation loss: 2.461809663779617

Epoch: 6| Step: 7
Training loss: 2.4903576868978896
Validation loss: 2.463291878702027

Epoch: 6| Step: 8
Training loss: 2.7298398146252434
Validation loss: 2.4633628398571705

Epoch: 6| Step: 9
Training loss: 2.350278079036097
Validation loss: 2.465694484207047

Epoch: 6| Step: 10
Training loss: 2.6473317046162457
Validation loss: 2.4630926474377817

Epoch: 6| Step: 11
Training loss: 2.375185909022069
Validation loss: 2.4684784816365264

Epoch: 6| Step: 12
Training loss: 2.4772667109246966
Validation loss: 2.4639672415153457

Epoch: 6| Step: 13
Training loss: 2.460044868494248
Validation loss: 2.465680407089716

Epoch: 131| Step: 0
Training loss: 2.5260954756101746
Validation loss: 2.467868695913248

Epoch: 6| Step: 1
Training loss: 2.216876138622851
Validation loss: 2.465286158754911

Epoch: 6| Step: 2
Training loss: 3.0059253668032104
Validation loss: 2.4643470033878527

Epoch: 6| Step: 3
Training loss: 2.7486064154163063
Validation loss: 2.4703998605721935

Epoch: 6| Step: 4
Training loss: 2.2432559986397784
Validation loss: 2.4746025504861415

Epoch: 6| Step: 5
Training loss: 2.8363383196432266
Validation loss: 2.4774374474264222

Epoch: 6| Step: 6
Training loss: 2.295568808416512
Validation loss: 2.463057026093355

Epoch: 6| Step: 7
Training loss: 2.699263973933739
Validation loss: 2.4674376931226125

Epoch: 6| Step: 8
Training loss: 2.8174339250129656
Validation loss: 2.464809459804445

Epoch: 6| Step: 9
Training loss: 1.9932780553282754
Validation loss: 2.4734604719376034

Epoch: 6| Step: 10
Training loss: 2.458484795855992
Validation loss: 2.4773214242362864

Epoch: 6| Step: 11
Training loss: 2.3881103654146982
Validation loss: 2.474879570481057

Epoch: 6| Step: 12
Training loss: 2.6175065031216787
Validation loss: 2.468925099661932

Epoch: 6| Step: 13
Training loss: 2.3605186267546925
Validation loss: 2.4655740324102324

Epoch: 132| Step: 0
Training loss: 2.417681798716736
Validation loss: 2.4674432893707987

Epoch: 6| Step: 1
Training loss: 2.3157276619870886
Validation loss: 2.464410484833103

Epoch: 6| Step: 2
Training loss: 2.7171598146771
Validation loss: 2.466595655355625

Epoch: 6| Step: 3
Training loss: 2.110357324256075
Validation loss: 2.4713947278075117

Epoch: 6| Step: 4
Training loss: 2.954852855136413
Validation loss: 2.4673375785266822

Epoch: 6| Step: 5
Training loss: 2.5611294128120785
Validation loss: 2.4741658869898764

Epoch: 6| Step: 6
Training loss: 2.2786145598672376
Validation loss: 2.4726666153484116

Epoch: 6| Step: 7
Training loss: 2.2622044491439235
Validation loss: 2.4716240936783356

Epoch: 6| Step: 8
Training loss: 2.602952190767605
Validation loss: 2.467424382858307

Epoch: 6| Step: 9
Training loss: 3.0266580309583615
Validation loss: 2.4682941820756072

Epoch: 6| Step: 10
Training loss: 3.0341177677138593
Validation loss: 2.4724079668320416

Epoch: 6| Step: 11
Training loss: 1.8635904947205917
Validation loss: 2.463828593690295

Epoch: 6| Step: 12
Training loss: 2.5572251714593235
Validation loss: 2.472696996014642

Epoch: 6| Step: 13
Training loss: 2.193723273046547
Validation loss: 2.4665464393424386

Epoch: 133| Step: 0
Training loss: 2.062871148209454
Validation loss: 2.4684575708441536

Epoch: 6| Step: 1
Training loss: 2.287057877635968
Validation loss: 2.477301502378819

Epoch: 6| Step: 2
Training loss: 2.5560882181396543
Validation loss: 2.474512529372409

Epoch: 6| Step: 3
Training loss: 2.193771744753454
Validation loss: 2.4897036875811467

Epoch: 6| Step: 4
Training loss: 1.6685629864887843
Validation loss: 2.506434504692933

Epoch: 6| Step: 5
Training loss: 2.7473929792392364
Validation loss: 2.5298320896232664

Epoch: 6| Step: 6
Training loss: 3.3122760049192266
Validation loss: 2.5083470869056907

Epoch: 6| Step: 7
Training loss: 2.2114766140968496
Validation loss: 2.485045240669684

Epoch: 6| Step: 8
Training loss: 2.950503846153567
Validation loss: 2.4769162187171507

Epoch: 6| Step: 9
Training loss: 2.8768215214086603
Validation loss: 2.4632959438199884

Epoch: 6| Step: 10
Training loss: 2.317785666100715
Validation loss: 2.466085339898255

Epoch: 6| Step: 11
Training loss: 2.8950404081011674
Validation loss: 2.463319060017999

Epoch: 6| Step: 12
Training loss: 2.9344635548904794
Validation loss: 2.4708054432144553

Epoch: 6| Step: 13
Training loss: 1.938013070376386
Validation loss: 2.4760648145116555

Epoch: 134| Step: 0
Training loss: 2.2362966743489885
Validation loss: 2.4802618626299098

Epoch: 6| Step: 1
Training loss: 2.613565882761549
Validation loss: 2.478745902977124

Epoch: 6| Step: 2
Training loss: 2.496731337901062
Validation loss: 2.484150906418649

Epoch: 6| Step: 3
Training loss: 2.8435175874077974
Validation loss: 2.481780466792866

Epoch: 6| Step: 4
Training loss: 2.9219973941402317
Validation loss: 2.480275832956901

Epoch: 6| Step: 5
Training loss: 2.0063513994588167
Validation loss: 2.484470997361193

Epoch: 6| Step: 6
Training loss: 2.5518923525812363
Validation loss: 2.480845217032946

Epoch: 6| Step: 7
Training loss: 2.224884364520062
Validation loss: 2.481283091237164

Epoch: 6| Step: 8
Training loss: 3.2184771079517063
Validation loss: 2.4863824790972644

Epoch: 6| Step: 9
Training loss: 2.7284978867365877
Validation loss: 2.4865856771430477

Epoch: 6| Step: 10
Training loss: 2.5248127782926177
Validation loss: 2.4834855844775503

Epoch: 6| Step: 11
Training loss: 1.8828233900586255
Validation loss: 2.484259276823791

Epoch: 6| Step: 12
Training loss: 3.260177083500786
Validation loss: 2.4806720480121958

Epoch: 6| Step: 13
Training loss: 2.374455640547581
Validation loss: 2.4782646098182632

Epoch: 135| Step: 0
Training loss: 2.055929874441394
Validation loss: 2.478647615822599

Epoch: 6| Step: 1
Training loss: 2.3390883816986183
Validation loss: 2.4786432712833197

Epoch: 6| Step: 2
Training loss: 2.222971057554144
Validation loss: 2.4814183617651713

Epoch: 6| Step: 3
Training loss: 2.5928529773875364
Validation loss: 2.478813568315833

Epoch: 6| Step: 4
Training loss: 2.9205797557889626
Validation loss: 2.4764480163234373

Epoch: 6| Step: 5
Training loss: 2.484280182570536
Validation loss: 2.475998662870187

Epoch: 6| Step: 6
Training loss: 2.602076757426284
Validation loss: 2.475397543977508

Epoch: 6| Step: 7
Training loss: 2.468406556782215
Validation loss: 2.476882609027524

Epoch: 6| Step: 8
Training loss: 1.7534518258531566
Validation loss: 2.475571764141092

Epoch: 6| Step: 9
Training loss: 2.54555285251577
Validation loss: 2.473762493747737

Epoch: 6| Step: 10
Training loss: 3.0889327952544763
Validation loss: 2.4809826816593508

Epoch: 6| Step: 11
Training loss: 2.6679667840059555
Validation loss: 2.474998710452171

Epoch: 6| Step: 12
Training loss: 3.2280794507900192
Validation loss: 2.4731100990682653

Epoch: 6| Step: 13
Training loss: 2.5177328625958353
Validation loss: 2.46856004652159

Epoch: 136| Step: 0
Training loss: 1.9894588558010369
Validation loss: 2.470425660808694

Epoch: 6| Step: 1
Training loss: 2.688356573529034
Validation loss: 2.4676706232034653

Epoch: 6| Step: 2
Training loss: 2.986708762122
Validation loss: 2.4652782446154897

Epoch: 6| Step: 3
Training loss: 2.460770083591085
Validation loss: 2.468154593990874

Epoch: 6| Step: 4
Training loss: 2.0212086070203794
Validation loss: 2.4648073559475776

Epoch: 6| Step: 5
Training loss: 2.851313666369142
Validation loss: 2.4657353855527515

Epoch: 6| Step: 6
Training loss: 2.3925910793654404
Validation loss: 2.461385441939965

Epoch: 6| Step: 7
Training loss: 2.7354441269258642
Validation loss: 2.4641619674935384

Epoch: 6| Step: 8
Training loss: 2.6762509567209145
Validation loss: 2.4694817339848583

Epoch: 6| Step: 9
Training loss: 2.6728026804079636
Validation loss: 2.46551315962916

Epoch: 6| Step: 10
Training loss: 2.469232053411293
Validation loss: 2.471620219105691

Epoch: 6| Step: 11
Training loss: 2.3470490697112245
Validation loss: 2.4667169593718676

Epoch: 6| Step: 12
Training loss: 2.0627896654575464
Validation loss: 2.4624828028199426

Epoch: 6| Step: 13
Training loss: 2.5423910536628456
Validation loss: 2.4598706874871965

Epoch: 137| Step: 0
Training loss: 2.571785640902341
Validation loss: 2.4687157962538206

Epoch: 6| Step: 1
Training loss: 2.1222801754258014
Validation loss: 2.4621066469926554

Epoch: 6| Step: 2
Training loss: 1.8532326163682458
Validation loss: 2.469013336880542

Epoch: 6| Step: 3
Training loss: 2.3962969345248277
Validation loss: 2.470094628471204

Epoch: 6| Step: 4
Training loss: 2.1857774764542492
Validation loss: 2.4659983272943857

Epoch: 6| Step: 5
Training loss: 2.9899951682163355
Validation loss: 2.466079039644299

Epoch: 6| Step: 6
Training loss: 2.483466312082427
Validation loss: 2.47250274937049

Epoch: 6| Step: 7
Training loss: 2.4850312331940523
Validation loss: 2.473285596966099

Epoch: 6| Step: 8
Training loss: 1.9426255263883867
Validation loss: 2.4737731757226094

Epoch: 6| Step: 9
Training loss: 3.080236030551271
Validation loss: 2.468075768836355

Epoch: 6| Step: 10
Training loss: 2.724222572790012
Validation loss: 2.47137686448013

Epoch: 6| Step: 11
Training loss: 2.570285136068483
Validation loss: 2.476290827309801

Epoch: 6| Step: 12
Training loss: 2.623654156770358
Validation loss: 2.473908664137845

Epoch: 6| Step: 13
Training loss: 2.762868078229613
Validation loss: 2.4802376867290565

Epoch: 138| Step: 0
Training loss: 2.556550446181027
Validation loss: 2.4671484987809364

Epoch: 6| Step: 1
Training loss: 3.034625032693544
Validation loss: 2.480366141532371

Epoch: 6| Step: 2
Training loss: 2.427917817259918
Validation loss: 2.4763518684098513

Epoch: 6| Step: 3
Training loss: 1.9646846638582127
Validation loss: 2.4831204555676964

Epoch: 6| Step: 4
Training loss: 2.222128002500547
Validation loss: 2.4762196107912784

Epoch: 6| Step: 5
Training loss: 2.715443321270078
Validation loss: 2.4802220419598733

Epoch: 6| Step: 6
Training loss: 2.9739806023525013
Validation loss: 2.4770357660507356

Epoch: 6| Step: 7
Training loss: 2.699155240892012
Validation loss: 2.474201219916388

Epoch: 6| Step: 8
Training loss: 2.1692609905066935
Validation loss: 2.4714131537507003

Epoch: 6| Step: 9
Training loss: 2.381747048233716
Validation loss: 2.46737265493041

Epoch: 6| Step: 10
Training loss: 2.542607388699413
Validation loss: 2.476302653739292

Epoch: 6| Step: 11
Training loss: 2.2718177085064712
Validation loss: 2.473601093934748

Epoch: 6| Step: 12
Training loss: 2.383909679519638
Validation loss: 2.4761538965716237

Epoch: 6| Step: 13
Training loss: 2.6953789301992512
Validation loss: 2.475128512786879

Epoch: 139| Step: 0
Training loss: 2.441776632061198
Validation loss: 2.4733571228860867

Epoch: 6| Step: 1
Training loss: 1.9357539276946347
Validation loss: 2.47279655616917

Epoch: 6| Step: 2
Training loss: 2.475745899818382
Validation loss: 2.46852524454582

Epoch: 6| Step: 3
Training loss: 2.2998916641926215
Validation loss: 2.466057915145928

Epoch: 6| Step: 4
Training loss: 3.1435524121904628
Validation loss: 2.4680800997772385

Epoch: 6| Step: 5
Training loss: 2.204539176553012
Validation loss: 2.469794233608534

Epoch: 6| Step: 6
Training loss: 2.847547573532831
Validation loss: 2.4679874578453

Epoch: 6| Step: 7
Training loss: 2.304227828397694
Validation loss: 2.465877519705619

Epoch: 6| Step: 8
Training loss: 2.8231637337497473
Validation loss: 2.46587158955554

Epoch: 6| Step: 9
Training loss: 2.617485735398038
Validation loss: 2.473060964494907

Epoch: 6| Step: 10
Training loss: 2.0986862069318546
Validation loss: 2.4819910859678718

Epoch: 6| Step: 11
Training loss: 2.7936909202114895
Validation loss: 2.4777114401215976

Epoch: 6| Step: 12
Training loss: 2.49329411443509
Validation loss: 2.474090417381036

Epoch: 6| Step: 13
Training loss: 2.2894170180621907
Validation loss: 2.474382550191991

Epoch: 140| Step: 0
Training loss: 2.9097554385267728
Validation loss: 2.4728382399178823

Epoch: 6| Step: 1
Training loss: 3.069169081528938
Validation loss: 2.4749609163839685

Epoch: 6| Step: 2
Training loss: 2.2096366155497877
Validation loss: 2.4785559861123647

Epoch: 6| Step: 3
Training loss: 2.625721786810895
Validation loss: 2.4800460895875247

Epoch: 6| Step: 4
Training loss: 2.8185145176135844
Validation loss: 2.4744179121425067

Epoch: 6| Step: 5
Training loss: 2.423158465516675
Validation loss: 2.475706191092277

Epoch: 6| Step: 6
Training loss: 1.9303999601031354
Validation loss: 2.4778770864748894

Epoch: 6| Step: 7
Training loss: 2.631127789121613
Validation loss: 2.473618611885972

Epoch: 6| Step: 8
Training loss: 3.0688805577616765
Validation loss: 2.473855754666477

Epoch: 6| Step: 9
Training loss: 2.374665387323382
Validation loss: 2.472058939690992

Epoch: 6| Step: 10
Training loss: 2.3536489361880917
Validation loss: 2.471177754404965

Epoch: 6| Step: 11
Training loss: 1.994293595592011
Validation loss: 2.471077284796766

Epoch: 6| Step: 12
Training loss: 2.0354724133242517
Validation loss: 2.469057876768629

Epoch: 6| Step: 13
Training loss: 2.1250692244081395
Validation loss: 2.4731783684753332

Epoch: 141| Step: 0
Training loss: 2.5928324719621076
Validation loss: 2.4651932506367995

Epoch: 6| Step: 1
Training loss: 2.235055566391399
Validation loss: 2.46915887915312

Epoch: 6| Step: 2
Training loss: 2.7268682707363197
Validation loss: 2.4695568778102004

Epoch: 6| Step: 3
Training loss: 2.307253685861798
Validation loss: 2.4743599388343163

Epoch: 6| Step: 4
Training loss: 2.4016223351514374
Validation loss: 2.469893645314724

Epoch: 6| Step: 5
Training loss: 1.879921177063886
Validation loss: 2.4643931513521036

Epoch: 6| Step: 6
Training loss: 3.0023325752886136
Validation loss: 2.470384861246005

Epoch: 6| Step: 7
Training loss: 2.4819519894833957
Validation loss: 2.4757838905539473

Epoch: 6| Step: 8
Training loss: 2.004588347530285
Validation loss: 2.4759523460401773

Epoch: 6| Step: 9
Training loss: 2.6117247092737874
Validation loss: 2.4747053176438203

Epoch: 6| Step: 10
Training loss: 2.549202165891648
Validation loss: 2.4722798218130886

Epoch: 6| Step: 11
Training loss: 2.6277937781304033
Validation loss: 2.473569415123791

Epoch: 6| Step: 12
Training loss: 2.776705683342096
Validation loss: 2.4722708371081805

Epoch: 6| Step: 13
Training loss: 2.4513412113134
Validation loss: 2.473397576208092

Epoch: 142| Step: 0
Training loss: 1.9349660608237853
Validation loss: 2.474678951851931

Epoch: 6| Step: 1
Training loss: 2.311149718449163
Validation loss: 2.4748385392771657

Epoch: 6| Step: 2
Training loss: 2.6937465375625766
Validation loss: 2.4746839456379757

Epoch: 6| Step: 3
Training loss: 2.6239956342149098
Validation loss: 2.4681122032433342

Epoch: 6| Step: 4
Training loss: 2.641890995436564
Validation loss: 2.4755272210636203

Epoch: 6| Step: 5
Training loss: 2.2320832991147554
Validation loss: 2.4753401474383314

Epoch: 6| Step: 6
Training loss: 2.519546390458385
Validation loss: 2.477038268590267

Epoch: 6| Step: 7
Training loss: 2.546612310611704
Validation loss: 2.478037814915274

Epoch: 6| Step: 8
Training loss: 2.628382547031082
Validation loss: 2.4727995129424247

Epoch: 6| Step: 9
Training loss: 2.4447999849788804
Validation loss: 2.4739892067572296

Epoch: 6| Step: 10
Training loss: 2.4463496826945104
Validation loss: 2.477694921386398

Epoch: 6| Step: 11
Training loss: 2.7990117781467267
Validation loss: 2.4757598153772693

Epoch: 6| Step: 12
Training loss: 2.895037937475747
Validation loss: 2.4793294057138833

Epoch: 6| Step: 13
Training loss: 1.8462590102051424
Validation loss: 2.478900243297232

Epoch: 143| Step: 0
Training loss: 2.794742815745028
Validation loss: 2.4707030606678186

Epoch: 6| Step: 1
Training loss: 2.6952511103176375
Validation loss: 2.4758043061203323

Epoch: 6| Step: 2
Training loss: 2.4006053558475466
Validation loss: 2.472143970875072

Epoch: 6| Step: 3
Training loss: 2.819786466535704
Validation loss: 2.4703496748016964

Epoch: 6| Step: 4
Training loss: 2.1056496961758313
Validation loss: 2.4728001717881574

Epoch: 6| Step: 5
Training loss: 3.2951765702539206
Validation loss: 2.47193463458929

Epoch: 6| Step: 6
Training loss: 1.9943915647310733
Validation loss: 2.4710084105847274

Epoch: 6| Step: 7
Training loss: 2.3694574029510247
Validation loss: 2.4741931415690477

Epoch: 6| Step: 8
Training loss: 2.224696826639303
Validation loss: 2.4690742923513067

Epoch: 6| Step: 9
Training loss: 2.888574811376359
Validation loss: 2.4734572428471435

Epoch: 6| Step: 10
Training loss: 2.4715072107443325
Validation loss: 2.471286235447836

Epoch: 6| Step: 11
Training loss: 2.434539170416044
Validation loss: 2.4771214124246104

Epoch: 6| Step: 12
Training loss: 1.928848702061659
Validation loss: 2.4754944031375454

Epoch: 6| Step: 13
Training loss: 2.0070881408967494
Validation loss: 2.477951125803438

Epoch: 144| Step: 0
Training loss: 1.668542981969066
Validation loss: 2.4830132277058654

Epoch: 6| Step: 1
Training loss: 2.3676600220687383
Validation loss: 2.4805361440719467

Epoch: 6| Step: 2
Training loss: 2.626580897623653
Validation loss: 2.4888770140305945

Epoch: 6| Step: 3
Training loss: 2.8034131228431356
Validation loss: 2.48184388657947

Epoch: 6| Step: 4
Training loss: 2.4804369346200272
Validation loss: 2.484543448761435

Epoch: 6| Step: 5
Training loss: 2.235971800556371
Validation loss: 2.4798087455979463

Epoch: 6| Step: 6
Training loss: 2.6725191823272714
Validation loss: 2.481742279646343

Epoch: 6| Step: 7
Training loss: 2.4841744203989293
Validation loss: 2.4834467595287273

Epoch: 6| Step: 8
Training loss: 2.3144963900228297
Validation loss: 2.4752969968214207

Epoch: 6| Step: 9
Training loss: 3.4229868297540853
Validation loss: 2.474661714381197

Epoch: 6| Step: 10
Training loss: 2.2007604585152287
Validation loss: 2.4715685146835944

Epoch: 6| Step: 11
Training loss: 2.335103680352983
Validation loss: 2.47963717080448

Epoch: 6| Step: 12
Training loss: 2.429884924027999
Validation loss: 2.4759854868954987

Epoch: 6| Step: 13
Training loss: 2.5378809600641348
Validation loss: 2.4745063790412365

Epoch: 145| Step: 0
Training loss: 2.3882474358448156
Validation loss: 2.47606897099683

Epoch: 6| Step: 1
Training loss: 2.1639264335960844
Validation loss: 2.4725292589020476

Epoch: 6| Step: 2
Training loss: 2.6113003691494248
Validation loss: 2.471675459326729

Epoch: 6| Step: 3
Training loss: 2.426530952518738
Validation loss: 2.4804783297776787

Epoch: 6| Step: 4
Training loss: 2.4661026292592836
Validation loss: 2.4781670572016026

Epoch: 6| Step: 5
Training loss: 2.607749204056035
Validation loss: 2.4831615019454243

Epoch: 6| Step: 6
Training loss: 2.695563705458572
Validation loss: 2.4745893991934143

Epoch: 6| Step: 7
Training loss: 2.725235143192851
Validation loss: 2.4857181461087103

Epoch: 6| Step: 8
Training loss: 2.48136921555397
Validation loss: 2.482680024441282

Epoch: 6| Step: 9
Training loss: 2.321452467659166
Validation loss: 2.4830137958232976

Epoch: 6| Step: 10
Training loss: 3.3126809412642992
Validation loss: 2.487172053714467

Epoch: 6| Step: 11
Training loss: 2.087989055429473
Validation loss: 2.475787638235392

Epoch: 6| Step: 12
Training loss: 2.372490209271857
Validation loss: 2.4811055164565445

Epoch: 6| Step: 13
Training loss: 1.8629368237785893
Validation loss: 2.4759261861171358

Epoch: 146| Step: 0
Training loss: 2.4796693009187627
Validation loss: 2.4896377546887694

Epoch: 6| Step: 1
Training loss: 2.9377928242928903
Validation loss: 2.4887347164990823

Epoch: 6| Step: 2
Training loss: 2.1735545737727535
Validation loss: 2.482936930754319

Epoch: 6| Step: 3
Training loss: 2.451148433497223
Validation loss: 2.490085572428171

Epoch: 6| Step: 4
Training loss: 2.1458102721916408
Validation loss: 2.485344335799087

Epoch: 6| Step: 5
Training loss: 2.567207385570664
Validation loss: 2.488061357220988

Epoch: 6| Step: 6
Training loss: 1.820197760768226
Validation loss: 2.4879708168816417

Epoch: 6| Step: 7
Training loss: 2.136033975338133
Validation loss: 2.482434440558981

Epoch: 6| Step: 8
Training loss: 2.6313187071467268
Validation loss: 2.4852264192922777

Epoch: 6| Step: 9
Training loss: 2.30187796342645
Validation loss: 2.483061085142537

Epoch: 6| Step: 10
Training loss: 2.7906631450032435
Validation loss: 2.4885599009273087

Epoch: 6| Step: 11
Training loss: 2.9461626601676314
Validation loss: 2.485562870258536

Epoch: 6| Step: 12
Training loss: 2.2004464823484544
Validation loss: 2.4834185664593362

Epoch: 6| Step: 13
Training loss: 2.7217818269428875
Validation loss: 2.4797394568983884

Epoch: 147| Step: 0
Training loss: 2.2937530268095663
Validation loss: 2.4850244852723598

Epoch: 6| Step: 1
Training loss: 2.5277950113941015
Validation loss: 2.478028738838893

Epoch: 6| Step: 2
Training loss: 2.3051980697695242
Validation loss: 2.475486465452031

Epoch: 6| Step: 3
Training loss: 2.3877704007876135
Validation loss: 2.4680382551642226

Epoch: 6| Step: 4
Training loss: 2.667724151345967
Validation loss: 2.4659281187757673

Epoch: 6| Step: 5
Training loss: 2.190844132242133
Validation loss: 2.4714526500849328

Epoch: 6| Step: 6
Training loss: 2.3369684400341346
Validation loss: 2.4689729646201943

Epoch: 6| Step: 7
Training loss: 2.3449144649563287
Validation loss: 2.470059445936095

Epoch: 6| Step: 8
Training loss: 2.939952232595599
Validation loss: 2.474765129376318

Epoch: 6| Step: 9
Training loss: 2.6492289483052103
Validation loss: 2.4735408604726414

Epoch: 6| Step: 10
Training loss: 3.0781962584946636
Validation loss: 2.4745417071060074

Epoch: 6| Step: 11
Training loss: 2.104658717671607
Validation loss: 2.468647427580852

Epoch: 6| Step: 12
Training loss: 2.5317073455951093
Validation loss: 2.4691227257310184

Epoch: 6| Step: 13
Training loss: 2.248081979220649
Validation loss: 2.475280847252749

Epoch: 148| Step: 0
Training loss: 2.4340092042609456
Validation loss: 2.4638147397682753

Epoch: 6| Step: 1
Training loss: 2.6871942745460053
Validation loss: 2.469975099116329

Epoch: 6| Step: 2
Training loss: 2.2202491531086963
Validation loss: 2.470082531012233

Epoch: 6| Step: 3
Training loss: 2.166699176935677
Validation loss: 2.4746172753548907

Epoch: 6| Step: 4
Training loss: 2.188276970344017
Validation loss: 2.4689950459223162

Epoch: 6| Step: 5
Training loss: 2.353793787050082
Validation loss: 2.459975943848342

Epoch: 6| Step: 6
Training loss: 2.533418644756932
Validation loss: 2.462498116532846

Epoch: 6| Step: 7
Training loss: 2.9844277262398924
Validation loss: 2.4679568179426674

Epoch: 6| Step: 8
Training loss: 2.3078928236778014
Validation loss: 2.4684935488875093

Epoch: 6| Step: 9
Training loss: 2.4680234588423176
Validation loss: 2.469162234562958

Epoch: 6| Step: 10
Training loss: 2.4861256890843326
Validation loss: 2.464425302847176

Epoch: 6| Step: 11
Training loss: 1.9214570125920105
Validation loss: 2.4637445980524393

Epoch: 6| Step: 12
Training loss: 2.4416624865534113
Validation loss: 2.4711411722340246

Epoch: 6| Step: 13
Training loss: 3.1732580617851696
Validation loss: 2.4733365264608054

Epoch: 149| Step: 0
Training loss: 2.786188177875019
Validation loss: 2.4749392575860196

Epoch: 6| Step: 1
Training loss: 1.9230940139451211
Validation loss: 2.4755968282987966

Epoch: 6| Step: 2
Training loss: 2.3095461563879445
Validation loss: 2.476591621492451

Epoch: 6| Step: 3
Training loss: 2.53558825557677
Validation loss: 2.47713922630586

Epoch: 6| Step: 4
Training loss: 2.5491552150336494
Validation loss: 2.4740316975741448

Epoch: 6| Step: 5
Training loss: 3.175544307639286
Validation loss: 2.4791153867744793

Epoch: 6| Step: 6
Training loss: 2.140567528168959
Validation loss: 2.484855829248831

Epoch: 6| Step: 7
Training loss: 2.0381729699613222
Validation loss: 2.4812160057218255

Epoch: 6| Step: 8
Training loss: 2.148431618422347
Validation loss: 2.47505393146106

Epoch: 6| Step: 9
Training loss: 2.2532441804769023
Validation loss: 2.480205724192249

Epoch: 6| Step: 10
Training loss: 2.8888541080956873
Validation loss: 2.4780434273133634

Epoch: 6| Step: 11
Training loss: 2.3923528074708837
Validation loss: 2.4880240810011878

Epoch: 6| Step: 12
Training loss: 2.660806495187875
Validation loss: 2.4817524949657486

Epoch: 6| Step: 13
Training loss: 2.647177967805962
Validation loss: 2.482603597204897

Epoch: 150| Step: 0
Training loss: 2.225303963461478
Validation loss: 2.4819594181830387

Epoch: 6| Step: 1
Training loss: 2.4150518963847225
Validation loss: 2.482723302821399

Epoch: 6| Step: 2
Training loss: 2.0688429889351707
Validation loss: 2.482223002553563

Epoch: 6| Step: 3
Training loss: 2.3547139389690206
Validation loss: 2.4819090018516574

Epoch: 6| Step: 4
Training loss: 2.776554301286828
Validation loss: 2.4807150170334293

Epoch: 6| Step: 5
Training loss: 2.302752183322785
Validation loss: 2.4779221004693563

Epoch: 6| Step: 6
Training loss: 2.6302126037764424
Validation loss: 2.482548087948601

Epoch: 6| Step: 7
Training loss: 2.747661289690964
Validation loss: 2.4784249123039728

Epoch: 6| Step: 8
Training loss: 1.9928023642332615
Validation loss: 2.479514816158886

Epoch: 6| Step: 9
Training loss: 2.5713918906577766
Validation loss: 2.472437924774863

Epoch: 6| Step: 10
Training loss: 2.4797502573457177
Validation loss: 2.4791547684156914

Epoch: 6| Step: 11
Training loss: 2.6465564450518912
Validation loss: 2.482991167045345

Epoch: 6| Step: 12
Training loss: 2.455991394562199
Validation loss: 2.4891197033583152

Epoch: 6| Step: 13
Training loss: 2.9114526920343566
Validation loss: 2.479357677335416

Epoch: 151| Step: 0
Training loss: 2.934858392421913
Validation loss: 2.4779047813235255

Epoch: 6| Step: 1
Training loss: 2.028832038165534
Validation loss: 2.479809947396884

Epoch: 6| Step: 2
Training loss: 2.657188608724952
Validation loss: 2.48251213752005

Epoch: 6| Step: 3
Training loss: 2.4715133846166717
Validation loss: 2.472916624031184

Epoch: 6| Step: 4
Training loss: 1.8710873788872482
Validation loss: 2.478545765634635

Epoch: 6| Step: 5
Training loss: 2.1140815502811177
Validation loss: 2.481130676859582

Epoch: 6| Step: 6
Training loss: 2.7133071612596265
Validation loss: 2.476827196161571

Epoch: 6| Step: 7
Training loss: 2.4541888026052536
Validation loss: 2.4727407303410334

Epoch: 6| Step: 8
Training loss: 3.0295997138680764
Validation loss: 2.471802928338455

Epoch: 6| Step: 9
Training loss: 2.0743870208934427
Validation loss: 2.47310616255405

Epoch: 6| Step: 10
Training loss: 2.452080376644075
Validation loss: 2.4682426575158325

Epoch: 6| Step: 11
Training loss: 2.501549621968238
Validation loss: 2.4776483315447573

Epoch: 6| Step: 12
Training loss: 2.52858669370303
Validation loss: 2.4803372566032507

Epoch: 6| Step: 13
Training loss: 2.445406683427334
Validation loss: 2.487732416026855

Epoch: 152| Step: 0
Training loss: 2.4789854886398515
Validation loss: 2.4916061951136514

Epoch: 6| Step: 1
Training loss: 2.655317075370087
Validation loss: 2.4915255920210413

Epoch: 6| Step: 2
Training loss: 3.079250071991454
Validation loss: 2.485803477352787

Epoch: 6| Step: 3
Training loss: 2.6683649575978237
Validation loss: 2.4876062105337975

Epoch: 6| Step: 4
Training loss: 2.4940268685515656
Validation loss: 2.487898912504351

Epoch: 6| Step: 5
Training loss: 2.5006876953320183
Validation loss: 2.484951728080753

Epoch: 6| Step: 6
Training loss: 2.3337218324486657
Validation loss: 2.485752291746393

Epoch: 6| Step: 7
Training loss: 2.216904853510092
Validation loss: 2.487432777352697

Epoch: 6| Step: 8
Training loss: 2.465226181517144
Validation loss: 2.4786607616146283

Epoch: 6| Step: 9
Training loss: 2.157671694681285
Validation loss: 2.477082046581177

Epoch: 6| Step: 10
Training loss: 2.5267057719094033
Validation loss: 2.4900251233315673

Epoch: 6| Step: 11
Training loss: 2.5345096086721424
Validation loss: 2.487654698416149

Epoch: 6| Step: 12
Training loss: 2.1723737624248445
Validation loss: 2.489071659088046

Epoch: 6| Step: 13
Training loss: 2.252250605419347
Validation loss: 2.4858617272728494

Epoch: 153| Step: 0
Training loss: 2.8078541000587616
Validation loss: 2.486160356565469

Epoch: 6| Step: 1
Training loss: 2.496135776983831
Validation loss: 2.483707714236007

Epoch: 6| Step: 2
Training loss: 2.4106129317195424
Validation loss: 2.4851895962184503

Epoch: 6| Step: 3
Training loss: 2.498678239457001
Validation loss: 2.4867639152219594

Epoch: 6| Step: 4
Training loss: 2.2934265199661685
Validation loss: 2.481104667628823

Epoch: 6| Step: 5
Training loss: 2.4836868196696384
Validation loss: 2.490265921598589

Epoch: 6| Step: 6
Training loss: 2.642710387084147
Validation loss: 2.486121941003588

Epoch: 6| Step: 7
Training loss: 2.342034284124102
Validation loss: 2.4813327035645196

Epoch: 6| Step: 8
Training loss: 2.759530545405173
Validation loss: 2.488597791849741

Epoch: 6| Step: 9
Training loss: 2.5557712507673256
Validation loss: 2.490723023186807

Epoch: 6| Step: 10
Training loss: 2.260203010083287
Validation loss: 2.501265650491652

Epoch: 6| Step: 11
Training loss: 2.30135878356057
Validation loss: 2.492322720772607

Epoch: 6| Step: 12
Training loss: 2.1577463900903076
Validation loss: 2.4946020501588255

Epoch: 6| Step: 13
Training loss: 2.2949981287198553
Validation loss: 2.4989818566060458

Epoch: 154| Step: 0
Training loss: 2.2705568501088926
Validation loss: 2.489915950587324

Epoch: 6| Step: 1
Training loss: 2.3703563869690814
Validation loss: 2.48086547882846

Epoch: 6| Step: 2
Training loss: 2.0079009634040994
Validation loss: 2.4814863705731884

Epoch: 6| Step: 3
Training loss: 2.068692937795803
Validation loss: 2.478591881699427

Epoch: 6| Step: 4
Training loss: 3.0209616447471164
Validation loss: 2.4728799390328464

Epoch: 6| Step: 5
Training loss: 2.1190545552437685
Validation loss: 2.478475094887947

Epoch: 6| Step: 6
Training loss: 2.0963686608865846
Validation loss: 2.4726225984763324

Epoch: 6| Step: 7
Training loss: 2.7332948131483175
Validation loss: 2.4749177190159575

Epoch: 6| Step: 8
Training loss: 2.6415173529495957
Validation loss: 2.4750530725305375

Epoch: 6| Step: 9
Training loss: 2.2467373398589356
Validation loss: 2.4771267942995827

Epoch: 6| Step: 10
Training loss: 2.669922946575315
Validation loss: 2.4808503745965953

Epoch: 6| Step: 11
Training loss: 2.4748774912405604
Validation loss: 2.4771934531855626

Epoch: 6| Step: 12
Training loss: 2.490295840234089
Validation loss: 2.480426425522683

Epoch: 6| Step: 13
Training loss: 2.8975874896002183
Validation loss: 2.4750510656823614

Epoch: 155| Step: 0
Training loss: 2.8200125495144426
Validation loss: 2.4746420360598664

Epoch: 6| Step: 1
Training loss: 2.713758073159557
Validation loss: 2.4782588696489913

Epoch: 6| Step: 2
Training loss: 2.2663745561005664
Validation loss: 2.483080424694332

Epoch: 6| Step: 3
Training loss: 2.389155316343069
Validation loss: 2.479758253492292

Epoch: 6| Step: 4
Training loss: 2.079275630116434
Validation loss: 2.4812936847854483

Epoch: 6| Step: 5
Training loss: 3.1054116297812855
Validation loss: 2.4901967642942044

Epoch: 6| Step: 6
Training loss: 2.3948191832136483
Validation loss: 2.4933650026333103

Epoch: 6| Step: 7
Training loss: 1.7971132866798167
Validation loss: 2.487685798530389

Epoch: 6| Step: 8
Training loss: 2.084891296224226
Validation loss: 2.497480911433957

Epoch: 6| Step: 9
Training loss: 2.0621781531554353
Validation loss: 2.4947937558562914

Epoch: 6| Step: 10
Training loss: 2.9121319714289315
Validation loss: 2.495470616939038

Epoch: 6| Step: 11
Training loss: 2.228036064951839
Validation loss: 2.495408403356704

Epoch: 6| Step: 12
Training loss: 2.8755953628415627
Validation loss: 2.487544215590513

Epoch: 6| Step: 13
Training loss: 2.3544424677519427
Validation loss: 2.4908236256479706

Epoch: 156| Step: 0
Training loss: 2.1606382966894513
Validation loss: 2.4860072981496346

Epoch: 6| Step: 1
Training loss: 2.245004831151713
Validation loss: 2.481942127209861

Epoch: 6| Step: 2
Training loss: 1.9414200657558272
Validation loss: 2.485583844974814

Epoch: 6| Step: 3
Training loss: 2.0475359133597153
Validation loss: 2.487429015266585

Epoch: 6| Step: 4
Training loss: 2.410195027291376
Validation loss: 2.486559229576111

Epoch: 6| Step: 5
Training loss: 3.0133372112969394
Validation loss: 2.495930602184855

Epoch: 6| Step: 6
Training loss: 2.2907009054932805
Validation loss: 2.502741010393238

Epoch: 6| Step: 7
Training loss: 2.355515310355536
Validation loss: 2.4945983864940837

Epoch: 6| Step: 8
Training loss: 2.985463528066788
Validation loss: 2.498183035203046

Epoch: 6| Step: 9
Training loss: 2.6273272053007366
Validation loss: 2.4932657777164695

Epoch: 6| Step: 10
Training loss: 3.05938422072115
Validation loss: 2.4902614218047137

Epoch: 6| Step: 11
Training loss: 2.6571518208605966
Validation loss: 2.48246981586752

Epoch: 6| Step: 12
Training loss: 2.2372995723697526
Validation loss: 2.481275452323941

Epoch: 6| Step: 13
Training loss: 1.900515953079304
Validation loss: 2.477880141422716

Epoch: 157| Step: 0
Training loss: 2.581348138379892
Validation loss: 2.475006176077076

Epoch: 6| Step: 1
Training loss: 2.3087597059573555
Validation loss: 2.479941228406041

Epoch: 6| Step: 2
Training loss: 2.2513475621257375
Validation loss: 2.481601790721714

Epoch: 6| Step: 3
Training loss: 2.584553789183845
Validation loss: 2.47990616954171

Epoch: 6| Step: 4
Training loss: 2.5618561656936154
Validation loss: 2.478984318499858

Epoch: 6| Step: 5
Training loss: 2.7905841170815933
Validation loss: 2.483687915598812

Epoch: 6| Step: 6
Training loss: 2.2039222086558863
Validation loss: 2.4880272273018167

Epoch: 6| Step: 7
Training loss: 2.310879732535778
Validation loss: 2.486804086537445

Epoch: 6| Step: 8
Training loss: 2.2695346116584396
Validation loss: 2.4861201428818225

Epoch: 6| Step: 9
Training loss: 3.015018224202459
Validation loss: 2.4879433139423215

Epoch: 6| Step: 10
Training loss: 3.1547473314193732
Validation loss: 2.500212104064914

Epoch: 6| Step: 11
Training loss: 2.046434194841935
Validation loss: 2.493893827467126

Epoch: 6| Step: 12
Training loss: 1.6405863439456387
Validation loss: 2.492823393084862

Epoch: 6| Step: 13
Training loss: 2.570423807905244
Validation loss: 2.490077362097133

Epoch: 158| Step: 0
Training loss: 2.524424073662451
Validation loss: 2.491962131686042

Epoch: 6| Step: 1
Training loss: 2.3858798936286147
Validation loss: 2.4946311362801574

Epoch: 6| Step: 2
Training loss: 2.368925860074516
Validation loss: 2.4833420179415757

Epoch: 6| Step: 3
Training loss: 1.9834799963421064
Validation loss: 2.4928914573687413

Epoch: 6| Step: 4
Training loss: 2.0324209506157205
Validation loss: 2.4876373432013508

Epoch: 6| Step: 5
Training loss: 2.8846436347556232
Validation loss: 2.490597639328449

Epoch: 6| Step: 6
Training loss: 2.854238931525331
Validation loss: 2.48832947720712

Epoch: 6| Step: 7
Training loss: 2.7335788112601778
Validation loss: 2.480288072949362

Epoch: 6| Step: 8
Training loss: 2.077075205499733
Validation loss: 2.487431387538108

Epoch: 6| Step: 9
Training loss: 2.937930298800976
Validation loss: 2.4914079680685597

Epoch: 6| Step: 10
Training loss: 1.9984845141740666
Validation loss: 2.481867910743412

Epoch: 6| Step: 11
Training loss: 2.1361592064006683
Validation loss: 2.4839641143297286

Epoch: 6| Step: 12
Training loss: 2.5320133894796832
Validation loss: 2.4886841340532224

Epoch: 6| Step: 13
Training loss: 2.64344411392548
Validation loss: 2.4862928205702035

Epoch: 159| Step: 0
Training loss: 2.8969561552101477
Validation loss: 2.487303393468082

Epoch: 6| Step: 1
Training loss: 2.54075439423918
Validation loss: 2.485839108434711

Epoch: 6| Step: 2
Training loss: 2.270140469275886
Validation loss: 2.4867021869120207

Epoch: 6| Step: 3
Training loss: 2.093156417287405
Validation loss: 2.4907912724928654

Epoch: 6| Step: 4
Training loss: 2.422940321391633
Validation loss: 2.481611974594736

Epoch: 6| Step: 5
Training loss: 2.3405996894231893
Validation loss: 2.492228333269234

Epoch: 6| Step: 6
Training loss: 2.184835173197124
Validation loss: 2.4810676392387823

Epoch: 6| Step: 7
Training loss: 2.7090630550826194
Validation loss: 2.4874083196975016

Epoch: 6| Step: 8
Training loss: 2.3655515752607266
Validation loss: 2.48477192073177

Epoch: 6| Step: 9
Training loss: 2.428060397708812
Validation loss: 2.4860244329770467

Epoch: 6| Step: 10
Training loss: 2.523778083422069
Validation loss: 2.487271345993693

Epoch: 6| Step: 11
Training loss: 2.3222393422608576
Validation loss: 2.4867925497344228

Epoch: 6| Step: 12
Training loss: 2.269349292808085
Validation loss: 2.4869871981559344

Epoch: 6| Step: 13
Training loss: 2.7068429416263378
Validation loss: 2.4871332144170135

Epoch: 160| Step: 0
Training loss: 2.746125960398531
Validation loss: 2.48557014428461

Epoch: 6| Step: 1
Training loss: 2.679546563804715
Validation loss: 2.486027437953264

Epoch: 6| Step: 2
Training loss: 2.1864123228871097
Validation loss: 2.4889812193596628

Epoch: 6| Step: 3
Training loss: 2.032502125906683
Validation loss: 2.4856210298980503

Epoch: 6| Step: 4
Training loss: 3.2250507498599714
Validation loss: 2.4830360243159872

Epoch: 6| Step: 5
Training loss: 2.6081343573908136
Validation loss: 2.4759646876502432

Epoch: 6| Step: 6
Training loss: 2.1329974978075046
Validation loss: 2.4804620537454727

Epoch: 6| Step: 7
Training loss: 2.61504811769639
Validation loss: 2.478424864205162

Epoch: 6| Step: 8
Training loss: 1.9111243293117803
Validation loss: 2.4799404993533507

Epoch: 6| Step: 9
Training loss: 2.1837818699363374
Validation loss: 2.483220469920432

Epoch: 6| Step: 10
Training loss: 2.612467868735105
Validation loss: 2.4797959904693245

Epoch: 6| Step: 11
Training loss: 3.0718151812390064
Validation loss: 2.4834486315884052

Epoch: 6| Step: 12
Training loss: 2.141818194341505
Validation loss: 2.4828084409091193

Epoch: 6| Step: 13
Training loss: 1.5759960960494743
Validation loss: 2.49012545079386

Epoch: 161| Step: 0
Training loss: 2.4135819731535104
Validation loss: 2.4945223722012186

Epoch: 6| Step: 1
Training loss: 2.9711833417746965
Validation loss: 2.4923559628174794

Epoch: 6| Step: 2
Training loss: 3.0049172474769703
Validation loss: 2.4874981936091984

Epoch: 6| Step: 3
Training loss: 2.117257993305796
Validation loss: 2.497742571476103

Epoch: 6| Step: 4
Training loss: 2.328959884972901
Validation loss: 2.5033645242237026

Epoch: 6| Step: 5
Training loss: 2.5496215988340722
Validation loss: 2.494188977885313

Epoch: 6| Step: 6
Training loss: 2.206378347321588
Validation loss: 2.4962207998657355

Epoch: 6| Step: 7
Training loss: 2.9040167647158954
Validation loss: 2.483665988923904

Epoch: 6| Step: 8
Training loss: 2.0959649966716882
Validation loss: 2.478619528482106

Epoch: 6| Step: 9
Training loss: 1.9785396051036288
Validation loss: 2.485314501452966

Epoch: 6| Step: 10
Training loss: 2.133075628013845
Validation loss: 2.495261963627356

Epoch: 6| Step: 11
Training loss: 2.0292409498128756
Validation loss: 2.4926633629659243

Epoch: 6| Step: 12
Training loss: 2.7843805760457285
Validation loss: 2.4861007710341863

Epoch: 6| Step: 13
Training loss: 2.4596877058026907
Validation loss: 2.4840377082824094

Epoch: 162| Step: 0
Training loss: 2.8436373174790375
Validation loss: 2.489243174235884

Epoch: 6| Step: 1
Training loss: 2.5496051407818756
Validation loss: 2.4898257649600724

Epoch: 6| Step: 2
Training loss: 2.2545963599381458
Validation loss: 2.487637710593255

Epoch: 6| Step: 3
Training loss: 3.0641647796445226
Validation loss: 2.485430063583025

Epoch: 6| Step: 4
Training loss: 2.9107419647050845
Validation loss: 2.489434007664726

Epoch: 6| Step: 5
Training loss: 2.1436708040873222
Validation loss: 2.4906737414943

Epoch: 6| Step: 6
Training loss: 2.5588172873188095
Validation loss: 2.489369025376876

Epoch: 6| Step: 7
Training loss: 2.495516762587163
Validation loss: 2.49323383875666

Epoch: 6| Step: 8
Training loss: 2.1445915060836898
Validation loss: 2.4971591782971796

Epoch: 6| Step: 9
Training loss: 1.793199711303892
Validation loss: 2.4950391345372758

Epoch: 6| Step: 10
Training loss: 2.002178793492744
Validation loss: 2.49794440000875

Epoch: 6| Step: 11
Training loss: 2.6146872349088452
Validation loss: 2.4966683917767516

Epoch: 6| Step: 12
Training loss: 2.465325986960926
Validation loss: 2.4982089779701124

Epoch: 6| Step: 13
Training loss: 1.9513483129998757
Validation loss: 2.5035293144621207

Epoch: 163| Step: 0
Training loss: 2.6076009053120606
Validation loss: 2.4941640448012135

Epoch: 6| Step: 1
Training loss: 2.7160568052034177
Validation loss: 2.491906496028643

Epoch: 6| Step: 2
Training loss: 2.3375952716526305
Validation loss: 2.488440404220637

Epoch: 6| Step: 3
Training loss: 2.3572816973003556
Validation loss: 2.4847285101152177

Epoch: 6| Step: 4
Training loss: 2.7713871643782237
Validation loss: 2.4846357612594967

Epoch: 6| Step: 5
Training loss: 2.418154116228737
Validation loss: 2.479756090208689

Epoch: 6| Step: 6
Training loss: 1.939492093681079
Validation loss: 2.479710460509268

Epoch: 6| Step: 7
Training loss: 2.729365353716835
Validation loss: 2.4810340817829606

Epoch: 6| Step: 8
Training loss: 2.7471919895621872
Validation loss: 2.4742992500850325

Epoch: 6| Step: 9
Training loss: 2.0752514928057115
Validation loss: 2.4801200241096115

Epoch: 6| Step: 10
Training loss: 2.831537874588559
Validation loss: 2.4784338266007726

Epoch: 6| Step: 11
Training loss: 1.89128492203344
Validation loss: 2.4754145756688963

Epoch: 6| Step: 12
Training loss: 2.051973472275022
Validation loss: 2.48211158956219

Epoch: 6| Step: 13
Training loss: 2.5856745375880266
Validation loss: 2.476087041194902

Epoch: 164| Step: 0
Training loss: 2.532220348346116
Validation loss: 2.4837019306504295

Epoch: 6| Step: 1
Training loss: 2.7768477843412884
Validation loss: 2.4829942557096514

Epoch: 6| Step: 2
Training loss: 2.1040568810958318
Validation loss: 2.4862732662712466

Epoch: 6| Step: 3
Training loss: 2.317568096818804
Validation loss: 2.4838854949270255

Epoch: 6| Step: 4
Training loss: 2.29725031478702
Validation loss: 2.488360121758027

Epoch: 6| Step: 5
Training loss: 2.0099429690872213
Validation loss: 2.4862021359119204

Epoch: 6| Step: 6
Training loss: 2.9025180605146574
Validation loss: 2.4869031538339965

Epoch: 6| Step: 7
Training loss: 2.6377941961865687
Validation loss: 2.491850045854768

Epoch: 6| Step: 8
Training loss: 2.3313422790754235
Validation loss: 2.4891861847541272

Epoch: 6| Step: 9
Training loss: 2.487961202067501
Validation loss: 2.4822021034935267

Epoch: 6| Step: 10
Training loss: 2.556914405938704
Validation loss: 2.486904384161095

Epoch: 6| Step: 11
Training loss: 2.537698702243657
Validation loss: 2.4880339191665737

Epoch: 6| Step: 12
Training loss: 2.2729963680830747
Validation loss: 2.4739634195911258

Epoch: 6| Step: 13
Training loss: 2.170208408174687
Validation loss: 2.485674760010428

Epoch: 165| Step: 0
Training loss: 2.4279761466373877
Validation loss: 2.487089293806113

Epoch: 6| Step: 1
Training loss: 1.9806429995112853
Validation loss: 2.480851351649371

Epoch: 6| Step: 2
Training loss: 2.8225038421307374
Validation loss: 2.4858426091729444

Epoch: 6| Step: 3
Training loss: 2.56235643310311
Validation loss: 2.481433190310275

Epoch: 6| Step: 4
Training loss: 2.7552396968409734
Validation loss: 2.4898336489516124

Epoch: 6| Step: 5
Training loss: 2.7443039597742835
Validation loss: 2.480909701824796

Epoch: 6| Step: 6
Training loss: 2.5647576783884554
Validation loss: 2.4810387144285526

Epoch: 6| Step: 7
Training loss: 2.1459260445229726
Validation loss: 2.4868579828319723

Epoch: 6| Step: 8
Training loss: 2.389354193514777
Validation loss: 2.480019355975264

Epoch: 6| Step: 9
Training loss: 1.9841489888439376
Validation loss: 2.4951910656208396

Epoch: 6| Step: 10
Training loss: 2.454236015890056
Validation loss: 2.491244928099935

Epoch: 6| Step: 11
Training loss: 2.6839292891180264
Validation loss: 2.490326524413297

Epoch: 6| Step: 12
Training loss: 2.0630545593088563
Validation loss: 2.483871608893393

Epoch: 6| Step: 13
Training loss: 2.2423097796442364
Validation loss: 2.4888658300984465

Epoch: 166| Step: 0
Training loss: 2.023928785149309
Validation loss: 2.501201904980859

Epoch: 6| Step: 1
Training loss: 2.2126715771370735
Validation loss: 2.49364133261859

Epoch: 6| Step: 2
Training loss: 1.9885895195930463
Validation loss: 2.492847223765704

Epoch: 6| Step: 3
Training loss: 2.360034370495361
Validation loss: 2.505637734161063

Epoch: 6| Step: 4
Training loss: 3.0642551919825145
Validation loss: 2.5094041220121994

Epoch: 6| Step: 5
Training loss: 2.3019261256145613
Validation loss: 2.5011809023657916

Epoch: 6| Step: 6
Training loss: 3.5226129552465317
Validation loss: 2.492063130590914

Epoch: 6| Step: 7
Training loss: 2.7606648075687374
Validation loss: 2.4850818899926583

Epoch: 6| Step: 8
Training loss: 1.8242616178715851
Validation loss: 2.4816519250767097

Epoch: 6| Step: 9
Training loss: 2.503326110761698
Validation loss: 2.470757235812784

Epoch: 6| Step: 10
Training loss: 2.2911051206677957
Validation loss: 2.476504456554901

Epoch: 6| Step: 11
Training loss: 2.2343291164568777
Validation loss: 2.4812088870879117

Epoch: 6| Step: 12
Training loss: 2.3244361070568913
Validation loss: 2.4745713020011246

Epoch: 6| Step: 13
Training loss: 2.3080528387239214
Validation loss: 2.486702794135579

Epoch: 167| Step: 0
Training loss: 2.5793047430971923
Validation loss: 2.4734891319388286

Epoch: 6| Step: 1
Training loss: 3.2214714322940865
Validation loss: 2.4751457068712797

Epoch: 6| Step: 2
Training loss: 2.3312985085357214
Validation loss: 2.473714930289149

Epoch: 6| Step: 3
Training loss: 2.5704970829785188
Validation loss: 2.472935456416394

Epoch: 6| Step: 4
Training loss: 2.585939989348075
Validation loss: 2.4824187856235285

Epoch: 6| Step: 5
Training loss: 1.762978046598623
Validation loss: 2.4803624568402194

Epoch: 6| Step: 6
Training loss: 1.7828386149386892
Validation loss: 2.4748319883508816

Epoch: 6| Step: 7
Training loss: 2.4074256303972414
Validation loss: 2.487669961001536

Epoch: 6| Step: 8
Training loss: 1.597414105632875
Validation loss: 2.48862854486707

Epoch: 6| Step: 9
Training loss: 2.3848462040415
Validation loss: 2.4834797363734578

Epoch: 6| Step: 10
Training loss: 2.6932766952161877
Validation loss: 2.504104487387146

Epoch: 6| Step: 11
Training loss: 2.9143072848763896
Validation loss: 2.49999457199779

Epoch: 6| Step: 12
Training loss: 2.3296761689655696
Validation loss: 2.4944037983416423

Epoch: 6| Step: 13
Training loss: 2.420473936347608
Validation loss: 2.482614513239019

Epoch: 168| Step: 0
Training loss: 3.0055671534977506
Validation loss: 2.4952981762523705

Epoch: 6| Step: 1
Training loss: 1.9871423003564301
Validation loss: 2.495623238264609

Epoch: 6| Step: 2
Training loss: 2.236654545978085
Validation loss: 2.494095354060175

Epoch: 6| Step: 3
Training loss: 2.32357291857619
Validation loss: 2.4845873983826414

Epoch: 6| Step: 4
Training loss: 2.3250201726879194
Validation loss: 2.4889356390454673

Epoch: 6| Step: 5
Training loss: 2.3693156228842764
Validation loss: 2.4872950780987693

Epoch: 6| Step: 6
Training loss: 2.519478257679151
Validation loss: 2.4986691588389704

Epoch: 6| Step: 7
Training loss: 2.4042083203317657
Validation loss: 2.50209237593881

Epoch: 6| Step: 8
Training loss: 3.145634844920129
Validation loss: 2.5074790344680276

Epoch: 6| Step: 9
Training loss: 2.428713489833299
Validation loss: 2.496203957892217

Epoch: 6| Step: 10
Training loss: 2.0651418931809378
Validation loss: 2.493409227050842

Epoch: 6| Step: 11
Training loss: 2.3912995826538013
Validation loss: 2.4961840355055664

Epoch: 6| Step: 12
Training loss: 2.3034391481390792
Validation loss: 2.4947391390331033

Epoch: 6| Step: 13
Training loss: 2.2074014268858586
Validation loss: 2.499193903982475

Epoch: 169| Step: 0
Training loss: 2.721914357230389
Validation loss: 2.4961010410956534

Epoch: 6| Step: 1
Training loss: 2.063052479123159
Validation loss: 2.4877276081637323

Epoch: 6| Step: 2
Training loss: 1.915899399587144
Validation loss: 2.4999154394471814

Epoch: 6| Step: 3
Training loss: 1.9607190014208968
Validation loss: 2.5018782871239673

Epoch: 6| Step: 4
Training loss: 2.572102488657519
Validation loss: 2.5021761085870615

Epoch: 6| Step: 5
Training loss: 3.0162577385295273
Validation loss: 2.5030656614663913

Epoch: 6| Step: 6
Training loss: 2.135245922674733
Validation loss: 2.492686127115936

Epoch: 6| Step: 7
Training loss: 2.4017430492628926
Validation loss: 2.4919672502954784

Epoch: 6| Step: 8
Training loss: 2.4017848411392353
Validation loss: 2.4900181655272235

Epoch: 6| Step: 9
Training loss: 2.0640187307217595
Validation loss: 2.500954684124946

Epoch: 6| Step: 10
Training loss: 2.5376130177552407
Validation loss: 2.4983541793241963

Epoch: 6| Step: 11
Training loss: 2.9458743907723726
Validation loss: 2.5053806100299196

Epoch: 6| Step: 12
Training loss: 2.3409165612056957
Validation loss: 2.49782251260654

Epoch: 6| Step: 13
Training loss: 2.579679263383088
Validation loss: 2.497967322829885

Epoch: 170| Step: 0
Training loss: 2.8757562057453363
Validation loss: 2.496873617350896

Epoch: 6| Step: 1
Training loss: 2.8107223827074397
Validation loss: 2.4970025530888518

Epoch: 6| Step: 2
Training loss: 2.1580897789099156
Validation loss: 2.5110072843313556

Epoch: 6| Step: 3
Training loss: 2.554453614520685
Validation loss: 2.5057032856899393

Epoch: 6| Step: 4
Training loss: 2.490885618734609
Validation loss: 2.512150578533394

Epoch: 6| Step: 5
Training loss: 2.254503934476511
Validation loss: 2.5023908467961578

Epoch: 6| Step: 6
Training loss: 2.07244739939681
Validation loss: 2.493187427722558

Epoch: 6| Step: 7
Training loss: 2.6971600820566337
Validation loss: 2.499111669388304

Epoch: 6| Step: 8
Training loss: 2.2965292118871523
Validation loss: 2.4901107697571208

Epoch: 6| Step: 9
Training loss: 2.273411806361199
Validation loss: 2.503607610626729

Epoch: 6| Step: 10
Training loss: 2.532154910496823
Validation loss: 2.5046203356784766

Epoch: 6| Step: 11
Training loss: 2.41874226413643
Validation loss: 2.511575191463047

Epoch: 6| Step: 12
Training loss: 2.1824201183404197
Validation loss: 2.514414920766538

Epoch: 6| Step: 13
Training loss: 2.1937919590950368
Validation loss: 2.5038212182994988

Epoch: 171| Step: 0
Training loss: 2.0215717683781027
Validation loss: 2.5076205614898552

Epoch: 6| Step: 1
Training loss: 2.50970530159144
Validation loss: 2.5075099520931095

Epoch: 6| Step: 2
Training loss: 1.9106326143052526
Validation loss: 2.5107954354205657

Epoch: 6| Step: 3
Training loss: 1.8280668330923904
Validation loss: 2.4944292945467836

Epoch: 6| Step: 4
Training loss: 2.6380395816439277
Validation loss: 2.499129716074889

Epoch: 6| Step: 5
Training loss: 2.4319606340635462
Validation loss: 2.5101978053588936

Epoch: 6| Step: 6
Training loss: 1.9180093982374786
Validation loss: 2.503326221875868

Epoch: 6| Step: 7
Training loss: 2.879917086361412
Validation loss: 2.498869696048656

Epoch: 6| Step: 8
Training loss: 2.899692315188995
Validation loss: 2.494142903262427

Epoch: 6| Step: 9
Training loss: 2.2249201556677667
Validation loss: 2.4909777520323413

Epoch: 6| Step: 10
Training loss: 2.2358364847478316
Validation loss: 2.495924807120984

Epoch: 6| Step: 11
Training loss: 2.3929264733655304
Validation loss: 2.486676028219538

Epoch: 6| Step: 12
Training loss: 2.747610007280093
Validation loss: 2.4944560011638712

Epoch: 6| Step: 13
Training loss: 2.7976124393342574
Validation loss: 2.503744896794497

Epoch: 172| Step: 0
Training loss: 2.5409019028404853
Validation loss: 2.4986979511228515

Epoch: 6| Step: 1
Training loss: 2.4107322066513897
Validation loss: 2.5131591969613956

Epoch: 6| Step: 2
Training loss: 2.3281028797711727
Validation loss: 2.5048938297378935

Epoch: 6| Step: 3
Training loss: 2.337587112190705
Validation loss: 2.5009533812672347

Epoch: 6| Step: 4
Training loss: 2.5258512969234594
Validation loss: 2.491249075208493

Epoch: 6| Step: 5
Training loss: 2.9852525309670237
Validation loss: 2.4941948566400765

Epoch: 6| Step: 6
Training loss: 2.1421628008753446
Validation loss: 2.502961502736246

Epoch: 6| Step: 7
Training loss: 2.071865665190368
Validation loss: 2.502599016886218

Epoch: 6| Step: 8
Training loss: 2.1578142324961367
Validation loss: 2.505088856175078

Epoch: 6| Step: 9
Training loss: 2.0199935059395826
Validation loss: 2.5101556813769426

Epoch: 6| Step: 10
Training loss: 2.8538137250177367
Validation loss: 2.5175357614784897

Epoch: 6| Step: 11
Training loss: 2.2393935603682964
Validation loss: 2.5082434088935535

Epoch: 6| Step: 12
Training loss: 2.832658537748504
Validation loss: 2.5171179122667153

Epoch: 6| Step: 13
Training loss: 2.0485767541220654
Validation loss: 2.520572401892024

Epoch: 173| Step: 0
Training loss: 2.773462773597432
Validation loss: 2.521794968555897

Epoch: 6| Step: 1
Training loss: 2.286538877929523
Validation loss: 2.518772959387602

Epoch: 6| Step: 2
Training loss: 2.2286462503141466
Validation loss: 2.513882936174383

Epoch: 6| Step: 3
Training loss: 1.9992551608718445
Validation loss: 2.513215769320982

Epoch: 6| Step: 4
Training loss: 2.695424837729141
Validation loss: 2.528824040071776

Epoch: 6| Step: 5
Training loss: 2.2931228403958257
Validation loss: 2.5262204818095815

Epoch: 6| Step: 6
Training loss: 2.193490898285611
Validation loss: 2.519768140435172

Epoch: 6| Step: 7
Training loss: 2.2265611079696854
Validation loss: 2.5115821528333306

Epoch: 6| Step: 8
Training loss: 2.4571066452127157
Validation loss: 2.5045757063302814

Epoch: 6| Step: 9
Training loss: 2.733297081063383
Validation loss: 2.5091747810547607

Epoch: 6| Step: 10
Training loss: 2.782133583558474
Validation loss: 2.491829331190573

Epoch: 6| Step: 11
Training loss: 2.682500491608844
Validation loss: 2.4959126756525016

Epoch: 6| Step: 12
Training loss: 2.4223884284404487
Validation loss: 2.497290764522053

Epoch: 6| Step: 13
Training loss: 1.736696699777256
Validation loss: 2.484896351234469

Epoch: 174| Step: 0
Training loss: 2.3905851074081674
Validation loss: 2.488948794360194

Epoch: 6| Step: 1
Training loss: 1.750138277312846
Validation loss: 2.4876443555852763

Epoch: 6| Step: 2
Training loss: 2.438472456006254
Validation loss: 2.482589047753419

Epoch: 6| Step: 3
Training loss: 2.4396019700074456
Validation loss: 2.4802005492665944

Epoch: 6| Step: 4
Training loss: 1.8391337391449882
Validation loss: 2.4793366900145473

Epoch: 6| Step: 5
Training loss: 2.320592381715323
Validation loss: 2.4789862420173634

Epoch: 6| Step: 6
Training loss: 2.3338013134276534
Validation loss: 2.4786713583547684

Epoch: 6| Step: 7
Training loss: 2.618167431838796
Validation loss: 2.479615665029064

Epoch: 6| Step: 8
Training loss: 2.666753042332162
Validation loss: 2.482173976330667

Epoch: 6| Step: 9
Training loss: 2.2045149510569426
Validation loss: 2.4884463843819753

Epoch: 6| Step: 10
Training loss: 3.2658044501102426
Validation loss: 2.491628793494513

Epoch: 6| Step: 11
Training loss: 2.253787561527829
Validation loss: 2.494670511912868

Epoch: 6| Step: 12
Training loss: 2.9542663629134718
Validation loss: 2.498177881610867

Epoch: 6| Step: 13
Training loss: 1.9673242401762623
Validation loss: 2.5033252218481614

Epoch: 175| Step: 0
Training loss: 2.7908346065390384
Validation loss: 2.5058831134245594

Epoch: 6| Step: 1
Training loss: 2.2985428962945105
Validation loss: 2.514309035423729

Epoch: 6| Step: 2
Training loss: 2.095097805462343
Validation loss: 2.505316596490779

Epoch: 6| Step: 3
Training loss: 2.191469895361698
Validation loss: 2.5256892374641318

Epoch: 6| Step: 4
Training loss: 2.4370042345638683
Validation loss: 2.5187639512148197

Epoch: 6| Step: 5
Training loss: 2.584315226185354
Validation loss: 2.5264759018211334

Epoch: 6| Step: 6
Training loss: 1.9483300516684474
Validation loss: 2.536050710229259

Epoch: 6| Step: 7
Training loss: 2.896906445773906
Validation loss: 2.510625653781605

Epoch: 6| Step: 8
Training loss: 2.5543461842844835
Validation loss: 2.5075177487892204

Epoch: 6| Step: 9
Training loss: 2.7883376774485193
Validation loss: 2.5073222852759502

Epoch: 6| Step: 10
Training loss: 1.5700251378033252
Validation loss: 2.485659301331855

Epoch: 6| Step: 11
Training loss: 2.292199806851228
Validation loss: 2.489483601209847

Epoch: 6| Step: 12
Training loss: 2.2721845707135397
Validation loss: 2.4943687595514623

Epoch: 6| Step: 13
Training loss: 2.7720745337403128
Validation loss: 2.497832503079408

Epoch: 176| Step: 0
Training loss: 2.1248245166800412
Validation loss: 2.492358139079774

Epoch: 6| Step: 1
Training loss: 2.724470325052836
Validation loss: 2.488864480998309

Epoch: 6| Step: 2
Training loss: 2.085746613530045
Validation loss: 2.498848395548384

Epoch: 6| Step: 3
Training loss: 1.66399809663462
Validation loss: 2.513754502691874

Epoch: 6| Step: 4
Training loss: 2.72946021755651
Validation loss: 2.5271358886017232

Epoch: 6| Step: 5
Training loss: 2.3971796869143915
Validation loss: 2.522349072677421

Epoch: 6| Step: 6
Training loss: 2.150220983814417
Validation loss: 2.5290982869272107

Epoch: 6| Step: 7
Training loss: 2.685574573720794
Validation loss: 2.533340501356859

Epoch: 6| Step: 8
Training loss: 2.7808009438766614
Validation loss: 2.5341601342222932

Epoch: 6| Step: 9
Training loss: 2.68477279326893
Validation loss: 2.5377284844420003

Epoch: 6| Step: 10
Training loss: 2.4071683245997866
Validation loss: 2.542329300558092

Epoch: 6| Step: 11
Training loss: 2.564526291767306
Validation loss: 2.523654152906628

Epoch: 6| Step: 12
Training loss: 2.2445302812552295
Validation loss: 2.5060548574781394

Epoch: 6| Step: 13
Training loss: 2.3090293202279533
Validation loss: 2.508831803376131

Epoch: 177| Step: 0
Training loss: 2.5226836126550047
Validation loss: 2.490764989233282

Epoch: 6| Step: 1
Training loss: 1.875772952657617
Validation loss: 2.4931977555274094

Epoch: 6| Step: 2
Training loss: 2.9032128984923182
Validation loss: 2.4800800169064683

Epoch: 6| Step: 3
Training loss: 2.627214406006052
Validation loss: 2.479734040632611

Epoch: 6| Step: 4
Training loss: 2.572336159726025
Validation loss: 2.4891491808009465

Epoch: 6| Step: 5
Training loss: 2.0139273658087617
Validation loss: 2.4902448905772667

Epoch: 6| Step: 6
Training loss: 2.186728532175724
Validation loss: 2.489928621956818

Epoch: 6| Step: 7
Training loss: 2.4823406215188673
Validation loss: 2.4960983666350924

Epoch: 6| Step: 8
Training loss: 2.645826284644482
Validation loss: 2.492264143543543

Epoch: 6| Step: 9
Training loss: 2.5487696615361575
Validation loss: 2.48550693148737

Epoch: 6| Step: 10
Training loss: 1.7444566395543215
Validation loss: 2.5056329368667964

Epoch: 6| Step: 11
Training loss: 2.4903076161104405
Validation loss: 2.5039697124276494

Epoch: 6| Step: 12
Training loss: 2.2179315696252404
Validation loss: 2.5192528701487764

Epoch: 6| Step: 13
Training loss: 2.641921046992601
Validation loss: 2.516397590547301

Epoch: 178| Step: 0
Training loss: 2.492035194454603
Validation loss: 2.518125227499483

Epoch: 6| Step: 1
Training loss: 2.0003759507644987
Validation loss: 2.5286881626303996

Epoch: 6| Step: 2
Training loss: 2.1792474117843526
Validation loss: 2.522889383821105

Epoch: 6| Step: 3
Training loss: 2.9852344813175504
Validation loss: 2.5109994984703117

Epoch: 6| Step: 4
Training loss: 2.0436438763331357
Validation loss: 2.5091123292230217

Epoch: 6| Step: 5
Training loss: 2.666356684628958
Validation loss: 2.5062736789158735

Epoch: 6| Step: 6
Training loss: 2.498897881761902
Validation loss: 2.511721217983333

Epoch: 6| Step: 7
Training loss: 1.799801442003144
Validation loss: 2.516419737324835

Epoch: 6| Step: 8
Training loss: 1.744034886759299
Validation loss: 2.499400814095112

Epoch: 6| Step: 9
Training loss: 1.770657818641923
Validation loss: 2.521839907692339

Epoch: 6| Step: 10
Training loss: 2.7915317066270275
Validation loss: 2.5104933973644807

Epoch: 6| Step: 11
Training loss: 2.3081760706391723
Validation loss: 2.5030055734732626

Epoch: 6| Step: 12
Training loss: 2.8219086840405083
Validation loss: 2.502065504668594

Epoch: 6| Step: 13
Training loss: 2.9945134218851144
Validation loss: 2.498424494528385

Epoch: 179| Step: 0
Training loss: 3.0497157230159893
Validation loss: 2.4962262042367476

Epoch: 6| Step: 1
Training loss: 2.0982928739630977
Validation loss: 2.4896142364456724

Epoch: 6| Step: 2
Training loss: 1.95548203723278
Validation loss: 2.500574316178385

Epoch: 6| Step: 3
Training loss: 2.047494576136074
Validation loss: 2.495630100830022

Epoch: 6| Step: 4
Training loss: 2.445975411841262
Validation loss: 2.498639372271803

Epoch: 6| Step: 5
Training loss: 1.9620826082949927
Validation loss: 2.496202859498693

Epoch: 6| Step: 6
Training loss: 2.3377771182697913
Validation loss: 2.5042905705964214

Epoch: 6| Step: 7
Training loss: 2.5778696569514916
Validation loss: 2.503923865388748

Epoch: 6| Step: 8
Training loss: 2.2587519080655896
Validation loss: 2.512615465006702

Epoch: 6| Step: 9
Training loss: 2.47156740534179
Validation loss: 2.5179393381927375

Epoch: 6| Step: 10
Training loss: 2.141336809971807
Validation loss: 2.514539164418873

Epoch: 6| Step: 11
Training loss: 2.556369985735102
Validation loss: 2.524970267218351

Epoch: 6| Step: 12
Training loss: 2.7331234928932107
Validation loss: 2.5259475585606346

Epoch: 6| Step: 13
Training loss: 2.735203731836237
Validation loss: 2.523426823549154

Epoch: 180| Step: 0
Training loss: 2.6340169896393957
Validation loss: 2.5131041570629398

Epoch: 6| Step: 1
Training loss: 2.5074920924966255
Validation loss: 2.506945942613806

Epoch: 6| Step: 2
Training loss: 2.6734822218792376
Validation loss: 2.503721392032123

Epoch: 6| Step: 3
Training loss: 2.1285922037575586
Validation loss: 2.51094252802075

Epoch: 6| Step: 4
Training loss: 2.614052058698981
Validation loss: 2.508875715561664

Epoch: 6| Step: 5
Training loss: 2.384151595262582
Validation loss: 2.501761149918606

Epoch: 6| Step: 6
Training loss: 2.0983671834132798
Validation loss: 2.4902201892722995

Epoch: 6| Step: 7
Training loss: 2.045427815426425
Validation loss: 2.486441338721695

Epoch: 6| Step: 8
Training loss: 2.403668988668403
Validation loss: 2.4891583200942042

Epoch: 6| Step: 9
Training loss: 2.2731534905020903
Validation loss: 2.495257568391722

Epoch: 6| Step: 10
Training loss: 2.245378622569344
Validation loss: 2.495777713068844

Epoch: 6| Step: 11
Training loss: 2.3200212803226403
Validation loss: 2.503872042465425

Epoch: 6| Step: 12
Training loss: 2.4166696044202465
Validation loss: 2.4961492923293984

Epoch: 6| Step: 13
Training loss: 2.961937888854876
Validation loss: 2.5121719797826025

Epoch: 181| Step: 0
Training loss: 2.1144725100285657
Validation loss: 2.510731417497949

Epoch: 6| Step: 1
Training loss: 2.6961742847831225
Validation loss: 2.5107558062241053

Epoch: 6| Step: 2
Training loss: 2.539357892973331
Validation loss: 2.5114787270345427

Epoch: 6| Step: 3
Training loss: 2.5284546852871492
Validation loss: 2.509152665349925

Epoch: 6| Step: 4
Training loss: 2.2677862973727834
Validation loss: 2.518054791750976

Epoch: 6| Step: 5
Training loss: 2.5812137481138886
Validation loss: 2.490833803723281

Epoch: 6| Step: 6
Training loss: 2.4869621768923653
Validation loss: 2.4917262656017036

Epoch: 6| Step: 7
Training loss: 2.3542883399870695
Validation loss: 2.4866569962795015

Epoch: 6| Step: 8
Training loss: 2.581232867980705
Validation loss: 2.485678500772388

Epoch: 6| Step: 9
Training loss: 2.5595024999363014
Validation loss: 2.480091456757314

Epoch: 6| Step: 10
Training loss: 2.699370936121071
Validation loss: 2.4854669310567763

Epoch: 6| Step: 11
Training loss: 1.7872051609405342
Validation loss: 2.4762739219967096

Epoch: 6| Step: 12
Training loss: 2.3925043834299333
Validation loss: 2.4758789370648935

Epoch: 6| Step: 13
Training loss: 2.316917118649777
Validation loss: 2.4762390599401476

Epoch: 182| Step: 0
Training loss: 2.6620355765174386
Validation loss: 2.4836932832449348

Epoch: 6| Step: 1
Training loss: 2.526497512009885
Validation loss: 2.496864991691179

Epoch: 6| Step: 2
Training loss: 2.790858868307181
Validation loss: 2.506020465211146

Epoch: 6| Step: 3
Training loss: 2.229663817207081
Validation loss: 2.513057148461837

Epoch: 6| Step: 4
Training loss: 2.382229793152632
Validation loss: 2.5153176888044153

Epoch: 6| Step: 5
Training loss: 2.70175012452143
Validation loss: 2.534000942661599

Epoch: 6| Step: 6
Training loss: 2.008299297292334
Validation loss: 2.5316407172920106

Epoch: 6| Step: 7
Training loss: 2.4486947845262614
Validation loss: 2.555669317846224

Epoch: 6| Step: 8
Training loss: 2.425168757121615
Validation loss: 2.5542499972550012

Epoch: 6| Step: 9
Training loss: 2.6855322265225494
Validation loss: 2.5457018937447473

Epoch: 6| Step: 10
Training loss: 2.4019030655256763
Validation loss: 2.5437679099562334

Epoch: 6| Step: 11
Training loss: 2.243870757952328
Validation loss: 2.5395394214800726

Epoch: 6| Step: 12
Training loss: 2.563701999015935
Validation loss: 2.525235624933525

Epoch: 6| Step: 13
Training loss: 1.8447071759006457
Validation loss: 2.527332586925131

Epoch: 183| Step: 0
Training loss: 2.593381740670709
Validation loss: 2.526780063161319

Epoch: 6| Step: 1
Training loss: 2.013391484479705
Validation loss: 2.5126370520718537

Epoch: 6| Step: 2
Training loss: 2.343598017533221
Validation loss: 2.5015517902323716

Epoch: 6| Step: 3
Training loss: 2.5133618902444206
Validation loss: 2.49772251022566

Epoch: 6| Step: 4
Training loss: 2.6041906330277387
Validation loss: 2.487527155128897

Epoch: 6| Step: 5
Training loss: 3.0508129787382563
Validation loss: 2.4835492967193398

Epoch: 6| Step: 6
Training loss: 2.9766810436122295
Validation loss: 2.491571252541882

Epoch: 6| Step: 7
Training loss: 1.8421230573440086
Validation loss: 2.4847911750044767

Epoch: 6| Step: 8
Training loss: 2.3051149133598408
Validation loss: 2.4800437422965804

Epoch: 6| Step: 9
Training loss: 2.2215524087854575
Validation loss: 2.4863586184181727

Epoch: 6| Step: 10
Training loss: 1.985904134474583
Validation loss: 2.4849731716854366

Epoch: 6| Step: 11
Training loss: 1.920317786560976
Validation loss: 2.4807379629067414

Epoch: 6| Step: 12
Training loss: 2.3023334442104773
Validation loss: 2.501136712097141

Epoch: 6| Step: 13
Training loss: 2.7851398997208103
Validation loss: 2.5088119495892665

Epoch: 184| Step: 0
Training loss: 1.2606328773536106
Validation loss: 2.5168232719587915

Epoch: 6| Step: 1
Training loss: 2.453040054697177
Validation loss: 2.530749032010052

Epoch: 6| Step: 2
Training loss: 2.9826114896542886
Validation loss: 2.5340667875862612

Epoch: 6| Step: 3
Training loss: 1.9803560063099526
Validation loss: 2.538759450188983

Epoch: 6| Step: 4
Training loss: 2.5615982702088576
Validation loss: 2.544782734773388

Epoch: 6| Step: 5
Training loss: 2.3761384142943984
Validation loss: 2.541316029068767

Epoch: 6| Step: 6
Training loss: 2.693609877480053
Validation loss: 2.536039240769162

Epoch: 6| Step: 7
Training loss: 1.676336734356897
Validation loss: 2.525606764227479

Epoch: 6| Step: 8
Training loss: 2.6216321866855434
Validation loss: 2.525104959906199

Epoch: 6| Step: 9
Training loss: 2.284745556043249
Validation loss: 2.5211801736946926

Epoch: 6| Step: 10
Training loss: 2.6603709847021557
Validation loss: 2.5167512682616637

Epoch: 6| Step: 11
Training loss: 2.7808710761667363
Validation loss: 2.527428870755116

Epoch: 6| Step: 12
Training loss: 2.3098682171110805
Validation loss: 2.5242680461276636

Epoch: 6| Step: 13
Training loss: 2.3538677284590683
Validation loss: 2.5017145794069764

Epoch: 185| Step: 0
Training loss: 2.1973107634252496
Validation loss: 2.504764340420405

Epoch: 6| Step: 1
Training loss: 2.4746139032552787
Validation loss: 2.4884191581640613

Epoch: 6| Step: 2
Training loss: 2.8590938242260497
Validation loss: 2.493613334486588

Epoch: 6| Step: 3
Training loss: 2.0049484546913514
Validation loss: 2.4891333924930135

Epoch: 6| Step: 4
Training loss: 2.680127610968903
Validation loss: 2.4951357886211403

Epoch: 6| Step: 5
Training loss: 2.0832495354647653
Validation loss: 2.4850237177350825

Epoch: 6| Step: 6
Training loss: 3.163923246356948
Validation loss: 2.4945157654430314

Epoch: 6| Step: 7
Training loss: 2.9501741390232414
Validation loss: 2.4978017997472737

Epoch: 6| Step: 8
Training loss: 1.9011764548258094
Validation loss: 2.4997100185062435

Epoch: 6| Step: 9
Training loss: 2.225735266422377
Validation loss: 2.5016601533908758

Epoch: 6| Step: 10
Training loss: 2.145816716497087
Validation loss: 2.5154736317335784

Epoch: 6| Step: 11
Training loss: 2.097989245929921
Validation loss: 2.5364082900691036

Epoch: 6| Step: 12
Training loss: 2.1255254656787868
Validation loss: 2.5433670880472143

Epoch: 6| Step: 13
Training loss: 2.3206714904714567
Validation loss: 2.5415470272318514

Epoch: 186| Step: 0
Training loss: 2.722778667833879
Validation loss: 2.550208876039742

Epoch: 6| Step: 1
Training loss: 2.3454201406115556
Validation loss: 2.527014481460103

Epoch: 6| Step: 2
Training loss: 2.7666276741344102
Validation loss: 2.520245118254414

Epoch: 6| Step: 3
Training loss: 2.11354477908634
Validation loss: 2.5006504484237344

Epoch: 6| Step: 4
Training loss: 2.370160643529306
Validation loss: 2.5048315567215726

Epoch: 6| Step: 5
Training loss: 1.8787810032076426
Validation loss: 2.496890168348828

Epoch: 6| Step: 6
Training loss: 2.162709608558705
Validation loss: 2.4923821256690584

Epoch: 6| Step: 7
Training loss: 2.4338933230667377
Validation loss: 2.496966778942731

Epoch: 6| Step: 8
Training loss: 2.1199863978615334
Validation loss: 2.491350182769338

Epoch: 6| Step: 9
Training loss: 2.9074422380215297
Validation loss: 2.4936147527262174

Epoch: 6| Step: 10
Training loss: 2.75047991639783
Validation loss: 2.4988737589454084

Epoch: 6| Step: 11
Training loss: 2.533069380595004
Validation loss: 2.4991891181686103

Epoch: 6| Step: 12
Training loss: 1.891811786524316
Validation loss: 2.500694655230324

Epoch: 6| Step: 13
Training loss: 2.7604678071281095
Validation loss: 2.518050041784174

Epoch: 187| Step: 0
Training loss: 2.595820875632905
Validation loss: 2.5216787486428793

Epoch: 6| Step: 1
Training loss: 1.7114382494419225
Validation loss: 2.5268199599960774

Epoch: 6| Step: 2
Training loss: 2.8609959744822113
Validation loss: 2.550925187961261

Epoch: 6| Step: 3
Training loss: 1.998724828946885
Validation loss: 2.5400985638450626

Epoch: 6| Step: 4
Training loss: 2.471443155908746
Validation loss: 2.5461637287759267

Epoch: 6| Step: 5
Training loss: 2.068774649020863
Validation loss: 2.5366509042652

Epoch: 6| Step: 6
Training loss: 2.588647166097229
Validation loss: 2.533669449652326

Epoch: 6| Step: 7
Training loss: 2.3826938286919326
Validation loss: 2.5275438987096703

Epoch: 6| Step: 8
Training loss: 1.6125116983625132
Validation loss: 2.518612479722378

Epoch: 6| Step: 9
Training loss: 1.6236033673405883
Validation loss: 2.513973507472746

Epoch: 6| Step: 10
Training loss: 2.663610694138999
Validation loss: 2.50629679508552

Epoch: 6| Step: 11
Training loss: 2.8641196320657887
Validation loss: 2.509904679974598

Epoch: 6| Step: 12
Training loss: 2.693776010622274
Validation loss: 2.5062841826887983

Epoch: 6| Step: 13
Training loss: 2.9425727385392255
Validation loss: 2.507889901904764

Epoch: 188| Step: 0
Training loss: 2.120490281615039
Validation loss: 2.5095323822846742

Epoch: 6| Step: 1
Training loss: 1.948010882650757
Validation loss: 2.5124818187580873

Epoch: 6| Step: 2
Training loss: 1.7322221746248265
Validation loss: 2.522728157928503

Epoch: 6| Step: 3
Training loss: 2.6340654148271683
Validation loss: 2.5275853477378525

Epoch: 6| Step: 4
Training loss: 1.9810181105978313
Validation loss: 2.524532682778826

Epoch: 6| Step: 5
Training loss: 2.38476762451288
Validation loss: 2.5137568106006567

Epoch: 6| Step: 6
Training loss: 2.760282366862494
Validation loss: 2.5147802225783256

Epoch: 6| Step: 7
Training loss: 2.5855142759903873
Validation loss: 2.523710001905177

Epoch: 6| Step: 8
Training loss: 2.6841737434162063
Validation loss: 2.5338995923906746

Epoch: 6| Step: 9
Training loss: 2.151865052646998
Validation loss: 2.515527585119914

Epoch: 6| Step: 10
Training loss: 3.016114822691143
Validation loss: 2.5144553614692327

Epoch: 6| Step: 11
Training loss: 2.773544954179399
Validation loss: 2.5155545021430474

Epoch: 6| Step: 12
Training loss: 2.4749431911846105
Validation loss: 2.5182321358432773

Epoch: 6| Step: 13
Training loss: 1.8321728356802716
Validation loss: 2.516966325927922

Epoch: 189| Step: 0
Training loss: 2.259418378442557
Validation loss: 2.520833201973231

Epoch: 6| Step: 1
Training loss: 2.3006344086139348
Validation loss: 2.5163585154188444

Epoch: 6| Step: 2
Training loss: 2.5040584047836965
Validation loss: 2.5215324872009495

Epoch: 6| Step: 3
Training loss: 2.291797449252634
Validation loss: 2.5235410025424714

Epoch: 6| Step: 4
Training loss: 2.487646480062154
Validation loss: 2.5230209116946676

Epoch: 6| Step: 5
Training loss: 2.678677204405034
Validation loss: 2.5220686247723547

Epoch: 6| Step: 6
Training loss: 2.4744767994281545
Validation loss: 2.5310490375381853

Epoch: 6| Step: 7
Training loss: 1.9200769712993568
Validation loss: 2.531246028316192

Epoch: 6| Step: 8
Training loss: 2.486302617639682
Validation loss: 2.5113751071054415

Epoch: 6| Step: 9
Training loss: 2.1036859724939747
Validation loss: 2.5092001905158137

Epoch: 6| Step: 10
Training loss: 2.1076402100320273
Validation loss: 2.5016070922460685

Epoch: 6| Step: 11
Training loss: 2.588412848989269
Validation loss: 2.505128003985086

Epoch: 6| Step: 12
Training loss: 3.1208013175541085
Validation loss: 2.5046110703548563

Epoch: 6| Step: 13
Training loss: 1.7120949649052064
Validation loss: 2.4944883944012757

Epoch: 190| Step: 0
Training loss: 2.3606525524370663
Validation loss: 2.497886686381126

Epoch: 6| Step: 1
Training loss: 2.1520200510189937
Validation loss: 2.4946278230917756

Epoch: 6| Step: 2
Training loss: 2.116135226639431
Validation loss: 2.5042950451822934

Epoch: 6| Step: 3
Training loss: 2.1189504793005494
Validation loss: 2.4952638268227334

Epoch: 6| Step: 4
Training loss: 2.272099786313278
Validation loss: 2.5074183470215914

Epoch: 6| Step: 5
Training loss: 2.1282853927331136
Validation loss: 2.5031054441630283

Epoch: 6| Step: 6
Training loss: 2.0912603122892435
Validation loss: 2.5235506235125023

Epoch: 6| Step: 7
Training loss: 2.6044315864598566
Validation loss: 2.522586037170723

Epoch: 6| Step: 8
Training loss: 2.3850047548514577
Validation loss: 2.52063820349056

Epoch: 6| Step: 9
Training loss: 2.445635009557965
Validation loss: 2.5365890270821643

Epoch: 6| Step: 10
Training loss: 3.2462206653889747
Validation loss: 2.5299387231575645

Epoch: 6| Step: 11
Training loss: 2.2328626943382743
Validation loss: 2.520582846079311

Epoch: 6| Step: 12
Training loss: 2.7548393670692475
Validation loss: 2.514093252578335

Epoch: 6| Step: 13
Training loss: 2.113063949158866
Validation loss: 2.523916240429829

Epoch: 191| Step: 0
Training loss: 2.500991338636309
Validation loss: 2.5185925373745244

Epoch: 6| Step: 1
Training loss: 2.036621737611532
Validation loss: 2.5138443989150936

Epoch: 6| Step: 2
Training loss: 2.645400114461796
Validation loss: 2.5238488711368565

Epoch: 6| Step: 3
Training loss: 2.5361301802546987
Validation loss: 2.5164592457444965

Epoch: 6| Step: 4
Training loss: 2.290361888393069
Validation loss: 2.512262644397804

Epoch: 6| Step: 5
Training loss: 2.8379359914431332
Validation loss: 2.4969994658384413

Epoch: 6| Step: 6
Training loss: 2.236040041829428
Validation loss: 2.49278257753336

Epoch: 6| Step: 7
Training loss: 2.593683908378824
Validation loss: 2.499369358947651

Epoch: 6| Step: 8
Training loss: 2.559232815436528
Validation loss: 2.5018164552459763

Epoch: 6| Step: 9
Training loss: 2.5030949508634963
Validation loss: 2.5113550123503146

Epoch: 6| Step: 10
Training loss: 2.3451263455513693
Validation loss: 2.5213676758543286

Epoch: 6| Step: 11
Training loss: 2.272440688531132
Validation loss: 2.525318543009496

Epoch: 6| Step: 12
Training loss: 2.1418638334047215
Validation loss: 2.540382363032161

Epoch: 6| Step: 13
Training loss: 1.7328491372172987
Validation loss: 2.5421480181628664

Epoch: 192| Step: 0
Training loss: 2.130325824012627
Validation loss: 2.5412450320821836

Epoch: 6| Step: 1
Training loss: 1.9293572147045173
Validation loss: 2.5446158064294355

Epoch: 6| Step: 2
Training loss: 1.9950898813254656
Validation loss: 2.5481504121507688

Epoch: 6| Step: 3
Training loss: 2.552902111096854
Validation loss: 2.532626409673935

Epoch: 6| Step: 4
Training loss: 2.2964821823428894
Validation loss: 2.5273474133645286

Epoch: 6| Step: 5
Training loss: 1.880353849773243
Validation loss: 2.521075628527

Epoch: 6| Step: 6
Training loss: 2.869622716528653
Validation loss: 2.5205835633766234

Epoch: 6| Step: 7
Training loss: 2.8794451640054977
Validation loss: 2.513084819288759

Epoch: 6| Step: 8
Training loss: 1.6521467086867727
Validation loss: 2.517517562623118

Epoch: 6| Step: 9
Training loss: 2.9122762242087044
Validation loss: 2.523772682943275

Epoch: 6| Step: 10
Training loss: 1.6777973274259692
Validation loss: 2.537765281102369

Epoch: 6| Step: 11
Training loss: 2.4960392093818817
Validation loss: 2.534500797534746

Epoch: 6| Step: 12
Training loss: 2.4967909243755164
Validation loss: 2.5375491909527033

Epoch: 6| Step: 13
Training loss: 2.684838596230932
Validation loss: 2.550530336120946

Epoch: 193| Step: 0
Training loss: 1.9596262647514353
Validation loss: 2.5551660305356902

Epoch: 6| Step: 1
Training loss: 2.3797988595035373
Validation loss: 2.5554512896437416

Epoch: 6| Step: 2
Training loss: 1.668697867847177
Validation loss: 2.5444394345028276

Epoch: 6| Step: 3
Training loss: 2.4327673327810815
Validation loss: 2.5463157773155696

Epoch: 6| Step: 4
Training loss: 2.760089226261765
Validation loss: 2.538725047061664

Epoch: 6| Step: 5
Training loss: 2.22267116011997
Validation loss: 2.527832581434853

Epoch: 6| Step: 6
Training loss: 2.5836787659413414
Validation loss: 2.5193650617177137

Epoch: 6| Step: 7
Training loss: 2.8401273352324314
Validation loss: 2.5161069799218834

Epoch: 6| Step: 8
Training loss: 2.5933196848368794
Validation loss: 2.5311362786512164

Epoch: 6| Step: 9
Training loss: 2.354406924070546
Validation loss: 2.5172101036176135

Epoch: 6| Step: 10
Training loss: 1.938770984804176
Validation loss: 2.511490474786909

Epoch: 6| Step: 11
Training loss: 2.524144407291525
Validation loss: 2.5147840622558433

Epoch: 6| Step: 12
Training loss: 2.256541174700811
Validation loss: 2.510524966382395

Epoch: 6| Step: 13
Training loss: 2.1472888442156925
Validation loss: 2.5243441406640583

Epoch: 194| Step: 0
Training loss: 2.6400608159776446
Validation loss: 2.5294944420908223

Epoch: 6| Step: 1
Training loss: 2.870088113103418
Validation loss: 2.5242993563004994

Epoch: 6| Step: 2
Training loss: 2.3667312031216365
Validation loss: 2.5287552301463085

Epoch: 6| Step: 3
Training loss: 2.358162069223946
Validation loss: 2.5323478766766843

Epoch: 6| Step: 4
Training loss: 2.2418605021041733
Validation loss: 2.52778844050952

Epoch: 6| Step: 5
Training loss: 2.625992178737501
Validation loss: 2.5499735201289773

Epoch: 6| Step: 6
Training loss: 1.8806980020255772
Validation loss: 2.5336043942730058

Epoch: 6| Step: 7
Training loss: 1.8799700669685553
Validation loss: 2.5406140247841447

Epoch: 6| Step: 8
Training loss: 2.770212366797792
Validation loss: 2.535580670567346

Epoch: 6| Step: 9
Training loss: 2.1461651246179696
Validation loss: 2.5294341650269705

Epoch: 6| Step: 10
Training loss: 2.5206566005157045
Validation loss: 2.524136646210195

Epoch: 6| Step: 11
Training loss: 2.2502300356786766
Validation loss: 2.5049196157546483

Epoch: 6| Step: 12
Training loss: 2.2712192265845936
Validation loss: 2.5055304866710486

Epoch: 6| Step: 13
Training loss: 1.9333064935180424
Validation loss: 2.4980825064242764

Epoch: 195| Step: 0
Training loss: 2.958050047156392
Validation loss: 2.48602118823801

Epoch: 6| Step: 1
Training loss: 2.2978306034557323
Validation loss: 2.503645868991137

Epoch: 6| Step: 2
Training loss: 2.559138256111147
Validation loss: 2.49430288624927

Epoch: 6| Step: 3
Training loss: 2.2999313675964976
Validation loss: 2.514574814987187

Epoch: 6| Step: 4
Training loss: 2.6627765135834256
Validation loss: 2.5247640518385186

Epoch: 6| Step: 5
Training loss: 2.475339569533253
Validation loss: 2.5336537270431556

Epoch: 6| Step: 6
Training loss: 2.0818414941597787
Validation loss: 2.5471077717073007

Epoch: 6| Step: 7
Training loss: 2.252887568350867
Validation loss: 2.5376498943836707

Epoch: 6| Step: 8
Training loss: 2.3210643231026538
Validation loss: 2.540218250642515

Epoch: 6| Step: 9
Training loss: 2.241155619551521
Validation loss: 2.5263216840088965

Epoch: 6| Step: 10
Training loss: 2.1803935558402316
Validation loss: 2.5333076088837356

Epoch: 6| Step: 11
Training loss: 1.7655121083585754
Validation loss: 2.5358917627070614

Epoch: 6| Step: 12
Training loss: 2.032688511813743
Validation loss: 2.526399572651718

Epoch: 6| Step: 13
Training loss: 2.764464312599898
Validation loss: 2.5178754072161382

Epoch: 196| Step: 0
Training loss: 1.9028547724656275
Validation loss: 2.5325869887168513

Epoch: 6| Step: 1
Training loss: 1.933038065275539
Validation loss: 2.520638250783856

Epoch: 6| Step: 2
Training loss: 2.8754361692536574
Validation loss: 2.505617712334907

Epoch: 6| Step: 3
Training loss: 2.1655363166562975
Validation loss: 2.510993564108791

Epoch: 6| Step: 4
Training loss: 2.2106174196863426
Validation loss: 2.5190298917258054

Epoch: 6| Step: 5
Training loss: 1.5627143712807134
Validation loss: 2.5280757199809973

Epoch: 6| Step: 6
Training loss: 2.4797642946520644
Validation loss: 2.530886180461164

Epoch: 6| Step: 7
Training loss: 2.4227399696565226
Validation loss: 2.5419273294915685

Epoch: 6| Step: 8
Training loss: 2.3639355975252005
Validation loss: 2.5511787108784993

Epoch: 6| Step: 9
Training loss: 2.8640059195515923
Validation loss: 2.5533744400672935

Epoch: 6| Step: 10
Training loss: 2.6213899948144554
Validation loss: 2.5494163487260795

Epoch: 6| Step: 11
Training loss: 2.2303274347062625
Validation loss: 2.5396586495909763

Epoch: 6| Step: 12
Training loss: 2.7719198023326657
Validation loss: 2.532757329918454

Epoch: 6| Step: 13
Training loss: 2.38333634418573
Validation loss: 2.5059915429947073

Epoch: 197| Step: 0
Training loss: 1.8410031822297268
Validation loss: 2.5080138350464627

Epoch: 6| Step: 1
Training loss: 2.177691896306559
Validation loss: 2.5021615220769133

Epoch: 6| Step: 2
Training loss: 1.6422909951739948
Validation loss: 2.506990418815386

Epoch: 6| Step: 3
Training loss: 1.9460619972483917
Validation loss: 2.500461821815558

Epoch: 6| Step: 4
Training loss: 2.9941358472931547
Validation loss: 2.5055433090340165

Epoch: 6| Step: 5
Training loss: 2.2543849601980335
Validation loss: 2.5012838563878836

Epoch: 6| Step: 6
Training loss: 2.4798554390643877
Validation loss: 2.5050006444629442

Epoch: 6| Step: 7
Training loss: 2.4093037833488298
Validation loss: 2.515551232308775

Epoch: 6| Step: 8
Training loss: 2.4292577627210497
Validation loss: 2.511961549974889

Epoch: 6| Step: 9
Training loss: 2.0930624444999073
Validation loss: 2.5212926892720335

Epoch: 6| Step: 10
Training loss: 2.4135973831043716
Validation loss: 2.520723298458754

Epoch: 6| Step: 11
Training loss: 2.5239009844889706
Validation loss: 2.5213881478439233

Epoch: 6| Step: 12
Training loss: 2.6855385298165793
Validation loss: 2.5244525800726465

Epoch: 6| Step: 13
Training loss: 2.8316752874352806
Validation loss: 2.524901966042565

Epoch: 198| Step: 0
Training loss: 2.475952265795437
Validation loss: 2.5328296394874283

Epoch: 6| Step: 1
Training loss: 2.475482404300763
Validation loss: 2.5439309732981195

Epoch: 6| Step: 2
Training loss: 2.5131844001206933
Validation loss: 2.5487004390610655

Epoch: 6| Step: 3
Training loss: 2.3505041839620797
Validation loss: 2.55844389110174

Epoch: 6| Step: 4
Training loss: 2.2273770097372063
Validation loss: 2.5354768758963186

Epoch: 6| Step: 5
Training loss: 1.6927615895818933
Validation loss: 2.5561199313698375

Epoch: 6| Step: 6
Training loss: 2.101729942940281
Validation loss: 2.5333162830013243

Epoch: 6| Step: 7
Training loss: 2.176692751172708
Validation loss: 2.529128296093375

Epoch: 6| Step: 8
Training loss: 2.0917870728791113
Validation loss: 2.52736194885085

Epoch: 6| Step: 9
Training loss: 2.3784369646291563
Validation loss: 2.52240358002664

Epoch: 6| Step: 10
Training loss: 3.191999662738677
Validation loss: 2.516151531078531

Epoch: 6| Step: 11
Training loss: 2.6589695192148723
Validation loss: 2.5178684395727027

Epoch: 6| Step: 12
Training loss: 1.5016560949079745
Validation loss: 2.521430517557665

Epoch: 6| Step: 13
Training loss: 2.6721068164581316
Validation loss: 2.52787793197453

Epoch: 199| Step: 0
Training loss: 1.3579664715910305
Validation loss: 2.5256463491998646

Epoch: 6| Step: 1
Training loss: 2.1766024945289053
Validation loss: 2.5376602291388135

Epoch: 6| Step: 2
Training loss: 2.337988116048953
Validation loss: 2.5434402208461724

Epoch: 6| Step: 3
Training loss: 2.701182290234349
Validation loss: 2.5406984350673527

Epoch: 6| Step: 4
Training loss: 1.6288722924368133
Validation loss: 2.5418630482417908

Epoch: 6| Step: 5
Training loss: 2.2602234741720215
Validation loss: 2.5400977581966164

Epoch: 6| Step: 6
Training loss: 3.135467089546453
Validation loss: 2.532007033559784

Epoch: 6| Step: 7
Training loss: 2.1920998303589565
Validation loss: 2.5244758760716643

Epoch: 6| Step: 8
Training loss: 1.5463561912344346
Validation loss: 2.5302187541832404

Epoch: 6| Step: 9
Training loss: 2.608267726215277
Validation loss: 2.5384115157315303

Epoch: 6| Step: 10
Training loss: 2.449853939451492
Validation loss: 2.535125293356554

Epoch: 6| Step: 11
Training loss: 2.3375255073338823
Validation loss: 2.5243392451185316

Epoch: 6| Step: 12
Training loss: 2.3068905403483986
Validation loss: 2.545111937219

Epoch: 6| Step: 13
Training loss: 2.857158531418449
Validation loss: 2.5385186341599653

Epoch: 200| Step: 0
Training loss: 2.773376550139033
Validation loss: 2.5526164114445065

Epoch: 6| Step: 1
Training loss: 2.673381536846683
Validation loss: 2.55578112355395

Epoch: 6| Step: 2
Training loss: 2.681529843680892
Validation loss: 2.5651184598004915

Epoch: 6| Step: 3
Training loss: 2.349576396504586
Validation loss: 2.5549777582523063

Epoch: 6| Step: 4
Training loss: 2.2439132588531217
Validation loss: 2.53553968918387

Epoch: 6| Step: 5
Training loss: 2.4330170316966298
Validation loss: 2.534814859610588

Epoch: 6| Step: 6
Training loss: 2.5014807130785663
Validation loss: 2.5319207797953123

Epoch: 6| Step: 7
Training loss: 1.8472994889406023
Validation loss: 2.519066440970553

Epoch: 6| Step: 8
Training loss: 1.6875364511579642
Validation loss: 2.522534810302713

Epoch: 6| Step: 9
Training loss: 2.3806697028247648
Validation loss: 2.5362371600236373

Epoch: 6| Step: 10
Training loss: 2.4894338480443827
Validation loss: 2.5364846157041314

Epoch: 6| Step: 11
Training loss: 2.1003384907718736
Validation loss: 2.5256553013591883

Epoch: 6| Step: 12
Training loss: 2.5082815331806008
Validation loss: 2.5299522935191705

Epoch: 6| Step: 13
Training loss: 1.7306233287512527
Validation loss: 2.5418652368324737

Testing loss: 2.0148432607393523
