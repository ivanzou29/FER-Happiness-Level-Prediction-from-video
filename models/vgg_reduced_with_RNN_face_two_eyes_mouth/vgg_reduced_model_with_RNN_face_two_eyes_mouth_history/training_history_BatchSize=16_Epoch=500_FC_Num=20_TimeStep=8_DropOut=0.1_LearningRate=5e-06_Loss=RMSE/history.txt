Epoch: 1| Step: 0
Training loss: 6.0358982654691715
Validation loss: 5.9393556606295395

Epoch: 6| Step: 1
Training loss: 5.594955911062081
Validation loss: 5.9367624728257775

Epoch: 6| Step: 2
Training loss: 6.453380367223251
Validation loss: 5.934172973086622

Epoch: 6| Step: 3
Training loss: 5.912846509526088
Validation loss: 5.931696226956157

Epoch: 6| Step: 4
Training loss: 6.251740785405325
Validation loss: 5.929149095621387

Epoch: 6| Step: 5
Training loss: 5.6604379566715615
Validation loss: 5.9267175848754245

Epoch: 6| Step: 6
Training loss: 5.939999987669665
Validation loss: 5.924153207608117

Epoch: 6| Step: 7
Training loss: 5.771259976073317
Validation loss: 5.921559213825992

Epoch: 6| Step: 8
Training loss: 6.444722096538479
Validation loss: 5.91914093864113

Epoch: 6| Step: 9
Training loss: 5.35747652377113
Validation loss: 5.916576098254837

Epoch: 6| Step: 10
Training loss: 6.541901732025969
Validation loss: 5.9142128149673034

Epoch: 6| Step: 11
Training loss: 6.005443964292062
Validation loss: 5.911525839085467

Epoch: 6| Step: 12
Training loss: 6.14556670391793
Validation loss: 5.908944136123899

Epoch: 6| Step: 13
Training loss: 6.300669849449169
Validation loss: 5.906270183548929

Epoch: 2| Step: 0
Training loss: 5.595839807994711
Validation loss: 5.9035147602039695

Epoch: 6| Step: 1
Training loss: 6.167290870760866
Validation loss: 5.900605075865711

Epoch: 6| Step: 2
Training loss: 6.269780101174988
Validation loss: 5.897640944162178

Epoch: 6| Step: 3
Training loss: 5.430694706210747
Validation loss: 5.894686404259809

Epoch: 6| Step: 4
Training loss: 5.521986969188775
Validation loss: 5.891416865785548

Epoch: 6| Step: 5
Training loss: 6.5752912565636645
Validation loss: 5.8880945195734995

Epoch: 6| Step: 6
Training loss: 5.417566703945528
Validation loss: 5.884529609560087

Epoch: 6| Step: 7
Training loss: 6.81067037949029
Validation loss: 5.880913078665106

Epoch: 6| Step: 8
Training loss: 5.631943888363051
Validation loss: 5.876907066163883

Epoch: 6| Step: 9
Training loss: 6.770145447829435
Validation loss: 5.872979026193622

Epoch: 6| Step: 10
Training loss: 5.399861524713757
Validation loss: 5.868624968681386

Epoch: 6| Step: 11
Training loss: 6.565851427519642
Validation loss: 5.864317766571822

Epoch: 6| Step: 12
Training loss: 5.5031985605620894
Validation loss: 5.859662617723876

Epoch: 6| Step: 13
Training loss: 5.986871343114357
Validation loss: 5.854798722905344

Epoch: 3| Step: 0
Training loss: 6.0874294269082
Validation loss: 5.849823921357691

Epoch: 6| Step: 1
Training loss: 6.250328055355219
Validation loss: 5.8445978484591405

Epoch: 6| Step: 2
Training loss: 5.712134365008079
Validation loss: 5.83907284618751

Epoch: 6| Step: 3
Training loss: 5.73328724036799
Validation loss: 5.833147027809849

Epoch: 6| Step: 4
Training loss: 5.704761176363626
Validation loss: 5.827196717162153

Epoch: 6| Step: 5
Training loss: 6.529185575722791
Validation loss: 5.820872084921655

Epoch: 6| Step: 6
Training loss: 6.3205834933019265
Validation loss: 5.814445908208487

Epoch: 6| Step: 7
Training loss: 4.85311673096728
Validation loss: 5.807693353511323

Epoch: 6| Step: 8
Training loss: 6.069730870723807
Validation loss: 5.800729325358582

Epoch: 6| Step: 9
Training loss: 5.92275261729492
Validation loss: 5.793131974557976

Epoch: 6| Step: 10
Training loss: 5.8057769944073
Validation loss: 5.785845248216355

Epoch: 6| Step: 11
Training loss: 5.96950729918471
Validation loss: 5.777890578212184

Epoch: 6| Step: 12
Training loss: 5.885085519122285
Validation loss: 5.769941469906065

Epoch: 6| Step: 13
Training loss: 5.931711366675627
Validation loss: 5.7618314397966435

Epoch: 4| Step: 0
Training loss: 5.130704356836946
Validation loss: 5.753409604877987

Epoch: 6| Step: 1
Training loss: 6.481400508475736
Validation loss: 5.7444341507374075

Epoch: 6| Step: 2
Training loss: 6.519576889070333
Validation loss: 5.7354100927649405

Epoch: 6| Step: 3
Training loss: 4.779262952602335
Validation loss: 5.726200690815985

Epoch: 6| Step: 4
Training loss: 6.694282870983141
Validation loss: 5.71713103288815

Epoch: 6| Step: 5
Training loss: 4.8719942656985955
Validation loss: 5.707616115908887

Epoch: 6| Step: 6
Training loss: 5.897106379188096
Validation loss: 5.69789085405583

Epoch: 6| Step: 7
Training loss: 5.865100067663888
Validation loss: 5.688261435265127

Epoch: 6| Step: 8
Training loss: 5.751550879929175
Validation loss: 5.679011651449627

Epoch: 6| Step: 9
Training loss: 5.566111731517726
Validation loss: 5.669347530950698

Epoch: 6| Step: 10
Training loss: 5.845810144568321
Validation loss: 5.660139850375943

Epoch: 6| Step: 11
Training loss: 6.368568017996943
Validation loss: 5.650753068952567

Epoch: 6| Step: 12
Training loss: 5.651949939309006
Validation loss: 5.6415646264424

Epoch: 6| Step: 13
Training loss: 5.518596767142922
Validation loss: 5.6322428379537355

Epoch: 5| Step: 0
Training loss: 5.383959732381209
Validation loss: 5.623175261483702

Epoch: 6| Step: 1
Training loss: 6.0324778517606195
Validation loss: 5.614236635769912

Epoch: 6| Step: 2
Training loss: 5.8567174963065245
Validation loss: 5.60558395710406

Epoch: 6| Step: 3
Training loss: 5.875887864571744
Validation loss: 5.59649661808712

Epoch: 6| Step: 4
Training loss: 5.732908638298549
Validation loss: 5.58776489813265

Epoch: 6| Step: 5
Training loss: 5.731493150384998
Validation loss: 5.579389469787038

Epoch: 6| Step: 6
Training loss: 5.66055555494987
Validation loss: 5.570832116358226

Epoch: 6| Step: 7
Training loss: 6.101973242616955
Validation loss: 5.562460567034561

Epoch: 6| Step: 8
Training loss: 5.71513577677919
Validation loss: 5.554072478808097

Epoch: 6| Step: 9
Training loss: 4.434777082584512
Validation loss: 5.546053027648207

Epoch: 6| Step: 10
Training loss: 6.530051381491717
Validation loss: 5.538223611986716

Epoch: 6| Step: 11
Training loss: 4.949992154818396
Validation loss: 5.530307955361624

Epoch: 6| Step: 12
Training loss: 5.169417889582799
Validation loss: 5.523073118745409

Epoch: 6| Step: 13
Training loss: 6.1256875411305876
Validation loss: 5.51565793813753

Epoch: 6| Step: 0
Training loss: 5.848484671196356
Validation loss: 5.508288409366831

Epoch: 6| Step: 1
Training loss: 5.260480682688556
Validation loss: 5.5004080129772595

Epoch: 6| Step: 2
Training loss: 5.620927820149105
Validation loss: 5.49300346987476

Epoch: 6| Step: 3
Training loss: 4.494607873771064
Validation loss: 5.485680927305748

Epoch: 6| Step: 4
Training loss: 4.611083047212025
Validation loss: 5.478825615347941

Epoch: 6| Step: 5
Training loss: 5.896170598640399
Validation loss: 5.471924069582356

Epoch: 6| Step: 6
Training loss: 5.514799493930124
Validation loss: 5.464872835057817

Epoch: 6| Step: 7
Training loss: 5.69948179332142
Validation loss: 5.4582214441066865

Epoch: 6| Step: 8
Training loss: 6.3287868577493045
Validation loss: 5.45182830054691

Epoch: 6| Step: 9
Training loss: 4.9284345240563106
Validation loss: 5.444911159354591

Epoch: 6| Step: 10
Training loss: 6.660510781436279
Validation loss: 5.438714604263664

Epoch: 6| Step: 11
Training loss: 5.844202360708445
Validation loss: 5.432274159750398

Epoch: 6| Step: 12
Training loss: 5.160192658428048
Validation loss: 5.425896903577505

Epoch: 6| Step: 13
Training loss: 5.866852000227901
Validation loss: 5.419739756230787

Epoch: 7| Step: 0
Training loss: 5.043592017061879
Validation loss: 5.413913565124328

Epoch: 6| Step: 1
Training loss: 5.093108154298975
Validation loss: 5.407598455940427

Epoch: 6| Step: 2
Training loss: 4.089385756650896
Validation loss: 5.4017968920427295

Epoch: 6| Step: 3
Training loss: 6.5978401117809
Validation loss: 5.39593592169409

Epoch: 6| Step: 4
Training loss: 5.7085707492137905
Validation loss: 5.3902136899148205

Epoch: 6| Step: 5
Training loss: 4.904352878264472
Validation loss: 5.384129186485134

Epoch: 6| Step: 6
Training loss: 5.2427525222930145
Validation loss: 5.37887179479781

Epoch: 6| Step: 7
Training loss: 4.782762674634806
Validation loss: 5.372752140992778

Epoch: 6| Step: 8
Training loss: 5.911480560485011
Validation loss: 5.3671581817225995

Epoch: 6| Step: 9
Training loss: 5.347167233050869
Validation loss: 5.36165606683346

Epoch: 6| Step: 10
Training loss: 5.496422037325949
Validation loss: 5.3558938274861765

Epoch: 6| Step: 11
Training loss: 6.022384215018233
Validation loss: 5.3503317352787505

Epoch: 6| Step: 12
Training loss: 5.916593667596365
Validation loss: 5.344664051190561

Epoch: 6| Step: 13
Training loss: 6.281201718272927
Validation loss: 5.33887004555667

Epoch: 8| Step: 0
Training loss: 4.43519489432092
Validation loss: 5.333130425328568

Epoch: 6| Step: 1
Training loss: 5.437303561466037
Validation loss: 5.3274198570769205

Epoch: 6| Step: 2
Training loss: 5.27943560791632
Validation loss: 5.321815670486873

Epoch: 6| Step: 3
Training loss: 5.62279009323816
Validation loss: 5.316098269908859

Epoch: 6| Step: 4
Training loss: 5.655940769236133
Validation loss: 5.310270642018499

Epoch: 6| Step: 5
Training loss: 5.972387353945356
Validation loss: 5.30458026041616

Epoch: 6| Step: 6
Training loss: 5.494588096668465
Validation loss: 5.299395536345521

Epoch: 6| Step: 7
Training loss: 4.6016698543026795
Validation loss: 5.293494692264003

Epoch: 6| Step: 8
Training loss: 5.91630223544346
Validation loss: 5.288302195533784

Epoch: 6| Step: 9
Training loss: 4.859199545290075
Validation loss: 5.282876420746165

Epoch: 6| Step: 10
Training loss: 5.53385217524474
Validation loss: 5.27730965573893

Epoch: 6| Step: 11
Training loss: 5.420952182476549
Validation loss: 5.272175714689418

Epoch: 6| Step: 12
Training loss: 5.9886290566803035
Validation loss: 5.266945723291207

Epoch: 6| Step: 13
Training loss: 5.3886853252822355
Validation loss: 5.2620092820100535

Epoch: 9| Step: 0
Training loss: 5.813739603411004
Validation loss: 5.256299704831887

Epoch: 6| Step: 1
Training loss: 4.8824857312534515
Validation loss: 5.250867045421997

Epoch: 6| Step: 2
Training loss: 4.834872077583005
Validation loss: 5.2454819387599425

Epoch: 6| Step: 3
Training loss: 5.360821498148373
Validation loss: 5.2404359562381755

Epoch: 6| Step: 4
Training loss: 5.282495656478837
Validation loss: 5.234966127030393

Epoch: 6| Step: 5
Training loss: 4.494602357038984
Validation loss: 5.229833441343845

Epoch: 6| Step: 6
Training loss: 5.511783115543732
Validation loss: 5.224504659678804

Epoch: 6| Step: 7
Training loss: 4.936040735085939
Validation loss: 5.219030467889599

Epoch: 6| Step: 8
Training loss: 6.061015468409628
Validation loss: 5.213842524924892

Epoch: 6| Step: 9
Training loss: 5.075309090057387
Validation loss: 5.208480141160123

Epoch: 6| Step: 10
Training loss: 5.362476219000026
Validation loss: 5.203154570502184

Epoch: 6| Step: 11
Training loss: 5.5265771125253
Validation loss: 5.198174581709775

Epoch: 6| Step: 12
Training loss: 5.4246309075732
Validation loss: 5.192476206813585

Epoch: 6| Step: 13
Training loss: 6.01222699788698
Validation loss: 5.18774560553748

Epoch: 10| Step: 0
Training loss: 5.641539269741127
Validation loss: 5.182501502716931

Epoch: 6| Step: 1
Training loss: 5.000566641170587
Validation loss: 5.177540176262737

Epoch: 6| Step: 2
Training loss: 5.582224303978804
Validation loss: 5.17226160300551

Epoch: 6| Step: 3
Training loss: 4.644730829132906
Validation loss: 5.167537441502504

Epoch: 6| Step: 4
Training loss: 4.873319287225509
Validation loss: 5.162708068300047

Epoch: 6| Step: 5
Training loss: 4.690344392539836
Validation loss: 5.15800871477282

Epoch: 6| Step: 6
Training loss: 4.957899806627168
Validation loss: 5.153168499240376

Epoch: 6| Step: 7
Training loss: 5.463018760228577
Validation loss: 5.1489226093888405

Epoch: 6| Step: 8
Training loss: 4.820105549776511
Validation loss: 5.144116330147957

Epoch: 6| Step: 9
Training loss: 5.441196281506205
Validation loss: 5.139684527323177

Epoch: 6| Step: 10
Training loss: 6.0662172856717245
Validation loss: 5.134891795275359

Epoch: 6| Step: 11
Training loss: 4.946188127517781
Validation loss: 5.130605345982793

Epoch: 6| Step: 12
Training loss: 5.345879738245264
Validation loss: 5.125825923955047

Epoch: 6| Step: 13
Training loss: 6.096118329839592
Validation loss: 5.1212890339466295

Epoch: 11| Step: 0
Training loss: 4.23881607548638
Validation loss: 5.116741566725919

Epoch: 6| Step: 1
Training loss: 6.566301970189971
Validation loss: 5.112256030142929

Epoch: 6| Step: 2
Training loss: 5.042103877170591
Validation loss: 5.107782891608654

Epoch: 6| Step: 3
Training loss: 5.6429283110009205
Validation loss: 5.103106963512583

Epoch: 6| Step: 4
Training loss: 5.8039132958632695
Validation loss: 5.098642476488

Epoch: 6| Step: 5
Training loss: 4.979764234791286
Validation loss: 5.093368796845914

Epoch: 6| Step: 6
Training loss: 5.410106363996088
Validation loss: 5.08884519871073

Epoch: 6| Step: 7
Training loss: 4.649043093430121
Validation loss: 5.084359685542218

Epoch: 6| Step: 8
Training loss: 5.3203505011950485
Validation loss: 5.079748526028348

Epoch: 6| Step: 9
Training loss: 5.256057514381138
Validation loss: 5.075415255089644

Epoch: 6| Step: 10
Training loss: 4.2965045561196415
Validation loss: 5.070730700534323

Epoch: 6| Step: 11
Training loss: 5.268433317212995
Validation loss: 5.066301464839362

Epoch: 6| Step: 12
Training loss: 5.212010400406011
Validation loss: 5.061837329585383

Epoch: 6| Step: 13
Training loss: 4.832795781903068
Validation loss: 5.05719937974646

Epoch: 12| Step: 0
Training loss: 5.215796085794934
Validation loss: 5.052638554951665

Epoch: 6| Step: 1
Training loss: 4.403717611920864
Validation loss: 5.04835549951781

Epoch: 6| Step: 2
Training loss: 5.190127523101402
Validation loss: 5.043924010220425

Epoch: 6| Step: 3
Training loss: 6.001831410964868
Validation loss: 5.039054046544912

Epoch: 6| Step: 4
Training loss: 4.558709228935793
Validation loss: 5.034941714826098

Epoch: 6| Step: 5
Training loss: 4.782481714304431
Validation loss: 5.030412339638078

Epoch: 6| Step: 6
Training loss: 3.563310229872151
Validation loss: 5.0262787705333025

Epoch: 6| Step: 7
Training loss: 5.242250808811084
Validation loss: 5.021537900164865

Epoch: 6| Step: 8
Training loss: 5.270738603346279
Validation loss: 5.01744542503866

Epoch: 6| Step: 9
Training loss: 5.662451279453758
Validation loss: 5.012634019336367

Epoch: 6| Step: 10
Training loss: 5.858378170415227
Validation loss: 5.007913652926907

Epoch: 6| Step: 11
Training loss: 5.951008738431058
Validation loss: 5.003297513155428

Epoch: 6| Step: 12
Training loss: 4.825481197100382
Validation loss: 4.998539552385139

Epoch: 6| Step: 13
Training loss: 4.981826944096687
Validation loss: 4.99332077225114

Epoch: 13| Step: 0
Training loss: 3.8851080696068694
Validation loss: 4.988320920304033

Epoch: 6| Step: 1
Training loss: 5.969586538441453
Validation loss: 4.982737145542417

Epoch: 6| Step: 2
Training loss: 4.533895207160364
Validation loss: 4.9773520298002145

Epoch: 6| Step: 3
Training loss: 3.925975828899924
Validation loss: 4.972400467919973

Epoch: 6| Step: 4
Training loss: 5.349150310316434
Validation loss: 4.967277388605837

Epoch: 6| Step: 5
Training loss: 4.688482969852162
Validation loss: 4.9622709950120445

Epoch: 6| Step: 6
Training loss: 5.38463633606576
Validation loss: 4.956697413168086

Epoch: 6| Step: 7
Training loss: 5.287456409464046
Validation loss: 4.951131056316989

Epoch: 6| Step: 8
Training loss: 5.132107713872731
Validation loss: 4.94564241310222

Epoch: 6| Step: 9
Training loss: 5.253999549008958
Validation loss: 4.940116671833089

Epoch: 6| Step: 10
Training loss: 4.986135333376356
Validation loss: 4.934524379898697

Epoch: 6| Step: 11
Training loss: 5.145378720772241
Validation loss: 4.928873695229344

Epoch: 6| Step: 12
Training loss: 5.118087013915144
Validation loss: 4.923233409910138

Epoch: 6| Step: 13
Training loss: 5.939708419476367
Validation loss: 4.917582227300315

Epoch: 14| Step: 0
Training loss: 4.934100755507829
Validation loss: 4.911714462877881

Epoch: 6| Step: 1
Training loss: 4.8691935071586805
Validation loss: 4.906353198219458

Epoch: 6| Step: 2
Training loss: 5.555505190726973
Validation loss: 4.900590779248635

Epoch: 6| Step: 3
Training loss: 6.339645185199148
Validation loss: 4.895051230869408

Epoch: 6| Step: 4
Training loss: 4.487456110577612
Validation loss: 4.888947090370837

Epoch: 6| Step: 5
Training loss: 4.876778107154446
Validation loss: 4.883743758850562

Epoch: 6| Step: 6
Training loss: 4.5098476741128595
Validation loss: 4.878290288692041

Epoch: 6| Step: 7
Training loss: 5.45480329597711
Validation loss: 4.872470982221979

Epoch: 6| Step: 8
Training loss: 4.8394756531227605
Validation loss: 4.867343302070522

Epoch: 6| Step: 9
Training loss: 4.488904200948486
Validation loss: 4.8621383937867595

Epoch: 6| Step: 10
Training loss: 4.424488818281789
Validation loss: 4.856423318683859

Epoch: 6| Step: 11
Training loss: 4.046250932214328
Validation loss: 4.851135038504308

Epoch: 6| Step: 12
Training loss: 4.871369012245613
Validation loss: 4.845769776933115

Epoch: 6| Step: 13
Training loss: 5.828430985914507
Validation loss: 4.840742165855175

Epoch: 15| Step: 0
Training loss: 4.6805832758584796
Validation loss: 4.835352437541786

Epoch: 6| Step: 1
Training loss: 4.996743095140863
Validation loss: 4.8302588166157285

Epoch: 6| Step: 2
Training loss: 4.268169384813698
Validation loss: 4.824368691527375

Epoch: 6| Step: 3
Training loss: 4.541119160446037
Validation loss: 4.819278913300341

Epoch: 6| Step: 4
Training loss: 4.973498876098862
Validation loss: 4.813437333414399

Epoch: 6| Step: 5
Training loss: 4.882663083651395
Validation loss: 4.808382659253615

Epoch: 6| Step: 6
Training loss: 5.618487848227812
Validation loss: 4.802752444747931

Epoch: 6| Step: 7
Training loss: 4.808973333032974
Validation loss: 4.796443128663478

Epoch: 6| Step: 8
Training loss: 4.70215766565164
Validation loss: 4.790918087189977

Epoch: 6| Step: 9
Training loss: 4.317162688243033
Validation loss: 4.785457513369437

Epoch: 6| Step: 10
Training loss: 5.9269907250792775
Validation loss: 4.779817536966905

Epoch: 6| Step: 11
Training loss: 5.203623154995852
Validation loss: 4.773740967939033

Epoch: 6| Step: 12
Training loss: 5.258217873895164
Validation loss: 4.767461037412413

Epoch: 6| Step: 13
Training loss: 4.461794261530507
Validation loss: 4.761098043591255

Epoch: 16| Step: 0
Training loss: 5.256395894496781
Validation loss: 4.755420904293304

Epoch: 6| Step: 1
Training loss: 4.6225612499744795
Validation loss: 4.750428531791289

Epoch: 6| Step: 2
Training loss: 5.105615194915759
Validation loss: 4.743753408264088

Epoch: 6| Step: 3
Training loss: 5.571837399752199
Validation loss: 4.736828075122318

Epoch: 6| Step: 4
Training loss: 4.447285353491595
Validation loss: 4.73036626762011

Epoch: 6| Step: 5
Training loss: 5.009175464751651
Validation loss: 4.7236028311083365

Epoch: 6| Step: 6
Training loss: 4.78452423281557
Validation loss: 4.717091148784897

Epoch: 6| Step: 7
Training loss: 5.204856790556785
Validation loss: 4.710693555497291

Epoch: 6| Step: 8
Training loss: 4.0308650816263265
Validation loss: 4.704305574558527

Epoch: 6| Step: 9
Training loss: 4.7909515289485425
Validation loss: 4.697797324052622

Epoch: 6| Step: 10
Training loss: 4.97951890452359
Validation loss: 4.690466488898934

Epoch: 6| Step: 11
Training loss: 4.122505358431672
Validation loss: 4.684318310388435

Epoch: 6| Step: 12
Training loss: 4.467878136580603
Validation loss: 4.67890345353116

Epoch: 6| Step: 13
Training loss: 5.133104197024425
Validation loss: 4.672196597254443

Epoch: 17| Step: 0
Training loss: 4.453838947017146
Validation loss: 4.665303689735112

Epoch: 6| Step: 1
Training loss: 4.251480517846451
Validation loss: 4.659192719231758

Epoch: 6| Step: 2
Training loss: 4.055861698132702
Validation loss: 4.653579441045953

Epoch: 6| Step: 3
Training loss: 4.231999142479044
Validation loss: 4.647186127957175

Epoch: 6| Step: 4
Training loss: 4.364999731529202
Validation loss: 4.6414250327496855

Epoch: 6| Step: 5
Training loss: 5.565841528371546
Validation loss: 4.635575686809618

Epoch: 6| Step: 6
Training loss: 5.393702946852175
Validation loss: 4.629483326754834

Epoch: 6| Step: 7
Training loss: 5.7674891655220355
Validation loss: 4.622937747906683

Epoch: 6| Step: 8
Training loss: 4.756800150790503
Validation loss: 4.616971479376688

Epoch: 6| Step: 9
Training loss: 4.68710122001645
Validation loss: 4.610604780553652

Epoch: 6| Step: 10
Training loss: 4.441570725159265
Validation loss: 4.60443909588515

Epoch: 6| Step: 11
Training loss: 4.692601390753321
Validation loss: 4.597405516756615

Epoch: 6| Step: 12
Training loss: 4.927681346945159
Validation loss: 4.592246469121443

Epoch: 6| Step: 13
Training loss: 4.571376996090003
Validation loss: 4.585162416255633

Epoch: 18| Step: 0
Training loss: 4.549614254875248
Validation loss: 4.578723785855777

Epoch: 6| Step: 1
Training loss: 3.8765661704719876
Validation loss: 4.572099871959977

Epoch: 6| Step: 2
Training loss: 4.985035054381083
Validation loss: 4.565954146290992

Epoch: 6| Step: 3
Training loss: 5.55508442894393
Validation loss: 4.560020365195502

Epoch: 6| Step: 4
Training loss: 4.313998639201594
Validation loss: 4.553763119663575

Epoch: 6| Step: 5
Training loss: 5.473291048513079
Validation loss: 4.5478696663711675

Epoch: 6| Step: 6
Training loss: 4.954527647290272
Validation loss: 4.541308444300074

Epoch: 6| Step: 7
Training loss: 4.207037143827116
Validation loss: 4.534035363722261

Epoch: 6| Step: 8
Training loss: 4.247659824321422
Validation loss: 4.52799298971777

Epoch: 6| Step: 9
Training loss: 4.660556312393534
Validation loss: 4.522351579875402

Epoch: 6| Step: 10
Training loss: 4.678177986532966
Validation loss: 4.516051345990567

Epoch: 6| Step: 11
Training loss: 4.833257521111498
Validation loss: 4.510099134067568

Epoch: 6| Step: 12
Training loss: 4.435003303604014
Validation loss: 4.504686705392623

Epoch: 6| Step: 13
Training loss: 4.244452502346768
Validation loss: 4.498455453642298

Epoch: 19| Step: 0
Training loss: 4.628612859900462
Validation loss: 4.493031121249271

Epoch: 6| Step: 1
Training loss: 4.891216985687122
Validation loss: 4.486464789942209

Epoch: 6| Step: 2
Training loss: 4.798164914933971
Validation loss: 4.480052109369853

Epoch: 6| Step: 3
Training loss: 4.513540030798347
Validation loss: 4.475149911539678

Epoch: 6| Step: 4
Training loss: 4.75484179629696
Validation loss: 4.46952987303699

Epoch: 6| Step: 5
Training loss: 4.04751970612675
Validation loss: 4.46364075570378

Epoch: 6| Step: 6
Training loss: 4.242456585690622
Validation loss: 4.457423548104311

Epoch: 6| Step: 7
Training loss: 4.122204382333142
Validation loss: 4.451343202215977

Epoch: 6| Step: 8
Training loss: 3.7538944367253637
Validation loss: 4.445659156874394

Epoch: 6| Step: 9
Training loss: 4.802429760444593
Validation loss: 4.44091872931263

Epoch: 6| Step: 10
Training loss: 3.77948196312761
Validation loss: 4.4350492130202595

Epoch: 6| Step: 11
Training loss: 4.94921875
Validation loss: 4.430132592931569

Epoch: 6| Step: 12
Training loss: 5.005831560228031
Validation loss: 4.424521688698914

Epoch: 6| Step: 13
Training loss: 5.512556135449722
Validation loss: 4.418910242436803

Epoch: 20| Step: 0
Training loss: 5.4796442130766385
Validation loss: 4.413360683946096

Epoch: 6| Step: 1
Training loss: 4.815537324041657
Validation loss: 4.4077320717630935

Epoch: 6| Step: 2
Training loss: 4.542123520764363
Validation loss: 4.4021152548739115

Epoch: 6| Step: 3
Training loss: 4.896610192963693
Validation loss: 4.396487411843687

Epoch: 6| Step: 4
Training loss: 4.440902050591661
Validation loss: 4.390666251028369

Epoch: 6| Step: 5
Training loss: 4.140109739093083
Validation loss: 4.384840624648577

Epoch: 6| Step: 6
Training loss: 4.213959411106973
Validation loss: 4.379556372252889

Epoch: 6| Step: 7
Training loss: 4.994311721013256
Validation loss: 4.3746340280687415

Epoch: 6| Step: 8
Training loss: 3.8935165996616505
Validation loss: 4.368784622106129

Epoch: 6| Step: 9
Training loss: 3.5917974060290527
Validation loss: 4.363845884285378

Epoch: 6| Step: 10
Training loss: 5.094168616569633
Validation loss: 4.35807217507821

Epoch: 6| Step: 11
Training loss: 4.595801485746172
Validation loss: 4.352926226639762

Epoch: 6| Step: 12
Training loss: 3.9568294010478366
Validation loss: 4.34815837637289

Epoch: 6| Step: 13
Training loss: 4.052368912362235
Validation loss: 4.342723770949876

Epoch: 21| Step: 0
Training loss: 4.660591098804828
Validation loss: 4.337616466530642

Epoch: 6| Step: 1
Training loss: 4.29027880600741
Validation loss: 4.33291557327894

Epoch: 6| Step: 2
Training loss: 3.7961560734297914
Validation loss: 4.327300873481034

Epoch: 6| Step: 3
Training loss: 3.816437235992429
Validation loss: 4.3227061515321035

Epoch: 6| Step: 4
Training loss: 4.65560765284055
Validation loss: 4.317385242308749

Epoch: 6| Step: 5
Training loss: 5.269051995904659
Validation loss: 4.312317793678045

Epoch: 6| Step: 6
Training loss: 5.1139811713596
Validation loss: 4.3072303604627935

Epoch: 6| Step: 7
Training loss: 4.131114243024031
Validation loss: 4.302521406996361

Epoch: 6| Step: 8
Training loss: 4.728280453543686
Validation loss: 4.29737843656488

Epoch: 6| Step: 9
Training loss: 4.439891761628933
Validation loss: 4.291859199624831

Epoch: 6| Step: 10
Training loss: 4.344984578938219
Validation loss: 4.286755996077881

Epoch: 6| Step: 11
Training loss: 3.747909090134471
Validation loss: 4.2815301436866235

Epoch: 6| Step: 12
Training loss: 4.602928282761433
Validation loss: 4.275937201849741

Epoch: 6| Step: 13
Training loss: 4.193566553961542
Validation loss: 4.271361167978571

Epoch: 22| Step: 0
Training loss: 4.663084608147717
Validation loss: 4.2661099187380636

Epoch: 6| Step: 1
Training loss: 4.319942079085134
Validation loss: 4.261565422752143

Epoch: 6| Step: 2
Training loss: 3.9259384199726046
Validation loss: 4.256206263141474

Epoch: 6| Step: 3
Training loss: 4.293813495638481
Validation loss: 4.251672453079463

Epoch: 6| Step: 4
Training loss: 4.531310824281963
Validation loss: 4.246523370096757

Epoch: 6| Step: 5
Training loss: 4.155469319156523
Validation loss: 4.242450310216223

Epoch: 6| Step: 6
Training loss: 4.344207080970418
Validation loss: 4.236732736778162

Epoch: 6| Step: 7
Training loss: 4.676023140803527
Validation loss: 4.231468939551989

Epoch: 6| Step: 8
Training loss: 4.46581999217553
Validation loss: 4.226954998376343

Epoch: 6| Step: 9
Training loss: 3.9799368281119385
Validation loss: 4.221735860742212

Epoch: 6| Step: 10
Training loss: 4.1498129193525095
Validation loss: 4.21719309017437

Epoch: 6| Step: 11
Training loss: 3.7276284794505132
Validation loss: 4.212045310334328

Epoch: 6| Step: 12
Training loss: 5.2355525727651235
Validation loss: 4.207174815234567

Epoch: 6| Step: 13
Training loss: 4.441044640897163
Validation loss: 4.202699906834551

Epoch: 23| Step: 0
Training loss: 3.6115350246217774
Validation loss: 4.197621009328951

Epoch: 6| Step: 1
Training loss: 5.058668782624034
Validation loss: 4.19260579175323

Epoch: 6| Step: 2
Training loss: 3.9433218891389408
Validation loss: 4.1875113871405345

Epoch: 6| Step: 3
Training loss: 4.303505626236456
Validation loss: 4.182774634243904

Epoch: 6| Step: 4
Training loss: 4.094848252536803
Validation loss: 4.177716949935415

Epoch: 6| Step: 5
Training loss: 5.09477626080921
Validation loss: 4.172853581292417

Epoch: 6| Step: 6
Training loss: 3.6912250131186997
Validation loss: 4.167723877615696

Epoch: 6| Step: 7
Training loss: 3.357179856024005
Validation loss: 4.163045943984778

Epoch: 6| Step: 8
Training loss: 4.895923803048196
Validation loss: 4.158313630897667

Epoch: 6| Step: 9
Training loss: 4.448817046588191
Validation loss: 4.153506547113177

Epoch: 6| Step: 10
Training loss: 3.559159435948737
Validation loss: 4.148785190415789

Epoch: 6| Step: 11
Training loss: 4.546279920721305
Validation loss: 4.144128087719041

Epoch: 6| Step: 12
Training loss: 4.4364210079593756
Validation loss: 4.139058441739981

Epoch: 6| Step: 13
Training loss: 4.634524461698739
Validation loss: 4.134645571112264

Epoch: 24| Step: 0
Training loss: 4.068273579118148
Validation loss: 4.129665433680621

Epoch: 6| Step: 1
Training loss: 3.9335182281184284
Validation loss: 4.124655314214742

Epoch: 6| Step: 2
Training loss: 4.7075474626171285
Validation loss: 4.1201259061099185

Epoch: 6| Step: 3
Training loss: 4.326720743257729
Validation loss: 4.11545062360703

Epoch: 6| Step: 4
Training loss: 3.806728434442913
Validation loss: 4.110581369607831

Epoch: 6| Step: 5
Training loss: 4.076373546310801
Validation loss: 4.105969234875901

Epoch: 6| Step: 6
Training loss: 4.578979829002751
Validation loss: 4.101465016977707

Epoch: 6| Step: 7
Training loss: 4.840088869650358
Validation loss: 4.096754975625475

Epoch: 6| Step: 8
Training loss: 4.6850880839109
Validation loss: 4.092125334867723

Epoch: 6| Step: 9
Training loss: 4.17414022946923
Validation loss: 4.086950231321436

Epoch: 6| Step: 10
Training loss: 4.06940167389759
Validation loss: 4.082179892722047

Epoch: 6| Step: 11
Training loss: 4.190935234630707
Validation loss: 4.077054912537603

Epoch: 6| Step: 12
Training loss: 4.30345642985407
Validation loss: 4.072234302281366

Epoch: 6| Step: 13
Training loss: 3.1977407467114514
Validation loss: 4.067466634227826

Epoch: 25| Step: 0
Training loss: 5.057416836426778
Validation loss: 4.062520834062413

Epoch: 6| Step: 1
Training loss: 3.6767409528165906
Validation loss: 4.057757441074077

Epoch: 6| Step: 2
Training loss: 4.093431533190575
Validation loss: 4.053078804546973

Epoch: 6| Step: 3
Training loss: 4.540415997036776
Validation loss: 4.048462545301968

Epoch: 6| Step: 4
Training loss: 3.880188452479829
Validation loss: 4.043821992385605

Epoch: 6| Step: 5
Training loss: 3.086501444218216
Validation loss: 4.03881821425524

Epoch: 6| Step: 6
Training loss: 3.286915275296511
Validation loss: 4.034240776368393

Epoch: 6| Step: 7
Training loss: 4.676186297853875
Validation loss: 4.02950968868386

Epoch: 6| Step: 8
Training loss: 4.039901321641239
Validation loss: 4.025174928106036

Epoch: 6| Step: 9
Training loss: 4.062001828680185
Validation loss: 4.020596920567466

Epoch: 6| Step: 10
Training loss: 4.131595309740149
Validation loss: 4.016436463931025

Epoch: 6| Step: 11
Training loss: 4.164307549514488
Validation loss: 4.011730398367339

Epoch: 6| Step: 12
Training loss: 4.776510445133634
Validation loss: 4.007369187334634

Epoch: 6| Step: 13
Training loss: 4.372224635880636
Validation loss: 4.002778479065497

Epoch: 26| Step: 0
Training loss: 4.01776398565894
Validation loss: 3.998094979279284

Epoch: 6| Step: 1
Training loss: 4.687497151691843
Validation loss: 3.9933220233555407

Epoch: 6| Step: 2
Training loss: 3.8997592558282324
Validation loss: 3.9883924388424745

Epoch: 6| Step: 3
Training loss: 3.9976075885696862
Validation loss: 3.9836854026272337

Epoch: 6| Step: 4
Training loss: 3.7874838145700216
Validation loss: 3.97884570653126

Epoch: 6| Step: 5
Training loss: 3.572431273710287
Validation loss: 3.974343370788777

Epoch: 6| Step: 6
Training loss: 4.260661720497039
Validation loss: 3.9699026521523066

Epoch: 6| Step: 7
Training loss: 3.456672054962206
Validation loss: 3.9653198557660785

Epoch: 6| Step: 8
Training loss: 4.694196876353275
Validation loss: 3.9605991437205548

Epoch: 6| Step: 9
Training loss: 4.898950285286133
Validation loss: 3.956044904184655

Epoch: 6| Step: 10
Training loss: 3.889680065933421
Validation loss: 3.9510810201736537

Epoch: 6| Step: 11
Training loss: 4.459696100940527
Validation loss: 3.946372133479008

Epoch: 6| Step: 12
Training loss: 3.913946762962632
Validation loss: 3.9416981271747726

Epoch: 6| Step: 13
Training loss: 3.558433487232358
Validation loss: 3.9369047865503086

Epoch: 27| Step: 0
Training loss: 4.128470377079015
Validation loss: 3.932468570325761

Epoch: 6| Step: 1
Training loss: 4.079201274928933
Validation loss: 3.92801247827318

Epoch: 6| Step: 2
Training loss: 4.073980220201705
Validation loss: 3.923068570386569

Epoch: 6| Step: 3
Training loss: 3.7788194142842397
Validation loss: 3.9183803353572824

Epoch: 6| Step: 4
Training loss: 4.377359898197168
Validation loss: 3.9137433214434214

Epoch: 6| Step: 5
Training loss: 3.9346500558126567
Validation loss: 3.909150392141615

Epoch: 6| Step: 6
Training loss: 4.455290257923566
Validation loss: 3.904583059040945

Epoch: 6| Step: 7
Training loss: 3.704835005984723
Validation loss: 3.900007768769963

Epoch: 6| Step: 8
Training loss: 4.130986118401369
Validation loss: 3.895398440371258

Epoch: 6| Step: 9
Training loss: 3.7695199916849362
Validation loss: 3.8907733158709683

Epoch: 6| Step: 10
Training loss: 4.154961178227556
Validation loss: 3.8861558771785427

Epoch: 6| Step: 11
Training loss: 3.2890045088414954
Validation loss: 3.881603684744956

Epoch: 6| Step: 12
Training loss: 4.664534195094099
Validation loss: 3.877265370540286

Epoch: 6| Step: 13
Training loss: 3.7867472388421843
Validation loss: 3.8725999967742433

Epoch: 28| Step: 0
Training loss: 4.722488640145027
Validation loss: 3.8681710273739682

Epoch: 6| Step: 1
Training loss: 4.2188542105908
Validation loss: 3.8637243723237944

Epoch: 6| Step: 2
Training loss: 2.971311728831658
Validation loss: 3.858968901278995

Epoch: 6| Step: 3
Training loss: 3.447207943701206
Validation loss: 3.854514063394609

Epoch: 6| Step: 4
Training loss: 3.7584466537905854
Validation loss: 3.8501530274203435

Epoch: 6| Step: 5
Training loss: 3.476990405548085
Validation loss: 3.8457122384152744

Epoch: 6| Step: 6
Training loss: 3.596760028290856
Validation loss: 3.8414511280180847

Epoch: 6| Step: 7
Training loss: 3.9436033871537965
Validation loss: 3.8371086119828024

Epoch: 6| Step: 8
Training loss: 3.802344131234571
Validation loss: 3.832901218495279

Epoch: 6| Step: 9
Training loss: 4.489601412542751
Validation loss: 3.828465909764511

Epoch: 6| Step: 10
Training loss: 4.318570715444173
Validation loss: 3.8240405863692315

Epoch: 6| Step: 11
Training loss: 4.089428433350927
Validation loss: 3.819578260139089

Epoch: 6| Step: 12
Training loss: 4.199596639973483
Validation loss: 3.815181122959529

Epoch: 6| Step: 13
Training loss: 4.2323547273457525
Validation loss: 3.810683688065901

Epoch: 29| Step: 0
Training loss: 4.162383866623188
Validation loss: 3.8060411660084115

Epoch: 6| Step: 1
Training loss: 3.719191837509103
Validation loss: 3.801311313511407

Epoch: 6| Step: 2
Training loss: 4.262711756304194
Validation loss: 3.796821353151367

Epoch: 6| Step: 3
Training loss: 3.7637929931536482
Validation loss: 3.7918543227712234

Epoch: 6| Step: 4
Training loss: 3.6777892187144823
Validation loss: 3.787532190620426

Epoch: 6| Step: 5
Training loss: 4.2887672086418815
Validation loss: 3.7831705223599497

Epoch: 6| Step: 6
Training loss: 4.337023679760547
Validation loss: 3.7784615736171774

Epoch: 6| Step: 7
Training loss: 3.8670159812421425
Validation loss: 3.7737291432651223

Epoch: 6| Step: 8
Training loss: 3.6278265095102697
Validation loss: 3.769141110801606

Epoch: 6| Step: 9
Training loss: 3.843757195194612
Validation loss: 3.764763887963041

Epoch: 6| Step: 10
Training loss: 3.423208038008262
Validation loss: 3.759911704920532

Epoch: 6| Step: 11
Training loss: 4.007909108088802
Validation loss: 3.7553094364405704

Epoch: 6| Step: 12
Training loss: 3.686098511313476
Validation loss: 3.750853017639386

Epoch: 6| Step: 13
Training loss: 3.99106099757352
Validation loss: 3.746586644878154

Epoch: 30| Step: 0
Training loss: 4.707524773142048
Validation loss: 3.742318827342885

Epoch: 6| Step: 1
Training loss: 3.60156620712255
Validation loss: 3.737721219527591

Epoch: 6| Step: 2
Training loss: 3.5000647130160742
Validation loss: 3.733276578068752

Epoch: 6| Step: 3
Training loss: 3.6039543897852457
Validation loss: 3.7289209480243732

Epoch: 6| Step: 4
Training loss: 4.596338075027899
Validation loss: 3.7246289625287914

Epoch: 6| Step: 5
Training loss: 4.6051425963948045
Validation loss: 3.720082874947309

Epoch: 6| Step: 6
Training loss: 3.5643806178413064
Validation loss: 3.7155029054371207

Epoch: 6| Step: 7
Training loss: 3.309347848177465
Validation loss: 3.7110151958697553

Epoch: 6| Step: 8
Training loss: 3.73190430187093
Validation loss: 3.706530908035558

Epoch: 6| Step: 9
Training loss: 3.5777618357169603
Validation loss: 3.7018296649489835

Epoch: 6| Step: 10
Training loss: 3.3590618608598155
Validation loss: 3.6976997777527614

Epoch: 6| Step: 11
Training loss: 3.9663667506681306
Validation loss: 3.69356921033788

Epoch: 6| Step: 12
Training loss: 3.5825206958841127
Validation loss: 3.6894919193315636

Epoch: 6| Step: 13
Training loss: 3.839430079486552
Validation loss: 3.685498141431687

Epoch: 31| Step: 0
Training loss: 3.984778050998908
Validation loss: 3.680825782948348

Epoch: 6| Step: 1
Training loss: 3.805932313286119
Validation loss: 3.676554756248264

Epoch: 6| Step: 2
Training loss: 4.235830584689088
Validation loss: 3.672437324482502

Epoch: 6| Step: 3
Training loss: 4.058272054367566
Validation loss: 3.6680031240935977

Epoch: 6| Step: 4
Training loss: 3.1968999151338493
Validation loss: 3.6635477643924426

Epoch: 6| Step: 5
Training loss: 3.6867874232882754
Validation loss: 3.6593565391207346

Epoch: 6| Step: 6
Training loss: 3.2089837806222823
Validation loss: 3.6549545775451233

Epoch: 6| Step: 7
Training loss: 3.7715536592224868
Validation loss: 3.6512260916472488

Epoch: 6| Step: 8
Training loss: 3.2310617772072825
Validation loss: 3.6473453692367377

Epoch: 6| Step: 9
Training loss: 3.390812600566874
Validation loss: 3.6432071855094166

Epoch: 6| Step: 10
Training loss: 4.560262680184144
Validation loss: 3.6391251166222283

Epoch: 6| Step: 11
Training loss: 3.702388384345321
Validation loss: 3.6350825064179464

Epoch: 6| Step: 12
Training loss: 3.82797103883636
Validation loss: 3.6307402795251176

Epoch: 6| Step: 13
Training loss: 4.117419125956096
Validation loss: 3.6264806989949223

Epoch: 32| Step: 0
Training loss: 3.7620044572024023
Validation loss: 3.6222315553793254

Epoch: 6| Step: 1
Training loss: 3.693631521735672
Validation loss: 3.618152992138935

Epoch: 6| Step: 2
Training loss: 3.4333964042672744
Validation loss: 3.613725250732937

Epoch: 6| Step: 3
Training loss: 4.343805765576165
Validation loss: 3.6096693747341173

Epoch: 6| Step: 4
Training loss: 3.450755691692763
Validation loss: 3.6056738699016178

Epoch: 6| Step: 5
Training loss: 4.414960759680825
Validation loss: 3.6014906737474135

Epoch: 6| Step: 6
Training loss: 3.7988123091733748
Validation loss: 3.597303474683634

Epoch: 6| Step: 7
Training loss: 3.470597608483266
Validation loss: 3.5929529163033553

Epoch: 6| Step: 8
Training loss: 3.6885093988477493
Validation loss: 3.588877307419122

Epoch: 6| Step: 9
Training loss: 3.8053578250375755
Validation loss: 3.584735788126461

Epoch: 6| Step: 10
Training loss: 3.6816094111326008
Validation loss: 3.5804800753796173

Epoch: 6| Step: 11
Training loss: 3.31014974457077
Validation loss: 3.5762430541953183

Epoch: 6| Step: 12
Training loss: 3.119168142294087
Validation loss: 3.57205271307997

Epoch: 6| Step: 13
Training loss: 4.042436323260059
Validation loss: 3.567852037788825

Epoch: 33| Step: 0
Training loss: 3.7222709336264486
Validation loss: 3.563546657177775

Epoch: 6| Step: 1
Training loss: 2.586668712117019
Validation loss: 3.5593529235851844

Epoch: 6| Step: 2
Training loss: 4.669905741881898
Validation loss: 3.555313468844231

Epoch: 6| Step: 3
Training loss: 3.9171724736854046
Validation loss: 3.55112192934744

Epoch: 6| Step: 4
Training loss: 4.610238928571449
Validation loss: 3.5467092780610465

Epoch: 6| Step: 5
Training loss: 2.8927330784374035
Validation loss: 3.5422851396477464

Epoch: 6| Step: 6
Training loss: 3.3967626193353957
Validation loss: 3.5379814759361277

Epoch: 6| Step: 7
Training loss: 3.485066845552428
Validation loss: 3.5340274926645225

Epoch: 6| Step: 8
Training loss: 3.7120292904618992
Validation loss: 3.5301243160932385

Epoch: 6| Step: 9
Training loss: 3.6219390573835435
Validation loss: 3.5258382102760075

Epoch: 6| Step: 10
Training loss: 2.763714491444832
Validation loss: 3.5224404965011975

Epoch: 6| Step: 11
Training loss: 3.883585371316525
Validation loss: 3.517994377533665

Epoch: 6| Step: 12
Training loss: 3.990514953577616
Validation loss: 3.5137066615872268

Epoch: 6| Step: 13
Training loss: 3.5388116137100463
Validation loss: 3.509618123103347

Epoch: 34| Step: 0
Training loss: 3.2689335321137887
Validation loss: 3.5057081722994266

Epoch: 6| Step: 1
Training loss: 3.497928006076363
Validation loss: 3.5012405104476203

Epoch: 6| Step: 2
Training loss: 3.5765907963091284
Validation loss: 3.497611911411135

Epoch: 6| Step: 3
Training loss: 3.6062703837805365
Validation loss: 3.493654220441931

Epoch: 6| Step: 4
Training loss: 3.3622421449400304
Validation loss: 3.4895424380207274

Epoch: 6| Step: 5
Training loss: 4.001992206373352
Validation loss: 3.48575458670821

Epoch: 6| Step: 6
Training loss: 4.422707846562434
Validation loss: 3.4820056266432453

Epoch: 6| Step: 7
Training loss: 2.8617410511561086
Validation loss: 3.47842526483593

Epoch: 6| Step: 8
Training loss: 3.814183848262263
Validation loss: 3.4749664643496776

Epoch: 6| Step: 9
Training loss: 4.064532431800755
Validation loss: 3.4759262817242025

Epoch: 6| Step: 10
Training loss: 3.1742226317314133
Validation loss: 3.466013289892593

Epoch: 6| Step: 11
Training loss: 3.0550725747835883
Validation loss: 3.4625106921530113

Epoch: 6| Step: 12
Training loss: 4.0118599544587115
Validation loss: 3.4592566272638754

Epoch: 6| Step: 13
Training loss: 3.59450198059834
Validation loss: 3.4554427065792512

Epoch: 35| Step: 0
Training loss: 3.583766970160188
Validation loss: 3.4521229873862973

Epoch: 6| Step: 1
Training loss: 3.656902287651485
Validation loss: 3.4481436125563136

Epoch: 6| Step: 2
Training loss: 3.183137788475378
Validation loss: 3.4441006029095362

Epoch: 6| Step: 3
Training loss: 3.6300148312604588
Validation loss: 3.440608982622893

Epoch: 6| Step: 4
Training loss: 3.460442294478133
Validation loss: 3.4361821046932564

Epoch: 6| Step: 5
Training loss: 3.1523579688147416
Validation loss: 3.4325657427836544

Epoch: 6| Step: 6
Training loss: 3.9595836605497525
Validation loss: 3.428334727518048

Epoch: 6| Step: 7
Training loss: 3.5589608799712895
Validation loss: 3.4245783376899026

Epoch: 6| Step: 8
Training loss: 3.9765201708746
Validation loss: 3.4206382339605352

Epoch: 6| Step: 9
Training loss: 3.3347912143397083
Validation loss: 3.416714148462864

Epoch: 6| Step: 10
Training loss: 3.7343354163206754
Validation loss: 3.413109641295252

Epoch: 6| Step: 11
Training loss: 2.990586612020555
Validation loss: 3.408902293487956

Epoch: 6| Step: 12
Training loss: 3.7279709047893017
Validation loss: 3.4048913818489615

Epoch: 6| Step: 13
Training loss: 3.803748921705401
Validation loss: 3.400814771264278

Epoch: 36| Step: 0
Training loss: 3.364912853501219
Validation loss: 3.3967466393871515

Epoch: 6| Step: 1
Training loss: 4.396306715993422
Validation loss: 3.3926579464731446

Epoch: 6| Step: 2
Training loss: 3.5715062923148997
Validation loss: 3.3885313211950168

Epoch: 6| Step: 3
Training loss: 3.427215171682078
Validation loss: 3.384643716849162

Epoch: 6| Step: 4
Training loss: 3.9885911363449735
Validation loss: 3.3807826129875145

Epoch: 6| Step: 5
Training loss: 2.9436111190658467
Validation loss: 3.376675966713824

Epoch: 6| Step: 6
Training loss: 3.4148846297652478
Validation loss: 3.372900557091742

Epoch: 6| Step: 7
Training loss: 3.1928576153967883
Validation loss: 3.3688237698226953

Epoch: 6| Step: 8
Training loss: 3.8619410829559087
Validation loss: 3.364857397737467

Epoch: 6| Step: 9
Training loss: 3.345271539771426
Validation loss: 3.3609047297404255

Epoch: 6| Step: 10
Training loss: 2.8175944495088494
Validation loss: 3.357121609318133

Epoch: 6| Step: 11
Training loss: 3.3595419199082923
Validation loss: 3.353682670661492

Epoch: 6| Step: 12
Training loss: 3.0351860997365843
Validation loss: 3.350085676340748

Epoch: 6| Step: 13
Training loss: 4.065540760290565
Validation loss: 3.3468249196432365

Epoch: 37| Step: 0
Training loss: 3.5633007287394447
Validation loss: 3.3432510098723687

Epoch: 6| Step: 1
Training loss: 3.2041808830379077
Validation loss: 3.339439120701892

Epoch: 6| Step: 2
Training loss: 3.152926366350927
Validation loss: 3.335948446763576

Epoch: 6| Step: 3
Training loss: 3.655871901565581
Validation loss: 3.3318718726384913

Epoch: 6| Step: 4
Training loss: 3.34224231990674
Validation loss: 3.328571582137743

Epoch: 6| Step: 5
Training loss: 3.4557846666645067
Validation loss: 3.325424686835341

Epoch: 6| Step: 6
Training loss: 2.8625500670473065
Validation loss: 3.3208158941700474

Epoch: 6| Step: 7
Training loss: 3.333376470922451
Validation loss: 3.3178079890560364

Epoch: 6| Step: 8
Training loss: 3.6203151553049175
Validation loss: 3.3139326728116227

Epoch: 6| Step: 9
Training loss: 4.397473841204974
Validation loss: 3.3102665455227047

Epoch: 6| Step: 10
Training loss: 3.2711153010097336
Validation loss: 3.306542851939752

Epoch: 6| Step: 11
Training loss: 3.9970441864449726
Validation loss: 3.302815537646355

Epoch: 6| Step: 12
Training loss: 3.2100203566336525
Validation loss: 3.298869007580756

Epoch: 6| Step: 13
Training loss: 3.070853226975522
Validation loss: 3.2955703443951507

Epoch: 38| Step: 0
Training loss: 3.627039894458854
Validation loss: 3.291990135491734

Epoch: 6| Step: 1
Training loss: 3.506288193003396
Validation loss: 3.288135195481079

Epoch: 6| Step: 2
Training loss: 3.6257629906971958
Validation loss: 3.285012355802496

Epoch: 6| Step: 3
Training loss: 3.3185315191333418
Validation loss: 3.2816426965572023

Epoch: 6| Step: 4
Training loss: 3.6843871863036646
Validation loss: 3.2792662421638537

Epoch: 6| Step: 5
Training loss: 3.3876544931239247
Validation loss: 3.2783471239811925

Epoch: 6| Step: 6
Training loss: 3.61181769345869
Validation loss: 3.2704842901575226

Epoch: 6| Step: 7
Training loss: 3.6587403774102354
Validation loss: 3.2664922022130614

Epoch: 6| Step: 8
Training loss: 3.1825669955673224
Validation loss: 3.2628587021345585

Epoch: 6| Step: 9
Training loss: 3.339520212307913
Validation loss: 3.2596192202290495

Epoch: 6| Step: 10
Training loss: 2.9115637326255843
Validation loss: 3.2562665801013617

Epoch: 6| Step: 11
Training loss: 3.046093649814053
Validation loss: 3.2535779160727065

Epoch: 6| Step: 12
Training loss: 3.427287380710586
Validation loss: 3.2504552131137094

Epoch: 6| Step: 13
Training loss: 3.31826855746825
Validation loss: 3.246945070227193

Epoch: 39| Step: 0
Training loss: 3.3558990238171114
Validation loss: 3.2433533070084173

Epoch: 6| Step: 1
Training loss: 3.545078444372961
Validation loss: 3.2400251539062395

Epoch: 6| Step: 2
Training loss: 3.346502009390184
Validation loss: 3.236885902163981

Epoch: 6| Step: 3
Training loss: 3.6709584492301355
Validation loss: 3.233870142850499

Epoch: 6| Step: 4
Training loss: 2.723832652083978
Validation loss: 3.230720113548588

Epoch: 6| Step: 5
Training loss: 3.713594084053636
Validation loss: 3.2268934472705855

Epoch: 6| Step: 6
Training loss: 3.574338817143155
Validation loss: 3.2232999771375215

Epoch: 6| Step: 7
Training loss: 3.4385262084601145
Validation loss: 3.2196300007320358

Epoch: 6| Step: 8
Training loss: 2.5262653579509338
Validation loss: 3.2163267179991655

Epoch: 6| Step: 9
Training loss: 2.900561271810737
Validation loss: 3.214345838600029

Epoch: 6| Step: 10
Training loss: 2.9008047302758797
Validation loss: 3.2116342053227087

Epoch: 6| Step: 11
Training loss: 3.611895849270375
Validation loss: 3.2084630386754447

Epoch: 6| Step: 12
Training loss: 3.8016604811102286
Validation loss: 3.2042580190135945

Epoch: 6| Step: 13
Training loss: 3.6548290915132253
Validation loss: 3.200724873299628

Epoch: 40| Step: 0
Training loss: 3.74915774741507
Validation loss: 3.196828195099377

Epoch: 6| Step: 1
Training loss: 3.9680810800159523
Validation loss: 3.193014075288335

Epoch: 6| Step: 2
Training loss: 3.4535928124503883
Validation loss: 3.189481356282295

Epoch: 6| Step: 3
Training loss: 3.302359552392993
Validation loss: 3.1862700713602856

Epoch: 6| Step: 4
Training loss: 3.147036863253552
Validation loss: 3.182930869147237

Epoch: 6| Step: 5
Training loss: 2.801425237319484
Validation loss: 3.179876148523129

Epoch: 6| Step: 6
Training loss: 3.273629339965195
Validation loss: 3.1759997453401208

Epoch: 6| Step: 7
Training loss: 3.53287988368158
Validation loss: 3.1730478808564104

Epoch: 6| Step: 8
Training loss: 3.1849453730666943
Validation loss: 3.1697516012694438

Epoch: 6| Step: 9
Training loss: 3.7760941845979676
Validation loss: 3.166170386693854

Epoch: 6| Step: 10
Training loss: 3.1581481664590396
Validation loss: 3.1627169412781773

Epoch: 6| Step: 11
Training loss: 2.5062461072934332
Validation loss: 3.159470152436089

Epoch: 6| Step: 12
Training loss: 3.0684128337163554
Validation loss: 3.156319796857438

Epoch: 6| Step: 13
Training loss: 3.2358238918635966
Validation loss: 3.1531018586785597

Epoch: 41| Step: 0
Training loss: 3.865583113965359
Validation loss: 3.150157890702235

Epoch: 6| Step: 1
Training loss: 3.5489286283580976
Validation loss: 3.147176396907124

Epoch: 6| Step: 2
Training loss: 2.442988354561868
Validation loss: 3.1436019882841757

Epoch: 6| Step: 3
Training loss: 3.5688037981831893
Validation loss: 3.140476634505048

Epoch: 6| Step: 4
Training loss: 2.726250748177294
Validation loss: 3.1395319717819765

Epoch: 6| Step: 5
Training loss: 3.56313679675612
Validation loss: 3.138736163186956

Epoch: 6| Step: 6
Training loss: 3.5984356395271053
Validation loss: 3.139360581368127

Epoch: 6| Step: 7
Training loss: 2.614572248903971
Validation loss: 3.129196553567995

Epoch: 6| Step: 8
Training loss: 3.477840985734987
Validation loss: 3.125656135341459

Epoch: 6| Step: 9
Training loss: 3.4298722688786465
Validation loss: 3.122695289147002

Epoch: 6| Step: 10
Training loss: 2.992719398811792
Validation loss: 3.120079222574027

Epoch: 6| Step: 11
Training loss: 3.1796353122636787
Validation loss: 3.1173478852506986

Epoch: 6| Step: 12
Training loss: 3.342995531759833
Validation loss: 3.1144198286502354

Epoch: 6| Step: 13
Training loss: 3.13282513318642
Validation loss: 3.111807314332068

Epoch: 42| Step: 0
Training loss: 3.3994203746619793
Validation loss: 3.1088250343175035

Epoch: 6| Step: 1
Training loss: 3.5501747410710185
Validation loss: 3.1059928659691627

Epoch: 6| Step: 2
Training loss: 3.1337844976984517
Validation loss: 3.1029091321036595

Epoch: 6| Step: 3
Training loss: 2.634496224036328
Validation loss: 3.1001682046151195

Epoch: 6| Step: 4
Training loss: 3.227895244387623
Validation loss: 3.097139524677738

Epoch: 6| Step: 5
Training loss: 2.9380908128428773
Validation loss: 3.0943274553108813

Epoch: 6| Step: 6
Training loss: 2.3691007731860503
Validation loss: 3.091306871281045

Epoch: 6| Step: 7
Training loss: 3.1123005508189485
Validation loss: 3.0885011735720096

Epoch: 6| Step: 8
Training loss: 3.829092347285519
Validation loss: 3.0856158511416565

Epoch: 6| Step: 9
Training loss: 2.676658586780456
Validation loss: 3.0826303780470155

Epoch: 6| Step: 10
Training loss: 3.329008889468039
Validation loss: 3.0798050866854663

Epoch: 6| Step: 11
Training loss: 3.3781201104085508
Validation loss: 3.0769175373541042

Epoch: 6| Step: 12
Training loss: 3.407160086186922
Validation loss: 3.0740485138151783

Epoch: 6| Step: 13
Training loss: 3.8736827211055247
Validation loss: 3.071365758183879

Epoch: 43| Step: 0
Training loss: 3.898752448254569
Validation loss: 3.0681789708579195

Epoch: 6| Step: 1
Training loss: 3.8410659971399563
Validation loss: 3.065387584165833

Epoch: 6| Step: 2
Training loss: 2.6330718413627348
Validation loss: 3.0624343320073093

Epoch: 6| Step: 3
Training loss: 2.7407886382328996
Validation loss: 3.0595344275918834

Epoch: 6| Step: 4
Training loss: 2.9808666118683447
Validation loss: 3.0568410009452265

Epoch: 6| Step: 5
Training loss: 2.7867028435118644
Validation loss: 3.0540076472443354

Epoch: 6| Step: 6
Training loss: 3.315957046838003
Validation loss: 3.051512958927256

Epoch: 6| Step: 7
Training loss: 3.028106317767608
Validation loss: 3.049054714322091

Epoch: 6| Step: 8
Training loss: 3.598868001346157
Validation loss: 3.045933922090781

Epoch: 6| Step: 9
Training loss: 2.6743620958616456
Validation loss: 3.043170417890161

Epoch: 6| Step: 10
Training loss: 3.3051209221907047
Validation loss: 3.040431520867409

Epoch: 6| Step: 11
Training loss: 3.296896694889371
Validation loss: 3.037356096163425

Epoch: 6| Step: 12
Training loss: 3.226717227061511
Validation loss: 3.034898757649476

Epoch: 6| Step: 13
Training loss: 3.0306062309705077
Validation loss: 3.031883383315798

Epoch: 44| Step: 0
Training loss: 2.7748968878482128
Validation loss: 3.0294200577850234

Epoch: 6| Step: 1
Training loss: 2.6772431995042947
Validation loss: 3.026229476134307

Epoch: 6| Step: 2
Training loss: 3.5124834053489224
Validation loss: 3.0244306433106867

Epoch: 6| Step: 3
Training loss: 3.128324037787708
Validation loss: 3.02161867303146

Epoch: 6| Step: 4
Training loss: 3.3198424242151394
Validation loss: 3.0191086987089677

Epoch: 6| Step: 5
Training loss: 3.2534214496665492
Validation loss: 3.0166131016592996

Epoch: 6| Step: 6
Training loss: 3.070343250382748
Validation loss: 3.014354484288447

Epoch: 6| Step: 7
Training loss: 3.1688440433067675
Validation loss: 3.0118299332615477

Epoch: 6| Step: 8
Training loss: 3.3602763541423935
Validation loss: 3.009225620722981

Epoch: 6| Step: 9
Training loss: 2.6543816671519016
Validation loss: 3.0062358869087835

Epoch: 6| Step: 10
Training loss: 3.629111359120435
Validation loss: 3.003623178519102

Epoch: 6| Step: 11
Training loss: 3.0508328285692707
Validation loss: 3.0012547200314246

Epoch: 6| Step: 12
Training loss: 3.3618827508545213
Validation loss: 2.998852510341944

Epoch: 6| Step: 13
Training loss: 3.0147232525843646
Validation loss: 2.9963555319031636

Epoch: 45| Step: 0
Training loss: 3.6067696287885322
Validation loss: 2.9936916730557206

Epoch: 6| Step: 1
Training loss: 2.888932180895389
Validation loss: 2.9913300828725475

Epoch: 6| Step: 2
Training loss: 2.372511815161272
Validation loss: 2.988153725024373

Epoch: 6| Step: 3
Training loss: 3.1685903294530395
Validation loss: 2.98613536637581

Epoch: 6| Step: 4
Training loss: 3.006074636186326
Validation loss: 2.982982157349601

Epoch: 6| Step: 5
Training loss: 3.0229132145958997
Validation loss: 2.9803306110945487

Epoch: 6| Step: 6
Training loss: 3.0786401927476628
Validation loss: 2.9781983186730336

Epoch: 6| Step: 7
Training loss: 3.5287685621626728
Validation loss: 2.9762616209881783

Epoch: 6| Step: 8
Training loss: 2.9952039528820658
Validation loss: 2.973626010763807

Epoch: 6| Step: 9
Training loss: 3.127542910689336
Validation loss: 2.970867271996346

Epoch: 6| Step: 10
Training loss: 3.329353786234069
Validation loss: 2.968752650209549

Epoch: 6| Step: 11
Training loss: 3.052341819120118
Validation loss: 2.9652714209348234

Epoch: 6| Step: 12
Training loss: 3.323135432552874
Validation loss: 2.963360267455252

Epoch: 6| Step: 13
Training loss: 2.993804733636128
Validation loss: 2.9606613526955514

Epoch: 46| Step: 0
Training loss: 2.2185408802611994
Validation loss: 2.957896527203289

Epoch: 6| Step: 1
Training loss: 2.7657630153205974
Validation loss: 2.9556879564456886

Epoch: 6| Step: 2
Training loss: 3.324751742854093
Validation loss: 2.9541806952856757

Epoch: 6| Step: 3
Training loss: 4.0259108561213255
Validation loss: 2.951351326098793

Epoch: 6| Step: 4
Training loss: 2.9224288333943877
Validation loss: 2.950274509653638

Epoch: 6| Step: 5
Training loss: 3.566668564507761
Validation loss: 2.9463896059374424

Epoch: 6| Step: 6
Training loss: 2.9775244892948547
Validation loss: 2.9442229072633093

Epoch: 6| Step: 7
Training loss: 2.6447457208257146
Validation loss: 2.9416561890182273

Epoch: 6| Step: 8
Training loss: 2.440567336335397
Validation loss: 2.9393355674513093

Epoch: 6| Step: 9
Training loss: 3.695692498506615
Validation loss: 2.937627045609825

Epoch: 6| Step: 10
Training loss: 2.6840858063888997
Validation loss: 2.934806034820849

Epoch: 6| Step: 11
Training loss: 3.3740037931320312
Validation loss: 2.932283314523044

Epoch: 6| Step: 12
Training loss: 3.0944467395779287
Validation loss: 2.930501812828279

Epoch: 6| Step: 13
Training loss: 2.9295825176502825
Validation loss: 2.9278626586686967

Epoch: 47| Step: 0
Training loss: 2.7145579674785485
Validation loss: 2.9251847993992435

Epoch: 6| Step: 1
Training loss: 3.2081510979226104
Validation loss: 2.9222445466776668

Epoch: 6| Step: 2
Training loss: 3.2606629267470737
Validation loss: 2.9198239857607327

Epoch: 6| Step: 3
Training loss: 3.0246562226470886
Validation loss: 2.917960960585459

Epoch: 6| Step: 4
Training loss: 2.651317639528974
Validation loss: 2.9191252745593093

Epoch: 6| Step: 5
Training loss: 3.11450125459605
Validation loss: 2.9319159547678626

Epoch: 6| Step: 6
Training loss: 2.892009341761695
Validation loss: 2.936010064024658

Epoch: 6| Step: 7
Training loss: 2.8560521564369385
Validation loss: 2.909837484289666

Epoch: 6| Step: 8
Training loss: 2.3562593414364312
Validation loss: 2.9091878282412393

Epoch: 6| Step: 9
Training loss: 3.3232383133885
Validation loss: 2.9086524440360244

Epoch: 6| Step: 10
Training loss: 3.440506331418142
Validation loss: 2.908420039708909

Epoch: 6| Step: 11
Training loss: 3.2753743198013954
Validation loss: 2.9093286212156872

Epoch: 6| Step: 12
Training loss: 3.086011050349765
Validation loss: 2.909279287083922

Epoch: 6| Step: 13
Training loss: 3.357036965737949
Validation loss: 2.9059107319229733

Epoch: 48| Step: 0
Training loss: 3.0543203303949737
Validation loss: 2.9017677471457017

Epoch: 6| Step: 1
Training loss: 2.6824952477291277
Validation loss: 2.8976588407155037

Epoch: 6| Step: 2
Training loss: 2.338764635995467
Validation loss: 2.894530371401126

Epoch: 6| Step: 3
Training loss: 3.4927781392823998
Validation loss: 2.8950148576147656

Epoch: 6| Step: 4
Training loss: 2.974680227837228
Validation loss: 2.891011090312223

Epoch: 6| Step: 5
Training loss: 2.953001312410584
Validation loss: 2.8886537721112666

Epoch: 6| Step: 6
Training loss: 3.3511490288918475
Validation loss: 2.8870921497831548

Epoch: 6| Step: 7
Training loss: 2.7953814562527803
Validation loss: 2.8844467947673906

Epoch: 6| Step: 8
Training loss: 2.9097049644846606
Validation loss: 2.8834106458835156

Epoch: 6| Step: 9
Training loss: 3.425241425630103
Validation loss: 2.8796347011804526

Epoch: 6| Step: 10
Training loss: 3.1474756328678812
Validation loss: 2.876184454475969

Epoch: 6| Step: 11
Training loss: 2.715219243929031
Validation loss: 2.873408651146608

Epoch: 6| Step: 12
Training loss: 3.327823535715691
Validation loss: 2.871221533459701

Epoch: 6| Step: 13
Training loss: 3.017106557004303
Validation loss: 2.8696376715372556

Epoch: 49| Step: 0
Training loss: 2.787243332614258
Validation loss: 2.868169257860995

Epoch: 6| Step: 1
Training loss: 3.152946178253969
Validation loss: 2.866798561595728

Epoch: 6| Step: 2
Training loss: 2.3783802271467893
Validation loss: 2.865101276158854

Epoch: 6| Step: 3
Training loss: 2.8232271556262747
Validation loss: 2.8632641800895935

Epoch: 6| Step: 4
Training loss: 3.2205834953525283
Validation loss: 2.860121582621394

Epoch: 6| Step: 5
Training loss: 3.5930655449596207
Validation loss: 2.858651241569869

Epoch: 6| Step: 6
Training loss: 2.6648872418909977
Validation loss: 2.8558610263131468

Epoch: 6| Step: 7
Training loss: 3.087409100758164
Validation loss: 2.8527874479859396

Epoch: 6| Step: 8
Training loss: 2.8779861864046086
Validation loss: 2.8509540483537408

Epoch: 6| Step: 9
Training loss: 2.5978035562380346
Validation loss: 2.8491767134763126

Epoch: 6| Step: 10
Training loss: 3.644429196219864
Validation loss: 2.8466685762183093

Epoch: 6| Step: 11
Training loss: 3.116574487665971
Validation loss: 2.84521876820903

Epoch: 6| Step: 12
Training loss: 2.7526987878180713
Validation loss: 2.8425076184692104

Epoch: 6| Step: 13
Training loss: 3.0053720060543903
Validation loss: 2.8408412099878073

Epoch: 50| Step: 0
Training loss: 3.215205342571056
Validation loss: 2.8386651855098766

Epoch: 6| Step: 1
Training loss: 2.810213303802082
Validation loss: 2.8364091731385472

Epoch: 6| Step: 2
Training loss: 3.269633046597036
Validation loss: 2.8342032826709245

Epoch: 6| Step: 3
Training loss: 2.9759825294145896
Validation loss: 2.833734222175235

Epoch: 6| Step: 4
Training loss: 2.4661329860547316
Validation loss: 2.8310133093338377

Epoch: 6| Step: 5
Training loss: 2.7451419401732213
Validation loss: 2.8302831687388776

Epoch: 6| Step: 6
Training loss: 3.011107386422131
Validation loss: 2.8275268371729503

Epoch: 6| Step: 7
Training loss: 3.32809763435969
Validation loss: 2.825551050730678

Epoch: 6| Step: 8
Training loss: 2.391428095740528
Validation loss: 2.8241576156928927

Epoch: 6| Step: 9
Training loss: 3.028304094149976
Validation loss: 2.8222080669231646

Epoch: 6| Step: 10
Training loss: 2.530786825118448
Validation loss: 2.8201509325520266

Epoch: 6| Step: 11
Training loss: 3.1471832275967673
Validation loss: 2.819877823489406

Epoch: 6| Step: 12
Training loss: 3.0157690458533537
Validation loss: 2.8171999902319627

Epoch: 6| Step: 13
Training loss: 3.423255398119158
Validation loss: 2.8149734358496863

Epoch: 51| Step: 0
Training loss: 2.897451392384008
Validation loss: 2.813684242437078

Epoch: 6| Step: 1
Training loss: 2.5389528221503976
Validation loss: 2.8121610083972906

Epoch: 6| Step: 2
Training loss: 3.073514942615055
Validation loss: 2.810192857280632

Epoch: 6| Step: 3
Training loss: 3.1015013104992106
Validation loss: 2.808628101519034

Epoch: 6| Step: 4
Training loss: 2.8728339286842384
Validation loss: 2.8099268268411435

Epoch: 6| Step: 5
Training loss: 3.3436466094102415
Validation loss: 2.8066411771621107

Epoch: 6| Step: 6
Training loss: 2.7764324511982807
Validation loss: 2.8049633064068593

Epoch: 6| Step: 7
Training loss: 2.58619619498834
Validation loss: 2.8024560522104034

Epoch: 6| Step: 8
Training loss: 2.8738029309841013
Validation loss: 2.8003766181245378

Epoch: 6| Step: 9
Training loss: 3.123738453856306
Validation loss: 2.7987534308288273

Epoch: 6| Step: 10
Training loss: 2.5960886879159006
Validation loss: 2.797313627376216

Epoch: 6| Step: 11
Training loss: 3.239775199155715
Validation loss: 2.7954600926898916

Epoch: 6| Step: 12
Training loss: 2.9247836562787266
Validation loss: 2.79342458424191

Epoch: 6| Step: 13
Training loss: 3.125775355471979
Validation loss: 2.792479387285228

Epoch: 52| Step: 0
Training loss: 2.5252626037011217
Validation loss: 2.7906029843113047

Epoch: 6| Step: 1
Training loss: 3.0263659270124834
Validation loss: 2.7883214028288106

Epoch: 6| Step: 2
Training loss: 3.332396152993128
Validation loss: 2.786462592481169

Epoch: 6| Step: 3
Training loss: 2.460038472006574
Validation loss: 2.784368602489881

Epoch: 6| Step: 4
Training loss: 3.5000662116191137
Validation loss: 2.7823615549655756

Epoch: 6| Step: 5
Training loss: 2.761152713938942
Validation loss: 2.780505963074957

Epoch: 6| Step: 6
Training loss: 2.803465000315789
Validation loss: 2.7793404671133746

Epoch: 6| Step: 7
Training loss: 3.0404793150639966
Validation loss: 2.775702240443332

Epoch: 6| Step: 8
Training loss: 2.588374991522813
Validation loss: 2.7766090132996792

Epoch: 6| Step: 9
Training loss: 2.6271999767847096
Validation loss: 2.776059683239691

Epoch: 6| Step: 10
Training loss: 2.5621429752892353
Validation loss: 2.775955260878197

Epoch: 6| Step: 11
Training loss: 3.2091466359996166
Validation loss: 2.773474543507657

Epoch: 6| Step: 12
Training loss: 3.4135563036492593
Validation loss: 2.7718786739194563

Epoch: 6| Step: 13
Training loss: 2.7501595190772288
Validation loss: 2.768228085297271

Epoch: 53| Step: 0
Training loss: 2.7758635749494167
Validation loss: 2.7650137044326706

Epoch: 6| Step: 1
Training loss: 2.6985964023121394
Validation loss: 2.761121743802382

Epoch: 6| Step: 2
Training loss: 2.9873795489046695
Validation loss: 2.760339719071741

Epoch: 6| Step: 3
Training loss: 3.258278792787431
Validation loss: 2.760665584833295

Epoch: 6| Step: 4
Training loss: 2.76376858060156
Validation loss: 2.760030371549526

Epoch: 6| Step: 5
Training loss: 3.3573710297378874
Validation loss: 2.760913031713772

Epoch: 6| Step: 6
Training loss: 2.930768355306475
Validation loss: 2.7596539193322926

Epoch: 6| Step: 7
Training loss: 3.078469504040066
Validation loss: 2.7566311244756743

Epoch: 6| Step: 8
Training loss: 2.9103721999364764
Validation loss: 2.755993525076219

Epoch: 6| Step: 9
Training loss: 2.912203361892934
Validation loss: 2.7524106701437514

Epoch: 6| Step: 10
Training loss: 2.952674791037926
Validation loss: 2.7508358335401777

Epoch: 6| Step: 11
Training loss: 2.355349510806029
Validation loss: 2.748582084283604

Epoch: 6| Step: 12
Training loss: 2.475665775493918
Validation loss: 2.7481781242024264

Epoch: 6| Step: 13
Training loss: 2.960261204767522
Validation loss: 2.747257743848372

Epoch: 54| Step: 0
Training loss: 2.9398291261802436
Validation loss: 2.747459177067404

Epoch: 6| Step: 1
Training loss: 3.1754897993858235
Validation loss: 2.746887294957315

Epoch: 6| Step: 2
Training loss: 3.0033901450837894
Validation loss: 2.7442694112257944

Epoch: 6| Step: 3
Training loss: 3.0495138625145577
Validation loss: 2.740486073642835

Epoch: 6| Step: 4
Training loss: 2.7839352792473617
Validation loss: 2.7378105887348405

Epoch: 6| Step: 5
Training loss: 2.8437801820599553
Validation loss: 2.7366935418823166

Epoch: 6| Step: 6
Training loss: 3.0067523623798413
Validation loss: 2.734766933871485

Epoch: 6| Step: 7
Training loss: 3.1803777072125676
Validation loss: 2.7337398408975147

Epoch: 6| Step: 8
Training loss: 2.5264383430620163
Validation loss: 2.7324437905614976

Epoch: 6| Step: 9
Training loss: 2.6791452465318413
Validation loss: 2.731087952323286

Epoch: 6| Step: 10
Training loss: 2.4843402596209985
Validation loss: 2.729877602577992

Epoch: 6| Step: 11
Training loss: 2.515979812904967
Validation loss: 2.728066657084466

Epoch: 6| Step: 12
Training loss: 3.2390100558608603
Validation loss: 2.726560139040212

Epoch: 6| Step: 13
Training loss: 2.703050292642
Validation loss: 2.7246996355317

Epoch: 55| Step: 0
Training loss: 2.7135210286610714
Validation loss: 2.723620134198523

Epoch: 6| Step: 1
Training loss: 2.685060502832223
Validation loss: 2.720773857093657

Epoch: 6| Step: 2
Training loss: 2.7638166302085745
Validation loss: 2.7199145194487477

Epoch: 6| Step: 3
Training loss: 2.6592080194965173
Validation loss: 2.719161780732239

Epoch: 6| Step: 4
Training loss: 2.3490329457096375
Validation loss: 2.717635251387415

Epoch: 6| Step: 5
Training loss: 2.7022326104413397
Validation loss: 2.7166885804148664

Epoch: 6| Step: 6
Training loss: 2.9700261635703615
Validation loss: 2.715026732208366

Epoch: 6| Step: 7
Training loss: 3.3099774526421646
Validation loss: 2.714769087023191

Epoch: 6| Step: 8
Training loss: 2.7127668820770685
Validation loss: 2.7130153802172576

Epoch: 6| Step: 9
Training loss: 3.1246751234937005
Validation loss: 2.7102275068897197

Epoch: 6| Step: 10
Training loss: 2.9206199194359668
Validation loss: 2.707142382198867

Epoch: 6| Step: 11
Training loss: 2.8545357866902137
Validation loss: 2.707653860297704

Epoch: 6| Step: 12
Training loss: 3.015048115158156
Validation loss: 2.705470733979662

Epoch: 6| Step: 13
Training loss: 3.069213981280977
Validation loss: 2.705651295299823

Epoch: 56| Step: 0
Training loss: 3.041572848053232
Validation loss: 2.7043147179309135

Epoch: 6| Step: 1
Training loss: 2.4041466375494003
Validation loss: 2.70386033539511

Epoch: 6| Step: 2
Training loss: 3.1925705615007374
Validation loss: 2.7028307157348044

Epoch: 6| Step: 3
Training loss: 2.5219752560036213
Validation loss: 2.7007773022213155

Epoch: 6| Step: 4
Training loss: 2.8943210376181194
Validation loss: 2.7007604705420194

Epoch: 6| Step: 5
Training loss: 3.0509244174553705
Validation loss: 2.699354110393171

Epoch: 6| Step: 6
Training loss: 2.8986309634726433
Validation loss: 2.6958894858390967

Epoch: 6| Step: 7
Training loss: 2.930178018831944
Validation loss: 2.696094285302969

Epoch: 6| Step: 8
Training loss: 3.1839313351497145
Validation loss: 2.692381085715918

Epoch: 6| Step: 9
Training loss: 2.269072967324427
Validation loss: 2.6899450106714067

Epoch: 6| Step: 10
Training loss: 2.8002033568513696
Validation loss: 2.6880260514537175

Epoch: 6| Step: 11
Training loss: 2.8642796210919657
Validation loss: 2.6862825548919074

Epoch: 6| Step: 12
Training loss: 2.901949910978416
Validation loss: 2.6866714767700124

Epoch: 6| Step: 13
Training loss: 2.5906965367801793
Validation loss: 2.684044131522113

Epoch: 57| Step: 0
Training loss: 2.9945118295152775
Validation loss: 2.6845832936331675

Epoch: 6| Step: 1
Training loss: 2.3518447453126425
Validation loss: 2.684762795399311

Epoch: 6| Step: 2
Training loss: 3.104536883574523
Validation loss: 2.6811726331478636

Epoch: 6| Step: 3
Training loss: 2.896836653602728
Validation loss: 2.6810268024654333

Epoch: 6| Step: 4
Training loss: 2.362172066670545
Validation loss: 2.677574043473016

Epoch: 6| Step: 5
Training loss: 2.7380078406434127
Validation loss: 2.6796015659859367

Epoch: 6| Step: 6
Training loss: 2.983502005669591
Validation loss: 2.6786359349309645

Epoch: 6| Step: 7
Training loss: 2.591131520191833
Validation loss: 2.676719155879661

Epoch: 6| Step: 8
Training loss: 2.9741476681238677
Validation loss: 2.6766101750516573

Epoch: 6| Step: 9
Training loss: 2.721163588182659
Validation loss: 2.675998190742835

Epoch: 6| Step: 10
Training loss: 2.7540664950884715
Validation loss: 2.6757701567259784

Epoch: 6| Step: 11
Training loss: 2.9219631242977484
Validation loss: 2.673152417445236

Epoch: 6| Step: 12
Training loss: 2.917961559771931
Validation loss: 2.671116979794959

Epoch: 6| Step: 13
Training loss: 3.007365404067817
Validation loss: 2.6689729378558518

Epoch: 58| Step: 0
Training loss: 3.0993515320843477
Validation loss: 2.66742889616995

Epoch: 6| Step: 1
Training loss: 2.8385090584004806
Validation loss: 2.6665087792226805

Epoch: 6| Step: 2
Training loss: 2.428839532494762
Validation loss: 2.6656865812331074

Epoch: 6| Step: 3
Training loss: 2.7913624232364462
Validation loss: 2.665123751440818

Epoch: 6| Step: 4
Training loss: 2.6588608420671487
Validation loss: 2.664150083711203

Epoch: 6| Step: 5
Training loss: 2.9193071311488556
Validation loss: 2.6656346012731142

Epoch: 6| Step: 6
Training loss: 2.53603316130753
Validation loss: 2.668571601402162

Epoch: 6| Step: 7
Training loss: 2.701285469496629
Validation loss: 2.6626276681107424

Epoch: 6| Step: 8
Training loss: 2.9497710058267925
Validation loss: 2.6582680460009005

Epoch: 6| Step: 9
Training loss: 2.9961364026869437
Validation loss: 2.6604753882594787

Epoch: 6| Step: 10
Training loss: 2.8039973267829548
Validation loss: 2.6600443349217295

Epoch: 6| Step: 11
Training loss: 2.7022262578579954
Validation loss: 2.6589124762218654

Epoch: 6| Step: 12
Training loss: 2.9289554749526956
Validation loss: 2.657132574323748

Epoch: 6| Step: 13
Training loss: 2.8485146315903447
Validation loss: 2.6573903796080818

Epoch: 59| Step: 0
Training loss: 2.931726666635853
Validation loss: 2.656199802597552

Epoch: 6| Step: 1
Training loss: 3.12151661325018
Validation loss: 2.653158378316226

Epoch: 6| Step: 2
Training loss: 2.1891605069359747
Validation loss: 2.651592314864802

Epoch: 6| Step: 3
Training loss: 2.8407966452799793
Validation loss: 2.6506232860211547

Epoch: 6| Step: 4
Training loss: 2.588209738579721
Validation loss: 2.6487197500520505

Epoch: 6| Step: 5
Training loss: 3.2060569184522394
Validation loss: 2.646594100873391

Epoch: 6| Step: 6
Training loss: 2.156828319007927
Validation loss: 2.646918739999316

Epoch: 6| Step: 7
Training loss: 3.0695203385289007
Validation loss: 2.643539896523084

Epoch: 6| Step: 8
Training loss: 2.529021612676098
Validation loss: 2.6442091805348156

Epoch: 6| Step: 9
Training loss: 2.6474658004958105
Validation loss: 2.642168079487575

Epoch: 6| Step: 10
Training loss: 3.0759170281340236
Validation loss: 2.6421561532743136

Epoch: 6| Step: 11
Training loss: 2.638003340145654
Validation loss: 2.641938554348146

Epoch: 6| Step: 12
Training loss: 3.129994025910255
Validation loss: 2.6391803770087603

Epoch: 6| Step: 13
Training loss: 2.629218571831166
Validation loss: 2.638873826926452

Epoch: 60| Step: 0
Training loss: 2.5245525152433808
Validation loss: 2.639674555510162

Epoch: 6| Step: 1
Training loss: 2.571354709805735
Validation loss: 2.6399068213164174

Epoch: 6| Step: 2
Training loss: 2.642642181815548
Validation loss: 2.6400221638760604

Epoch: 6| Step: 3
Training loss: 2.842392146631843
Validation loss: 2.640141715643582

Epoch: 6| Step: 4
Training loss: 2.8205840172929433
Validation loss: 2.6400511379539147

Epoch: 6| Step: 5
Training loss: 2.884601151846961
Validation loss: 2.6392583828178346

Epoch: 6| Step: 6
Training loss: 2.9843986470349146
Validation loss: 2.635371080891383

Epoch: 6| Step: 7
Training loss: 2.5303894275505923
Validation loss: 2.635571250352379

Epoch: 6| Step: 8
Training loss: 2.8721644474648818
Validation loss: 2.631781371429159

Epoch: 6| Step: 9
Training loss: 2.783732217390169
Validation loss: 2.6298958369273815

Epoch: 6| Step: 10
Training loss: 3.1194460533578026
Validation loss: 2.627296896070663

Epoch: 6| Step: 11
Training loss: 2.896467253826674
Validation loss: 2.629726695665632

Epoch: 6| Step: 12
Training loss: 2.551882262321189
Validation loss: 2.634820325324627

Epoch: 6| Step: 13
Training loss: 2.7108141076756427
Validation loss: 2.6241014395883466

Epoch: 61| Step: 0
Training loss: 2.7068991360483414
Validation loss: 2.6244720957522567

Epoch: 6| Step: 1
Training loss: 2.439328021712079
Validation loss: 2.628668824915331

Epoch: 6| Step: 2
Training loss: 2.3528415585214435
Validation loss: 2.6265605798669287

Epoch: 6| Step: 3
Training loss: 3.1927249943276195
Validation loss: 2.639075492373689

Epoch: 6| Step: 4
Training loss: 2.70049020767626
Validation loss: 2.643825570207071

Epoch: 6| Step: 5
Training loss: 2.828835413945876
Validation loss: 2.6361601664064724

Epoch: 6| Step: 6
Training loss: 2.775930224693287
Validation loss: 2.622263897806644

Epoch: 6| Step: 7
Training loss: 2.5162113998946833
Validation loss: 2.6216696851664065

Epoch: 6| Step: 8
Training loss: 3.0198587533622807
Validation loss: 2.6170727908679217

Epoch: 6| Step: 9
Training loss: 2.75847498903592
Validation loss: 2.6216106028381505

Epoch: 6| Step: 10
Training loss: 2.860203357215865
Validation loss: 2.6199255821224927

Epoch: 6| Step: 11
Training loss: 2.973301179680648
Validation loss: 2.621809397904669

Epoch: 6| Step: 12
Training loss: 2.9611724518733937
Validation loss: 2.6204445229597106

Epoch: 6| Step: 13
Training loss: 2.50103709644015
Validation loss: 2.6202718144326966

Epoch: 62| Step: 0
Training loss: 2.7884322450753536
Validation loss: 2.620124376125761

Epoch: 6| Step: 1
Training loss: 2.5185905652192027
Validation loss: 2.6152666169226273

Epoch: 6| Step: 2
Training loss: 2.939792631192973
Validation loss: 2.6118923234939397

Epoch: 6| Step: 3
Training loss: 3.2398992713529204
Validation loss: 2.612033335059707

Epoch: 6| Step: 4
Training loss: 2.627838688879926
Validation loss: 2.6112261694950942

Epoch: 6| Step: 5
Training loss: 3.146356922222754
Validation loss: 2.6084644914340127

Epoch: 6| Step: 6
Training loss: 2.466765753156311
Validation loss: 2.607911558043139

Epoch: 6| Step: 7
Training loss: 3.2385437862421615
Validation loss: 2.6047668884298076

Epoch: 6| Step: 8
Training loss: 2.67890015537729
Validation loss: 2.604245151608643

Epoch: 6| Step: 9
Training loss: 2.0432534830858793
Validation loss: 2.604467898430674

Epoch: 6| Step: 10
Training loss: 2.8045274269094524
Validation loss: 2.6057602215586892

Epoch: 6| Step: 11
Training loss: 2.9557869030303063
Validation loss: 2.6038688387635904

Epoch: 6| Step: 12
Training loss: 2.3157018198303247
Validation loss: 2.6014230135161536

Epoch: 6| Step: 13
Training loss: 2.4671602562915544
Validation loss: 2.6051012015377637

Epoch: 63| Step: 0
Training loss: 2.7487694848286384
Validation loss: 2.6069148681562555

Epoch: 6| Step: 1
Training loss: 2.7447496057481082
Validation loss: 2.6032871795727806

Epoch: 6| Step: 2
Training loss: 2.431918772526791
Validation loss: 2.6049421198559637

Epoch: 6| Step: 3
Training loss: 1.9694071081819442
Validation loss: 2.6006386064330704

Epoch: 6| Step: 4
Training loss: 3.3625419415549036
Validation loss: 2.6116210499301213

Epoch: 6| Step: 5
Training loss: 3.29025515137985
Validation loss: 2.608750137160937

Epoch: 6| Step: 6
Training loss: 2.8708487685129573
Validation loss: 2.6036690707059087

Epoch: 6| Step: 7
Training loss: 2.752413904019842
Validation loss: 2.5945851923140184

Epoch: 6| Step: 8
Training loss: 2.527805197803421
Validation loss: 2.5951371983671296

Epoch: 6| Step: 9
Training loss: 2.5725177244534105
Validation loss: 2.597056200520291

Epoch: 6| Step: 10
Training loss: 3.298560990516061
Validation loss: 2.5963184401420922

Epoch: 6| Step: 11
Training loss: 2.308065647712207
Validation loss: 2.600086377616383

Epoch: 6| Step: 12
Training loss: 2.7590045892028137
Validation loss: 2.601281747570792

Epoch: 6| Step: 13
Training loss: 2.4812164381241275
Validation loss: 2.600232980755646

Epoch: 64| Step: 0
Training loss: 3.0923014630891092
Validation loss: 2.5976508042510273

Epoch: 6| Step: 1
Training loss: 3.1316754567941762
Validation loss: 2.5956171354962634

Epoch: 6| Step: 2
Training loss: 3.099054586160581
Validation loss: 2.592676959544662

Epoch: 6| Step: 3
Training loss: 2.800895656659167
Validation loss: 2.588304863171572

Epoch: 6| Step: 4
Training loss: 2.4612624180966285
Validation loss: 2.590205286720129

Epoch: 6| Step: 5
Training loss: 2.53648550866287
Validation loss: 2.5951167569265734

Epoch: 6| Step: 6
Training loss: 2.510203899901279
Validation loss: 2.594546245626189

Epoch: 6| Step: 7
Training loss: 2.6447201186652998
Validation loss: 2.5935764637693204

Epoch: 6| Step: 8
Training loss: 2.4795246880870145
Validation loss: 2.5903237014622196

Epoch: 6| Step: 9
Training loss: 2.629476907585544
Validation loss: 2.587828959564046

Epoch: 6| Step: 10
Training loss: 2.3914632885775213
Validation loss: 2.5851287191674825

Epoch: 6| Step: 11
Training loss: 2.4542933312086466
Validation loss: 2.5842833669178304

Epoch: 6| Step: 12
Training loss: 2.9512324652015582
Validation loss: 2.5813121169330984

Epoch: 6| Step: 13
Training loss: 2.8754943754313285
Validation loss: 2.5826832866097833

Epoch: 65| Step: 0
Training loss: 3.0998375080960487
Validation loss: 2.58326327833945

Epoch: 6| Step: 1
Training loss: 2.4814271532135135
Validation loss: 2.5817215003176135

Epoch: 6| Step: 2
Training loss: 2.5489076331588576
Validation loss: 2.5809540918428673

Epoch: 6| Step: 3
Training loss: 2.252370645109108
Validation loss: 2.5805687006011166

Epoch: 6| Step: 4
Training loss: 3.170617366325142
Validation loss: 2.581397174460356

Epoch: 6| Step: 5
Training loss: 2.787235462996279
Validation loss: 2.5821887115927487

Epoch: 6| Step: 6
Training loss: 2.519078886837479
Validation loss: 2.5796158458509524

Epoch: 6| Step: 7
Training loss: 2.5895283364562856
Validation loss: 2.5778802158246408

Epoch: 6| Step: 8
Training loss: 3.1084958467791717
Validation loss: 2.575067282850108

Epoch: 6| Step: 9
Training loss: 3.006498292436215
Validation loss: 2.573432489701786

Epoch: 6| Step: 10
Training loss: 2.1621741032753943
Validation loss: 2.5704978404525454

Epoch: 6| Step: 11
Training loss: 2.278592586803473
Validation loss: 2.570264775259225

Epoch: 6| Step: 12
Training loss: 3.1253997547048256
Validation loss: 2.570844060008847

Epoch: 6| Step: 13
Training loss: 2.5735075319786573
Validation loss: 2.5688816404992036

Epoch: 66| Step: 0
Training loss: 2.8137397576801937
Validation loss: 2.5686198944902916

Epoch: 6| Step: 1
Training loss: 2.528676644061266
Validation loss: 2.5710965615845116

Epoch: 6| Step: 2
Training loss: 2.1824303873502777
Validation loss: 2.572732746382112

Epoch: 6| Step: 3
Training loss: 2.1441086316201967
Validation loss: 2.570442606097924

Epoch: 6| Step: 4
Training loss: 3.003604313194276
Validation loss: 2.5694316216455286

Epoch: 6| Step: 5
Training loss: 2.928258603365002
Validation loss: 2.5679996833296013

Epoch: 6| Step: 6
Training loss: 2.898346521641137
Validation loss: 2.5650505770331384

Epoch: 6| Step: 7
Training loss: 2.8859579815677345
Validation loss: 2.5642654881006672

Epoch: 6| Step: 8
Training loss: 2.6499951488522444
Validation loss: 2.567764936729855

Epoch: 6| Step: 9
Training loss: 2.6990782153233095
Validation loss: 2.5663603725813275

Epoch: 6| Step: 10
Training loss: 2.6102710944095087
Validation loss: 2.5681140932414896

Epoch: 6| Step: 11
Training loss: 3.2181022510772825
Validation loss: 2.5675823704359297

Epoch: 6| Step: 12
Training loss: 2.7750853035677365
Validation loss: 2.5703331541644188

Epoch: 6| Step: 13
Training loss: 2.395385788843329
Validation loss: 2.568848073901672

Epoch: 67| Step: 0
Training loss: 2.8405656697169683
Validation loss: 2.5694505508167

Epoch: 6| Step: 1
Training loss: 2.22168762876328
Validation loss: 2.568233263523968

Epoch: 6| Step: 2
Training loss: 2.2616369466531974
Validation loss: 2.568392507051724

Epoch: 6| Step: 3
Training loss: 2.625057583131902
Validation loss: 2.5651149123429877

Epoch: 6| Step: 4
Training loss: 3.1750582051386185
Validation loss: 2.5652315188839716

Epoch: 6| Step: 5
Training loss: 2.6340287565893337
Validation loss: 2.563589965249588

Epoch: 6| Step: 6
Training loss: 2.763863385038636
Validation loss: 2.563923200178185

Epoch: 6| Step: 7
Training loss: 2.9542691068190403
Validation loss: 2.561286576945249

Epoch: 6| Step: 8
Training loss: 2.6462059859920757
Validation loss: 2.5618604621806647

Epoch: 6| Step: 9
Training loss: 2.716838822634016
Validation loss: 2.563121014839751

Epoch: 6| Step: 10
Training loss: 2.2723308373534006
Validation loss: 2.5622479539676264

Epoch: 6| Step: 11
Training loss: 2.6286914845410134
Validation loss: 2.5629933510350646

Epoch: 6| Step: 12
Training loss: 2.964982543430757
Validation loss: 2.5612699921626554

Epoch: 6| Step: 13
Training loss: 2.926831941680928
Validation loss: 2.5615728143026195

Epoch: 68| Step: 0
Training loss: 2.539306065541259
Validation loss: 2.5590564882027165

Epoch: 6| Step: 1
Training loss: 2.8260451619939473
Validation loss: 2.559372800298979

Epoch: 6| Step: 2
Training loss: 2.763917816325958
Validation loss: 2.5569818209291704

Epoch: 6| Step: 3
Training loss: 2.6077900715863995
Validation loss: 2.555518292302818

Epoch: 6| Step: 4
Training loss: 2.4185199756313933
Validation loss: 2.5539620523394304

Epoch: 6| Step: 5
Training loss: 2.2796406752213776
Validation loss: 2.5529584409312327

Epoch: 6| Step: 6
Training loss: 2.7092394168988854
Validation loss: 2.5518931545060566

Epoch: 6| Step: 7
Training loss: 2.7652323815922855
Validation loss: 2.5530464586731743

Epoch: 6| Step: 8
Training loss: 2.9162940922693275
Validation loss: 2.554271442469314

Epoch: 6| Step: 9
Training loss: 2.4340410387878464
Validation loss: 2.5557162889667033

Epoch: 6| Step: 10
Training loss: 2.969759317786311
Validation loss: 2.553048030668923

Epoch: 6| Step: 11
Training loss: 2.496475405461316
Validation loss: 2.5521325450486185

Epoch: 6| Step: 12
Training loss: 2.794059316421912
Validation loss: 2.5490567900101997

Epoch: 6| Step: 13
Training loss: 3.091893110868033
Validation loss: 2.5482180434053623

Epoch: 69| Step: 0
Training loss: 2.955619283417731
Validation loss: 2.5486767096628014

Epoch: 6| Step: 1
Training loss: 2.6848534260954917
Validation loss: 2.5485013671955157

Epoch: 6| Step: 2
Training loss: 3.060823877162297
Validation loss: 2.5485752179987515

Epoch: 6| Step: 3
Training loss: 2.4589863141622614
Validation loss: 2.547467917482699

Epoch: 6| Step: 4
Training loss: 2.903600325748117
Validation loss: 2.5481402914789024

Epoch: 6| Step: 5
Training loss: 2.1816504605446374
Validation loss: 2.545724558236393

Epoch: 6| Step: 6
Training loss: 2.4839349512929356
Validation loss: 2.547161499634552

Epoch: 6| Step: 7
Training loss: 2.3635523112564387
Validation loss: 2.5462595502212046

Epoch: 6| Step: 8
Training loss: 2.5587512251753637
Validation loss: 2.544013836524131

Epoch: 6| Step: 9
Training loss: 2.8581613768817933
Validation loss: 2.5446088183109423

Epoch: 6| Step: 10
Training loss: 2.6285374738443066
Validation loss: 2.544100726768644

Epoch: 6| Step: 11
Training loss: 3.015832291035728
Validation loss: 2.543388710952298

Epoch: 6| Step: 12
Training loss: 2.6702733286422577
Validation loss: 2.5470846515013306

Epoch: 6| Step: 13
Training loss: 2.5183087362337466
Validation loss: 2.5437466495626193

Epoch: 70| Step: 0
Training loss: 2.437982560343403
Validation loss: 2.542192284896652

Epoch: 6| Step: 1
Training loss: 2.485684991140894
Validation loss: 2.540799342105646

Epoch: 6| Step: 2
Training loss: 2.877775428244058
Validation loss: 2.5396484794324303

Epoch: 6| Step: 3
Training loss: 2.6885781010894885
Validation loss: 2.5415260609575117

Epoch: 6| Step: 4
Training loss: 2.7523242491725077
Validation loss: 2.537766909537989

Epoch: 6| Step: 5
Training loss: 2.383816166856098
Validation loss: 2.537688524230335

Epoch: 6| Step: 6
Training loss: 2.5666352377449417
Validation loss: 2.5377203108135316

Epoch: 6| Step: 7
Training loss: 2.744508722670543
Validation loss: 2.5396828074658533

Epoch: 6| Step: 8
Training loss: 2.907614110936187
Validation loss: 2.5387102870693123

Epoch: 6| Step: 9
Training loss: 2.7638683020135466
Validation loss: 2.5362886271536373

Epoch: 6| Step: 10
Training loss: 2.8709867911624563
Validation loss: 2.5376062687261647

Epoch: 6| Step: 11
Training loss: 2.4861497597795186
Validation loss: 2.5406745840116267

Epoch: 6| Step: 12
Training loss: 2.397119215717648
Validation loss: 2.539777997269851

Epoch: 6| Step: 13
Training loss: 2.9371478904555888
Validation loss: 2.541774940269059

Epoch: 71| Step: 0
Training loss: 2.6325473368881767
Validation loss: 2.5395050445664764

Epoch: 6| Step: 1
Training loss: 2.3565592352927096
Validation loss: 2.5388079549891285

Epoch: 6| Step: 2
Training loss: 2.711212056353055
Validation loss: 2.5387528529011063

Epoch: 6| Step: 3
Training loss: 2.765972051020025
Validation loss: 2.537438696009555

Epoch: 6| Step: 4
Training loss: 2.8439828965951057
Validation loss: 2.534855727304393

Epoch: 6| Step: 5
Training loss: 2.732160619825792
Validation loss: 2.531089181069136

Epoch: 6| Step: 6
Training loss: 2.8190738568057654
Validation loss: 2.5296138451896057

Epoch: 6| Step: 7
Training loss: 2.900425807341329
Validation loss: 2.5325117537842985

Epoch: 6| Step: 8
Training loss: 2.561577793814236
Validation loss: 2.5365461116278745

Epoch: 6| Step: 9
Training loss: 2.7715679045893418
Validation loss: 2.540001798163551

Epoch: 6| Step: 10
Training loss: 2.8698997038751606
Validation loss: 2.545962757331648

Epoch: 6| Step: 11
Training loss: 2.941958351551011
Validation loss: 2.5452677173862757

Epoch: 6| Step: 12
Training loss: 2.1625316727804957
Validation loss: 2.5429500612352496

Epoch: 6| Step: 13
Training loss: 2.2534962087751262
Validation loss: 2.5438761305722237

Epoch: 72| Step: 0
Training loss: 3.0055168606125418
Validation loss: 2.546922070901015

Epoch: 6| Step: 1
Training loss: 2.18369430829083
Validation loss: 2.547600484855942

Epoch: 6| Step: 2
Training loss: 2.274809852450778
Validation loss: 2.5420087104736164

Epoch: 6| Step: 3
Training loss: 2.9213984299682734
Validation loss: 2.543259564484386

Epoch: 6| Step: 4
Training loss: 2.7327296074868985
Validation loss: 2.546415463044858

Epoch: 6| Step: 5
Training loss: 2.911417315381249
Validation loss: 2.544406615232402

Epoch: 6| Step: 6
Training loss: 2.3887567138577523
Validation loss: 2.537182108693292

Epoch: 6| Step: 7
Training loss: 2.077694037932147
Validation loss: 2.531220848009817

Epoch: 6| Step: 8
Training loss: 2.276880338182456
Validation loss: 2.5250914893870644

Epoch: 6| Step: 9
Training loss: 2.5710986943807383
Validation loss: 2.527950585458775

Epoch: 6| Step: 10
Training loss: 2.5080934171116396
Validation loss: 2.5286586196738523

Epoch: 6| Step: 11
Training loss: 3.5054152693557326
Validation loss: 2.5283919474430014

Epoch: 6| Step: 12
Training loss: 2.3036865129586954
Validation loss: 2.529381238789708

Epoch: 6| Step: 13
Training loss: 3.027316185610398
Validation loss: 2.530715336473642

Epoch: 73| Step: 0
Training loss: 2.9049202122457958
Validation loss: 2.531371266792208

Epoch: 6| Step: 1
Training loss: 2.55456999995578
Validation loss: 2.5317632837633552

Epoch: 6| Step: 2
Training loss: 2.387865555823696
Validation loss: 2.5307343825146322

Epoch: 6| Step: 3
Training loss: 3.045452392246101
Validation loss: 2.5285614083388928

Epoch: 6| Step: 4
Training loss: 2.688727165206782
Validation loss: 2.527225387450877

Epoch: 6| Step: 5
Training loss: 2.640156992232476
Validation loss: 2.5263448841283735

Epoch: 6| Step: 6
Training loss: 2.5722164071138405
Validation loss: 2.527463718497262

Epoch: 6| Step: 7
Training loss: 2.421542237094012
Validation loss: 2.5249050821272134

Epoch: 6| Step: 8
Training loss: 2.1050871041368855
Validation loss: 2.5196064624846626

Epoch: 6| Step: 9
Training loss: 2.0514438103816834
Validation loss: 2.5187145319004056

Epoch: 6| Step: 10
Training loss: 2.8617482160154615
Validation loss: 2.518311655349722

Epoch: 6| Step: 11
Training loss: 3.125186456839759
Validation loss: 2.5228696406607294

Epoch: 6| Step: 12
Training loss: 2.856003905531406
Validation loss: 2.5265479350648263

Epoch: 6| Step: 13
Training loss: 2.639440778833555
Validation loss: 2.5343597367748605

Epoch: 74| Step: 0
Training loss: 2.527583728463714
Validation loss: 2.5353412374551634

Epoch: 6| Step: 1
Training loss: 2.7733431088140796
Validation loss: 2.537228858254522

Epoch: 6| Step: 2
Training loss: 2.6788480906432377
Validation loss: 2.5350631751641144

Epoch: 6| Step: 3
Training loss: 1.9145132974206176
Validation loss: 2.5336681636171354

Epoch: 6| Step: 4
Training loss: 2.2856975729365376
Validation loss: 2.534053411749332

Epoch: 6| Step: 5
Training loss: 3.2218975491849284
Validation loss: 2.5333054913279156

Epoch: 6| Step: 6
Training loss: 2.812979847981956
Validation loss: 2.533151093210616

Epoch: 6| Step: 7
Training loss: 2.6713504387872966
Validation loss: 2.53632614971495

Epoch: 6| Step: 8
Training loss: 2.31296843861884
Validation loss: 2.528758262913684

Epoch: 6| Step: 9
Training loss: 2.4497949631200004
Validation loss: 2.53277164609053

Epoch: 6| Step: 10
Training loss: 2.853596836947524
Validation loss: 2.5299565970677182

Epoch: 6| Step: 11
Training loss: 2.8034905985182514
Validation loss: 2.5294660710481454

Epoch: 6| Step: 12
Training loss: 2.208977143590341
Validation loss: 2.529008838645661

Epoch: 6| Step: 13
Training loss: 3.284554116748514
Validation loss: 2.5301594680919264

Epoch: 75| Step: 0
Training loss: 2.7848518280115897
Validation loss: 2.5296722487048218

Epoch: 6| Step: 1
Training loss: 2.5593444188937733
Validation loss: 2.5285841793213986

Epoch: 6| Step: 2
Training loss: 2.055222474281732
Validation loss: 2.5288525833062283

Epoch: 6| Step: 3
Training loss: 2.7406982551275467
Validation loss: 2.529014620748612

Epoch: 6| Step: 4
Training loss: 2.7897367116647684
Validation loss: 2.5259042027355463

Epoch: 6| Step: 5
Training loss: 2.257871950416214
Validation loss: 2.523721700594379

Epoch: 6| Step: 6
Training loss: 2.3149384709991145
Validation loss: 2.526940747479042

Epoch: 6| Step: 7
Training loss: 2.825977838125619
Validation loss: 2.5240743677848076

Epoch: 6| Step: 8
Training loss: 2.6640352040791426
Validation loss: 2.5216874470036275

Epoch: 6| Step: 9
Training loss: 3.3587891533588694
Validation loss: 2.5319183628898676

Epoch: 6| Step: 10
Training loss: 2.7393332731083393
Validation loss: 2.5254631454939607

Epoch: 6| Step: 11
Training loss: 2.867820399642295
Validation loss: 2.518512766404014

Epoch: 6| Step: 12
Training loss: 2.769846221704091
Validation loss: 2.52458578936171

Epoch: 6| Step: 13
Training loss: 2.3223028925928393
Validation loss: 2.520692795127812

Epoch: 76| Step: 0
Training loss: 2.429549529153875
Validation loss: 2.518464020616525

Epoch: 6| Step: 1
Training loss: 2.51875110938566
Validation loss: 2.519809047160159

Epoch: 6| Step: 2
Training loss: 2.319602883486494
Validation loss: 2.514389872173918

Epoch: 6| Step: 3
Training loss: 2.773983238147571
Validation loss: 2.510258259398782

Epoch: 6| Step: 4
Training loss: 2.3243482024742366
Validation loss: 2.5076346883988347

Epoch: 6| Step: 5
Training loss: 2.319354646306122
Validation loss: 2.5116677444681828

Epoch: 6| Step: 6
Training loss: 2.604229908493158
Validation loss: 2.5128821352829056

Epoch: 6| Step: 7
Training loss: 3.070255346955333
Validation loss: 2.5163821350603386

Epoch: 6| Step: 8
Training loss: 2.660832032170402
Validation loss: 2.510691668589379

Epoch: 6| Step: 9
Training loss: 2.524687371870742
Validation loss: 2.5109286808412135

Epoch: 6| Step: 10
Training loss: 2.449852187699729
Validation loss: 2.5091704181080163

Epoch: 6| Step: 11
Training loss: 2.797540851802683
Validation loss: 2.5112317979227963

Epoch: 6| Step: 12
Training loss: 2.9974096559172123
Validation loss: 2.5110363386728474

Epoch: 6| Step: 13
Training loss: 3.0601130934616436
Validation loss: 2.5099708245647436

Epoch: 77| Step: 0
Training loss: 2.1053124760824087
Validation loss: 2.5070996405225583

Epoch: 6| Step: 1
Training loss: 2.6023915662355024
Validation loss: 2.504746778535902

Epoch: 6| Step: 2
Training loss: 2.7481954028802447
Validation loss: 2.5055753844783584

Epoch: 6| Step: 3
Training loss: 2.6499642891546986
Validation loss: 2.505352441736504

Epoch: 6| Step: 4
Training loss: 2.901262330863549
Validation loss: 2.505043822747193

Epoch: 6| Step: 5
Training loss: 2.502538060252326
Validation loss: 2.505372013658637

Epoch: 6| Step: 6
Training loss: 2.3710433728366933
Validation loss: 2.5058637674976523

Epoch: 6| Step: 7
Training loss: 2.520720066857195
Validation loss: 2.503090886880907

Epoch: 6| Step: 8
Training loss: 2.0065236983374373
Validation loss: 2.5049311483873997

Epoch: 6| Step: 9
Training loss: 3.4537930079794554
Validation loss: 2.504880797823467

Epoch: 6| Step: 10
Training loss: 2.9919254995036355
Validation loss: 2.5061895361604387

Epoch: 6| Step: 11
Training loss: 2.4086701743850627
Validation loss: 2.509604411012654

Epoch: 6| Step: 12
Training loss: 2.8478119733013134
Validation loss: 2.517157172934583

Epoch: 6| Step: 13
Training loss: 2.4965639343143
Validation loss: 2.520230328867345

Epoch: 78| Step: 0
Training loss: 2.466733084463204
Validation loss: 2.510781706127189

Epoch: 6| Step: 1
Training loss: 2.4992059400253432
Validation loss: 2.5057951199664914

Epoch: 6| Step: 2
Training loss: 1.9494559042464434
Validation loss: 2.505178603367981

Epoch: 6| Step: 3
Training loss: 2.9578167818081793
Validation loss: 2.505530946596149

Epoch: 6| Step: 4
Training loss: 2.942666724706988
Validation loss: 2.504231813147233

Epoch: 6| Step: 5
Training loss: 2.6226710933007316
Validation loss: 2.5021557573249082

Epoch: 6| Step: 6
Training loss: 2.7463531588668224
Validation loss: 2.5020420000112207

Epoch: 6| Step: 7
Training loss: 2.936634341988277
Validation loss: 2.5035299652207925

Epoch: 6| Step: 8
Training loss: 2.609428268163015
Validation loss: 2.5035492022056167

Epoch: 6| Step: 9
Training loss: 2.608441762732193
Validation loss: 2.5041525526701593

Epoch: 6| Step: 10
Training loss: 2.4940719893771712
Validation loss: 2.5042767659726053

Epoch: 6| Step: 11
Training loss: 2.8228943226810927
Validation loss: 2.503829105833315

Epoch: 6| Step: 12
Training loss: 2.898866524009589
Validation loss: 2.504048708921333

Epoch: 6| Step: 13
Training loss: 1.9746215095486754
Validation loss: 2.504210582058226

Epoch: 79| Step: 0
Training loss: 2.334022374821414
Validation loss: 2.5025330902919922

Epoch: 6| Step: 1
Training loss: 2.4338401314572704
Validation loss: 2.502794436480363

Epoch: 6| Step: 2
Training loss: 3.3462771554043833
Validation loss: 2.502248674615753

Epoch: 6| Step: 3
Training loss: 2.8238136771335505
Validation loss: 2.498280776473926

Epoch: 6| Step: 4
Training loss: 2.633163655122059
Validation loss: 2.5018522712258946

Epoch: 6| Step: 5
Training loss: 2.480110971675205
Validation loss: 2.498984361019813

Epoch: 6| Step: 6
Training loss: 2.336218571418338
Validation loss: 2.4980249232445377

Epoch: 6| Step: 7
Training loss: 2.155008815738498
Validation loss: 2.4979868730780943

Epoch: 6| Step: 8
Training loss: 2.2950662770393837
Validation loss: 2.4979737176390593

Epoch: 6| Step: 9
Training loss: 2.822539995313881
Validation loss: 2.493994971204234

Epoch: 6| Step: 10
Training loss: 3.037569046805575
Validation loss: 2.49847392552081

Epoch: 6| Step: 11
Training loss: 2.2403869842990303
Validation loss: 2.495035503366737

Epoch: 6| Step: 12
Training loss: 2.8070403619411843
Validation loss: 2.4946569407698416

Epoch: 6| Step: 13
Training loss: 2.6418883783179052
Validation loss: 2.4948394600916615

Epoch: 80| Step: 0
Training loss: 2.9265878785230033
Validation loss: 2.496837873186816

Epoch: 6| Step: 1
Training loss: 2.880122886526146
Validation loss: 2.4995411054331025

Epoch: 6| Step: 2
Training loss: 2.223138471964206
Validation loss: 2.5000115076435994

Epoch: 6| Step: 3
Training loss: 2.466672771893068
Validation loss: 2.4973059125244497

Epoch: 6| Step: 4
Training loss: 3.0194977712810926
Validation loss: 2.5017768744180944

Epoch: 6| Step: 5
Training loss: 2.621178524732817
Validation loss: 2.5009466921943937

Epoch: 6| Step: 6
Training loss: 2.2816114792466804
Validation loss: 2.5039095509111107

Epoch: 6| Step: 7
Training loss: 2.6067139539632778
Validation loss: 2.503922326030889

Epoch: 6| Step: 8
Training loss: 2.7631794089720256
Validation loss: 2.5059757180880693

Epoch: 6| Step: 9
Training loss: 2.8520101117547374
Validation loss: 2.508841599542557

Epoch: 6| Step: 10
Training loss: 2.2337357466914844
Validation loss: 2.508271259562113

Epoch: 6| Step: 11
Training loss: 2.298591024638216
Validation loss: 2.5101466106186576

Epoch: 6| Step: 12
Training loss: 2.6516469228294386
Validation loss: 2.5105736763845536

Epoch: 6| Step: 13
Training loss: 2.706086052912775
Validation loss: 2.51009327769627

Epoch: 81| Step: 0
Training loss: 2.757373461478676
Validation loss: 2.5083955461342393

Epoch: 6| Step: 1
Training loss: 2.927484523299017
Validation loss: 2.5102166113277815

Epoch: 6| Step: 2
Training loss: 2.2789359701819105
Validation loss: 2.507450438098704

Epoch: 6| Step: 3
Training loss: 1.9540479386734377
Validation loss: 2.508523810453288

Epoch: 6| Step: 4
Training loss: 1.9672582515146468
Validation loss: 2.5105132457680277

Epoch: 6| Step: 5
Training loss: 2.9518982291938145
Validation loss: 2.506602818490945

Epoch: 6| Step: 6
Training loss: 2.7561964968377906
Validation loss: 2.504122434617917

Epoch: 6| Step: 7
Training loss: 2.601043374444607
Validation loss: 2.5023820813598063

Epoch: 6| Step: 8
Training loss: 2.7334863581117266
Validation loss: 2.504025445046091

Epoch: 6| Step: 9
Training loss: 2.6847568085002735
Validation loss: 2.5043615124685714

Epoch: 6| Step: 10
Training loss: 2.4106581302944607
Validation loss: 2.501663433439676

Epoch: 6| Step: 11
Training loss: 2.7159202143055734
Validation loss: 2.501911958092235

Epoch: 6| Step: 12
Training loss: 2.5465084818532677
Validation loss: 2.5045925078739355

Epoch: 6| Step: 13
Training loss: 3.0854686525761807
Validation loss: 2.5041205304085503

Epoch: 82| Step: 0
Training loss: 2.3430156320204287
Validation loss: 2.5018945191284487

Epoch: 6| Step: 1
Training loss: 2.8896905161793494
Validation loss: 2.502789832196812

Epoch: 6| Step: 2
Training loss: 2.3814556323397023
Validation loss: 2.500459708227037

Epoch: 6| Step: 3
Training loss: 2.7417592640770088
Validation loss: 2.5038509114816097

Epoch: 6| Step: 4
Training loss: 2.3921214886308824
Validation loss: 2.5031771180961484

Epoch: 6| Step: 5
Training loss: 2.7026795477777372
Validation loss: 2.5036875866865076

Epoch: 6| Step: 6
Training loss: 2.692432401724137
Validation loss: 2.4992045408582118

Epoch: 6| Step: 7
Training loss: 2.457093545824442
Validation loss: 2.500261158018132

Epoch: 6| Step: 8
Training loss: 2.5394487762061866
Validation loss: 2.5005606976216823

Epoch: 6| Step: 9
Training loss: 3.1835997411753443
Validation loss: 2.5007953650153567

Epoch: 6| Step: 10
Training loss: 2.3893794386550824
Validation loss: 2.4997270991466713

Epoch: 6| Step: 11
Training loss: 1.7017143777229478
Validation loss: 2.4966649857970804

Epoch: 6| Step: 12
Training loss: 3.164206268435119
Validation loss: 2.499329961949813

Epoch: 6| Step: 13
Training loss: 2.686774399855748
Validation loss: 2.4961230893666864

Epoch: 83| Step: 0
Training loss: 2.6641882366142084
Validation loss: 2.4973194533605785

Epoch: 6| Step: 1
Training loss: 2.7026296172699156
Validation loss: 2.499877950550144

Epoch: 6| Step: 2
Training loss: 2.574626791861416
Validation loss: 2.5016853215002595

Epoch: 6| Step: 3
Training loss: 2.570189499158471
Validation loss: 2.4992320152694645

Epoch: 6| Step: 4
Training loss: 3.139036469567595
Validation loss: 2.495868957299259

Epoch: 6| Step: 5
Training loss: 2.8246169277845103
Validation loss: 2.494056120705294

Epoch: 6| Step: 6
Training loss: 2.937884366475517
Validation loss: 2.4950423834748574

Epoch: 6| Step: 7
Training loss: 2.219887884934662
Validation loss: 2.4928648216607106

Epoch: 6| Step: 8
Training loss: 2.787977675492214
Validation loss: 2.495286344304727

Epoch: 6| Step: 9
Training loss: 2.6795556394648337
Validation loss: 2.496569210611211

Epoch: 6| Step: 10
Training loss: 2.3135638496289257
Validation loss: 2.4952535314565205

Epoch: 6| Step: 11
Training loss: 2.511435105606524
Validation loss: 2.496493900961149

Epoch: 6| Step: 12
Training loss: 2.3046841896162666
Validation loss: 2.4936858548970875

Epoch: 6| Step: 13
Training loss: 2.1148019561752758
Validation loss: 2.493881112510496

Epoch: 84| Step: 0
Training loss: 2.9384554668568117
Validation loss: 2.4956466919194855

Epoch: 6| Step: 1
Training loss: 2.7175308651123236
Validation loss: 2.4895265538166496

Epoch: 6| Step: 2
Training loss: 2.154280052914829
Validation loss: 2.5073823807559545

Epoch: 6| Step: 3
Training loss: 2.811569738189006
Validation loss: 2.497942729704748

Epoch: 6| Step: 4
Training loss: 3.5242163903159356
Validation loss: 2.4973263430880293

Epoch: 6| Step: 5
Training loss: 2.844769976121271
Validation loss: 2.4959876287165965

Epoch: 6| Step: 6
Training loss: 2.5326364746677292
Validation loss: 2.4977518940959365

Epoch: 6| Step: 7
Training loss: 2.66672344942037
Validation loss: 2.492161701830211

Epoch: 6| Step: 8
Training loss: 2.550320967875332
Validation loss: 2.4955050431383174

Epoch: 6| Step: 9
Training loss: 2.483399781569141
Validation loss: 2.494770947226308

Epoch: 6| Step: 10
Training loss: 2.0696706100666318
Validation loss: 2.4940171814882173

Epoch: 6| Step: 11
Training loss: 2.2795087884163303
Validation loss: 2.494190889677

Epoch: 6| Step: 12
Training loss: 2.0579486683114885
Validation loss: 2.4996276260252555

Epoch: 6| Step: 13
Training loss: 2.6753528112746032
Validation loss: 2.4940406502462564

Epoch: 85| Step: 0
Training loss: 2.8531526495271695
Validation loss: 2.494909874352817

Epoch: 6| Step: 1
Training loss: 2.5357367228660888
Validation loss: 2.4965064434424473

Epoch: 6| Step: 2
Training loss: 2.070870263162467
Validation loss: 2.4933052705351684

Epoch: 6| Step: 3
Training loss: 2.3250410917198936
Validation loss: 2.4928908835324295

Epoch: 6| Step: 4
Training loss: 2.6426949598560157
Validation loss: 2.4911786053258034

Epoch: 6| Step: 5
Training loss: 2.5597331298367583
Validation loss: 2.491669907030871

Epoch: 6| Step: 6
Training loss: 2.5249579133407045
Validation loss: 2.4919111682597435

Epoch: 6| Step: 7
Training loss: 2.2866206245495193
Validation loss: 2.4901854666101997

Epoch: 6| Step: 8
Training loss: 2.579999022964174
Validation loss: 2.4919698335149403

Epoch: 6| Step: 9
Training loss: 2.5776901340749103
Validation loss: 2.490449983325974

Epoch: 6| Step: 10
Training loss: 2.3710433728366933
Validation loss: 2.485816265597071

Epoch: 6| Step: 11
Training loss: 3.2320633888260373
Validation loss: 2.486424670226602

Epoch: 6| Step: 12
Training loss: 3.0194382350950977
Validation loss: 2.4874908293741913

Epoch: 6| Step: 13
Training loss: 2.81665393517982
Validation loss: 2.4860679488339374

Epoch: 86| Step: 0
Training loss: 2.638832160830747
Validation loss: 2.487979026178595

Epoch: 6| Step: 1
Training loss: 2.937102595292415
Validation loss: 2.4885938958017313

Epoch: 6| Step: 2
Training loss: 2.9585215190796603
Validation loss: 2.4873408402430446

Epoch: 6| Step: 3
Training loss: 2.3839337821891253
Validation loss: 2.4878506929228883

Epoch: 6| Step: 4
Training loss: 2.783416589949842
Validation loss: 2.488355211309524

Epoch: 6| Step: 5
Training loss: 2.443749851704859
Validation loss: 2.4881394214622627

Epoch: 6| Step: 6
Training loss: 2.6398044191508596
Validation loss: 2.4890889164986962

Epoch: 6| Step: 7
Training loss: 2.838537784305449
Validation loss: 2.4862003138739626

Epoch: 6| Step: 8
Training loss: 2.4902708522144565
Validation loss: 2.484539226486152

Epoch: 6| Step: 9
Training loss: 2.662461322628862
Validation loss: 2.4829788923673544

Epoch: 6| Step: 10
Training loss: 2.52234883637132
Validation loss: 2.483924920920841

Epoch: 6| Step: 11
Training loss: 2.4492212809621092
Validation loss: 2.4791320723569616

Epoch: 6| Step: 12
Training loss: 2.41638318953316
Validation loss: 2.4848755066412798

Epoch: 6| Step: 13
Training loss: 2.1016245552742734
Validation loss: 2.4871359943786535

Epoch: 87| Step: 0
Training loss: 2.236751972661929
Validation loss: 2.483041881466681

Epoch: 6| Step: 1
Training loss: 2.3891096111714702
Validation loss: 2.4823786233795206

Epoch: 6| Step: 2
Training loss: 2.515877468163832
Validation loss: 2.485741405477446

Epoch: 6| Step: 3
Training loss: 2.6424740970320046
Validation loss: 2.4827496792156034

Epoch: 6| Step: 4
Training loss: 2.648964978468632
Validation loss: 2.479168696896873

Epoch: 6| Step: 5
Training loss: 2.4890997721628696
Validation loss: 2.482892455791545

Epoch: 6| Step: 6
Training loss: 2.3664304825860305
Validation loss: 2.4824112622554173

Epoch: 6| Step: 7
Training loss: 2.7055124312908156
Validation loss: 2.481865917411099

Epoch: 6| Step: 8
Training loss: 2.53621224861758
Validation loss: 2.4826578567835482

Epoch: 6| Step: 9
Training loss: 3.1047300983764514
Validation loss: 2.484357293983559

Epoch: 6| Step: 10
Training loss: 2.7735667023987416
Validation loss: 2.4869013802445106

Epoch: 6| Step: 11
Training loss: 2.837068190466771
Validation loss: 2.4802080152549575

Epoch: 6| Step: 12
Training loss: 2.3728101573034746
Validation loss: 2.480987222306747

Epoch: 6| Step: 13
Training loss: 2.5254087513850636
Validation loss: 2.484006698467296

Epoch: 88| Step: 0
Training loss: 2.5174287762079843
Validation loss: 2.484396280641402

Epoch: 6| Step: 1
Training loss: 2.504362496215588
Validation loss: 2.48218540653091

Epoch: 6| Step: 2
Training loss: 2.592703090941873
Validation loss: 2.484751131067141

Epoch: 6| Step: 3
Training loss: 2.62261845774803
Validation loss: 2.4813171537778156

Epoch: 6| Step: 4
Training loss: 2.203684201526751
Validation loss: 2.483491720571964

Epoch: 6| Step: 5
Training loss: 2.7252120469210452
Validation loss: 2.479245823042608

Epoch: 6| Step: 6
Training loss: 2.7965504548575053
Validation loss: 2.482320275717458

Epoch: 6| Step: 7
Training loss: 2.2347802281548526
Validation loss: 2.480368192141284

Epoch: 6| Step: 8
Training loss: 2.643868435129973
Validation loss: 2.4752921487512367

Epoch: 6| Step: 9
Training loss: 2.4742081579590534
Validation loss: 2.4765263102521637

Epoch: 6| Step: 10
Training loss: 2.7431624980526865
Validation loss: 2.475726310366771

Epoch: 6| Step: 11
Training loss: 2.747788320170573
Validation loss: 2.4755295485595856

Epoch: 6| Step: 12
Training loss: 2.9103353355656276
Validation loss: 2.4740758018044517

Epoch: 6| Step: 13
Training loss: 2.4403888505111677
Validation loss: 2.4714947343302396

Epoch: 89| Step: 0
Training loss: 2.5368062954978816
Validation loss: 2.470376295906284

Epoch: 6| Step: 1
Training loss: 2.881938688177976
Validation loss: 2.4696621718635012

Epoch: 6| Step: 2
Training loss: 2.30926369694357
Validation loss: 2.4719050081266594

Epoch: 6| Step: 3
Training loss: 2.2885139511113217
Validation loss: 2.4733403501471067

Epoch: 6| Step: 4
Training loss: 2.3263307352215055
Validation loss: 2.4692793813730614

Epoch: 6| Step: 5
Training loss: 2.358621843391193
Validation loss: 2.4785882344493455

Epoch: 6| Step: 6
Training loss: 2.3041085243362445
Validation loss: 2.4758789691637406

Epoch: 6| Step: 7
Training loss: 2.742243665679702
Validation loss: 2.4752903668422594

Epoch: 6| Step: 8
Training loss: 3.099000117343483
Validation loss: 2.476782699727453

Epoch: 6| Step: 9
Training loss: 3.083269651288014
Validation loss: 2.485331736987069

Epoch: 6| Step: 10
Training loss: 2.9739499779543217
Validation loss: 2.4813868067746525

Epoch: 6| Step: 11
Training loss: 1.8572306088266994
Validation loss: 2.4824993242517057

Epoch: 6| Step: 12
Training loss: 2.8128858513534
Validation loss: 2.475360052975334

Epoch: 6| Step: 13
Training loss: 2.282893385815145
Validation loss: 2.4748978982280967

Epoch: 90| Step: 0
Training loss: 2.5381625884202825
Validation loss: 2.4757752716676005

Epoch: 6| Step: 1
Training loss: 2.759639664223389
Validation loss: 2.476461799571875

Epoch: 6| Step: 2
Training loss: 2.371870488701552
Validation loss: 2.470934693914753

Epoch: 6| Step: 3
Training loss: 2.208615327020585
Validation loss: 2.475975986027368

Epoch: 6| Step: 4
Training loss: 2.4992667076420103
Validation loss: 2.475858112850194

Epoch: 6| Step: 5
Training loss: 1.8401551843591355
Validation loss: 2.477196404710696

Epoch: 6| Step: 6
Training loss: 2.5182161432749353
Validation loss: 2.476505860524361

Epoch: 6| Step: 7
Training loss: 2.1615474697868295
Validation loss: 2.4783822001924385

Epoch: 6| Step: 8
Training loss: 1.9483486519312763
Validation loss: 2.4787536699168804

Epoch: 6| Step: 9
Training loss: 2.962085672369478
Validation loss: 2.477599591698765

Epoch: 6| Step: 10
Training loss: 2.994389373738428
Validation loss: 2.4766849684092533

Epoch: 6| Step: 11
Training loss: 3.1161624303358013
Validation loss: 2.4754112287340813

Epoch: 6| Step: 12
Training loss: 2.7849049073563674
Validation loss: 2.474148300640653

Epoch: 6| Step: 13
Training loss: 3.0615695396249736
Validation loss: 2.473511670932979

Epoch: 91| Step: 0
Training loss: 3.0173022097764868
Validation loss: 2.4702492358579686

Epoch: 6| Step: 1
Training loss: 2.0706784482736618
Validation loss: 2.4742931795222627

Epoch: 6| Step: 2
Training loss: 2.713914802850102
Validation loss: 2.4747238072505278

Epoch: 6| Step: 3
Training loss: 2.679556529233779
Validation loss: 2.471007409538657

Epoch: 6| Step: 4
Training loss: 2.600343802536107
Validation loss: 2.4735902104133447

Epoch: 6| Step: 5
Training loss: 2.878114754558142
Validation loss: 2.4716295277160434

Epoch: 6| Step: 6
Training loss: 2.181092824437666
Validation loss: 2.4745547783621418

Epoch: 6| Step: 7
Training loss: 2.5837549870428598
Validation loss: 2.4751766751869835

Epoch: 6| Step: 8
Training loss: 2.5521068545963805
Validation loss: 2.4766396992842337

Epoch: 6| Step: 9
Training loss: 2.720057206113285
Validation loss: 2.4800524104384416

Epoch: 6| Step: 10
Training loss: 2.8951201258164945
Validation loss: 2.481055210900954

Epoch: 6| Step: 11
Training loss: 2.754281352584655
Validation loss: 2.479873257341434

Epoch: 6| Step: 12
Training loss: 2.6586451783027663
Validation loss: 2.480854074581304

Epoch: 6| Step: 13
Training loss: 1.4210530514837318
Validation loss: 2.4808445683324107

Epoch: 92| Step: 0
Training loss: 2.9379168275573306
Validation loss: 2.479610536947773

Epoch: 6| Step: 1
Training loss: 2.105904443846237
Validation loss: 2.4825627656898424

Epoch: 6| Step: 2
Training loss: 2.4165096780057107
Validation loss: 2.4811277620455625

Epoch: 6| Step: 3
Training loss: 2.8398014364540223
Validation loss: 2.4852831798006947

Epoch: 6| Step: 4
Training loss: 2.3706006915341926
Validation loss: 2.482266168840926

Epoch: 6| Step: 5
Training loss: 2.8243620903393727
Validation loss: 2.482246190619154

Epoch: 6| Step: 6
Training loss: 2.286927044097208
Validation loss: 2.486918189348105

Epoch: 6| Step: 7
Training loss: 2.596397611253927
Validation loss: 2.4858730605920893

Epoch: 6| Step: 8
Training loss: 2.1125384310324655
Validation loss: 2.481419835015518

Epoch: 6| Step: 9
Training loss: 2.786091137991203
Validation loss: 2.478742183814692

Epoch: 6| Step: 10
Training loss: 2.1917811326376158
Validation loss: 2.4793014943835265

Epoch: 6| Step: 11
Training loss: 3.536987504802761
Validation loss: 2.480383787927816

Epoch: 6| Step: 12
Training loss: 2.434530552410488
Validation loss: 2.4799082525776632

Epoch: 6| Step: 13
Training loss: 2.457482325353541
Validation loss: 2.475906469697998

Epoch: 93| Step: 0
Training loss: 2.4108974609214795
Validation loss: 2.480016247583306

Epoch: 6| Step: 1
Training loss: 2.537280305268549
Validation loss: 2.474485872474105

Epoch: 6| Step: 2
Training loss: 2.144595063585518
Validation loss: 2.477240324272447

Epoch: 6| Step: 3
Training loss: 2.8432132088559916
Validation loss: 2.4737576105438612

Epoch: 6| Step: 4
Training loss: 2.70333420489666
Validation loss: 2.4756221008669033

Epoch: 6| Step: 5
Training loss: 2.4520387613615
Validation loss: 2.4776300562196307

Epoch: 6| Step: 6
Training loss: 2.7672388572816606
Validation loss: 2.474007902485349

Epoch: 6| Step: 7
Training loss: 2.9479437693146413
Validation loss: 2.473793093868352

Epoch: 6| Step: 8
Training loss: 1.976569496112248
Validation loss: 2.4793560345771137

Epoch: 6| Step: 9
Training loss: 2.5815095821766523
Validation loss: 2.475560271301245

Epoch: 6| Step: 10
Training loss: 2.8499706266796876
Validation loss: 2.479822806609062

Epoch: 6| Step: 11
Training loss: 2.567776156155859
Validation loss: 2.4806075009764963

Epoch: 6| Step: 12
Training loss: 2.5088959727184004
Validation loss: 2.475941143849301

Epoch: 6| Step: 13
Training loss: 2.591096922957564
Validation loss: 2.4813541624304274

Epoch: 94| Step: 0
Training loss: 2.796411657047325
Validation loss: 2.4797191618652916

Epoch: 6| Step: 1
Training loss: 2.5023788578311073
Validation loss: 2.477317221732183

Epoch: 6| Step: 2
Training loss: 2.3299627027678067
Validation loss: 2.4837634615508537

Epoch: 6| Step: 3
Training loss: 2.2985356354655204
Validation loss: 2.4749689601146283

Epoch: 6| Step: 4
Training loss: 2.623464589436337
Validation loss: 2.4827415646630064

Epoch: 6| Step: 5
Training loss: 3.1035489656111115
Validation loss: 2.4812628808956365

Epoch: 6| Step: 6
Training loss: 2.0421397640658694
Validation loss: 2.4812559145353275

Epoch: 6| Step: 7
Training loss: 2.40836053412717
Validation loss: 2.478433473877408

Epoch: 6| Step: 8
Training loss: 2.877613372557861
Validation loss: 2.473924902974513

Epoch: 6| Step: 9
Training loss: 2.8720691503206592
Validation loss: 2.474123526964032

Epoch: 6| Step: 10
Training loss: 2.03235537456673
Validation loss: 2.4733758876546585

Epoch: 6| Step: 11
Training loss: 2.4053857415481845
Validation loss: 2.4755220203061064

Epoch: 6| Step: 12
Training loss: 2.8013665134450663
Validation loss: 2.475802749278825

Epoch: 6| Step: 13
Training loss: 2.7765022644825113
Validation loss: 2.47438518388783

Epoch: 95| Step: 0
Training loss: 2.8835628535771134
Validation loss: 2.4736842167559914

Epoch: 6| Step: 1
Training loss: 2.6825162231864863
Validation loss: 2.4739511322452077

Epoch: 6| Step: 2
Training loss: 2.2120024471855766
Validation loss: 2.4763604451736163

Epoch: 6| Step: 3
Training loss: 2.618606956781411
Validation loss: 2.474669462024957

Epoch: 6| Step: 4
Training loss: 3.0599211130383046
Validation loss: 2.478530262492279

Epoch: 6| Step: 5
Training loss: 2.5508314422763254
Validation loss: 2.4805560479609206

Epoch: 6| Step: 6
Training loss: 2.5182929256116715
Validation loss: 2.4760822267678053

Epoch: 6| Step: 7
Training loss: 2.4540934017970164
Validation loss: 2.472657824892946

Epoch: 6| Step: 8
Training loss: 2.3574147955180567
Validation loss: 2.471200917473196

Epoch: 6| Step: 9
Training loss: 2.7528578040787974
Validation loss: 2.4729298484941546

Epoch: 6| Step: 10
Training loss: 2.9169367710567147
Validation loss: 2.47008748582972

Epoch: 6| Step: 11
Training loss: 2.2567512103443357
Validation loss: 2.467335307723029

Epoch: 6| Step: 12
Training loss: 2.0905295129246992
Validation loss: 2.4684514537197475

Epoch: 6| Step: 13
Training loss: 2.59135657496621
Validation loss: 2.4684317822327153

Epoch: 96| Step: 0
Training loss: 2.587028158169545
Validation loss: 2.4713727403002417

Epoch: 6| Step: 1
Training loss: 1.9838924271738265
Validation loss: 2.4683041874231373

Epoch: 6| Step: 2
Training loss: 2.6870166432610927
Validation loss: 2.469363349662428

Epoch: 6| Step: 3
Training loss: 1.9203628545852667
Validation loss: 2.464229356030464

Epoch: 6| Step: 4
Training loss: 2.810608800188627
Validation loss: 2.466431216867862

Epoch: 6| Step: 5
Training loss: 2.213200250362711
Validation loss: 2.4701886391517522

Epoch: 6| Step: 6
Training loss: 2.7560676912319013
Validation loss: 2.4680695702646185

Epoch: 6| Step: 7
Training loss: 2.901140705566287
Validation loss: 2.4675555498440067

Epoch: 6| Step: 8
Training loss: 2.5863464585279443
Validation loss: 2.4744784052794184

Epoch: 6| Step: 9
Training loss: 2.5919943693300005
Validation loss: 2.4731305206394025

Epoch: 6| Step: 10
Training loss: 3.214751788060455
Validation loss: 2.4826466208265665

Epoch: 6| Step: 11
Training loss: 2.4655016037845443
Validation loss: 2.462552891726403

Epoch: 6| Step: 12
Training loss: 2.5103759973378996
Validation loss: 2.4723174800689405

Epoch: 6| Step: 13
Training loss: 2.831558251179336
Validation loss: 2.4710974497993035

Epoch: 97| Step: 0
Training loss: 2.852236148222487
Validation loss: 2.472744812064899

Epoch: 6| Step: 1
Training loss: 2.336200916148175
Validation loss: 2.4759247577452816

Epoch: 6| Step: 2
Training loss: 3.404603752797381
Validation loss: 2.479059126201799

Epoch: 6| Step: 3
Training loss: 2.024284038425709
Validation loss: 2.478629676513426

Epoch: 6| Step: 4
Training loss: 1.9663046530605224
Validation loss: 2.4827299769719

Epoch: 6| Step: 5
Training loss: 2.5281686748414764
Validation loss: 2.4763486912288304

Epoch: 6| Step: 6
Training loss: 2.927298830907868
Validation loss: 2.48104707479041

Epoch: 6| Step: 7
Training loss: 1.772681995404953
Validation loss: 2.476971276659978

Epoch: 6| Step: 8
Training loss: 2.5024063926666344
Validation loss: 2.4820065995127862

Epoch: 6| Step: 9
Training loss: 2.9998178426753515
Validation loss: 2.4811050439958677

Epoch: 6| Step: 10
Training loss: 2.7969857305845354
Validation loss: 2.4806436952588236

Epoch: 6| Step: 11
Training loss: 2.200146548852094
Validation loss: 2.4794935817646975

Epoch: 6| Step: 12
Training loss: 2.8217876940430306
Validation loss: 2.480276465785217

Epoch: 6| Step: 13
Training loss: 2.5960776673793715
Validation loss: 2.4789520993597693

Epoch: 98| Step: 0
Training loss: 2.2725630189322166
Validation loss: 2.4808588637308064

Epoch: 6| Step: 1
Training loss: 2.7692733235635276
Validation loss: 2.4821814844093075

Epoch: 6| Step: 2
Training loss: 2.82703551493501
Validation loss: 2.4861635371907496

Epoch: 6| Step: 3
Training loss: 2.330085696826025
Validation loss: 2.4836889475316797

Epoch: 6| Step: 4
Training loss: 2.3314279769581483
Validation loss: 2.4825178038287463

Epoch: 6| Step: 5
Training loss: 2.793273140919576
Validation loss: 2.4847853379691243

Epoch: 6| Step: 6
Training loss: 2.6335701687056097
Validation loss: 2.480122763866432

Epoch: 6| Step: 7
Training loss: 2.3913991833906127
Validation loss: 2.4788054569085625

Epoch: 6| Step: 8
Training loss: 2.5629846998361576
Validation loss: 2.4741932700519156

Epoch: 6| Step: 9
Training loss: 2.6450737491126084
Validation loss: 2.4777721896296248

Epoch: 6| Step: 10
Training loss: 2.6295474490555817
Validation loss: 2.4760476268096903

Epoch: 6| Step: 11
Training loss: 2.6457653687726506
Validation loss: 2.474802814039677

Epoch: 6| Step: 12
Training loss: 2.6538673036427873
Validation loss: 2.4751652206477637

Epoch: 6| Step: 13
Training loss: 2.6036467579972684
Validation loss: 2.4716742535725693

Epoch: 99| Step: 0
Training loss: 2.5396706190330924
Validation loss: 2.4713529393173297

Epoch: 6| Step: 1
Training loss: 3.0063112946604233
Validation loss: 2.4736354791220494

Epoch: 6| Step: 2
Training loss: 3.2698395468633388
Validation loss: 2.4713474403560474

Epoch: 6| Step: 3
Training loss: 2.2907127707034265
Validation loss: 2.4693808735390053

Epoch: 6| Step: 4
Training loss: 2.719735679405725
Validation loss: 2.4660972474954046

Epoch: 6| Step: 5
Training loss: 2.1794219043214493
Validation loss: 2.4672895529998673

Epoch: 6| Step: 6
Training loss: 2.6520447597610186
Validation loss: 2.467680767952571

Epoch: 6| Step: 7
Training loss: 2.6696303905445675
Validation loss: 2.46877169700134

Epoch: 6| Step: 8
Training loss: 2.243946408996925
Validation loss: 2.466352916644765

Epoch: 6| Step: 9
Training loss: 2.147477368911671
Validation loss: 2.4675594630060824

Epoch: 6| Step: 10
Training loss: 2.4616729121902705
Validation loss: 2.4641443742507647

Epoch: 6| Step: 11
Training loss: 2.60071941839659
Validation loss: 2.469067436444755

Epoch: 6| Step: 12
Training loss: 2.445735419510568
Validation loss: 2.469136751036403

Epoch: 6| Step: 13
Training loss: 2.474887028437426
Validation loss: 2.465484761487236

Epoch: 100| Step: 0
Training loss: 2.6560419337742553
Validation loss: 2.4590591932352

Epoch: 6| Step: 1
Training loss: 2.064396997300514
Validation loss: 2.4702570858136226

Epoch: 6| Step: 2
Training loss: 2.5461162536881385
Validation loss: 2.458720473070339

Epoch: 6| Step: 3
Training loss: 2.9064024198207554
Validation loss: 2.4624219827185896

Epoch: 6| Step: 4
Training loss: 2.6245902513686485
Validation loss: 2.4623164597480494

Epoch: 6| Step: 5
Training loss: 2.7547196722288634
Validation loss: 2.4598631274646956

Epoch: 6| Step: 6
Training loss: 3.09041438759208
Validation loss: 2.462449254321527

Epoch: 6| Step: 7
Training loss: 2.349842037816936
Validation loss: 2.469568479040723

Epoch: 6| Step: 8
Training loss: 2.2256188250024582
Validation loss: 2.4705904285325895

Epoch: 6| Step: 9
Training loss: 3.004248154408454
Validation loss: 2.470084493635933

Epoch: 6| Step: 10
Training loss: 2.766218563544173
Validation loss: 2.469691970037905

Epoch: 6| Step: 11
Training loss: 2.491463391571903
Validation loss: 2.4688799538189827

Epoch: 6| Step: 12
Training loss: 2.0297248396401173
Validation loss: 2.470311407466601

Epoch: 6| Step: 13
Training loss: 2.2631106400896774
Validation loss: 2.4716536913544265

Epoch: 101| Step: 0
Training loss: 2.324062823025895
Validation loss: 2.472103296114969

Epoch: 6| Step: 1
Training loss: 3.186127310987634
Validation loss: 2.469651633006251

Epoch: 6| Step: 2
Training loss: 2.5240016814406125
Validation loss: 2.4694649992884643

Epoch: 6| Step: 3
Training loss: 2.5541939448216677
Validation loss: 2.4649242099822923

Epoch: 6| Step: 4
Training loss: 2.1961757279562044
Validation loss: 2.461984466187646

Epoch: 6| Step: 5
Training loss: 2.0051705757318405
Validation loss: 2.461062844934299

Epoch: 6| Step: 6
Training loss: 3.5970492933054503
Validation loss: 2.4603381037517478

Epoch: 6| Step: 7
Training loss: 2.343723347830232
Validation loss: 2.4663872176040083

Epoch: 6| Step: 8
Training loss: 2.694471941367392
Validation loss: 2.4564290888162783

Epoch: 6| Step: 9
Training loss: 2.349229840632076
Validation loss: 2.464417498811697

Epoch: 6| Step: 10
Training loss: 2.747841855164236
Validation loss: 2.4625017795459496

Epoch: 6| Step: 11
Training loss: 2.4305977542180974
Validation loss: 2.459338343733684

Epoch: 6| Step: 12
Training loss: 2.3602984307606056
Validation loss: 2.458986782792912

Epoch: 6| Step: 13
Training loss: 2.1969344368459893
Validation loss: 2.4619257481666006

Epoch: 102| Step: 0
Training loss: 2.056450845017311
Validation loss: 2.4586870510134813

Epoch: 6| Step: 1
Training loss: 2.794975616130342
Validation loss: 2.4633080665426466

Epoch: 6| Step: 2
Training loss: 3.191313313843418
Validation loss: 2.4585852466974005

Epoch: 6| Step: 3
Training loss: 2.7801909412703787
Validation loss: 2.4595407710420107

Epoch: 6| Step: 4
Training loss: 1.9450217033489403
Validation loss: 2.4646495454417265

Epoch: 6| Step: 5
Training loss: 2.5518850651752043
Validation loss: 2.4601766227491595

Epoch: 6| Step: 6
Training loss: 2.3464827818061016
Validation loss: 2.4627311830391334

Epoch: 6| Step: 7
Training loss: 2.9300442491125986
Validation loss: 2.456512380212518

Epoch: 6| Step: 8
Training loss: 2.378626514142251
Validation loss: 2.455602734986579

Epoch: 6| Step: 9
Training loss: 2.511041956439743
Validation loss: 2.4580209716800283

Epoch: 6| Step: 10
Training loss: 2.874337824983157
Validation loss: 2.4539555401058437

Epoch: 6| Step: 11
Training loss: 2.659878485205817
Validation loss: 2.4559847367363274

Epoch: 6| Step: 12
Training loss: 2.410709262015139
Validation loss: 2.462132110482662

Epoch: 6| Step: 13
Training loss: 2.1736783012863037
Validation loss: 2.4627031723350035

Epoch: 103| Step: 0
Training loss: 2.808152292757002
Validation loss: 2.464126635748663

Epoch: 6| Step: 1
Training loss: 2.5657583780502233
Validation loss: 2.4635046350600565

Epoch: 6| Step: 2
Training loss: 3.3618173636640796
Validation loss: 2.4661758297496084

Epoch: 6| Step: 3
Training loss: 2.375494453759324
Validation loss: 2.465662091406902

Epoch: 6| Step: 4
Training loss: 2.639652321347263
Validation loss: 2.465479313906161

Epoch: 6| Step: 5
Training loss: 2.5392658797752783
Validation loss: 2.4698986165994152

Epoch: 6| Step: 6
Training loss: 2.0380062714649623
Validation loss: 2.4662582925024537

Epoch: 6| Step: 7
Training loss: 2.295741937090824
Validation loss: 2.464055212796663

Epoch: 6| Step: 8
Training loss: 2.332289484956399
Validation loss: 2.4612141933003184

Epoch: 6| Step: 9
Training loss: 2.3410563948664955
Validation loss: 2.462424451698627

Epoch: 6| Step: 10
Training loss: 2.025864607290915
Validation loss: 2.4636469543625665

Epoch: 6| Step: 11
Training loss: 2.7468870056376042
Validation loss: 2.457419020675823

Epoch: 6| Step: 12
Training loss: 2.8378899528990944
Validation loss: 2.464219971089831

Epoch: 6| Step: 13
Training loss: 2.622562912003636
Validation loss: 2.459722568199133

Epoch: 104| Step: 0
Training loss: 3.117495872904746
Validation loss: 2.4587106953879534

Epoch: 6| Step: 1
Training loss: 2.6867258598142607
Validation loss: 2.4587520442140267

Epoch: 6| Step: 2
Training loss: 2.455406440140899
Validation loss: 2.4590192473678147

Epoch: 6| Step: 3
Training loss: 2.919572545209439
Validation loss: 2.463388391179708

Epoch: 6| Step: 4
Training loss: 2.8523331110392007
Validation loss: 2.4628911896921024

Epoch: 6| Step: 5
Training loss: 2.2900191771857856
Validation loss: 2.468442656302412

Epoch: 6| Step: 6
Training loss: 2.720597089137482
Validation loss: 2.4703566397467993

Epoch: 6| Step: 7
Training loss: 2.194732480789275
Validation loss: 2.4623228825936554

Epoch: 6| Step: 8
Training loss: 2.185569783517673
Validation loss: 2.4607329914353047

Epoch: 6| Step: 9
Training loss: 2.2766157134885714
Validation loss: 2.4620924484911395

Epoch: 6| Step: 10
Training loss: 2.479215819141379
Validation loss: 2.461646842652884

Epoch: 6| Step: 11
Training loss: 2.5742282896197954
Validation loss: 2.4577741525758188

Epoch: 6| Step: 12
Training loss: 2.5438292844821304
Validation loss: 2.4609548255270166

Epoch: 6| Step: 13
Training loss: 2.4163401701038434
Validation loss: 2.460099270272717

Epoch: 105| Step: 0
Training loss: 2.393637261586929
Validation loss: 2.4594644972122044

Epoch: 6| Step: 1
Training loss: 2.7036163236364272
Validation loss: 2.4559747620983

Epoch: 6| Step: 2
Training loss: 1.8693726334832663
Validation loss: 2.4592063668266446

Epoch: 6| Step: 3
Training loss: 1.470576185850258
Validation loss: 2.465530050082848

Epoch: 6| Step: 4
Training loss: 2.2010242375413283
Validation loss: 2.462737943639466

Epoch: 6| Step: 5
Training loss: 3.0686334964678545
Validation loss: 2.466105497380146

Epoch: 6| Step: 6
Training loss: 2.379337966907308
Validation loss: 2.4624616636077308

Epoch: 6| Step: 7
Training loss: 2.6938477890072696
Validation loss: 2.4628785808933262

Epoch: 6| Step: 8
Training loss: 3.104334594144114
Validation loss: 2.463247452332743

Epoch: 6| Step: 9
Training loss: 2.6392761938962046
Validation loss: 2.461954413323794

Epoch: 6| Step: 10
Training loss: 2.91394140897035
Validation loss: 2.462649505775746

Epoch: 6| Step: 11
Training loss: 3.0743809891076483
Validation loss: 2.45968294005209

Epoch: 6| Step: 12
Training loss: 2.587184916307339
Validation loss: 2.460508133504068

Epoch: 6| Step: 13
Training loss: 2.1172221839006355
Validation loss: 2.4537062877532128

Epoch: 106| Step: 0
Training loss: 2.5268538175568276
Validation loss: 2.453167925092615

Epoch: 6| Step: 1
Training loss: 2.4202802760599975
Validation loss: 2.4535661531543558

Epoch: 6| Step: 2
Training loss: 3.413059392779466
Validation loss: 2.453700587299322

Epoch: 6| Step: 3
Training loss: 2.8871356420466587
Validation loss: 2.4463165951700367

Epoch: 6| Step: 4
Training loss: 2.3001127712964755
Validation loss: 2.4531410038581933

Epoch: 6| Step: 5
Training loss: 2.826396350606014
Validation loss: 2.4541486641224104

Epoch: 6| Step: 6
Training loss: 2.628980797083369
Validation loss: 2.4508374962570842

Epoch: 6| Step: 7
Training loss: 2.2058525786540866
Validation loss: 2.456587492103912

Epoch: 6| Step: 8
Training loss: 2.905980251468311
Validation loss: 2.4588540436310278

Epoch: 6| Step: 9
Training loss: 1.3468513185760245
Validation loss: 2.4590653418031962

Epoch: 6| Step: 10
Training loss: 2.4277607923253472
Validation loss: 2.464688384353107

Epoch: 6| Step: 11
Training loss: 1.909221272125439
Validation loss: 2.4692755353059854

Epoch: 6| Step: 12
Training loss: 3.066478091813676
Validation loss: 2.463262293474788

Epoch: 6| Step: 13
Training loss: 2.4917801192193143
Validation loss: 2.4625667608154265

Epoch: 107| Step: 0
Training loss: 3.2960836174830184
Validation loss: 2.4522960420415605

Epoch: 6| Step: 1
Training loss: 2.656536670250065
Validation loss: 2.4630075377048097

Epoch: 6| Step: 2
Training loss: 2.419014207076781
Validation loss: 2.46597961918354

Epoch: 6| Step: 3
Training loss: 2.502134937407477
Validation loss: 2.472325468110076

Epoch: 6| Step: 4
Training loss: 2.4237488419371145
Validation loss: 2.4748296762551116

Epoch: 6| Step: 5
Training loss: 2.4342861996713534
Validation loss: 2.4742066643542895

Epoch: 6| Step: 6
Training loss: 2.878500590218488
Validation loss: 2.4769213684192786

Epoch: 6| Step: 7
Training loss: 1.9680728656142448
Validation loss: 2.4753580784816376

Epoch: 6| Step: 8
Training loss: 2.2015220275580907
Validation loss: 2.475373585438524

Epoch: 6| Step: 9
Training loss: 2.297042944341044
Validation loss: 2.472551115592133

Epoch: 6| Step: 10
Training loss: 2.9063723958811676
Validation loss: 2.4726981610949124

Epoch: 6| Step: 11
Training loss: 2.86837818669994
Validation loss: 2.4739085838268156

Epoch: 6| Step: 12
Training loss: 2.415847464085132
Validation loss: 2.4734500456552277

Epoch: 6| Step: 13
Training loss: 2.4244589526477305
Validation loss: 2.4761650336097283

Epoch: 108| Step: 0
Training loss: 2.4150367918825255
Validation loss: 2.4673027432024592

Epoch: 6| Step: 1
Training loss: 2.0318989817372475
Validation loss: 2.471668313215157

Epoch: 6| Step: 2
Training loss: 2.9039497706795623
Validation loss: 2.469971720679041

Epoch: 6| Step: 3
Training loss: 2.4587004651431053
Validation loss: 2.470115107146364

Epoch: 6| Step: 4
Training loss: 2.7750436349823238
Validation loss: 2.473549760241748

Epoch: 6| Step: 5
Training loss: 2.467471600555585
Validation loss: 2.475417055768754

Epoch: 6| Step: 6
Training loss: 2.6051590719729965
Validation loss: 2.480308115005542

Epoch: 6| Step: 7
Training loss: 2.7922305965673284
Validation loss: 2.4770449981631972

Epoch: 6| Step: 8
Training loss: 2.768935382914278
Validation loss: 2.4742603211383076

Epoch: 6| Step: 9
Training loss: 2.76544309545888
Validation loss: 2.4710753551228244

Epoch: 6| Step: 10
Training loss: 2.4797524687074697
Validation loss: 2.4772270907392007

Epoch: 6| Step: 11
Training loss: 2.5684952732582556
Validation loss: 2.4670739902945864

Epoch: 6| Step: 12
Training loss: 2.291856122132911
Validation loss: 2.4745865730212624

Epoch: 6| Step: 13
Training loss: 2.6498715279584895
Validation loss: 2.464786970206999

Epoch: 109| Step: 0
Training loss: 2.9673346106855663
Validation loss: 2.468231999903513

Epoch: 6| Step: 1
Training loss: 2.3563655835040875
Validation loss: 2.4682694945321386

Epoch: 6| Step: 2
Training loss: 1.8520548363099887
Validation loss: 2.4659047772636553

Epoch: 6| Step: 3
Training loss: 2.33684223732602
Validation loss: 2.468622486024433

Epoch: 6| Step: 4
Training loss: 2.336380116047339
Validation loss: 2.468673020784341

Epoch: 6| Step: 5
Training loss: 2.711300872283256
Validation loss: 2.464756951514172

Epoch: 6| Step: 6
Training loss: 2.545295272216195
Validation loss: 2.470446249332798

Epoch: 6| Step: 7
Training loss: 2.7335822999970083
Validation loss: 2.4676760498442856

Epoch: 6| Step: 8
Training loss: 2.537843757984602
Validation loss: 2.471737418222106

Epoch: 6| Step: 9
Training loss: 2.3857847593290304
Validation loss: 2.4677449365501487

Epoch: 6| Step: 10
Training loss: 2.6028882563578195
Validation loss: 2.464639936384568

Epoch: 6| Step: 11
Training loss: 2.3257232156470296
Validation loss: 2.4617592706052163

Epoch: 6| Step: 12
Training loss: 2.9650777490724307
Validation loss: 2.460026825833531

Epoch: 6| Step: 13
Training loss: 2.8921519602400916
Validation loss: 2.460430597647544

Epoch: 110| Step: 0
Training loss: 2.642623145374773
Validation loss: 2.4596696928324215

Epoch: 6| Step: 1
Training loss: 2.4493778061516083
Validation loss: 2.461050057233949

Epoch: 6| Step: 2
Training loss: 2.4248597487959107
Validation loss: 2.4657014139548057

Epoch: 6| Step: 3
Training loss: 2.5815950103068475
Validation loss: 2.47240738824159

Epoch: 6| Step: 4
Training loss: 2.3321519881132105
Validation loss: 2.468227459939878

Epoch: 6| Step: 5
Training loss: 2.525782201491276
Validation loss: 2.46635844285315

Epoch: 6| Step: 6
Training loss: 2.4333382314693672
Validation loss: 2.4739062226813737

Epoch: 6| Step: 7
Training loss: 3.430244556972883
Validation loss: 2.4613346485817735

Epoch: 6| Step: 8
Training loss: 2.7920135358465914
Validation loss: 2.4578327353538336

Epoch: 6| Step: 9
Training loss: 2.203799421824064
Validation loss: 2.458638379734682

Epoch: 6| Step: 10
Training loss: 2.631008537612106
Validation loss: 2.46644223669972

Epoch: 6| Step: 11
Training loss: 2.2694069701947264
Validation loss: 2.467156809575069

Epoch: 6| Step: 12
Training loss: 2.58433146318991
Validation loss: 2.4667138342170967

Epoch: 6| Step: 13
Training loss: 2.178051844152345
Validation loss: 2.4684853069838364

Epoch: 111| Step: 0
Training loss: 2.3098100017669627
Validation loss: 2.472925943830186

Epoch: 6| Step: 1
Training loss: 2.8577726283141565
Validation loss: 2.478563897935597

Epoch: 6| Step: 2
Training loss: 2.578544258937646
Validation loss: 2.47511815774845

Epoch: 6| Step: 3
Training loss: 2.8675159401354953
Validation loss: 2.4742949942687784

Epoch: 6| Step: 4
Training loss: 2.4365506401913333
Validation loss: 2.4762490412097082

Epoch: 6| Step: 5
Training loss: 2.821532432065553
Validation loss: 2.476718324077177

Epoch: 6| Step: 6
Training loss: 2.392843276921097
Validation loss: 2.4748421679690664

Epoch: 6| Step: 7
Training loss: 1.925175198100354
Validation loss: 2.4759041425563604

Epoch: 6| Step: 8
Training loss: 3.0498264200814695
Validation loss: 2.4728099741063723

Epoch: 6| Step: 9
Training loss: 2.608350998287488
Validation loss: 2.4743927156000947

Epoch: 6| Step: 10
Training loss: 2.519139080428663
Validation loss: 2.4757083819904917

Epoch: 6| Step: 11
Training loss: 2.849457431478595
Validation loss: 2.4693948088745876

Epoch: 6| Step: 12
Training loss: 2.6148537322470147
Validation loss: 2.470602362667603

Epoch: 6| Step: 13
Training loss: 1.479431755418008
Validation loss: 2.4679400407039647

Epoch: 112| Step: 0
Training loss: 3.024443545273233
Validation loss: 2.4597157185365193

Epoch: 6| Step: 1
Training loss: 2.540955480498573
Validation loss: 2.4583808495622366

Epoch: 6| Step: 2
Training loss: 2.64251316439003
Validation loss: 2.4548153570990094

Epoch: 6| Step: 3
Training loss: 2.996263243097314
Validation loss: 2.4529695724847818

Epoch: 6| Step: 4
Training loss: 2.0875457393180916
Validation loss: 2.462784960761843

Epoch: 6| Step: 5
Training loss: 2.744272857412356
Validation loss: 2.456081803300448

Epoch: 6| Step: 6
Training loss: 2.584585891108211
Validation loss: 2.4590791820846283

Epoch: 6| Step: 7
Training loss: 2.1664469558627877
Validation loss: 2.4634936101526175

Epoch: 6| Step: 8
Training loss: 3.122435471148183
Validation loss: 2.4621298510170924

Epoch: 6| Step: 9
Training loss: 1.906569469759922
Validation loss: 2.4596430204700384

Epoch: 6| Step: 10
Training loss: 2.67300765808584
Validation loss: 2.459289758054065

Epoch: 6| Step: 11
Training loss: 2.2998223111718583
Validation loss: 2.464934527241451

Epoch: 6| Step: 12
Training loss: 2.5464842326876207
Validation loss: 2.4652640764694467

Epoch: 6| Step: 13
Training loss: 1.971671948505119
Validation loss: 2.4675839885678035

Epoch: 113| Step: 0
Training loss: 2.2760586130542846
Validation loss: 2.467032241365262

Epoch: 6| Step: 1
Training loss: 2.914517364591582
Validation loss: 2.463470995630652

Epoch: 6| Step: 2
Training loss: 2.780854100542389
Validation loss: 2.460863982217634

Epoch: 6| Step: 3
Training loss: 2.2105511978250054
Validation loss: 2.4657583660742

Epoch: 6| Step: 4
Training loss: 2.00918888161507
Validation loss: 2.4634656565085122

Epoch: 6| Step: 5
Training loss: 2.007462170388162
Validation loss: 2.466452257615187

Epoch: 6| Step: 6
Training loss: 2.9569809378976126
Validation loss: 2.4670669033347647

Epoch: 6| Step: 7
Training loss: 2.338675129118644
Validation loss: 2.464372963739622

Epoch: 6| Step: 8
Training loss: 3.2408000137317803
Validation loss: 2.466314635630963

Epoch: 6| Step: 9
Training loss: 2.744498037500526
Validation loss: 2.4634287662456935

Epoch: 6| Step: 10
Training loss: 2.4964775065060616
Validation loss: 2.4636018569615152

Epoch: 6| Step: 11
Training loss: 2.3262202516485164
Validation loss: 2.4655740001772273

Epoch: 6| Step: 12
Training loss: 2.6231838483119474
Validation loss: 2.4670498301206853

Epoch: 6| Step: 13
Training loss: 2.376548764040525
Validation loss: 2.461874243658756

Epoch: 114| Step: 0
Training loss: 2.810633739536738
Validation loss: 2.464634680407923

Epoch: 6| Step: 1
Training loss: 2.6850139741160994
Validation loss: 2.464245400648587

Epoch: 6| Step: 2
Training loss: 1.9017063459468708
Validation loss: 2.459475790605838

Epoch: 6| Step: 3
Training loss: 2.686481194006299
Validation loss: 2.459659741215594

Epoch: 6| Step: 4
Training loss: 1.718985524079429
Validation loss: 2.4682243688960286

Epoch: 6| Step: 5
Training loss: 2.7405739408671512
Validation loss: 2.4614290099806073

Epoch: 6| Step: 6
Training loss: 2.3101249045089256
Validation loss: 2.461550657392284

Epoch: 6| Step: 7
Training loss: 2.6802947576895613
Validation loss: 2.4597089819393534

Epoch: 6| Step: 8
Training loss: 2.6533878838699905
Validation loss: 2.4631394158029973

Epoch: 6| Step: 9
Training loss: 2.41262191701587
Validation loss: 2.469934187538709

Epoch: 6| Step: 10
Training loss: 2.1984866399092295
Validation loss: 2.46418168919198

Epoch: 6| Step: 11
Training loss: 2.114805563788746
Validation loss: 2.4626568474817376

Epoch: 6| Step: 12
Training loss: 3.2718239679155063
Validation loss: 2.467989808552544

Epoch: 6| Step: 13
Training loss: 2.971870468890309
Validation loss: 2.4628818964570334

Epoch: 115| Step: 0
Training loss: 2.3496544279502323
Validation loss: 2.4674324833664905

Epoch: 6| Step: 1
Training loss: 2.63087206230701
Validation loss: 2.469188313264317

Epoch: 6| Step: 2
Training loss: 2.0528004614793076
Validation loss: 2.4693924112300714

Epoch: 6| Step: 3
Training loss: 3.123632818606187
Validation loss: 2.4725011984857908

Epoch: 6| Step: 4
Training loss: 1.6964561015598527
Validation loss: 2.473951389236074

Epoch: 6| Step: 5
Training loss: 2.768075493141396
Validation loss: 2.4752004670668124

Epoch: 6| Step: 6
Training loss: 2.281435815219724
Validation loss: 2.4742286668279005

Epoch: 6| Step: 7
Training loss: 2.957544964974942
Validation loss: 2.4703359861341214

Epoch: 6| Step: 8
Training loss: 2.409065482003765
Validation loss: 2.4723519715063533

Epoch: 6| Step: 9
Training loss: 2.554224561457266
Validation loss: 2.467833449440758

Epoch: 6| Step: 10
Training loss: 2.6565013093433567
Validation loss: 2.4674577348793916

Epoch: 6| Step: 11
Training loss: 2.9548036355807654
Validation loss: 2.4656619463635563

Epoch: 6| Step: 12
Training loss: 2.351003789589577
Validation loss: 2.4608854742454582

Epoch: 6| Step: 13
Training loss: 2.48318395314685
Validation loss: 2.465268122216839

Epoch: 116| Step: 0
Training loss: 2.2764042638952917
Validation loss: 2.459364292326661

Epoch: 6| Step: 1
Training loss: 2.982061637901479
Validation loss: 2.4583276543847994

Epoch: 6| Step: 2
Training loss: 2.637292779673693
Validation loss: 2.4562242857644256

Epoch: 6| Step: 3
Training loss: 2.523804251176068
Validation loss: 2.458275605725451

Epoch: 6| Step: 4
Training loss: 2.430052309768341
Validation loss: 2.459337471235763

Epoch: 6| Step: 5
Training loss: 2.1344980140188903
Validation loss: 2.458036895163626

Epoch: 6| Step: 6
Training loss: 1.9577654224772771
Validation loss: 2.4576467967049136

Epoch: 6| Step: 7
Training loss: 2.19714431088715
Validation loss: 2.4577858740934015

Epoch: 6| Step: 8
Training loss: 2.7504813033180837
Validation loss: 2.4603406555769016

Epoch: 6| Step: 9
Training loss: 2.6729822374261034
Validation loss: 2.455319955387314

Epoch: 6| Step: 10
Training loss: 2.2440139827734615
Validation loss: 2.4548346520891995

Epoch: 6| Step: 11
Training loss: 2.688221324550958
Validation loss: 2.4580226286970897

Epoch: 6| Step: 12
Training loss: 3.0471097415583195
Validation loss: 2.4475014084112825

Epoch: 6| Step: 13
Training loss: 2.597770149200539
Validation loss: 2.450925225441105

Epoch: 117| Step: 0
Training loss: 2.531382051013991
Validation loss: 2.448804934970885

Epoch: 6| Step: 1
Training loss: 3.1547700036999715
Validation loss: 2.446811594330347

Epoch: 6| Step: 2
Training loss: 2.578475835799751
Validation loss: 2.4485588016092756

Epoch: 6| Step: 3
Training loss: 2.2850039178660255
Validation loss: 2.447090761716967

Epoch: 6| Step: 4
Training loss: 2.7112562008721306
Validation loss: 2.4534356068417704

Epoch: 6| Step: 5
Training loss: 2.602581202754518
Validation loss: 2.4493307831291844

Epoch: 6| Step: 6
Training loss: 2.5113697907134283
Validation loss: 2.4543787997865354

Epoch: 6| Step: 7
Training loss: 2.985117395542986
Validation loss: 2.4593767010215553

Epoch: 6| Step: 8
Training loss: 2.723454406300616
Validation loss: 2.458698307574183

Epoch: 6| Step: 9
Training loss: 2.2858776029925654
Validation loss: 2.450659612495362

Epoch: 6| Step: 10
Training loss: 2.1558688282953753
Validation loss: 2.455167855236724

Epoch: 6| Step: 11
Training loss: 2.405716775048906
Validation loss: 2.4568955910110213

Epoch: 6| Step: 12
Training loss: 2.4194070362284856
Validation loss: 2.45372648215234

Epoch: 6| Step: 13
Training loss: 1.7792637106927434
Validation loss: 2.452161093369911

Epoch: 118| Step: 0
Training loss: 3.136898581930546
Validation loss: 2.461195319662775

Epoch: 6| Step: 1
Training loss: 2.755184315298541
Validation loss: 2.457078602733288

Epoch: 6| Step: 2
Training loss: 1.9664871896326037
Validation loss: 2.452952854733446

Epoch: 6| Step: 3
Training loss: 1.9522106013817302
Validation loss: 2.4512344169996756

Epoch: 6| Step: 4
Training loss: 2.4730646600657678
Validation loss: 2.4523275905699347

Epoch: 6| Step: 5
Training loss: 2.5541892776193706
Validation loss: 2.4485422890576154

Epoch: 6| Step: 6
Training loss: 2.485456890879602
Validation loss: 2.449977037426003

Epoch: 6| Step: 7
Training loss: 2.386563709673813
Validation loss: 2.439975655074693

Epoch: 6| Step: 8
Training loss: 2.309336999314697
Validation loss: 2.4473762294397896

Epoch: 6| Step: 9
Training loss: 3.1677950471606318
Validation loss: 2.451964198880513

Epoch: 6| Step: 10
Training loss: 2.656848077200175
Validation loss: 2.4521725338311873

Epoch: 6| Step: 11
Training loss: 2.4583476653462544
Validation loss: 2.44765039713777

Epoch: 6| Step: 12
Training loss: 2.472792587016906
Validation loss: 2.4489442873321696

Epoch: 6| Step: 13
Training loss: 2.2976368788830337
Validation loss: 2.450823779674986

Epoch: 119| Step: 0
Training loss: 2.1467339437418933
Validation loss: 2.4538637737495206

Epoch: 6| Step: 1
Training loss: 2.3183118627318673
Validation loss: 2.4518229922988293

Epoch: 6| Step: 2
Training loss: 3.254709499539337
Validation loss: 2.4487022492090733

Epoch: 6| Step: 3
Training loss: 3.2284599433246584
Validation loss: 2.4483098194593667

Epoch: 6| Step: 4
Training loss: 2.5635550583220055
Validation loss: 2.451478498716373

Epoch: 6| Step: 5
Training loss: 1.6950117978385908
Validation loss: 2.452777781281904

Epoch: 6| Step: 6
Training loss: 2.565497622191257
Validation loss: 2.4537457776077845

Epoch: 6| Step: 7
Training loss: 2.045412429221851
Validation loss: 2.4580120803498904

Epoch: 6| Step: 8
Training loss: 2.057097091809085
Validation loss: 2.4582139379527317

Epoch: 6| Step: 9
Training loss: 3.2136829083449077
Validation loss: 2.463124702980806

Epoch: 6| Step: 10
Training loss: 2.633874967459117
Validation loss: 2.4558811457596184

Epoch: 6| Step: 11
Training loss: 2.1280162945962466
Validation loss: 2.4611689302322923

Epoch: 6| Step: 12
Training loss: 2.8057261804329108
Validation loss: 2.466308432632972

Epoch: 6| Step: 13
Training loss: 2.121307643271273
Validation loss: 2.466089223166972

Epoch: 120| Step: 0
Training loss: 2.3856802271426067
Validation loss: 2.4615003557744126

Epoch: 6| Step: 1
Training loss: 1.953974058613527
Validation loss: 2.4593259348452556

Epoch: 6| Step: 2
Training loss: 2.4271040057392046
Validation loss: 2.454817704232596

Epoch: 6| Step: 3
Training loss: 2.0123752152513723
Validation loss: 2.455267486917059

Epoch: 6| Step: 4
Training loss: 2.581513461136803
Validation loss: 2.4566913929664986

Epoch: 6| Step: 5
Training loss: 2.814191690939345
Validation loss: 2.451633153626275

Epoch: 6| Step: 6
Training loss: 1.911152149038292
Validation loss: 2.4536996399214686

Epoch: 6| Step: 7
Training loss: 2.9273776701689367
Validation loss: 2.4556497916334847

Epoch: 6| Step: 8
Training loss: 2.6652185163678856
Validation loss: 2.4574075237892625

Epoch: 6| Step: 9
Training loss: 2.12467000306347
Validation loss: 2.4583585436115616

Epoch: 6| Step: 10
Training loss: 2.238515365633056
Validation loss: 2.458771510325058

Epoch: 6| Step: 11
Training loss: 3.003189140214425
Validation loss: 2.4628290889190816

Epoch: 6| Step: 12
Training loss: 3.1628686984002847
Validation loss: 2.4579686740309974

Epoch: 6| Step: 13
Training loss: 2.780693084164506
Validation loss: 2.4596705813676802

Epoch: 121| Step: 0
Training loss: 2.661978882847005
Validation loss: 2.4568697457332966

Epoch: 6| Step: 1
Training loss: 2.5978614668703575
Validation loss: 2.4662239253010614

Epoch: 6| Step: 2
Training loss: 2.695190780766097
Validation loss: 2.462019747975343

Epoch: 6| Step: 3
Training loss: 2.9200747242602665
Validation loss: 2.460107411052949

Epoch: 6| Step: 4
Training loss: 2.985353638932464
Validation loss: 2.4589762062621836

Epoch: 6| Step: 5
Training loss: 2.6656697813970447
Validation loss: 2.466179551750391

Epoch: 6| Step: 6
Training loss: 2.0810478135151604
Validation loss: 2.468797530348468

Epoch: 6| Step: 7
Training loss: 2.392935440474279
Validation loss: 2.4622575721238262

Epoch: 6| Step: 8
Training loss: 2.1881409932096587
Validation loss: 2.468447026843946

Epoch: 6| Step: 9
Training loss: 2.4316939627684344
Validation loss: 2.4645964371974283

Epoch: 6| Step: 10
Training loss: 2.44169138959882
Validation loss: 2.465667651395389

Epoch: 6| Step: 11
Training loss: 2.7580032066564475
Validation loss: 2.4623387782576005

Epoch: 6| Step: 12
Training loss: 2.207736768456318
Validation loss: 2.456444618209025

Epoch: 6| Step: 13
Training loss: 2.3666946351274727
Validation loss: 2.4627629851286543

Epoch: 122| Step: 0
Training loss: 2.31143308204266
Validation loss: 2.456907292460053

Epoch: 6| Step: 1
Training loss: 2.0767179616080345
Validation loss: 2.458029693235344

Epoch: 6| Step: 2
Training loss: 2.6873643530390714
Validation loss: 2.4587553168586633

Epoch: 6| Step: 3
Training loss: 2.359996587459877
Validation loss: 2.4539364001326516

Epoch: 6| Step: 4
Training loss: 1.8506492583782619
Validation loss: 2.4616488765709934

Epoch: 6| Step: 5
Training loss: 2.528342095521024
Validation loss: 2.4565924660524683

Epoch: 6| Step: 6
Training loss: 2.1394462960053966
Validation loss: 2.462043360344069

Epoch: 6| Step: 7
Training loss: 2.7109309919207725
Validation loss: 2.4592333832440803

Epoch: 6| Step: 8
Training loss: 2.9411248101578042
Validation loss: 2.453087695054767

Epoch: 6| Step: 9
Training loss: 2.9338963907432403
Validation loss: 2.4575414890940688

Epoch: 6| Step: 10
Training loss: 2.6816217764951213
Validation loss: 2.4543699924025137

Epoch: 6| Step: 11
Training loss: 2.615324262423233
Validation loss: 2.4536379624069595

Epoch: 6| Step: 12
Training loss: 2.671210401542316
Validation loss: 2.455188498877478

Epoch: 6| Step: 13
Training loss: 2.6037180908416193
Validation loss: 2.4618706765564227

Epoch: 123| Step: 0
Training loss: 2.903654518741681
Validation loss: 2.4634738345549327

Epoch: 6| Step: 1
Training loss: 2.5016867669314813
Validation loss: 2.4661819041808895

Epoch: 6| Step: 2
Training loss: 2.6916503795528626
Validation loss: 2.4579011623447333

Epoch: 6| Step: 3
Training loss: 1.949196977818661
Validation loss: 2.463879670282737

Epoch: 6| Step: 4
Training loss: 2.649927940828439
Validation loss: 2.4665207354662986

Epoch: 6| Step: 5
Training loss: 3.207183202379922
Validation loss: 2.458827362420813

Epoch: 6| Step: 6
Training loss: 2.6037966554356093
Validation loss: 2.457145433547326

Epoch: 6| Step: 7
Training loss: 2.48557545191218
Validation loss: 2.457693458514918

Epoch: 6| Step: 8
Training loss: 2.1553781930746827
Validation loss: 2.454923905632574

Epoch: 6| Step: 9
Training loss: 2.7993391892088093
Validation loss: 2.457586924068903

Epoch: 6| Step: 10
Training loss: 2.3116622644596587
Validation loss: 2.455985489079645

Epoch: 6| Step: 11
Training loss: 1.9354904582311452
Validation loss: 2.4623627667988073

Epoch: 6| Step: 12
Training loss: 2.270554014986903
Validation loss: 2.4576275561302774

Epoch: 6| Step: 13
Training loss: 2.5223670791372306
Validation loss: 2.4573980157749316

Epoch: 124| Step: 0
Training loss: 2.7305253313611795
Validation loss: 2.4521600724762966

Epoch: 6| Step: 1
Training loss: 2.079906073246831
Validation loss: 2.464172481452171

Epoch: 6| Step: 2
Training loss: 2.243195204296509
Validation loss: 2.4592607871537693

Epoch: 6| Step: 3
Training loss: 1.956627962205107
Validation loss: 2.4568946529518785

Epoch: 6| Step: 4
Training loss: 2.5281053011849397
Validation loss: 2.4596406617856714

Epoch: 6| Step: 5
Training loss: 2.5745927136726667
Validation loss: 2.457410579928913

Epoch: 6| Step: 6
Training loss: 2.402256612050253
Validation loss: 2.463856365811591

Epoch: 6| Step: 7
Training loss: 3.0643359539322725
Validation loss: 2.464542981158965

Epoch: 6| Step: 8
Training loss: 1.8828884758400248
Validation loss: 2.462824232440314

Epoch: 6| Step: 9
Training loss: 2.5408513267466333
Validation loss: 2.4672470265979136

Epoch: 6| Step: 10
Training loss: 2.9393580627277873
Validation loss: 2.467655744162669

Epoch: 6| Step: 11
Training loss: 2.6442961144542734
Validation loss: 2.4666256194522687

Epoch: 6| Step: 12
Training loss: 2.4945844167317586
Validation loss: 2.474784557842808

Epoch: 6| Step: 13
Training loss: 2.8455392427716264
Validation loss: 2.4778285756437413

Epoch: 125| Step: 0
Training loss: 2.278758739762279
Validation loss: 2.475281537544619

Epoch: 6| Step: 1
Training loss: 2.1743460669679995
Validation loss: 2.479568646536564

Epoch: 6| Step: 2
Training loss: 1.8672355103006515
Validation loss: 2.4781563460623244

Epoch: 6| Step: 3
Training loss: 2.534341313788534
Validation loss: 2.472527266076576

Epoch: 6| Step: 4
Training loss: 2.2993192577526647
Validation loss: 2.4763650424351367

Epoch: 6| Step: 5
Training loss: 2.9955755031737796
Validation loss: 2.4674843066643084

Epoch: 6| Step: 6
Training loss: 1.816521228719788
Validation loss: 2.468793876676533

Epoch: 6| Step: 7
Training loss: 3.1197483949202414
Validation loss: 2.4672797287494315

Epoch: 6| Step: 8
Training loss: 3.02307599885829
Validation loss: 2.462702752817428

Epoch: 6| Step: 9
Training loss: 2.4648559376555856
Validation loss: 2.463754428335049

Epoch: 6| Step: 10
Training loss: 2.6581702976596255
Validation loss: 2.4596581741553787

Epoch: 6| Step: 11
Training loss: 2.7320143618673947
Validation loss: 2.455453006970239

Epoch: 6| Step: 12
Training loss: 2.515534962055727
Validation loss: 2.454680870689863

Epoch: 6| Step: 13
Training loss: 2.3790465565664216
Validation loss: 2.4657501311433814

Epoch: 126| Step: 0
Training loss: 2.4137828874841616
Validation loss: 2.4583805747800174

Epoch: 6| Step: 1
Training loss: 2.3343513742908466
Validation loss: 2.4634623014046912

Epoch: 6| Step: 2
Training loss: 2.006250033274618
Validation loss: 2.460827133691068

Epoch: 6| Step: 3
Training loss: 2.182391605198004
Validation loss: 2.4633191406742765

Epoch: 6| Step: 4
Training loss: 2.029676444102094
Validation loss: 2.459817233752537

Epoch: 6| Step: 5
Training loss: 2.4449154467482197
Validation loss: 2.4629351384745815

Epoch: 6| Step: 6
Training loss: 2.7964892414390103
Validation loss: 2.4603352773600387

Epoch: 6| Step: 7
Training loss: 2.384602659063721
Validation loss: 2.4613350764046626

Epoch: 6| Step: 8
Training loss: 2.6993771187768894
Validation loss: 2.458315507102171

Epoch: 6| Step: 9
Training loss: 2.804225022803203
Validation loss: 2.458744941348089

Epoch: 6| Step: 10
Training loss: 2.601550402913879
Validation loss: 2.4573729842959846

Epoch: 6| Step: 11
Training loss: 2.969225714866621
Validation loss: 2.454477281672648

Epoch: 6| Step: 12
Training loss: 2.461544967032969
Validation loss: 2.452664504190321

Epoch: 6| Step: 13
Training loss: 2.7423689475169857
Validation loss: 2.4557644682066466

Epoch: 127| Step: 0
Training loss: 2.6266134843751314
Validation loss: 2.454073250897323

Epoch: 6| Step: 1
Training loss: 2.5818892308593036
Validation loss: 2.458111984718952

Epoch: 6| Step: 2
Training loss: 2.1967343107622455
Validation loss: 2.4559401700957135

Epoch: 6| Step: 3
Training loss: 2.2023652843276413
Validation loss: 2.4609096464972593

Epoch: 6| Step: 4
Training loss: 2.6058883672241375
Validation loss: 2.4543574288735512

Epoch: 6| Step: 5
Training loss: 2.2200133259691186
Validation loss: 2.462174176511202

Epoch: 6| Step: 6
Training loss: 3.3754698814796686
Validation loss: 2.4629643807596997

Epoch: 6| Step: 7
Training loss: 1.9639104063494037
Validation loss: 2.4584410584548757

Epoch: 6| Step: 8
Training loss: 2.5705866797865227
Validation loss: 2.458334879686117

Epoch: 6| Step: 9
Training loss: 2.3586909837319263
Validation loss: 2.4582548506110955

Epoch: 6| Step: 10
Training loss: 2.7835973199462267
Validation loss: 2.4587409333509727

Epoch: 6| Step: 11
Training loss: 2.270283822116761
Validation loss: 2.455988013068447

Epoch: 6| Step: 12
Training loss: 2.5906264099190883
Validation loss: 2.4599786091213054

Epoch: 6| Step: 13
Training loss: 2.490232268687835
Validation loss: 2.457949387476495

Epoch: 128| Step: 0
Training loss: 3.08432606017642
Validation loss: 2.4571946518847416

Epoch: 6| Step: 1
Training loss: 2.236119263070084
Validation loss: 2.455361984380267

Epoch: 6| Step: 2
Training loss: 2.4458175966275366
Validation loss: 2.470034751905019

Epoch: 6| Step: 3
Training loss: 2.5586015773973783
Validation loss: 2.466503779299836

Epoch: 6| Step: 4
Training loss: 2.2160930574963773
Validation loss: 2.46205146241704

Epoch: 6| Step: 5
Training loss: 2.675354237141215
Validation loss: 2.471783830108377

Epoch: 6| Step: 6
Training loss: 2.481940846392241
Validation loss: 2.4781600661039676

Epoch: 6| Step: 7
Training loss: 2.1962525876528805
Validation loss: 2.485371755581646

Epoch: 6| Step: 8
Training loss: 2.7059822637254443
Validation loss: 2.474450656022991

Epoch: 6| Step: 9
Training loss: 2.681127400474144
Validation loss: 2.4699967612246594

Epoch: 6| Step: 10
Training loss: 2.806060370004513
Validation loss: 2.4575756947555836

Epoch: 6| Step: 11
Training loss: 2.2771973865514807
Validation loss: 2.457734573852359

Epoch: 6| Step: 12
Training loss: 2.41900858913756
Validation loss: 2.462673918880503

Epoch: 6| Step: 13
Training loss: 2.168485452748752
Validation loss: 2.4588382224032164

Epoch: 129| Step: 0
Training loss: 2.441508396300644
Validation loss: 2.4611549886844624

Epoch: 6| Step: 1
Training loss: 2.068769462931836
Validation loss: 2.458294113837722

Epoch: 6| Step: 2
Training loss: 2.405067847042356
Validation loss: 2.4576843396445662

Epoch: 6| Step: 3
Training loss: 1.884002879077793
Validation loss: 2.4553033831106954

Epoch: 6| Step: 4
Training loss: 2.9622340923999015
Validation loss: 2.459575199314294

Epoch: 6| Step: 5
Training loss: 2.817318497424488
Validation loss: 2.4645267208129256

Epoch: 6| Step: 6
Training loss: 2.706900281063622
Validation loss: 2.463993060726658

Epoch: 6| Step: 7
Training loss: 2.38784518717377
Validation loss: 2.465075143954481

Epoch: 6| Step: 8
Training loss: 2.9271694908268198
Validation loss: 2.4585957602609976

Epoch: 6| Step: 9
Training loss: 2.5557946655346724
Validation loss: 2.465301358344501

Epoch: 6| Step: 10
Training loss: 2.54278685685404
Validation loss: 2.4602800086364973

Epoch: 6| Step: 11
Training loss: 2.7054653730599956
Validation loss: 2.460097364292501

Epoch: 6| Step: 12
Training loss: 1.9149138133920613
Validation loss: 2.467597257712973

Epoch: 6| Step: 13
Training loss: 2.4966738508840094
Validation loss: 2.4673106508481037

Epoch: 130| Step: 0
Training loss: 2.3406895301388144
Validation loss: 2.4630819917408817

Epoch: 6| Step: 1
Training loss: 3.148750232849476
Validation loss: 2.4737483420678883

Epoch: 6| Step: 2
Training loss: 1.8148328960617977
Validation loss: 2.4617274555491018

Epoch: 6| Step: 3
Training loss: 2.706082176308414
Validation loss: 2.4585282415506136

Epoch: 6| Step: 4
Training loss: 2.519091096031217
Validation loss: 2.4586854914141436

Epoch: 6| Step: 5
Training loss: 2.582799107677819
Validation loss: 2.4526273218534733

Epoch: 6| Step: 6
Training loss: 2.4778055146246736
Validation loss: 2.449898332964655

Epoch: 6| Step: 7
Training loss: 1.9421705740868584
Validation loss: 2.4535181495861225

Epoch: 6| Step: 8
Training loss: 3.1014047577763235
Validation loss: 2.447287285159117

Epoch: 6| Step: 9
Training loss: 2.8669663013916695
Validation loss: 2.4571233023586703

Epoch: 6| Step: 10
Training loss: 2.40694625491469
Validation loss: 2.4553800775026557

Epoch: 6| Step: 11
Training loss: 2.085121938309515
Validation loss: 2.45511292337071

Epoch: 6| Step: 12
Training loss: 2.474639820131383
Validation loss: 2.4546208447674713

Epoch: 6| Step: 13
Training loss: 2.067549333456606
Validation loss: 2.4584865495382227

Epoch: 131| Step: 0
Training loss: 2.3824465611359895
Validation loss: 2.4633720344923975

Epoch: 6| Step: 1
Training loss: 2.383056528071692
Validation loss: 2.4653393327314386

Epoch: 6| Step: 2
Training loss: 2.3827832829919835
Validation loss: 2.4650422271763817

Epoch: 6| Step: 3
Training loss: 2.2815479449790304
Validation loss: 2.46666710140465

Epoch: 6| Step: 4
Training loss: 2.4500838946556156
Validation loss: 2.457469236052635

Epoch: 6| Step: 5
Training loss: 2.302273277858465
Validation loss: 2.4599420542469876

Epoch: 6| Step: 6
Training loss: 2.1030171971799283
Validation loss: 2.4603730215346244

Epoch: 6| Step: 7
Training loss: 2.74125503379544
Validation loss: 2.465280678498139

Epoch: 6| Step: 8
Training loss: 3.2638211903867194
Validation loss: 2.457613618746002

Epoch: 6| Step: 9
Training loss: 2.9914057335363715
Validation loss: 2.4607618481150157

Epoch: 6| Step: 10
Training loss: 2.5430953174507906
Validation loss: 2.473868717109746

Epoch: 6| Step: 11
Training loss: 2.3082036497225564
Validation loss: 2.4672719256898588

Epoch: 6| Step: 12
Training loss: 2.0981640192289337
Validation loss: 2.4718193256909893

Epoch: 6| Step: 13
Training loss: 2.3795110124853003
Validation loss: 2.4620385749438234

Epoch: 132| Step: 0
Training loss: 2.630516522673049
Validation loss: 2.462016068105276

Epoch: 6| Step: 1
Training loss: 2.1051514338662853
Validation loss: 2.4529465531483843

Epoch: 6| Step: 2
Training loss: 2.678185400621118
Validation loss: 2.454511667644127

Epoch: 6| Step: 3
Training loss: 2.4299451685241156
Validation loss: 2.4527640917511273

Epoch: 6| Step: 4
Training loss: 2.6308408876716807
Validation loss: 2.452791503137261

Epoch: 6| Step: 5
Training loss: 2.7484540929071146
Validation loss: 2.452052851973372

Epoch: 6| Step: 6
Training loss: 3.1079570661841744
Validation loss: 2.45284732129834

Epoch: 6| Step: 7
Training loss: 2.09014924570561
Validation loss: 2.4627075691976015

Epoch: 6| Step: 8
Training loss: 2.241634500076583
Validation loss: 2.4755108964269685

Epoch: 6| Step: 9
Training loss: 2.515863916649871
Validation loss: 2.4791274722123893

Epoch: 6| Step: 10
Training loss: 2.1739281479683954
Validation loss: 2.4779164236515587

Epoch: 6| Step: 11
Training loss: 2.399819637514982
Validation loss: 2.481365260114395

Epoch: 6| Step: 12
Training loss: 2.7536729213266606
Validation loss: 2.481524465580326

Epoch: 6| Step: 13
Training loss: 2.221556272327614
Validation loss: 2.4712159279259462

Epoch: 133| Step: 0
Training loss: 2.8220427639625343
Validation loss: 2.4703178738674945

Epoch: 6| Step: 1
Training loss: 3.1059381094303564
Validation loss: 2.45785060819882

Epoch: 6| Step: 2
Training loss: 2.573301855332885
Validation loss: 2.461485544367219

Epoch: 6| Step: 3
Training loss: 2.2623172159283587
Validation loss: 2.450926684595218

Epoch: 6| Step: 4
Training loss: 2.5256157794605665
Validation loss: 2.465875972711321

Epoch: 6| Step: 5
Training loss: 2.9041688091720785
Validation loss: 2.46913694415537

Epoch: 6| Step: 6
Training loss: 2.360807577581341
Validation loss: 2.4654620121154385

Epoch: 6| Step: 7
Training loss: 2.627879969800971
Validation loss: 2.4651932183988157

Epoch: 6| Step: 8
Training loss: 2.5883932294954812
Validation loss: 2.4638833312419077

Epoch: 6| Step: 9
Training loss: 2.0937568322824625
Validation loss: 2.461432101486195

Epoch: 6| Step: 10
Training loss: 2.2862206221789636
Validation loss: 2.4663161179034985

Epoch: 6| Step: 11
Training loss: 2.542839082145539
Validation loss: 2.460456405521149

Epoch: 6| Step: 12
Training loss: 2.3948146036340283
Validation loss: 2.463095164143719

Epoch: 6| Step: 13
Training loss: 1.8316774982459567
Validation loss: 2.4572090767864725

Epoch: 134| Step: 0
Training loss: 2.6489804591851054
Validation loss: 2.465750985256858

Epoch: 6| Step: 1
Training loss: 2.773360474282508
Validation loss: 2.4793149492386215

Epoch: 6| Step: 2
Training loss: 2.3173256090179577
Validation loss: 2.4880220526732924

Epoch: 6| Step: 3
Training loss: 2.7758294764590907
Validation loss: 2.4951355975144365

Epoch: 6| Step: 4
Training loss: 2.8641214634163386
Validation loss: 2.491191908303735

Epoch: 6| Step: 5
Training loss: 2.612854790210149
Validation loss: 2.4853691015517763

Epoch: 6| Step: 6
Training loss: 2.6358362600153704
Validation loss: 2.487643988194354

Epoch: 6| Step: 7
Training loss: 2.40331396344651
Validation loss: 2.470281729364785

Epoch: 6| Step: 8
Training loss: 2.467375360527613
Validation loss: 2.4596533760369654

Epoch: 6| Step: 9
Training loss: 2.2683707600723846
Validation loss: 2.4630581070022366

Epoch: 6| Step: 10
Training loss: 2.1103465915605497
Validation loss: 2.4599784637428543

Epoch: 6| Step: 11
Training loss: 2.4203431237723283
Validation loss: 2.4528903079497173

Epoch: 6| Step: 12
Training loss: 2.3890010329348477
Validation loss: 2.4584025410969748

Epoch: 6| Step: 13
Training loss: 2.3801979604504786
Validation loss: 2.452366786661032

Epoch: 135| Step: 0
Training loss: 2.2547921963372435
Validation loss: 2.4481469688569253

Epoch: 6| Step: 1
Training loss: 2.437219163415305
Validation loss: 2.4509202318849024

Epoch: 6| Step: 2
Training loss: 1.7917148968023178
Validation loss: 2.4613492106624393

Epoch: 6| Step: 3
Training loss: 2.9164806488300243
Validation loss: 2.463450300419004

Epoch: 6| Step: 4
Training loss: 2.5927622189611346
Validation loss: 2.465296442262681

Epoch: 6| Step: 5
Training loss: 2.27235066761495
Validation loss: 2.4651451349766456

Epoch: 6| Step: 6
Training loss: 2.798173741403285
Validation loss: 2.4677970592242278

Epoch: 6| Step: 7
Training loss: 2.050864837396241
Validation loss: 2.475306211339238

Epoch: 6| Step: 8
Training loss: 2.4116228238408706
Validation loss: 2.4797781075403322

Epoch: 6| Step: 9
Training loss: 2.237390896998211
Validation loss: 2.478371714448918

Epoch: 6| Step: 10
Training loss: 3.1870152721966747
Validation loss: 2.476274812597479

Epoch: 6| Step: 11
Training loss: 2.7552780306004374
Validation loss: 2.4959614399770067

Epoch: 6| Step: 12
Training loss: 2.246128566306246
Validation loss: 2.491140354880763

Epoch: 6| Step: 13
Training loss: 2.432227668219756
Validation loss: 2.501733417378644

Epoch: 136| Step: 0
Training loss: 2.9726947476153684
Validation loss: 2.490152466866798

Epoch: 6| Step: 1
Training loss: 2.6781111548832612
Validation loss: 2.488094592317057

Epoch: 6| Step: 2
Training loss: 2.2602641908284324
Validation loss: 2.4896414575748027

Epoch: 6| Step: 3
Training loss: 1.976237635999074
Validation loss: 2.480816513874144

Epoch: 6| Step: 4
Training loss: 1.8421583255855203
Validation loss: 2.4699560832805414

Epoch: 6| Step: 5
Training loss: 2.9063848648773423
Validation loss: 2.464803285261567

Epoch: 6| Step: 6
Training loss: 2.528891889633308
Validation loss: 2.472154049046499

Epoch: 6| Step: 7
Training loss: 2.4510602097323924
Validation loss: 2.4781676023781123

Epoch: 6| Step: 8
Training loss: 1.9000302136679175
Validation loss: 2.475346592676102

Epoch: 6| Step: 9
Training loss: 2.2530447174456647
Validation loss: 2.4851894443201425

Epoch: 6| Step: 10
Training loss: 2.689882065552468
Validation loss: 2.4856669427589257

Epoch: 6| Step: 11
Training loss: 2.685144945064806
Validation loss: 2.466560084600622

Epoch: 6| Step: 12
Training loss: 2.4744615759064046
Validation loss: 2.470073256789803

Epoch: 6| Step: 13
Training loss: 2.6088133795752206
Validation loss: 2.46563620909257

Epoch: 137| Step: 0
Training loss: 2.6462040939277474
Validation loss: 2.4589605554987948

Epoch: 6| Step: 1
Training loss: 2.3262964018345196
Validation loss: 2.4601620214238515

Epoch: 6| Step: 2
Training loss: 2.8440893620483174
Validation loss: 2.46245461178436

Epoch: 6| Step: 3
Training loss: 2.890622360640687
Validation loss: 2.4725711078659334

Epoch: 6| Step: 4
Training loss: 2.6557390506967185
Validation loss: 2.463714623109345

Epoch: 6| Step: 5
Training loss: 2.0534825726353128
Validation loss: 2.4666283661429156

Epoch: 6| Step: 6
Training loss: 2.5559239559651923
Validation loss: 2.472751754193951

Epoch: 6| Step: 7
Training loss: 2.028443613285578
Validation loss: 2.476146626979386

Epoch: 6| Step: 8
Training loss: 2.6373895992658025
Validation loss: 2.478362511328599

Epoch: 6| Step: 9
Training loss: 2.176009818489699
Validation loss: 2.478524835567931

Epoch: 6| Step: 10
Training loss: 2.426291984811957
Validation loss: 2.490497618081772

Epoch: 6| Step: 11
Training loss: 2.3707178562603564
Validation loss: 2.4723291888890375

Epoch: 6| Step: 12
Training loss: 2.364932455989562
Validation loss: 2.4878186205538815

Epoch: 6| Step: 13
Training loss: 2.5928201502383335
Validation loss: 2.477318256318778

Epoch: 138| Step: 0
Training loss: 2.725568442594336
Validation loss: 2.4697400453842295

Epoch: 6| Step: 1
Training loss: 2.172636159442519
Validation loss: 2.469196520635717

Epoch: 6| Step: 2
Training loss: 2.8159517088076402
Validation loss: 2.4664638895592526

Epoch: 6| Step: 3
Training loss: 2.2660988147802357
Validation loss: 2.4652476758119066

Epoch: 6| Step: 4
Training loss: 2.172668202410882
Validation loss: 2.463363283458781

Epoch: 6| Step: 5
Training loss: 1.8891758685174656
Validation loss: 2.46420695789136

Epoch: 6| Step: 6
Training loss: 2.7149870690587554
Validation loss: 2.4635934373981967

Epoch: 6| Step: 7
Training loss: 2.566662919260567
Validation loss: 2.4644787694999852

Epoch: 6| Step: 8
Training loss: 2.3829777894771915
Validation loss: 2.4622904050932295

Epoch: 6| Step: 9
Training loss: 2.4541077801602493
Validation loss: 2.4677064838995606

Epoch: 6| Step: 10
Training loss: 2.48312154374553
Validation loss: 2.468728592534343

Epoch: 6| Step: 11
Training loss: 2.506077341425207
Validation loss: 2.4697398040444667

Epoch: 6| Step: 12
Training loss: 2.6297062964399442
Validation loss: 2.4705102013415483

Epoch: 6| Step: 13
Training loss: 2.7799907791204324
Validation loss: 2.4655736375558917

Epoch: 139| Step: 0
Training loss: 2.1436120792430833
Validation loss: 2.4664288485642367

Epoch: 6| Step: 1
Training loss: 2.842041340698402
Validation loss: 2.4742222989788325

Epoch: 6| Step: 2
Training loss: 3.0634472997287436
Validation loss: 2.4658746432623206

Epoch: 6| Step: 3
Training loss: 2.122237710191667
Validation loss: 2.468701905373594

Epoch: 6| Step: 4
Training loss: 1.8469195520284687
Validation loss: 2.4715020497610896

Epoch: 6| Step: 5
Training loss: 2.7457176157099124
Validation loss: 2.477206751061789

Epoch: 6| Step: 6
Training loss: 3.283643739489067
Validation loss: 2.489705882122097

Epoch: 6| Step: 7
Training loss: 2.6993601606013686
Validation loss: 2.4825697283829853

Epoch: 6| Step: 8
Training loss: 2.426595505135628
Validation loss: 2.4821064986558405

Epoch: 6| Step: 9
Training loss: 2.303812979604707
Validation loss: 2.4718105804498407

Epoch: 6| Step: 10
Training loss: 2.0531769628350482
Validation loss: 2.472292406774187

Epoch: 6| Step: 11
Training loss: 2.086145740644334
Validation loss: 2.476630481705497

Epoch: 6| Step: 12
Training loss: 2.2178451412271976
Validation loss: 2.4773090492848975

Epoch: 6| Step: 13
Training loss: 2.3074642716738367
Validation loss: 2.4857409898480247

Epoch: 140| Step: 0
Training loss: 2.4441837716070385
Validation loss: 2.485353928760334

Epoch: 6| Step: 1
Training loss: 1.8339558397049573
Validation loss: 2.47686024509591

Epoch: 6| Step: 2
Training loss: 2.066053969816633
Validation loss: 2.474209763984675

Epoch: 6| Step: 3
Training loss: 2.1950390194007703
Validation loss: 2.4676853733328454

Epoch: 6| Step: 4
Training loss: 2.4408976032638363
Validation loss: 2.466199345932908

Epoch: 6| Step: 5
Training loss: 2.4638683486917596
Validation loss: 2.4656697303443855

Epoch: 6| Step: 6
Training loss: 2.010876169877463
Validation loss: 2.462347315074361

Epoch: 6| Step: 7
Training loss: 2.959682228712822
Validation loss: 2.457586059033632

Epoch: 6| Step: 8
Training loss: 3.027431324338173
Validation loss: 2.4588833263704144

Epoch: 6| Step: 9
Training loss: 3.555176150093117
Validation loss: 2.4626245196079486

Epoch: 6| Step: 10
Training loss: 2.394535830121537
Validation loss: 2.4604752606018523

Epoch: 6| Step: 11
Training loss: 2.6581448247992308
Validation loss: 2.4632421772531066

Epoch: 6| Step: 12
Training loss: 2.356859495627371
Validation loss: 2.458281230913178

Epoch: 6| Step: 13
Training loss: 1.7410875620111954
Validation loss: 2.4671561653284626

Epoch: 141| Step: 0
Training loss: 2.497571719555563
Validation loss: 2.482376814542558

Epoch: 6| Step: 1
Training loss: 1.718058568420208
Validation loss: 2.4848118204085394

Epoch: 6| Step: 2
Training loss: 2.3538918348821185
Validation loss: 2.4813775587884304

Epoch: 6| Step: 3
Training loss: 2.650329094371429
Validation loss: 2.482682537296853

Epoch: 6| Step: 4
Training loss: 2.973740088120402
Validation loss: 2.4714786885401465

Epoch: 6| Step: 5
Training loss: 1.9575288486425486
Validation loss: 2.4732156435153034

Epoch: 6| Step: 6
Training loss: 2.9698087711615484
Validation loss: 2.4608119226134204

Epoch: 6| Step: 7
Training loss: 1.8701055860035052
Validation loss: 2.46186170228516

Epoch: 6| Step: 8
Training loss: 2.4643979886148792
Validation loss: 2.461056160462859

Epoch: 6| Step: 9
Training loss: 1.9560664496065796
Validation loss: 2.4638366415091095

Epoch: 6| Step: 10
Training loss: 2.0835075941320462
Validation loss: 2.462068425037255

Epoch: 6| Step: 11
Training loss: 2.673773732269526
Validation loss: 2.4726855621287873

Epoch: 6| Step: 12
Training loss: 3.1452388749125606
Validation loss: 2.471577815450002

Epoch: 6| Step: 13
Training loss: 2.724252766341298
Validation loss: 2.4653653390464916

Epoch: 142| Step: 0
Training loss: 2.087307712127616
Validation loss: 2.4624976082288352

Epoch: 6| Step: 1
Training loss: 1.8244745700033052
Validation loss: 2.4682002038833453

Epoch: 6| Step: 2
Training loss: 2.6360987407616054
Validation loss: 2.4635102563728015

Epoch: 6| Step: 3
Training loss: 2.274714265422989
Validation loss: 2.468580489636604

Epoch: 6| Step: 4
Training loss: 2.649119151568182
Validation loss: 2.468570622232934

Epoch: 6| Step: 5
Training loss: 3.192893159296842
Validation loss: 2.468302915627391

Epoch: 6| Step: 6
Training loss: 2.8176774583254334
Validation loss: 2.467364385125327

Epoch: 6| Step: 7
Training loss: 2.943216159629579
Validation loss: 2.4669779280432973

Epoch: 6| Step: 8
Training loss: 2.045591811188564
Validation loss: 2.4670544849992586

Epoch: 6| Step: 9
Training loss: 2.450801161738974
Validation loss: 2.4656387554344232

Epoch: 6| Step: 10
Training loss: 2.356804261927691
Validation loss: 2.4615676638203716

Epoch: 6| Step: 11
Training loss: 2.6732826317365483
Validation loss: 2.465049948634407

Epoch: 6| Step: 12
Training loss: 2.774865698786388
Validation loss: 2.460400590405336

Epoch: 6| Step: 13
Training loss: 1.668207727684139
Validation loss: 2.472457821534139

Epoch: 143| Step: 0
Training loss: 2.037666866279807
Validation loss: 2.4705324940822377

Epoch: 6| Step: 1
Training loss: 2.3972439358895414
Validation loss: 2.476672911163337

Epoch: 6| Step: 2
Training loss: 2.67888208858422
Validation loss: 2.4807405097654573

Epoch: 6| Step: 3
Training loss: 2.4335961992425976
Validation loss: 2.493238157871456

Epoch: 6| Step: 4
Training loss: 2.910230965903281
Validation loss: 2.4908088689602175

Epoch: 6| Step: 5
Training loss: 2.8777333410392467
Validation loss: 2.5168803934791484

Epoch: 6| Step: 6
Training loss: 2.009837276267707
Validation loss: 2.5026692287047165

Epoch: 6| Step: 7
Training loss: 2.4990180948311393
Validation loss: 2.4845221453901845

Epoch: 6| Step: 8
Training loss: 2.130311498654323
Validation loss: 2.465885593066362

Epoch: 6| Step: 9
Training loss: 2.304240037831784
Validation loss: 2.4661348390317372

Epoch: 6| Step: 10
Training loss: 2.728662856873438
Validation loss: 2.453879934722606

Epoch: 6| Step: 11
Training loss: 2.567919977117787
Validation loss: 2.4560317779746637

Epoch: 6| Step: 12
Training loss: 2.519594839313828
Validation loss: 2.4550564526491803

Epoch: 6| Step: 13
Training loss: 2.629757520862004
Validation loss: 2.4514790012005676

Epoch: 144| Step: 0
Training loss: 2.758009690105187
Validation loss: 2.4474451030202435

Epoch: 6| Step: 1
Training loss: 2.5059671713283946
Validation loss: 2.442134673234078

Epoch: 6| Step: 2
Training loss: 2.5085723771497856
Validation loss: 2.4504022248630717

Epoch: 6| Step: 3
Training loss: 2.497457928460688
Validation loss: 2.4469868023413452

Epoch: 6| Step: 4
Training loss: 2.5980360169413945
Validation loss: 2.4502584470295754

Epoch: 6| Step: 5
Training loss: 2.774600190925248
Validation loss: 2.447464464232926

Epoch: 6| Step: 6
Training loss: 2.0880331306606053
Validation loss: 2.4522183437553924

Epoch: 6| Step: 7
Training loss: 2.955034556953283
Validation loss: 2.4500408182182323

Epoch: 6| Step: 8
Training loss: 2.3152533970478273
Validation loss: 2.4576961909357933

Epoch: 6| Step: 9
Training loss: 2.743628837673488
Validation loss: 2.4600217699881255

Epoch: 6| Step: 10
Training loss: 2.1049464326326524
Validation loss: 2.4693621749628565

Epoch: 6| Step: 11
Training loss: 2.1321696336118716
Validation loss: 2.4668080059574597

Epoch: 6| Step: 12
Training loss: 2.5644480116154753
Validation loss: 2.471123934205759

Epoch: 6| Step: 13
Training loss: 2.427645791387191
Validation loss: 2.461312538916544

Epoch: 145| Step: 0
Training loss: 2.665849282241943
Validation loss: 2.4582874864947577

Epoch: 6| Step: 1
Training loss: 2.489475029753681
Validation loss: 2.464508839951584

Epoch: 6| Step: 2
Training loss: 2.418287019012268
Validation loss: 2.465329645772349

Epoch: 6| Step: 3
Training loss: 2.0905073876933535
Validation loss: 2.4661737834524127

Epoch: 6| Step: 4
Training loss: 3.2391187001425683
Validation loss: 2.4643798488305126

Epoch: 6| Step: 5
Training loss: 1.9452061145294937
Validation loss: 2.463578501473696

Epoch: 6| Step: 6
Training loss: 2.5236795504194993
Validation loss: 2.4724605938889375

Epoch: 6| Step: 7
Training loss: 2.416696635970278
Validation loss: 2.4652471036002637

Epoch: 6| Step: 8
Training loss: 2.6449826192014356
Validation loss: 2.467848536731582

Epoch: 6| Step: 9
Training loss: 2.186140455377286
Validation loss: 2.4701738235376474

Epoch: 6| Step: 10
Training loss: 2.949402092293685
Validation loss: 2.4671274237055756

Epoch: 6| Step: 11
Training loss: 2.693026781466724
Validation loss: 2.4652840956008504

Epoch: 6| Step: 12
Training loss: 2.17935462515485
Validation loss: 2.4677457416662443

Epoch: 6| Step: 13
Training loss: 2.136237890612107
Validation loss: 2.4666045640739944

Epoch: 146| Step: 0
Training loss: 2.533012718274174
Validation loss: 2.461260117470796

Epoch: 6| Step: 1
Training loss: 2.868768157569085
Validation loss: 2.472290196776077

Epoch: 6| Step: 2
Training loss: 2.248011770231175
Validation loss: 2.4696726945860235

Epoch: 6| Step: 3
Training loss: 1.886455762395541
Validation loss: 2.4607285991186236

Epoch: 6| Step: 4
Training loss: 2.382175247779393
Validation loss: 2.464732405882744

Epoch: 6| Step: 5
Training loss: 2.3563514181718332
Validation loss: 2.477240757368704

Epoch: 6| Step: 6
Training loss: 2.227819790474388
Validation loss: 2.4722973250174363

Epoch: 6| Step: 7
Training loss: 2.858982413601766
Validation loss: 2.4700599929020672

Epoch: 6| Step: 8
Training loss: 2.9143189018293896
Validation loss: 2.4832438006891904

Epoch: 6| Step: 9
Training loss: 2.5930893757603406
Validation loss: 2.4873956993894613

Epoch: 6| Step: 10
Training loss: 2.785696440070146
Validation loss: 2.4790865433725675

Epoch: 6| Step: 11
Training loss: 2.0006029888969348
Validation loss: 2.489073894097095

Epoch: 6| Step: 12
Training loss: 2.3449941766011824
Validation loss: 2.479394458809465

Epoch: 6| Step: 13
Training loss: 2.362071031650664
Validation loss: 2.4777871522550288

Epoch: 147| Step: 0
Training loss: 2.522111857469477
Validation loss: 2.485795756418449

Epoch: 6| Step: 1
Training loss: 2.5674390877367044
Validation loss: 2.484746373407893

Epoch: 6| Step: 2
Training loss: 1.8817585888156378
Validation loss: 2.488391101274766

Epoch: 6| Step: 3
Training loss: 2.859191388347873
Validation loss: 2.47901596017316

Epoch: 6| Step: 4
Training loss: 1.8450177247144532
Validation loss: 2.4876767017472705

Epoch: 6| Step: 5
Training loss: 2.8372335703790306
Validation loss: 2.479614527236943

Epoch: 6| Step: 6
Training loss: 2.3568940919008243
Validation loss: 2.490775829615832

Epoch: 6| Step: 7
Training loss: 2.4534923497094927
Validation loss: 2.488591452784909

Epoch: 6| Step: 8
Training loss: 2.1780133124330856
Validation loss: 2.4903450655801462

Epoch: 6| Step: 9
Training loss: 2.193688168428675
Validation loss: 2.4893814521135758

Epoch: 6| Step: 10
Training loss: 2.3470979302759014
Validation loss: 2.4821322252360156

Epoch: 6| Step: 11
Training loss: 2.2850116390541193
Validation loss: 2.4857618511620427

Epoch: 6| Step: 12
Training loss: 3.0645587774071337
Validation loss: 2.4904884597703947

Epoch: 6| Step: 13
Training loss: 2.8252851865511666
Validation loss: 2.4733936883480596

Epoch: 148| Step: 0
Training loss: 2.5423414449849537
Validation loss: 2.4753943093876276

Epoch: 6| Step: 1
Training loss: 2.303824363332092
Validation loss: 2.473285131044745

Epoch: 6| Step: 2
Training loss: 2.718181857674199
Validation loss: 2.4655018294221964

Epoch: 6| Step: 3
Training loss: 2.8766091860453904
Validation loss: 2.4732858379598683

Epoch: 6| Step: 4
Training loss: 2.3601086214898483
Validation loss: 2.4749311816476856

Epoch: 6| Step: 5
Training loss: 2.137585786581469
Validation loss: 2.4760404692440856

Epoch: 6| Step: 6
Training loss: 2.8959259091589153
Validation loss: 2.4805897120019993

Epoch: 6| Step: 7
Training loss: 1.9736478522783278
Validation loss: 2.4762438580152635

Epoch: 6| Step: 8
Training loss: 2.590479523884675
Validation loss: 2.4794577152579795

Epoch: 6| Step: 9
Training loss: 1.8112633531287512
Validation loss: 2.483383212666027

Epoch: 6| Step: 10
Training loss: 2.08383175291939
Validation loss: 2.496048856758358

Epoch: 6| Step: 11
Training loss: 2.3611268872002023
Validation loss: 2.503727264275676

Epoch: 6| Step: 12
Training loss: 2.835227520137032
Validation loss: 2.5080340041025884

Epoch: 6| Step: 13
Training loss: 2.640219933856515
Validation loss: 2.515971663383693

Epoch: 149| Step: 0
Training loss: 2.531826848363449
Validation loss: 2.5052892522505292

Epoch: 6| Step: 1
Training loss: 2.36042408640392
Validation loss: 2.5178907943558717

Epoch: 6| Step: 2
Training loss: 2.296879255848789
Validation loss: 2.5093450567439177

Epoch: 6| Step: 3
Training loss: 2.6502498400972128
Validation loss: 2.4889388640198313

Epoch: 6| Step: 4
Training loss: 2.4357083901061105
Validation loss: 2.502115459272952

Epoch: 6| Step: 5
Training loss: 1.9957899246857553
Validation loss: 2.489553544466147

Epoch: 6| Step: 6
Training loss: 2.3086026315792565
Validation loss: 2.4771184768515155

Epoch: 6| Step: 7
Training loss: 2.030947501326243
Validation loss: 2.4810050965205157

Epoch: 6| Step: 8
Training loss: 2.2411567897530293
Validation loss: 2.4875935433081864

Epoch: 6| Step: 9
Training loss: 3.445079423628347
Validation loss: 2.482364616864204

Epoch: 6| Step: 10
Training loss: 2.4919276565411304
Validation loss: 2.490106237767426

Epoch: 6| Step: 11
Training loss: 2.092918344697375
Validation loss: 2.4852059052459454

Epoch: 6| Step: 12
Training loss: 2.2876053165726864
Validation loss: 2.4880558153333356

Epoch: 6| Step: 13
Training loss: 2.714172280243021
Validation loss: 2.485737377066279

Epoch: 150| Step: 0
Training loss: 2.5510947252464335
Validation loss: 2.494333345898095

Epoch: 6| Step: 1
Training loss: 2.798810406433796
Validation loss: 2.4903560753299065

Epoch: 6| Step: 2
Training loss: 2.2233407252168336
Validation loss: 2.490305158818347

Epoch: 6| Step: 3
Training loss: 2.1790816582850034
Validation loss: 2.49082831586339

Epoch: 6| Step: 4
Training loss: 2.331171589777884
Validation loss: 2.4902567305215904

Epoch: 6| Step: 5
Training loss: 2.355802951972628
Validation loss: 2.4985931888729422

Epoch: 6| Step: 6
Training loss: 2.178587824114316
Validation loss: 2.4921080637422652

Epoch: 6| Step: 7
Training loss: 2.350871849659553
Validation loss: 2.4978629833197674

Epoch: 6| Step: 8
Training loss: 2.84348572561519
Validation loss: 2.4909563521424474

Epoch: 6| Step: 9
Training loss: 2.3166121959000017
Validation loss: 2.4944637669770944

Epoch: 6| Step: 10
Training loss: 2.1509339411056407
Validation loss: 2.4958538801804795

Epoch: 6| Step: 11
Training loss: 2.170559930943709
Validation loss: 2.509940879234428

Epoch: 6| Step: 12
Training loss: 3.106935090132537
Validation loss: 2.5177274570414827

Epoch: 6| Step: 13
Training loss: 2.4237807128597177
Validation loss: 2.5251451979332082

Epoch: 151| Step: 0
Training loss: 2.9178071290058973
Validation loss: 2.5396732789014576

Epoch: 6| Step: 1
Training loss: 2.714102444879122
Validation loss: 2.54348965186535

Epoch: 6| Step: 2
Training loss: 2.1101002894427427
Validation loss: 2.5374368324623116

Epoch: 6| Step: 3
Training loss: 2.204558210684598
Validation loss: 2.555361597560531

Epoch: 6| Step: 4
Training loss: 2.517232914141412
Validation loss: 2.5366353176233383

Epoch: 6| Step: 5
Training loss: 2.5824228240868115
Validation loss: 2.511007743253306

Epoch: 6| Step: 6
Training loss: 2.6416160033108054
Validation loss: 2.4969451359720427

Epoch: 6| Step: 7
Training loss: 2.584029124500316
Validation loss: 2.483639878249325

Epoch: 6| Step: 8
Training loss: 1.999079850243643
Validation loss: 2.468501299793297

Epoch: 6| Step: 9
Training loss: 2.821884182295112
Validation loss: 2.4716113766972407

Epoch: 6| Step: 10
Training loss: 2.7452507624363256
Validation loss: 2.4671879748037346

Epoch: 6| Step: 11
Training loss: 1.999858970438127
Validation loss: 2.4679401453607976

Epoch: 6| Step: 12
Training loss: 2.1450567105494875
Validation loss: 2.470451090828001

Epoch: 6| Step: 13
Training loss: 2.4455000832853457
Validation loss: 2.470464127431533

Epoch: 152| Step: 0
Training loss: 2.4805740934815783
Validation loss: 2.4661973399362975

Epoch: 6| Step: 1
Training loss: 2.3470156489054936
Validation loss: 2.4805500087293932

Epoch: 6| Step: 2
Training loss: 2.595036934238794
Validation loss: 2.473191013131597

Epoch: 6| Step: 3
Training loss: 2.409597965912638
Validation loss: 2.4756785519021296

Epoch: 6| Step: 4
Training loss: 2.206628165106053
Validation loss: 2.483244088722003

Epoch: 6| Step: 5
Training loss: 2.4452120726806705
Validation loss: 2.4824985159171318

Epoch: 6| Step: 6
Training loss: 2.72691810715479
Validation loss: 2.4846583670631146

Epoch: 6| Step: 7
Training loss: 2.2851649096724276
Validation loss: 2.486674574063012

Epoch: 6| Step: 8
Training loss: 2.2573690539938203
Validation loss: 2.492898996928011

Epoch: 6| Step: 9
Training loss: 2.397760351561792
Validation loss: 2.4973586274930084

Epoch: 6| Step: 10
Training loss: 2.5904785114833575
Validation loss: 2.4802927029831205

Epoch: 6| Step: 11
Training loss: 2.46080912906134
Validation loss: 2.49187873354644

Epoch: 6| Step: 12
Training loss: 2.069560594591881
Validation loss: 2.4948597037980176

Epoch: 6| Step: 13
Training loss: 2.8351429228102822
Validation loss: 2.4941846126221336

Epoch: 153| Step: 0
Training loss: 2.6666880447802344
Validation loss: 2.4968039109824907

Epoch: 6| Step: 1
Training loss: 2.0050853212614994
Validation loss: 2.509756758658139

Epoch: 6| Step: 2
Training loss: 2.4244407598865894
Validation loss: 2.5191181327173378

Epoch: 6| Step: 3
Training loss: 2.668682667510434
Validation loss: 2.505315597257555

Epoch: 6| Step: 4
Training loss: 2.5834690078875684
Validation loss: 2.501008180147582

Epoch: 6| Step: 5
Training loss: 2.314981314993607
Validation loss: 2.4921858098932193

Epoch: 6| Step: 6
Training loss: 2.605831092448827
Validation loss: 2.4785299418471536

Epoch: 6| Step: 7
Training loss: 2.4341104855878224
Validation loss: 2.474743115615505

Epoch: 6| Step: 8
Training loss: 2.22971279073806
Validation loss: 2.468076235741128

Epoch: 6| Step: 9
Training loss: 2.8724184470556082
Validation loss: 2.4623689716676567

Epoch: 6| Step: 10
Training loss: 3.038068672604431
Validation loss: 2.468327771871081

Epoch: 6| Step: 11
Training loss: 2.1364576330110943
Validation loss: 2.4655610424750662

Epoch: 6| Step: 12
Training loss: 2.448928450760822
Validation loss: 2.471370577715834

Epoch: 6| Step: 13
Training loss: 1.7006432185937332
Validation loss: 2.479747629348027

Epoch: 154| Step: 0
Training loss: 3.376977835499167
Validation loss: 2.4680323785072735

Epoch: 6| Step: 1
Training loss: 2.464817633392245
Validation loss: 2.4788416454425724

Epoch: 6| Step: 2
Training loss: 1.7368012374803237
Validation loss: 2.4902758306904764

Epoch: 6| Step: 3
Training loss: 2.589753438488279
Validation loss: 2.502499777012325

Epoch: 6| Step: 4
Training loss: 2.562205693161383
Validation loss: 2.4979543263637805

Epoch: 6| Step: 5
Training loss: 1.9782037366772187
Validation loss: 2.4965355551263535

Epoch: 6| Step: 6
Training loss: 2.199942813476832
Validation loss: 2.4945539123608054

Epoch: 6| Step: 7
Training loss: 2.3922876298456157
Validation loss: 2.5047951011842517

Epoch: 6| Step: 8
Training loss: 2.4939637745028924
Validation loss: 2.4951390215073306

Epoch: 6| Step: 9
Training loss: 2.4247198316618856
Validation loss: 2.49297510853794

Epoch: 6| Step: 10
Training loss: 2.775159704063289
Validation loss: 2.4890338312554645

Epoch: 6| Step: 11
Training loss: 1.844406269755945
Validation loss: 2.480180209941795

Epoch: 6| Step: 12
Training loss: 2.2616833303573705
Validation loss: 2.4785336933925315

Epoch: 6| Step: 13
Training loss: 2.738980496490665
Validation loss: 2.476997730347003

Epoch: 155| Step: 0
Training loss: 1.8892551219790492
Validation loss: 2.484038388142474

Epoch: 6| Step: 1
Training loss: 2.534864693967635
Validation loss: 2.481699432488082

Epoch: 6| Step: 2
Training loss: 2.7530000101873062
Validation loss: 2.4842552620045475

Epoch: 6| Step: 3
Training loss: 1.9756984706927772
Validation loss: 2.4729348699150933

Epoch: 6| Step: 4
Training loss: 2.7603288360634
Validation loss: 2.492986999272778

Epoch: 6| Step: 5
Training loss: 2.0008627699540598
Validation loss: 2.4860968391060894

Epoch: 6| Step: 6
Training loss: 2.269920223867656
Validation loss: 2.492574376737782

Epoch: 6| Step: 7
Training loss: 2.3740821871908446
Validation loss: 2.4865520543266615

Epoch: 6| Step: 8
Training loss: 2.7791604754499555
Validation loss: 2.4943916355802735

Epoch: 6| Step: 9
Training loss: 2.5809419905400266
Validation loss: 2.529950188861376

Epoch: 6| Step: 10
Training loss: 2.836991715804689
Validation loss: 2.531113938807373

Epoch: 6| Step: 11
Training loss: 2.4939742902885182
Validation loss: 2.5252647437368396

Epoch: 6| Step: 12
Training loss: 2.2301312673961853
Validation loss: 2.5165476084540592

Epoch: 6| Step: 13
Training loss: 2.6550441024192075
Validation loss: 2.5001124515674054

Epoch: 156| Step: 0
Training loss: 2.67169313759956
Validation loss: 2.496094951917889

Epoch: 6| Step: 1
Training loss: 2.6664494088203856
Validation loss: 2.4899580658850313

Epoch: 6| Step: 2
Training loss: 2.7855029218086966
Validation loss: 2.484466535053565

Epoch: 6| Step: 3
Training loss: 3.11869236466659
Validation loss: 2.478608594853682

Epoch: 6| Step: 4
Training loss: 1.9739542401622785
Validation loss: 2.476981607909152

Epoch: 6| Step: 5
Training loss: 1.897001123398854
Validation loss: 2.4748909300073687

Epoch: 6| Step: 6
Training loss: 2.466820457750496
Validation loss: 2.47569073437066

Epoch: 6| Step: 7
Training loss: 2.639196607706758
Validation loss: 2.4823053003967392

Epoch: 6| Step: 8
Training loss: 2.360303077310254
Validation loss: 2.485194265088236

Epoch: 6| Step: 9
Training loss: 2.326190528826865
Validation loss: 2.4894086917503473

Epoch: 6| Step: 10
Training loss: 1.9871753547442486
Validation loss: 2.483557096636643

Epoch: 6| Step: 11
Training loss: 2.2508060283151035
Validation loss: 2.4933786764288794

Epoch: 6| Step: 12
Training loss: 2.0174190609944116
Validation loss: 2.4890866495746136

Epoch: 6| Step: 13
Training loss: 2.652862543035581
Validation loss: 2.4956442876513587

Epoch: 157| Step: 0
Training loss: 2.036178829853197
Validation loss: 2.510809781858448

Epoch: 6| Step: 1
Training loss: 2.4143777289635593
Validation loss: 2.5070648980431036

Epoch: 6| Step: 2
Training loss: 2.417451424174771
Validation loss: 2.534642367796167

Epoch: 6| Step: 3
Training loss: 3.064365675038873
Validation loss: 2.546352520106821

Epoch: 6| Step: 4
Training loss: 2.4080157056213913
Validation loss: 2.5454701018322528

Epoch: 6| Step: 5
Training loss: 2.9147989196519877
Validation loss: 2.5302463943761806

Epoch: 6| Step: 6
Training loss: 2.534043830655096
Validation loss: 2.506574362727662

Epoch: 6| Step: 7
Training loss: 2.7338626054510127
Validation loss: 2.4838053372084827

Epoch: 6| Step: 8
Training loss: 2.0921739938198876
Validation loss: 2.4841012863910774

Epoch: 6| Step: 9
Training loss: 2.5942170974955023
Validation loss: 2.484949073602276

Epoch: 6| Step: 10
Training loss: 3.037784101598533
Validation loss: 2.4772296251667982

Epoch: 6| Step: 11
Training loss: 1.7381813963595372
Validation loss: 2.4793008132245373

Epoch: 6| Step: 12
Training loss: 2.458810716818966
Validation loss: 2.4711782528835546

Epoch: 6| Step: 13
Training loss: 1.952842569911742
Validation loss: 2.476244082674071

Epoch: 158| Step: 0
Training loss: 2.3904275251619236
Validation loss: 2.477690262441657

Epoch: 6| Step: 1
Training loss: 2.3988826972234056
Validation loss: 2.4733787714399478

Epoch: 6| Step: 2
Training loss: 2.6779082594492687
Validation loss: 2.477100462302191

Epoch: 6| Step: 3
Training loss: 2.868932208755135
Validation loss: 2.475215092056234

Epoch: 6| Step: 4
Training loss: 2.4178579178708457
Validation loss: 2.478359593258923

Epoch: 6| Step: 5
Training loss: 2.6671977905003414
Validation loss: 2.4851205534831178

Epoch: 6| Step: 6
Training loss: 2.4437724861222705
Validation loss: 2.492405673594969

Epoch: 6| Step: 7
Training loss: 2.059191043492826
Validation loss: 2.5081506582342374

Epoch: 6| Step: 8
Training loss: 2.425061400117952
Validation loss: 2.506043266591648

Epoch: 6| Step: 9
Training loss: 2.232094621409626
Validation loss: 2.530812794795984

Epoch: 6| Step: 10
Training loss: 2.1543745647681196
Validation loss: 2.5311902671013966

Epoch: 6| Step: 11
Training loss: 2.640983150955642
Validation loss: 2.51184581634914

Epoch: 6| Step: 12
Training loss: 2.6598693424058735
Validation loss: 2.500423157165508

Epoch: 6| Step: 13
Training loss: 2.045813132171445
Validation loss: 2.490509456824623

Epoch: 159| Step: 0
Training loss: 1.744707961470656
Validation loss: 2.4882249890668726

Epoch: 6| Step: 1
Training loss: 3.0425133419449595
Validation loss: 2.486507292447806

Epoch: 6| Step: 2
Training loss: 2.654127641887012
Validation loss: 2.4911091543330413

Epoch: 6| Step: 3
Training loss: 2.346755580174952
Validation loss: 2.4832115808078634

Epoch: 6| Step: 4
Training loss: 2.4699138360689794
Validation loss: 2.4836910033966575

Epoch: 6| Step: 5
Training loss: 1.8970369423832003
Validation loss: 2.4807444822191154

Epoch: 6| Step: 6
Training loss: 2.293661659472902
Validation loss: 2.4894535610793773

Epoch: 6| Step: 7
Training loss: 2.3582962298310823
Validation loss: 2.4913428618201494

Epoch: 6| Step: 8
Training loss: 2.567186118071562
Validation loss: 2.5174375997447487

Epoch: 6| Step: 9
Training loss: 2.2914118769641956
Validation loss: 2.496156503667589

Epoch: 6| Step: 10
Training loss: 2.3243656400536703
Validation loss: 2.5132328925650147

Epoch: 6| Step: 11
Training loss: 2.77158553924774
Validation loss: 2.499050023468065

Epoch: 6| Step: 12
Training loss: 2.548665733572054
Validation loss: 2.4999183005652683

Epoch: 6| Step: 13
Training loss: 2.4597516790524443
Validation loss: 2.4978703249295946

Epoch: 160| Step: 0
Training loss: 2.691653922634446
Validation loss: 2.4969170714435758

Epoch: 6| Step: 1
Training loss: 2.132798303130692
Validation loss: 2.5080745001622775

Epoch: 6| Step: 2
Training loss: 1.9548583007153881
Validation loss: 2.503663906801677

Epoch: 6| Step: 3
Training loss: 2.7924023887629525
Validation loss: 2.5082350362060577

Epoch: 6| Step: 4
Training loss: 2.167658603237703
Validation loss: 2.514274242423203

Epoch: 6| Step: 5
Training loss: 2.097206337414584
Validation loss: 2.5072640584818493

Epoch: 6| Step: 6
Training loss: 2.4040395318524252
Validation loss: 2.509338595900995

Epoch: 6| Step: 7
Training loss: 1.7369069356545848
Validation loss: 2.5132913921492674

Epoch: 6| Step: 8
Training loss: 2.4621272042119307
Validation loss: 2.515590122526081

Epoch: 6| Step: 9
Training loss: 2.3448085174791093
Validation loss: 2.5222548635567414

Epoch: 6| Step: 10
Training loss: 2.6514681689736204
Validation loss: 2.5236373759220756

Epoch: 6| Step: 11
Training loss: 2.1742821396672456
Validation loss: 2.527075232932832

Epoch: 6| Step: 12
Training loss: 2.9909470977645154
Validation loss: 2.514692477238753

Epoch: 6| Step: 13
Training loss: 2.9035873521238473
Validation loss: 2.511939624905165

Epoch: 161| Step: 0
Training loss: 1.652580947624699
Validation loss: 2.496243849943987

Epoch: 6| Step: 1
Training loss: 1.8714221514838203
Validation loss: 2.4872751642338944

Epoch: 6| Step: 2
Training loss: 2.0632052516265453
Validation loss: 2.4899029280547587

Epoch: 6| Step: 3
Training loss: 3.1107003152692188
Validation loss: 2.486507580102581

Epoch: 6| Step: 4
Training loss: 2.4211856968602015
Validation loss: 2.481590726120478

Epoch: 6| Step: 5
Training loss: 2.546102863118711
Validation loss: 2.4778172215665997

Epoch: 6| Step: 6
Training loss: 2.195463779436506
Validation loss: 2.4929947457531685

Epoch: 6| Step: 7
Training loss: 2.7001515169368746
Validation loss: 2.4870756493405675

Epoch: 6| Step: 8
Training loss: 2.116605221114306
Validation loss: 2.4828443630407384

Epoch: 6| Step: 9
Training loss: 2.3773052672531807
Validation loss: 2.486635135735382

Epoch: 6| Step: 10
Training loss: 2.831735908630179
Validation loss: 2.484796004541169

Epoch: 6| Step: 11
Training loss: 3.089656086273246
Validation loss: 2.5043052637101235

Epoch: 6| Step: 12
Training loss: 2.1449071002396463
Validation loss: 2.5086952945286525

Epoch: 6| Step: 13
Training loss: 2.225615075637471
Validation loss: 2.5121425905850803

Epoch: 162| Step: 0
Training loss: 2.242367195611284
Validation loss: 2.5250548227735337

Epoch: 6| Step: 1
Training loss: 2.4884260246283407
Validation loss: 2.5260524133407767

Epoch: 6| Step: 2
Training loss: 2.2656186860095207
Validation loss: 2.5283886313462998

Epoch: 6| Step: 3
Training loss: 2.2213309951295184
Validation loss: 2.5298060234881543

Epoch: 6| Step: 4
Training loss: 2.248517501712044
Validation loss: 2.521363625564174

Epoch: 6| Step: 5
Training loss: 2.5810168144804595
Validation loss: 2.5061554152857317

Epoch: 6| Step: 6
Training loss: 2.9035080311097383
Validation loss: 2.5022374869277764

Epoch: 6| Step: 7
Training loss: 2.4809122004566206
Validation loss: 2.4879667122230074

Epoch: 6| Step: 8
Training loss: 2.8835307728048267
Validation loss: 2.4808137588659878

Epoch: 6| Step: 9
Training loss: 1.8583773974111115
Validation loss: 2.480240274154491

Epoch: 6| Step: 10
Training loss: 2.153928640510039
Validation loss: 2.479084163115742

Epoch: 6| Step: 11
Training loss: 2.52285088963421
Validation loss: 2.48587325241087

Epoch: 6| Step: 12
Training loss: 1.7102796430758134
Validation loss: 2.4747821975331177

Epoch: 6| Step: 13
Training loss: 2.994889993573787
Validation loss: 2.481256923457687

Epoch: 163| Step: 0
Training loss: 2.7455330027922424
Validation loss: 2.482013291600264

Epoch: 6| Step: 1
Training loss: 2.7437016580619966
Validation loss: 2.482124596940582

Epoch: 6| Step: 2
Training loss: 2.6807418839739925
Validation loss: 2.4922785488226573

Epoch: 6| Step: 3
Training loss: 2.27135190962904
Validation loss: 2.4805526919441547

Epoch: 6| Step: 4
Training loss: 2.7393181289315267
Validation loss: 2.510178144422594

Epoch: 6| Step: 5
Training loss: 2.501658271133327
Validation loss: 2.498299608526777

Epoch: 6| Step: 6
Training loss: 2.2113269692023563
Validation loss: 2.4986993585250747

Epoch: 6| Step: 7
Training loss: 1.932062826118396
Validation loss: 2.4887088745541015

Epoch: 6| Step: 8
Training loss: 1.8935288756540765
Validation loss: 2.4917948701552146

Epoch: 6| Step: 9
Training loss: 2.207299680336745
Validation loss: 2.486115403825782

Epoch: 6| Step: 10
Training loss: 2.8109099237807986
Validation loss: 2.4844254062745263

Epoch: 6| Step: 11
Training loss: 2.665244279440779
Validation loss: 2.49015036048535

Epoch: 6| Step: 12
Training loss: 2.17921579377309
Validation loss: 2.493545401457214

Epoch: 6| Step: 13
Training loss: 1.972885873857038
Validation loss: 2.501407211347688

Epoch: 164| Step: 0
Training loss: 2.0542286407634167
Validation loss: 2.5072191275190976

Epoch: 6| Step: 1
Training loss: 2.4419378327525703
Validation loss: 2.5078956217869672

Epoch: 6| Step: 2
Training loss: 2.615764356248367
Validation loss: 2.5056852704896397

Epoch: 6| Step: 3
Training loss: 2.6227130918959367
Validation loss: 2.497821701276575

Epoch: 6| Step: 4
Training loss: 2.6144155825922124
Validation loss: 2.5069307339810853

Epoch: 6| Step: 5
Training loss: 2.0422582612624143
Validation loss: 2.507766826209758

Epoch: 6| Step: 6
Training loss: 2.7877471130044156
Validation loss: 2.5128421911016163

Epoch: 6| Step: 7
Training loss: 2.1982094327163204
Validation loss: 2.507269494519038

Epoch: 6| Step: 8
Training loss: 2.4239768475223147
Validation loss: 2.532515488125637

Epoch: 6| Step: 9
Training loss: 2.66474113881894
Validation loss: 2.531779167215463

Epoch: 6| Step: 10
Training loss: 2.471721743765077
Validation loss: 2.5211147487551187

Epoch: 6| Step: 11
Training loss: 2.551751085309732
Validation loss: 2.483931383876561

Epoch: 6| Step: 12
Training loss: 2.1879012693484374
Validation loss: 2.4805681664275756

Epoch: 6| Step: 13
Training loss: 1.9689775365707614
Validation loss: 2.474801641922024

Epoch: 165| Step: 0
Training loss: 3.154424460461498
Validation loss: 2.479496835045943

Epoch: 6| Step: 1
Training loss: 2.1451777472131934
Validation loss: 2.4730851141472283

Epoch: 6| Step: 2
Training loss: 1.83939817828119
Validation loss: 2.470320793393695

Epoch: 6| Step: 3
Training loss: 2.5127045163854462
Validation loss: 2.4800372852322137

Epoch: 6| Step: 4
Training loss: 2.7081830105267737
Validation loss: 2.4817454979568367

Epoch: 6| Step: 5
Training loss: 2.7321648084825427
Validation loss: 2.484554356272706

Epoch: 6| Step: 6
Training loss: 1.2994049397625238
Validation loss: 2.4796284691607386

Epoch: 6| Step: 7
Training loss: 2.1826639396558787
Validation loss: 2.489398731320019

Epoch: 6| Step: 8
Training loss: 2.3724073011258633
Validation loss: 2.487759410168859

Epoch: 6| Step: 9
Training loss: 2.384692641632492
Validation loss: 2.4929832216594123

Epoch: 6| Step: 10
Training loss: 2.328001492699738
Validation loss: 2.4947475809065875

Epoch: 6| Step: 11
Training loss: 2.919050350705032
Validation loss: 2.5151563883215777

Epoch: 6| Step: 12
Training loss: 2.31358105933534
Validation loss: 2.512253170003709

Epoch: 6| Step: 13
Training loss: 2.495564531510379
Validation loss: 2.5119475502230157

Epoch: 166| Step: 0
Training loss: 2.152973283756974
Validation loss: 2.5239339287040217

Epoch: 6| Step: 1
Training loss: 2.870235309590814
Validation loss: 2.534077826910804

Epoch: 6| Step: 2
Training loss: 2.758865803689283
Validation loss: 2.5339126867663526

Epoch: 6| Step: 3
Training loss: 2.310182802307671
Validation loss: 2.5137739459667214

Epoch: 6| Step: 4
Training loss: 1.9532611646871434
Validation loss: 2.5075773324955373

Epoch: 6| Step: 5
Training loss: 2.3559138698280844
Validation loss: 2.4966155189890946

Epoch: 6| Step: 6
Training loss: 2.3107571606944517
Validation loss: 2.49386207978823

Epoch: 6| Step: 7
Training loss: 2.064888236136371
Validation loss: 2.492503338514698

Epoch: 6| Step: 8
Training loss: 2.694173290159196
Validation loss: 2.487231501748316

Epoch: 6| Step: 9
Training loss: 2.491607789924951
Validation loss: 2.482409277363008

Epoch: 6| Step: 10
Training loss: 2.8708047526745033
Validation loss: 2.4914028642594928

Epoch: 6| Step: 11
Training loss: 2.133485792593254
Validation loss: 2.489642399256148

Epoch: 6| Step: 12
Training loss: 2.2199748781862
Validation loss: 2.4899269303167615

Epoch: 6| Step: 13
Training loss: 2.5669753838530225
Validation loss: 2.4906087516659907

Epoch: 167| Step: 0
Training loss: 2.5928450694848326
Validation loss: 2.496235635990235

Epoch: 6| Step: 1
Training loss: 2.725911584669933
Validation loss: 2.5111766841320073

Epoch: 6| Step: 2
Training loss: 2.146812906713835
Validation loss: 2.507400225286227

Epoch: 6| Step: 3
Training loss: 2.667760525309187
Validation loss: 2.494229619074731

Epoch: 6| Step: 4
Training loss: 3.304817359483125
Validation loss: 2.513630125404998

Epoch: 6| Step: 5
Training loss: 2.5457980447457627
Validation loss: 2.5122163160107416

Epoch: 6| Step: 6
Training loss: 1.9579265929616754
Validation loss: 2.5196502263171654

Epoch: 6| Step: 7
Training loss: 2.3556484071657158
Validation loss: 2.5284924183961235

Epoch: 6| Step: 8
Training loss: 2.0261786904044814
Validation loss: 2.525939142303015

Epoch: 6| Step: 9
Training loss: 1.4061133000370911
Validation loss: 2.5144094053565267

Epoch: 6| Step: 10
Training loss: 1.9799799870914951
Validation loss: 2.502890219534135

Epoch: 6| Step: 11
Training loss: 2.807408025496963
Validation loss: 2.510020455610149

Epoch: 6| Step: 12
Training loss: 2.201922040919226
Validation loss: 2.4959937420363105

Epoch: 6| Step: 13
Training loss: 2.2754868122775664
Validation loss: 2.4922636492823504

Epoch: 168| Step: 0
Training loss: 2.06565546195095
Validation loss: 2.4873822802575076

Epoch: 6| Step: 1
Training loss: 2.449047806659102
Validation loss: 2.4791599134679116

Epoch: 6| Step: 2
Training loss: 2.8229432239667425
Validation loss: 2.4767215007840266

Epoch: 6| Step: 3
Training loss: 2.861023141276035
Validation loss: 2.4825265913836003

Epoch: 6| Step: 4
Training loss: 2.5288055296159513
Validation loss: 2.484065806343904

Epoch: 6| Step: 5
Training loss: 2.188548572450104
Validation loss: 2.4844777467861765

Epoch: 6| Step: 6
Training loss: 2.344962658289981
Validation loss: 2.491417880592859

Epoch: 6| Step: 7
Training loss: 2.472733964949237
Validation loss: 2.4980704013411557

Epoch: 6| Step: 8
Training loss: 2.6797381248919208
Validation loss: 2.493322363177389

Epoch: 6| Step: 9
Training loss: 2.173774053650016
Validation loss: 2.5105246656515825

Epoch: 6| Step: 10
Training loss: 2.7369468583009744
Validation loss: 2.5034225242597605

Epoch: 6| Step: 11
Training loss: 2.053106940203105
Validation loss: 2.4984029118996802

Epoch: 6| Step: 12
Training loss: 1.9592247280191193
Validation loss: 2.4930324816071385

Epoch: 6| Step: 13
Training loss: 2.305179039214098
Validation loss: 2.500564447896739

Epoch: 169| Step: 0
Training loss: 2.210922295076637
Validation loss: 2.495883954723041

Epoch: 6| Step: 1
Training loss: 2.5846786892565152
Validation loss: 2.5005565182831067

Epoch: 6| Step: 2
Training loss: 2.387219765079686
Validation loss: 2.5124195756582126

Epoch: 6| Step: 3
Training loss: 1.7758148660091888
Validation loss: 2.5192667031203357

Epoch: 6| Step: 4
Training loss: 2.312389783552479
Validation loss: 2.499796247126539

Epoch: 6| Step: 5
Training loss: 2.3188862639743726
Validation loss: 2.5121098950942646

Epoch: 6| Step: 6
Training loss: 2.4717433503753
Validation loss: 2.502265920549198

Epoch: 6| Step: 7
Training loss: 2.396608431837671
Validation loss: 2.527264742670239

Epoch: 6| Step: 8
Training loss: 1.7532152883633756
Validation loss: 2.526554697905828

Epoch: 6| Step: 9
Training loss: 2.4428854893670633
Validation loss: 2.5386951043789483

Epoch: 6| Step: 10
Training loss: 2.9069093345988
Validation loss: 2.539819528258284

Epoch: 6| Step: 11
Training loss: 2.5394972208980127
Validation loss: 2.5387047070498503

Epoch: 6| Step: 12
Training loss: 2.828783664612619
Validation loss: 2.5430397926169364

Epoch: 6| Step: 13
Training loss: 2.514403052347766
Validation loss: 2.542579335888201

Epoch: 170| Step: 0
Training loss: 2.101178215656972
Validation loss: 2.5401347708303836

Epoch: 6| Step: 1
Training loss: 2.339740018503554
Validation loss: 2.5476560428685198

Epoch: 6| Step: 2
Training loss: 2.4884761332754124
Validation loss: 2.516671115248161

Epoch: 6| Step: 3
Training loss: 2.4872003959535203
Validation loss: 2.5186894392963426

Epoch: 6| Step: 4
Training loss: 2.420733964448746
Validation loss: 2.5255758321359956

Epoch: 6| Step: 5
Training loss: 2.691949222091466
Validation loss: 2.508813739366684

Epoch: 6| Step: 6
Training loss: 1.9640853358529133
Validation loss: 2.503994230489208

Epoch: 6| Step: 7
Training loss: 2.416951940952796
Validation loss: 2.505665827883428

Epoch: 6| Step: 8
Training loss: 2.336886924270443
Validation loss: 2.504238771129394

Epoch: 6| Step: 9
Training loss: 2.4870527699282365
Validation loss: 2.5087477543391103

Epoch: 6| Step: 10
Training loss: 2.0817580052727287
Validation loss: 2.5055194801624334

Epoch: 6| Step: 11
Training loss: 2.679891150384914
Validation loss: 2.512511211895322

Epoch: 6| Step: 12
Training loss: 1.821212153306606
Validation loss: 2.530743332377218

Epoch: 6| Step: 13
Training loss: 2.9405822815665412
Validation loss: 2.54919416934247

Epoch: 171| Step: 0
Training loss: 2.068443519962747
Validation loss: 2.556583910012606

Epoch: 6| Step: 1
Training loss: 1.9152018989923252
Validation loss: 2.5565702944981283

Epoch: 6| Step: 2
Training loss: 2.6008259415045307
Validation loss: 2.551440213713434

Epoch: 6| Step: 3
Training loss: 3.2091763532425164
Validation loss: 2.565530303310207

Epoch: 6| Step: 4
Training loss: 1.8296464636913845
Validation loss: 2.5409036934722327

Epoch: 6| Step: 5
Training loss: 2.9176103609290744
Validation loss: 2.553924353235777

Epoch: 6| Step: 6
Training loss: 2.3647490679989813
Validation loss: 2.549752511374917

Epoch: 6| Step: 7
Training loss: 2.501052444182698
Validation loss: 2.55757046880556

Epoch: 6| Step: 8
Training loss: 2.4644177245486074
Validation loss: 2.53447917719415

Epoch: 6| Step: 9
Training loss: 1.8894678783649121
Validation loss: 2.509630204046529

Epoch: 6| Step: 10
Training loss: 2.8276930842762136
Validation loss: 2.504494021298845

Epoch: 6| Step: 11
Training loss: 2.3628831260084135
Validation loss: 2.5123776945392002

Epoch: 6| Step: 12
Training loss: 1.92967230292757
Validation loss: 2.511808877280132

Epoch: 6| Step: 13
Training loss: 2.1233186240812087
Validation loss: 2.509310614558366

Epoch: 172| Step: 0
Training loss: 2.695454557793977
Validation loss: 2.489205995531446

Epoch: 6| Step: 1
Training loss: 2.218080661445546
Validation loss: 2.4924065026309608

Epoch: 6| Step: 2
Training loss: 2.291389402320436
Validation loss: 2.497278321451346

Epoch: 6| Step: 3
Training loss: 2.2781771513904876
Validation loss: 2.4969126870784875

Epoch: 6| Step: 4
Training loss: 1.987218186653999
Validation loss: 2.4957682716240592

Epoch: 6| Step: 5
Training loss: 2.9061715720474517
Validation loss: 2.5046288394384835

Epoch: 6| Step: 6
Training loss: 1.9932047920607336
Validation loss: 2.504285667583573

Epoch: 6| Step: 7
Training loss: 1.7497035184121195
Validation loss: 2.5076430868600026

Epoch: 6| Step: 8
Training loss: 2.671016086588483
Validation loss: 2.5191400584049055

Epoch: 6| Step: 9
Training loss: 3.021565491093611
Validation loss: 2.522216005207957

Epoch: 6| Step: 10
Training loss: 2.443394112587798
Validation loss: 2.547207707241593

Epoch: 6| Step: 11
Training loss: 2.1676473843317536
Validation loss: 2.5267629059133316

Epoch: 6| Step: 12
Training loss: 2.2028724038622287
Validation loss: 2.542075895498545

Epoch: 6| Step: 13
Training loss: 2.6762767917622963
Validation loss: 2.5350256652586176

Epoch: 173| Step: 0
Training loss: 2.5435229750792225
Validation loss: 2.5455854150541692

Epoch: 6| Step: 1
Training loss: 2.040444559762613
Validation loss: 2.5345750797941506

Epoch: 6| Step: 2
Training loss: 1.9755901613817302
Validation loss: 2.5451315468726627

Epoch: 6| Step: 3
Training loss: 2.6516123958606923
Validation loss: 2.5276009273030113

Epoch: 6| Step: 4
Training loss: 1.61460958480003
Validation loss: 2.527505027345914

Epoch: 6| Step: 5
Training loss: 2.519321545294285
Validation loss: 2.529371294377551

Epoch: 6| Step: 6
Training loss: 2.5479510321889745
Validation loss: 2.522121972301114

Epoch: 6| Step: 7
Training loss: 2.539831989769182
Validation loss: 2.5131912937890024

Epoch: 6| Step: 8
Training loss: 2.594440322380776
Validation loss: 2.520488515763018

Epoch: 6| Step: 9
Training loss: 2.321588544259178
Validation loss: 2.515756560176967

Epoch: 6| Step: 10
Training loss: 2.5834820202112656
Validation loss: 2.529272649347062

Epoch: 6| Step: 11
Training loss: 2.2988410891002866
Validation loss: 2.538606205556697

Epoch: 6| Step: 12
Training loss: 2.8062203556525565
Validation loss: 2.527065916281796

Epoch: 6| Step: 13
Training loss: 2.0997488144104675
Validation loss: 2.5228991490288006

Epoch: 174| Step: 0
Training loss: 2.4612536999242125
Validation loss: 2.5198812157902615

Epoch: 6| Step: 1
Training loss: 2.1527577744515116
Validation loss: 2.531044924242502

Epoch: 6| Step: 2
Training loss: 2.0886750848508977
Validation loss: 2.5094771519981522

Epoch: 6| Step: 3
Training loss: 2.357546470402529
Validation loss: 2.4932116533701203

Epoch: 6| Step: 4
Training loss: 2.6912815192432604
Validation loss: 2.512961167860888

Epoch: 6| Step: 5
Training loss: 2.799799237547015
Validation loss: 2.513109414445157

Epoch: 6| Step: 6
Training loss: 2.7545895858214373
Validation loss: 2.523755961854017

Epoch: 6| Step: 7
Training loss: 2.4214101037544147
Validation loss: 2.5273920179393112

Epoch: 6| Step: 8
Training loss: 2.4626782270503376
Validation loss: 2.548630536484957

Epoch: 6| Step: 9
Training loss: 2.441940761800553
Validation loss: 2.546886740503379

Epoch: 6| Step: 10
Training loss: 2.6368583585725323
Validation loss: 2.5462923065950624

Epoch: 6| Step: 11
Training loss: 1.656893910890435
Validation loss: 2.5382143296139628

Epoch: 6| Step: 12
Training loss: 1.942260615598334
Validation loss: 2.5461187039362274

Epoch: 6| Step: 13
Training loss: 2.3886859484778076
Validation loss: 2.5334568607388426

Epoch: 175| Step: 0
Training loss: 1.988921296650682
Validation loss: 2.524949540996906

Epoch: 6| Step: 1
Training loss: 2.374463372088398
Validation loss: 2.5235202488357364

Epoch: 6| Step: 2
Training loss: 2.7482726133851623
Validation loss: 2.5231750005316522

Epoch: 6| Step: 3
Training loss: 2.8901134141361693
Validation loss: 2.5210694184107836

Epoch: 6| Step: 4
Training loss: 2.7658008584183595
Validation loss: 2.531058410175517

Epoch: 6| Step: 5
Training loss: 2.43469370174683
Validation loss: 2.522106185583518

Epoch: 6| Step: 6
Training loss: 1.9633561374697874
Validation loss: 2.5129653581942946

Epoch: 6| Step: 7
Training loss: 2.207059660872168
Validation loss: 2.5132075792147237

Epoch: 6| Step: 8
Training loss: 2.368215809679477
Validation loss: 2.5154619025834184

Epoch: 6| Step: 9
Training loss: 2.140636694660402
Validation loss: 2.531684916616545

Epoch: 6| Step: 10
Training loss: 2.0049513086509196
Validation loss: 2.541721708191614

Epoch: 6| Step: 11
Training loss: 2.275146890446397
Validation loss: 2.5604966869425927

Epoch: 6| Step: 12
Training loss: 2.442025214506376
Validation loss: 2.5642385632718385

Epoch: 6| Step: 13
Training loss: 2.4219802341363397
Validation loss: 2.5457325578796515

Epoch: 176| Step: 0
Training loss: 2.665718525970923
Validation loss: 2.544941579801481

Epoch: 6| Step: 1
Training loss: 1.8528425081769422
Validation loss: 2.5373585074302323

Epoch: 6| Step: 2
Training loss: 2.1809065496476228
Validation loss: 2.53002760456189

Epoch: 6| Step: 3
Training loss: 2.3444305449139535
Validation loss: 2.5242256846874285

Epoch: 6| Step: 4
Training loss: 2.050362331655202
Validation loss: 2.522465175064393

Epoch: 6| Step: 5
Training loss: 2.790197232429226
Validation loss: 2.5179043349610537

Epoch: 6| Step: 6
Training loss: 2.8010698113966868
Validation loss: 2.5288350551428986

Epoch: 6| Step: 7
Training loss: 2.9461548913454685
Validation loss: 2.534928995927524

Epoch: 6| Step: 8
Training loss: 2.4432323248967567
Validation loss: 2.5372221551877545

Epoch: 6| Step: 9
Training loss: 1.9243264419460462
Validation loss: 2.5436231920531855

Epoch: 6| Step: 10
Training loss: 2.4958584813383164
Validation loss: 2.5552878418122584

Epoch: 6| Step: 11
Training loss: 2.270610926758015
Validation loss: 2.5606668629916447

Epoch: 6| Step: 12
Training loss: 2.047775769229556
Validation loss: 2.5546192467269724

Epoch: 6| Step: 13
Training loss: 2.1435144233832326
Validation loss: 2.542962233949625

Epoch: 177| Step: 0
Training loss: 2.084038373538936
Validation loss: 2.535719563538184

Epoch: 6| Step: 1
Training loss: 2.970223151663644
Validation loss: 2.526599741110608

Epoch: 6| Step: 2
Training loss: 2.8099282268439967
Validation loss: 2.5217671096708925

Epoch: 6| Step: 3
Training loss: 2.1619805743026714
Validation loss: 2.5190360595466403

Epoch: 6| Step: 4
Training loss: 2.3021426876465907
Validation loss: 2.5097319169013526

Epoch: 6| Step: 5
Training loss: 2.3137175988762877
Validation loss: 2.508109149440754

Epoch: 6| Step: 6
Training loss: 2.3532919369839833
Validation loss: 2.510298743320899

Epoch: 6| Step: 7
Training loss: 2.825027371164242
Validation loss: 2.500270129550699

Epoch: 6| Step: 8
Training loss: 2.2553338301512715
Validation loss: 2.4970542400958275

Epoch: 6| Step: 9
Training loss: 2.439710348478412
Validation loss: 2.4949766553705293

Epoch: 6| Step: 10
Training loss: 2.0345776810008647
Validation loss: 2.514283290388128

Epoch: 6| Step: 11
Training loss: 2.522694859308183
Validation loss: 2.507326738603286

Epoch: 6| Step: 12
Training loss: 1.9111121658512034
Validation loss: 2.5208440628033593

Epoch: 6| Step: 13
Training loss: 1.8605546815377245
Validation loss: 2.5189753429240387

Epoch: 178| Step: 0
Training loss: 2.7472072639053815
Validation loss: 2.5368361195005393

Epoch: 6| Step: 1
Training loss: 2.802675338282843
Validation loss: 2.544264510637208

Epoch: 6| Step: 2
Training loss: 2.3154357626910493
Validation loss: 2.561230213069613

Epoch: 6| Step: 3
Training loss: 1.8481148600243698
Validation loss: 2.576926058567861

Epoch: 6| Step: 4
Training loss: 2.255871212090156
Validation loss: 2.586124179090933

Epoch: 6| Step: 5
Training loss: 2.1017940351152733
Validation loss: 2.591620110791757

Epoch: 6| Step: 6
Training loss: 2.499213953422005
Validation loss: 2.5732861586884934

Epoch: 6| Step: 7
Training loss: 2.024563155915379
Validation loss: 2.539856584059488

Epoch: 6| Step: 8
Training loss: 2.0512118223590527
Validation loss: 2.5251116085880465

Epoch: 6| Step: 9
Training loss: 2.758757259219341
Validation loss: 2.51193323401188

Epoch: 6| Step: 10
Training loss: 2.559836515332472
Validation loss: 2.5108370501514687

Epoch: 6| Step: 11
Training loss: 2.3192586335801435
Validation loss: 2.5254989250702935

Epoch: 6| Step: 12
Training loss: 2.303509737796127
Validation loss: 2.5176584306431784

Epoch: 6| Step: 13
Training loss: 2.608916099535687
Validation loss: 2.526616396198405

Epoch: 179| Step: 0
Training loss: 3.2825709999000425
Validation loss: 2.529336072306272

Epoch: 6| Step: 1
Training loss: 2.2866001881685016
Validation loss: 2.51646117219834

Epoch: 6| Step: 2
Training loss: 2.314452094870551
Validation loss: 2.519084155411544

Epoch: 6| Step: 3
Training loss: 1.9421088867972567
Validation loss: 2.5345126972664347

Epoch: 6| Step: 4
Training loss: 2.515318194333253
Validation loss: 2.5298386630533196

Epoch: 6| Step: 5
Training loss: 2.933675508337658
Validation loss: 2.5428070938911116

Epoch: 6| Step: 6
Training loss: 1.8508250381487654
Validation loss: 2.53968453637231

Epoch: 6| Step: 7
Training loss: 2.304053164325708
Validation loss: 2.559198035401217

Epoch: 6| Step: 8
Training loss: 1.599843661299624
Validation loss: 2.5722852130241587

Epoch: 6| Step: 9
Training loss: 2.0464157870646336
Validation loss: 2.5681437548115573

Epoch: 6| Step: 10
Training loss: 2.3843050925229674
Validation loss: 2.5705202553992383

Epoch: 6| Step: 11
Training loss: 2.5680213618771504
Validation loss: 2.555013202277287

Epoch: 6| Step: 12
Training loss: 2.6243814011977444
Validation loss: 2.561100119950805

Epoch: 6| Step: 13
Training loss: 2.161249529086713
Validation loss: 2.53911329952187

Epoch: 180| Step: 0
Training loss: 2.7245379694944236
Validation loss: 2.526605953361104

Epoch: 6| Step: 1
Training loss: 2.226894099656561
Validation loss: 2.5018659542243262

Epoch: 6| Step: 2
Training loss: 2.3478494015670948
Validation loss: 2.496765730801959

Epoch: 6| Step: 3
Training loss: 2.693377787282968
Validation loss: 2.4876948793070497

Epoch: 6| Step: 4
Training loss: 2.7045914745859636
Validation loss: 2.494706693302525

Epoch: 6| Step: 5
Training loss: 2.3425365103987748
Validation loss: 2.494272505883828

Epoch: 6| Step: 6
Training loss: 1.962314562935487
Validation loss: 2.4947180103320767

Epoch: 6| Step: 7
Training loss: 1.694628036781061
Validation loss: 2.500758230939003

Epoch: 6| Step: 8
Training loss: 2.1505179025401087
Validation loss: 2.491739549708505

Epoch: 6| Step: 9
Training loss: 2.396518200275752
Validation loss: 2.5097815843364177

Epoch: 6| Step: 10
Training loss: 2.88063260495189
Validation loss: 2.5235971532181507

Epoch: 6| Step: 11
Training loss: 2.2204956924063413
Validation loss: 2.5271351181305475

Epoch: 6| Step: 12
Training loss: 2.8636179644061
Validation loss: 2.5607050369885114

Epoch: 6| Step: 13
Training loss: 1.9446348059281269
Validation loss: 2.566949996750514

Epoch: 181| Step: 0
Training loss: 1.996812664844012
Validation loss: 2.5824984052369424

Epoch: 6| Step: 1
Training loss: 1.673230058793733
Validation loss: 2.5822716859262744

Epoch: 6| Step: 2
Training loss: 2.7564325527365336
Validation loss: 2.595211773808058

Epoch: 6| Step: 3
Training loss: 2.144092285589866
Validation loss: 2.579115767790695

Epoch: 6| Step: 4
Training loss: 2.4688731295626978
Validation loss: 2.54888918281004

Epoch: 6| Step: 5
Training loss: 2.9981063588357904
Validation loss: 2.548992556046154

Epoch: 6| Step: 6
Training loss: 2.4407556750376043
Validation loss: 2.54442002253725

Epoch: 6| Step: 7
Training loss: 1.5337182218435343
Validation loss: 2.543089895492847

Epoch: 6| Step: 8
Training loss: 2.228878703784502
Validation loss: 2.5367702994646746

Epoch: 6| Step: 9
Training loss: 1.7354809783095344
Validation loss: 2.5153244423453422

Epoch: 6| Step: 10
Training loss: 2.7644631914271116
Validation loss: 2.523046772314025

Epoch: 6| Step: 11
Training loss: 2.6504818388297453
Validation loss: 2.5076661190992584

Epoch: 6| Step: 12
Training loss: 2.6286711679810773
Validation loss: 2.5194419036715967

Epoch: 6| Step: 13
Training loss: 2.6740467547806506
Validation loss: 2.498783562673193

Epoch: 182| Step: 0
Training loss: 2.2620490957880137
Validation loss: 2.51195508004276

Epoch: 6| Step: 1
Training loss: 2.7908168372229305
Validation loss: 2.5091715900073424

Epoch: 6| Step: 2
Training loss: 2.737765580624222
Validation loss: 2.5092347133974418

Epoch: 6| Step: 3
Training loss: 2.2778720668205916
Validation loss: 2.5254739234759773

Epoch: 6| Step: 4
Training loss: 2.4857579826404055
Validation loss: 2.520198715867284

Epoch: 6| Step: 5
Training loss: 2.2946408363490303
Validation loss: 2.5396288978509323

Epoch: 6| Step: 6
Training loss: 2.2300693668815588
Validation loss: 2.554381185943677

Epoch: 6| Step: 7
Training loss: 1.8287524589266513
Validation loss: 2.565288236310213

Epoch: 6| Step: 8
Training loss: 2.1058386652881107
Validation loss: 2.5549432624544064

Epoch: 6| Step: 9
Training loss: 2.1002432500646533
Validation loss: 2.571924262735724

Epoch: 6| Step: 10
Training loss: 2.252004472291073
Validation loss: 2.5921525593756396

Epoch: 6| Step: 11
Training loss: 2.8739799680283817
Validation loss: 2.5560291900649474

Epoch: 6| Step: 12
Training loss: 2.4942980591891883
Validation loss: 2.5388822207883845

Epoch: 6| Step: 13
Training loss: 2.5815004388903775
Validation loss: 2.5125730494417726

Epoch: 183| Step: 0
Training loss: 2.425250254823809
Validation loss: 2.513493632113058

Epoch: 6| Step: 1
Training loss: 2.644508891384434
Validation loss: 2.517282149439405

Epoch: 6| Step: 2
Training loss: 2.4192525139571193
Validation loss: 2.5063418297817894

Epoch: 6| Step: 3
Training loss: 1.9031552066504156
Validation loss: 2.50972184713258

Epoch: 6| Step: 4
Training loss: 2.512837352214684
Validation loss: 2.5124015137204516

Epoch: 6| Step: 5
Training loss: 2.820682406273444
Validation loss: 2.5143312717156032

Epoch: 6| Step: 6
Training loss: 2.2258055353898443
Validation loss: 2.520841982067394

Epoch: 6| Step: 7
Training loss: 2.0417539876312967
Validation loss: 2.5432441823998997

Epoch: 6| Step: 8
Training loss: 2.477871136933141
Validation loss: 2.5463108615908205

Epoch: 6| Step: 9
Training loss: 2.359482718528713
Validation loss: 2.557192726059988

Epoch: 6| Step: 10
Training loss: 2.384088093506122
Validation loss: 2.560089598133331

Epoch: 6| Step: 11
Training loss: 2.3283027734664667
Validation loss: 2.5611991992217384

Epoch: 6| Step: 12
Training loss: 2.0495100459317697
Validation loss: 2.5425901507133624

Epoch: 6| Step: 13
Training loss: 2.6012249518549115
Validation loss: 2.555593425244396

Epoch: 184| Step: 0
Training loss: 2.113091479681243
Validation loss: 2.54066887536508

Epoch: 6| Step: 1
Training loss: 2.527670130224956
Validation loss: 2.527275167062354

Epoch: 6| Step: 2
Training loss: 2.362223743252022
Validation loss: 2.5227604637857683

Epoch: 6| Step: 3
Training loss: 2.5079803885951018
Validation loss: 2.513930861917119

Epoch: 6| Step: 4
Training loss: 2.7628994890197838
Validation loss: 2.5177274491501542

Epoch: 6| Step: 5
Training loss: 1.6458656533202511
Validation loss: 2.514708515918649

Epoch: 6| Step: 6
Training loss: 2.7150966608814664
Validation loss: 2.498808354250883

Epoch: 6| Step: 7
Training loss: 2.3802657729103953
Validation loss: 2.5047053005881335

Epoch: 6| Step: 8
Training loss: 2.2725415119202728
Validation loss: 2.506253400564067

Epoch: 6| Step: 9
Training loss: 2.7991991668961584
Validation loss: 2.509838375318611

Epoch: 6| Step: 10
Training loss: 2.287279391464436
Validation loss: 2.5097199155056495

Epoch: 6| Step: 11
Training loss: 2.143426996481477
Validation loss: 2.5122186886016786

Epoch: 6| Step: 12
Training loss: 2.6118420114508343
Validation loss: 2.512492660334607

Epoch: 6| Step: 13
Training loss: 1.8358865933766808
Validation loss: 2.5342146384120405

Epoch: 185| Step: 0
Training loss: 2.2443509712940695
Validation loss: 2.52078741730627

Epoch: 6| Step: 1
Training loss: 1.7391752879951599
Validation loss: 2.528435794947773

Epoch: 6| Step: 2
Training loss: 2.431709650124736
Validation loss: 2.5319421865713942

Epoch: 6| Step: 3
Training loss: 2.4316395464668794
Validation loss: 2.532209818772778

Epoch: 6| Step: 4
Training loss: 2.8079910586668504
Validation loss: 2.526036155668454

Epoch: 6| Step: 5
Training loss: 2.0713553627118775
Validation loss: 2.507035781826141

Epoch: 6| Step: 6
Training loss: 2.524488011942744
Validation loss: 2.502942793076688

Epoch: 6| Step: 7
Training loss: 1.8109435929729925
Validation loss: 2.4998433222948058

Epoch: 6| Step: 8
Training loss: 2.693152670781214
Validation loss: 2.5061954818973047

Epoch: 6| Step: 9
Training loss: 2.5509015415680336
Validation loss: 2.5166987463399146

Epoch: 6| Step: 10
Training loss: 2.4660303128398917
Validation loss: 2.508450467573691

Epoch: 6| Step: 11
Training loss: 2.056052563125268
Validation loss: 2.52012527126701

Epoch: 6| Step: 12
Training loss: 2.2429678486098417
Validation loss: 2.533523072699741

Epoch: 6| Step: 13
Training loss: 2.74736512273947
Validation loss: 2.535065479348322

Epoch: 186| Step: 0
Training loss: 2.366323181084711
Validation loss: 2.561129226629696

Epoch: 6| Step: 1
Training loss: 2.3369556874427038
Validation loss: 2.5791721567846317

Epoch: 6| Step: 2
Training loss: 1.78408353866972
Validation loss: 2.5951733800877865

Epoch: 6| Step: 3
Training loss: 1.904190076131797
Validation loss: 2.5989832497869503

Epoch: 6| Step: 4
Training loss: 2.2487253181158984
Validation loss: 2.62434674263459

Epoch: 6| Step: 5
Training loss: 2.770971873173332
Validation loss: 2.6199057056843182

Epoch: 6| Step: 6
Training loss: 1.8645167063596044
Validation loss: 2.5943601495766084

Epoch: 6| Step: 7
Training loss: 2.87422153050754
Validation loss: 2.5629748703023187

Epoch: 6| Step: 8
Training loss: 2.049452810994537
Validation loss: 2.565233331258651

Epoch: 6| Step: 9
Training loss: 2.8294345921737016
Validation loss: 2.5262833207676327

Epoch: 6| Step: 10
Training loss: 2.4743550086315897
Validation loss: 2.518252357184145

Epoch: 6| Step: 11
Training loss: 1.9900350873336303
Validation loss: 2.527993623253671

Epoch: 6| Step: 12
Training loss: 2.6128268680786544
Validation loss: 2.5229400207379427

Epoch: 6| Step: 13
Training loss: 2.935952935779673
Validation loss: 2.5201833270514347

Epoch: 187| Step: 0
Training loss: 1.886079099280806
Validation loss: 2.5151330533991767

Epoch: 6| Step: 1
Training loss: 1.9720127982523206
Validation loss: 2.5021992705517606

Epoch: 6| Step: 2
Training loss: 2.538183629444447
Validation loss: 2.506529157824451

Epoch: 6| Step: 3
Training loss: 3.154894849472874
Validation loss: 2.507792186555759

Epoch: 6| Step: 4
Training loss: 2.863705383779108
Validation loss: 2.5188044009711357

Epoch: 6| Step: 5
Training loss: 2.4082508438221337
Validation loss: 2.510190016987087

Epoch: 6| Step: 6
Training loss: 1.9896558645185998
Validation loss: 2.5203607026811996

Epoch: 6| Step: 7
Training loss: 2.428765321252297
Validation loss: 2.508163411752292

Epoch: 6| Step: 8
Training loss: 1.9652733759686614
Validation loss: 2.528618657561605

Epoch: 6| Step: 9
Training loss: 2.3072724926383628
Validation loss: 2.5323623913066102

Epoch: 6| Step: 10
Training loss: 2.6364196155548205
Validation loss: 2.5406892387523885

Epoch: 6| Step: 11
Training loss: 2.6777352653741224
Validation loss: 2.5425354666097593

Epoch: 6| Step: 12
Training loss: 1.9649919033126393
Validation loss: 2.5492622093543527

Epoch: 6| Step: 13
Training loss: 2.705221256366739
Validation loss: 2.537370041399115

Epoch: 188| Step: 0
Training loss: 2.478825350648681
Validation loss: 2.524044566164564

Epoch: 6| Step: 1
Training loss: 2.6781748959534792
Validation loss: 2.5315108459198123

Epoch: 6| Step: 2
Training loss: 1.6730193740397854
Validation loss: 2.506997709920695

Epoch: 6| Step: 3
Training loss: 2.2884961361726393
Validation loss: 2.502264634254397

Epoch: 6| Step: 4
Training loss: 2.3729759425484227
Validation loss: 2.499570428181501

Epoch: 6| Step: 5
Training loss: 2.45988340054957
Validation loss: 2.49486706220919

Epoch: 6| Step: 6
Training loss: 2.625983825877831
Validation loss: 2.5008987877413356

Epoch: 6| Step: 7
Training loss: 2.4023193358134436
Validation loss: 2.5013854002823814

Epoch: 6| Step: 8
Training loss: 2.6984636103388984
Validation loss: 2.5063820598814175

Epoch: 6| Step: 9
Training loss: 2.3419530464892864
Validation loss: 2.504519605175397

Epoch: 6| Step: 10
Training loss: 2.3265025995151043
Validation loss: 2.5195665618235674

Epoch: 6| Step: 11
Training loss: 2.054240943334419
Validation loss: 2.523567408946862

Epoch: 6| Step: 12
Training loss: 2.683783689659675
Validation loss: 2.550783633454452

Epoch: 6| Step: 13
Training loss: 2.2854207203729704
Validation loss: 2.5516834542610716

Epoch: 189| Step: 0
Training loss: 2.3956779982478995
Validation loss: 2.5697738716943292

Epoch: 6| Step: 1
Training loss: 2.297458081615372
Validation loss: 2.592085629868779

Epoch: 6| Step: 2
Training loss: 2.269332483093485
Validation loss: 2.5945038063951116

Epoch: 6| Step: 3
Training loss: 2.7369229897427196
Validation loss: 2.6030262141051446

Epoch: 6| Step: 4
Training loss: 2.6492585566462514
Validation loss: 2.591834544502417

Epoch: 6| Step: 5
Training loss: 2.4395223200004286
Validation loss: 2.5527015923260814

Epoch: 6| Step: 6
Training loss: 2.782549093932404
Validation loss: 2.563664396640221

Epoch: 6| Step: 7
Training loss: 1.929111719138527
Validation loss: 2.5595784163537774

Epoch: 6| Step: 8
Training loss: 1.901150621052799
Validation loss: 2.554299514659469

Epoch: 6| Step: 9
Training loss: 2.2485111396824076
Validation loss: 2.5391737928208085

Epoch: 6| Step: 10
Training loss: 1.9793136809775953
Validation loss: 2.5453812288794038

Epoch: 6| Step: 11
Training loss: 2.0376085966224684
Validation loss: 2.5444792574602184

Epoch: 6| Step: 12
Training loss: 2.8604779226954413
Validation loss: 2.5346524796551235

Epoch: 6| Step: 13
Training loss: 2.5932157954504444
Validation loss: 2.5262469860413153

Epoch: 190| Step: 0
Training loss: 2.911966915215147
Validation loss: 2.5149659345859106

Epoch: 6| Step: 1
Training loss: 2.102847702541249
Validation loss: 2.525094487213252

Epoch: 6| Step: 2
Training loss: 2.0923721562462005
Validation loss: 2.5194159350756005

Epoch: 6| Step: 3
Training loss: 1.7618601672470733
Validation loss: 2.528075641390728

Epoch: 6| Step: 4
Training loss: 2.8333671418211166
Validation loss: 2.5293904290884557

Epoch: 6| Step: 5
Training loss: 2.610273012519981
Validation loss: 2.538564271217066

Epoch: 6| Step: 6
Training loss: 2.3501001417859024
Validation loss: 2.529310975102972

Epoch: 6| Step: 7
Training loss: 2.615893872660212
Validation loss: 2.5510259708551493

Epoch: 6| Step: 8
Training loss: 2.1644423389011163
Validation loss: 2.5558570416767457

Epoch: 6| Step: 9
Training loss: 1.7342292793161187
Validation loss: 2.5559369841475332

Epoch: 6| Step: 10
Training loss: 2.719522651411105
Validation loss: 2.5779994124832846

Epoch: 6| Step: 11
Training loss: 1.996337517412563
Validation loss: 2.56252070162715

Epoch: 6| Step: 12
Training loss: 2.1024540141153447
Validation loss: 2.5841611233229127

Epoch: 6| Step: 13
Training loss: 2.6221256868279967
Validation loss: 2.561475828239532

Epoch: 191| Step: 0
Training loss: 2.6345906125274334
Validation loss: 2.5726859005955958

Epoch: 6| Step: 1
Training loss: 2.5056656534384807
Validation loss: 2.558437414464797

Epoch: 6| Step: 2
Training loss: 2.149818670033796
Validation loss: 2.5605876035770674

Epoch: 6| Step: 3
Training loss: 2.0180806423214
Validation loss: 2.569067687401474

Epoch: 6| Step: 4
Training loss: 2.0296222914160627
Validation loss: 2.580747715292801

Epoch: 6| Step: 5
Training loss: 2.654154321071911
Validation loss: 2.571853500406131

Epoch: 6| Step: 6
Training loss: 2.8231027595770564
Validation loss: 2.5613589033385837

Epoch: 6| Step: 7
Training loss: 2.3971456720539273
Validation loss: 2.551018322710236

Epoch: 6| Step: 8
Training loss: 2.6132695720964785
Validation loss: 2.5646767868587346

Epoch: 6| Step: 9
Training loss: 1.6052471666963077
Validation loss: 2.581455830271709

Epoch: 6| Step: 10
Training loss: 2.4112450414026196
Validation loss: 2.5611411500324435

Epoch: 6| Step: 11
Training loss: 2.660100502180634
Validation loss: 2.5678049550373685

Epoch: 6| Step: 12
Training loss: 2.3916624722682136
Validation loss: 2.5781425552541113

Epoch: 6| Step: 13
Training loss: 1.4936319120966912
Validation loss: 2.5744154473399834

Epoch: 192| Step: 0
Training loss: 2.6908489032230714
Validation loss: 2.5631784998468063

Epoch: 6| Step: 1
Training loss: 1.8864637877878514
Validation loss: 2.5594344682192918

Epoch: 6| Step: 2
Training loss: 1.7561745026675397
Validation loss: 2.5565871195953545

Epoch: 6| Step: 3
Training loss: 2.351636207413949
Validation loss: 2.59898366259589

Epoch: 6| Step: 4
Training loss: 2.182547931297755
Validation loss: 2.592301496620817

Epoch: 6| Step: 5
Training loss: 1.8296080222650748
Validation loss: 2.5961835238217668

Epoch: 6| Step: 6
Training loss: 2.292889309340443
Validation loss: 2.609309578263899

Epoch: 6| Step: 7
Training loss: 2.4953219514499407
Validation loss: 2.612034217403937

Epoch: 6| Step: 8
Training loss: 2.7027677619681416
Validation loss: 2.601146324862119

Epoch: 6| Step: 9
Training loss: 2.552616878452703
Validation loss: 2.5791369754353806

Epoch: 6| Step: 10
Training loss: 2.3924224678320094
Validation loss: 2.5559420368256767

Epoch: 6| Step: 11
Training loss: 2.639922460515494
Validation loss: 2.5563381901135007

Epoch: 6| Step: 12
Training loss: 2.369672622764759
Validation loss: 2.531276836174514

Epoch: 6| Step: 13
Training loss: 2.5012009597081013
Validation loss: 2.534262038542334

Epoch: 193| Step: 0
Training loss: 2.068783638211047
Validation loss: 2.5257595153748165

Epoch: 6| Step: 1
Training loss: 3.110488615504815
Validation loss: 2.5462022606668016

Epoch: 6| Step: 2
Training loss: 2.4853661437440637
Validation loss: 2.5423926635060567

Epoch: 6| Step: 3
Training loss: 1.954296035659674
Validation loss: 2.545792612935345

Epoch: 6| Step: 4
Training loss: 1.8047625373334049
Validation loss: 2.5541398358660072

Epoch: 6| Step: 5
Training loss: 2.3491003384066724
Validation loss: 2.5423297694559586

Epoch: 6| Step: 6
Training loss: 2.777884000230714
Validation loss: 2.527399627523799

Epoch: 6| Step: 7
Training loss: 2.129834901742198
Validation loss: 2.5364842397214105

Epoch: 6| Step: 8
Training loss: 2.4762479660588115
Validation loss: 2.5255946809326604

Epoch: 6| Step: 9
Training loss: 2.4306222767224877
Validation loss: 2.5263709466525555

Epoch: 6| Step: 10
Training loss: 1.6238863136450024
Validation loss: 2.5370132392835574

Epoch: 6| Step: 11
Training loss: 2.4031165391949156
Validation loss: 2.5419098993035867

Epoch: 6| Step: 12
Training loss: 2.5441688249039287
Validation loss: 2.5486831799214236

Epoch: 6| Step: 13
Training loss: 2.2662074951629676
Validation loss: 2.545345455586259

Epoch: 194| Step: 0
Training loss: 2.6121913307765157
Validation loss: 2.570218456522848

Epoch: 6| Step: 1
Training loss: 2.3850707312757993
Validation loss: 2.578080934090145

Epoch: 6| Step: 2
Training loss: 2.5939404521098393
Validation loss: 2.578153667868547

Epoch: 6| Step: 3
Training loss: 2.174249023928538
Validation loss: 2.5732683463941566

Epoch: 6| Step: 4
Training loss: 2.1446608763049295
Validation loss: 2.564642483493687

Epoch: 6| Step: 5
Training loss: 2.7176594794256435
Validation loss: 2.549552664445815

Epoch: 6| Step: 6
Training loss: 2.754963470327575
Validation loss: 2.5361491229590793

Epoch: 6| Step: 7
Training loss: 2.557851156549673
Validation loss: 2.516922183886379

Epoch: 6| Step: 8
Training loss: 1.9923936325839968
Validation loss: 2.507215529837527

Epoch: 6| Step: 9
Training loss: 2.3693544648250864
Validation loss: 2.5088224348157877

Epoch: 6| Step: 10
Training loss: 2.583269477383175
Validation loss: 2.503234471639091

Epoch: 6| Step: 11
Training loss: 1.6126432843089502
Validation loss: 2.510156362078249

Epoch: 6| Step: 12
Training loss: 1.9972025260903206
Validation loss: 2.513681502127422

Epoch: 6| Step: 13
Training loss: 2.2831934136542293
Validation loss: 2.5308722539912494

Epoch: 195| Step: 0
Training loss: 2.5119261470616996
Validation loss: 2.54381617866928

Epoch: 6| Step: 1
Training loss: 1.9546538815858694
Validation loss: 2.5710619884017865

Epoch: 6| Step: 2
Training loss: 2.744357475862477
Validation loss: 2.5896833781534903

Epoch: 6| Step: 3
Training loss: 2.075307901357534
Validation loss: 2.6081889763597306

Epoch: 6| Step: 4
Training loss: 2.572090160320233
Validation loss: 2.627427840326319

Epoch: 6| Step: 5
Training loss: 2.302849919572527
Validation loss: 2.608189608622827

Epoch: 6| Step: 6
Training loss: 2.7672970991869406
Validation loss: 2.642187450069801

Epoch: 6| Step: 7
Training loss: 2.016441002612425
Validation loss: 2.61424598695923

Epoch: 6| Step: 8
Training loss: 1.7810879014527654
Validation loss: 2.5842014566601677

Epoch: 6| Step: 9
Training loss: 2.9842161765452735
Validation loss: 2.536941738135804

Epoch: 6| Step: 10
Training loss: 2.7409442572118423
Validation loss: 2.517728695979783

Epoch: 6| Step: 11
Training loss: 1.7125039093641223
Validation loss: 2.5184901410287845

Epoch: 6| Step: 12
Training loss: 1.735279637758385
Validation loss: 2.5000377175346915

Epoch: 6| Step: 13
Training loss: 2.599749692458861
Validation loss: 2.4913495128794567

Epoch: 196| Step: 0
Training loss: 2.096281883620546
Validation loss: 2.491392393443476

Epoch: 6| Step: 1
Training loss: 2.9096726803038084
Validation loss: 2.501698560666016

Epoch: 6| Step: 2
Training loss: 2.1812558018298445
Validation loss: 2.511794417899186

Epoch: 6| Step: 3
Training loss: 2.0602200940524535
Validation loss: 2.5146651875453467

Epoch: 6| Step: 4
Training loss: 1.6952693248120434
Validation loss: 2.528468389338533

Epoch: 6| Step: 5
Training loss: 2.1432947370495974
Validation loss: 2.5623152596474905

Epoch: 6| Step: 6
Training loss: 2.551189582703675
Validation loss: 2.58154363062791

Epoch: 6| Step: 7
Training loss: 2.6766772920897224
Validation loss: 2.5890636007444368

Epoch: 6| Step: 8
Training loss: 3.02309161432967
Validation loss: 2.5899226357407303

Epoch: 6| Step: 9
Training loss: 2.933675183259316
Validation loss: 2.592897022125289

Epoch: 6| Step: 10
Training loss: 2.635364868700427
Validation loss: 2.566338176782512

Epoch: 6| Step: 11
Training loss: 1.8996861750778042
Validation loss: 2.573984400762454

Epoch: 6| Step: 12
Training loss: 1.8989561024072223
Validation loss: 2.5464820168578814

Epoch: 6| Step: 13
Training loss: 2.1583051976710674
Validation loss: 2.543892594448365

Epoch: 197| Step: 0
Training loss: 2.13131560730844
Validation loss: 2.518396734259668

Epoch: 6| Step: 1
Training loss: 2.5541553001296093
Validation loss: 2.5228749091937095

Epoch: 6| Step: 2
Training loss: 2.4622450488409946
Validation loss: 2.5106057429570274

Epoch: 6| Step: 3
Training loss: 2.623575641568905
Validation loss: 2.5117689318511234

Epoch: 6| Step: 4
Training loss: 2.5017415656310416
Validation loss: 2.5107902048456014

Epoch: 6| Step: 5
Training loss: 2.5694593503594123
Validation loss: 2.5262772492869607

Epoch: 6| Step: 6
Training loss: 2.4329426538911276
Validation loss: 2.5223380135281506

Epoch: 6| Step: 7
Training loss: 2.5972944194077083
Validation loss: 2.537902817597277

Epoch: 6| Step: 8
Training loss: 2.173328599320075
Validation loss: 2.5588617781397716

Epoch: 6| Step: 9
Training loss: 2.0609273984023786
Validation loss: 2.589085018510489

Epoch: 6| Step: 10
Training loss: 2.173169086701385
Validation loss: 2.5911736466082775

Epoch: 6| Step: 11
Training loss: 1.7859918487636213
Validation loss: 2.5942353709830592

Epoch: 6| Step: 12
Training loss: 2.076740348553781
Validation loss: 2.599270258489543

Epoch: 6| Step: 13
Training loss: 2.5074145990739485
Validation loss: 2.591550783242563

Epoch: 198| Step: 0
Training loss: 2.360320855328804
Validation loss: 2.596427439449956

Epoch: 6| Step: 1
Training loss: 2.5862384171592967
Validation loss: 2.5941057535730545

Epoch: 6| Step: 2
Training loss: 2.699123706607264
Validation loss: 2.599186160410039

Epoch: 6| Step: 3
Training loss: 2.600229282539781
Validation loss: 2.613510813606349

Epoch: 6| Step: 4
Training loss: 2.504948106178736
Validation loss: 2.584456327881539

Epoch: 6| Step: 5
Training loss: 2.6423441691000993
Validation loss: 2.547317209059296

Epoch: 6| Step: 6
Training loss: 2.179804316846173
Validation loss: 2.520769312862692

Epoch: 6| Step: 7
Training loss: 2.4735061607060493
Validation loss: 2.5193833418613156

Epoch: 6| Step: 8
Training loss: 2.5044881587861423
Validation loss: 2.5087900920275317

Epoch: 6| Step: 9
Training loss: 1.6907404410670044
Validation loss: 2.500590127595164

Epoch: 6| Step: 10
Training loss: 2.4925094922649267
Validation loss: 2.506162375855046

Epoch: 6| Step: 11
Training loss: 2.0228397856330202
Validation loss: 2.496291923317358

Epoch: 6| Step: 12
Training loss: 2.0274589961523515
Validation loss: 2.4982554547736946

Epoch: 6| Step: 13
Training loss: 2.421600621585873
Validation loss: 2.5052849697728794

Epoch: 199| Step: 0
Training loss: 2.6351409486427606
Validation loss: 2.4987998386340666

Epoch: 6| Step: 1
Training loss: 1.7748079760203934
Validation loss: 2.509556370978313

Epoch: 6| Step: 2
Training loss: 2.1675962385835903
Validation loss: 2.5116697378800046

Epoch: 6| Step: 3
Training loss: 2.0867573130767267
Validation loss: 2.5232775217214125

Epoch: 6| Step: 4
Training loss: 1.9982614113042654
Validation loss: 2.549031240036115

Epoch: 6| Step: 5
Training loss: 1.9783551074755044
Validation loss: 2.548297149579286

Epoch: 6| Step: 6
Training loss: 2.9053151257513243
Validation loss: 2.5539680113296446

Epoch: 6| Step: 7
Training loss: 2.1859688986322183
Validation loss: 2.555433718453758

Epoch: 6| Step: 8
Training loss: 2.5813784329511287
Validation loss: 2.5536159091674175

Epoch: 6| Step: 9
Training loss: 2.958226555701642
Validation loss: 2.5357439626572775

Epoch: 6| Step: 10
Training loss: 2.018418852393202
Validation loss: 2.512504711747694

Epoch: 6| Step: 11
Training loss: 2.039592571711699
Validation loss: 2.511884067883196

Epoch: 6| Step: 12
Training loss: 3.0274352619737215
Validation loss: 2.5042652779287953

Epoch: 6| Step: 13
Training loss: 2.3961086833676317
Validation loss: 2.5046186539613244

Epoch: 200| Step: 0
Training loss: 2.2619738393766657
Validation loss: 2.5160082728477846

Epoch: 6| Step: 1
Training loss: 2.5066852828951047
Validation loss: 2.521464912384745

Epoch: 6| Step: 2
Training loss: 2.5635511521886385
Validation loss: 2.5122330506376485

Epoch: 6| Step: 3
Training loss: 2.663714523186589
Validation loss: 2.536936898226258

Epoch: 6| Step: 4
Training loss: 2.133483781079298
Validation loss: 2.5478295719693485

Epoch: 6| Step: 5
Training loss: 2.6117051736134758
Validation loss: 2.5481538272836683

Epoch: 6| Step: 6
Training loss: 1.3368127643781662
Validation loss: 2.530513420782433

Epoch: 6| Step: 7
Training loss: 2.928725753599152
Validation loss: 2.516780879942682

Epoch: 6| Step: 8
Training loss: 1.9756037984239572
Validation loss: 2.529412422830224

Epoch: 6| Step: 9
Training loss: 2.7246823536933316
Validation loss: 2.522896487225934

Epoch: 6| Step: 10
Training loss: 2.024870493950897
Validation loss: 2.543430143924444

Epoch: 6| Step: 11
Training loss: 2.0831196357481727
Validation loss: 2.5407499916827114

Epoch: 6| Step: 12
Training loss: 1.9474627396002593
Validation loss: 2.545575346624413

Epoch: 6| Step: 13
Training loss: 2.181389694331381
Validation loss: 2.559713383663559

Epoch: 201| Step: 0
Training loss: 2.5257098946844496
Validation loss: 2.57527178468888

Epoch: 6| Step: 1
Training loss: 2.7040155079526698
Validation loss: 2.5757691842512855

Epoch: 6| Step: 2
Training loss: 2.358551892328976
Validation loss: 2.572460154653294

Epoch: 6| Step: 3
Training loss: 2.2819136607881876
Validation loss: 2.5505577717783923

Epoch: 6| Step: 4
Training loss: 1.9652253343514101
Validation loss: 2.5271496469760275

Epoch: 6| Step: 5
Training loss: 2.529520550709399
Validation loss: 2.50770088494073

Epoch: 6| Step: 6
Training loss: 2.451836897772527
Validation loss: 2.5109962227044864

Epoch: 6| Step: 7
Training loss: 2.451847594237091
Validation loss: 2.510180400214169

Epoch: 6| Step: 8
Training loss: 2.723249811302577
Validation loss: 2.5000845179576343

Epoch: 6| Step: 9
Training loss: 2.338309114330301
Validation loss: 2.502753140517254

Epoch: 6| Step: 10
Training loss: 1.6655666376878644
Validation loss: 2.490806005355006

Epoch: 6| Step: 11
Training loss: 2.730570473365569
Validation loss: 2.508207787152595

Epoch: 6| Step: 12
Training loss: 1.7606910702377812
Validation loss: 2.5233076552298552

Epoch: 6| Step: 13
Training loss: 2.3200434776046923
Validation loss: 2.5380166741382806

Epoch: 202| Step: 0
Training loss: 1.896484689290171
Validation loss: 2.540849825400076

Epoch: 6| Step: 1
Training loss: 1.9709728347516562
Validation loss: 2.58425349080963

Epoch: 6| Step: 2
Training loss: 2.715028956840187
Validation loss: 2.593638115120459

Epoch: 6| Step: 3
Training loss: 2.248115067893543
Validation loss: 2.614521806051237

Epoch: 6| Step: 4
Training loss: 2.6096929482097213
Validation loss: 2.6294848111048785

Epoch: 6| Step: 5
Training loss: 2.456186995535428
Validation loss: 2.622949813823201

Epoch: 6| Step: 6
Training loss: 2.564502398910189
Validation loss: 2.6439609710950323

Epoch: 6| Step: 7
Training loss: 2.140694498757756
Validation loss: 2.634351738841759

Epoch: 6| Step: 8
Training loss: 2.4418772006702296
Validation loss: 2.598194680306162

Epoch: 6| Step: 9
Training loss: 2.2570573540508665
Validation loss: 2.572948120995713

Epoch: 6| Step: 10
Training loss: 2.2635433762870565
Validation loss: 2.525873360811197

Epoch: 6| Step: 11
Training loss: 2.5697180341715478
Validation loss: 2.5108689076253876

Epoch: 6| Step: 12
Training loss: 2.4964379683675753
Validation loss: 2.499507728429899

Epoch: 6| Step: 13
Training loss: 2.4826908761178146
Validation loss: 2.4952006366508366

Epoch: 203| Step: 0
Training loss: 2.6127389935411385
Validation loss: 2.5014601893632684

Epoch: 6| Step: 1
Training loss: 2.4504440138826555
Validation loss: 2.503548305435269

Epoch: 6| Step: 2
Training loss: 2.7430822754750968
Validation loss: 2.503774194116453

Epoch: 6| Step: 3
Training loss: 2.222388279856351
Validation loss: 2.5040809621970963

Epoch: 6| Step: 4
Training loss: 1.6483722691940375
Validation loss: 2.5185186514927116

Epoch: 6| Step: 5
Training loss: 2.699169285454873
Validation loss: 2.5299381734307342

Epoch: 6| Step: 6
Training loss: 2.20959453436295
Validation loss: 2.5490528616598866

Epoch: 6| Step: 7
Training loss: 2.499998760223081
Validation loss: 2.5861670784972564

Epoch: 6| Step: 8
Training loss: 2.1704198779134076
Validation loss: 2.5841651520718987

Epoch: 6| Step: 9
Training loss: 2.5912452461430933
Validation loss: 2.579857400235747

Epoch: 6| Step: 10
Training loss: 1.8275739703361313
Validation loss: 2.5788196282995717

Epoch: 6| Step: 11
Training loss: 2.614129035864508
Validation loss: 2.5556617146939047

Epoch: 6| Step: 12
Training loss: 2.073369946274072
Validation loss: 2.5527634681030325

Epoch: 6| Step: 13
Training loss: 2.3398613777834
Validation loss: 2.562787536057926

Epoch: 204| Step: 0
Training loss: 2.0646537170833428
Validation loss: 2.545771041665779

Epoch: 6| Step: 1
Training loss: 2.513303929855947
Validation loss: 2.5328582709332492

Epoch: 6| Step: 2
Training loss: 2.083020288472073
Validation loss: 2.542362638980902

Epoch: 6| Step: 3
Training loss: 2.215588103123005
Validation loss: 2.547609515845001

Epoch: 6| Step: 4
Training loss: 1.7759725458411633
Validation loss: 2.5230480086402847

Epoch: 6| Step: 5
Training loss: 2.267711862173797
Validation loss: 2.5293919372368556

Epoch: 6| Step: 6
Training loss: 2.6770378336521836
Validation loss: 2.5284177138376664

Epoch: 6| Step: 7
Training loss: 1.7254105950016634
Validation loss: 2.539525073047911

Epoch: 6| Step: 8
Training loss: 2.5473784902717096
Validation loss: 2.531472247378517

Epoch: 6| Step: 9
Training loss: 2.9217530903398807
Validation loss: 2.5322506186640545

Epoch: 6| Step: 10
Training loss: 2.274337747619421
Validation loss: 2.557729886817542

Epoch: 6| Step: 11
Training loss: 1.8381126991231345
Validation loss: 2.5637522793193512

Epoch: 6| Step: 12
Training loss: 2.9236521492738516
Validation loss: 2.5647890675192553

Epoch: 6| Step: 13
Training loss: 2.3528493610868497
Validation loss: 2.565941538703988

Epoch: 205| Step: 0
Training loss: 2.98852538065275
Validation loss: 2.57134124977206

Epoch: 6| Step: 1
Training loss: 2.465478201824521
Validation loss: 2.5776871588781303

Epoch: 6| Step: 2
Training loss: 2.0663441755060914
Validation loss: 2.5738105045004347

Epoch: 6| Step: 3
Training loss: 2.3439820238341977
Validation loss: 2.5828204158500885

Epoch: 6| Step: 4
Training loss: 2.08662568930629
Validation loss: 2.5575374373812334

Epoch: 6| Step: 5
Training loss: 2.4592771711850445
Validation loss: 2.5479492854985506

Epoch: 6| Step: 6
Training loss: 1.9175790052786863
Validation loss: 2.5402599465024935

Epoch: 6| Step: 7
Training loss: 1.706401647738463
Validation loss: 2.5297087619980454

Epoch: 6| Step: 8
Training loss: 2.3636986734273484
Validation loss: 2.530238518522418

Epoch: 6| Step: 9
Training loss: 2.5881731678013935
Validation loss: 2.5484624646661875

Epoch: 6| Step: 10
Training loss: 2.3705317979831073
Validation loss: 2.531384672499099

Epoch: 6| Step: 11
Training loss: 1.688135380690067
Validation loss: 2.5517862782847462

Epoch: 6| Step: 12
Training loss: 2.3738784149452288
Validation loss: 2.5616099509879264

Epoch: 6| Step: 13
Training loss: 2.7080515690489837
Validation loss: 2.5621340575640548

Epoch: 206| Step: 0
Training loss: 2.421288893135682
Validation loss: 2.576675500776471

Epoch: 6| Step: 1
Training loss: 2.8106208457517385
Validation loss: 2.561133539851412

Epoch: 6| Step: 2
Training loss: 2.615052493937937
Validation loss: 2.569471258304203

Epoch: 6| Step: 3
Training loss: 2.8134428351306253
Validation loss: 2.5519999483979476

Epoch: 6| Step: 4
Training loss: 2.0026481501226563
Validation loss: 2.5350383462708006

Epoch: 6| Step: 5
Training loss: 1.8581812256057275
Validation loss: 2.5177998431590205

Epoch: 6| Step: 6
Training loss: 2.0903034595870573
Validation loss: 2.522319518489251

Epoch: 6| Step: 7
Training loss: 3.226030726173547
Validation loss: 2.5240171729227567

Epoch: 6| Step: 8
Training loss: 1.4884185327205997
Validation loss: 2.5492285714723586

Epoch: 6| Step: 9
Training loss: 2.003827842680555
Validation loss: 2.5362085823899956

Epoch: 6| Step: 10
Training loss: 1.6233839655871132
Validation loss: 2.5528898923862555

Epoch: 6| Step: 11
Training loss: 2.32410898670701
Validation loss: 2.5849353965320847

Epoch: 6| Step: 12
Training loss: 2.370907117860891
Validation loss: 2.5738525284485294

Epoch: 6| Step: 13
Training loss: 2.0986659853706726
Validation loss: 2.6017138768355643

Epoch: 207| Step: 0
Training loss: 1.638468023812907
Validation loss: 2.6284150963279247

Epoch: 6| Step: 1
Training loss: 2.764373409883998
Validation loss: 2.6120113828478213

Epoch: 6| Step: 2
Training loss: 2.1674242040279745
Validation loss: 2.618391301027178

Epoch: 6| Step: 3
Training loss: 2.399821922530332
Validation loss: 2.6302543157706415

Epoch: 6| Step: 4
Training loss: 2.398653300265945
Validation loss: 2.6366806668015563

Epoch: 6| Step: 5
Training loss: 1.878714632981863
Validation loss: 2.615999306983934

Epoch: 6| Step: 6
Training loss: 2.446727988941083
Validation loss: 2.5987123641823566

Epoch: 6| Step: 7
Training loss: 2.2215414620461917
Validation loss: 2.5529287897088513

Epoch: 6| Step: 8
Training loss: 2.9040417228833113
Validation loss: 2.5428800787166885

Epoch: 6| Step: 9
Training loss: 1.8030454092459054
Validation loss: 2.5279778417660395

Epoch: 6| Step: 10
Training loss: 3.000891235211034
Validation loss: 2.527368088476801

Epoch: 6| Step: 11
Training loss: 1.647958477983247
Validation loss: 2.527454591941258

Epoch: 6| Step: 12
Training loss: 2.8753325228579034
Validation loss: 2.532196629282704

Epoch: 6| Step: 13
Training loss: 1.8895505263716623
Validation loss: 2.5621810497493223

Epoch: 208| Step: 0
Training loss: 1.9715742410820203
Validation loss: 2.5606668785096454

Epoch: 6| Step: 1
Training loss: 2.4568065061412883
Validation loss: 2.5503540460229663

Epoch: 6| Step: 2
Training loss: 2.4493536661031277
Validation loss: 2.571481479467564

Epoch: 6| Step: 3
Training loss: 2.307170603541848
Validation loss: 2.591268570387636

Epoch: 6| Step: 4
Training loss: 2.7469422072867387
Validation loss: 2.5686301587838076

Epoch: 6| Step: 5
Training loss: 1.8269352750332362
Validation loss: 2.5507645969129613

Epoch: 6| Step: 6
Training loss: 2.439816083699309
Validation loss: 2.540427614671983

Epoch: 6| Step: 7
Training loss: 2.266029584868276
Validation loss: 2.5339640756563058

Epoch: 6| Step: 8
Training loss: 1.9796616453967903
Validation loss: 2.52536403310592

Epoch: 6| Step: 9
Training loss: 3.172631986140596
Validation loss: 2.519291608586881

Epoch: 6| Step: 10
Training loss: 2.77757732197891
Validation loss: 2.5035495672624806

Epoch: 6| Step: 11
Training loss: 2.442253661525581
Validation loss: 2.4925376303334184

Epoch: 6| Step: 12
Training loss: 1.4111132980106125
Validation loss: 2.5052614635985244

Epoch: 6| Step: 13
Training loss: 1.7660443643460317
Validation loss: 2.5039034331132792

Epoch: 209| Step: 0
Training loss: 2.6606547018897415
Validation loss: 2.501254736422265

Epoch: 6| Step: 1
Training loss: 2.037151859239099
Validation loss: 2.5003403273044187

Epoch: 6| Step: 2
Training loss: 2.4852345257315624
Validation loss: 2.4950334966649614

Epoch: 6| Step: 3
Training loss: 2.3324998547716493
Validation loss: 2.5021645870773925

Epoch: 6| Step: 4
Training loss: 2.4992474376943505
Validation loss: 2.513562180052953

Epoch: 6| Step: 5
Training loss: 2.644604184653641
Validation loss: 2.516037672167654

Epoch: 6| Step: 6
Training loss: 2.456264746235852
Validation loss: 2.5452347917054006

Epoch: 6| Step: 7
Training loss: 1.5582939758362553
Validation loss: 2.5740208180674222

Epoch: 6| Step: 8
Training loss: 2.514682948792308
Validation loss: 2.578775982598729

Epoch: 6| Step: 9
Training loss: 1.652871699117783
Validation loss: 2.602396040106418

Epoch: 6| Step: 10
Training loss: 2.532412226851415
Validation loss: 2.612598704491848

Epoch: 6| Step: 11
Training loss: 2.5322042479673854
Validation loss: 2.603615455783446

Epoch: 6| Step: 12
Training loss: 2.6569900379388973
Validation loss: 2.594552831225956

Epoch: 6| Step: 13
Training loss: 1.7900732924731146
Validation loss: 2.5640193497775186

Epoch: 210| Step: 0
Training loss: 2.295915571933351
Validation loss: 2.5358675295425037

Epoch: 6| Step: 1
Training loss: 1.7544969952944327
Validation loss: 2.546627446100625

Epoch: 6| Step: 2
Training loss: 2.0054295273360587
Validation loss: 2.5369236471645262

Epoch: 6| Step: 3
Training loss: 2.3222279461369806
Validation loss: 2.545690124363014

Epoch: 6| Step: 4
Training loss: 1.7847500595646346
Validation loss: 2.536905884994487

Epoch: 6| Step: 5
Training loss: 2.401549466953392
Validation loss: 2.533902964002857

Epoch: 6| Step: 6
Training loss: 2.294071069017294
Validation loss: 2.5510013596349044

Epoch: 6| Step: 7
Training loss: 2.719799672210806
Validation loss: 2.5378272392096397

Epoch: 6| Step: 8
Training loss: 2.3843858871111414
Validation loss: 2.54052753144219

Epoch: 6| Step: 9
Training loss: 2.7519500060974162
Validation loss: 2.5485654186434106

Epoch: 6| Step: 10
Training loss: 2.7831941303308603
Validation loss: 2.5838894143007534

Epoch: 6| Step: 11
Training loss: 2.0885150428907866
Validation loss: 2.5820381907005725

Epoch: 6| Step: 12
Training loss: 2.3180983540270397
Validation loss: 2.5868109757767

Epoch: 6| Step: 13
Training loss: 2.4066096445797514
Validation loss: 2.6103448188638496

Epoch: 211| Step: 0
Training loss: 2.334031466084824
Validation loss: 2.606902864499775

Epoch: 6| Step: 1
Training loss: 1.6962329809112326
Validation loss: 2.586811912807587

Epoch: 6| Step: 2
Training loss: 2.394598357861124
Validation loss: 2.5889695630671987

Epoch: 6| Step: 3
Training loss: 2.3961938559134124
Validation loss: 2.582912623593109

Epoch: 6| Step: 4
Training loss: 2.3941984707713453
Validation loss: 2.623198981288213

Epoch: 6| Step: 5
Training loss: 1.4090581195126157
Validation loss: 2.5992213684992227

Epoch: 6| Step: 6
Training loss: 2.9308282284388927
Validation loss: 2.616737235893417

Epoch: 6| Step: 7
Training loss: 2.292088718275069
Validation loss: 2.5880770864429627

Epoch: 6| Step: 8
Training loss: 2.746056243076008
Validation loss: 2.566548104045517

Epoch: 6| Step: 9
Training loss: 2.150976837388183
Validation loss: 2.53063575921347

Epoch: 6| Step: 10
Training loss: 2.1096140408175614
Validation loss: 2.5182973279804846

Epoch: 6| Step: 11
Training loss: 2.546324500752951
Validation loss: 2.5114476209359564

Epoch: 6| Step: 12
Training loss: 2.2048891187542687
Validation loss: 2.495532303510532

Epoch: 6| Step: 13
Training loss: 2.4383343955728853
Validation loss: 2.4972707553339237

Epoch: 212| Step: 0
Training loss: 2.339634346228905
Validation loss: 2.497046553949148

Epoch: 6| Step: 1
Training loss: 2.0339935554544835
Validation loss: 2.491447538183461

Epoch: 6| Step: 2
Training loss: 2.057685782108888
Validation loss: 2.4903866151636063

Epoch: 6| Step: 3
Training loss: 2.0715122417407734
Validation loss: 2.4999743778187336

Epoch: 6| Step: 4
Training loss: 2.5435540950985067
Validation loss: 2.511075963442012

Epoch: 6| Step: 5
Training loss: 2.7367564267094986
Validation loss: 2.518229682130705

Epoch: 6| Step: 6
Training loss: 2.0632847535675243
Validation loss: 2.533893013813524

Epoch: 6| Step: 7
Training loss: 2.6815341114248135
Validation loss: 2.5928384565593063

Epoch: 6| Step: 8
Training loss: 1.9261131387519024
Validation loss: 2.6254976194496

Epoch: 6| Step: 9
Training loss: 2.714350506002052
Validation loss: 2.658775804182506

Epoch: 6| Step: 10
Training loss: 2.2854228068025555
Validation loss: 2.6451318041093796

Epoch: 6| Step: 11
Training loss: 2.2183361473419128
Validation loss: 2.620188557243669

Epoch: 6| Step: 12
Training loss: 2.402549176620854
Validation loss: 2.6021088875054588

Epoch: 6| Step: 13
Training loss: 2.5380570049332083
Validation loss: 2.5652669374101156

Epoch: 213| Step: 0
Training loss: 2.5507087171444716
Validation loss: 2.5548988589270456

Epoch: 6| Step: 1
Training loss: 1.8892851566578626
Validation loss: 2.5408019460547533

Epoch: 6| Step: 2
Training loss: 1.9661060320802448
Validation loss: 2.547337386706689

Epoch: 6| Step: 3
Training loss: 2.5240757374229226
Validation loss: 2.5278787179385827

Epoch: 6| Step: 4
Training loss: 2.2106806198081643
Validation loss: 2.5416462355454374

Epoch: 6| Step: 5
Training loss: 1.5003269157201786
Validation loss: 2.5361198157622677

Epoch: 6| Step: 6
Training loss: 2.3584203746715238
Validation loss: 2.5306019051451814

Epoch: 6| Step: 7
Training loss: 2.096971453340042
Validation loss: 2.5393204465078236

Epoch: 6| Step: 8
Training loss: 2.6095955578451044
Validation loss: 2.539865251456188

Epoch: 6| Step: 9
Training loss: 2.6566822373505468
Validation loss: 2.5343699908726394

Epoch: 6| Step: 10
Training loss: 2.0941372413657726
Validation loss: 2.5430490038699576

Epoch: 6| Step: 11
Training loss: 1.7328954348311012
Validation loss: 2.552307186559564

Epoch: 6| Step: 12
Training loss: 2.961412537648149
Validation loss: 2.5542720258513008

Epoch: 6| Step: 13
Training loss: 2.328563879236526
Validation loss: 2.5772485187193355

Epoch: 214| Step: 0
Training loss: 2.0879335604214937
Validation loss: 2.612629123398858

Epoch: 6| Step: 1
Training loss: 2.565322252223191
Validation loss: 2.6479462774758544

Epoch: 6| Step: 2
Training loss: 2.592555862751902
Validation loss: 2.629218239336362

Epoch: 6| Step: 3
Training loss: 2.068687405748543
Validation loss: 2.62364940109391

Epoch: 6| Step: 4
Training loss: 2.3487931987856276
Validation loss: 2.575283557747884

Epoch: 6| Step: 5
Training loss: 1.9810715459606307
Validation loss: 2.568335394028174

Epoch: 6| Step: 6
Training loss: 2.5598681821264315
Validation loss: 2.5488743959321742

Epoch: 6| Step: 7
Training loss: 2.844169501917853
Validation loss: 2.521728527443212

Epoch: 6| Step: 8
Training loss: 1.8845616996221208
Validation loss: 2.531347343551059

Epoch: 6| Step: 9
Training loss: 2.803121655652487
Validation loss: 2.5204965324400703

Epoch: 6| Step: 10
Training loss: 2.327164829595017
Validation loss: 2.5352463591107828

Epoch: 6| Step: 11
Training loss: 1.6002893365078614
Validation loss: 2.5358867640971834

Epoch: 6| Step: 12
Training loss: 1.9826652189585965
Validation loss: 2.5275859451396996

Epoch: 6| Step: 13
Training loss: 2.330461903740101
Validation loss: 2.524724405815904

Epoch: 215| Step: 0
Training loss: 1.540181174582104
Validation loss: 2.554631464943462

Epoch: 6| Step: 1
Training loss: 1.671149265674393
Validation loss: 2.5530492291204774

Epoch: 6| Step: 2
Training loss: 1.7726484383435748
Validation loss: 2.5557165843798235

Epoch: 6| Step: 3
Training loss: 2.9523059173283834
Validation loss: 2.5682087707844286

Epoch: 6| Step: 4
Training loss: 3.0423288713159655
Validation loss: 2.5615101740119584

Epoch: 6| Step: 5
Training loss: 2.2152979686086653
Validation loss: 2.5478631659375486

Epoch: 6| Step: 6
Training loss: 2.115602470063866
Validation loss: 2.5561135732096343

Epoch: 6| Step: 7
Training loss: 2.310208396593987
Validation loss: 2.5322257778854516

Epoch: 6| Step: 8
Training loss: 1.6867314460562808
Validation loss: 2.537796299489708

Epoch: 6| Step: 9
Training loss: 2.0668674812376238
Validation loss: 2.529299545777628

Epoch: 6| Step: 10
Training loss: 2.705534638261541
Validation loss: 2.52819198375057

Epoch: 6| Step: 11
Training loss: 2.459630225387973
Validation loss: 2.5344046726206613

Epoch: 6| Step: 12
Training loss: 2.422319039277373
Validation loss: 2.5640523906836243

Epoch: 6| Step: 13
Training loss: 2.5219069997655166
Validation loss: 2.5689170628384628

Epoch: 216| Step: 0
Training loss: 2.5816375847843442
Validation loss: 2.617684433859977

Epoch: 6| Step: 1
Training loss: 2.0494104654187315
Validation loss: 2.6073642986288985

Epoch: 6| Step: 2
Training loss: 2.364292703880808
Validation loss: 2.5977800000383096

Epoch: 6| Step: 3
Training loss: 2.6830408229103715
Validation loss: 2.578517151880142

Epoch: 6| Step: 4
Training loss: 1.5440053041446085
Validation loss: 2.572751435033529

Epoch: 6| Step: 5
Training loss: 2.7271796022757373
Validation loss: 2.545531763132748

Epoch: 6| Step: 6
Training loss: 1.9883984004733877
Validation loss: 2.5417253039323953

Epoch: 6| Step: 7
Training loss: 2.520072464884985
Validation loss: 2.5148414513051183

Epoch: 6| Step: 8
Training loss: 1.883454272795382
Validation loss: 2.5182355363220217

Epoch: 6| Step: 9
Training loss: 1.5191245821956405
Validation loss: 2.53935387137772

Epoch: 6| Step: 10
Training loss: 2.5930923179613594
Validation loss: 2.529331233553433

Epoch: 6| Step: 11
Training loss: 2.6116042979018816
Validation loss: 2.531774301741709

Epoch: 6| Step: 12
Training loss: 2.4650370042975323
Validation loss: 2.540129006218528

Epoch: 6| Step: 13
Training loss: 2.188352800075915
Validation loss: 2.552030918335644

Epoch: 217| Step: 0
Training loss: 1.974426321417453
Validation loss: 2.5360818749346943

Epoch: 6| Step: 1
Training loss: 2.095568649940576
Validation loss: 2.5491332669256024

Epoch: 6| Step: 2
Training loss: 1.8730084969225493
Validation loss: 2.553422853985507

Epoch: 6| Step: 3
Training loss: 2.5443222264565892
Validation loss: 2.56336433286074

Epoch: 6| Step: 4
Training loss: 2.062989610299128
Validation loss: 2.576989195349902

Epoch: 6| Step: 5
Training loss: 1.8494500451108031
Validation loss: 2.598315820159845

Epoch: 6| Step: 6
Training loss: 2.1287449766896103
Validation loss: 2.60399827539882

Epoch: 6| Step: 7
Training loss: 2.0097069022716547
Validation loss: 2.575044506268604

Epoch: 6| Step: 8
Training loss: 3.065560038244806
Validation loss: 2.5313150217001597

Epoch: 6| Step: 9
Training loss: 3.1919228778786612
Validation loss: 2.5402609163474037

Epoch: 6| Step: 10
Training loss: 2.239613614136376
Validation loss: 2.5416264817443297

Epoch: 6| Step: 11
Training loss: 2.4603301736959273
Validation loss: 2.5121747953066222

Epoch: 6| Step: 12
Training loss: 2.117424195068809
Validation loss: 2.5097445990526523

Epoch: 6| Step: 13
Training loss: 2.2382267118137436
Validation loss: 2.5285235033914883

Epoch: 218| Step: 0
Training loss: 2.1185210697872052
Validation loss: 2.5116829323278846

Epoch: 6| Step: 1
Training loss: 2.7157703602191
Validation loss: 2.5118522549235602

Epoch: 6| Step: 2
Training loss: 2.971982461007325
Validation loss: 2.5277983911486577

Epoch: 6| Step: 3
Training loss: 2.345563263419914
Validation loss: 2.5508186061084634

Epoch: 6| Step: 4
Training loss: 2.4116133330413954
Validation loss: 2.5637063079091758

Epoch: 6| Step: 5
Training loss: 2.0636578402167443
Validation loss: 2.59845035050503

Epoch: 6| Step: 6
Training loss: 2.5087187368500596
Validation loss: 2.615140397100009

Epoch: 6| Step: 7
Training loss: 2.102223345577235
Validation loss: 2.599610062849153

Epoch: 6| Step: 8
Training loss: 2.541433688466235
Validation loss: 2.590556756667254

Epoch: 6| Step: 9
Training loss: 1.6774560344409328
Validation loss: 2.564212327756606

Epoch: 6| Step: 10
Training loss: 2.1440841681271348
Validation loss: 2.5522381378764067

Epoch: 6| Step: 11
Training loss: 1.2341551766042085
Validation loss: 2.544564390605976

Epoch: 6| Step: 12
Training loss: 1.9428358743509233
Validation loss: 2.540218586965264

Epoch: 6| Step: 13
Training loss: 2.609096398014002
Validation loss: 2.5439060591331386

Epoch: 219| Step: 0
Training loss: 1.8656147993310495
Validation loss: 2.5451922796344224

Epoch: 6| Step: 1
Training loss: 1.8095412604546943
Validation loss: 2.5467763776348393

Epoch: 6| Step: 2
Training loss: 2.498707818824558
Validation loss: 2.5507471336431644

Epoch: 6| Step: 3
Training loss: 1.718182001760674
Validation loss: 2.5511560636898865

Epoch: 6| Step: 4
Training loss: 2.6424664278523315
Validation loss: 2.5557113291307947

Epoch: 6| Step: 5
Training loss: 1.8519094278957133
Validation loss: 2.5596037368503515

Epoch: 6| Step: 6
Training loss: 2.162614027776567
Validation loss: 2.5771053262901322

Epoch: 6| Step: 7
Training loss: 1.8976589537373956
Validation loss: 2.5777520112233385

Epoch: 6| Step: 8
Training loss: 2.777557236075706
Validation loss: 2.585221359495145

Epoch: 6| Step: 9
Training loss: 2.162078719365442
Validation loss: 2.610252857066513

Epoch: 6| Step: 10
Training loss: 2.120410675721998
Validation loss: 2.588542751462979

Epoch: 6| Step: 11
Training loss: 1.9874046806654238
Validation loss: 2.607224451941941

Epoch: 6| Step: 12
Training loss: 2.7307443111353087
Validation loss: 2.610398950133569

Epoch: 6| Step: 13
Training loss: 2.9796117347882576
Validation loss: 2.5875826823957637

Epoch: 220| Step: 0
Training loss: 2.246139605510175
Validation loss: 2.5706655613476737

Epoch: 6| Step: 1
Training loss: 2.5549702619102255
Validation loss: 2.5329227963968655

Epoch: 6| Step: 2
Training loss: 2.234019111087099
Validation loss: 2.529111610412474

Epoch: 6| Step: 3
Training loss: 2.029795433974611
Validation loss: 2.5115035831568377

Epoch: 6| Step: 4
Training loss: 2.9616975236643746
Validation loss: 2.5078155422489337

Epoch: 6| Step: 5
Training loss: 2.4097250084276123
Validation loss: 2.5177774323301123

Epoch: 6| Step: 6
Training loss: 2.0009372422472698
Validation loss: 2.52013672643196

Epoch: 6| Step: 7
Training loss: 2.3353476912027795
Validation loss: 2.529068638778295

Epoch: 6| Step: 8
Training loss: 1.8331550453655363
Validation loss: 2.5400872456342434

Epoch: 6| Step: 9
Training loss: 2.2098036375884664
Validation loss: 2.5498272843554597

Epoch: 6| Step: 10
Training loss: 1.7709240684450929
Validation loss: 2.548389850220102

Epoch: 6| Step: 11
Training loss: 2.3904777930320735
Validation loss: 2.5526345780003648

Epoch: 6| Step: 12
Training loss: 1.9875948157576249
Validation loss: 2.5575525237526087

Epoch: 6| Step: 13
Training loss: 2.4937208475115495
Validation loss: 2.55407799343331

Epoch: 221| Step: 0
Training loss: 1.3779767499493156
Validation loss: 2.578047086520961

Epoch: 6| Step: 1
Training loss: 2.038882075837429
Validation loss: 2.594393761344213

Epoch: 6| Step: 2
Training loss: 2.3286611464498974
Validation loss: 2.54418842620824

Epoch: 6| Step: 3
Training loss: 2.344752491494232
Validation loss: 2.5579464469734123

Epoch: 6| Step: 4
Training loss: 3.041502612841373
Validation loss: 2.5488383053007504

Epoch: 6| Step: 5
Training loss: 2.6888585759740797
Validation loss: 2.542065344221984

Epoch: 6| Step: 6
Training loss: 2.269778003508533
Validation loss: 2.5297520604730117

Epoch: 6| Step: 7
Training loss: 2.864687794023384
Validation loss: 2.5084448440030482

Epoch: 6| Step: 8
Training loss: 2.5638059684190555
Validation loss: 2.5100790458938005

Epoch: 6| Step: 9
Training loss: 2.202107945511873
Validation loss: 2.505861198601043

Epoch: 6| Step: 10
Training loss: 2.1304520620679384
Validation loss: 2.505722030241488

Epoch: 6| Step: 11
Training loss: 2.3937142551233355
Validation loss: 2.5241193450525357

Epoch: 6| Step: 12
Training loss: 1.354240806701903
Validation loss: 2.54143481421755

Epoch: 6| Step: 13
Training loss: 2.0923541526145564
Validation loss: 2.5506856295785885

Epoch: 222| Step: 0
Training loss: 1.9692049257767383
Validation loss: 2.568527916236062

Epoch: 6| Step: 1
Training loss: 2.524456751331514
Validation loss: 2.6136518898855834

Epoch: 6| Step: 2
Training loss: 2.5798324941625594
Validation loss: 2.6197985477748973

Epoch: 6| Step: 3
Training loss: 2.250474244047267
Validation loss: 2.6133860902991732

Epoch: 6| Step: 4
Training loss: 2.4734048538800737
Validation loss: 2.6014201876614282

Epoch: 6| Step: 5
Training loss: 1.4769949305039936
Validation loss: 2.6196576053200396

Epoch: 6| Step: 6
Training loss: 2.838796136398019
Validation loss: 2.633553405410448

Epoch: 6| Step: 7
Training loss: 2.3738519001683964
Validation loss: 2.6244965100697906

Epoch: 6| Step: 8
Training loss: 2.1080434481795773
Validation loss: 2.5693557257127693

Epoch: 6| Step: 9
Training loss: 1.8208109291962116
Validation loss: 2.5260586505332046

Epoch: 6| Step: 10
Training loss: 2.2262013995837817
Validation loss: 2.5045329959498464

Epoch: 6| Step: 11
Training loss: 2.406654621139914
Validation loss: 2.4950947481205183

Epoch: 6| Step: 12
Training loss: 2.293775374352742
Validation loss: 2.5008511842647536

Epoch: 6| Step: 13
Training loss: 3.097530020875441
Validation loss: 2.4964096036650796

Epoch: 223| Step: 0
Training loss: 2.7244075796126896
Validation loss: 2.5002378350614083

Epoch: 6| Step: 1
Training loss: 2.3059132565331404
Validation loss: 2.4945303687844658

Epoch: 6| Step: 2
Training loss: 1.4508963280940197
Validation loss: 2.500305856432784

Epoch: 6| Step: 3
Training loss: 2.472570143612065
Validation loss: 2.4952009392285572

Epoch: 6| Step: 4
Training loss: 1.949727391481314
Validation loss: 2.5074287826095083

Epoch: 6| Step: 5
Training loss: 2.832386494422006
Validation loss: 2.516421205874315

Epoch: 6| Step: 6
Training loss: 1.8535039195906071
Validation loss: 2.535270245560158

Epoch: 6| Step: 7
Training loss: 2.1396604717826793
Validation loss: 2.582435287743114

Epoch: 6| Step: 8
Training loss: 2.3074783238212198
Validation loss: 2.6053244089906262

Epoch: 6| Step: 9
Training loss: 2.2183560303697933
Validation loss: 2.608517123156827

Epoch: 6| Step: 10
Training loss: 3.009759604654102
Validation loss: 2.596551263356164

Epoch: 6| Step: 11
Training loss: 2.541069857042813
Validation loss: 2.5921889820366735

Epoch: 6| Step: 12
Training loss: 1.6058874767594071
Validation loss: 2.587852759893976

Epoch: 6| Step: 13
Training loss: 2.221554984480975
Validation loss: 2.5507104931024225

Epoch: 224| Step: 0
Training loss: 2.181465763471264
Validation loss: 2.5333684839353174

Epoch: 6| Step: 1
Training loss: 2.246645227814816
Validation loss: 2.5187431739228723

Epoch: 6| Step: 2
Training loss: 1.9606147895719799
Validation loss: 2.5133587124181473

Epoch: 6| Step: 3
Training loss: 2.3054015007280895
Validation loss: 2.5222224094327315

Epoch: 6| Step: 4
Training loss: 2.274541318157974
Validation loss: 2.5297109375422226

Epoch: 6| Step: 5
Training loss: 2.238047216406524
Validation loss: 2.549291342082544

Epoch: 6| Step: 6
Training loss: 2.0084842493276773
Validation loss: 2.5623330627897154

Epoch: 6| Step: 7
Training loss: 2.4709397274309786
Validation loss: 2.5611759967703103

Epoch: 6| Step: 8
Training loss: 2.752636079534042
Validation loss: 2.52938128591953

Epoch: 6| Step: 9
Training loss: 1.6712001258409963
Validation loss: 2.537623853745817

Epoch: 6| Step: 10
Training loss: 1.774997378065295
Validation loss: 2.518974924890777

Epoch: 6| Step: 11
Training loss: 2.700733604375029
Validation loss: 2.5211148590852823

Epoch: 6| Step: 12
Training loss: 2.487811608661156
Validation loss: 2.5249936528645422

Epoch: 6| Step: 13
Training loss: 2.9078909230508163
Validation loss: 2.5213729790454145

Epoch: 225| Step: 0
Training loss: 2.001502783760767
Validation loss: 2.5541195641593295

Epoch: 6| Step: 1
Training loss: 2.337823928990681
Validation loss: 2.586054865544937

Epoch: 6| Step: 2
Training loss: 2.5557260064856426
Validation loss: 2.5891172254016506

Epoch: 6| Step: 3
Training loss: 1.9844314687308693
Validation loss: 2.577946982354736

Epoch: 6| Step: 4
Training loss: 2.0443328912795566
Validation loss: 2.6039139942931877

Epoch: 6| Step: 5
Training loss: 2.0890662342343447
Validation loss: 2.572354712231292

Epoch: 6| Step: 6
Training loss: 1.6022163359054347
Validation loss: 2.562550520980397

Epoch: 6| Step: 7
Training loss: 2.0854448172402917
Validation loss: 2.5582272798589316

Epoch: 6| Step: 8
Training loss: 2.2315878390615205
Validation loss: 2.5764827853969563

Epoch: 6| Step: 9
Training loss: 2.9093386736936475
Validation loss: 2.5799290442874674

Epoch: 6| Step: 10
Training loss: 2.5493527395029854
Validation loss: 2.6029028508838596

Epoch: 6| Step: 11
Training loss: 2.3531199015730584
Validation loss: 2.594270692212761

Epoch: 6| Step: 12
Training loss: 2.057379174282772
Validation loss: 2.578367587920056

Epoch: 6| Step: 13
Training loss: 2.5749038456120936
Validation loss: 2.578416857912845

Epoch: 226| Step: 0
Training loss: 2.2700797647586524
Validation loss: 2.585774826664816

Epoch: 6| Step: 1
Training loss: 2.103796696634797
Validation loss: 2.5825272245840063

Epoch: 6| Step: 2
Training loss: 1.8746857061821058
Validation loss: 2.591274305574057

Epoch: 6| Step: 3
Training loss: 2.1185588829243054
Validation loss: 2.602724001231773

Epoch: 6| Step: 4
Training loss: 2.5820866519680328
Validation loss: 2.6037749237415766

Epoch: 6| Step: 5
Training loss: 2.899900987184499
Validation loss: 2.5767035370722438

Epoch: 6| Step: 6
Training loss: 2.5728172458070677
Validation loss: 2.566078494126355

Epoch: 6| Step: 7
Training loss: 2.3716783886867994
Validation loss: 2.5755943748123977

Epoch: 6| Step: 8
Training loss: 1.924469723676159
Validation loss: 2.568458901375851

Epoch: 6| Step: 9
Training loss: 2.2644477679663217
Validation loss: 2.5537587226398797

Epoch: 6| Step: 10
Training loss: 2.5150913596576
Validation loss: 2.5556529142889493

Epoch: 6| Step: 11
Training loss: 1.4741567561260505
Validation loss: 2.5280906835238075

Epoch: 6| Step: 12
Training loss: 2.232264021718464
Validation loss: 2.530855791768735

Epoch: 6| Step: 13
Training loss: 2.188032684863116
Validation loss: 2.520609575119261

Epoch: 227| Step: 0
Training loss: 2.1263763234122766
Validation loss: 2.5199074792024483

Epoch: 6| Step: 1
Training loss: 1.5939643566114348
Validation loss: 2.5320134051732928

Epoch: 6| Step: 2
Training loss: 1.9212617593577874
Validation loss: 2.5544277685190866

Epoch: 6| Step: 3
Training loss: 2.5005511629987525
Validation loss: 2.560197602210561

Epoch: 6| Step: 4
Training loss: 2.232119081643049
Validation loss: 2.5699205959734557

Epoch: 6| Step: 5
Training loss: 2.1835926581364666
Validation loss: 2.5845518212368135

Epoch: 6| Step: 6
Training loss: 2.017829576537913
Validation loss: 2.5838644701990576

Epoch: 6| Step: 7
Training loss: 2.5006817841702995
Validation loss: 2.6517452712749474

Epoch: 6| Step: 8
Training loss: 2.713011550130699
Validation loss: 2.6606521480323164

Epoch: 6| Step: 9
Training loss: 2.1129153458426844
Validation loss: 2.688428555729817

Epoch: 6| Step: 10
Training loss: 1.5880609587540624
Validation loss: 2.644007515897086

Epoch: 6| Step: 11
Training loss: 2.213250880869569
Validation loss: 2.5997956531868156

Epoch: 6| Step: 12
Training loss: 2.3333237738640555
Validation loss: 2.6072136766080654

Epoch: 6| Step: 13
Training loss: 2.8173051264744435
Validation loss: 2.5855084972892373

Epoch: 228| Step: 0
Training loss: 1.4174267281999708
Validation loss: 2.5503920783511393

Epoch: 6| Step: 1
Training loss: 1.8734404117666592
Validation loss: 2.5165158386591027

Epoch: 6| Step: 2
Training loss: 2.9758229375689877
Validation loss: 2.5021060020400303

Epoch: 6| Step: 3
Training loss: 1.6156775017772407
Validation loss: 2.5012440844352604

Epoch: 6| Step: 4
Training loss: 2.2617406761674665
Validation loss: 2.5083089081682877

Epoch: 6| Step: 5
Training loss: 2.31510016173169
Validation loss: 2.5079128051219373

Epoch: 6| Step: 6
Training loss: 2.5972826696241933
Validation loss: 2.5019500120939195

Epoch: 6| Step: 7
Training loss: 2.1406245544878644
Validation loss: 2.5191853603721444

Epoch: 6| Step: 8
Training loss: 2.4492799790803974
Validation loss: 2.5322078572229816

Epoch: 6| Step: 9
Training loss: 3.1953023523295467
Validation loss: 2.532630285054301

Epoch: 6| Step: 10
Training loss: 1.6845509226692061
Validation loss: 2.5671646182154375

Epoch: 6| Step: 11
Training loss: 1.7273404539327863
Validation loss: 2.598163679463753

Epoch: 6| Step: 12
Training loss: 1.7729275007921743
Validation loss: 2.620972510697134

Epoch: 6| Step: 13
Training loss: 2.6967580263798676
Validation loss: 2.645343109332307

Epoch: 229| Step: 0
Training loss: 2.051848448140891
Validation loss: 2.616371414713558

Epoch: 6| Step: 1
Training loss: 1.8541728744688661
Validation loss: 2.613356394844416

Epoch: 6| Step: 2
Training loss: 2.13511494311489
Validation loss: 2.5981680076746234

Epoch: 6| Step: 3
Training loss: 2.297147358426996
Validation loss: 2.581768135981061

Epoch: 6| Step: 4
Training loss: 2.6347238185272
Validation loss: 2.580108103360191

Epoch: 6| Step: 5
Training loss: 2.4975898569188235
Validation loss: 2.561916595044379

Epoch: 6| Step: 6
Training loss: 1.991993853563378
Validation loss: 2.5803617850422333

Epoch: 6| Step: 7
Training loss: 2.546343601699315
Validation loss: 2.583023011632188

Epoch: 6| Step: 8
Training loss: 2.642816300242257
Validation loss: 2.6029756085658304

Epoch: 6| Step: 9
Training loss: 1.6828591144590928
Validation loss: 2.6188928921726067

Epoch: 6| Step: 10
Training loss: 2.0055474593168485
Validation loss: 2.601527170852106

Epoch: 6| Step: 11
Training loss: 2.1867917685465974
Validation loss: 2.615004043369316

Epoch: 6| Step: 12
Training loss: 2.7681313058105634
Validation loss: 2.5964330408071965

Epoch: 6| Step: 13
Training loss: 2.0264018963518393
Validation loss: 2.6110081235266644

Epoch: 230| Step: 0
Training loss: 2.0073530213171678
Validation loss: 2.5971004340799535

Epoch: 6| Step: 1
Training loss: 2.5161479145837125
Validation loss: 2.5532365386268383

Epoch: 6| Step: 2
Training loss: 2.2198659749857454
Validation loss: 2.560018345697551

Epoch: 6| Step: 3
Training loss: 3.0614239106131045
Validation loss: 2.553622709249083

Epoch: 6| Step: 4
Training loss: 1.8298004167670325
Validation loss: 2.5513505207938474

Epoch: 6| Step: 5
Training loss: 1.960909900243083
Validation loss: 2.567537922391864

Epoch: 6| Step: 6
Training loss: 1.666280566634129
Validation loss: 2.5740417203488595

Epoch: 6| Step: 7
Training loss: 1.9938162335243401
Validation loss: 2.571627665941142

Epoch: 6| Step: 8
Training loss: 2.0918006362667514
Validation loss: 2.5762771766163266

Epoch: 6| Step: 9
Training loss: 1.6505363806291935
Validation loss: 2.5573087304524273

Epoch: 6| Step: 10
Training loss: 2.594534146457469
Validation loss: 2.5424451938499826

Epoch: 6| Step: 11
Training loss: 2.61491090057469
Validation loss: 2.5424970198082124

Epoch: 6| Step: 12
Training loss: 2.233987201035872
Validation loss: 2.534258447891981

Epoch: 6| Step: 13
Training loss: 2.5148156801181796
Validation loss: 2.538892362714191

Epoch: 231| Step: 0
Training loss: 1.661700941527532
Validation loss: 2.534220784955974

Epoch: 6| Step: 1
Training loss: 2.0078224745921984
Validation loss: 2.543616490215069

Epoch: 6| Step: 2
Training loss: 2.080583537849704
Validation loss: 2.5260474660485674

Epoch: 6| Step: 3
Training loss: 2.4373071056237503
Validation loss: 2.551511028243286

Epoch: 6| Step: 4
Training loss: 2.167213102050582
Validation loss: 2.5642413138788283

Epoch: 6| Step: 5
Training loss: 1.809109179747374
Validation loss: 2.5872618174001514

Epoch: 6| Step: 6
Training loss: 1.8112952075737108
Validation loss: 2.622545729857554

Epoch: 6| Step: 7
Training loss: 2.77961605810055
Validation loss: 2.6507193788532697

Epoch: 6| Step: 8
Training loss: 2.8321986076627943
Validation loss: 2.6666727115642064

Epoch: 6| Step: 9
Training loss: 2.587818395218424
Validation loss: 2.624030373131961

Epoch: 6| Step: 10
Training loss: 2.099486279095055
Validation loss: 2.621444155697588

Epoch: 6| Step: 11
Training loss: 2.6962453803392927
Validation loss: 2.5961858962055975

Epoch: 6| Step: 12
Training loss: 2.030979197130297
Validation loss: 2.609097250891538

Epoch: 6| Step: 13
Training loss: 1.759923862197573
Validation loss: 2.59374799307014

Epoch: 232| Step: 0
Training loss: 3.1605198748808085
Validation loss: 2.5650735817778587

Epoch: 6| Step: 1
Training loss: 2.015402848177479
Validation loss: 2.5309977150611203

Epoch: 6| Step: 2
Training loss: 2.1183281672685097
Validation loss: 2.5171433441564117

Epoch: 6| Step: 3
Training loss: 1.709011509271196
Validation loss: 2.5269478080451013

Epoch: 6| Step: 4
Training loss: 2.3398842019992934
Validation loss: 2.534955785316847

Epoch: 6| Step: 5
Training loss: 2.400303614803199
Validation loss: 2.5335303266587412

Epoch: 6| Step: 6
Training loss: 2.6024892261879424
Validation loss: 2.545556380404383

Epoch: 6| Step: 7
Training loss: 1.7554593081320125
Validation loss: 2.5737102432725187

Epoch: 6| Step: 8
Training loss: 2.3470389114619516
Validation loss: 2.6272003095349414

Epoch: 6| Step: 9
Training loss: 1.7415918264173584
Validation loss: 2.6295157298069554

Epoch: 6| Step: 10
Training loss: 2.3894415026487
Validation loss: 2.6827146671906985

Epoch: 6| Step: 11
Training loss: 1.610338681772697
Validation loss: 2.688962390668332

Epoch: 6| Step: 12
Training loss: 2.7382165571943022
Validation loss: 2.7171861966996285

Epoch: 6| Step: 13
Training loss: 2.2750576053913716
Validation loss: 2.69356171878567

Epoch: 233| Step: 0
Training loss: 1.7705801240490333
Validation loss: 2.595751484233142

Epoch: 6| Step: 1
Training loss: 2.4985724187878744
Validation loss: 2.5349744076161156

Epoch: 6| Step: 2
Training loss: 2.26601411832231
Validation loss: 2.508486473968072

Epoch: 6| Step: 3
Training loss: 2.763528320034873
Validation loss: 2.514464859171838

Epoch: 6| Step: 4
Training loss: 2.8725344825315013
Validation loss: 2.51364142837403

Epoch: 6| Step: 5
Training loss: 2.142601270385468
Validation loss: 2.51560752973157

Epoch: 6| Step: 6
Training loss: 1.961608893365598
Validation loss: 2.518607375821645

Epoch: 6| Step: 7
Training loss: 2.5848223998931257
Validation loss: 2.505278220890465

Epoch: 6| Step: 8
Training loss: 1.5627371798746028
Validation loss: 2.506660886269188

Epoch: 6| Step: 9
Training loss: 2.3956089301681254
Validation loss: 2.5067522019856963

Epoch: 6| Step: 10
Training loss: 1.8716172539202878
Validation loss: 2.5016008973376525

Epoch: 6| Step: 11
Training loss: 1.8632895031632273
Validation loss: 2.5028698899548867

Epoch: 6| Step: 12
Training loss: 2.795567382655406
Validation loss: 2.5229679139211623

Epoch: 6| Step: 13
Training loss: 1.9143378234900073
Validation loss: 2.5257079595521708

Epoch: 234| Step: 0
Training loss: 2.0079630635728467
Validation loss: 2.539932501001164

Epoch: 6| Step: 1
Training loss: 2.761750087533264
Validation loss: 2.554140302595655

Epoch: 6| Step: 2
Training loss: 2.6610570158356848
Validation loss: 2.5733689877118704

Epoch: 6| Step: 3
Training loss: 1.7396191880724607
Validation loss: 2.5515386869585064

Epoch: 6| Step: 4
Training loss: 2.0887799844467327
Validation loss: 2.568181198766567

Epoch: 6| Step: 5
Training loss: 1.8605879345611422
Validation loss: 2.5547780478759785

Epoch: 6| Step: 6
Training loss: 2.328322229415787
Validation loss: 2.534099466356317

Epoch: 6| Step: 7
Training loss: 1.587059488528831
Validation loss: 2.5149339947087475

Epoch: 6| Step: 8
Training loss: 2.0101592009397065
Validation loss: 2.510439256642958

Epoch: 6| Step: 9
Training loss: 3.186695221675906
Validation loss: 2.509421524623679

Epoch: 6| Step: 10
Training loss: 2.412389280318357
Validation loss: 2.502457872786271

Epoch: 6| Step: 11
Training loss: 2.5937694870549963
Validation loss: 2.5000487322826013

Epoch: 6| Step: 12
Training loss: 2.026886816846082
Validation loss: 2.5049950924620332

Epoch: 6| Step: 13
Training loss: 2.6169526407564967
Validation loss: 2.4997820759205203

Epoch: 235| Step: 0
Training loss: 1.8271505252860867
Validation loss: 2.5199657765340286

Epoch: 6| Step: 1
Training loss: 1.721340308275479
Validation loss: 2.5000973046757773

Epoch: 6| Step: 2
Training loss: 2.182894081114898
Validation loss: 2.5212641234940847

Epoch: 6| Step: 3
Training loss: 2.6039459948821317
Validation loss: 2.52960195382992

Epoch: 6| Step: 4
Training loss: 2.146036033562492
Validation loss: 2.573107049567613

Epoch: 6| Step: 5
Training loss: 2.3864002670845497
Validation loss: 2.594449098429929

Epoch: 6| Step: 6
Training loss: 1.729922791891523
Validation loss: 2.6012048026733003

Epoch: 6| Step: 7
Training loss: 2.5651443607389166
Validation loss: 2.624660182331858

Epoch: 6| Step: 8
Training loss: 2.1776910204484916
Validation loss: 2.650203225002659

Epoch: 6| Step: 9
Training loss: 2.6531694388290537
Validation loss: 2.6357103769635457

Epoch: 6| Step: 10
Training loss: 2.2086145713750365
Validation loss: 2.6240543221219097

Epoch: 6| Step: 11
Training loss: 2.630706850655948
Validation loss: 2.598655871652514

Epoch: 6| Step: 12
Training loss: 2.054349806271045
Validation loss: 2.5662226889510804

Epoch: 6| Step: 13
Training loss: 2.298114571878377
Validation loss: 2.5616097415720374

Epoch: 236| Step: 0
Training loss: 1.8976030438857086
Validation loss: 2.5343738871053376

Epoch: 6| Step: 1
Training loss: 1.483221871049357
Validation loss: 2.5198626002188553

Epoch: 6| Step: 2
Training loss: 2.2757279960459478
Validation loss: 2.512987005503512

Epoch: 6| Step: 3
Training loss: 1.7304019958158317
Validation loss: 2.5106253688901568

Epoch: 6| Step: 4
Training loss: 1.9680880084518173
Validation loss: 2.492118268461477

Epoch: 6| Step: 5
Training loss: 2.0782064550971167
Validation loss: 2.5031571797728476

Epoch: 6| Step: 6
Training loss: 2.455271953739807
Validation loss: 2.508636165051628

Epoch: 6| Step: 7
Training loss: 2.002704103619417
Validation loss: 2.497387371241156

Epoch: 6| Step: 8
Training loss: 2.303755439176467
Validation loss: 2.529487467179597

Epoch: 6| Step: 9
Training loss: 3.1428647381826993
Validation loss: 2.5619877714222117

Epoch: 6| Step: 10
Training loss: 2.048453152129012
Validation loss: 2.59403455467905

Epoch: 6| Step: 11
Training loss: 2.756755334457532
Validation loss: 2.6341971539868436

Epoch: 6| Step: 12
Training loss: 2.7347532174251636
Validation loss: 2.712127673470928

Epoch: 6| Step: 13
Training loss: 2.1584596231204127
Validation loss: 2.709123413067637

Epoch: 237| Step: 0
Training loss: 2.5817871901780425
Validation loss: 2.6569638059843097

Epoch: 6| Step: 1
Training loss: 2.4498981221095337
Validation loss: 2.609418187193289

Epoch: 6| Step: 2
Training loss: 2.173871337241776
Validation loss: 2.5611449279630474

Epoch: 6| Step: 3
Training loss: 2.4758195695352185
Validation loss: 2.5235123441165106

Epoch: 6| Step: 4
Training loss: 2.105822248632223
Validation loss: 2.4986211471068622

Epoch: 6| Step: 5
Training loss: 2.671053308324157
Validation loss: 2.492605112576648

Epoch: 6| Step: 6
Training loss: 2.5130382056286407
Validation loss: 2.5016843208166164

Epoch: 6| Step: 7
Training loss: 2.555122268498382
Validation loss: 2.5015655066436167

Epoch: 6| Step: 8
Training loss: 2.5797617947227196
Validation loss: 2.4981503160746548

Epoch: 6| Step: 9
Training loss: 1.9344024508351088
Validation loss: 2.5111602035602676

Epoch: 6| Step: 10
Training loss: 2.0971663203027573
Validation loss: 2.497497148152589

Epoch: 6| Step: 11
Training loss: 1.5534016261143706
Validation loss: 2.5127905916409286

Epoch: 6| Step: 12
Training loss: 2.002358238355333
Validation loss: 2.5269967439874814

Epoch: 6| Step: 13
Training loss: 2.8208273631661447
Validation loss: 2.5162740624318434

Epoch: 238| Step: 0
Training loss: 2.522247695327418
Validation loss: 2.575668598149476

Epoch: 6| Step: 1
Training loss: 2.4316099356434355
Validation loss: 2.599772818127897

Epoch: 6| Step: 2
Training loss: 2.2043204885458794
Validation loss: 2.61027206868802

Epoch: 6| Step: 3
Training loss: 2.4112243758561034
Validation loss: 2.624161177534862

Epoch: 6| Step: 4
Training loss: 2.240016298064477
Validation loss: 2.600906778203249

Epoch: 6| Step: 5
Training loss: 2.175910110356034
Validation loss: 2.601682902653448

Epoch: 6| Step: 6
Training loss: 1.8613136507093957
Validation loss: 2.5396340220907994

Epoch: 6| Step: 7
Training loss: 2.462651312966944
Validation loss: 2.5516779649020505

Epoch: 6| Step: 8
Training loss: 2.5210986562609623
Validation loss: 2.5591242504755707

Epoch: 6| Step: 9
Training loss: 1.136513393244304
Validation loss: 2.551530230525032

Epoch: 6| Step: 10
Training loss: 2.8156830471545784
Validation loss: 2.573234389194975

Epoch: 6| Step: 11
Training loss: 1.8543808488332518
Validation loss: 2.5646836195880325

Epoch: 6| Step: 12
Training loss: 2.813730775893711
Validation loss: 2.574496279832033

Epoch: 6| Step: 13
Training loss: 2.034114988619441
Validation loss: 2.562044824321261

Epoch: 239| Step: 0
Training loss: 2.4503874842123285
Validation loss: 2.565452123494731

Epoch: 6| Step: 1
Training loss: 2.0696486074395257
Validation loss: 2.5831298030128993

Epoch: 6| Step: 2
Training loss: 2.1272940874694592
Validation loss: 2.5641810013010127

Epoch: 6| Step: 3
Training loss: 2.9074471581889725
Validation loss: 2.5605845541937526

Epoch: 6| Step: 4
Training loss: 1.8912429430238078
Validation loss: 2.5633616123160827

Epoch: 6| Step: 5
Training loss: 2.3516187692798023
Validation loss: 2.559661696713059

Epoch: 6| Step: 6
Training loss: 1.8711312117041856
Validation loss: 2.5550785912472143

Epoch: 6| Step: 7
Training loss: 2.434625152937294
Validation loss: 2.540651201939652

Epoch: 6| Step: 8
Training loss: 2.009606654457446
Validation loss: 2.5369060572912665

Epoch: 6| Step: 9
Training loss: 2.4199213823836767
Validation loss: 2.575514425353952

Epoch: 6| Step: 10
Training loss: 1.6830820248539506
Validation loss: 2.5492886922494415

Epoch: 6| Step: 11
Training loss: 1.8381805353423462
Validation loss: 2.563654166714626

Epoch: 6| Step: 12
Training loss: 2.5807961238075183
Validation loss: 2.5637283637492976

Epoch: 6| Step: 13
Training loss: 2.052636344739398
Validation loss: 2.5756741366581912

Epoch: 240| Step: 0
Training loss: 2.0088499483738915
Validation loss: 2.5836499901990733

Epoch: 6| Step: 1
Training loss: 1.9263062293517876
Validation loss: 2.611957847886007

Epoch: 6| Step: 2
Training loss: 2.991667779552143
Validation loss: 2.6804675124560333

Epoch: 6| Step: 3
Training loss: 1.7069558971542622
Validation loss: 2.663608874110979

Epoch: 6| Step: 4
Training loss: 2.453473692002552
Validation loss: 2.698846477593932

Epoch: 6| Step: 5
Training loss: 2.145487254360712
Validation loss: 2.7104614455452922

Epoch: 6| Step: 6
Training loss: 2.5722633077948465
Validation loss: 2.6816054024898746

Epoch: 6| Step: 7
Training loss: 2.9465413654090122
Validation loss: 2.678694768215493

Epoch: 6| Step: 8
Training loss: 2.3017410323025387
Validation loss: 2.6498547928091516

Epoch: 6| Step: 9
Training loss: 2.2675810689849536
Validation loss: 2.597044572064083

Epoch: 6| Step: 10
Training loss: 1.7991624950073748
Validation loss: 2.559473778414174

Epoch: 6| Step: 11
Training loss: 1.9874816365863164
Validation loss: 2.536522730663257

Epoch: 6| Step: 12
Training loss: 2.409863223867999
Validation loss: 2.5135977180092204

Epoch: 6| Step: 13
Training loss: 1.9189917794151414
Validation loss: 2.5130668411918804

Epoch: 241| Step: 0
Training loss: 2.167824790230169
Validation loss: 2.5088340207817432

Epoch: 6| Step: 1
Training loss: 2.296394142108058
Validation loss: 2.5201640672483836

Epoch: 6| Step: 2
Training loss: 1.8700881198785366
Validation loss: 2.516328654000355

Epoch: 6| Step: 3
Training loss: 2.033938697168706
Validation loss: 2.5246153878481676

Epoch: 6| Step: 4
Training loss: 2.750183186065118
Validation loss: 2.5339717595936166

Epoch: 6| Step: 5
Training loss: 2.244488960502399
Validation loss: 2.5378868002400585

Epoch: 6| Step: 6
Training loss: 2.055337201225674
Validation loss: 2.569509688113228

Epoch: 6| Step: 7
Training loss: 2.442557248212848
Validation loss: 2.5829412921688117

Epoch: 6| Step: 8
Training loss: 1.8828645437811695
Validation loss: 2.590784637477792

Epoch: 6| Step: 9
Training loss: 2.0533842297641094
Validation loss: 2.6378111434298535

Epoch: 6| Step: 10
Training loss: 1.7431559244601702
Validation loss: 2.635001565762657

Epoch: 6| Step: 11
Training loss: 1.9546581507003324
Validation loss: 2.622917181554799

Epoch: 6| Step: 12
Training loss: 2.9411364833133065
Validation loss: 2.622366840968759

Epoch: 6| Step: 13
Training loss: 3.011347924742762
Validation loss: 2.5772180985102557

Epoch: 242| Step: 0
Training loss: 2.7165018191571098
Validation loss: 2.5535422508295307

Epoch: 6| Step: 1
Training loss: 3.002471541524751
Validation loss: 2.564137749552789

Epoch: 6| Step: 2
Training loss: 2.2855469459347217
Validation loss: 2.5741739997582314

Epoch: 6| Step: 3
Training loss: 1.452577877616051
Validation loss: 2.582980752285201

Epoch: 6| Step: 4
Training loss: 2.2659131097118794
Validation loss: 2.59427263747033

Epoch: 6| Step: 5
Training loss: 2.461792424975053
Validation loss: 2.6282398424068694

Epoch: 6| Step: 6
Training loss: 1.8353473120527828
Validation loss: 2.627253004539854

Epoch: 6| Step: 7
Training loss: 1.6558889319357222
Validation loss: 2.6039320013491807

Epoch: 6| Step: 8
Training loss: 1.5575795327541038
Validation loss: 2.6105207718297554

Epoch: 6| Step: 9
Training loss: 1.7269065134470694
Validation loss: 2.587972280305718

Epoch: 6| Step: 10
Training loss: 1.9018918857834006
Validation loss: 2.6056628443280934

Epoch: 6| Step: 11
Training loss: 2.907121425133245
Validation loss: 2.6085967313801426

Epoch: 6| Step: 12
Training loss: 2.0860279077947133
Validation loss: 2.5943075293229327

Epoch: 6| Step: 13
Training loss: 2.3418115356088216
Validation loss: 2.5750783778734117

Epoch: 243| Step: 0
Training loss: 2.1144891977888935
Validation loss: 2.6038814439344513

Epoch: 6| Step: 1
Training loss: 1.991720646029628
Validation loss: 2.593901970635789

Epoch: 6| Step: 2
Training loss: 2.026145507452662
Validation loss: 2.5717238828714177

Epoch: 6| Step: 3
Training loss: 2.1906638018209557
Validation loss: 2.5626390000767483

Epoch: 6| Step: 4
Training loss: 1.4058673337990413
Validation loss: 2.5359129479285842

Epoch: 6| Step: 5
Training loss: 2.6020569660773982
Validation loss: 2.534220345917616

Epoch: 6| Step: 6
Training loss: 2.4487491139151825
Validation loss: 2.5348982246178116

Epoch: 6| Step: 7
Training loss: 2.779147006703565
Validation loss: 2.5388030169016353

Epoch: 6| Step: 8
Training loss: 1.6956748047884536
Validation loss: 2.564288809810237

Epoch: 6| Step: 9
Training loss: 2.161848016257838
Validation loss: 2.577483311181934

Epoch: 6| Step: 10
Training loss: 2.1795299842278926
Validation loss: 2.5941201754001746

Epoch: 6| Step: 11
Training loss: 2.8199990222469284
Validation loss: 2.622127838735036

Epoch: 6| Step: 12
Training loss: 1.8772204920214575
Validation loss: 2.6654007907204

Epoch: 6| Step: 13
Training loss: 2.1347366987189935
Validation loss: 2.6821060017644203

Epoch: 244| Step: 0
Training loss: 2.266335001223022
Validation loss: 2.7061466975534803

Epoch: 6| Step: 1
Training loss: 1.7284477608499786
Validation loss: 2.6493650479439887

Epoch: 6| Step: 2
Training loss: 2.6392238895085494
Validation loss: 2.614956868352694

Epoch: 6| Step: 3
Training loss: 2.2169603463955405
Validation loss: 2.575329600229832

Epoch: 6| Step: 4
Training loss: 2.0783675202854384
Validation loss: 2.5606806506980355

Epoch: 6| Step: 5
Training loss: 2.498239087784411
Validation loss: 2.5625391701286446

Epoch: 6| Step: 6
Training loss: 2.6076916044358494
Validation loss: 2.5560062282886347

Epoch: 6| Step: 7
Training loss: 2.3641721953402572
Validation loss: 2.572104690140102

Epoch: 6| Step: 8
Training loss: 2.15051102885842
Validation loss: 2.552294700329513

Epoch: 6| Step: 9
Training loss: 2.2806417621091692
Validation loss: 2.546456285003718

Epoch: 6| Step: 10
Training loss: 2.444127194692504
Validation loss: 2.5543677920320764

Epoch: 6| Step: 11
Training loss: 1.7767245712768638
Validation loss: 2.5419195132785553

Epoch: 6| Step: 12
Training loss: 1.2320912638617465
Validation loss: 2.5685127860353703

Epoch: 6| Step: 13
Training loss: 2.4692817791273285
Validation loss: 2.5722840544306655

Epoch: 245| Step: 0
Training loss: 1.505182215410119
Validation loss: 2.5755600162890233

Epoch: 6| Step: 1
Training loss: 1.5382190077604592
Validation loss: 2.588368927521952

Epoch: 6| Step: 2
Training loss: 2.234441689516394
Validation loss: 2.601105337671109

Epoch: 6| Step: 3
Training loss: 1.962851999386755
Validation loss: 2.6070195758037302

Epoch: 6| Step: 4
Training loss: 2.6355573795030676
Validation loss: 2.582502236551484

Epoch: 6| Step: 5
Training loss: 3.015277743728788
Validation loss: 2.607572492614034

Epoch: 6| Step: 6
Training loss: 1.9009708408766188
Validation loss: 2.6088047280059836

Epoch: 6| Step: 7
Training loss: 2.372773582514133
Validation loss: 2.6166868423688388

Epoch: 6| Step: 8
Training loss: 2.874417619183945
Validation loss: 2.5932844119454814

Epoch: 6| Step: 9
Training loss: 2.1212177275505124
Validation loss: 2.569226624016776

Epoch: 6| Step: 10
Training loss: 2.2721621157472054
Validation loss: 2.602831052965242

Epoch: 6| Step: 11
Training loss: 1.7628286718077457
Validation loss: 2.6001524287560356

Epoch: 6| Step: 12
Training loss: 2.1772252330135706
Validation loss: 2.635965498719213

Epoch: 6| Step: 13
Training loss: 1.732149638189377
Validation loss: 2.661623594424829

Epoch: 246| Step: 0
Training loss: 1.8327023836505953
Validation loss: 2.6659182948789515

Epoch: 6| Step: 1
Training loss: 1.8842857580103332
Validation loss: 2.6857660377547

Epoch: 6| Step: 2
Training loss: 2.542896931889568
Validation loss: 2.6647271663051217

Epoch: 6| Step: 3
Training loss: 2.1990661026064706
Validation loss: 2.666590232548442

Epoch: 6| Step: 4
Training loss: 2.7747811514671925
Validation loss: 2.6266166462064744

Epoch: 6| Step: 5
Training loss: 2.8714800308811177
Validation loss: 2.6364963918104536

Epoch: 6| Step: 6
Training loss: 1.5874150351067176
Validation loss: 2.590560530047088

Epoch: 6| Step: 7
Training loss: 1.9887135453542484
Validation loss: 2.561741848572256

Epoch: 6| Step: 8
Training loss: 2.5289748528113805
Validation loss: 2.5382212805441857

Epoch: 6| Step: 9
Training loss: 1.698875234673895
Validation loss: 2.527543812242184

Epoch: 6| Step: 10
Training loss: 1.9522921197787788
Validation loss: 2.565511360702881

Epoch: 6| Step: 11
Training loss: 1.5806646779043965
Validation loss: 2.586863594911743

Epoch: 6| Step: 12
Training loss: 2.1607392612531595
Validation loss: 2.580981727557094

Epoch: 6| Step: 13
Training loss: 2.4234066949555277
Validation loss: 2.5984210195991735

Epoch: 247| Step: 0
Training loss: 2.0379715262717806
Validation loss: 2.5975573145638093

Epoch: 6| Step: 1
Training loss: 2.4552700116439587
Validation loss: 2.6104684240553673

Epoch: 6| Step: 2
Training loss: 2.3156159517881063
Validation loss: 2.586201680221997

Epoch: 6| Step: 3
Training loss: 2.0940097249196006
Validation loss: 2.5935505633299014

Epoch: 6| Step: 4
Training loss: 2.6896192489656854
Validation loss: 2.5921247131702656

Epoch: 6| Step: 5
Training loss: 1.614183372262752
Validation loss: 2.5723394500635313

Epoch: 6| Step: 6
Training loss: 2.7204444252904247
Validation loss: 2.561912810496489

Epoch: 6| Step: 7
Training loss: 1.6364922924472134
Validation loss: 2.560732495533958

Epoch: 6| Step: 8
Training loss: 2.074215531571185
Validation loss: 2.559943715162227

Epoch: 6| Step: 9
Training loss: 1.9742940316982278
Validation loss: 2.553870666448946

Epoch: 6| Step: 10
Training loss: 2.084517663651638
Validation loss: 2.5553821548660065

Epoch: 6| Step: 11
Training loss: 2.3199326946098093
Validation loss: 2.5705472458273944

Epoch: 6| Step: 12
Training loss: 1.762243087116417
Validation loss: 2.5639361877138005

Epoch: 6| Step: 13
Training loss: 2.354819845772173
Validation loss: 2.553452203795655

Epoch: 248| Step: 0
Training loss: 2.324116372810896
Validation loss: 2.57858141317373

Epoch: 6| Step: 1
Training loss: 1.6938053586577113
Validation loss: 2.5667112683058106

Epoch: 6| Step: 2
Training loss: 2.134426749678623
Validation loss: 2.5942374081702604

Epoch: 6| Step: 3
Training loss: 2.601137968599408
Validation loss: 2.6139902047487205

Epoch: 6| Step: 4
Training loss: 2.329920338918386
Validation loss: 2.615915199871024

Epoch: 6| Step: 5
Training loss: 2.046686411316074
Validation loss: 2.6116982737172223

Epoch: 6| Step: 6
Training loss: 2.315990185481278
Validation loss: 2.5789309465315364

Epoch: 6| Step: 7
Training loss: 1.355210117433719
Validation loss: 2.6063933783595776

Epoch: 6| Step: 8
Training loss: 2.2141658007766396
Validation loss: 2.612568924038788

Epoch: 6| Step: 9
Training loss: 2.410783237904211
Validation loss: 2.631480044882226

Epoch: 6| Step: 10
Training loss: 2.3544338603569672
Validation loss: 2.6429135188910355

Epoch: 6| Step: 11
Training loss: 2.308308695123428
Validation loss: 2.6883631510380686

Epoch: 6| Step: 12
Training loss: 2.0333131142950314
Validation loss: 2.6903819445131516

Epoch: 6| Step: 13
Training loss: 2.1278855422939262
Validation loss: 2.7070735104240593

Epoch: 249| Step: 0
Training loss: 2.230299747831991
Validation loss: 2.7139099783930996

Epoch: 6| Step: 1
Training loss: 2.375075690418578
Validation loss: 2.6884808635573343

Epoch: 6| Step: 2
Training loss: 1.2624236697548876
Validation loss: 2.695776224096475

Epoch: 6| Step: 3
Training loss: 1.7707647272919649
Validation loss: 2.678944602432936

Epoch: 6| Step: 4
Training loss: 2.257275368972432
Validation loss: 2.6308953071071866

Epoch: 6| Step: 5
Training loss: 2.260404372877685
Validation loss: 2.657828157630353

Epoch: 6| Step: 6
Training loss: 2.267679479996903
Validation loss: 2.65424706733012

Epoch: 6| Step: 7
Training loss: 1.312834015987526
Validation loss: 2.6654476469011676

Epoch: 6| Step: 8
Training loss: 3.0008629511422353
Validation loss: 2.6778484146761254

Epoch: 6| Step: 9
Training loss: 1.7154231385257264
Validation loss: 2.6418141352971314

Epoch: 6| Step: 10
Training loss: 2.8221091679167283
Validation loss: 2.646671587901821

Epoch: 6| Step: 11
Training loss: 1.73508624365439
Validation loss: 2.59442609378425

Epoch: 6| Step: 12
Training loss: 2.5070213900164475
Validation loss: 2.6266383855849544

Epoch: 6| Step: 13
Training loss: 1.984970904408492
Validation loss: 2.5979705543914826

Epoch: 250| Step: 0
Training loss: 2.796535705785884
Validation loss: 2.5758606802522177

Epoch: 6| Step: 1
Training loss: 2.0926640669332697
Validation loss: 2.5778598687603815

Epoch: 6| Step: 2
Training loss: 2.579499589163209
Validation loss: 2.5886149610329383

Epoch: 6| Step: 3
Training loss: 1.856851355762615
Validation loss: 2.616156911298073

Epoch: 6| Step: 4
Training loss: 1.6963506236130612
Validation loss: 2.596890581912817

Epoch: 6| Step: 5
Training loss: 2.4458368001346833
Validation loss: 2.5824644463089887

Epoch: 6| Step: 6
Training loss: 2.316119274355704
Validation loss: 2.5844560050031564

Epoch: 6| Step: 7
Training loss: 1.8176257561960885
Validation loss: 2.5876381190688114

Epoch: 6| Step: 8
Training loss: 2.063197162594569
Validation loss: 2.5888126060078327

Epoch: 6| Step: 9
Training loss: 2.374196970853238
Validation loss: 2.601708454852993

Epoch: 6| Step: 10
Training loss: 1.86855224787849
Validation loss: 2.601679710520031

Epoch: 6| Step: 11
Training loss: 2.2395978587071355
Validation loss: 2.621151737305076

Epoch: 6| Step: 12
Training loss: 1.992365152254376
Validation loss: 2.647318735950693

Epoch: 6| Step: 13
Training loss: 1.7126386711611248
Validation loss: 2.6436593944273334

Epoch: 251| Step: 0
Training loss: 2.3007720273517935
Validation loss: 2.649674778301252

Epoch: 6| Step: 1
Training loss: 2.663546246487516
Validation loss: 2.652810176986604

Epoch: 6| Step: 2
Training loss: 1.3994441325330484
Validation loss: 2.620062165044547

Epoch: 6| Step: 3
Training loss: 2.362629042234717
Validation loss: 2.5872098130367758

Epoch: 6| Step: 4
Training loss: 1.2292954436694776
Validation loss: 2.5659203071716665

Epoch: 6| Step: 5
Training loss: 1.9225171264758651
Validation loss: 2.58725667230152

Epoch: 6| Step: 6
Training loss: 1.5463829413880688
Validation loss: 2.5514688232070015

Epoch: 6| Step: 7
Training loss: 2.1768226528308277
Validation loss: 2.5506353565377524

Epoch: 6| Step: 8
Training loss: 2.86191716819766
Validation loss: 2.5556327323271057

Epoch: 6| Step: 9
Training loss: 2.075643793450022
Validation loss: 2.5706699513144633

Epoch: 6| Step: 10
Training loss: 2.079969003886574
Validation loss: 2.5729099587624606

Epoch: 6| Step: 11
Training loss: 2.240164558633106
Validation loss: 2.5711133920805422

Epoch: 6| Step: 12
Training loss: 2.4861432386580224
Validation loss: 2.581254158293767

Epoch: 6| Step: 13
Training loss: 2.4326199317527677
Validation loss: 2.634242875725422

Epoch: 252| Step: 0
Training loss: 1.5423606736680018
Validation loss: 2.688493648446585

Epoch: 6| Step: 1
Training loss: 2.3008257047182936
Validation loss: 2.7349432654485115

Epoch: 6| Step: 2
Training loss: 1.8354487641119084
Validation loss: 2.7368406822722773

Epoch: 6| Step: 3
Training loss: 2.519957892202348
Validation loss: 2.7383881102284238

Epoch: 6| Step: 4
Training loss: 2.0392271245805356
Validation loss: 2.7353343915417407

Epoch: 6| Step: 5
Training loss: 2.3630513229123946
Validation loss: 2.695166896259645

Epoch: 6| Step: 6
Training loss: 1.7801064283721317
Validation loss: 2.654176194210309

Epoch: 6| Step: 7
Training loss: 2.054680073655781
Validation loss: 2.6343941470257723

Epoch: 6| Step: 8
Training loss: 2.0641729332535257
Validation loss: 2.5838383724440166

Epoch: 6| Step: 9
Training loss: 1.65619040327992
Validation loss: 2.607169904213971

Epoch: 6| Step: 10
Training loss: 3.2172999402666282
Validation loss: 2.5831892116911654

Epoch: 6| Step: 11
Training loss: 1.8942765841441789
Validation loss: 2.5729958191304068

Epoch: 6| Step: 12
Training loss: 2.3057513351759176
Validation loss: 2.5904581559971604

Epoch: 6| Step: 13
Training loss: 2.3038088400535295
Validation loss: 2.5746710249246423

Epoch: 253| Step: 0
Training loss: 1.6948278059463981
Validation loss: 2.5889461413680395

Epoch: 6| Step: 1
Training loss: 2.041539350419561
Validation loss: 2.5789260544546626

Epoch: 6| Step: 2
Training loss: 2.2242436698694013
Validation loss: 2.6017388865384823

Epoch: 6| Step: 3
Training loss: 1.9313747427445616
Validation loss: 2.6395007567421778

Epoch: 6| Step: 4
Training loss: 1.6737873869203848
Validation loss: 2.6552100146530133

Epoch: 6| Step: 5
Training loss: 2.454786673326574
Validation loss: 2.6967334484732186

Epoch: 6| Step: 6
Training loss: 1.7204437926428136
Validation loss: 2.705927034155087

Epoch: 6| Step: 7
Training loss: 3.4090368786778393
Validation loss: 2.724931886970786

Epoch: 6| Step: 8
Training loss: 2.3236366376470996
Validation loss: 2.7500858004507607

Epoch: 6| Step: 9
Training loss: 2.588923916650239
Validation loss: 2.725837691336724

Epoch: 6| Step: 10
Training loss: 2.3081407441408732
Validation loss: 2.703871739610088

Epoch: 6| Step: 11
Training loss: 1.4150359454492498
Validation loss: 2.6786882708057886

Epoch: 6| Step: 12
Training loss: 2.1624906594840954
Validation loss: 2.637562256570942

Epoch: 6| Step: 13
Training loss: 2.0477421212410953
Validation loss: 2.6051149294853055

Epoch: 254| Step: 0
Training loss: 1.7654701097454302
Validation loss: 2.5996666492827862

Epoch: 6| Step: 1
Training loss: 2.0275293166067185
Validation loss: 2.5765835402018857

Epoch: 6| Step: 2
Training loss: 1.9643626903957796
Validation loss: 2.550375516206659

Epoch: 6| Step: 3
Training loss: 2.492322194635958
Validation loss: 2.5463575918031935

Epoch: 6| Step: 4
Training loss: 1.8517876983055988
Validation loss: 2.5442496422178302

Epoch: 6| Step: 5
Training loss: 2.839378602187038
Validation loss: 2.5387937119848383

Epoch: 6| Step: 6
Training loss: 2.1149870638981563
Validation loss: 2.5508298611256413

Epoch: 6| Step: 7
Training loss: 2.676857212674658
Validation loss: 2.589949385616078

Epoch: 6| Step: 8
Training loss: 1.760870008012979
Validation loss: 2.620282740794556

Epoch: 6| Step: 9
Training loss: 2.408049269910381
Validation loss: 2.641652526175823

Epoch: 6| Step: 10
Training loss: 2.0189692233547087
Validation loss: 2.690990236830487

Epoch: 6| Step: 11
Training loss: 2.3802363243098803
Validation loss: 2.69851221902609

Epoch: 6| Step: 12
Training loss: 1.30040206193693
Validation loss: 2.735211751157382

Epoch: 6| Step: 13
Training loss: 2.366129925356897
Validation loss: 2.7241876091146753

Epoch: 255| Step: 0
Training loss: 1.7912245434098821
Validation loss: 2.675841185555173

Epoch: 6| Step: 1
Training loss: 1.412950616037013
Validation loss: 2.651696194912518

Epoch: 6| Step: 2
Training loss: 2.106640208516786
Validation loss: 2.588842959046594

Epoch: 6| Step: 3
Training loss: 2.1958699994823156
Validation loss: 2.579555168739557

Epoch: 6| Step: 4
Training loss: 1.6669681594270052
Validation loss: 2.5883217659974465

Epoch: 6| Step: 5
Training loss: 1.9373322075820631
Validation loss: 2.566284718725355

Epoch: 6| Step: 6
Training loss: 2.3229083301981914
Validation loss: 2.556384068636435

Epoch: 6| Step: 7
Training loss: 1.8117683512422973
Validation loss: 2.5363736043847913

Epoch: 6| Step: 8
Training loss: 2.542214840001649
Validation loss: 2.5308116015155537

Epoch: 6| Step: 9
Training loss: 2.0742332328678703
Validation loss: 2.5352463042531928

Epoch: 6| Step: 10
Training loss: 2.589654561723234
Validation loss: 2.567590278764253

Epoch: 6| Step: 11
Training loss: 2.999820544915442
Validation loss: 2.578295923597421

Epoch: 6| Step: 12
Training loss: 2.7346204375059697
Validation loss: 2.6081572715968226

Epoch: 6| Step: 13
Training loss: 1.4569037742178865
Validation loss: 2.6358345112620576

Epoch: 256| Step: 0
Training loss: 1.5632383509387502
Validation loss: 2.651449165926856

Epoch: 6| Step: 1
Training loss: 1.725680924517629
Validation loss: 2.7003409541277246

Epoch: 6| Step: 2
Training loss: 1.8482329615774171
Validation loss: 2.6677248067370796

Epoch: 6| Step: 3
Training loss: 1.8097392135659116
Validation loss: 2.662621459817226

Epoch: 6| Step: 4
Training loss: 2.4868685126861148
Validation loss: 2.605727534141438

Epoch: 6| Step: 5
Training loss: 2.5455970600410907
Validation loss: 2.601170538012903

Epoch: 6| Step: 6
Training loss: 2.1405783320999285
Validation loss: 2.6168459845003995

Epoch: 6| Step: 7
Training loss: 2.954744409651567
Validation loss: 2.584204009187209

Epoch: 6| Step: 8
Training loss: 2.1684231118751383
Validation loss: 2.548929349367897

Epoch: 6| Step: 9
Training loss: 1.641317893350484
Validation loss: 2.5682308034299175

Epoch: 6| Step: 10
Training loss: 1.744758658784872
Validation loss: 2.568385088541672

Epoch: 6| Step: 11
Training loss: 2.2406180069094694
Validation loss: 2.5898819849136827

Epoch: 6| Step: 12
Training loss: 2.833162152972219
Validation loss: 2.6073300844339866

Epoch: 6| Step: 13
Training loss: 1.9750296940563135
Validation loss: 2.608660556348662

Epoch: 257| Step: 0
Training loss: 1.5303465065615904
Validation loss: 2.595319066507299

Epoch: 6| Step: 1
Training loss: 3.0405304410841176
Validation loss: 2.598578550815621

Epoch: 6| Step: 2
Training loss: 1.4867326985364864
Validation loss: 2.613194379137169

Epoch: 6| Step: 3
Training loss: 2.2947039042097797
Validation loss: 2.6047773992916623

Epoch: 6| Step: 4
Training loss: 2.547457107766854
Validation loss: 2.6002103405624215

Epoch: 6| Step: 5
Training loss: 2.14647493369028
Validation loss: 2.6023337106044386

Epoch: 6| Step: 6
Training loss: 2.2055758648547736
Validation loss: 2.590634616025618

Epoch: 6| Step: 7
Training loss: 1.5658129855233494
Validation loss: 2.596726965022534

Epoch: 6| Step: 8
Training loss: 1.8918770671690783
Validation loss: 2.5801101594024414

Epoch: 6| Step: 9
Training loss: 1.163615813094162
Validation loss: 2.621330330144896

Epoch: 6| Step: 10
Training loss: 2.7561193353038598
Validation loss: 2.6286572153716614

Epoch: 6| Step: 11
Training loss: 2.0729743399975624
Validation loss: 2.6467105782883382

Epoch: 6| Step: 12
Training loss: 1.9000554352754424
Validation loss: 2.654823249158647

Epoch: 6| Step: 13
Training loss: 2.4460878940489033
Validation loss: 2.653315025926176

Epoch: 258| Step: 0
Training loss: 2.049083072011635
Validation loss: 2.643087739715654

Epoch: 6| Step: 1
Training loss: 2.846663606837085
Validation loss: 2.6078188095184056

Epoch: 6| Step: 2
Training loss: 1.4905507163166194
Validation loss: 2.5427481013064566

Epoch: 6| Step: 3
Training loss: 2.441732400089629
Validation loss: 2.5470090491467725

Epoch: 6| Step: 4
Training loss: 1.7522509947882958
Validation loss: 2.533620619065302

Epoch: 6| Step: 5
Training loss: 2.502862626515781
Validation loss: 2.5429600463030693

Epoch: 6| Step: 6
Training loss: 2.2930227140091026
Validation loss: 2.510530260821585

Epoch: 6| Step: 7
Training loss: 1.3870961709926235
Validation loss: 2.550933716497918

Epoch: 6| Step: 8
Training loss: 1.392475953707768
Validation loss: 2.5527775164195763

Epoch: 6| Step: 9
Training loss: 2.962739179911244
Validation loss: 2.578743215093718

Epoch: 6| Step: 10
Training loss: 2.345348169308412
Validation loss: 2.6423926146193377

Epoch: 6| Step: 11
Training loss: 1.5619994315367383
Validation loss: 2.689425953801903

Epoch: 6| Step: 12
Training loss: 2.448815514864745
Validation loss: 2.687753591475525

Epoch: 6| Step: 13
Training loss: 2.2507388703137705
Validation loss: 2.6939922102910177

Epoch: 259| Step: 0
Training loss: 2.422102985110955
Validation loss: 2.7026156789069242

Epoch: 6| Step: 1
Training loss: 2.0004062240043035
Validation loss: 2.6489025296598565

Epoch: 6| Step: 2
Training loss: 2.0226295065704964
Validation loss: 2.634957614065558

Epoch: 6| Step: 3
Training loss: 2.484266362723996
Validation loss: 2.597248498564978

Epoch: 6| Step: 4
Training loss: 1.385749284593018
Validation loss: 2.5716633594893006

Epoch: 6| Step: 5
Training loss: 2.122059526692562
Validation loss: 2.546517173422062

Epoch: 6| Step: 6
Training loss: 2.771483686795193
Validation loss: 2.54988497555677

Epoch: 6| Step: 7
Training loss: 2.6567619279209778
Validation loss: 2.5690723739760326

Epoch: 6| Step: 8
Training loss: 2.218483492466792
Validation loss: 2.5434272223908345

Epoch: 6| Step: 9
Training loss: 1.4348089488379725
Validation loss: 2.5715863627885236

Epoch: 6| Step: 10
Training loss: 2.300727778851277
Validation loss: 2.5753583917925185

Epoch: 6| Step: 11
Training loss: 2.0197463372980304
Validation loss: 2.602440595165655

Epoch: 6| Step: 12
Training loss: 1.4040794575641673
Validation loss: 2.6052574670656123

Epoch: 6| Step: 13
Training loss: 2.3652133074451394
Validation loss: 2.6317927407120987

Epoch: 260| Step: 0
Training loss: 1.2803865174752447
Validation loss: 2.633962317890184

Epoch: 6| Step: 1
Training loss: 1.8575671727804628
Validation loss: 2.6752950036257626

Epoch: 6| Step: 2
Training loss: 2.577803343156489
Validation loss: 2.687833321770892

Epoch: 6| Step: 3
Training loss: 2.9428068881565173
Validation loss: 2.6905236644912867

Epoch: 6| Step: 4
Training loss: 1.661976469398955
Validation loss: 2.6679774778045533

Epoch: 6| Step: 5
Training loss: 1.9016716805853624
Validation loss: 2.630936313515153

Epoch: 6| Step: 6
Training loss: 2.1667606871330243
Validation loss: 2.6010424425406335

Epoch: 6| Step: 7
Training loss: 2.32018703545341
Validation loss: 2.5701058719216903

Epoch: 6| Step: 8
Training loss: 1.6282594709456233
Validation loss: 2.572719849588951

Epoch: 6| Step: 9
Training loss: 2.2485317101799054
Validation loss: 2.5922520766474184

Epoch: 6| Step: 10
Training loss: 2.4186855849725193
Validation loss: 2.58922896800631

Epoch: 6| Step: 11
Training loss: 2.4771679640531743
Validation loss: 2.623514148470198

Epoch: 6| Step: 12
Training loss: 2.070533136091129
Validation loss: 2.655230487318516

Epoch: 6| Step: 13
Training loss: 1.9882152374041326
Validation loss: 2.7144015237892956

Epoch: 261| Step: 0
Training loss: 2.157677440573784
Validation loss: 2.727951963689744

Epoch: 6| Step: 1
Training loss: 1.8719196447993416
Validation loss: 2.7238666137269316

Epoch: 6| Step: 2
Training loss: 1.773999767823833
Validation loss: 2.717818557377516

Epoch: 6| Step: 3
Training loss: 1.833461829219611
Validation loss: 2.6971736508322057

Epoch: 6| Step: 4
Training loss: 1.894564221282037
Validation loss: 2.667014417226256

Epoch: 6| Step: 5
Training loss: 1.9745464069653789
Validation loss: 2.6446250399284987

Epoch: 6| Step: 6
Training loss: 2.097237486569712
Validation loss: 2.6136952420590123

Epoch: 6| Step: 7
Training loss: 2.1949167132380576
Validation loss: 2.5840587264071213

Epoch: 6| Step: 8
Training loss: 2.7906933886103285
Validation loss: 2.561481816289009

Epoch: 6| Step: 9
Training loss: 2.184237854326415
Validation loss: 2.576645505611814

Epoch: 6| Step: 10
Training loss: 2.124124683290982
Validation loss: 2.5472078632415474

Epoch: 6| Step: 11
Training loss: 1.6574637805784607
Validation loss: 2.5650944640206856

Epoch: 6| Step: 12
Training loss: 2.4170460458014476
Validation loss: 2.567150950466703

Epoch: 6| Step: 13
Training loss: 2.6099671931050152
Validation loss: 2.5791010694733214

Epoch: 262| Step: 0
Training loss: 2.1186752441181405
Validation loss: 2.62387327202983

Epoch: 6| Step: 1
Training loss: 2.110378676509067
Validation loss: 2.60572518569446

Epoch: 6| Step: 2
Training loss: 2.6352131479761014
Validation loss: 2.6695405008202084

Epoch: 6| Step: 3
Training loss: 1.5051269333244626
Validation loss: 2.6786440494320516

Epoch: 6| Step: 4
Training loss: 2.910200162210644
Validation loss: 2.6465227675615024

Epoch: 6| Step: 5
Training loss: 1.41259512454405
Validation loss: 2.6361684041172384

Epoch: 6| Step: 6
Training loss: 2.895089490755832
Validation loss: 2.6009980239435335

Epoch: 6| Step: 7
Training loss: 1.5153176694133974
Validation loss: 2.541228160135717

Epoch: 6| Step: 8
Training loss: 2.3754457758112646
Validation loss: 2.5140111418117796

Epoch: 6| Step: 9
Training loss: 2.4197536899598817
Validation loss: 2.5269239058264494

Epoch: 6| Step: 10
Training loss: 1.5613121094883187
Validation loss: 2.5300122912363423

Epoch: 6| Step: 11
Training loss: 2.4310748196523195
Validation loss: 2.5267399927066103

Epoch: 6| Step: 12
Training loss: 1.588458533274436
Validation loss: 2.54704535290993

Epoch: 6| Step: 13
Training loss: 2.2613661100775726
Validation loss: 2.57335546872727

Epoch: 263| Step: 0
Training loss: 2.446944207276032
Validation loss: 2.552162454637209

Epoch: 6| Step: 1
Training loss: 1.85500784520138
Validation loss: 2.5731403444079883

Epoch: 6| Step: 2
Training loss: 1.9198679174251223
Validation loss: 2.642628896920507

Epoch: 6| Step: 3
Training loss: 1.6111536659817691
Validation loss: 2.6423044074701627

Epoch: 6| Step: 4
Training loss: 1.6918330193769424
Validation loss: 2.6576003363547858

Epoch: 6| Step: 5
Training loss: 1.469981630820379
Validation loss: 2.7065113737237443

Epoch: 6| Step: 6
Training loss: 2.207469795340101
Validation loss: 2.696524350387941

Epoch: 6| Step: 7
Training loss: 1.5240219951203846
Validation loss: 2.6657235643500563

Epoch: 6| Step: 8
Training loss: 2.5713799297939555
Validation loss: 2.6641961117349164

Epoch: 6| Step: 9
Training loss: 2.5514988028710195
Validation loss: 2.637989195884693

Epoch: 6| Step: 10
Training loss: 2.2482116797893195
Validation loss: 2.6030359229287123

Epoch: 6| Step: 11
Training loss: 2.02437896624486
Validation loss: 2.5594841802999544

Epoch: 6| Step: 12
Training loss: 2.315869325420127
Validation loss: 2.5568227137258934

Epoch: 6| Step: 13
Training loss: 3.0480633887860837
Validation loss: 2.5420032861979984

Epoch: 264| Step: 0
Training loss: 2.4539925565847662
Validation loss: 2.5345799712468637

Epoch: 6| Step: 1
Training loss: 2.5508552762516454
Validation loss: 2.543401100294119

Epoch: 6| Step: 2
Training loss: 1.6506738904929485
Validation loss: 2.54711842690027

Epoch: 6| Step: 3
Training loss: 2.042098901369283
Validation loss: 2.581142609265802

Epoch: 6| Step: 4
Training loss: 2.169249340254668
Validation loss: 2.6247443271436017

Epoch: 6| Step: 5
Training loss: 1.7984610813692776
Validation loss: 2.6201813991250456

Epoch: 6| Step: 6
Training loss: 2.202221407812648
Validation loss: 2.641635242560053

Epoch: 6| Step: 7
Training loss: 1.8352623530051255
Validation loss: 2.642023126477372

Epoch: 6| Step: 8
Training loss: 2.1046071740265715
Validation loss: 2.6562553854495037

Epoch: 6| Step: 9
Training loss: 2.423575708615901
Validation loss: 2.691991335496378

Epoch: 6| Step: 10
Training loss: 1.3721899448790866
Validation loss: 2.6759328386197185

Epoch: 6| Step: 11
Training loss: 2.2449485446665998
Validation loss: 2.696030894198684

Epoch: 6| Step: 12
Training loss: 2.2501218550851716
Validation loss: 2.7159380054542903

Epoch: 6| Step: 13
Training loss: 2.332191653461993
Validation loss: 2.6980010403630406

Epoch: 265| Step: 0
Training loss: 2.122023461250812
Validation loss: 2.6730622001943365

Epoch: 6| Step: 1
Training loss: 2.414858097464506
Validation loss: 2.6666310178837556

Epoch: 6| Step: 2
Training loss: 1.9848060440125208
Validation loss: 2.6403706144033308

Epoch: 6| Step: 3
Training loss: 2.5774254977006628
Validation loss: 2.6336689055175433

Epoch: 6| Step: 4
Training loss: 1.7757648539426054
Validation loss: 2.6130481686352574

Epoch: 6| Step: 5
Training loss: 1.5174845662973993
Validation loss: 2.599059266683153

Epoch: 6| Step: 6
Training loss: 2.165414215883159
Validation loss: 2.6073075211078867

Epoch: 6| Step: 7
Training loss: 1.847634700463986
Validation loss: 2.605858754065643

Epoch: 6| Step: 8
Training loss: 1.7674618508890494
Validation loss: 2.6409507415118134

Epoch: 6| Step: 9
Training loss: 2.0619270222401047
Validation loss: 2.6577037498237437

Epoch: 6| Step: 10
Training loss: 1.7801156028969365
Validation loss: 2.6440949674115104

Epoch: 6| Step: 11
Training loss: 2.441951599247542
Validation loss: 2.649095864175292

Epoch: 6| Step: 12
Training loss: 1.8787113968975229
Validation loss: 2.669383763351233

Epoch: 6| Step: 13
Training loss: 2.587708388335897
Validation loss: 2.6792782544222526

Epoch: 266| Step: 0
Training loss: 2.4451756058177363
Validation loss: 2.6918947379111415

Epoch: 6| Step: 1
Training loss: 2.1793020037412765
Validation loss: 2.661662850979351

Epoch: 6| Step: 2
Training loss: 1.8387294885877445
Validation loss: 2.6700001360742007

Epoch: 6| Step: 3
Training loss: 1.9657819870208408
Validation loss: 2.660176087098699

Epoch: 6| Step: 4
Training loss: 2.7534898808412684
Validation loss: 2.640723503126482

Epoch: 6| Step: 5
Training loss: 1.9197459018970042
Validation loss: 2.614153083163637

Epoch: 6| Step: 6
Training loss: 1.5967482245898108
Validation loss: 2.5886044612971535

Epoch: 6| Step: 7
Training loss: 1.6600114826586574
Validation loss: 2.605088037893456

Epoch: 6| Step: 8
Training loss: 2.072822287502039
Validation loss: 2.5827816302298414

Epoch: 6| Step: 9
Training loss: 1.8901855966983296
Validation loss: 2.575127525628451

Epoch: 6| Step: 10
Training loss: 2.159974350953581
Validation loss: 2.56921876712434

Epoch: 6| Step: 11
Training loss: 1.6573725800709818
Validation loss: 2.5670380455777124

Epoch: 6| Step: 12
Training loss: 2.4563554037449133
Validation loss: 2.5942789633765906

Epoch: 6| Step: 13
Training loss: 2.431619936690356
Validation loss: 2.5961558356463135

Epoch: 267| Step: 0
Training loss: 2.3908649398967805
Validation loss: 2.599325858652398

Epoch: 6| Step: 1
Training loss: 2.3635441405304536
Validation loss: 2.6540331846374605

Epoch: 6| Step: 2
Training loss: 1.773580940260143
Validation loss: 2.642958270443159

Epoch: 6| Step: 3
Training loss: 2.1617768815099554
Validation loss: 2.7053700937923044

Epoch: 6| Step: 4
Training loss: 1.9951015328023247
Validation loss: 2.698641283284681

Epoch: 6| Step: 5
Training loss: 2.197609348115317
Validation loss: 2.655964211442078

Epoch: 6| Step: 6
Training loss: 2.4346446405809257
Validation loss: 2.6088225794518767

Epoch: 6| Step: 7
Training loss: 1.9718507840805184
Validation loss: 2.559211621408766

Epoch: 6| Step: 8
Training loss: 1.8418228293215353
Validation loss: 2.5496436206638697

Epoch: 6| Step: 9
Training loss: 2.1041824289870896
Validation loss: 2.573745676351667

Epoch: 6| Step: 10
Training loss: 1.462496002713471
Validation loss: 2.6073589874570327

Epoch: 6| Step: 11
Training loss: 2.0590863733243583
Validation loss: 2.6042954959792306

Epoch: 6| Step: 12
Training loss: 1.740813119471774
Validation loss: 2.604338668229274

Epoch: 6| Step: 13
Training loss: 2.6658372085732327
Validation loss: 2.656997059504239

Epoch: 268| Step: 0
Training loss: 1.800615613357457
Validation loss: 2.6897620063213816

Epoch: 6| Step: 1
Training loss: 1.509373464642804
Validation loss: 2.7370785236321225

Epoch: 6| Step: 2
Training loss: 2.2525916538368747
Validation loss: 2.7016679809758517

Epoch: 6| Step: 3
Training loss: 2.4722805611612335
Validation loss: 2.6993148941163323

Epoch: 6| Step: 4
Training loss: 2.022730287660684
Validation loss: 2.6931892177137247

Epoch: 6| Step: 5
Training loss: 2.0589341057807125
Validation loss: 2.67901410093129

Epoch: 6| Step: 6
Training loss: 1.922040172395246
Validation loss: 2.6638907547794934

Epoch: 6| Step: 7
Training loss: 2.128705216461426
Validation loss: 2.6166694545933478

Epoch: 6| Step: 8
Training loss: 2.2804434408656804
Validation loss: 2.588979309255729

Epoch: 6| Step: 9
Training loss: 2.5868837405912166
Validation loss: 2.554947010667805

Epoch: 6| Step: 10
Training loss: 2.4092093760837927
Validation loss: 2.554084683378763

Epoch: 6| Step: 11
Training loss: 2.2449131790398935
Validation loss: 2.553272458148434

Epoch: 6| Step: 12
Training loss: 2.585364701832121
Validation loss: 2.5347601253398713

Epoch: 6| Step: 13
Training loss: 1.5092925086689601
Validation loss: 2.5604754723380543

Epoch: 269| Step: 0
Training loss: 2.3046802585294075
Validation loss: 2.5425571122158086

Epoch: 6| Step: 1
Training loss: 2.404602378444135
Validation loss: 2.5603106069881805

Epoch: 6| Step: 2
Training loss: 2.094458958176104
Validation loss: 2.6136322470018136

Epoch: 6| Step: 3
Training loss: 2.1293677153601296
Validation loss: 2.626983120544944

Epoch: 6| Step: 4
Training loss: 1.8714645750956689
Validation loss: 2.665576269815679

Epoch: 6| Step: 5
Training loss: 2.4870583300282467
Validation loss: 2.6577654236921386

Epoch: 6| Step: 6
Training loss: 1.9856498407881908
Validation loss: 2.689971452795523

Epoch: 6| Step: 7
Training loss: 1.9415770672384145
Validation loss: 2.679301880133229

Epoch: 6| Step: 8
Training loss: 2.6951377037976445
Validation loss: 2.6623386089380463

Epoch: 6| Step: 9
Training loss: 2.0543274074388305
Validation loss: 2.6174302932702105

Epoch: 6| Step: 10
Training loss: 2.0345625642956886
Validation loss: 2.569827558691778

Epoch: 6| Step: 11
Training loss: 2.2611668362989867
Validation loss: 2.5343370176856577

Epoch: 6| Step: 12
Training loss: 1.9373718342382629
Validation loss: 2.542398079136174

Epoch: 6| Step: 13
Training loss: 1.6410289448772086
Validation loss: 2.500056584035756

Epoch: 270| Step: 0
Training loss: 2.0262325821256737
Validation loss: 2.5322278335750523

Epoch: 6| Step: 1
Training loss: 2.66516144311809
Validation loss: 2.5291520046540237

Epoch: 6| Step: 2
Training loss: 1.567634842714193
Validation loss: 2.534897237045394

Epoch: 6| Step: 3
Training loss: 2.3420147384844356
Validation loss: 2.51345298622246

Epoch: 6| Step: 4
Training loss: 2.60419228096127
Validation loss: 2.545688032716534

Epoch: 6| Step: 5
Training loss: 1.8949912859633296
Validation loss: 2.538848069746493

Epoch: 6| Step: 6
Training loss: 1.6199378615106321
Validation loss: 2.5364029791481943

Epoch: 6| Step: 7
Training loss: 1.806318330627262
Validation loss: 2.5696499481729456

Epoch: 6| Step: 8
Training loss: 2.334335236932041
Validation loss: 2.597962570294735

Epoch: 6| Step: 9
Training loss: 1.9074867489055767
Validation loss: 2.612585053892199

Epoch: 6| Step: 10
Training loss: 2.0804804023419226
Validation loss: 2.6426757433581765

Epoch: 6| Step: 11
Training loss: 2.0935815771884836
Validation loss: 2.6406071829712032

Epoch: 6| Step: 12
Training loss: 1.9109867217492393
Validation loss: 2.628363709678402

Epoch: 6| Step: 13
Training loss: 2.461688699057644
Validation loss: 2.6334518426070224

Epoch: 271| Step: 0
Training loss: 2.1182372246326273
Validation loss: 2.6519074940329577

Epoch: 6| Step: 1
Training loss: 2.0896698781350516
Validation loss: 2.658492514250053

Epoch: 6| Step: 2
Training loss: 1.7241556644349858
Validation loss: 2.6226522906813945

Epoch: 6| Step: 3
Training loss: 1.9537514864378367
Validation loss: 2.6295268973230765

Epoch: 6| Step: 4
Training loss: 1.9353295751822726
Validation loss: 2.6470259784393573

Epoch: 6| Step: 5
Training loss: 1.8222641857996058
Validation loss: 2.6379570810510713

Epoch: 6| Step: 6
Training loss: 2.643160082786528
Validation loss: 2.6262625428253847

Epoch: 6| Step: 7
Training loss: 2.0544456658715884
Validation loss: 2.6508741844249024

Epoch: 6| Step: 8
Training loss: 2.6191890521483083
Validation loss: 2.6417026164339372

Epoch: 6| Step: 9
Training loss: 1.9083131975113892
Validation loss: 2.6702104852935635

Epoch: 6| Step: 10
Training loss: 2.0416836900066238
Validation loss: 2.6505435757977183

Epoch: 6| Step: 11
Training loss: 1.714188365783484
Validation loss: 2.6729597154115536

Epoch: 6| Step: 12
Training loss: 1.5068427411443128
Validation loss: 2.646743360096053

Epoch: 6| Step: 13
Training loss: 2.5476454991052675
Validation loss: 2.6149112500848113

Epoch: 272| Step: 0
Training loss: 2.1237537993362867
Validation loss: 2.614325223140774

Epoch: 6| Step: 1
Training loss: 1.7235747157347763
Validation loss: 2.6154753061450116

Epoch: 6| Step: 2
Training loss: 2.0427873870113635
Validation loss: 2.5893726793101233

Epoch: 6| Step: 3
Training loss: 1.8474444858743255
Validation loss: 2.6196299301387214

Epoch: 6| Step: 4
Training loss: 1.5012410116442745
Validation loss: 2.595425979671855

Epoch: 6| Step: 5
Training loss: 1.884143849329889
Validation loss: 2.5939396861625004

Epoch: 6| Step: 6
Training loss: 2.0317384572706305
Validation loss: 2.630830450732062

Epoch: 6| Step: 7
Training loss: 2.159642632732773
Validation loss: 2.6069887408711008

Epoch: 6| Step: 8
Training loss: 2.50446112282604
Validation loss: 2.625311515125898

Epoch: 6| Step: 9
Training loss: 2.474385167828718
Validation loss: 2.6249154697916337

Epoch: 6| Step: 10
Training loss: 1.4565031101810395
Validation loss: 2.6287227300153657

Epoch: 6| Step: 11
Training loss: 1.9981561744603897
Validation loss: 2.6503722289310683

Epoch: 6| Step: 12
Training loss: 1.9435127236136491
Validation loss: 2.640689074098199

Epoch: 6| Step: 13
Training loss: 2.7749833218185023
Validation loss: 2.6535723036192698

Epoch: 273| Step: 0
Training loss: 1.5539283624286877
Validation loss: 2.649497406161046

Epoch: 6| Step: 1
Training loss: 1.5709902690875035
Validation loss: 2.650093903467275

Epoch: 6| Step: 2
Training loss: 2.3311547144830276
Validation loss: 2.6730222488406907

Epoch: 6| Step: 3
Training loss: 2.399632258851795
Validation loss: 2.6735653651784

Epoch: 6| Step: 4
Training loss: 2.25451577868326
Validation loss: 2.6678329217236456

Epoch: 6| Step: 5
Training loss: 2.0044940287233945
Validation loss: 2.648303918461085

Epoch: 6| Step: 6
Training loss: 1.4403674509859847
Validation loss: 2.6760234045640745

Epoch: 6| Step: 7
Training loss: 2.5921358348257417
Validation loss: 2.6623132207363995

Epoch: 6| Step: 8
Training loss: 1.4468956601869727
Validation loss: 2.6756160490175445

Epoch: 6| Step: 9
Training loss: 2.1210130426778315
Validation loss: 2.6707900523360166

Epoch: 6| Step: 10
Training loss: 1.7532999396800468
Validation loss: 2.660637593985171

Epoch: 6| Step: 11
Training loss: 2.1537292784116344
Validation loss: 2.664083456514478

Epoch: 6| Step: 12
Training loss: 2.4355041940676863
Validation loss: 2.659710279548023

Epoch: 6| Step: 13
Training loss: 2.3007097476023355
Validation loss: 2.616677723292258

Epoch: 274| Step: 0
Training loss: 1.3388356233600407
Validation loss: 2.6183850485512257

Epoch: 6| Step: 1
Training loss: 2.7872592428609977
Validation loss: 2.5989378251137456

Epoch: 6| Step: 2
Training loss: 2.5329700795125976
Validation loss: 2.557200666519039

Epoch: 6| Step: 3
Training loss: 1.9770029655283798
Validation loss: 2.5863626981443923

Epoch: 6| Step: 4
Training loss: 2.309459130351079
Validation loss: 2.6022855195007044

Epoch: 6| Step: 5
Training loss: 1.281513652191491
Validation loss: 2.618720824838569

Epoch: 6| Step: 6
Training loss: 1.9602181988532497
Validation loss: 2.6128110210717312

Epoch: 6| Step: 7
Training loss: 2.4374225310706192
Validation loss: 2.6445077644330808

Epoch: 6| Step: 8
Training loss: 1.6682044405439158
Validation loss: 2.666284300292443

Epoch: 6| Step: 9
Training loss: 2.3902383130061837
Validation loss: 2.6462448631096214

Epoch: 6| Step: 10
Training loss: 1.969863818733536
Validation loss: 2.6387757516890726

Epoch: 6| Step: 11
Training loss: 1.8646497519258618
Validation loss: 2.6174027843086747

Epoch: 6| Step: 12
Training loss: 1.8446240050774663
Validation loss: 2.6395894264044486

Epoch: 6| Step: 13
Training loss: 2.1011988669124606
Validation loss: 2.6276005170561767

Epoch: 275| Step: 0
Training loss: 1.3265113002929876
Validation loss: 2.6401151507243137

Epoch: 6| Step: 1
Training loss: 2.7691674255804752
Validation loss: 2.5938441094786597

Epoch: 6| Step: 2
Training loss: 2.2004625181036603
Validation loss: 2.5843796815718316

Epoch: 6| Step: 3
Training loss: 1.1039491055236037
Validation loss: 2.6488040006568765

Epoch: 6| Step: 4
Training loss: 2.4732826247076796
Validation loss: 2.602910545036193

Epoch: 6| Step: 5
Training loss: 2.4389968579761994
Validation loss: 2.6712960402323733

Epoch: 6| Step: 6
Training loss: 1.383831144674277
Validation loss: 2.653955523258367

Epoch: 6| Step: 7
Training loss: 2.1925873590897105
Validation loss: 2.6514492633402984

Epoch: 6| Step: 8
Training loss: 2.1231838768180853
Validation loss: 2.6318209674246673

Epoch: 6| Step: 9
Training loss: 2.007174379346554
Validation loss: 2.637937423326334

Epoch: 6| Step: 10
Training loss: 2.332203409814628
Validation loss: 2.6583020081861815

Epoch: 6| Step: 11
Training loss: 1.748668436543748
Validation loss: 2.64944420870128

Epoch: 6| Step: 12
Training loss: 1.9923808882851457
Validation loss: 2.669094371390237

Epoch: 6| Step: 13
Training loss: 1.7619543488961324
Validation loss: 2.6652817457800264

Epoch: 276| Step: 0
Training loss: 1.3332033789405615
Validation loss: 2.691070491404763

Epoch: 6| Step: 1
Training loss: 2.238256324509448
Validation loss: 2.66086338557488

Epoch: 6| Step: 2
Training loss: 1.4253508453798056
Validation loss: 2.6263869496775496

Epoch: 6| Step: 3
Training loss: 1.8893168944655665
Validation loss: 2.605375243438791

Epoch: 6| Step: 4
Training loss: 1.9478085601781483
Validation loss: 2.5934232942656594

Epoch: 6| Step: 5
Training loss: 2.6131248712437
Validation loss: 2.595366376470342

Epoch: 6| Step: 6
Training loss: 2.0591986851330097
Validation loss: 2.5822902901540528

Epoch: 6| Step: 7
Training loss: 1.8659919518463814
Validation loss: 2.5604402280819607

Epoch: 6| Step: 8
Training loss: 1.8767793477696955
Validation loss: 2.612917036022934

Epoch: 6| Step: 9
Training loss: 2.2179981085973024
Validation loss: 2.6101192395241832

Epoch: 6| Step: 10
Training loss: 2.5115140887895646
Validation loss: 2.6446223654139707

Epoch: 6| Step: 11
Training loss: 2.3713599971501553
Validation loss: 2.7204068422619696

Epoch: 6| Step: 12
Training loss: 2.0642512429376727
Validation loss: 2.729572030652894

Epoch: 6| Step: 13
Training loss: 2.418235751741541
Validation loss: 2.7337524577314216

Epoch: 277| Step: 0
Training loss: 2.2783150801616943
Validation loss: 2.6547067160656517

Epoch: 6| Step: 1
Training loss: 2.099399744258784
Validation loss: 2.658329676881705

Epoch: 6| Step: 2
Training loss: 2.4901912909875916
Validation loss: 2.612431272487929

Epoch: 6| Step: 3
Training loss: 1.1528981055358045
Validation loss: 2.577651733732394

Epoch: 6| Step: 4
Training loss: 1.752359026409881
Validation loss: 2.5268259829952364

Epoch: 6| Step: 5
Training loss: 2.130950562145759
Validation loss: 2.5356601004756425

Epoch: 6| Step: 6
Training loss: 2.6508371290483335
Validation loss: 2.5408475421004857

Epoch: 6| Step: 7
Training loss: 2.8307535169876568
Validation loss: 2.537780218828404

Epoch: 6| Step: 8
Training loss: 1.3115566133008474
Validation loss: 2.5651442213206894

Epoch: 6| Step: 9
Training loss: 1.107599799178282
Validation loss: 2.585000213067189

Epoch: 6| Step: 10
Training loss: 2.409232038123204
Validation loss: 2.600781641439017

Epoch: 6| Step: 11
Training loss: 2.293747829675297
Validation loss: 2.6015562529006813

Epoch: 6| Step: 12
Training loss: 1.6737851078376933
Validation loss: 2.644283446474156

Epoch: 6| Step: 13
Training loss: 2.064578078719098
Validation loss: 2.6553937392055813

Epoch: 278| Step: 0
Training loss: 1.8118690181658434
Validation loss: 2.640191571179863

Epoch: 6| Step: 1
Training loss: 1.7339852384843113
Validation loss: 2.638642072568136

Epoch: 6| Step: 2
Training loss: 2.2510004998049356
Validation loss: 2.622312888557638

Epoch: 6| Step: 3
Training loss: 1.9350251419444853
Validation loss: 2.604210156395486

Epoch: 6| Step: 4
Training loss: 1.6810136394911837
Validation loss: 2.5955348480536604

Epoch: 6| Step: 5
Training loss: 2.3085660723013026
Validation loss: 2.594728323644295

Epoch: 6| Step: 6
Training loss: 1.8317234455827147
Validation loss: 2.553452655089148

Epoch: 6| Step: 7
Training loss: 1.731821121594704
Validation loss: 2.5551949248886743

Epoch: 6| Step: 8
Training loss: 2.0057992304000267
Validation loss: 2.5356428857802045

Epoch: 6| Step: 9
Training loss: 3.073594685555768
Validation loss: 2.5483572065691753

Epoch: 6| Step: 10
Training loss: 2.5293854804702023
Validation loss: 2.570219863412647

Epoch: 6| Step: 11
Training loss: 2.1783319448842664
Validation loss: 2.6266057840139774

Epoch: 6| Step: 12
Training loss: 1.7965558639406463
Validation loss: 2.6512186382308682

Epoch: 6| Step: 13
Training loss: 1.8541510149120117
Validation loss: 2.722340314167754

Epoch: 279| Step: 0
Training loss: 1.8484556634160496
Validation loss: 2.7530426763609355

Epoch: 6| Step: 1
Training loss: 2.4896207883775943
Validation loss: 2.7453057509230603

Epoch: 6| Step: 2
Training loss: 1.7533548078684447
Validation loss: 2.723893689372591

Epoch: 6| Step: 3
Training loss: 2.3068804119649164
Validation loss: 2.6427100713230702

Epoch: 6| Step: 4
Training loss: 2.7152602500599126
Validation loss: 2.6252190104961866

Epoch: 6| Step: 5
Training loss: 1.8010955337696934
Validation loss: 2.603438746124984

Epoch: 6| Step: 6
Training loss: 2.01314540015386
Validation loss: 2.5847610302179453

Epoch: 6| Step: 7
Training loss: 2.0595957798330606
Validation loss: 2.5546850113074013

Epoch: 6| Step: 8
Training loss: 1.733116036635069
Validation loss: 2.5434572499719943

Epoch: 6| Step: 9
Training loss: 2.217342736345648
Validation loss: 2.5244280167273296

Epoch: 6| Step: 10
Training loss: 2.060897782805614
Validation loss: 2.5492647812779445

Epoch: 6| Step: 11
Training loss: 2.2677366741782623
Validation loss: 2.5451652232899944

Epoch: 6| Step: 12
Training loss: 1.771683485119366
Validation loss: 2.572954144121238

Epoch: 6| Step: 13
Training loss: 1.5314343399882715
Validation loss: 2.606333118823971

Epoch: 280| Step: 0
Training loss: 2.21276090128925
Validation loss: 2.6076341254513498

Epoch: 6| Step: 1
Training loss: 2.679320819112055
Validation loss: 2.6374684339445302

Epoch: 6| Step: 2
Training loss: 2.3877228717734678
Validation loss: 2.64474017671693

Epoch: 6| Step: 3
Training loss: 2.1658811123274555
Validation loss: 2.648547640060362

Epoch: 6| Step: 4
Training loss: 2.182815440345919
Validation loss: 2.6864788717781756

Epoch: 6| Step: 5
Training loss: 2.2342633839718897
Validation loss: 2.701616090265438

Epoch: 6| Step: 6
Training loss: 2.0780469836741955
Validation loss: 2.7253070844921536

Epoch: 6| Step: 7
Training loss: 2.074070927009516
Validation loss: 2.679691392545403

Epoch: 6| Step: 8
Training loss: 1.830808967887746
Validation loss: 2.6678440405545243

Epoch: 6| Step: 9
Training loss: 1.8551566734882168
Validation loss: 2.616832895121659

Epoch: 6| Step: 10
Training loss: 1.9122053206065839
Validation loss: 2.5657950050321836

Epoch: 6| Step: 11
Training loss: 1.6908579018983918
Validation loss: 2.5392801983746387

Epoch: 6| Step: 12
Training loss: 1.9819713061706739
Validation loss: 2.5219741373220885

Epoch: 6| Step: 13
Training loss: 1.8721058443664413
Validation loss: 2.519658868598537

Epoch: 281| Step: 0
Training loss: 2.1029852266613545
Validation loss: 2.5241521211215336

Epoch: 6| Step: 1
Training loss: 2.312619799011033
Validation loss: 2.5128492754682914

Epoch: 6| Step: 2
Training loss: 2.896145060568104
Validation loss: 2.5247287812312567

Epoch: 6| Step: 3
Training loss: 1.9007562362084922
Validation loss: 2.5546493294107013

Epoch: 6| Step: 4
Training loss: 2.5173692046872107
Validation loss: 2.548491341470209

Epoch: 6| Step: 5
Training loss: 2.4038407786382585
Validation loss: 2.5806241647637838

Epoch: 6| Step: 6
Training loss: 2.455032481738105
Validation loss: 2.5936717592258103

Epoch: 6| Step: 7
Training loss: 1.3533509609800076
Validation loss: 2.6247393160761616

Epoch: 6| Step: 8
Training loss: 1.6559823737657657
Validation loss: 2.6711801142127256

Epoch: 6| Step: 9
Training loss: 1.417194922447745
Validation loss: 2.6686922714815045

Epoch: 6| Step: 10
Training loss: 1.7041635409126747
Validation loss: 2.6755147313949474

Epoch: 6| Step: 11
Training loss: 2.1151631379394016
Validation loss: 2.698852823409181

Epoch: 6| Step: 12
Training loss: 2.5694239045659595
Validation loss: 2.6665500128582664

Epoch: 6| Step: 13
Training loss: 1.7577658413946462
Validation loss: 2.599240195382045

Epoch: 282| Step: 0
Training loss: 2.154988901415079
Validation loss: 2.5661981692796014

Epoch: 6| Step: 1
Training loss: 2.383754156436107
Validation loss: 2.55565366061422

Epoch: 6| Step: 2
Training loss: 2.4949673542340887
Validation loss: 2.5145872514805347

Epoch: 6| Step: 3
Training loss: 1.6422293674928399
Validation loss: 2.518392332064626

Epoch: 6| Step: 4
Training loss: 2.0422630477042047
Validation loss: 2.540296245042256

Epoch: 6| Step: 5
Training loss: 2.2245612536978743
Validation loss: 2.534839142029001

Epoch: 6| Step: 6
Training loss: 1.798089852359159
Validation loss: 2.5199931507421187

Epoch: 6| Step: 7
Training loss: 2.3163327596241663
Validation loss: 2.5415397883363977

Epoch: 6| Step: 8
Training loss: 1.9303212843193776
Validation loss: 2.5386094065631246

Epoch: 6| Step: 9
Training loss: 2.060258398608501
Validation loss: 2.5499113428997413

Epoch: 6| Step: 10
Training loss: 1.7826662289446054
Validation loss: 2.5489305029876097

Epoch: 6| Step: 11
Training loss: 2.3944575685798846
Validation loss: 2.5551836968742845

Epoch: 6| Step: 12
Training loss: 1.8936863853924448
Validation loss: 2.5576167835508623

Epoch: 6| Step: 13
Training loss: 2.4743658004632123
Validation loss: 2.552343056885643

Epoch: 283| Step: 0
Training loss: 1.9721041369420556
Validation loss: 2.5529276534609324

Epoch: 6| Step: 1
Training loss: 2.147115182559551
Validation loss: 2.5639382489753366

Epoch: 6| Step: 2
Training loss: 1.2860119414538933
Validation loss: 2.612662355649947

Epoch: 6| Step: 3
Training loss: 1.5564391270199982
Validation loss: 2.614983156999718

Epoch: 6| Step: 4
Training loss: 2.244039588028237
Validation loss: 2.647501357128935

Epoch: 6| Step: 5
Training loss: 1.835887307637537
Validation loss: 2.635598765679813

Epoch: 6| Step: 6
Training loss: 2.3438332097859287
Validation loss: 2.6910795577324222

Epoch: 6| Step: 7
Training loss: 2.2521903714537097
Validation loss: 2.7110075634670623

Epoch: 6| Step: 8
Training loss: 1.1268733110378173
Validation loss: 2.707126030448462

Epoch: 6| Step: 9
Training loss: 1.7267246083930061
Validation loss: 2.7045533921057525

Epoch: 6| Step: 10
Training loss: 1.7888954451080818
Validation loss: 2.687720999391561

Epoch: 6| Step: 11
Training loss: 2.8451175964401263
Validation loss: 2.699800950236598

Epoch: 6| Step: 12
Training loss: 2.3513738106593842
Validation loss: 2.6672902470892073

Epoch: 6| Step: 13
Training loss: 2.5388444542793285
Validation loss: 2.649619574801113

Epoch: 284| Step: 0
Training loss: 2.3344018283512624
Validation loss: 2.6033978408151204

Epoch: 6| Step: 1
Training loss: 1.4834129026409604
Validation loss: 2.6082377439620648

Epoch: 6| Step: 2
Training loss: 2.8183939740653887
Validation loss: 2.6039639254169487

Epoch: 6| Step: 3
Training loss: 2.3858792940545714
Validation loss: 2.6033984513468584

Epoch: 6| Step: 4
Training loss: 2.7138605107420566
Validation loss: 2.6200898432433326

Epoch: 6| Step: 5
Training loss: 1.5263383683249832
Validation loss: 2.6308529406994907

Epoch: 6| Step: 6
Training loss: 1.230636246195369
Validation loss: 2.635542355180122

Epoch: 6| Step: 7
Training loss: 1.4860659153721725
Validation loss: 2.650672846971454

Epoch: 6| Step: 8
Training loss: 2.4801232765691266
Validation loss: 2.633247890373903

Epoch: 6| Step: 9
Training loss: 1.8461594436328346
Validation loss: 2.640205199450159

Epoch: 6| Step: 10
Training loss: 1.5667937220463477
Validation loss: 2.65364076703118

Epoch: 6| Step: 11
Training loss: 1.8043750310778244
Validation loss: 2.696091588153118

Epoch: 6| Step: 12
Training loss: 1.7900207485296438
Validation loss: 2.6602762412757133

Epoch: 6| Step: 13
Training loss: 2.107647676011408
Validation loss: 2.657984642151877

Epoch: 285| Step: 0
Training loss: 2.2512168772546723
Validation loss: 2.61821504225727

Epoch: 6| Step: 1
Training loss: 1.2638945346515211
Validation loss: 2.6066466666167374

Epoch: 6| Step: 2
Training loss: 1.5959907188528093
Validation loss: 2.6059398082316254

Epoch: 6| Step: 3
Training loss: 2.4127181671006297
Validation loss: 2.6010822696798703

Epoch: 6| Step: 4
Training loss: 2.0764030263271334
Validation loss: 2.59771622896862

Epoch: 6| Step: 5
Training loss: 2.2758654446910667
Validation loss: 2.6009813180770993

Epoch: 6| Step: 6
Training loss: 1.933338495225702
Validation loss: 2.6420735556263084

Epoch: 6| Step: 7
Training loss: 2.334436859577697
Validation loss: 2.67765581315773

Epoch: 6| Step: 8
Training loss: 1.9956313939623813
Validation loss: 2.696164668169366

Epoch: 6| Step: 9
Training loss: 2.3949145559467553
Validation loss: 2.7306216246704187

Epoch: 6| Step: 10
Training loss: 2.0057179253467146
Validation loss: 2.713592160292669

Epoch: 6| Step: 11
Training loss: 1.9275958505193596
Validation loss: 2.719917470554166

Epoch: 6| Step: 12
Training loss: 1.6834400221878512
Validation loss: 2.6950221103381673

Epoch: 6| Step: 13
Training loss: 2.2209502580028553
Validation loss: 2.6089327012848718

Epoch: 286| Step: 0
Training loss: 2.301428401067845
Validation loss: 2.595560185209301

Epoch: 6| Step: 1
Training loss: 1.6280840438406716
Validation loss: 2.575983433438671

Epoch: 6| Step: 2
Training loss: 1.9395861315954601
Validation loss: 2.5659609582011678

Epoch: 6| Step: 3
Training loss: 2.5004373167923086
Validation loss: 2.5580607939031

Epoch: 6| Step: 4
Training loss: 1.698827799404286
Validation loss: 2.5395129307998947

Epoch: 6| Step: 5
Training loss: 1.9975473743497565
Validation loss: 2.5307908289252867

Epoch: 6| Step: 6
Training loss: 2.1779030773010613
Validation loss: 2.5507698311971234

Epoch: 6| Step: 7
Training loss: 2.1914445462340018
Validation loss: 2.5542156549789183

Epoch: 6| Step: 8
Training loss: 2.287780194241371
Validation loss: 2.582411729843376

Epoch: 6| Step: 9
Training loss: 1.7912410481902088
Validation loss: 2.605548825003366

Epoch: 6| Step: 10
Training loss: 1.495761764783592
Validation loss: 2.631217314818427

Epoch: 6| Step: 11
Training loss: 2.050173017132213
Validation loss: 2.6453851535506545

Epoch: 6| Step: 12
Training loss: 2.201236646049584
Validation loss: 2.6837807284335584

Epoch: 6| Step: 13
Training loss: 1.8649759642864927
Validation loss: 2.681818923523952

Epoch: 287| Step: 0
Training loss: 1.9873833868016644
Validation loss: 2.7217733300685083

Epoch: 6| Step: 1
Training loss: 1.9769945840910927
Validation loss: 2.7367672582609357

Epoch: 6| Step: 2
Training loss: 1.8227215980427613
Validation loss: 2.660161896418154

Epoch: 6| Step: 3
Training loss: 1.9225127239823152
Validation loss: 2.6112262760178484

Epoch: 6| Step: 4
Training loss: 1.1599923477249303
Validation loss: 2.6086685838654113

Epoch: 6| Step: 5
Training loss: 2.0323905677004444
Validation loss: 2.5711816402355456

Epoch: 6| Step: 6
Training loss: 2.6487995451631563
Validation loss: 2.5380183493820385

Epoch: 6| Step: 7
Training loss: 2.3026062959702736
Validation loss: 2.563783587764725

Epoch: 6| Step: 8
Training loss: 2.34682882901019
Validation loss: 2.5608018350034714

Epoch: 6| Step: 9
Training loss: 2.080267468641681
Validation loss: 2.588100208936625

Epoch: 6| Step: 10
Training loss: 2.069728668231978
Validation loss: 2.5975076962780133

Epoch: 6| Step: 11
Training loss: 1.9707089925930055
Validation loss: 2.5973960344584643

Epoch: 6| Step: 12
Training loss: 2.1183633952355017
Validation loss: 2.611337681222386

Epoch: 6| Step: 13
Training loss: 1.8258391214845122
Validation loss: 2.6679471984558796

Epoch: 288| Step: 0
Training loss: 1.9354506082778578
Validation loss: 2.636376493870066

Epoch: 6| Step: 1
Training loss: 2.2432653514694314
Validation loss: 2.678204006244887

Epoch: 6| Step: 2
Training loss: 1.8828659366606566
Validation loss: 2.6574857193571213

Epoch: 6| Step: 3
Training loss: 1.8106478731858957
Validation loss: 2.6500970222897946

Epoch: 6| Step: 4
Training loss: 1.6513718075408466
Validation loss: 2.6266125539790597

Epoch: 6| Step: 5
Training loss: 1.2950067506709946
Validation loss: 2.6323221204651794

Epoch: 6| Step: 6
Training loss: 2.036224143635115
Validation loss: 2.6257274618771436

Epoch: 6| Step: 7
Training loss: 2.3898433828712125
Validation loss: 2.6213876603991513

Epoch: 6| Step: 8
Training loss: 1.4849140995239718
Validation loss: 2.6376460651130036

Epoch: 6| Step: 9
Training loss: 2.011215472923732
Validation loss: 2.586683951185753

Epoch: 6| Step: 10
Training loss: 1.7516312489557029
Validation loss: 2.589212285959675

Epoch: 6| Step: 11
Training loss: 1.797552760468037
Validation loss: 2.555621506236204

Epoch: 6| Step: 12
Training loss: 3.143590333801079
Validation loss: 2.549107390362299

Epoch: 6| Step: 13
Training loss: 2.0134516391142245
Validation loss: 2.5675295960361995

Epoch: 289| Step: 0
Training loss: 1.9422423866722778
Validation loss: 2.5573204463626413

Epoch: 6| Step: 1
Training loss: 2.1432630336182292
Validation loss: 2.5946927406404825

Epoch: 6| Step: 2
Training loss: 1.51665375393132
Validation loss: 2.573829231642146

Epoch: 6| Step: 3
Training loss: 2.0953825094771954
Validation loss: 2.581760571210386

Epoch: 6| Step: 4
Training loss: 2.130818870991648
Validation loss: 2.5970057464137475

Epoch: 6| Step: 5
Training loss: 1.3142665600269428
Validation loss: 2.633581424647704

Epoch: 6| Step: 6
Training loss: 1.9926370150985955
Validation loss: 2.614820558239784

Epoch: 6| Step: 7
Training loss: 2.1895755185738826
Validation loss: 2.650808212903161

Epoch: 6| Step: 8
Training loss: 2.006702398233401
Validation loss: 2.670567941994252

Epoch: 6| Step: 9
Training loss: 2.0644919284432723
Validation loss: 2.686531646505202

Epoch: 6| Step: 10
Training loss: 1.7219078877764677
Validation loss: 2.6870210649615607

Epoch: 6| Step: 11
Training loss: 2.1438965683370874
Validation loss: 2.6697315593794304

Epoch: 6| Step: 12
Training loss: 1.743597785568319
Validation loss: 2.629300470065875

Epoch: 6| Step: 13
Training loss: 2.525854789401951
Validation loss: 2.635116700803869

Epoch: 290| Step: 0
Training loss: 1.9028471294427634
Validation loss: 2.6270536155340807

Epoch: 6| Step: 1
Training loss: 2.2953072731576594
Validation loss: 2.598040773618473

Epoch: 6| Step: 2
Training loss: 1.9160850582316062
Validation loss: 2.5926131625784916

Epoch: 6| Step: 3
Training loss: 2.420171717076439
Validation loss: 2.529534783091956

Epoch: 6| Step: 4
Training loss: 2.0114719869136093
Validation loss: 2.5773546088942836

Epoch: 6| Step: 5
Training loss: 2.217295317552003
Validation loss: 2.628024599120828

Epoch: 6| Step: 6
Training loss: 2.0838542922659595
Validation loss: 2.671691204092423

Epoch: 6| Step: 7
Training loss: 1.7983881674329765
Validation loss: 2.6683337146759554

Epoch: 6| Step: 8
Training loss: 1.8407510192942877
Validation loss: 2.635273508598964

Epoch: 6| Step: 9
Training loss: 1.3572650187587685
Validation loss: 2.668882929210942

Epoch: 6| Step: 10
Training loss: 2.2347918568408334
Validation loss: 2.6610150101744976

Epoch: 6| Step: 11
Training loss: 1.9265905076564387
Validation loss: 2.6333359557352005

Epoch: 6| Step: 12
Training loss: 1.9651610950508211
Validation loss: 2.6027623980744146

Epoch: 6| Step: 13
Training loss: 1.9424551082023986
Validation loss: 2.559299889884162

Epoch: 291| Step: 0
Training loss: 2.113393840505231
Validation loss: 2.553725626351955

Epoch: 6| Step: 1
Training loss: 2.3980935312949883
Validation loss: 2.556437710412088

Epoch: 6| Step: 2
Training loss: 2.0344357670440893
Validation loss: 2.5307558778330725

Epoch: 6| Step: 3
Training loss: 1.558812176306362
Validation loss: 2.5477049631754727

Epoch: 6| Step: 4
Training loss: 2.2181153800198965
Validation loss: 2.532730768302107

Epoch: 6| Step: 5
Training loss: 1.9052471587276658
Validation loss: 2.5212872519488942

Epoch: 6| Step: 6
Training loss: 2.4549310923926146
Validation loss: 2.5629681725541964

Epoch: 6| Step: 7
Training loss: 1.4339417079479215
Validation loss: 2.5948655667087204

Epoch: 6| Step: 8
Training loss: 1.6902738308692864
Validation loss: 2.640271887409512

Epoch: 6| Step: 9
Training loss: 1.995772304146026
Validation loss: 2.67460601317637

Epoch: 6| Step: 10
Training loss: 2.291958796059225
Validation loss: 2.6993571575800166

Epoch: 6| Step: 11
Training loss: 1.5149385136380156
Validation loss: 2.7156977126875086

Epoch: 6| Step: 12
Training loss: 2.1347505476437485
Validation loss: 2.686628998956964

Epoch: 6| Step: 13
Training loss: 2.220454998128122
Validation loss: 2.6857685751292903

Epoch: 292| Step: 0
Training loss: 2.2130377940222794
Validation loss: 2.6282521946231223

Epoch: 6| Step: 1
Training loss: 1.4843649612890397
Validation loss: 2.6098816507309763

Epoch: 6| Step: 2
Training loss: 2.1329049450189017
Validation loss: 2.5902164703104695

Epoch: 6| Step: 3
Training loss: 2.121918632047486
Validation loss: 2.5567164554331927

Epoch: 6| Step: 4
Training loss: 1.3798696378280078
Validation loss: 2.5210468947898557

Epoch: 6| Step: 5
Training loss: 1.9604687985479279
Validation loss: 2.5125174352569157

Epoch: 6| Step: 6
Training loss: 2.0685818330116224
Validation loss: 2.517174064147313

Epoch: 6| Step: 7
Training loss: 1.7323950385904094
Validation loss: 2.5289720088535455

Epoch: 6| Step: 8
Training loss: 1.4388776066033788
Validation loss: 2.5530232210389516

Epoch: 6| Step: 9
Training loss: 2.1485056363485264
Validation loss: 2.5819926525930383

Epoch: 6| Step: 10
Training loss: 2.104000676724285
Validation loss: 2.619328275212373

Epoch: 6| Step: 11
Training loss: 2.1631300256511476
Validation loss: 2.666333853298282

Epoch: 6| Step: 12
Training loss: 1.9508762689379668
Validation loss: 2.708820729537361

Epoch: 6| Step: 13
Training loss: 2.5855862012962354
Validation loss: 2.708604378464389

Epoch: 293| Step: 0
Training loss: 1.9963512515842867
Validation loss: 2.729922609734415

Epoch: 6| Step: 1
Training loss: 1.2850917347770536
Validation loss: 2.6701866600901347

Epoch: 6| Step: 2
Training loss: 2.344597319981619
Validation loss: 2.6375006978544784

Epoch: 6| Step: 3
Training loss: 1.230358300474454
Validation loss: 2.6251686132864314

Epoch: 6| Step: 4
Training loss: 2.9113054502651647
Validation loss: 2.6098187615570647

Epoch: 6| Step: 5
Training loss: 1.8479956542991967
Validation loss: 2.6048807665530425

Epoch: 6| Step: 6
Training loss: 2.4022772554948912
Validation loss: 2.592866877460384

Epoch: 6| Step: 7
Training loss: 1.1752379927160777
Validation loss: 2.5440861541556807

Epoch: 6| Step: 8
Training loss: 2.0507312586912834
Validation loss: 2.5253732222891454

Epoch: 6| Step: 9
Training loss: 2.4305292860761076
Validation loss: 2.5540106884955005

Epoch: 6| Step: 10
Training loss: 2.637594978828036
Validation loss: 2.5666827125997296

Epoch: 6| Step: 11
Training loss: 1.6184201173204258
Validation loss: 2.581266596804658

Epoch: 6| Step: 12
Training loss: 1.689017849454637
Validation loss: 2.594860727643567

Epoch: 6| Step: 13
Training loss: 1.7773366403961512
Validation loss: 2.6095069730053595

Epoch: 294| Step: 0
Training loss: 2.1680397915584395
Validation loss: 2.5990583952228863

Epoch: 6| Step: 1
Training loss: 2.0551561176558417
Validation loss: 2.6099535135170573

Epoch: 6| Step: 2
Training loss: 1.7069584811345409
Validation loss: 2.588009191711942

Epoch: 6| Step: 3
Training loss: 1.8352870357025814
Validation loss: 2.619629846710766

Epoch: 6| Step: 4
Training loss: 2.6015375726095558
Validation loss: 2.6279836380021964

Epoch: 6| Step: 5
Training loss: 1.9122411664952492
Validation loss: 2.644641838221947

Epoch: 6| Step: 6
Training loss: 2.165933619495593
Validation loss: 2.6265316536457637

Epoch: 6| Step: 7
Training loss: 1.5509100795630082
Validation loss: 2.6393215265381738

Epoch: 6| Step: 8
Training loss: 1.9025237763932994
Validation loss: 2.637464991332657

Epoch: 6| Step: 9
Training loss: 1.5126403049936425
Validation loss: 2.6026973902844475

Epoch: 6| Step: 10
Training loss: 1.3603930114434235
Validation loss: 2.624147110090151

Epoch: 6| Step: 11
Training loss: 2.6007384865368537
Validation loss: 2.6067778860041853

Epoch: 6| Step: 12
Training loss: 2.034574048314524
Validation loss: 2.6058433069034805

Epoch: 6| Step: 13
Training loss: 1.7131140812188737
Validation loss: 2.5941615946256826

Epoch: 295| Step: 0
Training loss: 1.5519601487126333
Validation loss: 2.5736530552608596

Epoch: 6| Step: 1
Training loss: 1.8648217828397275
Validation loss: 2.5603782584711228

Epoch: 6| Step: 2
Training loss: 2.073546104777735
Validation loss: 2.5589211446168614

Epoch: 6| Step: 3
Training loss: 2.525150438114019
Validation loss: 2.5975743178064237

Epoch: 6| Step: 4
Training loss: 1.5787190744930566
Validation loss: 2.6148509512996756

Epoch: 6| Step: 5
Training loss: 1.5401311736780765
Validation loss: 2.6212563234518846

Epoch: 6| Step: 6
Training loss: 1.9690787025829979
Validation loss: 2.636921288517338

Epoch: 6| Step: 7
Training loss: 1.6441625331253757
Validation loss: 2.6107078467987894

Epoch: 6| Step: 8
Training loss: 1.8444742622927146
Validation loss: 2.618286539732481

Epoch: 6| Step: 9
Training loss: 1.8501914054211623
Validation loss: 2.6219681078777497

Epoch: 6| Step: 10
Training loss: 1.5987029063168727
Validation loss: 2.624596534482228

Epoch: 6| Step: 11
Training loss: 2.5213198441915035
Validation loss: 2.621019251485287

Epoch: 6| Step: 12
Training loss: 1.8267177806209205
Validation loss: 2.6715211987252587

Epoch: 6| Step: 13
Training loss: 2.5667525570192473
Validation loss: 2.6670342778102216

Epoch: 296| Step: 0
Training loss: 2.4405224962969796
Validation loss: 2.6588715874340663

Epoch: 6| Step: 1
Training loss: 1.9779767792961611
Validation loss: 2.6527780318690026

Epoch: 6| Step: 2
Training loss: 1.7274591525557932
Validation loss: 2.6317132603935858

Epoch: 6| Step: 3
Training loss: 1.779226190731188
Validation loss: 2.6210119288674094

Epoch: 6| Step: 4
Training loss: 2.06674381952964
Validation loss: 2.6211561791555478

Epoch: 6| Step: 5
Training loss: 1.7977156289848886
Validation loss: 2.597513723646178

Epoch: 6| Step: 6
Training loss: 2.0042633868676014
Validation loss: 2.6016825055461545

Epoch: 6| Step: 7
Training loss: 1.2747138712091683
Validation loss: 2.5881191090419495

Epoch: 6| Step: 8
Training loss: 1.579752017249745
Validation loss: 2.6097322169986548

Epoch: 6| Step: 9
Training loss: 1.5730081072705697
Validation loss: 2.578454306792777

Epoch: 6| Step: 10
Training loss: 1.7902181299593307
Validation loss: 2.5941803203713207

Epoch: 6| Step: 11
Training loss: 2.2483001221658676
Validation loss: 2.5947828266407202

Epoch: 6| Step: 12
Training loss: 2.6615300377271027
Validation loss: 2.6325322274617022

Epoch: 6| Step: 13
Training loss: 1.7790777781286302
Validation loss: 2.6275778933907508

Epoch: 297| Step: 0
Training loss: 1.7378202019808728
Validation loss: 2.6220258257908515

Epoch: 6| Step: 1
Training loss: 1.702390880028597
Validation loss: 2.6420078005178627

Epoch: 6| Step: 2
Training loss: 1.4086246362263055
Validation loss: 2.6415042955656194

Epoch: 6| Step: 3
Training loss: 2.572112036126245
Validation loss: 2.6654944724428318

Epoch: 6| Step: 4
Training loss: 1.7805724612164298
Validation loss: 2.646772823590968

Epoch: 6| Step: 5
Training loss: 1.9957054044091138
Validation loss: 2.6275253410097332

Epoch: 6| Step: 6
Training loss: 2.225856093396593
Validation loss: 2.6777534289416

Epoch: 6| Step: 7
Training loss: 1.1131429485949471
Validation loss: 2.645095426932869

Epoch: 6| Step: 8
Training loss: 1.686311303135021
Validation loss: 2.660484349747287

Epoch: 6| Step: 9
Training loss: 2.578332141299754
Validation loss: 2.6398963449579984

Epoch: 6| Step: 10
Training loss: 1.73021274162648
Validation loss: 2.6409579637064375

Epoch: 6| Step: 11
Training loss: 1.5491268836719243
Validation loss: 2.6395162628572724

Epoch: 6| Step: 12
Training loss: 2.1425886962407286
Validation loss: 2.619355688100512

Epoch: 6| Step: 13
Training loss: 2.168171311271776
Validation loss: 2.628083174376844

Epoch: 298| Step: 0
Training loss: 1.6926953907007198
Validation loss: 2.597923613056929

Epoch: 6| Step: 1
Training loss: 1.9056894697704796
Validation loss: 2.602917231602488

Epoch: 6| Step: 2
Training loss: 2.104615896886007
Validation loss: 2.615867228592714

Epoch: 6| Step: 3
Training loss: 1.8913118990433309
Validation loss: 2.629151996464817

Epoch: 6| Step: 4
Training loss: 2.3031407225032057
Validation loss: 2.6587812144066203

Epoch: 6| Step: 5
Training loss: 1.972023679324157
Validation loss: 2.6753771103142436

Epoch: 6| Step: 6
Training loss: 1.565738602283843
Validation loss: 2.663487675347973

Epoch: 6| Step: 7
Training loss: 2.3961597275582287
Validation loss: 2.6488775377231253

Epoch: 6| Step: 8
Training loss: 1.608055759189107
Validation loss: 2.6513487082833236

Epoch: 6| Step: 9
Training loss: 1.5447544243461047
Validation loss: 2.6241224426665077

Epoch: 6| Step: 10
Training loss: 2.4379836360704545
Validation loss: 2.5877096935817665

Epoch: 6| Step: 11
Training loss: 1.682982296112202
Validation loss: 2.5905812988767374

Epoch: 6| Step: 12
Training loss: 1.9149870216188802
Validation loss: 2.599100362582877

Epoch: 6| Step: 13
Training loss: 1.5304581287866441
Validation loss: 2.5565502441221906

Epoch: 299| Step: 0
Training loss: 2.2275656063466713
Validation loss: 2.5624141523666113

Epoch: 6| Step: 1
Training loss: 2.1950805107071423
Validation loss: 2.546591526474154

Epoch: 6| Step: 2
Training loss: 1.7795756987301738
Validation loss: 2.545183435223412

Epoch: 6| Step: 3
Training loss: 2.438871535768327
Validation loss: 2.577489570377041

Epoch: 6| Step: 4
Training loss: 1.766616745309446
Validation loss: 2.5728743133971506

Epoch: 6| Step: 5
Training loss: 1.7090089283950463
Validation loss: 2.5657535924989494

Epoch: 6| Step: 6
Training loss: 1.4026065250815551
Validation loss: 2.5518544671855694

Epoch: 6| Step: 7
Training loss: 1.7479476474324604
Validation loss: 2.563349776750595

Epoch: 6| Step: 8
Training loss: 2.2718059545044498
Validation loss: 2.58250960681528

Epoch: 6| Step: 9
Training loss: 1.812992094915865
Validation loss: 2.552228874156725

Epoch: 6| Step: 10
Training loss: 1.8430603806637647
Validation loss: 2.551665810406934

Epoch: 6| Step: 11
Training loss: 2.3684438260974545
Validation loss: 2.5503083161105233

Epoch: 6| Step: 12
Training loss: 1.472084318855849
Validation loss: 2.5445174244470037

Epoch: 6| Step: 13
Training loss: 1.4796241625852504
Validation loss: 2.558014627003749

Epoch: 300| Step: 0
Training loss: 1.6827231012398227
Validation loss: 2.610177957794098

Epoch: 6| Step: 1
Training loss: 1.0331595110566738
Validation loss: 2.564689971995767

Epoch: 6| Step: 2
Training loss: 2.032025233299796
Validation loss: 2.6141734517521877

Epoch: 6| Step: 3
Training loss: 2.637382728898369
Validation loss: 2.6341507677103086

Epoch: 6| Step: 4
Training loss: 1.6753421377083988
Validation loss: 2.646451680074122

Epoch: 6| Step: 5
Training loss: 2.1007435844565845
Validation loss: 2.653616433671757

Epoch: 6| Step: 6
Training loss: 1.6825935951035738
Validation loss: 2.623598239163223

Epoch: 6| Step: 7
Training loss: 2.2443279191520347
Validation loss: 2.6916715789214702

Epoch: 6| Step: 8
Training loss: 1.7547978978742917
Validation loss: 2.6835249401971346

Epoch: 6| Step: 9
Training loss: 2.0854086902121614
Validation loss: 2.6772343980096682

Epoch: 6| Step: 10
Training loss: 2.0241123090501767
Validation loss: 2.739437249257004

Epoch: 6| Step: 11
Training loss: 1.95192419140991
Validation loss: 2.6507659398993515

Epoch: 6| Step: 12
Training loss: 1.5300662077497353
Validation loss: 2.656220379832553

Epoch: 6| Step: 13
Training loss: 1.9197550921406743
Validation loss: 2.6263010494373247

Epoch: 301| Step: 0
Training loss: 2.2050934783428073
Validation loss: 2.6001992840076222

Epoch: 6| Step: 1
Training loss: 2.3659844189708834
Validation loss: 2.600489382659023

Epoch: 6| Step: 2
Training loss: 1.9818696554226782
Validation loss: 2.5651039446267485

Epoch: 6| Step: 3
Training loss: 1.480989228806359
Validation loss: 2.5857138176837067

Epoch: 6| Step: 4
Training loss: 1.9949581850301827
Validation loss: 2.568613544066606

Epoch: 6| Step: 5
Training loss: 1.7010773414597609
Validation loss: 2.53893728094173

Epoch: 6| Step: 6
Training loss: 1.6367223917117153
Validation loss: 2.5830222962904217

Epoch: 6| Step: 7
Training loss: 1.9511227529946489
Validation loss: 2.5677346208218483

Epoch: 6| Step: 8
Training loss: 1.9738680601656893
Validation loss: 2.5626721828267685

Epoch: 6| Step: 9
Training loss: 1.7776560750007124
Validation loss: 2.563764446260622

Epoch: 6| Step: 10
Training loss: 1.9435638166843239
Validation loss: 2.541481337018045

Epoch: 6| Step: 11
Training loss: 1.8823883718599166
Validation loss: 2.5326136930501457

Epoch: 6| Step: 12
Training loss: 1.529705903952747
Validation loss: 2.586201511209369

Epoch: 6| Step: 13
Training loss: 2.2331300481637246
Validation loss: 2.6084637145178498

Epoch: 302| Step: 0
Training loss: 1.7906845935005609
Validation loss: 2.6127820642964146

Epoch: 6| Step: 1
Training loss: 1.6361125105524617
Validation loss: 2.6670831240861648

Epoch: 6| Step: 2
Training loss: 1.8637739445806734
Validation loss: 2.687200322557373

Epoch: 6| Step: 3
Training loss: 2.532768076860681
Validation loss: 2.77107440406507

Epoch: 6| Step: 4
Training loss: 2.0501979034544098
Validation loss: 2.7900673047359743

Epoch: 6| Step: 5
Training loss: 1.7256434829866063
Validation loss: 2.7345475641930137

Epoch: 6| Step: 6
Training loss: 1.8219502166872705
Validation loss: 2.6745252422658936

Epoch: 6| Step: 7
Training loss: 1.5636558072562785
Validation loss: 2.608160288212671

Epoch: 6| Step: 8
Training loss: 2.9349851191336787
Validation loss: 2.5811745688783256

Epoch: 6| Step: 9
Training loss: 2.03778948453376
Validation loss: 2.5591471376939916

Epoch: 6| Step: 10
Training loss: 1.76053676157963
Validation loss: 2.555587547788457

Epoch: 6| Step: 11
Training loss: 2.11751528521609
Validation loss: 2.550132244395941

Epoch: 6| Step: 12
Training loss: 1.4053140704634164
Validation loss: 2.5494563589092216

Epoch: 6| Step: 13
Training loss: 1.5069003335539124
Validation loss: 2.5377655159729557

Epoch: 303| Step: 0
Training loss: 2.0325801308989986
Validation loss: 2.5899584607189388

Epoch: 6| Step: 1
Training loss: 2.02415070796668
Validation loss: 2.6114055933050215

Epoch: 6| Step: 2
Training loss: 2.300478023113166
Validation loss: 2.6062578400906378

Epoch: 6| Step: 3
Training loss: 2.1543125902503633
Validation loss: 2.6387863228480133

Epoch: 6| Step: 4
Training loss: 1.716588204019696
Validation loss: 2.636792518619885

Epoch: 6| Step: 5
Training loss: 1.9448736224267384
Validation loss: 2.628207230462718

Epoch: 6| Step: 6
Training loss: 1.3920444145269526
Validation loss: 2.615646926137767

Epoch: 6| Step: 7
Training loss: 1.920628213032531
Validation loss: 2.6014149636408264

Epoch: 6| Step: 8
Training loss: 1.6150810048955029
Validation loss: 2.55218624504354

Epoch: 6| Step: 9
Training loss: 1.3671540174471475
Validation loss: 2.56030682006638

Epoch: 6| Step: 10
Training loss: 2.14839455301535
Validation loss: 2.5578982740222433

Epoch: 6| Step: 11
Training loss: 1.4893924439657715
Validation loss: 2.547526067663411

Epoch: 6| Step: 12
Training loss: 2.0780784200166194
Validation loss: 2.566700648004412

Epoch: 6| Step: 13
Training loss: 2.080881112430752
Validation loss: 2.5529842317669247

Epoch: 304| Step: 0
Training loss: 1.9055194392858064
Validation loss: 2.58870908066604

Epoch: 6| Step: 1
Training loss: 1.4715826436671282
Validation loss: 2.633281239666312

Epoch: 6| Step: 2
Training loss: 1.3918509919006363
Validation loss: 2.6529704773457645

Epoch: 6| Step: 3
Training loss: 2.0153464191342967
Validation loss: 2.6507952387603946

Epoch: 6| Step: 4
Training loss: 1.535087913952961
Validation loss: 2.6399222723639864

Epoch: 6| Step: 5
Training loss: 1.592011195071553
Validation loss: 2.644693073860469

Epoch: 6| Step: 6
Training loss: 1.9316484626634156
Validation loss: 2.644211359553025

Epoch: 6| Step: 7
Training loss: 2.1647453470212037
Validation loss: 2.6146214597640096

Epoch: 6| Step: 8
Training loss: 1.8262190052825338
Validation loss: 2.5935577872879945

Epoch: 6| Step: 9
Training loss: 2.5467474033712825
Validation loss: 2.558681465179019

Epoch: 6| Step: 10
Training loss: 1.2646185558426764
Validation loss: 2.580185022866131

Epoch: 6| Step: 11
Training loss: 1.7549912255222693
Validation loss: 2.591245568175512

Epoch: 6| Step: 12
Training loss: 1.7644231976565221
Validation loss: 2.5764269698882605

Epoch: 6| Step: 13
Training loss: 2.6733118844856425
Validation loss: 2.5638354473484295

Epoch: 305| Step: 0
Training loss: 1.3170894129241806
Validation loss: 2.604013702986447

Epoch: 6| Step: 1
Training loss: 1.5608782171804463
Validation loss: 2.5846435905474627

Epoch: 6| Step: 2
Training loss: 1.5740184419853025
Validation loss: 2.6010668399821424

Epoch: 6| Step: 3
Training loss: 2.0576366537700452
Validation loss: 2.617476702601321

Epoch: 6| Step: 4
Training loss: 1.4521430194397076
Validation loss: 2.618523707357962

Epoch: 6| Step: 5
Training loss: 2.8071670834859357
Validation loss: 2.6260494223488586

Epoch: 6| Step: 6
Training loss: 1.8767877321282993
Validation loss: 2.6889793035865264

Epoch: 6| Step: 7
Training loss: 1.9167197330702763
Validation loss: 2.700454230423727

Epoch: 6| Step: 8
Training loss: 2.2249343005135147
Validation loss: 2.7012683173574614

Epoch: 6| Step: 9
Training loss: 1.6089568844952156
Validation loss: 2.693680103985384

Epoch: 6| Step: 10
Training loss: 1.9968788111117535
Validation loss: 2.7054221181277502

Epoch: 6| Step: 11
Training loss: 1.8368399492043175
Validation loss: 2.6557333350250176

Epoch: 6| Step: 12
Training loss: 1.5163081880805875
Validation loss: 2.6519697821781336

Epoch: 6| Step: 13
Training loss: 2.283047111930766
Validation loss: 2.6263293578673816

Epoch: 306| Step: 0
Training loss: 0.9392654961208061
Validation loss: 2.6076406932361205

Epoch: 6| Step: 1
Training loss: 1.3412434465260663
Validation loss: 2.588057925016785

Epoch: 6| Step: 2
Training loss: 1.5992699566923223
Validation loss: 2.5965111677680253

Epoch: 6| Step: 3
Training loss: 2.5005513536915673
Validation loss: 2.602196601823355

Epoch: 6| Step: 4
Training loss: 2.678376792012325
Validation loss: 2.565340778004292

Epoch: 6| Step: 5
Training loss: 2.092026185931254
Validation loss: 2.5926351334346354

Epoch: 6| Step: 6
Training loss: 1.9480881097046425
Validation loss: 2.560167538157506

Epoch: 6| Step: 7
Training loss: 2.040493400968739
Validation loss: 2.600564377614543

Epoch: 6| Step: 8
Training loss: 1.5101092146225354
Validation loss: 2.619152777385468

Epoch: 6| Step: 9
Training loss: 1.6930532563739562
Validation loss: 2.6010374469185606

Epoch: 6| Step: 10
Training loss: 1.8531179855754287
Validation loss: 2.629400062378119

Epoch: 6| Step: 11
Training loss: 1.709186232498396
Validation loss: 2.5496408465160227

Epoch: 6| Step: 12
Training loss: 2.05716686272617
Validation loss: 2.576741535173234

Epoch: 6| Step: 13
Training loss: 1.782818555361923
Validation loss: 2.5412776810914295

Epoch: 307| Step: 0
Training loss: 2.2481179313134936
Validation loss: 2.5656030831308834

Epoch: 6| Step: 1
Training loss: 1.5300957358084284
Validation loss: 2.5566707771530166

Epoch: 6| Step: 2
Training loss: 1.3902684301078394
Validation loss: 2.569058553970054

Epoch: 6| Step: 3
Training loss: 1.8474100283548889
Validation loss: 2.576745297941704

Epoch: 6| Step: 4
Training loss: 2.5659993166963497
Validation loss: 2.596573927802116

Epoch: 6| Step: 5
Training loss: 0.9393366941762362
Validation loss: 2.61417416616995

Epoch: 6| Step: 6
Training loss: 1.9767076039484364
Validation loss: 2.6168157057220562

Epoch: 6| Step: 7
Training loss: 2.0484062465957598
Validation loss: 2.612917309761323

Epoch: 6| Step: 8
Training loss: 2.1574062619670884
Validation loss: 2.6333508342048706

Epoch: 6| Step: 9
Training loss: 2.0591051309803703
Validation loss: 2.634796783361059

Epoch: 6| Step: 10
Training loss: 1.7529147261722247
Validation loss: 2.5913176717599766

Epoch: 6| Step: 11
Training loss: 1.55519026864818
Validation loss: 2.5970757239691467

Epoch: 6| Step: 12
Training loss: 1.7364702370397127
Validation loss: 2.628624321386148

Epoch: 6| Step: 13
Training loss: 1.628470749121214
Validation loss: 2.58984397247605

Epoch: 308| Step: 0
Training loss: 1.6810274678833539
Validation loss: 2.5820205388157182

Epoch: 6| Step: 1
Training loss: 1.5953300721698038
Validation loss: 2.5749738142540073

Epoch: 6| Step: 2
Training loss: 2.3037939376077037
Validation loss: 2.569837702192048

Epoch: 6| Step: 3
Training loss: 1.7396845607277058
Validation loss: 2.578775034943368

Epoch: 6| Step: 4
Training loss: 1.0549915016880624
Validation loss: 2.611745811882859

Epoch: 6| Step: 5
Training loss: 1.7459664863787097
Validation loss: 2.6055701225115766

Epoch: 6| Step: 6
Training loss: 1.8789040928310772
Validation loss: 2.64355879107954

Epoch: 6| Step: 7
Training loss: 1.9812826256216785
Validation loss: 2.617344972038853

Epoch: 6| Step: 8
Training loss: 1.4704675574435149
Validation loss: 2.6462437969622186

Epoch: 6| Step: 9
Training loss: 2.59630743588577
Validation loss: 2.65379246739293

Epoch: 6| Step: 10
Training loss: 1.5899343253913405
Validation loss: 2.640934160481932

Epoch: 6| Step: 11
Training loss: 1.4048136263055058
Validation loss: 2.5882229420083287

Epoch: 6| Step: 12
Training loss: 2.1179042602311773
Validation loss: 2.5747791812866767

Epoch: 6| Step: 13
Training loss: 2.101638735838432
Validation loss: 2.5747498199381833

Epoch: 309| Step: 0
Training loss: 2.1936892552673766
Validation loss: 2.602605692646912

Epoch: 6| Step: 1
Training loss: 1.8050968647165508
Validation loss: 2.586249817641854

Epoch: 6| Step: 2
Training loss: 2.0106048759423336
Validation loss: 2.578590258607695

Epoch: 6| Step: 3
Training loss: 2.083705894218537
Validation loss: 2.573547237104771

Epoch: 6| Step: 4
Training loss: 1.75903589697161
Validation loss: 2.6013357008247544

Epoch: 6| Step: 5
Training loss: 1.6173703002814235
Validation loss: 2.5941953315053885

Epoch: 6| Step: 6
Training loss: 2.368137483742601
Validation loss: 2.595242679766051

Epoch: 6| Step: 7
Training loss: 1.8034203775003206
Validation loss: 2.6361528406255936

Epoch: 6| Step: 8
Training loss: 2.2878028085537476
Validation loss: 2.604029374636181

Epoch: 6| Step: 9
Training loss: 1.4126776558210232
Validation loss: 2.6276573551315763

Epoch: 6| Step: 10
Training loss: 1.7453644528763206
Validation loss: 2.6117844108066643

Epoch: 6| Step: 11
Training loss: 1.8815801869340225
Validation loss: 2.5724798338766637

Epoch: 6| Step: 12
Training loss: 1.3516026309014573
Validation loss: 2.604967045175895

Epoch: 6| Step: 13
Training loss: 1.105384365136587
Validation loss: 2.5596592749531846

Epoch: 310| Step: 0
Training loss: 1.9955695671509093
Validation loss: 2.590142993698628

Epoch: 6| Step: 1
Training loss: 1.77027079304978
Validation loss: 2.5582986054771193

Epoch: 6| Step: 2
Training loss: 1.1780769520480823
Validation loss: 2.55239616085685

Epoch: 6| Step: 3
Training loss: 1.97224787649146
Validation loss: 2.578198757465199

Epoch: 6| Step: 4
Training loss: 2.477984480463649
Validation loss: 2.560955473778775

Epoch: 6| Step: 5
Training loss: 2.165155678629464
Validation loss: 2.5612644225062464

Epoch: 6| Step: 6
Training loss: 1.5031184523473555
Validation loss: 2.5637133292196967

Epoch: 6| Step: 7
Training loss: 2.002340616081604
Validation loss: 2.572364490475392

Epoch: 6| Step: 8
Training loss: 1.2887283354454329
Validation loss: 2.600483278145594

Epoch: 6| Step: 9
Training loss: 1.7498356196993556
Validation loss: 2.6111997669355826

Epoch: 6| Step: 10
Training loss: 2.250288520963876
Validation loss: 2.5714616303488573

Epoch: 6| Step: 11
Training loss: 1.203327310569957
Validation loss: 2.5645383155852635

Epoch: 6| Step: 12
Training loss: 1.9512008344087775
Validation loss: 2.5808402665311685

Epoch: 6| Step: 13
Training loss: 2.162251399750421
Validation loss: 2.523083657099312

Epoch: 311| Step: 0
Training loss: 1.8825854405926952
Validation loss: 2.5285827492657296

Epoch: 6| Step: 1
Training loss: 2.0548371815280966
Validation loss: 2.53999674506492

Epoch: 6| Step: 2
Training loss: 2.116626510339328
Validation loss: 2.5558191062183835

Epoch: 6| Step: 3
Training loss: 1.5479440559164896
Validation loss: 2.5415258107995773

Epoch: 6| Step: 4
Training loss: 2.048195915030507
Validation loss: 2.537254589722528

Epoch: 6| Step: 5
Training loss: 1.5542603485808464
Validation loss: 2.5885972925934317

Epoch: 6| Step: 6
Training loss: 1.720028488455535
Validation loss: 2.5920264864155036

Epoch: 6| Step: 7
Training loss: 2.340463393862475
Validation loss: 2.5961192543536447

Epoch: 6| Step: 8
Training loss: 1.7858022777131428
Validation loss: 2.570614241461512

Epoch: 6| Step: 9
Training loss: 1.4957439123148075
Validation loss: 2.5679942520588277

Epoch: 6| Step: 10
Training loss: 1.6765541126222736
Validation loss: 2.6244122286132923

Epoch: 6| Step: 11
Training loss: 1.8931121859993656
Validation loss: 2.627482421191907

Epoch: 6| Step: 12
Training loss: 1.5479998111429025
Validation loss: 2.6312446793527338

Epoch: 6| Step: 13
Training loss: 2.0558760653743695
Validation loss: 2.6530202790266637

Epoch: 312| Step: 0
Training loss: 1.3785446600641054
Validation loss: 2.6003826165492607

Epoch: 6| Step: 1
Training loss: 1.2356657209232382
Validation loss: 2.5733969905454313

Epoch: 6| Step: 2
Training loss: 2.4724325407292778
Validation loss: 2.551388024311707

Epoch: 6| Step: 3
Training loss: 1.7779980471700065
Validation loss: 2.549155893114944

Epoch: 6| Step: 4
Training loss: 2.013657548559306
Validation loss: 2.545770464140131

Epoch: 6| Step: 5
Training loss: 1.957506803498314
Validation loss: 2.547266089557273

Epoch: 6| Step: 6
Training loss: 1.6945627549911002
Validation loss: 2.5325750485566374

Epoch: 6| Step: 7
Training loss: 1.6100808975082574
Validation loss: 2.553799349419595

Epoch: 6| Step: 8
Training loss: 1.7736712734394626
Validation loss: 2.572687337027048

Epoch: 6| Step: 9
Training loss: 2.2938145599842423
Validation loss: 2.5377878912111616

Epoch: 6| Step: 10
Training loss: 1.8506602732843858
Validation loss: 2.5344821403989455

Epoch: 6| Step: 11
Training loss: 1.146517023664707
Validation loss: 2.551952542956426

Epoch: 6| Step: 12
Training loss: 1.492174557934304
Validation loss: 2.615794753533177

Epoch: 6| Step: 13
Training loss: 2.5049291654763324
Validation loss: 2.6010117964632893

Epoch: 313| Step: 0
Training loss: 1.9228665654966373
Validation loss: 2.5581690156668095

Epoch: 6| Step: 1
Training loss: 2.0144394337631013
Validation loss: 2.539758369749682

Epoch: 6| Step: 2
Training loss: 1.52465396144451
Validation loss: 2.539659854360906

Epoch: 6| Step: 3
Training loss: 1.9156671765213216
Validation loss: 2.540377701738991

Epoch: 6| Step: 4
Training loss: 2.3014610335494567
Validation loss: 2.5461521332000907

Epoch: 6| Step: 5
Training loss: 1.6934569439613827
Validation loss: 2.560110901302992

Epoch: 6| Step: 6
Training loss: 2.048100694192609
Validation loss: 2.5660048605896884

Epoch: 6| Step: 7
Training loss: 1.4783253314214908
Validation loss: 2.6043891252232756

Epoch: 6| Step: 8
Training loss: 1.3888150984977254
Validation loss: 2.596749237724435

Epoch: 6| Step: 9
Training loss: 1.9067082088897755
Validation loss: 2.688954987076958

Epoch: 6| Step: 10
Training loss: 1.3884620561645504
Validation loss: 2.650034690126048

Epoch: 6| Step: 11
Training loss: 1.6385193891358805
Validation loss: 2.6537980524840474

Epoch: 6| Step: 12
Training loss: 1.6544314783455154
Validation loss: 2.6408751931629104

Epoch: 6| Step: 13
Training loss: 2.5802939798993987
Validation loss: 2.6170398727458055

Epoch: 314| Step: 0
Training loss: 1.9791664792780201
Validation loss: 2.575680701086942

Epoch: 6| Step: 1
Training loss: 2.3052686055666127
Validation loss: 2.640263052969598

Epoch: 6| Step: 2
Training loss: 2.056735450464109
Validation loss: 2.5931571068334884

Epoch: 6| Step: 3
Training loss: 1.8474480993597306
Validation loss: 2.5809328529410607

Epoch: 6| Step: 4
Training loss: 1.3301345432320222
Validation loss: 2.5969724591723624

Epoch: 6| Step: 5
Training loss: 1.7115928753352643
Validation loss: 2.558544455482916

Epoch: 6| Step: 6
Training loss: 1.6530775961181743
Validation loss: 2.6082567571382285

Epoch: 6| Step: 7
Training loss: 1.890999307701916
Validation loss: 2.6088930701453896

Epoch: 6| Step: 8
Training loss: 1.8449457461436038
Validation loss: 2.576627955579777

Epoch: 6| Step: 9
Training loss: 1.719781808653531
Validation loss: 2.6081573325385916

Epoch: 6| Step: 10
Training loss: 1.8725968537282704
Validation loss: 2.6053788123366837

Epoch: 6| Step: 11
Training loss: 1.7865831277779765
Validation loss: 2.5644659084167056

Epoch: 6| Step: 12
Training loss: 1.2339737638407926
Validation loss: 2.5974409353561394

Epoch: 6| Step: 13
Training loss: 1.7335359760575044
Validation loss: 2.5833120550284265

Epoch: 315| Step: 0
Training loss: 2.1637134477072193
Validation loss: 2.6260843005433743

Epoch: 6| Step: 1
Training loss: 1.0047129199192357
Validation loss: 2.634425815078608

Epoch: 6| Step: 2
Training loss: 2.104684998780529
Validation loss: 2.616595893153824

Epoch: 6| Step: 3
Training loss: 1.3963800137878617
Validation loss: 2.5935772451450174

Epoch: 6| Step: 4
Training loss: 1.5863395895281827
Validation loss: 2.6325211028834836

Epoch: 6| Step: 5
Training loss: 2.0071594126085976
Validation loss: 2.6415423393074358

Epoch: 6| Step: 6
Training loss: 1.8303815168824698
Validation loss: 2.6353897173763894

Epoch: 6| Step: 7
Training loss: 1.639025971593825
Validation loss: 2.6219990242869686

Epoch: 6| Step: 8
Training loss: 1.284918070233359
Validation loss: 2.606958347604818

Epoch: 6| Step: 9
Training loss: 1.8407304251097727
Validation loss: 2.6180197232394473

Epoch: 6| Step: 10
Training loss: 2.499958037977916
Validation loss: 2.6122285540648376

Epoch: 6| Step: 11
Training loss: 1.5048199936951538
Validation loss: 2.668717397986504

Epoch: 6| Step: 12
Training loss: 1.8967520056478009
Validation loss: 2.6182580001656865

Epoch: 6| Step: 13
Training loss: 2.0502629088242057
Validation loss: 2.594355240644509

Epoch: 316| Step: 0
Training loss: 1.2298737555744812
Validation loss: 2.6147756062565715

Epoch: 6| Step: 1
Training loss: 2.160871997648673
Validation loss: 2.5796943280911204

Epoch: 6| Step: 2
Training loss: 1.899401949571756
Validation loss: 2.5487123816312813

Epoch: 6| Step: 3
Training loss: 1.8155975182139161
Validation loss: 2.582378685333824

Epoch: 6| Step: 4
Training loss: 1.8619823606948311
Validation loss: 2.571246455759917

Epoch: 6| Step: 5
Training loss: 1.6881182915428217
Validation loss: 2.5936155935492535

Epoch: 6| Step: 6
Training loss: 2.050546861605612
Validation loss: 2.561820847366352

Epoch: 6| Step: 7
Training loss: 1.6002369675393902
Validation loss: 2.611069987246017

Epoch: 6| Step: 8
Training loss: 2.3270632991992772
Validation loss: 2.594687434159755

Epoch: 6| Step: 9
Training loss: 1.7090083703672583
Validation loss: 2.590559640388923

Epoch: 6| Step: 10
Training loss: 1.868609345925481
Validation loss: 2.630507564834229

Epoch: 6| Step: 11
Training loss: 1.6554293488750347
Validation loss: 2.6334204118149396

Epoch: 6| Step: 12
Training loss: 1.858556807841569
Validation loss: 2.5861248090658733

Epoch: 6| Step: 13
Training loss: 1.038292621122599
Validation loss: 2.568404775781493

Epoch: 317| Step: 0
Training loss: 1.089020831981615
Validation loss: 2.59644666154351

Epoch: 6| Step: 1
Training loss: 1.6331249467431463
Validation loss: 2.5628193912104127

Epoch: 6| Step: 2
Training loss: 2.499059881829315
Validation loss: 2.605016162917357

Epoch: 6| Step: 3
Training loss: 1.6709254054753138
Validation loss: 2.6181651097273875

Epoch: 6| Step: 4
Training loss: 1.688190036553297
Validation loss: 2.602844808152561

Epoch: 6| Step: 5
Training loss: 1.7446594491842613
Validation loss: 2.6462760064371738

Epoch: 6| Step: 6
Training loss: 1.207719773141902
Validation loss: 2.6522547726133516

Epoch: 6| Step: 7
Training loss: 2.028120123764783
Validation loss: 2.682463991623259

Epoch: 6| Step: 8
Training loss: 1.7666950190566275
Validation loss: 2.7081124631367173

Epoch: 6| Step: 9
Training loss: 1.5830191082936744
Validation loss: 2.6719045358553446

Epoch: 6| Step: 10
Training loss: 2.2368040952612263
Validation loss: 2.608327963907811

Epoch: 6| Step: 11
Training loss: 1.6905744590890528
Validation loss: 2.557883624666938

Epoch: 6| Step: 12
Training loss: 2.197285156163195
Validation loss: 2.561681027302875

Epoch: 6| Step: 13
Training loss: 1.9358897747471842
Validation loss: 2.5195547492141377

Epoch: 318| Step: 0
Training loss: 1.2627180175628074
Validation loss: 2.550323694540561

Epoch: 6| Step: 1
Training loss: 1.6212735363642268
Validation loss: 2.5124925970724434

Epoch: 6| Step: 2
Training loss: 1.9548804367070811
Validation loss: 2.5259466461452758

Epoch: 6| Step: 3
Training loss: 1.5173298793500887
Validation loss: 2.51129740122011

Epoch: 6| Step: 4
Training loss: 2.2515831781585383
Validation loss: 2.5439345190559974

Epoch: 6| Step: 5
Training loss: 1.4140126762253586
Validation loss: 2.561397004967261

Epoch: 6| Step: 6
Training loss: 2.0120349228181027
Validation loss: 2.578018987768705

Epoch: 6| Step: 7
Training loss: 2.3808679869999083
Validation loss: 2.600137650685167

Epoch: 6| Step: 8
Training loss: 1.6888708974621707
Validation loss: 2.618145181980754

Epoch: 6| Step: 9
Training loss: 1.5234368739982689
Validation loss: 2.638311633054742

Epoch: 6| Step: 10
Training loss: 1.7689182322803665
Validation loss: 2.7419165380488097

Epoch: 6| Step: 11
Training loss: 1.5594976189666407
Validation loss: 2.7229409490863183

Epoch: 6| Step: 12
Training loss: 2.3780938125149365
Validation loss: 2.73205414143296

Epoch: 6| Step: 13
Training loss: 2.1178148754793837
Validation loss: 2.635447179042207

Epoch: 319| Step: 0
Training loss: 2.1694034262651827
Validation loss: 2.5792633471961826

Epoch: 6| Step: 1
Training loss: 2.0575658559167254
Validation loss: 2.514765859288221

Epoch: 6| Step: 2
Training loss: 1.8221401486224718
Validation loss: 2.5327692064636387

Epoch: 6| Step: 3
Training loss: 1.7178131324471275
Validation loss: 2.516705661959985

Epoch: 6| Step: 4
Training loss: 1.7848748250288389
Validation loss: 2.496050369132478

Epoch: 6| Step: 5
Training loss: 1.6423259818272122
Validation loss: 2.5252703141154256

Epoch: 6| Step: 6
Training loss: 1.7980844159364422
Validation loss: 2.5518089354521005

Epoch: 6| Step: 7
Training loss: 1.524783200346755
Validation loss: 2.5462198487439403

Epoch: 6| Step: 8
Training loss: 2.1432140870488894
Validation loss: 2.5104175477929895

Epoch: 6| Step: 9
Training loss: 1.831222713644734
Validation loss: 2.573180850490508

Epoch: 6| Step: 10
Training loss: 1.9308417570841112
Validation loss: 2.5880585698747804

Epoch: 6| Step: 11
Training loss: 1.8587859045997723
Validation loss: 2.5519576735927734

Epoch: 6| Step: 12
Training loss: 1.99954039537968
Validation loss: 2.567233636913208

Epoch: 6| Step: 13
Training loss: 1.196393191418394
Validation loss: 2.543180426612891

Epoch: 320| Step: 0
Training loss: 2.2211177173868446
Validation loss: 2.579081633362139

Epoch: 6| Step: 1
Training loss: 2.0715303114161094
Validation loss: 2.619689307415652

Epoch: 6| Step: 2
Training loss: 2.121814022395928
Validation loss: 2.5849598460764995

Epoch: 6| Step: 3
Training loss: 1.2862865729734916
Validation loss: 2.57655923479597

Epoch: 6| Step: 4
Training loss: 2.0843757183296763
Validation loss: 2.583126218758416

Epoch: 6| Step: 5
Training loss: 1.6251109158736217
Validation loss: 2.5290785372450393

Epoch: 6| Step: 6
Training loss: 1.8541559654812845
Validation loss: 2.562979474994

Epoch: 6| Step: 7
Training loss: 1.839809150127486
Validation loss: 2.5528722724356436

Epoch: 6| Step: 8
Training loss: 1.7986555482668256
Validation loss: 2.5301516155253165

Epoch: 6| Step: 9
Training loss: 2.1903188799018047
Validation loss: 2.511641988179505

Epoch: 6| Step: 10
Training loss: 1.3749715195220464
Validation loss: 2.5297480078991357

Epoch: 6| Step: 11
Training loss: 1.7905150268230918
Validation loss: 2.5713261052182452

Epoch: 6| Step: 12
Training loss: 1.4090172137988355
Validation loss: 2.525020421767035

Epoch: 6| Step: 13
Training loss: 1.4551643090038768
Validation loss: 2.5308401929879407

Epoch: 321| Step: 0
Training loss: 1.8774932179538024
Validation loss: 2.5419493710828145

Epoch: 6| Step: 1
Training loss: 1.3592703768051932
Validation loss: 2.599011060731549

Epoch: 6| Step: 2
Training loss: 2.133999448831589
Validation loss: 2.605175545135429

Epoch: 6| Step: 3
Training loss: 1.7254231694066793
Validation loss: 2.6085058809272232

Epoch: 6| Step: 4
Training loss: 1.9143847135919472
Validation loss: 2.5991296858224193

Epoch: 6| Step: 5
Training loss: 1.1388423523789772
Validation loss: 2.5905933934988252

Epoch: 6| Step: 6
Training loss: 1.5518824897551577
Validation loss: 2.617038324004769

Epoch: 6| Step: 7
Training loss: 1.8330460525612953
Validation loss: 2.5667143026695673

Epoch: 6| Step: 8
Training loss: 2.2250145600946203
Validation loss: 2.5763042918183294

Epoch: 6| Step: 9
Training loss: 1.9225383947182042
Validation loss: 2.597692901429248

Epoch: 6| Step: 10
Training loss: 1.807257337729697
Validation loss: 2.5568130780820932

Epoch: 6| Step: 11
Training loss: 1.2344862006595438
Validation loss: 2.602249833688136

Epoch: 6| Step: 12
Training loss: 1.9666558284245357
Validation loss: 2.569189875825061

Epoch: 6| Step: 13
Training loss: 2.4571083917925423
Validation loss: 2.5744547757436416

Epoch: 322| Step: 0
Training loss: 1.4119516709353508
Validation loss: 2.6015965456639356

Epoch: 6| Step: 1
Training loss: 1.6736288408296176
Validation loss: 2.6594793996255115

Epoch: 6| Step: 2
Training loss: 1.6472292263974968
Validation loss: 2.6584730532131102

Epoch: 6| Step: 3
Training loss: 1.1932025313127697
Validation loss: 2.696807210990418

Epoch: 6| Step: 4
Training loss: 1.9173068207635129
Validation loss: 2.638760301457519

Epoch: 6| Step: 5
Training loss: 2.3908010181128057
Validation loss: 2.6498664294474845

Epoch: 6| Step: 6
Training loss: 1.3739268710236279
Validation loss: 2.686166676524398

Epoch: 6| Step: 7
Training loss: 2.654775681583125
Validation loss: 2.6676716450575615

Epoch: 6| Step: 8
Training loss: 2.0219103378202927
Validation loss: 2.6517472792655497

Epoch: 6| Step: 9
Training loss: 1.3319681997283515
Validation loss: 2.639802417128613

Epoch: 6| Step: 10
Training loss: 1.4585819940650044
Validation loss: 2.619094821682093

Epoch: 6| Step: 11
Training loss: 1.7313198640133196
Validation loss: 2.5535023357902795

Epoch: 6| Step: 12
Training loss: 1.503381018139618
Validation loss: 2.5654658854834667

Epoch: 6| Step: 13
Training loss: 1.1290164880486222
Validation loss: 2.5493478919817925

Epoch: 323| Step: 0
Training loss: 1.7613568325414721
Validation loss: 2.523277128022814

Epoch: 6| Step: 1
Training loss: 1.4157540336226742
Validation loss: 2.5329770448339564

Epoch: 6| Step: 2
Training loss: 1.8051151578101416
Validation loss: 2.525347236010776

Epoch: 6| Step: 3
Training loss: 1.8815988768447716
Validation loss: 2.5336321386831777

Epoch: 6| Step: 4
Training loss: 1.6289473786867756
Validation loss: 2.5344449825008493

Epoch: 6| Step: 5
Training loss: 1.718691946262998
Validation loss: 2.5348628442040386

Epoch: 6| Step: 6
Training loss: 1.9036343874676387
Validation loss: 2.540679229120036

Epoch: 6| Step: 7
Training loss: 1.8827486146084231
Validation loss: 2.552183785051071

Epoch: 6| Step: 8
Training loss: 1.4096796387419614
Validation loss: 2.562901597226519

Epoch: 6| Step: 9
Training loss: 1.7645534538372518
Validation loss: 2.599446288471402

Epoch: 6| Step: 10
Training loss: 1.236970273705355
Validation loss: 2.614038727312666

Epoch: 6| Step: 11
Training loss: 2.3612395744032986
Validation loss: 2.6542880572990573

Epoch: 6| Step: 12
Training loss: 1.7566792543866276
Validation loss: 2.6690094511251385

Epoch: 6| Step: 13
Training loss: 1.823166406872013
Validation loss: 2.730079430296777

Epoch: 324| Step: 0
Training loss: 2.0385273782979496
Validation loss: 2.6673116549658373

Epoch: 6| Step: 1
Training loss: 1.497440538706519
Validation loss: 2.6156424901233954

Epoch: 6| Step: 2
Training loss: 1.4055178113668492
Validation loss: 2.601148585784162

Epoch: 6| Step: 3
Training loss: 1.6412913831038956
Validation loss: 2.536655431422626

Epoch: 6| Step: 4
Training loss: 1.9701928195407787
Validation loss: 2.5154479539067145

Epoch: 6| Step: 5
Training loss: 2.4630323425226273
Validation loss: 2.496506602610587

Epoch: 6| Step: 6
Training loss: 1.7556689947366473
Validation loss: 2.5213737118777777

Epoch: 6| Step: 7
Training loss: 1.195557712510049
Validation loss: 2.554481676931094

Epoch: 6| Step: 8
Training loss: 1.3527084079313334
Validation loss: 2.5850013659613205

Epoch: 6| Step: 9
Training loss: 1.791974359158589
Validation loss: 2.607760769540679

Epoch: 6| Step: 10
Training loss: 1.4690845189719537
Validation loss: 2.6416863860909556

Epoch: 6| Step: 11
Training loss: 1.8410285002260038
Validation loss: 2.6550144388652748

Epoch: 6| Step: 12
Training loss: 1.5182252581782165
Validation loss: 2.595368971603558

Epoch: 6| Step: 13
Training loss: 1.9850340221958167
Validation loss: 2.5930630183939742

Epoch: 325| Step: 0
Training loss: 1.122147015505526
Validation loss: 2.6372841838627354

Epoch: 6| Step: 1
Training loss: 1.5004881223559956
Validation loss: 2.6381411485765938

Epoch: 6| Step: 2
Training loss: 2.26934824220457
Validation loss: 2.600467837253545

Epoch: 6| Step: 3
Training loss: 1.0349202012890626
Validation loss: 2.64626656136836

Epoch: 6| Step: 4
Training loss: 1.680830739438059
Validation loss: 2.6499297102717074

Epoch: 6| Step: 5
Training loss: 2.1201297824648915
Validation loss: 2.6418241528118958

Epoch: 6| Step: 6
Training loss: 2.155370781812792
Validation loss: 2.6344130091340467

Epoch: 6| Step: 7
Training loss: 1.450284005994627
Validation loss: 2.608055405439736

Epoch: 6| Step: 8
Training loss: 1.6551034665682949
Validation loss: 2.5673332069299204

Epoch: 6| Step: 9
Training loss: 2.239871114531078
Validation loss: 2.572083748943527

Epoch: 6| Step: 10
Training loss: 1.4827664142035204
Validation loss: 2.5263450571454134

Epoch: 6| Step: 11
Training loss: 1.596457481671119
Validation loss: 2.5009157728746287

Epoch: 6| Step: 12
Training loss: 1.9722339744695303
Validation loss: 2.5363723510539855

Epoch: 6| Step: 13
Training loss: 1.48009774181729
Validation loss: 2.487914261436375

Epoch: 326| Step: 0
Training loss: 1.3680026866596453
Validation loss: 2.5078846098137664

Epoch: 6| Step: 1
Training loss: 1.8399501372920266
Validation loss: 2.495245959199503

Epoch: 6| Step: 2
Training loss: 2.1117166590424468
Validation loss: 2.472528133920124

Epoch: 6| Step: 3
Training loss: 1.5653686130767757
Validation loss: 2.4991816850342206

Epoch: 6| Step: 4
Training loss: 1.722242240721054
Validation loss: 2.5095890997370147

Epoch: 6| Step: 5
Training loss: 2.218315511794791
Validation loss: 2.54997568617555

Epoch: 6| Step: 6
Training loss: 1.7928341750626189
Validation loss: 2.5710167968262643

Epoch: 6| Step: 7
Training loss: 1.9377931557649333
Validation loss: 2.6070198501613553

Epoch: 6| Step: 8
Training loss: 1.169080938312625
Validation loss: 2.659506503244534

Epoch: 6| Step: 9
Training loss: 1.7825028547609216
Validation loss: 2.6715738524625863

Epoch: 6| Step: 10
Training loss: 1.4601105170030086
Validation loss: 2.629191987227578

Epoch: 6| Step: 11
Training loss: 1.627973623432305
Validation loss: 2.589789956264398

Epoch: 6| Step: 12
Training loss: 1.8768681438471984
Validation loss: 2.619827434581286

Epoch: 6| Step: 13
Training loss: 1.7320345646710784
Validation loss: 2.6051296183090624

Epoch: 327| Step: 0
Training loss: 1.230532399302445
Validation loss: 2.5596200064179935

Epoch: 6| Step: 1
Training loss: 1.4952614961892399
Validation loss: 2.569064029392619

Epoch: 6| Step: 2
Training loss: 1.9273705414516915
Validation loss: 2.5612190735716753

Epoch: 6| Step: 3
Training loss: 1.7817913370551928
Validation loss: 2.5513092008728093

Epoch: 6| Step: 4
Training loss: 1.891268912130674
Validation loss: 2.588098949948264

Epoch: 6| Step: 5
Training loss: 1.4444210293086492
Validation loss: 2.6503299039942374

Epoch: 6| Step: 6
Training loss: 1.9924026073934253
Validation loss: 2.6447207196578217

Epoch: 6| Step: 7
Training loss: 1.7366539356597306
Validation loss: 2.6890801212872004

Epoch: 6| Step: 8
Training loss: 2.392979478453954
Validation loss: 2.7370236747357977

Epoch: 6| Step: 9
Training loss: 1.5469964490281367
Validation loss: 2.7605499139451193

Epoch: 6| Step: 10
Training loss: 2.173892833366989
Validation loss: 2.6840554422781775

Epoch: 6| Step: 11
Training loss: 1.500418604614961
Validation loss: 2.6109927372670105

Epoch: 6| Step: 12
Training loss: 1.4034249645650996
Validation loss: 2.548175690263469

Epoch: 6| Step: 13
Training loss: 2.087363680654366
Validation loss: 2.521050393924014

Epoch: 328| Step: 0
Training loss: 1.711212693470248
Validation loss: 2.5300235995472353

Epoch: 6| Step: 1
Training loss: 1.7569236033748603
Validation loss: 2.5025415138131994

Epoch: 6| Step: 2
Training loss: 2.3004002927660236
Validation loss: 2.492934574413764

Epoch: 6| Step: 3
Training loss: 2.0395161208188766
Validation loss: 2.4891241094320433

Epoch: 6| Step: 4
Training loss: 1.6502337319101443
Validation loss: 2.497039806670451

Epoch: 6| Step: 5
Training loss: 1.5934801060153219
Validation loss: 2.5019100204355946

Epoch: 6| Step: 6
Training loss: 1.3731873875831884
Validation loss: 2.5241325846205958

Epoch: 6| Step: 7
Training loss: 1.8370726626939877
Validation loss: 2.500181676303306

Epoch: 6| Step: 8
Training loss: 2.1948108031952343
Validation loss: 2.5821687216431592

Epoch: 6| Step: 9
Training loss: 1.731050966024891
Validation loss: 2.5884535919699987

Epoch: 6| Step: 10
Training loss: 1.5053387049761322
Validation loss: 2.6158533292137576

Epoch: 6| Step: 11
Training loss: 1.6585953139712362
Validation loss: 2.639887614627557

Epoch: 6| Step: 12
Training loss: 1.965659849891963
Validation loss: 2.594031850982019

Epoch: 6| Step: 13
Training loss: 1.4401891682138421
Validation loss: 2.5734140221722064

Epoch: 329| Step: 0
Training loss: 1.4374028048620515
Validation loss: 2.5580747975943114

Epoch: 6| Step: 1
Training loss: 1.6911017516037714
Validation loss: 2.5568400888756786

Epoch: 6| Step: 2
Training loss: 2.0556900421458097
Validation loss: 2.513938322570609

Epoch: 6| Step: 3
Training loss: 2.4483341158698355
Validation loss: 2.5271214068491124

Epoch: 6| Step: 4
Training loss: 1.5227106952670664
Validation loss: 2.5401212861547506

Epoch: 6| Step: 5
Training loss: 2.071777516368865
Validation loss: 2.5711461872760557

Epoch: 6| Step: 6
Training loss: 1.2310765778454704
Validation loss: 2.5546812316008802

Epoch: 6| Step: 7
Training loss: 2.2542784596736887
Validation loss: 2.6152179044205335

Epoch: 6| Step: 8
Training loss: 1.9469794672435352
Validation loss: 2.680595236788168

Epoch: 6| Step: 9
Training loss: 1.311239272838312
Validation loss: 2.6905692708752875

Epoch: 6| Step: 10
Training loss: 1.6836281615809667
Validation loss: 2.749403592662185

Epoch: 6| Step: 11
Training loss: 1.6963143618579681
Validation loss: 2.744362905602073

Epoch: 6| Step: 12
Training loss: 1.4691184373116828
Validation loss: 2.7636355268516675

Epoch: 6| Step: 13
Training loss: 1.7772333467169867
Validation loss: 2.73874470647419

Epoch: 330| Step: 0
Training loss: 1.9647222826442166
Validation loss: 2.692736381419116

Epoch: 6| Step: 1
Training loss: 1.9639906500615152
Validation loss: 2.642985310447651

Epoch: 6| Step: 2
Training loss: 1.5220122101202496
Validation loss: 2.5872604351358524

Epoch: 6| Step: 3
Training loss: 1.3744601143454522
Validation loss: 2.6334888936422947

Epoch: 6| Step: 4
Training loss: 2.197890644612477
Validation loss: 2.600181801259722

Epoch: 6| Step: 5
Training loss: 2.1159141624649904
Validation loss: 2.5555470349565996

Epoch: 6| Step: 6
Training loss: 1.5395957681293955
Validation loss: 2.5982345358038064

Epoch: 6| Step: 7
Training loss: 1.5155320286501708
Validation loss: 2.5539995019504476

Epoch: 6| Step: 8
Training loss: 1.3260925898496863
Validation loss: 2.5650422580948598

Epoch: 6| Step: 9
Training loss: 1.1834439727388613
Validation loss: 2.5920724844407865

Epoch: 6| Step: 10
Training loss: 1.3703451694260997
Validation loss: 2.585788549645383

Epoch: 6| Step: 11
Training loss: 1.9322495228849106
Validation loss: 2.617667196921839

Epoch: 6| Step: 12
Training loss: 1.522803619753416
Validation loss: 2.587055959394417

Epoch: 6| Step: 13
Training loss: 1.742492033339559
Validation loss: 2.593034331467501

Epoch: 331| Step: 0
Training loss: 1.4909157651341627
Validation loss: 2.5767760321522055

Epoch: 6| Step: 1
Training loss: 1.1234765864378518
Validation loss: 2.5436694248819207

Epoch: 6| Step: 2
Training loss: 1.488864574107309
Validation loss: 2.5475533640984005

Epoch: 6| Step: 3
Training loss: 1.6058356615309308
Validation loss: 2.560939670427608

Epoch: 6| Step: 4
Training loss: 1.4291637691249706
Validation loss: 2.5719439769593886

Epoch: 6| Step: 5
Training loss: 2.108255499004917
Validation loss: 2.5621466974609985

Epoch: 6| Step: 6
Training loss: 2.297380041533576
Validation loss: 2.5446365130097637

Epoch: 6| Step: 7
Training loss: 1.7389982994821491
Validation loss: 2.50921181432808

Epoch: 6| Step: 8
Training loss: 1.8516979570374537
Validation loss: 2.557262448974604

Epoch: 6| Step: 9
Training loss: 1.8125607710548879
Validation loss: 2.5779253024970914

Epoch: 6| Step: 10
Training loss: 1.411151988813259
Validation loss: 2.5816151432275296

Epoch: 6| Step: 11
Training loss: 1.943249692649135
Validation loss: 2.611375875328896

Epoch: 6| Step: 12
Training loss: 1.4626047341429613
Validation loss: 2.572652553536773

Epoch: 6| Step: 13
Training loss: 1.6747031845608265
Validation loss: 2.579073074647625

Epoch: 332| Step: 0
Training loss: 1.6311247649662206
Validation loss: 2.587679580624148

Epoch: 6| Step: 1
Training loss: 1.3871448130956512
Validation loss: 2.597417819522452

Epoch: 6| Step: 2
Training loss: 1.3367756673711144
Validation loss: 2.615447784217646

Epoch: 6| Step: 3
Training loss: 2.0721519503753427
Validation loss: 2.612486942386393

Epoch: 6| Step: 4
Training loss: 1.3973631754653937
Validation loss: 2.5885811821257976

Epoch: 6| Step: 5
Training loss: 1.893450997293947
Validation loss: 2.5993596125840774

Epoch: 6| Step: 6
Training loss: 1.7222361495709337
Validation loss: 2.5987937635608693

Epoch: 6| Step: 7
Training loss: 1.1076276746053964
Validation loss: 2.5958798867138917

Epoch: 6| Step: 8
Training loss: 1.9243284242995686
Validation loss: 2.617291599310017

Epoch: 6| Step: 9
Training loss: 1.909648804457502
Validation loss: 2.5818857218349605

Epoch: 6| Step: 10
Training loss: 1.4048793470768726
Validation loss: 2.575962662606913

Epoch: 6| Step: 11
Training loss: 1.6672459628750842
Validation loss: 2.576649592377159

Epoch: 6| Step: 12
Training loss: 1.907467562698402
Validation loss: 2.56527483738642

Epoch: 6| Step: 13
Training loss: 1.6714248051094407
Validation loss: 2.5338137167001658

Epoch: 333| Step: 0
Training loss: 1.8562203581527248
Validation loss: 2.545630059084637

Epoch: 6| Step: 1
Training loss: 1.8959466110873233
Validation loss: 2.542793560878755

Epoch: 6| Step: 2
Training loss: 1.2243161375141784
Validation loss: 2.5431238020716513

Epoch: 6| Step: 3
Training loss: 1.2231915067077228
Validation loss: 2.5572145117614618

Epoch: 6| Step: 4
Training loss: 2.024115253778152
Validation loss: 2.5442410131845947

Epoch: 6| Step: 5
Training loss: 1.3357101157686495
Validation loss: 2.524571143452118

Epoch: 6| Step: 6
Training loss: 1.5901554936124853
Validation loss: 2.5157714390435557

Epoch: 6| Step: 7
Training loss: 1.5605610833696895
Validation loss: 2.5499348114756724

Epoch: 6| Step: 8
Training loss: 1.248307847033199
Validation loss: 2.554734084767151

Epoch: 6| Step: 9
Training loss: 1.9013518267668876
Validation loss: 2.5693738280435703

Epoch: 6| Step: 10
Training loss: 1.9789255363407052
Validation loss: 2.6145446642768246

Epoch: 6| Step: 11
Training loss: 1.7329653260624804
Validation loss: 2.600051074259961

Epoch: 6| Step: 12
Training loss: 1.9788273436804464
Validation loss: 2.629623156625644

Epoch: 6| Step: 13
Training loss: 1.1651980602553382
Validation loss: 2.602785084769696

Epoch: 334| Step: 0
Training loss: 1.9927201101377514
Validation loss: 2.6128712452699077

Epoch: 6| Step: 1
Training loss: 1.6823689194018172
Validation loss: 2.6071274570923495

Epoch: 6| Step: 2
Training loss: 1.1603881398683351
Validation loss: 2.6276402138593102

Epoch: 6| Step: 3
Training loss: 1.4782817862267486
Validation loss: 2.6186610841791946

Epoch: 6| Step: 4
Training loss: 2.026536843424957
Validation loss: 2.623776574608314

Epoch: 6| Step: 5
Training loss: 1.8238977317248397
Validation loss: 2.640054012767156

Epoch: 6| Step: 6
Training loss: 1.575430959444842
Validation loss: 2.671610352495193

Epoch: 6| Step: 7
Training loss: 2.535090511745188
Validation loss: 2.6960378656718444

Epoch: 6| Step: 8
Training loss: 1.558790916266831
Validation loss: 2.7181707035425884

Epoch: 6| Step: 9
Training loss: 2.065158402322827
Validation loss: 2.680988051772394

Epoch: 6| Step: 10
Training loss: 1.5855014746595038
Validation loss: 2.6992367690019035

Epoch: 6| Step: 11
Training loss: 0.8416514968134482
Validation loss: 2.6633358334428925

Epoch: 6| Step: 12
Training loss: 1.6815084833026996
Validation loss: 2.680678396644091

Epoch: 6| Step: 13
Training loss: 1.006647308765585
Validation loss: 2.609260221534341

Epoch: 335| Step: 0
Training loss: 2.138072698957599
Validation loss: 2.609186771022554

Epoch: 6| Step: 1
Training loss: 2.1944515399844975
Validation loss: 2.5948312949073506

Epoch: 6| Step: 2
Training loss: 1.5544930341238743
Validation loss: 2.5156500757835487

Epoch: 6| Step: 3
Training loss: 1.950675588121088
Validation loss: 2.5599045363647255

Epoch: 6| Step: 4
Training loss: 1.5722265013571755
Validation loss: 2.5870488247991834

Epoch: 6| Step: 5
Training loss: 0.7991907094322839
Validation loss: 2.5384652398748613

Epoch: 6| Step: 6
Training loss: 1.5149847821771252
Validation loss: 2.515369892019316

Epoch: 6| Step: 7
Training loss: 1.9484348593833913
Validation loss: 2.4851033804437432

Epoch: 6| Step: 8
Training loss: 1.229917663206449
Validation loss: 2.4786095888218953

Epoch: 6| Step: 9
Training loss: 1.9475165447467648
Validation loss: 2.5257376943479355

Epoch: 6| Step: 10
Training loss: 1.6460911110312333
Validation loss: 2.5096153521048246

Epoch: 6| Step: 11
Training loss: 0.9481815275517492
Validation loss: 2.4914288776271696

Epoch: 6| Step: 12
Training loss: 1.6199645004385974
Validation loss: 2.527482223058329

Epoch: 6| Step: 13
Training loss: 1.3715098040512297
Validation loss: 2.5190894397487145

Epoch: 336| Step: 0
Training loss: 1.7538158503899026
Validation loss: 2.527044586131984

Epoch: 6| Step: 1
Training loss: 1.2710400345512598
Validation loss: 2.5443738111560195

Epoch: 6| Step: 2
Training loss: 1.930405085651261
Validation loss: 2.5276865424527966

Epoch: 6| Step: 3
Training loss: 1.7726049947915115
Validation loss: 2.5462421574922045

Epoch: 6| Step: 4
Training loss: 2.233803842810352
Validation loss: 2.553796533106806

Epoch: 6| Step: 5
Training loss: 1.2924015149312185
Validation loss: 2.529322325825137

Epoch: 6| Step: 6
Training loss: 1.9054401115589523
Validation loss: 2.5084874244158275

Epoch: 6| Step: 7
Training loss: 1.2727827951780193
Validation loss: 2.493113569920547

Epoch: 6| Step: 8
Training loss: 1.9760538886749182
Validation loss: 2.5217055448555126

Epoch: 6| Step: 9
Training loss: 1.2543101388140276
Validation loss: 2.5255916994337055

Epoch: 6| Step: 10
Training loss: 1.2545977435661664
Validation loss: 2.510988539671739

Epoch: 6| Step: 11
Training loss: 1.5206740134760082
Validation loss: 2.567711763721416

Epoch: 6| Step: 12
Training loss: 1.5579801417592232
Validation loss: 2.566246519338778

Epoch: 6| Step: 13
Training loss: 1.207820597198309
Validation loss: 2.6479053544093736

Epoch: 337| Step: 0
Training loss: 1.8129688182785757
Validation loss: 2.708975691301271

Epoch: 6| Step: 1
Training loss: 1.2927298425959348
Validation loss: 2.7320494435473353

Epoch: 6| Step: 2
Training loss: 1.2111355527303302
Validation loss: 2.7270656438437872

Epoch: 6| Step: 3
Training loss: 1.76528576317932
Validation loss: 2.7024883189317968

Epoch: 6| Step: 4
Training loss: 1.9830143386160832
Validation loss: 2.6829422738842363

Epoch: 6| Step: 5
Training loss: 1.2806324284544266
Validation loss: 2.6208343150061713

Epoch: 6| Step: 6
Training loss: 2.3658524075131444
Validation loss: 2.6468827777074213

Epoch: 6| Step: 7
Training loss: 1.6763218005659697
Validation loss: 2.631466801788578

Epoch: 6| Step: 8
Training loss: 1.3974109483437667
Validation loss: 2.6267997082389405

Epoch: 6| Step: 9
Training loss: 1.4609143260403004
Validation loss: 2.5920453885523513

Epoch: 6| Step: 10
Training loss: 1.6306986289838923
Validation loss: 2.5781932012611417

Epoch: 6| Step: 11
Training loss: 1.5245330001697461
Validation loss: 2.5525812299147126

Epoch: 6| Step: 12
Training loss: 1.4670000405444845
Validation loss: 2.5232367263460436

Epoch: 6| Step: 13
Training loss: 1.3745232535872574
Validation loss: 2.4985410883941612

Epoch: 338| Step: 0
Training loss: 1.8183921540580683
Validation loss: 2.529297173498816

Epoch: 6| Step: 1
Training loss: 1.6052349876387415
Validation loss: 2.4856657278055643

Epoch: 6| Step: 2
Training loss: 1.9920821816524115
Validation loss: 2.533465887249218

Epoch: 6| Step: 3
Training loss: 1.3460548505957615
Validation loss: 2.503046881146887

Epoch: 6| Step: 4
Training loss: 1.6763037376125016
Validation loss: 2.4979776467798605

Epoch: 6| Step: 5
Training loss: 1.4226916975436967
Validation loss: 2.4787868454567756

Epoch: 6| Step: 6
Training loss: 1.013151472570647
Validation loss: 2.537235428182452

Epoch: 6| Step: 7
Training loss: 1.4993294170617406
Validation loss: 2.532797493440107

Epoch: 6| Step: 8
Training loss: 1.447295606871462
Validation loss: 2.573548541812694

Epoch: 6| Step: 9
Training loss: 1.9589755513533524
Validation loss: 2.543807110781893

Epoch: 6| Step: 10
Training loss: 1.607539936239982
Validation loss: 2.5702716858936605

Epoch: 6| Step: 11
Training loss: 1.7692298211379047
Validation loss: 2.5739116726737925

Epoch: 6| Step: 12
Training loss: 1.3429813404391822
Validation loss: 2.6050533056876284

Epoch: 6| Step: 13
Training loss: 1.5265247851801447
Validation loss: 2.5596336289964694

Epoch: 339| Step: 0
Training loss: 1.2834961903437154
Validation loss: 2.566083124219251

Epoch: 6| Step: 1
Training loss: 1.7097241005093982
Validation loss: 2.503703195925113

Epoch: 6| Step: 2
Training loss: 1.2269475053223142
Validation loss: 2.540181591195915

Epoch: 6| Step: 3
Training loss: 1.4031834970357422
Validation loss: 2.556984602652926

Epoch: 6| Step: 4
Training loss: 1.2210216381333276
Validation loss: 2.5715078648825145

Epoch: 6| Step: 5
Training loss: 1.6515648992515612
Validation loss: 2.567297035275028

Epoch: 6| Step: 6
Training loss: 2.263423507796756
Validation loss: 2.584550560519959

Epoch: 6| Step: 7
Training loss: 1.255629689049783
Validation loss: 2.5787365737099543

Epoch: 6| Step: 8
Training loss: 1.2024895116780856
Validation loss: 2.6207426151490725

Epoch: 6| Step: 9
Training loss: 1.6521049308888454
Validation loss: 2.6290309625134602

Epoch: 6| Step: 10
Training loss: 1.6394468891351504
Validation loss: 2.641300679274431

Epoch: 6| Step: 11
Training loss: 1.8556081619089773
Validation loss: 2.602745390556743

Epoch: 6| Step: 12
Training loss: 2.042758908991982
Validation loss: 2.616210041375865

Epoch: 6| Step: 13
Training loss: 1.3286008094726558
Validation loss: 2.625567450573337

Epoch: 340| Step: 0
Training loss: 1.857315910838654
Validation loss: 2.619531430211162

Epoch: 6| Step: 1
Training loss: 1.98475186831762
Validation loss: 2.5887391279241867

Epoch: 6| Step: 2
Training loss: 1.2322878999026405
Validation loss: 2.59321228642948

Epoch: 6| Step: 3
Training loss: 0.933082600247962
Validation loss: 2.5861877750552167

Epoch: 6| Step: 4
Training loss: 1.190609675030941
Validation loss: 2.548849436547837

Epoch: 6| Step: 5
Training loss: 1.6999096397619824
Validation loss: 2.517355976903364

Epoch: 6| Step: 6
Training loss: 1.8147621507565004
Validation loss: 2.5243072113306866

Epoch: 6| Step: 7
Training loss: 1.653664207857028
Validation loss: 2.563640123750285

Epoch: 6| Step: 8
Training loss: 1.377671853645898
Validation loss: 2.5167512603672737

Epoch: 6| Step: 9
Training loss: 1.8508767576360663
Validation loss: 2.5323965513559883

Epoch: 6| Step: 10
Training loss: 1.2410038520943785
Validation loss: 2.542133145180123

Epoch: 6| Step: 11
Training loss: 1.0279550800379984
Validation loss: 2.533318392705361

Epoch: 6| Step: 12
Training loss: 2.27027867627398
Validation loss: 2.598630365893562

Epoch: 6| Step: 13
Training loss: 1.6453213277581762
Validation loss: 2.5401217398166955

Epoch: 341| Step: 0
Training loss: 1.2801401402081267
Validation loss: 2.6024476188545336

Epoch: 6| Step: 1
Training loss: 1.887352373021517
Validation loss: 2.6111363236132177

Epoch: 6| Step: 2
Training loss: 1.4523178648219395
Validation loss: 2.6154946845074813

Epoch: 6| Step: 3
Training loss: 1.5864355498506568
Validation loss: 2.5501358360687454

Epoch: 6| Step: 4
Training loss: 1.2513957337561423
Validation loss: 2.6022809538207055

Epoch: 6| Step: 5
Training loss: 1.5211007218477872
Validation loss: 2.6123280214592604

Epoch: 6| Step: 6
Training loss: 1.5534044655215193
Validation loss: 2.6385519855557025

Epoch: 6| Step: 7
Training loss: 1.40608171939631
Validation loss: 2.588571119748549

Epoch: 6| Step: 8
Training loss: 1.7970531209482616
Validation loss: 2.558239030394305

Epoch: 6| Step: 9
Training loss: 1.9984827246779446
Validation loss: 2.503900679702633

Epoch: 6| Step: 10
Training loss: 1.7500918228037718
Validation loss: 2.5022585124348917

Epoch: 6| Step: 11
Training loss: 1.196746663914691
Validation loss: 2.5370355976626087

Epoch: 6| Step: 12
Training loss: 1.5582498347849814
Validation loss: 2.483684987786947

Epoch: 6| Step: 13
Training loss: 1.8254701949282577
Validation loss: 2.481966886885588

Epoch: 342| Step: 0
Training loss: 1.4391945512224227
Validation loss: 2.568358941797334

Epoch: 6| Step: 1
Training loss: 1.6513402610672505
Validation loss: 2.560534289280862

Epoch: 6| Step: 2
Training loss: 1.4514922126038126
Validation loss: 2.5595259504319845

Epoch: 6| Step: 3
Training loss: 1.7234268367987355
Validation loss: 2.586588014221266

Epoch: 6| Step: 4
Training loss: 1.1787272201715562
Validation loss: 2.5724193128333104

Epoch: 6| Step: 5
Training loss: 1.7975907600207799
Validation loss: 2.6166376855383233

Epoch: 6| Step: 6
Training loss: 1.671968689191858
Validation loss: 2.60362108746255

Epoch: 6| Step: 7
Training loss: 1.1809172126216558
Validation loss: 2.623382069750176

Epoch: 6| Step: 8
Training loss: 1.6742439955224473
Validation loss: 2.556266879746497

Epoch: 6| Step: 9
Training loss: 1.1644175967145869
Validation loss: 2.5361712304359787

Epoch: 6| Step: 10
Training loss: 1.4483495197920748
Validation loss: 2.5465385355180508

Epoch: 6| Step: 11
Training loss: 1.5410095137364959
Validation loss: 2.519728258104421

Epoch: 6| Step: 12
Training loss: 1.8273254993794545
Validation loss: 2.5466424566719263

Epoch: 6| Step: 13
Training loss: 1.9783443817412918
Validation loss: 2.5551368870306024

Epoch: 343| Step: 0
Training loss: 1.7476091401559422
Validation loss: 2.57053654862402

Epoch: 6| Step: 1
Training loss: 1.8670910926095188
Validation loss: 2.616991299539072

Epoch: 6| Step: 2
Training loss: 1.6817445445986599
Validation loss: 2.5758243969462282

Epoch: 6| Step: 3
Training loss: 1.634371802361535
Validation loss: 2.582983767536359

Epoch: 6| Step: 4
Training loss: 1.7169055405251796
Validation loss: 2.5713812046948803

Epoch: 6| Step: 5
Training loss: 1.6257593874765164
Validation loss: 2.5670463270894395

Epoch: 6| Step: 6
Training loss: 1.5763577678967573
Validation loss: 2.5436600596580767

Epoch: 6| Step: 7
Training loss: 1.2933504860681122
Validation loss: 2.5787587013165627

Epoch: 6| Step: 8
Training loss: 1.4535003505479347
Validation loss: 2.629586134233969

Epoch: 6| Step: 9
Training loss: 1.711224257593911
Validation loss: 2.648319373032986

Epoch: 6| Step: 10
Training loss: 1.0219482768905912
Validation loss: 2.6778495721131343

Epoch: 6| Step: 11
Training loss: 1.5783682909474221
Validation loss: 2.7150275664455124

Epoch: 6| Step: 12
Training loss: 1.1941272119649156
Validation loss: 2.75725599514943

Epoch: 6| Step: 13
Training loss: 1.5994151536642236
Validation loss: 2.6966114397213286

Epoch: 344| Step: 0
Training loss: 2.1502316283607743
Validation loss: 2.671610516104648

Epoch: 6| Step: 1
Training loss: 1.5975319363979172
Validation loss: 2.6553088746179485

Epoch: 6| Step: 2
Training loss: 1.0822449070384808
Validation loss: 2.6560276985643956

Epoch: 6| Step: 3
Training loss: 1.3866921005912023
Validation loss: 2.635025769420761

Epoch: 6| Step: 4
Training loss: 2.0084874543796967
Validation loss: 2.6108702374904325

Epoch: 6| Step: 5
Training loss: 1.2476560550849585
Validation loss: 2.593776227826103

Epoch: 6| Step: 6
Training loss: 1.6798382358781638
Validation loss: 2.5814962058765056

Epoch: 6| Step: 7
Training loss: 2.0455618570094747
Validation loss: 2.5774691277279076

Epoch: 6| Step: 8
Training loss: 1.147677215322352
Validation loss: 2.556891654143811

Epoch: 6| Step: 9
Training loss: 1.1353269885750705
Validation loss: 2.542301604170679

Epoch: 6| Step: 10
Training loss: 1.8651101914853305
Validation loss: 2.5460818563259395

Epoch: 6| Step: 11
Training loss: 1.4391253032089255
Validation loss: 2.563552686741742

Epoch: 6| Step: 12
Training loss: 1.2393579946054407
Validation loss: 2.5816779575466295

Epoch: 6| Step: 13
Training loss: 0.6978565137950685
Validation loss: 2.603043112930374

Epoch: 345| Step: 0
Training loss: 1.332347485543883
Validation loss: 2.6076192907304367

Epoch: 6| Step: 1
Training loss: 1.943840235734549
Validation loss: 2.641965326540346

Epoch: 6| Step: 2
Training loss: 1.6047796919358301
Validation loss: 2.6670487150061093

Epoch: 6| Step: 3
Training loss: 1.225163919808942
Validation loss: 2.6367503223177264

Epoch: 6| Step: 4
Training loss: 1.3674802194311928
Validation loss: 2.6150753247321052

Epoch: 6| Step: 5
Training loss: 1.5833955133509219
Validation loss: 2.6341921910714006

Epoch: 6| Step: 6
Training loss: 1.673236185853235
Validation loss: 2.6153833196350558

Epoch: 6| Step: 7
Training loss: 1.5095753222863726
Validation loss: 2.621487371429442

Epoch: 6| Step: 8
Training loss: 0.9889810971574067
Validation loss: 2.6138631023721004

Epoch: 6| Step: 9
Training loss: 1.7582144722681485
Validation loss: 2.585951114553395

Epoch: 6| Step: 10
Training loss: 2.0366011339415415
Validation loss: 2.6393738741567048

Epoch: 6| Step: 11
Training loss: 1.2803150580513083
Validation loss: 2.608289313833572

Epoch: 6| Step: 12
Training loss: 1.4893021573828151
Validation loss: 2.655248161327493

Epoch: 6| Step: 13
Training loss: 1.3864834008170714
Validation loss: 2.6270063846299023

Epoch: 346| Step: 0
Training loss: 1.580879300658571
Validation loss: 2.6474921565769662

Epoch: 6| Step: 1
Training loss: 1.6130592618344626
Validation loss: 2.649741497867027

Epoch: 6| Step: 2
Training loss: 1.7164134008495642
Validation loss: 2.6181044533230584

Epoch: 6| Step: 3
Training loss: 1.7473845692331695
Validation loss: 2.6285934829008837

Epoch: 6| Step: 4
Training loss: 1.5762723869409885
Validation loss: 2.6066411024516505

Epoch: 6| Step: 5
Training loss: 1.2191430460653128
Validation loss: 2.586945044549317

Epoch: 6| Step: 6
Training loss: 1.947216404452531
Validation loss: 2.5892753610263037

Epoch: 6| Step: 7
Training loss: 1.2722195845071766
Validation loss: 2.5688920738983465

Epoch: 6| Step: 8
Training loss: 1.45988973488579
Validation loss: 2.5955606368361157

Epoch: 6| Step: 9
Training loss: 1.1112625826798024
Validation loss: 2.596107805374551

Epoch: 6| Step: 10
Training loss: 1.4144155156514395
Validation loss: 2.5743487358559447

Epoch: 6| Step: 11
Training loss: 1.5839267254556155
Validation loss: 2.579141112176841

Epoch: 6| Step: 12
Training loss: 1.5847239995900577
Validation loss: 2.5819546856015023

Epoch: 6| Step: 13
Training loss: 1.6930057988075948
Validation loss: 2.519487862620006

Epoch: 347| Step: 0
Training loss: 1.1093175631416237
Validation loss: 2.5093236313847522

Epoch: 6| Step: 1
Training loss: 1.7001392195298863
Validation loss: 2.5437101737488983

Epoch: 6| Step: 2
Training loss: 1.82311847841223
Validation loss: 2.5222481679585504

Epoch: 6| Step: 3
Training loss: 1.877100721385269
Validation loss: 2.539603315613273

Epoch: 6| Step: 4
Training loss: 1.3120727752005548
Validation loss: 2.543540237988349

Epoch: 6| Step: 5
Training loss: 1.2908985817813612
Validation loss: 2.579349519865501

Epoch: 6| Step: 6
Training loss: 1.5782854357457057
Validation loss: 2.537686504281298

Epoch: 6| Step: 7
Training loss: 2.3245804192738495
Validation loss: 2.565617610968769

Epoch: 6| Step: 8
Training loss: 0.8339491396748318
Validation loss: 2.6247608893346897

Epoch: 6| Step: 9
Training loss: 1.6796282380761227
Validation loss: 2.6384974228354374

Epoch: 6| Step: 10
Training loss: 1.382465728555722
Validation loss: 2.671956364097367

Epoch: 6| Step: 11
Training loss: 1.3491721652702138
Validation loss: 2.688664723629308

Epoch: 6| Step: 12
Training loss: 1.476332469965485
Validation loss: 2.6779718421279988

Epoch: 6| Step: 13
Training loss: 1.6181989814522186
Validation loss: 2.607652487777918

Epoch: 348| Step: 0
Training loss: 1.2179754192177044
Validation loss: 2.5717850228658454

Epoch: 6| Step: 1
Training loss: 1.410134439484638
Validation loss: 2.5359377839281603

Epoch: 6| Step: 2
Training loss: 0.9541697794989793
Validation loss: 2.532132234396716

Epoch: 6| Step: 3
Training loss: 1.5371649028050072
Validation loss: 2.514323575167748

Epoch: 6| Step: 4
Training loss: 1.592183858251478
Validation loss: 2.5351814695885815

Epoch: 6| Step: 5
Training loss: 1.8611723603502284
Validation loss: 2.5469733533220467

Epoch: 6| Step: 6
Training loss: 2.0357830231995764
Validation loss: 2.5427255978142083

Epoch: 6| Step: 7
Training loss: 1.7608853079398743
Validation loss: 2.6101540565576653

Epoch: 6| Step: 8
Training loss: 1.7160582532131654
Validation loss: 2.6784873773617903

Epoch: 6| Step: 9
Training loss: 1.7292432040392178
Validation loss: 2.703852517013751

Epoch: 6| Step: 10
Training loss: 1.558221375766613
Validation loss: 2.719495371518221

Epoch: 6| Step: 11
Training loss: 1.5225013399666338
Validation loss: 2.71110538545466

Epoch: 6| Step: 12
Training loss: 1.0825592295276438
Validation loss: 2.6534225899054267

Epoch: 6| Step: 13
Training loss: 1.8567743145311277
Validation loss: 2.646159735143065

Epoch: 349| Step: 0
Training loss: 1.6104327679314856
Validation loss: 2.5962440189322677

Epoch: 6| Step: 1
Training loss: 1.1031554047714294
Validation loss: 2.59103332479746

Epoch: 6| Step: 2
Training loss: 1.7278539048310246
Validation loss: 2.5272008825030894

Epoch: 6| Step: 3
Training loss: 2.141587757878445
Validation loss: 2.5323614890482564

Epoch: 6| Step: 4
Training loss: 1.4173258014728836
Validation loss: 2.5187193042787315

Epoch: 6| Step: 5
Training loss: 1.2264574819909293
Validation loss: 2.5079320956320306

Epoch: 6| Step: 6
Training loss: 1.42821147164424
Validation loss: 2.486480140883391

Epoch: 6| Step: 7
Training loss: 1.729060028035796
Validation loss: 2.562684742540618

Epoch: 6| Step: 8
Training loss: 1.4443445211881514
Validation loss: 2.5377827710725898

Epoch: 6| Step: 9
Training loss: 0.9634159659108247
Validation loss: 2.5453725412373727

Epoch: 6| Step: 10
Training loss: 1.8938773058915719
Validation loss: 2.5519343404031343

Epoch: 6| Step: 11
Training loss: 2.2720248628115596
Validation loss: 2.532402969063044

Epoch: 6| Step: 12
Training loss: 1.4242856895631524
Validation loss: 2.5725781813969855

Epoch: 6| Step: 13
Training loss: 1.1072668003987656
Validation loss: 2.5644159365163413

Epoch: 350| Step: 0
Training loss: 0.7926885175463071
Validation loss: 2.59642455459322

Epoch: 6| Step: 1
Training loss: 1.071627512128051
Validation loss: 2.615137191003752

Epoch: 6| Step: 2
Training loss: 1.307556150919226
Validation loss: 2.646014129789325

Epoch: 6| Step: 3
Training loss: 1.769549776026607
Validation loss: 2.629228274615546

Epoch: 6| Step: 4
Training loss: 2.147149605103654
Validation loss: 2.6547893771807534

Epoch: 6| Step: 5
Training loss: 1.5266806487452358
Validation loss: 2.663279771715811

Epoch: 6| Step: 6
Training loss: 1.4106689958045375
Validation loss: 2.595420054626785

Epoch: 6| Step: 7
Training loss: 1.279777704396943
Validation loss: 2.580587301708015

Epoch: 6| Step: 8
Training loss: 1.404261051405466
Validation loss: 2.525349139949423

Epoch: 6| Step: 9
Training loss: 1.790023146005513
Validation loss: 2.4972938514123486

Epoch: 6| Step: 10
Training loss: 1.331139319031999
Validation loss: 2.4435441648362257

Epoch: 6| Step: 11
Training loss: 1.8250648121233743
Validation loss: 2.4973432570496374

Epoch: 6| Step: 12
Training loss: 1.8375361198975384
Validation loss: 2.462965243906013

Epoch: 6| Step: 13
Training loss: 2.1455539286904886
Validation loss: 2.4742669056979114

Epoch: 351| Step: 0
Training loss: 1.2099273406037263
Validation loss: 2.512340620941947

Epoch: 6| Step: 1
Training loss: 1.8457834700601172
Validation loss: 2.5396461168205384

Epoch: 6| Step: 2
Training loss: 1.6354738294326305
Validation loss: 2.5503173998347144

Epoch: 6| Step: 3
Training loss: 1.9337764769247556
Validation loss: 2.52223277589249

Epoch: 6| Step: 4
Training loss: 1.6451191700725618
Validation loss: 2.555983040882715

Epoch: 6| Step: 5
Training loss: 1.7313507105871233
Validation loss: 2.5491982377653617

Epoch: 6| Step: 6
Training loss: 1.2890668464356174
Validation loss: 2.5294739414523426

Epoch: 6| Step: 7
Training loss: 1.3323002428977269
Validation loss: 2.5073032991155046

Epoch: 6| Step: 8
Training loss: 1.4393873678480227
Validation loss: 2.513133123916439

Epoch: 6| Step: 9
Training loss: 1.0086288103293337
Validation loss: 2.551928135311453

Epoch: 6| Step: 10
Training loss: 1.2797793810676639
Validation loss: 2.5655831498121944

Epoch: 6| Step: 11
Training loss: 1.3588498734561956
Validation loss: 2.5835733968699945

Epoch: 6| Step: 12
Training loss: 1.8702009456194406
Validation loss: 2.5548801952175917

Epoch: 6| Step: 13
Training loss: 1.4627980507257423
Validation loss: 2.581654069507354

Epoch: 352| Step: 0
Training loss: 1.4988046492666107
Validation loss: 2.5908526588603427

Epoch: 6| Step: 1
Training loss: 1.6755793523208837
Validation loss: 2.534873550867846

Epoch: 6| Step: 2
Training loss: 0.9514813556117385
Validation loss: 2.5258640239952386

Epoch: 6| Step: 3
Training loss: 1.2240079288038865
Validation loss: 2.553881161172589

Epoch: 6| Step: 4
Training loss: 1.1151489652673936
Validation loss: 2.5251863952175566

Epoch: 6| Step: 5
Training loss: 1.4205665017136704
Validation loss: 2.522719108749018

Epoch: 6| Step: 6
Training loss: 0.988650889872916
Validation loss: 2.586658312015543

Epoch: 6| Step: 7
Training loss: 1.7289270978067988
Validation loss: 2.5392603635720135

Epoch: 6| Step: 8
Training loss: 1.6048702414518075
Validation loss: 2.512546306075845

Epoch: 6| Step: 9
Training loss: 1.0700212068327895
Validation loss: 2.5513625599815457

Epoch: 6| Step: 10
Training loss: 1.4697173159489034
Validation loss: 2.584708729560186

Epoch: 6| Step: 11
Training loss: 2.045539478503819
Validation loss: 2.6198399402172616

Epoch: 6| Step: 12
Training loss: 1.9379348882084941
Validation loss: 2.6161842359068053

Epoch: 6| Step: 13
Training loss: 1.3745316661518834
Validation loss: 2.6318168681910037

Epoch: 353| Step: 0
Training loss: 1.0640256810925262
Validation loss: 2.624201191355745

Epoch: 6| Step: 1
Training loss: 1.2927338078417427
Validation loss: 2.608250465132935

Epoch: 6| Step: 2
Training loss: 1.1916318085825197
Validation loss: 2.6298763153717397

Epoch: 6| Step: 3
Training loss: 1.9590462002644318
Validation loss: 2.611343334289707

Epoch: 6| Step: 4
Training loss: 2.112901240960574
Validation loss: 2.5618461612102874

Epoch: 6| Step: 5
Training loss: 1.2005207561015714
Validation loss: 2.5808016513123486

Epoch: 6| Step: 6
Training loss: 0.6941331870518292
Validation loss: 2.58708787667536

Epoch: 6| Step: 7
Training loss: 1.9800610244864443
Validation loss: 2.5458371752904028

Epoch: 6| Step: 8
Training loss: 1.5959686842740592
Validation loss: 2.5781577445368686

Epoch: 6| Step: 9
Training loss: 1.1412559227512928
Validation loss: 2.578488719214015

Epoch: 6| Step: 10
Training loss: 1.2157962903939614
Validation loss: 2.5704493925827245

Epoch: 6| Step: 11
Training loss: 1.486393249127648
Validation loss: 2.573974690423295

Epoch: 6| Step: 12
Training loss: 1.3126280585895356
Validation loss: 2.5940813672528047

Epoch: 6| Step: 13
Training loss: 1.325375707010039
Validation loss: 2.5885088871825475

Epoch: 354| Step: 0
Training loss: 1.1447596403483713
Validation loss: 2.666044853152702

Epoch: 6| Step: 1
Training loss: 1.5764144086896041
Validation loss: 2.6051790151633076

Epoch: 6| Step: 2
Training loss: 1.2029260743401706
Validation loss: 2.601070712692106

Epoch: 6| Step: 3
Training loss: 1.5059651338915754
Validation loss: 2.585182594525532

Epoch: 6| Step: 4
Training loss: 1.4755356058641802
Validation loss: 2.5592402371864416

Epoch: 6| Step: 5
Training loss: 1.3293622705077008
Validation loss: 2.590836201990633

Epoch: 6| Step: 6
Training loss: 1.5273798867558086
Validation loss: 2.608887937244319

Epoch: 6| Step: 7
Training loss: 1.4747382303490266
Validation loss: 2.6012294124562754

Epoch: 6| Step: 8
Training loss: 1.3722374647961042
Validation loss: 2.5765017398774313

Epoch: 6| Step: 9
Training loss: 1.6852791618899126
Validation loss: 2.586417915150316

Epoch: 6| Step: 10
Training loss: 0.9512698771220883
Validation loss: 2.550514717450455

Epoch: 6| Step: 11
Training loss: 1.58642014549149
Validation loss: 2.570599757320304

Epoch: 6| Step: 12
Training loss: 1.697347096901043
Validation loss: 2.5684612684259767

Epoch: 6| Step: 13
Training loss: 1.1006159943315628
Validation loss: 2.552573275085673

Epoch: 355| Step: 0
Training loss: 1.2399619456573927
Validation loss: 2.5771291485607013

Epoch: 6| Step: 1
Training loss: 0.8475528073808342
Validation loss: 2.5673844531046646

Epoch: 6| Step: 2
Training loss: 1.1930684985395166
Validation loss: 2.5193808971560925

Epoch: 6| Step: 3
Training loss: 1.7061342025420334
Validation loss: 2.5759446605697156

Epoch: 6| Step: 4
Training loss: 1.949222847546263
Validation loss: 2.570968698763833

Epoch: 6| Step: 5
Training loss: 1.172409444374353
Validation loss: 2.5694970071130236

Epoch: 6| Step: 6
Training loss: 1.1431933710957853
Validation loss: 2.5736900639545275

Epoch: 6| Step: 7
Training loss: 1.248874061844517
Validation loss: 2.557020150951241

Epoch: 6| Step: 8
Training loss: 1.5062776175218708
Validation loss: 2.577397191747345

Epoch: 6| Step: 9
Training loss: 1.7485828110870254
Validation loss: 2.573481468160147

Epoch: 6| Step: 10
Training loss: 1.4444263938036785
Validation loss: 2.570284347611901

Epoch: 6| Step: 11
Training loss: 1.5917559846646019
Validation loss: 2.605785375417489

Epoch: 6| Step: 12
Training loss: 1.2193025656830274
Validation loss: 2.5929131287649683

Epoch: 6| Step: 13
Training loss: 1.365191239315417
Validation loss: 2.6181745651093276

Epoch: 356| Step: 0
Training loss: 1.2256922459184898
Validation loss: 2.6158517038170785

Epoch: 6| Step: 1
Training loss: 1.8330134054839418
Validation loss: 2.658284758081156

Epoch: 6| Step: 2
Training loss: 1.2510508888194818
Validation loss: 2.702177877740252

Epoch: 6| Step: 3
Training loss: 1.121996154193781
Validation loss: 2.685566317401213

Epoch: 6| Step: 4
Training loss: 1.329021555155289
Validation loss: 2.6855647046046394

Epoch: 6| Step: 5
Training loss: 1.2019789550703486
Validation loss: 2.5947583241708823

Epoch: 6| Step: 6
Training loss: 1.4848923434142125
Validation loss: 2.6571173205591534

Epoch: 6| Step: 7
Training loss: 1.454064998333521
Validation loss: 2.608984531570691

Epoch: 6| Step: 8
Training loss: 1.4337331927510837
Validation loss: 2.5938578357264364

Epoch: 6| Step: 9
Training loss: 1.19443534630753
Validation loss: 2.6017420480532767

Epoch: 6| Step: 10
Training loss: 2.348853696084094
Validation loss: 2.5922703333292145

Epoch: 6| Step: 11
Training loss: 1.8813974595179355
Validation loss: 2.5808010970227047

Epoch: 6| Step: 12
Training loss: 1.0955153251631107
Validation loss: 2.6015864037989744

Epoch: 6| Step: 13
Training loss: 2.275617779702223
Validation loss: 2.5921645776840023

Epoch: 357| Step: 0
Training loss: 1.9364530134068123
Validation loss: 2.5669841531810036

Epoch: 6| Step: 1
Training loss: 1.199813744872363
Validation loss: 2.5832743073970073

Epoch: 6| Step: 2
Training loss: 1.3362186426064409
Validation loss: 2.60845131429522

Epoch: 6| Step: 3
Training loss: 1.4678037314166261
Validation loss: 2.6526596338172954

Epoch: 6| Step: 4
Training loss: 1.5317817076247655
Validation loss: 2.6301832946995605

Epoch: 6| Step: 5
Training loss: 1.7708829386626008
Validation loss: 2.6527103101484855

Epoch: 6| Step: 6
Training loss: 1.5486706416724552
Validation loss: 2.6856497672050654

Epoch: 6| Step: 7
Training loss: 1.2385886980927983
Validation loss: 2.649100776669734

Epoch: 6| Step: 8
Training loss: 1.3681811400388502
Validation loss: 2.596591970457294

Epoch: 6| Step: 9
Training loss: 1.8577822747751551
Validation loss: 2.5609442477460296

Epoch: 6| Step: 10
Training loss: 1.6857328699071223
Validation loss: 2.566155330908013

Epoch: 6| Step: 11
Training loss: 1.1984093136811296
Validation loss: 2.553755579522365

Epoch: 6| Step: 12
Training loss: 1.0756066806082132
Validation loss: 2.582700672409595

Epoch: 6| Step: 13
Training loss: 1.5888943473496893
Validation loss: 2.5594519498418

Epoch: 358| Step: 0
Training loss: 1.2830429557810583
Validation loss: 2.5787668450292744

Epoch: 6| Step: 1
Training loss: 1.062281193362074
Validation loss: 2.584348699519673

Epoch: 6| Step: 2
Training loss: 1.258718318445807
Validation loss: 2.6034120814306236

Epoch: 6| Step: 3
Training loss: 1.4688386281645711
Validation loss: 2.6050115257540263

Epoch: 6| Step: 4
Training loss: 1.43959713426407
Validation loss: 2.594368550644782

Epoch: 6| Step: 5
Training loss: 1.4674161170237632
Validation loss: 2.608353374838894

Epoch: 6| Step: 6
Training loss: 1.7607493641094039
Validation loss: 2.6149922743878293

Epoch: 6| Step: 7
Training loss: 1.6923098364062832
Validation loss: 2.62391578142091

Epoch: 6| Step: 8
Training loss: 1.4366079962950649
Validation loss: 2.569206123354276

Epoch: 6| Step: 9
Training loss: 1.558546251993004
Validation loss: 2.6450030508426408

Epoch: 6| Step: 10
Training loss: 1.8907349609680764
Validation loss: 2.6064157209149394

Epoch: 6| Step: 11
Training loss: 1.4046812844483678
Validation loss: 2.5996111328363627

Epoch: 6| Step: 12
Training loss: 1.1752065477029108
Validation loss: 2.556386851010633

Epoch: 6| Step: 13
Training loss: 0.9710139001623364
Validation loss: 2.5694698664693485

Epoch: 359| Step: 0
Training loss: 1.9222328659208843
Validation loss: 2.5572021427269083

Epoch: 6| Step: 1
Training loss: 1.3135130923271776
Validation loss: 2.523384211777712

Epoch: 6| Step: 2
Training loss: 1.4590528438899764
Validation loss: 2.5669479069473544

Epoch: 6| Step: 3
Training loss: 1.3482171701925525
Validation loss: 2.526392274625594

Epoch: 6| Step: 4
Training loss: 0.9024096708452509
Validation loss: 2.5760224988085167

Epoch: 6| Step: 5
Training loss: 1.5408982690332427
Validation loss: 2.565371323565264

Epoch: 6| Step: 6
Training loss: 1.558476570332669
Validation loss: 2.565789615555595

Epoch: 6| Step: 7
Training loss: 1.1110810070463157
Validation loss: 2.574367196680245

Epoch: 6| Step: 8
Training loss: 1.726849355213829
Validation loss: 2.5760606457825705

Epoch: 6| Step: 9
Training loss: 1.5118679396869366
Validation loss: 2.5472489454970026

Epoch: 6| Step: 10
Training loss: 1.3449873439377722
Validation loss: 2.561841864699254

Epoch: 6| Step: 11
Training loss: 0.9470311454718765
Validation loss: 2.629091449957375

Epoch: 6| Step: 12
Training loss: 1.4137429144940623
Validation loss: 2.5804041334780323

Epoch: 6| Step: 13
Training loss: 1.5414514735103981
Validation loss: 2.5930273589027064

Epoch: 360| Step: 0
Training loss: 1.7638426705393555
Validation loss: 2.6021623349521925

Epoch: 6| Step: 1
Training loss: 1.2926142918359274
Validation loss: 2.596122093631422

Epoch: 6| Step: 2
Training loss: 1.1405131141447133
Validation loss: 2.5855904583509806

Epoch: 6| Step: 3
Training loss: 1.4042147425374385
Validation loss: 2.573828536903131

Epoch: 6| Step: 4
Training loss: 1.3578760937722587
Validation loss: 2.5921993599486792

Epoch: 6| Step: 5
Training loss: 1.2278723556364257
Validation loss: 2.5217857505765457

Epoch: 6| Step: 6
Training loss: 1.645751065801617
Validation loss: 2.5073731731822275

Epoch: 6| Step: 7
Training loss: 0.9836500616823324
Validation loss: 2.5223193136882314

Epoch: 6| Step: 8
Training loss: 1.287530578324233
Validation loss: 2.596550834856968

Epoch: 6| Step: 9
Training loss: 1.7327742879384707
Validation loss: 2.5248867554024494

Epoch: 6| Step: 10
Training loss: 1.166406818244116
Validation loss: 2.5674800165173166

Epoch: 6| Step: 11
Training loss: 1.0836956567570062
Validation loss: 2.5832961961681513

Epoch: 6| Step: 12
Training loss: 0.9984717015481307
Validation loss: 2.570688423099627

Epoch: 6| Step: 13
Training loss: 2.0734843590162337
Validation loss: 2.589468597505528

Epoch: 361| Step: 0
Training loss: 1.06317212780211
Validation loss: 2.5940808311188173

Epoch: 6| Step: 1
Training loss: 1.686679075268321
Validation loss: 2.612793257709797

Epoch: 6| Step: 2
Training loss: 1.3765523990256177
Validation loss: 2.6447678220219157

Epoch: 6| Step: 3
Training loss: 1.5387699217014166
Validation loss: 2.5903781207242162

Epoch: 6| Step: 4
Training loss: 1.404065745808636
Validation loss: 2.583889990995694

Epoch: 6| Step: 5
Training loss: 1.2169369636829515
Validation loss: 2.535867098624129

Epoch: 6| Step: 6
Training loss: 1.5535254040996116
Validation loss: 2.533507686395794

Epoch: 6| Step: 7
Training loss: 1.4621979686853916
Validation loss: 2.4879965546937783

Epoch: 6| Step: 8
Training loss: 1.0294063734266008
Validation loss: 2.5202984176655394

Epoch: 6| Step: 9
Training loss: 1.0046229791168813
Validation loss: 2.504083175875327

Epoch: 6| Step: 10
Training loss: 1.72797484478478
Validation loss: 2.4826262615271015

Epoch: 6| Step: 11
Training loss: 1.3864096283567864
Validation loss: 2.5532664819719115

Epoch: 6| Step: 12
Training loss: 1.4157743261538667
Validation loss: 2.5644703244913036

Epoch: 6| Step: 13
Training loss: 0.9660326470688979
Validation loss: 2.527649724835218

Epoch: 362| Step: 0
Training loss: 0.9131097637474588
Validation loss: 2.5507253082824066

Epoch: 6| Step: 1
Training loss: 1.2191918379157485
Validation loss: 2.5792348303181605

Epoch: 6| Step: 2
Training loss: 1.6072748796035905
Validation loss: 2.584212758492693

Epoch: 6| Step: 3
Training loss: 0.9201060959032678
Validation loss: 2.5659647058065125

Epoch: 6| Step: 4
Training loss: 1.3203302416089102
Validation loss: 2.5647102686077146

Epoch: 6| Step: 5
Training loss: 1.1619958645817612
Validation loss: 2.5492827067339436

Epoch: 6| Step: 6
Training loss: 1.2177381961620855
Validation loss: 2.528645380231592

Epoch: 6| Step: 7
Training loss: 1.706278480040578
Validation loss: 2.562491719302312

Epoch: 6| Step: 8
Training loss: 1.237582758823849
Validation loss: 2.5831634839939523

Epoch: 6| Step: 9
Training loss: 1.4430022875529112
Validation loss: 2.576952334266007

Epoch: 6| Step: 10
Training loss: 1.5201381853935683
Validation loss: 2.5629820331524704

Epoch: 6| Step: 11
Training loss: 1.2430401640684443
Validation loss: 2.647501417165058

Epoch: 6| Step: 12
Training loss: 1.7843640863248504
Validation loss: 2.680552351383629

Epoch: 6| Step: 13
Training loss: 1.8096749223506858
Validation loss: 2.6770773539989703

Epoch: 363| Step: 0
Training loss: 1.0639866918147458
Validation loss: 2.597148155294127

Epoch: 6| Step: 1
Training loss: 1.2202472781678715
Validation loss: 2.5572936659505348

Epoch: 6| Step: 2
Training loss: 1.1631518392525613
Validation loss: 2.548703448095127

Epoch: 6| Step: 3
Training loss: 1.3359650726149963
Validation loss: 2.581531193451842

Epoch: 6| Step: 4
Training loss: 1.4421738645626059
Validation loss: 2.530380264435798

Epoch: 6| Step: 5
Training loss: 1.1240662832570298
Validation loss: 2.5726321805725227

Epoch: 6| Step: 6
Training loss: 1.1379438791800724
Validation loss: 2.548996383160589

Epoch: 6| Step: 7
Training loss: 1.2261240473154469
Validation loss: 2.5499687828696294

Epoch: 6| Step: 8
Training loss: 1.3852208173562868
Validation loss: 2.5025439829078215

Epoch: 6| Step: 9
Training loss: 1.1798816041225086
Validation loss: 2.579336371151432

Epoch: 6| Step: 10
Training loss: 1.8364853711084355
Validation loss: 2.591482404514317

Epoch: 6| Step: 11
Training loss: 2.060028907795264
Validation loss: 2.5819288763468746

Epoch: 6| Step: 12
Training loss: 1.0195220128368065
Validation loss: 2.598922459132432

Epoch: 6| Step: 13
Training loss: 1.3989769092423876
Validation loss: 2.5759887475978327

Epoch: 364| Step: 0
Training loss: 1.3747632082873305
Validation loss: 2.6189649628728864

Epoch: 6| Step: 1
Training loss: 1.0101567291235027
Validation loss: 2.667337651077713

Epoch: 6| Step: 2
Training loss: 1.4240206783164875
Validation loss: 2.729136071264176

Epoch: 6| Step: 3
Training loss: 1.0315071132227889
Validation loss: 2.6764581200087947

Epoch: 6| Step: 4
Training loss: 1.5023430961651105
Validation loss: 2.6339597984969054

Epoch: 6| Step: 5
Training loss: 1.209596543633604
Validation loss: 2.580270310048875

Epoch: 6| Step: 6
Training loss: 1.6126931067469323
Validation loss: 2.5209657671060697

Epoch: 6| Step: 7
Training loss: 1.4098076640494004
Validation loss: 2.5149087537818002

Epoch: 6| Step: 8
Training loss: 1.4247240301236301
Validation loss: 2.486903713073662

Epoch: 6| Step: 9
Training loss: 1.297552552233903
Validation loss: 2.504171388169935

Epoch: 6| Step: 10
Training loss: 1.8016241587453805
Validation loss: 2.5450019735991916

Epoch: 6| Step: 11
Training loss: 1.4064375858229727
Validation loss: 2.539359692517943

Epoch: 6| Step: 12
Training loss: 1.1984109549834026
Validation loss: 2.5880076409521413

Epoch: 6| Step: 13
Training loss: 1.5200433726145832
Validation loss: 2.631065702289048

Epoch: 365| Step: 0
Training loss: 1.2471351218354323
Validation loss: 2.6276448564557824

Epoch: 6| Step: 1
Training loss: 1.7794991973849419
Validation loss: 2.6862264765103983

Epoch: 6| Step: 2
Training loss: 1.0285881831113954
Validation loss: 2.6829634531958293

Epoch: 6| Step: 3
Training loss: 1.4707433282187616
Validation loss: 2.7340651127648012

Epoch: 6| Step: 4
Training loss: 1.3439103851414407
Validation loss: 2.6977637602337

Epoch: 6| Step: 5
Training loss: 1.3005369031364231
Validation loss: 2.6591377119565847

Epoch: 6| Step: 6
Training loss: 1.3751282632132105
Validation loss: 2.59858585254548

Epoch: 6| Step: 7
Training loss: 1.2853675830853
Validation loss: 2.616052242799535

Epoch: 6| Step: 8
Training loss: 0.8511558401655329
Validation loss: 2.535283881424446

Epoch: 6| Step: 9
Training loss: 1.5180335030558931
Validation loss: 2.535136171329025

Epoch: 6| Step: 10
Training loss: 1.194481155412925
Validation loss: 2.560672573609488

Epoch: 6| Step: 11
Training loss: 1.4578445251152707
Validation loss: 2.556214120452954

Epoch: 6| Step: 12
Training loss: 1.5704635623371406
Validation loss: 2.6017603068715287

Epoch: 6| Step: 13
Training loss: 1.0861845764545763
Validation loss: 2.5887767344736288

Epoch: 366| Step: 0
Training loss: 1.3737112421290396
Validation loss: 2.549152970349456

Epoch: 6| Step: 1
Training loss: 1.216815195205935
Validation loss: 2.5829081390514133

Epoch: 6| Step: 2
Training loss: 1.2223806344793884
Validation loss: 2.585042239568985

Epoch: 6| Step: 3
Training loss: 1.1764292404678485
Validation loss: 2.6171872418911173

Epoch: 6| Step: 4
Training loss: 1.2047375857854887
Validation loss: 2.6376221416087837

Epoch: 6| Step: 5
Training loss: 1.581247846880868
Validation loss: 2.5955510378357176

Epoch: 6| Step: 6
Training loss: 0.8770636338100418
Validation loss: 2.5965723209437934

Epoch: 6| Step: 7
Training loss: 0.9329768101630405
Validation loss: 2.5499029589869187

Epoch: 6| Step: 8
Training loss: 0.7462525922643982
Validation loss: 2.6281240961448997

Epoch: 6| Step: 9
Training loss: 1.6056779785444124
Validation loss: 2.62643650652143

Epoch: 6| Step: 10
Training loss: 1.2732306002238698
Validation loss: 2.614517459318172

Epoch: 6| Step: 11
Training loss: 1.5309331137848763
Validation loss: 2.598326479462529

Epoch: 6| Step: 12
Training loss: 1.6026241598368818
Validation loss: 2.5942842324005393

Epoch: 6| Step: 13
Training loss: 1.3498285008039508
Validation loss: 2.5528696107540862

Epoch: 367| Step: 0
Training loss: 1.2455392877514777
Validation loss: 2.5113687780660543

Epoch: 6| Step: 1
Training loss: 1.194833796766371
Validation loss: 2.5358940974775788

Epoch: 6| Step: 2
Training loss: 1.2105749756615647
Validation loss: 2.519945702977021

Epoch: 6| Step: 3
Training loss: 1.4940269277359666
Validation loss: 2.5083545641671243

Epoch: 6| Step: 4
Training loss: 0.8647061149708288
Validation loss: 2.513862450485819

Epoch: 6| Step: 5
Training loss: 1.1714085985933338
Validation loss: 2.532008602924205

Epoch: 6| Step: 6
Training loss: 0.7479761951809925
Validation loss: 2.5378697493938707

Epoch: 6| Step: 7
Training loss: 1.6900828340082406
Validation loss: 2.5145730530139683

Epoch: 6| Step: 8
Training loss: 1.1327476745999188
Validation loss: 2.547303021433403

Epoch: 6| Step: 9
Training loss: 1.477046745862256
Validation loss: 2.5799821118170843

Epoch: 6| Step: 10
Training loss: 1.058051051143068
Validation loss: 2.594066248231848

Epoch: 6| Step: 11
Training loss: 1.3970648139494497
Validation loss: 2.578475342653428

Epoch: 6| Step: 12
Training loss: 1.5006299285617082
Validation loss: 2.523574069552632

Epoch: 6| Step: 13
Training loss: 1.047622641437526
Validation loss: 2.567241778489673

Epoch: 368| Step: 0
Training loss: 0.9403226955947548
Validation loss: 2.567374857100249

Epoch: 6| Step: 1
Training loss: 1.1106439774093515
Validation loss: 2.5509945681424533

Epoch: 6| Step: 2
Training loss: 0.6186971189076985
Validation loss: 2.577151382481226

Epoch: 6| Step: 3
Training loss: 1.931773490694806
Validation loss: 2.558738576269995

Epoch: 6| Step: 4
Training loss: 1.0950055137042574
Validation loss: 2.541756961865379

Epoch: 6| Step: 5
Training loss: 1.0256769271062978
Validation loss: 2.566856573147236

Epoch: 6| Step: 6
Training loss: 1.205340686060062
Validation loss: 2.505760058097161

Epoch: 6| Step: 7
Training loss: 1.0191043822459218
Validation loss: 2.534478346241919

Epoch: 6| Step: 8
Training loss: 1.4931775548411421
Validation loss: 2.4989568759351592

Epoch: 6| Step: 9
Training loss: 1.409947007312965
Validation loss: 2.5513847848269338

Epoch: 6| Step: 10
Training loss: 1.2543335183682705
Validation loss: 2.6238139212862177

Epoch: 6| Step: 11
Training loss: 1.4147510854201562
Validation loss: 2.625167523442705

Epoch: 6| Step: 12
Training loss: 1.291600728146468
Validation loss: 2.6966147110424936

Epoch: 6| Step: 13
Training loss: 1.5959051184116981
Validation loss: 2.6236670152281643

Epoch: 369| Step: 0
Training loss: 1.375432033289265
Validation loss: 2.6688838523155853

Epoch: 6| Step: 1
Training loss: 1.3849851275585416
Validation loss: 2.6317688545920697

Epoch: 6| Step: 2
Training loss: 0.9846842749230182
Validation loss: 2.6317516117588067

Epoch: 6| Step: 3
Training loss: 1.2459450755619763
Validation loss: 2.6014692807226263

Epoch: 6| Step: 4
Training loss: 2.124571252092644
Validation loss: 2.580531859850853

Epoch: 6| Step: 5
Training loss: 1.0144074404377434
Validation loss: 2.543650100770873

Epoch: 6| Step: 6
Training loss: 1.5931808352946615
Validation loss: 2.551014194883189

Epoch: 6| Step: 7
Training loss: 1.5160172731527695
Validation loss: 2.5205228997968394

Epoch: 6| Step: 8
Training loss: 0.9054614615620167
Validation loss: 2.497236178442467

Epoch: 6| Step: 9
Training loss: 1.3302974212057157
Validation loss: 2.4569745403430665

Epoch: 6| Step: 10
Training loss: 1.2148675946903778
Validation loss: 2.4961896150633627

Epoch: 6| Step: 11
Training loss: 0.7815006998270114
Validation loss: 2.47156967225712

Epoch: 6| Step: 12
Training loss: 1.6598269865347057
Validation loss: 2.512980759586099

Epoch: 6| Step: 13
Training loss: 1.166866739465522
Validation loss: 2.5071459128902402

Epoch: 370| Step: 0
Training loss: 1.2819357176805461
Validation loss: 2.544123866282141

Epoch: 6| Step: 1
Training loss: 1.1193304250458618
Validation loss: 2.6012996353676106

Epoch: 6| Step: 2
Training loss: 1.3265383948482576
Validation loss: 2.5875975321695193

Epoch: 6| Step: 3
Training loss: 1.278300449109187
Validation loss: 2.6171680506652555

Epoch: 6| Step: 4
Training loss: 0.9972501736380425
Validation loss: 2.5885710276442286

Epoch: 6| Step: 5
Training loss: 1.9829003569345096
Validation loss: 2.6029938968953763

Epoch: 6| Step: 6
Training loss: 1.197230875279507
Validation loss: 2.5766726246485683

Epoch: 6| Step: 7
Training loss: 1.3645935737672124
Validation loss: 2.5894203818117414

Epoch: 6| Step: 8
Training loss: 1.1172985741945143
Validation loss: 2.5724172892618298

Epoch: 6| Step: 9
Training loss: 1.0814116869744166
Validation loss: 2.5772944490085052

Epoch: 6| Step: 10
Training loss: 1.0033030794552484
Validation loss: 2.627706986310043

Epoch: 6| Step: 11
Training loss: 1.1187813866330902
Validation loss: 2.6228134191511376

Epoch: 6| Step: 12
Training loss: 1.3637259121593581
Validation loss: 2.6401295996653986

Epoch: 6| Step: 13
Training loss: 1.0866035230307407
Validation loss: 2.5898559017673057

Epoch: 371| Step: 0
Training loss: 1.2867193484927408
Validation loss: 2.598974336155694

Epoch: 6| Step: 1
Training loss: 1.2515045647897962
Validation loss: 2.5732158430320484

Epoch: 6| Step: 2
Training loss: 1.5324412791715338
Validation loss: 2.5115602402730106

Epoch: 6| Step: 3
Training loss: 1.863102038580147
Validation loss: 2.5515562382512407

Epoch: 6| Step: 4
Training loss: 1.1464381038030096
Validation loss: 2.522804157153978

Epoch: 6| Step: 5
Training loss: 0.829573174769998
Validation loss: 2.603718884435229

Epoch: 6| Step: 6
Training loss: 0.7446609640256003
Validation loss: 2.5856990723499838

Epoch: 6| Step: 7
Training loss: 1.3261019389121165
Validation loss: 2.6109080122921076

Epoch: 6| Step: 8
Training loss: 1.3001146412698905
Validation loss: 2.5732382960715356

Epoch: 6| Step: 9
Training loss: 1.0057866042395982
Validation loss: 2.5841644139809516

Epoch: 6| Step: 10
Training loss: 1.4432024425215257
Validation loss: 2.5760759167541663

Epoch: 6| Step: 11
Training loss: 0.8620141167292393
Validation loss: 2.5842885333122183

Epoch: 6| Step: 12
Training loss: 1.3739588003131264
Validation loss: 2.5767436787182407

Epoch: 6| Step: 13
Training loss: 1.2683577997769417
Validation loss: 2.5534692128366343

Epoch: 372| Step: 0
Training loss: 0.9728779980464903
Validation loss: 2.5818917087201116

Epoch: 6| Step: 1
Training loss: 0.9682437435295698
Validation loss: 2.611612955412182

Epoch: 6| Step: 2
Training loss: 1.2071549929301444
Validation loss: 2.580218826989242

Epoch: 6| Step: 3
Training loss: 1.1800706253899396
Validation loss: 2.5544580945714075

Epoch: 6| Step: 4
Training loss: 1.152969190620972
Validation loss: 2.6234097810833026

Epoch: 6| Step: 5
Training loss: 1.064608557315814
Validation loss: 2.5472568623544602

Epoch: 6| Step: 6
Training loss: 1.1593830858961418
Validation loss: 2.5943337361959826

Epoch: 6| Step: 7
Training loss: 1.195094668417315
Validation loss: 2.6067672688818364

Epoch: 6| Step: 8
Training loss: 1.6356190922666507
Validation loss: 2.6396565363688342

Epoch: 6| Step: 9
Training loss: 0.9498231949161101
Validation loss: 2.6031196981912625

Epoch: 6| Step: 10
Training loss: 1.3392443859444823
Validation loss: 2.597834607265861

Epoch: 6| Step: 11
Training loss: 0.6355142023448924
Validation loss: 2.5460351444634575

Epoch: 6| Step: 12
Training loss: 1.8897237600055832
Validation loss: 2.5696097343708777

Epoch: 6| Step: 13
Training loss: 1.6168131371966188
Validation loss: 2.570674001206755

Epoch: 373| Step: 0
Training loss: 1.4979637948564324
Validation loss: 2.596486941774822

Epoch: 6| Step: 1
Training loss: 1.5423435151590101
Validation loss: 2.5825336561936467

Epoch: 6| Step: 2
Training loss: 0.8525227723198446
Validation loss: 2.587314235389063

Epoch: 6| Step: 3
Training loss: 1.3923935948507025
Validation loss: 2.59750719144705

Epoch: 6| Step: 4
Training loss: 1.0542766194554944
Validation loss: 2.63437419874753

Epoch: 6| Step: 5
Training loss: 1.1232475831179636
Validation loss: 2.6663311111409778

Epoch: 6| Step: 6
Training loss: 0.9310930030129668
Validation loss: 2.7020918207518125

Epoch: 6| Step: 7
Training loss: 1.3514459813337922
Validation loss: 2.683510354720702

Epoch: 6| Step: 8
Training loss: 1.2317886781374414
Validation loss: 2.6387070305941482

Epoch: 6| Step: 9
Training loss: 1.3159388043341222
Validation loss: 2.5793865700700955

Epoch: 6| Step: 10
Training loss: 1.0241236825173488
Validation loss: 2.512322858952154

Epoch: 6| Step: 11
Training loss: 1.147762385602931
Validation loss: 2.5213545005675715

Epoch: 6| Step: 12
Training loss: 1.9385981370291008
Validation loss: 2.4870435509993927

Epoch: 6| Step: 13
Training loss: 1.406761288413365
Validation loss: 2.5435074461721783

Epoch: 374| Step: 0
Training loss: 1.3011662826944708
Validation loss: 2.5036588597195206

Epoch: 6| Step: 1
Training loss: 1.3953307181575476
Validation loss: 2.520138815633993

Epoch: 6| Step: 2
Training loss: 1.626180366825654
Validation loss: 2.609224783405392

Epoch: 6| Step: 3
Training loss: 1.4506715962142729
Validation loss: 2.5812976466377364

Epoch: 6| Step: 4
Training loss: 1.2700697945016954
Validation loss: 2.6710842367818994

Epoch: 6| Step: 5
Training loss: 1.3215514921215652
Validation loss: 2.695669723648005

Epoch: 6| Step: 6
Training loss: 1.2587343238074142
Validation loss: 2.7328530717342296

Epoch: 6| Step: 7
Training loss: 1.1692616632975636
Validation loss: 2.6712880967904

Epoch: 6| Step: 8
Training loss: 1.0874226794763002
Validation loss: 2.6265056470065553

Epoch: 6| Step: 9
Training loss: 1.0359395644223455
Validation loss: 2.6456974975880545

Epoch: 6| Step: 10
Training loss: 1.3318161776803064
Validation loss: 2.6084957659258463

Epoch: 6| Step: 11
Training loss: 1.4222023555656176
Validation loss: 2.5912964334604522

Epoch: 6| Step: 12
Training loss: 1.2837507452586536
Validation loss: 2.5564096072982245

Epoch: 6| Step: 13
Training loss: 1.054056162313255
Validation loss: 2.556310824266733

Epoch: 375| Step: 0
Training loss: 1.7282389101422828
Validation loss: 2.5185162769478544

Epoch: 6| Step: 1
Training loss: 1.1374325952365991
Validation loss: 2.5251827208499384

Epoch: 6| Step: 2
Training loss: 0.777044574156158
Validation loss: 2.573611861812864

Epoch: 6| Step: 3
Training loss: 1.2069618674277758
Validation loss: 2.5475005335334617

Epoch: 6| Step: 4
Training loss: 1.2046577796288052
Validation loss: 2.5382840259177155

Epoch: 6| Step: 5
Training loss: 0.8355165295041603
Validation loss: 2.5744541274781216

Epoch: 6| Step: 6
Training loss: 1.849695930751761
Validation loss: 2.608590470660703

Epoch: 6| Step: 7
Training loss: 0.8206818975057362
Validation loss: 2.6149556070988234

Epoch: 6| Step: 8
Training loss: 0.8875530871780032
Validation loss: 2.6971186239415847

Epoch: 6| Step: 9
Training loss: 1.1706189354099428
Validation loss: 2.691062591566672

Epoch: 6| Step: 10
Training loss: 1.0248131860897194
Validation loss: 2.645712847231594

Epoch: 6| Step: 11
Training loss: 1.5382899170297675
Validation loss: 2.6703790711805757

Epoch: 6| Step: 12
Training loss: 1.132090687162186
Validation loss: 2.5808023133803784

Epoch: 6| Step: 13
Training loss: 1.0424497648984008
Validation loss: 2.551697897837259

Epoch: 376| Step: 0
Training loss: 1.049253239068355
Validation loss: 2.5466586374069715

Epoch: 6| Step: 1
Training loss: 0.8005020026873496
Validation loss: 2.5331641522392188

Epoch: 6| Step: 2
Training loss: 1.5593718687343312
Validation loss: 2.494711798316582

Epoch: 6| Step: 3
Training loss: 1.4184283728010696
Validation loss: 2.518051004402755

Epoch: 6| Step: 4
Training loss: 1.1709530064431877
Validation loss: 2.579232735062393

Epoch: 6| Step: 5
Training loss: 1.1521292793994886
Validation loss: 2.506513304605513

Epoch: 6| Step: 6
Training loss: 0.8391566815077383
Validation loss: 2.5098430774973353

Epoch: 6| Step: 7
Training loss: 1.1027152340532096
Validation loss: 2.4865012357089813

Epoch: 6| Step: 8
Training loss: 0.8837704819891631
Validation loss: 2.537273351760499

Epoch: 6| Step: 9
Training loss: 1.0759296456171332
Validation loss: 2.5371267441959415

Epoch: 6| Step: 10
Training loss: 1.3609694852694512
Validation loss: 2.5733967666475017

Epoch: 6| Step: 11
Training loss: 1.2464158649320005
Validation loss: 2.5649738078549245

Epoch: 6| Step: 12
Training loss: 1.3196410328269692
Validation loss: 2.55089464076769

Epoch: 6| Step: 13
Training loss: 1.1734268086399702
Validation loss: 2.5933132186867938

Epoch: 377| Step: 0
Training loss: 1.0855763884681653
Validation loss: 2.600697385964274

Epoch: 6| Step: 1
Training loss: 1.3723576037917145
Validation loss: 2.626767244817718

Epoch: 6| Step: 2
Training loss: 1.4576535775095423
Validation loss: 2.5933222820182165

Epoch: 6| Step: 3
Training loss: 1.0943673707531623
Validation loss: 2.553228173414407

Epoch: 6| Step: 4
Training loss: 0.939141045203677
Validation loss: 2.551361212779018

Epoch: 6| Step: 5
Training loss: 1.0075513516158288
Validation loss: 2.550115789639371

Epoch: 6| Step: 6
Training loss: 0.9952078675946499
Validation loss: 2.5240374345043732

Epoch: 6| Step: 7
Training loss: 1.0318614418622427
Validation loss: 2.519689833901641

Epoch: 6| Step: 8
Training loss: 0.9189226753778956
Validation loss: 2.5761849241815544

Epoch: 6| Step: 9
Training loss: 1.4348270609783507
Validation loss: 2.531618609492338

Epoch: 6| Step: 10
Training loss: 1.4728529416785912
Validation loss: 2.6096390535376033

Epoch: 6| Step: 11
Training loss: 1.1282705345220798
Validation loss: 2.623327638356556

Epoch: 6| Step: 12
Training loss: 1.3469069899722959
Validation loss: 2.625011731681645

Epoch: 6| Step: 13
Training loss: 0.9274206333699984
Validation loss: 2.6927230116384466

Epoch: 378| Step: 0
Training loss: 1.3263251731486037
Validation loss: 2.6807300033750847

Epoch: 6| Step: 1
Training loss: 0.8505086064360163
Validation loss: 2.6334015199629586

Epoch: 6| Step: 2
Training loss: 1.2518864701688786
Validation loss: 2.6905012302382874

Epoch: 6| Step: 3
Training loss: 1.2246631081213946
Validation loss: 2.6577770256950792

Epoch: 6| Step: 4
Training loss: 0.7134634146743805
Validation loss: 2.6412212669228685

Epoch: 6| Step: 5
Training loss: 0.8830771260605096
Validation loss: 2.6784138001882303

Epoch: 6| Step: 6
Training loss: 1.086939397552608
Validation loss: 2.675888749907764

Epoch: 6| Step: 7
Training loss: 1.1263608648877785
Validation loss: 2.632733986247013

Epoch: 6| Step: 8
Training loss: 1.5056909053783458
Validation loss: 2.5819499916298425

Epoch: 6| Step: 9
Training loss: 1.215962131302726
Validation loss: 2.5458664096446295

Epoch: 6| Step: 10
Training loss: 1.2389236372382988
Validation loss: 2.514011631797359

Epoch: 6| Step: 11
Training loss: 0.7428796853192624
Validation loss: 2.5582895345593917

Epoch: 6| Step: 12
Training loss: 1.2344619140930155
Validation loss: 2.5323643056624014

Epoch: 6| Step: 13
Training loss: 1.672299340132565
Validation loss: 2.5403718360055656

Epoch: 379| Step: 0
Training loss: 0.9925050602743066
Validation loss: 2.5818490768703515

Epoch: 6| Step: 1
Training loss: 1.4488689483708397
Validation loss: 2.626871259470202

Epoch: 6| Step: 2
Training loss: 1.5806581165951819
Validation loss: 2.612285711391845

Epoch: 6| Step: 3
Training loss: 1.0116055694075312
Validation loss: 2.6247800099061314

Epoch: 6| Step: 4
Training loss: 1.3142065125792401
Validation loss: 2.633873715264346

Epoch: 6| Step: 5
Training loss: 1.6215598298126368
Validation loss: 2.7033844898603108

Epoch: 6| Step: 6
Training loss: 1.346706066467984
Validation loss: 2.749646351934108

Epoch: 6| Step: 7
Training loss: 1.0644984244410662
Validation loss: 2.742984116236969

Epoch: 6| Step: 8
Training loss: 0.696115373132179
Validation loss: 2.679631876762089

Epoch: 6| Step: 9
Training loss: 1.61285379949332
Validation loss: 2.6276669653857225

Epoch: 6| Step: 10
Training loss: 1.1589991903820616
Validation loss: 2.5697613002393678

Epoch: 6| Step: 11
Training loss: 0.8921372808696431
Validation loss: 2.4908824281862354

Epoch: 6| Step: 12
Training loss: 1.092603791323764
Validation loss: 2.451924704641777

Epoch: 6| Step: 13
Training loss: 0.8977925846959532
Validation loss: 2.5751368689966476

Epoch: 380| Step: 0
Training loss: 1.1330951206583306
Validation loss: 2.5272013384843963

Epoch: 6| Step: 1
Training loss: 1.2731568196833034
Validation loss: 2.5504391155014225

Epoch: 6| Step: 2
Training loss: 1.2093471790041246
Validation loss: 2.593955771009116

Epoch: 6| Step: 3
Training loss: 1.4269802121218618
Validation loss: 2.66847430494371

Epoch: 6| Step: 4
Training loss: 1.0693732825599314
Validation loss: 2.680959683153193

Epoch: 6| Step: 5
Training loss: 1.155488356191154
Validation loss: 2.758907342136283

Epoch: 6| Step: 6
Training loss: 1.1841434423507897
Validation loss: 2.7551397424439625

Epoch: 6| Step: 7
Training loss: 1.4000770292208105
Validation loss: 2.748486029865342

Epoch: 6| Step: 8
Training loss: 1.3259523909553235
Validation loss: 2.6876677675149923

Epoch: 6| Step: 9
Training loss: 1.482670015618318
Validation loss: 2.6281286244890922

Epoch: 6| Step: 10
Training loss: 1.3728302395388905
Validation loss: 2.6276338926561373

Epoch: 6| Step: 11
Training loss: 1.028733390590592
Validation loss: 2.543361135466653

Epoch: 6| Step: 12
Training loss: 1.137524401224852
Validation loss: 2.5564464614845765

Epoch: 6| Step: 13
Training loss: 0.8491761253910781
Validation loss: 2.5802622942825493

Epoch: 381| Step: 0
Training loss: 1.0961830869499178
Validation loss: 2.556024837137416

Epoch: 6| Step: 1
Training loss: 1.0543846543282185
Validation loss: 2.5569296513929047

Epoch: 6| Step: 2
Training loss: 1.2438532858283387
Validation loss: 2.5657535382936247

Epoch: 6| Step: 3
Training loss: 1.4101092470741698
Validation loss: 2.542102125000746

Epoch: 6| Step: 4
Training loss: 1.3994900881766195
Validation loss: 2.5345464520642964

Epoch: 6| Step: 5
Training loss: 1.1908731237072185
Validation loss: 2.5504651265639664

Epoch: 6| Step: 6
Training loss: 1.2325344608588393
Validation loss: 2.576401737611806

Epoch: 6| Step: 7
Training loss: 1.061463692114683
Validation loss: 2.5420814290394134

Epoch: 6| Step: 8
Training loss: 1.0795486559660683
Validation loss: 2.5512318235102156

Epoch: 6| Step: 9
Training loss: 1.1120735980041652
Validation loss: 2.581850354297019

Epoch: 6| Step: 10
Training loss: 1.08150714616888
Validation loss: 2.5603759305076013

Epoch: 6| Step: 11
Training loss: 0.7313401028149712
Validation loss: 2.6019860992915533

Epoch: 6| Step: 12
Training loss: 0.9323771702150085
Validation loss: 2.629889657131712

Epoch: 6| Step: 13
Training loss: 1.2114335059488954
Validation loss: 2.6501768808892736

Epoch: 382| Step: 0
Training loss: 0.969406489998917
Validation loss: 2.633149318864968

Epoch: 6| Step: 1
Training loss: 1.0004072552139904
Validation loss: 2.597459843985729

Epoch: 6| Step: 2
Training loss: 0.8697217048939409
Validation loss: 2.6167777124965452

Epoch: 6| Step: 3
Training loss: 1.2185339613929742
Validation loss: 2.48874905439174

Epoch: 6| Step: 4
Training loss: 0.9633194160171087
Validation loss: 2.541183681144939

Epoch: 6| Step: 5
Training loss: 1.2720265441140228
Validation loss: 2.5292530345676707

Epoch: 6| Step: 6
Training loss: 1.160624040511828
Validation loss: 2.547262665434348

Epoch: 6| Step: 7
Training loss: 0.9577978683772954
Validation loss: 2.533642615294938

Epoch: 6| Step: 8
Training loss: 0.8429536240062924
Validation loss: 2.5674566464105313

Epoch: 6| Step: 9
Training loss: 1.0821689008612057
Validation loss: 2.5614155203545774

Epoch: 6| Step: 10
Training loss: 1.5643840112552354
Validation loss: 2.5980333250559737

Epoch: 6| Step: 11
Training loss: 0.7819733132347862
Validation loss: 2.6347037294666413

Epoch: 6| Step: 12
Training loss: 1.767118244517384
Validation loss: 2.6453667376944594

Epoch: 6| Step: 13
Training loss: 0.9564075851244146
Validation loss: 2.7203689957883026

Epoch: 383| Step: 0
Training loss: 1.5946233263957126
Validation loss: 2.698637631579902

Epoch: 6| Step: 1
Training loss: 1.2354492148903742
Validation loss: 2.6961205344729033

Epoch: 6| Step: 2
Training loss: 0.9095854709010069
Validation loss: 2.722567373947781

Epoch: 6| Step: 3
Training loss: 1.0188085106271414
Validation loss: 2.6840373805769304

Epoch: 6| Step: 4
Training loss: 0.8378784249935862
Validation loss: 2.696367155125704

Epoch: 6| Step: 5
Training loss: 1.0053177347423428
Validation loss: 2.6207951822420195

Epoch: 6| Step: 6
Training loss: 0.8459406776777206
Validation loss: 2.591128621771053

Epoch: 6| Step: 7
Training loss: 1.1626175482601055
Validation loss: 2.561206188618435

Epoch: 6| Step: 8
Training loss: 1.0869936301282506
Validation loss: 2.5417984058029046

Epoch: 6| Step: 9
Training loss: 1.2422784256196147
Validation loss: 2.5288022533454377

Epoch: 6| Step: 10
Training loss: 1.398470446662021
Validation loss: 2.5511295690276743

Epoch: 6| Step: 11
Training loss: 1.3253422924777676
Validation loss: 2.5631758023591233

Epoch: 6| Step: 12
Training loss: 1.1204737101700288
Validation loss: 2.5613311722569416

Epoch: 6| Step: 13
Training loss: 0.9761952434427821
Validation loss: 2.6122732570575606

Epoch: 384| Step: 0
Training loss: 1.2975493366953132
Validation loss: 2.6579610362587665

Epoch: 6| Step: 1
Training loss: 0.9698391606016553
Validation loss: 2.7440284715135537

Epoch: 6| Step: 2
Training loss: 1.062232600952353
Validation loss: 2.7372383457128175

Epoch: 6| Step: 3
Training loss: 1.6014329066995077
Validation loss: 2.764554551144113

Epoch: 6| Step: 4
Training loss: 0.9999701674302988
Validation loss: 2.6560098576918136

Epoch: 6| Step: 5
Training loss: 1.0073844532933098
Validation loss: 2.747620853893508

Epoch: 6| Step: 6
Training loss: 1.2205321657629709
Validation loss: 2.6194826149836574

Epoch: 6| Step: 7
Training loss: 1.1822770351675285
Validation loss: 2.621205433163619

Epoch: 6| Step: 8
Training loss: 0.8438440199849686
Validation loss: 2.5446351075910894

Epoch: 6| Step: 9
Training loss: 1.3353019228640644
Validation loss: 2.551262413392184

Epoch: 6| Step: 10
Training loss: 1.1320451965947202
Validation loss: 2.5730793369983394

Epoch: 6| Step: 11
Training loss: 1.0278355106829469
Validation loss: 2.5450457066826524

Epoch: 6| Step: 12
Training loss: 1.0494406845319806
Validation loss: 2.55498097762898

Epoch: 6| Step: 13
Training loss: 1.047970326884437
Validation loss: 2.6585208386229926

Epoch: 385| Step: 0
Training loss: 1.2022788304778596
Validation loss: 2.6078918719226567

Epoch: 6| Step: 1
Training loss: 1.4169305200388458
Validation loss: 2.6144653663517756

Epoch: 6| Step: 2
Training loss: 1.025029175040766
Validation loss: 2.6560254693969303

Epoch: 6| Step: 3
Training loss: 1.3662174380122558
Validation loss: 2.6233689675421332

Epoch: 6| Step: 4
Training loss: 1.4281605555409218
Validation loss: 2.617164831869922

Epoch: 6| Step: 5
Training loss: 0.7655958442586162
Validation loss: 2.6172112155428158

Epoch: 6| Step: 6
Training loss: 0.7918252075124703
Validation loss: 2.5733376337503002

Epoch: 6| Step: 7
Training loss: 1.0042074619939065
Validation loss: 2.5234376574694384

Epoch: 6| Step: 8
Training loss: 1.0223240510237024
Validation loss: 2.534060530902278

Epoch: 6| Step: 9
Training loss: 1.4095180261277271
Validation loss: 2.5156547907927265

Epoch: 6| Step: 10
Training loss: 0.8698708884581522
Validation loss: 2.531808901334958

Epoch: 6| Step: 11
Training loss: 1.178547440941183
Validation loss: 2.5439955459291825

Epoch: 6| Step: 12
Training loss: 1.0768676281110463
Validation loss: 2.5695675714449697

Epoch: 6| Step: 13
Training loss: 0.8354895987191409
Validation loss: 2.6177745711030447

Epoch: 386| Step: 0
Training loss: 1.4005341822038995
Validation loss: 2.6381863501020906

Epoch: 6| Step: 1
Training loss: 1.0200545915318455
Validation loss: 2.589067123062098

Epoch: 6| Step: 2
Training loss: 0.9495174424656981
Validation loss: 2.6114109495043794

Epoch: 6| Step: 3
Training loss: 1.810612847073754
Validation loss: 2.5972825931280323

Epoch: 6| Step: 4
Training loss: 1.0204288433859867
Validation loss: 2.619053432635671

Epoch: 6| Step: 5
Training loss: 0.8576308150089439
Validation loss: 2.636796843702702

Epoch: 6| Step: 6
Training loss: 0.9230040086243808
Validation loss: 2.5908543152775985

Epoch: 6| Step: 7
Training loss: 0.9261837498785668
Validation loss: 2.5570166311089935

Epoch: 6| Step: 8
Training loss: 0.735353751008322
Validation loss: 2.5167136512143085

Epoch: 6| Step: 9
Training loss: 0.9170828257525673
Validation loss: 2.489014410243627

Epoch: 6| Step: 10
Training loss: 1.1909268774971729
Validation loss: 2.509644200891951

Epoch: 6| Step: 11
Training loss: 0.6779289735764481
Validation loss: 2.5079427588236234

Epoch: 6| Step: 12
Training loss: 1.4542905993330046
Validation loss: 2.5417734082013537

Epoch: 6| Step: 13
Training loss: 0.7281183790961887
Validation loss: 2.574423149456926

Epoch: 387| Step: 0
Training loss: 0.8031963865859985
Validation loss: 2.594180381641432

Epoch: 6| Step: 1
Training loss: 0.742595761093218
Validation loss: 2.5379051035461733

Epoch: 6| Step: 2
Training loss: 1.1047391067385637
Validation loss: 2.5346360968556176

Epoch: 6| Step: 3
Training loss: 1.3303295911677206
Validation loss: 2.583258263717513

Epoch: 6| Step: 4
Training loss: 0.773995631582663
Validation loss: 2.617016520063097

Epoch: 6| Step: 5
Training loss: 1.2314354868170903
Validation loss: 2.6254159506989687

Epoch: 6| Step: 6
Training loss: 1.393938681314246
Validation loss: 2.5853266921411406

Epoch: 6| Step: 7
Training loss: 1.196704926122684
Validation loss: 2.6888773146381104

Epoch: 6| Step: 8
Training loss: 1.0730037962463288
Validation loss: 2.644592389630713

Epoch: 6| Step: 9
Training loss: 1.0671662357831286
Validation loss: 2.632060425572975

Epoch: 6| Step: 10
Training loss: 1.1513017501548706
Validation loss: 2.6634585981627334

Epoch: 6| Step: 11
Training loss: 1.0355824870544579
Validation loss: 2.6074443458989003

Epoch: 6| Step: 12
Training loss: 1.0823107747412628
Validation loss: 2.683145795709417

Epoch: 6| Step: 13
Training loss: 0.7513989276493513
Validation loss: 2.6562595292462725

Epoch: 388| Step: 0
Training loss: 0.9259660753623011
Validation loss: 2.6470859195843306

Epoch: 6| Step: 1
Training loss: 0.80239200019804
Validation loss: 2.6525694536181916

Epoch: 6| Step: 2
Training loss: 0.8267119245548427
Validation loss: 2.5954954257033878

Epoch: 6| Step: 3
Training loss: 0.847156465215936
Validation loss: 2.5643740213497512

Epoch: 6| Step: 4
Training loss: 0.8778955709683518
Validation loss: 2.547373677991071

Epoch: 6| Step: 5
Training loss: 1.1769045916304786
Validation loss: 2.5829071236824013

Epoch: 6| Step: 6
Training loss: 1.3977806637245134
Validation loss: 2.550048411290007

Epoch: 6| Step: 7
Training loss: 1.2054853199619133
Validation loss: 2.595853511758409

Epoch: 6| Step: 8
Training loss: 0.822959625152995
Validation loss: 2.553535769541026

Epoch: 6| Step: 9
Training loss: 1.0634486507399499
Validation loss: 2.5545177656088436

Epoch: 6| Step: 10
Training loss: 0.9408176212220823
Validation loss: 2.583443552147554

Epoch: 6| Step: 11
Training loss: 1.406114147829752
Validation loss: 2.638193948882968

Epoch: 6| Step: 12
Training loss: 0.937611160045986
Validation loss: 2.5937250051864402

Epoch: 6| Step: 13
Training loss: 1.20474372069588
Validation loss: 2.612756346639173

Epoch: 389| Step: 0
Training loss: 0.8655248976574653
Validation loss: 2.593333750956027

Epoch: 6| Step: 1
Training loss: 1.018172312106152
Validation loss: 2.629094472781629

Epoch: 6| Step: 2
Training loss: 0.7876825635707376
Validation loss: 2.6418843849508176

Epoch: 6| Step: 3
Training loss: 1.3636791883593236
Validation loss: 2.6691881616707276

Epoch: 6| Step: 4
Training loss: 0.839061070730459
Validation loss: 2.7041526854809512

Epoch: 6| Step: 5
Training loss: 0.8499485435057309
Validation loss: 2.6989356268326707

Epoch: 6| Step: 6
Training loss: 1.0387479836711755
Validation loss: 2.618634999374432

Epoch: 6| Step: 7
Training loss: 0.8025863399584627
Validation loss: 2.6063996138651246

Epoch: 6| Step: 8
Training loss: 0.7582446566983648
Validation loss: 2.6062422352041668

Epoch: 6| Step: 9
Training loss: 0.9418744391102377
Validation loss: 2.6637532641090838

Epoch: 6| Step: 10
Training loss: 1.013218537612769
Validation loss: 2.602705420926017

Epoch: 6| Step: 11
Training loss: 1.6086153626437463
Validation loss: 2.6449275581472707

Epoch: 6| Step: 12
Training loss: 1.6188801186599733
Validation loss: 2.6381234653965193

Epoch: 6| Step: 13
Training loss: 1.1405565424193964
Validation loss: 2.6272575419478006

Epoch: 390| Step: 0
Training loss: 1.6088687137412487
Validation loss: 2.5879346006483765

Epoch: 6| Step: 1
Training loss: 0.8729953964042103
Validation loss: 2.6667712359986067

Epoch: 6| Step: 2
Training loss: 0.8627812935816959
Validation loss: 2.7175109714612953

Epoch: 6| Step: 3
Training loss: 1.209396168920279
Validation loss: 2.788620971722376

Epoch: 6| Step: 4
Training loss: 0.9947879984257091
Validation loss: 2.7665486777857398

Epoch: 6| Step: 5
Training loss: 0.7457827973604484
Validation loss: 2.7270311246167505

Epoch: 6| Step: 6
Training loss: 1.2407413437722186
Validation loss: 2.628778523501855

Epoch: 6| Step: 7
Training loss: 1.2194736972989335
Validation loss: 2.5524372140931924

Epoch: 6| Step: 8
Training loss: 1.3842792383144003
Validation loss: 2.5832904894157553

Epoch: 6| Step: 9
Training loss: 1.0114263752774155
Validation loss: 2.5139440128846586

Epoch: 6| Step: 10
Training loss: 1.0176920470096502
Validation loss: 2.5747079263858357

Epoch: 6| Step: 11
Training loss: 1.5090444799229292
Validation loss: 2.5465040502340615

Epoch: 6| Step: 12
Training loss: 0.9618069506809905
Validation loss: 2.529363816405214

Epoch: 6| Step: 13
Training loss: 0.8986989180011121
Validation loss: 2.5986159461600726

Epoch: 391| Step: 0
Training loss: 0.7238675250360938
Validation loss: 2.5389191024586117

Epoch: 6| Step: 1
Training loss: 0.9920479383460375
Validation loss: 2.577642237614064

Epoch: 6| Step: 2
Training loss: 0.6333824699146563
Validation loss: 2.5871738348050637

Epoch: 6| Step: 3
Training loss: 0.7622259554325146
Validation loss: 2.616450540967527

Epoch: 6| Step: 4
Training loss: 1.0231770773784312
Validation loss: 2.6634505716698547

Epoch: 6| Step: 5
Training loss: 1.166079878833824
Validation loss: 2.683236236671552

Epoch: 6| Step: 6
Training loss: 1.1392967119382256
Validation loss: 2.621237510684143

Epoch: 6| Step: 7
Training loss: 1.266310329675827
Validation loss: 2.6420772554305314

Epoch: 6| Step: 8
Training loss: 1.1669045387456363
Validation loss: 2.5970002916502612

Epoch: 6| Step: 9
Training loss: 1.262029225795417
Validation loss: 2.5379282447485294

Epoch: 6| Step: 10
Training loss: 1.246795552335069
Validation loss: 2.5627976454020676

Epoch: 6| Step: 11
Training loss: 0.9104651389468563
Validation loss: 2.517960374616817

Epoch: 6| Step: 12
Training loss: 0.8493164259002743
Validation loss: 2.510880302152791

Epoch: 6| Step: 13
Training loss: 1.568598936794144
Validation loss: 2.5381668154257446

Epoch: 392| Step: 0
Training loss: 1.0724819500166762
Validation loss: 2.5633492961960287

Epoch: 6| Step: 1
Training loss: 1.2015062812580664
Validation loss: 2.5989820113597366

Epoch: 6| Step: 2
Training loss: 1.313725852708094
Validation loss: 2.6352055330603656

Epoch: 6| Step: 3
Training loss: 0.826135007788712
Validation loss: 2.640763649695724

Epoch: 6| Step: 4
Training loss: 0.8844055723156238
Validation loss: 2.6728483215617147

Epoch: 6| Step: 5
Training loss: 0.759571786193909
Validation loss: 2.6723264197612666

Epoch: 6| Step: 6
Training loss: 0.8926055369769315
Validation loss: 2.695338697812937

Epoch: 6| Step: 7
Training loss: 1.39124361487446
Validation loss: 2.6478304847200445

Epoch: 6| Step: 8
Training loss: 1.1954782907037695
Validation loss: 2.60860288545468

Epoch: 6| Step: 9
Training loss: 1.0235027263327376
Validation loss: 2.5743667336177087

Epoch: 6| Step: 10
Training loss: 1.0247465308736285
Validation loss: 2.5524575147290633

Epoch: 6| Step: 11
Training loss: 1.4563317140893424
Validation loss: 2.5439607840645375

Epoch: 6| Step: 12
Training loss: 1.047277174035449
Validation loss: 2.5433478085100547

Epoch: 6| Step: 13
Training loss: 1.0288768975568616
Validation loss: 2.5552378381538543

Epoch: 393| Step: 0
Training loss: 1.010059601658681
Validation loss: 2.55497757162165

Epoch: 6| Step: 1
Training loss: 1.4385392122940608
Validation loss: 2.6427070490365723

Epoch: 6| Step: 2
Training loss: 0.9872481785571717
Validation loss: 2.6743043559491686

Epoch: 6| Step: 3
Training loss: 1.169269105815107
Validation loss: 2.64251185613912

Epoch: 6| Step: 4
Training loss: 0.8935407126746167
Validation loss: 2.6636593421320085

Epoch: 6| Step: 5
Training loss: 0.8442501422496763
Validation loss: 2.6733858473258305

Epoch: 6| Step: 6
Training loss: 0.880196806401425
Validation loss: 2.675811633751993

Epoch: 6| Step: 7
Training loss: 0.8119351918121128
Validation loss: 2.6989844478598664

Epoch: 6| Step: 8
Training loss: 1.634893451100348
Validation loss: 2.7008341451461435

Epoch: 6| Step: 9
Training loss: 0.9836789046581625
Validation loss: 2.6779702841107405

Epoch: 6| Step: 10
Training loss: 0.8910179609763945
Validation loss: 2.68409131364083

Epoch: 6| Step: 11
Training loss: 0.8174807399849106
Validation loss: 2.6224672648081104

Epoch: 6| Step: 12
Training loss: 1.2836956780073465
Validation loss: 2.6541828938521617

Epoch: 6| Step: 13
Training loss: 0.9319809905679892
Validation loss: 2.634907252315931

Epoch: 394| Step: 0
Training loss: 0.7971846409009553
Validation loss: 2.620758717439551

Epoch: 6| Step: 1
Training loss: 1.305758145465602
Validation loss: 2.671959353299601

Epoch: 6| Step: 2
Training loss: 0.9060908210655746
Validation loss: 2.60370525595754

Epoch: 6| Step: 3
Training loss: 0.8628342796154947
Validation loss: 2.5750643200541563

Epoch: 6| Step: 4
Training loss: 1.4377074713880122
Validation loss: 2.5449446479283964

Epoch: 6| Step: 5
Training loss: 0.8354175055508354
Validation loss: 2.6206910174068283

Epoch: 6| Step: 6
Training loss: 0.8925478740215278
Validation loss: 2.6154121564512534

Epoch: 6| Step: 7
Training loss: 1.0503952281619804
Validation loss: 2.580360075690777

Epoch: 6| Step: 8
Training loss: 0.8655393592528138
Validation loss: 2.566513996001136

Epoch: 6| Step: 9
Training loss: 0.9133451532436709
Validation loss: 2.56882134405777

Epoch: 6| Step: 10
Training loss: 1.013086815313897
Validation loss: 2.5748556041045343

Epoch: 6| Step: 11
Training loss: 0.8847431575794048
Validation loss: 2.5359184635785232

Epoch: 6| Step: 12
Training loss: 1.2286600049301042
Validation loss: 2.5858043932199366

Epoch: 6| Step: 13
Training loss: 0.9794445996119977
Validation loss: 2.5762354235828258

Epoch: 395| Step: 0
Training loss: 0.93216100590519
Validation loss: 2.5324827418440656

Epoch: 6| Step: 1
Training loss: 0.8896107838405871
Validation loss: 2.555965652133548

Epoch: 6| Step: 2
Training loss: 1.4539927691052916
Validation loss: 2.585130609819599

Epoch: 6| Step: 3
Training loss: 0.6824369178865215
Validation loss: 2.6574379153339733

Epoch: 6| Step: 4
Training loss: 1.059152040678215
Validation loss: 2.6089584566334763

Epoch: 6| Step: 5
Training loss: 1.2058058756189256
Validation loss: 2.6877768617894513

Epoch: 6| Step: 6
Training loss: 1.151411604085218
Validation loss: 2.6676173651300457

Epoch: 6| Step: 7
Training loss: 0.7471678825939778
Validation loss: 2.6879365403834177

Epoch: 6| Step: 8
Training loss: 0.8951192197832796
Validation loss: 2.657552078349244

Epoch: 6| Step: 9
Training loss: 0.7429650099025416
Validation loss: 2.6398201718518792

Epoch: 6| Step: 10
Training loss: 1.0404938898745792
Validation loss: 2.645405071371525

Epoch: 6| Step: 11
Training loss: 1.0275963882381332
Validation loss: 2.6170849756305437

Epoch: 6| Step: 12
Training loss: 0.6881828384969071
Validation loss: 2.5880425558536757

Epoch: 6| Step: 13
Training loss: 0.8358611669181587
Validation loss: 2.535655971153345

Epoch: 396| Step: 0
Training loss: 1.0239396355837271
Validation loss: 2.5970766572964896

Epoch: 6| Step: 1
Training loss: 0.6682988293779216
Validation loss: 2.583690885185303

Epoch: 6| Step: 2
Training loss: 0.8728238019201259
Validation loss: 2.554375087911332

Epoch: 6| Step: 3
Training loss: 0.824709777646774
Validation loss: 2.5889546904662724

Epoch: 6| Step: 4
Training loss: 0.8709923723699267
Validation loss: 2.6374577294407953

Epoch: 6| Step: 5
Training loss: 1.2825340256815585
Validation loss: 2.6776384206135484

Epoch: 6| Step: 6
Training loss: 0.8060092256008566
Validation loss: 2.7061378285431705

Epoch: 6| Step: 7
Training loss: 1.2854775719869094
Validation loss: 2.7083375832940035

Epoch: 6| Step: 8
Training loss: 1.157374685601994
Validation loss: 2.718152049872897

Epoch: 6| Step: 9
Training loss: 0.9282756952807579
Validation loss: 2.687536298521485

Epoch: 6| Step: 10
Training loss: 0.9181390482617838
Validation loss: 2.6578469954638058

Epoch: 6| Step: 11
Training loss: 0.9725372364201562
Validation loss: 2.566826958625876

Epoch: 6| Step: 12
Training loss: 1.0353771046091271
Validation loss: 2.536362230385036

Epoch: 6| Step: 13
Training loss: 1.4010738903249205
Validation loss: 2.525896100965823

Epoch: 397| Step: 0
Training loss: 1.1825332170784966
Validation loss: 2.534622990539771

Epoch: 6| Step: 1
Training loss: 0.8888571745128935
Validation loss: 2.4982612126200356

Epoch: 6| Step: 2
Training loss: 0.7393064293943914
Validation loss: 2.5557458067878893

Epoch: 6| Step: 3
Training loss: 1.0631808735979198
Validation loss: 2.5080222956129288

Epoch: 6| Step: 4
Training loss: 0.8888879534266106
Validation loss: 2.5894356967602126

Epoch: 6| Step: 5
Training loss: 0.6326045412811756
Validation loss: 2.5866979304944495

Epoch: 6| Step: 6
Training loss: 0.7919949344535632
Validation loss: 2.6084797402710764

Epoch: 6| Step: 7
Training loss: 1.176677577658866
Validation loss: 2.6636280440158067

Epoch: 6| Step: 8
Training loss: 1.0634406918307686
Validation loss: 2.6035244009829195

Epoch: 6| Step: 9
Training loss: 0.7287044331616378
Validation loss: 2.649598323921389

Epoch: 6| Step: 10
Training loss: 0.9925152094754212
Validation loss: 2.6618776731350033

Epoch: 6| Step: 11
Training loss: 1.311440448876386
Validation loss: 2.6948754734907263

Epoch: 6| Step: 12
Training loss: 1.2670050737840906
Validation loss: 2.6823346526519285

Epoch: 6| Step: 13
Training loss: 0.9587410114966134
Validation loss: 2.7204335287487567

Epoch: 398| Step: 0
Training loss: 1.043897294027631
Validation loss: 2.6653589578757706

Epoch: 6| Step: 1
Training loss: 1.0435369993778059
Validation loss: 2.61997319850851

Epoch: 6| Step: 2
Training loss: 0.9130081225197887
Validation loss: 2.6121859153295217

Epoch: 6| Step: 3
Training loss: 0.9670946067362262
Validation loss: 2.598424468062266

Epoch: 6| Step: 4
Training loss: 0.9211079267166347
Validation loss: 2.561881417145998

Epoch: 6| Step: 5
Training loss: 1.0473328912767643
Validation loss: 2.5908311560143025

Epoch: 6| Step: 6
Training loss: 1.3734084368203159
Validation loss: 2.604486130510822

Epoch: 6| Step: 7
Training loss: 0.593457827709543
Validation loss: 2.624169521053632

Epoch: 6| Step: 8
Training loss: 0.9926996786428104
Validation loss: 2.668938776467215

Epoch: 6| Step: 9
Training loss: 0.8012803917892095
Validation loss: 2.690050304916237

Epoch: 6| Step: 10
Training loss: 1.1659480447530046
Validation loss: 2.7138009170213935

Epoch: 6| Step: 11
Training loss: 0.93422923147112
Validation loss: 2.735355107083714

Epoch: 6| Step: 12
Training loss: 0.730402856802498
Validation loss: 2.717706925984071

Epoch: 6| Step: 13
Training loss: 0.9996965066993567
Validation loss: 2.719284377800781

Epoch: 399| Step: 0
Training loss: 0.9107059897784907
Validation loss: 2.757989548141227

Epoch: 6| Step: 1
Training loss: 1.1068523900519198
Validation loss: 2.7331634162408807

Epoch: 6| Step: 2
Training loss: 0.9377093081471709
Validation loss: 2.7267456576121956

Epoch: 6| Step: 3
Training loss: 0.7383436953662096
Validation loss: 2.7291201570542123

Epoch: 6| Step: 4
Training loss: 1.266233039132315
Validation loss: 2.7461063534848504

Epoch: 6| Step: 5
Training loss: 0.966267388743759
Validation loss: 2.7601121458590976

Epoch: 6| Step: 6
Training loss: 0.9742579007943081
Validation loss: 2.6867351034912224

Epoch: 6| Step: 7
Training loss: 0.7193164252090317
Validation loss: 2.6826827470924406

Epoch: 6| Step: 8
Training loss: 0.9233012400625936
Validation loss: 2.6813726437135825

Epoch: 6| Step: 9
Training loss: 1.0902129064214108
Validation loss: 2.6474776652675494

Epoch: 6| Step: 10
Training loss: 1.3164554665983974
Validation loss: 2.602128510481297

Epoch: 6| Step: 11
Training loss: 1.0503476748014513
Validation loss: 2.60061347919147

Epoch: 6| Step: 12
Training loss: 0.6598297756484899
Validation loss: 2.68190250474784

Epoch: 6| Step: 13
Training loss: 0.9679440868520824
Validation loss: 2.6552703247575846

Epoch: 400| Step: 0
Training loss: 1.0810911866791835
Validation loss: 2.683665549008622

Epoch: 6| Step: 1
Training loss: 0.9530762831948133
Validation loss: 2.679793271423095

Epoch: 6| Step: 2
Training loss: 0.9366398362110192
Validation loss: 2.635138671647481

Epoch: 6| Step: 3
Training loss: 0.9472955443386304
Validation loss: 2.6280609631079277

Epoch: 6| Step: 4
Training loss: 0.8604021696173297
Validation loss: 2.569652484227043

Epoch: 6| Step: 5
Training loss: 0.7405036295660834
Validation loss: 2.537333614863856

Epoch: 6| Step: 6
Training loss: 1.2431679940592288
Validation loss: 2.5500115035925797

Epoch: 6| Step: 7
Training loss: 1.1134981713693213
Validation loss: 2.5580551861916128

Epoch: 6| Step: 8
Training loss: 0.9546272446117858
Validation loss: 2.5788020314280358

Epoch: 6| Step: 9
Training loss: 1.371740813416257
Validation loss: 2.606137549690597

Epoch: 6| Step: 10
Training loss: 0.8423163632126464
Validation loss: 2.5780432794122885

Epoch: 6| Step: 11
Training loss: 1.067397442967835
Validation loss: 2.6144094573992263

Epoch: 6| Step: 12
Training loss: 0.8206779755738423
Validation loss: 2.62878602099201

Epoch: 6| Step: 13
Training loss: 1.0475922589881614
Validation loss: 2.6775810110598086

Epoch: 401| Step: 0
Training loss: 0.7808845428181693
Validation loss: 2.7301541985407813

Epoch: 6| Step: 1
Training loss: 0.8846248826343113
Validation loss: 2.7644196665731124

Epoch: 6| Step: 2
Training loss: 1.2223538155709988
Validation loss: 2.822549681134764

Epoch: 6| Step: 3
Training loss: 0.6591284159747798
Validation loss: 2.762584257495095

Epoch: 6| Step: 4
Training loss: 0.9147098889623002
Validation loss: 2.714171679988639

Epoch: 6| Step: 5
Training loss: 1.2598643182936977
Validation loss: 2.686396128148895

Epoch: 6| Step: 6
Training loss: 0.8536708524775881
Validation loss: 2.6800834726505354

Epoch: 6| Step: 7
Training loss: 1.0707050355478782
Validation loss: 2.634781867812123

Epoch: 6| Step: 8
Training loss: 1.3996732568921078
Validation loss: 2.65874533036645

Epoch: 6| Step: 9
Training loss: 1.3147598067543695
Validation loss: 2.6153593444214653

Epoch: 6| Step: 10
Training loss: 0.9871148625935712
Validation loss: 2.6487859986160136

Epoch: 6| Step: 11
Training loss: 0.7934990974425944
Validation loss: 2.6387202147623863

Epoch: 6| Step: 12
Training loss: 0.9676858533226707
Validation loss: 2.6811257257241956

Epoch: 6| Step: 13
Training loss: 1.0721659518472297
Validation loss: 2.6863527140884074

Epoch: 402| Step: 0
Training loss: 1.1090806919905019
Validation loss: 2.709118250055657

Epoch: 6| Step: 1
Training loss: 1.0216246411971575
Validation loss: 2.710609614086925

Epoch: 6| Step: 2
Training loss: 1.31992140174715
Validation loss: 2.7579648819592397

Epoch: 6| Step: 3
Training loss: 0.9102373864678466
Validation loss: 2.779963406498061

Epoch: 6| Step: 4
Training loss: 1.365543226853406
Validation loss: 2.7931565868463566

Epoch: 6| Step: 5
Training loss: 1.1883247924290883
Validation loss: 2.75218202258537

Epoch: 6| Step: 6
Training loss: 0.8204192319190233
Validation loss: 2.6844396539732034

Epoch: 6| Step: 7
Training loss: 0.5602042716283254
Validation loss: 2.6399697839568312

Epoch: 6| Step: 8
Training loss: 0.8680216583415276
Validation loss: 2.601106437596707

Epoch: 6| Step: 9
Training loss: 1.3268462364036737
Validation loss: 2.580994690837521

Epoch: 6| Step: 10
Training loss: 0.818096765157741
Validation loss: 2.5822076549664454

Epoch: 6| Step: 11
Training loss: 1.2983408078250698
Validation loss: 2.5456992401753675

Epoch: 6| Step: 12
Training loss: 0.8386075169709258
Validation loss: 2.5728406444443293

Epoch: 6| Step: 13
Training loss: 0.8031016157137578
Validation loss: 2.524557111316104

Epoch: 403| Step: 0
Training loss: 0.9866081520129655
Validation loss: 2.5055348797452806

Epoch: 6| Step: 1
Training loss: 0.8875093338703891
Validation loss: 2.5440070263777574

Epoch: 6| Step: 2
Training loss: 1.0513465240109012
Validation loss: 2.5237982996890675

Epoch: 6| Step: 3
Training loss: 0.7467030937882739
Validation loss: 2.5683288185613

Epoch: 6| Step: 4
Training loss: 0.8431987374469997
Validation loss: 2.562008104951274

Epoch: 6| Step: 5
Training loss: 0.9375397991633522
Validation loss: 2.614369255714389

Epoch: 6| Step: 6
Training loss: 0.6367429950989302
Validation loss: 2.6604523869692698

Epoch: 6| Step: 7
Training loss: 0.864966633103524
Validation loss: 2.628460873291384

Epoch: 6| Step: 8
Training loss: 1.3449974479792892
Validation loss: 2.7112480667269168

Epoch: 6| Step: 9
Training loss: 0.7358984060088523
Validation loss: 2.6974103494241173

Epoch: 6| Step: 10
Training loss: 1.1603105230543174
Validation loss: 2.7619276745594323

Epoch: 6| Step: 11
Training loss: 0.9468332463995055
Validation loss: 2.7167480961661985

Epoch: 6| Step: 12
Training loss: 1.5570398677849666
Validation loss: 2.668281339519657

Epoch: 6| Step: 13
Training loss: 0.9832067672183109
Validation loss: 2.693054004865697

Epoch: 404| Step: 0
Training loss: 0.8036246827054165
Validation loss: 2.6614852923815135

Epoch: 6| Step: 1
Training loss: 1.0200916956842974
Validation loss: 2.632980688441287

Epoch: 6| Step: 2
Training loss: 1.1516724781123453
Validation loss: 2.6330887284532114

Epoch: 6| Step: 3
Training loss: 0.6666129110439365
Validation loss: 2.640021125318795

Epoch: 6| Step: 4
Training loss: 1.0398658572397002
Validation loss: 2.6383441351619035

Epoch: 6| Step: 5
Training loss: 1.0842666395941056
Validation loss: 2.575137324205297

Epoch: 6| Step: 6
Training loss: 1.0577637631614782
Validation loss: 2.62484889882273

Epoch: 6| Step: 7
Training loss: 0.6689077324996734
Validation loss: 2.641166496058115

Epoch: 6| Step: 8
Training loss: 0.8885690147481452
Validation loss: 2.721964430334404

Epoch: 6| Step: 9
Training loss: 0.8944704126717679
Validation loss: 2.720517179767097

Epoch: 6| Step: 10
Training loss: 1.531116246201151
Validation loss: 2.755329819268214

Epoch: 6| Step: 11
Training loss: 1.0434207579716817
Validation loss: 2.752640229815677

Epoch: 6| Step: 12
Training loss: 1.6287841751131797
Validation loss: 2.786981941059699

Epoch: 6| Step: 13
Training loss: 0.9095224293758009
Validation loss: 2.6838862793211202

Epoch: 405| Step: 0
Training loss: 1.015053338777502
Validation loss: 2.6096378277805967

Epoch: 6| Step: 1
Training loss: 0.7035031891040867
Validation loss: 2.5604155521581804

Epoch: 6| Step: 2
Training loss: 1.1308775589029458
Validation loss: 2.5463059380538215

Epoch: 6| Step: 3
Training loss: 0.8684629048258556
Validation loss: 2.50181998127651

Epoch: 6| Step: 4
Training loss: 1.0398894726268515
Validation loss: 2.504445637308984

Epoch: 6| Step: 5
Training loss: 0.9511346829327944
Validation loss: 2.4518785083780332

Epoch: 6| Step: 6
Training loss: 1.3175847695457643
Validation loss: 2.498867779885664

Epoch: 6| Step: 7
Training loss: 1.0176128008127303
Validation loss: 2.548146965824801

Epoch: 6| Step: 8
Training loss: 1.1296204944118462
Validation loss: 2.5846447743487455

Epoch: 6| Step: 9
Training loss: 0.6935174466326529
Validation loss: 2.5901886876671183

Epoch: 6| Step: 10
Training loss: 0.9070074270505808
Validation loss: 2.6221032129327515

Epoch: 6| Step: 11
Training loss: 0.7879723298012111
Validation loss: 2.6782296295677983

Epoch: 6| Step: 12
Training loss: 1.134991569151634
Validation loss: 2.6727804542219222

Epoch: 6| Step: 13
Training loss: 1.1767418064912485
Validation loss: 2.664777374559296

Epoch: 406| Step: 0
Training loss: 0.8697148172993393
Validation loss: 2.6720105856240335

Epoch: 6| Step: 1
Training loss: 0.7919994876021837
Validation loss: 2.6835445601292216

Epoch: 6| Step: 2
Training loss: 0.4390312713160358
Validation loss: 2.6613912157129658

Epoch: 6| Step: 3
Training loss: 1.036604993913483
Validation loss: 2.6198523168703804

Epoch: 6| Step: 4
Training loss: 1.0417321693170596
Validation loss: 2.654432894431126

Epoch: 6| Step: 5
Training loss: 0.9280122039789928
Validation loss: 2.578716372087145

Epoch: 6| Step: 6
Training loss: 0.9810485341454198
Validation loss: 2.646143667288784

Epoch: 6| Step: 7
Training loss: 0.7648878636170738
Validation loss: 2.5868881798391787

Epoch: 6| Step: 8
Training loss: 0.8354495754720527
Validation loss: 2.621683765904497

Epoch: 6| Step: 9
Training loss: 1.0300414199278434
Validation loss: 2.604208455068362

Epoch: 6| Step: 10
Training loss: 1.0780590424195542
Validation loss: 2.708510507999492

Epoch: 6| Step: 11
Training loss: 0.9276007947623075
Validation loss: 2.7508489858818934

Epoch: 6| Step: 12
Training loss: 1.4200642552411746
Validation loss: 2.757436263776458

Epoch: 6| Step: 13
Training loss: 0.5992180606683897
Validation loss: 2.7468759825339095

Epoch: 407| Step: 0
Training loss: 0.6526597679505483
Validation loss: 2.842727666006098

Epoch: 6| Step: 1
Training loss: 1.015408478178042
Validation loss: 2.8242524190314198

Epoch: 6| Step: 2
Training loss: 1.0674074384775019
Validation loss: 2.831191436072062

Epoch: 6| Step: 3
Training loss: 0.858365836191654
Validation loss: 2.7296905063378953

Epoch: 6| Step: 4
Training loss: 1.28434913590649
Validation loss: 2.7516007677255274

Epoch: 6| Step: 5
Training loss: 0.7804161199135672
Validation loss: 2.666659777354242

Epoch: 6| Step: 6
Training loss: 0.8615696713242855
Validation loss: 2.6595635783195752

Epoch: 6| Step: 7
Training loss: 1.2754427795495293
Validation loss: 2.6030850236806633

Epoch: 6| Step: 8
Training loss: 0.8848951973257011
Validation loss: 2.5798205724320447

Epoch: 6| Step: 9
Training loss: 1.0627193224563782
Validation loss: 2.5102096936603204

Epoch: 6| Step: 10
Training loss: 1.0568255193983245
Validation loss: 2.5595287992528055

Epoch: 6| Step: 11
Training loss: 0.8011520643681785
Validation loss: 2.5781843005209497

Epoch: 6| Step: 12
Training loss: 0.6083215263823434
Validation loss: 2.6236569435321693

Epoch: 6| Step: 13
Training loss: 0.9085995045001631
Validation loss: 2.6931654039835555

Epoch: 408| Step: 0
Training loss: 0.7783140328224556
Validation loss: 2.6086269684632315

Epoch: 6| Step: 1
Training loss: 0.9252265523863124
Validation loss: 2.6524485743862005

Epoch: 6| Step: 2
Training loss: 1.0933152560933845
Validation loss: 2.6279053958038023

Epoch: 6| Step: 3
Training loss: 0.9569195117725986
Validation loss: 2.6531555776103333

Epoch: 6| Step: 4
Training loss: 0.7305336989633298
Validation loss: 2.716600262429066

Epoch: 6| Step: 5
Training loss: 0.7943297108991687
Validation loss: 2.696467188195015

Epoch: 6| Step: 6
Training loss: 0.8691298923472693
Validation loss: 2.749552921597725

Epoch: 6| Step: 7
Training loss: 0.9360152248913115
Validation loss: 2.6518663773616393

Epoch: 6| Step: 8
Training loss: 0.8291427188718533
Validation loss: 2.5860087681656343

Epoch: 6| Step: 9
Training loss: 1.2756384802951297
Validation loss: 2.584522324913676

Epoch: 6| Step: 10
Training loss: 0.6899517298828439
Validation loss: 2.5952153796497175

Epoch: 6| Step: 11
Training loss: 1.0063839627768136
Validation loss: 2.5968651582766284

Epoch: 6| Step: 12
Training loss: 1.0130783430836723
Validation loss: 2.6023373905601583

Epoch: 6| Step: 13
Training loss: 0.5822916920297397
Validation loss: 2.584412400675783

Epoch: 409| Step: 0
Training loss: 0.849719231178939
Validation loss: 2.611306882061906

Epoch: 6| Step: 1
Training loss: 1.255294981481214
Validation loss: 2.6519929769086406

Epoch: 6| Step: 2
Training loss: 0.6457206386768756
Validation loss: 2.649062661473996

Epoch: 6| Step: 3
Training loss: 0.7034555294076862
Validation loss: 2.666198604951005

Epoch: 6| Step: 4
Training loss: 1.137248017623626
Validation loss: 2.6604184223628295

Epoch: 6| Step: 5
Training loss: 0.7423375831240261
Validation loss: 2.694684664078033

Epoch: 6| Step: 6
Training loss: 0.7519632314027617
Validation loss: 2.67653667246718

Epoch: 6| Step: 7
Training loss: 0.6349025402596276
Validation loss: 2.7061050687514623

Epoch: 6| Step: 8
Training loss: 1.1008458613323655
Validation loss: 2.662184559578318

Epoch: 6| Step: 9
Training loss: 0.5649086984778751
Validation loss: 2.6223655984316854

Epoch: 6| Step: 10
Training loss: 1.0072308421714393
Validation loss: 2.62604510982842

Epoch: 6| Step: 11
Training loss: 0.9378214602882887
Validation loss: 2.6629391088740277

Epoch: 6| Step: 12
Training loss: 1.0424267221215322
Validation loss: 2.6510707701239067

Epoch: 6| Step: 13
Training loss: 0.9791053928655689
Validation loss: 2.6873179233588362

Epoch: 410| Step: 0
Training loss: 1.0003098961350247
Validation loss: 2.636029671001784

Epoch: 6| Step: 1
Training loss: 0.9951691768343914
Validation loss: 2.6600360441753517

Epoch: 6| Step: 2
Training loss: 0.8350289657274296
Validation loss: 2.6451391275564404

Epoch: 6| Step: 3
Training loss: 0.6036389913053264
Validation loss: 2.6557570280499

Epoch: 6| Step: 4
Training loss: 0.7165554378010118
Validation loss: 2.732490340550536

Epoch: 6| Step: 5
Training loss: 0.6555273527698842
Validation loss: 2.7190958292747047

Epoch: 6| Step: 6
Training loss: 0.7442258450628227
Validation loss: 2.705433721386278

Epoch: 6| Step: 7
Training loss: 1.263239507982268
Validation loss: 2.715717027024534

Epoch: 6| Step: 8
Training loss: 0.7518582370883977
Validation loss: 2.6643452126107596

Epoch: 6| Step: 9
Training loss: 0.6771004430125191
Validation loss: 2.6452488266112146

Epoch: 6| Step: 10
Training loss: 0.8349734656749249
Validation loss: 2.615603963326007

Epoch: 6| Step: 11
Training loss: 0.9078818788789124
Validation loss: 2.6257920659667335

Epoch: 6| Step: 12
Training loss: 1.0349003889460031
Validation loss: 2.612918792510431

Epoch: 6| Step: 13
Training loss: 0.9425426288344231
Validation loss: 2.5838674690402943

Epoch: 411| Step: 0
Training loss: 0.8082933098103331
Validation loss: 2.5750037671651103

Epoch: 6| Step: 1
Training loss: 1.1451883870696875
Validation loss: 2.618177312172157

Epoch: 6| Step: 2
Training loss: 0.942550849757055
Validation loss: 2.6269152935192173

Epoch: 6| Step: 3
Training loss: 0.6554047045148597
Validation loss: 2.662899639839416

Epoch: 6| Step: 4
Training loss: 1.079256818140552
Validation loss: 2.6334633706575707

Epoch: 6| Step: 5
Training loss: 0.7192209608138086
Validation loss: 2.6547928197788813

Epoch: 6| Step: 6
Training loss: 0.6815128589237014
Validation loss: 2.7830969432185024

Epoch: 6| Step: 7
Training loss: 0.7706382263979109
Validation loss: 2.724900942643949

Epoch: 6| Step: 8
Training loss: 0.6867443830720754
Validation loss: 2.661139337840815

Epoch: 6| Step: 9
Training loss: 0.9473523287075625
Validation loss: 2.677618905807044

Epoch: 6| Step: 10
Training loss: 1.1447510491970543
Validation loss: 2.7014631186525992

Epoch: 6| Step: 11
Training loss: 1.0169305479777861
Validation loss: 2.7366735842505445

Epoch: 6| Step: 12
Training loss: 0.8745604841734805
Validation loss: 2.6542547473834475

Epoch: 6| Step: 13
Training loss: 0.6721672487068006
Validation loss: 2.7007565715803654

Epoch: 412| Step: 0
Training loss: 0.6029572110185302
Validation loss: 2.640696101388247

Epoch: 6| Step: 1
Training loss: 0.5968224187728421
Validation loss: 2.5990925654197072

Epoch: 6| Step: 2
Training loss: 0.9680037238920322
Validation loss: 2.6085377566350907

Epoch: 6| Step: 3
Training loss: 0.6891503898638877
Validation loss: 2.570281472062317

Epoch: 6| Step: 4
Training loss: 0.8940375019033432
Validation loss: 2.638095004867591

Epoch: 6| Step: 5
Training loss: 0.6834257300836869
Validation loss: 2.6824615474100533

Epoch: 6| Step: 6
Training loss: 0.5769680664359279
Validation loss: 2.6614913838842065

Epoch: 6| Step: 7
Training loss: 1.1428631288507916
Validation loss: 2.6669463194799117

Epoch: 6| Step: 8
Training loss: 1.3807102322464306
Validation loss: 2.6943710378324086

Epoch: 6| Step: 9
Training loss: 0.8789635533619883
Validation loss: 2.7487671718549658

Epoch: 6| Step: 10
Training loss: 1.0018410424791708
Validation loss: 2.775673680252603

Epoch: 6| Step: 11
Training loss: 0.9287207890739148
Validation loss: 2.7448690404729557

Epoch: 6| Step: 12
Training loss: 0.8986127931171957
Validation loss: 2.660583909846297

Epoch: 6| Step: 13
Training loss: 0.7498143284171152
Validation loss: 2.7457802215054996

Epoch: 413| Step: 0
Training loss: 1.0623424637634238
Validation loss: 2.679871340600294

Epoch: 6| Step: 1
Training loss: 0.7229717906049506
Validation loss: 2.709538431309323

Epoch: 6| Step: 2
Training loss: 0.9146140627090419
Validation loss: 2.7199968862282002

Epoch: 6| Step: 3
Training loss: 0.7757283587447487
Validation loss: 2.6950532502886237

Epoch: 6| Step: 4
Training loss: 0.6130850897348988
Validation loss: 2.7077441283742223

Epoch: 6| Step: 5
Training loss: 1.0530528646604849
Validation loss: 2.66482518112377

Epoch: 6| Step: 6
Training loss: 0.9986027254033425
Validation loss: 2.697051853526807

Epoch: 6| Step: 7
Training loss: 0.7865321312104888
Validation loss: 2.680452198765754

Epoch: 6| Step: 8
Training loss: 0.6252377296366339
Validation loss: 2.728593683639456

Epoch: 6| Step: 9
Training loss: 1.000305546334482
Validation loss: 2.676329441022907

Epoch: 6| Step: 10
Training loss: 1.1027950668794686
Validation loss: 2.65226063062031

Epoch: 6| Step: 11
Training loss: 0.6538506651739985
Validation loss: 2.627066207777487

Epoch: 6| Step: 12
Training loss: 0.9082797438594103
Validation loss: 2.6546866360236923

Epoch: 6| Step: 13
Training loss: 0.5642419967996477
Validation loss: 2.6704106175383964

Epoch: 414| Step: 0
Training loss: 0.8480015767640624
Validation loss: 2.6967639350638346

Epoch: 6| Step: 1
Training loss: 0.654941116408935
Validation loss: 2.719126605846374

Epoch: 6| Step: 2
Training loss: 1.1771061931629638
Validation loss: 2.7401784146595376

Epoch: 6| Step: 3
Training loss: 0.7157132223462379
Validation loss: 2.749186568899771

Epoch: 6| Step: 4
Training loss: 0.643799198455762
Validation loss: 2.690606399335968

Epoch: 6| Step: 5
Training loss: 0.895264437518847
Validation loss: 2.689997953747393

Epoch: 6| Step: 6
Training loss: 0.821710322021855
Validation loss: 2.657129089893082

Epoch: 6| Step: 7
Training loss: 0.9184813022195146
Validation loss: 2.691142991639538

Epoch: 6| Step: 8
Training loss: 0.7192064577353756
Validation loss: 2.633612853518183

Epoch: 6| Step: 9
Training loss: 0.9513577822003206
Validation loss: 2.662088328311199

Epoch: 6| Step: 10
Training loss: 0.6901832583227224
Validation loss: 2.692191885459193

Epoch: 6| Step: 11
Training loss: 0.7640533275092679
Validation loss: 2.6912102187270355

Epoch: 6| Step: 12
Training loss: 0.8004938866061979
Validation loss: 2.6550487419965614

Epoch: 6| Step: 13
Training loss: 1.0962334367812248
Validation loss: 2.7264562839342856

Epoch: 415| Step: 0
Training loss: 0.7142009242004551
Validation loss: 2.7518244673338694

Epoch: 6| Step: 1
Training loss: 0.6907753517504794
Validation loss: 2.7646946320963313

Epoch: 6| Step: 2
Training loss: 1.0212159250801012
Validation loss: 2.848033892198591

Epoch: 6| Step: 3
Training loss: 0.7410427701861602
Validation loss: 2.7987132646728994

Epoch: 6| Step: 4
Training loss: 0.7142000896358728
Validation loss: 2.820415195557315

Epoch: 6| Step: 5
Training loss: 0.8595295853729578
Validation loss: 2.7471636970885216

Epoch: 6| Step: 6
Training loss: 0.847741399610582
Validation loss: 2.726388220696009

Epoch: 6| Step: 7
Training loss: 0.9895745059506402
Validation loss: 2.655406279360774

Epoch: 6| Step: 8
Training loss: 1.1889259410344997
Validation loss: 2.6189719422458957

Epoch: 6| Step: 9
Training loss: 1.0739411151343168
Validation loss: 2.515655398925595

Epoch: 6| Step: 10
Training loss: 0.7908939597671492
Validation loss: 2.6180752818957833

Epoch: 6| Step: 11
Training loss: 0.6664201956359735
Validation loss: 2.5522931356542333

Epoch: 6| Step: 12
Training loss: 0.5523339698281743
Validation loss: 2.6011478219593673

Epoch: 6| Step: 13
Training loss: 0.5070040209119813
Validation loss: 2.626047213128747

Epoch: 416| Step: 0
Training loss: 0.9367436536925707
Validation loss: 2.6680104413924393

Epoch: 6| Step: 1
Training loss: 0.8053216379910624
Validation loss: 2.7042074369894564

Epoch: 6| Step: 2
Training loss: 0.6605638227764438
Validation loss: 2.699202394412919

Epoch: 6| Step: 3
Training loss: 0.6967946660562491
Validation loss: 2.707389305108539

Epoch: 6| Step: 4
Training loss: 0.4995731081113684
Validation loss: 2.7432877668982063

Epoch: 6| Step: 5
Training loss: 0.8549473188020349
Validation loss: 2.71188658884794

Epoch: 6| Step: 6
Training loss: 0.5007736062643353
Validation loss: 2.6625350346894385

Epoch: 6| Step: 7
Training loss: 0.6723510696753825
Validation loss: 2.6453832346124058

Epoch: 6| Step: 8
Training loss: 0.9283054240658279
Validation loss: 2.625490384996406

Epoch: 6| Step: 9
Training loss: 0.9654698984954517
Validation loss: 2.6501658003899835

Epoch: 6| Step: 10
Training loss: 0.8248977395461288
Validation loss: 2.6424221867773934

Epoch: 6| Step: 11
Training loss: 0.7965690923203252
Validation loss: 2.7194106954425

Epoch: 6| Step: 12
Training loss: 0.9261236402676929
Validation loss: 2.701355489106496

Epoch: 6| Step: 13
Training loss: 0.7354115414823587
Validation loss: 2.6966790020129694

Epoch: 417| Step: 0
Training loss: 0.8814828024088363
Validation loss: 2.6764309653530423

Epoch: 6| Step: 1
Training loss: 0.763153173190602
Validation loss: 2.7311729210773255

Epoch: 6| Step: 2
Training loss: 0.9912064876362554
Validation loss: 2.715146669462128

Epoch: 6| Step: 3
Training loss: 0.731808051704781
Validation loss: 2.728922386496678

Epoch: 6| Step: 4
Training loss: 0.967889773000277
Validation loss: 2.6280681753649096

Epoch: 6| Step: 5
Training loss: 0.905019714288273
Validation loss: 2.643133863913965

Epoch: 6| Step: 6
Training loss: 0.595056201300086
Validation loss: 2.546015900737277

Epoch: 6| Step: 7
Training loss: 0.6135541709528086
Validation loss: 2.570054339862286

Epoch: 6| Step: 8
Training loss: 0.9304645400508572
Validation loss: 2.6332701031622427

Epoch: 6| Step: 9
Training loss: 0.6402190247907191
Validation loss: 2.5780274035543873

Epoch: 6| Step: 10
Training loss: 0.6777042964889733
Validation loss: 2.650054093174687

Epoch: 6| Step: 11
Training loss: 1.2742259387311108
Validation loss: 2.6298346124919085

Epoch: 6| Step: 12
Training loss: 0.6855116615054755
Validation loss: 2.7260799910101436

Epoch: 6| Step: 13
Training loss: 0.965332926555367
Validation loss: 2.7695499163071666

Epoch: 418| Step: 0
Training loss: 1.1029230467858344
Validation loss: 2.762128929889339

Epoch: 6| Step: 1
Training loss: 0.7266657766138395
Validation loss: 2.7360900441330664

Epoch: 6| Step: 2
Training loss: 0.5883398272567497
Validation loss: 2.693684271344653

Epoch: 6| Step: 3
Training loss: 0.6638257221628729
Validation loss: 2.6328673163649325

Epoch: 6| Step: 4
Training loss: 1.235885179186239
Validation loss: 2.6073267315711326

Epoch: 6| Step: 5
Training loss: 0.7678405468436772
Validation loss: 2.6058213101695116

Epoch: 6| Step: 6
Training loss: 0.8005487616256085
Validation loss: 2.587604949346214

Epoch: 6| Step: 7
Training loss: 0.4930528269798225
Validation loss: 2.6113199230551274

Epoch: 6| Step: 8
Training loss: 0.9150766143095915
Validation loss: 2.600527659694443

Epoch: 6| Step: 9
Training loss: 0.8362775806047009
Validation loss: 2.6422800298663787

Epoch: 6| Step: 10
Training loss: 0.9002651698162003
Validation loss: 2.5957683002985728

Epoch: 6| Step: 11
Training loss: 0.8967144573219927
Validation loss: 2.587778410008129

Epoch: 6| Step: 12
Training loss: 0.6452608083198852
Validation loss: 2.673111999185179

Epoch: 6| Step: 13
Training loss: 0.9250208955415091
Validation loss: 2.677603071254963

Epoch: 419| Step: 0
Training loss: 0.7843800973916556
Validation loss: 2.7211151796866697

Epoch: 6| Step: 1
Training loss: 0.9251375173467469
Validation loss: 2.7235297357607235

Epoch: 6| Step: 2
Training loss: 0.7354555499754455
Validation loss: 2.716590418262402

Epoch: 6| Step: 3
Training loss: 0.7742109573541789
Validation loss: 2.695209431174892

Epoch: 6| Step: 4
Training loss: 0.856583100286559
Validation loss: 2.6392738150778148

Epoch: 6| Step: 5
Training loss: 0.9198363440532824
Validation loss: 2.7021262615228148

Epoch: 6| Step: 6
Training loss: 0.8833919750097848
Validation loss: 2.6329936824529137

Epoch: 6| Step: 7
Training loss: 1.0317370102852441
Validation loss: 2.6497361291711337

Epoch: 6| Step: 8
Training loss: 0.7910884870715388
Validation loss: 2.636174938495302

Epoch: 6| Step: 9
Training loss: 0.5698716014000121
Validation loss: 2.658872872690623

Epoch: 6| Step: 10
Training loss: 0.561022619733193
Validation loss: 2.698245029767813

Epoch: 6| Step: 11
Training loss: 0.7412084446238135
Validation loss: 2.7014439083359583

Epoch: 6| Step: 12
Training loss: 0.7491946267231132
Validation loss: 2.670625569261448

Epoch: 6| Step: 13
Training loss: 0.818360613182424
Validation loss: 2.6767083337073547

Epoch: 420| Step: 0
Training loss: 0.47123030269751265
Validation loss: 2.6337579374792717

Epoch: 6| Step: 1
Training loss: 0.5912265106358018
Validation loss: 2.680635275393776

Epoch: 6| Step: 2
Training loss: 0.576122967212192
Validation loss: 2.658785683064093

Epoch: 6| Step: 3
Training loss: 0.7719362118808863
Validation loss: 2.6408328965791497

Epoch: 6| Step: 4
Training loss: 0.991266769565578
Validation loss: 2.6939754247198215

Epoch: 6| Step: 5
Training loss: 0.6006944015689116
Validation loss: 2.60506858211891

Epoch: 6| Step: 6
Training loss: 0.7688321263554453
Validation loss: 2.613897504689846

Epoch: 6| Step: 7
Training loss: 1.130209200576004
Validation loss: 2.6865676622946464

Epoch: 6| Step: 8
Training loss: 0.8022056379002664
Validation loss: 2.627586044586771

Epoch: 6| Step: 9
Training loss: 0.5739383921358223
Validation loss: 2.617610536613842

Epoch: 6| Step: 10
Training loss: 1.0200842749617758
Validation loss: 2.625247489524769

Epoch: 6| Step: 11
Training loss: 0.5770876056866462
Validation loss: 2.671522061421973

Epoch: 6| Step: 12
Training loss: 0.7112737845414575
Validation loss: 2.659235663822414

Epoch: 6| Step: 13
Training loss: 0.6247985038200907
Validation loss: 2.6889747742746084

Epoch: 421| Step: 0
Training loss: 0.8313947221788051
Validation loss: 2.7003852027865483

Epoch: 6| Step: 1
Training loss: 0.9392234220056971
Validation loss: 2.691021069045736

Epoch: 6| Step: 2
Training loss: 0.709025820526932
Validation loss: 2.6592526238476846

Epoch: 6| Step: 3
Training loss: 0.8025513229120602
Validation loss: 2.66815689786286

Epoch: 6| Step: 4
Training loss: 0.5880947835783327
Validation loss: 2.7038113966584567

Epoch: 6| Step: 5
Training loss: 1.0960115212927821
Validation loss: 2.636505314229896

Epoch: 6| Step: 6
Training loss: 0.7564580552347425
Validation loss: 2.629615449966662

Epoch: 6| Step: 7
Training loss: 1.1703485338192179
Validation loss: 2.6593749420249684

Epoch: 6| Step: 8
Training loss: 0.683044474498375
Validation loss: 2.7031678212914025

Epoch: 6| Step: 9
Training loss: 0.4604927600649743
Validation loss: 2.6894155964648947

Epoch: 6| Step: 10
Training loss: 0.7065685718381778
Validation loss: 2.746108581879139

Epoch: 6| Step: 11
Training loss: 0.8953449263367746
Validation loss: 2.7590878773228367

Epoch: 6| Step: 12
Training loss: 0.7465292573268532
Validation loss: 2.7651118863941027

Epoch: 6| Step: 13
Training loss: 0.6192841709412839
Validation loss: 2.7726195656047987

Epoch: 422| Step: 0
Training loss: 0.9541694671611972
Validation loss: 2.6869210499374567

Epoch: 6| Step: 1
Training loss: 0.6856426161291197
Validation loss: 2.6614855312642347

Epoch: 6| Step: 2
Training loss: 0.953203604536809
Validation loss: 2.6230240757174563

Epoch: 6| Step: 3
Training loss: 0.6440328347057374
Validation loss: 2.6674849526273787

Epoch: 6| Step: 4
Training loss: 0.6737555202123519
Validation loss: 2.6142282029475905

Epoch: 6| Step: 5
Training loss: 0.7077271635305249
Validation loss: 2.6831682618429444

Epoch: 6| Step: 6
Training loss: 0.7635506145860264
Validation loss: 2.703557768119687

Epoch: 6| Step: 7
Training loss: 0.7062852411845589
Validation loss: 2.758757518486698

Epoch: 6| Step: 8
Training loss: 0.8463022343279384
Validation loss: 2.782247828675343

Epoch: 6| Step: 9
Training loss: 0.7778731034157822
Validation loss: 2.7582419460020806

Epoch: 6| Step: 10
Training loss: 0.8328270844690839
Validation loss: 2.797794823018512

Epoch: 6| Step: 11
Training loss: 0.9768821803419089
Validation loss: 2.7171584399970645

Epoch: 6| Step: 12
Training loss: 0.6674755350194282
Validation loss: 2.745177418615621

Epoch: 6| Step: 13
Training loss: 0.8245492787691612
Validation loss: 2.670693387210061

Epoch: 423| Step: 0
Training loss: 0.7958253791837658
Validation loss: 2.7027099084865465

Epoch: 6| Step: 1
Training loss: 0.6527525254927204
Validation loss: 2.694818630213863

Epoch: 6| Step: 2
Training loss: 0.5053444380802393
Validation loss: 2.763798507467183

Epoch: 6| Step: 3
Training loss: 0.5664657298460173
Validation loss: 2.758422884875193

Epoch: 6| Step: 4
Training loss: 0.48152853225237147
Validation loss: 2.861516862531515

Epoch: 6| Step: 5
Training loss: 1.036562328137351
Validation loss: 2.7413631406467265

Epoch: 6| Step: 6
Training loss: 1.0046159781098003
Validation loss: 2.7873486008747927

Epoch: 6| Step: 7
Training loss: 0.7066887505434974
Validation loss: 2.811176221633365

Epoch: 6| Step: 8
Training loss: 0.7742994880343507
Validation loss: 2.7752211159026405

Epoch: 6| Step: 9
Training loss: 0.8290206815811031
Validation loss: 2.6718916715878893

Epoch: 6| Step: 10
Training loss: 1.1516418388292502
Validation loss: 2.6119841971432947

Epoch: 6| Step: 11
Training loss: 0.7380887138756619
Validation loss: 2.640857438009253

Epoch: 6| Step: 12
Training loss: 0.8901421760730782
Validation loss: 2.6097174474963385

Epoch: 6| Step: 13
Training loss: 0.6533522206085459
Validation loss: 2.6532673714056894

Epoch: 424| Step: 0
Training loss: 0.9757958721839805
Validation loss: 2.6367925638298466

Epoch: 6| Step: 1
Training loss: 0.7072319041094923
Validation loss: 2.6291387869862546

Epoch: 6| Step: 2
Training loss: 0.6155264025122206
Validation loss: 2.710856660925657

Epoch: 6| Step: 3
Training loss: 0.8013398245989152
Validation loss: 2.71783174522358

Epoch: 6| Step: 4
Training loss: 0.8362210942448671
Validation loss: 2.7287350136098834

Epoch: 6| Step: 5
Training loss: 0.7398727459648433
Validation loss: 2.707293535804079

Epoch: 6| Step: 6
Training loss: 0.9179550819191057
Validation loss: 2.679310815729192

Epoch: 6| Step: 7
Training loss: 0.6654760238776586
Validation loss: 2.7192956077344843

Epoch: 6| Step: 8
Training loss: 0.915995258031673
Validation loss: 2.6460404252433665

Epoch: 6| Step: 9
Training loss: 0.530402461139153
Validation loss: 2.62614562754253

Epoch: 6| Step: 10
Training loss: 0.8052996556919735
Validation loss: 2.667692245520289

Epoch: 6| Step: 11
Training loss: 0.6710906662609228
Validation loss: 2.5944321589436568

Epoch: 6| Step: 12
Training loss: 0.9271293514417551
Validation loss: 2.632863211214142

Epoch: 6| Step: 13
Training loss: 0.8954222793249352
Validation loss: 2.6175365461963707

Epoch: 425| Step: 0
Training loss: 0.9446240905620038
Validation loss: 2.6083526740611402

Epoch: 6| Step: 1
Training loss: 0.7585438217877041
Validation loss: 2.7265687667352023

Epoch: 6| Step: 2
Training loss: 1.0360997920118302
Validation loss: 2.6726523564263953

Epoch: 6| Step: 3
Training loss: 0.6908930581929943
Validation loss: 2.7127263802376143

Epoch: 6| Step: 4
Training loss: 0.37420108251736195
Validation loss: 2.6809547326946293

Epoch: 6| Step: 5
Training loss: 0.7786715491565823
Validation loss: 2.696370382532221

Epoch: 6| Step: 6
Training loss: 0.7199338203055973
Validation loss: 2.6600862961588456

Epoch: 6| Step: 7
Training loss: 0.7329209318645941
Validation loss: 2.637397848203057

Epoch: 6| Step: 8
Training loss: 0.8808930045938027
Validation loss: 2.6938344837461536

Epoch: 6| Step: 9
Training loss: 0.9290460890351203
Validation loss: 2.709167980306028

Epoch: 6| Step: 10
Training loss: 0.749124691720457
Validation loss: 2.7347741407902872

Epoch: 6| Step: 11
Training loss: 0.572499979094126
Validation loss: 2.7763870387039096

Epoch: 6| Step: 12
Training loss: 0.5566875504908801
Validation loss: 2.801321647008093

Epoch: 6| Step: 13
Training loss: 0.8356656497035656
Validation loss: 2.7708671300065024

Epoch: 426| Step: 0
Training loss: 0.8137057234618246
Validation loss: 2.818462931245485

Epoch: 6| Step: 1
Training loss: 0.5373705419731278
Validation loss: 2.7862775845001484

Epoch: 6| Step: 2
Training loss: 0.6760873266787311
Validation loss: 2.8734511335864354

Epoch: 6| Step: 3
Training loss: 0.8618284402931055
Validation loss: 2.8222490954767534

Epoch: 6| Step: 4
Training loss: 1.1539340667367748
Validation loss: 2.7648825789404823

Epoch: 6| Step: 5
Training loss: 0.5904542403647823
Validation loss: 2.76342079271144

Epoch: 6| Step: 6
Training loss: 0.9965112147946694
Validation loss: 2.696827441547992

Epoch: 6| Step: 7
Training loss: 0.643267484957302
Validation loss: 2.6670416975553306

Epoch: 6| Step: 8
Training loss: 0.5773106587467234
Validation loss: 2.68045852883033

Epoch: 6| Step: 9
Training loss: 0.5883510978743599
Validation loss: 2.685990833923917

Epoch: 6| Step: 10
Training loss: 0.861515085425892
Validation loss: 2.629886030838984

Epoch: 6| Step: 11
Training loss: 0.5570001344697746
Validation loss: 2.677537698940396

Epoch: 6| Step: 12
Training loss: 0.7163082609065348
Validation loss: 2.7152541474736624

Epoch: 6| Step: 13
Training loss: 0.8350564823920251
Validation loss: 2.6977606596941297

Epoch: 427| Step: 0
Training loss: 0.7556472993373222
Validation loss: 2.692021078706456

Epoch: 6| Step: 1
Training loss: 0.7141259346796773
Validation loss: 2.6912482833089046

Epoch: 6| Step: 2
Training loss: 0.9177275320434307
Validation loss: 2.678665433324027

Epoch: 6| Step: 3
Training loss: 0.8652823200246079
Validation loss: 2.7375110771152498

Epoch: 6| Step: 4
Training loss: 0.9161162168664989
Validation loss: 2.728779675562179

Epoch: 6| Step: 5
Training loss: 0.7793125925415092
Validation loss: 2.68817654307563

Epoch: 6| Step: 6
Training loss: 0.5717648863962392
Validation loss: 2.653780249029286

Epoch: 6| Step: 7
Training loss: 0.6759390453827114
Validation loss: 2.6936662004480887

Epoch: 6| Step: 8
Training loss: 0.7387784061037486
Validation loss: 2.714308944461721

Epoch: 6| Step: 9
Training loss: 0.6587620973652507
Validation loss: 2.7061328654088235

Epoch: 6| Step: 10
Training loss: 0.62849811081462
Validation loss: 2.689270899852519

Epoch: 6| Step: 11
Training loss: 0.56398254630969
Validation loss: 2.7544511837569297

Epoch: 6| Step: 12
Training loss: 0.4873829016288327
Validation loss: 2.6126738081309893

Epoch: 6| Step: 13
Training loss: 0.7597731562930067
Validation loss: 2.6247777542006743

Epoch: 428| Step: 0
Training loss: 0.7487315737028416
Validation loss: 2.671572127102328

Epoch: 6| Step: 1
Training loss: 0.7020761296122497
Validation loss: 2.649449203038819

Epoch: 6| Step: 2
Training loss: 0.4373188665629058
Validation loss: 2.7610843978457784

Epoch: 6| Step: 3
Training loss: 0.8067718842419321
Validation loss: 2.655735878650068

Epoch: 6| Step: 4
Training loss: 0.9644741941354674
Validation loss: 2.7209601206737513

Epoch: 6| Step: 5
Training loss: 0.7552094733569431
Validation loss: 2.654304749526506

Epoch: 6| Step: 6
Training loss: 0.80806637580102
Validation loss: 2.7125850951270185

Epoch: 6| Step: 7
Training loss: 0.5402526433121864
Validation loss: 2.7938881950135666

Epoch: 6| Step: 8
Training loss: 0.6171424462979958
Validation loss: 2.817032489119362

Epoch: 6| Step: 9
Training loss: 0.8389943285194551
Validation loss: 2.7458412774240735

Epoch: 6| Step: 10
Training loss: 0.835720354915188
Validation loss: 2.732234603939448

Epoch: 6| Step: 11
Training loss: 0.5394004370657565
Validation loss: 2.733435216803662

Epoch: 6| Step: 12
Training loss: 0.9711421534044272
Validation loss: 2.707705950818989

Epoch: 6| Step: 13
Training loss: 0.7823518993150572
Validation loss: 2.6710022064079904

Epoch: 429| Step: 0
Training loss: 0.8188353908941827
Validation loss: 2.61743352692054

Epoch: 6| Step: 1
Training loss: 0.738735725148732
Validation loss: 2.7612026655043636

Epoch: 6| Step: 2
Training loss: 0.6462446154253887
Validation loss: 2.6849543617201124

Epoch: 6| Step: 3
Training loss: 0.537709486968872
Validation loss: 2.711253782615292

Epoch: 6| Step: 4
Training loss: 0.8187902222282961
Validation loss: 2.716544254056959

Epoch: 6| Step: 5
Training loss: 0.4061825035951286
Validation loss: 2.768182868366998

Epoch: 6| Step: 6
Training loss: 0.7160604992512516
Validation loss: 2.8033833282977927

Epoch: 6| Step: 7
Training loss: 1.1566400643256831
Validation loss: 2.835317188305172

Epoch: 6| Step: 8
Training loss: 0.7136445122177939
Validation loss: 2.8335716811138365

Epoch: 6| Step: 9
Training loss: 0.485028487504429
Validation loss: 2.9236473515173027

Epoch: 6| Step: 10
Training loss: 0.9317805986797149
Validation loss: 2.7996982908617545

Epoch: 6| Step: 11
Training loss: 0.746548020041596
Validation loss: 2.7940414253955828

Epoch: 6| Step: 12
Training loss: 0.5498613833098372
Validation loss: 2.868513536923216

Epoch: 6| Step: 13
Training loss: 0.7101208953953672
Validation loss: 2.797882580543593

Epoch: 430| Step: 0
Training loss: 0.7573578247248364
Validation loss: 2.734075489897715

Epoch: 6| Step: 1
Training loss: 0.525364871617015
Validation loss: 2.730140531693304

Epoch: 6| Step: 2
Training loss: 0.8923976724130053
Validation loss: 2.7029380219166086

Epoch: 6| Step: 3
Training loss: 0.3424969288764871
Validation loss: 2.7626260133198333

Epoch: 6| Step: 4
Training loss: 0.8012141104529297
Validation loss: 2.6639033295186194

Epoch: 6| Step: 5
Training loss: 0.6211661530524893
Validation loss: 2.762130080781932

Epoch: 6| Step: 6
Training loss: 0.9472289402730644
Validation loss: 2.7444280037235202

Epoch: 6| Step: 7
Training loss: 1.0097350479307199
Validation loss: 2.7786817515565376

Epoch: 6| Step: 8
Training loss: 0.7445187546601156
Validation loss: 2.713324288553101

Epoch: 6| Step: 9
Training loss: 0.7449379401632539
Validation loss: 2.720541688867586

Epoch: 6| Step: 10
Training loss: 0.42653337595799207
Validation loss: 2.76542122587658

Epoch: 6| Step: 11
Training loss: 0.3878780866211827
Validation loss: 2.713071996028591

Epoch: 6| Step: 12
Training loss: 0.4340601809379964
Validation loss: 2.7096883807428163

Epoch: 6| Step: 13
Training loss: 0.7494430460829242
Validation loss: 2.7363424289428435

Epoch: 431| Step: 0
Training loss: 0.5757958688523502
Validation loss: 2.707730201663604

Epoch: 6| Step: 1
Training loss: 1.04683725089721
Validation loss: 2.7158381189345313

Epoch: 6| Step: 2
Training loss: 1.0109222693968973
Validation loss: 2.665322715133513

Epoch: 6| Step: 3
Training loss: 0.9347393716073731
Validation loss: 2.688470857306802

Epoch: 6| Step: 4
Training loss: 0.712420290118903
Validation loss: 2.730897330437463

Epoch: 6| Step: 5
Training loss: 0.5878682433268719
Validation loss: 2.7109622716000943

Epoch: 6| Step: 6
Training loss: 0.44545780287517667
Validation loss: 2.644031141166028

Epoch: 6| Step: 7
Training loss: 0.9275266073374274
Validation loss: 2.684028749409563

Epoch: 6| Step: 8
Training loss: 0.7421426056785793
Validation loss: 2.682824318351923

Epoch: 6| Step: 9
Training loss: 0.614148541117905
Validation loss: 2.760169026524932

Epoch: 6| Step: 10
Training loss: 0.5126343899815423
Validation loss: 2.8578582520852285

Epoch: 6| Step: 11
Training loss: 0.4963828918801832
Validation loss: 2.7832640738255194

Epoch: 6| Step: 12
Training loss: 0.5783544033712333
Validation loss: 2.8036344316904915

Epoch: 6| Step: 13
Training loss: 0.8301828116431228
Validation loss: 2.8241760897898964

Epoch: 432| Step: 0
Training loss: 0.7623045795977177
Validation loss: 2.8174793246711394

Epoch: 6| Step: 1
Training loss: 0.9437244096027504
Validation loss: 2.7768566707784896

Epoch: 6| Step: 2
Training loss: 1.0906312346621805
Validation loss: 2.7350998272016143

Epoch: 6| Step: 3
Training loss: 0.463045874849272
Validation loss: 2.744849554871408

Epoch: 6| Step: 4
Training loss: 0.42910616303149424
Validation loss: 2.695961104779346

Epoch: 6| Step: 5
Training loss: 0.6476807372246192
Validation loss: 2.642881809706194

Epoch: 6| Step: 6
Training loss: 0.6103234856823433
Validation loss: 2.6999072730071516

Epoch: 6| Step: 7
Training loss: 0.5759633608314407
Validation loss: 2.7161346659639545

Epoch: 6| Step: 8
Training loss: 0.502752446914629
Validation loss: 2.7421525914939946

Epoch: 6| Step: 9
Training loss: 0.7387771152225565
Validation loss: 2.7161983632426883

Epoch: 6| Step: 10
Training loss: 0.48564136227176535
Validation loss: 2.7169871845226266

Epoch: 6| Step: 11
Training loss: 0.7433521970000425
Validation loss: 2.769739140508294

Epoch: 6| Step: 12
Training loss: 0.7242954118928028
Validation loss: 2.7433205751498617

Epoch: 6| Step: 13
Training loss: 0.5253247641652794
Validation loss: 2.8024553999696717

Epoch: 433| Step: 0
Training loss: 0.6341666344514388
Validation loss: 2.7910650705843247

Epoch: 6| Step: 1
Training loss: 1.095217183927365
Validation loss: 2.758863571196093

Epoch: 6| Step: 2
Training loss: 0.6384221326534838
Validation loss: 2.7792821344488248

Epoch: 6| Step: 3
Training loss: 0.5917888174987777
Validation loss: 2.729814763078557

Epoch: 6| Step: 4
Training loss: 0.7852556535796028
Validation loss: 2.728003499113656

Epoch: 6| Step: 5
Training loss: 0.36324096784500753
Validation loss: 2.6390885391893084

Epoch: 6| Step: 6
Training loss: 0.6044013428100045
Validation loss: 2.682532324997629

Epoch: 6| Step: 7
Training loss: 0.8083800987270433
Validation loss: 2.660187424651176

Epoch: 6| Step: 8
Training loss: 0.5679291870106586
Validation loss: 2.6970761928014957

Epoch: 6| Step: 9
Training loss: 0.5621823632608361
Validation loss: 2.730824328669522

Epoch: 6| Step: 10
Training loss: 0.591751801942919
Validation loss: 2.7547007756049458

Epoch: 6| Step: 11
Training loss: 0.7901492047952862
Validation loss: 2.731321064470442

Epoch: 6| Step: 12
Training loss: 0.43816577117633015
Validation loss: 2.7182277309347906

Epoch: 6| Step: 13
Training loss: 1.0200786655608944
Validation loss: 2.6712477544508237

Epoch: 434| Step: 0
Training loss: 0.6760608337302815
Validation loss: 2.7077296586818655

Epoch: 6| Step: 1
Training loss: 1.0254835104879028
Validation loss: 2.6757278771193826

Epoch: 6| Step: 2
Training loss: 0.74583498476865
Validation loss: 2.710589002622812

Epoch: 6| Step: 3
Training loss: 0.6408092884997846
Validation loss: 2.6909477090573617

Epoch: 6| Step: 4
Training loss: 0.539575305226032
Validation loss: 2.7165570970293804

Epoch: 6| Step: 5
Training loss: 0.849135834717863
Validation loss: 2.8656058318794613

Epoch: 6| Step: 6
Training loss: 0.6430759762317639
Validation loss: 2.776005003342897

Epoch: 6| Step: 7
Training loss: 0.5845552034015453
Validation loss: 2.8224993511071936

Epoch: 6| Step: 8
Training loss: 0.9530444189309404
Validation loss: 2.8780670806325426

Epoch: 6| Step: 9
Training loss: 0.8707598401197337
Validation loss: 2.7739580265913557

Epoch: 6| Step: 10
Training loss: 0.6379293155558128
Validation loss: 2.725323764570848

Epoch: 6| Step: 11
Training loss: 0.7137842717268547
Validation loss: 2.6453160408538596

Epoch: 6| Step: 12
Training loss: 0.611086739851271
Validation loss: 2.645482397960705

Epoch: 6| Step: 13
Training loss: 0.7584391097470975
Validation loss: 2.6161926048655078

Epoch: 435| Step: 0
Training loss: 0.861472500488938
Validation loss: 2.6135497209514296

Epoch: 6| Step: 1
Training loss: 0.5400402213941283
Validation loss: 2.622078359580878

Epoch: 6| Step: 2
Training loss: 0.8221522454678228
Validation loss: 2.718694167459066

Epoch: 6| Step: 3
Training loss: 1.1299161518687597
Validation loss: 2.790817235894725

Epoch: 6| Step: 4
Training loss: 0.8317317154837823
Validation loss: 2.8495685869922953

Epoch: 6| Step: 5
Training loss: 0.5439578590795212
Validation loss: 2.8135579132850084

Epoch: 6| Step: 6
Training loss: 0.8239316756754382
Validation loss: 2.7983386225496085

Epoch: 6| Step: 7
Training loss: 0.651948317869462
Validation loss: 2.7930947726612843

Epoch: 6| Step: 8
Training loss: 0.6626680206066566
Validation loss: 2.7534284894200716

Epoch: 6| Step: 9
Training loss: 0.5198166715714393
Validation loss: 2.6781754894386247

Epoch: 6| Step: 10
Training loss: 0.4934462693530178
Validation loss: 2.5923659680358457

Epoch: 6| Step: 11
Training loss: 0.6391105428605316
Validation loss: 2.6009392130122437

Epoch: 6| Step: 12
Training loss: 0.7144128720314628
Validation loss: 2.5973967993865594

Epoch: 6| Step: 13
Training loss: 0.6556060447170987
Validation loss: 2.5906422545836647

Epoch: 436| Step: 0
Training loss: 0.6089463315658269
Validation loss: 2.6493123277872326

Epoch: 6| Step: 1
Training loss: 0.592950784966454
Validation loss: 2.69434754425716

Epoch: 6| Step: 2
Training loss: 0.9185638122300047
Validation loss: 2.735647795404055

Epoch: 6| Step: 3
Training loss: 0.7148601342496721
Validation loss: 2.645753293566405

Epoch: 6| Step: 4
Training loss: 0.7594859728946162
Validation loss: 2.6853403388856627

Epoch: 6| Step: 5
Training loss: 0.6226073481598826
Validation loss: 2.713258993370743

Epoch: 6| Step: 6
Training loss: 1.0384185631328589
Validation loss: 2.7462720455858505

Epoch: 6| Step: 7
Training loss: 0.7525273496150423
Validation loss: 2.8315466034215695

Epoch: 6| Step: 8
Training loss: 0.8972688454822212
Validation loss: 2.74884190883219

Epoch: 6| Step: 9
Training loss: 0.5769111674864625
Validation loss: 2.732450291029348

Epoch: 6| Step: 10
Training loss: 0.7018942551931158
Validation loss: 2.6063048371447155

Epoch: 6| Step: 11
Training loss: 0.6866083214756974
Validation loss: 2.6781112735831263

Epoch: 6| Step: 12
Training loss: 0.7030845206582488
Validation loss: 2.6917781932704554

Epoch: 6| Step: 13
Training loss: 0.9042475050432222
Validation loss: 2.65486994777438

Epoch: 437| Step: 0
Training loss: 0.62400290107664
Validation loss: 2.660301574232908

Epoch: 6| Step: 1
Training loss: 0.7155378546814181
Validation loss: 2.6586811982079435

Epoch: 6| Step: 2
Training loss: 0.794600738217414
Validation loss: 2.6103444991876628

Epoch: 6| Step: 3
Training loss: 1.041310796348076
Validation loss: 2.623595467484848

Epoch: 6| Step: 4
Training loss: 0.49750706459186034
Validation loss: 2.618984929899205

Epoch: 6| Step: 5
Training loss: 0.5300838349273056
Validation loss: 2.693963196852112

Epoch: 6| Step: 6
Training loss: 0.8683060657578868
Validation loss: 2.8206809411706133

Epoch: 6| Step: 7
Training loss: 0.955101777390376
Validation loss: 2.8758194349939292

Epoch: 6| Step: 8
Training loss: 0.761369674120375
Validation loss: 2.865889682561509

Epoch: 6| Step: 9
Training loss: 0.6234337493477723
Validation loss: 2.8519482495399875

Epoch: 6| Step: 10
Training loss: 0.5999489732740677
Validation loss: 2.7411014039874066

Epoch: 6| Step: 11
Training loss: 0.7320232476414841
Validation loss: 2.711647988622198

Epoch: 6| Step: 12
Training loss: 0.5763848121401867
Validation loss: 2.7212844523332844

Epoch: 6| Step: 13
Training loss: 1.0954413823855373
Validation loss: 2.7092443010073666

Epoch: 438| Step: 0
Training loss: 0.7352754469913321
Validation loss: 2.737524837805073

Epoch: 6| Step: 1
Training loss: 0.9436104323909658
Validation loss: 2.6711890546635204

Epoch: 6| Step: 2
Training loss: 1.0082862982275522
Validation loss: 2.649229053299912

Epoch: 6| Step: 3
Training loss: 0.7367756745725772
Validation loss: 2.699484017601024

Epoch: 6| Step: 4
Training loss: 0.5550856974311397
Validation loss: 2.710893768045759

Epoch: 6| Step: 5
Training loss: 0.711663765986991
Validation loss: 2.7092524851694066

Epoch: 6| Step: 6
Training loss: 0.9624575865677264
Validation loss: 2.830185843612242

Epoch: 6| Step: 7
Training loss: 0.7401126570262696
Validation loss: 2.8034878912996968

Epoch: 6| Step: 8
Training loss: 0.7818957139891652
Validation loss: 2.8231594971288896

Epoch: 6| Step: 9
Training loss: 0.5299828788852946
Validation loss: 2.821828672381513

Epoch: 6| Step: 10
Training loss: 1.1214198791177445
Validation loss: 2.8199066123649765

Epoch: 6| Step: 11
Training loss: 0.5714629079941805
Validation loss: 2.7644645138359913

Epoch: 6| Step: 12
Training loss: 0.6994276533854316
Validation loss: 2.780968098159004

Epoch: 6| Step: 13
Training loss: 0.7411878579709248
Validation loss: 2.733057980120249

Epoch: 439| Step: 0
Training loss: 1.013312891787427
Validation loss: 2.729843177133766

Epoch: 6| Step: 1
Training loss: 0.6028844007581307
Validation loss: 2.7469095580177

Epoch: 6| Step: 2
Training loss: 0.6336071064737144
Validation loss: 2.7450528584563543

Epoch: 6| Step: 3
Training loss: 0.5707695579636625
Validation loss: 2.742457218074097

Epoch: 6| Step: 4
Training loss: 0.6180204975052892
Validation loss: 2.7615874824460143

Epoch: 6| Step: 5
Training loss: 0.80633043878558
Validation loss: 2.7173706443388244

Epoch: 6| Step: 6
Training loss: 0.9056712637510735
Validation loss: 2.7037178080431366

Epoch: 6| Step: 7
Training loss: 0.6829780857946581
Validation loss: 2.68227983984454

Epoch: 6| Step: 8
Training loss: 0.64223508171286
Validation loss: 2.7135784905705793

Epoch: 6| Step: 9
Training loss: 0.9438501822748143
Validation loss: 2.680959105106108

Epoch: 6| Step: 10
Training loss: 0.690837734133236
Validation loss: 2.6779772432474775

Epoch: 6| Step: 11
Training loss: 0.7789429742999828
Validation loss: 2.6797480599517685

Epoch: 6| Step: 12
Training loss: 0.7914729550597439
Validation loss: 2.623498774970309

Epoch: 6| Step: 13
Training loss: 0.7468184701123998
Validation loss: 2.6832074031146895

Epoch: 440| Step: 0
Training loss: 0.6309606039834376
Validation loss: 2.573951703480779

Epoch: 6| Step: 1
Training loss: 0.5836716136541178
Validation loss: 2.653690196756151

Epoch: 6| Step: 2
Training loss: 0.8561228163439717
Validation loss: 2.6723892133520866

Epoch: 6| Step: 3
Training loss: 0.901899880894138
Validation loss: 2.6543063364054453

Epoch: 6| Step: 4
Training loss: 0.5148501787956485
Validation loss: 2.6749571781949704

Epoch: 6| Step: 5
Training loss: 0.620143331141816
Validation loss: 2.7113088157445113

Epoch: 6| Step: 6
Training loss: 1.0603984356545242
Validation loss: 2.7370332857123554

Epoch: 6| Step: 7
Training loss: 0.5100760848193998
Validation loss: 2.7265233544396965

Epoch: 6| Step: 8
Training loss: 0.7751500984167718
Validation loss: 2.847091381560907

Epoch: 6| Step: 9
Training loss: 0.4813394333362846
Validation loss: 2.795894713848449

Epoch: 6| Step: 10
Training loss: 0.6390012305998556
Validation loss: 2.874799306747716

Epoch: 6| Step: 11
Training loss: 0.775519679785785
Validation loss: 2.8539271335375522

Epoch: 6| Step: 12
Training loss: 0.8218977732821185
Validation loss: 2.783734372841238

Epoch: 6| Step: 13
Training loss: 0.7094328751670791
Validation loss: 2.7955623366510007

Epoch: 441| Step: 0
Training loss: 0.7845818995217707
Validation loss: 2.817381839322297

Epoch: 6| Step: 1
Training loss: 0.6952239633833592
Validation loss: 2.7934118457365402

Epoch: 6| Step: 2
Training loss: 0.7931097121452461
Validation loss: 2.813757947122227

Epoch: 6| Step: 3
Training loss: 0.5580906770069308
Validation loss: 2.7948372235153265

Epoch: 6| Step: 4
Training loss: 0.6439758682290736
Validation loss: 2.720841359763893

Epoch: 6| Step: 5
Training loss: 0.7341036193685683
Validation loss: 2.8109531387309676

Epoch: 6| Step: 6
Training loss: 0.5827973719210989
Validation loss: 2.753391695762572

Epoch: 6| Step: 7
Training loss: 0.7192283365529393
Validation loss: 2.712018093540146

Epoch: 6| Step: 8
Training loss: 0.5259921802875042
Validation loss: 2.7286589395308187

Epoch: 6| Step: 9
Training loss: 0.5775899731125014
Validation loss: 2.686220855294438

Epoch: 6| Step: 10
Training loss: 0.8833167399941196
Validation loss: 2.6414935096363976

Epoch: 6| Step: 11
Training loss: 0.6282529577237996
Validation loss: 2.691989254197415

Epoch: 6| Step: 12
Training loss: 0.9314489587323297
Validation loss: 2.6840315030954773

Epoch: 6| Step: 13
Training loss: 0.5680575273858346
Validation loss: 2.779326198599224

Epoch: 442| Step: 0
Training loss: 0.645177621115605
Validation loss: 2.706224740654204

Epoch: 6| Step: 1
Training loss: 0.5820554945843769
Validation loss: 2.6882468228296097

Epoch: 6| Step: 2
Training loss: 0.6022347991215804
Validation loss: 2.715772774454157

Epoch: 6| Step: 3
Training loss: 0.6232095822825509
Validation loss: 2.739626450193295

Epoch: 6| Step: 4
Training loss: 0.7440430985268007
Validation loss: 2.8122922326099227

Epoch: 6| Step: 5
Training loss: 0.5469286483608089
Validation loss: 2.8436403078714707

Epoch: 6| Step: 6
Training loss: 0.5988483383241016
Validation loss: 2.8118922954569223

Epoch: 6| Step: 7
Training loss: 0.7114206705322177
Validation loss: 2.855422006094866

Epoch: 6| Step: 8
Training loss: 0.5377707276421843
Validation loss: 2.783659430681917

Epoch: 6| Step: 9
Training loss: 0.7933873917757012
Validation loss: 2.7861523516683273

Epoch: 6| Step: 10
Training loss: 0.9964393165895793
Validation loss: 2.7380985012192958

Epoch: 6| Step: 11
Training loss: 0.9337901144334956
Validation loss: 2.6856998654338815

Epoch: 6| Step: 12
Training loss: 0.9362369612332089
Validation loss: 2.709958826012691

Epoch: 6| Step: 13
Training loss: 0.5849736487738147
Validation loss: 2.6755217266223603

Epoch: 443| Step: 0
Training loss: 0.6872248315667392
Validation loss: 2.636877255797071

Epoch: 6| Step: 1
Training loss: 0.9857205776493587
Validation loss: 2.6754489515996682

Epoch: 6| Step: 2
Training loss: 0.48084368459356863
Validation loss: 2.6754829630301287

Epoch: 6| Step: 3
Training loss: 0.7204083509242876
Validation loss: 2.7812985476710805

Epoch: 6| Step: 4
Training loss: 0.5143124028028581
Validation loss: 2.8269799937226368

Epoch: 6| Step: 5
Training loss: 0.7639120363331161
Validation loss: 2.7850107919197398

Epoch: 6| Step: 6
Training loss: 0.6600311431617374
Validation loss: 2.8287406518241993

Epoch: 6| Step: 7
Training loss: 0.6453144054985085
Validation loss: 2.87358676342252

Epoch: 6| Step: 8
Training loss: 0.599110647544169
Validation loss: 2.8001858456561073

Epoch: 6| Step: 9
Training loss: 0.7252970514456083
Validation loss: 2.7502571043568835

Epoch: 6| Step: 10
Training loss: 0.7327402465598077
Validation loss: 2.743721687674811

Epoch: 6| Step: 11
Training loss: 0.8057123343138268
Validation loss: 2.7454032192536766

Epoch: 6| Step: 12
Training loss: 0.6609608188420415
Validation loss: 2.6770506880336944

Epoch: 6| Step: 13
Training loss: 0.7527791824030547
Validation loss: 2.6770482982515023

Epoch: 444| Step: 0
Training loss: 1.0777620450954788
Validation loss: 2.710114734398025

Epoch: 6| Step: 1
Training loss: 0.4387431873977248
Validation loss: 2.657521156879946

Epoch: 6| Step: 2
Training loss: 0.5115003338082754
Validation loss: 2.803629782881913

Epoch: 6| Step: 3
Training loss: 0.7557493617704664
Validation loss: 2.788375492058453

Epoch: 6| Step: 4
Training loss: 1.0907114601294938
Validation loss: 2.8744172597555746

Epoch: 6| Step: 5
Training loss: 0.9043452536245744
Validation loss: 2.86557217725729

Epoch: 6| Step: 6
Training loss: 0.5099701745063451
Validation loss: 2.800432184334627

Epoch: 6| Step: 7
Training loss: 0.5136320149436315
Validation loss: 2.790190738324477

Epoch: 6| Step: 8
Training loss: 0.5469981463608377
Validation loss: 2.7812656730753162

Epoch: 6| Step: 9
Training loss: 0.5815790967505023
Validation loss: 2.702101511858573

Epoch: 6| Step: 10
Training loss: 0.805841562774148
Validation loss: 2.6776560209178144

Epoch: 6| Step: 11
Training loss: 0.8090807788680334
Validation loss: 2.686965726634071

Epoch: 6| Step: 12
Training loss: 0.8126561675010248
Validation loss: 2.7866483439370913

Epoch: 6| Step: 13
Training loss: 0.6025990559837374
Validation loss: 2.7754152794856295

Epoch: 445| Step: 0
Training loss: 0.6910863017526714
Validation loss: 2.77046443998038

Epoch: 6| Step: 1
Training loss: 0.6870028692460425
Validation loss: 2.7317489584358188

Epoch: 6| Step: 2
Training loss: 1.0398488331934888
Validation loss: 2.7230103972534545

Epoch: 6| Step: 3
Training loss: 0.7515045016744659
Validation loss: 2.7343492924526283

Epoch: 6| Step: 4
Training loss: 0.7100025358960708
Validation loss: 2.6693178250278007

Epoch: 6| Step: 5
Training loss: 0.7998392286282784
Validation loss: 2.7583895791841213

Epoch: 6| Step: 6
Training loss: 0.6258719798785269
Validation loss: 2.773856304229524

Epoch: 6| Step: 7
Training loss: 0.47650186747077944
Validation loss: 2.7985003701621496

Epoch: 6| Step: 8
Training loss: 0.6414699332326266
Validation loss: 2.7713929856412296

Epoch: 6| Step: 9
Training loss: 0.6973251189166844
Validation loss: 2.828219656299843

Epoch: 6| Step: 10
Training loss: 0.8530779312060625
Validation loss: 2.890120756140979

Epoch: 6| Step: 11
Training loss: 0.5138675621550415
Validation loss: 2.786069016874442

Epoch: 6| Step: 12
Training loss: 0.6959151110497158
Validation loss: 2.7790586289467836

Epoch: 6| Step: 13
Training loss: 0.813358037220367
Validation loss: 2.8505699206925197

Epoch: 446| Step: 0
Training loss: 0.4850852588799277
Validation loss: 2.841194891338543

Epoch: 6| Step: 1
Training loss: 0.8517842835159829
Validation loss: 2.902127818807043

Epoch: 6| Step: 2
Training loss: 0.6161962347196039
Validation loss: 2.8163066957526155

Epoch: 6| Step: 3
Training loss: 0.802501635445803
Validation loss: 2.83612481681741

Epoch: 6| Step: 4
Training loss: 0.391549599260708
Validation loss: 2.8490403400081106

Epoch: 6| Step: 5
Training loss: 0.6275962786884496
Validation loss: 2.8172108228031534

Epoch: 6| Step: 6
Training loss: 0.4605001055368392
Validation loss: 2.815870003831676

Epoch: 6| Step: 7
Training loss: 0.9455335689599074
Validation loss: 2.828125

Epoch: 6| Step: 8
Training loss: 0.5635334164714192
Validation loss: 2.8230123374652254

Epoch: 6| Step: 9
Training loss: 0.5810746902741377
Validation loss: 2.7664499363595962

Epoch: 6| Step: 10
Training loss: 0.6786825050600883
Validation loss: 2.744280995028994

Epoch: 6| Step: 11
Training loss: 0.6784907800389552
Validation loss: 2.681922951450903

Epoch: 6| Step: 12
Training loss: 0.3608256790209719
Validation loss: 2.6495445885794653

Epoch: 6| Step: 13
Training loss: 0.5506935861502532
Validation loss: 2.6996407075525584

Epoch: 447| Step: 0
Training loss: 0.582144374222747
Validation loss: 2.668171507697458

Epoch: 6| Step: 1
Training loss: 0.424600293326445
Validation loss: 2.7093960119926424

Epoch: 6| Step: 2
Training loss: 0.6807055686434855
Validation loss: 2.763764928682249

Epoch: 6| Step: 3
Training loss: 0.4728431017062391
Validation loss: 2.675146646728414

Epoch: 6| Step: 4
Training loss: 0.7980849112746388
Validation loss: 2.709172886544344

Epoch: 6| Step: 5
Training loss: 0.4828290572305736
Validation loss: 2.7651730327948703

Epoch: 6| Step: 6
Training loss: 0.6604667475110271
Validation loss: 2.7720583786599247

Epoch: 6| Step: 7
Training loss: 0.57936072380312
Validation loss: 2.7644364700078

Epoch: 6| Step: 8
Training loss: 0.6428710362658764
Validation loss: 2.7576480920935267

Epoch: 6| Step: 9
Training loss: 0.40159509504260854
Validation loss: 2.7845162775038026

Epoch: 6| Step: 10
Training loss: 0.6541664335124903
Validation loss: 2.699137000517322

Epoch: 6| Step: 11
Training loss: 0.7479045523368125
Validation loss: 2.7408079062380666

Epoch: 6| Step: 12
Training loss: 0.5367958957361719
Validation loss: 2.7443102149553362

Epoch: 6| Step: 13
Training loss: 1.0233711046419878
Validation loss: 2.646062155212927

Epoch: 448| Step: 0
Training loss: 0.4409166676110283
Validation loss: 2.7427485110397916

Epoch: 6| Step: 1
Training loss: 0.4934347184279777
Validation loss: 2.775100753719269

Epoch: 6| Step: 2
Training loss: 0.6495116884664306
Validation loss: 2.748757124852986

Epoch: 6| Step: 3
Training loss: 0.6980835207481659
Validation loss: 2.800207003820722

Epoch: 6| Step: 4
Training loss: 0.36645082881733304
Validation loss: 2.738483328988101

Epoch: 6| Step: 5
Training loss: 0.639914001781533
Validation loss: 2.754256465638698

Epoch: 6| Step: 6
Training loss: 0.8720100612694264
Validation loss: 2.7627953890701478

Epoch: 6| Step: 7
Training loss: 0.691814216038868
Validation loss: 2.7878738278098583

Epoch: 6| Step: 8
Training loss: 0.6429063833959054
Validation loss: 2.768980271843731

Epoch: 6| Step: 9
Training loss: 0.8128284377398519
Validation loss: 2.787914934052789

Epoch: 6| Step: 10
Training loss: 0.6909818262575478
Validation loss: 2.8345954458806015

Epoch: 6| Step: 11
Training loss: 0.5791470540337081
Validation loss: 2.745006680738128

Epoch: 6| Step: 12
Training loss: 0.654606919348336
Validation loss: 2.810463697993384

Epoch: 6| Step: 13
Training loss: 0.7549010912420522
Validation loss: 2.794895501659905

Epoch: 449| Step: 0
Training loss: 0.46619067873205394
Validation loss: 2.7587372883577435

Epoch: 6| Step: 1
Training loss: 0.7320913560876775
Validation loss: 2.8218484572425737

Epoch: 6| Step: 2
Training loss: 0.6011329206966932
Validation loss: 2.8112393838928793

Epoch: 6| Step: 3
Training loss: 0.4921654741717596
Validation loss: 2.836187920841579

Epoch: 6| Step: 4
Training loss: 0.38163908349997744
Validation loss: 2.7701795901484454

Epoch: 6| Step: 5
Training loss: 0.5423897599574456
Validation loss: 2.8391707163711777

Epoch: 6| Step: 6
Training loss: 0.5024154255992405
Validation loss: 2.7635481628119227

Epoch: 6| Step: 7
Training loss: 1.1847484231436467
Validation loss: 2.8184604075918833

Epoch: 6| Step: 8
Training loss: 0.6750351861330639
Validation loss: 2.7799134060983035

Epoch: 6| Step: 9
Training loss: 0.595708853271959
Validation loss: 2.7690597010787297

Epoch: 6| Step: 10
Training loss: 0.6537082586584033
Validation loss: 2.7300240768982484

Epoch: 6| Step: 11
Training loss: 0.46634276898960936
Validation loss: 2.7247585533804215

Epoch: 6| Step: 12
Training loss: 0.8180195323552099
Validation loss: 2.697435407292395

Epoch: 6| Step: 13
Training loss: 0.5391749665517174
Validation loss: 2.65886254578608

Epoch: 450| Step: 0
Training loss: 0.5777900859803531
Validation loss: 2.675737908747889

Epoch: 6| Step: 1
Training loss: 0.9085689341205824
Validation loss: 2.6418934320619503

Epoch: 6| Step: 2
Training loss: 0.627972187603276
Validation loss: 2.6749878981129354

Epoch: 6| Step: 3
Training loss: 0.7557826434476104
Validation loss: 2.691606740215553

Epoch: 6| Step: 4
Training loss: 0.6883313181372724
Validation loss: 2.7887310326200656

Epoch: 6| Step: 5
Training loss: 0.3632101789295364
Validation loss: 2.786770417511861

Epoch: 6| Step: 6
Training loss: 0.7788773174517725
Validation loss: 2.830316400600027

Epoch: 6| Step: 7
Training loss: 0.4679625413638824
Validation loss: 2.7999386905588244

Epoch: 6| Step: 8
Training loss: 0.4669743922603101
Validation loss: 2.779492369348819

Epoch: 6| Step: 9
Training loss: 0.7442931572084618
Validation loss: 2.788305156616321

Epoch: 6| Step: 10
Training loss: 0.46062961899552
Validation loss: 2.690962283755309

Epoch: 6| Step: 11
Training loss: 0.7594971170075617
Validation loss: 2.676493358294302

Epoch: 6| Step: 12
Training loss: 0.6582477678955806
Validation loss: 2.7194192289231767

Epoch: 6| Step: 13
Training loss: 0.6696998517441126
Validation loss: 2.6682376009343463

Epoch: 451| Step: 0
Training loss: 0.7255252283916638
Validation loss: 2.721736823865698

Epoch: 6| Step: 1
Training loss: 0.5027003978519751
Validation loss: 2.6488896436907114

Epoch: 6| Step: 2
Training loss: 0.41810431020093886
Validation loss: 2.746522612204492

Epoch: 6| Step: 3
Training loss: 0.6293948627053773
Validation loss: 2.7098919907239045

Epoch: 6| Step: 4
Training loss: 0.5315672544236472
Validation loss: 2.7476375865184917

Epoch: 6| Step: 5
Training loss: 0.465188099235611
Validation loss: 2.7791371195727104

Epoch: 6| Step: 6
Training loss: 0.4738738085933793
Validation loss: 2.7936080521060043

Epoch: 6| Step: 7
Training loss: 0.8125619864660606
Validation loss: 2.7100761063764236

Epoch: 6| Step: 8
Training loss: 0.6498562562165143
Validation loss: 2.772561879798943

Epoch: 6| Step: 9
Training loss: 0.9135172269039321
Validation loss: 2.761175725446507

Epoch: 6| Step: 10
Training loss: 0.6805826847244123
Validation loss: 2.755241167898017

Epoch: 6| Step: 11
Training loss: 0.6011041653917957
Validation loss: 2.823714412190825

Epoch: 6| Step: 12
Training loss: 0.5157888903394324
Validation loss: 2.7465281678746187

Epoch: 6| Step: 13
Training loss: 0.7251412632221048
Validation loss: 2.706333292442134

Epoch: 452| Step: 0
Training loss: 0.5771825170379324
Validation loss: 2.7635085490102393

Epoch: 6| Step: 1
Training loss: 0.5608041418828668
Validation loss: 2.7468509850954907

Epoch: 6| Step: 2
Training loss: 0.41663482862267737
Validation loss: 2.6430953619903828

Epoch: 6| Step: 3
Training loss: 0.8718319830998568
Validation loss: 2.7755595081336155

Epoch: 6| Step: 4
Training loss: 0.8771159609225164
Validation loss: 2.7048076765283016

Epoch: 6| Step: 5
Training loss: 0.5849867418612644
Validation loss: 2.700780568496578

Epoch: 6| Step: 6
Training loss: 0.47788070284259243
Validation loss: 2.6887424465459366

Epoch: 6| Step: 7
Training loss: 0.7170463772223575
Validation loss: 2.7196199333432554

Epoch: 6| Step: 8
Training loss: 0.5191812124811843
Validation loss: 2.775992707374844

Epoch: 6| Step: 9
Training loss: 0.729304768336222
Validation loss: 2.728296291571363

Epoch: 6| Step: 10
Training loss: 0.5753124227943348
Validation loss: 2.6980266671358026

Epoch: 6| Step: 11
Training loss: 0.5193536497885235
Validation loss: 2.746408573805148

Epoch: 6| Step: 12
Training loss: 0.45043915539243207
Validation loss: 2.717939058576416

Epoch: 6| Step: 13
Training loss: 0.5386509084182738
Validation loss: 2.700266508206589

Epoch: 453| Step: 0
Training loss: 0.5868021117215296
Validation loss: 2.760505866762779

Epoch: 6| Step: 1
Training loss: 0.703302975488327
Validation loss: 2.6979598160954414

Epoch: 6| Step: 2
Training loss: 0.4999025369067377
Validation loss: 2.73068632278626

Epoch: 6| Step: 3
Training loss: 0.7449826660315866
Validation loss: 2.723985840832979

Epoch: 6| Step: 4
Training loss: 0.5134144417152599
Validation loss: 2.7147992686188482

Epoch: 6| Step: 5
Training loss: 0.50943043530016
Validation loss: 2.7444111067394035

Epoch: 6| Step: 6
Training loss: 0.5040767588197975
Validation loss: 2.8013598040931353

Epoch: 6| Step: 7
Training loss: 1.01127290659684
Validation loss: 2.826409917550638

Epoch: 6| Step: 8
Training loss: 0.9007673489109237
Validation loss: 2.8934740340027596

Epoch: 6| Step: 9
Training loss: 0.5093728375535244
Validation loss: 2.833628798019927

Epoch: 6| Step: 10
Training loss: 0.6180797838850876
Validation loss: 2.7599761659403947

Epoch: 6| Step: 11
Training loss: 0.532867018296027
Validation loss: 2.747394078451503

Epoch: 6| Step: 12
Training loss: 0.5456115023154929
Validation loss: 2.858624816764639

Epoch: 6| Step: 13
Training loss: 0.5775672696720261
Validation loss: 2.740098351247205

Epoch: 454| Step: 0
Training loss: 0.6164235082417457
Validation loss: 2.748986086187933

Epoch: 6| Step: 1
Training loss: 0.8261311478191972
Validation loss: 2.696198042461944

Epoch: 6| Step: 2
Training loss: 0.34880415395154657
Validation loss: 2.6461443430416307

Epoch: 6| Step: 3
Training loss: 0.7151660296934312
Validation loss: 2.698805958254739

Epoch: 6| Step: 4
Training loss: 0.5902509988681819
Validation loss: 2.666577417151696

Epoch: 6| Step: 5
Training loss: 1.1919361374472055
Validation loss: 2.6743105222627896

Epoch: 6| Step: 6
Training loss: 0.9612384727987326
Validation loss: 2.672265914666418

Epoch: 6| Step: 7
Training loss: 0.618178381008267
Validation loss: 2.7401071973468607

Epoch: 6| Step: 8
Training loss: 0.6380930619649205
Validation loss: 2.894313568976788

Epoch: 6| Step: 9
Training loss: 0.4401680281163174
Validation loss: 2.9042920315874627

Epoch: 6| Step: 10
Training loss: 0.6332371311363553
Validation loss: 2.9481804441018356

Epoch: 6| Step: 11
Training loss: 0.9166714855992201
Validation loss: 2.925063571076093

Epoch: 6| Step: 12
Training loss: 0.7912267332588441
Validation loss: 2.9080623731845905

Epoch: 6| Step: 13
Training loss: 0.4424417384904225
Validation loss: 2.8830099753239113

Epoch: 455| Step: 0
Training loss: 0.9516535798379427
Validation loss: 2.809339867224727

Epoch: 6| Step: 1
Training loss: 0.6486484919682896
Validation loss: 2.7191991617698834

Epoch: 6| Step: 2
Training loss: 0.5176902793432943
Validation loss: 2.7048700098803526

Epoch: 6| Step: 3
Training loss: 0.596294797138186
Validation loss: 2.6658667964172613

Epoch: 6| Step: 4
Training loss: 0.5656501722266933
Validation loss: 2.676796245890514

Epoch: 6| Step: 5
Training loss: 0.46786778400471085
Validation loss: 2.707592317493146

Epoch: 6| Step: 6
Training loss: 0.5926602552476224
Validation loss: 2.729909160066832

Epoch: 6| Step: 7
Training loss: 0.5300713816293248
Validation loss: 2.818788407226906

Epoch: 6| Step: 8
Training loss: 0.8174454495256147
Validation loss: 2.778398473586602

Epoch: 6| Step: 9
Training loss: 0.7318216941960297
Validation loss: 2.8882187596918727

Epoch: 6| Step: 10
Training loss: 0.7280117061375981
Validation loss: 2.788867120818268

Epoch: 6| Step: 11
Training loss: 0.6763885944095138
Validation loss: 2.8012983978825043

Epoch: 6| Step: 12
Training loss: 0.6726151315347619
Validation loss: 2.756702246438266

Epoch: 6| Step: 13
Training loss: 0.9136071660488966
Validation loss: 2.7487619387448476

Epoch: 456| Step: 0
Training loss: 0.7016946443007329
Validation loss: 2.7749707206120777

Epoch: 6| Step: 1
Training loss: 0.5760316322469015
Validation loss: 2.706232346615907

Epoch: 6| Step: 2
Training loss: 0.48332377155755374
Validation loss: 2.6729643684901783

Epoch: 6| Step: 3
Training loss: 1.0209929412836913
Validation loss: 2.687997269276148

Epoch: 6| Step: 4
Training loss: 0.9843549574976288
Validation loss: 2.7058990665045224

Epoch: 6| Step: 5
Training loss: 0.4405321733619704
Validation loss: 2.6934647349330456

Epoch: 6| Step: 6
Training loss: 0.511960503932354
Validation loss: 2.727983601719409

Epoch: 6| Step: 7
Training loss: 0.7472206114129624
Validation loss: 2.6973466798839025

Epoch: 6| Step: 8
Training loss: 0.37076049698382835
Validation loss: 2.737398042333304

Epoch: 6| Step: 9
Training loss: 0.7285715853800458
Validation loss: 2.784837972994609

Epoch: 6| Step: 10
Training loss: 0.5689581113004956
Validation loss: 2.795982971583418

Epoch: 6| Step: 11
Training loss: 0.4982856028747387
Validation loss: 2.7446137912933293

Epoch: 6| Step: 12
Training loss: 0.4979400220950503
Validation loss: 2.758327230771355

Epoch: 6| Step: 13
Training loss: 0.6935720198239973
Validation loss: 2.765472034311797

Epoch: 457| Step: 0
Training loss: 0.6841494889799749
Validation loss: 2.7053616775649747

Epoch: 6| Step: 1
Training loss: 0.45345631358619803
Validation loss: 2.7444749585496084

Epoch: 6| Step: 2
Training loss: 0.5290155542931725
Validation loss: 2.6865502386999194

Epoch: 6| Step: 3
Training loss: 0.7922636759171371
Validation loss: 2.7389567617174575

Epoch: 6| Step: 4
Training loss: 0.7654766016797092
Validation loss: 2.7724349238030856

Epoch: 6| Step: 5
Training loss: 0.8141559818065174
Validation loss: 2.7801984592194273

Epoch: 6| Step: 6
Training loss: 0.510505023107746
Validation loss: 2.790257102805742

Epoch: 6| Step: 7
Training loss: 0.8574459272413043
Validation loss: 2.8528966700207476

Epoch: 6| Step: 8
Training loss: 0.47114769925609606
Validation loss: 2.794511531667486

Epoch: 6| Step: 9
Training loss: 0.7363552017697508
Validation loss: 2.8641005831758597

Epoch: 6| Step: 10
Training loss: 0.4048683255921262
Validation loss: 2.900452837720998

Epoch: 6| Step: 11
Training loss: 0.918467706661859
Validation loss: 2.8269445157997275

Epoch: 6| Step: 12
Training loss: 0.668028399386304
Validation loss: 2.8632282913119145

Epoch: 6| Step: 13
Training loss: 0.5097272134975954
Validation loss: 2.793016396851923

Epoch: 458| Step: 0
Training loss: 0.4084772531066351
Validation loss: 2.742867236104628

Epoch: 6| Step: 1
Training loss: 0.7224604160856627
Validation loss: 2.706919437978202

Epoch: 6| Step: 2
Training loss: 0.5979455484554543
Validation loss: 2.6413250132624984

Epoch: 6| Step: 3
Training loss: 1.0838361209147405
Validation loss: 2.6435144630644003

Epoch: 6| Step: 4
Training loss: 0.7107325667243537
Validation loss: 2.6409358607193685

Epoch: 6| Step: 5
Training loss: 0.521234002176589
Validation loss: 2.6614787081680706

Epoch: 6| Step: 6
Training loss: 0.7165920370263698
Validation loss: 2.638053687977782

Epoch: 6| Step: 7
Training loss: 0.42678946371135923
Validation loss: 2.678274273208348

Epoch: 6| Step: 8
Training loss: 0.5124892047582504
Validation loss: 2.7746785570531776

Epoch: 6| Step: 9
Training loss: 0.5437678213597189
Validation loss: 2.7545405097125033

Epoch: 6| Step: 10
Training loss: 0.5795450297692386
Validation loss: 2.7660821655354946

Epoch: 6| Step: 11
Training loss: 0.4943679769043665
Validation loss: 2.7852673894064695

Epoch: 6| Step: 12
Training loss: 0.8115367314504163
Validation loss: 2.742100655393245

Epoch: 6| Step: 13
Training loss: 0.9067305244602925
Validation loss: 2.7602784224147485

Epoch: 459| Step: 0
Training loss: 0.6968581347285016
Validation loss: 2.8661339094738985

Epoch: 6| Step: 1
Training loss: 0.5734837037891609
Validation loss: 2.8245581092801753

Epoch: 6| Step: 2
Training loss: 0.9133169932423593
Validation loss: 2.7705054459613834

Epoch: 6| Step: 3
Training loss: 0.47797981937755557
Validation loss: 2.7031073376734542

Epoch: 6| Step: 4
Training loss: 0.8111835231493949
Validation loss: 2.681393627952618

Epoch: 6| Step: 5
Training loss: 0.5911215778589763
Validation loss: 2.664227328603699

Epoch: 6| Step: 6
Training loss: 0.6975199345163542
Validation loss: 2.6425311039032695

Epoch: 6| Step: 7
Training loss: 0.5455649351812285
Validation loss: 2.5527489916405606

Epoch: 6| Step: 8
Training loss: 0.6943010195336595
Validation loss: 2.5709489616057257

Epoch: 6| Step: 9
Training loss: 0.6262240820602066
Validation loss: 2.664067079124356

Epoch: 6| Step: 10
Training loss: 0.6692602599579102
Validation loss: 2.6297694277528816

Epoch: 6| Step: 11
Training loss: 0.6186057587315772
Validation loss: 2.7368085658618737

Epoch: 6| Step: 12
Training loss: 0.6465149840516239
Validation loss: 2.7110843820201

Epoch: 6| Step: 13
Training loss: 0.4569715314142769
Validation loss: 2.855479172993296

Epoch: 460| Step: 0
Training loss: 0.7689451125117811
Validation loss: 2.8221657283223225

Epoch: 6| Step: 1
Training loss: 0.31902977501917495
Validation loss: 2.8313144943156066

Epoch: 6| Step: 2
Training loss: 1.0717757309747262
Validation loss: 2.843840433436444

Epoch: 6| Step: 3
Training loss: 0.7804457530317485
Validation loss: 2.836130533225568

Epoch: 6| Step: 4
Training loss: 0.723098537056474
Validation loss: 2.808414911581344

Epoch: 6| Step: 5
Training loss: 0.9868045977943444
Validation loss: 2.815139506797801

Epoch: 6| Step: 6
Training loss: 0.7362257180476202
Validation loss: 2.7707152353421227

Epoch: 6| Step: 7
Training loss: 0.6902619715270394
Validation loss: 2.7649513041903035

Epoch: 6| Step: 8
Training loss: 0.6886843104113366
Validation loss: 2.730554945880886

Epoch: 6| Step: 9
Training loss: 0.5281788183475374
Validation loss: 2.762137532799865

Epoch: 6| Step: 10
Training loss: 0.6526572564875079
Validation loss: 2.7577300667262383

Epoch: 6| Step: 11
Training loss: 0.6119317191919135
Validation loss: 2.7057764650726113

Epoch: 6| Step: 12
Training loss: 0.4546945944950308
Validation loss: 2.7380935669927453

Epoch: 6| Step: 13
Training loss: 0.6303319231860107
Validation loss: 2.8066003593471236

Epoch: 461| Step: 0
Training loss: 0.692266543247521
Validation loss: 2.7843543454712463

Epoch: 6| Step: 1
Training loss: 1.159889318924373
Validation loss: 2.7207850881819766

Epoch: 6| Step: 2
Training loss: 0.522986887083636
Validation loss: 2.813398373139772

Epoch: 6| Step: 3
Training loss: 0.665143849188043
Validation loss: 2.7658441460346266

Epoch: 6| Step: 4
Training loss: 0.6341447111540687
Validation loss: 2.7554371720139472

Epoch: 6| Step: 5
Training loss: 0.42109144702062223
Validation loss: 2.7227388986953094

Epoch: 6| Step: 6
Training loss: 0.7288535308580695
Validation loss: 2.673566375842569

Epoch: 6| Step: 7
Training loss: 0.6285298802837824
Validation loss: 2.738717197283868

Epoch: 6| Step: 8
Training loss: 0.5557732231841007
Validation loss: 2.680402758519895

Epoch: 6| Step: 9
Training loss: 0.5098980552565182
Validation loss: 2.720107050453365

Epoch: 6| Step: 10
Training loss: 0.4950516185193101
Validation loss: 2.762549966328609

Epoch: 6| Step: 11
Training loss: 0.5664142476536659
Validation loss: 2.7443910966373743

Epoch: 6| Step: 12
Training loss: 0.5616657110011783
Validation loss: 2.7704258143441827

Epoch: 6| Step: 13
Training loss: 0.5839826654007297
Validation loss: 2.7822696945330194

Epoch: 462| Step: 0
Training loss: 0.6246550561781954
Validation loss: 2.74000034615359

Epoch: 6| Step: 1
Training loss: 0.8546343701462541
Validation loss: 2.812332741744274

Epoch: 6| Step: 2
Training loss: 0.604670829444584
Validation loss: 2.7777363874742584

Epoch: 6| Step: 3
Training loss: 0.9132344334254934
Validation loss: 2.8037446543846243

Epoch: 6| Step: 4
Training loss: 0.6560767035780645
Validation loss: 2.8244278910800698

Epoch: 6| Step: 5
Training loss: 0.3770206964045706
Validation loss: 2.815410499714666

Epoch: 6| Step: 6
Training loss: 0.5177619175904704
Validation loss: 2.837401923614665

Epoch: 6| Step: 7
Training loss: 0.5772782904200552
Validation loss: 2.8394741848077034

Epoch: 6| Step: 8
Training loss: 0.5355517186141286
Validation loss: 2.8564071400583293

Epoch: 6| Step: 9
Training loss: 0.4634799344679211
Validation loss: 2.80916253327147

Epoch: 6| Step: 10
Training loss: 0.6915231810578284
Validation loss: 2.790343659085589

Epoch: 6| Step: 11
Training loss: 0.5845620095797361
Validation loss: 2.830350727144511

Epoch: 6| Step: 12
Training loss: 0.5399248164431728
Validation loss: 2.873723838745701

Epoch: 6| Step: 13
Training loss: 0.6298761411801505
Validation loss: 2.852866528694793

Epoch: 463| Step: 0
Training loss: 0.8631253684317254
Validation loss: 2.7976157203855507

Epoch: 6| Step: 1
Training loss: 0.4297946449555043
Validation loss: 2.7694894261109817

Epoch: 6| Step: 2
Training loss: 0.5708176975011527
Validation loss: 2.805321503991248

Epoch: 6| Step: 3
Training loss: 0.6841398836841686
Validation loss: 2.846540109343438

Epoch: 6| Step: 4
Training loss: 0.5886900779375265
Validation loss: 2.854302052723353

Epoch: 6| Step: 5
Training loss: 0.39449719952482554
Validation loss: 2.835928560493328

Epoch: 6| Step: 6
Training loss: 0.7918419560234806
Validation loss: 2.847227883268688

Epoch: 6| Step: 7
Training loss: 0.704509051073248
Validation loss: 2.8639458426695255

Epoch: 6| Step: 8
Training loss: 0.6173308483678651
Validation loss: 2.8890116407732727

Epoch: 6| Step: 9
Training loss: 0.6417844793198798
Validation loss: 2.8148215002288213

Epoch: 6| Step: 10
Training loss: 0.6557431079896445
Validation loss: 2.753124340690912

Epoch: 6| Step: 11
Training loss: 0.5662241149611122
Validation loss: 2.7873863647517565

Epoch: 6| Step: 12
Training loss: 0.7391052491806935
Validation loss: 2.705031646806636

Epoch: 6| Step: 13
Training loss: 0.5004666951804566
Validation loss: 2.7187986990706983

Epoch: 464| Step: 0
Training loss: 0.4165214543821722
Validation loss: 2.736630946014133

Epoch: 6| Step: 1
Training loss: 0.892826137685581
Validation loss: 2.718346342908959

Epoch: 6| Step: 2
Training loss: 0.5517667516473745
Validation loss: 2.786252170434685

Epoch: 6| Step: 3
Training loss: 0.9476143421237464
Validation loss: 2.83926878316012

Epoch: 6| Step: 4
Training loss: 0.5126676134165656
Validation loss: 2.8733964677528885

Epoch: 6| Step: 5
Training loss: 0.4586284637309977
Validation loss: 2.8799967121838415

Epoch: 6| Step: 6
Training loss: 0.5290289056232412
Validation loss: 2.9050658626826777

Epoch: 6| Step: 7
Training loss: 0.5523290597130265
Validation loss: 2.8827767718822606

Epoch: 6| Step: 8
Training loss: 0.6099246065262572
Validation loss: 2.8565759490916167

Epoch: 6| Step: 9
Training loss: 0.515022272350576
Validation loss: 2.8182839295177717

Epoch: 6| Step: 10
Training loss: 0.4320236336448885
Validation loss: 2.842301918761951

Epoch: 6| Step: 11
Training loss: 0.5714654633840608
Validation loss: 2.8555354898970675

Epoch: 6| Step: 12
Training loss: 0.7994603870352411
Validation loss: 2.827652570350362

Epoch: 6| Step: 13
Training loss: 0.6444001035490137
Validation loss: 2.834400289325267

Epoch: 465| Step: 0
Training loss: 0.44654568362223085
Validation loss: 2.793692186114396

Epoch: 6| Step: 1
Training loss: 0.44594024448846753
Validation loss: 2.7734244762705873

Epoch: 6| Step: 2
Training loss: 0.7554958366264178
Validation loss: 2.743483350421118

Epoch: 6| Step: 3
Training loss: 0.37253261490584516
Validation loss: 2.766220804466357

Epoch: 6| Step: 4
Training loss: 0.5214357389136621
Validation loss: 2.748417948323839

Epoch: 6| Step: 5
Training loss: 1.155718913411746
Validation loss: 2.7474599725308426

Epoch: 6| Step: 6
Training loss: 0.37814500377486204
Validation loss: 2.763795236590845

Epoch: 6| Step: 7
Training loss: 0.616763343406916
Validation loss: 2.7745202901399284

Epoch: 6| Step: 8
Training loss: 0.6137712792710789
Validation loss: 2.752717106335854

Epoch: 6| Step: 9
Training loss: 0.7349474278936049
Validation loss: 2.716756652636667

Epoch: 6| Step: 10
Training loss: 0.41201072343740885
Validation loss: 2.79701346226929

Epoch: 6| Step: 11
Training loss: 0.5551002471187965
Validation loss: 2.853914393578624

Epoch: 6| Step: 12
Training loss: 0.5780691171391735
Validation loss: 2.8603929052363872

Epoch: 6| Step: 13
Training loss: 0.7419956963303781
Validation loss: 2.889719132081509

Epoch: 466| Step: 0
Training loss: 0.6013650941827808
Validation loss: 2.8570138740376256

Epoch: 6| Step: 1
Training loss: 0.3303134011984435
Validation loss: 2.800766643803532

Epoch: 6| Step: 2
Training loss: 0.7101089344272166
Validation loss: 2.726243081460832

Epoch: 6| Step: 3
Training loss: 1.0070827710664754
Validation loss: 2.706522223544323

Epoch: 6| Step: 4
Training loss: 0.6710617555179109
Validation loss: 2.724128518462241

Epoch: 6| Step: 5
Training loss: 0.7318793156445292
Validation loss: 2.7163644314387527

Epoch: 6| Step: 6
Training loss: 0.38478804779554043
Validation loss: 2.6732834046791583

Epoch: 6| Step: 7
Training loss: 0.619018927807057
Validation loss: 2.733686901888243

Epoch: 6| Step: 8
Training loss: 0.7636154036850131
Validation loss: 2.7236618016741514

Epoch: 6| Step: 9
Training loss: 0.5153577863551186
Validation loss: 2.7620793115764286

Epoch: 6| Step: 10
Training loss: 0.6053313807042526
Validation loss: 2.751891526019473

Epoch: 6| Step: 11
Training loss: 0.5699375696877672
Validation loss: 2.7877409980497903

Epoch: 6| Step: 12
Training loss: 0.5021701150767955
Validation loss: 2.8278464079995076

Epoch: 6| Step: 13
Training loss: 0.4800388304580772
Validation loss: 2.8092979429071057

Epoch: 467| Step: 0
Training loss: 0.6551806957033833
Validation loss: 2.865514948238641

Epoch: 6| Step: 1
Training loss: 0.5186507141512893
Validation loss: 2.8087829186582076

Epoch: 6| Step: 2
Training loss: 0.5478714176054765
Validation loss: 2.775742138323032

Epoch: 6| Step: 3
Training loss: 1.0563834224604856
Validation loss: 2.790087841774942

Epoch: 6| Step: 4
Training loss: 0.5036093850213472
Validation loss: 2.75124371465658

Epoch: 6| Step: 5
Training loss: 0.5202559385973532
Validation loss: 2.743957267237568

Epoch: 6| Step: 6
Training loss: 0.4578754420839384
Validation loss: 2.749810848088741

Epoch: 6| Step: 7
Training loss: 0.3634075642505486
Validation loss: 2.7476144760900065

Epoch: 6| Step: 8
Training loss: 0.4358662516298814
Validation loss: 2.785214773511112

Epoch: 6| Step: 9
Training loss: 0.5862902278966083
Validation loss: 2.8008308211177906

Epoch: 6| Step: 10
Training loss: 0.6481639560848119
Validation loss: 2.8226044096217318

Epoch: 6| Step: 11
Training loss: 0.4064355573166326
Validation loss: 2.8175483747524965

Epoch: 6| Step: 12
Training loss: 0.4202157699854893
Validation loss: 2.7651434441413443

Epoch: 6| Step: 13
Training loss: 0.7245068336175067
Validation loss: 2.7524740187746626

Epoch: 468| Step: 0
Training loss: 0.6906891892236203
Validation loss: 2.8781233145190788

Epoch: 6| Step: 1
Training loss: 0.42592422464663665
Validation loss: 2.842307454982713

Epoch: 6| Step: 2
Training loss: 0.6870891036729577
Validation loss: 2.7543466779445684

Epoch: 6| Step: 3
Training loss: 0.2829846822212409
Validation loss: 2.828989209511976

Epoch: 6| Step: 4
Training loss: 0.3899154704138699
Validation loss: 2.8174421192893124

Epoch: 6| Step: 5
Training loss: 0.4719070613150079
Validation loss: 2.743010597558062

Epoch: 6| Step: 6
Training loss: 0.4717777379325873
Validation loss: 2.754929372778733

Epoch: 6| Step: 7
Training loss: 0.6003579552125367
Validation loss: 2.815349082397172

Epoch: 6| Step: 8
Training loss: 0.4348387157218677
Validation loss: 2.758142871177848

Epoch: 6| Step: 9
Training loss: 0.7197202684807901
Validation loss: 2.830050604988982

Epoch: 6| Step: 10
Training loss: 0.919282144075283
Validation loss: 2.8485167798706525

Epoch: 6| Step: 11
Training loss: 0.6037617400708213
Validation loss: 2.6864664618753853

Epoch: 6| Step: 12
Training loss: 0.6505706583758105
Validation loss: 2.7383368137760837

Epoch: 6| Step: 13
Training loss: 0.5187684101836433
Validation loss: 2.8192443515659775

Epoch: 469| Step: 0
Training loss: 0.7181362351085644
Validation loss: 2.8348572129807694

Epoch: 6| Step: 1
Training loss: 0.3345287971994635
Validation loss: 2.765844088567281

Epoch: 6| Step: 2
Training loss: 0.5289598637824537
Validation loss: 2.7676340769171

Epoch: 6| Step: 3
Training loss: 0.5170119733954988
Validation loss: 2.7282989277551053

Epoch: 6| Step: 4
Training loss: 0.3814217352624457
Validation loss: 2.728794849101163

Epoch: 6| Step: 5
Training loss: 0.569668680781038
Validation loss: 2.72983739827457

Epoch: 6| Step: 6
Training loss: 0.6536864208573974
Validation loss: 2.711118723210695

Epoch: 6| Step: 7
Training loss: 0.5715367750132003
Validation loss: 2.7351912887669383

Epoch: 6| Step: 8
Training loss: 0.7719952014813496
Validation loss: 2.75101900005909

Epoch: 6| Step: 9
Training loss: 0.5404700823522347
Validation loss: 2.7577980768764943

Epoch: 6| Step: 10
Training loss: 0.4642219231085247
Validation loss: 2.722842297247405

Epoch: 6| Step: 11
Training loss: 0.9344370716107512
Validation loss: 2.740745984273864

Epoch: 6| Step: 12
Training loss: 0.37931502796738037
Validation loss: 2.764696284968954

Epoch: 6| Step: 13
Training loss: 0.6736766700259885
Validation loss: 2.7021340554877926

Epoch: 470| Step: 0
Training loss: 0.44023107546066564
Validation loss: 2.7333203997732447

Epoch: 6| Step: 1
Training loss: 0.7083313511839415
Validation loss: 2.827041348113011

Epoch: 6| Step: 2
Training loss: 0.4796026533805077
Validation loss: 2.758239972319951

Epoch: 6| Step: 3
Training loss: 0.6099502098368949
Validation loss: 2.839559184862889

Epoch: 6| Step: 4
Training loss: 0.5815812746078858
Validation loss: 2.7970157069325645

Epoch: 6| Step: 5
Training loss: 0.46029144205275696
Validation loss: 2.867675199269905

Epoch: 6| Step: 6
Training loss: 0.3599649645393295
Validation loss: 2.793493787948978

Epoch: 6| Step: 7
Training loss: 0.5338769644234649
Validation loss: 2.8293724751136433

Epoch: 6| Step: 8
Training loss: 0.3883320074850105
Validation loss: 2.757619460196574

Epoch: 6| Step: 9
Training loss: 0.9352430515270816
Validation loss: 2.758519198291565

Epoch: 6| Step: 10
Training loss: 0.41174435834488077
Validation loss: 2.745477845176149

Epoch: 6| Step: 11
Training loss: 0.5555970699640878
Validation loss: 2.7648049412102242

Epoch: 6| Step: 12
Training loss: 0.8297821235219713
Validation loss: 2.73844783637208

Epoch: 6| Step: 13
Training loss: 0.6874996315348245
Validation loss: 2.757578421106173

Epoch: 471| Step: 0
Training loss: 0.6081122495249609
Validation loss: 2.7322256014582686

Epoch: 6| Step: 1
Training loss: 0.7456358058431017
Validation loss: 2.8319394712813444

Epoch: 6| Step: 2
Training loss: 0.5526911850085684
Validation loss: 2.7866193825833627

Epoch: 6| Step: 3
Training loss: 0.38841004873853974
Validation loss: 2.854429850080887

Epoch: 6| Step: 4
Training loss: 0.34127656843699533
Validation loss: 2.8470036125513025

Epoch: 6| Step: 5
Training loss: 0.3826545662023182
Validation loss: 2.8264389913639505

Epoch: 6| Step: 6
Training loss: 0.888743538115412
Validation loss: 2.7393559456993097

Epoch: 6| Step: 7
Training loss: 0.3432592009320444
Validation loss: 2.7705998764545474

Epoch: 6| Step: 8
Training loss: 0.4351027752055917
Validation loss: 2.7426094245003005

Epoch: 6| Step: 9
Training loss: 0.6779381833084024
Validation loss: 2.715363801686739

Epoch: 6| Step: 10
Training loss: 0.3650087077591408
Validation loss: 2.7627662495863663

Epoch: 6| Step: 11
Training loss: 0.7064206558577808
Validation loss: 2.780084101299026

Epoch: 6| Step: 12
Training loss: 0.3591655452530798
Validation loss: 2.823833673235755

Epoch: 6| Step: 13
Training loss: 0.659016432149181
Validation loss: 2.8164414232996746

Epoch: 472| Step: 0
Training loss: 0.3778313600046639
Validation loss: 2.782287547000038

Epoch: 6| Step: 1
Training loss: 0.4912532537900993
Validation loss: 2.805026148165919

Epoch: 6| Step: 2
Training loss: 0.6374050724186796
Validation loss: 2.8012142369876822

Epoch: 6| Step: 3
Training loss: 0.415867703067937
Validation loss: 2.8306269388886394

Epoch: 6| Step: 4
Training loss: 0.4380555372366495
Validation loss: 2.79915841091067

Epoch: 6| Step: 5
Training loss: 0.6835166233695087
Validation loss: 2.7590866675531633

Epoch: 6| Step: 6
Training loss: 0.6775818139117333
Validation loss: 2.720598856435723

Epoch: 6| Step: 7
Training loss: 0.8456256293543287
Validation loss: 2.757741032035484

Epoch: 6| Step: 8
Training loss: 0.6304392641114109
Validation loss: 2.7096049966835327

Epoch: 6| Step: 9
Training loss: 0.41190050807337164
Validation loss: 2.74256345195039

Epoch: 6| Step: 10
Training loss: 0.5542878067532947
Validation loss: 2.7979020660617815

Epoch: 6| Step: 11
Training loss: 0.6555472880473431
Validation loss: 2.745537865756407

Epoch: 6| Step: 12
Training loss: 0.5321098549649823
Validation loss: 2.8400431357049483

Epoch: 6| Step: 13
Training loss: 0.6293579517089763
Validation loss: 2.8002582879373072

Epoch: 473| Step: 0
Training loss: 0.5283508291967763
Validation loss: 2.763588868816591

Epoch: 6| Step: 1
Training loss: 1.0739065375481005
Validation loss: 2.82038181885467

Epoch: 6| Step: 2
Training loss: 0.45201468085610025
Validation loss: 2.850045470382514

Epoch: 6| Step: 3
Training loss: 0.4351915869071002
Validation loss: 2.8716293008476237

Epoch: 6| Step: 4
Training loss: 0.43817993529807203
Validation loss: 2.877496022857737

Epoch: 6| Step: 5
Training loss: 0.5257578987729056
Validation loss: 2.8894378836360746

Epoch: 6| Step: 6
Training loss: 0.4739161794032908
Validation loss: 2.8369389807022043

Epoch: 6| Step: 7
Training loss: 0.45875061250796473
Validation loss: 2.795475487091388

Epoch: 6| Step: 8
Training loss: 0.9188903727308678
Validation loss: 2.671948006210688

Epoch: 6| Step: 9
Training loss: 0.4239823548574771
Validation loss: 2.7455328797707157

Epoch: 6| Step: 10
Training loss: 0.41228385594380823
Validation loss: 2.7256893300995895

Epoch: 6| Step: 11
Training loss: 0.4024715035580781
Validation loss: 2.7680639227816

Epoch: 6| Step: 12
Training loss: 0.5579852811639302
Validation loss: 2.7613764311968203

Epoch: 6| Step: 13
Training loss: 0.7792654389659278
Validation loss: 2.714788144500425

Epoch: 474| Step: 0
Training loss: 0.7751414093091735
Validation loss: 2.7031367013196577

Epoch: 6| Step: 1
Training loss: 0.48039916550331946
Validation loss: 2.724366594479406

Epoch: 6| Step: 2
Training loss: 0.5502301699017161
Validation loss: 2.702461337607859

Epoch: 6| Step: 3
Training loss: 0.5629699386427436
Validation loss: 2.693935259874925

Epoch: 6| Step: 4
Training loss: 0.5267873866768215
Validation loss: 2.71762517702188

Epoch: 6| Step: 5
Training loss: 1.0461255707576844
Validation loss: 2.796938037694702

Epoch: 6| Step: 6
Training loss: 0.49692555776128067
Validation loss: 2.8300891329294773

Epoch: 6| Step: 7
Training loss: 0.4213735284431629
Validation loss: 2.7787098089192477

Epoch: 6| Step: 8
Training loss: 0.5334911197470282
Validation loss: 2.8389381108513554

Epoch: 6| Step: 9
Training loss: 0.6872354778838367
Validation loss: 2.8222372966607403

Epoch: 6| Step: 10
Training loss: 0.4092653863061682
Validation loss: 2.791755409158735

Epoch: 6| Step: 11
Training loss: 0.49743656837135536
Validation loss: 2.7871900483084224

Epoch: 6| Step: 12
Training loss: 0.44034655139474077
Validation loss: 2.7838323655923762

Epoch: 6| Step: 13
Training loss: 0.3536263181932192
Validation loss: 2.7425286931194757

Epoch: 475| Step: 0
Training loss: 0.3916814251750179
Validation loss: 2.8241247475414224

Epoch: 6| Step: 1
Training loss: 0.5481390377321926
Validation loss: 2.7922010384779137

Epoch: 6| Step: 2
Training loss: 0.584018361815415
Validation loss: 2.840215799411439

Epoch: 6| Step: 3
Training loss: 0.40321984321276344
Validation loss: 2.831437154258491

Epoch: 6| Step: 4
Training loss: 0.4806803570728653
Validation loss: 2.8226744112651225

Epoch: 6| Step: 5
Training loss: 0.6367845559780142
Validation loss: 2.8042216502935386

Epoch: 6| Step: 6
Training loss: 0.5818426863633327
Validation loss: 2.793677564189694

Epoch: 6| Step: 7
Training loss: 0.6211128231934684
Validation loss: 2.8207233865817853

Epoch: 6| Step: 8
Training loss: 0.6621743004398306
Validation loss: 2.7680745600496564

Epoch: 6| Step: 9
Training loss: 0.8911623086898269
Validation loss: 2.8342987173653076

Epoch: 6| Step: 10
Training loss: 0.539829178874318
Validation loss: 2.7776964610171357

Epoch: 6| Step: 11
Training loss: 0.5126146234868104
Validation loss: 2.789787654122241

Epoch: 6| Step: 12
Training loss: 0.36361297720516156
Validation loss: 2.747309698167808

Epoch: 6| Step: 13
Training loss: 0.41480149594508975
Validation loss: 2.807727451978795

Epoch: 476| Step: 0
Training loss: 0.7110482433546591
Validation loss: 2.8004651319088825

Epoch: 6| Step: 1
Training loss: 0.41315551604709305
Validation loss: 2.779134910512636

Epoch: 6| Step: 2
Training loss: 0.3925611577708731
Validation loss: 2.7556560611683043

Epoch: 6| Step: 3
Training loss: 0.4263957602502608
Validation loss: 2.731616490709909

Epoch: 6| Step: 4
Training loss: 0.489493642531931
Validation loss: 2.700602197601593

Epoch: 6| Step: 5
Training loss: 0.37058472104102613
Validation loss: 2.7923664572899987

Epoch: 6| Step: 6
Training loss: 0.8577068437500507
Validation loss: 2.730732582599939

Epoch: 6| Step: 7
Training loss: 0.7459408268816383
Validation loss: 2.7348724784621505

Epoch: 6| Step: 8
Training loss: 0.4427942716175427
Validation loss: 2.743460784360234

Epoch: 6| Step: 9
Training loss: 0.8398214647751887
Validation loss: 2.813297653115111

Epoch: 6| Step: 10
Training loss: 0.5274939146640016
Validation loss: 2.803375433115436

Epoch: 6| Step: 11
Training loss: 0.3799031896936252
Validation loss: 2.8073639350228157

Epoch: 6| Step: 12
Training loss: 0.5173491349281341
Validation loss: 2.767900123789852

Epoch: 6| Step: 13
Training loss: 0.47185044129991605
Validation loss: 2.871834947751608

Epoch: 477| Step: 0
Training loss: 0.8790297357913067
Validation loss: 2.8101830864491784

Epoch: 6| Step: 1
Training loss: 0.6349059434001814
Validation loss: 2.7813180065055803

Epoch: 6| Step: 2
Training loss: 0.3590177335795506
Validation loss: 2.800533799821376

Epoch: 6| Step: 3
Training loss: 0.4588984307521441
Validation loss: 2.7888337085106345

Epoch: 6| Step: 4
Training loss: 0.3100748613550537
Validation loss: 2.771933707583548

Epoch: 6| Step: 5
Training loss: 0.7173157354994673
Validation loss: 2.790468262374889

Epoch: 6| Step: 6
Training loss: 0.743369596634556
Validation loss: 2.74725608048394

Epoch: 6| Step: 7
Training loss: 0.3827686673974784
Validation loss: 2.7689717906471527

Epoch: 6| Step: 8
Training loss: 0.44671687149448114
Validation loss: 2.7989032856835676

Epoch: 6| Step: 9
Training loss: 0.5383198363006747
Validation loss: 2.7863271712096482

Epoch: 6| Step: 10
Training loss: 0.7092464582632472
Validation loss: 2.792909997708918

Epoch: 6| Step: 11
Training loss: 0.6848239619228991
Validation loss: 2.8271242341634526

Epoch: 6| Step: 12
Training loss: 0.45310536703788284
Validation loss: 2.8466181421797128

Epoch: 6| Step: 13
Training loss: 0.4441437190207256
Validation loss: 2.829194753523351

Epoch: 478| Step: 0
Training loss: 0.4598133474002282
Validation loss: 2.9016692043850614

Epoch: 6| Step: 1
Training loss: 1.1258080547458684
Validation loss: 2.8699954330372552

Epoch: 6| Step: 2
Training loss: 0.5156703697820427
Validation loss: 2.872967637467231

Epoch: 6| Step: 3
Training loss: 0.48414828008952737
Validation loss: 2.907639858198211

Epoch: 6| Step: 4
Training loss: 0.45102542300263937
Validation loss: 2.839885293341003

Epoch: 6| Step: 5
Training loss: 0.4938480581621764
Validation loss: 2.8083124846713687

Epoch: 6| Step: 6
Training loss: 0.7357713937089114
Validation loss: 2.7665069811671024

Epoch: 6| Step: 7
Training loss: 0.7191462461136872
Validation loss: 2.697064214723423

Epoch: 6| Step: 8
Training loss: 0.5226432981155008
Validation loss: 2.724805628409278

Epoch: 6| Step: 9
Training loss: 0.44017708379360904
Validation loss: 2.7746548269004885

Epoch: 6| Step: 10
Training loss: 0.33349766877502
Validation loss: 2.773074990521502

Epoch: 6| Step: 11
Training loss: 0.5927660971474576
Validation loss: 2.743268328005051

Epoch: 6| Step: 12
Training loss: 0.42474894541564034
Validation loss: 2.742561945115667

Epoch: 6| Step: 13
Training loss: 0.3929544609308315
Validation loss: 2.7531023732531823

Epoch: 479| Step: 0
Training loss: 0.3928575991807492
Validation loss: 2.753978120483754

Epoch: 6| Step: 1
Training loss: 0.4418259709741416
Validation loss: 2.8365680284380757

Epoch: 6| Step: 2
Training loss: 0.4164231860526046
Validation loss: 2.8212603581545004

Epoch: 6| Step: 3
Training loss: 0.6361167261504213
Validation loss: 2.816717912745738

Epoch: 6| Step: 4
Training loss: 0.7028425073048294
Validation loss: 2.829734302220067

Epoch: 6| Step: 5
Training loss: 0.517956577347864
Validation loss: 2.8250395240381914

Epoch: 6| Step: 6
Training loss: 0.7990724894018935
Validation loss: 2.854788946733977

Epoch: 6| Step: 7
Training loss: 0.38589316202220875
Validation loss: 2.798753984546991

Epoch: 6| Step: 8
Training loss: 0.473149145082195
Validation loss: 2.7867558234347203

Epoch: 6| Step: 9
Training loss: 0.448478968626887
Validation loss: 2.7197559147363215

Epoch: 6| Step: 10
Training loss: 0.3499383816804184
Validation loss: 2.783216260020175

Epoch: 6| Step: 11
Training loss: 0.640795568693629
Validation loss: 2.7076259912004996

Epoch: 6| Step: 12
Training loss: 0.9631184894458064
Validation loss: 2.7097989493862396

Epoch: 6| Step: 13
Training loss: 0.37467668423858574
Validation loss: 2.7423256805759513

Epoch: 480| Step: 0
Training loss: 0.4911136720496121
Validation loss: 2.718169577893736

Epoch: 6| Step: 1
Training loss: 0.49798335249969605
Validation loss: 2.7150831889948295

Epoch: 6| Step: 2
Training loss: 0.6327566428316233
Validation loss: 2.7310009002572317

Epoch: 6| Step: 3
Training loss: 0.4670808957547034
Validation loss: 2.8647953070615886

Epoch: 6| Step: 4
Training loss: 0.7332214060533148
Validation loss: 2.806403142747783

Epoch: 6| Step: 5
Training loss: 0.5620193547211491
Validation loss: 2.834160225948862

Epoch: 6| Step: 6
Training loss: 0.44462850810702786
Validation loss: 2.831394273002721

Epoch: 6| Step: 7
Training loss: 0.33974543059071344
Validation loss: 2.829997094650485

Epoch: 6| Step: 8
Training loss: 0.46496490694748993
Validation loss: 2.725423500271362

Epoch: 6| Step: 9
Training loss: 0.7919445846682672
Validation loss: 2.7251250623299934

Epoch: 6| Step: 10
Training loss: 0.9023762816803012
Validation loss: 2.7314811434149906

Epoch: 6| Step: 11
Training loss: 0.6857467316574997
Validation loss: 2.767775193625878

Epoch: 6| Step: 12
Training loss: 0.5187108151446983
Validation loss: 2.795664093610711

Epoch: 6| Step: 13
Training loss: 0.5618019275865116
Validation loss: 2.8179623153834443

Epoch: 481| Step: 0
Training loss: 0.5731882203155507
Validation loss: 2.879190873422915

Epoch: 6| Step: 1
Training loss: 0.4209933782360302
Validation loss: 2.8010451202730673

Epoch: 6| Step: 2
Training loss: 0.6453642115528903
Validation loss: 2.869272040778129

Epoch: 6| Step: 3
Training loss: 0.5547490690205461
Validation loss: 2.893330107312081

Epoch: 6| Step: 4
Training loss: 0.5547678446003441
Validation loss: 2.8507415983384097

Epoch: 6| Step: 5
Training loss: 0.37990058131694376
Validation loss: 2.8056591054693563

Epoch: 6| Step: 6
Training loss: 0.7525765349035612
Validation loss: 2.763065008205213

Epoch: 6| Step: 7
Training loss: 0.6737602089088989
Validation loss: 2.7412476699663806

Epoch: 6| Step: 8
Training loss: 0.8772777474799243
Validation loss: 2.782129441567125

Epoch: 6| Step: 9
Training loss: 0.689402570302868
Validation loss: 2.6414430543700496

Epoch: 6| Step: 10
Training loss: 0.5560978434905872
Validation loss: 2.6929356068975974

Epoch: 6| Step: 11
Training loss: 0.6320751745476557
Validation loss: 2.6655246603931815

Epoch: 6| Step: 12
Training loss: 0.7376906035507553
Validation loss: 2.6937472898819252

Epoch: 6| Step: 13
Training loss: 0.5812067938712747
Validation loss: 2.747483923103981

Epoch: 482| Step: 0
Training loss: 0.6222958477796333
Validation loss: 2.8149279251944823

Epoch: 6| Step: 1
Training loss: 0.41168981591605996
Validation loss: 2.887726576421617

Epoch: 6| Step: 2
Training loss: 0.5213129569073257
Validation loss: 2.852119064014356

Epoch: 6| Step: 3
Training loss: 0.5319067037616433
Validation loss: 2.9192872989858296

Epoch: 6| Step: 4
Training loss: 0.5893169855102245
Validation loss: 2.8615110996317017

Epoch: 6| Step: 5
Training loss: 0.37994529386804327
Validation loss: 2.828026111201668

Epoch: 6| Step: 6
Training loss: 0.5583802728944125
Validation loss: 2.8503808347110353

Epoch: 6| Step: 7
Training loss: 0.5096829811424457
Validation loss: 2.8432478688473926

Epoch: 6| Step: 8
Training loss: 0.40296700730525675
Validation loss: 2.8213616671341315

Epoch: 6| Step: 9
Training loss: 0.8436794251489951
Validation loss: 2.7762090454790735

Epoch: 6| Step: 10
Training loss: 0.6697780354617168
Validation loss: 2.7841570516643115

Epoch: 6| Step: 11
Training loss: 0.7443228270778202
Validation loss: 2.8177948031786917

Epoch: 6| Step: 12
Training loss: 0.7078277990443549
Validation loss: 2.808819998239722

Epoch: 6| Step: 13
Training loss: 0.9590940704071722
Validation loss: 2.801604621203206

Epoch: 483| Step: 0
Training loss: 0.467689172087457
Validation loss: 2.8021245667402974

Epoch: 6| Step: 1
Training loss: 0.5545084489706702
Validation loss: 2.762082361495539

Epoch: 6| Step: 2
Training loss: 0.5044234526947818
Validation loss: 2.8591353102317045

Epoch: 6| Step: 3
Training loss: 0.6764884291488945
Validation loss: 2.836349681538893

Epoch: 6| Step: 4
Training loss: 0.6817819618228026
Validation loss: 2.82061839184

Epoch: 6| Step: 5
Training loss: 0.37515390734594506
Validation loss: 2.8134299965910623

Epoch: 6| Step: 6
Training loss: 0.6466065720609714
Validation loss: 2.8092883245543696

Epoch: 6| Step: 7
Training loss: 0.635063031289759
Validation loss: 2.80332786310806

Epoch: 6| Step: 8
Training loss: 0.5955977549931402
Validation loss: 2.8346375848110297

Epoch: 6| Step: 9
Training loss: 0.8939115551672934
Validation loss: 2.7465069217160623

Epoch: 6| Step: 10
Training loss: 0.7105550051449985
Validation loss: 2.768332009664453

Epoch: 6| Step: 11
Training loss: 0.40286177091925796
Validation loss: 2.7863917452737836

Epoch: 6| Step: 12
Training loss: 0.6255548874994704
Validation loss: 2.7998000181398903

Epoch: 6| Step: 13
Training loss: 0.6989254469508946
Validation loss: 2.7997650899438704

Epoch: 484| Step: 0
Training loss: 0.2931518236994602
Validation loss: 2.796194736148904

Epoch: 6| Step: 1
Training loss: 0.6944192227445828
Validation loss: 2.8147278756826384

Epoch: 6| Step: 2
Training loss: 0.6931788679676976
Validation loss: 2.76349478829361

Epoch: 6| Step: 3
Training loss: 0.9740891530242757
Validation loss: 2.7086414357533672

Epoch: 6| Step: 4
Training loss: 0.3696274146348495
Validation loss: 2.7610285866461917

Epoch: 6| Step: 5
Training loss: 0.6920382310761092
Validation loss: 2.7726234996613823

Epoch: 6| Step: 6
Training loss: 0.5312057925511703
Validation loss: 2.6859584645534405

Epoch: 6| Step: 7
Training loss: 0.549131913462675
Validation loss: 2.743549946738128

Epoch: 6| Step: 8
Training loss: 0.33400922537814814
Validation loss: 2.808685442719206

Epoch: 6| Step: 9
Training loss: 0.5141074071128316
Validation loss: 2.7635316127954166

Epoch: 6| Step: 10
Training loss: 0.48375317436970744
Validation loss: 2.7710575548433556

Epoch: 6| Step: 11
Training loss: 0.5455775264523997
Validation loss: 2.8221898756234407

Epoch: 6| Step: 12
Training loss: 0.5020102383074867
Validation loss: 2.772885435078

Epoch: 6| Step: 13
Training loss: 0.41233859083179564
Validation loss: 2.8369279713379996

Epoch: 485| Step: 0
Training loss: 0.4427726998005406
Validation loss: 2.8766154298017153

Epoch: 6| Step: 1
Training loss: 0.5576028638292763
Validation loss: 2.8555882990312607

Epoch: 6| Step: 2
Training loss: 0.7884225043928188
Validation loss: 2.8384065275074915

Epoch: 6| Step: 3
Training loss: 0.5807274674417814
Validation loss: 2.8366272843208717

Epoch: 6| Step: 4
Training loss: 0.36744327970301
Validation loss: 2.8284399935546602

Epoch: 6| Step: 5
Training loss: 0.5224794758867863
Validation loss: 2.8173282294051876

Epoch: 6| Step: 6
Training loss: 0.3534842419261755
Validation loss: 2.7989117755621327

Epoch: 6| Step: 7
Training loss: 0.5091737548576156
Validation loss: 2.7743117123247587

Epoch: 6| Step: 8
Training loss: 0.7309130373184629
Validation loss: 2.7595839102013584

Epoch: 6| Step: 9
Training loss: 0.42164642711674055
Validation loss: 2.732134193325939

Epoch: 6| Step: 10
Training loss: 0.35043385854536446
Validation loss: 2.680698511751172

Epoch: 6| Step: 11
Training loss: 0.957573281763201
Validation loss: 2.759090138438541

Epoch: 6| Step: 12
Training loss: 0.35397166138168434
Validation loss: 2.830230098037422

Epoch: 6| Step: 13
Training loss: 0.6359016464586414
Validation loss: 2.902171003592521

Epoch: 486| Step: 0
Training loss: 0.40122270419961237
Validation loss: 2.908955903808465

Epoch: 6| Step: 1
Training loss: 0.8394597084777761
Validation loss: 2.942269545167659

Epoch: 6| Step: 2
Training loss: 0.6206198029622264
Validation loss: 2.958610284405025

Epoch: 6| Step: 3
Training loss: 0.4775226176732162
Validation loss: 2.8519410043279567

Epoch: 6| Step: 4
Training loss: 0.43748266321981794
Validation loss: 2.7837162298864304

Epoch: 6| Step: 5
Training loss: 0.5022788864665878
Validation loss: 2.8263354813208075

Epoch: 6| Step: 6
Training loss: 0.5471625525747578
Validation loss: 2.806104962424795

Epoch: 6| Step: 7
Training loss: 0.6657997519825811
Validation loss: 2.7007399898956668

Epoch: 6| Step: 8
Training loss: 0.5023631043213405
Validation loss: 2.770938531891121

Epoch: 6| Step: 9
Training loss: 0.41845514392761013
Validation loss: 2.789357437795343

Epoch: 6| Step: 10
Training loss: 0.5205529857164042
Validation loss: 2.732430585984112

Epoch: 6| Step: 11
Training loss: 0.7316173152601463
Validation loss: 2.854500846140577

Epoch: 6| Step: 12
Training loss: 0.6798657150770746
Validation loss: 2.7688343945134974

Epoch: 6| Step: 13
Training loss: 1.000891169185292
Validation loss: 2.8467787379137026

Epoch: 487| Step: 0
Training loss: 1.0193228673087853
Validation loss: 2.765013690061519

Epoch: 6| Step: 1
Training loss: 0.5836423299605874
Validation loss: 2.8420235979280344

Epoch: 6| Step: 2
Training loss: 0.6153389978006882
Validation loss: 2.8069144557596903

Epoch: 6| Step: 3
Training loss: 0.5687175814852775
Validation loss: 2.7815095444636135

Epoch: 6| Step: 4
Training loss: 0.4894465160608682
Validation loss: 2.859292909871731

Epoch: 6| Step: 5
Training loss: 0.48013034781725544
Validation loss: 2.836080262064834

Epoch: 6| Step: 6
Training loss: 0.6739378024417821
Validation loss: 2.863540797246748

Epoch: 6| Step: 7
Training loss: 0.5147070082283529
Validation loss: 2.825550713212666

Epoch: 6| Step: 8
Training loss: 0.6135119836316165
Validation loss: 2.8559030880037324

Epoch: 6| Step: 9
Training loss: 0.41266666715531564
Validation loss: 2.759564038919161

Epoch: 6| Step: 10
Training loss: 0.41132247065962413
Validation loss: 2.780202747013963

Epoch: 6| Step: 11
Training loss: 0.4757555085533309
Validation loss: 2.8155379383148524

Epoch: 6| Step: 12
Training loss: 0.7541400764231759
Validation loss: 2.752270592020329

Epoch: 6| Step: 13
Training loss: 0.5482658139238579
Validation loss: 2.765419257318309

Epoch: 488| Step: 0
Training loss: 0.2936122693143545
Validation loss: 2.7385776158049797

Epoch: 6| Step: 1
Training loss: 0.6458531089544277
Validation loss: 2.7133126824254665

Epoch: 6| Step: 2
Training loss: 0.5429690793262828
Validation loss: 2.6934589739174104

Epoch: 6| Step: 3
Training loss: 0.5779293863463962
Validation loss: 2.6576867799143353

Epoch: 6| Step: 4
Training loss: 0.6267899868446519
Validation loss: 2.7183954585039873

Epoch: 6| Step: 5
Training loss: 0.335068721501433
Validation loss: 2.7486471836763684

Epoch: 6| Step: 6
Training loss: 0.49492941160417586
Validation loss: 2.8030485076844256

Epoch: 6| Step: 7
Training loss: 0.6215710994840954
Validation loss: 2.7690587109180087

Epoch: 6| Step: 8
Training loss: 0.43529022250163063
Validation loss: 2.858588647329609

Epoch: 6| Step: 9
Training loss: 0.4241558337405248
Validation loss: 2.873786172460793

Epoch: 6| Step: 10
Training loss: 0.7847651935916092
Validation loss: 2.9156494592074758

Epoch: 6| Step: 11
Training loss: 1.0607864362224946
Validation loss: 2.9256697711155204

Epoch: 6| Step: 12
Training loss: 0.5862728176678681
Validation loss: 2.755412555089475

Epoch: 6| Step: 13
Training loss: 0.6446947988447367
Validation loss: 2.809237162851147

Epoch: 489| Step: 0
Training loss: 0.6202812398341363
Validation loss: 2.7734974026367247

Epoch: 6| Step: 1
Training loss: 0.6302771228626978
Validation loss: 2.716286665038028

Epoch: 6| Step: 2
Training loss: 0.5060136184311002
Validation loss: 2.683025360994196

Epoch: 6| Step: 3
Training loss: 0.7135412304359458
Validation loss: 2.7077624868685515

Epoch: 6| Step: 4
Training loss: 0.31833198055051465
Validation loss: 2.814653179921857

Epoch: 6| Step: 5
Training loss: 0.7504504758288537
Validation loss: 2.8212277520299303

Epoch: 6| Step: 6
Training loss: 0.417326210478904
Validation loss: 2.8231052931561615

Epoch: 6| Step: 7
Training loss: 0.9934721012335539
Validation loss: 2.8345394068614382

Epoch: 6| Step: 8
Training loss: 0.5649149236513852
Validation loss: 2.879834574522536

Epoch: 6| Step: 9
Training loss: 0.8245859277410367
Validation loss: 2.99335898365707

Epoch: 6| Step: 10
Training loss: 0.6459545488326857
Validation loss: 2.8747635481529787

Epoch: 6| Step: 11
Training loss: 0.4541046306547475
Validation loss: 2.8565778409204237

Epoch: 6| Step: 12
Training loss: 0.45967141533672423
Validation loss: 2.824968293948873

Epoch: 6| Step: 13
Training loss: 0.4915967908467783
Validation loss: 2.802188322990929

Epoch: 490| Step: 0
Training loss: 0.5514578484952337
Validation loss: 2.7487604642203083

Epoch: 6| Step: 1
Training loss: 0.8455441085345808
Validation loss: 2.7305524282953884

Epoch: 6| Step: 2
Training loss: 0.6040076068342326
Validation loss: 2.815762499614235

Epoch: 6| Step: 3
Training loss: 0.7957614523362847
Validation loss: 2.7834348205140076

Epoch: 6| Step: 4
Training loss: 0.44636740299512423
Validation loss: 2.8639052727180583

Epoch: 6| Step: 5
Training loss: 0.5322013359040872
Validation loss: 2.86274066729578

Epoch: 6| Step: 6
Training loss: 0.4521415495708312
Validation loss: 2.907650968809332

Epoch: 6| Step: 7
Training loss: 0.42363586987473345
Validation loss: 2.976358989122948

Epoch: 6| Step: 8
Training loss: 0.6872351743251446
Validation loss: 2.9173908878550145

Epoch: 6| Step: 9
Training loss: 0.5426808973273384
Validation loss: 2.8820545747439925

Epoch: 6| Step: 10
Training loss: 0.9219920843740343
Validation loss: 2.8850421088598357

Epoch: 6| Step: 11
Training loss: 0.5240083684471429
Validation loss: 2.7901861668074632

Epoch: 6| Step: 12
Training loss: 0.4365109776845766
Validation loss: 2.739851214483278

Epoch: 6| Step: 13
Training loss: 0.6485110781185895
Validation loss: 2.71455474705745

Epoch: 491| Step: 0
Training loss: 0.6046596905131695
Validation loss: 2.686175737213911

Epoch: 6| Step: 1
Training loss: 1.0768723882022475
Validation loss: 2.6957605625296948

Epoch: 6| Step: 2
Training loss: 0.4285220031819988
Validation loss: 2.6598675198178143

Epoch: 6| Step: 3
Training loss: 0.49396377535004565
Validation loss: 2.7028109123609623

Epoch: 6| Step: 4
Training loss: 0.7657916218588994
Validation loss: 2.762276355326859

Epoch: 6| Step: 5
Training loss: 0.6175783103059495
Validation loss: 2.7318352230157728

Epoch: 6| Step: 6
Training loss: 0.45415458779794343
Validation loss: 2.787527992552745

Epoch: 6| Step: 7
Training loss: 0.6784827418202146
Validation loss: 2.8387377376675094

Epoch: 6| Step: 8
Training loss: 0.5560729763077017
Validation loss: 2.862854069185651

Epoch: 6| Step: 9
Training loss: 0.47277565701003166
Validation loss: 2.8839839495257653

Epoch: 6| Step: 10
Training loss: 0.5453445272140119
Validation loss: 2.8686978539718875

Epoch: 6| Step: 11
Training loss: 0.643260118509436
Validation loss: 2.796141387940088

Epoch: 6| Step: 12
Training loss: 0.6983794177523135
Validation loss: 2.723218380927194

Epoch: 6| Step: 13
Training loss: 0.45162232936509783
Validation loss: 2.7331816330735736

Epoch: 492| Step: 0
Training loss: 0.580556293524598
Validation loss: 2.6768865451152593

Epoch: 6| Step: 1
Training loss: 0.9433974738157771
Validation loss: 2.6909010458663114

Epoch: 6| Step: 2
Training loss: 0.4323123176268794
Validation loss: 2.6839112117623976

Epoch: 6| Step: 3
Training loss: 0.514849021085809
Validation loss: 2.7339305698161684

Epoch: 6| Step: 4
Training loss: 0.5152179093582238
Validation loss: 2.7576383224107164

Epoch: 6| Step: 5
Training loss: 0.6306118789684009
Validation loss: 2.8415009404590954

Epoch: 6| Step: 6
Training loss: 0.8642598470028137
Validation loss: 2.8856384017706933

Epoch: 6| Step: 7
Training loss: 0.479122446618167
Validation loss: 2.9447614860989675

Epoch: 6| Step: 8
Training loss: 0.6426738215557015
Validation loss: 2.911858141658509

Epoch: 6| Step: 9
Training loss: 0.4824406546825499
Validation loss: 2.9141940648819307

Epoch: 6| Step: 10
Training loss: 0.5207563597702384
Validation loss: 2.92304656396511

Epoch: 6| Step: 11
Training loss: 0.7025876853221996
Validation loss: 2.8745018347770093

Epoch: 6| Step: 12
Training loss: 0.9429771328152887
Validation loss: 2.8907296788962507

Epoch: 6| Step: 13
Training loss: 0.6000948503147759
Validation loss: 2.8644906092577647

Epoch: 493| Step: 0
Training loss: 0.7076492138068714
Validation loss: 2.82163606901604

Epoch: 6| Step: 1
Training loss: 0.5617642624287607
Validation loss: 2.87562527974998

Epoch: 6| Step: 2
Training loss: 0.8960668385197033
Validation loss: 2.8441605673284114

Epoch: 6| Step: 3
Training loss: 0.4440200017824848
Validation loss: 2.817650437715099

Epoch: 6| Step: 4
Training loss: 0.4671433571466592
Validation loss: 2.810680804177559

Epoch: 6| Step: 5
Training loss: 0.422367162080256
Validation loss: 2.8159070818153547

Epoch: 6| Step: 6
Training loss: 0.5414017769324626
Validation loss: 2.7995792010273455

Epoch: 6| Step: 7
Training loss: 0.4920660807691131
Validation loss: 2.7801288530964414

Epoch: 6| Step: 8
Training loss: 0.5596603667275921
Validation loss: 2.764993484149082

Epoch: 6| Step: 9
Training loss: 0.5151079938210876
Validation loss: 2.774289998591897

Epoch: 6| Step: 10
Training loss: 0.43486458747987977
Validation loss: 2.799723675126494

Epoch: 6| Step: 11
Training loss: 0.504737582246223
Validation loss: 2.794954958617051

Epoch: 6| Step: 12
Training loss: 0.6648041342420252
Validation loss: 2.8106656627104316

Epoch: 6| Step: 13
Training loss: 0.5405474403181013
Validation loss: 2.846818519029213

Epoch: 494| Step: 0
Training loss: 0.37776125128833665
Validation loss: 2.77985967396296

Epoch: 6| Step: 1
Training loss: 0.45194531485915246
Validation loss: 2.8382144611066487

Epoch: 6| Step: 2
Training loss: 0.685305474102223
Validation loss: 2.901262098027198

Epoch: 6| Step: 3
Training loss: 0.5349796031468464
Validation loss: 2.9113077023505265

Epoch: 6| Step: 4
Training loss: 0.5629476249684704
Validation loss: 2.8420230945854152

Epoch: 6| Step: 5
Training loss: 0.8669195362578819
Validation loss: 2.820195217635138

Epoch: 6| Step: 6
Training loss: 0.4367582641086098
Validation loss: 2.7852143811708485

Epoch: 6| Step: 7
Training loss: 0.6273529346596566
Validation loss: 2.7735571893646234

Epoch: 6| Step: 8
Training loss: 0.3100470833631816
Validation loss: 2.836144950292029

Epoch: 6| Step: 9
Training loss: 0.5808482596816026
Validation loss: 2.7844352056328545

Epoch: 6| Step: 10
Training loss: 0.44191093625129807
Validation loss: 2.789657002265202

Epoch: 6| Step: 11
Training loss: 0.505848004423215
Validation loss: 2.7780126418058817

Epoch: 6| Step: 12
Training loss: 0.5831859322918184
Validation loss: 2.7397749849494772

Epoch: 6| Step: 13
Training loss: 0.38248004879996844
Validation loss: 2.801588168348429

Epoch: 495| Step: 0
Training loss: 0.5037694937670817
Validation loss: 2.798914842134013

Epoch: 6| Step: 1
Training loss: 1.0162006800696761
Validation loss: 2.7443791078811723

Epoch: 6| Step: 2
Training loss: 0.5120937924083884
Validation loss: 2.74308621567815

Epoch: 6| Step: 3
Training loss: 0.5034469758935055
Validation loss: 2.6910419042172293

Epoch: 6| Step: 4
Training loss: 0.759899215917312
Validation loss: 2.757432372900077

Epoch: 6| Step: 5
Training loss: 0.45414927242228753
Validation loss: 2.7080535206156844

Epoch: 6| Step: 6
Training loss: 0.5269597103309733
Validation loss: 2.7481199542651322

Epoch: 6| Step: 7
Training loss: 0.540544876599963
Validation loss: 2.6942926218796397

Epoch: 6| Step: 8
Training loss: 0.3329969611315637
Validation loss: 2.7233884128882195

Epoch: 6| Step: 9
Training loss: 0.40769450428191717
Validation loss: 2.7282667690523663

Epoch: 6| Step: 10
Training loss: 0.36794559867580956
Validation loss: 2.788146922106493

Epoch: 6| Step: 11
Training loss: 0.5168493934755475
Validation loss: 2.7828994745952493

Epoch: 6| Step: 12
Training loss: 0.47205953526534983
Validation loss: 2.8176683480650997

Epoch: 6| Step: 13
Training loss: 0.6833513320514081
Validation loss: 2.7964253126247334

Epoch: 496| Step: 0
Training loss: 0.42395933379196604
Validation loss: 2.7650365400975345

Epoch: 6| Step: 1
Training loss: 0.5931910343211579
Validation loss: 2.7759559050309184

Epoch: 6| Step: 2
Training loss: 0.49795447595712244
Validation loss: 2.7095810485889653

Epoch: 6| Step: 3
Training loss: 0.5840418860653768
Validation loss: 2.738071058099417

Epoch: 6| Step: 4
Training loss: 0.41017459646700244
Validation loss: 2.754270084957561

Epoch: 6| Step: 5
Training loss: 0.6128770504597599
Validation loss: 2.7446983413224477

Epoch: 6| Step: 6
Training loss: 0.525867005109936
Validation loss: 2.812782824389104

Epoch: 6| Step: 7
Training loss: 0.3556235259416062
Validation loss: 2.8344493355724

Epoch: 6| Step: 8
Training loss: 0.7046984128255064
Validation loss: 2.8501303364135615

Epoch: 6| Step: 9
Training loss: 0.5765591370605976
Validation loss: 2.851582050691933

Epoch: 6| Step: 10
Training loss: 0.850938585934207
Validation loss: 2.855636028185844

Epoch: 6| Step: 11
Training loss: 0.5333077743733984
Validation loss: 2.8418984725986167

Epoch: 6| Step: 12
Training loss: 0.6214099774765625
Validation loss: 2.8110788781584404

Epoch: 6| Step: 13
Training loss: 0.697659229131235
Validation loss: 2.7570530293239397

Epoch: 497| Step: 0
Training loss: 0.40581937120978195
Validation loss: 2.801988087185194

Epoch: 6| Step: 1
Training loss: 0.5116311791888203
Validation loss: 2.6825910728284246

Epoch: 6| Step: 2
Training loss: 0.8179233454624151
Validation loss: 2.7191927903705553

Epoch: 6| Step: 3
Training loss: 0.2922475712269807
Validation loss: 2.671527178100205

Epoch: 6| Step: 4
Training loss: 0.9335418112125524
Validation loss: 2.693057826448187

Epoch: 6| Step: 5
Training loss: 0.4722737743094221
Validation loss: 2.6565920740406557

Epoch: 6| Step: 6
Training loss: 0.7203854323265052
Validation loss: 2.7533781659060788

Epoch: 6| Step: 7
Training loss: 0.5193779224354846
Validation loss: 2.6948367744821917

Epoch: 6| Step: 8
Training loss: 0.43286174122230714
Validation loss: 2.7788372933168057

Epoch: 6| Step: 9
Training loss: 0.4135068728257491
Validation loss: 2.829414481169924

Epoch: 6| Step: 10
Training loss: 0.5822505409808203
Validation loss: 2.7994923625309753

Epoch: 6| Step: 11
Training loss: 0.5138829018985828
Validation loss: 2.7890828592250108

Epoch: 6| Step: 12
Training loss: 0.3778833168621231
Validation loss: 2.880307978216469

Epoch: 6| Step: 13
Training loss: 0.3592837259234332
Validation loss: 2.8606456025026015

Epoch: 498| Step: 0
Training loss: 0.48621765475330897
Validation loss: 2.7624656174535303

Epoch: 6| Step: 1
Training loss: 0.9649430814569635
Validation loss: 2.7843693303237087

Epoch: 6| Step: 2
Training loss: 0.44753933323454675
Validation loss: 2.7365558755482335

Epoch: 6| Step: 3
Training loss: 0.6123783243731099
Validation loss: 2.6955696757260283

Epoch: 6| Step: 4
Training loss: 0.4587392761317909
Validation loss: 2.6748010701042118

Epoch: 6| Step: 5
Training loss: 0.6490052965988424
Validation loss: 2.7837829485574774

Epoch: 6| Step: 6
Training loss: 0.6584049900105703
Validation loss: 2.7332797372804682

Epoch: 6| Step: 7
Training loss: 0.4261556256882638
Validation loss: 2.774462278637058

Epoch: 6| Step: 8
Training loss: 0.6088725243621662
Validation loss: 2.7940282132684198

Epoch: 6| Step: 9
Training loss: 0.5237109480617633
Validation loss: 2.8051626073994402

Epoch: 6| Step: 10
Training loss: 0.5192283952283793
Validation loss: 2.818520467114853

Epoch: 6| Step: 11
Training loss: 0.3866602535510703
Validation loss: 2.8182484408210478

Epoch: 6| Step: 12
Training loss: 0.47269537267266076
Validation loss: 2.8064138046068665

Epoch: 6| Step: 13
Training loss: 0.4060091625269646
Validation loss: 2.772151423178576

Epoch: 499| Step: 0
Training loss: 0.5204252710794235
Validation loss: 2.7700177954826293

Epoch: 6| Step: 1
Training loss: 0.43848668959717346
Validation loss: 2.769660505498752

Epoch: 6| Step: 2
Training loss: 0.5103560496037016
Validation loss: 2.7188912716697344

Epoch: 6| Step: 3
Training loss: 0.5989429610117962
Validation loss: 2.7804288044698917

Epoch: 6| Step: 4
Training loss: 0.47257495212483047
Validation loss: 2.7914861838989427

Epoch: 6| Step: 5
Training loss: 0.388601651389392
Validation loss: 2.777087493534697

Epoch: 6| Step: 6
Training loss: 0.45032982461337984
Validation loss: 2.876691099735727

Epoch: 6| Step: 7
Training loss: 0.7677090365761616
Validation loss: 2.8368578101494086

Epoch: 6| Step: 8
Training loss: 0.3288945528972294
Validation loss: 2.8393835983129385

Epoch: 6| Step: 9
Training loss: 0.483246920180633
Validation loss: 2.885378459764683

Epoch: 6| Step: 10
Training loss: 0.8653001265159487
Validation loss: 2.8092360029676158

Epoch: 6| Step: 11
Training loss: 0.5088327282932074
Validation loss: 2.8843518207647794

Epoch: 6| Step: 12
Training loss: 0.4628909952025402
Validation loss: 2.8172512753179904

Epoch: 6| Step: 13
Training loss: 0.40590754159822756
Validation loss: 2.794070124935567

Epoch: 500| Step: 0
Training loss: 0.8583685443347104
Validation loss: 2.8083120460344904

Epoch: 6| Step: 1
Training loss: 0.43393966691735547
Validation loss: 2.761157952347767

Epoch: 6| Step: 2
Training loss: 0.6458219147770008
Validation loss: 2.821222702624458

Epoch: 6| Step: 3
Training loss: 0.498340505173065
Validation loss: 2.7970782016127647

Epoch: 6| Step: 4
Training loss: 0.47690616785789497
Validation loss: 2.8567657238831408

Epoch: 6| Step: 5
Training loss: 0.39187222685129275
Validation loss: 2.900454468029811

Epoch: 6| Step: 6
Training loss: 0.7450186688049021
Validation loss: 2.9337332091726642

Epoch: 6| Step: 7
Training loss: 0.4963824265778721
Validation loss: 2.8770667263235836

Epoch: 6| Step: 8
Training loss: 0.43272054225550194
Validation loss: 2.9367238229983634

Epoch: 6| Step: 9
Training loss: 0.5990928637033547
Validation loss: 2.88429854633681

Epoch: 6| Step: 10
Training loss: 0.40284950912012935
Validation loss: 2.8446886798026876

Epoch: 6| Step: 11
Training loss: 0.7029202904991289
Validation loss: 2.8747238772935675

Epoch: 6| Step: 12
Training loss: 0.38271741270004694
Validation loss: 2.8218544137963506

Epoch: 6| Step: 13
Training loss: 0.4311500799825993
Validation loss: 2.7899057162612024

Testing loss: 2.5262375440644167
