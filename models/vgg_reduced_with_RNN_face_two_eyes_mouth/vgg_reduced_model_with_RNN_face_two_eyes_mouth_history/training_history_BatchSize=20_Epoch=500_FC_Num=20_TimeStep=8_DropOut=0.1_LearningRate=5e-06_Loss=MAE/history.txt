Epoch: 1| Step: 0
Training loss: 5.937224864959717
Validation loss: 5.3385498722394304

Epoch: 5| Step: 1
Training loss: 4.82481050491333
Validation loss: 5.336528102556865

Epoch: 5| Step: 2
Training loss: 5.683066368103027
Validation loss: 5.334513197342555

Epoch: 5| Step: 3
Training loss: 6.240786552429199
Validation loss: 5.332651972770691

Epoch: 5| Step: 4
Training loss: 4.88895320892334
Validation loss: 5.330854336420695

Epoch: 5| Step: 5
Training loss: 6.1678571701049805
Validation loss: 5.329023003578186

Epoch: 5| Step: 6
Training loss: 5.7305450439453125
Validation loss: 5.327226956685384

Epoch: 5| Step: 7
Training loss: 5.03985071182251
Validation loss: 5.325396219889323

Epoch: 5| Step: 8
Training loss: 4.516763210296631
Validation loss: 5.323572973410289

Epoch: 5| Step: 9
Training loss: 5.738772392272949
Validation loss: 5.3217136065165205

Epoch: 5| Step: 10
Training loss: 4.779440879821777
Validation loss: 5.319850126902263

Epoch: 5| Step: 11
Training loss: 4.532865047454834
Validation loss: 5.317929327487946

Epoch: 2| Step: 0
Training loss: 5.246351718902588
Validation loss: 5.315931558609009

Epoch: 5| Step: 1
Training loss: 4.593099594116211
Validation loss: 5.313809434572856

Epoch: 5| Step: 2
Training loss: 5.455477714538574
Validation loss: 5.3117542664210005

Epoch: 5| Step: 3
Training loss: 5.407214164733887
Validation loss: 5.309519171714783

Epoch: 5| Step: 4
Training loss: 6.03558349609375
Validation loss: 5.307246009508769

Epoch: 5| Step: 5
Training loss: 5.545003414154053
Validation loss: 5.304796576499939

Epoch: 5| Step: 6
Training loss: 5.563793182373047
Validation loss: 5.3022611538569135

Epoch: 5| Step: 7
Training loss: 5.162631988525391
Validation loss: 5.299696862697601

Epoch: 5| Step: 8
Training loss: 5.432559967041016
Validation loss: 5.296927094459534

Epoch: 5| Step: 9
Training loss: 4.473513126373291
Validation loss: 5.293997009595235

Epoch: 5| Step: 10
Training loss: 6.250933647155762
Validation loss: 5.291046003500621

Epoch: 5| Step: 11
Training loss: 5.0464606285095215
Validation loss: 5.28794393936793

Epoch: 3| Step: 0
Training loss: 5.480108261108398
Validation loss: 5.284494400024414

Epoch: 5| Step: 1
Training loss: 5.623856067657471
Validation loss: 5.281039178371429

Epoch: 5| Step: 2
Training loss: 4.924285888671875
Validation loss: 5.277322789033254

Epoch: 5| Step: 3
Training loss: 4.577709197998047
Validation loss: 5.2735680143038435

Epoch: 5| Step: 4
Training loss: 5.254305839538574
Validation loss: 5.269525508085887

Epoch: 5| Step: 5
Training loss: 5.604446887969971
Validation loss: 5.2651776274045305

Epoch: 5| Step: 6
Training loss: 5.074464321136475
Validation loss: 5.260763903458913

Epoch: 5| Step: 7
Training loss: 4.621245861053467
Validation loss: 5.256211360295613

Epoch: 5| Step: 8
Training loss: 5.771939754486084
Validation loss: 5.2512815197308855

Epoch: 5| Step: 9
Training loss: 5.542146682739258
Validation loss: 5.246305386225383

Epoch: 5| Step: 10
Training loss: 6.195815086364746
Validation loss: 5.240919411182404

Epoch: 5| Step: 11
Training loss: 5.28825044631958
Validation loss: 5.235399166742961

Epoch: 4| Step: 0
Training loss: 4.218593597412109
Validation loss: 5.229571282863617

Epoch: 5| Step: 1
Training loss: 5.12612247467041
Validation loss: 5.223493595918019

Epoch: 5| Step: 2
Training loss: 5.347869873046875
Validation loss: 5.217466076215108

Epoch: 5| Step: 3
Training loss: 5.4405717849731445
Validation loss: 5.210883339246114

Epoch: 5| Step: 4
Training loss: 5.694838523864746
Validation loss: 5.204231937726338

Epoch: 5| Step: 5
Training loss: 5.798925876617432
Validation loss: 5.197602450847626

Epoch: 5| Step: 6
Training loss: 5.384609222412109
Validation loss: 5.190474410851796

Epoch: 5| Step: 7
Training loss: 5.074504852294922
Validation loss: 5.183470984299977

Epoch: 5| Step: 8
Training loss: 5.026153564453125
Validation loss: 5.175902704397838

Epoch: 5| Step: 9
Training loss: 4.652780055999756
Validation loss: 5.168326000372569

Epoch: 5| Step: 10
Training loss: 6.171917915344238
Validation loss: 5.160659035046895

Epoch: 5| Step: 11
Training loss: 5.248120307922363
Validation loss: 5.1525760889053345

Epoch: 5| Step: 0
Training loss: 6.1438751220703125
Validation loss: 5.144737581411998

Epoch: 5| Step: 1
Training loss: 5.242471218109131
Validation loss: 5.136231581370036

Epoch: 5| Step: 2
Training loss: 3.8180689811706543
Validation loss: 5.1282588839530945

Epoch: 5| Step: 3
Training loss: 5.68004846572876
Validation loss: 5.119658907254537

Epoch: 5| Step: 4
Training loss: 5.57561731338501
Validation loss: 5.111097911993663

Epoch: 5| Step: 5
Training loss: 4.9062089920043945
Validation loss: 5.102374037106832

Epoch: 5| Step: 6
Training loss: 5.4858245849609375
Validation loss: 5.09372893969218

Epoch: 5| Step: 7
Training loss: 5.463146686553955
Validation loss: 5.084741930166881

Epoch: 5| Step: 8
Training loss: 5.168564796447754
Validation loss: 5.0754689772923784

Epoch: 5| Step: 9
Training loss: 4.700024604797363
Validation loss: 5.066295405228932

Epoch: 5| Step: 10
Training loss: 5.266491889953613
Validation loss: 5.057159463564555

Epoch: 5| Step: 11
Training loss: 2.5986104011535645
Validation loss: 5.047625700632731

Epoch: 6| Step: 0
Training loss: 4.951709270477295
Validation loss: 5.038740277290344

Epoch: 5| Step: 1
Training loss: 5.355569362640381
Validation loss: 5.029309034347534

Epoch: 5| Step: 2
Training loss: 5.102654933929443
Validation loss: 5.0203830798467

Epoch: 5| Step: 3
Training loss: 5.190103530883789
Validation loss: 5.011519889036815

Epoch: 5| Step: 4
Training loss: 4.7194294929504395
Validation loss: 5.002244373162587

Epoch: 5| Step: 5
Training loss: 4.235581398010254
Validation loss: 4.993131697177887

Epoch: 5| Step: 6
Training loss: 5.466915130615234
Validation loss: 4.984375536441803

Epoch: 5| Step: 7
Training loss: 5.430142402648926
Validation loss: 4.975495159626007

Epoch: 5| Step: 8
Training loss: 4.571877956390381
Validation loss: 4.966507037480672

Epoch: 5| Step: 9
Training loss: 5.450667381286621
Validation loss: 4.95779683192571

Epoch: 5| Step: 10
Training loss: 5.325760364532471
Validation loss: 4.948889950911204

Epoch: 5| Step: 11
Training loss: 5.122254848480225
Validation loss: 4.940432985623677

Epoch: 7| Step: 0
Training loss: 4.954779624938965
Validation loss: 4.931823591391246

Epoch: 5| Step: 1
Training loss: 5.625674724578857
Validation loss: 4.923541625340779

Epoch: 5| Step: 2
Training loss: 4.90121603012085
Validation loss: 4.915410002072652

Epoch: 5| Step: 3
Training loss: 5.023207664489746
Validation loss: 4.907097359498342

Epoch: 5| Step: 4
Training loss: 4.9541916847229
Validation loss: 4.899447868267695

Epoch: 5| Step: 5
Training loss: 5.356593608856201
Validation loss: 4.891650358835856

Epoch: 5| Step: 6
Training loss: 4.788077354431152
Validation loss: 4.884609738985698

Epoch: 5| Step: 7
Training loss: 5.400845050811768
Validation loss: 4.876586417357127

Epoch: 5| Step: 8
Training loss: 4.931905746459961
Validation loss: 4.86919230222702

Epoch: 5| Step: 9
Training loss: 4.5246686935424805
Validation loss: 4.861526707808177

Epoch: 5| Step: 10
Training loss: 4.300597190856934
Validation loss: 4.853997091452281

Epoch: 5| Step: 11
Training loss: 4.923501968383789
Validation loss: 4.84672333796819

Epoch: 8| Step: 0
Training loss: 5.872647285461426
Validation loss: 4.8391178250312805

Epoch: 5| Step: 1
Training loss: 5.462545871734619
Validation loss: 4.831531246503194

Epoch: 5| Step: 2
Training loss: 4.0614848136901855
Validation loss: 4.824135323365529

Epoch: 5| Step: 3
Training loss: 5.951437950134277
Validation loss: 4.81648204723994

Epoch: 5| Step: 4
Training loss: 4.432589054107666
Validation loss: 4.809751371542613

Epoch: 5| Step: 5
Training loss: 4.78477144241333
Validation loss: 4.802241921424866

Epoch: 5| Step: 6
Training loss: 4.358431816101074
Validation loss: 4.795072317123413

Epoch: 5| Step: 7
Training loss: 4.341856956481934
Validation loss: 4.788099467754364

Epoch: 5| Step: 8
Training loss: 5.026989459991455
Validation loss: 4.781009991963704

Epoch: 5| Step: 9
Training loss: 4.856296062469482
Validation loss: 4.774422665437062

Epoch: 5| Step: 10
Training loss: 4.827976703643799
Validation loss: 4.767789612213771

Epoch: 5| Step: 11
Training loss: 4.059608459472656
Validation loss: 4.76074755191803

Epoch: 9| Step: 0
Training loss: 4.532835960388184
Validation loss: 4.7544978857040405

Epoch: 5| Step: 1
Training loss: 4.778289794921875
Validation loss: 4.748232086499532

Epoch: 5| Step: 2
Training loss: 5.3160600662231445
Validation loss: 4.74237181742986

Epoch: 5| Step: 3
Training loss: 4.240838050842285
Validation loss: 4.73626176516215

Epoch: 5| Step: 4
Training loss: 5.29907751083374
Validation loss: 4.730096717675527

Epoch: 5| Step: 5
Training loss: 4.195763111114502
Validation loss: 4.723757227261861

Epoch: 5| Step: 6
Training loss: 4.392913341522217
Validation loss: 4.717916349569957

Epoch: 5| Step: 7
Training loss: 4.795377731323242
Validation loss: 4.711814979712169

Epoch: 5| Step: 8
Training loss: 5.209414482116699
Validation loss: 4.7057952880859375

Epoch: 5| Step: 9
Training loss: 5.511832237243652
Validation loss: 4.6995033621788025

Epoch: 5| Step: 10
Training loss: 4.517399311065674
Validation loss: 4.693445523579915

Epoch: 5| Step: 11
Training loss: 5.740256309509277
Validation loss: 4.687972992658615

Epoch: 10| Step: 0
Training loss: 4.715689659118652
Validation loss: 4.68152250846227

Epoch: 5| Step: 1
Training loss: 4.382981777191162
Validation loss: 4.675835033257802

Epoch: 5| Step: 2
Training loss: 4.23463249206543
Validation loss: 4.670301785071691

Epoch: 5| Step: 3
Training loss: 4.332622051239014
Validation loss: 4.6634881893793745

Epoch: 5| Step: 4
Training loss: 4.487521171569824
Validation loss: 4.65764993429184

Epoch: 5| Step: 5
Training loss: 5.20181131362915
Validation loss: 4.6517905195554095

Epoch: 5| Step: 6
Training loss: 5.634247779846191
Validation loss: 4.644918600718181

Epoch: 5| Step: 7
Training loss: 4.5142316818237305
Validation loss: 4.638473272323608

Epoch: 5| Step: 8
Training loss: 5.375550270080566
Validation loss: 4.631815314292908

Epoch: 5| Step: 9
Training loss: 4.2753801345825195
Validation loss: 4.625092566013336

Epoch: 5| Step: 10
Training loss: 4.608899116516113
Validation loss: 4.6187403202056885

Epoch: 5| Step: 11
Training loss: 7.003790855407715
Validation loss: 4.611939926942189

Epoch: 11| Step: 0
Training loss: 4.483757972717285
Validation loss: 4.605215171972911

Epoch: 5| Step: 1
Training loss: 4.494243144989014
Validation loss: 4.598900735378265

Epoch: 5| Step: 2
Training loss: 5.118663787841797
Validation loss: 4.591434796651204

Epoch: 5| Step: 3
Training loss: 4.616532802581787
Validation loss: 4.584323008855184

Epoch: 5| Step: 4
Training loss: 4.952010631561279
Validation loss: 4.57699054479599

Epoch: 5| Step: 5
Training loss: 5.257762432098389
Validation loss: 4.569451709588368

Epoch: 5| Step: 6
Training loss: 3.7028098106384277
Validation loss: 4.562615464131038

Epoch: 5| Step: 7
Training loss: 4.467450141906738
Validation loss: 4.554574807484944

Epoch: 5| Step: 8
Training loss: 4.567555904388428
Validation loss: 4.54771230618159

Epoch: 5| Step: 9
Training loss: 4.827920913696289
Validation loss: 4.540193696816762

Epoch: 5| Step: 10
Training loss: 4.740490913391113
Validation loss: 4.532316853602727

Epoch: 5| Step: 11
Training loss: 5.388943672180176
Validation loss: 4.5260112682978315

Epoch: 12| Step: 0
Training loss: 5.991909980773926
Validation loss: 4.51841613650322

Epoch: 5| Step: 1
Training loss: 4.066181182861328
Validation loss: 4.511722952127457

Epoch: 5| Step: 2
Training loss: 4.382881164550781
Validation loss: 4.505934149026871

Epoch: 5| Step: 3
Training loss: 4.197487831115723
Validation loss: 4.498508721590042

Epoch: 5| Step: 4
Training loss: 4.201496124267578
Validation loss: 4.490272651116054

Epoch: 5| Step: 5
Training loss: 4.5468010902404785
Validation loss: 4.483356724182765

Epoch: 5| Step: 6
Training loss: 4.31140661239624
Validation loss: 4.475638409455617

Epoch: 5| Step: 7
Training loss: 4.976653099060059
Validation loss: 4.46762548883756

Epoch: 5| Step: 8
Training loss: 4.204693794250488
Validation loss: 4.461021959781647

Epoch: 5| Step: 9
Training loss: 4.635324478149414
Validation loss: 4.454598983128865

Epoch: 5| Step: 10
Training loss: 4.87185525894165
Validation loss: 4.447437435388565

Epoch: 5| Step: 11
Training loss: 5.126178741455078
Validation loss: 4.44032343228658

Epoch: 13| Step: 0
Training loss: 5.492253303527832
Validation loss: 4.433144231637319

Epoch: 5| Step: 1
Training loss: 4.973190784454346
Validation loss: 4.425939629475276

Epoch: 5| Step: 2
Training loss: 4.376225471496582
Validation loss: 4.419492940107982

Epoch: 5| Step: 3
Training loss: 4.135114669799805
Validation loss: 4.413602252801259

Epoch: 5| Step: 4
Training loss: 3.6653950214385986
Validation loss: 4.407082587480545

Epoch: 5| Step: 5
Training loss: 5.290172576904297
Validation loss: 4.400621732076009

Epoch: 5| Step: 6
Training loss: 4.579771995544434
Validation loss: 4.393867125113805

Epoch: 5| Step: 7
Training loss: 4.849888324737549
Validation loss: 4.387431959311168

Epoch: 5| Step: 8
Training loss: 4.518212795257568
Validation loss: 4.381284246842067

Epoch: 5| Step: 9
Training loss: 4.593014240264893
Validation loss: 4.375130603710811

Epoch: 5| Step: 10
Training loss: 3.7102344036102295
Validation loss: 4.3689500987529755

Epoch: 5| Step: 11
Training loss: 2.0504984855651855
Validation loss: 4.362957775592804

Epoch: 14| Step: 0
Training loss: 4.293580532073975
Validation loss: 4.356852114200592

Epoch: 5| Step: 1
Training loss: 4.000678062438965
Validation loss: 4.349850048621495

Epoch: 5| Step: 2
Training loss: 5.195035934448242
Validation loss: 4.343872477610906

Epoch: 5| Step: 3
Training loss: 4.296805381774902
Validation loss: 4.33747719724973

Epoch: 5| Step: 4
Training loss: 3.9275615215301514
Validation loss: 4.331656396389008

Epoch: 5| Step: 5
Training loss: 5.793125629425049
Validation loss: 4.325521032015483

Epoch: 5| Step: 6
Training loss: 3.917487621307373
Validation loss: 4.319494058688481

Epoch: 5| Step: 7
Training loss: 5.158172130584717
Validation loss: 4.3135398626327515

Epoch: 5| Step: 8
Training loss: 3.2952358722686768
Validation loss: 4.306897461414337

Epoch: 5| Step: 9
Training loss: 4.443828582763672
Validation loss: 4.301217973232269

Epoch: 5| Step: 10
Training loss: 4.434900760650635
Validation loss: 4.296396215756734

Epoch: 5| Step: 11
Training loss: 5.366442680358887
Validation loss: 4.290347218513489

Epoch: 15| Step: 0
Training loss: 5.130218505859375
Validation loss: 4.284148663282394

Epoch: 5| Step: 1
Training loss: 3.997239351272583
Validation loss: 4.2786054114500685

Epoch: 5| Step: 2
Training loss: 3.820831298828125
Validation loss: 4.273086726665497

Epoch: 5| Step: 3
Training loss: 4.114193439483643
Validation loss: 4.267996380726497

Epoch: 5| Step: 4
Training loss: 4.292779922485352
Validation loss: 4.2628938754399615

Epoch: 5| Step: 5
Training loss: 4.962210178375244
Validation loss: 4.257250865300496

Epoch: 5| Step: 6
Training loss: 3.8582825660705566
Validation loss: 4.251513481140137

Epoch: 5| Step: 7
Training loss: 4.589577674865723
Validation loss: 4.246136715014775

Epoch: 5| Step: 8
Training loss: 4.239323139190674
Validation loss: 4.239746918280919

Epoch: 5| Step: 9
Training loss: 4.997269630432129
Validation loss: 4.234963138898213

Epoch: 5| Step: 10
Training loss: 4.437954902648926
Validation loss: 4.22985581556956

Epoch: 5| Step: 11
Training loss: 3.2939774990081787
Validation loss: 4.223768164714177

Epoch: 16| Step: 0
Training loss: 5.788004398345947
Validation loss: 4.216731071472168

Epoch: 5| Step: 1
Training loss: 4.094119071960449
Validation loss: 4.211108346780141

Epoch: 5| Step: 2
Training loss: 4.414642810821533
Validation loss: 4.205532332261403

Epoch: 5| Step: 3
Training loss: 5.110695838928223
Validation loss: 4.201943079630534

Epoch: 5| Step: 4
Training loss: 4.726373195648193
Validation loss: 4.1948814789454145

Epoch: 5| Step: 5
Training loss: 4.027202129364014
Validation loss: 4.190895597139995

Epoch: 5| Step: 6
Training loss: 4.43657922744751
Validation loss: 4.185360819101334

Epoch: 5| Step: 7
Training loss: 3.891098737716675
Validation loss: 4.179717501004537

Epoch: 5| Step: 8
Training loss: 3.856851577758789
Validation loss: 4.17347526550293

Epoch: 5| Step: 9
Training loss: 2.877415180206299
Validation loss: 4.166892816623052

Epoch: 5| Step: 10
Training loss: 4.511685848236084
Validation loss: 4.161577781041463

Epoch: 5| Step: 11
Training loss: 3.5607147216796875
Validation loss: 4.157128651936849

Epoch: 17| Step: 0
Training loss: 3.7951512336730957
Validation loss: 4.152787874142329

Epoch: 5| Step: 1
Training loss: 4.9004034996032715
Validation loss: 4.146596173445384

Epoch: 5| Step: 2
Training loss: 4.392179489135742
Validation loss: 4.141711850961049

Epoch: 5| Step: 3
Training loss: 4.340754508972168
Validation loss: 4.137089649836223

Epoch: 5| Step: 4
Training loss: 4.368838787078857
Validation loss: 4.132078160842259

Epoch: 5| Step: 5
Training loss: 5.7817230224609375
Validation loss: 4.1254284381866455

Epoch: 5| Step: 6
Training loss: 4.245139122009277
Validation loss: 4.119124213854472

Epoch: 5| Step: 7
Training loss: 3.523106336593628
Validation loss: 4.114043315251668

Epoch: 5| Step: 8
Training loss: 4.165301322937012
Validation loss: 4.1095695197582245

Epoch: 5| Step: 9
Training loss: 3.9320969581604004
Validation loss: 4.104831477006276

Epoch: 5| Step: 10
Training loss: 3.277024745941162
Validation loss: 4.100283126036326

Epoch: 5| Step: 11
Training loss: 5.303719520568848
Validation loss: 4.094929854075114

Epoch: 18| Step: 0
Training loss: 3.439448595046997
Validation loss: 4.08990607659022

Epoch: 5| Step: 1
Training loss: 5.193641662597656
Validation loss: 4.084986597299576

Epoch: 5| Step: 2
Training loss: 3.600769519805908
Validation loss: 4.078900367021561

Epoch: 5| Step: 3
Training loss: 5.331297874450684
Validation loss: 4.074437310298284

Epoch: 5| Step: 4
Training loss: 4.269649982452393
Validation loss: 4.069026788075765

Epoch: 5| Step: 5
Training loss: 4.377948760986328
Validation loss: 4.063718259334564

Epoch: 5| Step: 6
Training loss: 3.6641106605529785
Validation loss: 4.058629661798477

Epoch: 5| Step: 7
Training loss: 4.369626045227051
Validation loss: 4.054809331893921

Epoch: 5| Step: 8
Training loss: 4.627132892608643
Validation loss: 4.050758937994639

Epoch: 5| Step: 9
Training loss: 4.166624546051025
Validation loss: 4.044618010520935

Epoch: 5| Step: 10
Training loss: 2.809281587600708
Validation loss: 4.039959222078323

Epoch: 5| Step: 11
Training loss: 6.38986873626709
Validation loss: 4.034495135148366

Epoch: 19| Step: 0
Training loss: 3.5174167156219482
Validation loss: 4.029654214779536

Epoch: 5| Step: 1
Training loss: 4.26401424407959
Validation loss: 4.025889654954274

Epoch: 5| Step: 2
Training loss: 4.026640892028809
Validation loss: 4.0215257207552595

Epoch: 5| Step: 3
Training loss: 4.151728630065918
Validation loss: 4.0162093937397

Epoch: 5| Step: 4
Training loss: 3.9572348594665527
Validation loss: 4.010991523663203

Epoch: 5| Step: 5
Training loss: 4.203823566436768
Validation loss: 4.006238718827565

Epoch: 5| Step: 6
Training loss: 4.5595197677612305
Validation loss: 4.001923531293869

Epoch: 5| Step: 7
Training loss: 3.988076686859131
Validation loss: 3.9972177048524222

Epoch: 5| Step: 8
Training loss: 4.154402732849121
Validation loss: 3.9917587637901306

Epoch: 5| Step: 9
Training loss: 4.381321907043457
Validation loss: 3.9866567850112915

Epoch: 5| Step: 10
Training loss: 4.571788787841797
Validation loss: 3.9822378754615784

Epoch: 5| Step: 11
Training loss: 3.66266131401062
Validation loss: 3.9766806860764823

Epoch: 20| Step: 0
Training loss: 5.051732063293457
Validation loss: 3.971580614646276

Epoch: 5| Step: 1
Training loss: 4.546304225921631
Validation loss: 3.9674735764662423

Epoch: 5| Step: 2
Training loss: 4.362660884857178
Validation loss: 3.9623585045337677

Epoch: 5| Step: 3
Training loss: 3.9706521034240723
Validation loss: 3.957645038763682

Epoch: 5| Step: 4
Training loss: 3.8538718223571777
Validation loss: 3.951710045337677

Epoch: 5| Step: 5
Training loss: 3.6135799884796143
Validation loss: 3.9461636642615

Epoch: 5| Step: 6
Training loss: 4.231874942779541
Validation loss: 3.940662364164988

Epoch: 5| Step: 7
Training loss: 3.315436601638794
Validation loss: 3.9359888235727944

Epoch: 5| Step: 8
Training loss: 3.919286012649536
Validation loss: 3.930749624967575

Epoch: 5| Step: 9
Training loss: 4.516056060791016
Validation loss: 3.9258992969989777

Epoch: 5| Step: 10
Training loss: 3.7358241081237793
Validation loss: 3.920892129341761

Epoch: 5| Step: 11
Training loss: 3.795328140258789
Validation loss: 3.915736109018326

Epoch: 21| Step: 0
Training loss: 3.781411647796631
Validation loss: 3.9107227524121604

Epoch: 5| Step: 1
Training loss: 4.005923271179199
Validation loss: 3.9057347973187766

Epoch: 5| Step: 2
Training loss: 4.470925807952881
Validation loss: 3.9004389345645905

Epoch: 5| Step: 3
Training loss: 4.308549404144287
Validation loss: 3.895659406979879

Epoch: 5| Step: 4
Training loss: 3.556030750274658
Validation loss: 3.891425907611847

Epoch: 5| Step: 5
Training loss: 4.072851181030273
Validation loss: 3.885421007871628

Epoch: 5| Step: 6
Training loss: 4.409458160400391
Validation loss: 3.8807037075360618

Epoch: 5| Step: 7
Training loss: 3.0697858333587646
Validation loss: 3.875120759010315

Epoch: 5| Step: 8
Training loss: 3.5139472484588623
Validation loss: 3.869886269172033

Epoch: 5| Step: 9
Training loss: 4.499701023101807
Validation loss: 3.8664522071679435

Epoch: 5| Step: 10
Training loss: 4.221081733703613
Validation loss: 3.8605637351671853

Epoch: 5| Step: 11
Training loss: 6.489551544189453
Validation loss: 3.855163445075353

Epoch: 22| Step: 0
Training loss: 4.102416038513184
Validation loss: 3.850296606620153

Epoch: 5| Step: 1
Training loss: 5.097964286804199
Validation loss: 3.8465878665447235

Epoch: 5| Step: 2
Training loss: 4.211941719055176
Validation loss: 3.841040720542272

Epoch: 5| Step: 3
Training loss: 3.3167388439178467
Validation loss: 3.836464285850525

Epoch: 5| Step: 4
Training loss: 4.597827434539795
Validation loss: 3.8309883773326874

Epoch: 5| Step: 5
Training loss: 3.617499589920044
Validation loss: 3.825989325841268

Epoch: 5| Step: 6
Training loss: 3.8179943561553955
Validation loss: 3.8199686408042908

Epoch: 5| Step: 7
Training loss: 4.361536502838135
Validation loss: 3.8144111136595407

Epoch: 5| Step: 8
Training loss: 2.9256510734558105
Validation loss: 3.809339145819346

Epoch: 5| Step: 9
Training loss: 3.833617687225342
Validation loss: 3.8038589358329773

Epoch: 5| Step: 10
Training loss: 4.200162410736084
Validation loss: 3.799018899599711

Epoch: 5| Step: 11
Training loss: 2.4859957695007324
Validation loss: 3.794657737016678

Epoch: 23| Step: 0
Training loss: 3.771073818206787
Validation loss: 3.789911021788915

Epoch: 5| Step: 1
Training loss: 3.816676616668701
Validation loss: 3.7861391504605613

Epoch: 5| Step: 2
Training loss: 3.8032829761505127
Validation loss: 3.780320862929026

Epoch: 5| Step: 3
Training loss: 3.7374584674835205
Validation loss: 3.776596248149872

Epoch: 5| Step: 4
Training loss: 4.316344738006592
Validation loss: 3.77095490694046

Epoch: 5| Step: 5
Training loss: 3.034604549407959
Validation loss: 3.7662855088710785

Epoch: 5| Step: 6
Training loss: 4.790406703948975
Validation loss: 3.761238843202591

Epoch: 5| Step: 7
Training loss: 3.721209764480591
Validation loss: 3.7560969591140747

Epoch: 5| Step: 8
Training loss: 4.35750675201416
Validation loss: 3.7511081596215567

Epoch: 5| Step: 9
Training loss: 3.74937105178833
Validation loss: 3.745447893937429

Epoch: 5| Step: 10
Training loss: 4.129537105560303
Validation loss: 3.741581271092097

Epoch: 5| Step: 11
Training loss: 3.61985445022583
Validation loss: 3.7368071178595224

Epoch: 24| Step: 0
Training loss: 3.338951826095581
Validation loss: 3.7317727704842887

Epoch: 5| Step: 1
Training loss: 3.0665361881256104
Validation loss: 3.7271742026011148

Epoch: 5| Step: 2
Training loss: 4.614203453063965
Validation loss: 3.7227510114510856

Epoch: 5| Step: 3
Training loss: 3.5330207347869873
Validation loss: 3.7187600235144296

Epoch: 5| Step: 4
Training loss: 3.8234267234802246
Validation loss: 3.713399976491928

Epoch: 5| Step: 5
Training loss: 4.130356788635254
Validation loss: 3.709863235553106

Epoch: 5| Step: 6
Training loss: 4.470800876617432
Validation loss: 3.7052657306194305

Epoch: 5| Step: 7
Training loss: 3.7999961376190186
Validation loss: 3.7001366515954337

Epoch: 5| Step: 8
Training loss: 2.76572847366333
Validation loss: 3.696535805861155

Epoch: 5| Step: 9
Training loss: 3.9425270557403564
Validation loss: 3.6919596791267395

Epoch: 5| Step: 10
Training loss: 4.791913032531738
Validation loss: 3.6870783269405365

Epoch: 5| Step: 11
Training loss: 5.303067207336426
Validation loss: 3.6826225916544595

Epoch: 25| Step: 0
Training loss: 3.3007826805114746
Validation loss: 3.6769299109776816

Epoch: 5| Step: 1
Training loss: 4.0387067794799805
Validation loss: 3.672452747821808

Epoch: 5| Step: 2
Training loss: 3.8855068683624268
Validation loss: 3.6668814718723297

Epoch: 5| Step: 3
Training loss: 3.9478676319122314
Validation loss: 3.6623973349730172

Epoch: 5| Step: 4
Training loss: 4.215594291687012
Validation loss: 3.6577123403549194

Epoch: 5| Step: 5
Training loss: 3.203160047531128
Validation loss: 3.6525896986325583

Epoch: 5| Step: 6
Training loss: 5.033974647521973
Validation loss: 3.648280362288157

Epoch: 5| Step: 7
Training loss: 3.9626171588897705
Validation loss: 3.642264634370804

Epoch: 5| Step: 8
Training loss: 3.0410823822021484
Validation loss: 3.6374970277150473

Epoch: 5| Step: 9
Training loss: 3.7576584815979004
Validation loss: 3.632487714290619

Epoch: 5| Step: 10
Training loss: 3.5007662773132324
Validation loss: 3.627776732047399

Epoch: 5| Step: 11
Training loss: 4.169862747192383
Validation loss: 3.622741609811783

Epoch: 26| Step: 0
Training loss: 3.7381539344787598
Validation loss: 3.618081579605738

Epoch: 5| Step: 1
Training loss: 3.0451996326446533
Validation loss: 3.6141770680745444

Epoch: 5| Step: 2
Training loss: 5.13048791885376
Validation loss: 3.6093823611736298

Epoch: 5| Step: 3
Training loss: 3.4974606037139893
Validation loss: 3.603455513715744

Epoch: 5| Step: 4
Training loss: 3.5771689414978027
Validation loss: 3.5990496973196664

Epoch: 5| Step: 5
Training loss: 3.2465367317199707
Validation loss: 3.594628314177195

Epoch: 5| Step: 6
Training loss: 3.651186466217041
Validation loss: 3.5905102590719857

Epoch: 5| Step: 7
Training loss: 4.136974334716797
Validation loss: 3.5856042404969535

Epoch: 5| Step: 8
Training loss: 3.0742201805114746
Validation loss: 3.580006549755732

Epoch: 5| Step: 9
Training loss: 3.982693910598755
Validation loss: 3.575074781974157

Epoch: 5| Step: 10
Training loss: 4.068765640258789
Validation loss: 3.5699165562788644

Epoch: 5| Step: 11
Training loss: 4.689798355102539
Validation loss: 3.564838618040085

Epoch: 27| Step: 0
Training loss: 3.611341953277588
Validation loss: 3.558777093887329

Epoch: 5| Step: 1
Training loss: 4.435028553009033
Validation loss: 3.5530423521995544

Epoch: 5| Step: 2
Training loss: 3.1494686603546143
Validation loss: 3.547973861296972

Epoch: 5| Step: 3
Training loss: 3.9284636974334717
Validation loss: 3.543434659639994

Epoch: 5| Step: 4
Training loss: 3.760770797729492
Validation loss: 3.537826955318451

Epoch: 5| Step: 5
Training loss: 3.397681474685669
Validation loss: 3.532907952864965

Epoch: 5| Step: 6
Training loss: 3.9198899269104004
Validation loss: 3.5275695820649466

Epoch: 5| Step: 7
Training loss: 3.546638011932373
Validation loss: 3.5217843552430472

Epoch: 5| Step: 8
Training loss: 3.7243075370788574
Validation loss: 3.515996346871058

Epoch: 5| Step: 9
Training loss: 3.451873779296875
Validation loss: 3.5103584130605063

Epoch: 5| Step: 10
Training loss: 4.029330253601074
Validation loss: 3.505219837029775

Epoch: 5| Step: 11
Training loss: 2.230225086212158
Validation loss: 3.4999822974205017

Epoch: 28| Step: 0
Training loss: 3.86918306350708
Validation loss: 3.495039393504461

Epoch: 5| Step: 1
Training loss: 3.5794341564178467
Validation loss: 3.490339199701945

Epoch: 5| Step: 2
Training loss: 4.170506477355957
Validation loss: 3.4848219950993857

Epoch: 5| Step: 3
Training loss: 3.110339641571045
Validation loss: 3.478970875342687

Epoch: 5| Step: 4
Training loss: 3.447592258453369
Validation loss: 3.474251538515091

Epoch: 5| Step: 5
Training loss: 3.9306061267852783
Validation loss: 3.469372103611628

Epoch: 5| Step: 6
Training loss: 3.009648323059082
Validation loss: 3.4656456112861633

Epoch: 5| Step: 7
Training loss: 3.836836338043213
Validation loss: 3.459273080031077

Epoch: 5| Step: 8
Training loss: 3.7995617389678955
Validation loss: 3.453656037648519

Epoch: 5| Step: 9
Training loss: 3.4417107105255127
Validation loss: 3.448869615793228

Epoch: 5| Step: 10
Training loss: 3.7453854084014893
Validation loss: 3.443692753712336

Epoch: 5| Step: 11
Training loss: 3.858952283859253
Validation loss: 3.439083437124888

Epoch: 29| Step: 0
Training loss: 3.6366286277770996
Validation loss: 3.434482902288437

Epoch: 5| Step: 1
Training loss: 3.5681004524230957
Validation loss: 3.4285763005415597

Epoch: 5| Step: 2
Training loss: 3.6721789836883545
Validation loss: 3.423373212416967

Epoch: 5| Step: 3
Training loss: 4.5477752685546875
Validation loss: 3.416773666938146

Epoch: 5| Step: 4
Training loss: 3.970247983932495
Validation loss: 3.4106790522734323

Epoch: 5| Step: 5
Training loss: 3.0984740257263184
Validation loss: 3.4053860108057656

Epoch: 5| Step: 6
Training loss: 2.838674545288086
Validation loss: 3.4010613759358725

Epoch: 5| Step: 7
Training loss: 3.8914997577667236
Validation loss: 3.3973610401153564

Epoch: 5| Step: 8
Training loss: 4.460186958312988
Validation loss: 3.3913047909736633

Epoch: 5| Step: 9
Training loss: 2.582397937774658
Validation loss: 3.3839074075222015

Epoch: 5| Step: 10
Training loss: 3.19697642326355
Validation loss: 3.3778060376644135

Epoch: 5| Step: 11
Training loss: 2.898115634918213
Validation loss: 3.3733120461304984

Epoch: 30| Step: 0
Training loss: 3.784890651702881
Validation loss: 3.3690863847732544

Epoch: 5| Step: 1
Training loss: 3.686091899871826
Validation loss: 3.3639585971832275

Epoch: 5| Step: 2
Training loss: 3.960718870162964
Validation loss: 3.3577809631824493

Epoch: 5| Step: 3
Training loss: 3.9866862297058105
Validation loss: 3.352759222189585

Epoch: 5| Step: 4
Training loss: 3.8092567920684814
Validation loss: 3.348113606373469

Epoch: 5| Step: 5
Training loss: 2.9844963550567627
Validation loss: 3.3427570859591165

Epoch: 5| Step: 6
Training loss: 2.5309550762176514
Validation loss: 3.338426887989044

Epoch: 5| Step: 7
Training loss: 2.8348894119262695
Validation loss: 3.3337193528811135

Epoch: 5| Step: 8
Training loss: 3.9715142250061035
Validation loss: 3.328289568424225

Epoch: 5| Step: 9
Training loss: 3.7076046466827393
Validation loss: 3.3237749139467874

Epoch: 5| Step: 10
Training loss: 3.6915557384490967
Validation loss: 3.3181885480880737

Epoch: 5| Step: 11
Training loss: 2.0585200786590576
Validation loss: 3.312919855117798

Epoch: 31| Step: 0
Training loss: 3.2950119972229004
Validation loss: 3.30741094549497

Epoch: 5| Step: 1
Training loss: 3.16032338142395
Validation loss: 3.307383567094803

Epoch: 5| Step: 2
Training loss: 3.4293861389160156
Validation loss: 3.2977490723133087

Epoch: 5| Step: 3
Training loss: 3.5124924182891846
Validation loss: 3.294625153144201

Epoch: 5| Step: 4
Training loss: 3.401820421218872
Validation loss: 3.2918701767921448

Epoch: 5| Step: 5
Training loss: 3.1880054473876953
Validation loss: 3.2895320653915405

Epoch: 5| Step: 6
Training loss: 3.545292615890503
Validation loss: 3.2853884100914

Epoch: 5| Step: 7
Training loss: 3.4221343994140625
Validation loss: 3.279726872841517

Epoch: 5| Step: 8
Training loss: 3.570621967315674
Validation loss: 3.2745863099892936

Epoch: 5| Step: 9
Training loss: 3.7399539947509766
Validation loss: 3.26848495999972

Epoch: 5| Step: 10
Training loss: 3.945561170578003
Validation loss: 3.26319682598114

Epoch: 5| Step: 11
Training loss: 2.7386693954467773
Validation loss: 3.2583565513292947

Epoch: 32| Step: 0
Training loss: 2.8792717456817627
Validation loss: 3.25424000620842

Epoch: 5| Step: 1
Training loss: 3.5764384269714355
Validation loss: 3.2492894530296326

Epoch: 5| Step: 2
Training loss: 3.68475604057312
Validation loss: 3.244327853123347

Epoch: 5| Step: 3
Training loss: 3.5613129138946533
Validation loss: 3.240612785021464

Epoch: 5| Step: 4
Training loss: 3.6883773803710938
Validation loss: 3.2332571148872375

Epoch: 5| Step: 5
Training loss: 2.636366128921509
Validation loss: 3.2271365324656167

Epoch: 5| Step: 6
Training loss: 3.4616761207580566
Validation loss: 3.2228353520234427

Epoch: 5| Step: 7
Training loss: 2.805294990539551
Validation loss: 3.2178811927636466

Epoch: 5| Step: 8
Training loss: 3.3561851978302
Validation loss: 3.2129014432430267

Epoch: 5| Step: 9
Training loss: 3.918571949005127
Validation loss: 3.207660287618637

Epoch: 5| Step: 10
Training loss: 3.5661842823028564
Validation loss: 3.2032842536767325

Epoch: 5| Step: 11
Training loss: 5.0921478271484375
Validation loss: 3.1985591053962708

Epoch: 33| Step: 0
Training loss: 3.6878838539123535
Validation loss: 3.1938225626945496

Epoch: 5| Step: 1
Training loss: 3.3526241779327393
Validation loss: 3.188549816608429

Epoch: 5| Step: 2
Training loss: 3.1829068660736084
Validation loss: 3.185863822698593

Epoch: 5| Step: 3
Training loss: 3.325227737426758
Validation loss: 3.1778620878855386

Epoch: 5| Step: 4
Training loss: 3.3478798866271973
Validation loss: 3.1734518806139627

Epoch: 5| Step: 5
Training loss: 3.811455488204956
Validation loss: 3.16893940170606

Epoch: 5| Step: 6
Training loss: 2.807025671005249
Validation loss: 3.164417266845703

Epoch: 5| Step: 7
Training loss: 2.8646979331970215
Validation loss: 3.1604040265083313

Epoch: 5| Step: 8
Training loss: 3.806417465209961
Validation loss: 3.156122624874115

Epoch: 5| Step: 9
Training loss: 3.561749219894409
Validation loss: 3.1506098906199136

Epoch: 5| Step: 10
Training loss: 3.041649580001831
Validation loss: 3.145968725283941

Epoch: 5| Step: 11
Training loss: 3.786914825439453
Validation loss: 3.1414952874183655

Epoch: 34| Step: 0
Training loss: 3.0083980560302734
Validation loss: 3.1363035440444946

Epoch: 5| Step: 1
Training loss: 2.5699450969696045
Validation loss: 3.1317631204922995

Epoch: 5| Step: 2
Training loss: 3.3516101837158203
Validation loss: 3.126815696557363

Epoch: 5| Step: 3
Training loss: 3.1992812156677246
Validation loss: 3.1220226983229318

Epoch: 5| Step: 4
Training loss: 3.461146593093872
Validation loss: 3.116471360127131

Epoch: 5| Step: 5
Training loss: 3.370084285736084
Validation loss: 3.1120413541793823

Epoch: 5| Step: 6
Training loss: 3.6693077087402344
Validation loss: 3.107296794652939

Epoch: 5| Step: 7
Training loss: 3.1797661781311035
Validation loss: 3.1019555032253265

Epoch: 5| Step: 8
Training loss: 3.2589268684387207
Validation loss: 3.0982157786687217

Epoch: 5| Step: 9
Training loss: 3.794818878173828
Validation loss: 3.093737800916036

Epoch: 5| Step: 10
Training loss: 3.277085542678833
Validation loss: 3.08887987335523

Epoch: 5| Step: 11
Training loss: 4.011523246765137
Validation loss: 3.0847805043061576

Epoch: 35| Step: 0
Training loss: 3.2852165699005127
Validation loss: 3.0806325574715934

Epoch: 5| Step: 1
Training loss: 3.386409282684326
Validation loss: 3.076640874147415

Epoch: 5| Step: 2
Training loss: 3.2146270275115967
Validation loss: 3.072381556034088

Epoch: 5| Step: 3
Training loss: 3.0093319416046143
Validation loss: 3.067658027013143

Epoch: 5| Step: 4
Training loss: 2.840496063232422
Validation loss: 3.0636633038520813

Epoch: 5| Step: 5
Training loss: 3.1578545570373535
Validation loss: 3.0592271586259208

Epoch: 5| Step: 6
Training loss: 3.015098810195923
Validation loss: 3.054570565621058

Epoch: 5| Step: 7
Training loss: 3.214935302734375
Validation loss: 3.0505016148090363

Epoch: 5| Step: 8
Training loss: 3.570793867111206
Validation loss: 3.046246737241745

Epoch: 5| Step: 9
Training loss: 2.8426966667175293
Validation loss: 3.0429649452368417

Epoch: 5| Step: 10
Training loss: 3.8736259937286377
Validation loss: 3.0394263168176017

Epoch: 5| Step: 11
Training loss: 4.82310676574707
Validation loss: 3.0354938407739005

Epoch: 36| Step: 0
Training loss: 2.669053554534912
Validation loss: 3.0303070644537606

Epoch: 5| Step: 1
Training loss: 3.1860833168029785
Validation loss: 3.026363790035248

Epoch: 5| Step: 2
Training loss: 3.338975191116333
Validation loss: 3.0221986869970956

Epoch: 5| Step: 3
Training loss: 2.860128879547119
Validation loss: 3.0183200935522714

Epoch: 5| Step: 4
Training loss: 3.5959935188293457
Validation loss: 3.0139229794343314

Epoch: 5| Step: 5
Training loss: 3.2948715686798096
Validation loss: 3.0097212493419647

Epoch: 5| Step: 6
Training loss: 2.5894453525543213
Validation loss: 3.005699227253596

Epoch: 5| Step: 7
Training loss: 2.9536616802215576
Validation loss: 3.001529037952423

Epoch: 5| Step: 8
Training loss: 3.4295661449432373
Validation loss: 2.997414857149124

Epoch: 5| Step: 9
Training loss: 3.1824259757995605
Validation loss: 2.993520269791285

Epoch: 5| Step: 10
Training loss: 3.9412455558776855
Validation loss: 2.9896641770998635

Epoch: 5| Step: 11
Training loss: 4.125796318054199
Validation loss: 2.9861686726411185

Epoch: 37| Step: 0
Training loss: 3.0133748054504395
Validation loss: 2.981801301240921

Epoch: 5| Step: 1
Training loss: 3.1486573219299316
Validation loss: 2.9782912532488504

Epoch: 5| Step: 2
Training loss: 3.0587589740753174
Validation loss: 2.9743510683377585

Epoch: 5| Step: 3
Training loss: 3.411597490310669
Validation loss: 2.970178782939911

Epoch: 5| Step: 4
Training loss: 2.5895020961761475
Validation loss: 2.9670725663503013

Epoch: 5| Step: 5
Training loss: 3.0864005088806152
Validation loss: 2.96280629436175

Epoch: 5| Step: 6
Training loss: 2.8568413257598877
Validation loss: 2.9599846601486206

Epoch: 5| Step: 7
Training loss: 3.447535753250122
Validation loss: 2.9568437039852142

Epoch: 5| Step: 8
Training loss: 3.3259246349334717
Validation loss: 2.952716658512751

Epoch: 5| Step: 9
Training loss: 3.22497296333313
Validation loss: 2.9493022163709006

Epoch: 5| Step: 10
Training loss: 3.6699631214141846
Validation loss: 2.944923867781957

Epoch: 5| Step: 11
Training loss: 2.7925922870635986
Validation loss: 2.9412986238797507

Epoch: 38| Step: 0
Training loss: 3.279118061065674
Validation loss: 2.9389128983020782

Epoch: 5| Step: 1
Training loss: 3.3055496215820312
Validation loss: 2.9348282516002655

Epoch: 5| Step: 2
Training loss: 3.703252077102661
Validation loss: 2.932995935281118

Epoch: 5| Step: 3
Training loss: 2.9609572887420654
Validation loss: 2.9274918138980865

Epoch: 5| Step: 4
Training loss: 3.046882152557373
Validation loss: 2.924165199200312

Epoch: 5| Step: 5
Training loss: 2.694338083267212
Validation loss: 2.921024759610494

Epoch: 5| Step: 6
Training loss: 3.325162410736084
Validation loss: 2.9176754852135978

Epoch: 5| Step: 7
Training loss: 3.4530575275421143
Validation loss: 2.9152907729148865

Epoch: 5| Step: 8
Training loss: 2.4962940216064453
Validation loss: 2.911073992649714

Epoch: 5| Step: 9
Training loss: 3.1600286960601807
Validation loss: 2.9076884388923645

Epoch: 5| Step: 10
Training loss: 3.005537748336792
Validation loss: 2.9045173625151315

Epoch: 5| Step: 11
Training loss: 2.7280611991882324
Validation loss: 2.9009042183558145

Epoch: 39| Step: 0
Training loss: 2.9878792762756348
Validation loss: 2.897636443376541

Epoch: 5| Step: 1
Training loss: 3.9258809089660645
Validation loss: 2.894508570432663

Epoch: 5| Step: 2
Training loss: 2.9178621768951416
Validation loss: 2.8900372286637626

Epoch: 5| Step: 3
Training loss: 2.7793543338775635
Validation loss: 2.8869783182938895

Epoch: 5| Step: 4
Training loss: 2.871875286102295
Validation loss: 2.883772313594818

Epoch: 5| Step: 5
Training loss: 2.907339096069336
Validation loss: 2.879922479391098

Epoch: 5| Step: 6
Training loss: 2.8623692989349365
Validation loss: 2.8767936130364737

Epoch: 5| Step: 7
Training loss: 2.9282472133636475
Validation loss: 2.873714725176493

Epoch: 5| Step: 8
Training loss: 3.413133144378662
Validation loss: 2.870052933692932

Epoch: 5| Step: 9
Training loss: 3.0656495094299316
Validation loss: 2.8671794732411704

Epoch: 5| Step: 10
Training loss: 3.1831088066101074
Validation loss: 2.8639617760976157

Epoch: 5| Step: 11
Training loss: 3.637174367904663
Validation loss: 2.8599894841512046

Epoch: 40| Step: 0
Training loss: 3.3993077278137207
Validation loss: 2.8566957215468087

Epoch: 5| Step: 1
Training loss: 3.4830925464630127
Validation loss: 2.8529830276966095

Epoch: 5| Step: 2
Training loss: 3.4765288829803467
Validation loss: 2.849483847618103

Epoch: 5| Step: 3
Training loss: 2.7240500450134277
Validation loss: 2.8462723592917123

Epoch: 5| Step: 4
Training loss: 2.3400447368621826
Validation loss: 2.843058874209722

Epoch: 5| Step: 5
Training loss: 3.356428861618042
Validation loss: 2.840661217768987

Epoch: 5| Step: 6
Training loss: 2.5375030040740967
Validation loss: 2.8377232452233634

Epoch: 5| Step: 7
Training loss: 2.5648021697998047
Validation loss: 2.834269344806671

Epoch: 5| Step: 8
Training loss: 3.156019687652588
Validation loss: 2.831147978703181

Epoch: 5| Step: 9
Training loss: 3.3361105918884277
Validation loss: 2.827679475148519

Epoch: 5| Step: 10
Training loss: 3.0289788246154785
Validation loss: 2.8242766161759696

Epoch: 5| Step: 11
Training loss: 3.750800132751465
Validation loss: 2.820535510778427

Epoch: 41| Step: 0
Training loss: 3.501052141189575
Validation loss: 2.8171481986840567

Epoch: 5| Step: 1
Training loss: 3.0334620475769043
Validation loss: 2.813679506381353

Epoch: 5| Step: 2
Training loss: 2.7692806720733643
Validation loss: 2.81093164285024

Epoch: 5| Step: 3
Training loss: 3.0695385932922363
Validation loss: 2.8082719246546426

Epoch: 5| Step: 4
Training loss: 3.8115315437316895
Validation loss: 2.8052087823549905

Epoch: 5| Step: 5
Training loss: 2.739314556121826
Validation loss: 2.8023402194182077

Epoch: 5| Step: 6
Training loss: 2.2952027320861816
Validation loss: 2.7991877694924674

Epoch: 5| Step: 7
Training loss: 3.459536075592041
Validation loss: 2.7960498929023743

Epoch: 5| Step: 8
Training loss: 3.2275805473327637
Validation loss: 2.7946276366710663

Epoch: 5| Step: 9
Training loss: 2.4165234565734863
Validation loss: 2.789207955201467

Epoch: 5| Step: 10
Training loss: 2.921990156173706
Validation loss: 2.7849903106689453

Epoch: 5| Step: 11
Training loss: 2.6381804943084717
Validation loss: 2.7843138178189597

Epoch: 42| Step: 0
Training loss: 2.7210917472839355
Validation loss: 2.78108416001002

Epoch: 5| Step: 1
Training loss: 2.742999315261841
Validation loss: 2.7780947585900626

Epoch: 5| Step: 2
Training loss: 2.2734789848327637
Validation loss: 2.7768798569838204

Epoch: 5| Step: 3
Training loss: 3.206205368041992
Validation loss: 2.7722795009613037

Epoch: 5| Step: 4
Training loss: 3.4635181427001953
Validation loss: 2.7690154810746512

Epoch: 5| Step: 5
Training loss: 3.481335401535034
Validation loss: 2.7660596072673798

Epoch: 5| Step: 6
Training loss: 3.1677486896514893
Validation loss: 2.7637707392374673

Epoch: 5| Step: 7
Training loss: 2.4264369010925293
Validation loss: 2.761386493841807

Epoch: 5| Step: 8
Training loss: 3.0220184326171875
Validation loss: 2.7581789990266166

Epoch: 5| Step: 9
Training loss: 3.0630133152008057
Validation loss: 2.7549966474374137

Epoch: 5| Step: 10
Training loss: 3.3560519218444824
Validation loss: 2.753159840901693

Epoch: 5| Step: 11
Training loss: 2.1249091625213623
Validation loss: 2.749980409940084

Epoch: 43| Step: 0
Training loss: 2.970304250717163
Validation loss: 2.7465118964513144

Epoch: 5| Step: 1
Training loss: 2.7973930835723877
Validation loss: 2.7442544301350913

Epoch: 5| Step: 2
Training loss: 2.9513959884643555
Validation loss: 2.7414457201957703

Epoch: 5| Step: 3
Training loss: 2.590266704559326
Validation loss: 2.7390449394782386

Epoch: 5| Step: 4
Training loss: 3.263111114501953
Validation loss: 2.735733687877655

Epoch: 5| Step: 5
Training loss: 3.7368552684783936
Validation loss: 2.7337021927038827

Epoch: 5| Step: 6
Training loss: 2.9311208724975586
Validation loss: 2.730751554171244

Epoch: 5| Step: 7
Training loss: 3.0153374671936035
Validation loss: 2.727525924642881

Epoch: 5| Step: 8
Training loss: 2.8432583808898926
Validation loss: 2.7245030105113983

Epoch: 5| Step: 9
Training loss: 3.044381856918335
Validation loss: 2.721344898144404

Epoch: 5| Step: 10
Training loss: 2.6066274642944336
Validation loss: 2.7183677355448403

Epoch: 5| Step: 11
Training loss: 0.9059494733810425
Validation loss: 2.7160503566265106

Epoch: 44| Step: 0
Training loss: 3.4925689697265625
Validation loss: 2.7125628292560577

Epoch: 5| Step: 1
Training loss: 2.7693612575531006
Validation loss: 2.7097768088181815

Epoch: 5| Step: 2
Training loss: 2.767712116241455
Validation loss: 2.7070323824882507

Epoch: 5| Step: 3
Training loss: 2.801358222961426
Validation loss: 2.703585833311081

Epoch: 5| Step: 4
Training loss: 3.2610573768615723
Validation loss: 2.7013971308867135

Epoch: 5| Step: 5
Training loss: 2.9693431854248047
Validation loss: 2.6977238158384957

Epoch: 5| Step: 6
Training loss: 2.7388803958892822
Validation loss: 2.695197726289431

Epoch: 5| Step: 7
Training loss: 3.1130807399749756
Validation loss: 2.691658546527227

Epoch: 5| Step: 8
Training loss: 2.7952606678009033
Validation loss: 2.6880207111438117

Epoch: 5| Step: 9
Training loss: 2.271378755569458
Validation loss: 2.685182064771652

Epoch: 5| Step: 10
Training loss: 3.117424249649048
Validation loss: 2.6798757016658783

Epoch: 5| Step: 11
Training loss: 2.2650644779205322
Validation loss: 2.6767411728700004

Epoch: 45| Step: 0
Training loss: 3.2614428997039795
Validation loss: 2.6874152024586997

Epoch: 5| Step: 1
Training loss: 3.6635990142822266
Validation loss: 2.6788364748160043

Epoch: 5| Step: 2
Training loss: 2.596834421157837
Validation loss: 2.6690622369448342

Epoch: 5| Step: 3
Training loss: 3.320479154586792
Validation loss: 2.6671330332756042

Epoch: 5| Step: 4
Training loss: 3.0063936710357666
Validation loss: 2.6674939493338266

Epoch: 5| Step: 5
Training loss: 2.357614040374756
Validation loss: 2.666829456885656

Epoch: 5| Step: 6
Training loss: 2.7140843868255615
Validation loss: 2.664149949947993

Epoch: 5| Step: 7
Training loss: 2.3860764503479004
Validation loss: 2.6635327537854514

Epoch: 5| Step: 8
Training loss: 2.826584577560425
Validation loss: 2.6579599479834237

Epoch: 5| Step: 9
Training loss: 2.6411213874816895
Validation loss: 2.6527419090270996

Epoch: 5| Step: 10
Training loss: 2.763862371444702
Validation loss: 2.648272544145584

Epoch: 5| Step: 11
Training loss: 3.113405227661133
Validation loss: 2.645960877339045

Epoch: 46| Step: 0
Training loss: 2.5805623531341553
Validation loss: 2.6441036462783813

Epoch: 5| Step: 1
Training loss: 2.745568037033081
Validation loss: 2.6414231260617576

Epoch: 5| Step: 2
Training loss: 3.3870041370391846
Validation loss: 2.638403500119845

Epoch: 5| Step: 3
Training loss: 3.3755123615264893
Validation loss: 2.634951959053675

Epoch: 5| Step: 4
Training loss: 2.452086925506592
Validation loss: 2.631805350383123

Epoch: 5| Step: 5
Training loss: 2.460975170135498
Validation loss: 2.628407984972

Epoch: 5| Step: 6
Training loss: 3.4967868328094482
Validation loss: 2.625391195217768

Epoch: 5| Step: 7
Training loss: 3.078831672668457
Validation loss: 2.621589243412018

Epoch: 5| Step: 8
Training loss: 2.560962677001953
Validation loss: 2.618595391511917

Epoch: 5| Step: 9
Training loss: 2.8232364654541016
Validation loss: 2.6162947913010917

Epoch: 5| Step: 10
Training loss: 2.484142303466797
Validation loss: 2.6137331227461496

Epoch: 5| Step: 11
Training loss: 1.5348434448242188
Validation loss: 2.6115165650844574

Epoch: 47| Step: 0
Training loss: 2.7939515113830566
Validation loss: 2.6089556415875754

Epoch: 5| Step: 1
Training loss: 2.979206085205078
Validation loss: 2.6064807176589966

Epoch: 5| Step: 2
Training loss: 2.897526502609253
Validation loss: 2.6039553582668304

Epoch: 5| Step: 3
Training loss: 2.4200479984283447
Validation loss: 2.5994825959205627

Epoch: 5| Step: 4
Training loss: 2.6631228923797607
Validation loss: 2.596003790696462

Epoch: 5| Step: 5
Training loss: 3.3429737091064453
Validation loss: 2.5945815046628318

Epoch: 5| Step: 6
Training loss: 2.5909175872802734
Validation loss: 2.591799130042394

Epoch: 5| Step: 7
Training loss: 3.363386869430542
Validation loss: 2.587894082069397

Epoch: 5| Step: 8
Training loss: 2.430025100708008
Validation loss: 2.586052745580673

Epoch: 5| Step: 9
Training loss: 2.5647358894348145
Validation loss: 2.581964453061422

Epoch: 5| Step: 10
Training loss: 2.6840052604675293
Validation loss: 2.579984645048777

Epoch: 5| Step: 11
Training loss: 2.9710967540740967
Validation loss: 2.5742868979771933

Epoch: 48| Step: 0
Training loss: 2.720038890838623
Validation loss: 2.57199235757192

Epoch: 5| Step: 1
Training loss: 3.350825786590576
Validation loss: 2.568784991900126

Epoch: 5| Step: 2
Training loss: 2.9514753818511963
Validation loss: 2.5647118290265403

Epoch: 5| Step: 3
Training loss: 3.196566343307495
Validation loss: 2.5636551082134247

Epoch: 5| Step: 4
Training loss: 2.973931074142456
Validation loss: 2.5614319145679474

Epoch: 5| Step: 5
Training loss: 3.1823394298553467
Validation loss: 2.559590607881546

Epoch: 5| Step: 6
Training loss: 2.6420960426330566
Validation loss: 2.5602587262789407

Epoch: 5| Step: 7
Training loss: 2.3249258995056152
Validation loss: 2.5571683446566262

Epoch: 5| Step: 8
Training loss: 2.7669644355773926
Validation loss: 2.556988308827082

Epoch: 5| Step: 9
Training loss: 1.7564189434051514
Validation loss: 2.552580634752909

Epoch: 5| Step: 10
Training loss: 2.656832695007324
Validation loss: 2.551345616579056

Epoch: 5| Step: 11
Training loss: 1.989335298538208
Validation loss: 2.5472022692362466

Epoch: 49| Step: 0
Training loss: 3.0708372592926025
Validation loss: 2.5446986754735312

Epoch: 5| Step: 1
Training loss: 2.654613971710205
Validation loss: 2.5413293490807214

Epoch: 5| Step: 2
Training loss: 2.8325934410095215
Validation loss: 2.538297494252523

Epoch: 5| Step: 3
Training loss: 2.479046106338501
Validation loss: 2.534516930580139

Epoch: 5| Step: 4
Training loss: 2.751314640045166
Validation loss: 2.5300776263078055

Epoch: 5| Step: 5
Training loss: 2.4545247554779053
Validation loss: 2.5277280112107596

Epoch: 5| Step: 6
Training loss: 2.4392218589782715
Validation loss: 2.523890574773153

Epoch: 5| Step: 7
Training loss: 2.5384833812713623
Validation loss: 2.521285409728686

Epoch: 5| Step: 8
Training loss: 3.1024410724639893
Validation loss: 2.519525716702143

Epoch: 5| Step: 9
Training loss: 2.6787123680114746
Validation loss: 2.515764350692431

Epoch: 5| Step: 10
Training loss: 2.845982074737549
Validation loss: 2.5136497020721436

Epoch: 5| Step: 11
Training loss: 3.41343355178833
Validation loss: 2.5104722579320273

Epoch: 50| Step: 0
Training loss: 2.7926816940307617
Validation loss: 2.5092903077602386

Epoch: 5| Step: 1
Training loss: 3.0771007537841797
Validation loss: 2.5096567372481027

Epoch: 5| Step: 2
Training loss: 2.7137036323547363
Validation loss: 2.507315913836161

Epoch: 5| Step: 3
Training loss: 3.1101787090301514
Validation loss: 2.5036872128645578

Epoch: 5| Step: 4
Training loss: 2.307054281234741
Validation loss: 2.4998498956362405

Epoch: 5| Step: 5
Training loss: 3.0776498317718506
Validation loss: 2.496325353781382

Epoch: 5| Step: 6
Training loss: 2.7968032360076904
Validation loss: 2.4936630626519523

Epoch: 5| Step: 7
Training loss: 2.7105839252471924
Validation loss: 2.486779590447744

Epoch: 5| Step: 8
Training loss: 2.3027126789093018
Validation loss: 2.4856868187586465

Epoch: 5| Step: 9
Training loss: 2.1817963123321533
Validation loss: 2.4810613493124642

Epoch: 5| Step: 10
Training loss: 2.5695393085479736
Validation loss: 2.4778995315233865

Epoch: 5| Step: 11
Training loss: 2.4235405921936035
Validation loss: 2.4766183396180472

Epoch: 51| Step: 0
Training loss: 2.3718771934509277
Validation loss: 2.482526481151581

Epoch: 5| Step: 1
Training loss: 2.531721830368042
Validation loss: 2.4927085041999817

Epoch: 5| Step: 2
Training loss: 2.567570924758911
Validation loss: 2.4890729983647666

Epoch: 5| Step: 3
Training loss: 2.8940539360046387
Validation loss: 2.4711151917775473

Epoch: 5| Step: 4
Training loss: 2.880136013031006
Validation loss: 2.4641357163588204

Epoch: 5| Step: 5
Training loss: 2.4720547199249268
Validation loss: 2.4609335213899612

Epoch: 5| Step: 6
Training loss: 2.640747547149658
Validation loss: 2.4653383692105613

Epoch: 5| Step: 7
Training loss: 2.250121831893921
Validation loss: 2.4688848505417504

Epoch: 5| Step: 8
Training loss: 2.782205104827881
Validation loss: 2.467198461294174

Epoch: 5| Step: 9
Training loss: 3.3674228191375732
Validation loss: 2.4616665840148926

Epoch: 5| Step: 10
Training loss: 2.554385185241699
Validation loss: 2.4590896169344583

Epoch: 5| Step: 11
Training loss: 2.4113659858703613
Validation loss: 2.4568551778793335

Epoch: 52| Step: 0
Training loss: 3.1415858268737793
Validation loss: 2.4496877441803613

Epoch: 5| Step: 1
Training loss: 2.1176815032958984
Validation loss: 2.445436636606852

Epoch: 5| Step: 2
Training loss: 2.33729887008667
Validation loss: 2.443184624115626

Epoch: 5| Step: 3
Training loss: 2.619645357131958
Validation loss: 2.4403975506623587

Epoch: 5| Step: 4
Training loss: 2.182098865509033
Validation loss: 2.440526525179545

Epoch: 5| Step: 5
Training loss: 1.9523980617523193
Validation loss: 2.4389987091223397

Epoch: 5| Step: 6
Training loss: 2.6162428855895996
Validation loss: 2.438388928771019

Epoch: 5| Step: 7
Training loss: 3.029000997543335
Validation loss: 2.437591165304184

Epoch: 5| Step: 8
Training loss: 3.295344114303589
Validation loss: 2.430336798230807

Epoch: 5| Step: 9
Training loss: 3.0826330184936523
Validation loss: 2.425339549779892

Epoch: 5| Step: 10
Training loss: 2.6706008911132812
Validation loss: 2.4226051419973373

Epoch: 5| Step: 11
Training loss: 1.751020908355713
Validation loss: 2.4174029330412545

Epoch: 53| Step: 0
Training loss: 3.403637647628784
Validation loss: 2.4155403872330985

Epoch: 5| Step: 1
Training loss: 2.9622254371643066
Validation loss: 2.41393214960893

Epoch: 5| Step: 2
Training loss: 2.3348724842071533
Validation loss: 2.409440368413925

Epoch: 5| Step: 3
Training loss: 2.624424934387207
Validation loss: 2.4068410793940225

Epoch: 5| Step: 4
Training loss: 2.6750710010528564
Validation loss: 2.4051295121510825

Epoch: 5| Step: 5
Training loss: 2.3169658184051514
Validation loss: 2.402199625968933

Epoch: 5| Step: 6
Training loss: 2.1392760276794434
Validation loss: 2.398420055707296

Epoch: 5| Step: 7
Training loss: 2.4552478790283203
Validation loss: 2.3935763090848923

Epoch: 5| Step: 8
Training loss: 2.3972129821777344
Validation loss: 2.3918746411800385

Epoch: 5| Step: 9
Training loss: 2.908337116241455
Validation loss: 2.393566439549128

Epoch: 5| Step: 10
Training loss: 2.3632946014404297
Validation loss: 2.3947253227233887

Epoch: 5| Step: 11
Training loss: 2.175323963165283
Validation loss: 2.387147213021914

Epoch: 54| Step: 0
Training loss: 1.9650554656982422
Validation loss: 2.3792522847652435

Epoch: 5| Step: 1
Training loss: 2.4843504428863525
Validation loss: 2.3831054965655007

Epoch: 5| Step: 2
Training loss: 2.585658550262451
Validation loss: 2.377163444956144

Epoch: 5| Step: 3
Training loss: 2.141772508621216
Validation loss: 2.3791514535744986

Epoch: 5| Step: 4
Training loss: 2.5653223991394043
Validation loss: 2.3756517668565116

Epoch: 5| Step: 5
Training loss: 3.140929937362671
Validation loss: 2.377291296919187

Epoch: 5| Step: 6
Training loss: 2.5755629539489746
Validation loss: 2.378738691409429

Epoch: 5| Step: 7
Training loss: 3.085225820541382
Validation loss: 2.374591906865438

Epoch: 5| Step: 8
Training loss: 2.4070043563842773
Validation loss: 2.371736298004786

Epoch: 5| Step: 9
Training loss: 2.535745143890381
Validation loss: 2.3703020811080933

Epoch: 5| Step: 10
Training loss: 2.6300768852233887
Validation loss: 2.3649251063664756

Epoch: 5| Step: 11
Training loss: 2.585371971130371
Validation loss: 2.363266815741857

Epoch: 55| Step: 0
Training loss: 2.6948299407958984
Validation loss: 2.3630831837654114

Epoch: 5| Step: 1
Training loss: 2.85217547416687
Validation loss: 2.3580939173698425

Epoch: 5| Step: 2
Training loss: 1.8607537746429443
Validation loss: 2.3544088900089264

Epoch: 5| Step: 3
Training loss: 2.6418557167053223
Validation loss: 2.3513422906398773

Epoch: 5| Step: 4
Training loss: 2.602692127227783
Validation loss: 2.3524542152881622

Epoch: 5| Step: 5
Training loss: 2.757753610610962
Validation loss: 2.351293404897054

Epoch: 5| Step: 6
Training loss: 2.078346014022827
Validation loss: 2.346593350172043

Epoch: 5| Step: 7
Training loss: 2.922184944152832
Validation loss: 2.3431354264418283

Epoch: 5| Step: 8
Training loss: 2.2699177265167236
Validation loss: 2.342215970158577

Epoch: 5| Step: 9
Training loss: 2.769691228866577
Validation loss: 2.3411644796530404

Epoch: 5| Step: 10
Training loss: 2.2556869983673096
Validation loss: 2.3350613713264465

Epoch: 5| Step: 11
Training loss: 2.6489429473876953
Validation loss: 2.3372077643871307

Epoch: 56| Step: 0
Training loss: 2.5300588607788086
Validation loss: 2.33325665195783

Epoch: 5| Step: 1
Training loss: 2.4825148582458496
Validation loss: 2.332545682787895

Epoch: 5| Step: 2
Training loss: 1.758266806602478
Validation loss: 2.3298390905062356

Epoch: 5| Step: 3
Training loss: 2.4490411281585693
Validation loss: 2.3260479470094046

Epoch: 5| Step: 4
Training loss: 2.678304672241211
Validation loss: 2.321749915679296

Epoch: 5| Step: 5
Training loss: 2.4293980598449707
Validation loss: 2.3175800939400992

Epoch: 5| Step: 6
Training loss: 2.838221549987793
Validation loss: 2.3161846548318863

Epoch: 5| Step: 7
Training loss: 2.624741792678833
Validation loss: 2.3125001887480416

Epoch: 5| Step: 8
Training loss: 2.437217950820923
Validation loss: 2.3070421715577445

Epoch: 5| Step: 9
Training loss: 2.6680667400360107
Validation loss: 2.3098271687825522

Epoch: 5| Step: 10
Training loss: 2.5549428462982178
Validation loss: 2.3176656862099967

Epoch: 5| Step: 11
Training loss: 2.4303054809570312
Validation loss: 2.3373314340909324

Epoch: 57| Step: 0
Training loss: 2.537128448486328
Validation loss: 2.310394992431005

Epoch: 5| Step: 1
Training loss: 2.3337929248809814
Validation loss: 2.2987846781810126

Epoch: 5| Step: 2
Training loss: 1.6675004959106445
Validation loss: 2.30035533507665

Epoch: 5| Step: 3
Training loss: 2.2396881580352783
Validation loss: 2.3139458000659943

Epoch: 5| Step: 4
Training loss: 2.067836046218872
Validation loss: 2.3284356693426767

Epoch: 5| Step: 5
Training loss: 2.397221803665161
Validation loss: 2.3487499952316284

Epoch: 5| Step: 6
Training loss: 3.0978260040283203
Validation loss: 2.3507805168628693

Epoch: 5| Step: 7
Training loss: 2.735198497772217
Validation loss: 2.3351814498504004

Epoch: 5| Step: 8
Training loss: 2.972233295440674
Validation loss: 2.308236892024676

Epoch: 5| Step: 9
Training loss: 2.5451831817626953
Validation loss: 2.2894248267014823

Epoch: 5| Step: 10
Training loss: 2.7462356090545654
Validation loss: 2.2884099185466766

Epoch: 5| Step: 11
Training loss: 2.668750047683716
Validation loss: 2.280937766035398

Epoch: 58| Step: 0
Training loss: 2.596442461013794
Validation loss: 2.279271428783735

Epoch: 5| Step: 1
Training loss: 2.8891568183898926
Validation loss: 2.2762453059355416

Epoch: 5| Step: 2
Training loss: 2.3208439350128174
Validation loss: 2.2726954321066537

Epoch: 5| Step: 3
Training loss: 2.548415422439575
Validation loss: 2.2726108183463416

Epoch: 5| Step: 4
Training loss: 2.1487948894500732
Validation loss: 2.268147642413775

Epoch: 5| Step: 5
Training loss: 2.0638225078582764
Validation loss: 2.2708870669205985

Epoch: 5| Step: 6
Training loss: 2.400179386138916
Validation loss: 2.2690052688121796

Epoch: 5| Step: 7
Training loss: 2.8390517234802246
Validation loss: 2.268944283326467

Epoch: 5| Step: 8
Training loss: 2.561901569366455
Validation loss: 2.264706219236056

Epoch: 5| Step: 9
Training loss: 2.632793664932251
Validation loss: 2.26638126373291

Epoch: 5| Step: 10
Training loss: 1.7838128805160522
Validation loss: 2.261451025803884

Epoch: 5| Step: 11
Training loss: 2.450209140777588
Validation loss: 2.2617533951997757

Epoch: 59| Step: 0
Training loss: 2.825441360473633
Validation loss: 2.2599762777487435

Epoch: 5| Step: 1
Training loss: 2.090360641479492
Validation loss: 2.2621352076530457

Epoch: 5| Step: 2
Training loss: 2.3857765197753906
Validation loss: 2.265410542488098

Epoch: 5| Step: 3
Training loss: 2.702644109725952
Validation loss: 2.256940777103106

Epoch: 5| Step: 4
Training loss: 2.830822467803955
Validation loss: 2.2486648758252463

Epoch: 5| Step: 5
Training loss: 2.803825616836548
Validation loss: 2.2432941595713296

Epoch: 5| Step: 6
Training loss: 1.783082365989685
Validation loss: 2.2366696695486703

Epoch: 5| Step: 7
Training loss: 2.426809787750244
Validation loss: 2.235564966996511

Epoch: 5| Step: 8
Training loss: 2.386552095413208
Validation loss: 2.234559655189514

Epoch: 5| Step: 9
Training loss: 1.796820044517517
Validation loss: 2.231340060631434

Epoch: 5| Step: 10
Training loss: 2.5243756771087646
Validation loss: 2.232098529736201

Epoch: 5| Step: 11
Training loss: 2.556264877319336
Validation loss: 2.2290793855985007

Epoch: 60| Step: 0
Training loss: 1.906137466430664
Validation loss: 2.2307254473368325

Epoch: 5| Step: 1
Training loss: 2.9710264205932617
Validation loss: 2.2284229000409446

Epoch: 5| Step: 2
Training loss: 3.035733222961426
Validation loss: 2.2282528281211853

Epoch: 5| Step: 3
Training loss: 2.896211624145508
Validation loss: 2.22504090766112

Epoch: 5| Step: 4
Training loss: 2.744574546813965
Validation loss: 2.2245490103960037

Epoch: 5| Step: 5
Training loss: 1.8813577890396118
Validation loss: 2.217616006731987

Epoch: 5| Step: 6
Training loss: 2.213728427886963
Validation loss: 2.2178582698106766

Epoch: 5| Step: 7
Training loss: 1.8259239196777344
Validation loss: 2.21462619304657

Epoch: 5| Step: 8
Training loss: 2.6408848762512207
Validation loss: 2.2098786334196725

Epoch: 5| Step: 9
Training loss: 2.1505231857299805
Validation loss: 2.205520510673523

Epoch: 5| Step: 10
Training loss: 2.1073086261749268
Validation loss: 2.211799219250679

Epoch: 5| Step: 11
Training loss: 0.8990530967712402
Validation loss: 2.211750974257787

Epoch: 61| Step: 0
Training loss: 2.2211952209472656
Validation loss: 2.2148131281137466

Epoch: 5| Step: 1
Training loss: 1.9675703048706055
Validation loss: 2.2261213858922324

Epoch: 5| Step: 2
Training loss: 2.257255792617798
Validation loss: 2.244830682873726

Epoch: 5| Step: 3
Training loss: 3.1610376834869385
Validation loss: 2.2498491406440735

Epoch: 5| Step: 4
Training loss: 2.2150046825408936
Validation loss: 2.2292552838722863

Epoch: 5| Step: 5
Training loss: 2.067643642425537
Validation loss: 2.2144753684600196

Epoch: 5| Step: 6
Training loss: 2.2070915699005127
Validation loss: 2.205163856347402

Epoch: 5| Step: 7
Training loss: 2.564077138900757
Validation loss: 2.1996296544869742

Epoch: 5| Step: 8
Training loss: 1.8388103246688843
Validation loss: 2.2033261259396872

Epoch: 5| Step: 9
Training loss: 2.677511692047119
Validation loss: 2.2138224244117737

Epoch: 5| Step: 10
Training loss: 2.733548641204834
Validation loss: 2.2143856485684714

Epoch: 5| Step: 11
Training loss: 3.1930418014526367
Validation loss: 2.2113444854815802

Epoch: 62| Step: 0
Training loss: 1.7121632099151611
Validation loss: 2.2099839647610984

Epoch: 5| Step: 1
Training loss: 2.4733331203460693
Validation loss: 2.207538644472758

Epoch: 5| Step: 2
Training loss: 1.8120425939559937
Validation loss: 2.2113919804493585

Epoch: 5| Step: 3
Training loss: 2.058519124984741
Validation loss: 2.209438219666481

Epoch: 5| Step: 4
Training loss: 2.5295567512512207
Validation loss: 2.207626466949781

Epoch: 5| Step: 5
Training loss: 2.253080368041992
Validation loss: 2.200104773044586

Epoch: 5| Step: 6
Training loss: 2.398594379425049
Validation loss: 2.190473491946856

Epoch: 5| Step: 7
Training loss: 2.604969024658203
Validation loss: 2.1847209334373474

Epoch: 5| Step: 8
Training loss: 2.6166958808898926
Validation loss: 2.1810420056184134

Epoch: 5| Step: 9
Training loss: 2.624666690826416
Validation loss: 2.1843030005693436

Epoch: 5| Step: 10
Training loss: 2.743391990661621
Validation loss: 2.1829613794883094

Epoch: 5| Step: 11
Training loss: 2.544879198074341
Validation loss: 2.181920756896337

Epoch: 63| Step: 0
Training loss: 2.513803005218506
Validation loss: 2.177581563591957

Epoch: 5| Step: 1
Training loss: 1.9430115222930908
Validation loss: 2.176488200823466

Epoch: 5| Step: 2
Training loss: 2.4261274337768555
Validation loss: 2.1701681365569434

Epoch: 5| Step: 3
Training loss: 2.390383243560791
Validation loss: 2.1706575006246567

Epoch: 5| Step: 4
Training loss: 2.4999775886535645
Validation loss: 2.167546808719635

Epoch: 5| Step: 5
Training loss: 2.5240378379821777
Validation loss: 2.1672879457473755

Epoch: 5| Step: 6
Training loss: 2.146516799926758
Validation loss: 2.1655349135398865

Epoch: 5| Step: 7
Training loss: 2.6376919746398926
Validation loss: 2.158438578248024

Epoch: 5| Step: 8
Training loss: 2.1405155658721924
Validation loss: 2.160248945156733

Epoch: 5| Step: 9
Training loss: 2.007521152496338
Validation loss: 2.155451685190201

Epoch: 5| Step: 10
Training loss: 2.3675408363342285
Validation loss: 2.1588740199804306

Epoch: 5| Step: 11
Training loss: 2.327138662338257
Validation loss: 2.155367831389109

Epoch: 64| Step: 0
Training loss: 1.6801172494888306
Validation loss: 2.153502176205317

Epoch: 5| Step: 1
Training loss: 2.6696250438690186
Validation loss: 2.1562905063231788

Epoch: 5| Step: 2
Training loss: 2.2906835079193115
Validation loss: 2.1595909893512726

Epoch: 5| Step: 3
Training loss: 2.2943482398986816
Validation loss: 2.1604678481817245

Epoch: 5| Step: 4
Training loss: 2.219238758087158
Validation loss: 2.163865844408671

Epoch: 5| Step: 5
Training loss: 2.381730079650879
Validation loss: 2.1541616519292197

Epoch: 5| Step: 6
Training loss: 2.7497146129608154
Validation loss: 2.1519597272078195

Epoch: 5| Step: 7
Training loss: 2.421452760696411
Validation loss: 2.1497596502304077

Epoch: 5| Step: 8
Training loss: 2.3856496810913086
Validation loss: 2.1443502455949783

Epoch: 5| Step: 9
Training loss: 2.3034279346466064
Validation loss: 2.15046892563502

Epoch: 5| Step: 10
Training loss: 2.0955381393432617
Validation loss: 2.1504892160495124

Epoch: 5| Step: 11
Training loss: 2.3200783729553223
Validation loss: 2.1655685802300773

Epoch: 65| Step: 0
Training loss: 1.5243828296661377
Validation loss: 2.161868696411451

Epoch: 5| Step: 1
Training loss: 2.0411524772644043
Validation loss: 2.1675023635228476

Epoch: 5| Step: 2
Training loss: 2.3330178260803223
Validation loss: 2.154398168126742

Epoch: 5| Step: 3
Training loss: 2.517575740814209
Validation loss: 2.1466825803120932

Epoch: 5| Step: 4
Training loss: 3.34259033203125
Validation loss: 2.138309304912885

Epoch: 5| Step: 5
Training loss: 2.1894054412841797
Validation loss: 2.1325743794441223

Epoch: 5| Step: 6
Training loss: 2.1666860580444336
Validation loss: 2.1308046181996665

Epoch: 5| Step: 7
Training loss: 2.321798801422119
Validation loss: 2.13467871149381

Epoch: 5| Step: 8
Training loss: 2.3587539196014404
Validation loss: 2.150238504012426

Epoch: 5| Step: 9
Training loss: 2.0161232948303223
Validation loss: 2.1469806432724

Epoch: 5| Step: 10
Training loss: 2.3672256469726562
Validation loss: 2.1491472721099854

Epoch: 5| Step: 11
Training loss: 3.279381036758423
Validation loss: 2.143140524625778

Epoch: 66| Step: 0
Training loss: 1.7646780014038086
Validation loss: 2.1253838737805686

Epoch: 5| Step: 1
Training loss: 2.1412577629089355
Validation loss: 2.1284406085809073

Epoch: 5| Step: 2
Training loss: 2.6004340648651123
Validation loss: 2.1311028500398

Epoch: 5| Step: 3
Training loss: 2.5832977294921875
Validation loss: 2.1326942493518195

Epoch: 5| Step: 4
Training loss: 1.8688056468963623
Validation loss: 2.1369117498397827

Epoch: 5| Step: 5
Training loss: 2.4148356914520264
Validation loss: 2.1328513075908027

Epoch: 5| Step: 6
Training loss: 2.8358802795410156
Validation loss: 2.135007217526436

Epoch: 5| Step: 7
Training loss: 2.3329882621765137
Validation loss: 2.1366045574347177

Epoch: 5| Step: 8
Training loss: 2.224149465560913
Validation loss: 2.135079105695089

Epoch: 5| Step: 9
Training loss: 1.8767776489257812
Validation loss: 2.1317195097605386

Epoch: 5| Step: 10
Training loss: 2.260786533355713
Validation loss: 2.129231552282969

Epoch: 5| Step: 11
Training loss: 3.617903470993042
Validation loss: 2.1274381329615912

Epoch: 67| Step: 0
Training loss: 2.538806915283203
Validation loss: 2.1219413181145987

Epoch: 5| Step: 1
Training loss: 1.8812129497528076
Validation loss: 2.1144309838612876

Epoch: 5| Step: 2
Training loss: 2.6595187187194824
Validation loss: 2.113357683022817

Epoch: 5| Step: 3
Training loss: 2.491518020629883
Validation loss: 2.111384297410647

Epoch: 5| Step: 4
Training loss: 1.9273509979248047
Validation loss: 2.111342007915179

Epoch: 5| Step: 5
Training loss: 2.2783522605895996
Validation loss: 2.1074329862991967

Epoch: 5| Step: 6
Training loss: 2.573751211166382
Validation loss: 2.1059270153443017

Epoch: 5| Step: 7
Training loss: 2.2388463020324707
Validation loss: 2.100276216864586

Epoch: 5| Step: 8
Training loss: 1.9146029949188232
Validation loss: 2.1013960440953574

Epoch: 5| Step: 9
Training loss: 2.146378993988037
Validation loss: 2.100674723585447

Epoch: 5| Step: 10
Training loss: 2.3830361366271973
Validation loss: 2.1004699369271598

Epoch: 5| Step: 11
Training loss: 2.142772674560547
Validation loss: 2.098412255446116

Epoch: 68| Step: 0
Training loss: 1.9532502889633179
Validation loss: 2.0953573087851205

Epoch: 5| Step: 1
Training loss: 2.0498929023742676
Validation loss: 2.093808194001516

Epoch: 5| Step: 2
Training loss: 2.2408533096313477
Validation loss: 2.1038260459899902

Epoch: 5| Step: 3
Training loss: 2.479588747024536
Validation loss: 2.099116802215576

Epoch: 5| Step: 4
Training loss: 2.4500269889831543
Validation loss: 2.100391447544098

Epoch: 5| Step: 5
Training loss: 2.231297254562378
Validation loss: 2.112946704030037

Epoch: 5| Step: 6
Training loss: 2.1427884101867676
Validation loss: 2.112133393685023

Epoch: 5| Step: 7
Training loss: 2.55318021774292
Validation loss: 2.1057653625806174

Epoch: 5| Step: 8
Training loss: 2.3364169597625732
Validation loss: 2.098788688580195

Epoch: 5| Step: 9
Training loss: 2.0256881713867188
Validation loss: 2.0975671211878457

Epoch: 5| Step: 10
Training loss: 2.2117393016815186
Validation loss: 2.09174574414889

Epoch: 5| Step: 11
Training loss: 3.2769927978515625
Validation loss: 2.0886635979016623

Epoch: 69| Step: 0
Training loss: 2.662564516067505
Validation loss: 2.0946546345949173

Epoch: 5| Step: 1
Training loss: 2.4423365592956543
Validation loss: 2.1017233779033027

Epoch: 5| Step: 2
Training loss: 2.111917495727539
Validation loss: 2.1093438615401587

Epoch: 5| Step: 3
Training loss: 2.463862895965576
Validation loss: 2.107795541485151

Epoch: 5| Step: 4
Training loss: 2.5923633575439453
Validation loss: 2.113772635658582

Epoch: 5| Step: 5
Training loss: 2.344062328338623
Validation loss: 2.1150785287221274

Epoch: 5| Step: 6
Training loss: 2.067444324493408
Validation loss: 2.1147821048895517

Epoch: 5| Step: 7
Training loss: 2.441901206970215
Validation loss: 2.117975821097692

Epoch: 5| Step: 8
Training loss: 1.9396775960922241
Validation loss: 2.106065422296524

Epoch: 5| Step: 9
Training loss: 2.1697838306427
Validation loss: 2.1030724247296653

Epoch: 5| Step: 10
Training loss: 2.0516669750213623
Validation loss: 2.099292367696762

Epoch: 5| Step: 11
Training loss: 1.107304334640503
Validation loss: 2.094081918398539

Epoch: 70| Step: 0
Training loss: 2.516399621963501
Validation loss: 2.09053244193395

Epoch: 5| Step: 1
Training loss: 2.2695109844207764
Validation loss: 2.0888470659653344

Epoch: 5| Step: 2
Training loss: 2.0252766609191895
Validation loss: 2.0798870027065277

Epoch: 5| Step: 3
Training loss: 2.505197286605835
Validation loss: 2.081377034385999

Epoch: 5| Step: 4
Training loss: 2.2021889686584473
Validation loss: 2.0769222378730774

Epoch: 5| Step: 5
Training loss: 2.072763681411743
Validation loss: 2.0773081878821054

Epoch: 5| Step: 6
Training loss: 2.3878157138824463
Validation loss: 2.074035574992498

Epoch: 5| Step: 7
Training loss: 2.2925381660461426
Validation loss: 2.079340840379397

Epoch: 5| Step: 8
Training loss: 2.164618968963623
Validation loss: 2.076759288708369

Epoch: 5| Step: 9
Training loss: 2.5419178009033203
Validation loss: 2.07875527938207

Epoch: 5| Step: 10
Training loss: 1.9422029256820679
Validation loss: 2.077773481607437

Epoch: 5| Step: 11
Training loss: 1.8967927694320679
Validation loss: 2.079651822646459

Epoch: 71| Step: 0
Training loss: 2.146768093109131
Validation loss: 2.0749679456154504

Epoch: 5| Step: 1
Training loss: 1.883697509765625
Validation loss: 2.0777216156323752

Epoch: 5| Step: 2
Training loss: 1.8148177862167358
Validation loss: 2.078729803363482

Epoch: 5| Step: 3
Training loss: 2.219165325164795
Validation loss: 2.091220195094744

Epoch: 5| Step: 4
Training loss: 1.8226398229599
Validation loss: 2.101456726590792

Epoch: 5| Step: 5
Training loss: 2.7389345169067383
Validation loss: 2.1094243228435516

Epoch: 5| Step: 6
Training loss: 2.245114803314209
Validation loss: 2.1089339752991996

Epoch: 5| Step: 7
Training loss: 2.974222183227539
Validation loss: 2.116570850213369

Epoch: 5| Step: 8
Training loss: 2.0243191719055176
Validation loss: 2.1138884822527566

Epoch: 5| Step: 9
Training loss: 2.3928136825561523
Validation loss: 2.100116948286692

Epoch: 5| Step: 10
Training loss: 2.3682219982147217
Validation loss: 2.0958901246388755

Epoch: 5| Step: 11
Training loss: 2.704578399658203
Validation loss: 2.073701893289884

Epoch: 72| Step: 0
Training loss: 2.3920187950134277
Validation loss: 2.072017898162206

Epoch: 5| Step: 1
Training loss: 2.3360533714294434
Validation loss: 2.0652087330818176

Epoch: 5| Step: 2
Training loss: 1.7319793701171875
Validation loss: 2.0683865000804267

Epoch: 5| Step: 3
Training loss: 2.8383872509002686
Validation loss: 2.071402663985888

Epoch: 5| Step: 4
Training loss: 2.2303290367126465
Validation loss: 2.0749415953954062

Epoch: 5| Step: 5
Training loss: 2.246206283569336
Validation loss: 2.0733593702316284

Epoch: 5| Step: 6
Training loss: 2.000748634338379
Validation loss: 2.0788270433743796

Epoch: 5| Step: 7
Training loss: 2.5289700031280518
Validation loss: 2.0694503585497537

Epoch: 5| Step: 8
Training loss: 2.761591911315918
Validation loss: 2.072428375482559

Epoch: 5| Step: 9
Training loss: 1.964900255203247
Validation loss: 2.067170967658361

Epoch: 5| Step: 10
Training loss: 1.8116419315338135
Validation loss: 2.0647534678379693

Epoch: 5| Step: 11
Training loss: 1.3178596496582031
Validation loss: 2.0580403407414756

Epoch: 73| Step: 0
Training loss: 2.033433675765991
Validation loss: 2.063278908530871

Epoch: 5| Step: 1
Training loss: 2.5870792865753174
Validation loss: 2.0564688642819724

Epoch: 5| Step: 2
Training loss: 2.3613014221191406
Validation loss: 2.069974551598231

Epoch: 5| Step: 3
Training loss: 2.2729477882385254
Validation loss: 2.0816065818071365

Epoch: 5| Step: 4
Training loss: 2.3563930988311768
Validation loss: 2.083351085583369

Epoch: 5| Step: 5
Training loss: 1.5947787761688232
Validation loss: 2.0899812976519265

Epoch: 5| Step: 6
Training loss: 2.087611436843872
Validation loss: 2.0906061182419458

Epoch: 5| Step: 7
Training loss: 2.6066577434539795
Validation loss: 2.0827837685743966

Epoch: 5| Step: 8
Training loss: 2.3840842247009277
Validation loss: 2.081756129860878

Epoch: 5| Step: 9
Training loss: 2.2403998374938965
Validation loss: 2.0653745432694754

Epoch: 5| Step: 10
Training loss: 2.146073818206787
Validation loss: 2.0630030433336892

Epoch: 5| Step: 11
Training loss: 1.6232062578201294
Validation loss: 2.0586418509483337

Epoch: 74| Step: 0
Training loss: 2.3881614208221436
Validation loss: 2.046031912167867

Epoch: 5| Step: 1
Training loss: 2.8288135528564453
Validation loss: 2.047660782933235

Epoch: 5| Step: 2
Training loss: 2.401655673980713
Validation loss: 2.044265558322271

Epoch: 5| Step: 3
Training loss: 2.342958450317383
Validation loss: 2.045586700240771

Epoch: 5| Step: 4
Training loss: 2.035926342010498
Validation loss: 2.0495452533165612

Epoch: 5| Step: 5
Training loss: 1.994728446006775
Validation loss: 2.0515287766853967

Epoch: 5| Step: 6
Training loss: 2.262948989868164
Validation loss: 2.0422582079966864

Epoch: 5| Step: 7
Training loss: 1.8321685791015625
Validation loss: 2.039331321914991

Epoch: 5| Step: 8
Training loss: 1.6924511194229126
Validation loss: 2.053361808260282

Epoch: 5| Step: 9
Training loss: 2.0884029865264893
Validation loss: 2.0511418928702674

Epoch: 5| Step: 10
Training loss: 2.2493841648101807
Validation loss: 2.0600884159406028

Epoch: 5| Step: 11
Training loss: 2.9738378524780273
Validation loss: 2.062577962875366

Epoch: 75| Step: 0
Training loss: 2.314213275909424
Validation loss: 2.074697678287824

Epoch: 5| Step: 1
Training loss: 2.0460801124572754
Validation loss: 2.068004623055458

Epoch: 5| Step: 2
Training loss: 1.821519136428833
Validation loss: 2.0611565758784614

Epoch: 5| Step: 3
Training loss: 2.012064218521118
Validation loss: 2.059760734438896

Epoch: 5| Step: 4
Training loss: 2.174272060394287
Validation loss: 2.059178868929545

Epoch: 5| Step: 5
Training loss: 2.511420249938965
Validation loss: 2.0505411426226297

Epoch: 5| Step: 6
Training loss: 2.3040127754211426
Validation loss: 2.0400900145371756

Epoch: 5| Step: 7
Training loss: 2.4469900131225586
Validation loss: 2.0427839954694114

Epoch: 5| Step: 8
Training loss: 2.7816414833068848
Validation loss: 2.0381516814231873

Epoch: 5| Step: 9
Training loss: 1.8319957256317139
Validation loss: 2.0352986504634223

Epoch: 5| Step: 10
Training loss: 1.997070074081421
Validation loss: 2.041819244623184

Epoch: 5| Step: 11
Training loss: 2.5984745025634766
Validation loss: 2.0426599582036338

Epoch: 76| Step: 0
Training loss: 2.506504535675049
Validation loss: 2.0450893143812814

Epoch: 5| Step: 1
Training loss: 1.8917373418807983
Validation loss: 2.041473234693209

Epoch: 5| Step: 2
Training loss: 2.5210461616516113
Validation loss: 2.048534353574117

Epoch: 5| Step: 3
Training loss: 2.1128177642822266
Validation loss: 2.048880914847056

Epoch: 5| Step: 4
Training loss: 2.5132596492767334
Validation loss: 2.05503012239933

Epoch: 5| Step: 5
Training loss: 2.0200095176696777
Validation loss: 2.0457063913345337

Epoch: 5| Step: 6
Training loss: 2.526808261871338
Validation loss: 2.0490752259890237

Epoch: 5| Step: 7
Training loss: 2.048963785171509
Validation loss: 2.0419187247753143

Epoch: 5| Step: 8
Training loss: 2.408823251724243
Validation loss: 2.037913983066877

Epoch: 5| Step: 9
Training loss: 2.0928313732147217
Validation loss: 2.0368349154790244

Epoch: 5| Step: 10
Training loss: 2.106616973876953
Validation loss: 2.035421450932821

Epoch: 5| Step: 11
Training loss: 1.403533935546875
Validation loss: 2.028505558768908

Epoch: 77| Step: 0
Training loss: 2.292776107788086
Validation loss: 2.0276388178269067

Epoch: 5| Step: 1
Training loss: 2.2579033374786377
Validation loss: 2.0265411734580994

Epoch: 5| Step: 2
Training loss: 2.7032101154327393
Validation loss: 2.026482696334521

Epoch: 5| Step: 3
Training loss: 1.717291235923767
Validation loss: 2.0269664029280343

Epoch: 5| Step: 4
Training loss: 2.196397066116333
Validation loss: 2.0260406782229743

Epoch: 5| Step: 5
Training loss: 2.6491620540618896
Validation loss: 2.0260991752147675

Epoch: 5| Step: 6
Training loss: 2.416506290435791
Validation loss: 2.022073447704315

Epoch: 5| Step: 7
Training loss: 1.816300630569458
Validation loss: 2.037822345892588

Epoch: 5| Step: 8
Training loss: 1.8561210632324219
Validation loss: 2.0315430561701455

Epoch: 5| Step: 9
Training loss: 1.924523949623108
Validation loss: 2.0390671690305076

Epoch: 5| Step: 10
Training loss: 2.3999757766723633
Validation loss: 2.0513890832662582

Epoch: 5| Step: 11
Training loss: 2.4939894676208496
Validation loss: 2.054755136370659

Epoch: 78| Step: 0
Training loss: 2.7451694011688232
Validation loss: 2.052505577603976

Epoch: 5| Step: 1
Training loss: 2.698481798171997
Validation loss: 2.0558968832095466

Epoch: 5| Step: 2
Training loss: 1.8508861064910889
Validation loss: 2.05374668041865

Epoch: 5| Step: 3
Training loss: 2.7155215740203857
Validation loss: 2.060206005970637

Epoch: 5| Step: 4
Training loss: 2.000871419906616
Validation loss: 2.0536799132823944

Epoch: 5| Step: 5
Training loss: 2.015993356704712
Validation loss: 2.0557271391153336

Epoch: 5| Step: 6
Training loss: 1.9097156524658203
Validation loss: 2.0533636709054313

Epoch: 5| Step: 7
Training loss: 2.3368024826049805
Validation loss: 2.038417473435402

Epoch: 5| Step: 8
Training loss: 2.2237632274627686
Validation loss: 2.0388861099878945

Epoch: 5| Step: 9
Training loss: 1.3719581365585327
Validation loss: 2.0275789300600686

Epoch: 5| Step: 10
Training loss: 2.438120126724243
Validation loss: 2.0212055246035256

Epoch: 5| Step: 11
Training loss: 2.0304672718048096
Validation loss: 2.0273500134547553

Epoch: 79| Step: 0
Training loss: 2.6701626777648926
Validation loss: 2.036859408020973

Epoch: 5| Step: 1
Training loss: 1.8247709274291992
Validation loss: 2.035994306206703

Epoch: 5| Step: 2
Training loss: 2.2168867588043213
Validation loss: 2.043765197197596

Epoch: 5| Step: 3
Training loss: 2.2600083351135254
Validation loss: 2.0401988526185355

Epoch: 5| Step: 4
Training loss: 2.066316843032837
Validation loss: 2.0431786527236304

Epoch: 5| Step: 5
Training loss: 2.4108357429504395
Validation loss: 2.0359723766644797

Epoch: 5| Step: 6
Training loss: 2.6446499824523926
Validation loss: 2.035980924963951

Epoch: 5| Step: 7
Training loss: 2.083758592605591
Validation loss: 2.0318907350301743

Epoch: 5| Step: 8
Training loss: 1.819544792175293
Validation loss: 2.0331291258335114

Epoch: 5| Step: 9
Training loss: 2.142089605331421
Validation loss: 2.0280620753765106

Epoch: 5| Step: 10
Training loss: 2.079082489013672
Validation loss: 2.0221924036741257

Epoch: 5| Step: 11
Training loss: 2.4391143321990967
Validation loss: 2.02560064693292

Epoch: 80| Step: 0
Training loss: 2.270244598388672
Validation loss: 2.0341974993546805

Epoch: 5| Step: 1
Training loss: 1.8649088144302368
Validation loss: 2.0490961968898773

Epoch: 5| Step: 2
Training loss: 1.7950527667999268
Validation loss: 2.0459502190351486

Epoch: 5| Step: 3
Training loss: 2.5195729732513428
Validation loss: 2.0471510887145996

Epoch: 5| Step: 4
Training loss: 2.421576976776123
Validation loss: 2.048291484514872

Epoch: 5| Step: 5
Training loss: 1.9359893798828125
Validation loss: 2.042622541387876

Epoch: 5| Step: 6
Training loss: 2.4023618698120117
Validation loss: 2.048973227540652

Epoch: 5| Step: 7
Training loss: 2.234107494354248
Validation loss: 2.0439851929744086

Epoch: 5| Step: 8
Training loss: 1.8613609075546265
Validation loss: 2.047976473967234

Epoch: 5| Step: 9
Training loss: 2.490980625152588
Validation loss: 2.0533527135849

Epoch: 5| Step: 10
Training loss: 2.1809704303741455
Validation loss: 2.041802997390429

Epoch: 5| Step: 11
Training loss: 2.3489747047424316
Validation loss: 2.047346537311872

Epoch: 81| Step: 0
Training loss: 2.6585264205932617
Validation loss: 2.0454519192377725

Epoch: 5| Step: 1
Training loss: 2.209807872772217
Validation loss: 2.0396669507026672

Epoch: 5| Step: 2
Training loss: 2.318427562713623
Validation loss: 2.034736598531405

Epoch: 5| Step: 3
Training loss: 1.6710857152938843
Validation loss: 2.031802530090014

Epoch: 5| Step: 4
Training loss: 2.6081671714782715
Validation loss: 2.023442084590594

Epoch: 5| Step: 5
Training loss: 2.228623867034912
Validation loss: 2.0296607663234076

Epoch: 5| Step: 6
Training loss: 1.828495740890503
Validation loss: 2.0305657436450324

Epoch: 5| Step: 7
Training loss: 2.3297181129455566
Validation loss: 2.032908856868744

Epoch: 5| Step: 8
Training loss: 2.144298791885376
Validation loss: 2.036984145641327

Epoch: 5| Step: 9
Training loss: 1.9842979907989502
Validation loss: 2.0373523284991584

Epoch: 5| Step: 10
Training loss: 2.308307647705078
Validation loss: 2.039375106493632

Epoch: 5| Step: 11
Training loss: 1.1855688095092773
Validation loss: 2.035741557677587

Epoch: 82| Step: 0
Training loss: 2.625729560852051
Validation loss: 2.0392054269711175

Epoch: 5| Step: 1
Training loss: 2.254451036453247
Validation loss: 2.0354410062233605

Epoch: 5| Step: 2
Training loss: 2.3294551372528076
Validation loss: 2.0372250328461328

Epoch: 5| Step: 3
Training loss: 2.2119293212890625
Validation loss: 2.0314343571662903

Epoch: 5| Step: 4
Training loss: 1.6972627639770508
Validation loss: 2.0299602101246514

Epoch: 5| Step: 5
Training loss: 1.5602200031280518
Validation loss: 2.0265588959058127

Epoch: 5| Step: 6
Training loss: 1.7978017330169678
Validation loss: 2.027414927879969

Epoch: 5| Step: 7
Training loss: 2.7537999153137207
Validation loss: 2.0358162224292755

Epoch: 5| Step: 8
Training loss: 2.01741099357605
Validation loss: 2.046774427096049

Epoch: 5| Step: 9
Training loss: 2.0682201385498047
Validation loss: 2.056207920114199

Epoch: 5| Step: 10
Training loss: 2.5825600624084473
Validation loss: 2.069734131296476

Epoch: 5| Step: 11
Training loss: 2.506321430206299
Validation loss: 2.065879757205645

Epoch: 83| Step: 0
Training loss: 1.928501844406128
Validation loss: 2.0776349554459252

Epoch: 5| Step: 1
Training loss: 2.354295253753662
Validation loss: 2.0624793668588004

Epoch: 5| Step: 2
Training loss: 1.899181604385376
Validation loss: 2.04462235669295

Epoch: 5| Step: 3
Training loss: 2.689849376678467
Validation loss: 2.0456770211458206

Epoch: 5| Step: 4
Training loss: 2.127843141555786
Validation loss: 2.0322572688261666

Epoch: 5| Step: 5
Training loss: 1.5260951519012451
Validation loss: 2.021208648880323

Epoch: 5| Step: 6
Training loss: 2.6362526416778564
Validation loss: 2.0280448695023856

Epoch: 5| Step: 7
Training loss: 1.9200012683868408
Validation loss: 2.0262139240900674

Epoch: 5| Step: 8
Training loss: 2.275179386138916
Validation loss: 2.0228913774092994

Epoch: 5| Step: 9
Training loss: 2.4859957695007324
Validation loss: 2.0302529285351434

Epoch: 5| Step: 10
Training loss: 2.3367369174957275
Validation loss: 2.0291873464981713

Epoch: 5| Step: 11
Training loss: 1.4822691679000854
Validation loss: 2.0298005044460297

Epoch: 84| Step: 0
Training loss: 1.800789475440979
Validation loss: 2.041848729054133

Epoch: 5| Step: 1
Training loss: 2.8174338340759277
Validation loss: 2.0409570038318634

Epoch: 5| Step: 2
Training loss: 1.391233205795288
Validation loss: 2.0600875417391458

Epoch: 5| Step: 3
Training loss: 2.607327699661255
Validation loss: 2.065036197503408

Epoch: 5| Step: 4
Training loss: 1.777004599571228
Validation loss: 2.055391326546669

Epoch: 5| Step: 5
Training loss: 2.441298723220825
Validation loss: 2.0523671309153237

Epoch: 5| Step: 6
Training loss: 2.535473346710205
Validation loss: 2.0354467084010444

Epoch: 5| Step: 7
Training loss: 2.3195719718933105
Validation loss: 2.0328241884708405

Epoch: 5| Step: 8
Training loss: 2.2989661693573
Validation loss: 2.0355778684218726

Epoch: 5| Step: 9
Training loss: 1.7916688919067383
Validation loss: 2.026632140080134

Epoch: 5| Step: 10
Training loss: 1.9521987438201904
Validation loss: 2.021127680937449

Epoch: 5| Step: 11
Training loss: 3.5712270736694336
Validation loss: 2.024056449532509

Epoch: 85| Step: 0
Training loss: 1.8915847539901733
Validation loss: 2.018769999345144

Epoch: 5| Step: 1
Training loss: 1.9716670513153076
Validation loss: 2.019474819302559

Epoch: 5| Step: 2
Training loss: 2.3499770164489746
Validation loss: 2.023876150449117

Epoch: 5| Step: 3
Training loss: 2.2874093055725098
Validation loss: 2.0274885396162667

Epoch: 5| Step: 4
Training loss: 2.5388145446777344
Validation loss: 2.0228114078442254

Epoch: 5| Step: 5
Training loss: 2.1306464672088623
Validation loss: 2.0242218176523843

Epoch: 5| Step: 6
Training loss: 1.8518164157867432
Validation loss: 2.0169660300016403

Epoch: 5| Step: 7
Training loss: 2.046272039413452
Validation loss: 2.016961485147476

Epoch: 5| Step: 8
Training loss: 1.9746071100234985
Validation loss: 2.020407314101855

Epoch: 5| Step: 9
Training loss: 2.3486883640289307
Validation loss: 2.023671805858612

Epoch: 5| Step: 10
Training loss: 2.346555233001709
Validation loss: 2.03161513308684

Epoch: 5| Step: 11
Training loss: 2.6457719802856445
Validation loss: 2.0379352072874704

Epoch: 86| Step: 0
Training loss: 1.9728797674179077
Validation loss: 2.0252990424633026

Epoch: 5| Step: 1
Training loss: 2.3462440967559814
Validation loss: 2.0245713790257773

Epoch: 5| Step: 2
Training loss: 1.7164671421051025
Validation loss: 2.019876778125763

Epoch: 5| Step: 3
Training loss: 1.9713408946990967
Validation loss: 2.02569846312205

Epoch: 5| Step: 4
Training loss: 1.7872730493545532
Validation loss: 2.028002525369326

Epoch: 5| Step: 5
Training loss: 1.9506343603134155
Validation loss: 2.0284119993448257

Epoch: 5| Step: 6
Training loss: 2.103015422821045
Validation loss: 2.0202948848406472

Epoch: 5| Step: 7
Training loss: 2.793537139892578
Validation loss: 2.021436999241511

Epoch: 5| Step: 8
Training loss: 2.340427875518799
Validation loss: 2.023406187693278

Epoch: 5| Step: 9
Training loss: 2.0645947456359863
Validation loss: 2.0223456720511117

Epoch: 5| Step: 10
Training loss: 2.812839984893799
Validation loss: 2.019870842496554

Epoch: 5| Step: 11
Training loss: 2.7839245796203613
Validation loss: 2.038896550734838

Epoch: 87| Step: 0
Training loss: 2.5729713439941406
Validation loss: 2.025200476249059

Epoch: 5| Step: 1
Training loss: 2.0825085639953613
Validation loss: 2.027399629354477

Epoch: 5| Step: 2
Training loss: 2.242337703704834
Validation loss: 2.0237527787685394

Epoch: 5| Step: 3
Training loss: 2.195385456085205
Validation loss: 2.0336418946584067

Epoch: 5| Step: 4
Training loss: 2.1542866230010986
Validation loss: 2.035469427704811

Epoch: 5| Step: 5
Training loss: 1.693177580833435
Validation loss: 2.034137840072314

Epoch: 5| Step: 6
Training loss: 2.847158908843994
Validation loss: 2.0355852444966636

Epoch: 5| Step: 7
Training loss: 1.996232271194458
Validation loss: 2.032446543375651

Epoch: 5| Step: 8
Training loss: 2.633286952972412
Validation loss: 2.0300030956665673

Epoch: 5| Step: 9
Training loss: 1.9628251791000366
Validation loss: 2.036036491394043

Epoch: 5| Step: 10
Training loss: 1.8820359706878662
Validation loss: 2.030197560787201

Epoch: 5| Step: 11
Training loss: 1.538315773010254
Validation loss: 2.0350722670555115

Epoch: 88| Step: 0
Training loss: 1.6798598766326904
Validation loss: 2.024826258420944

Epoch: 5| Step: 1
Training loss: 1.749060869216919
Validation loss: 2.028985917568207

Epoch: 5| Step: 2
Training loss: 2.383953332901001
Validation loss: 2.0225770175457

Epoch: 5| Step: 3
Training loss: 2.3105781078338623
Validation loss: 2.032289355993271

Epoch: 5| Step: 4
Training loss: 2.8825013637542725
Validation loss: 2.031223565340042

Epoch: 5| Step: 5
Training loss: 2.60353946685791
Validation loss: 2.035620133082072

Epoch: 5| Step: 6
Training loss: 2.139345169067383
Validation loss: 2.035415311654409

Epoch: 5| Step: 7
Training loss: 2.7173140048980713
Validation loss: 2.0402338157097497

Epoch: 5| Step: 8
Training loss: 1.806269884109497
Validation loss: 2.0535472879807153

Epoch: 5| Step: 9
Training loss: 1.8910789489746094
Validation loss: 2.0528343319892883

Epoch: 5| Step: 10
Training loss: 1.8954318761825562
Validation loss: 2.0524925788243613

Epoch: 5| Step: 11
Training loss: 1.9189035892486572
Validation loss: 2.040537014603615

Epoch: 89| Step: 0
Training loss: 1.672797441482544
Validation loss: 2.0408403972784677

Epoch: 5| Step: 1
Training loss: 2.2490766048431396
Validation loss: 2.036279837290446

Epoch: 5| Step: 2
Training loss: 2.553361177444458
Validation loss: 2.0205161472161612

Epoch: 5| Step: 3
Training loss: 2.0040032863616943
Validation loss: 2.0177211463451385

Epoch: 5| Step: 4
Training loss: 3.041541814804077
Validation loss: 2.0222648680210114

Epoch: 5| Step: 5
Training loss: 1.9445663690567017
Validation loss: 2.0257843832174935

Epoch: 5| Step: 6
Training loss: 2.077157497406006
Validation loss: 2.031991814573606

Epoch: 5| Step: 7
Training loss: 1.9960120916366577
Validation loss: 2.027672534187635

Epoch: 5| Step: 8
Training loss: 2.58970308303833
Validation loss: 2.025459269682566

Epoch: 5| Step: 9
Training loss: 2.1661696434020996
Validation loss: 2.020813763141632

Epoch: 5| Step: 10
Training loss: 1.7386747598648071
Validation loss: 2.0201250662406287

Epoch: 5| Step: 11
Training loss: 1.650380253791809
Validation loss: 2.0125994036595025

Epoch: 90| Step: 0
Training loss: 2.179306745529175
Validation loss: 2.0211093028386435

Epoch: 5| Step: 1
Training loss: 2.049294948577881
Validation loss: 2.030913015206655

Epoch: 5| Step: 2
Training loss: 1.9617681503295898
Validation loss: 2.0331861029068627

Epoch: 5| Step: 3
Training loss: 2.1105599403381348
Validation loss: 2.0326616962750754

Epoch: 5| Step: 4
Training loss: 2.098656415939331
Validation loss: 2.0399630814790726

Epoch: 5| Step: 5
Training loss: 2.276062488555908
Validation loss: 2.0319146613279977

Epoch: 5| Step: 6
Training loss: 2.6925852298736572
Validation loss: 2.032659391562144

Epoch: 5| Step: 7
Training loss: 2.3763973712921143
Validation loss: 2.037105515599251

Epoch: 5| Step: 8
Training loss: 1.6635379791259766
Validation loss: 2.032990356286367

Epoch: 5| Step: 9
Training loss: 2.386936902999878
Validation loss: 2.0356756101051965

Epoch: 5| Step: 10
Training loss: 1.8937180042266846
Validation loss: 2.0348101407289505

Epoch: 5| Step: 11
Training loss: 2.8484528064727783
Validation loss: 2.0290065507094064

Epoch: 91| Step: 0
Training loss: 2.031191349029541
Validation loss: 2.031585231423378

Epoch: 5| Step: 1
Training loss: 2.069988965988159
Validation loss: 2.031379386782646

Epoch: 5| Step: 2
Training loss: 1.762648344039917
Validation loss: 2.0305900474389396

Epoch: 5| Step: 3
Training loss: 1.6399977207183838
Validation loss: 2.0301615645488105

Epoch: 5| Step: 4
Training loss: 2.256091594696045
Validation loss: 2.029730205734571

Epoch: 5| Step: 5
Training loss: 2.178673028945923
Validation loss: 2.026729722817739

Epoch: 5| Step: 6
Training loss: 2.619431734085083
Validation loss: 2.0339222103357315

Epoch: 5| Step: 7
Training loss: 2.5198311805725098
Validation loss: 2.030408392349879

Epoch: 5| Step: 8
Training loss: 2.3264613151550293
Validation loss: 2.0354506224393845

Epoch: 5| Step: 9
Training loss: 2.1660614013671875
Validation loss: 2.030803327759107

Epoch: 5| Step: 10
Training loss: 2.0069003105163574
Validation loss: 2.0272995779911676

Epoch: 5| Step: 11
Training loss: 2.495215892791748
Validation loss: 2.0303901632626853

Epoch: 92| Step: 0
Training loss: 2.0221500396728516
Validation loss: 2.0275611678759256

Epoch: 5| Step: 1
Training loss: 2.534821033477783
Validation loss: 2.0251518934965134

Epoch: 5| Step: 2
Training loss: 1.9842582941055298
Validation loss: 2.0256016304095588

Epoch: 5| Step: 3
Training loss: 2.760085344314575
Validation loss: 2.012711986899376

Epoch: 5| Step: 4
Training loss: 2.0106420516967773
Validation loss: 2.012668266892433

Epoch: 5| Step: 5
Training loss: 2.034944772720337
Validation loss: 2.0119584600130715

Epoch: 5| Step: 6
Training loss: 2.087646007537842
Validation loss: 2.012899160385132

Epoch: 5| Step: 7
Training loss: 1.8035541772842407
Validation loss: 2.0218099703391395

Epoch: 5| Step: 8
Training loss: 2.0065722465515137
Validation loss: 2.0277793407440186

Epoch: 5| Step: 9
Training loss: 2.2162601947784424
Validation loss: 2.031841213504473

Epoch: 5| Step: 10
Training loss: 2.445263624191284
Validation loss: 2.0301536868015924

Epoch: 5| Step: 11
Training loss: 1.56770920753479
Validation loss: 2.034063547849655

Epoch: 93| Step: 0
Training loss: 2.2543017864227295
Validation loss: 2.0402351319789886

Epoch: 5| Step: 1
Training loss: 1.9391345977783203
Validation loss: 2.0500856588284173

Epoch: 5| Step: 2
Training loss: 2.671546220779419
Validation loss: 2.0559020191431046

Epoch: 5| Step: 3
Training loss: 1.5495202541351318
Validation loss: 2.0650870303312936

Epoch: 5| Step: 4
Training loss: 2.1787612438201904
Validation loss: 2.060676490267118

Epoch: 5| Step: 5
Training loss: 2.7438533306121826
Validation loss: 2.062691162029902

Epoch: 5| Step: 6
Training loss: 2.720979690551758
Validation loss: 2.0582274248202643

Epoch: 5| Step: 7
Training loss: 2.300900936126709
Validation loss: 2.0416809568802514

Epoch: 5| Step: 8
Training loss: 2.0798840522766113
Validation loss: 2.0372390697399774

Epoch: 5| Step: 9
Training loss: 1.9811420440673828
Validation loss: 2.0208843300739923

Epoch: 5| Step: 10
Training loss: 1.612682580947876
Validation loss: 2.0167007595300674

Epoch: 5| Step: 11
Training loss: 1.9621872901916504
Validation loss: 2.0073876778284707

Epoch: 94| Step: 0
Training loss: 2.921250820159912
Validation loss: 2.016844237844149

Epoch: 5| Step: 1
Training loss: 2.3216941356658936
Validation loss: 2.02516500155131

Epoch: 5| Step: 2
Training loss: 1.5113513469696045
Validation loss: 2.0270982136329017

Epoch: 5| Step: 3
Training loss: 2.25627064704895
Validation loss: 2.034304589033127

Epoch: 5| Step: 4
Training loss: 2.5345377922058105
Validation loss: 2.0351566721995673

Epoch: 5| Step: 5
Training loss: 2.11773419380188
Validation loss: 2.0317837794621787

Epoch: 5| Step: 6
Training loss: 2.2142152786254883
Validation loss: 2.031066050132116

Epoch: 5| Step: 7
Training loss: 1.7811987400054932
Validation loss: 2.0377783526976905

Epoch: 5| Step: 8
Training loss: 2.2191624641418457
Validation loss: 2.0240378777186074

Epoch: 5| Step: 9
Training loss: 2.2993085384368896
Validation loss: 2.0256577332814536

Epoch: 5| Step: 10
Training loss: 2.122429609298706
Validation loss: 2.0213859428962073

Epoch: 5| Step: 11
Training loss: 0.5400164723396301
Validation loss: 2.019766479730606

Epoch: 95| Step: 0
Training loss: 2.267631769180298
Validation loss: 2.0146430085102716

Epoch: 5| Step: 1
Training loss: 1.8699535131454468
Validation loss: 2.015155871709188

Epoch: 5| Step: 2
Training loss: 2.287440538406372
Validation loss: 2.0181872993707657

Epoch: 5| Step: 3
Training loss: 2.024477243423462
Validation loss: 2.023209109902382

Epoch: 5| Step: 4
Training loss: 2.29606294631958
Validation loss: 2.0211064467827478

Epoch: 5| Step: 5
Training loss: 2.869093179702759
Validation loss: 2.0240369538466134

Epoch: 5| Step: 6
Training loss: 1.865380883216858
Validation loss: 2.023170674840609

Epoch: 5| Step: 7
Training loss: 2.177833080291748
Validation loss: 2.0276286602020264

Epoch: 5| Step: 8
Training loss: 1.609771490097046
Validation loss: 2.0252335717280707

Epoch: 5| Step: 9
Training loss: 1.8166042566299438
Validation loss: 2.024298995733261

Epoch: 5| Step: 10
Training loss: 2.491386651992798
Validation loss: 2.0457614809274673

Epoch: 5| Step: 11
Training loss: 2.820054531097412
Validation loss: 2.0449094474315643

Epoch: 96| Step: 0
Training loss: 1.8265800476074219
Validation loss: 2.0579261581103006

Epoch: 5| Step: 1
Training loss: 2.41379976272583
Validation loss: 2.0551965087652206

Epoch: 5| Step: 2
Training loss: 2.1173081398010254
Validation loss: 2.0760724594195685

Epoch: 5| Step: 3
Training loss: 1.845730185508728
Validation loss: 2.0593099147081375

Epoch: 5| Step: 4
Training loss: 2.513467788696289
Validation loss: 2.053060462077459

Epoch: 5| Step: 5
Training loss: 2.323580265045166
Validation loss: 2.0491406122843423

Epoch: 5| Step: 6
Training loss: 2.0450685024261475
Validation loss: 2.046831722060839

Epoch: 5| Step: 7
Training loss: 2.1794028282165527
Validation loss: 2.0445109804471335

Epoch: 5| Step: 8
Training loss: 2.112513780593872
Validation loss: 2.053273096680641

Epoch: 5| Step: 9
Training loss: 2.182502269744873
Validation loss: 2.0320971608161926

Epoch: 5| Step: 10
Training loss: 2.2351906299591064
Validation loss: 2.03029203414917

Epoch: 5| Step: 11
Training loss: 2.604672908782959
Validation loss: 2.0312475015719733

Epoch: 97| Step: 0
Training loss: 2.1656570434570312
Validation loss: 2.034419904152552

Epoch: 5| Step: 1
Training loss: 2.319037914276123
Validation loss: 2.032215361793836

Epoch: 5| Step: 2
Training loss: 2.1643478870391846
Validation loss: 2.019875004887581

Epoch: 5| Step: 3
Training loss: 1.9186979532241821
Validation loss: 2.0299130380153656

Epoch: 5| Step: 4
Training loss: 2.638607978820801
Validation loss: 2.025255799293518

Epoch: 5| Step: 5
Training loss: 1.6207956075668335
Validation loss: 2.029995083808899

Epoch: 5| Step: 6
Training loss: 1.9451825618743896
Validation loss: 2.02016274134318

Epoch: 5| Step: 7
Training loss: 2.285504102706909
Validation loss: 2.016344726085663

Epoch: 5| Step: 8
Training loss: 2.1415867805480957
Validation loss: 2.0161947309970856

Epoch: 5| Step: 9
Training loss: 2.514176368713379
Validation loss: 2.0220037549734116

Epoch: 5| Step: 10
Training loss: 2.0987277030944824
Validation loss: 2.015759746233622

Epoch: 5| Step: 11
Training loss: 1.5752367973327637
Validation loss: 2.0185391505559287

Epoch: 98| Step: 0
Training loss: 2.1565165519714355
Validation loss: 2.033032859365145

Epoch: 5| Step: 1
Training loss: 2.3684892654418945
Validation loss: 2.03921673198541

Epoch: 5| Step: 2
Training loss: 1.8448671102523804
Validation loss: 2.0522926251093545

Epoch: 5| Step: 3
Training loss: 2.2217650413513184
Validation loss: 2.0583999951680503

Epoch: 5| Step: 4
Training loss: 2.3852734565734863
Validation loss: 2.0583937913179398

Epoch: 5| Step: 5
Training loss: 2.432926654815674
Validation loss: 2.059283326069514

Epoch: 5| Step: 6
Training loss: 1.6165635585784912
Validation loss: 2.06684743364652

Epoch: 5| Step: 7
Training loss: 2.1544528007507324
Validation loss: 2.0676175951957703

Epoch: 5| Step: 8
Training loss: 2.2422118186950684
Validation loss: 2.0519688924153647

Epoch: 5| Step: 9
Training loss: 1.7815414667129517
Validation loss: 2.057454233368238

Epoch: 5| Step: 10
Training loss: 2.1393773555755615
Validation loss: 2.0383816957473755

Epoch: 5| Step: 11
Training loss: 3.904696226119995
Validation loss: 2.036999300122261

Epoch: 99| Step: 0
Training loss: 2.323028802871704
Validation loss: 2.027705272038778

Epoch: 5| Step: 1
Training loss: 1.4722955226898193
Validation loss: 2.0299815237522125

Epoch: 5| Step: 2
Training loss: 2.3035695552825928
Validation loss: 2.0298599352439246

Epoch: 5| Step: 3
Training loss: 2.853663682937622
Validation loss: 2.033435419201851

Epoch: 5| Step: 4
Training loss: 2.2290451526641846
Validation loss: 2.0351062615712485

Epoch: 5| Step: 5
Training loss: 2.2888662815093994
Validation loss: 2.0353757739067078

Epoch: 5| Step: 6
Training loss: 2.1611874103546143
Validation loss: 2.023741508523623

Epoch: 5| Step: 7
Training loss: 1.3353155851364136
Validation loss: 2.0257150381803513

Epoch: 5| Step: 8
Training loss: 2.6250338554382324
Validation loss: 2.0241392155488334

Epoch: 5| Step: 9
Training loss: 2.1017136573791504
Validation loss: 2.022260904312134

Epoch: 5| Step: 10
Training loss: 2.177788496017456
Validation loss: 2.017088010907173

Epoch: 5| Step: 11
Training loss: 2.0355632305145264
Validation loss: 2.0178904881079993

Epoch: 100| Step: 0
Training loss: 2.3220760822296143
Validation loss: 2.0099021742741265

Epoch: 5| Step: 1
Training loss: 2.14306902885437
Validation loss: 2.005815635124842

Epoch: 5| Step: 2
Training loss: 2.559074640274048
Validation loss: 2.0146798292795816

Epoch: 5| Step: 3
Training loss: 2.6941118240356445
Validation loss: 2.0173781166474023

Epoch: 5| Step: 4
Training loss: 2.3198962211608887
Validation loss: 2.0233127723137536

Epoch: 5| Step: 5
Training loss: 1.288570523262024
Validation loss: 2.024987449248632

Epoch: 5| Step: 6
Training loss: 2.385324001312256
Validation loss: 2.0311436355113983

Epoch: 5| Step: 7
Training loss: 2.5121922492980957
Validation loss: 2.0396071722110114

Epoch: 5| Step: 8
Training loss: 1.923142433166504
Validation loss: 2.031708210706711

Epoch: 5| Step: 9
Training loss: 1.7935359477996826
Validation loss: 2.0429086784521737

Epoch: 5| Step: 10
Training loss: 1.9266185760498047
Validation loss: 2.036574920018514

Epoch: 5| Step: 11
Training loss: 1.6350815296173096
Validation loss: 2.0427776177724204

Epoch: 101| Step: 0
Training loss: 1.8232600688934326
Validation loss: 2.0292712350686393

Epoch: 5| Step: 1
Training loss: 1.7562859058380127
Validation loss: 2.026689201593399

Epoch: 5| Step: 2
Training loss: 1.9325147867202759
Validation loss: 2.023226117094358

Epoch: 5| Step: 3
Training loss: 2.7888636589050293
Validation loss: 2.0168515543142953

Epoch: 5| Step: 4
Training loss: 2.058948040008545
Validation loss: 2.0137922912836075

Epoch: 5| Step: 5
Training loss: 2.3972008228302
Validation loss: 2.0080364098151526

Epoch: 5| Step: 6
Training loss: 1.6096864938735962
Validation loss: 2.0125410159428916

Epoch: 5| Step: 7
Training loss: 1.9741733074188232
Validation loss: 2.0202158043781915

Epoch: 5| Step: 8
Training loss: 2.8462440967559814
Validation loss: 2.0237664580345154

Epoch: 5| Step: 9
Training loss: 2.1448521614074707
Validation loss: 2.012271319826444

Epoch: 5| Step: 10
Training loss: 2.120251178741455
Validation loss: 2.019734005133311

Epoch: 5| Step: 11
Training loss: 2.2502236366271973
Validation loss: 2.0122985343138375

Epoch: 102| Step: 0
Training loss: 2.259835720062256
Validation loss: 2.016198053956032

Epoch: 5| Step: 1
Training loss: 2.0560708045959473
Validation loss: 2.0274527271588645

Epoch: 5| Step: 2
Training loss: 2.2545430660247803
Validation loss: 2.022597764929136

Epoch: 5| Step: 3
Training loss: 2.587986469268799
Validation loss: 2.02085609237353

Epoch: 5| Step: 4
Training loss: 1.824390172958374
Validation loss: 2.015325258175532

Epoch: 5| Step: 5
Training loss: 2.051975727081299
Validation loss: 2.014998431007067

Epoch: 5| Step: 6
Training loss: 1.9622665643692017
Validation loss: 2.020514448483785

Epoch: 5| Step: 7
Training loss: 2.1900336742401123
Validation loss: 2.0289011845986047

Epoch: 5| Step: 8
Training loss: 1.6886272430419922
Validation loss: 2.031130467851957

Epoch: 5| Step: 9
Training loss: 2.4083170890808105
Validation loss: 2.0197877486546836

Epoch: 5| Step: 10
Training loss: 2.511765956878662
Validation loss: 2.0140869667132697

Epoch: 5| Step: 11
Training loss: 0.48933613300323486
Validation loss: 2.0263776183128357

Epoch: 103| Step: 0
Training loss: 2.5802159309387207
Validation loss: 2.018545309702555

Epoch: 5| Step: 1
Training loss: 2.2578957080841064
Validation loss: 2.0144532521565757

Epoch: 5| Step: 2
Training loss: 1.8966217041015625
Validation loss: 2.0100060800711312

Epoch: 5| Step: 3
Training loss: 2.2617850303649902
Validation loss: 2.007153868675232

Epoch: 5| Step: 4
Training loss: 2.1215476989746094
Validation loss: 2.0080838849147162

Epoch: 5| Step: 5
Training loss: 2.2423787117004395
Validation loss: 2.0077203859885535

Epoch: 5| Step: 6
Training loss: 1.9583752155303955
Validation loss: 2.009742170572281

Epoch: 5| Step: 7
Training loss: 1.8005506992340088
Validation loss: 2.0069127281506858

Epoch: 5| Step: 8
Training loss: 2.3802692890167236
Validation loss: 2.0157661785682044

Epoch: 5| Step: 9
Training loss: 2.072416305541992
Validation loss: 2.018850420912107

Epoch: 5| Step: 10
Training loss: 2.334365129470825
Validation loss: 2.029550085465113

Epoch: 5| Step: 11
Training loss: 0.2653213143348694
Validation loss: 2.0303940176963806

Epoch: 104| Step: 0
Training loss: 2.309774398803711
Validation loss: 2.031415566802025

Epoch: 5| Step: 1
Training loss: 1.897698998451233
Validation loss: 2.0533234973748526

Epoch: 5| Step: 2
Training loss: 1.8723005056381226
Validation loss: 2.0558473418156304

Epoch: 5| Step: 3
Training loss: 2.319139003753662
Validation loss: 2.062439054250717

Epoch: 5| Step: 4
Training loss: 2.1956686973571777
Validation loss: 2.075661281744639

Epoch: 5| Step: 5
Training loss: 2.657203435897827
Validation loss: 2.0640430549780526

Epoch: 5| Step: 6
Training loss: 1.932498574256897
Validation loss: 2.0461135605971017

Epoch: 5| Step: 7
Training loss: 1.809486746788025
Validation loss: 2.0283086647590003

Epoch: 5| Step: 8
Training loss: 2.1532769203186035
Validation loss: 2.0299716542164483

Epoch: 5| Step: 9
Training loss: 2.26615571975708
Validation loss: 2.0091245472431183

Epoch: 5| Step: 10
Training loss: 2.10982084274292
Validation loss: 2.0062581350406012

Epoch: 5| Step: 11
Training loss: 3.3361682891845703
Validation loss: 1.9987404594818752

Epoch: 105| Step: 0
Training loss: 2.411618709564209
Validation loss: 2.0045509288708367

Epoch: 5| Step: 1
Training loss: 1.9661394357681274
Validation loss: 2.012854670484861

Epoch: 5| Step: 2
Training loss: 2.3418750762939453
Validation loss: 2.0194255858659744

Epoch: 5| Step: 3
Training loss: 2.215503215789795
Validation loss: 2.022382845481237

Epoch: 5| Step: 4
Training loss: 2.6285343170166016
Validation loss: 2.026040534178416

Epoch: 5| Step: 5
Training loss: 2.2922465801239014
Validation loss: 2.022146781285604

Epoch: 5| Step: 6
Training loss: 1.6382461786270142
Validation loss: 2.024397984147072

Epoch: 5| Step: 7
Training loss: 2.103605031967163
Validation loss: 2.020179346203804

Epoch: 5| Step: 8
Training loss: 1.9755347967147827
Validation loss: 2.0225309977928796

Epoch: 5| Step: 9
Training loss: 2.002452850341797
Validation loss: 2.0139401157697043

Epoch: 5| Step: 10
Training loss: 2.170271396636963
Validation loss: 2.0144328574339547

Epoch: 5| Step: 11
Training loss: 2.796915054321289
Validation loss: 2.014480118950208

Epoch: 106| Step: 0
Training loss: 1.8067420721054077
Validation loss: 2.0073891431093216

Epoch: 5| Step: 1
Training loss: 2.1293704509735107
Validation loss: 2.000167985757192

Epoch: 5| Step: 2
Training loss: 1.8933734893798828
Validation loss: 2.0143564343452454

Epoch: 5| Step: 3
Training loss: 2.187605619430542
Validation loss: 2.0136531740427017

Epoch: 5| Step: 4
Training loss: 2.381155490875244
Validation loss: 2.0230862448612847

Epoch: 5| Step: 5
Training loss: 1.8805310726165771
Validation loss: 2.0370532472928367

Epoch: 5| Step: 6
Training loss: 2.4248170852661133
Validation loss: 2.0326715807120004

Epoch: 5| Step: 7
Training loss: 2.4277920722961426
Validation loss: 2.041772852341334

Epoch: 5| Step: 8
Training loss: 2.1364493370056152
Validation loss: 2.046529774864515

Epoch: 5| Step: 9
Training loss: 2.6569650173187256
Validation loss: 2.045148948828379

Epoch: 5| Step: 10
Training loss: 1.805445909500122
Validation loss: 2.035988360643387

Epoch: 5| Step: 11
Training loss: 1.1262176036834717
Validation loss: 2.0357663283745446

Epoch: 107| Step: 0
Training loss: 2.402902364730835
Validation loss: 2.049149125814438

Epoch: 5| Step: 1
Training loss: 2.4420840740203857
Validation loss: 2.0391276627779007

Epoch: 5| Step: 2
Training loss: 1.925264596939087
Validation loss: 2.035419831673304

Epoch: 5| Step: 3
Training loss: 2.3755009174346924
Validation loss: 2.0421152164538703

Epoch: 5| Step: 4
Training loss: 2.2832694053649902
Validation loss: 2.0288462241490683

Epoch: 5| Step: 5
Training loss: 2.8330070972442627
Validation loss: 2.0211045841375985

Epoch: 5| Step: 6
Training loss: 1.4581295251846313
Validation loss: 2.0183613946040473

Epoch: 5| Step: 7
Training loss: 1.8715617656707764
Validation loss: 2.0161995937426886

Epoch: 5| Step: 8
Training loss: 2.2438881397247314
Validation loss: 2.0084131310383477

Epoch: 5| Step: 9
Training loss: 2.0400161743164062
Validation loss: 2.020760804414749

Epoch: 5| Step: 10
Training loss: 1.5708568096160889
Validation loss: 2.007442499200503

Epoch: 5| Step: 11
Training loss: 2.7004899978637695
Validation loss: 2.0161900222301483

Epoch: 108| Step: 0
Training loss: 2.230498790740967
Validation loss: 2.0118454645077386

Epoch: 5| Step: 1
Training loss: 1.7241865396499634
Validation loss: 2.0043763319651284

Epoch: 5| Step: 2
Training loss: 2.2176294326782227
Validation loss: 2.0046934386094413

Epoch: 5| Step: 3
Training loss: 2.8938395977020264
Validation loss: 2.0051615287860236

Epoch: 5| Step: 4
Training loss: 1.7926527261734009
Validation loss: 1.9995339612166088

Epoch: 5| Step: 5
Training loss: 2.314500331878662
Validation loss: 1.999054655432701

Epoch: 5| Step: 6
Training loss: 2.2231106758117676
Validation loss: 2.0031204471985498

Epoch: 5| Step: 7
Training loss: 2.1827855110168457
Validation loss: 2.0057464241981506

Epoch: 5| Step: 8
Training loss: 2.5942318439483643
Validation loss: 2.0147980650266013

Epoch: 5| Step: 9
Training loss: 1.5853335857391357
Validation loss: 2.0178619076808295

Epoch: 5| Step: 10
Training loss: 1.6163966655731201
Validation loss: 2.0173315157492957

Epoch: 5| Step: 11
Training loss: 2.293700695037842
Validation loss: 2.030939519405365

Epoch: 109| Step: 0
Training loss: 2.0499565601348877
Validation loss: 2.0486258616050086

Epoch: 5| Step: 1
Training loss: 2.7790205478668213
Validation loss: 2.051334396004677

Epoch: 5| Step: 2
Training loss: 2.0304384231567383
Validation loss: 2.037504384915034

Epoch: 5| Step: 3
Training loss: 1.9994609355926514
Validation loss: 2.0387246211369834

Epoch: 5| Step: 4
Training loss: 1.9653511047363281
Validation loss: 2.0306469003359475

Epoch: 5| Step: 5
Training loss: 1.9946520328521729
Validation loss: 2.028219888607661

Epoch: 5| Step: 6
Training loss: 1.619635820388794
Validation loss: 2.0159812271595

Epoch: 5| Step: 7
Training loss: 2.194923162460327
Validation loss: 2.015725697080294

Epoch: 5| Step: 8
Training loss: 2.4286231994628906
Validation loss: 2.0053108781576157

Epoch: 5| Step: 9
Training loss: 1.6851593255996704
Validation loss: 2.0036696741978326

Epoch: 5| Step: 10
Training loss: 2.8898651599884033
Validation loss: 1.9989156027634938

Epoch: 5| Step: 11
Training loss: 2.1977219581604004
Validation loss: 2.0014262894789376

Epoch: 110| Step: 0
Training loss: 2.0891880989074707
Validation loss: 2.001834104458491

Epoch: 5| Step: 1
Training loss: 2.2138404846191406
Validation loss: 2.0036585330963135

Epoch: 5| Step: 2
Training loss: 1.5945477485656738
Validation loss: 2.003594323992729

Epoch: 5| Step: 3
Training loss: 2.253685712814331
Validation loss: 2.0048742244640985

Epoch: 5| Step: 4
Training loss: 2.0307741165161133
Validation loss: 2.0110174963871636

Epoch: 5| Step: 5
Training loss: 2.4871318340301514
Validation loss: 2.0094080020984015

Epoch: 5| Step: 6
Training loss: 2.1382365226745605
Validation loss: 2.0088436851898828

Epoch: 5| Step: 7
Training loss: 1.9524948596954346
Validation loss: 2.0073843797047934

Epoch: 5| Step: 8
Training loss: 2.260831356048584
Validation loss: 2.018047973513603

Epoch: 5| Step: 9
Training loss: 2.344745635986328
Validation loss: 2.023640990257263

Epoch: 5| Step: 10
Training loss: 1.9973434209823608
Validation loss: 2.0230148881673813

Epoch: 5| Step: 11
Training loss: 1.7079997062683105
Validation loss: 2.019039506713549

Epoch: 111| Step: 0
Training loss: 2.016148805618286
Validation loss: 2.0329005271196365

Epoch: 5| Step: 1
Training loss: 2.043992519378662
Validation loss: 2.0435253034035363

Epoch: 5| Step: 2
Training loss: 2.4913268089294434
Validation loss: 2.041818141937256

Epoch: 5| Step: 3
Training loss: 1.8792203664779663
Validation loss: 2.02575147151947

Epoch: 5| Step: 4
Training loss: 2.2026093006134033
Validation loss: 2.032395968834559

Epoch: 5| Step: 5
Training loss: 2.1740450859069824
Validation loss: 2.0224680652221045

Epoch: 5| Step: 6
Training loss: 2.1528117656707764
Validation loss: 2.0130849877993264

Epoch: 5| Step: 7
Training loss: 2.2359817028045654
Validation loss: 2.0206816097100577

Epoch: 5| Step: 8
Training loss: 2.5242063999176025
Validation loss: 2.013494019707044

Epoch: 5| Step: 9
Training loss: 1.8168811798095703
Validation loss: 2.014034887154897

Epoch: 5| Step: 10
Training loss: 1.7890613079071045
Validation loss: 2.0075473686059317

Epoch: 5| Step: 11
Training loss: 2.714862823486328
Validation loss: 2.0036433239777884

Epoch: 112| Step: 0
Training loss: 2.6039910316467285
Validation loss: 2.0076365719238916

Epoch: 5| Step: 1
Training loss: 1.6131324768066406
Validation loss: 2.009812186161677

Epoch: 5| Step: 2
Training loss: 2.4576046466827393
Validation loss: 2.0042692124843597

Epoch: 5| Step: 3
Training loss: 1.9645153284072876
Validation loss: 2.0035656889279685

Epoch: 5| Step: 4
Training loss: 1.422930359840393
Validation loss: 2.008913114666939

Epoch: 5| Step: 5
Training loss: 2.273704767227173
Validation loss: 2.002645472685496

Epoch: 5| Step: 6
Training loss: 1.896256685256958
Validation loss: 2.008589113752047

Epoch: 5| Step: 7
Training loss: 2.3269851207733154
Validation loss: 2.0085693697134652

Epoch: 5| Step: 8
Training loss: 2.3821139335632324
Validation loss: 2.013022576769193

Epoch: 5| Step: 9
Training loss: 2.5616931915283203
Validation loss: 2.0150113304456077

Epoch: 5| Step: 10
Training loss: 1.8571193218231201
Validation loss: 2.015332907438278

Epoch: 5| Step: 11
Training loss: 2.005429983139038
Validation loss: 2.026687199870745

Epoch: 113| Step: 0
Training loss: 1.9698575735092163
Validation loss: 2.0410691648721695

Epoch: 5| Step: 1
Training loss: 1.9111427068710327
Validation loss: 2.0229075451691947

Epoch: 5| Step: 2
Training loss: 1.983687162399292
Validation loss: 2.0331384986639023

Epoch: 5| Step: 3
Training loss: 2.9636600017547607
Validation loss: 2.0352078626553216

Epoch: 5| Step: 4
Training loss: 1.639575719833374
Validation loss: 2.022610306739807

Epoch: 5| Step: 5
Training loss: 2.297542095184326
Validation loss: 2.032197838028272

Epoch: 5| Step: 6
Training loss: 2.324928045272827
Validation loss: 2.033396398027738

Epoch: 5| Step: 7
Training loss: 2.1543874740600586
Validation loss: 2.0211533854405084

Epoch: 5| Step: 8
Training loss: 2.2266058921813965
Validation loss: 2.0157073636849723

Epoch: 5| Step: 9
Training loss: 1.9415696859359741
Validation loss: 2.0226268271605172

Epoch: 5| Step: 10
Training loss: 1.9181194305419922
Validation loss: 2.0175197571516037

Epoch: 5| Step: 11
Training loss: 1.4374417066574097
Validation loss: 2.012789155046145

Epoch: 114| Step: 0
Training loss: 2.005657434463501
Validation loss: 2.0145198702812195

Epoch: 5| Step: 1
Training loss: 2.204380750656128
Validation loss: 2.016659234960874

Epoch: 5| Step: 2
Training loss: 2.3200936317443848
Validation loss: 2.018073613444964

Epoch: 5| Step: 3
Training loss: 2.39135479927063
Validation loss: 2.0210935374101004

Epoch: 5| Step: 4
Training loss: 1.7321813106536865
Validation loss: 2.019647538661957

Epoch: 5| Step: 5
Training loss: 2.448054075241089
Validation loss: 2.017916197578112

Epoch: 5| Step: 6
Training loss: 2.370621919631958
Validation loss: 2.023201748728752

Epoch: 5| Step: 7
Training loss: 1.6970770359039307
Validation loss: 2.0254071255524955

Epoch: 5| Step: 8
Training loss: 2.056278705596924
Validation loss: 2.025851065913836

Epoch: 5| Step: 9
Training loss: 1.9000040292739868
Validation loss: 2.0197756042083106

Epoch: 5| Step: 10
Training loss: 2.172427177429199
Validation loss: 2.025936876734098

Epoch: 5| Step: 11
Training loss: 1.2661672830581665
Validation loss: 2.028050715724627

Epoch: 115| Step: 0
Training loss: 2.04622220993042
Validation loss: 2.0437911550203958

Epoch: 5| Step: 1
Training loss: 2.1819350719451904
Validation loss: 2.038991019129753

Epoch: 5| Step: 2
Training loss: 2.442660331726074
Validation loss: 2.039276381333669

Epoch: 5| Step: 3
Training loss: 1.6654157638549805
Validation loss: 2.0441237092018127

Epoch: 5| Step: 4
Training loss: 2.1202175617218018
Validation loss: 2.045963724454244

Epoch: 5| Step: 5
Training loss: 1.7780405282974243
Validation loss: 2.030248781045278

Epoch: 5| Step: 6
Training loss: 2.213040828704834
Validation loss: 2.024660880366961

Epoch: 5| Step: 7
Training loss: 1.9121967554092407
Validation loss: 2.018612747391065

Epoch: 5| Step: 8
Training loss: 2.5080552101135254
Validation loss: 2.022683084011078

Epoch: 5| Step: 9
Training loss: 2.6145975589752197
Validation loss: 2.024316738049189

Epoch: 5| Step: 10
Training loss: 1.965772271156311
Validation loss: 2.018622875213623

Epoch: 5| Step: 11
Training loss: 1.9405889511108398
Validation loss: 2.016098494331042

Epoch: 116| Step: 0
Training loss: 1.9737962484359741
Validation loss: 2.014735902349154

Epoch: 5| Step: 1
Training loss: 2.6316986083984375
Validation loss: 2.014523615439733

Epoch: 5| Step: 2
Training loss: 2.1910576820373535
Validation loss: 2.0088027020295462

Epoch: 5| Step: 3
Training loss: 2.2860469818115234
Validation loss: 2.0130286713441214

Epoch: 5| Step: 4
Training loss: 1.8828296661376953
Validation loss: 2.0105693141619363

Epoch: 5| Step: 5
Training loss: 2.4163613319396973
Validation loss: 2.0250063687562943

Epoch: 5| Step: 6
Training loss: 1.5496633052825928
Validation loss: 2.014381527900696

Epoch: 5| Step: 7
Training loss: 2.1412549018859863
Validation loss: 2.0266129225492477

Epoch: 5| Step: 8
Training loss: 1.9310333728790283
Validation loss: 2.0221685022115707

Epoch: 5| Step: 9
Training loss: 2.0566954612731934
Validation loss: 2.024564266204834

Epoch: 5| Step: 10
Training loss: 2.1054940223693848
Validation loss: 2.0306590497493744

Epoch: 5| Step: 11
Training loss: 2.1309359073638916
Validation loss: 2.0405811617771783

Epoch: 117| Step: 0
Training loss: 2.192896842956543
Validation loss: 2.040132001042366

Epoch: 5| Step: 1
Training loss: 2.05857515335083
Validation loss: 2.0665751794974008

Epoch: 5| Step: 2
Training loss: 1.6489238739013672
Validation loss: 2.0725232859452567

Epoch: 5| Step: 3
Training loss: 2.4805374145507812
Validation loss: 2.0726058135430017

Epoch: 5| Step: 4
Training loss: 2.686418294906616
Validation loss: 2.1076129327217736

Epoch: 5| Step: 5
Training loss: 1.610846757888794
Validation loss: 2.0839443504810333

Epoch: 5| Step: 6
Training loss: 2.0565154552459717
Validation loss: 2.0785384327173233

Epoch: 5| Step: 7
Training loss: 1.913824439048767
Validation loss: 2.062948231895765

Epoch: 5| Step: 8
Training loss: 2.0555713176727295
Validation loss: 2.0504003117481866

Epoch: 5| Step: 9
Training loss: 1.9798530340194702
Validation loss: 2.044334883491198

Epoch: 5| Step: 10
Training loss: 2.7431490421295166
Validation loss: 2.0340241293112435

Epoch: 5| Step: 11
Training loss: 1.7563087940216064
Validation loss: 2.0300278862317405

Epoch: 118| Step: 0
Training loss: 2.1417202949523926
Validation loss: 2.018354440728823

Epoch: 5| Step: 1
Training loss: 2.6271533966064453
Validation loss: 2.0156018882989883

Epoch: 5| Step: 2
Training loss: 2.114461898803711
Validation loss: 2.0202326277891793

Epoch: 5| Step: 3
Training loss: 2.0544140338897705
Validation loss: 2.021634429693222

Epoch: 5| Step: 4
Training loss: 1.8284556865692139
Validation loss: 2.025644818941752

Epoch: 5| Step: 5
Training loss: 2.834259510040283
Validation loss: 2.0288300017515817

Epoch: 5| Step: 6
Training loss: 2.0549769401550293
Validation loss: 2.0282261818647385

Epoch: 5| Step: 7
Training loss: 1.9226003885269165
Validation loss: 2.025072897473971

Epoch: 5| Step: 8
Training loss: 1.771392822265625
Validation loss: 2.029884477456411

Epoch: 5| Step: 9
Training loss: 2.5139849185943604
Validation loss: 2.0281836887200675

Epoch: 5| Step: 10
Training loss: 2.065548896789551
Validation loss: 2.0272238353888192

Epoch: 5| Step: 11
Training loss: 1.0830364227294922
Validation loss: 2.0265847792228064

Epoch: 119| Step: 0
Training loss: 2.055570602416992
Validation loss: 2.0140218138694763

Epoch: 5| Step: 1
Training loss: 1.9998409748077393
Validation loss: 2.0114562710126243

Epoch: 5| Step: 2
Training loss: 1.9418996572494507
Validation loss: 2.0140653302272162

Epoch: 5| Step: 3
Training loss: 1.911625862121582
Validation loss: 2.025203595558802

Epoch: 5| Step: 4
Training loss: 2.3896632194519043
Validation loss: 2.0336200644572577

Epoch: 5| Step: 5
Training loss: 2.2825236320495605
Validation loss: 2.0371579925219216

Epoch: 5| Step: 6
Training loss: 1.9574848413467407
Validation loss: 2.047816331187884

Epoch: 5| Step: 7
Training loss: 2.3980937004089355
Validation loss: 2.0494496822357178

Epoch: 5| Step: 8
Training loss: 2.193077802658081
Validation loss: 2.053576489289602

Epoch: 5| Step: 9
Training loss: 2.246807813644409
Validation loss: 2.051141604781151

Epoch: 5| Step: 10
Training loss: 2.1823763847351074
Validation loss: 2.068412264188131

Epoch: 5| Step: 11
Training loss: 2.079249382019043
Validation loss: 2.058645178874334

Epoch: 120| Step: 0
Training loss: 1.4586347341537476
Validation loss: 2.050096278389295

Epoch: 5| Step: 1
Training loss: 2.54793119430542
Validation loss: 2.0498454620440802

Epoch: 5| Step: 2
Training loss: 1.6961454153060913
Validation loss: 2.034951647122701

Epoch: 5| Step: 3
Training loss: 1.889481544494629
Validation loss: 2.0300323416789374

Epoch: 5| Step: 4
Training loss: 2.459105968475342
Validation loss: 2.0222136775652566

Epoch: 5| Step: 5
Training loss: 2.389240026473999
Validation loss: 2.021713594595591

Epoch: 5| Step: 6
Training loss: 2.103714942932129
Validation loss: 2.007618084549904

Epoch: 5| Step: 7
Training loss: 2.431520462036133
Validation loss: 2.0049737691879272

Epoch: 5| Step: 8
Training loss: 2.445711135864258
Validation loss: 2.0091846932967505

Epoch: 5| Step: 9
Training loss: 2.0764896869659424
Validation loss: 2.0115883499383926

Epoch: 5| Step: 10
Training loss: 2.1925015449523926
Validation loss: 2.0148129065831504

Epoch: 5| Step: 11
Training loss: 1.8138115406036377
Validation loss: 2.0156624019145966

Epoch: 121| Step: 0
Training loss: 2.236257791519165
Validation loss: 2.0184841056664786

Epoch: 5| Step: 1
Training loss: 2.1407148838043213
Validation loss: 2.021450623869896

Epoch: 5| Step: 2
Training loss: 1.7769056558609009
Validation loss: 2.0205591022968292

Epoch: 5| Step: 3
Training loss: 2.0572924613952637
Validation loss: 2.0126983573039374

Epoch: 5| Step: 4
Training loss: 2.2011542320251465
Validation loss: 2.012611170609792

Epoch: 5| Step: 5
Training loss: 2.308645486831665
Validation loss: 2.0158091435829797

Epoch: 5| Step: 6
Training loss: 1.8709548711776733
Validation loss: 2.0191153635581336

Epoch: 5| Step: 7
Training loss: 1.9723132848739624
Validation loss: 2.0149577856063843

Epoch: 5| Step: 8
Training loss: 2.5134615898132324
Validation loss: 2.0110824207464852

Epoch: 5| Step: 9
Training loss: 2.3988964557647705
Validation loss: 2.0142892599105835

Epoch: 5| Step: 10
Training loss: 2.155913829803467
Validation loss: 2.012425263722738

Epoch: 5| Step: 11
Training loss: 1.9118458032608032
Validation loss: 2.011174276471138

Epoch: 122| Step: 0
Training loss: 1.6903331279754639
Validation loss: 2.018033877015114

Epoch: 5| Step: 1
Training loss: 1.9837028980255127
Validation loss: 2.0083041936159134

Epoch: 5| Step: 2
Training loss: 2.1615214347839355
Validation loss: 2.0270235190788903

Epoch: 5| Step: 3
Training loss: 2.03977632522583
Validation loss: 2.035669684410095

Epoch: 5| Step: 4
Training loss: 2.1242127418518066
Validation loss: 2.0333109398682914

Epoch: 5| Step: 5
Training loss: 2.1066877841949463
Validation loss: 2.0369714746872583

Epoch: 5| Step: 6
Training loss: 2.415968656539917
Validation loss: 2.0217750668525696

Epoch: 5| Step: 7
Training loss: 2.9443130493164062
Validation loss: 2.028916691740354

Epoch: 5| Step: 8
Training loss: 1.7805442810058594
Validation loss: 2.020029296477636

Epoch: 5| Step: 9
Training loss: 2.1333212852478027
Validation loss: 2.0279590636491776

Epoch: 5| Step: 10
Training loss: 2.059652328491211
Validation loss: 2.0198213259379068

Epoch: 5| Step: 11
Training loss: 2.009636402130127
Validation loss: 2.0241862883170447

Epoch: 123| Step: 0
Training loss: 1.9944061040878296
Validation loss: 2.017086406548818

Epoch: 5| Step: 1
Training loss: 1.745304822921753
Validation loss: 2.0191377152999244

Epoch: 5| Step: 2
Training loss: 2.4838452339172363
Validation loss: 2.0172100017468133

Epoch: 5| Step: 3
Training loss: 2.084085702896118
Validation loss: 2.0171094983816147

Epoch: 5| Step: 4
Training loss: 1.8219060897827148
Validation loss: 2.0179557651281357

Epoch: 5| Step: 5
Training loss: 2.0572946071624756
Validation loss: 2.0180638283491135

Epoch: 5| Step: 6
Training loss: 2.3634626865386963
Validation loss: 2.0239934821923575

Epoch: 5| Step: 7
Training loss: 2.788383960723877
Validation loss: 2.022578150033951

Epoch: 5| Step: 8
Training loss: 1.7958831787109375
Validation loss: 2.022465984026591

Epoch: 5| Step: 9
Training loss: 1.885230302810669
Validation loss: 2.0221463590860367

Epoch: 5| Step: 10
Training loss: 1.9952605962753296
Validation loss: 2.024446780482928

Epoch: 5| Step: 11
Training loss: 3.3145928382873535
Validation loss: 2.0247825980186462

Epoch: 124| Step: 0
Training loss: 1.7644199132919312
Validation loss: 2.0194559593995414

Epoch: 5| Step: 1
Training loss: 2.7861740589141846
Validation loss: 2.0174464931090674

Epoch: 5| Step: 2
Training loss: 2.1986804008483887
Validation loss: 2.0221614092588425

Epoch: 5| Step: 3
Training loss: 2.0408616065979004
Validation loss: 2.0250016202529273

Epoch: 5| Step: 4
Training loss: 2.607053279876709
Validation loss: 2.0239700376987457

Epoch: 5| Step: 5
Training loss: 2.2769007682800293
Validation loss: 2.0214691509803138

Epoch: 5| Step: 6
Training loss: 2.255436658859253
Validation loss: 2.0280887385209403

Epoch: 5| Step: 7
Training loss: 2.136362314224243
Validation loss: 2.0252368599176407

Epoch: 5| Step: 8
Training loss: 1.9239752292633057
Validation loss: 2.0243389109770455

Epoch: 5| Step: 9
Training loss: 2.212700605392456
Validation loss: 2.020682672659556

Epoch: 5| Step: 10
Training loss: 1.6844804286956787
Validation loss: 2.0191025833288827

Epoch: 5| Step: 11
Training loss: 1.1997112035751343
Validation loss: 2.0183226664861045

Epoch: 125| Step: 0
Training loss: 2.2060844898223877
Validation loss: 2.0170831133921943

Epoch: 5| Step: 1
Training loss: 2.380645990371704
Validation loss: 2.0158086319764457

Epoch: 5| Step: 2
Training loss: 1.8451530933380127
Validation loss: 2.0175042947133384

Epoch: 5| Step: 3
Training loss: 2.260612964630127
Validation loss: 2.0005815575520196

Epoch: 5| Step: 4
Training loss: 2.052194833755493
Validation loss: 1.9947844694058101

Epoch: 5| Step: 5
Training loss: 1.870519995689392
Validation loss: 1.9938847422599792

Epoch: 5| Step: 6
Training loss: 2.6357059478759766
Validation loss: 1.9920842597881954

Epoch: 5| Step: 7
Training loss: 2.075990676879883
Validation loss: 1.991643528143565

Epoch: 5| Step: 8
Training loss: 1.597831130027771
Validation loss: 1.984470322728157

Epoch: 5| Step: 9
Training loss: 2.284311532974243
Validation loss: 1.995962659517924

Epoch: 5| Step: 10
Training loss: 2.5185515880584717
Validation loss: 2.0003793438275657

Epoch: 5| Step: 11
Training loss: 2.1432697772979736
Validation loss: 2.0071977575620017

Epoch: 126| Step: 0
Training loss: 2.1803393363952637
Validation loss: 2.003647118806839

Epoch: 5| Step: 1
Training loss: 2.3620433807373047
Validation loss: 2.0024811575810113

Epoch: 5| Step: 2
Training loss: 2.4583845138549805
Validation loss: 2.003146151701609

Epoch: 5| Step: 3
Training loss: 2.1539530754089355
Validation loss: 1.9958507468303044

Epoch: 5| Step: 4
Training loss: 2.1687636375427246
Validation loss: 2.0032129486401877

Epoch: 5| Step: 5
Training loss: 1.7742652893066406
Validation loss: 2.00867789487044

Epoch: 5| Step: 6
Training loss: 2.1083405017852783
Validation loss: 2.0110164483388266

Epoch: 5| Step: 7
Training loss: 2.4635214805603027
Validation loss: 2.0158730198939643

Epoch: 5| Step: 8
Training loss: 1.9283825159072876
Validation loss: 2.0242702066898346

Epoch: 5| Step: 9
Training loss: 1.9150192737579346
Validation loss: 2.014678214987119

Epoch: 5| Step: 10
Training loss: 1.8855291604995728
Validation loss: 2.012811670700709

Epoch: 5| Step: 11
Training loss: 1.178795576095581
Validation loss: 2.0210872838894525

Epoch: 127| Step: 0
Training loss: 2.0606465339660645
Validation loss: 2.0210854609807334

Epoch: 5| Step: 1
Training loss: 2.4390640258789062
Validation loss: 2.0142849534749985

Epoch: 5| Step: 2
Training loss: 1.983875036239624
Validation loss: 2.0222740223010383

Epoch: 5| Step: 3
Training loss: 2.0155701637268066
Validation loss: 2.022729754447937

Epoch: 5| Step: 4
Training loss: 1.98213791847229
Validation loss: 2.018336926897367

Epoch: 5| Step: 5
Training loss: 2.04318904876709
Validation loss: 2.025684952735901

Epoch: 5| Step: 6
Training loss: 2.2233097553253174
Validation loss: 2.0282339503367743

Epoch: 5| Step: 7
Training loss: 1.730717658996582
Validation loss: 2.02874522904555

Epoch: 5| Step: 8
Training loss: 1.8793046474456787
Validation loss: 2.0321589410305023

Epoch: 5| Step: 9
Training loss: 2.1436057090759277
Validation loss: 2.0251051237185798

Epoch: 5| Step: 10
Training loss: 2.3102943897247314
Validation loss: 2.040873328844706

Epoch: 5| Step: 11
Training loss: 3.41452956199646
Validation loss: 2.0392844478289285

Epoch: 128| Step: 0
Training loss: 2.539721965789795
Validation loss: 2.049659326672554

Epoch: 5| Step: 1
Training loss: 1.8682626485824585
Validation loss: 2.055290291706721

Epoch: 5| Step: 2
Training loss: 1.5464913845062256
Validation loss: 2.068093791604042

Epoch: 5| Step: 3
Training loss: 2.9811909198760986
Validation loss: 2.0606657365957894

Epoch: 5| Step: 4
Training loss: 2.4682624340057373
Validation loss: 2.0660250832637153

Epoch: 5| Step: 5
Training loss: 1.9702943563461304
Validation loss: 2.079725076754888

Epoch: 5| Step: 6
Training loss: 1.5493948459625244
Validation loss: 2.0652628342310586

Epoch: 5| Step: 7
Training loss: 2.1750590801239014
Validation loss: 2.0493438641230264

Epoch: 5| Step: 8
Training loss: 2.15434193611145
Validation loss: 2.0489483028650284

Epoch: 5| Step: 9
Training loss: 1.9933459758758545
Validation loss: 2.0458843261003494

Epoch: 5| Step: 10
Training loss: 1.8605855703353882
Validation loss: 2.0344813565413156

Epoch: 5| Step: 11
Training loss: 3.0402982234954834
Validation loss: 2.0255296478668847

Epoch: 129| Step: 0
Training loss: 1.6646900177001953
Validation loss: 2.0138622174660363

Epoch: 5| Step: 1
Training loss: 2.3170242309570312
Validation loss: 2.0199156403541565

Epoch: 5| Step: 2
Training loss: 1.9898782968521118
Validation loss: 2.014513368407885

Epoch: 5| Step: 3
Training loss: 2.1226143836975098
Validation loss: 2.018703371286392

Epoch: 5| Step: 4
Training loss: 1.6942936182022095
Validation loss: 2.0227028131484985

Epoch: 5| Step: 5
Training loss: 2.6385223865509033
Validation loss: 2.02632308502992

Epoch: 5| Step: 6
Training loss: 2.4505069255828857
Validation loss: 2.0193963100512824

Epoch: 5| Step: 7
Training loss: 2.099388599395752
Validation loss: 2.015581578016281

Epoch: 5| Step: 8
Training loss: 2.1949996948242188
Validation loss: 2.016379867990812

Epoch: 5| Step: 9
Training loss: 1.9006164073944092
Validation loss: 2.016906683643659

Epoch: 5| Step: 10
Training loss: 2.3518564701080322
Validation loss: 2.0114840467770896

Epoch: 5| Step: 11
Training loss: 2.477133274078369
Validation loss: 2.015782058238983

Epoch: 130| Step: 0
Training loss: 1.7316076755523682
Validation loss: 2.015106126666069

Epoch: 5| Step: 1
Training loss: 1.9834372997283936
Validation loss: 2.0181299994389215

Epoch: 5| Step: 2
Training loss: 2.6273581981658936
Validation loss: 2.0236666947603226

Epoch: 5| Step: 3
Training loss: 2.210872173309326
Validation loss: 2.0296018520991006

Epoch: 5| Step: 4
Training loss: 2.1310269832611084
Validation loss: 2.0293016135692596

Epoch: 5| Step: 5
Training loss: 2.2313337326049805
Validation loss: 2.042793020606041

Epoch: 5| Step: 6
Training loss: 2.1893439292907715
Validation loss: 2.033496210972468

Epoch: 5| Step: 7
Training loss: 1.4850842952728271
Validation loss: 2.0380938003460565

Epoch: 5| Step: 8
Training loss: 2.0582785606384277
Validation loss: 2.040367215871811

Epoch: 5| Step: 9
Training loss: 2.2717301845550537
Validation loss: 2.044236277540525

Epoch: 5| Step: 10
Training loss: 2.2554314136505127
Validation loss: 2.037995825211207

Epoch: 5| Step: 11
Training loss: 2.4135937690734863
Validation loss: 2.032468448082606

Epoch: 131| Step: 0
Training loss: 2.531506299972534
Validation loss: 2.0166770021120706

Epoch: 5| Step: 1
Training loss: 1.791982889175415
Validation loss: 2.0256834576527276

Epoch: 5| Step: 2
Training loss: 1.5845997333526611
Validation loss: 2.021187419692675

Epoch: 5| Step: 3
Training loss: 2.7203171253204346
Validation loss: 2.0173015346129737

Epoch: 5| Step: 4
Training loss: 2.3671298027038574
Validation loss: 2.024361635247866

Epoch: 5| Step: 5
Training loss: 2.3516998291015625
Validation loss: 2.0273610999186835

Epoch: 5| Step: 6
Training loss: 1.6604276895523071
Validation loss: 2.0237840364376702

Epoch: 5| Step: 7
Training loss: 1.9933793544769287
Validation loss: 2.0245973666508994

Epoch: 5| Step: 8
Training loss: 2.2213306427001953
Validation loss: 2.0275624990463257

Epoch: 5| Step: 9
Training loss: 1.8424227237701416
Validation loss: 2.0337193310260773

Epoch: 5| Step: 10
Training loss: 2.090080976486206
Validation loss: 2.030390188097954

Epoch: 5| Step: 11
Training loss: 2.8166515827178955
Validation loss: 2.032348647713661

Epoch: 132| Step: 0
Training loss: 1.7937238216400146
Validation loss: 2.030673364798228

Epoch: 5| Step: 1
Training loss: 2.008617877960205
Validation loss: 2.032607600092888

Epoch: 5| Step: 2
Training loss: 2.4292712211608887
Validation loss: 2.0212876349687576

Epoch: 5| Step: 3
Training loss: 1.8538423776626587
Validation loss: 2.022727598746618

Epoch: 5| Step: 4
Training loss: 2.721106767654419
Validation loss: 2.0226306716601052

Epoch: 5| Step: 5
Training loss: 1.7254842519760132
Validation loss: 2.013134002685547

Epoch: 5| Step: 6
Training loss: 1.7335336208343506
Validation loss: 2.024396692713102

Epoch: 5| Step: 7
Training loss: 1.9695796966552734
Validation loss: 2.0224053164323172

Epoch: 5| Step: 8
Training loss: 2.197899580001831
Validation loss: 2.0395189970731735

Epoch: 5| Step: 9
Training loss: 2.5075182914733887
Validation loss: 2.0337845285733542

Epoch: 5| Step: 10
Training loss: 1.8453476428985596
Validation loss: 2.041041851043701

Epoch: 5| Step: 11
Training loss: 3.0547289848327637
Validation loss: 2.04317773381869

Epoch: 133| Step: 0
Training loss: 2.5942606925964355
Validation loss: 2.036941334605217

Epoch: 5| Step: 1
Training loss: 2.0199460983276367
Validation loss: 2.0408660173416138

Epoch: 5| Step: 2
Training loss: 2.031616687774658
Validation loss: 2.0371421575546265

Epoch: 5| Step: 3
Training loss: 2.3088550567626953
Validation loss: 2.0333952655394874

Epoch: 5| Step: 4
Training loss: 1.689941167831421
Validation loss: 2.0365679959456124

Epoch: 5| Step: 5
Training loss: 1.819403886795044
Validation loss: 2.0363265623648963

Epoch: 5| Step: 6
Training loss: 1.7737735509872437
Validation loss: 2.033743739128113

Epoch: 5| Step: 7
Training loss: 2.3542768955230713
Validation loss: 2.0339030424753823

Epoch: 5| Step: 8
Training loss: 2.0720431804656982
Validation loss: 2.029030670722326

Epoch: 5| Step: 9
Training loss: 2.741976261138916
Validation loss: 2.032310744126638

Epoch: 5| Step: 10
Training loss: 1.6948041915893555
Validation loss: 2.0357925593852997

Epoch: 5| Step: 11
Training loss: 0.9594213366508484
Validation loss: 2.0308795322974524

Epoch: 134| Step: 0
Training loss: 2.187025308609009
Validation loss: 2.0363838920990625

Epoch: 5| Step: 1
Training loss: 2.0929453372955322
Validation loss: 2.0457061529159546

Epoch: 5| Step: 2
Training loss: 1.7180503606796265
Validation loss: 2.0496712923049927

Epoch: 5| Step: 3
Training loss: 2.231797695159912
Validation loss: 2.050762673219045

Epoch: 5| Step: 4
Training loss: 2.3796637058258057
Validation loss: 2.048492729663849

Epoch: 5| Step: 5
Training loss: 1.8506091833114624
Validation loss: 2.0504472156365714

Epoch: 5| Step: 6
Training loss: 1.6325416564941406
Validation loss: 2.0324994126955667

Epoch: 5| Step: 7
Training loss: 2.2648589611053467
Validation loss: 2.0397378553946814

Epoch: 5| Step: 8
Training loss: 2.1564040184020996
Validation loss: 2.037516862154007

Epoch: 5| Step: 9
Training loss: 2.5044097900390625
Validation loss: 2.0374132096767426

Epoch: 5| Step: 10
Training loss: 2.22998046875
Validation loss: 2.04067724943161

Epoch: 5| Step: 11
Training loss: 1.789177656173706
Validation loss: 2.0463729997475943

Epoch: 135| Step: 0
Training loss: 2.255139112472534
Validation loss: 2.0283207098642984

Epoch: 5| Step: 1
Training loss: 1.532167673110962
Validation loss: 2.045350030064583

Epoch: 5| Step: 2
Training loss: 2.196719169616699
Validation loss: 2.0484574735164642

Epoch: 5| Step: 3
Training loss: 2.699023962020874
Validation loss: 2.036589508255323

Epoch: 5| Step: 4
Training loss: 1.9000616073608398
Validation loss: 2.0372148205836615

Epoch: 5| Step: 5
Training loss: 1.9336655139923096
Validation loss: 2.0371940582990646

Epoch: 5| Step: 6
Training loss: 2.3929667472839355
Validation loss: 2.0324900448322296

Epoch: 5| Step: 7
Training loss: 1.6938602924346924
Validation loss: 2.0311566839615502

Epoch: 5| Step: 8
Training loss: 1.5179141759872437
Validation loss: 2.0403156032164893

Epoch: 5| Step: 9
Training loss: 2.2400460243225098
Validation loss: 2.041360338528951

Epoch: 5| Step: 10
Training loss: 2.4663455486297607
Validation loss: 2.0379355549812317

Epoch: 5| Step: 11
Training loss: 2.0156049728393555
Validation loss: 2.0457804600397744

Epoch: 136| Step: 0
Training loss: 2.4771530628204346
Validation loss: 2.039556309580803

Epoch: 5| Step: 1
Training loss: 2.1774744987487793
Validation loss: 2.0506449043750763

Epoch: 5| Step: 2
Training loss: 1.933230996131897
Validation loss: 2.0477649569511414

Epoch: 5| Step: 3
Training loss: 1.967749834060669
Validation loss: 2.045548448959986

Epoch: 5| Step: 4
Training loss: 1.7892242670059204
Validation loss: 2.055821046233177

Epoch: 5| Step: 5
Training loss: 2.0025758743286133
Validation loss: 2.0499770740667977

Epoch: 5| Step: 6
Training loss: 1.8322563171386719
Validation loss: 2.04541007677714

Epoch: 5| Step: 7
Training loss: 2.22998309135437
Validation loss: 2.051293447613716

Epoch: 5| Step: 8
Training loss: 1.9830005168914795
Validation loss: 2.051108901699384

Epoch: 5| Step: 9
Training loss: 1.7675163745880127
Validation loss: 2.04059366385142

Epoch: 5| Step: 10
Training loss: 2.695657253265381
Validation loss: 2.05296428501606

Epoch: 5| Step: 11
Training loss: 2.4045214653015137
Validation loss: 2.0508336325486503

Epoch: 137| Step: 0
Training loss: 2.345663547515869
Validation loss: 2.048267592986425

Epoch: 5| Step: 1
Training loss: 1.5977060794830322
Validation loss: 2.0438224971294403

Epoch: 5| Step: 2
Training loss: 2.2582106590270996
Validation loss: 2.0448069671789804

Epoch: 5| Step: 3
Training loss: 2.25961971282959
Validation loss: 2.0350621889034906

Epoch: 5| Step: 4
Training loss: 2.4331846237182617
Validation loss: 2.0345037331183753

Epoch: 5| Step: 5
Training loss: 2.069549083709717
Validation loss: 2.0280194183190665

Epoch: 5| Step: 6
Training loss: 2.299287796020508
Validation loss: 2.027452846368154

Epoch: 5| Step: 7
Training loss: 2.54703426361084
Validation loss: 2.0235188206036887

Epoch: 5| Step: 8
Training loss: 1.7839208841323853
Validation loss: 2.018407573302587

Epoch: 5| Step: 9
Training loss: 1.8063997030258179
Validation loss: 2.016600792606672

Epoch: 5| Step: 10
Training loss: 1.5306737422943115
Validation loss: 2.0208995789289474

Epoch: 5| Step: 11
Training loss: 1.6770026683807373
Validation loss: 2.0296861976385117

Epoch: 138| Step: 0
Training loss: 2.007659912109375
Validation loss: 2.032750209172567

Epoch: 5| Step: 1
Training loss: 2.353186845779419
Validation loss: 2.043449799219767

Epoch: 5| Step: 2
Training loss: 1.945202112197876
Validation loss: 2.053105503320694

Epoch: 5| Step: 3
Training loss: 2.4995198249816895
Validation loss: 2.0644388149182

Epoch: 5| Step: 4
Training loss: 1.8098018169403076
Validation loss: 2.066981087128321

Epoch: 5| Step: 5
Training loss: 2.5329041481018066
Validation loss: 2.0560772716999054

Epoch: 5| Step: 6
Training loss: 2.5288596153259277
Validation loss: 2.0587762196858725

Epoch: 5| Step: 7
Training loss: 1.5615109205245972
Validation loss: 2.032173603773117

Epoch: 5| Step: 8
Training loss: 1.8827037811279297
Validation loss: 2.0430762817462287

Epoch: 5| Step: 9
Training loss: 1.9534820318222046
Validation loss: 2.031094620625178

Epoch: 5| Step: 10
Training loss: 1.9492461681365967
Validation loss: 2.0363307148218155

Epoch: 5| Step: 11
Training loss: 2.565572738647461
Validation loss: 2.032710005839666

Epoch: 139| Step: 0
Training loss: 1.7154556512832642
Validation loss: 2.0252760847409568

Epoch: 5| Step: 1
Training loss: 1.7024494409561157
Validation loss: 2.0342624286810556

Epoch: 5| Step: 2
Training loss: 2.087904453277588
Validation loss: 2.026567886273066

Epoch: 5| Step: 3
Training loss: 1.3257197141647339
Validation loss: 2.0285023599863052

Epoch: 5| Step: 4
Training loss: 2.0498480796813965
Validation loss: 2.035924881696701

Epoch: 5| Step: 5
Training loss: 2.7404379844665527
Validation loss: 2.028205697735151

Epoch: 5| Step: 6
Training loss: 2.479436159133911
Validation loss: 2.0415221452713013

Epoch: 5| Step: 7
Training loss: 2.230808973312378
Validation loss: 2.046798293789228

Epoch: 5| Step: 8
Training loss: 2.130843162536621
Validation loss: 2.041359523932139

Epoch: 5| Step: 9
Training loss: 1.915988564491272
Validation loss: 2.0358533412218094

Epoch: 5| Step: 10
Training loss: 2.425680160522461
Validation loss: 2.0433329045772552

Epoch: 5| Step: 11
Training loss: 2.3809006214141846
Validation loss: 2.0476409445206323

Epoch: 140| Step: 0
Training loss: 2.3742408752441406
Validation loss: 2.0369383146365485

Epoch: 5| Step: 1
Training loss: 1.8807868957519531
Validation loss: 2.0422002226114273

Epoch: 5| Step: 2
Training loss: 1.9202247858047485
Validation loss: 2.0369986643393836

Epoch: 5| Step: 3
Training loss: 1.9075952768325806
Validation loss: 2.0289377172787986

Epoch: 5| Step: 4
Training loss: 2.0671465396881104
Validation loss: 2.0332634299993515

Epoch: 5| Step: 5
Training loss: 1.7567955255508423
Validation loss: 2.030351017912229

Epoch: 5| Step: 6
Training loss: 1.8263921737670898
Validation loss: 2.0302297373612723

Epoch: 5| Step: 7
Training loss: 2.1435914039611816
Validation loss: 2.0218199590841928

Epoch: 5| Step: 8
Training loss: 2.1938750743865967
Validation loss: 2.016867275039355

Epoch: 5| Step: 9
Training loss: 2.657193422317505
Validation loss: 2.0219444781541824

Epoch: 5| Step: 10
Training loss: 2.0494658946990967
Validation loss: 2.026893471678098

Epoch: 5| Step: 11
Training loss: 1.9361692667007446
Validation loss: 2.027996078133583

Epoch: 141| Step: 0
Training loss: 2.2990565299987793
Validation loss: 2.0200162579615912

Epoch: 5| Step: 1
Training loss: 2.068498134613037
Validation loss: 2.0187538961569467

Epoch: 5| Step: 2
Training loss: 2.6876635551452637
Validation loss: 2.0227044920126596

Epoch: 5| Step: 3
Training loss: 2.0922794342041016
Validation loss: 2.024797668059667

Epoch: 5| Step: 4
Training loss: 1.586163878440857
Validation loss: 2.0221797774235406

Epoch: 5| Step: 5
Training loss: 2.0907177925109863
Validation loss: 2.02619435886542

Epoch: 5| Step: 6
Training loss: 2.112077236175537
Validation loss: 2.034771293401718

Epoch: 5| Step: 7
Training loss: 1.998248815536499
Validation loss: 2.0325295478105545

Epoch: 5| Step: 8
Training loss: 1.7200191020965576
Validation loss: 2.0179245124260583

Epoch: 5| Step: 9
Training loss: 2.0507328510284424
Validation loss: 2.0221669922272363

Epoch: 5| Step: 10
Training loss: 1.9743753671646118
Validation loss: 2.027449836333593

Epoch: 5| Step: 11
Training loss: 2.24296236038208
Validation loss: 2.032411202788353

Epoch: 142| Step: 0
Training loss: 1.7562382221221924
Validation loss: 2.0385041683912277

Epoch: 5| Step: 1
Training loss: 1.6649954319000244
Validation loss: 2.041874130566915

Epoch: 5| Step: 2
Training loss: 1.9948222637176514
Validation loss: 2.0423061897357306

Epoch: 5| Step: 3
Training loss: 2.117439031600952
Validation loss: 2.0407264977693558

Epoch: 5| Step: 4
Training loss: 2.066298246383667
Validation loss: 2.0380084216594696

Epoch: 5| Step: 5
Training loss: 2.121847629547119
Validation loss: 2.0290956993897757

Epoch: 5| Step: 6
Training loss: 1.9654285907745361
Validation loss: 2.030216614405314

Epoch: 5| Step: 7
Training loss: 2.337118625640869
Validation loss: 2.0239175806442895

Epoch: 5| Step: 8
Training loss: 2.169147491455078
Validation loss: 2.0239416708548865

Epoch: 5| Step: 9
Training loss: 2.1949141025543213
Validation loss: 2.0346778879563012

Epoch: 5| Step: 10
Training loss: 2.3495640754699707
Validation loss: 2.025249327222506

Epoch: 5| Step: 11
Training loss: 2.3229403495788574
Validation loss: 2.0272964785496392

Epoch: 143| Step: 0
Training loss: 1.9151630401611328
Validation loss: 2.0307280868291855

Epoch: 5| Step: 1
Training loss: 1.9851824045181274
Validation loss: 2.03417115410169

Epoch: 5| Step: 2
Training loss: 2.143751621246338
Validation loss: 2.039443517724673

Epoch: 5| Step: 3
Training loss: 1.7099945545196533
Validation loss: 2.0258087118466697

Epoch: 5| Step: 4
Training loss: 2.476722478866577
Validation loss: 2.0285274932781854

Epoch: 5| Step: 5
Training loss: 1.894222617149353
Validation loss: 2.0286294917265573

Epoch: 5| Step: 6
Training loss: 2.5818915367126465
Validation loss: 2.029795085390409

Epoch: 5| Step: 7
Training loss: 2.074903964996338
Validation loss: 2.0297401944796243

Epoch: 5| Step: 8
Training loss: 2.074862003326416
Validation loss: 2.02690722544988

Epoch: 5| Step: 9
Training loss: 2.1981639862060547
Validation loss: 2.0334926595290503

Epoch: 5| Step: 10
Training loss: 1.7678346633911133
Validation loss: 2.025684436162313

Epoch: 5| Step: 11
Training loss: 0.8502272367477417
Validation loss: 2.034147401650747

Epoch: 144| Step: 0
Training loss: 2.066636562347412
Validation loss: 2.038049285610517

Epoch: 5| Step: 1
Training loss: 2.0372366905212402
Validation loss: 2.0274865428606668

Epoch: 5| Step: 2
Training loss: 2.001570224761963
Validation loss: 2.0297815650701523

Epoch: 5| Step: 3
Training loss: 1.9957082271575928
Validation loss: 2.029215062657992

Epoch: 5| Step: 4
Training loss: 1.730958342552185
Validation loss: 2.0371598104635873

Epoch: 5| Step: 5
Training loss: 2.084110736846924
Validation loss: 2.0393203596274057

Epoch: 5| Step: 6
Training loss: 2.594547748565674
Validation loss: 2.0440030743678412

Epoch: 5| Step: 7
Training loss: 2.571448564529419
Validation loss: 2.049325833717982

Epoch: 5| Step: 8
Training loss: 1.5832128524780273
Validation loss: 2.047251765926679

Epoch: 5| Step: 9
Training loss: 2.2578115463256836
Validation loss: 2.0514424443244934

Epoch: 5| Step: 10
Training loss: 1.6532459259033203
Validation loss: 2.0514033834139505

Epoch: 5| Step: 11
Training loss: 2.0493507385253906
Validation loss: 2.057421013712883

Epoch: 145| Step: 0
Training loss: 2.0366668701171875
Validation loss: 2.047099143266678

Epoch: 5| Step: 1
Training loss: 1.8092396259307861
Validation loss: 2.045363967617353

Epoch: 5| Step: 2
Training loss: 2.2756505012512207
Validation loss: 2.050015538930893

Epoch: 5| Step: 3
Training loss: 2.42763090133667
Validation loss: 2.042925611138344

Epoch: 5| Step: 4
Training loss: 2.0492820739746094
Validation loss: 2.047165001432101

Epoch: 5| Step: 5
Training loss: 1.982020378112793
Validation loss: 2.044809232155482

Epoch: 5| Step: 6
Training loss: 1.9300529956817627
Validation loss: 2.037011668086052

Epoch: 5| Step: 7
Training loss: 2.3964827060699463
Validation loss: 2.040582870443662

Epoch: 5| Step: 8
Training loss: 2.069520950317383
Validation loss: 2.039536808927854

Epoch: 5| Step: 9
Training loss: 2.093252658843994
Validation loss: 2.0384290367364883

Epoch: 5| Step: 10
Training loss: 1.8056142330169678
Validation loss: 2.0446272244056067

Epoch: 5| Step: 11
Training loss: 2.0384511947631836
Validation loss: 2.043883348504702

Epoch: 146| Step: 0
Training loss: 2.391867160797119
Validation loss: 2.039157177011172

Epoch: 5| Step: 1
Training loss: 2.028742551803589
Validation loss: 2.0506158769130707

Epoch: 5| Step: 2
Training loss: 1.4256970882415771
Validation loss: 2.0538895428180695

Epoch: 5| Step: 3
Training loss: 2.658179521560669
Validation loss: 2.0699929296970367

Epoch: 5| Step: 4
Training loss: 1.7306849956512451
Validation loss: 2.0668949286142984

Epoch: 5| Step: 5
Training loss: 2.22192120552063
Validation loss: 2.065677687525749

Epoch: 5| Step: 6
Training loss: 1.8476765155792236
Validation loss: 2.0728513598442078

Epoch: 5| Step: 7
Training loss: 2.2302913665771484
Validation loss: 2.0654577116171517

Epoch: 5| Step: 8
Training loss: 2.3532752990722656
Validation loss: 2.0740436762571335

Epoch: 5| Step: 9
Training loss: 1.6971721649169922
Validation loss: 2.0696734885374704

Epoch: 5| Step: 10
Training loss: 2.183104991912842
Validation loss: 2.0660321613152823

Epoch: 5| Step: 11
Training loss: 2.486294984817505
Validation loss: 2.0373655259609222

Epoch: 147| Step: 0
Training loss: 2.334829807281494
Validation loss: 2.04731684923172

Epoch: 5| Step: 1
Training loss: 1.822899580001831
Validation loss: 2.0348808417717614

Epoch: 5| Step: 2
Training loss: 1.7251936197280884
Validation loss: 2.0448935429255166

Epoch: 5| Step: 3
Training loss: 1.1779614686965942
Validation loss: 2.031210318207741

Epoch: 5| Step: 4
Training loss: 2.2882351875305176
Validation loss: 2.0374511778354645

Epoch: 5| Step: 5
Training loss: 2.520066499710083
Validation loss: 2.0343438734610877

Epoch: 5| Step: 6
Training loss: 1.8555845022201538
Validation loss: 2.037778024872144

Epoch: 5| Step: 7
Training loss: 2.6731338500976562
Validation loss: 2.0372071663538613

Epoch: 5| Step: 8
Training loss: 2.189335584640503
Validation loss: 2.0363335808118186

Epoch: 5| Step: 9
Training loss: 1.8935753107070923
Validation loss: 2.035631279150645

Epoch: 5| Step: 10
Training loss: 2.2731564044952393
Validation loss: 2.035158723592758

Epoch: 5| Step: 11
Training loss: 1.9823675155639648
Validation loss: 2.043305198351542

Epoch: 148| Step: 0
Training loss: 2.014746904373169
Validation loss: 2.045625388622284

Epoch: 5| Step: 1
Training loss: 1.4870035648345947
Validation loss: 2.040765643119812

Epoch: 5| Step: 2
Training loss: 2.3563148975372314
Validation loss: 2.053900803128878

Epoch: 5| Step: 3
Training loss: 2.078892946243286
Validation loss: 2.0553021132946014

Epoch: 5| Step: 4
Training loss: 2.353468418121338
Validation loss: 2.050303727388382

Epoch: 5| Step: 5
Training loss: 2.3527424335479736
Validation loss: 2.0474300235509872

Epoch: 5| Step: 6
Training loss: 1.953047513961792
Validation loss: 2.0542877316474915

Epoch: 5| Step: 7
Training loss: 1.348487138748169
Validation loss: 2.0475040674209595

Epoch: 5| Step: 8
Training loss: 2.330543041229248
Validation loss: 2.0558635592460632

Epoch: 5| Step: 9
Training loss: 1.9125181436538696
Validation loss: 2.049493203560511

Epoch: 5| Step: 10
Training loss: 2.2134006023406982
Validation loss: 2.0559462755918503

Epoch: 5| Step: 11
Training loss: 1.8565199375152588
Validation loss: 2.046204298734665

Epoch: 149| Step: 0
Training loss: 2.542219400405884
Validation loss: 2.0463751951853433

Epoch: 5| Step: 1
Training loss: 2.3968656063079834
Validation loss: 2.047244906425476

Epoch: 5| Step: 2
Training loss: 2.0031745433807373
Validation loss: 2.050939400990804

Epoch: 5| Step: 3
Training loss: 1.563998818397522
Validation loss: 2.059914613763491

Epoch: 5| Step: 4
Training loss: 2.128507614135742
Validation loss: 2.0628262062867484

Epoch: 5| Step: 5
Training loss: 2.099289894104004
Validation loss: 2.0590033580859504

Epoch: 5| Step: 6
Training loss: 1.9195995330810547
Validation loss: 2.0555758823951087

Epoch: 5| Step: 7
Training loss: 1.7494125366210938
Validation loss: 2.0516382257143655

Epoch: 5| Step: 8
Training loss: 2.435436725616455
Validation loss: 2.055251027146975

Epoch: 5| Step: 9
Training loss: 1.6813242435455322
Validation loss: 2.0641951262950897

Epoch: 5| Step: 10
Training loss: 1.8497081995010376
Validation loss: 2.051839624842008

Epoch: 5| Step: 11
Training loss: 2.1810755729675293
Validation loss: 2.0458492785692215

Epoch: 150| Step: 0
Training loss: 1.943118691444397
Validation loss: 2.041221802433332

Epoch: 5| Step: 1
Training loss: 1.9510351419448853
Validation loss: 2.0366618633270264

Epoch: 5| Step: 2
Training loss: 1.912471055984497
Validation loss: 2.0348466485738754

Epoch: 5| Step: 3
Training loss: 2.465996503829956
Validation loss: 2.0388063391049704

Epoch: 5| Step: 4
Training loss: 2.0800092220306396
Validation loss: 2.0315649261077247

Epoch: 5| Step: 5
Training loss: 1.8452584743499756
Validation loss: 2.029498596986135

Epoch: 5| Step: 6
Training loss: 2.1033501625061035
Validation loss: 2.0214740137259164

Epoch: 5| Step: 7
Training loss: 2.2314372062683105
Validation loss: 2.0231025367975235

Epoch: 5| Step: 8
Training loss: 2.08860182762146
Validation loss: 2.0265441834926605

Epoch: 5| Step: 9
Training loss: 2.249174118041992
Validation loss: 2.0299116422732673

Epoch: 5| Step: 10
Training loss: 1.8265373706817627
Validation loss: 2.0476919462283454

Epoch: 5| Step: 11
Training loss: 1.465888500213623
Validation loss: 2.0447206099828086

Epoch: 151| Step: 0
Training loss: 1.6146600246429443
Validation loss: 2.0466976861159005

Epoch: 5| Step: 1
Training loss: 2.075791835784912
Validation loss: 2.062588488062223

Epoch: 5| Step: 2
Training loss: 2.6434998512268066
Validation loss: 2.076692685484886

Epoch: 5| Step: 3
Training loss: 2.338989734649658
Validation loss: 2.0818018714586892

Epoch: 5| Step: 4
Training loss: 1.7748610973358154
Validation loss: 2.0730777829885483

Epoch: 5| Step: 5
Training loss: 2.134298801422119
Validation loss: 2.0538406123717627

Epoch: 5| Step: 6
Training loss: 2.2749149799346924
Validation loss: 2.048992852369944

Epoch: 5| Step: 7
Training loss: 2.2003724575042725
Validation loss: 2.032043973604838

Epoch: 5| Step: 8
Training loss: 2.1294057369232178
Validation loss: 2.0457571198542914

Epoch: 5| Step: 9
Training loss: 1.461435079574585
Validation loss: 2.031785229841868

Epoch: 5| Step: 10
Training loss: 2.0065836906433105
Validation loss: 2.032429958383242

Epoch: 5| Step: 11
Training loss: 2.5581183433532715
Validation loss: 2.034966304898262

Epoch: 152| Step: 0
Training loss: 2.212583065032959
Validation loss: 2.028389349579811

Epoch: 5| Step: 1
Training loss: 2.4095146656036377
Validation loss: 2.0258050113916397

Epoch: 5| Step: 2
Training loss: 2.468745708465576
Validation loss: 2.033553510904312

Epoch: 5| Step: 3
Training loss: 2.1581997871398926
Validation loss: 2.036405250430107

Epoch: 5| Step: 4
Training loss: 2.0646564960479736
Validation loss: 2.0267241398493447

Epoch: 5| Step: 5
Training loss: 2.1523990631103516
Validation loss: 2.0300518622001014

Epoch: 5| Step: 6
Training loss: 1.8015575408935547
Validation loss: 2.0367053796847663

Epoch: 5| Step: 7
Training loss: 1.7398405075073242
Validation loss: 2.0225902646780014

Epoch: 5| Step: 8
Training loss: 1.780364990234375
Validation loss: 2.0350476503372192

Epoch: 5| Step: 9
Training loss: 1.8260250091552734
Validation loss: 2.034834921360016

Epoch: 5| Step: 10
Training loss: 2.071866512298584
Validation loss: 2.033237800002098

Epoch: 5| Step: 11
Training loss: 3.143739700317383
Validation loss: 2.0458761801322303

Epoch: 153| Step: 0
Training loss: 1.9531009197235107
Validation loss: 2.0410665571689606

Epoch: 5| Step: 1
Training loss: 1.856716513633728
Validation loss: 2.057031735777855

Epoch: 5| Step: 2
Training loss: 2.2670609951019287
Validation loss: 2.0488425344228745

Epoch: 5| Step: 3
Training loss: 2.5584094524383545
Validation loss: 2.045811320344607

Epoch: 5| Step: 4
Training loss: 2.151606798171997
Validation loss: 2.0587762196858725

Epoch: 5| Step: 5
Training loss: 2.088151454925537
Validation loss: 2.042256454626719

Epoch: 5| Step: 6
Training loss: 1.817003846168518
Validation loss: 2.0461706717809043

Epoch: 5| Step: 7
Training loss: 2.1374611854553223
Validation loss: 2.040280054012934

Epoch: 5| Step: 8
Training loss: 1.9176028966903687
Validation loss: 2.031766096750895

Epoch: 5| Step: 9
Training loss: 1.489309549331665
Validation loss: 2.0426364143689475

Epoch: 5| Step: 10
Training loss: 2.4769225120544434
Validation loss: 2.0418910135825477

Epoch: 5| Step: 11
Training loss: 1.3956371545791626
Validation loss: 2.0425159682830176

Epoch: 154| Step: 0
Training loss: 1.8535856008529663
Validation loss: 2.045577754577001

Epoch: 5| Step: 1
Training loss: 1.7190090417861938
Validation loss: 2.0491365740696588

Epoch: 5| Step: 2
Training loss: 2.3228695392608643
Validation loss: 2.0435504019260406

Epoch: 5| Step: 3
Training loss: 1.829267144203186
Validation loss: 2.0527966221173606

Epoch: 5| Step: 4
Training loss: 2.0447659492492676
Validation loss: 2.0485290636618934

Epoch: 5| Step: 5
Training loss: 2.3907909393310547
Validation loss: 2.056468442082405

Epoch: 5| Step: 6
Training loss: 2.3587486743927
Validation loss: 2.0556964526573815

Epoch: 5| Step: 7
Training loss: 2.357848644256592
Validation loss: 2.057581807176272

Epoch: 5| Step: 8
Training loss: 1.6115220785140991
Validation loss: 2.0626517136891684

Epoch: 5| Step: 9
Training loss: 1.7516393661499023
Validation loss: 2.0534398357073465

Epoch: 5| Step: 10
Training loss: 2.05442476272583
Validation loss: 2.0540569027264914

Epoch: 5| Step: 11
Training loss: 2.572650194168091
Validation loss: 2.0570710450410843

Epoch: 155| Step: 0
Training loss: 1.4487390518188477
Validation loss: 2.0479950259129205

Epoch: 5| Step: 1
Training loss: 2.1572327613830566
Validation loss: 2.0450894186894097

Epoch: 5| Step: 2
Training loss: 1.5325677394866943
Validation loss: 2.0404729892810187

Epoch: 5| Step: 3
Training loss: 2.16807222366333
Validation loss: 2.041519353787104

Epoch: 5| Step: 4
Training loss: 2.000338077545166
Validation loss: 2.0379540026187897

Epoch: 5| Step: 5
Training loss: 1.888663649559021
Validation loss: 2.038968245188395

Epoch: 5| Step: 6
Training loss: 1.8465389013290405
Validation loss: 2.037995472550392

Epoch: 5| Step: 7
Training loss: 2.225989818572998
Validation loss: 2.0325353840986886

Epoch: 5| Step: 8
Training loss: 1.9510166645050049
Validation loss: 2.034665043155352

Epoch: 5| Step: 9
Training loss: 2.4525721073150635
Validation loss: 2.0178613662719727

Epoch: 5| Step: 10
Training loss: 2.7233688831329346
Validation loss: 2.02836508055528

Epoch: 5| Step: 11
Training loss: 2.8485212326049805
Validation loss: 2.0275346636772156

Epoch: 156| Step: 0
Training loss: 2.251008987426758
Validation loss: 2.0397189259529114

Epoch: 5| Step: 1
Training loss: 1.6846516132354736
Validation loss: 2.025638520717621

Epoch: 5| Step: 2
Training loss: 2.036576986312866
Validation loss: 2.0368432948986688

Epoch: 5| Step: 3
Training loss: 1.5238313674926758
Validation loss: 2.0371380796035132

Epoch: 5| Step: 4
Training loss: 2.372637987136841
Validation loss: 2.0355364133914313

Epoch: 5| Step: 5
Training loss: 1.998726487159729
Validation loss: 2.0350344528754554

Epoch: 5| Step: 6
Training loss: 2.4576587677001953
Validation loss: 2.0396747489770255

Epoch: 5| Step: 7
Training loss: 2.206261157989502
Validation loss: 2.04209237297376

Epoch: 5| Step: 8
Training loss: 1.9706313610076904
Validation loss: 2.043863132596016

Epoch: 5| Step: 9
Training loss: 1.8171230554580688
Validation loss: 2.0495879501104355

Epoch: 5| Step: 10
Training loss: 1.9527212381362915
Validation loss: 2.050975188612938

Epoch: 5| Step: 11
Training loss: 2.3395586013793945
Validation loss: 2.0712741315364838

Epoch: 157| Step: 0
Training loss: 2.038224220275879
Validation loss: 2.074834610025088

Epoch: 5| Step: 1
Training loss: 2.1422324180603027
Validation loss: 2.0830086171627045

Epoch: 5| Step: 2
Training loss: 1.9801372289657593
Validation loss: 2.0694916447003684

Epoch: 5| Step: 3
Training loss: 2.1263644695281982
Validation loss: 2.075949937105179

Epoch: 5| Step: 4
Training loss: 1.6461517810821533
Validation loss: 2.070471669236819

Epoch: 5| Step: 5
Training loss: 1.953778862953186
Validation loss: 2.06616119047006

Epoch: 5| Step: 6
Training loss: 2.042928457260132
Validation loss: 2.055089602867762

Epoch: 5| Step: 7
Training loss: 2.0508949756622314
Validation loss: 2.062498872478803

Epoch: 5| Step: 8
Training loss: 1.7384653091430664
Validation loss: 2.063595021764437

Epoch: 5| Step: 9
Training loss: 2.0675644874572754
Validation loss: 2.0620544652144113

Epoch: 5| Step: 10
Training loss: 2.50998592376709
Validation loss: 2.0728808542092643

Epoch: 5| Step: 11
Training loss: 1.4042541980743408
Validation loss: 2.0782324175039926

Epoch: 158| Step: 0
Training loss: 1.999284029006958
Validation loss: 2.065811723470688

Epoch: 5| Step: 1
Training loss: 2.280078887939453
Validation loss: 2.080529416600863

Epoch: 5| Step: 2
Training loss: 2.3380961418151855
Validation loss: 2.0715819795926413

Epoch: 5| Step: 3
Training loss: 2.1559972763061523
Validation loss: 2.0838741113742194

Epoch: 5| Step: 4
Training loss: 1.8570349216461182
Validation loss: 2.0723570634921393

Epoch: 5| Step: 5
Training loss: 1.634433388710022
Validation loss: 2.0807215670744577

Epoch: 5| Step: 6
Training loss: 2.0084328651428223
Validation loss: 2.0686749517917633

Epoch: 5| Step: 7
Training loss: 2.2805984020233154
Validation loss: 2.06647257010142

Epoch: 5| Step: 8
Training loss: 2.030235767364502
Validation loss: 2.067622184753418

Epoch: 5| Step: 9
Training loss: 1.6359832286834717
Validation loss: 2.056247984369596

Epoch: 5| Step: 10
Training loss: 1.8970855474472046
Validation loss: 2.062055687109629

Epoch: 5| Step: 11
Training loss: 2.5165905952453613
Validation loss: 2.041284297903379

Epoch: 159| Step: 0
Training loss: 2.187324047088623
Validation loss: 2.0548046678304672

Epoch: 5| Step: 1
Training loss: 2.2357420921325684
Validation loss: 2.0538393606742225

Epoch: 5| Step: 2
Training loss: 2.1741466522216797
Validation loss: 2.051923697193464

Epoch: 5| Step: 3
Training loss: 1.769736647605896
Validation loss: 2.0438558210929236

Epoch: 5| Step: 4
Training loss: 1.8941386938095093
Validation loss: 2.0464320133129754

Epoch: 5| Step: 5
Training loss: 1.6725727319717407
Validation loss: 2.052805279692014

Epoch: 5| Step: 6
Training loss: 2.2725155353546143
Validation loss: 2.0523552546898522

Epoch: 5| Step: 7
Training loss: 2.174253463745117
Validation loss: 2.04731015364329

Epoch: 5| Step: 8
Training loss: 1.5096970796585083
Validation loss: 2.0579267740249634

Epoch: 5| Step: 9
Training loss: 1.7484500408172607
Validation loss: 2.0664291779200235

Epoch: 5| Step: 10
Training loss: 2.5772359371185303
Validation loss: 2.056489020586014

Epoch: 5| Step: 11
Training loss: 2.131045341491699
Validation loss: 2.066282734274864

Epoch: 160| Step: 0
Training loss: 2.2743308544158936
Validation loss: 2.062769631544749

Epoch: 5| Step: 1
Training loss: 1.5217379331588745
Validation loss: 2.0545918345451355

Epoch: 5| Step: 2
Training loss: 2.1947641372680664
Validation loss: 2.0574580232302346

Epoch: 5| Step: 3
Training loss: 2.370797872543335
Validation loss: 2.0498015930255256

Epoch: 5| Step: 4
Training loss: 2.1168298721313477
Validation loss: 2.0516511648893356

Epoch: 5| Step: 5
Training loss: 2.515573263168335
Validation loss: 2.038998896876971

Epoch: 5| Step: 6
Training loss: 1.860168218612671
Validation loss: 2.038805236419042

Epoch: 5| Step: 7
Training loss: 1.9119923114776611
Validation loss: 2.04622620344162

Epoch: 5| Step: 8
Training loss: 2.158864974975586
Validation loss: 2.050368453065554

Epoch: 5| Step: 9
Training loss: 2.0043272972106934
Validation loss: 2.054086074233055

Epoch: 5| Step: 10
Training loss: 1.6094833612442017
Validation loss: 2.0523229986429214

Epoch: 5| Step: 11
Training loss: 0.8083356618881226
Validation loss: 2.064085220297178

Epoch: 161| Step: 0
Training loss: 2.173058032989502
Validation loss: 2.0638856887817383

Epoch: 5| Step: 1
Training loss: 1.524841070175171
Validation loss: 2.0730909407138824

Epoch: 5| Step: 2
Training loss: 2.2459170818328857
Validation loss: 2.0795586903889975

Epoch: 5| Step: 3
Training loss: 2.2036614418029785
Validation loss: 2.0636486063400903

Epoch: 5| Step: 4
Training loss: 2.432568311691284
Validation loss: 2.0790241012970605

Epoch: 5| Step: 5
Training loss: 2.1669862270355225
Validation loss: 2.0671731531620026

Epoch: 5| Step: 6
Training loss: 2.035517930984497
Validation loss: 2.061244229475657

Epoch: 5| Step: 7
Training loss: 2.485468626022339
Validation loss: 2.057469899455706

Epoch: 5| Step: 8
Training loss: 1.7031511068344116
Validation loss: 2.0705028673013053

Epoch: 5| Step: 9
Training loss: 1.5573127269744873
Validation loss: 2.0577326516310372

Epoch: 5| Step: 10
Training loss: 2.100684881210327
Validation loss: 2.055903986096382

Epoch: 5| Step: 11
Training loss: 1.639278531074524
Validation loss: 2.0563466052214303

Epoch: 162| Step: 0
Training loss: 2.166830539703369
Validation loss: 2.052644819021225

Epoch: 5| Step: 1
Training loss: 1.704800009727478
Validation loss: 2.058538720011711

Epoch: 5| Step: 2
Training loss: 2.0758798122406006
Validation loss: 2.0661548376083374

Epoch: 5| Step: 3
Training loss: 1.6591533422470093
Validation loss: 2.0770518084367118

Epoch: 5| Step: 4
Training loss: 1.957190752029419
Validation loss: 2.0697279473145804

Epoch: 5| Step: 5
Training loss: 2.6989870071411133
Validation loss: 2.083425298333168

Epoch: 5| Step: 6
Training loss: 1.809261679649353
Validation loss: 2.075398767987887

Epoch: 5| Step: 7
Training loss: 1.850317358970642
Validation loss: 2.073033278187116

Epoch: 5| Step: 8
Training loss: 2.6533403396606445
Validation loss: 2.0574527084827423

Epoch: 5| Step: 9
Training loss: 2.109729290008545
Validation loss: 2.051948885122935

Epoch: 5| Step: 10
Training loss: 1.5559664964675903
Validation loss: 2.0539910147587457

Epoch: 5| Step: 11
Training loss: 2.5412702560424805
Validation loss: 2.0464302549759545

Epoch: 163| Step: 0
Training loss: 2.0500166416168213
Validation loss: 2.0356671114762626

Epoch: 5| Step: 1
Training loss: 1.8491847515106201
Validation loss: 2.037910203138987

Epoch: 5| Step: 2
Training loss: 2.205641984939575
Validation loss: 2.058319295446078

Epoch: 5| Step: 3
Training loss: 2.18119478225708
Validation loss: 2.0492364366849265

Epoch: 5| Step: 4
Training loss: 2.052382469177246
Validation loss: 2.0463403711716333

Epoch: 5| Step: 5
Training loss: 2.156412363052368
Validation loss: 2.0576591193675995

Epoch: 5| Step: 6
Training loss: 2.084291934967041
Validation loss: 2.052658279736837

Epoch: 5| Step: 7
Training loss: 1.5142552852630615
Validation loss: 2.0465441991885505

Epoch: 5| Step: 8
Training loss: 2.325037717819214
Validation loss: 2.0432692070802054

Epoch: 5| Step: 9
Training loss: 2.3335163593292236
Validation loss: 2.050765539209048

Epoch: 5| Step: 10
Training loss: 2.1553196907043457
Validation loss: 2.051699221134186

Epoch: 5| Step: 11
Training loss: 2.80898380279541
Validation loss: 2.0570934116840363

Epoch: 164| Step: 0
Training loss: 2.3562943935394287
Validation loss: 2.0521999994913735

Epoch: 5| Step: 1
Training loss: 1.7541732788085938
Validation loss: 2.052791694800059

Epoch: 5| Step: 2
Training loss: 2.147472858428955
Validation loss: 2.058219457666079

Epoch: 5| Step: 3
Training loss: 2.324434518814087
Validation loss: 2.0690752615531287

Epoch: 5| Step: 4
Training loss: 2.639162063598633
Validation loss: 2.066624959309896

Epoch: 5| Step: 5
Training loss: 1.9214082956314087
Validation loss: 2.051259661714236

Epoch: 5| Step: 6
Training loss: 1.4893262386322021
Validation loss: 2.0504895647366843

Epoch: 5| Step: 7
Training loss: 1.7217050790786743
Validation loss: 2.062459573149681

Epoch: 5| Step: 8
Training loss: 2.600522518157959
Validation loss: 2.050069590409597

Epoch: 5| Step: 9
Training loss: 1.4796396493911743
Validation loss: 2.05522021651268

Epoch: 5| Step: 10
Training loss: 2.1276488304138184
Validation loss: 2.050617054104805

Epoch: 5| Step: 11
Training loss: 1.9410312175750732
Validation loss: 2.053777148326238

Epoch: 165| Step: 0
Training loss: 2.2763895988464355
Validation loss: 2.0561874955892563

Epoch: 5| Step: 1
Training loss: 2.358480453491211
Validation loss: 2.066373328367869

Epoch: 5| Step: 2
Training loss: 1.8510029315948486
Validation loss: 2.059352378050486

Epoch: 5| Step: 3
Training loss: 1.1866921186447144
Validation loss: 2.062179525693258

Epoch: 5| Step: 4
Training loss: 2.219597101211548
Validation loss: 2.060379907488823

Epoch: 5| Step: 5
Training loss: 2.0527331829071045
Validation loss: 2.053208962082863

Epoch: 5| Step: 6
Training loss: 1.9446420669555664
Validation loss: 2.0567815403143563

Epoch: 5| Step: 7
Training loss: 2.0573277473449707
Validation loss: 2.0611781030893326

Epoch: 5| Step: 8
Training loss: 2.1708340644836426
Validation loss: 2.0518395006656647

Epoch: 5| Step: 9
Training loss: 1.7966396808624268
Validation loss: 2.059042697151502

Epoch: 5| Step: 10
Training loss: 2.3913183212280273
Validation loss: 2.0561939477920532

Epoch: 5| Step: 11
Training loss: 1.5917514562606812
Validation loss: 2.062439421812693

Epoch: 166| Step: 0
Training loss: 2.2083213329315186
Validation loss: 2.0638690143823624

Epoch: 5| Step: 1
Training loss: 1.7785565853118896
Validation loss: 2.0592767000198364

Epoch: 5| Step: 2
Training loss: 2.049795627593994
Validation loss: 2.056315769751867

Epoch: 5| Step: 3
Training loss: 2.4738383293151855
Validation loss: 2.0676720241705575

Epoch: 5| Step: 4
Training loss: 2.310518741607666
Validation loss: 2.0684788723786673

Epoch: 5| Step: 5
Training loss: 1.596864938735962
Validation loss: 2.0705209026734033

Epoch: 5| Step: 6
Training loss: 1.990837812423706
Validation loss: 2.0664270222187042

Epoch: 5| Step: 7
Training loss: 2.0113866329193115
Validation loss: 2.06807911892732

Epoch: 5| Step: 8
Training loss: 1.8746960163116455
Validation loss: 2.066772614916166

Epoch: 5| Step: 9
Training loss: 2.1134047508239746
Validation loss: 2.0648681074380875

Epoch: 5| Step: 10
Training loss: 1.9820588827133179
Validation loss: 2.0506354520718255

Epoch: 5| Step: 11
Training loss: 1.8848154544830322
Validation loss: 2.059110606710116

Epoch: 167| Step: 0
Training loss: 2.010648250579834
Validation loss: 2.049322019020716

Epoch: 5| Step: 1
Training loss: 1.4994615316390991
Validation loss: 2.046734541654587

Epoch: 5| Step: 2
Training loss: 1.7674293518066406
Validation loss: 2.0474488039811454

Epoch: 5| Step: 3
Training loss: 2.2690272331237793
Validation loss: 2.047961508234342

Epoch: 5| Step: 4
Training loss: 2.2026898860931396
Validation loss: 2.0604025423526764

Epoch: 5| Step: 5
Training loss: 2.048085927963257
Validation loss: 2.0676492005586624

Epoch: 5| Step: 6
Training loss: 1.6330921649932861
Validation loss: 2.06222132841746

Epoch: 5| Step: 7
Training loss: 2.152012586593628
Validation loss: 2.0686040868361792

Epoch: 5| Step: 8
Training loss: 1.9525429010391235
Validation loss: 2.0665048956871033

Epoch: 5| Step: 9
Training loss: 2.2694246768951416
Validation loss: 2.0790354112784066

Epoch: 5| Step: 10
Training loss: 1.9971768856048584
Validation loss: 2.077449157834053

Epoch: 5| Step: 11
Training loss: 3.491476058959961
Validation loss: 2.072656442721685

Epoch: 168| Step: 0
Training loss: 1.779484510421753
Validation loss: 2.072070906559626

Epoch: 5| Step: 1
Training loss: 2.1050963401794434
Validation loss: 2.0624577005704245

Epoch: 5| Step: 2
Training loss: 1.7922980785369873
Validation loss: 2.058670630057653

Epoch: 5| Step: 3
Training loss: 2.5781772136688232
Validation loss: 2.0769691417614617

Epoch: 5| Step: 4
Training loss: 1.9263267517089844
Validation loss: 2.0728479524453483

Epoch: 5| Step: 5
Training loss: 2.1026151180267334
Validation loss: 2.0583086013793945

Epoch: 5| Step: 6
Training loss: 1.5604315996170044
Validation loss: 2.0569797654946647

Epoch: 5| Step: 7
Training loss: 2.4738881587982178
Validation loss: 2.057161713639895

Epoch: 5| Step: 8
Training loss: 1.6363742351531982
Validation loss: 2.050495723883311

Epoch: 5| Step: 9
Training loss: 2.2005300521850586
Validation loss: 2.0551600555578866

Epoch: 5| Step: 10
Training loss: 1.8855371475219727
Validation loss: 2.0595815728108087

Epoch: 5| Step: 11
Training loss: 2.017793655395508
Validation loss: 2.056285639603933

Epoch: 169| Step: 0
Training loss: 1.7054942846298218
Validation loss: 2.0691770364840827

Epoch: 5| Step: 1
Training loss: 2.112351894378662
Validation loss: 2.052070011695226

Epoch: 5| Step: 2
Training loss: 1.910414457321167
Validation loss: 2.0736917555332184

Epoch: 5| Step: 3
Training loss: 2.588289976119995
Validation loss: 2.0675204445918403

Epoch: 5| Step: 4
Training loss: 2.472299098968506
Validation loss: 2.0735594034194946

Epoch: 5| Step: 5
Training loss: 2.4209787845611572
Validation loss: 2.0651770482460656

Epoch: 5| Step: 6
Training loss: 2.019160509109497
Validation loss: 2.074908286333084

Epoch: 5| Step: 7
Training loss: 1.8086111545562744
Validation loss: 2.059882899125417

Epoch: 5| Step: 8
Training loss: 1.7396318912506104
Validation loss: 2.064082066218058

Epoch: 5| Step: 9
Training loss: 1.8144524097442627
Validation loss: 2.067849005262057

Epoch: 5| Step: 10
Training loss: 1.5508447885513306
Validation loss: 2.061091730991999

Epoch: 5| Step: 11
Training loss: 1.6154900789260864
Validation loss: 2.058282509446144

Epoch: 170| Step: 0
Training loss: 2.223853349685669
Validation loss: 2.0616709887981415

Epoch: 5| Step: 1
Training loss: 1.9728038311004639
Validation loss: 2.069610506296158

Epoch: 5| Step: 2
Training loss: 1.8956127166748047
Validation loss: 2.0718652407328286

Epoch: 5| Step: 3
Training loss: 1.9237728118896484
Validation loss: 2.0653660744428635

Epoch: 5| Step: 4
Training loss: 1.4253783226013184
Validation loss: 2.0922458122173944

Epoch: 5| Step: 5
Training loss: 2.6454224586486816
Validation loss: 2.0702439496914544

Epoch: 5| Step: 6
Training loss: 2.3148984909057617
Validation loss: 2.074890931447347

Epoch: 5| Step: 7
Training loss: 1.979414701461792
Validation loss: 2.0664820075035095

Epoch: 5| Step: 8
Training loss: 1.86874520778656
Validation loss: 2.0667613397041955

Epoch: 5| Step: 9
Training loss: 1.6712576150894165
Validation loss: 2.0636789898077645

Epoch: 5| Step: 10
Training loss: 1.9852945804595947
Validation loss: 2.0512123703956604

Epoch: 5| Step: 11
Training loss: 1.9396836757659912
Validation loss: 2.0530579884847007

Epoch: 171| Step: 0
Training loss: 2.035646438598633
Validation loss: 2.0453018645445504

Epoch: 5| Step: 1
Training loss: 2.631037950515747
Validation loss: 2.053241024414698

Epoch: 5| Step: 2
Training loss: 2.067554473876953
Validation loss: 2.055235336224238

Epoch: 5| Step: 3
Training loss: 1.931273102760315
Validation loss: 2.0600957373778024

Epoch: 5| Step: 4
Training loss: 1.5693094730377197
Validation loss: 2.0546979705492654

Epoch: 5| Step: 5
Training loss: 1.7362079620361328
Validation loss: 2.058919628461202

Epoch: 5| Step: 6
Training loss: 1.6075903177261353
Validation loss: 2.0531678895155587

Epoch: 5| Step: 7
Training loss: 2.016462564468384
Validation loss: 2.0639865696430206

Epoch: 5| Step: 8
Training loss: 2.1129298210144043
Validation loss: 2.0612559666236243

Epoch: 5| Step: 9
Training loss: 2.3256847858428955
Validation loss: 2.055107295513153

Epoch: 5| Step: 10
Training loss: 1.9068491458892822
Validation loss: 2.060483142733574

Epoch: 5| Step: 11
Training loss: 1.5737061500549316
Validation loss: 2.0814586679140725

Epoch: 172| Step: 0
Training loss: 1.8016411066055298
Validation loss: 2.0766694098711014

Epoch: 5| Step: 1
Training loss: 2.2732911109924316
Validation loss: 2.084097678462664

Epoch: 5| Step: 2
Training loss: 2.0261738300323486
Validation loss: 2.090749035278956

Epoch: 5| Step: 3
Training loss: 2.4942538738250732
Validation loss: 2.082003131508827

Epoch: 5| Step: 4
Training loss: 1.873085379600525
Validation loss: 2.089847683906555

Epoch: 5| Step: 5
Training loss: 1.9307705163955688
Validation loss: 2.0839424282312393

Epoch: 5| Step: 6
Training loss: 1.6753685474395752
Validation loss: 2.0852645536263785

Epoch: 5| Step: 7
Training loss: 2.171825885772705
Validation loss: 2.0791508853435516

Epoch: 5| Step: 8
Training loss: 2.2441906929016113
Validation loss: 2.071775327126185

Epoch: 5| Step: 9
Training loss: 1.8579633235931396
Validation loss: 2.078732877969742

Epoch: 5| Step: 10
Training loss: 1.6539167165756226
Validation loss: 2.0641435782114663

Epoch: 5| Step: 11
Training loss: 1.5500630140304565
Validation loss: 2.065184404452642

Epoch: 173| Step: 0
Training loss: 1.7401880025863647
Validation loss: 2.0586942235628762

Epoch: 5| Step: 1
Training loss: 1.3925012350082397
Validation loss: 2.0689273377259574

Epoch: 5| Step: 2
Training loss: 2.2985033988952637
Validation loss: 2.05756676197052

Epoch: 5| Step: 3
Training loss: 1.8929239511489868
Validation loss: 2.0609604567289352

Epoch: 5| Step: 4
Training loss: 2.375880479812622
Validation loss: 2.0637001196543374

Epoch: 5| Step: 5
Training loss: 2.0645341873168945
Validation loss: 2.066914846499761

Epoch: 5| Step: 6
Training loss: 1.926782250404358
Validation loss: 2.065810054540634

Epoch: 5| Step: 7
Training loss: 1.9291940927505493
Validation loss: 2.0615282505750656

Epoch: 5| Step: 8
Training loss: 1.8020833730697632
Validation loss: 2.08130019903183

Epoch: 5| Step: 9
Training loss: 2.0540339946746826
Validation loss: 2.0896509339412055

Epoch: 5| Step: 10
Training loss: 2.300802707672119
Validation loss: 2.095881079634031

Epoch: 5| Step: 11
Training loss: 2.1962497234344482
Validation loss: 2.1040128618478775

Epoch: 174| Step: 0
Training loss: 2.1923718452453613
Validation loss: 2.079307109117508

Epoch: 5| Step: 1
Training loss: 2.071572780609131
Validation loss: 2.075905288259188

Epoch: 5| Step: 2
Training loss: 1.6942840814590454
Validation loss: 2.0690857619047165

Epoch: 5| Step: 3
Training loss: 1.8858047723770142
Validation loss: 2.0560125211874642

Epoch: 5| Step: 4
Training loss: 2.175015926361084
Validation loss: 2.0516459892193475

Epoch: 5| Step: 5
Training loss: 1.9194406270980835
Validation loss: 2.0481358418862023

Epoch: 5| Step: 6
Training loss: 2.347069025039673
Validation loss: 2.03909004231294

Epoch: 5| Step: 7
Training loss: 2.4910502433776855
Validation loss: 2.042434165875117

Epoch: 5| Step: 8
Training loss: 2.0644545555114746
Validation loss: 2.0454538613557816

Epoch: 5| Step: 9
Training loss: 1.6202647686004639
Validation loss: 2.0455286502838135

Epoch: 5| Step: 10
Training loss: 1.5510164499282837
Validation loss: 2.044516240557035

Epoch: 5| Step: 11
Training loss: 2.6588096618652344
Validation loss: 2.047582358121872

Epoch: 175| Step: 0
Training loss: 1.8732866048812866
Validation loss: 2.042969360947609

Epoch: 5| Step: 1
Training loss: 1.6355626583099365
Validation loss: 2.0453666200240455

Epoch: 5| Step: 2
Training loss: 1.9762933254241943
Validation loss: 2.0525811662276587

Epoch: 5| Step: 3
Training loss: 1.825347900390625
Validation loss: 2.0502220392227173

Epoch: 5| Step: 4
Training loss: 1.7615025043487549
Validation loss: 2.0501112838586173

Epoch: 5| Step: 5
Training loss: 2.0235750675201416
Validation loss: 2.04161673784256

Epoch: 5| Step: 6
Training loss: 2.5526785850524902
Validation loss: 2.06493670741717

Epoch: 5| Step: 7
Training loss: 1.496622085571289
Validation loss: 2.081327110528946

Epoch: 5| Step: 8
Training loss: 2.171947717666626
Validation loss: 2.0961429675420127

Epoch: 5| Step: 9
Training loss: 2.312990665435791
Validation loss: 2.0956211437781653

Epoch: 5| Step: 10
Training loss: 2.313182830810547
Validation loss: 2.0954003781080246

Epoch: 5| Step: 11
Training loss: 2.6507160663604736
Validation loss: 2.104104300340017

Epoch: 176| Step: 0
Training loss: 2.1941027641296387
Validation loss: 2.0736353198687234

Epoch: 5| Step: 1
Training loss: 2.0752804279327393
Validation loss: 2.0750477264324823

Epoch: 5| Step: 2
Training loss: 2.03308367729187
Validation loss: 2.060460180044174

Epoch: 5| Step: 3
Training loss: 1.5953668355941772
Validation loss: 2.054203992088636

Epoch: 5| Step: 4
Training loss: 2.0402157306671143
Validation loss: 2.0696035971244178

Epoch: 5| Step: 5
Training loss: 1.865600347518921
Validation loss: 2.064064641793569

Epoch: 5| Step: 6
Training loss: 2.3256635665893555
Validation loss: 2.0517676870028176

Epoch: 5| Step: 7
Training loss: 1.8778095245361328
Validation loss: 2.058684453368187

Epoch: 5| Step: 8
Training loss: 2.0116324424743652
Validation loss: 2.051124374071757

Epoch: 5| Step: 9
Training loss: 1.739082932472229
Validation loss: 2.0519151339928308

Epoch: 5| Step: 10
Training loss: 2.1739165782928467
Validation loss: 2.06242128709952

Epoch: 5| Step: 11
Training loss: 1.9850564002990723
Validation loss: 2.0642496049404144

Epoch: 177| Step: 0
Training loss: 2.2392570972442627
Validation loss: 2.071114957332611

Epoch: 5| Step: 1
Training loss: 1.6781091690063477
Validation loss: 2.0708503474791846

Epoch: 5| Step: 2
Training loss: 1.7028402090072632
Validation loss: 2.0702007164557776

Epoch: 5| Step: 3
Training loss: 1.9193121194839478
Validation loss: 2.080827002724012

Epoch: 5| Step: 4
Training loss: 1.7934623956680298
Validation loss: 2.0752675980329514

Epoch: 5| Step: 5
Training loss: 1.7456296682357788
Validation loss: 2.0756248434384665

Epoch: 5| Step: 6
Training loss: 1.7262405157089233
Validation loss: 2.0919623523950577

Epoch: 5| Step: 7
Training loss: 2.2944750785827637
Validation loss: 2.0927909910678864

Epoch: 5| Step: 8
Training loss: 2.3701202869415283
Validation loss: 2.078099250793457

Epoch: 5| Step: 9
Training loss: 2.033188581466675
Validation loss: 2.0873943666617074

Epoch: 5| Step: 10
Training loss: 2.2412822246551514
Validation loss: 2.0767129957675934

Epoch: 5| Step: 11
Training loss: 2.083388328552246
Validation loss: 2.070178439219793

Epoch: 178| Step: 0
Training loss: 2.0754947662353516
Validation loss: 2.078512022892634

Epoch: 5| Step: 1
Training loss: 1.6926084756851196
Validation loss: 2.0712056756019592

Epoch: 5| Step: 2
Training loss: 2.2802882194519043
Validation loss: 2.0689268509546914

Epoch: 5| Step: 3
Training loss: 2.2016372680664062
Validation loss: 2.067835475007693

Epoch: 5| Step: 4
Training loss: 2.106640100479126
Validation loss: 2.076525871952375

Epoch: 5| Step: 5
Training loss: 1.6363788843154907
Validation loss: 2.078321079413096

Epoch: 5| Step: 6
Training loss: 2.3548221588134766
Validation loss: 2.074085275332133

Epoch: 5| Step: 7
Training loss: 1.6393413543701172
Validation loss: 2.0896311352650323

Epoch: 5| Step: 8
Training loss: 1.5967636108398438
Validation loss: 2.0905864437421164

Epoch: 5| Step: 9
Training loss: 1.7241203784942627
Validation loss: 2.0908176402250924

Epoch: 5| Step: 10
Training loss: 2.3377156257629395
Validation loss: 2.093520070115725

Epoch: 5| Step: 11
Training loss: 2.4450058937072754
Validation loss: 2.0713929335276284

Epoch: 179| Step: 0
Training loss: 1.278274416923523
Validation loss: 2.0849794348080954

Epoch: 5| Step: 1
Training loss: 1.6512062549591064
Validation loss: 2.094367027282715

Epoch: 5| Step: 2
Training loss: 1.7307720184326172
Validation loss: 2.097992161909739

Epoch: 5| Step: 3
Training loss: 2.747250556945801
Validation loss: 2.0947773853937783

Epoch: 5| Step: 4
Training loss: 2.2547411918640137
Validation loss: 2.106884797414144

Epoch: 5| Step: 5
Training loss: 1.9871585369110107
Validation loss: 2.098127861817678

Epoch: 5| Step: 6
Training loss: 2.0328426361083984
Validation loss: 2.083043416341146

Epoch: 5| Step: 7
Training loss: 2.1204030513763428
Validation loss: 2.064947242538134

Epoch: 5| Step: 8
Training loss: 2.2751688957214355
Validation loss: 2.0727846026420593

Epoch: 5| Step: 9
Training loss: 1.9776862859725952
Validation loss: 2.063782279690107

Epoch: 5| Step: 10
Training loss: 1.7958955764770508
Validation loss: 2.0685700327157974

Epoch: 5| Step: 11
Training loss: 1.1966782808303833
Validation loss: 2.067083323995272

Epoch: 180| Step: 0
Training loss: 1.6493390798568726
Validation loss: 2.062052766482035

Epoch: 5| Step: 1
Training loss: 1.959363579750061
Validation loss: 2.069949080546697

Epoch: 5| Step: 2
Training loss: 2.384584903717041
Validation loss: 2.0836855272452035

Epoch: 5| Step: 3
Training loss: 2.2719054222106934
Validation loss: 2.0705038805802665

Epoch: 5| Step: 4
Training loss: 1.7666295766830444
Validation loss: 2.0741952508687973

Epoch: 5| Step: 5
Training loss: 1.737178087234497
Validation loss: 2.077109823624293

Epoch: 5| Step: 6
Training loss: 2.344320297241211
Validation loss: 2.077572529514631

Epoch: 5| Step: 7
Training loss: 2.0414960384368896
Validation loss: 2.0952701419591904

Epoch: 5| Step: 8
Training loss: 1.8733609914779663
Validation loss: 2.1015202701091766

Epoch: 5| Step: 9
Training loss: 1.5976451635360718
Validation loss: 2.0957543899615607

Epoch: 5| Step: 10
Training loss: 1.8986904621124268
Validation loss: 2.103660141428312

Epoch: 5| Step: 11
Training loss: 2.0902175903320312
Validation loss: 2.1004212498664856

Epoch: 181| Step: 0
Training loss: 1.9336475133895874
Validation loss: 2.095721830924352

Epoch: 5| Step: 1
Training loss: 2.405219316482544
Validation loss: 2.0951917121807733

Epoch: 5| Step: 2
Training loss: 2.545861005783081
Validation loss: 2.1005707532167435

Epoch: 5| Step: 3
Training loss: 1.0193312168121338
Validation loss: 2.086970791220665

Epoch: 5| Step: 4
Training loss: 1.820586919784546
Validation loss: 2.088493158419927

Epoch: 5| Step: 5
Training loss: 2.2638206481933594
Validation loss: 2.0933073411385217

Epoch: 5| Step: 6
Training loss: 1.5036935806274414
Validation loss: 2.078690931200981

Epoch: 5| Step: 7
Training loss: 2.453282594680786
Validation loss: 2.085032989581426

Epoch: 5| Step: 8
Training loss: 2.055266857147217
Validation loss: 2.0867404292027154

Epoch: 5| Step: 9
Training loss: 1.8814442157745361
Validation loss: 2.072755287090937

Epoch: 5| Step: 10
Training loss: 1.6839786767959595
Validation loss: 2.0809412747621536

Epoch: 5| Step: 11
Training loss: 2.0557494163513184
Validation loss: 2.081960548957189

Epoch: 182| Step: 0
Training loss: 2.292625665664673
Validation loss: 2.076606343189875

Epoch: 5| Step: 1
Training loss: 2.3866024017333984
Validation loss: 2.0890018343925476

Epoch: 5| Step: 2
Training loss: 1.7721933126449585
Validation loss: 2.1009048173824945

Epoch: 5| Step: 3
Training loss: 1.9762433767318726
Validation loss: 2.08565720419089

Epoch: 5| Step: 4
Training loss: 2.4005684852600098
Validation loss: 2.102182239294052

Epoch: 5| Step: 5
Training loss: 1.8963388204574585
Validation loss: 2.1133058816194534

Epoch: 5| Step: 6
Training loss: 1.7312586307525635
Validation loss: 2.101803625623385

Epoch: 5| Step: 7
Training loss: 1.8598251342773438
Validation loss: 2.0893090963363647

Epoch: 5| Step: 8
Training loss: 1.5729844570159912
Validation loss: 2.0975861797730126

Epoch: 5| Step: 9
Training loss: 1.9198678731918335
Validation loss: 2.085980316003164

Epoch: 5| Step: 10
Training loss: 1.719972014427185
Validation loss: 2.092081924279531

Epoch: 5| Step: 11
Training loss: 2.53273868560791
Validation loss: 2.097846398750941

Epoch: 183| Step: 0
Training loss: 2.277566909790039
Validation loss: 2.0692682613929114

Epoch: 5| Step: 1
Training loss: 2.354714870452881
Validation loss: 2.0686177561680474

Epoch: 5| Step: 2
Training loss: 2.2626709938049316
Validation loss: 2.076119378209114

Epoch: 5| Step: 3
Training loss: 1.6591888666152954
Validation loss: 2.0695186406373978

Epoch: 5| Step: 4
Training loss: 2.427633762359619
Validation loss: 2.0495578149954476

Epoch: 5| Step: 5
Training loss: 2.001551866531372
Validation loss: 2.0548627227544785

Epoch: 5| Step: 6
Training loss: 1.7794888019561768
Validation loss: 2.052731364965439

Epoch: 5| Step: 7
Training loss: 1.622134804725647
Validation loss: 2.063915620247523

Epoch: 5| Step: 8
Training loss: 1.805459976196289
Validation loss: 2.0639852533737817

Epoch: 5| Step: 9
Training loss: 1.4646036624908447
Validation loss: 2.057301009694735

Epoch: 5| Step: 10
Training loss: 2.0774195194244385
Validation loss: 2.060601368546486

Epoch: 5| Step: 11
Training loss: 2.105100393295288
Validation loss: 2.0572559436162314

Epoch: 184| Step: 0
Training loss: 1.7028957605361938
Validation loss: 2.062455808122953

Epoch: 5| Step: 1
Training loss: 1.7432682514190674
Validation loss: 2.0597890416781106

Epoch: 5| Step: 2
Training loss: 2.5550878047943115
Validation loss: 2.0731180757284164

Epoch: 5| Step: 3
Training loss: 1.8485157489776611
Validation loss: 2.0629414518674216

Epoch: 5| Step: 4
Training loss: 2.149954319000244
Validation loss: 2.066953028241793

Epoch: 5| Step: 5
Training loss: 1.9142239093780518
Validation loss: 2.0756375193595886

Epoch: 5| Step: 6
Training loss: 1.6731197834014893
Validation loss: 2.0755505909522376

Epoch: 5| Step: 7
Training loss: 2.2261104583740234
Validation loss: 2.0630186100800834

Epoch: 5| Step: 8
Training loss: 2.134019374847412
Validation loss: 2.0648090541362762

Epoch: 5| Step: 9
Training loss: 2.1300292015075684
Validation loss: 2.0817599842945733

Epoch: 5| Step: 10
Training loss: 1.4656007289886475
Validation loss: 2.076365520556768

Epoch: 5| Step: 11
Training loss: 2.5297329425811768
Validation loss: 2.096137523651123

Epoch: 185| Step: 0
Training loss: 1.988279938697815
Validation loss: 2.0829469362894693

Epoch: 5| Step: 1
Training loss: 1.8745390176773071
Validation loss: 2.0968084037303925

Epoch: 5| Step: 2
Training loss: 2.021014451980591
Validation loss: 2.098368470867475

Epoch: 5| Step: 3
Training loss: 1.8516521453857422
Validation loss: 2.0936254958311715

Epoch: 5| Step: 4
Training loss: 1.9196971654891968
Validation loss: 2.086581935485204

Epoch: 5| Step: 5
Training loss: 1.7165567874908447
Validation loss: 2.0841719110806785

Epoch: 5| Step: 6
Training loss: 1.9451125860214233
Validation loss: 2.0824491530656815

Epoch: 5| Step: 7
Training loss: 2.490108013153076
Validation loss: 2.086112086971601

Epoch: 5| Step: 8
Training loss: 1.6793540716171265
Validation loss: 2.083711544672648

Epoch: 5| Step: 9
Training loss: 2.0125644207000732
Validation loss: 2.0783647497495017

Epoch: 5| Step: 10
Training loss: 2.129870891571045
Validation loss: 2.0745472659667334

Epoch: 5| Step: 11
Training loss: 1.4405314922332764
Validation loss: 2.0815566132465997

Epoch: 186| Step: 0
Training loss: 1.4745652675628662
Validation loss: 2.0837129751841226

Epoch: 5| Step: 1
Training loss: 1.5781397819519043
Validation loss: 2.0780987987915673

Epoch: 5| Step: 2
Training loss: 1.8178441524505615
Validation loss: 2.07774385313193

Epoch: 5| Step: 3
Training loss: 2.2615761756896973
Validation loss: 2.096359113852183

Epoch: 5| Step: 4
Training loss: 2.008863925933838
Validation loss: 2.0856179893016815

Epoch: 5| Step: 5
Training loss: 2.3822758197784424
Validation loss: 2.084550326069196

Epoch: 5| Step: 6
Training loss: 1.9440343379974365
Validation loss: 2.0643622428178787

Epoch: 5| Step: 7
Training loss: 2.2637016773223877
Validation loss: 2.0908506959676743

Epoch: 5| Step: 8
Training loss: 2.213359832763672
Validation loss: 2.093194847305616

Epoch: 5| Step: 9
Training loss: 1.5597089529037476
Validation loss: 2.0939721862475076

Epoch: 5| Step: 10
Training loss: 2.018233060836792
Validation loss: 2.0851139773925147

Epoch: 5| Step: 11
Training loss: 2.301558017730713
Validation loss: 2.094857777158419

Epoch: 187| Step: 0
Training loss: 2.0171260833740234
Validation loss: 2.0907942950725555

Epoch: 5| Step: 1
Training loss: 1.5555006265640259
Validation loss: 2.097233364979426

Epoch: 5| Step: 2
Training loss: 1.7904436588287354
Validation loss: 2.094531148672104

Epoch: 5| Step: 3
Training loss: 2.0314555168151855
Validation loss: 2.0858160704374313

Epoch: 5| Step: 4
Training loss: 1.5826622247695923
Validation loss: 2.0856466541687646

Epoch: 5| Step: 5
Training loss: 2.2083756923675537
Validation loss: 2.0904018779595694

Epoch: 5| Step: 6
Training loss: 2.383362293243408
Validation loss: 2.0790173014005027

Epoch: 5| Step: 7
Training loss: 1.5391579866409302
Validation loss: 2.084989791115125

Epoch: 5| Step: 8
Training loss: 2.1753220558166504
Validation loss: 2.0898975233236947

Epoch: 5| Step: 9
Training loss: 1.6860201358795166
Validation loss: 2.095389445622762

Epoch: 5| Step: 10
Training loss: 2.314541816711426
Validation loss: 2.0948141117890677

Epoch: 5| Step: 11
Training loss: 2.182811975479126
Validation loss: 2.097027912735939

Epoch: 188| Step: 0
Training loss: 1.9174550771713257
Validation loss: 2.096715117494265

Epoch: 5| Step: 1
Training loss: 1.7172152996063232
Validation loss: 2.1016311844189963

Epoch: 5| Step: 2
Training loss: 2.110227346420288
Validation loss: 2.0846899648507438

Epoch: 5| Step: 3
Training loss: 2.18225359916687
Validation loss: 2.0843107054630914

Epoch: 5| Step: 4
Training loss: 2.010643720626831
Validation loss: 2.09476275742054

Epoch: 5| Step: 5
Training loss: 1.9969574213027954
Validation loss: 2.08677975833416

Epoch: 5| Step: 6
Training loss: 1.2701817750930786
Validation loss: 2.083193192879359

Epoch: 5| Step: 7
Training loss: 2.1591758728027344
Validation loss: 2.091018259525299

Epoch: 5| Step: 8
Training loss: 1.7437833547592163
Validation loss: 2.095288713773092

Epoch: 5| Step: 9
Training loss: 2.212639331817627
Validation loss: 2.0988274017969766

Epoch: 5| Step: 10
Training loss: 1.875797986984253
Validation loss: 2.090016151467959

Epoch: 5| Step: 11
Training loss: 2.672201633453369
Validation loss: 2.0933668414751687

Epoch: 189| Step: 0
Training loss: 1.8684093952178955
Validation loss: 2.0796157717704773

Epoch: 5| Step: 1
Training loss: 1.310075283050537
Validation loss: 2.0780373215675354

Epoch: 5| Step: 2
Training loss: 1.7532193660736084
Validation loss: 2.090100129445394

Epoch: 5| Step: 3
Training loss: 1.629071831703186
Validation loss: 2.08893812696139

Epoch: 5| Step: 4
Training loss: 1.9543941020965576
Validation loss: 2.0862349470456443

Epoch: 5| Step: 5
Training loss: 2.076932907104492
Validation loss: 2.105261132121086

Epoch: 5| Step: 6
Training loss: 1.8230289220809937
Validation loss: 2.0936707307895026

Epoch: 5| Step: 7
Training loss: 2.5403213500976562
Validation loss: 2.0960615972677865

Epoch: 5| Step: 8
Training loss: 1.7441715002059937
Validation loss: 2.0957048485676446

Epoch: 5| Step: 9
Training loss: 1.989131212234497
Validation loss: 2.1107994467020035

Epoch: 5| Step: 10
Training loss: 2.5749778747558594
Validation loss: 2.106377045313517

Epoch: 5| Step: 11
Training loss: 1.5835537910461426
Validation loss: 2.108780692021052

Epoch: 190| Step: 0
Training loss: 2.1185619831085205
Validation loss: 2.0901877035697303

Epoch: 5| Step: 1
Training loss: 1.9883613586425781
Validation loss: 2.109433948993683

Epoch: 5| Step: 2
Training loss: 2.265784978866577
Validation loss: 2.1100164453188577

Epoch: 5| Step: 3
Training loss: 2.3398871421813965
Validation loss: 2.1070303271214166

Epoch: 5| Step: 4
Training loss: 2.009483814239502
Validation loss: 2.099687844514847

Epoch: 5| Step: 5
Training loss: 2.0033326148986816
Validation loss: 2.0876631488402686

Epoch: 5| Step: 6
Training loss: 1.7287328243255615
Validation loss: 2.074573586384455

Epoch: 5| Step: 7
Training loss: 1.6255607604980469
Validation loss: 2.0791575660308204

Epoch: 5| Step: 8
Training loss: 1.6317037343978882
Validation loss: 2.0691203474998474

Epoch: 5| Step: 9
Training loss: 2.1332004070281982
Validation loss: 2.0710938771565757

Epoch: 5| Step: 10
Training loss: 2.2374749183654785
Validation loss: 2.078087975581487

Epoch: 5| Step: 11
Training loss: 1.8643016815185547
Validation loss: 2.0702404181162515

Epoch: 191| Step: 0
Training loss: 2.0572686195373535
Validation loss: 2.077885846296946

Epoch: 5| Step: 1
Training loss: 1.7516462802886963
Validation loss: 2.0895590583483377

Epoch: 5| Step: 2
Training loss: 1.548128366470337
Validation loss: 2.091089189052582

Epoch: 5| Step: 3
Training loss: 2.0162150859832764
Validation loss: 2.1085224052270255

Epoch: 5| Step: 4
Training loss: 2.156742811203003
Validation loss: 2.1001062095165253

Epoch: 5| Step: 5
Training loss: 2.4446702003479004
Validation loss: 2.1086309800545373

Epoch: 5| Step: 6
Training loss: 1.4382575750350952
Validation loss: 2.0959429095188775

Epoch: 5| Step: 7
Training loss: 1.7735522985458374
Validation loss: 2.1053639849027

Epoch: 5| Step: 8
Training loss: 2.0156121253967285
Validation loss: 2.0924173494180045

Epoch: 5| Step: 9
Training loss: 1.7655436992645264
Validation loss: 2.0864719102780023

Epoch: 5| Step: 10
Training loss: 2.1379313468933105
Validation loss: 2.0928933918476105

Epoch: 5| Step: 11
Training loss: 2.5185017585754395
Validation loss: 2.1011835436026254

Epoch: 192| Step: 0
Training loss: 1.5671262741088867
Validation loss: 2.108903338511785

Epoch: 5| Step: 1
Training loss: 2.2161784172058105
Validation loss: 2.1116613944371543

Epoch: 5| Step: 2
Training loss: 1.7114160060882568
Validation loss: 2.1182813396056495

Epoch: 5| Step: 3
Training loss: 2.485835552215576
Validation loss: 2.104576130708059

Epoch: 5| Step: 4
Training loss: 1.8211145401000977
Validation loss: 2.114259878794352

Epoch: 5| Step: 5
Training loss: 2.200519323348999
Validation loss: 2.095676397283872

Epoch: 5| Step: 6
Training loss: 1.510884404182434
Validation loss: 2.09726420044899

Epoch: 5| Step: 7
Training loss: 1.7317237854003906
Validation loss: 2.100417892138163

Epoch: 5| Step: 8
Training loss: 2.1347477436065674
Validation loss: 2.0855053712924323

Epoch: 5| Step: 9
Training loss: 2.0357019901275635
Validation loss: 2.075122684240341

Epoch: 5| Step: 10
Training loss: 1.659817099571228
Validation loss: 2.094997227191925

Epoch: 5| Step: 11
Training loss: 2.6584219932556152
Validation loss: 2.0903321554263434

Epoch: 193| Step: 0
Training loss: 1.8233835697174072
Validation loss: 2.096860870718956

Epoch: 5| Step: 1
Training loss: 1.6140015125274658
Validation loss: 2.0941197872161865

Epoch: 5| Step: 2
Training loss: 1.5736998319625854
Validation loss: 2.093150625626246

Epoch: 5| Step: 3
Training loss: 1.998499870300293
Validation loss: 2.0990771849950156

Epoch: 5| Step: 4
Training loss: 2.425556182861328
Validation loss: 2.10601843893528

Epoch: 5| Step: 5
Training loss: 2.3253045082092285
Validation loss: 2.1113462348779044

Epoch: 5| Step: 6
Training loss: 1.8125278949737549
Validation loss: 2.084074541926384

Epoch: 5| Step: 7
Training loss: 2.188011884689331
Validation loss: 2.106899326046308

Epoch: 5| Step: 8
Training loss: 1.3754184246063232
Validation loss: 2.105386217435201

Epoch: 5| Step: 9
Training loss: 1.5591843128204346
Validation loss: 2.1022315671046576

Epoch: 5| Step: 10
Training loss: 2.623734712600708
Validation loss: 2.094033643603325

Epoch: 5| Step: 11
Training loss: 2.5976457595825195
Validation loss: 2.07517246901989

Epoch: 194| Step: 0
Training loss: 2.1223528385162354
Validation loss: 2.088778575261434

Epoch: 5| Step: 1
Training loss: 1.092138648033142
Validation loss: 2.069230630993843

Epoch: 5| Step: 2
Training loss: 2.162414073944092
Validation loss: 2.0875579118728638

Epoch: 5| Step: 3
Training loss: 1.2882201671600342
Validation loss: 2.091728831330935

Epoch: 5| Step: 4
Training loss: 2.244020700454712
Validation loss: 2.078048417965571

Epoch: 5| Step: 5
Training loss: 2.026876449584961
Validation loss: 2.084124823411306

Epoch: 5| Step: 6
Training loss: 1.6269454956054688
Validation loss: 2.083709865808487

Epoch: 5| Step: 7
Training loss: 1.9570471048355103
Validation loss: 2.066704491774241

Epoch: 5| Step: 8
Training loss: 2.110222578048706
Validation loss: 2.0845677852630615

Epoch: 5| Step: 9
Training loss: 2.5539917945861816
Validation loss: 2.0772989243268967

Epoch: 5| Step: 10
Training loss: 2.260282039642334
Validation loss: 2.0773385912179947

Epoch: 5| Step: 11
Training loss: 1.862375259399414
Validation loss: 2.0826039413611093

Epoch: 195| Step: 0
Training loss: 1.6628916263580322
Validation loss: 2.083767995238304

Epoch: 5| Step: 1
Training loss: 2.0426108837127686
Validation loss: 2.0878452012936273

Epoch: 5| Step: 2
Training loss: 2.102099657058716
Validation loss: 2.087658147017161

Epoch: 5| Step: 3
Training loss: 1.9008556604385376
Validation loss: 2.081570322314898

Epoch: 5| Step: 4
Training loss: 2.332709550857544
Validation loss: 2.0810301204522452

Epoch: 5| Step: 5
Training loss: 1.5785691738128662
Validation loss: 2.075797120730082

Epoch: 5| Step: 6
Training loss: 2.062300205230713
Validation loss: 2.0857096115748086

Epoch: 5| Step: 7
Training loss: 2.1587491035461426
Validation loss: 2.0818724036216736

Epoch: 5| Step: 8
Training loss: 1.580586314201355
Validation loss: 2.0693955967823663

Epoch: 5| Step: 9
Training loss: 1.441672682762146
Validation loss: 2.084895983338356

Epoch: 5| Step: 10
Training loss: 2.483015537261963
Validation loss: 2.069985195994377

Epoch: 5| Step: 11
Training loss: 1.975620150566101
Validation loss: 2.067920506000519

Epoch: 196| Step: 0
Training loss: 2.090609312057495
Validation loss: 2.0656855205694833

Epoch: 5| Step: 1
Training loss: 1.9503542184829712
Validation loss: 2.077366997798284

Epoch: 5| Step: 2
Training loss: 1.5062358379364014
Validation loss: 2.0556365102529526

Epoch: 5| Step: 3
Training loss: 1.4823849201202393
Validation loss: 2.0690694600343704

Epoch: 5| Step: 4
Training loss: 2.0803933143615723
Validation loss: 2.0543596545855203

Epoch: 5| Step: 5
Training loss: 2.366236686706543
Validation loss: 2.064354514082273

Epoch: 5| Step: 6
Training loss: 2.0227513313293457
Validation loss: 2.0746593872706094

Epoch: 5| Step: 7
Training loss: 2.0549559593200684
Validation loss: 2.0914935072263083

Epoch: 5| Step: 8
Training loss: 2.5762271881103516
Validation loss: 2.0968957344690957

Epoch: 5| Step: 9
Training loss: 1.9484821557998657
Validation loss: 2.0910754203796387

Epoch: 5| Step: 10
Training loss: 1.543354868888855
Validation loss: 2.093619962533315

Epoch: 5| Step: 11
Training loss: 1.7394177913665771
Validation loss: 2.081667900085449

Epoch: 197| Step: 0
Training loss: 2.1892218589782715
Validation loss: 2.0846534272034964

Epoch: 5| Step: 1
Training loss: 1.513079285621643
Validation loss: 2.096396212776502

Epoch: 5| Step: 2
Training loss: 1.3025457859039307
Validation loss: 2.0942591975132623

Epoch: 5| Step: 3
Training loss: 1.7386474609375
Validation loss: 2.100321874022484

Epoch: 5| Step: 4
Training loss: 1.6332935094833374
Validation loss: 2.1046255628267923

Epoch: 5| Step: 5
Training loss: 2.6330158710479736
Validation loss: 2.0976972927649817

Epoch: 5| Step: 6
Training loss: 2.229142189025879
Validation loss: 2.096935138106346

Epoch: 5| Step: 7
Training loss: 1.9702351093292236
Validation loss: 2.0823388497034707

Epoch: 5| Step: 8
Training loss: 2.378533124923706
Validation loss: 2.0876592000325522

Epoch: 5| Step: 9
Training loss: 1.4042623043060303
Validation loss: 2.085104748606682

Epoch: 5| Step: 10
Training loss: 2.017545461654663
Validation loss: 2.074366102615992

Epoch: 5| Step: 11
Training loss: 2.5797367095947266
Validation loss: 2.0747845073541007

Epoch: 198| Step: 0
Training loss: 2.2797646522521973
Validation loss: 2.0990431805451712

Epoch: 5| Step: 1
Training loss: 1.67670476436615
Validation loss: 2.098020782073339

Epoch: 5| Step: 2
Training loss: 2.57930064201355
Validation loss: 2.101833393176397

Epoch: 5| Step: 3
Training loss: 2.228689432144165
Validation loss: 2.1062686145305634

Epoch: 5| Step: 4
Training loss: 2.163414478302002
Validation loss: 2.099159742395083

Epoch: 5| Step: 5
Training loss: 1.5931806564331055
Validation loss: 2.091926415761312

Epoch: 5| Step: 6
Training loss: 2.0932202339172363
Validation loss: 2.10355976720651

Epoch: 5| Step: 7
Training loss: 1.456931710243225
Validation loss: 2.087664703528086

Epoch: 5| Step: 8
Training loss: 1.685259461402893
Validation loss: 2.1054433633883796

Epoch: 5| Step: 9
Training loss: 1.6597554683685303
Validation loss: 2.0944092323382697

Epoch: 5| Step: 10
Training loss: 1.9649121761322021
Validation loss: 2.1043260991573334

Epoch: 5| Step: 11
Training loss: 1.3355199098587036
Validation loss: 2.1179217944542565

Epoch: 199| Step: 0
Training loss: 1.8104852437973022
Validation loss: 2.1218880861997604

Epoch: 5| Step: 1
Training loss: 1.9859437942504883
Validation loss: 2.1272810647885003

Epoch: 5| Step: 2
Training loss: 2.402064561843872
Validation loss: 2.1159758468468985

Epoch: 5| Step: 3
Training loss: 1.4281247854232788
Validation loss: 2.1091204384962716

Epoch: 5| Step: 4
Training loss: 2.257028341293335
Validation loss: 2.1070695171753564

Epoch: 5| Step: 5
Training loss: 2.3550608158111572
Validation loss: 2.100949371854464

Epoch: 5| Step: 6
Training loss: 2.4153027534484863
Validation loss: 2.0841835886240005

Epoch: 5| Step: 7
Training loss: 1.8238308429718018
Validation loss: 2.101859986782074

Epoch: 5| Step: 8
Training loss: 1.4641042947769165
Validation loss: 2.095439796646436

Epoch: 5| Step: 9
Training loss: 1.796931505203247
Validation loss: 2.086626028021177

Epoch: 5| Step: 10
Training loss: 1.6283448934555054
Validation loss: 2.0768409768740335

Epoch: 5| Step: 11
Training loss: 1.3527323007583618
Validation loss: 2.08766903479894

Epoch: 200| Step: 0
Training loss: 2.4730896949768066
Validation loss: 2.083281929294268

Epoch: 5| Step: 1
Training loss: 1.4987187385559082
Validation loss: 2.0835232685009637

Epoch: 5| Step: 2
Training loss: 1.5861815214157104
Validation loss: 2.084983617067337

Epoch: 5| Step: 3
Training loss: 1.8920180797576904
Validation loss: 2.089244688550631

Epoch: 5| Step: 4
Training loss: 1.6632407903671265
Validation loss: 2.093130643169085

Epoch: 5| Step: 5
Training loss: 1.5915569067001343
Validation loss: 2.08833871781826

Epoch: 5| Step: 6
Training loss: 2.2247941493988037
Validation loss: 2.098801856239637

Epoch: 5| Step: 7
Training loss: 2.2730395793914795
Validation loss: 2.0892202258110046

Epoch: 5| Step: 8
Training loss: 2.0672314167022705
Validation loss: 2.0851790010929108

Epoch: 5| Step: 9
Training loss: 2.148717164993286
Validation loss: 2.070639193058014

Epoch: 5| Step: 10
Training loss: 2.1860909461975098
Validation loss: 2.0973777920007706

Epoch: 5| Step: 11
Training loss: 0.8870314359664917
Validation loss: 2.0889746944109597

Epoch: 201| Step: 0
Training loss: 1.7270386219024658
Validation loss: 2.0989868144194284

Epoch: 5| Step: 1
Training loss: 1.9824813604354858
Validation loss: 2.082905724644661

Epoch: 5| Step: 2
Training loss: 2.618183135986328
Validation loss: 2.079363922278086

Epoch: 5| Step: 3
Training loss: 1.715943694114685
Validation loss: 2.095946177840233

Epoch: 5| Step: 4
Training loss: 1.4619680643081665
Validation loss: 2.0637572407722473

Epoch: 5| Step: 5
Training loss: 2.1466126441955566
Validation loss: 2.079237009088198

Epoch: 5| Step: 6
Training loss: 1.4207420349121094
Validation loss: 2.0854670107364655

Epoch: 5| Step: 7
Training loss: 2.3175575733184814
Validation loss: 2.0838027546803155

Epoch: 5| Step: 8
Training loss: 1.8697856664657593
Validation loss: 2.082337369521459

Epoch: 5| Step: 9
Training loss: 2.1091418266296387
Validation loss: 2.082894816994667

Epoch: 5| Step: 10
Training loss: 1.7520360946655273
Validation loss: 2.0900944819053016

Epoch: 5| Step: 11
Training loss: 3.1207728385925293
Validation loss: 2.0717218766609826

Epoch: 202| Step: 0
Training loss: 1.7311737537384033
Validation loss: 2.0914850582679114

Epoch: 5| Step: 1
Training loss: 2.0329203605651855
Validation loss: 2.0840044915676117

Epoch: 5| Step: 2
Training loss: 1.5458475351333618
Validation loss: 2.095607653260231

Epoch: 5| Step: 3
Training loss: 2.4962265491485596
Validation loss: 2.0893991639216742

Epoch: 5| Step: 4
Training loss: 1.8880093097686768
Validation loss: 2.1012039283911386

Epoch: 5| Step: 5
Training loss: 1.9519481658935547
Validation loss: 2.1053354094425836

Epoch: 5| Step: 6
Training loss: 2.1444129943847656
Validation loss: 2.0994145025809607

Epoch: 5| Step: 7
Training loss: 1.5901503562927246
Validation loss: 2.1062356432278952

Epoch: 5| Step: 8
Training loss: 1.9450546503067017
Validation loss: 2.111227661371231

Epoch: 5| Step: 9
Training loss: 1.7363853454589844
Validation loss: 2.1026424169540405

Epoch: 5| Step: 10
Training loss: 2.0417397022247314
Validation loss: 2.1000134348869324

Epoch: 5| Step: 11
Training loss: 2.9391391277313232
Validation loss: 2.106917455792427

Epoch: 203| Step: 0
Training loss: 2.2977187633514404
Validation loss: 2.1172469655672708

Epoch: 5| Step: 1
Training loss: 1.9220364093780518
Validation loss: 2.1168639957904816

Epoch: 5| Step: 2
Training loss: 2.495828628540039
Validation loss: 2.119368761777878

Epoch: 5| Step: 3
Training loss: 2.3897125720977783
Validation loss: 2.1124441226323447

Epoch: 5| Step: 4
Training loss: 1.9996343851089478
Validation loss: 2.1166217823823295

Epoch: 5| Step: 5
Training loss: 1.9412338733673096
Validation loss: 2.120260159174601

Epoch: 5| Step: 6
Training loss: 1.781732201576233
Validation loss: 2.1065280735492706

Epoch: 5| Step: 7
Training loss: 1.368356466293335
Validation loss: 2.1117212722698846

Epoch: 5| Step: 8
Training loss: 1.2606574296951294
Validation loss: 2.128228704134623

Epoch: 5| Step: 9
Training loss: 1.7125518321990967
Validation loss: 2.117783879240354

Epoch: 5| Step: 10
Training loss: 1.6695632934570312
Validation loss: 2.119178315003713

Epoch: 5| Step: 11
Training loss: 3.3817710876464844
Validation loss: 2.129787857333819

Epoch: 204| Step: 0
Training loss: 1.7114452123641968
Validation loss: 2.100567013025284

Epoch: 5| Step: 1
Training loss: 1.9921385049819946
Validation loss: 2.0941347926855087

Epoch: 5| Step: 2
Training loss: 1.6717846393585205
Validation loss: 2.100955600539843

Epoch: 5| Step: 3
Training loss: 2.2507667541503906
Validation loss: 2.0838724126418433

Epoch: 5| Step: 4
Training loss: 1.938246488571167
Validation loss: 2.062912712494532

Epoch: 5| Step: 5
Training loss: 1.912340521812439
Validation loss: 2.0660867939392724

Epoch: 5| Step: 6
Training loss: 2.039794921875
Validation loss: 2.0717716763416925

Epoch: 5| Step: 7
Training loss: 1.7030460834503174
Validation loss: 2.0798224608103433

Epoch: 5| Step: 8
Training loss: 1.9540115594863892
Validation loss: 2.0761637141307197

Epoch: 5| Step: 9
Training loss: 2.099837303161621
Validation loss: 2.084590474764506

Epoch: 5| Step: 10
Training loss: 2.2240374088287354
Validation loss: 2.088673988978068

Epoch: 5| Step: 11
Training loss: 0.7812147736549377
Validation loss: 2.0862404157718024

Epoch: 205| Step: 0
Training loss: 2.687608003616333
Validation loss: 2.101147562265396

Epoch: 5| Step: 1
Training loss: 2.2408652305603027
Validation loss: 2.1017880737781525

Epoch: 5| Step: 2
Training loss: 2.189030408859253
Validation loss: 2.123237654566765

Epoch: 5| Step: 3
Training loss: 2.0496015548706055
Validation loss: 2.0987621595462165

Epoch: 5| Step: 4
Training loss: 2.233065605163574
Validation loss: 2.0818655490875244

Epoch: 5| Step: 5
Training loss: 1.3906915187835693
Validation loss: 2.0951066315174103

Epoch: 5| Step: 6
Training loss: 1.5606870651245117
Validation loss: 2.0969225416580834

Epoch: 5| Step: 7
Training loss: 1.4419702291488647
Validation loss: 2.0832513570785522

Epoch: 5| Step: 8
Training loss: 2.0110597610473633
Validation loss: 2.0927542547384896

Epoch: 5| Step: 9
Training loss: 1.6974340677261353
Validation loss: 2.0919631520907083

Epoch: 5| Step: 10
Training loss: 1.4611918926239014
Validation loss: 2.096256211400032

Epoch: 5| Step: 11
Training loss: 2.2007498741149902
Validation loss: 2.1023060182730355

Epoch: 206| Step: 0
Training loss: 1.698097825050354
Validation loss: 2.0917797287305198

Epoch: 5| Step: 1
Training loss: 2.463533639907837
Validation loss: 2.093464583158493

Epoch: 5| Step: 2
Training loss: 2.1829681396484375
Validation loss: 2.0958017905553183

Epoch: 5| Step: 3
Training loss: 1.3017034530639648
Validation loss: 2.1153979102770486

Epoch: 5| Step: 4
Training loss: 1.9252328872680664
Validation loss: 2.0925027628739676

Epoch: 5| Step: 5
Training loss: 2.256842851638794
Validation loss: 2.1025506605704627

Epoch: 5| Step: 6
Training loss: 1.5259039402008057
Validation loss: 2.1001267433166504

Epoch: 5| Step: 7
Training loss: 2.05238676071167
Validation loss: 2.101977522174517

Epoch: 5| Step: 8
Training loss: 2.254884719848633
Validation loss: 2.101857374111811

Epoch: 5| Step: 9
Training loss: 2.2018938064575195
Validation loss: 2.1002213954925537

Epoch: 5| Step: 10
Training loss: 1.385965347290039
Validation loss: 2.1076359897851944

Epoch: 5| Step: 11
Training loss: 0.6093223094940186
Validation loss: 2.102635219693184

Epoch: 207| Step: 0
Training loss: 2.2314934730529785
Validation loss: 2.1118421405553818

Epoch: 5| Step: 1
Training loss: 1.9707508087158203
Validation loss: 2.1131668935219445

Epoch: 5| Step: 2
Training loss: 2.2324137687683105
Validation loss: 2.1166676729917526

Epoch: 5| Step: 3
Training loss: 2.337472438812256
Validation loss: 2.1216940581798553

Epoch: 5| Step: 4
Training loss: 1.4229973554611206
Validation loss: 2.1155324975649514

Epoch: 5| Step: 5
Training loss: 1.7027804851531982
Validation loss: 2.122750148177147

Epoch: 5| Step: 6
Training loss: 1.765799880027771
Validation loss: 2.113847464323044

Epoch: 5| Step: 7
Training loss: 1.4113292694091797
Validation loss: 2.115612804889679

Epoch: 5| Step: 8
Training loss: 1.8858048915863037
Validation loss: 2.0991055220365524

Epoch: 5| Step: 9
Training loss: 1.9779884815216064
Validation loss: 2.1138799687226615

Epoch: 5| Step: 10
Training loss: 1.8360769748687744
Validation loss: 2.10824986298879

Epoch: 5| Step: 11
Training loss: 2.5043909549713135
Validation loss: 2.1133535305658975

Epoch: 208| Step: 0
Training loss: 1.6372900009155273
Validation loss: 2.108892564972242

Epoch: 5| Step: 1
Training loss: 1.8545703887939453
Validation loss: 2.1210850377877555

Epoch: 5| Step: 2
Training loss: 1.684547781944275
Validation loss: 2.110821475585302

Epoch: 5| Step: 3
Training loss: 1.8102960586547852
Validation loss: 2.116849184036255

Epoch: 5| Step: 4
Training loss: 1.7739274501800537
Validation loss: 2.119820942481359

Epoch: 5| Step: 5
Training loss: 2.2785019874572754
Validation loss: 2.1011006832122803

Epoch: 5| Step: 6
Training loss: 1.8722091913223267
Validation loss: 2.1257163186868033

Epoch: 5| Step: 7
Training loss: 1.74431574344635
Validation loss: 2.10134819149971

Epoch: 5| Step: 8
Training loss: 1.795269250869751
Validation loss: 2.1061827689409256

Epoch: 5| Step: 9
Training loss: 1.9734439849853516
Validation loss: 2.102576951185862

Epoch: 5| Step: 10
Training loss: 2.298520565032959
Validation loss: 2.094466711084048

Epoch: 5| Step: 11
Training loss: 2.1821188926696777
Validation loss: 2.092223341266314

Epoch: 209| Step: 0
Training loss: 1.6896543502807617
Validation loss: 2.0995951940615973

Epoch: 5| Step: 1
Training loss: 2.039360523223877
Validation loss: 2.093576103448868

Epoch: 5| Step: 2
Training loss: 1.4801280498504639
Validation loss: 2.0852265059947968

Epoch: 5| Step: 3
Training loss: 1.7881526947021484
Validation loss: 2.0983125070730844

Epoch: 5| Step: 4
Training loss: 2.14170503616333
Validation loss: 2.0932961155970893

Epoch: 5| Step: 5
Training loss: 1.9633651971817017
Validation loss: 2.1128707925478616

Epoch: 5| Step: 6
Training loss: 1.3234564065933228
Validation loss: 2.1006068686644235

Epoch: 5| Step: 7
Training loss: 2.335580348968506
Validation loss: 2.1139935652414956

Epoch: 5| Step: 8
Training loss: 2.106142520904541
Validation loss: 2.112916186451912

Epoch: 5| Step: 9
Training loss: 1.4412953853607178
Validation loss: 2.118757704893748

Epoch: 5| Step: 10
Training loss: 2.534294605255127
Validation loss: 2.1178697496652603

Epoch: 5| Step: 11
Training loss: 1.8578212261199951
Validation loss: 2.0980261117219925

Epoch: 210| Step: 0
Training loss: 2.2164883613586426
Validation loss: 2.09592974682649

Epoch: 5| Step: 1
Training loss: 2.1993751525878906
Validation loss: 2.0933625996112823

Epoch: 5| Step: 2
Training loss: 1.6650779247283936
Validation loss: 2.086755022406578

Epoch: 5| Step: 3
Training loss: 1.8027870655059814
Validation loss: 2.0864223887523017

Epoch: 5| Step: 4
Training loss: 1.8038063049316406
Validation loss: 2.085928196708361

Epoch: 5| Step: 5
Training loss: 1.8331142663955688
Validation loss: 2.074921667575836

Epoch: 5| Step: 6
Training loss: 2.0433692932128906
Validation loss: 2.0908139000336328

Epoch: 5| Step: 7
Training loss: 2.323244571685791
Validation loss: 2.0930317789316177

Epoch: 5| Step: 8
Training loss: 1.8683446645736694
Validation loss: 2.093821326891581

Epoch: 5| Step: 9
Training loss: 1.644134521484375
Validation loss: 2.0941204726696014

Epoch: 5| Step: 10
Training loss: 1.469191074371338
Validation loss: 2.1112460494041443

Epoch: 5| Step: 11
Training loss: 1.2264856100082397
Validation loss: 2.1138546417156854

Epoch: 211| Step: 0
Training loss: 2.0266802310943604
Validation loss: 2.1284433603286743

Epoch: 5| Step: 1
Training loss: 1.9168800115585327
Validation loss: 2.1396003663539886

Epoch: 5| Step: 2
Training loss: 2.1432394981384277
Validation loss: 2.131781354546547

Epoch: 5| Step: 3
Training loss: 2.0042166709899902
Validation loss: 2.1392841736475625

Epoch: 5| Step: 4
Training loss: 2.066265106201172
Validation loss: 2.149207835396131

Epoch: 5| Step: 5
Training loss: 1.5074740648269653
Validation loss: 2.130974774559339

Epoch: 5| Step: 6
Training loss: 1.5152889490127563
Validation loss: 2.1393852134545646

Epoch: 5| Step: 7
Training loss: 1.6078150272369385
Validation loss: 2.1120234529177346

Epoch: 5| Step: 8
Training loss: 2.004363536834717
Validation loss: 2.088562617699305

Epoch: 5| Step: 9
Training loss: 2.137803316116333
Validation loss: 2.103785122434298

Epoch: 5| Step: 10
Training loss: 1.9988677501678467
Validation loss: 2.097889319062233

Epoch: 5| Step: 11
Training loss: 1.196090579032898
Validation loss: 2.1044583966334662

Epoch: 212| Step: 0
Training loss: 2.0272316932678223
Validation loss: 2.1081371506055198

Epoch: 5| Step: 1
Training loss: 1.8707141876220703
Validation loss: 2.093957076470057

Epoch: 5| Step: 2
Training loss: 1.0893369913101196
Validation loss: 2.0920645544926324

Epoch: 5| Step: 3
Training loss: 1.7666053771972656
Validation loss: 2.0977798153956733

Epoch: 5| Step: 4
Training loss: 2.137702226638794
Validation loss: 2.1137129217386246

Epoch: 5| Step: 5
Training loss: 1.8204667568206787
Validation loss: 2.114050423105558

Epoch: 5| Step: 6
Training loss: 1.738896369934082
Validation loss: 2.1091476331154504

Epoch: 5| Step: 7
Training loss: 1.6709429025650024
Validation loss: 2.105135311683019

Epoch: 5| Step: 8
Training loss: 2.1930699348449707
Validation loss: 2.119887664914131

Epoch: 5| Step: 9
Training loss: 1.653124213218689
Validation loss: 2.1060976684093475

Epoch: 5| Step: 10
Training loss: 2.332043170928955
Validation loss: 2.123249034086863

Epoch: 5| Step: 11
Training loss: 2.6351609230041504
Validation loss: 2.110583856701851

Epoch: 213| Step: 0
Training loss: 1.4928996562957764
Validation loss: 2.1199012398719788

Epoch: 5| Step: 1
Training loss: 2.191427707672119
Validation loss: 2.1143361230691275

Epoch: 5| Step: 2
Training loss: 1.6861381530761719
Validation loss: 2.0976626674334207

Epoch: 5| Step: 3
Training loss: 1.1404204368591309
Validation loss: 2.103229522705078

Epoch: 5| Step: 4
Training loss: 1.6547300815582275
Validation loss: 2.076813499132792

Epoch: 5| Step: 5
Training loss: 1.8403218984603882
Validation loss: 2.1088992158571878

Epoch: 5| Step: 6
Training loss: 1.873152494430542
Validation loss: 2.10159503420194

Epoch: 5| Step: 7
Training loss: 1.967477798461914
Validation loss: 2.087370211879412

Epoch: 5| Step: 8
Training loss: 1.8917083740234375
Validation loss: 2.091076076030731

Epoch: 5| Step: 9
Training loss: 2.3231282234191895
Validation loss: 2.111957927544912

Epoch: 5| Step: 10
Training loss: 2.278045177459717
Validation loss: 2.1144508371750512

Epoch: 5| Step: 11
Training loss: 3.4188780784606934
Validation loss: 2.1035325030485788

Epoch: 214| Step: 0
Training loss: 2.039019823074341
Validation loss: 2.1236054797967276

Epoch: 5| Step: 1
Training loss: 2.3484396934509277
Validation loss: 2.1168151001135507

Epoch: 5| Step: 2
Training loss: 1.5035383701324463
Validation loss: 2.115243191520373

Epoch: 5| Step: 3
Training loss: 1.7047793865203857
Validation loss: 2.1204492300748825

Epoch: 5| Step: 4
Training loss: 1.302324652671814
Validation loss: 2.1148436119159064

Epoch: 5| Step: 5
Training loss: 1.711745023727417
Validation loss: 2.1115007946888604

Epoch: 5| Step: 6
Training loss: 1.473259687423706
Validation loss: 2.1110415309667587

Epoch: 5| Step: 7
Training loss: 1.7626779079437256
Validation loss: 2.129564722379049

Epoch: 5| Step: 8
Training loss: 2.332979679107666
Validation loss: 2.1130515535672507

Epoch: 5| Step: 9
Training loss: 2.0694565773010254
Validation loss: 2.1185262501239777

Epoch: 5| Step: 10
Training loss: 1.9558391571044922
Validation loss: 2.0983678698539734

Epoch: 5| Step: 11
Training loss: 3.878699779510498
Validation loss: 2.1184223095575967

Epoch: 215| Step: 0
Training loss: 2.244810104370117
Validation loss: 2.0942400097846985

Epoch: 5| Step: 1
Training loss: 1.6665418148040771
Validation loss: 2.097668985525767

Epoch: 5| Step: 2
Training loss: 1.4548736810684204
Validation loss: 2.108451798558235

Epoch: 5| Step: 3
Training loss: 2.4735827445983887
Validation loss: 2.087444623311361

Epoch: 5| Step: 4
Training loss: 1.7679026126861572
Validation loss: 2.0933987448612847

Epoch: 5| Step: 5
Training loss: 1.4746272563934326
Validation loss: 2.089336926738421

Epoch: 5| Step: 6
Training loss: 1.8758313655853271
Validation loss: 2.0946478247642517

Epoch: 5| Step: 7
Training loss: 2.0389599800109863
Validation loss: 2.1042207181453705

Epoch: 5| Step: 8
Training loss: 1.9660041332244873
Validation loss: 2.1130635191996894

Epoch: 5| Step: 9
Training loss: 1.6779645681381226
Validation loss: 2.113049864768982

Epoch: 5| Step: 10
Training loss: 1.8598076105117798
Validation loss: 2.1257813622554145

Epoch: 5| Step: 11
Training loss: 2.00154185295105
Validation loss: 2.126041531562805

Epoch: 216| Step: 0
Training loss: 1.6437124013900757
Validation loss: 2.1219920416673026

Epoch: 5| Step: 1
Training loss: 2.7115886211395264
Validation loss: 2.13250802954038

Epoch: 5| Step: 2
Training loss: 1.2930690050125122
Validation loss: 2.128329669435819

Epoch: 5| Step: 3
Training loss: 2.5945444107055664
Validation loss: 2.1342866321404776

Epoch: 5| Step: 4
Training loss: 1.874535322189331
Validation loss: 2.1110263019800186

Epoch: 5| Step: 5
Training loss: 1.8933731317520142
Validation loss: 2.1283429314692817

Epoch: 5| Step: 6
Training loss: 1.79949951171875
Validation loss: 2.1337743451197944

Epoch: 5| Step: 7
Training loss: 1.5924136638641357
Validation loss: 2.115262766679128

Epoch: 5| Step: 8
Training loss: 1.5254980325698853
Validation loss: 2.1323129733403525

Epoch: 5| Step: 9
Training loss: 1.7346045970916748
Validation loss: 2.1114054520924888

Epoch: 5| Step: 10
Training loss: 1.8556640148162842
Validation loss: 2.0998663703600564

Epoch: 5| Step: 11
Training loss: 1.6857681274414062
Validation loss: 2.097749094168345

Epoch: 217| Step: 0
Training loss: 1.9170852899551392
Validation loss: 2.0970663776000342

Epoch: 5| Step: 1
Training loss: 2.126101016998291
Validation loss: 2.0879103740056357

Epoch: 5| Step: 2
Training loss: 1.8325598239898682
Validation loss: 2.0908091415961585

Epoch: 5| Step: 3
Training loss: 2.1083121299743652
Validation loss: 2.0895651082197824

Epoch: 5| Step: 4
Training loss: 1.534324288368225
Validation loss: 2.088242063919703

Epoch: 5| Step: 5
Training loss: 2.3453516960144043
Validation loss: 2.105765695373217

Epoch: 5| Step: 6
Training loss: 2.552321195602417
Validation loss: 2.1045322765906653

Epoch: 5| Step: 7
Training loss: 2.028918504714966
Validation loss: 2.0981639623641968

Epoch: 5| Step: 8
Training loss: 1.778204321861267
Validation loss: 2.1222274204095206

Epoch: 5| Step: 9
Training loss: 1.289367914199829
Validation loss: 2.1191595743099847

Epoch: 5| Step: 10
Training loss: 1.6785650253295898
Validation loss: 2.120310753583908

Epoch: 5| Step: 11
Training loss: 0.7530168294906616
Validation loss: 2.125102604428927

Epoch: 218| Step: 0
Training loss: 2.1134705543518066
Validation loss: 2.1339144110679626

Epoch: 5| Step: 1
Training loss: 1.5516868829727173
Validation loss: 2.1259273290634155

Epoch: 5| Step: 2
Training loss: 1.9792312383651733
Validation loss: 2.148403416077296

Epoch: 5| Step: 3
Training loss: 1.920885682106018
Validation loss: 2.126400093237559

Epoch: 5| Step: 4
Training loss: 1.4718782901763916
Validation loss: 2.134215513865153

Epoch: 5| Step: 5
Training loss: 1.8584487438201904
Validation loss: 2.1173584014177322

Epoch: 5| Step: 6
Training loss: 1.571733832359314
Validation loss: 2.1063305884599686

Epoch: 5| Step: 7
Training loss: 1.56095290184021
Validation loss: 2.1031882017850876

Epoch: 5| Step: 8
Training loss: 2.071190595626831
Validation loss: 2.116001635789871

Epoch: 5| Step: 9
Training loss: 1.9403867721557617
Validation loss: 2.1122547388076782

Epoch: 5| Step: 10
Training loss: 2.2241451740264893
Validation loss: 2.1182620177666345

Epoch: 5| Step: 11
Training loss: 2.8358612060546875
Validation loss: 2.1172126283248267

Epoch: 219| Step: 0
Training loss: 2.100926160812378
Validation loss: 2.129504457116127

Epoch: 5| Step: 1
Training loss: 1.3469727039337158
Validation loss: 2.117418979605039

Epoch: 5| Step: 2
Training loss: 2.0074875354766846
Validation loss: 2.107556829849879

Epoch: 5| Step: 3
Training loss: 2.3703200817108154
Validation loss: 2.1132410864035287

Epoch: 5| Step: 4
Training loss: 1.6954317092895508
Validation loss: 2.111524393161138

Epoch: 5| Step: 5
Training loss: 1.722848892211914
Validation loss: 2.1154358188311257

Epoch: 5| Step: 6
Training loss: 2.0839943885803223
Validation loss: 2.1209581593672433

Epoch: 5| Step: 7
Training loss: 2.1664719581604004
Validation loss: 2.111682708064715

Epoch: 5| Step: 8
Training loss: 1.6929126977920532
Validation loss: 2.1187016367912292

Epoch: 5| Step: 9
Training loss: 1.8641624450683594
Validation loss: 2.1195389727751413

Epoch: 5| Step: 10
Training loss: 1.4541447162628174
Validation loss: 2.139031713207563

Epoch: 5| Step: 11
Training loss: 1.661876916885376
Validation loss: 2.112784524758657

Epoch: 220| Step: 0
Training loss: 1.772812843322754
Validation loss: 2.119291936357816

Epoch: 5| Step: 1
Training loss: 1.5680217742919922
Validation loss: 2.0930426915486655

Epoch: 5| Step: 2
Training loss: 1.4990218877792358
Validation loss: 2.088450347383817

Epoch: 5| Step: 3
Training loss: 1.5455286502838135
Validation loss: 2.116147627433141

Epoch: 5| Step: 4
Training loss: 1.8650346994400024
Validation loss: 2.1123398542404175

Epoch: 5| Step: 5
Training loss: 2.0554356575012207
Validation loss: 2.1019510477781296

Epoch: 5| Step: 6
Training loss: 2.4453723430633545
Validation loss: 2.099983180562655

Epoch: 5| Step: 7
Training loss: 2.551238536834717
Validation loss: 2.1231133292118707

Epoch: 5| Step: 8
Training loss: 1.852121353149414
Validation loss: 2.1122273157040277

Epoch: 5| Step: 9
Training loss: 1.4232946634292603
Validation loss: 2.1189841479063034

Epoch: 5| Step: 10
Training loss: 1.9029659032821655
Validation loss: 2.1206917464733124

Epoch: 5| Step: 11
Training loss: 2.194883346557617
Validation loss: 2.1169497817754745

Epoch: 221| Step: 0
Training loss: 1.9665498733520508
Validation loss: 2.1166324516137442

Epoch: 5| Step: 1
Training loss: 1.4817261695861816
Validation loss: 2.128727912902832

Epoch: 5| Step: 2
Training loss: 2.055345058441162
Validation loss: 2.1276674966017404

Epoch: 5| Step: 3
Training loss: 1.4776041507720947
Validation loss: 2.109130253394445

Epoch: 5| Step: 4
Training loss: 2.0637853145599365
Validation loss: 2.1091958483060202

Epoch: 5| Step: 5
Training loss: 2.1775574684143066
Validation loss: 2.1203701198101044

Epoch: 5| Step: 6
Training loss: 1.765722632408142
Validation loss: 2.1374619901180267

Epoch: 5| Step: 7
Training loss: 1.8265653848648071
Validation loss: 2.1437591264645257

Epoch: 5| Step: 8
Training loss: 1.7543789148330688
Validation loss: 2.1328649520874023

Epoch: 5| Step: 9
Training loss: 2.0703253746032715
Validation loss: 2.1170690059661865

Epoch: 5| Step: 10
Training loss: 1.6161655187606812
Validation loss: 2.116938208540281

Epoch: 5| Step: 11
Training loss: 2.3321778774261475
Validation loss: 2.1203566938638687

Epoch: 222| Step: 0
Training loss: 1.7972770929336548
Validation loss: 2.1324203312397003

Epoch: 5| Step: 1
Training loss: 2.2465834617614746
Validation loss: 2.1144578556219735

Epoch: 5| Step: 2
Training loss: 1.7902870178222656
Validation loss: 2.1124018331368766

Epoch: 5| Step: 3
Training loss: 2.103921413421631
Validation loss: 2.0934287856022515

Epoch: 5| Step: 4
Training loss: 1.3363591432571411
Validation loss: 2.0893212656180062

Epoch: 5| Step: 5
Training loss: 2.118756055831909
Validation loss: 2.092594270904859

Epoch: 5| Step: 6
Training loss: 1.707449197769165
Validation loss: 2.1123669842878976

Epoch: 5| Step: 7
Training loss: 1.6411206722259521
Validation loss: 2.11841881275177

Epoch: 5| Step: 8
Training loss: 2.013613224029541
Validation loss: 2.124216919143995

Epoch: 5| Step: 9
Training loss: 1.9448349475860596
Validation loss: 2.1417914231618247

Epoch: 5| Step: 10
Training loss: 2.249178409576416
Validation loss: 2.153326099117597

Epoch: 5| Step: 11
Training loss: 0.9579445123672485
Validation loss: 2.1338167091210685

Epoch: 223| Step: 0
Training loss: 2.367581367492676
Validation loss: 2.1534004360437393

Epoch: 5| Step: 1
Training loss: 2.133103609085083
Validation loss: 2.1398075173298516

Epoch: 5| Step: 2
Training loss: 1.9979183673858643
Validation loss: 2.1548947344223657

Epoch: 5| Step: 3
Training loss: 1.6357831954956055
Validation loss: 2.1331826051076255

Epoch: 5| Step: 4
Training loss: 1.3559426069259644
Validation loss: 2.1411476035912833

Epoch: 5| Step: 5
Training loss: 1.540999174118042
Validation loss: 2.158011252681414

Epoch: 5| Step: 6
Training loss: 2.212059736251831
Validation loss: 2.1366252104441323

Epoch: 5| Step: 7
Training loss: 1.8361104726791382
Validation loss: 2.1359106798966727

Epoch: 5| Step: 8
Training loss: 1.868320107460022
Validation loss: 2.103015571832657

Epoch: 5| Step: 9
Training loss: 1.5420811176300049
Validation loss: 2.104456568757693

Epoch: 5| Step: 10
Training loss: 2.3249001502990723
Validation loss: 2.091019719839096

Epoch: 5| Step: 11
Training loss: 1.9657751321792603
Validation loss: 2.104562073945999

Epoch: 224| Step: 0
Training loss: 1.8960399627685547
Validation loss: 2.0897253304719925

Epoch: 5| Step: 1
Training loss: 2.0646986961364746
Validation loss: 2.0960708806912103

Epoch: 5| Step: 2
Training loss: 2.0084755420684814
Validation loss: 2.100585088133812

Epoch: 5| Step: 3
Training loss: 2.0172619819641113
Validation loss: 2.0898920198281608

Epoch: 5| Step: 4
Training loss: 2.047457456588745
Validation loss: 2.1218335032463074

Epoch: 5| Step: 5
Training loss: 1.5266621112823486
Validation loss: 2.11554683248202

Epoch: 5| Step: 6
Training loss: 1.8759838342666626
Validation loss: 2.1269066433111825

Epoch: 5| Step: 7
Training loss: 2.289968490600586
Validation loss: 2.117262522379557

Epoch: 5| Step: 8
Training loss: 1.5900017023086548
Validation loss: 2.122732271750768

Epoch: 5| Step: 9
Training loss: 1.6441271305084229
Validation loss: 2.1016809344291687

Epoch: 5| Step: 10
Training loss: 1.7285518646240234
Validation loss: 2.1060711294412613

Epoch: 5| Step: 11
Training loss: 1.6402970552444458
Validation loss: 2.1138985405365625

Epoch: 225| Step: 0
Training loss: 1.3212521076202393
Validation loss: 2.1166294117768607

Epoch: 5| Step: 1
Training loss: 1.9808223247528076
Validation loss: 2.1018202900886536

Epoch: 5| Step: 2
Training loss: 1.8677412271499634
Validation loss: 2.096783474087715

Epoch: 5| Step: 3
Training loss: 1.9705517292022705
Validation loss: 2.095535730322202

Epoch: 5| Step: 4
Training loss: 2.5134122371673584
Validation loss: 2.1027336517969766

Epoch: 5| Step: 5
Training loss: 1.636386513710022
Validation loss: 2.10458642244339

Epoch: 5| Step: 6
Training loss: 1.2360551357269287
Validation loss: 2.0962428549925485

Epoch: 5| Step: 7
Training loss: 1.8524796962738037
Validation loss: 2.110111420353254

Epoch: 5| Step: 8
Training loss: 2.051684856414795
Validation loss: 2.1025743136803308

Epoch: 5| Step: 9
Training loss: 2.1139278411865234
Validation loss: 2.099982733527819

Epoch: 5| Step: 10
Training loss: 1.831743597984314
Validation loss: 2.110135411222776

Epoch: 5| Step: 11
Training loss: 2.314025402069092
Validation loss: 2.127312203248342

Epoch: 226| Step: 0
Training loss: 1.918426752090454
Validation loss: 2.118455320596695

Epoch: 5| Step: 1
Training loss: 1.928903341293335
Validation loss: 2.105648289124171

Epoch: 5| Step: 2
Training loss: 2.2292847633361816
Validation loss: 2.1138725926478705

Epoch: 5| Step: 3
Training loss: 1.6553951501846313
Validation loss: 2.1259667674700418

Epoch: 5| Step: 4
Training loss: 1.9266353845596313
Validation loss: 2.1088813940684

Epoch: 5| Step: 5
Training loss: 1.6923093795776367
Validation loss: 2.0991317431131997

Epoch: 5| Step: 6
Training loss: 1.9838682413101196
Validation loss: 2.1086509029070535

Epoch: 5| Step: 7
Training loss: 1.7804549932479858
Validation loss: 2.1043919026851654

Epoch: 5| Step: 8
Training loss: 1.9039032459259033
Validation loss: 2.105127697189649

Epoch: 5| Step: 9
Training loss: 1.824223279953003
Validation loss: 2.1121676415205

Epoch: 5| Step: 10
Training loss: 1.322085976600647
Validation loss: 2.1251770555973053

Epoch: 5| Step: 11
Training loss: 1.703827142715454
Validation loss: 2.1160897264877954

Epoch: 227| Step: 0
Training loss: 1.6709868907928467
Validation loss: 2.131215294202169

Epoch: 5| Step: 1
Training loss: 1.5389044284820557
Validation loss: 2.1230073124170303

Epoch: 5| Step: 2
Training loss: 2.1759796142578125
Validation loss: 2.1246080497900643

Epoch: 5| Step: 3
Training loss: 1.7575725317001343
Validation loss: 2.1365330119927726

Epoch: 5| Step: 4
Training loss: 1.7753089666366577
Validation loss: 2.1054813166459403

Epoch: 5| Step: 5
Training loss: 1.9032071828842163
Validation loss: 2.1171610355377197

Epoch: 5| Step: 6
Training loss: 2.0180976390838623
Validation loss: 2.1071991324424744

Epoch: 5| Step: 7
Training loss: 2.1106297969818115
Validation loss: 2.086625804503759

Epoch: 5| Step: 8
Training loss: 1.8849678039550781
Validation loss: 2.082403967777888

Epoch: 5| Step: 9
Training loss: 1.8489137887954712
Validation loss: 2.102341224749883

Epoch: 5| Step: 10
Training loss: 1.9137294292449951
Validation loss: 2.10914837817351

Epoch: 5| Step: 11
Training loss: 1.1417421102523804
Validation loss: 2.109374384085337

Epoch: 228| Step: 0
Training loss: 2.5938973426818848
Validation loss: 2.1460429479678473

Epoch: 5| Step: 1
Training loss: 1.6448860168457031
Validation loss: 2.12662011384964

Epoch: 5| Step: 2
Training loss: 1.5735477209091187
Validation loss: 2.1334943970044455

Epoch: 5| Step: 3
Training loss: 1.542664885520935
Validation loss: 2.1449570854504905

Epoch: 5| Step: 4
Training loss: 1.7966378927230835
Validation loss: 2.1197963456312814

Epoch: 5| Step: 5
Training loss: 1.928161382675171
Validation loss: 2.1149609486262

Epoch: 5| Step: 6
Training loss: 2.2357757091522217
Validation loss: 2.111205438772837

Epoch: 5| Step: 7
Training loss: 2.0067198276519775
Validation loss: 2.095061103502909

Epoch: 5| Step: 8
Training loss: 1.7163517475128174
Validation loss: 2.117500285307566

Epoch: 5| Step: 9
Training loss: 1.7807376384735107
Validation loss: 2.0902105073134103

Epoch: 5| Step: 10
Training loss: 1.7794212102890015
Validation loss: 2.110055610537529

Epoch: 5| Step: 11
Training loss: 1.3901352882385254
Validation loss: 2.082459251085917

Epoch: 229| Step: 0
Training loss: 1.9189605712890625
Validation loss: 2.1091411113739014

Epoch: 5| Step: 1
Training loss: 1.6081441640853882
Validation loss: 2.107042441765467

Epoch: 5| Step: 2
Training loss: 1.7374598979949951
Validation loss: 2.1328855454921722

Epoch: 5| Step: 3
Training loss: 2.06101655960083
Validation loss: 2.11295910179615

Epoch: 5| Step: 4
Training loss: 1.7846686840057373
Validation loss: 2.112940808137258

Epoch: 5| Step: 5
Training loss: 2.27626895904541
Validation loss: 2.1311162809530892

Epoch: 5| Step: 6
Training loss: 1.882091760635376
Validation loss: 2.1252044985691705

Epoch: 5| Step: 7
Training loss: 1.52957284450531
Validation loss: 2.1217114130655923

Epoch: 5| Step: 8
Training loss: 1.5498631000518799
Validation loss: 2.110477859775225

Epoch: 5| Step: 9
Training loss: 1.7266929149627686
Validation loss: 2.1115106542905173

Epoch: 5| Step: 10
Training loss: 1.986454725265503
Validation loss: 2.107683077454567

Epoch: 5| Step: 11
Training loss: 2.9968481063842773
Validation loss: 2.1060091704130173

Epoch: 230| Step: 0
Training loss: 1.157429575920105
Validation loss: 2.098465512196223

Epoch: 5| Step: 1
Training loss: 2.282170534133911
Validation loss: 2.0959144781033197

Epoch: 5| Step: 2
Training loss: 1.837424874305725
Validation loss: 2.1148257901271186

Epoch: 5| Step: 3
Training loss: 2.322990894317627
Validation loss: 2.0841185549894967

Epoch: 5| Step: 4
Training loss: 2.1295485496520996
Validation loss: 2.1186456978321075

Epoch: 5| Step: 5
Training loss: 1.5349929332733154
Validation loss: 2.1203984369834266

Epoch: 5| Step: 6
Training loss: 1.5440294742584229
Validation loss: 2.1174115935961404

Epoch: 5| Step: 7
Training loss: 1.8276233673095703
Validation loss: 2.1260084559520087

Epoch: 5| Step: 8
Training loss: 2.258481502532959
Validation loss: 2.120964070161184

Epoch: 5| Step: 9
Training loss: 1.542183518409729
Validation loss: 2.1069254825512567

Epoch: 5| Step: 10
Training loss: 1.5484927892684937
Validation loss: 2.1088768541812897

Epoch: 5| Step: 11
Training loss: 2.8390560150146484
Validation loss: 2.099256361524264

Epoch: 231| Step: 0
Training loss: 1.468973994255066
Validation loss: 2.1059946914513907

Epoch: 5| Step: 1
Training loss: 1.835798978805542
Validation loss: 2.1089986165364585

Epoch: 5| Step: 2
Training loss: 2.3750247955322266
Validation loss: 2.1119284927845

Epoch: 5| Step: 3
Training loss: 2.3025152683258057
Validation loss: 2.120811919371287

Epoch: 5| Step: 4
Training loss: 1.4527555704116821
Validation loss: 2.126217618584633

Epoch: 5| Step: 5
Training loss: 1.3220964670181274
Validation loss: 2.123702809214592

Epoch: 5| Step: 6
Training loss: 1.5016252994537354
Validation loss: 2.1192683974901834

Epoch: 5| Step: 7
Training loss: 2.1045374870300293
Validation loss: 2.143417537212372

Epoch: 5| Step: 8
Training loss: 1.6574594974517822
Validation loss: 2.140952934821447

Epoch: 5| Step: 9
Training loss: 2.0267324447631836
Validation loss: 2.145776445666949

Epoch: 5| Step: 10
Training loss: 2.2222886085510254
Validation loss: 2.1601665069659552

Epoch: 5| Step: 11
Training loss: 1.1056690216064453
Validation loss: 2.1359706819057465

Epoch: 232| Step: 0
Training loss: 1.2280784845352173
Validation loss: 2.131819893916448

Epoch: 5| Step: 1
Training loss: 2.078922748565674
Validation loss: 2.1195841828982034

Epoch: 5| Step: 2
Training loss: 1.7629610300064087
Validation loss: 2.1160467714071274

Epoch: 5| Step: 3
Training loss: 1.8087337017059326
Validation loss: 2.1169895132382712

Epoch: 5| Step: 4
Training loss: 2.1131625175476074
Validation loss: 2.104104682803154

Epoch: 5| Step: 5
Training loss: 2.2913990020751953
Validation loss: 2.1142421613136926

Epoch: 5| Step: 6
Training loss: 2.15700101852417
Validation loss: 2.120241810878118

Epoch: 5| Step: 7
Training loss: 1.5559203624725342
Validation loss: 2.129025310277939

Epoch: 5| Step: 8
Training loss: 1.8559223413467407
Validation loss: 2.112173651655515

Epoch: 5| Step: 9
Training loss: 1.1885271072387695
Validation loss: 2.143522799015045

Epoch: 5| Step: 10
Training loss: 1.7826780080795288
Validation loss: 2.118429943919182

Epoch: 5| Step: 11
Training loss: 2.124505043029785
Validation loss: 2.1427972416083017

Epoch: 233| Step: 0
Training loss: 1.6596252918243408
Validation loss: 2.141949405272802

Epoch: 5| Step: 1
Training loss: 1.381026029586792
Validation loss: 2.153930256764094

Epoch: 5| Step: 2
Training loss: 1.885828971862793
Validation loss: 2.1454343646764755

Epoch: 5| Step: 3
Training loss: 1.825784683227539
Validation loss: 2.1389470299084983

Epoch: 5| Step: 4
Training loss: 1.9141261577606201
Validation loss: 2.1559831549723945

Epoch: 5| Step: 5
Training loss: 2.0970404148101807
Validation loss: 2.1464880108833313

Epoch: 5| Step: 6
Training loss: 2.552231550216675
Validation loss: 2.116262743870417

Epoch: 5| Step: 7
Training loss: 1.373761773109436
Validation loss: 2.096723794937134

Epoch: 5| Step: 8
Training loss: 1.8347737789154053
Validation loss: 2.0950821340084076

Epoch: 5| Step: 9
Training loss: 2.2088770866394043
Validation loss: 2.1035806834697723

Epoch: 5| Step: 10
Training loss: 1.715517282485962
Validation loss: 2.1010242948929467

Epoch: 5| Step: 11
Training loss: 0.9154155850410461
Validation loss: 2.1086073368787766

Epoch: 234| Step: 0
Training loss: 1.746260643005371
Validation loss: 2.1004519164562225

Epoch: 5| Step: 1
Training loss: 1.9132983684539795
Validation loss: 2.0945273439089456

Epoch: 5| Step: 2
Training loss: 1.7670507431030273
Validation loss: 2.1284110248088837

Epoch: 5| Step: 3
Training loss: 1.8005739450454712
Validation loss: 2.141992370287577

Epoch: 5| Step: 4
Training loss: 1.6928246021270752
Validation loss: 2.135475297768911

Epoch: 5| Step: 5
Training loss: 1.7043288946151733
Validation loss: 2.1457594831784568

Epoch: 5| Step: 6
Training loss: 2.3351593017578125
Validation loss: 2.1291566491127014

Epoch: 5| Step: 7
Training loss: 1.9154994487762451
Validation loss: 2.171287775039673

Epoch: 5| Step: 8
Training loss: 2.006925344467163
Validation loss: 2.1630459328492484

Epoch: 5| Step: 9
Training loss: 1.5800005197525024
Validation loss: 2.1706133832534156

Epoch: 5| Step: 10
Training loss: 1.6865904331207275
Validation loss: 2.1667648255825043

Epoch: 5| Step: 11
Training loss: 1.1071113348007202
Validation loss: 2.174738501509031

Epoch: 235| Step: 0
Training loss: 1.7050222158432007
Validation loss: 2.1700729429721832

Epoch: 5| Step: 1
Training loss: 1.6658308506011963
Validation loss: 2.1677796443303428

Epoch: 5| Step: 2
Training loss: 1.7645117044448853
Validation loss: 2.1524945894877114

Epoch: 5| Step: 3
Training loss: 2.1287121772766113
Validation loss: 2.163049211104711

Epoch: 5| Step: 4
Training loss: 1.3159762620925903
Validation loss: 2.14546737074852

Epoch: 5| Step: 5
Training loss: 1.8169820308685303
Validation loss: 2.1384340822696686

Epoch: 5| Step: 6
Training loss: 2.001579523086548
Validation loss: 2.1394669165213904

Epoch: 5| Step: 7
Training loss: 1.4953495264053345
Validation loss: 2.1413071056207023

Epoch: 5| Step: 8
Training loss: 1.8705263137817383
Validation loss: 2.1613531659046807

Epoch: 5| Step: 9
Training loss: 1.5628502368927002
Validation loss: 2.132742424805959

Epoch: 5| Step: 10
Training loss: 2.4185843467712402
Validation loss: 2.1326975574096045

Epoch: 5| Step: 11
Training loss: 2.273423433303833
Validation loss: 2.144749701023102

Epoch: 236| Step: 0
Training loss: 2.06312894821167
Validation loss: 2.133193035920461

Epoch: 5| Step: 1
Training loss: 2.0063979625701904
Validation loss: 2.1282508025566735

Epoch: 5| Step: 2
Training loss: 1.433739185333252
Validation loss: 2.1370310137669244

Epoch: 5| Step: 3
Training loss: 1.7151848077774048
Validation loss: 2.1217269798119864

Epoch: 5| Step: 4
Training loss: 1.8487695455551147
Validation loss: 2.1384824415047965

Epoch: 5| Step: 5
Training loss: 1.6741224527359009
Validation loss: 2.1393902699152627

Epoch: 5| Step: 6
Training loss: 1.5590568780899048
Validation loss: 2.1509936153888702

Epoch: 5| Step: 7
Training loss: 1.7488807439804077
Validation loss: 2.154663552840551

Epoch: 5| Step: 8
Training loss: 2.3545405864715576
Validation loss: 2.1175621449947357

Epoch: 5| Step: 9
Training loss: 1.5579593181610107
Validation loss: 2.124938279390335

Epoch: 5| Step: 10
Training loss: 1.6353477239608765
Validation loss: 2.118473748366038

Epoch: 5| Step: 11
Training loss: 3.1862316131591797
Validation loss: 2.115202859044075

Epoch: 237| Step: 0
Training loss: 1.6039247512817383
Validation loss: 2.130190148949623

Epoch: 5| Step: 1
Training loss: 1.8515170812606812
Validation loss: 2.1472218483686447

Epoch: 5| Step: 2
Training loss: 1.605798363685608
Validation loss: 2.156797006726265

Epoch: 5| Step: 3
Training loss: 2.302234172821045
Validation loss: 2.1765712251265845

Epoch: 5| Step: 4
Training loss: 1.883815050125122
Validation loss: 2.182912692427635

Epoch: 5| Step: 5
Training loss: 1.369727373123169
Validation loss: 2.159681975841522

Epoch: 5| Step: 6
Training loss: 1.6941564083099365
Validation loss: 2.1548707584540048

Epoch: 5| Step: 7
Training loss: 2.440772533416748
Validation loss: 2.141725738843282

Epoch: 5| Step: 8
Training loss: 1.8311243057250977
Validation loss: 2.1588395535945892

Epoch: 5| Step: 9
Training loss: 1.522040605545044
Validation loss: 2.1337386469046273

Epoch: 5| Step: 10
Training loss: 1.9492381811141968
Validation loss: 2.151223267118136

Epoch: 5| Step: 11
Training loss: 1.6626815795898438
Validation loss: 2.148033152023951

Epoch: 238| Step: 0
Training loss: 1.6921484470367432
Validation loss: 2.142325982451439

Epoch: 5| Step: 1
Training loss: 1.9939944744110107
Validation loss: 2.127867509921392

Epoch: 5| Step: 2
Training loss: 1.5512315034866333
Validation loss: 2.116615658005079

Epoch: 5| Step: 3
Training loss: 1.7842700481414795
Validation loss: 2.110458662112554

Epoch: 5| Step: 4
Training loss: 1.7309383153915405
Validation loss: 2.1098393152157464

Epoch: 5| Step: 5
Training loss: 1.5968687534332275
Validation loss: 2.097289964556694

Epoch: 5| Step: 6
Training loss: 2.2945518493652344
Validation loss: 2.0885441253582635

Epoch: 5| Step: 7
Training loss: 1.8150581121444702
Validation loss: 2.1194828848044076

Epoch: 5| Step: 8
Training loss: 1.7955124378204346
Validation loss: 2.1090976695219674

Epoch: 5| Step: 9
Training loss: 1.873079538345337
Validation loss: 2.126322423418363

Epoch: 5| Step: 10
Training loss: 2.059419870376587
Validation loss: 2.1320609549681344

Epoch: 5| Step: 11
Training loss: 1.2828013896942139
Validation loss: 2.1629344622294107

Epoch: 239| Step: 0
Training loss: 1.774120569229126
Validation loss: 2.173389494419098

Epoch: 5| Step: 1
Training loss: 1.9111340045928955
Validation loss: 2.1817840884129205

Epoch: 5| Step: 2
Training loss: 2.3587937355041504
Validation loss: 2.187313715616862

Epoch: 5| Step: 3
Training loss: 2.065417766571045
Validation loss: 2.1798884868621826

Epoch: 5| Step: 4
Training loss: 1.8596550226211548
Validation loss: 2.173142065604528

Epoch: 5| Step: 5
Training loss: 1.6505569219589233
Validation loss: 2.1668465783198676

Epoch: 5| Step: 6
Training loss: 2.072080135345459
Validation loss: 2.157999018828074

Epoch: 5| Step: 7
Training loss: 1.1536433696746826
Validation loss: 2.1710747877756753

Epoch: 5| Step: 8
Training loss: 1.8066074848175049
Validation loss: 2.183120717604955

Epoch: 5| Step: 9
Training loss: 1.8300888538360596
Validation loss: 2.1689379761616387

Epoch: 5| Step: 10
Training loss: 1.4745726585388184
Validation loss: 2.1642564634482064

Epoch: 5| Step: 11
Training loss: 1.6103354692459106
Validation loss: 2.1557447711626687

Epoch: 240| Step: 0
Training loss: 1.5020147562026978
Validation loss: 2.1603501737117767

Epoch: 5| Step: 1
Training loss: 1.4648338556289673
Validation loss: 2.1529684960842133

Epoch: 5| Step: 2
Training loss: 1.711111307144165
Validation loss: 2.1498574117819467

Epoch: 5| Step: 3
Training loss: 1.6290432214736938
Validation loss: 2.138958324988683

Epoch: 5| Step: 4
Training loss: 1.6449077129364014
Validation loss: 2.147302344441414

Epoch: 5| Step: 5
Training loss: 2.022571563720703
Validation loss: 2.1523866007725396

Epoch: 5| Step: 6
Training loss: 1.6705827713012695
Validation loss: 2.155383507410685

Epoch: 5| Step: 7
Training loss: 1.9122941493988037
Validation loss: 2.166182895501455

Epoch: 5| Step: 8
Training loss: 1.3656762838363647
Validation loss: 2.1508469631274543

Epoch: 5| Step: 9
Training loss: 2.8324272632598877
Validation loss: 2.1572893212238946

Epoch: 5| Step: 10
Training loss: 1.9703712463378906
Validation loss: 2.1398714085419974

Epoch: 5| Step: 11
Training loss: 2.1826934814453125
Validation loss: 2.122215593854586

Epoch: 241| Step: 0
Training loss: 1.5808968544006348
Validation loss: 2.126901830236117

Epoch: 5| Step: 1
Training loss: 1.1761420965194702
Validation loss: 2.115365003546079

Epoch: 5| Step: 2
Training loss: 1.6516740322113037
Validation loss: 2.1083420713742576

Epoch: 5| Step: 3
Training loss: 1.7075483798980713
Validation loss: 2.1162611146767936

Epoch: 5| Step: 4
Training loss: 1.6745977401733398
Validation loss: 2.1094792087872825

Epoch: 5| Step: 5
Training loss: 2.0453357696533203
Validation loss: 2.1094646404186883

Epoch: 5| Step: 6
Training loss: 1.6283636093139648
Validation loss: 2.1095329374074936

Epoch: 5| Step: 7
Training loss: 2.137148857116699
Validation loss: 2.129991059501966

Epoch: 5| Step: 8
Training loss: 1.6623576879501343
Validation loss: 2.141297861933708

Epoch: 5| Step: 9
Training loss: 2.5317883491516113
Validation loss: 2.124761253595352

Epoch: 5| Step: 10
Training loss: 2.0595710277557373
Validation loss: 2.133604576190313

Epoch: 5| Step: 11
Training loss: 1.5669978857040405
Validation loss: 2.1357563634713492

Epoch: 242| Step: 0
Training loss: 1.3962037563323975
Validation loss: 2.1297235091527305

Epoch: 5| Step: 1
Training loss: 1.5001643896102905
Validation loss: 2.1405741373697915

Epoch: 5| Step: 2
Training loss: 1.7033357620239258
Validation loss: 2.1393509109814963

Epoch: 5| Step: 3
Training loss: 1.8662850856781006
Validation loss: 2.1296584208806357

Epoch: 5| Step: 4
Training loss: 1.3561116456985474
Validation loss: 2.137384846806526

Epoch: 5| Step: 5
Training loss: 1.8072564601898193
Validation loss: 2.127837603290876

Epoch: 5| Step: 6
Training loss: 1.9465599060058594
Validation loss: 2.114998867114385

Epoch: 5| Step: 7
Training loss: 1.8611873388290405
Validation loss: 2.119122236967087

Epoch: 5| Step: 8
Training loss: 1.5227959156036377
Validation loss: 2.121764009197553

Epoch: 5| Step: 9
Training loss: 2.1483993530273438
Validation loss: 2.1248638232549033

Epoch: 5| Step: 10
Training loss: 2.3325021266937256
Validation loss: 2.1393382996320724

Epoch: 5| Step: 11
Training loss: 3.50242280960083
Validation loss: 2.1376299808422723

Epoch: 243| Step: 0
Training loss: 1.7689437866210938
Validation loss: 2.156194175283114

Epoch: 5| Step: 1
Training loss: 2.1293320655822754
Validation loss: 2.1625981479883194

Epoch: 5| Step: 2
Training loss: 1.6713058948516846
Validation loss: 2.1702146430810294

Epoch: 5| Step: 3
Training loss: 2.054830551147461
Validation loss: 2.163461113969485

Epoch: 5| Step: 4
Training loss: 1.8964378833770752
Validation loss: 2.1656416157881417

Epoch: 5| Step: 5
Training loss: 1.6913172006607056
Validation loss: 2.1368437310059867

Epoch: 5| Step: 6
Training loss: 1.499447226524353
Validation loss: 2.1373416086037955

Epoch: 5| Step: 7
Training loss: 1.9491798877716064
Validation loss: 2.146841218074163

Epoch: 5| Step: 8
Training loss: 1.535869836807251
Validation loss: 2.134429241220156

Epoch: 5| Step: 9
Training loss: 1.8328540325164795
Validation loss: 2.1220675806204476

Epoch: 5| Step: 10
Training loss: 1.9526011943817139
Validation loss: 2.119875987370809

Epoch: 5| Step: 11
Training loss: 1.9790990352630615
Validation loss: 2.1111249526341758

Epoch: 244| Step: 0
Training loss: 1.4024842977523804
Validation loss: 2.1050529380639396

Epoch: 5| Step: 1
Training loss: 1.462057113647461
Validation loss: 2.1048190842072168

Epoch: 5| Step: 2
Training loss: 1.6447664499282837
Validation loss: 2.103024572134018

Epoch: 5| Step: 3
Training loss: 1.868491768836975
Validation loss: 2.105553279320399

Epoch: 5| Step: 4
Training loss: 1.3606163263320923
Validation loss: 2.0925773282845817

Epoch: 5| Step: 5
Training loss: 2.028820037841797
Validation loss: 2.1376912941535315

Epoch: 5| Step: 6
Training loss: 2.0136656761169434
Validation loss: 2.181621472040812

Epoch: 5| Step: 7
Training loss: 1.7946590185165405
Validation loss: 2.1770815004905066

Epoch: 5| Step: 8
Training loss: 2.208763360977173
Validation loss: 2.1841641664505005

Epoch: 5| Step: 9
Training loss: 1.904844880104065
Validation loss: 2.1318645824988685

Epoch: 5| Step: 10
Training loss: 2.0793278217315674
Validation loss: 2.1648492515087128

Epoch: 5| Step: 11
Training loss: 2.936652421951294
Validation loss: 2.1621563931306205

Epoch: 245| Step: 0
Training loss: 1.9733216762542725
Validation loss: 2.1741275091965995

Epoch: 5| Step: 1
Training loss: 1.6018412113189697
Validation loss: 2.145555019378662

Epoch: 5| Step: 2
Training loss: 1.5922588109970093
Validation loss: 2.1356745958328247

Epoch: 5| Step: 3
Training loss: 1.8297319412231445
Validation loss: 2.093161424001058

Epoch: 5| Step: 4
Training loss: 1.5707967281341553
Validation loss: 2.091235796610514

Epoch: 5| Step: 5
Training loss: 2.08268141746521
Validation loss: 2.0894943376382193

Epoch: 5| Step: 6
Training loss: 1.8927043676376343
Validation loss: 2.081246723731359

Epoch: 5| Step: 7
Training loss: 2.262037754058838
Validation loss: 2.086383601029714

Epoch: 5| Step: 8
Training loss: 2.4454853534698486
Validation loss: 2.1035719364881516

Epoch: 5| Step: 9
Training loss: 1.6481068134307861
Validation loss: 2.0742401281992593

Epoch: 5| Step: 10
Training loss: 1.965314269065857
Validation loss: 2.0679532239834466

Epoch: 5| Step: 11
Training loss: 1.8007011413574219
Validation loss: 2.0857084343830743

Epoch: 246| Step: 0
Training loss: 1.7044436931610107
Validation loss: 2.079162289698919

Epoch: 5| Step: 1
Training loss: 2.471050977706909
Validation loss: 2.084028040369352

Epoch: 5| Step: 2
Training loss: 1.9732043743133545
Validation loss: 2.078108857075373

Epoch: 5| Step: 3
Training loss: 1.5475393533706665
Validation loss: 2.077643613020579

Epoch: 5| Step: 4
Training loss: 2.221497058868408
Validation loss: 2.0924212584892907

Epoch: 5| Step: 5
Training loss: 1.794563889503479
Validation loss: 2.1152597069740295

Epoch: 5| Step: 6
Training loss: 1.8094511032104492
Validation loss: 2.114846110343933

Epoch: 5| Step: 7
Training loss: 2.0068557262420654
Validation loss: 2.141722470521927

Epoch: 5| Step: 8
Training loss: 1.4446003437042236
Validation loss: 2.1445988615353904

Epoch: 5| Step: 9
Training loss: 1.6062225103378296
Validation loss: 2.1486207097768784

Epoch: 5| Step: 10
Training loss: 1.776052474975586
Validation loss: 2.1316033701101937

Epoch: 5| Step: 11
Training loss: 1.7241336107254028
Validation loss: 2.1623851656913757

Epoch: 247| Step: 0
Training loss: 2.3316233158111572
Validation loss: 2.1421872029701867

Epoch: 5| Step: 1
Training loss: 1.7177603244781494
Validation loss: 2.1550920655330024

Epoch: 5| Step: 2
Training loss: 1.7417128086090088
Validation loss: 2.1694640864928565

Epoch: 5| Step: 3
Training loss: 1.6145585775375366
Validation loss: 2.1622370332479477

Epoch: 5| Step: 4
Training loss: 1.8792438507080078
Validation loss: 2.1298874715964

Epoch: 5| Step: 5
Training loss: 1.9293696880340576
Validation loss: 2.1136029760042825

Epoch: 5| Step: 6
Training loss: 1.644357442855835
Validation loss: 2.113075782855352

Epoch: 5| Step: 7
Training loss: 2.0414695739746094
Validation loss: 2.111551915605863

Epoch: 5| Step: 8
Training loss: 1.2964239120483398
Validation loss: 2.130038782954216

Epoch: 5| Step: 9
Training loss: 1.7387306690216064
Validation loss: 2.119811624288559

Epoch: 5| Step: 10
Training loss: 2.241786241531372
Validation loss: 2.1593889743089676

Epoch: 5| Step: 11
Training loss: 1.2716145515441895
Validation loss: 2.1658574839433036

Epoch: 248| Step: 0
Training loss: 1.9193906784057617
Validation loss: 2.17719367146492

Epoch: 5| Step: 1
Training loss: 2.058213710784912
Validation loss: 2.18716328839461

Epoch: 5| Step: 2
Training loss: 1.7720531225204468
Validation loss: 2.183093080917994

Epoch: 5| Step: 3
Training loss: 1.327012538909912
Validation loss: 2.2082396000623703

Epoch: 5| Step: 4
Training loss: 1.289465308189392
Validation loss: 2.1830570697784424

Epoch: 5| Step: 5
Training loss: 1.487729787826538
Validation loss: 2.1996737718582153

Epoch: 5| Step: 6
Training loss: 2.109595775604248
Validation loss: 2.182136823733648

Epoch: 5| Step: 7
Training loss: 2.265671491622925
Validation loss: 2.1613039871056876

Epoch: 5| Step: 8
Training loss: 2.0774786472320557
Validation loss: 2.1266519278287888

Epoch: 5| Step: 9
Training loss: 1.9409122467041016
Validation loss: 2.1257205108801522

Epoch: 5| Step: 10
Training loss: 1.6568076610565186
Validation loss: 2.127889255682627

Epoch: 5| Step: 11
Training loss: 1.4100162982940674
Validation loss: 2.1164559026559195

Epoch: 249| Step: 0
Training loss: 1.8644605875015259
Validation loss: 2.102915897965431

Epoch: 5| Step: 1
Training loss: 1.616290807723999
Validation loss: 2.085108215610186

Epoch: 5| Step: 2
Training loss: 1.6073791980743408
Validation loss: 2.0989940067132316

Epoch: 5| Step: 3
Training loss: 1.4531688690185547
Validation loss: 2.0943741649389267

Epoch: 5| Step: 4
Training loss: 3.2027530670166016
Validation loss: 2.085658147931099

Epoch: 5| Step: 5
Training loss: 2.0049147605895996
Validation loss: 2.0956541101137796

Epoch: 5| Step: 6
Training loss: 1.675034761428833
Validation loss: 2.099331105748812

Epoch: 5| Step: 7
Training loss: 1.5587866306304932
Validation loss: 2.1162376403808594

Epoch: 5| Step: 8
Training loss: 1.5912015438079834
Validation loss: 2.1243010262648263

Epoch: 5| Step: 9
Training loss: 2.006772518157959
Validation loss: 2.1492019494374595

Epoch: 5| Step: 10
Training loss: 1.4253778457641602
Validation loss: 2.1484792480866113

Epoch: 5| Step: 11
Training loss: 2.2641820907592773
Validation loss: 2.156204417347908

Epoch: 250| Step: 0
Training loss: 2.036790132522583
Validation loss: 2.1570735375086465

Epoch: 5| Step: 1
Training loss: 1.8415014743804932
Validation loss: 2.1650399019320807

Epoch: 5| Step: 2
Training loss: 1.880914330482483
Validation loss: 2.1631087760130563

Epoch: 5| Step: 3
Training loss: 1.9987850189208984
Validation loss: 2.160546769698461

Epoch: 5| Step: 4
Training loss: 1.206457257270813
Validation loss: 2.1547838846842446

Epoch: 5| Step: 5
Training loss: 1.6034694910049438
Validation loss: 2.1570697526137033

Epoch: 5| Step: 6
Training loss: 2.3057100772857666
Validation loss: 2.157366250952085

Epoch: 5| Step: 7
Training loss: 2.0496826171875
Validation loss: 2.142667959133784

Epoch: 5| Step: 8
Training loss: 1.3458585739135742
Validation loss: 2.144480054577192

Epoch: 5| Step: 9
Training loss: 1.2895472049713135
Validation loss: 2.1374170184135437

Epoch: 5| Step: 10
Training loss: 2.4277873039245605
Validation loss: 2.1475781400998435

Epoch: 5| Step: 11
Training loss: 1.058709740638733
Validation loss: 2.1620443165302277

Epoch: 251| Step: 0
Training loss: 1.8406293392181396
Validation loss: 2.1789286037286124

Epoch: 5| Step: 1
Training loss: 1.3007619380950928
Validation loss: 2.1742545117934546

Epoch: 5| Step: 2
Training loss: 1.340745210647583
Validation loss: 2.1751826802889505

Epoch: 5| Step: 3
Training loss: 1.9081614017486572
Validation loss: 2.1573569675286612

Epoch: 5| Step: 4
Training loss: 2.1712093353271484
Validation loss: 2.1743639409542084

Epoch: 5| Step: 5
Training loss: 2.254412889480591
Validation loss: 2.1799219201008477

Epoch: 5| Step: 6
Training loss: 2.190364122390747
Validation loss: 2.171585202217102

Epoch: 5| Step: 7
Training loss: 1.3060224056243896
Validation loss: 2.172354499499003

Epoch: 5| Step: 8
Training loss: 1.669936180114746
Validation loss: 2.185969263315201

Epoch: 5| Step: 9
Training loss: 1.469602108001709
Validation loss: 2.161972920099894

Epoch: 5| Step: 10
Training loss: 1.8436905145645142
Validation loss: 2.16200744609038

Epoch: 5| Step: 11
Training loss: 2.4816198348999023
Validation loss: 2.1516875525315604

Epoch: 252| Step: 0
Training loss: 1.6939483880996704
Validation loss: 2.149860997994741

Epoch: 5| Step: 1
Training loss: 1.8982728719711304
Validation loss: 2.1617056280374527

Epoch: 5| Step: 2
Training loss: 1.807167410850525
Validation loss: 2.162018209695816

Epoch: 5| Step: 3
Training loss: 1.4327976703643799
Validation loss: 2.148913264274597

Epoch: 5| Step: 4
Training loss: 1.883998155593872
Validation loss: 2.1647273103396096

Epoch: 5| Step: 5
Training loss: 1.9012649059295654
Validation loss: 2.1775587797164917

Epoch: 5| Step: 6
Training loss: 2.0724716186523438
Validation loss: 2.196424921353658

Epoch: 5| Step: 7
Training loss: 1.3259119987487793
Validation loss: 2.1777531852324805

Epoch: 5| Step: 8
Training loss: 1.2499701976776123
Validation loss: 2.1942690014839172

Epoch: 5| Step: 9
Training loss: 1.6650426387786865
Validation loss: 2.1920272409915924

Epoch: 5| Step: 10
Training loss: 2.2988972663879395
Validation loss: 2.19465379913648

Epoch: 5| Step: 11
Training loss: 1.261941909790039
Validation loss: 2.187998274962107

Epoch: 253| Step: 0
Training loss: 2.148193836212158
Validation loss: 2.1921331038077674

Epoch: 5| Step: 1
Training loss: 1.3595211505889893
Validation loss: 2.174908791979154

Epoch: 5| Step: 2
Training loss: 1.3898844718933105
Validation loss: 2.1412838796774545

Epoch: 5| Step: 3
Training loss: 1.755661964416504
Validation loss: 2.1273962954680123

Epoch: 5| Step: 4
Training loss: 1.627861738204956
Validation loss: 2.1189420421918235

Epoch: 5| Step: 5
Training loss: 2.0748724937438965
Validation loss: 2.1187038669983544

Epoch: 5| Step: 6
Training loss: 1.95591139793396
Validation loss: 2.117174898584684

Epoch: 5| Step: 7
Training loss: 2.5585336685180664
Validation loss: 2.1413533091545105

Epoch: 5| Step: 8
Training loss: 1.5584921836853027
Validation loss: 2.131651426355044

Epoch: 5| Step: 9
Training loss: 1.5180379152297974
Validation loss: 2.132922242085139

Epoch: 5| Step: 10
Training loss: 1.7237640619277954
Validation loss: 2.1396318127711615

Epoch: 5| Step: 11
Training loss: 1.960044026374817
Validation loss: 2.1532668322324753

Epoch: 254| Step: 0
Training loss: 1.8894898891448975
Validation loss: 2.1805259386698403

Epoch: 5| Step: 1
Training loss: 1.857892632484436
Validation loss: 2.1708701650301614

Epoch: 5| Step: 2
Training loss: 1.7614266872406006
Validation loss: 2.1762246191501617

Epoch: 5| Step: 3
Training loss: 2.2230522632598877
Validation loss: 2.1702961921691895

Epoch: 5| Step: 4
Training loss: 1.6398909091949463
Validation loss: 2.1625163157780967

Epoch: 5| Step: 5
Training loss: 1.5173386335372925
Validation loss: 2.1571531842152276

Epoch: 5| Step: 6
Training loss: 1.8702948093414307
Validation loss: 2.147065301736196

Epoch: 5| Step: 7
Training loss: 1.9219974279403687
Validation loss: 2.1447042524814606

Epoch: 5| Step: 8
Training loss: 1.5493911504745483
Validation loss: 2.13571069141229

Epoch: 5| Step: 9
Training loss: 1.879568099975586
Validation loss: 2.1277846843004227

Epoch: 5| Step: 10
Training loss: 1.4635469913482666
Validation loss: 2.131616711616516

Epoch: 5| Step: 11
Training loss: 1.603856086730957
Validation loss: 2.1511058857043586

Epoch: 255| Step: 0
Training loss: 1.2300156354904175
Validation loss: 2.1434452484051385

Epoch: 5| Step: 1
Training loss: 0.9323204755783081
Validation loss: 2.15163454413414

Epoch: 5| Step: 2
Training loss: 1.931098222732544
Validation loss: 2.144575983285904

Epoch: 5| Step: 3
Training loss: 1.9873206615447998
Validation loss: 2.175022338827451

Epoch: 5| Step: 4
Training loss: 1.6938016414642334
Validation loss: 2.1542008171478906

Epoch: 5| Step: 5
Training loss: 2.077556848526001
Validation loss: 2.1710314949353537

Epoch: 5| Step: 6
Training loss: 1.8926074504852295
Validation loss: 2.173378904660543

Epoch: 5| Step: 7
Training loss: 2.3712916374206543
Validation loss: 2.1781766414642334

Epoch: 5| Step: 8
Training loss: 1.901869535446167
Validation loss: 2.158459727962812

Epoch: 5| Step: 9
Training loss: 1.5848900079727173
Validation loss: 2.1755399306615195

Epoch: 5| Step: 10
Training loss: 1.5776690244674683
Validation loss: 2.1665310164292655

Epoch: 5| Step: 11
Training loss: 2.060826301574707
Validation loss: 2.1536501348018646

Epoch: 256| Step: 0
Training loss: 1.78768789768219
Validation loss: 2.1381772061189017

Epoch: 5| Step: 1
Training loss: 1.6213243007659912
Validation loss: 2.121835226813952

Epoch: 5| Step: 2
Training loss: 2.3893980979919434
Validation loss: 2.1048922489086785

Epoch: 5| Step: 3
Training loss: 1.5984675884246826
Validation loss: 2.107422689596812

Epoch: 5| Step: 4
Training loss: 2.070636510848999
Validation loss: 2.1070873886346817

Epoch: 5| Step: 5
Training loss: 1.6908977031707764
Validation loss: 2.126638034979502

Epoch: 5| Step: 6
Training loss: 1.8613364696502686
Validation loss: 2.126852830251058

Epoch: 5| Step: 7
Training loss: 1.4062248468399048
Validation loss: 2.142859697341919

Epoch: 5| Step: 8
Training loss: 1.8465149402618408
Validation loss: 2.1554381450017295

Epoch: 5| Step: 9
Training loss: 1.632520079612732
Validation loss: 2.161590705315272

Epoch: 5| Step: 10
Training loss: 1.3966515064239502
Validation loss: 2.1440226833025613

Epoch: 5| Step: 11
Training loss: 1.2431167364120483
Validation loss: 2.1736131409804025

Epoch: 257| Step: 0
Training loss: 1.1864616870880127
Validation loss: 2.1653187771638236

Epoch: 5| Step: 1
Training loss: 1.6133196353912354
Validation loss: 2.1580590903759003

Epoch: 5| Step: 2
Training loss: 1.6213048696517944
Validation loss: 2.142012049754461

Epoch: 5| Step: 3
Training loss: 1.4033576250076294
Validation loss: 2.1513145913680396

Epoch: 5| Step: 4
Training loss: 1.451841115951538
Validation loss: 2.15408663948377

Epoch: 5| Step: 5
Training loss: 1.8794578313827515
Validation loss: 2.1533259550730386

Epoch: 5| Step: 6
Training loss: 1.3585673570632935
Validation loss: 2.143554305036863

Epoch: 5| Step: 7
Training loss: 1.1683824062347412
Validation loss: 2.1387472500403724

Epoch: 5| Step: 8
Training loss: 2.5155251026153564
Validation loss: 2.1229884972174964

Epoch: 5| Step: 9
Training loss: 1.9586174488067627
Validation loss: 2.1142230331897736

Epoch: 5| Step: 10
Training loss: 2.658022403717041
Validation loss: 2.116522560516993

Epoch: 5| Step: 11
Training loss: 2.088345527648926
Validation loss: 2.134010742108027

Epoch: 258| Step: 0
Training loss: 1.359184741973877
Validation loss: 2.124819169441859

Epoch: 5| Step: 1
Training loss: 2.2437777519226074
Validation loss: 2.142716000477473

Epoch: 5| Step: 2
Training loss: 2.4033420085906982
Validation loss: 2.1839893460273743

Epoch: 5| Step: 3
Training loss: 1.506475806236267
Validation loss: 2.1661589791377387

Epoch: 5| Step: 4
Training loss: 1.6099134683609009
Validation loss: 2.1590126305818558

Epoch: 5| Step: 5
Training loss: 1.3385581970214844
Validation loss: 2.148135686914126

Epoch: 5| Step: 6
Training loss: 2.0999271869659424
Validation loss: 2.1490545074144998

Epoch: 5| Step: 7
Training loss: 2.0422749519348145
Validation loss: 2.1832419335842133

Epoch: 5| Step: 8
Training loss: 1.703662633895874
Validation loss: 2.18788735071818

Epoch: 5| Step: 9
Training loss: 1.6013129949569702
Validation loss: 2.1817458818356195

Epoch: 5| Step: 10
Training loss: 1.6852281093597412
Validation loss: 2.1629533171653748

Epoch: 5| Step: 11
Training loss: 1.3296067714691162
Validation loss: 2.137156734863917

Epoch: 259| Step: 0
Training loss: 1.7825874090194702
Validation loss: 2.1187561651070914

Epoch: 5| Step: 1
Training loss: 1.915151834487915
Validation loss: 2.1118198235829673

Epoch: 5| Step: 2
Training loss: 1.687583327293396
Validation loss: 2.0971146325270333

Epoch: 5| Step: 3
Training loss: 2.2909903526306152
Validation loss: 2.1006381511688232

Epoch: 5| Step: 4
Training loss: 1.618354082107544
Validation loss: 2.110398516058922

Epoch: 5| Step: 5
Training loss: 1.785068154335022
Validation loss: 2.1185511350631714

Epoch: 5| Step: 6
Training loss: 1.8455654382705688
Validation loss: 2.1394812365372977

Epoch: 5| Step: 7
Training loss: 1.3046691417694092
Validation loss: 2.1396462619304657

Epoch: 5| Step: 8
Training loss: 1.403490424156189
Validation loss: 2.1392170637845993

Epoch: 5| Step: 9
Training loss: 2.229149580001831
Validation loss: 2.1327085494995117

Epoch: 5| Step: 10
Training loss: 1.734106421470642
Validation loss: 2.1450170427560806

Epoch: 5| Step: 11
Training loss: 0.730131983757019
Validation loss: 2.1378115862607956

Epoch: 260| Step: 0
Training loss: 1.9768680334091187
Validation loss: 2.1297320425510406

Epoch: 5| Step: 1
Training loss: 1.824284315109253
Validation loss: 2.145473207036654

Epoch: 5| Step: 2
Training loss: 1.3851555585861206
Validation loss: 2.1627641916275024

Epoch: 5| Step: 3
Training loss: 1.2175085544586182
Validation loss: 2.166579266389211

Epoch: 5| Step: 4
Training loss: 1.8057464361190796
Validation loss: 2.168441971143087

Epoch: 5| Step: 5
Training loss: 1.7637859582901
Validation loss: 2.189178943634033

Epoch: 5| Step: 6
Training loss: 1.7687324285507202
Validation loss: 2.1696767757336297

Epoch: 5| Step: 7
Training loss: 2.2950797080993652
Validation loss: 2.176211108764013

Epoch: 5| Step: 8
Training loss: 1.3037446737289429
Validation loss: 2.1811277319987616

Epoch: 5| Step: 9
Training loss: 1.4356580972671509
Validation loss: 2.1738612155119577

Epoch: 5| Step: 10
Training loss: 2.2564055919647217
Validation loss: 2.1594303250312805

Epoch: 5| Step: 11
Training loss: 1.662730097770691
Validation loss: 2.1693486670653024

Epoch: 261| Step: 0
Training loss: 1.2468057870864868
Validation loss: 2.148141399025917

Epoch: 5| Step: 1
Training loss: 2.092836856842041
Validation loss: 2.133201609055201

Epoch: 5| Step: 2
Training loss: 1.461359977722168
Validation loss: 2.1418382227420807

Epoch: 5| Step: 3
Training loss: 1.8220787048339844
Validation loss: 2.1170401374499

Epoch: 5| Step: 4
Training loss: 1.937569260597229
Validation loss: 2.1219658652941384

Epoch: 5| Step: 5
Training loss: 1.8196582794189453
Validation loss: 2.0978014369805655

Epoch: 5| Step: 6
Training loss: 1.641330361366272
Validation loss: 2.1039296885331473

Epoch: 5| Step: 7
Training loss: 1.3611749410629272
Validation loss: 2.1029702673355737

Epoch: 5| Step: 8
Training loss: 1.8122355937957764
Validation loss: 2.127827445665995

Epoch: 5| Step: 9
Training loss: 2.249582529067993
Validation loss: 2.116169879833857

Epoch: 5| Step: 10
Training loss: 1.3499943017959595
Validation loss: 2.1629902720451355

Epoch: 5| Step: 11
Training loss: 1.8733365535736084
Validation loss: 2.1759068767229715

Epoch: 262| Step: 0
Training loss: 1.8859100341796875
Validation loss: 2.1640779922405877

Epoch: 5| Step: 1
Training loss: 1.7578471899032593
Validation loss: 2.174884339173635

Epoch: 5| Step: 2
Training loss: 2.055197238922119
Validation loss: 2.1545908947785697

Epoch: 5| Step: 3
Training loss: 1.4474749565124512
Validation loss: 2.1530633866786957

Epoch: 5| Step: 4
Training loss: 1.8945655822753906
Validation loss: 2.1605707903703055

Epoch: 5| Step: 5
Training loss: 1.2454907894134521
Validation loss: 2.154686138033867

Epoch: 5| Step: 6
Training loss: 2.151134967803955
Validation loss: 2.1325036535660424

Epoch: 5| Step: 7
Training loss: 2.2622628211975098
Validation loss: 2.1137392471234002

Epoch: 5| Step: 8
Training loss: 1.7986587285995483
Validation loss: 2.1072155435880027

Epoch: 5| Step: 9
Training loss: 1.1149141788482666
Validation loss: 2.1027372578779855

Epoch: 5| Step: 10
Training loss: 1.7149937152862549
Validation loss: 2.102481633424759

Epoch: 5| Step: 11
Training loss: 1.9930694103240967
Validation loss: 2.111468325058619

Epoch: 263| Step: 0
Training loss: 2.757294178009033
Validation loss: 2.1061114321152368

Epoch: 5| Step: 1
Training loss: 2.0311734676361084
Validation loss: 2.09794349471728

Epoch: 5| Step: 2
Training loss: 1.7393357753753662
Validation loss: 2.0919534315665564

Epoch: 5| Step: 3
Training loss: 1.719792366027832
Validation loss: 2.0908518532911935

Epoch: 5| Step: 4
Training loss: 1.6544901132583618
Validation loss: 2.1296266913414

Epoch: 5| Step: 5
Training loss: 1.6253316402435303
Validation loss: 2.143243983387947

Epoch: 5| Step: 6
Training loss: 1.4433183670043945
Validation loss: 2.1666429738203683

Epoch: 5| Step: 7
Training loss: 1.8107751607894897
Validation loss: 2.197076971332232

Epoch: 5| Step: 8
Training loss: 1.4645743370056152
Validation loss: 2.2096300224463143

Epoch: 5| Step: 9
Training loss: 1.6847991943359375
Validation loss: 2.220576504866282

Epoch: 5| Step: 10
Training loss: 1.5889995098114014
Validation loss: 2.2101020415623984

Epoch: 5| Step: 11
Training loss: 3.041860580444336
Validation loss: 2.186585063735644

Epoch: 264| Step: 0
Training loss: 1.8899257183074951
Validation loss: 2.176153073708216

Epoch: 5| Step: 1
Training loss: 1.720458984375
Validation loss: 2.1826361219088235

Epoch: 5| Step: 2
Training loss: 1.9193092584609985
Validation loss: 2.1574387152989707

Epoch: 5| Step: 3
Training loss: 1.3418033123016357
Validation loss: 2.1717385152975717

Epoch: 5| Step: 4
Training loss: 2.0191574096679688
Validation loss: 2.1667961329221725

Epoch: 5| Step: 5
Training loss: 1.554783582687378
Validation loss: 2.1667204101880393

Epoch: 5| Step: 6
Training loss: 1.8728315830230713
Validation loss: 2.148546263575554

Epoch: 5| Step: 7
Training loss: 1.7923263311386108
Validation loss: 2.1224493285020194

Epoch: 5| Step: 8
Training loss: 1.7666749954223633
Validation loss: 2.115569591522217

Epoch: 5| Step: 9
Training loss: 1.7519527673721313
Validation loss: 2.1234511037667594

Epoch: 5| Step: 10
Training loss: 1.5074741840362549
Validation loss: 2.1029429535071054

Epoch: 5| Step: 11
Training loss: 2.3012869358062744
Validation loss: 2.1119765241940818

Epoch: 265| Step: 0
Training loss: 1.4344508647918701
Validation loss: 2.1085878858963647

Epoch: 5| Step: 1
Training loss: 1.758867621421814
Validation loss: 2.103889768322309

Epoch: 5| Step: 2
Training loss: 1.5871145725250244
Validation loss: 2.104623089234034

Epoch: 5| Step: 3
Training loss: 2.7835490703582764
Validation loss: 2.1047251919905343

Epoch: 5| Step: 4
Training loss: 1.6106112003326416
Validation loss: 2.0910825381676355

Epoch: 5| Step: 5
Training loss: 1.6853225231170654
Validation loss: 2.122373958428701

Epoch: 5| Step: 6
Training loss: 1.465893030166626
Validation loss: 2.131089652578036

Epoch: 5| Step: 7
Training loss: 1.910583734512329
Validation loss: 2.149871895710627

Epoch: 5| Step: 8
Training loss: 2.0090231895446777
Validation loss: 2.1417049864927926

Epoch: 5| Step: 9
Training loss: 1.6357266902923584
Validation loss: 2.128135139743487

Epoch: 5| Step: 10
Training loss: 1.7739585638046265
Validation loss: 2.169007897377014

Epoch: 5| Step: 11
Training loss: 1.8106365203857422
Validation loss: 2.168251007795334

Epoch: 266| Step: 0
Training loss: 1.2746325731277466
Validation loss: 2.156099413832029

Epoch: 5| Step: 1
Training loss: 2.078223705291748
Validation loss: 2.1844066977500916

Epoch: 5| Step: 2
Training loss: 1.358250379562378
Validation loss: 2.1886685142914453

Epoch: 5| Step: 3
Training loss: 1.7866817712783813
Validation loss: 2.1814492841561637

Epoch: 5| Step: 4
Training loss: 1.598008394241333
Validation loss: 2.1949645777543387

Epoch: 5| Step: 5
Training loss: 1.672113060951233
Validation loss: 2.2121422390143075

Epoch: 5| Step: 6
Training loss: 1.662213921546936
Validation loss: 2.1936184416214624

Epoch: 5| Step: 7
Training loss: 1.7367244958877563
Validation loss: 2.164027124643326

Epoch: 5| Step: 8
Training loss: 2.1583971977233887
Validation loss: 2.111593618988991

Epoch: 5| Step: 9
Training loss: 1.7296745777130127
Validation loss: 2.1078826189041138

Epoch: 5| Step: 10
Training loss: 2.0192320346832275
Validation loss: 2.133386015892029

Epoch: 5| Step: 11
Training loss: 2.114440441131592
Validation loss: 2.109910393754641

Epoch: 267| Step: 0
Training loss: 1.6971009969711304
Validation loss: 2.142065107822418

Epoch: 5| Step: 1
Training loss: 1.312721848487854
Validation loss: 2.1685895323753357

Epoch: 5| Step: 2
Training loss: 2.8187177181243896
Validation loss: 2.194136659304301

Epoch: 5| Step: 3
Training loss: 1.7234036922454834
Validation loss: 2.2266067266464233

Epoch: 5| Step: 4
Training loss: 1.1729004383087158
Validation loss: 2.238217204809189

Epoch: 5| Step: 5
Training loss: 1.7671693563461304
Validation loss: 2.2033167680104575

Epoch: 5| Step: 6
Training loss: 1.2387093305587769
Validation loss: 2.236055384079615

Epoch: 5| Step: 7
Training loss: 1.2495746612548828
Validation loss: 2.228055715560913

Epoch: 5| Step: 8
Training loss: 2.0894222259521484
Validation loss: 2.1934204449256263

Epoch: 5| Step: 9
Training loss: 1.913799524307251
Validation loss: 2.1826791564623513

Epoch: 5| Step: 10
Training loss: 1.702114462852478
Validation loss: 2.162167320648829

Epoch: 5| Step: 11
Training loss: 1.870068073272705
Validation loss: 2.122119203209877

Epoch: 268| Step: 0
Training loss: 1.8193340301513672
Validation loss: 2.1376716991265616

Epoch: 5| Step: 1
Training loss: 1.5626423358917236
Validation loss: 2.1340520828962326

Epoch: 5| Step: 2
Training loss: 2.0860743522644043
Validation loss: 2.1218851755062738

Epoch: 5| Step: 3
Training loss: 1.7006425857543945
Validation loss: 2.1309160937865577

Epoch: 5| Step: 4
Training loss: 1.5225622653961182
Validation loss: 2.1265526711940765

Epoch: 5| Step: 5
Training loss: 2.0697388648986816
Validation loss: 2.136246085166931

Epoch: 5| Step: 6
Training loss: 2.0592265129089355
Validation loss: 2.1373617748419442

Epoch: 5| Step: 7
Training loss: 1.495680570602417
Validation loss: 2.1634440422058105

Epoch: 5| Step: 8
Training loss: 1.2013800144195557
Validation loss: 2.166690240303675

Epoch: 5| Step: 9
Training loss: 1.6151721477508545
Validation loss: 2.1598834892114005

Epoch: 5| Step: 10
Training loss: 1.5932809114456177
Validation loss: 2.158306991060575

Epoch: 5| Step: 11
Training loss: 1.308090329170227
Validation loss: 2.163318768143654

Epoch: 269| Step: 0
Training loss: 1.2799016237258911
Validation loss: 2.1561531027158103

Epoch: 5| Step: 1
Training loss: 1.4779540300369263
Validation loss: 2.1452606866757074

Epoch: 5| Step: 2
Training loss: 1.8262994289398193
Validation loss: 2.162674749890963

Epoch: 5| Step: 3
Training loss: 2.1009888648986816
Validation loss: 2.1584972937901816

Epoch: 5| Step: 4
Training loss: 1.721173644065857
Validation loss: 2.1911863485972085

Epoch: 5| Step: 5
Training loss: 2.02929949760437
Validation loss: 2.1777783036231995

Epoch: 5| Step: 6
Training loss: 1.5775249004364014
Validation loss: 2.179745684067408

Epoch: 5| Step: 7
Training loss: 1.9342727661132812
Validation loss: 2.170841877659162

Epoch: 5| Step: 8
Training loss: 1.5977363586425781
Validation loss: 2.1704134295384088

Epoch: 5| Step: 9
Training loss: 1.3604440689086914
Validation loss: 2.1731202056010566

Epoch: 5| Step: 10
Training loss: 1.6119868755340576
Validation loss: 2.1729344874620438

Epoch: 5| Step: 11
Training loss: 1.1498161554336548
Validation loss: 2.1767495423555374

Epoch: 270| Step: 0
Training loss: 1.7525949478149414
Validation loss: 2.1584931214650473

Epoch: 5| Step: 1
Training loss: 1.4108582735061646
Validation loss: 2.177317281564077

Epoch: 5| Step: 2
Training loss: 1.920419454574585
Validation loss: 2.170430431763331

Epoch: 5| Step: 3
Training loss: 1.8127943277359009
Validation loss: 2.1555874397357306

Epoch: 5| Step: 4
Training loss: 1.2806798219680786
Validation loss: 2.159598837296168

Epoch: 5| Step: 5
Training loss: 1.5915374755859375
Validation loss: 2.1690664688746133

Epoch: 5| Step: 6
Training loss: 1.1060577630996704
Validation loss: 2.1636469016472497

Epoch: 5| Step: 7
Training loss: 1.629664659500122
Validation loss: 2.1594283878803253

Epoch: 5| Step: 8
Training loss: 1.4622060060501099
Validation loss: 2.1593950241804123

Epoch: 5| Step: 9
Training loss: 2.264873504638672
Validation loss: 2.1693394978841147

Epoch: 5| Step: 10
Training loss: 1.846408486366272
Validation loss: 2.174679840604464

Epoch: 5| Step: 11
Training loss: 1.1058013439178467
Validation loss: 2.1790764331817627

Epoch: 271| Step: 0
Training loss: 1.235635757446289
Validation loss: 2.1604493111371994

Epoch: 5| Step: 1
Training loss: 1.5658854246139526
Validation loss: 2.1092587262392044

Epoch: 5| Step: 2
Training loss: 1.274431586265564
Validation loss: 2.132015938560168

Epoch: 5| Step: 3
Training loss: 1.7365442514419556
Validation loss: 2.1242156624794006

Epoch: 5| Step: 4
Training loss: 1.2968721389770508
Validation loss: 2.128221482038498

Epoch: 5| Step: 5
Training loss: 1.7487818002700806
Validation loss: 2.126642500360807

Epoch: 5| Step: 6
Training loss: 2.341080904006958
Validation loss: 2.172205924987793

Epoch: 5| Step: 7
Training loss: 2.0640931129455566
Validation loss: 2.160754149158796

Epoch: 5| Step: 8
Training loss: 1.525962471961975
Validation loss: 2.235649993022283

Epoch: 5| Step: 9
Training loss: 1.5337297916412354
Validation loss: 2.226208950082461

Epoch: 5| Step: 10
Training loss: 2.0790584087371826
Validation loss: 2.237994114557902

Epoch: 5| Step: 11
Training loss: 1.4753154516220093
Validation loss: 2.229338695605596

Epoch: 272| Step: 0
Training loss: 1.5295383930206299
Validation loss: 2.2298637380202613

Epoch: 5| Step: 1
Training loss: 1.5430865287780762
Validation loss: 2.2111916889746985

Epoch: 5| Step: 2
Training loss: 1.6319129467010498
Validation loss: 2.1706889122724533

Epoch: 5| Step: 3
Training loss: 1.3025617599487305
Validation loss: 2.1735496620337167

Epoch: 5| Step: 4
Training loss: 2.0283660888671875
Validation loss: 2.1567546675602594

Epoch: 5| Step: 5
Training loss: 1.8745145797729492
Validation loss: 2.1727292289336524

Epoch: 5| Step: 6
Training loss: 1.2319406270980835
Validation loss: 2.16499599814415

Epoch: 5| Step: 7
Training loss: 2.062920331954956
Validation loss: 2.1489776571591697

Epoch: 5| Step: 8
Training loss: 1.192046880722046
Validation loss: 2.1446130524079003

Epoch: 5| Step: 9
Training loss: 1.8134170770645142
Validation loss: 2.131013880173365

Epoch: 5| Step: 10
Training loss: 1.9700376987457275
Validation loss: 2.1775287042061486

Epoch: 5| Step: 11
Training loss: 1.1439772844314575
Validation loss: 2.1715979079405465

Epoch: 273| Step: 0
Training loss: 1.634962797164917
Validation loss: 2.1960269014040628

Epoch: 5| Step: 1
Training loss: 1.789453148841858
Validation loss: 2.154245456059774

Epoch: 5| Step: 2
Training loss: 2.188319683074951
Validation loss: 2.1731034020582833

Epoch: 5| Step: 3
Training loss: 1.3676732778549194
Validation loss: 2.155683388312658

Epoch: 5| Step: 4
Training loss: 1.3013513088226318
Validation loss: 2.168223316470782

Epoch: 5| Step: 5
Training loss: 1.796229600906372
Validation loss: 2.139045317967733

Epoch: 5| Step: 6
Training loss: 1.5891143083572388
Validation loss: 2.1542598754167557

Epoch: 5| Step: 7
Training loss: 1.6556155681610107
Validation loss: 2.110317960381508

Epoch: 5| Step: 8
Training loss: 1.5827052593231201
Validation loss: 2.1343651910622916

Epoch: 5| Step: 9
Training loss: 1.443220853805542
Validation loss: 2.141708865761757

Epoch: 5| Step: 10
Training loss: 1.9537522792816162
Validation loss: 2.1601346333821616

Epoch: 5| Step: 11
Training loss: 1.5072813034057617
Validation loss: 2.161548003554344

Epoch: 274| Step: 0
Training loss: 1.5317236185073853
Validation loss: 2.172831585009893

Epoch: 5| Step: 1
Training loss: 1.3790156841278076
Validation loss: 2.1822526901960373

Epoch: 5| Step: 2
Training loss: 1.209795594215393
Validation loss: 2.191596766312917

Epoch: 5| Step: 3
Training loss: 1.9900890588760376
Validation loss: 2.186599756280581

Epoch: 5| Step: 4
Training loss: 2.3380331993103027
Validation loss: 2.1619378129641214

Epoch: 5| Step: 5
Training loss: 1.6099382638931274
Validation loss: 2.139928494890531

Epoch: 5| Step: 6
Training loss: 1.94387686252594
Validation loss: 2.126119941473007

Epoch: 5| Step: 7
Training loss: 1.4742976427078247
Validation loss: 2.1243469466765723

Epoch: 5| Step: 8
Training loss: 1.3377630710601807
Validation loss: 2.1214046825965247

Epoch: 5| Step: 9
Training loss: 1.3680320978164673
Validation loss: 2.140349119901657

Epoch: 5| Step: 10
Training loss: 1.7150609493255615
Validation loss: 2.1122036973635354

Epoch: 5| Step: 11
Training loss: 2.6044235229492188
Validation loss: 2.130624160170555

Epoch: 275| Step: 0
Training loss: 1.5213639736175537
Validation loss: 2.1015005807081857

Epoch: 5| Step: 1
Training loss: 1.7034858465194702
Validation loss: 2.1164824068546295

Epoch: 5| Step: 2
Training loss: 1.3093202114105225
Validation loss: 2.157667269309362

Epoch: 5| Step: 3
Training loss: 1.5517141819000244
Validation loss: 2.1661481658617654

Epoch: 5| Step: 4
Training loss: 1.7420814037322998
Validation loss: 2.1855716158946357

Epoch: 5| Step: 5
Training loss: 1.988153100013733
Validation loss: 2.1713389108578363

Epoch: 5| Step: 6
Training loss: 1.8539167642593384
Validation loss: 2.181941976149877

Epoch: 5| Step: 7
Training loss: 1.794832468032837
Validation loss: 2.177572250366211

Epoch: 5| Step: 8
Training loss: 1.5438346862792969
Validation loss: 2.1599176625410714

Epoch: 5| Step: 9
Training loss: 1.194601058959961
Validation loss: 2.160963088274002

Epoch: 5| Step: 10
Training loss: 2.1082262992858887
Validation loss: 2.154737412929535

Epoch: 5| Step: 11
Training loss: 1.2725939750671387
Validation loss: 2.140132258335749

Epoch: 276| Step: 0
Training loss: 1.1502763032913208
Validation loss: 2.1595468521118164

Epoch: 5| Step: 1
Training loss: 1.203900933265686
Validation loss: 2.1359758327404657

Epoch: 5| Step: 2
Training loss: 1.9960691928863525
Validation loss: 2.168386692802111

Epoch: 5| Step: 3
Training loss: 1.5705077648162842
Validation loss: 2.1896980106830597

Epoch: 5| Step: 4
Training loss: 1.8613994121551514
Validation loss: 2.173964406053225

Epoch: 5| Step: 5
Training loss: 1.9377174377441406
Validation loss: 2.1836106181144714

Epoch: 5| Step: 6
Training loss: 1.6589090824127197
Validation loss: 2.191359822948774

Epoch: 5| Step: 7
Training loss: 1.7832307815551758
Validation loss: 2.2106430679559708

Epoch: 5| Step: 8
Training loss: 1.8134078979492188
Validation loss: 2.2078098952770233

Epoch: 5| Step: 9
Training loss: 1.5921509265899658
Validation loss: 2.2361397395531335

Epoch: 5| Step: 10
Training loss: 1.3443950414657593
Validation loss: 2.222291866938273

Epoch: 5| Step: 11
Training loss: 1.6333078145980835
Validation loss: 2.2566887935002646

Epoch: 277| Step: 0
Training loss: 1.7841179370880127
Validation loss: 2.2152114460865655

Epoch: 5| Step: 1
Training loss: 1.743414282798767
Validation loss: 2.2174779971440635

Epoch: 5| Step: 2
Training loss: 1.6453593969345093
Validation loss: 2.193304648001989

Epoch: 5| Step: 3
Training loss: 1.4163644313812256
Validation loss: 2.232102702061335

Epoch: 5| Step: 4
Training loss: 1.8529456853866577
Validation loss: 2.236360788345337

Epoch: 5| Step: 5
Training loss: 1.9732662439346313
Validation loss: 2.2132261296113334

Epoch: 5| Step: 6
Training loss: 1.2403545379638672
Validation loss: 2.233750889698664

Epoch: 5| Step: 7
Training loss: 1.5369690656661987
Validation loss: 2.2238752196232476

Epoch: 5| Step: 8
Training loss: 1.6232601404190063
Validation loss: 2.234960829218229

Epoch: 5| Step: 9
Training loss: 1.6849663257598877
Validation loss: 2.209413250287374

Epoch: 5| Step: 10
Training loss: 1.61728036403656
Validation loss: 2.2168137530485788

Epoch: 5| Step: 11
Training loss: 1.0461479425430298
Validation loss: 2.2033722599347434

Epoch: 278| Step: 0
Training loss: 1.5746181011199951
Validation loss: 2.165062482158343

Epoch: 5| Step: 1
Training loss: 1.917093276977539
Validation loss: 2.1754679630200067

Epoch: 5| Step: 2
Training loss: 1.3166053295135498
Validation loss: 2.153105840086937

Epoch: 5| Step: 3
Training loss: 1.2303651571273804
Validation loss: 2.1499963154395423

Epoch: 5| Step: 4
Training loss: 1.1838432550430298
Validation loss: 2.1050491531689963

Epoch: 5| Step: 5
Training loss: 1.910883903503418
Validation loss: 2.1380553990602493

Epoch: 5| Step: 6
Training loss: 1.7469799518585205
Validation loss: 2.125556394457817

Epoch: 5| Step: 7
Training loss: 2.1862406730651855
Validation loss: 2.1347794234752655

Epoch: 5| Step: 8
Training loss: 1.5787264108657837
Validation loss: 2.1353635291258493

Epoch: 5| Step: 9
Training loss: 1.5357778072357178
Validation loss: 2.134650468826294

Epoch: 5| Step: 10
Training loss: 1.7660795450210571
Validation loss: 2.145581459005674

Epoch: 5| Step: 11
Training loss: 1.7695854902267456
Validation loss: 2.1750333507855735

Epoch: 279| Step: 0
Training loss: 1.631028413772583
Validation loss: 2.1680597166220346

Epoch: 5| Step: 1
Training loss: 1.5746917724609375
Validation loss: 2.185906077424685

Epoch: 5| Step: 2
Training loss: 1.5847413539886475
Validation loss: 2.1739812741676965

Epoch: 5| Step: 3
Training loss: 1.5681650638580322
Validation loss: 2.1714086135228476

Epoch: 5| Step: 4
Training loss: 1.6957086324691772
Validation loss: 2.17275108397007

Epoch: 5| Step: 5
Training loss: 1.5593104362487793
Validation loss: 2.2182223051786423

Epoch: 5| Step: 6
Training loss: 1.4487788677215576
Validation loss: 2.187761882940928

Epoch: 5| Step: 7
Training loss: 2.116565465927124
Validation loss: 2.197619358698527

Epoch: 5| Step: 8
Training loss: 1.8528544902801514
Validation loss: 2.217248558998108

Epoch: 5| Step: 9
Training loss: 1.5782955884933472
Validation loss: 2.2088619669278464

Epoch: 5| Step: 10
Training loss: 1.454575538635254
Validation loss: 2.238266517718633

Epoch: 5| Step: 11
Training loss: 1.874656319618225
Validation loss: 2.2275130649407706

Epoch: 280| Step: 0
Training loss: 2.1599886417388916
Validation loss: 2.192959909637769

Epoch: 5| Step: 1
Training loss: 1.7474193572998047
Validation loss: 2.1811403085788093

Epoch: 5| Step: 2
Training loss: 1.6400012969970703
Validation loss: 2.1486055850982666

Epoch: 5| Step: 3
Training loss: 1.474220633506775
Validation loss: 2.1634522577126822

Epoch: 5| Step: 4
Training loss: 1.6807997226715088
Validation loss: 2.1606909732023873

Epoch: 5| Step: 5
Training loss: 1.2520411014556885
Validation loss: 2.1371414363384247

Epoch: 5| Step: 6
Training loss: 1.4876956939697266
Validation loss: 2.1730517745018005

Epoch: 5| Step: 7
Training loss: 1.731223702430725
Validation loss: 2.1860894759496055

Epoch: 5| Step: 8
Training loss: 1.8106352090835571
Validation loss: 2.2072103967269263

Epoch: 5| Step: 9
Training loss: 1.433823823928833
Validation loss: 2.1961283832788467

Epoch: 5| Step: 10
Training loss: 1.5445196628570557
Validation loss: 2.227104971806208

Epoch: 5| Step: 11
Training loss: 1.1063590049743652
Validation loss: 2.2067559560139975

Epoch: 281| Step: 0
Training loss: 1.0639488697052002
Validation loss: 2.217104345560074

Epoch: 5| Step: 1
Training loss: 1.7914535999298096
Validation loss: 2.2248445252577462

Epoch: 5| Step: 2
Training loss: 1.4772931337356567
Validation loss: 2.2138243913650513

Epoch: 5| Step: 3
Training loss: 1.900363564491272
Validation loss: 2.188734749952952

Epoch: 5| Step: 4
Training loss: 1.427544355392456
Validation loss: 2.2135594685872397

Epoch: 5| Step: 5
Training loss: 1.821750283241272
Validation loss: 2.205757583181063

Epoch: 5| Step: 6
Training loss: 1.7277158498764038
Validation loss: 2.2132813384135566

Epoch: 5| Step: 7
Training loss: 1.4742035865783691
Validation loss: 2.1759599099556604

Epoch: 5| Step: 8
Training loss: 1.5607831478118896
Validation loss: 2.2003052085638046

Epoch: 5| Step: 9
Training loss: 1.8751323223114014
Validation loss: 2.187352334459623

Epoch: 5| Step: 10
Training loss: 1.5161155462265015
Validation loss: 2.1499648094177246

Epoch: 5| Step: 11
Training loss: 1.0938297510147095
Validation loss: 2.1617875397205353

Epoch: 282| Step: 0
Training loss: 1.4478919506072998
Validation loss: 2.1561595499515533

Epoch: 5| Step: 1
Training loss: 1.372623085975647
Validation loss: 2.16103429098924

Epoch: 5| Step: 2
Training loss: 1.3360438346862793
Validation loss: 2.158176600933075

Epoch: 5| Step: 3
Training loss: 1.1795084476470947
Validation loss: 2.142518957455953

Epoch: 5| Step: 4
Training loss: 1.6235551834106445
Validation loss: 2.144901692867279

Epoch: 5| Step: 5
Training loss: 2.295733690261841
Validation loss: 2.1472376783688865

Epoch: 5| Step: 6
Training loss: 1.084430456161499
Validation loss: 2.1711057871580124

Epoch: 5| Step: 7
Training loss: 1.997275710105896
Validation loss: 2.1772717585166297

Epoch: 5| Step: 8
Training loss: 1.9767783880233765
Validation loss: 2.180596391359965

Epoch: 5| Step: 9
Training loss: 2.2956364154815674
Validation loss: 2.217158774534861

Epoch: 5| Step: 10
Training loss: 1.468408465385437
Validation loss: 2.2111104925473533

Epoch: 5| Step: 11
Training loss: 0.7664729356765747
Validation loss: 2.215557942787806

Epoch: 283| Step: 0
Training loss: 1.5333583354949951
Validation loss: 2.2161379059155784

Epoch: 5| Step: 1
Training loss: 2.016653299331665
Validation loss: 2.2137351483106613

Epoch: 5| Step: 2
Training loss: 1.5182955265045166
Validation loss: 2.2345460951328278

Epoch: 5| Step: 3
Training loss: 1.9328514337539673
Validation loss: 2.2209721753994622

Epoch: 5| Step: 4
Training loss: 1.2507233619689941
Validation loss: 2.228735019763311

Epoch: 5| Step: 5
Training loss: 1.6623647212982178
Validation loss: 2.229201133052508

Epoch: 5| Step: 6
Training loss: 1.5981378555297852
Validation loss: 2.2520076980193457

Epoch: 5| Step: 7
Training loss: 1.9035027027130127
Validation loss: 2.2178405622641244

Epoch: 5| Step: 8
Training loss: 1.6103187799453735
Validation loss: 2.178620914618174

Epoch: 5| Step: 9
Training loss: 2.0831332206726074
Validation loss: 2.141838406523069

Epoch: 5| Step: 10
Training loss: 1.5942432880401611
Validation loss: 2.1331365456183753

Epoch: 5| Step: 11
Training loss: 1.4558547735214233
Validation loss: 2.137033005555471

Epoch: 284| Step: 0
Training loss: 1.305714726448059
Validation loss: 2.133694291114807

Epoch: 5| Step: 1
Training loss: 1.6388829946517944
Validation loss: 2.139355187614759

Epoch: 5| Step: 2
Training loss: 2.144818067550659
Validation loss: 2.134131287535032

Epoch: 5| Step: 3
Training loss: 1.4433350563049316
Validation loss: 2.153839553395907

Epoch: 5| Step: 4
Training loss: 1.8920364379882812
Validation loss: 2.143759702642759

Epoch: 5| Step: 5
Training loss: 2.1229665279388428
Validation loss: 2.153153032064438

Epoch: 5| Step: 6
Training loss: 1.2688062191009521
Validation loss: 2.1521385411421456

Epoch: 5| Step: 7
Training loss: 2.7197463512420654
Validation loss: 2.1507543325424194

Epoch: 5| Step: 8
Training loss: 1.2860331535339355
Validation loss: 2.1794987618923187

Epoch: 5| Step: 9
Training loss: 1.4214460849761963
Validation loss: 2.1574123253424964

Epoch: 5| Step: 10
Training loss: 1.6014206409454346
Validation loss: 2.1712312400341034

Epoch: 5| Step: 11
Training loss: 0.7805081009864807
Validation loss: 2.1590195695559182

Epoch: 285| Step: 0
Training loss: 1.6484034061431885
Validation loss: 2.1558074057102203

Epoch: 5| Step: 1
Training loss: 1.568651556968689
Validation loss: 2.1368450423081717

Epoch: 5| Step: 2
Training loss: 1.171155333518982
Validation loss: 2.1396812001864114

Epoch: 5| Step: 3
Training loss: 2.1953177452087402
Validation loss: 2.1499628176291785

Epoch: 5| Step: 4
Training loss: 1.6788021326065063
Validation loss: 2.1494589497645697

Epoch: 5| Step: 5
Training loss: 1.659181833267212
Validation loss: 2.1564412166674933

Epoch: 5| Step: 6
Training loss: 1.6014238595962524
Validation loss: 2.1750887632369995

Epoch: 5| Step: 7
Training loss: 1.22439444065094
Validation loss: 2.1808239420255027

Epoch: 5| Step: 8
Training loss: 1.8100097179412842
Validation loss: 2.2238300442695618

Epoch: 5| Step: 9
Training loss: 1.2203457355499268
Validation loss: 2.1990197549263635

Epoch: 5| Step: 10
Training loss: 1.685808777809143
Validation loss: 2.2113487124443054

Epoch: 5| Step: 11
Training loss: 3.2942628860473633
Validation loss: 2.22017177939415

Epoch: 286| Step: 0
Training loss: 1.5903377532958984
Validation loss: 2.1923251201709113

Epoch: 5| Step: 1
Training loss: 1.5422511100769043
Validation loss: 2.23408605158329

Epoch: 5| Step: 2
Training loss: 1.863613486289978
Validation loss: 2.21477210521698

Epoch: 5| Step: 3
Training loss: 2.0072054862976074
Validation loss: 2.2247349371512732

Epoch: 5| Step: 4
Training loss: 1.308032751083374
Validation loss: 2.178199827671051

Epoch: 5| Step: 5
Training loss: 1.026241660118103
Validation loss: 2.1843138188123703

Epoch: 5| Step: 6
Training loss: 1.5061578750610352
Validation loss: 2.1875162372986474

Epoch: 5| Step: 7
Training loss: 2.1467483043670654
Validation loss: 2.1511291166146598

Epoch: 5| Step: 8
Training loss: 1.272426962852478
Validation loss: 2.1404085556666055

Epoch: 5| Step: 9
Training loss: 1.5122088193893433
Validation loss: 2.1467290073633194

Epoch: 5| Step: 10
Training loss: 1.286287784576416
Validation loss: 2.1303406010071435

Epoch: 5| Step: 11
Training loss: 2.4989352226257324
Validation loss: 2.1020151674747467

Epoch: 287| Step: 0
Training loss: 1.1458579301834106
Validation loss: 2.0983581840991974

Epoch: 5| Step: 1
Training loss: 1.3319733142852783
Validation loss: 2.106412207086881

Epoch: 5| Step: 2
Training loss: 2.301788330078125
Validation loss: 2.12503744661808

Epoch: 5| Step: 3
Training loss: 1.4491283893585205
Validation loss: 2.1323107232650123

Epoch: 5| Step: 4
Training loss: 1.0989513397216797
Validation loss: 2.163243224223455

Epoch: 5| Step: 5
Training loss: 2.476318359375
Validation loss: 2.1912872741619744

Epoch: 5| Step: 6
Training loss: 1.4876807928085327
Validation loss: 2.2207492043574653

Epoch: 5| Step: 7
Training loss: 1.7751102447509766
Validation loss: 2.1644263366858163

Epoch: 5| Step: 8
Training loss: 1.7902730703353882
Validation loss: 2.1731012711922326

Epoch: 5| Step: 9
Training loss: 1.752537488937378
Validation loss: 2.1520871420701346

Epoch: 5| Step: 10
Training loss: 1.7834192514419556
Validation loss: 2.1703363408644996

Epoch: 5| Step: 11
Training loss: 0.6768772006034851
Validation loss: 2.162113070487976

Epoch: 288| Step: 0
Training loss: 1.4213205575942993
Validation loss: 2.1787603994210563

Epoch: 5| Step: 1
Training loss: 1.4833457469940186
Validation loss: 2.1575581630071006

Epoch: 5| Step: 2
Training loss: 1.9860379695892334
Validation loss: 2.142317603031794

Epoch: 5| Step: 3
Training loss: 1.5347181558609009
Validation loss: 2.112434168656667

Epoch: 5| Step: 4
Training loss: 1.4482746124267578
Validation loss: 2.10110833744208

Epoch: 5| Step: 5
Training loss: 1.7224260568618774
Validation loss: 2.0975266844034195

Epoch: 5| Step: 6
Training loss: 1.2952454090118408
Validation loss: 2.115876962741216

Epoch: 5| Step: 7
Training loss: 1.9264624118804932
Validation loss: 2.115538865327835

Epoch: 5| Step: 8
Training loss: 1.4968684911727905
Validation loss: 2.139961764216423

Epoch: 5| Step: 9
Training loss: 1.7398265600204468
Validation loss: 2.1279674569765725

Epoch: 5| Step: 10
Training loss: 1.6045198440551758
Validation loss: 2.1549570163091025

Epoch: 5| Step: 11
Training loss: 0.8113201260566711
Validation loss: 2.1864522099494934

Epoch: 289| Step: 0
Training loss: 1.245968222618103
Validation loss: 2.192496965328852

Epoch: 5| Step: 1
Training loss: 1.4882841110229492
Validation loss: 2.188769598801931

Epoch: 5| Step: 2
Training loss: 1.7609138488769531
Validation loss: 2.220047414302826

Epoch: 5| Step: 3
Training loss: 1.2001492977142334
Validation loss: 2.194146235783895

Epoch: 5| Step: 4
Training loss: 1.268301248550415
Validation loss: 2.2007954319318137

Epoch: 5| Step: 5
Training loss: 1.0729349851608276
Validation loss: 2.2402124255895615

Epoch: 5| Step: 6
Training loss: 2.0858826637268066
Validation loss: 2.212918668985367

Epoch: 5| Step: 7
Training loss: 2.812225341796875
Validation loss: 2.180696422855059

Epoch: 5| Step: 8
Training loss: 1.4614408016204834
Validation loss: 2.168675889571508

Epoch: 5| Step: 9
Training loss: 1.797991156578064
Validation loss: 2.1975818077723184

Epoch: 5| Step: 10
Training loss: 1.0388967990875244
Validation loss: 2.190178781747818

Epoch: 5| Step: 11
Training loss: 1.8126212358474731
Validation loss: 2.2145140965779624

Epoch: 290| Step: 0
Training loss: 1.3737653493881226
Validation loss: 2.2171459794044495

Epoch: 5| Step: 1
Training loss: 1.716609001159668
Validation loss: 2.2301433185736337

Epoch: 5| Step: 2
Training loss: 2.0565805435180664
Validation loss: 2.204570879538854

Epoch: 5| Step: 3
Training loss: 1.2906166315078735
Validation loss: 2.2032488783200583

Epoch: 5| Step: 4
Training loss: 1.4947869777679443
Validation loss: 2.247003654638926

Epoch: 5| Step: 5
Training loss: 1.8245960474014282
Validation loss: 2.241808593273163

Epoch: 5| Step: 6
Training loss: 1.5434327125549316
Validation loss: 2.2345744172732034

Epoch: 5| Step: 7
Training loss: 1.6214797496795654
Validation loss: 2.2012499471505484

Epoch: 5| Step: 8
Training loss: 1.3300193548202515
Validation loss: 2.1802532374858856

Epoch: 5| Step: 9
Training loss: 1.6246753931045532
Validation loss: 2.1567115982373557

Epoch: 5| Step: 10
Training loss: 1.6931993961334229
Validation loss: 2.135792131225268

Epoch: 5| Step: 11
Training loss: 0.8177971839904785
Validation loss: 2.1294082353512445

Epoch: 291| Step: 0
Training loss: 1.9651178121566772
Validation loss: 2.1431594093640647

Epoch: 5| Step: 1
Training loss: 1.7642148733139038
Validation loss: 2.168719381093979

Epoch: 5| Step: 2
Training loss: 1.4721214771270752
Validation loss: 2.1702265441417694

Epoch: 5| Step: 3
Training loss: 2.034541368484497
Validation loss: 2.18182535469532

Epoch: 5| Step: 4
Training loss: 1.4568005800247192
Validation loss: 2.2112466245889664

Epoch: 5| Step: 5
Training loss: 1.3301384449005127
Validation loss: 2.237260565161705

Epoch: 5| Step: 6
Training loss: 1.6052745580673218
Validation loss: 2.2366610566775003

Epoch: 5| Step: 7
Training loss: 1.597067952156067
Validation loss: 2.200665886203448

Epoch: 5| Step: 8
Training loss: 1.8413528203964233
Validation loss: 2.1938809702793756

Epoch: 5| Step: 9
Training loss: 1.5069382190704346
Validation loss: 2.226364885767301

Epoch: 5| Step: 10
Training loss: 1.1366305351257324
Validation loss: 2.198704555630684

Epoch: 5| Step: 11
Training loss: 2.408677577972412
Validation loss: 2.163102095325788

Epoch: 292| Step: 0
Training loss: 1.4630653858184814
Validation loss: 2.1180286606152854

Epoch: 5| Step: 1
Training loss: 1.717384934425354
Validation loss: 2.1370304425557456

Epoch: 5| Step: 2
Training loss: 2.316525459289551
Validation loss: 2.1589895536502204

Epoch: 5| Step: 3
Training loss: 1.5427297353744507
Validation loss: 2.14444171388944

Epoch: 5| Step: 4
Training loss: 1.5560274124145508
Validation loss: 2.191501498222351

Epoch: 5| Step: 5
Training loss: 0.9137922525405884
Validation loss: 2.2049246629079184

Epoch: 5| Step: 6
Training loss: 1.1808319091796875
Validation loss: 2.207702100276947

Epoch: 5| Step: 7
Training loss: 1.4374516010284424
Validation loss: 2.1997711658477783

Epoch: 5| Step: 8
Training loss: 1.1358894109725952
Validation loss: 2.186852922042211

Epoch: 5| Step: 9
Training loss: 1.9668619632720947
Validation loss: 2.2140779892603555

Epoch: 5| Step: 10
Training loss: 1.4093209505081177
Validation loss: 2.198871503273646

Epoch: 5| Step: 11
Training loss: 2.978393077850342
Validation loss: 2.206582764784495

Epoch: 293| Step: 0
Training loss: 1.6515648365020752
Validation loss: 2.1913283268610635

Epoch: 5| Step: 1
Training loss: 1.7014347314834595
Validation loss: 2.17102358241876

Epoch: 5| Step: 2
Training loss: 1.6220794916152954
Validation loss: 2.1518157770236335

Epoch: 5| Step: 3
Training loss: 1.4103050231933594
Validation loss: 2.1709502091010413

Epoch: 5| Step: 4
Training loss: 0.9709566235542297
Validation loss: 2.163705130418142

Epoch: 5| Step: 5
Training loss: 1.5291812419891357
Validation loss: 2.1483948876460395

Epoch: 5| Step: 6
Training loss: 1.5337008237838745
Validation loss: 2.1639319211244583

Epoch: 5| Step: 7
Training loss: 1.6540639400482178
Validation loss: 2.17145366470019

Epoch: 5| Step: 8
Training loss: 1.7461795806884766
Validation loss: 2.159670059879621

Epoch: 5| Step: 9
Training loss: 1.7862861156463623
Validation loss: 2.1668330232302346

Epoch: 5| Step: 10
Training loss: 1.9775466918945312
Validation loss: 2.1872671991586685

Epoch: 5| Step: 11
Training loss: 0.7267447710037231
Validation loss: 2.190995732943217

Epoch: 294| Step: 0
Training loss: 1.2088478803634644
Validation loss: 2.1811250845591226

Epoch: 5| Step: 1
Training loss: 1.467902421951294
Validation loss: 2.2032973965009055

Epoch: 5| Step: 2
Training loss: 1.7986253499984741
Validation loss: 2.215131769577662

Epoch: 5| Step: 3
Training loss: 1.4990242719650269
Validation loss: 2.2186244825522103

Epoch: 5| Step: 4
Training loss: 0.7593775391578674
Validation loss: 2.200840334097544

Epoch: 5| Step: 5
Training loss: 1.5562175512313843
Validation loss: 2.2161549429098764

Epoch: 5| Step: 6
Training loss: 1.7594980001449585
Validation loss: 2.2038653741280236

Epoch: 5| Step: 7
Training loss: 1.9569644927978516
Validation loss: 2.2368874152501426

Epoch: 5| Step: 8
Training loss: 1.0963852405548096
Validation loss: 2.205105130871137

Epoch: 5| Step: 9
Training loss: 1.6634509563446045
Validation loss: 2.1967848539352417

Epoch: 5| Step: 10
Training loss: 1.595971703529358
Validation loss: 2.172114203373591

Epoch: 5| Step: 11
Training loss: 3.2501420974731445
Validation loss: 2.1631403813759484

Epoch: 295| Step: 0
Training loss: 1.7254406213760376
Validation loss: 2.1757176319758096

Epoch: 5| Step: 1
Training loss: 1.4840514659881592
Validation loss: 2.2149793008963266

Epoch: 5| Step: 2
Training loss: 1.1100022792816162
Validation loss: 2.190208743015925

Epoch: 5| Step: 3
Training loss: 1.6207454204559326
Validation loss: 2.189345141251882

Epoch: 5| Step: 4
Training loss: 1.0938899517059326
Validation loss: 2.181940510869026

Epoch: 5| Step: 5
Training loss: 1.8776328563690186
Validation loss: 2.206291009982427

Epoch: 5| Step: 6
Training loss: 1.316980242729187
Validation loss: 2.2184584935506186

Epoch: 5| Step: 7
Training loss: 1.8760879039764404
Validation loss: 2.2244689762592316

Epoch: 5| Step: 8
Training loss: 1.8088867664337158
Validation loss: 2.20761006573836

Epoch: 5| Step: 9
Training loss: 1.7833646535873413
Validation loss: 2.197366272409757

Epoch: 5| Step: 10
Training loss: 1.4552370309829712
Validation loss: 2.1556973656018577

Epoch: 5| Step: 11
Training loss: 1.080981731414795
Validation loss: 2.147915760676066

Epoch: 296| Step: 0
Training loss: 1.4516925811767578
Validation loss: 2.20152518649896

Epoch: 5| Step: 1
Training loss: 1.6933543682098389
Validation loss: 2.200752134124438

Epoch: 5| Step: 2
Training loss: 1.5082391500473022
Validation loss: 2.183478390177091

Epoch: 5| Step: 3
Training loss: 1.2822805643081665
Validation loss: 2.1704377283652625

Epoch: 5| Step: 4
Training loss: 1.6413847208023071
Validation loss: 2.188944846391678

Epoch: 5| Step: 5
Training loss: 1.7405776977539062
Validation loss: 2.1500242352485657

Epoch: 5| Step: 6
Training loss: 2.0947048664093018
Validation loss: 2.16844509045283

Epoch: 5| Step: 7
Training loss: 1.1912548542022705
Validation loss: 2.1852125028769174

Epoch: 5| Step: 8
Training loss: 1.1826385259628296
Validation loss: 2.173006216684977

Epoch: 5| Step: 9
Training loss: 1.4489343166351318
Validation loss: 2.1479747941096625

Epoch: 5| Step: 10
Training loss: 1.358442783355713
Validation loss: 2.126935655872027

Epoch: 5| Step: 11
Training loss: 2.0370922088623047
Validation loss: 2.1362655063470206

Epoch: 297| Step: 0
Training loss: 1.670762300491333
Validation loss: 2.1113138447205224

Epoch: 5| Step: 1
Training loss: 1.9355003833770752
Validation loss: 2.1061601837476096

Epoch: 5| Step: 2
Training loss: 1.2836334705352783
Validation loss: 2.1383206297953925

Epoch: 5| Step: 3
Training loss: 1.0684936046600342
Validation loss: 2.1491976281007132

Epoch: 5| Step: 4
Training loss: 1.7907556295394897
Validation loss: 2.179518794020017

Epoch: 5| Step: 5
Training loss: 1.5908892154693604
Validation loss: 2.168366630872091

Epoch: 5| Step: 6
Training loss: 1.4003660678863525
Validation loss: 2.1969471474488578

Epoch: 5| Step: 7
Training loss: 1.103578805923462
Validation loss: 2.1692371467749276

Epoch: 5| Step: 8
Training loss: 1.4077482223510742
Validation loss: 2.1780710915724435

Epoch: 5| Step: 9
Training loss: 1.8586578369140625
Validation loss: 2.1880719711383185

Epoch: 5| Step: 10
Training loss: 1.5893346071243286
Validation loss: 2.1736892064412436

Epoch: 5| Step: 11
Training loss: 2.994138479232788
Validation loss: 2.1399573336044946

Epoch: 298| Step: 0
Training loss: 1.8223285675048828
Validation loss: 2.155932754278183

Epoch: 5| Step: 1
Training loss: 1.3061883449554443
Validation loss: 2.132603868842125

Epoch: 5| Step: 2
Training loss: 1.873815894126892
Validation loss: 2.158440962433815

Epoch: 5| Step: 3
Training loss: 1.2480871677398682
Validation loss: 2.162520264585813

Epoch: 5| Step: 4
Training loss: 1.2831182479858398
Validation loss: 2.1984282036622367

Epoch: 5| Step: 5
Training loss: 1.467537522315979
Validation loss: 2.1889253358046212

Epoch: 5| Step: 6
Training loss: 1.8815056085586548
Validation loss: 2.1804800579945245

Epoch: 5| Step: 7
Training loss: 1.761716604232788
Validation loss: 2.1983097344636917

Epoch: 5| Step: 8
Training loss: 1.0723531246185303
Validation loss: 2.1629698673884072

Epoch: 5| Step: 9
Training loss: 2.15510892868042
Validation loss: 2.160501485069593

Epoch: 5| Step: 10
Training loss: 1.0729992389678955
Validation loss: 2.1731520146131516

Epoch: 5| Step: 11
Training loss: 1.7321118116378784
Validation loss: 2.1534871260325112

Epoch: 299| Step: 0
Training loss: 1.4530175924301147
Validation loss: 2.173653706908226

Epoch: 5| Step: 1
Training loss: 1.6609141826629639
Validation loss: 2.173266351222992

Epoch: 5| Step: 2
Training loss: 1.6408755779266357
Validation loss: 2.1623353362083435

Epoch: 5| Step: 3
Training loss: 1.4610214233398438
Validation loss: 2.1587892274061837

Epoch: 5| Step: 4
Training loss: 1.8678922653198242
Validation loss: 2.1538181702295938

Epoch: 5| Step: 5
Training loss: 1.5841610431671143
Validation loss: 2.167781323194504

Epoch: 5| Step: 6
Training loss: 1.0901987552642822
Validation loss: 2.160604556401571

Epoch: 5| Step: 7
Training loss: 1.3141615390777588
Validation loss: 2.1872950543959937

Epoch: 5| Step: 8
Training loss: 1.1473214626312256
Validation loss: 2.1846357583999634

Epoch: 5| Step: 9
Training loss: 1.8976383209228516
Validation loss: 2.2062021295229592

Epoch: 5| Step: 10
Training loss: 1.2497174739837646
Validation loss: 2.2105712592601776

Epoch: 5| Step: 11
Training loss: 3.344240665435791
Validation loss: 2.214679002761841

Epoch: 300| Step: 0
Training loss: 1.3509572744369507
Validation loss: 2.199250956376394

Epoch: 5| Step: 1
Training loss: 1.1092398166656494
Validation loss: 2.190424154202143

Epoch: 5| Step: 2
Training loss: 2.075833797454834
Validation loss: 2.1873559951782227

Epoch: 5| Step: 3
Training loss: 1.5609989166259766
Validation loss: 2.1920264065265656

Epoch: 5| Step: 4
Training loss: 1.8105640411376953
Validation loss: 2.1558368653059006

Epoch: 5| Step: 5
Training loss: 1.7010972499847412
Validation loss: 2.1422061075766883

Epoch: 5| Step: 6
Training loss: 1.8059765100479126
Validation loss: 2.1808935354153314

Epoch: 5| Step: 7
Training loss: 1.7178634405136108
Validation loss: 2.1763741026322045

Epoch: 5| Step: 8
Training loss: 1.628696084022522
Validation loss: 2.184057131409645

Epoch: 5| Step: 9
Training loss: 1.1187251806259155
Validation loss: 2.215620348850886

Epoch: 5| Step: 10
Training loss: 1.353316068649292
Validation loss: 2.1993054300546646

Epoch: 5| Step: 11
Training loss: 1.6115469932556152
Validation loss: 2.2234286616245904

Epoch: 301| Step: 0
Training loss: 1.3151122331619263
Validation loss: 2.207933485507965

Epoch: 5| Step: 1
Training loss: 1.6676232814788818
Validation loss: 2.2034796873728433

Epoch: 5| Step: 2
Training loss: 1.125624656677246
Validation loss: 2.196773479382197

Epoch: 5| Step: 3
Training loss: 1.613654375076294
Validation loss: 2.1899001747369766

Epoch: 5| Step: 4
Training loss: 1.9316120147705078
Validation loss: 2.2461383243401847

Epoch: 5| Step: 5
Training loss: 1.3278067111968994
Validation loss: 2.239180321494738

Epoch: 5| Step: 6
Training loss: 1.674200415611267
Validation loss: 2.2212943186362586

Epoch: 5| Step: 7
Training loss: 1.7543131113052368
Validation loss: 2.2080235481262207

Epoch: 5| Step: 8
Training loss: 1.5222007036209106
Validation loss: 2.229656567176183

Epoch: 5| Step: 9
Training loss: 1.4151413440704346
Validation loss: 2.249043971300125

Epoch: 5| Step: 10
Training loss: 1.3482015132904053
Validation loss: 2.2182620714108148

Epoch: 5| Step: 11
Training loss: 1.3661549091339111
Validation loss: 2.2142189343770347

Epoch: 302| Step: 0
Training loss: 1.2795989513397217
Validation loss: 2.2166491597890854

Epoch: 5| Step: 1
Training loss: 1.2973591089248657
Validation loss: 2.2009826749563217

Epoch: 5| Step: 2
Training loss: 1.7219760417938232
Validation loss: 2.2246062556902566

Epoch: 5| Step: 3
Training loss: 1.4474420547485352
Validation loss: 2.2416395048300424

Epoch: 5| Step: 4
Training loss: 1.201054334640503
Validation loss: 2.2462377548217773

Epoch: 5| Step: 5
Training loss: 1.125265121459961
Validation loss: 2.1983405898014703

Epoch: 5| Step: 6
Training loss: 1.6784403324127197
Validation loss: 2.19639091193676

Epoch: 5| Step: 7
Training loss: 1.9678131341934204
Validation loss: 2.2010809928178787

Epoch: 5| Step: 8
Training loss: 2.0794034004211426
Validation loss: 2.201278661688169

Epoch: 5| Step: 9
Training loss: 1.3723194599151611
Validation loss: 2.2359615365664163

Epoch: 5| Step: 10
Training loss: 0.8899124264717102
Validation loss: 2.218004326025645

Epoch: 5| Step: 11
Training loss: 3.179884910583496
Validation loss: 2.207428604364395

Epoch: 303| Step: 0
Training loss: 1.4945318698883057
Validation loss: 2.243728776772817

Epoch: 5| Step: 1
Training loss: 1.9190120697021484
Validation loss: 2.212841580311457

Epoch: 5| Step: 2
Training loss: 1.040498971939087
Validation loss: 2.186128815015157

Epoch: 5| Step: 3
Training loss: 1.4327738285064697
Validation loss: 2.1846856772899628

Epoch: 5| Step: 4
Training loss: 1.8509635925292969
Validation loss: 2.219249134262403

Epoch: 5| Step: 5
Training loss: 1.5796579122543335
Validation loss: 2.1874884168306985

Epoch: 5| Step: 6
Training loss: 1.355501413345337
Validation loss: 2.1951192915439606

Epoch: 5| Step: 7
Training loss: 1.24954092502594
Validation loss: 2.187481001019478

Epoch: 5| Step: 8
Training loss: 1.4869269132614136
Validation loss: 2.2042335172494254

Epoch: 5| Step: 9
Training loss: 1.5157185792922974
Validation loss: 2.20635620256265

Epoch: 5| Step: 10
Training loss: 1.686666488647461
Validation loss: 2.2001352111498513

Epoch: 5| Step: 11
Training loss: 1.9647544622421265
Validation loss: 2.2002081871032715

Epoch: 304| Step: 0
Training loss: 1.7083168029785156
Validation loss: 2.1648413638273873

Epoch: 5| Step: 1
Training loss: 1.8478739261627197
Validation loss: 2.140602638324102

Epoch: 5| Step: 2
Training loss: 1.760516881942749
Validation loss: 2.1464203596115112

Epoch: 5| Step: 3
Training loss: 1.3194061517715454
Validation loss: 2.159953544537226

Epoch: 5| Step: 4
Training loss: 2.032742500305176
Validation loss: 2.1602678696314492

Epoch: 5| Step: 5
Training loss: 1.2800936698913574
Validation loss: 2.151074985663096

Epoch: 5| Step: 6
Training loss: 1.20222806930542
Validation loss: 2.161364192763964

Epoch: 5| Step: 7
Training loss: 1.5156481266021729
Validation loss: 2.1651606957117715

Epoch: 5| Step: 8
Training loss: 1.1134569644927979
Validation loss: 2.185608377059301

Epoch: 5| Step: 9
Training loss: 1.2633721828460693
Validation loss: 2.1827731132507324

Epoch: 5| Step: 10
Training loss: 1.4282702207565308
Validation loss: 2.1758964459101358

Epoch: 5| Step: 11
Training loss: 1.1990528106689453
Validation loss: 2.194858809312185

Epoch: 305| Step: 0
Training loss: 1.0638744831085205
Validation loss: 2.185424412290255

Epoch: 5| Step: 1
Training loss: 1.15715491771698
Validation loss: 2.190550704797109

Epoch: 5| Step: 2
Training loss: 2.1050667762756348
Validation loss: 2.1691863536834717

Epoch: 5| Step: 3
Training loss: 1.6687543392181396
Validation loss: 2.1620195309321084

Epoch: 5| Step: 4
Training loss: 1.7859134674072266
Validation loss: 2.177606994907061

Epoch: 5| Step: 5
Training loss: 0.9880415797233582
Validation loss: 2.1503304541110992

Epoch: 5| Step: 6
Training loss: 1.0489904880523682
Validation loss: 2.176832581559817

Epoch: 5| Step: 7
Training loss: 1.3150911331176758
Validation loss: 2.1820021867752075

Epoch: 5| Step: 8
Training loss: 1.6432030200958252
Validation loss: 2.183676540851593

Epoch: 5| Step: 9
Training loss: 1.8149850368499756
Validation loss: 2.18629298110803

Epoch: 5| Step: 10
Training loss: 1.3995921611785889
Validation loss: 2.1590681076049805

Epoch: 5| Step: 11
Training loss: 1.9018926620483398
Validation loss: 2.2088971932729087

Epoch: 306| Step: 0
Training loss: 1.9020872116088867
Validation loss: 2.192143509785334

Epoch: 5| Step: 1
Training loss: 1.5222491025924683
Validation loss: 2.1743637174367905

Epoch: 5| Step: 2
Training loss: 1.2837730646133423
Validation loss: 2.2128762751817703

Epoch: 5| Step: 3
Training loss: 1.3145451545715332
Validation loss: 2.199610417087873

Epoch: 5| Step: 4
Training loss: 1.4440070390701294
Validation loss: 2.2290486792723336

Epoch: 5| Step: 5
Training loss: 1.1471902132034302
Validation loss: 2.2271327078342438

Epoch: 5| Step: 6
Training loss: 1.5375391244888306
Validation loss: 2.2094637900590897

Epoch: 5| Step: 7
Training loss: 2.48919939994812
Validation loss: 2.2316121459007263

Epoch: 5| Step: 8
Training loss: 1.2994625568389893
Validation loss: 2.2475812286138535

Epoch: 5| Step: 9
Training loss: 0.9150928258895874
Validation loss: 2.2055088877677917

Epoch: 5| Step: 10
Training loss: 1.581095814704895
Validation loss: 2.2109102259079614

Epoch: 5| Step: 11
Training loss: 1.3867402076721191
Validation loss: 2.1889865646759668

Epoch: 307| Step: 0
Training loss: 1.4329540729522705
Validation loss: 2.1668309768040976

Epoch: 5| Step: 1
Training loss: 1.3883401155471802
Validation loss: 2.163530091444651

Epoch: 5| Step: 2
Training loss: 1.2507574558258057
Validation loss: 2.1715195775032043

Epoch: 5| Step: 3
Training loss: 1.5094525814056396
Validation loss: 2.1615795642137527

Epoch: 5| Step: 4
Training loss: 1.697758674621582
Validation loss: 2.1620845248301825

Epoch: 5| Step: 5
Training loss: 1.6515146493911743
Validation loss: 2.1974316587050757

Epoch: 5| Step: 6
Training loss: 1.1423110961914062
Validation loss: 2.1633534928162894

Epoch: 5| Step: 7
Training loss: 2.2549896240234375
Validation loss: 2.156634936730067

Epoch: 5| Step: 8
Training loss: 1.4531300067901611
Validation loss: 2.2098305424054465

Epoch: 5| Step: 9
Training loss: 1.6568975448608398
Validation loss: 2.1964787244796753

Epoch: 5| Step: 10
Training loss: 1.2257674932479858
Validation loss: 2.18735142548879

Epoch: 5| Step: 11
Training loss: 0.9303051829338074
Validation loss: 2.1834490448236465

Epoch: 308| Step: 0
Training loss: 1.7516683340072632
Validation loss: 2.201151192188263

Epoch: 5| Step: 1
Training loss: 1.202248215675354
Validation loss: 2.157399207353592

Epoch: 5| Step: 2
Training loss: 1.2242494821548462
Validation loss: 2.1030055483182273

Epoch: 5| Step: 3
Training loss: 1.9950714111328125
Validation loss: 2.1191776345173516

Epoch: 5| Step: 4
Training loss: 1.0011903047561646
Validation loss: 2.1129409869511924

Epoch: 5| Step: 5
Training loss: 1.6147598028182983
Validation loss: 2.117394814888636

Epoch: 5| Step: 6
Training loss: 1.6177600622177124
Validation loss: 2.148408964276314

Epoch: 5| Step: 7
Training loss: 2.3368020057678223
Validation loss: 2.206928382317225

Epoch: 5| Step: 8
Training loss: 1.2273750305175781
Validation loss: 2.226715316375097

Epoch: 5| Step: 9
Training loss: 1.2458125352859497
Validation loss: 2.225475693742434

Epoch: 5| Step: 10
Training loss: 1.5130349397659302
Validation loss: 2.2271383802096048

Epoch: 5| Step: 11
Training loss: 1.6071667671203613
Validation loss: 2.238760749499003

Epoch: 309| Step: 0
Training loss: 1.4307324886322021
Validation loss: 2.2546616395314536

Epoch: 5| Step: 1
Training loss: 1.8590008020401
Validation loss: 2.2626708249251046

Epoch: 5| Step: 2
Training loss: 1.355804443359375
Validation loss: 2.2481869210799537

Epoch: 5| Step: 3
Training loss: 1.2892040014266968
Validation loss: 2.2355054517587027

Epoch: 5| Step: 4
Training loss: 1.2411632537841797
Validation loss: 2.154324561357498

Epoch: 5| Step: 5
Training loss: 1.4182106256484985
Validation loss: 2.1705279697974524

Epoch: 5| Step: 6
Training loss: 2.304194211959839
Validation loss: 2.15736585855484

Epoch: 5| Step: 7
Training loss: 1.1659245491027832
Validation loss: 2.1323326428731284

Epoch: 5| Step: 8
Training loss: 1.232286810874939
Validation loss: 2.1418389727671943

Epoch: 5| Step: 9
Training loss: 1.273791790008545
Validation loss: 2.1593656738599143

Epoch: 5| Step: 10
Training loss: 2.0545783042907715
Validation loss: 2.169234295686086

Epoch: 5| Step: 11
Training loss: 0.892124354839325
Validation loss: 2.1842071463664374

Epoch: 310| Step: 0
Training loss: 1.363847255706787
Validation loss: 2.203819861014684

Epoch: 5| Step: 1
Training loss: 1.535761833190918
Validation loss: 2.1461958388487496

Epoch: 5| Step: 2
Training loss: 1.5903351306915283
Validation loss: 2.15468563636144

Epoch: 5| Step: 3
Training loss: 1.5576531887054443
Validation loss: 2.1793958793083825

Epoch: 5| Step: 4
Training loss: 1.4835822582244873
Validation loss: 2.174092431863149

Epoch: 5| Step: 5
Training loss: 1.5272738933563232
Validation loss: 2.1867511024077735

Epoch: 5| Step: 6
Training loss: 1.8630950450897217
Validation loss: 2.196721057097117

Epoch: 5| Step: 7
Training loss: 1.053650140762329
Validation loss: 2.2182471404472985

Epoch: 5| Step: 8
Training loss: 1.8584874868392944
Validation loss: 2.215512201189995

Epoch: 5| Step: 9
Training loss: 1.393721342086792
Validation loss: 2.2274014949798584

Epoch: 5| Step: 10
Training loss: 1.2826341390609741
Validation loss: 2.207528422276179

Epoch: 5| Step: 11
Training loss: 1.5988328456878662
Validation loss: 2.2327081163724265

Epoch: 311| Step: 0
Training loss: 1.9704334735870361
Validation loss: 2.197529673576355

Epoch: 5| Step: 1
Training loss: 1.3329098224639893
Validation loss: 2.1846809536218643

Epoch: 5| Step: 2
Training loss: 1.9625011682510376
Validation loss: 2.1880284398794174

Epoch: 5| Step: 3
Training loss: 1.1663802862167358
Validation loss: 2.1951856712500253

Epoch: 5| Step: 4
Training loss: 0.9241687655448914
Validation loss: 2.198197051882744

Epoch: 5| Step: 5
Training loss: 0.8396711349487305
Validation loss: 2.2109667708476386

Epoch: 5| Step: 6
Training loss: 1.7106975317001343
Validation loss: 2.20920937259992

Epoch: 5| Step: 7
Training loss: 1.9042441844940186
Validation loss: 2.1801897982756295

Epoch: 5| Step: 8
Training loss: 1.3669805526733398
Validation loss: 2.213646133740743

Epoch: 5| Step: 9
Training loss: 1.5392115116119385
Validation loss: 2.211397791902224

Epoch: 5| Step: 10
Training loss: 1.1618355512619019
Validation loss: 2.2176437179247537

Epoch: 5| Step: 11
Training loss: 3.4861507415771484
Validation loss: 2.213850478331248

Epoch: 312| Step: 0
Training loss: 1.141829252243042
Validation loss: 2.177079826593399

Epoch: 5| Step: 1
Training loss: 1.31759774684906
Validation loss: 2.166613355278969

Epoch: 5| Step: 2
Training loss: 2.063950538635254
Validation loss: 2.2062160670757294

Epoch: 5| Step: 3
Training loss: 1.6228439807891846
Validation loss: 2.207172433535258

Epoch: 5| Step: 4
Training loss: 1.102068543434143
Validation loss: 2.176845928033193

Epoch: 5| Step: 5
Training loss: 1.8725694417953491
Validation loss: 2.1744724760452905

Epoch: 5| Step: 6
Training loss: 1.0565478801727295
Validation loss: 2.1732494632403054

Epoch: 5| Step: 7
Training loss: 2.3736557960510254
Validation loss: 2.179372822244962

Epoch: 5| Step: 8
Training loss: 1.2142565250396729
Validation loss: 2.188342089454333

Epoch: 5| Step: 9
Training loss: 1.068946123123169
Validation loss: 2.187576656540235

Epoch: 5| Step: 10
Training loss: 1.538918375968933
Validation loss: 2.181021213531494

Epoch: 5| Step: 11
Training loss: 1.938582181930542
Validation loss: 2.1639180183410645

Epoch: 313| Step: 0
Training loss: 1.1321766376495361
Validation loss: 2.1296731332937875

Epoch: 5| Step: 1
Training loss: 1.7662365436553955
Validation loss: 2.154440979162852

Epoch: 5| Step: 2
Training loss: 1.3662641048431396
Validation loss: 2.1305736104647317

Epoch: 5| Step: 3
Training loss: 1.0533205270767212
Validation loss: 2.1304490069548288

Epoch: 5| Step: 4
Training loss: 0.7942401170730591
Validation loss: 2.157069370150566

Epoch: 5| Step: 5
Training loss: 1.713051199913025
Validation loss: 2.150160198410352

Epoch: 5| Step: 6
Training loss: 1.329974889755249
Validation loss: 2.178242951631546

Epoch: 5| Step: 7
Training loss: 1.7146507501602173
Validation loss: 2.156650558114052

Epoch: 5| Step: 8
Training loss: 1.6177898645401
Validation loss: 2.2170963982741037

Epoch: 5| Step: 9
Training loss: 1.6585925817489624
Validation loss: 2.2497053841749826

Epoch: 5| Step: 10
Training loss: 1.5505539178848267
Validation loss: 2.2170234620571136

Epoch: 5| Step: 11
Training loss: 2.2355916500091553
Validation loss: 2.169002960125605

Epoch: 314| Step: 0
Training loss: 1.5139819383621216
Validation loss: 2.1962602933247886

Epoch: 5| Step: 1
Training loss: 1.3949635028839111
Validation loss: 2.1663266122341156

Epoch: 5| Step: 2
Training loss: 1.3744789361953735
Validation loss: 2.1643554667631784

Epoch: 5| Step: 3
Training loss: 0.9105195999145508
Validation loss: 2.171862781047821

Epoch: 5| Step: 4
Training loss: 0.8875282406806946
Validation loss: 2.183949535091718

Epoch: 5| Step: 5
Training loss: 1.5114415884017944
Validation loss: 2.1353577772776284

Epoch: 5| Step: 6
Training loss: 2.329462766647339
Validation loss: 2.1337634921073914

Epoch: 5| Step: 7
Training loss: 1.2978321313858032
Validation loss: 2.1557622849941254

Epoch: 5| Step: 8
Training loss: 1.5400428771972656
Validation loss: 2.154650410016378

Epoch: 5| Step: 9
Training loss: 1.9602457284927368
Validation loss: 2.185053383310636

Epoch: 5| Step: 10
Training loss: 1.563845157623291
Validation loss: 2.195827225844065

Epoch: 5| Step: 11
Training loss: 1.3824900388717651
Validation loss: 2.2353180746237435

Epoch: 315| Step: 0
Training loss: 1.2861073017120361
Validation loss: 2.219447652498881

Epoch: 5| Step: 1
Training loss: 1.2741817235946655
Validation loss: 2.219880903760592

Epoch: 5| Step: 2
Training loss: 1.5114504098892212
Validation loss: 2.2236154675483704

Epoch: 5| Step: 3
Training loss: 1.8836129903793335
Validation loss: 2.22793218990167

Epoch: 5| Step: 4
Training loss: 1.6520757675170898
Validation loss: 2.2174632052580514

Epoch: 5| Step: 5
Training loss: 2.135601758956909
Validation loss: 2.190338452657064

Epoch: 5| Step: 6
Training loss: 1.0799801349639893
Validation loss: 2.1840417186419168

Epoch: 5| Step: 7
Training loss: 1.0727193355560303
Validation loss: 2.169596090912819

Epoch: 5| Step: 8
Training loss: 1.498078465461731
Validation loss: 2.1822695632775626

Epoch: 5| Step: 9
Training loss: 1.5254043340682983
Validation loss: 2.1846941858530045

Epoch: 5| Step: 10
Training loss: 1.083143949508667
Validation loss: 2.170159175992012

Epoch: 5| Step: 11
Training loss: 0.8743003010749817
Validation loss: 2.1665892700354257

Epoch: 316| Step: 0
Training loss: 1.2000869512557983
Validation loss: 2.185226251681646

Epoch: 5| Step: 1
Training loss: 1.8561471700668335
Validation loss: 2.1789285043875375

Epoch: 5| Step: 2
Training loss: 1.6205689907073975
Validation loss: 2.1452973783016205

Epoch: 5| Step: 3
Training loss: 1.7945683002471924
Validation loss: 2.1641384859879813

Epoch: 5| Step: 4
Training loss: 1.4801527261734009
Validation loss: 2.1807901759942374

Epoch: 5| Step: 5
Training loss: 1.5787065029144287
Validation loss: 2.1786674906810126

Epoch: 5| Step: 6
Training loss: 0.9121024012565613
Validation loss: 2.182037522395452

Epoch: 5| Step: 7
Training loss: 1.4552135467529297
Validation loss: 2.1815148293972015

Epoch: 5| Step: 8
Training loss: 1.3590528964996338
Validation loss: 2.2197821885347366

Epoch: 5| Step: 9
Training loss: 1.474461317062378
Validation loss: 2.1925814847151437

Epoch: 5| Step: 10
Training loss: 1.5567848682403564
Validation loss: 2.192723681529363

Epoch: 5| Step: 11
Training loss: 1.0149729251861572
Validation loss: 2.216752747694651

Epoch: 317| Step: 0
Training loss: 0.9192964434623718
Validation loss: 2.2163833578427634

Epoch: 5| Step: 1
Training loss: 1.810218095779419
Validation loss: 2.2632572750250497

Epoch: 5| Step: 2
Training loss: 0.8396813273429871
Validation loss: 2.2377977669239044

Epoch: 5| Step: 3
Training loss: 1.715856909751892
Validation loss: 2.2141212224960327

Epoch: 5| Step: 4
Training loss: 1.3457483053207397
Validation loss: 2.1987554331620536

Epoch: 5| Step: 5
Training loss: 1.1955976486206055
Validation loss: 2.2205602129300437

Epoch: 5| Step: 6
Training loss: 2.1287436485290527
Validation loss: 2.21361343562603

Epoch: 5| Step: 7
Training loss: 1.5667129755020142
Validation loss: 2.2104175984859467

Epoch: 5| Step: 8
Training loss: 1.6382558345794678
Validation loss: 2.204499915242195

Epoch: 5| Step: 9
Training loss: 1.479307770729065
Validation loss: 2.207077279686928

Epoch: 5| Step: 10
Training loss: 0.9944702982902527
Validation loss: 2.243521124124527

Epoch: 5| Step: 11
Training loss: 1.8937568664550781
Validation loss: 2.2049971719582877

Epoch: 318| Step: 0
Training loss: 1.3742914199829102
Validation loss: 2.216211214661598

Epoch: 5| Step: 1
Training loss: 1.2721912860870361
Validation loss: 2.186864266792933

Epoch: 5| Step: 2
Training loss: 1.407434105873108
Validation loss: 2.1984686255455017

Epoch: 5| Step: 3
Training loss: 1.587097406387329
Validation loss: 2.17285248140494

Epoch: 5| Step: 4
Training loss: 1.6134716272354126
Validation loss: 2.186539515852928

Epoch: 5| Step: 5
Training loss: 1.0400140285491943
Validation loss: 2.192988336086273

Epoch: 5| Step: 6
Training loss: 1.3148490190505981
Validation loss: 2.194252828756968

Epoch: 5| Step: 7
Training loss: 1.644076943397522
Validation loss: 2.1723692417144775

Epoch: 5| Step: 8
Training loss: 1.2656679153442383
Validation loss: 2.2046463042497635

Epoch: 5| Step: 9
Training loss: 1.2930338382720947
Validation loss: 2.1680484612782798

Epoch: 5| Step: 10
Training loss: 1.2119872570037842
Validation loss: 2.167789101600647

Epoch: 5| Step: 11
Training loss: 1.1541119813919067
Validation loss: 2.200544094045957

Epoch: 319| Step: 0
Training loss: 1.8276885747909546
Validation loss: 2.174625833829244

Epoch: 5| Step: 1
Training loss: 1.19905686378479
Validation loss: 2.1737818519274392

Epoch: 5| Step: 2
Training loss: 0.8483422994613647
Validation loss: 2.1962937315305076

Epoch: 5| Step: 3
Training loss: 1.138317346572876
Validation loss: 2.1890967388947806

Epoch: 5| Step: 4
Training loss: 1.1795015335083008
Validation loss: 2.1829316318035126

Epoch: 5| Step: 5
Training loss: 1.344164252281189
Validation loss: 2.1989309191703796

Epoch: 5| Step: 6
Training loss: 1.4544973373413086
Validation loss: 2.1826985279719033

Epoch: 5| Step: 7
Training loss: 1.6272366046905518
Validation loss: 2.1899511218070984

Epoch: 5| Step: 8
Training loss: 1.8357034921646118
Validation loss: 2.1954289078712463

Epoch: 5| Step: 9
Training loss: 1.5013439655303955
Validation loss: 2.1923235406478248

Epoch: 5| Step: 10
Training loss: 1.1187490224838257
Validation loss: 2.1969722658395767

Epoch: 5| Step: 11
Training loss: 1.8004472255706787
Validation loss: 2.189532458782196

Epoch: 320| Step: 0
Training loss: 1.3407220840454102
Validation loss: 2.1850022027889886

Epoch: 5| Step: 1
Training loss: 1.109252691268921
Validation loss: 2.2064151763916016

Epoch: 5| Step: 2
Training loss: 1.2117493152618408
Validation loss: 2.157208263874054

Epoch: 5| Step: 3
Training loss: 1.1553796529769897
Validation loss: 2.1914039303859076

Epoch: 5| Step: 4
Training loss: 1.2652772665023804
Validation loss: 2.1846251686414084

Epoch: 5| Step: 5
Training loss: 1.0717171430587769
Validation loss: 2.1816958536704383

Epoch: 5| Step: 6
Training loss: 1.3484009504318237
Validation loss: 2.1825085431337357

Epoch: 5| Step: 7
Training loss: 1.4592770338058472
Validation loss: 2.222448299328486

Epoch: 5| Step: 8
Training loss: 1.334936261177063
Validation loss: 2.216579109430313

Epoch: 5| Step: 9
Training loss: 1.6196982860565186
Validation loss: 2.2036766012509665

Epoch: 5| Step: 10
Training loss: 1.8451893329620361
Validation loss: 2.1945406198501587

Epoch: 5| Step: 11
Training loss: 2.155071258544922
Validation loss: 2.223973900079727

Epoch: 321| Step: 0
Training loss: 1.0857996940612793
Validation loss: 2.2163745115200677

Epoch: 5| Step: 1
Training loss: 1.6901881694793701
Validation loss: 2.2105068365732827

Epoch: 5| Step: 2
Training loss: 0.909272313117981
Validation loss: 2.2137621541817984

Epoch: 5| Step: 3
Training loss: 1.55818772315979
Validation loss: 2.2104156961043677

Epoch: 5| Step: 4
Training loss: 1.3378623723983765
Validation loss: 2.235776017109553

Epoch: 5| Step: 5
Training loss: 1.6254899501800537
Validation loss: 2.245760530233383

Epoch: 5| Step: 6
Training loss: 1.2296388149261475
Validation loss: 2.2231994767983756

Epoch: 5| Step: 7
Training loss: 1.5394269227981567
Validation loss: 2.2349739372730255

Epoch: 5| Step: 8
Training loss: 1.3945446014404297
Validation loss: 2.2126300831635795

Epoch: 5| Step: 9
Training loss: 0.9046320915222168
Validation loss: 2.2171363731225333

Epoch: 5| Step: 10
Training loss: 1.6103096008300781
Validation loss: 2.191632250944773

Epoch: 5| Step: 11
Training loss: 0.9981541633605957
Validation loss: 2.188189143935839

Epoch: 322| Step: 0
Training loss: 1.075157880783081
Validation loss: 2.169475808739662

Epoch: 5| Step: 1
Training loss: 1.5398343801498413
Validation loss: 2.1611114343007407

Epoch: 5| Step: 2
Training loss: 1.7116830348968506
Validation loss: 2.136956676840782

Epoch: 5| Step: 3
Training loss: 1.4511491060256958
Validation loss: 2.1390863209962845

Epoch: 5| Step: 4
Training loss: 1.3689037561416626
Validation loss: 2.156342104077339

Epoch: 5| Step: 5
Training loss: 1.002672553062439
Validation loss: 2.1486400862534842

Epoch: 5| Step: 6
Training loss: 1.5009620189666748
Validation loss: 2.188918719689051

Epoch: 5| Step: 7
Training loss: 1.254550576210022
Validation loss: 2.1732354164123535

Epoch: 5| Step: 8
Training loss: 1.9018462896347046
Validation loss: 2.156441867351532

Epoch: 5| Step: 9
Training loss: 1.6804462671279907
Validation loss: 2.152900313337644

Epoch: 5| Step: 10
Training loss: 1.0057260990142822
Validation loss: 2.1981926957766214

Epoch: 5| Step: 11
Training loss: 1.1494028568267822
Validation loss: 2.1871057202418647

Epoch: 323| Step: 0
Training loss: 0.9344841241836548
Validation loss: 2.166701520482699

Epoch: 5| Step: 1
Training loss: 1.4187557697296143
Validation loss: 2.2002488325039544

Epoch: 5| Step: 2
Training loss: 1.3957014083862305
Validation loss: 2.184983049829801

Epoch: 5| Step: 3
Training loss: 0.7064612507820129
Validation loss: 2.2091675897439322

Epoch: 5| Step: 4
Training loss: 1.0002131462097168
Validation loss: 2.2535317291816077

Epoch: 5| Step: 5
Training loss: 1.7285804748535156
Validation loss: 2.2311238447825112

Epoch: 5| Step: 6
Training loss: 2.414647340774536
Validation loss: 2.253443111975988

Epoch: 5| Step: 7
Training loss: 1.6657555103302002
Validation loss: 2.2012788355350494

Epoch: 5| Step: 8
Training loss: 1.4172041416168213
Validation loss: 2.2016128847996392

Epoch: 5| Step: 9
Training loss: 0.9564728736877441
Validation loss: 2.2124055375655494

Epoch: 5| Step: 10
Training loss: 1.345902681350708
Validation loss: 2.1830949733654657

Epoch: 5| Step: 11
Training loss: 1.7177460193634033
Validation loss: 2.156110813220342

Epoch: 324| Step: 0
Training loss: 1.4185994863510132
Validation loss: 2.1827746629714966

Epoch: 5| Step: 1
Training loss: 1.8529689311981201
Validation loss: 2.228739152352015

Epoch: 5| Step: 2
Training loss: 1.1879874467849731
Validation loss: 2.1814363996187844

Epoch: 5| Step: 3
Training loss: 1.4938241243362427
Validation loss: 2.1910399049520493

Epoch: 5| Step: 4
Training loss: 0.9637063145637512
Validation loss: 2.2140680948893228

Epoch: 5| Step: 5
Training loss: 2.1965458393096924
Validation loss: 2.206501767039299

Epoch: 5| Step: 6
Training loss: 0.7653848528862
Validation loss: 2.1997276147206626

Epoch: 5| Step: 7
Training loss: 0.990716278553009
Validation loss: 2.203140079975128

Epoch: 5| Step: 8
Training loss: 1.765439748764038
Validation loss: 2.1615167260169983

Epoch: 5| Step: 9
Training loss: 0.8526195287704468
Validation loss: 2.196070129672686

Epoch: 5| Step: 10
Training loss: 1.036414384841919
Validation loss: 2.169348751505216

Epoch: 5| Step: 11
Training loss: 3.494293451309204
Validation loss: 2.1748842298984528

Epoch: 325| Step: 0
Training loss: 1.5917418003082275
Validation loss: 2.17933655778567

Epoch: 5| Step: 1
Training loss: 1.402562141418457
Validation loss: 2.1821128726005554

Epoch: 5| Step: 2
Training loss: 2.1347618103027344
Validation loss: 2.166965574026108

Epoch: 5| Step: 3
Training loss: 1.7244065999984741
Validation loss: 2.162350118160248

Epoch: 5| Step: 4
Training loss: 1.4133951663970947
Validation loss: 2.197809567054113

Epoch: 5| Step: 5
Training loss: 0.8990274667739868
Validation loss: 2.2140491207440696

Epoch: 5| Step: 6
Training loss: 1.3878282308578491
Validation loss: 2.1988700926303864

Epoch: 5| Step: 7
Training loss: 0.9290367364883423
Validation loss: 2.2253073950608573

Epoch: 5| Step: 8
Training loss: 0.8805147409439087
Validation loss: 2.211650381485621

Epoch: 5| Step: 9
Training loss: 0.9946042895317078
Validation loss: 2.2467125356197357

Epoch: 5| Step: 10
Training loss: 1.3895143270492554
Validation loss: 2.2129171043634415

Epoch: 5| Step: 11
Training loss: 1.0255827903747559
Validation loss: 2.246118118365606

Epoch: 326| Step: 0
Training loss: 0.9970575571060181
Validation loss: 2.2479384442170462

Epoch: 5| Step: 1
Training loss: 1.2066799402236938
Validation loss: 2.2370186150074005

Epoch: 5| Step: 2
Training loss: 1.6371095180511475
Validation loss: 2.207992891470591

Epoch: 5| Step: 3
Training loss: 1.131611943244934
Validation loss: 2.2186616510152817

Epoch: 5| Step: 4
Training loss: 1.346742868423462
Validation loss: 2.2050846219062805

Epoch: 5| Step: 5
Training loss: 1.5018917322158813
Validation loss: 2.20905239880085

Epoch: 5| Step: 6
Training loss: 1.0753992795944214
Validation loss: 2.203749751051267

Epoch: 5| Step: 7
Training loss: 1.263575553894043
Validation loss: 2.1894330382347107

Epoch: 5| Step: 8
Training loss: 2.197233200073242
Validation loss: 2.1815635412931442

Epoch: 5| Step: 9
Training loss: 1.220194935798645
Validation loss: 2.2148666381835938

Epoch: 5| Step: 10
Training loss: 1.4335731267929077
Validation loss: 2.195467402537664

Epoch: 5| Step: 11
Training loss: 0.42163166403770447
Validation loss: 2.193572243054708

Epoch: 327| Step: 0
Training loss: 1.9270455837249756
Validation loss: 2.166492839654287

Epoch: 5| Step: 1
Training loss: 1.7364718914031982
Validation loss: 2.159535681207975

Epoch: 5| Step: 2
Training loss: 1.2343496084213257
Validation loss: 2.1786292791366577

Epoch: 5| Step: 3
Training loss: 1.7236381769180298
Validation loss: 2.2175678809483848

Epoch: 5| Step: 4
Training loss: 1.2772754430770874
Validation loss: 2.187859440843264

Epoch: 5| Step: 5
Training loss: 0.7744907140731812
Validation loss: 2.1964862793684006

Epoch: 5| Step: 6
Training loss: 0.8297675848007202
Validation loss: 2.199919934074084

Epoch: 5| Step: 7
Training loss: 0.7951887249946594
Validation loss: 2.1615133782227836

Epoch: 5| Step: 8
Training loss: 1.3045265674591064
Validation loss: 2.199350734551748

Epoch: 5| Step: 9
Training loss: 1.7272752523422241
Validation loss: 2.1473302245140076

Epoch: 5| Step: 10
Training loss: 1.4849746227264404
Validation loss: 2.172625412543615

Epoch: 5| Step: 11
Training loss: 0.8994684815406799
Validation loss: 2.1972487419843674

Epoch: 328| Step: 0
Training loss: 1.1334565877914429
Validation loss: 2.1961767822504044

Epoch: 5| Step: 1
Training loss: 1.8241325616836548
Validation loss: 2.180593103170395

Epoch: 5| Step: 2
Training loss: 1.434873342514038
Validation loss: 2.1568571428457894

Epoch: 5| Step: 3
Training loss: 1.6630834341049194
Validation loss: 2.1714860796928406

Epoch: 5| Step: 4
Training loss: 1.4418208599090576
Validation loss: 2.1658184429009757

Epoch: 5| Step: 5
Training loss: 1.2224409580230713
Validation loss: 2.148704946041107

Epoch: 5| Step: 6
Training loss: 1.6564807891845703
Validation loss: 2.164371366302172

Epoch: 5| Step: 7
Training loss: 1.5087095499038696
Validation loss: 2.120131323734919

Epoch: 5| Step: 8
Training loss: 1.3919565677642822
Validation loss: 2.1568549474080405

Epoch: 5| Step: 9
Training loss: 1.5492912530899048
Validation loss: 2.134695033232371

Epoch: 5| Step: 10
Training loss: 0.8987542390823364
Validation loss: 2.152024338642756

Epoch: 5| Step: 11
Training loss: 1.0423394441604614
Validation loss: 2.138165906071663

Epoch: 329| Step: 0
Training loss: 1.0300209522247314
Validation loss: 2.1602991769711175

Epoch: 5| Step: 1
Training loss: 1.501056432723999
Validation loss: 2.1822875638802848

Epoch: 5| Step: 2
Training loss: 1.232694149017334
Validation loss: 2.1816986203193665

Epoch: 5| Step: 3
Training loss: 1.3804782629013062
Validation loss: 2.170971244573593

Epoch: 5| Step: 4
Training loss: 1.0873217582702637
Validation loss: 2.217860514918963

Epoch: 5| Step: 5
Training loss: 1.2622634172439575
Validation loss: 2.231206069389979

Epoch: 5| Step: 6
Training loss: 1.5376001596450806
Validation loss: 2.2437118887901306

Epoch: 5| Step: 7
Training loss: 1.3576046228408813
Validation loss: 2.2335090984900794

Epoch: 5| Step: 8
Training loss: 1.765770673751831
Validation loss: 2.2431743492682776

Epoch: 5| Step: 9
Training loss: 1.0898622274398804
Validation loss: 2.2245440830787024

Epoch: 5| Step: 10
Training loss: 1.6536773443222046
Validation loss: 2.236209770043691

Epoch: 5| Step: 11
Training loss: 0.17886888980865479
Validation loss: 2.2475850184758506

Epoch: 330| Step: 0
Training loss: 1.2231346368789673
Validation loss: 2.2406947314739227

Epoch: 5| Step: 1
Training loss: 1.429286241531372
Validation loss: 2.2513339122136435

Epoch: 5| Step: 2
Training loss: 1.1948322057724
Validation loss: 2.29127769668897

Epoch: 5| Step: 3
Training loss: 0.9265936613082886
Validation loss: 2.241560419400533

Epoch: 5| Step: 4
Training loss: 1.6704747676849365
Validation loss: 2.259196182092031

Epoch: 5| Step: 5
Training loss: 1.7901971340179443
Validation loss: 2.244968389471372

Epoch: 5| Step: 6
Training loss: 0.8793738484382629
Validation loss: 2.246824155251185

Epoch: 5| Step: 7
Training loss: 1.2088677883148193
Validation loss: 2.2270317723353705

Epoch: 5| Step: 8
Training loss: 1.5264111757278442
Validation loss: 2.2396097779273987

Epoch: 5| Step: 9
Training loss: 1.1677837371826172
Validation loss: 2.2317078510920205

Epoch: 5| Step: 10
Training loss: 1.4216852188110352
Validation loss: 2.22207901875178

Epoch: 5| Step: 11
Training loss: 1.7609045505523682
Validation loss: 2.2105804483095803

Epoch: 331| Step: 0
Training loss: 0.9818717837333679
Validation loss: 2.2210801343123117

Epoch: 5| Step: 1
Training loss: 1.2329914569854736
Validation loss: 2.211399659514427

Epoch: 5| Step: 2
Training loss: 1.3862439393997192
Validation loss: 2.202853113412857

Epoch: 5| Step: 3
Training loss: 1.059988260269165
Validation loss: 2.235123261809349

Epoch: 5| Step: 4
Training loss: 1.2832953929901123
Validation loss: 2.208728770414988

Epoch: 5| Step: 5
Training loss: 1.4207452535629272
Validation loss: 2.223220005631447

Epoch: 5| Step: 6
Training loss: 1.323918104171753
Validation loss: 2.2452152222394943

Epoch: 5| Step: 7
Training loss: 2.1124539375305176
Validation loss: 2.2784613172213235

Epoch: 5| Step: 8
Training loss: 0.902849555015564
Validation loss: 2.2252887388070426

Epoch: 5| Step: 9
Training loss: 0.932050347328186
Validation loss: 2.2491793731848397

Epoch: 5| Step: 10
Training loss: 1.2917934656143188
Validation loss: 2.2562314569950104

Epoch: 5| Step: 11
Training loss: 1.9230997562408447
Validation loss: 2.236565127968788

Epoch: 332| Step: 0
Training loss: 1.2991702556610107
Validation loss: 2.2646753787994385

Epoch: 5| Step: 1
Training loss: 0.9337032437324524
Validation loss: 2.2477353860934577

Epoch: 5| Step: 2
Training loss: 1.1827805042266846
Validation loss: 2.2388866941134133

Epoch: 5| Step: 3
Training loss: 1.559531807899475
Validation loss: 2.287257661422094

Epoch: 5| Step: 4
Training loss: 1.5963435173034668
Validation loss: 2.253200799226761

Epoch: 5| Step: 5
Training loss: 1.0294859409332275
Validation loss: 2.2814452399810157

Epoch: 5| Step: 6
Training loss: 1.0900719165802002
Validation loss: 2.225756118694941

Epoch: 5| Step: 7
Training loss: 1.3033881187438965
Validation loss: 2.240472584962845

Epoch: 5| Step: 8
Training loss: 1.4892469644546509
Validation loss: 2.2599603831768036

Epoch: 5| Step: 9
Training loss: 1.7360512018203735
Validation loss: 2.2711237172285714

Epoch: 5| Step: 10
Training loss: 1.0449320077896118
Validation loss: 2.285839835802714

Epoch: 5| Step: 11
Training loss: 0.8163896203041077
Validation loss: 2.234721099336942

Epoch: 333| Step: 0
Training loss: 1.183194875717163
Validation loss: 2.2228111922740936

Epoch: 5| Step: 1
Training loss: 1.2180349826812744
Validation loss: 2.227184275786082

Epoch: 5| Step: 2
Training loss: 1.3328214883804321
Validation loss: 2.1932403345902762

Epoch: 5| Step: 3
Training loss: 1.2170133590698242
Validation loss: 2.1941860715548196

Epoch: 5| Step: 4
Training loss: 0.894943118095398
Validation loss: 2.195765649278959

Epoch: 5| Step: 5
Training loss: 1.312212586402893
Validation loss: 2.2108007768789926

Epoch: 5| Step: 6
Training loss: 1.492159128189087
Validation loss: 2.235769400993983

Epoch: 5| Step: 7
Training loss: 1.72345769405365
Validation loss: 2.2167892505725226

Epoch: 5| Step: 8
Training loss: 1.5492321252822876
Validation loss: 2.2375783373912177

Epoch: 5| Step: 9
Training loss: 1.3639479875564575
Validation loss: 2.255655989050865

Epoch: 5| Step: 10
Training loss: 1.440331220626831
Validation loss: 2.250854859749476

Epoch: 5| Step: 11
Training loss: 1.0987803936004639
Validation loss: 2.226329803466797

Epoch: 334| Step: 0
Training loss: 1.230701208114624
Validation loss: 2.246720179915428

Epoch: 5| Step: 1
Training loss: 1.3508021831512451
Validation loss: 2.2336564461390176

Epoch: 5| Step: 2
Training loss: 0.718789279460907
Validation loss: 2.2635700702667236

Epoch: 5| Step: 3
Training loss: 1.7611242532730103
Validation loss: 2.20993081231912

Epoch: 5| Step: 4
Training loss: 1.3198527097702026
Validation loss: 2.1986753344535828

Epoch: 5| Step: 5
Training loss: 1.9015041589736938
Validation loss: 2.2255329489707947

Epoch: 5| Step: 6
Training loss: 1.7797771692276
Validation loss: 2.223271518945694

Epoch: 5| Step: 7
Training loss: 1.0420211553573608
Validation loss: 2.2324630419413247

Epoch: 5| Step: 8
Training loss: 0.9543142318725586
Validation loss: 2.215224474668503

Epoch: 5| Step: 9
Training loss: 1.1159241199493408
Validation loss: 2.2038149336973825

Epoch: 5| Step: 10
Training loss: 1.0416898727416992
Validation loss: 2.1752542157967887

Epoch: 5| Step: 11
Training loss: 1.5671871900558472
Validation loss: 2.1547317604223886

Epoch: 335| Step: 0
Training loss: 1.2542335987091064
Validation loss: 2.185300201177597

Epoch: 5| Step: 1
Training loss: 1.7684640884399414
Validation loss: 2.16110069056352

Epoch: 5| Step: 2
Training loss: 1.9241950511932373
Validation loss: 2.1997047464052835

Epoch: 5| Step: 3
Training loss: 1.1740535497665405
Validation loss: 2.16958749294281

Epoch: 5| Step: 4
Training loss: 0.6737385392189026
Validation loss: 2.1930564641952515

Epoch: 5| Step: 5
Training loss: 1.0606433153152466
Validation loss: 2.226271311442057

Epoch: 5| Step: 6
Training loss: 1.8897771835327148
Validation loss: 2.148086821039518

Epoch: 5| Step: 7
Training loss: 1.4492056369781494
Validation loss: 2.210133080681165

Epoch: 5| Step: 8
Training loss: 0.867808997631073
Validation loss: 2.199275404214859

Epoch: 5| Step: 9
Training loss: 1.2655246257781982
Validation loss: 2.1851688424746194

Epoch: 5| Step: 10
Training loss: 1.3823598623275757
Validation loss: 2.19712133705616

Epoch: 5| Step: 11
Training loss: 1.2460575103759766
Validation loss: 2.24077300230662

Epoch: 336| Step: 0
Training loss: 1.555149793624878
Validation loss: 2.239133194088936

Epoch: 5| Step: 1
Training loss: 1.1157456636428833
Validation loss: 2.2543309231599173

Epoch: 5| Step: 2
Training loss: 1.1075624227523804
Validation loss: 2.2387063403924308

Epoch: 5| Step: 3
Training loss: 1.4303162097930908
Validation loss: 2.2056865890820823

Epoch: 5| Step: 4
Training loss: 1.6083695888519287
Validation loss: 2.2265361646811166

Epoch: 5| Step: 5
Training loss: 1.9554325342178345
Validation loss: 2.1955279310544333

Epoch: 5| Step: 6
Training loss: 1.099259614944458
Validation loss: 2.206892261902491

Epoch: 5| Step: 7
Training loss: 1.2078406810760498
Validation loss: 2.1926076660553613

Epoch: 5| Step: 8
Training loss: 1.111430287361145
Validation loss: 2.2319760074218116

Epoch: 5| Step: 9
Training loss: 0.5277284383773804
Validation loss: 2.2423419257005057

Epoch: 5| Step: 10
Training loss: 1.4148279428482056
Validation loss: 2.2770940909783044

Epoch: 5| Step: 11
Training loss: 1.0934197902679443
Validation loss: 2.2592389980951944

Epoch: 337| Step: 0
Training loss: 1.2640351057052612
Validation loss: 2.262881870071093

Epoch: 5| Step: 1
Training loss: 1.337066888809204
Validation loss: 2.2804016123215356

Epoch: 5| Step: 2
Training loss: 1.6876484155654907
Validation loss: 2.262409895658493

Epoch: 5| Step: 3
Training loss: 1.127851128578186
Validation loss: 2.1949588557084403

Epoch: 5| Step: 4
Training loss: 1.2797647714614868
Validation loss: 2.206870233019193

Epoch: 5| Step: 5
Training loss: 1.3277347087860107
Validation loss: 2.184947525461515

Epoch: 5| Step: 6
Training loss: 1.4258596897125244
Validation loss: 2.188255767027537

Epoch: 5| Step: 7
Training loss: 1.0744984149932861
Validation loss: 2.2021832366784415

Epoch: 5| Step: 8
Training loss: 1.0154905319213867
Validation loss: 2.2212832272052765

Epoch: 5| Step: 9
Training loss: 1.7048231363296509
Validation loss: 2.245216210683187

Epoch: 5| Step: 10
Training loss: 1.0441042184829712
Validation loss: 2.207601090272268

Epoch: 5| Step: 11
Training loss: 1.364203691482544
Validation loss: 2.208000401655833

Epoch: 338| Step: 0
Training loss: 1.136350154876709
Validation loss: 2.193402722477913

Epoch: 5| Step: 1
Training loss: 0.8295572400093079
Validation loss: 2.228814254204432

Epoch: 5| Step: 2
Training loss: 1.2842754125595093
Validation loss: 2.196628858645757

Epoch: 5| Step: 3
Training loss: 1.48738694190979
Validation loss: 2.206401710708936

Epoch: 5| Step: 4
Training loss: 1.5078785419464111
Validation loss: 2.203852489590645

Epoch: 5| Step: 5
Training loss: 1.7288453578948975
Validation loss: 2.210496872663498

Epoch: 5| Step: 6
Training loss: 1.2222167253494263
Validation loss: 2.236771454413732

Epoch: 5| Step: 7
Training loss: 1.1869289875030518
Validation loss: 2.2480828911066055

Epoch: 5| Step: 8
Training loss: 1.6381466388702393
Validation loss: 2.1938062955935798

Epoch: 5| Step: 9
Training loss: 0.8832143545150757
Validation loss: 2.1904891033967337

Epoch: 5| Step: 10
Training loss: 0.9367274045944214
Validation loss: 2.2444963455200195

Epoch: 5| Step: 11
Training loss: 1.0441255569458008
Validation loss: 2.2313024699687958

Epoch: 339| Step: 0
Training loss: 1.4715465307235718
Validation loss: 2.219151129325231

Epoch: 5| Step: 1
Training loss: 1.0880520343780518
Validation loss: 2.2292971114317575

Epoch: 5| Step: 2
Training loss: 1.4422125816345215
Validation loss: 2.2496146261692047

Epoch: 5| Step: 3
Training loss: 1.0758994817733765
Validation loss: 2.200639540950457

Epoch: 5| Step: 4
Training loss: 1.030984878540039
Validation loss: 2.201207290093104

Epoch: 5| Step: 5
Training loss: 1.3922332525253296
Validation loss: 2.175729994972547

Epoch: 5| Step: 6
Training loss: 0.9559151530265808
Validation loss: 2.2295491695404053

Epoch: 5| Step: 7
Training loss: 0.7460771203041077
Validation loss: 2.270932594935099

Epoch: 5| Step: 8
Training loss: 1.5881328582763672
Validation loss: 2.2764327128728232

Epoch: 5| Step: 9
Training loss: 1.7211239337921143
Validation loss: 2.253284220894178

Epoch: 5| Step: 10
Training loss: 1.400692343711853
Validation loss: 2.2085829426844916

Epoch: 5| Step: 11
Training loss: 0.5496855974197388
Validation loss: 2.2673319379488626

Epoch: 340| Step: 0
Training loss: 1.13799250125885
Validation loss: 2.2121863067150116

Epoch: 5| Step: 1
Training loss: 0.7496541738510132
Validation loss: 2.213654508193334

Epoch: 5| Step: 2
Training loss: 1.3862395286560059
Validation loss: 2.222772787014643

Epoch: 5| Step: 3
Training loss: 1.5389947891235352
Validation loss: 2.184415449698766

Epoch: 5| Step: 4
Training loss: 0.9847356677055359
Validation loss: 2.2107719679673514

Epoch: 5| Step: 5
Training loss: 1.491432785987854
Validation loss: 2.2027290165424347

Epoch: 5| Step: 6
Training loss: 1.154651165008545
Validation loss: 2.205372820297877

Epoch: 5| Step: 7
Training loss: 0.8163197636604309
Validation loss: 2.214115341504415

Epoch: 5| Step: 8
Training loss: 1.1333906650543213
Validation loss: 2.1880436092615128

Epoch: 5| Step: 9
Training loss: 1.7554938793182373
Validation loss: 2.1785154740015664

Epoch: 5| Step: 10
Training loss: 1.4636529684066772
Validation loss: 2.1675052642822266

Epoch: 5| Step: 11
Training loss: 0.9768322706222534
Validation loss: 2.210992932319641

Epoch: 341| Step: 0
Training loss: 1.8408386707305908
Validation loss: 2.175301735599836

Epoch: 5| Step: 1
Training loss: 1.260151743888855
Validation loss: 2.2034249802430472

Epoch: 5| Step: 2
Training loss: 1.2660359144210815
Validation loss: 2.2015643318494162

Epoch: 5| Step: 3
Training loss: 1.191136360168457
Validation loss: 2.215330178538958

Epoch: 5| Step: 4
Training loss: 1.5190699100494385
Validation loss: 2.1800369769334793

Epoch: 5| Step: 5
Training loss: 1.0720704793930054
Validation loss: 2.1713315844535828

Epoch: 5| Step: 6
Training loss: 1.7161095142364502
Validation loss: 2.2008808255195618

Epoch: 5| Step: 7
Training loss: 0.8630938529968262
Validation loss: 2.1889984210332236

Epoch: 5| Step: 8
Training loss: 1.1015578508377075
Validation loss: 2.212277829647064

Epoch: 5| Step: 9
Training loss: 1.499389886856079
Validation loss: 2.2142241398493447

Epoch: 5| Step: 10
Training loss: 0.9171208143234253
Validation loss: 2.2246674398581185

Epoch: 5| Step: 11
Training loss: 0.13245534896850586
Validation loss: 2.220597267150879

Epoch: 342| Step: 0
Training loss: 1.1401067972183228
Validation loss: 2.268609901269277

Epoch: 5| Step: 1
Training loss: 1.4040558338165283
Validation loss: 2.247666597366333

Epoch: 5| Step: 2
Training loss: 1.2513090372085571
Validation loss: 2.2400842805703483

Epoch: 5| Step: 3
Training loss: 1.0456552505493164
Validation loss: 2.2503128051757812

Epoch: 5| Step: 4
Training loss: 1.0557407140731812
Validation loss: 2.189512883623441

Epoch: 5| Step: 5
Training loss: 1.2199398279190063
Validation loss: 2.2147358854611716

Epoch: 5| Step: 6
Training loss: 0.940278172492981
Validation loss: 2.203722983598709

Epoch: 5| Step: 7
Training loss: 1.1414276361465454
Validation loss: 2.190203234553337

Epoch: 5| Step: 8
Training loss: 1.4661504030227661
Validation loss: 2.1860699554284415

Epoch: 5| Step: 9
Training loss: 2.5812277793884277
Validation loss: 2.223664397994677

Epoch: 5| Step: 10
Training loss: 1.109654188156128
Validation loss: 2.214322571953138

Epoch: 5| Step: 11
Training loss: 0.9246382713317871
Validation loss: 2.217079391082128

Epoch: 343| Step: 0
Training loss: 1.3368234634399414
Validation loss: 2.2232353885968528

Epoch: 5| Step: 1
Training loss: 1.5247987508773804
Validation loss: 2.2306553622086844

Epoch: 5| Step: 2
Training loss: 1.2678477764129639
Validation loss: 2.248068700234095

Epoch: 5| Step: 3
Training loss: 1.083875298500061
Validation loss: 2.2031130641698837

Epoch: 5| Step: 4
Training loss: 0.8356167078018188
Validation loss: 2.185619110862414

Epoch: 5| Step: 5
Training loss: 1.2391875982284546
Validation loss: 2.2384944756825766

Epoch: 5| Step: 6
Training loss: 1.3816543817520142
Validation loss: 2.2293556928634644

Epoch: 5| Step: 7
Training loss: 1.2916651964187622
Validation loss: 2.2294680376847587

Epoch: 5| Step: 8
Training loss: 1.6891695261001587
Validation loss: 2.2140726298093796

Epoch: 5| Step: 9
Training loss: 1.329429268836975
Validation loss: 2.2303084631760917

Epoch: 5| Step: 10
Training loss: 0.7536226511001587
Validation loss: 2.222478633125623

Epoch: 5| Step: 11
Training loss: 2.3202316761016846
Validation loss: 2.263141691684723

Epoch: 344| Step: 0
Training loss: 1.259734869003296
Validation loss: 2.2113739997148514

Epoch: 5| Step: 1
Training loss: 1.3382161855697632
Validation loss: 2.199466814597448

Epoch: 5| Step: 2
Training loss: 0.9886563420295715
Validation loss: 2.1987814704577127

Epoch: 5| Step: 3
Training loss: 1.2474459409713745
Validation loss: 2.244748115539551

Epoch: 5| Step: 4
Training loss: 1.0501680374145508
Validation loss: 2.2719279130299888

Epoch: 5| Step: 5
Training loss: 1.2753772735595703
Validation loss: 2.194157858689626

Epoch: 5| Step: 6
Training loss: 0.9545860290527344
Validation loss: 2.220713963111242

Epoch: 5| Step: 7
Training loss: 2.0435869693756104
Validation loss: 2.19635538260142

Epoch: 5| Step: 8
Training loss: 1.3879637718200684
Validation loss: 2.178024793664614

Epoch: 5| Step: 9
Training loss: 1.1948776245117188
Validation loss: 2.188379113872846

Epoch: 5| Step: 10
Training loss: 1.6239248514175415
Validation loss: 2.1595365405082703

Epoch: 5| Step: 11
Training loss: 1.2783645391464233
Validation loss: 2.1891651153564453

Epoch: 345| Step: 0
Training loss: 0.8052838444709778
Validation loss: 2.171217898527781

Epoch: 5| Step: 1
Training loss: 1.608078956604004
Validation loss: 2.1450325647989907

Epoch: 5| Step: 2
Training loss: 1.2524034976959229
Validation loss: 2.140657236178716

Epoch: 5| Step: 3
Training loss: 1.003210186958313
Validation loss: 2.1200426568587623

Epoch: 5| Step: 4
Training loss: 1.2577974796295166
Validation loss: 2.151608407497406

Epoch: 5| Step: 5
Training loss: 0.9138911962509155
Validation loss: 2.1596953670183816

Epoch: 5| Step: 6
Training loss: 1.4793274402618408
Validation loss: 2.161032050848007

Epoch: 5| Step: 7
Training loss: 1.5630829334259033
Validation loss: 2.1401787797609964

Epoch: 5| Step: 8
Training loss: 1.9563610553741455
Validation loss: 2.1844809552033744

Epoch: 5| Step: 9
Training loss: 1.1200300455093384
Validation loss: 2.1719512045383453

Epoch: 5| Step: 10
Training loss: 1.4137042760849
Validation loss: 2.191578427950541

Epoch: 5| Step: 11
Training loss: 0.4097597002983093
Validation loss: 2.1723501483599343

Epoch: 346| Step: 0
Training loss: 1.2685085535049438
Validation loss: 2.1685876746972403

Epoch: 5| Step: 1
Training loss: 1.683740258216858
Validation loss: 2.1648874630530677

Epoch: 5| Step: 2
Training loss: 1.0720287561416626
Validation loss: 2.116132616996765

Epoch: 5| Step: 3
Training loss: 1.3391590118408203
Validation loss: 2.152414376537005

Epoch: 5| Step: 4
Training loss: 1.5738524198532104
Validation loss: 2.1719327370325723

Epoch: 5| Step: 5
Training loss: 1.1853697299957275
Validation loss: 2.131704012552897

Epoch: 5| Step: 6
Training loss: 0.89021235704422
Validation loss: 2.1283246129751205

Epoch: 5| Step: 7
Training loss: 1.1781470775604248
Validation loss: 2.1359489311774573

Epoch: 5| Step: 8
Training loss: 1.1048336029052734
Validation loss: 2.1541628936926522

Epoch: 5| Step: 9
Training loss: 0.9613936543464661
Validation loss: 2.164442593852679

Epoch: 5| Step: 10
Training loss: 0.6938298940658569
Validation loss: 2.113948638240496

Epoch: 5| Step: 11
Training loss: 3.191460609436035
Validation loss: 2.172712415456772

Epoch: 347| Step: 0
Training loss: 2.1138713359832764
Validation loss: 2.179206222295761

Epoch: 5| Step: 1
Training loss: 0.9685478210449219
Validation loss: 2.1959484120210013

Epoch: 5| Step: 2
Training loss: 0.8673471212387085
Validation loss: 2.1921173334121704

Epoch: 5| Step: 3
Training loss: 1.0620572566986084
Validation loss: 2.2516244103511176

Epoch: 5| Step: 4
Training loss: 1.4975800514221191
Validation loss: 2.201142484943072

Epoch: 5| Step: 5
Training loss: 1.5301640033721924
Validation loss: 2.221576581398646

Epoch: 5| Step: 6
Training loss: 0.7375084161758423
Validation loss: 2.2015687823295593

Epoch: 5| Step: 7
Training loss: 0.9128996133804321
Validation loss: 2.2284131745497384

Epoch: 5| Step: 8
Training loss: 0.9717165231704712
Validation loss: 2.1711223324139914

Epoch: 5| Step: 9
Training loss: 1.4788302183151245
Validation loss: 2.2316794792811074

Epoch: 5| Step: 10
Training loss: 1.2183856964111328
Validation loss: 2.2194031327962875

Epoch: 5| Step: 11
Training loss: 1.0862741470336914
Validation loss: 2.2221504946549735

Epoch: 348| Step: 0
Training loss: 1.0139952898025513
Validation loss: 2.200750688711802

Epoch: 5| Step: 1
Training loss: 1.4436970949172974
Validation loss: 2.2091562201579413

Epoch: 5| Step: 2
Training loss: 0.9317499995231628
Validation loss: 2.167697007457415

Epoch: 5| Step: 3
Training loss: 1.462850570678711
Validation loss: 2.1377030412356057

Epoch: 5| Step: 4
Training loss: 1.500184416770935
Validation loss: 2.1354879339536033

Epoch: 5| Step: 5
Training loss: 0.7270961999893188
Validation loss: 2.1442236254612603

Epoch: 5| Step: 6
Training loss: 1.193272352218628
Validation loss: 2.1390979439020157

Epoch: 5| Step: 7
Training loss: 0.941555380821228
Validation loss: 2.172388086716334

Epoch: 5| Step: 8
Training loss: 1.1765053272247314
Validation loss: 2.1783024817705154

Epoch: 5| Step: 9
Training loss: 1.2727243900299072
Validation loss: 2.1916728913784027

Epoch: 5| Step: 10
Training loss: 1.5533658266067505
Validation loss: 2.1983495155970254

Epoch: 5| Step: 11
Training loss: 2.756451368331909
Validation loss: 2.201535811026891

Epoch: 349| Step: 0
Training loss: 0.983481764793396
Validation loss: 2.2216143012046814

Epoch: 5| Step: 1
Training loss: 0.876445472240448
Validation loss: 2.210461179415385

Epoch: 5| Step: 2
Training loss: 1.6077626943588257
Validation loss: 2.2047871251900992

Epoch: 5| Step: 3
Training loss: 0.6575834155082703
Validation loss: 2.184266855319341

Epoch: 5| Step: 4
Training loss: 1.2574856281280518
Validation loss: 2.2036390403906503

Epoch: 5| Step: 5
Training loss: 0.8871000409126282
Validation loss: 2.217204123735428

Epoch: 5| Step: 6
Training loss: 1.189466118812561
Validation loss: 2.228056420882543

Epoch: 5| Step: 7
Training loss: 0.9110549688339233
Validation loss: 2.243674005071322

Epoch: 5| Step: 8
Training loss: 1.4724940061569214
Validation loss: 2.232015937566757

Epoch: 5| Step: 9
Training loss: 1.2776849269866943
Validation loss: 2.1890932619571686

Epoch: 5| Step: 10
Training loss: 1.9313724040985107
Validation loss: 2.206968372066816

Epoch: 5| Step: 11
Training loss: 1.041962742805481
Validation loss: 2.146749014655749

Epoch: 350| Step: 0
Training loss: 1.0241625308990479
Validation loss: 2.1881923774878183

Epoch: 5| Step: 1
Training loss: 1.0766178369522095
Validation loss: 2.222419117887815

Epoch: 5| Step: 2
Training loss: 1.1119009256362915
Validation loss: 2.1835704197486243

Epoch: 5| Step: 3
Training loss: 1.0448681116104126
Validation loss: 2.184632435441017

Epoch: 5| Step: 4
Training loss: 1.1514317989349365
Validation loss: 2.154650698105494

Epoch: 5| Step: 5
Training loss: 1.1057546138763428
Validation loss: 2.191953589518865

Epoch: 5| Step: 6
Training loss: 1.1565728187561035
Validation loss: 2.22016034523646

Epoch: 5| Step: 7
Training loss: 1.1309239864349365
Validation loss: 2.205117200811704

Epoch: 5| Step: 8
Training loss: 1.2548812627792358
Validation loss: 2.2371698021888733

Epoch: 5| Step: 9
Training loss: 1.5506165027618408
Validation loss: 2.2329261104265847

Epoch: 5| Step: 10
Training loss: 1.0259140729904175
Validation loss: 2.2528524845838547

Epoch: 5| Step: 11
Training loss: 1.6488916873931885
Validation loss: 2.256097207466761

Epoch: 351| Step: 0
Training loss: 1.3525917530059814
Validation loss: 2.1749266982078552

Epoch: 5| Step: 1
Training loss: 1.1165565252304077
Validation loss: 2.1784808188676834

Epoch: 5| Step: 2
Training loss: 1.8215715885162354
Validation loss: 2.180221696694692

Epoch: 5| Step: 3
Training loss: 0.9762985110282898
Validation loss: 2.194616451859474

Epoch: 5| Step: 4
Training loss: 1.2703497409820557
Validation loss: 2.1659641911586127

Epoch: 5| Step: 5
Training loss: 0.6912131309509277
Validation loss: 2.231567919254303

Epoch: 5| Step: 6
Training loss: 0.9827452898025513
Validation loss: 2.2383930881818137

Epoch: 5| Step: 7
Training loss: 1.3342270851135254
Validation loss: 2.1807860881090164

Epoch: 5| Step: 8
Training loss: 0.9111042022705078
Validation loss: 2.2360375970602036

Epoch: 5| Step: 9
Training loss: 1.556233286857605
Validation loss: 2.2401083012421927

Epoch: 5| Step: 10
Training loss: 1.2434169054031372
Validation loss: 2.203076203664144

Epoch: 5| Step: 11
Training loss: 0.8594427108764648
Validation loss: 2.1864822655916214

Epoch: 352| Step: 0
Training loss: 2.052846670150757
Validation loss: 2.2151193718115487

Epoch: 5| Step: 1
Training loss: 0.8280202746391296
Validation loss: 2.1432047486305237

Epoch: 5| Step: 2
Training loss: 0.9932465553283691
Validation loss: 2.1770554582277932

Epoch: 5| Step: 3
Training loss: 1.1326234340667725
Validation loss: 2.216625859340032

Epoch: 5| Step: 4
Training loss: 0.9679250717163086
Validation loss: 2.199852312604586

Epoch: 5| Step: 5
Training loss: 1.348419427871704
Validation loss: 2.181701516111692

Epoch: 5| Step: 6
Training loss: 0.8420255780220032
Validation loss: 2.188365936279297

Epoch: 5| Step: 7
Training loss: 1.4454550743103027
Validation loss: 2.2076932340860367

Epoch: 5| Step: 8
Training loss: 1.215498447418213
Validation loss: 2.213856319586436

Epoch: 5| Step: 9
Training loss: 1.1948060989379883
Validation loss: 2.2313267340262732

Epoch: 5| Step: 10
Training loss: 0.9440447092056274
Validation loss: 2.206360548734665

Epoch: 5| Step: 11
Training loss: 0.6691799163818359
Validation loss: 2.207275072733561

Epoch: 353| Step: 0
Training loss: 1.7423508167266846
Validation loss: 2.2189287145932517

Epoch: 5| Step: 1
Training loss: 1.433899998664856
Validation loss: 2.243670791387558

Epoch: 5| Step: 2
Training loss: 1.093956708908081
Validation loss: 2.2081843316555023

Epoch: 5| Step: 3
Training loss: 0.6744502782821655
Validation loss: 2.2661448816458383

Epoch: 5| Step: 4
Training loss: 0.7724205851554871
Validation loss: 2.1973731418450675

Epoch: 5| Step: 5
Training loss: 1.2572566270828247
Validation loss: 2.258760223786036

Epoch: 5| Step: 6
Training loss: 0.9267222285270691
Validation loss: 2.2312288085619607

Epoch: 5| Step: 7
Training loss: 1.1122616529464722
Validation loss: 2.2153648138046265

Epoch: 5| Step: 8
Training loss: 0.7183641791343689
Validation loss: 2.2272501587867737

Epoch: 5| Step: 9
Training loss: 1.2536967992782593
Validation loss: 2.2275412480036416

Epoch: 5| Step: 10
Training loss: 1.7142292261123657
Validation loss: 2.2330583731333413

Epoch: 5| Step: 11
Training loss: 1.279471516609192
Validation loss: 2.2468207677205405

Epoch: 354| Step: 0
Training loss: 1.5984933376312256
Validation loss: 2.244594390193621

Epoch: 5| Step: 1
Training loss: 0.6932666897773743
Validation loss: 2.2489213248093924

Epoch: 5| Step: 2
Training loss: 0.9319146871566772
Validation loss: 2.279437546928724

Epoch: 5| Step: 3
Training loss: 1.416900396347046
Validation loss: 2.268771678209305

Epoch: 5| Step: 4
Training loss: 0.9793438911437988
Validation loss: 2.2387074629465737

Epoch: 5| Step: 5
Training loss: 1.079521894454956
Validation loss: 2.225139836470286

Epoch: 5| Step: 6
Training loss: 1.1629787683486938
Validation loss: 2.145230064789454

Epoch: 5| Step: 7
Training loss: 1.0127785205841064
Validation loss: 2.1969696382681527

Epoch: 5| Step: 8
Training loss: 1.4193888902664185
Validation loss: 2.1965805192788443

Epoch: 5| Step: 9
Training loss: 1.433184266090393
Validation loss: 2.2124233742554984

Epoch: 5| Step: 10
Training loss: 1.2265758514404297
Validation loss: 2.165147985021273

Epoch: 5| Step: 11
Training loss: 0.7147488594055176
Validation loss: 2.1757989873488746

Epoch: 355| Step: 0
Training loss: 1.9296875
Validation loss: 2.164129992326101

Epoch: 5| Step: 1
Training loss: 1.3757587671279907
Validation loss: 2.1969977021217346

Epoch: 5| Step: 2
Training loss: 2.0228354930877686
Validation loss: 2.1237180878718696

Epoch: 5| Step: 3
Training loss: 0.9460124969482422
Validation loss: 2.1509214341640472

Epoch: 5| Step: 4
Training loss: 0.9629697799682617
Validation loss: 2.141329045097033

Epoch: 5| Step: 5
Training loss: 1.3796064853668213
Validation loss: 2.1620463728904724

Epoch: 5| Step: 6
Training loss: 1.5309282541275024
Validation loss: 2.1624687910079956

Epoch: 5| Step: 7
Training loss: 0.9271425008773804
Validation loss: 2.1795471956332526

Epoch: 5| Step: 8
Training loss: 1.0925719738006592
Validation loss: 2.12778107325236

Epoch: 5| Step: 9
Training loss: 1.0815613269805908
Validation loss: 2.1760632395744324

Epoch: 5| Step: 10
Training loss: 1.2452059984207153
Validation loss: 2.145853658517202

Epoch: 5| Step: 11
Training loss: 1.7466185092926025
Validation loss: 2.148774335781733

Epoch: 356| Step: 0
Training loss: 1.0362346172332764
Validation loss: 2.1129022190968194

Epoch: 5| Step: 1
Training loss: 1.2721545696258545
Validation loss: 2.172092611591021

Epoch: 5| Step: 2
Training loss: 0.5709527730941772
Validation loss: 2.1803175061941147

Epoch: 5| Step: 3
Training loss: 1.1598358154296875
Validation loss: 2.162037248412768

Epoch: 5| Step: 4
Training loss: 1.1446807384490967
Validation loss: 2.154163181781769

Epoch: 5| Step: 5
Training loss: 1.2917001247406006
Validation loss: 2.149335741996765

Epoch: 5| Step: 6
Training loss: 1.0473283529281616
Validation loss: 2.2188505431016288

Epoch: 5| Step: 7
Training loss: 1.416069746017456
Validation loss: 2.2419117242097855

Epoch: 5| Step: 8
Training loss: 1.7115886211395264
Validation loss: 2.2013154725233712

Epoch: 5| Step: 9
Training loss: 1.8040153980255127
Validation loss: 2.2692478597164154

Epoch: 5| Step: 10
Training loss: 0.9773356318473816
Validation loss: 2.220277880628904

Epoch: 5| Step: 11
Training loss: 0.8707883358001709
Validation loss: 2.2319712738196054

Epoch: 357| Step: 0
Training loss: 1.4913746118545532
Validation loss: 2.246336122353872

Epoch: 5| Step: 1
Training loss: 0.8983670473098755
Validation loss: 2.2614125510056815

Epoch: 5| Step: 2
Training loss: 2.000659942626953
Validation loss: 2.240675856669744

Epoch: 5| Step: 3
Training loss: 1.3628555536270142
Validation loss: 2.2067364851633706

Epoch: 5| Step: 4
Training loss: 1.3479677438735962
Validation loss: 2.2562450071175895

Epoch: 5| Step: 5
Training loss: 1.2164289951324463
Validation loss: 2.221888313690821

Epoch: 5| Step: 6
Training loss: 0.9679969549179077
Validation loss: 2.201388339201609

Epoch: 5| Step: 7
Training loss: 0.7769049406051636
Validation loss: 2.205776502688726

Epoch: 5| Step: 8
Training loss: 0.8196040391921997
Validation loss: 2.214646806319555

Epoch: 5| Step: 9
Training loss: 1.2054895162582397
Validation loss: 2.195392295718193

Epoch: 5| Step: 10
Training loss: 0.9382905960083008
Validation loss: 2.2001881847778955

Epoch: 5| Step: 11
Training loss: 0.4616570472717285
Validation loss: 2.177900637189547

Epoch: 358| Step: 0
Training loss: 1.729214072227478
Validation loss: 2.1371224323908486

Epoch: 5| Step: 1
Training loss: 1.1824958324432373
Validation loss: 2.1564238170782724

Epoch: 5| Step: 2
Training loss: 0.7284058332443237
Validation loss: 2.1987870136896768

Epoch: 5| Step: 3
Training loss: 1.5730680227279663
Validation loss: 2.158795863389969

Epoch: 5| Step: 4
Training loss: 1.105675220489502
Validation loss: 2.15949310362339

Epoch: 5| Step: 5
Training loss: 0.671439528465271
Validation loss: 2.132915109395981

Epoch: 5| Step: 6
Training loss: 0.883922278881073
Validation loss: 2.1656193335851035

Epoch: 5| Step: 7
Training loss: 1.3057204484939575
Validation loss: 2.1874480644861856

Epoch: 5| Step: 8
Training loss: 1.1128286123275757
Validation loss: 2.182087928056717

Epoch: 5| Step: 9
Training loss: 0.7538694143295288
Validation loss: 2.17396088441213

Epoch: 5| Step: 10
Training loss: 1.6707899570465088
Validation loss: 2.209632992744446

Epoch: 5| Step: 11
Training loss: 0.8040050864219666
Validation loss: 2.2269469996293387

Epoch: 359| Step: 0
Training loss: 1.139350175857544
Validation loss: 2.27286326388518

Epoch: 5| Step: 1
Training loss: 1.2186799049377441
Validation loss: 2.2467015087604523

Epoch: 5| Step: 2
Training loss: 0.9950224757194519
Validation loss: 2.2267680565516152

Epoch: 5| Step: 3
Training loss: 1.8095461130142212
Validation loss: 2.246033529440562

Epoch: 5| Step: 4
Training loss: 1.1342859268188477
Validation loss: 2.207694242397944

Epoch: 5| Step: 5
Training loss: 0.9919446706771851
Validation loss: 2.258238563934962

Epoch: 5| Step: 6
Training loss: 0.6239652633666992
Validation loss: 2.2427130540211997

Epoch: 5| Step: 7
Training loss: 1.2130012512207031
Validation loss: 2.216058164834976

Epoch: 5| Step: 8
Training loss: 0.9810792207717896
Validation loss: 2.187661146124204

Epoch: 5| Step: 9
Training loss: 1.2351568937301636
Validation loss: 2.2041780600945153

Epoch: 5| Step: 10
Training loss: 1.0329527854919434
Validation loss: 2.1582068353891373

Epoch: 5| Step: 11
Training loss: 3.07912015914917
Validation loss: 2.1809665858745575

Epoch: 360| Step: 0
Training loss: 1.4865028858184814
Validation loss: 2.216104671359062

Epoch: 5| Step: 1
Training loss: 1.1367542743682861
Validation loss: 2.2321193516254425

Epoch: 5| Step: 2
Training loss: 1.2675586938858032
Validation loss: 2.2317714393138885

Epoch: 5| Step: 3
Training loss: 1.4364465475082397
Validation loss: 2.2459884534279504

Epoch: 5| Step: 4
Training loss: 0.9559768438339233
Validation loss: 2.280030369758606

Epoch: 5| Step: 5
Training loss: 1.2730382680892944
Validation loss: 2.2946146726608276

Epoch: 5| Step: 6
Training loss: 0.780786395072937
Validation loss: 2.2608439226945243

Epoch: 5| Step: 7
Training loss: 0.8990821838378906
Validation loss: 2.25242817401886

Epoch: 5| Step: 8
Training loss: 1.2214105129241943
Validation loss: 2.27178555727005

Epoch: 5| Step: 9
Training loss: 0.8853192329406738
Validation loss: 2.2451657255490622

Epoch: 5| Step: 10
Training loss: 1.2229582071304321
Validation loss: 2.2172776559988656

Epoch: 5| Step: 11
Training loss: 2.398622989654541
Validation loss: 2.2399469216664634

Epoch: 361| Step: 0
Training loss: 1.1554276943206787
Validation loss: 2.23759455482165

Epoch: 5| Step: 1
Training loss: 1.2913974523544312
Validation loss: 2.1942866245905557

Epoch: 5| Step: 2
Training loss: 1.3116995096206665
Validation loss: 2.2248932470877967

Epoch: 5| Step: 3
Training loss: 1.4460417032241821
Validation loss: 2.2082873781522117

Epoch: 5| Step: 4
Training loss: 0.7841120362281799
Validation loss: 2.248592272400856

Epoch: 5| Step: 5
Training loss: 0.8593082427978516
Validation loss: 2.2653906693061194

Epoch: 5| Step: 6
Training loss: 0.750771164894104
Validation loss: 2.2294421891371408

Epoch: 5| Step: 7
Training loss: 1.3448528051376343
Validation loss: 2.2452044636011124

Epoch: 5| Step: 8
Training loss: 1.8970365524291992
Validation loss: 2.26722285648187

Epoch: 5| Step: 9
Training loss: 1.0893549919128418
Validation loss: 2.2884742071231208

Epoch: 5| Step: 10
Training loss: 1.011667251586914
Validation loss: 2.283331016699473

Epoch: 5| Step: 11
Training loss: 0.24290567636489868
Validation loss: 2.269222011168798

Epoch: 362| Step: 0
Training loss: 1.2363892793655396
Validation loss: 2.2408403853575387

Epoch: 5| Step: 1
Training loss: 1.5838652849197388
Validation loss: 2.2246734549601874

Epoch: 5| Step: 2
Training loss: 1.450866460800171
Validation loss: 2.23384490609169

Epoch: 5| Step: 3
Training loss: 1.3901194334030151
Validation loss: 2.1817319293816886

Epoch: 5| Step: 4
Training loss: 0.609447717666626
Validation loss: 2.2140570282936096

Epoch: 5| Step: 5
Training loss: 1.554443597793579
Validation loss: 2.246377249558767

Epoch: 5| Step: 6
Training loss: 0.9633725881576538
Validation loss: 2.210612123211225

Epoch: 5| Step: 7
Training loss: 0.9687590599060059
Validation loss: 2.2257502675056458

Epoch: 5| Step: 8
Training loss: 1.4631659984588623
Validation loss: 2.2070025155941644

Epoch: 5| Step: 9
Training loss: 0.7153124213218689
Validation loss: 2.212861796220144

Epoch: 5| Step: 10
Training loss: 1.0387465953826904
Validation loss: 2.269780471920967

Epoch: 5| Step: 11
Training loss: 0.7507688999176025
Validation loss: 2.2632800539334617

Epoch: 363| Step: 0
Training loss: 1.1738536357879639
Validation loss: 2.2416684180498123

Epoch: 5| Step: 1
Training loss: 0.8056548237800598
Validation loss: 2.2587598313887916

Epoch: 5| Step: 2
Training loss: 1.5800052881240845
Validation loss: 2.2505862017472587

Epoch: 5| Step: 3
Training loss: 0.5873241424560547
Validation loss: 2.2401071190834045

Epoch: 5| Step: 4
Training loss: 1.6963636875152588
Validation loss: 2.24270028869311

Epoch: 5| Step: 5
Training loss: 0.8888904452323914
Validation loss: 2.2269383569558463

Epoch: 5| Step: 6
Training loss: 1.6311496496200562
Validation loss: 2.285740221540133

Epoch: 5| Step: 7
Training loss: 1.0544534921646118
Validation loss: 2.2742137710253396

Epoch: 5| Step: 8
Training loss: 1.6309077739715576
Validation loss: 2.312352016568184

Epoch: 5| Step: 9
Training loss: 0.9549892544746399
Validation loss: 2.2334090371926627

Epoch: 5| Step: 10
Training loss: 1.122933268547058
Validation loss: 2.239719753464063

Epoch: 5| Step: 11
Training loss: 0.8939752578735352
Validation loss: 2.2264850735664368

Epoch: 364| Step: 0
Training loss: 1.2163344621658325
Validation loss: 2.2253549794356027

Epoch: 5| Step: 1
Training loss: 1.108864426612854
Validation loss: 2.1919885327418647

Epoch: 5| Step: 2
Training loss: 1.1541023254394531
Validation loss: 2.1910640398661294

Epoch: 5| Step: 3
Training loss: 1.0568606853485107
Validation loss: 2.1870915492375693

Epoch: 5| Step: 4
Training loss: 0.6362283229827881
Validation loss: 2.194758822520574

Epoch: 5| Step: 5
Training loss: 1.1278842687606812
Validation loss: 2.197933316230774

Epoch: 5| Step: 6
Training loss: 1.0978214740753174
Validation loss: 2.20789265135924

Epoch: 5| Step: 7
Training loss: 1.0554994344711304
Validation loss: 2.199118281404177

Epoch: 5| Step: 8
Training loss: 1.3756494522094727
Validation loss: 2.2609826674064

Epoch: 5| Step: 9
Training loss: 1.7660472393035889
Validation loss: 2.183644344409307

Epoch: 5| Step: 10
Training loss: 0.9746410250663757
Validation loss: 2.233362396558126

Epoch: 5| Step: 11
Training loss: 2.355231761932373
Validation loss: 2.221872329711914

Epoch: 365| Step: 0
Training loss: 1.0083506107330322
Validation loss: 2.217095270752907

Epoch: 5| Step: 1
Training loss: 1.0876634120941162
Validation loss: 2.240251744786898

Epoch: 5| Step: 2
Training loss: 0.8521783947944641
Validation loss: 2.2481127182642617

Epoch: 5| Step: 3
Training loss: 1.2119245529174805
Validation loss: 2.270025819540024

Epoch: 5| Step: 4
Training loss: 1.441819667816162
Validation loss: 2.231315160791079

Epoch: 5| Step: 5
Training loss: 1.2567408084869385
Validation loss: 2.2182752092679343

Epoch: 5| Step: 6
Training loss: 1.335049033164978
Validation loss: 2.247592404484749

Epoch: 5| Step: 7
Training loss: 1.3442590236663818
Validation loss: 2.2256269057591758

Epoch: 5| Step: 8
Training loss: 0.9512968063354492
Validation loss: 2.2400341232617698

Epoch: 5| Step: 9
Training loss: 0.9901566505432129
Validation loss: 2.263916169603666

Epoch: 5| Step: 10
Training loss: 1.2443368434906006
Validation loss: 2.2953158020973206

Epoch: 5| Step: 11
Training loss: 0.6508901119232178
Validation loss: 2.2609460949897766

Epoch: 366| Step: 0
Training loss: 0.7873784899711609
Validation loss: 2.252613658706347

Epoch: 5| Step: 1
Training loss: 1.6127986907958984
Validation loss: 2.1906245102485022

Epoch: 5| Step: 2
Training loss: 1.4256155490875244
Validation loss: 2.1966302692890167

Epoch: 5| Step: 3
Training loss: 0.7549432516098022
Validation loss: 2.1732301066319146

Epoch: 5| Step: 4
Training loss: 1.0896615982055664
Validation loss: 2.1665170788764954

Epoch: 5| Step: 5
Training loss: 1.3358473777770996
Validation loss: 2.1848818361759186

Epoch: 5| Step: 6
Training loss: 1.0440633296966553
Validation loss: 2.1727403104305267

Epoch: 5| Step: 7
Training loss: 1.2435206174850464
Validation loss: 2.1921597123146057

Epoch: 5| Step: 8
Training loss: 1.7146211862564087
Validation loss: 2.2252462257941565

Epoch: 5| Step: 9
Training loss: 0.6197701692581177
Validation loss: 2.201617260773977

Epoch: 5| Step: 10
Training loss: 1.219521164894104
Validation loss: 2.2237867365280786

Epoch: 5| Step: 11
Training loss: 0.9315536022186279
Validation loss: 2.208967372775078

Epoch: 367| Step: 0
Training loss: 1.168373942375183
Validation loss: 2.21381838619709

Epoch: 5| Step: 1
Training loss: 0.5840506553649902
Validation loss: 2.210576126972834

Epoch: 5| Step: 2
Training loss: 1.2463198900222778
Validation loss: 2.2561824123064675

Epoch: 5| Step: 3
Training loss: 0.9413993954658508
Validation loss: 2.275743290781975

Epoch: 5| Step: 4
Training loss: 0.8946843147277832
Validation loss: 2.2967845797538757

Epoch: 5| Step: 5
Training loss: 1.7314834594726562
Validation loss: 2.286458750565847

Epoch: 5| Step: 6
Training loss: 0.8305290341377258
Validation loss: 2.2611992061138153

Epoch: 5| Step: 7
Training loss: 1.217513918876648
Validation loss: 2.2832475701967874

Epoch: 5| Step: 8
Training loss: 1.144688606262207
Validation loss: 2.2521860351165137

Epoch: 5| Step: 9
Training loss: 1.8077833652496338
Validation loss: 2.2409774462381997

Epoch: 5| Step: 10
Training loss: 1.2323358058929443
Validation loss: 2.1954824030399323

Epoch: 5| Step: 11
Training loss: 0.508855938911438
Validation loss: 2.2178713977336884

Epoch: 368| Step: 0
Training loss: 1.2287776470184326
Validation loss: 2.210883210102717

Epoch: 5| Step: 1
Training loss: 1.5414602756500244
Validation loss: 2.1986642678578696

Epoch: 5| Step: 2
Training loss: 0.8288412094116211
Validation loss: 2.2188724676767984

Epoch: 5| Step: 3
Training loss: 1.25376558303833
Validation loss: 2.214769015709559

Epoch: 5| Step: 4
Training loss: 1.2776161432266235
Validation loss: 2.198212837179502

Epoch: 5| Step: 5
Training loss: 1.449331521987915
Validation loss: 2.2111389140288034

Epoch: 5| Step: 6
Training loss: 1.035531997680664
Validation loss: 2.187094231446584

Epoch: 5| Step: 7
Training loss: 1.174194574356079
Validation loss: 2.1729028820991516

Epoch: 5| Step: 8
Training loss: 1.1967370510101318
Validation loss: 2.1740696926911673

Epoch: 5| Step: 9
Training loss: 1.2178421020507812
Validation loss: 2.1943127661943436

Epoch: 5| Step: 10
Training loss: 1.284062147140503
Validation loss: 2.228563964366913

Epoch: 5| Step: 11
Training loss: 2.5410385131835938
Validation loss: 2.203557103872299

Epoch: 369| Step: 0
Training loss: 1.1790473461151123
Validation loss: 2.1969249546527863

Epoch: 5| Step: 1
Training loss: 1.3720474243164062
Validation loss: 2.2365682125091553

Epoch: 5| Step: 2
Training loss: 1.1269335746765137
Validation loss: 2.151190608739853

Epoch: 5| Step: 3
Training loss: 1.2784693241119385
Validation loss: 2.170438359181086

Epoch: 5| Step: 4
Training loss: 1.5159465074539185
Validation loss: 2.2039420704046884

Epoch: 5| Step: 5
Training loss: 1.2460453510284424
Validation loss: 2.206333667039871

Epoch: 5| Step: 6
Training loss: 1.0432989597320557
Validation loss: 2.159638692935308

Epoch: 5| Step: 7
Training loss: 1.3506686687469482
Validation loss: 2.1857840518156686

Epoch: 5| Step: 8
Training loss: 1.3586891889572144
Validation loss: 2.2130067050457

Epoch: 5| Step: 9
Training loss: 1.2957572937011719
Validation loss: 2.1832106361786523

Epoch: 5| Step: 10
Training loss: 1.37644624710083
Validation loss: 2.2055639723936715

Epoch: 5| Step: 11
Training loss: 1.9260938167572021
Validation loss: 2.2344782650470734

Epoch: 370| Step: 0
Training loss: 1.5903706550598145
Validation loss: 2.2489300270875296

Epoch: 5| Step: 1
Training loss: 0.7628422379493713
Validation loss: 2.321112165848414

Epoch: 5| Step: 2
Training loss: 1.7807753086090088
Validation loss: 2.3093428760766983

Epoch: 5| Step: 3
Training loss: 2.126938819885254
Validation loss: 2.3845686515172324

Epoch: 5| Step: 4
Training loss: 1.2994487285614014
Validation loss: 2.353311081727346

Epoch: 5| Step: 5
Training loss: 1.789756178855896
Validation loss: 2.395638177792231

Epoch: 5| Step: 6
Training loss: 1.268817663192749
Validation loss: 2.366932521263758

Epoch: 5| Step: 7
Training loss: 0.9242000579833984
Validation loss: 2.297925651073456

Epoch: 5| Step: 8
Training loss: 1.2000449895858765
Validation loss: 2.1669512589772544

Epoch: 5| Step: 9
Training loss: 1.0426191091537476
Validation loss: 2.1957050959269204

Epoch: 5| Step: 10
Training loss: 1.0920078754425049
Validation loss: 2.1900193095207214

Epoch: 5| Step: 11
Training loss: 1.0028231143951416
Validation loss: 2.1893317898114524

Epoch: 371| Step: 0
Training loss: 0.9589449167251587
Validation loss: 2.201119581858317

Epoch: 5| Step: 1
Training loss: 1.1147825717926025
Validation loss: 2.1795056462287903

Epoch: 5| Step: 2
Training loss: 1.3208239078521729
Validation loss: 2.197003647685051

Epoch: 5| Step: 3
Training loss: 0.9713050723075867
Validation loss: 2.212647115190824

Epoch: 5| Step: 4
Training loss: 1.168733835220337
Validation loss: 2.1986599365870156

Epoch: 5| Step: 5
Training loss: 1.139384388923645
Validation loss: 2.212699383497238

Epoch: 5| Step: 6
Training loss: 1.5831339359283447
Validation loss: 2.2569212218125663

Epoch: 5| Step: 7
Training loss: 1.5304040908813477
Validation loss: 2.242044677337011

Epoch: 5| Step: 8
Training loss: 1.0837829113006592
Validation loss: 2.2304043720165887

Epoch: 5| Step: 9
Training loss: 1.0360405445098877
Validation loss: 2.205145647128423

Epoch: 5| Step: 10
Training loss: 1.0720221996307373
Validation loss: 2.235719546675682

Epoch: 5| Step: 11
Training loss: 1.1275116205215454
Validation loss: 2.229963223139445

Epoch: 372| Step: 0
Training loss: 1.237107515335083
Validation loss: 2.2349036981662116

Epoch: 5| Step: 1
Training loss: 0.6224733591079712
Validation loss: 2.2695487439632416

Epoch: 5| Step: 2
Training loss: 1.1120930910110474
Validation loss: 2.26546103755633

Epoch: 5| Step: 3
Training loss: 1.4084303379058838
Validation loss: 2.31010569135348

Epoch: 5| Step: 4
Training loss: 0.8743426203727722
Validation loss: 2.2669576555490494

Epoch: 5| Step: 5
Training loss: 0.7849546074867249
Validation loss: 2.272957215706507

Epoch: 5| Step: 6
Training loss: 1.9242208003997803
Validation loss: 2.2996345261732736

Epoch: 5| Step: 7
Training loss: 1.243446707725525
Validation loss: 2.270292341709137

Epoch: 5| Step: 8
Training loss: 1.278832197189331
Validation loss: 2.2590895295143127

Epoch: 5| Step: 9
Training loss: 0.775174617767334
Validation loss: 2.259501338005066

Epoch: 5| Step: 10
Training loss: 1.2044581174850464
Validation loss: 2.2551117489735284

Epoch: 5| Step: 11
Training loss: 0.32598596811294556
Validation loss: 2.246671050786972

Epoch: 373| Step: 0
Training loss: 0.940652072429657
Validation loss: 2.26491250594457

Epoch: 5| Step: 1
Training loss: 1.1966661214828491
Validation loss: 2.21690704425176

Epoch: 5| Step: 2
Training loss: 0.6847481727600098
Validation loss: 2.2539484798908234

Epoch: 5| Step: 3
Training loss: 0.9374022483825684
Validation loss: 2.24878100057443

Epoch: 5| Step: 4
Training loss: 1.4498045444488525
Validation loss: 2.2101365427176156

Epoch: 5| Step: 5
Training loss: 0.9410454630851746
Validation loss: 2.231387416521708

Epoch: 5| Step: 6
Training loss: 2.066093921661377
Validation loss: 2.2543006042639413

Epoch: 5| Step: 7
Training loss: 1.215188980102539
Validation loss: 2.2504340410232544

Epoch: 5| Step: 8
Training loss: 1.5202579498291016
Validation loss: 2.2369810342788696

Epoch: 5| Step: 9
Training loss: 0.8392407298088074
Validation loss: 2.240507036447525

Epoch: 5| Step: 10
Training loss: 1.2238727807998657
Validation loss: 2.2320903489987054

Epoch: 5| Step: 11
Training loss: 0.7324559092521667
Validation loss: 2.2575056900580726

Epoch: 374| Step: 0
Training loss: 1.0146422386169434
Validation loss: 2.2810189525286355

Epoch: 5| Step: 1
Training loss: 1.2038674354553223
Validation loss: 2.2694996198018393

Epoch: 5| Step: 2
Training loss: 1.3466519117355347
Validation loss: 2.2887336959441504

Epoch: 5| Step: 3
Training loss: 1.6239303350448608
Validation loss: 2.3054424772659936

Epoch: 5| Step: 4
Training loss: 1.1155070066452026
Validation loss: 2.2821245590845742

Epoch: 5| Step: 5
Training loss: 0.9799224138259888
Validation loss: 2.2909919569889703

Epoch: 5| Step: 6
Training loss: 0.8289400935173035
Validation loss: 2.2532483637332916

Epoch: 5| Step: 7
Training loss: 0.8788402676582336
Validation loss: 2.284236177802086

Epoch: 5| Step: 8
Training loss: 0.7789465188980103
Validation loss: 2.2522099961837134

Epoch: 5| Step: 9
Training loss: 1.1561812162399292
Validation loss: 2.1950673361619315

Epoch: 5| Step: 10
Training loss: 1.0196335315704346
Validation loss: 2.177617053190867

Epoch: 5| Step: 11
Training loss: 0.7560539245605469
Validation loss: 2.2097389151652655

Epoch: 375| Step: 0
Training loss: 1.140490174293518
Validation loss: 2.1729523738225303

Epoch: 5| Step: 1
Training loss: 1.1413761377334595
Validation loss: 2.1715842137734094

Epoch: 5| Step: 2
Training loss: 1.1851391792297363
Validation loss: 2.175753280520439

Epoch: 5| Step: 3
Training loss: 1.3829829692840576
Validation loss: 2.1845896939436593

Epoch: 5| Step: 4
Training loss: 1.3206934928894043
Validation loss: 2.2326227327187858

Epoch: 5| Step: 5
Training loss: 1.2387670278549194
Validation loss: 2.2001580397288003

Epoch: 5| Step: 6
Training loss: 0.8157659769058228
Validation loss: 2.1957839727401733

Epoch: 5| Step: 7
Training loss: 0.9782705307006836
Validation loss: 2.224803219238917

Epoch: 5| Step: 8
Training loss: 1.11962890625
Validation loss: 2.200676823655764

Epoch: 5| Step: 9
Training loss: 1.1374595165252686
Validation loss: 2.2150425414244332

Epoch: 5| Step: 10
Training loss: 0.8976390957832336
Validation loss: 2.242151290178299

Epoch: 5| Step: 11
Training loss: 0.5095345377922058
Validation loss: 2.239286720752716

Epoch: 376| Step: 0
Training loss: 1.3341169357299805
Validation loss: 2.1855516533056893

Epoch: 5| Step: 1
Training loss: 0.898093581199646
Validation loss: 2.191040133436521

Epoch: 5| Step: 2
Training loss: 1.2415692806243896
Validation loss: 2.1924778521060944

Epoch: 5| Step: 3
Training loss: 1.247368574142456
Validation loss: 2.1650039156277976

Epoch: 5| Step: 4
Training loss: 1.178107738494873
Validation loss: 2.2001474102338157

Epoch: 5| Step: 5
Training loss: 0.9256446957588196
Validation loss: 2.1513072699308395

Epoch: 5| Step: 6
Training loss: 1.1115810871124268
Validation loss: 2.2222570379575095

Epoch: 5| Step: 7
Training loss: 0.9480045437812805
Validation loss: 2.1394724349180856

Epoch: 5| Step: 8
Training loss: 0.8666326403617859
Validation loss: 2.231692443291346

Epoch: 5| Step: 9
Training loss: 1.039025068283081
Validation loss: 2.2142973442872367

Epoch: 5| Step: 10
Training loss: 1.1556226015090942
Validation loss: 2.2398313085238137

Epoch: 5| Step: 11
Training loss: 1.2231240272521973
Validation loss: 2.2477848529815674

Epoch: 377| Step: 0
Training loss: 1.133188009262085
Validation loss: 2.2900714625914893

Epoch: 5| Step: 1
Training loss: 1.2735456228256226
Validation loss: 2.3063753495613732

Epoch: 5| Step: 2
Training loss: 1.4353262186050415
Validation loss: 2.3109367142120996

Epoch: 5| Step: 3
Training loss: 0.7840827107429504
Validation loss: 2.316431944568952

Epoch: 5| Step: 4
Training loss: 1.087852120399475
Validation loss: 2.325904071331024

Epoch: 5| Step: 5
Training loss: 0.9950803518295288
Validation loss: 2.31477556626002

Epoch: 5| Step: 6
Training loss: 1.0627880096435547
Validation loss: 2.291436403989792

Epoch: 5| Step: 7
Training loss: 1.9018974304199219
Validation loss: 2.35419629017512

Epoch: 5| Step: 8
Training loss: 0.8300382494926453
Validation loss: 2.2999857465426126

Epoch: 5| Step: 9
Training loss: 1.119842290878296
Validation loss: 2.3386029799779258

Epoch: 5| Step: 10
Training loss: 0.9229933023452759
Validation loss: 2.304050480326017

Epoch: 5| Step: 11
Training loss: 0.552193284034729
Validation loss: 2.3289778331915536

Epoch: 378| Step: 0
Training loss: 0.9439747929573059
Validation loss: 2.304399554928144

Epoch: 5| Step: 1
Training loss: 1.0242993831634521
Validation loss: 2.2662278711795807

Epoch: 5| Step: 2
Training loss: 1.3722175359725952
Validation loss: 2.227039019266764

Epoch: 5| Step: 3
Training loss: 0.8857189416885376
Validation loss: 2.2137375275293985

Epoch: 5| Step: 4
Training loss: 1.6105817556381226
Validation loss: 2.215448091427485

Epoch: 5| Step: 5
Training loss: 1.027687668800354
Validation loss: 2.2308826545874276

Epoch: 5| Step: 6
Training loss: 1.03916597366333
Validation loss: 2.1912852873404822

Epoch: 5| Step: 7
Training loss: 0.6654728055000305
Validation loss: 2.208484257260958

Epoch: 5| Step: 8
Training loss: 1.3129712343215942
Validation loss: 2.2135748068491616

Epoch: 5| Step: 9
Training loss: 1.2833527326583862
Validation loss: 2.2261078159014382

Epoch: 5| Step: 10
Training loss: 1.375528335571289
Validation loss: 2.1995843400557837

Epoch: 5| Step: 11
Training loss: 0.7220223546028137
Validation loss: 2.2253632297118506

Epoch: 379| Step: 0
Training loss: 1.044189214706421
Validation loss: 2.243300199508667

Epoch: 5| Step: 1
Training loss: 1.0313479900360107
Validation loss: 2.2549950877825418

Epoch: 5| Step: 2
Training loss: 1.4727802276611328
Validation loss: 2.265353719393412

Epoch: 5| Step: 3
Training loss: 1.3517816066741943
Validation loss: 2.2435287833213806

Epoch: 5| Step: 4
Training loss: 1.3918590545654297
Validation loss: 2.250843197107315

Epoch: 5| Step: 5
Training loss: 1.2821214199066162
Validation loss: 2.220611204703649

Epoch: 5| Step: 6
Training loss: 0.9380658268928528
Validation loss: 2.2251051565011344

Epoch: 5| Step: 7
Training loss: 0.9267215728759766
Validation loss: 2.2443684240182242

Epoch: 5| Step: 8
Training loss: 1.1295419931411743
Validation loss: 2.233904182910919

Epoch: 5| Step: 9
Training loss: 1.0519258975982666
Validation loss: 2.204387456178665

Epoch: 5| Step: 10
Training loss: 0.8257803916931152
Validation loss: 2.254031404852867

Epoch: 5| Step: 11
Training loss: 2.151461601257324
Validation loss: 2.241706594824791

Epoch: 380| Step: 0
Training loss: 1.1197178363800049
Validation loss: 2.1793083250522614

Epoch: 5| Step: 1
Training loss: 1.3983272314071655
Validation loss: 2.2140237291653952

Epoch: 5| Step: 2
Training loss: 1.2554744482040405
Validation loss: 2.2031541963418326

Epoch: 5| Step: 3
Training loss: 0.6513211727142334
Validation loss: 2.183581163485845

Epoch: 5| Step: 4
Training loss: 0.793946385383606
Validation loss: 2.174982875585556

Epoch: 5| Step: 5
Training loss: 0.8422477841377258
Validation loss: 2.1391678551832833

Epoch: 5| Step: 6
Training loss: 1.1372253894805908
Validation loss: 2.1492200593153634

Epoch: 5| Step: 7
Training loss: 0.42375603318214417
Validation loss: 2.1552197337150574

Epoch: 5| Step: 8
Training loss: 1.2286803722381592
Validation loss: 2.1727104087670646

Epoch: 5| Step: 9
Training loss: 0.8823190927505493
Validation loss: 2.1183189948399863

Epoch: 5| Step: 10
Training loss: 1.8219034671783447
Validation loss: 2.1759229749441147

Epoch: 5| Step: 11
Training loss: 3.9144961833953857
Validation loss: 2.1270122975111008

Epoch: 381| Step: 0
Training loss: 0.9975641965866089
Validation loss: 2.1710517356793084

Epoch: 5| Step: 1
Training loss: 0.9529679417610168
Validation loss: 2.204452176888784

Epoch: 5| Step: 2
Training loss: 0.865306556224823
Validation loss: 2.1995611091454825

Epoch: 5| Step: 3
Training loss: 2.004845380783081
Validation loss: 2.180910254518191

Epoch: 5| Step: 4
Training loss: 0.5889593362808228
Validation loss: 2.1981172959009805

Epoch: 5| Step: 5
Training loss: 1.125140905380249
Validation loss: 2.203653931617737

Epoch: 5| Step: 6
Training loss: 0.9514064788818359
Validation loss: 2.2142551094293594

Epoch: 5| Step: 7
Training loss: 0.842758059501648
Validation loss: 2.1687340388695397

Epoch: 5| Step: 8
Training loss: 1.1063597202301025
Validation loss: 2.204888621966044

Epoch: 5| Step: 9
Training loss: 1.1084773540496826
Validation loss: 2.185188427567482

Epoch: 5| Step: 10
Training loss: 1.0721609592437744
Validation loss: 2.2061862697203956

Epoch: 5| Step: 11
Training loss: 0.4294031262397766
Validation loss: 2.180280551314354

Epoch: 382| Step: 0
Training loss: 1.536824345588684
Validation loss: 2.2126442790031433

Epoch: 5| Step: 1
Training loss: 0.8836145401000977
Validation loss: 2.1955671260754266

Epoch: 5| Step: 2
Training loss: 0.9947975277900696
Validation loss: 2.2203969955444336

Epoch: 5| Step: 3
Training loss: 1.3111822605133057
Validation loss: 2.147694781422615

Epoch: 5| Step: 4
Training loss: 1.8864027261734009
Validation loss: 2.197508076826731

Epoch: 5| Step: 5
Training loss: 0.9157726168632507
Validation loss: 2.2182446320851645

Epoch: 5| Step: 6
Training loss: 0.9673923254013062
Validation loss: 2.166160727540652

Epoch: 5| Step: 7
Training loss: 0.6147476434707642
Validation loss: 2.1743080019950867

Epoch: 5| Step: 8
Training loss: 1.0801597833633423
Validation loss: 2.21403369307518

Epoch: 5| Step: 9
Training loss: 0.9550286531448364
Validation loss: 2.2367159128189087

Epoch: 5| Step: 10
Training loss: 0.9720741510391235
Validation loss: 2.204914261897405

Epoch: 5| Step: 11
Training loss: 0.22154486179351807
Validation loss: 2.2000621259212494

Epoch: 383| Step: 0
Training loss: 0.7248638868331909
Validation loss: 2.2304460604985556

Epoch: 5| Step: 1
Training loss: 1.4441086053848267
Validation loss: 2.1656369169553122

Epoch: 5| Step: 2
Training loss: 0.9749306440353394
Validation loss: 2.234534978866577

Epoch: 5| Step: 3
Training loss: 0.8994506001472473
Validation loss: 2.2258848547935486

Epoch: 5| Step: 4
Training loss: 1.6998138427734375
Validation loss: 2.180139551560084

Epoch: 5| Step: 5
Training loss: 1.041473627090454
Validation loss: 2.2076977292696633

Epoch: 5| Step: 6
Training loss: 0.9400817155838013
Validation loss: 2.2183400094509125

Epoch: 5| Step: 7
Training loss: 0.8079546093940735
Validation loss: 2.201673239469528

Epoch: 5| Step: 8
Training loss: 0.7462453246116638
Validation loss: 2.221558084090551

Epoch: 5| Step: 9
Training loss: 0.9765116572380066
Validation loss: 2.2141022086143494

Epoch: 5| Step: 10
Training loss: 1.0010136365890503
Validation loss: 2.2535885820786157

Epoch: 5| Step: 11
Training loss: 1.9397634267807007
Validation loss: 2.2459648052851358

Epoch: 384| Step: 0
Training loss: 0.4367651343345642
Validation loss: 2.246892273426056

Epoch: 5| Step: 1
Training loss: 1.6035350561141968
Validation loss: 2.231965551773707

Epoch: 5| Step: 2
Training loss: 1.5297905206680298
Validation loss: 2.2244843095541

Epoch: 5| Step: 3
Training loss: 1.4083774089813232
Validation loss: 2.222796012957891

Epoch: 5| Step: 4
Training loss: 0.9980789422988892
Validation loss: 2.2167784670988717

Epoch: 5| Step: 5
Training loss: 0.9412168264389038
Validation loss: 2.2283712873856225

Epoch: 5| Step: 6
Training loss: 0.9633769989013672
Validation loss: 2.2160393794377646

Epoch: 5| Step: 7
Training loss: 0.9536029696464539
Validation loss: 2.15950479110082

Epoch: 5| Step: 8
Training loss: 0.8810012936592102
Validation loss: 2.2136788765589395

Epoch: 5| Step: 9
Training loss: 0.7014416456222534
Validation loss: 2.1911239326000214

Epoch: 5| Step: 10
Training loss: 0.9597864151000977
Validation loss: 2.2002856135368347

Epoch: 5| Step: 11
Training loss: 1.0018303394317627
Validation loss: 2.1912718613942466

Epoch: 385| Step: 0
Training loss: 0.8624717593193054
Validation loss: 2.1480698585510254

Epoch: 5| Step: 1
Training loss: 1.6097991466522217
Validation loss: 2.187041327357292

Epoch: 5| Step: 2
Training loss: 1.0936644077301025
Validation loss: 2.1860074947277703

Epoch: 5| Step: 3
Training loss: 0.756518542766571
Validation loss: 2.2471944938103356

Epoch: 5| Step: 4
Training loss: 0.7332075834274292
Validation loss: 2.1611297031243644

Epoch: 5| Step: 5
Training loss: 0.8361037969589233
Validation loss: 2.1864715218544006

Epoch: 5| Step: 6
Training loss: 0.6565185189247131
Validation loss: 2.188658078511556

Epoch: 5| Step: 7
Training loss: 1.129510521888733
Validation loss: 2.2335777084032693

Epoch: 5| Step: 8
Training loss: 1.2953343391418457
Validation loss: 2.2329869916041694

Epoch: 5| Step: 9
Training loss: 0.8858290910720825
Validation loss: 2.239585002263387

Epoch: 5| Step: 10
Training loss: 1.01936936378479
Validation loss: 2.275414248307546

Epoch: 5| Step: 11
Training loss: 1.6489254236221313
Validation loss: 2.229450434446335

Epoch: 386| Step: 0
Training loss: 0.9183151125907898
Validation loss: 2.221202274163564

Epoch: 5| Step: 1
Training loss: 1.0019742250442505
Validation loss: 2.208222677310308

Epoch: 5| Step: 2
Training loss: 1.017187237739563
Validation loss: 2.223213165998459

Epoch: 5| Step: 3
Training loss: 1.0299296379089355
Validation loss: 2.2160101930300393

Epoch: 5| Step: 4
Training loss: 1.1553571224212646
Validation loss: 2.200430855154991

Epoch: 5| Step: 5
Training loss: 1.005340814590454
Validation loss: 2.213956062992414

Epoch: 5| Step: 6
Training loss: 0.8026255369186401
Validation loss: 2.1820388436317444

Epoch: 5| Step: 7
Training loss: 1.3736889362335205
Validation loss: 2.2499246895313263

Epoch: 5| Step: 8
Training loss: 1.2241290807724
Validation loss: 2.23873969912529

Epoch: 5| Step: 9
Training loss: 0.7085493803024292
Validation loss: 2.245420530438423

Epoch: 5| Step: 10
Training loss: 0.9108810424804688
Validation loss: 2.2194016675154367

Epoch: 5| Step: 11
Training loss: 0.6664150953292847
Validation loss: 2.2327802181243896

Epoch: 387| Step: 0
Training loss: 1.4814844131469727
Validation loss: 2.2358239392439523

Epoch: 5| Step: 1
Training loss: 0.9550067782402039
Validation loss: 2.2494109074274697

Epoch: 5| Step: 2
Training loss: 1.554236650466919
Validation loss: 2.2346471548080444

Epoch: 5| Step: 3
Training loss: 1.3711729049682617
Validation loss: 2.263147860765457

Epoch: 5| Step: 4
Training loss: 1.022641897201538
Validation loss: 2.1976457834243774

Epoch: 5| Step: 5
Training loss: 1.063988208770752
Validation loss: 2.2168218195438385

Epoch: 5| Step: 6
Training loss: 1.1690219640731812
Validation loss: 2.240042418241501

Epoch: 5| Step: 7
Training loss: 0.7068623304367065
Validation loss: 2.218194325764974

Epoch: 5| Step: 8
Training loss: 0.6905239820480347
Validation loss: 2.2283849517504373

Epoch: 5| Step: 9
Training loss: 0.9551194310188293
Validation loss: 2.2597256898880005

Epoch: 5| Step: 10
Training loss: 0.669319748878479
Validation loss: 2.2350557843844094

Epoch: 5| Step: 11
Training loss: 1.04573655128479
Validation loss: 2.266648918390274

Epoch: 388| Step: 0
Training loss: 1.1591264009475708
Validation loss: 2.250681142012278

Epoch: 5| Step: 1
Training loss: 0.7650039792060852
Validation loss: 2.224729130665461

Epoch: 5| Step: 2
Training loss: 0.9535061717033386
Validation loss: 2.2215410570303598

Epoch: 5| Step: 3
Training loss: 0.9882500767707825
Validation loss: 2.2552302877108255

Epoch: 5| Step: 4
Training loss: 1.2550528049468994
Validation loss: 2.261219004789988

Epoch: 5| Step: 5
Training loss: 1.1926603317260742
Validation loss: 2.2220641672611237

Epoch: 5| Step: 6
Training loss: 0.9717143774032593
Validation loss: 2.251893937587738

Epoch: 5| Step: 7
Training loss: 0.9540098309516907
Validation loss: 2.225935618082682

Epoch: 5| Step: 8
Training loss: 1.054413914680481
Validation loss: 2.2641664346059165

Epoch: 5| Step: 9
Training loss: 1.2236064672470093
Validation loss: 2.2493717769781747

Epoch: 5| Step: 10
Training loss: 0.8221489191055298
Validation loss: 2.23452057937781

Epoch: 5| Step: 11
Training loss: 1.4781275987625122
Validation loss: 2.2820903062820435

Epoch: 389| Step: 0
Training loss: 0.777449905872345
Validation loss: 2.2278241316477456

Epoch: 5| Step: 1
Training loss: 1.4259326457977295
Validation loss: 2.202094500263532

Epoch: 5| Step: 2
Training loss: 0.9797088503837585
Validation loss: 2.2417386571566262

Epoch: 5| Step: 3
Training loss: 1.288905382156372
Validation loss: 2.194799840450287

Epoch: 5| Step: 4
Training loss: 0.8253313302993774
Validation loss: 2.2022538781166077

Epoch: 5| Step: 5
Training loss: 1.144261121749878
Validation loss: 2.1819225202004113

Epoch: 5| Step: 6
Training loss: 0.6586737632751465
Validation loss: 2.2089947859446206

Epoch: 5| Step: 7
Training loss: 1.0946786403656006
Validation loss: 2.2021196633577347

Epoch: 5| Step: 8
Training loss: 0.6395100355148315
Validation loss: 2.213017458717028

Epoch: 5| Step: 9
Training loss: 1.6278126239776611
Validation loss: 2.1801013747851052

Epoch: 5| Step: 10
Training loss: 0.7404778003692627
Validation loss: 2.220583289861679

Epoch: 5| Step: 11
Training loss: 0.5924578309059143
Validation loss: 2.2303493370612464

Epoch: 390| Step: 0
Training loss: 0.6591783761978149
Validation loss: 2.1955168545246124

Epoch: 5| Step: 1
Training loss: 1.034225344657898
Validation loss: 2.2421200474103293

Epoch: 5| Step: 2
Training loss: 0.5614444613456726
Validation loss: 2.2072279254595437

Epoch: 5| Step: 3
Training loss: 0.9711679220199585
Validation loss: 2.2353152682383857

Epoch: 5| Step: 4
Training loss: 1.153533697128296
Validation loss: 2.237961024045944

Epoch: 5| Step: 5
Training loss: 1.0660943984985352
Validation loss: 2.2267235865195594

Epoch: 5| Step: 6
Training loss: 1.6039941310882568
Validation loss: 2.2223910639683404

Epoch: 5| Step: 7
Training loss: 0.9378955960273743
Validation loss: 2.17200834552447

Epoch: 5| Step: 8
Training loss: 0.6966418027877808
Validation loss: 2.1728861977656684

Epoch: 5| Step: 9
Training loss: 1.193777084350586
Validation loss: 2.178182731072108

Epoch: 5| Step: 10
Training loss: 1.3082770109176636
Validation loss: 2.1684035807847977

Epoch: 5| Step: 11
Training loss: 0.4370301365852356
Validation loss: 2.1533102840185165

Epoch: 391| Step: 0
Training loss: 0.6986895799636841
Validation loss: 2.214817305405935

Epoch: 5| Step: 1
Training loss: 0.9457643628120422
Validation loss: 2.1994260400533676

Epoch: 5| Step: 2
Training loss: 1.5885934829711914
Validation loss: 2.215864986181259

Epoch: 5| Step: 3
Training loss: 1.4888479709625244
Validation loss: 2.203401133418083

Epoch: 5| Step: 4
Training loss: 0.7299532890319824
Validation loss: 2.210368757446607

Epoch: 5| Step: 5
Training loss: 1.1886708736419678
Validation loss: 2.2385846028725305

Epoch: 5| Step: 6
Training loss: 1.0483715534210205
Validation loss: 2.1953523010015488

Epoch: 5| Step: 7
Training loss: 1.315576195716858
Validation loss: 2.2341856956481934

Epoch: 5| Step: 8
Training loss: 0.8673950433731079
Validation loss: 2.2154791057109833

Epoch: 5| Step: 9
Training loss: 1.1063597202301025
Validation loss: 2.2125620345274606

Epoch: 5| Step: 10
Training loss: 0.7993812561035156
Validation loss: 2.1979581316312156

Epoch: 5| Step: 11
Training loss: 1.1913330554962158
Validation loss: 2.2186168928941092

Epoch: 392| Step: 0
Training loss: 1.0167549848556519
Validation loss: 2.234445944428444

Epoch: 5| Step: 1
Training loss: 1.1469204425811768
Validation loss: 2.21512101093928

Epoch: 5| Step: 2
Training loss: 1.1101009845733643
Validation loss: 2.2310960988203683

Epoch: 5| Step: 3
Training loss: 0.9032645225524902
Validation loss: 2.24495459596316

Epoch: 5| Step: 4
Training loss: 1.3580278158187866
Validation loss: 2.2495464831590652

Epoch: 5| Step: 5
Training loss: 0.8682208061218262
Validation loss: 2.2581017514069877

Epoch: 5| Step: 6
Training loss: 0.804327130317688
Validation loss: 2.23759392897288

Epoch: 5| Step: 7
Training loss: 1.3487892150878906
Validation loss: 2.2296416660149894

Epoch: 5| Step: 8
Training loss: 0.9491317868232727
Validation loss: 2.2413723369439444

Epoch: 5| Step: 9
Training loss: 1.0862095355987549
Validation loss: 2.269121065735817

Epoch: 5| Step: 10
Training loss: 1.0582904815673828
Validation loss: 2.2581986586252847

Epoch: 5| Step: 11
Training loss: 0.47335588932037354
Validation loss: 2.236927941441536

Epoch: 393| Step: 0
Training loss: 0.9870659112930298
Validation loss: 2.2324618101119995

Epoch: 5| Step: 1
Training loss: 1.086907148361206
Validation loss: 2.2134675135215125

Epoch: 5| Step: 2
Training loss: 0.6566888689994812
Validation loss: 2.207122122248014

Epoch: 5| Step: 3
Training loss: 0.8838953971862793
Validation loss: 2.206865365306536

Epoch: 5| Step: 4
Training loss: 1.0770899057388306
Validation loss: 2.2010963012774787

Epoch: 5| Step: 5
Training loss: 0.9591705203056335
Validation loss: 2.225472698609034

Epoch: 5| Step: 6
Training loss: 0.6807832717895508
Validation loss: 2.1475438276926675

Epoch: 5| Step: 7
Training loss: 1.0271272659301758
Validation loss: 2.1957073559363685

Epoch: 5| Step: 8
Training loss: 1.6192528009414673
Validation loss: 2.167414819200834

Epoch: 5| Step: 9
Training loss: 0.8965829014778137
Validation loss: 2.143940935532252

Epoch: 5| Step: 10
Training loss: 1.137656807899475
Validation loss: 2.1727182616790137

Epoch: 5| Step: 11
Training loss: 0.5936567783355713
Validation loss: 2.2201504011948905

Epoch: 394| Step: 0
Training loss: 1.0393290519714355
Validation loss: 2.193536659081777

Epoch: 5| Step: 1
Training loss: 0.7983171939849854
Validation loss: 2.24738872051239

Epoch: 5| Step: 2
Training loss: 1.0602186918258667
Validation loss: 2.250555376211802

Epoch: 5| Step: 3
Training loss: 1.2287068367004395
Validation loss: 2.2828941444555917

Epoch: 5| Step: 4
Training loss: 0.9361497163772583
Validation loss: 2.2291088700294495

Epoch: 5| Step: 5
Training loss: 0.6440805196762085
Validation loss: 2.2425135175387063

Epoch: 5| Step: 6
Training loss: 1.0824620723724365
Validation loss: 2.20857280989488

Epoch: 5| Step: 7
Training loss: 1.1235231161117554
Validation loss: 2.2402524252732596

Epoch: 5| Step: 8
Training loss: 1.1920806169509888
Validation loss: 2.2394741674264274

Epoch: 5| Step: 9
Training loss: 0.6441508531570435
Validation loss: 2.219717189669609

Epoch: 5| Step: 10
Training loss: 1.11685311794281
Validation loss: 2.266480972369512

Epoch: 5| Step: 11
Training loss: 0.4465206265449524
Validation loss: 2.252667839328448

Epoch: 395| Step: 0
Training loss: 0.9585938453674316
Validation loss: 2.237500101327896

Epoch: 5| Step: 1
Training loss: 0.47930940985679626
Validation loss: 2.2122594813505807

Epoch: 5| Step: 2
Training loss: 0.7598247528076172
Validation loss: 2.2187972416480384

Epoch: 5| Step: 3
Training loss: 1.4280582666397095
Validation loss: 2.2301542361577353

Epoch: 5| Step: 4
Training loss: 0.9145768284797668
Validation loss: 2.202088490128517

Epoch: 5| Step: 5
Training loss: 0.8731263279914856
Validation loss: 2.2375365744034448

Epoch: 5| Step: 6
Training loss: 1.5880496501922607
Validation loss: 2.246176838874817

Epoch: 5| Step: 7
Training loss: 1.2512600421905518
Validation loss: 2.2128206690152488

Epoch: 5| Step: 8
Training loss: 0.6243763566017151
Validation loss: 2.25114169716835

Epoch: 5| Step: 9
Training loss: 1.237147331237793
Validation loss: 2.2391107032696405

Epoch: 5| Step: 10
Training loss: 1.1083911657333374
Validation loss: 2.265396609902382

Epoch: 5| Step: 11
Training loss: 0.43466490507125854
Validation loss: 2.2714905937512717

Epoch: 396| Step: 0
Training loss: 0.6998804807662964
Validation loss: 2.2609177430470786

Epoch: 5| Step: 1
Training loss: 1.223883032798767
Validation loss: 2.2600623220205307

Epoch: 5| Step: 2
Training loss: 0.8724380731582642
Validation loss: 2.211181551218033

Epoch: 5| Step: 3
Training loss: 1.035313367843628
Validation loss: 2.2622495690981546

Epoch: 5| Step: 4
Training loss: 1.5398130416870117
Validation loss: 2.2356212685505548

Epoch: 5| Step: 5
Training loss: 0.8302463293075562
Validation loss: 2.247592801849047

Epoch: 5| Step: 6
Training loss: 1.1927490234375
Validation loss: 2.2574064979950585

Epoch: 5| Step: 7
Training loss: 1.1069995164871216
Validation loss: 2.222434843579928

Epoch: 5| Step: 8
Training loss: 0.6413490772247314
Validation loss: 2.2203957736492157

Epoch: 5| Step: 9
Training loss: 0.7703995704650879
Validation loss: 2.253623276948929

Epoch: 5| Step: 10
Training loss: 0.846463680267334
Validation loss: 2.1873674392700195

Epoch: 5| Step: 11
Training loss: 0.5233337879180908
Validation loss: 2.2153528928756714

Epoch: 397| Step: 0
Training loss: 1.574704647064209
Validation loss: 2.2045229772726693

Epoch: 5| Step: 1
Training loss: 0.9563659429550171
Validation loss: 2.2139886567989984

Epoch: 5| Step: 2
Training loss: 1.0817899703979492
Validation loss: 2.1765752136707306

Epoch: 5| Step: 3
Training loss: 1.0708962678909302
Validation loss: 2.164125849803289

Epoch: 5| Step: 4
Training loss: 0.6924793124198914
Validation loss: 2.244254524509112

Epoch: 5| Step: 5
Training loss: 1.2956286668777466
Validation loss: 2.2077982326348624

Epoch: 5| Step: 6
Training loss: 0.5030686259269714
Validation loss: 2.229640414317449

Epoch: 5| Step: 7
Training loss: 0.6943036317825317
Validation loss: 2.216799015800158

Epoch: 5| Step: 8
Training loss: 1.0508161783218384
Validation loss: 2.2636434684197106

Epoch: 5| Step: 9
Training loss: 1.0880581140518188
Validation loss: 2.226775050163269

Epoch: 5| Step: 10
Training loss: 0.8346840739250183
Validation loss: 2.265349785486857

Epoch: 5| Step: 11
Training loss: 1.4797691106796265
Validation loss: 2.2502989768981934

Epoch: 398| Step: 0
Training loss: 0.9057821035385132
Validation loss: 2.2305294374624887

Epoch: 5| Step: 1
Training loss: 1.2941033840179443
Validation loss: 2.250352998574575

Epoch: 5| Step: 2
Training loss: 0.8380399942398071
Validation loss: 2.2312536935011544

Epoch: 5| Step: 3
Training loss: 1.4329349994659424
Validation loss: 2.230270028114319

Epoch: 5| Step: 4
Training loss: 0.7840824723243713
Validation loss: 2.2415403674046197

Epoch: 5| Step: 5
Training loss: 1.2269197702407837
Validation loss: 2.174340377251307

Epoch: 5| Step: 6
Training loss: 0.7873138785362244
Validation loss: 2.186678633093834

Epoch: 5| Step: 7
Training loss: 0.9475241899490356
Validation loss: 2.214644973476728

Epoch: 5| Step: 8
Training loss: 1.1834698915481567
Validation loss: 2.228034734725952

Epoch: 5| Step: 9
Training loss: 0.8881462812423706
Validation loss: 2.218161334594091

Epoch: 5| Step: 10
Training loss: 1.1177364587783813
Validation loss: 2.2295141766468682

Epoch: 5| Step: 11
Training loss: 0.8983104228973389
Validation loss: 2.233639578024546

Epoch: 399| Step: 0
Training loss: 0.6052840948104858
Validation loss: 2.2799655000368753

Epoch: 5| Step: 1
Training loss: 0.9276771545410156
Validation loss: 2.2721979717413583

Epoch: 5| Step: 2
Training loss: 1.2658048868179321
Validation loss: 2.274539719025294

Epoch: 5| Step: 3
Training loss: 0.8366906046867371
Validation loss: 2.288903976480166

Epoch: 5| Step: 4
Training loss: 0.5178556442260742
Validation loss: 2.29495562116305

Epoch: 5| Step: 5
Training loss: 1.0669419765472412
Validation loss: 2.308534269531568

Epoch: 5| Step: 6
Training loss: 1.1155526638031006
Validation loss: 2.2756598045428595

Epoch: 5| Step: 7
Training loss: 1.7474029064178467
Validation loss: 2.3042602837085724

Epoch: 5| Step: 8
Training loss: 1.2921456098556519
Validation loss: 2.2363158762454987

Epoch: 5| Step: 9
Training loss: 0.9079147577285767
Validation loss: 2.259740630785624

Epoch: 5| Step: 10
Training loss: 0.9191845655441284
Validation loss: 2.236693188548088

Epoch: 5| Step: 11
Training loss: 0.9039617776870728
Validation loss: 2.223872641722361

Epoch: 400| Step: 0
Training loss: 1.1124048233032227
Validation loss: 2.264543096224467

Epoch: 5| Step: 1
Training loss: 1.274294137954712
Validation loss: 2.2288892517487207

Epoch: 5| Step: 2
Training loss: 1.1928874254226685
Validation loss: 2.234777311484019

Epoch: 5| Step: 3
Training loss: 1.2108290195465088
Validation loss: 2.2111264169216156

Epoch: 5| Step: 4
Training loss: 0.9204915761947632
Validation loss: 2.151193082332611

Epoch: 5| Step: 5
Training loss: 0.9009634256362915
Validation loss: 2.1998978902896247

Epoch: 5| Step: 6
Training loss: 0.9464394450187683
Validation loss: 2.2292290131251016

Epoch: 5| Step: 7
Training loss: 1.304774522781372
Validation loss: 2.203772410750389

Epoch: 5| Step: 8
Training loss: 0.8268474340438843
Validation loss: 2.1864528954029083

Epoch: 5| Step: 9
Training loss: 1.078187346458435
Validation loss: 2.223772088686625

Epoch: 5| Step: 10
Training loss: 0.9055804014205933
Validation loss: 2.2242210855086646

Epoch: 5| Step: 11
Training loss: 2.5154833793640137
Validation loss: 2.220486874381701

Epoch: 401| Step: 0
Training loss: 1.0549132823944092
Validation loss: 2.201697359482447

Epoch: 5| Step: 1
Training loss: 1.373674988746643
Validation loss: 2.2079847951730094

Epoch: 5| Step: 2
Training loss: 0.6179102659225464
Validation loss: 2.1832762956619263

Epoch: 5| Step: 3
Training loss: 1.4575796127319336
Validation loss: 2.2495732456445694

Epoch: 5| Step: 4
Training loss: 1.3039429187774658
Validation loss: 2.1985063950220742

Epoch: 5| Step: 5
Training loss: 1.0368530750274658
Validation loss: 2.1504833350578942

Epoch: 5| Step: 6
Training loss: 0.8917597532272339
Validation loss: 2.1445098221302032

Epoch: 5| Step: 7
Training loss: 0.418173223733902
Validation loss: 2.1447342236836753

Epoch: 5| Step: 8
Training loss: 1.0650570392608643
Validation loss: 2.1537468085686364

Epoch: 5| Step: 9
Training loss: 1.1683924198150635
Validation loss: 2.148891896009445

Epoch: 5| Step: 10
Training loss: 1.1743804216384888
Validation loss: 2.212437371412913

Epoch: 5| Step: 11
Training loss: 0.8425702452659607
Validation loss: 2.2337015022834144

Epoch: 402| Step: 0
Training loss: 0.6811116337776184
Validation loss: 2.241948649287224

Epoch: 5| Step: 1
Training loss: 1.0001647472381592
Validation loss: 2.207156424721082

Epoch: 5| Step: 2
Training loss: 0.6781326532363892
Validation loss: 2.2311404198408127

Epoch: 5| Step: 3
Training loss: 0.9628616571426392
Validation loss: 2.2206078370412192

Epoch: 5| Step: 4
Training loss: 1.5477206707000732
Validation loss: 2.2443681160608926

Epoch: 5| Step: 5
Training loss: 1.1234956979751587
Validation loss: 2.194344083468119

Epoch: 5| Step: 6
Training loss: 0.8188905715942383
Validation loss: 2.1929560204346976

Epoch: 5| Step: 7
Training loss: 1.29954993724823
Validation loss: 2.232379138469696

Epoch: 5| Step: 8
Training loss: 0.8672651052474976
Validation loss: 2.194985662897428

Epoch: 5| Step: 9
Training loss: 0.7074243426322937
Validation loss: 2.2402949829896293

Epoch: 5| Step: 10
Training loss: 0.9196202158927917
Validation loss: 2.2647526810566583

Epoch: 5| Step: 11
Training loss: 0.4686758518218994
Validation loss: 2.213034212589264

Epoch: 403| Step: 0
Training loss: 0.5709684491157532
Validation loss: 2.282071898380915

Epoch: 5| Step: 1
Training loss: 1.2162197828292847
Validation loss: 2.292414883772532

Epoch: 5| Step: 2
Training loss: 1.1680608987808228
Validation loss: 2.2881780366102853

Epoch: 5| Step: 3
Training loss: 1.0024168491363525
Validation loss: 2.257999673485756

Epoch: 5| Step: 4
Training loss: 1.313734531402588
Validation loss: 2.302435646454493

Epoch: 5| Step: 5
Training loss: 1.118931770324707
Validation loss: 2.2818003247181573

Epoch: 5| Step: 6
Training loss: 1.7817819118499756
Validation loss: 2.2770818223555884

Epoch: 5| Step: 7
Training loss: 1.6456218957901
Validation loss: 2.2747527360916138

Epoch: 5| Step: 8
Training loss: 0.7927210330963135
Validation loss: 2.295232022802035

Epoch: 5| Step: 9
Training loss: 0.9221275448799133
Validation loss: 2.3435156444708505

Epoch: 5| Step: 10
Training loss: 1.0270335674285889
Validation loss: 2.3158549765745797

Epoch: 5| Step: 11
Training loss: 0.22063837945461273
Validation loss: 2.3049216320117316

Epoch: 404| Step: 0
Training loss: 1.26495361328125
Validation loss: 2.3442249496777854

Epoch: 5| Step: 1
Training loss: 1.1580826044082642
Validation loss: 2.32438230017821

Epoch: 5| Step: 2
Training loss: 1.1958351135253906
Validation loss: 2.315037652850151

Epoch: 5| Step: 3
Training loss: 1.4053077697753906
Validation loss: 2.267354985078176

Epoch: 5| Step: 4
Training loss: 1.0250009298324585
Validation loss: 2.248516008257866

Epoch: 5| Step: 5
Training loss: 0.9164437055587769
Validation loss: 2.241045614083608

Epoch: 5| Step: 6
Training loss: 0.6751183271408081
Validation loss: 2.232707624634107

Epoch: 5| Step: 7
Training loss: 0.6202604174613953
Validation loss: 2.212893029054006

Epoch: 5| Step: 8
Training loss: 1.5564693212509155
Validation loss: 2.2321373919645944

Epoch: 5| Step: 9
Training loss: 1.28883695602417
Validation loss: 2.230901817480723

Epoch: 5| Step: 10
Training loss: 1.5601261854171753
Validation loss: 2.2289144098758698

Epoch: 5| Step: 11
Training loss: 0.45525914430618286
Validation loss: 2.249610717097918

Epoch: 405| Step: 0
Training loss: 1.022689938545227
Validation loss: 2.2377045849959054

Epoch: 5| Step: 1
Training loss: 1.5811411142349243
Validation loss: 2.2294314801692963

Epoch: 5| Step: 2
Training loss: 1.4485772848129272
Validation loss: 2.2587073345979056

Epoch: 5| Step: 3
Training loss: 0.6965391039848328
Validation loss: 2.219194437066714

Epoch: 5| Step: 4
Training loss: 0.7532312273979187
Validation loss: 2.2259129335482917

Epoch: 5| Step: 5
Training loss: 1.3979846239089966
Validation loss: 2.260497053464254

Epoch: 5| Step: 6
Training loss: 0.8564340472221375
Validation loss: 2.1984921197096505

Epoch: 5| Step: 7
Training loss: 1.197346806526184
Validation loss: 2.244905948638916

Epoch: 5| Step: 8
Training loss: 0.9990516901016235
Validation loss: 2.2485398997863135

Epoch: 5| Step: 9
Training loss: 0.5323191285133362
Validation loss: 2.2567293643951416

Epoch: 5| Step: 10
Training loss: 0.9667195081710815
Validation loss: 2.2676087021827698

Epoch: 5| Step: 11
Training loss: 0.3359975516796112
Validation loss: 2.2550827960173288

Epoch: 406| Step: 0
Training loss: 0.5261082053184509
Validation loss: 2.263017992178599

Epoch: 5| Step: 1
Training loss: 1.0384587049484253
Validation loss: 2.265993669629097

Epoch: 5| Step: 2
Training loss: 0.942529559135437
Validation loss: 2.292473723491033

Epoch: 5| Step: 3
Training loss: 1.1750987768173218
Validation loss: 2.2452488044897714

Epoch: 5| Step: 4
Training loss: 0.6414077877998352
Validation loss: 2.2541963358720145

Epoch: 5| Step: 5
Training loss: 1.0996297597885132
Validation loss: 2.2692361970742545

Epoch: 5| Step: 6
Training loss: 0.9098556637763977
Validation loss: 2.272914002339045

Epoch: 5| Step: 7
Training loss: 1.2883495092391968
Validation loss: 2.2732180655002594

Epoch: 5| Step: 8
Training loss: 1.0615403652191162
Validation loss: 2.220450828472773

Epoch: 5| Step: 9
Training loss: 1.0718533992767334
Validation loss: 2.227422664562861

Epoch: 5| Step: 10
Training loss: 0.8534770011901855
Validation loss: 2.241557682553927

Epoch: 5| Step: 11
Training loss: 1.2841334342956543
Validation loss: 2.2103080451488495

Epoch: 407| Step: 0
Training loss: 0.8321443796157837
Validation loss: 2.196218947569529

Epoch: 5| Step: 1
Training loss: 0.7378830313682556
Validation loss: 2.2664734423160553

Epoch: 5| Step: 2
Training loss: 0.6724780797958374
Validation loss: 2.2120431065559387

Epoch: 5| Step: 3
Training loss: 1.1002912521362305
Validation loss: 2.1812414824962616

Epoch: 5| Step: 4
Training loss: 1.0761486291885376
Validation loss: 2.210494508345922

Epoch: 5| Step: 5
Training loss: 1.3989794254302979
Validation loss: 2.196844885746638

Epoch: 5| Step: 6
Training loss: 0.5720536708831787
Validation loss: 2.217487628261248

Epoch: 5| Step: 7
Training loss: 0.9723159670829773
Validation loss: 2.1704472253719964

Epoch: 5| Step: 8
Training loss: 0.5770034790039062
Validation loss: 2.1980312963326774

Epoch: 5| Step: 9
Training loss: 1.2883819341659546
Validation loss: 2.2214313248793283

Epoch: 5| Step: 10
Training loss: 0.878247857093811
Validation loss: 2.2237751682599387

Epoch: 5| Step: 11
Training loss: 1.8866418600082397
Validation loss: 2.268709510564804

Epoch: 408| Step: 0
Training loss: 0.8922044634819031
Validation loss: 2.257129599650701

Epoch: 5| Step: 1
Training loss: 0.903763473033905
Validation loss: 2.2519436925649643

Epoch: 5| Step: 2
Training loss: 1.0113427639007568
Validation loss: 2.273359696070353

Epoch: 5| Step: 3
Training loss: 0.912061870098114
Validation loss: 2.17527145644029

Epoch: 5| Step: 4
Training loss: 1.1705081462860107
Validation loss: 2.2188889384269714

Epoch: 5| Step: 5
Training loss: 1.2054649591445923
Validation loss: 2.2257163524627686

Epoch: 5| Step: 6
Training loss: 1.2366862297058105
Validation loss: 2.2448596755663552

Epoch: 5| Step: 7
Training loss: 0.9299238920211792
Validation loss: 2.233604242404302

Epoch: 5| Step: 8
Training loss: 1.080610752105713
Validation loss: 2.2539076656103134

Epoch: 5| Step: 9
Training loss: 0.8126222491264343
Validation loss: 2.2740256637334824

Epoch: 5| Step: 10
Training loss: 0.6973474621772766
Validation loss: 2.2714007596174874

Epoch: 5| Step: 11
Training loss: 1.144822597503662
Validation loss: 2.2679754396279654

Epoch: 409| Step: 0
Training loss: 1.3922135829925537
Validation loss: 2.2846541901429496

Epoch: 5| Step: 1
Training loss: 0.8057559728622437
Validation loss: 2.283530980348587

Epoch: 5| Step: 2
Training loss: 0.6361834406852722
Validation loss: 2.259815181295077

Epoch: 5| Step: 3
Training loss: 0.8304828405380249
Validation loss: 2.2655183225870132

Epoch: 5| Step: 4
Training loss: 0.8045390844345093
Validation loss: 2.2634561359882355

Epoch: 5| Step: 5
Training loss: 0.7050848007202148
Validation loss: 2.231281280517578

Epoch: 5| Step: 6
Training loss: 0.9701870083808899
Validation loss: 2.1956144273281097

Epoch: 5| Step: 7
Training loss: 1.4046132564544678
Validation loss: 2.218334992726644

Epoch: 5| Step: 8
Training loss: 1.33125901222229
Validation loss: 2.1977289617061615

Epoch: 5| Step: 9
Training loss: 0.9359194040298462
Validation loss: 2.2272431552410126

Epoch: 5| Step: 10
Training loss: 0.7701848149299622
Validation loss: 2.2256334026654563

Epoch: 5| Step: 11
Training loss: 0.4152001440525055
Validation loss: 2.1691958407560983

Epoch: 410| Step: 0
Training loss: 0.999093234539032
Validation loss: 2.19562366604805

Epoch: 5| Step: 1
Training loss: 0.9114948511123657
Validation loss: 2.2066738506158194

Epoch: 5| Step: 2
Training loss: 0.8660299181938171
Validation loss: 2.234147787094116

Epoch: 5| Step: 3
Training loss: 1.1138943433761597
Validation loss: 2.2424799601236978

Epoch: 5| Step: 4
Training loss: 1.44779634475708
Validation loss: 2.215341945489248

Epoch: 5| Step: 5
Training loss: 0.634641706943512
Validation loss: 2.264400159319242

Epoch: 5| Step: 6
Training loss: 1.0760414600372314
Validation loss: 2.2524200032154718

Epoch: 5| Step: 7
Training loss: 0.8291357755661011
Validation loss: 2.2653144945700965

Epoch: 5| Step: 8
Training loss: 1.2409842014312744
Validation loss: 2.2438883731762567

Epoch: 5| Step: 9
Training loss: 0.7813461422920227
Validation loss: 2.238682592908541

Epoch: 5| Step: 10
Training loss: 1.4203559160232544
Validation loss: 2.2306140462557473

Epoch: 5| Step: 11
Training loss: 0.4049180746078491
Validation loss: 2.2484960754712424

Epoch: 411| Step: 0
Training loss: 0.6396068334579468
Validation loss: 2.2024962653716407

Epoch: 5| Step: 1
Training loss: 1.549668312072754
Validation loss: 2.203198552131653

Epoch: 5| Step: 2
Training loss: 1.0626003742218018
Validation loss: 2.212574233611425

Epoch: 5| Step: 3
Training loss: 1.095542550086975
Validation loss: 2.23541529973348

Epoch: 5| Step: 4
Training loss: 0.8455317616462708
Validation loss: 2.2110863278309503

Epoch: 5| Step: 5
Training loss: 0.9810284376144409
Validation loss: 2.1734503507614136

Epoch: 5| Step: 6
Training loss: 1.0989530086517334
Validation loss: 2.174331024289131

Epoch: 5| Step: 7
Training loss: 1.1041724681854248
Validation loss: 2.187775934735934

Epoch: 5| Step: 8
Training loss: 1.2056591510772705
Validation loss: 2.208805590867996

Epoch: 5| Step: 9
Training loss: 1.4284418821334839
Validation loss: 2.190383329987526

Epoch: 5| Step: 10
Training loss: 0.823663055896759
Validation loss: 2.1960764726003013

Epoch: 5| Step: 11
Training loss: 0.33399498462677
Validation loss: 2.1821633825699487

Epoch: 412| Step: 0
Training loss: 0.7191827893257141
Validation loss: 2.181073099374771

Epoch: 5| Step: 1
Training loss: 0.8521936535835266
Validation loss: 2.1989410122235618

Epoch: 5| Step: 2
Training loss: 0.6741387844085693
Validation loss: 2.258000855644544

Epoch: 5| Step: 3
Training loss: 1.0729081630706787
Validation loss: 2.184112216035525

Epoch: 5| Step: 4
Training loss: 0.8071308135986328
Validation loss: 2.234848201274872

Epoch: 5| Step: 5
Training loss: 1.182678461074829
Validation loss: 2.280342757701874

Epoch: 5| Step: 6
Training loss: 1.3213778734207153
Validation loss: 2.206190293033918

Epoch: 5| Step: 7
Training loss: 0.7034009695053101
Validation loss: 2.1712252845366797

Epoch: 5| Step: 8
Training loss: 0.5469893217086792
Validation loss: 2.1865981817245483

Epoch: 5| Step: 9
Training loss: 0.9474824070930481
Validation loss: 2.22756756345431

Epoch: 5| Step: 10
Training loss: 1.2957897186279297
Validation loss: 2.200045332312584

Epoch: 5| Step: 11
Training loss: 1.4503403902053833
Validation loss: 2.215500141183535

Epoch: 413| Step: 0
Training loss: 1.1098812818527222
Validation loss: 2.175192564725876

Epoch: 5| Step: 1
Training loss: 0.43116116523742676
Validation loss: 2.1572078416744866

Epoch: 5| Step: 2
Training loss: 1.0876108407974243
Validation loss: 2.1727783431609473

Epoch: 5| Step: 3
Training loss: 1.2249510288238525
Validation loss: 2.1611392199993134

Epoch: 5| Step: 4
Training loss: 1.119733452796936
Validation loss: 2.1145448684692383

Epoch: 5| Step: 5
Training loss: 0.8801105618476868
Validation loss: 2.176117887099584

Epoch: 5| Step: 6
Training loss: 0.86761873960495
Validation loss: 2.1571349501609802

Epoch: 5| Step: 7
Training loss: 1.2185869216918945
Validation loss: 2.1428411503632865

Epoch: 5| Step: 8
Training loss: 0.7369964718818665
Validation loss: 2.167856842279434

Epoch: 5| Step: 9
Training loss: 0.9245535731315613
Validation loss: 2.2238775342702866

Epoch: 5| Step: 10
Training loss: 0.5783363580703735
Validation loss: 2.2592194378376007

Epoch: 5| Step: 11
Training loss: 1.5574872493743896
Validation loss: 2.2350694636503854

Epoch: 414| Step: 0
Training loss: 1.2320982217788696
Validation loss: 2.2471706569194794

Epoch: 5| Step: 1
Training loss: 0.9200692176818848
Validation loss: 2.233539124329885

Epoch: 5| Step: 2
Training loss: 0.7702272534370422
Validation loss: 2.2320008973280587

Epoch: 5| Step: 3
Training loss: 0.9397100210189819
Validation loss: 2.2572162747383118

Epoch: 5| Step: 4
Training loss: 0.6042504906654358
Validation loss: 2.2276786218086877

Epoch: 5| Step: 5
Training loss: 0.48405399918556213
Validation loss: 2.251471628745397

Epoch: 5| Step: 6
Training loss: 0.9147624969482422
Validation loss: 2.2281658947467804

Epoch: 5| Step: 7
Training loss: 0.9377317428588867
Validation loss: 2.2225968887408576

Epoch: 5| Step: 8
Training loss: 0.7742173075675964
Validation loss: 2.19359881679217

Epoch: 5| Step: 9
Training loss: 0.8715761303901672
Validation loss: 2.270292008916537

Epoch: 5| Step: 10
Training loss: 1.559816598892212
Validation loss: 2.1956690599521003

Epoch: 5| Step: 11
Training loss: 0.8135249018669128
Validation loss: 2.2294631799062095

Epoch: 415| Step: 0
Training loss: 0.5038173794746399
Validation loss: 2.2173032661279044

Epoch: 5| Step: 1
Training loss: 0.8459183573722839
Validation loss: 2.228488435347875

Epoch: 5| Step: 2
Training loss: 0.8961664438247681
Validation loss: 2.2006543378035226

Epoch: 5| Step: 3
Training loss: 0.895344614982605
Validation loss: 2.214205880959829

Epoch: 5| Step: 4
Training loss: 0.6384655237197876
Validation loss: 2.179660737514496

Epoch: 5| Step: 5
Training loss: 1.282523512840271
Validation loss: 2.2150035053491592

Epoch: 5| Step: 6
Training loss: 1.048806071281433
Validation loss: 2.201559990644455

Epoch: 5| Step: 7
Training loss: 1.1619914770126343
Validation loss: 2.1895436495542526

Epoch: 5| Step: 8
Training loss: 0.9492069482803345
Validation loss: 2.196504389246305

Epoch: 5| Step: 9
Training loss: 1.4660866260528564
Validation loss: 2.198726857701937

Epoch: 5| Step: 10
Training loss: 1.0104485750198364
Validation loss: 2.1707348773876824

Epoch: 5| Step: 11
Training loss: 0.6210846900939941
Validation loss: 2.215449571609497

Epoch: 416| Step: 0
Training loss: 0.871077835559845
Validation loss: 2.189584568142891

Epoch: 5| Step: 1
Training loss: 1.1651623249053955
Validation loss: 2.1511665185292563

Epoch: 5| Step: 2
Training loss: 0.6288418769836426
Validation loss: 2.2250001579523087

Epoch: 5| Step: 3
Training loss: 0.8376026153564453
Validation loss: 2.2010153035322824

Epoch: 5| Step: 4
Training loss: 1.317995309829712
Validation loss: 2.208674589792887

Epoch: 5| Step: 5
Training loss: 1.0051716566085815
Validation loss: 2.208843563993772

Epoch: 5| Step: 6
Training loss: 0.8138355016708374
Validation loss: 2.174902026851972

Epoch: 5| Step: 7
Training loss: 0.7775559425354004
Validation loss: 2.1882887383302054

Epoch: 5| Step: 8
Training loss: 0.8439497947692871
Validation loss: 2.1956522117058435

Epoch: 5| Step: 9
Training loss: 0.8877401351928711
Validation loss: 2.20590478181839

Epoch: 5| Step: 10
Training loss: 1.4071242809295654
Validation loss: 2.197219888369242

Epoch: 5| Step: 11
Training loss: 0.09417009353637695
Validation loss: 2.146596595644951

Epoch: 417| Step: 0
Training loss: 0.7709296941757202
Validation loss: 2.151837795972824

Epoch: 5| Step: 1
Training loss: 0.7946649789810181
Validation loss: 2.219363749027252

Epoch: 5| Step: 2
Training loss: 0.9845539927482605
Validation loss: 2.1809695611397424

Epoch: 5| Step: 3
Training loss: 0.9289701581001282
Validation loss: 2.225722387433052

Epoch: 5| Step: 4
Training loss: 0.6360307931900024
Validation loss: 2.2260605543851852

Epoch: 5| Step: 5
Training loss: 1.3215606212615967
Validation loss: 2.2101200968027115

Epoch: 5| Step: 6
Training loss: 0.5639301538467407
Validation loss: 2.2753575444221497

Epoch: 5| Step: 7
Training loss: 1.6243221759796143
Validation loss: 2.2296350648005805

Epoch: 5| Step: 8
Training loss: 1.0780515670776367
Validation loss: 2.275855710109075

Epoch: 5| Step: 9
Training loss: 0.9377479553222656
Validation loss: 2.298045426607132

Epoch: 5| Step: 10
Training loss: 0.4981781542301178
Validation loss: 2.277380774418513

Epoch: 5| Step: 11
Training loss: 0.7384289503097534
Validation loss: 2.281395673751831

Epoch: 418| Step: 0
Training loss: 0.7484883069992065
Validation loss: 2.252494658033053

Epoch: 5| Step: 1
Training loss: 0.3076118528842926
Validation loss: 2.2468144992987313

Epoch: 5| Step: 2
Training loss: 0.8778200149536133
Validation loss: 2.245146860678991

Epoch: 5| Step: 3
Training loss: 0.5275801420211792
Validation loss: 2.2383174002170563

Epoch: 5| Step: 4
Training loss: 0.7422831654548645
Validation loss: 2.231649413704872

Epoch: 5| Step: 5
Training loss: 0.9522292017936707
Validation loss: 2.2019947369893393

Epoch: 5| Step: 6
Training loss: 1.6134233474731445
Validation loss: 2.2366567651430764

Epoch: 5| Step: 7
Training loss: 0.718206524848938
Validation loss: 2.214480703075727

Epoch: 5| Step: 8
Training loss: 1.0817290544509888
Validation loss: 2.182972008983294

Epoch: 5| Step: 9
Training loss: 0.9991699457168579
Validation loss: 2.2020455797513327

Epoch: 5| Step: 10
Training loss: 1.4459308385849
Validation loss: 2.203452005982399

Epoch: 5| Step: 11
Training loss: 0.12516683340072632
Validation loss: 2.1746127605438232

Epoch: 419| Step: 0
Training loss: 0.6761234998703003
Validation loss: 2.191722720861435

Epoch: 5| Step: 1
Training loss: 1.0749037265777588
Validation loss: 2.166220779220263

Epoch: 5| Step: 2
Training loss: 0.7344959378242493
Validation loss: 2.2071653455495834

Epoch: 5| Step: 3
Training loss: 1.2161192893981934
Validation loss: 2.2098658680915833

Epoch: 5| Step: 4
Training loss: 0.6622539758682251
Validation loss: 2.211887319882711

Epoch: 5| Step: 5
Training loss: 0.7645775079727173
Validation loss: 2.187907030185064

Epoch: 5| Step: 6
Training loss: 1.2525198459625244
Validation loss: 2.162047659357389

Epoch: 5| Step: 7
Training loss: 0.8740938305854797
Validation loss: 2.2244101762771606

Epoch: 5| Step: 8
Training loss: 0.9637697339057922
Validation loss: 2.1797564129034677

Epoch: 5| Step: 9
Training loss: 1.0360219478607178
Validation loss: 2.2144841154416404

Epoch: 5| Step: 10
Training loss: 0.8904050588607788
Validation loss: 2.132454733053843

Epoch: 5| Step: 11
Training loss: 0.41254785656929016
Validation loss: 2.184514597058296

Epoch: 420| Step: 0
Training loss: 0.9416658282279968
Validation loss: 2.186740756034851

Epoch: 5| Step: 1
Training loss: 0.5801613330841064
Validation loss: 2.141843557357788

Epoch: 5| Step: 2
Training loss: 1.2031116485595703
Validation loss: 2.1235277901093164

Epoch: 5| Step: 3
Training loss: 0.826269805431366
Validation loss: 2.123638575275739

Epoch: 5| Step: 4
Training loss: 0.7326250672340393
Validation loss: 2.091264635324478

Epoch: 5| Step: 5
Training loss: 0.48510169982910156
Validation loss: 2.1620557655890784

Epoch: 5| Step: 6
Training loss: 0.9630025625228882
Validation loss: 2.1547649850447974

Epoch: 5| Step: 7
Training loss: 0.910015881061554
Validation loss: 2.175027916828791

Epoch: 5| Step: 8
Training loss: 1.6377522945404053
Validation loss: 2.201473688085874

Epoch: 5| Step: 9
Training loss: 0.9784123301506042
Validation loss: 2.198869248231252

Epoch: 5| Step: 10
Training loss: 1.4085547924041748
Validation loss: 2.1995647152264914

Epoch: 5| Step: 11
Training loss: 0.5920076370239258
Validation loss: 2.173543095588684

Epoch: 421| Step: 0
Training loss: 0.8026683926582336
Validation loss: 2.2225887974103293

Epoch: 5| Step: 1
Training loss: 1.0364911556243896
Validation loss: 2.257785275578499

Epoch: 5| Step: 2
Training loss: 1.2059838771820068
Validation loss: 2.1886541744073233

Epoch: 5| Step: 3
Training loss: 1.2443324327468872
Validation loss: 2.2446815371513367

Epoch: 5| Step: 4
Training loss: 0.755201518535614
Validation loss: 2.261223395665487

Epoch: 5| Step: 5
Training loss: 0.7349393367767334
Validation loss: 2.269400730729103

Epoch: 5| Step: 6
Training loss: 0.7831994891166687
Validation loss: 2.252264449993769

Epoch: 5| Step: 7
Training loss: 1.1989272832870483
Validation loss: 2.1958966652552285

Epoch: 5| Step: 8
Training loss: 0.5148856043815613
Validation loss: 2.215530609091123

Epoch: 5| Step: 9
Training loss: 0.6687685251235962
Validation loss: 2.242550417780876

Epoch: 5| Step: 10
Training loss: 1.0387176275253296
Validation loss: 2.259835963447889

Epoch: 5| Step: 11
Training loss: 1.2647768259048462
Validation loss: 2.266857927044233

Epoch: 422| Step: 0
Training loss: 0.9130967855453491
Validation loss: 2.2082077463467917

Epoch: 5| Step: 1
Training loss: 1.0087461471557617
Validation loss: 2.1968709379434586

Epoch: 5| Step: 2
Training loss: 0.646954357624054
Validation loss: 2.216114883621534

Epoch: 5| Step: 3
Training loss: 0.9720450639724731
Validation loss: 2.1413267652193704

Epoch: 5| Step: 4
Training loss: 1.0287721157073975
Validation loss: 2.174894710381826

Epoch: 5| Step: 5
Training loss: 0.9053061604499817
Validation loss: 2.1289899150530496

Epoch: 5| Step: 6
Training loss: 0.7232505083084106
Validation loss: 2.1566431522369385

Epoch: 5| Step: 7
Training loss: 0.7922213673591614
Validation loss: 2.17692369222641

Epoch: 5| Step: 8
Training loss: 1.1201280355453491
Validation loss: 2.1552052398522696

Epoch: 5| Step: 9
Training loss: 0.7264969348907471
Validation loss: 2.1847348312536874

Epoch: 5| Step: 10
Training loss: 1.2258803844451904
Validation loss: 2.203335533539454

Epoch: 5| Step: 11
Training loss: 0.08688217401504517
Validation loss: 2.1677375783522925

Epoch: 423| Step: 0
Training loss: 0.8934362530708313
Validation loss: 2.1333716064691544

Epoch: 5| Step: 1
Training loss: 0.7563697099685669
Validation loss: 2.1922375758488974

Epoch: 5| Step: 2
Training loss: 0.7315515279769897
Validation loss: 2.2126339972019196

Epoch: 5| Step: 3
Training loss: 0.680583119392395
Validation loss: 2.2236344516277313

Epoch: 5| Step: 4
Training loss: 0.9857504963874817
Validation loss: 2.1141907473405204

Epoch: 5| Step: 5
Training loss: 1.1800501346588135
Validation loss: 2.2319611509641013

Epoch: 5| Step: 6
Training loss: 0.8046917915344238
Validation loss: 2.165676628549894

Epoch: 5| Step: 7
Training loss: 0.6863710880279541
Validation loss: 2.153367047508558

Epoch: 5| Step: 8
Training loss: 1.0149730443954468
Validation loss: 2.199056794246038

Epoch: 5| Step: 9
Training loss: 1.368774652481079
Validation loss: 2.241101731856664

Epoch: 5| Step: 10
Training loss: 1.0365492105484009
Validation loss: 2.2061717261870704

Epoch: 5| Step: 11
Training loss: 0.6421357989311218
Validation loss: 2.1899876296520233

Epoch: 424| Step: 0
Training loss: 1.587172269821167
Validation loss: 2.1890978862841926

Epoch: 5| Step: 1
Training loss: 1.292946219444275
Validation loss: 2.1603587617476783

Epoch: 5| Step: 2
Training loss: 1.2456626892089844
Validation loss: 2.150038013855616

Epoch: 5| Step: 3
Training loss: 0.8714367151260376
Validation loss: 2.177403469880422

Epoch: 5| Step: 4
Training loss: 0.48575258255004883
Validation loss: 2.179255644480387

Epoch: 5| Step: 5
Training loss: 0.5968204140663147
Validation loss: 2.2133562515179315

Epoch: 5| Step: 6
Training loss: 0.5678994059562683
Validation loss: 2.1993965804576874

Epoch: 5| Step: 7
Training loss: 0.8475047945976257
Validation loss: 2.1910475393136344

Epoch: 5| Step: 8
Training loss: 0.680486798286438
Validation loss: 2.208060562610626

Epoch: 5| Step: 9
Training loss: 0.7347502708435059
Validation loss: 2.1656637291113534

Epoch: 5| Step: 10
Training loss: 1.00063157081604
Validation loss: 2.2352325270573297

Epoch: 5| Step: 11
Training loss: 0.3930668830871582
Validation loss: 2.224571943283081

Epoch: 425| Step: 0
Training loss: 1.4496443271636963
Validation loss: 2.228278269370397

Epoch: 5| Step: 1
Training loss: 1.5383168458938599
Validation loss: 2.2432996730009713

Epoch: 5| Step: 2
Training loss: 1.292638897895813
Validation loss: 2.244712710380554

Epoch: 5| Step: 3
Training loss: 0.6622540354728699
Validation loss: 2.2639215936263404

Epoch: 5| Step: 4
Training loss: 0.6196696162223816
Validation loss: 2.253941297531128

Epoch: 5| Step: 5
Training loss: 0.62064129114151
Validation loss: 2.1980979839960733

Epoch: 5| Step: 6
Training loss: 0.931993842124939
Validation loss: 2.2339505553245544

Epoch: 5| Step: 7
Training loss: 1.1575536727905273
Validation loss: 2.242890626192093

Epoch: 5| Step: 8
Training loss: 0.8729904890060425
Validation loss: 2.1785584688186646

Epoch: 5| Step: 9
Training loss: 0.9331241846084595
Validation loss: 2.204660306374232

Epoch: 5| Step: 10
Training loss: 0.7758161425590515
Validation loss: 2.2280671199162803

Epoch: 5| Step: 11
Training loss: 0.7926322817802429
Validation loss: 2.240023603041967

Epoch: 426| Step: 0
Training loss: 0.8751811981201172
Validation loss: 2.1675682067871094

Epoch: 5| Step: 1
Training loss: 1.6227381229400635
Validation loss: 2.212616687019666

Epoch: 5| Step: 2
Training loss: 1.0454181432724
Validation loss: 2.223999793330828

Epoch: 5| Step: 3
Training loss: 1.0692946910858154
Validation loss: 2.2271341184775033

Epoch: 5| Step: 4
Training loss: 1.2221418619155884
Validation loss: 2.1267849604288735

Epoch: 5| Step: 5
Training loss: 0.4373456835746765
Validation loss: 2.110090042153994

Epoch: 5| Step: 6
Training loss: 1.378422498703003
Validation loss: 2.0971078326304755

Epoch: 5| Step: 7
Training loss: 1.1235644817352295
Validation loss: 2.1679463932911553

Epoch: 5| Step: 8
Training loss: 0.9448680877685547
Validation loss: 2.1076365311940513

Epoch: 5| Step: 9
Training loss: 0.6987274885177612
Validation loss: 2.158951868613561

Epoch: 5| Step: 10
Training loss: 1.093144416809082
Validation loss: 2.2253835101922355

Epoch: 5| Step: 11
Training loss: 0.2762044370174408
Validation loss: 2.20241508881251

Epoch: 427| Step: 0
Training loss: 0.7885807752609253
Validation loss: 2.1835071643193564

Epoch: 5| Step: 1
Training loss: 0.6001201868057251
Validation loss: 2.217631841699282

Epoch: 5| Step: 2
Training loss: 0.5682200193405151
Validation loss: 2.2149444768826165

Epoch: 5| Step: 3
Training loss: 0.7009514570236206
Validation loss: 2.172223483522733

Epoch: 5| Step: 4
Training loss: 1.4515804052352905
Validation loss: 2.217290515700976

Epoch: 5| Step: 5
Training loss: 0.6262555122375488
Validation loss: 2.2253432273864746

Epoch: 5| Step: 6
Training loss: 1.0816080570220947
Validation loss: 2.2166544596354165

Epoch: 5| Step: 7
Training loss: 1.2210264205932617
Validation loss: 2.1880695621172586

Epoch: 5| Step: 8
Training loss: 0.7300562858581543
Validation loss: 2.179844319820404

Epoch: 5| Step: 9
Training loss: 0.7051750421524048
Validation loss: 2.1724045475323996

Epoch: 5| Step: 10
Training loss: 1.4023756980895996
Validation loss: 2.1703831056753793

Epoch: 5| Step: 11
Training loss: 0.3566048741340637
Validation loss: 2.1644620398680368

Epoch: 428| Step: 0
Training loss: 1.0524675846099854
Validation loss: 2.157706141471863

Epoch: 5| Step: 1
Training loss: 0.6956893801689148
Validation loss: 2.161910817027092

Epoch: 5| Step: 2
Training loss: 0.5218490958213806
Validation loss: 2.1669948349396386

Epoch: 5| Step: 3
Training loss: 1.173254132270813
Validation loss: 2.180396174391111

Epoch: 5| Step: 4
Training loss: 0.5701214075088501
Validation loss: 2.144832198818525

Epoch: 5| Step: 5
Training loss: 0.8573280572891235
Validation loss: 2.1524148881435394

Epoch: 5| Step: 6
Training loss: 0.7056287527084351
Validation loss: 2.225268801053365

Epoch: 5| Step: 7
Training loss: 0.6278657913208008
Validation loss: 2.2029673357804618

Epoch: 5| Step: 8
Training loss: 0.7390446662902832
Validation loss: 2.221509645382563

Epoch: 5| Step: 9
Training loss: 1.103331208229065
Validation loss: 2.25636034210523

Epoch: 5| Step: 10
Training loss: 1.0487767457962036
Validation loss: 2.2236583083868027

Epoch: 5| Step: 11
Training loss: 1.2421350479125977
Validation loss: 2.194815456867218

Epoch: 429| Step: 0
Training loss: 0.5290295481681824
Validation loss: 2.2220642815033593

Epoch: 5| Step: 1
Training loss: 1.138609528541565
Validation loss: 2.1510572930177054

Epoch: 5| Step: 2
Training loss: 1.077784776687622
Validation loss: 2.1973683138688407

Epoch: 5| Step: 3
Training loss: 1.0687898397445679
Validation loss: 2.2469192991654077

Epoch: 5| Step: 4
Training loss: 0.7050164937973022
Validation loss: 2.2112637559572854

Epoch: 5| Step: 5
Training loss: 0.9428851008415222
Validation loss: 2.2042615711688995

Epoch: 5| Step: 6
Training loss: 1.1042249202728271
Validation loss: 2.2194313754638038

Epoch: 5| Step: 7
Training loss: 0.7186849117279053
Validation loss: 2.1511476139227548

Epoch: 5| Step: 8
Training loss: 0.5405942797660828
Validation loss: 2.184175491333008

Epoch: 5| Step: 9
Training loss: 1.0564429759979248
Validation loss: 2.204631825288137

Epoch: 5| Step: 10
Training loss: 0.8468826413154602
Validation loss: 2.20626766482989

Epoch: 5| Step: 11
Training loss: 2.528980255126953
Validation loss: 2.1601684292157493

Epoch: 430| Step: 0
Training loss: 1.1675019264221191
Validation loss: 2.1459121704101562

Epoch: 5| Step: 1
Training loss: 0.4658694863319397
Validation loss: 2.102169409394264

Epoch: 5| Step: 2
Training loss: 0.7278011441230774
Validation loss: 2.181674142678579

Epoch: 5| Step: 3
Training loss: 0.6450908780097961
Validation loss: 2.165019045273463

Epoch: 5| Step: 4
Training loss: 0.7519606351852417
Validation loss: 2.1664721618096032

Epoch: 5| Step: 5
Training loss: 0.9940837621688843
Validation loss: 2.186884045600891

Epoch: 5| Step: 6
Training loss: 1.012047529220581
Validation loss: 2.150776525338491

Epoch: 5| Step: 7
Training loss: 0.8826128840446472
Validation loss: 2.2114305098851523

Epoch: 5| Step: 8
Training loss: 0.6849653124809265
Validation loss: 2.1765197664499283

Epoch: 5| Step: 9
Training loss: 1.0471326112747192
Validation loss: 2.1623519708712897

Epoch: 5| Step: 10
Training loss: 0.6820535063743591
Validation loss: 2.2042548656463623

Epoch: 5| Step: 11
Training loss: 0.5446346998214722
Validation loss: 2.1626604149738946

Epoch: 431| Step: 0
Training loss: 0.6429389715194702
Validation loss: 2.222117473681768

Epoch: 5| Step: 1
Training loss: 0.501506507396698
Validation loss: 2.142385025819143

Epoch: 5| Step: 2
Training loss: 0.8822547197341919
Validation loss: 2.123263567686081

Epoch: 5| Step: 3
Training loss: 0.8522258996963501
Validation loss: 2.1289264261722565

Epoch: 5| Step: 4
Training loss: 1.1478612422943115
Validation loss: 2.0868225196997323

Epoch: 5| Step: 5
Training loss: 0.7956242561340332
Validation loss: 2.1276198426882424

Epoch: 5| Step: 6
Training loss: 1.0551427602767944
Validation loss: 2.127380927403768

Epoch: 5| Step: 7
Training loss: 0.8916932940483093
Validation loss: 2.125261868039767

Epoch: 5| Step: 8
Training loss: 1.0378167629241943
Validation loss: 2.119475334882736

Epoch: 5| Step: 9
Training loss: 0.9424997568130493
Validation loss: 2.139810800552368

Epoch: 5| Step: 10
Training loss: 0.7186393737792969
Validation loss: 2.1245260487000146

Epoch: 5| Step: 11
Training loss: 0.5719385147094727
Validation loss: 2.1404903133710227

Epoch: 432| Step: 0
Training loss: 0.8510242700576782
Validation loss: 2.169225439429283

Epoch: 5| Step: 1
Training loss: 0.6299314498901367
Validation loss: 2.1316915154457092

Epoch: 5| Step: 2
Training loss: 0.7844913005828857
Validation loss: 2.1728763381640115

Epoch: 5| Step: 3
Training loss: 0.6175010204315186
Validation loss: 2.176575466990471

Epoch: 5| Step: 4
Training loss: 0.7842712998390198
Validation loss: 2.1483632028102875

Epoch: 5| Step: 5
Training loss: 1.0079824924468994
Validation loss: 2.1579787184794745

Epoch: 5| Step: 6
Training loss: 0.8452385663986206
Validation loss: 2.1974171052376428

Epoch: 5| Step: 7
Training loss: 0.6586411595344543
Validation loss: 2.1775054236253104

Epoch: 5| Step: 8
Training loss: 0.7645220756530762
Validation loss: 2.170246014992396

Epoch: 5| Step: 9
Training loss: 1.1283183097839355
Validation loss: 2.1513054023186364

Epoch: 5| Step: 10
Training loss: 0.8096355199813843
Validation loss: 2.168106118837992

Epoch: 5| Step: 11
Training loss: 0.7692112922668457
Validation loss: 2.136106247703234

Epoch: 433| Step: 0
Training loss: 0.694273829460144
Validation loss: 2.115969349940618

Epoch: 5| Step: 1
Training loss: 1.008125901222229
Validation loss: 2.130549356341362

Epoch: 5| Step: 2
Training loss: 0.814173698425293
Validation loss: 2.133795991539955

Epoch: 5| Step: 3
Training loss: 0.5893096327781677
Validation loss: 2.14038555820783

Epoch: 5| Step: 4
Training loss: 0.8439093828201294
Validation loss: 2.1899052361647287

Epoch: 5| Step: 5
Training loss: 0.6694762706756592
Validation loss: 2.169178490837415

Epoch: 5| Step: 6
Training loss: 0.8989394307136536
Validation loss: 2.1508593608935676

Epoch: 5| Step: 7
Training loss: 1.3656198978424072
Validation loss: 2.2040877987941108

Epoch: 5| Step: 8
Training loss: 0.8494450449943542
Validation loss: 2.155739809075991

Epoch: 5| Step: 9
Training loss: 0.9307592511177063
Validation loss: 2.2140850027402244

Epoch: 5| Step: 10
Training loss: 0.6871469020843506
Validation loss: 2.268598342935244

Epoch: 5| Step: 11
Training loss: 0.47047173976898193
Validation loss: 2.2539386649926505

Epoch: 434| Step: 0
Training loss: 0.9818276166915894
Validation loss: 2.2424623171488443

Epoch: 5| Step: 1
Training loss: 0.7637879252433777
Validation loss: 2.253938967982928

Epoch: 5| Step: 2
Training loss: 0.6333835124969482
Validation loss: 2.289911558230718

Epoch: 5| Step: 3
Training loss: 0.5943028330802917
Validation loss: 2.286012997229894

Epoch: 5| Step: 4
Training loss: 0.6383844017982483
Validation loss: 2.26943809290727

Epoch: 5| Step: 5
Training loss: 1.663240671157837
Validation loss: 2.246932109196981

Epoch: 5| Step: 6
Training loss: 1.066162347793579
Validation loss: 2.273321717977524

Epoch: 5| Step: 7
Training loss: 1.283077359199524
Validation loss: 2.2161716520786285

Epoch: 5| Step: 8
Training loss: 0.7762276530265808
Validation loss: 2.210593193769455

Epoch: 5| Step: 9
Training loss: 0.7777212858200073
Validation loss: 2.233702758948008

Epoch: 5| Step: 10
Training loss: 0.5424970984458923
Validation loss: 2.197001576423645

Epoch: 5| Step: 11
Training loss: 1.0963103771209717
Validation loss: 2.262367198864619

Epoch: 435| Step: 0
Training loss: 1.2163764238357544
Validation loss: 2.2678176860014596

Epoch: 5| Step: 1
Training loss: 0.7581131458282471
Validation loss: 2.2386465718348822

Epoch: 5| Step: 2
Training loss: 0.7387886047363281
Validation loss: 2.2141164441903434

Epoch: 5| Step: 3
Training loss: 0.7379781603813171
Validation loss: 2.159444416562716

Epoch: 5| Step: 4
Training loss: 1.6135886907577515
Validation loss: 2.2162453532218933

Epoch: 5| Step: 5
Training loss: 0.6233307123184204
Validation loss: 2.152044360836347

Epoch: 5| Step: 6
Training loss: 0.5527973175048828
Validation loss: 2.1781538228193917

Epoch: 5| Step: 7
Training loss: 0.867972195148468
Validation loss: 2.126179983218511

Epoch: 5| Step: 8
Training loss: 0.5528475642204285
Validation loss: 2.124140977859497

Epoch: 5| Step: 9
Training loss: 1.0370447635650635
Validation loss: 2.1567400842905045

Epoch: 5| Step: 10
Training loss: 0.53790283203125
Validation loss: 2.1490971048672995

Epoch: 5| Step: 11
Training loss: 1.6115747690200806
Validation loss: 2.1639591604471207

Epoch: 436| Step: 0
Training loss: 0.3569257855415344
Validation loss: 2.1750738819440207

Epoch: 5| Step: 1
Training loss: 1.7380599975585938
Validation loss: 2.159096285700798

Epoch: 5| Step: 2
Training loss: 1.038620948791504
Validation loss: 2.199541613459587

Epoch: 5| Step: 3
Training loss: 0.6747040152549744
Validation loss: 2.1451420734326043

Epoch: 5| Step: 4
Training loss: 1.10146963596344
Validation loss: 2.153923064470291

Epoch: 5| Step: 5
Training loss: 0.9028249979019165
Validation loss: 2.1385743816693625

Epoch: 5| Step: 6
Training loss: 0.5350574851036072
Validation loss: 2.10885950922966

Epoch: 5| Step: 7
Training loss: 0.5919464826583862
Validation loss: 2.199841092030207

Epoch: 5| Step: 8
Training loss: 0.7508989572525024
Validation loss: 2.17848572631677

Epoch: 5| Step: 9
Training loss: 0.7188135981559753
Validation loss: 2.1905796428521476

Epoch: 5| Step: 10
Training loss: 0.6466907262802124
Validation loss: 2.2146749595801034

Epoch: 5| Step: 11
Training loss: 1.178614854812622
Validation loss: 2.2046651542186737

Epoch: 437| Step: 0
Training loss: 0.9558671116828918
Validation loss: 2.2204300860563913

Epoch: 5| Step: 1
Training loss: 0.5455540418624878
Validation loss: 2.236702119310697

Epoch: 5| Step: 2
Training loss: 0.8362624049186707
Validation loss: 2.1977431376775107

Epoch: 5| Step: 3
Training loss: 0.8140754699707031
Validation loss: 2.252672935525576

Epoch: 5| Step: 4
Training loss: 0.989799976348877
Validation loss: 2.221197326978048

Epoch: 5| Step: 5
Training loss: 1.3555737733840942
Validation loss: 2.203479588031769

Epoch: 5| Step: 6
Training loss: 0.6751569509506226
Validation loss: 2.2213363349437714

Epoch: 5| Step: 7
Training loss: 0.5826758146286011
Validation loss: 2.254384527603785

Epoch: 5| Step: 8
Training loss: 1.0454579591751099
Validation loss: 2.186134378115336

Epoch: 5| Step: 9
Training loss: 0.6518057584762573
Validation loss: 2.261571009953817

Epoch: 5| Step: 10
Training loss: 0.8118329048156738
Validation loss: 2.2635566095511117

Epoch: 5| Step: 11
Training loss: 0.9029385447502136
Validation loss: 2.2130761543909707

Epoch: 438| Step: 0
Training loss: 0.8275111317634583
Validation loss: 2.2401218712329865

Epoch: 5| Step: 1
Training loss: 0.9279400110244751
Validation loss: 2.2330476343631744

Epoch: 5| Step: 2
Training loss: 0.8729041218757629
Validation loss: 2.2125196307897568

Epoch: 5| Step: 3
Training loss: 0.5476733446121216
Validation loss: 2.2285301287968955

Epoch: 5| Step: 4
Training loss: 0.8789370656013489
Validation loss: 2.1466956635316214

Epoch: 5| Step: 5
Training loss: 0.5279804468154907
Validation loss: 2.166467393438021

Epoch: 5| Step: 6
Training loss: 0.765069842338562
Validation loss: 2.2039091984430947

Epoch: 5| Step: 7
Training loss: 0.9919236898422241
Validation loss: 2.135703523953756

Epoch: 5| Step: 8
Training loss: 0.6977609992027283
Validation loss: 2.135577291250229

Epoch: 5| Step: 9
Training loss: 1.1976796388626099
Validation loss: 2.114203691482544

Epoch: 5| Step: 10
Training loss: 0.9743820428848267
Validation loss: 2.1956517895062766

Epoch: 5| Step: 11
Training loss: 0.9353699684143066
Validation loss: 2.1610166132450104

Epoch: 439| Step: 0
Training loss: 0.8596292734146118
Validation loss: 2.1817229290803275

Epoch: 5| Step: 1
Training loss: 0.6900196075439453
Validation loss: 2.240254064400991

Epoch: 5| Step: 2
Training loss: 0.9411689043045044
Validation loss: 2.2216465771198273

Epoch: 5| Step: 3
Training loss: 0.8053756952285767
Validation loss: 2.2303967674573264

Epoch: 5| Step: 4
Training loss: 0.8943294286727905
Validation loss: 2.1517324397961297

Epoch: 5| Step: 5
Training loss: 0.5825868248939514
Validation loss: 2.1797195871671042

Epoch: 5| Step: 6
Training loss: 1.0201524496078491
Validation loss: 2.155917853116989

Epoch: 5| Step: 7
Training loss: 1.0489275455474854
Validation loss: 2.1935015469789505

Epoch: 5| Step: 8
Training loss: 0.9048084020614624
Validation loss: 2.2211039463678994

Epoch: 5| Step: 9
Training loss: 0.5466846227645874
Validation loss: 2.1756384472052255

Epoch: 5| Step: 10
Training loss: 1.0119508504867554
Validation loss: 2.1937412718931832

Epoch: 5| Step: 11
Training loss: 0.6496379375457764
Validation loss: 2.1562006076176963

Epoch: 440| Step: 0
Training loss: 0.6307637095451355
Validation loss: 2.150857816139857

Epoch: 5| Step: 1
Training loss: 0.7665766477584839
Validation loss: 2.157946909467379

Epoch: 5| Step: 2
Training loss: 0.69444340467453
Validation loss: 2.1652144342660904

Epoch: 5| Step: 3
Training loss: 0.7628124952316284
Validation loss: 2.1342463195323944

Epoch: 5| Step: 4
Training loss: 1.9375412464141846
Validation loss: 2.1460650712251663

Epoch: 5| Step: 5
Training loss: 0.6726644039154053
Validation loss: 2.1344909568627677

Epoch: 5| Step: 6
Training loss: 1.086491584777832
Validation loss: 2.1482495069503784

Epoch: 5| Step: 7
Training loss: 0.7944870591163635
Validation loss: 2.1828649193048477

Epoch: 5| Step: 8
Training loss: 1.18218994140625
Validation loss: 2.1635724107424417

Epoch: 5| Step: 9
Training loss: 0.7027028203010559
Validation loss: 2.2287676334381104

Epoch: 5| Step: 10
Training loss: 0.6852315664291382
Validation loss: 2.283959304292997

Epoch: 5| Step: 11
Training loss: 0.7897309064865112
Validation loss: 2.2462672342856727

Epoch: 441| Step: 0
Training loss: 0.8407332301139832
Validation loss: 2.339262147744497

Epoch: 5| Step: 1
Training loss: 0.49315136671066284
Validation loss: 2.240073333183924

Epoch: 5| Step: 2
Training loss: 0.7693454027175903
Validation loss: 2.263387138644854

Epoch: 5| Step: 3
Training loss: 1.1793352365493774
Validation loss: 2.2749496599038443

Epoch: 5| Step: 4
Training loss: 0.8755030632019043
Validation loss: 2.2751712600390115

Epoch: 5| Step: 5
Training loss: 0.7400612831115723
Validation loss: 2.2388796508312225

Epoch: 5| Step: 6
Training loss: 0.7683573961257935
Validation loss: 2.2443037182092667

Epoch: 5| Step: 7
Training loss: 0.8425911664962769
Validation loss: 2.2506496558586755

Epoch: 5| Step: 8
Training loss: 1.1266319751739502
Validation loss: 2.229320208231608

Epoch: 5| Step: 9
Training loss: 1.0051017999649048
Validation loss: 2.1852772931257882

Epoch: 5| Step: 10
Training loss: 0.6713145971298218
Validation loss: 2.145747443040212

Epoch: 5| Step: 11
Training loss: 0.283644437789917
Validation loss: 2.121287554502487

Epoch: 442| Step: 0
Training loss: 0.9047290682792664
Validation loss: 2.10444508989652

Epoch: 5| Step: 1
Training loss: 0.6888958215713501
Validation loss: 2.138827701409658

Epoch: 5| Step: 2
Training loss: 1.4162458181381226
Validation loss: 2.0937020728985467

Epoch: 5| Step: 3
Training loss: 1.132587194442749
Validation loss: 2.0819495022296906

Epoch: 5| Step: 4
Training loss: 0.5765708684921265
Validation loss: 2.1225223739941916

Epoch: 5| Step: 5
Training loss: 0.6566687226295471
Validation loss: 2.16763836145401

Epoch: 5| Step: 6
Training loss: 1.2565733194351196
Validation loss: 2.1362398167451224

Epoch: 5| Step: 7
Training loss: 1.02190101146698
Validation loss: 2.18479090432326

Epoch: 5| Step: 8
Training loss: 0.4199616312980652
Validation loss: 2.1942848563194275

Epoch: 5| Step: 9
Training loss: 0.8414775729179382
Validation loss: 2.249150797724724

Epoch: 5| Step: 10
Training loss: 0.6003367304801941
Validation loss: 2.1996948271989822

Epoch: 5| Step: 11
Training loss: 0.2780800461769104
Validation loss: 2.262748892108599

Epoch: 443| Step: 0
Training loss: 0.3875120282173157
Validation loss: 2.2589332262674966

Epoch: 5| Step: 1
Training loss: 0.7981972694396973
Validation loss: 2.2115101317564645

Epoch: 5| Step: 2
Training loss: 1.0975555181503296
Validation loss: 2.22778291006883

Epoch: 5| Step: 3
Training loss: 0.6556025743484497
Validation loss: 2.253119463721911

Epoch: 5| Step: 4
Training loss: 0.8531630635261536
Validation loss: 2.2477953135967255

Epoch: 5| Step: 5
Training loss: 1.1552561521530151
Validation loss: 2.2034447540839515

Epoch: 5| Step: 6
Training loss: 0.8709419369697571
Validation loss: 2.225889042019844

Epoch: 5| Step: 7
Training loss: 0.6718577146530151
Validation loss: 2.207495853304863

Epoch: 5| Step: 8
Training loss: 1.1033577919006348
Validation loss: 2.2336545487244925

Epoch: 5| Step: 9
Training loss: 0.4388549327850342
Validation loss: 2.2054561177889505

Epoch: 5| Step: 10
Training loss: 0.6703180074691772
Validation loss: 2.227961987257004

Epoch: 5| Step: 11
Training loss: 0.3956718444824219
Validation loss: 2.223873799045881

Epoch: 444| Step: 0
Training loss: 0.760360598564148
Validation loss: 2.2366749346256256

Epoch: 5| Step: 1
Training loss: 0.9526188969612122
Validation loss: 2.1829877495765686

Epoch: 5| Step: 2
Training loss: 0.6811093688011169
Validation loss: 2.1905186027288437

Epoch: 5| Step: 3
Training loss: 0.5940680503845215
Validation loss: 2.215556720892588

Epoch: 5| Step: 4
Training loss: 1.0619083642959595
Validation loss: 2.1612794448932013

Epoch: 5| Step: 5
Training loss: 0.8102205395698547
Validation loss: 2.1213850378990173

Epoch: 5| Step: 6
Training loss: 0.6922169923782349
Validation loss: 2.182138353586197

Epoch: 5| Step: 7
Training loss: 0.7200137376785278
Validation loss: 2.252480372786522

Epoch: 5| Step: 8
Training loss: 0.7551213502883911
Validation loss: 2.280206630627314

Epoch: 5| Step: 9
Training loss: 0.6934559941291809
Validation loss: 2.3023621886968613

Epoch: 5| Step: 10
Training loss: 1.2112404108047485
Validation loss: 2.2515656451384225

Epoch: 5| Step: 11
Training loss: 0.31922852993011475
Validation loss: 2.180916259686152

Epoch: 445| Step: 0
Training loss: 0.9392592310905457
Validation loss: 2.152549520134926

Epoch: 5| Step: 1
Training loss: 0.7000712156295776
Validation loss: 2.2173179984092712

Epoch: 5| Step: 2
Training loss: 0.6860250234603882
Validation loss: 2.1890295247236886

Epoch: 5| Step: 3
Training loss: 0.748724102973938
Validation loss: 2.204649567604065

Epoch: 5| Step: 4
Training loss: 0.8363302946090698
Validation loss: 2.22165247797966

Epoch: 5| Step: 5
Training loss: 0.7110670804977417
Validation loss: 2.1777761429548264

Epoch: 5| Step: 6
Training loss: 0.7843515872955322
Validation loss: 2.2004101127386093

Epoch: 5| Step: 7
Training loss: 1.1242539882659912
Validation loss: 2.182659536600113

Epoch: 5| Step: 8
Training loss: 0.42456093430519104
Validation loss: 2.1532504558563232

Epoch: 5| Step: 9
Training loss: 0.6023417711257935
Validation loss: 2.185437887907028

Epoch: 5| Step: 10
Training loss: 0.9160653948783875
Validation loss: 2.166999946037928

Epoch: 5| Step: 11
Training loss: 0.6817971467971802
Validation loss: 2.1735527366399765

Epoch: 446| Step: 0
Training loss: 0.5235599279403687
Validation loss: 2.156945457061132

Epoch: 5| Step: 1
Training loss: 0.5939517021179199
Validation loss: 2.19558518131574

Epoch: 5| Step: 2
Training loss: 0.5945319533348083
Validation loss: 2.1544080525636673

Epoch: 5| Step: 3
Training loss: 1.097452998161316
Validation loss: 2.2134249160687127

Epoch: 5| Step: 4
Training loss: 0.6079925298690796
Validation loss: 2.2117735793193183

Epoch: 5| Step: 5
Training loss: 0.7363074421882629
Validation loss: 2.2031967093547187

Epoch: 5| Step: 6
Training loss: 0.7564079165458679
Validation loss: 2.1997905174891152

Epoch: 5| Step: 7
Training loss: 0.6744979023933411
Validation loss: 2.2888249258200326

Epoch: 5| Step: 8
Training loss: 0.8471210598945618
Validation loss: 2.218963399529457

Epoch: 5| Step: 9
Training loss: 1.2277519702911377
Validation loss: 2.2720987300078073

Epoch: 5| Step: 10
Training loss: 0.9171534776687622
Validation loss: 2.2255897521972656

Epoch: 5| Step: 11
Training loss: 0.6074666380882263
Validation loss: 2.2311413437128067

Epoch: 447| Step: 0
Training loss: 0.5687100291252136
Validation loss: 2.198568031191826

Epoch: 5| Step: 1
Training loss: 0.6950348019599915
Validation loss: 2.2357678711414337

Epoch: 5| Step: 2
Training loss: 1.0168763399124146
Validation loss: 2.201658527056376

Epoch: 5| Step: 3
Training loss: 0.8193904757499695
Validation loss: 2.193075736363729

Epoch: 5| Step: 4
Training loss: 0.9353247880935669
Validation loss: 2.241978863875071

Epoch: 5| Step: 5
Training loss: 0.9566168785095215
Validation loss: 2.2221797704696655

Epoch: 5| Step: 6
Training loss: 0.6400224566459656
Validation loss: 2.165550818045934

Epoch: 5| Step: 7
Training loss: 0.7236244082450867
Validation loss: 2.1868515014648438

Epoch: 5| Step: 8
Training loss: 1.071665644645691
Validation loss: 2.2112025370200477

Epoch: 5| Step: 9
Training loss: 0.5684049129486084
Validation loss: 2.150334343314171

Epoch: 5| Step: 10
Training loss: 0.8306768536567688
Validation loss: 2.2136974334716797

Epoch: 5| Step: 11
Training loss: 0.35030999779701233
Validation loss: 2.244583636522293

Epoch: 448| Step: 0
Training loss: 1.3141051530838013
Validation loss: 2.167678783337275

Epoch: 5| Step: 1
Training loss: 0.9845955967903137
Validation loss: 2.224450240532557

Epoch: 5| Step: 2
Training loss: 0.6728611588478088
Validation loss: 2.203610877195994

Epoch: 5| Step: 3
Training loss: 0.9010318517684937
Validation loss: 2.227035701274872

Epoch: 5| Step: 4
Training loss: 0.5170565247535706
Validation loss: 2.1784482846657434

Epoch: 5| Step: 5
Training loss: 0.9429327249526978
Validation loss: 2.158559873700142

Epoch: 5| Step: 6
Training loss: 0.9981523752212524
Validation loss: 2.1868095099925995

Epoch: 5| Step: 7
Training loss: 0.7100051641464233
Validation loss: 2.12808029850324

Epoch: 5| Step: 8
Training loss: 0.850878894329071
Validation loss: 2.172008146842321

Epoch: 5| Step: 9
Training loss: 0.9536508321762085
Validation loss: 2.1306574791669846

Epoch: 5| Step: 10
Training loss: 0.8916810750961304
Validation loss: 2.1258941938479743

Epoch: 5| Step: 11
Training loss: 0.36156415939331055
Validation loss: 2.1516794115304947

Epoch: 449| Step: 0
Training loss: 0.9562287330627441
Validation loss: 2.12951198220253

Epoch: 5| Step: 1
Training loss: 0.6597737073898315
Validation loss: 2.1550782124201455

Epoch: 5| Step: 2
Training loss: 0.4373859465122223
Validation loss: 2.151276091734568

Epoch: 5| Step: 3
Training loss: 0.726271390914917
Validation loss: 2.1891358345746994

Epoch: 5| Step: 4
Training loss: 0.31539028882980347
Validation loss: 2.1996962626775107

Epoch: 5| Step: 5
Training loss: 0.7743952870368958
Validation loss: 2.1937899192174277

Epoch: 5| Step: 6
Training loss: 1.3152481317520142
Validation loss: 2.1598175515731177

Epoch: 5| Step: 7
Training loss: 1.0859558582305908
Validation loss: 2.2191021740436554

Epoch: 5| Step: 8
Training loss: 0.7403284907341003
Validation loss: 2.173233136534691

Epoch: 5| Step: 9
Training loss: 0.7018077969551086
Validation loss: 2.2520883977413177

Epoch: 5| Step: 10
Training loss: 1.0834739208221436
Validation loss: 2.2611345698436103

Epoch: 5| Step: 11
Training loss: 0.49616193771362305
Validation loss: 2.2304153442382812

Epoch: 450| Step: 0
Training loss: 0.8429255485534668
Validation loss: 2.2313568393389382

Epoch: 5| Step: 1
Training loss: 0.9004513621330261
Validation loss: 2.2006157288948693

Epoch: 5| Step: 2
Training loss: 0.8002683520317078
Validation loss: 2.2508261799812317

Epoch: 5| Step: 3
Training loss: 0.7734845876693726
Validation loss: 2.191851099332174

Epoch: 5| Step: 4
Training loss: 0.7088842391967773
Validation loss: 2.1826332360506058

Epoch: 5| Step: 5
Training loss: 0.49567222595214844
Validation loss: 2.172425299882889

Epoch: 5| Step: 6
Training loss: 1.0817428827285767
Validation loss: 2.2021827499071756

Epoch: 5| Step: 7
Training loss: 0.5175524950027466
Validation loss: 2.1562618017196655

Epoch: 5| Step: 8
Training loss: 0.6982093453407288
Validation loss: 2.1819709738095603

Epoch: 5| Step: 9
Training loss: 0.9449805021286011
Validation loss: 2.2055487781763077

Epoch: 5| Step: 10
Training loss: 0.28852301836013794
Validation loss: 2.136677493651708

Epoch: 5| Step: 11
Training loss: 0.6378986835479736
Validation loss: 2.190694888432821

Epoch: 451| Step: 0
Training loss: 1.003304362297058
Validation loss: 2.216291675964991

Epoch: 5| Step: 1
Training loss: 0.6146257519721985
Validation loss: 2.1614210506280265

Epoch: 5| Step: 2
Training loss: 0.4806141257286072
Validation loss: 2.195283522208532

Epoch: 5| Step: 3
Training loss: 1.1620852947235107
Validation loss: 2.1508747388919196

Epoch: 5| Step: 4
Training loss: 0.6998580694198608
Validation loss: 2.1847300678491592

Epoch: 5| Step: 5
Training loss: 0.8231026530265808
Validation loss: 2.1440008133649826

Epoch: 5| Step: 6
Training loss: 0.9137258529663086
Validation loss: 2.0874059597651162

Epoch: 5| Step: 7
Training loss: 0.7082705497741699
Validation loss: 2.123738850156466

Epoch: 5| Step: 8
Training loss: 0.6636286377906799
Validation loss: 2.177406599124273

Epoch: 5| Step: 9
Training loss: 0.9798834919929504
Validation loss: 2.1854706158240638

Epoch: 5| Step: 10
Training loss: 0.5420273542404175
Validation loss: 2.143340806166331

Epoch: 5| Step: 11
Training loss: 0.5864994525909424
Validation loss: 2.1781351268291473

Epoch: 452| Step: 0
Training loss: 0.6933333277702332
Validation loss: 2.2033066103855767

Epoch: 5| Step: 1
Training loss: 0.9317261576652527
Validation loss: 2.245220253864924

Epoch: 5| Step: 2
Training loss: 0.5629581212997437
Validation loss: 2.2410947680473328

Epoch: 5| Step: 3
Training loss: 0.6855553388595581
Validation loss: 2.176578571399053

Epoch: 5| Step: 4
Training loss: 1.2301578521728516
Validation loss: 2.1499131321907043

Epoch: 5| Step: 5
Training loss: 0.4140907824039459
Validation loss: 2.1383645236492157

Epoch: 5| Step: 6
Training loss: 0.9529606103897095
Validation loss: 2.108154604832331

Epoch: 5| Step: 7
Training loss: 0.42840614914894104
Validation loss: 2.1425079653660455

Epoch: 5| Step: 8
Training loss: 0.9068354368209839
Validation loss: 2.175587445497513

Epoch: 5| Step: 9
Training loss: 0.5868114233016968
Validation loss: 2.1656326254208884

Epoch: 5| Step: 10
Training loss: 0.7144408822059631
Validation loss: 2.142209748427073

Epoch: 5| Step: 11
Training loss: 0.6831856369972229
Validation loss: 2.1711838096380234

Epoch: 453| Step: 0
Training loss: 0.6982361674308777
Validation loss: 2.1718529164791107

Epoch: 5| Step: 1
Training loss: 0.3941548466682434
Validation loss: 2.1957221180200577

Epoch: 5| Step: 2
Training loss: 0.6864908933639526
Validation loss: 2.214648182193438

Epoch: 5| Step: 3
Training loss: 0.7407456040382385
Validation loss: 2.1996262470881143

Epoch: 5| Step: 4
Training loss: 0.5153230428695679
Validation loss: 2.200239896774292

Epoch: 5| Step: 5
Training loss: 0.8792415857315063
Validation loss: 2.1797053714593253

Epoch: 5| Step: 6
Training loss: 1.3243478536605835
Validation loss: 2.2375538299481073

Epoch: 5| Step: 7
Training loss: 0.7302274107933044
Validation loss: 2.2341945668061576

Epoch: 5| Step: 8
Training loss: 0.9166538119316101
Validation loss: 2.2256690760453544

Epoch: 5| Step: 9
Training loss: 0.8630860447883606
Validation loss: 2.1999464879433313

Epoch: 5| Step: 10
Training loss: 0.5994907021522522
Validation loss: 2.195394550760587

Epoch: 5| Step: 11
Training loss: 0.2365456521511078
Validation loss: 2.16696859896183

Epoch: 454| Step: 0
Training loss: 1.0062220096588135
Validation loss: 2.1846656501293182

Epoch: 5| Step: 1
Training loss: 0.584712028503418
Validation loss: 2.126846561829249

Epoch: 5| Step: 2
Training loss: 0.7589121460914612
Validation loss: 2.1900869558254876

Epoch: 5| Step: 3
Training loss: 0.5218676328659058
Validation loss: 2.1430868953466415

Epoch: 5| Step: 4
Training loss: 0.8851958513259888
Validation loss: 2.178734620412191

Epoch: 5| Step: 5
Training loss: 0.8979049921035767
Validation loss: 2.1846294154723487

Epoch: 5| Step: 6
Training loss: 0.9083333015441895
Validation loss: 2.2221780866384506

Epoch: 5| Step: 7
Training loss: 0.7595093846321106
Validation loss: 2.172376106182734

Epoch: 5| Step: 8
Training loss: 0.9186996221542358
Validation loss: 2.191660816470782

Epoch: 5| Step: 9
Training loss: 0.4143836498260498
Validation loss: 2.163221552968025

Epoch: 5| Step: 10
Training loss: 0.9203739166259766
Validation loss: 2.2418582836786904

Epoch: 5| Step: 11
Training loss: 0.19655680656433105
Validation loss: 2.1899378150701523

Epoch: 455| Step: 0
Training loss: 0.8746424913406372
Validation loss: 2.214297592639923

Epoch: 5| Step: 1
Training loss: 1.3589403629302979
Validation loss: 2.2381164530913034

Epoch: 5| Step: 2
Training loss: 0.6990209817886353
Validation loss: 2.1652269065380096

Epoch: 5| Step: 3
Training loss: 0.6113817095756531
Validation loss: 2.234879126151403

Epoch: 5| Step: 4
Training loss: 0.5889517068862915
Validation loss: 2.176367705066999

Epoch: 5| Step: 5
Training loss: 0.5606998205184937
Validation loss: 2.1375808864831924

Epoch: 5| Step: 6
Training loss: 0.4594170153141022
Validation loss: 2.1915331731239953

Epoch: 5| Step: 7
Training loss: 0.9045411944389343
Validation loss: 2.1137326508760452

Epoch: 5| Step: 8
Training loss: 0.6824803352355957
Validation loss: 2.176122566064199

Epoch: 5| Step: 9
Training loss: 0.48200517892837524
Validation loss: 2.1504965970913568

Epoch: 5| Step: 10
Training loss: 1.1858991384506226
Validation loss: 2.2133801778157554

Epoch: 5| Step: 11
Training loss: 0.4947589337825775
Validation loss: 2.194643681248029

Epoch: 456| Step: 0
Training loss: 0.6864984035491943
Validation loss: 2.2106421341498694

Epoch: 5| Step: 1
Training loss: 0.9140938520431519
Validation loss: 2.2963493317365646

Epoch: 5| Step: 2
Training loss: 0.8538471460342407
Validation loss: 2.2046206146478653

Epoch: 5| Step: 3
Training loss: 0.8119198083877563
Validation loss: 2.191441605488459

Epoch: 5| Step: 4
Training loss: 0.2553723454475403
Validation loss: 2.19651431341966

Epoch: 5| Step: 5
Training loss: 1.136031150817871
Validation loss: 2.2044633477926254

Epoch: 5| Step: 6
Training loss: 0.5185193419456482
Validation loss: 2.2249435732762017

Epoch: 5| Step: 7
Training loss: 0.8575292825698853
Validation loss: 2.249648481607437

Epoch: 5| Step: 8
Training loss: 0.5231152176856995
Validation loss: 2.2572190165519714

Epoch: 5| Step: 9
Training loss: 0.91736900806427
Validation loss: 2.245474418004354

Epoch: 5| Step: 10
Training loss: 0.7699142694473267
Validation loss: 2.2870212495326996

Epoch: 5| Step: 11
Training loss: 1.5417755842208862
Validation loss: 2.2473999758561454

Epoch: 457| Step: 0
Training loss: 0.9425451159477234
Validation loss: 2.2335170259078345

Epoch: 5| Step: 1
Training loss: 1.1798264980316162
Validation loss: 2.214584623773893

Epoch: 5| Step: 2
Training loss: 0.7127631902694702
Validation loss: 2.220695361495018

Epoch: 5| Step: 3
Training loss: 0.8522752523422241
Validation loss: 2.1419053226709366

Epoch: 5| Step: 4
Training loss: 0.7635571956634521
Validation loss: 2.1561665534973145

Epoch: 5| Step: 5
Training loss: 0.8988510370254517
Validation loss: 2.111542671918869

Epoch: 5| Step: 6
Training loss: 0.41588258743286133
Validation loss: 2.160178621610006

Epoch: 5| Step: 7
Training loss: 0.6837050914764404
Validation loss: 2.1537780364354453

Epoch: 5| Step: 8
Training loss: 1.067784070968628
Validation loss: 2.1754745145638785

Epoch: 5| Step: 9
Training loss: 0.4657011032104492
Validation loss: 2.1614722857872644

Epoch: 5| Step: 10
Training loss: 0.5607621073722839
Validation loss: 2.1750794549783072

Epoch: 5| Step: 11
Training loss: 1.4158068895339966
Validation loss: 2.159934341907501

Epoch: 458| Step: 0
Training loss: 0.8123151063919067
Validation loss: 2.2368445694446564

Epoch: 5| Step: 1
Training loss: 0.3267360031604767
Validation loss: 2.213753859202067

Epoch: 5| Step: 2
Training loss: 0.6234930753707886
Validation loss: 2.1875732441743216

Epoch: 5| Step: 3
Training loss: 0.8773722648620605
Validation loss: 2.1939197232325873

Epoch: 5| Step: 4
Training loss: 0.9066356420516968
Validation loss: 2.206490476926168

Epoch: 5| Step: 5
Training loss: 0.6851082444190979
Validation loss: 2.2450164953867593

Epoch: 5| Step: 6
Training loss: 0.4252384305000305
Validation loss: 2.265224983294805

Epoch: 5| Step: 7
Training loss: 0.8219555616378784
Validation loss: 2.247183938821157

Epoch: 5| Step: 8
Training loss: 0.3936212658882141
Validation loss: 2.235660339395205

Epoch: 5| Step: 9
Training loss: 1.2743836641311646
Validation loss: 2.217575266957283

Epoch: 5| Step: 10
Training loss: 1.082384705543518
Validation loss: 2.1556589802106223

Epoch: 5| Step: 11
Training loss: 0.24717414379119873
Validation loss: 2.1590090543031693

Epoch: 459| Step: 0
Training loss: 1.3812460899353027
Validation loss: 2.174529885252317

Epoch: 5| Step: 1
Training loss: 0.6942605972290039
Validation loss: 2.1456662664810815

Epoch: 5| Step: 2
Training loss: 0.7673428058624268
Validation loss: 2.1457305550575256

Epoch: 5| Step: 3
Training loss: 0.5330977439880371
Validation loss: 2.1660099228223166

Epoch: 5| Step: 4
Training loss: 0.4730061888694763
Validation loss: 2.1598403801520667

Epoch: 5| Step: 5
Training loss: 0.7028781175613403
Validation loss: 2.1534051845471063

Epoch: 5| Step: 6
Training loss: 0.45431503653526306
Validation loss: 2.2034709453582764

Epoch: 5| Step: 7
Training loss: 1.0240678787231445
Validation loss: 2.2110506892204285

Epoch: 5| Step: 8
Training loss: 0.7711049318313599
Validation loss: 2.2316380739212036

Epoch: 5| Step: 9
Training loss: 0.7170795202255249
Validation loss: 2.179572820663452

Epoch: 5| Step: 10
Training loss: 0.6482707262039185
Validation loss: 2.2115589131911597

Epoch: 5| Step: 11
Training loss: 0.32590872049331665
Validation loss: 2.225770761569341

Epoch: 460| Step: 0
Training loss: 0.6020007729530334
Validation loss: 2.2276292194922767

Epoch: 5| Step: 1
Training loss: 0.6602122187614441
Validation loss: 2.202210987607638

Epoch: 5| Step: 2
Training loss: 0.7445157170295715
Validation loss: 2.2461159974336624

Epoch: 5| Step: 3
Training loss: 1.0275160074234009
Validation loss: 2.2350972394148507

Epoch: 5| Step: 4
Training loss: 0.507964551448822
Validation loss: 2.2532144337892532

Epoch: 5| Step: 5
Training loss: 0.8217283487319946
Validation loss: 2.17173699537913

Epoch: 5| Step: 6
Training loss: 0.36414864659309387
Validation loss: 2.193927119175593

Epoch: 5| Step: 7
Training loss: 0.8660279512405396
Validation loss: 2.21536186337471

Epoch: 5| Step: 8
Training loss: 0.6684810519218445
Validation loss: 2.1452792485555015

Epoch: 5| Step: 9
Training loss: 1.1874291896820068
Validation loss: 2.1878617902596793

Epoch: 5| Step: 10
Training loss: 0.4861389994621277
Validation loss: 2.132791062196096

Epoch: 5| Step: 11
Training loss: 0.25594910979270935
Validation loss: 2.128571256995201

Epoch: 461| Step: 0
Training loss: 0.4545425474643707
Validation loss: 2.1747384468714395

Epoch: 5| Step: 1
Training loss: 0.6978391408920288
Validation loss: 2.1374499996503196

Epoch: 5| Step: 2
Training loss: 0.7039145231246948
Validation loss: 2.1208625187476478

Epoch: 5| Step: 3
Training loss: 0.590094804763794
Validation loss: 2.1240296910206475

Epoch: 5| Step: 4
Training loss: 0.5628088712692261
Validation loss: 2.1450262467066445

Epoch: 5| Step: 5
Training loss: 0.9649801254272461
Validation loss: 2.1817340155442557

Epoch: 5| Step: 6
Training loss: 0.6969720125198364
Validation loss: 2.176881412665049

Epoch: 5| Step: 7
Training loss: 0.6118820905685425
Validation loss: 2.213101014494896

Epoch: 5| Step: 8
Training loss: 0.964924693107605
Validation loss: 2.1737173199653625

Epoch: 5| Step: 9
Training loss: 0.946463942527771
Validation loss: 2.1520880113045373

Epoch: 5| Step: 10
Training loss: 0.32476359605789185
Validation loss: 2.197295551498731

Epoch: 5| Step: 11
Training loss: 0.24105501174926758
Validation loss: 2.138850082953771

Epoch: 462| Step: 0
Training loss: 0.8345483541488647
Validation loss: 2.1671936263640723

Epoch: 5| Step: 1
Training loss: 0.5839917659759521
Validation loss: 2.1578783988952637

Epoch: 5| Step: 2
Training loss: 1.082460880279541
Validation loss: 2.155141919851303

Epoch: 5| Step: 3
Training loss: 0.8346391916275024
Validation loss: 2.161219338575999

Epoch: 5| Step: 4
Training loss: 0.5251198410987854
Validation loss: 2.1490417470534644

Epoch: 5| Step: 5
Training loss: 0.7051839828491211
Validation loss: 2.1777620116869607

Epoch: 5| Step: 6
Training loss: 0.48327335715293884
Validation loss: 2.1328596671422324

Epoch: 5| Step: 7
Training loss: 0.5937196612358093
Validation loss: 2.0942181100447974

Epoch: 5| Step: 8
Training loss: 0.9886147379875183
Validation loss: 2.133965720733007

Epoch: 5| Step: 9
Training loss: 0.7628731727600098
Validation loss: 2.1411588390668235

Epoch: 5| Step: 10
Training loss: 0.4954821467399597
Validation loss: 2.133596653739611

Epoch: 5| Step: 11
Training loss: 0.3100508451461792
Validation loss: 2.164218654235204

Epoch: 463| Step: 0
Training loss: 1.2125916481018066
Validation loss: 2.1256665190060935

Epoch: 5| Step: 1
Training loss: 0.8546985387802124
Validation loss: 2.216100513935089

Epoch: 5| Step: 2
Training loss: 0.524253249168396
Validation loss: 2.1604584008455276

Epoch: 5| Step: 3
Training loss: 0.5187512040138245
Validation loss: 2.162204792102178

Epoch: 5| Step: 4
Training loss: 0.3806113302707672
Validation loss: 2.2119454542795816

Epoch: 5| Step: 5
Training loss: 0.4864397943019867
Validation loss: 2.2071329603592553

Epoch: 5| Step: 6
Training loss: 1.2774989604949951
Validation loss: 2.2574792305628457

Epoch: 5| Step: 7
Training loss: 0.7551963925361633
Validation loss: 2.16766390701135

Epoch: 5| Step: 8
Training loss: 0.9828359484672546
Validation loss: 2.22542213400205

Epoch: 5| Step: 9
Training loss: 0.5214029550552368
Validation loss: 2.18324742714564

Epoch: 5| Step: 10
Training loss: 1.1682385206222534
Validation loss: 2.1641053706407547

Epoch: 5| Step: 11
Training loss: 0.40911322832107544
Validation loss: 2.20121102531751

Epoch: 464| Step: 0
Training loss: 1.2141387462615967
Validation loss: 2.209272945920626

Epoch: 5| Step: 1
Training loss: 0.9050898551940918
Validation loss: 2.1962842692931495

Epoch: 5| Step: 2
Training loss: 0.6156443357467651
Validation loss: 2.1956325521071753

Epoch: 5| Step: 3
Training loss: 0.5054802894592285
Validation loss: 2.237521012624105

Epoch: 5| Step: 4
Training loss: 0.4129078984260559
Validation loss: 2.1510481933752694

Epoch: 5| Step: 5
Training loss: 0.4613494873046875
Validation loss: 2.196088890234629

Epoch: 5| Step: 6
Training loss: 0.477832555770874
Validation loss: 2.195442239443461

Epoch: 5| Step: 7
Training loss: 0.7806044816970825
Validation loss: 2.1600905855496726

Epoch: 5| Step: 8
Training loss: 1.1240055561065674
Validation loss: 2.1390348921219506

Epoch: 5| Step: 9
Training loss: 1.150195837020874
Validation loss: 2.1359446048736572

Epoch: 5| Step: 10
Training loss: 0.7313871383666992
Validation loss: 2.16581229865551

Epoch: 5| Step: 11
Training loss: 0.1982010304927826
Validation loss: 2.137115642428398

Epoch: 465| Step: 0
Training loss: 0.9097145795822144
Validation loss: 2.157222956418991

Epoch: 5| Step: 1
Training loss: 1.0460114479064941
Validation loss: 2.1432828505833945

Epoch: 5| Step: 2
Training loss: 0.4764479100704193
Validation loss: 2.182332217693329

Epoch: 5| Step: 3
Training loss: 0.9335702061653137
Validation loss: 2.1966137886047363

Epoch: 5| Step: 4
Training loss: 0.5581024289131165
Validation loss: 2.12478469312191

Epoch: 5| Step: 5
Training loss: 0.38456279039382935
Validation loss: 2.2324768751859665

Epoch: 5| Step: 6
Training loss: 0.7997208833694458
Validation loss: 2.1934376458326974

Epoch: 5| Step: 7
Training loss: 0.8378223180770874
Validation loss: 2.202594598134359

Epoch: 5| Step: 8
Training loss: 0.5778884887695312
Validation loss: 2.280036290486654

Epoch: 5| Step: 9
Training loss: 0.8080684542655945
Validation loss: 2.267835572361946

Epoch: 5| Step: 10
Training loss: 0.8758237957954407
Validation loss: 2.250613753994306

Epoch: 5| Step: 11
Training loss: 0.4562927782535553
Validation loss: 2.2146255671977997

Epoch: 466| Step: 0
Training loss: 0.40984487533569336
Validation loss: 2.1764234701792398

Epoch: 5| Step: 1
Training loss: 0.9537003636360168
Validation loss: 2.1984420468409858

Epoch: 5| Step: 2
Training loss: 0.6461438536643982
Validation loss: 2.194759741425514

Epoch: 5| Step: 3
Training loss: 1.044819951057434
Validation loss: 2.2099643498659134

Epoch: 5| Step: 4
Training loss: 1.349330186843872
Validation loss: 2.215328171849251

Epoch: 5| Step: 5
Training loss: 0.7812880277633667
Validation loss: 2.214925984541575

Epoch: 5| Step: 6
Training loss: 0.45789235830307007
Validation loss: 2.199870506922404

Epoch: 5| Step: 7
Training loss: 1.0951149463653564
Validation loss: 2.201892137527466

Epoch: 5| Step: 8
Training loss: 0.9012110829353333
Validation loss: 2.1901370783646903

Epoch: 5| Step: 9
Training loss: 0.5924395322799683
Validation loss: 2.1475728899240494

Epoch: 5| Step: 10
Training loss: 0.6193742156028748
Validation loss: 2.1163543413082757

Epoch: 5| Step: 11
Training loss: 0.5128285884857178
Validation loss: 2.090371862053871

Epoch: 467| Step: 0
Training loss: 0.9619914889335632
Validation loss: 2.1260505467653275

Epoch: 5| Step: 1
Training loss: 0.5982146263122559
Validation loss: 2.1467859894037247

Epoch: 5| Step: 2
Training loss: 0.5945747494697571
Validation loss: 2.1710849702358246

Epoch: 5| Step: 3
Training loss: 0.3864275813102722
Validation loss: 2.1776556173960366

Epoch: 5| Step: 4
Training loss: 0.52061927318573
Validation loss: 2.160438060760498

Epoch: 5| Step: 5
Training loss: 0.6155033111572266
Validation loss: 2.1713851491610208

Epoch: 5| Step: 6
Training loss: 1.12701416015625
Validation loss: 2.1440198570489883

Epoch: 5| Step: 7
Training loss: 1.2071378231048584
Validation loss: 2.16072386999925

Epoch: 5| Step: 8
Training loss: 0.904656708240509
Validation loss: 2.177351345618566

Epoch: 5| Step: 9
Training loss: 0.6722511053085327
Validation loss: 2.124922310312589

Epoch: 5| Step: 10
Training loss: 0.47845926880836487
Validation loss: 2.1188552528619766

Epoch: 5| Step: 11
Training loss: 0.20044255256652832
Validation loss: 2.131631006797155

Epoch: 468| Step: 0
Training loss: 0.5255175232887268
Validation loss: 2.103795657555262

Epoch: 5| Step: 1
Training loss: 0.9907954335212708
Validation loss: 2.111032838622729

Epoch: 5| Step: 2
Training loss: 0.5831578969955444
Validation loss: 2.0648310432831445

Epoch: 5| Step: 3
Training loss: 0.9356552362442017
Validation loss: 2.114397868514061

Epoch: 5| Step: 4
Training loss: 0.3405911922454834
Validation loss: 2.12366376320521

Epoch: 5| Step: 5
Training loss: 0.6689757108688354
Validation loss: 2.11947038769722

Epoch: 5| Step: 6
Training loss: 0.6336849331855774
Validation loss: 2.118166903654734

Epoch: 5| Step: 7
Training loss: 0.714372992515564
Validation loss: 2.0953540404637656

Epoch: 5| Step: 8
Training loss: 0.8045886158943176
Validation loss: 2.16538268327713

Epoch: 5| Step: 9
Training loss: 0.6588330864906311
Validation loss: 2.157289355993271

Epoch: 5| Step: 10
Training loss: 0.7521910071372986
Validation loss: 2.1689202884833017

Epoch: 5| Step: 11
Training loss: 0.38503026962280273
Validation loss: 2.1576364586750665

Epoch: 469| Step: 0
Training loss: 0.8487024307250977
Validation loss: 2.130984569589297

Epoch: 5| Step: 1
Training loss: 0.5997104644775391
Validation loss: 2.2196478247642517

Epoch: 5| Step: 2
Training loss: 0.8958624005317688
Validation loss: 2.1900151719649634

Epoch: 5| Step: 3
Training loss: 0.589096188545227
Validation loss: 2.1703381737073264

Epoch: 5| Step: 4
Training loss: 0.6754065752029419
Validation loss: 2.098557005325953

Epoch: 5| Step: 5
Training loss: 0.49111756682395935
Validation loss: 2.129946490128835

Epoch: 5| Step: 6
Training loss: 0.7801518440246582
Validation loss: 2.1620191782712936

Epoch: 5| Step: 7
Training loss: 1.0476195812225342
Validation loss: 2.1685675183931985

Epoch: 5| Step: 8
Training loss: 0.7737475037574768
Validation loss: 2.190290947755178

Epoch: 5| Step: 9
Training loss: 0.2651209831237793
Validation loss: 2.1129260758558908

Epoch: 5| Step: 10
Training loss: 1.0548704862594604
Validation loss: 2.132328083117803

Epoch: 5| Step: 11
Training loss: 0.5517042875289917
Validation loss: 2.1866012712319693

Epoch: 470| Step: 0
Training loss: 0.541190505027771
Validation loss: 2.156262328227361

Epoch: 5| Step: 1
Training loss: 0.6486139893531799
Validation loss: 2.0733043998479843

Epoch: 5| Step: 2
Training loss: 0.9154443740844727
Validation loss: 2.1651677787303925

Epoch: 5| Step: 3
Training loss: 0.6847493648529053
Validation loss: 2.1521174361308417

Epoch: 5| Step: 4
Training loss: 0.5534592270851135
Validation loss: 2.1443009078502655

Epoch: 5| Step: 5
Training loss: 0.9770599603652954
Validation loss: 2.1435604890187583

Epoch: 5| Step: 6
Training loss: 0.6748448610305786
Validation loss: 2.152233531077703

Epoch: 5| Step: 7
Training loss: 0.6300404667854309
Validation loss: 2.1612774481376014

Epoch: 5| Step: 8
Training loss: 0.716361939907074
Validation loss: 2.1053023785352707

Epoch: 5| Step: 9
Training loss: 0.5199476480484009
Validation loss: 2.144638697306315

Epoch: 5| Step: 10
Training loss: 1.1191494464874268
Validation loss: 2.1146969546874366

Epoch: 5| Step: 11
Training loss: 0.6344554424285889
Validation loss: 2.150827373067538

Epoch: 471| Step: 0
Training loss: 1.1937780380249023
Validation loss: 2.1628214617570243

Epoch: 5| Step: 1
Training loss: 0.5166719555854797
Validation loss: 2.1284593641757965

Epoch: 5| Step: 2
Training loss: 0.4239177703857422
Validation loss: 2.1813713113466897

Epoch: 5| Step: 3
Training loss: 0.43125420808792114
Validation loss: 2.2362748831510544

Epoch: 5| Step: 4
Training loss: 0.8622446060180664
Validation loss: 2.197415441274643

Epoch: 5| Step: 5
Training loss: 0.8707854151725769
Validation loss: 2.25931823750337

Epoch: 5| Step: 6
Training loss: 0.5590306520462036
Validation loss: 2.216123511393865

Epoch: 5| Step: 7
Training loss: 0.6836104393005371
Validation loss: 2.1863165348768234

Epoch: 5| Step: 8
Training loss: 0.7494828104972839
Validation loss: 2.191286027431488

Epoch: 5| Step: 9
Training loss: 0.7402366399765015
Validation loss: 2.2314539502064386

Epoch: 5| Step: 10
Training loss: 0.4020019471645355
Validation loss: 2.2249549428621926

Epoch: 5| Step: 11
Training loss: 1.9400275945663452
Validation loss: 2.219243804613749

Epoch: 472| Step: 0
Training loss: 0.3305134177207947
Validation loss: 2.2225643595059714

Epoch: 5| Step: 1
Training loss: 0.5944861173629761
Validation loss: 2.2170341114203134

Epoch: 5| Step: 2
Training loss: 0.9329147338867188
Validation loss: 2.235183854897817

Epoch: 5| Step: 3
Training loss: 0.9545363187789917
Validation loss: 2.1958376864592233

Epoch: 5| Step: 4
Training loss: 0.5663124322891235
Validation loss: 2.1905179768800735

Epoch: 5| Step: 5
Training loss: 0.7685779333114624
Validation loss: 2.1591639717419944

Epoch: 5| Step: 6
Training loss: 0.3128698468208313
Validation loss: 2.1621493150790534

Epoch: 5| Step: 7
Training loss: 0.994225025177002
Validation loss: 2.1160823653141656

Epoch: 5| Step: 8
Training loss: 1.0159000158309937
Validation loss: 2.147489761312803

Epoch: 5| Step: 9
Training loss: 0.47308605909347534
Validation loss: 2.1324640760819116

Epoch: 5| Step: 10
Training loss: 0.2654585838317871
Validation loss: 2.122400020559629

Epoch: 5| Step: 11
Training loss: 0.4609776735305786
Validation loss: 2.1565787295500436

Epoch: 473| Step: 0
Training loss: 0.33246397972106934
Validation loss: 2.114022140701612

Epoch: 5| Step: 1
Training loss: 0.3168369233608246
Validation loss: 2.0878953834374747

Epoch: 5| Step: 2
Training loss: 0.8100035786628723
Validation loss: 2.156509811679522

Epoch: 5| Step: 3
Training loss: 1.335410714149475
Validation loss: 2.1526668071746826

Epoch: 5| Step: 4
Training loss: 0.49081581830978394
Validation loss: 2.175798326730728

Epoch: 5| Step: 5
Training loss: 1.2219536304473877
Validation loss: 2.215256134668986

Epoch: 5| Step: 6
Training loss: 0.6527764201164246
Validation loss: 2.203844428062439

Epoch: 5| Step: 7
Training loss: 0.5209641456604004
Validation loss: 2.206888427337011

Epoch: 5| Step: 8
Training loss: 0.7067835927009583
Validation loss: 2.2030365268389382

Epoch: 5| Step: 9
Training loss: 1.068988561630249
Validation loss: 2.17153034110864

Epoch: 5| Step: 10
Training loss: 0.4781045913696289
Validation loss: 2.1208013047774634

Epoch: 5| Step: 11
Training loss: 1.3948489427566528
Validation loss: 2.172297308842341

Epoch: 474| Step: 0
Training loss: 0.8527328372001648
Validation loss: 2.1461615761121116

Epoch: 5| Step: 1
Training loss: 0.6697495579719543
Validation loss: 2.1488090554873147

Epoch: 5| Step: 2
Training loss: 0.7041599750518799
Validation loss: 2.108017692963282

Epoch: 5| Step: 3
Training loss: 0.7389106750488281
Validation loss: 2.0712307691574097

Epoch: 5| Step: 4
Training loss: 0.5371938347816467
Validation loss: 2.090652679403623

Epoch: 5| Step: 5
Training loss: 0.7975901365280151
Validation loss: 2.1178345680236816

Epoch: 5| Step: 6
Training loss: 0.5359259843826294
Validation loss: 2.1039604445298514

Epoch: 5| Step: 7
Training loss: 0.7886324524879456
Validation loss: 2.1189175645510354

Epoch: 5| Step: 8
Training loss: 0.6115759611129761
Validation loss: 2.12677493194739

Epoch: 5| Step: 9
Training loss: 0.9365106821060181
Validation loss: 2.1173561910788217

Epoch: 5| Step: 10
Training loss: 0.7796927690505981
Validation loss: 2.1363049497207007

Epoch: 5| Step: 11
Training loss: 0.3803083896636963
Validation loss: 2.130648617943128

Epoch: 475| Step: 0
Training loss: 0.46605342626571655
Validation loss: 2.1440508514642715

Epoch: 5| Step: 1
Training loss: 0.7146941423416138
Validation loss: 2.1833886404832206

Epoch: 5| Step: 2
Training loss: 0.754834771156311
Validation loss: 2.1600631773471832

Epoch: 5| Step: 3
Training loss: 0.36521196365356445
Validation loss: 2.1621708373228707

Epoch: 5| Step: 4
Training loss: 0.5199078321456909
Validation loss: 2.1928979406754174

Epoch: 5| Step: 5
Training loss: 1.0993990898132324
Validation loss: 2.150059516231219

Epoch: 5| Step: 6
Training loss: 0.5219871401786804
Validation loss: 2.175181195139885

Epoch: 5| Step: 7
Training loss: 0.5259162187576294
Validation loss: 2.1514215668042502

Epoch: 5| Step: 8
Training loss: 0.46578875184059143
Validation loss: 2.185943673054377

Epoch: 5| Step: 9
Training loss: 0.8327666521072388
Validation loss: 2.1593089501063027

Epoch: 5| Step: 10
Training loss: 0.8962501287460327
Validation loss: 2.1148813466231027

Epoch: 5| Step: 11
Training loss: 1.0660415887832642
Validation loss: 2.073772683739662

Epoch: 476| Step: 0
Training loss: 0.7623304128646851
Validation loss: 2.1044715891281762

Epoch: 5| Step: 1
Training loss: 0.5310239195823669
Validation loss: 2.1310171484947205

Epoch: 5| Step: 2
Training loss: 0.8255826234817505
Validation loss: 2.143419235944748

Epoch: 5| Step: 3
Training loss: 0.5048404932022095
Validation loss: 2.1594887177149453

Epoch: 5| Step: 4
Training loss: 0.9066213369369507
Validation loss: 2.1631341874599457

Epoch: 5| Step: 5
Training loss: 0.8563526272773743
Validation loss: 2.1365004231532416

Epoch: 5| Step: 6
Training loss: 0.7717780470848083
Validation loss: 2.123422304789225

Epoch: 5| Step: 7
Training loss: 0.8868347406387329
Validation loss: 2.0716995845238366

Epoch: 5| Step: 8
Training loss: 0.8387681841850281
Validation loss: 2.1240722636381784

Epoch: 5| Step: 9
Training loss: 0.41267961263656616
Validation loss: 2.090773344039917

Epoch: 5| Step: 10
Training loss: 0.8501570820808411
Validation loss: 2.1090810894966125

Epoch: 5| Step: 11
Training loss: 0.5836816430091858
Validation loss: 2.137841592232386

Epoch: 477| Step: 0
Training loss: 1.0034668445587158
Validation loss: 2.188891738653183

Epoch: 5| Step: 1
Training loss: 0.6946637034416199
Validation loss: 2.1467455128828683

Epoch: 5| Step: 2
Training loss: 0.8208843469619751
Validation loss: 2.1206113199392953

Epoch: 5| Step: 3
Training loss: 0.7124864459037781
Validation loss: 2.1565915445486703

Epoch: 5| Step: 4
Training loss: 0.45298129320144653
Validation loss: 2.1501854161421456

Epoch: 5| Step: 5
Training loss: 0.3924364149570465
Validation loss: 2.168665736913681

Epoch: 5| Step: 6
Training loss: 0.5455862283706665
Validation loss: 2.1295269081989923

Epoch: 5| Step: 7
Training loss: 0.9427531361579895
Validation loss: 2.134482522805532

Epoch: 5| Step: 8
Training loss: 0.5794830322265625
Validation loss: 2.097502132256826

Epoch: 5| Step: 9
Training loss: 0.7598743438720703
Validation loss: 2.12282041211923

Epoch: 5| Step: 10
Training loss: 0.5906600952148438
Validation loss: 2.0350890209277472

Epoch: 5| Step: 11
Training loss: 0.3823941946029663
Validation loss: 2.0547180275122323

Epoch: 478| Step: 0
Training loss: 0.6234563589096069
Validation loss: 2.118569259842237

Epoch: 5| Step: 1
Training loss: 0.9708853960037231
Validation loss: 2.1973960598309836

Epoch: 5| Step: 2
Training loss: 1.3496943712234497
Validation loss: 2.1843525171279907

Epoch: 5| Step: 3
Training loss: 0.5220423936843872
Validation loss: 2.1796108782291412

Epoch: 5| Step: 4
Training loss: 0.5601940155029297
Validation loss: 2.1861934512853622

Epoch: 5| Step: 5
Training loss: 0.3851966857910156
Validation loss: 2.151046176751455

Epoch: 5| Step: 6
Training loss: 0.7381335496902466
Validation loss: 2.171649217605591

Epoch: 5| Step: 7
Training loss: 0.8787161707878113
Validation loss: 2.2080494513114295

Epoch: 5| Step: 8
Training loss: 0.8625057339668274
Validation loss: 2.2135588427384696

Epoch: 5| Step: 9
Training loss: 0.8157636523246765
Validation loss: 2.2131991485754647

Epoch: 5| Step: 10
Training loss: 0.7149359583854675
Validation loss: 2.238970547914505

Epoch: 5| Step: 11
Training loss: 0.6699850559234619
Validation loss: 2.228996833165487

Epoch: 479| Step: 0
Training loss: 0.4797653555870056
Validation loss: 2.1627381990353265

Epoch: 5| Step: 1
Training loss: 0.781531035900116
Validation loss: 2.182307094335556

Epoch: 5| Step: 2
Training loss: 1.1659390926361084
Validation loss: 2.2179722984631858

Epoch: 5| Step: 3
Training loss: 0.8480377197265625
Validation loss: 2.1254168500502906

Epoch: 5| Step: 4
Training loss: 0.5225352048873901
Validation loss: 2.111439973115921

Epoch: 5| Step: 5
Training loss: 0.8171790242195129
Validation loss: 2.170389915506045

Epoch: 5| Step: 6
Training loss: 0.591777503490448
Validation loss: 2.142855162421862

Epoch: 5| Step: 7
Training loss: 0.9364193677902222
Validation loss: 2.2096135914325714

Epoch: 5| Step: 8
Training loss: 0.49165821075439453
Validation loss: 2.130949636300405

Epoch: 5| Step: 9
Training loss: 0.5524844527244568
Validation loss: 2.142553359270096

Epoch: 5| Step: 10
Training loss: 0.6021535396575928
Validation loss: 2.132131427526474

Epoch: 5| Step: 11
Training loss: 0.6138869524002075
Validation loss: 2.185120716691017

Epoch: 480| Step: 0
Training loss: 0.8482467532157898
Validation loss: 2.2130127251148224

Epoch: 5| Step: 1
Training loss: 0.49731653928756714
Validation loss: 2.218436355392138

Epoch: 5| Step: 2
Training loss: 0.8623157739639282
Validation loss: 2.2248590886592865

Epoch: 5| Step: 3
Training loss: 0.7581886053085327
Validation loss: 2.1696392943461738

Epoch: 5| Step: 4
Training loss: 0.6208838224411011
Validation loss: 2.1535690824190774

Epoch: 5| Step: 5
Training loss: 0.8798334002494812
Validation loss: 2.1230379541714988

Epoch: 5| Step: 6
Training loss: 1.083608627319336
Validation loss: 2.1662770807743073

Epoch: 5| Step: 7
Training loss: 0.8711207509040833
Validation loss: 2.1586265166600547

Epoch: 5| Step: 8
Training loss: 0.41812530159950256
Validation loss: 2.179274767637253

Epoch: 5| Step: 9
Training loss: 0.6824923753738403
Validation loss: 2.161867678165436

Epoch: 5| Step: 10
Training loss: 0.4785875380039215
Validation loss: 2.1343780209620795

Epoch: 5| Step: 11
Training loss: 1.2221934795379639
Validation loss: 2.1616371174653373

Epoch: 481| Step: 0
Training loss: 0.39460188150405884
Validation loss: 2.2023337483406067

Epoch: 5| Step: 1
Training loss: 0.5167456865310669
Validation loss: 2.2156111299991608

Epoch: 5| Step: 2
Training loss: 0.5562856793403625
Validation loss: 2.2457361618677774

Epoch: 5| Step: 3
Training loss: 0.8079290390014648
Validation loss: 2.2435974925756454

Epoch: 5| Step: 4
Training loss: 0.4256909489631653
Validation loss: 2.2799251278241477

Epoch: 5| Step: 5
Training loss: 0.9767556190490723
Validation loss: 2.2664014448722205

Epoch: 5| Step: 6
Training loss: 0.878809928894043
Validation loss: 2.248469799757004

Epoch: 5| Step: 7
Training loss: 0.9667266607284546
Validation loss: 2.241129125157992

Epoch: 5| Step: 8
Training loss: 0.5995278358459473
Validation loss: 2.2395646472771964

Epoch: 5| Step: 9
Training loss: 0.9675279855728149
Validation loss: 2.2163048734267554

Epoch: 5| Step: 10
Training loss: 0.29832661151885986
Validation loss: 2.2460195372502008

Epoch: 5| Step: 11
Training loss: 0.6387810707092285
Validation loss: 2.161536773045858

Epoch: 482| Step: 0
Training loss: 0.9272720217704773
Validation loss: 2.181419695417086

Epoch: 5| Step: 1
Training loss: 0.6001416444778442
Validation loss: 2.1852830747763314

Epoch: 5| Step: 2
Training loss: 0.5063490271568298
Validation loss: 2.1700721929470697

Epoch: 5| Step: 3
Training loss: 0.7795244455337524
Validation loss: 2.161303589741389

Epoch: 5| Step: 4
Training loss: 0.5031872391700745
Validation loss: 2.148729756474495

Epoch: 5| Step: 5
Training loss: 0.4432411789894104
Validation loss: 2.194216936826706

Epoch: 5| Step: 6
Training loss: 1.1806373596191406
Validation loss: 2.1534823874632516

Epoch: 5| Step: 7
Training loss: 0.538275420665741
Validation loss: 2.1869957000017166

Epoch: 5| Step: 8
Training loss: 0.38795679807662964
Validation loss: 2.212864170471827

Epoch: 5| Step: 9
Training loss: 0.8704453706741333
Validation loss: 2.20562681555748

Epoch: 5| Step: 10
Training loss: 0.4909079670906067
Validation loss: 2.191289852062861

Epoch: 5| Step: 11
Training loss: 0.16868650913238525
Validation loss: 2.1439983248710632

Epoch: 483| Step: 0
Training loss: 0.75560063123703
Validation loss: 2.181077241897583

Epoch: 5| Step: 1
Training loss: 0.6141160726547241
Validation loss: 2.1398617128531137

Epoch: 5| Step: 2
Training loss: 0.4686965048313141
Validation loss: 2.192329073945681

Epoch: 5| Step: 3
Training loss: 0.5211707949638367
Validation loss: 2.1615555584430695

Epoch: 5| Step: 4
Training loss: 0.8261560201644897
Validation loss: 2.1550799012184143

Epoch: 5| Step: 5
Training loss: 0.5939829349517822
Validation loss: 2.1143208096424737

Epoch: 5| Step: 6
Training loss: 0.725947916507721
Validation loss: 2.1656589259703956

Epoch: 5| Step: 7
Training loss: 0.32532650232315063
Validation loss: 2.121861000855764

Epoch: 5| Step: 8
Training loss: 0.5258388519287109
Validation loss: 2.107558245460192

Epoch: 5| Step: 9
Training loss: 0.7032092809677124
Validation loss: 2.141327982147535

Epoch: 5| Step: 10
Training loss: 0.764070987701416
Validation loss: 2.1379111458857856

Epoch: 5| Step: 11
Training loss: 0.7186234593391418
Validation loss: 2.1273673127094903

Epoch: 484| Step: 0
Training loss: 0.9722992777824402
Validation loss: 2.149470865726471

Epoch: 5| Step: 1
Training loss: 0.6160613298416138
Validation loss: 2.13866680363814

Epoch: 5| Step: 2
Training loss: 0.6141670346260071
Validation loss: 2.0945390363534293

Epoch: 5| Step: 3
Training loss: 0.567715585231781
Validation loss: 2.109979753692945

Epoch: 5| Step: 4
Training loss: 0.7528132200241089
Validation loss: 2.092024713754654

Epoch: 5| Step: 5
Training loss: 0.3997921049594879
Validation loss: 2.11631286640962

Epoch: 5| Step: 6
Training loss: 0.3630150258541107
Validation loss: 2.1092905600865683

Epoch: 5| Step: 7
Training loss: 0.31365281343460083
Validation loss: 2.13432369629542

Epoch: 5| Step: 8
Training loss: 0.6066979169845581
Validation loss: 2.1580261240402856

Epoch: 5| Step: 9
Training loss: 0.9442060589790344
Validation loss: 2.163612792889277

Epoch: 5| Step: 10
Training loss: 0.6688798069953918
Validation loss: 2.1700390726327896

Epoch: 5| Step: 11
Training loss: 0.23067545890808105
Validation loss: 2.171802505850792

Epoch: 485| Step: 0
Training loss: 0.5068492889404297
Validation loss: 2.147016853094101

Epoch: 5| Step: 1
Training loss: 0.5092143416404724
Validation loss: 2.1365752269824347

Epoch: 5| Step: 2
Training loss: 0.5163673162460327
Validation loss: 2.1612029373645782

Epoch: 5| Step: 3
Training loss: 0.7556018829345703
Validation loss: 2.18300299346447

Epoch: 5| Step: 4
Training loss: 0.7095038890838623
Validation loss: 2.148199071486791

Epoch: 5| Step: 5
Training loss: 0.9701024293899536
Validation loss: 2.1412185529867807

Epoch: 5| Step: 6
Training loss: 0.6079629063606262
Validation loss: 2.15599524974823

Epoch: 5| Step: 7
Training loss: 0.7395012378692627
Validation loss: 2.1238665332396827

Epoch: 5| Step: 8
Training loss: 0.5746806859970093
Validation loss: 2.1359585175911584

Epoch: 5| Step: 9
Training loss: 0.2789633870124817
Validation loss: 2.1173611829678216

Epoch: 5| Step: 10
Training loss: 0.8860904574394226
Validation loss: 2.124662106235822

Epoch: 5| Step: 11
Training loss: 0.22015315294265747
Validation loss: 2.083898216485977

Epoch: 486| Step: 0
Training loss: 0.7488627433776855
Validation loss: 2.101460869113604

Epoch: 5| Step: 1
Training loss: 0.7070020437240601
Validation loss: 2.126786748568217

Epoch: 5| Step: 2
Training loss: 1.0085597038269043
Validation loss: 2.113579586148262

Epoch: 5| Step: 3
Training loss: 0.3540711998939514
Validation loss: 2.1437039325634637

Epoch: 5| Step: 4
Training loss: 0.6533390283584595
Validation loss: 2.173936645189921

Epoch: 5| Step: 5
Training loss: 0.6496045589447021
Validation loss: 2.1476430346568427

Epoch: 5| Step: 6
Training loss: 0.8718239068984985
Validation loss: 2.1081205209096274

Epoch: 5| Step: 7
Training loss: 0.6914249658584595
Validation loss: 2.1794197062651315

Epoch: 5| Step: 8
Training loss: 0.6143487095832825
Validation loss: 2.1263164778550467

Epoch: 5| Step: 9
Training loss: 0.38427895307540894
Validation loss: 2.169202441970507

Epoch: 5| Step: 10
Training loss: 0.6565207839012146
Validation loss: 2.1664624015490213

Epoch: 5| Step: 11
Training loss: 0.15079987049102783
Validation loss: 2.1773597995440164

Epoch: 487| Step: 0
Training loss: 0.6526924967765808
Validation loss: 2.225063055753708

Epoch: 5| Step: 1
Training loss: 0.9610670804977417
Validation loss: 2.174483224749565

Epoch: 5| Step: 2
Training loss: 0.5628749132156372
Validation loss: 2.144911433259646

Epoch: 5| Step: 3
Training loss: 0.47529134154319763
Validation loss: 2.153266102075577

Epoch: 5| Step: 4
Training loss: 0.6427987813949585
Validation loss: 2.163149123390516

Epoch: 5| Step: 5
Training loss: 0.645987868309021
Validation loss: 2.1462148328622184

Epoch: 5| Step: 6
Training loss: 0.4264587461948395
Validation loss: 2.146137982606888

Epoch: 5| Step: 7
Training loss: 0.7120177745819092
Validation loss: 2.1524692873160043

Epoch: 5| Step: 8
Training loss: 0.5317062139511108
Validation loss: 2.173807700475057

Epoch: 5| Step: 9
Training loss: 0.8050549626350403
Validation loss: 2.1562854448954263

Epoch: 5| Step: 10
Training loss: 0.35982567071914673
Validation loss: 2.203548471132914

Epoch: 5| Step: 11
Training loss: 0.44307732582092285
Validation loss: 2.127132053176562

Epoch: 488| Step: 0
Training loss: 0.7573050260543823
Validation loss: 2.164531171321869

Epoch: 5| Step: 1
Training loss: 0.7022374868392944
Validation loss: 2.1409059166908264

Epoch: 5| Step: 2
Training loss: 0.5788325071334839
Validation loss: 2.123599966367086

Epoch: 5| Step: 3
Training loss: 0.7768400311470032
Validation loss: 2.1363536765178046

Epoch: 5| Step: 4
Training loss: 0.43317312002182007
Validation loss: 2.1626067608594894

Epoch: 5| Step: 5
Training loss: 0.7860604524612427
Validation loss: 2.128647526105245

Epoch: 5| Step: 6
Training loss: 0.34852519631385803
Validation loss: 2.125423009196917

Epoch: 5| Step: 7
Training loss: 0.6871446371078491
Validation loss: 2.177021324634552

Epoch: 5| Step: 8
Training loss: 0.5342124104499817
Validation loss: 2.174064705769221

Epoch: 5| Step: 9
Training loss: 0.6212927103042603
Validation loss: 2.111521532138189

Epoch: 5| Step: 10
Training loss: 0.5477237701416016
Validation loss: 2.115921969215075

Epoch: 5| Step: 11
Training loss: 0.4307568073272705
Validation loss: 2.1384200106064477

Epoch: 489| Step: 0
Training loss: 0.5449683666229248
Validation loss: 2.149738997220993

Epoch: 5| Step: 1
Training loss: 0.4918607771396637
Validation loss: 2.1436790078878403

Epoch: 5| Step: 2
Training loss: 0.8030099868774414
Validation loss: 2.17626228928566

Epoch: 5| Step: 3
Training loss: 0.6873455047607422
Validation loss: 2.1875110318263373

Epoch: 5| Step: 4
Training loss: 0.5250228047370911
Validation loss: 2.1950860619544983

Epoch: 5| Step: 5
Training loss: 0.9269354939460754
Validation loss: 2.2481816112995148

Epoch: 5| Step: 6
Training loss: 0.9518793225288391
Validation loss: 2.2162591914335885

Epoch: 5| Step: 7
Training loss: 1.090334177017212
Validation loss: 2.241162290175756

Epoch: 5| Step: 8
Training loss: 0.7007556557655334
Validation loss: 2.2935069799423218

Epoch: 5| Step: 9
Training loss: 0.8148864507675171
Validation loss: 2.248220687111219

Epoch: 5| Step: 10
Training loss: 0.7577535510063171
Validation loss: 2.310880790154139

Epoch: 5| Step: 11
Training loss: 0.7234009504318237
Validation loss: 2.2249261339505515

Epoch: 490| Step: 0
Training loss: 0.4490240216255188
Validation loss: 2.1825136840343475

Epoch: 5| Step: 1
Training loss: 0.3811609745025635
Validation loss: 2.2081205348173776

Epoch: 5| Step: 2
Training loss: 0.6317183375358582
Validation loss: 2.172832498947779

Epoch: 5| Step: 3
Training loss: 0.7373945713043213
Validation loss: 2.167229195435842

Epoch: 5| Step: 4
Training loss: 1.1265243291854858
Validation loss: 2.1951541701952615

Epoch: 5| Step: 5
Training loss: 0.7453680634498596
Validation loss: 2.217497115333875

Epoch: 5| Step: 6
Training loss: 0.6674691438674927
Validation loss: 2.1845721751451492

Epoch: 5| Step: 7
Training loss: 0.6896732449531555
Validation loss: 2.1431374649206796

Epoch: 5| Step: 8
Training loss: 0.6301531195640564
Validation loss: 2.1240713646014533

Epoch: 5| Step: 9
Training loss: 0.44695472717285156
Validation loss: 2.128353332479795

Epoch: 5| Step: 10
Training loss: 0.7912642359733582
Validation loss: 2.1502831280231476

Epoch: 5| Step: 11
Training loss: 0.5711528062820435
Validation loss: 2.1303097903728485

Epoch: 491| Step: 0
Training loss: 0.546873927116394
Validation loss: 2.1224700709184012

Epoch: 5| Step: 1
Training loss: 0.5457371473312378
Validation loss: 2.063091074426969

Epoch: 5| Step: 2
Training loss: 0.9163194894790649
Validation loss: 2.1475858787695565

Epoch: 5| Step: 3
Training loss: 0.5809763669967651
Validation loss: 2.1892729004224143

Epoch: 5| Step: 4
Training loss: 0.64061439037323
Validation loss: 2.178165376186371

Epoch: 5| Step: 5
Training loss: 0.8493595123291016
Validation loss: 2.1849689235289893

Epoch: 5| Step: 6
Training loss: 0.29044657945632935
Validation loss: 2.160231505831083

Epoch: 5| Step: 7
Training loss: 0.48556217551231384
Validation loss: 2.134378810723623

Epoch: 5| Step: 8
Training loss: 0.4111109673976898
Validation loss: 2.1458924462397895

Epoch: 5| Step: 9
Training loss: 0.9367095232009888
Validation loss: 2.101693719625473

Epoch: 5| Step: 10
Training loss: 0.9594219326972961
Validation loss: 2.1228794554869332

Epoch: 5| Step: 11
Training loss: 0.2623499035835266
Validation loss: 2.1114985992511115

Epoch: 492| Step: 0
Training loss: 0.42466363310813904
Validation loss: 2.122526610891024

Epoch: 5| Step: 1
Training loss: 0.6585806012153625
Validation loss: 2.1479864368836084

Epoch: 5| Step: 2
Training loss: 0.4383079409599304
Validation loss: 2.1145331809918084

Epoch: 5| Step: 3
Training loss: 0.6520280838012695
Validation loss: 2.131475875775019

Epoch: 5| Step: 4
Training loss: 0.567788302898407
Validation loss: 2.0868164201577506

Epoch: 5| Step: 5
Training loss: 0.5484594106674194
Validation loss: 2.16498934229215

Epoch: 5| Step: 6
Training loss: 1.0025665760040283
Validation loss: 2.1632872422536216

Epoch: 5| Step: 7
Training loss: 0.4343252182006836
Validation loss: 2.2075536797444024

Epoch: 5| Step: 8
Training loss: 0.39499393105506897
Validation loss: 2.1564082205295563

Epoch: 5| Step: 9
Training loss: 1.059952974319458
Validation loss: 2.235070432225863

Epoch: 5| Step: 10
Training loss: 0.6213150024414062
Validation loss: 2.1604963690042496

Epoch: 5| Step: 11
Training loss: 0.7015275955200195
Validation loss: 2.1801273425420127

Epoch: 493| Step: 0
Training loss: 0.40249958634376526
Validation loss: 2.1719610144694648

Epoch: 5| Step: 1
Training loss: 0.8300310969352722
Validation loss: 2.1409272650877633

Epoch: 5| Step: 2
Training loss: 1.0621923208236694
Validation loss: 2.1439023663600287

Epoch: 5| Step: 3
Training loss: 0.8542002439498901
Validation loss: 2.14863254626592

Epoch: 5| Step: 4
Training loss: 0.9392699003219604
Validation loss: 2.1070260604222617

Epoch: 5| Step: 5
Training loss: 0.5490872263908386
Validation loss: 2.0923947294553122

Epoch: 5| Step: 6
Training loss: 0.6086875200271606
Validation loss: 2.1875036557515464

Epoch: 5| Step: 7
Training loss: 0.7160378694534302
Validation loss: 2.1623181104660034

Epoch: 5| Step: 8
Training loss: 0.6980418562889099
Validation loss: 2.1222445219755173

Epoch: 5| Step: 9
Training loss: 1.079352617263794
Validation loss: 2.1132602244615555

Epoch: 5| Step: 10
Training loss: 0.9873774647712708
Validation loss: 2.124329055349032

Epoch: 5| Step: 11
Training loss: 1.6137146949768066
Validation loss: 2.1211225589116416

Epoch: 494| Step: 0
Training loss: 0.7302117943763733
Validation loss: 2.106457014878591

Epoch: 5| Step: 1
Training loss: 0.622560441493988
Validation loss: 2.16336323817571

Epoch: 5| Step: 2
Training loss: 0.6256003379821777
Validation loss: 2.1874340226252875

Epoch: 5| Step: 3
Training loss: 0.6586368083953857
Validation loss: 2.1839469323555627

Epoch: 5| Step: 4
Training loss: 1.0534669160842896
Validation loss: 2.16313045223554

Epoch: 5| Step: 5
Training loss: 1.2537826299667358
Validation loss: 2.2003576159477234

Epoch: 5| Step: 6
Training loss: 0.6190460324287415
Validation loss: 2.1701303919156394

Epoch: 5| Step: 7
Training loss: 0.7469568252563477
Validation loss: 2.1699360609054565

Epoch: 5| Step: 8
Training loss: 0.7675951719284058
Validation loss: 2.1320558985074363

Epoch: 5| Step: 9
Training loss: 0.4998622536659241
Validation loss: 2.1160132189591727

Epoch: 5| Step: 10
Training loss: 0.9949806332588196
Validation loss: 2.1302831172943115

Epoch: 5| Step: 11
Training loss: 0.6895452737808228
Validation loss: 2.160988082488378

Epoch: 495| Step: 0
Training loss: 0.5524498224258423
Validation loss: 2.14986385901769

Epoch: 5| Step: 1
Training loss: 1.0616306066513062
Validation loss: 2.1895386278629303

Epoch: 5| Step: 2
Training loss: 1.046398401260376
Validation loss: 2.1468357195456824

Epoch: 5| Step: 3
Training loss: 0.7761391401290894
Validation loss: 2.213342090447744

Epoch: 5| Step: 4
Training loss: 1.0401519536972046
Validation loss: 2.1115814546744027

Epoch: 5| Step: 5
Training loss: 0.6636680364608765
Validation loss: 2.068579842646917

Epoch: 5| Step: 6
Training loss: 0.6325469017028809
Validation loss: 2.1646379629770913

Epoch: 5| Step: 7
Training loss: 0.5143964886665344
Validation loss: 2.192398359378179

Epoch: 5| Step: 8
Training loss: 0.6062897443771362
Validation loss: 2.1271598984797797

Epoch: 5| Step: 9
Training loss: 0.5569380521774292
Validation loss: 2.151642690102259

Epoch: 5| Step: 10
Training loss: 0.5967562794685364
Validation loss: 2.203498105208079

Epoch: 5| Step: 11
Training loss: 0.12176632881164551
Validation loss: 2.21190345287323

Epoch: 496| Step: 0
Training loss: 0.4380878806114197
Validation loss: 2.244619886080424

Epoch: 5| Step: 1
Training loss: 0.4475463330745697
Validation loss: 2.175537789861361

Epoch: 5| Step: 2
Training loss: 0.991740345954895
Validation loss: 2.2050559570391974

Epoch: 5| Step: 3
Training loss: 0.6197797060012817
Validation loss: 2.215595453977585

Epoch: 5| Step: 4
Training loss: 0.46966853737831116
Validation loss: 2.242247814933459

Epoch: 5| Step: 5
Training loss: 0.3966713547706604
Validation loss: 2.2352471500635147

Epoch: 5| Step: 6
Training loss: 0.7181012630462646
Validation loss: 2.2613870004812875

Epoch: 5| Step: 7
Training loss: 0.6733711957931519
Validation loss: 2.272389908631643

Epoch: 5| Step: 8
Training loss: 0.549361526966095
Validation loss: 2.2551259299119315

Epoch: 5| Step: 9
Training loss: 0.8949018716812134
Validation loss: 2.2144960214694343

Epoch: 5| Step: 10
Training loss: 0.36855944991111755
Validation loss: 2.2188967168331146

Epoch: 5| Step: 11
Training loss: 1.3281183242797852
Validation loss: 2.2147624442974725

Epoch: 497| Step: 0
Training loss: 0.529315710067749
Validation loss: 2.1611503064632416

Epoch: 5| Step: 1
Training loss: 0.657985270023346
Validation loss: 2.157751758893331

Epoch: 5| Step: 2
Training loss: 1.103805661201477
Validation loss: 2.073309674859047

Epoch: 5| Step: 3
Training loss: 0.8033779859542847
Validation loss: 2.118132750193278

Epoch: 5| Step: 4
Training loss: 0.3893844187259674
Validation loss: 2.1152215749025345

Epoch: 5| Step: 5
Training loss: 0.44655925035476685
Validation loss: 2.117339536547661

Epoch: 5| Step: 6
Training loss: 0.6423975229263306
Validation loss: 2.1912915011247

Epoch: 5| Step: 7
Training loss: 0.42475757002830505
Validation loss: 2.1579598635435104

Epoch: 5| Step: 8
Training loss: 0.5748597383499146
Validation loss: 2.1627751936515174

Epoch: 5| Step: 9
Training loss: 0.5627177953720093
Validation loss: 2.1324649453163147

Epoch: 5| Step: 10
Training loss: 0.4686264991760254
Validation loss: 2.1660672575235367

Epoch: 5| Step: 11
Training loss: 0.6237812042236328
Validation loss: 2.192374666531881

Epoch: 498| Step: 0
Training loss: 0.3583281636238098
Validation loss: 2.1331799228986106

Epoch: 5| Step: 1
Training loss: 0.7524346113204956
Validation loss: 2.154992034037908

Epoch: 5| Step: 2
Training loss: 0.5950573682785034
Validation loss: 2.134969467918078

Epoch: 5| Step: 3
Training loss: 0.554022490978241
Validation loss: 2.1754195938507714

Epoch: 5| Step: 4
Training loss: 0.5453218221664429
Validation loss: 2.158342639605204

Epoch: 5| Step: 5
Training loss: 0.4976753294467926
Validation loss: 2.1840327084064484

Epoch: 5| Step: 6
Training loss: 0.6886803507804871
Validation loss: 2.2041379610697427

Epoch: 5| Step: 7
Training loss: 0.49444055557250977
Validation loss: 2.1447535008192062

Epoch: 5| Step: 8
Training loss: 0.9778668284416199
Validation loss: 2.1430788338184357

Epoch: 5| Step: 9
Training loss: 0.8180700540542603
Validation loss: 2.1598373701175055

Epoch: 5| Step: 10
Training loss: 0.22505967319011688
Validation loss: 2.125448629260063

Epoch: 5| Step: 11
Training loss: 0.36339128017425537
Validation loss: 2.145970731973648

Epoch: 499| Step: 0
Training loss: 0.7743908762931824
Validation loss: 2.150213266412417

Epoch: 5| Step: 1
Training loss: 0.5042131543159485
Validation loss: 2.068685551484426

Epoch: 5| Step: 2
Training loss: 0.8590036630630493
Validation loss: 2.140747686227163

Epoch: 5| Step: 3
Training loss: 0.41398072242736816
Validation loss: 2.1717724154392877

Epoch: 5| Step: 4
Training loss: 0.4626098573207855
Validation loss: 2.124009922146797

Epoch: 5| Step: 5
Training loss: 0.5356032252311707
Validation loss: 2.1271409541368484

Epoch: 5| Step: 6
Training loss: 0.8654486536979675
Validation loss: 2.1521111776431403

Epoch: 5| Step: 7
Training loss: 0.43826836347579956
Validation loss: 2.1383103877305984

Epoch: 5| Step: 8
Training loss: 0.7013234496116638
Validation loss: 2.1226916958888373

Epoch: 5| Step: 9
Training loss: 0.7157446146011353
Validation loss: 2.184077630440394

Epoch: 5| Step: 10
Training loss: 0.3370971977710724
Validation loss: 2.199625844756762

Epoch: 5| Step: 11
Training loss: 0.39490920305252075
Validation loss: 2.2045280237992606

Epoch: 500| Step: 0
Training loss: 0.6863334774971008
Validation loss: 2.2371529241402945

Epoch: 5| Step: 1
Training loss: 0.6357622146606445
Validation loss: 2.2419247130552926

Epoch: 5| Step: 2
Training loss: 0.5074940919876099
Validation loss: 2.224977115790049

Epoch: 5| Step: 3
Training loss: 0.6054341793060303
Validation loss: 2.229080781340599

Epoch: 5| Step: 4
Training loss: 0.8369537591934204
Validation loss: 2.272431413332621

Epoch: 5| Step: 5
Training loss: 0.5071024298667908
Validation loss: 2.1977306505044303

Epoch: 5| Step: 6
Training loss: 0.30233463644981384
Validation loss: 2.2515506744384766

Epoch: 5| Step: 7
Training loss: 0.700426459312439
Validation loss: 2.192747712135315

Epoch: 5| Step: 8
Training loss: 0.3559081256389618
Validation loss: 2.2138154804706573

Epoch: 5| Step: 9
Training loss: 0.8405315279960632
Validation loss: 2.1816317786773047

Epoch: 5| Step: 10
Training loss: 0.4138045310974121
Validation loss: 2.167588919401169

Epoch: 5| Step: 11
Training loss: 0.41514554619789124
Validation loss: 2.141768445571264

Testing loss: 1.8335712350529731
