Epoch: 1| Step: 0
Training loss: 5.155945777893066
Validation loss: 5.262535214424133

Epoch: 5| Step: 1
Training loss: 4.978886604309082
Validation loss: 5.260319550832112

Epoch: 5| Step: 2
Training loss: 4.631652355194092
Validation loss: 5.257988452911377

Epoch: 5| Step: 3
Training loss: 5.96899938583374
Validation loss: 5.255790571371715

Epoch: 5| Step: 4
Training loss: 5.097745418548584
Validation loss: 5.253499190012614

Epoch: 5| Step: 5
Training loss: 5.219927787780762
Validation loss: 5.2511576016743975

Epoch: 5| Step: 6
Training loss: 5.265781879425049
Validation loss: 5.24874871969223

Epoch: 5| Step: 7
Training loss: 6.009792804718018
Validation loss: 5.2463571429252625

Epoch: 5| Step: 8
Training loss: 5.597869873046875
Validation loss: 5.243805368741353

Epoch: 5| Step: 9
Training loss: 5.31182861328125
Validation loss: 5.24111654361089

Epoch: 5| Step: 10
Training loss: 5.172671318054199
Validation loss: 5.238331973552704

Epoch: 5| Step: 11
Training loss: 5.876492500305176
Validation loss: 5.2353331844011946

Epoch: 2| Step: 0
Training loss: 4.888809680938721
Validation loss: 5.23222953081131

Epoch: 5| Step: 1
Training loss: 6.017301559448242
Validation loss: 5.229085008303325

Epoch: 5| Step: 2
Training loss: 4.534426212310791
Validation loss: 5.225762029488881

Epoch: 5| Step: 3
Training loss: 6.300148963928223
Validation loss: 5.222325285275777

Epoch: 5| Step: 4
Training loss: 5.318211555480957
Validation loss: 5.218655010064443

Epoch: 5| Step: 5
Training loss: 5.7938551902771
Validation loss: 5.214751164118449

Epoch: 5| Step: 6
Training loss: 6.364623069763184
Validation loss: 5.21078606446584

Epoch: 5| Step: 7
Training loss: 4.493271827697754
Validation loss: 5.206358055273692

Epoch: 5| Step: 8
Training loss: 5.372773170471191
Validation loss: 5.201838970184326

Epoch: 5| Step: 9
Training loss: 4.50631046295166
Validation loss: 5.197193920612335

Epoch: 5| Step: 10
Training loss: 4.641909599304199
Validation loss: 5.192115843296051

Epoch: 5| Step: 11
Training loss: 4.696855545043945
Validation loss: 5.186973710854848

Epoch: 3| Step: 0
Training loss: 4.066302299499512
Validation loss: 5.181476652622223

Epoch: 5| Step: 1
Training loss: 5.322720527648926
Validation loss: 5.176049451033275

Epoch: 5| Step: 2
Training loss: 5.935784339904785
Validation loss: 5.170056362946828

Epoch: 5| Step: 3
Training loss: 5.953483581542969
Validation loss: 5.163701832294464

Epoch: 5| Step: 4
Training loss: 4.665070533752441
Validation loss: 5.157371163368225

Epoch: 5| Step: 5
Training loss: 5.132733345031738
Validation loss: 5.150675555070241

Epoch: 5| Step: 6
Training loss: 4.3781328201293945
Validation loss: 5.143607974052429

Epoch: 5| Step: 7
Training loss: 5.211884498596191
Validation loss: 5.13633128007253

Epoch: 5| Step: 8
Training loss: 5.786358833312988
Validation loss: 5.128639002641042

Epoch: 5| Step: 9
Training loss: 5.158916473388672
Validation loss: 5.12109245856603

Epoch: 5| Step: 10
Training loss: 5.8849968910217285
Validation loss: 5.112830221652985

Epoch: 5| Step: 11
Training loss: 4.822195529937744
Validation loss: 5.104592164357503

Epoch: 4| Step: 0
Training loss: 5.450200080871582
Validation loss: 5.096238990624745

Epoch: 5| Step: 1
Training loss: 5.4932661056518555
Validation loss: 5.0871663093566895

Epoch: 5| Step: 2
Training loss: 5.215928077697754
Validation loss: 5.078518092632294

Epoch: 5| Step: 3
Training loss: 4.414402008056641
Validation loss: 5.068986276785533

Epoch: 5| Step: 4
Training loss: 4.914183616638184
Validation loss: 5.05990727742513

Epoch: 5| Step: 5
Training loss: 5.46327018737793
Validation loss: 5.050598045190175

Epoch: 5| Step: 6
Training loss: 4.818755626678467
Validation loss: 5.040880799293518

Epoch: 5| Step: 7
Training loss: 5.544409275054932
Validation loss: 5.031555314858754

Epoch: 5| Step: 8
Training loss: 4.508863925933838
Validation loss: 5.021557192007701

Epoch: 5| Step: 9
Training loss: 5.940363883972168
Validation loss: 5.012008388837178

Epoch: 5| Step: 10
Training loss: 5.2402024269104
Validation loss: 5.001904288927714

Epoch: 5| Step: 11
Training loss: 2.055544376373291
Validation loss: 4.991879065831502

Epoch: 5| Step: 0
Training loss: 4.355037212371826
Validation loss: 4.981559634208679

Epoch: 5| Step: 1
Training loss: 5.715391635894775
Validation loss: 4.971223175525665

Epoch: 5| Step: 2
Training loss: 3.9222323894500732
Validation loss: 4.960586468378703

Epoch: 5| Step: 3
Training loss: 4.825074195861816
Validation loss: 4.950192232926686

Epoch: 5| Step: 4
Training loss: 4.629316806793213
Validation loss: 4.939503699541092

Epoch: 5| Step: 5
Training loss: 5.075799465179443
Validation loss: 4.928619384765625

Epoch: 5| Step: 6
Training loss: 5.382772922515869
Validation loss: 4.917751292387645

Epoch: 5| Step: 7
Training loss: 5.315810203552246
Validation loss: 4.907060345013936

Epoch: 5| Step: 8
Training loss: 5.251163482666016
Validation loss: 4.896099905172984

Epoch: 5| Step: 9
Training loss: 5.465238094329834
Validation loss: 4.885250826676686

Epoch: 5| Step: 10
Training loss: 5.194069862365723
Validation loss: 4.874240140120189

Epoch: 5| Step: 11
Training loss: 4.923038005828857
Validation loss: 4.86341526110967

Epoch: 6| Step: 0
Training loss: 4.540884971618652
Validation loss: 4.852067192395528

Epoch: 5| Step: 1
Training loss: 5.36426305770874
Validation loss: 4.8410375118255615

Epoch: 5| Step: 2
Training loss: 5.2984619140625
Validation loss: 4.83073224623998

Epoch: 5| Step: 3
Training loss: 5.007369041442871
Validation loss: 4.819831927617391

Epoch: 5| Step: 4
Training loss: 5.9876580238342285
Validation loss: 4.809308449427287

Epoch: 5| Step: 5
Training loss: 3.64850115776062
Validation loss: 4.7990604639053345

Epoch: 5| Step: 6
Training loss: 4.493109226226807
Validation loss: 4.78888597091039

Epoch: 5| Step: 7
Training loss: 5.073177814483643
Validation loss: 4.778870205084483

Epoch: 5| Step: 8
Training loss: 5.067628383636475
Validation loss: 4.7688294649124146

Epoch: 5| Step: 9
Training loss: 4.504330635070801
Validation loss: 4.7592118581136065

Epoch: 5| Step: 10
Training loss: 5.055661678314209
Validation loss: 4.749758680661519

Epoch: 5| Step: 11
Training loss: 3.5092997550964355
Validation loss: 4.740019142627716

Epoch: 7| Step: 0
Training loss: 5.775557518005371
Validation loss: 4.730741580327352

Epoch: 5| Step: 1
Training loss: 4.362652778625488
Validation loss: 4.721464137236278

Epoch: 5| Step: 2
Training loss: 5.902154922485352
Validation loss: 4.711887796719869

Epoch: 5| Step: 3
Training loss: 3.762530565261841
Validation loss: 4.7028798659642534

Epoch: 5| Step: 4
Training loss: 4.092662811279297
Validation loss: 4.69349084297816

Epoch: 5| Step: 5
Training loss: 5.3265380859375
Validation loss: 4.6845494111378985

Epoch: 5| Step: 6
Training loss: 5.169005870819092
Validation loss: 4.675688902537028

Epoch: 5| Step: 7
Training loss: 4.9379730224609375
Validation loss: 4.666917184988658

Epoch: 5| Step: 8
Training loss: 4.718087673187256
Validation loss: 4.658682107925415

Epoch: 5| Step: 9
Training loss: 4.1783905029296875
Validation loss: 4.650109529495239

Epoch: 5| Step: 10
Training loss: 4.42468786239624
Validation loss: 4.642044862111409

Epoch: 5| Step: 11
Training loss: 4.369690418243408
Validation loss: 4.633727729320526

Epoch: 8| Step: 0
Training loss: 4.875157356262207
Validation loss: 4.625248273213704

Epoch: 5| Step: 1
Training loss: 5.445347785949707
Validation loss: 4.617172320683797

Epoch: 5| Step: 2
Training loss: 4.681551456451416
Validation loss: 4.609343190987905

Epoch: 5| Step: 3
Training loss: 4.4372406005859375
Validation loss: 4.6015328367551165

Epoch: 5| Step: 4
Training loss: 3.783283233642578
Validation loss: 4.5939880311489105

Epoch: 5| Step: 5
Training loss: 4.10238790512085
Validation loss: 4.586526989936829

Epoch: 5| Step: 6
Training loss: 4.94305944442749
Validation loss: 4.579068263371785

Epoch: 5| Step: 7
Training loss: 4.9571661949157715
Validation loss: 4.571814934412639

Epoch: 5| Step: 8
Training loss: 4.94135046005249
Validation loss: 4.56495217482249

Epoch: 5| Step: 9
Training loss: 4.133144378662109
Validation loss: 4.557348002990087

Epoch: 5| Step: 10
Training loss: 5.323510646820068
Validation loss: 4.550204743941625

Epoch: 5| Step: 11
Training loss: 4.28150749206543
Validation loss: 4.543181190888087

Epoch: 9| Step: 0
Training loss: 4.675806522369385
Validation loss: 4.53593373298645

Epoch: 5| Step: 1
Training loss: 4.587423801422119
Validation loss: 4.5287224650383

Epoch: 5| Step: 2
Training loss: 5.0236921310424805
Validation loss: 4.522172103325526

Epoch: 5| Step: 3
Training loss: 3.8960258960723877
Validation loss: 4.515100379784902

Epoch: 5| Step: 4
Training loss: 4.722097873687744
Validation loss: 4.507851858933766

Epoch: 5| Step: 5
Training loss: 5.287444114685059
Validation loss: 4.500407914320628

Epoch: 5| Step: 6
Training loss: 6.090200424194336
Validation loss: 4.493317186832428

Epoch: 5| Step: 7
Training loss: 4.496308326721191
Validation loss: 4.485552291075389

Epoch: 5| Step: 8
Training loss: 2.927119016647339
Validation loss: 4.477992633978526

Epoch: 5| Step: 9
Training loss: 3.987553834915161
Validation loss: 4.470544715722402

Epoch: 5| Step: 10
Training loss: 5.202644348144531
Validation loss: 4.462899545828502

Epoch: 5| Step: 11
Training loss: 3.412130355834961
Validation loss: 4.45485504468282

Epoch: 10| Step: 0
Training loss: 4.5605316162109375
Validation loss: 4.447813510894775

Epoch: 5| Step: 1
Training loss: 4.378121852874756
Validation loss: 4.440127829710643

Epoch: 5| Step: 2
Training loss: 4.352594375610352
Validation loss: 4.433428525924683

Epoch: 5| Step: 3
Training loss: 3.9114387035369873
Validation loss: 4.42646465698878

Epoch: 5| Step: 4
Training loss: 5.147552967071533
Validation loss: 4.419838647047679

Epoch: 5| Step: 5
Training loss: 4.42179012298584
Validation loss: 4.413370788097382

Epoch: 5| Step: 6
Training loss: 5.5987548828125
Validation loss: 4.406451682249705

Epoch: 5| Step: 7
Training loss: 4.77396821975708
Validation loss: 4.399720589319865

Epoch: 5| Step: 8
Training loss: 4.528691291809082
Validation loss: 4.393353998661041

Epoch: 5| Step: 9
Training loss: 3.3313236236572266
Validation loss: 4.386373380819957

Epoch: 5| Step: 10
Training loss: 4.700848579406738
Validation loss: 4.379740575949351

Epoch: 5| Step: 11
Training loss: 5.053473472595215
Validation loss: 4.373253772656123

Epoch: 11| Step: 0
Training loss: 4.719359874725342
Validation loss: 4.366588552792867

Epoch: 5| Step: 1
Training loss: 3.375553846359253
Validation loss: 4.360315004984538

Epoch: 5| Step: 2
Training loss: 4.775640964508057
Validation loss: 4.354159394900004

Epoch: 5| Step: 3
Training loss: 4.1940598487854
Validation loss: 4.347752968470256

Epoch: 5| Step: 4
Training loss: 4.7122673988342285
Validation loss: 4.341021676858266

Epoch: 5| Step: 5
Training loss: 4.743124485015869
Validation loss: 4.334103355805079

Epoch: 5| Step: 6
Training loss: 4.493173599243164
Validation loss: 4.3278344968954725

Epoch: 5| Step: 7
Training loss: 4.6469621658325195
Validation loss: 4.321326752503713

Epoch: 5| Step: 8
Training loss: 5.266491889953613
Validation loss: 4.314750711123149

Epoch: 5| Step: 9
Training loss: 4.510148048400879
Validation loss: 4.3090284168720245

Epoch: 5| Step: 10
Training loss: 3.6991233825683594
Validation loss: 4.302918910980225

Epoch: 5| Step: 11
Training loss: 3.911100387573242
Validation loss: 4.29660842816035

Epoch: 12| Step: 0
Training loss: 4.286223411560059
Validation loss: 4.290560166041057

Epoch: 5| Step: 1
Training loss: 4.852488994598389
Validation loss: 4.284593423207601

Epoch: 5| Step: 2
Training loss: 4.072906494140625
Validation loss: 4.278216590483983

Epoch: 5| Step: 3
Training loss: 3.9524574279785156
Validation loss: 4.271475424369176

Epoch: 5| Step: 4
Training loss: 4.27377986907959
Validation loss: 4.265019545952479

Epoch: 5| Step: 5
Training loss: 4.761488914489746
Validation loss: 4.258203148841858

Epoch: 5| Step: 6
Training loss: 4.057743072509766
Validation loss: 4.252463420232137

Epoch: 5| Step: 7
Training loss: 4.505654811859131
Validation loss: 4.2459400196870165

Epoch: 5| Step: 8
Training loss: 4.9026641845703125
Validation loss: 4.240119198958079

Epoch: 5| Step: 9
Training loss: 4.128077030181885
Validation loss: 4.233498911062877

Epoch: 5| Step: 10
Training loss: 4.485229969024658
Validation loss: 4.227455010016759

Epoch: 5| Step: 11
Training loss: 4.343502521514893
Validation loss: 4.221262405316035

Epoch: 13| Step: 0
Training loss: 4.898661136627197
Validation loss: 4.215532739957173

Epoch: 5| Step: 1
Training loss: 3.6882388591766357
Validation loss: 4.209600706895192

Epoch: 5| Step: 2
Training loss: 4.537219047546387
Validation loss: 4.203196366628011

Epoch: 5| Step: 3
Training loss: 3.805044651031494
Validation loss: 4.197483738263448

Epoch: 5| Step: 4
Training loss: 4.86255407333374
Validation loss: 4.190651714801788

Epoch: 5| Step: 5
Training loss: 4.538088798522949
Validation loss: 4.185195783774058

Epoch: 5| Step: 6
Training loss: 3.936894178390503
Validation loss: 4.17873274286588

Epoch: 5| Step: 7
Training loss: 4.866693019866943
Validation loss: 4.173029283682506

Epoch: 5| Step: 8
Training loss: 3.7699408531188965
Validation loss: 4.16666978597641

Epoch: 5| Step: 9
Training loss: 3.772383451461792
Validation loss: 4.160650412241618

Epoch: 5| Step: 10
Training loss: 4.82781982421875
Validation loss: 4.154983739058177

Epoch: 5| Step: 11
Training loss: 4.413573265075684
Validation loss: 4.149567713340123

Epoch: 14| Step: 0
Training loss: 3.9047813415527344
Validation loss: 4.1442911028862

Epoch: 5| Step: 1
Training loss: 4.259188652038574
Validation loss: 4.139571706453959

Epoch: 5| Step: 2
Training loss: 5.075746059417725
Validation loss: 4.134213676055272

Epoch: 5| Step: 3
Training loss: 5.105416774749756
Validation loss: 4.128204703330994

Epoch: 5| Step: 4
Training loss: 2.8000197410583496
Validation loss: 4.121945401032765

Epoch: 5| Step: 5
Training loss: 5.008576393127441
Validation loss: 4.116162965695064

Epoch: 5| Step: 6
Training loss: 4.9084062576293945
Validation loss: 4.1112595697244005

Epoch: 5| Step: 7
Training loss: 3.827353000640869
Validation loss: 4.104622821013133

Epoch: 5| Step: 8
Training loss: 3.103400707244873
Validation loss: 4.10019326210022

Epoch: 5| Step: 9
Training loss: 4.224938869476318
Validation loss: 4.094393144051234

Epoch: 5| Step: 10
Training loss: 4.512413024902344
Validation loss: 4.08909539381663

Epoch: 5| Step: 11
Training loss: 4.758420467376709
Validation loss: 4.084243486324946

Epoch: 15| Step: 0
Training loss: 5.082449436187744
Validation loss: 4.079073439041774

Epoch: 5| Step: 1
Training loss: 4.888399600982666
Validation loss: 4.073350628217061

Epoch: 5| Step: 2
Training loss: 4.885984897613525
Validation loss: 4.067831099033356

Epoch: 5| Step: 3
Training loss: 3.286400318145752
Validation loss: 4.063101063172023

Epoch: 5| Step: 4
Training loss: 3.7919864654541016
Validation loss: 4.05837611357371

Epoch: 5| Step: 5
Training loss: 4.40442419052124
Validation loss: 4.0535442133744555

Epoch: 5| Step: 6
Training loss: 3.006420612335205
Validation loss: 4.048311124245326

Epoch: 5| Step: 7
Training loss: 4.006062984466553
Validation loss: 4.0435731112957

Epoch: 5| Step: 8
Training loss: 3.9522876739501953
Validation loss: 4.0389284789562225

Epoch: 5| Step: 9
Training loss: 4.757770538330078
Validation loss: 4.033670266469319

Epoch: 5| Step: 10
Training loss: 4.509766101837158
Validation loss: 4.027918299039205

Epoch: 5| Step: 11
Training loss: 2.2127327919006348
Validation loss: 4.022487352291743

Epoch: 16| Step: 0
Training loss: 2.9323058128356934
Validation loss: 4.019726941982905

Epoch: 5| Step: 1
Training loss: 4.085190773010254
Validation loss: 4.016384551922481

Epoch: 5| Step: 2
Training loss: 3.88401460647583
Validation loss: 4.01011265317599

Epoch: 5| Step: 3
Training loss: 4.668376922607422
Validation loss: 4.004318495591481

Epoch: 5| Step: 4
Training loss: 4.178493022918701
Validation loss: 3.9995396534601846

Epoch: 5| Step: 5
Training loss: 4.188710689544678
Validation loss: 3.9959004620711007

Epoch: 5| Step: 6
Training loss: 3.1839137077331543
Validation loss: 3.990634818871816

Epoch: 5| Step: 7
Training loss: 4.443727016448975
Validation loss: 3.985881725947062

Epoch: 5| Step: 8
Training loss: 5.252037048339844
Validation loss: 3.9815279444058738

Epoch: 5| Step: 9
Training loss: 3.6529133319854736
Validation loss: 3.9764468471209207

Epoch: 5| Step: 10
Training loss: 4.976097106933594
Validation loss: 3.9714799523353577

Epoch: 5| Step: 11
Training loss: 4.599738597869873
Validation loss: 3.966651737689972

Epoch: 17| Step: 0
Training loss: 5.269203186035156
Validation loss: 3.961513956387838

Epoch: 5| Step: 1
Training loss: 4.0257697105407715
Validation loss: 3.955662260452906

Epoch: 5| Step: 2
Training loss: 3.825890302658081
Validation loss: 3.9507278005282083

Epoch: 5| Step: 3
Training loss: 4.348050594329834
Validation loss: 3.946165998776754

Epoch: 5| Step: 4
Training loss: 3.8552207946777344
Validation loss: 3.942656675974528

Epoch: 5| Step: 5
Training loss: 4.0662922859191895
Validation loss: 3.937528689702352

Epoch: 5| Step: 6
Training loss: 3.965545177459717
Validation loss: 3.9316981534163156

Epoch: 5| Step: 7
Training loss: 4.158740997314453
Validation loss: 3.9256306290626526

Epoch: 5| Step: 8
Training loss: 3.9525551795959473
Validation loss: 3.9206274449825287

Epoch: 5| Step: 9
Training loss: 3.684502363204956
Validation loss: 3.9159651398658752

Epoch: 5| Step: 10
Training loss: 3.2138781547546387
Validation loss: 3.9104517996311188

Epoch: 5| Step: 11
Training loss: 6.849339962005615
Validation loss: 3.9056999882062278

Epoch: 18| Step: 0
Training loss: 4.1648688316345215
Validation loss: 3.8999648789564767

Epoch: 5| Step: 1
Training loss: 4.283607006072998
Validation loss: 3.8949165443579354

Epoch: 5| Step: 2
Training loss: 3.162985324859619
Validation loss: 3.88970555861791

Epoch: 5| Step: 3
Training loss: 4.243409156799316
Validation loss: 3.884935051202774

Epoch: 5| Step: 4
Training loss: 4.340668678283691
Validation loss: 3.8803113599618277

Epoch: 5| Step: 5
Training loss: 4.565514087677002
Validation loss: 3.8751274148623147

Epoch: 5| Step: 6
Training loss: 4.107522964477539
Validation loss: 3.869424303372701

Epoch: 5| Step: 7
Training loss: 3.6544291973114014
Validation loss: 3.8643778761227927

Epoch: 5| Step: 8
Training loss: 3.1045000553131104
Validation loss: 3.85959263642629

Epoch: 5| Step: 9
Training loss: 4.647829532623291
Validation loss: 3.854697674512863

Epoch: 5| Step: 10
Training loss: 3.667703628540039
Validation loss: 3.8494119147459664

Epoch: 5| Step: 11
Training loss: 5.670796871185303
Validation loss: 3.844086011250814

Epoch: 19| Step: 0
Training loss: 4.374268531799316
Validation loss: 3.8393062353134155

Epoch: 5| Step: 1
Training loss: 3.451180934906006
Validation loss: 3.833403547604879

Epoch: 5| Step: 2
Training loss: 4.044260501861572
Validation loss: 3.8290100594361625

Epoch: 5| Step: 3
Training loss: 4.573827266693115
Validation loss: 3.8245795567830405

Epoch: 5| Step: 4
Training loss: 3.367685317993164
Validation loss: 3.8183646500110626

Epoch: 5| Step: 5
Training loss: 3.8303401470184326
Validation loss: 3.8134726881980896

Epoch: 5| Step: 6
Training loss: 3.7386062145233154
Validation loss: 3.808154970407486

Epoch: 5| Step: 7
Training loss: 3.776547908782959
Validation loss: 3.804473568995794

Epoch: 5| Step: 8
Training loss: 3.6782898902893066
Validation loss: 3.7975878616174064

Epoch: 5| Step: 9
Training loss: 4.227414608001709
Validation loss: 3.7932477394739785

Epoch: 5| Step: 10
Training loss: 4.688485622406006
Validation loss: 3.7883045375347137

Epoch: 5| Step: 11
Training loss: 3.4378082752227783
Validation loss: 3.7832735975583396

Epoch: 20| Step: 0
Training loss: 4.2348713874816895
Validation loss: 3.780139833688736

Epoch: 5| Step: 1
Training loss: 3.766697406768799
Validation loss: 3.7755105098088584

Epoch: 5| Step: 2
Training loss: 3.986482620239258
Validation loss: 3.769908885161082

Epoch: 5| Step: 3
Training loss: 2.936570644378662
Validation loss: 3.76459131638209

Epoch: 5| Step: 4
Training loss: 4.117758274078369
Validation loss: 3.759658803542455

Epoch: 5| Step: 5
Training loss: 4.413004398345947
Validation loss: 3.759404867887497

Epoch: 5| Step: 6
Training loss: 4.586426258087158
Validation loss: 3.750079264243444

Epoch: 5| Step: 7
Training loss: 3.6209397315979004
Validation loss: 3.7445012032985687

Epoch: 5| Step: 8
Training loss: 3.4463253021240234
Validation loss: 3.7406193713347116

Epoch: 5| Step: 9
Training loss: 4.425568103790283
Validation loss: 3.737099379301071

Epoch: 5| Step: 10
Training loss: 3.6058592796325684
Validation loss: 3.7329763074715934

Epoch: 5| Step: 11
Training loss: 3.3908586502075195
Validation loss: 3.72755429148674

Epoch: 21| Step: 0
Training loss: 4.2864861488342285
Validation loss: 3.722858707110087

Epoch: 5| Step: 1
Training loss: 4.010024547576904
Validation loss: 3.7173417011896768

Epoch: 5| Step: 2
Training loss: 3.073944568634033
Validation loss: 3.7130589286486306

Epoch: 5| Step: 3
Training loss: 3.6145732402801514
Validation loss: 3.7077126602331796

Epoch: 5| Step: 4
Training loss: 4.243088722229004
Validation loss: 3.7036950290203094

Epoch: 5| Step: 5
Training loss: 3.407072067260742
Validation loss: 3.698457052310308

Epoch: 5| Step: 6
Training loss: 3.597146511077881
Validation loss: 3.693544179201126

Epoch: 5| Step: 7
Training loss: 4.51869535446167
Validation loss: 3.688207745552063

Epoch: 5| Step: 8
Training loss: 4.170769691467285
Validation loss: 3.6832174758116403

Epoch: 5| Step: 9
Training loss: 3.9326529502868652
Validation loss: 3.6793623566627502

Epoch: 5| Step: 10
Training loss: 3.687953233718872
Validation loss: 3.674298107624054

Epoch: 5| Step: 11
Training loss: 3.331911325454712
Validation loss: 3.6694677571455636

Epoch: 22| Step: 0
Training loss: 4.2272629737854
Validation loss: 3.6634875933329263

Epoch: 5| Step: 1
Training loss: 4.260218620300293
Validation loss: 3.6592076818148294

Epoch: 5| Step: 2
Training loss: 3.837982654571533
Validation loss: 3.653551995754242

Epoch: 5| Step: 3
Training loss: 3.816047191619873
Validation loss: 3.6480099658171334

Epoch: 5| Step: 4
Training loss: 3.909867763519287
Validation loss: 3.6450701653957367

Epoch: 5| Step: 5
Training loss: 2.601005792617798
Validation loss: 3.639466514190038

Epoch: 5| Step: 6
Training loss: 3.6441047191619873
Validation loss: 3.640541026989619

Epoch: 5| Step: 7
Training loss: 4.240471839904785
Validation loss: 3.6305151283740997

Epoch: 5| Step: 8
Training loss: 4.265505313873291
Validation loss: 3.6233325203259787

Epoch: 5| Step: 9
Training loss: 3.43891978263855
Validation loss: 3.6207931439081826

Epoch: 5| Step: 10
Training loss: 3.3708465099334717
Validation loss: 3.617832193771998

Epoch: 5| Step: 11
Training loss: 4.907728672027588
Validation loss: 3.6145322819550834

Epoch: 23| Step: 0
Training loss: 3.427777051925659
Validation loss: 3.610160171985626

Epoch: 5| Step: 1
Training loss: 3.6543145179748535
Validation loss: 3.602226714293162

Epoch: 5| Step: 2
Training loss: 3.6754631996154785
Validation loss: 3.597781797250112

Epoch: 5| Step: 3
Training loss: 4.031764030456543
Validation loss: 3.5937614738941193

Epoch: 5| Step: 4
Training loss: 4.008340358734131
Validation loss: 3.5904020965099335

Epoch: 5| Step: 5
Training loss: 3.152106761932373
Validation loss: 3.58714031179746

Epoch: 5| Step: 6
Training loss: 4.0284013748168945
Validation loss: 3.582123726606369

Epoch: 5| Step: 7
Training loss: 4.059513568878174
Validation loss: 3.5773761868476868

Epoch: 5| Step: 8
Training loss: 3.539013624191284
Validation loss: 3.572156290213267

Epoch: 5| Step: 9
Training loss: 3.073286533355713
Validation loss: 3.566125839948654

Epoch: 5| Step: 10
Training loss: 4.385032653808594
Validation loss: 3.561572959025701

Epoch: 5| Step: 11
Training loss: 4.709065914154053
Validation loss: 3.5553363064924874

Epoch: 24| Step: 0
Training loss: 3.637779712677002
Validation loss: 3.550410191218058

Epoch: 5| Step: 1
Training loss: 3.3982696533203125
Validation loss: 3.5458365380764008

Epoch: 5| Step: 2
Training loss: 3.9048304557800293
Validation loss: 3.541695237159729

Epoch: 5| Step: 3
Training loss: 4.055115222930908
Validation loss: 3.53497443596522

Epoch: 5| Step: 4
Training loss: 3.4174885749816895
Validation loss: 3.528235753377279

Epoch: 5| Step: 5
Training loss: 3.840559720993042
Validation loss: 3.5230157474676767

Epoch: 5| Step: 6
Training loss: 3.8759231567382812
Validation loss: 3.5182495613892875

Epoch: 5| Step: 7
Training loss: 3.8924708366394043
Validation loss: 3.5141011575857797

Epoch: 5| Step: 8
Training loss: 3.908080577850342
Validation loss: 3.506667971611023

Epoch: 5| Step: 9
Training loss: 3.4925942420959473
Validation loss: 3.5035579005877175

Epoch: 5| Step: 10
Training loss: 3.426945924758911
Validation loss: 3.496620496114095

Epoch: 5| Step: 11
Training loss: 2.2718005180358887
Validation loss: 3.4912084341049194

Epoch: 25| Step: 0
Training loss: 3.5792319774627686
Validation loss: 3.4842728972434998

Epoch: 5| Step: 1
Training loss: 3.780714511871338
Validation loss: 3.4803488155206046

Epoch: 5| Step: 2
Training loss: 2.4804892539978027
Validation loss: 3.4778411289056144

Epoch: 5| Step: 3
Training loss: 3.4195010662078857
Validation loss: 3.4716938634713492

Epoch: 5| Step: 4
Training loss: 4.323729515075684
Validation loss: 3.4670525391896567

Epoch: 5| Step: 5
Training loss: 3.9829699993133545
Validation loss: 3.462406188249588

Epoch: 5| Step: 6
Training loss: 4.490286350250244
Validation loss: 3.456753979126612

Epoch: 5| Step: 7
Training loss: 3.2431273460388184
Validation loss: 3.4520389338334403

Epoch: 5| Step: 8
Training loss: 4.108412742614746
Validation loss: 3.4468372762203217

Epoch: 5| Step: 9
Training loss: 3.252817153930664
Validation loss: 3.44222824772199

Epoch: 5| Step: 10
Training loss: 3.1063268184661865
Validation loss: 3.437437375386556

Epoch: 5| Step: 11
Training loss: 4.330544471740723
Validation loss: 3.433045377333959

Epoch: 26| Step: 0
Training loss: 2.9854378700256348
Validation loss: 3.427546411752701

Epoch: 5| Step: 1
Training loss: 4.186217308044434
Validation loss: 3.4211224615573883

Epoch: 5| Step: 2
Training loss: 3.511206865310669
Validation loss: 3.4168389439582825

Epoch: 5| Step: 3
Training loss: 2.8943216800689697
Validation loss: 3.410564959049225

Epoch: 5| Step: 4
Training loss: 3.7771811485290527
Validation loss: 3.406865805387497

Epoch: 5| Step: 5
Training loss: 3.3120884895324707
Validation loss: 3.40078271428744

Epoch: 5| Step: 6
Training loss: 3.3183205127716064
Validation loss: 3.3973001837730408

Epoch: 5| Step: 7
Training loss: 3.2951998710632324
Validation loss: 3.3934155801932016

Epoch: 5| Step: 8
Training loss: 3.789651870727539
Validation loss: 3.3893415331840515

Epoch: 5| Step: 9
Training loss: 4.19861364364624
Validation loss: 3.384430338939031

Epoch: 5| Step: 10
Training loss: 4.068183898925781
Validation loss: 3.3803755939006805

Epoch: 5| Step: 11
Training loss: 3.248509407043457
Validation loss: 3.3752394119898477

Epoch: 27| Step: 0
Training loss: 3.248723268508911
Validation loss: 3.370756447315216

Epoch: 5| Step: 1
Training loss: 4.020777702331543
Validation loss: 3.3658882081508636

Epoch: 5| Step: 2
Training loss: 2.647082805633545
Validation loss: 3.362362116575241

Epoch: 5| Step: 3
Training loss: 4.149432182312012
Validation loss: 3.3582080403963723

Epoch: 5| Step: 4
Training loss: 3.2195518016815186
Validation loss: 3.352726270755132

Epoch: 5| Step: 5
Training loss: 3.372310161590576
Validation loss: 3.3483303685983024

Epoch: 5| Step: 6
Training loss: 3.9788239002227783
Validation loss: 3.3442131181557975

Epoch: 5| Step: 7
Training loss: 3.5192675590515137
Validation loss: 3.3397308588027954

Epoch: 5| Step: 8
Training loss: 3.2150065898895264
Validation loss: 3.334745764732361

Epoch: 5| Step: 9
Training loss: 4.336127281188965
Validation loss: 3.33028573791186

Epoch: 5| Step: 10
Training loss: 3.0221951007843018
Validation loss: 3.3252703845500946

Epoch: 5| Step: 11
Training loss: 3.3151535987854004
Validation loss: 3.320287654797236

Epoch: 28| Step: 0
Training loss: 3.467130661010742
Validation loss: 3.3173299630482993

Epoch: 5| Step: 1
Training loss: 3.087395191192627
Validation loss: 3.31218613187472

Epoch: 5| Step: 2
Training loss: 3.5084927082061768
Validation loss: 3.308734287818273

Epoch: 5| Step: 3
Training loss: 3.5899925231933594
Validation loss: 3.3039273023605347

Epoch: 5| Step: 4
Training loss: 2.999859094619751
Validation loss: 3.29920694231987

Epoch: 5| Step: 5
Training loss: 5.027133941650391
Validation loss: 3.2956887582937875

Epoch: 5| Step: 6
Training loss: 3.617108106613159
Validation loss: 3.291682630777359

Epoch: 5| Step: 7
Training loss: 3.502619504928589
Validation loss: 3.2872489790121713

Epoch: 5| Step: 8
Training loss: 3.9802017211914062
Validation loss: 3.2837390204270682

Epoch: 5| Step: 9
Training loss: 2.6896376609802246
Validation loss: 3.2786361972490945

Epoch: 5| Step: 10
Training loss: 2.989426374435425
Validation loss: 3.274631748596827

Epoch: 5| Step: 11
Training loss: 2.0664114952087402
Validation loss: 3.270566165447235

Epoch: 29| Step: 0
Training loss: 3.375601291656494
Validation loss: 3.2675162057081857

Epoch: 5| Step: 1
Training loss: 4.060247421264648
Validation loss: 3.262896796067556

Epoch: 5| Step: 2
Training loss: 3.6777546405792236
Validation loss: 3.2584560215473175

Epoch: 5| Step: 3
Training loss: 2.380885362625122
Validation loss: 3.2539633214473724

Epoch: 5| Step: 4
Training loss: 2.8255629539489746
Validation loss: 3.249640087286631

Epoch: 5| Step: 5
Training loss: 3.609086513519287
Validation loss: 3.2453747391700745

Epoch: 5| Step: 6
Training loss: 3.2161993980407715
Validation loss: 3.2408553759256997

Epoch: 5| Step: 7
Training loss: 2.9422855377197266
Validation loss: 3.2366131246089935

Epoch: 5| Step: 8
Training loss: 4.408594608306885
Validation loss: 3.2329004804293313

Epoch: 5| Step: 9
Training loss: 3.4211277961730957
Validation loss: 3.2298545837402344

Epoch: 5| Step: 10
Training loss: 3.689732789993286
Validation loss: 3.2246293822924295

Epoch: 5| Step: 11
Training loss: 3.697294235229492
Validation loss: 3.2216880917549133

Epoch: 30| Step: 0
Training loss: 3.1938788890838623
Validation loss: 3.217947691679001

Epoch: 5| Step: 1
Training loss: 4.664217472076416
Validation loss: 3.215450714031855

Epoch: 5| Step: 2
Training loss: 2.2336127758026123
Validation loss: 3.2092706859111786

Epoch: 5| Step: 3
Training loss: 3.1327786445617676
Validation loss: 3.2050796945889792

Epoch: 5| Step: 4
Training loss: 3.671616792678833
Validation loss: 3.2007390558719635

Epoch: 5| Step: 5
Training loss: 3.1417343616485596
Validation loss: 3.1975437998771667

Epoch: 5| Step: 6
Training loss: 3.4930405616760254
Validation loss: 3.194987873236338

Epoch: 5| Step: 7
Training loss: 2.7254860401153564
Validation loss: 3.1896886924902597

Epoch: 5| Step: 8
Training loss: 3.0862319469451904
Validation loss: 3.1870329280694327

Epoch: 5| Step: 9
Training loss: 4.725852966308594
Validation loss: 3.1828024288018546

Epoch: 5| Step: 10
Training loss: 3.0854926109313965
Validation loss: 3.1777178049087524

Epoch: 5| Step: 11
Training loss: 3.3792061805725098
Validation loss: 3.174714148044586

Epoch: 31| Step: 0
Training loss: 3.3033313751220703
Validation loss: 3.1708797216415405

Epoch: 5| Step: 1
Training loss: 4.297236442565918
Validation loss: 3.166686167319616

Epoch: 5| Step: 2
Training loss: 4.246289253234863
Validation loss: 3.1618254085381827

Epoch: 5| Step: 3
Training loss: 2.3223421573638916
Validation loss: 3.1571499506632485

Epoch: 5| Step: 4
Training loss: 2.9516749382019043
Validation loss: 3.1531022588411965

Epoch: 5| Step: 5
Training loss: 3.9148921966552734
Validation loss: 3.148905018965403

Epoch: 5| Step: 6
Training loss: 3.093440532684326
Validation loss: 3.1452185809612274

Epoch: 5| Step: 7
Training loss: 2.6433908939361572
Validation loss: 3.1394770741462708

Epoch: 5| Step: 8
Training loss: 3.2070446014404297
Validation loss: 3.1367908815542855

Epoch: 5| Step: 9
Training loss: 3.2102725505828857
Validation loss: 3.1319170594215393

Epoch: 5| Step: 10
Training loss: 3.5018820762634277
Validation loss: 3.1288179457187653

Epoch: 5| Step: 11
Training loss: 3.2559211254119873
Validation loss: 3.124190847078959

Epoch: 32| Step: 0
Training loss: 2.876999616622925
Validation loss: 3.119364241758982

Epoch: 5| Step: 1
Training loss: 2.445765972137451
Validation loss: 3.115039974451065

Epoch: 5| Step: 2
Training loss: 2.5352721214294434
Validation loss: 3.110859751701355

Epoch: 5| Step: 3
Training loss: 3.8206253051757812
Validation loss: 3.107785145441691

Epoch: 5| Step: 4
Training loss: 3.692831516265869
Validation loss: 3.1031435330708823

Epoch: 5| Step: 5
Training loss: 3.6488444805145264
Validation loss: 3.098339468240738

Epoch: 5| Step: 6
Training loss: 2.8543362617492676
Validation loss: 3.0947245657444

Epoch: 5| Step: 7
Training loss: 4.211124420166016
Validation loss: 3.091352492570877

Epoch: 5| Step: 8
Training loss: 3.9556922912597656
Validation loss: 3.0902536114056907

Epoch: 5| Step: 9
Training loss: 3.2382519245147705
Validation loss: 3.0890132983525596

Epoch: 5| Step: 10
Training loss: 3.2782225608825684
Validation loss: 3.076670447985331

Epoch: 5| Step: 11
Training loss: 1.2809886932373047
Validation loss: 3.0751306414604187

Epoch: 33| Step: 0
Training loss: 3.9247353076934814
Validation loss: 3.071182906627655

Epoch: 5| Step: 1
Training loss: 3.3416595458984375
Validation loss: 3.0677675306797028

Epoch: 5| Step: 2
Training loss: 4.050663948059082
Validation loss: 3.0637381176153817

Epoch: 5| Step: 3
Training loss: 2.688041925430298
Validation loss: 3.0595006744066873

Epoch: 5| Step: 4
Training loss: 2.4949655532836914
Validation loss: 3.0549697279930115

Epoch: 5| Step: 5
Training loss: 3.4899659156799316
Validation loss: 3.0515580077966056

Epoch: 5| Step: 6
Training loss: 3.629051685333252
Validation loss: 3.0482481022675834

Epoch: 5| Step: 7
Training loss: 3.306561231613159
Validation loss: 3.04448730746905

Epoch: 5| Step: 8
Training loss: 3.5395493507385254
Validation loss: 3.04060235619545

Epoch: 5| Step: 9
Training loss: 2.9217031002044678
Validation loss: 3.0372762084007263

Epoch: 5| Step: 10
Training loss: 2.3345751762390137
Validation loss: 3.0330631037553153

Epoch: 5| Step: 11
Training loss: 3.07112193107605
Validation loss: 3.0290439128875732

Epoch: 34| Step: 0
Training loss: 2.8736910820007324
Validation loss: 3.025970220565796

Epoch: 5| Step: 1
Training loss: 3.336170196533203
Validation loss: 3.0223659376303353

Epoch: 5| Step: 2
Training loss: 2.8625025749206543
Validation loss: 3.0190242330233255

Epoch: 5| Step: 3
Training loss: 2.561440944671631
Validation loss: 3.015656719605128

Epoch: 5| Step: 4
Training loss: 3.606553554534912
Validation loss: 3.012068678935369

Epoch: 5| Step: 5
Training loss: 3.960493564605713
Validation loss: 3.008724272251129

Epoch: 5| Step: 6
Training loss: 3.880300998687744
Validation loss: 3.0046125650405884

Epoch: 5| Step: 7
Training loss: 3.1157960891723633
Validation loss: 3.0004575649897256

Epoch: 5| Step: 8
Training loss: 2.7519094944000244
Validation loss: 2.9970703522364297

Epoch: 5| Step: 9
Training loss: 3.0044167041778564
Validation loss: 2.9932849208513894

Epoch: 5| Step: 10
Training loss: 2.995044231414795
Validation loss: 2.989401380221049

Epoch: 5| Step: 11
Training loss: 4.446485996246338
Validation loss: 2.985185851653417

Epoch: 35| Step: 0
Training loss: 2.7035839557647705
Validation loss: 2.9817530612150827

Epoch: 5| Step: 1
Training loss: 3.0905072689056396
Validation loss: 2.97749063372612

Epoch: 5| Step: 2
Training loss: 2.764784336090088
Validation loss: 2.974212169647217

Epoch: 5| Step: 3
Training loss: 3.5934348106384277
Validation loss: 2.9720272918542228

Epoch: 5| Step: 4
Training loss: 3.037357807159424
Validation loss: 2.9668222268422446

Epoch: 5| Step: 5
Training loss: 3.0932674407958984
Validation loss: 2.964264859755834

Epoch: 5| Step: 6
Training loss: 4.100887298583984
Validation loss: 2.9604199628035226

Epoch: 5| Step: 7
Training loss: 2.576810836791992
Validation loss: 2.955594301223755

Epoch: 5| Step: 8
Training loss: 2.944977283477783
Validation loss: 2.9515031476815543

Epoch: 5| Step: 9
Training loss: 3.041994333267212
Validation loss: 2.948606679836909

Epoch: 5| Step: 10
Training loss: 3.7328314781188965
Validation loss: 2.9432577093442283

Epoch: 5| Step: 11
Training loss: 3.5015015602111816
Validation loss: 2.9467841188112893

Epoch: 36| Step: 0
Training loss: 3.0599799156188965
Validation loss: 2.942149887482325

Epoch: 5| Step: 1
Training loss: 2.9677982330322266
Validation loss: 2.938240041335424

Epoch: 5| Step: 2
Training loss: 3.6442081928253174
Validation loss: 2.927984520792961

Epoch: 5| Step: 3
Training loss: 2.8749136924743652
Validation loss: 2.925163894891739

Epoch: 5| Step: 4
Training loss: 2.5794730186462402
Validation loss: 2.9218173722426095

Epoch: 5| Step: 5
Training loss: 3.1994147300720215
Validation loss: 2.918446789185206

Epoch: 5| Step: 6
Training loss: 3.26542592048645
Validation loss: 2.9152893126010895

Epoch: 5| Step: 7
Training loss: 4.079892158508301
Validation loss: 2.911968191464742

Epoch: 5| Step: 8
Training loss: 3.041898488998413
Validation loss: 2.9092422326405845

Epoch: 5| Step: 9
Training loss: 2.490877866744995
Validation loss: 2.9061598678429923

Epoch: 5| Step: 10
Training loss: 3.267002820968628
Validation loss: 2.9020678400993347

Epoch: 5| Step: 11
Training loss: 2.3306517601013184
Validation loss: 2.89921506245931

Epoch: 37| Step: 0
Training loss: 4.161888599395752
Validation loss: 2.89505002895991

Epoch: 5| Step: 1
Training loss: 2.881431818008423
Validation loss: 2.8913422226905823

Epoch: 5| Step: 2
Training loss: 3.206178665161133
Validation loss: 2.887565642595291

Epoch: 5| Step: 3
Training loss: 3.1507954597473145
Validation loss: 2.8836847841739655

Epoch: 5| Step: 4
Training loss: 2.8990349769592285
Validation loss: 2.8800819516181946

Epoch: 5| Step: 5
Training loss: 2.7457351684570312
Validation loss: 2.8759770492712655

Epoch: 5| Step: 6
Training loss: 2.759443521499634
Validation loss: 2.8713685075441995

Epoch: 5| Step: 7
Training loss: 3.0995473861694336
Validation loss: 2.8697617053985596

Epoch: 5| Step: 8
Training loss: 3.1095943450927734
Validation loss: 2.866637885570526

Epoch: 5| Step: 9
Training loss: 2.5379841327667236
Validation loss: 2.8632380962371826

Epoch: 5| Step: 10
Training loss: 3.276507616043091
Validation loss: 2.8612139324347177

Epoch: 5| Step: 11
Training loss: 3.4572644233703613
Validation loss: 2.861018270254135

Epoch: 38| Step: 0
Training loss: 3.2610809803009033
Validation loss: 2.85193998614947

Epoch: 5| Step: 1
Training loss: 3.346475601196289
Validation loss: 2.8560737470785775

Epoch: 5| Step: 2
Training loss: 2.217461109161377
Validation loss: 2.857740710179011

Epoch: 5| Step: 3
Training loss: 3.355700731277466
Validation loss: 2.866206407546997

Epoch: 5| Step: 4
Training loss: 2.977762460708618
Validation loss: 2.861255089441935

Epoch: 5| Step: 5
Training loss: 2.675854444503784
Validation loss: 2.838025023539861

Epoch: 5| Step: 6
Training loss: 2.818967342376709
Validation loss: 2.8396699825922647

Epoch: 5| Step: 7
Training loss: 3.0518856048583984
Validation loss: 2.8359964986642203

Epoch: 5| Step: 8
Training loss: 3.9146454334259033
Validation loss: 2.834178706010183

Epoch: 5| Step: 9
Training loss: 3.3925833702087402
Validation loss: 2.8290682335694632

Epoch: 5| Step: 10
Training loss: 2.7825870513916016
Validation loss: 2.82655131816864

Epoch: 5| Step: 11
Training loss: 1.919025182723999
Validation loss: 2.821601947148641

Epoch: 39| Step: 0
Training loss: 2.92695951461792
Validation loss: 2.8202520310878754

Epoch: 5| Step: 1
Training loss: 3.2442550659179688
Validation loss: 2.817040274540583

Epoch: 5| Step: 2
Training loss: 3.304027557373047
Validation loss: 2.8128496408462524

Epoch: 5| Step: 3
Training loss: 3.013725757598877
Validation loss: 2.8085909684499106

Epoch: 5| Step: 4
Training loss: 2.629504680633545
Validation loss: 2.8032073775927224

Epoch: 5| Step: 5
Training loss: 2.7855453491210938
Validation loss: 2.800697465737661

Epoch: 5| Step: 6
Training loss: 3.0626132488250732
Validation loss: 2.7978793481985726

Epoch: 5| Step: 7
Training loss: 3.0715060234069824
Validation loss: 2.7943134208520255

Epoch: 5| Step: 8
Training loss: 3.299868106842041
Validation loss: 2.7913043002287545

Epoch: 5| Step: 9
Training loss: 3.266444444656372
Validation loss: 2.788161506255468

Epoch: 5| Step: 10
Training loss: 2.6337831020355225
Validation loss: 2.7855957746505737

Epoch: 5| Step: 11
Training loss: 2.5015709400177
Validation loss: 2.7839385668436685

Epoch: 40| Step: 0
Training loss: 2.5455260276794434
Validation loss: 2.778758933146795

Epoch: 5| Step: 1
Training loss: 2.986377000808716
Validation loss: 2.7751461466153464

Epoch: 5| Step: 2
Training loss: 3.1205365657806396
Validation loss: 2.7712603211402893

Epoch: 5| Step: 3
Training loss: 3.6111884117126465
Validation loss: 2.7680014769236245

Epoch: 5| Step: 4
Training loss: 2.8489601612091064
Validation loss: 2.7628961503505707

Epoch: 5| Step: 5
Training loss: 2.7218499183654785
Validation loss: 2.761141906181971

Epoch: 5| Step: 6
Training loss: 2.9859471321105957
Validation loss: 2.7582751512527466

Epoch: 5| Step: 7
Training loss: 2.657318592071533
Validation loss: 2.7541645566622415

Epoch: 5| Step: 8
Training loss: 2.483133554458618
Validation loss: 2.750544399023056

Epoch: 5| Step: 9
Training loss: 3.1263363361358643
Validation loss: 2.7477133373419442

Epoch: 5| Step: 10
Training loss: 3.547299861907959
Validation loss: 2.744587187965711

Epoch: 5| Step: 11
Training loss: 3.321916103363037
Validation loss: 2.743508776028951

Epoch: 41| Step: 0
Training loss: 2.923551559448242
Validation loss: 2.739615350961685

Epoch: 5| Step: 1
Training loss: 3.5190529823303223
Validation loss: 2.7368773271640143

Epoch: 5| Step: 2
Training loss: 3.0110690593719482
Validation loss: 2.7335152427355447

Epoch: 5| Step: 3
Training loss: 2.999272584915161
Validation loss: 2.727556655804316

Epoch: 5| Step: 4
Training loss: 2.320957899093628
Validation loss: 2.7258412738641105

Epoch: 5| Step: 5
Training loss: 2.849104404449463
Validation loss: 2.7233175337314606

Epoch: 5| Step: 6
Training loss: 2.754798412322998
Validation loss: 2.7213293413321176

Epoch: 5| Step: 7
Training loss: 2.894334077835083
Validation loss: 2.71706493695577

Epoch: 5| Step: 8
Training loss: 3.625861644744873
Validation loss: 2.7154336074988046

Epoch: 5| Step: 9
Training loss: 2.8648746013641357
Validation loss: 2.711920748154322

Epoch: 5| Step: 10
Training loss: 2.60811185836792
Validation loss: 2.7088190714518228

Epoch: 5| Step: 11
Training loss: 2.255394697189331
Validation loss: 2.7059441407521567

Epoch: 42| Step: 0
Training loss: 2.5620620250701904
Validation loss: 2.703315645456314

Epoch: 5| Step: 1
Training loss: 2.1995561122894287
Validation loss: 2.702385892470678

Epoch: 5| Step: 2
Training loss: 2.860565185546875
Validation loss: 2.6951140562693277

Epoch: 5| Step: 3
Training loss: 3.0680344104766846
Validation loss: 2.6935011545817056

Epoch: 5| Step: 4
Training loss: 3.142026424407959
Validation loss: 2.689970721801122

Epoch: 5| Step: 5
Training loss: 3.132929563522339
Validation loss: 2.686471482117971

Epoch: 5| Step: 6
Training loss: 2.879054069519043
Validation loss: 2.6830212672551474

Epoch: 5| Step: 7
Training loss: 3.561671733856201
Validation loss: 2.681954264640808

Epoch: 5| Step: 8
Training loss: 2.953061103820801
Validation loss: 2.6778282721837363

Epoch: 5| Step: 9
Training loss: 2.8301403522491455
Validation loss: 2.674126466115316

Epoch: 5| Step: 10
Training loss: 2.7888951301574707
Validation loss: 2.6710274716218314

Epoch: 5| Step: 11
Training loss: 2.0355567932128906
Validation loss: 2.669796735048294

Epoch: 43| Step: 0
Training loss: 2.7815632820129395
Validation loss: 2.6667922536532083

Epoch: 5| Step: 1
Training loss: 2.9470901489257812
Validation loss: 2.674722820520401

Epoch: 5| Step: 2
Training loss: 2.79597544670105
Validation loss: 2.6816877722740173

Epoch: 5| Step: 3
Training loss: 2.669358730316162
Validation loss: 2.6616311371326447

Epoch: 5| Step: 4
Training loss: 2.579725742340088
Validation loss: 2.655124088128408

Epoch: 5| Step: 5
Training loss: 3.2868545055389404
Validation loss: 2.6515122950077057

Epoch: 5| Step: 6
Training loss: 2.6148223876953125
Validation loss: 2.6486630539099374

Epoch: 5| Step: 7
Training loss: 3.028867721557617
Validation loss: 2.6490281422932944

Epoch: 5| Step: 8
Training loss: 2.788224458694458
Validation loss: 2.646508067846298

Epoch: 5| Step: 9
Training loss: 2.6184628009796143
Validation loss: 2.6457828084627786

Epoch: 5| Step: 10
Training loss: 3.1171956062316895
Validation loss: 2.6406956116358438

Epoch: 5| Step: 11
Training loss: 4.04135799407959
Validation loss: 2.6378451387087503

Epoch: 44| Step: 0
Training loss: 2.766472339630127
Validation loss: 2.6332557102044425

Epoch: 5| Step: 1
Training loss: 2.3945374488830566
Validation loss: 2.6287863552570343

Epoch: 5| Step: 2
Training loss: 2.868198871612549
Validation loss: 2.625344534715017

Epoch: 5| Step: 3
Training loss: 2.955500602722168
Validation loss: 2.6220655192931495

Epoch: 5| Step: 4
Training loss: 2.3513317108154297
Validation loss: 2.6191181540489197

Epoch: 5| Step: 5
Training loss: 3.2339560985565186
Validation loss: 2.614837884902954

Epoch: 5| Step: 6
Training loss: 2.487006187438965
Validation loss: 2.6114927232265472

Epoch: 5| Step: 7
Training loss: 3.5331053733825684
Validation loss: 2.608463078737259

Epoch: 5| Step: 8
Training loss: 2.8062171936035156
Validation loss: 2.6069546937942505

Epoch: 5| Step: 9
Training loss: 2.552351236343384
Validation loss: 2.603684812784195

Epoch: 5| Step: 10
Training loss: 3.2067904472351074
Validation loss: 2.60705628991127

Epoch: 5| Step: 11
Training loss: 2.072653293609619
Validation loss: 2.5995572805404663

Epoch: 45| Step: 0
Training loss: 3.145930290222168
Validation loss: 2.5963461498419442

Epoch: 5| Step: 1
Training loss: 2.446932792663574
Validation loss: 2.591396600008011

Epoch: 5| Step: 2
Training loss: 2.8233845233917236
Validation loss: 2.5855685075124106

Epoch: 5| Step: 3
Training loss: 2.8954086303710938
Validation loss: 2.5816188156604767

Epoch: 5| Step: 4
Training loss: 2.8525681495666504
Validation loss: 2.578004310528437

Epoch: 5| Step: 5
Training loss: 2.7940876483917236
Validation loss: 2.574278066555659

Epoch: 5| Step: 6
Training loss: 2.7007875442504883
Validation loss: 2.573516756296158

Epoch: 5| Step: 7
Training loss: 2.7691702842712402
Validation loss: 2.570147762695948

Epoch: 5| Step: 8
Training loss: 2.920607566833496
Validation loss: 2.566660607854525

Epoch: 5| Step: 9
Training loss: 2.825317144393921
Validation loss: 2.5639381408691406

Epoch: 5| Step: 10
Training loss: 2.5500168800354004
Validation loss: 2.5617567797501883

Epoch: 5| Step: 11
Training loss: 1.873431921005249
Validation loss: 2.5572671592235565

Epoch: 46| Step: 0
Training loss: 2.4277844429016113
Validation loss: 2.5592087507247925

Epoch: 5| Step: 1
Training loss: 2.3815841674804688
Validation loss: 2.56906924645106

Epoch: 5| Step: 2
Training loss: 2.672013759613037
Validation loss: 2.5520156721274057

Epoch: 5| Step: 3
Training loss: 2.935241460800171
Validation loss: 2.5471526384353638

Epoch: 5| Step: 4
Training loss: 2.6098732948303223
Validation loss: 2.544369558493296

Epoch: 5| Step: 5
Training loss: 2.826982021331787
Validation loss: 2.542670249938965

Epoch: 5| Step: 6
Training loss: 2.930232048034668
Validation loss: 2.5421223839124045

Epoch: 5| Step: 7
Training loss: 3.5723559856414795
Validation loss: 2.5434496055046716

Epoch: 5| Step: 8
Training loss: 2.9191763401031494
Validation loss: 2.534671743710836

Epoch: 5| Step: 9
Training loss: 2.6993157863616943
Validation loss: 2.531775265932083

Epoch: 5| Step: 10
Training loss: 2.4073691368103027
Validation loss: 2.532444973786672

Epoch: 5| Step: 11
Training loss: 1.577317476272583
Validation loss: 2.5257232586542764

Epoch: 47| Step: 0
Training loss: 3.498605728149414
Validation loss: 2.524350027243296

Epoch: 5| Step: 1
Training loss: 2.3172969818115234
Validation loss: 2.520782401164373

Epoch: 5| Step: 2
Training loss: 2.6373181343078613
Validation loss: 2.5195970286925635

Epoch: 5| Step: 3
Training loss: 2.6054847240448
Validation loss: 2.5169968605041504

Epoch: 5| Step: 4
Training loss: 2.7736144065856934
Validation loss: 2.514241655667623

Epoch: 5| Step: 5
Training loss: 2.638143301010132
Validation loss: 2.5112830698490143

Epoch: 5| Step: 6
Training loss: 2.379432201385498
Validation loss: 2.5111432472864785

Epoch: 5| Step: 7
Training loss: 2.3614633083343506
Validation loss: 2.508685419956843

Epoch: 5| Step: 8
Training loss: 3.2009100914001465
Validation loss: 2.507633070151011

Epoch: 5| Step: 9
Training loss: 2.6670446395874023
Validation loss: 2.5033302207787833

Epoch: 5| Step: 10
Training loss: 2.6782827377319336
Validation loss: 2.5056251287460327

Epoch: 5| Step: 11
Training loss: 2.6208527088165283
Validation loss: 2.4978688806295395

Epoch: 48| Step: 0
Training loss: 3.501962661743164
Validation loss: 2.4952187637488046

Epoch: 5| Step: 1
Training loss: 2.7489044666290283
Validation loss: 2.4918428560098014

Epoch: 5| Step: 2
Training loss: 2.4825847148895264
Validation loss: 2.4852364559968314

Epoch: 5| Step: 3
Training loss: 2.774932384490967
Validation loss: 2.484760115544001

Epoch: 5| Step: 4
Training loss: 2.9057679176330566
Validation loss: 2.487226357062658

Epoch: 5| Step: 5
Training loss: 2.1837010383605957
Validation loss: 2.4788826604684195

Epoch: 5| Step: 6
Training loss: 2.6980443000793457
Validation loss: 2.476033200820287

Epoch: 5| Step: 7
Training loss: 2.7858471870422363
Validation loss: 2.47740246852239

Epoch: 5| Step: 8
Training loss: 2.0594053268432617
Validation loss: 2.4718507130940757

Epoch: 5| Step: 9
Training loss: 2.719755172729492
Validation loss: 2.4697375744581223

Epoch: 5| Step: 10
Training loss: 2.6582326889038086
Validation loss: 2.467157964905103

Epoch: 5| Step: 11
Training loss: 1.8721461296081543
Validation loss: 2.4618273079395294

Epoch: 49| Step: 0
Training loss: 3.0135207176208496
Validation loss: 2.4628256062666574

Epoch: 5| Step: 1
Training loss: 2.6590311527252197
Validation loss: 2.46012482047081

Epoch: 5| Step: 2
Training loss: 2.6738858222961426
Validation loss: 2.4620545456806817

Epoch: 5| Step: 3
Training loss: 3.011192798614502
Validation loss: 2.456550041834513

Epoch: 5| Step: 4
Training loss: 3.0614418983459473
Validation loss: 2.449048638343811

Epoch: 5| Step: 5
Training loss: 2.5206427574157715
Validation loss: 2.4428289333979287

Epoch: 5| Step: 6
Training loss: 1.8085883855819702
Validation loss: 2.4444828430811563

Epoch: 5| Step: 7
Training loss: 2.1024794578552246
Validation loss: 2.4424554308255515

Epoch: 5| Step: 8
Training loss: 2.7377991676330566
Validation loss: 2.4373242557048798

Epoch: 5| Step: 9
Training loss: 3.1821279525756836
Validation loss: 2.4368723581234613

Epoch: 5| Step: 10
Training loss: 2.1695847511291504
Validation loss: 2.4310123225053153

Epoch: 5| Step: 11
Training loss: 2.8271543979644775
Validation loss: 2.4337540765603385

Epoch: 50| Step: 0
Training loss: 2.2828149795532227
Validation loss: 2.4256548384825387

Epoch: 5| Step: 1
Training loss: 2.638376235961914
Validation loss: 2.4301813344160714

Epoch: 5| Step: 2
Training loss: 2.9731814861297607
Validation loss: 2.4282318154970803

Epoch: 5| Step: 3
Training loss: 2.4968032836914062
Validation loss: 2.42320050795873

Epoch: 5| Step: 4
Training loss: 3.1029067039489746
Validation loss: 2.420573741197586

Epoch: 5| Step: 5
Training loss: 2.003206968307495
Validation loss: 2.4177333613236747

Epoch: 5| Step: 6
Training loss: 3.102724075317383
Validation loss: 2.4136246095101037

Epoch: 5| Step: 7
Training loss: 2.7225234508514404
Validation loss: 2.4135406712690988

Epoch: 5| Step: 8
Training loss: 2.6054255962371826
Validation loss: 2.41152860224247

Epoch: 5| Step: 9
Training loss: 2.2758278846740723
Validation loss: 2.406190941731135

Epoch: 5| Step: 10
Training loss: 2.6466588973999023
Validation loss: 2.4080185294151306

Epoch: 5| Step: 11
Training loss: 1.6102350950241089
Validation loss: 2.402782787879308

Epoch: 51| Step: 0
Training loss: 1.9379196166992188
Validation loss: 2.4022568265597024

Epoch: 5| Step: 1
Training loss: 3.049919605255127
Validation loss: 2.398463269074758

Epoch: 5| Step: 2
Training loss: 2.4406204223632812
Validation loss: 2.395436853170395

Epoch: 5| Step: 3
Training loss: 2.775757312774658
Validation loss: 2.390903910001119

Epoch: 5| Step: 4
Training loss: 3.2193474769592285
Validation loss: 2.3877261579036713

Epoch: 5| Step: 5
Training loss: 2.191092014312744
Validation loss: 2.3907200495402017

Epoch: 5| Step: 6
Training loss: 3.0631556510925293
Validation loss: 2.3845391869544983

Epoch: 5| Step: 7
Training loss: 2.195188522338867
Validation loss: 2.3831651707490287

Epoch: 5| Step: 8
Training loss: 2.7131526470184326
Validation loss: 2.3827980558077493

Epoch: 5| Step: 9
Training loss: 2.985776662826538
Validation loss: 2.3777932276328406

Epoch: 5| Step: 10
Training loss: 1.9326398372650146
Validation loss: 2.3768111964066825

Epoch: 5| Step: 11
Training loss: 1.067644476890564
Validation loss: 2.375262528657913

Epoch: 52| Step: 0
Training loss: 2.8011178970336914
Validation loss: 2.370016356309255

Epoch: 5| Step: 1
Training loss: 2.609964370727539
Validation loss: 2.368878742059072

Epoch: 5| Step: 2
Training loss: 2.8164985179901123
Validation loss: 2.3668821255366006

Epoch: 5| Step: 3
Training loss: 2.4074935913085938
Validation loss: 2.3607188165187836

Epoch: 5| Step: 4
Training loss: 2.4856255054473877
Validation loss: 2.3640463749567666

Epoch: 5| Step: 5
Training loss: 2.402965545654297
Validation loss: 2.3515833914279938

Epoch: 5| Step: 6
Training loss: 2.8356385231018066
Validation loss: 2.3538048466046653

Epoch: 5| Step: 7
Training loss: 2.5763697624206543
Validation loss: 2.3482761085033417

Epoch: 5| Step: 8
Training loss: 2.550339460372925
Validation loss: 2.342715402444204

Epoch: 5| Step: 9
Training loss: 1.9413686990737915
Validation loss: 2.342651387055715

Epoch: 5| Step: 10
Training loss: 2.668043613433838
Validation loss: 2.3423274755477905

Epoch: 5| Step: 11
Training loss: 0.9684548377990723
Validation loss: 2.337663024663925

Epoch: 53| Step: 0
Training loss: 2.2409467697143555
Validation loss: 2.3394721349080405

Epoch: 5| Step: 1
Training loss: 2.8460144996643066
Validation loss: 2.332156856854757

Epoch: 5| Step: 2
Training loss: 2.8382859230041504
Validation loss: 2.335040877262751

Epoch: 5| Step: 3
Training loss: 2.2661519050598145
Validation loss: 2.3300534884134927

Epoch: 5| Step: 4
Training loss: 2.372955322265625
Validation loss: 2.3282593290011087

Epoch: 5| Step: 5
Training loss: 2.5074994564056396
Validation loss: 2.325003147125244

Epoch: 5| Step: 6
Training loss: 2.657397747039795
Validation loss: 2.323612074057261

Epoch: 5| Step: 7
Training loss: 2.097642660140991
Validation loss: 2.3205907543500266

Epoch: 5| Step: 8
Training loss: 3.1909372806549072
Validation loss: 2.3211385359366736

Epoch: 5| Step: 9
Training loss: 2.088024854660034
Validation loss: 2.3193548222382865

Epoch: 5| Step: 10
Training loss: 2.249624729156494
Validation loss: 2.3183760344982147

Epoch: 5| Step: 11
Training loss: 2.989236831665039
Validation loss: 2.317664494117101

Epoch: 54| Step: 0
Training loss: 2.65403413772583
Validation loss: 2.3122275670369468

Epoch: 5| Step: 1
Training loss: 2.2715659141540527
Validation loss: 2.311054438352585

Epoch: 5| Step: 2
Training loss: 2.881718158721924
Validation loss: 2.3117564817269645

Epoch: 5| Step: 3
Training loss: 2.4172024726867676
Validation loss: 2.31100761393706

Epoch: 5| Step: 4
Training loss: 2.970160722732544
Validation loss: 2.3041194627682366

Epoch: 5| Step: 5
Training loss: 2.5429272651672363
Validation loss: 2.303614338239034

Epoch: 5| Step: 6
Training loss: 2.1002755165100098
Validation loss: 2.290714701016744

Epoch: 5| Step: 7
Training loss: 1.8085098266601562
Validation loss: 2.29358579715093

Epoch: 5| Step: 8
Training loss: 2.035006046295166
Validation loss: 2.2911051511764526

Epoch: 5| Step: 9
Training loss: 2.7353034019470215
Validation loss: 2.2867494871219

Epoch: 5| Step: 10
Training loss: 2.645866870880127
Validation loss: 2.292069981495539

Epoch: 5| Step: 11
Training loss: 2.6599225997924805
Validation loss: 2.291884938875834

Epoch: 55| Step: 0
Training loss: 1.9921340942382812
Validation loss: 2.280806839466095

Epoch: 5| Step: 1
Training loss: 2.987987995147705
Validation loss: 2.2770145386457443

Epoch: 5| Step: 2
Training loss: 2.360328197479248
Validation loss: 2.2744887868563333

Epoch: 5| Step: 3
Training loss: 2.1016457080841064
Validation loss: 2.2746519446372986

Epoch: 5| Step: 4
Training loss: 2.8486218452453613
Validation loss: 2.2762433191140494

Epoch: 5| Step: 5
Training loss: 1.906319260597229
Validation loss: 2.266334369778633

Epoch: 5| Step: 6
Training loss: 2.668475389480591
Validation loss: 2.2633732557296753

Epoch: 5| Step: 7
Training loss: 2.7410285472869873
Validation loss: 2.2594657838344574

Epoch: 5| Step: 8
Training loss: 2.73115611076355
Validation loss: 2.2598025798797607

Epoch: 5| Step: 9
Training loss: 1.8406184911727905
Validation loss: 2.262480785449346

Epoch: 5| Step: 10
Training loss: 2.5662097930908203
Validation loss: 2.2576903303464255

Epoch: 5| Step: 11
Training loss: 2.5152835845947266
Validation loss: 2.260389228661855

Epoch: 56| Step: 0
Training loss: 2.5417771339416504
Validation loss: 2.2585120797157288

Epoch: 5| Step: 1
Training loss: 2.555922031402588
Validation loss: 2.257236917813619

Epoch: 5| Step: 2
Training loss: 2.189751148223877
Validation loss: 2.2536989649136863

Epoch: 5| Step: 3
Training loss: 2.431011915206909
Validation loss: 2.2545232574144998

Epoch: 5| Step: 4
Training loss: 1.6612975597381592
Validation loss: 2.2522004495064416

Epoch: 5| Step: 5
Training loss: 1.8873211145401
Validation loss: 2.247316434979439

Epoch: 5| Step: 6
Training loss: 2.6886818408966064
Validation loss: 2.247288038333257

Epoch: 5| Step: 7
Training loss: 2.7737016677856445
Validation loss: 2.23946945865949

Epoch: 5| Step: 8
Training loss: 2.963106632232666
Validation loss: 2.2383688588937125

Epoch: 5| Step: 9
Training loss: 2.256056547164917
Validation loss: 2.2346764653921127

Epoch: 5| Step: 10
Training loss: 2.250725269317627
Validation loss: 2.232778936624527

Epoch: 5| Step: 11
Training loss: 3.6868295669555664
Validation loss: 2.2303553422292075

Epoch: 57| Step: 0
Training loss: 2.2925477027893066
Validation loss: 2.2280904352664948

Epoch: 5| Step: 1
Training loss: 2.493587017059326
Validation loss: 2.2280823091665902

Epoch: 5| Step: 2
Training loss: 2.1298468112945557
Validation loss: 2.227184772491455

Epoch: 5| Step: 3
Training loss: 2.633255958557129
Validation loss: 2.2190084556738534

Epoch: 5| Step: 4
Training loss: 2.0600571632385254
Validation loss: 2.219081242879232

Epoch: 5| Step: 5
Training loss: 2.7324042320251465
Validation loss: 2.2113573451836905

Epoch: 5| Step: 6
Training loss: 2.243968963623047
Validation loss: 2.211166128516197

Epoch: 5| Step: 7
Training loss: 2.4345364570617676
Validation loss: 2.2120878199736276

Epoch: 5| Step: 8
Training loss: 2.309117078781128
Validation loss: 2.2044290204842887

Epoch: 5| Step: 9
Training loss: 2.696901559829712
Validation loss: 2.202793449163437

Epoch: 5| Step: 10
Training loss: 2.242523670196533
Validation loss: 2.2081370850404105

Epoch: 5| Step: 11
Training loss: 1.2909142971038818
Validation loss: 2.2112487802902856

Epoch: 58| Step: 0
Training loss: 2.5437943935394287
Validation loss: 2.2120766639709473

Epoch: 5| Step: 1
Training loss: 2.597007989883423
Validation loss: 2.2113494277000427

Epoch: 5| Step: 2
Training loss: 2.4130239486694336
Validation loss: 2.2090181608994803

Epoch: 5| Step: 3
Training loss: 2.6644299030303955
Validation loss: 2.2067221949497857

Epoch: 5| Step: 4
Training loss: 2.647834062576294
Validation loss: 2.19567442437013

Epoch: 5| Step: 5
Training loss: 2.3005547523498535
Validation loss: 2.19768658777078

Epoch: 5| Step: 6
Training loss: 2.216966152191162
Validation loss: 2.1934003233909607

Epoch: 5| Step: 7
Training loss: 2.06221866607666
Validation loss: 2.193463255961736

Epoch: 5| Step: 8
Training loss: 1.8249362707138062
Validation loss: 2.1905197352170944

Epoch: 5| Step: 9
Training loss: 2.0291075706481934
Validation loss: 2.1891257961591086

Epoch: 5| Step: 10
Training loss: 2.7511019706726074
Validation loss: 2.1869393239418664

Epoch: 5| Step: 11
Training loss: 1.5795998573303223
Validation loss: 2.181578462322553

Epoch: 59| Step: 0
Training loss: 2.2614033222198486
Validation loss: 2.185662349065145

Epoch: 5| Step: 1
Training loss: 2.291846513748169
Validation loss: 2.1816113193829856

Epoch: 5| Step: 2
Training loss: 1.988525390625
Validation loss: 2.171829139192899

Epoch: 5| Step: 3
Training loss: 2.0472331047058105
Validation loss: 2.1768064747254052

Epoch: 5| Step: 4
Training loss: 2.037595748901367
Validation loss: 2.179012288649877

Epoch: 5| Step: 5
Training loss: 2.590742349624634
Validation loss: 2.1842204531033835

Epoch: 5| Step: 6
Training loss: 2.290177345275879
Validation loss: 2.1693019568920135

Epoch: 5| Step: 7
Training loss: 2.5650391578674316
Validation loss: 2.171857163310051

Epoch: 5| Step: 8
Training loss: 2.0672309398651123
Validation loss: 2.1732117384672165

Epoch: 5| Step: 9
Training loss: 2.58284330368042
Validation loss: 2.1809651305278144

Epoch: 5| Step: 10
Training loss: 2.6973557472229004
Validation loss: 2.1781532615423203

Epoch: 5| Step: 11
Training loss: 4.07984733581543
Validation loss: 2.1790140122175217

Epoch: 60| Step: 0
Training loss: 2.4938080310821533
Validation loss: 2.1859328001737595

Epoch: 5| Step: 1
Training loss: 1.8897497653961182
Validation loss: 2.187428966164589

Epoch: 5| Step: 2
Training loss: 2.590188503265381
Validation loss: 2.187131106853485

Epoch: 5| Step: 3
Training loss: 2.3436331748962402
Validation loss: 2.183165247241656

Epoch: 5| Step: 4
Training loss: 2.911991596221924
Validation loss: 2.1806779305140176

Epoch: 5| Step: 5
Training loss: 2.004098415374756
Validation loss: 2.181130826473236

Epoch: 5| Step: 6
Training loss: 2.3880372047424316
Validation loss: 2.1724791626135507

Epoch: 5| Step: 7
Training loss: 2.55564546585083
Validation loss: 2.1743916173775992

Epoch: 5| Step: 8
Training loss: 2.481459617614746
Validation loss: 2.1679309755563736

Epoch: 5| Step: 9
Training loss: 1.9225728511810303
Validation loss: 2.170013298590978

Epoch: 5| Step: 10
Training loss: 2.202411651611328
Validation loss: 2.161664769053459

Epoch: 5| Step: 11
Training loss: 1.941643476486206
Validation loss: 2.1517715950806937

Epoch: 61| Step: 0
Training loss: 2.1627745628356934
Validation loss: 2.150400082270304

Epoch: 5| Step: 1
Training loss: 2.7088494300842285
Validation loss: 2.152946109573046

Epoch: 5| Step: 2
Training loss: 2.458899974822998
Validation loss: 2.152659257253011

Epoch: 5| Step: 3
Training loss: 1.6545889377593994
Validation loss: 2.146705076098442

Epoch: 5| Step: 4
Training loss: 2.3993632793426514
Validation loss: 2.146401673555374

Epoch: 5| Step: 5
Training loss: 2.4107959270477295
Validation loss: 2.148768891890844

Epoch: 5| Step: 6
Training loss: 2.31264066696167
Validation loss: 2.146415283282598

Epoch: 5| Step: 7
Training loss: 2.4273645877838135
Validation loss: 2.142148956656456

Epoch: 5| Step: 8
Training loss: 2.906702995300293
Validation loss: 2.1431659311056137

Epoch: 5| Step: 9
Training loss: 2.278754711151123
Validation loss: 2.1405814389387765

Epoch: 5| Step: 10
Training loss: 1.9431995153427124
Validation loss: 2.1397941956917443

Epoch: 5| Step: 11
Training loss: 1.4621691703796387
Validation loss: 2.139139731725057

Epoch: 62| Step: 0
Training loss: 2.9276199340820312
Validation loss: 2.148971368869146

Epoch: 5| Step: 1
Training loss: 1.9688688516616821
Validation loss: 2.1516399582227073

Epoch: 5| Step: 2
Training loss: 2.5431272983551025
Validation loss: 2.151977077126503

Epoch: 5| Step: 3
Training loss: 1.7439353466033936
Validation loss: 2.147725368539492

Epoch: 5| Step: 4
Training loss: 2.410937547683716
Validation loss: 2.159166286389033

Epoch: 5| Step: 5
Training loss: 2.2185869216918945
Validation loss: 2.16629691918691

Epoch: 5| Step: 6
Training loss: 2.7533316612243652
Validation loss: 2.1731755832831063

Epoch: 5| Step: 7
Training loss: 2.4216971397399902
Validation loss: 2.1625254402558007

Epoch: 5| Step: 8
Training loss: 2.4065752029418945
Validation loss: 2.1477776815493903

Epoch: 5| Step: 9
Training loss: 2.04811429977417
Validation loss: 2.132834499080976

Epoch: 5| Step: 10
Training loss: 2.073718786239624
Validation loss: 2.128217861056328

Epoch: 5| Step: 11
Training loss: 2.105766773223877
Validation loss: 2.1276126354932785

Epoch: 63| Step: 0
Training loss: 2.1584537029266357
Validation loss: 2.1268677612145743

Epoch: 5| Step: 1
Training loss: 2.1894946098327637
Validation loss: 2.1287865142027536

Epoch: 5| Step: 2
Training loss: 2.3542513847351074
Validation loss: 2.1274235198895135

Epoch: 5| Step: 3
Training loss: 2.168424129486084
Validation loss: 2.127275546391805

Epoch: 5| Step: 4
Training loss: 2.5772640705108643
Validation loss: 2.125520537296931

Epoch: 5| Step: 5
Training loss: 2.2105915546417236
Validation loss: 2.1274517526229224

Epoch: 5| Step: 6
Training loss: 1.9728208780288696
Validation loss: 2.1279847721258798

Epoch: 5| Step: 7
Training loss: 1.938706398010254
Validation loss: 2.123816132545471

Epoch: 5| Step: 8
Training loss: 2.629348039627075
Validation loss: 2.125211904446284

Epoch: 5| Step: 9
Training loss: 2.3590023517608643
Validation loss: 2.1233797719081244

Epoch: 5| Step: 10
Training loss: 2.625884532928467
Validation loss: 2.1197545329729715

Epoch: 5| Step: 11
Training loss: 2.562441825866699
Validation loss: 2.118706459800402

Epoch: 64| Step: 0
Training loss: 2.740941286087036
Validation loss: 2.115604360898336

Epoch: 5| Step: 1
Training loss: 2.481257915496826
Validation loss: 2.124125142892202

Epoch: 5| Step: 2
Training loss: 2.2215847969055176
Validation loss: 2.1145471731821694

Epoch: 5| Step: 3
Training loss: 2.319897413253784
Validation loss: 2.111272523800532

Epoch: 5| Step: 4
Training loss: 2.4263713359832764
Validation loss: 2.112520898381869

Epoch: 5| Step: 5
Training loss: 1.9839088916778564
Validation loss: 2.1056838035583496

Epoch: 5| Step: 6
Training loss: 2.207031726837158
Validation loss: 2.1103925108909607

Epoch: 5| Step: 7
Training loss: 1.971408486366272
Validation loss: 2.0988165934880576

Epoch: 5| Step: 8
Training loss: 1.9434058666229248
Validation loss: 2.104202205936114

Epoch: 5| Step: 9
Training loss: 2.2928688526153564
Validation loss: 2.1038520137468972

Epoch: 5| Step: 10
Training loss: 2.511106491088867
Validation loss: 2.1005345980326333

Epoch: 5| Step: 11
Training loss: 2.896979331970215
Validation loss: 2.100042854746183

Epoch: 65| Step: 0
Training loss: 1.9681570529937744
Validation loss: 2.1016364643971124

Epoch: 5| Step: 1
Training loss: 2.1408653259277344
Validation loss: 2.1033228933811188

Epoch: 5| Step: 2
Training loss: 2.122767925262451
Validation loss: 2.1049106816450753

Epoch: 5| Step: 3
Training loss: 1.876155138015747
Validation loss: 2.1020149290561676

Epoch: 5| Step: 4
Training loss: 2.5683884620666504
Validation loss: 2.1011761824289956

Epoch: 5| Step: 5
Training loss: 1.9836442470550537
Validation loss: 2.092799117167791

Epoch: 5| Step: 6
Training loss: 2.995676279067993
Validation loss: 2.0996293822924295

Epoch: 5| Step: 7
Training loss: 2.3604533672332764
Validation loss: 2.0977512300014496

Epoch: 5| Step: 8
Training loss: 2.06205415725708
Validation loss: 2.0984088480472565

Epoch: 5| Step: 9
Training loss: 2.3432435989379883
Validation loss: 2.0985210041205087

Epoch: 5| Step: 10
Training loss: 2.4898793697357178
Validation loss: 2.0952931344509125

Epoch: 5| Step: 11
Training loss: 2.8696813583374023
Validation loss: 2.095009451111158

Epoch: 66| Step: 0
Training loss: 2.159639358520508
Validation loss: 2.0972084452708564

Epoch: 5| Step: 1
Training loss: 2.0335819721221924
Validation loss: 2.0942083100477853

Epoch: 5| Step: 2
Training loss: 2.136657238006592
Validation loss: 2.1029078364372253

Epoch: 5| Step: 3
Training loss: 2.2004241943359375
Validation loss: 2.0978363355000815

Epoch: 5| Step: 4
Training loss: 2.0435636043548584
Validation loss: 2.0965881049633026

Epoch: 5| Step: 5
Training loss: 1.8380324840545654
Validation loss: 2.0887086540460587

Epoch: 5| Step: 6
Training loss: 2.2582268714904785
Validation loss: 2.094274580478668

Epoch: 5| Step: 7
Training loss: 2.2669007778167725
Validation loss: 2.0978974302609763

Epoch: 5| Step: 8
Training loss: 2.265068531036377
Validation loss: 2.095828672250112

Epoch: 5| Step: 9
Training loss: 2.8507113456726074
Validation loss: 2.095020984609922

Epoch: 5| Step: 10
Training loss: 2.914929151535034
Validation loss: 2.100646754105886

Epoch: 5| Step: 11
Training loss: 2.8590152263641357
Validation loss: 2.101662109295527

Epoch: 67| Step: 0
Training loss: 1.9736274480819702
Validation loss: 2.096463998158773

Epoch: 5| Step: 1
Training loss: 2.7304415702819824
Validation loss: 2.0892307609319687

Epoch: 5| Step: 2
Training loss: 2.4696524143218994
Validation loss: 2.0841713597377143

Epoch: 5| Step: 3
Training loss: 2.4611144065856934
Validation loss: 2.0823403845230737

Epoch: 5| Step: 4
Training loss: 2.3512463569641113
Validation loss: 2.088180790344874

Epoch: 5| Step: 5
Training loss: 2.009756565093994
Validation loss: 2.095771625638008

Epoch: 5| Step: 6
Training loss: 1.854860544204712
Validation loss: 2.101945529381434

Epoch: 5| Step: 7
Training loss: 2.1073660850524902
Validation loss: 2.0965347588062286

Epoch: 5| Step: 8
Training loss: 2.4102046489715576
Validation loss: 2.0926277190446854

Epoch: 5| Step: 9
Training loss: 2.499990940093994
Validation loss: 2.0901125917832055

Epoch: 5| Step: 10
Training loss: 2.2115540504455566
Validation loss: 2.081727067629496

Epoch: 5| Step: 11
Training loss: 1.7276027202606201
Validation loss: 2.0825127561887107

Epoch: 68| Step: 0
Training loss: 2.1640524864196777
Validation loss: 2.0808371106783548

Epoch: 5| Step: 1
Training loss: 1.7727491855621338
Validation loss: 2.0786698907613754

Epoch: 5| Step: 2
Training loss: 2.5261473655700684
Validation loss: 2.085418865084648

Epoch: 5| Step: 3
Training loss: 2.5380754470825195
Validation loss: 2.0897759397824607

Epoch: 5| Step: 4
Training loss: 2.36015248298645
Validation loss: 2.08906626701355

Epoch: 5| Step: 5
Training loss: 1.960253119468689
Validation loss: 2.094018722573916

Epoch: 5| Step: 6
Training loss: 2.369553804397583
Validation loss: 2.09139446914196

Epoch: 5| Step: 7
Training loss: 1.6685634851455688
Validation loss: 2.091853529214859

Epoch: 5| Step: 8
Training loss: 2.465374708175659
Validation loss: 2.0872310400009155

Epoch: 5| Step: 9
Training loss: 2.8395426273345947
Validation loss: 2.0912415186564126

Epoch: 5| Step: 10
Training loss: 2.2598047256469727
Validation loss: 2.0868672331174216

Epoch: 5| Step: 11
Training loss: 2.0050063133239746
Validation loss: 2.092441270748774

Epoch: 69| Step: 0
Training loss: 2.386474370956421
Validation loss: 2.078792596856753

Epoch: 5| Step: 1
Training loss: 2.43324613571167
Validation loss: 2.0714900443951287

Epoch: 5| Step: 2
Training loss: 2.2776737213134766
Validation loss: 2.0663360009590783

Epoch: 5| Step: 3
Training loss: 2.245473861694336
Validation loss: 2.0722198138634362

Epoch: 5| Step: 4
Training loss: 2.619675874710083
Validation loss: 2.066815902789434

Epoch: 5| Step: 5
Training loss: 2.2135119438171387
Validation loss: 2.064262871940931

Epoch: 5| Step: 6
Training loss: 2.2746505737304688
Validation loss: 2.0679064144690833

Epoch: 5| Step: 7
Training loss: 2.1427512168884277
Validation loss: 2.0635971228281655

Epoch: 5| Step: 8
Training loss: 2.079305410385132
Validation loss: 2.067917068799337

Epoch: 5| Step: 9
Training loss: 2.1706442832946777
Validation loss: 2.065555602312088

Epoch: 5| Step: 10
Training loss: 1.8508412837982178
Validation loss: 2.064367711544037

Epoch: 5| Step: 11
Training loss: 1.9732682704925537
Validation loss: 2.065516178806623

Epoch: 70| Step: 0
Training loss: 2.068510055541992
Validation loss: 2.0918592313925424

Epoch: 5| Step: 1
Training loss: 2.3578410148620605
Validation loss: 2.096501737833023

Epoch: 5| Step: 2
Training loss: 1.696406602859497
Validation loss: 2.105609973271688

Epoch: 5| Step: 3
Training loss: 2.3775367736816406
Validation loss: 2.0879827986160913

Epoch: 5| Step: 4
Training loss: 2.6775386333465576
Validation loss: 2.0666162768999734

Epoch: 5| Step: 5
Training loss: 1.8632726669311523
Validation loss: 2.0565730780363083

Epoch: 5| Step: 6
Training loss: 2.000821352005005
Validation loss: 2.0501947700977325

Epoch: 5| Step: 7
Training loss: 1.8867485523223877
Validation loss: 2.064302255709966

Epoch: 5| Step: 8
Training loss: 2.4109911918640137
Validation loss: 2.0789149552583694

Epoch: 5| Step: 9
Training loss: 2.8733010292053223
Validation loss: 2.0839751164118447

Epoch: 5| Step: 10
Training loss: 2.2918286323547363
Validation loss: 2.0942514737447104

Epoch: 5| Step: 11
Training loss: 3.0954480171203613
Validation loss: 2.093070387840271

Epoch: 71| Step: 0
Training loss: 2.8667070865631104
Validation loss: 2.0962654650211334

Epoch: 5| Step: 1
Training loss: 1.9446561336517334
Validation loss: 2.0918380866448083

Epoch: 5| Step: 2
Training loss: 2.416024923324585
Validation loss: 2.091998259226481

Epoch: 5| Step: 3
Training loss: 1.7234299182891846
Validation loss: 2.085816184679667

Epoch: 5| Step: 4
Training loss: 1.9244544506072998
Validation loss: 2.0724123964707055

Epoch: 5| Step: 5
Training loss: 2.666712760925293
Validation loss: 2.070586989323298

Epoch: 5| Step: 6
Training loss: 1.9798568487167358
Validation loss: 2.0634150405724845

Epoch: 5| Step: 7
Training loss: 2.6740469932556152
Validation loss: 2.0587159792582193

Epoch: 5| Step: 8
Training loss: 2.131368637084961
Validation loss: 2.0570011089245477

Epoch: 5| Step: 9
Training loss: 2.215282440185547
Validation loss: 2.0507591664791107

Epoch: 5| Step: 10
Training loss: 2.058898687362671
Validation loss: 2.045160874724388

Epoch: 5| Step: 11
Training loss: 2.963616371154785
Validation loss: 2.051008015871048

Epoch: 72| Step: 0
Training loss: 2.694126605987549
Validation loss: 2.0643904159466424

Epoch: 5| Step: 1
Training loss: 2.8396124839782715
Validation loss: 2.0676800111929574

Epoch: 5| Step: 2
Training loss: 1.6640262603759766
Validation loss: 2.0710185120503106

Epoch: 5| Step: 3
Training loss: 1.7514543533325195
Validation loss: 2.0621682703495026

Epoch: 5| Step: 4
Training loss: 2.5625693798065186
Validation loss: 2.054955164591471

Epoch: 5| Step: 5
Training loss: 1.8177406787872314
Validation loss: 2.054466297229131

Epoch: 5| Step: 6
Training loss: 2.4940874576568604
Validation loss: 2.044528608520826

Epoch: 5| Step: 7
Training loss: 2.2240946292877197
Validation loss: 2.046538988749186

Epoch: 5| Step: 8
Training loss: 2.7574617862701416
Validation loss: 2.043978442748388

Epoch: 5| Step: 9
Training loss: 1.743188500404358
Validation loss: 2.042159949739774

Epoch: 5| Step: 10
Training loss: 2.1331582069396973
Validation loss: 2.0358362197875977

Epoch: 5| Step: 11
Training loss: 2.591982364654541
Validation loss: 2.0342537462711334

Epoch: 73| Step: 0
Training loss: 2.230534791946411
Validation loss: 2.0383988320827484

Epoch: 5| Step: 1
Training loss: 2.336642026901245
Validation loss: 2.0334738741318383

Epoch: 5| Step: 2
Training loss: 2.134521007537842
Validation loss: 2.0373305529356003

Epoch: 5| Step: 3
Training loss: 2.533583402633667
Validation loss: 2.0410219530264535

Epoch: 5| Step: 4
Training loss: 2.4780032634735107
Validation loss: 2.042500858505567

Epoch: 5| Step: 5
Training loss: 2.5065348148345947
Validation loss: 2.0368855347236

Epoch: 5| Step: 6
Training loss: 1.6914854049682617
Validation loss: 2.0531774908304214

Epoch: 5| Step: 7
Training loss: 2.416419506072998
Validation loss: 2.044223432739576

Epoch: 5| Step: 8
Training loss: 2.099494457244873
Validation loss: 2.040910556912422

Epoch: 5| Step: 9
Training loss: 1.7498260736465454
Validation loss: 2.0388169288635254

Epoch: 5| Step: 10
Training loss: 2.422405481338501
Validation loss: 2.0414793888727822

Epoch: 5| Step: 11
Training loss: 1.755312442779541
Validation loss: 2.039304365714391

Epoch: 74| Step: 0
Training loss: 2.1504735946655273
Validation loss: 2.0362784465154014

Epoch: 5| Step: 1
Training loss: 2.2042644023895264
Validation loss: 2.0411194215218225

Epoch: 5| Step: 2
Training loss: 2.3346853256225586
Validation loss: 2.0398732076088586

Epoch: 5| Step: 3
Training loss: 2.5362019538879395
Validation loss: 2.039514203866323

Epoch: 5| Step: 4
Training loss: 1.7986490726470947
Validation loss: 2.042510211467743

Epoch: 5| Step: 5
Training loss: 2.802003860473633
Validation loss: 2.039950663844744

Epoch: 5| Step: 6
Training loss: 1.9563148021697998
Validation loss: 2.0422891080379486

Epoch: 5| Step: 7
Training loss: 1.8507392406463623
Validation loss: 2.0359606742858887

Epoch: 5| Step: 8
Training loss: 2.449861764907837
Validation loss: 2.0366143782933555

Epoch: 5| Step: 9
Training loss: 2.1212189197540283
Validation loss: 2.033631523450216

Epoch: 5| Step: 10
Training loss: 2.2040703296661377
Validation loss: 2.0345329145590463

Epoch: 5| Step: 11
Training loss: 2.6879055500030518
Validation loss: 2.0309643695751824

Epoch: 75| Step: 0
Training loss: 2.4501049518585205
Validation loss: 2.0311045050621033

Epoch: 5| Step: 1
Training loss: 2.2758915424346924
Validation loss: 2.0316879401604333

Epoch: 5| Step: 2
Training loss: 2.5523195266723633
Validation loss: 2.0431632548570633

Epoch: 5| Step: 3
Training loss: 2.116518974304199
Validation loss: 2.0427158772945404

Epoch: 5| Step: 4
Training loss: 1.9645564556121826
Validation loss: 2.047342454393705

Epoch: 5| Step: 5
Training loss: 2.2614591121673584
Validation loss: 2.0487894813219705

Epoch: 5| Step: 6
Training loss: 2.384969711303711
Validation loss: 2.0452612390120826

Epoch: 5| Step: 7
Training loss: 2.358426809310913
Validation loss: 2.048761655886968

Epoch: 5| Step: 8
Training loss: 1.4828109741210938
Validation loss: 2.047007570664088

Epoch: 5| Step: 9
Training loss: 2.289703369140625
Validation loss: 2.0431408186753592

Epoch: 5| Step: 10
Training loss: 2.305424690246582
Validation loss: 2.0373844355344772

Epoch: 5| Step: 11
Training loss: 2.5476417541503906
Validation loss: 2.033698389927546

Epoch: 76| Step: 0
Training loss: 2.095783233642578
Validation loss: 2.032213717699051

Epoch: 5| Step: 1
Training loss: 2.7169408798217773
Validation loss: 2.031858036915461

Epoch: 5| Step: 2
Training loss: 2.146918773651123
Validation loss: 2.027988071242968

Epoch: 5| Step: 3
Training loss: 1.832588791847229
Validation loss: 2.029670938849449

Epoch: 5| Step: 4
Training loss: 1.98246169090271
Validation loss: 2.0249172846476235

Epoch: 5| Step: 5
Training loss: 1.7508080005645752
Validation loss: 2.0247288097937903

Epoch: 5| Step: 6
Training loss: 1.8597240447998047
Validation loss: 2.0272356569767

Epoch: 5| Step: 7
Training loss: 2.528560161590576
Validation loss: 2.023652826746305

Epoch: 5| Step: 8
Training loss: 2.9960289001464844
Validation loss: 2.028216153383255

Epoch: 5| Step: 9
Training loss: 2.3597145080566406
Validation loss: 2.0334576865037284

Epoch: 5| Step: 10
Training loss: 2.1183011531829834
Validation loss: 2.031043440103531

Epoch: 5| Step: 11
Training loss: 2.3980579376220703
Validation loss: 2.034163162112236

Epoch: 77| Step: 0
Training loss: 2.079077959060669
Validation loss: 2.042223865787188

Epoch: 5| Step: 1
Training loss: 1.6137447357177734
Validation loss: 2.029013137022654

Epoch: 5| Step: 2
Training loss: 2.369723081588745
Validation loss: 2.0316634674866996

Epoch: 5| Step: 3
Training loss: 1.6933733224868774
Validation loss: 2.0352840622266135

Epoch: 5| Step: 4
Training loss: 2.0354855060577393
Validation loss: 2.0331104000409446

Epoch: 5| Step: 5
Training loss: 2.3489840030670166
Validation loss: 2.0272987286249795

Epoch: 5| Step: 6
Training loss: 3.1135363578796387
Validation loss: 2.036158119638761

Epoch: 5| Step: 7
Training loss: 2.346815586090088
Validation loss: 2.0234453032414117

Epoch: 5| Step: 8
Training loss: 2.628133773803711
Validation loss: 2.020738328496615

Epoch: 5| Step: 9
Training loss: 1.9270025491714478
Validation loss: 2.0262147784233093

Epoch: 5| Step: 10
Training loss: 2.277599334716797
Validation loss: 2.02303255101045

Epoch: 5| Step: 11
Training loss: 0.8783584833145142
Validation loss: 2.029115746418635

Epoch: 78| Step: 0
Training loss: 2.344820022583008
Validation loss: 2.03366826971372

Epoch: 5| Step: 1
Training loss: 2.3695600032806396
Validation loss: 2.0351949632167816

Epoch: 5| Step: 2
Training loss: 2.455923318862915
Validation loss: 2.0378964245319366

Epoch: 5| Step: 3
Training loss: 2.3793742656707764
Validation loss: 2.0355474849541983

Epoch: 5| Step: 4
Training loss: 2.2886359691619873
Validation loss: 2.039073020219803

Epoch: 5| Step: 5
Training loss: 2.340846538543701
Validation loss: 2.0364913940429688

Epoch: 5| Step: 6
Training loss: 2.3308773040771484
Validation loss: 2.0402498841285706

Epoch: 5| Step: 7
Training loss: 1.6342874765396118
Validation loss: 2.0384351313114166

Epoch: 5| Step: 8
Training loss: 2.014346122741699
Validation loss: 2.0365747958421707

Epoch: 5| Step: 9
Training loss: 2.215305805206299
Validation loss: 2.0332814107338586

Epoch: 5| Step: 10
Training loss: 1.879852294921875
Validation loss: 2.027789538105329

Epoch: 5| Step: 11
Training loss: 2.9212894439697266
Validation loss: 2.026965767145157

Epoch: 79| Step: 0
Training loss: 2.754838466644287
Validation loss: 2.019994080066681

Epoch: 5| Step: 1
Training loss: 2.2782745361328125
Validation loss: 2.019024595618248

Epoch: 5| Step: 2
Training loss: 2.264726161956787
Validation loss: 2.0097850610812507

Epoch: 5| Step: 3
Training loss: 1.9368047714233398
Validation loss: 2.0221508791049323

Epoch: 5| Step: 4
Training loss: 2.421729326248169
Validation loss: 2.018243004878362

Epoch: 5| Step: 5
Training loss: 1.8849270343780518
Validation loss: 2.0261614670356116

Epoch: 5| Step: 6
Training loss: 2.029740571975708
Validation loss: 2.0211347391208014

Epoch: 5| Step: 7
Training loss: 2.311516523361206
Validation loss: 2.0216340720653534

Epoch: 5| Step: 8
Training loss: 2.0836679935455322
Validation loss: 2.024594704310099

Epoch: 5| Step: 9
Training loss: 2.355396032333374
Validation loss: 2.0261160085598626

Epoch: 5| Step: 10
Training loss: 2.052858829498291
Validation loss: 2.0333596219619117

Epoch: 5| Step: 11
Training loss: 1.2546014785766602
Validation loss: 2.0342979033788047

Epoch: 80| Step: 0
Training loss: 2.4682469367980957
Validation loss: 2.032113586862882

Epoch: 5| Step: 1
Training loss: 2.2542262077331543
Validation loss: 2.02944445113341

Epoch: 5| Step: 2
Training loss: 2.3005008697509766
Validation loss: 2.0290383398532867

Epoch: 5| Step: 3
Training loss: 2.1230883598327637
Validation loss: 2.021868273615837

Epoch: 5| Step: 4
Training loss: 2.4357738494873047
Validation loss: 2.0179639061292014

Epoch: 5| Step: 5
Training loss: 2.0361900329589844
Validation loss: 2.0218610614538193

Epoch: 5| Step: 6
Training loss: 1.968920111656189
Validation loss: 2.007070561250051

Epoch: 5| Step: 7
Training loss: 1.931530237197876
Validation loss: 2.0110903133948645

Epoch: 5| Step: 8
Training loss: 2.677259922027588
Validation loss: 2.01772578060627

Epoch: 5| Step: 9
Training loss: 2.0994372367858887
Validation loss: 2.010414053996404

Epoch: 5| Step: 10
Training loss: 1.9110956192016602
Validation loss: 2.0083605547746024

Epoch: 5| Step: 11
Training loss: 1.2171019315719604
Validation loss: 2.008964086572329

Epoch: 81| Step: 0
Training loss: 2.2109146118164062
Validation loss: 2.0068551500638327

Epoch: 5| Step: 1
Training loss: 2.911982297897339
Validation loss: 2.0232878824075065

Epoch: 5| Step: 2
Training loss: 1.9840621948242188
Validation loss: 2.0167352159818015

Epoch: 5| Step: 3
Training loss: 2.177154064178467
Validation loss: 2.029267758131027

Epoch: 5| Step: 4
Training loss: 2.1218795776367188
Validation loss: 2.0205121586720147

Epoch: 5| Step: 5
Training loss: 1.9554532766342163
Validation loss: 2.021432360013326

Epoch: 5| Step: 6
Training loss: 1.883535385131836
Validation loss: 2.0129691064357758

Epoch: 5| Step: 7
Training loss: 2.442545175552368
Validation loss: 2.003886034091314

Epoch: 5| Step: 8
Training loss: 2.1149966716766357
Validation loss: 2.0196920384963355

Epoch: 5| Step: 9
Training loss: 2.0623371601104736
Validation loss: 2.014540975292524

Epoch: 5| Step: 10
Training loss: 2.3611621856689453
Validation loss: 2.013471856713295

Epoch: 5| Step: 11
Training loss: 1.4197115898132324
Validation loss: 2.0188137342532477

Epoch: 82| Step: 0
Training loss: 2.2882649898529053
Validation loss: 2.026557053128878

Epoch: 5| Step: 1
Training loss: 2.4573991298675537
Validation loss: 2.0208105395237603

Epoch: 5| Step: 2
Training loss: 2.4611518383026123
Validation loss: 2.027244880795479

Epoch: 5| Step: 3
Training loss: 1.7930206060409546
Validation loss: 2.0263796150684357

Epoch: 5| Step: 4
Training loss: 2.604515790939331
Validation loss: 2.021468381086985

Epoch: 5| Step: 5
Training loss: 1.779205083847046
Validation loss: 2.0274695803721747

Epoch: 5| Step: 6
Training loss: 1.826316475868225
Validation loss: 2.016760841012001

Epoch: 5| Step: 7
Training loss: 2.223194122314453
Validation loss: 2.0117627580960593

Epoch: 5| Step: 8
Training loss: 2.4732062816619873
Validation loss: 2.018817961215973

Epoch: 5| Step: 9
Training loss: 2.010735034942627
Validation loss: 2.015479803085327

Epoch: 5| Step: 10
Training loss: 1.9723701477050781
Validation loss: 2.0176108876864114

Epoch: 5| Step: 11
Training loss: 2.4340453147888184
Validation loss: 2.026041259368261

Epoch: 83| Step: 0
Training loss: 2.3800647258758545
Validation loss: 2.018988400697708

Epoch: 5| Step: 1
Training loss: 2.35597825050354
Validation loss: 2.011194700996081

Epoch: 5| Step: 2
Training loss: 2.4337520599365234
Validation loss: 2.0170096158981323

Epoch: 5| Step: 3
Training loss: 2.1042704582214355
Validation loss: 2.0162024001280465

Epoch: 5| Step: 4
Training loss: 1.7092697620391846
Validation loss: 2.008745183547338

Epoch: 5| Step: 5
Training loss: 2.2142090797424316
Validation loss: 2.0124109039704003

Epoch: 5| Step: 6
Training loss: 2.204179286956787
Validation loss: 2.0195991843938828

Epoch: 5| Step: 7
Training loss: 2.1125431060791016
Validation loss: 2.0088863223791122

Epoch: 5| Step: 8
Training loss: 2.4294636249542236
Validation loss: 2.0164182633161545

Epoch: 5| Step: 9
Training loss: 2.317636489868164
Validation loss: 2.0236025055249534

Epoch: 5| Step: 10
Training loss: 1.7936054468154907
Validation loss: 2.014396886030833

Epoch: 5| Step: 11
Training loss: 1.8865275382995605
Validation loss: 2.0191716651121774

Epoch: 84| Step: 0
Training loss: 2.3642048835754395
Validation loss: 2.0070448368787766

Epoch: 5| Step: 1
Training loss: 2.125302314758301
Validation loss: 2.0175424118836722

Epoch: 5| Step: 2
Training loss: 1.9486558437347412
Validation loss: 2.0231407384077706

Epoch: 5| Step: 3
Training loss: 2.230614423751831
Validation loss: 2.0180280953645706

Epoch: 5| Step: 4
Training loss: 2.239591360092163
Validation loss: 2.012769192457199

Epoch: 5| Step: 5
Training loss: 2.030129909515381
Validation loss: 2.0199509263038635

Epoch: 5| Step: 6
Training loss: 1.8980159759521484
Validation loss: 2.0163792272408805

Epoch: 5| Step: 7
Training loss: 2.0072848796844482
Validation loss: 2.019313166538874

Epoch: 5| Step: 8
Training loss: 2.4669253826141357
Validation loss: 2.0274560252825418

Epoch: 5| Step: 9
Training loss: 2.025606155395508
Validation loss: 2.026933545867602

Epoch: 5| Step: 10
Training loss: 2.339216709136963
Validation loss: 2.0345534086227417

Epoch: 5| Step: 11
Training loss: 3.629793167114258
Validation loss: 2.026087130109469

Epoch: 85| Step: 0
Training loss: 2.062501907348633
Validation loss: 2.014966696500778

Epoch: 5| Step: 1
Training loss: 1.753130316734314
Validation loss: 2.0116350104411445

Epoch: 5| Step: 2
Training loss: 2.4879977703094482
Validation loss: 2.014013340075811

Epoch: 5| Step: 3
Training loss: 2.2996389865875244
Validation loss: 2.014477238059044

Epoch: 5| Step: 4
Training loss: 2.2631752490997314
Validation loss: 2.024284765124321

Epoch: 5| Step: 5
Training loss: 1.4615750312805176
Validation loss: 2.028894772132238

Epoch: 5| Step: 6
Training loss: 2.262373447418213
Validation loss: 2.022619148095449

Epoch: 5| Step: 7
Training loss: 2.2793264389038086
Validation loss: 2.02760456999143

Epoch: 5| Step: 8
Training loss: 2.761492967605591
Validation loss: 2.031439592440923

Epoch: 5| Step: 9
Training loss: 2.1622214317321777
Validation loss: 2.02570707599322

Epoch: 5| Step: 10
Training loss: 2.1221542358398438
Validation loss: 2.0306623727083206

Epoch: 5| Step: 11
Training loss: 3.1278998851776123
Validation loss: 2.022270311911901

Epoch: 86| Step: 0
Training loss: 1.718038558959961
Validation loss: 2.0184264481067657

Epoch: 5| Step: 1
Training loss: 2.2379183769226074
Validation loss: 2.0099235077699027

Epoch: 5| Step: 2
Training loss: 2.3425002098083496
Validation loss: 2.0018150160710015

Epoch: 5| Step: 3
Training loss: 2.5450596809387207
Validation loss: 2.0092619409163794

Epoch: 5| Step: 4
Training loss: 1.8592487573623657
Validation loss: 2.005509609977404

Epoch: 5| Step: 5
Training loss: 2.4164843559265137
Validation loss: 2.0048342496156693

Epoch: 5| Step: 6
Training loss: 2.0938804149627686
Validation loss: 2.0082994302113852

Epoch: 5| Step: 7
Training loss: 1.6235206127166748
Validation loss: 2.0135904053846994

Epoch: 5| Step: 8
Training loss: 2.388530731201172
Validation loss: 2.0185983777046204

Epoch: 5| Step: 9
Training loss: 2.269505739212036
Validation loss: 2.021771023670832

Epoch: 5| Step: 10
Training loss: 2.3600685596466064
Validation loss: 2.0234387467304864

Epoch: 5| Step: 11
Training loss: 2.7457308769226074
Validation loss: 2.0287342816591263

Epoch: 87| Step: 0
Training loss: 2.219120740890503
Validation loss: 2.031783238053322

Epoch: 5| Step: 1
Training loss: 2.381018877029419
Validation loss: 2.025388012329737

Epoch: 5| Step: 2
Training loss: 1.9486430883407593
Validation loss: 2.0197402437527976

Epoch: 5| Step: 3
Training loss: 1.9676780700683594
Validation loss: 2.017718811829885

Epoch: 5| Step: 4
Training loss: 2.8925650119781494
Validation loss: 2.0151768376429877

Epoch: 5| Step: 5
Training loss: 1.8794933557510376
Validation loss: 2.011561547716459

Epoch: 5| Step: 6
Training loss: 2.353349447250366
Validation loss: 2.007375786701838

Epoch: 5| Step: 7
Training loss: 2.195246696472168
Validation loss: 2.008895774682363

Epoch: 5| Step: 8
Training loss: 2.0617382526397705
Validation loss: 2.0085295041402182

Epoch: 5| Step: 9
Training loss: 1.949263572692871
Validation loss: 2.0008795956770578

Epoch: 5| Step: 10
Training loss: 2.111894130706787
Validation loss: 2.0037872393925986

Epoch: 5| Step: 11
Training loss: 2.4044981002807617
Validation loss: 2.0087721099456153

Epoch: 88| Step: 0
Training loss: 2.37308931350708
Validation loss: 2.008543536067009

Epoch: 5| Step: 1
Training loss: 2.5336790084838867
Validation loss: 2.01350474357605

Epoch: 5| Step: 2
Training loss: 1.4973986148834229
Validation loss: 2.010690768559774

Epoch: 5| Step: 3
Training loss: 2.281769037246704
Validation loss: 2.0111516962448754

Epoch: 5| Step: 4
Training loss: 2.1962764263153076
Validation loss: 2.0142736484607062

Epoch: 5| Step: 5
Training loss: 2.3990426063537598
Validation loss: 2.008363957206408

Epoch: 5| Step: 6
Training loss: 2.0790398120880127
Validation loss: 2.0047362446784973

Epoch: 5| Step: 7
Training loss: 1.8818165063858032
Validation loss: 2.0146833856900535

Epoch: 5| Step: 8
Training loss: 2.2189316749572754
Validation loss: 2.0110490322113037

Epoch: 5| Step: 9
Training loss: 2.326268434524536
Validation loss: 2.0141833374897637

Epoch: 5| Step: 10
Training loss: 2.033435106277466
Validation loss: 2.0117298662662506

Epoch: 5| Step: 11
Training loss: 2.6344809532165527
Validation loss: 2.0124943057696023

Epoch: 89| Step: 0
Training loss: 2.0173287391662598
Validation loss: 2.0087907910346985

Epoch: 5| Step: 1
Training loss: 2.1939291954040527
Validation loss: 2.0090931008259454

Epoch: 5| Step: 2
Training loss: 2.297011613845825
Validation loss: 2.007440596818924

Epoch: 5| Step: 3
Training loss: 1.9635009765625
Validation loss: 2.0116953253746033

Epoch: 5| Step: 4
Training loss: 2.246525526046753
Validation loss: 2.0180124988158545

Epoch: 5| Step: 5
Training loss: 2.488772392272949
Validation loss: 2.0245723774035773

Epoch: 5| Step: 6
Training loss: 2.673290729522705
Validation loss: 2.011294220884641

Epoch: 5| Step: 7
Training loss: 2.1386029720306396
Validation loss: 2.0168118278185525

Epoch: 5| Step: 8
Training loss: 2.235487222671509
Validation loss: 2.0255026717980704

Epoch: 5| Step: 9
Training loss: 1.5088683366775513
Validation loss: 2.0247634599606195

Epoch: 5| Step: 10
Training loss: 2.2255382537841797
Validation loss: 2.0134170800447464

Epoch: 5| Step: 11
Training loss: 1.1744431257247925
Validation loss: 2.0156791508197784

Epoch: 90| Step: 0
Training loss: 2.4103446006774902
Validation loss: 2.008555347720782

Epoch: 5| Step: 1
Training loss: 2.462397336959839
Validation loss: 2.003053923447927

Epoch: 5| Step: 2
Training loss: 1.854662299156189
Validation loss: 2.005959967772166

Epoch: 5| Step: 3
Training loss: 1.9196964502334595
Validation loss: 2.0076612681150436

Epoch: 5| Step: 4
Training loss: 2.0796334743499756
Validation loss: 2.003045623501142

Epoch: 5| Step: 5
Training loss: 2.117304801940918
Validation loss: 2.010943646232287

Epoch: 5| Step: 6
Training loss: 2.038562536239624
Validation loss: 2.0092667589584985

Epoch: 5| Step: 7
Training loss: 1.9792938232421875
Validation loss: 2.007618322968483

Epoch: 5| Step: 8
Training loss: 2.571261167526245
Validation loss: 2.0046502500772476

Epoch: 5| Step: 9
Training loss: 2.218473434448242
Validation loss: 2.0063632975021997

Epoch: 5| Step: 10
Training loss: 2.2339847087860107
Validation loss: 1.9988122632106144

Epoch: 5| Step: 11
Training loss: 2.538715362548828
Validation loss: 2.003744810819626

Epoch: 91| Step: 0
Training loss: 1.7916982173919678
Validation loss: 2.0015015502770743

Epoch: 5| Step: 1
Training loss: 1.980441689491272
Validation loss: 2.0149010568857193

Epoch: 5| Step: 2
Training loss: 1.7127834558486938
Validation loss: 2.0129949202140174

Epoch: 5| Step: 3
Training loss: 2.487396001815796
Validation loss: 2.023768295844396

Epoch: 5| Step: 4
Training loss: 2.1979269981384277
Validation loss: 2.0227763454119363

Epoch: 5| Step: 5
Training loss: 2.289379119873047
Validation loss: 2.027665545543035

Epoch: 5| Step: 6
Training loss: 2.140390157699585
Validation loss: 2.0271644790967307

Epoch: 5| Step: 7
Training loss: 2.2230899333953857
Validation loss: 2.0205575426419577

Epoch: 5| Step: 8
Training loss: 2.3686115741729736
Validation loss: 2.022358626127243

Epoch: 5| Step: 9
Training loss: 2.2556960582733154
Validation loss: 2.013044854005178

Epoch: 5| Step: 10
Training loss: 2.4622068405151367
Validation loss: 2.016179144382477

Epoch: 5| Step: 11
Training loss: 1.6097445487976074
Validation loss: 2.011863335967064

Epoch: 92| Step: 0
Training loss: 2.025688409805298
Validation loss: 2.014781485001246

Epoch: 5| Step: 1
Training loss: 2.471207618713379
Validation loss: 2.0116463899612427

Epoch: 5| Step: 2
Training loss: 1.8867725133895874
Validation loss: 2.0179064571857452

Epoch: 5| Step: 3
Training loss: 1.9561132192611694
Validation loss: 2.0257386018832526

Epoch: 5| Step: 4
Training loss: 1.8691667318344116
Validation loss: 2.017459198832512

Epoch: 5| Step: 5
Training loss: 2.3014426231384277
Validation loss: 2.0172722736994424

Epoch: 5| Step: 6
Training loss: 2.3756370544433594
Validation loss: 2.012522911032041

Epoch: 5| Step: 7
Training loss: 1.9102379083633423
Validation loss: 1.9975146353244781

Epoch: 5| Step: 8
Training loss: 2.1884543895721436
Validation loss: 2.0062560687462487

Epoch: 5| Step: 9
Training loss: 2.4652552604675293
Validation loss: 1.9957950015862782

Epoch: 5| Step: 10
Training loss: 2.4230265617370605
Validation loss: 1.9977873265743256

Epoch: 5| Step: 11
Training loss: 1.5897700786590576
Validation loss: 1.9949456204970677

Epoch: 93| Step: 0
Training loss: 2.147064685821533
Validation loss: 1.9945005824168522

Epoch: 5| Step: 1
Training loss: 2.5597496032714844
Validation loss: 2.0189254681269326

Epoch: 5| Step: 2
Training loss: 2.7912802696228027
Validation loss: 2.0326131532589593

Epoch: 5| Step: 3
Training loss: 2.4557929039001465
Validation loss: 2.0396289428075156

Epoch: 5| Step: 4
Training loss: 1.7150859832763672
Validation loss: 2.030850738286972

Epoch: 5| Step: 5
Training loss: 2.175203323364258
Validation loss: 2.0376065969467163

Epoch: 5| Step: 6
Training loss: 2.1390907764434814
Validation loss: 2.035850236813227

Epoch: 5| Step: 7
Training loss: 2.040234327316284
Validation loss: 2.031054357687632

Epoch: 5| Step: 8
Training loss: 1.89156174659729
Validation loss: 2.0183599342902503

Epoch: 5| Step: 9
Training loss: 1.70428466796875
Validation loss: 2.026914671063423

Epoch: 5| Step: 10
Training loss: 2.207512140274048
Validation loss: 2.0245628356933594

Epoch: 5| Step: 11
Training loss: 2.428060531616211
Validation loss: 2.0254161953926086

Epoch: 94| Step: 0
Training loss: 2.1882200241088867
Validation loss: 2.0236920366684594

Epoch: 5| Step: 1
Training loss: 2.552678346633911
Validation loss: 2.0261035412549973

Epoch: 5| Step: 2
Training loss: 2.1056625843048096
Validation loss: 2.019089922308922

Epoch: 5| Step: 3
Training loss: 2.3440542221069336
Validation loss: 2.0219063411156335

Epoch: 5| Step: 4
Training loss: 2.009556770324707
Validation loss: 2.018440375725428

Epoch: 5| Step: 5
Training loss: 1.596047282218933
Validation loss: 2.0190329601367316

Epoch: 5| Step: 6
Training loss: 2.4023303985595703
Validation loss: 2.0234535733858743

Epoch: 5| Step: 7
Training loss: 2.177903652191162
Validation loss: 2.0231813291708627

Epoch: 5| Step: 8
Training loss: 1.7076873779296875
Validation loss: 2.0280005733172097

Epoch: 5| Step: 9
Training loss: 1.6868280172348022
Validation loss: 2.0375020653009415

Epoch: 5| Step: 10
Training loss: 2.575402021408081
Validation loss: 2.028071636954943

Epoch: 5| Step: 11
Training loss: 3.476541042327881
Validation loss: 2.020648638407389

Epoch: 95| Step: 0
Training loss: 1.8436057567596436
Validation loss: 2.0132247706254325

Epoch: 5| Step: 1
Training loss: 2.2589192390441895
Validation loss: 2.012862890958786

Epoch: 5| Step: 2
Training loss: 1.9822094440460205
Validation loss: 2.006771211822828

Epoch: 5| Step: 3
Training loss: 1.8666877746582031
Validation loss: 2.0110344290733337

Epoch: 5| Step: 4
Training loss: 1.9166336059570312
Validation loss: 1.998880719145139

Epoch: 5| Step: 5
Training loss: 1.98760187625885
Validation loss: 2.0134038577477136

Epoch: 5| Step: 6
Training loss: 2.087040424346924
Validation loss: 2.005370150009791

Epoch: 5| Step: 7
Training loss: 2.401358127593994
Validation loss: 2.0109807550907135

Epoch: 5| Step: 8
Training loss: 2.6782174110412598
Validation loss: 2.005966936548551

Epoch: 5| Step: 9
Training loss: 2.6346631050109863
Validation loss: 2.0086199194192886

Epoch: 5| Step: 10
Training loss: 2.1282787322998047
Validation loss: 2.007208983103434

Epoch: 5| Step: 11
Training loss: 1.9942033290863037
Validation loss: 2.0071692218383155

Epoch: 96| Step: 0
Training loss: 1.9907827377319336
Validation loss: 2.0139135320981345

Epoch: 5| Step: 1
Training loss: 1.6066697835922241
Validation loss: 2.024017040928205

Epoch: 5| Step: 2
Training loss: 2.833545684814453
Validation loss: 2.0333124101161957

Epoch: 5| Step: 3
Training loss: 1.9771534204483032
Validation loss: 2.036804844935735

Epoch: 5| Step: 4
Training loss: 2.526207447052002
Validation loss: 2.051573390762011

Epoch: 5| Step: 5
Training loss: 2.3113982677459717
Validation loss: 2.050037696957588

Epoch: 5| Step: 6
Training loss: 2.1193289756774902
Validation loss: 2.051302433013916

Epoch: 5| Step: 7
Training loss: 2.0064525604248047
Validation loss: 2.0320685605208078

Epoch: 5| Step: 8
Training loss: 1.6604468822479248
Validation loss: 2.035880833864212

Epoch: 5| Step: 9
Training loss: 2.2120158672332764
Validation loss: 2.018060624599457

Epoch: 5| Step: 10
Training loss: 2.450772523880005
Validation loss: 2.0238653123378754

Epoch: 5| Step: 11
Training loss: 2.358503818511963
Validation loss: 2.008513644337654

Epoch: 97| Step: 0
Training loss: 2.1411685943603516
Validation loss: 2.0081741213798523

Epoch: 5| Step: 1
Training loss: 2.075946092605591
Validation loss: 2.0070311029752097

Epoch: 5| Step: 2
Training loss: 1.931897759437561
Validation loss: 2.0025132993857064

Epoch: 5| Step: 3
Training loss: 2.487743616104126
Validation loss: 2.013380760947863

Epoch: 5| Step: 4
Training loss: 1.712018609046936
Validation loss: 2.0086133778095245

Epoch: 5| Step: 5
Training loss: 2.0458195209503174
Validation loss: 2.0017625838518143

Epoch: 5| Step: 6
Training loss: 2.584731101989746
Validation loss: 2.0179944932460785

Epoch: 5| Step: 7
Training loss: 1.81049382686615
Validation loss: 2.0282380183537803

Epoch: 5| Step: 8
Training loss: 2.4172985553741455
Validation loss: 2.0254415522019067

Epoch: 5| Step: 9
Training loss: 1.9556865692138672
Validation loss: 2.026384229461352

Epoch: 5| Step: 10
Training loss: 2.846081018447876
Validation loss: 2.0236360828081765

Epoch: 5| Step: 11
Training loss: 0.38164520263671875
Validation loss: 2.0204498370488486

Epoch: 98| Step: 0
Training loss: 2.2239348888397217
Validation loss: 2.0346779376268387

Epoch: 5| Step: 1
Training loss: 2.1166958808898926
Validation loss: 2.016383185982704

Epoch: 5| Step: 2
Training loss: 2.0282864570617676
Validation loss: 2.020063112179438

Epoch: 5| Step: 3
Training loss: 2.048196315765381
Validation loss: 2.006558428208033

Epoch: 5| Step: 4
Training loss: 1.7634140253067017
Validation loss: 2.006133163968722

Epoch: 5| Step: 5
Training loss: 2.1750056743621826
Validation loss: 2.007083848118782

Epoch: 5| Step: 6
Training loss: 2.279816150665283
Validation loss: 1.9997338304917018

Epoch: 5| Step: 7
Training loss: 2.0759358406066895
Validation loss: 1.9985217303037643

Epoch: 5| Step: 8
Training loss: 2.822004795074463
Validation loss: 2.000637193520864

Epoch: 5| Step: 9
Training loss: 1.9571664333343506
Validation loss: 1.9992249260346096

Epoch: 5| Step: 10
Training loss: 2.1731936931610107
Validation loss: 2.001169820626577

Epoch: 5| Step: 11
Training loss: 1.5446181297302246
Validation loss: 1.9991114636262257

Epoch: 99| Step: 0
Training loss: 2.6600489616394043
Validation loss: 2.000793288151423

Epoch: 5| Step: 1
Training loss: 1.6803394556045532
Validation loss: 2.0116662085056305

Epoch: 5| Step: 2
Training loss: 2.135127305984497
Validation loss: 2.0093515465656915

Epoch: 5| Step: 3
Training loss: 2.013556957244873
Validation loss: 2.0083117534716926

Epoch: 5| Step: 4
Training loss: 1.7288227081298828
Validation loss: 2.0066681603590646

Epoch: 5| Step: 5
Training loss: 2.037914752960205
Validation loss: 2.007541134953499

Epoch: 5| Step: 6
Training loss: 2.4179930686950684
Validation loss: 2.0066104729970298

Epoch: 5| Step: 7
Training loss: 2.356015682220459
Validation loss: 2.004424497485161

Epoch: 5| Step: 8
Training loss: 1.7981363534927368
Validation loss: 2.0089080333709717

Epoch: 5| Step: 9
Training loss: 2.4097766876220703
Validation loss: 2.001679758230845

Epoch: 5| Step: 10
Training loss: 2.2227282524108887
Validation loss: 2.0134006440639496

Epoch: 5| Step: 11
Training loss: 2.5090885162353516
Validation loss: 2.022014851371447

Epoch: 100| Step: 0
Training loss: 2.0670876502990723
Validation loss: 2.0197232911984124

Epoch: 5| Step: 1
Training loss: 2.181384325027466
Validation loss: 2.02572367588679

Epoch: 5| Step: 2
Training loss: 2.3388404846191406
Validation loss: 2.0285958349704742

Epoch: 5| Step: 3
Training loss: 2.5129570960998535
Validation loss: 2.026880552371343

Epoch: 5| Step: 4
Training loss: 2.0146632194519043
Validation loss: 2.0301135877768197

Epoch: 5| Step: 5
Training loss: 2.194972038269043
Validation loss: 2.01850018898646

Epoch: 5| Step: 6
Training loss: 2.7322959899902344
Validation loss: 2.0157217482725778

Epoch: 5| Step: 7
Training loss: 2.11179256439209
Validation loss: 2.001432036360105

Epoch: 5| Step: 8
Training loss: 1.9396740198135376
Validation loss: 1.995255654056867

Epoch: 5| Step: 9
Training loss: 1.6428428888320923
Validation loss: 1.997038334608078

Epoch: 5| Step: 10
Training loss: 1.9523197412490845
Validation loss: 1.9855262885491054

Epoch: 5| Step: 11
Training loss: 1.5675181150436401
Validation loss: 1.9902890473604202

Epoch: 101| Step: 0
Training loss: 2.371476650238037
Validation loss: 1.9927217811346054

Epoch: 5| Step: 1
Training loss: 2.049083709716797
Validation loss: 1.9950791895389557

Epoch: 5| Step: 2
Training loss: 2.3473196029663086
Validation loss: 1.9931372503439586

Epoch: 5| Step: 3
Training loss: 2.2550930976867676
Validation loss: 2.0123493373394012

Epoch: 5| Step: 4
Training loss: 1.8205881118774414
Validation loss: 2.001932273308436

Epoch: 5| Step: 5
Training loss: 2.214528799057007
Validation loss: 2.0068553338448205

Epoch: 5| Step: 6
Training loss: 2.2378642559051514
Validation loss: 1.9995698283116023

Epoch: 5| Step: 7
Training loss: 2.1447856426239014
Validation loss: 2.0012229631344476

Epoch: 5| Step: 8
Training loss: 2.208878755569458
Validation loss: 1.9998569438854854

Epoch: 5| Step: 9
Training loss: 1.66752028465271
Validation loss: 1.993294487396876

Epoch: 5| Step: 10
Training loss: 2.3543853759765625
Validation loss: 1.9980985124905903

Epoch: 5| Step: 11
Training loss: 2.3710732460021973
Validation loss: 2.002216855684916

Epoch: 102| Step: 0
Training loss: 2.1218860149383545
Validation loss: 2.007907599210739

Epoch: 5| Step: 1
Training loss: 2.428948163986206
Validation loss: 2.006560663382212

Epoch: 5| Step: 2
Training loss: 2.1553399562835693
Validation loss: 2.007790893316269

Epoch: 5| Step: 3
Training loss: 1.8711154460906982
Validation loss: 2.0209274888038635

Epoch: 5| Step: 4
Training loss: 1.5287249088287354
Validation loss: 2.0312581161657968

Epoch: 5| Step: 5
Training loss: 2.819537878036499
Validation loss: 2.0253447691599527

Epoch: 5| Step: 6
Training loss: 1.8325841426849365
Validation loss: 2.042371263106664

Epoch: 5| Step: 7
Training loss: 1.9891456365585327
Validation loss: 2.040177881717682

Epoch: 5| Step: 8
Training loss: 2.245993137359619
Validation loss: 2.042907014489174

Epoch: 5| Step: 9
Training loss: 2.4800305366516113
Validation loss: 2.032537892460823

Epoch: 5| Step: 10
Training loss: 2.0243077278137207
Validation loss: 2.035973553856214

Epoch: 5| Step: 11
Training loss: 3.061066150665283
Validation loss: 2.0300313234329224

Epoch: 103| Step: 0
Training loss: 2.1939029693603516
Validation loss: 2.0181966572999954

Epoch: 5| Step: 1
Training loss: 2.493351697921753
Validation loss: 2.012281119823456

Epoch: 5| Step: 2
Training loss: 2.0967278480529785
Validation loss: 2.0225432316462197

Epoch: 5| Step: 3
Training loss: 2.1962122917175293
Validation loss: 2.011157304048538

Epoch: 5| Step: 4
Training loss: 2.1496033668518066
Validation loss: 2.01469516257445

Epoch: 5| Step: 5
Training loss: 1.7541898488998413
Validation loss: 2.0096483677625656

Epoch: 5| Step: 6
Training loss: 2.437290906906128
Validation loss: 2.006936172644297

Epoch: 5| Step: 7
Training loss: 2.424647092819214
Validation loss: 2.0146257181962333

Epoch: 5| Step: 8
Training loss: 1.765730857849121
Validation loss: 2.010804831981659

Epoch: 5| Step: 9
Training loss: 2.3311104774475098
Validation loss: 2.0088688135147095

Epoch: 5| Step: 10
Training loss: 1.8286052942276
Validation loss: 2.0083508640527725

Epoch: 5| Step: 11
Training loss: 1.7763811349868774
Validation loss: 2.0037124703327813

Epoch: 104| Step: 0
Training loss: 2.479700803756714
Validation loss: 2.007138952612877

Epoch: 5| Step: 1
Training loss: 2.732516050338745
Validation loss: 2.012154350678126

Epoch: 5| Step: 2
Training loss: 2.3654277324676514
Validation loss: 2.010248968998591

Epoch: 5| Step: 3
Training loss: 1.6804616451263428
Validation loss: 2.014113416274389

Epoch: 5| Step: 4
Training loss: 2.3590497970581055
Validation loss: 2.0157647331555686

Epoch: 5| Step: 5
Training loss: 2.1006343364715576
Validation loss: 2.0447321981191635

Epoch: 5| Step: 6
Training loss: 2.4011573791503906
Validation loss: 2.0401044487953186

Epoch: 5| Step: 7
Training loss: 1.474435806274414
Validation loss: 2.0491544951995215

Epoch: 5| Step: 8
Training loss: 1.7494852542877197
Validation loss: 2.0505347698926926

Epoch: 5| Step: 9
Training loss: 1.9450109004974365
Validation loss: 2.0473344971736274

Epoch: 5| Step: 10
Training loss: 2.286879539489746
Validation loss: 2.040281052390734

Epoch: 5| Step: 11
Training loss: 1.925897240638733
Validation loss: 2.0359165718158088

Epoch: 105| Step: 0
Training loss: 2.5685153007507324
Validation loss: 2.0328710873921714

Epoch: 5| Step: 1
Training loss: 2.028200149536133
Validation loss: 2.037933831413587

Epoch: 5| Step: 2
Training loss: 2.1909308433532715
Validation loss: 2.0321321934461594

Epoch: 5| Step: 3
Training loss: 2.5218119621276855
Validation loss: 2.037945032119751

Epoch: 5| Step: 4
Training loss: 2.102994918823242
Validation loss: 2.03823613623778

Epoch: 5| Step: 5
Training loss: 2.2644290924072266
Validation loss: 2.030406485001246

Epoch: 5| Step: 6
Training loss: 2.1972362995147705
Validation loss: 2.027111897865931

Epoch: 5| Step: 7
Training loss: 2.093365430831909
Validation loss: 2.039678772290548

Epoch: 5| Step: 8
Training loss: 2.126671314239502
Validation loss: 2.032176082332929

Epoch: 5| Step: 9
Training loss: 1.792462944984436
Validation loss: 2.025740370154381

Epoch: 5| Step: 10
Training loss: 1.7428935766220093
Validation loss: 2.021610473593076

Epoch: 5| Step: 11
Training loss: 1.16757071018219
Validation loss: 2.0135191778341928

Epoch: 106| Step: 0
Training loss: 2.243471622467041
Validation loss: 2.001195718844732

Epoch: 5| Step: 1
Training loss: 1.8859646320343018
Validation loss: 2.0088891933361688

Epoch: 5| Step: 2
Training loss: 2.2588813304901123
Validation loss: 1.9948806464672089

Epoch: 5| Step: 3
Training loss: 1.8730623722076416
Validation loss: 2.003456915418307

Epoch: 5| Step: 4
Training loss: 2.5192110538482666
Validation loss: 1.9933522740999858

Epoch: 5| Step: 5
Training loss: 2.3106367588043213
Validation loss: 1.9904223034779231

Epoch: 5| Step: 6
Training loss: 2.0331408977508545
Validation loss: 1.9889055341482162

Epoch: 5| Step: 7
Training loss: 2.3810172080993652
Validation loss: 1.988997220993042

Epoch: 5| Step: 8
Training loss: 2.0291106700897217
Validation loss: 1.9888715147972107

Epoch: 5| Step: 9
Training loss: 1.6567729711532593
Validation loss: 2.000178332130114

Epoch: 5| Step: 10
Training loss: 2.228081703186035
Validation loss: 1.9981341411670048

Epoch: 5| Step: 11
Training loss: 2.9368743896484375
Validation loss: 2.000781218210856

Epoch: 107| Step: 0
Training loss: 1.8834741115570068
Validation loss: 1.9966142177581787

Epoch: 5| Step: 1
Training loss: 1.7743587493896484
Validation loss: 1.9995775123437245

Epoch: 5| Step: 2
Training loss: 1.931628942489624
Validation loss: 2.0152117361625037

Epoch: 5| Step: 3
Training loss: 2.176579236984253
Validation loss: 2.0109765430291495

Epoch: 5| Step: 4
Training loss: 1.6450207233428955
Validation loss: 2.017855241894722

Epoch: 5| Step: 5
Training loss: 2.2746615409851074
Validation loss: 2.01705809434255

Epoch: 5| Step: 6
Training loss: 2.4650862216949463
Validation loss: 2.0167071471611657

Epoch: 5| Step: 7
Training loss: 2.4904189109802246
Validation loss: 2.0212334245443344

Epoch: 5| Step: 8
Training loss: 2.0542876720428467
Validation loss: 2.0264736215273538

Epoch: 5| Step: 9
Training loss: 2.2392473220825195
Validation loss: 2.0300091902414956

Epoch: 5| Step: 10
Training loss: 2.497002363204956
Validation loss: 2.0314745604991913

Epoch: 5| Step: 11
Training loss: 2.0713915824890137
Validation loss: 2.0219935923814774

Epoch: 108| Step: 0
Training loss: 2.2701282501220703
Validation loss: 2.019484410683314

Epoch: 5| Step: 1
Training loss: 2.3266220092773438
Validation loss: 2.0263729244470596

Epoch: 5| Step: 2
Training loss: 2.2832391262054443
Validation loss: 2.0331950088342032

Epoch: 5| Step: 3
Training loss: 1.5480365753173828
Validation loss: 2.0360887895027795

Epoch: 5| Step: 4
Training loss: 1.7656009197235107
Validation loss: 2.0240390499432883

Epoch: 5| Step: 5
Training loss: 2.2485358715057373
Validation loss: 2.028039405743281

Epoch: 5| Step: 6
Training loss: 2.439730405807495
Validation loss: 2.0492109755674996

Epoch: 5| Step: 7
Training loss: 1.8874080181121826
Validation loss: 2.0374575654665628

Epoch: 5| Step: 8
Training loss: 2.2142131328582764
Validation loss: 2.0323346306880317

Epoch: 5| Step: 9
Training loss: 2.198174238204956
Validation loss: 2.033925841252009

Epoch: 5| Step: 10
Training loss: 2.4011712074279785
Validation loss: 2.021466533342997

Epoch: 5| Step: 11
Training loss: 1.5932801961898804
Validation loss: 2.0159548173348107

Epoch: 109| Step: 0
Training loss: 2.1243271827697754
Validation loss: 2.022022391359011

Epoch: 5| Step: 1
Training loss: 1.624837875366211
Validation loss: 2.0195133686065674

Epoch: 5| Step: 2
Training loss: 1.970266580581665
Validation loss: 2.017595777908961

Epoch: 5| Step: 3
Training loss: 2.075582504272461
Validation loss: 2.0100317349036536

Epoch: 5| Step: 4
Training loss: 1.9860244989395142
Validation loss: 2.004618247350057

Epoch: 5| Step: 5
Training loss: 2.4688267707824707
Validation loss: 2.0127297093470893

Epoch: 5| Step: 6
Training loss: 2.142824649810791
Validation loss: 2.011839911341667

Epoch: 5| Step: 7
Training loss: 2.586556911468506
Validation loss: 2.0113205313682556

Epoch: 5| Step: 8
Training loss: 1.7452366352081299
Validation loss: 2.0141151398420334

Epoch: 5| Step: 9
Training loss: 2.345435619354248
Validation loss: 2.007751832405726

Epoch: 5| Step: 10
Training loss: 2.3984551429748535
Validation loss: 2.0297062397003174

Epoch: 5| Step: 11
Training loss: 2.2634243965148926
Validation loss: 2.020251214504242

Epoch: 110| Step: 0
Training loss: 2.709947347640991
Validation loss: 2.0198565870523453

Epoch: 5| Step: 1
Training loss: 2.0892038345336914
Validation loss: 2.030089204510053

Epoch: 5| Step: 2
Training loss: 2.2780792713165283
Validation loss: 2.028495674331983

Epoch: 5| Step: 3
Training loss: 1.5455968379974365
Validation loss: 2.0304556588331857

Epoch: 5| Step: 4
Training loss: 2.3222081661224365
Validation loss: 2.0371204366286597

Epoch: 5| Step: 5
Training loss: 2.1617441177368164
Validation loss: 2.040773088733355

Epoch: 5| Step: 6
Training loss: 2.4634013175964355
Validation loss: 2.0363581528266272

Epoch: 5| Step: 7
Training loss: 1.4109089374542236
Validation loss: 2.0301072796185813

Epoch: 5| Step: 8
Training loss: 1.8071250915527344
Validation loss: 2.0401330242554345

Epoch: 5| Step: 9
Training loss: 2.2233195304870605
Validation loss: 2.029981185992559

Epoch: 5| Step: 10
Training loss: 2.2120349407196045
Validation loss: 2.041543111205101

Epoch: 5| Step: 11
Training loss: 2.319514751434326
Validation loss: 2.037436912457148

Epoch: 111| Step: 0
Training loss: 2.1511199474334717
Validation loss: 2.0700596819321313

Epoch: 5| Step: 1
Training loss: 2.253931999206543
Validation loss: 2.0576137602329254

Epoch: 5| Step: 2
Training loss: 2.145275831222534
Validation loss: 2.071996361017227

Epoch: 5| Step: 3
Training loss: 2.1986656188964844
Validation loss: 2.07796078423659

Epoch: 5| Step: 4
Training loss: 1.8146775960922241
Validation loss: 2.073128511508306

Epoch: 5| Step: 5
Training loss: 2.2193703651428223
Validation loss: 2.0758953938881555

Epoch: 5| Step: 6
Training loss: 2.2978615760803223
Validation loss: 2.071700190504392

Epoch: 5| Step: 7
Training loss: 1.6736112833023071
Validation loss: 2.050567348798116

Epoch: 5| Step: 8
Training loss: 1.932633638381958
Validation loss: 2.0485291928052902

Epoch: 5| Step: 9
Training loss: 2.0680747032165527
Validation loss: 2.034317841132482

Epoch: 5| Step: 10
Training loss: 2.717505931854248
Validation loss: 2.0173317988713584

Epoch: 5| Step: 11
Training loss: 2.710190773010254
Validation loss: 2.0140607754389444

Epoch: 112| Step: 0
Training loss: 2.301889419555664
Validation loss: 2.0050167540709176

Epoch: 5| Step: 1
Training loss: 2.2034449577331543
Validation loss: 2.003827914595604

Epoch: 5| Step: 2
Training loss: 2.1763455867767334
Validation loss: 2.0102089742819467

Epoch: 5| Step: 3
Training loss: 2.9599967002868652
Validation loss: 2.018316681186358

Epoch: 5| Step: 4
Training loss: 2.027024030685425
Validation loss: 2.018527021010717

Epoch: 5| Step: 5
Training loss: 2.3579249382019043
Validation loss: 2.025251184900602

Epoch: 5| Step: 6
Training loss: 1.917218804359436
Validation loss: 2.028592268625895

Epoch: 5| Step: 7
Training loss: 1.7931703329086304
Validation loss: 2.021965349713961

Epoch: 5| Step: 8
Training loss: 1.757981300354004
Validation loss: 2.0192128717899323

Epoch: 5| Step: 9
Training loss: 2.101902723312378
Validation loss: 2.026364396015803

Epoch: 5| Step: 10
Training loss: 2.227454662322998
Validation loss: 2.0149656236171722

Epoch: 5| Step: 11
Training loss: 2.361931800842285
Validation loss: 2.0175522019465766

Epoch: 113| Step: 0
Training loss: 2.2333672046661377
Validation loss: 2.0069279869397483

Epoch: 5| Step: 1
Training loss: 2.2273998260498047
Validation loss: 2.008040964603424

Epoch: 5| Step: 2
Training loss: 1.9409955739974976
Validation loss: 2.0076852490504584

Epoch: 5| Step: 3
Training loss: 2.2284722328186035
Validation loss: 2.009371648232142

Epoch: 5| Step: 4
Training loss: 2.1259407997131348
Validation loss: 2.0055218984683356

Epoch: 5| Step: 5
Training loss: 2.9171714782714844
Validation loss: 1.9986949861049652

Epoch: 5| Step: 6
Training loss: 1.4548451900482178
Validation loss: 1.9957885642846425

Epoch: 5| Step: 7
Training loss: 2.271233081817627
Validation loss: 2.004074518879255

Epoch: 5| Step: 8
Training loss: 1.8037879467010498
Validation loss: 2.002422879139582

Epoch: 5| Step: 9
Training loss: 2.392472982406616
Validation loss: 2.011348232626915

Epoch: 5| Step: 10
Training loss: 1.7862415313720703
Validation loss: 2.0201827585697174

Epoch: 5| Step: 11
Training loss: 2.0412325859069824
Validation loss: 2.0287278244892755

Epoch: 114| Step: 0
Training loss: 2.228127956390381
Validation loss: 2.0392380009094873

Epoch: 5| Step: 1
Training loss: 2.224571704864502
Validation loss: 2.062673976023992

Epoch: 5| Step: 2
Training loss: 1.9662964344024658
Validation loss: 2.0735078354676566

Epoch: 5| Step: 3
Training loss: 2.174145221710205
Validation loss: 2.0755122750997543

Epoch: 5| Step: 4
Training loss: 1.9840008020401
Validation loss: 2.076462676127752

Epoch: 5| Step: 5
Training loss: 1.8248035907745361
Validation loss: 2.067577009399732

Epoch: 5| Step: 6
Training loss: 2.058821201324463
Validation loss: 2.0413517902294793

Epoch: 5| Step: 7
Training loss: 2.661273241043091
Validation loss: 2.024580553174019

Epoch: 5| Step: 8
Training loss: 2.793382167816162
Validation loss: 2.016966700553894

Epoch: 5| Step: 9
Training loss: 2.069904088973999
Validation loss: 2.0112112065156302

Epoch: 5| Step: 10
Training loss: 1.7485603094100952
Validation loss: 2.0018177032470703

Epoch: 5| Step: 11
Training loss: 0.6937923431396484
Validation loss: 2.0015024691820145

Epoch: 115| Step: 0
Training loss: 2.0189547538757324
Validation loss: 2.0183294663826623

Epoch: 5| Step: 1
Training loss: 1.7709640264511108
Validation loss: 2.015251194437345

Epoch: 5| Step: 2
Training loss: 2.2192177772521973
Validation loss: 2.013739228248596

Epoch: 5| Step: 3
Training loss: 2.1812329292297363
Validation loss: 2.019274945060412

Epoch: 5| Step: 4
Training loss: 2.036755084991455
Validation loss: 2.015893538792928

Epoch: 5| Step: 5
Training loss: 1.905763030052185
Validation loss: 2.016597514351209

Epoch: 5| Step: 6
Training loss: 2.464555025100708
Validation loss: 2.017266720533371

Epoch: 5| Step: 7
Training loss: 1.98873770236969
Validation loss: 2.011426111062368

Epoch: 5| Step: 8
Training loss: 2.3942654132843018
Validation loss: 2.007829080025355

Epoch: 5| Step: 9
Training loss: 2.583763599395752
Validation loss: 2.0061892171700797

Epoch: 5| Step: 10
Training loss: 2.254910945892334
Validation loss: 2.0074478536844254

Epoch: 5| Step: 11
Training loss: 1.4024280309677124
Validation loss: 2.003123144308726

Epoch: 116| Step: 0
Training loss: 2.18918776512146
Validation loss: 2.0067354092995324

Epoch: 5| Step: 1
Training loss: 2.0809895992279053
Validation loss: 2.0060443927844367

Epoch: 5| Step: 2
Training loss: 1.9207862615585327
Validation loss: 2.0102390746275582

Epoch: 5| Step: 3
Training loss: 2.276787281036377
Validation loss: 2.008742039402326

Epoch: 5| Step: 4
Training loss: 2.103576898574829
Validation loss: 2.0210572530825934

Epoch: 5| Step: 5
Training loss: 2.114830493927002
Validation loss: 2.029508406917254

Epoch: 5| Step: 6
Training loss: 2.1451187133789062
Validation loss: 2.0332490851481757

Epoch: 5| Step: 7
Training loss: 2.4082183837890625
Validation loss: 2.025667558113734

Epoch: 5| Step: 8
Training loss: 2.0284206867218018
Validation loss: 2.0345408022403717

Epoch: 5| Step: 9
Training loss: 2.3165435791015625
Validation loss: 2.0285192181666694

Epoch: 5| Step: 10
Training loss: 1.8050445318222046
Validation loss: 2.025179862976074

Epoch: 5| Step: 11
Training loss: 2.400420665740967
Validation loss: 2.0257891714572906

Epoch: 117| Step: 0
Training loss: 2.1757283210754395
Validation loss: 2.0268029073874154

Epoch: 5| Step: 1
Training loss: 2.192387342453003
Validation loss: 2.0190806090831757

Epoch: 5| Step: 2
Training loss: 2.473463773727417
Validation loss: 2.0114190032084784

Epoch: 5| Step: 3
Training loss: 2.107664108276367
Validation loss: 2.012161980072657

Epoch: 5| Step: 4
Training loss: 1.7800403833389282
Validation loss: 2.0103252281745276

Epoch: 5| Step: 5
Training loss: 2.5908892154693604
Validation loss: 1.9988178263107936

Epoch: 5| Step: 6
Training loss: 1.9061882495880127
Validation loss: 2.002073213458061

Epoch: 5| Step: 7
Training loss: 2.159912347793579
Validation loss: 2.0097184628248215

Epoch: 5| Step: 8
Training loss: 2.2050962448120117
Validation loss: 2.0044120401144028

Epoch: 5| Step: 9
Training loss: 1.6246559619903564
Validation loss: 2.0081360042095184

Epoch: 5| Step: 10
Training loss: 2.237212657928467
Validation loss: 2.0071438252925873

Epoch: 5| Step: 11
Training loss: 1.7559282779693604
Validation loss: 2.003549352288246

Epoch: 118| Step: 0
Training loss: 2.4812965393066406
Validation loss: 2.0048772344986596

Epoch: 5| Step: 1
Training loss: 2.3082714080810547
Validation loss: 2.0115208327770233

Epoch: 5| Step: 2
Training loss: 1.8069450855255127
Validation loss: 2.0092767228682837

Epoch: 5| Step: 3
Training loss: 1.9071686267852783
Validation loss: 2.0112166851758957

Epoch: 5| Step: 4
Training loss: 1.7410978078842163
Validation loss: 2.0079416086276374

Epoch: 5| Step: 5
Training loss: 2.549689769744873
Validation loss: 2.0066061168909073

Epoch: 5| Step: 6
Training loss: 2.499227285385132
Validation loss: 2.003965546687444

Epoch: 5| Step: 7
Training loss: 2.0471646785736084
Validation loss: 2.0137365460395813

Epoch: 5| Step: 8
Training loss: 2.103973627090454
Validation loss: 2.012180576721827

Epoch: 5| Step: 9
Training loss: 1.9420799016952515
Validation loss: 2.006689672668775

Epoch: 5| Step: 10
Training loss: 1.7139610052108765
Validation loss: 2.018715192874273

Epoch: 5| Step: 11
Training loss: 2.5352466106414795
Validation loss: 2.018038128813108

Epoch: 119| Step: 0
Training loss: 2.403693437576294
Validation loss: 2.009341672062874

Epoch: 5| Step: 1
Training loss: 2.21142315864563
Validation loss: 2.0100785245498023

Epoch: 5| Step: 2
Training loss: 1.780517816543579
Validation loss: 2.0190149495999017

Epoch: 5| Step: 3
Training loss: 1.9303767681121826
Validation loss: 2.0121132830778756

Epoch: 5| Step: 4
Training loss: 2.235705852508545
Validation loss: 2.0141717294851937

Epoch: 5| Step: 5
Training loss: 2.579867124557495
Validation loss: 2.0177693913380303

Epoch: 5| Step: 6
Training loss: 2.3652560710906982
Validation loss: 2.0193231801191964

Epoch: 5| Step: 7
Training loss: 1.899754285812378
Validation loss: 2.020521799723307

Epoch: 5| Step: 8
Training loss: 2.138152837753296
Validation loss: 2.0125193099180856

Epoch: 5| Step: 9
Training loss: 1.7983955144882202
Validation loss: 2.0080243398745856

Epoch: 5| Step: 10
Training loss: 1.891099214553833
Validation loss: 2.0076858748992286

Epoch: 5| Step: 11
Training loss: 1.6620875597000122
Validation loss: 2.0080613096555076

Epoch: 120| Step: 0
Training loss: 2.1937432289123535
Validation loss: 2.020299032330513

Epoch: 5| Step: 1
Training loss: 1.8600810766220093
Validation loss: 2.0208848416805267

Epoch: 5| Step: 2
Training loss: 2.825162887573242
Validation loss: 2.0302127053340278

Epoch: 5| Step: 3
Training loss: 2.0935189723968506
Validation loss: 2.023788094520569

Epoch: 5| Step: 4
Training loss: 2.2774860858917236
Validation loss: 2.023817946513494

Epoch: 5| Step: 5
Training loss: 1.489741563796997
Validation loss: 2.0298268844683967

Epoch: 5| Step: 6
Training loss: 2.2310726642608643
Validation loss: 2.0268857032060623

Epoch: 5| Step: 7
Training loss: 2.2588396072387695
Validation loss: 2.024569571018219

Epoch: 5| Step: 8
Training loss: 1.9057486057281494
Validation loss: 2.028417949875196

Epoch: 5| Step: 9
Training loss: 2.0855956077575684
Validation loss: 2.025308986504873

Epoch: 5| Step: 10
Training loss: 1.5589063167572021
Validation loss: 2.031216040253639

Epoch: 5| Step: 11
Training loss: 3.9916768074035645
Validation loss: 2.0321334898471832

Epoch: 121| Step: 0
Training loss: 2.4470298290252686
Validation loss: 2.029736985762914

Epoch: 5| Step: 1
Training loss: 1.8092868328094482
Validation loss: 2.024969056248665

Epoch: 5| Step: 2
Training loss: 2.318325996398926
Validation loss: 2.0261947313944497

Epoch: 5| Step: 3
Training loss: 1.9938675165176392
Validation loss: 2.0098995566368103

Epoch: 5| Step: 4
Training loss: 2.604252338409424
Validation loss: 2.0151277085145316

Epoch: 5| Step: 5
Training loss: 2.2865660190582275
Validation loss: 2.001352330048879

Epoch: 5| Step: 6
Training loss: 1.6448328495025635
Validation loss: 2.0015317499637604

Epoch: 5| Step: 7
Training loss: 2.0625414848327637
Validation loss: 1.9947754740715027

Epoch: 5| Step: 8
Training loss: 1.863569974899292
Validation loss: 2.000248442093531

Epoch: 5| Step: 9
Training loss: 1.8779548406600952
Validation loss: 2.0023952027161918

Epoch: 5| Step: 10
Training loss: 2.125911235809326
Validation loss: 2.000426789124807

Epoch: 5| Step: 11
Training loss: 3.1337273120880127
Validation loss: 1.9955036987860997

Epoch: 122| Step: 0
Training loss: 2.421048641204834
Validation loss: 2.0045090864102044

Epoch: 5| Step: 1
Training loss: 2.107140064239502
Validation loss: 2.0050116380055747

Epoch: 5| Step: 2
Training loss: 1.7195377349853516
Validation loss: 2.0114098141590753

Epoch: 5| Step: 3
Training loss: 1.888096570968628
Validation loss: 2.0206632564465203

Epoch: 5| Step: 4
Training loss: 2.2774817943573
Validation loss: 2.0322715491056442

Epoch: 5| Step: 5
Training loss: 1.713115930557251
Validation loss: 2.023486574490865

Epoch: 5| Step: 6
Training loss: 1.9017181396484375
Validation loss: 2.017120197415352

Epoch: 5| Step: 7
Training loss: 2.303896903991699
Validation loss: 2.0274360875288644

Epoch: 5| Step: 8
Training loss: 2.5040431022644043
Validation loss: 2.02853595217069

Epoch: 5| Step: 9
Training loss: 2.063152313232422
Validation loss: 2.0201936811208725

Epoch: 5| Step: 10
Training loss: 2.2344753742218018
Validation loss: 2.0319556842247644

Epoch: 5| Step: 11
Training loss: 1.8827508687973022
Validation loss: 2.0402809182802835

Epoch: 123| Step: 0
Training loss: 2.106837749481201
Validation loss: 2.045097534855207

Epoch: 5| Step: 1
Training loss: 1.8100913763046265
Validation loss: 2.0443623860677085

Epoch: 5| Step: 2
Training loss: 2.3360729217529297
Validation loss: 2.0376450270414352

Epoch: 5| Step: 3
Training loss: 1.7970272302627563
Validation loss: 2.0488292276859283

Epoch: 5| Step: 4
Training loss: 2.1719470024108887
Validation loss: 2.038976882894834

Epoch: 5| Step: 5
Training loss: 2.539930820465088
Validation loss: 2.0412035832802453

Epoch: 5| Step: 6
Training loss: 2.506439208984375
Validation loss: 2.0375372767448425

Epoch: 5| Step: 7
Training loss: 1.9059957265853882
Validation loss: 2.0266550381978354

Epoch: 5| Step: 8
Training loss: 1.4741801023483276
Validation loss: 2.0191619445880256

Epoch: 5| Step: 9
Training loss: 1.8886926174163818
Validation loss: 2.0128950575987496

Epoch: 5| Step: 10
Training loss: 2.5379557609558105
Validation loss: 2.0168434580167136

Epoch: 5| Step: 11
Training loss: 2.0815930366516113
Validation loss: 2.005634700258573

Epoch: 124| Step: 0
Training loss: 2.484260082244873
Validation loss: 2.015001580119133

Epoch: 5| Step: 1
Training loss: 2.0283775329589844
Validation loss: 2.0237225592136383

Epoch: 5| Step: 2
Training loss: 2.0653915405273438
Validation loss: 2.0217700451612473

Epoch: 5| Step: 3
Training loss: 2.18147611618042
Validation loss: 2.039686774214109

Epoch: 5| Step: 4
Training loss: 1.8780300617218018
Validation loss: 2.034455180168152

Epoch: 5| Step: 5
Training loss: 2.0272815227508545
Validation loss: 2.0336630046367645

Epoch: 5| Step: 6
Training loss: 1.5378906726837158
Validation loss: 2.0418141881624856

Epoch: 5| Step: 7
Training loss: 1.9442112445831299
Validation loss: 2.0340209702650704

Epoch: 5| Step: 8
Training loss: 2.6830639839172363
Validation loss: 2.056434949239095

Epoch: 5| Step: 9
Training loss: 2.178213357925415
Validation loss: 2.0675513496001563

Epoch: 5| Step: 10
Training loss: 1.970079779624939
Validation loss: 2.0614487131436667

Epoch: 5| Step: 11
Training loss: 2.4641480445861816
Validation loss: 2.060452784101168

Epoch: 125| Step: 0
Training loss: 1.9791799783706665
Validation loss: 2.0512773791948953

Epoch: 5| Step: 1
Training loss: 2.3100295066833496
Validation loss: 2.0482815305391946

Epoch: 5| Step: 2
Training loss: 2.37968111038208
Validation loss: 2.050061970949173

Epoch: 5| Step: 3
Training loss: 2.314946413040161
Validation loss: 2.045300076405207

Epoch: 5| Step: 4
Training loss: 2.4980013370513916
Validation loss: 2.053592711687088

Epoch: 5| Step: 5
Training loss: 1.6488271951675415
Validation loss: 2.048947046200434

Epoch: 5| Step: 6
Training loss: 2.1858482360839844
Validation loss: 2.053682585557302

Epoch: 5| Step: 7
Training loss: 2.0677194595336914
Validation loss: 2.0353769014279046

Epoch: 5| Step: 8
Training loss: 1.8591607809066772
Validation loss: 2.0365086048841476

Epoch: 5| Step: 9
Training loss: 2.097787857055664
Validation loss: 2.0378386278947196

Epoch: 5| Step: 10
Training loss: 1.6744190454483032
Validation loss: 2.0348552217086158

Epoch: 5| Step: 11
Training loss: 2.3486135005950928
Validation loss: 2.03439166645209

Epoch: 126| Step: 0
Training loss: 2.118211030960083
Validation loss: 2.0253875454266868

Epoch: 5| Step: 1
Training loss: 2.504257917404175
Validation loss: 2.0169955790042877

Epoch: 5| Step: 2
Training loss: 1.5746082067489624
Validation loss: 2.0150746951500573

Epoch: 5| Step: 3
Training loss: 2.01436185836792
Validation loss: 2.012747213244438

Epoch: 5| Step: 4
Training loss: 2.2423341274261475
Validation loss: 2.007983381549517

Epoch: 5| Step: 5
Training loss: 2.2717113494873047
Validation loss: 2.008002743124962

Epoch: 5| Step: 6
Training loss: 2.4824302196502686
Validation loss: 2.0081527680158615

Epoch: 5| Step: 7
Training loss: 2.146484375
Validation loss: 2.0125846515099206

Epoch: 5| Step: 8
Training loss: 2.2490968704223633
Validation loss: 2.0152745445569358

Epoch: 5| Step: 9
Training loss: 2.016510009765625
Validation loss: 2.0187664131323495

Epoch: 5| Step: 10
Training loss: 1.7088816165924072
Validation loss: 2.0261879016955695

Epoch: 5| Step: 11
Training loss: 1.3478795289993286
Validation loss: 2.0246300250291824

Epoch: 127| Step: 0
Training loss: 1.9436880350112915
Validation loss: 2.0367217709620795

Epoch: 5| Step: 1
Training loss: 1.580570101737976
Validation loss: 2.019364058971405

Epoch: 5| Step: 2
Training loss: 1.9097039699554443
Validation loss: 2.0312439650297165

Epoch: 5| Step: 3
Training loss: 2.256349802017212
Validation loss: 2.031599218646685

Epoch: 5| Step: 4
Training loss: 2.4310436248779297
Validation loss: 2.026215141018232

Epoch: 5| Step: 5
Training loss: 2.378450870513916
Validation loss: 2.0204902589321136

Epoch: 5| Step: 6
Training loss: 2.111973285675049
Validation loss: 2.015610675017039

Epoch: 5| Step: 7
Training loss: 2.2860119342803955
Validation loss: 2.018131429950396

Epoch: 5| Step: 8
Training loss: 1.9631977081298828
Validation loss: 2.0146456311146417

Epoch: 5| Step: 9
Training loss: 2.0789051055908203
Validation loss: 2.0188452899456024

Epoch: 5| Step: 10
Training loss: 2.0151164531707764
Validation loss: 2.036002511779467

Epoch: 5| Step: 11
Training loss: 3.247434139251709
Validation loss: 2.0349842309951782

Epoch: 128| Step: 0
Training loss: 1.6181690692901611
Validation loss: 2.028448596596718

Epoch: 5| Step: 1
Training loss: 1.9260749816894531
Validation loss: 2.0327241321404776

Epoch: 5| Step: 2
Training loss: 2.197577953338623
Validation loss: 2.045560345053673

Epoch: 5| Step: 3
Training loss: 2.319894313812256
Validation loss: 2.0434181292851767

Epoch: 5| Step: 4
Training loss: 2.6164889335632324
Validation loss: 2.037208462754885

Epoch: 5| Step: 5
Training loss: 1.8066604137420654
Validation loss: 2.0357055217027664

Epoch: 5| Step: 6
Training loss: 2.191410779953003
Validation loss: 2.022101104259491

Epoch: 5| Step: 7
Training loss: 1.8128769397735596
Validation loss: 2.032583718498548

Epoch: 5| Step: 8
Training loss: 1.9979511499404907
Validation loss: 2.027213523785273

Epoch: 5| Step: 9
Training loss: 2.205933094024658
Validation loss: 2.019911527633667

Epoch: 5| Step: 10
Training loss: 2.333749532699585
Validation loss: 2.0262205501397452

Epoch: 5| Step: 11
Training loss: 3.317455291748047
Validation loss: 2.0216506818930307

Epoch: 129| Step: 0
Training loss: 2.1520614624023438
Validation loss: 2.0225056459506354

Epoch: 5| Step: 1
Training loss: 2.266974925994873
Validation loss: 2.024340033531189

Epoch: 5| Step: 2
Training loss: 2.368313789367676
Validation loss: 2.0227093746264777

Epoch: 5| Step: 3
Training loss: 1.8893425464630127
Validation loss: 2.024571647246679

Epoch: 5| Step: 4
Training loss: 2.174783229827881
Validation loss: 2.013580411672592

Epoch: 5| Step: 5
Training loss: 2.100792646408081
Validation loss: 2.018438150485357

Epoch: 5| Step: 6
Training loss: 2.1319572925567627
Validation loss: 2.019921119014422

Epoch: 5| Step: 7
Training loss: 2.085242748260498
Validation loss: 2.0233116894960403

Epoch: 5| Step: 8
Training loss: 1.905073881149292
Validation loss: 2.0329438944657645

Epoch: 5| Step: 9
Training loss: 1.3900858163833618
Validation loss: 2.0357812494039536

Epoch: 5| Step: 10
Training loss: 2.426957845687866
Validation loss: 2.0306953539450965

Epoch: 5| Step: 11
Training loss: 3.060575485229492
Validation loss: 2.033644358317057

Epoch: 130| Step: 0
Training loss: 2.101865291595459
Validation loss: 2.035121818383535

Epoch: 5| Step: 1
Training loss: 2.3270630836486816
Validation loss: 2.0156191190083823

Epoch: 5| Step: 2
Training loss: 1.934157133102417
Validation loss: 2.020743956168493

Epoch: 5| Step: 3
Training loss: 1.980739951133728
Validation loss: 2.022712543606758

Epoch: 5| Step: 4
Training loss: 2.128584623336792
Validation loss: 2.018129830559095

Epoch: 5| Step: 5
Training loss: 2.405294418334961
Validation loss: 2.0063127328952155

Epoch: 5| Step: 6
Training loss: 2.131326675415039
Validation loss: 2.0090662936369577

Epoch: 5| Step: 7
Training loss: 2.033292293548584
Validation loss: 2.0154537359873452

Epoch: 5| Step: 8
Training loss: 1.6802955865859985
Validation loss: 2.009630719820658

Epoch: 5| Step: 9
Training loss: 2.2492921352386475
Validation loss: 2.0082802871863046

Epoch: 5| Step: 10
Training loss: 2.3581690788269043
Validation loss: 2.010987957318624

Epoch: 5| Step: 11
Training loss: 1.3294289112091064
Validation loss: 2.0101147890090942

Epoch: 131| Step: 0
Training loss: 2.49701189994812
Validation loss: 2.023589551448822

Epoch: 5| Step: 1
Training loss: 1.7669330835342407
Validation loss: 2.0307231148084006

Epoch: 5| Step: 2
Training loss: 2.144038677215576
Validation loss: 2.0257897029320397

Epoch: 5| Step: 3
Training loss: 1.4514648914337158
Validation loss: 2.0294026136398315

Epoch: 5| Step: 4
Training loss: 1.7588512897491455
Validation loss: 2.0303101539611816

Epoch: 5| Step: 5
Training loss: 1.7895835638046265
Validation loss: 2.0248494148254395

Epoch: 5| Step: 6
Training loss: 2.487877607345581
Validation loss: 2.025120730201403

Epoch: 5| Step: 7
Training loss: 1.8436317443847656
Validation loss: 2.030238618453344

Epoch: 5| Step: 8
Training loss: 2.6384263038635254
Validation loss: 2.0335028866926828

Epoch: 5| Step: 9
Training loss: 2.4339983463287354
Validation loss: 2.0152117709318795

Epoch: 5| Step: 10
Training loss: 2.154971122741699
Validation loss: 2.029013971487681

Epoch: 5| Step: 11
Training loss: 2.660458564758301
Validation loss: 2.01492939889431

Epoch: 132| Step: 0
Training loss: 2.6002705097198486
Validation loss: 2.0194078336159387

Epoch: 5| Step: 1
Training loss: 2.219979763031006
Validation loss: 2.0294149915377298

Epoch: 5| Step: 2
Training loss: 1.90157949924469
Validation loss: 2.0351885159810386

Epoch: 5| Step: 3
Training loss: 2.694267749786377
Validation loss: 2.035661041736603

Epoch: 5| Step: 4
Training loss: 1.5821508169174194
Validation loss: 2.0346876680850983

Epoch: 5| Step: 5
Training loss: 2.0438525676727295
Validation loss: 2.02038981517156

Epoch: 5| Step: 6
Training loss: 1.6527496576309204
Validation loss: 2.0401722341775894

Epoch: 5| Step: 7
Training loss: 1.8286021947860718
Validation loss: 2.0407948096593223

Epoch: 5| Step: 8
Training loss: 2.508711338043213
Validation loss: 2.0356512318054834

Epoch: 5| Step: 9
Training loss: 2.06168532371521
Validation loss: 2.0436289509137473

Epoch: 5| Step: 10
Training loss: 1.8034006357192993
Validation loss: 2.0436760584513345

Epoch: 5| Step: 11
Training loss: 1.961462378501892
Validation loss: 2.0475961913665137

Epoch: 133| Step: 0
Training loss: 2.4490764141082764
Validation loss: 2.0477344940106073

Epoch: 5| Step: 1
Training loss: 1.6355218887329102
Validation loss: 2.044074763854345

Epoch: 5| Step: 2
Training loss: 2.7164723873138428
Validation loss: 2.0488031804561615

Epoch: 5| Step: 3
Training loss: 1.7579084634780884
Validation loss: 2.0603028684854507

Epoch: 5| Step: 4
Training loss: 2.0197091102600098
Validation loss: 2.0455721467733383

Epoch: 5| Step: 5
Training loss: 2.24604868888855
Validation loss: 2.047488654653231

Epoch: 5| Step: 6
Training loss: 1.9995498657226562
Validation loss: 2.048228328426679

Epoch: 5| Step: 7
Training loss: 1.8913843631744385
Validation loss: 2.0521192053953805

Epoch: 5| Step: 8
Training loss: 2.183854579925537
Validation loss: 2.0492215305566788

Epoch: 5| Step: 9
Training loss: 1.5988272428512573
Validation loss: 2.049757495522499

Epoch: 5| Step: 10
Training loss: 2.440955638885498
Validation loss: 2.0377499808867774

Epoch: 5| Step: 11
Training loss: 1.6747090816497803
Validation loss: 2.032226949930191

Epoch: 134| Step: 0
Training loss: 2.1944289207458496
Validation loss: 2.040745571255684

Epoch: 5| Step: 1
Training loss: 2.248563289642334
Validation loss: 2.02573495109876

Epoch: 5| Step: 2
Training loss: 1.7696399688720703
Validation loss: 2.014028330643972

Epoch: 5| Step: 3
Training loss: 1.6893510818481445
Validation loss: 2.026000161965688

Epoch: 5| Step: 4
Training loss: 2.467287063598633
Validation loss: 2.0286268442869186

Epoch: 5| Step: 5
Training loss: 1.8275903463363647
Validation loss: 2.0268440693616867

Epoch: 5| Step: 6
Training loss: 1.593963384628296
Validation loss: 2.03227698802948

Epoch: 5| Step: 7
Training loss: 2.584486722946167
Validation loss: 2.0293433517217636

Epoch: 5| Step: 8
Training loss: 2.1342930793762207
Validation loss: 2.0328476577997208

Epoch: 5| Step: 9
Training loss: 2.4146175384521484
Validation loss: 2.026933973034223

Epoch: 5| Step: 10
Training loss: 2.2002458572387695
Validation loss: 2.021790380279223

Epoch: 5| Step: 11
Training loss: 3.194746255874634
Validation loss: 2.023964991172155

Epoch: 135| Step: 0
Training loss: 2.0361852645874023
Validation loss: 2.0302287141482034

Epoch: 5| Step: 1
Training loss: 2.4608378410339355
Validation loss: 2.035014425714811

Epoch: 5| Step: 2
Training loss: 1.8203094005584717
Validation loss: 2.044131209452947

Epoch: 5| Step: 3
Training loss: 1.5348796844482422
Validation loss: 2.0349730948607125

Epoch: 5| Step: 4
Training loss: 2.334117889404297
Validation loss: 2.048369805018107

Epoch: 5| Step: 5
Training loss: 2.3181066513061523
Validation loss: 2.0439471254746118

Epoch: 5| Step: 6
Training loss: 2.081033229827881
Validation loss: 2.0409438560406366

Epoch: 5| Step: 7
Training loss: 2.070547103881836
Validation loss: 2.0474680115779242

Epoch: 5| Step: 8
Training loss: 2.1864848136901855
Validation loss: 2.033486157655716

Epoch: 5| Step: 9
Training loss: 2.4444546699523926
Validation loss: 2.036175638437271

Epoch: 5| Step: 10
Training loss: 2.016235828399658
Validation loss: 2.0241891940434775

Epoch: 5| Step: 11
Training loss: 2.26497745513916
Validation loss: 2.0269786765178046

Epoch: 136| Step: 0
Training loss: 2.0558669567108154
Validation loss: 2.028725097576777

Epoch: 5| Step: 1
Training loss: 2.4852871894836426
Validation loss: 2.0329740941524506

Epoch: 5| Step: 2
Training loss: 2.142378091812134
Validation loss: 2.036689599355062

Epoch: 5| Step: 3
Training loss: 1.6869821548461914
Validation loss: 2.0357114374637604

Epoch: 5| Step: 4
Training loss: 2.3459630012512207
Validation loss: 2.041105036934217

Epoch: 5| Step: 5
Training loss: 2.220853328704834
Validation loss: 2.038187086582184

Epoch: 5| Step: 6
Training loss: 2.2977004051208496
Validation loss: 2.0594822466373444

Epoch: 5| Step: 7
Training loss: 2.112830400466919
Validation loss: 2.054025029142698

Epoch: 5| Step: 8
Training loss: 1.751548409461975
Validation loss: 2.054983268181483

Epoch: 5| Step: 9
Training loss: 1.8346033096313477
Validation loss: 2.061888188123703

Epoch: 5| Step: 10
Training loss: 1.8350216150283813
Validation loss: 2.073019524415334

Epoch: 5| Step: 11
Training loss: 2.136230945587158
Validation loss: 2.0612821777661643

Epoch: 137| Step: 0
Training loss: 1.8118095397949219
Validation loss: 2.06737353404363

Epoch: 5| Step: 1
Training loss: 1.833540678024292
Validation loss: 2.0512128273646035

Epoch: 5| Step: 2
Training loss: 2.4984323978424072
Validation loss: 2.0514516631762185

Epoch: 5| Step: 3
Training loss: 1.8358911275863647
Validation loss: 2.0428152134021125

Epoch: 5| Step: 4
Training loss: 2.2248570919036865
Validation loss: 2.048734704653422

Epoch: 5| Step: 5
Training loss: 2.0415732860565186
Validation loss: 2.0407082537810006

Epoch: 5| Step: 6
Training loss: 2.0657665729522705
Validation loss: 2.033361554145813

Epoch: 5| Step: 7
Training loss: 2.0546326637268066
Validation loss: 2.0279891043901443

Epoch: 5| Step: 8
Training loss: 2.1165771484375
Validation loss: 2.0277938495079675

Epoch: 5| Step: 9
Training loss: 2.713118076324463
Validation loss: 2.0224336236715317

Epoch: 5| Step: 10
Training loss: 1.3975739479064941
Validation loss: 2.022683029373487

Epoch: 5| Step: 11
Training loss: 2.5525994300842285
Validation loss: 2.0173456321159997

Epoch: 138| Step: 0
Training loss: 2.1685471534729004
Validation loss: 2.0343843201796212

Epoch: 5| Step: 1
Training loss: 1.4573709964752197
Validation loss: 2.0245614598194757

Epoch: 5| Step: 2
Training loss: 2.121412515640259
Validation loss: 2.028939147790273

Epoch: 5| Step: 3
Training loss: 2.280277729034424
Validation loss: 2.0184151083230972

Epoch: 5| Step: 4
Training loss: 2.1149396896362305
Validation loss: 2.0357317427794137

Epoch: 5| Step: 5
Training loss: 2.101421356201172
Validation loss: 2.0387567232052484

Epoch: 5| Step: 6
Training loss: 1.8189359903335571
Validation loss: 2.042892018953959

Epoch: 5| Step: 7
Training loss: 2.349454879760742
Validation loss: 2.0335742831230164

Epoch: 5| Step: 8
Training loss: 1.7239166498184204
Validation loss: 2.048107758164406

Epoch: 5| Step: 9
Training loss: 1.9998267889022827
Validation loss: 2.0345050444205603

Epoch: 5| Step: 10
Training loss: 2.6127102375030518
Validation loss: 2.032043685515722

Epoch: 5| Step: 11
Training loss: 1.7721917629241943
Validation loss: 2.0342862407366433

Epoch: 139| Step: 0
Training loss: 1.9940885305404663
Validation loss: 2.026966934402784

Epoch: 5| Step: 1
Training loss: 1.4574239253997803
Validation loss: 2.0399968524773917

Epoch: 5| Step: 2
Training loss: 2.180182695388794
Validation loss: 2.044579883416494

Epoch: 5| Step: 3
Training loss: 1.6083301305770874
Validation loss: 2.04440945883592

Epoch: 5| Step: 4
Training loss: 2.245122194290161
Validation loss: 2.0387277553478875

Epoch: 5| Step: 5
Training loss: 2.2126612663269043
Validation loss: 2.0466823677221933

Epoch: 5| Step: 6
Training loss: 2.198798656463623
Validation loss: 2.0472708642482758

Epoch: 5| Step: 7
Training loss: 2.6660075187683105
Validation loss: 2.0538253784179688

Epoch: 5| Step: 8
Training loss: 2.4348721504211426
Validation loss: 2.049141431848208

Epoch: 5| Step: 9
Training loss: 2.2209231853485107
Validation loss: 2.0426599582036338

Epoch: 5| Step: 10
Training loss: 1.7707513570785522
Validation loss: 2.046648586789767

Epoch: 5| Step: 11
Training loss: 1.2823644876480103
Validation loss: 2.041199271877607

Epoch: 140| Step: 0
Training loss: 2.5527520179748535
Validation loss: 2.031217113137245

Epoch: 5| Step: 1
Training loss: 1.380721092224121
Validation loss: 2.033829758564631

Epoch: 5| Step: 2
Training loss: 2.241957902908325
Validation loss: 2.0315375874439874

Epoch: 5| Step: 3
Training loss: 2.2710070610046387
Validation loss: 2.0372098882993064

Epoch: 5| Step: 4
Training loss: 2.3311822414398193
Validation loss: 2.0382982939481735

Epoch: 5| Step: 5
Training loss: 1.7695941925048828
Validation loss: 2.043775940934817

Epoch: 5| Step: 6
Training loss: 2.013524293899536
Validation loss: 2.048251340786616

Epoch: 5| Step: 7
Training loss: 1.960892915725708
Validation loss: 2.0501378873984017

Epoch: 5| Step: 8
Training loss: 2.1091842651367188
Validation loss: 2.059358388185501

Epoch: 5| Step: 9
Training loss: 1.6562373638153076
Validation loss: 2.0508350680271783

Epoch: 5| Step: 10
Training loss: 2.310927152633667
Validation loss: 2.052540977795919

Epoch: 5| Step: 11
Training loss: 2.4226653575897217
Validation loss: 2.054507538676262

Epoch: 141| Step: 0
Training loss: 2.4654080867767334
Validation loss: 2.0385587265094123

Epoch: 5| Step: 1
Training loss: 1.4173524379730225
Validation loss: 2.0466692000627518

Epoch: 5| Step: 2
Training loss: 2.3208136558532715
Validation loss: 2.0413073847691217

Epoch: 5| Step: 3
Training loss: 2.339061737060547
Validation loss: 2.0366531113783517

Epoch: 5| Step: 4
Training loss: 1.9411541223526
Validation loss: 2.041358545422554

Epoch: 5| Step: 5
Training loss: 2.051038980484009
Validation loss: 2.0391230235497155

Epoch: 5| Step: 6
Training loss: 1.7921020984649658
Validation loss: 2.02569588025411

Epoch: 5| Step: 7
Training loss: 2.210615396499634
Validation loss: 2.0385940174261727

Epoch: 5| Step: 8
Training loss: 1.976832628250122
Validation loss: 2.0363190919160843

Epoch: 5| Step: 9
Training loss: 2.0612213611602783
Validation loss: 2.028827632466952

Epoch: 5| Step: 10
Training loss: 2.329820394515991
Validation loss: 2.0431004961331687

Epoch: 5| Step: 11
Training loss: 1.3015620708465576
Validation loss: 2.0489680022001266

Epoch: 142| Step: 0
Training loss: 1.6868209838867188
Validation loss: 2.0419297317663827

Epoch: 5| Step: 1
Training loss: 2.276139736175537
Validation loss: 2.042326028148333

Epoch: 5| Step: 2
Training loss: 2.3345158100128174
Validation loss: 2.0297011782725654

Epoch: 5| Step: 3
Training loss: 2.3789844512939453
Validation loss: 2.0420468548933663

Epoch: 5| Step: 4
Training loss: 1.7720664739608765
Validation loss: 2.0429281691710153

Epoch: 5| Step: 5
Training loss: 2.3325722217559814
Validation loss: 2.046848143140475

Epoch: 5| Step: 6
Training loss: 2.5145843029022217
Validation loss: 2.038496737678846

Epoch: 5| Step: 7
Training loss: 1.4861371517181396
Validation loss: 2.0345774640639624

Epoch: 5| Step: 8
Training loss: 2.029877185821533
Validation loss: 2.03706086675326

Epoch: 5| Step: 9
Training loss: 1.8000233173370361
Validation loss: 2.0422528088092804

Epoch: 5| Step: 10
Training loss: 1.9881038665771484
Validation loss: 2.042710358897845

Epoch: 5| Step: 11
Training loss: 1.7078111171722412
Validation loss: 2.0378225396076837

Epoch: 143| Step: 0
Training loss: 2.252808094024658
Validation loss: 2.054698651035627

Epoch: 5| Step: 1
Training loss: 2.0954575538635254
Validation loss: 2.037706350286802

Epoch: 5| Step: 2
Training loss: 2.2206149101257324
Validation loss: 2.049447536468506

Epoch: 5| Step: 3
Training loss: 1.6330177783966064
Validation loss: 2.0499826620022454

Epoch: 5| Step: 4
Training loss: 1.8746778964996338
Validation loss: 2.0525610645612082

Epoch: 5| Step: 5
Training loss: 1.5953011512756348
Validation loss: 2.047074700395266

Epoch: 5| Step: 6
Training loss: 1.7500927448272705
Validation loss: 2.042258525888125

Epoch: 5| Step: 7
Training loss: 1.703812837600708
Validation loss: 2.039926052093506

Epoch: 5| Step: 8
Training loss: 2.352349042892456
Validation loss: 2.0373534858226776

Epoch: 5| Step: 9
Training loss: 2.974966526031494
Validation loss: 2.040130322178205

Epoch: 5| Step: 10
Training loss: 2.384601593017578
Validation loss: 2.043472091356913

Epoch: 5| Step: 11
Training loss: 1.2026206254959106
Validation loss: 2.0444570084412894

Epoch: 144| Step: 0
Training loss: 2.120540142059326
Validation loss: 2.0446154375871024

Epoch: 5| Step: 1
Training loss: 1.7854268550872803
Validation loss: 2.041361818710963

Epoch: 5| Step: 2
Training loss: 1.7626802921295166
Validation loss: 2.0503760129213333

Epoch: 5| Step: 3
Training loss: 2.1313223838806152
Validation loss: 2.043064624071121

Epoch: 5| Step: 4
Training loss: 2.677460193634033
Validation loss: 2.0582795292139053

Epoch: 5| Step: 5
Training loss: 1.8565231561660767
Validation loss: 2.0586595237255096

Epoch: 5| Step: 6
Training loss: 1.8631054162979126
Validation loss: 2.0456044375896454

Epoch: 5| Step: 7
Training loss: 1.9582080841064453
Validation loss: 2.0479410886764526

Epoch: 5| Step: 8
Training loss: 2.0498874187469482
Validation loss: 2.047058949867884

Epoch: 5| Step: 9
Training loss: 2.104379177093506
Validation loss: 2.0401593198378882

Epoch: 5| Step: 10
Training loss: 2.3172264099121094
Validation loss: 2.039891396959623

Epoch: 5| Step: 11
Training loss: 1.5642123222351074
Validation loss: 2.053791215022405

Epoch: 145| Step: 0
Training loss: 2.161834478378296
Validation loss: 2.045852243900299

Epoch: 5| Step: 1
Training loss: 1.9153703451156616
Validation loss: 2.0479002743959427

Epoch: 5| Step: 2
Training loss: 2.361621856689453
Validation loss: 2.055921529730161

Epoch: 5| Step: 3
Training loss: 2.0814123153686523
Validation loss: 2.055653457840284

Epoch: 5| Step: 4
Training loss: 2.407949924468994
Validation loss: 2.0673480878273645

Epoch: 5| Step: 5
Training loss: 1.7538177967071533
Validation loss: 2.0612620264291763

Epoch: 5| Step: 6
Training loss: 2.1755998134613037
Validation loss: 2.0477402905623117

Epoch: 5| Step: 7
Training loss: 2.5250601768493652
Validation loss: 2.053785120447477

Epoch: 5| Step: 8
Training loss: 1.3315517902374268
Validation loss: 2.0584228535493216

Epoch: 5| Step: 9
Training loss: 1.8073819875717163
Validation loss: 2.0504422883192697

Epoch: 5| Step: 10
Training loss: 1.960797905921936
Validation loss: 2.051367844144503

Epoch: 5| Step: 11
Training loss: 1.7977607250213623
Validation loss: 2.0551468282938004

Epoch: 146| Step: 0
Training loss: 2.1621005535125732
Validation loss: 2.05431721607844

Epoch: 5| Step: 1
Training loss: 2.3859729766845703
Validation loss: 2.040537898739179

Epoch: 5| Step: 2
Training loss: 1.7405672073364258
Validation loss: 2.0491072088479996

Epoch: 5| Step: 3
Training loss: 1.7732130289077759
Validation loss: 2.047341634829839

Epoch: 5| Step: 4
Training loss: 2.027947187423706
Validation loss: 2.0510775645573935

Epoch: 5| Step: 5
Training loss: 1.653066635131836
Validation loss: 2.0415480583906174

Epoch: 5| Step: 6
Training loss: 1.8596718311309814
Validation loss: 2.0589117258787155

Epoch: 5| Step: 7
Training loss: 2.3169913291931152
Validation loss: 2.0553361028432846

Epoch: 5| Step: 8
Training loss: 2.1302497386932373
Validation loss: 2.054036577542623

Epoch: 5| Step: 9
Training loss: 2.0161452293395996
Validation loss: 2.0436606258153915

Epoch: 5| Step: 10
Training loss: 2.261004686355591
Validation loss: 2.055447871486346

Epoch: 5| Step: 11
Training loss: 2.7905867099761963
Validation loss: 2.0298722883065543

Epoch: 147| Step: 0
Training loss: 2.049647569656372
Validation loss: 2.0457767248153687

Epoch: 5| Step: 1
Training loss: 1.7381328344345093
Validation loss: 2.047006587187449

Epoch: 5| Step: 2
Training loss: 1.7864134311676025
Validation loss: 2.043234169483185

Epoch: 5| Step: 3
Training loss: 2.4915242195129395
Validation loss: 2.0484094520409903

Epoch: 5| Step: 4
Training loss: 1.8413622379302979
Validation loss: 2.051975632707278

Epoch: 5| Step: 5
Training loss: 1.9394636154174805
Validation loss: 2.0446871568759284

Epoch: 5| Step: 6
Training loss: 2.0853588581085205
Validation loss: 2.044169376293818

Epoch: 5| Step: 7
Training loss: 2.102102041244507
Validation loss: 2.0522847274939218

Epoch: 5| Step: 8
Training loss: 1.9852917194366455
Validation loss: 2.0493123531341553

Epoch: 5| Step: 9
Training loss: 2.2110016345977783
Validation loss: 2.043263072768847

Epoch: 5| Step: 10
Training loss: 2.161820888519287
Validation loss: 2.0531595746676126

Epoch: 5| Step: 11
Training loss: 2.5492746829986572
Validation loss: 2.0501416524251304

Epoch: 148| Step: 0
Training loss: 1.8808120489120483
Validation loss: 2.0560998966296515

Epoch: 5| Step: 1
Training loss: 2.2445058822631836
Validation loss: 2.066193332274755

Epoch: 5| Step: 2
Training loss: 2.2482478618621826
Validation loss: 2.072919175028801

Epoch: 5| Step: 3
Training loss: 1.7966344356536865
Validation loss: 2.0798647354046502

Epoch: 5| Step: 4
Training loss: 2.0903162956237793
Validation loss: 2.0811599642038345

Epoch: 5| Step: 5
Training loss: 1.9796521663665771
Validation loss: 2.072943458954493

Epoch: 5| Step: 6
Training loss: 2.389603853225708
Validation loss: 2.0641500651836395

Epoch: 5| Step: 7
Training loss: 2.2574334144592285
Validation loss: 2.0535286913315454

Epoch: 5| Step: 8
Training loss: 2.275101661682129
Validation loss: 2.0359997004270554

Epoch: 5| Step: 9
Training loss: 1.8295236825942993
Validation loss: 2.038348615169525

Epoch: 5| Step: 10
Training loss: 1.7584987878799438
Validation loss: 2.03141118089358

Epoch: 5| Step: 11
Training loss: 1.5774662494659424
Validation loss: 2.031834547718366

Epoch: 149| Step: 0
Training loss: 2.354447603225708
Validation loss: 2.034898797671

Epoch: 5| Step: 1
Training loss: 1.8943355083465576
Validation loss: 2.0333316872517266

Epoch: 5| Step: 2
Training loss: 2.3558027744293213
Validation loss: 2.033832644422849

Epoch: 5| Step: 3
Training loss: 2.544264793395996
Validation loss: 2.0374687761068344

Epoch: 5| Step: 4
Training loss: 1.754115343093872
Validation loss: 2.0489564538002014

Epoch: 5| Step: 5
Training loss: 2.115339756011963
Validation loss: 2.0387315650780997

Epoch: 5| Step: 6
Training loss: 2.0833873748779297
Validation loss: 2.052136783798536

Epoch: 5| Step: 7
Training loss: 1.8723068237304688
Validation loss: 2.0445356170336404

Epoch: 5| Step: 8
Training loss: 1.2201874256134033
Validation loss: 2.050628880659739

Epoch: 5| Step: 9
Training loss: 1.7748212814331055
Validation loss: 2.0545233388741813

Epoch: 5| Step: 10
Training loss: 2.643195867538452
Validation loss: 2.0518756210803986

Epoch: 5| Step: 11
Training loss: 0.7113465070724487
Validation loss: 2.051963835954666

Epoch: 150| Step: 0
Training loss: 2.0536043643951416
Validation loss: 2.050926590959231

Epoch: 5| Step: 1
Training loss: 2.2012674808502197
Validation loss: 2.05047008395195

Epoch: 5| Step: 2
Training loss: 2.288767099380493
Validation loss: 2.038214017947515

Epoch: 5| Step: 3
Training loss: 1.8891475200653076
Validation loss: 2.046765352288882

Epoch: 5| Step: 4
Training loss: 2.137343406677246
Validation loss: 2.043399011095365

Epoch: 5| Step: 5
Training loss: 2.2735373973846436
Validation loss: 2.0532280753056207

Epoch: 5| Step: 6
Training loss: 2.2854437828063965
Validation loss: 2.060836831728617

Epoch: 5| Step: 7
Training loss: 1.8897535800933838
Validation loss: 2.0498499274253845

Epoch: 5| Step: 8
Training loss: 2.1015868186950684
Validation loss: 2.0438447445631027

Epoch: 5| Step: 9
Training loss: 1.99917733669281
Validation loss: 2.071141247948011

Epoch: 5| Step: 10
Training loss: 1.5302035808563232
Validation loss: 2.0484720319509506

Epoch: 5| Step: 11
Training loss: 1.3045531511306763
Validation loss: 2.0580666015545526

Epoch: 151| Step: 0
Training loss: 1.7527742385864258
Validation loss: 2.0635504871606827

Epoch: 5| Step: 1
Training loss: 2.173888683319092
Validation loss: 2.062037150065104

Epoch: 5| Step: 2
Training loss: 2.1594815254211426
Validation loss: 2.0694747616847358

Epoch: 5| Step: 3
Training loss: 2.087794542312622
Validation loss: 2.0637156665325165

Epoch: 5| Step: 4
Training loss: 2.316310405731201
Validation loss: 2.074965467055639

Epoch: 5| Step: 5
Training loss: 2.11875319480896
Validation loss: 2.068424408634504

Epoch: 5| Step: 6
Training loss: 2.041123151779175
Validation loss: 2.0708914697170258

Epoch: 5| Step: 7
Training loss: 2.0511531829833984
Validation loss: 2.059454729159673

Epoch: 5| Step: 8
Training loss: 1.4448282718658447
Validation loss: 2.055808653434118

Epoch: 5| Step: 9
Training loss: 2.2439749240875244
Validation loss: 2.0553236653407416

Epoch: 5| Step: 10
Training loss: 2.010556936264038
Validation loss: 2.0582894633213678

Epoch: 5| Step: 11
Training loss: 1.6572389602661133
Validation loss: 2.0498914370934167

Epoch: 152| Step: 0
Training loss: 1.9566961526870728
Validation loss: 2.0512024611234665

Epoch: 5| Step: 1
Training loss: 2.2802727222442627
Validation loss: 2.059688369433085

Epoch: 5| Step: 2
Training loss: 1.67154061794281
Validation loss: 2.052286605040232

Epoch: 5| Step: 3
Training loss: 2.4490818977355957
Validation loss: 2.0491123100121817

Epoch: 5| Step: 4
Training loss: 1.4277417659759521
Validation loss: 2.0376315812269845

Epoch: 5| Step: 5
Training loss: 2.2716734409332275
Validation loss: 2.031937559445699

Epoch: 5| Step: 6
Training loss: 1.9460718631744385
Validation loss: 2.0336289008458457

Epoch: 5| Step: 7
Training loss: 2.268860101699829
Validation loss: 2.0300578574339547

Epoch: 5| Step: 8
Training loss: 2.0590758323669434
Validation loss: 2.024325971802076

Epoch: 5| Step: 9
Training loss: 2.0799291133880615
Validation loss: 2.023013403018316

Epoch: 5| Step: 10
Training loss: 2.0900611877441406
Validation loss: 2.0337713907162347

Epoch: 5| Step: 11
Training loss: 2.5765199661254883
Validation loss: 2.0213002413511276

Epoch: 153| Step: 0
Training loss: 2.584078311920166
Validation loss: 2.0313933889071145

Epoch: 5| Step: 1
Training loss: 2.1598968505859375
Validation loss: 2.0278254648049674

Epoch: 5| Step: 2
Training loss: 1.7941049337387085
Validation loss: 2.0262001752853394

Epoch: 5| Step: 3
Training loss: 2.1028542518615723
Validation loss: 2.0474505722522736

Epoch: 5| Step: 4
Training loss: 2.0628316402435303
Validation loss: 2.038754398624102

Epoch: 5| Step: 5
Training loss: 2.3029797077178955
Validation loss: 2.04669843117396

Epoch: 5| Step: 6
Training loss: 1.3719340562820435
Validation loss: 2.0629214445749917

Epoch: 5| Step: 7
Training loss: 2.563074827194214
Validation loss: 2.0521487245957055

Epoch: 5| Step: 8
Training loss: 1.961633324623108
Validation loss: 2.0427013585964837

Epoch: 5| Step: 9
Training loss: 2.209695339202881
Validation loss: 2.044663260380427

Epoch: 5| Step: 10
Training loss: 1.511577844619751
Validation loss: 2.0393101274967194

Epoch: 5| Step: 11
Training loss: 1.3749189376831055
Validation loss: 2.0361981789271035

Epoch: 154| Step: 0
Training loss: 1.707622766494751
Validation loss: 2.0418435086806617

Epoch: 5| Step: 1
Training loss: 2.0620388984680176
Validation loss: 2.03360053896904

Epoch: 5| Step: 2
Training loss: 2.308720111846924
Validation loss: 2.038492431243261

Epoch: 5| Step: 3
Training loss: 2.3403706550598145
Validation loss: 2.04079540570577

Epoch: 5| Step: 4
Training loss: 1.7661796808242798
Validation loss: 2.0495523611704507

Epoch: 5| Step: 5
Training loss: 2.058725595474243
Validation loss: 2.053918023904165

Epoch: 5| Step: 6
Training loss: 1.9365921020507812
Validation loss: 2.0496507436037064

Epoch: 5| Step: 7
Training loss: 2.0445432662963867
Validation loss: 2.0545432368914285

Epoch: 5| Step: 8
Training loss: 2.474569797515869
Validation loss: 2.052173842986425

Epoch: 5| Step: 9
Training loss: 1.9796289205551147
Validation loss: 2.0556217233339944

Epoch: 5| Step: 10
Training loss: 1.822998046875
Validation loss: 2.041558881600698

Epoch: 5| Step: 11
Training loss: 1.7666664123535156
Validation loss: 2.0552470833063126

Epoch: 155| Step: 0
Training loss: 2.1261258125305176
Validation loss: 2.040890857577324

Epoch: 5| Step: 1
Training loss: 2.1146957874298096
Validation loss: 2.0534050663312278

Epoch: 5| Step: 2
Training loss: 2.400923490524292
Validation loss: 2.0616852839787803

Epoch: 5| Step: 3
Training loss: 2.489454746246338
Validation loss: 2.0418273707230887

Epoch: 5| Step: 4
Training loss: 2.2806859016418457
Validation loss: 2.05882835884889

Epoch: 5| Step: 5
Training loss: 1.7997058629989624
Validation loss: 2.0494448294242225

Epoch: 5| Step: 6
Training loss: 1.7493908405303955
Validation loss: 2.042631283402443

Epoch: 5| Step: 7
Training loss: 1.8884685039520264
Validation loss: 2.053964580098788

Epoch: 5| Step: 8
Training loss: 2.0454325675964355
Validation loss: 2.0553205808003745

Epoch: 5| Step: 9
Training loss: 1.612682580947876
Validation loss: 2.0483350455760956

Epoch: 5| Step: 10
Training loss: 1.7789485454559326
Validation loss: 2.0546822597583136

Epoch: 5| Step: 11
Training loss: 2.585860252380371
Validation loss: 2.066732962926229

Epoch: 156| Step: 0
Training loss: 2.3595948219299316
Validation loss: 2.0563309689362845

Epoch: 5| Step: 1
Training loss: 2.22300386428833
Validation loss: 2.070177440841993

Epoch: 5| Step: 2
Training loss: 2.4737768173217773
Validation loss: 2.0570904910564423

Epoch: 5| Step: 3
Training loss: 1.858755111694336
Validation loss: 2.0607697665691376

Epoch: 5| Step: 4
Training loss: 2.179173707962036
Validation loss: 2.0451644410689673

Epoch: 5| Step: 5
Training loss: 1.9690487384796143
Validation loss: 2.046947648127874

Epoch: 5| Step: 6
Training loss: 1.7773278951644897
Validation loss: 2.0377775927384696

Epoch: 5| Step: 7
Training loss: 1.9445457458496094
Validation loss: 2.036448131004969

Epoch: 5| Step: 8
Training loss: 1.8041614294052124
Validation loss: 2.0450312197208405

Epoch: 5| Step: 9
Training loss: 2.0147624015808105
Validation loss: 2.0367810179789863

Epoch: 5| Step: 10
Training loss: 1.9265601634979248
Validation loss: 2.0411404768625894

Epoch: 5| Step: 11
Training loss: 1.6985341310501099
Validation loss: 2.039855952064196

Epoch: 157| Step: 0
Training loss: 1.5538461208343506
Validation loss: 2.032559782266617

Epoch: 5| Step: 1
Training loss: 1.6956546306610107
Validation loss: 2.0474036584297814

Epoch: 5| Step: 2
Training loss: 2.378523588180542
Validation loss: 2.0478931119044623

Epoch: 5| Step: 3
Training loss: 2.1980233192443848
Validation loss: 2.0778518319129944

Epoch: 5| Step: 4
Training loss: 2.411010265350342
Validation loss: 2.0674747874339423

Epoch: 5| Step: 5
Training loss: 2.503594398498535
Validation loss: 2.0616161823272705

Epoch: 5| Step: 6
Training loss: 2.3758397102355957
Validation loss: 2.074715922276179

Epoch: 5| Step: 7
Training loss: 1.771378755569458
Validation loss: 2.0792653212944665

Epoch: 5| Step: 8
Training loss: 1.8987901210784912
Validation loss: 2.0631593465805054

Epoch: 5| Step: 9
Training loss: 2.3163981437683105
Validation loss: 2.0470376014709473

Epoch: 5| Step: 10
Training loss: 1.6592748165130615
Validation loss: 2.0392021387815475

Epoch: 5| Step: 11
Training loss: 1.5116145610809326
Validation loss: 2.024956534306208

Epoch: 158| Step: 0
Training loss: 1.4993623495101929
Validation loss: 2.023233080903689

Epoch: 5| Step: 1
Training loss: 1.4956634044647217
Validation loss: 2.0281795213619866

Epoch: 5| Step: 2
Training loss: 2.0122179985046387
Validation loss: 2.0269874036312103

Epoch: 5| Step: 3
Training loss: 2.505066394805908
Validation loss: 2.0306603759527206

Epoch: 5| Step: 4
Training loss: 2.038142681121826
Validation loss: 2.0410195092360177

Epoch: 5| Step: 5
Training loss: 2.426546335220337
Validation loss: 2.0485754708449044

Epoch: 5| Step: 6
Training loss: 2.449676036834717
Validation loss: 2.049321452776591

Epoch: 5| Step: 7
Training loss: 1.9621083736419678
Validation loss: 2.062380234400431

Epoch: 5| Step: 8
Training loss: 2.0834875106811523
Validation loss: 2.069918985168139

Epoch: 5| Step: 9
Training loss: 2.0156643390655518
Validation loss: 2.053940643866857

Epoch: 5| Step: 10
Training loss: 2.333629846572876
Validation loss: 2.062404135862986

Epoch: 5| Step: 11
Training loss: 1.7601711750030518
Validation loss: 2.0613239854574203

Epoch: 159| Step: 0
Training loss: 2.1583914756774902
Validation loss: 2.0734760661919913

Epoch: 5| Step: 1
Training loss: 2.1342034339904785
Validation loss: 2.0841709673404694

Epoch: 5| Step: 2
Training loss: 2.201773166656494
Validation loss: 2.0774233986934028

Epoch: 5| Step: 3
Training loss: 1.6334788799285889
Validation loss: 2.0712587932745614

Epoch: 5| Step: 4
Training loss: 2.031376600265503
Validation loss: 2.069975679119428

Epoch: 5| Step: 5
Training loss: 2.1226305961608887
Validation loss: 2.075375313560168

Epoch: 5| Step: 6
Training loss: 1.931483268737793
Validation loss: 2.072608927885691

Epoch: 5| Step: 7
Training loss: 2.092087984085083
Validation loss: 2.075534919897715

Epoch: 5| Step: 8
Training loss: 1.8729747533798218
Validation loss: 2.060628727078438

Epoch: 5| Step: 9
Training loss: 1.9266140460968018
Validation loss: 2.0709086110194526

Epoch: 5| Step: 10
Training loss: 2.322234630584717
Validation loss: 2.0517450273036957

Epoch: 5| Step: 11
Training loss: 2.234713077545166
Validation loss: 2.0493835558493934

Epoch: 160| Step: 0
Training loss: 1.9719616174697876
Validation loss: 2.0538420975208282

Epoch: 5| Step: 1
Training loss: 1.8690698146820068
Validation loss: 2.034374306599299

Epoch: 5| Step: 2
Training loss: 1.9833347797393799
Validation loss: 2.0492300242185593

Epoch: 5| Step: 3
Training loss: 2.333123207092285
Validation loss: 2.0571125646432242

Epoch: 5| Step: 4
Training loss: 1.9242063760757446
Validation loss: 2.0446781317392984

Epoch: 5| Step: 5
Training loss: 1.8052558898925781
Validation loss: 2.0589098831017814

Epoch: 5| Step: 6
Training loss: 1.953037977218628
Validation loss: 2.0542859633763633

Epoch: 5| Step: 7
Training loss: 1.8640992641448975
Validation loss: 2.050545255343119

Epoch: 5| Step: 8
Training loss: 2.2519307136535645
Validation loss: 2.048098161816597

Epoch: 5| Step: 9
Training loss: 1.8874597549438477
Validation loss: 2.0622610300779343

Epoch: 5| Step: 10
Training loss: 2.7143895626068115
Validation loss: 2.053054834405581

Epoch: 5| Step: 11
Training loss: 1.656202793121338
Validation loss: 2.048958813150724

Epoch: 161| Step: 0
Training loss: 1.8505929708480835
Validation loss: 2.056412766377131

Epoch: 5| Step: 1
Training loss: 2.4715209007263184
Validation loss: 2.0382052212953568

Epoch: 5| Step: 2
Training loss: 1.7175925970077515
Validation loss: 2.0372397700945535

Epoch: 5| Step: 3
Training loss: 2.5965116024017334
Validation loss: 2.0290822933117547

Epoch: 5| Step: 4
Training loss: 1.7466309070587158
Validation loss: 2.050163447856903

Epoch: 5| Step: 5
Training loss: 2.078517436981201
Validation loss: 2.041199207305908

Epoch: 5| Step: 6
Training loss: 2.1542229652404785
Validation loss: 2.04198449353377

Epoch: 5| Step: 7
Training loss: 2.1788649559020996
Validation loss: 2.03904727101326

Epoch: 5| Step: 8
Training loss: 1.7923004627227783
Validation loss: 2.046739583214124

Epoch: 5| Step: 9
Training loss: 1.9436556100845337
Validation loss: 2.0540207972129187

Epoch: 5| Step: 10
Training loss: 2.1202499866485596
Validation loss: 2.0512246787548065

Epoch: 5| Step: 11
Training loss: 0.8600943088531494
Validation loss: 2.0639036695162454

Epoch: 162| Step: 0
Training loss: 2.009861707687378
Validation loss: 2.058511887987455

Epoch: 5| Step: 1
Training loss: 2.194286346435547
Validation loss: 2.05903888742129

Epoch: 5| Step: 2
Training loss: 2.063025951385498
Validation loss: 2.060601328810056

Epoch: 5| Step: 3
Training loss: 2.06669545173645
Validation loss: 2.047345628341039

Epoch: 5| Step: 4
Training loss: 1.8599741458892822
Validation loss: 2.0583400328954062

Epoch: 5| Step: 5
Training loss: 1.4701523780822754
Validation loss: 2.0513527592023215

Epoch: 5| Step: 6
Training loss: 2.12082839012146
Validation loss: 2.0493951588869095

Epoch: 5| Step: 7
Training loss: 1.9804589748382568
Validation loss: 2.06144188841184

Epoch: 5| Step: 8
Training loss: 1.6209814548492432
Validation loss: 2.051231563091278

Epoch: 5| Step: 9
Training loss: 2.889756202697754
Validation loss: 2.049838816126188

Epoch: 5| Step: 10
Training loss: 2.2205958366394043
Validation loss: 2.045105720559756

Epoch: 5| Step: 11
Training loss: 0.9603642821311951
Validation loss: 2.0426384806632996

Epoch: 163| Step: 0
Training loss: 2.217417001724243
Validation loss: 2.04788730541865

Epoch: 5| Step: 1
Training loss: 2.1562557220458984
Validation loss: 2.0627827793359756

Epoch: 5| Step: 2
Training loss: 1.9407541751861572
Validation loss: 2.0500241170326867

Epoch: 5| Step: 3
Training loss: 1.7977784872055054
Validation loss: 2.051860665281614

Epoch: 5| Step: 4
Training loss: 2.107928991317749
Validation loss: 2.0644715974728265

Epoch: 5| Step: 5
Training loss: 1.7567285299301147
Validation loss: 2.0616579204797745

Epoch: 5| Step: 6
Training loss: 2.417733669281006
Validation loss: 2.0642405102650323

Epoch: 5| Step: 7
Training loss: 1.781576156616211
Validation loss: 2.064264992872874

Epoch: 5| Step: 8
Training loss: 2.0559802055358887
Validation loss: 2.0730491131544113

Epoch: 5| Step: 9
Training loss: 1.876142144203186
Validation loss: 2.06415922443072

Epoch: 5| Step: 10
Training loss: 1.901545763015747
Validation loss: 2.0699970920880637

Epoch: 5| Step: 11
Training loss: 2.896787166595459
Validation loss: 2.062123795350393

Epoch: 164| Step: 0
Training loss: 1.92813241481781
Validation loss: 2.0645849903424582

Epoch: 5| Step: 1
Training loss: 1.9395835399627686
Validation loss: 2.0598103404045105

Epoch: 5| Step: 2
Training loss: 1.5945756435394287
Validation loss: 2.037923331061999

Epoch: 5| Step: 3
Training loss: 2.0853941440582275
Validation loss: 2.0326436161994934

Epoch: 5| Step: 4
Training loss: 2.6117446422576904
Validation loss: 2.032093813021978

Epoch: 5| Step: 5
Training loss: 2.047545909881592
Validation loss: 2.026401857535044

Epoch: 5| Step: 6
Training loss: 1.9776992797851562
Validation loss: 2.0271021028359733

Epoch: 5| Step: 7
Training loss: 1.8828353881835938
Validation loss: 2.026062861084938

Epoch: 5| Step: 8
Training loss: 2.09210205078125
Validation loss: 2.036491940418879

Epoch: 5| Step: 9
Training loss: 1.9580762386322021
Validation loss: 2.0432486484448114

Epoch: 5| Step: 10
Training loss: 2.304549217224121
Validation loss: 2.044238969683647

Epoch: 5| Step: 11
Training loss: 2.1987111568450928
Validation loss: 2.042521486679713

Epoch: 165| Step: 0
Training loss: 1.9497798681259155
Validation loss: 2.053318371375402

Epoch: 5| Step: 1
Training loss: 2.0477302074432373
Validation loss: 2.0730735262235007

Epoch: 5| Step: 2
Training loss: 1.48036527633667
Validation loss: 2.072013313571612

Epoch: 5| Step: 3
Training loss: 1.7388349771499634
Validation loss: 2.0786999265352883

Epoch: 5| Step: 4
Training loss: 2.3543198108673096
Validation loss: 2.0984441190958023

Epoch: 5| Step: 5
Training loss: 2.334914445877075
Validation loss: 2.1045146137475967

Epoch: 5| Step: 6
Training loss: 1.9330384731292725
Validation loss: 2.1073687126239142

Epoch: 5| Step: 7
Training loss: 2.2467668056488037
Validation loss: 2.086580976843834

Epoch: 5| Step: 8
Training loss: 2.1633193492889404
Validation loss: 2.0735657066106796

Epoch: 5| Step: 9
Training loss: 2.3428120613098145
Validation loss: 2.0652866860230765

Epoch: 5| Step: 10
Training loss: 1.8889029026031494
Validation loss: 2.0571580876906714

Epoch: 5| Step: 11
Training loss: 1.8334447145462036
Validation loss: 2.0433682203292847

Epoch: 166| Step: 0
Training loss: 1.6990162134170532
Validation loss: 2.0333131750424704

Epoch: 5| Step: 1
Training loss: 2.1187305450439453
Validation loss: 2.0484304825464883

Epoch: 5| Step: 2
Training loss: 1.9743032455444336
Validation loss: 2.0483831663926444

Epoch: 5| Step: 3
Training loss: 2.0469348430633545
Validation loss: 2.061960150798162

Epoch: 5| Step: 4
Training loss: 2.4085640907287598
Validation loss: 2.067889153957367

Epoch: 5| Step: 5
Training loss: 2.100693464279175
Validation loss: 2.0743024994929633

Epoch: 5| Step: 6
Training loss: 1.9977248907089233
Validation loss: 2.07101833820343

Epoch: 5| Step: 7
Training loss: 2.580150842666626
Validation loss: 2.080262025197347

Epoch: 5| Step: 8
Training loss: 2.469282865524292
Validation loss: 2.084778611858686

Epoch: 5| Step: 9
Training loss: 2.20523738861084
Validation loss: 2.075356602668762

Epoch: 5| Step: 10
Training loss: 2.1108198165893555
Validation loss: 2.0822559793790183

Epoch: 5| Step: 11
Training loss: 2.5915355682373047
Validation loss: 2.082225427031517

Epoch: 167| Step: 0
Training loss: 2.609251022338867
Validation loss: 2.0694982558488846

Epoch: 5| Step: 1
Training loss: 1.8962516784667969
Validation loss: 2.086829791466395

Epoch: 5| Step: 2
Training loss: 1.9087035655975342
Validation loss: 2.0790634552637735

Epoch: 5| Step: 3
Training loss: 2.356935501098633
Validation loss: 2.0805072635412216

Epoch: 5| Step: 4
Training loss: 1.8976513147354126
Validation loss: 2.0772696087757745

Epoch: 5| Step: 5
Training loss: 2.0283477306365967
Validation loss: 2.07207353413105

Epoch: 5| Step: 6
Training loss: 2.0528995990753174
Validation loss: 2.0681394984324775

Epoch: 5| Step: 7
Training loss: 2.2195885181427
Validation loss: 2.065462499856949

Epoch: 5| Step: 8
Training loss: 2.390033006668091
Validation loss: 2.065549830595652

Epoch: 5| Step: 9
Training loss: 2.1428334712982178
Validation loss: 2.0516623308261237

Epoch: 5| Step: 10
Training loss: 2.0734171867370605
Validation loss: 2.0356180667877197

Epoch: 5| Step: 11
Training loss: 2.511167049407959
Validation loss: 2.031462316711744

Epoch: 168| Step: 0
Training loss: 2.089548110961914
Validation loss: 2.025369872649511

Epoch: 5| Step: 1
Training loss: 2.6808972358703613
Validation loss: 2.015044475595156

Epoch: 5| Step: 2
Training loss: 2.125380039215088
Validation loss: 2.020676389336586

Epoch: 5| Step: 3
Training loss: 2.2918925285339355
Validation loss: 2.0286074578762054

Epoch: 5| Step: 4
Training loss: 2.0025877952575684
Validation loss: 2.0394014418125153

Epoch: 5| Step: 5
Training loss: 1.884203314781189
Validation loss: 2.0496785988410315

Epoch: 5| Step: 6
Training loss: 1.8866363763809204
Validation loss: 2.046513537565867

Epoch: 5| Step: 7
Training loss: 1.5514553785324097
Validation loss: 2.0619176576534906

Epoch: 5| Step: 8
Training loss: 1.9799401760101318
Validation loss: 2.053877115249634

Epoch: 5| Step: 9
Training loss: 2.180579662322998
Validation loss: 2.0525586853424707

Epoch: 5| Step: 10
Training loss: 1.8651221990585327
Validation loss: 2.066004231572151

Epoch: 5| Step: 11
Training loss: 2.4791364669799805
Validation loss: 2.066377321879069

Epoch: 169| Step: 0
Training loss: 2.2074532508850098
Validation loss: 2.0613901168107986

Epoch: 5| Step: 1
Training loss: 1.75678288936615
Validation loss: 2.0616081406672797

Epoch: 5| Step: 2
Training loss: 1.906275987625122
Validation loss: 2.0465795745452247

Epoch: 5| Step: 3
Training loss: 1.939851999282837
Validation loss: 2.0615628212690353

Epoch: 5| Step: 4
Training loss: 1.8281360864639282
Validation loss: 2.0468611866235733

Epoch: 5| Step: 5
Training loss: 2.2547240257263184
Validation loss: 2.048210913936297

Epoch: 5| Step: 6
Training loss: 2.3502373695373535
Validation loss: 2.036525547504425

Epoch: 5| Step: 7
Training loss: 2.3094394207000732
Validation loss: 2.0594027837117515

Epoch: 5| Step: 8
Training loss: 2.1177477836608887
Validation loss: 2.0498909453550973

Epoch: 5| Step: 9
Training loss: 1.9390159845352173
Validation loss: 2.047681227326393

Epoch: 5| Step: 10
Training loss: 1.6611006259918213
Validation loss: 2.0577742606401443

Epoch: 5| Step: 11
Training loss: 1.7262132167816162
Validation loss: 2.0512686322132745

Epoch: 170| Step: 0
Training loss: 2.3984436988830566
Validation loss: 2.0540577421585717

Epoch: 5| Step: 1
Training loss: 1.5817961692810059
Validation loss: 2.0474457691113153

Epoch: 5| Step: 2
Training loss: 1.9220348596572876
Validation loss: 2.0662019650141397

Epoch: 5| Step: 3
Training loss: 2.4824283123016357
Validation loss: 2.075461596250534

Epoch: 5| Step: 4
Training loss: 2.185521364212036
Validation loss: 2.0677669048309326

Epoch: 5| Step: 5
Training loss: 1.6753454208374023
Validation loss: 2.0821662743886313

Epoch: 5| Step: 6
Training loss: 1.941742181777954
Validation loss: 2.0926383982102075

Epoch: 5| Step: 7
Training loss: 1.7002599239349365
Validation loss: 2.076275408267975

Epoch: 5| Step: 8
Training loss: 2.3170809745788574
Validation loss: 2.0826274901628494

Epoch: 5| Step: 9
Training loss: 2.36356782913208
Validation loss: 2.077600598335266

Epoch: 5| Step: 10
Training loss: 1.8086845874786377
Validation loss: 2.092566246787707

Epoch: 5| Step: 11
Training loss: 1.0623900890350342
Validation loss: 2.069228162368139

Epoch: 171| Step: 0
Training loss: 2.087010145187378
Validation loss: 2.0722239017486572

Epoch: 5| Step: 1
Training loss: 1.6374660730361938
Validation loss: 2.0827627380688987

Epoch: 5| Step: 2
Training loss: 2.1290535926818848
Validation loss: 2.072402238845825

Epoch: 5| Step: 3
Training loss: 1.6527366638183594
Validation loss: 2.0640770892302194

Epoch: 5| Step: 4
Training loss: 2.51004958152771
Validation loss: 2.055732304851214

Epoch: 5| Step: 5
Training loss: 2.1892752647399902
Validation loss: 2.0560013403495154

Epoch: 5| Step: 6
Training loss: 2.5079667568206787
Validation loss: 2.0474096288283667

Epoch: 5| Step: 7
Training loss: 2.5564064979553223
Validation loss: 2.037901689608892

Epoch: 5| Step: 8
Training loss: 1.633894681930542
Validation loss: 2.050549641251564

Epoch: 5| Step: 9
Training loss: 1.8132778406143188
Validation loss: 2.0496639758348465

Epoch: 5| Step: 10
Training loss: 1.5632610321044922
Validation loss: 2.062860369682312

Epoch: 5| Step: 11
Training loss: 2.0175294876098633
Validation loss: 2.0724170257647834

Epoch: 172| Step: 0
Training loss: 2.1678521633148193
Validation loss: 2.085322151581446

Epoch: 5| Step: 1
Training loss: 2.0469002723693848
Validation loss: 2.1027140070994697

Epoch: 5| Step: 2
Training loss: 1.9636011123657227
Validation loss: 2.143837417165438

Epoch: 5| Step: 3
Training loss: 2.29537296295166
Validation loss: 2.172703037659327

Epoch: 5| Step: 4
Training loss: 2.1972365379333496
Validation loss: 2.1634377936522164

Epoch: 5| Step: 5
Training loss: 2.1662795543670654
Validation loss: 2.1426259676615396

Epoch: 5| Step: 6
Training loss: 1.9864912033081055
Validation loss: 2.1138198922077813

Epoch: 5| Step: 7
Training loss: 2.3495373725891113
Validation loss: 2.0719274282455444

Epoch: 5| Step: 8
Training loss: 2.1440587043762207
Validation loss: 2.0466122974952063

Epoch: 5| Step: 9
Training loss: 1.9035934209823608
Validation loss: 2.045734167098999

Epoch: 5| Step: 10
Training loss: 2.225625991821289
Validation loss: 2.030113235116005

Epoch: 5| Step: 11
Training loss: 1.8393828868865967
Validation loss: 2.032777279615402

Epoch: 173| Step: 0
Training loss: 1.8171155452728271
Validation loss: 2.031034971276919

Epoch: 5| Step: 1
Training loss: 1.9973933696746826
Validation loss: 2.038496176401774

Epoch: 5| Step: 2
Training loss: 1.9893544912338257
Validation loss: 2.0415466924508414

Epoch: 5| Step: 3
Training loss: 1.7803637981414795
Validation loss: 2.0536989023288093

Epoch: 5| Step: 4
Training loss: 2.356931209564209
Validation loss: 2.050547311703364

Epoch: 5| Step: 5
Training loss: 2.0250120162963867
Validation loss: 2.0423670013745627

Epoch: 5| Step: 6
Training loss: 2.0487639904022217
Validation loss: 2.055342892805735

Epoch: 5| Step: 7
Training loss: 1.7799707651138306
Validation loss: 2.0479790469010672

Epoch: 5| Step: 8
Training loss: 2.5267200469970703
Validation loss: 2.0441054304440818

Epoch: 5| Step: 9
Training loss: 2.334193706512451
Validation loss: 2.0505981793006263

Epoch: 5| Step: 10
Training loss: 2.3039112091064453
Validation loss: 2.0468641767899194

Epoch: 5| Step: 11
Training loss: 2.1911063194274902
Validation loss: 2.063501998782158

Epoch: 174| Step: 0
Training loss: 1.5964725017547607
Validation loss: 2.063384855786959

Epoch: 5| Step: 1
Training loss: 2.366854190826416
Validation loss: 2.071449344356855

Epoch: 5| Step: 2
Training loss: 1.9614839553833008
Validation loss: 2.072564269105593

Epoch: 5| Step: 3
Training loss: 2.0560100078582764
Validation loss: 2.0731043020884194

Epoch: 5| Step: 4
Training loss: 2.0606420040130615
Validation loss: 2.0763304978609085

Epoch: 5| Step: 5
Training loss: 1.9613487720489502
Validation loss: 2.0834447542826333

Epoch: 5| Step: 6
Training loss: 1.4643663167953491
Validation loss: 2.0796563178300858

Epoch: 5| Step: 7
Training loss: 2.3338608741760254
Validation loss: 2.0781320532162986

Epoch: 5| Step: 8
Training loss: 1.7418180704116821
Validation loss: 2.076659252246221

Epoch: 5| Step: 9
Training loss: 2.5885612964630127
Validation loss: 2.0538178185621896

Epoch: 5| Step: 10
Training loss: 1.986485242843628
Validation loss: 2.053860440850258

Epoch: 5| Step: 11
Training loss: 3.9285309314727783
Validation loss: 2.060581937432289

Epoch: 175| Step: 0
Training loss: 1.5601106882095337
Validation loss: 2.03232479095459

Epoch: 5| Step: 1
Training loss: 1.9209849834442139
Validation loss: 2.0387548059225082

Epoch: 5| Step: 2
Training loss: 1.7135331630706787
Validation loss: 2.0487575928370156

Epoch: 5| Step: 3
Training loss: 1.654253363609314
Validation loss: 2.044492542743683

Epoch: 5| Step: 4
Training loss: 1.870094895362854
Validation loss: 2.0331694881121316

Epoch: 5| Step: 5
Training loss: 2.737374782562256
Validation loss: 2.0447860658168793

Epoch: 5| Step: 6
Training loss: 2.22021484375
Validation loss: 2.037943591674169

Epoch: 5| Step: 7
Training loss: 1.9328014850616455
Validation loss: 2.0444699923197427

Epoch: 5| Step: 8
Training loss: 2.1131508350372314
Validation loss: 2.0317682921886444

Epoch: 5| Step: 9
Training loss: 2.056946277618408
Validation loss: 2.0313310474157333

Epoch: 5| Step: 10
Training loss: 2.214822292327881
Validation loss: 2.0381125758091607

Epoch: 5| Step: 11
Training loss: 3.383349895477295
Validation loss: 2.0562978287537894

Epoch: 176| Step: 0
Training loss: 1.649196982383728
Validation loss: 2.0603244652350745

Epoch: 5| Step: 1
Training loss: 2.2388579845428467
Validation loss: 2.073917016386986

Epoch: 5| Step: 2
Training loss: 1.7023481130599976
Validation loss: 2.066523790359497

Epoch: 5| Step: 3
Training loss: 2.3668065071105957
Validation loss: 2.0525885274012885

Epoch: 5| Step: 4
Training loss: 1.3577362298965454
Validation loss: 2.0533887247244516

Epoch: 5| Step: 5
Training loss: 2.0931715965270996
Validation loss: 2.0725661168495813

Epoch: 5| Step: 6
Training loss: 2.8031692504882812
Validation loss: 2.074853544433912

Epoch: 5| Step: 7
Training loss: 1.9147207736968994
Validation loss: 2.0969119320313134

Epoch: 5| Step: 8
Training loss: 2.1267447471618652
Validation loss: 2.083086833357811

Epoch: 5| Step: 9
Training loss: 1.9901043176651
Validation loss: 2.102317521969477

Epoch: 5| Step: 10
Training loss: 1.8530480861663818
Validation loss: 2.09415303170681

Epoch: 5| Step: 11
Training loss: 2.876368761062622
Validation loss: 2.0863904704650245

Epoch: 177| Step: 0
Training loss: 2.178332567214966
Validation loss: 2.0873742600282035

Epoch: 5| Step: 1
Training loss: 1.9688785076141357
Validation loss: 2.0949535916248956

Epoch: 5| Step: 2
Training loss: 2.457590103149414
Validation loss: 2.0801173647244773

Epoch: 5| Step: 3
Training loss: 1.7106647491455078
Validation loss: 2.0730699400107064

Epoch: 5| Step: 4
Training loss: 1.7055490016937256
Validation loss: 2.055684650937716

Epoch: 5| Step: 5
Training loss: 2.059459924697876
Validation loss: 2.05498376985391

Epoch: 5| Step: 6
Training loss: 1.6859480142593384
Validation loss: 2.0573714474836984

Epoch: 5| Step: 7
Training loss: 2.046574115753174
Validation loss: 2.054743766784668

Epoch: 5| Step: 8
Training loss: 2.3570361137390137
Validation loss: 2.0438604255517325

Epoch: 5| Step: 9
Training loss: 2.2523446083068848
Validation loss: 2.0444616625706353

Epoch: 5| Step: 10
Training loss: 1.8548818826675415
Validation loss: 2.0564062694708505

Epoch: 5| Step: 11
Training loss: 2.2282373905181885
Validation loss: 2.056910827755928

Epoch: 178| Step: 0
Training loss: 2.3366758823394775
Validation loss: 2.0674661099910736

Epoch: 5| Step: 1
Training loss: 2.258457660675049
Validation loss: 2.0633579144875207

Epoch: 5| Step: 2
Training loss: 1.5352364778518677
Validation loss: 2.0737983733415604

Epoch: 5| Step: 3
Training loss: 2.253309726715088
Validation loss: 2.0822549909353256

Epoch: 5| Step: 4
Training loss: 1.28765869140625
Validation loss: 2.0834479480981827

Epoch: 5| Step: 5
Training loss: 1.8876953125
Validation loss: 2.0741338233153024

Epoch: 5| Step: 6
Training loss: 2.0308947563171387
Validation loss: 2.101390838623047

Epoch: 5| Step: 7
Training loss: 2.0788276195526123
Validation loss: 2.074781060218811

Epoch: 5| Step: 8
Training loss: 2.456916093826294
Validation loss: 2.0758964866399765

Epoch: 5| Step: 9
Training loss: 1.9546416997909546
Validation loss: 2.0915546913941703

Epoch: 5| Step: 10
Training loss: 1.81374192237854
Validation loss: 2.0659133195877075

Epoch: 5| Step: 11
Training loss: 2.6167635917663574
Validation loss: 2.0601836591959

Epoch: 179| Step: 0
Training loss: 2.24418306350708
Validation loss: 2.0571807424227395

Epoch: 5| Step: 1
Training loss: 1.6984115839004517
Validation loss: 2.049736579259237

Epoch: 5| Step: 2
Training loss: 2.233532428741455
Validation loss: 2.0411556462446847

Epoch: 5| Step: 3
Training loss: 1.7133928537368774
Validation loss: 2.039914608001709

Epoch: 5| Step: 4
Training loss: 1.9746379852294922
Validation loss: 2.049206554889679

Epoch: 5| Step: 5
Training loss: 2.1975812911987305
Validation loss: 2.0594083269437156

Epoch: 5| Step: 6
Training loss: 2.246488094329834
Validation loss: 2.056148946285248

Epoch: 5| Step: 7
Training loss: 1.9386022090911865
Validation loss: 2.0706447611252465

Epoch: 5| Step: 8
Training loss: 2.2204349040985107
Validation loss: 2.0728178520997367

Epoch: 5| Step: 9
Training loss: 1.9089691638946533
Validation loss: 2.0737661918004355

Epoch: 5| Step: 10
Training loss: 1.6738402843475342
Validation loss: 2.0625569770733514

Epoch: 5| Step: 11
Training loss: 2.6144847869873047
Validation loss: 2.073762779434522

Epoch: 180| Step: 0
Training loss: 2.1690380573272705
Validation loss: 2.077987109621366

Epoch: 5| Step: 1
Training loss: 2.100522518157959
Validation loss: 2.0631972601016364

Epoch: 5| Step: 2
Training loss: 2.2953715324401855
Validation loss: 2.055865148703257

Epoch: 5| Step: 3
Training loss: 1.8095496892929077
Validation loss: 2.0584033826986947

Epoch: 5| Step: 4
Training loss: 1.8238003253936768
Validation loss: 2.0487170666456223

Epoch: 5| Step: 5
Training loss: 2.3629987239837646
Validation loss: 2.057211627562841

Epoch: 5| Step: 6
Training loss: 2.148979663848877
Validation loss: 2.0447636594374976

Epoch: 5| Step: 7
Training loss: 1.9573571681976318
Validation loss: 2.048440004388491

Epoch: 5| Step: 8
Training loss: 1.7561686038970947
Validation loss: 2.0624962200721106

Epoch: 5| Step: 9
Training loss: 1.549919605255127
Validation loss: 2.061562900741895

Epoch: 5| Step: 10
Training loss: 2.2174699306488037
Validation loss: 2.080251023173332

Epoch: 5| Step: 11
Training loss: 2.674842119216919
Validation loss: 2.0900728503863015

Epoch: 181| Step: 0
Training loss: 2.767896890640259
Validation loss: 2.115703975160917

Epoch: 5| Step: 1
Training loss: 1.4607467651367188
Validation loss: 2.124229754010836

Epoch: 5| Step: 2
Training loss: 1.9384982585906982
Validation loss: 2.1264530569314957

Epoch: 5| Step: 3
Training loss: 2.4884984493255615
Validation loss: 2.119807024796804

Epoch: 5| Step: 4
Training loss: 1.8304595947265625
Validation loss: 2.1186671058336892

Epoch: 5| Step: 5
Training loss: 2.0591843128204346
Validation loss: 2.1107005923986435

Epoch: 5| Step: 6
Training loss: 2.087129592895508
Validation loss: 2.120998168985049

Epoch: 5| Step: 7
Training loss: 1.838362693786621
Validation loss: 2.1150210549434028

Epoch: 5| Step: 8
Training loss: 1.7549413442611694
Validation loss: 2.1006580144166946

Epoch: 5| Step: 9
Training loss: 2.205157518386841
Validation loss: 2.0852471391359964

Epoch: 5| Step: 10
Training loss: 1.9630701541900635
Validation loss: 2.074264963467916

Epoch: 5| Step: 11
Training loss: 1.6000335216522217
Validation loss: 2.075433457891146

Epoch: 182| Step: 0
Training loss: 2.044562339782715
Validation loss: 2.0681113650401435

Epoch: 5| Step: 1
Training loss: 1.093947172164917
Validation loss: 2.058922698100408

Epoch: 5| Step: 2
Training loss: 2.8752646446228027
Validation loss: 2.0734374274810157

Epoch: 5| Step: 3
Training loss: 2.087334632873535
Validation loss: 2.0669567237297692

Epoch: 5| Step: 4
Training loss: 1.8244616985321045
Validation loss: 2.0841444432735443

Epoch: 5| Step: 5
Training loss: 2.0335159301757812
Validation loss: 2.08306751648585

Epoch: 5| Step: 6
Training loss: 1.8336999416351318
Validation loss: 2.0886583477258682

Epoch: 5| Step: 7
Training loss: 2.2532989978790283
Validation loss: 2.104684347907702

Epoch: 5| Step: 8
Training loss: 2.123969316482544
Validation loss: 2.091051831841469

Epoch: 5| Step: 9
Training loss: 2.119988203048706
Validation loss: 2.0950199315945306

Epoch: 5| Step: 10
Training loss: 1.9456508159637451
Validation loss: 2.0915394574403763

Epoch: 5| Step: 11
Training loss: 1.7907376289367676
Validation loss: 2.090115929643313

Epoch: 183| Step: 0
Training loss: 2.128019094467163
Validation loss: 2.0844717423121133

Epoch: 5| Step: 1
Training loss: 1.4526201486587524
Validation loss: 2.0810826867818832

Epoch: 5| Step: 2
Training loss: 1.7582359313964844
Validation loss: 2.090727373957634

Epoch: 5| Step: 3
Training loss: 1.862209677696228
Validation loss: 2.0894007682800293

Epoch: 5| Step: 4
Training loss: 2.157355785369873
Validation loss: 2.0786371181408563

Epoch: 5| Step: 5
Training loss: 2.4515111446380615
Validation loss: 2.0776573022206626

Epoch: 5| Step: 6
Training loss: 2.322247266769409
Validation loss: 2.0776192446549735

Epoch: 5| Step: 7
Training loss: 2.0803134441375732
Validation loss: 2.0815229018529258

Epoch: 5| Step: 8
Training loss: 1.8365447521209717
Validation loss: 2.074401060740153

Epoch: 5| Step: 9
Training loss: 1.842392921447754
Validation loss: 2.06619926293691

Epoch: 5| Step: 10
Training loss: 2.3244879245758057
Validation loss: 2.0698900669813156

Epoch: 5| Step: 11
Training loss: 1.0752731561660767
Validation loss: 2.0594206353028617

Epoch: 184| Step: 0
Training loss: 1.8715747594833374
Validation loss: 2.075599953532219

Epoch: 5| Step: 1
Training loss: 1.8452653884887695
Validation loss: 2.0662589569886527

Epoch: 5| Step: 2
Training loss: 2.1049225330352783
Validation loss: 2.071489155292511

Epoch: 5| Step: 3
Training loss: 1.5597223043441772
Validation loss: 2.072256162762642

Epoch: 5| Step: 4
Training loss: 2.5951461791992188
Validation loss: 2.063695271809896

Epoch: 5| Step: 5
Training loss: 2.1303648948669434
Validation loss: 2.0850470463434854

Epoch: 5| Step: 6
Training loss: 2.2203118801116943
Validation loss: 2.083944653471311

Epoch: 5| Step: 7
Training loss: 1.870152235031128
Validation loss: 2.0867922405401864

Epoch: 5| Step: 8
Training loss: 1.8373167514801025
Validation loss: 2.096562534570694

Epoch: 5| Step: 9
Training loss: 1.740356683731079
Validation loss: 2.0796662966410318

Epoch: 5| Step: 10
Training loss: 2.1525228023529053
Validation loss: 2.097466011842092

Epoch: 5| Step: 11
Training loss: 1.2316534519195557
Validation loss: 2.0804157058397927

Epoch: 185| Step: 0
Training loss: 2.4406609535217285
Validation loss: 2.084474354982376

Epoch: 5| Step: 1
Training loss: 2.1361160278320312
Validation loss: 2.099851672848066

Epoch: 5| Step: 2
Training loss: 1.8375842571258545
Validation loss: 2.109582632780075

Epoch: 5| Step: 3
Training loss: 2.305058002471924
Validation loss: 2.084597885608673

Epoch: 5| Step: 4
Training loss: 1.7659168243408203
Validation loss: 2.0796590695778527

Epoch: 5| Step: 5
Training loss: 1.592767357826233
Validation loss: 2.06566754480203

Epoch: 5| Step: 6
Training loss: 2.269050121307373
Validation loss: 2.075326363245646

Epoch: 5| Step: 7
Training loss: 2.0454459190368652
Validation loss: 2.078930363059044

Epoch: 5| Step: 8
Training loss: 1.8535197973251343
Validation loss: 2.078245848417282

Epoch: 5| Step: 9
Training loss: 1.7760378122329712
Validation loss: 2.082615241408348

Epoch: 5| Step: 10
Training loss: 1.7485935688018799
Validation loss: 2.085165018836657

Epoch: 5| Step: 11
Training loss: 2.8669333457946777
Validation loss: 2.091039622823397

Epoch: 186| Step: 0
Training loss: 1.409111738204956
Validation loss: 2.0914886792500815

Epoch: 5| Step: 1
Training loss: 1.846133828163147
Validation loss: 2.088839446504911

Epoch: 5| Step: 2
Training loss: 1.8109804391860962
Validation loss: 2.103983844319979

Epoch: 5| Step: 3
Training loss: 2.6670844554901123
Validation loss: 2.08556999762853

Epoch: 5| Step: 4
Training loss: 1.8285181522369385
Validation loss: 2.094317391514778

Epoch: 5| Step: 5
Training loss: 1.903978943824768
Validation loss: 2.0765718718369803

Epoch: 5| Step: 6
Training loss: 2.5774736404418945
Validation loss: 2.0650308479865394

Epoch: 5| Step: 7
Training loss: 1.7775884866714478
Validation loss: 2.0715514570474625

Epoch: 5| Step: 8
Training loss: 1.9789577722549438
Validation loss: 2.0522502760092416

Epoch: 5| Step: 9
Training loss: 2.3128440380096436
Validation loss: 2.067428787549337

Epoch: 5| Step: 10
Training loss: 1.5237886905670166
Validation loss: 2.055861716469129

Epoch: 5| Step: 11
Training loss: 2.48088002204895
Validation loss: 2.058448185523351

Epoch: 187| Step: 0
Training loss: 2.482646942138672
Validation loss: 2.0515417555967965

Epoch: 5| Step: 1
Training loss: 1.1060909032821655
Validation loss: 2.07124100625515

Epoch: 5| Step: 2
Training loss: 2.3446621894836426
Validation loss: 2.0716997583707175

Epoch: 5| Step: 3
Training loss: 2.2847228050231934
Validation loss: 2.0748127748568854

Epoch: 5| Step: 4
Training loss: 2.2187695503234863
Validation loss: 2.07076529165109

Epoch: 5| Step: 5
Training loss: 2.072749137878418
Validation loss: 2.069052219390869

Epoch: 5| Step: 6
Training loss: 1.8574947118759155
Validation loss: 2.0534082849820456

Epoch: 5| Step: 7
Training loss: 1.8495432138442993
Validation loss: 2.0754677106936774

Epoch: 5| Step: 8
Training loss: 1.9010130167007446
Validation loss: 2.076841488480568

Epoch: 5| Step: 9
Training loss: 1.7552995681762695
Validation loss: 2.0806274811426797

Epoch: 5| Step: 10
Training loss: 2.0533313751220703
Validation loss: 2.078371912240982

Epoch: 5| Step: 11
Training loss: 1.686941385269165
Validation loss: 2.1040573517481485

Epoch: 188| Step: 0
Training loss: 1.9031022787094116
Validation loss: 2.079800342520078

Epoch: 5| Step: 1
Training loss: 2.1456332206726074
Validation loss: 2.0767670422792435

Epoch: 5| Step: 2
Training loss: 1.6951322555541992
Validation loss: 2.0935806781053543

Epoch: 5| Step: 3
Training loss: 2.379148006439209
Validation loss: 2.095960333943367

Epoch: 5| Step: 4
Training loss: 2.2136287689208984
Validation loss: 2.0805348257223764

Epoch: 5| Step: 5
Training loss: 1.7284505367279053
Validation loss: 2.070687880118688

Epoch: 5| Step: 6
Training loss: 2.0540060997009277
Validation loss: 2.0747985194126763

Epoch: 5| Step: 7
Training loss: 2.0513710975646973
Validation loss: 2.069633091489474

Epoch: 5| Step: 8
Training loss: 2.4100100994110107
Validation loss: 2.0813417583703995

Epoch: 5| Step: 9
Training loss: 1.8309571743011475
Validation loss: 2.0744437674681344

Epoch: 5| Step: 10
Training loss: 1.6513535976409912
Validation loss: 2.082551583647728

Epoch: 5| Step: 11
Training loss: 1.353507399559021
Validation loss: 2.0778981099526086

Epoch: 189| Step: 0
Training loss: 1.667520523071289
Validation loss: 2.0715602884689965

Epoch: 5| Step: 1
Training loss: 1.9438674449920654
Validation loss: 2.0835474332173667

Epoch: 5| Step: 2
Training loss: 1.5712823867797852
Validation loss: 2.0955252846082053

Epoch: 5| Step: 3
Training loss: 2.19266414642334
Validation loss: 2.1095312535762787

Epoch: 5| Step: 4
Training loss: 1.9001643657684326
Validation loss: 2.1087117344141006

Epoch: 5| Step: 5
Training loss: 2.6777355670928955
Validation loss: 2.096890618403753

Epoch: 5| Step: 6
Training loss: 1.8061854839324951
Validation loss: 2.091079905629158

Epoch: 5| Step: 7
Training loss: 2.2001137733459473
Validation loss: 2.113817483186722

Epoch: 5| Step: 8
Training loss: 2.087798595428467
Validation loss: 2.1027003874381385

Epoch: 5| Step: 9
Training loss: 2.219818115234375
Validation loss: 2.0822564413150153

Epoch: 5| Step: 10
Training loss: 1.7039188146591187
Validation loss: 2.0902959058682122

Epoch: 5| Step: 11
Training loss: 2.9464478492736816
Validation loss: 2.087125927209854

Epoch: 190| Step: 0
Training loss: 2.6525750160217285
Validation loss: 2.069619506597519

Epoch: 5| Step: 1
Training loss: 2.354543685913086
Validation loss: 2.063748816649119

Epoch: 5| Step: 2
Training loss: 1.840850591659546
Validation loss: 2.049145589272181

Epoch: 5| Step: 3
Training loss: 1.972214698791504
Validation loss: 2.0375142892201743

Epoch: 5| Step: 4
Training loss: 2.1966946125030518
Validation loss: 2.0504804899295173

Epoch: 5| Step: 5
Training loss: 1.942314863204956
Validation loss: 2.054050847887993

Epoch: 5| Step: 6
Training loss: 2.0691351890563965
Validation loss: 2.0563058803478875

Epoch: 5| Step: 7
Training loss: 1.829202651977539
Validation loss: 2.0587060352166495

Epoch: 5| Step: 8
Training loss: 2.0740928649902344
Validation loss: 2.0572374065717063

Epoch: 5| Step: 9
Training loss: 2.0885279178619385
Validation loss: 2.055111293991407

Epoch: 5| Step: 10
Training loss: 2.2411558628082275
Validation loss: 2.064776440461477

Epoch: 5| Step: 11
Training loss: 0.9127706289291382
Validation loss: 2.055773804585139

Epoch: 191| Step: 0
Training loss: 1.7200864553451538
Validation loss: 2.0619041323661804

Epoch: 5| Step: 1
Training loss: 1.4430615901947021
Validation loss: 2.059046591321627

Epoch: 5| Step: 2
Training loss: 2.0560085773468018
Validation loss: 2.075866108139356

Epoch: 5| Step: 3
Training loss: 2.212529182434082
Validation loss: 2.07883757352829

Epoch: 5| Step: 4
Training loss: 2.3816401958465576
Validation loss: 2.0678935199975967

Epoch: 5| Step: 5
Training loss: 2.0707688331604004
Validation loss: 2.063704237341881

Epoch: 5| Step: 6
Training loss: 2.2024693489074707
Validation loss: 2.049225995937983

Epoch: 5| Step: 7
Training loss: 1.6312745809555054
Validation loss: 2.045183757940928

Epoch: 5| Step: 8
Training loss: 2.084102153778076
Validation loss: 2.04446146885554

Epoch: 5| Step: 9
Training loss: 2.2326414585113525
Validation loss: 2.0456741700569787

Epoch: 5| Step: 10
Training loss: 2.30385160446167
Validation loss: 2.0584561228752136

Epoch: 5| Step: 11
Training loss: 2.161841869354248
Validation loss: 2.0514180809259415

Epoch: 192| Step: 0
Training loss: 1.8050512075424194
Validation loss: 2.079202115535736

Epoch: 5| Step: 1
Training loss: 1.942909598350525
Validation loss: 2.0791408916314444

Epoch: 5| Step: 2
Training loss: 2.149977922439575
Validation loss: 2.0854275623957315

Epoch: 5| Step: 3
Training loss: 2.103070020675659
Validation loss: 2.083910738428434

Epoch: 5| Step: 4
Training loss: 2.051316499710083
Validation loss: 2.120947023232778

Epoch: 5| Step: 5
Training loss: 2.4694721698760986
Validation loss: 2.102733020981153

Epoch: 5| Step: 6
Training loss: 1.804714560508728
Validation loss: 2.091506535808245

Epoch: 5| Step: 7
Training loss: 1.6716110706329346
Validation loss: 2.071433812379837

Epoch: 5| Step: 8
Training loss: 1.7829068899154663
Validation loss: 2.0845577170451484

Epoch: 5| Step: 9
Training loss: 2.2814745903015137
Validation loss: 2.0739201456308365

Epoch: 5| Step: 10
Training loss: 2.182304859161377
Validation loss: 2.0639010022083917

Epoch: 5| Step: 11
Training loss: 2.5797359943389893
Validation loss: 2.066636552413305

Epoch: 193| Step: 0
Training loss: 2.2079954147338867
Validation loss: 2.061287745833397

Epoch: 5| Step: 1
Training loss: 2.3514504432678223
Validation loss: 2.0494974851608276

Epoch: 5| Step: 2
Training loss: 1.774818778038025
Validation loss: 2.051527957121531

Epoch: 5| Step: 3
Training loss: 1.6999237537384033
Validation loss: 2.0515686124563217

Epoch: 5| Step: 4
Training loss: 2.4335498809814453
Validation loss: 2.053906425833702

Epoch: 5| Step: 5
Training loss: 1.5165451765060425
Validation loss: 2.052894870440165

Epoch: 5| Step: 6
Training loss: 1.7719261646270752
Validation loss: 2.061153456568718

Epoch: 5| Step: 7
Training loss: 1.99789297580719
Validation loss: 2.058186506231626

Epoch: 5| Step: 8
Training loss: 1.8589404821395874
Validation loss: 2.0440906633933387

Epoch: 5| Step: 9
Training loss: 2.095226526260376
Validation loss: 2.060921236872673

Epoch: 5| Step: 10
Training loss: 2.244205951690674
Validation loss: 2.069522500038147

Epoch: 5| Step: 11
Training loss: 2.3582258224487305
Validation loss: 2.065090298652649

Epoch: 194| Step: 0
Training loss: 1.8935915231704712
Validation loss: 2.0907347997029624

Epoch: 5| Step: 1
Training loss: 1.8569328784942627
Validation loss: 2.0829441944758096

Epoch: 5| Step: 2
Training loss: 2.2592129707336426
Validation loss: 2.1002373745044074

Epoch: 5| Step: 3
Training loss: 2.344217300415039
Validation loss: 2.1109814196825027

Epoch: 5| Step: 4
Training loss: 2.5850677490234375
Validation loss: 2.1033964455127716

Epoch: 5| Step: 5
Training loss: 1.966692566871643
Validation loss: 2.136464605728785

Epoch: 5| Step: 6
Training loss: 2.0197811126708984
Validation loss: 2.127198447783788

Epoch: 5| Step: 7
Training loss: 2.528939962387085
Validation loss: 2.1298052916924157

Epoch: 5| Step: 8
Training loss: 1.6526553630828857
Validation loss: 2.107515017191569

Epoch: 5| Step: 9
Training loss: 1.6040992736816406
Validation loss: 2.0787939925988517

Epoch: 5| Step: 10
Training loss: 1.8823350667953491
Validation loss: 2.094744791587194

Epoch: 5| Step: 11
Training loss: 1.0601681470870972
Validation loss: 2.0836171905199685

Epoch: 195| Step: 0
Training loss: 1.846022367477417
Validation loss: 2.0832505375146866

Epoch: 5| Step: 1
Training loss: 1.6468931436538696
Validation loss: 2.085394208629926

Epoch: 5| Step: 2
Training loss: 2.1043453216552734
Validation loss: 2.076581915219625

Epoch: 5| Step: 3
Training loss: 1.8103854656219482
Validation loss: 2.0760746598243713

Epoch: 5| Step: 4
Training loss: 2.262139081954956
Validation loss: 2.075808654228846

Epoch: 5| Step: 5
Training loss: 1.9246461391448975
Validation loss: 2.0821715841690698

Epoch: 5| Step: 6
Training loss: 2.00119686126709
Validation loss: 2.0690705478191376

Epoch: 5| Step: 7
Training loss: 2.5387637615203857
Validation loss: 2.0841057797273

Epoch: 5| Step: 8
Training loss: 1.8387062549591064
Validation loss: 2.0778622726599374

Epoch: 5| Step: 9
Training loss: 2.3292460441589355
Validation loss: 2.0858867218097052

Epoch: 5| Step: 10
Training loss: 1.597070336341858
Validation loss: 2.087855910261472

Epoch: 5| Step: 11
Training loss: 2.283914566040039
Validation loss: 2.0853881736596427

Epoch: 196| Step: 0
Training loss: 2.2235660552978516
Validation loss: 2.083954026301702

Epoch: 5| Step: 1
Training loss: 1.8243707418441772
Validation loss: 2.0741353084643683

Epoch: 5| Step: 2
Training loss: 1.8868697881698608
Validation loss: 2.076834132273992

Epoch: 5| Step: 3
Training loss: 2.0767829418182373
Validation loss: 2.0780857453743615

Epoch: 5| Step: 4
Training loss: 2.3550140857696533
Validation loss: 2.078599135080973

Epoch: 5| Step: 5
Training loss: 2.0158982276916504
Validation loss: 2.0789750069379807

Epoch: 5| Step: 6
Training loss: 1.8342424631118774
Validation loss: 2.083580548564593

Epoch: 5| Step: 7
Training loss: 1.712895154953003
Validation loss: 2.0817209581534066

Epoch: 5| Step: 8
Training loss: 2.0804455280303955
Validation loss: 2.084411919116974

Epoch: 5| Step: 9
Training loss: 1.9326403141021729
Validation loss: 2.0914261986811957

Epoch: 5| Step: 10
Training loss: 1.763003945350647
Validation loss: 2.091602991024653

Epoch: 5| Step: 11
Training loss: 1.8591201305389404
Validation loss: 2.0844312061866126

Epoch: 197| Step: 0
Training loss: 1.7748119831085205
Validation loss: 2.0956458846728006

Epoch: 5| Step: 1
Training loss: 2.2647087574005127
Validation loss: 2.0729615290959678

Epoch: 5| Step: 2
Training loss: 2.1314921379089355
Validation loss: 2.097270687421163

Epoch: 5| Step: 3
Training loss: 1.495400309562683
Validation loss: 2.091651404897372

Epoch: 5| Step: 4
Training loss: 1.7418577671051025
Validation loss: 2.092024321357409

Epoch: 5| Step: 5
Training loss: 2.4012725353240967
Validation loss: 2.0914966563383737

Epoch: 5| Step: 6
Training loss: 1.8729312419891357
Validation loss: 2.092615077892939

Epoch: 5| Step: 7
Training loss: 2.262277364730835
Validation loss: 2.096930220723152

Epoch: 5| Step: 8
Training loss: 1.650904655456543
Validation loss: 2.089112639427185

Epoch: 5| Step: 9
Training loss: 1.8624427318572998
Validation loss: 2.095986862977346

Epoch: 5| Step: 10
Training loss: 1.9752368927001953
Validation loss: 2.0885307987531028

Epoch: 5| Step: 11
Training loss: 2.642578601837158
Validation loss: 2.0986106197039285

Epoch: 198| Step: 0
Training loss: 2.111072063446045
Validation loss: 2.091894586881002

Epoch: 5| Step: 1
Training loss: 2.0809736251831055
Validation loss: 2.0884997149308524

Epoch: 5| Step: 2
Training loss: 1.485796332359314
Validation loss: 2.0778848032156625

Epoch: 5| Step: 3
Training loss: 1.6565797328948975
Validation loss: 2.0888503392537436

Epoch: 5| Step: 4
Training loss: 2.19245982170105
Validation loss: 2.083701958258947

Epoch: 5| Step: 5
Training loss: 2.755624294281006
Validation loss: 2.0874990671873093

Epoch: 5| Step: 6
Training loss: 1.8835089206695557
Validation loss: 2.0882384876410165

Epoch: 5| Step: 7
Training loss: 1.8684037923812866
Validation loss: 2.085144340991974

Epoch: 5| Step: 8
Training loss: 1.8365888595581055
Validation loss: 2.08507709701856

Epoch: 5| Step: 9
Training loss: 1.8222204446792603
Validation loss: 2.0963590492804847

Epoch: 5| Step: 10
Training loss: 1.779844045639038
Validation loss: 2.102740600705147

Epoch: 5| Step: 11
Training loss: 2.2535791397094727
Validation loss: 2.113016108671824

Epoch: 199| Step: 0
Training loss: 2.196826219558716
Validation loss: 2.1193029632170997

Epoch: 5| Step: 1
Training loss: 1.8457276821136475
Validation loss: 2.130941172440847

Epoch: 5| Step: 2
Training loss: 2.5117945671081543
Validation loss: 2.148414899905523

Epoch: 5| Step: 3
Training loss: 2.1846139430999756
Validation loss: 2.144663160045942

Epoch: 5| Step: 4
Training loss: 1.7384417057037354
Validation loss: 2.1393769681453705

Epoch: 5| Step: 5
Training loss: 1.686437964439392
Validation loss: 2.130200078090032

Epoch: 5| Step: 6
Training loss: 2.0804686546325684
Validation loss: 2.122444753845533

Epoch: 5| Step: 7
Training loss: 2.2387709617614746
Validation loss: 2.1023797492186227

Epoch: 5| Step: 8
Training loss: 1.9925518035888672
Validation loss: 2.0904406309127808

Epoch: 5| Step: 9
Training loss: 1.9778211116790771
Validation loss: 2.056917503476143

Epoch: 5| Step: 10
Training loss: 2.1252145767211914
Validation loss: 2.042312577366829

Epoch: 5| Step: 11
Training loss: 1.5605098009109497
Validation loss: 2.041470686594645

Epoch: 200| Step: 0
Training loss: 2.1680922508239746
Validation loss: 2.0426248560349145

Epoch: 5| Step: 1
Training loss: 1.9824978113174438
Validation loss: 2.0307692339022956

Epoch: 5| Step: 2
Training loss: 1.5374689102172852
Validation loss: 2.0470304687817893

Epoch: 5| Step: 3
Training loss: 2.2829127311706543
Validation loss: 2.0453110734621682

Epoch: 5| Step: 4
Training loss: 2.0597338676452637
Validation loss: 2.0451767345269523

Epoch: 5| Step: 5
Training loss: 1.9869998693466187
Validation loss: 2.047945494453112

Epoch: 5| Step: 6
Training loss: 1.8736215829849243
Validation loss: 2.048475210865339

Epoch: 5| Step: 7
Training loss: 2.055408000946045
Validation loss: 2.0383650908867517

Epoch: 5| Step: 8
Training loss: 2.3536605834960938
Validation loss: 2.0399383703867593

Epoch: 5| Step: 9
Training loss: 1.7043514251708984
Validation loss: 2.04872989654541

Epoch: 5| Step: 10
Training loss: 1.977790117263794
Validation loss: 2.0326356341441474

Epoch: 5| Step: 11
Training loss: 2.6926465034484863
Validation loss: 2.050653169552485

Epoch: 201| Step: 0
Training loss: 2.025019407272339
Validation loss: 2.064241280158361

Epoch: 5| Step: 1
Training loss: 1.9357693195343018
Validation loss: 2.056941037376722

Epoch: 5| Step: 2
Training loss: 1.6828027963638306
Validation loss: 2.058531035979589

Epoch: 5| Step: 3
Training loss: 1.9683395624160767
Validation loss: 2.0611671606699624

Epoch: 5| Step: 4
Training loss: 1.9146816730499268
Validation loss: 2.0708419730265937

Epoch: 5| Step: 5
Training loss: 1.8537571430206299
Validation loss: 2.054872676730156

Epoch: 5| Step: 6
Training loss: 1.5143682956695557
Validation loss: 2.068840965628624

Epoch: 5| Step: 7
Training loss: 1.8614189624786377
Validation loss: 2.066725050409635

Epoch: 5| Step: 8
Training loss: 2.4918811321258545
Validation loss: 2.069512829184532

Epoch: 5| Step: 9
Training loss: 2.312408685684204
Validation loss: 2.0754798551400504

Epoch: 5| Step: 10
Training loss: 2.1216881275177
Validation loss: 2.0754503856102624

Epoch: 5| Step: 11
Training loss: 1.77776038646698
Validation loss: 2.0753344545761743

Epoch: 202| Step: 0
Training loss: 1.9578707218170166
Validation loss: 2.076683188478152

Epoch: 5| Step: 1
Training loss: 1.67690110206604
Validation loss: 2.0666876832644143

Epoch: 5| Step: 2
Training loss: 1.9383652210235596
Validation loss: 2.0650634765625

Epoch: 5| Step: 3
Training loss: 2.812821865081787
Validation loss: 2.063674718141556

Epoch: 5| Step: 4
Training loss: 2.1431469917297363
Validation loss: 2.0697999745607376

Epoch: 5| Step: 5
Training loss: 2.34983229637146
Validation loss: 2.0641035785277686

Epoch: 5| Step: 6
Training loss: 2.0472235679626465
Validation loss: 2.080312122901281

Epoch: 5| Step: 7
Training loss: 1.6766302585601807
Validation loss: 2.0772947321335473

Epoch: 5| Step: 8
Training loss: 1.4312340021133423
Validation loss: 2.0675394535064697

Epoch: 5| Step: 9
Training loss: 2.009270429611206
Validation loss: 2.0701094220081964

Epoch: 5| Step: 10
Training loss: 1.8913469314575195
Validation loss: 2.068710600336393

Epoch: 5| Step: 11
Training loss: 2.4558849334716797
Validation loss: 2.0873767137527466

Epoch: 203| Step: 0
Training loss: 1.8980131149291992
Validation loss: 2.098834643761317

Epoch: 5| Step: 1
Training loss: 1.6947444677352905
Validation loss: 2.0994200309117637

Epoch: 5| Step: 2
Training loss: 2.1079859733581543
Validation loss: 2.0915748278299966

Epoch: 5| Step: 3
Training loss: 1.8635177612304688
Validation loss: 2.0963237086931863

Epoch: 5| Step: 4
Training loss: 1.691027045249939
Validation loss: 2.098825211326281

Epoch: 5| Step: 5
Training loss: 1.7983192205429077
Validation loss: 2.114482323328654

Epoch: 5| Step: 6
Training loss: 1.8107963800430298
Validation loss: 2.106785466273626

Epoch: 5| Step: 7
Training loss: 2.310533285140991
Validation loss: 2.0976638744274774

Epoch: 5| Step: 8
Training loss: 2.296891689300537
Validation loss: 2.099805916349093

Epoch: 5| Step: 9
Training loss: 2.042121171951294
Validation loss: 2.0840598295132318

Epoch: 5| Step: 10
Training loss: 1.994868278503418
Validation loss: 2.0812425265709558

Epoch: 5| Step: 11
Training loss: 1.8785030841827393
Validation loss: 2.086314837137858

Epoch: 204| Step: 0
Training loss: 1.5037990808486938
Validation loss: 2.0948381622632346

Epoch: 5| Step: 1
Training loss: 1.814562201499939
Validation loss: 2.0969382524490356

Epoch: 5| Step: 2
Training loss: 2.135427713394165
Validation loss: 2.0862657129764557

Epoch: 5| Step: 3
Training loss: 2.600572109222412
Validation loss: 2.069968049724897

Epoch: 5| Step: 4
Training loss: 1.7257534265518188
Validation loss: 2.0985497186581292

Epoch: 5| Step: 5
Training loss: 1.8790414333343506
Validation loss: 2.0944695323705673

Epoch: 5| Step: 6
Training loss: 1.8893251419067383
Validation loss: 2.101035326719284

Epoch: 5| Step: 7
Training loss: 1.8058650493621826
Validation loss: 2.109360699852308

Epoch: 5| Step: 8
Training loss: 2.2453906536102295
Validation loss: 2.111398031314214

Epoch: 5| Step: 9
Training loss: 1.8169910907745361
Validation loss: 2.11488605539004

Epoch: 5| Step: 10
Training loss: 2.043579339981079
Validation loss: 2.113002270460129

Epoch: 5| Step: 11
Training loss: 1.5931310653686523
Validation loss: 2.116356387734413

Epoch: 205| Step: 0
Training loss: 2.130141496658325
Validation loss: 2.12084469695886

Epoch: 5| Step: 1
Training loss: 1.7051289081573486
Validation loss: 2.108515371878942

Epoch: 5| Step: 2
Training loss: 1.6050317287445068
Validation loss: 2.108195369442304

Epoch: 5| Step: 3
Training loss: 1.5565249919891357
Validation loss: 2.1009611388047538

Epoch: 5| Step: 4
Training loss: 1.6043663024902344
Validation loss: 2.095773528019587

Epoch: 5| Step: 5
Training loss: 1.7858638763427734
Validation loss: 2.101140007376671

Epoch: 5| Step: 6
Training loss: 1.9789108037948608
Validation loss: 2.1008989959955215

Epoch: 5| Step: 7
Training loss: 2.0336999893188477
Validation loss: 2.088601976633072

Epoch: 5| Step: 8
Training loss: 2.701545476913452
Validation loss: 2.0937030762434006

Epoch: 5| Step: 9
Training loss: 1.8236783742904663
Validation loss: 2.1056925654411316

Epoch: 5| Step: 10
Training loss: 2.4175829887390137
Validation loss: 2.1144490440686545

Epoch: 5| Step: 11
Training loss: 2.21356201171875
Validation loss: 2.10983736316363

Epoch: 206| Step: 0
Training loss: 1.7722886800765991
Validation loss: 2.1014728248119354

Epoch: 5| Step: 1
Training loss: 1.644601821899414
Validation loss: 2.101047699650129

Epoch: 5| Step: 2
Training loss: 2.0925371646881104
Validation loss: 2.0984920412302017

Epoch: 5| Step: 3
Training loss: 1.915955901145935
Validation loss: 2.093853468696276

Epoch: 5| Step: 4
Training loss: 1.881777048110962
Validation loss: 2.0814260691404343

Epoch: 5| Step: 5
Training loss: 2.1095619201660156
Validation loss: 2.0977638363838196

Epoch: 5| Step: 6
Training loss: 1.9810035228729248
Validation loss: 2.0952942421038947

Epoch: 5| Step: 7
Training loss: 1.9564800262451172
Validation loss: 2.094871615370115

Epoch: 5| Step: 8
Training loss: 1.4794679880142212
Validation loss: 2.0867122461398444

Epoch: 5| Step: 9
Training loss: 1.7519108057022095
Validation loss: 2.077030817667643

Epoch: 5| Step: 10
Training loss: 2.832686185836792
Validation loss: 2.0994735658168793

Epoch: 5| Step: 11
Training loss: 2.2934179306030273
Validation loss: 2.092456211646398

Epoch: 207| Step: 0
Training loss: 1.7850574254989624
Validation loss: 2.0852078894774118

Epoch: 5| Step: 1
Training loss: 2.00472354888916
Validation loss: 2.095407118399938

Epoch: 5| Step: 2
Training loss: 1.7831199169158936
Validation loss: 2.0858461360136666

Epoch: 5| Step: 3
Training loss: 2.057910203933716
Validation loss: 2.1040912518898645

Epoch: 5| Step: 4
Training loss: 1.5222704410552979
Validation loss: 2.1110917131106057

Epoch: 5| Step: 5
Training loss: 1.6058956384658813
Validation loss: 2.1051162481307983

Epoch: 5| Step: 6
Training loss: 1.9479477405548096
Validation loss: 2.1055633276700974

Epoch: 5| Step: 7
Training loss: 1.8176887035369873
Validation loss: 2.1036677410205207

Epoch: 5| Step: 8
Training loss: 2.382441997528076
Validation loss: 2.1097454726696014

Epoch: 5| Step: 9
Training loss: 2.408252716064453
Validation loss: 2.1043263375759125

Epoch: 5| Step: 10
Training loss: 2.171616554260254
Validation loss: 2.1089297036329904

Epoch: 5| Step: 11
Training loss: 1.4201996326446533
Validation loss: 2.10776923596859

Epoch: 208| Step: 0
Training loss: 2.245183229446411
Validation loss: 2.107599914073944

Epoch: 5| Step: 1
Training loss: 2.1145167350769043
Validation loss: 2.1090723276138306

Epoch: 5| Step: 2
Training loss: 1.8768110275268555
Validation loss: 2.1169320394595466

Epoch: 5| Step: 3
Training loss: 1.8510240316390991
Validation loss: 2.1212813009818396

Epoch: 5| Step: 4
Training loss: 2.097064971923828
Validation loss: 2.1043894539276757

Epoch: 5| Step: 5
Training loss: 2.0027668476104736
Validation loss: 2.099432791272799

Epoch: 5| Step: 6
Training loss: 2.4359772205352783
Validation loss: 2.1129625837008157

Epoch: 5| Step: 7
Training loss: 1.7302383184432983
Validation loss: 2.1124201118946075

Epoch: 5| Step: 8
Training loss: 1.8634119033813477
Validation loss: 2.1132174034913382

Epoch: 5| Step: 9
Training loss: 1.5055797100067139
Validation loss: 2.1041387617588043

Epoch: 5| Step: 10
Training loss: 1.8239291906356812
Validation loss: 2.115273122986158

Epoch: 5| Step: 11
Training loss: 0.9140926599502563
Validation loss: 2.1162976225217185

Epoch: 209| Step: 0
Training loss: 1.9705612659454346
Validation loss: 2.0995726784070334

Epoch: 5| Step: 1
Training loss: 1.9898725748062134
Validation loss: 2.120032623410225

Epoch: 5| Step: 2
Training loss: 2.597921133041382
Validation loss: 2.107677007714907

Epoch: 5| Step: 3
Training loss: 2.204451084136963
Validation loss: 2.119702418645223

Epoch: 5| Step: 4
Training loss: 1.723554015159607
Validation loss: 2.1093353231747947

Epoch: 5| Step: 5
Training loss: 1.386702060699463
Validation loss: 2.1112371434768042

Epoch: 5| Step: 6
Training loss: 1.5349061489105225
Validation loss: 2.1120726267496743

Epoch: 5| Step: 7
Training loss: 2.2133781909942627
Validation loss: 2.1293148547410965

Epoch: 5| Step: 8
Training loss: 2.0947062969207764
Validation loss: 2.1258023927609124

Epoch: 5| Step: 9
Training loss: 2.1835756301879883
Validation loss: 2.1205253352721534

Epoch: 5| Step: 10
Training loss: 1.6351617574691772
Validation loss: 2.1160120765368142

Epoch: 5| Step: 11
Training loss: 1.6745035648345947
Validation loss: 2.1090368727842965

Epoch: 210| Step: 0
Training loss: 2.2881405353546143
Validation loss: 2.1104274789492288

Epoch: 5| Step: 1
Training loss: 1.74088454246521
Validation loss: 2.0918412655591965

Epoch: 5| Step: 2
Training loss: 1.6782722473144531
Validation loss: 2.0934162735939026

Epoch: 5| Step: 3
Training loss: 2.0319974422454834
Validation loss: 2.086066330472628

Epoch: 5| Step: 4
Training loss: 1.925134301185608
Validation loss: 2.089316541949908

Epoch: 5| Step: 5
Training loss: 1.7773950099945068
Validation loss: 2.0853544572989144

Epoch: 5| Step: 6
Training loss: 2.5067310333251953
Validation loss: 2.0776343643665314

Epoch: 5| Step: 7
Training loss: 2.2481656074523926
Validation loss: 2.0846918523311615

Epoch: 5| Step: 8
Training loss: 1.8919496536254883
Validation loss: 2.09374109407266

Epoch: 5| Step: 9
Training loss: 1.4709323644638062
Validation loss: 2.0962105790774026

Epoch: 5| Step: 10
Training loss: 1.875867486000061
Validation loss: 2.1026239693164825

Epoch: 5| Step: 11
Training loss: 1.4080147743225098
Validation loss: 2.1134296158949533

Epoch: 211| Step: 0
Training loss: 2.12441349029541
Validation loss: 2.1321189304192862

Epoch: 5| Step: 1
Training loss: 1.438145399093628
Validation loss: 2.1326834112405777

Epoch: 5| Step: 2
Training loss: 2.0488808155059814
Validation loss: 2.1163776417573295

Epoch: 5| Step: 3
Training loss: 2.209505796432495
Validation loss: 2.1327731758356094

Epoch: 5| Step: 4
Training loss: 2.0054502487182617
Validation loss: 2.1272258957227073

Epoch: 5| Step: 5
Training loss: 1.7010895013809204
Validation loss: 2.1245605647563934

Epoch: 5| Step: 6
Training loss: 1.8175389766693115
Validation loss: 2.110783169666926

Epoch: 5| Step: 7
Training loss: 1.9033117294311523
Validation loss: 2.098127782344818

Epoch: 5| Step: 8
Training loss: 2.6744232177734375
Validation loss: 2.100869059562683

Epoch: 5| Step: 9
Training loss: 1.8076308965682983
Validation loss: 2.1031922101974487

Epoch: 5| Step: 10
Training loss: 1.9439895153045654
Validation loss: 2.0973243017991385

Epoch: 5| Step: 11
Training loss: 1.1038239002227783
Validation loss: 2.086835592985153

Epoch: 212| Step: 0
Training loss: 1.900456190109253
Validation loss: 2.108160763978958

Epoch: 5| Step: 1
Training loss: 1.673617959022522
Validation loss: 2.0843490163485208

Epoch: 5| Step: 2
Training loss: 1.9727604389190674
Validation loss: 2.0779050836960473

Epoch: 5| Step: 3
Training loss: 1.8053522109985352
Validation loss: 2.1055485755205154

Epoch: 5| Step: 4
Training loss: 2.162391424179077
Validation loss: 2.0901148517926535

Epoch: 5| Step: 5
Training loss: 2.0641775131225586
Validation loss: 2.096105009317398

Epoch: 5| Step: 6
Training loss: 1.825621247291565
Validation loss: 2.0985679775476456

Epoch: 5| Step: 7
Training loss: 2.5790677070617676
Validation loss: 2.1136263062556586

Epoch: 5| Step: 8
Training loss: 2.0627613067626953
Validation loss: 2.113249570131302

Epoch: 5| Step: 9
Training loss: 1.3510271310806274
Validation loss: 2.109204133351644

Epoch: 5| Step: 10
Training loss: 2.080496311187744
Validation loss: 2.124032681186994

Epoch: 5| Step: 11
Training loss: 1.8668879270553589
Validation loss: 2.117933372656504

Epoch: 213| Step: 0
Training loss: 1.5068328380584717
Validation loss: 2.1181338330109916

Epoch: 5| Step: 1
Training loss: 1.416138768196106
Validation loss: 2.1151066223780313

Epoch: 5| Step: 2
Training loss: 2.2368321418762207
Validation loss: 2.1074445247650146

Epoch: 5| Step: 3
Training loss: 1.6739137172698975
Validation loss: 2.116906409462293

Epoch: 5| Step: 4
Training loss: 1.6190273761749268
Validation loss: 2.1314527293046317

Epoch: 5| Step: 5
Training loss: 1.5702524185180664
Validation loss: 2.127875799934069

Epoch: 5| Step: 6
Training loss: 1.9732080698013306
Validation loss: 2.129405051469803

Epoch: 5| Step: 7
Training loss: 2.3638293743133545
Validation loss: 2.133891994754473

Epoch: 5| Step: 8
Training loss: 2.139616012573242
Validation loss: 2.124495347340902

Epoch: 5| Step: 9
Training loss: 2.378080368041992
Validation loss: 2.131518622239431

Epoch: 5| Step: 10
Training loss: 1.7754020690917969
Validation loss: 2.121808424592018

Epoch: 5| Step: 11
Training loss: 3.702251434326172
Validation loss: 2.116005018353462

Epoch: 214| Step: 0
Training loss: 2.403341770172119
Validation loss: 2.1138270099957785

Epoch: 5| Step: 1
Training loss: 2.1199517250061035
Validation loss: 2.117343162496885

Epoch: 5| Step: 2
Training loss: 1.3152077198028564
Validation loss: 2.109857286016146

Epoch: 5| Step: 3
Training loss: 1.9664537906646729
Validation loss: 2.118889739116033

Epoch: 5| Step: 4
Training loss: 1.9097251892089844
Validation loss: 2.099640135963758

Epoch: 5| Step: 5
Training loss: 1.56380295753479
Validation loss: 2.106321190794309

Epoch: 5| Step: 6
Training loss: 2.2454655170440674
Validation loss: 2.1165879170099893

Epoch: 5| Step: 7
Training loss: 2.4626688957214355
Validation loss: 2.118837629755338

Epoch: 5| Step: 8
Training loss: 1.602726697921753
Validation loss: 2.119485378265381

Epoch: 5| Step: 9
Training loss: 1.6777334213256836
Validation loss: 2.128075515230497

Epoch: 5| Step: 10
Training loss: 1.9074957370758057
Validation loss: 2.124483029047648

Epoch: 5| Step: 11
Training loss: 1.8288439512252808
Validation loss: 2.1350495368242264

Epoch: 215| Step: 0
Training loss: 2.0956287384033203
Validation loss: 2.105162630478541

Epoch: 5| Step: 1
Training loss: 1.9851478338241577
Validation loss: 2.124481350183487

Epoch: 5| Step: 2
Training loss: 1.8108861446380615
Validation loss: 2.1166635056336722

Epoch: 5| Step: 3
Training loss: 1.7853639125823975
Validation loss: 2.118965675433477

Epoch: 5| Step: 4
Training loss: 2.146728515625
Validation loss: 2.109365234772364

Epoch: 5| Step: 5
Training loss: 1.608824372291565
Validation loss: 2.1183830996354422

Epoch: 5| Step: 6
Training loss: 1.941796064376831
Validation loss: 2.1185705264409385

Epoch: 5| Step: 7
Training loss: 1.6091045141220093
Validation loss: 2.1232258677482605

Epoch: 5| Step: 8
Training loss: 2.235069513320923
Validation loss: 2.129693994919459

Epoch: 5| Step: 9
Training loss: 1.8687785863876343
Validation loss: 2.1327265898386636

Epoch: 5| Step: 10
Training loss: 2.0652060508728027
Validation loss: 2.1257563134034476

Epoch: 5| Step: 11
Training loss: 2.0034289360046387
Validation loss: 2.1112139771382012

Epoch: 216| Step: 0
Training loss: 1.9425455331802368
Validation loss: 2.119265392422676

Epoch: 5| Step: 1
Training loss: 1.682781457901001
Validation loss: 2.109998434782028

Epoch: 5| Step: 2
Training loss: 1.8969818353652954
Validation loss: 2.115185553828875

Epoch: 5| Step: 3
Training loss: 2.1599502563476562
Validation loss: 2.116141527891159

Epoch: 5| Step: 4
Training loss: 1.776898980140686
Validation loss: 2.1121323754390082

Epoch: 5| Step: 5
Training loss: 1.6987491846084595
Validation loss: 2.1079983711242676

Epoch: 5| Step: 6
Training loss: 1.9428762197494507
Validation loss: 2.1134921411673226

Epoch: 5| Step: 7
Training loss: 2.1919541358947754
Validation loss: 2.1126059939463935

Epoch: 5| Step: 8
Training loss: 2.4044291973114014
Validation loss: 2.1158104240894318

Epoch: 5| Step: 9
Training loss: 1.4385896921157837
Validation loss: 2.101775959134102

Epoch: 5| Step: 10
Training loss: 2.0133206844329834
Validation loss: 2.109558343887329

Epoch: 5| Step: 11
Training loss: 2.171710729598999
Validation loss: 2.1159499188264212

Epoch: 217| Step: 0
Training loss: 2.383875608444214
Validation loss: 2.120764916141828

Epoch: 5| Step: 1
Training loss: 1.4783351421356201
Validation loss: 2.109130988518397

Epoch: 5| Step: 2
Training loss: 2.187563419342041
Validation loss: 2.12277752161026

Epoch: 5| Step: 3
Training loss: 2.0006868839263916
Validation loss: 2.119922305146853

Epoch: 5| Step: 4
Training loss: 1.6975141763687134
Validation loss: 2.123268331090609

Epoch: 5| Step: 5
Training loss: 1.2780355215072632
Validation loss: 2.1174645721912384

Epoch: 5| Step: 6
Training loss: 1.8848098516464233
Validation loss: 2.112045327822367

Epoch: 5| Step: 7
Training loss: 2.431492328643799
Validation loss: 2.1264150391022363

Epoch: 5| Step: 8
Training loss: 2.1374850273132324
Validation loss: 2.1163331270217896

Epoch: 5| Step: 9
Training loss: 1.6627235412597656
Validation loss: 2.134371886650721

Epoch: 5| Step: 10
Training loss: 1.868909239768982
Validation loss: 2.1256939669450126

Epoch: 5| Step: 11
Training loss: 1.889970064163208
Validation loss: 2.125979761282603

Epoch: 218| Step: 0
Training loss: 1.4415831565856934
Validation loss: 2.1184790631135306

Epoch: 5| Step: 1
Training loss: 2.3437118530273438
Validation loss: 2.11889711022377

Epoch: 5| Step: 2
Training loss: 1.5738807916641235
Validation loss: 2.11520583430926

Epoch: 5| Step: 3
Training loss: 1.647403359413147
Validation loss: 2.1261620223522186

Epoch: 5| Step: 4
Training loss: 1.1831823587417603
Validation loss: 2.1372296710809073

Epoch: 5| Step: 5
Training loss: 2.1543264389038086
Validation loss: 2.1253814498583474

Epoch: 5| Step: 6
Training loss: 2.08760404586792
Validation loss: 2.118226374189059

Epoch: 5| Step: 7
Training loss: 2.1322238445281982
Validation loss: 2.1087156434853873

Epoch: 5| Step: 8
Training loss: 1.8478775024414062
Validation loss: 2.129117891192436

Epoch: 5| Step: 9
Training loss: 1.9154951572418213
Validation loss: 2.115447700023651

Epoch: 5| Step: 10
Training loss: 2.5288443565368652
Validation loss: 2.1216873874266944

Epoch: 5| Step: 11
Training loss: 2.059347629547119
Validation loss: 2.103786071141561

Epoch: 219| Step: 0
Training loss: 1.7617400884628296
Validation loss: 2.121156429251035

Epoch: 5| Step: 1
Training loss: 1.8349330425262451
Validation loss: 2.1173568864663443

Epoch: 5| Step: 2
Training loss: 2.202075242996216
Validation loss: 2.135523349046707

Epoch: 5| Step: 3
Training loss: 2.0076651573181152
Validation loss: 2.1410139401753745

Epoch: 5| Step: 4
Training loss: 1.8232109546661377
Validation loss: 2.136311103900274

Epoch: 5| Step: 5
Training loss: 1.7869240045547485
Validation loss: 2.1526977171500525

Epoch: 5| Step: 6
Training loss: 2.0789759159088135
Validation loss: 2.141597956418991

Epoch: 5| Step: 7
Training loss: 1.9442209005355835
Validation loss: 2.1258709530035653

Epoch: 5| Step: 8
Training loss: 2.0046021938323975
Validation loss: 2.1215411126613617

Epoch: 5| Step: 9
Training loss: 1.9485712051391602
Validation loss: 2.1419876515865326

Epoch: 5| Step: 10
Training loss: 1.7657215595245361
Validation loss: 2.14418825507164

Epoch: 5| Step: 11
Training loss: 1.8035004138946533
Validation loss: 2.132968376080195

Epoch: 220| Step: 0
Training loss: 2.284348249435425
Validation loss: 2.159882644812266

Epoch: 5| Step: 1
Training loss: 2.61215877532959
Validation loss: 2.1325923949480057

Epoch: 5| Step: 2
Training loss: 2.021869421005249
Validation loss: 2.1318960090478263

Epoch: 5| Step: 3
Training loss: 2.256265640258789
Validation loss: 2.125657707452774

Epoch: 5| Step: 4
Training loss: 1.5897047519683838
Validation loss: 2.1373237123092017

Epoch: 5| Step: 5
Training loss: 1.4290649890899658
Validation loss: 2.1271932323773703

Epoch: 5| Step: 6
Training loss: 2.0148491859436035
Validation loss: 2.146065284808477

Epoch: 5| Step: 7
Training loss: 1.4680086374282837
Validation loss: 2.132726122935613

Epoch: 5| Step: 8
Training loss: 2.3532018661499023
Validation loss: 2.1260788341363273

Epoch: 5| Step: 9
Training loss: 1.4040998220443726
Validation loss: 2.13455996910731

Epoch: 5| Step: 10
Training loss: 1.707119345664978
Validation loss: 2.1200444946686425

Epoch: 5| Step: 11
Training loss: 1.5016790628433228
Validation loss: 2.128945787747701

Epoch: 221| Step: 0
Training loss: 1.8366117477416992
Validation loss: 2.1279523322979608

Epoch: 5| Step: 1
Training loss: 1.777990698814392
Validation loss: 2.1167209297418594

Epoch: 5| Step: 2
Training loss: 1.6346505880355835
Validation loss: 2.128816137711207

Epoch: 5| Step: 3
Training loss: 1.994195580482483
Validation loss: 2.1307077457507453

Epoch: 5| Step: 4
Training loss: 2.5702884197235107
Validation loss: 2.120358814795812

Epoch: 5| Step: 5
Training loss: 1.5304431915283203
Validation loss: 2.124531482656797

Epoch: 5| Step: 6
Training loss: 2.175772190093994
Validation loss: 2.128477836648623

Epoch: 5| Step: 7
Training loss: 1.4825828075408936
Validation loss: 2.116836041212082

Epoch: 5| Step: 8
Training loss: 2.1465988159179688
Validation loss: 2.128708447019259

Epoch: 5| Step: 9
Training loss: 2.267320394515991
Validation loss: 2.1243871549765267

Epoch: 5| Step: 10
Training loss: 1.6492063999176025
Validation loss: 2.1200523376464844

Epoch: 5| Step: 11
Training loss: 2.385678768157959
Validation loss: 2.1092946430047355

Epoch: 222| Step: 0
Training loss: 1.6941114664077759
Validation loss: 2.129452039798101

Epoch: 5| Step: 1
Training loss: 2.197967529296875
Validation loss: 2.130531296133995

Epoch: 5| Step: 2
Training loss: 2.248643398284912
Validation loss: 2.146333023905754

Epoch: 5| Step: 3
Training loss: 2.116431713104248
Validation loss: 2.1403569132089615

Epoch: 5| Step: 4
Training loss: 1.7974350452423096
Validation loss: 2.1479705621798835

Epoch: 5| Step: 5
Training loss: 1.9083375930786133
Validation loss: 2.1534579743941626

Epoch: 5| Step: 6
Training loss: 1.2237145900726318
Validation loss: 2.1524664014577866

Epoch: 5| Step: 7
Training loss: 1.3396801948547363
Validation loss: 2.1437020897865295

Epoch: 5| Step: 8
Training loss: 2.163154125213623
Validation loss: 2.1492812087138495

Epoch: 5| Step: 9
Training loss: 2.3306756019592285
Validation loss: 2.138868898153305

Epoch: 5| Step: 10
Training loss: 2.233250856399536
Validation loss: 2.156083216269811

Epoch: 5| Step: 11
Training loss: 1.0962696075439453
Validation loss: 2.1406696339448295

Epoch: 223| Step: 0
Training loss: 2.073197364807129
Validation loss: 2.1283203760782876

Epoch: 5| Step: 1
Training loss: 2.3388962745666504
Validation loss: 2.128674258788427

Epoch: 5| Step: 2
Training loss: 2.2599422931671143
Validation loss: 2.1265647957722345

Epoch: 5| Step: 3
Training loss: 1.762500524520874
Validation loss: 2.1265519758065543

Epoch: 5| Step: 4
Training loss: 1.631974458694458
Validation loss: 2.1124016841252646

Epoch: 5| Step: 5
Training loss: 1.4645185470581055
Validation loss: 2.1269026398658752

Epoch: 5| Step: 6
Training loss: 1.9703242778778076
Validation loss: 2.1227147032817206

Epoch: 5| Step: 7
Training loss: 1.6288011074066162
Validation loss: 2.125557005405426

Epoch: 5| Step: 8
Training loss: 1.976599931716919
Validation loss: 2.1227691570917764

Epoch: 5| Step: 9
Training loss: 1.732839822769165
Validation loss: 2.129955197374026

Epoch: 5| Step: 10
Training loss: 2.012763738632202
Validation loss: 2.1276087562243142

Epoch: 5| Step: 11
Training loss: 2.2796356678009033
Validation loss: 2.144704441229502

Epoch: 224| Step: 0
Training loss: 1.930202841758728
Validation loss: 2.1409388184547424

Epoch: 5| Step: 1
Training loss: 2.1222262382507324
Validation loss: 2.1382800936698914

Epoch: 5| Step: 2
Training loss: 1.3836431503295898
Validation loss: 2.1299508462349572

Epoch: 5| Step: 3
Training loss: 1.2136170864105225
Validation loss: 2.127986341714859

Epoch: 5| Step: 4
Training loss: 1.760785698890686
Validation loss: 2.1185560723145804

Epoch: 5| Step: 5
Training loss: 2.1675498485565186
Validation loss: 2.130814532438914

Epoch: 5| Step: 6
Training loss: 2.0253846645355225
Validation loss: 2.1309762547413507

Epoch: 5| Step: 7
Training loss: 2.101820468902588
Validation loss: 2.127494916319847

Epoch: 5| Step: 8
Training loss: 2.0797603130340576
Validation loss: 2.1078347663084664

Epoch: 5| Step: 9
Training loss: 2.170895576477051
Validation loss: 2.12362872560819

Epoch: 5| Step: 10
Training loss: 1.7260339260101318
Validation loss: 2.1127385596434274

Epoch: 5| Step: 11
Training loss: 3.294499158859253
Validation loss: 2.1171299666166306

Epoch: 225| Step: 0
Training loss: 1.408095121383667
Validation loss: 2.119163438677788

Epoch: 5| Step: 1
Training loss: 1.407598853111267
Validation loss: 2.132909814516703

Epoch: 5| Step: 2
Training loss: 1.4813172817230225
Validation loss: 2.1230892539024353

Epoch: 5| Step: 3
Training loss: 1.9250094890594482
Validation loss: 2.112684413790703

Epoch: 5| Step: 4
Training loss: 1.92532217502594
Validation loss: 2.1307091464598975

Epoch: 5| Step: 5
Training loss: 1.6892509460449219
Validation loss: 2.1018156905968985

Epoch: 5| Step: 6
Training loss: 2.3288638591766357
Validation loss: 2.0986033380031586

Epoch: 5| Step: 7
Training loss: 2.533982515335083
Validation loss: 2.113203078508377

Epoch: 5| Step: 8
Training loss: 1.7402832508087158
Validation loss: 2.1056221773227057

Epoch: 5| Step: 9
Training loss: 2.195505142211914
Validation loss: 2.1053062280019126

Epoch: 5| Step: 10
Training loss: 2.2598013877868652
Validation loss: 2.1049125840266547

Epoch: 5| Step: 11
Training loss: 2.282102584838867
Validation loss: 2.109447638193766

Epoch: 226| Step: 0
Training loss: 1.972994089126587
Validation loss: 2.115927040576935

Epoch: 5| Step: 1
Training loss: 2.0836474895477295
Validation loss: 2.1112899432579675

Epoch: 5| Step: 2
Training loss: 1.6679481267929077
Validation loss: 2.1090234418710074

Epoch: 5| Step: 3
Training loss: 2.0661463737487793
Validation loss: 2.1194137185811996

Epoch: 5| Step: 4
Training loss: 1.3183414936065674
Validation loss: 2.12956495086352

Epoch: 5| Step: 5
Training loss: 2.186056137084961
Validation loss: 2.130621070663134

Epoch: 5| Step: 6
Training loss: 1.630470633506775
Validation loss: 2.144501010576884

Epoch: 5| Step: 7
Training loss: 1.9701703786849976
Validation loss: 2.14810677866141

Epoch: 5| Step: 8
Training loss: 2.154236316680908
Validation loss: 2.136404260993004

Epoch: 5| Step: 9
Training loss: 2.0091423988342285
Validation loss: 2.135943502187729

Epoch: 5| Step: 10
Training loss: 2.0911707878112793
Validation loss: 2.1467164953549704

Epoch: 5| Step: 11
Training loss: 0.6293344497680664
Validation loss: 2.1432357877492905

Epoch: 227| Step: 0
Training loss: 2.777214288711548
Validation loss: 2.150193159778913

Epoch: 5| Step: 1
Training loss: 1.9579893350601196
Validation loss: 2.1416631837685904

Epoch: 5| Step: 2
Training loss: 1.9395681619644165
Validation loss: 2.1370901266733804

Epoch: 5| Step: 3
Training loss: 2.0372040271759033
Validation loss: 2.130028784275055

Epoch: 5| Step: 4
Training loss: 1.7563650608062744
Validation loss: 2.1433785458405814

Epoch: 5| Step: 5
Training loss: 1.7662887573242188
Validation loss: 2.1329146524270377

Epoch: 5| Step: 6
Training loss: 1.8614078760147095
Validation loss: 2.132566958665848

Epoch: 5| Step: 7
Training loss: 1.3341495990753174
Validation loss: 2.1116591344277063

Epoch: 5| Step: 8
Training loss: 1.676812767982483
Validation loss: 2.10050405561924

Epoch: 5| Step: 9
Training loss: 2.2118725776672363
Validation loss: 2.1140467723210654

Epoch: 5| Step: 10
Training loss: 1.6350138187408447
Validation loss: 2.1074281185865402

Epoch: 5| Step: 11
Training loss: 1.805268406867981
Validation loss: 2.111056571205457

Epoch: 228| Step: 0
Training loss: 1.1672592163085938
Validation loss: 2.1253204196691513

Epoch: 5| Step: 1
Training loss: 1.9865038394927979
Validation loss: 2.1148310403029122

Epoch: 5| Step: 2
Training loss: 1.494196891784668
Validation loss: 2.125931590795517

Epoch: 5| Step: 3
Training loss: 1.8033565282821655
Validation loss: 2.1362164914608

Epoch: 5| Step: 4
Training loss: 1.4422671794891357
Validation loss: 2.1255823572476706

Epoch: 5| Step: 5
Training loss: 2.5843758583068848
Validation loss: 2.124668851494789

Epoch: 5| Step: 6
Training loss: 2.2216601371765137
Validation loss: 2.126171052455902

Epoch: 5| Step: 7
Training loss: 2.2716636657714844
Validation loss: 2.1358588288227716

Epoch: 5| Step: 8
Training loss: 1.8522710800170898
Validation loss: 2.1505002776781716

Epoch: 5| Step: 9
Training loss: 1.9729125499725342
Validation loss: 2.134780153632164

Epoch: 5| Step: 10
Training loss: 2.143092155456543
Validation loss: 2.130987599492073

Epoch: 5| Step: 11
Training loss: 1.3929169178009033
Validation loss: 2.1236261427402496

Epoch: 229| Step: 0
Training loss: 1.5665088891983032
Validation loss: 2.1333256314198175

Epoch: 5| Step: 1
Training loss: 2.18422269821167
Validation loss: 2.125533401966095

Epoch: 5| Step: 2
Training loss: 1.832640290260315
Validation loss: 2.1368092646201453

Epoch: 5| Step: 3
Training loss: 2.7149405479431152
Validation loss: 2.137198716402054

Epoch: 5| Step: 4
Training loss: 2.234025478363037
Validation loss: 2.146643246213595

Epoch: 5| Step: 5
Training loss: 1.6015520095825195
Validation loss: 2.1450045853853226

Epoch: 5| Step: 6
Training loss: 1.3208860158920288
Validation loss: 2.149641737341881

Epoch: 5| Step: 7
Training loss: 2.0381321907043457
Validation loss: 2.1327492942412696

Epoch: 5| Step: 8
Training loss: 1.3741037845611572
Validation loss: 2.1364355981349945

Epoch: 5| Step: 9
Training loss: 2.254967212677002
Validation loss: 2.136434664328893

Epoch: 5| Step: 10
Training loss: 1.5593650341033936
Validation loss: 2.1221416890621185

Epoch: 5| Step: 11
Training loss: 1.6437489986419678
Validation loss: 2.141841858625412

Epoch: 230| Step: 0
Training loss: 2.0959415435791016
Validation loss: 2.119604046146075

Epoch: 5| Step: 1
Training loss: 1.8906141519546509
Validation loss: 2.128059675296148

Epoch: 5| Step: 2
Training loss: 1.6132519245147705
Validation loss: 2.109613999724388

Epoch: 5| Step: 3
Training loss: 2.0769760608673096
Validation loss: 2.1212256054083505

Epoch: 5| Step: 4
Training loss: 1.5136725902557373
Validation loss: 2.1175352285305657

Epoch: 5| Step: 5
Training loss: 1.5611810684204102
Validation loss: 2.1300007154544196

Epoch: 5| Step: 6
Training loss: 1.9559673070907593
Validation loss: 2.1290595630804696

Epoch: 5| Step: 7
Training loss: 2.496664047241211
Validation loss: 2.1420947213967643

Epoch: 5| Step: 8
Training loss: 1.7429332733154297
Validation loss: 2.119433671236038

Epoch: 5| Step: 9
Training loss: 2.05613374710083
Validation loss: 2.114212950070699

Epoch: 5| Step: 10
Training loss: 1.9869558811187744
Validation loss: 2.131640776991844

Epoch: 5| Step: 11
Training loss: 0.864324152469635
Validation loss: 2.135109633207321

Epoch: 231| Step: 0
Training loss: 2.0249714851379395
Validation loss: 2.142662932475408

Epoch: 5| Step: 1
Training loss: 2.4646148681640625
Validation loss: 2.1337694923082986

Epoch: 5| Step: 2
Training loss: 2.070443868637085
Validation loss: 2.149170239766439

Epoch: 5| Step: 3
Training loss: 1.5257517099380493
Validation loss: 2.1417084534962973

Epoch: 5| Step: 4
Training loss: 1.9222984313964844
Validation loss: 2.145062749584516

Epoch: 5| Step: 5
Training loss: 2.0643205642700195
Validation loss: 2.149642303586006

Epoch: 5| Step: 6
Training loss: 2.035959482192993
Validation loss: 2.150477240482966

Epoch: 5| Step: 7
Training loss: 1.455891728401184
Validation loss: 2.16064190864563

Epoch: 5| Step: 8
Training loss: 1.5024316310882568
Validation loss: 2.1305054426193237

Epoch: 5| Step: 9
Training loss: 1.9956960678100586
Validation loss: 2.133738731344541

Epoch: 5| Step: 10
Training loss: 1.7813217639923096
Validation loss: 2.140362188220024

Epoch: 5| Step: 11
Training loss: 2.757748603820801
Validation loss: 2.1363185197114944

Epoch: 232| Step: 0
Training loss: 2.498872756958008
Validation loss: 2.1294766813516617

Epoch: 5| Step: 1
Training loss: 2.2072882652282715
Validation loss: 2.1339730471372604

Epoch: 5| Step: 2
Training loss: 1.5917168855667114
Validation loss: 2.13369020819664

Epoch: 5| Step: 3
Training loss: 1.9753364324569702
Validation loss: 2.1498767932256064

Epoch: 5| Step: 4
Training loss: 1.9221786260604858
Validation loss: 2.126121461391449

Epoch: 5| Step: 5
Training loss: 1.9240459203720093
Validation loss: 2.154225160678228

Epoch: 5| Step: 6
Training loss: 1.6814981698989868
Validation loss: 2.118652959664663

Epoch: 5| Step: 7
Training loss: 2.3375515937805176
Validation loss: 2.147704799969991

Epoch: 5| Step: 8
Training loss: 1.4139750003814697
Validation loss: 2.1369782189528146

Epoch: 5| Step: 9
Training loss: 1.7750133275985718
Validation loss: 2.1706595371166864

Epoch: 5| Step: 10
Training loss: 1.6987619400024414
Validation loss: 2.1758772134780884

Epoch: 5| Step: 11
Training loss: 1.9009510278701782
Validation loss: 2.1699287742376328

Epoch: 233| Step: 0
Training loss: 1.8099901676177979
Validation loss: 2.1839409172534943

Epoch: 5| Step: 1
Training loss: 1.9752919673919678
Validation loss: 2.1858618954817453

Epoch: 5| Step: 2
Training loss: 1.687054991722107
Validation loss: 2.1666215856870017

Epoch: 5| Step: 3
Training loss: 1.9991228580474854
Validation loss: 2.166356717546781

Epoch: 5| Step: 4
Training loss: 1.8512382507324219
Validation loss: 2.146724134683609

Epoch: 5| Step: 5
Training loss: 1.6774698495864868
Validation loss: 2.1293244808912277

Epoch: 5| Step: 6
Training loss: 1.9808673858642578
Validation loss: 2.125517706076304

Epoch: 5| Step: 7
Training loss: 2.5152809619903564
Validation loss: 2.1442514260609946

Epoch: 5| Step: 8
Training loss: 2.4553685188293457
Validation loss: 2.146407872438431

Epoch: 5| Step: 9
Training loss: 1.6090542078018188
Validation loss: 2.1284626374642053

Epoch: 5| Step: 10
Training loss: 1.5511751174926758
Validation loss: 2.1246029883623123

Epoch: 5| Step: 11
Training loss: 0.6392838954925537
Validation loss: 2.1255893607934317

Epoch: 234| Step: 0
Training loss: 1.338726282119751
Validation loss: 2.140678664048513

Epoch: 5| Step: 1
Training loss: 1.7398134469985962
Validation loss: 2.1236029863357544

Epoch: 5| Step: 2
Training loss: 2.2023541927337646
Validation loss: 2.1355950832366943

Epoch: 5| Step: 3
Training loss: 1.8364245891571045
Validation loss: 2.1430722922086716

Epoch: 5| Step: 4
Training loss: 2.367300033569336
Validation loss: 2.1395182510217032

Epoch: 5| Step: 5
Training loss: 2.6598355770111084
Validation loss: 2.1325661142667136

Epoch: 5| Step: 6
Training loss: 1.4868757724761963
Validation loss: 2.138699342807134

Epoch: 5| Step: 7
Training loss: 1.742767095565796
Validation loss: 2.125328535834948

Epoch: 5| Step: 8
Training loss: 1.7536375522613525
Validation loss: 2.1282160580158234

Epoch: 5| Step: 9
Training loss: 1.7909009456634521
Validation loss: 2.1187601735194526

Epoch: 5| Step: 10
Training loss: 1.7430976629257202
Validation loss: 2.13038602968057

Epoch: 5| Step: 11
Training loss: 1.5047221183776855
Validation loss: 2.117739056547483

Epoch: 235| Step: 0
Training loss: 1.77438485622406
Validation loss: 2.1324105759461722

Epoch: 5| Step: 1
Training loss: 0.9321838617324829
Validation loss: 2.1411229769388833

Epoch: 5| Step: 2
Training loss: 1.6905266046524048
Validation loss: 2.1281466086705527

Epoch: 5| Step: 3
Training loss: 2.011146068572998
Validation loss: 2.138252834479014

Epoch: 5| Step: 4
Training loss: 1.912308931350708
Validation loss: 2.1346257477998734

Epoch: 5| Step: 5
Training loss: 1.755877137184143
Validation loss: 2.1433114111423492

Epoch: 5| Step: 6
Training loss: 1.6763782501220703
Validation loss: 2.1497832338015237

Epoch: 5| Step: 7
Training loss: 2.4090516567230225
Validation loss: 2.147352417310079

Epoch: 5| Step: 8
Training loss: 2.0372605323791504
Validation loss: 2.150834704438845

Epoch: 5| Step: 9
Training loss: 2.3423943519592285
Validation loss: 2.1636444528897605

Epoch: 5| Step: 10
Training loss: 1.9983549118041992
Validation loss: 2.1471955676873526

Epoch: 5| Step: 11
Training loss: 2.232358694076538
Validation loss: 2.128330186009407

Epoch: 236| Step: 0
Training loss: 1.9321368932724
Validation loss: 2.1232658425966897

Epoch: 5| Step: 1
Training loss: 1.9962291717529297
Validation loss: 2.1240982363621392

Epoch: 5| Step: 2
Training loss: 1.9897079467773438
Validation loss: 2.1184625824292502

Epoch: 5| Step: 3
Training loss: 1.7368748188018799
Validation loss: 2.112616255879402

Epoch: 5| Step: 4
Training loss: 1.7500064373016357
Validation loss: 2.114892899990082

Epoch: 5| Step: 5
Training loss: 2.045872449874878
Validation loss: 2.1178999841213226

Epoch: 5| Step: 6
Training loss: 1.3371381759643555
Validation loss: 2.1327250798543296

Epoch: 5| Step: 7
Training loss: 2.3847835063934326
Validation loss: 2.146102418502172

Epoch: 5| Step: 8
Training loss: 1.7406810522079468
Validation loss: 2.1491306324799857

Epoch: 5| Step: 9
Training loss: 1.707495927810669
Validation loss: 2.1601030429204306

Epoch: 5| Step: 10
Training loss: 2.2070679664611816
Validation loss: 2.1732300519943237

Epoch: 5| Step: 11
Training loss: 1.7903733253479004
Validation loss: 2.187706246972084

Epoch: 237| Step: 0
Training loss: 2.213362693786621
Validation loss: 2.1560468475023904

Epoch: 5| Step: 1
Training loss: 1.9717174768447876
Validation loss: 2.142704968651136

Epoch: 5| Step: 2
Training loss: 1.5427119731903076
Validation loss: 2.1530369371175766

Epoch: 5| Step: 3
Training loss: 1.5127007961273193
Validation loss: 2.137972210844358

Epoch: 5| Step: 4
Training loss: 1.9940013885498047
Validation loss: 2.1286096622546515

Epoch: 5| Step: 5
Training loss: 1.2897366285324097
Validation loss: 2.1311391790707908

Epoch: 5| Step: 6
Training loss: 1.8174015283584595
Validation loss: 2.1121470481157303

Epoch: 5| Step: 7
Training loss: 2.679616928100586
Validation loss: 2.114693373441696

Epoch: 5| Step: 8
Training loss: 1.6922229528427124
Validation loss: 2.118254000941912

Epoch: 5| Step: 9
Training loss: 1.918572187423706
Validation loss: 2.1287994186083474

Epoch: 5| Step: 10
Training loss: 2.157907485961914
Validation loss: 2.1128015518188477

Epoch: 5| Step: 11
Training loss: 1.2820523977279663
Validation loss: 2.128492663304011

Epoch: 238| Step: 0
Training loss: 1.4022881984710693
Validation loss: 2.13269571463267

Epoch: 5| Step: 1
Training loss: 1.842940330505371
Validation loss: 2.1583980321884155

Epoch: 5| Step: 2
Training loss: 1.9788239002227783
Validation loss: 2.161220903197924

Epoch: 5| Step: 3
Training loss: 2.0354442596435547
Validation loss: 2.159718871116638

Epoch: 5| Step: 4
Training loss: 2.238319158554077
Validation loss: 2.1467074950536094

Epoch: 5| Step: 5
Training loss: 2.088956832885742
Validation loss: 2.141404449939728

Epoch: 5| Step: 6
Training loss: 1.7126200199127197
Validation loss: 2.1297064274549484

Epoch: 5| Step: 7
Training loss: 1.8797610998153687
Validation loss: 2.1301601032416024

Epoch: 5| Step: 8
Training loss: 1.4752061367034912
Validation loss: 2.145502671599388

Epoch: 5| Step: 9
Training loss: 2.2108194828033447
Validation loss: 2.1172544360160828

Epoch: 5| Step: 10
Training loss: 2.1027491092681885
Validation loss: 2.118642603357633

Epoch: 5| Step: 11
Training loss: 1.122986078262329
Validation loss: 2.11537134150664

Epoch: 239| Step: 0
Training loss: 2.4213156700134277
Validation loss: 2.112048844496409

Epoch: 5| Step: 1
Training loss: 1.7042548656463623
Validation loss: 2.127940058708191

Epoch: 5| Step: 2
Training loss: 1.618872046470642
Validation loss: 2.1245978424946466

Epoch: 5| Step: 3
Training loss: 1.7667388916015625
Validation loss: 2.123053545753161

Epoch: 5| Step: 4
Training loss: 1.4772382974624634
Validation loss: 2.137170950571696

Epoch: 5| Step: 5
Training loss: 2.1352500915527344
Validation loss: 2.139699692527453

Epoch: 5| Step: 6
Training loss: 1.8636503219604492
Validation loss: 2.1361347834269204

Epoch: 5| Step: 7
Training loss: 1.6619571447372437
Validation loss: 2.1447176138559976

Epoch: 5| Step: 8
Training loss: 2.475579023361206
Validation loss: 2.148376002907753

Epoch: 5| Step: 9
Training loss: 1.9151042699813843
Validation loss: 2.174096405506134

Epoch: 5| Step: 10
Training loss: 1.7429630756378174
Validation loss: 2.1712121665477753

Epoch: 5| Step: 11
Training loss: 0.6642086505889893
Validation loss: 2.172391494115194

Epoch: 240| Step: 0
Training loss: 2.1640419960021973
Validation loss: 2.1681054532527924

Epoch: 5| Step: 1
Training loss: 1.7449779510498047
Validation loss: 2.1731726179520288

Epoch: 5| Step: 2
Training loss: 2.1003732681274414
Validation loss: 2.175347020228704

Epoch: 5| Step: 3
Training loss: 1.6551835536956787
Validation loss: 2.174501970410347

Epoch: 5| Step: 4
Training loss: 1.534338355064392
Validation loss: 2.1590508123238883

Epoch: 5| Step: 5
Training loss: 1.9240089654922485
Validation loss: 2.143692339460055

Epoch: 5| Step: 6
Training loss: 1.9462039470672607
Validation loss: 2.13975727558136

Epoch: 5| Step: 7
Training loss: 1.6438007354736328
Validation loss: 2.121798182527224

Epoch: 5| Step: 8
Training loss: 1.6551377773284912
Validation loss: 2.1339799414078393

Epoch: 5| Step: 9
Training loss: 1.9579365253448486
Validation loss: 2.1268198688824973

Epoch: 5| Step: 10
Training loss: 2.3266196250915527
Validation loss: 2.120890994866689

Epoch: 5| Step: 11
Training loss: 1.9888510704040527
Validation loss: 2.1332372029622397

Epoch: 241| Step: 0
Training loss: 1.6530574560165405
Validation loss: 2.1243858138720193

Epoch: 5| Step: 1
Training loss: 1.6736600399017334
Validation loss: 2.137404983242353

Epoch: 5| Step: 2
Training loss: 1.9550021886825562
Validation loss: 2.1481036990880966

Epoch: 5| Step: 3
Training loss: 1.7420053482055664
Validation loss: 2.1292150964339576

Epoch: 5| Step: 4
Training loss: 1.9073187112808228
Validation loss: 2.1417294442653656

Epoch: 5| Step: 5
Training loss: 1.5796109437942505
Validation loss: 2.146449406941732

Epoch: 5| Step: 6
Training loss: 2.31311297416687
Validation loss: 2.1498263279596963

Epoch: 5| Step: 7
Training loss: 1.9618793725967407
Validation loss: 2.1457340816656747

Epoch: 5| Step: 8
Training loss: 1.4730844497680664
Validation loss: 2.1436268041531243

Epoch: 5| Step: 9
Training loss: 2.2099709510803223
Validation loss: 2.1558664540449777

Epoch: 5| Step: 10
Training loss: 2.096205234527588
Validation loss: 2.1430285473664603

Epoch: 5| Step: 11
Training loss: 1.7164967060089111
Validation loss: 2.1447145144144693

Epoch: 242| Step: 0
Training loss: 1.7645797729492188
Validation loss: 2.1520619690418243

Epoch: 5| Step: 1
Training loss: 1.6247094869613647
Validation loss: 2.120633214712143

Epoch: 5| Step: 2
Training loss: 1.503600001335144
Validation loss: 2.1469625582297645

Epoch: 5| Step: 3
Training loss: 1.9130630493164062
Validation loss: 2.144245147705078

Epoch: 5| Step: 4
Training loss: 1.1144622564315796
Validation loss: 2.1370620926221213

Epoch: 5| Step: 5
Training loss: 2.066286563873291
Validation loss: 2.1383467266956964

Epoch: 5| Step: 6
Training loss: 1.9909738302230835
Validation loss: 2.1449475238720574

Epoch: 5| Step: 7
Training loss: 2.038717269897461
Validation loss: 2.145096997419993

Epoch: 5| Step: 8
Training loss: 2.1262454986572266
Validation loss: 2.1512559354305267

Epoch: 5| Step: 9
Training loss: 1.9383690357208252
Validation loss: 2.143870304028193

Epoch: 5| Step: 10
Training loss: 2.3922743797302246
Validation loss: 2.1321044166882834

Epoch: 5| Step: 11
Training loss: 1.8208400011062622
Validation loss: 2.13493704299132

Epoch: 243| Step: 0
Training loss: 2.0569188594818115
Validation loss: 2.1291997035344443

Epoch: 5| Step: 1
Training loss: 2.0628135204315186
Validation loss: 2.137048934896787

Epoch: 5| Step: 2
Training loss: 1.7506306171417236
Validation loss: 2.1317551334698996

Epoch: 5| Step: 3
Training loss: 1.336928129196167
Validation loss: 2.1297199378410974

Epoch: 5| Step: 4
Training loss: 2.084651470184326
Validation loss: 2.123015488187472

Epoch: 5| Step: 5
Training loss: 1.866384744644165
Validation loss: 2.140168716510137

Epoch: 5| Step: 6
Training loss: 2.267768383026123
Validation loss: 2.1485297779242196

Epoch: 5| Step: 7
Training loss: 1.7385448217391968
Validation loss: 2.1384496788183847

Epoch: 5| Step: 8
Training loss: 1.852494239807129
Validation loss: 2.1516654590765634

Epoch: 5| Step: 9
Training loss: 1.9135220050811768
Validation loss: 2.1446785728136697

Epoch: 5| Step: 10
Training loss: 1.4223182201385498
Validation loss: 2.137460634112358

Epoch: 5| Step: 11
Training loss: 2.103217124938965
Validation loss: 2.1500231673320136

Epoch: 244| Step: 0
Training loss: 1.8456761837005615
Validation loss: 2.1477743734916053

Epoch: 5| Step: 1
Training loss: 1.9788564443588257
Validation loss: 2.141981780529022

Epoch: 5| Step: 2
Training loss: 1.6428067684173584
Validation loss: 2.173056334257126

Epoch: 5| Step: 3
Training loss: 1.8441359996795654
Validation loss: 2.1517090499401093

Epoch: 5| Step: 4
Training loss: 1.1702125072479248
Validation loss: 2.142642542719841

Epoch: 5| Step: 5
Training loss: 1.923785924911499
Validation loss: 2.1323262055714927

Epoch: 5| Step: 6
Training loss: 1.5825433731079102
Validation loss: 2.144441992044449

Epoch: 5| Step: 7
Training loss: 2.202144145965576
Validation loss: 2.1488471031188965

Epoch: 5| Step: 8
Training loss: 2.1349937915802
Validation loss: 2.1748028000195823

Epoch: 5| Step: 9
Training loss: 2.035954713821411
Validation loss: 2.18153578042984

Epoch: 5| Step: 10
Training loss: 1.9810588359832764
Validation loss: 2.2014803737401962

Epoch: 5| Step: 11
Training loss: 1.5911155939102173
Validation loss: 2.1834832976261773

Epoch: 245| Step: 0
Training loss: 1.6199957132339478
Validation loss: 2.1935328394174576

Epoch: 5| Step: 1
Training loss: 1.973802924156189
Validation loss: 2.1988020737965903

Epoch: 5| Step: 2
Training loss: 2.0514490604400635
Validation loss: 2.194573387503624

Epoch: 5| Step: 3
Training loss: 1.7699744701385498
Validation loss: 2.1720037857691445

Epoch: 5| Step: 4
Training loss: 1.6973698139190674
Validation loss: 2.1728034963210425

Epoch: 5| Step: 5
Training loss: 1.6487665176391602
Validation loss: 2.1538413812716803

Epoch: 5| Step: 6
Training loss: 1.9682689905166626
Validation loss: 2.1478886057933173

Epoch: 5| Step: 7
Training loss: 1.7465579509735107
Validation loss: 2.1546622117360434

Epoch: 5| Step: 8
Training loss: 2.1876280307769775
Validation loss: 2.1324236939350762

Epoch: 5| Step: 9
Training loss: 1.9446747303009033
Validation loss: 2.1417607913414636

Epoch: 5| Step: 10
Training loss: 1.8398277759552002
Validation loss: 2.1332568675279617

Epoch: 5| Step: 11
Training loss: 3.441049098968506
Validation loss: 2.13362118601799

Epoch: 246| Step: 0
Training loss: 1.749535322189331
Validation loss: 2.137127230564753

Epoch: 5| Step: 1
Training loss: 1.796761155128479
Validation loss: 2.1569455564022064

Epoch: 5| Step: 2
Training loss: 1.935380220413208
Validation loss: 2.1246140698591867

Epoch: 5| Step: 3
Training loss: 2.1563186645507812
Validation loss: 2.1415557513634362

Epoch: 5| Step: 4
Training loss: 2.1935455799102783
Validation loss: 2.1296296815077462

Epoch: 5| Step: 5
Training loss: 1.4888038635253906
Validation loss: 2.1439151763916016

Epoch: 5| Step: 6
Training loss: 1.9704444408416748
Validation loss: 2.136125465234121

Epoch: 5| Step: 7
Training loss: 1.5892176628112793
Validation loss: 2.1625815480947495

Epoch: 5| Step: 8
Training loss: 1.9708112478256226
Validation loss: 2.158009042342504

Epoch: 5| Step: 9
Training loss: 1.3322104215621948
Validation loss: 2.150101885199547

Epoch: 5| Step: 10
Training loss: 2.0487618446350098
Validation loss: 2.153263032436371

Epoch: 5| Step: 11
Training loss: 2.8530516624450684
Validation loss: 2.1427540481090546

Epoch: 247| Step: 0
Training loss: 1.5153331756591797
Validation loss: 2.131994436184565

Epoch: 5| Step: 1
Training loss: 1.8058817386627197
Validation loss: 2.1412755151589713

Epoch: 5| Step: 2
Training loss: 2.1896159648895264
Validation loss: 2.120436737934748

Epoch: 5| Step: 3
Training loss: 1.6240184307098389
Validation loss: 2.119715010126432

Epoch: 5| Step: 4
Training loss: 1.5770864486694336
Validation loss: 2.1249751845995584

Epoch: 5| Step: 5
Training loss: 2.3327763080596924
Validation loss: 2.1194529036680856

Epoch: 5| Step: 6
Training loss: 1.8119373321533203
Validation loss: 2.1308660755554834

Epoch: 5| Step: 7
Training loss: 1.951202630996704
Validation loss: 2.1202110995848975

Epoch: 5| Step: 8
Training loss: 2.3462765216827393
Validation loss: 2.1464191476504006

Epoch: 5| Step: 9
Training loss: 1.3884406089782715
Validation loss: 2.1519330392281213

Epoch: 5| Step: 10
Training loss: 1.9473152160644531
Validation loss: 2.142324020465215

Epoch: 5| Step: 11
Training loss: 3.7497053146362305
Validation loss: 2.1587817470232644

Epoch: 248| Step: 0
Training loss: 1.6398226022720337
Validation loss: 2.1735106855630875

Epoch: 5| Step: 1
Training loss: 2.7731761932373047
Validation loss: 2.186915010213852

Epoch: 5| Step: 2
Training loss: 1.9404926300048828
Validation loss: 2.1701950232187905

Epoch: 5| Step: 3
Training loss: 1.9613189697265625
Validation loss: 2.1657808969418206

Epoch: 5| Step: 4
Training loss: 2.366617202758789
Validation loss: 2.1533520420392356

Epoch: 5| Step: 5
Training loss: 1.8460273742675781
Validation loss: 2.1440880994002023

Epoch: 5| Step: 6
Training loss: 1.763075590133667
Validation loss: 2.141924853126208

Epoch: 5| Step: 7
Training loss: 1.5620129108428955
Validation loss: 2.137834201256434

Epoch: 5| Step: 8
Training loss: 1.8894693851470947
Validation loss: 2.158951073884964

Epoch: 5| Step: 9
Training loss: 2.20241117477417
Validation loss: 2.130796084801356

Epoch: 5| Step: 10
Training loss: 1.414402723312378
Validation loss: 2.11276121934255

Epoch: 5| Step: 11
Training loss: 1.4382704496383667
Validation loss: 2.1214775343736014

Epoch: 249| Step: 0
Training loss: 1.848672866821289
Validation loss: 2.105171983440717

Epoch: 5| Step: 1
Training loss: 1.8612661361694336
Validation loss: 2.09313628077507

Epoch: 5| Step: 2
Training loss: 1.9465020895004272
Validation loss: 2.0912079364061356

Epoch: 5| Step: 3
Training loss: 1.8661342859268188
Validation loss: 2.091281915704409

Epoch: 5| Step: 4
Training loss: 2.0582923889160156
Validation loss: 2.1123655090729394

Epoch: 5| Step: 5
Training loss: 2.0559144020080566
Validation loss: 2.108718683322271

Epoch: 5| Step: 6
Training loss: 1.5621497631072998
Validation loss: 2.130152260263761

Epoch: 5| Step: 7
Training loss: 2.2675397396087646
Validation loss: 2.1268023351828256

Epoch: 5| Step: 8
Training loss: 1.7662874460220337
Validation loss: 2.1457479695479074

Epoch: 5| Step: 9
Training loss: 1.8418331146240234
Validation loss: 2.1391073962052665

Epoch: 5| Step: 10
Training loss: 2.1683871746063232
Validation loss: 2.145315498113632

Epoch: 5| Step: 11
Training loss: 1.7289729118347168
Validation loss: 2.152766371766726

Epoch: 250| Step: 0
Training loss: 1.767887830734253
Validation loss: 2.1547534416119256

Epoch: 5| Step: 1
Training loss: 2.071686267852783
Validation loss: 2.1535885632038116

Epoch: 5| Step: 2
Training loss: 1.9797776937484741
Validation loss: 2.1593190828959146

Epoch: 5| Step: 3
Training loss: 1.7689628601074219
Validation loss: 2.1629488418499627

Epoch: 5| Step: 4
Training loss: 2.4770545959472656
Validation loss: 2.1600277572870255

Epoch: 5| Step: 5
Training loss: 1.9031473398208618
Validation loss: 2.1483390629291534

Epoch: 5| Step: 6
Training loss: 2.02616024017334
Validation loss: 2.1501555492480597

Epoch: 5| Step: 7
Training loss: 1.4893033504486084
Validation loss: 2.1079883774121604

Epoch: 5| Step: 8
Training loss: 1.8551992177963257
Validation loss: 2.114959344267845

Epoch: 5| Step: 9
Training loss: 1.7784709930419922
Validation loss: 2.124774217605591

Epoch: 5| Step: 10
Training loss: 2.026549816131592
Validation loss: 2.1319841941197715

Epoch: 5| Step: 11
Training loss: 0.752468466758728
Validation loss: 2.1254815608263016

Testing loss: 1.7410458352068345
