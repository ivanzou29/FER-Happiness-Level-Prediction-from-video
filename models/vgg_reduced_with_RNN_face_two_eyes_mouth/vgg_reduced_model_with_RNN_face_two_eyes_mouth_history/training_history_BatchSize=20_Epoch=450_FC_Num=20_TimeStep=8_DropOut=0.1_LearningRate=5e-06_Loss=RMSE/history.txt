Epoch: 1| Step: 0
Training loss: 4.716488125570493
Validation loss: 5.862967641814564

Epoch: 5| Step: 1
Training loss: 6.216741649731148
Validation loss: 5.861038839829727

Epoch: 5| Step: 2
Training loss: 6.283774101252082
Validation loss: 5.859115445640113

Epoch: 5| Step: 3
Training loss: 6.474176314702699
Validation loss: 5.857301214505353

Epoch: 5| Step: 4
Training loss: 5.814565640181937
Validation loss: 5.8555405476422235

Epoch: 5| Step: 5
Training loss: 5.883122774125954
Validation loss: 5.853696697914814

Epoch: 5| Step: 6
Training loss: 6.544801807127553
Validation loss: 5.851933289728903

Epoch: 5| Step: 7
Training loss: 5.935566155570857
Validation loss: 5.850169023968335

Epoch: 5| Step: 8
Training loss: 5.610833363640904
Validation loss: 5.8483913301926185

Epoch: 5| Step: 9
Training loss: 5.608001115698166
Validation loss: 5.846575368478675

Epoch: 5| Step: 10
Training loss: 6.226893015361341
Validation loss: 5.844659418343439

Epoch: 5| Step: 11
Training loss: 6.6208598317823775
Validation loss: 5.8427301764752935

Epoch: 2| Step: 0
Training loss: 5.468405053295183
Validation loss: 5.840722317987859

Epoch: 5| Step: 1
Training loss: 6.135616521597292
Validation loss: 5.838618454667836

Epoch: 5| Step: 2
Training loss: 6.745342201731283
Validation loss: 5.836464609141269

Epoch: 5| Step: 3
Training loss: 5.715458490731723
Validation loss: 5.834138496780261

Epoch: 5| Step: 4
Training loss: 4.785043047130363
Validation loss: 5.831789918349154

Epoch: 5| Step: 5
Training loss: 5.54366379319247
Validation loss: 5.829344443754466

Epoch: 5| Step: 6
Training loss: 5.080659861623941
Validation loss: 5.826847676201469

Epoch: 5| Step: 7
Training loss: 6.282154226931796
Validation loss: 5.824320242407046

Epoch: 5| Step: 8
Training loss: 6.591719617602818
Validation loss: 5.821604281110414

Epoch: 5| Step: 9
Training loss: 6.650998905276431
Validation loss: 5.818683377494703

Epoch: 5| Step: 10
Training loss: 5.711237407694656
Validation loss: 5.815512604526691

Epoch: 5| Step: 11
Training loss: 7.375347064628923
Validation loss: 5.8123330191414375

Epoch: 3| Step: 0
Training loss: 6.251442704582029
Validation loss: 5.808957657812334

Epoch: 5| Step: 1
Training loss: 6.2185469551101855
Validation loss: 5.805426898343944

Epoch: 5| Step: 2
Training loss: 5.139334751524989
Validation loss: 5.801732272400284

Epoch: 5| Step: 3
Training loss: 6.321192431407448
Validation loss: 5.797748660925907

Epoch: 5| Step: 4
Training loss: 5.783655934126395
Validation loss: 5.793744450922794

Epoch: 5| Step: 5
Training loss: 5.463708264696147
Validation loss: 5.7893714496302815

Epoch: 5| Step: 6
Training loss: 5.790312720832036
Validation loss: 5.784965469061667

Epoch: 5| Step: 7
Training loss: 5.593146094430448
Validation loss: 5.780155146946421

Epoch: 5| Step: 8
Training loss: 5.787367764439127
Validation loss: 5.775491558143748

Epoch: 5| Step: 9
Training loss: 5.805184303269094
Validation loss: 5.770217747912745

Epoch: 5| Step: 10
Training loss: 6.4694699978609265
Validation loss: 5.76481559330556

Epoch: 5| Step: 11
Training loss: 6.729644317523836
Validation loss: 5.759146768260227

Epoch: 4| Step: 0
Training loss: 5.675561468774684
Validation loss: 5.75342272738026

Epoch: 5| Step: 1
Training loss: 6.50067545975843
Validation loss: 5.7468833700633875

Epoch: 5| Step: 2
Training loss: 6.175185771418009
Validation loss: 5.740564129817661

Epoch: 5| Step: 3
Training loss: 6.010943922411762
Validation loss: 5.733883080444377

Epoch: 5| Step: 4
Training loss: 5.637439790053159
Validation loss: 5.726842702521755

Epoch: 5| Step: 5
Training loss: 5.979663398480793
Validation loss: 5.7197723656044275

Epoch: 5| Step: 6
Training loss: 5.363687009528207
Validation loss: 5.712075617112056

Epoch: 5| Step: 7
Training loss: 5.920268865098831
Validation loss: 5.704359706494399

Epoch: 5| Step: 8
Training loss: 4.99709159186035
Validation loss: 5.696743060307168

Epoch: 5| Step: 9
Training loss: 5.825983630779723
Validation loss: 5.6886094726403345

Epoch: 5| Step: 10
Training loss: 5.514167917378371
Validation loss: 5.680242337320323

Epoch: 5| Step: 11
Training loss: 7.659738423236289
Validation loss: 5.671798614463994

Epoch: 5| Step: 0
Training loss: 5.902107198684689
Validation loss: 5.663407028681222

Epoch: 5| Step: 1
Training loss: 5.984454998547376
Validation loss: 5.654620376670588

Epoch: 5| Step: 2
Training loss: 6.113112767246988
Validation loss: 5.645522790605311

Epoch: 5| Step: 3
Training loss: 5.485369035238995
Validation loss: 5.636493300319653

Epoch: 5| Step: 4
Training loss: 6.005119047358614
Validation loss: 5.6275346414230505

Epoch: 5| Step: 5
Training loss: 5.921760658629805
Validation loss: 5.618232159483951

Epoch: 5| Step: 6
Training loss: 6.1392165260090525
Validation loss: 5.608702269497628

Epoch: 5| Step: 7
Training loss: 4.70726181035437
Validation loss: 5.599260524904224

Epoch: 5| Step: 8
Training loss: 5.410824995333609
Validation loss: 5.590241509340314

Epoch: 5| Step: 9
Training loss: 6.234843071597023
Validation loss: 5.580844141609002

Epoch: 5| Step: 10
Training loss: 5.039470330819496
Validation loss: 5.571217966698721

Epoch: 5| Step: 11
Training loss: 5.359691910785548
Validation loss: 5.561811933215979

Epoch: 6| Step: 0
Training loss: 6.274772074538034
Validation loss: 5.55264029175492

Epoch: 5| Step: 1
Training loss: 5.361592804258977
Validation loss: 5.542787469610694

Epoch: 5| Step: 2
Training loss: 5.449441359700322
Validation loss: 5.533585638973573

Epoch: 5| Step: 3
Training loss: 5.152904372989358
Validation loss: 5.524237625607008

Epoch: 5| Step: 4
Training loss: 5.3658250081593675
Validation loss: 5.514333499926815

Epoch: 5| Step: 5
Training loss: 6.0424971787963395
Validation loss: 5.505168321572966

Epoch: 5| Step: 6
Training loss: 5.521981442628577
Validation loss: 5.495611744892203

Epoch: 5| Step: 7
Training loss: 4.971145532252303
Validation loss: 5.4858615595828155

Epoch: 5| Step: 8
Training loss: 5.206657241702046
Validation loss: 5.4760847332224625

Epoch: 5| Step: 9
Training loss: 6.117958536676604
Validation loss: 5.466170445556867

Epoch: 5| Step: 10
Training loss: 6.242613738478603
Validation loss: 5.455860774259292

Epoch: 5| Step: 11
Training loss: 5.332623951146912
Validation loss: 5.445358684823737

Epoch: 7| Step: 0
Training loss: 5.620986184581479
Validation loss: 5.434621363168991

Epoch: 5| Step: 1
Training loss: 5.834306726531272
Validation loss: 5.424314765312974

Epoch: 5| Step: 2
Training loss: 5.065878223676919
Validation loss: 5.413544080023062

Epoch: 5| Step: 3
Training loss: 4.403751178777029
Validation loss: 5.4029196769866985

Epoch: 5| Step: 4
Training loss: 4.748825329541828
Validation loss: 5.393059119235024

Epoch: 5| Step: 5
Training loss: 5.156692763305465
Validation loss: 5.383320962027555

Epoch: 5| Step: 6
Training loss: 5.704038614749614
Validation loss: 5.374301421434475

Epoch: 5| Step: 7
Training loss: 5.607410650132444
Validation loss: 5.364887068461419

Epoch: 5| Step: 8
Training loss: 5.611172273929907
Validation loss: 5.356138707313755

Epoch: 5| Step: 9
Training loss: 6.487131732344655
Validation loss: 5.346761067089011

Epoch: 5| Step: 10
Training loss: 5.987519954257916
Validation loss: 5.337919389386915

Epoch: 5| Step: 11
Training loss: 5.408174910769669
Validation loss: 5.328669276922465

Epoch: 8| Step: 0
Training loss: 5.916557561737032
Validation loss: 5.319903432213424

Epoch: 5| Step: 1
Training loss: 5.766513166791801
Validation loss: 5.31111187470447

Epoch: 5| Step: 2
Training loss: 5.617490375614113
Validation loss: 5.302638508847505

Epoch: 5| Step: 3
Training loss: 5.556928265841568
Validation loss: 5.29423305524891

Epoch: 5| Step: 4
Training loss: 5.095856026416737
Validation loss: 5.2864041881575865

Epoch: 5| Step: 5
Training loss: 5.611699294850899
Validation loss: 5.27889862233126

Epoch: 5| Step: 6
Training loss: 4.929629463059714
Validation loss: 5.271026263519494

Epoch: 5| Step: 7
Training loss: 5.610039206791107
Validation loss: 5.26366860620212

Epoch: 5| Step: 8
Training loss: 4.341119861887418
Validation loss: 5.256118380561445

Epoch: 5| Step: 9
Training loss: 6.164330460945315
Validation loss: 5.248804334695556

Epoch: 5| Step: 10
Training loss: 4.867950820461284
Validation loss: 5.2415457350219565

Epoch: 5| Step: 11
Training loss: 3.5017295378812063
Validation loss: 5.234270981091959

Epoch: 9| Step: 0
Training loss: 5.114542829530567
Validation loss: 5.2275829221891685

Epoch: 5| Step: 1
Training loss: 5.114252497998241
Validation loss: 5.220372775750875

Epoch: 5| Step: 2
Training loss: 5.2566268513650645
Validation loss: 5.213815415773099

Epoch: 5| Step: 3
Training loss: 5.4129967018905285
Validation loss: 5.206978257966783

Epoch: 5| Step: 4
Training loss: 5.535883627555929
Validation loss: 5.200342971544072

Epoch: 5| Step: 5
Training loss: 4.984445792625208
Validation loss: 5.19346410620156

Epoch: 5| Step: 6
Training loss: 4.461535198301544
Validation loss: 5.18654709225619

Epoch: 5| Step: 7
Training loss: 5.958111454315938
Validation loss: 5.179657925942803

Epoch: 5| Step: 8
Training loss: 4.744452801135464
Validation loss: 5.172839025907501

Epoch: 5| Step: 9
Training loss: 5.602181329954121
Validation loss: 5.166190704859495

Epoch: 5| Step: 10
Training loss: 5.704582968605429
Validation loss: 5.159214978323325

Epoch: 5| Step: 11
Training loss: 7.031691066895211
Validation loss: 5.1527726286765

Epoch: 10| Step: 0
Training loss: 5.827372893620984
Validation loss: 5.145554595481676

Epoch: 5| Step: 1
Training loss: 5.928484044440497
Validation loss: 5.138312015573777

Epoch: 5| Step: 2
Training loss: 5.073669544831087
Validation loss: 5.131536571942913

Epoch: 5| Step: 3
Training loss: 4.959967763242251
Validation loss: 5.124826211231233

Epoch: 5| Step: 4
Training loss: 5.381125574744737
Validation loss: 5.118245620626042

Epoch: 5| Step: 5
Training loss: 4.613837509792956
Validation loss: 5.111170695252418

Epoch: 5| Step: 6
Training loss: 5.1670297474596385
Validation loss: 5.104521107207053

Epoch: 5| Step: 7
Training loss: 4.735998699883979
Validation loss: 5.098012813798942

Epoch: 5| Step: 8
Training loss: 5.453440659795175
Validation loss: 5.09146516258641

Epoch: 5| Step: 9
Training loss: 5.456603768711881
Validation loss: 5.0847709399994585

Epoch: 5| Step: 10
Training loss: 5.151789359922316
Validation loss: 5.078448789006285

Epoch: 5| Step: 11
Training loss: 3.4433221236197578
Validation loss: 5.0724720012605875

Epoch: 11| Step: 0
Training loss: 4.423104374778043
Validation loss: 5.066693300043343

Epoch: 5| Step: 1
Training loss: 4.157724678175759
Validation loss: 5.0613682741688235

Epoch: 5| Step: 2
Training loss: 5.602174350410078
Validation loss: 5.055687390286468

Epoch: 5| Step: 3
Training loss: 4.503962573504069
Validation loss: 5.050352900043523

Epoch: 5| Step: 4
Training loss: 5.049712809337488
Validation loss: 5.044874324222508

Epoch: 5| Step: 5
Training loss: 5.600417271463079
Validation loss: 5.039752851801951

Epoch: 5| Step: 6
Training loss: 5.85740852418035
Validation loss: 5.034273798766194

Epoch: 5| Step: 7
Training loss: 4.711469882723495
Validation loss: 5.028586541538627

Epoch: 5| Step: 8
Training loss: 5.879341955926428
Validation loss: 5.02345477586211

Epoch: 5| Step: 9
Training loss: 5.265090870014196
Validation loss: 5.017708920835218

Epoch: 5| Step: 10
Training loss: 5.336176809638675
Validation loss: 5.012080341316759

Epoch: 5| Step: 11
Training loss: 5.452663631651199
Validation loss: 5.006664578991457

Epoch: 12| Step: 0
Training loss: 5.297794768560786
Validation loss: 5.0011048765133514

Epoch: 5| Step: 1
Training loss: 6.21139014172156
Validation loss: 4.99592481481147

Epoch: 5| Step: 2
Training loss: 5.599395460467592
Validation loss: 4.990538084339838

Epoch: 5| Step: 3
Training loss: 4.501582609142975
Validation loss: 4.9852235524191295

Epoch: 5| Step: 4
Training loss: 4.853666921057357
Validation loss: 4.9799831098757785

Epoch: 5| Step: 5
Training loss: 4.427839482376191
Validation loss: 4.974767420075025

Epoch: 5| Step: 6
Training loss: 5.19436228387401
Validation loss: 4.96951507979922

Epoch: 5| Step: 7
Training loss: 5.776507767863513
Validation loss: 4.964978368071127

Epoch: 5| Step: 8
Training loss: 4.622138297916708
Validation loss: 4.959794152536236

Epoch: 5| Step: 9
Training loss: 4.757582585334112
Validation loss: 4.95519842157929

Epoch: 5| Step: 10
Training loss: 4.410434116094154
Validation loss: 4.9502491991014095

Epoch: 5| Step: 11
Training loss: 5.668867506598919
Validation loss: 4.944994618432511

Epoch: 13| Step: 0
Training loss: 3.3674749618992794
Validation loss: 4.9401833851813235

Epoch: 5| Step: 1
Training loss: 4.741701204859086
Validation loss: 4.93529404884673

Epoch: 5| Step: 2
Training loss: 4.8747836333946255
Validation loss: 4.930707033125871

Epoch: 5| Step: 3
Training loss: 5.988267872416564
Validation loss: 4.926237508207363

Epoch: 5| Step: 4
Training loss: 5.382088179224241
Validation loss: 4.921618936326413

Epoch: 5| Step: 5
Training loss: 5.0742818991451575
Validation loss: 4.916691402868773

Epoch: 5| Step: 6
Training loss: 5.858952133178505
Validation loss: 4.9118601235868535

Epoch: 5| Step: 7
Training loss: 4.814991095704018
Validation loss: 4.906808606721669

Epoch: 5| Step: 8
Training loss: 4.8967136105718865
Validation loss: 4.9019585162980315

Epoch: 5| Step: 9
Training loss: 4.914079772239617
Validation loss: 4.897234877049932

Epoch: 5| Step: 10
Training loss: 4.78304900189373
Validation loss: 4.892760747875553

Epoch: 5| Step: 11
Training loss: 6.364520566373788
Validation loss: 4.887960339759388

Epoch: 14| Step: 0
Training loss: 5.134532901427814
Validation loss: 4.882919294079526

Epoch: 5| Step: 1
Training loss: 5.225594606287194
Validation loss: 4.877876517178206

Epoch: 5| Step: 2
Training loss: 4.058057733116622
Validation loss: 4.8730906635526345

Epoch: 5| Step: 3
Training loss: 5.721694271748139
Validation loss: 4.8679022511667664

Epoch: 5| Step: 4
Training loss: 4.80191282464735
Validation loss: 4.863087249113848

Epoch: 5| Step: 5
Training loss: 5.538243242591583
Validation loss: 4.85827189985184

Epoch: 5| Step: 6
Training loss: 4.492829013297146
Validation loss: 4.853449333244774

Epoch: 5| Step: 7
Training loss: 3.866494966399842
Validation loss: 4.848854599227918

Epoch: 5| Step: 8
Training loss: 5.19565795667721
Validation loss: 4.844008933088747

Epoch: 5| Step: 9
Training loss: 5.608022542714999
Validation loss: 4.838619287673745

Epoch: 5| Step: 10
Training loss: 4.932628304562061
Validation loss: 4.834256399188009

Epoch: 5| Step: 11
Training loss: 4.397112523151956
Validation loss: 4.829547174694822

Epoch: 15| Step: 0
Training loss: 5.191681061669115
Validation loss: 4.824906800247864

Epoch: 5| Step: 1
Training loss: 4.127962378071703
Validation loss: 4.819401160780836

Epoch: 5| Step: 2
Training loss: 5.466617364583569
Validation loss: 4.815026037291694

Epoch: 5| Step: 3
Training loss: 4.57638902267021
Validation loss: 4.810614637671242

Epoch: 5| Step: 4
Training loss: 4.79915800656964
Validation loss: 4.8052523149183415

Epoch: 5| Step: 5
Training loss: 5.676468767504762
Validation loss: 4.800825407995802

Epoch: 5| Step: 6
Training loss: 5.0410192194751815
Validation loss: 4.79517426716746

Epoch: 5| Step: 7
Training loss: 4.433663657557339
Validation loss: 4.791381407276859

Epoch: 5| Step: 8
Training loss: 4.360001932546205
Validation loss: 4.7865069459169876

Epoch: 5| Step: 9
Training loss: 5.254708131766105
Validation loss: 4.7822278254967365

Epoch: 5| Step: 10
Training loss: 5.154553498431118
Validation loss: 4.776999069426725

Epoch: 5| Step: 11
Training loss: 4.290725802399514
Validation loss: 4.772177480500971

Epoch: 16| Step: 0
Training loss: 4.818421721006758
Validation loss: 4.767633742263692

Epoch: 5| Step: 1
Training loss: 4.569638455236067
Validation loss: 4.7630241509438696

Epoch: 5| Step: 2
Training loss: 4.780391640998989
Validation loss: 4.7582339730163286

Epoch: 5| Step: 3
Training loss: 4.790048718612846
Validation loss: 4.753776956020888

Epoch: 5| Step: 4
Training loss: 4.094733200231622
Validation loss: 4.747901620320739

Epoch: 5| Step: 5
Training loss: 4.892113212379622
Validation loss: 4.743778914881568

Epoch: 5| Step: 6
Training loss: 4.920918495847441
Validation loss: 4.739144519431963

Epoch: 5| Step: 7
Training loss: 4.920813067483583
Validation loss: 4.7346021306076205

Epoch: 5| Step: 8
Training loss: 5.413785236519657
Validation loss: 4.729657154723136

Epoch: 5| Step: 9
Training loss: 4.907664489943216
Validation loss: 4.725271245110611

Epoch: 5| Step: 10
Training loss: 5.298234163171984
Validation loss: 4.7203108456594105

Epoch: 5| Step: 11
Training loss: 5.120244681055005
Validation loss: 4.715420430378453

Epoch: 17| Step: 0
Training loss: 4.161637793702926
Validation loss: 4.710217144044648

Epoch: 5| Step: 1
Training loss: 4.804506872239896
Validation loss: 4.705718372067299

Epoch: 5| Step: 2
Training loss: 4.911062031112771
Validation loss: 4.701163236586068

Epoch: 5| Step: 3
Training loss: 5.274376905621526
Validation loss: 4.6960542825992775

Epoch: 5| Step: 4
Training loss: 4.42443773393576
Validation loss: 4.691231763793943

Epoch: 5| Step: 5
Training loss: 5.097097408604023
Validation loss: 4.686720609508225

Epoch: 5| Step: 6
Training loss: 5.026473532456463
Validation loss: 4.681435786500466

Epoch: 5| Step: 7
Training loss: 5.02052063449661
Validation loss: 4.676362118696155

Epoch: 5| Step: 8
Training loss: 4.5674524471185745
Validation loss: 4.671245222054354

Epoch: 5| Step: 9
Training loss: 5.18665371161823
Validation loss: 4.66629019422138

Epoch: 5| Step: 10
Training loss: 4.626836051442046
Validation loss: 4.661338815986114

Epoch: 5| Step: 11
Training loss: 3.1751786489613187
Validation loss: 4.656424299387133

Epoch: 18| Step: 0
Training loss: 5.053413619726386
Validation loss: 4.651192493563352

Epoch: 5| Step: 1
Training loss: 5.25353303739493
Validation loss: 4.6469308500476

Epoch: 5| Step: 2
Training loss: 3.713625285886697
Validation loss: 4.641741788428599

Epoch: 5| Step: 3
Training loss: 4.783511555682157
Validation loss: 4.636703838269777

Epoch: 5| Step: 4
Training loss: 4.698692285944893
Validation loss: 4.632090554640789

Epoch: 5| Step: 5
Training loss: 5.051824357254303
Validation loss: 4.626936172190213

Epoch: 5| Step: 6
Training loss: 4.12797854999026
Validation loss: 4.622239165180792

Epoch: 5| Step: 7
Training loss: 5.264900497264288
Validation loss: 4.6175248420321084

Epoch: 5| Step: 8
Training loss: 5.258444216728398
Validation loss: 4.61228341194548

Epoch: 5| Step: 9
Training loss: 3.9323305376502145
Validation loss: 4.606895667915455

Epoch: 5| Step: 10
Training loss: 4.912545799449553
Validation loss: 4.602504251738185

Epoch: 5| Step: 11
Training loss: 4.419437019431953
Validation loss: 4.597438914073142

Epoch: 19| Step: 0
Training loss: 4.563523896174112
Validation loss: 4.592257280956345

Epoch: 5| Step: 1
Training loss: 5.239779742321892
Validation loss: 4.587314162964124

Epoch: 5| Step: 2
Training loss: 3.4422178318178194
Validation loss: 4.582236855293187

Epoch: 5| Step: 3
Training loss: 5.254433893985597
Validation loss: 4.577175627819548

Epoch: 5| Step: 4
Training loss: 4.108745338151803
Validation loss: 4.572210994602126

Epoch: 5| Step: 5
Training loss: 6.08229498514968
Validation loss: 4.566977163651

Epoch: 5| Step: 6
Training loss: 4.523049135287456
Validation loss: 4.561517026038276

Epoch: 5| Step: 7
Training loss: 3.813613728927186
Validation loss: 4.556628067385183

Epoch: 5| Step: 8
Training loss: 4.746581805217115
Validation loss: 4.551573210473494

Epoch: 5| Step: 9
Training loss: 4.615332732764871
Validation loss: 4.545489638727719

Epoch: 5| Step: 10
Training loss: 4.406297182953273
Validation loss: 4.540774890712353

Epoch: 5| Step: 11
Training loss: 5.972698403628224
Validation loss: 4.53590545905791

Epoch: 20| Step: 0
Training loss: 4.910018736887063
Validation loss: 4.530186157745354

Epoch: 5| Step: 1
Training loss: 4.671064529799683
Validation loss: 4.5248622198889406

Epoch: 5| Step: 2
Training loss: 3.9289664181395296
Validation loss: 4.519677162287828

Epoch: 5| Step: 3
Training loss: 4.947905573246884
Validation loss: 4.5138128575825665

Epoch: 5| Step: 4
Training loss: 4.698594252391708
Validation loss: 4.5089975096393315

Epoch: 5| Step: 5
Training loss: 4.812769102028827
Validation loss: 4.50299028543216

Epoch: 5| Step: 6
Training loss: 5.135311453194779
Validation loss: 4.498040099200304

Epoch: 5| Step: 7
Training loss: 4.006914599634568
Validation loss: 4.492094637145918

Epoch: 5| Step: 8
Training loss: 4.477594333253471
Validation loss: 4.487288628384451

Epoch: 5| Step: 9
Training loss: 5.087902246267918
Validation loss: 4.482081381637282

Epoch: 5| Step: 10
Training loss: 3.9595362123880005
Validation loss: 4.4758840227615595

Epoch: 5| Step: 11
Training loss: 5.1354191633712345
Validation loss: 4.470282889708866

Epoch: 21| Step: 0
Training loss: 4.217672026630183
Validation loss: 4.46575214515533

Epoch: 5| Step: 1
Training loss: 5.284022038254273
Validation loss: 4.4609296835381596

Epoch: 5| Step: 2
Training loss: 5.053999935124483
Validation loss: 4.454590932030632

Epoch: 5| Step: 3
Training loss: 4.651720134920312
Validation loss: 4.448608535213772

Epoch: 5| Step: 4
Training loss: 4.045013588787024
Validation loss: 4.443390612370166

Epoch: 5| Step: 5
Training loss: 4.476247619952113
Validation loss: 4.438033139076299

Epoch: 5| Step: 6
Training loss: 5.003289857015137
Validation loss: 4.432028432784992

Epoch: 5| Step: 7
Training loss: 4.6540708627064085
Validation loss: 4.426368775388703

Epoch: 5| Step: 8
Training loss: 4.149311210738425
Validation loss: 4.420578468854861

Epoch: 5| Step: 9
Training loss: 3.5360047054604684
Validation loss: 4.416037067787

Epoch: 5| Step: 10
Training loss: 4.734860637672318
Validation loss: 4.411546828618247

Epoch: 5| Step: 11
Training loss: 5.296443235191284
Validation loss: 4.405140784500344

Epoch: 22| Step: 0
Training loss: 5.014244578887174
Validation loss: 4.398738446507299

Epoch: 5| Step: 1
Training loss: 4.259160435646578
Validation loss: 4.393849131450293

Epoch: 5| Step: 2
Training loss: 4.208435107722133
Validation loss: 4.390367167766023

Epoch: 5| Step: 3
Training loss: 4.146773239761484
Validation loss: 4.383100703028995

Epoch: 5| Step: 4
Training loss: 4.866713695211802
Validation loss: 4.377241786441225

Epoch: 5| Step: 5
Training loss: 4.500335257015538
Validation loss: 4.371720565384134

Epoch: 5| Step: 6
Training loss: 4.938045423296455
Validation loss: 4.367140094679493

Epoch: 5| Step: 7
Training loss: 4.109709403352612
Validation loss: 4.3611696302465806

Epoch: 5| Step: 8
Training loss: 3.98361258598643
Validation loss: 4.35558563668596

Epoch: 5| Step: 9
Training loss: 4.522572805346873
Validation loss: 4.349684761580561

Epoch: 5| Step: 10
Training loss: 4.852837092597488
Validation loss: 4.344001799313177

Epoch: 5| Step: 11
Training loss: 4.28303234561781
Validation loss: 4.338987506918509

Epoch: 23| Step: 0
Training loss: 4.4056248863978915
Validation loss: 4.332809002344439

Epoch: 5| Step: 1
Training loss: 3.4493840870268397
Validation loss: 4.327670306434404

Epoch: 5| Step: 2
Training loss: 5.120065127494966
Validation loss: 4.321487386574228

Epoch: 5| Step: 3
Training loss: 4.636749601703383
Validation loss: 4.315305456125869

Epoch: 5| Step: 4
Training loss: 4.1322131813057315
Validation loss: 4.308913863721591

Epoch: 5| Step: 5
Training loss: 3.8759727487619813
Validation loss: 4.30367032106867

Epoch: 5| Step: 6
Training loss: 5.113355853160885
Validation loss: 4.297441664812618

Epoch: 5| Step: 7
Training loss: 4.114607695817247
Validation loss: 4.290497767263022

Epoch: 5| Step: 8
Training loss: 4.74286115157045
Validation loss: 4.283604570748851

Epoch: 5| Step: 9
Training loss: 4.179752527604547
Validation loss: 4.277155484450177

Epoch: 5| Step: 10
Training loss: 4.498577740872534
Validation loss: 4.270371308185241

Epoch: 5| Step: 11
Training loss: 5.310223259839075
Validation loss: 4.26361084872678

Epoch: 24| Step: 0
Training loss: 4.495196215597672
Validation loss: 4.257746084086062

Epoch: 5| Step: 1
Training loss: 4.197809992618873
Validation loss: 4.251995983033363

Epoch: 5| Step: 2
Training loss: 4.676110430533578
Validation loss: 4.24541217816572

Epoch: 5| Step: 3
Training loss: 4.164880267891746
Validation loss: 4.238966700943926

Epoch: 5| Step: 4
Training loss: 4.592900411710941
Validation loss: 4.231761073957096

Epoch: 5| Step: 5
Training loss: 3.652980418480939
Validation loss: 4.224897765440674

Epoch: 5| Step: 6
Training loss: 3.9681369578352124
Validation loss: 4.2176726625755085

Epoch: 5| Step: 7
Training loss: 3.915451442954724
Validation loss: 4.212301308259734

Epoch: 5| Step: 8
Training loss: 4.856076411970521
Validation loss: 4.206383294255595

Epoch: 5| Step: 9
Training loss: 4.589268373177777
Validation loss: 4.200066296114769

Epoch: 5| Step: 10
Training loss: 4.57594137877149
Validation loss: 4.1937084671594205

Epoch: 5| Step: 11
Training loss: 4.71842945349068
Validation loss: 4.18739882389651

Epoch: 25| Step: 0
Training loss: 3.894971633239795
Validation loss: 4.181812756182112

Epoch: 5| Step: 1
Training loss: 4.770190444119495
Validation loss: 4.176866590754079

Epoch: 5| Step: 2
Training loss: 3.80492849977062
Validation loss: 4.169878344937704

Epoch: 5| Step: 3
Training loss: 4.277808595246341
Validation loss: 4.162821572285797

Epoch: 5| Step: 4
Training loss: 3.147211863302534
Validation loss: 4.156830223712992

Epoch: 5| Step: 5
Training loss: 3.8072407202001677
Validation loss: 4.151062359473114

Epoch: 5| Step: 6
Training loss: 3.872357113235653
Validation loss: 4.146006923983813

Epoch: 5| Step: 7
Training loss: 5.32348753175326
Validation loss: 4.14070232007272

Epoch: 5| Step: 8
Training loss: 4.521869921467215
Validation loss: 4.134570045512629

Epoch: 5| Step: 9
Training loss: 5.097764007481767
Validation loss: 4.128925748097538

Epoch: 5| Step: 10
Training loss: 3.97028243148449
Validation loss: 4.123123320029418

Epoch: 5| Step: 11
Training loss: 4.851245421338888
Validation loss: 4.116887911103622

Epoch: 26| Step: 0
Training loss: 4.216150910168474
Validation loss: 4.1113130377389195

Epoch: 5| Step: 1
Training loss: 4.4002588542742735
Validation loss: 4.1054238348094

Epoch: 5| Step: 2
Training loss: 4.6734763370533985
Validation loss: 4.098907022829605

Epoch: 5| Step: 3
Training loss: 3.578333552916801
Validation loss: 4.093330939395237

Epoch: 5| Step: 4
Training loss: 4.512990004545538
Validation loss: 4.087759002155841

Epoch: 5| Step: 5
Training loss: 3.610065344644407
Validation loss: 4.0818214715475305

Epoch: 5| Step: 6
Training loss: 3.722355609294128
Validation loss: 4.07574096507688

Epoch: 5| Step: 7
Training loss: 4.058209075174313
Validation loss: 4.07002158171753

Epoch: 5| Step: 8
Training loss: 4.289713936896071
Validation loss: 4.064769414216771

Epoch: 5| Step: 9
Training loss: 5.070435509269604
Validation loss: 4.058968872710327

Epoch: 5| Step: 10
Training loss: 4.091099703808137
Validation loss: 4.053585453981463

Epoch: 5| Step: 11
Training loss: 3.512406567182745
Validation loss: 4.04759220754182

Epoch: 27| Step: 0
Training loss: 4.472517439508101
Validation loss: 4.042204023144835

Epoch: 5| Step: 1
Training loss: 4.342433812367775
Validation loss: 4.036668684205786

Epoch: 5| Step: 2
Training loss: 4.61514304091281
Validation loss: 4.031647625615758

Epoch: 5| Step: 3
Training loss: 4.247572710605995
Validation loss: 4.025417322239639

Epoch: 5| Step: 4
Training loss: 4.675206658186665
Validation loss: 4.020275811923578

Epoch: 5| Step: 5
Training loss: 4.33649041027063
Validation loss: 4.014141090606712

Epoch: 5| Step: 6
Training loss: 3.419421566238397
Validation loss: 4.008918099101952

Epoch: 5| Step: 7
Training loss: 4.598358541440061
Validation loss: 4.003168083314441

Epoch: 5| Step: 8
Training loss: 3.9016273917842654
Validation loss: 3.9981159750255286

Epoch: 5| Step: 9
Training loss: 2.9909534748301643
Validation loss: 3.9928064333100903

Epoch: 5| Step: 10
Training loss: 3.8606937024261114
Validation loss: 3.987682799530962

Epoch: 5| Step: 11
Training loss: 3.2689854611843367
Validation loss: 3.982193293426186

Epoch: 28| Step: 0
Training loss: 3.862520858560184
Validation loss: 3.976819947508311

Epoch: 5| Step: 1
Training loss: 4.040667039928367
Validation loss: 3.972383502910892

Epoch: 5| Step: 2
Training loss: 3.5763061431563203
Validation loss: 3.967556756528445

Epoch: 5| Step: 3
Training loss: 4.088788935803345
Validation loss: 3.9622440628526205

Epoch: 5| Step: 4
Training loss: 4.560815996810516
Validation loss: 3.9570759566437372

Epoch: 5| Step: 5
Training loss: 4.231465258398352
Validation loss: 3.9520635825900183

Epoch: 5| Step: 6
Training loss: 4.289627677215222
Validation loss: 3.947066115632356

Epoch: 5| Step: 7
Training loss: 4.462038134868034
Validation loss: 3.941364566619108

Epoch: 5| Step: 8
Training loss: 4.17441415845196
Validation loss: 3.9361936884874287

Epoch: 5| Step: 9
Training loss: 3.147074439842062
Validation loss: 3.931018530617021

Epoch: 5| Step: 10
Training loss: 4.330576729017534
Validation loss: 3.9260273212600256

Epoch: 5| Step: 11
Training loss: 3.9269572000796398
Validation loss: 3.9218775431306856

Epoch: 29| Step: 0
Training loss: 3.176495123438107
Validation loss: 3.915867062713148

Epoch: 5| Step: 1
Training loss: 4.811288259963124
Validation loss: 3.9107071688173174

Epoch: 5| Step: 2
Training loss: 4.720991196087444
Validation loss: 3.9055238481147643

Epoch: 5| Step: 3
Training loss: 2.8680431949655985
Validation loss: 3.9005452932306612

Epoch: 5| Step: 4
Training loss: 3.8170756413812876
Validation loss: 3.8958441620266537

Epoch: 5| Step: 5
Training loss: 3.9817945314562455
Validation loss: 3.8909183937988274

Epoch: 5| Step: 6
Training loss: 4.125728427264935
Validation loss: 3.8859397375869595

Epoch: 5| Step: 7
Training loss: 3.7248897356956516
Validation loss: 3.881213620763249

Epoch: 5| Step: 8
Training loss: 3.982354104146871
Validation loss: 3.876436685009071

Epoch: 5| Step: 9
Training loss: 3.482939146331141
Validation loss: 3.8711811752532497

Epoch: 5| Step: 10
Training loss: 5.089430586586157
Validation loss: 3.8661209485246992

Epoch: 5| Step: 11
Training loss: 3.484901285839514
Validation loss: 3.860962416433256

Epoch: 30| Step: 0
Training loss: 4.125107734891647
Validation loss: 3.8564757913180547

Epoch: 5| Step: 1
Training loss: 3.8754606896007378
Validation loss: 3.8512392817629473

Epoch: 5| Step: 2
Training loss: 3.8178313453635724
Validation loss: 3.846630201031898

Epoch: 5| Step: 3
Training loss: 3.5111991998698953
Validation loss: 3.8413082058311026

Epoch: 5| Step: 4
Training loss: 4.308180041263867
Validation loss: 3.837099757741196

Epoch: 5| Step: 5
Training loss: 3.7611552575990714
Validation loss: 3.8314422351761084

Epoch: 5| Step: 6
Training loss: 4.223420221347725
Validation loss: 3.827171487196155

Epoch: 5| Step: 7
Training loss: 3.5559904623944276
Validation loss: 3.821775929707534

Epoch: 5| Step: 8
Training loss: 4.3269550380993556
Validation loss: 3.817441218851469

Epoch: 5| Step: 9
Training loss: 4.340257516771286
Validation loss: 3.8127707713544776

Epoch: 5| Step: 10
Training loss: 3.708780854613989
Validation loss: 3.807511114153104

Epoch: 5| Step: 11
Training loss: 3.749378661497134
Validation loss: 3.8023272065983087

Epoch: 31| Step: 0
Training loss: 3.7353154358955614
Validation loss: 3.7978404195263535

Epoch: 5| Step: 1
Training loss: 3.67787828938749
Validation loss: 3.792465312742974

Epoch: 5| Step: 2
Training loss: 3.6187908005596747
Validation loss: 3.787948255797812

Epoch: 5| Step: 3
Training loss: 4.233449011195896
Validation loss: 3.7834338772783367

Epoch: 5| Step: 4
Training loss: 3.8474523809806374
Validation loss: 3.778705350204262

Epoch: 5| Step: 5
Training loss: 3.754648252386035
Validation loss: 3.7739918724771737

Epoch: 5| Step: 6
Training loss: 4.2873106889664045
Validation loss: 3.768919905401143

Epoch: 5| Step: 7
Training loss: 4.239011358844777
Validation loss: 3.7644171828882675

Epoch: 5| Step: 8
Training loss: 3.5543040980563214
Validation loss: 3.7587724386157975

Epoch: 5| Step: 9
Training loss: 3.7744091354673532
Validation loss: 3.7547601211008104

Epoch: 5| Step: 10
Training loss: 4.270719846132545
Validation loss: 3.7499292208031916

Epoch: 5| Step: 11
Training loss: 3.3199859099491285
Validation loss: 3.7450867361118045

Epoch: 32| Step: 0
Training loss: 3.9832933341429473
Validation loss: 3.7397406853995636

Epoch: 5| Step: 1
Training loss: 4.265641544295984
Validation loss: 3.734880022192715

Epoch: 5| Step: 2
Training loss: 3.3856244458723963
Validation loss: 3.730160584295515

Epoch: 5| Step: 3
Training loss: 3.6226322728577607
Validation loss: 3.725451759065298

Epoch: 5| Step: 4
Training loss: 3.8250120624027915
Validation loss: 3.7209292632605804

Epoch: 5| Step: 5
Training loss: 3.449214602648271
Validation loss: 3.7165704158043367

Epoch: 5| Step: 6
Training loss: 3.7384876285933473
Validation loss: 3.7110332382969617

Epoch: 5| Step: 7
Training loss: 4.0136193636315545
Validation loss: 3.7063298528259065

Epoch: 5| Step: 8
Training loss: 3.921439948401722
Validation loss: 3.7017679692324283

Epoch: 5| Step: 9
Training loss: 3.984349867797575
Validation loss: 3.697307789960617

Epoch: 5| Step: 10
Training loss: 3.8798603217555407
Validation loss: 3.6926551549585946

Epoch: 5| Step: 11
Training loss: 4.795368169148803
Validation loss: 3.6876426389014236

Epoch: 33| Step: 0
Training loss: 3.4646821785362363
Validation loss: 3.683294667750155

Epoch: 5| Step: 1
Training loss: 2.8412170867423314
Validation loss: 3.6790108298148954

Epoch: 5| Step: 2
Training loss: 4.051906918540167
Validation loss: 3.674962205541121

Epoch: 5| Step: 3
Training loss: 3.8730467518831926
Validation loss: 3.6705713216835214

Epoch: 5| Step: 4
Training loss: 4.322206492478471
Validation loss: 3.6650727322410233

Epoch: 5| Step: 5
Training loss: 3.9523841857349784
Validation loss: 3.659755460928806

Epoch: 5| Step: 6
Training loss: 4.026524812923894
Validation loss: 3.654978647930714

Epoch: 5| Step: 7
Training loss: 3.7760967101546696
Validation loss: 3.6496650542117655

Epoch: 5| Step: 8
Training loss: 4.001049619291202
Validation loss: 3.6451475188671423

Epoch: 5| Step: 9
Training loss: 3.436608909938069
Validation loss: 3.6406058664323915

Epoch: 5| Step: 10
Training loss: 3.888911471225627
Validation loss: 3.635392922193632

Epoch: 5| Step: 11
Training loss: 3.3161406753297817
Validation loss: 3.630204854313165

Epoch: 34| Step: 0
Training loss: 3.3867536672796312
Validation loss: 3.625658556432112

Epoch: 5| Step: 1
Training loss: 4.6051479807053255
Validation loss: 3.6211658842329086

Epoch: 5| Step: 2
Training loss: 3.906627301114353
Validation loss: 3.6158871218556317

Epoch: 5| Step: 3
Training loss: 3.2852228727173585
Validation loss: 3.611535063131027

Epoch: 5| Step: 4
Training loss: 3.7823541463602757
Validation loss: 3.607109272452934

Epoch: 5| Step: 5
Training loss: 4.151646179573376
Validation loss: 3.602366387384298

Epoch: 5| Step: 6
Training loss: 3.841063266017602
Validation loss: 3.5978804362110566

Epoch: 5| Step: 7
Training loss: 3.514818158282305
Validation loss: 3.5931204783500266

Epoch: 5| Step: 8
Training loss: 2.9633449138276338
Validation loss: 3.5882954321520857

Epoch: 5| Step: 9
Training loss: 4.23063962244366
Validation loss: 3.5832744563980405

Epoch: 5| Step: 10
Training loss: 3.465073432749751
Validation loss: 3.5786672400630666

Epoch: 5| Step: 11
Training loss: 1.7101608673632847
Validation loss: 3.574674105517558

Epoch: 35| Step: 0
Training loss: 3.507967735203046
Validation loss: 3.570314475517366

Epoch: 5| Step: 1
Training loss: 4.061648000727232
Validation loss: 3.565683604323547

Epoch: 5| Step: 2
Training loss: 3.662583042283953
Validation loss: 3.561323992387977

Epoch: 5| Step: 3
Training loss: 3.841943952327351
Validation loss: 3.557284240193618

Epoch: 5| Step: 4
Training loss: 3.4461895784291428
Validation loss: 3.552904110643215

Epoch: 5| Step: 5
Training loss: 3.6304802083572807
Validation loss: 3.548786527690448

Epoch: 5| Step: 6
Training loss: 4.1642864804032325
Validation loss: 3.5448712698246743

Epoch: 5| Step: 7
Training loss: 2.9831334272641645
Validation loss: 3.540207375219295

Epoch: 5| Step: 8
Training loss: 4.227010593882042
Validation loss: 3.536082811975693

Epoch: 5| Step: 9
Training loss: 3.5649912639580434
Validation loss: 3.5317095342185447

Epoch: 5| Step: 10
Training loss: 3.25911154336009
Validation loss: 3.5270076350774886

Epoch: 5| Step: 11
Training loss: 3.716545028292629
Validation loss: 3.522881514052223

Epoch: 36| Step: 0
Training loss: 3.348875306772783
Validation loss: 3.5186346551251613

Epoch: 5| Step: 1
Training loss: 3.7128318047517284
Validation loss: 3.514969811316659

Epoch: 5| Step: 2
Training loss: 3.236987841536462
Validation loss: 3.5107491936611535

Epoch: 5| Step: 3
Training loss: 4.00964979625995
Validation loss: 3.506626605538124

Epoch: 5| Step: 4
Training loss: 3.1212697462894106
Validation loss: 3.5023780248687837

Epoch: 5| Step: 5
Training loss: 3.5560345790627843
Validation loss: 3.4982597730731757

Epoch: 5| Step: 6
Training loss: 4.267766282322328
Validation loss: 3.4938895894270603

Epoch: 5| Step: 7
Training loss: 3.5521026938946503
Validation loss: 3.4895401377874964

Epoch: 5| Step: 8
Training loss: 3.3691918587590006
Validation loss: 3.485195325643641

Epoch: 5| Step: 9
Training loss: 3.5787194437047574
Validation loss: 3.4807371698919485

Epoch: 5| Step: 10
Training loss: 3.781130954350208
Validation loss: 3.4769070229571946

Epoch: 5| Step: 11
Training loss: 4.9225709453408655
Validation loss: 3.4729513723053893

Epoch: 37| Step: 0
Training loss: 3.4901608724598088
Validation loss: 3.4684072044463883

Epoch: 5| Step: 1
Training loss: 3.7042781788733214
Validation loss: 3.464494936364543

Epoch: 5| Step: 2
Training loss: 4.092147396979184
Validation loss: 3.4602040991277883

Epoch: 5| Step: 3
Training loss: 3.8484902034841504
Validation loss: 3.4562556314451247

Epoch: 5| Step: 4
Training loss: 4.0537677522894615
Validation loss: 3.451582602998862

Epoch: 5| Step: 5
Training loss: 2.9206511030249036
Validation loss: 3.447120872390603

Epoch: 5| Step: 6
Training loss: 3.8201584736172665
Validation loss: 3.4428403985820992

Epoch: 5| Step: 7
Training loss: 3.7913028975713368
Validation loss: 3.43833789439291

Epoch: 5| Step: 8
Training loss: 3.4361115859523133
Validation loss: 3.4340694996238894

Epoch: 5| Step: 9
Training loss: 2.617627462728486
Validation loss: 3.429768641735061

Epoch: 5| Step: 10
Training loss: 3.1793749606457022
Validation loss: 3.42596340528861

Epoch: 5| Step: 11
Training loss: 4.392879029683562
Validation loss: 3.4214511446256055

Epoch: 38| Step: 0
Training loss: 3.9155144044886123
Validation loss: 3.417177918997335

Epoch: 5| Step: 1
Training loss: 3.429817075606094
Validation loss: 3.412936789583285

Epoch: 5| Step: 2
Training loss: 3.347079321913751
Validation loss: 3.40931074185048

Epoch: 5| Step: 3
Training loss: 3.9327961511768477
Validation loss: 3.4053328151283027

Epoch: 5| Step: 4
Training loss: 3.630323644454964
Validation loss: 3.400035789245284

Epoch: 5| Step: 5
Training loss: 3.247422883819189
Validation loss: 3.395444559102954

Epoch: 5| Step: 6
Training loss: 3.395749908233823
Validation loss: 3.391016473159593

Epoch: 5| Step: 7
Training loss: 3.7931568165914133
Validation loss: 3.386899609633248

Epoch: 5| Step: 8
Training loss: 2.8484732838536724
Validation loss: 3.382405909300764

Epoch: 5| Step: 9
Training loss: 4.039830029755153
Validation loss: 3.3787452203677053

Epoch: 5| Step: 10
Training loss: 3.3123288380288862
Validation loss: 3.37484846834575

Epoch: 5| Step: 11
Training loss: 2.5008883805166073
Validation loss: 3.3713330669775115

Epoch: 39| Step: 0
Training loss: 2.7336385552636573
Validation loss: 3.366927825048798

Epoch: 5| Step: 1
Training loss: 3.979137613613192
Validation loss: 3.363091930535672

Epoch: 5| Step: 2
Training loss: 3.229599084921937
Validation loss: 3.359445509059743

Epoch: 5| Step: 3
Training loss: 3.6469037183139146
Validation loss: 3.3555598692536432

Epoch: 5| Step: 4
Training loss: 3.5725121598140213
Validation loss: 3.3513813696039736

Epoch: 5| Step: 5
Training loss: 3.0552865536120533
Validation loss: 3.3470886829500786

Epoch: 5| Step: 6
Training loss: 3.9588583882426485
Validation loss: 3.3433975022041356

Epoch: 5| Step: 7
Training loss: 3.4581175740664016
Validation loss: 3.3393601779464817

Epoch: 5| Step: 8
Training loss: 3.40439394157551
Validation loss: 3.335603654104713

Epoch: 5| Step: 9
Training loss: 3.2264114603154512
Validation loss: 3.33147886765192

Epoch: 5| Step: 10
Training loss: 3.5374304774701324
Validation loss: 3.3283560468204003

Epoch: 5| Step: 11
Training loss: 4.9553918314422924
Validation loss: 3.3242105677407228

Epoch: 40| Step: 0
Training loss: 4.34107548550467
Validation loss: 3.3198867494970874

Epoch: 5| Step: 1
Training loss: 3.8575621760481886
Validation loss: 3.315708112379086

Epoch: 5| Step: 2
Training loss: 3.569299733699771
Validation loss: 3.3114029429217964

Epoch: 5| Step: 3
Training loss: 3.2300329871604303
Validation loss: 3.307209639645915

Epoch: 5| Step: 4
Training loss: 3.0527551495314396
Validation loss: 3.3031451366319637

Epoch: 5| Step: 5
Training loss: 3.6543418926359266
Validation loss: 3.2995377525100165

Epoch: 5| Step: 6
Training loss: 2.9649479663007736
Validation loss: 3.294393946743271

Epoch: 5| Step: 7
Training loss: 3.852796128741249
Validation loss: 3.290574095677343

Epoch: 5| Step: 8
Training loss: 3.4328008263467162
Validation loss: 3.28662635305208

Epoch: 5| Step: 9
Training loss: 2.921644885135575
Validation loss: 3.282293662350378

Epoch: 5| Step: 10
Training loss: 2.7434918814445663
Validation loss: 3.2786431447634934

Epoch: 5| Step: 11
Training loss: 2.8426315287922717
Validation loss: 3.2751404877734656

Epoch: 41| Step: 0
Training loss: 3.186225935679358
Validation loss: 3.271488462227313

Epoch: 5| Step: 1
Training loss: 3.681166948764385
Validation loss: 3.2679136065643415

Epoch: 5| Step: 2
Training loss: 3.690498038489484
Validation loss: 3.2641169794118716

Epoch: 5| Step: 3
Training loss: 3.453717763434837
Validation loss: 3.2606859806864463

Epoch: 5| Step: 4
Training loss: 3.8440205548597266
Validation loss: 3.257242840574901

Epoch: 5| Step: 5
Training loss: 3.2402376125473578
Validation loss: 3.252711311369428

Epoch: 5| Step: 6
Training loss: 2.8795142185279428
Validation loss: 3.2490398229612545

Epoch: 5| Step: 7
Training loss: 3.108883919586556
Validation loss: 3.245947986425598

Epoch: 5| Step: 8
Training loss: 3.420161963749139
Validation loss: 3.24260879904656

Epoch: 5| Step: 9
Training loss: 2.954870444877119
Validation loss: 3.2387995932023683

Epoch: 5| Step: 10
Training loss: 3.422695113890714
Validation loss: 3.2361843159290213

Epoch: 5| Step: 11
Training loss: 4.682424824157534
Validation loss: 3.233293490721501

Epoch: 42| Step: 0
Training loss: 2.7687147736730346
Validation loss: 3.2283807885209455

Epoch: 5| Step: 1
Training loss: 3.183519158922951
Validation loss: 3.224562772664027

Epoch: 5| Step: 2
Training loss: 3.366332899362607
Validation loss: 3.219906537440069

Epoch: 5| Step: 3
Training loss: 3.377378826325414
Validation loss: 3.2167193664588734

Epoch: 5| Step: 4
Training loss: 3.608236157971356
Validation loss: 3.213130019833949

Epoch: 5| Step: 5
Training loss: 3.0117219165434066
Validation loss: 3.209652317871824

Epoch: 5| Step: 6
Training loss: 3.546893014736052
Validation loss: 3.205963130359754

Epoch: 5| Step: 7
Training loss: 3.6511950639759903
Validation loss: 3.2026049059903556

Epoch: 5| Step: 8
Training loss: 3.7717039813798667
Validation loss: 3.1987107261312824

Epoch: 5| Step: 9
Training loss: 3.2964193743406374
Validation loss: 3.1951323180939593

Epoch: 5| Step: 10
Training loss: 3.0919921196446047
Validation loss: 3.1915349043365246

Epoch: 5| Step: 11
Training loss: 3.5390827102589326
Validation loss: 3.188403705818008

Epoch: 43| Step: 0
Training loss: 3.296017069624245
Validation loss: 3.184508602944683

Epoch: 5| Step: 1
Training loss: 3.419630037117945
Validation loss: 3.1810501921484517

Epoch: 5| Step: 2
Training loss: 2.6429709222228177
Validation loss: 3.1774345995887785

Epoch: 5| Step: 3
Training loss: 3.504716420149988
Validation loss: 3.1739819549058805

Epoch: 5| Step: 4
Training loss: 3.8372068460925726
Validation loss: 3.1719958653465157

Epoch: 5| Step: 5
Training loss: 3.508270709520127
Validation loss: 3.170094229759769

Epoch: 5| Step: 6
Training loss: 3.181844743394834
Validation loss: 3.164000390467517

Epoch: 5| Step: 7
Training loss: 2.998019836502667
Validation loss: 3.160266231451023

Epoch: 5| Step: 8
Training loss: 2.944244110041931
Validation loss: 3.156577864384405

Epoch: 5| Step: 9
Training loss: 3.3732847870913267
Validation loss: 3.1541010840151795

Epoch: 5| Step: 10
Training loss: 3.639748922219344
Validation loss: 3.151338044197207

Epoch: 5| Step: 11
Training loss: 2.5783466590614252
Validation loss: 3.148686603444525

Epoch: 44| Step: 0
Training loss: 2.897113837115324
Validation loss: 3.14625096338394

Epoch: 5| Step: 1
Training loss: 2.7748967160086124
Validation loss: 3.1448926382332987

Epoch: 5| Step: 2
Training loss: 3.57871264833604
Validation loss: 3.1408327328128163

Epoch: 5| Step: 3
Training loss: 3.4900899642672822
Validation loss: 3.1376848391815106

Epoch: 5| Step: 4
Training loss: 2.980298358651293
Validation loss: 3.133855818792999

Epoch: 5| Step: 5
Training loss: 3.7531586377925743
Validation loss: 3.1301890270549664

Epoch: 5| Step: 6
Training loss: 3.451661365037718
Validation loss: 3.1290139613540577

Epoch: 5| Step: 7
Training loss: 3.6151845177376547
Validation loss: 3.126465355315378

Epoch: 5| Step: 8
Training loss: 3.039601256169761
Validation loss: 3.119992516643157

Epoch: 5| Step: 9
Training loss: 2.9644136581779525
Validation loss: 3.1168150906401633

Epoch: 5| Step: 10
Training loss: 3.2100600182932597
Validation loss: 3.114856661197415

Epoch: 5| Step: 11
Training loss: 3.6033263945064262
Validation loss: 3.1133937296856447

Epoch: 45| Step: 0
Training loss: 3.1189301096676885
Validation loss: 3.1119302189806852

Epoch: 5| Step: 1
Training loss: 3.7295059958994177
Validation loss: 3.1093375684571365

Epoch: 5| Step: 2
Training loss: 3.1020476684842913
Validation loss: 3.1039059079286297

Epoch: 5| Step: 3
Training loss: 3.1138492769626973
Validation loss: 3.0992682336745427

Epoch: 5| Step: 4
Training loss: 2.9118920800992987
Validation loss: 3.0954208806933026

Epoch: 5| Step: 5
Training loss: 3.4721143748170973
Validation loss: 3.092723014508036

Epoch: 5| Step: 6
Training loss: 3.8295234461384258
Validation loss: 3.090190458076079

Epoch: 5| Step: 7
Training loss: 2.832522687694867
Validation loss: 3.0874184865397294

Epoch: 5| Step: 8
Training loss: 3.4949103542285944
Validation loss: 3.0844249575716525

Epoch: 5| Step: 9
Training loss: 2.9918856555692392
Validation loss: 3.081069838239253

Epoch: 5| Step: 10
Training loss: 2.8674565742483695
Validation loss: 3.0775261633716586

Epoch: 5| Step: 11
Training loss: 2.9342813917672887
Validation loss: 3.0750443361027244

Epoch: 46| Step: 0
Training loss: 3.092147412071578
Validation loss: 3.071450932396002

Epoch: 5| Step: 1
Training loss: 3.5786690777241317
Validation loss: 3.068356784922257

Epoch: 5| Step: 2
Training loss: 3.4292264380794464
Validation loss: 3.0648330281180534

Epoch: 5| Step: 3
Training loss: 3.0403503983988336
Validation loss: 3.0618671554856354

Epoch: 5| Step: 4
Training loss: 2.991325074850638
Validation loss: 3.05842767867902

Epoch: 5| Step: 5
Training loss: 2.826664500085732
Validation loss: 3.055656871175589

Epoch: 5| Step: 6
Training loss: 3.560768375841316
Validation loss: 3.0538380963077163

Epoch: 5| Step: 7
Training loss: 2.8053905912776043
Validation loss: 3.053546032073624

Epoch: 5| Step: 8
Training loss: 3.457105456918951
Validation loss: 3.0520523002444233

Epoch: 5| Step: 9
Training loss: 2.9033114436040117
Validation loss: 3.0430550977202717

Epoch: 5| Step: 10
Training loss: 3.2254867422966482
Validation loss: 3.0399238294179303

Epoch: 5| Step: 11
Training loss: 3.8706522515642066
Validation loss: 3.037995285893789

Epoch: 47| Step: 0
Training loss: 3.0144980108545916
Validation loss: 3.035116515355691

Epoch: 5| Step: 1
Training loss: 3.3865120548589633
Validation loss: 3.0321243965108593

Epoch: 5| Step: 2
Training loss: 3.597903032982019
Validation loss: 3.029465363024905

Epoch: 5| Step: 3
Training loss: 3.3550483697852456
Validation loss: 3.026539849633266

Epoch: 5| Step: 4
Training loss: 3.3459902950221365
Validation loss: 3.0231878652365856

Epoch: 5| Step: 5
Training loss: 2.7849091879046055
Validation loss: 3.020122830375112

Epoch: 5| Step: 6
Training loss: 3.0467926796771994
Validation loss: 3.0171148312821083

Epoch: 5| Step: 7
Training loss: 3.1382485883483655
Validation loss: 3.014182257889246

Epoch: 5| Step: 8
Training loss: 2.9160375370702174
Validation loss: 3.0118046512054626

Epoch: 5| Step: 9
Training loss: 2.7983601638783036
Validation loss: 3.0096217143124324

Epoch: 5| Step: 10
Training loss: 3.4003102721964344
Validation loss: 3.0062014967772064

Epoch: 5| Step: 11
Training loss: 2.496478652529723
Validation loss: 3.0034093590529625

Epoch: 48| Step: 0
Training loss: 2.9634696178471818
Validation loss: 3.0001511005920123

Epoch: 5| Step: 1
Training loss: 3.3612451360233933
Validation loss: 3.011372679516326

Epoch: 5| Step: 2
Training loss: 3.1717263172799246
Validation loss: 2.9970795403491044

Epoch: 5| Step: 3
Training loss: 2.69201192698451
Validation loss: 2.9935030655504056

Epoch: 5| Step: 4
Training loss: 3.1229085408504362
Validation loss: 2.991125726850895

Epoch: 5| Step: 5
Training loss: 3.2127748601864545
Validation loss: 2.990060121395357

Epoch: 5| Step: 6
Training loss: 2.8549720760122277
Validation loss: 2.988276868497009

Epoch: 5| Step: 7
Training loss: 2.651162155401091
Validation loss: 2.986814147905127

Epoch: 5| Step: 8
Training loss: 3.647688794966187
Validation loss: 2.9853140467070003

Epoch: 5| Step: 9
Training loss: 3.586339192549432
Validation loss: 2.9819441177234927

Epoch: 5| Step: 10
Training loss: 3.268318051450472
Validation loss: 2.9789653667830494

Epoch: 5| Step: 11
Training loss: 1.4026364841791648
Validation loss: 2.9763272009733788

Epoch: 49| Step: 0
Training loss: 2.758772988061577
Validation loss: 2.973747327214617

Epoch: 5| Step: 1
Training loss: 3.135900179227973
Validation loss: 2.9709153794457253

Epoch: 5| Step: 2
Training loss: 3.4279622320099903
Validation loss: 2.9685239103458496

Epoch: 5| Step: 3
Training loss: 3.6130492429737684
Validation loss: 2.9652749218407086

Epoch: 5| Step: 4
Training loss: 3.0473898428205697
Validation loss: 2.9626566040721274

Epoch: 5| Step: 5
Training loss: 2.7811485014836386
Validation loss: 2.9594203581618643

Epoch: 5| Step: 6
Training loss: 3.13431275325895
Validation loss: 2.9565762800150837

Epoch: 5| Step: 7
Training loss: 3.1327421794048216
Validation loss: 2.953632082453369

Epoch: 5| Step: 8
Training loss: 3.2850012272058806
Validation loss: 2.9507914040595895

Epoch: 5| Step: 9
Training loss: 3.243951597913337
Validation loss: 2.9486597402939623

Epoch: 5| Step: 10
Training loss: 2.4561375871322495
Validation loss: 2.946122716604319

Epoch: 5| Step: 11
Training loss: 2.7969846224479764
Validation loss: 2.94340952843368

Epoch: 50| Step: 0
Training loss: 3.739648774122563
Validation loss: 2.940465218489706

Epoch: 5| Step: 1
Training loss: 3.3105206603866226
Validation loss: 2.938246375149712

Epoch: 5| Step: 2
Training loss: 2.8607692966985483
Validation loss: 2.9350176495124827

Epoch: 5| Step: 3
Training loss: 2.793757912712071
Validation loss: 2.9331051503822625

Epoch: 5| Step: 4
Training loss: 3.2324217274830027
Validation loss: 2.929901342428945

Epoch: 5| Step: 5
Training loss: 3.140788515303724
Validation loss: 2.927542122196607

Epoch: 5| Step: 6
Training loss: 3.251515255336883
Validation loss: 2.9247214652031186

Epoch: 5| Step: 7
Training loss: 2.6905221137424893
Validation loss: 2.9220072704438405

Epoch: 5| Step: 8
Training loss: 2.6607564957544887
Validation loss: 2.919971668920293

Epoch: 5| Step: 9
Training loss: 2.818184342900597
Validation loss: 2.9178296506683465

Epoch: 5| Step: 10
Training loss: 3.200446222903269
Validation loss: 2.915344334756791

Epoch: 5| Step: 11
Training loss: 2.537723129309081
Validation loss: 2.9128651924825433

Epoch: 51| Step: 0
Training loss: 3.368670143780429
Validation loss: 2.910615977728678

Epoch: 5| Step: 1
Training loss: 3.4340186783777495
Validation loss: 2.9083222176322088

Epoch: 5| Step: 2
Training loss: 2.712811440725903
Validation loss: 2.9053832508351807

Epoch: 5| Step: 3
Training loss: 3.028943787096926
Validation loss: 2.9032050044735622

Epoch: 5| Step: 4
Training loss: 3.0152420037918457
Validation loss: 2.9011783921481142

Epoch: 5| Step: 5
Training loss: 2.6330663179477067
Validation loss: 2.898482312921091

Epoch: 5| Step: 6
Training loss: 3.2351334276939663
Validation loss: 2.8964918792003194

Epoch: 5| Step: 7
Training loss: 2.6292912058244204
Validation loss: 2.89385009795731

Epoch: 5| Step: 8
Training loss: 3.4421140741732517
Validation loss: 2.891361482980239

Epoch: 5| Step: 9
Training loss: 3.2104537859401923
Validation loss: 2.889482220725885

Epoch: 5| Step: 10
Training loss: 2.7318847651886373
Validation loss: 2.8865716919975126

Epoch: 5| Step: 11
Training loss: 2.0430944342090376
Validation loss: 2.8845146412659957

Epoch: 52| Step: 0
Training loss: 3.191750030491284
Validation loss: 2.8824967760220774

Epoch: 5| Step: 1
Training loss: 3.3674806259266306
Validation loss: 2.8807525339088684

Epoch: 5| Step: 2
Training loss: 2.9642579476242803
Validation loss: 2.8793600372616805

Epoch: 5| Step: 3
Training loss: 2.8323252137304094
Validation loss: 2.8769842397781664

Epoch: 5| Step: 4
Training loss: 3.3750830746069123
Validation loss: 2.875235917598219

Epoch: 5| Step: 5
Training loss: 2.8996092697527933
Validation loss: 2.873890434606968

Epoch: 5| Step: 6
Training loss: 2.705818554182216
Validation loss: 2.8706271391421194

Epoch: 5| Step: 7
Training loss: 2.9696295790436484
Validation loss: 2.868487992577004

Epoch: 5| Step: 8
Training loss: 2.988959022401889
Validation loss: 2.8662522823681225

Epoch: 5| Step: 9
Training loss: 2.865440397650133
Validation loss: 2.8640790819186503

Epoch: 5| Step: 10
Training loss: 3.020139645259417
Validation loss: 2.862594442322696

Epoch: 5| Step: 11
Training loss: 2.49667213198272
Validation loss: 2.859453200224608

Epoch: 53| Step: 0
Training loss: 3.3958772683763176
Validation loss: 2.858153820703074

Epoch: 5| Step: 1
Training loss: 3.152660330341393
Validation loss: 2.8599599333770933

Epoch: 5| Step: 2
Training loss: 2.5419997846421722
Validation loss: 2.8559839850993156

Epoch: 5| Step: 3
Training loss: 2.9649656569757936
Validation loss: 2.855630931779903

Epoch: 5| Step: 4
Training loss: 2.4329877316204405
Validation loss: 2.851655368076536

Epoch: 5| Step: 5
Training loss: 2.81067013022929
Validation loss: 2.850201481395295

Epoch: 5| Step: 6
Training loss: 3.062763124956732
Validation loss: 2.847689069812587

Epoch: 5| Step: 7
Training loss: 2.940026677847512
Validation loss: 2.84700758339502

Epoch: 5| Step: 8
Training loss: 2.755672932461228
Validation loss: 2.8465255076126943

Epoch: 5| Step: 9
Training loss: 3.5465864828792757
Validation loss: 2.8453529472346135

Epoch: 5| Step: 10
Training loss: 3.1923483084992967
Validation loss: 2.844980424317522

Epoch: 5| Step: 11
Training loss: 2.5963733688965713
Validation loss: 2.8444861936785673

Epoch: 54| Step: 0
Training loss: 3.2019057023353996
Validation loss: 2.843961295637546

Epoch: 5| Step: 1
Training loss: 2.7716718184223876
Validation loss: 2.8413889693793273

Epoch: 5| Step: 2
Training loss: 2.8487397737139566
Validation loss: 2.8386104027128103

Epoch: 5| Step: 3
Training loss: 2.429285341202621
Validation loss: 2.8353501859817793

Epoch: 5| Step: 4
Training loss: 3.305983124834713
Validation loss: 2.831976907142949

Epoch: 5| Step: 5
Training loss: 3.257407769326921
Validation loss: 2.8292096939991143

Epoch: 5| Step: 6
Training loss: 2.757496845454524
Validation loss: 2.8272644054322336

Epoch: 5| Step: 7
Training loss: 2.5661515990658907
Validation loss: 2.825137490609217

Epoch: 5| Step: 8
Training loss: 3.189245905221127
Validation loss: 2.82397432091743

Epoch: 5| Step: 9
Training loss: 3.3904176991460235
Validation loss: 2.8220672678512457

Epoch: 5| Step: 10
Training loss: 2.943717382942807
Validation loss: 2.8192861174042227

Epoch: 5| Step: 11
Training loss: 2.063694925665085
Validation loss: 2.818204625693235

Epoch: 55| Step: 0
Training loss: 3.254934526244975
Validation loss: 2.81623660990668

Epoch: 5| Step: 1
Training loss: 2.9944404904778428
Validation loss: 2.814893654084391

Epoch: 5| Step: 2
Training loss: 2.351982712824863
Validation loss: 2.8124481796859535

Epoch: 5| Step: 3
Training loss: 2.911173434071668
Validation loss: 2.812318213203989

Epoch: 5| Step: 4
Training loss: 3.3382604582728512
Validation loss: 2.810011548737498

Epoch: 5| Step: 5
Training loss: 3.1897906879885882
Validation loss: 2.8068034797978867

Epoch: 5| Step: 6
Training loss: 2.9601405538231917
Validation loss: 2.8049091262172783

Epoch: 5| Step: 7
Training loss: 2.977537781341968
Validation loss: 2.8031811791116574

Epoch: 5| Step: 8
Training loss: 2.7386241921205117
Validation loss: 2.801958866025754

Epoch: 5| Step: 9
Training loss: 2.584884475251598
Validation loss: 2.8003152754941967

Epoch: 5| Step: 10
Training loss: 2.8806640558787886
Validation loss: 2.797853128322942

Epoch: 5| Step: 11
Training loss: 3.3825278922296302
Validation loss: 2.7969921165680716

Epoch: 56| Step: 0
Training loss: 2.6474814700882137
Validation loss: 2.792753987625085

Epoch: 5| Step: 1
Training loss: 2.7340187930652085
Validation loss: 2.790684418083096

Epoch: 5| Step: 2
Training loss: 3.4726458142770644
Validation loss: 2.7873560246747013

Epoch: 5| Step: 3
Training loss: 3.499083535234312
Validation loss: 2.789805230585416

Epoch: 5| Step: 4
Training loss: 3.0217682718011907
Validation loss: 2.7827436708152096

Epoch: 5| Step: 5
Training loss: 3.1298189772643936
Validation loss: 2.781727767655736

Epoch: 5| Step: 6
Training loss: 2.6487065631496667
Validation loss: 2.7791874270447754

Epoch: 5| Step: 7
Training loss: 2.531621646677534
Validation loss: 2.7786599361177386

Epoch: 5| Step: 8
Training loss: 2.6785607819118535
Validation loss: 2.7768987736445223

Epoch: 5| Step: 9
Training loss: 2.9181560165185076
Validation loss: 2.774606288296132

Epoch: 5| Step: 10
Training loss: 2.663028281370735
Validation loss: 2.7725697803171987

Epoch: 5| Step: 11
Training loss: 3.1012271728659555
Validation loss: 2.7706930560023113

Epoch: 57| Step: 0
Training loss: 3.128936576934411
Validation loss: 2.7679215754057207

Epoch: 5| Step: 1
Training loss: 2.770914999157526
Validation loss: 2.7677859073765654

Epoch: 5| Step: 2
Training loss: 3.015029294961344
Validation loss: 2.7674142111025186

Epoch: 5| Step: 3
Training loss: 2.762132583971665
Validation loss: 2.764654829906537

Epoch: 5| Step: 4
Training loss: 3.109992804564956
Validation loss: 2.7649824218524657

Epoch: 5| Step: 5
Training loss: 2.8143655311989386
Validation loss: 2.7621842728939887

Epoch: 5| Step: 6
Training loss: 2.816679328874948
Validation loss: 2.762821320938672

Epoch: 5| Step: 7
Training loss: 3.1478325425896663
Validation loss: 2.760656718246835

Epoch: 5| Step: 8
Training loss: 2.673795489494496
Validation loss: 2.75798971743231

Epoch: 5| Step: 9
Training loss: 2.9250205340846573
Validation loss: 2.756490655370823

Epoch: 5| Step: 10
Training loss: 2.7617991218580418
Validation loss: 2.7537097076190324

Epoch: 5| Step: 11
Training loss: 2.7495376891893044
Validation loss: 2.7528096461886653

Epoch: 58| Step: 0
Training loss: 2.5175687495279755
Validation loss: 2.750378911327934

Epoch: 5| Step: 1
Training loss: 3.1824718534628857
Validation loss: 2.7564233589870355

Epoch: 5| Step: 2
Training loss: 2.8439966451139553
Validation loss: 2.7514465999365125

Epoch: 5| Step: 3
Training loss: 2.930803498380293
Validation loss: 2.746690394997723

Epoch: 5| Step: 4
Training loss: 2.4805098883153587
Validation loss: 2.746226423738519

Epoch: 5| Step: 5
Training loss: 2.9570264123350456
Validation loss: 2.7436566017608

Epoch: 5| Step: 6
Training loss: 2.9771623782926575
Validation loss: 2.742245594724312

Epoch: 5| Step: 7
Training loss: 2.981738458760291
Validation loss: 2.7425124726639227

Epoch: 5| Step: 8
Training loss: 2.8316931371441396
Validation loss: 2.744702319018658

Epoch: 5| Step: 9
Training loss: 3.081420992735763
Validation loss: 2.7391746104904438

Epoch: 5| Step: 10
Training loss: 2.9951173467048378
Validation loss: 2.736485696594562

Epoch: 5| Step: 11
Training loss: 2.091750827428509
Validation loss: 2.7330827184279944

Epoch: 59| Step: 0
Training loss: 2.985896975702899
Validation loss: 2.7337484350317727

Epoch: 5| Step: 1
Training loss: 3.349234103431685
Validation loss: 2.731660541869305

Epoch: 5| Step: 2
Training loss: 3.050276046517911
Validation loss: 2.7305479060947984

Epoch: 5| Step: 3
Training loss: 2.8790026458378275
Validation loss: 2.7306351144850276

Epoch: 5| Step: 4
Training loss: 3.110358001366962
Validation loss: 2.7278558911509023

Epoch: 5| Step: 5
Training loss: 2.621506500719193
Validation loss: 2.7270992592350685

Epoch: 5| Step: 6
Training loss: 2.626319735153609
Validation loss: 2.7248765566043995

Epoch: 5| Step: 7
Training loss: 2.5629527924737463
Validation loss: 2.7235624282147914

Epoch: 5| Step: 8
Training loss: 2.6689148505796836
Validation loss: 2.7208918396256374

Epoch: 5| Step: 9
Training loss: 3.007968967876255
Validation loss: 2.7190130771496923

Epoch: 5| Step: 10
Training loss: 2.6134814084524614
Validation loss: 2.7200139166146378

Epoch: 5| Step: 11
Training loss: 2.5466109999053383
Validation loss: 2.7225898176322705

Epoch: 60| Step: 0
Training loss: 3.158832060423902
Validation loss: 2.724498149465622

Epoch: 5| Step: 1
Training loss: 2.146444721220107
Validation loss: 2.713555785647006

Epoch: 5| Step: 2
Training loss: 2.577664790837975
Validation loss: 2.7122325900178885

Epoch: 5| Step: 3
Training loss: 2.760352588605599
Validation loss: 2.7110272703230938

Epoch: 5| Step: 4
Training loss: 2.8282007028131977
Validation loss: 2.710492272511252

Epoch: 5| Step: 5
Training loss: 3.2680741028899543
Validation loss: 2.7089535015375747

Epoch: 5| Step: 6
Training loss: 3.212858122223513
Validation loss: 2.7093738770033444

Epoch: 5| Step: 7
Training loss: 2.6449656728381075
Validation loss: 2.7083192580419757

Epoch: 5| Step: 8
Training loss: 2.536429392644962
Validation loss: 2.7072422372890643

Epoch: 5| Step: 9
Training loss: 2.8067935272807576
Validation loss: 2.704513876557961

Epoch: 5| Step: 10
Training loss: 3.1989674452007324
Validation loss: 2.7057448867962894

Epoch: 5| Step: 11
Training loss: 2.9900441274289196
Validation loss: 2.7026797352359444

Epoch: 61| Step: 0
Training loss: 2.7824793466793722
Validation loss: 2.700684973137558

Epoch: 5| Step: 1
Training loss: 2.6369041999308656
Validation loss: 2.697181313624407

Epoch: 5| Step: 2
Training loss: 2.3459684934915117
Validation loss: 2.694790750028329

Epoch: 5| Step: 3
Training loss: 3.227580134004939
Validation loss: 2.69583741020197

Epoch: 5| Step: 4
Training loss: 2.8291546543710915
Validation loss: 2.693803668981092

Epoch: 5| Step: 5
Training loss: 2.795999059488687
Validation loss: 2.6926601425275876

Epoch: 5| Step: 6
Training loss: 2.7429279946928653
Validation loss: 2.6992315686773054

Epoch: 5| Step: 7
Training loss: 3.291208178945939
Validation loss: 2.690558172113049

Epoch: 5| Step: 8
Training loss: 2.613680913040391
Validation loss: 2.685231530372975

Epoch: 5| Step: 9
Training loss: 3.041624426004096
Validation loss: 2.687250210738268

Epoch: 5| Step: 10
Training loss: 2.792780260248065
Validation loss: 2.693343898552609

Epoch: 5| Step: 11
Training loss: 2.087439407108822
Validation loss: 2.6891697420572154

Epoch: 62| Step: 0
Training loss: 3.3492338186876727
Validation loss: 2.699345193303692

Epoch: 5| Step: 1
Training loss: 3.15646633502103
Validation loss: 2.7058103449481017

Epoch: 5| Step: 2
Training loss: 2.9264922354064162
Validation loss: 2.6920975792425286

Epoch: 5| Step: 3
Training loss: 2.940390929616286
Validation loss: 2.687457993644848

Epoch: 5| Step: 4
Training loss: 3.0148962850113104
Validation loss: 2.6838495427827236

Epoch: 5| Step: 5
Training loss: 2.3756285387839293
Validation loss: 2.6815703906784965

Epoch: 5| Step: 6
Training loss: 2.507098990690454
Validation loss: 2.680519367845617

Epoch: 5| Step: 7
Training loss: 2.6389669596405914
Validation loss: 2.678127602183125

Epoch: 5| Step: 8
Training loss: 2.5625759206550534
Validation loss: 2.676127026717177

Epoch: 5| Step: 9
Training loss: 2.956284543373929
Validation loss: 2.6767090425684024

Epoch: 5| Step: 10
Training loss: 2.6883143588407705
Validation loss: 2.6744362116666562

Epoch: 5| Step: 11
Training loss: 1.9713779651275352
Validation loss: 2.671588603503614

Epoch: 63| Step: 0
Training loss: 3.196458084201577
Validation loss: 2.6700280035171993

Epoch: 5| Step: 1
Training loss: 2.6684568078825386
Validation loss: 2.668985587285049

Epoch: 5| Step: 2
Training loss: 2.662278727618326
Validation loss: 2.6645319125175155

Epoch: 5| Step: 3
Training loss: 2.8833010706630886
Validation loss: 2.6659780385554925

Epoch: 5| Step: 4
Training loss: 3.039031746912203
Validation loss: 2.663183341292593

Epoch: 5| Step: 5
Training loss: 2.9678892795238663
Validation loss: 2.6639388718543895

Epoch: 5| Step: 6
Training loss: 2.5772637055621246
Validation loss: 2.6624040932612214

Epoch: 5| Step: 7
Training loss: 2.8556020055902493
Validation loss: 2.6623444708767154

Epoch: 5| Step: 8
Training loss: 2.9407548119718756
Validation loss: 2.660967594349134

Epoch: 5| Step: 9
Training loss: 2.5908628274051266
Validation loss: 2.6601830927857097

Epoch: 5| Step: 10
Training loss: 2.5247291117479356
Validation loss: 2.6584406589399454

Epoch: 5| Step: 11
Training loss: 1.8985822332022069
Validation loss: 2.6560761189114483

Epoch: 64| Step: 0
Training loss: 2.7759254149715304
Validation loss: 2.6542381409244244

Epoch: 5| Step: 1
Training loss: 2.3639028188930293
Validation loss: 2.654330296665064

Epoch: 5| Step: 2
Training loss: 2.851390927522499
Validation loss: 2.653816761704982

Epoch: 5| Step: 3
Training loss: 2.697930079442759
Validation loss: 2.6583249496060692

Epoch: 5| Step: 4
Training loss: 2.7637555544420844
Validation loss: 2.6609414501388597

Epoch: 5| Step: 5
Training loss: 2.914546322990915
Validation loss: 2.657581522939109

Epoch: 5| Step: 6
Training loss: 2.7023244565400186
Validation loss: 2.655842989237811

Epoch: 5| Step: 7
Training loss: 3.0105079364250678
Validation loss: 2.6480261934340015

Epoch: 5| Step: 8
Training loss: 2.875308808037347
Validation loss: 2.642780988809925

Epoch: 5| Step: 9
Training loss: 2.8269251180149375
Validation loss: 2.644740300670709

Epoch: 5| Step: 10
Training loss: 2.8888100364715656
Validation loss: 2.645794959553462

Epoch: 5| Step: 11
Training loss: 2.233572435627578
Validation loss: 2.645032068008891

Epoch: 65| Step: 0
Training loss: 3.3453629070762267
Validation loss: 2.6435866892389828

Epoch: 5| Step: 1
Training loss: 2.927109868663549
Validation loss: 2.643985220483071

Epoch: 5| Step: 2
Training loss: 2.3064167324262375
Validation loss: 2.6462530544109013

Epoch: 5| Step: 3
Training loss: 2.435443303920025
Validation loss: 2.644196369374201

Epoch: 5| Step: 4
Training loss: 2.576923807233845
Validation loss: 2.642772008639737

Epoch: 5| Step: 5
Training loss: 3.2062096606239616
Validation loss: 2.6420442352466127

Epoch: 5| Step: 6
Training loss: 2.662701569569915
Validation loss: 2.6405495890546775

Epoch: 5| Step: 7
Training loss: 2.963959372279327
Validation loss: 2.640553543056969

Epoch: 5| Step: 8
Training loss: 2.546376185335956
Validation loss: 2.638128929270819

Epoch: 5| Step: 9
Training loss: 2.3969519173864744
Validation loss: 2.6353917566763165

Epoch: 5| Step: 10
Training loss: 2.9174663718932443
Validation loss: 2.6351723966114196

Epoch: 5| Step: 11
Training loss: 3.026794935132822
Validation loss: 2.6311708533554836

Epoch: 66| Step: 0
Training loss: 2.8922160950436755
Validation loss: 2.632370995726437

Epoch: 5| Step: 1
Training loss: 2.8720332885555644
Validation loss: 2.6297981502609473

Epoch: 5| Step: 2
Training loss: 2.6683785387729535
Validation loss: 2.6272191211982574

Epoch: 5| Step: 3
Training loss: 3.0028205963416257
Validation loss: 2.6269744286033783

Epoch: 5| Step: 4
Training loss: 2.6849440907317277
Validation loss: 2.6263811814755265

Epoch: 5| Step: 5
Training loss: 3.095117902343421
Validation loss: 2.62523935377215

Epoch: 5| Step: 6
Training loss: 2.328259150589179
Validation loss: 2.6221785292738877

Epoch: 5| Step: 7
Training loss: 2.6769249024372304
Validation loss: 2.6226985280653126

Epoch: 5| Step: 8
Training loss: 2.4159856253190015
Validation loss: 2.6207037615219724

Epoch: 5| Step: 9
Training loss: 2.7553863660168414
Validation loss: 2.6245076043148465

Epoch: 5| Step: 10
Training loss: 2.9139101535767495
Validation loss: 2.622467170106188

Epoch: 5| Step: 11
Training loss: 2.5461953783426763
Validation loss: 2.6194828387348332

Epoch: 67| Step: 0
Training loss: 2.337097798388458
Validation loss: 2.6173354225678285

Epoch: 5| Step: 1
Training loss: 3.2955383194466736
Validation loss: 2.615961404433799

Epoch: 5| Step: 2
Training loss: 2.5825444114093865
Validation loss: 2.6183493507250657

Epoch: 5| Step: 3
Training loss: 2.6982997980639465
Validation loss: 2.6180546021621365

Epoch: 5| Step: 4
Training loss: 2.2891219720503284
Validation loss: 2.6199469030559395

Epoch: 5| Step: 5
Training loss: 2.7873271597746965
Validation loss: 2.6212717480015755

Epoch: 5| Step: 6
Training loss: 2.920850931315028
Validation loss: 2.623635701971376

Epoch: 5| Step: 7
Training loss: 2.6070287515264194
Validation loss: 2.6232423763934483

Epoch: 5| Step: 8
Training loss: 2.8493203741495017
Validation loss: 2.623372712659724

Epoch: 5| Step: 9
Training loss: 3.1578683764210775
Validation loss: 2.620056807573116

Epoch: 5| Step: 10
Training loss: 2.523701090081319
Validation loss: 2.616848239450567

Epoch: 5| Step: 11
Training loss: 3.093444346732387
Validation loss: 2.615667651492214

Epoch: 68| Step: 0
Training loss: 2.4859052060161786
Validation loss: 2.6124310253170187

Epoch: 5| Step: 1
Training loss: 2.831794676271924
Validation loss: 2.6102343531880288

Epoch: 5| Step: 2
Training loss: 2.8986840978634674
Validation loss: 2.608867401731224

Epoch: 5| Step: 3
Training loss: 3.005301400809009
Validation loss: 2.6084636002654533

Epoch: 5| Step: 4
Training loss: 2.563603419480206
Validation loss: 2.6071987709101427

Epoch: 5| Step: 5
Training loss: 2.355100080951208
Validation loss: 2.606732654323704

Epoch: 5| Step: 6
Training loss: 2.86473223674902
Validation loss: 2.6039433243663828

Epoch: 5| Step: 7
Training loss: 2.6186881702197993
Validation loss: 2.6041831333911354

Epoch: 5| Step: 8
Training loss: 2.5696166235710276
Validation loss: 2.605332172251351

Epoch: 5| Step: 9
Training loss: 2.7287103887907884
Validation loss: 2.6031151492393065

Epoch: 5| Step: 10
Training loss: 2.9218289784769698
Validation loss: 2.601359473049299

Epoch: 5| Step: 11
Training loss: 3.7488484203905794
Validation loss: 2.6040282683154135

Epoch: 69| Step: 0
Training loss: 2.450571565714363
Validation loss: 2.6058259306427276

Epoch: 5| Step: 1
Training loss: 2.811784950064232
Validation loss: 2.6148648636049767

Epoch: 5| Step: 2
Training loss: 3.0851281758642104
Validation loss: 2.604844803571073

Epoch: 5| Step: 3
Training loss: 2.759615905544914
Validation loss: 2.602841415162221

Epoch: 5| Step: 4
Training loss: 2.5314365836240893
Validation loss: 2.598548384132002

Epoch: 5| Step: 5
Training loss: 2.907704143360349
Validation loss: 2.5965533102040244

Epoch: 5| Step: 6
Training loss: 2.4782353957457905
Validation loss: 2.6001581176032227

Epoch: 5| Step: 7
Training loss: 2.926110120556311
Validation loss: 2.5992406540132995

Epoch: 5| Step: 8
Training loss: 2.4900332141484087
Validation loss: 2.5971238549168714

Epoch: 5| Step: 9
Training loss: 2.9844294837651795
Validation loss: 2.59745922058448

Epoch: 5| Step: 10
Training loss: 2.7424490170882168
Validation loss: 2.598061356470439

Epoch: 5| Step: 11
Training loss: 2.291686445208654
Validation loss: 2.598530469750143

Epoch: 70| Step: 0
Training loss: 2.52295654248562
Validation loss: 2.5994290223148457

Epoch: 5| Step: 1
Training loss: 3.0536915748306828
Validation loss: 2.596166714272302

Epoch: 5| Step: 2
Training loss: 2.717206407144496
Validation loss: 2.594695903083432

Epoch: 5| Step: 3
Training loss: 2.7405018203526077
Validation loss: 2.592407104896461

Epoch: 5| Step: 4
Training loss: 3.1902117694172007
Validation loss: 2.5891930677097

Epoch: 5| Step: 5
Training loss: 2.877950564057297
Validation loss: 2.587506243871751

Epoch: 5| Step: 6
Training loss: 2.6445397245871414
Validation loss: 2.584411228299632

Epoch: 5| Step: 7
Training loss: 3.1277906545942753
Validation loss: 2.582369414330274

Epoch: 5| Step: 8
Training loss: 2.0581159525793185
Validation loss: 2.5822599601158345

Epoch: 5| Step: 9
Training loss: 2.191098223846706
Validation loss: 2.58107564828391

Epoch: 5| Step: 10
Training loss: 2.572985989232618
Validation loss: 2.58162497490066

Epoch: 5| Step: 11
Training loss: 2.793162348513127
Validation loss: 2.5796616107605073

Epoch: 71| Step: 0
Training loss: 2.8870157339409257
Validation loss: 2.5797762582298187

Epoch: 5| Step: 1
Training loss: 2.6376047411907555
Validation loss: 2.5771724983606075

Epoch: 5| Step: 2
Training loss: 2.232094621409626
Validation loss: 2.577368349727065

Epoch: 5| Step: 3
Training loss: 2.84409305054377
Validation loss: 2.574394308846523

Epoch: 5| Step: 4
Training loss: 2.603967877748016
Validation loss: 2.5721906546305067

Epoch: 5| Step: 5
Training loss: 2.632462384859969
Validation loss: 2.5724864219032857

Epoch: 5| Step: 6
Training loss: 2.692435589571587
Validation loss: 2.573091154835697

Epoch: 5| Step: 7
Training loss: 2.839102500083688
Validation loss: 2.5705122014995108

Epoch: 5| Step: 8
Training loss: 3.1915964469123987
Validation loss: 2.5705967043559

Epoch: 5| Step: 9
Training loss: 2.415337284615921
Validation loss: 2.570120930900276

Epoch: 5| Step: 10
Training loss: 2.4106197560663527
Validation loss: 2.574263877646753

Epoch: 5| Step: 11
Training loss: 3.7472909678971416
Validation loss: 2.5686695254885263

Epoch: 72| Step: 0
Training loss: 2.9567056574897235
Validation loss: 2.5691664826051452

Epoch: 5| Step: 1
Training loss: 2.590871661583583
Validation loss: 2.5694752056983976

Epoch: 5| Step: 2
Training loss: 3.0703283411447257
Validation loss: 2.568071546006769

Epoch: 5| Step: 3
Training loss: 2.8145657900007732
Validation loss: 2.5686361959018695

Epoch: 5| Step: 4
Training loss: 2.174930097837849
Validation loss: 2.568849025219116

Epoch: 5| Step: 5
Training loss: 2.0344840493691394
Validation loss: 2.5664351145738635

Epoch: 5| Step: 6
Training loss: 2.7697729696613758
Validation loss: 2.568079228467151

Epoch: 5| Step: 7
Training loss: 2.993375935608878
Validation loss: 2.567431058995024

Epoch: 5| Step: 8
Training loss: 2.81297213512171
Validation loss: 2.567083179492654

Epoch: 5| Step: 9
Training loss: 2.4944593066155316
Validation loss: 2.5659435209241517

Epoch: 5| Step: 10
Training loss: 2.8819514283449252
Validation loss: 2.5644765922051778

Epoch: 5| Step: 11
Training loss: 2.194221415500099
Validation loss: 2.5611039444879906

Epoch: 73| Step: 0
Training loss: 2.4839264086819397
Validation loss: 2.559771721367572

Epoch: 5| Step: 1
Training loss: 3.0905157580996105
Validation loss: 2.5599224649300716

Epoch: 5| Step: 2
Training loss: 2.6401559988806143
Validation loss: 2.5600649071886656

Epoch: 5| Step: 3
Training loss: 2.7951739375495053
Validation loss: 2.557951130622144

Epoch: 5| Step: 4
Training loss: 2.6834480434880064
Validation loss: 2.555931076388114

Epoch: 5| Step: 5
Training loss: 2.6205336402927566
Validation loss: 2.5537579952107987

Epoch: 5| Step: 6
Training loss: 2.58745970395173
Validation loss: 2.558207949217681

Epoch: 5| Step: 7
Training loss: 3.0488576844839472
Validation loss: 2.553375572225815

Epoch: 5| Step: 8
Training loss: 2.138945094384326
Validation loss: 2.5569491315632145

Epoch: 5| Step: 9
Training loss: 2.481499693483714
Validation loss: 2.553096380738715

Epoch: 5| Step: 10
Training loss: 2.657897976549807
Validation loss: 2.558870909144527

Epoch: 5| Step: 11
Training loss: 3.496102479039382
Validation loss: 2.5595728973526986

Epoch: 74| Step: 0
Training loss: 2.3094131900174473
Validation loss: 2.5467704720295146

Epoch: 5| Step: 1
Training loss: 2.6725457671254893
Validation loss: 2.550977168754753

Epoch: 5| Step: 2
Training loss: 2.903669791129909
Validation loss: 2.552995975304935

Epoch: 5| Step: 3
Training loss: 3.301160296283386
Validation loss: 2.5528955347917295

Epoch: 5| Step: 4
Training loss: 2.6883822922368474
Validation loss: 2.556037958082184

Epoch: 5| Step: 5
Training loss: 2.605746184395217
Validation loss: 2.560320865793279

Epoch: 5| Step: 6
Training loss: 2.7211996859033154
Validation loss: 2.5604859613291837

Epoch: 5| Step: 7
Training loss: 2.309160140473546
Validation loss: 2.5630515055586938

Epoch: 5| Step: 8
Training loss: 2.890464324609598
Validation loss: 2.565351767942483

Epoch: 5| Step: 9
Training loss: 2.229429520650704
Validation loss: 2.5649079507567527

Epoch: 5| Step: 10
Training loss: 3.0274040757598324
Validation loss: 2.5674776795162106

Epoch: 5| Step: 11
Training loss: 1.337459745425235
Validation loss: 2.561259830245613

Epoch: 75| Step: 0
Training loss: 2.817302249173099
Validation loss: 2.561429691865589

Epoch: 5| Step: 1
Training loss: 2.6138262216116566
Validation loss: 2.5615067340259197

Epoch: 5| Step: 2
Training loss: 2.7389401066315493
Validation loss: 2.556371283665788

Epoch: 5| Step: 3
Training loss: 2.6443734734714965
Validation loss: 2.5539221905381697

Epoch: 5| Step: 4
Training loss: 2.6944787546531783
Validation loss: 2.553417201073731

Epoch: 5| Step: 5
Training loss: 2.4883675792336435
Validation loss: 2.550611802879989

Epoch: 5| Step: 6
Training loss: 2.7745740683907374
Validation loss: 2.5506480806804035

Epoch: 5| Step: 7
Training loss: 2.757088714804972
Validation loss: 2.5491386409560337

Epoch: 5| Step: 8
Training loss: 2.4949360104231046
Validation loss: 2.546125797157051

Epoch: 5| Step: 9
Training loss: 2.674788643161081
Validation loss: 2.54706094995223

Epoch: 5| Step: 10
Training loss: 2.8981416864924583
Validation loss: 2.5421434421703495

Epoch: 5| Step: 11
Training loss: 2.206819939413979
Validation loss: 2.541079853408221

Epoch: 76| Step: 0
Training loss: 2.3089228619774755
Validation loss: 2.5389672403316803

Epoch: 5| Step: 1
Training loss: 2.7757475353011167
Validation loss: 2.5397952738993315

Epoch: 5| Step: 2
Training loss: 2.4932030787928308
Validation loss: 2.540485980745407

Epoch: 5| Step: 3
Training loss: 3.0187753617068367
Validation loss: 2.535433847582825

Epoch: 5| Step: 4
Training loss: 2.7913631919531485
Validation loss: 2.535266487847885

Epoch: 5| Step: 5
Training loss: 1.9604632651465974
Validation loss: 2.538910013168244

Epoch: 5| Step: 6
Training loss: 2.859854402637426
Validation loss: 2.53825803092308

Epoch: 5| Step: 7
Training loss: 3.040262568829666
Validation loss: 2.53961472986063

Epoch: 5| Step: 8
Training loss: 2.9466842573454985
Validation loss: 2.5409479154205132

Epoch: 5| Step: 9
Training loss: 2.5648141041813477
Validation loss: 2.5404199228885807

Epoch: 5| Step: 10
Training loss: 2.4655018938900928
Validation loss: 2.5409693008801764

Epoch: 5| Step: 11
Training loss: 2.2953128822487345
Validation loss: 2.5391559407573427

Epoch: 77| Step: 0
Training loss: 2.905955309950195
Validation loss: 2.538100896822799

Epoch: 5| Step: 1
Training loss: 2.689707980135037
Validation loss: 2.5408381508364184

Epoch: 5| Step: 2
Training loss: 2.8853378193315664
Validation loss: 2.5475376881814875

Epoch: 5| Step: 3
Training loss: 2.5664102446874826
Validation loss: 2.5586158304984634

Epoch: 5| Step: 4
Training loss: 3.1627731144999496
Validation loss: 2.5645976629923393

Epoch: 5| Step: 5
Training loss: 2.703798331482561
Validation loss: 2.545786205569365

Epoch: 5| Step: 6
Training loss: 2.6871476940512173
Validation loss: 2.530461211986803

Epoch: 5| Step: 7
Training loss: 2.3871800153315093
Validation loss: 2.530164686108961

Epoch: 5| Step: 8
Training loss: 1.8498587837964857
Validation loss: 2.532648685185224

Epoch: 5| Step: 9
Training loss: 2.6920024504912563
Validation loss: 2.5301295693142998

Epoch: 5| Step: 10
Training loss: 2.537836524183586
Validation loss: 2.531914851310476

Epoch: 5| Step: 11
Training loss: 3.2527058414707124
Validation loss: 2.532391891054852

Epoch: 78| Step: 0
Training loss: 2.857887423092675
Validation loss: 2.5357342704213126

Epoch: 5| Step: 1
Training loss: 2.411432407533646
Validation loss: 2.537783968904099

Epoch: 5| Step: 2
Training loss: 2.9730251649778876
Validation loss: 2.538324708606681

Epoch: 5| Step: 3
Training loss: 2.4527833542760997
Validation loss: 2.5392721001603293

Epoch: 5| Step: 4
Training loss: 2.5469394043812357
Validation loss: 2.54145857996225

Epoch: 5| Step: 5
Training loss: 2.8675590087353218
Validation loss: 2.5442173788545723

Epoch: 5| Step: 6
Training loss: 2.5167549391501294
Validation loss: 2.543491690639918

Epoch: 5| Step: 7
Training loss: 2.016966380817404
Validation loss: 2.549860220861629

Epoch: 5| Step: 8
Training loss: 2.829256790216355
Validation loss: 2.5454474584911204

Epoch: 5| Step: 9
Training loss: 2.9023874518286195
Validation loss: 2.544360778426516

Epoch: 5| Step: 10
Training loss: 2.879939273088029
Validation loss: 2.542288877329403

Epoch: 5| Step: 11
Training loss: 2.577552038161389
Validation loss: 2.5397984929640116

Epoch: 79| Step: 0
Training loss: 2.811520554281693
Validation loss: 2.535247499364712

Epoch: 5| Step: 1
Training loss: 2.8156419793737917
Validation loss: 2.535058825422912

Epoch: 5| Step: 2
Training loss: 2.5219613591076837
Validation loss: 2.5309257927632576

Epoch: 5| Step: 3
Training loss: 2.5777890998036295
Validation loss: 2.532052827213686

Epoch: 5| Step: 4
Training loss: 3.1171657781393853
Validation loss: 2.5272406469085165

Epoch: 5| Step: 5
Training loss: 2.9634490219321843
Validation loss: 2.5291345257002544

Epoch: 5| Step: 6
Training loss: 2.773477559404794
Validation loss: 2.526876997065095

Epoch: 5| Step: 7
Training loss: 2.4121890406252167
Validation loss: 2.5248203326974266

Epoch: 5| Step: 8
Training loss: 2.3622388826613885
Validation loss: 2.526558846034811

Epoch: 5| Step: 9
Training loss: 2.3570819347319674
Validation loss: 2.522597910408373

Epoch: 5| Step: 10
Training loss: 2.5908748823703185
Validation loss: 2.5205027439677865

Epoch: 5| Step: 11
Training loss: 1.8104549578036566
Validation loss: 2.520491132812804

Epoch: 80| Step: 0
Training loss: 2.641685318103815
Validation loss: 2.521089376629611

Epoch: 5| Step: 1
Training loss: 2.5240949122784953
Validation loss: 2.519917283561299

Epoch: 5| Step: 2
Training loss: 2.404624687301489
Validation loss: 2.5174934406504432

Epoch: 5| Step: 3
Training loss: 2.9210984121093113
Validation loss: 2.522104897590971

Epoch: 5| Step: 4
Training loss: 2.5639723292924197
Validation loss: 2.521119705726993

Epoch: 5| Step: 5
Training loss: 2.839541496552662
Validation loss: 2.5206256234423385

Epoch: 5| Step: 6
Training loss: 2.7928940556281643
Validation loss: 2.521474771754669

Epoch: 5| Step: 7
Training loss: 2.8816640163370466
Validation loss: 2.523836602300724

Epoch: 5| Step: 8
Training loss: 2.350269253503701
Validation loss: 2.5276530261806287

Epoch: 5| Step: 9
Training loss: 2.9613371808288855
Validation loss: 2.5270845849290113

Epoch: 5| Step: 10
Training loss: 2.0575177676058285
Validation loss: 2.528196789319909

Epoch: 5| Step: 11
Training loss: 3.011725399737309
Validation loss: 2.530145270633694

Epoch: 81| Step: 0
Training loss: 2.867412672633757
Validation loss: 2.529533773789319

Epoch: 5| Step: 1
Training loss: 2.790381539074174
Validation loss: 2.5320924918836822

Epoch: 5| Step: 2
Training loss: 2.594083649650542
Validation loss: 2.5322009682480564

Epoch: 5| Step: 3
Training loss: 2.435695958717797
Validation loss: 2.529442597147271

Epoch: 5| Step: 4
Training loss: 2.1513205309781376
Validation loss: 2.528497451268242

Epoch: 5| Step: 5
Training loss: 2.843192580370219
Validation loss: 2.525606347291837

Epoch: 5| Step: 6
Training loss: 2.3852380632950054
Validation loss: 2.525145913934531

Epoch: 5| Step: 7
Training loss: 2.8091235768617526
Validation loss: 2.521560742644771

Epoch: 5| Step: 8
Training loss: 2.8371915540383665
Validation loss: 2.5194595168988982

Epoch: 5| Step: 9
Training loss: 2.8123263835301904
Validation loss: 2.5198518691980096

Epoch: 5| Step: 10
Training loss: 2.53628961418428
Validation loss: 2.515652721560306

Epoch: 5| Step: 11
Training loss: 2.4654362324637833
Validation loss: 2.513596002776875

Epoch: 82| Step: 0
Training loss: 2.6799828725239054
Validation loss: 2.5119220419999393

Epoch: 5| Step: 1
Training loss: 2.9385353049545544
Validation loss: 2.5088477963702007

Epoch: 5| Step: 2
Training loss: 2.655938881998166
Validation loss: 2.511172494769847

Epoch: 5| Step: 3
Training loss: 2.6938396465492893
Validation loss: 2.511171256552875

Epoch: 5| Step: 4
Training loss: 2.291423738492864
Validation loss: 2.5162009730950237

Epoch: 5| Step: 5
Training loss: 2.0479930124834187
Validation loss: 2.518734076901597

Epoch: 5| Step: 6
Training loss: 2.3603376231099564
Validation loss: 2.517109616458166

Epoch: 5| Step: 7
Training loss: 2.87752604428858
Validation loss: 2.5170992959921437

Epoch: 5| Step: 8
Training loss: 2.9926532751361465
Validation loss: 2.520325027532438

Epoch: 5| Step: 9
Training loss: 2.7756862925835883
Validation loss: 2.521815890092555

Epoch: 5| Step: 10
Training loss: 2.7527357711777625
Validation loss: 2.523016155327778

Epoch: 5| Step: 11
Training loss: 2.2454903231547974
Validation loss: 2.5221423672705203

Epoch: 83| Step: 0
Training loss: 2.510833726695735
Validation loss: 2.524160594500491

Epoch: 5| Step: 1
Training loss: 2.6234312365277095
Validation loss: 2.5201649029203383

Epoch: 5| Step: 2
Training loss: 2.9755263239638885
Validation loss: 2.518836090629655

Epoch: 5| Step: 3
Training loss: 2.3387437377715363
Validation loss: 2.519173624843217

Epoch: 5| Step: 4
Training loss: 3.0403569855142396
Validation loss: 2.5206413248461867

Epoch: 5| Step: 5
Training loss: 2.8345563904110147
Validation loss: 2.5177268809744224

Epoch: 5| Step: 6
Training loss: 2.551053977511883
Validation loss: 2.5181102086833103

Epoch: 5| Step: 7
Training loss: 2.7422880931346896
Validation loss: 2.516065768215178

Epoch: 5| Step: 8
Training loss: 2.756827721632506
Validation loss: 2.517608768660378

Epoch: 5| Step: 9
Training loss: 2.1633009689606086
Validation loss: 2.5165380258450525

Epoch: 5| Step: 10
Training loss: 2.3310788252834906
Validation loss: 2.5160227455212523

Epoch: 5| Step: 11
Training loss: 2.969853246383348
Validation loss: 2.5139079503015247

Epoch: 84| Step: 0
Training loss: 2.785010549364365
Validation loss: 2.5075706472266637

Epoch: 5| Step: 1
Training loss: 2.6166799480157867
Validation loss: 2.5078162037791376

Epoch: 5| Step: 2
Training loss: 2.2388957779459933
Validation loss: 2.5102301379245175

Epoch: 5| Step: 3
Training loss: 2.5468183639875632
Validation loss: 2.5143832346501394

Epoch: 5| Step: 4
Training loss: 3.0398489515524276
Validation loss: 2.5251201141543307

Epoch: 5| Step: 5
Training loss: 2.7307629951992736
Validation loss: 2.540541758860844

Epoch: 5| Step: 6
Training loss: 2.2187987846061716
Validation loss: 2.546709554560345

Epoch: 5| Step: 7
Training loss: 2.916938732718699
Validation loss: 2.5390494126202676

Epoch: 5| Step: 8
Training loss: 2.7820895353069783
Validation loss: 2.5191393761876473

Epoch: 5| Step: 9
Training loss: 2.5091242226674653
Validation loss: 2.504561240888311

Epoch: 5| Step: 10
Training loss: 2.7208185328908137
Validation loss: 2.506184728030911

Epoch: 5| Step: 11
Training loss: 2.7036849307458946
Validation loss: 2.5027308529568604

Epoch: 85| Step: 0
Training loss: 2.5244682734145347
Validation loss: 2.504983179412835

Epoch: 5| Step: 1
Training loss: 2.6744466975889853
Validation loss: 2.5086529196009337

Epoch: 5| Step: 2
Training loss: 2.6759183751075137
Validation loss: 2.5073434345483436

Epoch: 5| Step: 3
Training loss: 2.9155380972026816
Validation loss: 2.5133111512620188

Epoch: 5| Step: 4
Training loss: 2.7639084138505403
Validation loss: 2.5131533625679148

Epoch: 5| Step: 5
Training loss: 2.511669105051026
Validation loss: 2.518175924712038

Epoch: 5| Step: 6
Training loss: 2.4694382879034804
Validation loss: 2.5196233175642107

Epoch: 5| Step: 7
Training loss: 2.6464702310219366
Validation loss: 2.519380151914835

Epoch: 5| Step: 8
Training loss: 2.99629618571321
Validation loss: 2.5173493748241462

Epoch: 5| Step: 9
Training loss: 2.4151529855231626
Validation loss: 2.514181176880144

Epoch: 5| Step: 10
Training loss: 2.392135242810795
Validation loss: 2.517615815939255

Epoch: 5| Step: 11
Training loss: 2.650794586678753
Validation loss: 2.5164215256390077

Epoch: 86| Step: 0
Training loss: 2.411196986318172
Validation loss: 2.5126258750559627

Epoch: 5| Step: 1
Training loss: 3.0272870458399144
Validation loss: 2.50960378557975

Epoch: 5| Step: 2
Training loss: 2.512588184384353
Validation loss: 2.508495812101659

Epoch: 5| Step: 3
Training loss: 2.354142608069532
Validation loss: 2.5074853178604224

Epoch: 5| Step: 4
Training loss: 2.8679465970290736
Validation loss: 2.500350687146742

Epoch: 5| Step: 5
Training loss: 2.9852926231608246
Validation loss: 2.503491423349969

Epoch: 5| Step: 6
Training loss: 2.291620485245054
Validation loss: 2.4982393701119086

Epoch: 5| Step: 7
Training loss: 2.441497263928532
Validation loss: 2.5067746043829127

Epoch: 5| Step: 8
Training loss: 2.6639484817403467
Validation loss: 2.5018287248578113

Epoch: 5| Step: 9
Training loss: 2.6685457959990564
Validation loss: 2.502625005174163

Epoch: 5| Step: 10
Training loss: 2.5358230348750443
Validation loss: 2.498443985533592

Epoch: 5| Step: 11
Training loss: 2.8523958007610406
Validation loss: 2.503892772556956

Epoch: 87| Step: 0
Training loss: 2.1651038133077827
Validation loss: 2.4995761591528622

Epoch: 5| Step: 1
Training loss: 2.656803746565808
Validation loss: 2.4977058434357975

Epoch: 5| Step: 2
Training loss: 2.492762388691921
Validation loss: 2.495396273358678

Epoch: 5| Step: 3
Training loss: 2.6057707970360307
Validation loss: 2.4995370515698525

Epoch: 5| Step: 4
Training loss: 2.4616794012829795
Validation loss: 2.497035983469653

Epoch: 5| Step: 5
Training loss: 2.5571053638434367
Validation loss: 2.4952839715386212

Epoch: 5| Step: 6
Training loss: 3.1055086721097442
Validation loss: 2.49849614370172

Epoch: 5| Step: 7
Training loss: 2.920709224427729
Validation loss: 2.4986288602164524

Epoch: 5| Step: 8
Training loss: 2.4352933236229513
Validation loss: 2.4998986462075057

Epoch: 5| Step: 9
Training loss: 2.415612374454089
Validation loss: 2.4987829146539924

Epoch: 5| Step: 10
Training loss: 2.7170940924937805
Validation loss: 2.500354729758134

Epoch: 5| Step: 11
Training loss: 3.363349302447404
Validation loss: 2.5018687972291205

Epoch: 88| Step: 0
Training loss: 2.283162921848517
Validation loss: 2.498052243606489

Epoch: 5| Step: 1
Training loss: 2.5888480319217764
Validation loss: 2.4953188501769694

Epoch: 5| Step: 2
Training loss: 2.952470979475252
Validation loss: 2.4923691797951077

Epoch: 5| Step: 3
Training loss: 2.5555461408837905
Validation loss: 2.4909566193431005

Epoch: 5| Step: 4
Training loss: 2.8878388045068286
Validation loss: 2.495334085790324

Epoch: 5| Step: 5
Training loss: 2.476908758849285
Validation loss: 2.4939525337163486

Epoch: 5| Step: 6
Training loss: 2.615522259115232
Validation loss: 2.493800300116351

Epoch: 5| Step: 7
Training loss: 2.498490259163377
Validation loss: 2.490322260084959

Epoch: 5| Step: 8
Training loss: 2.8286056531621857
Validation loss: 2.492277472614865

Epoch: 5| Step: 9
Training loss: 2.312362873032602
Validation loss: 2.486778643980698

Epoch: 5| Step: 10
Training loss: 2.5383162590282495
Validation loss: 2.4913074330665417

Epoch: 5| Step: 11
Training loss: 3.2157750872256434
Validation loss: 2.4921100648272168

Epoch: 89| Step: 0
Training loss: 2.683840811072077
Validation loss: 2.495823813236105

Epoch: 5| Step: 1
Training loss: 2.6293243937227557
Validation loss: 2.49746315911442

Epoch: 5| Step: 2
Training loss: 2.5973801545003354
Validation loss: 2.5001164250285037

Epoch: 5| Step: 3
Training loss: 2.534181945446971
Validation loss: 2.498895655539415

Epoch: 5| Step: 4
Training loss: 2.7884925238509264
Validation loss: 2.500949695129545

Epoch: 5| Step: 5
Training loss: 2.428217796015521
Validation loss: 2.5021862206333294

Epoch: 5| Step: 6
Training loss: 2.6470978986436564
Validation loss: 2.502882202031387

Epoch: 5| Step: 7
Training loss: 2.3672944601840857
Validation loss: 2.5010946619048

Epoch: 5| Step: 8
Training loss: 2.35902109081224
Validation loss: 2.5021488729549057

Epoch: 5| Step: 9
Training loss: 2.5533671568911953
Validation loss: 2.5035863782122663

Epoch: 5| Step: 10
Training loss: 3.1338573815687107
Validation loss: 2.502361291114669

Epoch: 5| Step: 11
Training loss: 2.412534755001842
Validation loss: 2.496484696999982

Epoch: 90| Step: 0
Training loss: 2.400703974633695
Validation loss: 2.494823166257476

Epoch: 5| Step: 1
Training loss: 2.7312305790191065
Validation loss: 2.492892864064141

Epoch: 5| Step: 2
Training loss: 2.3357626552914676
Validation loss: 2.4932693437301294

Epoch: 5| Step: 3
Training loss: 2.876433471239224
Validation loss: 2.490484925674333

Epoch: 5| Step: 4
Training loss: 2.5809822664120907
Validation loss: 2.490354850697104

Epoch: 5| Step: 5
Training loss: 3.345611054355597
Validation loss: 2.4949885564744227

Epoch: 5| Step: 6
Training loss: 2.5170478351095626
Validation loss: 2.493313522032791

Epoch: 5| Step: 7
Training loss: 2.2162952006679766
Validation loss: 2.495278756222639

Epoch: 5| Step: 8
Training loss: 2.424191357786398
Validation loss: 2.4892329258034516

Epoch: 5| Step: 9
Training loss: 2.727336347444793
Validation loss: 2.489537870452211

Epoch: 5| Step: 10
Training loss: 2.3813917583412345
Validation loss: 2.4891624028331436

Epoch: 5| Step: 11
Training loss: 2.7764508278049425
Validation loss: 2.4842817420970023

Epoch: 91| Step: 0
Training loss: 3.138506578176915
Validation loss: 2.490566595518313

Epoch: 5| Step: 1
Training loss: 2.332964788577494
Validation loss: 2.497936907493493

Epoch: 5| Step: 2
Training loss: 2.7583544147373495
Validation loss: 2.493016219795438

Epoch: 5| Step: 3
Training loss: 2.383352149764612
Validation loss: 2.4987216939717536

Epoch: 5| Step: 4
Training loss: 2.2200543505227306
Validation loss: 2.4944935038444984

Epoch: 5| Step: 5
Training loss: 2.9422871966293043
Validation loss: 2.497111555247978

Epoch: 5| Step: 6
Training loss: 2.603271930848017
Validation loss: 2.5032710253046737

Epoch: 5| Step: 7
Training loss: 2.788676088209452
Validation loss: 2.5072025892353667

Epoch: 5| Step: 8
Training loss: 2.395341098363351
Validation loss: 2.5100466599313247

Epoch: 5| Step: 9
Training loss: 2.2711832202757787
Validation loss: 2.5224416990256624

Epoch: 5| Step: 10
Training loss: 2.773437242104962
Validation loss: 2.527362518791147

Epoch: 5| Step: 11
Training loss: 2.8701156922525026
Validation loss: 2.5255191983651466

Epoch: 92| Step: 0
Training loss: 2.6665151274856598
Validation loss: 2.5013143620875575

Epoch: 5| Step: 1
Training loss: 1.9646912168598405
Validation loss: 2.4943728536750966

Epoch: 5| Step: 2
Training loss: 2.694717474231793
Validation loss: 2.4886757434628692

Epoch: 5| Step: 3
Training loss: 2.449438641912049
Validation loss: 2.483715925624485

Epoch: 5| Step: 4
Training loss: 2.5354043283739585
Validation loss: 2.482843882908746

Epoch: 5| Step: 5
Training loss: 2.0932323897780596
Validation loss: 2.4866552584691552

Epoch: 5| Step: 6
Training loss: 3.0165335912138267
Validation loss: 2.485524569362416

Epoch: 5| Step: 7
Training loss: 2.564122686429417
Validation loss: 2.49213998922664

Epoch: 5| Step: 8
Training loss: 2.7433712569713675
Validation loss: 2.4898363062022453

Epoch: 5| Step: 9
Training loss: 2.800349288680046
Validation loss: 2.495331390602364

Epoch: 5| Step: 10
Training loss: 3.0009760858179737
Validation loss: 2.498741985738833

Epoch: 5| Step: 11
Training loss: 2.520005576263798
Validation loss: 2.494111073118989

Epoch: 93| Step: 0
Training loss: 2.6162972373725903
Validation loss: 2.4911630053403226

Epoch: 5| Step: 1
Training loss: 2.549527898731193
Validation loss: 2.4921923431062427

Epoch: 5| Step: 2
Training loss: 2.29301730726775
Validation loss: 2.4908613545115856

Epoch: 5| Step: 3
Training loss: 3.0015874477384292
Validation loss: 2.488311851229456

Epoch: 5| Step: 4
Training loss: 2.6604239487355423
Validation loss: 2.491546955124741

Epoch: 5| Step: 5
Training loss: 1.7673905583967666
Validation loss: 2.4856616333284336

Epoch: 5| Step: 6
Training loss: 3.015161033872099
Validation loss: 2.4806750794950396

Epoch: 5| Step: 7
Training loss: 2.471192322802265
Validation loss: 2.4815510468698454

Epoch: 5| Step: 8
Training loss: 2.9960402741316328
Validation loss: 2.4802044825315055

Epoch: 5| Step: 9
Training loss: 2.7988885206160288
Validation loss: 2.4790570264235163

Epoch: 5| Step: 10
Training loss: 2.240454239769357
Validation loss: 2.485251973673159

Epoch: 5| Step: 11
Training loss: 2.325754482126781
Validation loss: 2.486069419328928

Epoch: 94| Step: 0
Training loss: 2.44309833940474
Validation loss: 2.483454943779225

Epoch: 5| Step: 1
Training loss: 2.6515504440006565
Validation loss: 2.490241826862829

Epoch: 5| Step: 2
Training loss: 2.7176904477200683
Validation loss: 2.489365066686004

Epoch: 5| Step: 3
Training loss: 2.641156024696298
Validation loss: 2.4901453598169545

Epoch: 5| Step: 4
Training loss: 2.4566167775975716
Validation loss: 2.490331786001997

Epoch: 5| Step: 5
Training loss: 2.3783856403218877
Validation loss: 2.488756111542424

Epoch: 5| Step: 6
Training loss: 2.5334666401104897
Validation loss: 2.4884086827774037

Epoch: 5| Step: 7
Training loss: 2.6196602598164467
Validation loss: 2.485631828768728

Epoch: 5| Step: 8
Training loss: 2.755698542021295
Validation loss: 2.48919996132266

Epoch: 5| Step: 9
Training loss: 2.3477977132464884
Validation loss: 2.485570847705783

Epoch: 5| Step: 10
Training loss: 3.0090396111905653
Validation loss: 2.4857010451384656

Epoch: 5| Step: 11
Training loss: 2.558278584179217
Validation loss: 2.4818201023480335

Epoch: 95| Step: 0
Training loss: 2.7714976229092283
Validation loss: 2.478604825385928

Epoch: 5| Step: 1
Training loss: 2.288770220847941
Validation loss: 2.479983821535407

Epoch: 5| Step: 2
Training loss: 2.265518712148548
Validation loss: 2.4780786167596807

Epoch: 5| Step: 3
Training loss: 3.080979935454124
Validation loss: 2.4760945837785324

Epoch: 5| Step: 4
Training loss: 2.377887075304799
Validation loss: 2.4844406926968503

Epoch: 5| Step: 5
Training loss: 2.395912456588051
Validation loss: 2.4772563768544025

Epoch: 5| Step: 6
Training loss: 2.122652103109735
Validation loss: 2.484464955650647

Epoch: 5| Step: 7
Training loss: 2.0948003155722463
Validation loss: 2.487106533017958

Epoch: 5| Step: 8
Training loss: 3.135402151350892
Validation loss: 2.4822126571006047

Epoch: 5| Step: 9
Training loss: 2.797282780590808
Validation loss: 2.4779004354818235

Epoch: 5| Step: 10
Training loss: 3.035708265539018
Validation loss: 2.478618386224795

Epoch: 5| Step: 11
Training loss: 2.2964328677686647
Validation loss: 2.471334862642027

Epoch: 96| Step: 0
Training loss: 2.6002683427690187
Validation loss: 2.4798962029916303

Epoch: 5| Step: 1
Training loss: 2.4661654693455555
Validation loss: 2.4816497234135864

Epoch: 5| Step: 2
Training loss: 2.3804175175761495
Validation loss: 2.4884942131792758

Epoch: 5| Step: 3
Training loss: 2.045539361948461
Validation loss: 2.487371600813262

Epoch: 5| Step: 4
Training loss: 2.804466302591387
Validation loss: 2.486963511046553

Epoch: 5| Step: 5
Training loss: 2.3856186649357323
Validation loss: 2.4890536751743353

Epoch: 5| Step: 6
Training loss: 2.545494220164355
Validation loss: 2.4896959787419677

Epoch: 5| Step: 7
Training loss: 2.620300627779921
Validation loss: 2.4905490771136654

Epoch: 5| Step: 8
Training loss: 2.791002128039881
Validation loss: 2.488415162032814

Epoch: 5| Step: 9
Training loss: 2.671531878295992
Validation loss: 2.489561405377935

Epoch: 5| Step: 10
Training loss: 2.9474981075989373
Validation loss: 2.490500787184726

Epoch: 5| Step: 11
Training loss: 3.1877578930215957
Validation loss: 2.4913918391987515

Epoch: 97| Step: 0
Training loss: 3.110310782699701
Validation loss: 2.492531767597753

Epoch: 5| Step: 1
Training loss: 2.0452789606968267
Validation loss: 2.4892537738163183

Epoch: 5| Step: 2
Training loss: 2.135818877759762
Validation loss: 2.4882142293977854

Epoch: 5| Step: 3
Training loss: 2.4237369394171804
Validation loss: 2.487025668257054

Epoch: 5| Step: 4
Training loss: 2.3764215531647466
Validation loss: 2.483953336203933

Epoch: 5| Step: 5
Training loss: 2.699248693275259
Validation loss: 2.4871777134010324

Epoch: 5| Step: 6
Training loss: 2.980705841753506
Validation loss: 2.4871226177818637

Epoch: 5| Step: 7
Training loss: 2.322056792216085
Validation loss: 2.481192563799066

Epoch: 5| Step: 8
Training loss: 2.700182686029475
Validation loss: 2.4849262905446414

Epoch: 5| Step: 9
Training loss: 2.9876026854165536
Validation loss: 2.4804552293143645

Epoch: 5| Step: 10
Training loss: 2.3683389312048018
Validation loss: 2.4801031769419364

Epoch: 5| Step: 11
Training loss: 3.243996577363378
Validation loss: 2.47689783371193

Epoch: 98| Step: 0
Training loss: 2.600302909665599
Validation loss: 2.478628251703479

Epoch: 5| Step: 1
Training loss: 2.2575384587489786
Validation loss: 2.473835688445468

Epoch: 5| Step: 2
Training loss: 2.312305751580864
Validation loss: 2.4741690268226364

Epoch: 5| Step: 3
Training loss: 2.6153475998291564
Validation loss: 2.4728716374298427

Epoch: 5| Step: 4
Training loss: 2.8720711426278127
Validation loss: 2.4733300679520323

Epoch: 5| Step: 5
Training loss: 2.605473691372282
Validation loss: 2.471159531727507

Epoch: 5| Step: 6
Training loss: 3.098283316988474
Validation loss: 2.4728092469685277

Epoch: 5| Step: 7
Training loss: 2.630437577835884
Validation loss: 2.4747914942500944

Epoch: 5| Step: 8
Training loss: 2.5874432101444578
Validation loss: 2.476147032183489

Epoch: 5| Step: 9
Training loss: 2.585117175399768
Validation loss: 2.4710173556571124

Epoch: 5| Step: 10
Training loss: 2.2146386752984526
Validation loss: 2.4705099359505667

Epoch: 5| Step: 11
Training loss: 2.3772205211782595
Validation loss: 2.4710589447931164

Epoch: 99| Step: 0
Training loss: 2.249103897517274
Validation loss: 2.473063675919719

Epoch: 5| Step: 1
Training loss: 2.79693825080147
Validation loss: 2.472359943363782

Epoch: 5| Step: 2
Training loss: 2.556664777835445
Validation loss: 2.468699605644718

Epoch: 5| Step: 3
Training loss: 2.5996832031038406
Validation loss: 2.470711033824782

Epoch: 5| Step: 4
Training loss: 2.389885981405781
Validation loss: 2.469300003592888

Epoch: 5| Step: 5
Training loss: 2.218736460469802
Validation loss: 2.4707734752585697

Epoch: 5| Step: 6
Training loss: 2.3850586357346297
Validation loss: 2.464246493130093

Epoch: 5| Step: 7
Training loss: 2.200871390384763
Validation loss: 2.468637846157638

Epoch: 5| Step: 8
Training loss: 2.7406020403849602
Validation loss: 2.468923003335808

Epoch: 5| Step: 9
Training loss: 3.0812038766376264
Validation loss: 2.4683477319458005

Epoch: 5| Step: 10
Training loss: 2.9599177635213247
Validation loss: 2.4733805788245573

Epoch: 5| Step: 11
Training loss: 2.5904081946419493
Validation loss: 2.474424215252735

Epoch: 100| Step: 0
Training loss: 2.5751457802699895
Validation loss: 2.4789374282916796

Epoch: 5| Step: 1
Training loss: 2.630884024569008
Validation loss: 2.475497320571679

Epoch: 5| Step: 2
Training loss: 2.7875975279574985
Validation loss: 2.4744375520992836

Epoch: 5| Step: 3
Training loss: 2.806767959201568
Validation loss: 2.481366461159467

Epoch: 5| Step: 4
Training loss: 2.621073829359146
Validation loss: 2.478164656018343

Epoch: 5| Step: 5
Training loss: 2.6758914674209526
Validation loss: 2.474449608193409

Epoch: 5| Step: 6
Training loss: 2.4608191083253
Validation loss: 2.4752122625850554

Epoch: 5| Step: 7
Training loss: 2.3544021646194797
Validation loss: 2.475816957427515

Epoch: 5| Step: 8
Training loss: 2.4100270538077884
Validation loss: 2.477286139822563

Epoch: 5| Step: 9
Training loss: 2.748598608659227
Validation loss: 2.4691758653656297

Epoch: 5| Step: 10
Training loss: 2.4466761482671777
Validation loss: 2.47293484982943

Epoch: 5| Step: 11
Training loss: 1.9027713866795535
Validation loss: 2.4730407552483222

Epoch: 101| Step: 0
Training loss: 2.329074537972148
Validation loss: 2.470203679885164

Epoch: 5| Step: 1
Training loss: 2.653043179997114
Validation loss: 2.4712020309994687

Epoch: 5| Step: 2
Training loss: 2.0670477695195704
Validation loss: 2.470957919566664

Epoch: 5| Step: 3
Training loss: 2.2768813853104946
Validation loss: 2.4699899923389546

Epoch: 5| Step: 4
Training loss: 2.5957893718917795
Validation loss: 2.469916474529852

Epoch: 5| Step: 5
Training loss: 2.808401385047831
Validation loss: 2.4699082132420456

Epoch: 5| Step: 6
Training loss: 3.1846887495704546
Validation loss: 2.4726198584443324

Epoch: 5| Step: 7
Training loss: 2.966590175999858
Validation loss: 2.4765444132147425

Epoch: 5| Step: 8
Training loss: 2.632238399045649
Validation loss: 2.4758863579060106

Epoch: 5| Step: 9
Training loss: 2.468242158444379
Validation loss: 2.480086646098174

Epoch: 5| Step: 10
Training loss: 2.2692658733751188
Validation loss: 2.4690848195909467

Epoch: 5| Step: 11
Training loss: 2.917247024198553
Validation loss: 2.4685962645230184

Epoch: 102| Step: 0
Training loss: 2.682612477101571
Validation loss: 2.4731627393016495

Epoch: 5| Step: 1
Training loss: 2.3741394290809965
Validation loss: 2.4766157367170902

Epoch: 5| Step: 2
Training loss: 2.406569719748323
Validation loss: 2.481508504660183

Epoch: 5| Step: 3
Training loss: 2.694322841124387
Validation loss: 2.482679526271365

Epoch: 5| Step: 4
Training loss: 2.846921054036279
Validation loss: 2.47932567941319

Epoch: 5| Step: 5
Training loss: 2.716169601633905
Validation loss: 2.476493100418378

Epoch: 5| Step: 6
Training loss: 2.474339013508855
Validation loss: 2.4776305894857438

Epoch: 5| Step: 7
Training loss: 3.009300121671157
Validation loss: 2.474858717787334

Epoch: 5| Step: 8
Training loss: 2.535028345675627
Validation loss: 2.4709519533649917

Epoch: 5| Step: 9
Training loss: 2.2163490952284945
Validation loss: 2.4688646193345924

Epoch: 5| Step: 10
Training loss: 2.1374614199006543
Validation loss: 2.470346964419368

Epoch: 5| Step: 11
Training loss: 3.3267998721325562
Validation loss: 2.4686308401459374

Epoch: 103| Step: 0
Training loss: 2.466388297053414
Validation loss: 2.4658758276805557

Epoch: 5| Step: 1
Training loss: 2.1583447440102295
Validation loss: 2.470810448849883

Epoch: 5| Step: 2
Training loss: 2.788760727229533
Validation loss: 2.468591902294104

Epoch: 5| Step: 3
Training loss: 2.773103935706778
Validation loss: 2.4712310548646923

Epoch: 5| Step: 4
Training loss: 2.880346716832451
Validation loss: 2.464773996275998

Epoch: 5| Step: 5
Training loss: 2.3322314203638377
Validation loss: 2.468799425588058

Epoch: 5| Step: 6
Training loss: 2.7560028968817956
Validation loss: 2.46906833366835

Epoch: 5| Step: 7
Training loss: 2.694500433175156
Validation loss: 2.4709349150358886

Epoch: 5| Step: 8
Training loss: 2.371787257324389
Validation loss: 2.474103466930026

Epoch: 5| Step: 9
Training loss: 2.7399724725050523
Validation loss: 2.471884692977246

Epoch: 5| Step: 10
Training loss: 2.4202280659043707
Validation loss: 2.4724464307394056

Epoch: 5| Step: 11
Training loss: 2.6537519489268595
Validation loss: 2.4720221736480847

Epoch: 104| Step: 0
Training loss: 2.4848213994339634
Validation loss: 2.46860430082308

Epoch: 5| Step: 1
Training loss: 3.1220609958904624
Validation loss: 2.470503638938

Epoch: 5| Step: 2
Training loss: 2.310015710058915
Validation loss: 2.471227449009676

Epoch: 5| Step: 3
Training loss: 2.32499022943228
Validation loss: 2.474890636988441

Epoch: 5| Step: 4
Training loss: 2.002177721776375
Validation loss: 2.478237546326946

Epoch: 5| Step: 5
Training loss: 2.8022661303109473
Validation loss: 2.4777274134734237

Epoch: 5| Step: 6
Training loss: 2.8059303696381726
Validation loss: 2.4779516710274545

Epoch: 5| Step: 7
Training loss: 2.77514234985355
Validation loss: 2.4695906596050703

Epoch: 5| Step: 8
Training loss: 2.181773291834064
Validation loss: 2.469403699448866

Epoch: 5| Step: 9
Training loss: 2.816619822622359
Validation loss: 2.4648112371993642

Epoch: 5| Step: 10
Training loss: 2.430571465818617
Validation loss: 2.4720171101869415

Epoch: 5| Step: 11
Training loss: 2.841606925567573
Validation loss: 2.473864858099504

Epoch: 105| Step: 0
Training loss: 2.033985701901754
Validation loss: 2.4779927909960193

Epoch: 5| Step: 1
Training loss: 2.417948634937535
Validation loss: 2.4812075538431815

Epoch: 5| Step: 2
Training loss: 2.839675499550789
Validation loss: 2.4838949055502715

Epoch: 5| Step: 3
Training loss: 2.651705635626839
Validation loss: 2.4922876447529143

Epoch: 5| Step: 4
Training loss: 2.8529569377891764
Validation loss: 2.486005360084529

Epoch: 5| Step: 5
Training loss: 2.185624872065282
Validation loss: 2.4857697720212397

Epoch: 5| Step: 6
Training loss: 2.824217230452133
Validation loss: 2.48039698859911

Epoch: 5| Step: 7
Training loss: 2.4895973258376776
Validation loss: 2.4840761200843424

Epoch: 5| Step: 8
Training loss: 2.5250417611473934
Validation loss: 2.4867487589305486

Epoch: 5| Step: 9
Training loss: 2.942645497059118
Validation loss: 2.4815137929523448

Epoch: 5| Step: 10
Training loss: 2.5833396193725235
Validation loss: 2.4755497695919253

Epoch: 5| Step: 11
Training loss: 2.932820102557824
Validation loss: 2.4707716177190506

Epoch: 106| Step: 0
Training loss: 2.46069702911179
Validation loss: 2.4736054754422065

Epoch: 5| Step: 1
Training loss: 2.14120453277969
Validation loss: 2.4711304869219024

Epoch: 5| Step: 2
Training loss: 2.894635362078362
Validation loss: 2.4706890482746533

Epoch: 5| Step: 3
Training loss: 2.7678360371290376
Validation loss: 2.466896347090131

Epoch: 5| Step: 4
Training loss: 2.693594653259264
Validation loss: 2.4665504668763187

Epoch: 5| Step: 5
Training loss: 2.866343860046006
Validation loss: 2.4634599826704138

Epoch: 5| Step: 6
Training loss: 2.7580056271457596
Validation loss: 2.464896727978528

Epoch: 5| Step: 7
Training loss: 3.1183422120166857
Validation loss: 2.4697524301047364

Epoch: 5| Step: 8
Training loss: 2.192929967218627
Validation loss: 2.4630485885345865

Epoch: 5| Step: 9
Training loss: 2.265600585805957
Validation loss: 2.4652501540509406

Epoch: 5| Step: 10
Training loss: 2.1513977741243773
Validation loss: 2.464198193697281

Epoch: 5| Step: 11
Training loss: 2.8018672439090033
Validation loss: 2.4618047326544956

Epoch: 107| Step: 0
Training loss: 2.0054335694743686
Validation loss: 2.4657773337065083

Epoch: 5| Step: 1
Training loss: 3.290105296481934
Validation loss: 2.464427612611202

Epoch: 5| Step: 2
Training loss: 2.278737918991231
Validation loss: 2.4747063934649303

Epoch: 5| Step: 3
Training loss: 2.6698608837960944
Validation loss: 2.478271356103562

Epoch: 5| Step: 4
Training loss: 2.325594967425465
Validation loss: 2.4822729562771135

Epoch: 5| Step: 5
Training loss: 2.634520749079715
Validation loss: 2.48150134282944

Epoch: 5| Step: 6
Training loss: 2.70022957143728
Validation loss: 2.483549096721138

Epoch: 5| Step: 7
Training loss: 2.5435279430596482
Validation loss: 2.4855410200752788

Epoch: 5| Step: 8
Training loss: 2.4620527374420313
Validation loss: 2.4844558990550354

Epoch: 5| Step: 9
Training loss: 2.6481470719606732
Validation loss: 2.4825995797081153

Epoch: 5| Step: 10
Training loss: 2.5158261994644753
Validation loss: 2.4858704170880084

Epoch: 5| Step: 11
Training loss: 3.7478186302799705
Validation loss: 2.4802151828229633

Epoch: 108| Step: 0
Training loss: 2.2153630799944266
Validation loss: 2.4810170686481383

Epoch: 5| Step: 1
Training loss: 2.6367999481131723
Validation loss: 2.479140928011941

Epoch: 5| Step: 2
Training loss: 2.5533417589863667
Validation loss: 2.4769280301286556

Epoch: 5| Step: 3
Training loss: 2.9542458642441742
Validation loss: 2.4750396226029676

Epoch: 5| Step: 4
Training loss: 2.4044092246610207
Validation loss: 2.4759057835926734

Epoch: 5| Step: 5
Training loss: 2.2765883800996582
Validation loss: 2.4727605001239312

Epoch: 5| Step: 6
Training loss: 2.5916793095156625
Validation loss: 2.4718497609788272

Epoch: 5| Step: 7
Training loss: 2.61472598797417
Validation loss: 2.4723251788052134

Epoch: 5| Step: 8
Training loss: 3.0389611391555915
Validation loss: 2.4712332095313987

Epoch: 5| Step: 9
Training loss: 2.7244387337357017
Validation loss: 2.4675390154579646

Epoch: 5| Step: 10
Training loss: 2.469519965904206
Validation loss: 2.4659644640594576

Epoch: 5| Step: 11
Training loss: 1.0225645812515707
Validation loss: 2.4612401140439726

Epoch: 109| Step: 0
Training loss: 2.8684573155113613
Validation loss: 2.4606454464017142

Epoch: 5| Step: 1
Training loss: 2.6288580925485605
Validation loss: 2.4615637048118906

Epoch: 5| Step: 2
Training loss: 2.7006812543070913
Validation loss: 2.4632808145300276

Epoch: 5| Step: 3
Training loss: 2.282270020580032
Validation loss: 2.460967331155484

Epoch: 5| Step: 4
Training loss: 2.688790920625411
Validation loss: 2.4645032652561576

Epoch: 5| Step: 5
Training loss: 2.4513771001612183
Validation loss: 2.464938496956615

Epoch: 5| Step: 6
Training loss: 2.517746309355151
Validation loss: 2.4600766810817225

Epoch: 5| Step: 7
Training loss: 2.987123511944284
Validation loss: 2.464691612840293

Epoch: 5| Step: 8
Training loss: 1.7592060583930584
Validation loss: 2.4668998183322923

Epoch: 5| Step: 9
Training loss: 2.7331688536801106
Validation loss: 2.4645785971494187

Epoch: 5| Step: 10
Training loss: 2.5490685126703827
Validation loss: 2.4611940764839635

Epoch: 5| Step: 11
Training loss: 1.919718392999296
Validation loss: 2.46101166144146

Epoch: 110| Step: 0
Training loss: 2.737527915080675
Validation loss: 2.462012351915119

Epoch: 5| Step: 1
Training loss: 3.193788346808759
Validation loss: 2.4640066153011237

Epoch: 5| Step: 2
Training loss: 2.6783839132885507
Validation loss: 2.4677028970482717

Epoch: 5| Step: 3
Training loss: 2.3346586777648244
Validation loss: 2.465689391635814

Epoch: 5| Step: 4
Training loss: 2.2108206027235133
Validation loss: 2.4716220961037787

Epoch: 5| Step: 5
Training loss: 2.781085234487058
Validation loss: 2.473157758511076

Epoch: 5| Step: 6
Training loss: 2.2954587138058287
Validation loss: 2.473982356440038

Epoch: 5| Step: 7
Training loss: 2.1016377148410093
Validation loss: 2.480032081915631

Epoch: 5| Step: 8
Training loss: 2.996115235571185
Validation loss: 2.482749643204334

Epoch: 5| Step: 9
Training loss: 2.496438541388547
Validation loss: 2.477709066562538

Epoch: 5| Step: 10
Training loss: 2.436619232679718
Validation loss: 2.4795500448196783

Epoch: 5| Step: 11
Training loss: 2.0918163651271633
Validation loss: 2.479245554579824

Epoch: 111| Step: 0
Training loss: 2.183571257500994
Validation loss: 2.479626886676206

Epoch: 5| Step: 1
Training loss: 3.060449030224415
Validation loss: 2.4769242039594155

Epoch: 5| Step: 2
Training loss: 2.358487903485505
Validation loss: 2.4783981772377506

Epoch: 5| Step: 3
Training loss: 2.3274680625289546
Validation loss: 2.4754242171434733

Epoch: 5| Step: 4
Training loss: 2.2424236532119926
Validation loss: 2.4725143809747276

Epoch: 5| Step: 5
Training loss: 2.771490052683138
Validation loss: 2.4736490772433966

Epoch: 5| Step: 6
Training loss: 2.7671987937209983
Validation loss: 2.4709956381713107

Epoch: 5| Step: 7
Training loss: 2.4425461206210795
Validation loss: 2.466667367209086

Epoch: 5| Step: 8
Training loss: 2.411921666057889
Validation loss: 2.4655687663374444

Epoch: 5| Step: 9
Training loss: 2.9494636888663197
Validation loss: 2.465494584831563

Epoch: 5| Step: 10
Training loss: 2.637652196605915
Validation loss: 2.4599404873666146

Epoch: 5| Step: 11
Training loss: 2.0209042513748883
Validation loss: 2.453460646099738

Epoch: 112| Step: 0
Training loss: 2.911615812151947
Validation loss: 2.45822929846465

Epoch: 5| Step: 1
Training loss: 2.69215637295308
Validation loss: 2.4586719984143204

Epoch: 5| Step: 2
Training loss: 3.0461568915374873
Validation loss: 2.447328071984843

Epoch: 5| Step: 3
Training loss: 2.5223767203384626
Validation loss: 2.4536132245672673

Epoch: 5| Step: 4
Training loss: 2.4531384121473523
Validation loss: 2.4548263967008856

Epoch: 5| Step: 5
Training loss: 2.4009765704440533
Validation loss: 2.4520145219164875

Epoch: 5| Step: 6
Training loss: 2.1662415918890328
Validation loss: 2.454514310519599

Epoch: 5| Step: 7
Training loss: 2.687579663892415
Validation loss: 2.4603614132841356

Epoch: 5| Step: 8
Training loss: 2.4154947223546452
Validation loss: 2.453479652118803

Epoch: 5| Step: 9
Training loss: 2.4621214909764557
Validation loss: 2.4595230518454287

Epoch: 5| Step: 10
Training loss: 2.3304451256122705
Validation loss: 2.4607122994374095

Epoch: 5| Step: 11
Training loss: 2.4439715038704843
Validation loss: 2.466590608947084

Epoch: 113| Step: 0
Training loss: 2.527898476994568
Validation loss: 2.467350482610597

Epoch: 5| Step: 1
Training loss: 2.6964772237179724
Validation loss: 2.4672946946104237

Epoch: 5| Step: 2
Training loss: 2.619065342673901
Validation loss: 2.4673478897205268

Epoch: 5| Step: 3
Training loss: 2.2276077761623445
Validation loss: 2.464542501492385

Epoch: 5| Step: 4
Training loss: 2.413868325334508
Validation loss: 2.4640164042216806

Epoch: 5| Step: 5
Training loss: 2.952038438913731
Validation loss: 2.4676962869225876

Epoch: 5| Step: 6
Training loss: 2.6198422760116644
Validation loss: 2.466538247318234

Epoch: 5| Step: 7
Training loss: 2.953627932072793
Validation loss: 2.4636568858413117

Epoch: 5| Step: 8
Training loss: 2.1345189013918735
Validation loss: 2.461881567500854

Epoch: 5| Step: 9
Training loss: 2.560132491438336
Validation loss: 2.461848458718977

Epoch: 5| Step: 10
Training loss: 2.37027239831586
Validation loss: 2.4610975425390196

Epoch: 5| Step: 11
Training loss: 2.2336832322792612
Validation loss: 2.4584787104881345

Epoch: 114| Step: 0
Training loss: 2.9235931077786925
Validation loss: 2.4586367352540934

Epoch: 5| Step: 1
Training loss: 2.3534379241906507
Validation loss: 2.4592094166912615

Epoch: 5| Step: 2
Training loss: 2.5784278460562193
Validation loss: 2.4557867714256596

Epoch: 5| Step: 3
Training loss: 2.4880697738394333
Validation loss: 2.4572841956809457

Epoch: 5| Step: 4
Training loss: 2.775664560971913
Validation loss: 2.458299039881679

Epoch: 5| Step: 5
Training loss: 2.638098055031584
Validation loss: 2.4583140078824894

Epoch: 5| Step: 6
Training loss: 2.081695701370166
Validation loss: 2.4557313538127286

Epoch: 5| Step: 7
Training loss: 2.6659686744663906
Validation loss: 2.4578975248089896

Epoch: 5| Step: 8
Training loss: 2.8864864932150116
Validation loss: 2.454715156682663

Epoch: 5| Step: 9
Training loss: 1.548745767681506
Validation loss: 2.4473897705089622

Epoch: 5| Step: 10
Training loss: 3.0132277056936574
Validation loss: 2.4516725310024903

Epoch: 5| Step: 11
Training loss: 0.5237786903352942
Validation loss: 2.454852413220234

Epoch: 115| Step: 0
Training loss: 2.6618239319007744
Validation loss: 2.4531717073242034

Epoch: 5| Step: 1
Training loss: 2.4017644912665332
Validation loss: 2.453142708716488

Epoch: 5| Step: 2
Training loss: 2.1930983703161937
Validation loss: 2.450850633136231

Epoch: 5| Step: 3
Training loss: 2.381020894881347
Validation loss: 2.453317517220095

Epoch: 5| Step: 4
Training loss: 2.8384581573987857
Validation loss: 2.452136022611522

Epoch: 5| Step: 5
Training loss: 2.7325121828524854
Validation loss: 2.4523501458175265

Epoch: 5| Step: 6
Training loss: 2.9146544645262855
Validation loss: 2.4518783422611485

Epoch: 5| Step: 7
Training loss: 2.3636203995412295
Validation loss: 2.4556803464166315

Epoch: 5| Step: 8
Training loss: 2.0722051066946596
Validation loss: 2.4540916328315308

Epoch: 5| Step: 9
Training loss: 2.9290179899059807
Validation loss: 2.4518466238589918

Epoch: 5| Step: 10
Training loss: 2.31260464405734
Validation loss: 2.452990319671326

Epoch: 5| Step: 11
Training loss: 3.040792487648885
Validation loss: 2.453674671929696

Epoch: 116| Step: 0
Training loss: 2.265706238441147
Validation loss: 2.455684416043951

Epoch: 5| Step: 1
Training loss: 2.286093912359934
Validation loss: 2.4566707821733464

Epoch: 5| Step: 2
Training loss: 2.091949371848526
Validation loss: 2.4553895670331123

Epoch: 5| Step: 3
Training loss: 2.2171111165627297
Validation loss: 2.4545571465607128

Epoch: 5| Step: 4
Training loss: 2.450392251825241
Validation loss: 2.4553160186725536

Epoch: 5| Step: 5
Training loss: 2.098414676454087
Validation loss: 2.459850022562953

Epoch: 5| Step: 6
Training loss: 3.2888950477433605
Validation loss: 2.458529873981763

Epoch: 5| Step: 7
Training loss: 2.827034671582978
Validation loss: 2.460027362915539

Epoch: 5| Step: 8
Training loss: 2.662807314334615
Validation loss: 2.4653308103048013

Epoch: 5| Step: 9
Training loss: 2.991084998777144
Validation loss: 2.4599146579267415

Epoch: 5| Step: 10
Training loss: 2.7068247970967265
Validation loss: 2.458388802069623

Epoch: 5| Step: 11
Training loss: 1.83021185029122
Validation loss: 2.4518886050221944

Epoch: 117| Step: 0
Training loss: 2.4594177397488433
Validation loss: 2.457062580048383

Epoch: 5| Step: 1
Training loss: 2.1309683515757527
Validation loss: 2.4546175099509653

Epoch: 5| Step: 2
Training loss: 2.0054491435193342
Validation loss: 2.457927065485273

Epoch: 5| Step: 3
Training loss: 2.4713052008507472
Validation loss: 2.4550441151855233

Epoch: 5| Step: 4
Training loss: 2.8697493331380683
Validation loss: 2.4525355706080303

Epoch: 5| Step: 5
Training loss: 2.3426937520642115
Validation loss: 2.454255028047696

Epoch: 5| Step: 6
Training loss: 2.4443006280535
Validation loss: 2.452770794770566

Epoch: 5| Step: 7
Training loss: 2.747495898312257
Validation loss: 2.452727457704939

Epoch: 5| Step: 8
Training loss: 2.810339458094068
Validation loss: 2.451628351958108

Epoch: 5| Step: 9
Training loss: 3.0477065296616703
Validation loss: 2.4513310475740346

Epoch: 5| Step: 10
Training loss: 2.376791629618078
Validation loss: 2.450894830252781

Epoch: 5| Step: 11
Training loss: 3.0638080839505535
Validation loss: 2.442837190516693

Epoch: 118| Step: 0
Training loss: 2.4428084840286464
Validation loss: 2.448681567113594

Epoch: 5| Step: 1
Training loss: 2.983371266242881
Validation loss: 2.4467916636040647

Epoch: 5| Step: 2
Training loss: 2.63779998085785
Validation loss: 2.449892473618471

Epoch: 5| Step: 3
Training loss: 2.179899472009856
Validation loss: 2.4452092572437145

Epoch: 5| Step: 4
Training loss: 2.3341338169664976
Validation loss: 2.4514231620142146

Epoch: 5| Step: 5
Training loss: 2.2160101078367553
Validation loss: 2.4527569026917933

Epoch: 5| Step: 6
Training loss: 2.5861904792703028
Validation loss: 2.444478588485915

Epoch: 5| Step: 7
Training loss: 2.6573528917278404
Validation loss: 2.4482789292359914

Epoch: 5| Step: 8
Training loss: 2.3493652216897343
Validation loss: 2.44820128199871

Epoch: 5| Step: 9
Training loss: 3.0850816529780847
Validation loss: 2.4434643628083474

Epoch: 5| Step: 10
Training loss: 2.4462569975131556
Validation loss: 2.441386535564934

Epoch: 5| Step: 11
Training loss: 2.621238465727177
Validation loss: 2.447581297985745

Epoch: 119| Step: 0
Training loss: 2.6724593209577714
Validation loss: 2.446392608907962

Epoch: 5| Step: 1
Training loss: 2.7392476290753223
Validation loss: 2.4481290616899445

Epoch: 5| Step: 2
Training loss: 2.4189125893527446
Validation loss: 2.447609309251558

Epoch: 5| Step: 3
Training loss: 2.4870381027082216
Validation loss: 2.452937744671698

Epoch: 5| Step: 4
Training loss: 2.4863802896138147
Validation loss: 2.457422113183598

Epoch: 5| Step: 5
Training loss: 2.3764992047771436
Validation loss: 2.4552733738964236

Epoch: 5| Step: 6
Training loss: 2.3701364007964028
Validation loss: 2.4557366935692837

Epoch: 5| Step: 7
Training loss: 2.5046979631477884
Validation loss: 2.45753312557166

Epoch: 5| Step: 8
Training loss: 2.777642213904292
Validation loss: 2.461526366326949

Epoch: 5| Step: 9
Training loss: 2.644099460889459
Validation loss: 2.4582126043599546

Epoch: 5| Step: 10
Training loss: 2.3819228215498134
Validation loss: 2.455303107984066

Epoch: 5| Step: 11
Training loss: 2.9790707730596866
Validation loss: 2.4538975367836193

Epoch: 120| Step: 0
Training loss: 2.833262966254581
Validation loss: 2.451190651546869

Epoch: 5| Step: 1
Training loss: 2.251042230603949
Validation loss: 2.4487367243891307

Epoch: 5| Step: 2
Training loss: 2.7274556705498356
Validation loss: 2.4526543823877947

Epoch: 5| Step: 3
Training loss: 2.88010351577798
Validation loss: 2.4507890582200944

Epoch: 5| Step: 4
Training loss: 2.781109238395038
Validation loss: 2.4464619730882506

Epoch: 5| Step: 5
Training loss: 2.3455007499152036
Validation loss: 2.445555320440571

Epoch: 5| Step: 6
Training loss: 2.1972128899921723
Validation loss: 2.4491162235555297

Epoch: 5| Step: 7
Training loss: 2.1224536224798025
Validation loss: 2.4480806877431074

Epoch: 5| Step: 8
Training loss: 2.5118673942091982
Validation loss: 2.4546694338251265

Epoch: 5| Step: 9
Training loss: 2.5630211649068086
Validation loss: 2.4476863401016193

Epoch: 5| Step: 10
Training loss: 2.80522690370355
Validation loss: 2.4483271146493633

Epoch: 5| Step: 11
Training loss: 1.2931138616997608
Validation loss: 2.448622083816663

Epoch: 121| Step: 0
Training loss: 2.2281919707389615
Validation loss: 2.4452022084804077

Epoch: 5| Step: 1
Training loss: 2.4088558602541905
Validation loss: 2.4430503050038257

Epoch: 5| Step: 2
Training loss: 2.099355112693104
Validation loss: 2.447254949101419

Epoch: 5| Step: 3
Training loss: 2.737015762350614
Validation loss: 2.449205255547298

Epoch: 5| Step: 4
Training loss: 2.4649346723276
Validation loss: 2.4498119132836527

Epoch: 5| Step: 5
Training loss: 2.498181349152454
Validation loss: 2.4534849643841277

Epoch: 5| Step: 6
Training loss: 2.708008869004482
Validation loss: 2.443421864898444

Epoch: 5| Step: 7
Training loss: 2.7993927603701385
Validation loss: 2.4479722415756893

Epoch: 5| Step: 8
Training loss: 2.953418212543492
Validation loss: 2.4463938910789422

Epoch: 5| Step: 9
Training loss: 2.6403524043665807
Validation loss: 2.447123936202025

Epoch: 5| Step: 10
Training loss: 2.3232142738182273
Validation loss: 2.4497729155665793

Epoch: 5| Step: 11
Training loss: 2.83463545404848
Validation loss: 2.448324945910244

Epoch: 122| Step: 0
Training loss: 2.5001122449472555
Validation loss: 2.4488894349183368

Epoch: 5| Step: 1
Training loss: 2.4301445337961196
Validation loss: 2.4531379747958777

Epoch: 5| Step: 2
Training loss: 2.6087784684898505
Validation loss: 2.4572820449539394

Epoch: 5| Step: 3
Training loss: 2.5899870819889017
Validation loss: 2.461828221992581

Epoch: 5| Step: 4
Training loss: 1.8986066578041776
Validation loss: 2.463632252636

Epoch: 5| Step: 5
Training loss: 2.4542249412504673
Validation loss: 2.455091097566558

Epoch: 5| Step: 6
Training loss: 2.58820117166792
Validation loss: 2.459883909393774

Epoch: 5| Step: 7
Training loss: 2.8664247085421954
Validation loss: 2.4566961402582934

Epoch: 5| Step: 8
Training loss: 2.5650675866218395
Validation loss: 2.4525642118495883

Epoch: 5| Step: 9
Training loss: 2.9281574780791186
Validation loss: 2.4562249005226766

Epoch: 5| Step: 10
Training loss: 2.4633433374383293
Validation loss: 2.4552007142311405

Epoch: 5| Step: 11
Training loss: 2.656104947785826
Validation loss: 2.449622859602413

Epoch: 123| Step: 0
Training loss: 2.6897145395658266
Validation loss: 2.4556368341546704

Epoch: 5| Step: 1
Training loss: 2.7231757435985804
Validation loss: 2.4517220618029687

Epoch: 5| Step: 2
Training loss: 2.496724748924741
Validation loss: 2.4532754774977104

Epoch: 5| Step: 3
Training loss: 2.387320634585328
Validation loss: 2.4519480779503815

Epoch: 5| Step: 4
Training loss: 2.1542851438228867
Validation loss: 2.4522622529068974

Epoch: 5| Step: 5
Training loss: 2.543208754035257
Validation loss: 2.451942223502422

Epoch: 5| Step: 6
Training loss: 2.3025571125580786
Validation loss: 2.453306843361512

Epoch: 5| Step: 7
Training loss: 2.82184050106957
Validation loss: 2.4537471662593417

Epoch: 5| Step: 8
Training loss: 2.6477535118502593
Validation loss: 2.4513765166069197

Epoch: 5| Step: 9
Training loss: 2.377227842556027
Validation loss: 2.453182345325466

Epoch: 5| Step: 10
Training loss: 2.832847067300645
Validation loss: 2.449259754103339

Epoch: 5| Step: 11
Training loss: 2.679915526894966
Validation loss: 2.447760976074366

Epoch: 124| Step: 0
Training loss: 2.0171786685575945
Validation loss: 2.4521222099867424

Epoch: 5| Step: 1
Training loss: 2.127084607140449
Validation loss: 2.451137377330282

Epoch: 5| Step: 2
Training loss: 2.7412873010493684
Validation loss: 2.444881267122004

Epoch: 5| Step: 3
Training loss: 2.6509380407758902
Validation loss: 2.4450730032836265

Epoch: 5| Step: 4
Training loss: 2.921184927493505
Validation loss: 2.4480837271208156

Epoch: 5| Step: 5
Training loss: 2.744161998081802
Validation loss: 2.4506838856096658

Epoch: 5| Step: 6
Training loss: 2.651458187895061
Validation loss: 2.451590108462743

Epoch: 5| Step: 7
Training loss: 2.6364771301330956
Validation loss: 2.4532036009423877

Epoch: 5| Step: 8
Training loss: 2.3304261989206445
Validation loss: 2.448640474216848

Epoch: 5| Step: 9
Training loss: 2.6379137736089575
Validation loss: 2.4524388092630414

Epoch: 5| Step: 10
Training loss: 2.317325197477
Validation loss: 2.4458816178855955

Epoch: 5| Step: 11
Training loss: 2.6379831856805587
Validation loss: 2.4473900830567366

Epoch: 125| Step: 0
Training loss: 2.2948083208276024
Validation loss: 2.446101931624577

Epoch: 5| Step: 1
Training loss: 2.5904176746415737
Validation loss: 2.4440349292423478

Epoch: 5| Step: 2
Training loss: 1.9769530984682189
Validation loss: 2.443732367612118

Epoch: 5| Step: 3
Training loss: 2.434259853161705
Validation loss: 2.4423472592423767

Epoch: 5| Step: 4
Training loss: 2.9474076729146996
Validation loss: 2.441424043717709

Epoch: 5| Step: 5
Training loss: 3.0784374407678308
Validation loss: 2.444922317559289

Epoch: 5| Step: 6
Training loss: 1.9620468223848764
Validation loss: 2.4422922383255976

Epoch: 5| Step: 7
Training loss: 2.8977811743743014
Validation loss: 2.4432418839717243

Epoch: 5| Step: 8
Training loss: 2.349263128452005
Validation loss: 2.4482614247383276

Epoch: 5| Step: 9
Training loss: 2.680544346427431
Validation loss: 2.45000797922431

Epoch: 5| Step: 10
Training loss: 2.6144817884769886
Validation loss: 2.4538911364167966

Epoch: 5| Step: 11
Training loss: 2.4015868940833194
Validation loss: 2.455810207082875

Epoch: 126| Step: 0
Training loss: 2.7192335904492446
Validation loss: 2.454998928543758

Epoch: 5| Step: 1
Training loss: 2.127725424204083
Validation loss: 2.457612159519933

Epoch: 5| Step: 2
Training loss: 2.5041748474122874
Validation loss: 2.4543802285549527

Epoch: 5| Step: 3
Training loss: 2.3877609150305252
Validation loss: 2.454878304016779

Epoch: 5| Step: 4
Training loss: 2.164253529404209
Validation loss: 2.450637511915654

Epoch: 5| Step: 5
Training loss: 2.7863371540470383
Validation loss: 2.4541920125221344

Epoch: 5| Step: 6
Training loss: 2.399988126725391
Validation loss: 2.4506486453305456

Epoch: 5| Step: 7
Training loss: 2.5796503352001396
Validation loss: 2.447521915802006

Epoch: 5| Step: 8
Training loss: 2.8445321149858787
Validation loss: 2.450893334600366

Epoch: 5| Step: 9
Training loss: 2.7032198145119586
Validation loss: 2.443764225885037

Epoch: 5| Step: 10
Training loss: 2.698322152752143
Validation loss: 2.4494860562560126

Epoch: 5| Step: 11
Training loss: 2.326164700411375
Validation loss: 2.441160770536322

Epoch: 127| Step: 0
Training loss: 2.5266626492705737
Validation loss: 2.444046978820128

Epoch: 5| Step: 1
Training loss: 2.3421355727167263
Validation loss: 2.4430458768294208

Epoch: 5| Step: 2
Training loss: 2.6718112871035715
Validation loss: 2.446283028012039

Epoch: 5| Step: 3
Training loss: 2.0156223977242167
Validation loss: 2.447024518978812

Epoch: 5| Step: 4
Training loss: 2.293369862502102
Validation loss: 2.447447481575798

Epoch: 5| Step: 5
Training loss: 2.7119619758832303
Validation loss: 2.4429870167240333

Epoch: 5| Step: 6
Training loss: 2.878627147628869
Validation loss: 2.446622601154718

Epoch: 5| Step: 7
Training loss: 2.957398244440661
Validation loss: 2.4438782976168687

Epoch: 5| Step: 8
Training loss: 2.6082891157828403
Validation loss: 2.455233876242878

Epoch: 5| Step: 9
Training loss: 2.595686499870339
Validation loss: 2.4551708777484804

Epoch: 5| Step: 10
Training loss: 2.2890183376179345
Validation loss: 2.45538773224507

Epoch: 5| Step: 11
Training loss: 2.241539838339438
Validation loss: 2.454991118822265

Epoch: 128| Step: 0
Training loss: 2.7280560531730558
Validation loss: 2.450918659236849

Epoch: 5| Step: 1
Training loss: 2.266069250289349
Validation loss: 2.4525455389807926

Epoch: 5| Step: 2
Training loss: 2.4453550097393277
Validation loss: 2.451886538697921

Epoch: 5| Step: 3
Training loss: 2.9362226915124867
Validation loss: 2.4518322504682675

Epoch: 5| Step: 4
Training loss: 2.6534216689097025
Validation loss: 2.4563990043826234

Epoch: 5| Step: 5
Training loss: 2.559959268543936
Validation loss: 2.450920025170912

Epoch: 5| Step: 6
Training loss: 2.6972682767795617
Validation loss: 2.4530808835608346

Epoch: 5| Step: 7
Training loss: 2.6037342068490346
Validation loss: 2.452690017103867

Epoch: 5| Step: 8
Training loss: 2.6906138279203304
Validation loss: 2.4528468028943293

Epoch: 5| Step: 9
Training loss: 2.3139971448902132
Validation loss: 2.4508638145313584

Epoch: 5| Step: 10
Training loss: 2.0230962399243624
Validation loss: 2.4567401634718897

Epoch: 5| Step: 11
Training loss: 1.9061278006986928
Validation loss: 2.449302680013846

Epoch: 129| Step: 0
Training loss: 2.443299754000055
Validation loss: 2.4494360341167813

Epoch: 5| Step: 1
Training loss: 2.8013416618115636
Validation loss: 2.4498386602411513

Epoch: 5| Step: 2
Training loss: 2.5994689582487194
Validation loss: 2.4457684296006503

Epoch: 5| Step: 3
Training loss: 2.856987295003006
Validation loss: 2.4453496940311004

Epoch: 5| Step: 4
Training loss: 2.5117895611737824
Validation loss: 2.4542337855847127

Epoch: 5| Step: 5
Training loss: 2.430869842070306
Validation loss: 2.447168391417832

Epoch: 5| Step: 6
Training loss: 2.5783264081484263
Validation loss: 2.4472174369530926

Epoch: 5| Step: 7
Training loss: 2.619172849179564
Validation loss: 2.4459568958058493

Epoch: 5| Step: 8
Training loss: 2.246654991021461
Validation loss: 2.453165041845774

Epoch: 5| Step: 9
Training loss: 2.2888339713009227
Validation loss: 2.4533567744302234

Epoch: 5| Step: 10
Training loss: 2.496285540118104
Validation loss: 2.446862914492795

Epoch: 5| Step: 11
Training loss: 2.253714991343633
Validation loss: 2.449483549901042

Epoch: 130| Step: 0
Training loss: 2.957702479908309
Validation loss: 2.452849006110619

Epoch: 5| Step: 1
Training loss: 2.737118026351703
Validation loss: 2.460369008114389

Epoch: 5| Step: 2
Training loss: 2.4386704397984023
Validation loss: 2.4592754019088177

Epoch: 5| Step: 3
Training loss: 2.576008986036846
Validation loss: 2.464943393601539

Epoch: 5| Step: 4
Training loss: 2.9144574835989725
Validation loss: 2.4656934528010646

Epoch: 5| Step: 5
Training loss: 2.0294755667911826
Validation loss: 2.4684110481225137

Epoch: 5| Step: 6
Training loss: 2.078077961095333
Validation loss: 2.4597415621814687

Epoch: 5| Step: 7
Training loss: 2.7085689344388895
Validation loss: 2.4609602790868186

Epoch: 5| Step: 8
Training loss: 2.3905785250665326
Validation loss: 2.4603418709230778

Epoch: 5| Step: 9
Training loss: 2.0491141382377602
Validation loss: 2.459791035506017

Epoch: 5| Step: 10
Training loss: 2.852860664749182
Validation loss: 2.456949492419932

Epoch: 5| Step: 11
Training loss: 2.6272860064415435
Validation loss: 2.4624245888641116

Epoch: 131| Step: 0
Training loss: 2.728130949697747
Validation loss: 2.445198283915201

Epoch: 5| Step: 1
Training loss: 2.413079614140845
Validation loss: 2.448981367387163

Epoch: 5| Step: 2
Training loss: 2.5449953222325474
Validation loss: 2.4725381020457013

Epoch: 5| Step: 3
Training loss: 2.667335803797896
Validation loss: 2.493073635750054

Epoch: 5| Step: 4
Training loss: 2.045209833399565
Validation loss: 2.5206251505069703

Epoch: 5| Step: 5
Training loss: 3.0868019148799526
Validation loss: 2.512164063081582

Epoch: 5| Step: 6
Training loss: 2.749165668500858
Validation loss: 2.505202098423634

Epoch: 5| Step: 7
Training loss: 2.4475375159157795
Validation loss: 2.501776171582727

Epoch: 5| Step: 8
Training loss: 2.948014292543876
Validation loss: 2.49323998671947

Epoch: 5| Step: 9
Training loss: 2.2399984167297764
Validation loss: 2.4770766305204477

Epoch: 5| Step: 10
Training loss: 2.6863486019195566
Validation loss: 2.463763278781532

Epoch: 5| Step: 11
Training loss: 2.840444299303165
Validation loss: 2.4558002398262886

Epoch: 132| Step: 0
Training loss: 2.8445574274406575
Validation loss: 2.4556796405014647

Epoch: 5| Step: 1
Training loss: 3.05228386091106
Validation loss: 2.458955077304078

Epoch: 5| Step: 2
Training loss: 2.791570481498511
Validation loss: 2.4597180488778863

Epoch: 5| Step: 3
Training loss: 2.8061796591594024
Validation loss: 2.4617086867329854

Epoch: 5| Step: 4
Training loss: 2.5636473157416324
Validation loss: 2.4761516980437723

Epoch: 5| Step: 5
Training loss: 2.271636144368174
Validation loss: 2.477758586071037

Epoch: 5| Step: 6
Training loss: 2.40932822571709
Validation loss: 2.4736963086488286

Epoch: 5| Step: 7
Training loss: 2.3972648214084322
Validation loss: 2.479003932297437

Epoch: 5| Step: 8
Training loss: 2.4895807582783385
Validation loss: 2.465456145435034

Epoch: 5| Step: 9
Training loss: 2.1457207165644023
Validation loss: 2.4688902223577522

Epoch: 5| Step: 10
Training loss: 2.3446284364554226
Validation loss: 2.4598519489273087

Epoch: 5| Step: 11
Training loss: 2.2426691368730496
Validation loss: 2.4658428531031946

Epoch: 133| Step: 0
Training loss: 1.940349022350615
Validation loss: 2.4642944126818076

Epoch: 5| Step: 1
Training loss: 2.74245736296762
Validation loss: 2.4609505143401744

Epoch: 5| Step: 2
Training loss: 2.7263796507288647
Validation loss: 2.460740617415037

Epoch: 5| Step: 3
Training loss: 2.4401621830305027
Validation loss: 2.4615649659646204

Epoch: 5| Step: 4
Training loss: 2.406537422749945
Validation loss: 2.468015110715135

Epoch: 5| Step: 5
Training loss: 2.722355873909843
Validation loss: 2.4570446125227132

Epoch: 5| Step: 6
Training loss: 2.73190876503742
Validation loss: 2.4634643983451148

Epoch: 5| Step: 7
Training loss: 2.016922880348537
Validation loss: 2.461108291593027

Epoch: 5| Step: 8
Training loss: 2.8038178267078964
Validation loss: 2.4610026517448413

Epoch: 5| Step: 9
Training loss: 2.4418689014757997
Validation loss: 2.4475574040394474

Epoch: 5| Step: 10
Training loss: 2.548776490137903
Validation loss: 2.4499941160819056

Epoch: 5| Step: 11
Training loss: 3.7147957430684837
Validation loss: 2.4427253882511577

Epoch: 134| Step: 0
Training loss: 2.7238390418068734
Validation loss: 2.4470420059368156

Epoch: 5| Step: 1
Training loss: 2.556014623274783
Validation loss: 2.4442858831198504

Epoch: 5| Step: 2
Training loss: 2.3358677882378527
Validation loss: 2.444451287078191

Epoch: 5| Step: 3
Training loss: 2.404609021547742
Validation loss: 2.4468956678093337

Epoch: 5| Step: 4
Training loss: 2.354121137420689
Validation loss: 2.4422790391411104

Epoch: 5| Step: 5
Training loss: 2.2967704697262827
Validation loss: 2.448417731332892

Epoch: 5| Step: 6
Training loss: 2.6220855882934915
Validation loss: 2.449631132526926

Epoch: 5| Step: 7
Training loss: 2.5733983956975095
Validation loss: 2.4459181615447494

Epoch: 5| Step: 8
Training loss: 2.7758432189740945
Validation loss: 2.4480020602867913

Epoch: 5| Step: 9
Training loss: 2.5516058857973243
Validation loss: 2.4512607107490982

Epoch: 5| Step: 10
Training loss: 2.4259823333398876
Validation loss: 2.4535168984684206

Epoch: 5| Step: 11
Training loss: 3.5412678363107144
Validation loss: 2.45328451759706

Epoch: 135| Step: 0
Training loss: 2.3868128481731845
Validation loss: 2.4505178807585737

Epoch: 5| Step: 1
Training loss: 1.9789450538104834
Validation loss: 2.4545783255176383

Epoch: 5| Step: 2
Training loss: 2.9353819982910423
Validation loss: 2.452543448906805

Epoch: 5| Step: 3
Training loss: 2.4606104073298876
Validation loss: 2.452477922563798

Epoch: 5| Step: 4
Training loss: 2.6466688704141177
Validation loss: 2.449821491290777

Epoch: 5| Step: 5
Training loss: 2.262903091182972
Validation loss: 2.4512273713778763

Epoch: 5| Step: 6
Training loss: 2.532990975419213
Validation loss: 2.4496944924694466

Epoch: 5| Step: 7
Training loss: 2.6809254447647297
Validation loss: 2.447774933032786

Epoch: 5| Step: 8
Training loss: 2.7990363949300163
Validation loss: 2.4464806720872714

Epoch: 5| Step: 9
Training loss: 2.7189363437677576
Validation loss: 2.446942717328473

Epoch: 5| Step: 10
Training loss: 2.4915924796943387
Validation loss: 2.442134087471277

Epoch: 5| Step: 11
Training loss: 1.72475286731407
Validation loss: 2.4412622190587334

Epoch: 136| Step: 0
Training loss: 2.4675121825747457
Validation loss: 2.444337859834369

Epoch: 5| Step: 1
Training loss: 2.2561756787515224
Validation loss: 2.446191213431302

Epoch: 5| Step: 2
Training loss: 2.4899239619644504
Validation loss: 2.4415443991675243

Epoch: 5| Step: 3
Training loss: 2.4411801653130443
Validation loss: 2.4440227515685558

Epoch: 5| Step: 4
Training loss: 2.6659798532398664
Validation loss: 2.4441852022706585

Epoch: 5| Step: 5
Training loss: 3.023224105992831
Validation loss: 2.443874578235566

Epoch: 5| Step: 6
Training loss: 2.583593314430055
Validation loss: 2.4449034583353

Epoch: 5| Step: 7
Training loss: 3.017717495264523
Validation loss: 2.4439073898936807

Epoch: 5| Step: 8
Training loss: 2.327218512897941
Validation loss: 2.4466387815363255

Epoch: 5| Step: 9
Training loss: 2.201552892031798
Validation loss: 2.448176002292552

Epoch: 5| Step: 10
Training loss: 2.1717575370804454
Validation loss: 2.4447241167689797

Epoch: 5| Step: 11
Training loss: 2.360930075592748
Validation loss: 2.4458644069428526

Epoch: 137| Step: 0
Training loss: 2.258025585005959
Validation loss: 2.442977330593602

Epoch: 5| Step: 1
Training loss: 2.7489825013603935
Validation loss: 2.44711410812503

Epoch: 5| Step: 2
Training loss: 2.540473428594372
Validation loss: 2.4546897983681912

Epoch: 5| Step: 3
Training loss: 2.123199822356986
Validation loss: 2.4632516667422237

Epoch: 5| Step: 4
Training loss: 2.8853606254194126
Validation loss: 2.4765627406748947

Epoch: 5| Step: 5
Training loss: 2.220610147776003
Validation loss: 2.479464346113495

Epoch: 5| Step: 6
Training loss: 2.8575850757606434
Validation loss: 2.474363636479915

Epoch: 5| Step: 7
Training loss: 2.4726934686303372
Validation loss: 2.452285665533315

Epoch: 5| Step: 8
Training loss: 2.3636365386989504
Validation loss: 2.451841954288864

Epoch: 5| Step: 9
Training loss: 2.407519117301231
Validation loss: 2.4565500982023503

Epoch: 5| Step: 10
Training loss: 2.8970052054071718
Validation loss: 2.4500218220147634

Epoch: 5| Step: 11
Training loss: 3.742766206150388
Validation loss: 2.4465537369033914

Epoch: 138| Step: 0
Training loss: 2.39517427308148
Validation loss: 2.4609415003829818

Epoch: 5| Step: 1
Training loss: 2.765584826851145
Validation loss: 2.4645397605387083

Epoch: 5| Step: 2
Training loss: 2.138931049685529
Validation loss: 2.4718591089135726

Epoch: 5| Step: 3
Training loss: 2.6542717242645804
Validation loss: 2.476079951947746

Epoch: 5| Step: 4
Training loss: 2.9690845501772216
Validation loss: 2.4835077607471545

Epoch: 5| Step: 5
Training loss: 2.4215893976950453
Validation loss: 2.48944645801998

Epoch: 5| Step: 6
Training loss: 2.435615593645131
Validation loss: 2.48647440769437

Epoch: 5| Step: 7
Training loss: 2.9380093396728477
Validation loss: 2.4887801408307677

Epoch: 5| Step: 8
Training loss: 2.5805331918244465
Validation loss: 2.4922460511284363

Epoch: 5| Step: 9
Training loss: 2.730187921448958
Validation loss: 2.487974578148491

Epoch: 5| Step: 10
Training loss: 2.0471897028918606
Validation loss: 2.4908817222768556

Epoch: 5| Step: 11
Training loss: 2.8136360417204913
Validation loss: 2.4877882648257583

Epoch: 139| Step: 0
Training loss: 2.6084823452083534
Validation loss: 2.4845245564227865

Epoch: 5| Step: 1
Training loss: 2.3293476350618563
Validation loss: 2.488371092383577

Epoch: 5| Step: 2
Training loss: 2.373593064233298
Validation loss: 2.478507492577147

Epoch: 5| Step: 3
Training loss: 2.566310933054439
Validation loss: 2.4760306917513564

Epoch: 5| Step: 4
Training loss: 2.635778912362248
Validation loss: 2.47539741154401

Epoch: 5| Step: 5
Training loss: 2.047599489545302
Validation loss: 2.4679798099808976

Epoch: 5| Step: 6
Training loss: 2.940633685011002
Validation loss: 2.468143207485788

Epoch: 5| Step: 7
Training loss: 2.4890335838041504
Validation loss: 2.4641948194339363

Epoch: 5| Step: 8
Training loss: 2.6700892141346118
Validation loss: 2.457921273778527

Epoch: 5| Step: 9
Training loss: 2.6946279347483344
Validation loss: 2.460550199034959

Epoch: 5| Step: 10
Training loss: 2.382419941568786
Validation loss: 2.455490373076677

Epoch: 5| Step: 11
Training loss: 3.559594023197779
Validation loss: 2.455119789921176

Epoch: 140| Step: 0
Training loss: 2.9878823007793573
Validation loss: 2.4540144771694514

Epoch: 5| Step: 1
Training loss: 1.9951978490715394
Validation loss: 2.452253308288819

Epoch: 5| Step: 2
Training loss: 2.6872490166859198
Validation loss: 2.450850681776196

Epoch: 5| Step: 3
Training loss: 2.2840480627892012
Validation loss: 2.451876081449744

Epoch: 5| Step: 4
Training loss: 2.063748068759507
Validation loss: 2.4511380217343426

Epoch: 5| Step: 5
Training loss: 2.4408112556220503
Validation loss: 2.4521835731775337

Epoch: 5| Step: 6
Training loss: 2.798306998953883
Validation loss: 2.4547716635835175

Epoch: 5| Step: 7
Training loss: 2.7927981878099377
Validation loss: 2.459472559311096

Epoch: 5| Step: 8
Training loss: 2.517624149538092
Validation loss: 2.461458601099345

Epoch: 5| Step: 9
Training loss: 2.5994995919425574
Validation loss: 2.455364343128959

Epoch: 5| Step: 10
Training loss: 2.49573477251661
Validation loss: 2.45067061001331

Epoch: 5| Step: 11
Training loss: 2.5445498284565566
Validation loss: 2.452641583249964

Epoch: 141| Step: 0
Training loss: 2.419283360071399
Validation loss: 2.4475727847540667

Epoch: 5| Step: 1
Training loss: 2.8129570483669015
Validation loss: 2.4568208605393167

Epoch: 5| Step: 2
Training loss: 2.6156965421420217
Validation loss: 2.4565496735900556

Epoch: 5| Step: 3
Training loss: 2.446422873242756
Validation loss: 2.4562763495807416

Epoch: 5| Step: 4
Training loss: 2.6120993275004905
Validation loss: 2.4631321965289676

Epoch: 5| Step: 5
Training loss: 2.2241948974959724
Validation loss: 2.458131344762225

Epoch: 5| Step: 6
Training loss: 2.647880293033303
Validation loss: 2.4609427134140742

Epoch: 5| Step: 7
Training loss: 2.679631713642391
Validation loss: 2.4625205705561304

Epoch: 5| Step: 8
Training loss: 2.3560209370380645
Validation loss: 2.462223173288861

Epoch: 5| Step: 9
Training loss: 2.43087445180399
Validation loss: 2.4589249793351384

Epoch: 5| Step: 10
Training loss: 2.79660476146228
Validation loss: 2.4516571010460906

Epoch: 5| Step: 11
Training loss: 1.2027193847197846
Validation loss: 2.4519128902793312

Epoch: 142| Step: 0
Training loss: 2.5411742833046027
Validation loss: 2.446726738411439

Epoch: 5| Step: 1
Training loss: 2.7660727273202177
Validation loss: 2.4427871989605268

Epoch: 5| Step: 2
Training loss: 2.3028688658443293
Validation loss: 2.441240399640139

Epoch: 5| Step: 3
Training loss: 2.6237445735648106
Validation loss: 2.4495583095549573

Epoch: 5| Step: 4
Training loss: 2.4776649307798477
Validation loss: 2.4513795194786003

Epoch: 5| Step: 5
Training loss: 2.340037138880563
Validation loss: 2.461195923088627

Epoch: 5| Step: 6
Training loss: 2.7080749877565693
Validation loss: 2.467796652649087

Epoch: 5| Step: 7
Training loss: 2.5033583019177983
Validation loss: 2.4727406881578284

Epoch: 5| Step: 8
Training loss: 2.5999923412503634
Validation loss: 2.486741626173671

Epoch: 5| Step: 9
Training loss: 2.7643370997094543
Validation loss: 2.466649437427491

Epoch: 5| Step: 10
Training loss: 2.426717727913413
Validation loss: 2.4494085040651825

Epoch: 5| Step: 11
Training loss: 2.7341486373937873
Validation loss: 2.4493822269344436

Epoch: 143| Step: 0
Training loss: 2.8286417283574083
Validation loss: 2.4534372467104375

Epoch: 5| Step: 1
Training loss: 2.620052397982962
Validation loss: 2.44628460364021

Epoch: 5| Step: 2
Training loss: 2.8017013081397057
Validation loss: 2.449547757202236

Epoch: 5| Step: 3
Training loss: 2.2152257519242875
Validation loss: 2.4486870196092325

Epoch: 5| Step: 4
Training loss: 2.0250372141491537
Validation loss: 2.4510541829379875

Epoch: 5| Step: 5
Training loss: 2.2413060386277155
Validation loss: 2.4464327568851076

Epoch: 5| Step: 6
Training loss: 2.328938591651588
Validation loss: 2.4468491248804414

Epoch: 5| Step: 7
Training loss: 2.775712662334485
Validation loss: 2.4488795733608804

Epoch: 5| Step: 8
Training loss: 2.7059583863627332
Validation loss: 2.446683361283868

Epoch: 5| Step: 9
Training loss: 2.541834424428731
Validation loss: 2.4404562401316077

Epoch: 5| Step: 10
Training loss: 2.5264959077664164
Validation loss: 2.449169566072831

Epoch: 5| Step: 11
Training loss: 2.5897908154999887
Validation loss: 2.4492289508970164

Epoch: 144| Step: 0
Training loss: 3.2653128004735663
Validation loss: 2.446336359212764

Epoch: 5| Step: 1
Training loss: 2.0863823005686126
Validation loss: 2.441091483615101

Epoch: 5| Step: 2
Training loss: 3.025543346946212
Validation loss: 2.4394699149041377

Epoch: 5| Step: 3
Training loss: 1.9923633572619803
Validation loss: 2.4456241559375607

Epoch: 5| Step: 4
Training loss: 2.563541572836376
Validation loss: 2.4476062043454765

Epoch: 5| Step: 5
Training loss: 2.8484789754805777
Validation loss: 2.448846487565776

Epoch: 5| Step: 6
Training loss: 2.3271586825729162
Validation loss: 2.4481673876556838

Epoch: 5| Step: 7
Training loss: 2.1054320606439205
Validation loss: 2.44551578566433

Epoch: 5| Step: 8
Training loss: 2.406995979701933
Validation loss: 2.4477321325237082

Epoch: 5| Step: 9
Training loss: 1.8401595895430327
Validation loss: 2.4448064863495054

Epoch: 5| Step: 10
Training loss: 2.7692814164135533
Validation loss: 2.4507173600612826

Epoch: 5| Step: 11
Training loss: 2.7433533540399186
Validation loss: 2.4478302284292544

Epoch: 145| Step: 0
Training loss: 2.348214944635285
Validation loss: 2.442056395366887

Epoch: 5| Step: 1
Training loss: 2.8646781397071837
Validation loss: 2.448018408074621

Epoch: 5| Step: 2
Training loss: 2.4452346935629725
Validation loss: 2.4496124048568633

Epoch: 5| Step: 3
Training loss: 1.8886619654398447
Validation loss: 2.446422792029424

Epoch: 5| Step: 4
Training loss: 2.4734743521590383
Validation loss: 2.448123179848872

Epoch: 5| Step: 5
Training loss: 2.8365239149215498
Validation loss: 2.448268517442773

Epoch: 5| Step: 6
Training loss: 2.742987708903835
Validation loss: 2.448677911825122

Epoch: 5| Step: 7
Training loss: 2.6392600239112323
Validation loss: 2.44728855163925

Epoch: 5| Step: 8
Training loss: 2.410738536167787
Validation loss: 2.4484926594467127

Epoch: 5| Step: 9
Training loss: 2.1648960092074567
Validation loss: 2.4429760618784586

Epoch: 5| Step: 10
Training loss: 2.6016627570185427
Validation loss: 2.4444148616975494

Epoch: 5| Step: 11
Training loss: 2.9145641559863376
Validation loss: 2.4427871033928366

Epoch: 146| Step: 0
Training loss: 1.7135924898937578
Validation loss: 2.44573102056865

Epoch: 5| Step: 1
Training loss: 1.9317974339355273
Validation loss: 2.437912820434753

Epoch: 5| Step: 2
Training loss: 2.7967879638768602
Validation loss: 2.4385621251015706

Epoch: 5| Step: 3
Training loss: 2.417401717199046
Validation loss: 2.4419380483631667

Epoch: 5| Step: 4
Training loss: 2.49423755287138
Validation loss: 2.441714213974835

Epoch: 5| Step: 5
Training loss: 2.1481141003045545
Validation loss: 2.445502329680241

Epoch: 5| Step: 6
Training loss: 3.096740356351459
Validation loss: 2.4448232760591684

Epoch: 5| Step: 7
Training loss: 2.9619271026233718
Validation loss: 2.444873876101004

Epoch: 5| Step: 8
Training loss: 2.277444775076166
Validation loss: 2.4488011541081587

Epoch: 5| Step: 9
Training loss: 2.817782040875911
Validation loss: 2.4392741870434884

Epoch: 5| Step: 10
Training loss: 2.732943001843336
Validation loss: 2.4409990057478956

Epoch: 5| Step: 11
Training loss: 2.0203873315864485
Validation loss: 2.446094521955224

Epoch: 147| Step: 0
Training loss: 1.8836173082584868
Validation loss: 2.4425449370913404

Epoch: 5| Step: 1
Training loss: 2.2696833600596453
Validation loss: 2.439737436236212

Epoch: 5| Step: 2
Training loss: 2.7312462917974862
Validation loss: 2.4419848659226324

Epoch: 5| Step: 3
Training loss: 2.520962945637799
Validation loss: 2.4469315406629506

Epoch: 5| Step: 4
Training loss: 2.533487720135263
Validation loss: 2.4391017769732866

Epoch: 5| Step: 5
Training loss: 2.9822571914462066
Validation loss: 2.442017896201062

Epoch: 5| Step: 6
Training loss: 1.957245653175656
Validation loss: 2.443499631487363

Epoch: 5| Step: 7
Training loss: 2.952417359515844
Validation loss: 2.4479848175842838

Epoch: 5| Step: 8
Training loss: 2.783330417867569
Validation loss: 2.4510455824700066

Epoch: 5| Step: 9
Training loss: 2.3229907470203552
Validation loss: 2.451755534235601

Epoch: 5| Step: 10
Training loss: 2.561780409843048
Validation loss: 2.4448022889040737

Epoch: 5| Step: 11
Training loss: 1.729372180844054
Validation loss: 2.446388560370005

Epoch: 148| Step: 0
Training loss: 2.4272693240785106
Validation loss: 2.44681410748231

Epoch: 5| Step: 1
Training loss: 2.1907627296413112
Validation loss: 2.449316429449573

Epoch: 5| Step: 2
Training loss: 2.4680274195639487
Validation loss: 2.4453193656329377

Epoch: 5| Step: 3
Training loss: 2.636684027549151
Validation loss: 2.4487856918604094

Epoch: 5| Step: 4
Training loss: 2.541218004076861
Validation loss: 2.4488357455391156

Epoch: 5| Step: 5
Training loss: 2.317557809349427
Validation loss: 2.4512894641488323

Epoch: 5| Step: 6
Training loss: 2.467918449099368
Validation loss: 2.4477782690546808

Epoch: 5| Step: 7
Training loss: 3.192087798725234
Validation loss: 2.4496359786633577

Epoch: 5| Step: 8
Training loss: 2.2660612541330187
Validation loss: 2.453242167531702

Epoch: 5| Step: 9
Training loss: 2.286252533174491
Validation loss: 2.448970694911646

Epoch: 5| Step: 10
Training loss: 2.6341348377956972
Validation loss: 2.4455033655397598

Epoch: 5| Step: 11
Training loss: 3.0557102530265627
Validation loss: 2.4447194193721726

Epoch: 149| Step: 0
Training loss: 2.37856045920495
Validation loss: 2.4461516706573576

Epoch: 5| Step: 1
Training loss: 2.7430535060268637
Validation loss: 2.4511084255806095

Epoch: 5| Step: 2
Training loss: 2.5847175232780044
Validation loss: 2.4470276834880758

Epoch: 5| Step: 3
Training loss: 2.762428375972697
Validation loss: 2.450467502663648

Epoch: 5| Step: 4
Training loss: 2.746909919664365
Validation loss: 2.4504567353111493

Epoch: 5| Step: 5
Training loss: 1.8563113578134507
Validation loss: 2.449049433240567

Epoch: 5| Step: 6
Training loss: 2.135202263714193
Validation loss: 2.4478330895515605

Epoch: 5| Step: 7
Training loss: 2.8497156302478337
Validation loss: 2.4483489906073532

Epoch: 5| Step: 8
Training loss: 2.2270129367228226
Validation loss: 2.4472927285835047

Epoch: 5| Step: 9
Training loss: 2.468321944199104
Validation loss: 2.4479244773144937

Epoch: 5| Step: 10
Training loss: 2.287209447533121
Validation loss: 2.4461308126729295

Epoch: 5| Step: 11
Training loss: 3.846908760077605
Validation loss: 2.447322624579894

Epoch: 150| Step: 0
Training loss: 2.1809956443284872
Validation loss: 2.44548244921685

Epoch: 5| Step: 1
Training loss: 2.366453453542753
Validation loss: 2.4489555156588247

Epoch: 5| Step: 2
Training loss: 2.952908301097815
Validation loss: 2.444279254373453

Epoch: 5| Step: 3
Training loss: 2.2315722406460803
Validation loss: 2.4512128565631217

Epoch: 5| Step: 4
Training loss: 3.088656461403933
Validation loss: 2.4488446985834886

Epoch: 5| Step: 5
Training loss: 2.2225759052578087
Validation loss: 2.451262814074762

Epoch: 5| Step: 6
Training loss: 2.2500136692903463
Validation loss: 2.44967414925638

Epoch: 5| Step: 7
Training loss: 3.127669300647277
Validation loss: 2.4486087321291934

Epoch: 5| Step: 8
Training loss: 1.8302536008038928
Validation loss: 2.4464243249306072

Epoch: 5| Step: 9
Training loss: 2.5845429039580483
Validation loss: 2.446480093455894

Epoch: 5| Step: 10
Training loss: 2.532746990846325
Validation loss: 2.445660063689401

Epoch: 5| Step: 11
Training loss: 1.6865669779411498
Validation loss: 2.4447066071358656

Epoch: 151| Step: 0
Training loss: 2.685839916540354
Validation loss: 2.4459262967246054

Epoch: 5| Step: 1
Training loss: 2.4042089153348214
Validation loss: 2.4452566032805425

Epoch: 5| Step: 2
Training loss: 2.093187398905907
Validation loss: 2.4458996328913334

Epoch: 5| Step: 3
Training loss: 2.7747447197143233
Validation loss: 2.4515515564057724

Epoch: 5| Step: 4
Training loss: 2.799590598557448
Validation loss: 2.4441068234310555

Epoch: 5| Step: 5
Training loss: 2.7670642103734844
Validation loss: 2.444035514549573

Epoch: 5| Step: 6
Training loss: 1.8652392961527031
Validation loss: 2.445896737015019

Epoch: 5| Step: 7
Training loss: 2.5860564328413895
Validation loss: 2.447929172619197

Epoch: 5| Step: 8
Training loss: 2.6467144517724597
Validation loss: 2.4517133785878835

Epoch: 5| Step: 9
Training loss: 2.264666018925663
Validation loss: 2.4420594422424062

Epoch: 5| Step: 10
Training loss: 2.614580091091947
Validation loss: 2.4461465901950583

Epoch: 5| Step: 11
Training loss: 1.7688744275435384
Validation loss: 2.449295375341228

Epoch: 152| Step: 0
Training loss: 2.8395594647403297
Validation loss: 2.448468764250962

Epoch: 5| Step: 1
Training loss: 2.0967871430094185
Validation loss: 2.451939768276488

Epoch: 5| Step: 2
Training loss: 3.0156895131538484
Validation loss: 2.4506401873449306

Epoch: 5| Step: 3
Training loss: 2.901623396473246
Validation loss: 2.4508830676717515

Epoch: 5| Step: 4
Training loss: 2.3334583407930283
Validation loss: 2.441743035038961

Epoch: 5| Step: 5
Training loss: 2.49874216861843
Validation loss: 2.4482667807870624

Epoch: 5| Step: 6
Training loss: 2.514072009934575
Validation loss: 2.4433292699108273

Epoch: 5| Step: 7
Training loss: 2.4908281882385976
Validation loss: 2.4516197069056784

Epoch: 5| Step: 8
Training loss: 1.9205483300310955
Validation loss: 2.452751402540904

Epoch: 5| Step: 9
Training loss: 2.317162221512172
Validation loss: 2.4515400238984246

Epoch: 5| Step: 10
Training loss: 2.5812253863105568
Validation loss: 2.453715899141929

Epoch: 5| Step: 11
Training loss: 1.3385524922488528
Validation loss: 2.4533475098662483

Epoch: 153| Step: 0
Training loss: 2.426203643340253
Validation loss: 2.450119104539459

Epoch: 5| Step: 1
Training loss: 3.038497440790904
Validation loss: 2.4514526530597913

Epoch: 5| Step: 2
Training loss: 2.989257972016902
Validation loss: 2.4464282982872154

Epoch: 5| Step: 3
Training loss: 2.087820396277083
Validation loss: 2.4479626238682104

Epoch: 5| Step: 4
Training loss: 2.2415880205995613
Validation loss: 2.4479727772443622

Epoch: 5| Step: 5
Training loss: 2.6090816858326167
Validation loss: 2.4529699855673113

Epoch: 5| Step: 6
Training loss: 2.0600769374886956
Validation loss: 2.46480014558925

Epoch: 5| Step: 7
Training loss: 2.3699439590202305
Validation loss: 2.463288975042233

Epoch: 5| Step: 8
Training loss: 2.7269082273757923
Validation loss: 2.464875794860855

Epoch: 5| Step: 9
Training loss: 2.545194949344682
Validation loss: 2.4591174989781535

Epoch: 5| Step: 10
Training loss: 2.1756464644208564
Validation loss: 2.455047186406444

Epoch: 5| Step: 11
Training loss: 3.3486528904964565
Validation loss: 2.4583943946711995

Epoch: 154| Step: 0
Training loss: 2.0437143398521918
Validation loss: 2.449073294376924

Epoch: 5| Step: 1
Training loss: 2.6439443638556046
Validation loss: 2.460703692354755

Epoch: 5| Step: 2
Training loss: 2.871192567123864
Validation loss: 2.4711360426467626

Epoch: 5| Step: 3
Training loss: 3.0800233205928014
Validation loss: 2.471188005355729

Epoch: 5| Step: 4
Training loss: 2.070075485769702
Validation loss: 2.4602793827781206

Epoch: 5| Step: 5
Training loss: 2.1679722691412877
Validation loss: 2.47059444143213

Epoch: 5| Step: 6
Training loss: 2.875948376347449
Validation loss: 2.4660590309944763

Epoch: 5| Step: 7
Training loss: 2.6409336789985653
Validation loss: 2.4732304810742467

Epoch: 5| Step: 8
Training loss: 2.364871664295216
Validation loss: 2.4698977196774314

Epoch: 5| Step: 9
Training loss: 2.5929877758333797
Validation loss: 2.472742405616309

Epoch: 5| Step: 10
Training loss: 2.346090546820782
Validation loss: 2.470444214615205

Epoch: 5| Step: 11
Training loss: 2.4071249423910777
Validation loss: 2.4721891133690477

Epoch: 155| Step: 0
Training loss: 2.88402484326502
Validation loss: 2.4738753107428697

Epoch: 5| Step: 1
Training loss: 2.5155237781702717
Validation loss: 2.4769721670100115

Epoch: 5| Step: 2
Training loss: 2.555051818441629
Validation loss: 2.466104723954624

Epoch: 5| Step: 3
Training loss: 2.9409625160710666
Validation loss: 2.46817282677933

Epoch: 5| Step: 4
Training loss: 2.3734642886168733
Validation loss: 2.466787713266144

Epoch: 5| Step: 5
Training loss: 2.474210856081503
Validation loss: 2.4680887052859206

Epoch: 5| Step: 6
Training loss: 2.5189985318302663
Validation loss: 2.468425117716287

Epoch: 5| Step: 7
Training loss: 1.915724737113044
Validation loss: 2.4649015924646296

Epoch: 5| Step: 8
Training loss: 2.872687031340048
Validation loss: 2.4637423803868717

Epoch: 5| Step: 9
Training loss: 2.499749171071755
Validation loss: 2.46325874048126

Epoch: 5| Step: 10
Training loss: 2.4414193359024297
Validation loss: 2.4632876724270747

Epoch: 5| Step: 11
Training loss: 2.0692006706468256
Validation loss: 2.4578249811177715

Epoch: 156| Step: 0
Training loss: 2.78554315006412
Validation loss: 2.452885294094198

Epoch: 5| Step: 1
Training loss: 2.3705666975942523
Validation loss: 2.451563360353071

Epoch: 5| Step: 2
Training loss: 2.2830055484177967
Validation loss: 2.458700416658431

Epoch: 5| Step: 3
Training loss: 2.67563868233333
Validation loss: 2.450063424927563

Epoch: 5| Step: 4
Training loss: 2.7894695423061378
Validation loss: 2.4451703526920645

Epoch: 5| Step: 5
Training loss: 2.4497974934868063
Validation loss: 2.4518677107571105

Epoch: 5| Step: 6
Training loss: 2.8466135216903115
Validation loss: 2.4525469202108807

Epoch: 5| Step: 7
Training loss: 2.5885687864380933
Validation loss: 2.4536984617715767

Epoch: 5| Step: 8
Training loss: 2.1370451013699516
Validation loss: 2.4599447094608045

Epoch: 5| Step: 9
Training loss: 2.5223327675044893
Validation loss: 2.4484557890558905

Epoch: 5| Step: 10
Training loss: 2.2880364419595915
Validation loss: 2.4560928493439618

Epoch: 5| Step: 11
Training loss: 2.435724932563822
Validation loss: 2.4524950081077423

Epoch: 157| Step: 0
Training loss: 2.750150763107018
Validation loss: 2.4602135860044516

Epoch: 5| Step: 1
Training loss: 2.3508628235213234
Validation loss: 2.452624936170133

Epoch: 5| Step: 2
Training loss: 2.021967762819332
Validation loss: 2.4557613918149346

Epoch: 5| Step: 3
Training loss: 2.6218290704607603
Validation loss: 2.459954306570952

Epoch: 5| Step: 4
Training loss: 2.725543599635343
Validation loss: 2.4530409456338096

Epoch: 5| Step: 5
Training loss: 2.3939247047674552
Validation loss: 2.447385735797746

Epoch: 5| Step: 6
Training loss: 2.753866079050987
Validation loss: 2.4496564600738333

Epoch: 5| Step: 7
Training loss: 2.961907622911727
Validation loss: 2.4516397017088036

Epoch: 5| Step: 8
Training loss: 2.136444799515816
Validation loss: 2.4504140140765793

Epoch: 5| Step: 9
Training loss: 2.2056259137111467
Validation loss: 2.4490767320650426

Epoch: 5| Step: 10
Training loss: 2.6900022523721674
Validation loss: 2.452924817415535

Epoch: 5| Step: 11
Training loss: 2.24143474849269
Validation loss: 2.4541602653286083

Epoch: 158| Step: 0
Training loss: 2.935929060959881
Validation loss: 2.4538903996246044

Epoch: 5| Step: 1
Training loss: 2.481933641780813
Validation loss: 2.4600908225695104

Epoch: 5| Step: 2
Training loss: 2.87132492691745
Validation loss: 2.460774823014328

Epoch: 5| Step: 3
Training loss: 2.4631862478087285
Validation loss: 2.455854772036869

Epoch: 5| Step: 4
Training loss: 2.106356799760076
Validation loss: 2.455719513265677

Epoch: 5| Step: 5
Training loss: 2.3614230330130868
Validation loss: 2.4562151533507124

Epoch: 5| Step: 6
Training loss: 2.604869859486896
Validation loss: 2.456205216048853

Epoch: 5| Step: 7
Training loss: 2.204365698824783
Validation loss: 2.457651724046334

Epoch: 5| Step: 8
Training loss: 1.9131058151045872
Validation loss: 2.461078395544137

Epoch: 5| Step: 9
Training loss: 2.8211890044778665
Validation loss: 2.4543446224266807

Epoch: 5| Step: 10
Training loss: 2.699991515817381
Validation loss: 2.4543353575440343

Epoch: 5| Step: 11
Training loss: 2.2452465283942877
Validation loss: 2.4637333907566363

Epoch: 159| Step: 0
Training loss: 2.8384816761268703
Validation loss: 2.455544426698864

Epoch: 5| Step: 1
Training loss: 2.1282554821731114
Validation loss: 2.454618620882453

Epoch: 5| Step: 2
Training loss: 2.3978123549092554
Validation loss: 2.457956557307178

Epoch: 5| Step: 3
Training loss: 2.4754128660840524
Validation loss: 2.46325461884103

Epoch: 5| Step: 4
Training loss: 2.5863460897937474
Validation loss: 2.4567453797276473

Epoch: 5| Step: 5
Training loss: 2.330501086336483
Validation loss: 2.4566437052240735

Epoch: 5| Step: 6
Training loss: 2.4268440707129675
Validation loss: 2.4555450841059256

Epoch: 5| Step: 7
Training loss: 2.3677985784336104
Validation loss: 2.461061355461257

Epoch: 5| Step: 8
Training loss: 2.5191097409648364
Validation loss: 2.459924792258534

Epoch: 5| Step: 9
Training loss: 2.5720574389580255
Validation loss: 2.4596886872230663

Epoch: 5| Step: 10
Training loss: 2.4430663301298856
Validation loss: 2.4553751031210482

Epoch: 5| Step: 11
Training loss: 4.032427002351918
Validation loss: 2.454323736927497

Epoch: 160| Step: 0
Training loss: 2.6142749579191222
Validation loss: 2.454886358920532

Epoch: 5| Step: 1
Training loss: 2.6876236643173343
Validation loss: 2.4583367446024442

Epoch: 5| Step: 2
Training loss: 2.53270594792213
Validation loss: 2.4523583001690206

Epoch: 5| Step: 3
Training loss: 2.8388566055336835
Validation loss: 2.459370322992514

Epoch: 5| Step: 4
Training loss: 2.45057127384132
Validation loss: 2.456088691410308

Epoch: 5| Step: 5
Training loss: 2.516814335749613
Validation loss: 2.452698210828181

Epoch: 5| Step: 6
Training loss: 2.2265531840882415
Validation loss: 2.4542690856969682

Epoch: 5| Step: 7
Training loss: 2.365789321574241
Validation loss: 2.454105031600142

Epoch: 5| Step: 8
Training loss: 2.7465451820444753
Validation loss: 2.4488698294053766

Epoch: 5| Step: 9
Training loss: 2.407439297141547
Validation loss: 2.456353668762427

Epoch: 5| Step: 10
Training loss: 2.181533196108617
Validation loss: 2.4606628385797573

Epoch: 5| Step: 11
Training loss: 1.9551121482975482
Validation loss: 2.453419625150728

Epoch: 161| Step: 0
Training loss: 2.163677305237815
Validation loss: 2.4534685214280154

Epoch: 5| Step: 1
Training loss: 3.0180673147168386
Validation loss: 2.4539512975865923

Epoch: 5| Step: 2
Training loss: 2.124076867144083
Validation loss: 2.451088250140814

Epoch: 5| Step: 3
Training loss: 2.2537331870028985
Validation loss: 2.4490068050916673

Epoch: 5| Step: 4
Training loss: 2.062421739422831
Validation loss: 2.4481251864530202

Epoch: 5| Step: 5
Training loss: 2.846232912785467
Validation loss: 2.4535983250606566

Epoch: 5| Step: 6
Training loss: 2.08971540110396
Validation loss: 2.4529310785575102

Epoch: 5| Step: 7
Training loss: 2.704999857847876
Validation loss: 2.454448213494748

Epoch: 5| Step: 8
Training loss: 2.589916383579185
Validation loss: 2.450909932643103

Epoch: 5| Step: 9
Training loss: 2.7784250035196387
Validation loss: 2.4613250951965764

Epoch: 5| Step: 10
Training loss: 2.822307948022841
Validation loss: 2.4490661249056465

Epoch: 5| Step: 11
Training loss: 1.4157677584785104
Validation loss: 2.447292066930031

Epoch: 162| Step: 0
Training loss: 2.462352914822778
Validation loss: 2.4524380153246277

Epoch: 5| Step: 1
Training loss: 2.450131478966219
Validation loss: 2.455657676122726

Epoch: 5| Step: 2
Training loss: 2.5136558455139157
Validation loss: 2.4559762667908163

Epoch: 5| Step: 3
Training loss: 2.7267858200651367
Validation loss: 2.4553231476416166

Epoch: 5| Step: 4
Training loss: 2.561808888349407
Validation loss: 2.4547024816051426

Epoch: 5| Step: 5
Training loss: 1.8929665937423232
Validation loss: 2.4581746896105092

Epoch: 5| Step: 6
Training loss: 2.7841815714326317
Validation loss: 2.45416102835089

Epoch: 5| Step: 7
Training loss: 2.9177695414451197
Validation loss: 2.4555148411761034

Epoch: 5| Step: 8
Training loss: 2.260216301213555
Validation loss: 2.4615804367248124

Epoch: 5| Step: 9
Training loss: 2.5308014272069306
Validation loss: 2.4551033639837065

Epoch: 5| Step: 10
Training loss: 2.2309545198436016
Validation loss: 2.4517359394860447

Epoch: 5| Step: 11
Training loss: 2.2329977632708693
Validation loss: 2.4529362381152766

Epoch: 163| Step: 0
Training loss: 2.509408793334683
Validation loss: 2.450870263336913

Epoch: 5| Step: 1
Training loss: 1.8603540615755851
Validation loss: 2.456245231947344

Epoch: 5| Step: 2
Training loss: 3.043247978904841
Validation loss: 2.4626109332223822

Epoch: 5| Step: 3
Training loss: 2.381270513170852
Validation loss: 2.464722607714316

Epoch: 5| Step: 4
Training loss: 1.9282484364374035
Validation loss: 2.4636623334198364

Epoch: 5| Step: 5
Training loss: 2.382417139491779
Validation loss: 2.4704664958878997

Epoch: 5| Step: 6
Training loss: 2.345561637073421
Validation loss: 2.464891823180419

Epoch: 5| Step: 7
Training loss: 2.353720653673104
Validation loss: 2.4642500265586573

Epoch: 5| Step: 8
Training loss: 2.2080798333496814
Validation loss: 2.4644264879619726

Epoch: 5| Step: 9
Training loss: 3.1200299222440546
Validation loss: 2.465624738434559

Epoch: 5| Step: 10
Training loss: 2.5489704896184655
Validation loss: 2.4601502869994993

Epoch: 5| Step: 11
Training loss: 3.705652332201892
Validation loss: 2.4621423547121526

Epoch: 164| Step: 0
Training loss: 2.8729237232485816
Validation loss: 2.4723283491024826

Epoch: 5| Step: 1
Training loss: 2.6481362680713585
Validation loss: 2.472451093538444

Epoch: 5| Step: 2
Training loss: 2.475782783100957
Validation loss: 2.4665147222833124

Epoch: 5| Step: 3
Training loss: 2.4942743538872616
Validation loss: 2.455052511465496

Epoch: 5| Step: 4
Training loss: 2.7135102214687494
Validation loss: 2.466333280782299

Epoch: 5| Step: 5
Training loss: 2.8766085229908254
Validation loss: 2.4518473430327763

Epoch: 5| Step: 6
Training loss: 2.2716387682307366
Validation loss: 2.4567298926723664

Epoch: 5| Step: 7
Training loss: 2.6860494913184327
Validation loss: 2.4585414747174457

Epoch: 5| Step: 8
Training loss: 1.9526220055436236
Validation loss: 2.462916758008153

Epoch: 5| Step: 9
Training loss: 2.1460966917725335
Validation loss: 2.462084080253828

Epoch: 5| Step: 10
Training loss: 2.206651070857567
Validation loss: 2.4615909092463046

Epoch: 5| Step: 11
Training loss: 1.6345991371175845
Validation loss: 2.466583697807381

Epoch: 165| Step: 0
Training loss: 2.387462144321888
Validation loss: 2.4621393811060135

Epoch: 5| Step: 1
Training loss: 2.4569533294791186
Validation loss: 2.4622106901773635

Epoch: 5| Step: 2
Training loss: 2.294101623692085
Validation loss: 2.460312373373173

Epoch: 5| Step: 3
Training loss: 2.8893469382146058
Validation loss: 2.4588196618238687

Epoch: 5| Step: 4
Training loss: 2.7869442715091304
Validation loss: 2.461315808156664

Epoch: 5| Step: 5
Training loss: 2.6205151710995476
Validation loss: 2.4661460656256935

Epoch: 5| Step: 6
Training loss: 2.093124979588123
Validation loss: 2.458908229352863

Epoch: 5| Step: 7
Training loss: 2.3856829254497485
Validation loss: 2.4541612975337608

Epoch: 5| Step: 8
Training loss: 2.8023537619938064
Validation loss: 2.45609966866349

Epoch: 5| Step: 9
Training loss: 2.336016395282692
Validation loss: 2.4595824128729262

Epoch: 5| Step: 10
Training loss: 2.294455778798497
Validation loss: 2.464599411869781

Epoch: 5| Step: 11
Training loss: 2.4238627490476237
Validation loss: 2.4722649785486634

Epoch: 166| Step: 0
Training loss: 2.3450663621048724
Validation loss: 2.4724311947160493

Epoch: 5| Step: 1
Training loss: 2.7427992613821606
Validation loss: 2.463543314593828

Epoch: 5| Step: 2
Training loss: 2.641117388622823
Validation loss: 2.4605590731188274

Epoch: 5| Step: 3
Training loss: 2.3304885029635027
Validation loss: 2.45980131371677

Epoch: 5| Step: 4
Training loss: 2.5072442002050117
Validation loss: 2.462229289748316

Epoch: 5| Step: 5
Training loss: 2.4193671254902247
Validation loss: 2.4617404455360643

Epoch: 5| Step: 6
Training loss: 2.200063756539095
Validation loss: 2.4564118688696364

Epoch: 5| Step: 7
Training loss: 2.576239248787307
Validation loss: 2.457015429164327

Epoch: 5| Step: 8
Training loss: 2.4495409399202157
Validation loss: 2.4623289221511553

Epoch: 5| Step: 9
Training loss: 2.8173966908237036
Validation loss: 2.459466516778536

Epoch: 5| Step: 10
Training loss: 2.537809749545883
Validation loss: 2.45994669430698

Epoch: 5| Step: 11
Training loss: 2.7681767819682377
Validation loss: 2.461303913752324

Epoch: 167| Step: 0
Training loss: 2.3996242109781174
Validation loss: 2.4613975216046

Epoch: 5| Step: 1
Training loss: 2.599382650002268
Validation loss: 2.465711333129625

Epoch: 5| Step: 2
Training loss: 2.3782925119441014
Validation loss: 2.4538944114958965

Epoch: 5| Step: 3
Training loss: 2.659814664220827
Validation loss: 2.4562845232529678

Epoch: 5| Step: 4
Training loss: 2.135492450640925
Validation loss: 2.455099574612165

Epoch: 5| Step: 5
Training loss: 3.0480374197377533
Validation loss: 2.4551921768422957

Epoch: 5| Step: 6
Training loss: 2.453319663324142
Validation loss: 2.45826347435006

Epoch: 5| Step: 7
Training loss: 2.3990880226883484
Validation loss: 2.4554151062502183

Epoch: 5| Step: 8
Training loss: 2.0455106891286587
Validation loss: 2.466549399580481

Epoch: 5| Step: 9
Training loss: 2.533653907402816
Validation loss: 2.464869130805438

Epoch: 5| Step: 10
Training loss: 2.7176393893235415
Validation loss: 2.456557652244998

Epoch: 5| Step: 11
Training loss: 2.126847081478968
Validation loss: 2.4654047046068386

Epoch: 168| Step: 0
Training loss: 2.4346446405809257
Validation loss: 2.461075567984362

Epoch: 5| Step: 1
Training loss: 2.2734494553084494
Validation loss: 2.472065333205435

Epoch: 5| Step: 2
Training loss: 2.525133726148067
Validation loss: 2.473527912375928

Epoch: 5| Step: 3
Training loss: 2.561096365227201
Validation loss: 2.4806021186437777

Epoch: 5| Step: 4
Training loss: 2.7651102912525074
Validation loss: 2.474241559062311

Epoch: 5| Step: 5
Training loss: 2.5479309139856694
Validation loss: 2.469942380365644

Epoch: 5| Step: 6
Training loss: 2.5796265824240017
Validation loss: 2.4700336619836265

Epoch: 5| Step: 7
Training loss: 2.4119902670175217
Validation loss: 2.46434779348955

Epoch: 5| Step: 8
Training loss: 2.5356455185313647
Validation loss: 2.4673227457927203

Epoch: 5| Step: 9
Training loss: 2.0693920464535105
Validation loss: 2.459807278694043

Epoch: 5| Step: 10
Training loss: 2.6062093022597126
Validation loss: 2.4552420048326016

Epoch: 5| Step: 11
Training loss: 3.0919828666222187
Validation loss: 2.4620818046048187

Epoch: 169| Step: 0
Training loss: 1.7603421468217346
Validation loss: 2.4628139426434448

Epoch: 5| Step: 1
Training loss: 2.190242682819316
Validation loss: 2.4618718911472772

Epoch: 5| Step: 2
Training loss: 2.452011730495851
Validation loss: 2.463832357540693

Epoch: 5| Step: 3
Training loss: 2.9434735858834298
Validation loss: 2.4626055518957357

Epoch: 5| Step: 4
Training loss: 2.6644101629189656
Validation loss: 2.4645320334514182

Epoch: 5| Step: 5
Training loss: 2.7348307202550814
Validation loss: 2.4641666076702293

Epoch: 5| Step: 6
Training loss: 2.523408304996313
Validation loss: 2.4612777232579544

Epoch: 5| Step: 7
Training loss: 2.9674191352862325
Validation loss: 2.462230362951376

Epoch: 5| Step: 8
Training loss: 2.710110848894092
Validation loss: 2.4629670569156246

Epoch: 5| Step: 9
Training loss: 2.2699213792402873
Validation loss: 2.45960659389191

Epoch: 5| Step: 10
Training loss: 2.3908109904225068
Validation loss: 2.4556366521103037

Epoch: 5| Step: 11
Training loss: 1.1255435690053808
Validation loss: 2.455269522073721

Epoch: 170| Step: 0
Training loss: 2.156467924300943
Validation loss: 2.4596513283522676

Epoch: 5| Step: 1
Training loss: 2.802599456410732
Validation loss: 2.4608962928511016

Epoch: 5| Step: 2
Training loss: 2.1576089308591
Validation loss: 2.4624220835756656

Epoch: 5| Step: 3
Training loss: 2.357651946590808
Validation loss: 2.468879052503196

Epoch: 5| Step: 4
Training loss: 2.64575969163031
Validation loss: 2.4631714465390484

Epoch: 5| Step: 5
Training loss: 2.4816023991932883
Validation loss: 2.4759439423956464

Epoch: 5| Step: 6
Training loss: 2.8437283693266457
Validation loss: 2.46651602722179

Epoch: 5| Step: 7
Training loss: 2.582689810144847
Validation loss: 2.4729468248730293

Epoch: 5| Step: 8
Training loss: 2.671915422100345
Validation loss: 2.4682848608867096

Epoch: 5| Step: 9
Training loss: 1.95359759907243
Validation loss: 2.473851923745519

Epoch: 5| Step: 10
Training loss: 2.65226078044129
Validation loss: 2.467574213799932

Epoch: 5| Step: 11
Training loss: 2.779087726285924
Validation loss: 2.467199273108525

Epoch: 171| Step: 0
Training loss: 2.3689789996007384
Validation loss: 2.4666356758692514

Epoch: 5| Step: 1
Training loss: 2.513013348872976
Validation loss: 2.4625338508486787

Epoch: 5| Step: 2
Training loss: 2.5457042039087785
Validation loss: 2.459901492723272

Epoch: 5| Step: 3
Training loss: 2.7002188876400766
Validation loss: 2.4659132171351827

Epoch: 5| Step: 4
Training loss: 2.380631846695737
Validation loss: 2.462680695773475

Epoch: 5| Step: 5
Training loss: 2.402116172369751
Validation loss: 2.468920613280435

Epoch: 5| Step: 6
Training loss: 2.5188207763117907
Validation loss: 2.458052741756441

Epoch: 5| Step: 7
Training loss: 2.6465430221534527
Validation loss: 2.453657991372027

Epoch: 5| Step: 8
Training loss: 2.797347556316533
Validation loss: 2.459312750332697

Epoch: 5| Step: 9
Training loss: 2.2617459468491106
Validation loss: 2.463369046239713

Epoch: 5| Step: 10
Training loss: 2.149227149805525
Validation loss: 2.4613935703943928

Epoch: 5| Step: 11
Training loss: 2.3924619311709123
Validation loss: 2.4565652467034305

Epoch: 172| Step: 0
Training loss: 2.023485809102973
Validation loss: 2.4634177208354453

Epoch: 5| Step: 1
Training loss: 2.5865162550398653
Validation loss: 2.464102051586218

Epoch: 5| Step: 2
Training loss: 2.398275761323091
Validation loss: 2.464294598117819

Epoch: 5| Step: 3
Training loss: 2.5984368320264664
Validation loss: 2.4595016286937255

Epoch: 5| Step: 4
Training loss: 2.6185699000371585
Validation loss: 2.463296197889638

Epoch: 5| Step: 5
Training loss: 2.3938718202036093
Validation loss: 2.4616863786527587

Epoch: 5| Step: 6
Training loss: 2.2487397373170968
Validation loss: 2.4658727900897914

Epoch: 5| Step: 7
Training loss: 3.0771507619100236
Validation loss: 2.4580628413296224

Epoch: 5| Step: 8
Training loss: 2.2319044846910856
Validation loss: 2.4554507170842466

Epoch: 5| Step: 9
Training loss: 2.433982756798882
Validation loss: 2.463243213718422

Epoch: 5| Step: 10
Training loss: 2.68330561661079
Validation loss: 2.4705309399501827

Epoch: 5| Step: 11
Training loss: 2.095810858098503
Validation loss: 2.4623060508295187

Epoch: 173| Step: 0
Training loss: 2.560838858733675
Validation loss: 2.463570170543422

Epoch: 5| Step: 1
Training loss: 2.341297341360473
Validation loss: 2.462967258585132

Epoch: 5| Step: 2
Training loss: 2.584029124500316
Validation loss: 2.463431919763737

Epoch: 5| Step: 3
Training loss: 2.2931017341587583
Validation loss: 2.4638045145884373

Epoch: 5| Step: 4
Training loss: 2.924610346736265
Validation loss: 2.4648011169132054

Epoch: 5| Step: 5
Training loss: 2.050404541293982
Validation loss: 2.4626211149506703

Epoch: 5| Step: 6
Training loss: 2.1685972660161803
Validation loss: 2.462061230866978

Epoch: 5| Step: 7
Training loss: 2.303114739114376
Validation loss: 2.4683664965628718

Epoch: 5| Step: 8
Training loss: 2.5867157194395753
Validation loss: 2.468350708134262

Epoch: 5| Step: 9
Training loss: 3.025943003811687
Validation loss: 2.4781228734536844

Epoch: 5| Step: 10
Training loss: 2.1777308716339534
Validation loss: 2.47169764509828

Epoch: 5| Step: 11
Training loss: 2.926176607237363
Validation loss: 2.4713002283757617

Epoch: 174| Step: 0
Training loss: 1.8386111007705541
Validation loss: 2.4564353774233467

Epoch: 5| Step: 1
Training loss: 2.5703703807122755
Validation loss: 2.4731698449443864

Epoch: 5| Step: 2
Training loss: 2.5414807819703285
Validation loss: 2.462199594921713

Epoch: 5| Step: 3
Training loss: 2.423773335368614
Validation loss: 2.4617924451516267

Epoch: 5| Step: 4
Training loss: 2.865739253937388
Validation loss: 2.462668578030282

Epoch: 5| Step: 5
Training loss: 2.7957345352870817
Validation loss: 2.468691599835182

Epoch: 5| Step: 6
Training loss: 2.057630976126972
Validation loss: 2.46549944813808

Epoch: 5| Step: 7
Training loss: 2.584215126489435
Validation loss: 2.463943728219315

Epoch: 5| Step: 8
Training loss: 1.8712670359476273
Validation loss: 2.467853435653295

Epoch: 5| Step: 9
Training loss: 2.6678204921116984
Validation loss: 2.463789265444088

Epoch: 5| Step: 10
Training loss: 2.764650334741931
Validation loss: 2.4617202119571724

Epoch: 5| Step: 11
Training loss: 2.9825150850590814
Validation loss: 2.459461694051388

Epoch: 175| Step: 0
Training loss: 2.8311148167014846
Validation loss: 2.473234907421371

Epoch: 5| Step: 1
Training loss: 2.5529686981505613
Validation loss: 2.4722266645129674

Epoch: 5| Step: 2
Training loss: 2.414793823476427
Validation loss: 2.475132044728063

Epoch: 5| Step: 3
Training loss: 2.4822496644080463
Validation loss: 2.4709015697451053

Epoch: 5| Step: 4
Training loss: 1.8058299622315734
Validation loss: 2.4752519712081633

Epoch: 5| Step: 5
Training loss: 1.9212154093937495
Validation loss: 2.4769808138162177

Epoch: 5| Step: 6
Training loss: 2.830954469326107
Validation loss: 2.4852721235948727

Epoch: 5| Step: 7
Training loss: 2.6144485033588034
Validation loss: 2.484951610148411

Epoch: 5| Step: 8
Training loss: 2.8953409851286973
Validation loss: 2.4973524777358698

Epoch: 5| Step: 9
Training loss: 2.128537767350764
Validation loss: 2.4792301359520432

Epoch: 5| Step: 10
Training loss: 2.7606901980977594
Validation loss: 2.47108985578158

Epoch: 5| Step: 11
Training loss: 1.8172764160234698
Validation loss: 2.471108842792183

Epoch: 176| Step: 0
Training loss: 2.2794188374476576
Validation loss: 2.462873264688188

Epoch: 5| Step: 1
Training loss: 2.854298238204478
Validation loss: 2.4646761716854217

Epoch: 5| Step: 2
Training loss: 1.808014482376869
Validation loss: 2.4668107443908154

Epoch: 5| Step: 3
Training loss: 2.3090083593892095
Validation loss: 2.4747252082159656

Epoch: 5| Step: 4
Training loss: 2.3899024419944377
Validation loss: 2.475293870459368

Epoch: 5| Step: 5
Training loss: 2.4609198675583603
Validation loss: 2.48282570184231

Epoch: 5| Step: 6
Training loss: 2.511774563799583
Validation loss: 2.4855596528940596

Epoch: 5| Step: 7
Training loss: 2.395408780725353
Validation loss: 2.4791996790720874

Epoch: 5| Step: 8
Training loss: 2.815774833596107
Validation loss: 2.481982008337797

Epoch: 5| Step: 9
Training loss: 3.0958824129864917
Validation loss: 2.478710694949647

Epoch: 5| Step: 10
Training loss: 2.4948893762194655
Validation loss: 2.4741407782222837

Epoch: 5| Step: 11
Training loss: 2.887680120753918
Validation loss: 2.467385333365492

Epoch: 177| Step: 0
Training loss: 2.3912514258548456
Validation loss: 2.4610809607293884

Epoch: 5| Step: 1
Training loss: 2.6846691569937304
Validation loss: 2.460557260353614

Epoch: 5| Step: 2
Training loss: 2.0808331046246256
Validation loss: 2.4613270648033185

Epoch: 5| Step: 3
Training loss: 2.0568540341036945
Validation loss: 2.4596689456547964

Epoch: 5| Step: 4
Training loss: 2.4757484999633546
Validation loss: 2.454446102780315

Epoch: 5| Step: 5
Training loss: 2.4601789970715213
Validation loss: 2.4549413788109757

Epoch: 5| Step: 6
Training loss: 1.9701571809444427
Validation loss: 2.458132409651111

Epoch: 5| Step: 7
Training loss: 3.3311709224626473
Validation loss: 2.4606778325732974

Epoch: 5| Step: 8
Training loss: 2.437319528794515
Validation loss: 2.4588208456003087

Epoch: 5| Step: 9
Training loss: 2.6210728287750182
Validation loss: 2.4565524396345415

Epoch: 5| Step: 10
Training loss: 2.4676095766977104
Validation loss: 2.4553587031669117

Epoch: 5| Step: 11
Training loss: 2.5501510986739815
Validation loss: 2.4706683813574815

Epoch: 178| Step: 0
Training loss: 2.6036948323368745
Validation loss: 2.462011815266131

Epoch: 5| Step: 1
Training loss: 2.154872067010732
Validation loss: 2.455509970231303

Epoch: 5| Step: 2
Training loss: 2.073011028755466
Validation loss: 2.454993688344773

Epoch: 5| Step: 3
Training loss: 2.883474382541053
Validation loss: 2.4636111999011145

Epoch: 5| Step: 4
Training loss: 2.67509400389734
Validation loss: 2.4642481459609704

Epoch: 5| Step: 5
Training loss: 2.6978418838171603
Validation loss: 2.4652087489987196

Epoch: 5| Step: 6
Training loss: 2.681924403457222
Validation loss: 2.4603592571717527

Epoch: 5| Step: 7
Training loss: 2.3379055140633866
Validation loss: 2.4577624875893744

Epoch: 5| Step: 8
Training loss: 1.9016529372062625
Validation loss: 2.466513876489486

Epoch: 5| Step: 9
Training loss: 2.468151454556753
Validation loss: 2.465836592516647

Epoch: 5| Step: 10
Training loss: 2.4763169994273415
Validation loss: 2.465165481487233

Epoch: 5| Step: 11
Training loss: 2.766163574192505
Validation loss: 2.4665025951831443

Epoch: 179| Step: 0
Training loss: 2.1300109796733566
Validation loss: 2.4655701644466186

Epoch: 5| Step: 1
Training loss: 2.361675530333791
Validation loss: 2.467158037669696

Epoch: 5| Step: 2
Training loss: 2.2520945654302853
Validation loss: 2.4679900178619847

Epoch: 5| Step: 3
Training loss: 2.889718238268574
Validation loss: 2.469206140123059

Epoch: 5| Step: 4
Training loss: 2.6441980149167805
Validation loss: 2.461611503057461

Epoch: 5| Step: 5
Training loss: 2.42710685445715
Validation loss: 2.465184199806276

Epoch: 5| Step: 6
Training loss: 2.4166376397154483
Validation loss: 2.464980301497794

Epoch: 5| Step: 7
Training loss: 2.4749078367393813
Validation loss: 2.4629633663607255

Epoch: 5| Step: 8
Training loss: 2.7295118409679286
Validation loss: 2.464002970651904

Epoch: 5| Step: 9
Training loss: 1.6047461895485164
Validation loss: 2.460183761861184

Epoch: 5| Step: 10
Training loss: 2.990193711196811
Validation loss: 2.465867158048208

Epoch: 5| Step: 11
Training loss: 2.4663569767174383
Validation loss: 2.467364493832779

Epoch: 180| Step: 0
Training loss: 2.7058857837884522
Validation loss: 2.4673779252055565

Epoch: 5| Step: 1
Training loss: 1.9806371011602073
Validation loss: 2.466229272550038

Epoch: 5| Step: 2
Training loss: 2.0756116310339228
Validation loss: 2.4684631366093077

Epoch: 5| Step: 3
Training loss: 2.4686219387399566
Validation loss: 2.4732815683501106

Epoch: 5| Step: 4
Training loss: 2.838300912895522
Validation loss: 2.472638652913662

Epoch: 5| Step: 5
Training loss: 2.0390926665782176
Validation loss: 2.4614736871056198

Epoch: 5| Step: 6
Training loss: 2.9964225419534474
Validation loss: 2.469896915262819

Epoch: 5| Step: 7
Training loss: 2.6603423962324193
Validation loss: 2.4710793350736777

Epoch: 5| Step: 8
Training loss: 2.756275040216516
Validation loss: 2.4664850146082458

Epoch: 5| Step: 9
Training loss: 2.2619893335483856
Validation loss: 2.462514027202176

Epoch: 5| Step: 10
Training loss: 1.9117023475108554
Validation loss: 2.4642906958962074

Epoch: 5| Step: 11
Training loss: 3.133742653374416
Validation loss: 2.463446566229408

Epoch: 181| Step: 0
Training loss: 2.527213374788806
Validation loss: 2.467213200633999

Epoch: 5| Step: 1
Training loss: 2.229043000495747
Validation loss: 2.4647210841782514

Epoch: 5| Step: 2
Training loss: 2.0005916673957533
Validation loss: 2.4661382428663043

Epoch: 5| Step: 3
Training loss: 2.6429370937994356
Validation loss: 2.4664754509645332

Epoch: 5| Step: 4
Training loss: 2.5872834267026743
Validation loss: 2.4770733479928726

Epoch: 5| Step: 5
Training loss: 2.5763682535675527
Validation loss: 2.47533589341168

Epoch: 5| Step: 6
Training loss: 2.7150359819813383
Validation loss: 2.4679892249011255

Epoch: 5| Step: 7
Training loss: 2.591876168895832
Validation loss: 2.4684003348940697

Epoch: 5| Step: 8
Training loss: 2.301065268740154
Validation loss: 2.4649732568797713

Epoch: 5| Step: 9
Training loss: 2.762973095873669
Validation loss: 2.469637429612602

Epoch: 5| Step: 10
Training loss: 2.2801822619619934
Validation loss: 2.4708115384286207

Epoch: 5| Step: 11
Training loss: 2.5903953091499403
Validation loss: 2.464457292684749

Epoch: 182| Step: 0
Training loss: 2.341612795100363
Validation loss: 2.4659743096636926

Epoch: 5| Step: 1
Training loss: 2.2707430153713806
Validation loss: 2.4700850405963584

Epoch: 5| Step: 2
Training loss: 2.7064338674480166
Validation loss: 2.4677853168241377

Epoch: 5| Step: 3
Training loss: 2.820311147420036
Validation loss: 2.4688683161571428

Epoch: 5| Step: 4
Training loss: 2.17502250659742
Validation loss: 2.4679048475795815

Epoch: 5| Step: 5
Training loss: 2.084788488184427
Validation loss: 2.4712783887612506

Epoch: 5| Step: 6
Training loss: 2.454818141284809
Validation loss: 2.4652516772600377

Epoch: 5| Step: 7
Training loss: 2.393418817543105
Validation loss: 2.4644370491639034

Epoch: 5| Step: 8
Training loss: 2.4195742599906653
Validation loss: 2.462574441626933

Epoch: 5| Step: 9
Training loss: 2.9269332756775572
Validation loss: 2.4677237296976076

Epoch: 5| Step: 10
Training loss: 2.2960383130442406
Validation loss: 2.4614447136587057

Epoch: 5| Step: 11
Training loss: 2.880525172617064
Validation loss: 2.468451155911988

Epoch: 183| Step: 0
Training loss: 2.5210360505954887
Validation loss: 2.457745551838305

Epoch: 5| Step: 1
Training loss: 3.0034633354589646
Validation loss: 2.4584760961189644

Epoch: 5| Step: 2
Training loss: 2.698699503749101
Validation loss: 2.4669179879099423

Epoch: 5| Step: 3
Training loss: 2.6486324812421445
Validation loss: 2.459261837415459

Epoch: 5| Step: 4
Training loss: 2.5251995347753584
Validation loss: 2.4624545512709144

Epoch: 5| Step: 5
Training loss: 1.5591392996401485
Validation loss: 2.4593291784507163

Epoch: 5| Step: 6
Training loss: 2.753906423149374
Validation loss: 2.4546140719284772

Epoch: 5| Step: 7
Training loss: 2.435369196011177
Validation loss: 2.457411440983446

Epoch: 5| Step: 8
Training loss: 2.317642370992677
Validation loss: 2.460384936589733

Epoch: 5| Step: 9
Training loss: 1.9060035296084215
Validation loss: 2.4647267672048074

Epoch: 5| Step: 10
Training loss: 2.345524535737753
Validation loss: 2.455824846417644

Epoch: 5| Step: 11
Training loss: 3.1864112041604913
Validation loss: 2.4617109627269116

Epoch: 184| Step: 0
Training loss: 2.6037414407062904
Validation loss: 2.466983919963121

Epoch: 5| Step: 1
Training loss: 3.0089819282047365
Validation loss: 2.4709366840042626

Epoch: 5| Step: 2
Training loss: 2.5046154333111734
Validation loss: 2.473111358349806

Epoch: 5| Step: 3
Training loss: 2.3397700786933493
Validation loss: 2.47182087298457

Epoch: 5| Step: 4
Training loss: 2.49672006978607
Validation loss: 2.4696237611322953

Epoch: 5| Step: 5
Training loss: 2.480380896266532
Validation loss: 2.477743739543877

Epoch: 5| Step: 6
Training loss: 2.5555379309484163
Validation loss: 2.4684492201606765

Epoch: 5| Step: 7
Training loss: 2.654614472353033
Validation loss: 2.476014563016684

Epoch: 5| Step: 8
Training loss: 2.021193980123047
Validation loss: 2.4616466650885247

Epoch: 5| Step: 9
Training loss: 2.232096116802768
Validation loss: 2.4701372264987187

Epoch: 5| Step: 10
Training loss: 1.820410991836519
Validation loss: 2.4677172887040344

Epoch: 5| Step: 11
Training loss: 2.893479705776292
Validation loss: 2.4730089045620214

Epoch: 185| Step: 0
Training loss: 2.473246186135765
Validation loss: 2.469480873116224

Epoch: 5| Step: 1
Training loss: 2.5298973519531733
Validation loss: 2.471001334909027

Epoch: 5| Step: 2
Training loss: 2.284798775124422
Validation loss: 2.465271902002726

Epoch: 5| Step: 3
Training loss: 2.5599088826951273
Validation loss: 2.460581928380373

Epoch: 5| Step: 4
Training loss: 2.6296710280720186
Validation loss: 2.4687537140959153

Epoch: 5| Step: 5
Training loss: 3.1098537364063956
Validation loss: 2.463497489441695

Epoch: 5| Step: 6
Training loss: 2.0519382664352928
Validation loss: 2.4629199686503154

Epoch: 5| Step: 7
Training loss: 2.395399225684298
Validation loss: 2.4689114413208744

Epoch: 5| Step: 8
Training loss: 2.1986457254342864
Validation loss: 2.4679962005328377

Epoch: 5| Step: 9
Training loss: 2.373773057131603
Validation loss: 2.466842356967532

Epoch: 5| Step: 10
Training loss: 2.4161214103760877
Validation loss: 2.4712618752636253

Epoch: 5| Step: 11
Training loss: 2.4356148105375897
Validation loss: 2.4713098195756236

Epoch: 186| Step: 0
Training loss: 2.4190464360549258
Validation loss: 2.4800729190453135

Epoch: 5| Step: 1
Training loss: 2.362807347726319
Validation loss: 2.4934583431242388

Epoch: 5| Step: 2
Training loss: 2.452730572328932
Validation loss: 2.487143100042345

Epoch: 5| Step: 3
Training loss: 2.4694819270768473
Validation loss: 2.475436583458496

Epoch: 5| Step: 4
Training loss: 2.6920232633064494
Validation loss: 2.475742808130103

Epoch: 5| Step: 5
Training loss: 2.3080778368447277
Validation loss: 2.4748703102208545

Epoch: 5| Step: 6
Training loss: 2.485147703912186
Validation loss: 2.4689023337063447

Epoch: 5| Step: 7
Training loss: 2.312649490060998
Validation loss: 2.4684709640741356

Epoch: 5| Step: 8
Training loss: 1.8401926928670007
Validation loss: 2.462164396405252

Epoch: 5| Step: 9
Training loss: 2.3640956515794564
Validation loss: 2.462546316185696

Epoch: 5| Step: 10
Training loss: 2.7048289490663313
Validation loss: 2.4576525688479314

Epoch: 5| Step: 11
Training loss: 4.793188212872363
Validation loss: 2.4577640073551246

Epoch: 187| Step: 0
Training loss: 2.4627700037993336
Validation loss: 2.455788104313172

Epoch: 5| Step: 1
Training loss: 2.7853422597696746
Validation loss: 2.4616512857932467

Epoch: 5| Step: 2
Training loss: 2.6600907327479293
Validation loss: 2.4632875070795905

Epoch: 5| Step: 3
Training loss: 2.980831899055162
Validation loss: 2.4539752992997323

Epoch: 5| Step: 4
Training loss: 1.8154889159162326
Validation loss: 2.460379651335201

Epoch: 5| Step: 5
Training loss: 2.669328156142624
Validation loss: 2.462923631036014

Epoch: 5| Step: 6
Training loss: 2.151014634178814
Validation loss: 2.4616013696163592

Epoch: 5| Step: 7
Training loss: 1.9171136321097455
Validation loss: 2.458459031937835

Epoch: 5| Step: 8
Training loss: 2.7623420670186642
Validation loss: 2.4641059984533578

Epoch: 5| Step: 9
Training loss: 2.5226538418604467
Validation loss: 2.4524026118912357

Epoch: 5| Step: 10
Training loss: 2.4399347127716124
Validation loss: 2.4585671892843637

Epoch: 5| Step: 11
Training loss: 1.247857116696411
Validation loss: 2.4660004603483983

Epoch: 188| Step: 0
Training loss: 2.7525936380339577
Validation loss: 2.4669798045466353

Epoch: 5| Step: 1
Training loss: 2.4755470287869388
Validation loss: 2.4724258869970432

Epoch: 5| Step: 2
Training loss: 2.6730236239204594
Validation loss: 2.466677636903992

Epoch: 5| Step: 3
Training loss: 2.1005079608740043
Validation loss: 2.4778479119343215

Epoch: 5| Step: 4
Training loss: 2.781731124582136
Validation loss: 2.482840796057928

Epoch: 5| Step: 5
Training loss: 2.9859840090017493
Validation loss: 2.4906554181560017

Epoch: 5| Step: 6
Training loss: 2.00273374643422
Validation loss: 2.4778229066300903

Epoch: 5| Step: 7
Training loss: 1.8733954875902696
Validation loss: 2.4749419428698167

Epoch: 5| Step: 8
Training loss: 2.835490378029685
Validation loss: 2.479362056683328

Epoch: 5| Step: 9
Training loss: 2.0576424472672357
Validation loss: 2.4766991353976486

Epoch: 5| Step: 10
Training loss: 2.56304674596051
Validation loss: 2.467259685546694

Epoch: 5| Step: 11
Training loss: 1.2343647630484333
Validation loss: 2.4625494062886077

Epoch: 189| Step: 0
Training loss: 2.6750609382034285
Validation loss: 2.4596577016138292

Epoch: 5| Step: 1
Training loss: 2.800452730498777
Validation loss: 2.4654393431206407

Epoch: 5| Step: 2
Training loss: 2.043164099841076
Validation loss: 2.472254659735177

Epoch: 5| Step: 3
Training loss: 2.3958541426929734
Validation loss: 2.4749199306817125

Epoch: 5| Step: 4
Training loss: 2.5240132056010207
Validation loss: 2.4733403139988397

Epoch: 5| Step: 5
Training loss: 3.02010412074592
Validation loss: 2.4748276812679633

Epoch: 5| Step: 6
Training loss: 1.9983968269796355
Validation loss: 2.467608821859728

Epoch: 5| Step: 7
Training loss: 2.541321673717084
Validation loss: 2.4647660643702842

Epoch: 5| Step: 8
Training loss: 2.3578940284542402
Validation loss: 2.474388941717284

Epoch: 5| Step: 9
Training loss: 2.3578655138369435
Validation loss: 2.4760130544530434

Epoch: 5| Step: 10
Training loss: 2.190231144172867
Validation loss: 2.472492574183052

Epoch: 5| Step: 11
Training loss: 3.0784338781614125
Validation loss: 2.467447271154046

Epoch: 190| Step: 0
Training loss: 2.0816164444463707
Validation loss: 2.4782082016564395

Epoch: 5| Step: 1
Training loss: 2.5387148575108984
Validation loss: 2.4698588621302604

Epoch: 5| Step: 2
Training loss: 3.2881893349034588
Validation loss: 2.4650876407699354

Epoch: 5| Step: 3
Training loss: 3.0289538624002375
Validation loss: 2.4646373527348726

Epoch: 5| Step: 4
Training loss: 2.250942456696611
Validation loss: 2.4690952763765615

Epoch: 5| Step: 5
Training loss: 2.552639014543207
Validation loss: 2.4640276485309505

Epoch: 5| Step: 6
Training loss: 2.1191214986896094
Validation loss: 2.4659212420363543

Epoch: 5| Step: 7
Training loss: 2.1881015495431835
Validation loss: 2.4567491524080487

Epoch: 5| Step: 8
Training loss: 2.0217372275437597
Validation loss: 2.4658246474023366

Epoch: 5| Step: 9
Training loss: 2.6582427684061685
Validation loss: 2.4651693541156

Epoch: 5| Step: 10
Training loss: 1.9043409450028776
Validation loss: 2.460624089543248

Epoch: 5| Step: 11
Training loss: 2.454361330698065
Validation loss: 2.470690962167186

Epoch: 191| Step: 0
Training loss: 2.2884496708261994
Validation loss: 2.473016747766317

Epoch: 5| Step: 1
Training loss: 1.8771378726917936
Validation loss: 2.46987619747422

Epoch: 5| Step: 2
Training loss: 2.7315475231982473
Validation loss: 2.4678940113935646

Epoch: 5| Step: 3
Training loss: 2.702888169690937
Validation loss: 2.4682842652309547

Epoch: 5| Step: 4
Training loss: 2.6396631599605618
Validation loss: 2.4679707532687187

Epoch: 5| Step: 5
Training loss: 2.1936265437934632
Validation loss: 2.468148637112475

Epoch: 5| Step: 6
Training loss: 2.7571037613717877
Validation loss: 2.466365189482899

Epoch: 5| Step: 7
Training loss: 2.3364164441917663
Validation loss: 2.4668506567119324

Epoch: 5| Step: 8
Training loss: 2.067198055410504
Validation loss: 2.4712036389787606

Epoch: 5| Step: 9
Training loss: 2.482363288242076
Validation loss: 2.4690785290023527

Epoch: 5| Step: 10
Training loss: 2.5358390182580153
Validation loss: 2.466876695418277

Epoch: 5| Step: 11
Training loss: 3.5475761627989573
Validation loss: 2.4670323259268865

Epoch: 192| Step: 0
Training loss: 2.137122414238347
Validation loss: 2.4638584019376677

Epoch: 5| Step: 1
Training loss: 2.468054564826503
Validation loss: 2.470469218202514

Epoch: 5| Step: 2
Training loss: 2.4396906081236405
Validation loss: 2.466494153300734

Epoch: 5| Step: 3
Training loss: 2.004944173744382
Validation loss: 2.4682294884353

Epoch: 5| Step: 4
Training loss: 2.781146615496423
Validation loss: 2.477449645304733

Epoch: 5| Step: 5
Training loss: 2.920406360046542
Validation loss: 2.469430262363142

Epoch: 5| Step: 6
Training loss: 2.5721020251872617
Validation loss: 2.462131916814266

Epoch: 5| Step: 7
Training loss: 1.7847896007414417
Validation loss: 2.475510017590231

Epoch: 5| Step: 8
Training loss: 2.2665014216083854
Validation loss: 2.4715960551400658

Epoch: 5| Step: 9
Training loss: 2.389350701083061
Validation loss: 2.465890354886503

Epoch: 5| Step: 10
Training loss: 2.7726999940965817
Validation loss: 2.462784460584414

Epoch: 5| Step: 11
Training loss: 3.215004232116097
Validation loss: 2.4682565892157124

Epoch: 193| Step: 0
Training loss: 2.4585329933768847
Validation loss: 2.468514845710399

Epoch: 5| Step: 1
Training loss: 1.918437084813748
Validation loss: 2.4668065682787312

Epoch: 5| Step: 2
Training loss: 2.276716980310697
Validation loss: 2.4659577566183484

Epoch: 5| Step: 3
Training loss: 2.642657338694031
Validation loss: 2.46416828071181

Epoch: 5| Step: 4
Training loss: 2.863343533492951
Validation loss: 2.470182176434159

Epoch: 5| Step: 5
Training loss: 2.1209923595271065
Validation loss: 2.4626522004264215

Epoch: 5| Step: 6
Training loss: 2.4138551888444306
Validation loss: 2.469926795067714

Epoch: 5| Step: 7
Training loss: 2.4842185684953586
Validation loss: 2.4722469487245515

Epoch: 5| Step: 8
Training loss: 2.5057020963101104
Validation loss: 2.469590257347788

Epoch: 5| Step: 9
Training loss: 2.5261703196270533
Validation loss: 2.4652804246330082

Epoch: 5| Step: 10
Training loss: 2.704803122302975
Validation loss: 2.467622966478691

Epoch: 5| Step: 11
Training loss: 2.080021731189768
Validation loss: 2.4648798009429522

Epoch: 194| Step: 0
Training loss: 2.65101934297427
Validation loss: 2.4715741819654764

Epoch: 5| Step: 1
Training loss: 2.334305106754663
Validation loss: 2.4763125665544203

Epoch: 5| Step: 2
Training loss: 2.41609526050419
Validation loss: 2.476075899793962

Epoch: 5| Step: 3
Training loss: 2.185532693416344
Validation loss: 2.4954208517705636

Epoch: 5| Step: 4
Training loss: 2.653385367945568
Validation loss: 2.4844971352871164

Epoch: 5| Step: 5
Training loss: 2.5083028248635095
Validation loss: 2.4855574586890654

Epoch: 5| Step: 6
Training loss: 2.7080170569002417
Validation loss: 2.4795684101598177

Epoch: 5| Step: 7
Training loss: 2.3650445586315585
Validation loss: 2.476235960844046

Epoch: 5| Step: 8
Training loss: 1.7536146435533426
Validation loss: 2.470772269064236

Epoch: 5| Step: 9
Training loss: 3.1279731340157038
Validation loss: 2.4715239537197493

Epoch: 5| Step: 10
Training loss: 1.9714569374081412
Validation loss: 2.4742338482213704

Epoch: 5| Step: 11
Training loss: 2.359271217741514
Validation loss: 2.4779240669063864

Epoch: 195| Step: 0
Training loss: 2.306043219665047
Validation loss: 2.480949387328674

Epoch: 5| Step: 1
Training loss: 2.109533798456966
Validation loss: 2.4790649566836973

Epoch: 5| Step: 2
Training loss: 2.1001112227277745
Validation loss: 2.4800012623555547

Epoch: 5| Step: 3
Training loss: 2.8092157473633765
Validation loss: 2.4649956843265515

Epoch: 5| Step: 4
Training loss: 2.750798889640971
Validation loss: 2.477442451691456

Epoch: 5| Step: 5
Training loss: 2.136843606205562
Validation loss: 2.482316329797248

Epoch: 5| Step: 6
Training loss: 2.0403828639364017
Validation loss: 2.462721409178993

Epoch: 5| Step: 7
Training loss: 2.9748485366347595
Validation loss: 2.474814007333889

Epoch: 5| Step: 8
Training loss: 2.2635987790856893
Validation loss: 2.468894246068194

Epoch: 5| Step: 9
Training loss: 2.9198862743440093
Validation loss: 2.473087504194805

Epoch: 5| Step: 10
Training loss: 2.3234305960803403
Validation loss: 2.4731217679843023

Epoch: 5| Step: 11
Training loss: 1.8957876542285892
Validation loss: 2.4692375007594465

Epoch: 196| Step: 0
Training loss: 2.383474989551573
Validation loss: 2.4658897949098235

Epoch: 5| Step: 1
Training loss: 2.0158037209934516
Validation loss: 2.471253011473649

Epoch: 5| Step: 2
Training loss: 2.2956915680674093
Validation loss: 2.4734830754527897

Epoch: 5| Step: 3
Training loss: 2.2183745160520663
Validation loss: 2.478102699474486

Epoch: 5| Step: 4
Training loss: 2.2742898398544726
Validation loss: 2.4772935524382786

Epoch: 5| Step: 5
Training loss: 3.0693994771004336
Validation loss: 2.4725370734944985

Epoch: 5| Step: 6
Training loss: 2.2029667790731
Validation loss: 2.477978034069128

Epoch: 5| Step: 7
Training loss: 2.3314735857641025
Validation loss: 2.48035758262491

Epoch: 5| Step: 8
Training loss: 2.521199276006789
Validation loss: 2.47153530656221

Epoch: 5| Step: 9
Training loss: 2.634304269223493
Validation loss: 2.488444603908206

Epoch: 5| Step: 10
Training loss: 2.451547394822062
Validation loss: 2.4871826141919096

Epoch: 5| Step: 11
Training loss: 3.5855465345489543
Validation loss: 2.4938884299918884

Epoch: 197| Step: 0
Training loss: 2.6512552311480118
Validation loss: 2.480632646407439

Epoch: 5| Step: 1
Training loss: 2.657753462811345
Validation loss: 2.4740924852372346

Epoch: 5| Step: 2
Training loss: 2.7406984291113634
Validation loss: 2.4795689510218306

Epoch: 5| Step: 3
Training loss: 1.9572088043013305
Validation loss: 2.468374928017284

Epoch: 5| Step: 4
Training loss: 2.2096117985365513
Validation loss: 2.4667537702558224

Epoch: 5| Step: 5
Training loss: 2.1507512620857683
Validation loss: 2.4722687114733075

Epoch: 5| Step: 6
Training loss: 1.9323656285638167
Validation loss: 2.4694081608154814

Epoch: 5| Step: 7
Training loss: 2.2194502893953647
Validation loss: 2.468966679781993

Epoch: 5| Step: 8
Training loss: 2.8723271425990684
Validation loss: 2.4731946321906295

Epoch: 5| Step: 9
Training loss: 2.7493544601155335
Validation loss: 2.4721685875802644

Epoch: 5| Step: 10
Training loss: 2.396891738853047
Validation loss: 2.4803384261049737

Epoch: 5| Step: 11
Training loss: 3.231672254232606
Validation loss: 2.4745943249147193

Epoch: 198| Step: 0
Training loss: 2.410106887188226
Validation loss: 2.4857258353124223

Epoch: 5| Step: 1
Training loss: 2.7169199956095
Validation loss: 2.4853956896868485

Epoch: 5| Step: 2
Training loss: 2.3082703752803155
Validation loss: 2.4696431254608173

Epoch: 5| Step: 3
Training loss: 2.08473599580635
Validation loss: 2.4801574752017284

Epoch: 5| Step: 4
Training loss: 1.900632805599704
Validation loss: 2.4811805404690657

Epoch: 5| Step: 5
Training loss: 2.4552320433615367
Validation loss: 2.4744569991964283

Epoch: 5| Step: 6
Training loss: 2.783192674048361
Validation loss: 2.4804303904693654

Epoch: 5| Step: 7
Training loss: 3.098959803647673
Validation loss: 2.480106283222185

Epoch: 5| Step: 8
Training loss: 2.0326794802915655
Validation loss: 2.496264818485334

Epoch: 5| Step: 9
Training loss: 1.8710689025375877
Validation loss: 2.4807187052064394

Epoch: 5| Step: 10
Training loss: 2.7536615790579604
Validation loss: 2.4847105067608144

Epoch: 5| Step: 11
Training loss: 2.319861576949378
Validation loss: 2.493616563370864

Epoch: 199| Step: 0
Training loss: 2.2956337202172916
Validation loss: 2.5000380036326537

Epoch: 5| Step: 1
Training loss: 2.9983584363253013
Validation loss: 2.5009966373693007

Epoch: 5| Step: 2
Training loss: 1.8150738823515629
Validation loss: 2.494129954578872

Epoch: 5| Step: 3
Training loss: 2.879812111023878
Validation loss: 2.4937039169476973

Epoch: 5| Step: 4
Training loss: 2.21603625183888
Validation loss: 2.4868886574990676

Epoch: 5| Step: 5
Training loss: 2.3008585529909444
Validation loss: 2.4894284408992036

Epoch: 5| Step: 6
Training loss: 2.312352768618596
Validation loss: 2.497101462434338

Epoch: 5| Step: 7
Training loss: 1.9606839202209052
Validation loss: 2.4931280340452133

Epoch: 5| Step: 8
Training loss: 3.0315326676858656
Validation loss: 2.489594071789384

Epoch: 5| Step: 9
Training loss: 2.3843320910191332
Validation loss: 2.489603115678877

Epoch: 5| Step: 10
Training loss: 2.2561905787032264
Validation loss: 2.4827662663509336

Epoch: 5| Step: 11
Training loss: 1.8324809549338603
Validation loss: 2.4807550700584793

Epoch: 200| Step: 0
Training loss: 2.394787922430796
Validation loss: 2.478026670258529

Epoch: 5| Step: 1
Training loss: 2.570850721781664
Validation loss: 2.474581996542467

Epoch: 5| Step: 2
Training loss: 2.5478904899527186
Validation loss: 2.4779332215422327

Epoch: 5| Step: 3
Training loss: 2.3499027110313007
Validation loss: 2.4789982279021925

Epoch: 5| Step: 4
Training loss: 2.8121310521893355
Validation loss: 2.476559288993543

Epoch: 5| Step: 5
Training loss: 2.189547860837918
Validation loss: 2.483100580235721

Epoch: 5| Step: 6
Training loss: 2.8567419383912642
Validation loss: 2.478676418242126

Epoch: 5| Step: 7
Training loss: 2.4614332880421386
Validation loss: 2.4738042415347627

Epoch: 5| Step: 8
Training loss: 2.176633493288483
Validation loss: 2.4792992625854335

Epoch: 5| Step: 9
Training loss: 1.877013206512702
Validation loss: 2.486178493267385

Epoch: 5| Step: 10
Training loss: 2.5937943052621297
Validation loss: 2.483314619751214

Epoch: 5| Step: 11
Training loss: 1.0304610962832945
Validation loss: 2.4839417781617823

Epoch: 201| Step: 0
Training loss: 2.6648980673357
Validation loss: 2.490760881202549

Epoch: 5| Step: 1
Training loss: 2.255696925799925
Validation loss: 2.49463345391653

Epoch: 5| Step: 2
Training loss: 2.2321472800074766
Validation loss: 2.491955689558288

Epoch: 5| Step: 3
Training loss: 2.4399876738064963
Validation loss: 2.499189408338649

Epoch: 5| Step: 4
Training loss: 2.537715989114276
Validation loss: 2.5002948984420446

Epoch: 5| Step: 5
Training loss: 2.4004694876818378
Validation loss: 2.5138293821856865

Epoch: 5| Step: 6
Training loss: 2.0811182707834086
Validation loss: 2.50376704042768

Epoch: 5| Step: 7
Training loss: 3.0633402080548686
Validation loss: 2.508975473350822

Epoch: 5| Step: 8
Training loss: 2.263582874618761
Validation loss: 2.5266954316646553

Epoch: 5| Step: 9
Training loss: 2.127293527089463
Validation loss: 2.5070242628374824

Epoch: 5| Step: 10
Training loss: 2.6329730519771264
Validation loss: 2.5036427343825625

Epoch: 5| Step: 11
Training loss: 1.4519151142308164
Validation loss: 2.4947553577581547

Epoch: 202| Step: 0
Training loss: 2.7011083235474116
Validation loss: 2.486674665946554

Epoch: 5| Step: 1
Training loss: 2.581781741738658
Validation loss: 2.4828340101740696

Epoch: 5| Step: 2
Training loss: 2.2527321016588906
Validation loss: 2.490727617869209

Epoch: 5| Step: 3
Training loss: 2.2581902950168526
Validation loss: 2.480596059500784

Epoch: 5| Step: 4
Training loss: 2.7963266527756443
Validation loss: 2.4771983977902163

Epoch: 5| Step: 5
Training loss: 2.2367025136941265
Validation loss: 2.4777739737630684

Epoch: 5| Step: 6
Training loss: 2.175183856252661
Validation loss: 2.48447905828369

Epoch: 5| Step: 7
Training loss: 2.8162331283206186
Validation loss: 2.4862739734890713

Epoch: 5| Step: 8
Training loss: 1.7964280609242809
Validation loss: 2.486288083841079

Epoch: 5| Step: 9
Training loss: 2.039492740768752
Validation loss: 2.5001185587745076

Epoch: 5| Step: 10
Training loss: 2.8641865588435165
Validation loss: 2.5088429814562456

Epoch: 5| Step: 11
Training loss: 2.348415766023432
Validation loss: 2.50505872756901

Epoch: 203| Step: 0
Training loss: 1.9052096169955637
Validation loss: 2.498558709800998

Epoch: 5| Step: 1
Training loss: 2.2307575526551573
Validation loss: 2.4864371795990334

Epoch: 5| Step: 2
Training loss: 3.1543367838032603
Validation loss: 2.5038518319487575

Epoch: 5| Step: 3
Training loss: 2.1621018765396167
Validation loss: 2.490659067677972

Epoch: 5| Step: 4
Training loss: 2.3852892401585826
Validation loss: 2.4929701434220903

Epoch: 5| Step: 5
Training loss: 2.1146349845804298
Validation loss: 2.4841310913185803

Epoch: 5| Step: 6
Training loss: 2.5363482713156253
Validation loss: 2.479053560182574

Epoch: 5| Step: 7
Training loss: 1.823614114218327
Validation loss: 2.4855503524891036

Epoch: 5| Step: 8
Training loss: 2.896324683203219
Validation loss: 2.48812860951932

Epoch: 5| Step: 9
Training loss: 2.969835424262528
Validation loss: 2.497742408409491

Epoch: 5| Step: 10
Training loss: 2.120953353253783
Validation loss: 2.4785519941190204

Epoch: 5| Step: 11
Training loss: 2.674883659898901
Validation loss: 2.4890488898189944

Epoch: 204| Step: 0
Training loss: 2.5757614861592955
Validation loss: 2.49267478890544

Epoch: 5| Step: 1
Training loss: 1.6780014447238965
Validation loss: 2.481525814667692

Epoch: 5| Step: 2
Training loss: 2.5669192842128514
Validation loss: 2.477080809370273

Epoch: 5| Step: 3
Training loss: 1.9780955645403544
Validation loss: 2.481238882903106

Epoch: 5| Step: 4
Training loss: 2.3914986802850584
Validation loss: 2.4800289094493553

Epoch: 5| Step: 5
Training loss: 3.006650863854042
Validation loss: 2.486473602649697

Epoch: 5| Step: 6
Training loss: 2.5330849107440243
Validation loss: 2.483582352200802

Epoch: 5| Step: 7
Training loss: 2.3297815765687226
Validation loss: 2.4843665668656314

Epoch: 5| Step: 8
Training loss: 3.163347629746616
Validation loss: 2.480715461536656

Epoch: 5| Step: 9
Training loss: 2.677466091792569
Validation loss: 2.4799177824448346

Epoch: 5| Step: 10
Training loss: 1.5170110283628662
Validation loss: 2.4826156576591716

Epoch: 5| Step: 11
Training loss: 2.413741599670364
Validation loss: 2.4806893158015133

Epoch: 205| Step: 0
Training loss: 2.1106493456032
Validation loss: 2.485689675066258

Epoch: 5| Step: 1
Training loss: 2.22870219968327
Validation loss: 2.4830034536651855

Epoch: 5| Step: 2
Training loss: 2.5574996356087554
Validation loss: 2.4874116385083815

Epoch: 5| Step: 3
Training loss: 2.133814761358402
Validation loss: 2.4936591479993733

Epoch: 5| Step: 4
Training loss: 2.246579961811017
Validation loss: 2.4912883966322625

Epoch: 5| Step: 5
Training loss: 2.681224059933114
Validation loss: 2.4834713241995754

Epoch: 5| Step: 6
Training loss: 2.7339461508012475
Validation loss: 2.486106453138803

Epoch: 5| Step: 7
Training loss: 2.3124309220177808
Validation loss: 2.488397446838239

Epoch: 5| Step: 8
Training loss: 2.2687399661680345
Validation loss: 2.4929968616857563

Epoch: 5| Step: 9
Training loss: 2.1855516748997785
Validation loss: 2.493777227452275

Epoch: 5| Step: 10
Training loss: 2.958419332910874
Validation loss: 2.4874817358717065

Epoch: 5| Step: 11
Training loss: 2.512558104189575
Validation loss: 2.4988008444483953

Epoch: 206| Step: 0
Training loss: 1.9987962795909238
Validation loss: 2.50222713291222

Epoch: 5| Step: 1
Training loss: 2.774962701632741
Validation loss: 2.5123355715199573

Epoch: 5| Step: 2
Training loss: 2.496840960637029
Validation loss: 2.5146583393976014

Epoch: 5| Step: 3
Training loss: 2.227336227099219
Validation loss: 2.5112420436061544

Epoch: 5| Step: 4
Training loss: 2.7203670384496017
Validation loss: 2.5166592929955223

Epoch: 5| Step: 5
Training loss: 2.3258949198189396
Validation loss: 2.5150721359082877

Epoch: 5| Step: 6
Training loss: 2.50862369905579
Validation loss: 2.5138233478062615

Epoch: 5| Step: 7
Training loss: 2.149500802216754
Validation loss: 2.5053272866752514

Epoch: 5| Step: 8
Training loss: 2.6084075779042397
Validation loss: 2.4952400908835703

Epoch: 5| Step: 9
Training loss: 2.2399753197945227
Validation loss: 2.4919710732998728

Epoch: 5| Step: 10
Training loss: 2.195360828017037
Validation loss: 2.4994253571024023

Epoch: 5| Step: 11
Training loss: 3.249697010882187
Validation loss: 2.4952981523655877

Epoch: 207| Step: 0
Training loss: 2.0407339677443783
Validation loss: 2.4953513775215224

Epoch: 5| Step: 1
Training loss: 2.578900214889939
Validation loss: 2.4894469209166035

Epoch: 5| Step: 2
Training loss: 2.6323705466412246
Validation loss: 2.490200697727242

Epoch: 5| Step: 3
Training loss: 2.7428315104694674
Validation loss: 2.4885099296946565

Epoch: 5| Step: 4
Training loss: 2.258836771275237
Validation loss: 2.492050262786208

Epoch: 5| Step: 5
Training loss: 2.7246560150857966
Validation loss: 2.4978412805040837

Epoch: 5| Step: 6
Training loss: 2.454653221391237
Validation loss: 2.4970707501135183

Epoch: 5| Step: 7
Training loss: 2.1484087577977977
Validation loss: 2.5068720265252527

Epoch: 5| Step: 8
Training loss: 2.5724196681166887
Validation loss: 2.4986876977364028

Epoch: 5| Step: 9
Training loss: 1.8203863693769728
Validation loss: 2.5139215419965772

Epoch: 5| Step: 10
Training loss: 2.2468202162471664
Validation loss: 2.517484262165325

Epoch: 5| Step: 11
Training loss: 3.1729062663605214
Validation loss: 2.5031236803334695

Epoch: 208| Step: 0
Training loss: 2.672788408095688
Validation loss: 2.51174569202012

Epoch: 5| Step: 1
Training loss: 2.008779804837078
Validation loss: 2.5061334790598453

Epoch: 5| Step: 2
Training loss: 2.46540296591912
Validation loss: 2.483896885256105

Epoch: 5| Step: 3
Training loss: 2.2616679395064407
Validation loss: 2.49699064964873

Epoch: 5| Step: 4
Training loss: 2.4500568422224105
Validation loss: 2.4913791991956633

Epoch: 5| Step: 5
Training loss: 2.853591322629166
Validation loss: 2.5045825800632513

Epoch: 5| Step: 6
Training loss: 2.5519244916621298
Validation loss: 2.4984901001216078

Epoch: 5| Step: 7
Training loss: 2.100378901495202
Validation loss: 2.512264653154565

Epoch: 5| Step: 8
Training loss: 2.411808480093998
Validation loss: 2.5178219854933643

Epoch: 5| Step: 9
Training loss: 2.343204485668657
Validation loss: 2.5065984272883863

Epoch: 5| Step: 10
Training loss: 2.302598840867977
Validation loss: 2.497916120020595

Epoch: 5| Step: 11
Training loss: 2.211608677007771
Validation loss: 2.4910931790547077

Epoch: 209| Step: 0
Training loss: 1.8235595949903374
Validation loss: 2.4788744511144203

Epoch: 5| Step: 1
Training loss: 2.5845875515417296
Validation loss: 2.4839925451614735

Epoch: 5| Step: 2
Training loss: 1.9287964157284787
Validation loss: 2.4762532996852613

Epoch: 5| Step: 3
Training loss: 2.1807950395198836
Validation loss: 2.479446572976843

Epoch: 5| Step: 4
Training loss: 2.919686053395232
Validation loss: 2.471154639359938

Epoch: 5| Step: 5
Training loss: 3.165306167136738
Validation loss: 2.4754092903992593

Epoch: 5| Step: 6
Training loss: 2.573037416247606
Validation loss: 2.480878432676226

Epoch: 5| Step: 7
Training loss: 2.4304310927237314
Validation loss: 2.481550034063881

Epoch: 5| Step: 8
Training loss: 1.9352134625290278
Validation loss: 2.4884391746529735

Epoch: 5| Step: 9
Training loss: 2.485279422454993
Validation loss: 2.484732482190169

Epoch: 5| Step: 10
Training loss: 2.4831303771714723
Validation loss: 2.4982793489539965

Epoch: 5| Step: 11
Training loss: 2.215771892719647
Validation loss: 2.500293217788746

Epoch: 210| Step: 0
Training loss: 2.1910366351826815
Validation loss: 2.5043481406109174

Epoch: 5| Step: 1
Training loss: 2.5337489473164747
Validation loss: 2.4901240864185503

Epoch: 5| Step: 2
Training loss: 2.2215942634676042
Validation loss: 2.4908675880944013

Epoch: 5| Step: 3
Training loss: 2.5391403421060446
Validation loss: 2.4950228539517805

Epoch: 5| Step: 4
Training loss: 2.1713473550407993
Validation loss: 2.4918247106328644

Epoch: 5| Step: 5
Training loss: 2.442357627131742
Validation loss: 2.492861573870142

Epoch: 5| Step: 6
Training loss: 2.400322089834764
Validation loss: 2.495124791999073

Epoch: 5| Step: 7
Training loss: 2.221103655578015
Validation loss: 2.499926375258653

Epoch: 5| Step: 8
Training loss: 1.7538303962056265
Validation loss: 2.500911693434291

Epoch: 5| Step: 9
Training loss: 3.0045020972155854
Validation loss: 2.509327323036271

Epoch: 5| Step: 10
Training loss: 2.712774791949818
Validation loss: 2.503650582800187

Epoch: 5| Step: 11
Training loss: 2.81543815577117
Validation loss: 2.5012139671064944

Epoch: 211| Step: 0
Training loss: 2.12579375757185
Validation loss: 2.5106754143252386

Epoch: 5| Step: 1
Training loss: 2.861470939535325
Validation loss: 2.511305597556021

Epoch: 5| Step: 2
Training loss: 2.501381683009748
Validation loss: 2.506951704275997

Epoch: 5| Step: 3
Training loss: 2.7213792912298387
Validation loss: 2.513483747364873

Epoch: 5| Step: 4
Training loss: 2.4197979295714953
Validation loss: 2.4993952973503397

Epoch: 5| Step: 5
Training loss: 2.518730663291596
Validation loss: 2.4954871254914135

Epoch: 5| Step: 6
Training loss: 1.9169314312161123
Validation loss: 2.504068116477267

Epoch: 5| Step: 7
Training loss: 1.75237929860426
Validation loss: 2.499647139442673

Epoch: 5| Step: 8
Training loss: 2.1004399701579914
Validation loss: 2.496623612322519

Epoch: 5| Step: 9
Training loss: 2.930377360184776
Validation loss: 2.503097232882077

Epoch: 5| Step: 10
Training loss: 1.907773081679215
Validation loss: 2.5108585298563035

Epoch: 5| Step: 11
Training loss: 3.680580500552178
Validation loss: 2.5178464160112237

Epoch: 212| Step: 0
Training loss: 2.353704649113042
Validation loss: 2.5210075646606867

Epoch: 5| Step: 1
Training loss: 2.9119379311643327
Validation loss: 2.520192633669791

Epoch: 5| Step: 2
Training loss: 2.6770513708282144
Validation loss: 2.497242821761805

Epoch: 5| Step: 3
Training loss: 2.305487852621745
Validation loss: 2.502456997458417

Epoch: 5| Step: 4
Training loss: 2.2443364176651324
Validation loss: 2.4994878681463555

Epoch: 5| Step: 5
Training loss: 1.925416552074401
Validation loss: 2.5002181196427844

Epoch: 5| Step: 6
Training loss: 2.4652710557825084
Validation loss: 2.497463119337627

Epoch: 5| Step: 7
Training loss: 2.31959866932954
Validation loss: 2.4999836484056415

Epoch: 5| Step: 8
Training loss: 2.2729399356181266
Validation loss: 2.5030974273496516

Epoch: 5| Step: 9
Training loss: 2.4849232962300816
Validation loss: 2.50107815660398

Epoch: 5| Step: 10
Training loss: 2.205396090373743
Validation loss: 2.5094511871680356

Epoch: 5| Step: 11
Training loss: 2.801103857978342
Validation loss: 2.5070678817626213

Epoch: 213| Step: 0
Training loss: 2.8692446612562446
Validation loss: 2.498944882421215

Epoch: 5| Step: 1
Training loss: 1.5814706821769429
Validation loss: 2.505546471001193

Epoch: 5| Step: 2
Training loss: 2.76075168711887
Validation loss: 2.517475742638659

Epoch: 5| Step: 3
Training loss: 2.1932769787089073
Validation loss: 2.521927758869981

Epoch: 5| Step: 4
Training loss: 2.213287291028753
Validation loss: 2.5217661366528024

Epoch: 5| Step: 5
Training loss: 2.241913250356767
Validation loss: 2.5304639129419706

Epoch: 5| Step: 6
Training loss: 2.5407680945081945
Validation loss: 2.5179778640681545

Epoch: 5| Step: 7
Training loss: 2.3168831602888775
Validation loss: 2.5248411150631993

Epoch: 5| Step: 8
Training loss: 2.4878663296500765
Validation loss: 2.5311057418563343

Epoch: 5| Step: 9
Training loss: 2.4330511330132243
Validation loss: 2.518122288442165

Epoch: 5| Step: 10
Training loss: 2.6271359064547624
Validation loss: 2.5131975589470668

Epoch: 5| Step: 11
Training loss: 2.5486100728387706
Validation loss: 2.496658527951372

Epoch: 214| Step: 0
Training loss: 2.5578412762178444
Validation loss: 2.4778571450300055

Epoch: 5| Step: 1
Training loss: 2.625188911543141
Validation loss: 2.470313687598699

Epoch: 5| Step: 2
Training loss: 2.728945240230376
Validation loss: 2.48423081705373

Epoch: 5| Step: 3
Training loss: 1.9056567535307143
Validation loss: 2.491323917368655

Epoch: 5| Step: 4
Training loss: 2.7464555960481962
Validation loss: 2.4927315432058723

Epoch: 5| Step: 5
Training loss: 2.436526568760513
Validation loss: 2.49326477763798

Epoch: 5| Step: 6
Training loss: 2.22746114163911
Validation loss: 2.495275587216154

Epoch: 5| Step: 7
Training loss: 2.105499323975023
Validation loss: 2.4986185747397616

Epoch: 5| Step: 8
Training loss: 2.669550191015534
Validation loss: 2.491874439981584

Epoch: 5| Step: 9
Training loss: 2.9855561640204504
Validation loss: 2.490572171705961

Epoch: 5| Step: 10
Training loss: 2.445017641468021
Validation loss: 2.479599503524414

Epoch: 5| Step: 11
Training loss: 2.3803479065377076
Validation loss: 2.480307790585059

Epoch: 215| Step: 0
Training loss: 2.3042850466274434
Validation loss: 2.484687429652075

Epoch: 5| Step: 1
Training loss: 2.7382982283431825
Validation loss: 2.476336684496571

Epoch: 5| Step: 2
Training loss: 2.1700596529588543
Validation loss: 2.485869448002286

Epoch: 5| Step: 3
Training loss: 2.36846365695134
Validation loss: 2.481130014220157

Epoch: 5| Step: 4
Training loss: 3.185373232545165
Validation loss: 2.4707015850479492

Epoch: 5| Step: 5
Training loss: 2.1818609305731034
Validation loss: 2.4766776843315803

Epoch: 5| Step: 6
Training loss: 2.40099106829792
Validation loss: 2.474323620514493

Epoch: 5| Step: 7
Training loss: 2.706969509549131
Validation loss: 2.4717787902730537

Epoch: 5| Step: 8
Training loss: 2.9266911760953485
Validation loss: 2.478488642408164

Epoch: 5| Step: 9
Training loss: 2.192897241810676
Validation loss: 2.475715283708458

Epoch: 5| Step: 10
Training loss: 2.1799200337293545
Validation loss: 2.4681123602176314

Epoch: 5| Step: 11
Training loss: 2.736655978725191
Validation loss: 2.462834167236719

Epoch: 216| Step: 0
Training loss: 2.293514985978021
Validation loss: 2.4641444951946587

Epoch: 5| Step: 1
Training loss: 1.911400699699412
Validation loss: 2.4713751320038417

Epoch: 5| Step: 2
Training loss: 2.0879029576050647
Validation loss: 2.470989901217515

Epoch: 5| Step: 3
Training loss: 3.534034913663997
Validation loss: 2.4668169622340876

Epoch: 5| Step: 4
Training loss: 2.8811195592253336
Validation loss: 2.4824683812565

Epoch: 5| Step: 5
Training loss: 2.232581105398278
Validation loss: 2.4811761082777744

Epoch: 5| Step: 6
Training loss: 2.2716531469437693
Validation loss: 2.4730202405450648

Epoch: 5| Step: 7
Training loss: 2.2419864152331717
Validation loss: 2.4799277168617477

Epoch: 5| Step: 8
Training loss: 2.595530163331929
Validation loss: 2.4805588833510215

Epoch: 5| Step: 9
Training loss: 2.4398407089893595
Validation loss: 2.4760716911638525

Epoch: 5| Step: 10
Training loss: 1.948770230661124
Validation loss: 2.4752035754863124

Epoch: 5| Step: 11
Training loss: 3.163247538033886
Validation loss: 2.4792246023722773

Epoch: 217| Step: 0
Training loss: 2.35866915015907
Validation loss: 2.4962638156287604

Epoch: 5| Step: 1
Training loss: 2.012653022777149
Validation loss: 2.49071631062775

Epoch: 5| Step: 2
Training loss: 2.3417427113992693
Validation loss: 2.498337999867142

Epoch: 5| Step: 3
Training loss: 2.687603615825961
Validation loss: 2.5127298110825427

Epoch: 5| Step: 4
Training loss: 2.414603657235117
Validation loss: 2.500190095826762

Epoch: 5| Step: 5
Training loss: 2.4122273898888107
Validation loss: 2.5312867279684808

Epoch: 5| Step: 6
Training loss: 2.464884568736399
Validation loss: 2.545744131953159

Epoch: 5| Step: 7
Training loss: 2.0916978258747814
Validation loss: 2.521182711221385

Epoch: 5| Step: 8
Training loss: 2.479389105896842
Validation loss: 2.528702230770708

Epoch: 5| Step: 9
Training loss: 2.747428385223825
Validation loss: 2.514425275955664

Epoch: 5| Step: 10
Training loss: 2.6785699499216995
Validation loss: 2.498445162464167

Epoch: 5| Step: 11
Training loss: 2.230949817628275
Validation loss: 2.4967568739988715

Epoch: 218| Step: 0
Training loss: 1.9374890480962519
Validation loss: 2.480779649369137

Epoch: 5| Step: 1
Training loss: 2.3175581179741727
Validation loss: 2.4809968721558917

Epoch: 5| Step: 2
Training loss: 2.837061803650808
Validation loss: 2.4762317905979283

Epoch: 5| Step: 3
Training loss: 2.2769879804251247
Validation loss: 2.4778382578400344

Epoch: 5| Step: 4
Training loss: 3.1666064173002937
Validation loss: 2.4826109359222737

Epoch: 5| Step: 5
Training loss: 2.7958561410745855
Validation loss: 2.4837272447370164

Epoch: 5| Step: 6
Training loss: 2.5212336976295444
Validation loss: 2.4871109985774447

Epoch: 5| Step: 7
Training loss: 2.432252174290993
Validation loss: 2.487616363835623

Epoch: 5| Step: 8
Training loss: 2.2833167342350666
Validation loss: 2.4879631705519922

Epoch: 5| Step: 9
Training loss: 1.8598225159207284
Validation loss: 2.4961871476427655

Epoch: 5| Step: 10
Training loss: 1.8986538736246357
Validation loss: 2.498235381735992

Epoch: 5| Step: 11
Training loss: 2.7711559098324154
Validation loss: 2.5059657362944594

Epoch: 219| Step: 0
Training loss: 2.612887639394598
Validation loss: 2.532120041004952

Epoch: 5| Step: 1
Training loss: 2.55308300343295
Validation loss: 2.5532168239172583

Epoch: 5| Step: 2
Training loss: 2.6620501751659975
Validation loss: 2.593192833495693

Epoch: 5| Step: 3
Training loss: 2.2809158498518145
Validation loss: 2.593526466726097

Epoch: 5| Step: 4
Training loss: 2.540973589679213
Validation loss: 2.585940477229284

Epoch: 5| Step: 5
Training loss: 2.681297241363853
Validation loss: 2.581584058732455

Epoch: 5| Step: 6
Training loss: 2.137789442308572
Validation loss: 2.546128832643753

Epoch: 5| Step: 7
Training loss: 2.2447336872399
Validation loss: 2.5150728508274223

Epoch: 5| Step: 8
Training loss: 2.7096611778187105
Validation loss: 2.499323117492805

Epoch: 5| Step: 9
Training loss: 2.537449344824694
Validation loss: 2.499853487489959

Epoch: 5| Step: 10
Training loss: 2.127821675780971
Validation loss: 2.488322630437874

Epoch: 5| Step: 11
Training loss: 2.4962126654295753
Validation loss: 2.486649030306696

Epoch: 220| Step: 0
Training loss: 3.033831725903906
Validation loss: 2.4813465998027793

Epoch: 5| Step: 1
Training loss: 2.0864699466386565
Validation loss: 2.47987844096184

Epoch: 5| Step: 2
Training loss: 1.8171766390685011
Validation loss: 2.482462036544266

Epoch: 5| Step: 3
Training loss: 2.839760801423556
Validation loss: 2.4862363408306263

Epoch: 5| Step: 4
Training loss: 2.1810147746135327
Validation loss: 2.4797428140157645

Epoch: 5| Step: 5
Training loss: 2.2549404369870016
Validation loss: 2.4812473907264807

Epoch: 5| Step: 6
Training loss: 2.1041278143087587
Validation loss: 2.493338591118316

Epoch: 5| Step: 7
Training loss: 2.4469581404746896
Validation loss: 2.479752492744

Epoch: 5| Step: 8
Training loss: 2.334887418463034
Validation loss: 2.4863953802297516

Epoch: 5| Step: 9
Training loss: 2.5341617179336406
Validation loss: 2.49414493457857

Epoch: 5| Step: 10
Training loss: 2.2546595962288727
Validation loss: 2.501059089281142

Epoch: 5| Step: 11
Training loss: 3.2463910532475087
Validation loss: 2.4999106629621894

Epoch: 221| Step: 0
Training loss: 2.965787835268343
Validation loss: 2.5030906051006196

Epoch: 5| Step: 1
Training loss: 2.632379241521139
Validation loss: 2.505814486245499

Epoch: 5| Step: 2
Training loss: 2.607773157809232
Validation loss: 2.5169117600312814

Epoch: 5| Step: 3
Training loss: 2.6524527840542165
Validation loss: 2.513282621251077

Epoch: 5| Step: 4
Training loss: 2.256772550900197
Validation loss: 2.4940336120319224

Epoch: 5| Step: 5
Training loss: 2.4889943105740655
Validation loss: 2.4994317024739043

Epoch: 5| Step: 6
Training loss: 1.9499971903267206
Validation loss: 2.497302996700247

Epoch: 5| Step: 7
Training loss: 2.201568486548705
Validation loss: 2.49784091461296

Epoch: 5| Step: 8
Training loss: 2.5262438401529828
Validation loss: 2.4953193478140987

Epoch: 5| Step: 9
Training loss: 2.1352055018774663
Validation loss: 2.487664332384988

Epoch: 5| Step: 10
Training loss: 1.6908993567142732
Validation loss: 2.499465297102213

Epoch: 5| Step: 11
Training loss: 3.041858788959108
Validation loss: 2.5070348090343386

Epoch: 222| Step: 0
Training loss: 2.9852630731896816
Validation loss: 2.491705549908468

Epoch: 5| Step: 1
Training loss: 2.267668966203666
Validation loss: 2.4812475588808134

Epoch: 5| Step: 2
Training loss: 1.926565200296383
Validation loss: 2.491998723134111

Epoch: 5| Step: 3
Training loss: 2.0597096844142437
Validation loss: 2.492659453345713

Epoch: 5| Step: 4
Training loss: 2.3089259597650598
Validation loss: 2.479549736325674

Epoch: 5| Step: 5
Training loss: 3.038606977278523
Validation loss: 2.49489459633118

Epoch: 5| Step: 6
Training loss: 2.0385430503792437
Validation loss: 2.483490860559645

Epoch: 5| Step: 7
Training loss: 2.484078635526756
Validation loss: 2.492695068125347

Epoch: 5| Step: 8
Training loss: 2.6766120010849175
Validation loss: 2.4999184475948595

Epoch: 5| Step: 9
Training loss: 2.420083743293699
Validation loss: 2.5024120139279966

Epoch: 5| Step: 10
Training loss: 2.1141703034719126
Validation loss: 2.4937671689467864

Epoch: 5| Step: 11
Training loss: 1.153628186276775
Validation loss: 2.494398853991154

Epoch: 223| Step: 0
Training loss: 2.5071046965275676
Validation loss: 2.497474280680926

Epoch: 5| Step: 1
Training loss: 2.380241032103817
Validation loss: 2.508417737819684

Epoch: 5| Step: 2
Training loss: 1.8726419243803716
Validation loss: 2.510304778258259

Epoch: 5| Step: 3
Training loss: 2.4656807858111542
Validation loss: 2.511839828618314

Epoch: 5| Step: 4
Training loss: 2.604230091594174
Validation loss: 2.5064997381337903

Epoch: 5| Step: 5
Training loss: 2.426032748983287
Validation loss: 2.503596774221663

Epoch: 5| Step: 6
Training loss: 2.4949251164453656
Validation loss: 2.4985068670443993

Epoch: 5| Step: 7
Training loss: 2.133861018523585
Validation loss: 2.505424118794314

Epoch: 5| Step: 8
Training loss: 2.817045057337923
Validation loss: 2.4974415801110963

Epoch: 5| Step: 9
Training loss: 1.4892265141434518
Validation loss: 2.5042153939781424

Epoch: 5| Step: 10
Training loss: 2.9120112913667358
Validation loss: 2.5041112870383424

Epoch: 5| Step: 11
Training loss: 0.8311695059903806
Validation loss: 2.5011943904497387

Epoch: 224| Step: 0
Training loss: 2.7687586041525627
Validation loss: 2.5048527984109876

Epoch: 5| Step: 1
Training loss: 1.9577750431505478
Validation loss: 2.4982206529226945

Epoch: 5| Step: 2
Training loss: 2.1608230086066573
Validation loss: 2.493281816769074

Epoch: 5| Step: 3
Training loss: 2.2627266069601646
Validation loss: 2.5034067108911073

Epoch: 5| Step: 4
Training loss: 2.3005298418855085
Validation loss: 2.4983700604588366

Epoch: 5| Step: 5
Training loss: 2.8465823645992163
Validation loss: 2.494033424823913

Epoch: 5| Step: 6
Training loss: 2.558840674213285
Validation loss: 2.4997356116046756

Epoch: 5| Step: 7
Training loss: 2.0530655990206053
Validation loss: 2.493425464386735

Epoch: 5| Step: 8
Training loss: 1.7676524446996602
Validation loss: 2.507576429242473

Epoch: 5| Step: 9
Training loss: 2.369207244464722
Validation loss: 2.5177239611804447

Epoch: 5| Step: 10
Training loss: 2.784365419998557
Validation loss: 2.5235355385709837

Epoch: 5| Step: 11
Training loss: 2.5945806437140937
Validation loss: 2.5137801424910062

Epoch: 225| Step: 0
Training loss: 2.565837826189562
Validation loss: 2.5164669910274293

Epoch: 5| Step: 1
Training loss: 2.65088119970487
Validation loss: 2.5145788209037674

Epoch: 5| Step: 2
Training loss: 2.6717548008701884
Validation loss: 2.5035179459982735

Epoch: 5| Step: 3
Training loss: 2.700713564924208
Validation loss: 2.500049920378412

Epoch: 5| Step: 4
Training loss: 2.4423713912605307
Validation loss: 2.498907339209965

Epoch: 5| Step: 5
Training loss: 2.182372049992256
Validation loss: 2.4842181806033627

Epoch: 5| Step: 6
Training loss: 2.3088609053529696
Validation loss: 2.4928592625564856

Epoch: 5| Step: 7
Training loss: 2.5193128387648547
Validation loss: 2.489765838227551

Epoch: 5| Step: 8
Training loss: 1.935936204418768
Validation loss: 2.4941260353085846

Epoch: 5| Step: 9
Training loss: 2.4033110865261254
Validation loss: 2.4886121864168445

Epoch: 5| Step: 10
Training loss: 2.009334951805538
Validation loss: 2.500447868919958

Epoch: 5| Step: 11
Training loss: 1.7239718787207623
Validation loss: 2.50973505182112

Epoch: 226| Step: 0
Training loss: 2.0452550636660605
Validation loss: 2.4972835922609247

Epoch: 5| Step: 1
Training loss: 2.140955433089019
Validation loss: 2.5168401614653684

Epoch: 5| Step: 2
Training loss: 2.845463330933644
Validation loss: 2.5177640922684064

Epoch: 5| Step: 3
Training loss: 2.351831870635228
Validation loss: 2.51453944491623

Epoch: 5| Step: 4
Training loss: 2.147521999543984
Validation loss: 2.525830963366068

Epoch: 5| Step: 5
Training loss: 2.20639109822221
Validation loss: 2.5289390634900952

Epoch: 5| Step: 6
Training loss: 2.622337080528744
Validation loss: 2.537900304616833

Epoch: 5| Step: 7
Training loss: 1.7708356819885236
Validation loss: 2.521341933943281

Epoch: 5| Step: 8
Training loss: 2.43574304104257
Validation loss: 2.515609306776171

Epoch: 5| Step: 9
Training loss: 2.263147196224984
Validation loss: 2.522796041490955

Epoch: 5| Step: 10
Training loss: 2.678482897067445
Validation loss: 2.4933379994557403

Epoch: 5| Step: 11
Training loss: 4.395442613831328
Validation loss: 2.5053655346397554

Epoch: 227| Step: 0
Training loss: 2.222790544740132
Validation loss: 2.506433210628828

Epoch: 5| Step: 1
Training loss: 2.2552359375941817
Validation loss: 2.4880438111950234

Epoch: 5| Step: 2
Training loss: 2.0898414683106705
Validation loss: 2.4930405626640164

Epoch: 5| Step: 3
Training loss: 2.403028635540988
Validation loss: 2.5010778289197306

Epoch: 5| Step: 4
Training loss: 2.673742522826224
Validation loss: 2.4980216344413706

Epoch: 5| Step: 5
Training loss: 2.7071697865716544
Validation loss: 2.5034902884727526

Epoch: 5| Step: 6
Training loss: 2.335479487295359
Validation loss: 2.5175242195050327

Epoch: 5| Step: 7
Training loss: 2.576437102829492
Validation loss: 2.511897338324282

Epoch: 5| Step: 8
Training loss: 2.6837033800500913
Validation loss: 2.5202339040283035

Epoch: 5| Step: 9
Training loss: 2.216311229326892
Validation loss: 2.5300777491646342

Epoch: 5| Step: 10
Training loss: 2.1958423124512203
Validation loss: 2.537467447707868

Epoch: 5| Step: 11
Training loss: 0.9677124312156304
Validation loss: 2.526881054243455

Epoch: 228| Step: 0
Training loss: 1.967950386061631
Validation loss: 2.545358370091883

Epoch: 5| Step: 1
Training loss: 2.0890073439421974
Validation loss: 2.57570698948942

Epoch: 5| Step: 2
Training loss: 1.7428198381022881
Validation loss: 2.574316703078898

Epoch: 5| Step: 3
Training loss: 3.4333482118549608
Validation loss: 2.5776950477667366

Epoch: 5| Step: 4
Training loss: 2.67615099948753
Validation loss: 2.5621083181210094

Epoch: 5| Step: 5
Training loss: 2.378725643223695
Validation loss: 2.5467132251745963

Epoch: 5| Step: 6
Training loss: 1.4325670936943202
Validation loss: 2.5276023048558045

Epoch: 5| Step: 7
Training loss: 2.741911523739618
Validation loss: 2.5099557094605114

Epoch: 5| Step: 8
Training loss: 2.3367156196759478
Validation loss: 2.4988058536362563

Epoch: 5| Step: 9
Training loss: 2.379675329005676
Validation loss: 2.4953106013294595

Epoch: 5| Step: 10
Training loss: 2.4156287584361933
Validation loss: 2.491902856306706

Epoch: 5| Step: 11
Training loss: 2.772188921057146
Validation loss: 2.4933657875239543

Epoch: 229| Step: 0
Training loss: 2.1990050623663295
Validation loss: 2.492913812972237

Epoch: 5| Step: 1
Training loss: 2.3660955648913435
Validation loss: 2.4885983906270703

Epoch: 5| Step: 2
Training loss: 1.9641055470364346
Validation loss: 2.4848113166691186

Epoch: 5| Step: 3
Training loss: 2.3931985603398322
Validation loss: 2.482344535385222

Epoch: 5| Step: 4
Training loss: 2.8306507613276812
Validation loss: 2.488399267267428

Epoch: 5| Step: 5
Training loss: 2.494803846060079
Validation loss: 2.491949717818553

Epoch: 5| Step: 6
Training loss: 1.8258301114231354
Validation loss: 2.4889702653927492

Epoch: 5| Step: 7
Training loss: 2.7837484046441565
Validation loss: 2.489605932784887

Epoch: 5| Step: 8
Training loss: 2.274012332356076
Validation loss: 2.4973071198258343

Epoch: 5| Step: 9
Training loss: 2.351651212216573
Validation loss: 2.5196951287963243

Epoch: 5| Step: 10
Training loss: 2.464778167771047
Validation loss: 2.5201050846641277

Epoch: 5| Step: 11
Training loss: 2.956007585002165
Validation loss: 2.5302729663679124

Epoch: 230| Step: 0
Training loss: 2.2438465320786722
Validation loss: 2.5462133800287177

Epoch: 5| Step: 1
Training loss: 2.8181687764456123
Validation loss: 2.538012200292638

Epoch: 5| Step: 2
Training loss: 2.3479722710032993
Validation loss: 2.5346015515337177

Epoch: 5| Step: 3
Training loss: 1.837939076286665
Validation loss: 2.5288508862773496

Epoch: 5| Step: 4
Training loss: 2.4933208889914185
Validation loss: 2.512569989230703

Epoch: 5| Step: 5
Training loss: 2.2748170842006274
Validation loss: 2.4998969811830376

Epoch: 5| Step: 6
Training loss: 2.7106794514815067
Validation loss: 2.5089467059625723

Epoch: 5| Step: 7
Training loss: 2.0095368932643725
Validation loss: 2.49347794864553

Epoch: 5| Step: 8
Training loss: 1.5943624778145156
Validation loss: 2.4886690373569946

Epoch: 5| Step: 9
Training loss: 2.074686058838015
Validation loss: 2.5138847341965636

Epoch: 5| Step: 10
Training loss: 3.3155804112462635
Validation loss: 2.499453294104369

Epoch: 5| Step: 11
Training loss: 3.010162307570793
Validation loss: 2.51494980274713

Epoch: 231| Step: 0
Training loss: 1.9601184608706057
Validation loss: 2.5017782840590543

Epoch: 5| Step: 1
Training loss: 2.8393006782788617
Validation loss: 2.494924268337647

Epoch: 5| Step: 2
Training loss: 2.5046480838484637
Validation loss: 2.4779454530611456

Epoch: 5| Step: 3
Training loss: 2.2591386220277845
Validation loss: 2.4784555189912374

Epoch: 5| Step: 4
Training loss: 1.8842042709618014
Validation loss: 2.477843337469915

Epoch: 5| Step: 5
Training loss: 2.708989127553059
Validation loss: 2.47910190679346

Epoch: 5| Step: 6
Training loss: 2.114865539461079
Validation loss: 2.4730211724874964

Epoch: 5| Step: 7
Training loss: 2.516430269805903
Validation loss: 2.479234679809177

Epoch: 5| Step: 8
Training loss: 2.6161089596411307
Validation loss: 2.471084892923613

Epoch: 5| Step: 9
Training loss: 2.503416587809864
Validation loss: 2.475989137979551

Epoch: 5| Step: 10
Training loss: 2.6775273549795564
Validation loss: 2.4841282879990274

Epoch: 5| Step: 11
Training loss: 1.9322290401814954
Validation loss: 2.4867651296387816

Epoch: 232| Step: 0
Training loss: 1.9727114830216206
Validation loss: 2.4965113895876403

Epoch: 5| Step: 1
Training loss: 2.123125146793409
Validation loss: 2.5162652821905045

Epoch: 5| Step: 2
Training loss: 2.2091022328472936
Validation loss: 2.5317375553415764

Epoch: 5| Step: 3
Training loss: 2.7767597770268075
Validation loss: 2.550751826616577

Epoch: 5| Step: 4
Training loss: 2.260322416482356
Validation loss: 2.5624820623312745

Epoch: 5| Step: 5
Training loss: 1.9920596811017708
Validation loss: 2.5605151778023747

Epoch: 5| Step: 6
Training loss: 2.6746114359497133
Validation loss: 2.5562894233641997

Epoch: 5| Step: 7
Training loss: 2.678157981571545
Validation loss: 2.5381349678974168

Epoch: 5| Step: 8
Training loss: 2.1442252741648176
Validation loss: 2.524640759951718

Epoch: 5| Step: 9
Training loss: 2.2691484085713896
Validation loss: 2.5155223722828475

Epoch: 5| Step: 10
Training loss: 3.0729264253795434
Validation loss: 2.502534189876718

Epoch: 5| Step: 11
Training loss: 1.4730487978246698
Validation loss: 2.494724915208071

Epoch: 233| Step: 0
Training loss: 1.5080703752017939
Validation loss: 2.497553418981636

Epoch: 5| Step: 1
Training loss: 2.2960067457372477
Validation loss: 2.502328388422226

Epoch: 5| Step: 2
Training loss: 2.5113002019016055
Validation loss: 2.488469051378391

Epoch: 5| Step: 3
Training loss: 3.0184355767505875
Validation loss: 2.4907375091706143

Epoch: 5| Step: 4
Training loss: 2.3473320608629447
Validation loss: 2.4969484619995908

Epoch: 5| Step: 5
Training loss: 2.0681602951362774
Validation loss: 2.491756278332889

Epoch: 5| Step: 6
Training loss: 2.4206864917055015
Validation loss: 2.4989264805936755

Epoch: 5| Step: 7
Training loss: 2.9954889077388884
Validation loss: 2.5052463716301068

Epoch: 5| Step: 8
Training loss: 2.067041887040696
Validation loss: 2.512869876155447

Epoch: 5| Step: 9
Training loss: 2.0490211708609736
Validation loss: 2.524555360244863

Epoch: 5| Step: 10
Training loss: 2.642447931503898
Validation loss: 2.5183588498849048

Epoch: 5| Step: 11
Training loss: 2.587962944891615
Validation loss: 2.5284576987704153

Epoch: 234| Step: 0
Training loss: 1.7220797103793268
Validation loss: 2.5437002658277934

Epoch: 5| Step: 1
Training loss: 3.076467929702072
Validation loss: 2.5381719347896015

Epoch: 5| Step: 2
Training loss: 3.1755486622527846
Validation loss: 2.5646518456929273

Epoch: 5| Step: 3
Training loss: 1.6087807604524695
Validation loss: 2.5388732644012375

Epoch: 5| Step: 4
Training loss: 2.2771915234419864
Validation loss: 2.5342332347977514

Epoch: 5| Step: 5
Training loss: 2.4722991733742976
Validation loss: 2.5253538447172783

Epoch: 5| Step: 6
Training loss: 2.7513582170028394
Validation loss: 2.5352144435479054

Epoch: 5| Step: 7
Training loss: 2.4503020548004937
Validation loss: 2.5139065277038126

Epoch: 5| Step: 8
Training loss: 1.9461248455832831
Validation loss: 2.525244912931981

Epoch: 5| Step: 9
Training loss: 2.0912888138766617
Validation loss: 2.5104008010637275

Epoch: 5| Step: 10
Training loss: 2.204249642822818
Validation loss: 2.5057697671600714

Epoch: 5| Step: 11
Training loss: 1.0420865674879385
Validation loss: 2.513922579301293

Epoch: 235| Step: 0
Training loss: 2.028319254596197
Validation loss: 2.523533593898162

Epoch: 5| Step: 1
Training loss: 2.9305207148485146
Validation loss: 2.525595565941567

Epoch: 5| Step: 2
Training loss: 1.81461270290685
Validation loss: 2.545233144629571

Epoch: 5| Step: 3
Training loss: 2.7387001054642104
Validation loss: 2.5699201553028956

Epoch: 5| Step: 4
Training loss: 2.328961215799019
Validation loss: 2.5731245811461445

Epoch: 5| Step: 5
Training loss: 1.7302487063381704
Validation loss: 2.5609247126249364

Epoch: 5| Step: 6
Training loss: 2.485086399165212
Validation loss: 2.563233681450255

Epoch: 5| Step: 7
Training loss: 2.040533127403415
Validation loss: 2.548022337464024

Epoch: 5| Step: 8
Training loss: 2.7246312513122652
Validation loss: 2.5406104470211948

Epoch: 5| Step: 9
Training loss: 2.9413062252145457
Validation loss: 2.5242035080089353

Epoch: 5| Step: 10
Training loss: 2.0157171420542217
Validation loss: 2.517491696504084

Epoch: 5| Step: 11
Training loss: 2.3334373950460128
Validation loss: 2.5113790904364275

Epoch: 236| Step: 0
Training loss: 1.8724653277987804
Validation loss: 2.5151731231351615

Epoch: 5| Step: 1
Training loss: 2.0169972324834626
Validation loss: 2.514235892914328

Epoch: 5| Step: 2
Training loss: 2.188674175663613
Validation loss: 2.495336542111232

Epoch: 5| Step: 3
Training loss: 3.051768906229836
Validation loss: 2.4995830863774042

Epoch: 5| Step: 4
Training loss: 2.7532179817839535
Validation loss: 2.4999174322957503

Epoch: 5| Step: 5
Training loss: 2.474178960231494
Validation loss: 2.505895561339544

Epoch: 5| Step: 6
Training loss: 2.4719159071053647
Validation loss: 2.515467589450932

Epoch: 5| Step: 7
Training loss: 2.5828928930898534
Validation loss: 2.5430952549499004

Epoch: 5| Step: 8
Training loss: 2.442272307326176
Validation loss: 2.548275155097131

Epoch: 5| Step: 9
Training loss: 1.828712955707193
Validation loss: 2.5540373010736896

Epoch: 5| Step: 10
Training loss: 2.253845531366392
Validation loss: 2.570224138188464

Epoch: 5| Step: 11
Training loss: 1.4236024696067147
Validation loss: 2.577778590655975

Epoch: 237| Step: 0
Training loss: 2.4144648244463554
Validation loss: 2.562417261602229

Epoch: 5| Step: 1
Training loss: 1.8589641213240553
Validation loss: 2.5442158326393067

Epoch: 5| Step: 2
Training loss: 2.479749103590977
Validation loss: 2.5428057538760687

Epoch: 5| Step: 3
Training loss: 2.2819891999212287
Validation loss: 2.5167439501519064

Epoch: 5| Step: 4
Training loss: 2.184054576855587
Validation loss: 2.5270360477318388

Epoch: 5| Step: 5
Training loss: 2.151569538755961
Validation loss: 2.521749945891832

Epoch: 5| Step: 6
Training loss: 1.9135748417165355
Validation loss: 2.519742782347779

Epoch: 5| Step: 7
Training loss: 2.527553826729587
Validation loss: 2.520903441870283

Epoch: 5| Step: 8
Training loss: 2.6607149184492314
Validation loss: 2.509231831230083

Epoch: 5| Step: 9
Training loss: 2.6761036031308545
Validation loss: 2.514602287387498

Epoch: 5| Step: 10
Training loss: 2.5090164669525805
Validation loss: 2.497885664290671

Epoch: 5| Step: 11
Training loss: 2.7967155879958834
Validation loss: 2.4961058447698528

Epoch: 238| Step: 0
Training loss: 2.069049608368748
Validation loss: 2.48915286844995

Epoch: 5| Step: 1
Training loss: 2.560048954763825
Validation loss: 2.495519676517667

Epoch: 5| Step: 2
Training loss: 2.7639456785194154
Validation loss: 2.4951519331033856

Epoch: 5| Step: 3
Training loss: 2.607160713746793
Validation loss: 2.4888182838559025

Epoch: 5| Step: 4
Training loss: 2.6627605758455535
Validation loss: 2.4862011849361356

Epoch: 5| Step: 5
Training loss: 2.605203732305097
Validation loss: 2.482986321995538

Epoch: 5| Step: 6
Training loss: 2.4241328389874037
Validation loss: 2.4770167121772606

Epoch: 5| Step: 7
Training loss: 1.9953188353148923
Validation loss: 2.4862852170267864

Epoch: 5| Step: 8
Training loss: 2.276742636649742
Validation loss: 2.488792376918265

Epoch: 5| Step: 9
Training loss: 2.5277170085472527
Validation loss: 2.4911758976666185

Epoch: 5| Step: 10
Training loss: 1.825628548644475
Validation loss: 2.511643020492839

Epoch: 5| Step: 11
Training loss: 2.5840519141541924
Validation loss: 2.5138875932467677

Epoch: 239| Step: 0
Training loss: 2.467415364368607
Validation loss: 2.5227321508981633

Epoch: 5| Step: 1
Training loss: 2.284899053201058
Validation loss: 2.528768512226252

Epoch: 5| Step: 2
Training loss: 2.3000764917010437
Validation loss: 2.5161395287176473

Epoch: 5| Step: 3
Training loss: 3.1581756458490684
Validation loss: 2.5386977457040283

Epoch: 5| Step: 4
Training loss: 1.6421778278447101
Validation loss: 2.5452661210704153

Epoch: 5| Step: 5
Training loss: 2.6373688073094828
Validation loss: 2.5209678359180887

Epoch: 5| Step: 6
Training loss: 1.7327810988061951
Validation loss: 2.516333150606262

Epoch: 5| Step: 7
Training loss: 2.3082786383730594
Validation loss: 2.5075561970808966

Epoch: 5| Step: 8
Training loss: 2.397472174903654
Validation loss: 2.5028375655044885

Epoch: 5| Step: 9
Training loss: 2.1960337258478146
Validation loss: 2.507944719546712

Epoch: 5| Step: 10
Training loss: 2.6646091649819326
Validation loss: 2.5030844535512284

Epoch: 5| Step: 11
Training loss: 2.2258683042684213
Validation loss: 2.499990495027911

Epoch: 240| Step: 0
Training loss: 2.0485428865211146
Validation loss: 2.5011439606892556

Epoch: 5| Step: 1
Training loss: 2.0699059429084676
Validation loss: 2.5110222348576148

Epoch: 5| Step: 2
Training loss: 2.3790308225991335
Validation loss: 2.5163335907915707

Epoch: 5| Step: 3
Training loss: 2.136166795926079
Validation loss: 2.521942557998187

Epoch: 5| Step: 4
Training loss: 2.313794572711033
Validation loss: 2.542422140649113

Epoch: 5| Step: 5
Training loss: 3.081907939498905
Validation loss: 2.5565558590204516

Epoch: 5| Step: 6
Training loss: 2.1912871139699677
Validation loss: 2.569565360056572

Epoch: 5| Step: 7
Training loss: 2.29142269801035
Validation loss: 2.5911464953142147

Epoch: 5| Step: 8
Training loss: 2.579587949036901
Validation loss: 2.598654837588469

Epoch: 5| Step: 9
Training loss: 2.6256100990110487
Validation loss: 2.575220980930391

Epoch: 5| Step: 10
Training loss: 2.5076933740385847
Validation loss: 2.5335599147542127

Epoch: 5| Step: 11
Training loss: 1.922436019765431
Validation loss: 2.522603463047598

Epoch: 241| Step: 0
Training loss: 2.5229370754769938
Validation loss: 2.4997178673492257

Epoch: 5| Step: 1
Training loss: 2.4128317056421893
Validation loss: 2.494283558039143

Epoch: 5| Step: 2
Training loss: 2.798410516264814
Validation loss: 2.500410097977343

Epoch: 5| Step: 3
Training loss: 2.2151578381103456
Validation loss: 2.4985807602401815

Epoch: 5| Step: 4
Training loss: 2.1790899736124123
Validation loss: 2.4996643914023595

Epoch: 5| Step: 5
Training loss: 2.639970777378761
Validation loss: 2.500081156367055

Epoch: 5| Step: 6
Training loss: 2.037172691407255
Validation loss: 2.509134255242878

Epoch: 5| Step: 7
Training loss: 2.311749104425903
Validation loss: 2.509320159445875

Epoch: 5| Step: 8
Training loss: 2.515534298606282
Validation loss: 2.5086420257906528

Epoch: 5| Step: 9
Training loss: 2.7712588927556894
Validation loss: 2.503554344740877

Epoch: 5| Step: 10
Training loss: 2.643727663635696
Validation loss: 2.497794485776096

Epoch: 5| Step: 11
Training loss: 2.859101996391357
Validation loss: 2.49385829155012

Epoch: 242| Step: 0
Training loss: 2.641768710053822
Validation loss: 2.4802941408551673

Epoch: 5| Step: 1
Training loss: 2.848433442146897
Validation loss: 2.4843586935151967

Epoch: 5| Step: 2
Training loss: 2.2562062182629967
Validation loss: 2.4804389170857615

Epoch: 5| Step: 3
Training loss: 2.3312903270352714
Validation loss: 2.5007108651238577

Epoch: 5| Step: 4
Training loss: 1.8073727665568218
Validation loss: 2.506551554288619

Epoch: 5| Step: 5
Training loss: 2.5989428094821996
Validation loss: 2.535136637638761

Epoch: 5| Step: 6
Training loss: 2.2259017231540428
Validation loss: 2.561701277952184

Epoch: 5| Step: 7
Training loss: 1.8768533447926872
Validation loss: 2.5806012293530074

Epoch: 5| Step: 8
Training loss: 2.621235827988427
Validation loss: 2.5914805644967016

Epoch: 5| Step: 9
Training loss: 2.629514445312885
Validation loss: 2.603118354877418

Epoch: 5| Step: 10
Training loss: 2.3254195501321826
Validation loss: 2.56346157299685

Epoch: 5| Step: 11
Training loss: 1.5408222188320062
Validation loss: 2.525354041404707

Epoch: 243| Step: 0
Training loss: 1.6261096246933617
Validation loss: 2.511432423742103

Epoch: 5| Step: 1
Training loss: 2.010177940729018
Validation loss: 2.501873135187612

Epoch: 5| Step: 2
Training loss: 2.3976201457129656
Validation loss: 2.489158866854353

Epoch: 5| Step: 3
Training loss: 3.0015987268949464
Validation loss: 2.477128033492685

Epoch: 5| Step: 4
Training loss: 1.9991846210627042
Validation loss: 2.475378782494732

Epoch: 5| Step: 5
Training loss: 2.3192401296001153
Validation loss: 2.484678983584601

Epoch: 5| Step: 6
Training loss: 2.3851757899663806
Validation loss: 2.4912189247744014

Epoch: 5| Step: 7
Training loss: 2.140979375534104
Validation loss: 2.4773199565686785

Epoch: 5| Step: 8
Training loss: 2.4874207642170347
Validation loss: 2.479223167886875

Epoch: 5| Step: 9
Training loss: 3.0680073633913807
Validation loss: 2.487317316257631

Epoch: 5| Step: 10
Training loss: 2.4433335166434946
Validation loss: 2.4829469791208716

Epoch: 5| Step: 11
Training loss: 2.0875660685974173
Validation loss: 2.4889720355123663

Epoch: 244| Step: 0
Training loss: 2.161133695068731
Validation loss: 2.5007745238411014

Epoch: 5| Step: 1
Training loss: 2.70766337006618
Validation loss: 2.5111309053781143

Epoch: 5| Step: 2
Training loss: 2.868725605779912
Validation loss: 2.5063710254040736

Epoch: 5| Step: 3
Training loss: 1.909322420136113
Validation loss: 2.5279716250274786

Epoch: 5| Step: 4
Training loss: 2.5563499337880704
Validation loss: 2.5317894474599045

Epoch: 5| Step: 5
Training loss: 1.9654028155925345
Validation loss: 2.5503411295481673

Epoch: 5| Step: 6
Training loss: 2.303759061368114
Validation loss: 2.5623104444035367

Epoch: 5| Step: 7
Training loss: 2.3825125083314793
Validation loss: 2.5686024017810176

Epoch: 5| Step: 8
Training loss: 2.7671123750764566
Validation loss: 2.565044008637186

Epoch: 5| Step: 9
Training loss: 1.8974160794282577
Validation loss: 2.5676804103197095

Epoch: 5| Step: 10
Training loss: 2.3824508642711826
Validation loss: 2.555472106682596

Epoch: 5| Step: 11
Training loss: 2.6567865166459534
Validation loss: 2.525446223182676

Epoch: 245| Step: 0
Training loss: 2.7083806449474612
Validation loss: 2.5196974982876608

Epoch: 5| Step: 1
Training loss: 2.523504959007849
Validation loss: 2.5139873220750735

Epoch: 5| Step: 2
Training loss: 2.4843428507710046
Validation loss: 2.510539353935483

Epoch: 5| Step: 3
Training loss: 2.7070599619125795
Validation loss: 2.5091707190011387

Epoch: 5| Step: 4
Training loss: 2.240468499372327
Validation loss: 2.5115409974066942

Epoch: 5| Step: 5
Training loss: 1.3645939232024629
Validation loss: 2.51849599855913

Epoch: 5| Step: 6
Training loss: 2.293056089957124
Validation loss: 2.51595142371231

Epoch: 5| Step: 7
Training loss: 2.0609068063528335
Validation loss: 2.528978034583621

Epoch: 5| Step: 8
Training loss: 2.5881945392005994
Validation loss: 2.5266763315879883

Epoch: 5| Step: 9
Training loss: 1.675088094415919
Validation loss: 2.5264372243906634

Epoch: 5| Step: 10
Training loss: 2.619819979707426
Validation loss: 2.5306158232889557

Epoch: 5| Step: 11
Training loss: 3.399186396022911
Validation loss: 2.5132396477554657

Epoch: 246| Step: 0
Training loss: 2.536191755277458
Validation loss: 2.536398240042714

Epoch: 5| Step: 1
Training loss: 2.2863086370474766
Validation loss: 2.5387601310468986

Epoch: 5| Step: 2
Training loss: 2.0473843006426082
Validation loss: 2.531893177499261

Epoch: 5| Step: 3
Training loss: 2.7478315300197362
Validation loss: 2.530150842046187

Epoch: 5| Step: 4
Training loss: 2.0511345259332314
Validation loss: 2.5398508696630846

Epoch: 5| Step: 5
Training loss: 2.6098011148612184
Validation loss: 2.5571223175059123

Epoch: 5| Step: 6
Training loss: 2.092947962858115
Validation loss: 2.5399436360773677

Epoch: 5| Step: 7
Training loss: 3.007807426943774
Validation loss: 2.5401388850501125

Epoch: 5| Step: 8
Training loss: 1.7019159767801857
Validation loss: 2.5186020707515744

Epoch: 5| Step: 9
Training loss: 2.168597485898932
Validation loss: 2.528374400370079

Epoch: 5| Step: 10
Training loss: 2.3749227009290603
Validation loss: 2.5152316605344502

Epoch: 5| Step: 11
Training loss: 1.5656057390867057
Validation loss: 2.5217219683270122

Epoch: 247| Step: 0
Training loss: 2.1153226289803913
Validation loss: 2.5108395902182425

Epoch: 5| Step: 1
Training loss: 2.494885362579233
Validation loss: 2.5141206472629727

Epoch: 5| Step: 2
Training loss: 2.5139708204131312
Validation loss: 2.510908087965848

Epoch: 5| Step: 3
Training loss: 2.0464348938681898
Validation loss: 2.5019705794373515

Epoch: 5| Step: 4
Training loss: 2.2541712137436147
Validation loss: 2.49639586290418

Epoch: 5| Step: 5
Training loss: 2.3010128403379557
Validation loss: 2.4972103807144777

Epoch: 5| Step: 6
Training loss: 2.50096779210684
Validation loss: 2.5064898099506356

Epoch: 5| Step: 7
Training loss: 2.396308774351693
Validation loss: 2.510718859031629

Epoch: 5| Step: 8
Training loss: 2.199378541389079
Validation loss: 2.520578096935363

Epoch: 5| Step: 9
Training loss: 2.050838447863068
Validation loss: 2.515044737763018

Epoch: 5| Step: 10
Training loss: 2.474371774492621
Validation loss: 2.5402498999824226

Epoch: 5| Step: 11
Training loss: 3.376438258267082
Validation loss: 2.5627615880419206

Epoch: 248| Step: 0
Training loss: 2.190490749016553
Validation loss: 2.5687591783061032

Epoch: 5| Step: 1
Training loss: 2.7156974054128553
Validation loss: 2.5857224158879566

Epoch: 5| Step: 2
Training loss: 2.261098298930309
Validation loss: 2.5919655460148547

Epoch: 5| Step: 3
Training loss: 2.4904606017033224
Validation loss: 2.602756608050018

Epoch: 5| Step: 4
Training loss: 2.4045396150818656
Validation loss: 2.5843049549972186

Epoch: 5| Step: 5
Training loss: 2.0769935912472803
Validation loss: 2.550012828133922

Epoch: 5| Step: 6
Training loss: 2.5415002945609544
Validation loss: 2.537705975583553

Epoch: 5| Step: 7
Training loss: 2.1931122855521545
Validation loss: 2.5246354557551216

Epoch: 5| Step: 8
Training loss: 1.7602775413418448
Validation loss: 2.522856390527288

Epoch: 5| Step: 9
Training loss: 3.1228780026849146
Validation loss: 2.515227351539499

Epoch: 5| Step: 10
Training loss: 2.110845434749275
Validation loss: 2.510015745848145

Epoch: 5| Step: 11
Training loss: 2.5200751139027413
Validation loss: 2.5080924665145736

Epoch: 249| Step: 0
Training loss: 2.4407684713827313
Validation loss: 2.50052428311189

Epoch: 5| Step: 1
Training loss: 2.0562132765438643
Validation loss: 2.50026681986152

Epoch: 5| Step: 2
Training loss: 2.4401775228302602
Validation loss: 2.501430372489241

Epoch: 5| Step: 3
Training loss: 2.517941752734963
Validation loss: 2.507753211060344

Epoch: 5| Step: 4
Training loss: 2.7870019305235845
Validation loss: 2.501056662412209

Epoch: 5| Step: 5
Training loss: 2.5057111355826533
Validation loss: 2.505786362474087

Epoch: 5| Step: 6
Training loss: 2.428791825527764
Validation loss: 2.498163927888558

Epoch: 5| Step: 7
Training loss: 2.3246450337806532
Validation loss: 2.507586366989096

Epoch: 5| Step: 8
Training loss: 1.9772116458311382
Validation loss: 2.510327746503566

Epoch: 5| Step: 9
Training loss: 2.786207516989406
Validation loss: 2.512901166263931

Epoch: 5| Step: 10
Training loss: 2.05607146441722
Validation loss: 2.504892834301904

Epoch: 5| Step: 11
Training loss: 2.0280535857289705
Validation loss: 2.5188333377666074

Epoch: 250| Step: 0
Training loss: 1.6014006742271851
Validation loss: 2.519058005666468

Epoch: 5| Step: 1
Training loss: 2.2054567375220815
Validation loss: 2.5268296353160635

Epoch: 5| Step: 2
Training loss: 2.6991040085337685
Validation loss: 2.5145064724350696

Epoch: 5| Step: 3
Training loss: 2.6262336738438465
Validation loss: 2.5066700528655446

Epoch: 5| Step: 4
Training loss: 2.1385423316217484
Validation loss: 2.5048150621637406

Epoch: 5| Step: 5
Training loss: 2.8933920323735824
Validation loss: 2.506649611270065

Epoch: 5| Step: 6
Training loss: 2.2880699948428256
Validation loss: 2.505895668375487

Epoch: 5| Step: 7
Training loss: 2.9825807940019033
Validation loss: 2.499114952781949

Epoch: 5| Step: 8
Training loss: 2.542948029839501
Validation loss: 2.507107141316301

Epoch: 5| Step: 9
Training loss: 1.9175836677649891
Validation loss: 2.5028016008874934

Epoch: 5| Step: 10
Training loss: 1.6133007574864786
Validation loss: 2.509095629211534

Epoch: 5| Step: 11
Training loss: 2.4403376567656205
Validation loss: 2.5134779018677467

Epoch: 251| Step: 0
Training loss: 2.4897242124485865
Validation loss: 2.5338988239761076

Epoch: 5| Step: 1
Training loss: 1.8860581783694303
Validation loss: 2.532040515738717

Epoch: 5| Step: 2
Training loss: 2.705371694781974
Validation loss: 2.5173272243864417

Epoch: 5| Step: 3
Training loss: 2.602482172074025
Validation loss: 2.535011706666921

Epoch: 5| Step: 4
Training loss: 2.0488448819619793
Validation loss: 2.528601351712426

Epoch: 5| Step: 5
Training loss: 1.8777340347165934
Validation loss: 2.5490538827197766

Epoch: 5| Step: 6
Training loss: 2.6184814898142776
Validation loss: 2.5421698624542817

Epoch: 5| Step: 7
Training loss: 2.055481499835742
Validation loss: 2.558949977158506

Epoch: 5| Step: 8
Training loss: 2.3138138415299565
Validation loss: 2.558485817998719

Epoch: 5| Step: 9
Training loss: 2.0063988128327015
Validation loss: 2.5426334447171466

Epoch: 5| Step: 10
Training loss: 2.877969617925822
Validation loss: 2.548540054743214

Epoch: 5| Step: 11
Training loss: 2.272084570956131
Validation loss: 2.5504767297960615

Epoch: 252| Step: 0
Training loss: 3.087922126855442
Validation loss: 2.534024907495526

Epoch: 5| Step: 1
Training loss: 2.191637540365058
Validation loss: 2.5273248356342806

Epoch: 5| Step: 2
Training loss: 2.6460373166567654
Validation loss: 2.512940419677857

Epoch: 5| Step: 3
Training loss: 2.3257080435643993
Validation loss: 2.5157481019285446

Epoch: 5| Step: 4
Training loss: 2.3129692632510577
Validation loss: 2.508310916130884

Epoch: 5| Step: 5
Training loss: 2.021268175146028
Validation loss: 2.51463849013253

Epoch: 5| Step: 6
Training loss: 1.9905934257937643
Validation loss: 2.5174972209454185

Epoch: 5| Step: 7
Training loss: 2.2654877719755415
Validation loss: 2.516817836821212

Epoch: 5| Step: 8
Training loss: 2.2318141106616247
Validation loss: 2.5256567330724113

Epoch: 5| Step: 9
Training loss: 2.1854665842043497
Validation loss: 2.522520010710967

Epoch: 5| Step: 10
Training loss: 1.9631482311138504
Validation loss: 2.525425197977336

Epoch: 5| Step: 11
Training loss: 3.5441163211789304
Validation loss: 2.5284827455099497

Epoch: 253| Step: 0
Training loss: 2.2070738121587357
Validation loss: 2.550621670321418

Epoch: 5| Step: 1
Training loss: 2.476374381348491
Validation loss: 2.5608811110626273

Epoch: 5| Step: 2
Training loss: 2.3708863018356006
Validation loss: 2.555423517778303

Epoch: 5| Step: 3
Training loss: 1.8474690058151204
Validation loss: 2.5682093432642663

Epoch: 5| Step: 4
Training loss: 2.345770511723313
Validation loss: 2.5562703267838343

Epoch: 5| Step: 5
Training loss: 2.6409281720263134
Validation loss: 2.5674462149167163

Epoch: 5| Step: 6
Training loss: 2.293407079856419
Validation loss: 2.544705002805853

Epoch: 5| Step: 7
Training loss: 2.939410460913387
Validation loss: 2.5179151452986974

Epoch: 5| Step: 8
Training loss: 2.030048895561775
Validation loss: 2.5136093926240903

Epoch: 5| Step: 9
Training loss: 2.308046537501985
Validation loss: 2.5125877316816725

Epoch: 5| Step: 10
Training loss: 2.1632381480377356
Validation loss: 2.5203832757909157

Epoch: 5| Step: 11
Training loss: 2.292012055696534
Validation loss: 2.524804944508342

Epoch: 254| Step: 0
Training loss: 2.2785120170900846
Validation loss: 2.5203716049626794

Epoch: 5| Step: 1
Training loss: 2.2150321221013742
Validation loss: 2.521734145027067

Epoch: 5| Step: 2
Training loss: 2.038308775289365
Validation loss: 2.5282971187199093

Epoch: 5| Step: 3
Training loss: 2.4359341017605787
Validation loss: 2.5107452697220625

Epoch: 5| Step: 4
Training loss: 2.74311330442093
Validation loss: 2.5060053024953874

Epoch: 5| Step: 5
Training loss: 1.9576953362724971
Validation loss: 2.5033657107458405

Epoch: 5| Step: 6
Training loss: 2.1993571859528838
Validation loss: 2.5170420195966225

Epoch: 5| Step: 7
Training loss: 2.6727688727447116
Validation loss: 2.5138098484479086

Epoch: 5| Step: 8
Training loss: 1.8593336469395372
Validation loss: 2.51069335810885

Epoch: 5| Step: 9
Training loss: 3.069470938160184
Validation loss: 2.5245999511908024

Epoch: 5| Step: 10
Training loss: 2.2530801670730254
Validation loss: 2.52811657676661

Epoch: 5| Step: 11
Training loss: 1.512381711385465
Validation loss: 2.556042373171677

Epoch: 255| Step: 0
Training loss: 2.2040474766292673
Validation loss: 2.5620492445689593

Epoch: 5| Step: 1
Training loss: 2.7147993125297516
Validation loss: 2.569226465487196

Epoch: 5| Step: 2
Training loss: 2.0875433409069126
Validation loss: 2.574963174019595

Epoch: 5| Step: 3
Training loss: 2.59616693238006
Validation loss: 2.5978178275200667

Epoch: 5| Step: 4
Training loss: 1.9596476169007853
Validation loss: 2.5935607902423836

Epoch: 5| Step: 5
Training loss: 2.7545500307191046
Validation loss: 2.579768934067828

Epoch: 5| Step: 6
Training loss: 2.3072507924979506
Validation loss: 2.5669427598323176

Epoch: 5| Step: 7
Training loss: 2.5547561869588824
Validation loss: 2.535927230616734

Epoch: 5| Step: 8
Training loss: 2.336517772238806
Validation loss: 2.531665442169057

Epoch: 5| Step: 9
Training loss: 2.2743543106819524
Validation loss: 2.516196126849122

Epoch: 5| Step: 10
Training loss: 1.587825909899352
Validation loss: 2.496063980458318

Epoch: 5| Step: 11
Training loss: 2.9676469861901627
Validation loss: 2.507497318066082

Epoch: 256| Step: 0
Training loss: 1.9834666538575136
Validation loss: 2.512887752876635

Epoch: 5| Step: 1
Training loss: 1.6444316480470926
Validation loss: 2.516301243875028

Epoch: 5| Step: 2
Training loss: 2.995386868361064
Validation loss: 2.5185109401303953

Epoch: 5| Step: 3
Training loss: 2.2274009865826354
Validation loss: 2.5181575647935666

Epoch: 5| Step: 4
Training loss: 2.5207420101385316
Validation loss: 2.524111609476096

Epoch: 5| Step: 5
Training loss: 2.515954227109984
Validation loss: 2.532590875925063

Epoch: 5| Step: 6
Training loss: 2.1958461126526285
Validation loss: 2.5330952249065404

Epoch: 5| Step: 7
Training loss: 2.5950950903549987
Validation loss: 2.534922988262295

Epoch: 5| Step: 8
Training loss: 2.313722029835835
Validation loss: 2.530373735598115

Epoch: 5| Step: 9
Training loss: 2.3891212870298997
Validation loss: 2.5497250982218618

Epoch: 5| Step: 10
Training loss: 1.88714481068598
Validation loss: 2.5594334590633703

Epoch: 5| Step: 11
Training loss: 2.3795357608821295
Validation loss: 2.558447467223386

Epoch: 257| Step: 0
Training loss: 1.859490014373809
Validation loss: 2.6104745927448723

Epoch: 5| Step: 1
Training loss: 2.47278487366635
Validation loss: 2.6229299565151014

Epoch: 5| Step: 2
Training loss: 2.3391235465911246
Validation loss: 2.6556837899600207

Epoch: 5| Step: 3
Training loss: 2.213518772380838
Validation loss: 2.6616673894446086

Epoch: 5| Step: 4
Training loss: 2.6701763620600785
Validation loss: 2.6598612976122844

Epoch: 5| Step: 5
Training loss: 1.9983515502485385
Validation loss: 2.60752156384952

Epoch: 5| Step: 6
Training loss: 2.3191047376542104
Validation loss: 2.5913946610533656

Epoch: 5| Step: 7
Training loss: 2.1046984790495817
Validation loss: 2.590048270303487

Epoch: 5| Step: 8
Training loss: 2.401043597459879
Validation loss: 2.557703452484063

Epoch: 5| Step: 9
Training loss: 2.2906654135767597
Validation loss: 2.535059472006536

Epoch: 5| Step: 10
Training loss: 3.1382005737662024
Validation loss: 2.530349492773201

Epoch: 5| Step: 11
Training loss: 2.580135879043465
Validation loss: 2.511447106716949

Epoch: 258| Step: 0
Training loss: 2.366962082204992
Validation loss: 2.494750019885943

Epoch: 5| Step: 1
Training loss: 2.466378630325486
Validation loss: 2.5021067365451266

Epoch: 5| Step: 2
Training loss: 2.213281581783034
Validation loss: 2.495828000499736

Epoch: 5| Step: 3
Training loss: 2.7632330771904483
Validation loss: 2.4980285341624966

Epoch: 5| Step: 4
Training loss: 2.159090134287426
Validation loss: 2.5027945952486106

Epoch: 5| Step: 5
Training loss: 2.17140620818848
Validation loss: 2.494009358519795

Epoch: 5| Step: 6
Training loss: 3.226669051140569
Validation loss: 2.4882024316366445

Epoch: 5| Step: 7
Training loss: 2.482371163919486
Validation loss: 2.4966106964003614

Epoch: 5| Step: 8
Training loss: 2.313258278734941
Validation loss: 2.4950784519719824

Epoch: 5| Step: 9
Training loss: 2.0368795000034194
Validation loss: 2.4967500224881376

Epoch: 5| Step: 10
Training loss: 1.964470587118216
Validation loss: 2.502622952954732

Epoch: 5| Step: 11
Training loss: 1.3061790392277797
Validation loss: 2.512576682943357

Epoch: 259| Step: 0
Training loss: 2.2565514233725015
Validation loss: 2.527768719893309

Epoch: 5| Step: 1
Training loss: 2.0275297869694393
Validation loss: 2.547433167904595

Epoch: 5| Step: 2
Training loss: 3.0218834641189147
Validation loss: 2.546909185776892

Epoch: 5| Step: 3
Training loss: 2.3251325590019922
Validation loss: 2.569697065793696

Epoch: 5| Step: 4
Training loss: 2.5480757615041094
Validation loss: 2.5836405661122623

Epoch: 5| Step: 5
Training loss: 2.8431204633494183
Validation loss: 2.582342574394991

Epoch: 5| Step: 6
Training loss: 1.8004452605015855
Validation loss: 2.578807439936359

Epoch: 5| Step: 7
Training loss: 2.55486611957986
Validation loss: 2.5838049963068768

Epoch: 5| Step: 8
Training loss: 2.142976680327903
Validation loss: 2.5398765745675154

Epoch: 5| Step: 9
Training loss: 2.553013057425817
Validation loss: 2.5110739972516565

Epoch: 5| Step: 10
Training loss: 2.0195069302361834
Validation loss: 2.500686467813698

Epoch: 5| Step: 11
Training loss: 1.9691558903891526
Validation loss: 2.516678003312992

Epoch: 260| Step: 0
Training loss: 3.145430802282225
Validation loss: 2.5016610508380692

Epoch: 5| Step: 1
Training loss: 2.8942225159026074
Validation loss: 2.5128907099160016

Epoch: 5| Step: 2
Training loss: 2.074238750124269
Validation loss: 2.511556427309774

Epoch: 5| Step: 3
Training loss: 2.389367165359317
Validation loss: 2.5116973132478897

Epoch: 5| Step: 4
Training loss: 2.3852988356982645
Validation loss: 2.512928795323245

Epoch: 5| Step: 5
Training loss: 2.114329080063288
Validation loss: 2.5149636475367076

Epoch: 5| Step: 6
Training loss: 2.2883677811702805
Validation loss: 2.5116719745336473

Epoch: 5| Step: 7
Training loss: 2.441603605304471
Validation loss: 2.510141505334526

Epoch: 5| Step: 8
Training loss: 1.9394975639853111
Validation loss: 2.5037431033936652

Epoch: 5| Step: 9
Training loss: 2.3923088576158076
Validation loss: 2.5005070648947876

Epoch: 5| Step: 10
Training loss: 2.363288211024097
Validation loss: 2.5102369605571253

Epoch: 5| Step: 11
Training loss: 3.254248996007395
Validation loss: 2.5109624599125384

Epoch: 261| Step: 0
Training loss: 2.615908911096169
Validation loss: 2.517920250602603

Epoch: 5| Step: 1
Training loss: 2.6207835529817394
Validation loss: 2.5350785167593117

Epoch: 5| Step: 2
Training loss: 2.2147691502193694
Validation loss: 2.550335621719055

Epoch: 5| Step: 3
Training loss: 2.2440341695132164
Validation loss: 2.559286428556156

Epoch: 5| Step: 4
Training loss: 2.6809634182236644
Validation loss: 2.598361796692583

Epoch: 5| Step: 5
Training loss: 2.1147567477472045
Validation loss: 2.6147853284421676

Epoch: 5| Step: 6
Training loss: 2.2987266913555193
Validation loss: 2.633073908867566

Epoch: 5| Step: 7
Training loss: 2.2351459160265525
Validation loss: 2.648106155748613

Epoch: 5| Step: 8
Training loss: 2.6215708905198416
Validation loss: 2.6556997589460174

Epoch: 5| Step: 9
Training loss: 1.958963745860506
Validation loss: 2.6402813313479396

Epoch: 5| Step: 10
Training loss: 2.2272554089044525
Validation loss: 2.6027362264509892

Epoch: 5| Step: 11
Training loss: 2.207049074354185
Validation loss: 2.577513146285218

Epoch: 262| Step: 0
Training loss: 1.7562833789626489
Validation loss: 2.5591589072964975

Epoch: 5| Step: 1
Training loss: 2.673349163439805
Validation loss: 2.529250493354645

Epoch: 5| Step: 2
Training loss: 2.3978209060209386
Validation loss: 2.517427237215846

Epoch: 5| Step: 3
Training loss: 1.9522756942482635
Validation loss: 2.503954648379825

Epoch: 5| Step: 4
Training loss: 3.0186693705972396
Validation loss: 2.493098213151991

Epoch: 5| Step: 5
Training loss: 2.1986005059754463
Validation loss: 2.4907003607490856

Epoch: 5| Step: 6
Training loss: 2.008139260862061
Validation loss: 2.4981539188582076

Epoch: 5| Step: 7
Training loss: 2.5028965382607793
Validation loss: 2.4933824056328384

Epoch: 5| Step: 8
Training loss: 1.9949161766244246
Validation loss: 2.499021020579787

Epoch: 5| Step: 9
Training loss: 2.1822254349908703
Validation loss: 2.5067683826156886

Epoch: 5| Step: 10
Training loss: 2.674454364209686
Validation loss: 2.4933608271703007

Epoch: 5| Step: 11
Training loss: 2.5859603650329763
Validation loss: 2.51330675992232

Epoch: 263| Step: 0
Training loss: 2.10738171246629
Validation loss: 2.5224565089225415

Epoch: 5| Step: 1
Training loss: 2.681340633541105
Validation loss: 2.5299041765207666

Epoch: 5| Step: 2
Training loss: 2.697229295357482
Validation loss: 2.536172315436528

Epoch: 5| Step: 3
Training loss: 1.6838372357602123
Validation loss: 2.5583294836340484

Epoch: 5| Step: 4
Training loss: 2.69362802251453
Validation loss: 2.5575840518062907

Epoch: 5| Step: 5
Training loss: 2.1860597501303887
Validation loss: 2.5538646352696817

Epoch: 5| Step: 6
Training loss: 2.2062147402444805
Validation loss: 2.5699610523013705

Epoch: 5| Step: 7
Training loss: 1.8786057451999973
Validation loss: 2.5488312663988264

Epoch: 5| Step: 8
Training loss: 2.7231486899987294
Validation loss: 2.5583429694123683

Epoch: 5| Step: 9
Training loss: 2.6172099098270984
Validation loss: 2.5665877813647513

Epoch: 5| Step: 10
Training loss: 2.0523695254005125
Validation loss: 2.5671701286348876

Epoch: 5| Step: 11
Training loss: 1.893936284033794
Validation loss: 2.5461157308641966

Epoch: 264| Step: 0
Training loss: 2.5162460792537487
Validation loss: 2.5514086545157713

Epoch: 5| Step: 1
Training loss: 2.822459579191857
Validation loss: 2.5613178612311076

Epoch: 5| Step: 2
Training loss: 2.2925279443799456
Validation loss: 2.551710566071014

Epoch: 5| Step: 3
Training loss: 2.0760698984245525
Validation loss: 2.543287316841798

Epoch: 5| Step: 4
Training loss: 2.0570349682036517
Validation loss: 2.539635778411856

Epoch: 5| Step: 5
Training loss: 2.056726872301253
Validation loss: 2.546418283619828

Epoch: 5| Step: 6
Training loss: 2.4756911035354374
Validation loss: 2.5567268957353213

Epoch: 5| Step: 7
Training loss: 2.126252870910967
Validation loss: 2.5466638957336425

Epoch: 5| Step: 8
Training loss: 1.4949031704065656
Validation loss: 2.543921007661407

Epoch: 5| Step: 9
Training loss: 2.254248317102331
Validation loss: 2.5413800114394034

Epoch: 5| Step: 10
Training loss: 3.09464089253069
Validation loss: 2.5591195301554013

Epoch: 5| Step: 11
Training loss: 1.4811622786803351
Validation loss: 2.5570849874436306

Epoch: 265| Step: 0
Training loss: 1.8453887510251812
Validation loss: 2.556307843617904

Epoch: 5| Step: 1
Training loss: 2.4721981064076237
Validation loss: 2.5648714079359585

Epoch: 5| Step: 2
Training loss: 1.785277514856923
Validation loss: 2.5725292475267003

Epoch: 5| Step: 3
Training loss: 2.480720375094045
Validation loss: 2.5550087581927343

Epoch: 5| Step: 4
Training loss: 2.077519378755347
Validation loss: 2.5742146053483443

Epoch: 5| Step: 5
Training loss: 2.1840110202692924
Validation loss: 2.536039409207647

Epoch: 5| Step: 6
Training loss: 2.518123357549318
Validation loss: 2.545572751460676

Epoch: 5| Step: 7
Training loss: 2.1262131762133176
Validation loss: 2.534033790852586

Epoch: 5| Step: 8
Training loss: 2.5457908335466537
Validation loss: 2.5412416428470626

Epoch: 5| Step: 9
Training loss: 2.7752417484865575
Validation loss: 2.5481127986034164

Epoch: 5| Step: 10
Training loss: 2.5040781137695403
Validation loss: 2.54478577186213

Epoch: 5| Step: 11
Training loss: 1.735425201553783
Validation loss: 2.553880247067537

Epoch: 266| Step: 0
Training loss: 2.7647984018349887
Validation loss: 2.5556463839335293

Epoch: 5| Step: 1
Training loss: 2.2954177905006263
Validation loss: 2.5782650032947165

Epoch: 5| Step: 2
Training loss: 2.0298084719275216
Validation loss: 2.5808299834379835

Epoch: 5| Step: 3
Training loss: 1.8741451858006404
Validation loss: 2.563609495561211

Epoch: 5| Step: 4
Training loss: 2.0689100589663836
Validation loss: 2.5539788518329782

Epoch: 5| Step: 5
Training loss: 2.2336258065697607
Validation loss: 2.558558557477038

Epoch: 5| Step: 6
Training loss: 2.130585230632136
Validation loss: 2.5370289019165213

Epoch: 5| Step: 7
Training loss: 2.3666142439968785
Validation loss: 2.520578983705659

Epoch: 5| Step: 8
Training loss: 2.582892985396652
Validation loss: 2.5324452878634776

Epoch: 5| Step: 9
Training loss: 1.9968400668579476
Validation loss: 2.534027145978991

Epoch: 5| Step: 10
Training loss: 2.7124261204375295
Validation loss: 2.5144683990717844

Epoch: 5| Step: 11
Training loss: 2.5994017279485138
Validation loss: 2.522694308002823

Epoch: 267| Step: 0
Training loss: 2.337062603015289
Validation loss: 2.5254360154575113

Epoch: 5| Step: 1
Training loss: 2.1028838701023114
Validation loss: 2.534971750655016

Epoch: 5| Step: 2
Training loss: 2.580417885020608
Validation loss: 2.5218863862390006

Epoch: 5| Step: 3
Training loss: 1.6572190814504097
Validation loss: 2.541935462235695

Epoch: 5| Step: 4
Training loss: 2.3398142002385964
Validation loss: 2.547533028282115

Epoch: 5| Step: 5
Training loss: 2.1572132999535727
Validation loss: 2.5465694236372576

Epoch: 5| Step: 6
Training loss: 2.548781541420573
Validation loss: 2.5647310221146826

Epoch: 5| Step: 7
Training loss: 2.731046907394339
Validation loss: 2.544928745154132

Epoch: 5| Step: 8
Training loss: 2.201665949776836
Validation loss: 2.5405579647653207

Epoch: 5| Step: 9
Training loss: 2.668958444071016
Validation loss: 2.5216567307831372

Epoch: 5| Step: 10
Training loss: 2.196234675675819
Validation loss: 2.527786255450815

Epoch: 5| Step: 11
Training loss: 1.2647329883958296
Validation loss: 2.516596417020275

Epoch: 268| Step: 0
Training loss: 2.099150454024578
Validation loss: 2.5091068694638325

Epoch: 5| Step: 1
Training loss: 1.7165793149754078
Validation loss: 2.5113381373785924

Epoch: 5| Step: 2
Training loss: 2.266680241525429
Validation loss: 2.51650793562346

Epoch: 5| Step: 3
Training loss: 2.1688929881689454
Validation loss: 2.5132195165228612

Epoch: 5| Step: 4
Training loss: 2.5725204121453618
Validation loss: 2.5205668408372883

Epoch: 5| Step: 5
Training loss: 1.9984148419417735
Validation loss: 2.50429620151236

Epoch: 5| Step: 6
Training loss: 2.6016331568565203
Validation loss: 2.5156522792814

Epoch: 5| Step: 7
Training loss: 2.108672074357531
Validation loss: 2.5281930800341588

Epoch: 5| Step: 8
Training loss: 2.5064278936631736
Validation loss: 2.5341768650634573

Epoch: 5| Step: 9
Training loss: 2.736152986398609
Validation loss: 2.539921139027287

Epoch: 5| Step: 10
Training loss: 2.5765429642343265
Validation loss: 2.565234551125502

Epoch: 5| Step: 11
Training loss: 1.4160028286059732
Validation loss: 2.5644941750364394

Epoch: 269| Step: 0
Training loss: 2.379578243359939
Validation loss: 2.5790217872462082

Epoch: 5| Step: 1
Training loss: 2.366996027186887
Validation loss: 2.5897000072974037

Epoch: 5| Step: 2
Training loss: 2.422589202907691
Validation loss: 2.6042730932741005

Epoch: 5| Step: 3
Training loss: 2.3323887434385373
Validation loss: 2.6036822567858295

Epoch: 5| Step: 4
Training loss: 2.1467439392153556
Validation loss: 2.5743046979202706

Epoch: 5| Step: 5
Training loss: 2.4442121571173487
Validation loss: 2.556341481612112

Epoch: 5| Step: 6
Training loss: 2.582413591710027
Validation loss: 2.5409350371428014

Epoch: 5| Step: 7
Training loss: 2.1033712211779427
Validation loss: 2.538961400684676

Epoch: 5| Step: 8
Training loss: 2.3962384309922213
Validation loss: 2.5461049583260924

Epoch: 5| Step: 9
Training loss: 2.3933250787144575
Validation loss: 2.520180686031071

Epoch: 5| Step: 10
Training loss: 2.0815921628196077
Validation loss: 2.53824961243279

Epoch: 5| Step: 11
Training loss: 2.0344906119268065
Validation loss: 2.539083349680271

Epoch: 270| Step: 0
Training loss: 2.437982560343403
Validation loss: 2.5362097848818923

Epoch: 5| Step: 1
Training loss: 2.2163382303626826
Validation loss: 2.5530887543600738

Epoch: 5| Step: 2
Training loss: 2.2859951468321915
Validation loss: 2.5644811399682013

Epoch: 5| Step: 3
Training loss: 1.7005286769092136
Validation loss: 2.592616791192787

Epoch: 5| Step: 4
Training loss: 2.317196793129228
Validation loss: 2.6025222710979676

Epoch: 5| Step: 5
Training loss: 2.6289838804938466
Validation loss: 2.6137199318760365

Epoch: 5| Step: 6
Training loss: 2.4584108976207633
Validation loss: 2.637728824000086

Epoch: 5| Step: 7
Training loss: 2.6584317391417116
Validation loss: 2.6255562359471822

Epoch: 5| Step: 8
Training loss: 1.9648823971293932
Validation loss: 2.6578504042003552

Epoch: 5| Step: 9
Training loss: 2.506776209358576
Validation loss: 2.6262407171178235

Epoch: 5| Step: 10
Training loss: 2.5675507987846315
Validation loss: 2.597201800450249

Epoch: 5| Step: 11
Training loss: 1.3365054345496732
Validation loss: 2.552361645736519

Epoch: 271| Step: 0
Training loss: 2.9579196336208935
Validation loss: 2.5126971588147753

Epoch: 5| Step: 1
Training loss: 2.4448684435441086
Validation loss: 2.5055952084042823

Epoch: 5| Step: 2
Training loss: 2.533196913241709
Validation loss: 2.5078636235525393

Epoch: 5| Step: 3
Training loss: 2.098368774106686
Validation loss: 2.5073872579037273

Epoch: 5| Step: 4
Training loss: 1.6937275874495494
Validation loss: 2.511869363733381

Epoch: 5| Step: 5
Training loss: 2.3960355479830606
Validation loss: 2.517281912657654

Epoch: 5| Step: 6
Training loss: 2.878410306989909
Validation loss: 2.519706353305444

Epoch: 5| Step: 7
Training loss: 2.0936126663944328
Validation loss: 2.509776933498609

Epoch: 5| Step: 8
Training loss: 2.3227202898391193
Validation loss: 2.516140393363322

Epoch: 5| Step: 9
Training loss: 2.390270530999524
Validation loss: 2.532610657054642

Epoch: 5| Step: 10
Training loss: 2.081772206636621
Validation loss: 2.5497764606294098

Epoch: 5| Step: 11
Training loss: 1.3530467708959186
Validation loss: 2.5480775159051703

Epoch: 272| Step: 0
Training loss: 1.9720657522370395
Validation loss: 2.5596909982735534

Epoch: 5| Step: 1
Training loss: 2.1294135093061946
Validation loss: 2.5579699622210725

Epoch: 5| Step: 2
Training loss: 2.138066900378846
Validation loss: 2.5692856659387933

Epoch: 5| Step: 3
Training loss: 2.2578093320830934
Validation loss: 2.5566155199528455

Epoch: 5| Step: 4
Training loss: 2.3424533563324195
Validation loss: 2.541479155914347

Epoch: 5| Step: 5
Training loss: 2.064336941281901
Validation loss: 2.545941757186727

Epoch: 5| Step: 6
Training loss: 2.5692986341006385
Validation loss: 2.5451306647537493

Epoch: 5| Step: 7
Training loss: 2.450722848563001
Validation loss: 2.5607318205181455

Epoch: 5| Step: 8
Training loss: 2.3358936114318696
Validation loss: 2.5396079744161115

Epoch: 5| Step: 9
Training loss: 2.7350593800349006
Validation loss: 2.5401055017973224

Epoch: 5| Step: 10
Training loss: 2.5408455090237814
Validation loss: 2.5196184286170737

Epoch: 5| Step: 11
Training loss: 1.0537641651473049
Validation loss: 2.526298845445895

Epoch: 273| Step: 0
Training loss: 2.7963246065025498
Validation loss: 2.5186876013183475

Epoch: 5| Step: 1
Training loss: 2.067260565587395
Validation loss: 2.5279636910007506

Epoch: 5| Step: 2
Training loss: 1.9187716106974677
Validation loss: 2.547681423368203

Epoch: 5| Step: 3
Training loss: 2.7873842976596097
Validation loss: 2.5397362230910234

Epoch: 5| Step: 4
Training loss: 2.9205325709614804
Validation loss: 2.54441519685267

Epoch: 5| Step: 5
Training loss: 2.27820153546071
Validation loss: 2.545498376455784

Epoch: 5| Step: 6
Training loss: 2.2775475752684256
Validation loss: 2.567737595944025

Epoch: 5| Step: 7
Training loss: 1.8625411957146754
Validation loss: 2.556268772314359

Epoch: 5| Step: 8
Training loss: 1.6375694522252198
Validation loss: 2.5654974731117393

Epoch: 5| Step: 9
Training loss: 1.8246716216961658
Validation loss: 2.5697329137296996

Epoch: 5| Step: 10
Training loss: 2.3896735797614825
Validation loss: 2.5586241470356117

Epoch: 5| Step: 11
Training loss: 3.286332472110595
Validation loss: 2.546231763933911

Epoch: 274| Step: 0
Training loss: 2.6663058950839957
Validation loss: 2.543647015460652

Epoch: 5| Step: 1
Training loss: 1.7754223173395187
Validation loss: 2.5345053246131686

Epoch: 5| Step: 2
Training loss: 1.975577489709447
Validation loss: 2.5578320133720926

Epoch: 5| Step: 3
Training loss: 2.576780951442382
Validation loss: 2.5461900098048194

Epoch: 5| Step: 4
Training loss: 2.338977583348437
Validation loss: 2.525878162925931

Epoch: 5| Step: 5
Training loss: 2.021655384146501
Validation loss: 2.543037194865672

Epoch: 5| Step: 6
Training loss: 1.9831917907258718
Validation loss: 2.5517497422053843

Epoch: 5| Step: 7
Training loss: 2.2427057072797876
Validation loss: 2.527448000519204

Epoch: 5| Step: 8
Training loss: 2.440939213140822
Validation loss: 2.548972847485008

Epoch: 5| Step: 9
Training loss: 2.281682012751122
Validation loss: 2.533929160492572

Epoch: 5| Step: 10
Training loss: 2.528519747439141
Validation loss: 2.5547151554333407

Epoch: 5| Step: 11
Training loss: 3.107030396704764
Validation loss: 2.5587014367347014

Epoch: 275| Step: 0
Training loss: 2.8331749441716845
Validation loss: 2.5518364079709164

Epoch: 5| Step: 1
Training loss: 2.2156863485217477
Validation loss: 2.566196102091032

Epoch: 5| Step: 2
Training loss: 2.225087637729119
Validation loss: 2.5782040092614937

Epoch: 5| Step: 3
Training loss: 1.7586752575661366
Validation loss: 2.5986702758733986

Epoch: 5| Step: 4
Training loss: 2.1660193674590076
Validation loss: 2.6180360509740073

Epoch: 5| Step: 5
Training loss: 2.167695559223109
Validation loss: 2.598016305698786

Epoch: 5| Step: 6
Training loss: 2.693869649615109
Validation loss: 2.5749671785799833

Epoch: 5| Step: 7
Training loss: 1.8560190127730767
Validation loss: 2.568453142318314

Epoch: 5| Step: 8
Training loss: 1.8638150072433652
Validation loss: 2.556668156338879

Epoch: 5| Step: 9
Training loss: 2.2182753149174737
Validation loss: 2.542736318252716

Epoch: 5| Step: 10
Training loss: 2.9779517268462827
Validation loss: 2.5268328591040103

Epoch: 5| Step: 11
Training loss: 2.26735636886041
Validation loss: 2.527180866414985

Epoch: 276| Step: 0
Training loss: 2.433052406903721
Validation loss: 2.5308249395325704

Epoch: 5| Step: 1
Training loss: 2.2574223904032333
Validation loss: 2.527844854455827

Epoch: 5| Step: 2
Training loss: 2.352406397871824
Validation loss: 2.549452438967719

Epoch: 5| Step: 3
Training loss: 2.3629698997514437
Validation loss: 2.547954654228471

Epoch: 5| Step: 4
Training loss: 2.2796633702779694
Validation loss: 2.5791369523250744

Epoch: 5| Step: 5
Training loss: 1.6457685948769654
Validation loss: 2.5964809981078782

Epoch: 5| Step: 6
Training loss: 2.487437921257408
Validation loss: 2.5982762297198847

Epoch: 5| Step: 7
Training loss: 2.6972222238373247
Validation loss: 2.619588265128934

Epoch: 5| Step: 8
Training loss: 2.1242640847871304
Validation loss: 2.5955654612007026

Epoch: 5| Step: 9
Training loss: 2.533025236802974
Validation loss: 2.6157727607303856

Epoch: 5| Step: 10
Training loss: 2.214135865885126
Validation loss: 2.5890351668706715

Epoch: 5| Step: 11
Training loss: 1.0014604989659226
Validation loss: 2.5734321384184926

Epoch: 277| Step: 0
Training loss: 2.4229117850738007
Validation loss: 2.5326813273396738

Epoch: 5| Step: 1
Training loss: 2.4894381577900626
Validation loss: 2.5254476628816334

Epoch: 5| Step: 2
Training loss: 1.8978228417775413
Validation loss: 2.5178087955981194

Epoch: 5| Step: 3
Training loss: 2.667834076058545
Validation loss: 2.512710849967447

Epoch: 5| Step: 4
Training loss: 2.7891858498360302
Validation loss: 2.5112967959876813

Epoch: 5| Step: 5
Training loss: 2.176161891987625
Validation loss: 2.516121931731756

Epoch: 5| Step: 6
Training loss: 2.348408557868326
Validation loss: 2.5071024974043845

Epoch: 5| Step: 7
Training loss: 2.233084245806873
Validation loss: 2.5238709171054254

Epoch: 5| Step: 8
Training loss: 1.9836374549212688
Validation loss: 2.521328208887957

Epoch: 5| Step: 9
Training loss: 2.2811808118387438
Validation loss: 2.5295144948534625

Epoch: 5| Step: 10
Training loss: 2.1270274419910886
Validation loss: 2.5540743761880633

Epoch: 5| Step: 11
Training loss: 1.8463819436233342
Validation loss: 2.559724587927935

Epoch: 278| Step: 0
Training loss: 1.7833872237337047
Validation loss: 2.5745891156038803

Epoch: 5| Step: 1
Training loss: 2.3397804722962405
Validation loss: 2.5990569466106566

Epoch: 5| Step: 2
Training loss: 2.152269420967298
Validation loss: 2.591941306280447

Epoch: 5| Step: 3
Training loss: 2.4047527857117004
Validation loss: 2.612048331067897

Epoch: 5| Step: 4
Training loss: 2.6820676148302525
Validation loss: 2.638263440187343

Epoch: 5| Step: 5
Training loss: 2.2410649802691074
Validation loss: 2.600628460832362

Epoch: 5| Step: 6
Training loss: 1.6980925938866585
Validation loss: 2.580700506878156

Epoch: 5| Step: 7
Training loss: 2.361333476297958
Validation loss: 2.552414628667648

Epoch: 5| Step: 8
Training loss: 2.4525330430661976
Validation loss: 2.5474907651402554

Epoch: 5| Step: 9
Training loss: 2.6117203274561493
Validation loss: 2.527044593994218

Epoch: 5| Step: 10
Training loss: 2.519804237421625
Validation loss: 2.54920777359319

Epoch: 5| Step: 11
Training loss: 1.0781575073648821
Validation loss: 2.540649360299089

Epoch: 279| Step: 0
Training loss: 2.223168285635913
Validation loss: 2.522504600612703

Epoch: 5| Step: 1
Training loss: 2.3369667056857883
Validation loss: 2.5202804555509313

Epoch: 5| Step: 2
Training loss: 2.3795670216470586
Validation loss: 2.5350101195678274

Epoch: 5| Step: 3
Training loss: 1.80077701328135
Validation loss: 2.5391720870406367

Epoch: 5| Step: 4
Training loss: 2.1502283019456985
Validation loss: 2.5340413687314145

Epoch: 5| Step: 5
Training loss: 2.68941314379437
Validation loss: 2.526742306446679

Epoch: 5| Step: 6
Training loss: 2.2143414178337286
Validation loss: 2.542578671681399

Epoch: 5| Step: 7
Training loss: 2.343783975990714
Validation loss: 2.564847107737018

Epoch: 5| Step: 8
Training loss: 1.6812667165159159
Validation loss: 2.5769420298758225

Epoch: 5| Step: 9
Training loss: 2.6329840086361873
Validation loss: 2.5876518244897744

Epoch: 5| Step: 10
Training loss: 2.125493609375501
Validation loss: 2.5779856711606715

Epoch: 5| Step: 11
Training loss: 3.1235409191389114
Validation loss: 2.5883158841796665

Epoch: 280| Step: 0
Training loss: 1.7981814072041569
Validation loss: 2.584567011289108

Epoch: 5| Step: 1
Training loss: 1.9556001772208864
Validation loss: 2.6128763855538395

Epoch: 5| Step: 2
Training loss: 1.9128552424792682
Validation loss: 2.5895612168435376

Epoch: 5| Step: 3
Training loss: 2.182797636556298
Validation loss: 2.5647103034681695

Epoch: 5| Step: 4
Training loss: 2.3711508629344786
Validation loss: 2.5871911021148897

Epoch: 5| Step: 5
Training loss: 2.577189142701463
Validation loss: 2.5671124273008608

Epoch: 5| Step: 6
Training loss: 2.2988992710820417
Validation loss: 2.5584381677435575

Epoch: 5| Step: 7
Training loss: 2.750483817109261
Validation loss: 2.5622600931584243

Epoch: 5| Step: 8
Training loss: 2.154641809456246
Validation loss: 2.5642237428731187

Epoch: 5| Step: 9
Training loss: 2.7040416067522637
Validation loss: 2.5563260733205833

Epoch: 5| Step: 10
Training loss: 1.7789686886464096
Validation loss: 2.5405044256473466

Epoch: 5| Step: 11
Training loss: 3.190842913771565
Validation loss: 2.5258884180257235

Epoch: 281| Step: 0
Training loss: 1.9011288627240646
Validation loss: 2.520973305454829

Epoch: 5| Step: 1
Training loss: 2.073926082445268
Validation loss: 2.504977831609176

Epoch: 5| Step: 2
Training loss: 1.623486841386361
Validation loss: 2.515101739710173

Epoch: 5| Step: 3
Training loss: 2.0267308361577436
Validation loss: 2.522320073815009

Epoch: 5| Step: 4
Training loss: 2.089494850767591
Validation loss: 2.5310886080431576

Epoch: 5| Step: 5
Training loss: 2.4750111049826824
Validation loss: 2.539695097540044

Epoch: 5| Step: 6
Training loss: 2.50708367996336
Validation loss: 2.5390085576514068

Epoch: 5| Step: 7
Training loss: 2.6766234026302724
Validation loss: 2.542524751185143

Epoch: 5| Step: 8
Training loss: 2.509836396284527
Validation loss: 2.544447824705184

Epoch: 5| Step: 9
Training loss: 2.2911702629903417
Validation loss: 2.5479562644553555

Epoch: 5| Step: 10
Training loss: 2.405317447831223
Validation loss: 2.5504569548032046

Epoch: 5| Step: 11
Training loss: 3.4996337699018594
Validation loss: 2.5421533874211244

Epoch: 282| Step: 0
Training loss: 2.0570780840394582
Validation loss: 2.5436099680130013

Epoch: 5| Step: 1
Training loss: 2.6153869812294457
Validation loss: 2.539623879215147

Epoch: 5| Step: 2
Training loss: 2.1267298221278894
Validation loss: 2.5562647268031187

Epoch: 5| Step: 3
Training loss: 1.7295438822296072
Validation loss: 2.5534065993988375

Epoch: 5| Step: 4
Training loss: 1.722553898891286
Validation loss: 2.554365532483155

Epoch: 5| Step: 5
Training loss: 2.170704368328722
Validation loss: 2.5387686847980246

Epoch: 5| Step: 6
Training loss: 2.5412450242638838
Validation loss: 2.540664609511924

Epoch: 5| Step: 7
Training loss: 2.4703999088272512
Validation loss: 2.524322779644939

Epoch: 5| Step: 8
Training loss: 2.5108802546757008
Validation loss: 2.53210113485445

Epoch: 5| Step: 9
Training loss: 2.3609419917954457
Validation loss: 2.5148430076804225

Epoch: 5| Step: 10
Training loss: 2.449609071332803
Validation loss: 2.5334531317062723

Epoch: 5| Step: 11
Training loss: 1.9687665908356617
Validation loss: 2.5469657671147687

Epoch: 283| Step: 0
Training loss: 1.8918498461701716
Validation loss: 2.5423963833340446

Epoch: 5| Step: 1
Training loss: 1.9393904907316013
Validation loss: 2.5485542510743815

Epoch: 5| Step: 2
Training loss: 2.282974949669639
Validation loss: 2.539238329937034

Epoch: 5| Step: 3
Training loss: 1.919197139765845
Validation loss: 2.508832995231891

Epoch: 5| Step: 4
Training loss: 2.6211350461887473
Validation loss: 2.506331179597067

Epoch: 5| Step: 5
Training loss: 2.450917994509018
Validation loss: 2.5073801779143707

Epoch: 5| Step: 6
Training loss: 2.0612287360413726
Validation loss: 2.502262359416602

Epoch: 5| Step: 7
Training loss: 2.821548317960105
Validation loss: 2.513901777802287

Epoch: 5| Step: 8
Training loss: 1.6500919229737796
Validation loss: 2.510055137392159

Epoch: 5| Step: 9
Training loss: 2.738157261369091
Validation loss: 2.5224031034862775

Epoch: 5| Step: 10
Training loss: 2.4147554162368827
Validation loss: 2.5363326593136537

Epoch: 5| Step: 11
Training loss: 2.0171200434414707
Validation loss: 2.548369544468245

Epoch: 284| Step: 0
Training loss: 1.9157106115928326
Validation loss: 2.5298388908062646

Epoch: 5| Step: 1
Training loss: 2.145657492040758
Validation loss: 2.5282860718362414

Epoch: 5| Step: 2
Training loss: 2.6692928753694845
Validation loss: 2.5273702031460505

Epoch: 5| Step: 3
Training loss: 3.472948162910115
Validation loss: 2.5191485446989406

Epoch: 5| Step: 4
Training loss: 1.624455213925632
Validation loss: 2.5302510978903143

Epoch: 5| Step: 5
Training loss: 1.699003008596755
Validation loss: 2.5288152169809117

Epoch: 5| Step: 6
Training loss: 2.0223377435243246
Validation loss: 2.5406523749584236

Epoch: 5| Step: 7
Training loss: 2.297453204187922
Validation loss: 2.561190551659306

Epoch: 5| Step: 8
Training loss: 2.2370858986689988
Validation loss: 2.565453540742901

Epoch: 5| Step: 9
Training loss: 2.571757458287109
Validation loss: 2.5532441879087284

Epoch: 5| Step: 10
Training loss: 1.8562897160966172
Validation loss: 2.5268519344090117

Epoch: 5| Step: 11
Training loss: 2.2404510473084973
Validation loss: 2.5374330583834483

Epoch: 285| Step: 0
Training loss: 1.8783447949461174
Validation loss: 2.525306678629625

Epoch: 5| Step: 1
Training loss: 2.1926752180074045
Validation loss: 2.506171322298716

Epoch: 5| Step: 2
Training loss: 2.3319323852643286
Validation loss: 2.5046948338220973

Epoch: 5| Step: 3
Training loss: 2.354866317712769
Validation loss: 2.5015108073395877

Epoch: 5| Step: 4
Training loss: 1.8724715668947676
Validation loss: 2.5139957783445337

Epoch: 5| Step: 5
Training loss: 1.835438891942717
Validation loss: 2.517913989304954

Epoch: 5| Step: 6
Training loss: 2.9227313250515348
Validation loss: 2.5238608486437606

Epoch: 5| Step: 7
Training loss: 1.8671917775635822
Validation loss: 2.528479229159135

Epoch: 5| Step: 8
Training loss: 2.2239013831345935
Validation loss: 2.5619379140426966

Epoch: 5| Step: 9
Training loss: 2.9940912549949616
Validation loss: 2.561251305064261

Epoch: 5| Step: 10
Training loss: 2.181531666055678
Validation loss: 2.5838937433542997

Epoch: 5| Step: 11
Training loss: 1.4758526745905052
Validation loss: 2.6316099089863227

Epoch: 286| Step: 0
Training loss: 2.6309465536896757
Validation loss: 2.6137605540231093

Epoch: 5| Step: 1
Training loss: 2.046881988746418
Validation loss: 2.640542854822112

Epoch: 5| Step: 2
Training loss: 2.5006741568442092
Validation loss: 2.6275655720311404

Epoch: 5| Step: 3
Training loss: 2.205854416090639
Validation loss: 2.6160563933171224

Epoch: 5| Step: 4
Training loss: 2.96036332735836
Validation loss: 2.571112163411695

Epoch: 5| Step: 5
Training loss: 2.2692434945924695
Validation loss: 2.5350417124497215

Epoch: 5| Step: 6
Training loss: 2.1249096795129074
Validation loss: 2.5269931548073306

Epoch: 5| Step: 7
Training loss: 1.8153413665940232
Validation loss: 2.516643925957746

Epoch: 5| Step: 8
Training loss: 2.6996787268620475
Validation loss: 2.503364601605598

Epoch: 5| Step: 9
Training loss: 2.4022969063014235
Validation loss: 2.5031260694802326

Epoch: 5| Step: 10
Training loss: 1.7249248902927599
Validation loss: 2.4926176507132816

Epoch: 5| Step: 11
Training loss: 1.5138878059188905
Validation loss: 2.502433252336817

Epoch: 287| Step: 0
Training loss: 2.538095706863653
Validation loss: 2.5014332755595885

Epoch: 5| Step: 1
Training loss: 2.3384010822091352
Validation loss: 2.5041092955438127

Epoch: 5| Step: 2
Training loss: 1.6844688318618175
Validation loss: 2.497693456126661

Epoch: 5| Step: 3
Training loss: 2.0148479531145576
Validation loss: 2.4970698947779337

Epoch: 5| Step: 4
Training loss: 2.7514258069685327
Validation loss: 2.5044760251658515

Epoch: 5| Step: 5
Training loss: 2.140463607161487
Validation loss: 2.5117371767593237

Epoch: 5| Step: 6
Training loss: 2.703098186734789
Validation loss: 2.520115893445243

Epoch: 5| Step: 7
Training loss: 2.4964190586017208
Validation loss: 2.52687601422052

Epoch: 5| Step: 8
Training loss: 2.328974421647746
Validation loss: 2.549928726185059

Epoch: 5| Step: 9
Training loss: 1.9924080520914431
Validation loss: 2.554981070944186

Epoch: 5| Step: 10
Training loss: 1.910829327969097
Validation loss: 2.537618549283668

Epoch: 5| Step: 11
Training loss: 2.575171426048207
Validation loss: 2.524278848889548

Epoch: 288| Step: 0
Training loss: 1.4572923850693293
Validation loss: 2.5314045258438402

Epoch: 5| Step: 1
Training loss: 2.0608267499132378
Validation loss: 2.4942015917004885

Epoch: 5| Step: 2
Training loss: 2.389131665522823
Validation loss: 2.4857554089511877

Epoch: 5| Step: 3
Training loss: 2.75472547101418
Validation loss: 2.476279353854079

Epoch: 5| Step: 4
Training loss: 2.168146019638803
Validation loss: 2.4811480295414

Epoch: 5| Step: 5
Training loss: 1.5426388158424509
Validation loss: 2.477788222728785

Epoch: 5| Step: 6
Training loss: 3.1047486819961665
Validation loss: 2.4952542719599164

Epoch: 5| Step: 7
Training loss: 3.0397371068016388
Validation loss: 2.493182044656078

Epoch: 5| Step: 8
Training loss: 2.474752348252379
Validation loss: 2.4932976684552473

Epoch: 5| Step: 9
Training loss: 2.2342094946966427
Validation loss: 2.5024095208842616

Epoch: 5| Step: 10
Training loss: 1.812613648107254
Validation loss: 2.5038273878766075

Epoch: 5| Step: 11
Training loss: 1.6384170934325613
Validation loss: 2.546641339073967

Epoch: 289| Step: 0
Training loss: 1.6322072928928655
Validation loss: 2.534078293415292

Epoch: 5| Step: 1
Training loss: 2.348350485727098
Validation loss: 2.5515975502785295

Epoch: 5| Step: 2
Training loss: 1.9369504210665909
Validation loss: 2.565618931325224

Epoch: 5| Step: 3
Training loss: 1.7024155985431302
Validation loss: 2.5655501208760176

Epoch: 5| Step: 4
Training loss: 2.573856218248089
Validation loss: 2.5637762101654946

Epoch: 5| Step: 5
Training loss: 2.1588026776096263
Validation loss: 2.559073964643463

Epoch: 5| Step: 6
Training loss: 2.65905326573567
Validation loss: 2.5431158059410937

Epoch: 5| Step: 7
Training loss: 3.1649296831994813
Validation loss: 2.553289655140857

Epoch: 5| Step: 8
Training loss: 2.0672373839895397
Validation loss: 2.5372857533444533

Epoch: 5| Step: 9
Training loss: 2.525086799867045
Validation loss: 2.544075490167633

Epoch: 5| Step: 10
Training loss: 1.905245531934608
Validation loss: 2.5266362201706576

Epoch: 5| Step: 11
Training loss: 1.189370088231363
Validation loss: 2.538932898710612

Epoch: 290| Step: 0
Training loss: 2.056518087332122
Validation loss: 2.537591966127553

Epoch: 5| Step: 1
Training loss: 2.4171284091978884
Validation loss: 2.5369207142221812

Epoch: 5| Step: 2
Training loss: 2.3019852653316875
Validation loss: 2.5397745786971355

Epoch: 5| Step: 3
Training loss: 1.6677779148826624
Validation loss: 2.547125380832698

Epoch: 5| Step: 4
Training loss: 1.8650064538838906
Validation loss: 2.5388846036750565

Epoch: 5| Step: 5
Training loss: 3.1297309160196907
Validation loss: 2.557145910259336

Epoch: 5| Step: 6
Training loss: 1.7809855616186139
Validation loss: 2.5503375693261825

Epoch: 5| Step: 7
Training loss: 1.9869082043643058
Validation loss: 2.553302132614662

Epoch: 5| Step: 8
Training loss: 2.574466676017398
Validation loss: 2.5697764501493547

Epoch: 5| Step: 9
Training loss: 2.7288670460320037
Validation loss: 2.582689338958462

Epoch: 5| Step: 10
Training loss: 1.9183484107628348
Validation loss: 2.579279550527598

Epoch: 5| Step: 11
Training loss: 1.6146019062901846
Validation loss: 2.583002278178391

Epoch: 291| Step: 0
Training loss: 2.7210582712222395
Validation loss: 2.5988082816943527

Epoch: 5| Step: 1
Training loss: 2.4101983905984703
Validation loss: 2.614437605810221

Epoch: 5| Step: 2
Training loss: 2.176900086303524
Validation loss: 2.5974389924713526

Epoch: 5| Step: 3
Training loss: 2.7335520350567752
Validation loss: 2.582610941963036

Epoch: 5| Step: 4
Training loss: 1.7150852320097276
Validation loss: 2.5780827721114066

Epoch: 5| Step: 5
Training loss: 2.3195620777912045
Validation loss: 2.5613178340815086

Epoch: 5| Step: 6
Training loss: 1.9756635951393795
Validation loss: 2.550171390240205

Epoch: 5| Step: 7
Training loss: 2.3262766214740456
Validation loss: 2.5618655923628926

Epoch: 5| Step: 8
Training loss: 2.3434685093005307
Validation loss: 2.555074310572046

Epoch: 5| Step: 9
Training loss: 2.1133570631040737
Validation loss: 2.555438480569173

Epoch: 5| Step: 10
Training loss: 1.42218869280697
Validation loss: 2.5266487820876398

Epoch: 5| Step: 11
Training loss: 2.4813042622741737
Validation loss: 2.55470369977413

Epoch: 292| Step: 0
Training loss: 2.1031735282842647
Validation loss: 2.5580772791056403

Epoch: 5| Step: 1
Training loss: 2.649543463769985
Validation loss: 2.556384346485391

Epoch: 5| Step: 2
Training loss: 2.1674756838304643
Validation loss: 2.5531083066372

Epoch: 5| Step: 3
Training loss: 2.9248610960754102
Validation loss: 2.5464670072914077

Epoch: 5| Step: 4
Training loss: 2.4797032414052675
Validation loss: 2.538915862715282

Epoch: 5| Step: 5
Training loss: 2.078780909690967
Validation loss: 2.563750748760549

Epoch: 5| Step: 6
Training loss: 2.0122835125790695
Validation loss: 2.57826160492855

Epoch: 5| Step: 7
Training loss: 1.945837356051331
Validation loss: 2.5959127172656578

Epoch: 5| Step: 8
Training loss: 2.441917719861529
Validation loss: 2.617961404733761

Epoch: 5| Step: 9
Training loss: 2.1718790616882546
Validation loss: 2.6080058040481178

Epoch: 5| Step: 10
Training loss: 1.6687403017826654
Validation loss: 2.5964173386112743

Epoch: 5| Step: 11
Training loss: 1.1275844557568635
Validation loss: 2.6017476341503407

Epoch: 293| Step: 0
Training loss: 2.191957020352143
Validation loss: 2.577697687667889

Epoch: 5| Step: 1
Training loss: 2.216272071861867
Validation loss: 2.572941812142704

Epoch: 5| Step: 2
Training loss: 2.005302909173036
Validation loss: 2.586100439679502

Epoch: 5| Step: 3
Training loss: 2.2964955749601974
Validation loss: 2.587733406713418

Epoch: 5| Step: 4
Training loss: 2.2120752002219017
Validation loss: 2.580192549904537

Epoch: 5| Step: 5
Training loss: 2.3460184944575073
Validation loss: 2.600427439137131

Epoch: 5| Step: 6
Training loss: 2.2698969062215726
Validation loss: 2.590386442667022

Epoch: 5| Step: 7
Training loss: 2.3775001216210496
Validation loss: 2.5874667337524366

Epoch: 5| Step: 8
Training loss: 2.3282400013215265
Validation loss: 2.562270506995213

Epoch: 5| Step: 9
Training loss: 2.2287411387594194
Validation loss: 2.5500059833643407

Epoch: 5| Step: 10
Training loss: 1.888324251896613
Validation loss: 2.569197040681047

Epoch: 5| Step: 11
Training loss: 2.585832023198194
Validation loss: 2.5566082071532334

Epoch: 294| Step: 0
Training loss: 1.938367280353946
Validation loss: 2.572386757854655

Epoch: 5| Step: 1
Training loss: 1.9373979849261354
Validation loss: 2.5580579356804987

Epoch: 5| Step: 2
Training loss: 2.643096579748214
Validation loss: 2.5667582153944815

Epoch: 5| Step: 3
Training loss: 1.9690953511892701
Validation loss: 2.5592003702587895

Epoch: 5| Step: 4
Training loss: 2.102045960814014
Validation loss: 2.5748079327058377

Epoch: 5| Step: 5
Training loss: 2.680041409357621
Validation loss: 2.557225173401684

Epoch: 5| Step: 6
Training loss: 2.258219645924258
Validation loss: 2.5580807081697587

Epoch: 5| Step: 7
Training loss: 2.2805201787007774
Validation loss: 2.5467778130771292

Epoch: 5| Step: 8
Training loss: 2.0043442751198124
Validation loss: 2.5582275710988944

Epoch: 5| Step: 9
Training loss: 2.277129017568523
Validation loss: 2.5619633314234376

Epoch: 5| Step: 10
Training loss: 2.1856894493472847
Validation loss: 2.5620564371486942

Epoch: 5| Step: 11
Training loss: 1.6163336669791464
Validation loss: 2.5550355314495246

Epoch: 295| Step: 0
Training loss: 2.05221513302321
Validation loss: 2.557997819062974

Epoch: 5| Step: 1
Training loss: 1.892192915539351
Validation loss: 2.5889611252940323

Epoch: 5| Step: 2
Training loss: 2.1387209255219872
Validation loss: 2.5943175541340993

Epoch: 5| Step: 3
Training loss: 2.1633195944625574
Validation loss: 2.602193124000834

Epoch: 5| Step: 4
Training loss: 1.7051258058643248
Validation loss: 2.585129061175793

Epoch: 5| Step: 5
Training loss: 2.648424986863185
Validation loss: 2.5880146731029967

Epoch: 5| Step: 6
Training loss: 1.9893955188667387
Validation loss: 2.5706132019140746

Epoch: 5| Step: 7
Training loss: 2.3390178464654743
Validation loss: 2.591736628721671

Epoch: 5| Step: 8
Training loss: 2.572283606441042
Validation loss: 2.579501041056233

Epoch: 5| Step: 9
Training loss: 2.678884758561312
Validation loss: 2.584846174101427

Epoch: 5| Step: 10
Training loss: 2.1349624026559333
Validation loss: 2.5507528684165575

Epoch: 5| Step: 11
Training loss: 1.8322380290838163
Validation loss: 2.5675324707986653

Epoch: 296| Step: 0
Training loss: 2.308755678542692
Validation loss: 2.538079495022464

Epoch: 5| Step: 1
Training loss: 2.1979597427943998
Validation loss: 2.539799451251008

Epoch: 5| Step: 2
Training loss: 2.585185976108275
Validation loss: 2.539343031033314

Epoch: 5| Step: 3
Training loss: 1.7427265376819712
Validation loss: 2.5475298930814225

Epoch: 5| Step: 4
Training loss: 2.7086634703697197
Validation loss: 2.526816846272867

Epoch: 5| Step: 5
Training loss: 2.020144931957126
Validation loss: 2.5346265963511274

Epoch: 5| Step: 6
Training loss: 1.9610257071911439
Validation loss: 2.5561121371804307

Epoch: 5| Step: 7
Training loss: 1.8617348962004414
Validation loss: 2.576205172647725

Epoch: 5| Step: 8
Training loss: 2.480829167651377
Validation loss: 2.603519452095319

Epoch: 5| Step: 9
Training loss: 2.101600958603436
Validation loss: 2.6480166758257595

Epoch: 5| Step: 10
Training loss: 2.4465928305971243
Validation loss: 2.6075205847335146

Epoch: 5| Step: 11
Training loss: 2.454224066934687
Validation loss: 2.59502449282564

Epoch: 297| Step: 0
Training loss: 2.1350545312497085
Validation loss: 2.5431906900666417

Epoch: 5| Step: 1
Training loss: 2.0809330146123663
Validation loss: 2.534011805859126

Epoch: 5| Step: 2
Training loss: 2.2478248890928194
Validation loss: 2.52295619598678

Epoch: 5| Step: 3
Training loss: 2.0764341430949242
Validation loss: 2.5011198714513494

Epoch: 5| Step: 4
Training loss: 2.185258316204018
Validation loss: 2.50419088006545

Epoch: 5| Step: 5
Training loss: 2.5196165085199183
Validation loss: 2.492966658669948

Epoch: 5| Step: 6
Training loss: 2.1600960969741236
Validation loss: 2.493046154237965

Epoch: 5| Step: 7
Training loss: 2.391629076760881
Validation loss: 2.4971594169869773

Epoch: 5| Step: 8
Training loss: 2.4298810973727467
Validation loss: 2.4867120702559737

Epoch: 5| Step: 9
Training loss: 2.737909441423517
Validation loss: 2.4989672196487183

Epoch: 5| Step: 10
Training loss: 2.3214227864958397
Validation loss: 2.5041997284275

Epoch: 5| Step: 11
Training loss: 2.899334133918507
Validation loss: 2.5335591932887276

Epoch: 298| Step: 0
Training loss: 2.820056005422279
Validation loss: 2.5374715525499854

Epoch: 5| Step: 1
Training loss: 2.1528525746248506
Validation loss: 2.5167080303186546

Epoch: 5| Step: 2
Training loss: 1.7308269328092543
Validation loss: 2.530102344039915

Epoch: 5| Step: 3
Training loss: 2.2471017184626234
Validation loss: 2.5351959836693894

Epoch: 5| Step: 4
Training loss: 1.9106206972861766
Validation loss: 2.5108031269573012

Epoch: 5| Step: 5
Training loss: 2.4392195285099207
Validation loss: 2.5090964804476195

Epoch: 5| Step: 6
Training loss: 3.1093835878493215
Validation loss: 2.512948308237479

Epoch: 5| Step: 7
Training loss: 2.278174953671766
Validation loss: 2.5236845220353943

Epoch: 5| Step: 8
Training loss: 1.8189613665168536
Validation loss: 2.5452567187887123

Epoch: 5| Step: 9
Training loss: 2.2977580753865605
Validation loss: 2.545450166960662

Epoch: 5| Step: 10
Training loss: 1.6302175389559082
Validation loss: 2.5591427939516875

Epoch: 5| Step: 11
Training loss: 2.3183144337669677
Validation loss: 2.560974388019811

Epoch: 299| Step: 0
Training loss: 2.615846751667698
Validation loss: 2.5814809169422297

Epoch: 5| Step: 1
Training loss: 2.7097606907997998
Validation loss: 2.628535213804693

Epoch: 5| Step: 2
Training loss: 2.231417532649838
Validation loss: 2.62824308921597

Epoch: 5| Step: 3
Training loss: 2.5918270474411784
Validation loss: 2.6781042109320197

Epoch: 5| Step: 4
Training loss: 2.8042340350360195
Validation loss: 2.7207760405143273

Epoch: 5| Step: 5
Training loss: 1.889251777752076
Validation loss: 2.6399541488010856

Epoch: 5| Step: 6
Training loss: 2.438946123786392
Validation loss: 2.5962793893609257

Epoch: 5| Step: 7
Training loss: 1.7569446371059119
Validation loss: 2.5453042099085703

Epoch: 5| Step: 8
Training loss: 1.5608876110577716
Validation loss: 2.536536383292898

Epoch: 5| Step: 9
Training loss: 1.8799495219494924
Validation loss: 2.517604298007952

Epoch: 5| Step: 10
Training loss: 2.1881481845197306
Validation loss: 2.499457534905225

Epoch: 5| Step: 11
Training loss: 2.345953452342015
Validation loss: 2.506582126665038

Epoch: 300| Step: 0
Training loss: 2.67775743559431
Validation loss: 2.497015836974583

Epoch: 5| Step: 1
Training loss: 2.1468743203507725
Validation loss: 2.5076957449666124

Epoch: 5| Step: 2
Training loss: 2.18730805781088
Validation loss: 2.5059443573628566

Epoch: 5| Step: 3
Training loss: 2.424520216996198
Validation loss: 2.5051150486339226

Epoch: 5| Step: 4
Training loss: 2.390627991917552
Validation loss: 2.5035457341627567

Epoch: 5| Step: 5
Training loss: 2.8521248040947165
Validation loss: 2.507755076859121

Epoch: 5| Step: 6
Training loss: 2.2899092322272514
Validation loss: 2.50371878919544

Epoch: 5| Step: 7
Training loss: 1.8765095038637083
Validation loss: 2.4996043329257094

Epoch: 5| Step: 8
Training loss: 2.0506723138849674
Validation loss: 2.4820310543621766

Epoch: 5| Step: 9
Training loss: 2.5790306581329348
Validation loss: 2.4868147724135508

Epoch: 5| Step: 10
Training loss: 2.3922912176509885
Validation loss: 2.482813626403745

Epoch: 5| Step: 11
Training loss: 1.411718459517212
Validation loss: 2.4909147442641415

Epoch: 301| Step: 0
Training loss: 2.427013532647189
Validation loss: 2.5003558422200727

Epoch: 5| Step: 1
Training loss: 2.2234893471093997
Validation loss: 2.493472462621067

Epoch: 5| Step: 2
Training loss: 2.759366988692097
Validation loss: 2.4923908943878463

Epoch: 5| Step: 3
Training loss: 1.7703175261006128
Validation loss: 2.4951502250977513

Epoch: 5| Step: 4
Training loss: 2.551494504509655
Validation loss: 2.495283716744811

Epoch: 5| Step: 5
Training loss: 2.413620300285232
Validation loss: 2.493316402679562

Epoch: 5| Step: 6
Training loss: 2.4548725293973206
Validation loss: 2.4853625284189103

Epoch: 5| Step: 7
Training loss: 1.7090040456457227
Validation loss: 2.4898586214098417

Epoch: 5| Step: 8
Training loss: 2.1952815477897505
Validation loss: 2.4930731237182706

Epoch: 5| Step: 9
Training loss: 2.495086992234122
Validation loss: 2.5078123375881693

Epoch: 5| Step: 10
Training loss: 2.1838127667862044
Validation loss: 2.5084755754747334

Epoch: 5| Step: 11
Training loss: 2.9329262696658263
Validation loss: 2.515701810086702

Epoch: 302| Step: 0
Training loss: 2.1126983459174395
Validation loss: 2.520763957169763

Epoch: 5| Step: 1
Training loss: 1.9158996484713637
Validation loss: 2.512709240875405

Epoch: 5| Step: 2
Training loss: 1.9606888450026243
Validation loss: 2.5420397200691354

Epoch: 5| Step: 3
Training loss: 2.266910688036783
Validation loss: 2.550968266515422

Epoch: 5| Step: 4
Training loss: 1.7215992978564323
Validation loss: 2.5790849825003432

Epoch: 5| Step: 5
Training loss: 2.593238688247974
Validation loss: 2.5990544927590737

Epoch: 5| Step: 6
Training loss: 3.090665107675093
Validation loss: 2.620870505849149

Epoch: 5| Step: 7
Training loss: 2.432829269909987
Validation loss: 2.6321912913676515

Epoch: 5| Step: 8
Training loss: 2.3016376553013878
Validation loss: 2.630822879771297

Epoch: 5| Step: 9
Training loss: 2.356670926893701
Validation loss: 2.6465834370333443

Epoch: 5| Step: 10
Training loss: 1.8792200282514282
Validation loss: 2.645779944554539

Epoch: 5| Step: 11
Training loss: 1.4287433946511876
Validation loss: 2.6295906525047963

Epoch: 303| Step: 0
Training loss: 2.247895740297318
Validation loss: 2.637791473319329

Epoch: 5| Step: 1
Training loss: 2.396582765432607
Validation loss: 2.607503874938319

Epoch: 5| Step: 2
Training loss: 2.3381800269264708
Validation loss: 2.588521108539287

Epoch: 5| Step: 3
Training loss: 2.081755829248734
Validation loss: 2.608185270380787

Epoch: 5| Step: 4
Training loss: 2.4011400137817227
Validation loss: 2.586846144924566

Epoch: 5| Step: 5
Training loss: 2.210956047708199
Validation loss: 2.5777554565067087

Epoch: 5| Step: 6
Training loss: 2.472921589238817
Validation loss: 2.573978985979277

Epoch: 5| Step: 7
Training loss: 1.6243654626123796
Validation loss: 2.59127152999077

Epoch: 5| Step: 8
Training loss: 2.8431186184714017
Validation loss: 2.606863534036811

Epoch: 5| Step: 9
Training loss: 1.6183751854295743
Validation loss: 2.6112485734172677

Epoch: 5| Step: 10
Training loss: 2.0871493930253657
Validation loss: 2.615660974732956

Epoch: 5| Step: 11
Training loss: 0.880473253159063
Validation loss: 2.6165154728265825

Epoch: 304| Step: 0
Training loss: 2.5348140914734794
Validation loss: 2.606577788276384

Epoch: 5| Step: 1
Training loss: 1.962403558681821
Validation loss: 2.6032789675579306

Epoch: 5| Step: 2
Training loss: 2.1031171869413403
Validation loss: 2.589526050043514

Epoch: 5| Step: 3
Training loss: 2.118942378039723
Validation loss: 2.598351408984466

Epoch: 5| Step: 4
Training loss: 1.5786434870389616
Validation loss: 2.597754785872587

Epoch: 5| Step: 5
Training loss: 2.965433778215416
Validation loss: 2.6138075263942926

Epoch: 5| Step: 6
Training loss: 2.16174335362337
Validation loss: 2.6050650242361524

Epoch: 5| Step: 7
Training loss: 1.7914653783290675
Validation loss: 2.6126653670641695

Epoch: 5| Step: 8
Training loss: 2.187657595815845
Validation loss: 2.6049051166041086

Epoch: 5| Step: 9
Training loss: 2.4873529016908815
Validation loss: 2.5911703610177867

Epoch: 5| Step: 10
Training loss: 2.0090265425755813
Validation loss: 2.5765082405072555

Epoch: 5| Step: 11
Training loss: 2.195524266573874
Validation loss: 2.565446020799678

Epoch: 305| Step: 0
Training loss: 2.859463883149365
Validation loss: 2.5807839986684082

Epoch: 5| Step: 1
Training loss: 2.437894544703727
Validation loss: 2.568432368605889

Epoch: 5| Step: 2
Training loss: 1.9324531042175384
Validation loss: 2.566832225948762

Epoch: 5| Step: 3
Training loss: 1.9528736410521443
Validation loss: 2.5646894529581643

Epoch: 5| Step: 4
Training loss: 2.2573262783390184
Validation loss: 2.561780219830164

Epoch: 5| Step: 5
Training loss: 2.496580360034523
Validation loss: 2.5816014211506926

Epoch: 5| Step: 6
Training loss: 1.4523937887730813
Validation loss: 2.568617604936181

Epoch: 5| Step: 7
Training loss: 1.9859523361456237
Validation loss: 2.5742460605405593

Epoch: 5| Step: 8
Training loss: 2.8162244931220237
Validation loss: 2.5814410432988684

Epoch: 5| Step: 9
Training loss: 1.7246279688488382
Validation loss: 2.5681276784997227

Epoch: 5| Step: 10
Training loss: 1.6278462059616294
Validation loss: 2.5819757506561265

Epoch: 5| Step: 11
Training loss: 3.3224675623427573
Validation loss: 2.5890983613591936

Epoch: 306| Step: 0
Training loss: 2.8899886796986975
Validation loss: 2.587522856293501

Epoch: 5| Step: 1
Training loss: 2.111053025411402
Validation loss: 2.582771633722604

Epoch: 5| Step: 2
Training loss: 1.483075506684205
Validation loss: 2.577180126708956

Epoch: 5| Step: 3
Training loss: 2.3229757623610907
Validation loss: 2.5787140760879623

Epoch: 5| Step: 4
Training loss: 2.0681519949227094
Validation loss: 2.5615157082300843

Epoch: 5| Step: 5
Training loss: 2.1931839258774106
Validation loss: 2.543677263055688

Epoch: 5| Step: 6
Training loss: 1.5851639237460187
Validation loss: 2.5505926112105133

Epoch: 5| Step: 7
Training loss: 2.605712970686105
Validation loss: 2.5580518308791382

Epoch: 5| Step: 8
Training loss: 1.7483527059848467
Validation loss: 2.546134228622105

Epoch: 5| Step: 9
Training loss: 2.309871313630841
Validation loss: 2.540433374695854

Epoch: 5| Step: 10
Training loss: 2.291860283273052
Validation loss: 2.5363696289740085

Epoch: 5| Step: 11
Training loss: 3.2675969498953403
Validation loss: 2.553792596487592

Epoch: 307| Step: 0
Training loss: 2.630186044327872
Validation loss: 2.603200860538118

Epoch: 5| Step: 1
Training loss: 2.579798392321701
Validation loss: 2.653241495780719

Epoch: 5| Step: 2
Training loss: 2.201908506192097
Validation loss: 2.6817351544771997

Epoch: 5| Step: 3
Training loss: 1.8321752430627682
Validation loss: 2.6582665848099976

Epoch: 5| Step: 4
Training loss: 2.6414926220893538
Validation loss: 2.6282374951768372

Epoch: 5| Step: 5
Training loss: 2.3244530311281615
Validation loss: 2.612195502640596

Epoch: 5| Step: 6
Training loss: 1.490529122458072
Validation loss: 2.5490683353499604

Epoch: 5| Step: 7
Training loss: 2.016440766137772
Validation loss: 2.529060020795938

Epoch: 5| Step: 8
Training loss: 2.0176946379262906
Validation loss: 2.492271041267133

Epoch: 5| Step: 9
Training loss: 2.1349813870549994
Validation loss: 2.507539712522317

Epoch: 5| Step: 10
Training loss: 2.670485732082755
Validation loss: 2.5102618804213352

Epoch: 5| Step: 11
Training loss: 2.888041233349577
Validation loss: 2.499221585204462

Epoch: 308| Step: 0
Training loss: 1.9608775581833904
Validation loss: 2.495274802926239

Epoch: 5| Step: 1
Training loss: 1.9563183732926743
Validation loss: 2.516214368820269

Epoch: 5| Step: 2
Training loss: 2.0865900397729282
Validation loss: 2.5299829129507763

Epoch: 5| Step: 3
Training loss: 1.9586945734903283
Validation loss: 2.5444926214365395

Epoch: 5| Step: 4
Training loss: 1.9657722236068884
Validation loss: 2.571957008967069

Epoch: 5| Step: 5
Training loss: 2.625433295683169
Validation loss: 2.605839044812511

Epoch: 5| Step: 6
Training loss: 2.756515932986086
Validation loss: 2.636554451050333

Epoch: 5| Step: 7
Training loss: 2.2648155081686587
Validation loss: 2.6527021687458294

Epoch: 5| Step: 8
Training loss: 2.3875081806142573
Validation loss: 2.6833640180239158

Epoch: 5| Step: 9
Training loss: 2.3924760820076165
Validation loss: 2.594140762553503

Epoch: 5| Step: 10
Training loss: 2.0774089755649494
Validation loss: 2.586462138605001

Epoch: 5| Step: 11
Training loss: 2.900317299683394
Validation loss: 2.5684600152820645

Epoch: 309| Step: 0
Training loss: 2.357634148447037
Validation loss: 2.525850415937131

Epoch: 5| Step: 1
Training loss: 2.1263208211309506
Validation loss: 2.514467427180108

Epoch: 5| Step: 2
Training loss: 2.4777126589753657
Validation loss: 2.518231352785747

Epoch: 5| Step: 3
Training loss: 2.5026607659191926
Validation loss: 2.5125349962033527

Epoch: 5| Step: 4
Training loss: 2.6079612145553
Validation loss: 2.4989735979857195

Epoch: 5| Step: 5
Training loss: 2.6306386966942394
Validation loss: 2.5022655672151983

Epoch: 5| Step: 6
Training loss: 1.814724970595431
Validation loss: 2.528813845981394

Epoch: 5| Step: 7
Training loss: 1.9388159313095914
Validation loss: 2.5114574108546646

Epoch: 5| Step: 8
Training loss: 2.3300096704830815
Validation loss: 2.514243380320607

Epoch: 5| Step: 9
Training loss: 1.8514451903189375
Validation loss: 2.5325680193689784

Epoch: 5| Step: 10
Training loss: 1.9408408863427866
Validation loss: 2.5418611996628355

Epoch: 5| Step: 11
Training loss: 1.1340410607992708
Validation loss: 2.585585674927066

Epoch: 310| Step: 0
Training loss: 2.4084787327083053
Validation loss: 2.6068983640670202

Epoch: 5| Step: 1
Training loss: 2.609811529319099
Validation loss: 2.6068855334087178

Epoch: 5| Step: 2
Training loss: 2.4696705707373825
Validation loss: 2.588765801768793

Epoch: 5| Step: 3
Training loss: 2.130725328405767
Validation loss: 2.611483158216241

Epoch: 5| Step: 4
Training loss: 1.9620491311729675
Validation loss: 2.606381738201116

Epoch: 5| Step: 5
Training loss: 2.1805184260593347
Validation loss: 2.5945269520199523

Epoch: 5| Step: 6
Training loss: 2.296452074623479
Validation loss: 2.583868883877003

Epoch: 5| Step: 7
Training loss: 2.1247284659638623
Validation loss: 2.5669057390000867

Epoch: 5| Step: 8
Training loss: 2.2950084134282163
Validation loss: 2.552077458173775

Epoch: 5| Step: 9
Training loss: 2.5290344337783
Validation loss: 2.556727874875724

Epoch: 5| Step: 10
Training loss: 1.6918635289818302
Validation loss: 2.557899800315571

Epoch: 5| Step: 11
Training loss: 0.8728178607190118
Validation loss: 2.5390484227499384

Epoch: 311| Step: 0
Training loss: 2.0969848694989945
Validation loss: 2.578919764077611

Epoch: 5| Step: 1
Training loss: 2.075969065308929
Validation loss: 2.5533476027055957

Epoch: 5| Step: 2
Training loss: 2.3345961786402754
Validation loss: 2.575376548364103

Epoch: 5| Step: 3
Training loss: 2.1817817061799816
Validation loss: 2.5741882515365906

Epoch: 5| Step: 4
Training loss: 2.356202474666287
Validation loss: 2.608618327700318

Epoch: 5| Step: 5
Training loss: 2.4309502659570477
Validation loss: 2.5971256335607276

Epoch: 5| Step: 6
Training loss: 2.49829596618979
Validation loss: 2.6141807403242363

Epoch: 5| Step: 7
Training loss: 1.9614150237172325
Validation loss: 2.6118450504352793

Epoch: 5| Step: 8
Training loss: 1.5882624980159168
Validation loss: 2.6085309359518627

Epoch: 5| Step: 9
Training loss: 1.7487454686027752
Validation loss: 2.5747727264486313

Epoch: 5| Step: 10
Training loss: 2.5190934621471897
Validation loss: 2.5569205095705505

Epoch: 5| Step: 11
Training loss: 2.0911170004206467
Validation loss: 2.562268300940246

Epoch: 312| Step: 0
Training loss: 2.0291192249598256
Validation loss: 2.559446337415616

Epoch: 5| Step: 1
Training loss: 2.509585980468786
Validation loss: 2.5552568024927726

Epoch: 5| Step: 2
Training loss: 2.213793093295829
Validation loss: 2.5606319996262727

Epoch: 5| Step: 3
Training loss: 2.214805643066691
Validation loss: 2.5654807238759485

Epoch: 5| Step: 4
Training loss: 2.426808997982579
Validation loss: 2.5738032752932436

Epoch: 5| Step: 5
Training loss: 1.8651919375080723
Validation loss: 2.5770421036917464

Epoch: 5| Step: 6
Training loss: 2.1338373314048504
Validation loss: 2.583172829061587

Epoch: 5| Step: 7
Training loss: 2.0839791123557028
Validation loss: 2.5659502922076523

Epoch: 5| Step: 8
Training loss: 1.5483033492624372
Validation loss: 2.5749712217136334

Epoch: 5| Step: 9
Training loss: 1.7630417417322286
Validation loss: 2.58545647302846

Epoch: 5| Step: 10
Training loss: 2.7852938967125986
Validation loss: 2.591457452997514

Epoch: 5| Step: 11
Training loss: 1.7797416189805253
Validation loss: 2.6145708316843517

Epoch: 313| Step: 0
Training loss: 2.3759784690639187
Validation loss: 2.6256432729023325

Epoch: 5| Step: 1
Training loss: 2.19968551642156
Validation loss: 2.644873720398414

Epoch: 5| Step: 2
Training loss: 2.2478567087722934
Validation loss: 2.6364651216570034

Epoch: 5| Step: 3
Training loss: 2.147133171183698
Validation loss: 2.6278101245223553

Epoch: 5| Step: 4
Training loss: 3.074224644113632
Validation loss: 2.58670203594191

Epoch: 5| Step: 5
Training loss: 1.6004096371073315
Validation loss: 2.5493825219409603

Epoch: 5| Step: 6
Training loss: 1.8036063783056961
Validation loss: 2.561594403750666

Epoch: 5| Step: 7
Training loss: 2.1112831809653225
Validation loss: 2.537672478117962

Epoch: 5| Step: 8
Training loss: 2.4930963563074524
Validation loss: 2.5335012832504344

Epoch: 5| Step: 9
Training loss: 1.7743294107318646
Validation loss: 2.551019405290186

Epoch: 5| Step: 10
Training loss: 2.0249794052395416
Validation loss: 2.5682596861780014

Epoch: 5| Step: 11
Training loss: 3.164476909107786
Validation loss: 2.6007322641963535

Epoch: 314| Step: 0
Training loss: 2.0780752075654867
Validation loss: 2.6295574793005274

Epoch: 5| Step: 1
Training loss: 3.253309472210207
Validation loss: 2.6576846399786382

Epoch: 5| Step: 2
Training loss: 1.7976391038404371
Validation loss: 2.678766880246259

Epoch: 5| Step: 3
Training loss: 1.882184505596436
Validation loss: 2.6927871704858126

Epoch: 5| Step: 4
Training loss: 2.4764073079578863
Validation loss: 2.6800243881406463

Epoch: 5| Step: 5
Training loss: 2.615762077577102
Validation loss: 2.647871198846566

Epoch: 5| Step: 6
Training loss: 1.8563599704829872
Validation loss: 2.6416875443300425

Epoch: 5| Step: 7
Training loss: 2.494198552760638
Validation loss: 2.6358115700739764

Epoch: 5| Step: 8
Training loss: 1.5676567432452597
Validation loss: 2.612792885103737

Epoch: 5| Step: 9
Training loss: 2.006183245252411
Validation loss: 2.595515799095674

Epoch: 5| Step: 10
Training loss: 1.7350980608929014
Validation loss: 2.5393972440285686

Epoch: 5| Step: 11
Training loss: 1.2648727159205244
Validation loss: 2.543310446178962

Epoch: 315| Step: 0
Training loss: 1.2825166907163206
Validation loss: 2.5383162081506656

Epoch: 5| Step: 1
Training loss: 2.3210273437861577
Validation loss: 2.541274430673067

Epoch: 5| Step: 2
Training loss: 2.7762623330039427
Validation loss: 2.521434973546253

Epoch: 5| Step: 3
Training loss: 2.091397230366127
Validation loss: 2.516694266176358

Epoch: 5| Step: 4
Training loss: 2.932912775438035
Validation loss: 2.526596253593667

Epoch: 5| Step: 5
Training loss: 1.4708106013082223
Validation loss: 2.5318794135126867

Epoch: 5| Step: 6
Training loss: 2.534278094488661
Validation loss: 2.533619195773277

Epoch: 5| Step: 7
Training loss: 2.4359940009082406
Validation loss: 2.5420721830173414

Epoch: 5| Step: 8
Training loss: 2.323752476699601
Validation loss: 2.572285518120358

Epoch: 5| Step: 9
Training loss: 1.9695234444572123
Validation loss: 2.6316217886214903

Epoch: 5| Step: 10
Training loss: 2.1408038656311033
Validation loss: 2.648315846997823

Epoch: 5| Step: 11
Training loss: 1.7588578570275135
Validation loss: 2.6596946147706557

Epoch: 316| Step: 0
Training loss: 2.566537514033957
Validation loss: 2.6825583513638023

Epoch: 5| Step: 1
Training loss: 2.081394234089889
Validation loss: 2.661841737536833

Epoch: 5| Step: 2
Training loss: 2.3058981608974354
Validation loss: 2.620054767712041

Epoch: 5| Step: 3
Training loss: 2.1901525491336358
Validation loss: 2.5994647124575283

Epoch: 5| Step: 4
Training loss: 2.397286005106003
Validation loss: 2.598613965925312

Epoch: 5| Step: 5
Training loss: 1.6430394888907702
Validation loss: 2.606016765803549

Epoch: 5| Step: 6
Training loss: 1.9604917832785875
Validation loss: 2.5575647434928195

Epoch: 5| Step: 7
Training loss: 2.046266421634912
Validation loss: 2.568495304199663

Epoch: 5| Step: 8
Training loss: 1.8887467315261806
Validation loss: 2.5579392273023918

Epoch: 5| Step: 9
Training loss: 2.5043340308634687
Validation loss: 2.5682821013184314

Epoch: 5| Step: 10
Training loss: 1.9702138151523028
Validation loss: 2.5570105160514482

Epoch: 5| Step: 11
Training loss: 1.9102733864782382
Validation loss: 2.540037496141701

Epoch: 317| Step: 0
Training loss: 1.948673454870998
Validation loss: 2.5604227144083516

Epoch: 5| Step: 1
Training loss: 2.4615317944060413
Validation loss: 2.5688746719858844

Epoch: 5| Step: 2
Training loss: 2.1103321305792084
Validation loss: 2.5392368628469497

Epoch: 5| Step: 3
Training loss: 2.2818532694751226
Validation loss: 2.5444815101716336

Epoch: 5| Step: 4
Training loss: 2.557743216515939
Validation loss: 2.537434596986816

Epoch: 5| Step: 5
Training loss: 1.515826103790195
Validation loss: 2.562581572746213

Epoch: 5| Step: 6
Training loss: 2.5992869829968384
Validation loss: 2.5687108890776678

Epoch: 5| Step: 7
Training loss: 1.8432382422966898
Validation loss: 2.606093743974186

Epoch: 5| Step: 8
Training loss: 2.0156966795485056
Validation loss: 2.6188944701628603

Epoch: 5| Step: 9
Training loss: 2.8410418684014944
Validation loss: 2.6223067552930455

Epoch: 5| Step: 10
Training loss: 2.176464692579329
Validation loss: 2.631594322310256

Epoch: 5| Step: 11
Training loss: 1.3780160683551845
Validation loss: 2.6035885525195805

Epoch: 318| Step: 0
Training loss: 2.241060831200127
Validation loss: 2.611732179647324

Epoch: 5| Step: 1
Training loss: 1.8065839438954787
Validation loss: 2.617197319505784

Epoch: 5| Step: 2
Training loss: 1.4643702034051531
Validation loss: 2.581328723036459

Epoch: 5| Step: 3
Training loss: 2.3577737995912718
Validation loss: 2.634188744177817

Epoch: 5| Step: 4
Training loss: 2.1605237541278917
Validation loss: 2.6071703042957615

Epoch: 5| Step: 5
Training loss: 1.6590798153156003
Validation loss: 2.5719597629068915

Epoch: 5| Step: 6
Training loss: 2.294507733576184
Validation loss: 2.5592571534167408

Epoch: 5| Step: 7
Training loss: 1.7463026497835688
Validation loss: 2.5667664784576587

Epoch: 5| Step: 8
Training loss: 2.1920620893957063
Validation loss: 2.5636094684358817

Epoch: 5| Step: 9
Training loss: 1.5703581997878284
Validation loss: 2.5489462658235724

Epoch: 5| Step: 10
Training loss: 3.1844199764231282
Validation loss: 2.5474378240869906

Epoch: 5| Step: 11
Training loss: 4.4528791393203715
Validation loss: 2.5502056740112584

Epoch: 319| Step: 0
Training loss: 1.3654845612895286
Validation loss: 2.5712197315311847

Epoch: 5| Step: 1
Training loss: 1.8246142593739818
Validation loss: 2.567740787716259

Epoch: 5| Step: 2
Training loss: 2.4655286801553244
Validation loss: 2.5695204707803296

Epoch: 5| Step: 3
Training loss: 2.199745779087835
Validation loss: 2.559874063336515

Epoch: 5| Step: 4
Training loss: 2.07628429607289
Validation loss: 2.6122740594607348

Epoch: 5| Step: 5
Training loss: 2.5413948497405117
Validation loss: 2.6195727358600105

Epoch: 5| Step: 6
Training loss: 2.2216852678501344
Validation loss: 2.6391455777848103

Epoch: 5| Step: 7
Training loss: 2.046762011954869
Validation loss: 2.6583509588603964

Epoch: 5| Step: 8
Training loss: 2.677263948950468
Validation loss: 2.6106602174336193

Epoch: 5| Step: 9
Training loss: 2.570460909469229
Validation loss: 2.6358245275167227

Epoch: 5| Step: 10
Training loss: 2.0540936558291896
Validation loss: 2.6306104648484894

Epoch: 5| Step: 11
Training loss: 1.7785990212248521
Validation loss: 2.595329688358058

Epoch: 320| Step: 0
Training loss: 1.8481293086807034
Validation loss: 2.587454885590132

Epoch: 5| Step: 1
Training loss: 2.313867525467921
Validation loss: 2.564300885103759

Epoch: 5| Step: 2
Training loss: 2.274933627491353
Validation loss: 2.5648074577150535

Epoch: 5| Step: 3
Training loss: 1.816262581998927
Validation loss: 2.552779133333043

Epoch: 5| Step: 4
Training loss: 2.442893004333456
Validation loss: 2.5691400866773515

Epoch: 5| Step: 5
Training loss: 2.308330488604871
Validation loss: 2.5690740831042307

Epoch: 5| Step: 6
Training loss: 1.9962807285951116
Validation loss: 2.577070091668918

Epoch: 5| Step: 7
Training loss: 2.0025088548404972
Validation loss: 2.5647975073495792

Epoch: 5| Step: 8
Training loss: 2.7352544623630455
Validation loss: 2.5758446482464685

Epoch: 5| Step: 9
Training loss: 1.7980102933137119
Validation loss: 2.5484967675286154

Epoch: 5| Step: 10
Training loss: 2.2936992878725966
Validation loss: 2.5677389152103625

Epoch: 5| Step: 11
Training loss: 1.4412644065805218
Validation loss: 2.535828993397974

Epoch: 321| Step: 0
Training loss: 1.9592353758884955
Validation loss: 2.542981164826746

Epoch: 5| Step: 1
Training loss: 2.0776146283527446
Validation loss: 2.5631845808107814

Epoch: 5| Step: 2
Training loss: 1.896258889808009
Validation loss: 2.5484378949571806

Epoch: 5| Step: 3
Training loss: 2.8175402089916424
Validation loss: 2.559309970307474

Epoch: 5| Step: 4
Training loss: 2.1942017484072935
Validation loss: 2.5636322846117348

Epoch: 5| Step: 5
Training loss: 2.071426610053125
Validation loss: 2.560190326804185

Epoch: 5| Step: 6
Training loss: 2.2381074048980256
Validation loss: 2.593743102129608

Epoch: 5| Step: 7
Training loss: 2.192703814890745
Validation loss: 2.570996986623062

Epoch: 5| Step: 8
Training loss: 2.2948553846750923
Validation loss: 2.5803460158471005

Epoch: 5| Step: 9
Training loss: 1.7049477998232292
Validation loss: 2.579324142864221

Epoch: 5| Step: 10
Training loss: 1.9353720762155207
Validation loss: 2.5752362375933813

Epoch: 5| Step: 11
Training loss: 2.130706529878595
Validation loss: 2.5684777680971367

Epoch: 322| Step: 0
Training loss: 1.5140272547789557
Validation loss: 2.544743755876944

Epoch: 5| Step: 1
Training loss: 2.6554698920521043
Validation loss: 2.569979123310293

Epoch: 5| Step: 2
Training loss: 2.074826139037357
Validation loss: 2.55781047761154

Epoch: 5| Step: 3
Training loss: 2.0443326580312497
Validation loss: 2.5721855566278284

Epoch: 5| Step: 4
Training loss: 1.881993602409394
Validation loss: 2.5736581850959137

Epoch: 5| Step: 5
Training loss: 1.9124257465982388
Validation loss: 2.584480243832441

Epoch: 5| Step: 6
Training loss: 2.2588041563144095
Validation loss: 2.5593949517049563

Epoch: 5| Step: 7
Training loss: 2.4352255749250507
Validation loss: 2.559676498894284

Epoch: 5| Step: 8
Training loss: 2.1364917808926336
Validation loss: 2.554679932811546

Epoch: 5| Step: 9
Training loss: 2.2801472336930604
Validation loss: 2.55365567071555

Epoch: 5| Step: 10
Training loss: 2.3902124784501213
Validation loss: 2.5707644806291774

Epoch: 5| Step: 11
Training loss: 1.4268060215214704
Validation loss: 2.5605457072154705

Epoch: 323| Step: 0
Training loss: 2.3757276926022
Validation loss: 2.5787289191472413

Epoch: 5| Step: 1
Training loss: 1.9184889699714778
Validation loss: 2.5978160875903606

Epoch: 5| Step: 2
Training loss: 1.9102229631315613
Validation loss: 2.6055080710155334

Epoch: 5| Step: 3
Training loss: 2.5407949318073757
Validation loss: 2.6002766330590914

Epoch: 5| Step: 4
Training loss: 2.713653874533199
Validation loss: 2.56931143207335

Epoch: 5| Step: 5
Training loss: 2.1208628604334874
Validation loss: 2.599485161744526

Epoch: 5| Step: 6
Training loss: 2.0055312916329053
Validation loss: 2.581854994582547

Epoch: 5| Step: 7
Training loss: 2.09511726488213
Validation loss: 2.5863034084552337

Epoch: 5| Step: 8
Training loss: 2.4769300314454323
Validation loss: 2.5655212850667213

Epoch: 5| Step: 9
Training loss: 1.3280249614064457
Validation loss: 2.563705808046932

Epoch: 5| Step: 10
Training loss: 1.3375854144051764
Validation loss: 2.549191683080839

Epoch: 5| Step: 11
Training loss: 3.02957815097881
Validation loss: 2.5699802829428906

Epoch: 324| Step: 0
Training loss: 1.233090855415261
Validation loss: 2.5545903653062725

Epoch: 5| Step: 1
Training loss: 1.9467064332928337
Validation loss: 2.5612139886385097

Epoch: 5| Step: 2
Training loss: 1.9285999275806434
Validation loss: 2.5561908377755076

Epoch: 5| Step: 3
Training loss: 2.778256037124477
Validation loss: 2.555209916232635

Epoch: 5| Step: 4
Training loss: 2.0547188295942016
Validation loss: 2.533552284462101

Epoch: 5| Step: 5
Training loss: 2.19627994384501
Validation loss: 2.5512227352541417

Epoch: 5| Step: 6
Training loss: 1.9497516033715303
Validation loss: 2.542756317375611

Epoch: 5| Step: 7
Training loss: 1.7708615319493883
Validation loss: 2.543645734469992

Epoch: 5| Step: 8
Training loss: 2.3623685729592694
Validation loss: 2.5584934282897476

Epoch: 5| Step: 9
Training loss: 2.6161259106598873
Validation loss: 2.5604959885860605

Epoch: 5| Step: 10
Training loss: 2.320212108354037
Validation loss: 2.5694578347988437

Epoch: 5| Step: 11
Training loss: 1.9284871186391686
Validation loss: 2.567018158230857

Epoch: 325| Step: 0
Training loss: 2.5805002079523627
Validation loss: 2.566898689656079

Epoch: 5| Step: 1
Training loss: 2.5234204932428073
Validation loss: 2.6054964230891757

Epoch: 5| Step: 2
Training loss: 2.4808442559950556
Validation loss: 2.568686650338873

Epoch: 5| Step: 3
Training loss: 2.4733270636150895
Validation loss: 2.542359970203894

Epoch: 5| Step: 4
Training loss: 2.2349855882491494
Validation loss: 2.531328180463672

Epoch: 5| Step: 5
Training loss: 1.3691361844892773
Validation loss: 2.5253991178255197

Epoch: 5| Step: 6
Training loss: 1.5953015273834896
Validation loss: 2.547304710069215

Epoch: 5| Step: 7
Training loss: 2.3111667398131943
Validation loss: 2.5110275005549814

Epoch: 5| Step: 8
Training loss: 1.338840921201367
Validation loss: 2.538078410837213

Epoch: 5| Step: 9
Training loss: 2.532121861386344
Validation loss: 2.540964582020001

Epoch: 5| Step: 10
Training loss: 1.663772557748392
Validation loss: 2.569938342564522

Epoch: 5| Step: 11
Training loss: 1.327116190425237
Validation loss: 2.5597681587385606

Epoch: 326| Step: 0
Training loss: 2.391911478394904
Validation loss: 2.590339060925752

Epoch: 5| Step: 1
Training loss: 1.6868327199040707
Validation loss: 2.5901673710747257

Epoch: 5| Step: 2
Training loss: 2.1260501286364577
Validation loss: 2.5491864962168727

Epoch: 5| Step: 3
Training loss: 2.4974318665154738
Validation loss: 2.568659412182048

Epoch: 5| Step: 4
Training loss: 1.4475885563775703
Validation loss: 2.5581617694408307

Epoch: 5| Step: 5
Training loss: 2.4572012498323645
Validation loss: 2.5612834934870143

Epoch: 5| Step: 6
Training loss: 1.7702946311001735
Validation loss: 2.531754082459078

Epoch: 5| Step: 7
Training loss: 2.413363358572531
Validation loss: 2.538898413809191

Epoch: 5| Step: 8
Training loss: 2.3686714179459014
Validation loss: 2.5323778041833678

Epoch: 5| Step: 9
Training loss: 2.393511656207439
Validation loss: 2.5683250511979874

Epoch: 5| Step: 10
Training loss: 1.9705991991690925
Validation loss: 2.571338232458632

Epoch: 5| Step: 11
Training loss: 1.1477475331919125
Validation loss: 2.588158897074136

Epoch: 327| Step: 0
Training loss: 2.0784505718154525
Validation loss: 2.5841137869739903

Epoch: 5| Step: 1
Training loss: 1.8403999799864779
Validation loss: 2.6125637223109357

Epoch: 5| Step: 2
Training loss: 2.5199840996255753
Validation loss: 2.5834975856944205

Epoch: 5| Step: 3
Training loss: 2.088175055718264
Validation loss: 2.5589991474030933

Epoch: 5| Step: 4
Training loss: 2.0243952189487215
Validation loss: 2.5334654206319636

Epoch: 5| Step: 5
Training loss: 1.7474279576024008
Validation loss: 2.51949662768802

Epoch: 5| Step: 6
Training loss: 2.032438194770991
Validation loss: 2.508072133553148

Epoch: 5| Step: 7
Training loss: 1.7785983509820904
Validation loss: 2.5190691383689843

Epoch: 5| Step: 8
Training loss: 1.8883775957154978
Validation loss: 2.525695754811786

Epoch: 5| Step: 9
Training loss: 2.390668581895687
Validation loss: 2.544578734046482

Epoch: 5| Step: 10
Training loss: 2.5054899019134136
Validation loss: 2.561664588559643

Epoch: 5| Step: 11
Training loss: 4.35608332792646
Validation loss: 2.585904346879723

Epoch: 328| Step: 0
Training loss: 2.0711420664409053
Validation loss: 2.6116068027249257

Epoch: 5| Step: 1
Training loss: 2.118233172642153
Validation loss: 2.614870182325839

Epoch: 5| Step: 2
Training loss: 2.1148164993294767
Validation loss: 2.6158874699059353

Epoch: 5| Step: 3
Training loss: 2.963083581544446
Validation loss: 2.5974315211479087

Epoch: 5| Step: 4
Training loss: 1.456880290620379
Validation loss: 2.5737197423190463

Epoch: 5| Step: 5
Training loss: 2.1684464211946297
Validation loss: 2.543145979776546

Epoch: 5| Step: 6
Training loss: 1.858568417287096
Validation loss: 2.5536282411099407

Epoch: 5| Step: 7
Training loss: 2.6175106019950323
Validation loss: 2.524052351143689

Epoch: 5| Step: 8
Training loss: 2.171447821671622
Validation loss: 2.5371625080765767

Epoch: 5| Step: 9
Training loss: 1.6815421577361713
Validation loss: 2.5371807735382297

Epoch: 5| Step: 10
Training loss: 1.373990945763997
Validation loss: 2.523523154050026

Epoch: 5| Step: 11
Training loss: 3.49046593886804
Validation loss: 2.524660591567273

Epoch: 329| Step: 0
Training loss: 1.9159530956085913
Validation loss: 2.518046502974179

Epoch: 5| Step: 1
Training loss: 2.4170248380054766
Validation loss: 2.5199373612868974

Epoch: 5| Step: 2
Training loss: 1.4817007771196147
Validation loss: 2.542976301253319

Epoch: 5| Step: 3
Training loss: 1.9910258178569777
Validation loss: 2.5158551033883323

Epoch: 5| Step: 4
Training loss: 2.8258369421328875
Validation loss: 2.5176559448052607

Epoch: 5| Step: 5
Training loss: 1.9719412234834208
Validation loss: 2.517601078186283

Epoch: 5| Step: 6
Training loss: 2.373035923810894
Validation loss: 2.5389651079328233

Epoch: 5| Step: 7
Training loss: 2.2374827506823
Validation loss: 2.5469995245886285

Epoch: 5| Step: 8
Training loss: 2.129962288249544
Validation loss: 2.557916981732845

Epoch: 5| Step: 9
Training loss: 1.7743228265361786
Validation loss: 2.5817042579914435

Epoch: 5| Step: 10
Training loss: 1.5152275114796456
Validation loss: 2.561577937304692

Epoch: 5| Step: 11
Training loss: 2.9838150857283887
Validation loss: 2.580468867493751

Epoch: 330| Step: 0
Training loss: 2.233998833849815
Validation loss: 2.548496034699563

Epoch: 5| Step: 1
Training loss: 1.7540912488127227
Validation loss: 2.5428229864938054

Epoch: 5| Step: 2
Training loss: 1.7800521838650447
Validation loss: 2.5308993689302324

Epoch: 5| Step: 3
Training loss: 1.6928534186369968
Validation loss: 2.5361535961742447

Epoch: 5| Step: 4
Training loss: 1.78620609322917
Validation loss: 2.525141653330263

Epoch: 5| Step: 5
Training loss: 1.870756688349828
Validation loss: 2.5192820502165483

Epoch: 5| Step: 6
Training loss: 2.7796055078877613
Validation loss: 2.5276748346028826

Epoch: 5| Step: 7
Training loss: 2.3083050800710647
Validation loss: 2.5322101404668

Epoch: 5| Step: 8
Training loss: 2.5496045797100417
Validation loss: 2.5587698218256985

Epoch: 5| Step: 9
Training loss: 2.3469459614394084
Validation loss: 2.568657018242487

Epoch: 5| Step: 10
Training loss: 1.9803549227836614
Validation loss: 2.546168484819519

Epoch: 5| Step: 11
Training loss: 2.6222774374082225
Validation loss: 2.569541106181477

Epoch: 331| Step: 0
Training loss: 2.3797279279334282
Validation loss: 2.5428640614576703

Epoch: 5| Step: 1
Training loss: 2.0056385189847767
Validation loss: 2.500692804026387

Epoch: 5| Step: 2
Training loss: 1.8994809646395712
Validation loss: 2.4933468684032665

Epoch: 5| Step: 3
Training loss: 2.1359773845618353
Validation loss: 2.4830194809912847

Epoch: 5| Step: 4
Training loss: 2.1829019450359755
Validation loss: 2.472692315600436

Epoch: 5| Step: 5
Training loss: 2.1263071415582697
Validation loss: 2.492887807129951

Epoch: 5| Step: 6
Training loss: 1.9746169213698839
Validation loss: 2.515013405199772

Epoch: 5| Step: 7
Training loss: 2.3796641077506195
Validation loss: 2.5165519901910254

Epoch: 5| Step: 8
Training loss: 2.2270200025108107
Validation loss: 2.535974154126169

Epoch: 5| Step: 9
Training loss: 2.347248162521893
Validation loss: 2.5940744779226237

Epoch: 5| Step: 10
Training loss: 1.7651878423397032
Validation loss: 2.5783343490219663

Epoch: 5| Step: 11
Training loss: 1.888389526848657
Validation loss: 2.6084947414751007

Epoch: 332| Step: 0
Training loss: 2.5467127648853207
Validation loss: 2.6355993725214684

Epoch: 5| Step: 1
Training loss: 1.698867586177086
Validation loss: 2.6274061396179813

Epoch: 5| Step: 2
Training loss: 2.0401393341651
Validation loss: 2.6212013779670778

Epoch: 5| Step: 3
Training loss: 1.7471078407005542
Validation loss: 2.5847153440683788

Epoch: 5| Step: 4
Training loss: 2.353685706866523
Validation loss: 2.570617781329931

Epoch: 5| Step: 5
Training loss: 2.1343085662645582
Validation loss: 2.511272155388027

Epoch: 5| Step: 6
Training loss: 2.421687555750283
Validation loss: 2.494473111806956

Epoch: 5| Step: 7
Training loss: 2.001461091402161
Validation loss: 2.498944131085479

Epoch: 5| Step: 8
Training loss: 2.386304953708198
Validation loss: 2.5029043255137573

Epoch: 5| Step: 9
Training loss: 2.1166597391250463
Validation loss: 2.500763414965448

Epoch: 5| Step: 10
Training loss: 2.1097948574844247
Validation loss: 2.5006419946966543

Epoch: 5| Step: 11
Training loss: 2.5667766147035116
Validation loss: 2.4973152646197603

Epoch: 333| Step: 0
Training loss: 1.7226961092327413
Validation loss: 2.517606424824174

Epoch: 5| Step: 1
Training loss: 2.1643407759795754
Validation loss: 2.551112567751757

Epoch: 5| Step: 2
Training loss: 2.1163588587910485
Validation loss: 2.5702562451607847

Epoch: 5| Step: 3
Training loss: 2.4723606987602293
Validation loss: 2.5840259490029007

Epoch: 5| Step: 4
Training loss: 2.010977895667377
Validation loss: 2.6087227118368324

Epoch: 5| Step: 5
Training loss: 1.8936797125837617
Validation loss: 2.596843617230898

Epoch: 5| Step: 6
Training loss: 2.268198170032239
Validation loss: 2.5535820485369625

Epoch: 5| Step: 7
Training loss: 2.077593283641889
Validation loss: 2.549163772874004

Epoch: 5| Step: 8
Training loss: 2.3242450103558494
Validation loss: 2.5370712257827677

Epoch: 5| Step: 9
Training loss: 1.5658319424062537
Validation loss: 2.5180826956524314

Epoch: 5| Step: 10
Training loss: 2.724207257092593
Validation loss: 2.5193962711580387

Epoch: 5| Step: 11
Training loss: 1.8747108872359026
Validation loss: 2.5189538259520847

Epoch: 334| Step: 0
Training loss: 2.1220896369345614
Validation loss: 2.530304641953275

Epoch: 5| Step: 1
Training loss: 2.299584898600524
Validation loss: 2.5563154642789856

Epoch: 5| Step: 2
Training loss: 1.5805074252394966
Validation loss: 2.539627841708606

Epoch: 5| Step: 3
Training loss: 2.099795027220884
Validation loss: 2.5462987360958653

Epoch: 5| Step: 4
Training loss: 2.8254633228174146
Validation loss: 2.5453861717676216

Epoch: 5| Step: 5
Training loss: 1.6244550671572953
Validation loss: 2.5648949332837865

Epoch: 5| Step: 6
Training loss: 2.139089437333242
Validation loss: 2.566181302675543

Epoch: 5| Step: 7
Training loss: 1.8716952764623622
Validation loss: 2.560828505022301

Epoch: 5| Step: 8
Training loss: 1.377824396751299
Validation loss: 2.5723000738704207

Epoch: 5| Step: 9
Training loss: 2.1772903879317815
Validation loss: 2.574007360397215

Epoch: 5| Step: 10
Training loss: 2.5475261768497335
Validation loss: 2.6155011338012897

Epoch: 5| Step: 11
Training loss: 1.6309073252681408
Validation loss: 2.6134007896525002

Epoch: 335| Step: 0
Training loss: 1.8663539542228418
Validation loss: 2.662551910270445

Epoch: 5| Step: 1
Training loss: 2.454335491114019
Validation loss: 2.6450624669612237

Epoch: 5| Step: 2
Training loss: 1.8052008753242965
Validation loss: 2.66380523229961

Epoch: 5| Step: 3
Training loss: 2.3454073323208475
Validation loss: 2.6304617404041832

Epoch: 5| Step: 4
Training loss: 1.7832583432458975
Validation loss: 2.6168183365275026

Epoch: 5| Step: 5
Training loss: 2.0824473468036286
Validation loss: 2.5945268218383553

Epoch: 5| Step: 6
Training loss: 2.736765138416441
Validation loss: 2.557123890880896

Epoch: 5| Step: 7
Training loss: 2.3510592609694227
Validation loss: 2.547284578961558

Epoch: 5| Step: 8
Training loss: 2.014528197908497
Validation loss: 2.540775978776208

Epoch: 5| Step: 9
Training loss: 2.1552520875344334
Validation loss: 2.534484400036253

Epoch: 5| Step: 10
Training loss: 1.4524056079284522
Validation loss: 2.546652505279366

Epoch: 5| Step: 11
Training loss: 1.2157632469665138
Validation loss: 2.5376711980260716

Epoch: 336| Step: 0
Training loss: 2.703060524232181
Validation loss: 2.5385821274413276

Epoch: 5| Step: 1
Training loss: 2.0483850630996447
Validation loss: 2.574083613165961

Epoch: 5| Step: 2
Training loss: 1.8363263956048415
Validation loss: 2.594229784027243

Epoch: 5| Step: 3
Training loss: 2.3093715848368377
Validation loss: 2.5913096058270115

Epoch: 5| Step: 4
Training loss: 1.8935636271304577
Validation loss: 2.6107165986048924

Epoch: 5| Step: 5
Training loss: 2.0532836759846265
Validation loss: 2.6328470320281134

Epoch: 5| Step: 6
Training loss: 2.3338342083621924
Validation loss: 2.6067257603201575

Epoch: 5| Step: 7
Training loss: 1.8115605517592919
Validation loss: 2.6133539031021646

Epoch: 5| Step: 8
Training loss: 1.779197045215033
Validation loss: 2.567546306757109

Epoch: 5| Step: 9
Training loss: 1.5058203468262386
Validation loss: 2.571422681126837

Epoch: 5| Step: 10
Training loss: 2.2887040726675156
Validation loss: 2.5736005867671228

Epoch: 5| Step: 11
Training loss: 4.002666538259702
Validation loss: 2.549050687034789

Epoch: 337| Step: 0
Training loss: 2.5450410383172115
Validation loss: 2.5372816521170045

Epoch: 5| Step: 1
Training loss: 2.532532731924514
Validation loss: 2.522747669865199

Epoch: 5| Step: 2
Training loss: 1.7751715832371984
Validation loss: 2.5180256684747024

Epoch: 5| Step: 3
Training loss: 1.7678885340139858
Validation loss: 2.5391195594049365

Epoch: 5| Step: 4
Training loss: 1.7866212271966335
Validation loss: 2.5260216479475

Epoch: 5| Step: 5
Training loss: 1.4148920481719962
Validation loss: 2.5427968386559674

Epoch: 5| Step: 6
Training loss: 2.1753414675254303
Validation loss: 2.543188953778328

Epoch: 5| Step: 7
Training loss: 2.6935286216312746
Validation loss: 2.5861927052520484

Epoch: 5| Step: 8
Training loss: 1.86900043659399
Validation loss: 2.574151323329767

Epoch: 5| Step: 9
Training loss: 1.6838101205945986
Validation loss: 2.5608593837080473

Epoch: 5| Step: 10
Training loss: 2.554119081868109
Validation loss: 2.541524735901924

Epoch: 5| Step: 11
Training loss: 1.4522863449563181
Validation loss: 2.540190449111526

Epoch: 338| Step: 0
Training loss: 1.8979731490282925
Validation loss: 2.5409093351268894

Epoch: 5| Step: 1
Training loss: 2.1108174231293955
Validation loss: 2.554851602539104

Epoch: 5| Step: 2
Training loss: 2.1893178743210813
Validation loss: 2.5270074328738557

Epoch: 5| Step: 3
Training loss: 2.041619462486105
Validation loss: 2.532710323277

Epoch: 5| Step: 4
Training loss: 1.8124451464541014
Validation loss: 2.5473788061504288

Epoch: 5| Step: 5
Training loss: 2.229466842928381
Validation loss: 2.5347040377506023

Epoch: 5| Step: 6
Training loss: 2.0581926392979364
Validation loss: 2.535963544165376

Epoch: 5| Step: 7
Training loss: 2.387233847118128
Validation loss: 2.5587451705582662

Epoch: 5| Step: 8
Training loss: 2.039528512136775
Validation loss: 2.5560791471507134

Epoch: 5| Step: 9
Training loss: 2.202207117081279
Validation loss: 2.574467605965138

Epoch: 5| Step: 10
Training loss: 2.0651924592265583
Validation loss: 2.6223606093363503

Epoch: 5| Step: 11
Training loss: 1.974985692419064
Validation loss: 2.628151284992438

Epoch: 339| Step: 0
Training loss: 2.036908060222842
Validation loss: 2.5868377155862188

Epoch: 5| Step: 1
Training loss: 2.1831804406405038
Validation loss: 2.566092914747706

Epoch: 5| Step: 2
Training loss: 1.9410675797290824
Validation loss: 2.526951692134278

Epoch: 5| Step: 3
Training loss: 2.1878293470680226
Validation loss: 2.5318440105318647

Epoch: 5| Step: 4
Training loss: 2.137999100444951
Validation loss: 2.5315624993909798

Epoch: 5| Step: 5
Training loss: 2.2502659534524114
Validation loss: 2.532216601800263

Epoch: 5| Step: 6
Training loss: 2.0888347721304408
Validation loss: 2.541931507247568

Epoch: 5| Step: 7
Training loss: 2.148924949141369
Validation loss: 2.545232547466744

Epoch: 5| Step: 8
Training loss: 2.01863925500162
Validation loss: 2.554117106028933

Epoch: 5| Step: 9
Training loss: 2.216853983811467
Validation loss: 2.6054963239576643

Epoch: 5| Step: 10
Training loss: 2.1005540434802668
Validation loss: 2.6103513988566656

Epoch: 5| Step: 11
Training loss: 1.614922822106138
Validation loss: 2.64213128175789

Epoch: 340| Step: 0
Training loss: 2.3119020462207263
Validation loss: 2.6229311987848267

Epoch: 5| Step: 1
Training loss: 1.8954243550704069
Validation loss: 2.62877190271656

Epoch: 5| Step: 2
Training loss: 1.9022090167011074
Validation loss: 2.6593180384738395

Epoch: 5| Step: 3
Training loss: 1.645174530417569
Validation loss: 2.601404446830692

Epoch: 5| Step: 4
Training loss: 2.3147994285354714
Validation loss: 2.590378354659379

Epoch: 5| Step: 5
Training loss: 2.8327891631303985
Validation loss: 2.5455417517325887

Epoch: 5| Step: 6
Training loss: 1.971229203234822
Validation loss: 2.529857519357064

Epoch: 5| Step: 7
Training loss: 1.7344477870204882
Validation loss: 2.531297385003786

Epoch: 5| Step: 8
Training loss: 2.145820160859303
Validation loss: 2.489180561561571

Epoch: 5| Step: 9
Training loss: 2.0993184300597596
Validation loss: 2.504685322869065

Epoch: 5| Step: 10
Training loss: 2.1363006126876845
Validation loss: 2.5013099179136087

Epoch: 5| Step: 11
Training loss: 1.5194336533768626
Validation loss: 2.509274144915098

Epoch: 341| Step: 0
Training loss: 2.734312045871279
Validation loss: 2.5291727121480956

Epoch: 5| Step: 1
Training loss: 2.151136000614477
Validation loss: 2.5747536396332142

Epoch: 5| Step: 2
Training loss: 1.9199437308013376
Validation loss: 2.5870552259681503

Epoch: 5| Step: 3
Training loss: 1.3953100855892946
Validation loss: 2.591183020294539

Epoch: 5| Step: 4
Training loss: 2.271236337254295
Validation loss: 2.6165926318922548

Epoch: 5| Step: 5
Training loss: 1.5655480219329816
Validation loss: 2.5659171170064794

Epoch: 5| Step: 6
Training loss: 1.8864725714458144
Validation loss: 2.5526263042165356

Epoch: 5| Step: 7
Training loss: 2.0126476920767518
Validation loss: 2.5592734368324868

Epoch: 5| Step: 8
Training loss: 2.382085470381343
Validation loss: 2.540205618953535

Epoch: 5| Step: 9
Training loss: 1.9153906748896485
Validation loss: 2.562113864617714

Epoch: 5| Step: 10
Training loss: 2.431242221535446
Validation loss: 2.528991115160774

Epoch: 5| Step: 11
Training loss: 1.4459723538595821
Validation loss: 2.567679922837835

Epoch: 342| Step: 0
Training loss: 2.210062777287836
Validation loss: 2.53334032881758

Epoch: 5| Step: 1
Training loss: 1.8910328448795404
Validation loss: 2.5562016688521365

Epoch: 5| Step: 2
Training loss: 2.044580935791716
Validation loss: 2.5490553714399518

Epoch: 5| Step: 3
Training loss: 1.7733159632776203
Validation loss: 2.5581685224891646

Epoch: 5| Step: 4
Training loss: 1.6407251963219134
Validation loss: 2.5746966484232323

Epoch: 5| Step: 5
Training loss: 2.6655149555634687
Validation loss: 2.614845324811109

Epoch: 5| Step: 6
Training loss: 2.2840035946779307
Validation loss: 2.606239178251613

Epoch: 5| Step: 7
Training loss: 2.3608864496595414
Validation loss: 2.575073181427211

Epoch: 5| Step: 8
Training loss: 2.0919023018848426
Validation loss: 2.5652484343311786

Epoch: 5| Step: 9
Training loss: 2.0791222036903982
Validation loss: 2.5449012488121916

Epoch: 5| Step: 10
Training loss: 1.5085613387511487
Validation loss: 2.5422273171246634

Epoch: 5| Step: 11
Training loss: 1.596386393169394
Validation loss: 2.5216995647786398

Epoch: 343| Step: 0
Training loss: 1.7155236219460326
Validation loss: 2.541354540644672

Epoch: 5| Step: 1
Training loss: 1.8540307184450164
Validation loss: 2.5090404011889547

Epoch: 5| Step: 2
Training loss: 2.295545439718894
Validation loss: 2.541702427899118

Epoch: 5| Step: 3
Training loss: 2.029177738397095
Validation loss: 2.5145136350776696

Epoch: 5| Step: 4
Training loss: 2.6430188225297107
Validation loss: 2.5398591889751434

Epoch: 5| Step: 5
Training loss: 2.2258741954545584
Validation loss: 2.521855361244347

Epoch: 5| Step: 6
Training loss: 1.600098922770898
Validation loss: 2.545661656750853

Epoch: 5| Step: 7
Training loss: 1.7892488607435235
Validation loss: 2.5532723492078415

Epoch: 5| Step: 8
Training loss: 2.44663600022364
Validation loss: 2.5581663400798647

Epoch: 5| Step: 9
Training loss: 1.8534797367524691
Validation loss: 2.5846093676941564

Epoch: 5| Step: 10
Training loss: 1.84428928053244
Validation loss: 2.5958070487829135

Epoch: 5| Step: 11
Training loss: 2.298688108058038
Validation loss: 2.6033247209724792

Epoch: 344| Step: 0
Training loss: 2.0703530361597604
Validation loss: 2.5818947290907066

Epoch: 5| Step: 1
Training loss: 2.223373324231405
Validation loss: 2.562934795956986

Epoch: 5| Step: 2
Training loss: 1.8235237055441305
Validation loss: 2.5403511767845877

Epoch: 5| Step: 3
Training loss: 2.267128912223271
Validation loss: 2.524620239574411

Epoch: 5| Step: 4
Training loss: 1.9733985033206864
Validation loss: 2.542904010657662

Epoch: 5| Step: 5
Training loss: 1.8562649273512999
Validation loss: 2.5255897760110084

Epoch: 5| Step: 6
Training loss: 2.381677175738474
Validation loss: 2.526563945668408

Epoch: 5| Step: 7
Training loss: 1.8044290729133148
Validation loss: 2.5207110695837134

Epoch: 5| Step: 8
Training loss: 2.003948843282108
Validation loss: 2.493227073190954

Epoch: 5| Step: 9
Training loss: 1.995913921101656
Validation loss: 2.507775251957661

Epoch: 5| Step: 10
Training loss: 2.0957350928436114
Validation loss: 2.5439569025147852

Epoch: 5| Step: 11
Training loss: 1.021131056882612
Validation loss: 2.595884945837519

Epoch: 345| Step: 0
Training loss: 2.351153873666862
Validation loss: 2.579477075088808

Epoch: 5| Step: 1
Training loss: 2.3018501013994688
Validation loss: 2.6127610308912805

Epoch: 5| Step: 2
Training loss: 2.2077080423167064
Validation loss: 2.6141841451976457

Epoch: 5| Step: 3
Training loss: 1.5985690542846525
Validation loss: 2.6055697031208647

Epoch: 5| Step: 4
Training loss: 2.097418006140042
Validation loss: 2.602893801829367

Epoch: 5| Step: 5
Training loss: 2.2721419690464857
Validation loss: 2.584364721054061

Epoch: 5| Step: 6
Training loss: 1.8957343302716387
Validation loss: 2.5423866031443905

Epoch: 5| Step: 7
Training loss: 1.5208847960382912
Validation loss: 2.5426912874189327

Epoch: 5| Step: 8
Training loss: 2.3062323096612554
Validation loss: 2.53343692936853

Epoch: 5| Step: 9
Training loss: 2.3249665411725866
Validation loss: 2.531064293567903

Epoch: 5| Step: 10
Training loss: 2.1135651967064466
Validation loss: 2.5356371148741257

Epoch: 5| Step: 11
Training loss: 1.1327678803173715
Validation loss: 2.518147293990069

Epoch: 346| Step: 0
Training loss: 2.165653456463811
Validation loss: 2.5102567555846016

Epoch: 5| Step: 1
Training loss: 2.544585901832398
Validation loss: 2.522613764933106

Epoch: 5| Step: 2
Training loss: 2.2724854878212972
Validation loss: 2.536795553915243

Epoch: 5| Step: 3
Training loss: 2.213584366928832
Validation loss: 2.548225914369169

Epoch: 5| Step: 4
Training loss: 2.0348860841401533
Validation loss: 2.544413490682065

Epoch: 5| Step: 5
Training loss: 1.5722340835345525
Validation loss: 2.5556472235515897

Epoch: 5| Step: 6
Training loss: 1.6551618060163964
Validation loss: 2.5807308937372357

Epoch: 5| Step: 7
Training loss: 2.1559313110138874
Validation loss: 2.6022956586410184

Epoch: 5| Step: 8
Training loss: 1.861781702486033
Validation loss: 2.577829370984894

Epoch: 5| Step: 9
Training loss: 1.7870267921919814
Validation loss: 2.596953592897597

Epoch: 5| Step: 10
Training loss: 1.940407632396206
Validation loss: 2.564172340549402

Epoch: 5| Step: 11
Training loss: 1.91891139342637
Validation loss: 2.54476967681199

Epoch: 347| Step: 0
Training loss: 1.7897841151812355
Validation loss: 2.5359274872029633

Epoch: 5| Step: 1
Training loss: 1.8896301426359212
Validation loss: 2.5441730692629108

Epoch: 5| Step: 2
Training loss: 1.2216154793653562
Validation loss: 2.5529934110313643

Epoch: 5| Step: 3
Training loss: 2.146771037820397
Validation loss: 2.587587274010194

Epoch: 5| Step: 4
Training loss: 2.266789945821576
Validation loss: 2.596231659830718

Epoch: 5| Step: 5
Training loss: 1.6585305545535098
Validation loss: 2.621454705798174

Epoch: 5| Step: 6
Training loss: 2.2961731960885587
Validation loss: 2.6112956898856865

Epoch: 5| Step: 7
Training loss: 2.0791946755805246
Validation loss: 2.6310806200264807

Epoch: 5| Step: 8
Training loss: 2.270795092712766
Validation loss: 2.6144675017658403

Epoch: 5| Step: 9
Training loss: 2.2076871994325487
Validation loss: 2.5983544771285607

Epoch: 5| Step: 10
Training loss: 2.508775187595439
Validation loss: 2.5732310227906514

Epoch: 5| Step: 11
Training loss: 1.5440467641893694
Validation loss: 2.5890334996970705

Epoch: 348| Step: 0
Training loss: 2.473471653233193
Validation loss: 2.5747661635632335

Epoch: 5| Step: 1
Training loss: 2.3810686578059936
Validation loss: 2.5725678479015244

Epoch: 5| Step: 2
Training loss: 2.0967554186224153
Validation loss: 2.5833024297424476

Epoch: 5| Step: 3
Training loss: 1.8417466481420246
Validation loss: 2.5809793219530595

Epoch: 5| Step: 4
Training loss: 1.9959499359579602
Validation loss: 2.6202565963080233

Epoch: 5| Step: 5
Training loss: 1.957817787595582
Validation loss: 2.601321269355482

Epoch: 5| Step: 6
Training loss: 2.0534764190872896
Validation loss: 2.5971696976389795

Epoch: 5| Step: 7
Training loss: 2.131646253156511
Validation loss: 2.6118133082775286

Epoch: 5| Step: 8
Training loss: 1.7870762222633587
Validation loss: 2.62350698049242

Epoch: 5| Step: 9
Training loss: 2.2571291829983227
Validation loss: 2.630137049146506

Epoch: 5| Step: 10
Training loss: 1.5300045008375
Validation loss: 2.6128310237197936

Epoch: 5| Step: 11
Training loss: 1.8027495180033346
Validation loss: 2.5877181200796966

Epoch: 349| Step: 0
Training loss: 2.0378748917443033
Validation loss: 2.59724334265088

Epoch: 5| Step: 1
Training loss: 1.4709514595700066
Validation loss: 2.6256922535681313

Epoch: 5| Step: 2
Training loss: 1.731099790811694
Validation loss: 2.636423553142936

Epoch: 5| Step: 3
Training loss: 2.0857867354297226
Validation loss: 2.6517842301420678

Epoch: 5| Step: 4
Training loss: 1.8087621490977377
Validation loss: 2.576532685196215

Epoch: 5| Step: 5
Training loss: 1.7597514669545267
Validation loss: 2.5444545126409923

Epoch: 5| Step: 6
Training loss: 2.579354472761506
Validation loss: 2.550747671096159

Epoch: 5| Step: 7
Training loss: 2.299468878913466
Validation loss: 2.557525695275191

Epoch: 5| Step: 8
Training loss: 2.3110823538816914
Validation loss: 2.5668877856779293

Epoch: 5| Step: 9
Training loss: 2.506954533588071
Validation loss: 2.539679502200234

Epoch: 5| Step: 10
Training loss: 1.8098444723256106
Validation loss: 2.5315589304184147

Epoch: 5| Step: 11
Training loss: 0.41242366937072467
Validation loss: 2.5394240175761977

Epoch: 350| Step: 0
Training loss: 2.529390758995995
Validation loss: 2.54229182752395

Epoch: 5| Step: 1
Training loss: 2.238698444465052
Validation loss: 2.5351667751726614

Epoch: 5| Step: 2
Training loss: 1.8140520488165244
Validation loss: 2.563817116050892

Epoch: 5| Step: 3
Training loss: 1.795835708592991
Validation loss: 2.5673880709437937

Epoch: 5| Step: 4
Training loss: 2.5253025402452844
Validation loss: 2.5517063965394353

Epoch: 5| Step: 5
Training loss: 2.265156875129251
Validation loss: 2.568318955329424

Epoch: 5| Step: 6
Training loss: 1.5568453128883193
Validation loss: 2.5535432467523567

Epoch: 5| Step: 7
Training loss: 2.195858273252939
Validation loss: 2.5909501786221423

Epoch: 5| Step: 8
Training loss: 2.087435866415763
Validation loss: 2.579309611347063

Epoch: 5| Step: 9
Training loss: 1.9100923430004797
Validation loss: 2.5919786440772596

Epoch: 5| Step: 10
Training loss: 1.3842527141768344
Validation loss: 2.5868597585360127

Epoch: 5| Step: 11
Training loss: 1.6856155469924254
Validation loss: 2.6059168516543276

Epoch: 351| Step: 0
Training loss: 1.4168632969248838
Validation loss: 2.5668460463309004

Epoch: 5| Step: 1
Training loss: 1.927679955855492
Validation loss: 2.6091070208884264

Epoch: 5| Step: 2
Training loss: 2.6408955813488983
Validation loss: 2.6034054018590163

Epoch: 5| Step: 3
Training loss: 1.579543656347535
Validation loss: 2.6313896749216914

Epoch: 5| Step: 4
Training loss: 2.0758482428706584
Validation loss: 2.6263303413188477

Epoch: 5| Step: 5
Training loss: 1.8847532914306624
Validation loss: 2.61313281091476

Epoch: 5| Step: 6
Training loss: 1.5054641383070257
Validation loss: 2.589844935260116

Epoch: 5| Step: 7
Training loss: 2.221262731306335
Validation loss: 2.587612865584842

Epoch: 5| Step: 8
Training loss: 2.1193252412742134
Validation loss: 2.588947311690605

Epoch: 5| Step: 9
Training loss: 2.6302319113300925
Validation loss: 2.560064321246335

Epoch: 5| Step: 10
Training loss: 2.2101651517514154
Validation loss: 2.55667982272958

Epoch: 5| Step: 11
Training loss: 1.5152356935727942
Validation loss: 2.531706959093225

Epoch: 352| Step: 0
Training loss: 2.0675068972563637
Validation loss: 2.5531822498553267

Epoch: 5| Step: 1
Training loss: 2.0071181941105
Validation loss: 2.506359875934915

Epoch: 5| Step: 2
Training loss: 2.0031351312390053
Validation loss: 2.521068772179537

Epoch: 5| Step: 3
Training loss: 1.8899828868676531
Validation loss: 2.5467612898392153

Epoch: 5| Step: 4
Training loss: 2.057609308243101
Validation loss: 2.574652813218136

Epoch: 5| Step: 5
Training loss: 1.7746101569162032
Validation loss: 2.5992143055165324

Epoch: 5| Step: 6
Training loss: 1.7210016240672505
Validation loss: 2.585822288197827

Epoch: 5| Step: 7
Training loss: 2.31551092899044
Validation loss: 2.6162527778016575

Epoch: 5| Step: 8
Training loss: 2.459429566530542
Validation loss: 2.5638154847876686

Epoch: 5| Step: 9
Training loss: 2.1413736635252616
Validation loss: 2.586415812270493

Epoch: 5| Step: 10
Training loss: 2.2417099075212117
Validation loss: 2.566004874139692

Epoch: 5| Step: 11
Training loss: 0.5634070077474514
Validation loss: 2.556137882593754

Epoch: 353| Step: 0
Training loss: 1.6488538460350926
Validation loss: 2.5416433471381192

Epoch: 5| Step: 1
Training loss: 1.7328055213945925
Validation loss: 2.52625115040497

Epoch: 5| Step: 2
Training loss: 1.582420772117997
Validation loss: 2.528734047814723

Epoch: 5| Step: 3
Training loss: 2.2488893310741616
Validation loss: 2.510125041711865

Epoch: 5| Step: 4
Training loss: 2.2007821253354
Validation loss: 2.5097499505529504

Epoch: 5| Step: 5
Training loss: 2.092170689054474
Validation loss: 2.517895459796969

Epoch: 5| Step: 6
Training loss: 1.6383077332807816
Validation loss: 2.527631889635084

Epoch: 5| Step: 7
Training loss: 2.684225527206722
Validation loss: 2.5180239878201944

Epoch: 5| Step: 8
Training loss: 2.0987915149465586
Validation loss: 2.567608428363038

Epoch: 5| Step: 9
Training loss: 1.9878122792141135
Validation loss: 2.6058197776345065

Epoch: 5| Step: 10
Training loss: 2.1053657011105216
Validation loss: 2.589236430386582

Epoch: 5| Step: 11
Training loss: 1.309309442012442
Validation loss: 2.618021036140297

Epoch: 354| Step: 0
Training loss: 2.55351206951527
Validation loss: 2.6119326317629916

Epoch: 5| Step: 1
Training loss: 1.57091355089456
Validation loss: 2.577911395076847

Epoch: 5| Step: 2
Training loss: 1.9532259495395903
Validation loss: 2.5793931905235827

Epoch: 5| Step: 3
Training loss: 1.9538830316102853
Validation loss: 2.5566423288392603

Epoch: 5| Step: 4
Training loss: 2.046479165044547
Validation loss: 2.5497091512364296

Epoch: 5| Step: 5
Training loss: 1.6920228323241389
Validation loss: 2.5465810504711563

Epoch: 5| Step: 6
Training loss: 1.6340114444439275
Validation loss: 2.561217498833727

Epoch: 5| Step: 7
Training loss: 1.6402743010125642
Validation loss: 2.6002411259811296

Epoch: 5| Step: 8
Training loss: 2.0331184596775325
Validation loss: 2.5848918579386644

Epoch: 5| Step: 9
Training loss: 2.381390957402478
Validation loss: 2.586408535716981

Epoch: 5| Step: 10
Training loss: 2.220687450128826
Validation loss: 2.6061634241448135

Epoch: 5| Step: 11
Training loss: 2.612532390046904
Validation loss: 2.5834243448181757

Epoch: 355| Step: 0
Training loss: 2.1432825006930605
Validation loss: 2.6023782247403062

Epoch: 5| Step: 1
Training loss: 1.4944437754147784
Validation loss: 2.5560050759191713

Epoch: 5| Step: 2
Training loss: 1.9750908359933232
Validation loss: 2.536991937947548

Epoch: 5| Step: 3
Training loss: 2.267345117496659
Validation loss: 2.5749570475702632

Epoch: 5| Step: 4
Training loss: 2.449391920182641
Validation loss: 2.5969626856022816

Epoch: 5| Step: 5
Training loss: 1.8254664073309657
Validation loss: 2.5712066301055008

Epoch: 5| Step: 6
Training loss: 1.7026609436009672
Validation loss: 2.5628948275785484

Epoch: 5| Step: 7
Training loss: 2.1292688463431113
Validation loss: 2.5335555271430055

Epoch: 5| Step: 8
Training loss: 1.9549197686359379
Validation loss: 2.5520918995200956

Epoch: 5| Step: 9
Training loss: 1.7000689604740837
Validation loss: 2.5362226656103037

Epoch: 5| Step: 10
Training loss: 2.1722531435435903
Validation loss: 2.552255803073874

Epoch: 5| Step: 11
Training loss: 2.368515397585296
Validation loss: 2.535183722724825

Epoch: 356| Step: 0
Training loss: 1.265694321982689
Validation loss: 2.570092656590327

Epoch: 5| Step: 1
Training loss: 1.8810252971093926
Validation loss: 2.624924083399099

Epoch: 5| Step: 2
Training loss: 2.3046214983266378
Validation loss: 2.709999515843084

Epoch: 5| Step: 3
Training loss: 2.2922634619235263
Validation loss: 2.718499515584856

Epoch: 5| Step: 4
Training loss: 2.071431789489652
Validation loss: 2.6195019674935125

Epoch: 5| Step: 5
Training loss: 2.8621029374373146
Validation loss: 2.572299602711852

Epoch: 5| Step: 6
Training loss: 2.0522684572114556
Validation loss: 2.494785166806943

Epoch: 5| Step: 7
Training loss: 2.6627201938466976
Validation loss: 2.519098202259502

Epoch: 5| Step: 8
Training loss: 2.1217255889469966
Validation loss: 2.498198307031634

Epoch: 5| Step: 9
Training loss: 1.819632996875098
Validation loss: 2.4942474860129322

Epoch: 5| Step: 10
Training loss: 2.0329312922420795
Validation loss: 2.488617747024604

Epoch: 5| Step: 11
Training loss: 1.7174741691412656
Validation loss: 2.4896156868900654

Epoch: 357| Step: 0
Training loss: 1.980534539268003
Validation loss: 2.4863437473298764

Epoch: 5| Step: 1
Training loss: 1.7361247541103482
Validation loss: 2.4725418948245648

Epoch: 5| Step: 2
Training loss: 2.572843656134658
Validation loss: 2.4736963929826463

Epoch: 5| Step: 3
Training loss: 2.1986477857711693
Validation loss: 2.4828553020228092

Epoch: 5| Step: 4
Training loss: 2.0974776833112014
Validation loss: 2.4707228547968314

Epoch: 5| Step: 5
Training loss: 2.1677397735921127
Validation loss: 2.4851689419606684

Epoch: 5| Step: 6
Training loss: 2.650008914140787
Validation loss: 2.484479833986162

Epoch: 5| Step: 7
Training loss: 2.831385634922848
Validation loss: 2.5054399511499894

Epoch: 5| Step: 8
Training loss: 2.414623207726317
Validation loss: 2.5242540083712917

Epoch: 5| Step: 9
Training loss: 1.6024366272820139
Validation loss: 2.5127110239232815

Epoch: 5| Step: 10
Training loss: 2.1935732865413304
Validation loss: 2.5526026502312997

Epoch: 5| Step: 11
Training loss: 2.267739197417746
Validation loss: 2.5298018571225915

Epoch: 358| Step: 0
Training loss: 2.0944061389908892
Validation loss: 2.5395551487237777

Epoch: 5| Step: 1
Training loss: 2.3693254843699734
Validation loss: 2.5339346373359444

Epoch: 5| Step: 2
Training loss: 1.792222476474917
Validation loss: 2.5444545399705243

Epoch: 5| Step: 3
Training loss: 2.4834546957720303
Validation loss: 2.5285098349983617

Epoch: 5| Step: 4
Training loss: 2.003462773974211
Validation loss: 2.5125656559021934

Epoch: 5| Step: 5
Training loss: 2.16816185443485
Validation loss: 2.519601691786703

Epoch: 5| Step: 6
Training loss: 1.926256782673276
Validation loss: 2.4922523450238043

Epoch: 5| Step: 7
Training loss: 3.365075956170365
Validation loss: 2.5182200211073216

Epoch: 5| Step: 8
Training loss: 1.7463265419570875
Validation loss: 2.5302761661382815

Epoch: 5| Step: 9
Training loss: 1.8846868152645628
Validation loss: 2.5222966200568626

Epoch: 5| Step: 10
Training loss: 1.7652569952754462
Validation loss: 2.531824568697666

Epoch: 5| Step: 11
Training loss: 2.088818450116622
Validation loss: 2.581314637681042

Epoch: 359| Step: 0
Training loss: 2.246968027876307
Validation loss: 2.598513572161964

Epoch: 5| Step: 1
Training loss: 2.071465052673354
Validation loss: 2.6536143260179714

Epoch: 5| Step: 2
Training loss: 2.5491560567897125
Validation loss: 2.665144133042937

Epoch: 5| Step: 3
Training loss: 2.094801112273356
Validation loss: 2.649106709150879

Epoch: 5| Step: 4
Training loss: 1.8726160789131088
Validation loss: 2.607979745989291

Epoch: 5| Step: 5
Training loss: 2.265700240365683
Validation loss: 2.590365894706294

Epoch: 5| Step: 6
Training loss: 1.2730381813466483
Validation loss: 2.5792788264446016

Epoch: 5| Step: 7
Training loss: 2.6718494793303296
Validation loss: 2.5565676444380787

Epoch: 5| Step: 8
Training loss: 2.344831090183619
Validation loss: 2.5549670425200492

Epoch: 5| Step: 9
Training loss: 2.002558740332949
Validation loss: 2.542991477915527

Epoch: 5| Step: 10
Training loss: 1.5202538505446468
Validation loss: 2.5335196731345104

Epoch: 5| Step: 11
Training loss: 2.3432819153347952
Validation loss: 2.5664352345680617

Epoch: 360| Step: 0
Training loss: 2.133366998267784
Validation loss: 2.5637867108386754

Epoch: 5| Step: 1
Training loss: 1.8353178886075954
Validation loss: 2.537727030180048

Epoch: 5| Step: 2
Training loss: 2.836175577558322
Validation loss: 2.5847513449907944

Epoch: 5| Step: 3
Training loss: 1.3702014073367026
Validation loss: 2.591764371774024

Epoch: 5| Step: 4
Training loss: 2.169310997953282
Validation loss: 2.5816045765421776

Epoch: 5| Step: 5
Training loss: 1.7536777950765934
Validation loss: 2.588279631545381

Epoch: 5| Step: 6
Training loss: 2.0334449059981883
Validation loss: 2.573751813404049

Epoch: 5| Step: 7
Training loss: 1.5673148167202062
Validation loss: 2.5296737213419256

Epoch: 5| Step: 8
Training loss: 2.6444853605405036
Validation loss: 2.557013798914528

Epoch: 5| Step: 9
Training loss: 2.190695472269407
Validation loss: 2.532671935212773

Epoch: 5| Step: 10
Training loss: 2.0371839266454725
Validation loss: 2.5160212076432478

Epoch: 5| Step: 11
Training loss: 2.054420134695859
Validation loss: 2.520624338634381

Epoch: 361| Step: 0
Training loss: 2.1327185976924756
Validation loss: 2.5035483113872856

Epoch: 5| Step: 1
Training loss: 1.9913268979269447
Validation loss: 2.5019279278199344

Epoch: 5| Step: 2
Training loss: 2.1538281315531598
Validation loss: 2.52042428289259

Epoch: 5| Step: 3
Training loss: 1.5667374182342466
Validation loss: 2.5206447457213983

Epoch: 5| Step: 4
Training loss: 2.286748869097747
Validation loss: 2.5213281813077506

Epoch: 5| Step: 5
Training loss: 2.0002965707238536
Validation loss: 2.537253319208055

Epoch: 5| Step: 6
Training loss: 1.9575704414292092
Validation loss: 2.5376666472354534

Epoch: 5| Step: 7
Training loss: 2.2368774272503704
Validation loss: 2.5204532641528927

Epoch: 5| Step: 8
Training loss: 1.8307945127658736
Validation loss: 2.5573199763288157

Epoch: 5| Step: 9
Training loss: 2.3103894061540466
Validation loss: 2.5872147316867817

Epoch: 5| Step: 10
Training loss: 1.7136459164276143
Validation loss: 2.578497187404

Epoch: 5| Step: 11
Training loss: 2.0958450994546816
Validation loss: 2.5946644967145396

Epoch: 362| Step: 0
Training loss: 2.5010090698846463
Validation loss: 2.576576490346889

Epoch: 5| Step: 1
Training loss: 1.3202238786739398
Validation loss: 2.5662828219309657

Epoch: 5| Step: 2
Training loss: 1.5888513565447113
Validation loss: 2.553282764685628

Epoch: 5| Step: 3
Training loss: 2.1840459529387974
Validation loss: 2.5703493790072716

Epoch: 5| Step: 4
Training loss: 1.9493498672083358
Validation loss: 2.555736645183009

Epoch: 5| Step: 5
Training loss: 2.6288167362929498
Validation loss: 2.5401956289246868

Epoch: 5| Step: 6
Training loss: 2.1618850715713602
Validation loss: 2.5420227517903857

Epoch: 5| Step: 7
Training loss: 2.2584945546089417
Validation loss: 2.557748622947235

Epoch: 5| Step: 8
Training loss: 1.593875057325466
Validation loss: 2.545455037515353

Epoch: 5| Step: 9
Training loss: 1.9287298505797368
Validation loss: 2.5606185588797556

Epoch: 5| Step: 10
Training loss: 2.322168808596062
Validation loss: 2.5779153873503526

Epoch: 5| Step: 11
Training loss: 1.1292509193002853
Validation loss: 2.602929765051484

Epoch: 363| Step: 0
Training loss: 2.316438877332664
Validation loss: 2.6163785225055958

Epoch: 5| Step: 1
Training loss: 1.4457216250811125
Validation loss: 2.6767427559315133

Epoch: 5| Step: 2
Training loss: 1.7774318798977928
Validation loss: 2.7163651848081574

Epoch: 5| Step: 3
Training loss: 1.7204069993398903
Validation loss: 2.719318458350992

Epoch: 5| Step: 4
Training loss: 2.2734041506494047
Validation loss: 2.729691658169702

Epoch: 5| Step: 5
Training loss: 1.7096690871638756
Validation loss: 2.7315078308130083

Epoch: 5| Step: 6
Training loss: 2.5598857849689667
Validation loss: 2.6858594233963564

Epoch: 5| Step: 7
Training loss: 2.206181779622606
Validation loss: 2.6382922151891384

Epoch: 5| Step: 8
Training loss: 1.7029319443782356
Validation loss: 2.6683995209569726

Epoch: 5| Step: 9
Training loss: 2.4450196892193254
Validation loss: 2.6255341130269985

Epoch: 5| Step: 10
Training loss: 1.831805965667683
Validation loss: 2.6290146917278694

Epoch: 5| Step: 11
Training loss: 1.3757298006643728
Validation loss: 2.6020982379705346

Epoch: 364| Step: 0
Training loss: 1.5410737968266235
Validation loss: 2.574544879204082

Epoch: 5| Step: 1
Training loss: 1.8497316990717938
Validation loss: 2.5463587192789383

Epoch: 5| Step: 2
Training loss: 1.6818145059503222
Validation loss: 2.5213197653906514

Epoch: 5| Step: 3
Training loss: 2.3661118886937946
Validation loss: 2.5244332623320376

Epoch: 5| Step: 4
Training loss: 2.59362038897502
Validation loss: 2.5470471158212242

Epoch: 5| Step: 5
Training loss: 2.124762353511311
Validation loss: 2.5229342483382498

Epoch: 5| Step: 6
Training loss: 2.06824064409281
Validation loss: 2.546310588494723

Epoch: 5| Step: 7
Training loss: 1.974352600125158
Validation loss: 2.582097101261535

Epoch: 5| Step: 8
Training loss: 1.7080503865209267
Validation loss: 2.5837549428272752

Epoch: 5| Step: 9
Training loss: 1.732186388527756
Validation loss: 2.623741508607662

Epoch: 5| Step: 10
Training loss: 1.717684328718464
Validation loss: 2.67227818977247

Epoch: 5| Step: 11
Training loss: 2.3841017940281684
Validation loss: 2.7049358013735385

Epoch: 365| Step: 0
Training loss: 2.319904124482206
Validation loss: 2.683593923984246

Epoch: 5| Step: 1
Training loss: 2.489011169402402
Validation loss: 2.6906353086716392

Epoch: 5| Step: 2
Training loss: 1.7316779396172393
Validation loss: 2.7071985520576827

Epoch: 5| Step: 3
Training loss: 2.196093980157461
Validation loss: 2.6626920409933197

Epoch: 5| Step: 4
Training loss: 1.9931549116912366
Validation loss: 2.579502277282806

Epoch: 5| Step: 5
Training loss: 1.9525807957655195
Validation loss: 2.559859431109182

Epoch: 5| Step: 6
Training loss: 1.5683140730342395
Validation loss: 2.5485583633960687

Epoch: 5| Step: 7
Training loss: 1.9852236637587477
Validation loss: 2.5405094972876037

Epoch: 5| Step: 8
Training loss: 2.4602867598212526
Validation loss: 2.508719758486788

Epoch: 5| Step: 9
Training loss: 1.9456669128393413
Validation loss: 2.5229084456289104

Epoch: 5| Step: 10
Training loss: 1.9206659499227414
Validation loss: 2.529668812548245

Epoch: 5| Step: 11
Training loss: 2.0596272662822233
Validation loss: 2.5264640625363683

Epoch: 366| Step: 0
Training loss: 1.8940505843613007
Validation loss: 2.5168590480544273

Epoch: 5| Step: 1
Training loss: 1.4676888061408462
Validation loss: 2.5057852881032865

Epoch: 5| Step: 2
Training loss: 2.3593117408608735
Validation loss: 2.5212303287758107

Epoch: 5| Step: 3
Training loss: 2.3125397962290437
Validation loss: 2.5262582168307053

Epoch: 5| Step: 4
Training loss: 1.685652675380252
Validation loss: 2.5732920729297417

Epoch: 5| Step: 5
Training loss: 1.9427108219188742
Validation loss: 2.552744454108812

Epoch: 5| Step: 6
Training loss: 2.3182875920200163
Validation loss: 2.5595929919706495

Epoch: 5| Step: 7
Training loss: 1.5965891961169054
Validation loss: 2.556774080551198

Epoch: 5| Step: 8
Training loss: 1.8037640739838252
Validation loss: 2.564356588777452

Epoch: 5| Step: 9
Training loss: 1.8450619184240413
Validation loss: 2.5476336256214083

Epoch: 5| Step: 10
Training loss: 2.267445431423844
Validation loss: 2.557645355026777

Epoch: 5| Step: 11
Training loss: 3.080215131751926
Validation loss: 2.5511872152041444

Epoch: 367| Step: 0
Training loss: 2.5104163606466736
Validation loss: 2.554512539004328

Epoch: 5| Step: 1
Training loss: 2.1075652094082304
Validation loss: 2.5676852425755055

Epoch: 5| Step: 2
Training loss: 1.5281987833570139
Validation loss: 2.5569377208791457

Epoch: 5| Step: 3
Training loss: 1.9589043521986014
Validation loss: 2.528165433110024

Epoch: 5| Step: 4
Training loss: 1.7806520629625782
Validation loss: 2.529040869837117

Epoch: 5| Step: 5
Training loss: 1.881079925250563
Validation loss: 2.5336928451846683

Epoch: 5| Step: 6
Training loss: 1.9727423016503456
Validation loss: 2.519069528781676

Epoch: 5| Step: 7
Training loss: 2.0792702408897354
Validation loss: 2.5206653812250135

Epoch: 5| Step: 8
Training loss: 2.259984750105458
Validation loss: 2.5190991605340356

Epoch: 5| Step: 9
Training loss: 1.9250376660513822
Validation loss: 2.5004794455781045

Epoch: 5| Step: 10
Training loss: 2.2430509705655766
Validation loss: 2.5496830623298368

Epoch: 5| Step: 11
Training loss: 1.4056594456327456
Validation loss: 2.5489062378899985

Epoch: 368| Step: 0
Training loss: 2.0806930850787277
Validation loss: 2.606887130099366

Epoch: 5| Step: 1
Training loss: 2.207291039224787
Validation loss: 2.6197010856323772

Epoch: 5| Step: 2
Training loss: 2.15439249277829
Validation loss: 2.645010156810275

Epoch: 5| Step: 3
Training loss: 1.7648063044398248
Validation loss: 2.6234632262467477

Epoch: 5| Step: 4
Training loss: 1.5032546179830704
Validation loss: 2.617104231994866

Epoch: 5| Step: 5
Training loss: 1.8988117116074714
Validation loss: 2.6199291615337184

Epoch: 5| Step: 6
Training loss: 2.2654784056493726
Validation loss: 2.5822321457265462

Epoch: 5| Step: 7
Training loss: 2.043289071931779
Validation loss: 2.5699247630123825

Epoch: 5| Step: 8
Training loss: 2.184237199401547
Validation loss: 2.5660687422562134

Epoch: 5| Step: 9
Training loss: 2.0357379338317836
Validation loss: 2.542557670935691

Epoch: 5| Step: 10
Training loss: 2.2728028345551583
Validation loss: 2.538642844708037

Epoch: 5| Step: 11
Training loss: 1.385841113397655
Validation loss: 2.535528048939726

Epoch: 369| Step: 0
Training loss: 1.9534314945063336
Validation loss: 2.54747646539291

Epoch: 5| Step: 1
Training loss: 1.8016684243790306
Validation loss: 2.544083858141525

Epoch: 5| Step: 2
Training loss: 1.7112180575614238
Validation loss: 2.550910845157005

Epoch: 5| Step: 3
Training loss: 1.4099098053620243
Validation loss: 2.5721730954446587

Epoch: 5| Step: 4
Training loss: 2.5364510120283574
Validation loss: 2.5782272896559406

Epoch: 5| Step: 5
Training loss: 1.8753110627593343
Validation loss: 2.5627759304196633

Epoch: 5| Step: 6
Training loss: 2.096754167830297
Validation loss: 2.582982567589891

Epoch: 5| Step: 7
Training loss: 1.9051784567961056
Validation loss: 2.603151151381491

Epoch: 5| Step: 8
Training loss: 1.9402483858785757
Validation loss: 2.588777459737427

Epoch: 5| Step: 9
Training loss: 2.504124291220655
Validation loss: 2.610408030254897

Epoch: 5| Step: 10
Training loss: 1.4741591012407291
Validation loss: 2.6280408646961733

Epoch: 5| Step: 11
Training loss: 1.1563087139171782
Validation loss: 2.6697119272394505

Epoch: 370| Step: 0
Training loss: 1.5835414130694934
Validation loss: 2.6998266187971693

Epoch: 5| Step: 1
Training loss: 2.0408297659470374
Validation loss: 2.6714342843220007

Epoch: 5| Step: 2
Training loss: 1.7417134550949571
Validation loss: 2.6842982197188454

Epoch: 5| Step: 3
Training loss: 2.475628697855556
Validation loss: 2.637024077645134

Epoch: 5| Step: 4
Training loss: 1.715518896716517
Validation loss: 2.6645022539255843

Epoch: 5| Step: 5
Training loss: 2.0139038070769257
Validation loss: 2.5737659555872825

Epoch: 5| Step: 6
Training loss: 1.9480697517283299
Validation loss: 2.5633609147400644

Epoch: 5| Step: 7
Training loss: 1.5422591883607801
Validation loss: 2.483454327761309

Epoch: 5| Step: 8
Training loss: 2.145091833002816
Validation loss: 2.468505513281715

Epoch: 5| Step: 9
Training loss: 2.0036585247555743
Validation loss: 2.4647103226665332

Epoch: 5| Step: 10
Training loss: 2.384795117644975
Validation loss: 2.4640155696653077

Epoch: 5| Step: 11
Training loss: 1.158835587370449
Validation loss: 2.4564486178205813

Epoch: 371| Step: 0
Training loss: 1.929948117344474
Validation loss: 2.5062275212485603

Epoch: 5| Step: 1
Training loss: 1.964615431274249
Validation loss: 2.4700368131019097

Epoch: 5| Step: 2
Training loss: 1.499722693559551
Validation loss: 2.478484067122266

Epoch: 5| Step: 3
Training loss: 2.163189102364916
Validation loss: 2.491933042317336

Epoch: 5| Step: 4
Training loss: 2.3282652947058544
Validation loss: 2.5017636078708763

Epoch: 5| Step: 5
Training loss: 1.234570741223377
Validation loss: 2.52516491543391

Epoch: 5| Step: 6
Training loss: 2.2730609804860715
Validation loss: 2.5346630069196885

Epoch: 5| Step: 7
Training loss: 2.0473879105996806
Validation loss: 2.5913024292723925

Epoch: 5| Step: 8
Training loss: 2.2665986172428085
Validation loss: 2.6461142831356166

Epoch: 5| Step: 9
Training loss: 1.9328223953672208
Validation loss: 2.6536872356405707

Epoch: 5| Step: 10
Training loss: 2.380994760045322
Validation loss: 2.6496087881638095

Epoch: 5| Step: 11
Training loss: 1.4893536246074905
Validation loss: 2.664210985656501

Epoch: 372| Step: 0
Training loss: 2.054099111110309
Validation loss: 2.6531187300800814

Epoch: 5| Step: 1
Training loss: 1.8648281753586442
Validation loss: 2.584435990308477

Epoch: 5| Step: 2
Training loss: 1.8685518650923991
Validation loss: 2.6123316873361317

Epoch: 5| Step: 3
Training loss: 1.9216341937790677
Validation loss: 2.5574235390084343

Epoch: 5| Step: 4
Training loss: 1.8201345594149987
Validation loss: 2.575979183646024

Epoch: 5| Step: 5
Training loss: 2.5521430079950567
Validation loss: 2.569113748479531

Epoch: 5| Step: 6
Training loss: 2.0439004031960106
Validation loss: 2.5644641845960487

Epoch: 5| Step: 7
Training loss: 1.689485018214136
Validation loss: 2.5821391096108646

Epoch: 5| Step: 8
Training loss: 1.7135387138488125
Validation loss: 2.572401764862787

Epoch: 5| Step: 9
Training loss: 1.9817166882878465
Validation loss: 2.5877754041825023

Epoch: 5| Step: 10
Training loss: 1.6358239543462607
Validation loss: 2.5919381404765933

Epoch: 5| Step: 11
Training loss: 2.406491156049211
Validation loss: 2.588233992151602

Epoch: 373| Step: 0
Training loss: 2.3468169427387875
Validation loss: 2.6078222607916968

Epoch: 5| Step: 1
Training loss: 1.9063198514553785
Validation loss: 2.6417391418619434

Epoch: 5| Step: 2
Training loss: 1.7184163550008833
Validation loss: 2.5969740237052146

Epoch: 5| Step: 3
Training loss: 2.0806486251832745
Validation loss: 2.599496851892577

Epoch: 5| Step: 4
Training loss: 1.6147383420635302
Validation loss: 2.6014645169491315

Epoch: 5| Step: 5
Training loss: 2.0469327729203686
Validation loss: 2.5764993532245244

Epoch: 5| Step: 6
Training loss: 1.3492870249478979
Validation loss: 2.5681714858261318

Epoch: 5| Step: 7
Training loss: 2.7102999858288
Validation loss: 2.5649243416016714

Epoch: 5| Step: 8
Training loss: 2.3683943992364265
Validation loss: 2.5566446660308335

Epoch: 5| Step: 9
Training loss: 1.9249406879750035
Validation loss: 2.5419377640984817

Epoch: 5| Step: 10
Training loss: 1.0345655951411294
Validation loss: 2.558812164613104

Epoch: 5| Step: 11
Training loss: 1.2984746236807616
Validation loss: 2.537173318583268

Epoch: 374| Step: 0
Training loss: 1.4769631301472392
Validation loss: 2.558385095994232

Epoch: 5| Step: 1
Training loss: 2.4623295797640705
Validation loss: 2.5801447152980868

Epoch: 5| Step: 2
Training loss: 1.9727899789332908
Validation loss: 2.5550829282909

Epoch: 5| Step: 3
Training loss: 1.610553347111738
Validation loss: 2.5873620103969226

Epoch: 5| Step: 4
Training loss: 2.2090532341030342
Validation loss: 2.526994041292059

Epoch: 5| Step: 5
Training loss: 2.0015691323806974
Validation loss: 2.544730199981595

Epoch: 5| Step: 6
Training loss: 2.624080224340177
Validation loss: 2.5341946581212733

Epoch: 5| Step: 7
Training loss: 1.519540193428453
Validation loss: 2.5321320303893575

Epoch: 5| Step: 8
Training loss: 1.9587670583170855
Validation loss: 2.578952070952211

Epoch: 5| Step: 9
Training loss: 1.5565409131823038
Validation loss: 2.5694063941326184

Epoch: 5| Step: 10
Training loss: 1.4583705443221584
Validation loss: 2.562090732487059

Epoch: 5| Step: 11
Training loss: 0.6180445117058991
Validation loss: 2.5717932581899534

Epoch: 375| Step: 0
Training loss: 1.8136829593606474
Validation loss: 2.553044427528719

Epoch: 5| Step: 1
Training loss: 1.990900020075934
Validation loss: 2.555079537971408

Epoch: 5| Step: 2
Training loss: 1.8544545825200898
Validation loss: 2.550343404348234

Epoch: 5| Step: 3
Training loss: 2.2319722094019183
Validation loss: 2.548048322514332

Epoch: 5| Step: 4
Training loss: 1.7636434863267556
Validation loss: 2.5496337046299384

Epoch: 5| Step: 5
Training loss: 1.2049494200098627
Validation loss: 2.5408113100839205

Epoch: 5| Step: 6
Training loss: 2.902603158357971
Validation loss: 2.54708276380993

Epoch: 5| Step: 7
Training loss: 1.3170052362684055
Validation loss: 2.5366975206764044

Epoch: 5| Step: 8
Training loss: 1.4630211643296933
Validation loss: 2.5497058200065026

Epoch: 5| Step: 9
Training loss: 2.1107830857979053
Validation loss: 2.571664920104994

Epoch: 5| Step: 10
Training loss: 1.8462655961314829
Validation loss: 2.6170498104789783

Epoch: 5| Step: 11
Training loss: 2.418916236231435
Validation loss: 2.63301741786435

Epoch: 376| Step: 0
Training loss: 1.8767776963007066
Validation loss: 2.6287957858362394

Epoch: 5| Step: 1
Training loss: 2.4180254459667148
Validation loss: 2.581562101570902

Epoch: 5| Step: 2
Training loss: 1.8369646810709108
Validation loss: 2.5397661358980073

Epoch: 5| Step: 3
Training loss: 2.177438539673434
Validation loss: 2.5311589048029703

Epoch: 5| Step: 4
Training loss: 2.1715942860054396
Validation loss: 2.5567226081061674

Epoch: 5| Step: 5
Training loss: 1.8616845028921296
Validation loss: 2.5417748621023613

Epoch: 5| Step: 6
Training loss: 1.5702188947876718
Validation loss: 2.5445632935675953

Epoch: 5| Step: 7
Training loss: 2.0171003043596767
Validation loss: 2.5394853836418054

Epoch: 5| Step: 8
Training loss: 2.0102188592820274
Validation loss: 2.545865722883084

Epoch: 5| Step: 9
Training loss: 1.913852353140221
Validation loss: 2.5649560559624955

Epoch: 5| Step: 10
Training loss: 1.4271750965920045
Validation loss: 2.559363964136199

Epoch: 5| Step: 11
Training loss: 1.0789518088431795
Validation loss: 2.542790525317306

Epoch: 377| Step: 0
Training loss: 2.2504523140534145
Validation loss: 2.560167666205977

Epoch: 5| Step: 1
Training loss: 1.3740286430471755
Validation loss: 2.5653814188551585

Epoch: 5| Step: 2
Training loss: 1.9810275581711427
Validation loss: 2.588058458560019

Epoch: 5| Step: 3
Training loss: 1.7582097939697656
Validation loss: 2.576008723801991

Epoch: 5| Step: 4
Training loss: 2.3224831648463833
Validation loss: 2.5908950313678947

Epoch: 5| Step: 5
Training loss: 1.9199950164491826
Validation loss: 2.6301234914611173

Epoch: 5| Step: 6
Training loss: 1.8241152356203447
Validation loss: 2.6582921312441634

Epoch: 5| Step: 7
Training loss: 1.604712909322738
Validation loss: 2.6454955708936425

Epoch: 5| Step: 8
Training loss: 2.161024584777314
Validation loss: 2.666366956428555

Epoch: 5| Step: 9
Training loss: 1.9683396653545362
Validation loss: 2.632155142955892

Epoch: 5| Step: 10
Training loss: 2.0548961228895974
Validation loss: 2.5802219243950018

Epoch: 5| Step: 11
Training loss: 1.9914103469417388
Validation loss: 2.5877757957461918

Epoch: 378| Step: 0
Training loss: 1.7677180619460082
Validation loss: 2.5552834662396364

Epoch: 5| Step: 1
Training loss: 1.52294303498965
Validation loss: 2.5442476938549654

Epoch: 5| Step: 2
Training loss: 2.3209242094683296
Validation loss: 2.526207776195737

Epoch: 5| Step: 3
Training loss: 1.842319580209462
Validation loss: 2.530805109118092

Epoch: 5| Step: 4
Training loss: 2.1427065342246667
Validation loss: 2.535952904780386

Epoch: 5| Step: 5
Training loss: 1.917511366868925
Validation loss: 2.5269690721808358

Epoch: 5| Step: 6
Training loss: 2.0649727534604856
Validation loss: 2.543582582392804

Epoch: 5| Step: 7
Training loss: 1.4226957195238772
Validation loss: 2.559340545149123

Epoch: 5| Step: 8
Training loss: 1.9999863504897692
Validation loss: 2.5986280339696566

Epoch: 5| Step: 9
Training loss: 2.1380948895271965
Validation loss: 2.665116110163567

Epoch: 5| Step: 10
Training loss: 2.22585030927603
Validation loss: 2.655634793863292

Epoch: 5| Step: 11
Training loss: 2.7119660199098647
Validation loss: 2.65525237403962

Epoch: 379| Step: 0
Training loss: 1.504293971429131
Validation loss: 2.6879800914763217

Epoch: 5| Step: 1
Training loss: 1.9895679080491662
Validation loss: 2.7510777261766783

Epoch: 5| Step: 2
Training loss: 2.0494874778750303
Validation loss: 2.7593264724191164

Epoch: 5| Step: 3
Training loss: 2.017125125928266
Validation loss: 2.7296805783646043

Epoch: 5| Step: 4
Training loss: 1.6143848256141842
Validation loss: 2.659131346081172

Epoch: 5| Step: 5
Training loss: 2.318824367924355
Validation loss: 2.582612511349484

Epoch: 5| Step: 6
Training loss: 2.4313399898869226
Validation loss: 2.543553388184624

Epoch: 5| Step: 7
Training loss: 2.4689443970449116
Validation loss: 2.558032728038266

Epoch: 5| Step: 8
Training loss: 1.50795077149458
Validation loss: 2.53295292105198

Epoch: 5| Step: 9
Training loss: 1.9169212946169332
Validation loss: 2.551306833484279

Epoch: 5| Step: 10
Training loss: 1.8456967954173875
Validation loss: 2.556106255087574

Epoch: 5| Step: 11
Training loss: 1.8079206561258256
Validation loss: 2.5571825207469066

Epoch: 380| Step: 0
Training loss: 1.9669477903014427
Validation loss: 2.577227357207949

Epoch: 5| Step: 1
Training loss: 1.8072748174257545
Validation loss: 2.569053623759667

Epoch: 5| Step: 2
Training loss: 1.530794815606119
Validation loss: 2.609974737020735

Epoch: 5| Step: 3
Training loss: 2.1387412142726427
Validation loss: 2.6268661957341455

Epoch: 5| Step: 4
Training loss: 1.5555872781485918
Validation loss: 2.6212185423962464

Epoch: 5| Step: 5
Training loss: 1.620549121967864
Validation loss: 2.6037994672654934

Epoch: 5| Step: 6
Training loss: 2.034788131369698
Validation loss: 2.5992520853711603

Epoch: 5| Step: 7
Training loss: 1.7608709557999236
Validation loss: 2.5666544120256574

Epoch: 5| Step: 8
Training loss: 1.8577704679131368
Validation loss: 2.556571705012841

Epoch: 5| Step: 9
Training loss: 2.7848923225064417
Validation loss: 2.533893323532378

Epoch: 5| Step: 10
Training loss: 2.2425233808678593
Validation loss: 2.5421386434263935

Epoch: 5| Step: 11
Training loss: 1.7820929155797465
Validation loss: 2.5353527923558277

Epoch: 381| Step: 0
Training loss: 1.8629097558205279
Validation loss: 2.5399401688381147

Epoch: 5| Step: 1
Training loss: 1.6339149950998546
Validation loss: 2.5575954168810116

Epoch: 5| Step: 2
Training loss: 1.7470758394310635
Validation loss: 2.5486028306175745

Epoch: 5| Step: 3
Training loss: 2.1920477324321626
Validation loss: 2.5972676839833237

Epoch: 5| Step: 4
Training loss: 2.4623203812361774
Validation loss: 2.6008585835772924

Epoch: 5| Step: 5
Training loss: 1.5159538148321747
Validation loss: 2.6007302473756115

Epoch: 5| Step: 6
Training loss: 1.6539438855155655
Validation loss: 2.60485124109574

Epoch: 5| Step: 7
Training loss: 1.5751732140615125
Validation loss: 2.6237863126619376

Epoch: 5| Step: 8
Training loss: 2.283696991671195
Validation loss: 2.648394227026023

Epoch: 5| Step: 9
Training loss: 2.2572570962434164
Validation loss: 2.6431944157362746

Epoch: 5| Step: 10
Training loss: 1.8378968517429057
Validation loss: 2.624589513291066

Epoch: 5| Step: 11
Training loss: 1.1041639735830802
Validation loss: 2.624902581496217

Epoch: 382| Step: 0
Training loss: 1.348741486940572
Validation loss: 2.594729131473126

Epoch: 5| Step: 1
Training loss: 2.329379057597932
Validation loss: 2.568228610230876

Epoch: 5| Step: 2
Training loss: 1.9233627763452588
Validation loss: 2.5793044234253997

Epoch: 5| Step: 3
Training loss: 1.7026647943403266
Validation loss: 2.5815568989353292

Epoch: 5| Step: 4
Training loss: 2.173846002249884
Validation loss: 2.584404878239893

Epoch: 5| Step: 5
Training loss: 1.8571805426159014
Validation loss: 2.5579398137315135

Epoch: 5| Step: 6
Training loss: 1.6445996050548763
Validation loss: 2.5629847347200827

Epoch: 5| Step: 7
Training loss: 2.007636392788952
Validation loss: 2.564331962161696

Epoch: 5| Step: 8
Training loss: 2.0739106777456877
Validation loss: 2.556225845266317

Epoch: 5| Step: 9
Training loss: 1.9796454469569416
Validation loss: 2.572010190770273

Epoch: 5| Step: 10
Training loss: 1.3153348009172525
Validation loss: 2.5543998610771763

Epoch: 5| Step: 11
Training loss: 2.017679749225474
Validation loss: 2.571428812133561

Epoch: 383| Step: 0
Training loss: 1.8199530643657107
Validation loss: 2.576506840906846

Epoch: 5| Step: 1
Training loss: 1.8537858579103805
Validation loss: 2.5917883697730506

Epoch: 5| Step: 2
Training loss: 1.6889038604287452
Validation loss: 2.6094047521848043

Epoch: 5| Step: 3
Training loss: 1.9946178496671831
Validation loss: 2.60704388301518

Epoch: 5| Step: 4
Training loss: 1.571339437508221
Validation loss: 2.5980594522862606

Epoch: 5| Step: 5
Training loss: 2.027002912326371
Validation loss: 2.607670069012996

Epoch: 5| Step: 6
Training loss: 2.410076121477477
Validation loss: 2.5787111425222733

Epoch: 5| Step: 7
Training loss: 1.6292928332999124
Validation loss: 2.5911886559914294

Epoch: 5| Step: 8
Training loss: 1.7435268847288294
Validation loss: 2.576252837471816

Epoch: 5| Step: 9
Training loss: 1.7253844786368904
Validation loss: 2.5298860587847734

Epoch: 5| Step: 10
Training loss: 2.1469558323020324
Validation loss: 2.536278459148943

Epoch: 5| Step: 11
Training loss: 0.7279300330437325
Validation loss: 2.525529449022329

Epoch: 384| Step: 0
Training loss: 1.6915269064210845
Validation loss: 2.5197671193355267

Epoch: 5| Step: 1
Training loss: 1.9606190457069717
Validation loss: 2.5139578869227748

Epoch: 5| Step: 2
Training loss: 1.6752055853321561
Validation loss: 2.516800228789449

Epoch: 5| Step: 3
Training loss: 1.589893387153185
Validation loss: 2.547026319630646

Epoch: 5| Step: 4
Training loss: 2.2919426722921608
Validation loss: 2.506214635001755

Epoch: 5| Step: 5
Training loss: 1.9298907956669655
Validation loss: 2.535759437249872

Epoch: 5| Step: 6
Training loss: 1.3554287335647976
Validation loss: 2.563702018390471

Epoch: 5| Step: 7
Training loss: 1.5720972954340438
Validation loss: 2.6031797993277808

Epoch: 5| Step: 8
Training loss: 1.6399699765457774
Validation loss: 2.639942378158239

Epoch: 5| Step: 9
Training loss: 2.208443464975815
Validation loss: 2.6219282342646517

Epoch: 5| Step: 10
Training loss: 2.3069631946936524
Validation loss: 2.580973725547157

Epoch: 5| Step: 11
Training loss: 2.9971487483117745
Validation loss: 2.5559389235997862

Epoch: 385| Step: 0
Training loss: 2.22405457716465
Validation loss: 2.5678366434925164

Epoch: 5| Step: 1
Training loss: 1.608898573789783
Validation loss: 2.5503519815727014

Epoch: 5| Step: 2
Training loss: 1.4258303281097282
Validation loss: 2.553792814324387

Epoch: 5| Step: 3
Training loss: 2.0550317512156933
Validation loss: 2.523894533355174

Epoch: 5| Step: 4
Training loss: 2.3340440303568677
Validation loss: 2.557296466758144

Epoch: 5| Step: 5
Training loss: 1.8788893732593788
Validation loss: 2.5404409373957564

Epoch: 5| Step: 6
Training loss: 2.051376750407647
Validation loss: 2.561773158320952

Epoch: 5| Step: 7
Training loss: 1.9155873355616508
Validation loss: 2.5565979373361043

Epoch: 5| Step: 8
Training loss: 1.7583803065143917
Validation loss: 2.55983371342326

Epoch: 5| Step: 9
Training loss: 2.059445749552321
Validation loss: 2.547402442346918

Epoch: 5| Step: 10
Training loss: 1.34975303404245
Validation loss: 2.5437227997508893

Epoch: 5| Step: 11
Training loss: 1.5563725679841363
Validation loss: 2.526879418792497

Epoch: 386| Step: 0
Training loss: 1.8576604166496729
Validation loss: 2.5259102436498453

Epoch: 5| Step: 1
Training loss: 1.7981174320065663
Validation loss: 2.557943242979912

Epoch: 5| Step: 2
Training loss: 1.990170463756243
Validation loss: 2.563678311598486

Epoch: 5| Step: 3
Training loss: 1.9554172339913747
Validation loss: 2.5312815927174412

Epoch: 5| Step: 4
Training loss: 1.4981450691518086
Validation loss: 2.568398258509578

Epoch: 5| Step: 5
Training loss: 2.0452745310244
Validation loss: 2.5993051061874177

Epoch: 5| Step: 6
Training loss: 2.062890911625974
Validation loss: 2.6478171320610238

Epoch: 5| Step: 7
Training loss: 1.8854564922475208
Validation loss: 2.643415447617687

Epoch: 5| Step: 8
Training loss: 1.4159374978447086
Validation loss: 2.6373237386747697

Epoch: 5| Step: 9
Training loss: 1.9085807309544007
Validation loss: 2.6115209469759457

Epoch: 5| Step: 10
Training loss: 2.1052447537822383
Validation loss: 2.5406024195194323

Epoch: 5| Step: 11
Training loss: 2.3475907454658747
Validation loss: 2.5579563851531746

Epoch: 387| Step: 0
Training loss: 2.4094452883589645
Validation loss: 2.5537761458659447

Epoch: 5| Step: 1
Training loss: 2.1286188614078174
Validation loss: 2.536177352653216

Epoch: 5| Step: 2
Training loss: 1.6152257400152727
Validation loss: 2.5454105699417986

Epoch: 5| Step: 3
Training loss: 1.9694574689531583
Validation loss: 2.569228286643493

Epoch: 5| Step: 4
Training loss: 2.0489163302480007
Validation loss: 2.529863790362381

Epoch: 5| Step: 5
Training loss: 1.753335498813312
Validation loss: 2.572206114648058

Epoch: 5| Step: 6
Training loss: 1.5075449335540783
Validation loss: 2.584896946254175

Epoch: 5| Step: 7
Training loss: 1.3528169312099425
Validation loss: 2.5834665757601036

Epoch: 5| Step: 8
Training loss: 1.9854231942047165
Validation loss: 2.560838335036278

Epoch: 5| Step: 9
Training loss: 1.6741045052643844
Validation loss: 2.5793342798295713

Epoch: 5| Step: 10
Training loss: 2.15000542041184
Validation loss: 2.5983870623157443

Epoch: 5| Step: 11
Training loss: 1.2673543253445516
Validation loss: 2.5608619323467567

Epoch: 388| Step: 0
Training loss: 1.0042673493136178
Validation loss: 2.5634571648726663

Epoch: 5| Step: 1
Training loss: 2.05871535345593
Validation loss: 2.57451832426589

Epoch: 5| Step: 2
Training loss: 1.8676273354623667
Validation loss: 2.571602147068261

Epoch: 5| Step: 3
Training loss: 2.072917637912644
Validation loss: 2.578218720399149

Epoch: 5| Step: 4
Training loss: 1.9045317363182885
Validation loss: 2.591762589450905

Epoch: 5| Step: 5
Training loss: 1.7646151329997413
Validation loss: 2.5695262622407897

Epoch: 5| Step: 6
Training loss: 1.9167128294762132
Validation loss: 2.5530497738709976

Epoch: 5| Step: 7
Training loss: 1.5311974496971663
Validation loss: 2.5166439772734663

Epoch: 5| Step: 8
Training loss: 1.394225613308791
Validation loss: 2.550282618967677

Epoch: 5| Step: 9
Training loss: 2.154629084270351
Validation loss: 2.537310064971427

Epoch: 5| Step: 10
Training loss: 1.970624606455804
Validation loss: 2.567891918426039

Epoch: 5| Step: 11
Training loss: 2.6175617007440626
Validation loss: 2.5256778153489816

Epoch: 389| Step: 0
Training loss: 1.6154303103226568
Validation loss: 2.544568728002202

Epoch: 5| Step: 1
Training loss: 1.4316607756191875
Validation loss: 2.549002618772614

Epoch: 5| Step: 2
Training loss: 2.2621881133024817
Validation loss: 2.528433186121094

Epoch: 5| Step: 3
Training loss: 1.644389601743759
Validation loss: 2.524703367713585

Epoch: 5| Step: 4
Training loss: 2.2802880754348154
Validation loss: 2.5426291118336217

Epoch: 5| Step: 5
Training loss: 1.8479891390460677
Validation loss: 2.569104158934303

Epoch: 5| Step: 6
Training loss: 1.723073411459148
Validation loss: 2.5591377980566503

Epoch: 5| Step: 7
Training loss: 1.7932943742389318
Validation loss: 2.53196080357097

Epoch: 5| Step: 8
Training loss: 1.6321316992642738
Validation loss: 2.5616680709915265

Epoch: 5| Step: 9
Training loss: 1.5504214544443609
Validation loss: 2.567486036993811

Epoch: 5| Step: 10
Training loss: 1.9232692468280872
Validation loss: 2.5499551047630264

Epoch: 5| Step: 11
Training loss: 3.138058501000369
Validation loss: 2.552601434057164

Epoch: 390| Step: 0
Training loss: 1.7638254362826653
Validation loss: 2.5706044758822055

Epoch: 5| Step: 1
Training loss: 1.8773674959037465
Validation loss: 2.5764159654997885

Epoch: 5| Step: 2
Training loss: 2.007129360012021
Validation loss: 2.5845145491133144

Epoch: 5| Step: 3
Training loss: 1.381552127228846
Validation loss: 2.5607167839128806

Epoch: 5| Step: 4
Training loss: 1.520890831404748
Validation loss: 2.584376371968346

Epoch: 5| Step: 5
Training loss: 2.0690572135983363
Validation loss: 2.57872936986948

Epoch: 5| Step: 6
Training loss: 2.1001847867046517
Validation loss: 2.5860102625019

Epoch: 5| Step: 7
Training loss: 1.8089962340484946
Validation loss: 2.6036213202078335

Epoch: 5| Step: 8
Training loss: 2.2347026664721734
Validation loss: 2.5583737072466644

Epoch: 5| Step: 9
Training loss: 1.4299993956504558
Validation loss: 2.5621138956361866

Epoch: 5| Step: 10
Training loss: 2.072715314993368
Validation loss: 2.596818311725163

Epoch: 5| Step: 11
Training loss: 1.7213389924535254
Validation loss: 2.5607242207588734

Epoch: 391| Step: 0
Training loss: 1.3633736740305913
Validation loss: 2.5460564384211932

Epoch: 5| Step: 1
Training loss: 2.159225180434356
Validation loss: 2.5727210137781737

Epoch: 5| Step: 2
Training loss: 2.145074382995038
Validation loss: 2.5608087362611633

Epoch: 5| Step: 3
Training loss: 1.7213490342271922
Validation loss: 2.594855467447001

Epoch: 5| Step: 4
Training loss: 1.625007702735838
Validation loss: 2.56739746569368

Epoch: 5| Step: 5
Training loss: 1.2720961263700346
Validation loss: 2.571250556901851

Epoch: 5| Step: 6
Training loss: 1.5342590194966625
Validation loss: 2.5760612859311776

Epoch: 5| Step: 7
Training loss: 2.100474930600704
Validation loss: 2.594551690233705

Epoch: 5| Step: 8
Training loss: 1.3766328479747856
Validation loss: 2.5878409250153407

Epoch: 5| Step: 9
Training loss: 2.1167285604764188
Validation loss: 2.569515228298857

Epoch: 5| Step: 10
Training loss: 2.2589043217999265
Validation loss: 2.6226580670846373

Epoch: 5| Step: 11
Training loss: 1.722078325898263
Validation loss: 2.591368708138779

Epoch: 392| Step: 0
Training loss: 1.5090726024284002
Validation loss: 2.6177794664774536

Epoch: 5| Step: 1
Training loss: 2.037214589167797
Validation loss: 2.5739218386743046

Epoch: 5| Step: 2
Training loss: 1.7289256498590326
Validation loss: 2.663655910993271

Epoch: 5| Step: 3
Training loss: 1.6610764051544968
Validation loss: 2.6256505334186637

Epoch: 5| Step: 4
Training loss: 1.8790664445945742
Validation loss: 2.6109977043298334

Epoch: 5| Step: 5
Training loss: 1.976295362672141
Validation loss: 2.5660718393210127

Epoch: 5| Step: 6
Training loss: 2.0792215078864067
Validation loss: 2.5691033275809136

Epoch: 5| Step: 7
Training loss: 1.6531130756027428
Validation loss: 2.55863125217899

Epoch: 5| Step: 8
Training loss: 1.800190793628035
Validation loss: 2.5295852359288493

Epoch: 5| Step: 9
Training loss: 1.2563560061542385
Validation loss: 2.5470904881250864

Epoch: 5| Step: 10
Training loss: 2.501434868076912
Validation loss: 2.541516605752223

Epoch: 5| Step: 11
Training loss: 1.0105958104680723
Validation loss: 2.5539477654870733

Epoch: 393| Step: 0
Training loss: 1.191957340046754
Validation loss: 2.514051308457821

Epoch: 5| Step: 1
Training loss: 1.294306636240906
Validation loss: 2.5560691511478972

Epoch: 5| Step: 2
Training loss: 1.5862583531128953
Validation loss: 2.5300358501603326

Epoch: 5| Step: 3
Training loss: 1.5493829606479923
Validation loss: 2.5700481707886236

Epoch: 5| Step: 4
Training loss: 1.842523004913606
Validation loss: 2.567231210687471

Epoch: 5| Step: 5
Training loss: 2.397934951071762
Validation loss: 2.557930815330788

Epoch: 5| Step: 6
Training loss: 1.6682186609517593
Validation loss: 2.53586290304231

Epoch: 5| Step: 7
Training loss: 2.4085005107084796
Validation loss: 2.549826620088686

Epoch: 5| Step: 8
Training loss: 1.8785726207416487
Validation loss: 2.5396477518733733

Epoch: 5| Step: 9
Training loss: 1.8172362697416913
Validation loss: 2.5507165998957637

Epoch: 5| Step: 10
Training loss: 1.964638428170024
Validation loss: 2.571752146972925

Epoch: 5| Step: 11
Training loss: 1.4995300828460734
Validation loss: 2.5404605987459976

Epoch: 394| Step: 0
Training loss: 2.0037994058839814
Validation loss: 2.556044510756279

Epoch: 5| Step: 1
Training loss: 1.7127498973422672
Validation loss: 2.5509203044849675

Epoch: 5| Step: 2
Training loss: 2.116502489145727
Validation loss: 2.5273944037980702

Epoch: 5| Step: 3
Training loss: 1.6798329844789357
Validation loss: 2.548523913239297

Epoch: 5| Step: 4
Training loss: 1.7570485807508023
Validation loss: 2.554720229970647

Epoch: 5| Step: 5
Training loss: 1.5546132745707788
Validation loss: 2.544621623340249

Epoch: 5| Step: 6
Training loss: 2.217777200122028
Validation loss: 2.5675335889759285

Epoch: 5| Step: 7
Training loss: 1.790533668625487
Validation loss: 2.5595224864323685

Epoch: 5| Step: 8
Training loss: 1.6338419612112052
Validation loss: 2.576995725589435

Epoch: 5| Step: 9
Training loss: 1.365202721923274
Validation loss: 2.565623442215317

Epoch: 5| Step: 10
Training loss: 1.8072399897887188
Validation loss: 2.5659657356227252

Epoch: 5| Step: 11
Training loss: 1.0027344391974744
Validation loss: 2.5885416673062873

Epoch: 395| Step: 0
Training loss: 2.079816087148059
Validation loss: 2.6367493239148994

Epoch: 5| Step: 1
Training loss: 1.6871061925202242
Validation loss: 2.590685888264335

Epoch: 5| Step: 2
Training loss: 1.8200299612660242
Validation loss: 2.568872343987766

Epoch: 5| Step: 3
Training loss: 1.5034021895231944
Validation loss: 2.573713647648365

Epoch: 5| Step: 4
Training loss: 1.9150800219118593
Validation loss: 2.550837108707303

Epoch: 5| Step: 5
Training loss: 1.5928915367103276
Validation loss: 2.5443971765879683

Epoch: 5| Step: 6
Training loss: 2.030491848821936
Validation loss: 2.556663874439578

Epoch: 5| Step: 7
Training loss: 1.345707820003829
Validation loss: 2.546458165357234

Epoch: 5| Step: 8
Training loss: 2.18942143658073
Validation loss: 2.53827649201487

Epoch: 5| Step: 9
Training loss: 1.7428742838403035
Validation loss: 2.552238034730133

Epoch: 5| Step: 10
Training loss: 2.0521756327311955
Validation loss: 2.5299119886254564

Epoch: 5| Step: 11
Training loss: 1.4545282131224424
Validation loss: 2.5164204873905365

Epoch: 396| Step: 0
Training loss: 1.5639098863714718
Validation loss: 2.537445140114056

Epoch: 5| Step: 1
Training loss: 2.169037756394704
Validation loss: 2.600469143735344

Epoch: 5| Step: 2
Training loss: 1.5443922212783712
Validation loss: 2.6013410853958505

Epoch: 5| Step: 3
Training loss: 1.7249944133944508
Validation loss: 2.65430844350974

Epoch: 5| Step: 4
Training loss: 1.6139095828505454
Validation loss: 2.6162312596903408

Epoch: 5| Step: 5
Training loss: 1.4899833337760593
Validation loss: 2.6144517463966563

Epoch: 5| Step: 6
Training loss: 1.7185417742742064
Validation loss: 2.5437448843639774

Epoch: 5| Step: 7
Training loss: 1.6047862289054637
Validation loss: 2.5448303420888085

Epoch: 5| Step: 8
Training loss: 2.6203554935829305
Validation loss: 2.528087834641837

Epoch: 5| Step: 9
Training loss: 2.019828494127885
Validation loss: 2.5132531106496323

Epoch: 5| Step: 10
Training loss: 1.513651792331494
Validation loss: 2.5349869125387023

Epoch: 5| Step: 11
Training loss: 2.853341161889481
Validation loss: 2.5533765215267312

Epoch: 397| Step: 0
Training loss: 1.630897238286142
Validation loss: 2.5459679351556987

Epoch: 5| Step: 1
Training loss: 2.1949898153429386
Validation loss: 2.6055239281251974

Epoch: 5| Step: 2
Training loss: 1.4789911712269483
Validation loss: 2.637105616692707

Epoch: 5| Step: 3
Training loss: 1.8603393874683625
Validation loss: 2.6693912993749

Epoch: 5| Step: 4
Training loss: 2.363109941815432
Validation loss: 2.6584603855261113

Epoch: 5| Step: 5
Training loss: 2.0127460116127875
Validation loss: 2.5455630224999863

Epoch: 5| Step: 6
Training loss: 1.609834549855458
Validation loss: 2.4962752410065896

Epoch: 5| Step: 7
Training loss: 1.7859140202671755
Validation loss: 2.4708025443639197

Epoch: 5| Step: 8
Training loss: 2.1532950678792324
Validation loss: 2.480105159674459

Epoch: 5| Step: 9
Training loss: 1.7163797854856255
Validation loss: 2.465890669117966

Epoch: 5| Step: 10
Training loss: 2.128854285489652
Validation loss: 2.4672304659857494

Epoch: 5| Step: 11
Training loss: 1.7418532114955436
Validation loss: 2.474189961615941

Epoch: 398| Step: 0
Training loss: 2.1963185893135266
Validation loss: 2.49324880421841

Epoch: 5| Step: 1
Training loss: 2.179115904100706
Validation loss: 2.4970267019390957

Epoch: 5| Step: 2
Training loss: 1.7589491496497183
Validation loss: 2.507614559708307

Epoch: 5| Step: 3
Training loss: 2.2644332382121193
Validation loss: 2.5127357018085186

Epoch: 5| Step: 4
Training loss: 1.7142576289146962
Validation loss: 2.4907217149770733

Epoch: 5| Step: 5
Training loss: 2.1009356049406125
Validation loss: 2.488180209373557

Epoch: 5| Step: 6
Training loss: 2.098951568466404
Validation loss: 2.5048135471496162

Epoch: 5| Step: 7
Training loss: 1.86076463333643
Validation loss: 2.551136056429251

Epoch: 5| Step: 8
Training loss: 1.3672432152431022
Validation loss: 2.547891688880749

Epoch: 5| Step: 9
Training loss: 1.8640742184061998
Validation loss: 2.544907791126049

Epoch: 5| Step: 10
Training loss: 1.319472186594431
Validation loss: 2.547455998325529

Epoch: 5| Step: 11
Training loss: 2.715434365555562
Validation loss: 2.5438800708217295

Epoch: 399| Step: 0
Training loss: 1.601975476123678
Validation loss: 2.56704181482982

Epoch: 5| Step: 1
Training loss: 2.195884657180978
Validation loss: 2.5544575073429843

Epoch: 5| Step: 2
Training loss: 1.4032412661360996
Validation loss: 2.58246782760423

Epoch: 5| Step: 3
Training loss: 1.599236711588495
Validation loss: 2.5871148478531563

Epoch: 5| Step: 4
Training loss: 2.5133751706689464
Validation loss: 2.609203199719505

Epoch: 5| Step: 5
Training loss: 1.6693893922151823
Validation loss: 2.5820960509478623

Epoch: 5| Step: 6
Training loss: 1.9355378213279992
Validation loss: 2.6072882228701064

Epoch: 5| Step: 7
Training loss: 1.9594422981349715
Validation loss: 2.588954268383988

Epoch: 5| Step: 8
Training loss: 1.7674703491400108
Validation loss: 2.5626413569965325

Epoch: 5| Step: 9
Training loss: 1.7524226313340185
Validation loss: 2.5821839026313294

Epoch: 5| Step: 10
Training loss: 1.3984846394867887
Validation loss: 2.5718000488360553

Epoch: 5| Step: 11
Training loss: 1.4580905530566632
Validation loss: 2.5718388571503636

Epoch: 400| Step: 0
Training loss: 1.4206377452273584
Validation loss: 2.569119629791779

Epoch: 5| Step: 1
Training loss: 1.9082304875453102
Validation loss: 2.5661977163564056

Epoch: 5| Step: 2
Training loss: 1.6719609889083527
Validation loss: 2.5773277244443524

Epoch: 5| Step: 3
Training loss: 1.5037548434844619
Validation loss: 2.587072855020484

Epoch: 5| Step: 4
Training loss: 2.014346641461636
Validation loss: 2.5578057276799817

Epoch: 5| Step: 5
Training loss: 1.49874706392104
Validation loss: 2.5569893735352265

Epoch: 5| Step: 6
Training loss: 2.0389528208499224
Validation loss: 2.5109295631066444

Epoch: 5| Step: 7
Training loss: 1.7877195556890602
Validation loss: 2.5475725864623664

Epoch: 5| Step: 8
Training loss: 1.3947844716181603
Validation loss: 2.546693194712617

Epoch: 5| Step: 9
Training loss: 1.6047750863275994
Validation loss: 2.5289048803068654

Epoch: 5| Step: 10
Training loss: 2.2974996949902353
Validation loss: 2.5690635924419527

Epoch: 5| Step: 11
Training loss: 2.223347909909134
Validation loss: 2.539859044257677

Epoch: 401| Step: 0
Training loss: 2.321894867145877
Validation loss: 2.5787660668705144

Epoch: 5| Step: 1
Training loss: 1.5666657420757621
Validation loss: 2.628724566639094

Epoch: 5| Step: 2
Training loss: 2.016120672270147
Validation loss: 2.6135545330154084

Epoch: 5| Step: 3
Training loss: 2.134325657465486
Validation loss: 2.5863951348213954

Epoch: 5| Step: 4
Training loss: 1.724991510895559
Validation loss: 2.6189481971291086

Epoch: 5| Step: 5
Training loss: 1.8519106509445944
Validation loss: 2.5844242512546924

Epoch: 5| Step: 6
Training loss: 1.2764203294754315
Validation loss: 2.5642875585013045

Epoch: 5| Step: 7
Training loss: 1.719472421197002
Validation loss: 2.5103390880854417

Epoch: 5| Step: 8
Training loss: 1.7720319917214948
Validation loss: 2.5095511338622876

Epoch: 5| Step: 9
Training loss: 1.5773506908821409
Validation loss: 2.5299054723226604

Epoch: 5| Step: 10
Training loss: 1.9868048261866083
Validation loss: 2.53283860155698

Epoch: 5| Step: 11
Training loss: 0.7543727241993783
Validation loss: 2.542036316261821

Epoch: 402| Step: 0
Training loss: 1.2768500070838018
Validation loss: 2.535601631152773

Epoch: 5| Step: 1
Training loss: 2.2326873594737373
Validation loss: 2.5500608422930844

Epoch: 5| Step: 2
Training loss: 1.8795130140539513
Validation loss: 2.5509859736074523

Epoch: 5| Step: 3
Training loss: 1.5168350737558622
Validation loss: 2.601785640674162

Epoch: 5| Step: 4
Training loss: 2.0071102353980947
Validation loss: 2.593378346791269

Epoch: 5| Step: 5
Training loss: 1.4578943227556798
Validation loss: 2.6347227213245814

Epoch: 5| Step: 6
Training loss: 2.0975455427170044
Validation loss: 2.6127276478073687

Epoch: 5| Step: 7
Training loss: 1.963754097723616
Validation loss: 2.579852991246799

Epoch: 5| Step: 8
Training loss: 1.1870649444309072
Validation loss: 2.6039974590006874

Epoch: 5| Step: 9
Training loss: 1.1392015955680752
Validation loss: 2.5720092676588027

Epoch: 5| Step: 10
Training loss: 2.079602397550304
Validation loss: 2.5471269603828475

Epoch: 5| Step: 11
Training loss: 2.1256586063984524
Validation loss: 2.5504580454114936

Epoch: 403| Step: 0
Training loss: 1.8978121006031015
Validation loss: 2.5510844293397885

Epoch: 5| Step: 1
Training loss: 1.754863656119359
Validation loss: 2.540250107248516

Epoch: 5| Step: 2
Training loss: 1.9846296972988162
Validation loss: 2.5850338619923914

Epoch: 5| Step: 3
Training loss: 2.0264867246368516
Validation loss: 2.560687614353829

Epoch: 5| Step: 4
Training loss: 2.090065746459648
Validation loss: 2.604350142055542

Epoch: 5| Step: 5
Training loss: 1.3984688696726
Validation loss: 2.5768228112918368

Epoch: 5| Step: 6
Training loss: 1.4997620393829716
Validation loss: 2.5905941144193476

Epoch: 5| Step: 7
Training loss: 1.1435601082012856
Validation loss: 2.589358185002936

Epoch: 5| Step: 8
Training loss: 1.5408985011237375
Validation loss: 2.639995853632744

Epoch: 5| Step: 9
Training loss: 1.9181153033605889
Validation loss: 2.675856328871562

Epoch: 5| Step: 10
Training loss: 1.7677780796993585
Validation loss: 2.6650213602330095

Epoch: 5| Step: 11
Training loss: 2.216304021823468
Validation loss: 2.697947783026827

Epoch: 404| Step: 0
Training loss: 1.6074318126496425
Validation loss: 2.5679991997767573

Epoch: 5| Step: 1
Training loss: 2.0140613730511054
Validation loss: 2.555142357294958

Epoch: 5| Step: 2
Training loss: 1.827535811463457
Validation loss: 2.5662074290251904

Epoch: 5| Step: 3
Training loss: 1.6335210403614606
Validation loss: 2.557561909963218

Epoch: 5| Step: 4
Training loss: 1.9287747838522622
Validation loss: 2.52282645638865

Epoch: 5| Step: 5
Training loss: 2.3249626443794766
Validation loss: 2.530459362930077

Epoch: 5| Step: 6
Training loss: 2.239426883881122
Validation loss: 2.5290362760207943

Epoch: 5| Step: 7
Training loss: 1.7736638802717566
Validation loss: 2.530034236381038

Epoch: 5| Step: 8
Training loss: 2.091703639013987
Validation loss: 2.515934804632938

Epoch: 5| Step: 9
Training loss: 1.834492151006011
Validation loss: 2.5344559280669903

Epoch: 5| Step: 10
Training loss: 2.1424095344807066
Validation loss: 2.5649630060744277

Epoch: 5| Step: 11
Training loss: 0.7848966938124616
Validation loss: 2.578523951787034

Epoch: 405| Step: 0
Training loss: 1.8213766368439468
Validation loss: 2.6113876453921456

Epoch: 5| Step: 1
Training loss: 2.0718593360918653
Validation loss: 2.737827700621462

Epoch: 5| Step: 2
Training loss: 2.196746140847941
Validation loss: 2.72037414475092

Epoch: 5| Step: 3
Training loss: 1.596179531516513
Validation loss: 2.6156654752807444

Epoch: 5| Step: 4
Training loss: 2.076107795709736
Validation loss: 2.543106130081686

Epoch: 5| Step: 5
Training loss: 1.9529158213180666
Validation loss: 2.5239914757450626

Epoch: 5| Step: 6
Training loss: 1.8232295685113322
Validation loss: 2.5760706220563376

Epoch: 5| Step: 7
Training loss: 1.7390793243444373
Validation loss: 2.5801836406607843

Epoch: 5| Step: 8
Training loss: 2.1215389339516504
Validation loss: 2.593717659131998

Epoch: 5| Step: 9
Training loss: 1.4144704662272385
Validation loss: 2.601115508145972

Epoch: 5| Step: 10
Training loss: 2.3905882988400116
Validation loss: 2.6007357745302397

Epoch: 5| Step: 11
Training loss: 1.6358017275777683
Validation loss: 2.584883329991642

Epoch: 406| Step: 0
Training loss: 1.7859681534827312
Validation loss: 2.5875848899037184

Epoch: 5| Step: 1
Training loss: 1.5874162366500246
Validation loss: 2.585183720439368

Epoch: 5| Step: 2
Training loss: 2.148114655253075
Validation loss: 2.5682815559307963

Epoch: 5| Step: 3
Training loss: 1.8322941117724885
Validation loss: 2.5469218914809364

Epoch: 5| Step: 4
Training loss: 1.7798974774871137
Validation loss: 2.544516717800752

Epoch: 5| Step: 5
Training loss: 1.716542924970416
Validation loss: 2.5225271781664556

Epoch: 5| Step: 6
Training loss: 1.8481510459553276
Validation loss: 2.5420929806579426

Epoch: 5| Step: 7
Training loss: 1.3171865261884281
Validation loss: 2.51593193803794

Epoch: 5| Step: 8
Training loss: 2.1494232690554194
Validation loss: 2.5362751807812662

Epoch: 5| Step: 9
Training loss: 1.5946579385208137
Validation loss: 2.5271450163086957

Epoch: 5| Step: 10
Training loss: 2.4866738869338088
Validation loss: 2.6428996114006624

Epoch: 5| Step: 11
Training loss: 2.000441740843332
Validation loss: 2.673483580001362

Epoch: 407| Step: 0
Training loss: 1.7978566017888364
Validation loss: 2.671398016161357

Epoch: 5| Step: 1
Training loss: 1.8910946853712287
Validation loss: 2.6639307125604037

Epoch: 5| Step: 2
Training loss: 1.5687518359169723
Validation loss: 2.5990870003712967

Epoch: 5| Step: 3
Training loss: 1.9016589551675134
Validation loss: 2.586958081629453

Epoch: 5| Step: 4
Training loss: 1.3979613276632397
Validation loss: 2.570161573468026

Epoch: 5| Step: 5
Training loss: 1.9382129710978067
Validation loss: 2.563991511863737

Epoch: 5| Step: 6
Training loss: 1.6754145009746972
Validation loss: 2.5566304524537204

Epoch: 5| Step: 7
Training loss: 2.141814186962681
Validation loss: 2.5731921196541894

Epoch: 5| Step: 8
Training loss: 2.426352711566584
Validation loss: 2.5606055855536844

Epoch: 5| Step: 9
Training loss: 1.7439822544761205
Validation loss: 2.546320669622683

Epoch: 5| Step: 10
Training loss: 1.8401908142207182
Validation loss: 2.565569202592302

Epoch: 5| Step: 11
Training loss: 2.788043437039249
Validation loss: 2.5722919985095714

Epoch: 408| Step: 0
Training loss: 2.207094012693043
Validation loss: 2.570549877610852

Epoch: 5| Step: 1
Training loss: 1.627962346656128
Validation loss: 2.558099643666421

Epoch: 5| Step: 2
Training loss: 1.7078806424659518
Validation loss: 2.5470473693371285

Epoch: 5| Step: 3
Training loss: 2.2035978634965017
Validation loss: 2.5707918781006804

Epoch: 5| Step: 4
Training loss: 1.7062934311030775
Validation loss: 2.5540660176092884

Epoch: 5| Step: 5
Training loss: 1.9676746883178202
Validation loss: 2.5593398581216538

Epoch: 5| Step: 6
Training loss: 1.485715722382029
Validation loss: 2.565767550331883

Epoch: 5| Step: 7
Training loss: 1.8980867038213478
Validation loss: 2.5618800056770326

Epoch: 5| Step: 8
Training loss: 1.515935649693763
Validation loss: 2.587238733489549

Epoch: 5| Step: 9
Training loss: 1.8157373652921331
Validation loss: 2.559689729193048

Epoch: 5| Step: 10
Training loss: 2.066103821168581
Validation loss: 2.528681702102434

Epoch: 5| Step: 11
Training loss: 2.3442540961798604
Validation loss: 2.5486170382925946

Epoch: 409| Step: 0
Training loss: 1.8100631380397165
Validation loss: 2.5534246124937074

Epoch: 5| Step: 1
Training loss: 1.4072413870608373
Validation loss: 2.5636666712431295

Epoch: 5| Step: 2
Training loss: 2.134526049964557
Validation loss: 2.520291598620208

Epoch: 5| Step: 3
Training loss: 1.9591030339733
Validation loss: 2.5543768282632464

Epoch: 5| Step: 4
Training loss: 1.5639135451751247
Validation loss: 2.5340314778897133

Epoch: 5| Step: 5
Training loss: 1.844036920496456
Validation loss: 2.516504080812104

Epoch: 5| Step: 6
Training loss: 2.0156723135193086
Validation loss: 2.5450334151234637

Epoch: 5| Step: 7
Training loss: 1.8670223274755218
Validation loss: 2.5435391639419915

Epoch: 5| Step: 8
Training loss: 1.4654069555309894
Validation loss: 2.5408301240540636

Epoch: 5| Step: 9
Training loss: 1.7475134349955974
Validation loss: 2.520354987438878

Epoch: 5| Step: 10
Training loss: 1.8903527812604235
Validation loss: 2.5468867210009263

Epoch: 5| Step: 11
Training loss: 1.3972054707176247
Validation loss: 2.55807019378249

Epoch: 410| Step: 0
Training loss: 1.3792074160976122
Validation loss: 2.52500155688071

Epoch: 5| Step: 1
Training loss: 1.2630709084353569
Validation loss: 2.5291404901613146

Epoch: 5| Step: 2
Training loss: 1.923893372644339
Validation loss: 2.519325409595714

Epoch: 5| Step: 3
Training loss: 2.156267359566953
Validation loss: 2.5319903472324174

Epoch: 5| Step: 4
Training loss: 1.9683419667613689
Validation loss: 2.558917650682381

Epoch: 5| Step: 5
Training loss: 1.7368555287096428
Validation loss: 2.5489266874663654

Epoch: 5| Step: 6
Training loss: 1.581815351660059
Validation loss: 2.5866398813046385

Epoch: 5| Step: 7
Training loss: 1.8018229816508613
Validation loss: 2.6336965463334887

Epoch: 5| Step: 8
Training loss: 1.2543404086009144
Validation loss: 2.617977949122689

Epoch: 5| Step: 9
Training loss: 1.7685591362192115
Validation loss: 2.701347409730486

Epoch: 5| Step: 10
Training loss: 2.249560949086191
Validation loss: 2.667813592125366

Epoch: 5| Step: 11
Training loss: 2.3874412729120698
Validation loss: 2.6642674267539483

Epoch: 411| Step: 0
Training loss: 1.6116394112197912
Validation loss: 2.6609526238988863

Epoch: 5| Step: 1
Training loss: 2.0853615869443893
Validation loss: 2.63969882545828

Epoch: 5| Step: 2
Training loss: 1.8140203742131187
Validation loss: 2.6376244541232308

Epoch: 5| Step: 3
Training loss: 1.829573815232031
Validation loss: 2.5888415968129115

Epoch: 5| Step: 4
Training loss: 1.5582819653100797
Validation loss: 2.587962127273562

Epoch: 5| Step: 5
Training loss: 1.386826846785417
Validation loss: 2.5652413784965673

Epoch: 5| Step: 6
Training loss: 1.7423280394109844
Validation loss: 2.5786832763710756

Epoch: 5| Step: 7
Training loss: 2.0838102430618184
Validation loss: 2.572793263913633

Epoch: 5| Step: 8
Training loss: 1.2113558138992158
Validation loss: 2.5372790621737735

Epoch: 5| Step: 9
Training loss: 1.6862645748518073
Validation loss: 2.589325912050808

Epoch: 5| Step: 10
Training loss: 1.627876596666344
Validation loss: 2.5937817966090186

Epoch: 5| Step: 11
Training loss: 1.4270647516456303
Validation loss: 2.5540563521176427

Epoch: 412| Step: 0
Training loss: 1.6947334812573058
Validation loss: 2.588704011356049

Epoch: 5| Step: 1
Training loss: 1.9530628652225905
Validation loss: 2.5813949924476973

Epoch: 5| Step: 2
Training loss: 1.8819292458096082
Validation loss: 2.5796267980792438

Epoch: 5| Step: 3
Training loss: 1.6327781126060863
Validation loss: 2.6086995512649866

Epoch: 5| Step: 4
Training loss: 1.5041978429520424
Validation loss: 2.6471290206769362

Epoch: 5| Step: 5
Training loss: 1.4176808635097389
Validation loss: 2.6059541378823585

Epoch: 5| Step: 6
Training loss: 1.7512761639989687
Validation loss: 2.6281331074665584

Epoch: 5| Step: 7
Training loss: 1.649237054662711
Validation loss: 2.6207231012237755

Epoch: 5| Step: 8
Training loss: 1.314417709621689
Validation loss: 2.5991349067920533

Epoch: 5| Step: 9
Training loss: 2.0583465833147385
Validation loss: 2.558272277981564

Epoch: 5| Step: 10
Training loss: 1.8193647020966492
Validation loss: 2.5569009553631137

Epoch: 5| Step: 11
Training loss: 1.142570247786014
Validation loss: 2.5560250081454234

Epoch: 413| Step: 0
Training loss: 2.1275911801586593
Validation loss: 2.5652937856127807

Epoch: 5| Step: 1
Training loss: 2.040021531982481
Validation loss: 2.5767666176224067

Epoch: 5| Step: 2
Training loss: 1.263361236738853
Validation loss: 2.576667315755255

Epoch: 5| Step: 3
Training loss: 1.3044120360720184
Validation loss: 2.6002191315214738

Epoch: 5| Step: 4
Training loss: 1.6514259476812907
Validation loss: 2.588761557610495

Epoch: 5| Step: 5
Training loss: 1.7949864953895842
Validation loss: 2.5966684246261322

Epoch: 5| Step: 6
Training loss: 1.6940745391164587
Validation loss: 2.5802871115070998

Epoch: 5| Step: 7
Training loss: 1.6016015769099
Validation loss: 2.6170440141052014

Epoch: 5| Step: 8
Training loss: 1.4777835056286346
Validation loss: 2.6044079033061114

Epoch: 5| Step: 9
Training loss: 1.7844703074320651
Validation loss: 2.6217725455658583

Epoch: 5| Step: 10
Training loss: 1.956736590042065
Validation loss: 2.6175271321547946

Epoch: 5| Step: 11
Training loss: 1.7305796568314664
Validation loss: 2.5910990891321752

Epoch: 414| Step: 0
Training loss: 2.018680474468832
Validation loss: 2.602946893491982

Epoch: 5| Step: 1
Training loss: 1.5164653375464467
Validation loss: 2.627385482282724

Epoch: 5| Step: 2
Training loss: 1.3400639389213258
Validation loss: 2.635930517609881

Epoch: 5| Step: 3
Training loss: 1.56780220671619
Validation loss: 2.614060567492956

Epoch: 5| Step: 4
Training loss: 2.054755844313974
Validation loss: 2.615515186977712

Epoch: 5| Step: 5
Training loss: 1.7074333084062256
Validation loss: 2.566831254532937

Epoch: 5| Step: 6
Training loss: 1.9109353191023302
Validation loss: 2.6006897158226776

Epoch: 5| Step: 7
Training loss: 1.1459197387483986
Validation loss: 2.586937287551463

Epoch: 5| Step: 8
Training loss: 1.4461889960002114
Validation loss: 2.58167312454621

Epoch: 5| Step: 9
Training loss: 1.3616920105261547
Validation loss: 2.5813933222639225

Epoch: 5| Step: 10
Training loss: 2.1808651166481936
Validation loss: 2.5696881317591904

Epoch: 5| Step: 11
Training loss: 1.7861372174375016
Validation loss: 2.5797760233332534

Epoch: 415| Step: 0
Training loss: 1.848838573033777
Validation loss: 2.5771736200645847

Epoch: 5| Step: 1
Training loss: 1.7031077112842752
Validation loss: 2.581818191425392

Epoch: 5| Step: 2
Training loss: 1.5755204718303002
Validation loss: 2.5791286518600636

Epoch: 5| Step: 3
Training loss: 2.1185214074074867
Validation loss: 2.5950077982695317

Epoch: 5| Step: 4
Training loss: 1.4213073771225777
Validation loss: 2.589128851093117

Epoch: 5| Step: 5
Training loss: 1.6121841653640372
Validation loss: 2.6261630736243293

Epoch: 5| Step: 6
Training loss: 1.9243586549377594
Validation loss: 2.6494434363028923

Epoch: 5| Step: 7
Training loss: 1.703527630451168
Validation loss: 2.632873749515751

Epoch: 5| Step: 8
Training loss: 1.6231704830103009
Validation loss: 2.6663623104653396

Epoch: 5| Step: 9
Training loss: 1.5424565104779124
Validation loss: 2.654853973797057

Epoch: 5| Step: 10
Training loss: 1.3857852856504917
Validation loss: 2.636803470710433

Epoch: 5| Step: 11
Training loss: 1.5353943928828733
Validation loss: 2.608949889314808

Epoch: 416| Step: 0
Training loss: 2.0988232085573117
Validation loss: 2.61527044201596

Epoch: 5| Step: 1
Training loss: 1.641434823849191
Validation loss: 2.5788392089154386

Epoch: 5| Step: 2
Training loss: 2.1668231858670506
Validation loss: 2.5818383533872313

Epoch: 5| Step: 3
Training loss: 2.1052438477835222
Validation loss: 2.566601661121094

Epoch: 5| Step: 4
Training loss: 1.630108579400954
Validation loss: 2.597898295127765

Epoch: 5| Step: 5
Training loss: 1.2807144813683338
Validation loss: 2.5790525944760407

Epoch: 5| Step: 6
Training loss: 1.6323107080702082
Validation loss: 2.5751596601918947

Epoch: 5| Step: 7
Training loss: 1.18017578125
Validation loss: 2.6023732164131506

Epoch: 5| Step: 8
Training loss: 1.2385035173953718
Validation loss: 2.632944460315303

Epoch: 5| Step: 9
Training loss: 1.7077979280036841
Validation loss: 2.6763764659144784

Epoch: 5| Step: 10
Training loss: 2.085753814953485
Validation loss: 2.6603402827048277

Epoch: 5| Step: 11
Training loss: 0.6119231475730349
Validation loss: 2.614011247265072

Epoch: 417| Step: 0
Training loss: 1.7748997243575926
Validation loss: 2.6008943725075664

Epoch: 5| Step: 1
Training loss: 1.382641194395558
Validation loss: 2.6510561428661603

Epoch: 5| Step: 2
Training loss: 2.142552753809447
Validation loss: 2.5998936475496515

Epoch: 5| Step: 3
Training loss: 1.4022001230119296
Validation loss: 2.575288121143896

Epoch: 5| Step: 4
Training loss: 1.5190351995492015
Validation loss: 2.539818894620503

Epoch: 5| Step: 5
Training loss: 1.6327545301742217
Validation loss: 2.530122187815147

Epoch: 5| Step: 6
Training loss: 1.3006926726920778
Validation loss: 2.579424151220425

Epoch: 5| Step: 7
Training loss: 1.592816247604479
Validation loss: 2.5673684223401017

Epoch: 5| Step: 8
Training loss: 1.7858243063685053
Validation loss: 2.5708917855882834

Epoch: 5| Step: 9
Training loss: 2.3637771464483044
Validation loss: 2.583773061541437

Epoch: 5| Step: 10
Training loss: 1.5053934249681635
Validation loss: 2.611206618691735

Epoch: 5| Step: 11
Training loss: 2.284629826350634
Validation loss: 2.5675161739868817

Epoch: 418| Step: 0
Training loss: 1.2939348558687158
Validation loss: 2.5758352148858954

Epoch: 5| Step: 1
Training loss: 1.497096350755092
Validation loss: 2.5825077450178515

Epoch: 5| Step: 2
Training loss: 1.5134052657090091
Validation loss: 2.6097824555202482

Epoch: 5| Step: 3
Training loss: 1.242947040322715
Validation loss: 2.6344050336689184

Epoch: 5| Step: 4
Training loss: 2.5572272225914237
Validation loss: 2.6091949339847917

Epoch: 5| Step: 5
Training loss: 2.080965209354824
Validation loss: 2.633439748662056

Epoch: 5| Step: 6
Training loss: 1.628375142919807
Validation loss: 2.651781973057111

Epoch: 5| Step: 7
Training loss: 1.4049826103030265
Validation loss: 2.616093011001695

Epoch: 5| Step: 8
Training loss: 1.6770435194261342
Validation loss: 2.6176753675938067

Epoch: 5| Step: 9
Training loss: 1.677777006697881
Validation loss: 2.596467264684423

Epoch: 5| Step: 10
Training loss: 1.4646463083083103
Validation loss: 2.5946252296041994

Epoch: 5| Step: 11
Training loss: 1.7914551306941873
Validation loss: 2.5817234434870766

Epoch: 419| Step: 0
Training loss: 1.6039088483771726
Validation loss: 2.5538677024013228

Epoch: 5| Step: 1
Training loss: 1.6789664916692995
Validation loss: 2.582527843896397

Epoch: 5| Step: 2
Training loss: 1.5310689079479767
Validation loss: 2.568964364047808

Epoch: 5| Step: 3
Training loss: 1.8716359796270148
Validation loss: 2.566174189402704

Epoch: 5| Step: 4
Training loss: 1.1913138431921548
Validation loss: 2.5648716926117734

Epoch: 5| Step: 5
Training loss: 1.9313390668064736
Validation loss: 2.576178488290284

Epoch: 5| Step: 6
Training loss: 1.8629832159362325
Validation loss: 2.6055177324638774

Epoch: 5| Step: 7
Training loss: 1.1638997623438445
Validation loss: 2.5815357034743456

Epoch: 5| Step: 8
Training loss: 1.9519334133665203
Validation loss: 2.591698616654753

Epoch: 5| Step: 9
Training loss: 1.6131944979418003
Validation loss: 2.598757987750953

Epoch: 5| Step: 10
Training loss: 1.5867384217703668
Validation loss: 2.6301975980231136

Epoch: 5| Step: 11
Training loss: 1.7740496280613762
Validation loss: 2.5966426315427644

Epoch: 420| Step: 0
Training loss: 1.5445166440976457
Validation loss: 2.598527931295946

Epoch: 5| Step: 1
Training loss: 1.7617690931346293
Validation loss: 2.6294035344396214

Epoch: 5| Step: 2
Training loss: 1.3598507892575915
Validation loss: 2.6281989753584325

Epoch: 5| Step: 3
Training loss: 1.5312828527546376
Validation loss: 2.6420460964499175

Epoch: 5| Step: 4
Training loss: 2.1675184727357872
Validation loss: 2.5802202823276508

Epoch: 5| Step: 5
Training loss: 1.5966218243767978
Validation loss: 2.5802204863829705

Epoch: 5| Step: 6
Training loss: 1.556733055673119
Validation loss: 2.5962140087889356

Epoch: 5| Step: 7
Training loss: 1.978472363675911
Validation loss: 2.5738635360775937

Epoch: 5| Step: 8
Training loss: 1.3024806929491781
Validation loss: 2.5521006499241445

Epoch: 5| Step: 9
Training loss: 1.4463067011816881
Validation loss: 2.5781674776527486

Epoch: 5| Step: 10
Training loss: 1.6983537247955673
Validation loss: 2.5732031802961424

Epoch: 5| Step: 11
Training loss: 2.516786484887078
Validation loss: 2.5563382289741936

Epoch: 421| Step: 0
Training loss: 1.493382160433025
Validation loss: 2.619095997497721

Epoch: 5| Step: 1
Training loss: 1.4452374413048077
Validation loss: 2.623303500962756

Epoch: 5| Step: 2
Training loss: 1.3551774385269917
Validation loss: 2.643956642702409

Epoch: 5| Step: 3
Training loss: 1.8614084360543253
Validation loss: 2.584901646403788

Epoch: 5| Step: 4
Training loss: 1.3711143992029253
Validation loss: 2.6026015015937656

Epoch: 5| Step: 5
Training loss: 2.017785858361248
Validation loss: 2.5990144740114203

Epoch: 5| Step: 6
Training loss: 1.7131135245282938
Validation loss: 2.57982971397064

Epoch: 5| Step: 7
Training loss: 1.745269785796346
Validation loss: 2.610631881791861

Epoch: 5| Step: 8
Training loss: 1.0547332188622376
Validation loss: 2.5951113977207605

Epoch: 5| Step: 9
Training loss: 1.5620674297465758
Validation loss: 2.576868976620211

Epoch: 5| Step: 10
Training loss: 2.1088715129002913
Validation loss: 2.6164401073738817

Epoch: 5| Step: 11
Training loss: 1.7782867948001377
Validation loss: 2.6079410450442944

Epoch: 422| Step: 0
Training loss: 1.8805843480978641
Validation loss: 2.595516266039856

Epoch: 5| Step: 1
Training loss: 1.44964428846522
Validation loss: 2.6106578429821936

Epoch: 5| Step: 2
Training loss: 1.7376149475715756
Validation loss: 2.605987777371335

Epoch: 5| Step: 3
Training loss: 1.9330351668117634
Validation loss: 2.5680113465966095

Epoch: 5| Step: 4
Training loss: 2.3120725081930473
Validation loss: 2.552008074344943

Epoch: 5| Step: 5
Training loss: 1.5568953129849425
Validation loss: 2.5409694494439834

Epoch: 5| Step: 6
Training loss: 1.9274573160830997
Validation loss: 2.5448684159795207

Epoch: 5| Step: 7
Training loss: 1.3310130414374008
Validation loss: 2.5459008528397136

Epoch: 5| Step: 8
Training loss: 1.2643688702965072
Validation loss: 2.571078755371608

Epoch: 5| Step: 9
Training loss: 1.353243978084215
Validation loss: 2.590365020321371

Epoch: 5| Step: 10
Training loss: 1.1446700809370816
Validation loss: 2.584526529909167

Epoch: 5| Step: 11
Training loss: 2.453086415370073
Validation loss: 2.611940033081654

Epoch: 423| Step: 0
Training loss: 1.4398792314219697
Validation loss: 2.6183321940453776

Epoch: 5| Step: 1
Training loss: 1.2464432181482676
Validation loss: 2.594910461624253

Epoch: 5| Step: 2
Training loss: 1.7608199099769102
Validation loss: 2.601566276509367

Epoch: 5| Step: 3
Training loss: 1.410561162664437
Validation loss: 2.597760963719553

Epoch: 5| Step: 4
Training loss: 1.9985276405459709
Validation loss: 2.596013544531002

Epoch: 5| Step: 5
Training loss: 1.60259269517676
Validation loss: 2.580905720932765

Epoch: 5| Step: 6
Training loss: 1.7646653935051104
Validation loss: 2.5750716151614887

Epoch: 5| Step: 7
Training loss: 1.7042679057871286
Validation loss: 2.571201058791895

Epoch: 5| Step: 8
Training loss: 1.6696421606471836
Validation loss: 2.552504268627726

Epoch: 5| Step: 9
Training loss: 2.0546486274320124
Validation loss: 2.616047579630109

Epoch: 5| Step: 10
Training loss: 1.1710377563364223
Validation loss: 2.619637453812457

Epoch: 5| Step: 11
Training loss: 1.9472789706554334
Validation loss: 2.6247335442532442

Epoch: 424| Step: 0
Training loss: 1.9402428562508096
Validation loss: 2.583678266098206

Epoch: 5| Step: 1
Training loss: 1.618088181166289
Validation loss: 2.597622508353317

Epoch: 5| Step: 2
Training loss: 1.5296510405671626
Validation loss: 2.5632096912797913

Epoch: 5| Step: 3
Training loss: 1.630723483882795
Validation loss: 2.573568841901948

Epoch: 5| Step: 4
Training loss: 1.7959572480089903
Validation loss: 2.6150674954256465

Epoch: 5| Step: 5
Training loss: 1.9519631554065504
Validation loss: 2.605339805847641

Epoch: 5| Step: 6
Training loss: 1.7368914931407495
Validation loss: 2.6589032254875575

Epoch: 5| Step: 7
Training loss: 1.3135023376885484
Validation loss: 2.6325102650537957

Epoch: 5| Step: 8
Training loss: 1.6167638841218381
Validation loss: 2.6413481435070096

Epoch: 5| Step: 9
Training loss: 1.3246579862430823
Validation loss: 2.649912986736341

Epoch: 5| Step: 10
Training loss: 1.3931196318258139
Validation loss: 2.617968124955726

Epoch: 5| Step: 11
Training loss: 1.1893874778233349
Validation loss: 2.625765934719498

Epoch: 425| Step: 0
Training loss: 0.9933542615224114
Validation loss: 2.607485269640226

Epoch: 5| Step: 1
Training loss: 1.219113124646029
Validation loss: 2.6234432592247336

Epoch: 5| Step: 2
Training loss: 1.588974773794912
Validation loss: 2.6363638330527284

Epoch: 5| Step: 3
Training loss: 2.0883789633322123
Validation loss: 2.6465666698315307

Epoch: 5| Step: 4
Training loss: 1.2335404097637586
Validation loss: 2.6087630500400025

Epoch: 5| Step: 5
Training loss: 1.2617779413753316
Validation loss: 2.6024838249065443

Epoch: 5| Step: 6
Training loss: 1.8669444927592758
Validation loss: 2.6191568205823645

Epoch: 5| Step: 7
Training loss: 1.9060194782890945
Validation loss: 2.6057901179486866

Epoch: 5| Step: 8
Training loss: 1.9959193562211088
Validation loss: 2.573829173747235

Epoch: 5| Step: 9
Training loss: 1.9957826972967527
Validation loss: 2.5981441030135746

Epoch: 5| Step: 10
Training loss: 1.4179679933656297
Validation loss: 2.5670604946043287

Epoch: 5| Step: 11
Training loss: 1.4634360097665344
Validation loss: 2.5638026400065494

Epoch: 426| Step: 0
Training loss: 1.6651766633483405
Validation loss: 2.5591460624340723

Epoch: 5| Step: 1
Training loss: 1.1966012726362711
Validation loss: 2.5961986266863164

Epoch: 5| Step: 2
Training loss: 1.4475731567976127
Validation loss: 2.5821973869364974

Epoch: 5| Step: 3
Training loss: 2.0867425743693904
Validation loss: 2.5656717798736253

Epoch: 5| Step: 4
Training loss: 1.415042600765504
Validation loss: 2.591277706042899

Epoch: 5| Step: 5
Training loss: 1.678647806290917
Validation loss: 2.578061721487579

Epoch: 5| Step: 6
Training loss: 1.5101819963229008
Validation loss: 2.592436227942952

Epoch: 5| Step: 7
Training loss: 1.4421746911568072
Validation loss: 2.6280778748365394

Epoch: 5| Step: 8
Training loss: 1.4119782235219693
Validation loss: 2.585102841688354

Epoch: 5| Step: 9
Training loss: 1.6822077806027296
Validation loss: 2.6076996768402303

Epoch: 5| Step: 10
Training loss: 1.8552197741056298
Validation loss: 2.5920340825462698

Epoch: 5| Step: 11
Training loss: 1.2071372173916015
Validation loss: 2.6026498738758295

Epoch: 427| Step: 0
Training loss: 1.6173041112754238
Validation loss: 2.5910686590053396

Epoch: 5| Step: 1
Training loss: 1.6088857555241804
Validation loss: 2.5932282129794055

Epoch: 5| Step: 2
Training loss: 1.402961106275814
Validation loss: 2.594265461453876

Epoch: 5| Step: 3
Training loss: 1.708297085571304
Validation loss: 2.5916574263842387

Epoch: 5| Step: 4
Training loss: 1.4426557712642967
Validation loss: 2.597158130890804

Epoch: 5| Step: 5
Training loss: 1.558412699114817
Validation loss: 2.6265242594049973

Epoch: 5| Step: 6
Training loss: 1.7763898700190779
Validation loss: 2.633349570443599

Epoch: 5| Step: 7
Training loss: 1.5215433718955251
Validation loss: 2.656524991779315

Epoch: 5| Step: 8
Training loss: 1.4879202016793616
Validation loss: 2.655743101783806

Epoch: 5| Step: 9
Training loss: 1.5383615979414977
Validation loss: 2.620467534233947

Epoch: 5| Step: 10
Training loss: 2.0137718020489657
Validation loss: 2.5892639124787102

Epoch: 5| Step: 11
Training loss: 0.9341443724500068
Validation loss: 2.5703878188765037

Epoch: 428| Step: 0
Training loss: 1.6411066710620743
Validation loss: 2.5730246792771183

Epoch: 5| Step: 1
Training loss: 1.3175000816504436
Validation loss: 2.583725224016113

Epoch: 5| Step: 2
Training loss: 1.579182110243731
Validation loss: 2.5852358155136397

Epoch: 5| Step: 3
Training loss: 1.263667346881377
Validation loss: 2.596967746441792

Epoch: 5| Step: 4
Training loss: 1.3694257017679559
Validation loss: 2.5749365346611963

Epoch: 5| Step: 5
Training loss: 1.90002023786508
Validation loss: 2.586102502481665

Epoch: 5| Step: 6
Training loss: 2.0736932753426713
Validation loss: 2.5910026638535557

Epoch: 5| Step: 7
Training loss: 1.6973298897994222
Validation loss: 2.582080123061784

Epoch: 5| Step: 8
Training loss: 1.226845289542017
Validation loss: 2.615676352522075

Epoch: 5| Step: 9
Training loss: 1.333729039521764
Validation loss: 2.6774647375456744

Epoch: 5| Step: 10
Training loss: 1.957940353030549
Validation loss: 2.6656869576257374

Epoch: 5| Step: 11
Training loss: 0.6748978678825773
Validation loss: 2.6713571734506623

Epoch: 429| Step: 0
Training loss: 1.4995289698769558
Validation loss: 2.6866470136546807

Epoch: 5| Step: 1
Training loss: 1.6058558533374028
Validation loss: 2.6590790661264294

Epoch: 5| Step: 2
Training loss: 1.7914720326060407
Validation loss: 2.637609192996945

Epoch: 5| Step: 3
Training loss: 1.2031700819412405
Validation loss: 2.63628854515098

Epoch: 5| Step: 4
Training loss: 1.9028862213022417
Validation loss: 2.6193436959454006

Epoch: 5| Step: 5
Training loss: 1.9153687671345119
Validation loss: 2.6041716626437266

Epoch: 5| Step: 6
Training loss: 1.4299527115105493
Validation loss: 2.6156388212907564

Epoch: 5| Step: 7
Training loss: 1.643189161229811
Validation loss: 2.5741135262655788

Epoch: 5| Step: 8
Training loss: 1.886086304616497
Validation loss: 2.574560579749968

Epoch: 5| Step: 9
Training loss: 1.6685808474644392
Validation loss: 2.579624995817025

Epoch: 5| Step: 10
Training loss: 1.1788518105609447
Validation loss: 2.573652657688566

Epoch: 5| Step: 11
Training loss: 1.2694002524061179
Validation loss: 2.5747626641225

Epoch: 430| Step: 0
Training loss: 2.1451459604678247
Validation loss: 2.567742223045267

Epoch: 5| Step: 1
Training loss: 1.1781293671625686
Validation loss: 2.5369330176772262

Epoch: 5| Step: 2
Training loss: 1.3421989626944542
Validation loss: 2.5629253499638462

Epoch: 5| Step: 3
Training loss: 1.333132738680226
Validation loss: 2.622822865350862

Epoch: 5| Step: 4
Training loss: 1.5334556420238206
Validation loss: 2.5870122260898545

Epoch: 5| Step: 5
Training loss: 1.1632378236390366
Validation loss: 2.604964287995719

Epoch: 5| Step: 6
Training loss: 1.0012057902544746
Validation loss: 2.619862894236382

Epoch: 5| Step: 7
Training loss: 2.3386358795785624
Validation loss: 2.655585276886503

Epoch: 5| Step: 8
Training loss: 1.8887193391786667
Validation loss: 2.5918669050347978

Epoch: 5| Step: 9
Training loss: 1.6109475166016791
Validation loss: 2.6164277791257278

Epoch: 5| Step: 10
Training loss: 1.6441996550436786
Validation loss: 2.6114975905894493

Epoch: 5| Step: 11
Training loss: 1.5662760311803983
Validation loss: 2.585142699200647

Epoch: 431| Step: 0
Training loss: 1.6795209935185917
Validation loss: 2.571446131086188

Epoch: 5| Step: 1
Training loss: 1.4551275257710967
Validation loss: 2.6238430099818526

Epoch: 5| Step: 2
Training loss: 1.618473076422909
Validation loss: 2.5819638388216943

Epoch: 5| Step: 3
Training loss: 1.093215920978551
Validation loss: 2.6165284954531085

Epoch: 5| Step: 4
Training loss: 1.8918362355238403
Validation loss: 2.605112820724733

Epoch: 5| Step: 5
Training loss: 1.3606140803545947
Validation loss: 2.6135576270234293

Epoch: 5| Step: 6
Training loss: 1.5759727985726213
Validation loss: 2.624777182704521

Epoch: 5| Step: 7
Training loss: 1.8422554553620623
Validation loss: 2.6466595018163344

Epoch: 5| Step: 8
Training loss: 1.1316717257454498
Validation loss: 2.6320913253424516

Epoch: 5| Step: 9
Training loss: 1.4107988325310492
Validation loss: 2.622881727210637

Epoch: 5| Step: 10
Training loss: 1.8507165706696345
Validation loss: 2.6000973162106096

Epoch: 5| Step: 11
Training loss: 1.4730624744092062
Validation loss: 2.6405979245394753

Epoch: 432| Step: 0
Training loss: 1.609635045050966
Validation loss: 2.6195621288803124

Epoch: 5| Step: 1
Training loss: 1.6433522399500815
Validation loss: 2.5792353079129873

Epoch: 5| Step: 2
Training loss: 1.3471677475279584
Validation loss: 2.579693758160005

Epoch: 5| Step: 3
Training loss: 1.1442201471482993
Validation loss: 2.571219403127051

Epoch: 5| Step: 4
Training loss: 1.2795731806665422
Validation loss: 2.5834411661397305

Epoch: 5| Step: 5
Training loss: 2.0371818200430267
Validation loss: 2.5819260022233954

Epoch: 5| Step: 6
Training loss: 1.8075394987272695
Validation loss: 2.592359260002402

Epoch: 5| Step: 7
Training loss: 1.5573800698729112
Validation loss: 2.617994626216264

Epoch: 5| Step: 8
Training loss: 1.761391010798844
Validation loss: 2.6514747405791557

Epoch: 5| Step: 9
Training loss: 1.804118078985678
Validation loss: 2.634517148015228

Epoch: 5| Step: 10
Training loss: 1.238336796522539
Validation loss: 2.626714385007867

Epoch: 5| Step: 11
Training loss: 1.5240897322993223
Validation loss: 2.622041863370601

Epoch: 433| Step: 0
Training loss: 1.5039124327693525
Validation loss: 2.585157866567285

Epoch: 5| Step: 1
Training loss: 1.3111959518624983
Validation loss: 2.588016381237192

Epoch: 5| Step: 2
Training loss: 1.261204003363927
Validation loss: 2.576710769708508

Epoch: 5| Step: 3
Training loss: 1.4896252588449688
Validation loss: 2.5833728746238798

Epoch: 5| Step: 4
Training loss: 2.069270724771764
Validation loss: 2.6139561342867736

Epoch: 5| Step: 5
Training loss: 1.5567686633744426
Validation loss: 2.5821403561161476

Epoch: 5| Step: 6
Training loss: 1.3478744551324897
Validation loss: 2.612507331570159

Epoch: 5| Step: 7
Training loss: 1.5204468153207444
Validation loss: 2.618736939560787

Epoch: 5| Step: 8
Training loss: 1.7494037838687448
Validation loss: 2.6339095930488736

Epoch: 5| Step: 9
Training loss: 1.409477345203695
Validation loss: 2.6253696211697557

Epoch: 5| Step: 10
Training loss: 1.7720738348163287
Validation loss: 2.6530886256312183

Epoch: 5| Step: 11
Training loss: 2.8001311543946517
Validation loss: 2.6138910552398844

Epoch: 434| Step: 0
Training loss: 1.8037735908007184
Validation loss: 2.615020275967329

Epoch: 5| Step: 1
Training loss: 1.3357390317671818
Validation loss: 2.5596021475347044

Epoch: 5| Step: 2
Training loss: 1.217450843304331
Validation loss: 2.5774486502284706

Epoch: 5| Step: 3
Training loss: 1.9045036946984684
Validation loss: 2.6238358466885825

Epoch: 5| Step: 4
Training loss: 1.1853096990253031
Validation loss: 2.5871559030982727

Epoch: 5| Step: 5
Training loss: 1.5604209801377018
Validation loss: 2.5701011872317134

Epoch: 5| Step: 6
Training loss: 1.3285323471995487
Validation loss: 2.583889150943354

Epoch: 5| Step: 7
Training loss: 2.058540937119037
Validation loss: 2.5618381071850513

Epoch: 5| Step: 8
Training loss: 1.794296271850203
Validation loss: 2.609693026245415

Epoch: 5| Step: 9
Training loss: 1.727370267377234
Validation loss: 2.6140963808893987

Epoch: 5| Step: 10
Training loss: 1.9150050742378437
Validation loss: 2.5717557161772655

Epoch: 5| Step: 11
Training loss: 1.2402706591487407
Validation loss: 2.6030425633768077

Epoch: 435| Step: 0
Training loss: 1.6092092928713624
Validation loss: 2.605698288963273

Epoch: 5| Step: 1
Training loss: 1.6100741599163368
Validation loss: 2.6418687761671293

Epoch: 5| Step: 2
Training loss: 1.4341457873606493
Validation loss: 2.5848829994802855

Epoch: 5| Step: 3
Training loss: 1.6311170911174044
Validation loss: 2.610514169431326

Epoch: 5| Step: 4
Training loss: 1.2895931192169543
Validation loss: 2.609626525664797

Epoch: 5| Step: 5
Training loss: 1.7840373666810097
Validation loss: 2.580513000416852

Epoch: 5| Step: 6
Training loss: 1.6741640339221953
Validation loss: 2.5964956745597974

Epoch: 5| Step: 7
Training loss: 1.2650668008227168
Validation loss: 2.5811709511193133

Epoch: 5| Step: 8
Training loss: 1.2151276480570643
Validation loss: 2.5910903822494293

Epoch: 5| Step: 9
Training loss: 1.8340698482270676
Validation loss: 2.5964634654545766

Epoch: 5| Step: 10
Training loss: 2.193189143897681
Validation loss: 2.586456726899239

Epoch: 5| Step: 11
Training loss: 1.0817330290289855
Validation loss: 2.6136220454149237

Epoch: 436| Step: 0
Training loss: 1.7056144928180466
Validation loss: 2.612984300666852

Epoch: 5| Step: 1
Training loss: 0.9656112953867793
Validation loss: 2.6135464786947953

Epoch: 5| Step: 2
Training loss: 1.3826793886762458
Validation loss: 2.671474954798872

Epoch: 5| Step: 3
Training loss: 1.9819750352705734
Validation loss: 2.690550089851858

Epoch: 5| Step: 4
Training loss: 1.6917492384403634
Validation loss: 2.7269108794733743

Epoch: 5| Step: 5
Training loss: 1.58456210925747
Validation loss: 2.6973119313258698

Epoch: 5| Step: 6
Training loss: 1.5784709286893075
Validation loss: 2.6571113573602156

Epoch: 5| Step: 7
Training loss: 1.1192694518286532
Validation loss: 2.6361572722732496

Epoch: 5| Step: 8
Training loss: 1.6723579350963818
Validation loss: 2.578167901500982

Epoch: 5| Step: 9
Training loss: 1.6242375419083737
Validation loss: 2.6057078429579805

Epoch: 5| Step: 10
Training loss: 1.4478034745941015
Validation loss: 2.6054419878834385

Epoch: 5| Step: 11
Training loss: 0.9428753608279123
Validation loss: 2.579106450392205

Epoch: 437| Step: 0
Training loss: 2.041456665864724
Validation loss: 2.5981281396857425

Epoch: 5| Step: 1
Training loss: 1.0271631234354603
Validation loss: 2.5993746664211055

Epoch: 5| Step: 2
Training loss: 1.241995838662024
Validation loss: 2.5846618971280884

Epoch: 5| Step: 3
Training loss: 1.489320327197129
Validation loss: 2.642660853483544

Epoch: 5| Step: 4
Training loss: 1.485864474230005
Validation loss: 2.6954725171931644

Epoch: 5| Step: 5
Training loss: 1.9006880618581237
Validation loss: 2.7087082542215177

Epoch: 5| Step: 6
Training loss: 2.1573718925624767
Validation loss: 2.7995895482266024

Epoch: 5| Step: 7
Training loss: 2.047995922874326
Validation loss: 2.747529419217062

Epoch: 5| Step: 8
Training loss: 1.3496347251090173
Validation loss: 2.6607224510237653

Epoch: 5| Step: 9
Training loss: 1.4707621325728888
Validation loss: 2.626702891630894

Epoch: 5| Step: 10
Training loss: 1.197474052371069
Validation loss: 2.6095485020440248

Epoch: 5| Step: 11
Training loss: 1.0469539100172067
Validation loss: 2.596707048734655

Epoch: 438| Step: 0
Training loss: 1.1834903080119943
Validation loss: 2.5693732790213164

Epoch: 5| Step: 1
Training loss: 1.486807506515852
Validation loss: 2.5548821937963306

Epoch: 5| Step: 2
Training loss: 1.5300778164740323
Validation loss: 2.556401248582929

Epoch: 5| Step: 3
Training loss: 1.4522451382669088
Validation loss: 2.5722047687071803

Epoch: 5| Step: 4
Training loss: 1.7393486945917929
Validation loss: 2.589280310282212

Epoch: 5| Step: 5
Training loss: 1.6986673096102143
Validation loss: 2.5542573284738377

Epoch: 5| Step: 6
Training loss: 1.6068110365657855
Validation loss: 2.593109760394413

Epoch: 5| Step: 7
Training loss: 1.8801218648736904
Validation loss: 2.6523012917237874

Epoch: 5| Step: 8
Training loss: 1.8525667967703545
Validation loss: 2.6872824462543963

Epoch: 5| Step: 9
Training loss: 1.4005683562686453
Validation loss: 2.678556346245341

Epoch: 5| Step: 10
Training loss: 1.5490998730856005
Validation loss: 2.6544318615121174

Epoch: 5| Step: 11
Training loss: 2.328728207267644
Validation loss: 2.6716254156782817

Epoch: 439| Step: 0
Training loss: 1.14715208401589
Validation loss: 2.6076393560608637

Epoch: 5| Step: 1
Training loss: 1.2079188962514267
Validation loss: 2.613141309396363

Epoch: 5| Step: 2
Training loss: 1.6065306481418864
Validation loss: 2.574637707435869

Epoch: 5| Step: 3
Training loss: 1.3511094232459429
Validation loss: 2.5846776822699704

Epoch: 5| Step: 4
Training loss: 1.2991717120731854
Validation loss: 2.6010552103598723

Epoch: 5| Step: 5
Training loss: 1.7623377894434262
Validation loss: 2.5751712852440147

Epoch: 5| Step: 6
Training loss: 1.64193223009102
Validation loss: 2.597360818837389

Epoch: 5| Step: 7
Training loss: 1.154545791044985
Validation loss: 2.5865556337324502

Epoch: 5| Step: 8
Training loss: 1.4412058455758148
Validation loss: 2.5877035397256223

Epoch: 5| Step: 9
Training loss: 1.6681276911245386
Validation loss: 2.6286903545876554

Epoch: 5| Step: 10
Training loss: 1.848113505457047
Validation loss: 2.5979766342188144

Epoch: 5| Step: 11
Training loss: 2.0026311256634544
Validation loss: 2.585412543603733

Epoch: 440| Step: 0
Training loss: 1.364525257456935
Validation loss: 2.6255143774238636

Epoch: 5| Step: 1
Training loss: 0.9955623031770242
Validation loss: 2.5970180980062536

Epoch: 5| Step: 2
Training loss: 1.3304176737399918
Validation loss: 2.5938688542048096

Epoch: 5| Step: 3
Training loss: 1.3204409294190413
Validation loss: 2.588662579640008

Epoch: 5| Step: 4
Training loss: 1.8315781803758358
Validation loss: 2.6101633049919895

Epoch: 5| Step: 5
Training loss: 1.9941376360087173
Validation loss: 2.6317960907155493

Epoch: 5| Step: 6
Training loss: 1.338438180962923
Validation loss: 2.6315976857785603

Epoch: 5| Step: 7
Training loss: 1.1063057793816709
Validation loss: 2.607482265577907

Epoch: 5| Step: 8
Training loss: 1.9672317705937443
Validation loss: 2.617389853326889

Epoch: 5| Step: 9
Training loss: 1.6748799921572477
Validation loss: 2.647202720605838

Epoch: 5| Step: 10
Training loss: 0.8852727249426096
Validation loss: 2.65779133376556

Epoch: 5| Step: 11
Training loss: 1.7868680196907945
Validation loss: 2.621440544248947

Epoch: 441| Step: 0
Training loss: 1.4694772096925859
Validation loss: 2.6474302058615526

Epoch: 5| Step: 1
Training loss: 0.978484619624018
Validation loss: 2.681423725822339

Epoch: 5| Step: 2
Training loss: 1.6039421452864269
Validation loss: 2.6648037085371534

Epoch: 5| Step: 3
Training loss: 1.4493931256699328
Validation loss: 2.631999791222374

Epoch: 5| Step: 4
Training loss: 1.5958771067991084
Validation loss: 2.5871921158026123

Epoch: 5| Step: 5
Training loss: 1.767230966102586
Validation loss: 2.598032307950813

Epoch: 5| Step: 6
Training loss: 1.1230208684149132
Validation loss: 2.5946375925289904

Epoch: 5| Step: 7
Training loss: 1.4781964661820353
Validation loss: 2.600972548791051

Epoch: 5| Step: 8
Training loss: 1.2818095218297045
Validation loss: 2.586610312777896

Epoch: 5| Step: 9
Training loss: 1.694893710536947
Validation loss: 2.6184756131449993

Epoch: 5| Step: 10
Training loss: 1.4872679777868696
Validation loss: 2.5706521518076224

Epoch: 5| Step: 11
Training loss: 2.188498568817849
Validation loss: 2.6356299254989763

Epoch: 442| Step: 0
Training loss: 1.5309732148053061
Validation loss: 2.5977396519018923

Epoch: 5| Step: 1
Training loss: 1.517278575422589
Validation loss: 2.648895539141883

Epoch: 5| Step: 2
Training loss: 1.537627970014178
Validation loss: 2.6909871321781247

Epoch: 5| Step: 3
Training loss: 1.0859465015504846
Validation loss: 2.6431672839107025

Epoch: 5| Step: 4
Training loss: 1.2645426230919028
Validation loss: 2.625713633610915

Epoch: 5| Step: 5
Training loss: 1.24125117875242
Validation loss: 2.6284156027815184

Epoch: 5| Step: 6
Training loss: 0.9953110855068534
Validation loss: 2.606277793931232

Epoch: 5| Step: 7
Training loss: 1.6915689086228882
Validation loss: 2.6180881298095033

Epoch: 5| Step: 8
Training loss: 1.4577219453512031
Validation loss: 2.6051130266435623

Epoch: 5| Step: 9
Training loss: 2.073809279778168
Validation loss: 2.619997631998909

Epoch: 5| Step: 10
Training loss: 1.7962673984393769
Validation loss: 2.6478913793449372

Epoch: 5| Step: 11
Training loss: 0.7349095935105556
Validation loss: 2.6156055319064224

Epoch: 443| Step: 0
Training loss: 1.6201152008210016
Validation loss: 2.6131318396036507

Epoch: 5| Step: 1
Training loss: 1.817095291540377
Validation loss: 2.6286423745815033

Epoch: 5| Step: 2
Training loss: 1.2583967001330307
Validation loss: 2.6587832843375203

Epoch: 5| Step: 3
Training loss: 1.4471358062137696
Validation loss: 2.650871561185103

Epoch: 5| Step: 4
Training loss: 1.1683933672715727
Validation loss: 2.6304914089247005

Epoch: 5| Step: 5
Training loss: 1.3569642976661862
Validation loss: 2.611289568787374

Epoch: 5| Step: 6
Training loss: 1.0979873320816333
Validation loss: 2.6036428280715302

Epoch: 5| Step: 7
Training loss: 1.260168581841348
Validation loss: 2.587459746184342

Epoch: 5| Step: 8
Training loss: 1.7601918033644366
Validation loss: 2.604238380716257

Epoch: 5| Step: 9
Training loss: 1.3972557231753786
Validation loss: 2.6344438926223006

Epoch: 5| Step: 10
Training loss: 1.212137181771084
Validation loss: 2.5922849435639126

Epoch: 5| Step: 11
Training loss: 2.3179307009431924
Validation loss: 2.574204016003195

Epoch: 444| Step: 0
Training loss: 1.683449440278755
Validation loss: 2.6127807677736268

Epoch: 5| Step: 1
Training loss: 1.1573179313547464
Validation loss: 2.604663364090334

Epoch: 5| Step: 2
Training loss: 1.5274809558636477
Validation loss: 2.6110484264224083

Epoch: 5| Step: 3
Training loss: 1.5408650797325536
Validation loss: 2.5853526557562128

Epoch: 5| Step: 4
Training loss: 1.377321797248435
Validation loss: 2.610893599489069

Epoch: 5| Step: 5
Training loss: 1.4450876421897805
Validation loss: 2.6136653866808737

Epoch: 5| Step: 6
Training loss: 1.6577341879164058
Validation loss: 2.5837947115561355

Epoch: 5| Step: 7
Training loss: 1.4760425600826743
Validation loss: 2.5513467711904756

Epoch: 5| Step: 8
Training loss: 1.420421905836158
Validation loss: 2.580808860916108

Epoch: 5| Step: 9
Training loss: 1.2745991656461242
Validation loss: 2.6017949761277794

Epoch: 5| Step: 10
Training loss: 1.6175267697555593
Validation loss: 2.608406621971796

Epoch: 5| Step: 11
Training loss: 1.764654247145597
Validation loss: 2.6057399015772926

Epoch: 445| Step: 0
Training loss: 1.4058510956304466
Validation loss: 2.626608669761004

Epoch: 5| Step: 1
Training loss: 1.366924762003168
Validation loss: 2.665354949357301

Epoch: 5| Step: 2
Training loss: 1.8678420447849324
Validation loss: 2.6880743610620903

Epoch: 5| Step: 3
Training loss: 1.0906773049127974
Validation loss: 2.691603263505849

Epoch: 5| Step: 4
Training loss: 1.5558910216288617
Validation loss: 2.6703538673073117

Epoch: 5| Step: 5
Training loss: 1.5742567639931777
Validation loss: 2.677052354200451

Epoch: 5| Step: 6
Training loss: 1.5020928088492016
Validation loss: 2.6533619907004105

Epoch: 5| Step: 7
Training loss: 1.269202462683211
Validation loss: 2.669751913246279

Epoch: 5| Step: 8
Training loss: 1.6966031694552834
Validation loss: 2.6461114073979735

Epoch: 5| Step: 9
Training loss: 1.8104699703866605
Validation loss: 2.5972241111539973

Epoch: 5| Step: 10
Training loss: 1.1748738890804067
Validation loss: 2.6243109744871993

Epoch: 5| Step: 11
Training loss: 1.3216479167273691
Validation loss: 2.5961936829663217

Epoch: 446| Step: 0
Training loss: 1.0902226380796538
Validation loss: 2.6174109520106548

Epoch: 5| Step: 1
Training loss: 0.9076112192481843
Validation loss: 2.599746773076897

Epoch: 5| Step: 2
Training loss: 1.7479447148482046
Validation loss: 2.647226148489911

Epoch: 5| Step: 3
Training loss: 1.5659063973399248
Validation loss: 2.64708764964606

Epoch: 5| Step: 4
Training loss: 1.1548371833549542
Validation loss: 2.6411971200396653

Epoch: 5| Step: 5
Training loss: 1.2102551906815584
Validation loss: 2.6509159535477442

Epoch: 5| Step: 6
Training loss: 1.2125152645919932
Validation loss: 2.6645384742732685

Epoch: 5| Step: 7
Training loss: 1.292020605672912
Validation loss: 2.6428691311881005

Epoch: 5| Step: 8
Training loss: 2.243201900257715
Validation loss: 2.620428502141066

Epoch: 5| Step: 9
Training loss: 1.5938694479068307
Validation loss: 2.6364104592267035

Epoch: 5| Step: 10
Training loss: 1.3396877720741118
Validation loss: 2.613616739357715

Epoch: 5| Step: 11
Training loss: 1.6598547089430493
Validation loss: 2.5983853571758724

Epoch: 447| Step: 0
Training loss: 1.806915295315525
Validation loss: 2.597271428489235

Epoch: 5| Step: 1
Training loss: 1.835131269327969
Validation loss: 2.597664812499349

Epoch: 5| Step: 2
Training loss: 1.332214298144302
Validation loss: 2.652010792361701

Epoch: 5| Step: 3
Training loss: 1.5577743785789022
Validation loss: 2.608766024067677

Epoch: 5| Step: 4
Training loss: 1.3895145225740586
Validation loss: 2.6182190641369294

Epoch: 5| Step: 5
Training loss: 1.3388599309300295
Validation loss: 2.6411171554205075

Epoch: 5| Step: 6
Training loss: 1.0446204775787324
Validation loss: 2.59786172689934

Epoch: 5| Step: 7
Training loss: 1.1711976191676283
Validation loss: 2.6506103447039226

Epoch: 5| Step: 8
Training loss: 1.347988938993697
Validation loss: 2.653838955805836

Epoch: 5| Step: 9
Training loss: 1.3540198857891141
Validation loss: 2.7015315598112886

Epoch: 5| Step: 10
Training loss: 1.4396156830012106
Validation loss: 2.6565457011168365

Epoch: 5| Step: 11
Training loss: 1.3008081931683158
Validation loss: 2.6279616905030037

Epoch: 448| Step: 0
Training loss: 1.3305320469330886
Validation loss: 2.628182863845093

Epoch: 5| Step: 1
Training loss: 1.4414147684315954
Validation loss: 2.600364722444309

Epoch: 5| Step: 2
Training loss: 1.5007473355482026
Validation loss: 2.623087583724473

Epoch: 5| Step: 3
Training loss: 1.0946223458631137
Validation loss: 2.633451661537763

Epoch: 5| Step: 4
Training loss: 1.406228637533053
Validation loss: 2.632380418950586

Epoch: 5| Step: 5
Training loss: 1.2893319050719494
Validation loss: 2.651934738721018

Epoch: 5| Step: 6
Training loss: 1.6564018611743663
Validation loss: 2.646082105480515

Epoch: 5| Step: 7
Training loss: 1.7951485342344207
Validation loss: 2.620687238131738

Epoch: 5| Step: 8
Training loss: 1.2528051372415439
Validation loss: 2.609207642874235

Epoch: 5| Step: 9
Training loss: 1.4248119665199175
Validation loss: 2.63269284558468

Epoch: 5| Step: 10
Training loss: 1.0871163974196583
Validation loss: 2.6460606685102612

Epoch: 5| Step: 11
Training loss: 1.6174586709121086
Validation loss: 2.631125066906746

Epoch: 449| Step: 0
Training loss: 1.29450413566745
Validation loss: 2.611585187373331

Epoch: 5| Step: 1
Training loss: 1.7450755177855937
Validation loss: 2.6022039544822313

Epoch: 5| Step: 2
Training loss: 1.4333873465067746
Validation loss: 2.614505414574282

Epoch: 5| Step: 3
Training loss: 1.0829072016358263
Validation loss: 2.613086470799128

Epoch: 5| Step: 4
Training loss: 1.7368071402752197
Validation loss: 2.589582849156239

Epoch: 5| Step: 5
Training loss: 1.7421022402851933
Validation loss: 2.5895152739534555

Epoch: 5| Step: 6
Training loss: 1.7481361408990175
Validation loss: 2.5999247118246274

Epoch: 5| Step: 7
Training loss: 1.531446716751644
Validation loss: 2.570503347591181

Epoch: 5| Step: 8
Training loss: 1.4588922065515717
Validation loss: 2.6027964127763608

Epoch: 5| Step: 9
Training loss: 1.2257447645156094
Validation loss: 2.6164236671655496

Epoch: 5| Step: 10
Training loss: 0.9691411428515501
Validation loss: 2.6135041465412567

Epoch: 5| Step: 11
Training loss: 0.8694071157571864
Validation loss: 2.628678361557783

Epoch: 450| Step: 0
Training loss: 1.2714503879956214
Validation loss: 2.658586887795792

Epoch: 5| Step: 1
Training loss: 1.3232844384686853
Validation loss: 2.663691022149304

Epoch: 5| Step: 2
Training loss: 1.7332016008399176
Validation loss: 2.6737135831728667

Epoch: 5| Step: 3
Training loss: 0.8646926734143652
Validation loss: 2.6544165922277143

Epoch: 5| Step: 4
Training loss: 1.1418853485356748
Validation loss: 2.698129105519522

Epoch: 5| Step: 5
Training loss: 1.6389679305993021
Validation loss: 2.679928400835209

Epoch: 5| Step: 6
Training loss: 1.1986859159872352
Validation loss: 2.6650168051139116

Epoch: 5| Step: 7
Training loss: 1.5558719436248944
Validation loss: 2.6160621766897516

Epoch: 5| Step: 8
Training loss: 1.576809627646013
Validation loss: 2.640833957387558

Epoch: 5| Step: 9
Training loss: 1.4510566183042397
Validation loss: 2.627392276705601

Epoch: 5| Step: 10
Training loss: 1.5780116880924386
Validation loss: 2.6214649981686056

Epoch: 5| Step: 11
Training loss: 1.162790666153264
Validation loss: 2.63257735548393

Testing loss: 2.247842962268186
