Epoch: 1| Step: 0
Training loss: 6.600347518920898
Validation loss: 5.31768258412679

Epoch: 6| Step: 1
Training loss: 5.6665730476379395
Validation loss: 5.3156882127126055

Epoch: 6| Step: 2
Training loss: 4.646172523498535
Validation loss: 5.313898324966431

Epoch: 6| Step: 3
Training loss: 4.507129192352295
Validation loss: 5.31212854385376

Epoch: 6| Step: 4
Training loss: 4.961859703063965
Validation loss: 5.310710430145264

Epoch: 6| Step: 5
Training loss: 5.62862491607666
Validation loss: 5.309253374735515

Epoch: 6| Step: 6
Training loss: 5.478131294250488
Validation loss: 5.307812770207723

Epoch: 6| Step: 7
Training loss: 4.988535404205322
Validation loss: 5.306437730789185

Epoch: 6| Step: 8
Training loss: 4.162035942077637
Validation loss: 5.304940700531006

Epoch: 6| Step: 9
Training loss: 5.7177414894104
Validation loss: 5.303459088007609

Epoch: 6| Step: 10
Training loss: 5.489863395690918
Validation loss: 5.301962931950887

Epoch: 6| Step: 11
Training loss: 5.977640151977539
Validation loss: 5.300381739934285

Epoch: 6| Step: 12
Training loss: 6.16185188293457
Validation loss: 5.29874316851298

Epoch: 6| Step: 13
Training loss: 5.279254913330078
Validation loss: 5.2970733642578125

Epoch: 2| Step: 0
Training loss: 5.976927757263184
Validation loss: 5.295252641042073

Epoch: 6| Step: 1
Training loss: 6.206935405731201
Validation loss: 5.293382485707601

Epoch: 6| Step: 2
Training loss: 5.580751419067383
Validation loss: 5.291392087936401

Epoch: 6| Step: 3
Training loss: 5.750494956970215
Validation loss: 5.2892835934956866

Epoch: 6| Step: 4
Training loss: 5.389915466308594
Validation loss: 5.287182569503784

Epoch: 6| Step: 5
Training loss: 4.673444747924805
Validation loss: 5.284840742746989

Epoch: 6| Step: 6
Training loss: 4.327437400817871
Validation loss: 5.2825086911519366

Epoch: 6| Step: 7
Training loss: 5.750606060028076
Validation loss: 5.280052900314331

Epoch: 6| Step: 8
Training loss: 4.472819805145264
Validation loss: 5.277332901954651

Epoch: 6| Step: 9
Training loss: 5.4600830078125
Validation loss: 5.274552663167317

Epoch: 6| Step: 10
Training loss: 5.748408317565918
Validation loss: 5.2715688943862915

Epoch: 6| Step: 11
Training loss: 5.504820823669434
Validation loss: 5.268580277760823

Epoch: 6| Step: 12
Training loss: 4.159905433654785
Validation loss: 5.26528533299764

Epoch: 6| Step: 13
Training loss: 5.892685890197754
Validation loss: 5.261796792348226

Epoch: 3| Step: 0
Training loss: 5.479219436645508
Validation loss: 5.258197704950969

Epoch: 6| Step: 1
Training loss: 6.411456108093262
Validation loss: 5.254175782203674

Epoch: 6| Step: 2
Training loss: 3.6900815963745117
Validation loss: 5.250070174535115

Epoch: 6| Step: 3
Training loss: 5.3302507400512695
Validation loss: 5.245723883310954

Epoch: 6| Step: 4
Training loss: 6.4718217849731445
Validation loss: 5.240903774897258

Epoch: 6| Step: 5
Training loss: 4.282168388366699
Validation loss: 5.235929489135742

Epoch: 6| Step: 6
Training loss: 4.602903366088867
Validation loss: 5.230852127075195

Epoch: 6| Step: 7
Training loss: 4.942642688751221
Validation loss: 5.225418329238892

Epoch: 6| Step: 8
Training loss: 6.393792152404785
Validation loss: 5.219573179880778

Epoch: 6| Step: 9
Training loss: 5.740507125854492
Validation loss: 5.21345051129659

Epoch: 6| Step: 10
Training loss: 4.899667263031006
Validation loss: 5.207260608673096

Epoch: 6| Step: 11
Training loss: 5.475975036621094
Validation loss: 5.200610637664795

Epoch: 6| Step: 12
Training loss: 5.248138904571533
Validation loss: 5.193913221359253

Epoch: 6| Step: 13
Training loss: 5.178201198577881
Validation loss: 5.186376889546712

Epoch: 4| Step: 0
Training loss: 4.841901779174805
Validation loss: 5.178664366404216

Epoch: 6| Step: 1
Training loss: 5.675790786743164
Validation loss: 5.170653661092122

Epoch: 6| Step: 2
Training loss: 5.443500518798828
Validation loss: 5.162328322728475

Epoch: 6| Step: 3
Training loss: 4.7460503578186035
Validation loss: 5.153680721918742

Epoch: 6| Step: 4
Training loss: 5.611421585083008
Validation loss: 5.14475146929423

Epoch: 6| Step: 5
Training loss: 4.03834342956543
Validation loss: 5.135896682739258

Epoch: 6| Step: 6
Training loss: 5.2660369873046875
Validation loss: 5.1258753935496015

Epoch: 6| Step: 7
Training loss: 5.638238430023193
Validation loss: 5.115920464197795

Epoch: 6| Step: 8
Training loss: 4.489757061004639
Validation loss: 5.105671644210815

Epoch: 6| Step: 9
Training loss: 3.844662666320801
Validation loss: 5.095130840937297

Epoch: 6| Step: 10
Training loss: 5.385397911071777
Validation loss: 5.08441964785258

Epoch: 6| Step: 11
Training loss: 6.571352958679199
Validation loss: 5.0735838413238525

Epoch: 6| Step: 12
Training loss: 5.787178039550781
Validation loss: 5.06253703435262

Epoch: 6| Step: 13
Training loss: 5.361621856689453
Validation loss: 5.051187197367351

Epoch: 5| Step: 0
Training loss: 4.697004795074463
Validation loss: 5.039908806482951

Epoch: 6| Step: 1
Training loss: 5.142132759094238
Validation loss: 5.028442462285359

Epoch: 6| Step: 2
Training loss: 4.071771621704102
Validation loss: 5.017043352127075

Epoch: 6| Step: 3
Training loss: 4.695590496063232
Validation loss: 5.0053125222524

Epoch: 6| Step: 4
Training loss: 6.059628486633301
Validation loss: 4.993586778640747

Epoch: 6| Step: 5
Training loss: 5.082991123199463
Validation loss: 4.98201338450114

Epoch: 6| Step: 6
Training loss: 5.635458946228027
Validation loss: 4.970842520395915

Epoch: 6| Step: 7
Training loss: 5.8105878829956055
Validation loss: 4.9592336018880205

Epoch: 6| Step: 8
Training loss: 5.665585517883301
Validation loss: 4.94774317741394

Epoch: 6| Step: 9
Training loss: 5.678342819213867
Validation loss: 4.936148722966512

Epoch: 6| Step: 10
Training loss: 4.102265357971191
Validation loss: 4.924419800440471

Epoch: 6| Step: 11
Training loss: 4.671422004699707
Validation loss: 4.912908871968587

Epoch: 6| Step: 12
Training loss: 5.005149841308594
Validation loss: 4.901056369145711

Epoch: 6| Step: 13
Training loss: 4.329631805419922
Validation loss: 4.889714241027832

Epoch: 6| Step: 0
Training loss: 5.476110458374023
Validation loss: 4.878463347752889

Epoch: 6| Step: 1
Training loss: 4.507852077484131
Validation loss: 4.867056608200073

Epoch: 6| Step: 2
Training loss: 6.074979782104492
Validation loss: 4.8555366198221845

Epoch: 6| Step: 3
Training loss: 4.4424357414245605
Validation loss: 4.844013134638469

Epoch: 6| Step: 4
Training loss: 5.844285488128662
Validation loss: 4.832865397135417

Epoch: 6| Step: 5
Training loss: 5.058547496795654
Validation loss: 4.821815729141235

Epoch: 6| Step: 6
Training loss: 4.283005714416504
Validation loss: 4.810793558756511

Epoch: 6| Step: 7
Training loss: 4.991636276245117
Validation loss: 4.80031172434489

Epoch: 6| Step: 8
Training loss: 5.329831123352051
Validation loss: 4.789737900098165

Epoch: 6| Step: 9
Training loss: 2.8214728832244873
Validation loss: 4.77950390179952

Epoch: 6| Step: 10
Training loss: 5.483301162719727
Validation loss: 4.769294500350952

Epoch: 6| Step: 11
Training loss: 5.210926055908203
Validation loss: 4.760163942972819

Epoch: 6| Step: 12
Training loss: 4.225640773773193
Validation loss: 4.7503485679626465

Epoch: 6| Step: 13
Training loss: 4.8109283447265625
Validation loss: 4.741216103235881

Epoch: 7| Step: 0
Training loss: 4.570339202880859
Validation loss: 4.732296307881673

Epoch: 6| Step: 1
Training loss: 4.907745361328125
Validation loss: 4.723328034083049

Epoch: 6| Step: 2
Training loss: 4.607517242431641
Validation loss: 4.7150505383809405

Epoch: 6| Step: 3
Training loss: 3.9325101375579834
Validation loss: 4.706291874249776

Epoch: 6| Step: 4
Training loss: 4.053127765655518
Validation loss: 4.698225021362305

Epoch: 6| Step: 5
Training loss: 5.191856384277344
Validation loss: 4.689455350240071

Epoch: 6| Step: 6
Training loss: 4.778855323791504
Validation loss: 4.681114236513774

Epoch: 6| Step: 7
Training loss: 3.8116159439086914
Validation loss: 4.672450621922811

Epoch: 6| Step: 8
Training loss: 4.818018913269043
Validation loss: 4.663785616556804

Epoch: 6| Step: 9
Training loss: 5.778684139251709
Validation loss: 4.655316670735677

Epoch: 6| Step: 10
Training loss: 4.95720100402832
Validation loss: 4.646237691243489

Epoch: 6| Step: 11
Training loss: 5.0513410568237305
Validation loss: 4.63742200533549

Epoch: 6| Step: 12
Training loss: 5.999574661254883
Validation loss: 4.628406286239624

Epoch: 6| Step: 13
Training loss: 4.310908317565918
Validation loss: 4.619386275609334

Epoch: 8| Step: 0
Training loss: 6.1106414794921875
Validation loss: 4.610858758290608

Epoch: 6| Step: 1
Training loss: 4.977420806884766
Validation loss: 4.60204831759135

Epoch: 6| Step: 2
Training loss: 4.0656561851501465
Validation loss: 4.593043486277263

Epoch: 6| Step: 3
Training loss: 4.406411170959473
Validation loss: 4.584590633710225

Epoch: 6| Step: 4
Training loss: 6.192658424377441
Validation loss: 4.57664676507314

Epoch: 6| Step: 5
Training loss: 3.938112497329712
Validation loss: 4.5689932107925415

Epoch: 6| Step: 6
Training loss: 3.3700361251831055
Validation loss: 4.560645381609599

Epoch: 6| Step: 7
Training loss: 4.647433757781982
Validation loss: 4.552916924158732

Epoch: 6| Step: 8
Training loss: 3.9300708770751953
Validation loss: 4.5460487604141235

Epoch: 6| Step: 9
Training loss: 5.154792785644531
Validation loss: 4.539158463478088

Epoch: 6| Step: 10
Training loss: 4.390722274780273
Validation loss: 4.532139142354329

Epoch: 6| Step: 11
Training loss: 4.869172096252441
Validation loss: 4.525250156720479

Epoch: 6| Step: 12
Training loss: 4.034400463104248
Validation loss: 4.518542369206746

Epoch: 6| Step: 13
Training loss: 5.164278984069824
Validation loss: 4.511909564336141

Epoch: 9| Step: 0
Training loss: 4.921614646911621
Validation loss: 4.505417346954346

Epoch: 6| Step: 1
Training loss: 4.913356781005859
Validation loss: 4.499045054117839

Epoch: 6| Step: 2
Training loss: 4.485394477844238
Validation loss: 4.492709080378215

Epoch: 6| Step: 3
Training loss: 5.5294036865234375
Validation loss: 4.48608644803365

Epoch: 6| Step: 4
Training loss: 3.6693177223205566
Validation loss: 4.480204900105794

Epoch: 6| Step: 5
Training loss: 3.6357014179229736
Validation loss: 4.473954598108928

Epoch: 6| Step: 6
Training loss: 4.690317630767822
Validation loss: 4.468209266662598

Epoch: 6| Step: 7
Training loss: 4.279491424560547
Validation loss: 4.462096929550171

Epoch: 6| Step: 8
Training loss: 4.991765975952148
Validation loss: 4.455429156621297

Epoch: 6| Step: 9
Training loss: 4.806951999664307
Validation loss: 4.4498733679453535

Epoch: 6| Step: 10
Training loss: 5.054369926452637
Validation loss: 4.443121552467346

Epoch: 6| Step: 11
Training loss: 4.206306457519531
Validation loss: 4.435955921808879

Epoch: 6| Step: 12
Training loss: 4.8229475021362305
Validation loss: 4.429530382156372

Epoch: 6| Step: 13
Training loss: 4.041447639465332
Validation loss: 4.422723929087321

Epoch: 10| Step: 0
Training loss: 4.680540084838867
Validation loss: 4.415380398432414

Epoch: 6| Step: 1
Training loss: 5.575999736785889
Validation loss: 4.407612403233846

Epoch: 6| Step: 2
Training loss: 4.372170925140381
Validation loss: 4.400728464126587

Epoch: 6| Step: 3
Training loss: 3.921400547027588
Validation loss: 4.3932093779246015

Epoch: 6| Step: 4
Training loss: 4.865250587463379
Validation loss: 4.385560115178426

Epoch: 6| Step: 5
Training loss: 4.7279815673828125
Validation loss: 4.3784611622492475

Epoch: 6| Step: 6
Training loss: 4.267366886138916
Validation loss: 4.370956500371297

Epoch: 6| Step: 7
Training loss: 4.069072246551514
Validation loss: 4.364716291427612

Epoch: 6| Step: 8
Training loss: 4.640682220458984
Validation loss: 4.358071843783061

Epoch: 6| Step: 9
Training loss: 4.527173042297363
Validation loss: 4.351834932963054

Epoch: 6| Step: 10
Training loss: 4.965005874633789
Validation loss: 4.345938841501872

Epoch: 6| Step: 11
Training loss: 3.6021175384521484
Validation loss: 4.339577833811442

Epoch: 6| Step: 12
Training loss: 3.5335075855255127
Validation loss: 4.334024469057719

Epoch: 6| Step: 13
Training loss: 5.098944664001465
Validation loss: 4.328152537345886

Epoch: 11| Step: 0
Training loss: 5.044327735900879
Validation loss: 4.321683247884114

Epoch: 6| Step: 1
Training loss: 4.279177665710449
Validation loss: 4.31533686319987

Epoch: 6| Step: 2
Training loss: 4.99700927734375
Validation loss: 4.309267282485962

Epoch: 6| Step: 3
Training loss: 5.094943046569824
Validation loss: 4.303564548492432

Epoch: 6| Step: 4
Training loss: 3.6379098892211914
Validation loss: 4.297717730204265

Epoch: 6| Step: 5
Training loss: 4.04527473449707
Validation loss: 4.291634639104207

Epoch: 6| Step: 6
Training loss: 4.066218376159668
Validation loss: 4.285805304845174

Epoch: 6| Step: 7
Training loss: 4.181591033935547
Validation loss: 4.279424667358398

Epoch: 6| Step: 8
Training loss: 4.413070201873779
Validation loss: 4.273072004318237

Epoch: 6| Step: 9
Training loss: 5.439417839050293
Validation loss: 4.2676381667455034

Epoch: 6| Step: 10
Training loss: 3.704672336578369
Validation loss: 4.261814912160237

Epoch: 6| Step: 11
Training loss: 4.319914817810059
Validation loss: 4.257144331932068

Epoch: 6| Step: 12
Training loss: 3.7110469341278076
Validation loss: 4.252731005350749

Epoch: 6| Step: 13
Training loss: 4.821660995483398
Validation loss: 4.24863342444102

Epoch: 12| Step: 0
Training loss: 3.6495800018310547
Validation loss: 4.241716742515564

Epoch: 6| Step: 1
Training loss: 4.446258068084717
Validation loss: 4.236550052960713

Epoch: 6| Step: 2
Training loss: 4.240280628204346
Validation loss: 4.231657822926839

Epoch: 6| Step: 3
Training loss: 4.4308953285217285
Validation loss: 4.226419806480408

Epoch: 6| Step: 4
Training loss: 4.819766521453857
Validation loss: 4.221624970436096

Epoch: 6| Step: 5
Training loss: 4.52861213684082
Validation loss: 4.215929587682088

Epoch: 6| Step: 6
Training loss: 4.489681720733643
Validation loss: 4.210329254468282

Epoch: 6| Step: 7
Training loss: 4.912479400634766
Validation loss: 4.20481018225352

Epoch: 6| Step: 8
Training loss: 3.506439685821533
Validation loss: 4.199716488520305

Epoch: 6| Step: 9
Training loss: 4.023918628692627
Validation loss: 4.195447365442912

Epoch: 6| Step: 10
Training loss: 4.563381671905518
Validation loss: 4.188618779182434

Epoch: 6| Step: 11
Training loss: 4.536502838134766
Validation loss: 4.18353796005249

Epoch: 6| Step: 12
Training loss: 4.397789001464844
Validation loss: 4.178469777107239

Epoch: 6| Step: 13
Training loss: 4.224545001983643
Validation loss: 4.173737684885661

Epoch: 13| Step: 0
Training loss: 4.306534290313721
Validation loss: 4.168358604113261

Epoch: 6| Step: 1
Training loss: 3.9074206352233887
Validation loss: 4.162519733111064

Epoch: 6| Step: 2
Training loss: 4.730447769165039
Validation loss: 4.1577045520146685

Epoch: 6| Step: 3
Training loss: 4.828524589538574
Validation loss: 4.152331233024597

Epoch: 6| Step: 4
Training loss: 4.633942127227783
Validation loss: 4.148107488950093

Epoch: 6| Step: 5
Training loss: 4.036334037780762
Validation loss: 4.142564455668132

Epoch: 6| Step: 6
Training loss: 4.630170822143555
Validation loss: 4.1376045147577925

Epoch: 6| Step: 7
Training loss: 4.169013023376465
Validation loss: 4.132447441418965

Epoch: 6| Step: 8
Training loss: 3.980867385864258
Validation loss: 4.127991755803426

Epoch: 6| Step: 9
Training loss: 3.7570133209228516
Validation loss: 4.12269651889801

Epoch: 6| Step: 10
Training loss: 3.9463419914245605
Validation loss: 4.116817156473796

Epoch: 6| Step: 11
Training loss: 4.284879684448242
Validation loss: 4.112765312194824

Epoch: 6| Step: 12
Training loss: 3.6161131858825684
Validation loss: 4.107422391573588

Epoch: 6| Step: 13
Training loss: 5.010049343109131
Validation loss: 4.10263991355896

Epoch: 14| Step: 0
Training loss: 4.275266647338867
Validation loss: 4.097661813100179

Epoch: 6| Step: 1
Training loss: 3.583587169647217
Validation loss: 4.092236240704854

Epoch: 6| Step: 2
Training loss: 5.139304161071777
Validation loss: 4.087161382039388

Epoch: 6| Step: 3
Training loss: 3.942842721939087
Validation loss: 4.081819732983907

Epoch: 6| Step: 4
Training loss: 4.551455974578857
Validation loss: 4.076192816098531

Epoch: 6| Step: 5
Training loss: 3.4251017570495605
Validation loss: 4.070772131284078

Epoch: 6| Step: 6
Training loss: 4.925360202789307
Validation loss: 4.065320014953613

Epoch: 6| Step: 7
Training loss: 4.497565269470215
Validation loss: 4.060493508974711

Epoch: 6| Step: 8
Training loss: 3.9248759746551514
Validation loss: 4.055994908014934

Epoch: 6| Step: 9
Training loss: 3.976283073425293
Validation loss: 4.0505024989446

Epoch: 6| Step: 10
Training loss: 4.248849391937256
Validation loss: 4.045677105585734

Epoch: 6| Step: 11
Training loss: 3.360914468765259
Validation loss: 4.039976239204407

Epoch: 6| Step: 12
Training loss: 4.905304431915283
Validation loss: 4.034555713335673

Epoch: 6| Step: 13
Training loss: 4.13267183303833
Validation loss: 4.029379049936931

Epoch: 15| Step: 0
Training loss: 4.90455436706543
Validation loss: 4.023894906044006

Epoch: 6| Step: 1
Training loss: 3.5835213661193848
Validation loss: 4.019270420074463

Epoch: 6| Step: 2
Training loss: 3.8899295330047607
Validation loss: 4.014635721842448

Epoch: 6| Step: 3
Training loss: 5.067355632781982
Validation loss: 4.009500185648601

Epoch: 6| Step: 4
Training loss: 2.7898125648498535
Validation loss: 4.004228234291077

Epoch: 6| Step: 5
Training loss: 3.8139092922210693
Validation loss: 3.998586416244507

Epoch: 6| Step: 6
Training loss: 3.6470389366149902
Validation loss: 3.992867906888326

Epoch: 6| Step: 7
Training loss: 4.536274433135986
Validation loss: 3.9887882073720298

Epoch: 6| Step: 8
Training loss: 4.040358543395996
Validation loss: 3.9834863742192588

Epoch: 6| Step: 9
Training loss: 5.011563301086426
Validation loss: 3.9784231583277383

Epoch: 6| Step: 10
Training loss: 3.485564947128296
Validation loss: 3.9730610052744546

Epoch: 6| Step: 11
Training loss: 4.839216709136963
Validation loss: 3.968754251797994

Epoch: 6| Step: 12
Training loss: 3.7760307788848877
Validation loss: 3.9644153118133545

Epoch: 6| Step: 13
Training loss: 4.527451515197754
Validation loss: 3.958329121271769

Epoch: 16| Step: 0
Training loss: 3.3588719367980957
Validation loss: 3.952902396519979

Epoch: 6| Step: 1
Training loss: 3.728496789932251
Validation loss: 3.947862903277079

Epoch: 6| Step: 2
Training loss: 4.273366928100586
Validation loss: 3.942508260409037

Epoch: 6| Step: 3
Training loss: 4.832714080810547
Validation loss: 3.9364296197891235

Epoch: 6| Step: 4
Training loss: 5.465619087219238
Validation loss: 3.9305419524510703

Epoch: 6| Step: 5
Training loss: 3.9871339797973633
Validation loss: 3.926647106806437

Epoch: 6| Step: 6
Training loss: 4.506222724914551
Validation loss: 3.920989990234375

Epoch: 6| Step: 7
Training loss: 4.115220069885254
Validation loss: 3.9142272075017295

Epoch: 6| Step: 8
Training loss: 3.6455726623535156
Validation loss: 3.9098833004633584

Epoch: 6| Step: 9
Training loss: 3.2350687980651855
Validation loss: 3.9045486052831015

Epoch: 6| Step: 10
Training loss: 4.761385440826416
Validation loss: 3.8997515439987183

Epoch: 6| Step: 11
Training loss: 3.8841967582702637
Validation loss: 3.892647624015808

Epoch: 6| Step: 12
Training loss: 3.314126491546631
Validation loss: 3.888027628262838

Epoch: 6| Step: 13
Training loss: 3.8396217823028564
Validation loss: 3.882950703303019

Epoch: 17| Step: 0
Training loss: 4.944225311279297
Validation loss: 3.876582304636637

Epoch: 6| Step: 1
Training loss: 3.4325242042541504
Validation loss: 3.8709988594055176

Epoch: 6| Step: 2
Training loss: 3.6818575859069824
Validation loss: 3.865777929623922

Epoch: 6| Step: 3
Training loss: 3.0325870513916016
Validation loss: 3.861302653948466

Epoch: 6| Step: 4
Training loss: 4.185297966003418
Validation loss: 3.855558395385742

Epoch: 6| Step: 5
Training loss: 4.067043304443359
Validation loss: 3.8493510484695435

Epoch: 6| Step: 6
Training loss: 3.578507900238037
Validation loss: 3.844040632247925

Epoch: 6| Step: 7
Training loss: 4.535296440124512
Validation loss: 3.839004397392273

Epoch: 6| Step: 8
Training loss: 4.198249816894531
Validation loss: 3.8341906468073526

Epoch: 6| Step: 9
Training loss: 3.746180534362793
Validation loss: 3.8286144733428955

Epoch: 6| Step: 10
Training loss: 3.7673847675323486
Validation loss: 3.822757045427958

Epoch: 6| Step: 11
Training loss: 3.9146833419799805
Validation loss: 3.8176373640696206

Epoch: 6| Step: 12
Training loss: 4.10811710357666
Validation loss: 3.813718875249227

Epoch: 6| Step: 13
Training loss: 4.740364074707031
Validation loss: 3.8079883654912314

Epoch: 18| Step: 0
Training loss: 3.1148388385772705
Validation loss: 3.8035844961802163

Epoch: 6| Step: 1
Training loss: 4.281193733215332
Validation loss: 3.7973170280456543

Epoch: 6| Step: 2
Training loss: 4.044407367706299
Validation loss: 3.793173591295878

Epoch: 6| Step: 3
Training loss: 4.349827766418457
Validation loss: 3.7886577447255454

Epoch: 6| Step: 4
Training loss: 2.939060688018799
Validation loss: 3.7836814721425376

Epoch: 6| Step: 5
Training loss: 3.7095718383789062
Validation loss: 3.7778462966283164

Epoch: 6| Step: 6
Training loss: 4.322000980377197
Validation loss: 3.774778405825297

Epoch: 6| Step: 7
Training loss: 3.3072566986083984
Validation loss: 3.77315346399943

Epoch: 6| Step: 8
Training loss: 4.1230788230896
Validation loss: 3.7682588497797647

Epoch: 6| Step: 9
Training loss: 4.015632629394531
Validation loss: 3.7594945430755615

Epoch: 6| Step: 10
Training loss: 4.374133110046387
Validation loss: 3.754703720410665

Epoch: 6| Step: 11
Training loss: 4.652566432952881
Validation loss: 3.7532836198806763

Epoch: 6| Step: 12
Training loss: 3.653937339782715
Validation loss: 3.745438734690348

Epoch: 6| Step: 13
Training loss: 4.108070373535156
Validation loss: 3.7405478954315186

Epoch: 19| Step: 0
Training loss: 4.646361351013184
Validation loss: 3.7357294956843057

Epoch: 6| Step: 1
Training loss: 3.5296709537506104
Validation loss: 3.73017680644989

Epoch: 6| Step: 2
Training loss: 3.3567605018615723
Validation loss: 3.725055456161499

Epoch: 6| Step: 3
Training loss: 4.639230728149414
Validation loss: 3.720861633618673

Epoch: 6| Step: 4
Training loss: 4.188371658325195
Validation loss: 3.7164167563120523

Epoch: 6| Step: 5
Training loss: 2.8167052268981934
Validation loss: 3.7117939790089927

Epoch: 6| Step: 6
Training loss: 4.328316688537598
Validation loss: 3.7074689865112305

Epoch: 6| Step: 7
Training loss: 3.1773808002471924
Validation loss: 3.704054037729899

Epoch: 6| Step: 8
Training loss: 3.3805625438690186
Validation loss: 3.699040492375692

Epoch: 6| Step: 9
Training loss: 4.029392242431641
Validation loss: 3.6933927138646445

Epoch: 6| Step: 10
Training loss: 4.879230499267578
Validation loss: 3.687806169191996

Epoch: 6| Step: 11
Training loss: 3.8554940223693848
Validation loss: 3.682995835940043

Epoch: 6| Step: 12
Training loss: 3.799286365509033
Validation loss: 3.6788916190465293

Epoch: 6| Step: 13
Training loss: 3.5005195140838623
Validation loss: 3.6737436056137085

Epoch: 20| Step: 0
Training loss: 2.927377700805664
Validation loss: 3.668730894724528

Epoch: 6| Step: 1
Training loss: 4.8661909103393555
Validation loss: 3.6657036542892456

Epoch: 6| Step: 2
Training loss: 3.212477684020996
Validation loss: 3.6611992915471396

Epoch: 6| Step: 3
Training loss: 3.3280715942382812
Validation loss: 3.6561272939046225

Epoch: 6| Step: 4
Training loss: 4.53040885925293
Validation loss: 3.6518510977427163

Epoch: 6| Step: 5
Training loss: 2.554244041442871
Validation loss: 3.648053248723348

Epoch: 6| Step: 6
Training loss: 4.443437576293945
Validation loss: 3.643855611483256

Epoch: 6| Step: 7
Training loss: 3.9542746543884277
Validation loss: 3.638483723004659

Epoch: 6| Step: 8
Training loss: 4.273653507232666
Validation loss: 3.633856018384298

Epoch: 6| Step: 9
Training loss: 4.094076156616211
Validation loss: 3.6289520263671875

Epoch: 6| Step: 10
Training loss: 4.262643337249756
Validation loss: 3.624543031056722

Epoch: 6| Step: 11
Training loss: 3.726698875427246
Validation loss: 3.620659907658895

Epoch: 6| Step: 12
Training loss: 3.219353437423706
Validation loss: 3.615946809450785

Epoch: 6| Step: 13
Training loss: 3.8107614517211914
Validation loss: 3.6113099257151284

Epoch: 21| Step: 0
Training loss: 3.3497517108917236
Validation loss: 3.6070824464162192

Epoch: 6| Step: 1
Training loss: 3.958594799041748
Validation loss: 3.6016767819722495

Epoch: 6| Step: 2
Training loss: 3.423839807510376
Validation loss: 3.5968518257141113

Epoch: 6| Step: 3
Training loss: 4.468199729919434
Validation loss: 3.590881625811259

Epoch: 6| Step: 4
Training loss: 3.684752941131592
Validation loss: 3.586962580680847

Epoch: 6| Step: 5
Training loss: 4.016813278198242
Validation loss: 3.5811604658762612

Epoch: 6| Step: 6
Training loss: 2.8462464809417725
Validation loss: 3.576447010040283

Epoch: 6| Step: 7
Training loss: 3.7444908618927
Validation loss: 3.570763905843099

Epoch: 6| Step: 8
Training loss: 3.487532138824463
Validation loss: 3.5666170914967856

Epoch: 6| Step: 9
Training loss: 3.440371036529541
Validation loss: 3.56169327100118

Epoch: 6| Step: 10
Training loss: 3.761688232421875
Validation loss: 3.5564792156219482

Epoch: 6| Step: 11
Training loss: 4.013647079467773
Validation loss: 3.551345785458883

Epoch: 6| Step: 12
Training loss: 4.143759250640869
Validation loss: 3.546673536300659

Epoch: 6| Step: 13
Training loss: 3.992941379547119
Validation loss: 3.543553034464518

Epoch: 22| Step: 0
Training loss: 3.927846670150757
Validation loss: 3.5394135316212973

Epoch: 6| Step: 1
Training loss: 3.770071506500244
Validation loss: 3.532747467358907

Epoch: 6| Step: 2
Training loss: 3.053724765777588
Validation loss: 3.5282914638519287

Epoch: 6| Step: 3
Training loss: 4.034193515777588
Validation loss: 3.523111899693807

Epoch: 6| Step: 4
Training loss: 3.058642864227295
Validation loss: 3.5180238087972007

Epoch: 6| Step: 5
Training loss: 3.143357276916504
Validation loss: 3.512648264567057

Epoch: 6| Step: 6
Training loss: 4.597452163696289
Validation loss: 3.507797280947367

Epoch: 6| Step: 7
Training loss: 2.570720672607422
Validation loss: 3.5039539337158203

Epoch: 6| Step: 8
Training loss: 4.083588123321533
Validation loss: 3.499558766682943

Epoch: 6| Step: 9
Training loss: 3.315195083618164
Validation loss: 3.4948784907658896

Epoch: 6| Step: 10
Training loss: 4.907837867736816
Validation loss: 3.490750710169474

Epoch: 6| Step: 11
Training loss: 4.285987854003906
Validation loss: 3.4867637157440186

Epoch: 6| Step: 12
Training loss: 2.7906854152679443
Validation loss: 3.482731262842814

Epoch: 6| Step: 13
Training loss: 3.8922600746154785
Validation loss: 3.4778149922688804

Epoch: 23| Step: 0
Training loss: 4.688736915588379
Validation loss: 3.471674124399821

Epoch: 6| Step: 1
Training loss: 3.40380859375
Validation loss: 3.4660889307657876

Epoch: 6| Step: 2
Training loss: 3.6588571071624756
Validation loss: 3.461698293685913

Epoch: 6| Step: 3
Training loss: 3.8116626739501953
Validation loss: 3.458001216252645

Epoch: 6| Step: 4
Training loss: 4.320242404937744
Validation loss: 3.4544734954833984

Epoch: 6| Step: 5
Training loss: 3.9288687705993652
Validation loss: 3.44875701268514

Epoch: 6| Step: 6
Training loss: 3.277524948120117
Validation loss: 3.4466100136439004

Epoch: 6| Step: 7
Training loss: 2.2522952556610107
Validation loss: 3.4420337677001953

Epoch: 6| Step: 8
Training loss: 3.5120034217834473
Validation loss: 3.440095822016398

Epoch: 6| Step: 9
Training loss: 3.1785786151885986
Validation loss: 3.434589425722758

Epoch: 6| Step: 10
Training loss: 3.0129566192626953
Validation loss: 3.429415464401245

Epoch: 6| Step: 11
Training loss: 4.096188545227051
Validation loss: 3.4257147709528604

Epoch: 6| Step: 12
Training loss: 3.0409483909606934
Validation loss: 3.4210756619771323

Epoch: 6| Step: 13
Training loss: 4.369573593139648
Validation loss: 3.420154412587484

Epoch: 24| Step: 0
Training loss: 3.462006092071533
Validation loss: 3.4110987981160483

Epoch: 6| Step: 1
Training loss: 3.965907096862793
Validation loss: 3.4082479079564414

Epoch: 6| Step: 2
Training loss: 3.893404960632324
Validation loss: 3.4054512977600098

Epoch: 6| Step: 3
Training loss: 4.625186920166016
Validation loss: 3.4007766246795654

Epoch: 6| Step: 4
Training loss: 2.376673460006714
Validation loss: 3.3971850872039795

Epoch: 6| Step: 5
Training loss: 4.345880031585693
Validation loss: 3.392457644144694

Epoch: 6| Step: 6
Training loss: 4.009450435638428
Validation loss: 3.3881696462631226

Epoch: 6| Step: 7
Training loss: 2.574971914291382
Validation loss: 3.3832793633143106

Epoch: 6| Step: 8
Training loss: 3.8624167442321777
Validation loss: 3.3784322341283164

Epoch: 6| Step: 9
Training loss: 3.624690055847168
Validation loss: 3.374340375264486

Epoch: 6| Step: 10
Training loss: 4.1228179931640625
Validation loss: 3.369936545689901

Epoch: 6| Step: 11
Training loss: 3.025562286376953
Validation loss: 3.3655109802881875

Epoch: 6| Step: 12
Training loss: 3.008657932281494
Validation loss: 3.3636771043141684

Epoch: 6| Step: 13
Training loss: 2.853670597076416
Validation loss: 3.355838139851888

Epoch: 25| Step: 0
Training loss: 3.732801675796509
Validation loss: 3.351443350315094

Epoch: 6| Step: 1
Training loss: 3.4461874961853027
Validation loss: 3.348182757695516

Epoch: 6| Step: 2
Training loss: 3.6111369132995605
Validation loss: 3.3449302911758423

Epoch: 6| Step: 3
Training loss: 2.569532871246338
Validation loss: 3.3409098386764526

Epoch: 6| Step: 4
Training loss: 3.265460968017578
Validation loss: 3.334716041882833

Epoch: 6| Step: 5
Training loss: 3.353236198425293
Validation loss: 3.33165709177653

Epoch: 6| Step: 6
Training loss: 2.874512195587158
Validation loss: 3.326308488845825

Epoch: 6| Step: 7
Training loss: 3.148118019104004
Validation loss: 3.322842518488566

Epoch: 6| Step: 8
Training loss: 3.6133298873901367
Validation loss: 3.3172646363576255

Epoch: 6| Step: 9
Training loss: 4.343435287475586
Validation loss: 3.3130073149998984

Epoch: 6| Step: 10
Training loss: 4.165201187133789
Validation loss: 3.308990399042765

Epoch: 6| Step: 11
Training loss: 3.4738330841064453
Validation loss: 3.3050827185312905

Epoch: 6| Step: 12
Training loss: 2.7809906005859375
Validation loss: 3.299833099047343

Epoch: 6| Step: 13
Training loss: 4.586098670959473
Validation loss: 3.296804189682007

Epoch: 26| Step: 0
Training loss: 3.1078402996063232
Validation loss: 3.292807141939799

Epoch: 6| Step: 1
Training loss: 3.1857526302337646
Validation loss: 3.2877357403437295

Epoch: 6| Step: 2
Training loss: 3.7598633766174316
Validation loss: 3.2837425072987876

Epoch: 6| Step: 3
Training loss: 3.1796278953552246
Validation loss: 3.2797508239746094

Epoch: 6| Step: 4
Training loss: 3.76336669921875
Validation loss: 3.2758362690607705

Epoch: 6| Step: 5
Training loss: 3.376922130584717
Validation loss: 3.2721768617630005

Epoch: 6| Step: 6
Training loss: 4.227466583251953
Validation loss: 3.268324096997579

Epoch: 6| Step: 7
Training loss: 3.8858513832092285
Validation loss: 3.2640404303868613

Epoch: 6| Step: 8
Training loss: 3.5242786407470703
Validation loss: 3.2599777380625405

Epoch: 6| Step: 9
Training loss: 3.3403546810150146
Validation loss: 3.2566707531611123

Epoch: 6| Step: 10
Training loss: 3.873231887817383
Validation loss: 3.2525803248087564

Epoch: 6| Step: 11
Training loss: 2.522552967071533
Validation loss: 3.2485541899998984

Epoch: 6| Step: 12
Training loss: 3.3579344749450684
Validation loss: 3.245242476463318

Epoch: 6| Step: 13
Training loss: 3.071033239364624
Validation loss: 3.2417972882588706

Epoch: 27| Step: 0
Training loss: 3.631162643432617
Validation loss: 3.2383849223454795

Epoch: 6| Step: 1
Training loss: 3.4932353496551514
Validation loss: 3.233132799466451

Epoch: 6| Step: 2
Training loss: 4.175543785095215
Validation loss: 3.229270577430725

Epoch: 6| Step: 3
Training loss: 3.1641318798065186
Validation loss: 3.2256484826405845

Epoch: 6| Step: 4
Training loss: 3.107907772064209
Validation loss: 3.22096319993337

Epoch: 6| Step: 5
Training loss: 4.181207656860352
Validation loss: 3.2171765168507895

Epoch: 6| Step: 6
Training loss: 3.3670859336853027
Validation loss: 3.212769945462545

Epoch: 6| Step: 7
Training loss: 3.6316304206848145
Validation loss: 3.208745320638021

Epoch: 6| Step: 8
Training loss: 2.9272305965423584
Validation loss: 3.205348332722982

Epoch: 6| Step: 9
Training loss: 3.854518413543701
Validation loss: 3.201147119204203

Epoch: 6| Step: 10
Training loss: 3.3193132877349854
Validation loss: 3.1981276273727417

Epoch: 6| Step: 11
Training loss: 3.739569902420044
Validation loss: 3.193651556968689

Epoch: 6| Step: 12
Training loss: 2.8356847763061523
Validation loss: 3.1897323528925576

Epoch: 6| Step: 13
Training loss: 2.0501513481140137
Validation loss: 3.185917059580485

Epoch: 28| Step: 0
Training loss: 3.1567602157592773
Validation loss: 3.1818280617396035

Epoch: 6| Step: 1
Training loss: 3.408369541168213
Validation loss: 3.178724010785421

Epoch: 6| Step: 2
Training loss: 3.4847307205200195
Validation loss: 3.174102266629537

Epoch: 6| Step: 3
Training loss: 2.9672293663024902
Validation loss: 3.170286933581034

Epoch: 6| Step: 4
Training loss: 3.7521708011627197
Validation loss: 3.1663242181142173

Epoch: 6| Step: 5
Training loss: 3.7194676399230957
Validation loss: 3.162755846977234

Epoch: 6| Step: 6
Training loss: 4.1847004890441895
Validation loss: 3.1583162546157837

Epoch: 6| Step: 7
Training loss: 4.421100616455078
Validation loss: 3.1534142891565957

Epoch: 6| Step: 8
Training loss: 2.6793718338012695
Validation loss: 3.1508466800053916

Epoch: 6| Step: 9
Training loss: 2.462930202484131
Validation loss: 3.1461902459462485

Epoch: 6| Step: 10
Training loss: 3.1849215030670166
Validation loss: 3.1429200967152915

Epoch: 6| Step: 11
Training loss: 2.522951126098633
Validation loss: 3.13907798131307

Epoch: 6| Step: 12
Training loss: 3.1694605350494385
Validation loss: 3.135119875272115

Epoch: 6| Step: 13
Training loss: 3.6681604385375977
Validation loss: 3.1312087376912436

Epoch: 29| Step: 0
Training loss: 3.4677834510803223
Validation loss: 3.1286776065826416

Epoch: 6| Step: 1
Training loss: 2.8339099884033203
Validation loss: 3.1243885358174643

Epoch: 6| Step: 2
Training loss: 3.303929090499878
Validation loss: 3.1210010051727295

Epoch: 6| Step: 3
Training loss: 3.6354875564575195
Validation loss: 3.1175026496251426

Epoch: 6| Step: 4
Training loss: 2.457618236541748
Validation loss: 3.114588141441345

Epoch: 6| Step: 5
Training loss: 3.277538299560547
Validation loss: 3.1095192432403564

Epoch: 6| Step: 6
Training loss: 3.3536839485168457
Validation loss: 3.106192191441854

Epoch: 6| Step: 7
Training loss: 3.543304443359375
Validation loss: 3.1027937730153403

Epoch: 6| Step: 8
Training loss: 3.6123340129852295
Validation loss: 3.0987558364868164

Epoch: 6| Step: 9
Training loss: 3.5186705589294434
Validation loss: 3.0956634283065796

Epoch: 6| Step: 10
Training loss: 3.5199241638183594
Validation loss: 3.0930200020472207

Epoch: 6| Step: 11
Training loss: 3.260134220123291
Validation loss: 3.0892459551493325

Epoch: 6| Step: 12
Training loss: 3.2193665504455566
Validation loss: 3.0857545534769693

Epoch: 6| Step: 13
Training loss: 3.0888137817382812
Validation loss: 3.0822157859802246

Epoch: 30| Step: 0
Training loss: 3.670663595199585
Validation loss: 3.0781649947166443

Epoch: 6| Step: 1
Training loss: 3.0085389614105225
Validation loss: 3.0754273732503257

Epoch: 6| Step: 2
Training loss: 3.925210952758789
Validation loss: 3.0715585947036743

Epoch: 6| Step: 3
Training loss: 3.5556468963623047
Validation loss: 3.068657120068868

Epoch: 6| Step: 4
Training loss: 3.220569372177124
Validation loss: 3.064685304959615

Epoch: 6| Step: 5
Training loss: 2.9284491539001465
Validation loss: 3.0632129510243735

Epoch: 6| Step: 6
Training loss: 2.9525070190429688
Validation loss: 3.0597645044326782

Epoch: 6| Step: 7
Training loss: 3.2102651596069336
Validation loss: 3.0570805072784424

Epoch: 6| Step: 8
Training loss: 3.3612241744995117
Validation loss: 3.0544496377309165

Epoch: 6| Step: 9
Training loss: 3.1327927112579346
Validation loss: 3.050613005956014

Epoch: 6| Step: 10
Training loss: 2.920734405517578
Validation loss: 3.0479679107666016

Epoch: 6| Step: 11
Training loss: 2.7571353912353516
Validation loss: 3.0426833629608154

Epoch: 6| Step: 12
Training loss: 3.413071393966675
Validation loss: 3.041179895401001

Epoch: 6| Step: 13
Training loss: 3.395575761795044
Validation loss: 3.038643479347229

Epoch: 31| Step: 0
Training loss: 3.6614575386047363
Validation loss: 3.0355782906214395

Epoch: 6| Step: 1
Training loss: 3.2082881927490234
Validation loss: 3.032148520151774

Epoch: 6| Step: 2
Training loss: 3.9033753871917725
Validation loss: 3.0278786023457847

Epoch: 6| Step: 3
Training loss: 3.13664174079895
Validation loss: 3.0251030921936035

Epoch: 6| Step: 4
Training loss: 2.899108409881592
Validation loss: 3.022148291269938

Epoch: 6| Step: 5
Training loss: 2.805265426635742
Validation loss: 3.0175392627716064

Epoch: 6| Step: 6
Training loss: 3.315717935562134
Validation loss: 3.0148940086364746

Epoch: 6| Step: 7
Training loss: 3.127495527267456
Validation loss: 3.0121285120646157

Epoch: 6| Step: 8
Training loss: 2.9014687538146973
Validation loss: 3.0079335371653237

Epoch: 6| Step: 9
Training loss: 3.6634654998779297
Validation loss: 3.0055041710535684

Epoch: 6| Step: 10
Training loss: 3.2868738174438477
Validation loss: 3.0017385482788086

Epoch: 6| Step: 11
Training loss: 2.172361373901367
Validation loss: 2.9976433515548706

Epoch: 6| Step: 12
Training loss: 3.025606632232666
Validation loss: 2.9955689112345376

Epoch: 6| Step: 13
Training loss: 3.764878273010254
Validation loss: 2.9918490250905356

Epoch: 32| Step: 0
Training loss: 3.8474249839782715
Validation loss: 2.988828500111898

Epoch: 6| Step: 1
Training loss: 3.1470389366149902
Validation loss: 2.9856280088424683

Epoch: 6| Step: 2
Training loss: 2.554076671600342
Validation loss: 2.982751250267029

Epoch: 6| Step: 3
Training loss: 3.6537632942199707
Validation loss: 2.9796470403671265

Epoch: 6| Step: 4
Training loss: 2.5579628944396973
Validation loss: 2.9767099618911743

Epoch: 6| Step: 5
Training loss: 3.396023988723755
Validation loss: 2.9730335474014282

Epoch: 6| Step: 6
Training loss: 3.0371360778808594
Validation loss: 2.971044341723124

Epoch: 6| Step: 7
Training loss: 2.476714611053467
Validation loss: 2.9683172702789307

Epoch: 6| Step: 8
Training loss: 3.6959919929504395
Validation loss: 2.9654961427052817

Epoch: 6| Step: 9
Training loss: 3.069390296936035
Validation loss: 2.9611608187357583

Epoch: 6| Step: 10
Training loss: 2.3765876293182373
Validation loss: 2.957087437311808

Epoch: 6| Step: 11
Training loss: 3.759319543838501
Validation loss: 2.9545520146687827

Epoch: 6| Step: 12
Training loss: 3.3725008964538574
Validation loss: 2.952220320701599

Epoch: 6| Step: 13
Training loss: 3.3607711791992188
Validation loss: 2.9487990736961365

Epoch: 33| Step: 0
Training loss: 2.6391868591308594
Validation loss: 2.9470649560292563

Epoch: 6| Step: 1
Training loss: 3.5282182693481445
Validation loss: 2.946294983228048

Epoch: 6| Step: 2
Training loss: 3.2623329162597656
Validation loss: 2.9424993991851807

Epoch: 6| Step: 3
Training loss: 3.370144844055176
Validation loss: 2.9372278849283853

Epoch: 6| Step: 4
Training loss: 4.749168395996094
Validation loss: 2.9341965119043985

Epoch: 6| Step: 5
Training loss: 3.6301279067993164
Validation loss: 2.9305375019709268

Epoch: 6| Step: 6
Training loss: 3.2266898155212402
Validation loss: 2.9278258879979453

Epoch: 6| Step: 7
Training loss: 2.4632010459899902
Validation loss: 2.924067219098409

Epoch: 6| Step: 8
Training loss: 2.671114444732666
Validation loss: 2.9207880894343057

Epoch: 6| Step: 9
Training loss: 3.007906675338745
Validation loss: 2.918001413345337

Epoch: 6| Step: 10
Training loss: 3.2361278533935547
Validation loss: 2.914551933606466

Epoch: 6| Step: 11
Training loss: 3.283517360687256
Validation loss: 2.91300098101298

Epoch: 6| Step: 12
Training loss: 2.3697969913482666
Validation loss: 2.909506897131602

Epoch: 6| Step: 13
Training loss: 2.371649980545044
Validation loss: 2.905665159225464

Epoch: 34| Step: 0
Training loss: 3.3771650791168213
Validation loss: 2.902958949406942

Epoch: 6| Step: 1
Training loss: 3.2201004028320312
Validation loss: 2.901987632115682

Epoch: 6| Step: 2
Training loss: 3.1163032054901123
Validation loss: 2.8986881176630654

Epoch: 6| Step: 3
Training loss: 3.5668752193450928
Validation loss: 2.893363833427429

Epoch: 6| Step: 4
Training loss: 2.736703872680664
Validation loss: 2.89258865515391

Epoch: 6| Step: 5
Training loss: 2.9275970458984375
Validation loss: 2.8899506330490112

Epoch: 6| Step: 6
Training loss: 3.124098300933838
Validation loss: 2.8868913650512695

Epoch: 6| Step: 7
Training loss: 2.933514356613159
Validation loss: 2.8855851888656616

Epoch: 6| Step: 8
Training loss: 3.0007781982421875
Validation loss: 2.8829553524653115

Epoch: 6| Step: 9
Training loss: 3.2179996967315674
Validation loss: 2.8809740940729776

Epoch: 6| Step: 10
Training loss: 2.8292863368988037
Validation loss: 2.87690261999766

Epoch: 6| Step: 11
Training loss: 3.654736280441284
Validation loss: 2.8735032081604004

Epoch: 6| Step: 12
Training loss: 2.8594722747802734
Validation loss: 2.870112895965576

Epoch: 6| Step: 13
Training loss: 2.692373275756836
Validation loss: 2.867953658103943

Epoch: 35| Step: 0
Training loss: 2.9882068634033203
Validation loss: 2.8651127020517984

Epoch: 6| Step: 1
Training loss: 3.0754177570343018
Validation loss: 2.8625166416168213

Epoch: 6| Step: 2
Training loss: 2.295152187347412
Validation loss: 2.8594412406285605

Epoch: 6| Step: 3
Training loss: 3.1966238021850586
Validation loss: 2.8574581146240234

Epoch: 6| Step: 4
Training loss: 2.4206557273864746
Validation loss: 2.8553656339645386

Epoch: 6| Step: 5
Training loss: 3.3725388050079346
Validation loss: 2.851240118344625

Epoch: 6| Step: 6
Training loss: 3.3420968055725098
Validation loss: 2.8498392502466836

Epoch: 6| Step: 7
Training loss: 2.4995834827423096
Validation loss: 2.847162445386251

Epoch: 6| Step: 8
Training loss: 3.3465089797973633
Validation loss: 2.844476898511251

Epoch: 6| Step: 9
Training loss: 3.1400973796844482
Validation loss: 2.8420518239339194

Epoch: 6| Step: 10
Training loss: 3.7417831420898438
Validation loss: 2.8452539443969727

Epoch: 6| Step: 11
Training loss: 2.4682488441467285
Validation loss: 2.8383286396662393

Epoch: 6| Step: 12
Training loss: 3.184326648712158
Validation loss: 2.8332544565200806

Epoch: 6| Step: 13
Training loss: 3.6972410678863525
Validation loss: 2.8304183085759482

Epoch: 36| Step: 0
Training loss: 3.3135251998901367
Validation loss: 2.82741117477417

Epoch: 6| Step: 1
Training loss: 2.9048495292663574
Validation loss: 2.8245810667673745

Epoch: 6| Step: 2
Training loss: 3.13240909576416
Validation loss: 2.822258710861206

Epoch: 6| Step: 3
Training loss: 2.7730824947357178
Validation loss: 2.819347937901815

Epoch: 6| Step: 4
Training loss: 3.6123008728027344
Validation loss: 2.8164910872777305

Epoch: 6| Step: 5
Training loss: 2.489696502685547
Validation loss: 2.814035097757975

Epoch: 6| Step: 6
Training loss: 2.9763002395629883
Validation loss: 2.8110526402791343

Epoch: 6| Step: 7
Training loss: 3.039396286010742
Validation loss: 2.807925581932068

Epoch: 6| Step: 8
Training loss: 3.042480707168579
Validation loss: 2.805054942766825

Epoch: 6| Step: 9
Training loss: 3.022848129272461
Validation loss: 2.8025478521982827

Epoch: 6| Step: 10
Training loss: 2.8227829933166504
Validation loss: 2.799977501233419

Epoch: 6| Step: 11
Training loss: 2.926738739013672
Validation loss: 2.7999949057896933

Epoch: 6| Step: 12
Training loss: 3.197446346282959
Validation loss: 2.7963693141937256

Epoch: 6| Step: 13
Training loss: 3.021806478500366
Validation loss: 2.7918919722239175

Epoch: 37| Step: 0
Training loss: 3.012824535369873
Validation loss: 2.794280727704366

Epoch: 6| Step: 1
Training loss: 2.7791595458984375
Validation loss: 2.7954147259394326

Epoch: 6| Step: 2
Training loss: 3.576857566833496
Validation loss: 2.7862050930658975

Epoch: 6| Step: 3
Training loss: 2.63554048538208
Validation loss: 2.78359055519104

Epoch: 6| Step: 4
Training loss: 2.6218535900115967
Validation loss: 2.7809728384017944

Epoch: 6| Step: 5
Training loss: 3.620954751968384
Validation loss: 2.7771851619084678

Epoch: 6| Step: 6
Training loss: 3.071755886077881
Validation loss: 2.7755210399627686

Epoch: 6| Step: 7
Training loss: 3.217038154602051
Validation loss: 2.772441824277242

Epoch: 6| Step: 8
Training loss: 2.8608992099761963
Validation loss: 2.772574543952942

Epoch: 6| Step: 9
Training loss: 2.9401919841766357
Validation loss: 2.771230697631836

Epoch: 6| Step: 10
Training loss: 3.1416900157928467
Validation loss: 2.768396337827047

Epoch: 6| Step: 11
Training loss: 2.7049007415771484
Validation loss: 2.7648588021596274

Epoch: 6| Step: 12
Training loss: 2.8218841552734375
Validation loss: 2.7638839284578958

Epoch: 6| Step: 13
Training loss: 2.810671806335449
Validation loss: 2.7580681244532266

Epoch: 38| Step: 0
Training loss: 2.8718950748443604
Validation loss: 2.7539753913879395

Epoch: 6| Step: 1
Training loss: 2.7947793006896973
Validation loss: 2.752520720163981

Epoch: 6| Step: 2
Training loss: 2.736203193664551
Validation loss: 2.74802029132843

Epoch: 6| Step: 3
Training loss: 2.588573932647705
Validation loss: 2.7480870882670083

Epoch: 6| Step: 4
Training loss: 3.537379741668701
Validation loss: 2.7458431720733643

Epoch: 6| Step: 5
Training loss: 2.3905539512634277
Validation loss: 2.740916093190511

Epoch: 6| Step: 6
Training loss: 3.221426248550415
Validation loss: 2.7402999798456826

Epoch: 6| Step: 7
Training loss: 3.506503105163574
Validation loss: 2.736435373624166

Epoch: 6| Step: 8
Training loss: 4.367312431335449
Validation loss: 2.7341977755228677

Epoch: 6| Step: 9
Training loss: 2.7046759128570557
Validation loss: 2.730053424835205

Epoch: 6| Step: 10
Training loss: 3.583347797393799
Validation loss: 2.7266228199005127

Epoch: 6| Step: 11
Training loss: 2.4834189414978027
Validation loss: 2.724736213684082

Epoch: 6| Step: 12
Training loss: 2.079263925552368
Validation loss: 2.7241448958714805

Epoch: 6| Step: 13
Training loss: 2.409942626953125
Validation loss: 2.7220253547032676

Epoch: 39| Step: 0
Training loss: 2.6651062965393066
Validation loss: 2.719134589036306

Epoch: 6| Step: 1
Training loss: 2.6868436336517334
Validation loss: 2.717648148536682

Epoch: 6| Step: 2
Training loss: 2.6768393516540527
Validation loss: 2.713997721672058

Epoch: 6| Step: 3
Training loss: 3.428157329559326
Validation loss: 2.7155770858128867

Epoch: 6| Step: 4
Training loss: 2.7313642501831055
Validation loss: 2.7177428801854453

Epoch: 6| Step: 5
Training loss: 3.0497472286224365
Validation loss: 2.712611436843872

Epoch: 6| Step: 6
Training loss: 3.398077964782715
Validation loss: 2.7129830519358316

Epoch: 6| Step: 7
Training loss: 2.5498571395874023
Validation loss: 2.700664440790812

Epoch: 6| Step: 8
Training loss: 3.0190577507019043
Validation loss: 2.700867454210917

Epoch: 6| Step: 9
Training loss: 3.7970104217529297
Validation loss: 2.7003833055496216

Epoch: 6| Step: 10
Training loss: 2.716820240020752
Validation loss: 2.6993413964907327

Epoch: 6| Step: 11
Training loss: 2.709638833999634
Validation loss: 2.70363978544871

Epoch: 6| Step: 12
Training loss: 3.0074501037597656
Validation loss: 2.7030115127563477

Epoch: 6| Step: 13
Training loss: 2.333052158355713
Validation loss: 2.700398246447245

Epoch: 40| Step: 0
Training loss: 3.022401809692383
Validation loss: 2.6902509927749634

Epoch: 6| Step: 1
Training loss: 2.613616466522217
Validation loss: 2.685108721256256

Epoch: 6| Step: 2
Training loss: 2.8471617698669434
Validation loss: 2.6805028518040976

Epoch: 6| Step: 3
Training loss: 3.0585312843322754
Validation loss: 2.6763347387313843

Epoch: 6| Step: 4
Training loss: 2.792825937271118
Validation loss: 2.6748573581377664

Epoch: 6| Step: 5
Training loss: 3.0573368072509766
Validation loss: 2.6744335095087686

Epoch: 6| Step: 6
Training loss: 2.921452522277832
Validation loss: 2.680062214533488

Epoch: 6| Step: 7
Training loss: 2.5682692527770996
Validation loss: 2.6881302197774253

Epoch: 6| Step: 8
Training loss: 3.4896442890167236
Validation loss: 2.6833693981170654

Epoch: 6| Step: 9
Training loss: 3.2672946453094482
Validation loss: 2.6792649825414023

Epoch: 6| Step: 10
Training loss: 2.5537829399108887
Validation loss: 2.663597504297892

Epoch: 6| Step: 11
Training loss: 3.141191005706787
Validation loss: 2.656674106915792

Epoch: 6| Step: 12
Training loss: 1.9321496486663818
Validation loss: 2.657039920488993

Epoch: 6| Step: 13
Training loss: 3.0409305095672607
Validation loss: 2.66091521581014

Epoch: 41| Step: 0
Training loss: 2.873967170715332
Validation loss: 2.672808845837911

Epoch: 6| Step: 1
Training loss: 3.6581473350524902
Validation loss: 2.670031746228536

Epoch: 6| Step: 2
Training loss: 2.6683664321899414
Validation loss: 2.6648342609405518

Epoch: 6| Step: 3
Training loss: 2.2062788009643555
Validation loss: 2.6587026119232178

Epoch: 6| Step: 4
Training loss: 3.5024924278259277
Validation loss: 2.6513576904932656

Epoch: 6| Step: 5
Training loss: 2.6599433422088623
Validation loss: 2.642955183982849

Epoch: 6| Step: 6
Training loss: 2.3663549423217773
Validation loss: 2.637685219446818

Epoch: 6| Step: 7
Training loss: 2.9435501098632812
Validation loss: 2.6342119773228965

Epoch: 6| Step: 8
Training loss: 2.421515464782715
Validation loss: 2.6310300827026367

Epoch: 6| Step: 9
Training loss: 2.622009038925171
Validation loss: 2.626224915186564

Epoch: 6| Step: 10
Training loss: 3.6921262741088867
Validation loss: 2.625950574874878

Epoch: 6| Step: 11
Training loss: 2.517505645751953
Validation loss: 2.6221439043680825

Epoch: 6| Step: 12
Training loss: 2.7009010314941406
Validation loss: 2.619210163752238

Epoch: 6| Step: 13
Training loss: 3.0098910331726074
Validation loss: 2.6153921683629355

Epoch: 42| Step: 0
Training loss: 2.743035316467285
Validation loss: 2.617572784423828

Epoch: 6| Step: 1
Training loss: 2.7028331756591797
Validation loss: 2.6127767165501914

Epoch: 6| Step: 2
Training loss: 2.68935227394104
Validation loss: 2.6081461906433105

Epoch: 6| Step: 3
Training loss: 2.848339319229126
Validation loss: 2.603533943494161

Epoch: 6| Step: 4
Training loss: 2.947079658508301
Validation loss: 2.6006381511688232

Epoch: 6| Step: 5
Training loss: 3.4974918365478516
Validation loss: 2.598093827565511

Epoch: 6| Step: 6
Training loss: 2.8707242012023926
Validation loss: 2.595828056335449

Epoch: 6| Step: 7
Training loss: 2.649894952774048
Validation loss: 2.593009829521179

Epoch: 6| Step: 8
Training loss: 2.9840426445007324
Validation loss: 2.589621682961782

Epoch: 6| Step: 9
Training loss: 2.727613925933838
Validation loss: 2.5878489017486572

Epoch: 6| Step: 10
Training loss: 2.8016483783721924
Validation loss: 2.5839136441548667

Epoch: 6| Step: 11
Training loss: 2.5635364055633545
Validation loss: 2.5811248222986856

Epoch: 6| Step: 12
Training loss: 2.427828311920166
Validation loss: 2.5805956522623696

Epoch: 6| Step: 13
Training loss: 2.7492835521698
Validation loss: 2.5803526639938354

Epoch: 43| Step: 0
Training loss: 2.9709839820861816
Validation loss: 2.5775867303212485

Epoch: 6| Step: 1
Training loss: 2.7500014305114746
Validation loss: 2.573678811391195

Epoch: 6| Step: 2
Training loss: 3.0127792358398438
Validation loss: 2.569089392820994

Epoch: 6| Step: 3
Training loss: 3.120290994644165
Validation loss: 2.567713896433512

Epoch: 6| Step: 4
Training loss: 3.039793014526367
Validation loss: 2.56616864601771

Epoch: 6| Step: 5
Training loss: 2.735139846801758
Validation loss: 2.560662627220154

Epoch: 6| Step: 6
Training loss: 2.418255090713501
Validation loss: 2.56033456325531

Epoch: 6| Step: 7
Training loss: 2.911193370819092
Validation loss: 2.558101495107015

Epoch: 6| Step: 8
Training loss: 3.0000572204589844
Validation loss: 2.5525744954744973

Epoch: 6| Step: 9
Training loss: 2.8478424549102783
Validation loss: 2.5534178018569946

Epoch: 6| Step: 10
Training loss: 2.914597749710083
Validation loss: 2.546919564406077

Epoch: 6| Step: 11
Training loss: 2.3946852684020996
Validation loss: 2.5441924333572388

Epoch: 6| Step: 12
Training loss: 2.4772815704345703
Validation loss: 2.5439687371253967

Epoch: 6| Step: 13
Training loss: 1.9942189455032349
Validation loss: 2.5424523750940957

Epoch: 44| Step: 0
Training loss: 2.284745216369629
Validation loss: 2.5395963986714682

Epoch: 6| Step: 1
Training loss: 2.749746799468994
Validation loss: 2.5416572093963623

Epoch: 6| Step: 2
Training loss: 3.088925838470459
Validation loss: 2.541164994239807

Epoch: 6| Step: 3
Training loss: 3.1521096229553223
Validation loss: 2.535541554292043

Epoch: 6| Step: 4
Training loss: 3.3694114685058594
Validation loss: 2.5436302026112876

Epoch: 6| Step: 5
Training loss: 2.7782912254333496
Validation loss: 2.538441757361094

Epoch: 6| Step: 6
Training loss: 2.377668857574463
Validation loss: 2.5343647400538125

Epoch: 6| Step: 7
Training loss: 2.3593533039093018
Validation loss: 2.5270042419433594

Epoch: 6| Step: 8
Training loss: 2.9077095985412598
Validation loss: 2.5222703019777932

Epoch: 6| Step: 9
Training loss: 2.5767312049865723
Validation loss: 2.521466056505839

Epoch: 6| Step: 10
Training loss: 3.0584301948547363
Validation loss: 2.5191980600357056

Epoch: 6| Step: 11
Training loss: 2.43129825592041
Validation loss: 2.5180036226908364

Epoch: 6| Step: 12
Training loss: 2.9375991821289062
Validation loss: 2.516749382019043

Epoch: 6| Step: 13
Training loss: 2.048757553100586
Validation loss: 2.5131398836771646

Epoch: 45| Step: 0
Training loss: 2.9235239028930664
Validation loss: 2.5088833570480347

Epoch: 6| Step: 1
Training loss: 2.2288930416107178
Validation loss: 2.5066593488057456

Epoch: 6| Step: 2
Training loss: 2.651763677597046
Validation loss: 2.5041406551996865

Epoch: 6| Step: 3
Training loss: 2.362046003341675
Validation loss: 2.503142476081848

Epoch: 6| Step: 4
Training loss: 2.6468019485473633
Validation loss: 2.5012332995732627

Epoch: 6| Step: 5
Training loss: 2.594836711883545
Validation loss: 2.5005549589792886

Epoch: 6| Step: 6
Training loss: 2.749135732650757
Validation loss: 2.4965890645980835

Epoch: 6| Step: 7
Training loss: 2.349545478820801
Validation loss: 2.4945935805638633

Epoch: 6| Step: 8
Training loss: 3.0779027938842773
Validation loss: 2.4908668597539267

Epoch: 6| Step: 9
Training loss: 2.455960988998413
Validation loss: 2.490740398565928

Epoch: 6| Step: 10
Training loss: 3.3222479820251465
Validation loss: 2.4862821896870932

Epoch: 6| Step: 11
Training loss: 3.0531229972839355
Validation loss: 2.484079897403717

Epoch: 6| Step: 12
Training loss: 2.566136360168457
Validation loss: 2.4796692927678428

Epoch: 6| Step: 13
Training loss: 2.6721677780151367
Validation loss: 2.487401763598124

Epoch: 46| Step: 0
Training loss: 2.203483819961548
Validation loss: 2.4885441064834595

Epoch: 6| Step: 1
Training loss: 3.129390239715576
Validation loss: 2.4988886515299478

Epoch: 6| Step: 2
Training loss: 3.3265743255615234
Validation loss: 2.478368639945984

Epoch: 6| Step: 3
Training loss: 2.4629197120666504
Validation loss: 2.472158153851827

Epoch: 6| Step: 4
Training loss: 2.6612513065338135
Validation loss: 2.4667245149612427

Epoch: 6| Step: 5
Training loss: 2.7260124683380127
Validation loss: 2.4652777115503945

Epoch: 6| Step: 6
Training loss: 2.4734625816345215
Validation loss: 2.4672107100486755

Epoch: 6| Step: 7
Training loss: 2.616140842437744
Validation loss: 2.465349872907003

Epoch: 6| Step: 8
Training loss: 3.0912084579467773
Validation loss: 2.467906971772512

Epoch: 6| Step: 9
Training loss: 2.808809518814087
Validation loss: 2.4649807612101235

Epoch: 6| Step: 10
Training loss: 2.159946918487549
Validation loss: 2.4612056612968445

Epoch: 6| Step: 11
Training loss: 1.706404685974121
Validation loss: 2.457489232222239

Epoch: 6| Step: 12
Training loss: 3.058265447616577
Validation loss: 2.45621387163798

Epoch: 6| Step: 13
Training loss: 2.8808021545410156
Validation loss: 2.451624035835266

Epoch: 47| Step: 0
Training loss: 2.186495780944824
Validation loss: 2.4526100953420005

Epoch: 6| Step: 1
Training loss: 1.9260585308074951
Validation loss: 2.4454954862594604

Epoch: 6| Step: 2
Training loss: 2.6770284175872803
Validation loss: 2.4428380330403647

Epoch: 6| Step: 3
Training loss: 3.121523141860962
Validation loss: 2.4432695508003235

Epoch: 6| Step: 4
Training loss: 2.985933303833008
Validation loss: 2.4367686112721763

Epoch: 6| Step: 5
Training loss: 2.209733009338379
Validation loss: 2.435437778631846

Epoch: 6| Step: 6
Training loss: 2.396603584289551
Validation loss: 2.4374093214670816

Epoch: 6| Step: 7
Training loss: 2.7692465782165527
Validation loss: 2.4347058534622192

Epoch: 6| Step: 8
Training loss: 2.521794319152832
Validation loss: 2.4352289835611978

Epoch: 6| Step: 9
Training loss: 3.096104621887207
Validation loss: 2.4326210816701255

Epoch: 6| Step: 10
Training loss: 3.0950002670288086
Validation loss: 2.428072770436605

Epoch: 6| Step: 11
Training loss: 3.0920894145965576
Validation loss: 2.426024913787842

Epoch: 6| Step: 12
Training loss: 1.7316110134124756
Validation loss: 2.418410301208496

Epoch: 6| Step: 13
Training loss: 2.887065887451172
Validation loss: 2.4199647108713784

Epoch: 48| Step: 0
Training loss: 2.8380444049835205
Validation loss: 2.415849486986796

Epoch: 6| Step: 1
Training loss: 3.2610108852386475
Validation loss: 2.4155146280924478

Epoch: 6| Step: 2
Training loss: 3.2324581146240234
Validation loss: 2.4101521571477256

Epoch: 6| Step: 3
Training loss: 2.2048189640045166
Validation loss: 2.409468690554301

Epoch: 6| Step: 4
Training loss: 2.734236717224121
Validation loss: 2.4039539893468223

Epoch: 6| Step: 5
Training loss: 3.051431179046631
Validation loss: 2.402352432409922

Epoch: 6| Step: 6
Training loss: 2.029618740081787
Validation loss: 2.4019757906595864

Epoch: 6| Step: 7
Training loss: 2.783651351928711
Validation loss: 2.3976410627365112

Epoch: 6| Step: 8
Training loss: 2.1909339427948
Validation loss: 2.3978593349456787

Epoch: 6| Step: 9
Training loss: 2.69258451461792
Validation loss: 2.394613345464071

Epoch: 6| Step: 10
Training loss: 2.324719190597534
Validation loss: 2.3932663202285767

Epoch: 6| Step: 11
Training loss: 2.2851920127868652
Validation loss: 2.3891303141911826

Epoch: 6| Step: 12
Training loss: 1.876144528388977
Validation loss: 2.3842799266179404

Epoch: 6| Step: 13
Training loss: 2.644052505493164
Validation loss: 2.384784201780955

Epoch: 49| Step: 0
Training loss: 2.431400775909424
Validation loss: 2.378355940183004

Epoch: 6| Step: 1
Training loss: 2.8119804859161377
Validation loss: 2.383479634920756

Epoch: 6| Step: 2
Training loss: 2.477902889251709
Validation loss: 2.3788391749064126

Epoch: 6| Step: 3
Training loss: 2.6060197353363037
Validation loss: 2.373674154281616

Epoch: 6| Step: 4
Training loss: 2.0378165245056152
Validation loss: 2.376130918661753

Epoch: 6| Step: 5
Training loss: 3.165191888809204
Validation loss: 2.3775081833203635

Epoch: 6| Step: 6
Training loss: 2.52982497215271
Validation loss: 2.3730368614196777

Epoch: 6| Step: 7
Training loss: 2.1005630493164062
Validation loss: 2.370772202809652

Epoch: 6| Step: 8
Training loss: 2.0481858253479004
Validation loss: 2.3687462409337363

Epoch: 6| Step: 9
Training loss: 3.424985408782959
Validation loss: 2.36854883035024

Epoch: 6| Step: 10
Training loss: 2.678093910217285
Validation loss: 2.3663354317347207

Epoch: 6| Step: 11
Training loss: 2.3418118953704834
Validation loss: 2.368440628051758

Epoch: 6| Step: 12
Training loss: 2.535834312438965
Validation loss: 2.3607651392618814

Epoch: 6| Step: 13
Training loss: 2.4671244621276855
Validation loss: 2.3558066685994468

Epoch: 50| Step: 0
Training loss: 2.111116647720337
Validation loss: 2.3553208907445273

Epoch: 6| Step: 1
Training loss: 1.8027695417404175
Validation loss: 2.3516351779301963

Epoch: 6| Step: 2
Training loss: 2.429687023162842
Validation loss: 2.351978858311971

Epoch: 6| Step: 3
Training loss: 2.633826732635498
Validation loss: 2.3497119744618735

Epoch: 6| Step: 4
Training loss: 2.8318891525268555
Validation loss: 2.3516735831896463

Epoch: 6| Step: 5
Training loss: 2.466482162475586
Validation loss: 2.3493070205052695

Epoch: 6| Step: 6
Training loss: 3.1616897583007812
Validation loss: 2.3467612663904824

Epoch: 6| Step: 7
Training loss: 2.5401060581207275
Validation loss: 2.34608922402064

Epoch: 6| Step: 8
Training loss: 2.4501476287841797
Validation loss: 2.3389110763867698

Epoch: 6| Step: 9
Training loss: 2.200230121612549
Validation loss: 2.3407263358434043

Epoch: 6| Step: 10
Training loss: 2.1703758239746094
Validation loss: 2.338060657183329

Epoch: 6| Step: 11
Training loss: 2.53603458404541
Validation loss: 2.333922783533732

Epoch: 6| Step: 12
Training loss: 3.4290544986724854
Validation loss: 2.3352043430010476

Epoch: 6| Step: 13
Training loss: 2.4323835372924805
Validation loss: 2.3340622584025064

Epoch: 51| Step: 0
Training loss: 2.3099493980407715
Validation loss: 2.332733154296875

Epoch: 6| Step: 1
Training loss: 2.306057929992676
Validation loss: 2.323703726132711

Epoch: 6| Step: 2
Training loss: 2.6436493396759033
Validation loss: 2.323500712712606

Epoch: 6| Step: 3
Training loss: 2.3891685009002686
Validation loss: 2.325416405995687

Epoch: 6| Step: 4
Training loss: 2.4873034954071045
Validation loss: 2.3198599418004355

Epoch: 6| Step: 5
Training loss: 2.2101759910583496
Validation loss: 2.314866781234741

Epoch: 6| Step: 6
Training loss: 3.226654529571533
Validation loss: 2.3144012093544006

Epoch: 6| Step: 7
Training loss: 2.6294355392456055
Validation loss: 2.3153573075930276

Epoch: 6| Step: 8
Training loss: 2.469320774078369
Validation loss: 2.3109089136123657

Epoch: 6| Step: 9
Training loss: 2.170328140258789
Validation loss: 2.3178264697392783

Epoch: 6| Step: 10
Training loss: 2.2983734607696533
Validation loss: 2.3145328760147095

Epoch: 6| Step: 11
Training loss: 2.9446771144866943
Validation loss: 2.3070196310679116

Epoch: 6| Step: 12
Training loss: 2.4060263633728027
Validation loss: 2.303681969642639

Epoch: 6| Step: 13
Training loss: 2.2596993446350098
Validation loss: 2.3001460433006287

Epoch: 52| Step: 0
Training loss: 3.1702370643615723
Validation loss: 2.2984790404637656

Epoch: 6| Step: 1
Training loss: 2.6797995567321777
Validation loss: 2.2985161940256753

Epoch: 6| Step: 2
Training loss: 2.8861265182495117
Validation loss: 2.297460675239563

Epoch: 6| Step: 3
Training loss: 2.1909799575805664
Validation loss: 2.2982789079348245

Epoch: 6| Step: 4
Training loss: 2.246523857116699
Validation loss: 2.295083006223043

Epoch: 6| Step: 5
Training loss: 2.546109199523926
Validation loss: 2.290927012761434

Epoch: 6| Step: 6
Training loss: 2.3168692588806152
Validation loss: 2.2891600529352822

Epoch: 6| Step: 7
Training loss: 2.0183627605438232
Validation loss: 2.2901820143063865

Epoch: 6| Step: 8
Training loss: 1.3258881568908691
Validation loss: 2.293666362762451

Epoch: 6| Step: 9
Training loss: 2.175241470336914
Validation loss: 2.2869144678115845

Epoch: 6| Step: 10
Training loss: 2.3112144470214844
Validation loss: 2.286612788836161

Epoch: 6| Step: 11
Training loss: 3.64888596534729
Validation loss: 2.2776342233022056

Epoch: 6| Step: 12
Training loss: 2.4925711154937744
Validation loss: 2.277565598487854

Epoch: 6| Step: 13
Training loss: 2.304795980453491
Validation loss: 2.2721468210220337

Epoch: 53| Step: 0
Training loss: 2.008518695831299
Validation loss: 2.2700168093045554

Epoch: 6| Step: 1
Training loss: 1.8375864028930664
Validation loss: 2.275440295537313

Epoch: 6| Step: 2
Training loss: 1.8748400211334229
Validation loss: 2.272041360537211

Epoch: 6| Step: 3
Training loss: 3.048022508621216
Validation loss: 2.273846904436747

Epoch: 6| Step: 4
Training loss: 2.5245914459228516
Validation loss: 2.2734416723251343

Epoch: 6| Step: 5
Training loss: 2.1543800830841064
Validation loss: 2.2653382619222007

Epoch: 6| Step: 6
Training loss: 3.075676918029785
Validation loss: 2.2664106488227844

Epoch: 6| Step: 7
Training loss: 2.4182865619659424
Validation loss: 2.267119566599528

Epoch: 6| Step: 8
Training loss: 2.8253653049468994
Validation loss: 2.2628270387649536

Epoch: 6| Step: 9
Training loss: 3.0293307304382324
Validation loss: 2.261541485786438

Epoch: 6| Step: 10
Training loss: 2.2127506732940674
Validation loss: 2.2571045557657876

Epoch: 6| Step: 11
Training loss: 2.121424674987793
Validation loss: 2.2606966694196067

Epoch: 6| Step: 12
Training loss: 2.3479466438293457
Validation loss: 2.2527499993642173

Epoch: 6| Step: 13
Training loss: 2.421475648880005
Validation loss: 2.2530025243759155

Epoch: 54| Step: 0
Training loss: 1.9139277935028076
Validation loss: 2.2512622674306235

Epoch: 6| Step: 1
Training loss: 1.596219539642334
Validation loss: 2.247269113858541

Epoch: 6| Step: 2
Training loss: 2.437075138092041
Validation loss: 2.2496371070543923

Epoch: 6| Step: 3
Training loss: 2.976717472076416
Validation loss: 2.242098649342855

Epoch: 6| Step: 4
Training loss: 2.244284152984619
Validation loss: 2.241342226664225

Epoch: 6| Step: 5
Training loss: 3.34572696685791
Validation loss: 2.24012819925944

Epoch: 6| Step: 6
Training loss: 1.895263671875
Validation loss: 2.2394280234972634

Epoch: 6| Step: 7
Training loss: 1.8147706985473633
Validation loss: 2.238907059033712

Epoch: 6| Step: 8
Training loss: 2.906865119934082
Validation loss: 2.2367777228355408

Epoch: 6| Step: 9
Training loss: 2.547677516937256
Validation loss: 2.229068477948507

Epoch: 6| Step: 10
Training loss: 2.3447604179382324
Validation loss: 2.2242998282114663

Epoch: 6| Step: 11
Training loss: 2.1833181381225586
Validation loss: 2.225259006023407

Epoch: 6| Step: 12
Training loss: 2.4771976470947266
Validation loss: 2.2263510624567666

Epoch: 6| Step: 13
Training loss: 2.7254974842071533
Validation loss: 2.2311939001083374

Epoch: 55| Step: 0
Training loss: 2.762756824493408
Validation loss: 2.2252223889033

Epoch: 6| Step: 1
Training loss: 2.202212333679199
Validation loss: 2.2244356075922647

Epoch: 6| Step: 2
Training loss: 2.478907585144043
Validation loss: 2.215145468711853

Epoch: 6| Step: 3
Training loss: 2.806755542755127
Validation loss: 2.214802066485087

Epoch: 6| Step: 4
Training loss: 1.659623384475708
Validation loss: 2.219905217488607

Epoch: 6| Step: 5
Training loss: 1.6885852813720703
Validation loss: 2.214923600355784

Epoch: 6| Step: 6
Training loss: 2.4155173301696777
Validation loss: 2.209726631641388

Epoch: 6| Step: 7
Training loss: 2.1440632343292236
Validation loss: 2.2093466321627298

Epoch: 6| Step: 8
Training loss: 2.583697557449341
Validation loss: 2.2092491587003074

Epoch: 6| Step: 9
Training loss: 2.154508590698242
Validation loss: 2.2105815410614014

Epoch: 6| Step: 10
Training loss: 2.1257526874542236
Validation loss: 2.2089927196502686

Epoch: 6| Step: 11
Training loss: 3.175684690475464
Validation loss: 2.1988001664479575

Epoch: 6| Step: 12
Training loss: 2.61869740486145
Validation loss: 2.199795186519623

Epoch: 6| Step: 13
Training loss: 2.3063931465148926
Validation loss: 2.198058823744456

Epoch: 56| Step: 0
Training loss: 2.441225051879883
Validation loss: 2.1957585414250693

Epoch: 6| Step: 1
Training loss: 2.6804115772247314
Validation loss: 2.19426429271698

Epoch: 6| Step: 2
Training loss: 2.3007469177246094
Validation loss: 2.194169600804647

Epoch: 6| Step: 3
Training loss: 2.877017021179199
Validation loss: 2.195628046989441

Epoch: 6| Step: 4
Training loss: 2.3435752391815186
Validation loss: 2.190703272819519

Epoch: 6| Step: 5
Training loss: 2.0244863033294678
Validation loss: 2.1903675397237143

Epoch: 6| Step: 6
Training loss: 2.3492579460144043
Validation loss: 2.182586391766866

Epoch: 6| Step: 7
Training loss: 2.139039993286133
Validation loss: 2.1835426688194275

Epoch: 6| Step: 8
Training loss: 2.7530264854431152
Validation loss: 2.190885543823242

Epoch: 6| Step: 9
Training loss: 2.645936965942383
Validation loss: 2.182319621245066

Epoch: 6| Step: 10
Training loss: 2.136186122894287
Validation loss: 2.188010354836782

Epoch: 6| Step: 11
Training loss: 1.7880611419677734
Validation loss: 2.185529887676239

Epoch: 6| Step: 12
Training loss: 2.0756583213806152
Validation loss: 2.185231328010559

Epoch: 6| Step: 13
Training loss: 2.2799525260925293
Validation loss: 2.183209220568339

Epoch: 57| Step: 0
Training loss: 1.9899978637695312
Validation loss: 2.17988657951355

Epoch: 6| Step: 1
Training loss: 2.298809289932251
Validation loss: 2.178416132926941

Epoch: 6| Step: 2
Training loss: 2.3389153480529785
Validation loss: 2.1812638640403748

Epoch: 6| Step: 3
Training loss: 3.1421244144439697
Validation loss: 2.186904708544413

Epoch: 6| Step: 4
Training loss: 2.6529812812805176
Validation loss: 2.182381490866343

Epoch: 6| Step: 5
Training loss: 2.0568079948425293
Validation loss: 2.1902878880500793

Epoch: 6| Step: 6
Training loss: 1.9705764055252075
Validation loss: 2.189048786958059

Epoch: 6| Step: 7
Training loss: 2.4693191051483154
Validation loss: 2.1916796962420144

Epoch: 6| Step: 8
Training loss: 1.8656085729599
Validation loss: 2.191051503022512

Epoch: 6| Step: 9
Training loss: 2.775747299194336
Validation loss: 2.1804060538609824

Epoch: 6| Step: 10
Training loss: 2.179633140563965
Validation loss: 2.1745702226956687

Epoch: 6| Step: 11
Training loss: 1.974189043045044
Validation loss: 2.170595566431681

Epoch: 6| Step: 12
Training loss: 2.308276891708374
Validation loss: 2.167958895365397

Epoch: 6| Step: 13
Training loss: 2.691211223602295
Validation loss: 2.17216157913208

Epoch: 58| Step: 0
Training loss: 2.0841686725616455
Validation loss: 2.1739166180292764

Epoch: 6| Step: 1
Training loss: 2.6592767238616943
Validation loss: 2.1710960070292153

Epoch: 6| Step: 2
Training loss: 2.3699047565460205
Validation loss: 2.1768429279327393

Epoch: 6| Step: 3
Training loss: 2.5527000427246094
Validation loss: 2.172347664833069

Epoch: 6| Step: 4
Training loss: 2.496943950653076
Validation loss: 2.1689786116282144

Epoch: 6| Step: 5
Training loss: 2.3010079860687256
Validation loss: 2.1739405393600464

Epoch: 6| Step: 6
Training loss: 1.483971118927002
Validation loss: 2.171516259511312

Epoch: 6| Step: 7
Training loss: 2.383082389831543
Validation loss: 2.170504848162333

Epoch: 6| Step: 8
Training loss: 2.5940842628479004
Validation loss: 2.1626213788986206

Epoch: 6| Step: 9
Training loss: 2.6787374019622803
Validation loss: 2.1583659052848816

Epoch: 6| Step: 10
Training loss: 2.2859883308410645
Validation loss: 2.158038338025411

Epoch: 6| Step: 11
Training loss: 2.561835289001465
Validation loss: 2.168888529141744

Epoch: 6| Step: 12
Training loss: 1.4486603736877441
Validation loss: 2.1815132300059

Epoch: 6| Step: 13
Training loss: 2.5171616077423096
Validation loss: 2.1835463444391885

Epoch: 59| Step: 0
Training loss: 2.2952210903167725
Validation loss: 2.1950447161992392

Epoch: 6| Step: 1
Training loss: 2.5937347412109375
Validation loss: 2.204440196355184

Epoch: 6| Step: 2
Training loss: 2.565105438232422
Validation loss: 2.20745313167572

Epoch: 6| Step: 3
Training loss: 2.371588706970215
Validation loss: 2.207449793815613

Epoch: 6| Step: 4
Training loss: 2.3753490447998047
Validation loss: 2.201307694117228

Epoch: 6| Step: 5
Training loss: 2.452270984649658
Validation loss: 2.1940019130706787

Epoch: 6| Step: 6
Training loss: 1.8083341121673584
Validation loss: 2.180190841356913

Epoch: 6| Step: 7
Training loss: 2.053804874420166
Validation loss: 2.173410256703695

Epoch: 6| Step: 8
Training loss: 2.472533941268921
Validation loss: 2.162452677885691

Epoch: 6| Step: 9
Training loss: 1.9100772142410278
Validation loss: 2.1587473154067993

Epoch: 6| Step: 10
Training loss: 1.9576027393341064
Validation loss: 2.151837388674418

Epoch: 6| Step: 11
Training loss: 2.487344264984131
Validation loss: 2.147336999575297

Epoch: 6| Step: 12
Training loss: 2.7897143363952637
Validation loss: 2.1447919607162476

Epoch: 6| Step: 13
Training loss: 2.5991294384002686
Validation loss: 2.1424530148506165

Epoch: 60| Step: 0
Training loss: 2.251140832901001
Validation loss: 2.147749880949656

Epoch: 6| Step: 1
Training loss: 2.7721924781799316
Validation loss: 2.1411471565564475

Epoch: 6| Step: 2
Training loss: 2.3958349227905273
Validation loss: 2.1503747701644897

Epoch: 6| Step: 3
Training loss: 2.0062503814697266
Validation loss: 2.1402293841044107

Epoch: 6| Step: 4
Training loss: 2.5956358909606934
Validation loss: 2.1545268495877585

Epoch: 6| Step: 5
Training loss: 2.48848295211792
Validation loss: 2.1505537629127502

Epoch: 6| Step: 6
Training loss: 2.5948104858398438
Validation loss: 2.155180195967356

Epoch: 6| Step: 7
Training loss: 1.4721238613128662
Validation loss: 2.155464251836141

Epoch: 6| Step: 8
Training loss: 1.569300651550293
Validation loss: 2.150041917959849

Epoch: 6| Step: 9
Training loss: 2.6000900268554688
Validation loss: 2.1769421895345054

Epoch: 6| Step: 10
Training loss: 2.7754249572753906
Validation loss: 2.16919869184494

Epoch: 6| Step: 11
Training loss: 2.1672112941741943
Validation loss: 2.1428640484809875

Epoch: 6| Step: 12
Training loss: 2.461860179901123
Validation loss: 2.134453594684601

Epoch: 6| Step: 13
Training loss: 2.2044944763183594
Validation loss: 2.1298789580663047

Epoch: 61| Step: 0
Training loss: 2.3558425903320312
Validation loss: 2.1301613648732505

Epoch: 6| Step: 1
Training loss: 3.19600772857666
Validation loss: 2.128715713818868

Epoch: 6| Step: 2
Training loss: 1.4878754615783691
Validation loss: 2.1322221755981445

Epoch: 6| Step: 3
Training loss: 2.372321605682373
Validation loss: 2.132944643497467

Epoch: 6| Step: 4
Training loss: 2.4364161491394043
Validation loss: 2.134312391281128

Epoch: 6| Step: 5
Training loss: 2.1948139667510986
Validation loss: 2.137448231379191

Epoch: 6| Step: 6
Training loss: 1.9918887615203857
Validation loss: 2.1396698554356894

Epoch: 6| Step: 7
Training loss: 2.2619991302490234
Validation loss: 2.1431920329729715

Epoch: 6| Step: 8
Training loss: 2.2037172317504883
Validation loss: 2.1407450636227927

Epoch: 6| Step: 9
Training loss: 2.7034482955932617
Validation loss: 2.140837868054708

Epoch: 6| Step: 10
Training loss: 1.7714686393737793
Validation loss: 2.132554749647776

Epoch: 6| Step: 11
Training loss: 2.5326151847839355
Validation loss: 2.1301596760749817

Epoch: 6| Step: 12
Training loss: 2.766521692276001
Validation loss: 2.1265922586123147

Epoch: 6| Step: 13
Training loss: 1.9656174182891846
Validation loss: 2.1181463996569314

Epoch: 62| Step: 0
Training loss: 2.7411551475524902
Validation loss: 2.1173524061838784

Epoch: 6| Step: 1
Training loss: 2.7154030799865723
Validation loss: 2.1116464932759604

Epoch: 6| Step: 2
Training loss: 2.299511432647705
Validation loss: 2.111883898576101

Epoch: 6| Step: 3
Training loss: 2.6126909255981445
Validation loss: 2.1139737566312156

Epoch: 6| Step: 4
Training loss: 2.8590359687805176
Validation loss: 2.109999438126882

Epoch: 6| Step: 5
Training loss: 1.9386825561523438
Validation loss: 2.10334579149882

Epoch: 6| Step: 6
Training loss: 2.7057321071624756
Validation loss: 2.105252822240194

Epoch: 6| Step: 7
Training loss: 1.9221088886260986
Validation loss: 2.1000053683916726

Epoch: 6| Step: 8
Training loss: 1.4802780151367188
Validation loss: 2.0983548363049827

Epoch: 6| Step: 9
Training loss: 1.7800960540771484
Validation loss: 2.1052218079566956

Epoch: 6| Step: 10
Training loss: 2.0443999767303467
Validation loss: 2.1049002408981323

Epoch: 6| Step: 11
Training loss: 2.6609139442443848
Validation loss: 2.1119824250539145

Epoch: 6| Step: 12
Training loss: 1.9105817079544067
Validation loss: 2.1149027744928994

Epoch: 6| Step: 13
Training loss: 2.1412885189056396
Validation loss: 2.109212120374044

Epoch: 63| Step: 0
Training loss: 1.8311221599578857
Validation loss: 2.0997358560562134

Epoch: 6| Step: 1
Training loss: 1.7876466512680054
Validation loss: 2.1071004072825112

Epoch: 6| Step: 2
Training loss: 2.4059348106384277
Validation loss: 2.118453045686086

Epoch: 6| Step: 3
Training loss: 2.1048383712768555
Validation loss: 2.1309683124224343

Epoch: 6| Step: 4
Training loss: 2.7400600910186768
Validation loss: 2.1102478305498757

Epoch: 6| Step: 5
Training loss: 1.684762716293335
Validation loss: 2.0985777576764426

Epoch: 6| Step: 6
Training loss: 2.2814927101135254
Validation loss: 2.091027836004893

Epoch: 6| Step: 7
Training loss: 2.6824021339416504
Validation loss: 2.0995319883028665

Epoch: 6| Step: 8
Training loss: 2.084242582321167
Validation loss: 2.1022205352783203

Epoch: 6| Step: 9
Training loss: 2.1551690101623535
Validation loss: 2.1029076973597207

Epoch: 6| Step: 10
Training loss: 3.178576946258545
Validation loss: 2.107705056667328

Epoch: 6| Step: 11
Training loss: 1.8311281204223633
Validation loss: 2.099210739135742

Epoch: 6| Step: 12
Training loss: 2.5219435691833496
Validation loss: 2.096440315246582

Epoch: 6| Step: 13
Training loss: 2.355050563812256
Validation loss: 2.098965664704641

Epoch: 64| Step: 0
Training loss: 2.597994089126587
Validation loss: 2.089110255241394

Epoch: 6| Step: 1
Training loss: 2.5599684715270996
Validation loss: 2.097622493902842

Epoch: 6| Step: 2
Training loss: 2.7954134941101074
Validation loss: 2.08040843407313

Epoch: 6| Step: 3
Training loss: 2.375399351119995
Validation loss: 2.084331830342611

Epoch: 6| Step: 4
Training loss: 2.4824881553649902
Validation loss: 2.089351932207743

Epoch: 6| Step: 5
Training loss: 2.010566234588623
Validation loss: 2.0898095766703286

Epoch: 6| Step: 6
Training loss: 1.7941696643829346
Validation loss: 2.097013274828593

Epoch: 6| Step: 7
Training loss: 2.707622528076172
Validation loss: 2.10567573706309

Epoch: 6| Step: 8
Training loss: 1.9186846017837524
Validation loss: 2.095177928606669

Epoch: 6| Step: 9
Training loss: 2.3584442138671875
Validation loss: 2.10160497824351

Epoch: 6| Step: 10
Training loss: 1.4707845449447632
Validation loss: 2.0939573844273887

Epoch: 6| Step: 11
Training loss: 1.924497365951538
Validation loss: 2.0891547997792563

Epoch: 6| Step: 12
Training loss: 2.2875218391418457
Validation loss: 2.089134852091471

Epoch: 6| Step: 13
Training loss: 2.3292059898376465
Validation loss: 2.082231084505717

Epoch: 65| Step: 0
Training loss: 2.0852062702178955
Validation loss: 2.0756484866142273

Epoch: 6| Step: 1
Training loss: 2.0416512489318848
Validation loss: 2.073376218477885

Epoch: 6| Step: 2
Training loss: 2.4742512702941895
Validation loss: 2.073147694269816

Epoch: 6| Step: 3
Training loss: 1.7017287015914917
Validation loss: 2.072897473971049

Epoch: 6| Step: 4
Training loss: 2.281195640563965
Validation loss: 2.0834717949231467

Epoch: 6| Step: 5
Training loss: 1.663846492767334
Validation loss: 2.08212012052536

Epoch: 6| Step: 6
Training loss: 2.1788158416748047
Validation loss: 2.0787559946378074

Epoch: 6| Step: 7
Training loss: 2.5310888290405273
Validation loss: 2.0695919394493103

Epoch: 6| Step: 8
Training loss: 2.2815818786621094
Validation loss: 2.076068619887034

Epoch: 6| Step: 9
Training loss: 2.3269784450531006
Validation loss: 2.06166938940684

Epoch: 6| Step: 10
Training loss: 2.1892924308776855
Validation loss: 2.063977062702179

Epoch: 6| Step: 11
Training loss: 2.345505714416504
Validation loss: 2.0631529490152993

Epoch: 6| Step: 12
Training loss: 2.523995876312256
Validation loss: 2.062566022078196

Epoch: 6| Step: 13
Training loss: 2.59294056892395
Validation loss: 2.0687997341156006

Epoch: 66| Step: 0
Training loss: 2.6420235633850098
Validation loss: 2.0742884079615274

Epoch: 6| Step: 1
Training loss: 2.3239898681640625
Validation loss: 2.06917933622996

Epoch: 6| Step: 2
Training loss: 2.3303029537200928
Validation loss: 2.06939826409022

Epoch: 6| Step: 3
Training loss: 2.1990489959716797
Validation loss: 2.070610523223877

Epoch: 6| Step: 4
Training loss: 2.2957077026367188
Validation loss: 2.0710514386494956

Epoch: 6| Step: 5
Training loss: 2.3188772201538086
Validation loss: 2.0678072373072305

Epoch: 6| Step: 6
Training loss: 2.224653959274292
Validation loss: 2.0663575728734336

Epoch: 6| Step: 7
Training loss: 1.7234796285629272
Validation loss: 2.0647682547569275

Epoch: 6| Step: 8
Training loss: 1.9989310503005981
Validation loss: 2.0705093145370483

Epoch: 6| Step: 9
Training loss: 1.909188151359558
Validation loss: 2.073458274205526

Epoch: 6| Step: 10
Training loss: 2.3182082176208496
Validation loss: 2.0791779359181723

Epoch: 6| Step: 11
Training loss: 2.036282777786255
Validation loss: 2.070537745952606

Epoch: 6| Step: 12
Training loss: 2.586846351623535
Validation loss: 2.0661091009775796

Epoch: 6| Step: 13
Training loss: 2.4207262992858887
Validation loss: 2.059190034866333

Epoch: 67| Step: 0
Training loss: 2.0733392238616943
Validation loss: 2.0606882174809775

Epoch: 6| Step: 1
Training loss: 2.8568015098571777
Validation loss: 2.0620489517847695

Epoch: 6| Step: 2
Training loss: 2.312866687774658
Validation loss: 2.0608387192090354

Epoch: 6| Step: 3
Training loss: 2.5009493827819824
Validation loss: 2.057792087395986

Epoch: 6| Step: 4
Training loss: 2.025973320007324
Validation loss: 2.0709015329678855

Epoch: 6| Step: 5
Training loss: 2.260197639465332
Validation loss: 2.069682459036509

Epoch: 6| Step: 6
Training loss: 1.877684235572815
Validation loss: 2.0656004746754966

Epoch: 6| Step: 7
Training loss: 1.9325923919677734
Validation loss: 2.0659605065981546

Epoch: 6| Step: 8
Training loss: 1.4979389905929565
Validation loss: 2.067681908607483

Epoch: 6| Step: 9
Training loss: 2.1427929401397705
Validation loss: 2.085108498732249

Epoch: 6| Step: 10
Training loss: 2.266660690307617
Validation loss: 2.107349773248037

Epoch: 6| Step: 11
Training loss: 2.766369342803955
Validation loss: 2.124623199303945

Epoch: 6| Step: 12
Training loss: 2.3776636123657227
Validation loss: 2.104706585407257

Epoch: 6| Step: 13
Training loss: 2.480520009994507
Validation loss: 2.072187125682831

Epoch: 68| Step: 0
Training loss: 2.1547319889068604
Validation loss: 2.070611000061035

Epoch: 6| Step: 1
Training loss: 2.6886210441589355
Validation loss: 2.0727092226346335

Epoch: 6| Step: 2
Training loss: 2.2926273345947266
Validation loss: 2.0562793016433716

Epoch: 6| Step: 3
Training loss: 1.9978357553482056
Validation loss: 2.0463680028915405

Epoch: 6| Step: 4
Training loss: 1.9574191570281982
Validation loss: 2.0391825238863626

Epoch: 6| Step: 5
Training loss: 2.100304126739502
Validation loss: 2.0535297989845276

Epoch: 6| Step: 6
Training loss: 2.912674903869629
Validation loss: 2.048286040623983

Epoch: 6| Step: 7
Training loss: 2.400127410888672
Validation loss: 2.041748861471812

Epoch: 6| Step: 8
Training loss: 2.1580686569213867
Validation loss: 2.044885277748108

Epoch: 6| Step: 9
Training loss: 1.8650271892547607
Validation loss: 2.0458805759747825

Epoch: 6| Step: 10
Training loss: 2.493037223815918
Validation loss: 2.047019282976786

Epoch: 6| Step: 11
Training loss: 1.7619911432266235
Validation loss: 2.0473897655804953

Epoch: 6| Step: 12
Training loss: 1.4239108562469482
Validation loss: 2.051991959412893

Epoch: 6| Step: 13
Training loss: 2.613844871520996
Validation loss: 2.0710734327634177

Epoch: 69| Step: 0
Training loss: 2.4615354537963867
Validation loss: 2.075224280357361

Epoch: 6| Step: 1
Training loss: 2.2575154304504395
Validation loss: 2.0905140240987143

Epoch: 6| Step: 2
Training loss: 2.294931173324585
Validation loss: 2.096891979376475

Epoch: 6| Step: 3
Training loss: 2.014728546142578
Validation loss: 2.123995840549469

Epoch: 6| Step: 4
Training loss: 2.0259850025177
Validation loss: 2.1104700366655984

Epoch: 6| Step: 5
Training loss: 2.000892162322998
Validation loss: 2.094975392023722

Epoch: 6| Step: 6
Training loss: 2.2348825931549072
Validation loss: 2.094025492668152

Epoch: 6| Step: 7
Training loss: 1.6135625839233398
Validation loss: 2.0867143074671426

Epoch: 6| Step: 8
Training loss: 1.972625494003296
Validation loss: 2.0664125879605613

Epoch: 6| Step: 9
Training loss: 2.8117804527282715
Validation loss: 2.0547295808792114

Epoch: 6| Step: 10
Training loss: 2.089354991912842
Validation loss: 2.0355388720830283

Epoch: 6| Step: 11
Training loss: 2.5432543754577637
Validation loss: 2.037023742993673

Epoch: 6| Step: 12
Training loss: 2.31319522857666
Validation loss: 2.045012871424357

Epoch: 6| Step: 13
Training loss: 2.098684310913086
Validation loss: 2.0547609329223633

Epoch: 70| Step: 0
Training loss: 2.2483744621276855
Validation loss: 2.061290721098582

Epoch: 6| Step: 1
Training loss: 2.2973835468292236
Validation loss: 2.069822529951731

Epoch: 6| Step: 2
Training loss: 2.259030818939209
Validation loss: 2.0861610770225525

Epoch: 6| Step: 3
Training loss: 2.152883529663086
Validation loss: 2.101894994576772

Epoch: 6| Step: 4
Training loss: 1.5052430629730225
Validation loss: 2.114328066507975

Epoch: 6| Step: 5
Training loss: 2.0986759662628174
Validation loss: 2.125250538190206

Epoch: 6| Step: 6
Training loss: 2.131244659423828
Validation loss: 2.137382924556732

Epoch: 6| Step: 7
Training loss: 2.393054962158203
Validation loss: 2.137346565723419

Epoch: 6| Step: 8
Training loss: 2.081389904022217
Validation loss: 2.1427027185757956

Epoch: 6| Step: 9
Training loss: 2.777904748916626
Validation loss: 2.1280433336893716

Epoch: 6| Step: 10
Training loss: 2.1403579711914062
Validation loss: 2.108584761619568

Epoch: 6| Step: 11
Training loss: 2.6547935009002686
Validation loss: 2.090174158414205

Epoch: 6| Step: 12
Training loss: 2.7873268127441406
Validation loss: 2.07311874628067

Epoch: 6| Step: 13
Training loss: 2.4826855659484863
Validation loss: 2.07303520043691

Epoch: 71| Step: 0
Training loss: 2.304377555847168
Validation loss: 2.0497832695643106

Epoch: 6| Step: 1
Training loss: 2.3834447860717773
Validation loss: 2.0390796264012656

Epoch: 6| Step: 2
Training loss: 2.1786231994628906
Validation loss: 2.0254443089167276

Epoch: 6| Step: 3
Training loss: 2.80111026763916
Validation loss: 2.0353491504987082

Epoch: 6| Step: 4
Training loss: 2.087869882583618
Validation loss: 2.0393804907798767

Epoch: 6| Step: 5
Training loss: 1.7861592769622803
Validation loss: 2.057464083035787

Epoch: 6| Step: 6
Training loss: 2.282512903213501
Validation loss: 2.0793150464693704

Epoch: 6| Step: 7
Training loss: 2.904672145843506
Validation loss: 2.0838236808776855

Epoch: 6| Step: 8
Training loss: 1.5098819732666016
Validation loss: 2.078836500644684

Epoch: 6| Step: 9
Training loss: 2.5346317291259766
Validation loss: 2.0593583981196084

Epoch: 6| Step: 10
Training loss: 2.168750286102295
Validation loss: 2.057179073492686

Epoch: 6| Step: 11
Training loss: 2.245990037918091
Validation loss: 2.0452855626742044

Epoch: 6| Step: 12
Training loss: 1.9975297451019287
Validation loss: 2.037016491095225

Epoch: 6| Step: 13
Training loss: 1.8102513551712036
Validation loss: 2.031026621659597

Epoch: 72| Step: 0
Training loss: 2.035818099975586
Validation loss: 2.03058789173762

Epoch: 6| Step: 1
Training loss: 2.6725878715515137
Validation loss: 2.030478080113729

Epoch: 6| Step: 2
Training loss: 2.0270895957946777
Validation loss: 2.0325007239977517

Epoch: 6| Step: 3
Training loss: 1.7642135620117188
Validation loss: 2.0403268535931907

Epoch: 6| Step: 4
Training loss: 2.372295618057251
Validation loss: 2.0369324684143066

Epoch: 6| Step: 5
Training loss: 1.9451113939285278
Validation loss: 2.0430922905604043

Epoch: 6| Step: 6
Training loss: 1.9355727434158325
Validation loss: 2.0379164616266885

Epoch: 6| Step: 7
Training loss: 2.0153448581695557
Validation loss: 2.0369099775950112

Epoch: 6| Step: 8
Training loss: 2.252197027206421
Validation loss: 2.03064235051473

Epoch: 6| Step: 9
Training loss: 2.187441825866699
Validation loss: 2.0335214932759604

Epoch: 6| Step: 10
Training loss: 2.1145360469818115
Validation loss: 2.0352030793825784

Epoch: 6| Step: 11
Training loss: 3.1338047981262207
Validation loss: 2.0433998505274453

Epoch: 6| Step: 12
Training loss: 2.4477944374084473
Validation loss: 2.034379005432129

Epoch: 6| Step: 13
Training loss: 1.8888816833496094
Validation loss: 2.0554771423339844

Epoch: 73| Step: 0
Training loss: 2.2664923667907715
Validation loss: 2.0400723814964294

Epoch: 6| Step: 1
Training loss: 1.4757124185562134
Validation loss: 2.042916019757589

Epoch: 6| Step: 2
Training loss: 2.261443614959717
Validation loss: 2.038447916507721

Epoch: 6| Step: 3
Training loss: 1.4095873832702637
Validation loss: 2.0489995082219443

Epoch: 6| Step: 4
Training loss: 2.3049073219299316
Validation loss: 2.0305914282798767

Epoch: 6| Step: 5
Training loss: 2.0960264205932617
Validation loss: 2.036548693974813

Epoch: 6| Step: 6
Training loss: 2.1477434635162354
Validation loss: 2.0271576642990112

Epoch: 6| Step: 7
Training loss: 3.204070568084717
Validation loss: 2.026644984881083

Epoch: 6| Step: 8
Training loss: 1.5807132720947266
Validation loss: 2.029114087422689

Epoch: 6| Step: 9
Training loss: 2.816558361053467
Validation loss: 2.0349426865577698

Epoch: 6| Step: 10
Training loss: 1.7838966846466064
Validation loss: 2.040379504362742

Epoch: 6| Step: 11
Training loss: 1.9631719589233398
Validation loss: 2.040129065513611

Epoch: 6| Step: 12
Training loss: 2.6068756580352783
Validation loss: 2.0672385692596436

Epoch: 6| Step: 13
Training loss: 2.701972723007202
Validation loss: 2.066019336382548

Epoch: 74| Step: 0
Training loss: 1.9297642707824707
Validation loss: 2.0812593897183738

Epoch: 6| Step: 1
Training loss: 1.5364372730255127
Validation loss: 2.076239824295044

Epoch: 6| Step: 2
Training loss: 2.2597317695617676
Validation loss: 2.0755645434061685

Epoch: 6| Step: 3
Training loss: 1.9820044040679932
Validation loss: 2.089249928792318

Epoch: 6| Step: 4
Training loss: 2.3200643062591553
Validation loss: 2.0737669666608176

Epoch: 6| Step: 5
Training loss: 2.2371435165405273
Validation loss: 2.0814529061317444

Epoch: 6| Step: 6
Training loss: 2.7097082138061523
Validation loss: 2.108482221762339

Epoch: 6| Step: 7
Training loss: 2.2922677993774414
Validation loss: 2.0931153496106467

Epoch: 6| Step: 8
Training loss: 2.224703788757324
Validation loss: 2.070865035057068

Epoch: 6| Step: 9
Training loss: 2.683993339538574
Validation loss: 2.068711260954539

Epoch: 6| Step: 10
Training loss: 2.033864736557007
Validation loss: 2.0356687108675637

Epoch: 6| Step: 11
Training loss: 2.505617141723633
Validation loss: 2.025541126728058

Epoch: 6| Step: 12
Training loss: 2.0667052268981934
Validation loss: 2.021230856577555

Epoch: 6| Step: 13
Training loss: 1.8536152839660645
Validation loss: 2.037383178869883

Epoch: 75| Step: 0
Training loss: 2.7461955547332764
Validation loss: 2.0445846120516458

Epoch: 6| Step: 1
Training loss: 2.3510422706604004
Validation loss: 2.052204151948293

Epoch: 6| Step: 2
Training loss: 1.9648001194000244
Validation loss: 2.0569901863733926

Epoch: 6| Step: 3
Training loss: 1.826188087463379
Validation loss: 2.06224391857783

Epoch: 6| Step: 4
Training loss: 1.9955153465270996
Validation loss: 2.064159572124481

Epoch: 6| Step: 5
Training loss: 2.8199591636657715
Validation loss: 2.068387488524119

Epoch: 6| Step: 6
Training loss: 2.4548351764678955
Validation loss: 2.073261638482412

Epoch: 6| Step: 7
Training loss: 2.30383038520813
Validation loss: 2.0745391647020974

Epoch: 6| Step: 8
Training loss: 1.9639160633087158
Validation loss: 2.0764516790707908

Epoch: 6| Step: 9
Training loss: 1.803222417831421
Validation loss: 2.076582392056783

Epoch: 6| Step: 10
Training loss: 2.2848081588745117
Validation loss: 2.0748465259869895

Epoch: 6| Step: 11
Training loss: 2.4833805561065674
Validation loss: 2.063144067923228

Epoch: 6| Step: 12
Training loss: 1.9353337287902832
Validation loss: 2.0658743580182395

Epoch: 6| Step: 13
Training loss: 2.639521598815918
Validation loss: 2.060074826081594

Epoch: 76| Step: 0
Training loss: 2.687422752380371
Validation loss: 2.0571430126825967

Epoch: 6| Step: 1
Training loss: 2.2479395866394043
Validation loss: 2.0505056381225586

Epoch: 6| Step: 2
Training loss: 1.8397449254989624
Validation loss: 2.049697776635488

Epoch: 6| Step: 3
Training loss: 2.481969118118286
Validation loss: 2.0465086897214255

Epoch: 6| Step: 4
Training loss: 1.8854362964630127
Validation loss: 2.042154312133789

Epoch: 6| Step: 5
Training loss: 2.609290599822998
Validation loss: 2.033814529577891

Epoch: 6| Step: 6
Training loss: 2.2325406074523926
Validation loss: 2.023041625817617

Epoch: 6| Step: 7
Training loss: 2.2148571014404297
Validation loss: 2.016278306643168

Epoch: 6| Step: 8
Training loss: 1.8391586542129517
Validation loss: 2.0184879899024963

Epoch: 6| Step: 9
Training loss: 1.6047885417938232
Validation loss: 2.0320598085721335

Epoch: 6| Step: 10
Training loss: 1.7440178394317627
Validation loss: 2.044796625773112

Epoch: 6| Step: 11
Training loss: 2.359447479248047
Validation loss: 2.063214063644409

Epoch: 6| Step: 12
Training loss: 2.724393367767334
Validation loss: 2.075696647167206

Epoch: 6| Step: 13
Training loss: 2.5611729621887207
Validation loss: 2.0889899333318076

Epoch: 77| Step: 0
Training loss: 1.3562160730361938
Validation loss: 2.084906895955404

Epoch: 6| Step: 1
Training loss: 2.149742364883423
Validation loss: 2.1016161839167276

Epoch: 6| Step: 2
Training loss: 1.988349437713623
Validation loss: 2.0956453680992126

Epoch: 6| Step: 3
Training loss: 1.7656605243682861
Validation loss: 2.0679020086924234

Epoch: 6| Step: 4
Training loss: 2.4147157669067383
Validation loss: 2.0526670018831887

Epoch: 6| Step: 5
Training loss: 2.507323741912842
Validation loss: 2.0264145334561667

Epoch: 6| Step: 6
Training loss: 2.519167900085449
Validation loss: 2.0260573029518127

Epoch: 6| Step: 7
Training loss: 2.0899181365966797
Validation loss: 2.018207937479019

Epoch: 6| Step: 8
Training loss: 2.328555107116699
Validation loss: 2.0159784952799478

Epoch: 6| Step: 9
Training loss: 2.1906802654266357
Validation loss: 2.0277021328608194

Epoch: 6| Step: 10
Training loss: 2.179318904876709
Validation loss: 2.027467687924703

Epoch: 6| Step: 11
Training loss: 2.479285717010498
Validation loss: 2.031908094882965

Epoch: 6| Step: 12
Training loss: 2.1456727981567383
Validation loss: 2.0406941970189414

Epoch: 6| Step: 13
Training loss: 2.2000699043273926
Validation loss: 2.034837305545807

Epoch: 78| Step: 0
Training loss: 2.655489206314087
Validation loss: 2.034228801727295

Epoch: 6| Step: 1
Training loss: 2.0286033153533936
Validation loss: 2.0348567167917886

Epoch: 6| Step: 2
Training loss: 2.1267178058624268
Validation loss: 2.032306353251139

Epoch: 6| Step: 3
Training loss: 2.234070301055908
Validation loss: 2.0286722580591836

Epoch: 6| Step: 4
Training loss: 2.1418213844299316
Validation loss: 2.027327080567678

Epoch: 6| Step: 5
Training loss: 2.700515031814575
Validation loss: 2.0177378257115683

Epoch: 6| Step: 6
Training loss: 1.7645663022994995
Validation loss: 2.0255468090375266

Epoch: 6| Step: 7
Training loss: 2.4596424102783203
Validation loss: 2.020492653052012

Epoch: 6| Step: 8
Training loss: 1.6802866458892822
Validation loss: 2.0129618446032205

Epoch: 6| Step: 9
Training loss: 2.226391315460205
Validation loss: 2.016628384590149

Epoch: 6| Step: 10
Training loss: 2.0927751064300537
Validation loss: 2.031920154889425

Epoch: 6| Step: 11
Training loss: 2.105142593383789
Validation loss: 2.0317469239234924

Epoch: 6| Step: 12
Training loss: 2.259860038757324
Validation loss: 2.0469791491826377

Epoch: 6| Step: 13
Training loss: 2.194493532180786
Validation loss: 2.0574338833491006

Epoch: 79| Step: 0
Training loss: 1.818331241607666
Validation loss: 2.0597778956095376

Epoch: 6| Step: 1
Training loss: 2.073917865753174
Validation loss: 2.064638535181681

Epoch: 6| Step: 2
Training loss: 2.0226306915283203
Validation loss: 2.0649739503860474

Epoch: 6| Step: 3
Training loss: 2.669327974319458
Validation loss: 2.0521369775136313

Epoch: 6| Step: 4
Training loss: 2.4280035495758057
Validation loss: 2.056784689426422

Epoch: 6| Step: 5
Training loss: 1.9433653354644775
Validation loss: 2.043732444445292

Epoch: 6| Step: 6
Training loss: 2.3679139614105225
Validation loss: 2.042584995428721

Epoch: 6| Step: 7
Training loss: 1.800628900527954
Validation loss: 2.05062468846639

Epoch: 6| Step: 8
Training loss: 2.0976576805114746
Validation loss: 2.0311642487843833

Epoch: 6| Step: 9
Training loss: 2.3180394172668457
Validation loss: 2.0269437034924827

Epoch: 6| Step: 10
Training loss: 1.8565311431884766
Validation loss: 2.0264420906702676

Epoch: 6| Step: 11
Training loss: 2.3399159908294678
Validation loss: 2.0248391230901084

Epoch: 6| Step: 12
Training loss: 2.2491936683654785
Validation loss: 2.0170151591300964

Epoch: 6| Step: 13
Training loss: 2.1496660709381104
Validation loss: 2.024578998486201

Epoch: 80| Step: 0
Training loss: 1.8086755275726318
Validation loss: 2.0236671566963196

Epoch: 6| Step: 1
Training loss: 1.9407622814178467
Validation loss: 2.0274473826090493

Epoch: 6| Step: 2
Training loss: 2.32275128364563
Validation loss: 2.0241830547650657

Epoch: 6| Step: 3
Training loss: 2.8471083641052246
Validation loss: 2.025413393974304

Epoch: 6| Step: 4
Training loss: 2.2613983154296875
Validation loss: 2.021823982397715

Epoch: 6| Step: 5
Training loss: 1.468186616897583
Validation loss: 2.020947357018789

Epoch: 6| Step: 6
Training loss: 1.9554738998413086
Validation loss: 2.021481474240621

Epoch: 6| Step: 7
Training loss: 1.8508827686309814
Validation loss: 2.0264777143796286

Epoch: 6| Step: 8
Training loss: 2.6356382369995117
Validation loss: 2.0264710982640586

Epoch: 6| Step: 9
Training loss: 2.0367629528045654
Validation loss: 2.0270497798919678

Epoch: 6| Step: 10
Training loss: 2.467623710632324
Validation loss: 2.0331539511680603

Epoch: 6| Step: 11
Training loss: 2.134629249572754
Validation loss: 2.039966265360514

Epoch: 6| Step: 12
Training loss: 1.9137625694274902
Validation loss: 2.0452430844306946

Epoch: 6| Step: 13
Training loss: 2.4889516830444336
Validation loss: 2.0652325550715127

Epoch: 81| Step: 0
Training loss: 2.2041244506835938
Validation loss: 2.062184433142344

Epoch: 6| Step: 1
Training loss: 2.040365695953369
Validation loss: 2.0587347547213235

Epoch: 6| Step: 2
Training loss: 2.7664291858673096
Validation loss: 2.058464845021566

Epoch: 6| Step: 3
Training loss: 1.9383811950683594
Validation loss: 2.0692771474520364

Epoch: 6| Step: 4
Training loss: 2.053417444229126
Validation loss: 2.053001046180725

Epoch: 6| Step: 5
Training loss: 2.016265630722046
Validation loss: 2.049865404764811

Epoch: 6| Step: 6
Training loss: 2.390164375305176
Validation loss: 2.0453220208485923

Epoch: 6| Step: 7
Training loss: 2.0238914489746094
Validation loss: 2.0499041279157004

Epoch: 6| Step: 8
Training loss: 2.005262851715088
Validation loss: 2.0374868512153625

Epoch: 6| Step: 9
Training loss: 1.946466326713562
Validation loss: 2.0293507973353067

Epoch: 6| Step: 10
Training loss: 2.0625061988830566
Validation loss: 2.035298307736715

Epoch: 6| Step: 11
Training loss: 2.782402515411377
Validation loss: 2.0277086098988852

Epoch: 6| Step: 12
Training loss: 2.1026666164398193
Validation loss: 2.032193601131439

Epoch: 6| Step: 13
Training loss: 1.7750604152679443
Validation loss: 2.0209022959073386

Epoch: 82| Step: 0
Training loss: 2.876620054244995
Validation loss: 2.0292454759279885

Epoch: 6| Step: 1
Training loss: 1.9441872835159302
Validation loss: 2.030577520529429

Epoch: 6| Step: 2
Training loss: 2.639650344848633
Validation loss: 2.031940758228302

Epoch: 6| Step: 3
Training loss: 1.8731025457382202
Validation loss: 2.0376757383346558

Epoch: 6| Step: 4
Training loss: 2.1382622718811035
Validation loss: 2.0441614786783853

Epoch: 6| Step: 5
Training loss: 1.4572384357452393
Validation loss: 2.04587984085083

Epoch: 6| Step: 6
Training loss: 2.243102788925171
Validation loss: 2.038792093594869

Epoch: 6| Step: 7
Training loss: 2.3303818702697754
Validation loss: 2.042113482952118

Epoch: 6| Step: 8
Training loss: 2.145448684692383
Validation loss: 2.054061472415924

Epoch: 6| Step: 9
Training loss: 1.9558477401733398
Validation loss: 2.054347197214762

Epoch: 6| Step: 10
Training loss: 2.6480231285095215
Validation loss: 2.0588061213493347

Epoch: 6| Step: 11
Training loss: 1.7178142070770264
Validation loss: 2.0409085154533386

Epoch: 6| Step: 12
Training loss: 2.008976936340332
Validation loss: 2.0352413058280945

Epoch: 6| Step: 13
Training loss: 2.126082420349121
Validation loss: 2.0234617590904236

Epoch: 83| Step: 0
Training loss: 2.4495909214019775
Validation loss: 2.0220681031545005

Epoch: 6| Step: 1
Training loss: 2.0852463245391846
Validation loss: 2.0237741271654763

Epoch: 6| Step: 2
Training loss: 1.816368818283081
Validation loss: 2.0139315724372864

Epoch: 6| Step: 3
Training loss: 2.421515941619873
Validation loss: 2.0188215374946594

Epoch: 6| Step: 4
Training loss: 2.5610008239746094
Validation loss: 2.0315000216166177

Epoch: 6| Step: 5
Training loss: 2.7385172843933105
Validation loss: 2.024650832017263

Epoch: 6| Step: 6
Training loss: 2.491259813308716
Validation loss: 2.028477430343628

Epoch: 6| Step: 7
Training loss: 1.884939193725586
Validation loss: 2.027821739514669

Epoch: 6| Step: 8
Training loss: 2.290945529937744
Validation loss: 2.0230011145273843

Epoch: 6| Step: 9
Training loss: 2.1932787895202637
Validation loss: 2.018685062726339

Epoch: 6| Step: 10
Training loss: 1.7959636449813843
Validation loss: 2.023879130681356

Epoch: 6| Step: 11
Training loss: 1.6880437135696411
Validation loss: 2.024586856365204

Epoch: 6| Step: 12
Training loss: 1.8181363344192505
Validation loss: 2.0197365283966064

Epoch: 6| Step: 13
Training loss: 2.1251864433288574
Validation loss: 2.0260987480481467

Epoch: 84| Step: 0
Training loss: 1.8342490196228027
Validation loss: 2.0222667256991067

Epoch: 6| Step: 1
Training loss: 1.9355528354644775
Validation loss: 2.0166844924290976

Epoch: 6| Step: 2
Training loss: 1.6761493682861328
Validation loss: 2.0130377411842346

Epoch: 6| Step: 3
Training loss: 1.8193469047546387
Validation loss: 2.020067512989044

Epoch: 6| Step: 4
Training loss: 2.3292465209960938
Validation loss: 2.021164337793986

Epoch: 6| Step: 5
Training loss: 2.418398857116699
Validation loss: 2.0311911702156067

Epoch: 6| Step: 6
Training loss: 2.240422248840332
Validation loss: 2.0260451833407083

Epoch: 6| Step: 7
Training loss: 2.357689380645752
Validation loss: 2.0176740288734436

Epoch: 6| Step: 8
Training loss: 1.7836661338806152
Validation loss: 2.022082487742106

Epoch: 6| Step: 9
Training loss: 2.6264333724975586
Validation loss: 2.016770521799723

Epoch: 6| Step: 10
Training loss: 2.0097157955169678
Validation loss: 2.022175053755442

Epoch: 6| Step: 11
Training loss: 3.2922325134277344
Validation loss: 2.0243470668792725

Epoch: 6| Step: 12
Training loss: 1.818464756011963
Validation loss: 2.028236150741577

Epoch: 6| Step: 13
Training loss: 1.9630074501037598
Validation loss: 2.0248316725095115

Epoch: 85| Step: 0
Training loss: 2.753209114074707
Validation loss: 2.0268201430638633

Epoch: 6| Step: 1
Training loss: 2.1254870891571045
Validation loss: 2.0342827439308167

Epoch: 6| Step: 2
Training loss: 2.4729671478271484
Validation loss: 2.0257535775502524

Epoch: 6| Step: 3
Training loss: 1.7231605052947998
Validation loss: 2.0249845385551453

Epoch: 6| Step: 4
Training loss: 1.7421292066574097
Validation loss: 2.021468142668406

Epoch: 6| Step: 5
Training loss: 2.37583065032959
Validation loss: 2.0220890839894614

Epoch: 6| Step: 6
Training loss: 2.1062357425689697
Validation loss: 2.0222649574279785

Epoch: 6| Step: 7
Training loss: 2.5858840942382812
Validation loss: 2.024221400419871

Epoch: 6| Step: 8
Training loss: 1.6086795330047607
Validation loss: 2.0297962625821433

Epoch: 6| Step: 9
Training loss: 1.374127984046936
Validation loss: 2.0273974339167276

Epoch: 6| Step: 10
Training loss: 2.5180552005767822
Validation loss: 2.043613870938619

Epoch: 6| Step: 11
Training loss: 2.063413143157959
Validation loss: 2.0506192247072854

Epoch: 6| Step: 12
Training loss: 2.382913589477539
Validation loss: 2.0453965067863464

Epoch: 6| Step: 13
Training loss: 2.1528568267822266
Validation loss: 2.0532713333765664

Epoch: 86| Step: 0
Training loss: 2.249884605407715
Validation loss: 2.049034277598063

Epoch: 6| Step: 1
Training loss: 2.0487663745880127
Validation loss: 2.0475971698760986

Epoch: 6| Step: 2
Training loss: 1.461289644241333
Validation loss: 2.0663066705067954

Epoch: 6| Step: 3
Training loss: 2.124643564224243
Validation loss: 2.0608550906181335

Epoch: 6| Step: 4
Training loss: 2.5852620601654053
Validation loss: 2.0795087019602456

Epoch: 6| Step: 5
Training loss: 2.507981538772583
Validation loss: 2.069906791051229

Epoch: 6| Step: 6
Training loss: 1.9003138542175293
Validation loss: 2.090570350488027

Epoch: 6| Step: 7
Training loss: 2.452136754989624
Validation loss: 2.0678038597106934

Epoch: 6| Step: 8
Training loss: 2.020038604736328
Validation loss: 2.0474040309588113

Epoch: 6| Step: 9
Training loss: 1.961540699005127
Validation loss: 2.0335341095924377

Epoch: 6| Step: 10
Training loss: 2.20297908782959
Validation loss: 2.0310028791427612

Epoch: 6| Step: 11
Training loss: 1.9985613822937012
Validation loss: 2.0211431980133057

Epoch: 6| Step: 12
Training loss: 2.578355312347412
Validation loss: 2.0284288922945657

Epoch: 6| Step: 13
Training loss: 2.169203281402588
Validation loss: 2.028316299120585

Epoch: 87| Step: 0
Training loss: 1.9538606405258179
Validation loss: 2.0312422712643943

Epoch: 6| Step: 1
Training loss: 2.0805888175964355
Validation loss: 2.0164175033569336

Epoch: 6| Step: 2
Training loss: 2.294731616973877
Validation loss: 2.021969497203827

Epoch: 6| Step: 3
Training loss: 2.256105422973633
Validation loss: 2.0319143732388816

Epoch: 6| Step: 4
Training loss: 3.0681304931640625
Validation loss: 2.0388667384783425

Epoch: 6| Step: 5
Training loss: 2.1603760719299316
Validation loss: 2.0432778000831604

Epoch: 6| Step: 6
Training loss: 2.4701929092407227
Validation loss: 2.0522354443868003

Epoch: 6| Step: 7
Training loss: 2.4413061141967773
Validation loss: 2.060012102127075

Epoch: 6| Step: 8
Training loss: 2.043221950531006
Validation loss: 2.0718376636505127

Epoch: 6| Step: 9
Training loss: 2.249703884124756
Validation loss: 2.0715017318725586

Epoch: 6| Step: 10
Training loss: 2.2325048446655273
Validation loss: 2.064629395802816

Epoch: 6| Step: 11
Training loss: 1.7809202671051025
Validation loss: 2.052635073661804

Epoch: 6| Step: 12
Training loss: 1.767482042312622
Validation loss: 2.050067663192749

Epoch: 6| Step: 13
Training loss: 1.5531835556030273
Validation loss: 2.0350054701169333

Epoch: 88| Step: 0
Training loss: 2.540271043777466
Validation loss: 2.027189393838247

Epoch: 6| Step: 1
Training loss: 2.32338809967041
Validation loss: 2.013024469216665

Epoch: 6| Step: 2
Training loss: 1.997507929801941
Validation loss: 2.009435534477234

Epoch: 6| Step: 3
Training loss: 2.2795071601867676
Validation loss: 2.001347064971924

Epoch: 6| Step: 4
Training loss: 1.9016605615615845
Validation loss: 2.005651036898295

Epoch: 6| Step: 5
Training loss: 2.2398111820220947
Validation loss: 2.006641149520874

Epoch: 6| Step: 6
Training loss: 2.5819263458251953
Validation loss: 2.005283991495768

Epoch: 6| Step: 7
Training loss: 2.7872302532196045
Validation loss: 2.004837393760681

Epoch: 6| Step: 8
Training loss: 2.0234451293945312
Validation loss: 2.0078017711639404

Epoch: 6| Step: 9
Training loss: 2.3175415992736816
Validation loss: 2.007409413655599

Epoch: 6| Step: 10
Training loss: 1.6093580722808838
Validation loss: 2.001551647981008

Epoch: 6| Step: 11
Training loss: 2.066288471221924
Validation loss: 1.9992020726203918

Epoch: 6| Step: 12
Training loss: 2.0225071907043457
Validation loss: 1.9964982867240906

Epoch: 6| Step: 13
Training loss: 1.7253237962722778
Validation loss: 2.005290905634562

Epoch: 89| Step: 0
Training loss: 2.0369973182678223
Validation loss: 1.9999786019325256

Epoch: 6| Step: 1
Training loss: 1.8904049396514893
Validation loss: 2.001112381617228

Epoch: 6| Step: 2
Training loss: 1.462673306465149
Validation loss: 2.0061917901039124

Epoch: 6| Step: 3
Training loss: 2.329195022583008
Validation loss: 2.012740691502889

Epoch: 6| Step: 4
Training loss: 2.022480010986328
Validation loss: 2.02068559328715

Epoch: 6| Step: 5
Training loss: 1.9213823080062866
Validation loss: 2.0188939372698465

Epoch: 6| Step: 6
Training loss: 1.6321742534637451
Validation loss: 2.034250537554423

Epoch: 6| Step: 7
Training loss: 2.568012237548828
Validation loss: 2.04461137453715

Epoch: 6| Step: 8
Training loss: 1.973197340965271
Validation loss: 2.0447988311449685

Epoch: 6| Step: 9
Training loss: 1.9851971864700317
Validation loss: 2.0424453020095825

Epoch: 6| Step: 10
Training loss: 3.3533544540405273
Validation loss: 2.0529093543688455

Epoch: 6| Step: 11
Training loss: 2.68729567527771
Validation loss: 2.03872678677241

Epoch: 6| Step: 12
Training loss: 1.7130542993545532
Validation loss: 2.03928150733312

Epoch: 6| Step: 13
Training loss: 2.584657669067383
Validation loss: 2.0387845436731973

Epoch: 90| Step: 0
Training loss: 2.454226016998291
Validation loss: 2.0206772287686667

Epoch: 6| Step: 1
Training loss: 2.0070948600769043
Validation loss: 2.032319664955139

Epoch: 6| Step: 2
Training loss: 1.5487147569656372
Validation loss: 2.0300541321436563

Epoch: 6| Step: 3
Training loss: 2.169447422027588
Validation loss: 2.0209573109944663

Epoch: 6| Step: 4
Training loss: 1.617525339126587
Validation loss: 2.031758884588877

Epoch: 6| Step: 5
Training loss: 2.2160277366638184
Validation loss: 2.0237706700960794

Epoch: 6| Step: 6
Training loss: 2.5538487434387207
Validation loss: 2.028657694657644

Epoch: 6| Step: 7
Training loss: 1.6271090507507324
Validation loss: 2.0215449730555215

Epoch: 6| Step: 8
Training loss: 2.112234592437744
Validation loss: 2.024699608484904

Epoch: 6| Step: 9
Training loss: 2.358797788619995
Validation loss: 2.0270944436391196

Epoch: 6| Step: 10
Training loss: 2.475985527038574
Validation loss: 2.029461224873861

Epoch: 6| Step: 11
Training loss: 2.294287919998169
Validation loss: 2.028140425682068

Epoch: 6| Step: 12
Training loss: 2.6012275218963623
Validation loss: 2.035767992337545

Epoch: 6| Step: 13
Training loss: 2.067868232727051
Validation loss: 2.0304741064707437

Epoch: 91| Step: 0
Training loss: 2.1602373123168945
Validation loss: 2.0265063047409058

Epoch: 6| Step: 1
Training loss: 2.2852821350097656
Validation loss: 2.0267959237098694

Epoch: 6| Step: 2
Training loss: 2.1353044509887695
Validation loss: 2.025260945161184

Epoch: 6| Step: 3
Training loss: 2.089491128921509
Validation loss: 2.0167425672213235

Epoch: 6| Step: 4
Training loss: 1.550864338874817
Validation loss: 2.0200077096621194

Epoch: 6| Step: 5
Training loss: 1.8651468753814697
Validation loss: 2.0103506843249

Epoch: 6| Step: 6
Training loss: 2.3742408752441406
Validation loss: 2.0102981328964233

Epoch: 6| Step: 7
Training loss: 2.5929980278015137
Validation loss: 2.014230569203695

Epoch: 6| Step: 8
Training loss: 1.9448591470718384
Validation loss: 2.0118285616238913

Epoch: 6| Step: 9
Training loss: 2.571842908859253
Validation loss: 2.0126708348592124

Epoch: 6| Step: 10
Training loss: 1.8222341537475586
Validation loss: 2.0220545331637063

Epoch: 6| Step: 11
Training loss: 2.2232017517089844
Validation loss: 2.0162846048672995

Epoch: 6| Step: 12
Training loss: 2.7678394317626953
Validation loss: 2.020407418409983

Epoch: 6| Step: 13
Training loss: 1.592181921005249
Validation loss: 2.0159127513567605

Epoch: 92| Step: 0
Training loss: 1.6956987380981445
Validation loss: 2.017167250315348

Epoch: 6| Step: 1
Training loss: 1.716956377029419
Validation loss: 2.019401470820109

Epoch: 6| Step: 2
Training loss: 2.5743751525878906
Validation loss: 2.030499438444773

Epoch: 6| Step: 3
Training loss: 2.1925296783447266
Validation loss: 2.0332165360450745

Epoch: 6| Step: 4
Training loss: 2.570293426513672
Validation loss: 2.040556530157725

Epoch: 6| Step: 5
Training loss: 2.3647685050964355
Validation loss: 2.0378641486167908

Epoch: 6| Step: 6
Training loss: 2.4595608711242676
Validation loss: 2.052422126134237

Epoch: 6| Step: 7
Training loss: 2.1690096855163574
Validation loss: 2.046227673689524

Epoch: 6| Step: 8
Training loss: 1.8998264074325562
Validation loss: 2.052234729131063

Epoch: 6| Step: 9
Training loss: 2.5602149963378906
Validation loss: 2.0553085803985596

Epoch: 6| Step: 10
Training loss: 1.5397834777832031
Validation loss: 2.059906224409739

Epoch: 6| Step: 11
Training loss: 2.4689462184906006
Validation loss: 2.055845618247986

Epoch: 6| Step: 12
Training loss: 1.6634085178375244
Validation loss: 2.0458820859591165

Epoch: 6| Step: 13
Training loss: 2.0993428230285645
Validation loss: 2.036750853061676

Epoch: 93| Step: 0
Training loss: 2.872873544692993
Validation loss: 2.038268764813741

Epoch: 6| Step: 1
Training loss: 1.994702696800232
Validation loss: 2.0259775718053183

Epoch: 6| Step: 2
Training loss: 2.4093825817108154
Validation loss: 2.0208574732144675

Epoch: 6| Step: 3
Training loss: 1.8049728870391846
Validation loss: 2.0178760488828025

Epoch: 6| Step: 4
Training loss: 2.174612283706665
Validation loss: 2.021365205446879

Epoch: 6| Step: 5
Training loss: 2.4888410568237305
Validation loss: 2.0261868834495544

Epoch: 6| Step: 6
Training loss: 2.30610990524292
Validation loss: 2.0253976782162986

Epoch: 6| Step: 7
Training loss: 1.8605024814605713
Validation loss: 2.017153342564901

Epoch: 6| Step: 8
Training loss: 1.438308835029602
Validation loss: 2.022237479686737

Epoch: 6| Step: 9
Training loss: 2.050586462020874
Validation loss: 2.0286705692609153

Epoch: 6| Step: 10
Training loss: 2.2296876907348633
Validation loss: 2.028828044732412

Epoch: 6| Step: 11
Training loss: 1.6270067691802979
Validation loss: 2.024395525455475

Epoch: 6| Step: 12
Training loss: 2.1184029579162598
Validation loss: 2.0232495864232383

Epoch: 6| Step: 13
Training loss: 2.504213809967041
Validation loss: 2.025216042995453

Epoch: 94| Step: 0
Training loss: 1.9587273597717285
Validation loss: 2.019145210584005

Epoch: 6| Step: 1
Training loss: 2.024954080581665
Validation loss: 2.0182228088378906

Epoch: 6| Step: 2
Training loss: 2.236114025115967
Validation loss: 2.0324754317601523

Epoch: 6| Step: 3
Training loss: 1.973034143447876
Validation loss: 2.0328249335289

Epoch: 6| Step: 4
Training loss: 2.428297519683838
Validation loss: 2.0330181320508323

Epoch: 6| Step: 5
Training loss: 2.220604181289673
Validation loss: 2.0290578603744507

Epoch: 6| Step: 6
Training loss: 1.4715180397033691
Validation loss: 2.0368396838506064

Epoch: 6| Step: 7
Training loss: 2.4305779933929443
Validation loss: 2.032589316368103

Epoch: 6| Step: 8
Training loss: 2.1206326484680176
Validation loss: 2.043738921483358

Epoch: 6| Step: 9
Training loss: 2.514510154724121
Validation loss: 2.048279802004496

Epoch: 6| Step: 10
Training loss: 1.758100152015686
Validation loss: 2.0502928296724954

Epoch: 6| Step: 11
Training loss: 1.93453049659729
Validation loss: 2.042394995689392

Epoch: 6| Step: 12
Training loss: 2.4005239009857178
Validation loss: 2.05156417687734

Epoch: 6| Step: 13
Training loss: 2.31717586517334
Validation loss: 2.0526732405026755

Epoch: 95| Step: 0
Training loss: 1.8011078834533691
Validation loss: 2.0590724547704062

Epoch: 6| Step: 1
Training loss: 1.7700613737106323
Validation loss: 2.0446432630221048

Epoch: 6| Step: 2
Training loss: 1.873556137084961
Validation loss: 2.0563237269719443

Epoch: 6| Step: 3
Training loss: 2.5153563022613525
Validation loss: 2.0598713159561157

Epoch: 6| Step: 4
Training loss: 2.113628387451172
Validation loss: 2.062576870123545

Epoch: 6| Step: 5
Training loss: 2.122872829437256
Validation loss: 2.0553415218989053

Epoch: 6| Step: 6
Training loss: 2.3830196857452393
Validation loss: 2.0492968956629434

Epoch: 6| Step: 7
Training loss: 2.202388048171997
Validation loss: 2.0457980632781982

Epoch: 6| Step: 8
Training loss: 2.51081919670105
Validation loss: 2.044805924097697

Epoch: 6| Step: 9
Training loss: 2.811408519744873
Validation loss: 2.0292596419652305

Epoch: 6| Step: 10
Training loss: 2.2136616706848145
Validation loss: 2.0226869185765586

Epoch: 6| Step: 11
Training loss: 2.5866003036499023
Validation loss: 2.0294240911801658

Epoch: 6| Step: 12
Training loss: 1.4908593893051147
Validation loss: 2.0192182262738547

Epoch: 6| Step: 13
Training loss: 1.5578598976135254
Validation loss: 2.0238415598869324

Epoch: 96| Step: 0
Training loss: 1.9402748346328735
Validation loss: 2.032668093840281

Epoch: 6| Step: 1
Training loss: 2.620919942855835
Validation loss: 2.0325789054234824

Epoch: 6| Step: 2
Training loss: 1.9909707307815552
Validation loss: 2.036087234814962

Epoch: 6| Step: 3
Training loss: 2.7298147678375244
Validation loss: 2.0225298603375754

Epoch: 6| Step: 4
Training loss: 2.285304546356201
Validation loss: 2.034227669239044

Epoch: 6| Step: 5
Training loss: 1.9973846673965454
Validation loss: 2.0405975580215454

Epoch: 6| Step: 6
Training loss: 1.9596980810165405
Validation loss: 2.0315118432044983

Epoch: 6| Step: 7
Training loss: 1.905601978302002
Validation loss: 2.0318085749944053

Epoch: 6| Step: 8
Training loss: 2.387478828430176
Validation loss: 2.021954675515493

Epoch: 6| Step: 9
Training loss: 1.9657318592071533
Validation loss: 2.020539144674937

Epoch: 6| Step: 10
Training loss: 2.180485486984253
Validation loss: 2.011998414993286

Epoch: 6| Step: 11
Training loss: 1.8099572658538818
Validation loss: 2.0049766898155212

Epoch: 6| Step: 12
Training loss: 2.0481300354003906
Validation loss: 2.0049137671788535

Epoch: 6| Step: 13
Training loss: 2.4667069911956787
Validation loss: 2.010712126890818

Epoch: 97| Step: 0
Training loss: 1.8460122346878052
Validation loss: 2.01905224720637

Epoch: 6| Step: 1
Training loss: 1.2558470964431763
Validation loss: 2.024521807829539

Epoch: 6| Step: 2
Training loss: 2.4435954093933105
Validation loss: 2.033195118109385

Epoch: 6| Step: 3
Training loss: 2.3712375164031982
Validation loss: 2.046067555745443

Epoch: 6| Step: 4
Training loss: 2.5348610877990723
Validation loss: 2.039463222026825

Epoch: 6| Step: 5
Training loss: 2.594423770904541
Validation loss: 2.03924560546875

Epoch: 6| Step: 6
Training loss: 1.4821429252624512
Validation loss: 2.0305320819218955

Epoch: 6| Step: 7
Training loss: 2.7619214057922363
Validation loss: 2.0305392940839133

Epoch: 6| Step: 8
Training loss: 2.4327781200408936
Validation loss: 2.017416775226593

Epoch: 6| Step: 9
Training loss: 1.682460069656372
Validation loss: 2.0215845704078674

Epoch: 6| Step: 10
Training loss: 2.393435001373291
Validation loss: 2.017735322316488

Epoch: 6| Step: 11
Training loss: 2.169861316680908
Validation loss: 2.0098838011423745

Epoch: 6| Step: 12
Training loss: 1.7541189193725586
Validation loss: 2.011524041493734

Epoch: 6| Step: 13
Training loss: 2.237142562866211
Validation loss: 2.0062357981999717

Epoch: 98| Step: 0
Training loss: 2.247865676879883
Validation loss: 2.007583657900492

Epoch: 6| Step: 1
Training loss: 1.776107907295227
Validation loss: 2.0142216285069785

Epoch: 6| Step: 2
Training loss: 1.487645149230957
Validation loss: 2.035965899626414

Epoch: 6| Step: 3
Training loss: 1.725144624710083
Validation loss: 2.0209721326828003

Epoch: 6| Step: 4
Training loss: 2.5880990028381348
Validation loss: 2.043914477030436

Epoch: 6| Step: 5
Training loss: 2.2036781311035156
Validation loss: 2.0481539765993753

Epoch: 6| Step: 6
Training loss: 1.8542718887329102
Validation loss: 2.055560211340586

Epoch: 6| Step: 7
Training loss: 2.0779073238372803
Validation loss: 2.062341550985972

Epoch: 6| Step: 8
Training loss: 1.761056900024414
Validation loss: 2.0730154116948447

Epoch: 6| Step: 9
Training loss: 1.925523281097412
Validation loss: 2.0719769398371377

Epoch: 6| Step: 10
Training loss: 2.6231019496917725
Validation loss: 2.0778401096661887

Epoch: 6| Step: 11
Training loss: 2.213665008544922
Validation loss: 2.060658613840739

Epoch: 6| Step: 12
Training loss: 2.2444303035736084
Validation loss: 2.0629480282465615

Epoch: 6| Step: 13
Training loss: 3.0188019275665283
Validation loss: 2.0493535796801248

Epoch: 99| Step: 0
Training loss: 2.17132568359375
Validation loss: 2.0367328921953836

Epoch: 6| Step: 1
Training loss: 2.5474860668182373
Validation loss: 2.032690684000651

Epoch: 6| Step: 2
Training loss: 2.3542160987854004
Validation loss: 2.0310856103897095

Epoch: 6| Step: 3
Training loss: 2.513136625289917
Validation loss: 2.0332219004631042

Epoch: 6| Step: 4
Training loss: 1.8952771425247192
Validation loss: 2.0296539465586343

Epoch: 6| Step: 5
Training loss: 2.198723316192627
Validation loss: 2.037824352582296

Epoch: 6| Step: 6
Training loss: 1.3607568740844727
Validation loss: 2.0420142809549966

Epoch: 6| Step: 7
Training loss: 2.4015402793884277
Validation loss: 2.039299805959066

Epoch: 6| Step: 8
Training loss: 1.7090976238250732
Validation loss: 2.0427304108937583

Epoch: 6| Step: 9
Training loss: 2.603260040283203
Validation loss: 2.038071036338806

Epoch: 6| Step: 10
Training loss: 2.146839141845703
Validation loss: 2.031495749950409

Epoch: 6| Step: 11
Training loss: 1.9565715789794922
Validation loss: 2.0317825078964233

Epoch: 6| Step: 12
Training loss: 2.455655097961426
Validation loss: 2.0346201062202454

Epoch: 6| Step: 13
Training loss: 1.9803400039672852
Validation loss: 2.030461291472117

Epoch: 100| Step: 0
Training loss: 2.0946402549743652
Validation loss: 2.0357678135236106

Epoch: 6| Step: 1
Training loss: 2.5133843421936035
Validation loss: 2.0344632863998413

Epoch: 6| Step: 2
Training loss: 2.829498767852783
Validation loss: 2.021738807360331

Epoch: 6| Step: 3
Training loss: 1.8522447347640991
Validation loss: 2.01313046614329

Epoch: 6| Step: 4
Training loss: 2.175731897354126
Validation loss: 2.0156250993410745

Epoch: 6| Step: 5
Training loss: 1.78706693649292
Validation loss: 2.012831528981527

Epoch: 6| Step: 6
Training loss: 2.2426180839538574
Validation loss: 2.0126387079556785

Epoch: 6| Step: 7
Training loss: 2.0542311668395996
Validation loss: 2.013262689113617

Epoch: 6| Step: 8
Training loss: 2.1196489334106445
Validation loss: 2.0037477215131125

Epoch: 6| Step: 9
Training loss: 1.483142614364624
Validation loss: 2.006858249505361

Epoch: 6| Step: 10
Training loss: 2.1718201637268066
Validation loss: 2.007951080799103

Epoch: 6| Step: 11
Training loss: 2.4337282180786133
Validation loss: 2.007516026496887

Epoch: 6| Step: 12
Training loss: 2.185439348220825
Validation loss: 2.0159538785616555

Epoch: 6| Step: 13
Training loss: 2.2250726222991943
Validation loss: 2.0131128629048667

Epoch: 101| Step: 0
Training loss: 1.8854848146438599
Validation loss: 2.0260342955589294

Epoch: 6| Step: 1
Training loss: 1.7323355674743652
Validation loss: 2.032380779584249

Epoch: 6| Step: 2
Training loss: 1.899820327758789
Validation loss: 2.0330233772595725

Epoch: 6| Step: 3
Training loss: 2.4304118156433105
Validation loss: 2.0456849932670593

Epoch: 6| Step: 4
Training loss: 2.648930311203003
Validation loss: 2.059032698472341

Epoch: 6| Step: 5
Training loss: 2.862247943878174
Validation loss: 2.059839129447937

Epoch: 6| Step: 6
Training loss: 1.8178613185882568
Validation loss: 2.0734995007514954

Epoch: 6| Step: 7
Training loss: 1.9644570350646973
Validation loss: 2.0645318031311035

Epoch: 6| Step: 8
Training loss: 2.993922710418701
Validation loss: 2.067072629928589

Epoch: 6| Step: 9
Training loss: 1.631222128868103
Validation loss: 2.058903435866038

Epoch: 6| Step: 10
Training loss: 2.511293411254883
Validation loss: 2.042381207148234

Epoch: 6| Step: 11
Training loss: 1.1594020128250122
Validation loss: 2.034110347429911

Epoch: 6| Step: 12
Training loss: 2.0811266899108887
Validation loss: 2.02336315313975

Epoch: 6| Step: 13
Training loss: 2.33895206451416
Validation loss: 2.0110252499580383

Epoch: 102| Step: 0
Training loss: 1.5755547285079956
Validation loss: 2.0110365549723306

Epoch: 6| Step: 1
Training loss: 1.8478342294692993
Validation loss: 2.017454147338867

Epoch: 6| Step: 2
Training loss: 1.7793893814086914
Validation loss: 2.01315176486969

Epoch: 6| Step: 3
Training loss: 1.7454578876495361
Validation loss: 2.0141894618670144

Epoch: 6| Step: 4
Training loss: 2.5956459045410156
Validation loss: 2.0141621430714927

Epoch: 6| Step: 5
Training loss: 1.7781857252120972
Validation loss: 2.0136272509892783

Epoch: 6| Step: 6
Training loss: 2.4656176567077637
Validation loss: 2.0232240756352744

Epoch: 6| Step: 7
Training loss: 2.3661324977874756
Validation loss: 2.0313554803530374

Epoch: 6| Step: 8
Training loss: 1.9561774730682373
Validation loss: 2.0372735063234964

Epoch: 6| Step: 9
Training loss: 2.3144850730895996
Validation loss: 2.041277547677358

Epoch: 6| Step: 10
Training loss: 2.726393699645996
Validation loss: 2.039708455403646

Epoch: 6| Step: 11
Training loss: 2.2935714721679688
Validation loss: 2.0383606354395547

Epoch: 6| Step: 12
Training loss: 2.0807673931121826
Validation loss: 2.02408238252004

Epoch: 6| Step: 13
Training loss: 2.357516288757324
Validation loss: 2.01037190357844

Epoch: 103| Step: 0
Training loss: 2.316842555999756
Validation loss: 2.0111536979675293

Epoch: 6| Step: 1
Training loss: 2.4114880561828613
Validation loss: 2.0215941866238913

Epoch: 6| Step: 2
Training loss: 2.473137855529785
Validation loss: 2.025225122769674

Epoch: 6| Step: 3
Training loss: 2.5086379051208496
Validation loss: 2.042473793029785

Epoch: 6| Step: 4
Training loss: 2.8340601921081543
Validation loss: 2.03475558757782

Epoch: 6| Step: 5
Training loss: 2.2007575035095215
Validation loss: 2.0372454126675925

Epoch: 6| Step: 6
Training loss: 2.0209884643554688
Validation loss: 2.0419968565305076

Epoch: 6| Step: 7
Training loss: 1.9108275175094604
Validation loss: 2.040010174115499

Epoch: 6| Step: 8
Training loss: 2.0232465267181396
Validation loss: 2.04098649819692

Epoch: 6| Step: 9
Training loss: 2.1975903511047363
Validation loss: 2.0422105193138123

Epoch: 6| Step: 10
Training loss: 2.0748701095581055
Validation loss: 2.0421085755030313

Epoch: 6| Step: 11
Training loss: 1.451772689819336
Validation loss: 2.040540079275767

Epoch: 6| Step: 12
Training loss: 2.0141401290893555
Validation loss: 2.0412261883417764

Epoch: 6| Step: 13
Training loss: 2.0927720069885254
Validation loss: 2.0215770999590554

Epoch: 104| Step: 0
Training loss: 1.845005989074707
Validation loss: 2.027557293574015

Epoch: 6| Step: 1
Training loss: 1.2804813385009766
Validation loss: 2.0201377272605896

Epoch: 6| Step: 2
Training loss: 2.613455057144165
Validation loss: 2.021101991335551

Epoch: 6| Step: 3
Training loss: 1.9892590045928955
Validation loss: 2.011565903822581

Epoch: 6| Step: 4
Training loss: 2.613320827484131
Validation loss: 2.0103822151819863

Epoch: 6| Step: 5
Training loss: 2.320805549621582
Validation loss: 2.0088271299997964

Epoch: 6| Step: 6
Training loss: 2.3716623783111572
Validation loss: 2.006675918896993

Epoch: 6| Step: 7
Training loss: 2.2079267501831055
Validation loss: 2.0155858596165976

Epoch: 6| Step: 8
Training loss: 2.447368621826172
Validation loss: 2.0241731802622476

Epoch: 6| Step: 9
Training loss: 2.447323799133301
Validation loss: 2.0335382223129272

Epoch: 6| Step: 10
Training loss: 1.2380335330963135
Validation loss: 2.0388243993123374

Epoch: 6| Step: 11
Training loss: 2.563573122024536
Validation loss: 2.042740265528361

Epoch: 6| Step: 12
Training loss: 2.1163330078125
Validation loss: 2.053539216518402

Epoch: 6| Step: 13
Training loss: 1.9240368604660034
Validation loss: 2.0810100038846335

Epoch: 105| Step: 0
Training loss: 2.5236399173736572
Validation loss: 2.0847750902175903

Epoch: 6| Step: 1
Training loss: 1.7380698919296265
Validation loss: 2.0658549666404724

Epoch: 6| Step: 2
Training loss: 1.5162439346313477
Validation loss: 2.054916242758433

Epoch: 6| Step: 3
Training loss: 1.605053424835205
Validation loss: 2.039369304974874

Epoch: 6| Step: 4
Training loss: 2.362705945968628
Validation loss: 2.033716400464376

Epoch: 6| Step: 5
Training loss: 1.9352205991744995
Validation loss: 2.0279205441474915

Epoch: 6| Step: 6
Training loss: 2.710639476776123
Validation loss: 2.019947369893392

Epoch: 6| Step: 7
Training loss: 2.2969589233398438
Validation loss: 2.022708535194397

Epoch: 6| Step: 8
Training loss: 2.4158434867858887
Validation loss: 2.0281806190808616

Epoch: 6| Step: 9
Training loss: 2.1908457279205322
Validation loss: 2.02810808022817

Epoch: 6| Step: 10
Training loss: 2.2692317962646484
Validation loss: 2.033847133318583

Epoch: 6| Step: 11
Training loss: 1.778125524520874
Validation loss: 2.03460031747818

Epoch: 6| Step: 12
Training loss: 2.045085906982422
Validation loss: 2.024787743886312

Epoch: 6| Step: 13
Training loss: 2.7925453186035156
Validation loss: 2.0244843562444053

Epoch: 106| Step: 0
Training loss: 2.288832426071167
Validation loss: 2.0320794781049094

Epoch: 6| Step: 1
Training loss: 2.3866381645202637
Validation loss: 2.030702988306681

Epoch: 6| Step: 2
Training loss: 1.8330678939819336
Validation loss: 2.026544729868571

Epoch: 6| Step: 3
Training loss: 1.878136157989502
Validation loss: 2.026310622692108

Epoch: 6| Step: 4
Training loss: 1.8493493795394897
Validation loss: 2.0193015734354653

Epoch: 6| Step: 5
Training loss: 2.296550989151001
Validation loss: 2.0227559010187783

Epoch: 6| Step: 6
Training loss: 2.82051420211792
Validation loss: 2.0337356527646384

Epoch: 6| Step: 7
Training loss: 2.2537264823913574
Validation loss: 2.033284684022268

Epoch: 6| Step: 8
Training loss: 1.9552665948867798
Validation loss: 2.0417662064234414

Epoch: 6| Step: 9
Training loss: 1.7353790998458862
Validation loss: 2.0583131313323975

Epoch: 6| Step: 10
Training loss: 1.7722041606903076
Validation loss: 2.0629390875498452

Epoch: 6| Step: 11
Training loss: 2.484433174133301
Validation loss: 2.078615208466848

Epoch: 6| Step: 12
Training loss: 2.4204187393188477
Validation loss: 2.0898213982582092

Epoch: 6| Step: 13
Training loss: 1.8559730052947998
Validation loss: 2.1107945839564004

Epoch: 107| Step: 0
Training loss: 2.1865715980529785
Validation loss: 2.1122230092684426

Epoch: 6| Step: 1
Training loss: 1.98739755153656
Validation loss: 2.1315675377845764

Epoch: 6| Step: 2
Training loss: 2.55108642578125
Validation loss: 2.119150757789612

Epoch: 6| Step: 3
Training loss: 2.0731186866760254
Validation loss: 2.084414859612783

Epoch: 6| Step: 4
Training loss: 2.4453835487365723
Validation loss: 2.0748882492383323

Epoch: 6| Step: 5
Training loss: 2.4669694900512695
Validation loss: 2.047565241654714

Epoch: 6| Step: 6
Training loss: 1.550093173980713
Validation loss: 2.036504089832306

Epoch: 6| Step: 7
Training loss: 2.5370891094207764
Validation loss: 2.0204745531082153

Epoch: 6| Step: 8
Training loss: 1.8961877822875977
Validation loss: 2.0196598966916404

Epoch: 6| Step: 9
Training loss: 1.747770071029663
Validation loss: 2.026969770590464

Epoch: 6| Step: 10
Training loss: 2.0516538619995117
Validation loss: 2.0212626258532205

Epoch: 6| Step: 11
Training loss: 1.5226964950561523
Validation loss: 2.024142801761627

Epoch: 6| Step: 12
Training loss: 2.455601692199707
Validation loss: 2.031059682369232

Epoch: 6| Step: 13
Training loss: 2.6037049293518066
Validation loss: 2.0223851998647056

Epoch: 108| Step: 0
Training loss: 1.7875592708587646
Validation loss: 2.025851289431254

Epoch: 6| Step: 1
Training loss: 2.109219551086426
Validation loss: 2.022419035434723

Epoch: 6| Step: 2
Training loss: 2.3460843563079834
Validation loss: 2.0201335350672402

Epoch: 6| Step: 3
Training loss: 1.429896593093872
Validation loss: 2.019372880458832

Epoch: 6| Step: 4
Training loss: 1.7800863981246948
Validation loss: 2.0198245445887246

Epoch: 6| Step: 5
Training loss: 2.339052200317383
Validation loss: 2.0229185024897256

Epoch: 6| Step: 6
Training loss: 2.042942523956299
Validation loss: 2.0297972162564597

Epoch: 6| Step: 7
Training loss: 2.5312588214874268
Validation loss: 2.040678103764852

Epoch: 6| Step: 8
Training loss: 2.5266647338867188
Validation loss: 2.046539008617401

Epoch: 6| Step: 9
Training loss: 1.6458592414855957
Validation loss: 2.054421901702881

Epoch: 6| Step: 10
Training loss: 2.4665000438690186
Validation loss: 2.0460585157076516

Epoch: 6| Step: 11
Training loss: 1.7324886322021484
Validation loss: 2.052699704964956

Epoch: 6| Step: 12
Training loss: 2.321834087371826
Validation loss: 2.0693955421447754

Epoch: 6| Step: 13
Training loss: 2.8266189098358154
Validation loss: 2.0664368073145547

Epoch: 109| Step: 0
Training loss: 2.4379868507385254
Validation loss: 2.0562692085901895

Epoch: 6| Step: 1
Training loss: 1.8835245370864868
Validation loss: 2.064265509446462

Epoch: 6| Step: 2
Training loss: 2.2171683311462402
Validation loss: 2.0680330395698547

Epoch: 6| Step: 3
Training loss: 2.6547937393188477
Validation loss: 2.0649093786875405

Epoch: 6| Step: 4
Training loss: 2.4905571937561035
Validation loss: 2.070792237917582

Epoch: 6| Step: 5
Training loss: 2.1563568115234375
Validation loss: 2.0728135108947754

Epoch: 6| Step: 6
Training loss: 1.8701872825622559
Validation loss: 2.0713244477907815

Epoch: 6| Step: 7
Training loss: 1.346022129058838
Validation loss: 2.0721117655436196

Epoch: 6| Step: 8
Training loss: 1.2888615131378174
Validation loss: 2.0584139227867126

Epoch: 6| Step: 9
Training loss: 1.8396213054656982
Validation loss: 2.0769862731297812

Epoch: 6| Step: 10
Training loss: 2.67327880859375
Validation loss: 2.069762567679087

Epoch: 6| Step: 11
Training loss: 1.7682147026062012
Validation loss: 2.064605394999186

Epoch: 6| Step: 12
Training loss: 2.4236578941345215
Validation loss: 2.0492767095565796

Epoch: 6| Step: 13
Training loss: 2.489013195037842
Validation loss: 2.0475984811782837

Epoch: 110| Step: 0
Training loss: 2.582868814468384
Validation loss: 2.0363137125968933

Epoch: 6| Step: 1
Training loss: 1.9596900939941406
Validation loss: 2.032874902089437

Epoch: 6| Step: 2
Training loss: 2.1787662506103516
Validation loss: 2.0372227827707925

Epoch: 6| Step: 3
Training loss: 2.4850234985351562
Validation loss: 2.037912885348002

Epoch: 6| Step: 4
Training loss: 1.988792896270752
Validation loss: 2.040926933288574

Epoch: 6| Step: 5
Training loss: 2.1666922569274902
Validation loss: 2.0317533214886985

Epoch: 6| Step: 6
Training loss: 1.5874629020690918
Validation loss: 2.0376503666241965

Epoch: 6| Step: 7
Training loss: 2.239551067352295
Validation loss: 2.0432963768641152

Epoch: 6| Step: 8
Training loss: 1.6861392259597778
Validation loss: 2.039433022340139

Epoch: 6| Step: 9
Training loss: 2.3700718879699707
Validation loss: 2.033246318499247

Epoch: 6| Step: 10
Training loss: 2.4808034896850586
Validation loss: 2.0316834449768066

Epoch: 6| Step: 11
Training loss: 2.2944586277008057
Validation loss: 2.034889002641042

Epoch: 6| Step: 12
Training loss: 2.5363149642944336
Validation loss: 2.0359339714050293

Epoch: 6| Step: 13
Training loss: 1.6138360500335693
Validation loss: 2.0347361962000527

Epoch: 111| Step: 0
Training loss: 2.0300040245056152
Validation loss: 2.0290735761324563

Epoch: 6| Step: 1
Training loss: 1.6221309900283813
Validation loss: 2.0404586791992188

Epoch: 6| Step: 2
Training loss: 1.7153644561767578
Validation loss: 2.03921777009964

Epoch: 6| Step: 3
Training loss: 2.2275376319885254
Validation loss: 2.0515916546185813

Epoch: 6| Step: 4
Training loss: 2.0863027572631836
Validation loss: 2.0636220375696817

Epoch: 6| Step: 5
Training loss: 2.4976019859313965
Validation loss: 2.0725326339403787

Epoch: 6| Step: 6
Training loss: 1.8582589626312256
Validation loss: 2.068673054377238

Epoch: 6| Step: 7
Training loss: 2.2988085746765137
Validation loss: 2.0855122208595276

Epoch: 6| Step: 8
Training loss: 2.2335495948791504
Validation loss: 2.0669498840967813

Epoch: 6| Step: 9
Training loss: 1.7835065126419067
Validation loss: 2.0666045347849527

Epoch: 6| Step: 10
Training loss: 2.2094500064849854
Validation loss: 2.0652913252512612

Epoch: 6| Step: 11
Training loss: 3.0594942569732666
Validation loss: 2.066872775554657

Epoch: 6| Step: 12
Training loss: 1.7816851139068604
Validation loss: 2.0674848556518555

Epoch: 6| Step: 13
Training loss: 2.254716634750366
Validation loss: 2.053217569986979

Epoch: 112| Step: 0
Training loss: 2.3476781845092773
Validation loss: 2.0544439554214478

Epoch: 6| Step: 1
Training loss: 1.9412076473236084
Validation loss: 2.0554663141568503

Epoch: 6| Step: 2
Training loss: 2.003035545349121
Validation loss: 2.0419649283091226

Epoch: 6| Step: 3
Training loss: 1.9648220539093018
Validation loss: 2.045265336831411

Epoch: 6| Step: 4
Training loss: 2.514484405517578
Validation loss: 2.0421456694602966

Epoch: 6| Step: 5
Training loss: 1.816712498664856
Validation loss: 2.0348856449127197

Epoch: 6| Step: 6
Training loss: 2.5361216068267822
Validation loss: 2.031953235467275

Epoch: 6| Step: 7
Training loss: 1.5742456912994385
Validation loss: 2.038884778817495

Epoch: 6| Step: 8
Training loss: 1.6759330034255981
Validation loss: 2.0381630460421243

Epoch: 6| Step: 9
Training loss: 2.00616455078125
Validation loss: 2.0305237571398416

Epoch: 6| Step: 10
Training loss: 2.108212471008301
Validation loss: 2.0310057997703552

Epoch: 6| Step: 11
Training loss: 2.404447078704834
Validation loss: 2.029354453086853

Epoch: 6| Step: 12
Training loss: 1.9553723335266113
Validation loss: 2.0268855889638266

Epoch: 6| Step: 13
Training loss: 2.5986080169677734
Validation loss: 2.039461314678192

Epoch: 113| Step: 0
Training loss: 2.4594578742980957
Validation loss: 2.0343478123346963

Epoch: 6| Step: 1
Training loss: 1.4863369464874268
Validation loss: 2.030473470687866

Epoch: 6| Step: 2
Training loss: 2.054741859436035
Validation loss: 2.03055610259374

Epoch: 6| Step: 3
Training loss: 2.098628044128418
Validation loss: 2.0279501477877298

Epoch: 6| Step: 4
Training loss: 2.33046817779541
Validation loss: 2.028034051259359

Epoch: 6| Step: 5
Training loss: 1.5398807525634766
Validation loss: 2.0256613294283548

Epoch: 6| Step: 6
Training loss: 1.7944246530532837
Validation loss: 2.0278416673342385

Epoch: 6| Step: 7
Training loss: 2.3878836631774902
Validation loss: 2.0271830956141152

Epoch: 6| Step: 8
Training loss: 2.2089157104492188
Validation loss: 2.0300870736440024

Epoch: 6| Step: 9
Training loss: 1.934674859046936
Validation loss: 2.0322821338971457

Epoch: 6| Step: 10
Training loss: 2.220296621322632
Validation loss: 2.0396642287572226

Epoch: 6| Step: 11
Training loss: 2.015512228012085
Validation loss: 2.044720470905304

Epoch: 6| Step: 12
Training loss: 1.8737914562225342
Validation loss: 2.044483959674835

Epoch: 6| Step: 13
Training loss: 2.9584507942199707
Validation loss: 2.04992022116979

Epoch: 114| Step: 0
Training loss: 2.328993797302246
Validation loss: 2.0494052171707153

Epoch: 6| Step: 1
Training loss: 1.5372081995010376
Validation loss: 2.056737760702769

Epoch: 6| Step: 2
Training loss: 2.0977463722229004
Validation loss: 2.0600953896840415

Epoch: 6| Step: 3
Training loss: 2.3365509510040283
Validation loss: 2.0682764848073325

Epoch: 6| Step: 4
Training loss: 1.6683199405670166
Validation loss: 2.05361678202947

Epoch: 6| Step: 5
Training loss: 1.9290307760238647
Validation loss: 2.0380924542744956

Epoch: 6| Step: 6
Training loss: 1.9056020975112915
Validation loss: 2.0347476402918496

Epoch: 6| Step: 7
Training loss: 1.980234146118164
Validation loss: 2.0287034114201865

Epoch: 6| Step: 8
Training loss: 2.0773000717163086
Validation loss: 2.0316569209098816

Epoch: 6| Step: 9
Training loss: 2.5039501190185547
Validation loss: 2.03228759765625

Epoch: 6| Step: 10
Training loss: 2.582940101623535
Validation loss: 2.0253653724988303

Epoch: 6| Step: 11
Training loss: 2.0600109100341797
Validation loss: 2.0345264871915183

Epoch: 6| Step: 12
Training loss: 2.064774990081787
Validation loss: 2.0280620455741882

Epoch: 6| Step: 13
Training loss: 2.6523051261901855
Validation loss: 2.0281629165013633

Epoch: 115| Step: 0
Training loss: 2.132473945617676
Validation loss: 2.0257216890652976

Epoch: 6| Step: 1
Training loss: 2.339200496673584
Validation loss: 2.0396173000335693

Epoch: 6| Step: 2
Training loss: 2.5733468532562256
Validation loss: 2.029858668645223

Epoch: 6| Step: 3
Training loss: 2.016002655029297
Validation loss: 2.0329359769821167

Epoch: 6| Step: 4
Training loss: 2.291687488555908
Validation loss: 2.0325214862823486

Epoch: 6| Step: 5
Training loss: 2.1309752464294434
Validation loss: 2.036682585875193

Epoch: 6| Step: 6
Training loss: 1.5149562358856201
Validation loss: 2.038021465142568

Epoch: 6| Step: 7
Training loss: 1.6192519664764404
Validation loss: 2.044493794441223

Epoch: 6| Step: 8
Training loss: 1.744957447052002
Validation loss: 2.06245881319046

Epoch: 6| Step: 9
Training loss: 2.038869857788086
Validation loss: 2.0524888237317405

Epoch: 6| Step: 10
Training loss: 2.7559404373168945
Validation loss: 2.0716316302617392

Epoch: 6| Step: 11
Training loss: 2.561948776245117
Validation loss: 2.054272949695587

Epoch: 6| Step: 12
Training loss: 1.4656274318695068
Validation loss: 2.050732672214508

Epoch: 6| Step: 13
Training loss: 2.155097007751465
Validation loss: 2.043638447920481

Epoch: 116| Step: 0
Training loss: 2.1917600631713867
Validation loss: 2.05169141292572

Epoch: 6| Step: 1
Training loss: 2.5621109008789062
Validation loss: 2.03751411040624

Epoch: 6| Step: 2
Training loss: 1.6034637689590454
Validation loss: 2.051091412703196

Epoch: 6| Step: 3
Training loss: 1.9916150569915771
Validation loss: 2.042797009150187

Epoch: 6| Step: 4
Training loss: 2.309253692626953
Validation loss: 2.0346226692199707

Epoch: 6| Step: 5
Training loss: 2.0467047691345215
Validation loss: 2.045266628265381

Epoch: 6| Step: 6
Training loss: 2.3197269439697266
Validation loss: 2.0471163590749106

Epoch: 6| Step: 7
Training loss: 2.3899500370025635
Validation loss: 2.037143329779307

Epoch: 6| Step: 8
Training loss: 1.680802583694458
Validation loss: 2.0426676074663797

Epoch: 6| Step: 9
Training loss: 1.9352138042449951
Validation loss: 2.049417813618978

Epoch: 6| Step: 10
Training loss: 2.601114273071289
Validation loss: 2.054589112599691

Epoch: 6| Step: 11
Training loss: 1.636458158493042
Validation loss: 2.050143857796987

Epoch: 6| Step: 12
Training loss: 1.9417238235473633
Validation loss: 2.0420484940210977

Epoch: 6| Step: 13
Training loss: 2.1337547302246094
Validation loss: 2.0475508769353232

Epoch: 117| Step: 0
Training loss: 1.9468207359313965
Validation loss: 2.0447216431299844

Epoch: 6| Step: 1
Training loss: 2.207803726196289
Validation loss: 2.0487458308537803

Epoch: 6| Step: 2
Training loss: 2.163620710372925
Validation loss: 2.053767681121826

Epoch: 6| Step: 3
Training loss: 2.1668636798858643
Validation loss: 2.0518966913223267

Epoch: 6| Step: 4
Training loss: 1.8526240587234497
Validation loss: 2.0583889881769815

Epoch: 6| Step: 5
Training loss: 1.9994388818740845
Validation loss: 2.0480395754178367

Epoch: 6| Step: 6
Training loss: 2.083875894546509
Validation loss: 2.051760494709015

Epoch: 6| Step: 7
Training loss: 2.718486785888672
Validation loss: 2.0549168984095254

Epoch: 6| Step: 8
Training loss: 2.259028911590576
Validation loss: 2.059780935446421

Epoch: 6| Step: 9
Training loss: 1.4657394886016846
Validation loss: 2.0600696404774985

Epoch: 6| Step: 10
Training loss: 2.1963448524475098
Validation loss: 2.072678327560425

Epoch: 6| Step: 11
Training loss: 1.8340574502944946
Validation loss: 2.0754855275154114

Epoch: 6| Step: 12
Training loss: 1.8348791599273682
Validation loss: 2.0548667510350547

Epoch: 6| Step: 13
Training loss: 2.3965344429016113
Validation loss: 2.0532506505648294

Epoch: 118| Step: 0
Training loss: 1.610337495803833
Validation loss: 2.047516425450643

Epoch: 6| Step: 1
Training loss: 1.7868659496307373
Validation loss: 2.047353466351827

Epoch: 6| Step: 2
Training loss: 2.00129771232605
Validation loss: 2.0424800316492715

Epoch: 6| Step: 3
Training loss: 1.5062131881713867
Validation loss: 2.032004952430725

Epoch: 6| Step: 4
Training loss: 2.301219940185547
Validation loss: 2.0476143757502236

Epoch: 6| Step: 5
Training loss: 2.192694902420044
Validation loss: 2.0330263574918113

Epoch: 6| Step: 6
Training loss: 2.174182415008545
Validation loss: 2.048777222633362

Epoch: 6| Step: 7
Training loss: 2.2137231826782227
Validation loss: 2.0506473580996194

Epoch: 6| Step: 8
Training loss: 2.2095119953155518
Validation loss: 2.0483564933141074

Epoch: 6| Step: 9
Training loss: 2.242818832397461
Validation loss: 2.041753351688385

Epoch: 6| Step: 10
Training loss: 1.9082961082458496
Validation loss: 2.042969902356466

Epoch: 6| Step: 11
Training loss: 2.2400007247924805
Validation loss: 2.0407764514287314

Epoch: 6| Step: 12
Training loss: 2.365567684173584
Validation loss: 2.0491783022880554

Epoch: 6| Step: 13
Training loss: 2.4960975646972656
Validation loss: 2.0401360193888345

Epoch: 119| Step: 0
Training loss: 1.7761132717132568
Validation loss: 2.0496596693992615

Epoch: 6| Step: 1
Training loss: 2.1923680305480957
Validation loss: 2.0490921338399253

Epoch: 6| Step: 2
Training loss: 1.668959617614746
Validation loss: 2.051166613896688

Epoch: 6| Step: 3
Training loss: 2.003986358642578
Validation loss: 2.0577800273895264

Epoch: 6| Step: 4
Training loss: 2.632521867752075
Validation loss: 2.0576560497283936

Epoch: 6| Step: 5
Training loss: 1.5692741870880127
Validation loss: 2.0589829881985984

Epoch: 6| Step: 6
Training loss: 2.44750714302063
Validation loss: 2.069833775361379

Epoch: 6| Step: 7
Training loss: 2.5609047412872314
Validation loss: 2.0618197321891785

Epoch: 6| Step: 8
Training loss: 2.403047561645508
Validation loss: 2.052622159322103

Epoch: 6| Step: 9
Training loss: 2.4031100273132324
Validation loss: 2.0491922895113626

Epoch: 6| Step: 10
Training loss: 1.5142481327056885
Validation loss: 2.0523128112157187

Epoch: 6| Step: 11
Training loss: 2.1740903854370117
Validation loss: 2.0427690545717874

Epoch: 6| Step: 12
Training loss: 2.191413402557373
Validation loss: 2.040216565132141

Epoch: 6| Step: 13
Training loss: 1.8314855098724365
Validation loss: 2.037967582543691

Epoch: 120| Step: 0
Training loss: 2.5633533000946045
Validation loss: 2.0346238811810813

Epoch: 6| Step: 1
Training loss: 1.9083011150360107
Validation loss: 2.0495792229970298

Epoch: 6| Step: 2
Training loss: 1.696786642074585
Validation loss: 2.040211856365204

Epoch: 6| Step: 3
Training loss: 2.6115944385528564
Validation loss: 2.0469836791356406

Epoch: 6| Step: 4
Training loss: 2.079085350036621
Validation loss: 2.047037343184153

Epoch: 6| Step: 5
Training loss: 1.82484769821167
Validation loss: 2.0626988410949707

Epoch: 6| Step: 6
Training loss: 1.80997896194458
Validation loss: 2.0873685280481973

Epoch: 6| Step: 7
Training loss: 2.0016722679138184
Validation loss: 2.0715502897898355

Epoch: 6| Step: 8
Training loss: 2.318753242492676
Validation loss: 2.068325936794281

Epoch: 6| Step: 9
Training loss: 1.639331579208374
Validation loss: 2.0718634923299155

Epoch: 6| Step: 10
Training loss: 2.411860227584839
Validation loss: 2.082874119281769

Epoch: 6| Step: 11
Training loss: 2.142995834350586
Validation loss: 2.067304849624634

Epoch: 6| Step: 12
Training loss: 2.3210349082946777
Validation loss: 2.063432276248932

Epoch: 6| Step: 13
Training loss: 1.9581577777862549
Validation loss: 2.070882717768351

Epoch: 121| Step: 0
Training loss: 1.753066062927246
Validation loss: 2.0505006512006125

Epoch: 6| Step: 1
Training loss: 1.7784240245819092
Validation loss: 2.0498351653416953

Epoch: 6| Step: 2
Training loss: 2.036522626876831
Validation loss: 2.0425432920455933

Epoch: 6| Step: 3
Training loss: 1.780369520187378
Validation loss: 2.0383870601654053

Epoch: 6| Step: 4
Training loss: 2.868140935897827
Validation loss: 2.0366474390029907

Epoch: 6| Step: 5
Training loss: 1.9758131504058838
Validation loss: 2.036269942919413

Epoch: 6| Step: 6
Training loss: 2.3252854347229004
Validation loss: 2.0435052712758384

Epoch: 6| Step: 7
Training loss: 2.476078510284424
Validation loss: 2.0379845897356668

Epoch: 6| Step: 8
Training loss: 2.3447203636169434
Validation loss: 2.0394485791524253

Epoch: 6| Step: 9
Training loss: 1.840796947479248
Validation loss: 2.0428826610247293

Epoch: 6| Step: 10
Training loss: 2.388535499572754
Validation loss: 2.036142110824585

Epoch: 6| Step: 11
Training loss: 1.6913340091705322
Validation loss: 2.041337311267853

Epoch: 6| Step: 12
Training loss: 1.7613117694854736
Validation loss: 2.0609264771143594

Epoch: 6| Step: 13
Training loss: 2.0523126125335693
Validation loss: 2.067727486292521

Epoch: 122| Step: 0
Training loss: 1.8252654075622559
Validation loss: 2.0971810817718506

Epoch: 6| Step: 1
Training loss: 2.3302743434906006
Validation loss: 2.0774924755096436

Epoch: 6| Step: 2
Training loss: 2.1904985904693604
Validation loss: 2.060948371887207

Epoch: 6| Step: 3
Training loss: 1.792151927947998
Validation loss: 2.051786502202352

Epoch: 6| Step: 4
Training loss: 2.5517499446868896
Validation loss: 2.035159687201182

Epoch: 6| Step: 5
Training loss: 2.0554609298706055
Validation loss: 2.025377174218496

Epoch: 6| Step: 6
Training loss: 1.876027226448059
Validation loss: 2.0163298646608987

Epoch: 6| Step: 7
Training loss: 1.9866117238998413
Validation loss: 2.0183494091033936

Epoch: 6| Step: 8
Training loss: 2.674619674682617
Validation loss: 2.029194474220276

Epoch: 6| Step: 9
Training loss: 2.532540798187256
Validation loss: 2.0302186012268066

Epoch: 6| Step: 10
Training loss: 2.2092671394348145
Validation loss: 2.0323685805002847

Epoch: 6| Step: 11
Training loss: 2.223548650741577
Validation loss: 2.0313602685928345

Epoch: 6| Step: 12
Training loss: 1.8919471502304077
Validation loss: 2.022438923517863

Epoch: 6| Step: 13
Training loss: 2.081112861633301
Validation loss: 2.0283822814623513

Epoch: 123| Step: 0
Training loss: 1.8736275434494019
Validation loss: 2.022400895754496

Epoch: 6| Step: 1
Training loss: 2.2348411083221436
Validation loss: 2.0232049226760864

Epoch: 6| Step: 2
Training loss: 2.2896764278411865
Validation loss: 2.0170097947120667

Epoch: 6| Step: 3
Training loss: 2.2617857456207275
Validation loss: 2.014624913533529

Epoch: 6| Step: 4
Training loss: 2.055314302444458
Validation loss: 2.0133357445398965

Epoch: 6| Step: 5
Training loss: 2.928311824798584
Validation loss: 2.006840169429779

Epoch: 6| Step: 6
Training loss: 1.84352445602417
Validation loss: 2.004442592461904

Epoch: 6| Step: 7
Training loss: 1.565314769744873
Validation loss: 2.008861521879832

Epoch: 6| Step: 8
Training loss: 2.0506107807159424
Validation loss: 2.0096256534258523

Epoch: 6| Step: 9
Training loss: 2.2674036026000977
Validation loss: 2.0114590724309287

Epoch: 6| Step: 10
Training loss: 1.8208606243133545
Validation loss: 2.019814372062683

Epoch: 6| Step: 11
Training loss: 1.9425153732299805
Validation loss: 2.022365609804789

Epoch: 6| Step: 12
Training loss: 2.429489850997925
Validation loss: 2.0344513257344565

Epoch: 6| Step: 13
Training loss: 2.154297113418579
Validation loss: 2.030524969100952

Epoch: 124| Step: 0
Training loss: 1.9853339195251465
Validation loss: 2.03993692000707

Epoch: 6| Step: 1
Training loss: 1.7109017372131348
Validation loss: 2.043038070201874

Epoch: 6| Step: 2
Training loss: 2.095889091491699
Validation loss: 2.0335691968599954

Epoch: 6| Step: 3
Training loss: 1.9480763673782349
Validation loss: 2.0465574860572815

Epoch: 6| Step: 4
Training loss: 2.362727165222168
Validation loss: 2.0373913645744324

Epoch: 6| Step: 5
Training loss: 2.9060449600219727
Validation loss: 2.055654009183248

Epoch: 6| Step: 6
Training loss: 2.0671896934509277
Validation loss: 2.053297499815623

Epoch: 6| Step: 7
Training loss: 1.5599887371063232
Validation loss: 2.044443686803182

Epoch: 6| Step: 8
Training loss: 2.7232091426849365
Validation loss: 2.045273542404175

Epoch: 6| Step: 9
Training loss: 1.924264907836914
Validation loss: 2.0502010782559714

Epoch: 6| Step: 10
Training loss: 1.406017541885376
Validation loss: 2.0387808084487915

Epoch: 6| Step: 11
Training loss: 2.5005011558532715
Validation loss: 2.0492782394091287

Epoch: 6| Step: 12
Training loss: 1.9931998252868652
Validation loss: 2.046440303325653

Epoch: 6| Step: 13
Training loss: 1.9922473430633545
Validation loss: 2.0545665621757507

Epoch: 125| Step: 0
Training loss: 1.5105115175247192
Validation loss: 2.055601437886556

Epoch: 6| Step: 1
Training loss: 1.8917500972747803
Validation loss: 2.0533524552981057

Epoch: 6| Step: 2
Training loss: 2.0876927375793457
Validation loss: 2.0620294411977134

Epoch: 6| Step: 3
Training loss: 2.3826236724853516
Validation loss: 2.055192530155182

Epoch: 6| Step: 4
Training loss: 1.7904971837997437
Validation loss: 2.0675554076830545

Epoch: 6| Step: 5
Training loss: 1.7239007949829102
Validation loss: 2.076911727587382

Epoch: 6| Step: 6
Training loss: 1.4579720497131348
Validation loss: 2.055700937906901

Epoch: 6| Step: 7
Training loss: 2.2849059104919434
Validation loss: 2.0652753710746765

Epoch: 6| Step: 8
Training loss: 2.3892829418182373
Validation loss: 2.065319001674652

Epoch: 6| Step: 9
Training loss: 2.0000762939453125
Validation loss: 2.058510939280192

Epoch: 6| Step: 10
Training loss: 2.2858729362487793
Validation loss: 2.0616222421328225

Epoch: 6| Step: 11
Training loss: 2.944211006164551
Validation loss: 2.0603758096694946

Epoch: 6| Step: 12
Training loss: 1.9871959686279297
Validation loss: 2.051668345928192

Epoch: 6| Step: 13
Training loss: 2.349980354309082
Validation loss: 2.041133403778076

Epoch: 126| Step: 0
Training loss: 2.387143135070801
Validation loss: 2.0222455859184265

Epoch: 6| Step: 1
Training loss: 1.9307029247283936
Validation loss: 2.024405598640442

Epoch: 6| Step: 2
Training loss: 2.173708915710449
Validation loss: 2.0298643906911216

Epoch: 6| Step: 3
Training loss: 2.020432949066162
Validation loss: 2.024265726407369

Epoch: 6| Step: 4
Training loss: 1.903730869293213
Validation loss: 2.0309354662895203

Epoch: 6| Step: 5
Training loss: 2.032650947570801
Validation loss: 2.0165651440620422

Epoch: 6| Step: 6
Training loss: 2.2357125282287598
Validation loss: 2.018831451733907

Epoch: 6| Step: 7
Training loss: 2.1280651092529297
Validation loss: 2.0137210687001548

Epoch: 6| Step: 8
Training loss: 2.172870397567749
Validation loss: 2.018946905930837

Epoch: 6| Step: 9
Training loss: 2.336082935333252
Validation loss: 2.021084189414978

Epoch: 6| Step: 10
Training loss: 1.7876043319702148
Validation loss: 2.0216983358065286

Epoch: 6| Step: 11
Training loss: 1.8320964574813843
Validation loss: 2.031760096549988

Epoch: 6| Step: 12
Training loss: 1.6586732864379883
Validation loss: 2.036971469720205

Epoch: 6| Step: 13
Training loss: 2.815321445465088
Validation loss: 2.052417198816935

Epoch: 127| Step: 0
Training loss: 2.9167439937591553
Validation loss: 2.0531212290128074

Epoch: 6| Step: 1
Training loss: 2.846496343612671
Validation loss: 2.053409695625305

Epoch: 6| Step: 2
Training loss: 2.276414155960083
Validation loss: 2.0579562385876975

Epoch: 6| Step: 3
Training loss: 1.619210124015808
Validation loss: 2.043858746687571

Epoch: 6| Step: 4
Training loss: 2.180615186691284
Validation loss: 2.046112815539042

Epoch: 6| Step: 5
Training loss: 2.0207698345184326
Validation loss: 2.0445789893468223

Epoch: 6| Step: 6
Training loss: 1.850303292274475
Validation loss: 2.045250336329142

Epoch: 6| Step: 7
Training loss: 2.5316147804260254
Validation loss: 2.053298552831014

Epoch: 6| Step: 8
Training loss: 2.2313742637634277
Validation loss: 2.062916020552317

Epoch: 6| Step: 9
Training loss: 1.5124799013137817
Validation loss: 2.061671475569407

Epoch: 6| Step: 10
Training loss: 1.85660719871521
Validation loss: 2.060540715853373

Epoch: 6| Step: 11
Training loss: 1.781368374824524
Validation loss: 2.067382792631785

Epoch: 6| Step: 12
Training loss: 1.4875911474227905
Validation loss: 2.0720150073369346

Epoch: 6| Step: 13
Training loss: 1.9178857803344727
Validation loss: 2.0812086860338845

Epoch: 128| Step: 0
Training loss: 1.7267858982086182
Validation loss: 2.077921191851298

Epoch: 6| Step: 1
Training loss: 2.149921417236328
Validation loss: 2.078980545202891

Epoch: 6| Step: 2
Training loss: 2.2786834239959717
Validation loss: 2.09081639846166

Epoch: 6| Step: 3
Training loss: 2.101322650909424
Validation loss: 2.0669827461242676

Epoch: 6| Step: 4
Training loss: 2.2381644248962402
Validation loss: 2.054482400417328

Epoch: 6| Step: 5
Training loss: 1.9904215335845947
Validation loss: 2.0638213753700256

Epoch: 6| Step: 6
Training loss: 2.0582501888275146
Validation loss: 2.0548044045766196

Epoch: 6| Step: 7
Training loss: 2.35616397857666
Validation loss: 2.0540621479352317

Epoch: 6| Step: 8
Training loss: 1.9744200706481934
Validation loss: 2.040984352429708

Epoch: 6| Step: 9
Training loss: 1.9444620609283447
Validation loss: 2.05318146944046

Epoch: 6| Step: 10
Training loss: 1.6942594051361084
Validation loss: 2.044457574685415

Epoch: 6| Step: 11
Training loss: 2.3613715171813965
Validation loss: 2.0396578510602317

Epoch: 6| Step: 12
Training loss: 2.0154712200164795
Validation loss: 2.022771974404653

Epoch: 6| Step: 13
Training loss: 2.2735414505004883
Validation loss: 2.0352383057276406

Epoch: 129| Step: 0
Training loss: 2.0014734268188477
Validation loss: 2.0418055256207785

Epoch: 6| Step: 1
Training loss: 1.6273728609085083
Validation loss: 2.0423279205958047

Epoch: 6| Step: 2
Training loss: 1.2853760719299316
Validation loss: 2.0477155447006226

Epoch: 6| Step: 3
Training loss: 2.113417625427246
Validation loss: 2.0523908734321594

Epoch: 6| Step: 4
Training loss: 3.242701530456543
Validation loss: 2.0617416302363076

Epoch: 6| Step: 5
Training loss: 1.8885936737060547
Validation loss: 2.070704539616903

Epoch: 6| Step: 6
Training loss: 1.5147678852081299
Validation loss: 2.071812907854716

Epoch: 6| Step: 7
Training loss: 2.4075193405151367
Validation loss: 2.0752537647883096

Epoch: 6| Step: 8
Training loss: 2.5993618965148926
Validation loss: 2.0739981134732566

Epoch: 6| Step: 9
Training loss: 2.3675479888916016
Validation loss: 2.071801006793976

Epoch: 6| Step: 10
Training loss: 2.0541625022888184
Validation loss: 2.0680179794629416

Epoch: 6| Step: 11
Training loss: 1.2891120910644531
Validation loss: 2.0647701422373452

Epoch: 6| Step: 12
Training loss: 1.662619709968567
Validation loss: 2.0667373538017273

Epoch: 6| Step: 13
Training loss: 2.867940664291382
Validation loss: 2.054150938987732

Epoch: 130| Step: 0
Training loss: 2.115865707397461
Validation loss: 2.0523159901301065

Epoch: 6| Step: 1
Training loss: 2.093136787414551
Validation loss: 2.049033999443054

Epoch: 6| Step: 2
Training loss: 1.1428806781768799
Validation loss: 2.0459224780400596

Epoch: 6| Step: 3
Training loss: 2.152503252029419
Validation loss: 2.0288285414377847

Epoch: 6| Step: 4
Training loss: 2.123903274536133
Validation loss: 2.028871556123098

Epoch: 6| Step: 5
Training loss: 2.114166259765625
Validation loss: 2.033135255177816

Epoch: 6| Step: 6
Training loss: 2.4383506774902344
Validation loss: 2.0221674839655557

Epoch: 6| Step: 7
Training loss: 2.0413410663604736
Validation loss: 2.025244494279226

Epoch: 6| Step: 8
Training loss: 2.040027141571045
Validation loss: 2.035330335299174

Epoch: 6| Step: 9
Training loss: 1.9534645080566406
Validation loss: 2.0422065059343972

Epoch: 6| Step: 10
Training loss: 2.7104339599609375
Validation loss: 2.0452140172322593

Epoch: 6| Step: 11
Training loss: 2.2647907733917236
Validation loss: 2.0625481406847634

Epoch: 6| Step: 12
Training loss: 2.370365619659424
Validation loss: 2.055665930112203

Epoch: 6| Step: 13
Training loss: 1.5270506143569946
Validation loss: 2.0701763232549033

Epoch: 131| Step: 0
Training loss: 2.2973361015319824
Validation loss: 2.074563960234324

Epoch: 6| Step: 1
Training loss: 2.240565776824951
Validation loss: 2.0605633656183877

Epoch: 6| Step: 2
Training loss: 2.1549410820007324
Validation loss: 2.0726325313250222

Epoch: 6| Step: 3
Training loss: 2.6237070560455322
Validation loss: 2.052640974521637

Epoch: 6| Step: 4
Training loss: 1.4016153812408447
Validation loss: 2.04732080300649

Epoch: 6| Step: 5
Training loss: 1.5512640476226807
Validation loss: 2.039415796597799

Epoch: 6| Step: 6
Training loss: 2.453758955001831
Validation loss: 2.034347355365753

Epoch: 6| Step: 7
Training loss: 2.216322422027588
Validation loss: 2.035899579524994

Epoch: 6| Step: 8
Training loss: 1.8345379829406738
Validation loss: 2.0313167174657187

Epoch: 6| Step: 9
Training loss: 2.2669599056243896
Validation loss: 2.0344234506289163

Epoch: 6| Step: 10
Training loss: 2.2327094078063965
Validation loss: 2.0385667085647583

Epoch: 6| Step: 11
Training loss: 1.723311185836792
Validation loss: 2.0350565910339355

Epoch: 6| Step: 12
Training loss: 1.9106509685516357
Validation loss: 2.0269489089647927

Epoch: 6| Step: 13
Training loss: 2.153449535369873
Validation loss: 2.0384734670321145

Epoch: 132| Step: 0
Training loss: 1.6107592582702637
Validation loss: 2.040085474650065

Epoch: 6| Step: 1
Training loss: 1.7942113876342773
Validation loss: 2.0502551992734275

Epoch: 6| Step: 2
Training loss: 2.0315871238708496
Validation loss: 2.0596452554066977

Epoch: 6| Step: 3
Training loss: 2.357142925262451
Validation loss: 2.0709367195765176

Epoch: 6| Step: 4
Training loss: 2.040924072265625
Validation loss: 2.0896878242492676

Epoch: 6| Step: 5
Training loss: 2.10546875
Validation loss: 2.0934206446011863

Epoch: 6| Step: 6
Training loss: 2.290632486343384
Validation loss: 2.1109463572502136

Epoch: 6| Step: 7
Training loss: 2.166194438934326
Validation loss: 2.0978184938430786

Epoch: 6| Step: 8
Training loss: 2.210073471069336
Validation loss: 2.0674082040786743

Epoch: 6| Step: 9
Training loss: 1.127587080001831
Validation loss: 2.047998289267222

Epoch: 6| Step: 10
Training loss: 2.3926784992218018
Validation loss: 2.0416296323140464

Epoch: 6| Step: 11
Training loss: 2.5021471977233887
Validation loss: 2.043310205141703

Epoch: 6| Step: 12
Training loss: 2.4285128116607666
Validation loss: 2.0308978160222373

Epoch: 6| Step: 13
Training loss: 2.58052659034729
Validation loss: 2.0383863846460977

Epoch: 133| Step: 0
Training loss: 2.5723540782928467
Validation loss: 2.041011373202006

Epoch: 6| Step: 1
Training loss: 1.3824365139007568
Validation loss: 2.037358502546946

Epoch: 6| Step: 2
Training loss: 1.4121458530426025
Validation loss: 2.0386308630307517

Epoch: 6| Step: 3
Training loss: 2.2456936836242676
Validation loss: 2.053744296232859

Epoch: 6| Step: 4
Training loss: 1.5231765508651733
Validation loss: 2.0464860796928406

Epoch: 6| Step: 5
Training loss: 2.089986801147461
Validation loss: 2.039930045604706

Epoch: 6| Step: 6
Training loss: 2.4948105812072754
Validation loss: 2.0442405541737876

Epoch: 6| Step: 7
Training loss: 2.033592939376831
Validation loss: 2.042996962865194

Epoch: 6| Step: 8
Training loss: 2.7221736907958984
Validation loss: 2.0421012242635093

Epoch: 6| Step: 9
Training loss: 1.8773565292358398
Validation loss: 2.0402488708496094

Epoch: 6| Step: 10
Training loss: 2.5712532997131348
Validation loss: 2.0331851840019226

Epoch: 6| Step: 11
Training loss: 2.316220283508301
Validation loss: 2.028167724609375

Epoch: 6| Step: 12
Training loss: 1.9123313426971436
Validation loss: 2.0359594027201333

Epoch: 6| Step: 13
Training loss: 2.5020501613616943
Validation loss: 2.0457754929860434

Epoch: 134| Step: 0
Training loss: 2.1492960453033447
Validation loss: 2.0425644715627036

Epoch: 6| Step: 1
Training loss: 2.661691904067993
Validation loss: 2.058430254459381

Epoch: 6| Step: 2
Training loss: 1.7657642364501953
Validation loss: 2.0660784244537354

Epoch: 6| Step: 3
Training loss: 2.2582240104675293
Validation loss: 2.0721382300059

Epoch: 6| Step: 4
Training loss: 1.9398525953292847
Validation loss: 2.0837255915006003

Epoch: 6| Step: 5
Training loss: 1.8761003017425537
Validation loss: 2.079733928044637

Epoch: 6| Step: 6
Training loss: 1.5064842700958252
Validation loss: 2.0814542373021445

Epoch: 6| Step: 7
Training loss: 1.8227930068969727
Validation loss: 2.0763430992762246

Epoch: 6| Step: 8
Training loss: 2.416982412338257
Validation loss: 2.053788105646769

Epoch: 6| Step: 9
Training loss: 2.231200695037842
Validation loss: 2.069988509019216

Epoch: 6| Step: 10
Training loss: 2.3236234188079834
Validation loss: 2.066966195901235

Epoch: 6| Step: 11
Training loss: 2.048556327819824
Validation loss: 2.0686515172322593

Epoch: 6| Step: 12
Training loss: 1.9564646482467651
Validation loss: 2.0669976274172464

Epoch: 6| Step: 13
Training loss: 2.1261849403381348
Validation loss: 2.0612276196479797

Epoch: 135| Step: 0
Training loss: 2.3762450218200684
Validation loss: 2.052707552909851

Epoch: 6| Step: 1
Training loss: 1.8243597745895386
Validation loss: 2.0488057136535645

Epoch: 6| Step: 2
Training loss: 2.1811413764953613
Validation loss: 2.0379076401392617

Epoch: 6| Step: 3
Training loss: 2.301485061645508
Validation loss: 2.051322956879934

Epoch: 6| Step: 4
Training loss: 2.019455909729004
Validation loss: 2.0499526262283325

Epoch: 6| Step: 5
Training loss: 2.4116601943969727
Validation loss: 2.0463435649871826

Epoch: 6| Step: 6
Training loss: 1.9550062417984009
Validation loss: 2.047534783681234

Epoch: 6| Step: 7
Training loss: 1.974257469177246
Validation loss: 2.0559431513150535

Epoch: 6| Step: 8
Training loss: 2.511063575744629
Validation loss: 2.0660252968470254

Epoch: 6| Step: 9
Training loss: 2.2321720123291016
Validation loss: 2.074907879034678

Epoch: 6| Step: 10
Training loss: 1.540329933166504
Validation loss: 2.0769262313842773

Epoch: 6| Step: 11
Training loss: 2.0562281608581543
Validation loss: 2.081799030303955

Epoch: 6| Step: 12
Training loss: 1.58028244972229
Validation loss: 2.074891666571299

Epoch: 6| Step: 13
Training loss: 1.9017585515975952
Validation loss: 2.0715914169947305

Epoch: 136| Step: 0
Training loss: 2.3499608039855957
Validation loss: 2.071310559908549

Epoch: 6| Step: 1
Training loss: 1.455251932144165
Validation loss: 2.0612988670667014

Epoch: 6| Step: 2
Training loss: 2.134056568145752
Validation loss: 2.0373603900273642

Epoch: 6| Step: 3
Training loss: 2.2251012325286865
Validation loss: 2.0547022422154746

Epoch: 6| Step: 4
Training loss: 2.0279006958007812
Validation loss: 2.042606314023336

Epoch: 6| Step: 5
Training loss: 2.3668198585510254
Validation loss: 2.0538015564282737

Epoch: 6| Step: 6
Training loss: 2.233565092086792
Validation loss: 2.049354533354441

Epoch: 6| Step: 7
Training loss: 1.6930038928985596
Validation loss: 2.044088125228882

Epoch: 6| Step: 8
Training loss: 1.744009017944336
Validation loss: 2.0527796745300293

Epoch: 6| Step: 9
Training loss: 2.1907856464385986
Validation loss: 2.0373196403185525

Epoch: 6| Step: 10
Training loss: 1.9397220611572266
Validation loss: 2.0546321074167886

Epoch: 6| Step: 11
Training loss: 2.2784841060638428
Validation loss: 2.0501944025357566

Epoch: 6| Step: 12
Training loss: 1.8734604120254517
Validation loss: 2.0658471385637918

Epoch: 6| Step: 13
Training loss: 2.335421562194824
Validation loss: 2.067460854848226

Epoch: 137| Step: 0
Training loss: 2.594521999359131
Validation loss: 2.0751646955808005

Epoch: 6| Step: 1
Training loss: 2.1907100677490234
Validation loss: 2.0818371574083963

Epoch: 6| Step: 2
Training loss: 1.6319565773010254
Validation loss: 2.0791178544362388

Epoch: 6| Step: 3
Training loss: 2.264779567718506
Validation loss: 2.0762357115745544

Epoch: 6| Step: 4
Training loss: 1.459750771522522
Validation loss: 2.0811883211135864

Epoch: 6| Step: 5
Training loss: 1.6492372751235962
Validation loss: 2.0781025886535645

Epoch: 6| Step: 6
Training loss: 1.9021351337432861
Validation loss: 2.0744807521502175

Epoch: 6| Step: 7
Training loss: 2.448007583618164
Validation loss: 2.0654874642690024

Epoch: 6| Step: 8
Training loss: 2.3066253662109375
Validation loss: 2.0630568464597068

Epoch: 6| Step: 9
Training loss: 1.815902829170227
Validation loss: 2.0621105631192527

Epoch: 6| Step: 10
Training loss: 1.769566535949707
Validation loss: 2.049431045850118

Epoch: 6| Step: 11
Training loss: 2.208681583404541
Validation loss: 2.049667398134867

Epoch: 6| Step: 12
Training loss: 2.171565532684326
Validation loss: 2.045751770337423

Epoch: 6| Step: 13
Training loss: 2.287450075149536
Validation loss: 2.0432296792666116

Epoch: 138| Step: 0
Training loss: 1.601083517074585
Validation loss: 2.051152149836222

Epoch: 6| Step: 1
Training loss: 1.9443840980529785
Validation loss: 2.055203676223755

Epoch: 6| Step: 2
Training loss: 2.0844976902008057
Validation loss: 2.0562919974327087

Epoch: 6| Step: 3
Training loss: 1.685886025428772
Validation loss: 2.0577028393745422

Epoch: 6| Step: 4
Training loss: 2.0249485969543457
Validation loss: 2.0713141759236655

Epoch: 6| Step: 5
Training loss: 1.8350372314453125
Validation loss: 2.0733995040257773

Epoch: 6| Step: 6
Training loss: 1.725916862487793
Validation loss: 2.0788108110427856

Epoch: 6| Step: 7
Training loss: 2.03348970413208
Validation loss: 2.0844810803731284

Epoch: 6| Step: 8
Training loss: 1.9439505338668823
Validation loss: 2.0817817648251853

Epoch: 6| Step: 9
Training loss: 2.241755485534668
Validation loss: 2.0777563055356345

Epoch: 6| Step: 10
Training loss: 2.205044746398926
Validation loss: 2.084782520929972

Epoch: 6| Step: 11
Training loss: 2.2419161796569824
Validation loss: 2.0880589286486306

Epoch: 6| Step: 12
Training loss: 2.4952619075775146
Validation loss: 2.076959252357483

Epoch: 6| Step: 13
Training loss: 2.902233362197876
Validation loss: 2.0719010631243386

Epoch: 139| Step: 0
Training loss: 2.4918289184570312
Validation loss: 2.0526417891184487

Epoch: 6| Step: 1
Training loss: 1.5725505352020264
Validation loss: 2.065921743710836

Epoch: 6| Step: 2
Training loss: 2.3670477867126465
Validation loss: 2.0506893595059714

Epoch: 6| Step: 3
Training loss: 2.063971519470215
Validation loss: 2.0573415557543435

Epoch: 6| Step: 4
Training loss: 2.1072490215301514
Validation loss: 2.056715508302053

Epoch: 6| Step: 5
Training loss: 2.1232540607452393
Validation loss: 2.063844084739685

Epoch: 6| Step: 6
Training loss: 1.9700312614440918
Validation loss: 2.0698291460673013

Epoch: 6| Step: 7
Training loss: 1.2444453239440918
Validation loss: 2.075658619403839

Epoch: 6| Step: 8
Training loss: 2.4621870517730713
Validation loss: 2.0864564379056296

Epoch: 6| Step: 9
Training loss: 2.112809658050537
Validation loss: 2.095227082570394

Epoch: 6| Step: 10
Training loss: 2.073620557785034
Validation loss: 2.0852270325024924

Epoch: 6| Step: 11
Training loss: 1.8776705265045166
Validation loss: 2.0683202942212424

Epoch: 6| Step: 12
Training loss: 2.3432130813598633
Validation loss: 2.0685520569483438

Epoch: 6| Step: 13
Training loss: 1.9376428127288818
Validation loss: 2.078134616216024

Epoch: 140| Step: 0
Training loss: 2.7411015033721924
Validation loss: 2.0536124110221863

Epoch: 6| Step: 1
Training loss: 2.004882335662842
Validation loss: 2.0607965191205344

Epoch: 6| Step: 2
Training loss: 1.7969465255737305
Validation loss: 2.0579777359962463

Epoch: 6| Step: 3
Training loss: 2.188714027404785
Validation loss: 2.0650817354520163

Epoch: 6| Step: 4
Training loss: 1.7729361057281494
Validation loss: 2.0805809696515403

Epoch: 6| Step: 5
Training loss: 2.4094653129577637
Validation loss: 2.086671749750773

Epoch: 6| Step: 6
Training loss: 1.6594955921173096
Validation loss: 2.0630330244700112

Epoch: 6| Step: 7
Training loss: 1.8372752666473389
Validation loss: 2.077556610107422

Epoch: 6| Step: 8
Training loss: 1.6511571407318115
Validation loss: 2.0579126675923667

Epoch: 6| Step: 9
Training loss: 1.7084599733352661
Validation loss: 2.0503540436426797

Epoch: 6| Step: 10
Training loss: 2.111875057220459
Validation loss: 2.048041522502899

Epoch: 6| Step: 11
Training loss: 1.8819859027862549
Validation loss: 2.0479833682378135

Epoch: 6| Step: 12
Training loss: 2.84930157661438
Validation loss: 2.0441070596377053

Epoch: 6| Step: 13
Training loss: 1.8482507467269897
Validation loss: 2.036200761795044

Epoch: 141| Step: 0
Training loss: 2.1227309703826904
Validation loss: 2.0501640240351358

Epoch: 6| Step: 1
Training loss: 1.3036224842071533
Validation loss: 2.0424888531366983

Epoch: 6| Step: 2
Training loss: 1.7824673652648926
Validation loss: 2.045972466468811

Epoch: 6| Step: 3
Training loss: 2.5320019721984863
Validation loss: 2.058537026246389

Epoch: 6| Step: 4
Training loss: 1.7378337383270264
Validation loss: 2.069079021612803

Epoch: 6| Step: 5
Training loss: 2.0139808654785156
Validation loss: 2.0619327227274575

Epoch: 6| Step: 6
Training loss: 2.1018295288085938
Validation loss: 2.095030685265859

Epoch: 6| Step: 7
Training loss: 2.223212718963623
Validation loss: 2.0748078028361

Epoch: 6| Step: 8
Training loss: 1.7156909704208374
Validation loss: 2.0969618956247964

Epoch: 6| Step: 9
Training loss: 2.578287124633789
Validation loss: 2.0849323868751526

Epoch: 6| Step: 10
Training loss: 1.8619571924209595
Validation loss: 2.108344852924347

Epoch: 6| Step: 11
Training loss: 2.750825881958008
Validation loss: 2.089117149511973

Epoch: 6| Step: 12
Training loss: 2.1125409603118896
Validation loss: 2.0933007995287576

Epoch: 6| Step: 13
Training loss: 1.8630414009094238
Validation loss: 2.081526796023051

Epoch: 142| Step: 0
Training loss: 1.7429516315460205
Validation loss: 2.068909446398417

Epoch: 6| Step: 1
Training loss: 1.9163070917129517
Validation loss: 2.0678110321362815

Epoch: 6| Step: 2
Training loss: 1.5261270999908447
Validation loss: 2.055693825085958

Epoch: 6| Step: 3
Training loss: 2.477090358734131
Validation loss: 2.057355284690857

Epoch: 6| Step: 4
Training loss: 1.9597841501235962
Validation loss: 2.049825608730316

Epoch: 6| Step: 5
Training loss: 2.207660675048828
Validation loss: 2.064618726571401

Epoch: 6| Step: 6
Training loss: 1.8145990371704102
Validation loss: 2.0496301452318826

Epoch: 6| Step: 7
Training loss: 2.2417001724243164
Validation loss: 2.069737136363983

Epoch: 6| Step: 8
Training loss: 2.157695770263672
Validation loss: 2.058436850706736

Epoch: 6| Step: 9
Training loss: 1.6829614639282227
Validation loss: 2.0819809238115945

Epoch: 6| Step: 10
Training loss: 1.9197018146514893
Validation loss: 2.0753981272379556

Epoch: 6| Step: 11
Training loss: 2.2301058769226074
Validation loss: 2.0764667987823486

Epoch: 6| Step: 12
Training loss: 2.43867564201355
Validation loss: 2.088420887788137

Epoch: 6| Step: 13
Training loss: 2.382530689239502
Validation loss: 2.0853222211201987

Epoch: 143| Step: 0
Training loss: 1.6986935138702393
Validation loss: 2.0791757305463157

Epoch: 6| Step: 1
Training loss: 2.416614055633545
Validation loss: 2.0859233140945435

Epoch: 6| Step: 2
Training loss: 1.59432053565979
Validation loss: 2.0950406193733215

Epoch: 6| Step: 3
Training loss: 2.2870755195617676
Validation loss: 2.088703771432241

Epoch: 6| Step: 4
Training loss: 2.099022150039673
Validation loss: 2.073825716972351

Epoch: 6| Step: 5
Training loss: 2.1859450340270996
Validation loss: 2.081922094027201

Epoch: 6| Step: 6
Training loss: 1.9162951707839966
Validation loss: 2.0938609838485718

Epoch: 6| Step: 7
Training loss: 2.2592391967773438
Validation loss: 2.090283373991648

Epoch: 6| Step: 8
Training loss: 1.659314513206482
Validation loss: 2.078242520491282

Epoch: 6| Step: 9
Training loss: 2.103541851043701
Validation loss: 2.073539932568868

Epoch: 6| Step: 10
Training loss: 1.8120003938674927
Validation loss: 2.0727970600128174

Epoch: 6| Step: 11
Training loss: 2.1155216693878174
Validation loss: 2.06277068456014

Epoch: 6| Step: 12
Training loss: 1.885307788848877
Validation loss: 2.07977024714152

Epoch: 6| Step: 13
Training loss: 2.38116455078125
Validation loss: 2.0661339362462363

Epoch: 144| Step: 0
Training loss: 2.3026678562164307
Validation loss: 2.0707061290740967

Epoch: 6| Step: 1
Training loss: 2.5405471324920654
Validation loss: 2.0812580784161887

Epoch: 6| Step: 2
Training loss: 2.356997489929199
Validation loss: 2.1029367446899414

Epoch: 6| Step: 3
Training loss: 2.4151601791381836
Validation loss: 2.1090049346288047

Epoch: 6| Step: 4
Training loss: 1.8503448963165283
Validation loss: 2.117876092592875

Epoch: 6| Step: 5
Training loss: 1.8536295890808105
Validation loss: 2.1014609336853027

Epoch: 6| Step: 6
Training loss: 1.521274209022522
Validation loss: 2.083298842112223

Epoch: 6| Step: 7
Training loss: 2.2643675804138184
Validation loss: 2.086821754773458

Epoch: 6| Step: 8
Training loss: 1.5663843154907227
Validation loss: 2.0719021558761597

Epoch: 6| Step: 9
Training loss: 1.8053311109542847
Validation loss: 2.063051780064901

Epoch: 6| Step: 10
Training loss: 1.6880838871002197
Validation loss: 2.0644230445226035

Epoch: 6| Step: 11
Training loss: 2.2947516441345215
Validation loss: 2.0533533692359924

Epoch: 6| Step: 12
Training loss: 2.1371541023254395
Validation loss: 2.070541779200236

Epoch: 6| Step: 13
Training loss: 1.953066110610962
Validation loss: 2.0659143527348838

Epoch: 145| Step: 0
Training loss: 2.2732458114624023
Validation loss: 2.0791753133138022

Epoch: 6| Step: 1
Training loss: 1.2006922960281372
Validation loss: 2.0812648932139077

Epoch: 6| Step: 2
Training loss: 1.8526411056518555
Validation loss: 2.079076608022054

Epoch: 6| Step: 3
Training loss: 1.76655113697052
Validation loss: 2.070583383242289

Epoch: 6| Step: 4
Training loss: 1.8405500650405884
Validation loss: 2.0804099241892495

Epoch: 6| Step: 5
Training loss: 2.332469940185547
Validation loss: 2.0782782634099326

Epoch: 6| Step: 6
Training loss: 2.9582276344299316
Validation loss: 2.0734799901644387

Epoch: 6| Step: 7
Training loss: 2.3954148292541504
Validation loss: 2.055796047051748

Epoch: 6| Step: 8
Training loss: 1.97126042842865
Validation loss: 2.056022802988688

Epoch: 6| Step: 9
Training loss: 1.9387881755828857
Validation loss: 2.0634666681289673

Epoch: 6| Step: 10
Training loss: 2.0198512077331543
Validation loss: 2.0518443981806436

Epoch: 6| Step: 11
Training loss: 1.8559356927871704
Validation loss: 2.045244892438253

Epoch: 6| Step: 12
Training loss: 1.5167200565338135
Validation loss: 2.036355455716451

Epoch: 6| Step: 13
Training loss: 2.3552441596984863
Validation loss: 2.0369229316711426

Epoch: 146| Step: 0
Training loss: 1.9434186220169067
Validation loss: 2.0421677231788635

Epoch: 6| Step: 1
Training loss: 2.633789300918579
Validation loss: 2.0387316147486367

Epoch: 6| Step: 2
Training loss: 1.4689613580703735
Validation loss: 2.0415321389834085

Epoch: 6| Step: 3
Training loss: 1.8137840032577515
Validation loss: 2.043233791987101

Epoch: 6| Step: 4
Training loss: 2.268435001373291
Validation loss: 2.040259003639221

Epoch: 6| Step: 5
Training loss: 2.1434547901153564
Validation loss: 2.037054101626078

Epoch: 6| Step: 6
Training loss: 1.9283277988433838
Validation loss: 2.0450594425201416

Epoch: 6| Step: 7
Training loss: 2.3482656478881836
Validation loss: 2.0584291219711304

Epoch: 6| Step: 8
Training loss: 1.9971612691879272
Validation loss: 2.079022765159607

Epoch: 6| Step: 9
Training loss: 2.0049948692321777
Validation loss: 2.082905193169912

Epoch: 6| Step: 10
Training loss: 2.241957664489746
Validation loss: 2.0801763335863748

Epoch: 6| Step: 11
Training loss: 1.782698631286621
Validation loss: 2.0933969616889954

Epoch: 6| Step: 12
Training loss: 2.0719850063323975
Validation loss: 2.0865714947382608

Epoch: 6| Step: 13
Training loss: 1.9424071311950684
Validation loss: 2.0906174778938293

Epoch: 147| Step: 0
Training loss: 1.552005410194397
Validation loss: 2.078108012676239

Epoch: 6| Step: 1
Training loss: 1.9886335134506226
Validation loss: 2.084346354007721

Epoch: 6| Step: 2
Training loss: 1.962446928024292
Validation loss: 2.0589901010195413

Epoch: 6| Step: 3
Training loss: 2.1277432441711426
Validation loss: 2.068414568901062

Epoch: 6| Step: 4
Training loss: 2.1773343086242676
Validation loss: 2.0650596817334494

Epoch: 6| Step: 5
Training loss: 2.016191005706787
Validation loss: 2.0534623662630715

Epoch: 6| Step: 6
Training loss: 2.0605268478393555
Validation loss: 2.051969607671102

Epoch: 6| Step: 7
Training loss: 1.7548959255218506
Validation loss: 2.0602066914240518

Epoch: 6| Step: 8
Training loss: 2.105496406555176
Validation loss: 2.058391749858856

Epoch: 6| Step: 9
Training loss: 2.1142921447753906
Validation loss: 2.057073791821798

Epoch: 6| Step: 10
Training loss: 2.4439797401428223
Validation loss: 2.0608378648757935

Epoch: 6| Step: 11
Training loss: 2.7937231063842773
Validation loss: 2.065086007118225

Epoch: 6| Step: 12
Training loss: 1.9853296279907227
Validation loss: 2.0666406750679016

Epoch: 6| Step: 13
Training loss: 1.7400007247924805
Validation loss: 2.0720489621162415

Epoch: 148| Step: 0
Training loss: 2.1492176055908203
Validation loss: 2.0945762197176614

Epoch: 6| Step: 1
Training loss: 2.1039276123046875
Validation loss: 2.0807535648345947

Epoch: 6| Step: 2
Training loss: 1.6323260068893433
Validation loss: 2.092024485270182

Epoch: 6| Step: 3
Training loss: 1.3849151134490967
Validation loss: 2.106351355711619

Epoch: 6| Step: 4
Training loss: 1.995189905166626
Validation loss: 2.1146434942881265

Epoch: 6| Step: 5
Training loss: 1.7455052137374878
Validation loss: 2.114838798840841

Epoch: 6| Step: 6
Training loss: 2.6992335319519043
Validation loss: 2.122751156489054

Epoch: 6| Step: 7
Training loss: 2.119992971420288
Validation loss: 2.1042487223943076

Epoch: 6| Step: 8
Training loss: 2.3241469860076904
Validation loss: 2.081200917561849

Epoch: 6| Step: 9
Training loss: 2.3825035095214844
Validation loss: 2.066208283106486

Epoch: 6| Step: 10
Training loss: 1.879746675491333
Validation loss: 2.0639765858650208

Epoch: 6| Step: 11
Training loss: 2.499560832977295
Validation loss: 2.0575634837150574

Epoch: 6| Step: 12
Training loss: 1.849778175354004
Validation loss: 2.052861452102661

Epoch: 6| Step: 13
Training loss: 2.126491069793701
Validation loss: 2.048062284787496

Epoch: 149| Step: 0
Training loss: 1.752759575843811
Validation loss: 2.048716723918915

Epoch: 6| Step: 1
Training loss: 1.4831548929214478
Validation loss: 2.0556936661402383

Epoch: 6| Step: 2
Training loss: 1.8523601293563843
Validation loss: 2.0535937746365867

Epoch: 6| Step: 3
Training loss: 1.8988438844680786
Validation loss: 2.0544967651367188

Epoch: 6| Step: 4
Training loss: 1.9521733522415161
Validation loss: 2.0638359586397805

Epoch: 6| Step: 5
Training loss: 2.149845600128174
Validation loss: 2.0679033597310386

Epoch: 6| Step: 6
Training loss: 2.439605236053467
Validation loss: 2.0582215785980225

Epoch: 6| Step: 7
Training loss: 2.3626997470855713
Validation loss: 2.0777557690938315

Epoch: 6| Step: 8
Training loss: 2.209648609161377
Validation loss: 2.077765961488088

Epoch: 6| Step: 9
Training loss: 2.1401143074035645
Validation loss: 2.0811551809310913

Epoch: 6| Step: 10
Training loss: 1.7990165948867798
Validation loss: 2.0898958841959634

Epoch: 6| Step: 11
Training loss: 2.339360237121582
Validation loss: 2.081369916598002

Epoch: 6| Step: 12
Training loss: 2.1021926403045654
Validation loss: 2.084455410639445

Epoch: 6| Step: 13
Training loss: 1.9026871919631958
Validation loss: 2.0988968213399253

Epoch: 150| Step: 0
Training loss: 1.9454598426818848
Validation loss: 2.0742210745811462

Epoch: 6| Step: 1
Training loss: 1.6605515480041504
Validation loss: 2.0963118275006614

Epoch: 6| Step: 2
Training loss: 1.2998614311218262
Validation loss: 2.0804888208707175

Epoch: 6| Step: 3
Training loss: 1.9059141874313354
Validation loss: 2.084251642227173

Epoch: 6| Step: 4
Training loss: 2.8073978424072266
Validation loss: 2.095357040564219

Epoch: 6| Step: 5
Training loss: 2.2140231132507324
Validation loss: 2.103765308856964

Epoch: 6| Step: 6
Training loss: 2.247112989425659
Validation loss: 2.0807459354400635

Epoch: 6| Step: 7
Training loss: 1.8891010284423828
Validation loss: 2.077418565750122

Epoch: 6| Step: 8
Training loss: 1.8033469915390015
Validation loss: 2.0731988151868186

Epoch: 6| Step: 9
Training loss: 1.588608741760254
Validation loss: 2.0625682274500527

Epoch: 6| Step: 10
Training loss: 2.0022125244140625
Validation loss: 2.06322850783666

Epoch: 6| Step: 11
Training loss: 2.4149506092071533
Validation loss: 2.053634981314341

Epoch: 6| Step: 12
Training loss: 2.1594316959381104
Validation loss: 2.0668638944625854

Epoch: 6| Step: 13
Training loss: 2.251427173614502
Validation loss: 2.0568449099858603

Epoch: 151| Step: 0
Training loss: 2.4574551582336426
Validation loss: 2.074657698472341

Epoch: 6| Step: 1
Training loss: 2.641248941421509
Validation loss: 2.0711729526519775

Epoch: 6| Step: 2
Training loss: 2.2486116886138916
Validation loss: 2.060095647970835

Epoch: 6| Step: 3
Training loss: 1.3991644382476807
Validation loss: 2.0678556760152182

Epoch: 6| Step: 4
Training loss: 1.9132053852081299
Validation loss: 2.082955280939738

Epoch: 6| Step: 5
Training loss: 2.0593905448913574
Validation loss: 2.0848732391993203

Epoch: 6| Step: 6
Training loss: 2.493229389190674
Validation loss: 2.0877116521199546

Epoch: 6| Step: 7
Training loss: 2.049999713897705
Validation loss: 2.092541972796122

Epoch: 6| Step: 8
Training loss: 1.7607109546661377
Validation loss: 2.08858052889506

Epoch: 6| Step: 9
Training loss: 1.5505801439285278
Validation loss: 2.086586892604828

Epoch: 6| Step: 10
Training loss: 1.6407017707824707
Validation loss: 2.0935529470443726

Epoch: 6| Step: 11
Training loss: 1.732515573501587
Validation loss: 2.087312380472819

Epoch: 6| Step: 12
Training loss: 1.546384572982788
Validation loss: 2.0774261554082236

Epoch: 6| Step: 13
Training loss: 2.629528760910034
Validation loss: 2.062172849973043

Epoch: 152| Step: 0
Training loss: 1.419740915298462
Validation loss: 2.0644227464993796

Epoch: 6| Step: 1
Training loss: 1.708886981010437
Validation loss: 2.0760533014933267

Epoch: 6| Step: 2
Training loss: 2.652209520339966
Validation loss: 2.089422603448232

Epoch: 6| Step: 3
Training loss: 2.306928873062134
Validation loss: 2.0759097735087075

Epoch: 6| Step: 4
Training loss: 2.078547716140747
Validation loss: 2.070501705010732

Epoch: 6| Step: 5
Training loss: 1.4528558254241943
Validation loss: 2.0741077860196433

Epoch: 6| Step: 6
Training loss: 2.07405161857605
Validation loss: 2.063959002494812

Epoch: 6| Step: 7
Training loss: 1.789483666419983
Validation loss: 2.058306634426117

Epoch: 6| Step: 8
Training loss: 2.1678824424743652
Validation loss: 2.0599488615989685

Epoch: 6| Step: 9
Training loss: 2.093689441680908
Validation loss: 2.066308339436849

Epoch: 6| Step: 10
Training loss: 2.253408908843994
Validation loss: 2.068224092324575

Epoch: 6| Step: 11
Training loss: 2.214376211166382
Validation loss: 2.0656583110491433

Epoch: 6| Step: 12
Training loss: 1.3764041662216187
Validation loss: 2.0666467348734536

Epoch: 6| Step: 13
Training loss: 2.425168752670288
Validation loss: 2.0755980213483176

Epoch: 153| Step: 0
Training loss: 2.1727635860443115
Validation loss: 2.0996629496415458

Epoch: 6| Step: 1
Training loss: 1.957979440689087
Validation loss: 2.0870099465052285

Epoch: 6| Step: 2
Training loss: 1.8500862121582031
Validation loss: 2.1235984166463218

Epoch: 6| Step: 3
Training loss: 2.278327226638794
Validation loss: 2.125283499558767

Epoch: 6| Step: 4
Training loss: 2.329738140106201
Validation loss: 2.104763905207316

Epoch: 6| Step: 5
Training loss: 1.6105804443359375
Validation loss: 2.120723783969879

Epoch: 6| Step: 6
Training loss: 2.4088058471679688
Validation loss: 2.106007178624471

Epoch: 6| Step: 7
Training loss: 1.5399585962295532
Validation loss: 2.0849278370539346

Epoch: 6| Step: 8
Training loss: 1.8530471324920654
Validation loss: 2.0701648791631064

Epoch: 6| Step: 9
Training loss: 1.6436347961425781
Validation loss: 2.076144496599833

Epoch: 6| Step: 10
Training loss: 2.1184566020965576
Validation loss: 2.0729004542032876

Epoch: 6| Step: 11
Training loss: 2.102436065673828
Validation loss: 2.066381017367045

Epoch: 6| Step: 12
Training loss: 2.2240548133850098
Validation loss: 2.0849154790242515

Epoch: 6| Step: 13
Training loss: 2.2704453468322754
Validation loss: 2.0888124306996665

Epoch: 154| Step: 0
Training loss: 2.195847988128662
Validation loss: 2.1017664869626365

Epoch: 6| Step: 1
Training loss: 2.1087214946746826
Validation loss: 2.101719697316488

Epoch: 6| Step: 2
Training loss: 2.128406286239624
Validation loss: 2.0866525967915854

Epoch: 6| Step: 3
Training loss: 1.631413459777832
Validation loss: 2.101171135902405

Epoch: 6| Step: 4
Training loss: 1.764464259147644
Validation loss: 2.083509842554728

Epoch: 6| Step: 5
Training loss: 2.3269972801208496
Validation loss: 2.0862512985865274

Epoch: 6| Step: 6
Training loss: 2.04821515083313
Validation loss: 2.090754667917887

Epoch: 6| Step: 7
Training loss: 2.2832114696502686
Validation loss: 2.092383027076721

Epoch: 6| Step: 8
Training loss: 1.2060003280639648
Validation loss: 2.0894113779067993

Epoch: 6| Step: 9
Training loss: 2.464852809906006
Validation loss: 2.09314093987147

Epoch: 6| Step: 10
Training loss: 2.089465856552124
Validation loss: 2.074643313884735

Epoch: 6| Step: 11
Training loss: 1.722537875175476
Validation loss: 2.0833434661229453

Epoch: 6| Step: 12
Training loss: 1.4681261777877808
Validation loss: 2.085066338380178

Epoch: 6| Step: 13
Training loss: 2.636383533477783
Validation loss: 2.0720090866088867

Epoch: 155| Step: 0
Training loss: 2.270329475402832
Validation loss: 2.0898918310801187

Epoch: 6| Step: 1
Training loss: 1.8548376560211182
Validation loss: 2.083052138487498

Epoch: 6| Step: 2
Training loss: 2.112872838973999
Validation loss: 2.0840951005617776

Epoch: 6| Step: 3
Training loss: 1.915565848350525
Validation loss: 2.0795475045839944

Epoch: 6| Step: 4
Training loss: 2.172934055328369
Validation loss: 2.0814563035964966

Epoch: 6| Step: 5
Training loss: 2.7471444606781006
Validation loss: 2.082244654496511

Epoch: 6| Step: 6
Training loss: 1.6678521633148193
Validation loss: 2.0808576941490173

Epoch: 6| Step: 7
Training loss: 1.2650256156921387
Validation loss: 2.090299606323242

Epoch: 6| Step: 8
Training loss: 1.85799241065979
Validation loss: 2.077613890171051

Epoch: 6| Step: 9
Training loss: 2.0692367553710938
Validation loss: 2.094075342019399

Epoch: 6| Step: 10
Training loss: 2.3329083919525146
Validation loss: 2.0961100260416665

Epoch: 6| Step: 11
Training loss: 1.7863094806671143
Validation loss: 2.092517137527466

Epoch: 6| Step: 12
Training loss: 1.9501516819000244
Validation loss: 2.0894619623819985

Epoch: 6| Step: 13
Training loss: 1.8482303619384766
Validation loss: 2.0862995982170105

Epoch: 156| Step: 0
Training loss: 2.2382144927978516
Validation loss: 2.0872525572776794

Epoch: 6| Step: 1
Training loss: 2.2441699504852295
Validation loss: 2.090542495250702

Epoch: 6| Step: 2
Training loss: 1.8090977668762207
Validation loss: 2.0923997362454734

Epoch: 6| Step: 3
Training loss: 2.2065653800964355
Validation loss: 2.0990448594093323

Epoch: 6| Step: 4
Training loss: 1.9586429595947266
Validation loss: 2.0850216150283813

Epoch: 6| Step: 5
Training loss: 2.0545883178710938
Validation loss: 2.0896224776903787

Epoch: 6| Step: 6
Training loss: 2.0027642250061035
Validation loss: 2.0844178994496665

Epoch: 6| Step: 7
Training loss: 1.3060097694396973
Validation loss: 2.087276836236318

Epoch: 6| Step: 8
Training loss: 2.172487735748291
Validation loss: 2.117026627063751

Epoch: 6| Step: 9
Training loss: 2.0922939777374268
Validation loss: 2.1040669282277427

Epoch: 6| Step: 10
Training loss: 1.751999020576477
Validation loss: 2.100746273994446

Epoch: 6| Step: 11
Training loss: 1.4899932146072388
Validation loss: 2.0838074684143066

Epoch: 6| Step: 12
Training loss: 2.5055079460144043
Validation loss: 2.1002033948898315

Epoch: 6| Step: 13
Training loss: 2.0291643142700195
Validation loss: 2.092081348101298

Epoch: 157| Step: 0
Training loss: 2.0686357021331787
Validation loss: 2.098038673400879

Epoch: 6| Step: 1
Training loss: 1.9519349336624146
Validation loss: 2.0956207116444907

Epoch: 6| Step: 2
Training loss: 2.0038163661956787
Validation loss: 2.0848591327667236

Epoch: 6| Step: 3
Training loss: 2.127070426940918
Validation loss: 2.0860294500986734

Epoch: 6| Step: 4
Training loss: 2.6082866191864014
Validation loss: 2.0895687540372214

Epoch: 6| Step: 5
Training loss: 1.5682991743087769
Validation loss: 2.0837222139040628

Epoch: 6| Step: 6
Training loss: 1.608473300933838
Validation loss: 2.094074070453644

Epoch: 6| Step: 7
Training loss: 1.6279736757278442
Validation loss: 2.092616617679596

Epoch: 6| Step: 8
Training loss: 2.0554120540618896
Validation loss: 2.110270341237386

Epoch: 6| Step: 9
Training loss: 2.268111228942871
Validation loss: 2.1015851497650146

Epoch: 6| Step: 10
Training loss: 1.7965943813323975
Validation loss: 2.109782099723816

Epoch: 6| Step: 11
Training loss: 2.218942880630493
Validation loss: 2.0934327840805054

Epoch: 6| Step: 12
Training loss: 1.7736810445785522
Validation loss: 2.0917013684908548

Epoch: 6| Step: 13
Training loss: 2.1797051429748535
Validation loss: 2.073882003625234

Epoch: 158| Step: 0
Training loss: 2.2037160396575928
Validation loss: 2.0661399761835733

Epoch: 6| Step: 1
Training loss: 2.132056713104248
Validation loss: 2.0648783246676126

Epoch: 6| Step: 2
Training loss: 1.9972877502441406
Validation loss: 2.0671160221099854

Epoch: 6| Step: 3
Training loss: 1.81925368309021
Validation loss: 2.0549457669258118

Epoch: 6| Step: 4
Training loss: 1.7112014293670654
Validation loss: 2.068552235762278

Epoch: 6| Step: 5
Training loss: 2.045595645904541
Validation loss: 2.0788572827974954

Epoch: 6| Step: 6
Training loss: 1.8014452457427979
Validation loss: 2.070050299167633

Epoch: 6| Step: 7
Training loss: 2.0863213539123535
Validation loss: 2.0914172530174255

Epoch: 6| Step: 8
Training loss: 2.032019853591919
Validation loss: 2.1201526323954263

Epoch: 6| Step: 9
Training loss: 1.435903787612915
Validation loss: 2.107554276784261

Epoch: 6| Step: 10
Training loss: 1.7881325483322144
Validation loss: 2.132122198740641

Epoch: 6| Step: 11
Training loss: 2.047999620437622
Validation loss: 2.1304182012875876

Epoch: 6| Step: 12
Training loss: 2.151827096939087
Validation loss: 2.1122374534606934

Epoch: 6| Step: 13
Training loss: 2.7974472045898438
Validation loss: 2.1140562693277993

Epoch: 159| Step: 0
Training loss: 2.0655064582824707
Validation loss: 2.096709191799164

Epoch: 6| Step: 1
Training loss: 1.6882580518722534
Validation loss: 2.087743639945984

Epoch: 6| Step: 2
Training loss: 2.2161970138549805
Validation loss: 2.0762081940968833

Epoch: 6| Step: 3
Training loss: 1.9487817287445068
Validation loss: 2.0859780311584473

Epoch: 6| Step: 4
Training loss: 1.868852138519287
Validation loss: 2.073129177093506

Epoch: 6| Step: 5
Training loss: 1.765777349472046
Validation loss: 2.0713964303334556

Epoch: 6| Step: 6
Training loss: 2.1023030281066895
Validation loss: 2.0624656478563943

Epoch: 6| Step: 7
Training loss: 1.4889377355575562
Validation loss: 2.066482186317444

Epoch: 6| Step: 8
Training loss: 2.0812506675720215
Validation loss: 2.0765907367070517

Epoch: 6| Step: 9
Training loss: 2.0656230449676514
Validation loss: 2.090029855569204

Epoch: 6| Step: 10
Training loss: 1.7151854038238525
Validation loss: 2.086219827334086

Epoch: 6| Step: 11
Training loss: 1.7112821340560913
Validation loss: 2.076020081837972

Epoch: 6| Step: 12
Training loss: 2.5096635818481445
Validation loss: 2.0900745590527854

Epoch: 6| Step: 13
Training loss: 2.5023398399353027
Validation loss: 2.092058539390564

Epoch: 160| Step: 0
Training loss: 1.9093546867370605
Validation loss: 2.098023513952891

Epoch: 6| Step: 1
Training loss: 1.5567044019699097
Validation loss: 2.1009419759114585

Epoch: 6| Step: 2
Training loss: 1.2984628677368164
Validation loss: 2.109136919180552

Epoch: 6| Step: 3
Training loss: 2.1578285694122314
Validation loss: 2.0972126921017966

Epoch: 6| Step: 4
Training loss: 1.8742446899414062
Validation loss: 2.0942216515541077

Epoch: 6| Step: 5
Training loss: 1.8041998147964478
Validation loss: 2.0937804182370505

Epoch: 6| Step: 6
Training loss: 1.5369601249694824
Validation loss: 2.0815056363741555

Epoch: 6| Step: 7
Training loss: 2.7290000915527344
Validation loss: 2.072682738304138

Epoch: 6| Step: 8
Training loss: 1.757634162902832
Validation loss: 2.0799293716748557

Epoch: 6| Step: 9
Training loss: 2.6128196716308594
Validation loss: 2.089213232199351

Epoch: 6| Step: 10
Training loss: 1.937371015548706
Validation loss: 2.0970426003138223

Epoch: 6| Step: 11
Training loss: 2.5450122356414795
Validation loss: 2.0886467695236206

Epoch: 6| Step: 12
Training loss: 1.901451587677002
Validation loss: 2.091018815835317

Epoch: 6| Step: 13
Training loss: 2.202821969985962
Validation loss: 2.087798078854879

Epoch: 161| Step: 0
Training loss: 2.0717599391937256
Validation loss: 2.1024746894836426

Epoch: 6| Step: 1
Training loss: 2.045898199081421
Validation loss: 2.099679390589396

Epoch: 6| Step: 2
Training loss: 1.7849657535552979
Validation loss: 2.093500097592672

Epoch: 6| Step: 3
Training loss: 2.0889787673950195
Validation loss: 2.0833040674527488

Epoch: 6| Step: 4
Training loss: 1.7307919263839722
Validation loss: 2.0829609831174216

Epoch: 6| Step: 5
Training loss: 2.094510078430176
Validation loss: 2.087373514970144

Epoch: 6| Step: 6
Training loss: 1.7601736783981323
Validation loss: 2.088873783747355

Epoch: 6| Step: 7
Training loss: 2.2392685413360596
Validation loss: 2.0925948222478232

Epoch: 6| Step: 8
Training loss: 1.4491634368896484
Validation loss: 2.0972744623819985

Epoch: 6| Step: 9
Training loss: 2.356288433074951
Validation loss: 2.1094446976979575

Epoch: 6| Step: 10
Training loss: 1.4861664772033691
Validation loss: 2.1052929162979126

Epoch: 6| Step: 11
Training loss: 2.708834648132324
Validation loss: 2.0945796370506287

Epoch: 6| Step: 12
Training loss: 2.0307888984680176
Validation loss: 2.101416031519572

Epoch: 6| Step: 13
Training loss: 2.041511058807373
Validation loss: 2.1063037316004434

Epoch: 162| Step: 0
Training loss: 1.2401701211929321
Validation loss: 2.095234235127767

Epoch: 6| Step: 1
Training loss: 1.995081901550293
Validation loss: 2.088432729244232

Epoch: 6| Step: 2
Training loss: 2.0750932693481445
Validation loss: 2.086013694604238

Epoch: 6| Step: 3
Training loss: 1.7620353698730469
Validation loss: 2.0830119252204895

Epoch: 6| Step: 4
Training loss: 1.5479471683502197
Validation loss: 2.079431335131327

Epoch: 6| Step: 5
Training loss: 1.725706934928894
Validation loss: 2.0697482426961265

Epoch: 6| Step: 6
Training loss: 2.2972702980041504
Validation loss: 2.0637663205464682

Epoch: 6| Step: 7
Training loss: 2.265265464782715
Validation loss: 2.065514107545217

Epoch: 6| Step: 8
Training loss: 2.390288829803467
Validation loss: 2.077309330304464

Epoch: 6| Step: 9
Training loss: 1.7443692684173584
Validation loss: 2.069037894407908

Epoch: 6| Step: 10
Training loss: 1.9445239305496216
Validation loss: 2.0632457733154297

Epoch: 6| Step: 11
Training loss: 2.220017433166504
Validation loss: 2.0661866068840027

Epoch: 6| Step: 12
Training loss: 2.129840135574341
Validation loss: 2.0714247624079385

Epoch: 6| Step: 13
Training loss: 2.5870301723480225
Validation loss: 2.077119449774424

Epoch: 163| Step: 0
Training loss: 1.6675746440887451
Validation loss: 2.084067483743032

Epoch: 6| Step: 1
Training loss: 1.5917130708694458
Validation loss: 2.0952932834625244

Epoch: 6| Step: 2
Training loss: 2.1910722255706787
Validation loss: 2.0904656648635864

Epoch: 6| Step: 3
Training loss: 1.7687736749649048
Validation loss: 2.091680924097697

Epoch: 6| Step: 4
Training loss: 1.8330541849136353
Validation loss: 2.079867204030355

Epoch: 6| Step: 5
Training loss: 2.8818273544311523
Validation loss: 2.089436888694763

Epoch: 6| Step: 6
Training loss: 2.6330504417419434
Validation loss: 2.0929831663767495

Epoch: 6| Step: 7
Training loss: 1.8804242610931396
Validation loss: 2.1085266868273416

Epoch: 6| Step: 8
Training loss: 1.968395471572876
Validation loss: 2.111328125

Epoch: 6| Step: 9
Training loss: 1.5631791353225708
Validation loss: 2.112054467201233

Epoch: 6| Step: 10
Training loss: 2.113703727722168
Validation loss: 2.1224290132522583

Epoch: 6| Step: 11
Training loss: 1.8959146738052368
Validation loss: 2.1150821844736734

Epoch: 6| Step: 12
Training loss: 1.9649996757507324
Validation loss: 2.090891738732656

Epoch: 6| Step: 13
Training loss: 1.507214903831482
Validation loss: 2.078058381875356

Epoch: 164| Step: 0
Training loss: 1.7557990550994873
Validation loss: 2.069137692451477

Epoch: 6| Step: 1
Training loss: 1.553824543952942
Validation loss: 2.059139390786489

Epoch: 6| Step: 2
Training loss: 2.2336103916168213
Validation loss: 2.059674302736918

Epoch: 6| Step: 3
Training loss: 1.8711153268814087
Validation loss: 2.068173110485077

Epoch: 6| Step: 4
Training loss: 2.151468515396118
Validation loss: 2.082956155141195

Epoch: 6| Step: 5
Training loss: 2.5820531845092773
Validation loss: 2.0976932446161904

Epoch: 6| Step: 6
Training loss: 2.1476387977600098
Validation loss: 2.098409334818522

Epoch: 6| Step: 7
Training loss: 2.380674123764038
Validation loss: 2.096778452396393

Epoch: 6| Step: 8
Training loss: 2.422156810760498
Validation loss: 2.108500043551127

Epoch: 6| Step: 9
Training loss: 2.1520140171051025
Validation loss: 2.1029369036356607

Epoch: 6| Step: 10
Training loss: 2.5048112869262695
Validation loss: 2.0960855881373086

Epoch: 6| Step: 11
Training loss: 1.9349188804626465
Validation loss: 2.086866001288096

Epoch: 6| Step: 12
Training loss: 2.4263100624084473
Validation loss: 2.0857656598091125

Epoch: 6| Step: 13
Training loss: 1.7855150699615479
Validation loss: 2.0741225481033325

Epoch: 165| Step: 0
Training loss: 1.7230310440063477
Validation loss: 2.0600685278574624

Epoch: 6| Step: 1
Training loss: 2.575380802154541
Validation loss: 2.059064567089081

Epoch: 6| Step: 2
Training loss: 2.3656301498413086
Validation loss: 2.068032443523407

Epoch: 6| Step: 3
Training loss: 2.2711644172668457
Validation loss: 2.060676614443461

Epoch: 6| Step: 4
Training loss: 1.924415111541748
Validation loss: 2.0538898507754006

Epoch: 6| Step: 5
Training loss: 1.862566351890564
Validation loss: 2.0748826265335083

Epoch: 6| Step: 6
Training loss: 2.621108293533325
Validation loss: 2.0925494035085044

Epoch: 6| Step: 7
Training loss: 1.7622277736663818
Validation loss: 2.09138822555542

Epoch: 6| Step: 8
Training loss: 2.3799643516540527
Validation loss: 2.108518918355306

Epoch: 6| Step: 9
Training loss: 2.2062151432037354
Validation loss: 2.10551255941391

Epoch: 6| Step: 10
Training loss: 1.7269716262817383
Validation loss: 2.0910510818163552

Epoch: 6| Step: 11
Training loss: 1.6922667026519775
Validation loss: 2.099085728327433

Epoch: 6| Step: 12
Training loss: 1.2339645624160767
Validation loss: 2.0827186703681946

Epoch: 6| Step: 13
Training loss: 1.9926044940948486
Validation loss: 2.0854733983675637

Epoch: 166| Step: 0
Training loss: 1.771510124206543
Validation loss: 2.084351599216461

Epoch: 6| Step: 1
Training loss: 1.6717290878295898
Validation loss: 2.0986164808273315

Epoch: 6| Step: 2
Training loss: 2.226576089859009
Validation loss: 2.082197586695353

Epoch: 6| Step: 3
Training loss: 2.434420585632324
Validation loss: 2.0840002298355103

Epoch: 6| Step: 4
Training loss: 2.1182150840759277
Validation loss: 2.081728537877401

Epoch: 6| Step: 5
Training loss: 2.2916488647460938
Validation loss: 2.0937190850575766

Epoch: 6| Step: 6
Training loss: 2.2435545921325684
Validation loss: 2.0859044194221497

Epoch: 6| Step: 7
Training loss: 2.416816234588623
Validation loss: 2.0876089334487915

Epoch: 6| Step: 8
Training loss: 1.3014438152313232
Validation loss: 2.0980481108029685

Epoch: 6| Step: 9
Training loss: 1.484344720840454
Validation loss: 2.096624573071798

Epoch: 6| Step: 10
Training loss: 2.240645170211792
Validation loss: 2.1005736788113913

Epoch: 6| Step: 11
Training loss: 1.6674127578735352
Validation loss: 2.099599560101827

Epoch: 6| Step: 12
Training loss: 1.9356389045715332
Validation loss: 2.0893285473187766

Epoch: 6| Step: 13
Training loss: 1.6687049865722656
Validation loss: 2.1186107794443765

Epoch: 167| Step: 0
Training loss: 1.9856551885604858
Validation loss: 2.1090563337008157

Epoch: 6| Step: 1
Training loss: 2.8479719161987305
Validation loss: 2.1299094955126443

Epoch: 6| Step: 2
Training loss: 1.9118797779083252
Validation loss: 2.1139963269233704

Epoch: 6| Step: 3
Training loss: 1.4717990159988403
Validation loss: 2.1055801113446555

Epoch: 6| Step: 4
Training loss: 2.1666324138641357
Validation loss: 2.104307154814402

Epoch: 6| Step: 5
Training loss: 1.9066494703292847
Validation loss: 2.0944358110427856

Epoch: 6| Step: 6
Training loss: 1.947946548461914
Validation loss: 2.0930365920066833

Epoch: 6| Step: 7
Training loss: 2.2065701484680176
Validation loss: 2.098574161529541

Epoch: 6| Step: 8
Training loss: 2.37361478805542
Validation loss: 2.0892597436904907

Epoch: 6| Step: 9
Training loss: 1.6988154649734497
Validation loss: 2.111880441506704

Epoch: 6| Step: 10
Training loss: 1.4860749244689941
Validation loss: 2.0887595415115356

Epoch: 6| Step: 11
Training loss: 1.8694052696228027
Validation loss: 2.0923273960749307

Epoch: 6| Step: 12
Training loss: 1.5597184896469116
Validation loss: 2.121608078479767

Epoch: 6| Step: 13
Training loss: 2.2787864208221436
Validation loss: 2.1125144163767495

Epoch: 168| Step: 0
Training loss: 2.1177141666412354
Validation loss: 2.1307850082715354

Epoch: 6| Step: 1
Training loss: 1.9603543281555176
Validation loss: 2.140735467274984

Epoch: 6| Step: 2
Training loss: 1.8363888263702393
Validation loss: 2.15644641717275

Epoch: 6| Step: 3
Training loss: 1.7252534627914429
Validation loss: 2.1258027950922647

Epoch: 6| Step: 4
Training loss: 2.0103774070739746
Validation loss: 2.15251495440801

Epoch: 6| Step: 5
Training loss: 2.4024956226348877
Validation loss: 2.121102730433146

Epoch: 6| Step: 6
Training loss: 2.1505775451660156
Validation loss: 2.121924857298533

Epoch: 6| Step: 7
Training loss: 1.565057635307312
Validation loss: 2.1091763575871787

Epoch: 6| Step: 8
Training loss: 2.0762827396392822
Validation loss: 2.1040613452593484

Epoch: 6| Step: 9
Training loss: 1.934759497642517
Validation loss: 2.0938841303189597

Epoch: 6| Step: 10
Training loss: 1.9843769073486328
Validation loss: 2.0955268144607544

Epoch: 6| Step: 11
Training loss: 1.9825568199157715
Validation loss: 2.0917611122131348

Epoch: 6| Step: 12
Training loss: 1.8081059455871582
Validation loss: 2.090367913246155

Epoch: 6| Step: 13
Training loss: 2.2554407119750977
Validation loss: 2.0868112246195474

Epoch: 169| Step: 0
Training loss: 2.675192356109619
Validation loss: 2.0877925952275596

Epoch: 6| Step: 1
Training loss: 1.8598628044128418
Validation loss: 2.098569313685099

Epoch: 6| Step: 2
Training loss: 1.341511845588684
Validation loss: 2.1099595030148826

Epoch: 6| Step: 3
Training loss: 2.0809764862060547
Validation loss: 2.115018844604492

Epoch: 6| Step: 4
Training loss: 1.8996257781982422
Validation loss: 2.141050179799398

Epoch: 6| Step: 5
Training loss: 1.3712825775146484
Validation loss: 2.1345643599828086

Epoch: 6| Step: 6
Training loss: 2.0070996284484863
Validation loss: 2.1289098858833313

Epoch: 6| Step: 7
Training loss: 2.3332793712615967
Validation loss: 2.1355013648668923

Epoch: 6| Step: 8
Training loss: 2.262962579727173
Validation loss: 2.115764796733856

Epoch: 6| Step: 9
Training loss: 1.8947417736053467
Validation loss: 2.117804447809855

Epoch: 6| Step: 10
Training loss: 2.073965549468994
Validation loss: 2.09930811325709

Epoch: 6| Step: 11
Training loss: 2.243354320526123
Validation loss: 2.087368885676066

Epoch: 6| Step: 12
Training loss: 1.9376611709594727
Validation loss: 2.0933961470921836

Epoch: 6| Step: 13
Training loss: 1.9520879983901978
Validation loss: 2.0880536635716758

Epoch: 170| Step: 0
Training loss: 2.3641774654388428
Validation loss: 2.0759911139806113

Epoch: 6| Step: 1
Training loss: 2.2284140586853027
Validation loss: 2.081375002861023

Epoch: 6| Step: 2
Training loss: 2.0091493129730225
Validation loss: 2.070533017317454

Epoch: 6| Step: 3
Training loss: 1.8712431192398071
Validation loss: 2.077979107697805

Epoch: 6| Step: 4
Training loss: 1.8233007192611694
Validation loss: 2.061399062474569

Epoch: 6| Step: 5
Training loss: 1.5602879524230957
Validation loss: 2.074961264928182

Epoch: 6| Step: 6
Training loss: 1.5145165920257568
Validation loss: 2.0664203763008118

Epoch: 6| Step: 7
Training loss: 2.172524929046631
Validation loss: 2.099982798099518

Epoch: 6| Step: 8
Training loss: 2.3651957511901855
Validation loss: 2.090210974216461

Epoch: 6| Step: 9
Training loss: 1.56611967086792
Validation loss: 2.1028979619344077

Epoch: 6| Step: 10
Training loss: 2.2682278156280518
Validation loss: 2.1078978975613913

Epoch: 6| Step: 11
Training loss: 2.0345864295959473
Validation loss: 2.1004433234532676

Epoch: 6| Step: 12
Training loss: 2.4483728408813477
Validation loss: 2.1057262420654297

Epoch: 6| Step: 13
Training loss: 1.7291157245635986
Validation loss: 2.124932070573171

Epoch: 171| Step: 0
Training loss: 1.533596158027649
Validation loss: 2.1040005683898926

Epoch: 6| Step: 1
Training loss: 2.0070960521698
Validation loss: 2.1000487407048545

Epoch: 6| Step: 2
Training loss: 1.417007327079773
Validation loss: 2.0988584756851196

Epoch: 6| Step: 3
Training loss: 1.7662391662597656
Validation loss: 2.0978206197420755

Epoch: 6| Step: 4
Training loss: 2.321547746658325
Validation loss: 2.1022746562957764

Epoch: 6| Step: 5
Training loss: 1.756077527999878
Validation loss: 2.1035942236582437

Epoch: 6| Step: 6
Training loss: 1.7360577583312988
Validation loss: 2.095168431599935

Epoch: 6| Step: 7
Training loss: 1.7615172863006592
Validation loss: 2.075130740801493

Epoch: 6| Step: 8
Training loss: 2.49808406829834
Validation loss: 2.072649657726288

Epoch: 6| Step: 9
Training loss: 2.758759021759033
Validation loss: 2.07193652788798

Epoch: 6| Step: 10
Training loss: 2.0460524559020996
Validation loss: 2.072568416595459

Epoch: 6| Step: 11
Training loss: 2.31097412109375
Validation loss: 2.065072218577067

Epoch: 6| Step: 12
Training loss: 1.8117570877075195
Validation loss: 2.0741881926854453

Epoch: 6| Step: 13
Training loss: 2.4109432697296143
Validation loss: 2.0824413696924844

Epoch: 172| Step: 0
Training loss: 2.38580322265625
Validation loss: 2.079479734102885

Epoch: 6| Step: 1
Training loss: 1.74308443069458
Validation loss: 2.1048359672228494

Epoch: 6| Step: 2
Training loss: 1.568063497543335
Validation loss: 2.111057976881663

Epoch: 6| Step: 3
Training loss: 2.4148807525634766
Validation loss: 2.1124898195266724

Epoch: 6| Step: 4
Training loss: 2.0775461196899414
Validation loss: 2.0996448198954263

Epoch: 6| Step: 5
Training loss: 2.08333420753479
Validation loss: 2.104255755742391

Epoch: 6| Step: 6
Training loss: 2.4333248138427734
Validation loss: 2.0897676944732666

Epoch: 6| Step: 7
Training loss: 1.9587033987045288
Validation loss: 2.104267875353495

Epoch: 6| Step: 8
Training loss: 1.547157645225525
Validation loss: 2.1048060854276023

Epoch: 6| Step: 9
Training loss: 1.536476492881775
Validation loss: 2.09405654668808

Epoch: 6| Step: 10
Training loss: 1.6698089838027954
Validation loss: 2.1052146355311074

Epoch: 6| Step: 11
Training loss: 1.8033275604248047
Validation loss: 2.093825618426005

Epoch: 6| Step: 12
Training loss: 1.6987589597702026
Validation loss: 2.098580062389374

Epoch: 6| Step: 13
Training loss: 2.4411473274230957
Validation loss: 2.0978959798812866

Epoch: 173| Step: 0
Training loss: 2.073927640914917
Validation loss: 2.0984991788864136

Epoch: 6| Step: 1
Training loss: 1.540644645690918
Validation loss: 2.1000898480415344

Epoch: 6| Step: 2
Training loss: 1.5261512994766235
Validation loss: 2.098686456680298

Epoch: 6| Step: 3
Training loss: 2.2311391830444336
Validation loss: 2.09694105386734

Epoch: 6| Step: 4
Training loss: 1.735505223274231
Validation loss: 2.105259339014689

Epoch: 6| Step: 5
Training loss: 1.6660476922988892
Validation loss: 2.0997463862101235

Epoch: 6| Step: 6
Training loss: 2.4004108905792236
Validation loss: 2.0905678073565164

Epoch: 6| Step: 7
Training loss: 1.548367977142334
Validation loss: 2.102098365624746

Epoch: 6| Step: 8
Training loss: 2.405810832977295
Validation loss: 2.1121567487716675

Epoch: 6| Step: 9
Training loss: 1.8501113653182983
Validation loss: 2.1152716477711997

Epoch: 6| Step: 10
Training loss: 2.515408515930176
Validation loss: 2.1214650670687356

Epoch: 6| Step: 11
Training loss: 1.2290481328964233
Validation loss: 2.108153283596039

Epoch: 6| Step: 12
Training loss: 1.7450422048568726
Validation loss: 2.109099785486857

Epoch: 6| Step: 13
Training loss: 3.0324831008911133
Validation loss: 2.099481701850891

Epoch: 174| Step: 0
Training loss: 2.9469399452209473
Validation loss: 2.1100794275601706

Epoch: 6| Step: 1
Training loss: 1.999640703201294
Validation loss: 2.095983306566874

Epoch: 6| Step: 2
Training loss: 2.2075095176696777
Validation loss: 2.0985050797462463

Epoch: 6| Step: 3
Training loss: 1.184680700302124
Validation loss: 2.103773772716522

Epoch: 6| Step: 4
Training loss: 2.0235466957092285
Validation loss: 2.1182708740234375

Epoch: 6| Step: 5
Training loss: 2.009647846221924
Validation loss: 2.132791002591451

Epoch: 6| Step: 6
Training loss: 1.5893235206604004
Validation loss: 2.1278711358706155

Epoch: 6| Step: 7
Training loss: 2.023966073989868
Validation loss: 2.1416397094726562

Epoch: 6| Step: 8
Training loss: 1.984712839126587
Validation loss: 2.142559270064036

Epoch: 6| Step: 9
Training loss: 1.7161973714828491
Validation loss: 2.1334739526112876

Epoch: 6| Step: 10
Training loss: 1.8436341285705566
Validation loss: 2.1188328663508096

Epoch: 6| Step: 11
Training loss: 1.7869850397109985
Validation loss: 2.106430987517039

Epoch: 6| Step: 12
Training loss: 2.8269152641296387
Validation loss: 2.099988102912903

Epoch: 6| Step: 13
Training loss: 1.6952495574951172
Validation loss: 2.0870481133461

Epoch: 175| Step: 0
Training loss: 2.044049024581909
Validation loss: 2.075555602709452

Epoch: 6| Step: 1
Training loss: 2.1136603355407715
Validation loss: 2.0787904262542725

Epoch: 6| Step: 2
Training loss: 1.5516947507858276
Validation loss: 2.084648927052816

Epoch: 6| Step: 3
Training loss: 1.868960976600647
Validation loss: 2.085054179032644

Epoch: 6| Step: 4
Training loss: 2.00363826751709
Validation loss: 2.083617071310679

Epoch: 6| Step: 5
Training loss: 2.573568820953369
Validation loss: 2.0858179529507956

Epoch: 6| Step: 6
Training loss: 1.9500916004180908
Validation loss: 2.094688673814138

Epoch: 6| Step: 7
Training loss: 2.5448760986328125
Validation loss: 2.0881988207499185

Epoch: 6| Step: 8
Training loss: 1.9461008310317993
Validation loss: 2.093213438987732

Epoch: 6| Step: 9
Training loss: 2.288198947906494
Validation loss: 2.0907780130704245

Epoch: 6| Step: 10
Training loss: 2.3668808937072754
Validation loss: 2.093503932158152

Epoch: 6| Step: 11
Training loss: 1.456430435180664
Validation loss: 2.09600438674291

Epoch: 6| Step: 12
Training loss: 1.7782812118530273
Validation loss: 2.1093585093816123

Epoch: 6| Step: 13
Training loss: 2.193028211593628
Validation loss: 2.099980036417643

Epoch: 176| Step: 0
Training loss: 1.8497750759124756
Validation loss: 2.1116882960001626

Epoch: 6| Step: 1
Training loss: 2.063568592071533
Validation loss: 2.1150752107302346

Epoch: 6| Step: 2
Training loss: 1.9941213130950928
Validation loss: 2.100452462832133

Epoch: 6| Step: 3
Training loss: 2.5205538272857666
Validation loss: 2.1029526789983115

Epoch: 6| Step: 4
Training loss: 2.0179920196533203
Validation loss: 2.1102816462516785

Epoch: 6| Step: 5
Training loss: 1.8730201721191406
Validation loss: 2.105582853158315

Epoch: 6| Step: 6
Training loss: 1.5409482717514038
Validation loss: 2.1051119764645896

Epoch: 6| Step: 7
Training loss: 2.630626916885376
Validation loss: 2.1031582752863565

Epoch: 6| Step: 8
Training loss: 2.265871524810791
Validation loss: 2.102825403213501

Epoch: 6| Step: 9
Training loss: 1.6837668418884277
Validation loss: 2.1025591095288596

Epoch: 6| Step: 10
Training loss: 2.1684112548828125
Validation loss: 2.111250956853231

Epoch: 6| Step: 11
Training loss: 1.732800841331482
Validation loss: 2.0963730414708457

Epoch: 6| Step: 12
Training loss: 1.4655629396438599
Validation loss: 2.100836376349131

Epoch: 6| Step: 13
Training loss: 2.1789584159851074
Validation loss: 2.0855810046195984

Epoch: 177| Step: 0
Training loss: 2.2736363410949707
Validation loss: 2.106878916422526

Epoch: 6| Step: 1
Training loss: 1.7723069190979004
Validation loss: 2.0844930609067283

Epoch: 6| Step: 2
Training loss: 1.037863850593567
Validation loss: 2.0821046233177185

Epoch: 6| Step: 3
Training loss: 2.3736772537231445
Validation loss: 2.077722708384196

Epoch: 6| Step: 4
Training loss: 1.9250168800354004
Validation loss: 2.0763192574183145

Epoch: 6| Step: 5
Training loss: 1.5500880479812622
Validation loss: 2.0682114958763123

Epoch: 6| Step: 6
Training loss: 2.225024461746216
Validation loss: 2.074448068936666

Epoch: 6| Step: 7
Training loss: 2.3334860801696777
Validation loss: 2.0635667641957602

Epoch: 6| Step: 8
Training loss: 1.835991382598877
Validation loss: 2.0557809869448342

Epoch: 6| Step: 9
Training loss: 2.144989252090454
Validation loss: 2.064539114634196

Epoch: 6| Step: 10
Training loss: 2.046334743499756
Validation loss: 2.0618927081425986

Epoch: 6| Step: 11
Training loss: 1.9725100994110107
Validation loss: 2.072888652483622

Epoch: 6| Step: 12
Training loss: 2.3810601234436035
Validation loss: 2.064138650894165

Epoch: 6| Step: 13
Training loss: 2.1014652252197266
Validation loss: 2.065214455127716

Epoch: 178| Step: 0
Training loss: 2.3347272872924805
Validation loss: 2.06681619087855

Epoch: 6| Step: 1
Training loss: 1.6695325374603271
Validation loss: 2.06818825006485

Epoch: 6| Step: 2
Training loss: 2.189143419265747
Validation loss: 2.0682912468910217

Epoch: 6| Step: 3
Training loss: 2.158067226409912
Validation loss: 2.0720921754837036

Epoch: 6| Step: 4
Training loss: 1.9691063165664673
Validation loss: 2.0912352800369263

Epoch: 6| Step: 5
Training loss: 1.731992244720459
Validation loss: 2.0822181701660156

Epoch: 6| Step: 6
Training loss: 1.7068977355957031
Validation loss: 2.0805563728014627

Epoch: 6| Step: 7
Training loss: 1.447551965713501
Validation loss: 2.1024471322695413

Epoch: 6| Step: 8
Training loss: 2.1842589378356934
Validation loss: 2.0976816415786743

Epoch: 6| Step: 9
Training loss: 1.7850401401519775
Validation loss: 2.107718269030253

Epoch: 6| Step: 10
Training loss: 2.7900424003601074
Validation loss: 2.129559636116028

Epoch: 6| Step: 11
Training loss: 2.034186363220215
Validation loss: 2.126790225505829

Epoch: 6| Step: 12
Training loss: 1.4271278381347656
Validation loss: 2.117891490459442

Epoch: 6| Step: 13
Training loss: 2.073094367980957
Validation loss: 2.132251222928365

Epoch: 179| Step: 0
Training loss: 1.5492441654205322
Validation loss: 2.1188735961914062

Epoch: 6| Step: 1
Training loss: 1.2894532680511475
Validation loss: 2.1259668668111167

Epoch: 6| Step: 2
Training loss: 1.6820979118347168
Validation loss: 2.122710923353831

Epoch: 6| Step: 3
Training loss: 2.243856906890869
Validation loss: 2.1216005285580954

Epoch: 6| Step: 4
Training loss: 1.8883963823318481
Validation loss: 2.1202443838119507

Epoch: 6| Step: 5
Training loss: 1.6124060153961182
Validation loss: 2.130590240160624

Epoch: 6| Step: 6
Training loss: 2.395195722579956
Validation loss: 2.1172502636909485

Epoch: 6| Step: 7
Training loss: 1.741286039352417
Validation loss: 2.105317771434784

Epoch: 6| Step: 8
Training loss: 1.5344167947769165
Validation loss: 2.1212809085845947

Epoch: 6| Step: 9
Training loss: 2.222236156463623
Validation loss: 2.113844911257426

Epoch: 6| Step: 10
Training loss: 1.8954555988311768
Validation loss: 2.1124850312868753

Epoch: 6| Step: 11
Training loss: 2.432002544403076
Validation loss: 2.1246430476506553

Epoch: 6| Step: 12
Training loss: 2.7120707035064697
Validation loss: 2.114055852095286

Epoch: 6| Step: 13
Training loss: 2.2660651206970215
Validation loss: 2.1262170871098838

Epoch: 180| Step: 0
Training loss: 1.657853126525879
Validation loss: 2.119006315867106

Epoch: 6| Step: 1
Training loss: 2.001868724822998
Validation loss: 2.128609557946523

Epoch: 6| Step: 2
Training loss: 1.6435425281524658
Validation loss: 2.110701044400533

Epoch: 6| Step: 3
Training loss: 1.5871832370758057
Validation loss: 2.1051600178082785

Epoch: 6| Step: 4
Training loss: 1.5501788854599
Validation loss: 2.1049320300420127

Epoch: 6| Step: 5
Training loss: 2.4292659759521484
Validation loss: 2.108153680960337

Epoch: 6| Step: 6
Training loss: 1.962174415588379
Validation loss: 2.115009884039561

Epoch: 6| Step: 7
Training loss: 1.869425654411316
Validation loss: 2.100812077522278

Epoch: 6| Step: 8
Training loss: 2.623619556427002
Validation loss: 2.1107782125473022

Epoch: 6| Step: 9
Training loss: 1.6875004768371582
Validation loss: 2.090367019176483

Epoch: 6| Step: 10
Training loss: 1.9359633922576904
Validation loss: 2.1085963050524392

Epoch: 6| Step: 11
Training loss: 1.8828034400939941
Validation loss: 2.1018271446228027

Epoch: 6| Step: 12
Training loss: 2.0973780155181885
Validation loss: 2.100736677646637

Epoch: 6| Step: 13
Training loss: 2.2440459728240967
Validation loss: 2.1142746607462564

Epoch: 181| Step: 0
Training loss: 2.019550323486328
Validation loss: 2.126755634943644

Epoch: 6| Step: 1
Training loss: 1.771536946296692
Validation loss: 2.1295186479886374

Epoch: 6| Step: 2
Training loss: 2.097466230392456
Validation loss: 2.1150623758633933

Epoch: 6| Step: 3
Training loss: 2.7213969230651855
Validation loss: 2.114969809850057

Epoch: 6| Step: 4
Training loss: 2.0572640895843506
Validation loss: 2.105863928794861

Epoch: 6| Step: 5
Training loss: 1.7959412336349487
Validation loss: 2.111845374107361

Epoch: 6| Step: 6
Training loss: 2.0651073455810547
Validation loss: 2.108999808629354

Epoch: 6| Step: 7
Training loss: 1.5526684522628784
Validation loss: 2.1069775422414145

Epoch: 6| Step: 8
Training loss: 1.3490221500396729
Validation loss: 2.1079726219177246

Epoch: 6| Step: 9
Training loss: 2.115003824234009
Validation loss: 2.114257276058197

Epoch: 6| Step: 10
Training loss: 1.325930118560791
Validation loss: 2.1261391639709473

Epoch: 6| Step: 11
Training loss: 2.400175094604492
Validation loss: 2.1362860004107156

Epoch: 6| Step: 12
Training loss: 1.7305430173873901
Validation loss: 2.1369277238845825

Epoch: 6| Step: 13
Training loss: 2.1706669330596924
Validation loss: 2.1542090574900308

Epoch: 182| Step: 0
Training loss: 1.4756791591644287
Validation loss: 2.1363766392072043

Epoch: 6| Step: 1
Training loss: 1.5822540521621704
Validation loss: 2.1312456130981445

Epoch: 6| Step: 2
Training loss: 2.4666805267333984
Validation loss: 2.1392918030420938

Epoch: 6| Step: 3
Training loss: 1.8162384033203125
Validation loss: 2.1212201913197837

Epoch: 6| Step: 4
Training loss: 1.8139011859893799
Validation loss: 2.1192617217699685

Epoch: 6| Step: 5
Training loss: 1.6700439453125
Validation loss: 2.1131004889806113

Epoch: 6| Step: 6
Training loss: 2.1461758613586426
Validation loss: 2.0998802185058594

Epoch: 6| Step: 7
Training loss: 1.7400349378585815
Validation loss: 2.0888978242874146

Epoch: 6| Step: 8
Training loss: 0.9746475219726562
Validation loss: 2.1032830675443015

Epoch: 6| Step: 9
Training loss: 2.497194528579712
Validation loss: 2.0937159061431885

Epoch: 6| Step: 10
Training loss: 2.1348729133605957
Validation loss: 2.0991690357526145

Epoch: 6| Step: 11
Training loss: 2.56679630279541
Validation loss: 2.0976064205169678

Epoch: 6| Step: 12
Training loss: 2.257996082305908
Validation loss: 2.1057090759277344

Epoch: 6| Step: 13
Training loss: 2.221113681793213
Validation loss: 2.091988285382589

Epoch: 183| Step: 0
Training loss: 1.6774134635925293
Validation loss: 2.1128451029459634

Epoch: 6| Step: 1
Training loss: 1.8861193656921387
Validation loss: 2.112371484438578

Epoch: 6| Step: 2
Training loss: 1.9054142236709595
Validation loss: 2.1118869384129844

Epoch: 6| Step: 3
Training loss: 1.8082945346832275
Validation loss: 2.124998132387797

Epoch: 6| Step: 4
Training loss: 2.1886162757873535
Validation loss: 2.1319709618886313

Epoch: 6| Step: 5
Training loss: 2.4161112308502197
Validation loss: 2.1161096890767417

Epoch: 6| Step: 6
Training loss: 2.454852819442749
Validation loss: 2.1298806269963584

Epoch: 6| Step: 7
Training loss: 1.6457593441009521
Validation loss: 2.1322304010391235

Epoch: 6| Step: 8
Training loss: 1.8616029024124146
Validation loss: 2.150692582130432

Epoch: 6| Step: 9
Training loss: 1.8282307386398315
Validation loss: 2.1451088786125183

Epoch: 6| Step: 10
Training loss: 1.7451138496398926
Validation loss: 2.127736488978068

Epoch: 6| Step: 11
Training loss: 1.7936140298843384
Validation loss: 2.1218220591545105

Epoch: 6| Step: 12
Training loss: 2.3981785774230957
Validation loss: 2.119598646958669

Epoch: 6| Step: 13
Training loss: 1.7589997053146362
Validation loss: 2.1246259808540344

Epoch: 184| Step: 0
Training loss: 1.9594136476516724
Validation loss: 2.1238842805226645

Epoch: 6| Step: 1
Training loss: 1.9057666063308716
Validation loss: 2.1172606547673545

Epoch: 6| Step: 2
Training loss: 1.6630303859710693
Validation loss: 2.1126296321551004

Epoch: 6| Step: 3
Training loss: 1.32487154006958
Validation loss: 2.1209722757339478

Epoch: 6| Step: 4
Training loss: 1.0141551494598389
Validation loss: 2.1143738627433777

Epoch: 6| Step: 5
Training loss: 1.4350144863128662
Validation loss: 2.1107192436854043

Epoch: 6| Step: 6
Training loss: 2.392110586166382
Validation loss: 2.1208584705988565

Epoch: 6| Step: 7
Training loss: 1.8597261905670166
Validation loss: 2.106570521990458

Epoch: 6| Step: 8
Training loss: 1.868255376815796
Validation loss: 2.1276215513547263

Epoch: 6| Step: 9
Training loss: 2.2888448238372803
Validation loss: 2.1321029663085938

Epoch: 6| Step: 10
Training loss: 2.5153160095214844
Validation loss: 2.1432854930559793

Epoch: 6| Step: 11
Training loss: 2.281503200531006
Validation loss: 2.1397521098454795

Epoch: 6| Step: 12
Training loss: 2.365623950958252
Validation loss: 2.141138970851898

Epoch: 6| Step: 13
Training loss: 2.7022705078125
Validation loss: 2.1395259499549866

Epoch: 185| Step: 0
Training loss: 1.732804775238037
Validation loss: 2.152261177698771

Epoch: 6| Step: 1
Training loss: 1.5639936923980713
Validation loss: 2.1450587113698325

Epoch: 6| Step: 2
Training loss: 1.72324538230896
Validation loss: 2.1406533122062683

Epoch: 6| Step: 3
Training loss: 2.5119833946228027
Validation loss: 2.1105618675549827

Epoch: 6| Step: 4
Training loss: 1.6871503591537476
Validation loss: 2.1308809916178384

Epoch: 6| Step: 5
Training loss: 2.338857650756836
Validation loss: 2.099390963713328

Epoch: 6| Step: 6
Training loss: 2.2759130001068115
Validation loss: 2.105440159638723

Epoch: 6| Step: 7
Training loss: 1.6693094968795776
Validation loss: 2.0998946030934653

Epoch: 6| Step: 8
Training loss: 1.9339284896850586
Validation loss: 2.0869685808817544

Epoch: 6| Step: 9
Training loss: 2.629734992980957
Validation loss: 2.114284793535868

Epoch: 6| Step: 10
Training loss: 2.005215644836426
Validation loss: 2.0948596596717834

Epoch: 6| Step: 11
Training loss: 2.3111867904663086
Validation loss: 2.1153416434923806

Epoch: 6| Step: 12
Training loss: 1.6729297637939453
Validation loss: 2.1092760960261026

Epoch: 6| Step: 13
Training loss: 1.2088768482208252
Validation loss: 2.1039831042289734

Epoch: 186| Step: 0
Training loss: 2.094456195831299
Validation loss: 2.1372498273849487

Epoch: 6| Step: 1
Training loss: 1.754741907119751
Validation loss: 2.142212390899658

Epoch: 6| Step: 2
Training loss: 1.9155346155166626
Validation loss: 2.134891390800476

Epoch: 6| Step: 3
Training loss: 1.974422812461853
Validation loss: 2.138567407925924

Epoch: 6| Step: 4
Training loss: 1.4640530347824097
Validation loss: 2.133107622464498

Epoch: 6| Step: 5
Training loss: 2.4510529041290283
Validation loss: 2.1316450238227844

Epoch: 6| Step: 6
Training loss: 2.284666061401367
Validation loss: 2.125260591506958

Epoch: 6| Step: 7
Training loss: 2.093193769454956
Validation loss: 2.0921931664148965

Epoch: 6| Step: 8
Training loss: 1.6832953691482544
Validation loss: 2.100638469060262

Epoch: 6| Step: 9
Training loss: 2.450089454650879
Validation loss: 2.0921326677004495

Epoch: 6| Step: 10
Training loss: 1.679715633392334
Validation loss: 2.107050438721975

Epoch: 6| Step: 11
Training loss: 1.8663829565048218
Validation loss: 2.1022156278292337

Epoch: 6| Step: 12
Training loss: 2.104886770248413
Validation loss: 2.1121631860733032

Epoch: 6| Step: 13
Training loss: 1.6635832786560059
Validation loss: 2.1217024525006614

Epoch: 187| Step: 0
Training loss: 1.2257113456726074
Validation loss: 2.108465870221456

Epoch: 6| Step: 1
Training loss: 1.9329686164855957
Validation loss: 2.1123261054356894

Epoch: 6| Step: 2
Training loss: 2.052070140838623
Validation loss: 2.122753401597341

Epoch: 6| Step: 3
Training loss: 1.8654143810272217
Validation loss: 2.134994367758433

Epoch: 6| Step: 4
Training loss: 2.2469263076782227
Validation loss: 2.1364917159080505

Epoch: 6| Step: 5
Training loss: 1.923868179321289
Validation loss: 2.141446848710378

Epoch: 6| Step: 6
Training loss: 1.7682334184646606
Validation loss: 2.1366855104764304

Epoch: 6| Step: 7
Training loss: 2.238060235977173
Validation loss: 2.1335193514823914

Epoch: 6| Step: 8
Training loss: 1.7715706825256348
Validation loss: 2.1279406944910684

Epoch: 6| Step: 9
Training loss: 2.1426033973693848
Validation loss: 2.116430342197418

Epoch: 6| Step: 10
Training loss: 1.653897762298584
Validation loss: 2.1059219241142273

Epoch: 6| Step: 11
Training loss: 2.2827377319335938
Validation loss: 2.1037115454673767

Epoch: 6| Step: 12
Training loss: 2.2373275756835938
Validation loss: 2.0923571785291037

Epoch: 6| Step: 13
Training loss: 2.058149576187134
Validation loss: 2.094718277454376

Epoch: 188| Step: 0
Training loss: 1.9382742643356323
Validation loss: 2.0874685446421304

Epoch: 6| Step: 1
Training loss: 1.4728188514709473
Validation loss: 2.0957409342130027

Epoch: 6| Step: 2
Training loss: 2.4700353145599365
Validation loss: 2.0892394383748374

Epoch: 6| Step: 3
Training loss: 2.4013895988464355
Validation loss: 2.0999200145403543

Epoch: 6| Step: 4
Training loss: 2.251152753829956
Validation loss: 2.095396955808004

Epoch: 6| Step: 5
Training loss: 2.063822031021118
Validation loss: 2.1076321800549827

Epoch: 6| Step: 6
Training loss: 1.8835086822509766
Validation loss: 2.1198500792185464

Epoch: 6| Step: 7
Training loss: 1.6386479139328003
Validation loss: 2.110523740450541

Epoch: 6| Step: 8
Training loss: 1.709937334060669
Validation loss: 2.1103139321009317

Epoch: 6| Step: 9
Training loss: 1.806532382965088
Validation loss: 2.1190461913744607

Epoch: 6| Step: 10
Training loss: 1.6716673374176025
Validation loss: 2.1425167322158813

Epoch: 6| Step: 11
Training loss: 2.0856528282165527
Validation loss: 2.124309480190277

Epoch: 6| Step: 12
Training loss: 1.845446228981018
Validation loss: 2.1315544843673706

Epoch: 6| Step: 13
Training loss: 1.828371286392212
Validation loss: 2.1210845907529197

Epoch: 189| Step: 0
Training loss: 1.701412558555603
Validation loss: 2.1127347151438394

Epoch: 6| Step: 1
Training loss: 1.7151153087615967
Validation loss: 2.115336298942566

Epoch: 6| Step: 2
Training loss: 1.5241948366165161
Validation loss: 2.1319833000501

Epoch: 6| Step: 3
Training loss: 1.4764139652252197
Validation loss: 2.117414037386576

Epoch: 6| Step: 4
Training loss: 2.558027982711792
Validation loss: 2.1196923653284707

Epoch: 6| Step: 5
Training loss: 1.665647029876709
Validation loss: 2.1311625242233276

Epoch: 6| Step: 6
Training loss: 1.322277545928955
Validation loss: 2.1301031510035195

Epoch: 6| Step: 7
Training loss: 2.113511085510254
Validation loss: 2.1333068211873374

Epoch: 6| Step: 8
Training loss: 3.062239646911621
Validation loss: 2.1240853667259216

Epoch: 6| Step: 9
Training loss: 2.3742456436157227
Validation loss: 2.1345598896344504

Epoch: 6| Step: 10
Training loss: 1.5786184072494507
Validation loss: 2.1081586480140686

Epoch: 6| Step: 11
Training loss: 1.922221064567566
Validation loss: 2.136078675587972

Epoch: 6| Step: 12
Training loss: 2.0115997791290283
Validation loss: 2.1402375300725303

Epoch: 6| Step: 13
Training loss: 1.8104121685028076
Validation loss: 2.142315149307251

Epoch: 190| Step: 0
Training loss: 2.288339614868164
Validation loss: 2.1236408948898315

Epoch: 6| Step: 1
Training loss: 2.352587938308716
Validation loss: 2.159011960029602

Epoch: 6| Step: 2
Training loss: 1.5638320446014404
Validation loss: 2.1464510758717856

Epoch: 6| Step: 3
Training loss: 2.0370118618011475
Validation loss: 2.133715510368347

Epoch: 6| Step: 4
Training loss: 1.6851729154586792
Validation loss: 2.1618318955103555

Epoch: 6| Step: 5
Training loss: 1.9378159046173096
Validation loss: 2.148105045159658

Epoch: 6| Step: 6
Training loss: 1.787226676940918
Validation loss: 2.146603544553121

Epoch: 6| Step: 7
Training loss: 1.9686918258666992
Validation loss: 2.1357137163480124

Epoch: 6| Step: 8
Training loss: 2.150226593017578
Validation loss: 2.1159519155820212

Epoch: 6| Step: 9
Training loss: 1.9495353698730469
Validation loss: 2.124771018822988

Epoch: 6| Step: 10
Training loss: 2.0822057723999023
Validation loss: 2.1202637751897178

Epoch: 6| Step: 11
Training loss: 1.9562472105026245
Validation loss: 2.1368690530459085

Epoch: 6| Step: 12
Training loss: 1.8376023769378662
Validation loss: 2.1171541611353555

Epoch: 6| Step: 13
Training loss: 1.638917088508606
Validation loss: 2.1368783712387085

Epoch: 191| Step: 0
Training loss: 2.325798988342285
Validation loss: 2.1193458239237466

Epoch: 6| Step: 1
Training loss: 2.5247135162353516
Validation loss: 2.128714640935262

Epoch: 6| Step: 2
Training loss: 1.6393160820007324
Validation loss: 2.1630468567212424

Epoch: 6| Step: 3
Training loss: 2.255331516265869
Validation loss: 2.1641348600387573

Epoch: 6| Step: 4
Training loss: 1.5088047981262207
Validation loss: 2.1505202452341714

Epoch: 6| Step: 5
Training loss: 2.427814483642578
Validation loss: 2.151187241077423

Epoch: 6| Step: 6
Training loss: 1.9462429285049438
Validation loss: 2.1733710964520774

Epoch: 6| Step: 7
Training loss: 1.6010080575942993
Validation loss: 2.172305623690287

Epoch: 6| Step: 8
Training loss: 1.6351293325424194
Validation loss: 2.171888013680776

Epoch: 6| Step: 9
Training loss: 1.0432122945785522
Validation loss: 2.161741038163503

Epoch: 6| Step: 10
Training loss: 1.9563382863998413
Validation loss: 2.1440043449401855

Epoch: 6| Step: 11
Training loss: 1.9939353466033936
Validation loss: 2.130383392175039

Epoch: 6| Step: 12
Training loss: 1.451483964920044
Validation loss: 2.129773199558258

Epoch: 6| Step: 13
Training loss: 2.493770122528076
Validation loss: 2.115185002485911

Epoch: 192| Step: 0
Training loss: 1.9729175567626953
Validation loss: 2.1116730173428855

Epoch: 6| Step: 1
Training loss: 1.7003612518310547
Validation loss: 2.098795493443807

Epoch: 6| Step: 2
Training loss: 2.130913257598877
Validation loss: 2.1094335317611694

Epoch: 6| Step: 3
Training loss: 1.8105685710906982
Validation loss: 2.1094178756078086

Epoch: 6| Step: 4
Training loss: 2.1935031414031982
Validation loss: 2.110757887363434

Epoch: 6| Step: 5
Training loss: 1.5313218832015991
Validation loss: 2.1123925050099692

Epoch: 6| Step: 6
Training loss: 1.514902114868164
Validation loss: 2.10934046904246

Epoch: 6| Step: 7
Training loss: 1.9534335136413574
Validation loss: 2.1272605061531067

Epoch: 6| Step: 8
Training loss: 1.857367992401123
Validation loss: 2.142876386642456

Epoch: 6| Step: 9
Training loss: 2.1528005599975586
Validation loss: 2.1412874460220337

Epoch: 6| Step: 10
Training loss: 2.4904632568359375
Validation loss: 2.1496251424153647

Epoch: 6| Step: 11
Training loss: 2.033041000366211
Validation loss: 2.1681199272473655

Epoch: 6| Step: 12
Training loss: 2.1226043701171875
Validation loss: 2.1697953144709268

Epoch: 6| Step: 13
Training loss: 2.243832588195801
Validation loss: 2.1687212387720742

Epoch: 193| Step: 0
Training loss: 2.12772274017334
Validation loss: 2.155587832132975

Epoch: 6| Step: 1
Training loss: 2.042983055114746
Validation loss: 2.15454492966334

Epoch: 6| Step: 2
Training loss: 1.9353759288787842
Validation loss: 2.1299856503804526

Epoch: 6| Step: 3
Training loss: 2.092139720916748
Validation loss: 2.135603984196981

Epoch: 6| Step: 4
Training loss: 1.9538395404815674
Validation loss: 2.128852625687917

Epoch: 6| Step: 5
Training loss: 1.9109916687011719
Validation loss: 2.134955624739329

Epoch: 6| Step: 6
Training loss: 1.538798451423645
Validation loss: 2.113060931364695

Epoch: 6| Step: 7
Training loss: 1.500043272972107
Validation loss: 2.111274798711141

Epoch: 6| Step: 8
Training loss: 2.40976619720459
Validation loss: 2.1158703565597534

Epoch: 6| Step: 9
Training loss: 1.51387619972229
Validation loss: 2.112783590952555

Epoch: 6| Step: 10
Training loss: 1.9773454666137695
Validation loss: 2.118012269337972

Epoch: 6| Step: 11
Training loss: 2.284306049346924
Validation loss: 2.1080742478370667

Epoch: 6| Step: 12
Training loss: 1.7791059017181396
Validation loss: 2.1062169869740806

Epoch: 6| Step: 13
Training loss: 2.0349559783935547
Validation loss: 2.110113581021627

Epoch: 194| Step: 0
Training loss: 1.5250338315963745
Validation loss: 2.1032675306002298

Epoch: 6| Step: 1
Training loss: 1.8224332332611084
Validation loss: 2.109303573767344

Epoch: 6| Step: 2
Training loss: 1.4481319189071655
Validation loss: 2.1004201769828796

Epoch: 6| Step: 3
Training loss: 2.3883228302001953
Validation loss: 2.1260815461476645

Epoch: 6| Step: 4
Training loss: 1.5912764072418213
Validation loss: 2.122602621714274

Epoch: 6| Step: 5
Training loss: 2.2079358100891113
Validation loss: 2.1348246733347573

Epoch: 6| Step: 6
Training loss: 1.7085554599761963
Validation loss: 2.1345739563306174

Epoch: 6| Step: 7
Training loss: 1.6352710723876953
Validation loss: 2.127652168273926

Epoch: 6| Step: 8
Training loss: 1.6582884788513184
Validation loss: 2.1462887724240622

Epoch: 6| Step: 9
Training loss: 2.414524555206299
Validation loss: 2.136378029982249

Epoch: 6| Step: 10
Training loss: 2.634974956512451
Validation loss: 2.13772314786911

Epoch: 6| Step: 11
Training loss: 2.13816237449646
Validation loss: 2.1242833733558655

Epoch: 6| Step: 12
Training loss: 1.9109978675842285
Validation loss: 2.122274875640869

Epoch: 6| Step: 13
Training loss: 2.0662078857421875
Validation loss: 2.111310879389445

Epoch: 195| Step: 0
Training loss: 1.794084906578064
Validation loss: 2.1136346459388733

Epoch: 6| Step: 1
Training loss: 2.529130458831787
Validation loss: 2.1179311871528625

Epoch: 6| Step: 2
Training loss: 1.9897890090942383
Validation loss: 2.107122818628947

Epoch: 6| Step: 3
Training loss: 2.527186870574951
Validation loss: 2.121403972307841

Epoch: 6| Step: 4
Training loss: 1.4093918800354004
Validation loss: 2.126667598883311

Epoch: 6| Step: 5
Training loss: 1.906461238861084
Validation loss: 2.1206464767456055

Epoch: 6| Step: 6
Training loss: 1.8388869762420654
Validation loss: 2.115815003712972

Epoch: 6| Step: 7
Training loss: 1.6032075881958008
Validation loss: 2.1204005082448325

Epoch: 6| Step: 8
Training loss: 1.859239935874939
Validation loss: 2.1273811062177024

Epoch: 6| Step: 9
Training loss: 1.957278847694397
Validation loss: 2.1222762862841287

Epoch: 6| Step: 10
Training loss: 2.060120105743408
Validation loss: 2.1208744049072266

Epoch: 6| Step: 11
Training loss: 1.7674819231033325
Validation loss: 2.1265949606895447

Epoch: 6| Step: 12
Training loss: 1.4963624477386475
Validation loss: 2.1234758694966636

Epoch: 6| Step: 13
Training loss: 1.9520334005355835
Validation loss: 2.1383339166641235

Epoch: 196| Step: 0
Training loss: 2.5929036140441895
Validation loss: 2.1396615703900657

Epoch: 6| Step: 1
Training loss: 1.5766953229904175
Validation loss: 2.1294747988382974

Epoch: 6| Step: 2
Training loss: 1.7456740140914917
Validation loss: 2.118273218472799

Epoch: 6| Step: 3
Training loss: 2.1314773559570312
Validation loss: 2.1237959067026773

Epoch: 6| Step: 4
Training loss: 1.8728785514831543
Validation loss: 2.1184344490369162

Epoch: 6| Step: 5
Training loss: 2.0707764625549316
Validation loss: 2.1225393414497375

Epoch: 6| Step: 6
Training loss: 2.114847183227539
Validation loss: 2.1236146092414856

Epoch: 6| Step: 7
Training loss: 1.8696625232696533
Validation loss: 2.1223153670628867

Epoch: 6| Step: 8
Training loss: 1.2112951278686523
Validation loss: 2.137068271636963

Epoch: 6| Step: 9
Training loss: 2.197265148162842
Validation loss: 2.111638526121775

Epoch: 6| Step: 10
Training loss: 1.9917263984680176
Validation loss: 2.123340984185537

Epoch: 6| Step: 11
Training loss: 2.1590256690979004
Validation loss: 2.135965804258982

Epoch: 6| Step: 12
Training loss: 2.0997228622436523
Validation loss: 2.126873195171356

Epoch: 6| Step: 13
Training loss: 1.120178461074829
Validation loss: 2.139280994733175

Epoch: 197| Step: 0
Training loss: 2.052105188369751
Validation loss: 2.134589195251465

Epoch: 6| Step: 1
Training loss: 1.8250908851623535
Validation loss: 2.1330533822377524

Epoch: 6| Step: 2
Training loss: 1.5434050559997559
Validation loss: 2.1392887433369956

Epoch: 6| Step: 3
Training loss: 1.6192327737808228
Validation loss: 2.129013697306315

Epoch: 6| Step: 4
Training loss: 2.5204708576202393
Validation loss: 2.133978088696798

Epoch: 6| Step: 5
Training loss: 2.457415819168091
Validation loss: 2.1235384543736777

Epoch: 6| Step: 6
Training loss: 1.9837887287139893
Validation loss: 2.125624656677246

Epoch: 6| Step: 7
Training loss: 1.8083059787750244
Validation loss: 2.130154331525167

Epoch: 6| Step: 8
Training loss: 1.2430055141448975
Validation loss: 2.1334598660469055

Epoch: 6| Step: 9
Training loss: 2.074634313583374
Validation loss: 2.1372960805892944

Epoch: 6| Step: 10
Training loss: 1.8146724700927734
Validation loss: 2.130783478418986

Epoch: 6| Step: 11
Training loss: 0.8826448917388916
Validation loss: 2.146846890449524

Epoch: 6| Step: 12
Training loss: 2.5506551265716553
Validation loss: 2.1313637296358743

Epoch: 6| Step: 13
Training loss: 1.9279392957687378
Validation loss: 2.143214007218679

Epoch: 198| Step: 0
Training loss: 2.0567843914031982
Validation loss: 2.1263489921887717

Epoch: 6| Step: 1
Training loss: 2.006488800048828
Validation loss: 2.127197484175364

Epoch: 6| Step: 2
Training loss: 1.6430412530899048
Validation loss: 2.1404565572738647

Epoch: 6| Step: 3
Training loss: 2.4917569160461426
Validation loss: 2.1549373666445413

Epoch: 6| Step: 4
Training loss: 2.1891679763793945
Validation loss: 2.1311227877934775

Epoch: 6| Step: 5
Training loss: 2.2336511611938477
Validation loss: 2.1385427117347717

Epoch: 6| Step: 6
Training loss: 2.0138325691223145
Validation loss: 2.136346975962321

Epoch: 6| Step: 7
Training loss: 1.9360158443450928
Validation loss: 2.1340579986572266

Epoch: 6| Step: 8
Training loss: 1.6759586334228516
Validation loss: 2.139224330584208

Epoch: 6| Step: 9
Training loss: 1.9940420389175415
Validation loss: 2.1448097626368203

Epoch: 6| Step: 10
Training loss: 1.4144198894500732
Validation loss: 2.138631542523702

Epoch: 6| Step: 11
Training loss: 1.8760703802108765
Validation loss: 2.136754353841146

Epoch: 6| Step: 12
Training loss: 1.9605481624603271
Validation loss: 2.135401209195455

Epoch: 6| Step: 13
Training loss: 1.1446938514709473
Validation loss: 2.1349058747291565

Epoch: 199| Step: 0
Training loss: 1.3963987827301025
Validation loss: 2.1488137443860373

Epoch: 6| Step: 1
Training loss: 1.9306981563568115
Validation loss: 2.1502663095792136

Epoch: 6| Step: 2
Training loss: 1.771166205406189
Validation loss: 2.1482656796773276

Epoch: 6| Step: 3
Training loss: 1.7307555675506592
Validation loss: 2.1644532879193625

Epoch: 6| Step: 4
Training loss: 1.999975323677063
Validation loss: 2.1636423071225486

Epoch: 6| Step: 5
Training loss: 1.896509051322937
Validation loss: 2.1529290278752646

Epoch: 6| Step: 6
Training loss: 2.495857000350952
Validation loss: 2.164150655269623

Epoch: 6| Step: 7
Training loss: 2.3084092140197754
Validation loss: 2.1588735779126487

Epoch: 6| Step: 8
Training loss: 2.544414520263672
Validation loss: 2.148980696996053

Epoch: 6| Step: 9
Training loss: 1.399489164352417
Validation loss: 2.1429945826530457

Epoch: 6| Step: 10
Training loss: 1.8015611171722412
Validation loss: 2.1467197934786477

Epoch: 6| Step: 11
Training loss: 1.7146694660186768
Validation loss: 2.146100918451945

Epoch: 6| Step: 12
Training loss: 1.7024476528167725
Validation loss: 2.148791750272115

Epoch: 6| Step: 13
Training loss: 1.8174452781677246
Validation loss: 2.142578681310018

Epoch: 200| Step: 0
Training loss: 1.8854913711547852
Validation loss: 2.154472311337789

Epoch: 6| Step: 1
Training loss: 1.5397346019744873
Validation loss: 2.146998484929403

Epoch: 6| Step: 2
Training loss: 2.1525959968566895
Validation loss: 2.1455071171124778

Epoch: 6| Step: 3
Training loss: 1.58644437789917
Validation loss: 2.15989096959432

Epoch: 6| Step: 4
Training loss: 1.6821985244750977
Validation loss: 2.149322211742401

Epoch: 6| Step: 5
Training loss: 2.1342506408691406
Validation loss: 2.150045096874237

Epoch: 6| Step: 6
Training loss: 1.6026487350463867
Validation loss: 2.1451919873555503

Epoch: 6| Step: 7
Training loss: 1.8250951766967773
Validation loss: 2.1666096647580466

Epoch: 6| Step: 8
Training loss: 2.0416669845581055
Validation loss: 2.1460593342781067

Epoch: 6| Step: 9
Training loss: 2.3767361640930176
Validation loss: 2.1561591227849326

Epoch: 6| Step: 10
Training loss: 1.6992013454437256
Validation loss: 2.141877035299937

Epoch: 6| Step: 11
Training loss: 1.8839925527572632
Validation loss: 2.129642367362976

Epoch: 6| Step: 12
Training loss: 2.4049479961395264
Validation loss: 2.129414200782776

Epoch: 6| Step: 13
Training loss: 1.6491239070892334
Validation loss: 2.1383796334266663

Epoch: 201| Step: 0
Training loss: 1.9780356884002686
Validation loss: 2.13028613726298

Epoch: 6| Step: 1
Training loss: 1.184382438659668
Validation loss: 2.135402818520864

Epoch: 6| Step: 2
Training loss: 1.7508213520050049
Validation loss: 2.1543147563934326

Epoch: 6| Step: 3
Training loss: 2.239278554916382
Validation loss: 2.13272092739741

Epoch: 6| Step: 4
Training loss: 1.4253878593444824
Validation loss: 2.145944118499756

Epoch: 6| Step: 5
Training loss: 1.8257306814193726
Validation loss: 2.1450698177019754

Epoch: 6| Step: 6
Training loss: 2.3930091857910156
Validation loss: 2.1279369990030923

Epoch: 6| Step: 7
Training loss: 1.7208220958709717
Validation loss: 2.1364771525065103

Epoch: 6| Step: 8
Training loss: 1.9295111894607544
Validation loss: 2.1425827940305076

Epoch: 6| Step: 9
Training loss: 2.2176833152770996
Validation loss: 2.155836741129557

Epoch: 6| Step: 10
Training loss: 2.1186418533325195
Validation loss: 2.1553742488225303

Epoch: 6| Step: 11
Training loss: 1.6732643842697144
Validation loss: 2.134524325529734

Epoch: 6| Step: 12
Training loss: 2.257105827331543
Validation loss: 2.1326042811075845

Epoch: 6| Step: 13
Training loss: 1.6338129043579102
Validation loss: 2.139596482117971

Epoch: 202| Step: 0
Training loss: 1.7465620040893555
Validation loss: 2.1317806442578635

Epoch: 6| Step: 1
Training loss: 1.871174693107605
Validation loss: 2.1323206226030984

Epoch: 6| Step: 2
Training loss: 1.5840396881103516
Validation loss: 2.130398750305176

Epoch: 6| Step: 3
Training loss: 1.6553174257278442
Validation loss: 2.122817039489746

Epoch: 6| Step: 4
Training loss: 2.175924777984619
Validation loss: 2.1376659075419107

Epoch: 6| Step: 5
Training loss: 2.5261459350585938
Validation loss: 2.1373283664385476

Epoch: 6| Step: 6
Training loss: 1.7515416145324707
Validation loss: 2.132300535837809

Epoch: 6| Step: 7
Training loss: 1.7946252822875977
Validation loss: 2.144086023171743

Epoch: 6| Step: 8
Training loss: 2.7875304222106934
Validation loss: 2.1682048638661704

Epoch: 6| Step: 9
Training loss: 1.7031699419021606
Validation loss: 2.145176867643992

Epoch: 6| Step: 10
Training loss: 1.8517990112304688
Validation loss: 2.177541494369507

Epoch: 6| Step: 11
Training loss: 1.4209609031677246
Validation loss: 2.1569780111312866

Epoch: 6| Step: 12
Training loss: 1.8336886167526245
Validation loss: 2.1311821937561035

Epoch: 6| Step: 13
Training loss: 1.8751075267791748
Validation loss: 2.131005128224691

Epoch: 203| Step: 0
Training loss: 1.722665548324585
Validation loss: 2.1352083484331765

Epoch: 6| Step: 1
Training loss: 2.0644407272338867
Validation loss: 2.1107400258382163

Epoch: 6| Step: 2
Training loss: 1.9809484481811523
Validation loss: 2.1442208091417947

Epoch: 6| Step: 3
Training loss: 2.273414134979248
Validation loss: 2.1385865608851113

Epoch: 6| Step: 4
Training loss: 1.8969967365264893
Validation loss: 2.1287804444630942

Epoch: 6| Step: 5
Training loss: 1.9603973627090454
Validation loss: 2.145960529645284

Epoch: 6| Step: 6
Training loss: 1.3231089115142822
Validation loss: 2.1547439098358154

Epoch: 6| Step: 7
Training loss: 1.9430046081542969
Validation loss: 2.1500080029169717

Epoch: 6| Step: 8
Training loss: 2.012362480163574
Validation loss: 2.153947671254476

Epoch: 6| Step: 9
Training loss: 1.9495649337768555
Validation loss: 2.157358705997467

Epoch: 6| Step: 10
Training loss: 1.2394622564315796
Validation loss: 2.1537747780481973

Epoch: 6| Step: 11
Training loss: 2.303253173828125
Validation loss: 2.127525349458059

Epoch: 6| Step: 12
Training loss: 1.90693199634552
Validation loss: 2.1455396811167398

Epoch: 6| Step: 13
Training loss: 1.7417349815368652
Validation loss: 2.135260800520579

Epoch: 204| Step: 0
Training loss: 1.6446093320846558
Validation loss: 2.1341038942337036

Epoch: 6| Step: 1
Training loss: 2.2074942588806152
Validation loss: 2.1204806367556253

Epoch: 6| Step: 2
Training loss: 1.8345465660095215
Validation loss: 2.1155884663263955

Epoch: 6| Step: 3
Training loss: 2.4946236610412598
Validation loss: 2.1152581175168357

Epoch: 6| Step: 4
Training loss: 1.980814814567566
Validation loss: 2.1183669368426004

Epoch: 6| Step: 5
Training loss: 2.091398239135742
Validation loss: 2.114504039287567

Epoch: 6| Step: 6
Training loss: 1.6221399307250977
Validation loss: 2.1383256117502847

Epoch: 6| Step: 7
Training loss: 1.3937739133834839
Validation loss: 2.1319431265195212

Epoch: 6| Step: 8
Training loss: 1.2574613094329834
Validation loss: 2.1562694311141968

Epoch: 6| Step: 9
Training loss: 1.4831573963165283
Validation loss: 2.137931764125824

Epoch: 6| Step: 10
Training loss: 2.2299270629882812
Validation loss: 2.1449695229530334

Epoch: 6| Step: 11
Training loss: 2.0477588176727295
Validation loss: 2.1573578914006553

Epoch: 6| Step: 12
Training loss: 2.247636079788208
Validation loss: 2.1729848384857178

Epoch: 6| Step: 13
Training loss: 1.8494189977645874
Validation loss: 2.1803505420684814

Epoch: 205| Step: 0
Training loss: 1.7724354267120361
Validation loss: 2.1768112778663635

Epoch: 6| Step: 1
Training loss: 1.9651076793670654
Validation loss: 2.162150740623474

Epoch: 6| Step: 2
Training loss: 2.629582643508911
Validation loss: 2.1601210832595825

Epoch: 6| Step: 3
Training loss: 2.128791332244873
Validation loss: 2.1397813161214194

Epoch: 6| Step: 4
Training loss: 2.09110164642334
Validation loss: 2.113250255584717

Epoch: 6| Step: 5
Training loss: 1.5918405055999756
Validation loss: 2.1137712001800537

Epoch: 6| Step: 6
Training loss: 1.1539058685302734
Validation loss: 2.12056694428126

Epoch: 6| Step: 7
Training loss: 1.667456865310669
Validation loss: 2.1330577532450357

Epoch: 6| Step: 8
Training loss: 1.6738265752792358
Validation loss: 2.118031998475393

Epoch: 6| Step: 9
Training loss: 2.0616135597229004
Validation loss: 2.1135971744855246

Epoch: 6| Step: 10
Training loss: 1.8327089548110962
Validation loss: 2.1469316681226096

Epoch: 6| Step: 11
Training loss: 2.2548341751098633
Validation loss: 2.1108125845591226

Epoch: 6| Step: 12
Training loss: 2.0821971893310547
Validation loss: 2.114528218905131

Epoch: 6| Step: 13
Training loss: 1.9670307636260986
Validation loss: 2.149724026521047

Epoch: 206| Step: 0
Training loss: 2.6130924224853516
Validation loss: 2.136855661869049

Epoch: 6| Step: 1
Training loss: 1.1290349960327148
Validation loss: 2.1390395760536194

Epoch: 6| Step: 2
Training loss: 1.8988629579544067
Validation loss: 2.145878036816915

Epoch: 6| Step: 3
Training loss: 1.2964738607406616
Validation loss: 2.155041833718618

Epoch: 6| Step: 4
Training loss: 2.0511159896850586
Validation loss: 2.1341713269551597

Epoch: 6| Step: 5
Training loss: 1.7584068775177002
Validation loss: 2.1274693409601846

Epoch: 6| Step: 6
Training loss: 1.9350799322128296
Validation loss: 2.1343636512756348

Epoch: 6| Step: 7
Training loss: 1.5542969703674316
Validation loss: 2.131819506486257

Epoch: 6| Step: 8
Training loss: 2.3366007804870605
Validation loss: 2.1289352973302207

Epoch: 6| Step: 9
Training loss: 2.1094436645507812
Validation loss: 2.1400967240333557

Epoch: 6| Step: 10
Training loss: 1.5118768215179443
Validation loss: 2.140723705291748

Epoch: 6| Step: 11
Training loss: 2.3287806510925293
Validation loss: 2.1209948658943176

Epoch: 6| Step: 12
Training loss: 1.730661153793335
Validation loss: 2.131800651550293

Epoch: 6| Step: 13
Training loss: 2.119980573654175
Validation loss: 2.139501969019572

Epoch: 207| Step: 0
Training loss: 1.8362444639205933
Validation loss: 2.1425727009773254

Epoch: 6| Step: 1
Training loss: 2.0687475204467773
Validation loss: 2.15320752064387

Epoch: 6| Step: 2
Training loss: 1.5373539924621582
Validation loss: 2.156036893526713

Epoch: 6| Step: 3
Training loss: 2.598297119140625
Validation loss: 2.1447064876556396

Epoch: 6| Step: 4
Training loss: 1.567187786102295
Validation loss: 2.149863521258036

Epoch: 6| Step: 5
Training loss: 1.7102978229522705
Validation loss: 2.1540480653444924

Epoch: 6| Step: 6
Training loss: 1.6884924173355103
Validation loss: 2.1404659946759543

Epoch: 6| Step: 7
Training loss: 1.647571086883545
Validation loss: 2.139008025328318

Epoch: 6| Step: 8
Training loss: 2.32486891746521
Validation loss: 2.1315666238466897

Epoch: 6| Step: 9
Training loss: 1.9916329383850098
Validation loss: 2.15181964635849

Epoch: 6| Step: 10
Training loss: 1.1751054525375366
Validation loss: 2.1315287351608276

Epoch: 6| Step: 11
Training loss: 2.629950523376465
Validation loss: 2.158657709757487

Epoch: 6| Step: 12
Training loss: 2.0794341564178467
Validation loss: 2.1548707087834678

Epoch: 6| Step: 13
Training loss: 1.593043565750122
Validation loss: 2.1645256082216897

Epoch: 208| Step: 0
Training loss: 1.1405799388885498
Validation loss: 2.1603114207585654

Epoch: 6| Step: 1
Training loss: 1.6691203117370605
Validation loss: 2.1821743647257485

Epoch: 6| Step: 2
Training loss: 1.7049241065979004
Validation loss: 2.150101820627848

Epoch: 6| Step: 3
Training loss: 2.407071113586426
Validation loss: 2.1691838105519614

Epoch: 6| Step: 4
Training loss: 2.051076889038086
Validation loss: 2.1505743066469827

Epoch: 6| Step: 5
Training loss: 1.7493700981140137
Validation loss: 2.14462016026179

Epoch: 6| Step: 6
Training loss: 2.3228883743286133
Validation loss: 2.178363879521688

Epoch: 6| Step: 7
Training loss: 1.2969553470611572
Validation loss: 2.166305124759674

Epoch: 6| Step: 8
Training loss: 1.8925633430480957
Validation loss: 2.14087051153183

Epoch: 6| Step: 9
Training loss: 2.522015333175659
Validation loss: 2.154111464818319

Epoch: 6| Step: 10
Training loss: 2.076110363006592
Validation loss: 2.1594486236572266

Epoch: 6| Step: 11
Training loss: 1.5926942825317383
Validation loss: 2.1459937493006387

Epoch: 6| Step: 12
Training loss: 1.7314141988754272
Validation loss: 2.1488460699717202

Epoch: 6| Step: 13
Training loss: 2.3407907485961914
Validation loss: 2.1631339391072593

Epoch: 209| Step: 0
Training loss: 1.4696714878082275
Validation loss: 2.1666502952575684

Epoch: 6| Step: 1
Training loss: 1.6482360363006592
Validation loss: 2.1551905473073325

Epoch: 6| Step: 2
Training loss: 1.7381923198699951
Validation loss: 2.140838086605072

Epoch: 6| Step: 3
Training loss: 2.1734888553619385
Validation loss: 2.153705358505249

Epoch: 6| Step: 4
Training loss: 2.1735939979553223
Validation loss: 2.1492915948232016

Epoch: 6| Step: 5
Training loss: 2.328360080718994
Validation loss: 2.1413860519727073

Epoch: 6| Step: 6
Training loss: 1.406393051147461
Validation loss: 2.1246842543284097

Epoch: 6| Step: 7
Training loss: 1.6637523174285889
Validation loss: 2.1420134703318277

Epoch: 6| Step: 8
Training loss: 2.2042880058288574
Validation loss: 2.1268450021743774

Epoch: 6| Step: 9
Training loss: 1.6816463470458984
Validation loss: 2.1470662156740823

Epoch: 6| Step: 10
Training loss: 1.833331823348999
Validation loss: 2.1352862119674683

Epoch: 6| Step: 11
Training loss: 2.2041854858398438
Validation loss: 2.1506044467290244

Epoch: 6| Step: 12
Training loss: 1.5515010356903076
Validation loss: 2.1549466649691262

Epoch: 6| Step: 13
Training loss: 2.2077183723449707
Validation loss: 2.1562813917795816

Epoch: 210| Step: 0
Training loss: 1.5114545822143555
Validation loss: 2.178626457850138

Epoch: 6| Step: 1
Training loss: 2.2289371490478516
Validation loss: 2.1776907046635947

Epoch: 6| Step: 2
Training loss: 1.8002591133117676
Validation loss: 2.1883434653282166

Epoch: 6| Step: 3
Training loss: 1.9425820112228394
Validation loss: 2.1646162271499634

Epoch: 6| Step: 4
Training loss: 1.9972025156021118
Validation loss: 2.151910722255707

Epoch: 6| Step: 5
Training loss: 2.413393020629883
Validation loss: 2.152592102686564

Epoch: 6| Step: 6
Training loss: 1.6588473320007324
Validation loss: 2.1404024958610535

Epoch: 6| Step: 7
Training loss: 2.0130488872528076
Validation loss: 2.137547572453817

Epoch: 6| Step: 8
Training loss: 1.749563217163086
Validation loss: 2.13381560643514

Epoch: 6| Step: 9
Training loss: 1.9030263423919678
Validation loss: 2.1344763239224753

Epoch: 6| Step: 10
Training loss: 2.404393196105957
Validation loss: 2.143386801083883

Epoch: 6| Step: 11
Training loss: 1.7656383514404297
Validation loss: 2.1387723286946616

Epoch: 6| Step: 12
Training loss: 1.7566990852355957
Validation loss: 2.134893755118052

Epoch: 6| Step: 13
Training loss: 1.854715347290039
Validation loss: 2.169954856236776

Epoch: 211| Step: 0
Training loss: 1.8653333187103271
Validation loss: 2.174340387185415

Epoch: 6| Step: 1
Training loss: 2.064729690551758
Validation loss: 2.191736618677775

Epoch: 6| Step: 2
Training loss: 2.0488741397857666
Validation loss: 2.2009604374567666

Epoch: 6| Step: 3
Training loss: 1.7459664344787598
Validation loss: 2.194274922211965

Epoch: 6| Step: 4
Training loss: 1.8665761947631836
Validation loss: 2.1742707093556723

Epoch: 6| Step: 5
Training loss: 1.8989659547805786
Validation loss: 2.185054143269857

Epoch: 6| Step: 6
Training loss: 2.6839935779571533
Validation loss: 2.18105940024058

Epoch: 6| Step: 7
Training loss: 1.893367052078247
Validation loss: 2.1930652856826782

Epoch: 6| Step: 8
Training loss: 1.8460655212402344
Validation loss: 2.1862725814183555

Epoch: 6| Step: 9
Training loss: 1.8522883653640747
Validation loss: 2.153728723526001

Epoch: 6| Step: 10
Training loss: 1.7996315956115723
Validation loss: 2.1356182297070823

Epoch: 6| Step: 11
Training loss: 1.2606500387191772
Validation loss: 2.1249986688296

Epoch: 6| Step: 12
Training loss: 1.588860273361206
Validation loss: 2.1383644938468933

Epoch: 6| Step: 13
Training loss: 2.3031418323516846
Validation loss: 2.1228265364964805

Epoch: 212| Step: 0
Training loss: 1.6715900897979736
Validation loss: 2.1239771644274392

Epoch: 6| Step: 1
Training loss: 1.7543981075286865
Validation loss: 2.142807960510254

Epoch: 6| Step: 2
Training loss: 2.056452989578247
Validation loss: 2.1420299410820007

Epoch: 6| Step: 3
Training loss: 1.9156360626220703
Validation loss: 2.1507579485575357

Epoch: 6| Step: 4
Training loss: 2.483522415161133
Validation loss: 2.1494271953900657

Epoch: 6| Step: 5
Training loss: 1.6093645095825195
Validation loss: 2.170274297396342

Epoch: 6| Step: 6
Training loss: 1.5976734161376953
Validation loss: 2.173139750957489

Epoch: 6| Step: 7
Training loss: 1.6387174129486084
Validation loss: 2.1765847206115723

Epoch: 6| Step: 8
Training loss: 1.634253978729248
Validation loss: 2.180428147315979

Epoch: 6| Step: 9
Training loss: 2.5348691940307617
Validation loss: 2.189643462498983

Epoch: 6| Step: 10
Training loss: 2.095879077911377
Validation loss: 2.1931803226470947

Epoch: 6| Step: 11
Training loss: 1.6008195877075195
Validation loss: 2.189691503842672

Epoch: 6| Step: 12
Training loss: 2.1749167442321777
Validation loss: 2.1555423935254416

Epoch: 6| Step: 13
Training loss: 1.74924898147583
Validation loss: 2.1651236017545066

Epoch: 213| Step: 0
Training loss: 2.3865883350372314
Validation loss: 2.1480414072672525

Epoch: 6| Step: 1
Training loss: 1.7562992572784424
Validation loss: 2.1562602718671164

Epoch: 6| Step: 2
Training loss: 1.6961379051208496
Validation loss: 2.131596803665161

Epoch: 6| Step: 3
Training loss: 2.1875648498535156
Validation loss: 2.121385872364044

Epoch: 6| Step: 4
Training loss: 1.238853096961975
Validation loss: 2.120645602544149

Epoch: 6| Step: 5
Training loss: 1.7803164720535278
Validation loss: 2.1128313144048056

Epoch: 6| Step: 6
Training loss: 2.534590721130371
Validation loss: 2.1050124367078147

Epoch: 6| Step: 7
Training loss: 1.928426742553711
Validation loss: 2.1134862701098123

Epoch: 6| Step: 8
Training loss: 2.244673252105713
Validation loss: 2.1168233354886374

Epoch: 6| Step: 9
Training loss: 1.9735033512115479
Validation loss: 2.1196001768112183

Epoch: 6| Step: 10
Training loss: 1.7823679447174072
Validation loss: 2.122128208478292

Epoch: 6| Step: 11
Training loss: 1.7535059452056885
Validation loss: 2.1334253549575806

Epoch: 6| Step: 12
Training loss: 1.4915344715118408
Validation loss: 2.151748021443685

Epoch: 6| Step: 13
Training loss: 1.9435877799987793
Validation loss: 2.1409937938054404

Epoch: 214| Step: 0
Training loss: 1.6202683448791504
Validation loss: 2.160528063774109

Epoch: 6| Step: 1
Training loss: 1.1168711185455322
Validation loss: 2.1437160770098367

Epoch: 6| Step: 2
Training loss: 2.2417893409729004
Validation loss: 2.1646565596262612

Epoch: 6| Step: 3
Training loss: 1.7278400659561157
Validation loss: 2.1754388014475503

Epoch: 6| Step: 4
Training loss: 1.9258935451507568
Validation loss: 2.1508871714274087

Epoch: 6| Step: 5
Training loss: 2.3906989097595215
Validation loss: 2.1486681699752808

Epoch: 6| Step: 6
Training loss: 2.7355544567108154
Validation loss: 2.148151695728302

Epoch: 6| Step: 7
Training loss: 2.198174476623535
Validation loss: 2.1476349234580994

Epoch: 6| Step: 8
Training loss: 1.7050632238388062
Validation loss: 2.1463023821512857

Epoch: 6| Step: 9
Training loss: 2.309504985809326
Validation loss: 2.1415339708328247

Epoch: 6| Step: 10
Training loss: 1.161302089691162
Validation loss: 2.160076141357422

Epoch: 6| Step: 11
Training loss: 1.8221997022628784
Validation loss: 2.1563517252604165

Epoch: 6| Step: 12
Training loss: 2.513031005859375
Validation loss: 2.160657048225403

Epoch: 6| Step: 13
Training loss: 1.482879400253296
Validation loss: 2.158515294392904

Epoch: 215| Step: 0
Training loss: 1.7868061065673828
Validation loss: 2.175435642401377

Epoch: 6| Step: 1
Training loss: 2.0102505683898926
Validation loss: 2.149595061937968

Epoch: 6| Step: 2
Training loss: 2.127108573913574
Validation loss: 2.1715908646583557

Epoch: 6| Step: 3
Training loss: 1.3553329706192017
Validation loss: 2.163129230340322

Epoch: 6| Step: 4
Training loss: 1.447601556777954
Validation loss: 2.1717418432235718

Epoch: 6| Step: 5
Training loss: 1.8614299297332764
Validation loss: 2.1594650745391846

Epoch: 6| Step: 6
Training loss: 1.9173672199249268
Validation loss: 2.1598054567972818

Epoch: 6| Step: 7
Training loss: 2.1884799003601074
Validation loss: 2.1632545789082847

Epoch: 6| Step: 8
Training loss: 1.6289565563201904
Validation loss: 2.152685562769572

Epoch: 6| Step: 9
Training loss: 1.581490397453308
Validation loss: 2.1532031297683716

Epoch: 6| Step: 10
Training loss: 1.8541733026504517
Validation loss: 2.154278516769409

Epoch: 6| Step: 11
Training loss: 2.080277442932129
Validation loss: 2.163656791051229

Epoch: 6| Step: 12
Training loss: 2.8454041481018066
Validation loss: 2.1662877003351846

Epoch: 6| Step: 13
Training loss: 1.619278073310852
Validation loss: 2.1645238399505615

Epoch: 216| Step: 0
Training loss: 1.9693495035171509
Validation loss: 2.1778117219607034

Epoch: 6| Step: 1
Training loss: 1.5105345249176025
Validation loss: 2.1719310681025186

Epoch: 6| Step: 2
Training loss: 1.268289566040039
Validation loss: 2.202296733856201

Epoch: 6| Step: 3
Training loss: 2.1208131313323975
Validation loss: 2.1888243754704795

Epoch: 6| Step: 4
Training loss: 2.088120460510254
Validation loss: 2.1879372000694275

Epoch: 6| Step: 5
Training loss: 2.223188638687134
Validation loss: 2.1805144349733987

Epoch: 6| Step: 6
Training loss: 1.8998584747314453
Validation loss: 2.1593352953592935

Epoch: 6| Step: 7
Training loss: 1.7303173542022705
Validation loss: 2.1591373284657798

Epoch: 6| Step: 8
Training loss: 2.241217613220215
Validation loss: 2.160421152909597

Epoch: 6| Step: 9
Training loss: 1.7750405073165894
Validation loss: 2.136048436164856

Epoch: 6| Step: 10
Training loss: 1.9659698009490967
Validation loss: 2.1376454830169678

Epoch: 6| Step: 11
Training loss: 2.6367011070251465
Validation loss: 2.118929465611776

Epoch: 6| Step: 12
Training loss: 1.8716813325881958
Validation loss: 2.123705248037974

Epoch: 6| Step: 13
Training loss: 1.5426853895187378
Validation loss: 2.131185313065847

Epoch: 217| Step: 0
Training loss: 1.6840647459030151
Validation loss: 2.1371077497800193

Epoch: 6| Step: 1
Training loss: 1.9965689182281494
Validation loss: 2.132950941721598

Epoch: 6| Step: 2
Training loss: 1.3878874778747559
Validation loss: 2.116783102353414

Epoch: 6| Step: 3
Training loss: 2.1698193550109863
Validation loss: 2.1265769004821777

Epoch: 6| Step: 4
Training loss: 1.5841892957687378
Validation loss: 2.129039446512858

Epoch: 6| Step: 5
Training loss: 2.203664541244507
Validation loss: 2.1313790877660117

Epoch: 6| Step: 6
Training loss: 1.8116165399551392
Validation loss: 2.1102609833081565

Epoch: 6| Step: 7
Training loss: 1.5341514348983765
Validation loss: 2.1323700547218323

Epoch: 6| Step: 8
Training loss: 2.1633830070495605
Validation loss: 2.1333215634028115

Epoch: 6| Step: 9
Training loss: 2.0558907985687256
Validation loss: 2.1226239005724588

Epoch: 6| Step: 10
Training loss: 1.893155574798584
Validation loss: 2.1502259572347007

Epoch: 6| Step: 11
Training loss: 1.8784265518188477
Validation loss: 2.1380027333895364

Epoch: 6| Step: 12
Training loss: 1.9891067743301392
Validation loss: 2.145890772342682

Epoch: 6| Step: 13
Training loss: 2.2121453285217285
Validation loss: 2.129755139350891

Epoch: 218| Step: 0
Training loss: 2.1568408012390137
Validation loss: 2.164030392964681

Epoch: 6| Step: 1
Training loss: 1.4871644973754883
Validation loss: 2.1403573950131736

Epoch: 6| Step: 2
Training loss: 1.9909782409667969
Validation loss: 2.144153078397115

Epoch: 6| Step: 3
Training loss: 2.299315929412842
Validation loss: 2.146423856417338

Epoch: 6| Step: 4
Training loss: 2.074479579925537
Validation loss: 2.143220523993174

Epoch: 6| Step: 5
Training loss: 1.423940896987915
Validation loss: 2.156302253405253

Epoch: 6| Step: 6
Training loss: 1.4664931297302246
Validation loss: 2.1426516572634378

Epoch: 6| Step: 7
Training loss: 1.7578761577606201
Validation loss: 2.1595141688982644

Epoch: 6| Step: 8
Training loss: 2.2836155891418457
Validation loss: 2.1766178409258523

Epoch: 6| Step: 9
Training loss: 1.896582841873169
Validation loss: 2.145536263783773

Epoch: 6| Step: 10
Training loss: 1.7231223583221436
Validation loss: 2.1583672364552817

Epoch: 6| Step: 11
Training loss: 1.7558016777038574
Validation loss: 2.155177275339762

Epoch: 6| Step: 12
Training loss: 1.37748384475708
Validation loss: 2.1719823678334556

Epoch: 6| Step: 13
Training loss: 2.6284425258636475
Validation loss: 2.1530450582504272

Epoch: 219| Step: 0
Training loss: 2.0622434616088867
Validation loss: 2.1563876271247864

Epoch: 6| Step: 1
Training loss: 2.411719560623169
Validation loss: 2.1578511397043862

Epoch: 6| Step: 2
Training loss: 1.9127451181411743
Validation loss: 2.1583901842435202

Epoch: 6| Step: 3
Training loss: 1.8842668533325195
Validation loss: 2.1543490091959634

Epoch: 6| Step: 4
Training loss: 2.0401206016540527
Validation loss: 2.1665632724761963

Epoch: 6| Step: 5
Training loss: 1.1438792943954468
Validation loss: 2.1370840072631836

Epoch: 6| Step: 6
Training loss: 1.774933934211731
Validation loss: 2.155354698499044

Epoch: 6| Step: 7
Training loss: 1.4945499897003174
Validation loss: 2.154121239980062

Epoch: 6| Step: 8
Training loss: 2.2140307426452637
Validation loss: 2.1485610802968345

Epoch: 6| Step: 9
Training loss: 2.0880086421966553
Validation loss: 2.155416786670685

Epoch: 6| Step: 10
Training loss: 1.1984578371047974
Validation loss: 2.1455390652020774

Epoch: 6| Step: 11
Training loss: 1.8925371170043945
Validation loss: 2.1757861971855164

Epoch: 6| Step: 12
Training loss: 1.897452473640442
Validation loss: 2.1914332707722983

Epoch: 6| Step: 13
Training loss: 1.9979000091552734
Validation loss: 2.184555927912394

Epoch: 220| Step: 0
Training loss: 1.2109074592590332
Validation loss: 2.173201580842336

Epoch: 6| Step: 1
Training loss: 2.156771183013916
Validation loss: 2.1664780577023826

Epoch: 6| Step: 2
Training loss: 2.3741536140441895
Validation loss: 2.168046534061432

Epoch: 6| Step: 3
Training loss: 1.8644719123840332
Validation loss: 2.1640846530596414

Epoch: 6| Step: 4
Training loss: 2.1903603076934814
Validation loss: 2.173115928967794

Epoch: 6| Step: 5
Training loss: 2.336731433868408
Validation loss: 2.172697106997172

Epoch: 6| Step: 6
Training loss: 1.5233536958694458
Validation loss: 2.1735629638036094

Epoch: 6| Step: 7
Training loss: 1.6594069004058838
Validation loss: 2.1595587730407715

Epoch: 6| Step: 8
Training loss: 2.1129555702209473
Validation loss: 2.172651708126068

Epoch: 6| Step: 9
Training loss: 1.4554880857467651
Validation loss: 2.171059528986613

Epoch: 6| Step: 10
Training loss: 1.668121337890625
Validation loss: 2.155105471611023

Epoch: 6| Step: 11
Training loss: 1.6724320650100708
Validation loss: 2.1574254433314004

Epoch: 6| Step: 12
Training loss: 1.4843757152557373
Validation loss: 2.1489749352137246

Epoch: 6| Step: 13
Training loss: 2.4139320850372314
Validation loss: 2.1630118687947593

Epoch: 221| Step: 0
Training loss: 2.0540478229522705
Validation loss: 2.179600954055786

Epoch: 6| Step: 1
Training loss: 1.7508732080459595
Validation loss: 2.1914857625961304

Epoch: 6| Step: 2
Training loss: 1.521817922592163
Validation loss: 2.1856897672017417

Epoch: 6| Step: 3
Training loss: 1.9748115539550781
Validation loss: 2.212122599283854

Epoch: 6| Step: 4
Training loss: 2.5374934673309326
Validation loss: 2.1985318660736084

Epoch: 6| Step: 5
Training loss: 2.0831706523895264
Validation loss: 2.194717446962992

Epoch: 6| Step: 6
Training loss: 2.032834053039551
Validation loss: 2.178288698196411

Epoch: 6| Step: 7
Training loss: 1.383300542831421
Validation loss: 2.1728482643763223

Epoch: 6| Step: 8
Training loss: 1.39181387424469
Validation loss: 2.177706261475881

Epoch: 6| Step: 9
Training loss: 2.3258047103881836
Validation loss: 2.18914794921875

Epoch: 6| Step: 10
Training loss: 1.6280241012573242
Validation loss: 2.1767008701960244

Epoch: 6| Step: 11
Training loss: 1.727360486984253
Validation loss: 2.174264371395111

Epoch: 6| Step: 12
Training loss: 1.655916690826416
Validation loss: 2.1845045685768127

Epoch: 6| Step: 13
Training loss: 1.8137586116790771
Validation loss: 2.176854431629181

Epoch: 222| Step: 0
Training loss: 1.9240885972976685
Validation loss: 2.1746074557304382

Epoch: 6| Step: 1
Training loss: 0.9398324489593506
Validation loss: 2.180283784866333

Epoch: 6| Step: 2
Training loss: 1.6391990184783936
Validation loss: 2.182776470979055

Epoch: 6| Step: 3
Training loss: 2.660299777984619
Validation loss: 2.2017951011657715

Epoch: 6| Step: 4
Training loss: 2.342287540435791
Validation loss: 2.1873989502588906

Epoch: 6| Step: 5
Training loss: 2.5597026348114014
Validation loss: 2.188354750474294

Epoch: 6| Step: 6
Training loss: 2.061878204345703
Validation loss: 2.190128525098165

Epoch: 6| Step: 7
Training loss: 1.7312315702438354
Validation loss: 2.1784902016321817

Epoch: 6| Step: 8
Training loss: 2.176992416381836
Validation loss: 2.180954853693644

Epoch: 6| Step: 9
Training loss: 1.529677391052246
Validation loss: 2.1785953442255654

Epoch: 6| Step: 10
Training loss: 1.324613332748413
Validation loss: 2.186866303284963

Epoch: 6| Step: 11
Training loss: 1.5612764358520508
Validation loss: 2.1613818407058716

Epoch: 6| Step: 12
Training loss: 1.7948908805847168
Validation loss: 2.155795137087504

Epoch: 6| Step: 13
Training loss: 1.5521029233932495
Validation loss: 2.1736468275388083

Epoch: 223| Step: 0
Training loss: 2.5020556449890137
Validation loss: 2.1688894828160605

Epoch: 6| Step: 1
Training loss: 1.9534579515457153
Validation loss: 2.1491549611091614

Epoch: 6| Step: 2
Training loss: 0.909839928150177
Validation loss: 2.169721225897471

Epoch: 6| Step: 3
Training loss: 1.59011709690094
Validation loss: 2.1607852578163147

Epoch: 6| Step: 4
Training loss: 2.5237488746643066
Validation loss: 2.1738824049631753

Epoch: 6| Step: 5
Training loss: 1.3499866724014282
Validation loss: 2.1750952204068503

Epoch: 6| Step: 6
Training loss: 1.747732400894165
Validation loss: 2.15038655201594

Epoch: 6| Step: 7
Training loss: 2.2314019203186035
Validation loss: 2.1543803215026855

Epoch: 6| Step: 8
Training loss: 1.1140435934066772
Validation loss: 2.1539080142974854

Epoch: 6| Step: 9
Training loss: 1.630314826965332
Validation loss: 2.194770038127899

Epoch: 6| Step: 10
Training loss: 1.8614039421081543
Validation loss: 2.1737675269444785

Epoch: 6| Step: 11
Training loss: 2.241994619369507
Validation loss: 2.1633484760920205

Epoch: 6| Step: 12
Training loss: 2.0047755241394043
Validation loss: 2.180083453655243

Epoch: 6| Step: 13
Training loss: 1.9023423194885254
Validation loss: 2.1917006174723306

Epoch: 224| Step: 0
Training loss: 2.602992534637451
Validation loss: 2.201597491900126

Epoch: 6| Step: 1
Training loss: 2.7859725952148438
Validation loss: 2.1993566751480103

Epoch: 6| Step: 2
Training loss: 1.9823939800262451
Validation loss: 2.1911979715029397

Epoch: 6| Step: 3
Training loss: 1.9422619342803955
Validation loss: 2.1839222510655723

Epoch: 6| Step: 4
Training loss: 1.943487286567688
Validation loss: 2.1706632574399314

Epoch: 6| Step: 5
Training loss: 1.8441886901855469
Validation loss: 2.189192752043406

Epoch: 6| Step: 6
Training loss: 1.847177267074585
Validation loss: 2.1755178372065225

Epoch: 6| Step: 7
Training loss: 1.0952030420303345
Validation loss: 2.16233758131663

Epoch: 6| Step: 8
Training loss: 1.6422091722488403
Validation loss: 2.168281535307566

Epoch: 6| Step: 9
Training loss: 1.6484097242355347
Validation loss: 2.1730765104293823

Epoch: 6| Step: 10
Training loss: 2.0023791790008545
Validation loss: 2.1390657822291055

Epoch: 6| Step: 11
Training loss: 2.318314552307129
Validation loss: 2.1254976391792297

Epoch: 6| Step: 12
Training loss: 1.7985777854919434
Validation loss: 2.1459065278371177

Epoch: 6| Step: 13
Training loss: 1.024879813194275
Validation loss: 2.134249190489451

Epoch: 225| Step: 0
Training loss: 1.3287569284439087
Validation loss: 2.135123610496521

Epoch: 6| Step: 1
Training loss: 1.7689332962036133
Validation loss: 2.126030743122101

Epoch: 6| Step: 2
Training loss: 1.9803521633148193
Validation loss: 2.1462594270706177

Epoch: 6| Step: 3
Training loss: 1.7166790962219238
Validation loss: 2.141154666741689

Epoch: 6| Step: 4
Training loss: 1.6527899503707886
Validation loss: 2.162457227706909

Epoch: 6| Step: 5
Training loss: 1.5460231304168701
Validation loss: 2.173470934232076

Epoch: 6| Step: 6
Training loss: 1.8709681034088135
Validation loss: 2.160673201084137

Epoch: 6| Step: 7
Training loss: 1.6665656566619873
Validation loss: 2.1842931509017944

Epoch: 6| Step: 8
Training loss: 2.003845691680908
Validation loss: 2.1715331276257834

Epoch: 6| Step: 9
Training loss: 1.6859995126724243
Validation loss: 2.1768884658813477

Epoch: 6| Step: 10
Training loss: 2.846190929412842
Validation loss: 2.171482563018799

Epoch: 6| Step: 11
Training loss: 2.3873848915100098
Validation loss: 2.213225503762563

Epoch: 6| Step: 12
Training loss: 1.581291675567627
Validation loss: 2.227392395337423

Epoch: 6| Step: 13
Training loss: 2.1060538291931152
Validation loss: 2.2318124572436013

Epoch: 226| Step: 0
Training loss: 1.3980801105499268
Validation loss: 2.2140646974245706

Epoch: 6| Step: 1
Training loss: 2.130594253540039
Validation loss: 2.252535422643026

Epoch: 6| Step: 2
Training loss: 2.0086863040924072
Validation loss: 2.2377471129099527

Epoch: 6| Step: 3
Training loss: 2.3024449348449707
Validation loss: 2.220050315062205

Epoch: 6| Step: 4
Training loss: 2.4093880653381348
Validation loss: 2.2019044160842896

Epoch: 6| Step: 5
Training loss: 1.7865018844604492
Validation loss: 2.2209047079086304

Epoch: 6| Step: 6
Training loss: 2.0458362102508545
Validation loss: 2.1853318413098655

Epoch: 6| Step: 7
Training loss: 1.716688632965088
Validation loss: 2.1841230988502502

Epoch: 6| Step: 8
Training loss: 2.368929147720337
Validation loss: 2.150992492834727

Epoch: 6| Step: 9
Training loss: 1.7597123384475708
Validation loss: 2.1654663483301797

Epoch: 6| Step: 10
Training loss: 1.611249327659607
Validation loss: 2.1615081230799356

Epoch: 6| Step: 11
Training loss: 1.4157562255859375
Validation loss: 2.155385434627533

Epoch: 6| Step: 12
Training loss: 1.526141881942749
Validation loss: 2.1356563568115234

Epoch: 6| Step: 13
Training loss: 2.0313172340393066
Validation loss: 2.14964497089386

Epoch: 227| Step: 0
Training loss: 2.3490567207336426
Validation loss: 2.1533576250076294

Epoch: 6| Step: 1
Training loss: 1.350812554359436
Validation loss: 2.1548736890157065

Epoch: 6| Step: 2
Training loss: 2.25370454788208
Validation loss: 2.153493106365204

Epoch: 6| Step: 3
Training loss: 1.571869134902954
Validation loss: 2.1790269017219543

Epoch: 6| Step: 4
Training loss: 1.4198520183563232
Validation loss: 2.1821487744649253

Epoch: 6| Step: 5
Training loss: 1.8009812831878662
Validation loss: 2.1750545700391135

Epoch: 6| Step: 6
Training loss: 1.48008131980896
Validation loss: 2.1900353034337363

Epoch: 6| Step: 7
Training loss: 2.0060760974884033
Validation loss: 2.1727837721506753

Epoch: 6| Step: 8
Training loss: 2.374454975128174
Validation loss: 2.1924051443735757

Epoch: 6| Step: 9
Training loss: 2.3418374061584473
Validation loss: 2.19010724623998

Epoch: 6| Step: 10
Training loss: 1.9770641326904297
Validation loss: 2.188262482484182

Epoch: 6| Step: 11
Training loss: 1.4470542669296265
Validation loss: 2.186117112636566

Epoch: 6| Step: 12
Training loss: 1.3580149412155151
Validation loss: 2.1838932832082114

Epoch: 6| Step: 13
Training loss: 1.911399245262146
Validation loss: 2.190028170744578

Epoch: 228| Step: 0
Training loss: 1.9766374826431274
Validation loss: 2.1804810563723245

Epoch: 6| Step: 1
Training loss: 2.373718738555908
Validation loss: 2.1738065083821616

Epoch: 6| Step: 2
Training loss: 1.341158151626587
Validation loss: 2.174190104007721

Epoch: 6| Step: 3
Training loss: 2.445070743560791
Validation loss: 2.164742171764374

Epoch: 6| Step: 4
Training loss: 1.4923312664031982
Validation loss: 2.156380554040273

Epoch: 6| Step: 5
Training loss: 1.962457537651062
Validation loss: 2.1648439168930054

Epoch: 6| Step: 6
Training loss: 1.8980774879455566
Validation loss: 2.1577803691228232

Epoch: 6| Step: 7
Training loss: 1.853599190711975
Validation loss: 2.1750267148017883

Epoch: 6| Step: 8
Training loss: 1.8488749265670776
Validation loss: 2.1676371892293296

Epoch: 6| Step: 9
Training loss: 1.3972082138061523
Validation loss: 2.1605884234110513

Epoch: 6| Step: 10
Training loss: 1.032313346862793
Validation loss: 2.1705602010091147

Epoch: 6| Step: 11
Training loss: 1.9142241477966309
Validation loss: 2.1619573831558228

Epoch: 6| Step: 12
Training loss: 2.233257532119751
Validation loss: 2.187458614508311

Epoch: 6| Step: 13
Training loss: 1.8116719722747803
Validation loss: 2.168553630510966

Epoch: 229| Step: 0
Training loss: 2.8256869316101074
Validation loss: 2.170180837313334

Epoch: 6| Step: 1
Training loss: 2.4578258991241455
Validation loss: 2.1908069252967834

Epoch: 6| Step: 2
Training loss: 1.9553165435791016
Validation loss: 2.1794128020604453

Epoch: 6| Step: 3
Training loss: 2.0487849712371826
Validation loss: 2.173775295416514

Epoch: 6| Step: 4
Training loss: 1.9289343357086182
Validation loss: 2.167780339717865

Epoch: 6| Step: 5
Training loss: 1.7319517135620117
Validation loss: 2.179920196533203

Epoch: 6| Step: 6
Training loss: 1.4527887105941772
Validation loss: 2.1615570783615112

Epoch: 6| Step: 7
Training loss: 2.067563056945801
Validation loss: 2.16619735956192

Epoch: 6| Step: 8
Training loss: 1.157204270362854
Validation loss: 2.1882887482643127

Epoch: 6| Step: 9
Training loss: 1.5240864753723145
Validation loss: 2.1940490206082663

Epoch: 6| Step: 10
Training loss: 1.3915739059448242
Validation loss: 2.1848293344179788

Epoch: 6| Step: 11
Training loss: 1.8412184715270996
Validation loss: 2.170532782872518

Epoch: 6| Step: 12
Training loss: 1.4113726615905762
Validation loss: 2.1838783820470176

Epoch: 6| Step: 13
Training loss: 1.4955105781555176
Validation loss: 2.175141235192617

Epoch: 230| Step: 0
Training loss: 2.5699195861816406
Validation loss: 2.1988333662350974

Epoch: 6| Step: 1
Training loss: 2.1981163024902344
Validation loss: 2.199443737665812

Epoch: 6| Step: 2
Training loss: 1.782480239868164
Validation loss: 2.1823869546254477

Epoch: 6| Step: 3
Training loss: 1.9158395528793335
Validation loss: 2.1993530988693237

Epoch: 6| Step: 4
Training loss: 1.8335016965866089
Validation loss: 2.201385974884033

Epoch: 6| Step: 5
Training loss: 1.95526123046875
Validation loss: 2.175656874974569

Epoch: 6| Step: 6
Training loss: 1.3737517595291138
Validation loss: 2.1654969453811646

Epoch: 6| Step: 7
Training loss: 1.387413740158081
Validation loss: 2.1729809244473777

Epoch: 6| Step: 8
Training loss: 1.5151864290237427
Validation loss: 2.153693437576294

Epoch: 6| Step: 9
Training loss: 1.9786698818206787
Validation loss: 2.160384257634481

Epoch: 6| Step: 10
Training loss: 1.6259629726409912
Validation loss: 2.1507937908172607

Epoch: 6| Step: 11
Training loss: 2.23197078704834
Validation loss: 2.1387473742167153

Epoch: 6| Step: 12
Training loss: 1.9608609676361084
Validation loss: 2.133506258328756

Epoch: 6| Step: 13
Training loss: 1.5475857257843018
Validation loss: 2.1348748207092285

Epoch: 231| Step: 0
Training loss: 1.3143507242202759
Validation loss: 2.142873446146647

Epoch: 6| Step: 1
Training loss: 1.9037450551986694
Validation loss: 2.1326754887898765

Epoch: 6| Step: 2
Training loss: 2.581027030944824
Validation loss: 2.138027548789978

Epoch: 6| Step: 3
Training loss: 1.6320674419403076
Validation loss: 2.149241348107656

Epoch: 6| Step: 4
Training loss: 1.6178863048553467
Validation loss: 2.146954973538717

Epoch: 6| Step: 5
Training loss: 1.5085855722427368
Validation loss: 2.13792218764623

Epoch: 6| Step: 6
Training loss: 1.9067983627319336
Validation loss: 2.159228960673014

Epoch: 6| Step: 7
Training loss: 2.1439552307128906
Validation loss: 2.1588847041130066

Epoch: 6| Step: 8
Training loss: 2.3757920265197754
Validation loss: 2.1678099830945334

Epoch: 6| Step: 9
Training loss: 1.7141011953353882
Validation loss: 2.164782166481018

Epoch: 6| Step: 10
Training loss: 1.7037484645843506
Validation loss: 2.186883012453715

Epoch: 6| Step: 11
Training loss: 2.1838488578796387
Validation loss: 2.2002281745274863

Epoch: 6| Step: 12
Training loss: 1.9297447204589844
Validation loss: 2.197054902712504

Epoch: 6| Step: 13
Training loss: 1.707453966140747
Validation loss: 2.1762625575065613

Epoch: 232| Step: 0
Training loss: 1.7029142379760742
Validation loss: 2.1982288360595703

Epoch: 6| Step: 1
Training loss: 1.8527226448059082
Validation loss: 2.203622897466024

Epoch: 6| Step: 2
Training loss: 1.9951903820037842
Validation loss: 2.1937211751937866

Epoch: 6| Step: 3
Training loss: 1.7405171394348145
Validation loss: 2.2025745113690696

Epoch: 6| Step: 4
Training loss: 2.291515350341797
Validation loss: 2.207561651865641

Epoch: 6| Step: 5
Training loss: 1.2868943214416504
Validation loss: 2.1744424700737

Epoch: 6| Step: 6
Training loss: 1.5155224800109863
Validation loss: 2.167668600877126

Epoch: 6| Step: 7
Training loss: 1.6895060539245605
Validation loss: 2.144813060760498

Epoch: 6| Step: 8
Training loss: 2.928305149078369
Validation loss: 2.145932952562968

Epoch: 6| Step: 9
Training loss: 1.918597936630249
Validation loss: 2.134259025255839

Epoch: 6| Step: 10
Training loss: 1.7422900199890137
Validation loss: 2.1521360675493875

Epoch: 6| Step: 11
Training loss: 1.8645042181015015
Validation loss: 2.1553694804509482

Epoch: 6| Step: 12
Training loss: 1.8773558139801025
Validation loss: 2.152998765309652

Epoch: 6| Step: 13
Training loss: 1.9853901863098145
Validation loss: 2.156642516454061

Epoch: 233| Step: 0
Training loss: 2.755093574523926
Validation loss: 2.1615458329518638

Epoch: 6| Step: 1
Training loss: 1.466366171836853
Validation loss: 2.1481118400891623

Epoch: 6| Step: 2
Training loss: 1.4783968925476074
Validation loss: 2.143227239449819

Epoch: 6| Step: 3
Training loss: 2.392331600189209
Validation loss: 2.16510138909022

Epoch: 6| Step: 4
Training loss: 1.5079644918441772
Validation loss: 2.1605315605799356

Epoch: 6| Step: 5
Training loss: 1.6819100379943848
Validation loss: 2.1511989633242288

Epoch: 6| Step: 6
Training loss: 1.9526257514953613
Validation loss: 2.1661965052286782

Epoch: 6| Step: 7
Training loss: 1.6109275817871094
Validation loss: 2.1595283150672913

Epoch: 6| Step: 8
Training loss: 1.7903295755386353
Validation loss: 2.170768121878306

Epoch: 6| Step: 9
Training loss: 1.5320980548858643
Validation loss: 2.155470371246338

Epoch: 6| Step: 10
Training loss: 2.3953170776367188
Validation loss: 2.158465643723806

Epoch: 6| Step: 11
Training loss: 1.8702198266983032
Validation loss: 2.1653058727582297

Epoch: 6| Step: 12
Training loss: 1.6807096004486084
Validation loss: 2.1632222334543862

Epoch: 6| Step: 13
Training loss: 1.4587090015411377
Validation loss: 2.178012510140737

Epoch: 234| Step: 0
Training loss: 2.3799996376037598
Validation loss: 2.1671926180521646

Epoch: 6| Step: 1
Training loss: 1.4170608520507812
Validation loss: 2.1533222993214927

Epoch: 6| Step: 2
Training loss: 2.54366135597229
Validation loss: 2.166534701983134

Epoch: 6| Step: 3
Training loss: 1.8589462041854858
Validation loss: 2.170371154944102

Epoch: 6| Step: 4
Training loss: 1.5617785453796387
Validation loss: 2.1631116469701133

Epoch: 6| Step: 5
Training loss: 1.6062912940979004
Validation loss: 2.163203001022339

Epoch: 6| Step: 6
Training loss: 2.0892720222473145
Validation loss: 2.1615836024284363

Epoch: 6| Step: 7
Training loss: 2.1260013580322266
Validation loss: 2.1711321274439492

Epoch: 6| Step: 8
Training loss: 1.6473562717437744
Validation loss: 2.1687180201212564

Epoch: 6| Step: 9
Training loss: 1.7461211681365967
Validation loss: 2.1791361371676126

Epoch: 6| Step: 10
Training loss: 2.1036317348480225
Validation loss: 2.1748710672060647

Epoch: 6| Step: 11
Training loss: 1.3255467414855957
Validation loss: 2.189941167831421

Epoch: 6| Step: 12
Training loss: 1.5194778442382812
Validation loss: 2.209023098150889

Epoch: 6| Step: 13
Training loss: 1.7132086753845215
Validation loss: 2.204027016957601

Epoch: 235| Step: 0
Training loss: 1.3004119396209717
Validation loss: 2.2312570015589395

Epoch: 6| Step: 1
Training loss: 1.7962161302566528
Validation loss: 2.2162629763285318

Epoch: 6| Step: 2
Training loss: 2.246108055114746
Validation loss: 2.2258275747299194

Epoch: 6| Step: 3
Training loss: 1.9852356910705566
Validation loss: 2.2255487044652305

Epoch: 6| Step: 4
Training loss: 1.7541896104812622
Validation loss: 2.2175795435905457

Epoch: 6| Step: 5
Training loss: 1.6065291166305542
Validation loss: 2.199658751487732

Epoch: 6| Step: 6
Training loss: 2.0328359603881836
Validation loss: 2.2027374108632407

Epoch: 6| Step: 7
Training loss: 1.8266980648040771
Validation loss: 2.180370648701986

Epoch: 6| Step: 8
Training loss: 1.535735845565796
Validation loss: 2.18783030907313

Epoch: 6| Step: 9
Training loss: 1.6924231052398682
Validation loss: 2.175569752852122

Epoch: 6| Step: 10
Training loss: 2.2659220695495605
Validation loss: 2.1895214319229126

Epoch: 6| Step: 11
Training loss: 1.8683533668518066
Validation loss: 2.2014390031496682

Epoch: 6| Step: 12
Training loss: 1.0878996849060059
Validation loss: 2.164831558863322

Epoch: 6| Step: 13
Training loss: 2.1013922691345215
Validation loss: 2.1861714124679565

Epoch: 236| Step: 0
Training loss: 1.9379382133483887
Validation loss: 2.1718693176905313

Epoch: 6| Step: 1
Training loss: 2.673328399658203
Validation loss: 2.191245416800181

Epoch: 6| Step: 2
Training loss: 1.5035388469696045
Validation loss: 2.19972558816274

Epoch: 6| Step: 3
Training loss: 1.9387019872665405
Validation loss: 2.2164459427197776

Epoch: 6| Step: 4
Training loss: 2.1837728023529053
Validation loss: 2.215276598930359

Epoch: 6| Step: 5
Training loss: 1.3916432857513428
Validation loss: 2.2367359399795532

Epoch: 6| Step: 6
Training loss: 1.9865598678588867
Validation loss: 2.207390248775482

Epoch: 6| Step: 7
Training loss: 1.9889965057373047
Validation loss: 2.211908002694448

Epoch: 6| Step: 8
Training loss: 1.76755690574646
Validation loss: 2.2076706488927207

Epoch: 6| Step: 9
Training loss: 1.6542515754699707
Validation loss: 2.1745136976242065

Epoch: 6| Step: 10
Training loss: 1.785825490951538
Validation loss: 2.162951429684957

Epoch: 6| Step: 11
Training loss: 1.5986316204071045
Validation loss: 2.161059478918711

Epoch: 6| Step: 12
Training loss: 2.3229048252105713
Validation loss: 2.151715040206909

Epoch: 6| Step: 13
Training loss: 1.3803598880767822
Validation loss: 2.160879611968994

Epoch: 237| Step: 0
Training loss: 1.901545524597168
Validation loss: 2.135916252930959

Epoch: 6| Step: 1
Training loss: 1.7809092998504639
Validation loss: 2.143949548403422

Epoch: 6| Step: 2
Training loss: 1.959071159362793
Validation loss: 2.1509875059127808

Epoch: 6| Step: 3
Training loss: 2.1537818908691406
Validation loss: 2.173786461353302

Epoch: 6| Step: 4
Training loss: 2.2031776905059814
Validation loss: 2.1712918082873025

Epoch: 6| Step: 5
Training loss: 1.9949771165847778
Validation loss: 2.161771237850189

Epoch: 6| Step: 6
Training loss: 1.4364449977874756
Validation loss: 2.1620944937070212

Epoch: 6| Step: 7
Training loss: 1.8097362518310547
Validation loss: 2.1757763425509133

Epoch: 6| Step: 8
Training loss: 1.5942670106887817
Validation loss: 2.1957454085350037

Epoch: 6| Step: 9
Training loss: 2.2565629482269287
Validation loss: 2.166423718134562

Epoch: 6| Step: 10
Training loss: 1.7823328971862793
Validation loss: 2.157875577608744

Epoch: 6| Step: 11
Training loss: 1.8745102882385254
Validation loss: 2.153393566608429

Epoch: 6| Step: 12
Training loss: 1.3859665393829346
Validation loss: 2.1688136061032615

Epoch: 6| Step: 13
Training loss: 1.1935572624206543
Validation loss: 2.1634528636932373

Epoch: 238| Step: 0
Training loss: 1.9684998989105225
Validation loss: 2.210432529449463

Epoch: 6| Step: 1
Training loss: 1.3936500549316406
Validation loss: 2.154713968435923

Epoch: 6| Step: 2
Training loss: 2.175835132598877
Validation loss: 2.1852142612139382

Epoch: 6| Step: 3
Training loss: 1.7223036289215088
Validation loss: 2.184462865193685

Epoch: 6| Step: 4
Training loss: 2.120048999786377
Validation loss: 2.1850516398747764

Epoch: 6| Step: 5
Training loss: 1.7653028964996338
Validation loss: 2.2016737262407937

Epoch: 6| Step: 6
Training loss: 1.5961551666259766
Validation loss: 2.2072377602259317

Epoch: 6| Step: 7
Training loss: 1.8915443420410156
Validation loss: 2.197502772013346

Epoch: 6| Step: 8
Training loss: 1.4333277940750122
Validation loss: 2.21082466840744

Epoch: 6| Step: 9
Training loss: 1.1921968460083008
Validation loss: 2.2071119944254556

Epoch: 6| Step: 10
Training loss: 1.5462405681610107
Validation loss: 2.1793243487675986

Epoch: 6| Step: 11
Training loss: 1.9068458080291748
Validation loss: 2.2094024419784546

Epoch: 6| Step: 12
Training loss: 2.0337185859680176
Validation loss: 2.195064822832743

Epoch: 6| Step: 13
Training loss: 2.325993061065674
Validation loss: 2.2085753083229065

Epoch: 239| Step: 0
Training loss: 1.812575340270996
Validation loss: 2.180074612299601

Epoch: 6| Step: 1
Training loss: 1.5514945983886719
Validation loss: 2.1979377071062722

Epoch: 6| Step: 2
Training loss: 2.031620502471924
Validation loss: 2.18642928202947

Epoch: 6| Step: 3
Training loss: 1.602077603340149
Validation loss: 2.191611409187317

Epoch: 6| Step: 4
Training loss: 2.4960849285125732
Validation loss: 2.1992688179016113

Epoch: 6| Step: 5
Training loss: 2.113485336303711
Validation loss: 2.186641275882721

Epoch: 6| Step: 6
Training loss: 1.7136147022247314
Validation loss: 2.194701850414276

Epoch: 6| Step: 7
Training loss: 1.86073899269104
Validation loss: 2.181799511114756

Epoch: 6| Step: 8
Training loss: 1.8259727954864502
Validation loss: 2.200561285018921

Epoch: 6| Step: 9
Training loss: 1.4292230606079102
Validation loss: 2.2132521867752075

Epoch: 6| Step: 10
Training loss: 1.6200263500213623
Validation loss: 2.198307156562805

Epoch: 6| Step: 11
Training loss: 1.8674845695495605
Validation loss: 2.197769502798716

Epoch: 6| Step: 12
Training loss: 1.6295061111450195
Validation loss: 2.18737131357193

Epoch: 6| Step: 13
Training loss: 1.6810972690582275
Validation loss: 2.212366978327433

Epoch: 240| Step: 0
Training loss: 1.8336451053619385
Validation loss: 2.189431349436442

Epoch: 6| Step: 1
Training loss: 2.1768553256988525
Validation loss: 2.2134694258371987

Epoch: 6| Step: 2
Training loss: 1.5318008661270142
Validation loss: 2.195204178492228

Epoch: 6| Step: 3
Training loss: 2.3098011016845703
Validation loss: 2.197097142537435

Epoch: 6| Step: 4
Training loss: 1.4107389450073242
Validation loss: 2.195110241572062

Epoch: 6| Step: 5
Training loss: 1.7069765329360962
Validation loss: 2.1907885670661926

Epoch: 6| Step: 6
Training loss: 1.5716075897216797
Validation loss: 2.1843727231025696

Epoch: 6| Step: 7
Training loss: 1.9764537811279297
Validation loss: 2.201881249745687

Epoch: 6| Step: 8
Training loss: 1.3859479427337646
Validation loss: 2.173641781012217

Epoch: 6| Step: 9
Training loss: 2.337034225463867
Validation loss: 2.1741228501001992

Epoch: 6| Step: 10
Training loss: 2.2085187435150146
Validation loss: 2.196309983730316

Epoch: 6| Step: 11
Training loss: 1.7357566356658936
Validation loss: 2.20015956958135

Epoch: 6| Step: 12
Training loss: 1.4747669696807861
Validation loss: 2.2205329736073813

Epoch: 6| Step: 13
Training loss: 1.581969976425171
Validation loss: 2.1966972748438516

Epoch: 241| Step: 0
Training loss: 1.3332409858703613
Validation loss: 2.203803857167562

Epoch: 6| Step: 1
Training loss: 1.9300419092178345
Validation loss: 2.207116405169169

Epoch: 6| Step: 2
Training loss: 1.8939045667648315
Validation loss: 2.2051722208658853

Epoch: 6| Step: 3
Training loss: 1.5067638158798218
Validation loss: 2.214226762453715

Epoch: 6| Step: 4
Training loss: 2.345296621322632
Validation loss: 2.219333748022715

Epoch: 6| Step: 5
Training loss: 2.376147747039795
Validation loss: 2.2358121275901794

Epoch: 6| Step: 6
Training loss: 1.2598391771316528
Validation loss: 2.225189983844757

Epoch: 6| Step: 7
Training loss: 1.89101243019104
Validation loss: 2.214022974173228

Epoch: 6| Step: 8
Training loss: 1.3744406700134277
Validation loss: 2.2224369843800864

Epoch: 6| Step: 9
Training loss: 1.710251808166504
Validation loss: 2.231842597325643

Epoch: 6| Step: 10
Training loss: 2.6843514442443848
Validation loss: 2.218791405359904

Epoch: 6| Step: 11
Training loss: 1.4620856046676636
Validation loss: 2.2262913584709167

Epoch: 6| Step: 12
Training loss: 1.067910075187683
Validation loss: 2.2064003944396973

Epoch: 6| Step: 13
Training loss: 2.128035068511963
Validation loss: 2.181666394074758

Epoch: 242| Step: 0
Training loss: 2.4321975708007812
Validation loss: 2.202002167701721

Epoch: 6| Step: 1
Training loss: 1.238628625869751
Validation loss: 2.2115543286005654

Epoch: 6| Step: 2
Training loss: 1.5138428211212158
Validation loss: 2.1827991008758545

Epoch: 6| Step: 3
Training loss: 1.4136390686035156
Validation loss: 2.197794477144877

Epoch: 6| Step: 4
Training loss: 1.6895508766174316
Validation loss: 2.2063733537991843

Epoch: 6| Step: 5
Training loss: 2.6859803199768066
Validation loss: 2.184570630391439

Epoch: 6| Step: 6
Training loss: 1.4295690059661865
Validation loss: 2.1993505160013833

Epoch: 6| Step: 7
Training loss: 1.662309169769287
Validation loss: 2.182132919629415

Epoch: 6| Step: 8
Training loss: 1.8713228702545166
Validation loss: 2.2147849202156067

Epoch: 6| Step: 9
Training loss: 1.8195974826812744
Validation loss: 2.1852699716885886

Epoch: 6| Step: 10
Training loss: 1.8710331916809082
Validation loss: 2.2083197037378945

Epoch: 6| Step: 11
Training loss: 1.9008095264434814
Validation loss: 2.201859732468923

Epoch: 6| Step: 12
Training loss: 1.411386489868164
Validation loss: 2.2267707188924155

Epoch: 6| Step: 13
Training loss: 1.6817643642425537
Validation loss: 2.213444987932841

Epoch: 243| Step: 0
Training loss: 1.5949606895446777
Validation loss: 2.2294722398122153

Epoch: 6| Step: 1
Training loss: 2.2984626293182373
Validation loss: 2.2231215834617615

Epoch: 6| Step: 2
Training loss: 1.7756847143173218
Validation loss: 2.2146751284599304

Epoch: 6| Step: 3
Training loss: 1.3236539363861084
Validation loss: 2.192888339360555

Epoch: 6| Step: 4
Training loss: 1.992598533630371
Validation loss: 2.1876832445462546

Epoch: 6| Step: 5
Training loss: 1.6737077236175537
Validation loss: 2.1809173226356506

Epoch: 6| Step: 6
Training loss: 1.658980369567871
Validation loss: 2.174386421839396

Epoch: 6| Step: 7
Training loss: 1.1027922630310059
Validation loss: 2.1753350297609964

Epoch: 6| Step: 8
Training loss: 1.8874257802963257
Validation loss: 2.1753859917322793

Epoch: 6| Step: 9
Training loss: 1.7802609205245972
Validation loss: 2.187702695528666

Epoch: 6| Step: 10
Training loss: 1.8422715663909912
Validation loss: 2.1889482537905374

Epoch: 6| Step: 11
Training loss: 2.1181094646453857
Validation loss: 2.207140803337097

Epoch: 6| Step: 12
Training loss: 2.180640459060669
Validation loss: 2.207955817381541

Epoch: 6| Step: 13
Training loss: 2.0020864009857178
Validation loss: 2.2237746516863504

Epoch: 244| Step: 0
Training loss: 1.4391034841537476
Validation loss: 2.2051591873168945

Epoch: 6| Step: 1
Training loss: 1.6503584384918213
Validation loss: 2.18802938858668

Epoch: 6| Step: 2
Training loss: 2.162221908569336
Validation loss: 2.1921503941218057

Epoch: 6| Step: 3
Training loss: 2.0974912643432617
Validation loss: 2.1944863200187683

Epoch: 6| Step: 4
Training loss: 1.023163914680481
Validation loss: 2.185012956460317

Epoch: 6| Step: 5
Training loss: 1.6345360279083252
Validation loss: 2.176438351472219

Epoch: 6| Step: 6
Training loss: 1.777658462524414
Validation loss: 2.1766604582468667

Epoch: 6| Step: 7
Training loss: 1.5892696380615234
Validation loss: 2.179888049761454

Epoch: 6| Step: 8
Training loss: 2.0861973762512207
Validation loss: 2.184820572535197

Epoch: 6| Step: 9
Training loss: 2.7503623962402344
Validation loss: 2.1833712458610535

Epoch: 6| Step: 10
Training loss: 1.9388819932937622
Validation loss: 2.1802083055178323

Epoch: 6| Step: 11
Training loss: 1.554942011833191
Validation loss: 2.1943235397338867

Epoch: 6| Step: 12
Training loss: 1.5471413135528564
Validation loss: 2.176438808441162

Epoch: 6| Step: 13
Training loss: 1.670081377029419
Validation loss: 2.200316389401754

Epoch: 245| Step: 0
Training loss: 1.2281396389007568
Validation loss: 2.1819795767466226

Epoch: 6| Step: 1
Training loss: 2.75785493850708
Validation loss: 2.1786378423372903

Epoch: 6| Step: 2
Training loss: 1.6295192241668701
Validation loss: 2.2091976006825766

Epoch: 6| Step: 3
Training loss: 2.1749162673950195
Validation loss: 2.1987051367759705

Epoch: 6| Step: 4
Training loss: 1.9768277406692505
Validation loss: 2.1973231633504233

Epoch: 6| Step: 5
Training loss: 1.1039857864379883
Validation loss: 2.1919052600860596

Epoch: 6| Step: 6
Training loss: 1.6451683044433594
Validation loss: 2.1822325388590493

Epoch: 6| Step: 7
Training loss: 1.8468053340911865
Validation loss: 2.1736425161361694

Epoch: 6| Step: 8
Training loss: 1.3359531164169312
Validation loss: 2.1705848972002664

Epoch: 6| Step: 9
Training loss: 1.9153751134872437
Validation loss: 2.2041881481806436

Epoch: 6| Step: 10
Training loss: 1.5684560537338257
Validation loss: 2.1919769843419394

Epoch: 6| Step: 11
Training loss: 1.8910731077194214
Validation loss: 2.1775660713513694

Epoch: 6| Step: 12
Training loss: 1.398262619972229
Validation loss: 2.182264804840088

Epoch: 6| Step: 13
Training loss: 2.543954610824585
Validation loss: 2.2083361943562827

Epoch: 246| Step: 0
Training loss: 2.516688108444214
Validation loss: 2.172171195348104

Epoch: 6| Step: 1
Training loss: 2.2253618240356445
Validation loss: 2.1734678745269775

Epoch: 6| Step: 2
Training loss: 2.4838547706604004
Validation loss: 2.19730939467748

Epoch: 6| Step: 3
Training loss: 1.4413540363311768
Validation loss: 2.1892543037732444

Epoch: 6| Step: 4
Training loss: 1.7921903133392334
Validation loss: 2.189663847287496

Epoch: 6| Step: 5
Training loss: 1.6871533393859863
Validation loss: 2.173096776008606

Epoch: 6| Step: 6
Training loss: 1.7169177532196045
Validation loss: 2.194241464138031

Epoch: 6| Step: 7
Training loss: 1.5497170686721802
Validation loss: 2.1767581701278687

Epoch: 6| Step: 8
Training loss: 1.304195761680603
Validation loss: 2.193096399307251

Epoch: 6| Step: 9
Training loss: 1.3659594058990479
Validation loss: 2.1863954663276672

Epoch: 6| Step: 10
Training loss: 1.7822988033294678
Validation loss: 2.1974446773529053

Epoch: 6| Step: 11
Training loss: 1.4829893112182617
Validation loss: 2.188321570555369

Epoch: 6| Step: 12
Training loss: 1.5652846097946167
Validation loss: 2.1751227180163064

Epoch: 6| Step: 13
Training loss: 1.9051408767700195
Validation loss: 2.1825249592463174

Epoch: 247| Step: 0
Training loss: 1.8454228639602661
Validation loss: 2.19534695148468

Epoch: 6| Step: 1
Training loss: 1.6245121955871582
Validation loss: 2.192253828048706

Epoch: 6| Step: 2
Training loss: 1.2218971252441406
Validation loss: 2.1740883588790894

Epoch: 6| Step: 3
Training loss: 1.4302892684936523
Validation loss: 2.191820045312246

Epoch: 6| Step: 4
Training loss: 2.698173761367798
Validation loss: 2.191039760907491

Epoch: 6| Step: 5
Training loss: 1.4998786449432373
Validation loss: 2.2116758227348328

Epoch: 6| Step: 6
Training loss: 1.8960057497024536
Validation loss: 2.1921814481417337

Epoch: 6| Step: 7
Training loss: 2.368774652481079
Validation loss: 2.215440313021342

Epoch: 6| Step: 8
Training loss: 2.421335220336914
Validation loss: 2.2107906142870584

Epoch: 6| Step: 9
Training loss: 1.8882161378860474
Validation loss: 2.205830136934916

Epoch: 6| Step: 10
Training loss: 1.5674587488174438
Validation loss: 2.1820810039838157

Epoch: 6| Step: 11
Training loss: 1.4371249675750732
Validation loss: 2.179723600546519

Epoch: 6| Step: 12
Training loss: 1.422018051147461
Validation loss: 2.185465097427368

Epoch: 6| Step: 13
Training loss: 1.756386399269104
Validation loss: 2.1679515639940896

Epoch: 248| Step: 0
Training loss: 1.8284554481506348
Validation loss: 2.1540932257970176

Epoch: 6| Step: 1
Training loss: 1.3702534437179565
Validation loss: 2.17843234539032

Epoch: 6| Step: 2
Training loss: 2.4521284103393555
Validation loss: 2.178221046924591

Epoch: 6| Step: 3
Training loss: 2.1778414249420166
Validation loss: 2.181666096051534

Epoch: 6| Step: 4
Training loss: 1.7358837127685547
Validation loss: 2.165791928768158

Epoch: 6| Step: 5
Training loss: 1.9171106815338135
Validation loss: 2.1878846883773804

Epoch: 6| Step: 6
Training loss: 1.851813554763794
Validation loss: 2.1869776844978333

Epoch: 6| Step: 7
Training loss: 1.929408311843872
Validation loss: 2.201363484064738

Epoch: 6| Step: 8
Training loss: 1.5662477016448975
Validation loss: 2.188871661822001

Epoch: 6| Step: 9
Training loss: 1.4759414196014404
Validation loss: 2.1757145722707114

Epoch: 6| Step: 10
Training loss: 2.044308662414551
Validation loss: 2.190162976582845

Epoch: 6| Step: 11
Training loss: 1.9068249464035034
Validation loss: 2.2086119651794434

Epoch: 6| Step: 12
Training loss: 1.1984384059906006
Validation loss: 2.1729390819867453

Epoch: 6| Step: 13
Training loss: 1.8968298435211182
Validation loss: 2.1703140338261924

Epoch: 249| Step: 0
Training loss: 1.4832355976104736
Validation loss: 2.1743096907933555

Epoch: 6| Step: 1
Training loss: 2.038407325744629
Validation loss: 2.1718151370684304

Epoch: 6| Step: 2
Training loss: 1.7289178371429443
Validation loss: 2.185431659221649

Epoch: 6| Step: 3
Training loss: 1.7960889339447021
Validation loss: 2.17497988541921

Epoch: 6| Step: 4
Training loss: 1.5579757690429688
Validation loss: 2.168352782726288

Epoch: 6| Step: 5
Training loss: 1.7402639389038086
Validation loss: 2.1698610385258994

Epoch: 6| Step: 6
Training loss: 2.796539306640625
Validation loss: 2.1606565515200296

Epoch: 6| Step: 7
Training loss: 1.7113075256347656
Validation loss: 2.1858879725138345

Epoch: 6| Step: 8
Training loss: 1.5284687280654907
Validation loss: 2.1812530358632407

Epoch: 6| Step: 9
Training loss: 2.211498498916626
Validation loss: 2.2077792088190713

Epoch: 6| Step: 10
Training loss: 2.327181100845337
Validation loss: 2.1934746901194253

Epoch: 6| Step: 11
Training loss: 1.143937587738037
Validation loss: 2.220557431379954

Epoch: 6| Step: 12
Training loss: 2.018662929534912
Validation loss: 2.210242450237274

Epoch: 6| Step: 13
Training loss: 1.6832878589630127
Validation loss: 2.2229920625686646

Epoch: 250| Step: 0
Training loss: 2.1071014404296875
Validation loss: 2.2324046889940896

Epoch: 6| Step: 1
Training loss: 2.1267595291137695
Validation loss: 2.23806103070577

Epoch: 6| Step: 2
Training loss: 1.7675634622573853
Validation loss: 2.2079853216807046

Epoch: 6| Step: 3
Training loss: 1.5908079147338867
Validation loss: 2.223263223965963

Epoch: 6| Step: 4
Training loss: 1.123787760734558
Validation loss: 2.19897989432017

Epoch: 6| Step: 5
Training loss: 1.6978548765182495
Validation loss: 2.1974936922391257

Epoch: 6| Step: 6
Training loss: 1.6514829397201538
Validation loss: 2.190068503220876

Epoch: 6| Step: 7
Training loss: 2.118537187576294
Validation loss: 2.1868584553400674

Epoch: 6| Step: 8
Training loss: 1.4368541240692139
Validation loss: 2.180277705192566

Epoch: 6| Step: 9
Training loss: 1.8429920673370361
Validation loss: 2.184424579143524

Epoch: 6| Step: 10
Training loss: 2.2832388877868652
Validation loss: 2.181883692741394

Epoch: 6| Step: 11
Training loss: 2.3828229904174805
Validation loss: 2.1932056744893393

Epoch: 6| Step: 12
Training loss: 1.7554981708526611
Validation loss: 2.2054614623387656

Epoch: 6| Step: 13
Training loss: 1.1525778770446777
Validation loss: 2.1892537077267966

Epoch: 251| Step: 0
Training loss: 2.0184972286224365
Validation loss: 2.1684451699256897

Epoch: 6| Step: 1
Training loss: 1.6711008548736572
Validation loss: 2.187240401903788

Epoch: 6| Step: 2
Training loss: 1.098172664642334
Validation loss: 2.2022345860799155

Epoch: 6| Step: 3
Training loss: 1.6767661571502686
Validation loss: 2.174803098042806

Epoch: 6| Step: 4
Training loss: 1.3094377517700195
Validation loss: 2.173151731491089

Epoch: 6| Step: 5
Training loss: 1.7182857990264893
Validation loss: 2.197281837463379

Epoch: 6| Step: 6
Training loss: 2.4737255573272705
Validation loss: 2.1813166737556458

Epoch: 6| Step: 7
Training loss: 1.776753544807434
Validation loss: 2.2067925731341043

Epoch: 6| Step: 8
Training loss: 1.717606782913208
Validation loss: 2.1571752031644187

Epoch: 6| Step: 9
Training loss: 1.6508939266204834
Validation loss: 2.1766274174054465

Epoch: 6| Step: 10
Training loss: 1.5631978511810303
Validation loss: 2.1896494229634604

Epoch: 6| Step: 11
Training loss: 1.670517921447754
Validation loss: 2.18526291847229

Epoch: 6| Step: 12
Training loss: 1.7404506206512451
Validation loss: 2.1908174951871238

Epoch: 6| Step: 13
Training loss: 2.657036304473877
Validation loss: 2.1993547677993774

Epoch: 252| Step: 0
Training loss: 1.5859323740005493
Validation loss: 2.1975490053494773

Epoch: 6| Step: 1
Training loss: 2.372210741043091
Validation loss: 2.1954181790351868

Epoch: 6| Step: 2
Training loss: 1.0669740438461304
Validation loss: 2.2057597438494363

Epoch: 6| Step: 3
Training loss: 1.8203909397125244
Validation loss: 2.171026428540548

Epoch: 6| Step: 4
Training loss: 1.5379974842071533
Validation loss: 2.197493016719818

Epoch: 6| Step: 5
Training loss: 1.499260663986206
Validation loss: 2.1975837548573813

Epoch: 6| Step: 6
Training loss: 2.1490437984466553
Validation loss: 2.1945815086364746

Epoch: 6| Step: 7
Training loss: 1.5510737895965576
Validation loss: 2.2102880676587424

Epoch: 6| Step: 8
Training loss: 2.1599347591400146
Validation loss: 2.2239768505096436

Epoch: 6| Step: 9
Training loss: 1.7756335735321045
Validation loss: 2.2195818622907004

Epoch: 6| Step: 10
Training loss: 1.8115737438201904
Validation loss: 2.2346799770991006

Epoch: 6| Step: 11
Training loss: 1.7213226556777954
Validation loss: 2.221181650956472

Epoch: 6| Step: 12
Training loss: 1.9564388990402222
Validation loss: 2.232329527537028

Epoch: 6| Step: 13
Training loss: 1.6973812580108643
Validation loss: 2.2028632164001465

Epoch: 253| Step: 0
Training loss: 1.8437143564224243
Validation loss: 2.2203567822774253

Epoch: 6| Step: 1
Training loss: 2.6110198497772217
Validation loss: 2.2112799088160195

Epoch: 6| Step: 2
Training loss: 2.2924327850341797
Validation loss: 2.218793352444967

Epoch: 6| Step: 3
Training loss: 1.4472683668136597
Validation loss: 2.226314107577006

Epoch: 6| Step: 4
Training loss: 1.6286189556121826
Validation loss: 2.182636241118113

Epoch: 6| Step: 5
Training loss: 1.664257526397705
Validation loss: 2.202046056588491

Epoch: 6| Step: 6
Training loss: 1.241211175918579
Validation loss: 2.1917123595873513

Epoch: 6| Step: 7
Training loss: 1.652117133140564
Validation loss: 2.205202301343282

Epoch: 6| Step: 8
Training loss: 2.3621530532836914
Validation loss: 2.1983522176742554

Epoch: 6| Step: 9
Training loss: 1.891179084777832
Validation loss: 2.183431069056193

Epoch: 6| Step: 10
Training loss: 1.0683708190917969
Validation loss: 2.1906848549842834

Epoch: 6| Step: 11
Training loss: 1.9588212966918945
Validation loss: 2.1998345255851746

Epoch: 6| Step: 12
Training loss: 1.3433811664581299
Validation loss: 2.204366405804952

Epoch: 6| Step: 13
Training loss: 1.6522552967071533
Validation loss: 2.200575828552246

Epoch: 254| Step: 0
Training loss: 2.116891860961914
Validation loss: 2.219348986943563

Epoch: 6| Step: 1
Training loss: 1.6817317008972168
Validation loss: 2.201456685860952

Epoch: 6| Step: 2
Training loss: 1.5593655109405518
Validation loss: 2.2039844393730164

Epoch: 6| Step: 3
Training loss: 1.5458080768585205
Validation loss: 2.1938284635543823

Epoch: 6| Step: 4
Training loss: 1.597847580909729
Validation loss: 2.188593069712321

Epoch: 6| Step: 5
Training loss: 1.7872567176818848
Validation loss: 2.172439455986023

Epoch: 6| Step: 6
Training loss: 1.6199204921722412
Validation loss: 2.1958329677581787

Epoch: 6| Step: 7
Training loss: 2.050930976867676
Validation loss: 2.1880958477656045

Epoch: 6| Step: 8
Training loss: 1.874125599861145
Validation loss: 2.173077404499054

Epoch: 6| Step: 9
Training loss: 2.021324396133423
Validation loss: 2.1870581905047097

Epoch: 6| Step: 10
Training loss: 1.5825717449188232
Validation loss: 2.177776018778483

Epoch: 6| Step: 11
Training loss: 1.42758309841156
Validation loss: 2.197144607702891

Epoch: 6| Step: 12
Training loss: 2.3745627403259277
Validation loss: 2.2014614144961038

Epoch: 6| Step: 13
Training loss: 1.8425989151000977
Validation loss: 2.1849365631739297

Epoch: 255| Step: 0
Training loss: 2.2927494049072266
Validation loss: 2.187897264957428

Epoch: 6| Step: 1
Training loss: 2.238194465637207
Validation loss: 2.2172064781188965

Epoch: 6| Step: 2
Training loss: 1.1960984468460083
Validation loss: 2.2094923655192056

Epoch: 6| Step: 3
Training loss: 1.3222956657409668
Validation loss: 2.2087793350219727

Epoch: 6| Step: 4
Training loss: 1.8676915168762207
Validation loss: 2.219143191973368

Epoch: 6| Step: 5
Training loss: 1.9468951225280762
Validation loss: 2.214393198490143

Epoch: 6| Step: 6
Training loss: 2.576052665710449
Validation loss: 2.1967162688573203

Epoch: 6| Step: 7
Training loss: 1.7367379665374756
Validation loss: 2.2142871220906577

Epoch: 6| Step: 8
Training loss: 2.2103800773620605
Validation loss: 2.218344787756602

Epoch: 6| Step: 9
Training loss: 1.8416247367858887
Validation loss: 2.212870955467224

Epoch: 6| Step: 10
Training loss: 1.0495493412017822
Validation loss: 2.166626811027527

Epoch: 6| Step: 11
Training loss: 1.619277000427246
Validation loss: 2.169149915377299

Epoch: 6| Step: 12
Training loss: 2.019893169403076
Validation loss: 2.1691264708836875

Epoch: 6| Step: 13
Training loss: 1.907821774482727
Validation loss: 2.163274824619293

Epoch: 256| Step: 0
Training loss: 2.4732656478881836
Validation loss: 2.173779050509135

Epoch: 6| Step: 1
Training loss: 0.988412618637085
Validation loss: 2.170019825299581

Epoch: 6| Step: 2
Training loss: 2.611063241958618
Validation loss: 2.179312527179718

Epoch: 6| Step: 3
Training loss: 1.5911037921905518
Validation loss: 2.1732448736826577

Epoch: 6| Step: 4
Training loss: 1.6681489944458008
Validation loss: 2.169511874516805

Epoch: 6| Step: 5
Training loss: 1.8661277294158936
Validation loss: 2.1960221926371255

Epoch: 6| Step: 6
Training loss: 1.4282811880111694
Validation loss: 2.195420185724894

Epoch: 6| Step: 7
Training loss: 1.5629103183746338
Validation loss: 2.203824460506439

Epoch: 6| Step: 8
Training loss: 1.959786057472229
Validation loss: 2.224810838699341

Epoch: 6| Step: 9
Training loss: 1.682695746421814
Validation loss: 2.225253959496816

Epoch: 6| Step: 10
Training loss: 1.039089322090149
Validation loss: 2.188438574473063

Epoch: 6| Step: 11
Training loss: 2.5541932582855225
Validation loss: 2.188687880833944

Epoch: 6| Step: 12
Training loss: 1.377608299255371
Validation loss: 2.161342223485311

Epoch: 6| Step: 13
Training loss: 2.121030569076538
Validation loss: 2.165620426336924

Epoch: 257| Step: 0
Training loss: 1.7620320320129395
Validation loss: 2.1449380119641623

Epoch: 6| Step: 1
Training loss: 1.8964264392852783
Validation loss: 2.1545056303342185

Epoch: 6| Step: 2
Training loss: 1.5651907920837402
Validation loss: 2.1937958796819053

Epoch: 6| Step: 3
Training loss: 1.939971923828125
Validation loss: 2.1872569719950357

Epoch: 6| Step: 4
Training loss: 2.1586403846740723
Validation loss: 2.169628103574117

Epoch: 6| Step: 5
Training loss: 1.3240388631820679
Validation loss: 2.1913320223490396

Epoch: 6| Step: 6
Training loss: 2.2159950733184814
Validation loss: 2.1956946849823

Epoch: 6| Step: 7
Training loss: 1.8268975019454956
Validation loss: 2.188262641429901

Epoch: 6| Step: 8
Training loss: 1.0140035152435303
Validation loss: 2.1907557447751365

Epoch: 6| Step: 9
Training loss: 1.5892523527145386
Validation loss: 2.1976853410402932

Epoch: 6| Step: 10
Training loss: 2.4427614212036133
Validation loss: 2.2107441624005637

Epoch: 6| Step: 11
Training loss: 1.3281558752059937
Validation loss: 2.1724929213523865

Epoch: 6| Step: 12
Training loss: 2.0402231216430664
Validation loss: 2.185624818007151

Epoch: 6| Step: 13
Training loss: 1.3510921001434326
Validation loss: 2.1747946540514627

Epoch: 258| Step: 0
Training loss: 2.114996910095215
Validation loss: 2.2022198836008706

Epoch: 6| Step: 1
Training loss: 2.542691707611084
Validation loss: 2.188574254512787

Epoch: 6| Step: 2
Training loss: 1.6660943031311035
Validation loss: 2.2082702914873757

Epoch: 6| Step: 3
Training loss: 1.6488813161849976
Validation loss: 2.2167646288871765

Epoch: 6| Step: 4
Training loss: 1.8449041843414307
Validation loss: 2.2052427927652993

Epoch: 6| Step: 5
Training loss: 1.7983434200286865
Validation loss: 2.216941316922506

Epoch: 6| Step: 6
Training loss: 1.3355202674865723
Validation loss: 2.187952478726705

Epoch: 6| Step: 7
Training loss: 2.271059274673462
Validation loss: 2.204849203427633

Epoch: 6| Step: 8
Training loss: 1.431124210357666
Validation loss: 2.2122995456059775

Epoch: 6| Step: 9
Training loss: 2.038686752319336
Validation loss: 2.2084840734799704

Epoch: 6| Step: 10
Training loss: 1.713304042816162
Validation loss: 2.1859784523646035

Epoch: 6| Step: 11
Training loss: 1.6058952808380127
Validation loss: 2.1732893586158752

Epoch: 6| Step: 12
Training loss: 1.1800892353057861
Validation loss: 2.175878405570984

Epoch: 6| Step: 13
Training loss: 1.8751940727233887
Validation loss: 2.1667772928873696

Epoch: 259| Step: 0
Training loss: 1.7280139923095703
Validation loss: 2.1591997146606445

Epoch: 6| Step: 1
Training loss: 1.96842622756958
Validation loss: 2.1697089274724326

Epoch: 6| Step: 2
Training loss: 0.9652847647666931
Validation loss: 2.188453952471415

Epoch: 6| Step: 3
Training loss: 1.7511364221572876
Validation loss: 2.1986051400502524

Epoch: 6| Step: 4
Training loss: 1.675893783569336
Validation loss: 2.206913411617279

Epoch: 6| Step: 5
Training loss: 1.8606334924697876
Validation loss: 2.218644996484121

Epoch: 6| Step: 6
Training loss: 2.0278518199920654
Validation loss: 2.181424836317698

Epoch: 6| Step: 7
Training loss: 1.3131330013275146
Validation loss: 2.197880744934082

Epoch: 6| Step: 8
Training loss: 1.5678048133850098
Validation loss: 2.18273389339447

Epoch: 6| Step: 9
Training loss: 1.3158742189407349
Validation loss: 2.173392732938131

Epoch: 6| Step: 10
Training loss: 1.852271318435669
Validation loss: 2.1898990869522095

Epoch: 6| Step: 11
Training loss: 1.7130056619644165
Validation loss: 2.157085736592611

Epoch: 6| Step: 12
Training loss: 2.5174965858459473
Validation loss: 2.1750943263371787

Epoch: 6| Step: 13
Training loss: 1.7912158966064453
Validation loss: 2.1698030829429626

Epoch: 260| Step: 0
Training loss: 2.1186020374298096
Validation loss: 2.1705427964528403

Epoch: 6| Step: 1
Training loss: 1.4281020164489746
Validation loss: 2.1770326693852744

Epoch: 6| Step: 2
Training loss: 1.7285257577896118
Validation loss: 2.167708992958069

Epoch: 6| Step: 3
Training loss: 2.0941851139068604
Validation loss: 2.2066659331321716

Epoch: 6| Step: 4
Training loss: 1.8855538368225098
Validation loss: 2.1960971355438232

Epoch: 6| Step: 5
Training loss: 1.4433989524841309
Validation loss: 2.2041577100753784

Epoch: 6| Step: 6
Training loss: 1.277311086654663
Validation loss: 2.198698401451111

Epoch: 6| Step: 7
Training loss: 1.8894213438034058
Validation loss: 2.1796737909317017

Epoch: 6| Step: 8
Training loss: 1.6381996870040894
Validation loss: 2.1955464283625283

Epoch: 6| Step: 9
Training loss: 2.2516403198242188
Validation loss: 2.214416821797689

Epoch: 6| Step: 10
Training loss: 1.3899917602539062
Validation loss: 2.188328226407369

Epoch: 6| Step: 11
Training loss: 1.6693460941314697
Validation loss: 2.1961077054341636

Epoch: 6| Step: 12
Training loss: 1.779252290725708
Validation loss: 2.199556827545166

Epoch: 6| Step: 13
Training loss: 1.7745211124420166
Validation loss: 2.184483011563619

Epoch: 261| Step: 0
Training loss: 1.3830403089523315
Validation loss: 2.21770441532135

Epoch: 6| Step: 1
Training loss: 1.462864637374878
Validation loss: 2.217513640721639

Epoch: 6| Step: 2
Training loss: 1.949803113937378
Validation loss: 2.2021321256955466

Epoch: 6| Step: 3
Training loss: 1.9229530096054077
Validation loss: 2.2203258673350015

Epoch: 6| Step: 4
Training loss: 1.1433725357055664
Validation loss: 2.2079272468884787

Epoch: 6| Step: 5
Training loss: 2.510929822921753
Validation loss: 2.221915523211161

Epoch: 6| Step: 6
Training loss: 1.8481744527816772
Validation loss: 2.208028773466746

Epoch: 6| Step: 7
Training loss: 2.0708537101745605
Validation loss: 2.235718866189321

Epoch: 6| Step: 8
Training loss: 1.5490760803222656
Validation loss: 2.220228155454

Epoch: 6| Step: 9
Training loss: 1.4296236038208008
Validation loss: 2.1821338136990867

Epoch: 6| Step: 10
Training loss: 2.05410099029541
Validation loss: 2.208096206188202

Epoch: 6| Step: 11
Training loss: 1.4836324453353882
Validation loss: 2.2061798175175986

Epoch: 6| Step: 12
Training loss: 1.682602882385254
Validation loss: 2.2113552490870156

Epoch: 6| Step: 13
Training loss: 1.5528719425201416
Validation loss: 2.1841155290603638

Epoch: 262| Step: 0
Training loss: 1.3952974081039429
Validation loss: 2.1796574195226035

Epoch: 6| Step: 1
Training loss: 1.3699641227722168
Validation loss: 2.158551255861918

Epoch: 6| Step: 2
Training loss: 1.5808517932891846
Validation loss: 2.189543068408966

Epoch: 6| Step: 3
Training loss: 2.177158832550049
Validation loss: 2.1600645383199057

Epoch: 6| Step: 4
Training loss: 1.3956987857818604
Validation loss: 2.1642271478970847

Epoch: 6| Step: 5
Training loss: 1.9765682220458984
Validation loss: 2.173947890599569

Epoch: 6| Step: 6
Training loss: 1.813902497291565
Validation loss: 2.1813037991523743

Epoch: 6| Step: 7
Training loss: 1.3691446781158447
Validation loss: 2.1909488240877786

Epoch: 6| Step: 8
Training loss: 1.548784852027893
Validation loss: 2.176465014616648

Epoch: 6| Step: 9
Training loss: 2.10888671875
Validation loss: 2.1945265531539917

Epoch: 6| Step: 10
Training loss: 2.41225004196167
Validation loss: 2.1955823500951133

Epoch: 6| Step: 11
Training loss: 1.4725842475891113
Validation loss: 2.1969696482022605

Epoch: 6| Step: 12
Training loss: 2.0428590774536133
Validation loss: 2.171338438987732

Epoch: 6| Step: 13
Training loss: 2.0090625286102295
Validation loss: 2.177891194820404

Epoch: 263| Step: 0
Training loss: 0.8054978847503662
Validation loss: 2.1973392168680825

Epoch: 6| Step: 1
Training loss: 0.9233235120773315
Validation loss: 2.20157523949941

Epoch: 6| Step: 2
Training loss: 2.0230507850646973
Validation loss: 2.20781809091568

Epoch: 6| Step: 3
Training loss: 1.4400572776794434
Validation loss: 2.197339713573456

Epoch: 6| Step: 4
Training loss: 1.3536431789398193
Validation loss: 2.2113619844118753

Epoch: 6| Step: 5
Training loss: 2.1490893363952637
Validation loss: 2.206263621648153

Epoch: 6| Step: 6
Training loss: 1.7149420976638794
Validation loss: 2.208265463511149

Epoch: 6| Step: 7
Training loss: 3.0190343856811523
Validation loss: 2.22002907594045

Epoch: 6| Step: 8
Training loss: 1.8816038370132446
Validation loss: 2.2435045639673867

Epoch: 6| Step: 9
Training loss: 2.359147071838379
Validation loss: 2.2248467206954956

Epoch: 6| Step: 10
Training loss: 2.015749454498291
Validation loss: 2.203684230645498

Epoch: 6| Step: 11
Training loss: 1.1351897716522217
Validation loss: 2.2455705205599465

Epoch: 6| Step: 12
Training loss: 1.2554056644439697
Validation loss: 2.263847231864929

Epoch: 6| Step: 13
Training loss: 1.8933601379394531
Validation loss: 2.261570413907369

Epoch: 264| Step: 0
Training loss: 1.5626331567764282
Validation loss: 2.242639144261678

Epoch: 6| Step: 1
Training loss: 2.4270431995391846
Validation loss: 2.2117846806844077

Epoch: 6| Step: 2
Training loss: 2.171025514602661
Validation loss: 2.2259283860524497

Epoch: 6| Step: 3
Training loss: 1.6637035608291626
Validation loss: 2.23759263753891

Epoch: 6| Step: 4
Training loss: 2.2988083362579346
Validation loss: 2.2338825861612954

Epoch: 6| Step: 5
Training loss: 1.6029863357543945
Validation loss: 2.227038820584615

Epoch: 6| Step: 6
Training loss: 1.4947513341903687
Validation loss: 2.23353519042333

Epoch: 6| Step: 7
Training loss: 1.6890755891799927
Validation loss: 2.2363099654515586

Epoch: 6| Step: 8
Training loss: 1.7105152606964111
Validation loss: 2.2234406073888144

Epoch: 6| Step: 9
Training loss: 1.959967017173767
Validation loss: 2.2254318594932556

Epoch: 6| Step: 10
Training loss: 1.034226655960083
Validation loss: 2.208070437113444

Epoch: 6| Step: 11
Training loss: 1.4523789882659912
Validation loss: 2.218630234400431

Epoch: 6| Step: 12
Training loss: 1.6311535835266113
Validation loss: 2.2272837162017822

Epoch: 6| Step: 13
Training loss: 1.8870275020599365
Validation loss: 2.199047068754832

Epoch: 265| Step: 0
Training loss: 1.7260327339172363
Validation loss: 2.181544542312622

Epoch: 6| Step: 1
Training loss: 1.4202667474746704
Validation loss: 2.1803026596705117

Epoch: 6| Step: 2
Training loss: 1.672587513923645
Validation loss: 2.209170619646708

Epoch: 6| Step: 3
Training loss: 1.8685044050216675
Validation loss: 2.17336376508077

Epoch: 6| Step: 4
Training loss: 1.4989213943481445
Validation loss: 2.205831011136373

Epoch: 6| Step: 5
Training loss: 1.8640614748001099
Validation loss: 2.182282288869222

Epoch: 6| Step: 6
Training loss: 1.3901047706604004
Validation loss: 2.218514104684194

Epoch: 6| Step: 7
Training loss: 1.7888398170471191
Validation loss: 2.1897794604301453

Epoch: 6| Step: 8
Training loss: 1.8170452117919922
Validation loss: 2.1867535511652627

Epoch: 6| Step: 9
Training loss: 1.7758617401123047
Validation loss: 2.2145747343699136

Epoch: 6| Step: 10
Training loss: 2.2288150787353516
Validation loss: 2.192651410897573

Epoch: 6| Step: 11
Training loss: 2.1175906658172607
Validation loss: 2.1967559854189553

Epoch: 6| Step: 12
Training loss: 1.4811575412750244
Validation loss: 2.1966824730237327

Epoch: 6| Step: 13
Training loss: 1.7220630645751953
Validation loss: 2.1926927169164023

Epoch: 266| Step: 0
Training loss: 1.4158360958099365
Validation loss: 2.1911068161328635

Epoch: 6| Step: 1
Training loss: 1.6679508686065674
Validation loss: 2.2113370498021445

Epoch: 6| Step: 2
Training loss: 1.1346137523651123
Validation loss: 2.213152448336283

Epoch: 6| Step: 3
Training loss: 2.7328922748565674
Validation loss: 2.2116626501083374

Epoch: 6| Step: 4
Training loss: 1.8514808416366577
Validation loss: 2.195716063181559

Epoch: 6| Step: 5
Training loss: 1.457261323928833
Validation loss: 2.2052109241485596

Epoch: 6| Step: 6
Training loss: 1.4971094131469727
Validation loss: 2.186126192410787

Epoch: 6| Step: 7
Training loss: 1.378989338874817
Validation loss: 2.179679195086161

Epoch: 6| Step: 8
Training loss: 2.395946979522705
Validation loss: 2.2016445795694985

Epoch: 6| Step: 9
Training loss: 1.8292336463928223
Validation loss: 2.2180636525154114

Epoch: 6| Step: 10
Training loss: 1.842564582824707
Validation loss: 2.2168468832969666

Epoch: 6| Step: 11
Training loss: 2.0786614418029785
Validation loss: 2.195356607437134

Epoch: 6| Step: 12
Training loss: 1.7402191162109375
Validation loss: 2.2315502564112344

Epoch: 6| Step: 13
Training loss: 1.2456105947494507
Validation loss: 2.1813344756762185

Epoch: 267| Step: 0
Training loss: 2.234562397003174
Validation loss: 2.218722959359487

Epoch: 6| Step: 1
Training loss: 1.9723048210144043
Validation loss: 2.1961508989334106

Epoch: 6| Step: 2
Training loss: 1.2850172519683838
Validation loss: 2.1924638748168945

Epoch: 6| Step: 3
Training loss: 1.7394156455993652
Validation loss: 2.187207579612732

Epoch: 6| Step: 4
Training loss: 1.279674768447876
Validation loss: 2.2166072924931846

Epoch: 6| Step: 5
Training loss: 1.5801808834075928
Validation loss: 2.2016385793685913

Epoch: 6| Step: 6
Training loss: 1.2696654796600342
Validation loss: 2.199983457724253

Epoch: 6| Step: 7
Training loss: 1.7213623523712158
Validation loss: 2.20743457476298

Epoch: 6| Step: 8
Training loss: 1.4207520484924316
Validation loss: 2.2045673529307046

Epoch: 6| Step: 9
Training loss: 1.5603013038635254
Validation loss: 2.184819479783376

Epoch: 6| Step: 10
Training loss: 1.8595457077026367
Validation loss: 2.202567537625631

Epoch: 6| Step: 11
Training loss: 1.7303129434585571
Validation loss: 2.1963655153910318

Epoch: 6| Step: 12
Training loss: 1.777698278427124
Validation loss: 2.192389488220215

Epoch: 6| Step: 13
Training loss: 2.7223591804504395
Validation loss: 2.204624354839325

Epoch: 268| Step: 0
Training loss: 1.9819316864013672
Validation loss: 2.233515461285909

Epoch: 6| Step: 1
Training loss: 1.0445343255996704
Validation loss: 2.21332053343455

Epoch: 6| Step: 2
Training loss: 1.603053331375122
Validation loss: 2.2062102357546487

Epoch: 6| Step: 3
Training loss: 1.806122064590454
Validation loss: 2.2369232177734375

Epoch: 6| Step: 4
Training loss: 1.0915486812591553
Validation loss: 2.2310299078623452

Epoch: 6| Step: 5
Training loss: 2.533703088760376
Validation loss: 2.201264282067617

Epoch: 6| Step: 6
Training loss: 1.7704415321350098
Validation loss: 2.1778928637504578

Epoch: 6| Step: 7
Training loss: 2.0995736122131348
Validation loss: 2.1690990726153054

Epoch: 6| Step: 8
Training loss: 2.408172369003296
Validation loss: 2.1656786799430847

Epoch: 6| Step: 9
Training loss: 1.4857152700424194
Validation loss: 2.1712255080540976

Epoch: 6| Step: 10
Training loss: 2.169097900390625
Validation loss: 2.18013326327006

Epoch: 6| Step: 11
Training loss: 1.9155480861663818
Validation loss: 2.1773183941841125

Epoch: 6| Step: 12
Training loss: 1.7584919929504395
Validation loss: 2.183737556139628

Epoch: 6| Step: 13
Training loss: 1.6236846446990967
Validation loss: 2.1928470532099404

Epoch: 269| Step: 0
Training loss: 1.6764799356460571
Validation loss: 2.174767712752024

Epoch: 6| Step: 1
Training loss: 1.4858320951461792
Validation loss: 2.218411684036255

Epoch: 6| Step: 2
Training loss: 1.8814899921417236
Validation loss: 2.232702116171519

Epoch: 6| Step: 3
Training loss: 1.6764287948608398
Validation loss: 2.2321287790934243

Epoch: 6| Step: 4
Training loss: 1.6711965799331665
Validation loss: 2.2067635456720986

Epoch: 6| Step: 5
Training loss: 2.341129779815674
Validation loss: 2.2189387679100037

Epoch: 6| Step: 6
Training loss: 1.7455618381500244
Validation loss: 2.193282147248586

Epoch: 6| Step: 7
Training loss: 1.444229006767273
Validation loss: 2.203486700852712

Epoch: 6| Step: 8
Training loss: 2.313056230545044
Validation loss: 2.2113766074180603

Epoch: 6| Step: 9
Training loss: 2.338231086730957
Validation loss: 2.176894704500834

Epoch: 6| Step: 10
Training loss: 1.8846023082733154
Validation loss: 2.1981714566548667

Epoch: 6| Step: 11
Training loss: 1.213621735572815
Validation loss: 2.206058899561564

Epoch: 6| Step: 12
Training loss: 1.878288984298706
Validation loss: 2.166996936003367

Epoch: 6| Step: 13
Training loss: 1.8608916997909546
Validation loss: 2.193371752897898

Epoch: 270| Step: 0
Training loss: 1.917717695236206
Validation loss: 2.1557551622390747

Epoch: 6| Step: 1
Training loss: 1.925055742263794
Validation loss: 2.1806684931119285

Epoch: 6| Step: 2
Training loss: 1.6643730401992798
Validation loss: 2.164480288823446

Epoch: 6| Step: 3
Training loss: 1.2385848760604858
Validation loss: 2.172480523586273

Epoch: 6| Step: 4
Training loss: 2.039870023727417
Validation loss: 2.167336026827494

Epoch: 6| Step: 5
Training loss: 1.7517114877700806
Validation loss: 2.1990642150243125

Epoch: 6| Step: 6
Training loss: 1.36771821975708
Validation loss: 2.1830469369888306

Epoch: 6| Step: 7
Training loss: 2.2603819370269775
Validation loss: 2.1733251214027405

Epoch: 6| Step: 8
Training loss: 1.2338666915893555
Validation loss: 2.1976972421010337

Epoch: 6| Step: 9
Training loss: 1.665851354598999
Validation loss: 2.209862848122915

Epoch: 6| Step: 10
Training loss: 1.745373010635376
Validation loss: 2.183192014694214

Epoch: 6| Step: 11
Training loss: 1.396803855895996
Validation loss: 2.214029928048452

Epoch: 6| Step: 12
Training loss: 1.5131412744522095
Validation loss: 2.1779045263926187

Epoch: 6| Step: 13
Training loss: 2.257565498352051
Validation loss: 2.1991602977116904

Epoch: 271| Step: 0
Training loss: 1.2128829956054688
Validation loss: 2.1882393757502236

Epoch: 6| Step: 1
Training loss: 2.008090019226074
Validation loss: 2.1980061729749045

Epoch: 6| Step: 2
Training loss: 1.6763317584991455
Validation loss: 2.181076963742574

Epoch: 6| Step: 3
Training loss: 2.150695323944092
Validation loss: 2.1787524024645486

Epoch: 6| Step: 4
Training loss: 2.9664859771728516
Validation loss: 2.1840708255767822

Epoch: 6| Step: 5
Training loss: 1.403719186782837
Validation loss: 2.198495308558146

Epoch: 6| Step: 6
Training loss: 1.3043562173843384
Validation loss: 2.2097657322883606

Epoch: 6| Step: 7
Training loss: 1.961417555809021
Validation loss: 2.173018991947174

Epoch: 6| Step: 8
Training loss: 1.7518842220306396
Validation loss: 2.181218683719635

Epoch: 6| Step: 9
Training loss: 1.975358486175537
Validation loss: 2.189348578453064

Epoch: 6| Step: 10
Training loss: 1.4981859922409058
Validation loss: 2.1986790100733438

Epoch: 6| Step: 11
Training loss: 1.5023105144500732
Validation loss: 2.1907097895940146

Epoch: 6| Step: 12
Training loss: 2.0861165523529053
Validation loss: 2.1702993512153625

Epoch: 6| Step: 13
Training loss: 1.502864956855774
Validation loss: 2.197476089000702

Epoch: 272| Step: 0
Training loss: 2.4620018005371094
Validation loss: 2.1867823799451194

Epoch: 6| Step: 1
Training loss: 1.3903741836547852
Validation loss: 2.2053894996643066

Epoch: 6| Step: 2
Training loss: 1.926528811454773
Validation loss: 2.1956116557121277

Epoch: 6| Step: 3
Training loss: 2.006735324859619
Validation loss: 2.188008646170298

Epoch: 6| Step: 4
Training loss: 1.6067817211151123
Validation loss: 2.19930233558019

Epoch: 6| Step: 5
Training loss: 1.9435856342315674
Validation loss: 2.1923574209213257

Epoch: 6| Step: 6
Training loss: 1.4536092281341553
Validation loss: 2.1980477571487427

Epoch: 6| Step: 7
Training loss: 1.5686914920806885
Validation loss: 2.202550530433655

Epoch: 6| Step: 8
Training loss: 1.5988155603408813
Validation loss: 2.2100510398546853

Epoch: 6| Step: 9
Training loss: 1.0160725116729736
Validation loss: 2.222261349360148

Epoch: 6| Step: 10
Training loss: 1.902260661125183
Validation loss: 2.198500394821167

Epoch: 6| Step: 11
Training loss: 1.56173574924469
Validation loss: 2.1856711705525718

Epoch: 6| Step: 12
Training loss: 2.3728578090667725
Validation loss: 2.1975057125091553

Epoch: 6| Step: 13
Training loss: 1.305403470993042
Validation loss: 2.2036540508270264

Epoch: 273| Step: 0
Training loss: 1.559070348739624
Validation loss: 2.2121996879577637

Epoch: 6| Step: 1
Training loss: 1.5249993801116943
Validation loss: 2.2188322941462197

Epoch: 6| Step: 2
Training loss: 1.4689617156982422
Validation loss: 2.2114192247390747

Epoch: 6| Step: 3
Training loss: 1.7356011867523193
Validation loss: 2.236745516459147

Epoch: 6| Step: 4
Training loss: 1.5837101936340332
Validation loss: 2.268538991610209

Epoch: 6| Step: 5
Training loss: 1.5142861604690552
Validation loss: 2.2663155794143677

Epoch: 6| Step: 6
Training loss: 1.077938199043274
Validation loss: 2.2543274760246277

Epoch: 6| Step: 7
Training loss: 1.4611703157424927
Validation loss: 2.2773500879605613

Epoch: 6| Step: 8
Training loss: 1.6964143514633179
Validation loss: 2.280853033065796

Epoch: 6| Step: 9
Training loss: 2.876194953918457
Validation loss: 2.242909053961436

Epoch: 6| Step: 10
Training loss: 1.93270742893219
Validation loss: 2.237634559472402

Epoch: 6| Step: 11
Training loss: 1.6618858575820923
Validation loss: 2.227627913157145

Epoch: 6| Step: 12
Training loss: 1.279181718826294
Validation loss: 2.2356359163920083

Epoch: 6| Step: 13
Training loss: 2.745974540710449
Validation loss: 2.208449343840281

Epoch: 274| Step: 0
Training loss: 2.24763822555542
Validation loss: 2.2151378393173218

Epoch: 6| Step: 1
Training loss: 1.9198237657546997
Validation loss: 2.218804200490316

Epoch: 6| Step: 2
Training loss: 1.5062978267669678
Validation loss: 2.2230706214904785

Epoch: 6| Step: 3
Training loss: 2.0918772220611572
Validation loss: 2.210311015446981

Epoch: 6| Step: 4
Training loss: 1.5842534303665161
Validation loss: 2.212417244911194

Epoch: 6| Step: 5
Training loss: 2.137269973754883
Validation loss: 2.2286218404769897

Epoch: 6| Step: 6
Training loss: 1.205833911895752
Validation loss: 2.2252796292304993

Epoch: 6| Step: 7
Training loss: 1.5754377841949463
Validation loss: 2.2324359814325967

Epoch: 6| Step: 8
Training loss: 1.6151931285858154
Validation loss: 2.228713035583496

Epoch: 6| Step: 9
Training loss: 1.873459815979004
Validation loss: 2.2571624914805093

Epoch: 6| Step: 10
Training loss: 1.5233614444732666
Validation loss: 2.2341542840003967

Epoch: 6| Step: 11
Training loss: 1.598752498626709
Validation loss: 2.2432827750841775

Epoch: 6| Step: 12
Training loss: 1.5882465839385986
Validation loss: 2.227409283320109

Epoch: 6| Step: 13
Training loss: 1.526391863822937
Validation loss: 2.2199309269587197

Epoch: 275| Step: 0
Training loss: 1.9046860933303833
Validation loss: 2.218551536401113

Epoch: 6| Step: 1
Training loss: 1.4197700023651123
Validation loss: 2.198738674322764

Epoch: 6| Step: 2
Training loss: 2.161229133605957
Validation loss: 2.1811644236246743

Epoch: 6| Step: 3
Training loss: 1.1508214473724365
Validation loss: 2.1800532142321267

Epoch: 6| Step: 4
Training loss: 1.4845701456069946
Validation loss: 2.188027878602346

Epoch: 6| Step: 5
Training loss: 1.99588143825531
Validation loss: 2.189144571622213

Epoch: 6| Step: 6
Training loss: 1.8388105630874634
Validation loss: 2.2000799576441445

Epoch: 6| Step: 7
Training loss: 1.1038495302200317
Validation loss: 2.2166121006011963

Epoch: 6| Step: 8
Training loss: 1.4248771667480469
Validation loss: 2.212987204392751

Epoch: 6| Step: 9
Training loss: 1.2948148250579834
Validation loss: 2.2465846141179404

Epoch: 6| Step: 10
Training loss: 2.327148914337158
Validation loss: 2.233956456184387

Epoch: 6| Step: 11
Training loss: 1.9415220022201538
Validation loss: 2.2232302824656167

Epoch: 6| Step: 12
Training loss: 2.0542497634887695
Validation loss: 2.2004487117131553

Epoch: 6| Step: 13
Training loss: 2.2843246459960938
Validation loss: 2.237361490726471

Epoch: 276| Step: 0
Training loss: 2.3310039043426514
Validation loss: 2.1904696027437844

Epoch: 6| Step: 1
Training loss: 1.443421721458435
Validation loss: 2.180984834829966

Epoch: 6| Step: 2
Training loss: 1.9090057611465454
Validation loss: 2.153851012388865

Epoch: 6| Step: 3
Training loss: 0.8422389626502991
Validation loss: 2.1824939250946045

Epoch: 6| Step: 4
Training loss: 1.6905107498168945
Validation loss: 2.183037539323171

Epoch: 6| Step: 5
Training loss: 1.0947341918945312
Validation loss: 2.1817983388900757

Epoch: 6| Step: 6
Training loss: 1.1438040733337402
Validation loss: 2.1550968488057456

Epoch: 6| Step: 7
Training loss: 2.1435723304748535
Validation loss: 2.1649850805600486

Epoch: 6| Step: 8
Training loss: 2.332731246948242
Validation loss: 2.187768201033274

Epoch: 6| Step: 9
Training loss: 2.0459651947021484
Validation loss: 2.174960454305013

Epoch: 6| Step: 10
Training loss: 1.6570689678192139
Validation loss: 2.1906087597211203

Epoch: 6| Step: 11
Training loss: 1.2247941493988037
Validation loss: 2.162432551383972

Epoch: 6| Step: 12
Training loss: 1.5686683654785156
Validation loss: 2.1904457410176597

Epoch: 6| Step: 13
Training loss: 2.6863789558410645
Validation loss: 2.179962972799937

Epoch: 277| Step: 0
Training loss: 1.6029173135757446
Validation loss: 2.199090321858724

Epoch: 6| Step: 1
Training loss: 2.1848649978637695
Validation loss: 2.1870826880137124

Epoch: 6| Step: 2
Training loss: 1.5896778106689453
Validation loss: 2.2005381186803183

Epoch: 6| Step: 3
Training loss: 1.5463908910751343
Validation loss: 2.2102320194244385

Epoch: 6| Step: 4
Training loss: 1.3961470127105713
Validation loss: 2.22258992989858

Epoch: 6| Step: 5
Training loss: 2.094585418701172
Validation loss: 2.2187410394350686

Epoch: 6| Step: 6
Training loss: 1.5534873008728027
Validation loss: 2.208602567513784

Epoch: 6| Step: 7
Training loss: 1.778202772140503
Validation loss: 2.25097264846166

Epoch: 6| Step: 8
Training loss: 1.6620620489120483
Validation loss: 2.230894168217977

Epoch: 6| Step: 9
Training loss: 1.1151533126831055
Validation loss: 2.2682841221491494

Epoch: 6| Step: 10
Training loss: 2.8144443035125732
Validation loss: 2.2438249985376992

Epoch: 6| Step: 11
Training loss: 1.8543237447738647
Validation loss: 2.2238600651423135

Epoch: 6| Step: 12
Training loss: 1.5483129024505615
Validation loss: 2.209477702776591

Epoch: 6| Step: 13
Training loss: 1.5735145807266235
Validation loss: 2.221543331940969

Epoch: 278| Step: 0
Training loss: 1.893194556236267
Validation loss: 2.226361413796743

Epoch: 6| Step: 1
Training loss: 1.9441423416137695
Validation loss: 2.2065608302752175

Epoch: 6| Step: 2
Training loss: 2.044849395751953
Validation loss: 2.250396211942037

Epoch: 6| Step: 3
Training loss: 1.7367703914642334
Validation loss: 2.2351937890052795

Epoch: 6| Step: 4
Training loss: 1.6850063800811768
Validation loss: 2.2589979569117227

Epoch: 6| Step: 5
Training loss: 1.395700454711914
Validation loss: 2.2504172722498574

Epoch: 6| Step: 6
Training loss: 1.9934688806533813
Validation loss: 2.2516183058420816

Epoch: 6| Step: 7
Training loss: 1.661478042602539
Validation loss: 2.2538084983825684

Epoch: 6| Step: 8
Training loss: 2.3814144134521484
Validation loss: 2.245688716570536

Epoch: 6| Step: 9
Training loss: 1.3309290409088135
Validation loss: 2.249394635359446

Epoch: 6| Step: 10
Training loss: 1.5276252031326294
Validation loss: 2.254110415776571

Epoch: 6| Step: 11
Training loss: 1.6916887760162354
Validation loss: 2.252333919207255

Epoch: 6| Step: 12
Training loss: 1.4270210266113281
Validation loss: 2.2206944028536477

Epoch: 6| Step: 13
Training loss: 1.7365784645080566
Validation loss: 2.220642348130544

Epoch: 279| Step: 0
Training loss: 1.8897825479507446
Validation loss: 2.231420079867045

Epoch: 6| Step: 1
Training loss: 1.5160248279571533
Validation loss: 2.1976390878359475

Epoch: 6| Step: 2
Training loss: 1.6356405019760132
Validation loss: 2.2027132709821067

Epoch: 6| Step: 3
Training loss: 1.2820312976837158
Validation loss: 2.1845568815867105

Epoch: 6| Step: 4
Training loss: 1.4803105592727661
Validation loss: 2.1822941501935325

Epoch: 6| Step: 5
Training loss: 2.0507359504699707
Validation loss: 2.193043351173401

Epoch: 6| Step: 6
Training loss: 1.5729167461395264
Validation loss: 2.169863442579905

Epoch: 6| Step: 7
Training loss: 1.1103748083114624
Validation loss: 2.1912867029507956

Epoch: 6| Step: 8
Training loss: 1.635172724723816
Validation loss: 2.1827247937520347

Epoch: 6| Step: 9
Training loss: 1.6821998357772827
Validation loss: 2.18056054910024

Epoch: 6| Step: 10
Training loss: 2.3374154567718506
Validation loss: 2.18358451128006

Epoch: 6| Step: 11
Training loss: 1.8668091297149658
Validation loss: 2.1856956680615744

Epoch: 6| Step: 12
Training loss: 1.9233927726745605
Validation loss: 2.2025306224823

Epoch: 6| Step: 13
Training loss: 1.882659912109375
Validation loss: 2.1706307530403137

Epoch: 280| Step: 0
Training loss: 1.4067898988723755
Validation loss: 2.190900186697642

Epoch: 6| Step: 1
Training loss: 2.4252285957336426
Validation loss: 2.2185192306836448

Epoch: 6| Step: 2
Training loss: 1.668241024017334
Validation loss: 2.230068306128184

Epoch: 6| Step: 3
Training loss: 1.6633062362670898
Validation loss: 2.195867657661438

Epoch: 6| Step: 4
Training loss: 1.453086018562317
Validation loss: 2.2155419190724692

Epoch: 6| Step: 5
Training loss: 1.6548186540603638
Validation loss: 2.223237991333008

Epoch: 6| Step: 6
Training loss: 1.4738280773162842
Validation loss: 2.224851210912069

Epoch: 6| Step: 7
Training loss: 1.2044365406036377
Validation loss: 2.2393896778424582

Epoch: 6| Step: 8
Training loss: 1.2108546495437622
Validation loss: 2.227714995543162

Epoch: 6| Step: 9
Training loss: 1.799720048904419
Validation loss: 2.2253164450327554

Epoch: 6| Step: 10
Training loss: 2.530848503112793
Validation loss: 2.2162024974823

Epoch: 6| Step: 11
Training loss: 1.3556498289108276
Validation loss: 2.2109984954198203

Epoch: 6| Step: 12
Training loss: 1.556375503540039
Validation loss: 2.1969794432322183

Epoch: 6| Step: 13
Training loss: 2.017803907394409
Validation loss: 2.2052433490753174

Epoch: 281| Step: 0
Training loss: 1.4386534690856934
Validation loss: 2.204089800516764

Epoch: 6| Step: 1
Training loss: 0.8726447820663452
Validation loss: 2.224506358305613

Epoch: 6| Step: 2
Training loss: 1.6089783906936646
Validation loss: 2.2102458079655967

Epoch: 6| Step: 3
Training loss: 1.6806292533874512
Validation loss: 2.2088586886723838

Epoch: 6| Step: 4
Training loss: 1.8464901447296143
Validation loss: 2.236035386721293

Epoch: 6| Step: 5
Training loss: 1.360019326210022
Validation loss: 2.2289007902145386

Epoch: 6| Step: 6
Training loss: 2.2861576080322266
Validation loss: 2.2184631625811257

Epoch: 6| Step: 7
Training loss: 1.9648938179016113
Validation loss: 2.219048102696737

Epoch: 6| Step: 8
Training loss: 1.394644856452942
Validation loss: 2.227990686893463

Epoch: 6| Step: 9
Training loss: 1.5956671237945557
Validation loss: 2.2291409174601235

Epoch: 6| Step: 10
Training loss: 1.276400089263916
Validation loss: 2.2309486667315164

Epoch: 6| Step: 11
Training loss: 1.9668000936508179
Validation loss: 2.2405356566111245

Epoch: 6| Step: 12
Training loss: 1.2600343227386475
Validation loss: 2.2134310404459634

Epoch: 6| Step: 13
Training loss: 2.6272385120391846
Validation loss: 2.2329747080802917

Epoch: 282| Step: 0
Training loss: 1.7035071849822998
Validation loss: 2.2143381039301553

Epoch: 6| Step: 1
Training loss: 2.3798575401306152
Validation loss: 2.217897574106852

Epoch: 6| Step: 2
Training loss: 1.7603192329406738
Validation loss: 2.2199378609657288

Epoch: 6| Step: 3
Training loss: 1.3087496757507324
Validation loss: 2.221161941687266

Epoch: 6| Step: 4
Training loss: 1.0690597295761108
Validation loss: 2.208958685398102

Epoch: 6| Step: 5
Training loss: 1.9519846439361572
Validation loss: 2.1898173689842224

Epoch: 6| Step: 6
Training loss: 1.501292109489441
Validation loss: 2.204952816168467

Epoch: 6| Step: 7
Training loss: 1.911569356918335
Validation loss: 2.1975457866986594

Epoch: 6| Step: 8
Training loss: 1.852104902267456
Validation loss: 2.2331895430882773

Epoch: 6| Step: 9
Training loss: 1.4529227018356323
Validation loss: 2.208126505215963

Epoch: 6| Step: 10
Training loss: 2.0189669132232666
Validation loss: 2.2160140673319497

Epoch: 6| Step: 11
Training loss: 2.110137939453125
Validation loss: 2.2347583572069802

Epoch: 6| Step: 12
Training loss: 1.0924886465072632
Validation loss: 2.213033358256022

Epoch: 6| Step: 13
Training loss: 1.1909818649291992
Validation loss: 2.204685389995575

Epoch: 283| Step: 0
Training loss: 1.401545524597168
Validation loss: 2.2421103914578757

Epoch: 6| Step: 1
Training loss: 1.4778757095336914
Validation loss: 2.223146359125773

Epoch: 6| Step: 2
Training loss: 1.6492122411727905
Validation loss: 2.2283361752827964

Epoch: 6| Step: 3
Training loss: 1.0985040664672852
Validation loss: 2.193045973777771

Epoch: 6| Step: 4
Training loss: 1.1739485263824463
Validation loss: 2.222612460454305

Epoch: 6| Step: 5
Training loss: 1.3186652660369873
Validation loss: 2.2165462374687195

Epoch: 6| Step: 6
Training loss: 2.125438928604126
Validation loss: 2.2179338137308755

Epoch: 6| Step: 7
Training loss: 1.9626060724258423
Validation loss: 2.2178276578585305

Epoch: 6| Step: 8
Training loss: 2.013202428817749
Validation loss: 2.207788268725077

Epoch: 6| Step: 9
Training loss: 1.6253348588943481
Validation loss: 2.2240267992019653

Epoch: 6| Step: 10
Training loss: 1.661704659461975
Validation loss: 2.205397049585978

Epoch: 6| Step: 11
Training loss: 1.778696060180664
Validation loss: 2.218030313650767

Epoch: 6| Step: 12
Training loss: 1.4937357902526855
Validation loss: 2.202854812145233

Epoch: 6| Step: 13
Training loss: 2.1222498416900635
Validation loss: 2.217294613520304

Epoch: 284| Step: 0
Training loss: 1.7320523262023926
Validation loss: 2.2179506023724875

Epoch: 6| Step: 1
Training loss: 1.586879849433899
Validation loss: 2.23519774278005

Epoch: 6| Step: 2
Training loss: 1.232263207435608
Validation loss: 2.237937331199646

Epoch: 6| Step: 3
Training loss: 2.673610210418701
Validation loss: 2.2149929205576577

Epoch: 6| Step: 4
Training loss: 1.2541773319244385
Validation loss: 2.19810559352239

Epoch: 6| Step: 5
Training loss: 2.029869556427002
Validation loss: 2.2000390688578286

Epoch: 6| Step: 6
Training loss: 1.1673318147659302
Validation loss: 2.2103648583094277

Epoch: 6| Step: 7
Training loss: 1.42147958278656
Validation loss: 2.2366795937220254

Epoch: 6| Step: 8
Training loss: 1.5822889804840088
Validation loss: 2.2097193797429404

Epoch: 6| Step: 9
Training loss: 1.1677589416503906
Validation loss: 2.2018688718477883

Epoch: 6| Step: 10
Training loss: 1.6292301416397095
Validation loss: 2.213187793890635

Epoch: 6| Step: 11
Training loss: 1.4399971961975098
Validation loss: 2.2252368529637656

Epoch: 6| Step: 12
Training loss: 2.5527045726776123
Validation loss: 2.2230375011761985

Epoch: 6| Step: 13
Training loss: 1.4637837409973145
Validation loss: 2.1866835355758667

Epoch: 285| Step: 0
Training loss: 1.1708718538284302
Validation loss: 2.202951510747274

Epoch: 6| Step: 1
Training loss: 2.109694719314575
Validation loss: 2.227119207382202

Epoch: 6| Step: 2
Training loss: 1.7772725820541382
Validation loss: 2.2369815508524575

Epoch: 6| Step: 3
Training loss: 1.279483675956726
Validation loss: 2.225664575894674

Epoch: 6| Step: 4
Training loss: 2.253474235534668
Validation loss: 2.2175309658050537

Epoch: 6| Step: 5
Training loss: 1.6583970785140991
Validation loss: 2.2408087054888406

Epoch: 6| Step: 6
Training loss: 1.417588472366333
Validation loss: 2.198106825351715

Epoch: 6| Step: 7
Training loss: 1.1053872108459473
Validation loss: 2.244284749031067

Epoch: 6| Step: 8
Training loss: 1.3361765146255493
Validation loss: 2.202965339024862

Epoch: 6| Step: 9
Training loss: 2.172764301300049
Validation loss: 2.229280412197113

Epoch: 6| Step: 10
Training loss: 1.3140100240707397
Validation loss: 2.2138221661249795

Epoch: 6| Step: 11
Training loss: 2.041337490081787
Validation loss: 2.247507691383362

Epoch: 6| Step: 12
Training loss: 0.9831898212432861
Validation loss: 2.2305751045544944

Epoch: 6| Step: 13
Training loss: 2.444021463394165
Validation loss: 2.209583282470703

Epoch: 286| Step: 0
Training loss: 1.5213924646377563
Validation loss: 2.1995541055997214

Epoch: 6| Step: 1
Training loss: 1.1597269773483276
Validation loss: 2.1860711574554443

Epoch: 6| Step: 2
Training loss: 2.162940740585327
Validation loss: 2.214315712451935

Epoch: 6| Step: 3
Training loss: 1.527360200881958
Validation loss: 2.2160265843073526

Epoch: 6| Step: 4
Training loss: 1.219622015953064
Validation loss: 2.178612450758616

Epoch: 6| Step: 5
Training loss: 1.3174045085906982
Validation loss: 2.1992647647857666

Epoch: 6| Step: 6
Training loss: 1.9075613021850586
Validation loss: 2.1971867084503174

Epoch: 6| Step: 7
Training loss: 2.093459129333496
Validation loss: 2.2115105390548706

Epoch: 6| Step: 8
Training loss: 2.1335608959198
Validation loss: 2.1959149638811746

Epoch: 6| Step: 9
Training loss: 2.109454870223999
Validation loss: 2.2191184957822165

Epoch: 6| Step: 10
Training loss: 1.5216236114501953
Validation loss: 2.187441368897756

Epoch: 6| Step: 11
Training loss: 1.3334105014801025
Validation loss: 2.2236667474110923

Epoch: 6| Step: 12
Training loss: 1.15191650390625
Validation loss: 2.2034342686335244

Epoch: 6| Step: 13
Training loss: 2.1136374473571777
Validation loss: 2.1799659729003906

Epoch: 287| Step: 0
Training loss: 1.7309417724609375
Validation loss: 2.198937018712362

Epoch: 6| Step: 1
Training loss: 1.8308066129684448
Validation loss: 2.1875970363616943

Epoch: 6| Step: 2
Training loss: 1.3649849891662598
Validation loss: 2.2256237268447876

Epoch: 6| Step: 3
Training loss: 1.2171549797058105
Validation loss: 2.2229334314664206

Epoch: 6| Step: 4
Training loss: 2.3127944469451904
Validation loss: 2.226321220397949

Epoch: 6| Step: 5
Training loss: 1.2337086200714111
Validation loss: 2.1960502664248147

Epoch: 6| Step: 6
Training loss: 2.500335216522217
Validation loss: 2.2262933055559793

Epoch: 6| Step: 7
Training loss: 1.138676404953003
Validation loss: 2.206566353638967

Epoch: 6| Step: 8
Training loss: 1.526321291923523
Validation loss: 2.2265248696009317

Epoch: 6| Step: 9
Training loss: 1.4559687376022339
Validation loss: 2.2050429383913674

Epoch: 6| Step: 10
Training loss: 1.2570587396621704
Validation loss: 2.206716775894165

Epoch: 6| Step: 11
Training loss: 1.8803627490997314
Validation loss: 2.209127962589264

Epoch: 6| Step: 12
Training loss: 2.1248016357421875
Validation loss: 2.20817494392395

Epoch: 6| Step: 13
Training loss: 1.2628499269485474
Validation loss: 2.2025572061538696

Epoch: 288| Step: 0
Training loss: 1.2601425647735596
Validation loss: 2.1812580823898315

Epoch: 6| Step: 1
Training loss: 2.1129183769226074
Validation loss: 2.205415646235148

Epoch: 6| Step: 2
Training loss: 1.550127387046814
Validation loss: 2.235390524069468

Epoch: 6| Step: 3
Training loss: 2.433850049972534
Validation loss: 2.2174970706303916

Epoch: 6| Step: 4
Training loss: 1.4778306484222412
Validation loss: 2.2311522563298545

Epoch: 6| Step: 5
Training loss: 1.777811050415039
Validation loss: 2.2102122704188027

Epoch: 6| Step: 6
Training loss: 1.9530737400054932
Validation loss: 2.213829000790914

Epoch: 6| Step: 7
Training loss: 1.0339250564575195
Validation loss: 2.2406168778737388

Epoch: 6| Step: 8
Training loss: 1.7199530601501465
Validation loss: 2.182251513004303

Epoch: 6| Step: 9
Training loss: 1.942845344543457
Validation loss: 2.215036710103353

Epoch: 6| Step: 10
Training loss: 1.4714784622192383
Validation loss: 2.2099212408065796

Epoch: 6| Step: 11
Training loss: 1.1253581047058105
Validation loss: 2.201433261235555

Epoch: 6| Step: 12
Training loss: 1.323225975036621
Validation loss: 2.213334878285726

Epoch: 6| Step: 13
Training loss: 1.2650682926177979
Validation loss: 2.2267496983210244

Epoch: 289| Step: 0
Training loss: 2.5410330295562744
Validation loss: 2.2302247683207193

Epoch: 6| Step: 1
Training loss: 2.0245771408081055
Validation loss: 2.20357882976532

Epoch: 6| Step: 2
Training loss: 1.8554489612579346
Validation loss: 2.215070108572642

Epoch: 6| Step: 3
Training loss: 1.7937841415405273
Validation loss: 2.230963349342346

Epoch: 6| Step: 4
Training loss: 1.1180964708328247
Validation loss: 2.2121155063311257

Epoch: 6| Step: 5
Training loss: 1.3945977687835693
Validation loss: 2.216519514719645

Epoch: 6| Step: 6
Training loss: 1.643250584602356
Validation loss: 2.2258101105690002

Epoch: 6| Step: 7
Training loss: 1.5749151706695557
Validation loss: 2.229682981967926

Epoch: 6| Step: 8
Training loss: 1.37774658203125
Validation loss: 2.221772531668345

Epoch: 6| Step: 9
Training loss: 1.506150484085083
Validation loss: 2.241137901941935

Epoch: 6| Step: 10
Training loss: 0.9568580389022827
Validation loss: 2.1922344962755838

Epoch: 6| Step: 11
Training loss: 2.160750150680542
Validation loss: 2.2355696161588035

Epoch: 6| Step: 12
Training loss: 1.3301962614059448
Validation loss: 2.2053874135017395

Epoch: 6| Step: 13
Training loss: 1.158762812614441
Validation loss: 2.2244668006896973

Epoch: 290| Step: 0
Training loss: 1.5898187160491943
Validation loss: 2.2142268419265747

Epoch: 6| Step: 1
Training loss: 0.9189580082893372
Validation loss: 2.2321438789367676

Epoch: 6| Step: 2
Training loss: 1.2591588497161865
Validation loss: 2.2369072437286377

Epoch: 6| Step: 3
Training loss: 1.9641897678375244
Validation loss: 2.245002865791321

Epoch: 6| Step: 4
Training loss: 2.4560441970825195
Validation loss: 2.2337701320648193

Epoch: 6| Step: 5
Training loss: 1.6792187690734863
Validation loss: 2.2196757396062217

Epoch: 6| Step: 6
Training loss: 1.750713586807251
Validation loss: 2.228259483973185

Epoch: 6| Step: 7
Training loss: 1.2165817022323608
Validation loss: 2.2265185912450156

Epoch: 6| Step: 8
Training loss: 0.9071881771087646
Validation loss: 2.228789448738098

Epoch: 6| Step: 9
Training loss: 2.1876800060272217
Validation loss: 2.2527277072270713

Epoch: 6| Step: 10
Training loss: 1.775054931640625
Validation loss: 2.1978621085484824

Epoch: 6| Step: 11
Training loss: 1.4354608058929443
Validation loss: 2.230700353781382

Epoch: 6| Step: 12
Training loss: 2.3413431644439697
Validation loss: 2.208478490511576

Epoch: 6| Step: 13
Training loss: 1.5336836576461792
Validation loss: 2.221025904019674

Epoch: 291| Step: 0
Training loss: 1.2634658813476562
Validation loss: 2.197656253973643

Epoch: 6| Step: 1
Training loss: 2.6568102836608887
Validation loss: 2.208117584387461

Epoch: 6| Step: 2
Training loss: 1.6768497228622437
Validation loss: 2.210491100947062

Epoch: 6| Step: 3
Training loss: 1.3656549453735352
Validation loss: 2.1763795614242554

Epoch: 6| Step: 4
Training loss: 1.3797330856323242
Validation loss: 2.2244454423586526

Epoch: 6| Step: 5
Training loss: 1.919266700744629
Validation loss: 2.1955071489016214

Epoch: 6| Step: 6
Training loss: 1.640410304069519
Validation loss: 2.176226536432902

Epoch: 6| Step: 7
Training loss: 1.3819048404693604
Validation loss: 2.206788718700409

Epoch: 6| Step: 8
Training loss: 1.0528149604797363
Validation loss: 2.2111653089523315

Epoch: 6| Step: 9
Training loss: 1.3267018795013428
Validation loss: 2.2287736336390176

Epoch: 6| Step: 10
Training loss: 1.8182506561279297
Validation loss: 2.2237489223480225

Epoch: 6| Step: 11
Training loss: 2.0431337356567383
Validation loss: 2.230315844217936

Epoch: 6| Step: 12
Training loss: 1.5881800651550293
Validation loss: 2.192274490992228

Epoch: 6| Step: 13
Training loss: 1.2638622522354126
Validation loss: 2.2132839957873025

Epoch: 292| Step: 0
Training loss: 2.106905460357666
Validation loss: 2.221147835254669

Epoch: 6| Step: 1
Training loss: 2.065263032913208
Validation loss: 2.209622840086619

Epoch: 6| Step: 2
Training loss: 1.8856550455093384
Validation loss: 2.1840447584788003

Epoch: 6| Step: 3
Training loss: 1.4945542812347412
Validation loss: 2.2122295101483664

Epoch: 6| Step: 4
Training loss: 1.7516999244689941
Validation loss: 2.2093058228492737

Epoch: 6| Step: 5
Training loss: 1.696789264678955
Validation loss: 2.2395459612210593

Epoch: 6| Step: 6
Training loss: 0.9238450527191162
Validation loss: 2.1826621492703757

Epoch: 6| Step: 7
Training loss: 1.6491241455078125
Validation loss: 2.221225639184316

Epoch: 6| Step: 8
Training loss: 1.6149516105651855
Validation loss: 2.159456253051758

Epoch: 6| Step: 9
Training loss: 1.4966316223144531
Validation loss: 2.2171985308329263

Epoch: 6| Step: 10
Training loss: 1.2466609477996826
Validation loss: 2.226286510626475

Epoch: 6| Step: 11
Training loss: 1.3827826976776123
Validation loss: 2.2003458937009177

Epoch: 6| Step: 12
Training loss: 1.3008942604064941
Validation loss: 2.1995046536127725

Epoch: 6| Step: 13
Training loss: 1.617350459098816
Validation loss: 2.226373612880707

Epoch: 293| Step: 0
Training loss: 1.5920472145080566
Validation loss: 2.228843331336975

Epoch: 6| Step: 1
Training loss: 2.0282363891601562
Validation loss: 2.2124700943628945

Epoch: 6| Step: 2
Training loss: 2.0811715126037598
Validation loss: 2.2234559655189514

Epoch: 6| Step: 3
Training loss: 2.1131434440612793
Validation loss: 2.219390034675598

Epoch: 6| Step: 4
Training loss: 1.3177564144134521
Validation loss: 2.2238884568214417

Epoch: 6| Step: 5
Training loss: 0.9591184854507446
Validation loss: 2.1971020301183066

Epoch: 6| Step: 6
Training loss: 1.073480486869812
Validation loss: 2.2200192411740622

Epoch: 6| Step: 7
Training loss: 2.1076197624206543
Validation loss: 2.226567109425863

Epoch: 6| Step: 8
Training loss: 1.5330908298492432
Validation loss: 2.213491360346476

Epoch: 6| Step: 9
Training loss: 1.7154641151428223
Validation loss: 2.1869913736979165

Epoch: 6| Step: 10
Training loss: 1.0421549081802368
Validation loss: 2.232210715611776

Epoch: 6| Step: 11
Training loss: 1.886798620223999
Validation loss: 2.2040982047716775

Epoch: 6| Step: 12
Training loss: 1.0623377561569214
Validation loss: 2.215115209420522

Epoch: 6| Step: 13
Training loss: 1.719380497932434
Validation loss: 2.1927819649378457

Epoch: 294| Step: 0
Training loss: 2.482605457305908
Validation loss: 2.1748099327087402

Epoch: 6| Step: 1
Training loss: 1.4061486721038818
Validation loss: 2.1981346209843955

Epoch: 6| Step: 2
Training loss: 1.3210824728012085
Validation loss: 2.223521888256073

Epoch: 6| Step: 3
Training loss: 1.6374658346176147
Validation loss: 2.2209938963254294

Epoch: 6| Step: 4
Training loss: 1.1431729793548584
Validation loss: 2.2131505409876504

Epoch: 6| Step: 5
Training loss: 0.9874212741851807
Validation loss: 2.228661060333252

Epoch: 6| Step: 6
Training loss: 1.8109079599380493
Validation loss: 2.213464299837748

Epoch: 6| Step: 7
Training loss: 2.0203633308410645
Validation loss: 2.2516956130663552

Epoch: 6| Step: 8
Training loss: 2.18115234375
Validation loss: 2.2272297541300454

Epoch: 6| Step: 9
Training loss: 2.647461414337158
Validation loss: 2.210034410158793

Epoch: 6| Step: 10
Training loss: 1.7729520797729492
Validation loss: 2.225788652896881

Epoch: 6| Step: 11
Training loss: 1.0728724002838135
Validation loss: 2.2377410729726157

Epoch: 6| Step: 12
Training loss: 0.725011944770813
Validation loss: 2.2249067227045694

Epoch: 6| Step: 13
Training loss: 1.868901252746582
Validation loss: 2.258156140645345

Epoch: 295| Step: 0
Training loss: 2.020507335662842
Validation loss: 2.2345300714174905

Epoch: 6| Step: 1
Training loss: 1.280149221420288
Validation loss: 2.2458726366360984

Epoch: 6| Step: 2
Training loss: 2.030435562133789
Validation loss: 2.2317862510681152

Epoch: 6| Step: 3
Training loss: 1.6164358854293823
Validation loss: 2.2144596378008523

Epoch: 6| Step: 4
Training loss: 2.187312602996826
Validation loss: 2.2219123244285583

Epoch: 6| Step: 5
Training loss: 1.3503166437149048
Validation loss: 2.243407726287842

Epoch: 6| Step: 6
Training loss: 1.8198148012161255
Validation loss: 2.2372392614682517

Epoch: 6| Step: 7
Training loss: 1.7161768674850464
Validation loss: 2.2196642557779946

Epoch: 6| Step: 8
Training loss: 1.3119981288909912
Validation loss: 2.2308655977249146

Epoch: 6| Step: 9
Training loss: 1.1454839706420898
Validation loss: 2.205594460169474

Epoch: 6| Step: 10
Training loss: 1.5239195823669434
Validation loss: 2.2177647948265076

Epoch: 6| Step: 11
Training loss: 1.6821420192718506
Validation loss: 2.208401620388031

Epoch: 6| Step: 12
Training loss: 0.9092057347297668
Validation loss: 2.194727838039398

Epoch: 6| Step: 13
Training loss: 2.032743453979492
Validation loss: 2.187248647212982

Epoch: 296| Step: 0
Training loss: 2.244947910308838
Validation loss: 2.1909361282984414

Epoch: 6| Step: 1
Training loss: 1.316030740737915
Validation loss: 2.1712236205736795

Epoch: 6| Step: 2
Training loss: 2.318230152130127
Validation loss: 2.1941160957018533

Epoch: 6| Step: 3
Training loss: 1.3557252883911133
Validation loss: 2.1944568951924643

Epoch: 6| Step: 4
Training loss: 1.5904285907745361
Validation loss: 2.1806145310401917

Epoch: 6| Step: 5
Training loss: 1.1908975839614868
Validation loss: 2.195806006590525

Epoch: 6| Step: 6
Training loss: 1.5229995250701904
Validation loss: 2.1974006295204163

Epoch: 6| Step: 7
Training loss: 1.6110399961471558
Validation loss: 2.2362142205238342

Epoch: 6| Step: 8
Training loss: 1.3517799377441406
Validation loss: 2.1909095644950867

Epoch: 6| Step: 9
Training loss: 1.2099874019622803
Validation loss: 2.1903056303660073

Epoch: 6| Step: 10
Training loss: 1.300764560699463
Validation loss: 2.186562637488047

Epoch: 6| Step: 11
Training loss: 0.8660678863525391
Validation loss: 2.1862494945526123

Epoch: 6| Step: 12
Training loss: 1.866083025932312
Validation loss: 2.1881271998087564

Epoch: 6| Step: 13
Training loss: 2.258768320083618
Validation loss: 2.2055763403574624

Epoch: 297| Step: 0
Training loss: 1.132976770401001
Validation loss: 2.2044230302174888

Epoch: 6| Step: 1
Training loss: 0.9429528713226318
Validation loss: 2.1892223358154297

Epoch: 6| Step: 2
Training loss: 1.642707109451294
Validation loss: 2.2212426463762918

Epoch: 6| Step: 3
Training loss: 1.811690092086792
Validation loss: 2.2055710355440774

Epoch: 6| Step: 4
Training loss: 1.7270081043243408
Validation loss: 2.2387357552846274

Epoch: 6| Step: 5
Training loss: 1.334862232208252
Validation loss: 2.2175791462262473

Epoch: 6| Step: 6
Training loss: 2.1977572441101074
Validation loss: 2.2162455717722573

Epoch: 6| Step: 7
Training loss: 1.431631326675415
Validation loss: 2.166102945804596

Epoch: 6| Step: 8
Training loss: 1.9578341245651245
Validation loss: 2.2133031288782754

Epoch: 6| Step: 9
Training loss: 1.75496506690979
Validation loss: 2.2202601432800293

Epoch: 6| Step: 10
Training loss: 1.3655086755752563
Validation loss: 2.2022817134857178

Epoch: 6| Step: 11
Training loss: 1.8022899627685547
Validation loss: 2.197376569112142

Epoch: 6| Step: 12
Training loss: 1.5384254455566406
Validation loss: 2.2274022102355957

Epoch: 6| Step: 13
Training loss: 1.3826344013214111
Validation loss: 2.2036563555399575

Epoch: 298| Step: 0
Training loss: 1.173565149307251
Validation loss: 2.230467200279236

Epoch: 6| Step: 1
Training loss: 1.5682599544525146
Validation loss: 2.230591098467509

Epoch: 6| Step: 2
Training loss: 1.5185601711273193
Validation loss: 2.2176254391670227

Epoch: 6| Step: 3
Training loss: 1.5647926330566406
Validation loss: 2.2114765644073486

Epoch: 6| Step: 4
Training loss: 1.4705655574798584
Validation loss: 2.2058263023694358

Epoch: 6| Step: 5
Training loss: 0.9720740914344788
Validation loss: 2.2510961095492044

Epoch: 6| Step: 6
Training loss: 1.8229066133499146
Validation loss: 2.228177547454834

Epoch: 6| Step: 7
Training loss: 2.0384609699249268
Validation loss: 2.2457152605056763

Epoch: 6| Step: 8
Training loss: 1.6343680620193481
Validation loss: 2.2294184366861978

Epoch: 6| Step: 9
Training loss: 1.8799837827682495
Validation loss: 2.211119612058004

Epoch: 6| Step: 10
Training loss: 1.3754806518554688
Validation loss: 2.2007829546928406

Epoch: 6| Step: 11
Training loss: 1.471648097038269
Validation loss: 2.1705877979596457

Epoch: 6| Step: 12
Training loss: 2.4988653659820557
Validation loss: 2.2047871549924216

Epoch: 6| Step: 13
Training loss: 1.309912919998169
Validation loss: 2.2023815711339316

Epoch: 299| Step: 0
Training loss: 1.3643909692764282
Validation loss: 2.205695947011312

Epoch: 6| Step: 1
Training loss: 1.1440277099609375
Validation loss: 2.1799108386039734

Epoch: 6| Step: 2
Training loss: 1.9342856407165527
Validation loss: 2.1928388277689614

Epoch: 6| Step: 3
Training loss: 1.7428714036941528
Validation loss: 2.208398679892222

Epoch: 6| Step: 4
Training loss: 1.5990536212921143
Validation loss: 2.279856503009796

Epoch: 6| Step: 5
Training loss: 1.0304734706878662
Validation loss: 2.1702648997306824

Epoch: 6| Step: 6
Training loss: 1.6116323471069336
Validation loss: 2.2094868222872415

Epoch: 6| Step: 7
Training loss: 1.9039525985717773
Validation loss: 2.1938679615656533

Epoch: 6| Step: 8
Training loss: 1.859015703201294
Validation loss: 2.207630236943563

Epoch: 6| Step: 9
Training loss: 1.7251179218292236
Validation loss: 2.2246386607488

Epoch: 6| Step: 10
Training loss: 1.527280330657959
Validation loss: 2.1960753202438354

Epoch: 6| Step: 11
Training loss: 1.7962491512298584
Validation loss: 2.209812959035238

Epoch: 6| Step: 12
Training loss: 2.0155062675476074
Validation loss: 2.214495539665222

Epoch: 6| Step: 13
Training loss: 2.0883986949920654
Validation loss: 2.2368480364481607

Epoch: 300| Step: 0
Training loss: 1.4059100151062012
Validation loss: 2.1769588788350425

Epoch: 6| Step: 1
Training loss: 1.4889742136001587
Validation loss: 2.195794959863027

Epoch: 6| Step: 2
Training loss: 1.3958508968353271
Validation loss: 2.2479899326960244

Epoch: 6| Step: 3
Training loss: 1.1348603963851929
Validation loss: 2.2311145861943564

Epoch: 6| Step: 4
Training loss: 1.6377902030944824
Validation loss: 2.2497861782709756

Epoch: 6| Step: 5
Training loss: 1.481698751449585
Validation loss: 2.2736910382906594

Epoch: 6| Step: 6
Training loss: 1.7196776866912842
Validation loss: 2.241144816080729

Epoch: 6| Step: 7
Training loss: 1.3991872072219849
Validation loss: 2.2259388367335

Epoch: 6| Step: 8
Training loss: 1.5371407270431519
Validation loss: 2.229212919871012

Epoch: 6| Step: 9
Training loss: 1.1005192995071411
Validation loss: 2.239244600137075

Epoch: 6| Step: 10
Training loss: 1.7867522239685059
Validation loss: 2.2806768218676248

Epoch: 6| Step: 11
Training loss: 1.8390196561813354
Validation loss: 2.217664877573649

Epoch: 6| Step: 12
Training loss: 1.9845523834228516
Validation loss: 2.2700828313827515

Epoch: 6| Step: 13
Training loss: 1.9229443073272705
Validation loss: 2.2324952681859336

Epoch: 301| Step: 0
Training loss: 1.557600736618042
Validation loss: 2.224561254183451

Epoch: 6| Step: 1
Training loss: 1.7690871953964233
Validation loss: 2.244478464126587

Epoch: 6| Step: 2
Training loss: 1.6019525527954102
Validation loss: 2.2384923299153647

Epoch: 6| Step: 3
Training loss: 1.1850013732910156
Validation loss: 2.206725835800171

Epoch: 6| Step: 4
Training loss: 2.1174216270446777
Validation loss: 2.203933616479238

Epoch: 6| Step: 5
Training loss: 1.5030412673950195
Validation loss: 2.191175421079

Epoch: 6| Step: 6
Training loss: 1.9628592729568481
Validation loss: 2.2334262132644653

Epoch: 6| Step: 7
Training loss: 1.5508010387420654
Validation loss: 2.184595743815104

Epoch: 6| Step: 8
Training loss: 1.4632163047790527
Validation loss: 2.178529659907023

Epoch: 6| Step: 9
Training loss: 2.037541389465332
Validation loss: 2.1955096324284873

Epoch: 6| Step: 10
Training loss: 0.7978949546813965
Validation loss: 2.226617137591044

Epoch: 6| Step: 11
Training loss: 1.1293132305145264
Validation loss: 2.215422431627909

Epoch: 6| Step: 12
Training loss: 1.4189393520355225
Validation loss: 2.2252978483835855

Epoch: 6| Step: 13
Training loss: 2.1117660999298096
Validation loss: 2.2343437472979226

Epoch: 302| Step: 0
Training loss: 0.9368087649345398
Validation loss: 2.2328143318494162

Epoch: 6| Step: 1
Training loss: 1.464827299118042
Validation loss: 2.1760352651278176

Epoch: 6| Step: 2
Training loss: 1.370179295539856
Validation loss: 2.2527215083440146

Epoch: 6| Step: 3
Training loss: 1.2385543584823608
Validation loss: 2.2475099563598633

Epoch: 6| Step: 4
Training loss: 1.6735223531723022
Validation loss: 2.23923925558726

Epoch: 6| Step: 5
Training loss: 2.1238765716552734
Validation loss: 2.25451922416687

Epoch: 6| Step: 6
Training loss: 2.0959582328796387
Validation loss: 2.2223229010899863

Epoch: 6| Step: 7
Training loss: 1.6676726341247559
Validation loss: 2.2336716651916504

Epoch: 6| Step: 8
Training loss: 1.4607480764389038
Validation loss: 2.225480556488037

Epoch: 6| Step: 9
Training loss: 1.0680500268936157
Validation loss: 2.2148956855138144

Epoch: 6| Step: 10
Training loss: 1.989824891090393
Validation loss: 2.2212775548299155

Epoch: 6| Step: 11
Training loss: 2.0536460876464844
Validation loss: 2.22122452656428

Epoch: 6| Step: 12
Training loss: 1.1254677772521973
Validation loss: 2.2035116950670877

Epoch: 6| Step: 13
Training loss: 1.2801086902618408
Validation loss: 2.2043423652648926

Epoch: 303| Step: 0
Training loss: 2.2684788703918457
Validation loss: 2.2258346478144326

Epoch: 6| Step: 1
Training loss: 1.4574041366577148
Validation loss: 2.229623019695282

Epoch: 6| Step: 2
Training loss: 2.2978744506835938
Validation loss: 2.2243237694104514

Epoch: 6| Step: 3
Training loss: 1.2058871984481812
Validation loss: 2.222100019454956

Epoch: 6| Step: 4
Training loss: 1.2301734685897827
Validation loss: 2.206285834312439

Epoch: 6| Step: 5
Training loss: 1.3540467023849487
Validation loss: 2.198838452498118

Epoch: 6| Step: 6
Training loss: 1.1408326625823975
Validation loss: 2.2239418228467307

Epoch: 6| Step: 7
Training loss: 1.43123459815979
Validation loss: 2.2305216789245605

Epoch: 6| Step: 8
Training loss: 2.080674648284912
Validation loss: 2.2461907267570496

Epoch: 6| Step: 9
Training loss: 1.253240704536438
Validation loss: 2.2439207633336387

Epoch: 6| Step: 10
Training loss: 1.3105509281158447
Validation loss: 2.2233113050460815

Epoch: 6| Step: 11
Training loss: 2.039842367172241
Validation loss: 2.2254130840301514

Epoch: 6| Step: 12
Training loss: 0.993649423122406
Validation loss: 2.219727039337158

Epoch: 6| Step: 13
Training loss: 1.1639690399169922
Validation loss: 2.222944676876068

Epoch: 304| Step: 0
Training loss: 1.7058439254760742
Validation loss: 2.289536436398824

Epoch: 6| Step: 1
Training loss: 1.2448102235794067
Validation loss: 2.2719366749127707

Epoch: 6| Step: 2
Training loss: 1.6710429191589355
Validation loss: 2.2192129095395408

Epoch: 6| Step: 3
Training loss: 1.4293186664581299
Validation loss: 2.2406674226125083

Epoch: 6| Step: 4
Training loss: 1.615356683731079
Validation loss: 2.24269300699234

Epoch: 6| Step: 5
Training loss: 1.390627145767212
Validation loss: 2.233307639757792

Epoch: 6| Step: 6
Training loss: 1.6757614612579346
Validation loss: 2.2444728016853333

Epoch: 6| Step: 7
Training loss: 1.5232908725738525
Validation loss: 2.1996740897496543

Epoch: 6| Step: 8
Training loss: 1.7771644592285156
Validation loss: 2.2424681584040322

Epoch: 6| Step: 9
Training loss: 1.478261947631836
Validation loss: 2.211338738600413

Epoch: 6| Step: 10
Training loss: 2.0460734367370605
Validation loss: 2.221470514933268

Epoch: 6| Step: 11
Training loss: 1.2978332042694092
Validation loss: 2.21582422653834

Epoch: 6| Step: 12
Training loss: 1.972878336906433
Validation loss: 2.239512006441752

Epoch: 6| Step: 13
Training loss: 1.3608753681182861
Validation loss: 2.2122572660446167

Epoch: 305| Step: 0
Training loss: 1.6781578063964844
Validation loss: 2.2557260990142822

Epoch: 6| Step: 1
Training loss: 1.262400507926941
Validation loss: 2.2163795630137124

Epoch: 6| Step: 2
Training loss: 2.1880946159362793
Validation loss: 2.212032198905945

Epoch: 6| Step: 3
Training loss: 1.1255507469177246
Validation loss: 2.2117724418640137

Epoch: 6| Step: 4
Training loss: 1.1485159397125244
Validation loss: 2.2253279288609824

Epoch: 6| Step: 5
Training loss: 2.473079204559326
Validation loss: 2.224280834197998

Epoch: 6| Step: 6
Training loss: 1.1562249660491943
Validation loss: 2.239864408969879

Epoch: 6| Step: 7
Training loss: 1.4601538181304932
Validation loss: 2.2413582603136697

Epoch: 6| Step: 8
Training loss: 1.3226999044418335
Validation loss: 2.2532577315966287

Epoch: 6| Step: 9
Training loss: 1.708902359008789
Validation loss: 2.2052688598632812

Epoch: 6| Step: 10
Training loss: 1.3154528141021729
Validation loss: 2.2102704445521035

Epoch: 6| Step: 11
Training loss: 1.9998496770858765
Validation loss: 2.244980255762736

Epoch: 6| Step: 12
Training loss: 1.0270211696624756
Validation loss: 2.2308908104896545

Epoch: 6| Step: 13
Training loss: 1.4992412328720093
Validation loss: 2.2214683492978415

Epoch: 306| Step: 0
Training loss: 2.0464425086975098
Validation loss: 2.2481438716252646

Epoch: 6| Step: 1
Training loss: 1.927739143371582
Validation loss: 2.208002209663391

Epoch: 6| Step: 2
Training loss: 1.3290703296661377
Validation loss: 2.2592446406682334

Epoch: 6| Step: 3
Training loss: 1.4583368301391602
Validation loss: 2.222328782081604

Epoch: 6| Step: 4
Training loss: 1.1627767086029053
Validation loss: 2.2328460017840066

Epoch: 6| Step: 5
Training loss: 1.1348133087158203
Validation loss: 2.2127907474835715

Epoch: 6| Step: 6
Training loss: 1.9497807025909424
Validation loss: 2.241718888282776

Epoch: 6| Step: 7
Training loss: 1.9033355712890625
Validation loss: 2.2257534662882485

Epoch: 6| Step: 8
Training loss: 1.5980039834976196
Validation loss: 2.242238938808441

Epoch: 6| Step: 9
Training loss: 1.3651597499847412
Validation loss: 2.2170284191767373

Epoch: 6| Step: 10
Training loss: 1.5440497398376465
Validation loss: 2.2167676289876304

Epoch: 6| Step: 11
Training loss: 1.741646647453308
Validation loss: 2.221582611401876

Epoch: 6| Step: 12
Training loss: 1.2794160842895508
Validation loss: 2.213553011417389

Epoch: 6| Step: 13
Training loss: 1.0120573043823242
Validation loss: 2.20743727684021

Epoch: 307| Step: 0
Training loss: 1.8049358129501343
Validation loss: 2.210864782333374

Epoch: 6| Step: 1
Training loss: 2.500325918197632
Validation loss: 2.224205255508423

Epoch: 6| Step: 2
Training loss: 1.7178055047988892
Validation loss: 2.1940839290618896

Epoch: 6| Step: 3
Training loss: 1.4693832397460938
Validation loss: 2.207069158554077

Epoch: 6| Step: 4
Training loss: 1.8272937536239624
Validation loss: 2.219186027844747

Epoch: 6| Step: 5
Training loss: 1.4662163257598877
Validation loss: 2.189546843369802

Epoch: 6| Step: 6
Training loss: 1.3755698204040527
Validation loss: 2.1908963123957315

Epoch: 6| Step: 7
Training loss: 1.3379747867584229
Validation loss: 2.18230269352595

Epoch: 6| Step: 8
Training loss: 1.7948795557022095
Validation loss: 2.1537758906682334

Epoch: 6| Step: 9
Training loss: 1.5879327058792114
Validation loss: 2.1653443773587546

Epoch: 6| Step: 10
Training loss: 1.5786948204040527
Validation loss: 2.1725496848424277

Epoch: 6| Step: 11
Training loss: 0.9685698747634888
Validation loss: 2.1818325916926065

Epoch: 6| Step: 12
Training loss: 1.9280060529708862
Validation loss: 2.180321375528971

Epoch: 6| Step: 13
Training loss: 1.047327995300293
Validation loss: 2.222476919492086

Epoch: 308| Step: 0
Training loss: 1.6990833282470703
Validation loss: 2.1943957010904946

Epoch: 6| Step: 1
Training loss: 1.6916784048080444
Validation loss: 2.2105416854222617

Epoch: 6| Step: 2
Training loss: 1.7387964725494385
Validation loss: 2.16659144560496

Epoch: 6| Step: 3
Training loss: 1.211179256439209
Validation loss: 2.190611561139425

Epoch: 6| Step: 4
Training loss: 1.1617255210876465
Validation loss: 2.2161904772122702

Epoch: 6| Step: 5
Training loss: 1.3432958126068115
Validation loss: 2.1831010977427163

Epoch: 6| Step: 6
Training loss: 1.85862135887146
Validation loss: 2.21184378862381

Epoch: 6| Step: 7
Training loss: 2.217088222503662
Validation loss: 2.2233548959096274

Epoch: 6| Step: 8
Training loss: 1.3227312564849854
Validation loss: 2.206552267074585

Epoch: 6| Step: 9
Training loss: 1.377704381942749
Validation loss: 2.1744381189346313

Epoch: 6| Step: 10
Training loss: 2.391695261001587
Validation loss: 2.1679357290267944

Epoch: 6| Step: 11
Training loss: 1.2513113021850586
Validation loss: 2.2177032033602395

Epoch: 6| Step: 12
Training loss: 1.2740076780319214
Validation loss: 2.2090465426445007

Epoch: 6| Step: 13
Training loss: 1.2446478605270386
Validation loss: 2.2335925896962485

Epoch: 309| Step: 0
Training loss: 1.371521234512329
Validation loss: 2.230521500110626

Epoch: 6| Step: 1
Training loss: 1.9410268068313599
Validation loss: 2.2044543425242105

Epoch: 6| Step: 2
Training loss: 0.9993723630905151
Validation loss: 2.1827391187349954

Epoch: 6| Step: 3
Training loss: 0.9064105749130249
Validation loss: 2.174875497817993

Epoch: 6| Step: 4
Training loss: 1.4543602466583252
Validation loss: 2.1885250012079873

Epoch: 6| Step: 5
Training loss: 2.007234573364258
Validation loss: 2.193649411201477

Epoch: 6| Step: 6
Training loss: 1.7468318939208984
Validation loss: 2.223586320877075

Epoch: 6| Step: 7
Training loss: 2.2964649200439453
Validation loss: 2.2052709261576333

Epoch: 6| Step: 8
Training loss: 1.091091513633728
Validation loss: 2.1962331732114158

Epoch: 6| Step: 9
Training loss: 1.7082083225250244
Validation loss: 2.2219338019688926

Epoch: 6| Step: 10
Training loss: 1.5800156593322754
Validation loss: 2.230534791946411

Epoch: 6| Step: 11
Training loss: 2.093836545944214
Validation loss: 2.2050055464108786

Epoch: 6| Step: 12
Training loss: 1.6048263311386108
Validation loss: 2.2196552753448486

Epoch: 6| Step: 13
Training loss: 0.8940199017524719
Validation loss: 2.2102800806363425

Epoch: 310| Step: 0
Training loss: 1.080247402191162
Validation loss: 2.176562031110128

Epoch: 6| Step: 1
Training loss: 1.5796937942504883
Validation loss: 2.1846160093943277

Epoch: 6| Step: 2
Training loss: 1.53072988986969
Validation loss: 2.182289401690165

Epoch: 6| Step: 3
Training loss: 1.302899718284607
Validation loss: 2.161215325196584

Epoch: 6| Step: 4
Training loss: 1.0601768493652344
Validation loss: 2.201423724492391

Epoch: 6| Step: 5
Training loss: 1.6774637699127197
Validation loss: 2.217416604359945

Epoch: 6| Step: 6
Training loss: 1.8701125383377075
Validation loss: 2.2328670422236123

Epoch: 6| Step: 7
Training loss: 1.8989671468734741
Validation loss: 2.2332303524017334

Epoch: 6| Step: 8
Training loss: 1.5399022102355957
Validation loss: 2.2237879832585654

Epoch: 6| Step: 9
Training loss: 1.212538242340088
Validation loss: 2.1876684625943503

Epoch: 6| Step: 10
Training loss: 1.6333246231079102
Validation loss: 2.2004432678222656

Epoch: 6| Step: 11
Training loss: 1.4266656637191772
Validation loss: 2.1735647916793823

Epoch: 6| Step: 12
Training loss: 1.261378526687622
Validation loss: 2.166211982568105

Epoch: 6| Step: 13
Training loss: 1.5880978107452393
Validation loss: 2.1729156573613486

Epoch: 311| Step: 0
Training loss: 1.7734967470169067
Validation loss: 2.1637526750564575

Epoch: 6| Step: 1
Training loss: 1.1417336463928223
Validation loss: 2.157563885052999

Epoch: 6| Step: 2
Training loss: 1.4462275505065918
Validation loss: 2.163522998491923

Epoch: 6| Step: 3
Training loss: 1.4053831100463867
Validation loss: 2.1815724770228067

Epoch: 6| Step: 4
Training loss: 1.2516632080078125
Validation loss: 2.1611285408337912

Epoch: 6| Step: 5
Training loss: 1.2699470520019531
Validation loss: 2.183167894681295

Epoch: 6| Step: 6
Training loss: 1.3024919033050537
Validation loss: 2.186988969643911

Epoch: 6| Step: 7
Training loss: 2.183361768722534
Validation loss: 2.204468866189321

Epoch: 6| Step: 8
Training loss: 1.4583826065063477
Validation loss: 2.210447589556376

Epoch: 6| Step: 9
Training loss: 2.0345942974090576
Validation loss: 2.180443048477173

Epoch: 6| Step: 10
Training loss: 2.291541576385498
Validation loss: 2.194610814253489

Epoch: 6| Step: 11
Training loss: 1.001451015472412
Validation loss: 2.187395970026652

Epoch: 6| Step: 12
Training loss: 1.5801382064819336
Validation loss: 2.203040341536204

Epoch: 6| Step: 13
Training loss: 0.90021151304245
Validation loss: 2.1911767522493997

Epoch: 312| Step: 0
Training loss: 1.0027843713760376
Validation loss: 2.203526496887207

Epoch: 6| Step: 1
Training loss: 2.1131114959716797
Validation loss: 2.2196325858434043

Epoch: 6| Step: 2
Training loss: 3.0024220943450928
Validation loss: 2.274653911590576

Epoch: 6| Step: 3
Training loss: 1.483241081237793
Validation loss: 2.259290337562561

Epoch: 6| Step: 4
Training loss: 1.6501147747039795
Validation loss: 2.2798771063486734

Epoch: 6| Step: 5
Training loss: 1.3611472845077515
Validation loss: 2.232514043649038

Epoch: 6| Step: 6
Training loss: 1.9079434871673584
Validation loss: 2.2421173453330994

Epoch: 6| Step: 7
Training loss: 1.2847175598144531
Validation loss: 2.2017611265182495

Epoch: 6| Step: 8
Training loss: 1.5534876585006714
Validation loss: 2.2353819012641907

Epoch: 6| Step: 9
Training loss: 1.7345882654190063
Validation loss: 2.199278195699056

Epoch: 6| Step: 10
Training loss: 1.6577824354171753
Validation loss: 2.1877572536468506

Epoch: 6| Step: 11
Training loss: 2.0095043182373047
Validation loss: 2.213878552118937

Epoch: 6| Step: 12
Training loss: 1.9627152681350708
Validation loss: 2.2057104110717773

Epoch: 6| Step: 13
Training loss: 1.9002165794372559
Validation loss: 2.1765482425689697

Epoch: 313| Step: 0
Training loss: 1.4935178756713867
Validation loss: 2.21814892689387

Epoch: 6| Step: 1
Training loss: 1.6261258125305176
Validation loss: 2.2154409885406494

Epoch: 6| Step: 2
Training loss: 1.065369963645935
Validation loss: 2.241354008515676

Epoch: 6| Step: 3
Training loss: 1.6551599502563477
Validation loss: 2.2036402821540833

Epoch: 6| Step: 4
Training loss: 1.503448724746704
Validation loss: 2.207228422164917

Epoch: 6| Step: 5
Training loss: 1.727604866027832
Validation loss: 2.233018775780996

Epoch: 6| Step: 6
Training loss: 1.7746734619140625
Validation loss: 2.2392210165659585

Epoch: 6| Step: 7
Training loss: 1.9224035739898682
Validation loss: 2.226980725924174

Epoch: 6| Step: 8
Training loss: 1.165575385093689
Validation loss: 2.197649518648783

Epoch: 6| Step: 9
Training loss: 2.318385362625122
Validation loss: 2.2129573822021484

Epoch: 6| Step: 10
Training loss: 1.5465247631072998
Validation loss: 2.1865497628847756

Epoch: 6| Step: 11
Training loss: 1.5623905658721924
Validation loss: 2.162069876988729

Epoch: 6| Step: 12
Training loss: 1.4174493551254272
Validation loss: 2.19094971815745

Epoch: 6| Step: 13
Training loss: 1.6167166233062744
Validation loss: 2.1575861175855002

Epoch: 314| Step: 0
Training loss: 1.2612712383270264
Validation loss: 2.1561822493871055

Epoch: 6| Step: 1
Training loss: 1.3442131280899048
Validation loss: 2.13260018825531

Epoch: 6| Step: 2
Training loss: 1.3072803020477295
Validation loss: 2.125604748725891

Epoch: 6| Step: 3
Training loss: 1.568800926208496
Validation loss: 2.169751147429148

Epoch: 6| Step: 4
Training loss: 1.4177366495132446
Validation loss: 2.182400325934092

Epoch: 6| Step: 5
Training loss: 1.131641149520874
Validation loss: 2.1798306703567505

Epoch: 6| Step: 6
Training loss: 1.536708116531372
Validation loss: 2.1723702549934387

Epoch: 6| Step: 7
Training loss: 1.8077161312103271
Validation loss: 2.211956183115641

Epoch: 6| Step: 8
Training loss: 1.7832773923873901
Validation loss: 2.2004403869311013

Epoch: 6| Step: 9
Training loss: 1.4171433448791504
Validation loss: 2.186036467552185

Epoch: 6| Step: 10
Training loss: 1.8704397678375244
Validation loss: 2.1894248723983765

Epoch: 6| Step: 11
Training loss: 1.6617112159729004
Validation loss: 2.1525515715281167

Epoch: 6| Step: 12
Training loss: 1.464815378189087
Validation loss: 2.1761616865793862

Epoch: 6| Step: 13
Training loss: 1.7866911888122559
Validation loss: 2.1971776485443115

Epoch: 315| Step: 0
Training loss: 0.9078584909439087
Validation loss: 2.1986371278762817

Epoch: 6| Step: 1
Training loss: 0.9960866570472717
Validation loss: 2.212703307469686

Epoch: 6| Step: 2
Training loss: 1.739924669265747
Validation loss: 2.2281999985376992

Epoch: 6| Step: 3
Training loss: 1.5222325325012207
Validation loss: 2.2089237570762634

Epoch: 6| Step: 4
Training loss: 1.5382194519042969
Validation loss: 2.213919242223104

Epoch: 6| Step: 5
Training loss: 1.3205738067626953
Validation loss: 2.211538811524709

Epoch: 6| Step: 6
Training loss: 1.1691991090774536
Validation loss: 2.210179885228475

Epoch: 6| Step: 7
Training loss: 1.9661033153533936
Validation loss: 2.224086105823517

Epoch: 6| Step: 8
Training loss: 1.5633758306503296
Validation loss: 2.221094528834025

Epoch: 6| Step: 9
Training loss: 1.6771049499511719
Validation loss: 2.2095633347829184

Epoch: 6| Step: 10
Training loss: 1.6331713199615479
Validation loss: 2.201016585032145

Epoch: 6| Step: 11
Training loss: 2.152204990386963
Validation loss: 2.2130001982053122

Epoch: 6| Step: 12
Training loss: 2.254227638244629
Validation loss: 2.2499147852261863

Epoch: 6| Step: 13
Training loss: 1.5785714387893677
Validation loss: 2.226636211077372

Epoch: 316| Step: 0
Training loss: 0.9649515748023987
Validation loss: 2.2196399768193564

Epoch: 6| Step: 1
Training loss: 1.340606451034546
Validation loss: 2.1961880127588906

Epoch: 6| Step: 2
Training loss: 1.7117093801498413
Validation loss: 2.194241682688395

Epoch: 6| Step: 3
Training loss: 1.5072821378707886
Validation loss: 2.2009937167167664

Epoch: 6| Step: 4
Training loss: 1.828248381614685
Validation loss: 2.22466504573822

Epoch: 6| Step: 5
Training loss: 1.931634545326233
Validation loss: 2.2295777599016824

Epoch: 6| Step: 6
Training loss: 2.1968135833740234
Validation loss: 2.2175480127334595

Epoch: 6| Step: 7
Training loss: 1.1387887001037598
Validation loss: 2.186794380346934

Epoch: 6| Step: 8
Training loss: 1.8731701374053955
Validation loss: 2.185615519682566

Epoch: 6| Step: 9
Training loss: 1.9081157445907593
Validation loss: 2.1704537868499756

Epoch: 6| Step: 10
Training loss: 1.5927915573120117
Validation loss: 2.125267664591471

Epoch: 6| Step: 11
Training loss: 1.832427740097046
Validation loss: 2.1369822223981223

Epoch: 6| Step: 12
Training loss: 1.2415504455566406
Validation loss: 2.173913757006327

Epoch: 6| Step: 13
Training loss: 1.664961576461792
Validation loss: 2.1610820094744363

Epoch: 317| Step: 0
Training loss: 1.683213710784912
Validation loss: 2.1622133453687034

Epoch: 6| Step: 1
Training loss: 1.0762749910354614
Validation loss: 2.19313907623291

Epoch: 6| Step: 2
Training loss: 0.8460955619812012
Validation loss: 2.1681009332338967

Epoch: 6| Step: 3
Training loss: 2.26530122756958
Validation loss: 2.1871795852979026

Epoch: 6| Step: 4
Training loss: 1.4266417026519775
Validation loss: 2.183454076449076

Epoch: 6| Step: 5
Training loss: 1.1620243787765503
Validation loss: 2.2094893058141074

Epoch: 6| Step: 6
Training loss: 1.8681306838989258
Validation loss: 2.181480626265208

Epoch: 6| Step: 7
Training loss: 1.45393967628479
Validation loss: 2.196682572364807

Epoch: 6| Step: 8
Training loss: 1.6421639919281006
Validation loss: 2.204713463783264

Epoch: 6| Step: 9
Training loss: 1.5205636024475098
Validation loss: 2.19409441947937

Epoch: 6| Step: 10
Training loss: 1.1606000661849976
Validation loss: 2.2013289531071982

Epoch: 6| Step: 11
Training loss: 1.4798907041549683
Validation loss: 2.166915992895762

Epoch: 6| Step: 12
Training loss: 2.0792455673217773
Validation loss: 2.151983380317688

Epoch: 6| Step: 13
Training loss: 1.4206082820892334
Validation loss: 2.1718128323554993

Epoch: 318| Step: 0
Training loss: 1.4681346416473389
Validation loss: 2.1476701696713767

Epoch: 6| Step: 1
Training loss: 1.736526370048523
Validation loss: 2.150718410809835

Epoch: 6| Step: 2
Training loss: 1.7000532150268555
Validation loss: 2.1873417297999063

Epoch: 6| Step: 3
Training loss: 1.7634453773498535
Validation loss: 2.20096488793691

Epoch: 6| Step: 4
Training loss: 1.354698896408081
Validation loss: 2.1956477959950766

Epoch: 6| Step: 5
Training loss: 1.3556448221206665
Validation loss: 2.1825961470603943

Epoch: 6| Step: 6
Training loss: 1.986884355545044
Validation loss: 2.2067532936731973

Epoch: 6| Step: 7
Training loss: 2.0287249088287354
Validation loss: 2.1828529834747314

Epoch: 6| Step: 8
Training loss: 1.3326666355133057
Validation loss: 2.192727824052175

Epoch: 6| Step: 9
Training loss: 1.218308448791504
Validation loss: 2.204909384250641

Epoch: 6| Step: 10
Training loss: 1.476436734199524
Validation loss: 2.218949556350708

Epoch: 6| Step: 11
Training loss: 0.8087175488471985
Validation loss: 2.200269321600596

Epoch: 6| Step: 12
Training loss: 1.3746826648712158
Validation loss: 2.1903041203816733

Epoch: 6| Step: 13
Training loss: 1.3516759872436523
Validation loss: 2.215337634086609

Epoch: 319| Step: 0
Training loss: 1.160583734512329
Validation loss: 2.1959200302759805

Epoch: 6| Step: 1
Training loss: 1.93461012840271
Validation loss: 2.2324684262275696

Epoch: 6| Step: 2
Training loss: 1.2605395317077637
Validation loss: 2.190537472565969

Epoch: 6| Step: 3
Training loss: 1.3409056663513184
Validation loss: 2.1957878271738687

Epoch: 6| Step: 4
Training loss: 1.6342906951904297
Validation loss: 2.189407686392466

Epoch: 6| Step: 5
Training loss: 1.3475124835968018
Validation loss: 2.1745911637941995

Epoch: 6| Step: 6
Training loss: 1.4603235721588135
Validation loss: 2.169645448525747

Epoch: 6| Step: 7
Training loss: 2.199514865875244
Validation loss: 2.20696093638738

Epoch: 6| Step: 8
Training loss: 1.3187097311019897
Validation loss: 2.170509954293569

Epoch: 6| Step: 9
Training loss: 1.8074934482574463
Validation loss: 2.2113991578420005

Epoch: 6| Step: 10
Training loss: 1.255873680114746
Validation loss: 2.225031018257141

Epoch: 6| Step: 11
Training loss: 1.2808982133865356
Validation loss: 2.223165432612101

Epoch: 6| Step: 12
Training loss: 1.7199652194976807
Validation loss: 2.205574373404185

Epoch: 6| Step: 13
Training loss: 1.6440982818603516
Validation loss: 2.1922912995020547

Epoch: 320| Step: 0
Training loss: 1.886489987373352
Validation loss: 2.1889320413271585

Epoch: 6| Step: 1
Training loss: 1.0051051378250122
Validation loss: 2.211297412713369

Epoch: 6| Step: 2
Training loss: 1.7323648929595947
Validation loss: 2.1948217352231345

Epoch: 6| Step: 3
Training loss: 1.5321879386901855
Validation loss: 2.2000531752904258

Epoch: 6| Step: 4
Training loss: 1.4058387279510498
Validation loss: 2.22086501121521

Epoch: 6| Step: 5
Training loss: 1.4642494916915894
Validation loss: 2.1939671436945596

Epoch: 6| Step: 6
Training loss: 1.193289875984192
Validation loss: 2.239557981491089

Epoch: 6| Step: 7
Training loss: 2.042355537414551
Validation loss: 2.220200796922048

Epoch: 6| Step: 8
Training loss: 1.6160781383514404
Validation loss: 2.2063366174697876

Epoch: 6| Step: 9
Training loss: 1.0667022466659546
Validation loss: 2.206593712170919

Epoch: 6| Step: 10
Training loss: 1.582021713256836
Validation loss: 2.1849032243092856

Epoch: 6| Step: 11
Training loss: 1.9648257493972778
Validation loss: 2.2162556449572244

Epoch: 6| Step: 12
Training loss: 1.2305572032928467
Validation loss: 2.2318971355756125

Epoch: 6| Step: 13
Training loss: 0.6629713773727417
Validation loss: 2.2117070953051248

Epoch: 321| Step: 0
Training loss: 1.674971342086792
Validation loss: 2.1662174463272095

Epoch: 6| Step: 1
Training loss: 1.3052769899368286
Validation loss: 2.2186065514882407

Epoch: 6| Step: 2
Training loss: 0.950828492641449
Validation loss: 2.1744028329849243

Epoch: 6| Step: 3
Training loss: 1.5309785604476929
Validation loss: 2.211481432120005

Epoch: 6| Step: 4
Training loss: 1.4633381366729736
Validation loss: 2.194887359937032

Epoch: 6| Step: 5
Training loss: 1.1475112438201904
Validation loss: 2.1895002524058023

Epoch: 6| Step: 6
Training loss: 1.464771032333374
Validation loss: 2.151091913382212

Epoch: 6| Step: 7
Training loss: 0.9539926052093506
Validation loss: 2.1650249361991882

Epoch: 6| Step: 8
Training loss: 2.1698591709136963
Validation loss: 2.1522388656934104

Epoch: 6| Step: 9
Training loss: 1.2029407024383545
Validation loss: 2.139911691347758

Epoch: 6| Step: 10
Training loss: 1.2787816524505615
Validation loss: 2.1503146489461265

Epoch: 6| Step: 11
Training loss: 1.2633404731750488
Validation loss: 2.173258582750956

Epoch: 6| Step: 12
Training loss: 1.9742807149887085
Validation loss: 2.1572397152582803

Epoch: 6| Step: 13
Training loss: 1.4732086658477783
Validation loss: 2.15726375579834

Epoch: 322| Step: 0
Training loss: 1.5860004425048828
Validation loss: 2.182822863260905

Epoch: 6| Step: 1
Training loss: 0.9488986134529114
Validation loss: 2.142633080482483

Epoch: 6| Step: 2
Training loss: 1.2984755039215088
Validation loss: 2.1556686957677207

Epoch: 6| Step: 3
Training loss: 1.317684292793274
Validation loss: 2.117628355820974

Epoch: 6| Step: 4
Training loss: 1.8429715633392334
Validation loss: 2.1574968099594116

Epoch: 6| Step: 5
Training loss: 1.6826775074005127
Validation loss: 2.144475201765696

Epoch: 6| Step: 6
Training loss: 2.1462459564208984
Validation loss: 2.1444784800211587

Epoch: 6| Step: 7
Training loss: 1.4190824031829834
Validation loss: 2.1976446310679116

Epoch: 6| Step: 8
Training loss: 1.1840791702270508
Validation loss: 2.178251028060913

Epoch: 6| Step: 9
Training loss: 0.8846954107284546
Validation loss: 2.1391883889834085

Epoch: 6| Step: 10
Training loss: 1.5858209133148193
Validation loss: 2.1319857637087503

Epoch: 6| Step: 11
Training loss: 1.3114972114562988
Validation loss: 2.124407947063446

Epoch: 6| Step: 12
Training loss: 1.8343472480773926
Validation loss: 2.13661923011144

Epoch: 6| Step: 13
Training loss: 1.3605782985687256
Validation loss: 2.1695003310839334

Epoch: 323| Step: 0
Training loss: 2.1706995964050293
Validation loss: 2.1190057396888733

Epoch: 6| Step: 1
Training loss: 1.2553229331970215
Validation loss: 2.1577388842900596

Epoch: 6| Step: 2
Training loss: 1.5226962566375732
Validation loss: 2.1343125104904175

Epoch: 6| Step: 3
Training loss: 0.7969950437545776
Validation loss: 2.1275785764058432

Epoch: 6| Step: 4
Training loss: 0.9908791184425354
Validation loss: 2.1423530181248984

Epoch: 6| Step: 5
Training loss: 0.9421161413192749
Validation loss: 2.1191900968551636

Epoch: 6| Step: 6
Training loss: 0.6705857515335083
Validation loss: 2.1473576426506042

Epoch: 6| Step: 7
Training loss: 1.7766623497009277
Validation loss: 2.1313928167025247

Epoch: 6| Step: 8
Training loss: 2.0150258541107178
Validation loss: 2.1680633624394736

Epoch: 6| Step: 9
Training loss: 1.7418909072875977
Validation loss: 2.1436362067858377

Epoch: 6| Step: 10
Training loss: 1.1543530225753784
Validation loss: 2.1744526425997415

Epoch: 6| Step: 11
Training loss: 1.4271800518035889
Validation loss: 2.1646814346313477

Epoch: 6| Step: 12
Training loss: 1.8482739925384521
Validation loss: 2.141045113404592

Epoch: 6| Step: 13
Training loss: 1.1844347715377808
Validation loss: 2.1491964856783548

Epoch: 324| Step: 0
Training loss: 1.1768940687179565
Validation loss: 2.1980894406636557

Epoch: 6| Step: 1
Training loss: 1.179685354232788
Validation loss: 2.1724510987599692

Epoch: 6| Step: 2
Training loss: 1.9595152139663696
Validation loss: 2.2067018349965415

Epoch: 6| Step: 3
Training loss: 1.582007884979248
Validation loss: 2.1904016733169556

Epoch: 6| Step: 4
Training loss: 1.8232574462890625
Validation loss: 2.1944210529327393

Epoch: 6| Step: 5
Training loss: 1.8263431787490845
Validation loss: 2.174962282180786

Epoch: 6| Step: 6
Training loss: 1.4958364963531494
Validation loss: 2.189878841241201

Epoch: 6| Step: 7
Training loss: 1.2891331911087036
Validation loss: 2.1877658367156982

Epoch: 6| Step: 8
Training loss: 1.1005123853683472
Validation loss: 2.1851077477137246

Epoch: 6| Step: 9
Training loss: 0.9090090394020081
Validation loss: 2.197054624557495

Epoch: 6| Step: 10
Training loss: 1.8988523483276367
Validation loss: 2.2106118202209473

Epoch: 6| Step: 11
Training loss: 1.8983612060546875
Validation loss: 2.2138414780298867

Epoch: 6| Step: 12
Training loss: 1.3644083738327026
Validation loss: 2.1952833930651345

Epoch: 6| Step: 13
Training loss: 1.1368927955627441
Validation loss: 2.193999151388804

Epoch: 325| Step: 0
Training loss: 1.0422567129135132
Validation loss: 2.157412270704905

Epoch: 6| Step: 1
Training loss: 1.9128267765045166
Validation loss: 2.181091328461965

Epoch: 6| Step: 2
Training loss: 1.5135717391967773
Validation loss: 2.1579939126968384

Epoch: 6| Step: 3
Training loss: 1.9996037483215332
Validation loss: 2.1420910557111106

Epoch: 6| Step: 4
Training loss: 1.31549870967865
Validation loss: 2.134408930937449

Epoch: 6| Step: 5
Training loss: 1.496146559715271
Validation loss: 2.1325828234354653

Epoch: 6| Step: 6
Training loss: 1.6428449153900146
Validation loss: 2.0939979553222656

Epoch: 6| Step: 7
Training loss: 1.6899161338806152
Validation loss: 2.1015512148539224

Epoch: 6| Step: 8
Training loss: 1.7136032581329346
Validation loss: 2.0741748213768005

Epoch: 6| Step: 9
Training loss: 1.7022156715393066
Validation loss: 2.073936879634857

Epoch: 6| Step: 10
Training loss: 1.302293300628662
Validation loss: 2.0417447884877524

Epoch: 6| Step: 11
Training loss: 1.3361320495605469
Validation loss: 2.082013646761576

Epoch: 6| Step: 12
Training loss: 1.1650304794311523
Validation loss: 2.0597120920817056

Epoch: 6| Step: 13
Training loss: 1.6356141567230225
Validation loss: 2.101142187913259

Epoch: 326| Step: 0
Training loss: 0.836396336555481
Validation loss: 2.0678892731666565

Epoch: 6| Step: 1
Training loss: 1.037099003791809
Validation loss: 2.1110655466715493

Epoch: 6| Step: 2
Training loss: 1.6863412857055664
Validation loss: 2.141777197519938

Epoch: 6| Step: 3
Training loss: 1.634036660194397
Validation loss: 2.122612734635671

Epoch: 6| Step: 4
Training loss: 1.204321026802063
Validation loss: 2.1432724595069885

Epoch: 6| Step: 5
Training loss: 2.7271134853363037
Validation loss: 2.162010431289673

Epoch: 6| Step: 6
Training loss: 1.397270917892456
Validation loss: 2.1280774672826133

Epoch: 6| Step: 7
Training loss: 1.7517330646514893
Validation loss: 2.1319623589515686

Epoch: 6| Step: 8
Training loss: 1.32684326171875
Validation loss: 2.134254773457845

Epoch: 6| Step: 9
Training loss: 0.9731941223144531
Validation loss: 2.1495439410209656

Epoch: 6| Step: 10
Training loss: 1.5259202718734741
Validation loss: 2.1031179626782737

Epoch: 6| Step: 11
Training loss: 1.4438652992248535
Validation loss: 2.163624087969462

Epoch: 6| Step: 12
Training loss: 1.2631947994232178
Validation loss: 2.1889529824256897

Epoch: 6| Step: 13
Training loss: 1.2402387857437134
Validation loss: 2.226401229699453

Epoch: 327| Step: 0
Training loss: 1.6865715980529785
Validation loss: 2.2040483752886453

Epoch: 6| Step: 1
Training loss: 1.8266241550445557
Validation loss: 2.2138908902804055

Epoch: 6| Step: 2
Training loss: 1.2121448516845703
Validation loss: 2.246980349222819

Epoch: 6| Step: 3
Training loss: 1.0911717414855957
Validation loss: 2.2400965889294944

Epoch: 6| Step: 4
Training loss: 0.8242765665054321
Validation loss: 2.210910201072693

Epoch: 6| Step: 5
Training loss: 1.7824909687042236
Validation loss: 2.2077635526657104

Epoch: 6| Step: 6
Training loss: 1.0879685878753662
Validation loss: 2.194392502307892

Epoch: 6| Step: 7
Training loss: 1.1194267272949219
Validation loss: 2.2358148097991943

Epoch: 6| Step: 8
Training loss: 1.2655503749847412
Validation loss: 2.2285128235816956

Epoch: 6| Step: 9
Training loss: 1.1494226455688477
Validation loss: 2.2018588383992515

Epoch: 6| Step: 10
Training loss: 2.134605884552002
Validation loss: 2.2159034808476767

Epoch: 6| Step: 11
Training loss: 1.4680304527282715
Validation loss: 2.225755512714386

Epoch: 6| Step: 12
Training loss: 1.6075230836868286
Validation loss: 2.2499903440475464

Epoch: 6| Step: 13
Training loss: 1.5782785415649414
Validation loss: 2.2327847878138223

Epoch: 328| Step: 0
Training loss: 1.192880630493164
Validation loss: 2.2500179608662925

Epoch: 6| Step: 1
Training loss: 1.7289766073226929
Validation loss: 2.214261829853058

Epoch: 6| Step: 2
Training loss: 1.4740753173828125
Validation loss: 2.242586672306061

Epoch: 6| Step: 3
Training loss: 1.1807403564453125
Validation loss: 2.2464192509651184

Epoch: 6| Step: 4
Training loss: 1.3493741750717163
Validation loss: 2.245139161745707

Epoch: 6| Step: 5
Training loss: 1.346959114074707
Validation loss: 2.22786412636439

Epoch: 6| Step: 6
Training loss: 1.6094883680343628
Validation loss: 2.2312913139661155

Epoch: 6| Step: 7
Training loss: 1.035614013671875
Validation loss: 2.1733454863230386

Epoch: 6| Step: 8
Training loss: 1.735750675201416
Validation loss: 2.2088257471720376

Epoch: 6| Step: 9
Training loss: 1.673555612564087
Validation loss: 2.184319873650869

Epoch: 6| Step: 10
Training loss: 1.3534908294677734
Validation loss: 2.1966699957847595

Epoch: 6| Step: 11
Training loss: 1.4143497943878174
Validation loss: 2.1644063591957092

Epoch: 6| Step: 12
Training loss: 1.4960801601409912
Validation loss: 2.1570407152175903

Epoch: 6| Step: 13
Training loss: 1.1733592748641968
Validation loss: 2.1883835991223655

Epoch: 329| Step: 0
Training loss: 1.2714440822601318
Validation loss: 2.205267349878947

Epoch: 6| Step: 1
Training loss: 0.8970563411712646
Validation loss: 2.2306978503863015

Epoch: 6| Step: 2
Training loss: 2.1363444328308105
Validation loss: 2.1916173299153647

Epoch: 6| Step: 3
Training loss: 1.2717151641845703
Validation loss: 2.2006931702295938

Epoch: 6| Step: 4
Training loss: 0.8444234132766724
Validation loss: 2.216603696346283

Epoch: 6| Step: 5
Training loss: 1.4101585149765015
Validation loss: 2.1998406847318015

Epoch: 6| Step: 6
Training loss: 1.1099369525909424
Validation loss: 2.1697714726130166

Epoch: 6| Step: 7
Training loss: 1.1898186206817627
Validation loss: 2.1941625475883484

Epoch: 6| Step: 8
Training loss: 1.6886166334152222
Validation loss: 2.1879579226175943

Epoch: 6| Step: 9
Training loss: 1.1722867488861084
Validation loss: 2.177023927370707

Epoch: 6| Step: 10
Training loss: 1.6482014656066895
Validation loss: 2.1457330783208213

Epoch: 6| Step: 11
Training loss: 2.268733263015747
Validation loss: 2.153536836306254

Epoch: 6| Step: 12
Training loss: 1.4356067180633545
Validation loss: 2.130440612634023

Epoch: 6| Step: 13
Training loss: 1.0255415439605713
Validation loss: 2.155228396256765

Epoch: 330| Step: 0
Training loss: 1.4277311563491821
Validation loss: 2.122669041156769

Epoch: 6| Step: 1
Training loss: 1.5578792095184326
Validation loss: 2.1598185300827026

Epoch: 6| Step: 2
Training loss: 1.5819928646087646
Validation loss: 2.167611618836721

Epoch: 6| Step: 3
Training loss: 1.4514150619506836
Validation loss: 2.1786319812138877

Epoch: 6| Step: 4
Training loss: 1.3168683052062988
Validation loss: 2.1707559625307717

Epoch: 6| Step: 5
Training loss: 1.172037124633789
Validation loss: 2.144386569658915

Epoch: 6| Step: 6
Training loss: 1.6817539930343628
Validation loss: 2.173491656780243

Epoch: 6| Step: 7
Training loss: 1.1072344779968262
Validation loss: 2.154430945714315

Epoch: 6| Step: 8
Training loss: 2.097093105316162
Validation loss: 2.181126832962036

Epoch: 6| Step: 9
Training loss: 0.8681392669677734
Validation loss: 2.1827232837677

Epoch: 6| Step: 10
Training loss: 1.2336088418960571
Validation loss: 2.1896764834721885

Epoch: 6| Step: 11
Training loss: 0.883539080619812
Validation loss: 2.2193692127863565

Epoch: 6| Step: 12
Training loss: 1.0996562242507935
Validation loss: 2.195736308892568

Epoch: 6| Step: 13
Training loss: 2.3157472610473633
Validation loss: 2.199155787626902

Epoch: 331| Step: 0
Training loss: 1.3598181009292603
Validation loss: 2.2277921040852866

Epoch: 6| Step: 1
Training loss: 1.4055325984954834
Validation loss: 2.168469766775767

Epoch: 6| Step: 2
Training loss: 0.8204472064971924
Validation loss: 2.1904836893081665

Epoch: 6| Step: 3
Training loss: 0.9741741418838501
Validation loss: 2.181326905886332

Epoch: 6| Step: 4
Training loss: 1.2451608180999756
Validation loss: 2.1725445985794067

Epoch: 6| Step: 5
Training loss: 1.0798205137252808
Validation loss: 2.162324845790863

Epoch: 6| Step: 6
Training loss: 1.7005544900894165
Validation loss: 2.1992668509483337

Epoch: 6| Step: 7
Training loss: 1.1620373725891113
Validation loss: 2.165631870428721

Epoch: 6| Step: 8
Training loss: 1.575141429901123
Validation loss: 2.190828482309977

Epoch: 6| Step: 9
Training loss: 1.344504952430725
Validation loss: 2.181150754292806

Epoch: 6| Step: 10
Training loss: 2.295759916305542
Validation loss: 2.1657725969950357

Epoch: 6| Step: 11
Training loss: 0.9574272632598877
Validation loss: 2.1391990184783936

Epoch: 6| Step: 12
Training loss: 1.4613234996795654
Validation loss: 2.1400312582651773

Epoch: 6| Step: 13
Training loss: 1.483004093170166
Validation loss: 2.115009049574534

Epoch: 332| Step: 0
Training loss: 1.3077948093414307
Validation loss: 2.08458544810613

Epoch: 6| Step: 1
Training loss: 1.5022939443588257
Validation loss: 2.078996996084849

Epoch: 6| Step: 2
Training loss: 1.1691045761108398
Validation loss: 2.090676466623942

Epoch: 6| Step: 3
Training loss: 1.0630433559417725
Validation loss: 2.072013815244039

Epoch: 6| Step: 4
Training loss: 1.2706438302993774
Validation loss: 2.082288304964701

Epoch: 6| Step: 5
Training loss: 1.8290647268295288
Validation loss: 2.119149406750997

Epoch: 6| Step: 6
Training loss: 1.7293965816497803
Validation loss: 2.1587013403574624

Epoch: 6| Step: 7
Training loss: 1.5806530714035034
Validation loss: 2.1927099426587424

Epoch: 6| Step: 8
Training loss: 1.8143466711044312
Validation loss: 2.227522293726603

Epoch: 6| Step: 9
Training loss: 1.6342418193817139
Validation loss: 2.2168822487195334

Epoch: 6| Step: 10
Training loss: 2.340177536010742
Validation loss: 2.2091575463612876

Epoch: 6| Step: 11
Training loss: 1.3468215465545654
Validation loss: 2.1706559658050537

Epoch: 6| Step: 12
Training loss: 0.9535980224609375
Validation loss: 2.1273709535598755

Epoch: 6| Step: 13
Training loss: 0.9621264934539795
Validation loss: 2.0796557863553367

Epoch: 333| Step: 0
Training loss: 0.9594680070877075
Validation loss: 2.1298195521036782

Epoch: 6| Step: 1
Training loss: 1.9716830253601074
Validation loss: 2.133313298225403

Epoch: 6| Step: 2
Training loss: 1.9427292346954346
Validation loss: 2.0992989540100098

Epoch: 6| Step: 3
Training loss: 1.720908522605896
Validation loss: 2.1369891365369162

Epoch: 6| Step: 4
Training loss: 1.0885601043701172
Validation loss: 2.138674318790436

Epoch: 6| Step: 5
Training loss: 0.8528861999511719
Validation loss: 2.163323998451233

Epoch: 6| Step: 6
Training loss: 1.4950240850448608
Validation loss: 2.2301290035247803

Epoch: 6| Step: 7
Training loss: 1.6747685670852661
Validation loss: 2.2748067378997803

Epoch: 6| Step: 8
Training loss: 1.8327490091323853
Validation loss: 2.244565804799398

Epoch: 6| Step: 9
Training loss: 1.3855879306793213
Validation loss: 2.210236648718516

Epoch: 6| Step: 10
Training loss: 2.275719165802002
Validation loss: 2.224238872528076

Epoch: 6| Step: 11
Training loss: 1.5775789022445679
Validation loss: 2.2016167640686035

Epoch: 6| Step: 12
Training loss: 1.9470285177230835
Validation loss: 2.1951847473780313

Epoch: 6| Step: 13
Training loss: 1.4082837104797363
Validation loss: 2.125806530316671

Epoch: 334| Step: 0
Training loss: 1.0388848781585693
Validation loss: 2.1719200809796653

Epoch: 6| Step: 1
Training loss: 1.552081823348999
Validation loss: 2.174771507581075

Epoch: 6| Step: 2
Training loss: 1.2662084102630615
Validation loss: 2.1294177770614624

Epoch: 6| Step: 3
Training loss: 1.0554641485214233
Validation loss: 2.139848073323568

Epoch: 6| Step: 4
Training loss: 1.88856840133667
Validation loss: 2.216593623161316

Epoch: 6| Step: 5
Training loss: 0.8300796151161194
Validation loss: 2.1973637342453003

Epoch: 6| Step: 6
Training loss: 1.7407464981079102
Validation loss: 2.2232512831687927

Epoch: 6| Step: 7
Training loss: 0.9753655195236206
Validation loss: 2.205362876256307

Epoch: 6| Step: 8
Training loss: 1.5400805473327637
Validation loss: 2.21601003408432

Epoch: 6| Step: 9
Training loss: 1.3632185459136963
Validation loss: 2.18357123931249

Epoch: 6| Step: 10
Training loss: 1.2195587158203125
Validation loss: 2.202662944793701

Epoch: 6| Step: 11
Training loss: 2.0979549884796143
Validation loss: 2.1723161737124124

Epoch: 6| Step: 12
Training loss: 1.311626672744751
Validation loss: 2.1810991565386453

Epoch: 6| Step: 13
Training loss: 0.9391562938690186
Validation loss: 2.2100184758504233

Epoch: 335| Step: 0
Training loss: 1.3678581714630127
Validation loss: 2.175445238749186

Epoch: 6| Step: 1
Training loss: 0.9622553586959839
Validation loss: 2.1757788260777793

Epoch: 6| Step: 2
Training loss: 0.7819375991821289
Validation loss: 2.1405957142512

Epoch: 6| Step: 3
Training loss: 1.35475492477417
Validation loss: 2.1759092211723328

Epoch: 6| Step: 4
Training loss: 1.8625538349151611
Validation loss: 2.147197107474009

Epoch: 6| Step: 5
Training loss: 1.0389716625213623
Validation loss: 2.1709486842155457

Epoch: 6| Step: 6
Training loss: 0.9677631855010986
Validation loss: 2.1710283557573953

Epoch: 6| Step: 7
Training loss: 1.7420110702514648
Validation loss: 2.214446564515432

Epoch: 6| Step: 8
Training loss: 1.0283986330032349
Validation loss: 2.20741597811381

Epoch: 6| Step: 9
Training loss: 1.283590316772461
Validation loss: 2.1832964619000754

Epoch: 6| Step: 10
Training loss: 1.4085845947265625
Validation loss: 2.1683775385220847

Epoch: 6| Step: 11
Training loss: 1.6674060821533203
Validation loss: 2.159909208615621

Epoch: 6| Step: 12
Training loss: 1.5296781063079834
Validation loss: 2.1543187697728476

Epoch: 6| Step: 13
Training loss: 1.9589924812316895
Validation loss: 2.0926337242126465

Epoch: 336| Step: 0
Training loss: 1.0593242645263672
Validation loss: 2.1693405508995056

Epoch: 6| Step: 1
Training loss: 1.5416903495788574
Validation loss: 2.154552936553955

Epoch: 6| Step: 2
Training loss: 1.9805806875228882
Validation loss: 2.1257553100585938

Epoch: 6| Step: 3
Training loss: 1.3351389169692993
Validation loss: 2.101207892100016

Epoch: 6| Step: 4
Training loss: 1.2472691535949707
Validation loss: 2.140020569165548

Epoch: 6| Step: 5
Training loss: 1.1844561100006104
Validation loss: 2.1225390434265137

Epoch: 6| Step: 6
Training loss: 0.9583677053451538
Validation loss: 2.1604297359784446

Epoch: 6| Step: 7
Training loss: 1.2955396175384521
Validation loss: 2.2078921794891357

Epoch: 6| Step: 8
Training loss: 2.0103962421417236
Validation loss: 2.2460556427637735

Epoch: 6| Step: 9
Training loss: 1.6932425498962402
Validation loss: 2.228610336780548

Epoch: 6| Step: 10
Training loss: 1.5550709962844849
Validation loss: 2.2208276987075806

Epoch: 6| Step: 11
Training loss: 1.595442771911621
Validation loss: 2.229234000047048

Epoch: 6| Step: 12
Training loss: 1.4072728157043457
Validation loss: 2.219857474168142

Epoch: 6| Step: 13
Training loss: 1.4277667999267578
Validation loss: 2.1645894646644592

Epoch: 337| Step: 0
Training loss: 1.309415578842163
Validation loss: 2.118446151415507

Epoch: 6| Step: 1
Training loss: 2.286848306655884
Validation loss: 2.0913986961046853

Epoch: 6| Step: 2
Training loss: 1.7782175540924072
Validation loss: 2.090595543384552

Epoch: 6| Step: 3
Training loss: 0.9934694766998291
Validation loss: 2.122055987517039

Epoch: 6| Step: 4
Training loss: 1.1620895862579346
Validation loss: 2.0754417975743613

Epoch: 6| Step: 5
Training loss: 1.6844065189361572
Validation loss: 2.118788262208303

Epoch: 6| Step: 6
Training loss: 1.6241905689239502
Validation loss: 2.148435056209564

Epoch: 6| Step: 7
Training loss: 2.1557326316833496
Validation loss: 2.156977355480194

Epoch: 6| Step: 8
Training loss: 0.9898316860198975
Validation loss: 2.199627419312795

Epoch: 6| Step: 9
Training loss: 0.8823997974395752
Validation loss: 2.176311989625295

Epoch: 6| Step: 10
Training loss: 1.040960431098938
Validation loss: 2.2385407288869223

Epoch: 6| Step: 11
Training loss: 1.2505418062210083
Validation loss: 2.2403228680292764

Epoch: 6| Step: 12
Training loss: 1.1606708765029907
Validation loss: 2.2417786717414856

Epoch: 6| Step: 13
Training loss: 1.5927493572235107
Validation loss: 2.1974013845125833

Epoch: 338| Step: 0
Training loss: 1.3534131050109863
Validation loss: 2.1975937485694885

Epoch: 6| Step: 1
Training loss: 1.1918706893920898
Validation loss: 2.2450705766677856

Epoch: 6| Step: 2
Training loss: 1.0746684074401855
Validation loss: 2.159144957860311

Epoch: 6| Step: 3
Training loss: 1.44905424118042
Validation loss: 2.1933460235595703

Epoch: 6| Step: 4
Training loss: 0.8854302763938904
Validation loss: 2.1930164893468223

Epoch: 6| Step: 5
Training loss: 1.178600549697876
Validation loss: 2.231307327747345

Epoch: 6| Step: 6
Training loss: 1.4197419881820679
Validation loss: 2.206547419230143

Epoch: 6| Step: 7
Training loss: 1.5080615282058716
Validation loss: 2.2247355779012046

Epoch: 6| Step: 8
Training loss: 0.8722041845321655
Validation loss: 2.224428335825602

Epoch: 6| Step: 9
Training loss: 2.1562247276306152
Validation loss: 2.200666924317678

Epoch: 6| Step: 10
Training loss: 1.6181563138961792
Validation loss: 2.2088345686594644

Epoch: 6| Step: 11
Training loss: 1.3880984783172607
Validation loss: 2.2058763901392617

Epoch: 6| Step: 12
Training loss: 1.4816778898239136
Validation loss: 2.1886142094930015

Epoch: 6| Step: 13
Training loss: 1.0488975048065186
Validation loss: 2.1460522214571633

Epoch: 339| Step: 0
Training loss: 1.328398585319519
Validation loss: 2.1934163570404053

Epoch: 6| Step: 1
Training loss: 0.779420018196106
Validation loss: 2.1619897882143655

Epoch: 6| Step: 2
Training loss: 0.7969844341278076
Validation loss: 2.1781076192855835

Epoch: 6| Step: 3
Training loss: 1.5043957233428955
Validation loss: 2.2493414878845215

Epoch: 6| Step: 4
Training loss: 1.2341587543487549
Validation loss: 2.1897175312042236

Epoch: 6| Step: 5
Training loss: 1.6439459323883057
Validation loss: 2.215557038784027

Epoch: 6| Step: 6
Training loss: 0.6561205387115479
Validation loss: 2.2005929549535117

Epoch: 6| Step: 7
Training loss: 1.819453477859497
Validation loss: 2.212358375390371

Epoch: 6| Step: 8
Training loss: 0.9866266250610352
Validation loss: 2.1592104037602744

Epoch: 6| Step: 9
Training loss: 1.19130277633667
Validation loss: 2.2059592803319297

Epoch: 6| Step: 10
Training loss: 1.4152132272720337
Validation loss: 2.140364388624827

Epoch: 6| Step: 11
Training loss: 1.906489610671997
Validation loss: 2.145281414190928

Epoch: 6| Step: 12
Training loss: 0.9551811814308167
Validation loss: 2.1330018639564514

Epoch: 6| Step: 13
Training loss: 2.0255095958709717
Validation loss: 2.150736411412557

Epoch: 340| Step: 0
Training loss: 1.417815923690796
Validation loss: 2.170352896054586

Epoch: 6| Step: 1
Training loss: 1.23404860496521
Validation loss: 2.1751820047696433

Epoch: 6| Step: 2
Training loss: 0.8196547031402588
Validation loss: 2.165135900179545

Epoch: 6| Step: 3
Training loss: 1.322400689125061
Validation loss: 2.1501428683598838

Epoch: 6| Step: 4
Training loss: 1.5302815437316895
Validation loss: 2.163963953653971

Epoch: 6| Step: 5
Training loss: 1.5346487760543823
Validation loss: 2.177208105723063

Epoch: 6| Step: 6
Training loss: 1.3962674140930176
Validation loss: 2.163896322250366

Epoch: 6| Step: 7
Training loss: 1.544726014137268
Validation loss: 2.210237701733907

Epoch: 6| Step: 8
Training loss: 1.2892512083053589
Validation loss: 2.1793166200319924

Epoch: 6| Step: 9
Training loss: 1.2421618700027466
Validation loss: 2.159446140130361

Epoch: 6| Step: 10
Training loss: 1.070683479309082
Validation loss: 2.1875388423601785

Epoch: 6| Step: 11
Training loss: 1.546332597732544
Validation loss: 2.1945209900538125

Epoch: 6| Step: 12
Training loss: 1.017162561416626
Validation loss: 2.2152825395266214

Epoch: 6| Step: 13
Training loss: 1.095435619354248
Validation loss: 2.1843807697296143

Epoch: 341| Step: 0
Training loss: 1.5066355466842651
Validation loss: 2.190408984820048

Epoch: 6| Step: 1
Training loss: 1.3500186204910278
Validation loss: 2.171113212903341

Epoch: 6| Step: 2
Training loss: 1.106967806816101
Validation loss: 2.1377204259236655

Epoch: 6| Step: 3
Training loss: 1.0056734085083008
Validation loss: 2.194966514905294

Epoch: 6| Step: 4
Training loss: 0.6544808745384216
Validation loss: 2.167525291442871

Epoch: 6| Step: 5
Training loss: 0.7661025524139404
Validation loss: 2.135458469390869

Epoch: 6| Step: 6
Training loss: 1.229820728302002
Validation loss: 2.161230683326721

Epoch: 6| Step: 7
Training loss: 0.8455789089202881
Validation loss: 2.1474637389183044

Epoch: 6| Step: 8
Training loss: 0.9187710881233215
Validation loss: 2.1500678658485413

Epoch: 6| Step: 9
Training loss: 1.6223416328430176
Validation loss: 2.1647926370302835

Epoch: 6| Step: 10
Training loss: 1.12143874168396
Validation loss: 2.1553781628608704

Epoch: 6| Step: 11
Training loss: 1.465134620666504
Validation loss: 2.1598257422447205

Epoch: 6| Step: 12
Training loss: 2.247420072555542
Validation loss: 2.211109240849813

Epoch: 6| Step: 13
Training loss: 2.1020212173461914
Validation loss: 2.181944410006205

Epoch: 342| Step: 0
Training loss: 1.370009422302246
Validation loss: 2.1491882602373757

Epoch: 6| Step: 1
Training loss: 2.2781362533569336
Validation loss: 2.1285990277926126

Epoch: 6| Step: 2
Training loss: 1.6641013622283936
Validation loss: 2.0954426725705466

Epoch: 6| Step: 3
Training loss: 0.7777799367904663
Validation loss: 2.105248669783274

Epoch: 6| Step: 4
Training loss: 2.035048007965088
Validation loss: 2.1045749386151633

Epoch: 6| Step: 5
Training loss: 0.9774136543273926
Validation loss: 2.1041597922643027

Epoch: 6| Step: 6
Training loss: 1.3314156532287598
Validation loss: 2.1530089179674783

Epoch: 6| Step: 7
Training loss: 0.8992574214935303
Validation loss: 2.153799374898275

Epoch: 6| Step: 8
Training loss: 1.239231824874878
Validation loss: 2.184744934240977

Epoch: 6| Step: 9
Training loss: 1.286031723022461
Validation loss: 2.218799869219462

Epoch: 6| Step: 10
Training loss: 1.0075641870498657
Validation loss: 2.2433173060417175

Epoch: 6| Step: 11
Training loss: 0.8576964139938354
Validation loss: 2.235502382119497

Epoch: 6| Step: 12
Training loss: 1.711950421333313
Validation loss: 2.1924238999684653

Epoch: 6| Step: 13
Training loss: 0.7614254355430603
Validation loss: 2.181664745012919

Epoch: 343| Step: 0
Training loss: 1.246840238571167
Validation loss: 2.1556832790374756

Epoch: 6| Step: 1
Training loss: 0.9074568748474121
Validation loss: 2.1591724157333374

Epoch: 6| Step: 2
Training loss: 1.3521702289581299
Validation loss: 2.1417219638824463

Epoch: 6| Step: 3
Training loss: 0.8937553763389587
Validation loss: 2.1476033528645835

Epoch: 6| Step: 4
Training loss: 1.2999073266983032
Validation loss: 2.1368320186932883

Epoch: 6| Step: 5
Training loss: 2.056985855102539
Validation loss: 2.154998481273651

Epoch: 6| Step: 6
Training loss: 1.3564486503601074
Validation loss: 2.1738645831743875

Epoch: 6| Step: 7
Training loss: 1.424865484237671
Validation loss: 2.1976720889409385

Epoch: 6| Step: 8
Training loss: 1.1791017055511475
Validation loss: 2.141522228717804

Epoch: 6| Step: 9
Training loss: 1.348686695098877
Validation loss: 2.2071458299954734

Epoch: 6| Step: 10
Training loss: 1.4274879693984985
Validation loss: 2.1557535529136658

Epoch: 6| Step: 11
Training loss: 1.2437987327575684
Validation loss: 2.152881145477295

Epoch: 6| Step: 12
Training loss: 0.8975977301597595
Validation loss: 2.1619659264882407

Epoch: 6| Step: 13
Training loss: 1.214113712310791
Validation loss: 2.1730273564656577

Epoch: 344| Step: 0
Training loss: 1.3603278398513794
Validation loss: 2.153431713581085

Epoch: 6| Step: 1
Training loss: 1.0652227401733398
Validation loss: 2.2203253904978433

Epoch: 6| Step: 2
Training loss: 1.7633867263793945
Validation loss: 2.1659096479415894

Epoch: 6| Step: 3
Training loss: 1.6792312860488892
Validation loss: 2.2068893114725747

Epoch: 6| Step: 4
Training loss: 1.5897892713546753
Validation loss: 2.193532566229502

Epoch: 6| Step: 5
Training loss: 1.250112771987915
Validation loss: 2.2114461064338684

Epoch: 6| Step: 6
Training loss: 1.9037528038024902
Validation loss: 2.1795989871025085

Epoch: 6| Step: 7
Training loss: 1.497422695159912
Validation loss: 2.210845708847046

Epoch: 6| Step: 8
Training loss: 1.0630996227264404
Validation loss: 2.197398324807485

Epoch: 6| Step: 9
Training loss: 0.7140982747077942
Validation loss: 2.220162649949392

Epoch: 6| Step: 10
Training loss: 0.753066897392273
Validation loss: 2.2065283258756003

Epoch: 6| Step: 11
Training loss: 1.3998794555664062
Validation loss: 2.195807933807373

Epoch: 6| Step: 12
Training loss: 0.9520201683044434
Validation loss: 2.2032674749692283

Epoch: 6| Step: 13
Training loss: 1.1603879928588867
Validation loss: 2.1864289045333862

Epoch: 345| Step: 0
Training loss: 1.1137311458587646
Validation loss: 2.2015696366628013

Epoch: 6| Step: 1
Training loss: 1.7863996028900146
Validation loss: 2.257470687230428

Epoch: 6| Step: 2
Training loss: 1.5214488506317139
Validation loss: 2.169279376665751

Epoch: 6| Step: 3
Training loss: 1.144914150238037
Validation loss: 2.229350765546163

Epoch: 6| Step: 4
Training loss: 1.7349355220794678
Validation loss: 2.2097368836402893

Epoch: 6| Step: 5
Training loss: 0.8423548340797424
Validation loss: 2.1895069678624473

Epoch: 6| Step: 6
Training loss: 0.884297251701355
Validation loss: 2.2290396889050803

Epoch: 6| Step: 7
Training loss: 1.0894577503204346
Validation loss: 2.2182259956995645

Epoch: 6| Step: 8
Training loss: 0.9763933420181274
Validation loss: 2.1651522318522134

Epoch: 6| Step: 9
Training loss: 1.5234203338623047
Validation loss: 2.1478015383084617

Epoch: 6| Step: 10
Training loss: 0.98032546043396
Validation loss: 2.106450080871582

Epoch: 6| Step: 11
Training loss: 1.4890761375427246
Validation loss: 2.1890937288602195

Epoch: 6| Step: 12
Training loss: 1.642836332321167
Validation loss: 2.1408780415852866

Epoch: 6| Step: 13
Training loss: 0.8882692456245422
Validation loss: 2.17660391330719

Epoch: 346| Step: 0
Training loss: 1.2649353742599487
Validation loss: 2.1973676681518555

Epoch: 6| Step: 1
Training loss: 1.243102788925171
Validation loss: 2.1842692494392395

Epoch: 6| Step: 2
Training loss: 2.326627254486084
Validation loss: 2.1671343644460044

Epoch: 6| Step: 3
Training loss: 1.291719913482666
Validation loss: 2.113024135430654

Epoch: 6| Step: 4
Training loss: 0.9326383471488953
Validation loss: 2.1711909770965576

Epoch: 6| Step: 5
Training loss: 0.9671728014945984
Validation loss: 2.133949796358744

Epoch: 6| Step: 6
Training loss: 1.306516408920288
Validation loss: 2.1213082869847617

Epoch: 6| Step: 7
Training loss: 1.5469954013824463
Validation loss: 2.1092361013094583

Epoch: 6| Step: 8
Training loss: 0.9800231456756592
Validation loss: 2.1405811309814453

Epoch: 6| Step: 9
Training loss: 1.191838026046753
Validation loss: 2.140968998273214

Epoch: 6| Step: 10
Training loss: 0.5716234445571899
Validation loss: 2.1868605613708496

Epoch: 6| Step: 11
Training loss: 1.2172636985778809
Validation loss: 2.215963045756022

Epoch: 6| Step: 12
Training loss: 1.6981589794158936
Validation loss: 2.1822293202082315

Epoch: 6| Step: 13
Training loss: 1.519402027130127
Validation loss: 2.1720808943112693

Epoch: 347| Step: 0
Training loss: 1.999308466911316
Validation loss: 2.130873123804728

Epoch: 6| Step: 1
Training loss: 1.1371750831604004
Validation loss: 2.149645984172821

Epoch: 6| Step: 2
Training loss: 0.7296046614646912
Validation loss: 2.175447106361389

Epoch: 6| Step: 3
Training loss: 1.3177385330200195
Validation loss: 2.1055055459340415

Epoch: 6| Step: 4
Training loss: 1.2217105627059937
Validation loss: 2.174833575884501

Epoch: 6| Step: 5
Training loss: 1.665855884552002
Validation loss: 2.1780839761098227

Epoch: 6| Step: 6
Training loss: 1.7669854164123535
Validation loss: 2.1930799881617227

Epoch: 6| Step: 7
Training loss: 1.6524567604064941
Validation loss: 2.2046439051628113

Epoch: 6| Step: 8
Training loss: 0.7626703977584839
Validation loss: 2.229878584543864

Epoch: 6| Step: 9
Training loss: 1.0532822608947754
Validation loss: 2.2009596029917398

Epoch: 6| Step: 10
Training loss: 1.011767864227295
Validation loss: 2.207623382409414

Epoch: 6| Step: 11
Training loss: 1.2234406471252441
Validation loss: 2.2054918805758157

Epoch: 6| Step: 12
Training loss: 1.2499955892562866
Validation loss: 2.2171071767807007

Epoch: 6| Step: 13
Training loss: 0.8330879807472229
Validation loss: 2.1782085299491882

Epoch: 348| Step: 0
Training loss: 1.39095139503479
Validation loss: 2.2425567905108132

Epoch: 6| Step: 1
Training loss: 1.321600317955017
Validation loss: 2.153866986433665

Epoch: 6| Step: 2
Training loss: 1.1645691394805908
Validation loss: 2.1671213507652283

Epoch: 6| Step: 3
Training loss: 0.9669247269630432
Validation loss: 2.12592875957489

Epoch: 6| Step: 4
Training loss: 1.8139355182647705
Validation loss: 2.1635355154673257

Epoch: 6| Step: 5
Training loss: 1.2922568321228027
Validation loss: 2.1645777821540833

Epoch: 6| Step: 6
Training loss: 0.9280626177787781
Validation loss: 2.181057890256246

Epoch: 6| Step: 7
Training loss: 0.8132564425468445
Validation loss: 2.1435564160346985

Epoch: 6| Step: 8
Training loss: 1.631505012512207
Validation loss: 2.1493794918060303

Epoch: 6| Step: 9
Training loss: 1.3083128929138184
Validation loss: 2.1299574971199036

Epoch: 6| Step: 10
Training loss: 1.0842779874801636
Validation loss: 2.186635375022888

Epoch: 6| Step: 11
Training loss: 1.944103717803955
Validation loss: 2.1061355471611023

Epoch: 6| Step: 12
Training loss: 0.8640586137771606
Validation loss: 2.1493939558664956

Epoch: 6| Step: 13
Training loss: 1.3197154998779297
Validation loss: 2.1398156682650247

Epoch: 349| Step: 0
Training loss: 1.1909124851226807
Validation loss: 2.1294134656588235

Epoch: 6| Step: 1
Training loss: 1.6468489170074463
Validation loss: 2.1140676538149514

Epoch: 6| Step: 2
Training loss: 1.2007602453231812
Validation loss: 2.14917520682017

Epoch: 6| Step: 3
Training loss: 1.6562981605529785
Validation loss: 2.1237322092056274

Epoch: 6| Step: 4
Training loss: 2.5299577713012695
Validation loss: 2.1450830896695456

Epoch: 6| Step: 5
Training loss: 1.188586950302124
Validation loss: 2.140056927998861

Epoch: 6| Step: 6
Training loss: 1.0750162601470947
Validation loss: 2.096543471018473

Epoch: 6| Step: 7
Training loss: 1.5033912658691406
Validation loss: 2.1392396092414856

Epoch: 6| Step: 8
Training loss: 1.0997581481933594
Validation loss: 2.161344289779663

Epoch: 6| Step: 9
Training loss: 0.7630380392074585
Validation loss: 2.1521976391474404

Epoch: 6| Step: 10
Training loss: 0.8071762919425964
Validation loss: 2.1519840359687805

Epoch: 6| Step: 11
Training loss: 0.8922608494758606
Validation loss: 2.149994452794393

Epoch: 6| Step: 12
Training loss: 1.5227363109588623
Validation loss: 2.2139548659324646

Epoch: 6| Step: 13
Training loss: 1.2459728717803955
Validation loss: 2.2182613611221313

Epoch: 350| Step: 0
Training loss: 1.3490684032440186
Validation loss: 2.2164361476898193

Epoch: 6| Step: 1
Training loss: 1.5858821868896484
Validation loss: 2.2381044228871665

Epoch: 6| Step: 2
Training loss: 1.9930779933929443
Validation loss: 2.230488419532776

Epoch: 6| Step: 3
Training loss: 0.9467560052871704
Validation loss: 2.1759758989016214

Epoch: 6| Step: 4
Training loss: 1.582945704460144
Validation loss: 2.152108073234558

Epoch: 6| Step: 5
Training loss: 0.8393126726150513
Validation loss: 2.1627118587493896

Epoch: 6| Step: 6
Training loss: 0.920632004737854
Validation loss: 2.1745607058207193

Epoch: 6| Step: 7
Training loss: 1.8041603565216064
Validation loss: 2.1454769174257913

Epoch: 6| Step: 8
Training loss: 1.9414572715759277
Validation loss: 2.1960707902908325

Epoch: 6| Step: 9
Training loss: 1.5600967407226562
Validation loss: 2.2141353686650596

Epoch: 6| Step: 10
Training loss: 0.9822282791137695
Validation loss: 2.166808068752289

Epoch: 6| Step: 11
Training loss: 1.212177038192749
Validation loss: 2.1712759931882224

Epoch: 6| Step: 12
Training loss: 1.4209699630737305
Validation loss: 2.193081537882487

Epoch: 6| Step: 13
Training loss: 1.2277323007583618
Validation loss: 2.2015691995620728

Epoch: 351| Step: 0
Training loss: 1.6573262214660645
Validation loss: 2.1926238735516868

Epoch: 6| Step: 1
Training loss: 1.5066876411437988
Validation loss: 2.2284292380015054

Epoch: 6| Step: 2
Training loss: 0.9260785579681396
Validation loss: 2.219311475753784

Epoch: 6| Step: 3
Training loss: 1.2633591890335083
Validation loss: 2.217200001080831

Epoch: 6| Step: 4
Training loss: 1.6111654043197632
Validation loss: 2.190110683441162

Epoch: 6| Step: 5
Training loss: 1.4613003730773926
Validation loss: 2.175144592920939

Epoch: 6| Step: 6
Training loss: 0.9352990388870239
Validation loss: 2.1771033803621926

Epoch: 6| Step: 7
Training loss: 1.201873779296875
Validation loss: 2.170837620894114

Epoch: 6| Step: 8
Training loss: 0.938285231590271
Validation loss: 2.1565313736597695

Epoch: 6| Step: 9
Training loss: 0.8300079107284546
Validation loss: 2.129640976587931

Epoch: 6| Step: 10
Training loss: 0.8483887910842896
Validation loss: 2.1157724459966025

Epoch: 6| Step: 11
Training loss: 1.1320748329162598
Validation loss: 2.137789249420166

Epoch: 6| Step: 12
Training loss: 1.0569853782653809
Validation loss: 2.167617360750834

Epoch: 6| Step: 13
Training loss: 2.2533063888549805
Validation loss: 2.14762290318807

Epoch: 352| Step: 0
Training loss: 1.2538927793502808
Validation loss: 2.153699199358622

Epoch: 6| Step: 1
Training loss: 1.0333077907562256
Validation loss: 2.186929762363434

Epoch: 6| Step: 2
Training loss: 1.8029087781906128
Validation loss: 2.2065006295839944

Epoch: 6| Step: 3
Training loss: 1.463694453239441
Validation loss: 2.2109176317850747

Epoch: 6| Step: 4
Training loss: 1.3209068775177002
Validation loss: 2.193709135055542

Epoch: 6| Step: 5
Training loss: 0.8575083017349243
Validation loss: 2.227157692114512

Epoch: 6| Step: 6
Training loss: 1.5341715812683105
Validation loss: 2.2084583838780723

Epoch: 6| Step: 7
Training loss: 0.6825564503669739
Validation loss: 2.1799877882003784

Epoch: 6| Step: 8
Training loss: 1.6738885641098022
Validation loss: 2.1497153441111245

Epoch: 6| Step: 9
Training loss: 1.2685848474502563
Validation loss: 2.166211704413096

Epoch: 6| Step: 10
Training loss: 1.3171279430389404
Validation loss: 2.148500839869181

Epoch: 6| Step: 11
Training loss: 0.9633574485778809
Validation loss: 2.2198785543441772

Epoch: 6| Step: 12
Training loss: 1.3383179903030396
Validation loss: 2.1491352121035256

Epoch: 6| Step: 13
Training loss: 1.5870938301086426
Validation loss: 2.124780833721161

Epoch: 353| Step: 0
Training loss: 1.2337011098861694
Validation loss: 2.1615609725316367

Epoch: 6| Step: 1
Training loss: 1.390610694885254
Validation loss: 2.22217059135437

Epoch: 6| Step: 2
Training loss: 2.4550940990448
Validation loss: 2.256651282310486

Epoch: 6| Step: 3
Training loss: 1.6357927322387695
Validation loss: 2.2525625824928284

Epoch: 6| Step: 4
Training loss: 1.4049632549285889
Validation loss: 2.253999869028727

Epoch: 6| Step: 5
Training loss: 1.868863821029663
Validation loss: 2.2452332377433777

Epoch: 6| Step: 6
Training loss: 0.8514111042022705
Validation loss: 2.1870691776275635

Epoch: 6| Step: 7
Training loss: 1.20133638381958
Validation loss: 2.1947256326675415

Epoch: 6| Step: 8
Training loss: 1.2040454149246216
Validation loss: 2.136546532313029

Epoch: 6| Step: 9
Training loss: 1.033510684967041
Validation loss: 2.1258075634638467

Epoch: 6| Step: 10
Training loss: 1.2848066091537476
Validation loss: 2.1158047715822854

Epoch: 6| Step: 11
Training loss: 0.7267296314239502
Validation loss: 2.10582172870636

Epoch: 6| Step: 12
Training loss: 0.7615213394165039
Validation loss: 2.0915889342625937

Epoch: 6| Step: 13
Training loss: 1.1013972759246826
Validation loss: 2.114762087663015

Epoch: 354| Step: 0
Training loss: 1.0817906856536865
Validation loss: 2.171174685160319

Epoch: 6| Step: 1
Training loss: 1.6550767421722412
Validation loss: 2.2454277078310647

Epoch: 6| Step: 2
Training loss: 0.8738336563110352
Validation loss: 2.1866812109947205

Epoch: 6| Step: 3
Training loss: 1.1124210357666016
Validation loss: 2.2612508138020835

Epoch: 6| Step: 4
Training loss: 1.1820094585418701
Validation loss: 2.2350462873776755

Epoch: 6| Step: 5
Training loss: 0.8138534426689148
Validation loss: 2.1910937229792276

Epoch: 6| Step: 6
Training loss: 0.8221569061279297
Validation loss: 2.1963005860646567

Epoch: 6| Step: 7
Training loss: 1.0189580917358398
Validation loss: 2.1953414479891458

Epoch: 6| Step: 8
Training loss: 0.9599245190620422
Validation loss: 2.1886642376581826

Epoch: 6| Step: 9
Training loss: 1.7914422750473022
Validation loss: 2.1818729043006897

Epoch: 6| Step: 10
Training loss: 1.1262595653533936
Validation loss: 2.1553320487340293

Epoch: 6| Step: 11
Training loss: 1.787172794342041
Validation loss: 2.19754829009374

Epoch: 6| Step: 12
Training loss: 1.1530869007110596
Validation loss: 2.1775179704030356

Epoch: 6| Step: 13
Training loss: 1.8128200769424438
Validation loss: 2.213804602622986

Epoch: 355| Step: 0
Training loss: 0.6810120344161987
Validation loss: 2.194209317366282

Epoch: 6| Step: 1
Training loss: 0.9799476861953735
Validation loss: 2.2021755377451577

Epoch: 6| Step: 2
Training loss: 0.703797459602356
Validation loss: 2.274677316347758

Epoch: 6| Step: 3
Training loss: 1.468915581703186
Validation loss: 2.245465616385142

Epoch: 6| Step: 4
Training loss: 1.2481610774993896
Validation loss: 2.242986718813578

Epoch: 6| Step: 5
Training loss: 0.9782090187072754
Validation loss: 2.259450316429138

Epoch: 6| Step: 6
Training loss: 0.869939923286438
Validation loss: 2.2198591430981955

Epoch: 6| Step: 7
Training loss: 1.8330016136169434
Validation loss: 2.1974584658940635

Epoch: 6| Step: 8
Training loss: 0.9880273938179016
Validation loss: 2.1965075731277466

Epoch: 6| Step: 9
Training loss: 1.132219672203064
Validation loss: 2.1348897218704224

Epoch: 6| Step: 10
Training loss: 1.6447185277938843
Validation loss: 2.128792643547058

Epoch: 6| Step: 11
Training loss: 1.0296580791473389
Validation loss: 2.1239720980326333

Epoch: 6| Step: 12
Training loss: 1.8012161254882812
Validation loss: 2.1884517669677734

Epoch: 6| Step: 13
Training loss: 1.6637237071990967
Validation loss: 2.119071980317434

Epoch: 356| Step: 0
Training loss: 1.7449500560760498
Validation loss: 2.1308199763298035

Epoch: 6| Step: 1
Training loss: 0.9425877928733826
Validation loss: 2.146186590194702

Epoch: 6| Step: 2
Training loss: 1.1983919143676758
Validation loss: 2.1589060624440513

Epoch: 6| Step: 3
Training loss: 1.2165560722351074
Validation loss: 2.2307928005854287

Epoch: 6| Step: 4
Training loss: 0.9790903925895691
Validation loss: 2.2034268776575723

Epoch: 6| Step: 5
Training loss: 1.6283056735992432
Validation loss: 2.260040561358134

Epoch: 6| Step: 6
Training loss: 1.1247010231018066
Validation loss: 2.1801902850468955

Epoch: 6| Step: 7
Training loss: 1.4287294149398804
Validation loss: 2.157568633556366

Epoch: 6| Step: 8
Training loss: 0.7230435609817505
Validation loss: 2.1369644602139792

Epoch: 6| Step: 9
Training loss: 1.3547985553741455
Validation loss: 2.1425698002179465

Epoch: 6| Step: 10
Training loss: 1.1166017055511475
Validation loss: 2.1727553804715476

Epoch: 6| Step: 11
Training loss: 0.7891872525215149
Validation loss: 2.179905911286672

Epoch: 6| Step: 12
Training loss: 1.8569968938827515
Validation loss: 2.1743414402008057

Epoch: 6| Step: 13
Training loss: 1.3120768070220947
Validation loss: 2.141463875770569

Epoch: 357| Step: 0
Training loss: 1.2214384078979492
Validation loss: 2.1380130847295127

Epoch: 6| Step: 1
Training loss: 1.3204578161239624
Validation loss: 2.1294339497884116

Epoch: 6| Step: 2
Training loss: 0.7696589231491089
Validation loss: 2.1225887537002563

Epoch: 6| Step: 3
Training loss: 1.1346800327301025
Validation loss: 2.153494874636332

Epoch: 6| Step: 4
Training loss: 1.1742510795593262
Validation loss: 2.1448143323262534

Epoch: 6| Step: 5
Training loss: 1.3743304014205933
Validation loss: 2.144522766272227

Epoch: 6| Step: 6
Training loss: 1.0279971361160278
Validation loss: 2.1030507485071817

Epoch: 6| Step: 7
Training loss: 1.4541430473327637
Validation loss: 2.121351718902588

Epoch: 6| Step: 8
Training loss: 1.333130955696106
Validation loss: 2.126835584640503

Epoch: 6| Step: 9
Training loss: 1.3066515922546387
Validation loss: 2.0706544319788613

Epoch: 6| Step: 10
Training loss: 1.1811532974243164
Validation loss: 2.1079933245976767

Epoch: 6| Step: 11
Training loss: 0.7413901090621948
Validation loss: 2.1290404001871743

Epoch: 6| Step: 12
Training loss: 0.7293596863746643
Validation loss: 2.156964341799418

Epoch: 6| Step: 13
Training loss: 1.724709153175354
Validation loss: 2.191922942797343

Epoch: 358| Step: 0
Training loss: 1.0293773412704468
Validation loss: 2.1471805572509766

Epoch: 6| Step: 1
Training loss: 0.9609041810035706
Validation loss: 2.155564268430074

Epoch: 6| Step: 2
Training loss: 1.0026905536651611
Validation loss: 2.1867221196492515

Epoch: 6| Step: 3
Training loss: 1.3797478675842285
Validation loss: 2.130269189675649

Epoch: 6| Step: 4
Training loss: 1.0259814262390137
Validation loss: 2.095889230569204

Epoch: 6| Step: 5
Training loss: 1.0726827383041382
Validation loss: 2.0982246001561484

Epoch: 6| Step: 6
Training loss: 1.2982409000396729
Validation loss: 2.080205261707306

Epoch: 6| Step: 7
Training loss: 1.1868782043457031
Validation loss: 2.0769110321998596

Epoch: 6| Step: 8
Training loss: 1.3664567470550537
Validation loss: 2.092746078968048

Epoch: 6| Step: 9
Training loss: 1.2390048503875732
Validation loss: 2.1181942224502563

Epoch: 6| Step: 10
Training loss: 1.1247063875198364
Validation loss: 2.2034783363342285

Epoch: 6| Step: 11
Training loss: 1.9483188390731812
Validation loss: 2.249727269013723

Epoch: 6| Step: 12
Training loss: 1.4029271602630615
Validation loss: 2.210962394873301

Epoch: 6| Step: 13
Training loss: 1.011880874633789
Validation loss: 2.196430246035258

Epoch: 359| Step: 0
Training loss: 1.5880857706069946
Validation loss: 2.1735124786694846

Epoch: 6| Step: 1
Training loss: 1.1098942756652832
Validation loss: 2.0991137822469077

Epoch: 6| Step: 2
Training loss: 1.4807486534118652
Validation loss: 2.068239370981852

Epoch: 6| Step: 3
Training loss: 1.3059258460998535
Validation loss: 2.115260442097982

Epoch: 6| Step: 4
Training loss: 0.8266700506210327
Validation loss: 2.1140973965326944

Epoch: 6| Step: 5
Training loss: 1.0055675506591797
Validation loss: 2.0736809571584067

Epoch: 6| Step: 6
Training loss: 1.314814805984497
Validation loss: 2.0706366896629333

Epoch: 6| Step: 7
Training loss: 1.0477136373519897
Validation loss: 2.105382780234019

Epoch: 6| Step: 8
Training loss: 1.4576349258422852
Validation loss: 2.0993340412775674

Epoch: 6| Step: 9
Training loss: 1.6196331977844238
Validation loss: 2.1129310528437295

Epoch: 6| Step: 10
Training loss: 0.8215738534927368
Validation loss: 2.119825839996338

Epoch: 6| Step: 11
Training loss: 0.7906237840652466
Validation loss: 2.125264286994934

Epoch: 6| Step: 12
Training loss: 1.5478843450546265
Validation loss: 2.0969709157943726

Epoch: 6| Step: 13
Training loss: 0.9462099075317383
Validation loss: 2.0818020900090537

Epoch: 360| Step: 0
Training loss: 0.9688361883163452
Validation loss: 2.0597116947174072

Epoch: 6| Step: 1
Training loss: 1.5118966102600098
Validation loss: 2.0795243978500366

Epoch: 6| Step: 2
Training loss: 1.885264277458191
Validation loss: 2.081523060798645

Epoch: 6| Step: 3
Training loss: 0.668817400932312
Validation loss: 2.0837614138921103

Epoch: 6| Step: 4
Training loss: 0.8237128853797913
Validation loss: 2.095164875189463

Epoch: 6| Step: 5
Training loss: 0.891674280166626
Validation loss: 2.0392170349756875

Epoch: 6| Step: 6
Training loss: 1.5867024660110474
Validation loss: 2.1023770570755005

Epoch: 6| Step: 7
Training loss: 1.1576478481292725
Validation loss: 2.0935435692469277

Epoch: 6| Step: 8
Training loss: 1.4807326793670654
Validation loss: 2.102554976940155

Epoch: 6| Step: 9
Training loss: 0.7315747737884521
Validation loss: 2.1416096289952598

Epoch: 6| Step: 10
Training loss: 1.29469895362854
Validation loss: 2.1625800728797913

Epoch: 6| Step: 11
Training loss: 0.8218376636505127
Validation loss: 2.149679124355316

Epoch: 6| Step: 12
Training loss: 0.8920772075653076
Validation loss: 2.1347941160202026

Epoch: 6| Step: 13
Training loss: 1.2913707494735718
Validation loss: 2.050536890824636

Epoch: 361| Step: 0
Training loss: 0.7859396934509277
Validation loss: 2.044303774833679

Epoch: 6| Step: 1
Training loss: 1.1161376237869263
Validation loss: 2.1042355497678122

Epoch: 6| Step: 2
Training loss: 1.0190324783325195
Validation loss: 2.079250395298004

Epoch: 6| Step: 3
Training loss: 1.0221506357192993
Validation loss: 2.137159844239553

Epoch: 6| Step: 4
Training loss: 1.3461849689483643
Validation loss: 2.1017762223879495

Epoch: 6| Step: 5
Training loss: 1.3376739025115967
Validation loss: 2.134878178437551

Epoch: 6| Step: 6
Training loss: 0.9574884176254272
Validation loss: 2.1524064540863037

Epoch: 6| Step: 7
Training loss: 0.7355006337165833
Validation loss: 2.1510863304138184

Epoch: 6| Step: 8
Training loss: 1.910905122756958
Validation loss: 2.1790075103441873

Epoch: 6| Step: 9
Training loss: 1.066847324371338
Validation loss: 2.039822260538737

Epoch: 6| Step: 10
Training loss: 2.146757125854492
Validation loss: 2.0811575651168823

Epoch: 6| Step: 11
Training loss: 1.4843555688858032
Validation loss: 2.122670352458954

Epoch: 6| Step: 12
Training loss: 1.0543804168701172
Validation loss: 2.127354462941488

Epoch: 6| Step: 13
Training loss: 0.8863223195075989
Validation loss: 2.115382512410482

Epoch: 362| Step: 0
Training loss: 1.167715072631836
Validation loss: 2.0863115588823953

Epoch: 6| Step: 1
Training loss: 1.377759337425232
Validation loss: 2.1190436681111655

Epoch: 6| Step: 2
Training loss: 0.7001338601112366
Validation loss: 2.1943994760513306

Epoch: 6| Step: 3
Training loss: 1.4803709983825684
Validation loss: 2.2259878714879355

Epoch: 6| Step: 4
Training loss: 1.039023756980896
Validation loss: 2.219613234202067

Epoch: 6| Step: 5
Training loss: 1.367363452911377
Validation loss: 2.2082439064979553

Epoch: 6| Step: 6
Training loss: 1.4818792343139648
Validation loss: 2.194634954134623

Epoch: 6| Step: 7
Training loss: 0.6904065012931824
Validation loss: 2.156376282374064

Epoch: 6| Step: 8
Training loss: 1.025998830795288
Validation loss: 2.1343687375386557

Epoch: 6| Step: 9
Training loss: 1.2321529388427734
Validation loss: 2.1075587471326194

Epoch: 6| Step: 10
Training loss: 1.0525273084640503
Validation loss: 2.090586225191752

Epoch: 6| Step: 11
Training loss: 1.8204206228256226
Validation loss: 2.075248956680298

Epoch: 6| Step: 12
Training loss: 1.4236392974853516
Validation loss: 2.0842588941256204

Epoch: 6| Step: 13
Training loss: 1.5177836418151855
Validation loss: 2.1706106464068093

Epoch: 363| Step: 0
Training loss: 1.3297972679138184
Validation loss: 2.1347169280052185

Epoch: 6| Step: 1
Training loss: 0.8254762291908264
Validation loss: 2.0599663456281028

Epoch: 6| Step: 2
Training loss: 1.5353797674179077
Validation loss: 2.177283445994059

Epoch: 6| Step: 3
Training loss: 1.268193006515503
Validation loss: 2.201827108860016

Epoch: 6| Step: 4
Training loss: 1.0788825750350952
Validation loss: 2.2150001525878906

Epoch: 6| Step: 5
Training loss: 1.5246431827545166
Validation loss: 2.2236880461374917

Epoch: 6| Step: 6
Training loss: 1.2912952899932861
Validation loss: 2.262892762819926

Epoch: 6| Step: 7
Training loss: 0.8492708206176758
Validation loss: 2.2209636569023132

Epoch: 6| Step: 8
Training loss: 1.4427767992019653
Validation loss: 2.168147643407186

Epoch: 6| Step: 9
Training loss: 0.9693446755409241
Validation loss: 2.157894790172577

Epoch: 6| Step: 10
Training loss: 1.262104868888855
Validation loss: 2.1343977053960166

Epoch: 6| Step: 11
Training loss: 1.417524814605713
Validation loss: 2.1701457500457764

Epoch: 6| Step: 12
Training loss: 1.8099204301834106
Validation loss: 2.2216564615567527

Epoch: 6| Step: 13
Training loss: 0.9691029787063599
Validation loss: 2.2309804558753967

Epoch: 364| Step: 0
Training loss: 1.8060039281845093
Validation loss: 2.255495766798655

Epoch: 6| Step: 1
Training loss: 1.1123957633972168
Validation loss: 2.226322034994761

Epoch: 6| Step: 2
Training loss: 0.9662766456604004
Validation loss: 2.2562981049219766

Epoch: 6| Step: 3
Training loss: 1.6866313219070435
Validation loss: 2.2783068815867105

Epoch: 6| Step: 4
Training loss: 1.990538239479065
Validation loss: 2.2670650680859885

Epoch: 6| Step: 5
Training loss: 0.7655795812606812
Validation loss: 2.224220077196757

Epoch: 6| Step: 6
Training loss: 0.9198998212814331
Validation loss: 2.1946470936139426

Epoch: 6| Step: 7
Training loss: 1.4452992677688599
Validation loss: 2.228101213773092

Epoch: 6| Step: 8
Training loss: 1.233569860458374
Validation loss: 2.202579359213511

Epoch: 6| Step: 9
Training loss: 1.400390386581421
Validation loss: 2.1510184605916343

Epoch: 6| Step: 10
Training loss: 1.1613565683364868
Validation loss: 2.135921537876129

Epoch: 6| Step: 11
Training loss: 1.181592583656311
Validation loss: 2.151718537012736

Epoch: 6| Step: 12
Training loss: 1.240471363067627
Validation loss: 2.121990442276001

Epoch: 6| Step: 13
Training loss: 0.7967165112495422
Validation loss: 2.157824714978536

Epoch: 365| Step: 0
Training loss: 0.5523271560668945
Validation loss: 2.160531143347422

Epoch: 6| Step: 1
Training loss: 0.9445842504501343
Validation loss: 2.196904102961222

Epoch: 6| Step: 2
Training loss: 0.8583701848983765
Validation loss: 2.1353461941083274

Epoch: 6| Step: 3
Training loss: 1.8260715007781982
Validation loss: 2.187118331591288

Epoch: 6| Step: 4
Training loss: 1.1099141836166382
Validation loss: 2.129832704861959

Epoch: 6| Step: 5
Training loss: 1.2165201902389526
Validation loss: 2.1270993749300637

Epoch: 6| Step: 6
Training loss: 1.4522737264633179
Validation loss: 2.1265362898508706

Epoch: 6| Step: 7
Training loss: 1.0815213918685913
Validation loss: 2.1223153471946716

Epoch: 6| Step: 8
Training loss: 1.055538535118103
Validation loss: 2.116148054599762

Epoch: 6| Step: 9
Training loss: 1.086127758026123
Validation loss: 2.1471052169799805

Epoch: 6| Step: 10
Training loss: 1.7607638835906982
Validation loss: 2.1939836740493774

Epoch: 6| Step: 11
Training loss: 1.3249419927597046
Validation loss: 2.195075035095215

Epoch: 6| Step: 12
Training loss: 0.9825754761695862
Validation loss: 2.171827812989553

Epoch: 6| Step: 13
Training loss: 0.81913161277771
Validation loss: 2.164363066355387

Epoch: 366| Step: 0
Training loss: 1.5447592735290527
Validation loss: 2.203432043393453

Epoch: 6| Step: 1
Training loss: 0.42298370599746704
Validation loss: 2.1647945245107016

Epoch: 6| Step: 2
Training loss: 1.1032687425613403
Validation loss: 2.1755322217941284

Epoch: 6| Step: 3
Training loss: 1.455549955368042
Validation loss: 2.1802645921707153

Epoch: 6| Step: 4
Training loss: 0.9146628379821777
Validation loss: 2.225131889184316

Epoch: 6| Step: 5
Training loss: 1.1693460941314697
Validation loss: 2.246331214904785

Epoch: 6| Step: 6
Training loss: 2.0469789505004883
Validation loss: 2.171175539493561

Epoch: 6| Step: 7
Training loss: 0.7885096669197083
Validation loss: 2.251023014386495

Epoch: 6| Step: 8
Training loss: 1.2418606281280518
Validation loss: 2.263434727986654

Epoch: 6| Step: 9
Training loss: 0.8724761009216309
Validation loss: 2.210468610127767

Epoch: 6| Step: 10
Training loss: 0.7807386517524719
Validation loss: 2.195510228474935

Epoch: 6| Step: 11
Training loss: 0.8096880912780762
Validation loss: 2.16263610124588

Epoch: 6| Step: 12
Training loss: 1.1685466766357422
Validation loss: 2.161482294400533

Epoch: 6| Step: 13
Training loss: 1.3962996006011963
Validation loss: 2.181465486685435

Epoch: 367| Step: 0
Training loss: 0.8408908843994141
Validation loss: 2.196540574232737

Epoch: 6| Step: 1
Training loss: 1.238507866859436
Validation loss: 2.1461392839749656

Epoch: 6| Step: 2
Training loss: 1.1983654499053955
Validation loss: 2.2339604695638022

Epoch: 6| Step: 3
Training loss: 1.4327011108398438
Validation loss: 2.146205504735311

Epoch: 6| Step: 4
Training loss: 0.628476083278656
Validation loss: 2.1674864490826926

Epoch: 6| Step: 5
Training loss: 0.42888253927230835
Validation loss: 2.143061856428782

Epoch: 6| Step: 6
Training loss: 1.7646814584732056
Validation loss: 2.1619787216186523

Epoch: 6| Step: 7
Training loss: 1.3697764873504639
Validation loss: 2.179404854774475

Epoch: 6| Step: 8
Training loss: 0.7897670269012451
Validation loss: 2.164231797059377

Epoch: 6| Step: 9
Training loss: 1.5695500373840332
Validation loss: 2.1657989422480264

Epoch: 6| Step: 10
Training loss: 1.2263174057006836
Validation loss: 2.151843011379242

Epoch: 6| Step: 11
Training loss: 0.9408149123191833
Validation loss: 2.150623639424642

Epoch: 6| Step: 12
Training loss: 0.7742949724197388
Validation loss: 2.114166339238485

Epoch: 6| Step: 13
Training loss: 1.3473849296569824
Validation loss: 2.069673220316569

Epoch: 368| Step: 0
Training loss: 0.623365044593811
Validation loss: 2.0689454873402915

Epoch: 6| Step: 1
Training loss: 1.1235926151275635
Validation loss: 2.1026835242907205

Epoch: 6| Step: 2
Training loss: 1.1223779916763306
Validation loss: 2.126945654551188

Epoch: 6| Step: 3
Training loss: 1.445712685585022
Validation loss: 2.1496653159459433

Epoch: 6| Step: 4
Training loss: 1.6357581615447998
Validation loss: 2.1235975424448648

Epoch: 6| Step: 5
Training loss: 1.2604485750198364
Validation loss: 2.1411739389101663

Epoch: 6| Step: 6
Training loss: 1.2459425926208496
Validation loss: 2.103087226549784

Epoch: 6| Step: 7
Training loss: 0.793287456035614
Validation loss: 2.1199225187301636

Epoch: 6| Step: 8
Training loss: 0.8786238431930542
Validation loss: 2.163200298945109

Epoch: 6| Step: 9
Training loss: 1.5365369319915771
Validation loss: 2.117115636666616

Epoch: 6| Step: 10
Training loss: 1.2415452003479004
Validation loss: 2.128454546133677

Epoch: 6| Step: 11
Training loss: 0.6594560742378235
Validation loss: 2.1722509264945984

Epoch: 6| Step: 12
Training loss: 1.2288480997085571
Validation loss: 2.1559760371843972

Epoch: 6| Step: 13
Training loss: 1.391547679901123
Validation loss: 2.1431813836097717

Epoch: 369| Step: 0
Training loss: 1.1831358671188354
Validation loss: 2.092771748701731

Epoch: 6| Step: 1
Training loss: 0.8011163473129272
Validation loss: 2.108884116013845

Epoch: 6| Step: 2
Training loss: 1.5492302179336548
Validation loss: 2.1790589690208435

Epoch: 6| Step: 3
Training loss: 0.8999605178833008
Validation loss: 2.141739785671234

Epoch: 6| Step: 4
Training loss: 0.9425106048583984
Validation loss: 2.1811969677607217

Epoch: 6| Step: 5
Training loss: 0.9001448154449463
Validation loss: 2.1572006940841675

Epoch: 6| Step: 6
Training loss: 0.9045465588569641
Validation loss: 2.1694746216138205

Epoch: 6| Step: 7
Training loss: 0.7143781185150146
Validation loss: 2.170953710873922

Epoch: 6| Step: 8
Training loss: 0.9192023277282715
Validation loss: 2.143679658571879

Epoch: 6| Step: 9
Training loss: 1.2971794605255127
Validation loss: 2.177870988845825

Epoch: 6| Step: 10
Training loss: 1.4572339057922363
Validation loss: 2.1587897340456643

Epoch: 6| Step: 11
Training loss: 1.4046669006347656
Validation loss: 2.225704630215963

Epoch: 6| Step: 12
Training loss: 1.0676569938659668
Validation loss: 2.1236663659413657

Epoch: 6| Step: 13
Training loss: 1.6829156875610352
Validation loss: 2.216386596361796

Epoch: 370| Step: 0
Training loss: 0.7294591665267944
Validation loss: 2.19462513923645

Epoch: 6| Step: 1
Training loss: 1.516175389289856
Validation loss: 2.1597845355669656

Epoch: 6| Step: 2
Training loss: 0.975166380405426
Validation loss: 2.1878233353296914

Epoch: 6| Step: 3
Training loss: 0.9843193292617798
Validation loss: 2.237963835398356

Epoch: 6| Step: 4
Training loss: 1.1039793491363525
Validation loss: 2.1781344413757324

Epoch: 6| Step: 5
Training loss: 0.7859868407249451
Validation loss: 2.2094987630844116

Epoch: 6| Step: 6
Training loss: 0.8417589664459229
Validation loss: 2.129419763882955

Epoch: 6| Step: 7
Training loss: 0.6319087743759155
Validation loss: 2.186400512854258

Epoch: 6| Step: 8
Training loss: 1.398605227470398
Validation loss: 2.202755550543467

Epoch: 6| Step: 9
Training loss: 2.308490753173828
Validation loss: 2.2251808643341064

Epoch: 6| Step: 10
Training loss: 0.44983699917793274
Validation loss: 2.167256693045298

Epoch: 6| Step: 11
Training loss: 1.1994074583053589
Validation loss: 2.1803106466929116

Epoch: 6| Step: 12
Training loss: 1.0686166286468506
Validation loss: 2.1787710984547934

Epoch: 6| Step: 13
Training loss: 1.079977035522461
Validation loss: 2.1348988016446433

Epoch: 371| Step: 0
Training loss: 0.7280588150024414
Validation loss: 2.160906513532003

Epoch: 6| Step: 1
Training loss: 2.1942577362060547
Validation loss: 2.123498578866323

Epoch: 6| Step: 2
Training loss: 0.9497328400611877
Validation loss: 2.106361746788025

Epoch: 6| Step: 3
Training loss: 1.204969882965088
Validation loss: 2.132983982563019

Epoch: 6| Step: 4
Training loss: 0.609830915927887
Validation loss: 2.1732324163118997

Epoch: 6| Step: 5
Training loss: 1.5209269523620605
Validation loss: 2.1738007267316184

Epoch: 6| Step: 6
Training loss: 1.2011936902999878
Validation loss: 2.2483898599942527

Epoch: 6| Step: 7
Training loss: 1.0608364343643188
Validation loss: 2.2164807518323264

Epoch: 6| Step: 8
Training loss: 1.1505414247512817
Validation loss: 2.2575324376424155

Epoch: 6| Step: 9
Training loss: 1.4397865533828735
Validation loss: 2.22884472211202

Epoch: 6| Step: 10
Training loss: 1.5071086883544922
Validation loss: 2.1771342158317566

Epoch: 6| Step: 11
Training loss: 0.7405569553375244
Validation loss: 2.1685744524002075

Epoch: 6| Step: 12
Training loss: 1.1398851871490479
Validation loss: 2.1049831310908

Epoch: 6| Step: 13
Training loss: 1.6732501983642578
Validation loss: 2.1855760415395102

Epoch: 372| Step: 0
Training loss: 1.2527552843093872
Validation loss: 2.1734610199928284

Epoch: 6| Step: 1
Training loss: 1.122821569442749
Validation loss: 2.1597649653752646

Epoch: 6| Step: 2
Training loss: 1.574552059173584
Validation loss: 2.0892360607783

Epoch: 6| Step: 3
Training loss: 1.171794056892395
Validation loss: 2.1315191984176636

Epoch: 6| Step: 4
Training loss: 0.5481612086296082
Validation loss: 2.115641395250956

Epoch: 6| Step: 5
Training loss: 1.3910624980926514
Validation loss: 2.1471857031186423

Epoch: 6| Step: 6
Training loss: 1.2092742919921875
Validation loss: 2.187682489554087

Epoch: 6| Step: 7
Training loss: 1.798248529434204
Validation loss: 2.2107694149017334

Epoch: 6| Step: 8
Training loss: 1.5318138599395752
Validation loss: 2.2194650173187256

Epoch: 6| Step: 9
Training loss: 1.1276265382766724
Validation loss: 2.1676522493362427

Epoch: 6| Step: 10
Training loss: 1.1988855600357056
Validation loss: 2.1643012166023254

Epoch: 6| Step: 11
Training loss: 0.9009671807289124
Validation loss: 2.1110111276308694

Epoch: 6| Step: 12
Training loss: 1.184951901435852
Validation loss: 2.1275859673817954

Epoch: 6| Step: 13
Training loss: 1.0043045282363892
Validation loss: 2.059421102205912

Epoch: 373| Step: 0
Training loss: 0.7766207456588745
Validation loss: 2.121959149837494

Epoch: 6| Step: 1
Training loss: 1.8647799491882324
Validation loss: 2.1062128941218057

Epoch: 6| Step: 2
Training loss: 1.0041276216506958
Validation loss: 2.107919931411743

Epoch: 6| Step: 3
Training loss: 0.7123611569404602
Validation loss: 2.1346572240193686

Epoch: 6| Step: 4
Training loss: 0.7234246730804443
Validation loss: 2.1298541824022927

Epoch: 6| Step: 5
Training loss: 1.124521255493164
Validation loss: 2.1587521036465964

Epoch: 6| Step: 6
Training loss: 1.2949182987213135
Validation loss: 2.1427807211875916

Epoch: 6| Step: 7
Training loss: 0.7816510796546936
Validation loss: 2.148653527100881

Epoch: 6| Step: 8
Training loss: 1.3360352516174316
Validation loss: 2.1171034574508667

Epoch: 6| Step: 9
Training loss: 1.1016650199890137
Validation loss: 2.106458326180776

Epoch: 6| Step: 10
Training loss: 0.9307439923286438
Validation loss: 2.116422931353251

Epoch: 6| Step: 11
Training loss: 1.2627965211868286
Validation loss: 2.042352338631948

Epoch: 6| Step: 12
Training loss: 1.8437527418136597
Validation loss: 2.0399974584579468

Epoch: 6| Step: 13
Training loss: 0.7993018627166748
Validation loss: 2.0926162004470825

Epoch: 374| Step: 0
Training loss: 0.6616191864013672
Validation loss: 2.0708137353261313

Epoch: 6| Step: 1
Training loss: 1.7839133739471436
Validation loss: 2.1156317392985025

Epoch: 6| Step: 2
Training loss: 0.9930874109268188
Validation loss: 2.176975965499878

Epoch: 6| Step: 3
Training loss: 0.9602530002593994
Validation loss: 2.1673458417256675

Epoch: 6| Step: 4
Training loss: 1.1830272674560547
Validation loss: 2.1203795870145163

Epoch: 6| Step: 5
Training loss: 0.9372276067733765
Validation loss: 2.163537641366323

Epoch: 6| Step: 6
Training loss: 0.836111307144165
Validation loss: 2.1535931626955667

Epoch: 6| Step: 7
Training loss: 1.3426032066345215
Validation loss: 2.088524103164673

Epoch: 6| Step: 8
Training loss: 1.205473780632019
Validation loss: 2.099880119164785

Epoch: 6| Step: 9
Training loss: 1.4467275142669678
Validation loss: 2.0656829476356506

Epoch: 6| Step: 10
Training loss: 1.0681452751159668
Validation loss: 2.0895148317019143

Epoch: 6| Step: 11
Training loss: 1.3831380605697632
Validation loss: 2.083066980044047

Epoch: 6| Step: 12
Training loss: 1.0351701974868774
Validation loss: 2.1105759143829346

Epoch: 6| Step: 13
Training loss: 1.6675946712493896
Validation loss: 2.0661953687667847

Epoch: 375| Step: 0
Training loss: 1.858989953994751
Validation loss: 2.030038913091024

Epoch: 6| Step: 1
Training loss: 0.7089192867279053
Validation loss: 2.085521678129832

Epoch: 6| Step: 2
Training loss: 0.9299101233482361
Validation loss: 2.0605446696281433

Epoch: 6| Step: 3
Training loss: 1.8579856157302856
Validation loss: 2.100512226422628

Epoch: 6| Step: 4
Training loss: 0.5603113174438477
Validation loss: 2.1424436370531716

Epoch: 6| Step: 5
Training loss: 1.415830373764038
Validation loss: 2.2064697543780007

Epoch: 6| Step: 6
Training loss: 1.6281728744506836
Validation loss: 2.1247323552767434

Epoch: 6| Step: 7
Training loss: 0.4861365556716919
Validation loss: 2.1126942237218223

Epoch: 6| Step: 8
Training loss: 0.8531646728515625
Validation loss: 2.1292607386906943

Epoch: 6| Step: 9
Training loss: 0.9699965119361877
Validation loss: 2.093413770198822

Epoch: 6| Step: 10
Training loss: 0.9478883147239685
Validation loss: 2.1405903100967407

Epoch: 6| Step: 11
Training loss: 0.9184030890464783
Validation loss: 2.0441006223360696

Epoch: 6| Step: 12
Training loss: 0.696239709854126
Validation loss: 2.0583794514338174

Epoch: 6| Step: 13
Training loss: 1.3949174880981445
Validation loss: 2.1336143811543784

Epoch: 376| Step: 0
Training loss: 1.1011431217193604
Validation loss: 2.106549024581909

Epoch: 6| Step: 1
Training loss: 0.9029811024665833
Validation loss: 2.1057768066724143

Epoch: 6| Step: 2
Training loss: 2.5270750522613525
Validation loss: 2.13839989900589

Epoch: 6| Step: 3
Training loss: 1.1040704250335693
Validation loss: 2.1113338073094687

Epoch: 6| Step: 4
Training loss: 1.1592366695404053
Validation loss: 2.05468213558197

Epoch: 6| Step: 5
Training loss: 1.2373900413513184
Validation loss: 1.9725714127222698

Epoch: 6| Step: 6
Training loss: 1.1572468280792236
Validation loss: 2.0733545621236167

Epoch: 6| Step: 7
Training loss: 1.1728283166885376
Validation loss: 2.0631927649180093

Epoch: 6| Step: 8
Training loss: 1.252415418624878
Validation loss: 2.065089166164398

Epoch: 6| Step: 9
Training loss: 1.030565857887268
Validation loss: 2.063691000143687

Epoch: 6| Step: 10
Training loss: 1.2004295587539673
Validation loss: 2.12072217464447

Epoch: 6| Step: 11
Training loss: 0.767992377281189
Validation loss: 2.1318138043085733

Epoch: 6| Step: 12
Training loss: 0.5230839848518372
Validation loss: 2.1996897260348

Epoch: 6| Step: 13
Training loss: 0.9499448537826538
Validation loss: 2.2129283944765725

Epoch: 377| Step: 0
Training loss: 1.480736494064331
Validation loss: 2.2169382770856223

Epoch: 6| Step: 1
Training loss: 1.103166937828064
Validation loss: 2.16794490814209

Epoch: 6| Step: 2
Training loss: 0.8747204542160034
Validation loss: 2.1410651008288064

Epoch: 6| Step: 3
Training loss: 1.385086178779602
Validation loss: 2.1188159386316934

Epoch: 6| Step: 4
Training loss: 1.4000179767608643
Validation loss: 2.1051945090293884

Epoch: 6| Step: 5
Training loss: 1.0654680728912354
Validation loss: 2.1238249937693277

Epoch: 6| Step: 6
Training loss: 1.2010188102722168
Validation loss: 2.074433664480845

Epoch: 6| Step: 7
Training loss: 1.5963358879089355
Validation loss: 2.099148174126943

Epoch: 6| Step: 8
Training loss: 1.3485430479049683
Validation loss: 2.1115138133366904

Epoch: 6| Step: 9
Training loss: 0.9875653386116028
Validation loss: 2.0900726318359375

Epoch: 6| Step: 10
Training loss: 0.786353588104248
Validation loss: 2.095675985018412

Epoch: 6| Step: 11
Training loss: 0.9334161281585693
Validation loss: 2.1462124983469644

Epoch: 6| Step: 12
Training loss: 1.211841344833374
Validation loss: 2.1821412245432534

Epoch: 6| Step: 13
Training loss: 0.5911304354667664
Validation loss: 2.1707088947296143

Epoch: 378| Step: 0
Training loss: 1.9782898426055908
Validation loss: 2.210561752319336

Epoch: 6| Step: 1
Training loss: 1.6294312477111816
Validation loss: 2.1751303672790527

Epoch: 6| Step: 2
Training loss: 1.7562037706375122
Validation loss: 2.1946776707967124

Epoch: 6| Step: 3
Training loss: 1.1664917469024658
Validation loss: 2.1650558511416116

Epoch: 6| Step: 4
Training loss: 1.28879714012146
Validation loss: 2.08191047112147

Epoch: 6| Step: 5
Training loss: 0.7691248059272766
Validation loss: 2.1808345317840576

Epoch: 6| Step: 6
Training loss: 0.9803793430328369
Validation loss: 2.09180341164271

Epoch: 6| Step: 7
Training loss: 1.0783946514129639
Validation loss: 2.0902143518129983

Epoch: 6| Step: 8
Training loss: 0.935431718826294
Validation loss: 2.0675717989603677

Epoch: 6| Step: 9
Training loss: 0.7159794569015503
Validation loss: 2.085118313630422

Epoch: 6| Step: 10
Training loss: 0.6777926683425903
Validation loss: 2.1031331221262612

Epoch: 6| Step: 11
Training loss: 0.988049328327179
Validation loss: 2.167330880959829

Epoch: 6| Step: 12
Training loss: 1.063656210899353
Validation loss: 2.2495762507120767

Epoch: 6| Step: 13
Training loss: 1.421410322189331
Validation loss: 2.2768880128860474

Epoch: 379| Step: 0
Training loss: 1.424824833869934
Validation loss: 2.2868018547693887

Epoch: 6| Step: 1
Training loss: 1.4052338600158691
Validation loss: 2.2635629773139954

Epoch: 6| Step: 2
Training loss: 1.0773884057998657
Validation loss: 2.199921488761902

Epoch: 6| Step: 3
Training loss: 0.5289758443832397
Validation loss: 2.179980138937632

Epoch: 6| Step: 4
Training loss: 1.5107512474060059
Validation loss: 2.1430084307988486

Epoch: 6| Step: 5
Training loss: 0.7399588227272034
Validation loss: 2.1165776451428733

Epoch: 6| Step: 6
Training loss: 0.775026798248291
Validation loss: 2.1257986028989158

Epoch: 6| Step: 7
Training loss: 0.9384092092514038
Validation loss: 2.0681366523106894

Epoch: 6| Step: 8
Training loss: 1.6973553895950317
Validation loss: 2.0942280093828836

Epoch: 6| Step: 9
Training loss: 1.0388460159301758
Validation loss: 2.1386530001958213

Epoch: 6| Step: 10
Training loss: 0.7532346248626709
Validation loss: 2.129378100236257

Epoch: 6| Step: 11
Training loss: 1.0580068826675415
Validation loss: 2.1067731380462646

Epoch: 6| Step: 12
Training loss: 0.8522756695747375
Validation loss: 2.11887397368749

Epoch: 6| Step: 13
Training loss: 1.6062769889831543
Validation loss: 2.0938998659451804

Epoch: 380| Step: 0
Training loss: 0.9779782295227051
Validation loss: 2.054477334022522

Epoch: 6| Step: 1
Training loss: 1.0144723653793335
Validation loss: 2.125753482182821

Epoch: 6| Step: 2
Training loss: 1.7191698551177979
Validation loss: 2.064517597357432

Epoch: 6| Step: 3
Training loss: 1.0493454933166504
Validation loss: 2.113250414530436

Epoch: 6| Step: 4
Training loss: 0.5855153799057007
Validation loss: 2.0528982877731323

Epoch: 6| Step: 5
Training loss: 1.087430715560913
Validation loss: 2.1332611242930093

Epoch: 6| Step: 6
Training loss: 1.6730247735977173
Validation loss: 2.1888115207354226

Epoch: 6| Step: 7
Training loss: 1.191504716873169
Validation loss: 2.2413163781166077

Epoch: 6| Step: 8
Training loss: 2.1868598461151123
Validation loss: 2.280968348185221

Epoch: 6| Step: 9
Training loss: 1.0287306308746338
Validation loss: 2.25713441769282

Epoch: 6| Step: 10
Training loss: 1.1040427684783936
Validation loss: 2.1933797001838684

Epoch: 6| Step: 11
Training loss: 0.9939769506454468
Validation loss: 2.141487638155619

Epoch: 6| Step: 12
Training loss: 0.7844593524932861
Validation loss: 2.1453976233800254

Epoch: 6| Step: 13
Training loss: 1.1187636852264404
Validation loss: 2.087098260720571

Epoch: 381| Step: 0
Training loss: 1.355666160583496
Validation loss: 2.089692711830139

Epoch: 6| Step: 1
Training loss: 1.163536548614502
Validation loss: 2.133641759554545

Epoch: 6| Step: 2
Training loss: 1.5511279106140137
Validation loss: 2.1375881234804788

Epoch: 6| Step: 3
Training loss: 0.7368206977844238
Validation loss: 2.126936197280884

Epoch: 6| Step: 4
Training loss: 1.3894805908203125
Validation loss: 2.1488216121991477

Epoch: 6| Step: 5
Training loss: 1.233439564704895
Validation loss: 2.150503913561503

Epoch: 6| Step: 6
Training loss: 1.1627087593078613
Validation loss: 2.18349826335907

Epoch: 6| Step: 7
Training loss: 0.9824860692024231
Validation loss: 2.2285123268763223

Epoch: 6| Step: 8
Training loss: 1.6593221426010132
Validation loss: 2.2295811573664346

Epoch: 6| Step: 9
Training loss: 0.9351189732551575
Validation loss: 2.249352832635244

Epoch: 6| Step: 10
Training loss: 1.10430908203125
Validation loss: 2.2097957332928977

Epoch: 6| Step: 11
Training loss: 1.1024816036224365
Validation loss: 2.219366212685903

Epoch: 6| Step: 12
Training loss: 0.9969147443771362
Validation loss: 2.1467411120732627

Epoch: 6| Step: 13
Training loss: 1.0245726108551025
Validation loss: 2.127614359060923

Epoch: 382| Step: 0
Training loss: 1.0727812051773071
Validation loss: 2.1493765314420066

Epoch: 6| Step: 1
Training loss: 1.1705107688903809
Validation loss: 2.1360374093055725

Epoch: 6| Step: 2
Training loss: 1.304408311843872
Validation loss: 2.1817898948987327

Epoch: 6| Step: 3
Training loss: 0.5832557678222656
Validation loss: 2.1772945125897727

Epoch: 6| Step: 4
Training loss: 0.8847343325614929
Validation loss: 2.1921419501304626

Epoch: 6| Step: 5
Training loss: 1.2530417442321777
Validation loss: 2.1422371665636697

Epoch: 6| Step: 6
Training loss: 1.7813138961791992
Validation loss: 2.1128429969151816

Epoch: 6| Step: 7
Training loss: 0.8646789789199829
Validation loss: 2.123931606610616

Epoch: 6| Step: 8
Training loss: 0.9256892204284668
Validation loss: 2.0990618069966636

Epoch: 6| Step: 9
Training loss: 1.3609669208526611
Validation loss: 2.08706925312678

Epoch: 6| Step: 10
Training loss: 0.7471507787704468
Validation loss: 2.1217196782430015

Epoch: 6| Step: 11
Training loss: 0.8350450992584229
Validation loss: 2.1475230058034263

Epoch: 6| Step: 12
Training loss: 1.3610221147537231
Validation loss: 2.14176211754481

Epoch: 6| Step: 13
Training loss: 0.9545934200286865
Validation loss: 2.1564923922220864

Epoch: 383| Step: 0
Training loss: 0.9150664806365967
Validation loss: 2.1799981594085693

Epoch: 6| Step: 1
Training loss: 1.3275134563446045
Validation loss: 2.1463831861813865

Epoch: 6| Step: 2
Training loss: 0.6329003572463989
Validation loss: 2.132332424322764

Epoch: 6| Step: 3
Training loss: 0.6470625996589661
Validation loss: 2.1443773905436196

Epoch: 6| Step: 4
Training loss: 1.1513900756835938
Validation loss: 2.1112661361694336

Epoch: 6| Step: 5
Training loss: 0.93216872215271
Validation loss: 2.075168331464132

Epoch: 6| Step: 6
Training loss: 0.6417127847671509
Validation loss: 2.0739261905352273

Epoch: 6| Step: 7
Training loss: 1.4585285186767578
Validation loss: 2.120564619700114

Epoch: 6| Step: 8
Training loss: 0.7901604771614075
Validation loss: 2.087795933087667

Epoch: 6| Step: 9
Training loss: 0.8948891162872314
Validation loss: 2.1343857844670615

Epoch: 6| Step: 10
Training loss: 2.206937313079834
Validation loss: 2.1409623622894287

Epoch: 6| Step: 11
Training loss: 0.9393723011016846
Validation loss: 2.1189712484677634

Epoch: 6| Step: 12
Training loss: 0.7356188297271729
Validation loss: 2.123932639757792

Epoch: 6| Step: 13
Training loss: 1.2879359722137451
Validation loss: 2.084802985191345

Epoch: 384| Step: 0
Training loss: 0.7510966062545776
Validation loss: 2.083258867263794

Epoch: 6| Step: 1
Training loss: 0.6968773603439331
Validation loss: 2.139487346013387

Epoch: 6| Step: 2
Training loss: 1.4489245414733887
Validation loss: 2.1830551822980246

Epoch: 6| Step: 3
Training loss: 0.9139724969863892
Validation loss: 2.1447487076123557

Epoch: 6| Step: 4
Training loss: 1.0368307828903198
Validation loss: 2.0854373574256897

Epoch: 6| Step: 5
Training loss: 1.06736421585083
Validation loss: 2.1466697057088218

Epoch: 6| Step: 6
Training loss: 1.8228135108947754
Validation loss: 2.0929513573646545

Epoch: 6| Step: 7
Training loss: 1.0874335765838623
Validation loss: 2.070933918158213

Epoch: 6| Step: 8
Training loss: 0.49202239513397217
Validation loss: 2.114129811525345

Epoch: 6| Step: 9
Training loss: 0.7355650067329407
Validation loss: 2.098409096399943

Epoch: 6| Step: 10
Training loss: 0.936198353767395
Validation loss: 2.113787511984507

Epoch: 6| Step: 11
Training loss: 1.0663546323776245
Validation loss: 2.1001744071642556

Epoch: 6| Step: 12
Training loss: 1.403857946395874
Validation loss: 2.112768272558848

Epoch: 6| Step: 13
Training loss: 1.2132594585418701
Validation loss: 2.1785068909327188

Epoch: 385| Step: 0
Training loss: 1.4568276405334473
Validation loss: 2.136669933795929

Epoch: 6| Step: 1
Training loss: 0.8791416883468628
Validation loss: 2.1259403824806213

Epoch: 6| Step: 2
Training loss: 1.3658558130264282
Validation loss: 2.0988364815711975

Epoch: 6| Step: 3
Training loss: 0.9354066848754883
Validation loss: 2.0950766801834106

Epoch: 6| Step: 4
Training loss: 0.8174445033073425
Validation loss: 2.1060049732526145

Epoch: 6| Step: 5
Training loss: 1.474592924118042
Validation loss: 2.071971297264099

Epoch: 6| Step: 6
Training loss: 1.2210490703582764
Validation loss: 2.059122681617737

Epoch: 6| Step: 7
Training loss: 0.6825191974639893
Validation loss: 2.1042346358299255

Epoch: 6| Step: 8
Training loss: 1.1074483394622803
Validation loss: 2.112628757953644

Epoch: 6| Step: 9
Training loss: 0.5705028772354126
Validation loss: 2.0955547293027244

Epoch: 6| Step: 10
Training loss: 0.9154620170593262
Validation loss: 2.138936460018158

Epoch: 6| Step: 11
Training loss: 0.7376090288162231
Validation loss: 2.11850368976593

Epoch: 6| Step: 12
Training loss: 0.8752639293670654
Validation loss: 2.122952123483022

Epoch: 6| Step: 13
Training loss: 1.0979201793670654
Validation loss: 2.142768144607544

Epoch: 386| Step: 0
Training loss: 0.9290069341659546
Validation loss: 2.1189353664716086

Epoch: 6| Step: 1
Training loss: 0.7144153118133545
Validation loss: 2.166081647078196

Epoch: 6| Step: 2
Training loss: 1.3033850193023682
Validation loss: 2.1743801832199097

Epoch: 6| Step: 3
Training loss: 0.848553478717804
Validation loss: 2.1108755270640054

Epoch: 6| Step: 4
Training loss: 1.0865247249603271
Validation loss: 2.152800718943278

Epoch: 6| Step: 5
Training loss: 0.5853694081306458
Validation loss: 2.10649174451828

Epoch: 6| Step: 6
Training loss: 1.40664803981781
Validation loss: 2.122991601626078

Epoch: 6| Step: 7
Training loss: 1.3904097080230713
Validation loss: 2.1370448668797812

Epoch: 6| Step: 8
Training loss: 1.3675309419631958
Validation loss: 2.152209222316742

Epoch: 6| Step: 9
Training loss: 1.0149612426757812
Validation loss: 2.1291491985321045

Epoch: 6| Step: 10
Training loss: 0.912344217300415
Validation loss: 2.1912545959154763

Epoch: 6| Step: 11
Training loss: 1.0217373371124268
Validation loss: 2.1677947441736856

Epoch: 6| Step: 12
Training loss: 0.8646790981292725
Validation loss: 2.105116049448649

Epoch: 6| Step: 13
Training loss: 0.9588749408721924
Validation loss: 2.106715281804403

Epoch: 387| Step: 0
Training loss: 1.1270363330841064
Validation loss: 2.062521735827128

Epoch: 6| Step: 1
Training loss: 1.0333971977233887
Validation loss: 2.08032888174057

Epoch: 6| Step: 2
Training loss: 0.6324434280395508
Validation loss: 2.068205694357554

Epoch: 6| Step: 3
Training loss: 0.9164040684700012
Validation loss: 2.078360358874003

Epoch: 6| Step: 4
Training loss: 0.9071550369262695
Validation loss: 2.094018359978994

Epoch: 6| Step: 5
Training loss: 0.8215488195419312
Validation loss: 2.101333479086558

Epoch: 6| Step: 6
Training loss: 0.5479585528373718
Validation loss: 2.0999210278193154

Epoch: 6| Step: 7
Training loss: 1.0518357753753662
Validation loss: 2.074837883313497

Epoch: 6| Step: 8
Training loss: 0.5334319472312927
Validation loss: 2.112957855065664

Epoch: 6| Step: 9
Training loss: 0.911737859249115
Validation loss: 2.1088842153549194

Epoch: 6| Step: 10
Training loss: 1.042634129524231
Validation loss: 2.0951534112294516

Epoch: 6| Step: 11
Training loss: 2.2822976112365723
Validation loss: 2.0725446740786233

Epoch: 6| Step: 12
Training loss: 1.4343383312225342
Validation loss: 2.0568350553512573

Epoch: 6| Step: 13
Training loss: 1.0056843757629395
Validation loss: 2.0630786220232644

Epoch: 388| Step: 0
Training loss: 0.9730873107910156
Validation loss: 2.040327787399292

Epoch: 6| Step: 1
Training loss: 1.056814193725586
Validation loss: 2.0432013273239136

Epoch: 6| Step: 2
Training loss: 1.2202461957931519
Validation loss: 2.110340714454651

Epoch: 6| Step: 3
Training loss: 0.9956164360046387
Validation loss: 2.0666165947914124

Epoch: 6| Step: 4
Training loss: 0.6598993539810181
Validation loss: 2.070267995198568

Epoch: 6| Step: 5
Training loss: 0.6770564317703247
Validation loss: 2.133548160394033

Epoch: 6| Step: 6
Training loss: 1.6683690547943115
Validation loss: 2.170255978902181

Epoch: 6| Step: 7
Training loss: 0.609964907169342
Validation loss: 2.0824692249298096

Epoch: 6| Step: 8
Training loss: 1.527857780456543
Validation loss: 2.071238418420156

Epoch: 6| Step: 9
Training loss: 0.5649670362472534
Validation loss: 2.0404225786527

Epoch: 6| Step: 10
Training loss: 1.6265926361083984
Validation loss: 2.045227328936259

Epoch: 6| Step: 11
Training loss: 1.3944149017333984
Validation loss: 2.0904106299082437

Epoch: 6| Step: 12
Training loss: 1.0753748416900635
Validation loss: 2.0667108496030173

Epoch: 6| Step: 13
Training loss: 0.8666107058525085
Validation loss: 2.0164537827173867

Epoch: 389| Step: 0
Training loss: 0.685614287853241
Validation loss: 2.071830928325653

Epoch: 6| Step: 1
Training loss: 0.9944538474082947
Validation loss: 2.0718129674593606

Epoch: 6| Step: 2
Training loss: 0.6723584532737732
Validation loss: 2.012239396572113

Epoch: 6| Step: 3
Training loss: 1.3942861557006836
Validation loss: 2.1269761125246682

Epoch: 6| Step: 4
Training loss: 1.0992534160614014
Validation loss: 2.177444318930308

Epoch: 6| Step: 5
Training loss: 1.8106663227081299
Validation loss: 2.2004762490590415

Epoch: 6| Step: 6
Training loss: 0.6869490742683411
Validation loss: 2.2038767337799072

Epoch: 6| Step: 7
Training loss: 1.6356818675994873
Validation loss: 2.200704554716746

Epoch: 6| Step: 8
Training loss: 0.9449853897094727
Validation loss: 2.1873425046602883

Epoch: 6| Step: 9
Training loss: 0.3509678542613983
Validation loss: 2.109327812989553

Epoch: 6| Step: 10
Training loss: 1.4922764301300049
Validation loss: 2.138538380463918

Epoch: 6| Step: 11
Training loss: 0.7674150466918945
Validation loss: 2.0874587098757424

Epoch: 6| Step: 12
Training loss: 0.8746123909950256
Validation loss: 2.0690300464630127

Epoch: 6| Step: 13
Training loss: 1.0867520570755005
Validation loss: 2.042198042074839

Epoch: 390| Step: 0
Training loss: 0.74794602394104
Validation loss: 2.0310935775438943

Epoch: 6| Step: 1
Training loss: 0.884162425994873
Validation loss: 2.0704989433288574

Epoch: 6| Step: 2
Training loss: 1.1515092849731445
Validation loss: 2.044163187344869

Epoch: 6| Step: 3
Training loss: 1.277873158454895
Validation loss: 2.0773536364237466

Epoch: 6| Step: 4
Training loss: 0.8875036239624023
Validation loss: 2.0877795219421387

Epoch: 6| Step: 5
Training loss: 0.9679708480834961
Validation loss: 2.149210492769877

Epoch: 6| Step: 6
Training loss: 0.8670844435691833
Validation loss: 2.1616752545038858

Epoch: 6| Step: 7
Training loss: 1.2248767614364624
Validation loss: 2.175046364466349

Epoch: 6| Step: 8
Training loss: 1.0734630823135376
Validation loss: 2.1305357813835144

Epoch: 6| Step: 9
Training loss: 1.8267507553100586
Validation loss: 2.11794513463974

Epoch: 6| Step: 10
Training loss: 0.4957689642906189
Validation loss: 2.1128004789352417

Epoch: 6| Step: 11
Training loss: 0.9698207378387451
Validation loss: 2.0842185020446777

Epoch: 6| Step: 12
Training loss: 0.8529782295227051
Validation loss: 2.054336746533712

Epoch: 6| Step: 13
Training loss: 0.9162102937698364
Validation loss: 2.0572513937950134

Epoch: 391| Step: 0
Training loss: 1.2798824310302734
Validation loss: 2.1257957816123962

Epoch: 6| Step: 1
Training loss: 0.7632919549942017
Validation loss: 2.1046231190363565

Epoch: 6| Step: 2
Training loss: 1.1816688776016235
Validation loss: 2.1275776624679565

Epoch: 6| Step: 3
Training loss: 1.0283653736114502
Validation loss: 2.1335679292678833

Epoch: 6| Step: 4
Training loss: 1.8034459352493286
Validation loss: 2.084070066610972

Epoch: 6| Step: 5
Training loss: 0.550809383392334
Validation loss: 2.1112082799275718

Epoch: 6| Step: 6
Training loss: 1.5443007946014404
Validation loss: 2.103466788927714

Epoch: 6| Step: 7
Training loss: 0.9419472217559814
Validation loss: 2.1341235041618347

Epoch: 6| Step: 8
Training loss: 0.7383090853691101
Validation loss: 2.1657126347223916

Epoch: 6| Step: 9
Training loss: 0.9444741010665894
Validation loss: 2.1682904958724976

Epoch: 6| Step: 10
Training loss: 0.4822080135345459
Validation loss: 2.1588820219039917

Epoch: 6| Step: 11
Training loss: 0.7461973428726196
Validation loss: 2.1692774097124734

Epoch: 6| Step: 12
Training loss: 1.2009778022766113
Validation loss: 2.135144035021464

Epoch: 6| Step: 13
Training loss: 1.0801992416381836
Validation loss: 2.100906511147817

Epoch: 392| Step: 0
Training loss: 1.4638863801956177
Validation loss: 2.0418898661931357

Epoch: 6| Step: 1
Training loss: 0.9524915218353271
Validation loss: 2.09699954589208

Epoch: 6| Step: 2
Training loss: 0.5623409748077393
Validation loss: 2.0374346574147544

Epoch: 6| Step: 3
Training loss: 0.8991631269454956
Validation loss: 2.011441727479299

Epoch: 6| Step: 4
Training loss: 0.4962422251701355
Validation loss: 2.0097139875094094

Epoch: 6| Step: 5
Training loss: 1.0941991806030273
Validation loss: 2.0211474299430847

Epoch: 6| Step: 6
Training loss: 1.3623199462890625
Validation loss: 2.1067665219306946

Epoch: 6| Step: 7
Training loss: 0.7491933107376099
Validation loss: 2.0693415800730386

Epoch: 6| Step: 8
Training loss: 1.3181657791137695
Validation loss: 2.1009740233421326

Epoch: 6| Step: 9
Training loss: 0.7432891130447388
Validation loss: 2.181424140930176

Epoch: 6| Step: 10
Training loss: 1.6355406045913696
Validation loss: 2.2494351069132485

Epoch: 6| Step: 11
Training loss: 0.9819004535675049
Validation loss: 2.2368352015813193

Epoch: 6| Step: 12
Training loss: 1.4718611240386963
Validation loss: 2.1797667145729065

Epoch: 6| Step: 13
Training loss: 0.8837766647338867
Validation loss: 2.1577868262926736

Epoch: 393| Step: 0
Training loss: 0.6476777791976929
Validation loss: 2.1137385169665017

Epoch: 6| Step: 1
Training loss: 0.592035174369812
Validation loss: 2.0735963384310403

Epoch: 6| Step: 2
Training loss: 0.9900164604187012
Validation loss: 2.091702103614807

Epoch: 6| Step: 3
Training loss: 1.0246440172195435
Validation loss: 2.058929920196533

Epoch: 6| Step: 4
Training loss: 0.9536629915237427
Validation loss: 2.057471990585327

Epoch: 6| Step: 5
Training loss: 0.8189079165458679
Validation loss: 2.1357468962669373

Epoch: 6| Step: 6
Training loss: 1.9304637908935547
Validation loss: 2.097427765528361

Epoch: 6| Step: 7
Training loss: 1.7910921573638916
Validation loss: 2.159566283226013

Epoch: 6| Step: 8
Training loss: 0.600697934627533
Validation loss: 2.1819390654563904

Epoch: 6| Step: 9
Training loss: 1.5790568590164185
Validation loss: 2.1984689235687256

Epoch: 6| Step: 10
Training loss: 1.1312192678451538
Validation loss: 2.1959967414538064

Epoch: 6| Step: 11
Training loss: 1.1819208860397339
Validation loss: 2.20555986960729

Epoch: 6| Step: 12
Training loss: 0.8493582010269165
Validation loss: 2.1812389294306436

Epoch: 6| Step: 13
Training loss: 0.6865516304969788
Validation loss: 2.1676318248113

Epoch: 394| Step: 0
Training loss: 0.8076592087745667
Validation loss: 2.1540333231290183

Epoch: 6| Step: 1
Training loss: 0.6832987070083618
Validation loss: 2.113238275051117

Epoch: 6| Step: 2
Training loss: 1.373838186264038
Validation loss: 2.1055442889531455

Epoch: 6| Step: 3
Training loss: 1.9139485359191895
Validation loss: 2.128779649734497

Epoch: 6| Step: 4
Training loss: 0.754231333732605
Validation loss: 2.1182058652242026

Epoch: 6| Step: 5
Training loss: 0.9150561094284058
Validation loss: 2.077816387017568

Epoch: 6| Step: 6
Training loss: 1.1421072483062744
Validation loss: 2.0733606417973838

Epoch: 6| Step: 7
Training loss: 0.9240244626998901
Validation loss: 2.0914960702260337

Epoch: 6| Step: 8
Training loss: 0.9474939107894897
Validation loss: 2.129926323890686

Epoch: 6| Step: 9
Training loss: 1.115301251411438
Validation loss: 2.1438874999682107

Epoch: 6| Step: 10
Training loss: 0.9021452069282532
Validation loss: 2.1294756730397544

Epoch: 6| Step: 11
Training loss: 0.636954665184021
Validation loss: 2.1685208678245544

Epoch: 6| Step: 12
Training loss: 1.274601697921753
Validation loss: 2.12860761086146

Epoch: 6| Step: 13
Training loss: 0.611918568611145
Validation loss: 2.075531860192617

Epoch: 395| Step: 0
Training loss: 0.9535638689994812
Validation loss: 2.111392557621002

Epoch: 6| Step: 1
Training loss: 1.6281099319458008
Validation loss: 2.0815607706705728

Epoch: 6| Step: 2
Training loss: 0.7445200681686401
Validation loss: 2.004051625728607

Epoch: 6| Step: 3
Training loss: 1.3710830211639404
Validation loss: 2.073162019252777

Epoch: 6| Step: 4
Training loss: 0.9000674486160278
Validation loss: 2.0237486362457275

Epoch: 6| Step: 5
Training loss: 0.5180175304412842
Validation loss: 2.095536013444265

Epoch: 6| Step: 6
Training loss: 0.46472904086112976
Validation loss: 2.0599302649497986

Epoch: 6| Step: 7
Training loss: 0.9593589901924133
Validation loss: 2.1126176913579306

Epoch: 6| Step: 8
Training loss: 1.5473315715789795
Validation loss: 2.2039658228556314

Epoch: 6| Step: 9
Training loss: 1.4633095264434814
Validation loss: 2.195923467477163

Epoch: 6| Step: 10
Training loss: 1.40669846534729
Validation loss: 2.166342477003733

Epoch: 6| Step: 11
Training loss: 0.5481133460998535
Validation loss: 2.1028570334116616

Epoch: 6| Step: 12
Training loss: 1.3552989959716797
Validation loss: 2.0690225958824158

Epoch: 6| Step: 13
Training loss: 1.102637529373169
Validation loss: 2.090559800465902

Epoch: 396| Step: 0
Training loss: 1.1792129278182983
Validation loss: 2.0762876868247986

Epoch: 6| Step: 1
Training loss: 1.488373875617981
Validation loss: 2.0938744942347207

Epoch: 6| Step: 2
Training loss: 1.1294615268707275
Validation loss: 2.0781604846318564

Epoch: 6| Step: 3
Training loss: 1.6383397579193115
Validation loss: 2.0663089752197266

Epoch: 6| Step: 4
Training loss: 0.7656668424606323
Validation loss: 2.066556990146637

Epoch: 6| Step: 5
Training loss: 0.6016386151313782
Validation loss: 2.0574429432551065

Epoch: 6| Step: 6
Training loss: 1.338651180267334
Validation loss: 2.119269549846649

Epoch: 6| Step: 7
Training loss: 1.1680899858474731
Validation loss: 2.141051709651947

Epoch: 6| Step: 8
Training loss: 0.7258180379867554
Validation loss: 2.155607759952545

Epoch: 6| Step: 9
Training loss: 0.9005496501922607
Validation loss: 2.1819919546445212

Epoch: 6| Step: 10
Training loss: 0.6366862058639526
Validation loss: 2.212169428666433

Epoch: 6| Step: 11
Training loss: 0.8963799476623535
Validation loss: 2.1803805232048035

Epoch: 6| Step: 12
Training loss: 0.7237730026245117
Validation loss: 2.1966019670168557

Epoch: 6| Step: 13
Training loss: 1.7211318016052246
Validation loss: 2.1385618845621743

Epoch: 397| Step: 0
Training loss: 0.76700758934021
Validation loss: 2.057121992111206

Epoch: 6| Step: 1
Training loss: 1.533139944076538
Validation loss: 2.0456904768943787

Epoch: 6| Step: 2
Training loss: 1.1234583854675293
Validation loss: 1.9906856020291646

Epoch: 6| Step: 3
Training loss: 1.2715373039245605
Validation loss: 2.0009540716807046

Epoch: 6| Step: 4
Training loss: 0.7294849157333374
Validation loss: 2.103710730870565

Epoch: 6| Step: 5
Training loss: 0.7325798273086548
Validation loss: 2.064552068710327

Epoch: 6| Step: 6
Training loss: 0.8452293276786804
Validation loss: 2.0733611981074014

Epoch: 6| Step: 7
Training loss: 1.554152488708496
Validation loss: 2.075899600982666

Epoch: 6| Step: 8
Training loss: 1.2556679248809814
Validation loss: 2.1846961180369058

Epoch: 6| Step: 9
Training loss: 0.809535562992096
Validation loss: 2.2179168065389

Epoch: 6| Step: 10
Training loss: 1.2674442529678345
Validation loss: 2.2667411168416343

Epoch: 6| Step: 11
Training loss: 1.2569475173950195
Validation loss: 2.2663761973381042

Epoch: 6| Step: 12
Training loss: 0.8080484867095947
Validation loss: 2.27310319741567

Epoch: 6| Step: 13
Training loss: 1.6643444299697876
Validation loss: 2.2292528549830117

Epoch: 398| Step: 0
Training loss: 0.9156433343887329
Validation loss: 2.1452451745669046

Epoch: 6| Step: 1
Training loss: 0.7329325675964355
Validation loss: 2.1548492113749185

Epoch: 6| Step: 2
Training loss: 0.6063153743743896
Validation loss: 2.0801199475924173

Epoch: 6| Step: 3
Training loss: 0.5934334993362427
Validation loss: 2.1202200849850974

Epoch: 6| Step: 4
Training loss: 1.3636865615844727
Validation loss: 2.0783161918322244

Epoch: 6| Step: 5
Training loss: 1.0781358480453491
Validation loss: 2.0589687824249268

Epoch: 6| Step: 6
Training loss: 1.1850517988204956
Validation loss: 2.0936437845230103

Epoch: 6| Step: 7
Training loss: 0.7367605566978455
Validation loss: 2.0519883036613464

Epoch: 6| Step: 8
Training loss: 1.651735544204712
Validation loss: 2.0876683394114175

Epoch: 6| Step: 9
Training loss: 0.8270856738090515
Validation loss: 2.0772592027982077

Epoch: 6| Step: 10
Training loss: 0.7277414798736572
Validation loss: 2.1015618642171225

Epoch: 6| Step: 11
Training loss: 0.7903388738632202
Validation loss: 2.1239819526672363

Epoch: 6| Step: 12
Training loss: 1.4037286043167114
Validation loss: 2.0940717260042825

Epoch: 6| Step: 13
Training loss: 1.4014959335327148
Validation loss: 2.0557620525360107

Epoch: 399| Step: 0
Training loss: 1.0998090505599976
Validation loss: 2.0328071316083274

Epoch: 6| Step: 1
Training loss: 0.9284335970878601
Validation loss: 2.047688901424408

Epoch: 6| Step: 2
Training loss: 1.4047129154205322
Validation loss: 2.0609715580940247

Epoch: 6| Step: 3
Training loss: 0.49147677421569824
Validation loss: 2.100549022356669

Epoch: 6| Step: 4
Training loss: 1.3399096727371216
Validation loss: 2.0845852891604104

Epoch: 6| Step: 5
Training loss: 0.744038462638855
Validation loss: 2.0961533188819885

Epoch: 6| Step: 6
Training loss: 0.6122514605522156
Validation loss: 2.102108379205068

Epoch: 6| Step: 7
Training loss: 0.4704258441925049
Validation loss: 2.146139601866404

Epoch: 6| Step: 8
Training loss: 0.9136162996292114
Validation loss: 2.1185513138771057

Epoch: 6| Step: 9
Training loss: 1.2075592279434204
Validation loss: 2.156905194123586

Epoch: 6| Step: 10
Training loss: 0.9029649496078491
Validation loss: 2.146843751271566

Epoch: 6| Step: 11
Training loss: 1.49796724319458
Validation loss: 2.120026111602783

Epoch: 6| Step: 12
Training loss: 1.182841181755066
Validation loss: 2.0830203096071878

Epoch: 6| Step: 13
Training loss: 0.564047634601593
Validation loss: 2.149343033631643

Epoch: 400| Step: 0
Training loss: 1.176110029220581
Validation loss: 2.0343342820803323

Epoch: 6| Step: 1
Training loss: 1.1593283414840698
Validation loss: 2.057953894138336

Epoch: 6| Step: 2
Training loss: 0.7262964844703674
Validation loss: 2.126343091328939

Epoch: 6| Step: 3
Training loss: 0.5653581619262695
Validation loss: 2.1044130325317383

Epoch: 6| Step: 4
Training loss: 0.7909835577011108
Validation loss: 2.132422467072805

Epoch: 6| Step: 5
Training loss: 0.723395586013794
Validation loss: 2.1285633643468223

Epoch: 6| Step: 6
Training loss: 0.8412178754806519
Validation loss: 2.1590320666631064

Epoch: 6| Step: 7
Training loss: 1.5332369804382324
Validation loss: 2.189908444881439

Epoch: 6| Step: 8
Training loss: 0.8600645065307617
Validation loss: 2.1628470420837402

Epoch: 6| Step: 9
Training loss: 1.107358694076538
Validation loss: 2.1503675977389016

Epoch: 6| Step: 10
Training loss: 0.8418580293655396
Validation loss: 2.0903061032295227

Epoch: 6| Step: 11
Training loss: 0.6119564771652222
Validation loss: 2.0582160154978433

Epoch: 6| Step: 12
Training loss: 0.6845858693122864
Validation loss: 2.061446746190389

Epoch: 6| Step: 13
Training loss: 1.2617828845977783
Validation loss: 2.0624932050704956

Testing loss: 2.0356452739496027
