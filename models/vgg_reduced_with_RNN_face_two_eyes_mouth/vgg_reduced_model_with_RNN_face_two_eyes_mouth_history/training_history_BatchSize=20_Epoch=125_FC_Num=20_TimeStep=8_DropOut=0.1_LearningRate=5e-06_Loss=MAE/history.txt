Epoch: 1| Step: 0
Training loss: 5.289508819580078
Validation loss: 5.3159934480985

Epoch: 5| Step: 1
Training loss: 4.5824456214904785
Validation loss: 5.313722213109334

Epoch: 5| Step: 2
Training loss: 5.824326515197754
Validation loss: 5.311600863933563

Epoch: 5| Step: 3
Training loss: 5.1033830642700195
Validation loss: 5.309469223022461

Epoch: 5| Step: 4
Training loss: 5.231330871582031
Validation loss: 5.307362775007884

Epoch: 5| Step: 5
Training loss: 5.808962821960449
Validation loss: 5.305270592371623

Epoch: 5| Step: 6
Training loss: 5.856778621673584
Validation loss: 5.303270181020101

Epoch: 5| Step: 7
Training loss: 4.964446067810059
Validation loss: 5.3011818925539655

Epoch: 5| Step: 8
Training loss: 5.583930015563965
Validation loss: 5.299002726872762

Epoch: 5| Step: 9
Training loss: 5.465205192565918
Validation loss: 5.296752214431763

Epoch: 5| Step: 10
Training loss: 5.367030143737793
Validation loss: 5.294474204381307

Epoch: 5| Step: 11
Training loss: 5.555830001831055
Validation loss: 5.292099475860596

Epoch: 2| Step: 0
Training loss: 5.1251420974731445
Validation loss: 5.289637207984924

Epoch: 5| Step: 1
Training loss: 5.281230926513672
Validation loss: 5.287071724732717

Epoch: 5| Step: 2
Training loss: 5.974374771118164
Validation loss: 5.284504334131877

Epoch: 5| Step: 3
Training loss: 5.331356048583984
Validation loss: 5.281765719254811

Epoch: 5| Step: 4
Training loss: 5.264457702636719
Validation loss: 5.279024263223012

Epoch: 5| Step: 5
Training loss: 5.830822944641113
Validation loss: 5.276039163271586

Epoch: 5| Step: 6
Training loss: 4.607551097869873
Validation loss: 5.272980352242787

Epoch: 5| Step: 7
Training loss: 4.8674774169921875
Validation loss: 5.269774218400319

Epoch: 5| Step: 8
Training loss: 5.316323757171631
Validation loss: 5.266477406024933

Epoch: 5| Step: 9
Training loss: 5.977743625640869
Validation loss: 5.262932360172272

Epoch: 5| Step: 10
Training loss: 5.353806495666504
Validation loss: 5.259225249290466

Epoch: 5| Step: 11
Training loss: 4.625275611877441
Validation loss: 5.255394816398621

Epoch: 3| Step: 0
Training loss: 5.354854583740234
Validation loss: 5.251478870709737

Epoch: 5| Step: 1
Training loss: 5.289977550506592
Validation loss: 5.247145871321361

Epoch: 5| Step: 2
Training loss: 5.332035064697266
Validation loss: 5.2427467703819275

Epoch: 5| Step: 3
Training loss: 5.0495195388793945
Validation loss: 5.238197386264801

Epoch: 5| Step: 4
Training loss: 4.928908348083496
Validation loss: 5.233388642470042

Epoch: 5| Step: 5
Training loss: 5.124121189117432
Validation loss: 5.2283070882161455

Epoch: 5| Step: 6
Training loss: 5.669323921203613
Validation loss: 5.223045031229655

Epoch: 5| Step: 7
Training loss: 4.986178398132324
Validation loss: 5.217622419198354

Epoch: 5| Step: 8
Training loss: 5.470412254333496
Validation loss: 5.21194205681483

Epoch: 5| Step: 9
Training loss: 5.312315464019775
Validation loss: 5.205972651640574

Epoch: 5| Step: 10
Training loss: 5.658467769622803
Validation loss: 5.1999742190043134

Epoch: 5| Step: 11
Training loss: 5.752501964569092
Validation loss: 5.193758686383565

Epoch: 4| Step: 0
Training loss: 6.29266357421875
Validation loss: 5.1871325969696045

Epoch: 5| Step: 1
Training loss: 4.890438556671143
Validation loss: 5.180480003356934

Epoch: 5| Step: 2
Training loss: 5.554483413696289
Validation loss: 5.173593501249949

Epoch: 5| Step: 3
Training loss: 6.003897190093994
Validation loss: 5.166601697603862

Epoch: 5| Step: 4
Training loss: 4.830269813537598
Validation loss: 5.1594982743263245

Epoch: 5| Step: 5
Training loss: 5.543653964996338
Validation loss: 5.152221242586772

Epoch: 5| Step: 6
Training loss: 5.422100067138672
Validation loss: 5.1448918382326765

Epoch: 5| Step: 7
Training loss: 4.6509504318237305
Validation loss: 5.136968274911244

Epoch: 5| Step: 8
Training loss: 5.551030158996582
Validation loss: 5.129245380560557

Epoch: 5| Step: 9
Training loss: 4.719989776611328
Validation loss: 5.121290942033132

Epoch: 5| Step: 10
Training loss: 3.9305331707000732
Validation loss: 5.1133478085199995

Epoch: 5| Step: 11
Training loss: 5.559577465057373
Validation loss: 5.104820132255554

Epoch: 5| Step: 0
Training loss: 5.434460639953613
Validation loss: 5.096457103888194

Epoch: 5| Step: 1
Training loss: 4.525323390960693
Validation loss: 5.087996343771617

Epoch: 5| Step: 2
Training loss: 5.534111976623535
Validation loss: 5.0795057614644366

Epoch: 5| Step: 3
Training loss: 6.005527019500732
Validation loss: 5.070534308751424

Epoch: 5| Step: 4
Training loss: 5.11535120010376
Validation loss: 5.061510493357976

Epoch: 5| Step: 5
Training loss: 5.3465704917907715
Validation loss: 5.0522834459940595

Epoch: 5| Step: 6
Training loss: 4.75302791595459
Validation loss: 5.042938371499379

Epoch: 5| Step: 7
Training loss: 5.397353172302246
Validation loss: 5.033164819081624

Epoch: 5| Step: 8
Training loss: 3.9644577503204346
Validation loss: 5.023364921410878

Epoch: 5| Step: 9
Training loss: 5.384693622589111
Validation loss: 5.012910962104797

Epoch: 5| Step: 10
Training loss: 5.011404514312744
Validation loss: 5.002737353245418

Epoch: 5| Step: 11
Training loss: 4.785499095916748
Validation loss: 4.992282440265019

Epoch: 6| Step: 0
Training loss: 5.585234642028809
Validation loss: 4.981452564398448

Epoch: 5| Step: 1
Training loss: 5.06899881362915
Validation loss: 4.971067567666371

Epoch: 5| Step: 2
Training loss: 4.599398136138916
Validation loss: 4.959676444530487

Epoch: 5| Step: 3
Training loss: 5.5745954513549805
Validation loss: 4.948492209116618

Epoch: 5| Step: 4
Training loss: 5.216323375701904
Validation loss: 4.937590738137563

Epoch: 5| Step: 5
Training loss: 3.4338364601135254
Validation loss: 4.926120658715566

Epoch: 5| Step: 6
Training loss: 5.274888515472412
Validation loss: 4.914614975452423

Epoch: 5| Step: 7
Training loss: 5.406410217285156
Validation loss: 4.902513960997264

Epoch: 5| Step: 8
Training loss: 6.1416778564453125
Validation loss: 4.891171991825104

Epoch: 5| Step: 9
Training loss: 5.272851467132568
Validation loss: 4.8788625200589495

Epoch: 5| Step: 10
Training loss: 3.7276673316955566
Validation loss: 4.867129147052765

Epoch: 5| Step: 11
Training loss: 3.9336671829223633
Validation loss: 4.855171422163646

Epoch: 7| Step: 0
Training loss: 4.203814506530762
Validation loss: 4.8437320192654925

Epoch: 5| Step: 1
Training loss: 4.935510158538818
Validation loss: 4.832249661286672

Epoch: 5| Step: 2
Training loss: 4.380775451660156
Validation loss: 4.821259637673696

Epoch: 5| Step: 3
Training loss: 4.677250862121582
Validation loss: 4.8097619613011675

Epoch: 5| Step: 4
Training loss: 4.709164619445801
Validation loss: 4.799080530802409

Epoch: 5| Step: 5
Training loss: 5.105245590209961
Validation loss: 4.788166145483653

Epoch: 5| Step: 6
Training loss: 5.056708812713623
Validation loss: 4.7782294154167175

Epoch: 5| Step: 7
Training loss: 4.57590389251709
Validation loss: 4.768118480841319

Epoch: 5| Step: 8
Training loss: 5.750296592712402
Validation loss: 4.758113006750743

Epoch: 5| Step: 9
Training loss: 4.692377090454102
Validation loss: 4.748523096243541

Epoch: 5| Step: 10
Training loss: 5.481369495391846
Validation loss: 4.738540232181549

Epoch: 5| Step: 11
Training loss: 5.284598350524902
Validation loss: 4.728504200776418

Epoch: 8| Step: 0
Training loss: 4.769241809844971
Validation loss: 4.718511303265889

Epoch: 5| Step: 1
Training loss: 4.644217491149902
Validation loss: 4.709433456261952

Epoch: 5| Step: 2
Training loss: 4.998457431793213
Validation loss: 4.699922472238541

Epoch: 5| Step: 3
Training loss: 4.469097137451172
Validation loss: 4.690582305192947

Epoch: 5| Step: 4
Training loss: 4.874006271362305
Validation loss: 4.681796590487163

Epoch: 5| Step: 5
Training loss: 5.224095821380615
Validation loss: 4.673006574312846

Epoch: 5| Step: 6
Training loss: 5.681179046630859
Validation loss: 4.664422790209453

Epoch: 5| Step: 7
Training loss: 3.933065414428711
Validation loss: 4.656552930672963

Epoch: 5| Step: 8
Training loss: 4.405370235443115
Validation loss: 4.647843360900879

Epoch: 5| Step: 9
Training loss: 5.392103672027588
Validation loss: 4.639912883440654

Epoch: 5| Step: 10
Training loss: 4.083646774291992
Validation loss: 4.631858944892883

Epoch: 5| Step: 11
Training loss: 4.649567604064941
Validation loss: 4.623966226975123

Epoch: 9| Step: 0
Training loss: 4.505883693695068
Validation loss: 4.616343428691228

Epoch: 5| Step: 1
Training loss: 4.326571464538574
Validation loss: 4.6089904109636946

Epoch: 5| Step: 2
Training loss: 5.161801815032959
Validation loss: 4.601300915082295

Epoch: 5| Step: 3
Training loss: 4.843911170959473
Validation loss: 4.5937515298525495

Epoch: 5| Step: 4
Training loss: 4.601690769195557
Validation loss: 4.586258798837662

Epoch: 5| Step: 5
Training loss: 4.427762508392334
Validation loss: 4.578470766544342

Epoch: 5| Step: 6
Training loss: 4.557768821716309
Validation loss: 4.570582926273346

Epoch: 5| Step: 7
Training loss: 4.801770210266113
Validation loss: 4.562658429145813

Epoch: 5| Step: 8
Training loss: 4.460540771484375
Validation loss: 4.555122196674347

Epoch: 5| Step: 9
Training loss: 5.278208255767822
Validation loss: 4.548169483741124

Epoch: 5| Step: 10
Training loss: 4.2495012283325195
Validation loss: 4.541158934434255

Epoch: 5| Step: 11
Training loss: 5.854215621948242
Validation loss: 4.534112393856049

Epoch: 10| Step: 0
Training loss: 4.628594875335693
Validation loss: 4.52688804268837

Epoch: 5| Step: 1
Training loss: 4.0615057945251465
Validation loss: 4.519305785497029

Epoch: 5| Step: 2
Training loss: 4.383649826049805
Validation loss: 4.512492696444194

Epoch: 5| Step: 3
Training loss: 5.092101573944092
Validation loss: 4.505255550146103

Epoch: 5| Step: 4
Training loss: 5.28761100769043
Validation loss: 4.49797722697258

Epoch: 5| Step: 5
Training loss: 5.119871139526367
Validation loss: 4.49116587638855

Epoch: 5| Step: 6
Training loss: 5.378603458404541
Validation loss: 4.484415590763092

Epoch: 5| Step: 7
Training loss: 3.8065528869628906
Validation loss: 4.477244198322296

Epoch: 5| Step: 8
Training loss: 4.238025665283203
Validation loss: 4.470897972583771

Epoch: 5| Step: 9
Training loss: 4.695877552032471
Validation loss: 4.463794728120168

Epoch: 5| Step: 10
Training loss: 3.5617942810058594
Validation loss: 4.457439512014389

Epoch: 5| Step: 11
Training loss: 6.239202976226807
Validation loss: 4.450899163881938

Epoch: 11| Step: 0
Training loss: 4.3197526931762695
Validation loss: 4.444456577301025

Epoch: 5| Step: 1
Training loss: 5.042240142822266
Validation loss: 4.437828838825226

Epoch: 5| Step: 2
Training loss: 5.155486583709717
Validation loss: 4.430813491344452

Epoch: 5| Step: 3
Training loss: 4.262497901916504
Validation loss: 4.4243015348911285

Epoch: 5| Step: 4
Training loss: 4.809033393859863
Validation loss: 4.417773544788361

Epoch: 5| Step: 5
Training loss: 5.576545715332031
Validation loss: 4.411760906378428

Epoch: 5| Step: 6
Training loss: 4.089157581329346
Validation loss: 4.405247718095779

Epoch: 5| Step: 7
Training loss: 3.998316526412964
Validation loss: 4.3987522919972735

Epoch: 5| Step: 8
Training loss: 5.272513389587402
Validation loss: 4.3931271731853485

Epoch: 5| Step: 9
Training loss: 4.20866584777832
Validation loss: 4.386973897616069

Epoch: 5| Step: 10
Training loss: 3.5971884727478027
Validation loss: 4.3813567360242205

Epoch: 5| Step: 11
Training loss: 1.9251506328582764
Validation loss: 4.3757034341494245

Epoch: 12| Step: 0
Training loss: 5.400615215301514
Validation loss: 4.3710076212883

Epoch: 5| Step: 1
Training loss: 4.7415313720703125
Validation loss: 4.367654919624329

Epoch: 5| Step: 2
Training loss: 4.238330364227295
Validation loss: 4.3621750473976135

Epoch: 5| Step: 3
Training loss: 4.655221462249756
Validation loss: 4.356254994869232

Epoch: 5| Step: 4
Training loss: 4.561212062835693
Validation loss: 4.34976248939832

Epoch: 5| Step: 5
Training loss: 4.430781364440918
Validation loss: 4.344734052817027

Epoch: 5| Step: 6
Training loss: 4.148061275482178
Validation loss: 4.340362469355266

Epoch: 5| Step: 7
Training loss: 4.863308906555176
Validation loss: 4.3356359998385114

Epoch: 5| Step: 8
Training loss: 4.0150885581970215
Validation loss: 4.330260157585144

Epoch: 5| Step: 9
Training loss: 3.5294928550720215
Validation loss: 4.325027336676915

Epoch: 5| Step: 10
Training loss: 4.231368064880371
Validation loss: 4.319375991821289

Epoch: 5| Step: 11
Training loss: 6.041072845458984
Validation loss: 4.31443719069163

Epoch: 13| Step: 0
Training loss: 4.425146579742432
Validation loss: 4.310106386741002

Epoch: 5| Step: 1
Training loss: 5.427894592285156
Validation loss: 4.3065130313237505

Epoch: 5| Step: 2
Training loss: 4.448995113372803
Validation loss: 4.299670338630676

Epoch: 5| Step: 3
Training loss: 3.2484302520751953
Validation loss: 4.293115059534709

Epoch: 5| Step: 4
Training loss: 4.6524658203125
Validation loss: 4.2890501618385315

Epoch: 5| Step: 5
Training loss: 4.889805316925049
Validation loss: 4.28531946738561

Epoch: 5| Step: 6
Training loss: 3.813317060470581
Validation loss: 4.28171952565511

Epoch: 5| Step: 7
Training loss: 4.535362243652344
Validation loss: 4.275099108616511

Epoch: 5| Step: 8
Training loss: 3.7560863494873047
Validation loss: 4.2690634826819105

Epoch: 5| Step: 9
Training loss: 4.829517364501953
Validation loss: 4.262790699799855

Epoch: 5| Step: 10
Training loss: 4.677516937255859
Validation loss: 4.256777375936508

Epoch: 5| Step: 11
Training loss: 3.4830541610717773
Validation loss: 4.25140114625295

Epoch: 14| Step: 0
Training loss: 4.725436210632324
Validation loss: 4.247352461020152

Epoch: 5| Step: 1
Training loss: 4.435214519500732
Validation loss: 4.2450255155563354

Epoch: 5| Step: 2
Training loss: 4.041991233825684
Validation loss: 4.237504094839096

Epoch: 5| Step: 3
Training loss: 4.07432222366333
Validation loss: 4.231682459513347

Epoch: 5| Step: 4
Training loss: 3.928244113922119
Validation loss: 4.226096232732137

Epoch: 5| Step: 5
Training loss: 5.14638090133667
Validation loss: 4.221479336420695

Epoch: 5| Step: 6
Training loss: 5.056982517242432
Validation loss: 4.216141661008199

Epoch: 5| Step: 7
Training loss: 4.419663429260254
Validation loss: 4.211568862199783

Epoch: 5| Step: 8
Training loss: 3.950049638748169
Validation loss: 4.206527193387349

Epoch: 5| Step: 9
Training loss: 3.884514331817627
Validation loss: 4.200827270746231

Epoch: 5| Step: 10
Training loss: 4.492673397064209
Validation loss: 4.195648471514384

Epoch: 5| Step: 11
Training loss: 2.9600558280944824
Validation loss: 4.1903201043605804

Epoch: 15| Step: 0
Training loss: 4.290538787841797
Validation loss: 4.1854996383190155

Epoch: 5| Step: 1
Training loss: 4.603626251220703
Validation loss: 4.181108425060908

Epoch: 5| Step: 2
Training loss: 4.27535343170166
Validation loss: 4.176023374001185

Epoch: 5| Step: 3
Training loss: 5.200815677642822
Validation loss: 4.169800211985906

Epoch: 5| Step: 4
Training loss: 5.257719993591309
Validation loss: 4.16474324464798

Epoch: 5| Step: 5
Training loss: 2.966959238052368
Validation loss: 4.159244954586029

Epoch: 5| Step: 6
Training loss: 3.7469658851623535
Validation loss: 4.153121888637543

Epoch: 5| Step: 7
Training loss: 3.8164119720458984
Validation loss: 4.149290144443512

Epoch: 5| Step: 8
Training loss: 4.57841682434082
Validation loss: 4.143531908591588

Epoch: 5| Step: 9
Training loss: 4.577870845794678
Validation loss: 4.1385019818941755

Epoch: 5| Step: 10
Training loss: 4.145517826080322
Validation loss: 4.133821686108907

Epoch: 5| Step: 11
Training loss: 3.2922656536102295
Validation loss: 4.129256367683411

Epoch: 16| Step: 0
Training loss: 3.811788558959961
Validation loss: 4.123667309681575

Epoch: 5| Step: 1
Training loss: 4.150890350341797
Validation loss: 4.1183938682079315

Epoch: 5| Step: 2
Training loss: 4.783698558807373
Validation loss: 4.114964763323466

Epoch: 5| Step: 3
Training loss: 4.038819789886475
Validation loss: 4.109909216562907

Epoch: 5| Step: 4
Training loss: 3.1963086128234863
Validation loss: 4.104714939991633

Epoch: 5| Step: 5
Training loss: 4.923239231109619
Validation loss: 4.099369088808696

Epoch: 5| Step: 6
Training loss: 4.915186405181885
Validation loss: 4.0941033363342285

Epoch: 5| Step: 7
Training loss: 4.506194591522217
Validation loss: 4.088880628347397

Epoch: 5| Step: 8
Training loss: 3.8988330364227295
Validation loss: 4.084267238775889

Epoch: 5| Step: 9
Training loss: 4.5675787925720215
Validation loss: 4.079212655623754

Epoch: 5| Step: 10
Training loss: 4.019008636474609
Validation loss: 4.074737221002579

Epoch: 5| Step: 11
Training loss: 3.388795852661133
Validation loss: 4.0691731969515486

Epoch: 17| Step: 0
Training loss: 2.9350152015686035
Validation loss: 4.064703782399495

Epoch: 5| Step: 1
Training loss: 3.3469691276550293
Validation loss: 4.06026687224706

Epoch: 5| Step: 2
Training loss: 4.0759501457214355
Validation loss: 4.05506573120753

Epoch: 5| Step: 3
Training loss: 4.400253772735596
Validation loss: 4.049955040216446

Epoch: 5| Step: 4
Training loss: 3.585947036743164
Validation loss: 4.044737895329793

Epoch: 5| Step: 5
Training loss: 4.337090492248535
Validation loss: 4.040827403465907

Epoch: 5| Step: 6
Training loss: 4.709602355957031
Validation loss: 4.035752276579539

Epoch: 5| Step: 7
Training loss: 5.203153610229492
Validation loss: 4.032292366027832

Epoch: 5| Step: 8
Training loss: 4.630360126495361
Validation loss: 4.02596914768219

Epoch: 5| Step: 9
Training loss: 5.031734943389893
Validation loss: 4.020820736885071

Epoch: 5| Step: 10
Training loss: 3.4609687328338623
Validation loss: 4.015769104162852

Epoch: 5| Step: 11
Training loss: 5.726531982421875
Validation loss: 4.011052946249644

Epoch: 18| Step: 0
Training loss: 4.3135600090026855
Validation loss: 4.006283283233643

Epoch: 5| Step: 1
Training loss: 3.5393853187561035
Validation loss: 4.001423488060634

Epoch: 5| Step: 2
Training loss: 4.111719608306885
Validation loss: 3.996611307064692

Epoch: 5| Step: 3
Training loss: 4.649107456207275
Validation loss: 3.9914600551128387

Epoch: 5| Step: 4
Training loss: 4.929469585418701
Validation loss: 3.9863450030485788

Epoch: 5| Step: 5
Training loss: 4.13107967376709
Validation loss: 3.9814096788565316

Epoch: 5| Step: 6
Training loss: 3.992504596710205
Validation loss: 3.9767427841822305

Epoch: 5| Step: 7
Training loss: 3.3630032539367676
Validation loss: 3.971599926551183

Epoch: 5| Step: 8
Training loss: 4.043824195861816
Validation loss: 3.9669531087080636

Epoch: 5| Step: 9
Training loss: 3.914557695388794
Validation loss: 3.962205787499746

Epoch: 5| Step: 10
Training loss: 4.718480587005615
Validation loss: 3.956960807243983

Epoch: 5| Step: 11
Training loss: 2.598813056945801
Validation loss: 3.952296038468679

Epoch: 19| Step: 0
Training loss: 3.6539249420166016
Validation loss: 3.9475072224934897

Epoch: 5| Step: 1
Training loss: 5.2809553146362305
Validation loss: 3.942771722873052

Epoch: 5| Step: 2
Training loss: 4.4777140617370605
Validation loss: 3.938525289297104

Epoch: 5| Step: 3
Training loss: 4.3407673835754395
Validation loss: 3.9344911674658456

Epoch: 5| Step: 4
Training loss: 3.323127269744873
Validation loss: 3.9294716914494834

Epoch: 5| Step: 5
Training loss: 3.7832343578338623
Validation loss: 3.9252406458059945

Epoch: 5| Step: 6
Training loss: 3.1328001022338867
Validation loss: 3.920347442229589

Epoch: 5| Step: 7
Training loss: 4.867811679840088
Validation loss: 3.9154798289140067

Epoch: 5| Step: 8
Training loss: 3.8553428649902344
Validation loss: 3.9102603693803153

Epoch: 5| Step: 9
Training loss: 4.19388484954834
Validation loss: 3.90529203414917

Epoch: 5| Step: 10
Training loss: 3.9993526935577393
Validation loss: 3.899933954079946

Epoch: 5| Step: 11
Training loss: 3.5136218070983887
Validation loss: 3.8969167172908783

Epoch: 20| Step: 0
Training loss: 4.327110290527344
Validation loss: 3.8927326699097953

Epoch: 5| Step: 1
Training loss: 4.3585309982299805
Validation loss: 3.8864130675792694

Epoch: 5| Step: 2
Training loss: 3.6551947593688965
Validation loss: 3.880924314260483

Epoch: 5| Step: 3
Training loss: 4.646503925323486
Validation loss: 3.8755818009376526

Epoch: 5| Step: 4
Training loss: 3.5728554725646973
Validation loss: 3.8715545535087585

Epoch: 5| Step: 5
Training loss: 4.433629035949707
Validation loss: 3.867705682913462

Epoch: 5| Step: 6
Training loss: 3.814993381500244
Validation loss: 3.8619028131167092

Epoch: 5| Step: 7
Training loss: 3.765834331512451
Validation loss: 3.8565597037474313

Epoch: 5| Step: 8
Training loss: 3.9785454273223877
Validation loss: 3.8506970703601837

Epoch: 5| Step: 9
Training loss: 4.048753261566162
Validation loss: 3.8470028837521872

Epoch: 5| Step: 10
Training loss: 3.5533156394958496
Validation loss: 3.8420487344264984

Epoch: 5| Step: 11
Training loss: 4.190106391906738
Validation loss: 3.8387272357940674

Epoch: 21| Step: 0
Training loss: 3.6291797161102295
Validation loss: 3.8345268865426383

Epoch: 5| Step: 1
Training loss: 4.234508037567139
Validation loss: 3.8255276580651603

Epoch: 5| Step: 2
Training loss: 3.641040802001953
Validation loss: 3.8208035230636597

Epoch: 5| Step: 3
Training loss: 4.499361515045166
Validation loss: 3.8162995278835297

Epoch: 5| Step: 4
Training loss: 4.18140172958374
Validation loss: 3.812132845322291

Epoch: 5| Step: 5
Training loss: 2.729358673095703
Validation loss: 3.805436074733734

Epoch: 5| Step: 6
Training loss: 3.074619770050049
Validation loss: 3.799738963445028

Epoch: 5| Step: 7
Training loss: 4.48119592666626
Validation loss: 3.7949294050534568

Epoch: 5| Step: 8
Training loss: 3.7523021697998047
Validation loss: 3.7894872426986694

Epoch: 5| Step: 9
Training loss: 4.615143775939941
Validation loss: 3.7840011219183602

Epoch: 5| Step: 10
Training loss: 4.6363325119018555
Validation loss: 3.7791929244995117

Epoch: 5| Step: 11
Training loss: 4.460990905761719
Validation loss: 3.77384881178538

Epoch: 22| Step: 0
Training loss: 3.636239528656006
Validation loss: 3.7678356568018594

Epoch: 5| Step: 1
Training loss: 3.62939715385437
Validation loss: 3.7633547286192575

Epoch: 5| Step: 2
Training loss: 4.311461925506592
Validation loss: 3.7589825292428336

Epoch: 5| Step: 3
Training loss: 4.125823974609375
Validation loss: 3.7552649974823

Epoch: 5| Step: 4
Training loss: 4.56441068649292
Validation loss: 3.7482467591762543

Epoch: 5| Step: 5
Training loss: 3.216352939605713
Validation loss: 3.7416645685831704

Epoch: 5| Step: 6
Training loss: 3.8716559410095215
Validation loss: 3.737040708462397

Epoch: 5| Step: 7
Training loss: 4.01988410949707
Validation loss: 3.7332303722699485

Epoch: 5| Step: 8
Training loss: 3.833510160446167
Validation loss: 3.726586639881134

Epoch: 5| Step: 9
Training loss: 3.244091749191284
Validation loss: 3.721791446208954

Epoch: 5| Step: 10
Training loss: 3.9683003425598145
Validation loss: 3.715802182753881

Epoch: 5| Step: 11
Training loss: 6.430290699005127
Validation loss: 3.7110978762308755

Epoch: 23| Step: 0
Training loss: 3.912895917892456
Validation loss: 3.705423206090927

Epoch: 5| Step: 1
Training loss: 3.8589375019073486
Validation loss: 3.7005712389945984

Epoch: 5| Step: 2
Training loss: 2.7843358516693115
Validation loss: 3.6965582768122354

Epoch: 5| Step: 3
Training loss: 3.165851593017578
Validation loss: 3.6926255226135254

Epoch: 5| Step: 4
Training loss: 4.2032647132873535
Validation loss: 3.6866341829299927

Epoch: 5| Step: 5
Training loss: 3.939142942428589
Validation loss: 3.681149035692215

Epoch: 5| Step: 6
Training loss: 4.088269233703613
Validation loss: 3.6766695976257324

Epoch: 5| Step: 7
Training loss: 4.390021324157715
Validation loss: 3.671282152334849

Epoch: 5| Step: 8
Training loss: 3.6403679847717285
Validation loss: 3.667646606763204

Epoch: 5| Step: 9
Training loss: 4.047242641448975
Validation loss: 3.6616099973519645

Epoch: 5| Step: 10
Training loss: 4.447361946105957
Validation loss: 3.6559994320074716

Epoch: 5| Step: 11
Training loss: 2.719418525695801
Validation loss: 3.6517512003580728

Epoch: 24| Step: 0
Training loss: 3.4774703979492188
Validation loss: 3.6465758085250854

Epoch: 5| Step: 1
Training loss: 3.1043450832366943
Validation loss: 3.642045478026072

Epoch: 5| Step: 2
Training loss: 2.8557395935058594
Validation loss: 3.6370321214199066

Epoch: 5| Step: 3
Training loss: 3.752009630203247
Validation loss: 3.6316902140776315

Epoch: 5| Step: 4
Training loss: 3.4112274646759033
Validation loss: 3.6269408563772836

Epoch: 5| Step: 5
Training loss: 3.7431247234344482
Validation loss: 3.6214045186837516

Epoch: 5| Step: 6
Training loss: 3.7045505046844482
Validation loss: 3.618782897790273

Epoch: 5| Step: 7
Training loss: 4.841849327087402
Validation loss: 3.6150028705596924

Epoch: 5| Step: 8
Training loss: 3.5647404193878174
Validation loss: 3.608538568019867

Epoch: 5| Step: 9
Training loss: 4.825991153717041
Validation loss: 3.6027762790520987

Epoch: 5| Step: 10
Training loss: 4.1985273361206055
Validation loss: 3.599280536174774

Epoch: 5| Step: 11
Training loss: 4.528115272521973
Validation loss: 3.593251417080561

Epoch: 25| Step: 0
Training loss: 3.8754684925079346
Validation loss: 3.5892455180486045

Epoch: 5| Step: 1
Training loss: 4.534486293792725
Validation loss: 3.5843717654546103

Epoch: 5| Step: 2
Training loss: 3.991119384765625
Validation loss: 3.578893413146337

Epoch: 5| Step: 3
Training loss: 3.063920259475708
Validation loss: 3.574001987775167

Epoch: 5| Step: 4
Training loss: 4.116816997528076
Validation loss: 3.5678612887859344

Epoch: 5| Step: 5
Training loss: 3.6968886852264404
Validation loss: 3.562843312819799

Epoch: 5| Step: 6
Training loss: 3.5955429077148438
Validation loss: 3.5582642455895743

Epoch: 5| Step: 7
Training loss: 4.273324012756348
Validation loss: 3.553352783123652

Epoch: 5| Step: 8
Training loss: 3.1386241912841797
Validation loss: 3.548940281073252

Epoch: 5| Step: 9
Training loss: 2.94524884223938
Validation loss: 3.542497823635737

Epoch: 5| Step: 10
Training loss: 3.6144134998321533
Validation loss: 3.539727568626404

Epoch: 5| Step: 11
Training loss: 4.463374614715576
Validation loss: 3.5343414147694907

Epoch: 26| Step: 0
Training loss: 3.582728862762451
Validation loss: 3.529457380374273

Epoch: 5| Step: 1
Training loss: 2.92626953125
Validation loss: 3.522617131471634

Epoch: 5| Step: 2
Training loss: 3.5847129821777344
Validation loss: 3.51903173327446

Epoch: 5| Step: 3
Training loss: 3.704934597015381
Validation loss: 3.515060325463613

Epoch: 5| Step: 4
Training loss: 4.043459892272949
Validation loss: 3.509841779867808

Epoch: 5| Step: 5
Training loss: 2.713266134262085
Validation loss: 3.504463404417038

Epoch: 5| Step: 6
Training loss: 4.348806858062744
Validation loss: 3.4995830357074738

Epoch: 5| Step: 7
Training loss: 3.6592507362365723
Validation loss: 3.495728611946106

Epoch: 5| Step: 8
Training loss: 4.059747219085693
Validation loss: 3.490239222844442

Epoch: 5| Step: 9
Training loss: 3.661965847015381
Validation loss: 3.486377398173014

Epoch: 5| Step: 10
Training loss: 3.7649269104003906
Validation loss: 3.480984697739283

Epoch: 5| Step: 11
Training loss: 5.1938371658325195
Validation loss: 3.475368102391561

Epoch: 27| Step: 0
Training loss: 3.793997287750244
Validation loss: 3.47055584192276

Epoch: 5| Step: 1
Training loss: 4.096013069152832
Validation loss: 3.4648609459400177

Epoch: 5| Step: 2
Training loss: 3.5639541149139404
Validation loss: 3.4597857296466827

Epoch: 5| Step: 3
Training loss: 4.372298240661621
Validation loss: 3.4547715981801352

Epoch: 5| Step: 4
Training loss: 3.440282106399536
Validation loss: 3.4496483405431113

Epoch: 5| Step: 5
Training loss: 3.9059383869171143
Validation loss: 3.4440868894259133

Epoch: 5| Step: 6
Training loss: 3.771923780441284
Validation loss: 3.4408400853474936

Epoch: 5| Step: 7
Training loss: 2.9333291053771973
Validation loss: 3.4371472795804343

Epoch: 5| Step: 8
Training loss: 3.9637961387634277
Validation loss: 3.4324874182542167

Epoch: 5| Step: 9
Training loss: 3.1088948249816895
Validation loss: 3.4268231292565665

Epoch: 5| Step: 10
Training loss: 2.9224276542663574
Validation loss: 3.4209206998348236

Epoch: 5| Step: 11
Training loss: 2.8734560012817383
Validation loss: 3.4174208839734397

Epoch: 28| Step: 0
Training loss: 3.3941569328308105
Validation loss: 3.4122509161631265

Epoch: 5| Step: 1
Training loss: 2.704418420791626
Validation loss: 3.408213367064794

Epoch: 5| Step: 2
Training loss: 4.4335198402404785
Validation loss: 3.403302123149236

Epoch: 5| Step: 3
Training loss: 3.3825912475585938
Validation loss: 3.398857206106186

Epoch: 5| Step: 4
Training loss: 3.06589937210083
Validation loss: 3.3953190247217813

Epoch: 5| Step: 5
Training loss: 4.281210899353027
Validation loss: 3.390810569127401

Epoch: 5| Step: 6
Training loss: 3.7600739002227783
Validation loss: 3.3862341245015464

Epoch: 5| Step: 7
Training loss: 3.9304492473602295
Validation loss: 3.381891200939814

Epoch: 5| Step: 8
Training loss: 3.7345404624938965
Validation loss: 3.376852124929428

Epoch: 5| Step: 9
Training loss: 2.9407174587249756
Validation loss: 3.3727327783902488

Epoch: 5| Step: 10
Training loss: 3.8614096641540527
Validation loss: 3.3673000633716583

Epoch: 5| Step: 11
Training loss: 1.706153392791748
Validation loss: 3.3632211685180664

Epoch: 29| Step: 0
Training loss: 3.5326240062713623
Validation loss: 3.3599323332309723

Epoch: 5| Step: 1
Training loss: 4.615919589996338
Validation loss: 3.3547013103961945

Epoch: 5| Step: 2
Training loss: 3.7622642517089844
Validation loss: 3.3493950267632804

Epoch: 5| Step: 3
Training loss: 3.370824098587036
Validation loss: 3.344952017068863

Epoch: 5| Step: 4
Training loss: 2.9157557487487793
Validation loss: 3.3405311504999795

Epoch: 5| Step: 5
Training loss: 3.2675979137420654
Validation loss: 3.3356652557849884

Epoch: 5| Step: 6
Training loss: 3.35901141166687
Validation loss: 3.3321101566155753

Epoch: 5| Step: 7
Training loss: 3.4266364574432373
Validation loss: 3.327474037806193

Epoch: 5| Step: 8
Training loss: 3.85553240776062
Validation loss: 3.323122670253118

Epoch: 5| Step: 9
Training loss: 3.2261359691619873
Validation loss: 3.3182824651400247

Epoch: 5| Step: 10
Training loss: 3.28499174118042
Validation loss: 3.31490159034729

Epoch: 5| Step: 11
Training loss: 3.387856960296631
Validation loss: 3.310361683368683

Epoch: 30| Step: 0
Training loss: 3.426631212234497
Validation loss: 3.305700788895289

Epoch: 5| Step: 1
Training loss: 3.9414970874786377
Validation loss: 3.301121493180593

Epoch: 5| Step: 2
Training loss: 3.3154265880584717
Validation loss: 3.2977142135302224

Epoch: 5| Step: 3
Training loss: 3.620742082595825
Validation loss: 3.2937792539596558

Epoch: 5| Step: 4
Training loss: 4.246531963348389
Validation loss: 3.289509783188502

Epoch: 5| Step: 5
Training loss: 3.700824737548828
Validation loss: 3.284569332997004

Epoch: 5| Step: 6
Training loss: 3.5934739112854004
Validation loss: 3.2810311516126

Epoch: 5| Step: 7
Training loss: 3.123657464981079
Validation loss: 3.277256747086843

Epoch: 5| Step: 8
Training loss: 3.21673321723938
Validation loss: 3.2724112371603646

Epoch: 5| Step: 9
Training loss: 2.932662010192871
Validation loss: 3.267631302277247

Epoch: 5| Step: 10
Training loss: 2.9281840324401855
Validation loss: 3.264128456513087

Epoch: 5| Step: 11
Training loss: 3.5758023262023926
Validation loss: 3.2606506745020547

Epoch: 31| Step: 0
Training loss: 3.219196319580078
Validation loss: 3.256267706553141

Epoch: 5| Step: 1
Training loss: 1.8791309595108032
Validation loss: 3.2521464824676514

Epoch: 5| Step: 2
Training loss: 3.971123456954956
Validation loss: 3.248018125693003

Epoch: 5| Step: 3
Training loss: 3.8252601623535156
Validation loss: 3.2448757688204446

Epoch: 5| Step: 4
Training loss: 3.8544907569885254
Validation loss: 3.2407354613145194

Epoch: 5| Step: 5
Training loss: 2.7233123779296875
Validation loss: 3.2366348803043365

Epoch: 5| Step: 6
Training loss: 4.104147434234619
Validation loss: 3.233661472797394

Epoch: 5| Step: 7
Training loss: 2.952425003051758
Validation loss: 3.2289250195026398

Epoch: 5| Step: 8
Training loss: 3.8165054321289062
Validation loss: 3.2249628603458405

Epoch: 5| Step: 9
Training loss: 3.3903374671936035
Validation loss: 3.2213324705759683

Epoch: 5| Step: 10
Training loss: 3.636190891265869
Validation loss: 3.217308541138967

Epoch: 5| Step: 11
Training loss: 4.188896179199219
Validation loss: 3.2130042910575867

Epoch: 32| Step: 0
Training loss: 4.485997676849365
Validation loss: 3.2081345518430076

Epoch: 5| Step: 1
Training loss: 3.490652561187744
Validation loss: 3.2036440471808114

Epoch: 5| Step: 2
Training loss: 2.4702389240264893
Validation loss: 3.1993855039278665

Epoch: 5| Step: 3
Training loss: 3.264700412750244
Validation loss: 3.1953056852022805

Epoch: 5| Step: 4
Training loss: 3.072389841079712
Validation loss: 3.1909280320008597

Epoch: 5| Step: 5
Training loss: 3.473784923553467
Validation loss: 3.186126401027044

Epoch: 5| Step: 6
Training loss: 3.117530345916748
Validation loss: 3.1825411717096963

Epoch: 5| Step: 7
Training loss: 3.550020694732666
Validation loss: 3.1780585249265036

Epoch: 5| Step: 8
Training loss: 3.708531141281128
Validation loss: 3.1739881932735443

Epoch: 5| Step: 9
Training loss: 3.4176979064941406
Validation loss: 3.169878045717875

Epoch: 5| Step: 10
Training loss: 2.990966320037842
Validation loss: 3.165771186351776

Epoch: 5| Step: 11
Training loss: 3.416628360748291
Validation loss: 3.16226393977801

Epoch: 33| Step: 0
Training loss: 2.790440320968628
Validation loss: 3.1568762759367623

Epoch: 5| Step: 1
Training loss: 2.745694875717163
Validation loss: 3.1532156566778817

Epoch: 5| Step: 2
Training loss: 2.6870224475860596
Validation loss: 3.1492525339126587

Epoch: 5| Step: 3
Training loss: 4.07388973236084
Validation loss: 3.1464215318361917

Epoch: 5| Step: 4
Training loss: 3.610752582550049
Validation loss: 3.1426648100217185

Epoch: 5| Step: 5
Training loss: 3.6752915382385254
Validation loss: 3.1381158034006753

Epoch: 5| Step: 6
Training loss: 3.092155694961548
Validation loss: 3.1345414916674295

Epoch: 5| Step: 7
Training loss: 3.627471923828125
Validation loss: 3.1298141181468964

Epoch: 5| Step: 8
Training loss: 3.193988800048828
Validation loss: 3.1255991955598197

Epoch: 5| Step: 9
Training loss: 4.1435112953186035
Validation loss: 3.122813512881597

Epoch: 5| Step: 10
Training loss: 2.8954434394836426
Validation loss: 3.1185052196184793

Epoch: 5| Step: 11
Training loss: 3.3638932704925537
Validation loss: 3.114468981822332

Epoch: 34| Step: 0
Training loss: 3.0605781078338623
Validation loss: 3.110539654890696

Epoch: 5| Step: 1
Training loss: 3.084350109100342
Validation loss: 3.107884486516317

Epoch: 5| Step: 2
Training loss: 3.4209914207458496
Validation loss: 3.10258016983668

Epoch: 5| Step: 3
Training loss: 3.2172131538391113
Validation loss: 3.0987560550371804

Epoch: 5| Step: 4
Training loss: 3.661975383758545
Validation loss: 3.0950815081596375

Epoch: 5| Step: 5
Training loss: 3.249047040939331
Validation loss: 3.091427971919378

Epoch: 5| Step: 6
Training loss: 3.0427117347717285
Validation loss: 3.0882148842016854

Epoch: 5| Step: 7
Training loss: 2.9528422355651855
Validation loss: 3.0850037137667337

Epoch: 5| Step: 8
Training loss: 3.248124361038208
Validation loss: 3.0812617043654122

Epoch: 5| Step: 9
Training loss: 3.2329559326171875
Validation loss: 3.0780070225397744

Epoch: 5| Step: 10
Training loss: 3.710855007171631
Validation loss: 3.074745923280716

Epoch: 5| Step: 11
Training loss: 4.271669387817383
Validation loss: 3.0713886817296348

Epoch: 35| Step: 0
Training loss: 3.684086322784424
Validation loss: 3.06695627172788

Epoch: 5| Step: 1
Training loss: 3.1474204063415527
Validation loss: 3.0636477967103324

Epoch: 5| Step: 2
Training loss: 3.0449092388153076
Validation loss: 3.0599888066450753

Epoch: 5| Step: 3
Training loss: 2.9204609394073486
Validation loss: 3.0560670594374337

Epoch: 5| Step: 4
Training loss: 3.6110281944274902
Validation loss: 3.0529673298199973

Epoch: 5| Step: 5
Training loss: 2.7700958251953125
Validation loss: 3.049043834209442

Epoch: 5| Step: 6
Training loss: 3.871426820755005
Validation loss: 3.0457103153069816

Epoch: 5| Step: 7
Training loss: 3.134678363800049
Validation loss: 3.048148036003113

Epoch: 5| Step: 8
Training loss: 3.366671085357666
Validation loss: 3.0389597912629447

Epoch: 5| Step: 9
Training loss: 2.5956568717956543
Validation loss: 3.034673184156418

Epoch: 5| Step: 10
Training loss: 3.0775771141052246
Validation loss: 3.0320247610410056

Epoch: 5| Step: 11
Training loss: 5.199219226837158
Validation loss: 3.0291704138120017

Epoch: 36| Step: 0
Training loss: 3.855259656906128
Validation loss: 3.025705357392629

Epoch: 5| Step: 1
Training loss: 3.466388702392578
Validation loss: 3.0218059619267783

Epoch: 5| Step: 2
Training loss: 2.578911542892456
Validation loss: 3.0174849530061087

Epoch: 5| Step: 3
Training loss: 3.137444496154785
Validation loss: 3.0139868557453156

Epoch: 5| Step: 4
Training loss: 2.9444146156311035
Validation loss: 3.0110483169555664

Epoch: 5| Step: 5
Training loss: 3.2278475761413574
Validation loss: 3.00804336865743

Epoch: 5| Step: 6
Training loss: 2.9837825298309326
Validation loss: 3.002877563238144

Epoch: 5| Step: 7
Training loss: 2.7588980197906494
Validation loss: 2.9993900855382285

Epoch: 5| Step: 8
Training loss: 2.893003463745117
Validation loss: 2.995187689860662

Epoch: 5| Step: 9
Training loss: 3.389086961746216
Validation loss: 2.992377370595932

Epoch: 5| Step: 10
Training loss: 3.956529140472412
Validation loss: 2.9897351364294686

Epoch: 5| Step: 11
Training loss: 3.129359006881714
Validation loss: 2.9851905703544617

Epoch: 37| Step: 0
Training loss: 3.3079566955566406
Validation loss: 2.9810059467951455

Epoch: 5| Step: 1
Training loss: 2.854403018951416
Validation loss: 2.977690637111664

Epoch: 5| Step: 2
Training loss: 3.5328636169433594
Validation loss: 2.97437114516894

Epoch: 5| Step: 3
Training loss: 2.9361910820007324
Validation loss: 2.9699796040852866

Epoch: 5| Step: 4
Training loss: 2.5188469886779785
Validation loss: 2.966984142859777

Epoch: 5| Step: 5
Training loss: 2.711998701095581
Validation loss: 2.9627476930618286

Epoch: 5| Step: 6
Training loss: 2.937734603881836
Validation loss: 2.95892067750295

Epoch: 5| Step: 7
Training loss: 3.3022098541259766
Validation loss: 2.9557694594065347

Epoch: 5| Step: 8
Training loss: 4.325827121734619
Validation loss: 2.953037440776825

Epoch: 5| Step: 9
Training loss: 3.327117919921875
Validation loss: 2.9500427146752677

Epoch: 5| Step: 10
Training loss: 3.286465883255005
Validation loss: 2.945456395546595

Epoch: 5| Step: 11
Training loss: 1.6725056171417236
Validation loss: 2.943793833255768

Epoch: 38| Step: 0
Training loss: 3.9235939979553223
Validation loss: 2.9392374952634177

Epoch: 5| Step: 1
Training loss: 2.3952858448028564
Validation loss: 2.937854458888372

Epoch: 5| Step: 2
Training loss: 3.2205519676208496
Validation loss: 2.9314091006914773

Epoch: 5| Step: 3
Training loss: 3.3019440174102783
Validation loss: 2.928332527478536

Epoch: 5| Step: 4
Training loss: 3.1014151573181152
Validation loss: 2.9253578086694083

Epoch: 5| Step: 5
Training loss: 2.5119242668151855
Validation loss: 2.9225264191627502

Epoch: 5| Step: 6
Training loss: 2.8948657512664795
Validation loss: 2.920921911795934

Epoch: 5| Step: 7
Training loss: 3.3238556385040283
Validation loss: 2.9171376824378967

Epoch: 5| Step: 8
Training loss: 3.249403715133667
Validation loss: 2.9118582904338837

Epoch: 5| Step: 9
Training loss: 3.025665760040283
Validation loss: 2.9084444443384805

Epoch: 5| Step: 10
Training loss: 3.4116199016571045
Validation loss: 2.905525634686152

Epoch: 5| Step: 11
Training loss: 3.19956636428833
Validation loss: 2.902873625357946

Epoch: 39| Step: 0
Training loss: 2.773353099822998
Validation loss: 2.9003281394640603

Epoch: 5| Step: 1
Training loss: 3.621861219406128
Validation loss: 2.8975217044353485

Epoch: 5| Step: 2
Training loss: 3.697638988494873
Validation loss: 2.8933458626270294

Epoch: 5| Step: 3
Training loss: 2.7338645458221436
Validation loss: 2.88986544807752

Epoch: 5| Step: 4
Training loss: 2.6511683464050293
Validation loss: 2.8868316610654197

Epoch: 5| Step: 5
Training loss: 2.400266170501709
Validation loss: 2.8867619832356772

Epoch: 5| Step: 6
Training loss: 3.10471773147583
Validation loss: 2.8859773178895316

Epoch: 5| Step: 7
Training loss: 3.2278263568878174
Validation loss: 2.881236602862676

Epoch: 5| Step: 8
Training loss: 3.5442001819610596
Validation loss: 2.87748392422994

Epoch: 5| Step: 9
Training loss: 3.1769070625305176
Validation loss: 2.8731167217095694

Epoch: 5| Step: 10
Training loss: 3.0629711151123047
Validation loss: 2.869655728340149

Epoch: 5| Step: 11
Training loss: 2.8915903568267822
Validation loss: 2.865344067414602

Epoch: 40| Step: 0
Training loss: 2.6055920124053955
Validation loss: 2.8631327052911124

Epoch: 5| Step: 1
Training loss: 2.8948588371276855
Validation loss: 2.8604086140791574

Epoch: 5| Step: 2
Training loss: 3.30517315864563
Validation loss: 2.8572078744570413

Epoch: 5| Step: 3
Training loss: 3.102909564971924
Validation loss: 2.8531456689039865

Epoch: 5| Step: 4
Training loss: 2.615736961364746
Validation loss: 2.850456823905309

Epoch: 5| Step: 5
Training loss: 2.6062912940979004
Validation loss: 2.8482365111509957

Epoch: 5| Step: 6
Training loss: 3.364536762237549
Validation loss: 2.8456359207630157

Epoch: 5| Step: 7
Training loss: 3.526350498199463
Validation loss: 2.84102725982666

Epoch: 5| Step: 8
Training loss: 3.3381423950195312
Validation loss: 2.837102005879084

Epoch: 5| Step: 9
Training loss: 2.6422622203826904
Validation loss: 2.833726942539215

Epoch: 5| Step: 10
Training loss: 3.393115282058716
Validation loss: 2.8320051530996957

Epoch: 5| Step: 11
Training loss: 3.9639971256256104
Validation loss: 2.8272676169872284

Epoch: 41| Step: 0
Training loss: 3.1710493564605713
Validation loss: 2.8254382014274597

Epoch: 5| Step: 1
Training loss: 3.493643283843994
Validation loss: 2.8196324904759726

Epoch: 5| Step: 2
Training loss: 3.348341464996338
Validation loss: 2.8158606688181558

Epoch: 5| Step: 3
Training loss: 2.389599323272705
Validation loss: 2.814640372991562

Epoch: 5| Step: 4
Training loss: 2.9006810188293457
Validation loss: 2.81088133653005

Epoch: 5| Step: 5
Training loss: 3.427886486053467
Validation loss: 2.808253268400828

Epoch: 5| Step: 6
Training loss: 3.228163957595825
Validation loss: 2.8048430681228638

Epoch: 5| Step: 7
Training loss: 2.7355735301971436
Validation loss: 2.800383369127909

Epoch: 5| Step: 8
Training loss: 2.897881031036377
Validation loss: 2.798130730787913

Epoch: 5| Step: 9
Training loss: 2.819263458251953
Validation loss: 2.7945620715618134

Epoch: 5| Step: 10
Training loss: 2.9109020233154297
Validation loss: 2.7919076482454934

Epoch: 5| Step: 11
Training loss: 2.477907419204712
Validation loss: 2.7898875574270883

Epoch: 42| Step: 0
Training loss: 2.8944735527038574
Validation loss: 2.7877070605754852

Epoch: 5| Step: 1
Training loss: 3.889944553375244
Validation loss: 2.7896997928619385

Epoch: 5| Step: 2
Training loss: 2.8983914852142334
Validation loss: 2.7923956513404846

Epoch: 5| Step: 3
Training loss: 2.1489696502685547
Validation loss: 2.796326865752538

Epoch: 5| Step: 4
Training loss: 2.516388416290283
Validation loss: 2.789437164862951

Epoch: 5| Step: 5
Training loss: 3.6413936614990234
Validation loss: 2.779414484898249

Epoch: 5| Step: 6
Training loss: 3.097560405731201
Validation loss: 2.772332489490509

Epoch: 5| Step: 7
Training loss: 3.0556273460388184
Validation loss: 2.7696422139803567

Epoch: 5| Step: 8
Training loss: 3.2439472675323486
Validation loss: 2.765797813733419

Epoch: 5| Step: 9
Training loss: 2.7392170429229736
Validation loss: 2.7646967669328055

Epoch: 5| Step: 10
Training loss: 3.08377742767334
Validation loss: 2.763113180796305

Epoch: 5| Step: 11
Training loss: 1.0889966487884521
Validation loss: 2.7617627878983817

Epoch: 43| Step: 0
Training loss: 2.9265542030334473
Validation loss: 2.76113423705101

Epoch: 5| Step: 1
Training loss: 3.2131316661834717
Validation loss: 2.7589059273401895

Epoch: 5| Step: 2
Training loss: 2.541313409805298
Validation loss: 2.754080762465795

Epoch: 5| Step: 3
Training loss: 2.9039459228515625
Validation loss: 2.748970538377762

Epoch: 5| Step: 4
Training loss: 3.175140619277954
Validation loss: 2.746780256430308

Epoch: 5| Step: 5
Training loss: 3.2079319953918457
Validation loss: 2.743738075097402

Epoch: 5| Step: 6
Training loss: 2.67462420463562
Validation loss: 2.742708424727122

Epoch: 5| Step: 7
Training loss: 2.993959665298462
Validation loss: 2.739661991596222

Epoch: 5| Step: 8
Training loss: 3.3185501098632812
Validation loss: 2.7368603448073068

Epoch: 5| Step: 9
Training loss: 3.1438279151916504
Validation loss: 2.732539971669515

Epoch: 5| Step: 10
Training loss: 2.4431231021881104
Validation loss: 2.7296235064665475

Epoch: 5| Step: 11
Training loss: 2.706166982650757
Validation loss: 2.7247995138168335

Epoch: 44| Step: 0
Training loss: 3.2486495971679688
Validation loss: 2.723828891913096

Epoch: 5| Step: 1
Training loss: 2.2169418334960938
Validation loss: 2.7227073510487876

Epoch: 5| Step: 2
Training loss: 2.8497729301452637
Validation loss: 2.7267798682053885

Epoch: 5| Step: 3
Training loss: 3.431910753250122
Validation loss: 2.7244312167167664

Epoch: 5| Step: 4
Training loss: 3.3418140411376953
Validation loss: 2.7197465101877847

Epoch: 5| Step: 5
Training loss: 2.5380027294158936
Validation loss: 2.7093466321627298

Epoch: 5| Step: 6
Training loss: 2.9021148681640625
Validation loss: 2.706844667593638

Epoch: 5| Step: 7
Training loss: 2.578024387359619
Validation loss: 2.7060895760854087

Epoch: 5| Step: 8
Training loss: 2.7987637519836426
Validation loss: 2.704940527677536

Epoch: 5| Step: 9
Training loss: 2.9197826385498047
Validation loss: 2.703370451927185

Epoch: 5| Step: 10
Training loss: 3.0805890560150146
Validation loss: 2.7004948407411575

Epoch: 5| Step: 11
Training loss: 3.819256544113159
Validation loss: 2.695626844962438

Epoch: 45| Step: 0
Training loss: 2.692322254180908
Validation loss: 2.693506956100464

Epoch: 5| Step: 1
Training loss: 2.8588194847106934
Validation loss: 2.6908335983753204

Epoch: 5| Step: 2
Training loss: 3.439854860305786
Validation loss: 2.6855824291706085

Epoch: 5| Step: 3
Training loss: 2.2949259281158447
Validation loss: 2.68227681517601

Epoch: 5| Step: 4
Training loss: 3.403830051422119
Validation loss: 2.6784123182296753

Epoch: 5| Step: 5
Training loss: 3.1064279079437256
Validation loss: 2.6747026493151984

Epoch: 5| Step: 6
Training loss: 3.2275683879852295
Validation loss: 2.6705605884393058

Epoch: 5| Step: 7
Training loss: 2.5605363845825195
Validation loss: 2.668680260578791

Epoch: 5| Step: 8
Training loss: 2.558530330657959
Validation loss: 2.6656018992265067

Epoch: 5| Step: 9
Training loss: 3.0545573234558105
Validation loss: 2.66377130150795

Epoch: 5| Step: 10
Training loss: 2.334516763687134
Validation loss: 2.6607646544774375

Epoch: 5| Step: 11
Training loss: 3.6649177074432373
Validation loss: 2.658434142669042

Epoch: 46| Step: 0
Training loss: 2.3311562538146973
Validation loss: 2.653406113386154

Epoch: 5| Step: 1
Training loss: 3.158240795135498
Validation loss: 2.649942616621653

Epoch: 5| Step: 2
Training loss: 2.8879547119140625
Validation loss: 2.6482342183589935

Epoch: 5| Step: 3
Training loss: 2.4224066734313965
Validation loss: 2.645902375380198

Epoch: 5| Step: 4
Training loss: 2.9853129386901855
Validation loss: 2.642347733179728

Epoch: 5| Step: 5
Training loss: 2.666740894317627
Validation loss: 2.6420790950457254

Epoch: 5| Step: 6
Training loss: 2.609166383743286
Validation loss: 2.6387365758419037

Epoch: 5| Step: 7
Training loss: 2.783151149749756
Validation loss: 2.635088970263799

Epoch: 5| Step: 8
Training loss: 3.3189690113067627
Validation loss: 2.6323090891043344

Epoch: 5| Step: 9
Training loss: 2.956700086593628
Validation loss: 2.629281222820282

Epoch: 5| Step: 10
Training loss: 3.0079689025878906
Validation loss: 2.6279609203338623

Epoch: 5| Step: 11
Training loss: 3.5478389263153076
Validation loss: 2.6238401929537454

Epoch: 47| Step: 0
Training loss: 2.7929327487945557
Validation loss: 2.6211292147636414

Epoch: 5| Step: 1
Training loss: 2.678226947784424
Validation loss: 2.617708990971247

Epoch: 5| Step: 2
Training loss: 2.658571720123291
Validation loss: 2.6140978882710137

Epoch: 5| Step: 3
Training loss: 2.5401253700256348
Validation loss: 2.6147369047005973

Epoch: 5| Step: 4
Training loss: 2.4256558418273926
Validation loss: 2.6149263878663382

Epoch: 5| Step: 5
Training loss: 3.180908679962158
Validation loss: 2.616018146276474

Epoch: 5| Step: 6
Training loss: 2.9063830375671387
Validation loss: 2.61009174088637

Epoch: 5| Step: 7
Training loss: 3.295409679412842
Validation loss: 2.6048156519730887

Epoch: 5| Step: 8
Training loss: 2.176819324493408
Validation loss: 2.5996223588784537

Epoch: 5| Step: 9
Training loss: 3.1872072219848633
Validation loss: 2.5976956288019815

Epoch: 5| Step: 10
Training loss: 3.1189606189727783
Validation loss: 2.5976433058579764

Epoch: 5| Step: 11
Training loss: 2.3396236896514893
Validation loss: 2.596746246019999

Epoch: 48| Step: 0
Training loss: 3.2843143939971924
Validation loss: 2.5951655407746634

Epoch: 5| Step: 1
Training loss: 2.9748377799987793
Validation loss: 2.591857065757116

Epoch: 5| Step: 2
Training loss: 2.6049976348876953
Validation loss: 2.5891857047875724

Epoch: 5| Step: 3
Training loss: 3.036564350128174
Validation loss: 2.5859997868537903

Epoch: 5| Step: 4
Training loss: 2.206319570541382
Validation loss: 2.583907882372538

Epoch: 5| Step: 5
Training loss: 3.0544137954711914
Validation loss: 2.578949064016342

Epoch: 5| Step: 6
Training loss: 3.0515694618225098
Validation loss: 2.579277455806732

Epoch: 5| Step: 7
Training loss: 2.4346165657043457
Validation loss: 2.577255795399348

Epoch: 5| Step: 8
Training loss: 2.335292100906372
Validation loss: 2.5732743740081787

Epoch: 5| Step: 9
Training loss: 2.4321446418762207
Validation loss: 2.5709590911865234

Epoch: 5| Step: 10
Training loss: 3.1165528297424316
Validation loss: 2.5687566796938577

Epoch: 5| Step: 11
Training loss: 2.7392325401306152
Validation loss: 2.563211659590403

Epoch: 49| Step: 0
Training loss: 2.741669178009033
Validation loss: 2.5639351308345795

Epoch: 5| Step: 1
Training loss: 2.668827772140503
Validation loss: 2.5598244766394296

Epoch: 5| Step: 2
Training loss: 3.022813320159912
Validation loss: 2.556556820869446

Epoch: 5| Step: 3
Training loss: 2.4300899505615234
Validation loss: 2.550686856110891

Epoch: 5| Step: 4
Training loss: 2.9305789470672607
Validation loss: 2.5500781138738

Epoch: 5| Step: 5
Training loss: 2.4331564903259277
Validation loss: 2.5467661718527475

Epoch: 5| Step: 6
Training loss: 2.769243001937866
Validation loss: 2.5441747307777405

Epoch: 5| Step: 7
Training loss: 3.009986162185669
Validation loss: 2.544756601254145

Epoch: 5| Step: 8
Training loss: 3.0044708251953125
Validation loss: 2.543603320916494

Epoch: 5| Step: 9
Training loss: 2.227268934249878
Validation loss: 2.5410427500804267

Epoch: 5| Step: 10
Training loss: 2.9452064037323
Validation loss: 2.538542151451111

Epoch: 5| Step: 11
Training loss: 2.65455961227417
Validation loss: 2.5344078044096627

Epoch: 50| Step: 0
Training loss: 2.6595301628112793
Validation loss: 2.528956651687622

Epoch: 5| Step: 1
Training loss: 3.2175960540771484
Validation loss: 2.526542196671168

Epoch: 5| Step: 2
Training loss: 3.136237621307373
Validation loss: 2.5273892879486084

Epoch: 5| Step: 3
Training loss: 2.226534366607666
Validation loss: 2.5268962929646173

Epoch: 5| Step: 4
Training loss: 2.1891605854034424
Validation loss: 2.5226592222849527

Epoch: 5| Step: 5
Training loss: 2.164780378341675
Validation loss: 2.5209231873353324

Epoch: 5| Step: 6
Training loss: 2.7551894187927246
Validation loss: 2.5196283559004464

Epoch: 5| Step: 7
Training loss: 2.907099485397339
Validation loss: 2.5146421790122986

Epoch: 5| Step: 8
Training loss: 2.8748116493225098
Validation loss: 2.5114047626654306

Epoch: 5| Step: 9
Training loss: 3.196397066116333
Validation loss: 2.5092274645964303

Epoch: 5| Step: 10
Training loss: 2.604072093963623
Validation loss: 2.5054482420285544

Epoch: 5| Step: 11
Training loss: 2.0106372833251953
Validation loss: 2.5004743138949075

Epoch: 51| Step: 0
Training loss: 3.0778305530548096
Validation loss: 2.4963458478450775

Epoch: 5| Step: 1
Training loss: 2.4643218517303467
Validation loss: 2.497507721185684

Epoch: 5| Step: 2
Training loss: 2.5119075775146484
Validation loss: 2.4934323032697043

Epoch: 5| Step: 3
Training loss: 2.502196788787842
Validation loss: 2.4892353216807046

Epoch: 5| Step: 4
Training loss: 2.6562232971191406
Validation loss: 2.484733372926712

Epoch: 5| Step: 5
Training loss: 3.077946901321411
Validation loss: 2.4834050039450326

Epoch: 5| Step: 6
Training loss: 2.2975363731384277
Validation loss: 2.4808752238750458

Epoch: 5| Step: 7
Training loss: 2.5679805278778076
Validation loss: 2.478474353750547

Epoch: 5| Step: 8
Training loss: 2.805022716522217
Validation loss: 2.4749550024668374

Epoch: 5| Step: 9
Training loss: 2.303927421569824
Validation loss: 2.47280545035998

Epoch: 5| Step: 10
Training loss: 3.0309157371520996
Validation loss: 2.469624251127243

Epoch: 5| Step: 11
Training loss: 3.0547425746917725
Validation loss: 2.4674982776244483

Epoch: 52| Step: 0
Training loss: 2.5007476806640625
Validation loss: 2.463923672835032

Epoch: 5| Step: 1
Training loss: 2.629204511642456
Validation loss: 2.4605209132035575

Epoch: 5| Step: 2
Training loss: 2.546060562133789
Validation loss: 2.462524394194285

Epoch: 5| Step: 3
Training loss: 2.6404900550842285
Validation loss: 2.4619201024373374

Epoch: 5| Step: 4
Training loss: 2.899254560470581
Validation loss: 2.45304204026858

Epoch: 5| Step: 5
Training loss: 2.7472949028015137
Validation loss: 2.452941432595253

Epoch: 5| Step: 6
Training loss: 2.1595940589904785
Validation loss: 2.453326294819514

Epoch: 5| Step: 7
Training loss: 3.017106533050537
Validation loss: 2.4549318055311837

Epoch: 5| Step: 8
Training loss: 2.6421401500701904
Validation loss: 2.4481683373451233

Epoch: 5| Step: 9
Training loss: 2.7134971618652344
Validation loss: 2.4403041501839957

Epoch: 5| Step: 10
Training loss: 2.539229154586792
Validation loss: 2.4360811909039817

Epoch: 5| Step: 11
Training loss: 2.491367816925049
Validation loss: 2.43612069884936

Epoch: 53| Step: 0
Training loss: 2.3350064754486084
Validation loss: 2.4362985690434775

Epoch: 5| Step: 1
Training loss: 2.386582851409912
Validation loss: 2.4375234643618264

Epoch: 5| Step: 2
Training loss: 2.350680112838745
Validation loss: 2.435601681470871

Epoch: 5| Step: 3
Training loss: 2.332953929901123
Validation loss: 2.4361785451571145

Epoch: 5| Step: 4
Training loss: 2.5944082736968994
Validation loss: 2.4332133481899896

Epoch: 5| Step: 5
Training loss: 3.0273780822753906
Validation loss: 2.427738140026728

Epoch: 5| Step: 6
Training loss: 2.491037607192993
Validation loss: 2.4222200363874435

Epoch: 5| Step: 7
Training loss: 2.404005289077759
Validation loss: 2.419646590948105

Epoch: 5| Step: 8
Training loss: 2.7028820514678955
Validation loss: 2.41301957766215

Epoch: 5| Step: 9
Training loss: 2.4367239475250244
Validation loss: 2.408385713895162

Epoch: 5| Step: 10
Training loss: 3.597105026245117
Validation loss: 2.408586084842682

Epoch: 5| Step: 11
Training loss: 2.935580253601074
Validation loss: 2.4076740443706512

Epoch: 54| Step: 0
Training loss: 2.9385287761688232
Validation loss: 2.4091694355010986

Epoch: 5| Step: 1
Training loss: 2.668276309967041
Validation loss: 2.408084665735563

Epoch: 5| Step: 2
Training loss: 2.841832399368286
Validation loss: 2.408840239048004

Epoch: 5| Step: 3
Training loss: 2.8421618938446045
Validation loss: 2.4018264462550483

Epoch: 5| Step: 4
Training loss: 2.2976279258728027
Validation loss: 2.4021357744932175

Epoch: 5| Step: 5
Training loss: 3.1729226112365723
Validation loss: 2.3986078649759293

Epoch: 5| Step: 6
Training loss: 2.166893482208252
Validation loss: 2.3956242203712463

Epoch: 5| Step: 7
Training loss: 1.8456062078475952
Validation loss: 2.389996031920115

Epoch: 5| Step: 8
Training loss: 2.709700107574463
Validation loss: 2.384368528922399

Epoch: 5| Step: 9
Training loss: 2.8766350746154785
Validation loss: 2.3845043182373047

Epoch: 5| Step: 10
Training loss: 1.874792456626892
Validation loss: 2.381040463844935

Epoch: 5| Step: 11
Training loss: 3.000586986541748
Validation loss: 2.382084687550863

Epoch: 55| Step: 0
Training loss: 3.215864896774292
Validation loss: 2.378995567560196

Epoch: 5| Step: 1
Training loss: 2.2217509746551514
Validation loss: 2.376729349295298

Epoch: 5| Step: 2
Training loss: 2.176445722579956
Validation loss: 2.3733142713705697

Epoch: 5| Step: 3
Training loss: 2.498300075531006
Validation loss: 2.37034247815609

Epoch: 5| Step: 4
Training loss: 2.6984033584594727
Validation loss: 2.367195427417755

Epoch: 5| Step: 5
Training loss: 2.635956048965454
Validation loss: 2.3690019845962524

Epoch: 5| Step: 6
Training loss: 2.254424571990967
Validation loss: 2.365432287255923

Epoch: 5| Step: 7
Training loss: 2.4132962226867676
Validation loss: 2.3690594136714935

Epoch: 5| Step: 8
Training loss: 3.248732328414917
Validation loss: 2.3604934165875116

Epoch: 5| Step: 9
Training loss: 2.3407225608825684
Validation loss: 2.360321452220281

Epoch: 5| Step: 10
Training loss: 2.3106517791748047
Validation loss: 2.3614981373151145

Epoch: 5| Step: 11
Training loss: 2.0389351844787598
Validation loss: 2.3563919166723886

Epoch: 56| Step: 0
Training loss: 2.461322546005249
Validation loss: 2.351735552151998

Epoch: 5| Step: 1
Training loss: 2.1254401206970215
Validation loss: 2.3479723383982978

Epoch: 5| Step: 2
Training loss: 2.719571828842163
Validation loss: 2.3472136507431665

Epoch: 5| Step: 3
Training loss: 2.5770862102508545
Validation loss: 2.344023128350576

Epoch: 5| Step: 4
Training loss: 2.2380120754241943
Validation loss: 2.345772614081701

Epoch: 5| Step: 5
Training loss: 2.2473206520080566
Validation loss: 2.341024696826935

Epoch: 5| Step: 6
Training loss: 2.349684476852417
Validation loss: 2.337574298183123

Epoch: 5| Step: 7
Training loss: 2.2686312198638916
Validation loss: 2.3320257862408957

Epoch: 5| Step: 8
Training loss: 2.8803584575653076
Validation loss: 2.333355983098348

Epoch: 5| Step: 9
Training loss: 3.138514757156372
Validation loss: 2.334549536307653

Epoch: 5| Step: 10
Training loss: 2.5580928325653076
Validation loss: 2.332451264063517

Epoch: 5| Step: 11
Training loss: 2.5166378021240234
Validation loss: 2.3291282852490744

Epoch: 57| Step: 0
Training loss: 2.3099071979522705
Validation loss: 2.331746151049932

Epoch: 5| Step: 1
Training loss: 2.731849193572998
Validation loss: 2.3271423280239105

Epoch: 5| Step: 2
Training loss: 2.6453499794006348
Validation loss: 2.3263740142186484

Epoch: 5| Step: 3
Training loss: 2.7275238037109375
Validation loss: 2.3191312650839486

Epoch: 5| Step: 4
Training loss: 2.3788273334503174
Validation loss: 2.3184434274832406

Epoch: 5| Step: 5
Training loss: 1.8643407821655273
Validation loss: 2.3133888890345893

Epoch: 5| Step: 6
Training loss: 3.1345207691192627
Validation loss: 2.308062106370926

Epoch: 5| Step: 7
Training loss: 2.6835215091705322
Validation loss: 2.3107555210590363

Epoch: 5| Step: 8
Training loss: 2.677197217941284
Validation loss: 2.3073675284783044

Epoch: 5| Step: 9
Training loss: 1.599123239517212
Validation loss: 2.3044447153806686

Epoch: 5| Step: 10
Training loss: 2.743995189666748
Validation loss: 2.3011389126380286

Epoch: 5| Step: 11
Training loss: 1.4192447662353516
Validation loss: 2.2999486376841864

Epoch: 58| Step: 0
Training loss: 2.772317409515381
Validation loss: 2.2984738250573478

Epoch: 5| Step: 1
Training loss: 1.7611316442489624
Validation loss: 2.296181380748749

Epoch: 5| Step: 2
Training loss: 2.3810582160949707
Validation loss: 2.2940827359755835

Epoch: 5| Step: 3
Training loss: 2.630855083465576
Validation loss: 2.297471637527148

Epoch: 5| Step: 4
Training loss: 2.11920166015625
Validation loss: 2.29388365149498

Epoch: 5| Step: 5
Training loss: 3.577509641647339
Validation loss: 2.2968369275331497

Epoch: 5| Step: 6
Training loss: 2.580207586288452
Validation loss: 2.2881479958693185

Epoch: 5| Step: 7
Training loss: 1.9644851684570312
Validation loss: 2.2828780512015023

Epoch: 5| Step: 8
Training loss: 2.0808444023132324
Validation loss: 2.277024726072947

Epoch: 5| Step: 9
Training loss: 2.609922409057617
Validation loss: 2.2799548357725143

Epoch: 5| Step: 10
Training loss: 2.4963505268096924
Validation loss: 2.2791168292363486

Epoch: 5| Step: 11
Training loss: 2.2267942428588867
Validation loss: 2.2824642757574716

Epoch: 59| Step: 0
Training loss: 1.6608597040176392
Validation loss: 2.2792971630891166

Epoch: 5| Step: 1
Training loss: 2.7293505668640137
Validation loss: 2.2782994508743286

Epoch: 5| Step: 2
Training loss: 2.0272886753082275
Validation loss: 2.2757946898539863

Epoch: 5| Step: 3
Training loss: 3.0764546394348145
Validation loss: 2.2691719134648642

Epoch: 5| Step: 4
Training loss: 1.746398687362671
Validation loss: 2.2655761937300363

Epoch: 5| Step: 5
Training loss: 2.0982069969177246
Validation loss: 2.260096937417984

Epoch: 5| Step: 6
Training loss: 2.388266086578369
Validation loss: 2.2586659590403237

Epoch: 5| Step: 7
Training loss: 2.380919933319092
Validation loss: 2.2547992368539176

Epoch: 5| Step: 8
Training loss: 2.694554567337036
Validation loss: 2.2538921236991882

Epoch: 5| Step: 9
Training loss: 2.953235149383545
Validation loss: 2.2503051261107125

Epoch: 5| Step: 10
Training loss: 2.9766783714294434
Validation loss: 2.2501232028007507

Epoch: 5| Step: 11
Training loss: 1.9781817197799683
Validation loss: 2.245292976498604

Epoch: 60| Step: 0
Training loss: 1.966456651687622
Validation loss: 2.246753543615341

Epoch: 5| Step: 1
Training loss: 1.787334680557251
Validation loss: 2.239225218693415

Epoch: 5| Step: 2
Training loss: 2.740461587905884
Validation loss: 2.2366813272237778

Epoch: 5| Step: 3
Training loss: 2.8585383892059326
Validation loss: 2.2391026417414346

Epoch: 5| Step: 4
Training loss: 2.1051251888275146
Validation loss: 2.2338551183541617

Epoch: 5| Step: 5
Training loss: 2.8512215614318848
Validation loss: 2.231492886940638

Epoch: 5| Step: 6
Training loss: 2.8147802352905273
Validation loss: 2.232502669095993

Epoch: 5| Step: 7
Training loss: 1.78977370262146
Validation loss: 2.2302623987197876

Epoch: 5| Step: 8
Training loss: 1.981310248374939
Validation loss: 2.2282190918922424

Epoch: 5| Step: 9
Training loss: 2.3814330101013184
Validation loss: 2.2225501934687295

Epoch: 5| Step: 10
Training loss: 3.027663469314575
Validation loss: 2.224005470673243

Epoch: 5| Step: 11
Training loss: 1.8688039779663086
Validation loss: 2.2246714532375336

Epoch: 61| Step: 0
Training loss: 2.240720272064209
Validation loss: 2.221335291862488

Epoch: 5| Step: 1
Training loss: 1.9815514087677002
Validation loss: 2.221665541330973

Epoch: 5| Step: 2
Training loss: 1.8714172840118408
Validation loss: 2.220389907558759

Epoch: 5| Step: 3
Training loss: 2.822718381881714
Validation loss: 2.2192155867815018

Epoch: 5| Step: 4
Training loss: 3.0224878787994385
Validation loss: 2.2190421173969903

Epoch: 5| Step: 5
Training loss: 2.2112877368927
Validation loss: 2.2137133280436196

Epoch: 5| Step: 6
Training loss: 2.3332626819610596
Validation loss: 2.2124892473220825

Epoch: 5| Step: 7
Training loss: 2.470630168914795
Validation loss: 2.212626745303472

Epoch: 5| Step: 8
Training loss: 2.3448092937469482
Validation loss: 2.20754407842954

Epoch: 5| Step: 9
Training loss: 2.0243232250213623
Validation loss: 2.206959386666616

Epoch: 5| Step: 10
Training loss: 2.628469705581665
Validation loss: 2.2000286678473153

Epoch: 5| Step: 11
Training loss: 2.9193267822265625
Validation loss: 2.1990651339292526

Epoch: 62| Step: 0
Training loss: 2.6863930225372314
Validation loss: 2.1964438954989114

Epoch: 5| Step: 1
Training loss: 2.9079365730285645
Validation loss: 2.1914949963490167

Epoch: 5| Step: 2
Training loss: 2.3324050903320312
Validation loss: 2.1878526508808136

Epoch: 5| Step: 3
Training loss: 2.088528871536255
Validation loss: 2.1840819269418716

Epoch: 5| Step: 4
Training loss: 2.329158306121826
Validation loss: 2.186759432156881

Epoch: 5| Step: 5
Training loss: 1.9732671976089478
Validation loss: 2.1847078601519265

Epoch: 5| Step: 6
Training loss: 2.2972652912139893
Validation loss: 2.1858323762814202

Epoch: 5| Step: 7
Training loss: 2.728074550628662
Validation loss: 2.1884367167949677

Epoch: 5| Step: 8
Training loss: 2.5246427059173584
Validation loss: 2.1952209373315177

Epoch: 5| Step: 9
Training loss: 2.1146185398101807
Validation loss: 2.184694012006124

Epoch: 5| Step: 10
Training loss: 1.8357206583023071
Validation loss: 2.172789673010508

Epoch: 5| Step: 11
Training loss: 2.0962066650390625
Validation loss: 2.1719448069731393

Epoch: 63| Step: 0
Training loss: 2.2575578689575195
Validation loss: 2.169465626279513

Epoch: 5| Step: 1
Training loss: 2.416565179824829
Validation loss: 2.16456430653731

Epoch: 5| Step: 2
Training loss: 2.3015832901000977
Validation loss: 2.168205718199412

Epoch: 5| Step: 3
Training loss: 1.7914535999298096
Validation loss: 2.166240726908048

Epoch: 5| Step: 4
Training loss: 1.9904762506484985
Validation loss: 2.1664369056622186

Epoch: 5| Step: 5
Training loss: 2.446155071258545
Validation loss: 2.1663826256990433

Epoch: 5| Step: 6
Training loss: 2.3611228466033936
Validation loss: 2.1647631227970123

Epoch: 5| Step: 7
Training loss: 1.7405145168304443
Validation loss: 2.1724470357100167

Epoch: 5| Step: 8
Training loss: 2.451674699783325
Validation loss: 2.1685043275356293

Epoch: 5| Step: 9
Training loss: 3.276409864425659
Validation loss: 2.1572978595892587

Epoch: 5| Step: 10
Training loss: 2.6357228755950928
Validation loss: 2.159098282456398

Epoch: 5| Step: 11
Training loss: 1.7347389459609985
Validation loss: 2.154673844575882

Epoch: 64| Step: 0
Training loss: 1.8506206274032593
Validation loss: 2.1525180687506995

Epoch: 5| Step: 1
Training loss: 1.931441307067871
Validation loss: 2.152810533841451

Epoch: 5| Step: 2
Training loss: 2.836268663406372
Validation loss: 2.1538068602482476

Epoch: 5| Step: 3
Training loss: 2.3268871307373047
Validation loss: 2.1540581484635672

Epoch: 5| Step: 4
Training loss: 2.0446698665618896
Validation loss: 2.1509428123633065

Epoch: 5| Step: 5
Training loss: 2.467754364013672
Validation loss: 2.1520237227280936

Epoch: 5| Step: 6
Training loss: 3.067408561706543
Validation loss: 2.1463738282521567

Epoch: 5| Step: 7
Training loss: 1.1319141387939453
Validation loss: 2.146295870343844

Epoch: 5| Step: 8
Training loss: 2.7467942237854004
Validation loss: 2.1450299322605133

Epoch: 5| Step: 9
Training loss: 2.6537024974823
Validation loss: 2.145407736301422

Epoch: 5| Step: 10
Training loss: 2.122598886489868
Validation loss: 2.1420989632606506

Epoch: 5| Step: 11
Training loss: 3.1969046592712402
Validation loss: 2.145108332236608

Epoch: 65| Step: 0
Training loss: 2.717634677886963
Validation loss: 2.139792670806249

Epoch: 5| Step: 1
Training loss: 2.366086006164551
Validation loss: 2.1409123738606772

Epoch: 5| Step: 2
Training loss: 2.3645243644714355
Validation loss: 2.1386991441249847

Epoch: 5| Step: 3
Training loss: 2.3828542232513428
Validation loss: 2.1413389345010123

Epoch: 5| Step: 4
Training loss: 1.715635895729065
Validation loss: 2.136413966615995

Epoch: 5| Step: 5
Training loss: 1.6472446918487549
Validation loss: 2.132701963186264

Epoch: 5| Step: 6
Training loss: 3.1223227977752686
Validation loss: 2.1377627899249396

Epoch: 5| Step: 7
Training loss: 1.887171745300293
Validation loss: 2.1369494845469794

Epoch: 5| Step: 8
Training loss: 2.2611770629882812
Validation loss: 2.1385514636834464

Epoch: 5| Step: 9
Training loss: 2.9992196559906006
Validation loss: 2.1373194456100464

Epoch: 5| Step: 10
Training loss: 1.9475047588348389
Validation loss: 2.1397069791952767

Epoch: 5| Step: 11
Training loss: 1.6454031467437744
Validation loss: 2.13265494008859

Epoch: 66| Step: 0
Training loss: 2.6694562435150146
Validation loss: 2.128981272379557

Epoch: 5| Step: 1
Training loss: 2.332458734512329
Validation loss: 2.122579817970594

Epoch: 5| Step: 2
Training loss: 2.45443058013916
Validation loss: 2.123132660984993

Epoch: 5| Step: 3
Training loss: 2.7134907245635986
Validation loss: 2.1230867157379785

Epoch: 5| Step: 4
Training loss: 1.464462161064148
Validation loss: 2.129742448528608

Epoch: 5| Step: 5
Training loss: 2.3549721240997314
Validation loss: 2.134535178542137

Epoch: 5| Step: 6
Training loss: 2.161550521850586
Validation loss: 2.1338372826576233

Epoch: 5| Step: 7
Training loss: 1.99698805809021
Validation loss: 2.135664016008377

Epoch: 5| Step: 8
Training loss: 2.668612241744995
Validation loss: 2.1376706461111703

Epoch: 5| Step: 9
Training loss: 2.092951774597168
Validation loss: 2.1405643026034036

Epoch: 5| Step: 10
Training loss: 2.5176644325256348
Validation loss: 2.1356254667043686

Epoch: 5| Step: 11
Training loss: 1.8538410663604736
Validation loss: 2.1334429681301117

Epoch: 67| Step: 0
Training loss: 2.599623680114746
Validation loss: 2.135431617498398

Epoch: 5| Step: 1
Training loss: 1.9431416988372803
Validation loss: 2.12698824206988

Epoch: 5| Step: 2
Training loss: 2.0223937034606934
Validation loss: 2.123669554789861

Epoch: 5| Step: 3
Training loss: 2.256269931793213
Validation loss: 2.12025785446167

Epoch: 5| Step: 4
Training loss: 2.108604669570923
Validation loss: 2.115944117307663

Epoch: 5| Step: 5
Training loss: 2.2891812324523926
Validation loss: 2.112313305338224

Epoch: 5| Step: 6
Training loss: 2.422245502471924
Validation loss: 2.1103036353985467

Epoch: 5| Step: 7
Training loss: 2.1482224464416504
Validation loss: 2.1014874974886575

Epoch: 5| Step: 8
Training loss: 2.817227363586426
Validation loss: 2.097947617371877

Epoch: 5| Step: 9
Training loss: 1.957291841506958
Validation loss: 2.097623517115911

Epoch: 5| Step: 10
Training loss: 2.1955454349517822
Validation loss: 2.0934938490390778

Epoch: 5| Step: 11
Training loss: 3.7549991607666016
Validation loss: 2.092430571715037

Epoch: 68| Step: 0
Training loss: 2.1222357749938965
Validation loss: 2.103050837914149

Epoch: 5| Step: 1
Training loss: 1.9687296152114868
Validation loss: 2.108635733524958

Epoch: 5| Step: 2
Training loss: 2.2533764839172363
Validation loss: 2.1064011553923288

Epoch: 5| Step: 3
Training loss: 2.7564022541046143
Validation loss: 2.104767918586731

Epoch: 5| Step: 4
Training loss: 2.113447904586792
Validation loss: 2.103040417035421

Epoch: 5| Step: 5
Training loss: 2.244143009185791
Validation loss: 2.0979909896850586

Epoch: 5| Step: 6
Training loss: 2.018706798553467
Validation loss: 2.0933578660090766

Epoch: 5| Step: 7
Training loss: 2.046069622039795
Validation loss: 2.0934005081653595

Epoch: 5| Step: 8
Training loss: 3.0172410011291504
Validation loss: 2.0926620612541833

Epoch: 5| Step: 9
Training loss: 2.630283832550049
Validation loss: 2.0927413950363793

Epoch: 5| Step: 10
Training loss: 1.9791685342788696
Validation loss: 2.082118238011996

Epoch: 5| Step: 11
Training loss: 1.7353756427764893
Validation loss: 2.085602189103762

Epoch: 69| Step: 0
Training loss: 2.6670982837677
Validation loss: 2.081767717997233

Epoch: 5| Step: 1
Training loss: 2.569091796875
Validation loss: 2.0813438395659127

Epoch: 5| Step: 2
Training loss: 1.9759771823883057
Validation loss: 2.0834520955880484

Epoch: 5| Step: 3
Training loss: 1.7902767658233643
Validation loss: 2.0810226251681647

Epoch: 5| Step: 4
Training loss: 1.993786096572876
Validation loss: 2.0809402217467627

Epoch: 5| Step: 5
Training loss: 2.3130440711975098
Validation loss: 2.0774790793657303

Epoch: 5| Step: 6
Training loss: 2.3422904014587402
Validation loss: 2.0779238641262054

Epoch: 5| Step: 7
Training loss: 2.7360777854919434
Validation loss: 2.076264798641205

Epoch: 5| Step: 8
Training loss: 2.030205488204956
Validation loss: 2.0729225873947144

Epoch: 5| Step: 9
Training loss: 2.467348575592041
Validation loss: 2.0753587832053504

Epoch: 5| Step: 10
Training loss: 1.8107662200927734
Validation loss: 2.075410788257917

Epoch: 5| Step: 11
Training loss: 2.6158409118652344
Validation loss: 2.068355013926824

Epoch: 70| Step: 0
Training loss: 2.3103420734405518
Validation loss: 2.0685962786277137

Epoch: 5| Step: 1
Training loss: 2.1184563636779785
Validation loss: 2.0709776828686395

Epoch: 5| Step: 2
Training loss: 2.2701985836029053
Validation loss: 2.071886360645294

Epoch: 5| Step: 3
Training loss: 2.0711498260498047
Validation loss: 2.069228415687879

Epoch: 5| Step: 4
Training loss: 2.1425387859344482
Validation loss: 2.069103171428045

Epoch: 5| Step: 5
Training loss: 2.1603360176086426
Validation loss: 2.0598600953817368

Epoch: 5| Step: 6
Training loss: 1.8556146621704102
Validation loss: 2.0706501503785453

Epoch: 5| Step: 7
Training loss: 2.509946346282959
Validation loss: 2.065405383706093

Epoch: 5| Step: 8
Training loss: 2.4641337394714355
Validation loss: 2.069654365380605

Epoch: 5| Step: 9
Training loss: 2.5835185050964355
Validation loss: 2.065761059522629

Epoch: 5| Step: 10
Training loss: 2.041579484939575
Validation loss: 2.0648817171653113

Epoch: 5| Step: 11
Training loss: 2.9379448890686035
Validation loss: 2.059478531281153

Epoch: 71| Step: 0
Training loss: 2.5996475219726562
Validation loss: 2.0560292154550552

Epoch: 5| Step: 1
Training loss: 2.5089001655578613
Validation loss: 2.062968611717224

Epoch: 5| Step: 2
Training loss: 2.058809280395508
Validation loss: 2.065046936273575

Epoch: 5| Step: 3
Training loss: 1.7970796823501587
Validation loss: 2.060929462313652

Epoch: 5| Step: 4
Training loss: 1.9279435873031616
Validation loss: 2.062249466776848

Epoch: 5| Step: 5
Training loss: 2.120584487915039
Validation loss: 2.0582436521848044

Epoch: 5| Step: 6
Training loss: 2.3161351680755615
Validation loss: 2.0615560909112296

Epoch: 5| Step: 7
Training loss: 2.2958426475524902
Validation loss: 2.054369494318962

Epoch: 5| Step: 8
Training loss: 2.4289605617523193
Validation loss: 2.061154688398043

Epoch: 5| Step: 9
Training loss: 2.402329921722412
Validation loss: 2.0624835590521493

Epoch: 5| Step: 10
Training loss: 1.9627583026885986
Validation loss: 2.06172876060009

Epoch: 5| Step: 11
Training loss: 3.0927419662475586
Validation loss: 2.0608717699845633

Epoch: 72| Step: 0
Training loss: 2.2723548412323
Validation loss: 2.056233157714208

Epoch: 5| Step: 1
Training loss: 1.9094865322113037
Validation loss: 2.0561950554450354

Epoch: 5| Step: 2
Training loss: 2.319709062576294
Validation loss: 2.051505217949549

Epoch: 5| Step: 3
Training loss: 1.9597755670547485
Validation loss: 2.0464910169442496

Epoch: 5| Step: 4
Training loss: 2.5829169750213623
Validation loss: 2.0474299639463425

Epoch: 5| Step: 5
Training loss: 2.074986457824707
Validation loss: 2.0522359112898507

Epoch: 5| Step: 6
Training loss: 2.22611141204834
Validation loss: 2.0490472614765167

Epoch: 5| Step: 7
Training loss: 2.541511297225952
Validation loss: 2.0481236030658088

Epoch: 5| Step: 8
Training loss: 2.016744375228882
Validation loss: 2.0549744069576263

Epoch: 5| Step: 9
Training loss: 2.4548542499542236
Validation loss: 2.0487111608187356

Epoch: 5| Step: 10
Training loss: 2.2446377277374268
Validation loss: 2.0403151313463845

Epoch: 5| Step: 11
Training loss: 1.970105528831482
Validation loss: 2.043344353636106

Epoch: 73| Step: 0
Training loss: 2.3790502548217773
Validation loss: 2.047028770049413

Epoch: 5| Step: 1
Training loss: 2.055453062057495
Validation loss: 2.0570568641026816

Epoch: 5| Step: 2
Training loss: 1.7479994297027588
Validation loss: 2.063342606027921

Epoch: 5| Step: 3
Training loss: 2.0782129764556885
Validation loss: 2.04941759010156

Epoch: 5| Step: 4
Training loss: 2.407059907913208
Validation loss: 2.0520072231690087

Epoch: 5| Step: 5
Training loss: 2.1403956413269043
Validation loss: 2.0431096057097116

Epoch: 5| Step: 6
Training loss: 2.5288596153259277
Validation loss: 2.0476377308368683

Epoch: 5| Step: 7
Training loss: 2.3194127082824707
Validation loss: 2.0466133107741675

Epoch: 5| Step: 8
Training loss: 2.304727077484131
Validation loss: 2.048694441715876

Epoch: 5| Step: 9
Training loss: 2.0970261096954346
Validation loss: 2.066441317399343

Epoch: 5| Step: 10
Training loss: 2.48958683013916
Validation loss: 2.0655139088630676

Epoch: 5| Step: 11
Training loss: 2.5949478149414062
Validation loss: 2.062185520927111

Epoch: 74| Step: 0
Training loss: 2.2826967239379883
Validation loss: 2.082494373122851

Epoch: 5| Step: 1
Training loss: 2.505434274673462
Validation loss: 2.105505550901095

Epoch: 5| Step: 2
Training loss: 2.0603113174438477
Validation loss: 2.116117795308431

Epoch: 5| Step: 3
Training loss: 1.5921518802642822
Validation loss: 2.1136538485685983

Epoch: 5| Step: 4
Training loss: 2.4835116863250732
Validation loss: 2.1061413437128067

Epoch: 5| Step: 5
Training loss: 2.3893213272094727
Validation loss: 2.09658774236838

Epoch: 5| Step: 6
Training loss: 2.4708309173583984
Validation loss: 2.0904630720615387

Epoch: 5| Step: 7
Training loss: 1.7132856845855713
Validation loss: 2.0836136788129807

Epoch: 5| Step: 8
Training loss: 2.3131625652313232
Validation loss: 2.062017331520716

Epoch: 5| Step: 9
Training loss: 2.770378351211548
Validation loss: 2.060022051135699

Epoch: 5| Step: 10
Training loss: 1.9040883779525757
Validation loss: 2.0533820192019143

Epoch: 5| Step: 11
Training loss: 3.1369638442993164
Validation loss: 2.057088886698087

Epoch: 75| Step: 0
Training loss: 2.687516689300537
Validation loss: 2.053359031677246

Epoch: 5| Step: 1
Training loss: 2.2745919227600098
Validation loss: 2.0542947749296823

Epoch: 5| Step: 2
Training loss: 2.343214511871338
Validation loss: 2.0575757026672363

Epoch: 5| Step: 3
Training loss: 2.5807907581329346
Validation loss: 2.058018922805786

Epoch: 5| Step: 4
Training loss: 1.9144909381866455
Validation loss: 2.053257162372271

Epoch: 5| Step: 5
Training loss: 2.415109157562256
Validation loss: 2.053877462943395

Epoch: 5| Step: 6
Training loss: 2.085875988006592
Validation loss: 2.056496704618136

Epoch: 5| Step: 7
Training loss: 1.6661075353622437
Validation loss: 2.0529612799485526

Epoch: 5| Step: 8
Training loss: 2.187427520751953
Validation loss: 2.0567611704270043

Epoch: 5| Step: 9
Training loss: 2.15783953666687
Validation loss: 2.0498383939266205

Epoch: 5| Step: 10
Training loss: 2.118408203125
Validation loss: 2.047457461555799

Epoch: 5| Step: 11
Training loss: 2.829030990600586
Validation loss: 2.047216142217318

Epoch: 76| Step: 0
Training loss: 1.943882942199707
Validation loss: 2.042838523785273

Epoch: 5| Step: 1
Training loss: 2.3842575550079346
Validation loss: 2.045172999302546

Epoch: 5| Step: 2
Training loss: 2.138338565826416
Validation loss: 2.039035161336263

Epoch: 5| Step: 3
Training loss: 1.7438135147094727
Validation loss: 2.0371449291706085

Epoch: 5| Step: 4
Training loss: 1.9193403720855713
Validation loss: 2.0430446167786918

Epoch: 5| Step: 5
Training loss: 2.93672513961792
Validation loss: 2.037536397576332

Epoch: 5| Step: 6
Training loss: 2.1345577239990234
Validation loss: 2.03768723209699

Epoch: 5| Step: 7
Training loss: 3.1389636993408203
Validation loss: 2.031777878602346

Epoch: 5| Step: 8
Training loss: 2.0102016925811768
Validation loss: 2.0330440551042557

Epoch: 5| Step: 9
Training loss: 2.2442193031311035
Validation loss: 2.033925175666809

Epoch: 5| Step: 10
Training loss: 1.6783645153045654
Validation loss: 2.0333406726519265

Epoch: 5| Step: 11
Training loss: 2.215182304382324
Validation loss: 2.0393123030662537

Epoch: 77| Step: 0
Training loss: 1.6903101205825806
Validation loss: 2.0510590026775994

Epoch: 5| Step: 1
Training loss: 2.279806613922119
Validation loss: 2.056429540117582

Epoch: 5| Step: 2
Training loss: 2.015841007232666
Validation loss: 2.0696743627389274

Epoch: 5| Step: 3
Training loss: 1.7968460321426392
Validation loss: 2.069387505451838

Epoch: 5| Step: 4
Training loss: 2.2572124004364014
Validation loss: 2.0882353087266288

Epoch: 5| Step: 5
Training loss: 2.861171007156372
Validation loss: 2.084903985261917

Epoch: 5| Step: 6
Training loss: 2.0248219966888428
Validation loss: 2.092951928575834

Epoch: 5| Step: 7
Training loss: 2.4501492977142334
Validation loss: 2.06595478951931

Epoch: 5| Step: 8
Training loss: 2.531677722930908
Validation loss: 2.0563172648350396

Epoch: 5| Step: 9
Training loss: 2.560234546661377
Validation loss: 2.036363328496615

Epoch: 5| Step: 10
Training loss: 2.0468902587890625
Validation loss: 2.029672543207804

Epoch: 5| Step: 11
Training loss: 2.023409128189087
Validation loss: 2.036314939459165

Epoch: 78| Step: 0
Training loss: 2.3110110759735107
Validation loss: 2.042661373813947

Epoch: 5| Step: 1
Training loss: 2.2259156703948975
Validation loss: 2.046288937330246

Epoch: 5| Step: 2
Training loss: 2.3984720706939697
Validation loss: 2.0438511073589325

Epoch: 5| Step: 3
Training loss: 2.232874631881714
Validation loss: 2.041596308350563

Epoch: 5| Step: 4
Training loss: 2.4172024726867676
Validation loss: 2.0394362062215805

Epoch: 5| Step: 5
Training loss: 2.018887519836426
Validation loss: 2.0362947434186935

Epoch: 5| Step: 6
Training loss: 1.8593908548355103
Validation loss: 2.032160912950834

Epoch: 5| Step: 7
Training loss: 2.152855634689331
Validation loss: 2.024961213270823

Epoch: 5| Step: 8
Training loss: 2.1766295433044434
Validation loss: 2.0211229622364044

Epoch: 5| Step: 9
Training loss: 2.1803042888641357
Validation loss: 2.0204200943311057

Epoch: 5| Step: 10
Training loss: 2.04933500289917
Validation loss: 2.0121411979198456

Epoch: 5| Step: 11
Training loss: 3.4540064334869385
Validation loss: 2.0184822231531143

Epoch: 79| Step: 0
Training loss: 2.2746520042419434
Validation loss: 2.0197239915529885

Epoch: 5| Step: 1
Training loss: 2.3619465827941895
Validation loss: 2.0145198702812195

Epoch: 5| Step: 2
Training loss: 2.2221052646636963
Validation loss: 2.0191497653722763

Epoch: 5| Step: 3
Training loss: 1.967231035232544
Validation loss: 2.0188104708989463

Epoch: 5| Step: 4
Training loss: 2.421165704727173
Validation loss: 2.0159850070873895

Epoch: 5| Step: 5
Training loss: 2.229562282562256
Validation loss: 2.0215576390425363

Epoch: 5| Step: 6
Training loss: 2.5526294708251953
Validation loss: 2.0170354396104813

Epoch: 5| Step: 7
Training loss: 1.8799450397491455
Validation loss: 2.0167546222607293

Epoch: 5| Step: 8
Training loss: 1.8641332387924194
Validation loss: 2.0176029006640115

Epoch: 5| Step: 9
Training loss: 2.3103039264678955
Validation loss: 2.0161715298891068

Epoch: 5| Step: 10
Training loss: 1.987959623336792
Validation loss: 2.0135363390048346

Epoch: 5| Step: 11
Training loss: 2.3274953365325928
Validation loss: 2.019395833214124

Epoch: 80| Step: 0
Training loss: 2.6235287189483643
Validation loss: 2.0158946414788566

Epoch: 5| Step: 1
Training loss: 1.836382269859314
Validation loss: 2.011393348375956

Epoch: 5| Step: 2
Training loss: 1.9969269037246704
Validation loss: 2.0209506998459497

Epoch: 5| Step: 3
Training loss: 2.331407308578491
Validation loss: 2.0239041248957315

Epoch: 5| Step: 4
Training loss: 2.111560583114624
Validation loss: 2.031774510939916

Epoch: 5| Step: 5
Training loss: 2.301565408706665
Validation loss: 2.0344447791576385

Epoch: 5| Step: 6
Training loss: 2.175448179244995
Validation loss: 2.0183186630407968

Epoch: 5| Step: 7
Training loss: 1.9844815731048584
Validation loss: 2.022149384021759

Epoch: 5| Step: 8
Training loss: 1.935638666152954
Validation loss: 2.018309608101845

Epoch: 5| Step: 9
Training loss: 2.054807424545288
Validation loss: 2.0248329490423203

Epoch: 5| Step: 10
Training loss: 2.6087677478790283
Validation loss: 2.0235677460829415

Epoch: 5| Step: 11
Training loss: 2.8310325145721436
Validation loss: 2.0275757114092507

Epoch: 81| Step: 0
Training loss: 2.1730284690856934
Validation loss: 2.020353148380915

Epoch: 5| Step: 1
Training loss: 1.9228681325912476
Validation loss: 2.0138580054044724

Epoch: 5| Step: 2
Training loss: 1.7648000717163086
Validation loss: 2.0148494243621826

Epoch: 5| Step: 3
Training loss: 1.3854986429214478
Validation loss: 2.008426457643509

Epoch: 5| Step: 4
Training loss: 2.5422534942626953
Validation loss: 2.0128431916236877

Epoch: 5| Step: 5
Training loss: 2.2195606231689453
Validation loss: 2.0136802246173224

Epoch: 5| Step: 6
Training loss: 2.43810772895813
Validation loss: 2.012164036432902

Epoch: 5| Step: 7
Training loss: 2.911731243133545
Validation loss: 2.0107472042242684

Epoch: 5| Step: 8
Training loss: 2.0512633323669434
Validation loss: 2.016432046890259

Epoch: 5| Step: 9
Training loss: 2.3361411094665527
Validation loss: 2.016540080308914

Epoch: 5| Step: 10
Training loss: 2.4297173023223877
Validation loss: 2.0112529397010803

Epoch: 5| Step: 11
Training loss: 1.3926284313201904
Validation loss: 2.010226999719938

Epoch: 82| Step: 0
Training loss: 2.846219062805176
Validation loss: 2.013106122612953

Epoch: 5| Step: 1
Training loss: 2.0406136512756348
Validation loss: 2.016017054518064

Epoch: 5| Step: 2
Training loss: 2.090304374694824
Validation loss: 2.014968459804853

Epoch: 5| Step: 3
Training loss: 2.1412441730499268
Validation loss: 2.0191891938447952

Epoch: 5| Step: 4
Training loss: 1.9284474849700928
Validation loss: 2.0213277538617453

Epoch: 5| Step: 5
Training loss: 2.434335470199585
Validation loss: 2.026661197344462

Epoch: 5| Step: 6
Training loss: 1.8118999004364014
Validation loss: 2.0245847702026367

Epoch: 5| Step: 7
Training loss: 2.207786798477173
Validation loss: 2.0173048079013824

Epoch: 5| Step: 8
Training loss: 1.7392228841781616
Validation loss: 2.0201232979695

Epoch: 5| Step: 9
Training loss: 2.0604469776153564
Validation loss: 2.0135714958111444

Epoch: 5| Step: 10
Training loss: 2.7427308559417725
Validation loss: 2.0125958373149238

Epoch: 5| Step: 11
Training loss: 1.3749148845672607
Validation loss: 2.014559472600619

Epoch: 83| Step: 0
Training loss: 2.213343381881714
Validation loss: 2.0095216035842896

Epoch: 5| Step: 1
Training loss: 2.1055121421813965
Validation loss: 2.0160296509663262

Epoch: 5| Step: 2
Training loss: 2.141115665435791
Validation loss: 2.011805310845375

Epoch: 5| Step: 3
Training loss: 1.724087119102478
Validation loss: 2.0162026981512704

Epoch: 5| Step: 4
Training loss: 2.324068069458008
Validation loss: 2.017305394013723

Epoch: 5| Step: 5
Training loss: 2.1918234825134277
Validation loss: 2.013633280992508

Epoch: 5| Step: 6
Training loss: 1.9480483531951904
Validation loss: 2.0132442712783813

Epoch: 5| Step: 7
Training loss: 2.1413159370422363
Validation loss: 2.0116358747084937

Epoch: 5| Step: 8
Training loss: 2.8504347801208496
Validation loss: 2.01618729531765

Epoch: 5| Step: 9
Training loss: 2.0253350734710693
Validation loss: 2.0139197508494058

Epoch: 5| Step: 10
Training loss: 2.4495019912719727
Validation loss: 2.0147093385457993

Epoch: 5| Step: 11
Training loss: 1.222475290298462
Validation loss: 2.0168840885162354

Epoch: 84| Step: 0
Training loss: 1.763635277748108
Validation loss: 2.016643449664116

Epoch: 5| Step: 1
Training loss: 2.012711763381958
Validation loss: 2.029823104540507

Epoch: 5| Step: 2
Training loss: 1.9552116394042969
Validation loss: 2.028861954808235

Epoch: 5| Step: 3
Training loss: 2.6846120357513428
Validation loss: 2.0233798772096634

Epoch: 5| Step: 4
Training loss: 2.1942265033721924
Validation loss: 2.0261832922697067

Epoch: 5| Step: 5
Training loss: 1.996045708656311
Validation loss: 2.0232126613458

Epoch: 5| Step: 6
Training loss: 1.959244966506958
Validation loss: 2.0229765077432

Epoch: 5| Step: 7
Training loss: 2.1794848442077637
Validation loss: 2.0132133016983667

Epoch: 5| Step: 8
Training loss: 2.193291187286377
Validation loss: 2.0153485983610153

Epoch: 5| Step: 9
Training loss: 2.4142708778381348
Validation loss: 2.0180770456790924

Epoch: 5| Step: 10
Training loss: 2.2100136280059814
Validation loss: 2.0134256382783255

Epoch: 5| Step: 11
Training loss: 3.3035836219787598
Validation loss: 2.0123824824889502

Epoch: 85| Step: 0
Training loss: 2.5665128231048584
Validation loss: 2.008924677968025

Epoch: 5| Step: 1
Training loss: 1.545541763305664
Validation loss: 2.007419769962629

Epoch: 5| Step: 2
Training loss: 2.1496968269348145
Validation loss: 2.004660134514173

Epoch: 5| Step: 3
Training loss: 1.8123142719268799
Validation loss: 2.011547659834226

Epoch: 5| Step: 4
Training loss: 2.2337260246276855
Validation loss: 2.008563588062922

Epoch: 5| Step: 5
Training loss: 2.3617310523986816
Validation loss: 2.0136525432268777

Epoch: 5| Step: 6
Training loss: 2.343358278274536
Validation loss: 2.00490964949131

Epoch: 5| Step: 7
Training loss: 2.221696376800537
Validation loss: 2.0089575896660485

Epoch: 5| Step: 8
Training loss: 2.5882837772369385
Validation loss: 2.009965310494105

Epoch: 5| Step: 9
Training loss: 2.15140438079834
Validation loss: 2.0065129548311234

Epoch: 5| Step: 10
Training loss: 1.6797559261322021
Validation loss: 2.009870539108912

Epoch: 5| Step: 11
Training loss: 2.919576406478882
Validation loss: 2.011385331551234

Epoch: 86| Step: 0
Training loss: 2.114628314971924
Validation loss: 2.0091773172219596

Epoch: 5| Step: 1
Training loss: 1.9785892963409424
Validation loss: 2.005118449529012

Epoch: 5| Step: 2
Training loss: 2.1375346183776855
Validation loss: 2.0034147451321282

Epoch: 5| Step: 3
Training loss: 2.175940752029419
Validation loss: 2.002583235502243

Epoch: 5| Step: 4
Training loss: 2.0820670127868652
Validation loss: 2.01186333100001

Epoch: 5| Step: 5
Training loss: 2.53956937789917
Validation loss: 2.0107214550177255

Epoch: 5| Step: 6
Training loss: 2.933375120162964
Validation loss: 2.008724515636762

Epoch: 5| Step: 7
Training loss: 1.829123854637146
Validation loss: 2.0091327180465064

Epoch: 5| Step: 8
Training loss: 2.5351758003234863
Validation loss: 2.0102826257546744

Epoch: 5| Step: 9
Training loss: 1.810956597328186
Validation loss: 2.0144426971673965

Epoch: 5| Step: 10
Training loss: 1.8098971843719482
Validation loss: 2.0201568454504013

Epoch: 5| Step: 11
Training loss: 0.8082565665245056
Validation loss: 2.018500213821729

Epoch: 87| Step: 0
Training loss: 1.9876677989959717
Validation loss: 2.0266851782798767

Epoch: 5| Step: 1
Training loss: 2.6589457988739014
Validation loss: 2.038582980632782

Epoch: 5| Step: 2
Training loss: 2.7798800468444824
Validation loss: 2.038850719730059

Epoch: 5| Step: 3
Training loss: 1.7988373041152954
Validation loss: 2.039910147587458

Epoch: 5| Step: 4
Training loss: 2.0996851921081543
Validation loss: 2.0436394810676575

Epoch: 5| Step: 5
Training loss: 2.4423186779022217
Validation loss: 2.054717163244883

Epoch: 5| Step: 6
Training loss: 2.264202117919922
Validation loss: 2.054327353835106

Epoch: 5| Step: 7
Training loss: 1.751233696937561
Validation loss: 2.045812467734019

Epoch: 5| Step: 8
Training loss: 2.2731592655181885
Validation loss: 2.0301388104756675

Epoch: 5| Step: 9
Training loss: 1.9050451517105103
Validation loss: 2.020909453431765

Epoch: 5| Step: 10
Training loss: 2.076228618621826
Validation loss: 2.0144249349832535

Epoch: 5| Step: 11
Training loss: 2.300750255584717
Validation loss: 2.0226187060276666

Epoch: 88| Step: 0
Training loss: 2.2596380710601807
Validation loss: 2.0236971775690713

Epoch: 5| Step: 1
Training loss: 1.8176352977752686
Validation loss: 2.0289242466290793

Epoch: 5| Step: 2
Training loss: 2.2608370780944824
Validation loss: 2.0269041707118354

Epoch: 5| Step: 3
Training loss: 2.0538249015808105
Validation loss: 2.033024792869886

Epoch: 5| Step: 4
Training loss: 2.0739517211914062
Validation loss: 2.0344788829485574

Epoch: 5| Step: 5
Training loss: 2.8443143367767334
Validation loss: 2.0349549055099487

Epoch: 5| Step: 6
Training loss: 1.923193335533142
Validation loss: 2.0351453771193824

Epoch: 5| Step: 7
Training loss: 2.372568368911743
Validation loss: 2.029256964723269

Epoch: 5| Step: 8
Training loss: 2.3353309631347656
Validation loss: 2.032007614771525

Epoch: 5| Step: 9
Training loss: 1.7591140270233154
Validation loss: 2.03589936097463

Epoch: 5| Step: 10
Training loss: 2.114561080932617
Validation loss: 2.0327721486488977

Epoch: 5| Step: 11
Training loss: 3.305285930633545
Validation loss: 2.0286612759033837

Epoch: 89| Step: 0
Training loss: 1.8543134927749634
Validation loss: 2.0250325252612433

Epoch: 5| Step: 1
Training loss: 1.7122085094451904
Validation loss: 2.015700022379557

Epoch: 5| Step: 2
Training loss: 2.1551952362060547
Validation loss: 2.020369902253151

Epoch: 5| Step: 3
Training loss: 2.172792673110962
Validation loss: 2.0141481359799704

Epoch: 5| Step: 4
Training loss: 2.2564587593078613
Validation loss: 2.014076386888822

Epoch: 5| Step: 5
Training loss: 2.2456822395324707
Validation loss: 2.012072821458181

Epoch: 5| Step: 6
Training loss: 2.002586841583252
Validation loss: 2.0216971089442572

Epoch: 5| Step: 7
Training loss: 2.53615140914917
Validation loss: 2.0280626018842063

Epoch: 5| Step: 8
Training loss: 2.4505505561828613
Validation loss: 2.031982108950615

Epoch: 5| Step: 9
Training loss: 1.8464515209197998
Validation loss: 2.0381512542565665

Epoch: 5| Step: 10
Training loss: 2.1866281032562256
Validation loss: 2.0252059499422708

Epoch: 5| Step: 11
Training loss: 3.540567398071289
Validation loss: 2.0352213035027185

Epoch: 90| Step: 0
Training loss: 2.392918109893799
Validation loss: 2.0338399161895118

Epoch: 5| Step: 1
Training loss: 2.1071133613586426
Validation loss: 2.0270875046650567

Epoch: 5| Step: 2
Training loss: 2.1344082355499268
Validation loss: 2.0117017130057016

Epoch: 5| Step: 3
Training loss: 1.9692665338516235
Validation loss: 2.012566770116488

Epoch: 5| Step: 4
Training loss: 2.1452300548553467
Validation loss: 2.0159316460291543

Epoch: 5| Step: 5
Training loss: 1.8356552124023438
Validation loss: 2.0110181470712027

Epoch: 5| Step: 6
Training loss: 1.962205171585083
Validation loss: 2.0091412464777627

Epoch: 5| Step: 7
Training loss: 2.5886788368225098
Validation loss: 2.016724372903506

Epoch: 5| Step: 8
Training loss: 2.5809836387634277
Validation loss: 2.0182787577311196

Epoch: 5| Step: 9
Training loss: 2.015908718109131
Validation loss: 2.0154825250307717

Epoch: 5| Step: 10
Training loss: 1.847275972366333
Validation loss: 2.0104555586973825

Epoch: 5| Step: 11
Training loss: 2.279697895050049
Validation loss: 2.006906638542811

Epoch: 91| Step: 0
Training loss: 2.5906453132629395
Validation loss: 2.007810205221176

Epoch: 5| Step: 1
Training loss: 2.826242208480835
Validation loss: 2.013219545284907

Epoch: 5| Step: 2
Training loss: 2.2468819618225098
Validation loss: 2.0099878758192062

Epoch: 5| Step: 3
Training loss: 1.5045028924942017
Validation loss: 2.010693460702896

Epoch: 5| Step: 4
Training loss: 2.1243577003479004
Validation loss: 2.009218076864878

Epoch: 5| Step: 5
Training loss: 1.4201911687850952
Validation loss: 2.004328111807505

Epoch: 5| Step: 6
Training loss: 2.3571982383728027
Validation loss: 2.004039004445076

Epoch: 5| Step: 7
Training loss: 2.203174114227295
Validation loss: 2.0106096416711807

Epoch: 5| Step: 8
Training loss: 1.7719417810440063
Validation loss: 2.0133962829907737

Epoch: 5| Step: 9
Training loss: 2.4191131591796875
Validation loss: 2.0129205087820687

Epoch: 5| Step: 10
Training loss: 2.121849298477173
Validation loss: 2.010039726893107

Epoch: 5| Step: 11
Training loss: 2.1355037689208984
Validation loss: 2.022034391760826

Epoch: 92| Step: 0
Training loss: 2.5315842628479004
Validation loss: 2.024130960305532

Epoch: 5| Step: 1
Training loss: 1.941839575767517
Validation loss: 2.026046941677729

Epoch: 5| Step: 2
Training loss: 1.6906038522720337
Validation loss: 2.0313601394494376

Epoch: 5| Step: 3
Training loss: 2.3111348152160645
Validation loss: 2.027052958806356

Epoch: 5| Step: 4
Training loss: 2.12178111076355
Validation loss: 2.0205040772755942

Epoch: 5| Step: 5
Training loss: 1.883557677268982
Validation loss: 2.023670330643654

Epoch: 5| Step: 6
Training loss: 2.772880792617798
Validation loss: 2.030997375647227

Epoch: 5| Step: 7
Training loss: 1.5831695795059204
Validation loss: 2.0179104010264077

Epoch: 5| Step: 8
Training loss: 2.2201461791992188
Validation loss: 2.0209006617466607

Epoch: 5| Step: 9
Training loss: 2.150808095932007
Validation loss: 2.0227002948522568

Epoch: 5| Step: 10
Training loss: 2.5313267707824707
Validation loss: 2.024289737145106

Epoch: 5| Step: 11
Training loss: 2.0901505947113037
Validation loss: 2.017118270198504

Epoch: 93| Step: 0
Training loss: 2.048638343811035
Validation loss: 2.0182793686787286

Epoch: 5| Step: 1
Training loss: 2.1874375343322754
Validation loss: 2.009847412506739

Epoch: 5| Step: 2
Training loss: 1.9289859533309937
Validation loss: 2.0116131653388343

Epoch: 5| Step: 3
Training loss: 2.0222010612487793
Validation loss: 2.008630429704984

Epoch: 5| Step: 4
Training loss: 1.9431549310684204
Validation loss: 2.0180222590764365

Epoch: 5| Step: 5
Training loss: 2.4848928451538086
Validation loss: 2.0139235258102417

Epoch: 5| Step: 6
Training loss: 2.3015522956848145
Validation loss: 2.0063623040914536

Epoch: 5| Step: 7
Training loss: 2.265209674835205
Validation loss: 1.9996568461259205

Epoch: 5| Step: 8
Training loss: 1.7220052480697632
Validation loss: 2.004467378060023

Epoch: 5| Step: 9
Training loss: 2.265260934829712
Validation loss: 2.0028665562470755

Epoch: 5| Step: 10
Training loss: 2.535649061203003
Validation loss: 2.003269925713539

Epoch: 5| Step: 11
Training loss: 1.157067060470581
Validation loss: 1.9982756773630779

Epoch: 94| Step: 0
Training loss: 2.0875391960144043
Validation loss: 2.010994623104731

Epoch: 5| Step: 1
Training loss: 2.236962080001831
Validation loss: 2.013537183403969

Epoch: 5| Step: 2
Training loss: 2.1155471801757812
Validation loss: 2.014877667029699

Epoch: 5| Step: 3
Training loss: 1.7845308780670166
Validation loss: 2.0087535778681436

Epoch: 5| Step: 4
Training loss: 2.234739303588867
Validation loss: 2.0164699057737985

Epoch: 5| Step: 5
Training loss: 1.7945797443389893
Validation loss: 2.021097640196482

Epoch: 5| Step: 6
Training loss: 2.182539463043213
Validation loss: 2.0299908270438514

Epoch: 5| Step: 7
Training loss: 2.430773973464966
Validation loss: 2.022118682662646

Epoch: 5| Step: 8
Training loss: 2.2318577766418457
Validation loss: 2.012042616804441

Epoch: 5| Step: 9
Training loss: 2.2397971153259277
Validation loss: 2.0179311285416284

Epoch: 5| Step: 10
Training loss: 2.136996030807495
Validation loss: 2.01609343290329

Epoch: 5| Step: 11
Training loss: 1.934049367904663
Validation loss: 2.0177316615978875

Epoch: 95| Step: 0
Training loss: 2.1287384033203125
Validation loss: 2.0076937576135

Epoch: 5| Step: 1
Training loss: 1.732836127281189
Validation loss: 2.0256807704766593

Epoch: 5| Step: 2
Training loss: 2.7892513275146484
Validation loss: 2.0262442529201508

Epoch: 5| Step: 3
Training loss: 2.130990982055664
Validation loss: 2.0271271963914237

Epoch: 5| Step: 4
Training loss: 2.0699281692504883
Validation loss: 2.027700180808703

Epoch: 5| Step: 5
Training loss: 2.4904799461364746
Validation loss: 2.024093727270762

Epoch: 5| Step: 6
Training loss: 2.056694269180298
Validation loss: 2.0215168992678323

Epoch: 5| Step: 7
Training loss: 2.139249801635742
Validation loss: 2.0068912704785666

Epoch: 5| Step: 8
Training loss: 1.4704453945159912
Validation loss: 2.0002684046824775

Epoch: 5| Step: 9
Training loss: 2.307746410369873
Validation loss: 2.0133369167645774

Epoch: 5| Step: 10
Training loss: 2.2475829124450684
Validation loss: 2.0228439221779504

Epoch: 5| Step: 11
Training loss: 2.6205039024353027
Validation loss: 2.0044438441594443

Epoch: 96| Step: 0
Training loss: 1.574237585067749
Validation loss: 2.015343025326729

Epoch: 5| Step: 1
Training loss: 2.4115519523620605
Validation loss: 2.0138499389092126

Epoch: 5| Step: 2
Training loss: 2.4654505252838135
Validation loss: 2.0282738705476127

Epoch: 5| Step: 3
Training loss: 1.7939560413360596
Validation loss: 2.0183543413877487

Epoch: 5| Step: 4
Training loss: 2.162480592727661
Validation loss: 2.0160513569911322

Epoch: 5| Step: 5
Training loss: 2.1716809272766113
Validation loss: 2.001793543497721

Epoch: 5| Step: 6
Training loss: 1.8960189819335938
Validation loss: 2.0111676454544067

Epoch: 5| Step: 7
Training loss: 2.4008545875549316
Validation loss: 2.008646165331205

Epoch: 5| Step: 8
Training loss: 2.210301399230957
Validation loss: 2.0157720744609833

Epoch: 5| Step: 9
Training loss: 1.8533872365951538
Validation loss: 2.0061863909165063

Epoch: 5| Step: 10
Training loss: 2.4549789428710938
Validation loss: 2.01531720161438

Epoch: 5| Step: 11
Training loss: 2.803447723388672
Validation loss: 2.0107733805974326

Epoch: 97| Step: 0
Training loss: 2.1525139808654785
Validation loss: 2.008189246058464

Epoch: 5| Step: 1
Training loss: 2.139934539794922
Validation loss: 2.0088309943675995

Epoch: 5| Step: 2
Training loss: 2.37864089012146
Validation loss: 2.007260118921598

Epoch: 5| Step: 3
Training loss: 1.604006052017212
Validation loss: 2.0073391844828925

Epoch: 5| Step: 4
Training loss: 2.2039690017700195
Validation loss: 2.0153538435697556

Epoch: 5| Step: 5
Training loss: 2.278249502182007
Validation loss: 2.011374374230703

Epoch: 5| Step: 6
Training loss: 2.446502447128296
Validation loss: 2.022461637854576

Epoch: 5| Step: 7
Training loss: 2.0888209342956543
Validation loss: 2.0126221080621085

Epoch: 5| Step: 8
Training loss: 1.6647049188613892
Validation loss: 2.0184615155061087

Epoch: 5| Step: 9
Training loss: 2.146636962890625
Validation loss: 2.0163422326246896

Epoch: 5| Step: 10
Training loss: 2.498908519744873
Validation loss: 2.0266500115394592

Epoch: 5| Step: 11
Training loss: 1.3921419382095337
Validation loss: 2.0321916739145913

Epoch: 98| Step: 0
Training loss: 2.081256866455078
Validation loss: 2.032745679219564

Epoch: 5| Step: 1
Training loss: 2.0948262214660645
Validation loss: 2.038608824213346

Epoch: 5| Step: 2
Training loss: 1.8071056604385376
Validation loss: 2.0348340272903442

Epoch: 5| Step: 3
Training loss: 2.82265043258667
Validation loss: 2.0269144078095755

Epoch: 5| Step: 4
Training loss: 2.3183226585388184
Validation loss: 2.027130668361982

Epoch: 5| Step: 5
Training loss: 2.3268465995788574
Validation loss: 2.02618141969045

Epoch: 5| Step: 6
Training loss: 2.4214229583740234
Validation loss: 2.0283134977022805

Epoch: 5| Step: 7
Training loss: 2.010159730911255
Validation loss: 2.020974005262057

Epoch: 5| Step: 8
Training loss: 1.8458976745605469
Validation loss: 2.0123766660690308

Epoch: 5| Step: 9
Training loss: 1.6811323165893555
Validation loss: 2.009193648894628

Epoch: 5| Step: 10
Training loss: 2.0984280109405518
Validation loss: 2.0056486378113427

Epoch: 5| Step: 11
Training loss: 2.044461250305176
Validation loss: 2.0034323732058206

Epoch: 99| Step: 0
Training loss: 2.345259666442871
Validation loss: 2.005587120850881

Epoch: 5| Step: 1
Training loss: 1.5970450639724731
Validation loss: 2.0170768996079764

Epoch: 5| Step: 2
Training loss: 2.2439613342285156
Validation loss: 2.0078525294860206

Epoch: 5| Step: 3
Training loss: 1.895043969154358
Validation loss: 2.006638392806053

Epoch: 5| Step: 4
Training loss: 2.4488580226898193
Validation loss: 2.0080779691537223

Epoch: 5| Step: 5
Training loss: 2.042011260986328
Validation loss: 2.004033779104551

Epoch: 5| Step: 6
Training loss: 2.0484604835510254
Validation loss: 2.0060046861569085

Epoch: 5| Step: 7
Training loss: 2.047769546508789
Validation loss: 2.00198824206988

Epoch: 5| Step: 8
Training loss: 2.287926197052002
Validation loss: 2.004697243372599

Epoch: 5| Step: 9
Training loss: 2.456608533859253
Validation loss: 2.004307101170222

Epoch: 5| Step: 10
Training loss: 2.229449510574341
Validation loss: 2.0017236322164536

Epoch: 5| Step: 11
Training loss: 1.577932357788086
Validation loss: 2.005821938316027

Epoch: 100| Step: 0
Training loss: 2.2176694869995117
Validation loss: 2.011621450384458

Epoch: 5| Step: 1
Training loss: 1.5012915134429932
Validation loss: 2.033868670463562

Epoch: 5| Step: 2
Training loss: 2.2117600440979004
Validation loss: 2.052249918381373

Epoch: 5| Step: 3
Training loss: 2.8374109268188477
Validation loss: 2.0638045370578766

Epoch: 5| Step: 4
Training loss: 2.05444598197937
Validation loss: 2.062258705496788

Epoch: 5| Step: 5
Training loss: 2.1002845764160156
Validation loss: 2.05322157839934

Epoch: 5| Step: 6
Training loss: 2.145026445388794
Validation loss: 2.054292604327202

Epoch: 5| Step: 7
Training loss: 1.6209609508514404
Validation loss: 2.051127498348554

Epoch: 5| Step: 8
Training loss: 2.7926924228668213
Validation loss: 2.0547124594449997

Epoch: 5| Step: 9
Training loss: 1.49281907081604
Validation loss: 2.038433164358139

Epoch: 5| Step: 10
Training loss: 2.6334102153778076
Validation loss: 2.016602282722791

Epoch: 5| Step: 11
Training loss: 2.66461181640625
Validation loss: 2.006381005048752

Epoch: 101| Step: 0
Training loss: 1.9700486660003662
Validation loss: 2.003146459658941

Epoch: 5| Step: 1
Training loss: 2.254213333129883
Validation loss: 2.0003152936697006

Epoch: 5| Step: 2
Training loss: 2.0477020740509033
Validation loss: 2.007670039931933

Epoch: 5| Step: 3
Training loss: 2.33019757270813
Validation loss: 2.0158724933862686

Epoch: 5| Step: 4
Training loss: 2.219775915145874
Validation loss: 2.0210111687580743

Epoch: 5| Step: 5
Training loss: 2.2748515605926514
Validation loss: 2.0214818716049194

Epoch: 5| Step: 6
Training loss: 1.8520663976669312
Validation loss: 2.0270783454179764

Epoch: 5| Step: 7
Training loss: 1.722739577293396
Validation loss: 2.0242326309283576

Epoch: 5| Step: 8
Training loss: 2.083836793899536
Validation loss: 2.0327284236749015

Epoch: 5| Step: 9
Training loss: 2.5102741718292236
Validation loss: 2.034373104572296

Epoch: 5| Step: 10
Training loss: 2.405517101287842
Validation loss: 2.0210222055514655

Epoch: 5| Step: 11
Training loss: 2.4531567096710205
Validation loss: 2.017650236686071

Epoch: 102| Step: 0
Training loss: 2.115009069442749
Validation loss: 2.012958620985349

Epoch: 5| Step: 1
Training loss: 1.9398475885391235
Validation loss: 2.010838568210602

Epoch: 5| Step: 2
Training loss: 2.043302059173584
Validation loss: 2.007712701956431

Epoch: 5| Step: 3
Training loss: 2.416931629180908
Validation loss: 2.002310817440351

Epoch: 5| Step: 4
Training loss: 2.2973618507385254
Validation loss: 2.0176820307970047

Epoch: 5| Step: 5
Training loss: 2.4234325885772705
Validation loss: 2.026000499725342

Epoch: 5| Step: 6
Training loss: 2.255167007446289
Validation loss: 2.0307491372028985

Epoch: 5| Step: 7
Training loss: 2.5945682525634766
Validation loss: 2.0418261885643005

Epoch: 5| Step: 8
Training loss: 1.5993366241455078
Validation loss: 2.0355572005112967

Epoch: 5| Step: 9
Training loss: 2.12548565864563
Validation loss: 2.0339961101611457

Epoch: 5| Step: 10
Training loss: 1.6273314952850342
Validation loss: 2.029645323753357

Epoch: 5| Step: 11
Training loss: 3.2089662551879883
Validation loss: 2.0231740971406302

Epoch: 103| Step: 0
Training loss: 2.649585723876953
Validation loss: 2.0140538116296134

Epoch: 5| Step: 1
Training loss: 1.888806700706482
Validation loss: 2.0139904767274857

Epoch: 5| Step: 2
Training loss: 1.8107726573944092
Validation loss: 2.0097966690858207

Epoch: 5| Step: 3
Training loss: 2.06343674659729
Validation loss: 2.0097119410832724

Epoch: 5| Step: 4
Training loss: 1.6735929250717163
Validation loss: 2.00909952322642

Epoch: 5| Step: 5
Training loss: 2.1244893074035645
Validation loss: 2.010108143091202

Epoch: 5| Step: 6
Training loss: 1.8062775135040283
Validation loss: 2.020542080203692

Epoch: 5| Step: 7
Training loss: 2.360368490219116
Validation loss: 2.016718124349912

Epoch: 5| Step: 8
Training loss: 2.1918489933013916
Validation loss: 2.018603026866913

Epoch: 5| Step: 9
Training loss: 2.6749207973480225
Validation loss: 2.02429007490476

Epoch: 5| Step: 10
Training loss: 2.3135507106781006
Validation loss: 2.0206650843222937

Epoch: 5| Step: 11
Training loss: 1.4050297737121582
Validation loss: 2.018211076656977

Epoch: 104| Step: 0
Training loss: 1.9941555261611938
Validation loss: 2.013568634788195

Epoch: 5| Step: 1
Training loss: 1.7461678981781006
Validation loss: 2.0103436360756555

Epoch: 5| Step: 2
Training loss: 1.7667810916900635
Validation loss: 2.010117123524348

Epoch: 5| Step: 3
Training loss: 2.2686386108398438
Validation loss: 2.0129036903381348

Epoch: 5| Step: 4
Training loss: 1.9938862323760986
Validation loss: 2.012325013677279

Epoch: 5| Step: 5
Training loss: 2.3114728927612305
Validation loss: 2.009591445326805

Epoch: 5| Step: 6
Training loss: 2.225797653198242
Validation loss: 2.0142477403084436

Epoch: 5| Step: 7
Training loss: 2.2232089042663574
Validation loss: 2.0090461472670236

Epoch: 5| Step: 8
Training loss: 2.2141268253326416
Validation loss: 2.009225979447365

Epoch: 5| Step: 9
Training loss: 2.4793004989624023
Validation loss: 2.018364374836286

Epoch: 5| Step: 10
Training loss: 2.175690174102783
Validation loss: 2.0087112734715142

Epoch: 5| Step: 11
Training loss: 1.5201913118362427
Validation loss: 2.0089532335599265

Epoch: 105| Step: 0
Training loss: 2.00565767288208
Validation loss: 2.0078186790148416

Epoch: 5| Step: 1
Training loss: 2.2250373363494873
Validation loss: 2.012101044257482

Epoch: 5| Step: 2
Training loss: 2.2604928016662598
Validation loss: 2.011613756418228

Epoch: 5| Step: 3
Training loss: 2.348407745361328
Validation loss: 2.016017958521843

Epoch: 5| Step: 4
Training loss: 2.0585532188415527
Validation loss: 2.0086667587359748

Epoch: 5| Step: 5
Training loss: 2.179185628890991
Validation loss: 2.0114358961582184

Epoch: 5| Step: 6
Training loss: 2.0956051349639893
Validation loss: 2.0069959461688995

Epoch: 5| Step: 7
Training loss: 2.202871799468994
Validation loss: 2.0059651136398315

Epoch: 5| Step: 8
Training loss: 2.0111770629882812
Validation loss: 1.9985018422206242

Epoch: 5| Step: 9
Training loss: 2.039691209793091
Validation loss: 2.0016451428333917

Epoch: 5| Step: 10
Training loss: 2.127558708190918
Validation loss: 2.0084012548128762

Epoch: 5| Step: 11
Training loss: 1.2012165784835815
Validation loss: 2.0067720164855323

Epoch: 106| Step: 0
Training loss: 2.094761610031128
Validation loss: 2.009901617964109

Epoch: 5| Step: 1
Training loss: 1.533666729927063
Validation loss: 2.017351354161898

Epoch: 5| Step: 2
Training loss: 1.794999361038208
Validation loss: 2.017894188563029

Epoch: 5| Step: 3
Training loss: 1.931016206741333
Validation loss: 2.0178153216838837

Epoch: 5| Step: 4
Training loss: 2.1656737327575684
Validation loss: 2.023831988374392

Epoch: 5| Step: 5
Training loss: 2.0374398231506348
Validation loss: 2.0258584866921105

Epoch: 5| Step: 6
Training loss: 1.8788875341415405
Validation loss: 2.009867156545321

Epoch: 5| Step: 7
Training loss: 2.774055004119873
Validation loss: 2.0166882226864495

Epoch: 5| Step: 8
Training loss: 2.264894723892212
Validation loss: 2.0080294758081436

Epoch: 5| Step: 9
Training loss: 2.1836161613464355
Validation loss: 2.003684788942337

Epoch: 5| Step: 10
Training loss: 2.60221004486084
Validation loss: 2.0055867383877435

Epoch: 5| Step: 11
Training loss: 2.3725476264953613
Validation loss: 2.0053523778915405

Epoch: 107| Step: 0
Training loss: 1.9366251230239868
Validation loss: 2.0000909020503364

Epoch: 5| Step: 1
Training loss: 2.195265293121338
Validation loss: 2.0014729648828506

Epoch: 5| Step: 2
Training loss: 2.117497682571411
Validation loss: 2.0053061296542487

Epoch: 5| Step: 3
Training loss: 1.8951228857040405
Validation loss: 1.9998149176438649

Epoch: 5| Step: 4
Training loss: 1.8177963495254517
Validation loss: 2.0029210448265076

Epoch: 5| Step: 5
Training loss: 2.65152907371521
Validation loss: 2.0089294811089835

Epoch: 5| Step: 6
Training loss: 2.43048357963562
Validation loss: 2.0043238749106727

Epoch: 5| Step: 7
Training loss: 2.0070548057556152
Validation loss: 2.0029771625995636

Epoch: 5| Step: 8
Training loss: 1.7132999897003174
Validation loss: 2.0077540576457977

Epoch: 5| Step: 9
Training loss: 1.9185917377471924
Validation loss: 2.0023586998383203

Epoch: 5| Step: 10
Training loss: 2.5642597675323486
Validation loss: 2.0036376416683197

Epoch: 5| Step: 11
Training loss: 1.96260666847229
Validation loss: 2.0019878149032593

Epoch: 108| Step: 0
Training loss: 1.8620634078979492
Validation loss: 2.002968048055967

Epoch: 5| Step: 1
Training loss: 1.9879413843154907
Validation loss: 2.011689911286036

Epoch: 5| Step: 2
Training loss: 2.2340986728668213
Validation loss: 1.9997479021549225

Epoch: 5| Step: 3
Training loss: 1.3918052911758423
Validation loss: 2.0091889053583145

Epoch: 5| Step: 4
Training loss: 2.2139153480529785
Validation loss: 2.009933054447174

Epoch: 5| Step: 5
Training loss: 2.2730278968811035
Validation loss: 2.0061096449693046

Epoch: 5| Step: 6
Training loss: 2.605259895324707
Validation loss: 2.004749611020088

Epoch: 5| Step: 7
Training loss: 2.0027060508728027
Validation loss: 2.0093133648236594

Epoch: 5| Step: 8
Training loss: 2.2861337661743164
Validation loss: 2.013615235686302

Epoch: 5| Step: 9
Training loss: 2.175936222076416
Validation loss: 2.0134625881910324

Epoch: 5| Step: 10
Training loss: 1.9714069366455078
Validation loss: 2.0222876369953156

Epoch: 5| Step: 11
Training loss: 2.6699984073638916
Validation loss: 2.0149807830651603

Epoch: 109| Step: 0
Training loss: 2.775506019592285
Validation loss: 2.023939147591591

Epoch: 5| Step: 1
Training loss: 2.307677745819092
Validation loss: 2.0257758498191833

Epoch: 5| Step: 2
Training loss: 2.693659543991089
Validation loss: 2.0390282223622003

Epoch: 5| Step: 3
Training loss: 1.615813970565796
Validation loss: 2.050961881875992

Epoch: 5| Step: 4
Training loss: 1.8397867679595947
Validation loss: 2.0477718909581504

Epoch: 5| Step: 5
Training loss: 1.9483566284179688
Validation loss: 2.0503641019264855

Epoch: 5| Step: 6
Training loss: 2.249579668045044
Validation loss: 2.0520148475964866

Epoch: 5| Step: 7
Training loss: 1.7570250034332275
Validation loss: 2.0351787010828652

Epoch: 5| Step: 8
Training loss: 1.921918511390686
Validation loss: 2.012375995516777

Epoch: 5| Step: 9
Training loss: 2.0278940200805664
Validation loss: 2.014052559932073

Epoch: 5| Step: 10
Training loss: 2.136852264404297
Validation loss: 2.005882124106089

Epoch: 5| Step: 11
Training loss: 2.5847573280334473
Validation loss: 2.0107958863178887

Epoch: 110| Step: 0
Training loss: 1.379923701286316
Validation loss: 2.0083719740311303

Epoch: 5| Step: 1
Training loss: 2.6515085697174072
Validation loss: 2.0057343592246375

Epoch: 5| Step: 2
Training loss: 2.8208673000335693
Validation loss: 2.008695145448049

Epoch: 5| Step: 3
Training loss: 2.1465048789978027
Validation loss: 2.008831277489662

Epoch: 5| Step: 4
Training loss: 2.2270026206970215
Validation loss: 2.004417429367701

Epoch: 5| Step: 5
Training loss: 1.9183915853500366
Validation loss: 2.007371892531713

Epoch: 5| Step: 6
Training loss: 1.4037679433822632
Validation loss: 2.0000821302334466

Epoch: 5| Step: 7
Training loss: 2.075042724609375
Validation loss: 2.004864056905111

Epoch: 5| Step: 8
Training loss: 2.431344509124756
Validation loss: 2.005251795053482

Epoch: 5| Step: 9
Training loss: 2.3374152183532715
Validation loss: 2.0053074111541114

Epoch: 5| Step: 10
Training loss: 1.9017105102539062
Validation loss: 2.007727712392807

Epoch: 5| Step: 11
Training loss: 1.9395259618759155
Validation loss: 2.007890154918035

Epoch: 111| Step: 0
Training loss: 2.3796284198760986
Validation loss: 2.014530753095945

Epoch: 5| Step: 1
Training loss: 1.5936973094940186
Validation loss: 2.025315135717392

Epoch: 5| Step: 2
Training loss: 2.9294698238372803
Validation loss: 2.0249680876731873

Epoch: 5| Step: 3
Training loss: 2.206951141357422
Validation loss: 2.029877026875814

Epoch: 5| Step: 4
Training loss: 2.34698748588562
Validation loss: 2.0341688295205436

Epoch: 5| Step: 5
Training loss: 1.8399527072906494
Validation loss: 2.0264591375986734

Epoch: 5| Step: 6
Training loss: 1.8743118047714233
Validation loss: 2.025277222196261

Epoch: 5| Step: 7
Training loss: 1.9759315252304077
Validation loss: 2.027333984772364

Epoch: 5| Step: 8
Training loss: 2.0015158653259277
Validation loss: 2.0178447564442954

Epoch: 5| Step: 9
Training loss: 2.0848793983459473
Validation loss: 2.0182811419169107

Epoch: 5| Step: 10
Training loss: 2.1628212928771973
Validation loss: 2.0202070524295173

Epoch: 5| Step: 11
Training loss: 2.0103988647460938
Validation loss: 2.0162630826234818

Epoch: 112| Step: 0
Training loss: 2.4939658641815186
Validation loss: 2.0060960253079734

Epoch: 5| Step: 1
Training loss: 2.0255181789398193
Validation loss: 2.0079728166262307

Epoch: 5| Step: 2
Training loss: 2.329082489013672
Validation loss: 2.0168752670288086

Epoch: 5| Step: 3
Training loss: 1.7011419534683228
Validation loss: 2.01214591662089

Epoch: 5| Step: 4
Training loss: 2.1914401054382324
Validation loss: 2.015341266989708

Epoch: 5| Step: 5
Training loss: 2.0550270080566406
Validation loss: 2.014480541149775

Epoch: 5| Step: 6
Training loss: 2.2852795124053955
Validation loss: 2.019051045179367

Epoch: 5| Step: 7
Training loss: 2.103915214538574
Validation loss: 2.0083666245142617

Epoch: 5| Step: 8
Training loss: 2.3314127922058105
Validation loss: 2.0137133647998176

Epoch: 5| Step: 9
Training loss: 1.7550303936004639
Validation loss: 2.009438077608744

Epoch: 5| Step: 10
Training loss: 1.9426853656768799
Validation loss: 2.0112531731526055

Epoch: 5| Step: 11
Training loss: 2.1191914081573486
Validation loss: 2.018196627497673

Epoch: 113| Step: 0
Training loss: 1.7919524908065796
Validation loss: 2.01370836297671

Epoch: 5| Step: 1
Training loss: 1.9736604690551758
Validation loss: 2.01800666252772

Epoch: 5| Step: 2
Training loss: 2.2287049293518066
Validation loss: 2.009750703970591

Epoch: 5| Step: 3
Training loss: 1.6611744165420532
Validation loss: 2.0187846223513284

Epoch: 5| Step: 4
Training loss: 2.3566737174987793
Validation loss: 2.016844908396403

Epoch: 5| Step: 5
Training loss: 1.9058386087417603
Validation loss: 2.0237981379032135

Epoch: 5| Step: 6
Training loss: 2.267738103866577
Validation loss: 2.0240265081326165

Epoch: 5| Step: 7
Training loss: 1.9963737726211548
Validation loss: 2.0217584321896234

Epoch: 5| Step: 8
Training loss: 2.1074531078338623
Validation loss: 2.01616178949674

Epoch: 5| Step: 9
Training loss: 2.4047317504882812
Validation loss: 2.019398555159569

Epoch: 5| Step: 10
Training loss: 2.225097417831421
Validation loss: 2.0121737817923226

Epoch: 5| Step: 11
Training loss: 3.1442160606384277
Validation loss: 2.0077497015396752

Epoch: 114| Step: 0
Training loss: 1.8908027410507202
Validation loss: 2.0055497835079827

Epoch: 5| Step: 1
Training loss: 2.323004722595215
Validation loss: 2.0118640661239624

Epoch: 5| Step: 2
Training loss: 2.4717602729797363
Validation loss: 2.0054569393396378

Epoch: 5| Step: 3
Training loss: 2.123586416244507
Validation loss: 2.0077804972728095

Epoch: 5| Step: 4
Training loss: 1.8857460021972656
Validation loss: 2.0043159276247025

Epoch: 5| Step: 5
Training loss: 2.215360641479492
Validation loss: 2.0056294004122415

Epoch: 5| Step: 6
Training loss: 1.7326561212539673
Validation loss: 2.002676581343015

Epoch: 5| Step: 7
Training loss: 1.877234697341919
Validation loss: 2.0048521161079407

Epoch: 5| Step: 8
Training loss: 2.118626117706299
Validation loss: 1.9968472669521968

Epoch: 5| Step: 9
Training loss: 2.1861300468444824
Validation loss: 2.002527336279551

Epoch: 5| Step: 10
Training loss: 2.341629981994629
Validation loss: 1.9979563156763713

Epoch: 5| Step: 11
Training loss: 2.239992618560791
Validation loss: 2.0009315411249795

Epoch: 115| Step: 0
Training loss: 1.9363540410995483
Validation loss: 1.99970443546772

Epoch: 5| Step: 1
Training loss: 2.117039918899536
Validation loss: 2.0041170368591943

Epoch: 5| Step: 2
Training loss: 2.380335569381714
Validation loss: 2.007776767015457

Epoch: 5| Step: 3
Training loss: 2.1111907958984375
Validation loss: 2.010943432648977

Epoch: 5| Step: 4
Training loss: 2.6381542682647705
Validation loss: 2.0036452064911523

Epoch: 5| Step: 5
Training loss: 1.9558922052383423
Validation loss: 2.0046298851569495

Epoch: 5| Step: 6
Training loss: 1.969274878501892
Validation loss: 2.0136628299951553

Epoch: 5| Step: 7
Training loss: 2.0164191722869873
Validation loss: 2.008355145653089

Epoch: 5| Step: 8
Training loss: 1.9170868396759033
Validation loss: 2.013676638404528

Epoch: 5| Step: 9
Training loss: 2.422787666320801
Validation loss: 2.0136114954948425

Epoch: 5| Step: 10
Training loss: 1.8197616338729858
Validation loss: 2.0174577136834464

Epoch: 5| Step: 11
Training loss: 1.348307728767395
Validation loss: 2.0219995031754174

Epoch: 116| Step: 0
Training loss: 2.444329023361206
Validation loss: 2.0457863410313926

Epoch: 5| Step: 1
Training loss: 2.2788968086242676
Validation loss: 2.0403843224048615

Epoch: 5| Step: 2
Training loss: 1.9477672576904297
Validation loss: 2.0521990011135736

Epoch: 5| Step: 3
Training loss: 2.0343401432037354
Validation loss: 2.06362975637118

Epoch: 5| Step: 4
Training loss: 1.908042550086975
Validation loss: 2.0558405965566635

Epoch: 5| Step: 5
Training loss: 2.0097625255584717
Validation loss: 2.0426982392867408

Epoch: 5| Step: 6
Training loss: 2.3035309314727783
Validation loss: 2.030611972014109

Epoch: 5| Step: 7
Training loss: 2.0046966075897217
Validation loss: 2.0278898030519485

Epoch: 5| Step: 8
Training loss: 2.048518657684326
Validation loss: 2.0198605308930078

Epoch: 5| Step: 9
Training loss: 1.9617092609405518
Validation loss: 2.017107898990313

Epoch: 5| Step: 10
Training loss: 2.379561185836792
Validation loss: 2.0135876586039863

Epoch: 5| Step: 11
Training loss: 2.03446626663208
Validation loss: 2.01206403474013

Epoch: 117| Step: 0
Training loss: 2.193880081176758
Validation loss: 2.0106884837150574

Epoch: 5| Step: 1
Training loss: 2.053520917892456
Validation loss: 2.0072527627150216

Epoch: 5| Step: 2
Training loss: 2.0338358879089355
Validation loss: 2.018829276164373

Epoch: 5| Step: 3
Training loss: 2.284749984741211
Validation loss: 2.0146317780017853

Epoch: 5| Step: 4
Training loss: 2.1533424854278564
Validation loss: 2.016292547186216

Epoch: 5| Step: 5
Training loss: 1.9759712219238281
Validation loss: 2.014302263657252

Epoch: 5| Step: 6
Training loss: 2.014165163040161
Validation loss: 2.013921707868576

Epoch: 5| Step: 7
Training loss: 2.5229289531707764
Validation loss: 2.017816881338755

Epoch: 5| Step: 8
Training loss: 2.0720252990722656
Validation loss: 2.0176596889893212

Epoch: 5| Step: 9
Training loss: 2.0422680377960205
Validation loss: 2.0178471952676773

Epoch: 5| Step: 10
Training loss: 1.6736692190170288
Validation loss: 2.011622831225395

Epoch: 5| Step: 11
Training loss: 2.6996653079986572
Validation loss: 2.018775557478269

Epoch: 118| Step: 0
Training loss: 2.1807684898376465
Validation loss: 2.021269033352534

Epoch: 5| Step: 1
Training loss: 2.516869068145752
Validation loss: 2.021809329589208

Epoch: 5| Step: 2
Training loss: 1.8104751110076904
Validation loss: 2.025708874066671

Epoch: 5| Step: 3
Training loss: 1.9810664653778076
Validation loss: 2.0239847848812738

Epoch: 5| Step: 4
Training loss: 1.7195451259613037
Validation loss: 2.0264606922864914

Epoch: 5| Step: 5
Training loss: 2.3654932975769043
Validation loss: 2.0283960153659186

Epoch: 5| Step: 6
Training loss: 2.130542278289795
Validation loss: 2.0220963458220163

Epoch: 5| Step: 7
Training loss: 1.7558269500732422
Validation loss: 2.019258663058281

Epoch: 5| Step: 8
Training loss: 2.2530932426452637
Validation loss: 2.0356143563985825

Epoch: 5| Step: 9
Training loss: 2.27028226852417
Validation loss: 2.028671140472094

Epoch: 5| Step: 10
Training loss: 2.3737950325012207
Validation loss: 2.0206976930300393

Epoch: 5| Step: 11
Training loss: 0.975438117980957
Validation loss: 2.0222684095303216

Epoch: 119| Step: 0
Training loss: 2.1588644981384277
Validation loss: 2.025501703222593

Epoch: 5| Step: 1
Training loss: 1.7844234704971313
Validation loss: 2.029064858953158

Epoch: 5| Step: 2
Training loss: 2.304530620574951
Validation loss: 2.0322877913713455

Epoch: 5| Step: 3
Training loss: 2.2444827556610107
Validation loss: 2.028779928882917

Epoch: 5| Step: 4
Training loss: 2.1090776920318604
Validation loss: 2.0274026493231454

Epoch: 5| Step: 5
Training loss: 1.9951181411743164
Validation loss: 2.0309072583913803

Epoch: 5| Step: 6
Training loss: 1.5996121168136597
Validation loss: 2.0326567689577737

Epoch: 5| Step: 7
Training loss: 1.9578202962875366
Validation loss: 2.027916451295217

Epoch: 5| Step: 8
Training loss: 2.260960340499878
Validation loss: 2.031738758087158

Epoch: 5| Step: 9
Training loss: 2.6741275787353516
Validation loss: 2.021941607197126

Epoch: 5| Step: 10
Training loss: 1.8871185779571533
Validation loss: 2.0243205974499383

Epoch: 5| Step: 11
Training loss: 2.437238931655884
Validation loss: 2.026636466383934

Epoch: 120| Step: 0
Training loss: 2.2494049072265625
Validation loss: 2.018239955107371

Epoch: 5| Step: 1
Training loss: 2.309603214263916
Validation loss: 2.0136373986800513

Epoch: 5| Step: 2
Training loss: 2.0027384757995605
Validation loss: 2.0173530826965966

Epoch: 5| Step: 3
Training loss: 1.7417751550674438
Validation loss: 2.0070244719584784

Epoch: 5| Step: 4
Training loss: 2.4378206729888916
Validation loss: 2.0076706210772195

Epoch: 5| Step: 5
Training loss: 2.905984401702881
Validation loss: 2.006813352306684

Epoch: 5| Step: 6
Training loss: 1.8423435688018799
Validation loss: 2.011268521348635

Epoch: 5| Step: 7
Training loss: 2.0111794471740723
Validation loss: 2.010000934203466

Epoch: 5| Step: 8
Training loss: 1.847015619277954
Validation loss: 2.0111625691254935

Epoch: 5| Step: 9
Training loss: 2.2275023460388184
Validation loss: 2.012102802594503

Epoch: 5| Step: 10
Training loss: 1.667436957359314
Validation loss: 2.0033863137165704

Epoch: 5| Step: 11
Training loss: 1.9867902994155884
Validation loss: 2.0167038639386496

Epoch: 121| Step: 0
Training loss: 2.4243547916412354
Validation loss: 2.014820004502932

Epoch: 5| Step: 1
Training loss: 2.0030272006988525
Validation loss: 2.012311965227127

Epoch: 5| Step: 2
Training loss: 2.484321355819702
Validation loss: 2.0159884045521417

Epoch: 5| Step: 3
Training loss: 2.5306200981140137
Validation loss: 2.0222811301549277

Epoch: 5| Step: 4
Training loss: 1.7271556854248047
Validation loss: 2.030804713567098

Epoch: 5| Step: 5
Training loss: 1.8189239501953125
Validation loss: 2.03521699210008

Epoch: 5| Step: 6
Training loss: 1.813433289527893
Validation loss: 2.040231853723526

Epoch: 5| Step: 7
Training loss: 2.253816604614258
Validation loss: 2.041087493300438

Epoch: 5| Step: 8
Training loss: 1.774505853652954
Validation loss: 2.0610128243764243

Epoch: 5| Step: 9
Training loss: 1.6958577632904053
Validation loss: 2.0328321357568107

Epoch: 5| Step: 10
Training loss: 2.622087001800537
Validation loss: 2.0384665528933206

Epoch: 5| Step: 11
Training loss: 1.559281349182129
Validation loss: 2.0334962656100593

Epoch: 122| Step: 0
Training loss: 2.224483013153076
Validation loss: 2.024129475156466

Epoch: 5| Step: 1
Training loss: 1.7855451107025146
Validation loss: 2.015178292989731

Epoch: 5| Step: 2
Training loss: 2.1107282638549805
Validation loss: 2.0231583217779794

Epoch: 5| Step: 3
Training loss: 2.012035369873047
Validation loss: 2.015095671017965

Epoch: 5| Step: 4
Training loss: 2.157533645629883
Validation loss: 2.0203666339317956

Epoch: 5| Step: 5
Training loss: 2.198373317718506
Validation loss: 2.0214485774437585

Epoch: 5| Step: 6
Training loss: 1.9193528890609741
Validation loss: 2.025801345705986

Epoch: 5| Step: 7
Training loss: 2.157458782196045
Validation loss: 2.030127098162969

Epoch: 5| Step: 8
Training loss: 1.7651808261871338
Validation loss: 2.0243265479803085

Epoch: 5| Step: 9
Training loss: 2.242527484893799
Validation loss: 2.0219612568616867

Epoch: 5| Step: 10
Training loss: 2.209746837615967
Validation loss: 2.023819456497828

Epoch: 5| Step: 11
Training loss: 3.1747238636016846
Validation loss: 2.0222441256046295

Epoch: 123| Step: 0
Training loss: 1.8919427394866943
Validation loss: 2.0293440520763397

Epoch: 5| Step: 1
Training loss: 1.8328475952148438
Validation loss: 2.0362035234769187

Epoch: 5| Step: 2
Training loss: 1.8346741199493408
Validation loss: 2.0313954055309296

Epoch: 5| Step: 3
Training loss: 1.6920560598373413
Validation loss: 2.0394226064284644

Epoch: 5| Step: 4
Training loss: 1.8617862462997437
Validation loss: 2.038310637076696

Epoch: 5| Step: 5
Training loss: 2.871880292892456
Validation loss: 2.034893825650215

Epoch: 5| Step: 6
Training loss: 1.3520952463150024
Validation loss: 2.0381205727656684

Epoch: 5| Step: 7
Training loss: 2.3538126945495605
Validation loss: 2.0331535637378693

Epoch: 5| Step: 8
Training loss: 2.7661874294281006
Validation loss: 2.0279008795817695

Epoch: 5| Step: 9
Training loss: 1.9601967334747314
Validation loss: 2.028569052616755

Epoch: 5| Step: 10
Training loss: 2.472679615020752
Validation loss: 2.0266859432061515

Epoch: 5| Step: 11
Training loss: 3.1861510276794434
Validation loss: 2.0227940579255423

Epoch: 124| Step: 0
Training loss: 2.20365834236145
Validation loss: 2.017245834072431

Epoch: 5| Step: 1
Training loss: 1.9431699514389038
Validation loss: 2.020350163181623

Epoch: 5| Step: 2
Training loss: 1.5194978713989258
Validation loss: 2.020708978176117

Epoch: 5| Step: 3
Training loss: 2.2325987815856934
Validation loss: 2.0331514229377112

Epoch: 5| Step: 4
Training loss: 2.1614573001861572
Validation loss: 2.02360608180364

Epoch: 5| Step: 5
Training loss: 2.4814438819885254
Validation loss: 2.0304142783085504

Epoch: 5| Step: 6
Training loss: 1.7412519454956055
Validation loss: 2.022118260463079

Epoch: 5| Step: 7
Training loss: 2.2161991596221924
Validation loss: 2.0289051036039987

Epoch: 5| Step: 8
Training loss: 1.9827582836151123
Validation loss: 2.0231788208087287

Epoch: 5| Step: 9
Training loss: 2.029592990875244
Validation loss: 2.0276415248711905

Epoch: 5| Step: 10
Training loss: 2.381345748901367
Validation loss: 2.0240167627731958

Epoch: 5| Step: 11
Training loss: 2.4115407466888428
Validation loss: 2.021947051088015

Epoch: 125| Step: 0
Training loss: 1.9604135751724243
Validation loss: 2.02869521578153

Epoch: 5| Step: 1
Training loss: 2.1227126121520996
Validation loss: 2.0305716743071875

Epoch: 5| Step: 2
Training loss: 1.971923589706421
Validation loss: 2.02259428302447

Epoch: 5| Step: 3
Training loss: 1.8921626806259155
Validation loss: 2.0212618658939996

Epoch: 5| Step: 4
Training loss: 2.270294666290283
Validation loss: 2.028749465942383

Epoch: 5| Step: 5
Training loss: 2.323045253753662
Validation loss: 2.0256813963254294

Epoch: 5| Step: 6
Training loss: 2.3405086994171143
Validation loss: 2.027868871887525

Epoch: 5| Step: 7
Training loss: 1.7968170642852783
Validation loss: 2.026717931032181

Epoch: 5| Step: 8
Training loss: 2.2175941467285156
Validation loss: 2.0275242229302726

Epoch: 5| Step: 9
Training loss: 2.4379611015319824
Validation loss: 2.023591642578443

Epoch: 5| Step: 10
Training loss: 1.6804136037826538
Validation loss: 2.0350146194299064

Epoch: 5| Step: 11
Training loss: 1.8718222379684448
Validation loss: 2.037349378069242

Testing loss: 1.65284920253342
