Epoch: 1| Step: 0
Training loss: 6.3787848513019485
Validation loss: 5.873710950835428

Epoch: 6| Step: 1
Training loss: 6.350800603423426
Validation loss: 5.871724182649921

Epoch: 6| Step: 2
Training loss: 5.901473116835361
Validation loss: 5.869782884168669

Epoch: 6| Step: 3
Training loss: 5.780428441414061
Validation loss: 5.867861882110487

Epoch: 6| Step: 4
Training loss: 5.864539390747154
Validation loss: 5.866012272678547

Epoch: 6| Step: 5
Training loss: 5.711865893672985
Validation loss: 5.864115053207868

Epoch: 6| Step: 6
Training loss: 5.914702971635666
Validation loss: 5.86238006165451

Epoch: 6| Step: 7
Training loss: 6.001812661063811
Validation loss: 5.860520639953902

Epoch: 6| Step: 8
Training loss: 6.740086941030972
Validation loss: 5.858675793784916

Epoch: 6| Step: 9
Training loss: 6.142457334364821
Validation loss: 5.856773836692853

Epoch: 6| Step: 10
Training loss: 5.098065566660815
Validation loss: 5.8547541729677235

Epoch: 6| Step: 11
Training loss: 5.771774857854871
Validation loss: 5.852752550953167

Epoch: 6| Step: 12
Training loss: 6.203134224450006
Validation loss: 5.850634376929406

Epoch: 6| Step: 13
Training loss: 5.67081897667444
Validation loss: 5.8483117126314506

Epoch: 2| Step: 0
Training loss: 6.0619896742765205
Validation loss: 5.846012758568

Epoch: 6| Step: 1
Training loss: 6.503719146145042
Validation loss: 5.843644765086536

Epoch: 6| Step: 2
Training loss: 5.153036144779057
Validation loss: 5.841021793412989

Epoch: 6| Step: 3
Training loss: 6.058976870240662
Validation loss: 5.838431809611499

Epoch: 6| Step: 4
Training loss: 5.752093390161588
Validation loss: 5.83550912152117

Epoch: 6| Step: 5
Training loss: 6.19970147429385
Validation loss: 5.8326754698593

Epoch: 6| Step: 6
Training loss: 5.691337883511826
Validation loss: 5.829595249100137

Epoch: 6| Step: 7
Training loss: 5.915357238867974
Validation loss: 5.826301814527293

Epoch: 6| Step: 8
Training loss: 6.94183846299652
Validation loss: 5.823085129631965

Epoch: 6| Step: 9
Training loss: 5.550164936810947
Validation loss: 5.819480560036906

Epoch: 6| Step: 10
Training loss: 5.4271597927025645
Validation loss: 5.815780698238619

Epoch: 6| Step: 11
Training loss: 6.225429302563857
Validation loss: 5.811892761450559

Epoch: 6| Step: 12
Training loss: 5.698136998948785
Validation loss: 5.808001729437761

Epoch: 6| Step: 13
Training loss: 5.801974046135612
Validation loss: 5.803608564320899

Epoch: 3| Step: 0
Training loss: 6.184916872222988
Validation loss: 5.799213962346538

Epoch: 6| Step: 1
Training loss: 6.407405097845041
Validation loss: 5.794654935185623

Epoch: 6| Step: 2
Training loss: 6.111008525719467
Validation loss: 5.789925247131486

Epoch: 6| Step: 3
Training loss: 5.8625658629404285
Validation loss: 5.784858470999989

Epoch: 6| Step: 4
Training loss: 6.095812326300775
Validation loss: 5.779564771666647

Epoch: 6| Step: 5
Training loss: 5.552956956715473
Validation loss: 5.77422333265854

Epoch: 6| Step: 6
Training loss: 5.656211557837253
Validation loss: 5.768161205525738

Epoch: 6| Step: 7
Training loss: 5.30629520464402
Validation loss: 5.762217161528871

Epoch: 6| Step: 8
Training loss: 4.927446778047256
Validation loss: 5.755915211438112

Epoch: 6| Step: 9
Training loss: 6.074332419555397
Validation loss: 5.749388759024445

Epoch: 6| Step: 10
Training loss: 6.015552708575367
Validation loss: 5.742608613296416

Epoch: 6| Step: 11
Training loss: 5.72448742833266
Validation loss: 5.735469897219833

Epoch: 6| Step: 12
Training loss: 6.162203161429715
Validation loss: 5.727940995860815

Epoch: 6| Step: 13
Training loss: 6.0495347277590925
Validation loss: 5.72037464960078

Epoch: 4| Step: 0
Training loss: 6.048099679660333
Validation loss: 5.712178441185579

Epoch: 6| Step: 1
Training loss: 5.980441321989684
Validation loss: 5.703618973193929

Epoch: 6| Step: 2
Training loss: 6.373865961672185
Validation loss: 5.69482897052045

Epoch: 6| Step: 3
Training loss: 5.334279373822511
Validation loss: 5.685808649898026

Epoch: 6| Step: 4
Training loss: 5.16242601835799
Validation loss: 5.676172931245673

Epoch: 6| Step: 5
Training loss: 6.654854928261843
Validation loss: 5.666760649556211

Epoch: 6| Step: 6
Training loss: 5.7891026957528275
Validation loss: 5.65686464570546

Epoch: 6| Step: 7
Training loss: 6.577951025757613
Validation loss: 5.6469878345356435

Epoch: 6| Step: 8
Training loss: 5.61444355844346
Validation loss: 5.636568535812109

Epoch: 6| Step: 9
Training loss: 4.965733218109146
Validation loss: 5.626089259045639

Epoch: 6| Step: 10
Training loss: 5.976789083735919
Validation loss: 5.615724191725419

Epoch: 6| Step: 11
Training loss: 5.390322469431944
Validation loss: 5.605273944513505

Epoch: 6| Step: 12
Training loss: 5.416935058204472
Validation loss: 5.59439824786154

Epoch: 6| Step: 13
Training loss: 5.154359413105828
Validation loss: 5.584260673754458

Epoch: 5| Step: 0
Training loss: 5.472988731201213
Validation loss: 5.5741182071820425

Epoch: 6| Step: 1
Training loss: 6.065519229963147
Validation loss: 5.563401309939542

Epoch: 6| Step: 2
Training loss: 5.2858981833262915
Validation loss: 5.553149819305204

Epoch: 6| Step: 3
Training loss: 6.434159384288042
Validation loss: 5.54279993654618

Epoch: 6| Step: 4
Training loss: 5.954307458742152
Validation loss: 5.532489185210637

Epoch: 6| Step: 5
Training loss: 4.636507307468309
Validation loss: 5.522077609743584

Epoch: 6| Step: 6
Training loss: 4.932351820624911
Validation loss: 5.512033447682734

Epoch: 6| Step: 7
Training loss: 5.387793640489583
Validation loss: 5.502182614134786

Epoch: 6| Step: 8
Training loss: 5.113474656447784
Validation loss: 5.492543078325815

Epoch: 6| Step: 9
Training loss: 5.702991891640148
Validation loss: 5.482544364326426

Epoch: 6| Step: 10
Training loss: 5.5849519727207735
Validation loss: 5.473005052696743

Epoch: 6| Step: 11
Training loss: 6.348277313367156
Validation loss: 5.463548784521053

Epoch: 6| Step: 12
Training loss: 5.746599601714206
Validation loss: 5.453884971732697

Epoch: 6| Step: 13
Training loss: 5.803530427557349
Validation loss: 5.444513233987208

Epoch: 6| Step: 0
Training loss: 5.883480363400853
Validation loss: 5.4348487675275

Epoch: 6| Step: 1
Training loss: 4.9157863195179825
Validation loss: 5.425714106518498

Epoch: 6| Step: 2
Training loss: 4.690464760662904
Validation loss: 5.416942599188629

Epoch: 6| Step: 3
Training loss: 5.674763934229204
Validation loss: 5.408255996895688

Epoch: 6| Step: 4
Training loss: 4.725047172835681
Validation loss: 5.399857874754258

Epoch: 6| Step: 5
Training loss: 5.30198400538049
Validation loss: 5.391478834855304

Epoch: 6| Step: 6
Training loss: 6.032703283863115
Validation loss: 5.384006524683346

Epoch: 6| Step: 7
Training loss: 5.4664254616038175
Validation loss: 5.3758169632682495

Epoch: 6| Step: 8
Training loss: 5.863276045134265
Validation loss: 5.36843548091397

Epoch: 6| Step: 9
Training loss: 5.970297408116067
Validation loss: 5.360531340211495

Epoch: 6| Step: 10
Training loss: 5.356536202368119
Validation loss: 5.352708056280167

Epoch: 6| Step: 11
Training loss: 5.6528890329587504
Validation loss: 5.3446132564958555

Epoch: 6| Step: 12
Training loss: 5.100899201950282
Validation loss: 5.337055735148795

Epoch: 6| Step: 13
Training loss: 6.113560172351052
Validation loss: 5.329721698187154

Epoch: 7| Step: 0
Training loss: 5.681614775744738
Validation loss: 5.322505519488406

Epoch: 6| Step: 1
Training loss: 5.969359042266454
Validation loss: 5.314693850638359

Epoch: 6| Step: 2
Training loss: 5.635143712943561
Validation loss: 5.307517044727605

Epoch: 6| Step: 3
Training loss: 5.705218539653418
Validation loss: 5.300147022151451

Epoch: 6| Step: 4
Training loss: 5.955941882975262
Validation loss: 5.292871813572676

Epoch: 6| Step: 5
Training loss: 5.105456047947091
Validation loss: 5.285728827693382

Epoch: 6| Step: 6
Training loss: 4.916946898841829
Validation loss: 5.27853200219198

Epoch: 6| Step: 7
Training loss: 5.144374789999312
Validation loss: 5.272039368454004

Epoch: 6| Step: 8
Training loss: 6.057078031105621
Validation loss: 5.265534442609657

Epoch: 6| Step: 9
Training loss: 5.384561240793847
Validation loss: 5.259137119497729

Epoch: 6| Step: 10
Training loss: 4.8412280008184085
Validation loss: 5.252866870499565

Epoch: 6| Step: 11
Training loss: 5.3756509431076145
Validation loss: 5.246493849050991

Epoch: 6| Step: 12
Training loss: 4.78386222936968
Validation loss: 5.240219239412

Epoch: 6| Step: 13
Training loss: 4.819214137740251
Validation loss: 5.23417877284942

Epoch: 8| Step: 0
Training loss: 6.012136899647051
Validation loss: 5.228534837625017

Epoch: 6| Step: 1
Training loss: 4.048757461394937
Validation loss: 5.2224215081699965

Epoch: 6| Step: 2
Training loss: 5.430868731111124
Validation loss: 5.21671640821311

Epoch: 6| Step: 3
Training loss: 6.282205233840873
Validation loss: 5.21095262913221

Epoch: 6| Step: 4
Training loss: 4.838721834187977
Validation loss: 5.205249402327785

Epoch: 6| Step: 5
Training loss: 5.247831714281244
Validation loss: 5.198957635870171

Epoch: 6| Step: 6
Training loss: 4.577139582380222
Validation loss: 5.19325788594109

Epoch: 6| Step: 7
Training loss: 4.284689085818688
Validation loss: 5.187174407668523

Epoch: 6| Step: 8
Training loss: 5.14874572294372
Validation loss: 5.181507862823644

Epoch: 6| Step: 9
Training loss: 5.304209804234639
Validation loss: 5.175752720784187

Epoch: 6| Step: 10
Training loss: 6.519596197811604
Validation loss: 5.169341943157256

Epoch: 6| Step: 11
Training loss: 5.14388109413226
Validation loss: 5.163546029954085

Epoch: 6| Step: 12
Training loss: 5.635560697265055
Validation loss: 5.15713416331416

Epoch: 6| Step: 13
Training loss: 5.302241394844646
Validation loss: 5.1512555218446145

Epoch: 9| Step: 0
Training loss: 4.973119194254615
Validation loss: 5.14522480423178

Epoch: 6| Step: 1
Training loss: 5.932402018345974
Validation loss: 5.13895312546914

Epoch: 6| Step: 2
Training loss: 5.965691067233365
Validation loss: 5.132436551784074

Epoch: 6| Step: 3
Training loss: 4.59261427353512
Validation loss: 5.1264086082371145

Epoch: 6| Step: 4
Training loss: 5.312233592814693
Validation loss: 5.119980719003533

Epoch: 6| Step: 5
Training loss: 4.669293459064267
Validation loss: 5.113548262122972

Epoch: 6| Step: 6
Training loss: 5.813149036554233
Validation loss: 5.107400619627935

Epoch: 6| Step: 7
Training loss: 5.001011173997832
Validation loss: 5.100884307289206

Epoch: 6| Step: 8
Training loss: 4.633562152801768
Validation loss: 5.094210832028811

Epoch: 6| Step: 9
Training loss: 5.52479840769586
Validation loss: 5.087658943861384

Epoch: 6| Step: 10
Training loss: 5.374055291479508
Validation loss: 5.0809874306843446

Epoch: 6| Step: 11
Training loss: 4.7865724546534825
Validation loss: 5.074652696573898

Epoch: 6| Step: 12
Training loss: 5.020818095625974
Validation loss: 5.067876590184638

Epoch: 6| Step: 13
Training loss: 5.322102025868621
Validation loss: 5.061590701728433

Epoch: 10| Step: 0
Training loss: 5.2509624870499
Validation loss: 5.055271340975866

Epoch: 6| Step: 1
Training loss: 5.1388808425061345
Validation loss: 5.048907174943292

Epoch: 6| Step: 2
Training loss: 5.877793966622384
Validation loss: 5.042987156644048

Epoch: 6| Step: 3
Training loss: 4.800745095597182
Validation loss: 5.036448602624255

Epoch: 6| Step: 4
Training loss: 4.778545936420356
Validation loss: 5.0306926916200645

Epoch: 6| Step: 5
Training loss: 5.480191713863952
Validation loss: 5.024874104556477

Epoch: 6| Step: 6
Training loss: 4.7968962727923055
Validation loss: 5.01918253794405

Epoch: 6| Step: 7
Training loss: 5.182213352959882
Validation loss: 5.012997359844258

Epoch: 6| Step: 8
Training loss: 5.170577425263501
Validation loss: 5.007059200322141

Epoch: 6| Step: 9
Training loss: 4.804413975318971
Validation loss: 5.000865924874996

Epoch: 6| Step: 10
Training loss: 5.185469080454592
Validation loss: 4.9956595018616765

Epoch: 6| Step: 11
Training loss: 5.745943711926266
Validation loss: 4.989304181003746

Epoch: 6| Step: 12
Training loss: 4.298283016821972
Validation loss: 4.9836006798790455

Epoch: 6| Step: 13
Training loss: 5.248198427170702
Validation loss: 4.978139295156372

Epoch: 11| Step: 0
Training loss: 5.460563068350873
Validation loss: 4.972658327656102

Epoch: 6| Step: 1
Training loss: 5.452752305550701
Validation loss: 4.967363815962248

Epoch: 6| Step: 2
Training loss: 4.792327813133224
Validation loss: 4.961664165632451

Epoch: 6| Step: 3
Training loss: 5.576936311984357
Validation loss: 4.9559729698722785

Epoch: 6| Step: 4
Training loss: 4.412334812951859
Validation loss: 4.9505276613892395

Epoch: 6| Step: 5
Training loss: 5.209414967439099
Validation loss: 4.945310667980753

Epoch: 6| Step: 6
Training loss: 5.141920117891691
Validation loss: 4.939838515562507

Epoch: 6| Step: 7
Training loss: 5.561246237741759
Validation loss: 4.9361124785151915

Epoch: 6| Step: 8
Training loss: 4.927357747324339
Validation loss: 4.932574942435658

Epoch: 6| Step: 9
Training loss: 4.419533261127901
Validation loss: 4.927633253489549

Epoch: 6| Step: 10
Training loss: 4.91838254998114
Validation loss: 4.921983376576319

Epoch: 6| Step: 11
Training loss: 4.410069534895374
Validation loss: 4.917202979541161

Epoch: 6| Step: 12
Training loss: 4.8473654758935565
Validation loss: 4.911836039912095

Epoch: 6| Step: 13
Training loss: 5.52934102883289
Validation loss: 4.906471749577144

Epoch: 12| Step: 0
Training loss: 6.348495737757427
Validation loss: 4.900641570616025

Epoch: 6| Step: 1
Training loss: 3.9092456774891717
Validation loss: 4.89475038062776

Epoch: 6| Step: 2
Training loss: 4.849774557950035
Validation loss: 4.88941483967836

Epoch: 6| Step: 3
Training loss: 4.946231123951141
Validation loss: 4.8839732669762075

Epoch: 6| Step: 4
Training loss: 4.957017398030291
Validation loss: 4.879814281317033

Epoch: 6| Step: 5
Training loss: 5.233834218800096
Validation loss: 4.874014371693966

Epoch: 6| Step: 6
Training loss: 4.263078201768592
Validation loss: 4.870535803530083

Epoch: 6| Step: 7
Training loss: 4.883516746088435
Validation loss: 4.866020050377544

Epoch: 6| Step: 8
Training loss: 5.093652642378643
Validation loss: 4.859370551562138

Epoch: 6| Step: 9
Training loss: 5.888517048130458
Validation loss: 4.853414791090812

Epoch: 6| Step: 10
Training loss: 4.605413046670661
Validation loss: 4.848162472729144

Epoch: 6| Step: 11
Training loss: 4.935201761900324
Validation loss: 4.8429245440270705

Epoch: 6| Step: 12
Training loss: 4.079210392708191
Validation loss: 4.838393927359093

Epoch: 6| Step: 13
Training loss: 5.3504598330811755
Validation loss: 4.832519572363574

Epoch: 13| Step: 0
Training loss: 5.503049871829775
Validation loss: 4.82662751349662

Epoch: 6| Step: 1
Training loss: 4.91869762736919
Validation loss: 4.82044485643095

Epoch: 6| Step: 2
Training loss: 5.849802075811786
Validation loss: 4.814499179704925

Epoch: 6| Step: 3
Training loss: 4.991033716251844
Validation loss: 4.808713538059143

Epoch: 6| Step: 4
Training loss: 4.617641471839403
Validation loss: 4.803236761470237

Epoch: 6| Step: 5
Training loss: 4.821845158739887
Validation loss: 4.797193386185349

Epoch: 6| Step: 6
Training loss: 4.8054111338959835
Validation loss: 4.792566507959522

Epoch: 6| Step: 7
Training loss: 4.423415707528114
Validation loss: 4.786455698880816

Epoch: 6| Step: 8
Training loss: 5.157943539946836
Validation loss: 4.780876660367035

Epoch: 6| Step: 9
Training loss: 4.519815684923843
Validation loss: 4.775291536495398

Epoch: 6| Step: 10
Training loss: 5.370006637142917
Validation loss: 4.769541080932316

Epoch: 6| Step: 11
Training loss: 4.971610919069918
Validation loss: 4.764276666061406

Epoch: 6| Step: 12
Training loss: 4.7386990682953565
Validation loss: 4.75856824696964

Epoch: 6| Step: 13
Training loss: 3.8288562309829057
Validation loss: 4.752970486114362

Epoch: 14| Step: 0
Training loss: 5.586133833415915
Validation loss: 4.7476810014640405

Epoch: 6| Step: 1
Training loss: 4.615404640056501
Validation loss: 4.742677465324845

Epoch: 6| Step: 2
Training loss: 4.487568319751631
Validation loss: 4.7376328140202

Epoch: 6| Step: 3
Training loss: 4.33072977836392
Validation loss: 4.731707905456056

Epoch: 6| Step: 4
Training loss: 5.322478672628107
Validation loss: 4.727025772804568

Epoch: 6| Step: 5
Training loss: 4.43654289132181
Validation loss: 4.721823998408691

Epoch: 6| Step: 6
Training loss: 5.107842358408256
Validation loss: 4.71698793770641

Epoch: 6| Step: 7
Training loss: 5.138908308296054
Validation loss: 4.711593422002735

Epoch: 6| Step: 8
Training loss: 4.630345734773502
Validation loss: 4.706213341612819

Epoch: 6| Step: 9
Training loss: 5.223308285716231
Validation loss: 4.701152840039448

Epoch: 6| Step: 10
Training loss: 4.4178703155479795
Validation loss: 4.696370205092616

Epoch: 6| Step: 11
Training loss: 4.175634169240887
Validation loss: 4.691683178472288

Epoch: 6| Step: 12
Training loss: 5.335244710470689
Validation loss: 4.686337441284657

Epoch: 6| Step: 13
Training loss: 4.704477717632758
Validation loss: 4.68157615187536

Epoch: 15| Step: 0
Training loss: 5.37667323837935
Validation loss: 4.675930410676043

Epoch: 6| Step: 1
Training loss: 4.344765743354182
Validation loss: 4.670457486705308

Epoch: 6| Step: 2
Training loss: 5.15226897097933
Validation loss: 4.6656299302317175

Epoch: 6| Step: 3
Training loss: 5.590818521424386
Validation loss: 4.6605448532835485

Epoch: 6| Step: 4
Training loss: 4.429059450006777
Validation loss: 4.655871860246198

Epoch: 6| Step: 5
Training loss: 4.22245704823269
Validation loss: 4.651687571525184

Epoch: 6| Step: 6
Training loss: 5.161689432348726
Validation loss: 4.6463739340058465

Epoch: 6| Step: 7
Training loss: 4.082751226129617
Validation loss: 4.640494125353176

Epoch: 6| Step: 8
Training loss: 4.794753608936559
Validation loss: 4.635284056177512

Epoch: 6| Step: 9
Training loss: 5.282209320519789
Validation loss: 4.6296779069855845

Epoch: 6| Step: 10
Training loss: 3.7725039130835847
Validation loss: 4.624662919691362

Epoch: 6| Step: 11
Training loss: 4.673355531372231
Validation loss: 4.619488963890498

Epoch: 6| Step: 12
Training loss: 5.334611540847941
Validation loss: 4.614503703352417

Epoch: 6| Step: 13
Training loss: 4.108182436716949
Validation loss: 4.609469310420683

Epoch: 16| Step: 0
Training loss: 4.772816719108759
Validation loss: 4.604526465441073

Epoch: 6| Step: 1
Training loss: 5.279537848852013
Validation loss: 4.599650496874743

Epoch: 6| Step: 2
Training loss: 5.391032416386157
Validation loss: 4.594166051314601

Epoch: 6| Step: 3
Training loss: 4.546735728644542
Validation loss: 4.588717067222427

Epoch: 6| Step: 4
Training loss: 5.007232394369239
Validation loss: 4.583791253305034

Epoch: 6| Step: 5
Training loss: 3.6905723316074783
Validation loss: 4.578975906540837

Epoch: 6| Step: 6
Training loss: 5.373086810613583
Validation loss: 4.573791101685772

Epoch: 6| Step: 7
Training loss: 4.72250116060484
Validation loss: 4.568628036603639

Epoch: 6| Step: 8
Training loss: 4.371882826802881
Validation loss: 4.563531802486837

Epoch: 6| Step: 9
Training loss: 4.886663325275217
Validation loss: 4.5582921730056825

Epoch: 6| Step: 10
Training loss: 3.935103277380392
Validation loss: 4.552930297738063

Epoch: 6| Step: 11
Training loss: 4.657149874375161
Validation loss: 4.547280205043845

Epoch: 6| Step: 12
Training loss: 4.200596612608198
Validation loss: 4.542198004249523

Epoch: 6| Step: 13
Training loss: 4.614822324099576
Validation loss: 4.537422290903723

Epoch: 17| Step: 0
Training loss: 4.117354272001849
Validation loss: 4.532390740282805

Epoch: 6| Step: 1
Training loss: 4.3428291058173105
Validation loss: 4.527443982063372

Epoch: 6| Step: 2
Training loss: 4.4115054125414845
Validation loss: 4.522662424151512

Epoch: 6| Step: 3
Training loss: 4.016043674596262
Validation loss: 4.517497095903322

Epoch: 6| Step: 4
Training loss: 5.471945390406488
Validation loss: 4.51277493091079

Epoch: 6| Step: 5
Training loss: 3.679045343756782
Validation loss: 4.508100036583004

Epoch: 6| Step: 6
Training loss: 5.110193776079059
Validation loss: 4.503300057228721

Epoch: 6| Step: 7
Training loss: 4.224716149901814
Validation loss: 4.498506015451469

Epoch: 6| Step: 8
Training loss: 5.198664038778226
Validation loss: 4.493974147931088

Epoch: 6| Step: 9
Training loss: 4.241062415550808
Validation loss: 4.488403637365301

Epoch: 6| Step: 10
Training loss: 5.338394068716748
Validation loss: 4.48344585438219

Epoch: 6| Step: 11
Training loss: 5.0283879260542035
Validation loss: 4.478182993671059

Epoch: 6| Step: 12
Training loss: 4.585756366538357
Validation loss: 4.472848217882703

Epoch: 6| Step: 13
Training loss: 4.601827358013225
Validation loss: 4.467566415684066

Epoch: 18| Step: 0
Training loss: 4.025474728849075
Validation loss: 4.462757850413692

Epoch: 6| Step: 1
Training loss: 4.263480181716305
Validation loss: 4.4575227850308305

Epoch: 6| Step: 2
Training loss: 4.695953071554713
Validation loss: 4.452560549650417

Epoch: 6| Step: 3
Training loss: 3.8921518049284027
Validation loss: 4.446962967532208

Epoch: 6| Step: 4
Training loss: 3.669467347701125
Validation loss: 4.4419283553014655

Epoch: 6| Step: 5
Training loss: 4.692172557236654
Validation loss: 4.43737276996303

Epoch: 6| Step: 6
Training loss: 4.728672130567756
Validation loss: 4.432766032431994

Epoch: 6| Step: 7
Training loss: 6.1304390560562245
Validation loss: 4.427992472328925

Epoch: 6| Step: 8
Training loss: 4.266424418565966
Validation loss: 4.422304202256527

Epoch: 6| Step: 9
Training loss: 4.4662165362783055
Validation loss: 4.417471446484905

Epoch: 6| Step: 10
Training loss: 4.4287259035372815
Validation loss: 4.412754659535455

Epoch: 6| Step: 11
Training loss: 4.925599254419376
Validation loss: 4.4076495642050535

Epoch: 6| Step: 12
Training loss: 4.599558162201625
Validation loss: 4.402717346568229

Epoch: 6| Step: 13
Training loss: 4.5466220431408
Validation loss: 4.397305764771379

Epoch: 19| Step: 0
Training loss: 4.810871195421423
Validation loss: 4.392341504495089

Epoch: 6| Step: 1
Training loss: 4.2552179953544425
Validation loss: 4.387481958219959

Epoch: 6| Step: 2
Training loss: 4.487488626024714
Validation loss: 4.381662110134894

Epoch: 6| Step: 3
Training loss: 4.908638731042908
Validation loss: 4.377053932165033

Epoch: 6| Step: 4
Training loss: 4.803034204879473
Validation loss: 4.371657066194088

Epoch: 6| Step: 5
Training loss: 4.073120788506483
Validation loss: 4.366136236710005

Epoch: 6| Step: 6
Training loss: 4.539111664024837
Validation loss: 4.360701310219664

Epoch: 6| Step: 7
Training loss: 4.3927839408207205
Validation loss: 4.355958390475328

Epoch: 6| Step: 8
Training loss: 3.723967282300036
Validation loss: 4.351107068430662

Epoch: 6| Step: 9
Training loss: 4.718593569556314
Validation loss: 4.345949965192333

Epoch: 6| Step: 10
Training loss: 4.507778438657602
Validation loss: 4.341307266550358

Epoch: 6| Step: 11
Training loss: 4.164964073731445
Validation loss: 4.335819460433438

Epoch: 6| Step: 12
Training loss: 4.222213340772244
Validation loss: 4.330283993312452

Epoch: 6| Step: 13
Training loss: 5.044582164992494
Validation loss: 4.325334514698506

Epoch: 20| Step: 0
Training loss: 4.519367290875889
Validation loss: 4.320513977540271

Epoch: 6| Step: 1
Training loss: 5.286155634389817
Validation loss: 4.31521904039851

Epoch: 6| Step: 2
Training loss: 3.61498020129764
Validation loss: 4.31001464434125

Epoch: 6| Step: 3
Training loss: 3.4463091250035895
Validation loss: 4.304699500240854

Epoch: 6| Step: 4
Training loss: 5.316901504129474
Validation loss: 4.299885327636159

Epoch: 6| Step: 5
Training loss: 4.139115659459495
Validation loss: 4.295081190734066

Epoch: 6| Step: 6
Training loss: 2.7969212022087335
Validation loss: 4.290454427871483

Epoch: 6| Step: 7
Training loss: 4.372987556821896
Validation loss: 4.285341892260788

Epoch: 6| Step: 8
Training loss: 4.3201480440981195
Validation loss: 4.280378081179583

Epoch: 6| Step: 9
Training loss: 4.22066606878689
Validation loss: 4.2755200729651355

Epoch: 6| Step: 10
Training loss: 5.103464797154088
Validation loss: 4.270790726363865

Epoch: 6| Step: 11
Training loss: 4.908186220685673
Validation loss: 4.265437232648591

Epoch: 6| Step: 12
Training loss: 4.641645017581405
Validation loss: 4.260560080703448

Epoch: 6| Step: 13
Training loss: 4.408682510209833
Validation loss: 4.25484020768371

Epoch: 21| Step: 0
Training loss: 4.559373385224504
Validation loss: 4.249983881003535

Epoch: 6| Step: 1
Training loss: 5.1329825037842545
Validation loss: 4.245073604776853

Epoch: 6| Step: 2
Training loss: 3.4840057587953748
Validation loss: 4.2396988849061055

Epoch: 6| Step: 3
Training loss: 4.130321422566401
Validation loss: 4.234284290876456

Epoch: 6| Step: 4
Training loss: 4.231252271913625
Validation loss: 4.229419036751727

Epoch: 6| Step: 5
Training loss: 5.079574425059808
Validation loss: 4.224524306806005

Epoch: 6| Step: 6
Training loss: 4.743081927594652
Validation loss: 4.219024102996213

Epoch: 6| Step: 7
Training loss: 3.371757928125758
Validation loss: 4.213935063516438

Epoch: 6| Step: 8
Training loss: 3.7684528290604242
Validation loss: 4.209079688837654

Epoch: 6| Step: 9
Training loss: 4.201124204314617
Validation loss: 4.204553996990502

Epoch: 6| Step: 10
Training loss: 4.810344461015049
Validation loss: 4.199580195048834

Epoch: 6| Step: 11
Training loss: 3.9001796094177217
Validation loss: 4.194812425186759

Epoch: 6| Step: 12
Training loss: 4.374983869250396
Validation loss: 4.189854145197196

Epoch: 6| Step: 13
Training loss: 4.633702313301525
Validation loss: 4.18474172970324

Epoch: 22| Step: 0
Training loss: 5.00645792668626
Validation loss: 4.179810100908288

Epoch: 6| Step: 1
Training loss: 3.107340237967543
Validation loss: 4.17469438968576

Epoch: 6| Step: 2
Training loss: 4.356779686401396
Validation loss: 4.169927630692261

Epoch: 6| Step: 3
Training loss: 4.705460586300095
Validation loss: 4.164764535971495

Epoch: 6| Step: 4
Training loss: 3.7518846226584213
Validation loss: 4.159927634104948

Epoch: 6| Step: 5
Training loss: 4.463299181244612
Validation loss: 4.155392570296965

Epoch: 6| Step: 6
Training loss: 3.8196265730156918
Validation loss: 4.150405388300949

Epoch: 6| Step: 7
Training loss: 4.710837899289139
Validation loss: 4.145507870012515

Epoch: 6| Step: 8
Training loss: 3.963853112849181
Validation loss: 4.140661620931807

Epoch: 6| Step: 9
Training loss: 5.1720486983435405
Validation loss: 4.135672720693896

Epoch: 6| Step: 10
Training loss: 3.948745412410282
Validation loss: 4.131133153573991

Epoch: 6| Step: 11
Training loss: 4.136627455614413
Validation loss: 4.126371098000703

Epoch: 6| Step: 12
Training loss: 3.18924186833849
Validation loss: 4.121675268910573

Epoch: 6| Step: 13
Training loss: 4.959489746304671
Validation loss: 4.1170681689424224

Epoch: 23| Step: 0
Training loss: 4.737993827587148
Validation loss: 4.11202266864181

Epoch: 6| Step: 1
Training loss: 5.168113977492233
Validation loss: 4.107267818563899

Epoch: 6| Step: 2
Training loss: 3.4383248466600227
Validation loss: 4.1021239075107925

Epoch: 6| Step: 3
Training loss: 4.372226380848849
Validation loss: 4.097169375033897

Epoch: 6| Step: 4
Training loss: 3.5308741816832616
Validation loss: 4.092029103052255

Epoch: 6| Step: 5
Training loss: 4.465049224958089
Validation loss: 4.087418044237879

Epoch: 6| Step: 6
Training loss: 4.275471595495824
Validation loss: 4.082534763852373

Epoch: 6| Step: 7
Training loss: 4.356722335712714
Validation loss: 4.077724227602742

Epoch: 6| Step: 8
Training loss: 3.8825995465527474
Validation loss: 4.07257807788506

Epoch: 6| Step: 9
Training loss: 3.9753035855273913
Validation loss: 4.0679548761121325

Epoch: 6| Step: 10
Training loss: 4.579086254872847
Validation loss: 4.063339479226358

Epoch: 6| Step: 11
Training loss: 4.286052822184494
Validation loss: 4.058258346293045

Epoch: 6| Step: 12
Training loss: 3.3397338135232317
Validation loss: 4.053691352092985

Epoch: 6| Step: 13
Training loss: 4.190284145070674
Validation loss: 4.0491314541440415

Epoch: 24| Step: 0
Training loss: 3.6471784163090546
Validation loss: 4.044427669290074

Epoch: 6| Step: 1
Training loss: 3.7675729359007164
Validation loss: 4.0397029051741855

Epoch: 6| Step: 2
Training loss: 3.824179472833603
Validation loss: 4.035263862664357

Epoch: 6| Step: 3
Training loss: 4.127680283415217
Validation loss: 4.030826871681568

Epoch: 6| Step: 4
Training loss: 4.539015226397006
Validation loss: 4.02623320301164

Epoch: 6| Step: 5
Training loss: 3.666404512454974
Validation loss: 4.021735523317888

Epoch: 6| Step: 6
Training loss: 5.202828430338359
Validation loss: 4.017141290906097

Epoch: 6| Step: 7
Training loss: 4.33811574297677
Validation loss: 4.012526111775303

Epoch: 6| Step: 8
Training loss: 4.244951054051619
Validation loss: 4.007748113143508

Epoch: 6| Step: 9
Training loss: 4.017600438228023
Validation loss: 4.003012516169565

Epoch: 6| Step: 10
Training loss: 4.05911019557661
Validation loss: 3.9984880609906903

Epoch: 6| Step: 11
Training loss: 3.9781276418193188
Validation loss: 3.9934818884252294

Epoch: 6| Step: 12
Training loss: 4.046060723234222
Validation loss: 3.9886286151793926

Epoch: 6| Step: 13
Training loss: 4.3419642448341245
Validation loss: 3.9837946051438577

Epoch: 25| Step: 0
Training loss: 4.136466532826932
Validation loss: 3.979300045687329

Epoch: 6| Step: 1
Training loss: 3.244263060462415
Validation loss: 3.9745676049389402

Epoch: 6| Step: 2
Training loss: 3.652467384897735
Validation loss: 3.9700022446492316

Epoch: 6| Step: 3
Training loss: 5.0358276393079
Validation loss: 3.9655338582496658

Epoch: 6| Step: 4
Training loss: 3.7538254617022124
Validation loss: 3.96087377573452

Epoch: 6| Step: 5
Training loss: 4.345242031366864
Validation loss: 3.956309065295013

Epoch: 6| Step: 6
Training loss: 4.060329385559537
Validation loss: 3.9514205736179755

Epoch: 6| Step: 7
Training loss: 4.0625877957760705
Validation loss: 3.9467313223345486

Epoch: 6| Step: 8
Training loss: 3.958401983903898
Validation loss: 3.9419898718547848

Epoch: 6| Step: 9
Training loss: 3.384314082646225
Validation loss: 3.937451982962274

Epoch: 6| Step: 10
Training loss: 4.432736916447284
Validation loss: 3.9328675444182037

Epoch: 6| Step: 11
Training loss: 4.640759809700145
Validation loss: 3.928203750100168

Epoch: 6| Step: 12
Training loss: 4.309291143341449
Validation loss: 3.9235410760951215

Epoch: 6| Step: 13
Training loss: 3.7550200875020554
Validation loss: 3.9185643502470104

Epoch: 26| Step: 0
Training loss: 4.301454635137911
Validation loss: 3.913682626042599

Epoch: 6| Step: 1
Training loss: 3.7176342740978794
Validation loss: 3.9089319203179094

Epoch: 6| Step: 2
Training loss: 4.313964152916258
Validation loss: 3.904199962548627

Epoch: 6| Step: 3
Training loss: 3.7118100074207683
Validation loss: 3.8992028513957315

Epoch: 6| Step: 4
Training loss: 4.355936642819186
Validation loss: 3.8949392112065815

Epoch: 6| Step: 5
Training loss: 4.038011189037614
Validation loss: 3.8899299582915137

Epoch: 6| Step: 6
Training loss: 3.3213462028310237
Validation loss: 3.885336962880377

Epoch: 6| Step: 7
Training loss: 4.222455693086444
Validation loss: 3.8806382660063816

Epoch: 6| Step: 8
Training loss: 4.040622904128662
Validation loss: 3.875921139905942

Epoch: 6| Step: 9
Training loss: 3.835495684443634
Validation loss: 3.871251559513292

Epoch: 6| Step: 10
Training loss: 4.339123354503269
Validation loss: 3.8666031007364956

Epoch: 6| Step: 11
Training loss: 3.7893426221357407
Validation loss: 3.8616992577198417

Epoch: 6| Step: 12
Training loss: 4.350704855101763
Validation loss: 3.8569812223587094

Epoch: 6| Step: 13
Training loss: 3.7371440501063264
Validation loss: 3.8523848599063744

Epoch: 27| Step: 0
Training loss: 4.513398885621835
Validation loss: 3.847600047674079

Epoch: 6| Step: 1
Training loss: 3.754780075195608
Validation loss: 3.84265602898653

Epoch: 6| Step: 2
Training loss: 4.086615249119489
Validation loss: 3.837795266090291

Epoch: 6| Step: 3
Training loss: 4.217678357814933
Validation loss: 3.8329011770265033

Epoch: 6| Step: 4
Training loss: 4.284395496366682
Validation loss: 3.828246300261186

Epoch: 6| Step: 5
Training loss: 4.0183763392607545
Validation loss: 3.8230452693474475

Epoch: 6| Step: 6
Training loss: 3.646775841365961
Validation loss: 3.818276120682315

Epoch: 6| Step: 7
Training loss: 2.8429007467306557
Validation loss: 3.813664763915246

Epoch: 6| Step: 8
Training loss: 3.77787062275308
Validation loss: 3.8089105249373016

Epoch: 6| Step: 9
Training loss: 4.4162875078704795
Validation loss: 3.8043296901594412

Epoch: 6| Step: 10
Training loss: 3.212737903617615
Validation loss: 3.7996648682499328

Epoch: 6| Step: 11
Training loss: 4.464474853868616
Validation loss: 3.7952427541083456

Epoch: 6| Step: 12
Training loss: 3.2774933154563914
Validation loss: 3.790744641442518

Epoch: 6| Step: 13
Training loss: 4.368298002117385
Validation loss: 3.785905205555693

Epoch: 28| Step: 0
Training loss: 4.356823902829178
Validation loss: 3.781560123221034

Epoch: 6| Step: 1
Training loss: 4.223802042310571
Validation loss: 3.776793657161593

Epoch: 6| Step: 2
Training loss: 3.893742059543406
Validation loss: 3.7722250265324213

Epoch: 6| Step: 3
Training loss: 4.168353133634396
Validation loss: 3.767146983509589

Epoch: 6| Step: 4
Training loss: 2.949602882682234
Validation loss: 3.762539708972471

Epoch: 6| Step: 5
Training loss: 3.7465277809203563
Validation loss: 3.7578657732047085

Epoch: 6| Step: 6
Training loss: 4.260543311489983
Validation loss: 3.7531943385494873

Epoch: 6| Step: 7
Training loss: 4.422707199668436
Validation loss: 3.7485921548241046

Epoch: 6| Step: 8
Training loss: 2.8567365970605954
Validation loss: 3.744021779142379

Epoch: 6| Step: 9
Training loss: 4.236754702401969
Validation loss: 3.739467867004607

Epoch: 6| Step: 10
Training loss: 3.9123097528875523
Validation loss: 3.7349755350968787

Epoch: 6| Step: 11
Training loss: 3.4770344274581184
Validation loss: 3.7303047716673676

Epoch: 6| Step: 12
Training loss: 3.5067373552437755
Validation loss: 3.7258365971747116

Epoch: 6| Step: 13
Training loss: 3.999437531025481
Validation loss: 3.721335999871828

Epoch: 29| Step: 0
Training loss: 4.710951468224006
Validation loss: 3.716662357880927

Epoch: 6| Step: 1
Training loss: 3.6503929762733196
Validation loss: 3.7118072026035676

Epoch: 6| Step: 2
Training loss: 3.088960890384373
Validation loss: 3.707128171789313

Epoch: 6| Step: 3
Training loss: 3.4594196926631136
Validation loss: 3.7025830909185338

Epoch: 6| Step: 4
Training loss: 3.9337098787320577
Validation loss: 3.6980582769797112

Epoch: 6| Step: 5
Training loss: 3.8362333412840384
Validation loss: 3.693624851712253

Epoch: 6| Step: 6
Training loss: 3.9030626644779605
Validation loss: 3.688939325499788

Epoch: 6| Step: 7
Training loss: 4.122356145510682
Validation loss: 3.684315464788761

Epoch: 6| Step: 8
Training loss: 3.375758191881663
Validation loss: 3.6796568527079287

Epoch: 6| Step: 9
Training loss: 4.3564233118770295
Validation loss: 3.675284395004752

Epoch: 6| Step: 10
Training loss: 3.4692601009276003
Validation loss: 3.670685942191734

Epoch: 6| Step: 11
Training loss: 3.6782342912354977
Validation loss: 3.6663301631376095

Epoch: 6| Step: 12
Training loss: 4.254179750447916
Validation loss: 3.661744306890363

Epoch: 6| Step: 13
Training loss: 3.3598970229399505
Validation loss: 3.6573119400985052

Epoch: 30| Step: 0
Training loss: 3.241523840208587
Validation loss: 3.6527504978361915

Epoch: 6| Step: 1
Training loss: 4.043216185438565
Validation loss: 3.6480669572691835

Epoch: 6| Step: 2
Training loss: 4.3987054827888175
Validation loss: 3.6434406530890815

Epoch: 6| Step: 3
Training loss: 3.6279382307688777
Validation loss: 3.6389580049494783

Epoch: 6| Step: 4
Training loss: 4.274124564498171
Validation loss: 3.63436801654979

Epoch: 6| Step: 5
Training loss: 3.711794977001551
Validation loss: 3.6294066074265716

Epoch: 6| Step: 6
Training loss: 3.5388517674911717
Validation loss: 3.6243817251579076

Epoch: 6| Step: 7
Training loss: 3.84458876971615
Validation loss: 3.619496322036254

Epoch: 6| Step: 8
Training loss: 3.849528365538428
Validation loss: 3.6147824030135585

Epoch: 6| Step: 9
Training loss: 3.7117597773200854
Validation loss: 3.609704799364611

Epoch: 6| Step: 10
Training loss: 3.4544168532769195
Validation loss: 3.6044765772826435

Epoch: 6| Step: 11
Training loss: 3.003612885951241
Validation loss: 3.5997315757073856

Epoch: 6| Step: 12
Training loss: 3.92296958937613
Validation loss: 3.595299273481359

Epoch: 6| Step: 13
Training loss: 3.7941436362257046
Validation loss: 3.5909889118671745

Epoch: 31| Step: 0
Training loss: 3.2017146285232854
Validation loss: 3.5864128512466884

Epoch: 6| Step: 1
Training loss: 3.236394279508305
Validation loss: 3.582359617845397

Epoch: 6| Step: 2
Training loss: 4.191471778378725
Validation loss: 3.5781024338012024

Epoch: 6| Step: 3
Training loss: 3.8473881816912723
Validation loss: 3.5738460492372472

Epoch: 6| Step: 4
Training loss: 3.581209011409197
Validation loss: 3.569495888886438

Epoch: 6| Step: 5
Training loss: 3.90235963499332
Validation loss: 3.564944204007057

Epoch: 6| Step: 6
Training loss: 4.235061420954579
Validation loss: 3.560776935175102

Epoch: 6| Step: 7
Training loss: 3.9940989597078045
Validation loss: 3.5559255379331662

Epoch: 6| Step: 8
Training loss: 3.880936535940274
Validation loss: 3.5513949058049765

Epoch: 6| Step: 9
Training loss: 4.011313413295278
Validation loss: 3.5465726793594463

Epoch: 6| Step: 10
Training loss: 3.838617387056682
Validation loss: 3.5419082708789165

Epoch: 6| Step: 11
Training loss: 3.2163976573296535
Validation loss: 3.537159748585832

Epoch: 6| Step: 12
Training loss: 3.5404693973351606
Validation loss: 3.5326536196570753

Epoch: 6| Step: 13
Training loss: 2.7643108801894885
Validation loss: 3.528571156442373

Epoch: 32| Step: 0
Training loss: 3.8811935641843496
Validation loss: 3.524097975624246

Epoch: 6| Step: 1
Training loss: 4.220135948558577
Validation loss: 3.519974726131044

Epoch: 6| Step: 2
Training loss: 3.870811659988702
Validation loss: 3.5154505029394088

Epoch: 6| Step: 3
Training loss: 3.890319076827921
Validation loss: 3.5109431082399625

Epoch: 6| Step: 4
Training loss: 3.6731030297705467
Validation loss: 3.5065044634863285

Epoch: 6| Step: 5
Training loss: 3.8649512404589905
Validation loss: 3.5022728102646896

Epoch: 6| Step: 6
Training loss: 3.60273879033463
Validation loss: 3.4977135455963135

Epoch: 6| Step: 7
Training loss: 3.5627824102529217
Validation loss: 3.4934506674224726

Epoch: 6| Step: 8
Training loss: 3.6611150994003356
Validation loss: 3.4889760566021795

Epoch: 6| Step: 9
Training loss: 4.064977741250896
Validation loss: 3.484735490200921

Epoch: 6| Step: 10
Training loss: 2.724669315676906
Validation loss: 3.4801561848169116

Epoch: 6| Step: 11
Training loss: 2.91580254605998
Validation loss: 3.476116023165272

Epoch: 6| Step: 12
Training loss: 3.7795986636612104
Validation loss: 3.4723074372749125

Epoch: 6| Step: 13
Training loss: 2.829944678530823
Validation loss: 3.468117252409258

Epoch: 33| Step: 0
Training loss: 3.8322152843088717
Validation loss: 3.4641392969024953

Epoch: 6| Step: 1
Training loss: 3.5943093569443865
Validation loss: 3.4599425620160744

Epoch: 6| Step: 2
Training loss: 3.1866106774852936
Validation loss: 3.455704245037872

Epoch: 6| Step: 3
Training loss: 3.829408889652923
Validation loss: 3.4515983578529097

Epoch: 6| Step: 4
Training loss: 3.0744858350664774
Validation loss: 3.447505077370309

Epoch: 6| Step: 5
Training loss: 2.9664739617613542
Validation loss: 3.443477242728543

Epoch: 6| Step: 6
Training loss: 3.877279902986881
Validation loss: 3.4397134417011976

Epoch: 6| Step: 7
Training loss: 3.5578497266936915
Validation loss: 3.4359907015754967

Epoch: 6| Step: 8
Training loss: 3.818830893201366
Validation loss: 3.4319052162708994

Epoch: 6| Step: 9
Training loss: 3.7465845448825954
Validation loss: 3.4277687817302134

Epoch: 6| Step: 10
Training loss: 3.8893743136364116
Validation loss: 3.423624169352924

Epoch: 6| Step: 11
Training loss: 3.9085566919809045
Validation loss: 3.4194439943177124

Epoch: 6| Step: 12
Training loss: 3.7048884188880957
Validation loss: 3.415217759174393

Epoch: 6| Step: 13
Training loss: 2.84376643249459
Validation loss: 3.4110862160132154

Epoch: 34| Step: 0
Training loss: 3.4298619810312103
Validation loss: 3.407099230067031

Epoch: 6| Step: 1
Training loss: 3.3193507338685366
Validation loss: 3.4031131427746315

Epoch: 6| Step: 2
Training loss: 2.6075458625717474
Validation loss: 3.399128623637915

Epoch: 6| Step: 3
Training loss: 3.0162922017338163
Validation loss: 3.395548373632786

Epoch: 6| Step: 4
Training loss: 3.1806306307250525
Validation loss: 3.391831635970636

Epoch: 6| Step: 5
Training loss: 4.052082496518765
Validation loss: 3.388274800748392

Epoch: 6| Step: 6
Training loss: 3.5383146392668636
Validation loss: 3.3844629245184503

Epoch: 6| Step: 7
Training loss: 3.9087767706656655
Validation loss: 3.3807230098615215

Epoch: 6| Step: 8
Training loss: 3.7160632260859816
Validation loss: 3.3767841003372614

Epoch: 6| Step: 9
Training loss: 4.2696581208277085
Validation loss: 3.372788493544817

Epoch: 6| Step: 10
Training loss: 3.2926065736755175
Validation loss: 3.3686654136291003

Epoch: 6| Step: 11
Training loss: 4.132441888067145
Validation loss: 3.3646352584816075

Epoch: 6| Step: 12
Training loss: 2.9826850300364134
Validation loss: 3.360345082349293

Epoch: 6| Step: 13
Training loss: 3.420155550447642
Validation loss: 3.3561886365645357

Epoch: 35| Step: 0
Training loss: 3.870856007378523
Validation loss: 3.352265516174429

Epoch: 6| Step: 1
Training loss: 3.520219708001553
Validation loss: 3.348172100951856

Epoch: 6| Step: 2
Training loss: 3.152201558325013
Validation loss: 3.344065357203823

Epoch: 6| Step: 3
Training loss: 3.2286950700187798
Validation loss: 3.340038652291568

Epoch: 6| Step: 4
Training loss: 3.960675533743423
Validation loss: 3.336121624787007

Epoch: 6| Step: 5
Training loss: 3.5408701879950955
Validation loss: 3.332181055861179

Epoch: 6| Step: 6
Training loss: 2.802667001585694
Validation loss: 3.3281103859164176

Epoch: 6| Step: 7
Training loss: 4.209058013059431
Validation loss: 3.3243354749974525

Epoch: 6| Step: 8
Training loss: 3.502840524330447
Validation loss: 3.320347182148828

Epoch: 6| Step: 9
Training loss: 2.785611707943672
Validation loss: 3.316469800719873

Epoch: 6| Step: 10
Training loss: 3.3147333641472017
Validation loss: 3.3126495615465794

Epoch: 6| Step: 11
Training loss: 2.9373375056348694
Validation loss: 3.308926676303916

Epoch: 6| Step: 12
Training loss: 3.868087139871989
Validation loss: 3.305095674454427

Epoch: 6| Step: 13
Training loss: 3.49119031353174
Validation loss: 3.3012317357586602

Epoch: 36| Step: 0
Training loss: 3.0680078296586335
Validation loss: 3.297422029211124

Epoch: 6| Step: 1
Training loss: 3.618977246042457
Validation loss: 3.293817099382998

Epoch: 6| Step: 2
Training loss: 3.5824633288852543
Validation loss: 3.290036018893294

Epoch: 6| Step: 3
Training loss: 3.0416004400141605
Validation loss: 3.2862013259403664

Epoch: 6| Step: 4
Training loss: 3.0837660477262823
Validation loss: 3.282414281248344

Epoch: 6| Step: 5
Training loss: 4.06067369931813
Validation loss: 3.2787598379775056

Epoch: 6| Step: 6
Training loss: 3.3441027874093208
Validation loss: 3.274943925411462

Epoch: 6| Step: 7
Training loss: 3.16116645047943
Validation loss: 3.2709775313808156

Epoch: 6| Step: 8
Training loss: 3.0770006014154174
Validation loss: 3.267201312422232

Epoch: 6| Step: 9
Training loss: 3.4086032403030844
Validation loss: 3.263386837017706

Epoch: 6| Step: 10
Training loss: 3.4601407823972696
Validation loss: 3.2596193543246876

Epoch: 6| Step: 11
Training loss: 3.6322324228154854
Validation loss: 3.2559210930283453

Epoch: 6| Step: 12
Training loss: 3.722968521710526
Validation loss: 3.2523619187698447

Epoch: 6| Step: 13
Training loss: 3.3721210775302
Validation loss: 3.248531352062474

Epoch: 37| Step: 0
Training loss: 3.3866241336264253
Validation loss: 3.2448908554436873

Epoch: 6| Step: 1
Training loss: 3.0100376370126853
Validation loss: 3.241378916216561

Epoch: 6| Step: 2
Training loss: 3.143913104033394
Validation loss: 3.2379014697855695

Epoch: 6| Step: 3
Training loss: 3.7460660008585123
Validation loss: 3.2344875592534863

Epoch: 6| Step: 4
Training loss: 3.501208641627841
Validation loss: 3.230980017356745

Epoch: 6| Step: 5
Training loss: 3.2303131693377765
Validation loss: 3.2274518207526417

Epoch: 6| Step: 6
Training loss: 3.9377494611886874
Validation loss: 3.224099796541995

Epoch: 6| Step: 7
Training loss: 3.321546186248629
Validation loss: 3.2202682247755234

Epoch: 6| Step: 8
Training loss: 3.1785850769533703
Validation loss: 3.216952800542427

Epoch: 6| Step: 9
Training loss: 3.5142878045043755
Validation loss: 3.2134308056537657

Epoch: 6| Step: 10
Training loss: 3.251058259477759
Validation loss: 3.2098038428673923

Epoch: 6| Step: 11
Training loss: 3.4259532854822528
Validation loss: 3.2061494024506336

Epoch: 6| Step: 12
Training loss: 3.2446513546180737
Validation loss: 3.2026897599925266

Epoch: 6| Step: 13
Training loss: 3.0664188457643373
Validation loss: 3.19913744328248

Epoch: 38| Step: 0
Training loss: 3.817860321447346
Validation loss: 3.1956777325034693

Epoch: 6| Step: 1
Training loss: 2.8474857818275336
Validation loss: 3.1921527414394766

Epoch: 6| Step: 2
Training loss: 3.372009223762468
Validation loss: 3.188696368723622

Epoch: 6| Step: 3
Training loss: 3.0957219168396515
Validation loss: 3.1853192417838514

Epoch: 6| Step: 4
Training loss: 3.6470730372302116
Validation loss: 3.181931474761824

Epoch: 6| Step: 5
Training loss: 2.9773816360789813
Validation loss: 3.1787960043060943

Epoch: 6| Step: 6
Training loss: 3.058382029409894
Validation loss: 3.175247929622367

Epoch: 6| Step: 7
Training loss: 3.216039757259832
Validation loss: 3.1720327078161996

Epoch: 6| Step: 8
Training loss: 3.009270015164794
Validation loss: 3.168886853635484

Epoch: 6| Step: 9
Training loss: 3.730268063564575
Validation loss: 3.1652794652196645

Epoch: 6| Step: 10
Training loss: 2.8073549469920756
Validation loss: 3.162040686141114

Epoch: 6| Step: 11
Training loss: 3.141301172449129
Validation loss: 3.158789944081062

Epoch: 6| Step: 12
Training loss: 3.7224021096357003
Validation loss: 3.155417921213038

Epoch: 6| Step: 13
Training loss: 3.7088834518835667
Validation loss: 3.152212588493815

Epoch: 39| Step: 0
Training loss: 2.6866368526700812
Validation loss: 3.148721459695905

Epoch: 6| Step: 1
Training loss: 3.1167143268986983
Validation loss: 3.1452513697508304

Epoch: 6| Step: 2
Training loss: 2.7275640621057144
Validation loss: 3.141778787759024

Epoch: 6| Step: 3
Training loss: 3.7024254761896667
Validation loss: 3.138684877069205

Epoch: 6| Step: 4
Training loss: 3.727027464196108
Validation loss: 3.1352621317111318

Epoch: 6| Step: 5
Training loss: 3.014643534120972
Validation loss: 3.1318284008766892

Epoch: 6| Step: 6
Training loss: 3.120298281863106
Validation loss: 3.128476282009624

Epoch: 6| Step: 7
Training loss: 3.382391570863353
Validation loss: 3.125231238392851

Epoch: 6| Step: 8
Training loss: 3.3754111145548986
Validation loss: 3.1218258313853324

Epoch: 6| Step: 9
Training loss: 3.089380280160067
Validation loss: 3.118910489383714

Epoch: 6| Step: 10
Training loss: 2.8973480398042146
Validation loss: 3.1156028091216874

Epoch: 6| Step: 11
Training loss: 4.035343428015917
Validation loss: 3.112478435906366

Epoch: 6| Step: 12
Training loss: 3.4350256597679385
Validation loss: 3.1095430466115213

Epoch: 6| Step: 13
Training loss: 3.159809937616171
Validation loss: 3.106169218961244

Epoch: 40| Step: 0
Training loss: 3.2069790611713547
Validation loss: 3.102876783510535

Epoch: 6| Step: 1
Training loss: 3.227511730453484
Validation loss: 3.0995875555919823

Epoch: 6| Step: 2
Training loss: 3.283734498148944
Validation loss: 3.0963563312151856

Epoch: 6| Step: 3
Training loss: 3.3854734601856773
Validation loss: 3.093000880009711

Epoch: 6| Step: 4
Training loss: 3.07299904578182
Validation loss: 3.0897252654496064

Epoch: 6| Step: 5
Training loss: 3.531757149526624
Validation loss: 3.086462228965468

Epoch: 6| Step: 6
Training loss: 3.1313291924183737
Validation loss: 3.083128771998394

Epoch: 6| Step: 7
Training loss: 3.160719926165581
Validation loss: 3.0804045961146005

Epoch: 6| Step: 8
Training loss: 3.2185088132103803
Validation loss: 3.077250839009735

Epoch: 6| Step: 9
Training loss: 3.3482228248124
Validation loss: 3.074296574655708

Epoch: 6| Step: 10
Training loss: 3.076878948995631
Validation loss: 3.07128947651693

Epoch: 6| Step: 11
Training loss: 3.0164125036862943
Validation loss: 3.068259357560068

Epoch: 6| Step: 12
Training loss: 3.304464706955079
Validation loss: 3.065601802197645

Epoch: 6| Step: 13
Training loss: 3.15813684246501
Validation loss: 3.062461787913146

Epoch: 41| Step: 0
Training loss: 3.502062053869176
Validation loss: 3.0594632020106727

Epoch: 6| Step: 1
Training loss: 3.5694096798982966
Validation loss: 3.0564555769249147

Epoch: 6| Step: 2
Training loss: 2.760503218151636
Validation loss: 3.0532893292478116

Epoch: 6| Step: 3
Training loss: 2.1736265296375636
Validation loss: 3.050149107243122

Epoch: 6| Step: 4
Training loss: 2.77665261898937
Validation loss: 3.047356461526144

Epoch: 6| Step: 5
Training loss: 2.8918151055162893
Validation loss: 3.044672243114711

Epoch: 6| Step: 6
Training loss: 3.602954785709392
Validation loss: 3.042184992395539

Epoch: 6| Step: 7
Training loss: 3.3737864255122467
Validation loss: 3.0391527830963816

Epoch: 6| Step: 8
Training loss: 2.763473881075763
Validation loss: 3.0363255117864734

Epoch: 6| Step: 9
Training loss: 3.2288573742482503
Validation loss: 3.0334810783400132

Epoch: 6| Step: 10
Training loss: 3.726227239406806
Validation loss: 3.0308245724109235

Epoch: 6| Step: 11
Training loss: 3.579389190565768
Validation loss: 3.0280718577957373

Epoch: 6| Step: 12
Training loss: 3.199834855109805
Validation loss: 3.0251572323755127

Epoch: 6| Step: 13
Training loss: 3.0193164744120895
Validation loss: 3.022088958413821

Epoch: 42| Step: 0
Training loss: 2.9885130948154304
Validation loss: 3.019349547162878

Epoch: 6| Step: 1
Training loss: 2.891846105044954
Validation loss: 3.0164358468733274

Epoch: 6| Step: 2
Training loss: 3.1239619247519332
Validation loss: 3.013653705481993

Epoch: 6| Step: 3
Training loss: 3.922831019869352
Validation loss: 3.0108026215308192

Epoch: 6| Step: 4
Training loss: 2.5540203191535915
Validation loss: 3.0081105534565733

Epoch: 6| Step: 5
Training loss: 2.913499056673069
Validation loss: 3.005248776344977

Epoch: 6| Step: 6
Training loss: 3.6614322290624988
Validation loss: 3.0025578164688858

Epoch: 6| Step: 7
Training loss: 2.821972303096428
Validation loss: 2.9999930990987456

Epoch: 6| Step: 8
Training loss: 3.3212266090037414
Validation loss: 2.997152977635456

Epoch: 6| Step: 9
Training loss: 3.0242291185481647
Validation loss: 2.994904004629905

Epoch: 6| Step: 10
Training loss: 2.700113725033224
Validation loss: 2.9919666577307122

Epoch: 6| Step: 11
Training loss: 3.1625385146377876
Validation loss: 2.9899117071241603

Epoch: 6| Step: 12
Training loss: 3.616230848454839
Validation loss: 2.9870295942994716

Epoch: 6| Step: 13
Training loss: 3.0078023538789913
Validation loss: 2.9844584561540817

Epoch: 43| Step: 0
Training loss: 3.181210165017972
Validation loss: 2.9818385131795493

Epoch: 6| Step: 1
Training loss: 3.3421920997477406
Validation loss: 2.9790119628930696

Epoch: 6| Step: 2
Training loss: 3.295044883688606
Validation loss: 2.976384929389909

Epoch: 6| Step: 3
Training loss: 3.128294771905557
Validation loss: 2.9737202448276268

Epoch: 6| Step: 4
Training loss: 2.9489600466003796
Validation loss: 2.971083918235976

Epoch: 6| Step: 5
Training loss: 2.800023017516214
Validation loss: 2.9683467658065794

Epoch: 6| Step: 6
Training loss: 3.2450619376315366
Validation loss: 2.9657680995491447

Epoch: 6| Step: 7
Training loss: 2.63165094578279
Validation loss: 2.9629265002042473

Epoch: 6| Step: 8
Training loss: 3.662487220090891
Validation loss: 2.9602439021025795

Epoch: 6| Step: 9
Training loss: 3.700181523587068
Validation loss: 2.957614117267077

Epoch: 6| Step: 10
Training loss: 2.9249067438371505
Validation loss: 2.9551449280907542

Epoch: 6| Step: 11
Training loss: 2.6193113904295875
Validation loss: 2.952292161732909

Epoch: 6| Step: 12
Training loss: 3.3566832648141234
Validation loss: 2.949885076234725

Epoch: 6| Step: 13
Training loss: 2.3640454278444207
Validation loss: 2.947516684923087

Epoch: 44| Step: 0
Training loss: 3.411936641484981
Validation loss: 2.945070656477722

Epoch: 6| Step: 1
Training loss: 2.8243406488431964
Validation loss: 2.942604877825143

Epoch: 6| Step: 2
Training loss: 2.6690203491784423
Validation loss: 2.939933904826109

Epoch: 6| Step: 3
Training loss: 3.3295199197659358
Validation loss: 2.937632239861966

Epoch: 6| Step: 4
Training loss: 2.6220679483811504
Validation loss: 2.935457520553718

Epoch: 6| Step: 5
Training loss: 2.9975951410486825
Validation loss: 2.932786108218991

Epoch: 6| Step: 6
Training loss: 2.892455310261991
Validation loss: 2.9304613642649073

Epoch: 6| Step: 7
Training loss: 3.176266190969131
Validation loss: 2.9279091689321106

Epoch: 6| Step: 8
Training loss: 3.2907527829942165
Validation loss: 2.9256736555632816

Epoch: 6| Step: 9
Training loss: 3.165173898171167
Validation loss: 2.9234049390362227

Epoch: 6| Step: 10
Training loss: 3.1617269302386766
Validation loss: 2.921177935622092

Epoch: 6| Step: 11
Training loss: 2.9511465075328505
Validation loss: 2.9188834394710566

Epoch: 6| Step: 12
Training loss: 3.333228268557018
Validation loss: 2.9168042740830806

Epoch: 6| Step: 13
Training loss: 3.0624240165159353
Validation loss: 2.9143408811959346

Epoch: 45| Step: 0
Training loss: 3.318849631787793
Validation loss: 2.9122258757244457

Epoch: 6| Step: 1
Training loss: 3.2154217150671074
Validation loss: 2.9100427524358183

Epoch: 6| Step: 2
Training loss: 2.696422403665957
Validation loss: 2.907559267414726

Epoch: 6| Step: 3
Training loss: 2.993673329177894
Validation loss: 2.905282546598115

Epoch: 6| Step: 4
Training loss: 3.0983648848573013
Validation loss: 2.903058449673948

Epoch: 6| Step: 5
Training loss: 2.9997208783319143
Validation loss: 2.901008596637011

Epoch: 6| Step: 6
Training loss: 2.9683060163482895
Validation loss: 2.898871211996396

Epoch: 6| Step: 7
Training loss: 3.051864998117682
Validation loss: 2.8960390543877303

Epoch: 6| Step: 8
Training loss: 3.1835276965444366
Validation loss: 2.8938462325834666

Epoch: 6| Step: 9
Training loss: 2.433348813290761
Validation loss: 2.8913519555221394

Epoch: 6| Step: 10
Training loss: 3.161801884611327
Validation loss: 2.8891995188610613

Epoch: 6| Step: 11
Training loss: 2.6401616880725807
Validation loss: 2.8870520564927835

Epoch: 6| Step: 12
Training loss: 3.5719441831869005
Validation loss: 2.884877431085042

Epoch: 6| Step: 13
Training loss: 3.0616048945004803
Validation loss: 2.8827976202300785

Epoch: 46| Step: 0
Training loss: 3.083748420062393
Validation loss: 2.8806597520880186

Epoch: 6| Step: 1
Training loss: 2.8656018105403733
Validation loss: 2.878243496443965

Epoch: 6| Step: 2
Training loss: 3.10184291081276
Validation loss: 2.8766817895956636

Epoch: 6| Step: 3
Training loss: 2.7039368573440132
Validation loss: 2.874093686868863

Epoch: 6| Step: 4
Training loss: 3.1752262545491345
Validation loss: 2.872415458955695

Epoch: 6| Step: 5
Training loss: 3.227430471650911
Validation loss: 2.8704750415102565

Epoch: 6| Step: 6
Training loss: 2.5671886256024523
Validation loss: 2.8684580081558853

Epoch: 6| Step: 7
Training loss: 2.50280813814303
Validation loss: 2.866642954824395

Epoch: 6| Step: 8
Training loss: 3.297089917739457
Validation loss: 2.8643475221618164

Epoch: 6| Step: 9
Training loss: 3.2419449681030206
Validation loss: 2.862989382160203

Epoch: 6| Step: 10
Training loss: 3.2713868630523453
Validation loss: 2.8609928216729705

Epoch: 6| Step: 11
Training loss: 3.140331653161128
Validation loss: 2.8587117911230244

Epoch: 6| Step: 12
Training loss: 2.9926755820815933
Validation loss: 2.856553580903091

Epoch: 6| Step: 13
Training loss: 2.8173462546371657
Validation loss: 2.8529925797182454

Epoch: 47| Step: 0
Training loss: 3.4574356446031307
Validation loss: 2.85246229215367

Epoch: 6| Step: 1
Training loss: 2.5592621607236747
Validation loss: 2.8498195111416402

Epoch: 6| Step: 2
Training loss: 3.1023391020410283
Validation loss: 2.847957251556547

Epoch: 6| Step: 3
Training loss: 3.0629225458856655
Validation loss: 2.846846044444098

Epoch: 6| Step: 4
Training loss: 3.2139299468291154
Validation loss: 2.8451674984262265

Epoch: 6| Step: 5
Training loss: 3.3533647577723236
Validation loss: 2.8439073204707936

Epoch: 6| Step: 6
Training loss: 2.727479534544419
Validation loss: 2.842144299710626

Epoch: 6| Step: 7
Training loss: 3.1289071643842297
Validation loss: 2.8405694187435393

Epoch: 6| Step: 8
Training loss: 3.134581563424182
Validation loss: 2.838098674585713

Epoch: 6| Step: 9
Training loss: 2.3761630974801404
Validation loss: 2.835471122792418

Epoch: 6| Step: 10
Training loss: 2.3722563506129943
Validation loss: 2.8339273493905486

Epoch: 6| Step: 11
Training loss: 2.8487196874072875
Validation loss: 2.832197751817946

Epoch: 6| Step: 12
Training loss: 2.992633358080063
Validation loss: 2.8310264892156316

Epoch: 6| Step: 13
Training loss: 3.2012043474748677
Validation loss: 2.8284217018464832

Epoch: 48| Step: 0
Training loss: 3.0288486997712445
Validation loss: 2.8258627876524858

Epoch: 6| Step: 1
Training loss: 2.9999788601448376
Validation loss: 2.8239880366904977

Epoch: 6| Step: 2
Training loss: 3.3217266347486416
Validation loss: 2.8213066258097816

Epoch: 6| Step: 3
Training loss: 3.500201219496578
Validation loss: 2.8197588601732875

Epoch: 6| Step: 4
Training loss: 2.6469987320156543
Validation loss: 2.817134450877411

Epoch: 6| Step: 5
Training loss: 2.505339071202606
Validation loss: 2.81512416346691

Epoch: 6| Step: 6
Training loss: 2.321883366648
Validation loss: 2.813347088439665

Epoch: 6| Step: 7
Training loss: 3.0486434108342912
Validation loss: 2.811495735868508

Epoch: 6| Step: 8
Training loss: 3.3918648839166736
Validation loss: 2.8100950908748827

Epoch: 6| Step: 9
Training loss: 2.658821387218107
Validation loss: 2.807970369543115

Epoch: 6| Step: 10
Training loss: 2.807564537549818
Validation loss: 2.805618060919144

Epoch: 6| Step: 11
Training loss: 3.2004156796361527
Validation loss: 2.80413941931748

Epoch: 6| Step: 12
Training loss: 2.531383557975822
Validation loss: 2.802443645431337

Epoch: 6| Step: 13
Training loss: 3.1245422027956002
Validation loss: 2.7996921807206103

Epoch: 49| Step: 0
Training loss: 2.8763510805063555
Validation loss: 2.7985638256090732

Epoch: 6| Step: 1
Training loss: 3.1556528867417537
Validation loss: 2.79589448644972

Epoch: 6| Step: 2
Training loss: 2.9582471879765047
Validation loss: 2.7937227667406423

Epoch: 6| Step: 3
Training loss: 2.608938580411088
Validation loss: 2.7918148760573085

Epoch: 6| Step: 4
Training loss: 3.1674455053011936
Validation loss: 2.7907380841884817

Epoch: 6| Step: 5
Training loss: 2.6113204556497327
Validation loss: 2.7891651921818776

Epoch: 6| Step: 6
Training loss: 2.7650549349578863
Validation loss: 2.788041185152363

Epoch: 6| Step: 7
Training loss: 2.7658706814538307
Validation loss: 2.787818966279949

Epoch: 6| Step: 8
Training loss: 3.6257490502283707
Validation loss: 2.7865604892911833

Epoch: 6| Step: 9
Training loss: 2.4217067537011228
Validation loss: 2.784481585710651

Epoch: 6| Step: 10
Training loss: 2.5225839972522937
Validation loss: 2.7826189251185616

Epoch: 6| Step: 11
Training loss: 3.026458413890047
Validation loss: 2.7800227540043227

Epoch: 6| Step: 12
Training loss: 3.0385136047329886
Validation loss: 2.778217391089418

Epoch: 6| Step: 13
Training loss: 3.2440593417627888
Validation loss: 2.776728938031458

Epoch: 50| Step: 0
Training loss: 2.890714241918453
Validation loss: 2.775122847716074

Epoch: 6| Step: 1
Training loss: 2.684079854991045
Validation loss: 2.7766917876778345

Epoch: 6| Step: 2
Training loss: 2.891857317558594
Validation loss: 2.7725321478509137

Epoch: 6| Step: 3
Training loss: 2.7706870611680547
Validation loss: 2.7722768871402375

Epoch: 6| Step: 4
Training loss: 2.73689197772837
Validation loss: 2.7762111495183874

Epoch: 6| Step: 5
Training loss: 3.0305728745968454
Validation loss: 2.781010135208311

Epoch: 6| Step: 6
Training loss: 3.3335017797506254
Validation loss: 2.7676447014797523

Epoch: 6| Step: 7
Training loss: 2.538740683481692
Validation loss: 2.7637075900408696

Epoch: 6| Step: 8
Training loss: 3.304218664798419
Validation loss: 2.7627339599178726

Epoch: 6| Step: 9
Training loss: 2.9581967353625864
Validation loss: 2.7684103235711564

Epoch: 6| Step: 10
Training loss: 2.4466278146193474
Validation loss: 2.786718913695817

Epoch: 6| Step: 11
Training loss: 2.918410098033718
Validation loss: 2.7959195428358803

Epoch: 6| Step: 12
Training loss: 3.165408453355539
Validation loss: 2.7875923249788452

Epoch: 6| Step: 13
Training loss: 3.040211438304844
Validation loss: 2.775483028082571

Testing loss: 2.3138199735960994
