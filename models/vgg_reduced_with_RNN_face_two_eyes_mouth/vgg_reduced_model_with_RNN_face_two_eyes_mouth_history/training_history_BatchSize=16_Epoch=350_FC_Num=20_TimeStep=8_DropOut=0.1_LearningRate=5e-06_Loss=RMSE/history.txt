Epoch: 1| Step: 0
Training loss: 6.6636740961512215
Validation loss: 5.818534207329087

Epoch: 6| Step: 1
Training loss: 4.875250002979615
Validation loss: 5.816037677251063

Epoch: 6| Step: 2
Training loss: 5.197689665562678
Validation loss: 5.813756608660571

Epoch: 6| Step: 3
Training loss: 6.52031730909465
Validation loss: 5.811332475997746

Epoch: 6| Step: 4
Training loss: 6.371928353902422
Validation loss: 5.809155886551661

Epoch: 6| Step: 5
Training loss: 5.6546463352717256
Validation loss: 5.806870746040969

Epoch: 6| Step: 6
Training loss: 5.781354913532853
Validation loss: 5.804648972970016

Epoch: 6| Step: 7
Training loss: 5.982641860548883
Validation loss: 5.802349210042915

Epoch: 6| Step: 8
Training loss: 6.055263329472783
Validation loss: 5.8000974789462925

Epoch: 6| Step: 9
Training loss: 5.0982574926802116
Validation loss: 5.797794814022429

Epoch: 6| Step: 10
Training loss: 5.895894008724154
Validation loss: 5.795294039674486

Epoch: 6| Step: 11
Training loss: 6.313948361262658
Validation loss: 5.7928330964393515

Epoch: 6| Step: 12
Training loss: 6.336413420878029
Validation loss: 5.790348241388519

Epoch: 6| Step: 13
Training loss: 5.817460435340154
Validation loss: 5.787708036502524

Epoch: 2| Step: 0
Training loss: 5.8684301774667755
Validation loss: 5.784811898714733

Epoch: 6| Step: 1
Training loss: 6.119905182347025
Validation loss: 5.781954088380429

Epoch: 6| Step: 2
Training loss: 6.023643955200493
Validation loss: 5.778870348861602

Epoch: 6| Step: 3
Training loss: 6.014774886664991
Validation loss: 5.775722631295205

Epoch: 6| Step: 4
Training loss: 5.939479136637385
Validation loss: 5.772261469249353

Epoch: 6| Step: 5
Training loss: 6.667656379985587
Validation loss: 5.768776877228025

Epoch: 6| Step: 6
Training loss: 5.385221830738244
Validation loss: 5.765041607819367

Epoch: 6| Step: 7
Training loss: 6.378892495583763
Validation loss: 5.7610995098909905

Epoch: 6| Step: 8
Training loss: 5.547078389481946
Validation loss: 5.757027160557491

Epoch: 6| Step: 9
Training loss: 5.8885860405228545
Validation loss: 5.752654388977546

Epoch: 6| Step: 10
Training loss: 5.867666984298193
Validation loss: 5.748147721420751

Epoch: 6| Step: 11
Training loss: 6.438149724967843
Validation loss: 5.74353352036005

Epoch: 6| Step: 12
Training loss: 5.094853006775026
Validation loss: 5.73860673390318

Epoch: 6| Step: 13
Training loss: 4.777311211114147
Validation loss: 5.733405063239585

Epoch: 3| Step: 0
Training loss: 6.704304055686448
Validation loss: 5.72792506780397

Epoch: 6| Step: 1
Training loss: 6.020713338569161
Validation loss: 5.722314054046494

Epoch: 6| Step: 2
Training loss: 5.6380186531702865
Validation loss: 5.716343913777427

Epoch: 6| Step: 3
Training loss: 5.720346696923868
Validation loss: 5.7105568316669215

Epoch: 6| Step: 4
Training loss: 6.572318153114753
Validation loss: 5.704016405926438

Epoch: 6| Step: 5
Training loss: 5.9961739102947975
Validation loss: 5.697534812206034

Epoch: 6| Step: 6
Training loss: 5.1463439111524085
Validation loss: 5.690380135717552

Epoch: 6| Step: 7
Training loss: 5.992473013589925
Validation loss: 5.683209879737864

Epoch: 6| Step: 8
Training loss: 5.482952400742559
Validation loss: 5.675758314512977

Epoch: 6| Step: 9
Training loss: 5.213039174541348
Validation loss: 5.668240085647256

Epoch: 6| Step: 10
Training loss: 5.611857510433353
Validation loss: 5.660160602631967

Epoch: 6| Step: 11
Training loss: 5.650013894933308
Validation loss: 5.652159896352648

Epoch: 6| Step: 12
Training loss: 5.759432809242564
Validation loss: 5.643712460663051

Epoch: 6| Step: 13
Training loss: 5.503692081310409
Validation loss: 5.635060165702369

Epoch: 4| Step: 0
Training loss: 5.376013726739162
Validation loss: 5.6264005542187325

Epoch: 6| Step: 1
Training loss: 5.835589744491608
Validation loss: 5.616994883666205

Epoch: 6| Step: 2
Training loss: 6.921570230839908
Validation loss: 5.607825076617982

Epoch: 6| Step: 3
Training loss: 5.067116975014152
Validation loss: 5.5986101287678585

Epoch: 6| Step: 4
Training loss: 5.9402600749715315
Validation loss: 5.5886828098682075

Epoch: 6| Step: 5
Training loss: 5.882432497271935
Validation loss: 5.579044982099758

Epoch: 6| Step: 6
Training loss: 6.396541328467821
Validation loss: 5.569690500195202

Epoch: 6| Step: 7
Training loss: 5.390415176509736
Validation loss: 5.559455524195203

Epoch: 6| Step: 8
Training loss: 4.796280118854154
Validation loss: 5.549802825907732

Epoch: 6| Step: 9
Training loss: 5.745497557870858
Validation loss: 5.540055043007903

Epoch: 6| Step: 10
Training loss: 5.73892738023282
Validation loss: 5.530001569475224

Epoch: 6| Step: 11
Training loss: 5.295747800186825
Validation loss: 5.520504731769513

Epoch: 6| Step: 12
Training loss: 5.855223789906139
Validation loss: 5.510555772762245

Epoch: 6| Step: 13
Training loss: 4.946395008274295
Validation loss: 5.500761297307423

Epoch: 5| Step: 0
Training loss: 5.614789894093061
Validation loss: 5.491168821669588

Epoch: 6| Step: 1
Training loss: 6.039243786695212
Validation loss: 5.481644257619227

Epoch: 6| Step: 2
Training loss: 5.8127283851300735
Validation loss: 5.472206839697443

Epoch: 6| Step: 3
Training loss: 5.78262296302634
Validation loss: 5.462496802753179

Epoch: 6| Step: 4
Training loss: 5.666111227002835
Validation loss: 5.453501516203278

Epoch: 6| Step: 5
Training loss: 6.224221127972748
Validation loss: 5.443913765862656

Epoch: 6| Step: 6
Training loss: 5.2108243961441625
Validation loss: 5.434668114105746

Epoch: 6| Step: 7
Training loss: 5.158113455002018
Validation loss: 5.425623731017948

Epoch: 6| Step: 8
Training loss: 6.061415113142155
Validation loss: 5.416958355997127

Epoch: 6| Step: 9
Training loss: 5.0502884130928525
Validation loss: 5.4078498193158

Epoch: 6| Step: 10
Training loss: 5.489175374786819
Validation loss: 5.399247678696602

Epoch: 6| Step: 11
Training loss: 4.97635878979898
Validation loss: 5.390506142305673

Epoch: 6| Step: 12
Training loss: 4.546813335197186
Validation loss: 5.3827677347936005

Epoch: 6| Step: 13
Training loss: 5.831939349054045
Validation loss: 5.374187762967842

Epoch: 6| Step: 0
Training loss: 4.80654380108697
Validation loss: 5.366414510043323

Epoch: 6| Step: 1
Training loss: 5.328111754817664
Validation loss: 5.358450258362582

Epoch: 6| Step: 2
Training loss: 4.846283674538828
Validation loss: 5.350508700752842

Epoch: 6| Step: 3
Training loss: 5.0704024061510875
Validation loss: 5.343107248061783

Epoch: 6| Step: 4
Training loss: 5.065108392578035
Validation loss: 5.335625791590957

Epoch: 6| Step: 5
Training loss: 5.073997345896242
Validation loss: 5.327870442116409

Epoch: 6| Step: 6
Training loss: 5.404924704338656
Validation loss: 5.320632334920359

Epoch: 6| Step: 7
Training loss: 5.7851048170401045
Validation loss: 5.313083661498244

Epoch: 6| Step: 8
Training loss: 6.600316542924049
Validation loss: 5.30577292782047

Epoch: 6| Step: 9
Training loss: 4.935860277074776
Validation loss: 5.298322991697753

Epoch: 6| Step: 10
Training loss: 6.286476200545066
Validation loss: 5.290830811494791

Epoch: 6| Step: 11
Training loss: 6.100674026021825
Validation loss: 5.283143225216889

Epoch: 6| Step: 12
Training loss: 5.315790929789142
Validation loss: 5.275584535919979

Epoch: 6| Step: 13
Training loss: 5.122205577187974
Validation loss: 5.2677431157342784

Epoch: 7| Step: 0
Training loss: 5.366587953799802
Validation loss: 5.259839782305394

Epoch: 6| Step: 1
Training loss: 5.5383620579254265
Validation loss: 5.2517067995821

Epoch: 6| Step: 2
Training loss: 5.59121595556963
Validation loss: 5.244110194472541

Epoch: 6| Step: 3
Training loss: 5.298530072478128
Validation loss: 5.236143141878186

Epoch: 6| Step: 4
Training loss: 4.775042524697649
Validation loss: 5.2283455658707645

Epoch: 6| Step: 5
Training loss: 5.514402086454501
Validation loss: 5.220250627778449

Epoch: 6| Step: 6
Training loss: 5.949275176193341
Validation loss: 5.212813878843309

Epoch: 6| Step: 7
Training loss: 6.007489616140598
Validation loss: 5.205231813758635

Epoch: 6| Step: 8
Training loss: 5.264594727194256
Validation loss: 5.19732084152974

Epoch: 6| Step: 9
Training loss: 5.172486790547529
Validation loss: 5.1895460819891595

Epoch: 6| Step: 10
Training loss: 5.771057712126887
Validation loss: 5.1824137253180975

Epoch: 6| Step: 11
Training loss: 3.6311629949707465
Validation loss: 5.174813441355353

Epoch: 6| Step: 12
Training loss: 5.281359789909105
Validation loss: 5.168179608399943

Epoch: 6| Step: 13
Training loss: 5.100868166163872
Validation loss: 5.161088403506513

Epoch: 8| Step: 0
Training loss: 5.105959062447298
Validation loss: 5.15439592415408

Epoch: 6| Step: 1
Training loss: 4.632426717047811
Validation loss: 5.148085818051876

Epoch: 6| Step: 2
Training loss: 6.168394551186826
Validation loss: 5.141512051220087

Epoch: 6| Step: 3
Training loss: 5.8806579616164925
Validation loss: 5.134791286477417

Epoch: 6| Step: 4
Training loss: 5.983043233626949
Validation loss: 5.127744451579619

Epoch: 6| Step: 5
Training loss: 5.1059514045957926
Validation loss: 5.120594177786553

Epoch: 6| Step: 6
Training loss: 5.397164002738933
Validation loss: 5.113530886554473

Epoch: 6| Step: 7
Training loss: 4.159615437632337
Validation loss: 5.106969113336874

Epoch: 6| Step: 8
Training loss: 4.830457204341895
Validation loss: 5.100311827008919

Epoch: 6| Step: 9
Training loss: 5.099889881216761
Validation loss: 5.093947112281292

Epoch: 6| Step: 10
Training loss: 4.896559165015178
Validation loss: 5.087156463196555

Epoch: 6| Step: 11
Training loss: 4.779531132514955
Validation loss: 5.080325482271651

Epoch: 6| Step: 12
Training loss: 5.36086437116537
Validation loss: 5.073884196775204

Epoch: 6| Step: 13
Training loss: 5.514547010339838
Validation loss: 5.067192116687329

Epoch: 9| Step: 0
Training loss: 5.03095391391489
Validation loss: 5.060590281779458

Epoch: 6| Step: 1
Training loss: 5.265828567328059
Validation loss: 5.0536964384353205

Epoch: 6| Step: 2
Training loss: 5.599617890536776
Validation loss: 5.047791042593613

Epoch: 6| Step: 3
Training loss: 5.263507360601619
Validation loss: 5.040633713174105

Epoch: 6| Step: 4
Training loss: 5.1893884369792085
Validation loss: 5.03393378855068

Epoch: 6| Step: 5
Training loss: 4.735803772521215
Validation loss: 5.027023087841524

Epoch: 6| Step: 6
Training loss: 4.161048127328538
Validation loss: 5.020346347517833

Epoch: 6| Step: 7
Training loss: 5.072739030781503
Validation loss: 5.01419760099132

Epoch: 6| Step: 8
Training loss: 4.853973821430319
Validation loss: 5.008829046377259

Epoch: 6| Step: 9
Training loss: 5.3453543413002675
Validation loss: 5.0028907049098565

Epoch: 6| Step: 10
Training loss: 5.02459542083404
Validation loss: 4.9966507502517175

Epoch: 6| Step: 11
Training loss: 5.140142632668834
Validation loss: 4.990971870446531

Epoch: 6| Step: 12
Training loss: 5.486825944173042
Validation loss: 4.985159785274369

Epoch: 6| Step: 13
Training loss: 5.645283896349744
Validation loss: 4.979693375611826

Epoch: 10| Step: 0
Training loss: 3.9592348912475837
Validation loss: 4.973240101138961

Epoch: 6| Step: 1
Training loss: 5.01512870828789
Validation loss: 4.9677495049100795

Epoch: 6| Step: 2
Training loss: 5.128946413113882
Validation loss: 4.962250719447483

Epoch: 6| Step: 3
Training loss: 4.392570743240796
Validation loss: 4.956381480400002

Epoch: 6| Step: 4
Training loss: 4.913322841852202
Validation loss: 4.951039867158682

Epoch: 6| Step: 5
Training loss: 5.297901515461503
Validation loss: 4.945316260458434

Epoch: 6| Step: 6
Training loss: 5.712890291132469
Validation loss: 4.9400248128188045

Epoch: 6| Step: 7
Training loss: 5.53411601325973
Validation loss: 4.934206318725219

Epoch: 6| Step: 8
Training loss: 4.912859698223501
Validation loss: 4.929028772836791

Epoch: 6| Step: 9
Training loss: 5.692737892216069
Validation loss: 4.923018969445362

Epoch: 6| Step: 10
Training loss: 5.439198897223256
Validation loss: 4.918103827009454

Epoch: 6| Step: 11
Training loss: 4.269470940362014
Validation loss: 4.911878430983829

Epoch: 6| Step: 12
Training loss: 5.415761353569631
Validation loss: 4.906459795764935

Epoch: 6| Step: 13
Training loss: 4.806692607525697
Validation loss: 4.9003527079686755

Epoch: 11| Step: 0
Training loss: 4.1769170688381125
Validation loss: 4.894987620363048

Epoch: 6| Step: 1
Training loss: 5.403399294702204
Validation loss: 4.889943588285096

Epoch: 6| Step: 2
Training loss: 4.786445138917931
Validation loss: 4.884831874092602

Epoch: 6| Step: 3
Training loss: 4.663793814889626
Validation loss: 4.879738094618431

Epoch: 6| Step: 4
Training loss: 5.052450118236263
Validation loss: 4.874835769625758

Epoch: 6| Step: 5
Training loss: 5.872685727381288
Validation loss: 4.869365206998172

Epoch: 6| Step: 6
Training loss: 4.734843517323981
Validation loss: 4.863988258619526

Epoch: 6| Step: 7
Training loss: 4.600781515325175
Validation loss: 4.858536462915838

Epoch: 6| Step: 8
Training loss: 5.02170467598237
Validation loss: 4.853416035562349

Epoch: 6| Step: 9
Training loss: 5.11518440935887
Validation loss: 4.848147768753431

Epoch: 6| Step: 10
Training loss: 4.993260610039836
Validation loss: 4.84324955149518

Epoch: 6| Step: 11
Training loss: 5.520675637734055
Validation loss: 4.837793802281443

Epoch: 6| Step: 12
Training loss: 5.509842648621941
Validation loss: 4.832585287852843

Epoch: 6| Step: 13
Training loss: 4.017133733626239
Validation loss: 4.827244420080964

Epoch: 12| Step: 0
Training loss: 4.795256201748273
Validation loss: 4.8221805853933475

Epoch: 6| Step: 1
Training loss: 4.185526824205357
Validation loss: 4.816814354784989

Epoch: 6| Step: 2
Training loss: 5.842376057881672
Validation loss: 4.811394799883826

Epoch: 6| Step: 3
Training loss: 4.29389167563015
Validation loss: 4.806434326208923

Epoch: 6| Step: 4
Training loss: 4.736601353265941
Validation loss: 4.80128408912343

Epoch: 6| Step: 5
Training loss: 4.7028336038647645
Validation loss: 4.796362270658088

Epoch: 6| Step: 6
Training loss: 4.818878108794307
Validation loss: 4.790875090300244

Epoch: 6| Step: 7
Training loss: 4.915897675631114
Validation loss: 4.785783500821557

Epoch: 6| Step: 8
Training loss: 4.676651875986178
Validation loss: 4.780609021407199

Epoch: 6| Step: 9
Training loss: 5.253749416804185
Validation loss: 4.7760888793786025

Epoch: 6| Step: 10
Training loss: 5.244798172230428
Validation loss: 4.770837086949545

Epoch: 6| Step: 11
Training loss: 5.572434715275349
Validation loss: 4.7655431521531915

Epoch: 6| Step: 12
Training loss: 4.987657954647511
Validation loss: 4.76002131294373

Epoch: 6| Step: 13
Training loss: 4.496419541845385
Validation loss: 4.754997435367506

Epoch: 13| Step: 0
Training loss: 4.55984503432524
Validation loss: 4.7497785750863635

Epoch: 6| Step: 1
Training loss: 5.280963054739397
Validation loss: 4.744579602166879

Epoch: 6| Step: 2
Training loss: 5.0725995329543325
Validation loss: 4.739457762455577

Epoch: 6| Step: 3
Training loss: 5.131785111397926
Validation loss: 4.73447585129623

Epoch: 6| Step: 4
Training loss: 4.215800292581895
Validation loss: 4.72913247430795

Epoch: 6| Step: 5
Training loss: 4.002280538857659
Validation loss: 4.72442045408358

Epoch: 6| Step: 6
Training loss: 3.8971002460103095
Validation loss: 4.718200634772783

Epoch: 6| Step: 7
Training loss: 4.532498733511915
Validation loss: 4.712832683824138

Epoch: 6| Step: 8
Training loss: 5.4420199845692565
Validation loss: 4.707886339873152

Epoch: 6| Step: 9
Training loss: 5.579197200874871
Validation loss: 4.703281454903686

Epoch: 6| Step: 10
Training loss: 5.183251169091149
Validation loss: 4.6972682305194615

Epoch: 6| Step: 11
Training loss: 4.726334091846862
Validation loss: 4.692694773709108

Epoch: 6| Step: 12
Training loss: 5.08237314796794
Validation loss: 4.687125720870331

Epoch: 6| Step: 13
Training loss: 4.724260762833591
Validation loss: 4.68148271689307

Epoch: 14| Step: 0
Training loss: 5.2045405298128715
Validation loss: 4.676788145179223

Epoch: 6| Step: 1
Training loss: 4.416395263010392
Validation loss: 4.671131019509531

Epoch: 6| Step: 2
Training loss: 4.7782651273190275
Validation loss: 4.665431279195351

Epoch: 6| Step: 3
Training loss: 5.087102191190313
Validation loss: 4.660131368599973

Epoch: 6| Step: 4
Training loss: 4.108789670617498
Validation loss: 4.6548066771805505

Epoch: 6| Step: 5
Training loss: 5.363523606994574
Validation loss: 4.649790881523885

Epoch: 6| Step: 6
Training loss: 4.883469487050885
Validation loss: 4.6446979429694855

Epoch: 6| Step: 7
Training loss: 4.040982349050403
Validation loss: 4.6391703405423375

Epoch: 6| Step: 8
Training loss: 4.577195213083746
Validation loss: 4.63353752308362

Epoch: 6| Step: 9
Training loss: 4.31600964135197
Validation loss: 4.628864323550895

Epoch: 6| Step: 10
Training loss: 5.648453539644844
Validation loss: 4.623783707706829

Epoch: 6| Step: 11
Training loss: 5.399776750824078
Validation loss: 4.618640995761137

Epoch: 6| Step: 12
Training loss: 4.293667570652786
Validation loss: 4.612589569738354

Epoch: 6| Step: 13
Training loss: 4.270797332363826
Validation loss: 4.608980668436601

Epoch: 15| Step: 0
Training loss: 5.561184502539819
Validation loss: 4.603326274876543

Epoch: 6| Step: 1
Training loss: 3.987777633329228
Validation loss: 4.597433434302338

Epoch: 6| Step: 2
Training loss: 4.974189899373495
Validation loss: 4.5929510758292365

Epoch: 6| Step: 3
Training loss: 4.932022533170362
Validation loss: 4.587406579503433

Epoch: 6| Step: 4
Training loss: 4.696122846955898
Validation loss: 4.582519435865631

Epoch: 6| Step: 5
Training loss: 4.708392162574374
Validation loss: 4.577678741126563

Epoch: 6| Step: 6
Training loss: 5.1633893149887164
Validation loss: 4.572076771043477

Epoch: 6| Step: 7
Training loss: 4.830328478651315
Validation loss: 4.567302684395087

Epoch: 6| Step: 8
Training loss: 4.603507131342928
Validation loss: 4.5618206023470105

Epoch: 6| Step: 9
Training loss: 4.760049328588487
Validation loss: 4.556357843546942

Epoch: 6| Step: 10
Training loss: 5.007632914401325
Validation loss: 4.551662690421544

Epoch: 6| Step: 11
Training loss: 3.8856618086292634
Validation loss: 4.54696046938973

Epoch: 6| Step: 12
Training loss: 4.137883268277941
Validation loss: 4.541879555615192

Epoch: 6| Step: 13
Training loss: 4.234813934886674
Validation loss: 4.5365879056392195

Epoch: 16| Step: 0
Training loss: 4.108077972296149
Validation loss: 4.532247534381917

Epoch: 6| Step: 1
Training loss: 4.785497835384601
Validation loss: 4.527758777061073

Epoch: 6| Step: 2
Training loss: 4.787801604568835
Validation loss: 4.522795478442435

Epoch: 6| Step: 3
Training loss: 4.3860938968096495
Validation loss: 4.51778630294992

Epoch: 6| Step: 4
Training loss: 5.286279394068509
Validation loss: 4.513261152128831

Epoch: 6| Step: 5
Training loss: 4.957904038424265
Validation loss: 4.508427851750282

Epoch: 6| Step: 6
Training loss: 4.580969021495705
Validation loss: 4.503959256224477

Epoch: 6| Step: 7
Training loss: 4.162896599648523
Validation loss: 4.498964367128133

Epoch: 6| Step: 8
Training loss: 4.570153910175818
Validation loss: 4.493487590685079

Epoch: 6| Step: 9
Training loss: 4.316518928817734
Validation loss: 4.489286207853784

Epoch: 6| Step: 10
Training loss: 4.441622686019259
Validation loss: 4.484307991971553

Epoch: 6| Step: 11
Training loss: 4.020981596484567
Validation loss: 4.479448614192006

Epoch: 6| Step: 12
Training loss: 5.384330812207594
Validation loss: 4.476287105448767

Epoch: 6| Step: 13
Training loss: 4.792950046443743
Validation loss: 4.469914478021522

Epoch: 17| Step: 0
Training loss: 5.3220523896504055
Validation loss: 4.46851912037654

Epoch: 6| Step: 1
Training loss: 4.557296084447263
Validation loss: 4.465042550374414

Epoch: 6| Step: 2
Training loss: 4.908786385335531
Validation loss: 4.459397281126814

Epoch: 6| Step: 3
Training loss: 3.8686565036599654
Validation loss: 4.454633401528634

Epoch: 6| Step: 4
Training loss: 4.113888194922446
Validation loss: 4.450445642909431

Epoch: 6| Step: 5
Training loss: 4.321348759298109
Validation loss: 4.446820781463911

Epoch: 6| Step: 6
Training loss: 4.414050833087457
Validation loss: 4.442812824101233

Epoch: 6| Step: 7
Training loss: 3.8121243901567317
Validation loss: 4.43887733969355

Epoch: 6| Step: 8
Training loss: 4.166622212490724
Validation loss: 4.433729333806994

Epoch: 6| Step: 9
Training loss: 5.141308028925228
Validation loss: 4.428298974775479

Epoch: 6| Step: 10
Training loss: 5.3134904723501535
Validation loss: 4.4233228202604815

Epoch: 6| Step: 11
Training loss: 4.279272360581312
Validation loss: 4.417618750872453

Epoch: 6| Step: 12
Training loss: 4.786077318879723
Validation loss: 4.413238538509612

Epoch: 6| Step: 13
Training loss: 4.601730369523928
Validation loss: 4.408570672744956

Epoch: 18| Step: 0
Training loss: 4.030385479156516
Validation loss: 4.40425288255237

Epoch: 6| Step: 1
Training loss: 4.866804227234795
Validation loss: 4.399632636542227

Epoch: 6| Step: 2
Training loss: 5.2065720695534505
Validation loss: 4.394699794221601

Epoch: 6| Step: 3
Training loss: 4.296269932540547
Validation loss: 4.389027894443729

Epoch: 6| Step: 4
Training loss: 5.298892736831931
Validation loss: 4.384763522526407

Epoch: 6| Step: 5
Training loss: 3.679163415604246
Validation loss: 4.380078138789566

Epoch: 6| Step: 6
Training loss: 4.05070449918249
Validation loss: 4.376041542688247

Epoch: 6| Step: 7
Training loss: 3.242295596607257
Validation loss: 4.371985514118596

Epoch: 6| Step: 8
Training loss: 4.377404560331893
Validation loss: 4.367696460598871

Epoch: 6| Step: 9
Training loss: 4.766648279612542
Validation loss: 4.362870304309555

Epoch: 6| Step: 10
Training loss: 4.971278668791682
Validation loss: 4.358268770623466

Epoch: 6| Step: 11
Training loss: 4.204040427655091
Validation loss: 4.353770309489951

Epoch: 6| Step: 12
Training loss: 4.718368009554149
Validation loss: 4.349656770399708

Epoch: 6| Step: 13
Training loss: 4.8391110756209414
Validation loss: 4.345232539039638

Epoch: 19| Step: 0
Training loss: 3.6697202163195564
Validation loss: 4.3408303820304095

Epoch: 6| Step: 1
Training loss: 4.486331526174157
Validation loss: 4.336736693631765

Epoch: 6| Step: 2
Training loss: 4.696237177888426
Validation loss: 4.331839316140453

Epoch: 6| Step: 3
Training loss: 3.412065214189041
Validation loss: 4.327493412652632

Epoch: 6| Step: 4
Training loss: 3.906255615230339
Validation loss: 4.323574533922892

Epoch: 6| Step: 5
Training loss: 4.644914385085627
Validation loss: 4.3193793596854615

Epoch: 6| Step: 6
Training loss: 5.436628951536922
Validation loss: 4.315005215155087

Epoch: 6| Step: 7
Training loss: 4.752652883062247
Validation loss: 4.310835954945684

Epoch: 6| Step: 8
Training loss: 4.6763107012796254
Validation loss: 4.305903379002107

Epoch: 6| Step: 9
Training loss: 4.623883911734724
Validation loss: 4.301265863642271

Epoch: 6| Step: 10
Training loss: 3.978799426856095
Validation loss: 4.297043157812799

Epoch: 6| Step: 11
Training loss: 4.741948582068396
Validation loss: 4.2925988206576555

Epoch: 6| Step: 12
Training loss: 4.795040015728899
Validation loss: 4.287525839769444

Epoch: 6| Step: 13
Training loss: 3.929574407387314
Validation loss: 4.283022455642739

Epoch: 20| Step: 0
Training loss: 3.9043518337333727
Validation loss: 4.278068195464676

Epoch: 6| Step: 1
Training loss: 3.947751701887526
Validation loss: 4.273707240098012

Epoch: 6| Step: 2
Training loss: 4.617658407140903
Validation loss: 4.2689183415609255

Epoch: 6| Step: 3
Training loss: 3.8378226626059493
Validation loss: 4.264874309582412

Epoch: 6| Step: 4
Training loss: 4.537981807465483
Validation loss: 4.260661888371367

Epoch: 6| Step: 5
Training loss: 4.758836257108733
Validation loss: 4.255335880206067

Epoch: 6| Step: 6
Training loss: 5.023621266564868
Validation loss: 4.250549636155517

Epoch: 6| Step: 7
Training loss: 4.137836251324289
Validation loss: 4.245601378678905

Epoch: 6| Step: 8
Training loss: 3.4014372817031133
Validation loss: 4.240932777834475

Epoch: 6| Step: 9
Training loss: 4.822520141559501
Validation loss: 4.236486605207612

Epoch: 6| Step: 10
Training loss: 4.348480064301652
Validation loss: 4.231667134897317

Epoch: 6| Step: 11
Training loss: 4.83038356261058
Validation loss: 4.22746428002551

Epoch: 6| Step: 12
Training loss: 4.227990323534731
Validation loss: 4.223598529184079

Epoch: 6| Step: 13
Training loss: 4.585462087394426
Validation loss: 4.21848610888582

Epoch: 21| Step: 0
Training loss: 4.782953096134669
Validation loss: 4.214367509345248

Epoch: 6| Step: 1
Training loss: 4.86297042650051
Validation loss: 4.209727777029716

Epoch: 6| Step: 2
Training loss: 3.7631477026578484
Validation loss: 4.204760964577683

Epoch: 6| Step: 3
Training loss: 4.768460190192346
Validation loss: 4.200585942040672

Epoch: 6| Step: 4
Training loss: 4.090720883288262
Validation loss: 4.195682066558638

Epoch: 6| Step: 5
Training loss: 4.204893512987743
Validation loss: 4.191697138125095

Epoch: 6| Step: 6
Training loss: 3.79412742383874
Validation loss: 4.187050619732432

Epoch: 6| Step: 7
Training loss: 4.038125023427827
Validation loss: 4.182617947529894

Epoch: 6| Step: 8
Training loss: 3.936288314153153
Validation loss: 4.178291558289025

Epoch: 6| Step: 9
Training loss: 4.339124453428234
Validation loss: 4.17434503058588

Epoch: 6| Step: 10
Training loss: 3.57011696845594
Validation loss: 4.170041637502464

Epoch: 6| Step: 11
Training loss: 4.093881153597436
Validation loss: 4.166228303102189

Epoch: 6| Step: 12
Training loss: 5.024892830536192
Validation loss: 4.161535244049169

Epoch: 6| Step: 13
Training loss: 4.832972787147028
Validation loss: 4.157248623226154

Epoch: 22| Step: 0
Training loss: 4.15499560708228
Validation loss: 4.152974111678243

Epoch: 6| Step: 1
Training loss: 4.646948824451933
Validation loss: 4.148506618960834

Epoch: 6| Step: 2
Training loss: 4.558255245974184
Validation loss: 4.14405128223767

Epoch: 6| Step: 3
Training loss: 4.614427183564811
Validation loss: 4.139620465958568

Epoch: 6| Step: 4
Training loss: 3.5486338283527497
Validation loss: 4.135149366578577

Epoch: 6| Step: 5
Training loss: 3.7674147282235912
Validation loss: 4.130521623708234

Epoch: 6| Step: 6
Training loss: 4.731660070751753
Validation loss: 4.126270772763606

Epoch: 6| Step: 7
Training loss: 4.401255705856009
Validation loss: 4.122249630399644

Epoch: 6| Step: 8
Training loss: 4.201698940525892
Validation loss: 4.117345142181621

Epoch: 6| Step: 9
Training loss: 4.033594676816909
Validation loss: 4.113305864927635

Epoch: 6| Step: 10
Training loss: 4.216100468272707
Validation loss: 4.108607695563659

Epoch: 6| Step: 11
Training loss: 4.1399581660124305
Validation loss: 4.1040207244691835

Epoch: 6| Step: 12
Training loss: 3.852105340366965
Validation loss: 4.10013893248707

Epoch: 6| Step: 13
Training loss: 4.546347676010064
Validation loss: 4.095795137544865

Epoch: 23| Step: 0
Training loss: 4.482729300800231
Validation loss: 4.091899074834966

Epoch: 6| Step: 1
Training loss: 4.243708722415232
Validation loss: 4.087160101396547

Epoch: 6| Step: 2
Training loss: 4.290137651275834
Validation loss: 4.082870509069737

Epoch: 6| Step: 3
Training loss: 3.726092358888568
Validation loss: 4.078311004878942

Epoch: 6| Step: 4
Training loss: 4.476679242860385
Validation loss: 4.073868246048878

Epoch: 6| Step: 5
Training loss: 4.4025987146803285
Validation loss: 4.069892163578134

Epoch: 6| Step: 6
Training loss: 3.829892120435614
Validation loss: 4.065211344969208

Epoch: 6| Step: 7
Training loss: 4.469292667757756
Validation loss: 4.061342142847801

Epoch: 6| Step: 8
Training loss: 4.409233219670878
Validation loss: 4.0568924374054545

Epoch: 6| Step: 9
Training loss: 3.7250168511950403
Validation loss: 4.052760298925621

Epoch: 6| Step: 10
Training loss: 4.245627453984551
Validation loss: 4.048994120734184

Epoch: 6| Step: 11
Training loss: 3.977060343038306
Validation loss: 4.044341012018717

Epoch: 6| Step: 12
Training loss: 4.121833047949771
Validation loss: 4.039938540856746

Epoch: 6| Step: 13
Training loss: 4.244747281768843
Validation loss: 4.035816927575944

Epoch: 24| Step: 0
Training loss: 4.115503650866193
Validation loss: 4.031174336198936

Epoch: 6| Step: 1
Training loss: 4.009912130482344
Validation loss: 4.027159495783848

Epoch: 6| Step: 2
Training loss: 3.20822794026915
Validation loss: 4.02304762645714

Epoch: 6| Step: 3
Training loss: 3.9959257357152627
Validation loss: 4.019224856469059

Epoch: 6| Step: 4
Training loss: 4.674472252744132
Validation loss: 4.014967828750777

Epoch: 6| Step: 5
Training loss: 4.865630903589566
Validation loss: 4.01067513297672

Epoch: 6| Step: 6
Training loss: 3.6833508958584824
Validation loss: 4.006575147394944

Epoch: 6| Step: 7
Training loss: 3.740576793643663
Validation loss: 4.002027573892926

Epoch: 6| Step: 8
Training loss: 4.480169683717064
Validation loss: 3.9979888708059272

Epoch: 6| Step: 9
Training loss: 4.343693794600397
Validation loss: 3.993590405160278

Epoch: 6| Step: 10
Training loss: 4.434046301242523
Validation loss: 3.9892597050625356

Epoch: 6| Step: 11
Training loss: 3.168333133762386
Validation loss: 3.984902779523208

Epoch: 6| Step: 12
Training loss: 3.859304574177147
Validation loss: 3.980983891718763

Epoch: 6| Step: 13
Training loss: 4.870606031680732
Validation loss: 3.9765693849355355

Epoch: 25| Step: 0
Training loss: 4.8469495481049725
Validation loss: 3.972013238301518

Epoch: 6| Step: 1
Training loss: 3.913626945459301
Validation loss: 3.9679118395261286

Epoch: 6| Step: 2
Training loss: 4.038675728731598
Validation loss: 3.963277553158337

Epoch: 6| Step: 3
Training loss: 4.091073129235761
Validation loss: 3.9587996492603934

Epoch: 6| Step: 4
Training loss: 3.9765708938240243
Validation loss: 3.954426808671771

Epoch: 6| Step: 5
Training loss: 3.9525641846436885
Validation loss: 3.9503113756705557

Epoch: 6| Step: 6
Training loss: 4.468812741992894
Validation loss: 3.9461940271554408

Epoch: 6| Step: 7
Training loss: 4.5714149645194135
Validation loss: 3.9416097154327114

Epoch: 6| Step: 8
Training loss: 4.228909389143025
Validation loss: 3.937114777466518

Epoch: 6| Step: 9
Training loss: 3.492706874654078
Validation loss: 3.9327374473001075

Epoch: 6| Step: 10
Training loss: 4.058338557454741
Validation loss: 3.9281880707736603

Epoch: 6| Step: 11
Training loss: 3.7901161852417977
Validation loss: 3.9239143044384988

Epoch: 6| Step: 12
Training loss: 4.729101889190455
Validation loss: 3.9197986876767583

Epoch: 6| Step: 13
Training loss: 2.3591799623830454
Validation loss: 3.915063198386617

Epoch: 26| Step: 0
Training loss: 3.2329850458235274
Validation loss: 3.9112387577332988

Epoch: 6| Step: 1
Training loss: 4.334189452673928
Validation loss: 3.9069232614787275

Epoch: 6| Step: 2
Training loss: 3.5472823257817683
Validation loss: 3.9030308390637107

Epoch: 6| Step: 3
Training loss: 4.5684971521549675
Validation loss: 3.8986426167622574

Epoch: 6| Step: 4
Training loss: 4.4785616207297885
Validation loss: 3.8944046066237084

Epoch: 6| Step: 5
Training loss: 4.345652650690022
Validation loss: 3.8899990328907683

Epoch: 6| Step: 6
Training loss: 3.758285778164886
Validation loss: 3.885781046917614

Epoch: 6| Step: 7
Training loss: 3.7890645135303926
Validation loss: 3.8815099525728645

Epoch: 6| Step: 8
Training loss: 3.7533268476422266
Validation loss: 3.877280189945786

Epoch: 6| Step: 9
Training loss: 4.100627916216122
Validation loss: 3.87320548723641

Epoch: 6| Step: 10
Training loss: 4.342979307894389
Validation loss: 3.869162171592843

Epoch: 6| Step: 11
Training loss: 3.272796495264266
Validation loss: 3.864524813446314

Epoch: 6| Step: 12
Training loss: 4.08665655457416
Validation loss: 3.860381187005554

Epoch: 6| Step: 13
Training loss: 4.33379777228974
Validation loss: 3.8562788184772354

Epoch: 27| Step: 0
Training loss: 4.1177551920500655
Validation loss: 3.8518735026263236

Epoch: 6| Step: 1
Training loss: 4.816930539692134
Validation loss: 3.8476277255116003

Epoch: 6| Step: 2
Training loss: 4.20981629684406
Validation loss: 3.8430155851081365

Epoch: 6| Step: 3
Training loss: 4.379239888884204
Validation loss: 3.8380888935414403

Epoch: 6| Step: 4
Training loss: 4.025203931866711
Validation loss: 3.833333132923508

Epoch: 6| Step: 5
Training loss: 2.5520210933232117
Validation loss: 3.8288813667705632

Epoch: 6| Step: 6
Training loss: 3.541447322261414
Validation loss: 3.824367189107924

Epoch: 6| Step: 7
Training loss: 3.9155815055118124
Validation loss: 3.8200702655448033

Epoch: 6| Step: 8
Training loss: 3.2046961954892543
Validation loss: 3.8157380325025407

Epoch: 6| Step: 9
Training loss: 3.220415591792821
Validation loss: 3.8115301722640456

Epoch: 6| Step: 10
Training loss: 4.618524916020519
Validation loss: 3.8074234062534327

Epoch: 6| Step: 11
Training loss: 4.054994898556512
Validation loss: 3.8032479510027533

Epoch: 6| Step: 12
Training loss: 4.175660205653253
Validation loss: 3.7992448566744423

Epoch: 6| Step: 13
Training loss: 4.000401476739261
Validation loss: 3.795127456025802

Epoch: 28| Step: 0
Training loss: 4.144758356687052
Validation loss: 3.790403148577676

Epoch: 6| Step: 1
Training loss: 3.350675736783016
Validation loss: 3.7862149789608823

Epoch: 6| Step: 2
Training loss: 3.1196487385526477
Validation loss: 3.7817661364001305

Epoch: 6| Step: 3
Training loss: 3.5433340000021576
Validation loss: 3.777607216599963

Epoch: 6| Step: 4
Training loss: 4.083410353161275
Validation loss: 3.7737902785067345

Epoch: 6| Step: 5
Training loss: 4.65878206570058
Validation loss: 3.7696170566523763

Epoch: 6| Step: 6
Training loss: 3.807996998521279
Validation loss: 3.765597162631859

Epoch: 6| Step: 7
Training loss: 4.1011165122108535
Validation loss: 3.7611076727481554

Epoch: 6| Step: 8
Training loss: 4.080138429275505
Validation loss: 3.756636109610038

Epoch: 6| Step: 9
Training loss: 4.396124928039986
Validation loss: 3.752226931238563

Epoch: 6| Step: 10
Training loss: 4.223824846609867
Validation loss: 3.747886782843872

Epoch: 6| Step: 11
Training loss: 4.311384637311397
Validation loss: 3.743430040853463

Epoch: 6| Step: 12
Training loss: 3.2861956427407306
Validation loss: 3.7390225059877342

Epoch: 6| Step: 13
Training loss: 3.0375671630466923
Validation loss: 3.734440418558909

Epoch: 29| Step: 0
Training loss: 3.236244582742258
Validation loss: 3.730125659124814

Epoch: 6| Step: 1
Training loss: 3.7400719510261484
Validation loss: 3.725673054901059

Epoch: 6| Step: 2
Training loss: 3.2302201716257257
Validation loss: 3.7214690667422783

Epoch: 6| Step: 3
Training loss: 4.038799934043102
Validation loss: 3.717685130267721

Epoch: 6| Step: 4
Training loss: 3.6123852087876065
Validation loss: 3.7134979088529425

Epoch: 6| Step: 5
Training loss: 4.647196935957445
Validation loss: 3.7092064497548356

Epoch: 6| Step: 6
Training loss: 3.439150743335945
Validation loss: 3.7053645104900217

Epoch: 6| Step: 7
Training loss: 4.5641668749833535
Validation loss: 3.700859546484077

Epoch: 6| Step: 8
Training loss: 4.798703916725381
Validation loss: 3.696572710556792

Epoch: 6| Step: 9
Training loss: 3.8762908754281757
Validation loss: 3.6920210499588757

Epoch: 6| Step: 10
Training loss: 3.017739300914055
Validation loss: 3.687300682069063

Epoch: 6| Step: 11
Training loss: 3.5181100158318093
Validation loss: 3.683193040710512

Epoch: 6| Step: 12
Training loss: 3.6905481703575544
Validation loss: 3.678827162242405

Epoch: 6| Step: 13
Training loss: 3.8283911787641505
Validation loss: 3.6744960006807683

Epoch: 30| Step: 0
Training loss: 3.9656120570627658
Validation loss: 3.6700303442494855

Epoch: 6| Step: 1
Training loss: 4.003978896063523
Validation loss: 3.665584505664565

Epoch: 6| Step: 2
Training loss: 3.602755069849011
Validation loss: 3.6611821742888018

Epoch: 6| Step: 3
Training loss: 3.5815514562463338
Validation loss: 3.656694303725155

Epoch: 6| Step: 4
Training loss: 4.355058180270389
Validation loss: 3.6524841172823623

Epoch: 6| Step: 5
Training loss: 3.4025396735171802
Validation loss: 3.6480139323799485

Epoch: 6| Step: 6
Training loss: 3.072224650076408
Validation loss: 3.6437402802518193

Epoch: 6| Step: 7
Training loss: 4.63398035778086
Validation loss: 3.639635816667703

Epoch: 6| Step: 8
Training loss: 3.248979261468912
Validation loss: 3.6351768538432703

Epoch: 6| Step: 9
Training loss: 4.271888019622853
Validation loss: 3.6309726663896837

Epoch: 6| Step: 10
Training loss: 3.4408225907940038
Validation loss: 3.626780697406627

Epoch: 6| Step: 11
Training loss: 2.922919591538336
Validation loss: 3.622441232791229

Epoch: 6| Step: 12
Training loss: 3.936028705189866
Validation loss: 3.6182026547438566

Epoch: 6| Step: 13
Training loss: 4.037968205092977
Validation loss: 3.6136278910652995

Epoch: 31| Step: 0
Training loss: 3.6111952910433565
Validation loss: 3.609588088313868

Epoch: 6| Step: 1
Training loss: 3.8941573075396243
Validation loss: 3.605215144304824

Epoch: 6| Step: 2
Training loss: 3.0681169342475845
Validation loss: 3.6010692642091624

Epoch: 6| Step: 3
Training loss: 4.161472567206506
Validation loss: 3.5966467640502575

Epoch: 6| Step: 4
Training loss: 3.594654931285089
Validation loss: 3.5925082286580317

Epoch: 6| Step: 5
Training loss: 4.2904486301122216
Validation loss: 3.588084700694269

Epoch: 6| Step: 6
Training loss: 3.705387760108082
Validation loss: 3.5833927785393103

Epoch: 6| Step: 7
Training loss: 3.3454021044529934
Validation loss: 3.5789607597573934

Epoch: 6| Step: 8
Training loss: 4.126545009843189
Validation loss: 3.5747924344287836

Epoch: 6| Step: 9
Training loss: 3.4960501044761663
Validation loss: 3.5702812922454235

Epoch: 6| Step: 10
Training loss: 3.9986389944177536
Validation loss: 3.565940132892316

Epoch: 6| Step: 11
Training loss: 3.5072923712205233
Validation loss: 3.5611578437554363

Epoch: 6| Step: 12
Training loss: 3.4466406236718554
Validation loss: 3.5559131339855603

Epoch: 6| Step: 13
Training loss: 3.612942736465661
Validation loss: 3.5499682836951507

Epoch: 32| Step: 0
Training loss: 4.080526412214636
Validation loss: 3.54344197077707

Epoch: 6| Step: 1
Training loss: 3.092018182175488
Validation loss: 3.5374600541877728

Epoch: 6| Step: 2
Training loss: 3.407316828259393
Validation loss: 3.53272574316952

Epoch: 6| Step: 3
Training loss: 4.471206096788755
Validation loss: 3.5291850936630764

Epoch: 6| Step: 4
Training loss: 2.679820777537042
Validation loss: 3.524288145292694

Epoch: 6| Step: 5
Training loss: 3.360044900503331
Validation loss: 3.520575986105985

Epoch: 6| Step: 6
Training loss: 3.6763932370295165
Validation loss: 3.51528047356983

Epoch: 6| Step: 7
Training loss: 3.5123840312887133
Validation loss: 3.510927342398889

Epoch: 6| Step: 8
Training loss: 3.7251063286883745
Validation loss: 3.5064187682997146

Epoch: 6| Step: 9
Training loss: 3.564306503833738
Validation loss: 3.5022486320727295

Epoch: 6| Step: 10
Training loss: 3.5582740212946105
Validation loss: 3.4979686291674557

Epoch: 6| Step: 11
Training loss: 3.6943105101309057
Validation loss: 3.4938419300375076

Epoch: 6| Step: 12
Training loss: 4.414053857845523
Validation loss: 3.48952674630056

Epoch: 6| Step: 13
Training loss: 3.48046875
Validation loss: 3.485274696232865

Epoch: 33| Step: 0
Training loss: 2.9413799877438147
Validation loss: 3.480885992646541

Epoch: 6| Step: 1
Training loss: 3.179578024739332
Validation loss: 3.476925903072035

Epoch: 6| Step: 2
Training loss: 3.60050872811
Validation loss: 3.4734509663300073

Epoch: 6| Step: 3
Training loss: 4.413864158292745
Validation loss: 3.469465783301903

Epoch: 6| Step: 4
Training loss: 3.9666855616613694
Validation loss: 3.465082859188048

Epoch: 6| Step: 5
Training loss: 3.495736113428965
Validation loss: 3.4609105415528547

Epoch: 6| Step: 6
Training loss: 3.314783712612539
Validation loss: 3.4566403270319963

Epoch: 6| Step: 7
Training loss: 3.994047146102014
Validation loss: 3.4527636492859464

Epoch: 6| Step: 8
Training loss: 3.799493208770566
Validation loss: 3.4483828426351226

Epoch: 6| Step: 9
Training loss: 3.8957362171382894
Validation loss: 3.4444328678784273

Epoch: 6| Step: 10
Training loss: 3.6121786218793646
Validation loss: 3.439963019009612

Epoch: 6| Step: 11
Training loss: 3.5892100973507812
Validation loss: 3.4357791870523653

Epoch: 6| Step: 12
Training loss: 3.472298396652498
Validation loss: 3.431607252931013

Epoch: 6| Step: 13
Training loss: 2.6512200695832173
Validation loss: 3.427132827416851

Epoch: 34| Step: 0
Training loss: 3.998262504871501
Validation loss: 3.4231171465482917

Epoch: 6| Step: 1
Training loss: 3.508364355776187
Validation loss: 3.419053201753714

Epoch: 6| Step: 2
Training loss: 3.9179991761810853
Validation loss: 3.41490718073113

Epoch: 6| Step: 3
Training loss: 3.6489980132290176
Validation loss: 3.4104411620462622

Epoch: 6| Step: 4
Training loss: 3.40608032923895
Validation loss: 3.4062786976016604

Epoch: 6| Step: 5
Training loss: 3.4796940447604876
Validation loss: 3.4022104884670026

Epoch: 6| Step: 6
Training loss: 2.8809744084554607
Validation loss: 3.3977505512122494

Epoch: 6| Step: 7
Training loss: 3.6772831474385472
Validation loss: 3.393592789616734

Epoch: 6| Step: 8
Training loss: 3.563786458418014
Validation loss: 3.3894975138286214

Epoch: 6| Step: 9
Training loss: 3.73499960045257
Validation loss: 3.385221825886056

Epoch: 6| Step: 10
Training loss: 3.426543373927755
Validation loss: 3.381159025180022

Epoch: 6| Step: 11
Training loss: 3.5924538306638905
Validation loss: 3.3772912313081265

Epoch: 6| Step: 12
Training loss: 2.8624807698632515
Validation loss: 3.3734254107391917

Epoch: 6| Step: 13
Training loss: 3.647742129597838
Validation loss: 3.369879051777437

Epoch: 35| Step: 0
Training loss: 3.2012402455614364
Validation loss: 3.366217488989944

Epoch: 6| Step: 1
Training loss: 3.0238642428367126
Validation loss: 3.362350660030674

Epoch: 6| Step: 2
Training loss: 3.0326929492372003
Validation loss: 3.358858834762906

Epoch: 6| Step: 3
Training loss: 4.2982060260909565
Validation loss: 3.3555249175054747

Epoch: 6| Step: 4
Training loss: 3.4514714074882593
Validation loss: 3.351670542815433

Epoch: 6| Step: 5
Training loss: 3.456444021232171
Validation loss: 3.3481140417200117

Epoch: 6| Step: 6
Training loss: 4.003200680972498
Validation loss: 3.3447441215703937

Epoch: 6| Step: 7
Training loss: 3.896763994705367
Validation loss: 3.3411921524956143

Epoch: 6| Step: 8
Training loss: 3.4700139122939655
Validation loss: 3.3372880046822884

Epoch: 6| Step: 9
Training loss: 3.1155349825574197
Validation loss: 3.3338067115982364

Epoch: 6| Step: 10
Training loss: 3.1430891248620636
Validation loss: 3.329865443801757

Epoch: 6| Step: 11
Training loss: 3.14377447463836
Validation loss: 3.3263682473395475

Epoch: 6| Step: 12
Training loss: 3.4949418711705817
Validation loss: 3.322495596265398

Epoch: 6| Step: 13
Training loss: 3.722161147026167
Validation loss: 3.3187345697172357

Epoch: 36| Step: 0
Training loss: 3.370960502599075
Validation loss: 3.315225044118396

Epoch: 6| Step: 1
Training loss: 4.181152543327757
Validation loss: 3.3114170847472972

Epoch: 6| Step: 2
Training loss: 3.2412246193500773
Validation loss: 3.3072504396447195

Epoch: 6| Step: 3
Training loss: 3.2102480702789142
Validation loss: 3.303433732804772

Epoch: 6| Step: 4
Training loss: 2.7624077483779144
Validation loss: 3.299794210895436

Epoch: 6| Step: 5
Training loss: 3.012276643569209
Validation loss: 3.296071091639061

Epoch: 6| Step: 6
Training loss: 3.102315124364283
Validation loss: 3.2925796007340202

Epoch: 6| Step: 7
Training loss: 3.8508879591245533
Validation loss: 3.288881515875562

Epoch: 6| Step: 8
Training loss: 2.4505496751396714
Validation loss: 3.285562448567101

Epoch: 6| Step: 9
Training loss: 4.013480122016221
Validation loss: 3.2827152795208323

Epoch: 6| Step: 10
Training loss: 4.141709441201412
Validation loss: 3.2791171574682334

Epoch: 6| Step: 11
Training loss: 3.0964677991407763
Validation loss: 3.274926999178784

Epoch: 6| Step: 12
Training loss: 3.547752507089876
Validation loss: 3.271541996538568

Epoch: 6| Step: 13
Training loss: 3.553608556637001
Validation loss: 3.2679453124937745

Epoch: 37| Step: 0
Training loss: 2.861326458510607
Validation loss: 3.2642276092156357

Epoch: 6| Step: 1
Training loss: 3.5988136774003117
Validation loss: 3.2608945859879768

Epoch: 6| Step: 2
Training loss: 3.823797777519017
Validation loss: 3.257194551915734

Epoch: 6| Step: 3
Training loss: 3.6521795062502096
Validation loss: 3.253943630460215

Epoch: 6| Step: 4
Training loss: 3.388893634674696
Validation loss: 3.250241564062887

Epoch: 6| Step: 5
Training loss: 3.2747996552900145
Validation loss: 3.246881602834059

Epoch: 6| Step: 6
Training loss: 4.145482621942015
Validation loss: 3.2434363843837093

Epoch: 6| Step: 7
Training loss: 3.902683919107585
Validation loss: 3.2396553783848736

Epoch: 6| Step: 8
Training loss: 3.3803600557404105
Validation loss: 3.235719066733833

Epoch: 6| Step: 9
Training loss: 2.8833572989406795
Validation loss: 3.2319996537878777

Epoch: 6| Step: 10
Training loss: 2.6031122946915706
Validation loss: 3.2287286563905764

Epoch: 6| Step: 11
Training loss: 3.1610662897020405
Validation loss: 3.224992346939351

Epoch: 6| Step: 12
Training loss: 3.274938708015734
Validation loss: 3.2216408842751982

Epoch: 6| Step: 13
Training loss: 3.045682546603079
Validation loss: 3.2182171328043307

Epoch: 38| Step: 0
Training loss: 3.2698547130354814
Validation loss: 3.2147278577480725

Epoch: 6| Step: 1
Training loss: 3.794677852180743
Validation loss: 3.2115284297856137

Epoch: 6| Step: 2
Training loss: 3.6015456855033876
Validation loss: 3.207973278368788

Epoch: 6| Step: 3
Training loss: 3.5459535721064745
Validation loss: 3.204624191147383

Epoch: 6| Step: 4
Training loss: 3.4634017265941575
Validation loss: 3.2014128412181364

Epoch: 6| Step: 5
Training loss: 2.7815568733222706
Validation loss: 3.1978193551995986

Epoch: 6| Step: 6
Training loss: 3.2409296376312553
Validation loss: 3.1943265331086725

Epoch: 6| Step: 7
Training loss: 3.268406901396413
Validation loss: 3.1908693145957536

Epoch: 6| Step: 8
Training loss: 2.923351220917501
Validation loss: 3.1875204197846623

Epoch: 6| Step: 9
Training loss: 3.216858094865616
Validation loss: 3.1844166571700376

Epoch: 6| Step: 10
Training loss: 3.3534246220180113
Validation loss: 3.1811449864210455

Epoch: 6| Step: 11
Training loss: 2.7525172416846884
Validation loss: 3.1780777839246563

Epoch: 6| Step: 12
Training loss: 3.9549643116340287
Validation loss: 3.174959884350078

Epoch: 6| Step: 13
Training loss: 3.286816045011512
Validation loss: 3.171776931324027

Epoch: 39| Step: 0
Training loss: 3.343615662915513
Validation loss: 3.168306896320823

Epoch: 6| Step: 1
Training loss: 3.0519114023850387
Validation loss: 3.165322060131362

Epoch: 6| Step: 2
Training loss: 3.5439247263197213
Validation loss: 3.1621935187036616

Epoch: 6| Step: 3
Training loss: 3.428137635422461
Validation loss: 3.1589272981476966

Epoch: 6| Step: 4
Training loss: 3.561966705560769
Validation loss: 3.1556181951993314

Epoch: 6| Step: 5
Training loss: 3.6389140418609416
Validation loss: 3.152355851122994

Epoch: 6| Step: 6
Training loss: 3.7344181585012604
Validation loss: 3.149161458296724

Epoch: 6| Step: 7
Training loss: 3.092701435606063
Validation loss: 3.1457113448652643

Epoch: 6| Step: 8
Training loss: 3.132378070038358
Validation loss: 3.142526990096328

Epoch: 6| Step: 9
Training loss: 3.472779416623791
Validation loss: 3.139202978985572

Epoch: 6| Step: 10
Training loss: 2.707831370468995
Validation loss: 3.136183880356942

Epoch: 6| Step: 11
Training loss: 2.8367616070803825
Validation loss: 3.132923634778375

Epoch: 6| Step: 12
Training loss: 3.2640775819889263
Validation loss: 3.1300717333007104

Epoch: 6| Step: 13
Training loss: 3.070042877394869
Validation loss: 3.1270695763339775

Epoch: 40| Step: 0
Training loss: 2.6352510563578946
Validation loss: 3.1240772410818924

Epoch: 6| Step: 1
Training loss: 3.6908145813857844
Validation loss: 3.120989604003306

Epoch: 6| Step: 2
Training loss: 3.142434732735035
Validation loss: 3.117828762091944

Epoch: 6| Step: 3
Training loss: 3.6086255901523425
Validation loss: 3.1147766478561296

Epoch: 6| Step: 4
Training loss: 3.263369132427777
Validation loss: 3.1117678944311806

Epoch: 6| Step: 5
Training loss: 3.0219287508550132
Validation loss: 3.1086262579406396

Epoch: 6| Step: 6
Training loss: 3.202031390815992
Validation loss: 3.1052980771938588

Epoch: 6| Step: 7
Training loss: 2.9848827309632346
Validation loss: 3.1023385000396604

Epoch: 6| Step: 8
Training loss: 3.1621081686223764
Validation loss: 3.0992798496868605

Epoch: 6| Step: 9
Training loss: 3.305812058171583
Validation loss: 3.0963411622326436

Epoch: 6| Step: 10
Training loss: 3.0014655983736036
Validation loss: 3.0931635856367103

Epoch: 6| Step: 11
Training loss: 3.968901864097415
Validation loss: 3.090126072925816

Epoch: 6| Step: 12
Training loss: 3.4046499711551004
Validation loss: 3.087151178482971

Epoch: 6| Step: 13
Training loss: 2.8277449378817425
Validation loss: 3.0843327595073853

Epoch: 41| Step: 0
Training loss: 3.3698869757560295
Validation loss: 3.08153459989769

Epoch: 6| Step: 1
Training loss: 2.203876015646091
Validation loss: 3.078619024970686

Epoch: 6| Step: 2
Training loss: 3.5559302536568502
Validation loss: 3.075768551498683

Epoch: 6| Step: 3
Training loss: 3.59863347502538
Validation loss: 3.072983800294819

Epoch: 6| Step: 4
Training loss: 2.8788406592341587
Validation loss: 3.0700916084637835

Epoch: 6| Step: 5
Training loss: 3.6515780865226826
Validation loss: 3.0669203665392746

Epoch: 6| Step: 6
Training loss: 3.0801906722363053
Validation loss: 3.06389741739804

Epoch: 6| Step: 7
Training loss: 2.7610966738556457
Validation loss: 3.0609570723137174

Epoch: 6| Step: 8
Training loss: 3.1985640641941044
Validation loss: 3.0583614295237127

Epoch: 6| Step: 9
Training loss: 2.8214391428799415
Validation loss: 3.0555706779992007

Epoch: 6| Step: 10
Training loss: 3.1050549117437276
Validation loss: 3.052968809205673

Epoch: 6| Step: 11
Training loss: 3.2120010582244003
Validation loss: 3.050567645525228

Epoch: 6| Step: 12
Training loss: 3.4196870680743126
Validation loss: 3.0477555396425737

Epoch: 6| Step: 13
Training loss: 3.680955154191364
Validation loss: 3.0453281616831203

Epoch: 42| Step: 0
Training loss: 3.5943210313990894
Validation loss: 3.0424440426932287

Epoch: 6| Step: 1
Training loss: 3.1132363731375836
Validation loss: 3.0395513695406056

Epoch: 6| Step: 2
Training loss: 2.9171062864779005
Validation loss: 3.0369253481014646

Epoch: 6| Step: 3
Training loss: 3.118829204035205
Validation loss: 3.0339870876723984

Epoch: 6| Step: 4
Training loss: 2.8933551164618656
Validation loss: 3.0312731896001734

Epoch: 6| Step: 5
Training loss: 3.6491601787775743
Validation loss: 3.0285492890119405

Epoch: 6| Step: 6
Training loss: 2.9294137241871545
Validation loss: 3.02569740074826

Epoch: 6| Step: 7
Training loss: 3.2098934954506246
Validation loss: 3.022959169439116

Epoch: 6| Step: 8
Training loss: 3.503362539032325
Validation loss: 3.0202610438411

Epoch: 6| Step: 9
Training loss: 2.8082383823662163
Validation loss: 3.0176526435942823

Epoch: 6| Step: 10
Training loss: 3.1677113533110157
Validation loss: 3.015028451476383

Epoch: 6| Step: 11
Training loss: 2.977890559412466
Validation loss: 3.01249482298178

Epoch: 6| Step: 12
Training loss: 2.9983147020027925
Validation loss: 3.0098222103819214

Epoch: 6| Step: 13
Training loss: 3.327659466918302
Validation loss: 3.0071316431481714

Epoch: 43| Step: 0
Training loss: 2.548588088852937
Validation loss: 3.0046714598461803

Epoch: 6| Step: 1
Training loss: 3.0559405710423553
Validation loss: 3.0022944709465262

Epoch: 6| Step: 2
Training loss: 3.4878688111350984
Validation loss: 3.000031325388652

Epoch: 6| Step: 3
Training loss: 3.435984190605839
Validation loss: 2.9976714156947537

Epoch: 6| Step: 4
Training loss: 2.981887499707708
Validation loss: 2.9951992299381853

Epoch: 6| Step: 5
Training loss: 3.514458899489532
Validation loss: 2.992869818092989

Epoch: 6| Step: 6
Training loss: 3.1791364862518523
Validation loss: 2.9904752767587213

Epoch: 6| Step: 7
Training loss: 3.381753451789679
Validation loss: 2.9883063421255556

Epoch: 6| Step: 8
Training loss: 2.76466689243443
Validation loss: 2.9856698654005482

Epoch: 6| Step: 9
Training loss: 3.455218892871514
Validation loss: 2.9833888609920294

Epoch: 6| Step: 10
Training loss: 2.511739632859339
Validation loss: 2.9807698308977226

Epoch: 6| Step: 11
Training loss: 2.8405884995334403
Validation loss: 2.978134661215515

Epoch: 6| Step: 12
Training loss: 3.3953495422112208
Validation loss: 2.9757990087365

Epoch: 6| Step: 13
Training loss: 3.0257115055381756
Validation loss: 2.9731072423347293

Epoch: 44| Step: 0
Training loss: 2.7078384142833656
Validation loss: 2.9705406142842525

Epoch: 6| Step: 1
Training loss: 3.1682222126178887
Validation loss: 2.9682686532620375

Epoch: 6| Step: 2
Training loss: 3.0208383669756462
Validation loss: 2.9659759678260373

Epoch: 6| Step: 3
Training loss: 3.118473409187353
Validation loss: 2.9637469649088173

Epoch: 6| Step: 4
Training loss: 3.1563627015189555
Validation loss: 2.9613155234395427

Epoch: 6| Step: 5
Training loss: 3.1154394769864533
Validation loss: 2.959019048674389

Epoch: 6| Step: 6
Training loss: 3.3403872399074666
Validation loss: 2.956664680392843

Epoch: 6| Step: 7
Training loss: 2.2780601460836816
Validation loss: 2.954116183998767

Epoch: 6| Step: 8
Training loss: 3.1567113558040596
Validation loss: 2.9516493997727564

Epoch: 6| Step: 9
Training loss: 2.858786600576671
Validation loss: 2.9493024060508684

Epoch: 6| Step: 10
Training loss: 3.5056971095369773
Validation loss: 2.9470029612348227

Epoch: 6| Step: 11
Training loss: 2.8393025256376405
Validation loss: 2.9445953710329857

Epoch: 6| Step: 12
Training loss: 3.2179853401395455
Validation loss: 2.942358719754222

Epoch: 6| Step: 13
Training loss: 3.637437202462122
Validation loss: 2.939931917959278

Epoch: 45| Step: 0
Training loss: 3.0691956485895924
Validation loss: 2.9376164406498515

Epoch: 6| Step: 1
Training loss: 3.4364944374398
Validation loss: 2.935224977781336

Epoch: 6| Step: 2
Training loss: 2.878728025139681
Validation loss: 2.9327691718728346

Epoch: 6| Step: 3
Training loss: 2.9835060012831183
Validation loss: 2.9304607676342496

Epoch: 6| Step: 4
Training loss: 2.999349364616091
Validation loss: 2.9280075749940284

Epoch: 6| Step: 5
Training loss: 2.666355969289971
Validation loss: 2.9255750080073164

Epoch: 6| Step: 6
Training loss: 3.0952788919687646
Validation loss: 2.923523816768442

Epoch: 6| Step: 7
Training loss: 2.914062172733728
Validation loss: 2.9213436956020185

Epoch: 6| Step: 8
Training loss: 3.4175341520577316
Validation loss: 2.919065978150221

Epoch: 6| Step: 9
Training loss: 2.665443398124589
Validation loss: 2.9166648365196663

Epoch: 6| Step: 10
Training loss: 3.193693538995329
Validation loss: 2.9143985148891103

Epoch: 6| Step: 11
Training loss: 3.312203160067264
Validation loss: 2.912163928156513

Epoch: 6| Step: 12
Training loss: 2.8866189776821
Validation loss: 2.9098679094606044

Epoch: 6| Step: 13
Training loss: 3.272737633081857
Validation loss: 2.90779596317542

Epoch: 46| Step: 0
Training loss: 3.1283173310472305
Validation loss: 2.9057044197355673

Epoch: 6| Step: 1
Training loss: 2.915205907599601
Validation loss: 2.9037088475709814

Epoch: 6| Step: 2
Training loss: 2.8684591440925433
Validation loss: 2.901704083646417

Epoch: 6| Step: 3
Training loss: 3.431566979058211
Validation loss: 2.8998054778970124

Epoch: 6| Step: 4
Training loss: 3.136050408444775
Validation loss: 2.897596033176345

Epoch: 6| Step: 5
Training loss: 2.610080007006462
Validation loss: 2.8954924421669053

Epoch: 6| Step: 6
Training loss: 3.209450630403749
Validation loss: 2.893776929605082

Epoch: 6| Step: 7
Training loss: 3.578579802947937
Validation loss: 2.8913292654089635

Epoch: 6| Step: 8
Training loss: 3.123831263382349
Validation loss: 2.889207399570961

Epoch: 6| Step: 9
Training loss: 2.831718395973844
Validation loss: 2.8870199869651247

Epoch: 6| Step: 10
Training loss: 3.2960293666123923
Validation loss: 2.884964743431273

Epoch: 6| Step: 11
Training loss: 2.935764205715033
Validation loss: 2.8825811139902577

Epoch: 6| Step: 12
Training loss: 2.631203904280487
Validation loss: 2.8799823628653787

Epoch: 6| Step: 13
Training loss: 2.59691794092548
Validation loss: 2.8781443277345824

Epoch: 47| Step: 0
Training loss: 3.128634970878811
Validation loss: 2.876154018382762

Epoch: 6| Step: 1
Training loss: 2.9379809371402517
Validation loss: 2.874539822224568

Epoch: 6| Step: 2
Training loss: 2.934576324609066
Validation loss: 2.87206285517439

Epoch: 6| Step: 3
Training loss: 3.173645878180994
Validation loss: 2.8702182118159842

Epoch: 6| Step: 4
Training loss: 2.652453053712438
Validation loss: 2.868228484311198

Epoch: 6| Step: 5
Training loss: 2.833357717371713
Validation loss: 2.865647362275474

Epoch: 6| Step: 6
Training loss: 2.8756063070769584
Validation loss: 2.864306409917559

Epoch: 6| Step: 7
Training loss: 2.4390150399145143
Validation loss: 2.8634599783411754

Epoch: 6| Step: 8
Training loss: 2.937945393012644
Validation loss: 2.8680180620806732

Epoch: 6| Step: 9
Training loss: 2.745565393444745
Validation loss: 2.858696528753246

Epoch: 6| Step: 10
Training loss: 2.8022731069142535
Validation loss: 2.857928718051694

Epoch: 6| Step: 11
Training loss: 3.63544695093754
Validation loss: 2.8571943573624483

Epoch: 6| Step: 12
Training loss: 3.4448601735034523
Validation loss: 2.8562106218134673

Epoch: 6| Step: 13
Training loss: 3.331025914426083
Validation loss: 2.8550333438224453

Epoch: 48| Step: 0
Training loss: 2.9391963200217495
Validation loss: 2.853540913467399

Epoch: 6| Step: 1
Training loss: 3.244631955710098
Validation loss: 2.8527589282492647

Epoch: 6| Step: 2
Training loss: 3.2091332631505316
Validation loss: 2.849897760933226

Epoch: 6| Step: 3
Training loss: 2.5479646001898852
Validation loss: 2.8477226427499076

Epoch: 6| Step: 4
Training loss: 2.5807664690808676
Validation loss: 2.8454618925551327

Epoch: 6| Step: 5
Training loss: 2.2863116611948335
Validation loss: 2.84309203532344

Epoch: 6| Step: 6
Training loss: 3.1890261119540257
Validation loss: 2.841689904156162

Epoch: 6| Step: 7
Training loss: 3.751966088196632
Validation loss: 2.8388506006701753

Epoch: 6| Step: 8
Training loss: 2.5474744220082237
Validation loss: 2.8364626115441443

Epoch: 6| Step: 9
Training loss: 2.786868303508631
Validation loss: 2.8352662860606785

Epoch: 6| Step: 10
Training loss: 2.9263845313237455
Validation loss: 2.8329555081914384

Epoch: 6| Step: 11
Training loss: 3.6498247078386132
Validation loss: 2.8310771448675225

Epoch: 6| Step: 12
Training loss: 2.7598274801764173
Validation loss: 2.8289241750522023

Epoch: 6| Step: 13
Training loss: 2.9466698551879937
Validation loss: 2.827093045005525

Epoch: 49| Step: 0
Training loss: 2.8347533725254537
Validation loss: 2.8253413739617312

Epoch: 6| Step: 1
Training loss: 3.224693070821001
Validation loss: 2.822856118842035

Epoch: 6| Step: 2
Training loss: 3.075237023127337
Validation loss: 2.8212419072188495

Epoch: 6| Step: 3
Training loss: 2.759456241919432
Validation loss: 2.819266113713292

Epoch: 6| Step: 4
Training loss: 2.982725316607457
Validation loss: 2.8178685272615818

Epoch: 6| Step: 5
Training loss: 2.748544307713158
Validation loss: 2.8154946173181363

Epoch: 6| Step: 6
Training loss: 2.8856681594777207
Validation loss: 2.8134864348821282

Epoch: 6| Step: 7
Training loss: 3.3669025628063016
Validation loss: 2.811715292073906

Epoch: 6| Step: 8
Training loss: 2.7067390052950513
Validation loss: 2.8104626375873014

Epoch: 6| Step: 9
Training loss: 2.9168903446713443
Validation loss: 2.809101835159275

Epoch: 6| Step: 10
Training loss: 3.2231749700904206
Validation loss: 2.807681639885207

Epoch: 6| Step: 11
Training loss: 2.381666264232533
Validation loss: 2.8055336188622233

Epoch: 6| Step: 12
Training loss: 2.758005281361702
Validation loss: 2.8031501488211323

Epoch: 6| Step: 13
Training loss: 3.352688829080855
Validation loss: 2.802407318066367

Epoch: 50| Step: 0
Training loss: 2.986552298036358
Validation loss: 2.8017713427424695

Epoch: 6| Step: 1
Training loss: 2.3643567373007572
Validation loss: 2.79859108729702

Epoch: 6| Step: 2
Training loss: 3.012545579747492
Validation loss: 2.7960656982447243

Epoch: 6| Step: 3
Training loss: 3.032470614675372
Validation loss: 2.7949267870959593

Epoch: 6| Step: 4
Training loss: 2.4910646976628077
Validation loss: 2.79302644114277

Epoch: 6| Step: 5
Training loss: 3.2123384783916933
Validation loss: 2.791676369455661

Epoch: 6| Step: 6
Training loss: 2.963333489067952
Validation loss: 2.7892109664880476

Epoch: 6| Step: 7
Training loss: 3.20423207573834
Validation loss: 2.787960386817602

Epoch: 6| Step: 8
Training loss: 2.616679674671018
Validation loss: 2.7865071562770907

Epoch: 6| Step: 9
Training loss: 3.0053656595833282
Validation loss: 2.7857785878311465

Epoch: 6| Step: 10
Training loss: 3.1294510232579476
Validation loss: 2.781877596906874

Epoch: 6| Step: 11
Training loss: 2.602574790151107
Validation loss: 2.78082793672987

Epoch: 6| Step: 12
Training loss: 2.7884537916809458
Validation loss: 2.779938334940613

Epoch: 6| Step: 13
Training loss: 3.453678828916798
Validation loss: 2.778441808063155

Epoch: 51| Step: 0
Training loss: 2.7870944904232013
Validation loss: 2.7777983574634724

Epoch: 6| Step: 1
Training loss: 3.797767565645114
Validation loss: 2.776229613468457

Epoch: 6| Step: 2
Training loss: 3.1456149869684045
Validation loss: 2.7747775713239924

Epoch: 6| Step: 3
Training loss: 3.456582664221935
Validation loss: 2.773560570506993

Epoch: 6| Step: 4
Training loss: 2.903322776077411
Validation loss: 2.770996982837596

Epoch: 6| Step: 5
Training loss: 2.6293379045231347
Validation loss: 2.769884382008612

Epoch: 6| Step: 6
Training loss: 2.7824372747022688
Validation loss: 2.7675541760277316

Epoch: 6| Step: 7
Training loss: 2.6249740235996155
Validation loss: 2.766590919568414

Epoch: 6| Step: 8
Training loss: 3.001031698210152
Validation loss: 2.764939735128345

Epoch: 6| Step: 9
Training loss: 2.8492623026944472
Validation loss: 2.763838239319662

Epoch: 6| Step: 10
Training loss: 2.252349686259195
Validation loss: 2.7625415660786237

Epoch: 6| Step: 11
Training loss: 2.662196425919895
Validation loss: 2.7604217145381815

Epoch: 6| Step: 12
Training loss: 3.0404949979836626
Validation loss: 2.7580546560047057

Epoch: 6| Step: 13
Training loss: 2.4392148368031394
Validation loss: 2.758488429070316

Epoch: 52| Step: 0
Training loss: 2.769495265710782
Validation loss: 2.7561709351563555

Epoch: 6| Step: 1
Training loss: 3.0866234898139253
Validation loss: 2.7550810776703747

Epoch: 6| Step: 2
Training loss: 3.1973604760289187
Validation loss: 2.754392973181398

Epoch: 6| Step: 3
Training loss: 2.8491866574102596
Validation loss: 2.751686316092112

Epoch: 6| Step: 4
Training loss: 3.0099978744144473
Validation loss: 2.7495519244122786

Epoch: 6| Step: 5
Training loss: 3.145827506019972
Validation loss: 2.7476658741125597

Epoch: 6| Step: 6
Training loss: 2.4203996656173956
Validation loss: 2.7466567264148627

Epoch: 6| Step: 7
Training loss: 2.5608007798348322
Validation loss: 2.743683004176841

Epoch: 6| Step: 8
Training loss: 2.769152530661254
Validation loss: 2.7430202165304354

Epoch: 6| Step: 9
Training loss: 3.132441700897478
Validation loss: 2.7408032523530634

Epoch: 6| Step: 10
Training loss: 3.0227655654744976
Validation loss: 2.7382368736281015

Epoch: 6| Step: 11
Training loss: 2.675904386708202
Validation loss: 2.736050700850983

Epoch: 6| Step: 12
Training loss: 2.9007751415464735
Validation loss: 2.7348837969477633

Epoch: 6| Step: 13
Training loss: 2.7714548680654856
Validation loss: 2.7331077763680396

Epoch: 53| Step: 0
Training loss: 2.845881072314651
Validation loss: 2.7328752164803536

Epoch: 6| Step: 1
Training loss: 2.5107516834223382
Validation loss: 2.731288017514656

Epoch: 6| Step: 2
Training loss: 3.2014679879442856
Validation loss: 2.7313944966773454

Epoch: 6| Step: 3
Training loss: 2.7746208138050847
Validation loss: 2.7270829688631246

Epoch: 6| Step: 4
Training loss: 2.339561993124275
Validation loss: 2.728080814989842

Epoch: 6| Step: 5
Training loss: 3.5068008561319632
Validation loss: 2.7307820283666353

Epoch: 6| Step: 6
Training loss: 3.292805406313537
Validation loss: 2.724549783034466

Epoch: 6| Step: 7
Training loss: 2.235859411170245
Validation loss: 2.725340619511703

Epoch: 6| Step: 8
Training loss: 3.1061663917633764
Validation loss: 2.727042257078777

Epoch: 6| Step: 9
Training loss: 3.1419451771402356
Validation loss: 2.7264671418312068

Epoch: 6| Step: 10
Training loss: 2.2340261547159277
Validation loss: 2.7277851223657907

Epoch: 6| Step: 11
Training loss: 3.2833668011607164
Validation loss: 2.729527141458695

Epoch: 6| Step: 12
Training loss: 2.8153214607515364
Validation loss: 2.726892329308191

Epoch: 6| Step: 13
Training loss: 2.4727245158674815
Validation loss: 2.724511950356447

Epoch: 54| Step: 0
Training loss: 3.4696953662314853
Validation loss: 2.722393006743608

Epoch: 6| Step: 1
Training loss: 3.0017011905303708
Validation loss: 2.721306194752615

Epoch: 6| Step: 2
Training loss: 2.818554274705898
Validation loss: 2.7181274899871664

Epoch: 6| Step: 3
Training loss: 2.5881074864914906
Validation loss: 2.7157812315757943

Epoch: 6| Step: 4
Training loss: 2.385522720666871
Validation loss: 2.7123392605363037

Epoch: 6| Step: 5
Training loss: 2.591851148346121
Validation loss: 2.710615287342926

Epoch: 6| Step: 6
Training loss: 2.9427258696357095
Validation loss: 2.7088481169309553

Epoch: 6| Step: 7
Training loss: 3.207905844079589
Validation loss: 2.707414373357072

Epoch: 6| Step: 8
Training loss: 3.1866699334717077
Validation loss: 2.7060018383065927

Epoch: 6| Step: 9
Training loss: 2.4005421900252677
Validation loss: 2.7032917831213044

Epoch: 6| Step: 10
Training loss: 2.5358428730588303
Validation loss: 2.7008874706228108

Epoch: 6| Step: 11
Training loss: 3.1197065151781067
Validation loss: 2.6980792012590142

Epoch: 6| Step: 12
Training loss: 3.0476154699191027
Validation loss: 2.698533776794301

Epoch: 6| Step: 13
Training loss: 2.3882979492562035
Validation loss: 2.700150825267377

Epoch: 55| Step: 0
Training loss: 2.7259800679631936
Validation loss: 2.6988556797573464

Epoch: 6| Step: 1
Training loss: 2.6623946979456155
Validation loss: 2.694178953778934

Epoch: 6| Step: 2
Training loss: 3.1568622561816655
Validation loss: 2.694397937945727

Epoch: 6| Step: 3
Training loss: 2.8378360162824876
Validation loss: 2.692997241185349

Epoch: 6| Step: 4
Training loss: 2.7299940490657795
Validation loss: 2.6916988160267388

Epoch: 6| Step: 5
Training loss: 2.716711398109427
Validation loss: 2.6928067118654186

Epoch: 6| Step: 6
Training loss: 2.7071615080437192
Validation loss: 2.692167155166242

Epoch: 6| Step: 7
Training loss: 2.561549126586777
Validation loss: 2.6898779735517135

Epoch: 6| Step: 8
Training loss: 2.8010359346372025
Validation loss: 2.6853717834730872

Epoch: 6| Step: 9
Training loss: 2.5868352616643353
Validation loss: 2.685664992075753

Epoch: 6| Step: 10
Training loss: 3.3112962082907242
Validation loss: 2.684134216523006

Epoch: 6| Step: 11
Training loss: 2.8251866203039895
Validation loss: 2.6859302815800237

Epoch: 6| Step: 12
Training loss: 3.130834092712175
Validation loss: 2.681182800019947

Epoch: 6| Step: 13
Training loss: 2.7908811650278356
Validation loss: 2.6800865417475817

Epoch: 56| Step: 0
Training loss: 2.5999048582422435
Validation loss: 2.6814870473176735

Epoch: 6| Step: 1
Training loss: 3.0514784247110533
Validation loss: 2.6814623590772615

Epoch: 6| Step: 2
Training loss: 2.8266521855049347
Validation loss: 2.681756061793072

Epoch: 6| Step: 3
Training loss: 2.6582669846756186
Validation loss: 2.6813382031235116

Epoch: 6| Step: 4
Training loss: 3.058267276338108
Validation loss: 2.6781712756912435

Epoch: 6| Step: 5
Training loss: 2.349617797126167
Validation loss: 2.6759653441128997

Epoch: 6| Step: 6
Training loss: 2.611608040871192
Validation loss: 2.6749813322800353

Epoch: 6| Step: 7
Training loss: 2.5464838581813214
Validation loss: 2.6734575637608504

Epoch: 6| Step: 8
Training loss: 2.5021887734520556
Validation loss: 2.6719553379525456

Epoch: 6| Step: 9
Training loss: 2.9906502303092597
Validation loss: 2.671748331201674

Epoch: 6| Step: 10
Training loss: 2.972974000808763
Validation loss: 2.6706683016140538

Epoch: 6| Step: 11
Training loss: 2.8913278086179033
Validation loss: 2.6699651395115

Epoch: 6| Step: 12
Training loss: 2.8331401048481046
Validation loss: 2.670951906885952

Epoch: 6| Step: 13
Training loss: 3.392959564498705
Validation loss: 2.668666750155138

Epoch: 57| Step: 0
Training loss: 2.105693401744052
Validation loss: 2.6659397286777784

Epoch: 6| Step: 1
Training loss: 2.666114441993058
Validation loss: 2.664591836406233

Epoch: 6| Step: 2
Training loss: 3.434815763283055
Validation loss: 2.6639742421794175

Epoch: 6| Step: 3
Training loss: 2.594922823190121
Validation loss: 2.6631610646671082

Epoch: 6| Step: 4
Training loss: 2.9346445693080017
Validation loss: 2.6613352250045956

Epoch: 6| Step: 5
Training loss: 3.045752998541576
Validation loss: 2.6608959556886136

Epoch: 6| Step: 6
Training loss: 2.4214688852734434
Validation loss: 2.6585572189315787

Epoch: 6| Step: 7
Training loss: 2.6857107549429644
Validation loss: 2.65770235934185

Epoch: 6| Step: 8
Training loss: 3.3727098394876713
Validation loss: 2.6548001390270226

Epoch: 6| Step: 9
Training loss: 2.7575230433036433
Validation loss: 2.6545525157095446

Epoch: 6| Step: 10
Training loss: 2.9934455477857944
Validation loss: 2.655291470383055

Epoch: 6| Step: 11
Training loss: 2.2085288579021385
Validation loss: 2.6543439721052327

Epoch: 6| Step: 12
Training loss: 3.002629081752838
Validation loss: 2.654474405466731

Epoch: 6| Step: 13
Training loss: 2.6346272629475975
Validation loss: 2.654709462746127

Epoch: 58| Step: 0
Training loss: 2.5110401524258283
Validation loss: 2.6553082460921047

Epoch: 6| Step: 1
Training loss: 2.8193383898986997
Validation loss: 2.6543113665060014

Epoch: 6| Step: 2
Training loss: 3.128767565298057
Validation loss: 2.654533834128125

Epoch: 6| Step: 3
Training loss: 2.8889904452674604
Validation loss: 2.652587564804542

Epoch: 6| Step: 4
Training loss: 3.3312452133745514
Validation loss: 2.6513942991103487

Epoch: 6| Step: 5
Training loss: 2.9921511655349415
Validation loss: 2.6500099937682373

Epoch: 6| Step: 6
Training loss: 2.48805262115617
Validation loss: 2.6499537775818873

Epoch: 6| Step: 7
Training loss: 2.675214944207508
Validation loss: 2.647676731847216

Epoch: 6| Step: 8
Training loss: 2.5076554388852745
Validation loss: 2.6467475563182883

Epoch: 6| Step: 9
Training loss: 2.502154852114709
Validation loss: 2.6455725193383235

Epoch: 6| Step: 10
Training loss: 3.242734564162365
Validation loss: 2.643557783974529

Epoch: 6| Step: 11
Training loss: 2.6264132373886393
Validation loss: 2.6403890049080223

Epoch: 6| Step: 12
Training loss: 2.667461833019403
Validation loss: 2.639489164732555

Epoch: 6| Step: 13
Training loss: 2.4589984338917503
Validation loss: 2.6357888171328026

Epoch: 59| Step: 0
Training loss: 2.1681730706787463
Validation loss: 2.6334185256536995

Epoch: 6| Step: 1
Training loss: 3.0156743337123983
Validation loss: 2.6335851062054547

Epoch: 6| Step: 2
Training loss: 3.0434726596567487
Validation loss: 2.642851408224377

Epoch: 6| Step: 3
Training loss: 2.700086881864489
Validation loss: 2.654396262985298

Epoch: 6| Step: 4
Training loss: 2.4075774457443897
Validation loss: 2.632557699097062

Epoch: 6| Step: 5
Training loss: 2.8532322005890998
Validation loss: 2.6330342260735122

Epoch: 6| Step: 6
Training loss: 2.6023045303563874
Validation loss: 2.633356477740341

Epoch: 6| Step: 7
Training loss: 3.188082922198078
Validation loss: 2.6345146555478154

Epoch: 6| Step: 8
Training loss: 2.7491567359167566
Validation loss: 2.6249098383844776

Epoch: 6| Step: 9
Training loss: 2.9145355249773472
Validation loss: 2.6262593351764405

Epoch: 6| Step: 10
Training loss: 2.611096299808059
Validation loss: 2.628150774708024

Epoch: 6| Step: 11
Training loss: 2.3726913876611815
Validation loss: 2.630137018930263

Epoch: 6| Step: 12
Training loss: 2.86718051504173
Validation loss: 2.6316682043749533

Epoch: 6| Step: 13
Training loss: 3.1796791020312933
Validation loss: 2.6357592082407466

Epoch: 60| Step: 0
Training loss: 2.7048354718276273
Validation loss: 2.639092190479301

Epoch: 6| Step: 1
Training loss: 2.1562444714461506
Validation loss: 2.642504608116595

Epoch: 6| Step: 2
Training loss: 3.053647696069241
Validation loss: 2.6443658398540433

Epoch: 6| Step: 3
Training loss: 2.452075126156702
Validation loss: 2.6426704505267162

Epoch: 6| Step: 4
Training loss: 2.907960449915281
Validation loss: 2.64222946930738

Epoch: 6| Step: 5
Training loss: 3.0661487252530812
Validation loss: 2.6366345201390153

Epoch: 6| Step: 6
Training loss: 2.1354419861819887
Validation loss: 2.6334619824656746

Epoch: 6| Step: 7
Training loss: 2.8267951494232793
Validation loss: 2.629147613464413

Epoch: 6| Step: 8
Training loss: 2.5734891885130495
Validation loss: 2.628749984472749

Epoch: 6| Step: 9
Training loss: 2.5555754352109648
Validation loss: 2.6252958494316117

Epoch: 6| Step: 10
Training loss: 3.137485130244426
Validation loss: 2.6231282085004914

Epoch: 6| Step: 11
Training loss: 3.4084875474534186
Validation loss: 2.6218173851621143

Epoch: 6| Step: 12
Training loss: 2.704807970349027
Validation loss: 2.620683041879089

Epoch: 6| Step: 13
Training loss: 2.796216578209241
Validation loss: 2.61420093389477

Epoch: 61| Step: 0
Training loss: 3.0984147479308373
Validation loss: 2.6086444403106657

Epoch: 6| Step: 1
Training loss: 2.9563947065555554
Validation loss: 2.6086553315948873

Epoch: 6| Step: 2
Training loss: 3.0831363374481136
Validation loss: 2.607805278654559

Epoch: 6| Step: 3
Training loss: 2.2492833585691754
Validation loss: 2.6060981352521977

Epoch: 6| Step: 4
Training loss: 2.6334914059416366
Validation loss: 2.605697385411282

Epoch: 6| Step: 5
Training loss: 3.1310211158900563
Validation loss: 2.6063056909357516

Epoch: 6| Step: 6
Training loss: 2.687202437140043
Validation loss: 2.6059560248616194

Epoch: 6| Step: 7
Training loss: 2.3658927171363926
Validation loss: 2.5993853557772035

Epoch: 6| Step: 8
Training loss: 2.278674199972243
Validation loss: 2.601888596084336

Epoch: 6| Step: 9
Training loss: 2.5794794397305583
Validation loss: 2.60073294028932

Epoch: 6| Step: 10
Training loss: 2.646889563366167
Validation loss: 2.5968621361907736

Epoch: 6| Step: 11
Training loss: 2.8324444068240817
Validation loss: 2.597592016969982

Epoch: 6| Step: 12
Training loss: 2.7641430348706852
Validation loss: 2.598369024478976

Epoch: 6| Step: 13
Training loss: 2.8922693472831824
Validation loss: 2.59810582145077

Epoch: 62| Step: 0
Training loss: 3.097431958846725
Validation loss: 2.5959567292236256

Epoch: 6| Step: 1
Training loss: 3.1376775318999006
Validation loss: 2.5949832481573685

Epoch: 6| Step: 2
Training loss: 2.767581743172035
Validation loss: 2.597885985959335

Epoch: 6| Step: 3
Training loss: 2.5024614614287826
Validation loss: 2.597786317403742

Epoch: 6| Step: 4
Training loss: 1.8935927121149891
Validation loss: 2.5974804811597916

Epoch: 6| Step: 5
Training loss: 2.489940527240182
Validation loss: 2.5981071673562726

Epoch: 6| Step: 6
Training loss: 2.6760935357515185
Validation loss: 2.5985153575005673

Epoch: 6| Step: 7
Training loss: 2.6647509806737038
Validation loss: 2.601208820301197

Epoch: 6| Step: 8
Training loss: 2.7994543361301902
Validation loss: 2.600135725097876

Epoch: 6| Step: 9
Training loss: 2.668643804576922
Validation loss: 2.6007641396876884

Epoch: 6| Step: 10
Training loss: 2.8760699064329875
Validation loss: 2.598137801812293

Epoch: 6| Step: 11
Training loss: 3.019531881670374
Validation loss: 2.597443413679507

Epoch: 6| Step: 12
Training loss: 2.741223461963729
Validation loss: 2.5955833941330124

Epoch: 6| Step: 13
Training loss: 2.7730255250798073
Validation loss: 2.593288012805645

Epoch: 63| Step: 0
Training loss: 2.9457531505788985
Validation loss: 2.5883289661685858

Epoch: 6| Step: 1
Training loss: 2.167554001184971
Validation loss: 2.5833216995059334

Epoch: 6| Step: 2
Training loss: 2.3899389541682607
Validation loss: 2.583021873238746

Epoch: 6| Step: 3
Training loss: 3.1752887264143004
Validation loss: 2.581404370855876

Epoch: 6| Step: 4
Training loss: 2.9142519810003815
Validation loss: 2.5811833592418614

Epoch: 6| Step: 5
Training loss: 2.7982039890383295
Validation loss: 2.578792015641928

Epoch: 6| Step: 6
Training loss: 2.904107893828427
Validation loss: 2.579358524423638

Epoch: 6| Step: 7
Training loss: 2.4310554014646057
Validation loss: 2.585616815050138

Epoch: 6| Step: 8
Training loss: 2.623030150495826
Validation loss: 2.58031632514785

Epoch: 6| Step: 9
Training loss: 2.7975799695023014
Validation loss: 2.5793835737219775

Epoch: 6| Step: 10
Training loss: 2.8937909908151536
Validation loss: 2.576285351309096

Epoch: 6| Step: 11
Training loss: 2.758980133731741
Validation loss: 2.577097123360237

Epoch: 6| Step: 12
Training loss: 2.806363086078589
Validation loss: 2.5775151465853052

Epoch: 6| Step: 13
Training loss: 2.19133074353263
Validation loss: 2.578714106906757

Epoch: 64| Step: 0
Training loss: 3.115808320463273
Validation loss: 2.5874500288261344

Epoch: 6| Step: 1
Training loss: 2.6173934627737854
Validation loss: 2.582173461383463

Epoch: 6| Step: 2
Training loss: 2.2253654608459645
Validation loss: 2.5767989553475084

Epoch: 6| Step: 3
Training loss: 2.6549526861253034
Validation loss: 2.5712237226039503

Epoch: 6| Step: 4
Training loss: 3.0095346252001023
Validation loss: 2.571658816701594

Epoch: 6| Step: 5
Training loss: 2.6911187758924155
Validation loss: 2.5720013420186514

Epoch: 6| Step: 6
Training loss: 2.7713341702492174
Validation loss: 2.5732502482973842

Epoch: 6| Step: 7
Training loss: 2.8949560762278543
Validation loss: 2.582118092056181

Epoch: 6| Step: 8
Training loss: 2.6521579413296745
Validation loss: 2.594595713792379

Epoch: 6| Step: 9
Training loss: 3.2810000369819843
Validation loss: 2.5973973807317603

Epoch: 6| Step: 10
Training loss: 2.7101106729466125
Validation loss: 2.5858380777813577

Epoch: 6| Step: 11
Training loss: 2.1635754860108283
Validation loss: 2.5692196177733027

Epoch: 6| Step: 12
Training loss: 2.497779718568364
Validation loss: 2.5689056163717687

Epoch: 6| Step: 13
Training loss: 2.664219915935531
Validation loss: 2.5671704227299754

Epoch: 65| Step: 0
Training loss: 2.806731348024843
Validation loss: 2.5657970183394996

Epoch: 6| Step: 1
Training loss: 2.608002627271955
Validation loss: 2.571185442049608

Epoch: 6| Step: 2
Training loss: 2.590234419181684
Validation loss: 2.566900676942226

Epoch: 6| Step: 3
Training loss: 2.633501907779603
Validation loss: 2.5645660197347317

Epoch: 6| Step: 4
Training loss: 2.973794446038192
Validation loss: 2.5643737269339586

Epoch: 6| Step: 5
Training loss: 2.9945049823153287
Validation loss: 2.563286017223864

Epoch: 6| Step: 6
Training loss: 2.4667114339666716
Validation loss: 2.5652815755822775

Epoch: 6| Step: 7
Training loss: 2.7439393970926167
Validation loss: 2.568474960143706

Epoch: 6| Step: 8
Training loss: 3.035028049898695
Validation loss: 2.5670354295432216

Epoch: 6| Step: 9
Training loss: 2.9835302944981934
Validation loss: 2.5666986818504984

Epoch: 6| Step: 10
Training loss: 2.4310464768919657
Validation loss: 2.5651344000620857

Epoch: 6| Step: 11
Training loss: 2.555057510505101
Validation loss: 2.5631623381324653

Epoch: 6| Step: 12
Training loss: 2.633168001256159
Validation loss: 2.561420748386924

Epoch: 6| Step: 13
Training loss: 2.2762117533269803
Validation loss: 2.561813510647919

Epoch: 66| Step: 0
Training loss: 2.9903794844567084
Validation loss: 2.5596474533168037

Epoch: 6| Step: 1
Training loss: 3.2713352636260713
Validation loss: 2.5606523381019124

Epoch: 6| Step: 2
Training loss: 2.592039532430612
Validation loss: 2.560338263763632

Epoch: 6| Step: 3
Training loss: 2.871194892191708
Validation loss: 2.5619428695792803

Epoch: 6| Step: 4
Training loss: 2.67440765097046
Validation loss: 2.562899628158126

Epoch: 6| Step: 5
Training loss: 2.678996183232475
Validation loss: 2.5623036441160663

Epoch: 6| Step: 6
Training loss: 2.6983634156625085
Validation loss: 2.5629731958669293

Epoch: 6| Step: 7
Training loss: 2.146216558907957
Validation loss: 2.5581811159641137

Epoch: 6| Step: 8
Training loss: 2.654992916866416
Validation loss: 2.5585217181833286

Epoch: 6| Step: 9
Training loss: 2.3302482805052356
Validation loss: 2.5548988278209768

Epoch: 6| Step: 10
Training loss: 2.6122084897591398
Validation loss: 2.5574919369055564

Epoch: 6| Step: 11
Training loss: 2.957117359111999
Validation loss: 2.552363482818283

Epoch: 6| Step: 12
Training loss: 2.5801085268896276
Validation loss: 2.551840515003368

Epoch: 6| Step: 13
Training loss: 2.465027042109043
Validation loss: 2.552515691347179

Epoch: 67| Step: 0
Training loss: 2.8369550744668937
Validation loss: 2.5509224930935215

Epoch: 6| Step: 1
Training loss: 3.010980696237157
Validation loss: 2.5537906203958176

Epoch: 6| Step: 2
Training loss: 2.732006420429555
Validation loss: 2.5615417890900867

Epoch: 6| Step: 3
Training loss: 3.114787083386134
Validation loss: 2.571374799277178

Epoch: 6| Step: 4
Training loss: 2.241295401118122
Validation loss: 2.5750580086701653

Epoch: 6| Step: 5
Training loss: 2.5976973680956252
Validation loss: 2.569343562050205

Epoch: 6| Step: 6
Training loss: 2.4534830208737577
Validation loss: 2.555074431099783

Epoch: 6| Step: 7
Training loss: 2.6714753861547305
Validation loss: 2.5525113635630636

Epoch: 6| Step: 8
Training loss: 2.6682321800995776
Validation loss: 2.546029416621801

Epoch: 6| Step: 9
Training loss: 3.1357462932568105
Validation loss: 2.5476050237508177

Epoch: 6| Step: 10
Training loss: 2.5529670171523415
Validation loss: 2.544657000802744

Epoch: 6| Step: 11
Training loss: 2.298637907314432
Validation loss: 2.5483371149620937

Epoch: 6| Step: 12
Training loss: 2.571661041741473
Validation loss: 2.5518338814614134

Epoch: 6| Step: 13
Training loss: 2.6716030049329555
Validation loss: 2.553193334927974

Epoch: 68| Step: 0
Training loss: 3.04805165580972
Validation loss: 2.553805970076378

Epoch: 6| Step: 1
Training loss: 3.2110432331283754
Validation loss: 2.554011108573428

Epoch: 6| Step: 2
Training loss: 3.047569156703844
Validation loss: 2.556783098564535

Epoch: 6| Step: 3
Training loss: 2.7622510081487968
Validation loss: 2.55465800883685

Epoch: 6| Step: 4
Training loss: 2.062880625426969
Validation loss: 2.5563037049015755

Epoch: 6| Step: 5
Training loss: 2.5830120584204233
Validation loss: 2.5550358152772032

Epoch: 6| Step: 6
Training loss: 2.529931184036331
Validation loss: 2.550548034568619

Epoch: 6| Step: 7
Training loss: 2.6648561073090518
Validation loss: 2.5513305228455176

Epoch: 6| Step: 8
Training loss: 2.535020069291165
Validation loss: 2.5460857424395997

Epoch: 6| Step: 9
Training loss: 2.765763704948879
Validation loss: 2.543906355917731

Epoch: 6| Step: 10
Training loss: 2.8558471262004796
Validation loss: 2.5456359361163425

Epoch: 6| Step: 11
Training loss: 2.72845830290539
Validation loss: 2.541943290123895

Epoch: 6| Step: 12
Training loss: 2.276336185304761
Validation loss: 2.541523434297975

Epoch: 6| Step: 13
Training loss: 2.311353244487043
Validation loss: 2.5419379126056865

Epoch: 69| Step: 0
Training loss: 2.707381056605986
Validation loss: 2.539704054940479

Epoch: 6| Step: 1
Training loss: 2.762122743833437
Validation loss: 2.537925035054446

Epoch: 6| Step: 2
Training loss: 2.870783990252308
Validation loss: 2.53898814557095

Epoch: 6| Step: 3
Training loss: 2.3018485477449144
Validation loss: 2.5383658524465496

Epoch: 6| Step: 4
Training loss: 2.780732953305455
Validation loss: 2.5403211242201524

Epoch: 6| Step: 5
Training loss: 2.6444648948469944
Validation loss: 2.534123394977299

Epoch: 6| Step: 6
Training loss: 2.5846786892565152
Validation loss: 2.5373278830398394

Epoch: 6| Step: 7
Training loss: 2.283960795912847
Validation loss: 2.532976840894639

Epoch: 6| Step: 8
Training loss: 2.9851616426851972
Validation loss: 2.536353378683267

Epoch: 6| Step: 9
Training loss: 2.937721244109669
Validation loss: 2.536352767679704

Epoch: 6| Step: 10
Training loss: 3.2517817088361554
Validation loss: 2.5327004723441147

Epoch: 6| Step: 11
Training loss: 1.9485607068494397
Validation loss: 2.533012718274174

Epoch: 6| Step: 12
Training loss: 2.151268997064173
Validation loss: 2.5327875938187194

Epoch: 6| Step: 13
Training loss: 2.8084964655765123
Validation loss: 2.530186276570705

Epoch: 70| Step: 0
Training loss: 2.9663805691499316
Validation loss: 2.5319950906646684

Epoch: 6| Step: 1
Training loss: 2.4502856107563837
Validation loss: 2.530551013274803

Epoch: 6| Step: 2
Training loss: 2.98666421858937
Validation loss: 2.5331752425565917

Epoch: 6| Step: 3
Training loss: 2.635840420837554
Validation loss: 2.5292774096590507

Epoch: 6| Step: 4
Training loss: 2.732211581380045
Validation loss: 2.5315206720506582

Epoch: 6| Step: 5
Training loss: 2.5421227426375883
Validation loss: 2.5254026148630206

Epoch: 6| Step: 6
Training loss: 2.2168897970612913
Validation loss: 2.5296831344180406

Epoch: 6| Step: 7
Training loss: 2.138597628206076
Validation loss: 2.52749318895136

Epoch: 6| Step: 8
Training loss: 2.6131553448509797
Validation loss: 2.530129722440916

Epoch: 6| Step: 9
Training loss: 3.1591381795476416
Validation loss: 2.5309057747332684

Epoch: 6| Step: 10
Training loss: 2.608233904746213
Validation loss: 2.526786243516333

Epoch: 6| Step: 11
Training loss: 1.9632056140105882
Validation loss: 2.528650542443733

Epoch: 6| Step: 12
Training loss: 3.1367090208441892
Validation loss: 2.536753241113901

Epoch: 6| Step: 13
Training loss: 2.8764425887809293
Validation loss: 2.525663639897327

Epoch: 71| Step: 0
Training loss: 2.8503308288232496
Validation loss: 2.5224291791699964

Epoch: 6| Step: 1
Training loss: 2.7323147232608913
Validation loss: 2.5271462034585146

Epoch: 6| Step: 2
Training loss: 2.2574156310072193
Validation loss: 2.5285997684472115

Epoch: 6| Step: 3
Training loss: 3.0977701596726317
Validation loss: 2.5277037091517998

Epoch: 6| Step: 4
Training loss: 2.559156888766932
Validation loss: 2.5304716349882974

Epoch: 6| Step: 5
Training loss: 2.813321311557389
Validation loss: 2.5345202070815245

Epoch: 6| Step: 6
Training loss: 1.9724447306926516
Validation loss: 2.5335235589116962

Epoch: 6| Step: 7
Training loss: 2.741755524869841
Validation loss: 2.5350150376124043

Epoch: 6| Step: 8
Training loss: 3.0223249414072995
Validation loss: 2.5336254261007767

Epoch: 6| Step: 9
Training loss: 2.5204140705943052
Validation loss: 2.5324335510182445

Epoch: 6| Step: 10
Training loss: 2.8208673412201954
Validation loss: 2.5304886885749918

Epoch: 6| Step: 11
Training loss: 2.8483423732958606
Validation loss: 2.52847994028746

Epoch: 6| Step: 12
Training loss: 2.5254227237180866
Validation loss: 2.526558393869423

Epoch: 6| Step: 13
Training loss: 2.312679593097494
Validation loss: 2.524508852135177

Epoch: 72| Step: 0
Training loss: 2.799813884271606
Validation loss: 2.523664765413645

Epoch: 6| Step: 1
Training loss: 2.538187011021347
Validation loss: 2.5249082926346476

Epoch: 6| Step: 2
Training loss: 2.401231561021043
Validation loss: 2.5190680183968865

Epoch: 6| Step: 3
Training loss: 3.047486385724996
Validation loss: 2.516930211922559

Epoch: 6| Step: 4
Training loss: 2.9994175663459544
Validation loss: 2.518269761766549

Epoch: 6| Step: 5
Training loss: 3.226379684921918
Validation loss: 2.521742165623001

Epoch: 6| Step: 6
Training loss: 2.419017361001853
Validation loss: 2.516768517443731

Epoch: 6| Step: 7
Training loss: 2.6258434575437644
Validation loss: 2.5186415409940484

Epoch: 6| Step: 8
Training loss: 2.830096827222107
Validation loss: 2.5183002628887508

Epoch: 6| Step: 9
Training loss: 2.4806748191961296
Validation loss: 2.514396383251648

Epoch: 6| Step: 10
Training loss: 2.5662905871660557
Validation loss: 2.5174662799717256

Epoch: 6| Step: 11
Training loss: 1.92487182190444
Validation loss: 2.5154799267498658

Epoch: 6| Step: 12
Training loss: 2.590503085112672
Validation loss: 2.5132634390042865

Epoch: 6| Step: 13
Training loss: 2.4046714856542164
Validation loss: 2.5131561769924775

Epoch: 73| Step: 0
Training loss: 2.4520218427970235
Validation loss: 2.5181218584321483

Epoch: 6| Step: 1
Training loss: 2.0071341114406365
Validation loss: 2.5149372021448606

Epoch: 6| Step: 2
Training loss: 3.1031173536930594
Validation loss: 2.5146781766546487

Epoch: 6| Step: 3
Training loss: 1.8826039305591311
Validation loss: 2.5150696988619754

Epoch: 6| Step: 4
Training loss: 2.8800829859539543
Validation loss: 2.516481810426905

Epoch: 6| Step: 5
Training loss: 2.4006550133459466
Validation loss: 2.5157231376887084

Epoch: 6| Step: 6
Training loss: 2.4242634470707225
Validation loss: 2.5143949372249192

Epoch: 6| Step: 7
Training loss: 2.9375404192801815
Validation loss: 2.512639337285111

Epoch: 6| Step: 8
Training loss: 3.2002061896652956
Validation loss: 2.5151976702234045

Epoch: 6| Step: 9
Training loss: 2.606474675069951
Validation loss: 2.5097583656849256

Epoch: 6| Step: 10
Training loss: 2.7259995718302847
Validation loss: 2.5151220573146573

Epoch: 6| Step: 11
Training loss: 2.794273061238894
Validation loss: 2.5084664194364628

Epoch: 6| Step: 12
Training loss: 2.822811382812495
Validation loss: 2.5084617463590666

Epoch: 6| Step: 13
Training loss: 2.3386745174425525
Validation loss: 2.5106693051004076

Epoch: 74| Step: 0
Training loss: 2.2572015377887826
Validation loss: 2.509249282544416

Epoch: 6| Step: 1
Training loss: 2.494753099965036
Validation loss: 2.512841558567906

Epoch: 6| Step: 2
Training loss: 2.9816872841847357
Validation loss: 2.506520383080159

Epoch: 6| Step: 3
Training loss: 1.5006690917236265
Validation loss: 2.5090789132518347

Epoch: 6| Step: 4
Training loss: 2.486423056109446
Validation loss: 2.5068904809847066

Epoch: 6| Step: 5
Training loss: 2.6895637572561286
Validation loss: 2.5106993287903303

Epoch: 6| Step: 6
Training loss: 2.0800242528968647
Validation loss: 2.512305618788537

Epoch: 6| Step: 7
Training loss: 3.2225639191318804
Validation loss: 2.513204527681822

Epoch: 6| Step: 8
Training loss: 3.0159295279164597
Validation loss: 2.509354019552388

Epoch: 6| Step: 9
Training loss: 2.578677031630652
Validation loss: 2.5108387435296033

Epoch: 6| Step: 10
Training loss: 3.2749025985560696
Validation loss: 2.5099836400753985

Epoch: 6| Step: 11
Training loss: 1.8525308257921793
Validation loss: 2.5107234329478705

Epoch: 6| Step: 12
Training loss: 2.536952623982759
Validation loss: 2.508561680993795

Epoch: 6| Step: 13
Training loss: 3.303139614913786
Validation loss: 2.5044279859240484

Epoch: 75| Step: 0
Training loss: 2.9901477843541167
Validation loss: 2.510151549674354

Epoch: 6| Step: 1
Training loss: 2.425656817649454
Validation loss: 2.5088380200261957

Epoch: 6| Step: 2
Training loss: 2.622901440960781
Validation loss: 2.5046784018234094

Epoch: 6| Step: 3
Training loss: 3.3452866490455233
Validation loss: 2.506048784557977

Epoch: 6| Step: 4
Training loss: 2.4927624843362453
Validation loss: 2.505902062773744

Epoch: 6| Step: 5
Training loss: 2.4063694911864206
Validation loss: 2.508201307537595

Epoch: 6| Step: 6
Training loss: 2.8263341808309574
Validation loss: 2.512054009653693

Epoch: 6| Step: 7
Training loss: 2.212661987236908
Validation loss: 2.5147218682391537

Epoch: 6| Step: 8
Training loss: 2.085539476231842
Validation loss: 2.5197379803677893

Epoch: 6| Step: 9
Training loss: 2.4492499001208894
Validation loss: 2.5088338386377846

Epoch: 6| Step: 10
Training loss: 2.7806831382252026
Validation loss: 2.5063392058848795

Epoch: 6| Step: 11
Training loss: 2.7051778065738015
Validation loss: 2.5038289312604007

Epoch: 6| Step: 12
Training loss: 2.324470467921198
Validation loss: 2.5054531228958252

Epoch: 6| Step: 13
Training loss: 2.9376740099723775
Validation loss: 2.515723690521757

Epoch: 76| Step: 0
Training loss: 2.4852778875376678
Validation loss: 2.520695159740308

Epoch: 6| Step: 1
Training loss: 3.1816347800072924
Validation loss: 2.5264051090712667

Epoch: 6| Step: 2
Training loss: 3.101512072559201
Validation loss: 2.512446771124286

Epoch: 6| Step: 3
Training loss: 2.010490916829532
Validation loss: 2.5075872999507287

Epoch: 6| Step: 4
Training loss: 2.5757331619193655
Validation loss: 2.5043994657830195

Epoch: 6| Step: 5
Training loss: 2.4967549243839096
Validation loss: 2.5059332377092325

Epoch: 6| Step: 6
Training loss: 2.125103667479349
Validation loss: 2.503632671865732

Epoch: 6| Step: 7
Training loss: 2.7700258574673264
Validation loss: 2.5046372321136143

Epoch: 6| Step: 8
Training loss: 2.5671407034771145
Validation loss: 2.503685206011162

Epoch: 6| Step: 9
Training loss: 2.773368899074554
Validation loss: 2.502451219492954

Epoch: 6| Step: 10
Training loss: 2.348841921564233
Validation loss: 2.5025732148975885

Epoch: 6| Step: 11
Training loss: 2.676011658932501
Validation loss: 2.502858562155958

Epoch: 6| Step: 12
Training loss: 2.579491085752112
Validation loss: 2.498615914901442

Epoch: 6| Step: 13
Training loss: 2.929173131929283
Validation loss: 2.4990028777027695

Epoch: 77| Step: 0
Training loss: 2.491209789053048
Validation loss: 2.4969393750908795

Epoch: 6| Step: 1
Training loss: 3.2266029928035684
Validation loss: 2.4964613347827496

Epoch: 6| Step: 2
Training loss: 2.589075863607447
Validation loss: 2.496590037152437

Epoch: 6| Step: 3
Training loss: 2.184750163724234
Validation loss: 2.4954931325551106

Epoch: 6| Step: 4
Training loss: 2.392274374851328
Validation loss: 2.498484263281674

Epoch: 6| Step: 5
Training loss: 2.1311806944376515
Validation loss: 2.4967234916060277

Epoch: 6| Step: 6
Training loss: 3.1511349162446183
Validation loss: 2.4947848363051492

Epoch: 6| Step: 7
Training loss: 2.915637207005696
Validation loss: 2.499002162161537

Epoch: 6| Step: 8
Training loss: 2.39538628650545
Validation loss: 2.495876169447422

Epoch: 6| Step: 9
Training loss: 3.1403161651441134
Validation loss: 2.502403224746829

Epoch: 6| Step: 10
Training loss: 2.273791728001195
Validation loss: 2.503369460787027

Epoch: 6| Step: 11
Training loss: 2.5697105189761493
Validation loss: 2.501003048265123

Epoch: 6| Step: 12
Training loss: 2.523907313590179
Validation loss: 2.5006481760901282

Epoch: 6| Step: 13
Training loss: 2.4590002760854026
Validation loss: 2.503965427693219

Epoch: 78| Step: 0
Training loss: 2.128325160804219
Validation loss: 2.5013460588668655

Epoch: 6| Step: 1
Training loss: 2.6890375041963637
Validation loss: 2.497955185373419

Epoch: 6| Step: 2
Training loss: 2.011772080983021
Validation loss: 2.4987982563640663

Epoch: 6| Step: 3
Training loss: 2.4717334152163772
Validation loss: 2.489998895818524

Epoch: 6| Step: 4
Training loss: 2.8605481018705547
Validation loss: 2.490457777586343

Epoch: 6| Step: 5
Training loss: 2.550464277449911
Validation loss: 2.5032581714601014

Epoch: 6| Step: 6
Training loss: 2.45031460668889
Validation loss: 2.496774372719701

Epoch: 6| Step: 7
Training loss: 2.8767717955627132
Validation loss: 2.502495743820631

Epoch: 6| Step: 8
Training loss: 2.5935434466007155
Validation loss: 2.503317269232655

Epoch: 6| Step: 9
Training loss: 2.443699899145253
Validation loss: 2.513670349515834

Epoch: 6| Step: 10
Training loss: 3.4773773952785647
Validation loss: 2.5071340179856825

Epoch: 6| Step: 11
Training loss: 2.9234071682080778
Validation loss: 2.5038784618690513

Epoch: 6| Step: 12
Training loss: 2.7671059991174105
Validation loss: 2.497880712912701

Epoch: 6| Step: 13
Training loss: 2.3558562863012935
Validation loss: 2.492948585300389

Epoch: 79| Step: 0
Training loss: 2.5695005485205984
Validation loss: 2.492337022080786

Epoch: 6| Step: 1
Training loss: 2.4167516846884243
Validation loss: 2.4977935590995894

Epoch: 6| Step: 2
Training loss: 3.1772564116480884
Validation loss: 2.49997383739769

Epoch: 6| Step: 3
Training loss: 3.10204643874883
Validation loss: 2.5019446994978116

Epoch: 6| Step: 4
Training loss: 2.3904766959271435
Validation loss: 2.5106808113223726

Epoch: 6| Step: 5
Training loss: 2.7062171493545097
Validation loss: 2.5154910713385625

Epoch: 6| Step: 6
Training loss: 2.7411272656561274
Validation loss: 2.52389744207465

Epoch: 6| Step: 7
Training loss: 2.5573418036762465
Validation loss: 2.5292372687937092

Epoch: 6| Step: 8
Training loss: 2.6283538827554414
Validation loss: 2.5286736111960013

Epoch: 6| Step: 9
Training loss: 2.285112116460841
Validation loss: 2.53346011530537

Epoch: 6| Step: 10
Training loss: 2.6537666829861006
Validation loss: 2.5357062355965256

Epoch: 6| Step: 11
Training loss: 2.491540328515307
Validation loss: 2.5412511068936836

Epoch: 6| Step: 12
Training loss: 2.8889476961687506
Validation loss: 2.5306383971737976

Epoch: 6| Step: 13
Training loss: 2.378586119610926
Validation loss: 2.528490375385067

Epoch: 80| Step: 0
Training loss: 2.661455864852288
Validation loss: 2.524446693076705

Epoch: 6| Step: 1
Training loss: 2.387615828175995
Validation loss: 2.526050407682941

Epoch: 6| Step: 2
Training loss: 2.3945055613298845
Validation loss: 2.5223382813428796

Epoch: 6| Step: 3
Training loss: 2.818048471920594
Validation loss: 2.52142617581762

Epoch: 6| Step: 4
Training loss: 2.4709238066896306
Validation loss: 2.519604940593567

Epoch: 6| Step: 5
Training loss: 2.648189926954106
Validation loss: 2.5218084094124125

Epoch: 6| Step: 6
Training loss: 2.760439909831144
Validation loss: 2.515263723016664

Epoch: 6| Step: 7
Training loss: 2.54220696214988
Validation loss: 2.513581988415289

Epoch: 6| Step: 8
Training loss: 2.6096699256748312
Validation loss: 2.509196991582553

Epoch: 6| Step: 9
Training loss: 2.6099772415045837
Validation loss: 2.5080247197025547

Epoch: 6| Step: 10
Training loss: 2.7301122953913044
Validation loss: 2.5070675766546793

Epoch: 6| Step: 11
Training loss: 2.552969071705571
Validation loss: 2.499721225454265

Epoch: 6| Step: 12
Training loss: 2.851985868614252
Validation loss: 2.4994177935098145

Epoch: 6| Step: 13
Training loss: 2.8061956319661183
Validation loss: 2.497951606164643

Epoch: 81| Step: 0
Training loss: 2.2532103206230887
Validation loss: 2.4973841492210846

Epoch: 6| Step: 1
Training loss: 3.2368197577035183
Validation loss: 2.4924472525986365

Epoch: 6| Step: 2
Training loss: 2.2192307072374877
Validation loss: 2.4910300186759904

Epoch: 6| Step: 3
Training loss: 2.7759866524136356
Validation loss: 2.4857787478987845

Epoch: 6| Step: 4
Training loss: 2.417130973761585
Validation loss: 2.4862750562911136

Epoch: 6| Step: 5
Training loss: 2.634714769419781
Validation loss: 2.4885662400725117

Epoch: 6| Step: 6
Training loss: 2.32947557433342
Validation loss: 2.4914256239774044

Epoch: 6| Step: 7
Training loss: 2.829739104737203
Validation loss: 2.4939554654075886

Epoch: 6| Step: 8
Training loss: 2.43694631694762
Validation loss: 2.4906354035240392

Epoch: 6| Step: 9
Training loss: 3.1897404594431187
Validation loss: 2.499539809787328

Epoch: 6| Step: 10
Training loss: 2.8035565064356796
Validation loss: 2.509628842358305

Epoch: 6| Step: 11
Training loss: 2.2446246044423916
Validation loss: 2.4981001310659154

Epoch: 6| Step: 12
Training loss: 2.7357081188031374
Validation loss: 2.502431958188465

Epoch: 6| Step: 13
Training loss: 2.3750706712347265
Validation loss: 2.495813169912704

Epoch: 82| Step: 0
Training loss: 3.2447969896855584
Validation loss: 2.485505860341142

Epoch: 6| Step: 1
Training loss: 2.3461685925822415
Validation loss: 2.4890589354625847

Epoch: 6| Step: 2
Training loss: 2.6964162142352253
Validation loss: 2.4885219615242877

Epoch: 6| Step: 3
Training loss: 2.7699246362562917
Validation loss: 2.490248161726542

Epoch: 6| Step: 4
Training loss: 2.5031542906077306
Validation loss: 2.4876875476007663

Epoch: 6| Step: 5
Training loss: 2.5896815368576322
Validation loss: 2.4889233457880335

Epoch: 6| Step: 6
Training loss: 2.6510094501408945
Validation loss: 2.487663092450365

Epoch: 6| Step: 7
Training loss: 1.8542229575995595
Validation loss: 2.4885519330619457

Epoch: 6| Step: 8
Training loss: 2.4034802237534887
Validation loss: 2.4896475625365175

Epoch: 6| Step: 9
Training loss: 2.583132510429298
Validation loss: 2.4877908284256414

Epoch: 6| Step: 10
Training loss: 2.4160475979341545
Validation loss: 2.4889879086595275

Epoch: 6| Step: 11
Training loss: 3.080889240060649
Validation loss: 2.4881179412636905

Epoch: 6| Step: 12
Training loss: 2.654330019712346
Validation loss: 2.4882227852349152

Epoch: 6| Step: 13
Training loss: 2.5222882467563736
Validation loss: 2.4881861662051947

Epoch: 83| Step: 0
Training loss: 2.726706602119665
Validation loss: 2.487808813482009

Epoch: 6| Step: 1
Training loss: 2.1485241681737737
Validation loss: 2.4877965785466123

Epoch: 6| Step: 2
Training loss: 2.376855526928874
Validation loss: 2.4883734877102337

Epoch: 6| Step: 3
Training loss: 1.8206291087111086
Validation loss: 2.487668890786671

Epoch: 6| Step: 4
Training loss: 2.226640024006752
Validation loss: 2.4897800245489776

Epoch: 6| Step: 5
Training loss: 2.9045431395676284
Validation loss: 2.4873980796803075

Epoch: 6| Step: 6
Training loss: 2.9641751024156386
Validation loss: 2.484742623246536

Epoch: 6| Step: 7
Training loss: 3.0150294531147477
Validation loss: 2.488907763597846

Epoch: 6| Step: 8
Training loss: 2.944098670218182
Validation loss: 2.4868277432078245

Epoch: 6| Step: 9
Training loss: 2.7238940103107425
Validation loss: 2.488507398771529

Epoch: 6| Step: 10
Training loss: 2.4663009084560272
Validation loss: 2.4843818296582536

Epoch: 6| Step: 11
Training loss: 2.4208809073714845
Validation loss: 2.4887314353772885

Epoch: 6| Step: 12
Training loss: 2.526916184732506
Validation loss: 2.486302809425322

Epoch: 6| Step: 13
Training loss: 2.824865327848993
Validation loss: 2.485769044678007

Epoch: 84| Step: 0
Training loss: 2.5395313945045683
Validation loss: 2.484061807208521

Epoch: 6| Step: 1
Training loss: 2.840240996437922
Validation loss: 2.4868746963581323

Epoch: 6| Step: 2
Training loss: 2.8108013533593716
Validation loss: 2.484348256988859

Epoch: 6| Step: 3
Training loss: 1.5710442958732727
Validation loss: 2.491321201892429

Epoch: 6| Step: 4
Training loss: 2.653988402731537
Validation loss: 2.491331298185556

Epoch: 6| Step: 5
Training loss: 2.250621074152952
Validation loss: 2.491868001613735

Epoch: 6| Step: 6
Training loss: 2.5406420680149604
Validation loss: 2.4810856570149022

Epoch: 6| Step: 7
Training loss: 2.733358837411879
Validation loss: 2.4879090706010745

Epoch: 6| Step: 8
Training loss: 2.8448433922435172
Validation loss: 2.4902774742236438

Epoch: 6| Step: 9
Training loss: 2.792044533355264
Validation loss: 2.493971629480285

Epoch: 6| Step: 10
Training loss: 2.588649376534993
Validation loss: 2.484894944010053

Epoch: 6| Step: 11
Training loss: 2.7570241174040815
Validation loss: 2.484118658312328

Epoch: 6| Step: 12
Training loss: 2.6791043105712378
Validation loss: 2.488025885732492

Epoch: 6| Step: 13
Training loss: 2.559729776723745
Validation loss: 2.4833941492745453

Epoch: 85| Step: 0
Training loss: 2.679118638228598
Validation loss: 2.4891513838126964

Epoch: 6| Step: 1
Training loss: 2.9531161192099438
Validation loss: 2.4853388837829438

Epoch: 6| Step: 2
Training loss: 2.9890770743812873
Validation loss: 2.4897591649827255

Epoch: 6| Step: 3
Training loss: 2.4321763026932923
Validation loss: 2.488833794759835

Epoch: 6| Step: 4
Training loss: 2.5876222406528053
Validation loss: 2.4879976327533235

Epoch: 6| Step: 5
Training loss: 1.9811178193389138
Validation loss: 2.4924933107389005

Epoch: 6| Step: 6
Training loss: 2.418197103388175
Validation loss: 2.4876418796888813

Epoch: 6| Step: 7
Training loss: 2.831096963346388
Validation loss: 2.483011555359431

Epoch: 6| Step: 8
Training loss: 2.5662726566375533
Validation loss: 2.4836294627014426

Epoch: 6| Step: 9
Training loss: 2.472966131043959
Validation loss: 2.4822771503911407

Epoch: 6| Step: 10
Training loss: 2.558403835091451
Validation loss: 2.479247489915363

Epoch: 6| Step: 11
Training loss: 2.7215323406584755
Validation loss: 2.4814696207548557

Epoch: 6| Step: 12
Training loss: 2.463493061728721
Validation loss: 2.4791886358062403

Epoch: 6| Step: 13
Training loss: 2.675547613260275
Validation loss: 2.4762905224214555

Epoch: 86| Step: 0
Training loss: 2.661557628075778
Validation loss: 2.4782909935817274

Epoch: 6| Step: 1
Training loss: 2.6622121879220124
Validation loss: 2.482062024822367

Epoch: 6| Step: 2
Training loss: 2.9512701112868998
Validation loss: 2.4843367247762

Epoch: 6| Step: 3
Training loss: 3.181714960380852
Validation loss: 2.4788756052762544

Epoch: 6| Step: 4
Training loss: 2.6345455453859383
Validation loss: 2.4790153190085102

Epoch: 6| Step: 5
Training loss: 2.761318150754726
Validation loss: 2.4824107980468506

Epoch: 6| Step: 6
Training loss: 2.451948527668643
Validation loss: 2.479574704183791

Epoch: 6| Step: 7
Training loss: 2.824802955574687
Validation loss: 2.479459862775665

Epoch: 6| Step: 8
Training loss: 2.669431048291383
Validation loss: 2.483913050794997

Epoch: 6| Step: 9
Training loss: 1.7818777751599941
Validation loss: 2.4739450447662574

Epoch: 6| Step: 10
Training loss: 2.388655705369944
Validation loss: 2.485731158593367

Epoch: 6| Step: 11
Training loss: 2.281130643883715
Validation loss: 2.480378300977634

Epoch: 6| Step: 12
Training loss: 2.626145158478887
Validation loss: 2.482915357536137

Epoch: 6| Step: 13
Training loss: 2.1204001063532676
Validation loss: 2.480407249509276

Epoch: 87| Step: 0
Training loss: 2.842147375560729
Validation loss: 2.4777656785339786

Epoch: 6| Step: 1
Training loss: 2.657954846965211
Validation loss: 2.4767260893533942

Epoch: 6| Step: 2
Training loss: 2.250106385153119
Validation loss: 2.4766999857352574

Epoch: 6| Step: 3
Training loss: 2.596978350073549
Validation loss: 2.480763559518821

Epoch: 6| Step: 4
Training loss: 2.430399603306108
Validation loss: 2.479631962642005

Epoch: 6| Step: 5
Training loss: 2.7224093835635905
Validation loss: 2.4791204677946777

Epoch: 6| Step: 6
Training loss: 2.734694456785375
Validation loss: 2.4774495971869883

Epoch: 6| Step: 7
Training loss: 2.731184225796209
Validation loss: 2.47817980467978

Epoch: 6| Step: 8
Training loss: 2.8342401138056523
Validation loss: 2.474347557101333

Epoch: 6| Step: 9
Training loss: 2.8025751261378318
Validation loss: 2.4777738574937374

Epoch: 6| Step: 10
Training loss: 2.4725479656693015
Validation loss: 2.4780436999152324

Epoch: 6| Step: 11
Training loss: 2.2288627655034103
Validation loss: 2.4771991156192685

Epoch: 6| Step: 12
Training loss: 2.591282417620876
Validation loss: 2.4778349582800816

Epoch: 6| Step: 13
Training loss: 2.160454341470416
Validation loss: 2.480035578833983

Epoch: 88| Step: 0
Training loss: 2.6252068937602586
Validation loss: 2.4815640171547426

Epoch: 6| Step: 1
Training loss: 2.6679504304538963
Validation loss: 2.4753038194206622

Epoch: 6| Step: 2
Training loss: 2.2004766034679095
Validation loss: 2.479112325334569

Epoch: 6| Step: 3
Training loss: 2.2779854186196733
Validation loss: 2.476823409944823

Epoch: 6| Step: 4
Training loss: 2.951468835882326
Validation loss: 2.478387940076066

Epoch: 6| Step: 5
Training loss: 2.1307940311360456
Validation loss: 2.4793360248922722

Epoch: 6| Step: 6
Training loss: 2.582501574919258
Validation loss: 2.4793968147284247

Epoch: 6| Step: 7
Training loss: 2.6505036073468364
Validation loss: 2.4815877317843107

Epoch: 6| Step: 8
Training loss: 2.1976178103169275
Validation loss: 2.4741253819869833

Epoch: 6| Step: 9
Training loss: 2.678310919309624
Validation loss: 2.4761536959760977

Epoch: 6| Step: 10
Training loss: 2.64697549352193
Validation loss: 2.4807991989174223

Epoch: 6| Step: 11
Training loss: 2.588795169158125
Validation loss: 2.4789048759231425

Epoch: 6| Step: 12
Training loss: 2.980702642260235
Validation loss: 2.4751701572636677

Epoch: 6| Step: 13
Training loss: 2.7569220729104904
Validation loss: 2.4760655206331807

Epoch: 89| Step: 0
Training loss: 2.258286053583733
Validation loss: 2.475762206855292

Epoch: 6| Step: 1
Training loss: 2.693471086051239
Validation loss: 2.4744796578426804

Epoch: 6| Step: 2
Training loss: 2.9500889586920556
Validation loss: 2.480725757170187

Epoch: 6| Step: 3
Training loss: 2.5755413634456223
Validation loss: 2.4759222540802686

Epoch: 6| Step: 4
Training loss: 2.4046738652071413
Validation loss: 2.4703217987393837

Epoch: 6| Step: 5
Training loss: 2.7418239602494183
Validation loss: 2.4723003788236806

Epoch: 6| Step: 6
Training loss: 2.9842625142413746
Validation loss: 2.4702354822894583

Epoch: 6| Step: 7
Training loss: 2.5770229874260275
Validation loss: 2.4749979558608737

Epoch: 6| Step: 8
Training loss: 2.534306787967536
Validation loss: 2.4677935892441414

Epoch: 6| Step: 9
Training loss: 1.624326566390209
Validation loss: 2.4740875424557602

Epoch: 6| Step: 10
Training loss: 1.9947992296465604
Validation loss: 2.4664338268324886

Epoch: 6| Step: 11
Training loss: 3.018697645787761
Validation loss: 2.484744766196576

Epoch: 6| Step: 12
Training loss: 3.0176192098740326
Validation loss: 2.479097643193242

Epoch: 6| Step: 13
Training loss: 2.3988070622625006
Validation loss: 2.470361175797485

Epoch: 90| Step: 0
Training loss: 3.0182540580945303
Validation loss: 2.4759737552439236

Epoch: 6| Step: 1
Training loss: 2.659423996219614
Validation loss: 2.4820181105324655

Epoch: 6| Step: 2
Training loss: 2.849201050251782
Validation loss: 2.481509749671691

Epoch: 6| Step: 3
Training loss: 2.7171575332928306
Validation loss: 2.4847330599096504

Epoch: 6| Step: 4
Training loss: 1.8470140433859303
Validation loss: 2.483174079763958

Epoch: 6| Step: 5
Training loss: 2.4399480019954125
Validation loss: 2.481034966670989

Epoch: 6| Step: 6
Training loss: 2.287180885610803
Validation loss: 2.4833791404271404

Epoch: 6| Step: 7
Training loss: 2.551415824528758
Validation loss: 2.4842386428231995

Epoch: 6| Step: 8
Training loss: 2.4476407700483502
Validation loss: 2.4828642724322725

Epoch: 6| Step: 9
Training loss: 2.770912762031681
Validation loss: 2.4819586176776802

Epoch: 6| Step: 10
Training loss: 2.7008173800284374
Validation loss: 2.481841484950828

Epoch: 6| Step: 11
Training loss: 2.234955185477174
Validation loss: 2.4820693491316113

Epoch: 6| Step: 12
Training loss: 2.9728588381094863
Validation loss: 2.4816280989748853

Epoch: 6| Step: 13
Training loss: 2.6017338693440744
Validation loss: 2.479135213914204

Epoch: 91| Step: 0
Training loss: 2.300011601626119
Validation loss: 2.4763614480673457

Epoch: 6| Step: 1
Training loss: 2.4125575834527435
Validation loss: 2.479453468295886

Epoch: 6| Step: 2
Training loss: 2.301112101006317
Validation loss: 2.4772253102220594

Epoch: 6| Step: 3
Training loss: 2.957099298981704
Validation loss: 2.4788048798113813

Epoch: 6| Step: 4
Training loss: 2.8263487744016604
Validation loss: 2.475247648802524

Epoch: 6| Step: 5
Training loss: 2.8990181806506774
Validation loss: 2.4809187673615978

Epoch: 6| Step: 6
Training loss: 2.939894005039001
Validation loss: 2.472793470836787

Epoch: 6| Step: 7
Training loss: 2.9376529085659615
Validation loss: 2.4758581369245323

Epoch: 6| Step: 8
Training loss: 2.4060835347248895
Validation loss: 2.47671561264235

Epoch: 6| Step: 9
Training loss: 2.515845626728575
Validation loss: 2.475684426459656

Epoch: 6| Step: 10
Training loss: 2.4495000601630466
Validation loss: 2.4778908938469204

Epoch: 6| Step: 11
Training loss: 2.82650314108463
Validation loss: 2.4723715796579175

Epoch: 6| Step: 12
Training loss: 1.9995834989786792
Validation loss: 2.478493051348477

Epoch: 6| Step: 13
Training loss: 2.1138279008637895
Validation loss: 2.472662300476096

Epoch: 92| Step: 0
Training loss: 2.295792512709625
Validation loss: 2.4821386768505813

Epoch: 6| Step: 1
Training loss: 2.6278490318528966
Validation loss: 2.4767535403722962

Epoch: 6| Step: 2
Training loss: 2.425357603467931
Validation loss: 2.477605381510187

Epoch: 6| Step: 3
Training loss: 2.804967499678984
Validation loss: 2.4813169135640742

Epoch: 6| Step: 4
Training loss: 2.7777003235085025
Validation loss: 2.4807510015143572

Epoch: 6| Step: 5
Training loss: 2.684322696837934
Validation loss: 2.473315094429006

Epoch: 6| Step: 6
Training loss: 2.3635100450974114
Validation loss: 2.4750870121004356

Epoch: 6| Step: 7
Training loss: 2.777679380157587
Validation loss: 2.473815228522821

Epoch: 6| Step: 8
Training loss: 2.4533498867485415
Validation loss: 2.472776557683328

Epoch: 6| Step: 9
Training loss: 2.3801880438431655
Validation loss: 2.4745273832423558

Epoch: 6| Step: 10
Training loss: 2.2703329695784995
Validation loss: 2.4743777966850877

Epoch: 6| Step: 11
Training loss: 2.6904866678119914
Validation loss: 2.477199981826116

Epoch: 6| Step: 12
Training loss: 3.067144647610816
Validation loss: 2.4740725574559614

Epoch: 6| Step: 13
Training loss: 2.3089218293806906
Validation loss: 2.477387171645162

Epoch: 93| Step: 0
Training loss: 3.2067821931020792
Validation loss: 2.4777451187551174

Epoch: 6| Step: 1
Training loss: 2.11401320665722
Validation loss: 2.4681250670526333

Epoch: 6| Step: 2
Training loss: 2.9547600634866917
Validation loss: 2.472614394441837

Epoch: 6| Step: 3
Training loss: 2.6678109296865804
Validation loss: 2.4799024040492013

Epoch: 6| Step: 4
Training loss: 2.7205289961607497
Validation loss: 2.471513207761168

Epoch: 6| Step: 5
Training loss: 2.362800385285555
Validation loss: 2.4678479007163814

Epoch: 6| Step: 6
Training loss: 2.893790496476896
Validation loss: 2.472171006642539

Epoch: 6| Step: 7
Training loss: 2.6550359307567986
Validation loss: 2.4684144286958425

Epoch: 6| Step: 8
Training loss: 2.1446821093696484
Validation loss: 2.4716770669980264

Epoch: 6| Step: 9
Training loss: 1.9756194869401684
Validation loss: 2.4718553191059396

Epoch: 6| Step: 10
Training loss: 2.9168118758612183
Validation loss: 2.467189440445623

Epoch: 6| Step: 11
Training loss: 2.691639750280131
Validation loss: 2.468043230186155

Epoch: 6| Step: 12
Training loss: 2.2761859862592444
Validation loss: 2.4708185020717846

Epoch: 6| Step: 13
Training loss: 1.821747897443609
Validation loss: 2.4696223009576195

Epoch: 94| Step: 0
Training loss: 2.691945856533306
Validation loss: 2.463467487296411

Epoch: 6| Step: 1
Training loss: 1.8423629974816977
Validation loss: 2.475261719670054

Epoch: 6| Step: 2
Training loss: 2.4834825364250155
Validation loss: 2.4694206035203603

Epoch: 6| Step: 3
Training loss: 2.4026603180014297
Validation loss: 2.4662192688548443

Epoch: 6| Step: 4
Training loss: 2.552732693847476
Validation loss: 2.4658396664102264

Epoch: 6| Step: 5
Training loss: 1.9641403850447392
Validation loss: 2.466481949574227

Epoch: 6| Step: 6
Training loss: 2.6066179157618694
Validation loss: 2.465605556087435

Epoch: 6| Step: 7
Training loss: 3.0079748332817298
Validation loss: 2.463605453816

Epoch: 6| Step: 8
Training loss: 2.6533499650417967
Validation loss: 2.464464645129052

Epoch: 6| Step: 9
Training loss: 2.7930252603002526
Validation loss: 2.469512853782204

Epoch: 6| Step: 10
Training loss: 2.59648071307169
Validation loss: 2.4718639195093783

Epoch: 6| Step: 11
Training loss: 2.6330703925992585
Validation loss: 2.4679913381211236

Epoch: 6| Step: 12
Training loss: 2.4661849011096435
Validation loss: 2.4646333744733373

Epoch: 6| Step: 13
Training loss: 2.891535105355446
Validation loss: 2.4683921007282086

Epoch: 95| Step: 0
Training loss: 2.5941998195112586
Validation loss: 2.4700664599611404

Epoch: 6| Step: 1
Training loss: 2.6388670357139508
Validation loss: 2.4630174193288354

Epoch: 6| Step: 2
Training loss: 2.9824640836895333
Validation loss: 2.4671031110430692

Epoch: 6| Step: 3
Training loss: 2.340780793366866
Validation loss: 2.471002364099479

Epoch: 6| Step: 4
Training loss: 2.3192064108568835
Validation loss: 2.470255863281185

Epoch: 6| Step: 5
Training loss: 1.9901593824039836
Validation loss: 2.466791929681512

Epoch: 6| Step: 6
Training loss: 2.443821656720465
Validation loss: 2.4701037337004466

Epoch: 6| Step: 7
Training loss: 2.363466063279816
Validation loss: 2.4744986469452406

Epoch: 6| Step: 8
Training loss: 2.8097112605036703
Validation loss: 2.46175373407249

Epoch: 6| Step: 9
Training loss: 2.6749046059114554
Validation loss: 2.4667351302964273

Epoch: 6| Step: 10
Training loss: 2.8192035893717247
Validation loss: 2.4645651747055295

Epoch: 6| Step: 11
Training loss: 2.1845484848876
Validation loss: 2.4661572196614343

Epoch: 6| Step: 12
Training loss: 2.760460465761505
Validation loss: 2.4707108287666046

Epoch: 6| Step: 13
Training loss: 2.705425364107618
Validation loss: 2.4681851670405175

Epoch: 96| Step: 0
Training loss: 2.74038115126665
Validation loss: 2.4719068889273004

Epoch: 6| Step: 1
Training loss: 2.1481646000328345
Validation loss: 2.4683918592566543

Epoch: 6| Step: 2
Training loss: 2.456021779258908
Validation loss: 2.4711780920840205

Epoch: 6| Step: 3
Training loss: 2.8027551311295893
Validation loss: 2.4646881102741

Epoch: 6| Step: 4
Training loss: 2.56731687789764
Validation loss: 2.471637887750727

Epoch: 6| Step: 5
Training loss: 2.719905388532991
Validation loss: 2.470830788913937

Epoch: 6| Step: 6
Training loss: 2.9201994799056803
Validation loss: 2.4720389593494567

Epoch: 6| Step: 7
Training loss: 2.2636495462390984
Validation loss: 2.4757572473446054

Epoch: 6| Step: 8
Training loss: 2.598730888938633
Validation loss: 2.472003097205089

Epoch: 6| Step: 9
Training loss: 2.445097502498093
Validation loss: 2.4704337997301367

Epoch: 6| Step: 10
Training loss: 2.5116936903396074
Validation loss: 2.4705379466050794

Epoch: 6| Step: 11
Training loss: 2.475981057441244
Validation loss: 2.469253022014945

Epoch: 6| Step: 12
Training loss: 2.698548958425262
Validation loss: 2.4695212370731756

Epoch: 6| Step: 13
Training loss: 2.430802166250424
Validation loss: 2.470743074961106

Epoch: 97| Step: 0
Training loss: 2.4931193077651668
Validation loss: 2.471520957235903

Epoch: 6| Step: 1
Training loss: 2.46322554535314
Validation loss: 2.4700506462021936

Epoch: 6| Step: 2
Training loss: 2.4393242098705525
Validation loss: 2.4671317965770534

Epoch: 6| Step: 3
Training loss: 2.7760824137280324
Validation loss: 2.466750369284215

Epoch: 6| Step: 4
Training loss: 2.9064344122019405
Validation loss: 2.4657508079880475

Epoch: 6| Step: 5
Training loss: 2.4634317020017513
Validation loss: 2.470284930434656

Epoch: 6| Step: 6
Training loss: 2.238737955151504
Validation loss: 2.4650351101952155

Epoch: 6| Step: 7
Training loss: 2.7029244232732896
Validation loss: 2.470553692908796

Epoch: 6| Step: 8
Training loss: 2.24268550858235
Validation loss: 2.480215176814952

Epoch: 6| Step: 9
Training loss: 2.622173240531017
Validation loss: 2.4746246779003043

Epoch: 6| Step: 10
Training loss: 2.6716967071475217
Validation loss: 2.470700431088473

Epoch: 6| Step: 11
Training loss: 2.148917737519739
Validation loss: 2.4717244687162836

Epoch: 6| Step: 12
Training loss: 3.2329326859890277
Validation loss: 2.471641215679742

Epoch: 6| Step: 13
Training loss: 2.3344620858204266
Validation loss: 2.47262103963152

Epoch: 98| Step: 0
Training loss: 2.3690158342546423
Validation loss: 2.470647477037184

Epoch: 6| Step: 1
Training loss: 2.4395188016579374
Validation loss: 2.4630658185473604

Epoch: 6| Step: 2
Training loss: 2.6923213560155883
Validation loss: 2.463600808550027

Epoch: 6| Step: 3
Training loss: 1.6808324415853566
Validation loss: 2.4607102223557256

Epoch: 6| Step: 4
Training loss: 1.9215879148352588
Validation loss: 2.46419625863643

Epoch: 6| Step: 5
Training loss: 2.812992307173065
Validation loss: 2.4601184107548764

Epoch: 6| Step: 6
Training loss: 2.4087436190146003
Validation loss: 2.465798444493585

Epoch: 6| Step: 7
Training loss: 2.8932621653838426
Validation loss: 2.4672431048874994

Epoch: 6| Step: 8
Training loss: 2.9039671761415318
Validation loss: 2.4674494895158383

Epoch: 6| Step: 9
Training loss: 2.3170526384244567
Validation loss: 2.4632652616924666

Epoch: 6| Step: 10
Training loss: 2.333160893562427
Validation loss: 2.4681866159908172

Epoch: 6| Step: 11
Training loss: 3.3761094706897548
Validation loss: 2.471688401051001

Epoch: 6| Step: 12
Training loss: 2.633669569383335
Validation loss: 2.470629238385902

Epoch: 6| Step: 13
Training loss: 2.580491892623953
Validation loss: 2.468131812878271

Epoch: 99| Step: 0
Training loss: 2.091832435797171
Validation loss: 2.4688064794075477

Epoch: 6| Step: 1
Training loss: 3.304544360079673
Validation loss: 2.469965864710128

Epoch: 6| Step: 2
Training loss: 2.412525267789875
Validation loss: 2.4741816423253504

Epoch: 6| Step: 3
Training loss: 2.2518036289005936
Validation loss: 2.4715000239516374

Epoch: 6| Step: 4
Training loss: 2.4556091753924787
Validation loss: 2.475505021457643

Epoch: 6| Step: 5
Training loss: 2.862504257798672
Validation loss: 2.4769638410215213

Epoch: 6| Step: 6
Training loss: 2.5888345860947077
Validation loss: 2.472665185093618

Epoch: 6| Step: 7
Training loss: 2.7787524378358732
Validation loss: 2.4775941226400926

Epoch: 6| Step: 8
Training loss: 2.392486246641483
Validation loss: 2.476877154428676

Epoch: 6| Step: 9
Training loss: 2.8170956681825037
Validation loss: 2.478388709668391

Epoch: 6| Step: 10
Training loss: 2.247586545370537
Validation loss: 2.472683874762378

Epoch: 6| Step: 11
Training loss: 2.8874269682660914
Validation loss: 2.4688631023783225

Epoch: 6| Step: 12
Training loss: 1.4691332053392971
Validation loss: 2.461602693301994

Epoch: 6| Step: 13
Training loss: 2.9142811056576146
Validation loss: 2.46917162485834

Epoch: 100| Step: 0
Training loss: 2.0968642346806483
Validation loss: 2.4754367199029703

Epoch: 6| Step: 1
Training loss: 2.3640157771866916
Validation loss: 2.4931820008264736

Epoch: 6| Step: 2
Training loss: 2.3972015675636844
Validation loss: 2.4875963547030464

Epoch: 6| Step: 3
Training loss: 2.408937909844317
Validation loss: 2.4836059275621882

Epoch: 6| Step: 4
Training loss: 2.7910122080542417
Validation loss: 2.475250249470889

Epoch: 6| Step: 5
Training loss: 2.7532544385984576
Validation loss: 2.4668720845012833

Epoch: 6| Step: 6
Training loss: 2.2661767748087565
Validation loss: 2.46821172294455

Epoch: 6| Step: 7
Training loss: 2.7457951563803884
Validation loss: 2.4734197465328145

Epoch: 6| Step: 8
Training loss: 2.5341877784673343
Validation loss: 2.4720758657912216

Epoch: 6| Step: 9
Training loss: 2.6640886322261212
Validation loss: 2.473506851493189

Epoch: 6| Step: 10
Training loss: 2.6390809730980895
Validation loss: 2.4707999912819214

Epoch: 6| Step: 11
Training loss: 2.490648517952308
Validation loss: 2.4702430909982263

Epoch: 6| Step: 12
Training loss: 2.590743563047616
Validation loss: 2.474231830671154

Epoch: 6| Step: 13
Training loss: 2.951672716642527
Validation loss: 2.479515537323797

Epoch: 101| Step: 0
Training loss: 2.761132076814069
Validation loss: 2.4724300174561176

Epoch: 6| Step: 1
Training loss: 2.627528290020101
Validation loss: 2.4763518684098513

Epoch: 6| Step: 2
Training loss: 2.054424196495039
Validation loss: 2.472480723502291

Epoch: 6| Step: 3
Training loss: 2.334511107698782
Validation loss: 2.4746648054129627

Epoch: 6| Step: 4
Training loss: 2.2857171829239333
Validation loss: 2.471591666051097

Epoch: 6| Step: 5
Training loss: 2.6937069741196153
Validation loss: 2.4788554955324082

Epoch: 6| Step: 6
Training loss: 2.977585984533123
Validation loss: 2.4753745004422623

Epoch: 6| Step: 7
Training loss: 2.4247784346205186
Validation loss: 2.473202741916335

Epoch: 6| Step: 8
Training loss: 2.9856337843476854
Validation loss: 2.471279441955262

Epoch: 6| Step: 9
Training loss: 2.446314792155109
Validation loss: 2.477096411817807

Epoch: 6| Step: 10
Training loss: 2.754960874082354
Validation loss: 2.470956870255958

Epoch: 6| Step: 11
Training loss: 2.3259961937096665
Validation loss: 2.4796346548627426

Epoch: 6| Step: 12
Training loss: 2.4951692639196104
Validation loss: 2.484398943707707

Epoch: 6| Step: 13
Training loss: 2.5166995200061177
Validation loss: 2.4694078751917106

Epoch: 102| Step: 0
Training loss: 2.806043206902543
Validation loss: 2.4673864727707255

Epoch: 6| Step: 1
Training loss: 2.549771773652945
Validation loss: 2.469139607586254

Epoch: 6| Step: 2
Training loss: 2.7373951826539122
Validation loss: 2.4722746624427057

Epoch: 6| Step: 3
Training loss: 2.2717173777475823
Validation loss: 2.4685113364959905

Epoch: 6| Step: 4
Training loss: 2.851234396256727
Validation loss: 2.467567176587228

Epoch: 6| Step: 5
Training loss: 2.4874377295592867
Validation loss: 2.465703009405601

Epoch: 6| Step: 6
Training loss: 2.4909021776150233
Validation loss: 2.457418778126029

Epoch: 6| Step: 7
Training loss: 2.3291861144899126
Validation loss: 2.4666159778189547

Epoch: 6| Step: 8
Training loss: 2.4516429919515916
Validation loss: 2.4653896849639003

Epoch: 6| Step: 9
Training loss: 2.5221270769670996
Validation loss: 2.46376554884537

Epoch: 6| Step: 10
Training loss: 2.248561611289133
Validation loss: 2.4641408265605595

Epoch: 6| Step: 11
Training loss: 2.4781473666284537
Validation loss: 2.4633324811862543

Epoch: 6| Step: 12
Training loss: 2.869366475273137
Validation loss: 2.465769824024164

Epoch: 6| Step: 13
Training loss: 2.500910593136196
Validation loss: 2.4684935488875093

Epoch: 103| Step: 0
Training loss: 2.5236844629901323
Validation loss: 2.4722740838210564

Epoch: 6| Step: 1
Training loss: 2.2474012201685936
Validation loss: 2.466099986718008

Epoch: 6| Step: 2
Training loss: 2.6932383642197597
Validation loss: 2.4701599730297628

Epoch: 6| Step: 3
Training loss: 2.414957318925924
Validation loss: 2.4711604764317143

Epoch: 6| Step: 4
Training loss: 2.82252225666039
Validation loss: 2.4723874267880936

Epoch: 6| Step: 5
Training loss: 2.178819928078431
Validation loss: 2.471304847109931

Epoch: 6| Step: 6
Training loss: 2.1756950101078174
Validation loss: 2.4651078346193454

Epoch: 6| Step: 7
Training loss: 2.805409967990592
Validation loss: 2.4708958084502144

Epoch: 6| Step: 8
Training loss: 2.5589650590843367
Validation loss: 2.4724043827834548

Epoch: 6| Step: 9
Training loss: 2.4948413076751352
Validation loss: 2.4664458616336487

Epoch: 6| Step: 10
Training loss: 2.7817432094836327
Validation loss: 2.470989933379872

Epoch: 6| Step: 11
Training loss: 2.968734901791377
Validation loss: 2.462452304203906

Epoch: 6| Step: 12
Training loss: 2.709909909429485
Validation loss: 2.458235243009538

Epoch: 6| Step: 13
Training loss: 2.1391919762134934
Validation loss: 2.4702168464841034

Epoch: 104| Step: 0
Training loss: 2.4566813160611782
Validation loss: 2.470361481417622

Epoch: 6| Step: 1
Training loss: 2.4582180922916543
Validation loss: 2.469277241093796

Epoch: 6| Step: 2
Training loss: 3.2147477832065374
Validation loss: 2.467208775562874

Epoch: 6| Step: 3
Training loss: 2.8139363329964002
Validation loss: 2.4669253692626367

Epoch: 6| Step: 4
Training loss: 2.5528067569058663
Validation loss: 2.471233149232916

Epoch: 6| Step: 5
Training loss: 1.9769863232152558
Validation loss: 2.466725432709728

Epoch: 6| Step: 6
Training loss: 2.9191294127394065
Validation loss: 2.4672161922835927

Epoch: 6| Step: 7
Training loss: 2.113376015955148
Validation loss: 2.463757904003928

Epoch: 6| Step: 8
Training loss: 2.7184132334530196
Validation loss: 2.4750324581085796

Epoch: 6| Step: 9
Training loss: 1.8587830186180243
Validation loss: 2.466420414484898

Epoch: 6| Step: 10
Training loss: 2.636293911086608
Validation loss: 2.4692459976330183

Epoch: 6| Step: 11
Training loss: 2.1497953805473338
Validation loss: 2.4639444700688458

Epoch: 6| Step: 12
Training loss: 2.6196677227290763
Validation loss: 2.4619513063338627

Epoch: 6| Step: 13
Training loss: 2.9160584678492025
Validation loss: 2.4613700688363274

Epoch: 105| Step: 0
Training loss: 2.692790214036419
Validation loss: 2.455663497440507

Epoch: 6| Step: 1
Training loss: 1.8920424011189168
Validation loss: 2.458379241277636

Epoch: 6| Step: 2
Training loss: 2.4201075842091666
Validation loss: 2.4594444145543672

Epoch: 6| Step: 3
Training loss: 1.9281367816286876
Validation loss: 2.4614332234676803

Epoch: 6| Step: 4
Training loss: 2.1955546724049126
Validation loss: 2.4619862093070535

Epoch: 6| Step: 5
Training loss: 3.166609127793498
Validation loss: 2.4606477274162843

Epoch: 6| Step: 6
Training loss: 2.9222235650211372
Validation loss: 2.4633333684003293

Epoch: 6| Step: 7
Training loss: 1.9699472087234904
Validation loss: 2.4662720118586177

Epoch: 6| Step: 8
Training loss: 2.508311664660908
Validation loss: 2.4671448748793807

Epoch: 6| Step: 9
Training loss: 3.1476313692512243
Validation loss: 2.462675290396062

Epoch: 6| Step: 10
Training loss: 2.724176975517415
Validation loss: 2.4678253502487246

Epoch: 6| Step: 11
Training loss: 2.8424072449110547
Validation loss: 2.4654479981400534

Epoch: 6| Step: 12
Training loss: 2.3663555231762303
Validation loss: 2.4623922418037547

Epoch: 6| Step: 13
Training loss: 2.725630374055536
Validation loss: 2.4662717943474006

Epoch: 106| Step: 0
Training loss: 2.602417309974541
Validation loss: 2.46548368164224

Epoch: 6| Step: 1
Training loss: 2.649975175561331
Validation loss: 2.4634488325524946

Epoch: 6| Step: 2
Training loss: 2.67434275030673
Validation loss: 2.462561919955531

Epoch: 6| Step: 3
Training loss: 2.4083898368287757
Validation loss: 2.4622939151046053

Epoch: 6| Step: 4
Training loss: 2.6242091486199577
Validation loss: 2.4607675483592315

Epoch: 6| Step: 5
Training loss: 2.2409375258746165
Validation loss: 2.4564783134183865

Epoch: 6| Step: 6
Training loss: 2.7420196047081355
Validation loss: 2.462486030164618

Epoch: 6| Step: 7
Training loss: 2.3729621777902192
Validation loss: 2.462717726323571

Epoch: 6| Step: 8
Training loss: 2.967144662589013
Validation loss: 2.461878052866401

Epoch: 6| Step: 9
Training loss: 2.8603238892054983
Validation loss: 2.464536862379961

Epoch: 6| Step: 10
Training loss: 2.420862983176245
Validation loss: 2.4668946114672186

Epoch: 6| Step: 11
Training loss: 2.0642632547798208
Validation loss: 2.4649269988706677

Epoch: 6| Step: 12
Training loss: 2.117702069689983
Validation loss: 2.460731021353057

Epoch: 6| Step: 13
Training loss: 2.780173018169159
Validation loss: 2.4681805625928086

Epoch: 107| Step: 0
Training loss: 2.3352574407885527
Validation loss: 2.470174901332333

Epoch: 6| Step: 1
Training loss: 2.623505666550365
Validation loss: 2.467580824252624

Epoch: 6| Step: 2
Training loss: 2.5327326823794625
Validation loss: 2.4639022729900306

Epoch: 6| Step: 3
Training loss: 2.6176290111209535
Validation loss: 2.464837156388723

Epoch: 6| Step: 4
Training loss: 2.8714054691006208
Validation loss: 2.462449028404163

Epoch: 6| Step: 5
Training loss: 2.628655204859541
Validation loss: 2.462904645459903

Epoch: 6| Step: 6
Training loss: 2.9512074214024038
Validation loss: 2.463339353054195

Epoch: 6| Step: 7
Training loss: 2.0279110976451586
Validation loss: 2.466074318471578

Epoch: 6| Step: 8
Training loss: 2.8366886541797203
Validation loss: 2.463236902162174

Epoch: 6| Step: 9
Training loss: 2.0661932505564478
Validation loss: 2.4667165647004783

Epoch: 6| Step: 10
Training loss: 2.9397901981777133
Validation loss: 2.4590952845440324

Epoch: 6| Step: 11
Training loss: 2.6712240575049235
Validation loss: 2.4623817041063996

Epoch: 6| Step: 12
Training loss: 2.263138030909348
Validation loss: 2.4617506106877474

Epoch: 6| Step: 13
Training loss: 2.169779363393736
Validation loss: 2.4681641571655883

Epoch: 108| Step: 0
Training loss: 2.465519686965153
Validation loss: 2.4658288856080337

Epoch: 6| Step: 1
Training loss: 2.2133492300121462
Validation loss: 2.464967413216821

Epoch: 6| Step: 2
Training loss: 3.07808270885248
Validation loss: 2.4683637196097674

Epoch: 6| Step: 3
Training loss: 2.3312105559011234
Validation loss: 2.46358487264047

Epoch: 6| Step: 4
Training loss: 2.388536925102504
Validation loss: 2.458332519746635

Epoch: 6| Step: 5
Training loss: 2.7872896089400587
Validation loss: 2.456752532854163

Epoch: 6| Step: 6
Training loss: 2.608031515223582
Validation loss: 2.465271910061965

Epoch: 6| Step: 7
Training loss: 2.0239125286998263
Validation loss: 2.4676810255964496

Epoch: 6| Step: 8
Training loss: 2.5028492903104103
Validation loss: 2.46314991799403

Epoch: 6| Step: 9
Training loss: 2.5535634218865932
Validation loss: 2.474331561930428

Epoch: 6| Step: 10
Training loss: 2.374452427432304
Validation loss: 2.467617129090624

Epoch: 6| Step: 11
Training loss: 3.166986616602023
Validation loss: 2.4646096740587686

Epoch: 6| Step: 12
Training loss: 2.2001806835191093
Validation loss: 2.463024614739508

Epoch: 6| Step: 13
Training loss: 2.634309880548021
Validation loss: 2.4676984648039557

Epoch: 109| Step: 0
Training loss: 2.800671435641368
Validation loss: 2.4671688811147443

Epoch: 6| Step: 1
Training loss: 2.8791702542832396
Validation loss: 2.4666162597385926

Epoch: 6| Step: 2
Training loss: 3.0005098545425626
Validation loss: 2.4621846747500182

Epoch: 6| Step: 3
Training loss: 2.4126080819857965
Validation loss: 2.463195023669405

Epoch: 6| Step: 4
Training loss: 2.3779128432411625
Validation loss: 2.4601008128234207

Epoch: 6| Step: 5
Training loss: 2.3684113111909113
Validation loss: 2.464198379140533

Epoch: 6| Step: 6
Training loss: 2.4994210526539353
Validation loss: 2.4623322182828344

Epoch: 6| Step: 7
Training loss: 2.4285149888284314
Validation loss: 2.4706460616969297

Epoch: 6| Step: 8
Training loss: 2.5793182386027453
Validation loss: 2.46681404661523

Epoch: 6| Step: 9
Training loss: 2.893354786853389
Validation loss: 2.4659131003066093

Epoch: 6| Step: 10
Training loss: 2.784151942162701
Validation loss: 2.469818366936224

Epoch: 6| Step: 11
Training loss: 2.7669243642756247
Validation loss: 2.468606654967117

Epoch: 6| Step: 12
Training loss: 1.7372799850688996
Validation loss: 2.467844253689347

Epoch: 6| Step: 13
Training loss: 1.4598053814233904
Validation loss: 2.4697325316618834

Epoch: 110| Step: 0
Training loss: 2.605577092012799
Validation loss: 2.4740015019448487

Epoch: 6| Step: 1
Training loss: 2.577477206139551
Validation loss: 2.470622322459997

Epoch: 6| Step: 2
Training loss: 2.281102005848047
Validation loss: 2.4719979694063885

Epoch: 6| Step: 3
Training loss: 2.2742210689573477
Validation loss: 2.466039561983279

Epoch: 6| Step: 4
Training loss: 2.1397480525790007
Validation loss: 2.470299391497602

Epoch: 6| Step: 5
Training loss: 3.0850236915902833
Validation loss: 2.4719991428534245

Epoch: 6| Step: 6
Training loss: 2.615802819919765
Validation loss: 2.472527475001902

Epoch: 6| Step: 7
Training loss: 2.601193788536102
Validation loss: 2.467855911275606

Epoch: 6| Step: 8
Training loss: 2.660536505007274
Validation loss: 2.4699299402893073

Epoch: 6| Step: 9
Training loss: 2.164343640075204
Validation loss: 2.4682839835018315

Epoch: 6| Step: 10
Training loss: 2.3056804005271414
Validation loss: 2.4627817822132254

Epoch: 6| Step: 11
Training loss: 2.6834515973995017
Validation loss: 2.462402376024522

Epoch: 6| Step: 12
Training loss: 2.582732735825484
Validation loss: 2.4700057461577796

Epoch: 6| Step: 13
Training loss: 2.635536754018241
Validation loss: 2.4698102420755665

Epoch: 111| Step: 0
Training loss: 1.9993542582421886
Validation loss: 2.4697638413690473

Epoch: 6| Step: 1
Training loss: 2.149965277103103
Validation loss: 2.4664831578666737

Epoch: 6| Step: 2
Training loss: 2.6879825602374403
Validation loss: 2.4712514799039966

Epoch: 6| Step: 3
Training loss: 2.8045868496912227
Validation loss: 2.468600610647482

Epoch: 6| Step: 4
Training loss: 2.50734005099371
Validation loss: 2.4710316636853498

Epoch: 6| Step: 5
Training loss: 2.140101682083298
Validation loss: 2.4785557536470653

Epoch: 6| Step: 6
Training loss: 2.820307089676251
Validation loss: 2.4691143813204808

Epoch: 6| Step: 7
Training loss: 2.7305999855297998
Validation loss: 2.4687001750441055

Epoch: 6| Step: 8
Training loss: 3.0567417115872617
Validation loss: 2.4631741970814502

Epoch: 6| Step: 9
Training loss: 2.7959071354759044
Validation loss: 2.4637009943490256

Epoch: 6| Step: 10
Training loss: 2.7657226717668646
Validation loss: 2.4707909127422014

Epoch: 6| Step: 11
Training loss: 2.503849022935884
Validation loss: 2.4662963488258525

Epoch: 6| Step: 12
Training loss: 2.468660377131125
Validation loss: 2.4699151231234153

Epoch: 6| Step: 13
Training loss: 1.6499802299239874
Validation loss: 2.467483469254848

Epoch: 112| Step: 0
Training loss: 2.11467771523096
Validation loss: 2.4715697044119325

Epoch: 6| Step: 1
Training loss: 2.9981147882678494
Validation loss: 2.4666180479138293

Epoch: 6| Step: 2
Training loss: 2.979379517391966
Validation loss: 2.4711988512173386

Epoch: 6| Step: 3
Training loss: 2.005188529837444
Validation loss: 2.4698216490505738

Epoch: 6| Step: 4
Training loss: 2.2769847344786007
Validation loss: 2.4680931086543434

Epoch: 6| Step: 5
Training loss: 2.639150896506073
Validation loss: 2.4633419824258245

Epoch: 6| Step: 6
Training loss: 2.738016548368659
Validation loss: 2.4672369847520166

Epoch: 6| Step: 7
Training loss: 2.6946916390340436
Validation loss: 2.4708535049369873

Epoch: 6| Step: 8
Training loss: 2.271991072972987
Validation loss: 2.4693600508471434

Epoch: 6| Step: 9
Training loss: 2.5162544173890256
Validation loss: 2.4649862418522654

Epoch: 6| Step: 10
Training loss: 2.520584335850424
Validation loss: 2.481308890411759

Epoch: 6| Step: 11
Training loss: 2.691813799337531
Validation loss: 2.466981375009705

Epoch: 6| Step: 12
Training loss: 2.4548307672040393
Validation loss: 2.4749741459790178

Epoch: 6| Step: 13
Training loss: 2.638389860340064
Validation loss: 2.4747661248882262

Epoch: 113| Step: 0
Training loss: 2.7549020252010834
Validation loss: 2.4730228194538664

Epoch: 6| Step: 1
Training loss: 2.663437039962598
Validation loss: 2.464332281650708

Epoch: 6| Step: 2
Training loss: 2.3978730074843355
Validation loss: 2.4682188629645836

Epoch: 6| Step: 3
Training loss: 2.7121777953998265
Validation loss: 2.4746416506811424

Epoch: 6| Step: 4
Training loss: 2.4154699475664017
Validation loss: 2.4633517739875135

Epoch: 6| Step: 5
Training loss: 2.9115594745099056
Validation loss: 2.461148740391306

Epoch: 6| Step: 6
Training loss: 2.675992948970429
Validation loss: 2.4708699487950474

Epoch: 6| Step: 7
Training loss: 2.474287365900569
Validation loss: 2.468443340457675

Epoch: 6| Step: 8
Training loss: 2.3073408984119306
Validation loss: 2.4665087735272464

Epoch: 6| Step: 9
Training loss: 2.272104193501145
Validation loss: 2.477703742083945

Epoch: 6| Step: 10
Training loss: 2.420918725018362
Validation loss: 2.467110342857084

Epoch: 6| Step: 11
Training loss: 2.48995833718248
Validation loss: 2.4645802336345755

Epoch: 6| Step: 12
Training loss: 2.7053754842766824
Validation loss: 2.4657333388900335

Epoch: 6| Step: 13
Training loss: 2.071109834117159
Validation loss: 2.4698739531372413

Epoch: 114| Step: 0
Training loss: 1.9980145971053294
Validation loss: 2.4734555238768707

Epoch: 6| Step: 1
Training loss: 1.8918664812715997
Validation loss: 2.47408571952655

Epoch: 6| Step: 2
Training loss: 2.4398401226758177
Validation loss: 2.4719304550772794

Epoch: 6| Step: 3
Training loss: 2.480334757392241
Validation loss: 2.4658253564562687

Epoch: 6| Step: 4
Training loss: 2.5637390118628036
Validation loss: 2.4684624806304085

Epoch: 6| Step: 5
Training loss: 2.4163442155415185
Validation loss: 2.4681985536989663

Epoch: 6| Step: 6
Training loss: 2.9161588680909194
Validation loss: 2.473117040171944

Epoch: 6| Step: 7
Training loss: 2.829043413117017
Validation loss: 2.4681095145538205

Epoch: 6| Step: 8
Training loss: 2.4371650661312034
Validation loss: 2.467793452377077

Epoch: 6| Step: 9
Training loss: 2.6367258933641664
Validation loss: 2.4616863423333606

Epoch: 6| Step: 10
Training loss: 2.5753580677735073
Validation loss: 2.4705068477625014

Epoch: 6| Step: 11
Training loss: 2.4616984810534968
Validation loss: 2.4697473981910334

Epoch: 6| Step: 12
Training loss: 3.1975992316505897
Validation loss: 2.462389369357798

Epoch: 6| Step: 13
Training loss: 2.2379691287477645
Validation loss: 2.4639755791665645

Epoch: 115| Step: 0
Training loss: 2.333380176437292
Validation loss: 2.4674899913787125

Epoch: 6| Step: 1
Training loss: 2.70416178142026
Validation loss: 2.465797832122154

Epoch: 6| Step: 2
Training loss: 2.6653915177801175
Validation loss: 2.470953710260107

Epoch: 6| Step: 3
Training loss: 2.2177359184340126
Validation loss: 2.4753371615939748

Epoch: 6| Step: 4
Training loss: 1.6653494000333036
Validation loss: 2.4702874237274104

Epoch: 6| Step: 5
Training loss: 2.455324389747049
Validation loss: 2.4742010673434716

Epoch: 6| Step: 6
Training loss: 2.6762254777806675
Validation loss: 2.4749226721811666

Epoch: 6| Step: 7
Training loss: 2.6800788615850815
Validation loss: 2.4724782806357952

Epoch: 6| Step: 8
Training loss: 2.3450283379052403
Validation loss: 2.4722227145371916

Epoch: 6| Step: 9
Training loss: 2.744559281203591
Validation loss: 2.4798363307428244

Epoch: 6| Step: 10
Training loss: 2.6986479976967006
Validation loss: 2.4595180232377785

Epoch: 6| Step: 11
Training loss: 2.7076911067001306
Validation loss: 2.46366518018813

Epoch: 6| Step: 12
Training loss: 2.7764335675376697
Validation loss: 2.470172327493499

Epoch: 6| Step: 13
Training loss: 2.522737955262907
Validation loss: 2.474895056352427

Epoch: 116| Step: 0
Training loss: 2.3062055340540475
Validation loss: 2.4701467015643312

Epoch: 6| Step: 1
Training loss: 2.5192241629414784
Validation loss: 2.4730253581901227

Epoch: 6| Step: 2
Training loss: 2.291637859741411
Validation loss: 2.4760898977505543

Epoch: 6| Step: 3
Training loss: 3.133728350095519
Validation loss: 2.473903749098018

Epoch: 6| Step: 4
Training loss: 2.5195819701774655
Validation loss: 2.4744047116914825

Epoch: 6| Step: 5
Training loss: 2.203598296277019
Validation loss: 2.477160168079879

Epoch: 6| Step: 6
Training loss: 2.4505927750624403
Validation loss: 2.481049004716683

Epoch: 6| Step: 7
Training loss: 3.4123642667388276
Validation loss: 2.4767679315797544

Epoch: 6| Step: 8
Training loss: 2.2005510377033644
Validation loss: 2.4779634414225677

Epoch: 6| Step: 9
Training loss: 3.0803495008164536
Validation loss: 2.477526552306314

Epoch: 6| Step: 10
Training loss: 2.3051020879749182
Validation loss: 2.4753772293987693

Epoch: 6| Step: 11
Training loss: 2.295223550650554
Validation loss: 2.476087634973595

Epoch: 6| Step: 12
Training loss: 2.4328406379459206
Validation loss: 2.4740634186494717

Epoch: 6| Step: 13
Training loss: 2.7647658053338815
Validation loss: 2.4697640022606593

Epoch: 117| Step: 0
Training loss: 3.1656863719718786
Validation loss: 2.4685032717228697

Epoch: 6| Step: 1
Training loss: 2.2665754758031347
Validation loss: 2.4699266100545545

Epoch: 6| Step: 2
Training loss: 2.3649886087865077
Validation loss: 2.4668138855312147

Epoch: 6| Step: 3
Training loss: 2.6257899775951636
Validation loss: 2.4620615012035376

Epoch: 6| Step: 4
Training loss: 2.3471385619874896
Validation loss: 2.46788912865378

Epoch: 6| Step: 5
Training loss: 2.2338365025947415
Validation loss: 2.4712487303120025

Epoch: 6| Step: 6
Training loss: 1.8813259223496435
Validation loss: 2.469023717522474

Epoch: 6| Step: 7
Training loss: 2.290614516584234
Validation loss: 2.4667998228561414

Epoch: 6| Step: 8
Training loss: 2.4224547645904178
Validation loss: 2.4778083852361004

Epoch: 6| Step: 9
Training loss: 2.407477325934792
Validation loss: 2.469552742545646

Epoch: 6| Step: 10
Training loss: 3.2747099595091917
Validation loss: 2.47587612841417

Epoch: 6| Step: 11
Training loss: 2.927690400040826
Validation loss: 2.4674338522370163

Epoch: 6| Step: 12
Training loss: 2.5425864780539067
Validation loss: 2.4639529529410757

Epoch: 6| Step: 13
Training loss: 2.731733168544464
Validation loss: 2.45981329211959

Epoch: 118| Step: 0
Training loss: 2.9518539680605618
Validation loss: 2.45861635895742

Epoch: 6| Step: 1
Training loss: 2.691478180166342
Validation loss: 2.4554159073176027

Epoch: 6| Step: 2
Training loss: 2.9049587867951785
Validation loss: 2.4510967268449186

Epoch: 6| Step: 3
Training loss: 2.392243479466768
Validation loss: 2.4576327947554373

Epoch: 6| Step: 4
Training loss: 2.7483013281993434
Validation loss: 2.489366774670338

Epoch: 6| Step: 5
Training loss: 2.4734178668825586
Validation loss: 2.511771526345803

Epoch: 6| Step: 6
Training loss: 2.2000997347332776
Validation loss: 2.496602101664672

Epoch: 6| Step: 7
Training loss: 2.75101296235237
Validation loss: 2.4687279326020013

Epoch: 6| Step: 8
Training loss: 2.610345808337513
Validation loss: 2.4695217519768757

Epoch: 6| Step: 9
Training loss: 2.4480187793834154
Validation loss: 2.4611680826013553

Epoch: 6| Step: 10
Training loss: 1.901626357649595
Validation loss: 2.4521748186761245

Epoch: 6| Step: 11
Training loss: 2.5312622446776563
Validation loss: 2.459773132335379

Epoch: 6| Step: 12
Training loss: 2.400288814809737
Validation loss: 2.460196602519585

Epoch: 6| Step: 13
Training loss: 2.72692973552138
Validation loss: 2.464912280597557

Epoch: 119| Step: 0
Training loss: 2.551751085309732
Validation loss: 2.4604080034233204

Epoch: 6| Step: 1
Training loss: 2.339786586158727
Validation loss: 2.4672545156785115

Epoch: 6| Step: 2
Training loss: 3.0650278674503224
Validation loss: 2.469263691312842

Epoch: 6| Step: 3
Training loss: 2.6921814354436915
Validation loss: 2.4724479213896022

Epoch: 6| Step: 4
Training loss: 2.4890141388432925
Validation loss: 2.4664448385972793

Epoch: 6| Step: 5
Training loss: 2.270608721715956
Validation loss: 2.4611958282357436

Epoch: 6| Step: 6
Training loss: 2.8884694903536894
Validation loss: 2.4654847937214077

Epoch: 6| Step: 7
Training loss: 2.5916037814574775
Validation loss: 2.4668923885794776

Epoch: 6| Step: 8
Training loss: 2.435727086011591
Validation loss: 2.4668454900135806

Epoch: 6| Step: 9
Training loss: 2.440551510533557
Validation loss: 2.4600306217489707

Epoch: 6| Step: 10
Training loss: 2.157509698415023
Validation loss: 2.463623615431538

Epoch: 6| Step: 11
Training loss: 2.3414596556617835
Validation loss: 2.476520317352171

Epoch: 6| Step: 12
Training loss: 2.915407744691994
Validation loss: 2.47773347562216

Epoch: 6| Step: 13
Training loss: 2.560853010160567
Validation loss: 2.474988964968141

Epoch: 120| Step: 0
Training loss: 2.0816018984115234
Validation loss: 2.472731875869645

Epoch: 6| Step: 1
Training loss: 2.3231662450807766
Validation loss: 2.465126871734796

Epoch: 6| Step: 2
Training loss: 2.3527736649770667
Validation loss: 2.4691801782839797

Epoch: 6| Step: 3
Training loss: 3.1680434061795144
Validation loss: 2.457038220353744

Epoch: 6| Step: 4
Training loss: 2.986089882787512
Validation loss: 2.4602320553102204

Epoch: 6| Step: 5
Training loss: 2.4062664477293993
Validation loss: 2.461496344192273

Epoch: 6| Step: 6
Training loss: 2.4560669187692454
Validation loss: 2.465160738415898

Epoch: 6| Step: 7
Training loss: 2.249348440138025
Validation loss: 2.459065770020894

Epoch: 6| Step: 8
Training loss: 2.2730345483613825
Validation loss: 2.464778087162514

Epoch: 6| Step: 9
Training loss: 2.8298570587399623
Validation loss: 2.466563024684738

Epoch: 6| Step: 10
Training loss: 2.638481669767292
Validation loss: 2.46354677443079

Epoch: 6| Step: 11
Training loss: 2.6971008559829106
Validation loss: 2.4566515865234027

Epoch: 6| Step: 12
Training loss: 2.6040008390398914
Validation loss: 2.462903015928386

Epoch: 6| Step: 13
Training loss: 1.9610682592071846
Validation loss: 2.468126950733724

Epoch: 121| Step: 0
Training loss: 2.307398142772508
Validation loss: 2.457530898258573

Epoch: 6| Step: 1
Training loss: 2.844323069082251
Validation loss: 2.45878237055415

Epoch: 6| Step: 2
Training loss: 2.6286400579443616
Validation loss: 2.4627646631574867

Epoch: 6| Step: 3
Training loss: 2.2417236273618046
Validation loss: 2.4581679972853374

Epoch: 6| Step: 4
Training loss: 2.2981572107999395
Validation loss: 2.4632105588019897

Epoch: 6| Step: 5
Training loss: 2.2071737327832244
Validation loss: 2.460292598450546

Epoch: 6| Step: 6
Training loss: 2.9658196693899535
Validation loss: 2.464814989473319

Epoch: 6| Step: 7
Training loss: 2.614928953471138
Validation loss: 2.4656915027979496

Epoch: 6| Step: 8
Training loss: 2.2256664949494844
Validation loss: 2.463947147176164

Epoch: 6| Step: 9
Training loss: 2.4578825866057548
Validation loss: 2.463994246049351

Epoch: 6| Step: 10
Training loss: 2.4839767040812717
Validation loss: 2.460801991763588

Epoch: 6| Step: 11
Training loss: 2.8466252473889613
Validation loss: 2.462003479034503

Epoch: 6| Step: 12
Training loss: 2.669901872181837
Validation loss: 2.466528299248326

Epoch: 6| Step: 13
Training loss: 2.2934998087378737
Validation loss: 2.4633207376680297

Epoch: 122| Step: 0
Training loss: 1.9828304978343685
Validation loss: 2.463844786068521

Epoch: 6| Step: 1
Training loss: 2.4576145565307184
Validation loss: 2.473994209966358

Epoch: 6| Step: 2
Training loss: 2.445814087340901
Validation loss: 2.4759138443151523

Epoch: 6| Step: 3
Training loss: 1.9672068042732083
Validation loss: 2.4833537947901982

Epoch: 6| Step: 4
Training loss: 2.6961599593321894
Validation loss: 2.472867421337704

Epoch: 6| Step: 5
Training loss: 2.4075580360967566
Validation loss: 2.4596379961465074

Epoch: 6| Step: 6
Training loss: 2.8032124075131626
Validation loss: 2.4592096631039992

Epoch: 6| Step: 7
Training loss: 2.6804691876172315
Validation loss: 2.4634102805804727

Epoch: 6| Step: 8
Training loss: 2.305810376783586
Validation loss: 2.4699751312919003

Epoch: 6| Step: 9
Training loss: 2.7688147474860063
Validation loss: 2.47253459452363

Epoch: 6| Step: 10
Training loss: 2.7511252788609597
Validation loss: 2.4817908740893984

Epoch: 6| Step: 11
Training loss: 3.070236709862913
Validation loss: 2.4725565797344657

Epoch: 6| Step: 12
Training loss: 2.5485765822656004
Validation loss: 2.476227730669035

Epoch: 6| Step: 13
Training loss: 2.6740796546969774
Validation loss: 2.476591364775556

Epoch: 123| Step: 0
Training loss: 2.7062118633305405
Validation loss: 2.479270777933861

Epoch: 6| Step: 1
Training loss: 2.7270342137338055
Validation loss: 2.483046794421225

Epoch: 6| Step: 2
Training loss: 2.1907877601748273
Validation loss: 2.479014581668958

Epoch: 6| Step: 3
Training loss: 2.89781786935112
Validation loss: 2.479174178510126

Epoch: 6| Step: 4
Training loss: 2.6005283625808433
Validation loss: 2.4789839337961777

Epoch: 6| Step: 5
Training loss: 2.565421509194235
Validation loss: 2.476879432527303

Epoch: 6| Step: 6
Training loss: 2.188331881791636
Validation loss: 2.4699579655652317

Epoch: 6| Step: 7
Training loss: 2.949125457702842
Validation loss: 2.462336244640882

Epoch: 6| Step: 8
Training loss: 2.8828644373073806
Validation loss: 2.4672144367534496

Epoch: 6| Step: 9
Training loss: 2.724376687672655
Validation loss: 2.4702022160317103

Epoch: 6| Step: 10
Training loss: 2.105556847139408
Validation loss: 2.4560618224144624

Epoch: 6| Step: 11
Training loss: 1.9670391217691718
Validation loss: 2.466008430582049

Epoch: 6| Step: 12
Training loss: 2.3406733346183337
Validation loss: 2.4616041945543525

Epoch: 6| Step: 13
Training loss: 2.5335728854138666
Validation loss: 2.466304904167413

Epoch: 124| Step: 0
Training loss: 2.5280164622241617
Validation loss: 2.463950420984171

Epoch: 6| Step: 1
Training loss: 2.0311427161421727
Validation loss: 2.4657374322137704

Epoch: 6| Step: 2
Training loss: 2.5963786948884224
Validation loss: 2.463604389276655

Epoch: 6| Step: 3
Training loss: 2.6829891939802235
Validation loss: 2.4687520280660675

Epoch: 6| Step: 4
Training loss: 2.702820865522448
Validation loss: 2.4657731034698034

Epoch: 6| Step: 5
Training loss: 2.1856040367580682
Validation loss: 2.46574189618506

Epoch: 6| Step: 6
Training loss: 2.8584766748666737
Validation loss: 2.465622026887301

Epoch: 6| Step: 7
Training loss: 2.5481959000979257
Validation loss: 2.4677122003072247

Epoch: 6| Step: 8
Training loss: 2.8291816212891376
Validation loss: 2.4676685942486394

Epoch: 6| Step: 9
Training loss: 2.2263698561466922
Validation loss: 2.461883282446957

Epoch: 6| Step: 10
Training loss: 2.53571246471378
Validation loss: 2.4629973333739015

Epoch: 6| Step: 11
Training loss: 2.4821464091605856
Validation loss: 2.4689381362758036

Epoch: 6| Step: 12
Training loss: 2.339269806486431
Validation loss: 2.4698485493528373

Epoch: 6| Step: 13
Training loss: 2.4635940019292044
Validation loss: 2.4675194776050358

Epoch: 125| Step: 0
Training loss: 2.414495929214544
Validation loss: 2.470029587845159

Epoch: 6| Step: 1
Training loss: 2.4803189930801404
Validation loss: 2.4752344046156867

Epoch: 6| Step: 2
Training loss: 2.2464183274312126
Validation loss: 2.473617664104532

Epoch: 6| Step: 3
Training loss: 2.2302910889320318
Validation loss: 2.4623523015944655

Epoch: 6| Step: 4
Training loss: 2.3022192200015574
Validation loss: 2.467754034346743

Epoch: 6| Step: 5
Training loss: 2.2470736016585553
Validation loss: 2.4808587195759397

Epoch: 6| Step: 6
Training loss: 3.0567764983279333
Validation loss: 2.468059346612287

Epoch: 6| Step: 7
Training loss: 2.3701278503957712
Validation loss: 2.4664433000142245

Epoch: 6| Step: 8
Training loss: 2.6886344112306193
Validation loss: 2.469604400674487

Epoch: 6| Step: 9
Training loss: 2.6106552364104334
Validation loss: 2.470755575274184

Epoch: 6| Step: 10
Training loss: 2.7549838074971573
Validation loss: 2.458308112020479

Epoch: 6| Step: 11
Training loss: 2.5035816285707058
Validation loss: 2.462169165422165

Epoch: 6| Step: 12
Training loss: 2.972197769238745
Validation loss: 2.4674867222669303

Epoch: 6| Step: 13
Training loss: 2.19155214201447
Validation loss: 2.4658188943890313

Epoch: 126| Step: 0
Training loss: 2.391808410148211
Validation loss: 2.4656863135259495

Epoch: 6| Step: 1
Training loss: 2.520841982067394
Validation loss: 2.460359204682102

Epoch: 6| Step: 2
Training loss: 2.283483378731359
Validation loss: 2.4604677912616824

Epoch: 6| Step: 3
Training loss: 2.332579888450691
Validation loss: 2.4654738179615774

Epoch: 6| Step: 4
Training loss: 2.6584698545344203
Validation loss: 2.4638972009057243

Epoch: 6| Step: 5
Training loss: 2.4199314317368295
Validation loss: 2.4677122647173766

Epoch: 6| Step: 6
Training loss: 2.7486109259769567
Validation loss: 2.4630598816277303

Epoch: 6| Step: 7
Training loss: 2.2168375288810784
Validation loss: 2.454181937497808

Epoch: 6| Step: 8
Training loss: 3.2894769620377122
Validation loss: 2.468013573111003

Epoch: 6| Step: 9
Training loss: 2.523892671615509
Validation loss: 2.462509863974087

Epoch: 6| Step: 10
Training loss: 2.329518969738408
Validation loss: 2.4581259516082015

Epoch: 6| Step: 11
Training loss: 2.5808680882226724
Validation loss: 2.454099773300577

Epoch: 6| Step: 12
Training loss: 2.420735540291478
Validation loss: 2.4586531598081454

Epoch: 6| Step: 13
Training loss: 2.22802739725441
Validation loss: 2.452124211292821

Epoch: 127| Step: 0
Training loss: 2.7773491581731364
Validation loss: 2.450828886921972

Epoch: 6| Step: 1
Training loss: 2.735832654162983
Validation loss: 2.461181612370786

Epoch: 6| Step: 2
Training loss: 2.3916018615697547
Validation loss: 2.460353406587621

Epoch: 6| Step: 3
Training loss: 2.776408320983324
Validation loss: 2.459380497940426

Epoch: 6| Step: 4
Training loss: 2.144886980969583
Validation loss: 2.446964189536821

Epoch: 6| Step: 5
Training loss: 2.6379780340661165
Validation loss: 2.4635913244381347

Epoch: 6| Step: 6
Training loss: 1.949513629021349
Validation loss: 2.4624957121732662

Epoch: 6| Step: 7
Training loss: 2.744858182985443
Validation loss: 2.4627938187259377

Epoch: 6| Step: 8
Training loss: 2.497677868990245
Validation loss: 2.467709398463996

Epoch: 6| Step: 9
Training loss: 2.7826781303097734
Validation loss: 2.457089680682954

Epoch: 6| Step: 10
Training loss: 2.760683116409066
Validation loss: 2.4637862091526133

Epoch: 6| Step: 11
Training loss: 2.574179572355752
Validation loss: 2.457430784312094

Epoch: 6| Step: 12
Training loss: 2.13629938504907
Validation loss: 2.462122394766001

Epoch: 6| Step: 13
Training loss: 2.0044703591206487
Validation loss: 2.464899528988682

Epoch: 128| Step: 0
Training loss: 2.590791048588498
Validation loss: 2.4570804544524383

Epoch: 6| Step: 1
Training loss: 2.8531305887558216
Validation loss: 2.4665575392098997

Epoch: 6| Step: 2
Training loss: 3.0050721206515796
Validation loss: 2.47192228893342

Epoch: 6| Step: 3
Training loss: 2.1880441261388923
Validation loss: 2.475785078256604

Epoch: 6| Step: 4
Training loss: 2.608930629879733
Validation loss: 2.447949645990375

Epoch: 6| Step: 5
Training loss: 2.3926523625281164
Validation loss: 2.459518459454753

Epoch: 6| Step: 6
Training loss: 1.5458213994198744
Validation loss: 2.472753425444331

Epoch: 6| Step: 7
Training loss: 2.731851863235108
Validation loss: 2.480039071741779

Epoch: 6| Step: 8
Training loss: 1.8499964920216887
Validation loss: 2.4764627302191795

Epoch: 6| Step: 9
Training loss: 2.1953937339007292
Validation loss: 2.4736553421530636

Epoch: 6| Step: 10
Training loss: 3.107596190506732
Validation loss: 2.4746779563049555

Epoch: 6| Step: 11
Training loss: 2.1908565382552596
Validation loss: 2.4750370337544476

Epoch: 6| Step: 12
Training loss: 3.155342651477012
Validation loss: 2.480415019256884

Epoch: 6| Step: 13
Training loss: 3.0414527573987207
Validation loss: 2.4813606480959165

Epoch: 129| Step: 0
Training loss: 2.6642232270292934
Validation loss: 2.490044943392415

Epoch: 6| Step: 1
Training loss: 2.6300696509533674
Validation loss: 2.491859829048543

Epoch: 6| Step: 2
Training loss: 2.9167857191220636
Validation loss: 2.4944056064222573

Epoch: 6| Step: 3
Training loss: 2.6865572495657135
Validation loss: 2.490541223308006

Epoch: 6| Step: 4
Training loss: 2.510207414150162
Validation loss: 2.4972724022194783

Epoch: 6| Step: 5
Training loss: 2.6625523915755203
Validation loss: 2.495213711159939

Epoch: 6| Step: 6
Training loss: 3.004765857581372
Validation loss: 2.494272920091613

Epoch: 6| Step: 7
Training loss: 2.3600505341760685
Validation loss: 2.495396858561774

Epoch: 6| Step: 8
Training loss: 2.7879447513781654
Validation loss: 2.4895302089838305

Epoch: 6| Step: 9
Training loss: 2.9684796661970734
Validation loss: 2.484121441647535

Epoch: 6| Step: 10
Training loss: 2.209738038706632
Validation loss: 2.4845796256896273

Epoch: 6| Step: 11
Training loss: 2.0862405963957764
Validation loss: 2.485879062914425

Epoch: 6| Step: 12
Training loss: 2.6085081202369844
Validation loss: 2.482105698197917

Epoch: 6| Step: 13
Training loss: 2.2409530591018956
Validation loss: 2.483832398026793

Epoch: 130| Step: 0
Training loss: 2.725179151892974
Validation loss: 2.4858061149335553

Epoch: 6| Step: 1
Training loss: 2.5084641225012034
Validation loss: 2.477234934623803

Epoch: 6| Step: 2
Training loss: 2.44781161684848
Validation loss: 2.4723162826641714

Epoch: 6| Step: 3
Training loss: 2.6876613657212793
Validation loss: 2.4700991328290876

Epoch: 6| Step: 4
Training loss: 2.913434735707755
Validation loss: 2.468132231473049

Epoch: 6| Step: 5
Training loss: 2.521736823814401
Validation loss: 2.4670099653164645

Epoch: 6| Step: 6
Training loss: 1.9489629726738678
Validation loss: 2.46295769338222

Epoch: 6| Step: 7
Training loss: 2.5000635139026697
Validation loss: 2.4594038286664324

Epoch: 6| Step: 8
Training loss: 2.6016907989666516
Validation loss: 2.4661944074724533

Epoch: 6| Step: 9
Training loss: 2.6418659973352123
Validation loss: 2.462483303058644

Epoch: 6| Step: 10
Training loss: 2.7474333316118176
Validation loss: 2.4635699850528825

Epoch: 6| Step: 11
Training loss: 2.6607405459167843
Validation loss: 2.4631012139070863

Epoch: 6| Step: 12
Training loss: 2.684852715684686
Validation loss: 2.4646159780688377

Epoch: 6| Step: 13
Training loss: 2.3975727125165984
Validation loss: 2.4619422274447125

Epoch: 131| Step: 0
Training loss: 2.4991715966057644
Validation loss: 2.464248206430372

Epoch: 6| Step: 1
Training loss: 2.345969204894843
Validation loss: 2.466912322012122

Epoch: 6| Step: 2
Training loss: 2.4158714454945662
Validation loss: 2.465367168423681

Epoch: 6| Step: 3
Training loss: 2.5181624605219155
Validation loss: 2.463017661327294

Epoch: 6| Step: 4
Training loss: 2.3952761015891757
Validation loss: 2.4563268754623753

Epoch: 6| Step: 5
Training loss: 2.8338857747966353
Validation loss: 2.4658981139747507

Epoch: 6| Step: 6
Training loss: 2.546242196506983
Validation loss: 2.465633195380776

Epoch: 6| Step: 7
Training loss: 2.3084097077258936
Validation loss: 2.466432086856378

Epoch: 6| Step: 8
Training loss: 2.8592335817146326
Validation loss: 2.478773331627728

Epoch: 6| Step: 9
Training loss: 2.797478125983552
Validation loss: 2.470146186790902

Epoch: 6| Step: 10
Training loss: 2.3688515835119413
Validation loss: 2.48095116917729

Epoch: 6| Step: 11
Training loss: 2.3326433614849664
Validation loss: 2.4738553049150576

Epoch: 6| Step: 12
Training loss: 2.8782062067593297
Validation loss: 2.468244653800636

Epoch: 6| Step: 13
Training loss: 2.022625970300704
Validation loss: 2.4684922932867734

Epoch: 132| Step: 0
Training loss: 2.4597393691776017
Validation loss: 2.467033884276298

Epoch: 6| Step: 1
Training loss: 2.778192790076493
Validation loss: 2.47406015019291

Epoch: 6| Step: 2
Training loss: 2.0193704507883368
Validation loss: 2.4672453435648443

Epoch: 6| Step: 3
Training loss: 2.860806799777695
Validation loss: 2.46718956929322

Epoch: 6| Step: 4
Training loss: 2.2180841010808794
Validation loss: 2.470018254224221

Epoch: 6| Step: 5
Training loss: 2.437195489887201
Validation loss: 2.4781966488884266

Epoch: 6| Step: 6
Training loss: 2.3737283615082236
Validation loss: 2.4667051433663896

Epoch: 6| Step: 7
Training loss: 2.5750436575438553
Validation loss: 2.467863189188278

Epoch: 6| Step: 8
Training loss: 2.5208639242874993
Validation loss: 2.4832330954459665

Epoch: 6| Step: 9
Training loss: 2.390619614538971
Validation loss: 2.4815098537562257

Epoch: 6| Step: 10
Training loss: 2.6004816049410384
Validation loss: 2.473312813047368

Epoch: 6| Step: 11
Training loss: 2.5886368506960364
Validation loss: 2.4801641482460544

Epoch: 6| Step: 12
Training loss: 2.9992244035767404
Validation loss: 2.470151913639258

Epoch: 6| Step: 13
Training loss: 2.0785610343849252
Validation loss: 2.468938345504848

Epoch: 133| Step: 0
Training loss: 2.3521776376970824
Validation loss: 2.4680857187189544

Epoch: 6| Step: 1
Training loss: 2.034379631541147
Validation loss: 2.463752468733032

Epoch: 6| Step: 2
Training loss: 1.9100447858183291
Validation loss: 2.476295946219051

Epoch: 6| Step: 3
Training loss: 2.903027460371146
Validation loss: 2.4680753180316626

Epoch: 6| Step: 4
Training loss: 2.5951738241260833
Validation loss: 2.4713932485809846

Epoch: 6| Step: 5
Training loss: 2.727604008552547
Validation loss: 2.4653365765456217

Epoch: 6| Step: 6
Training loss: 2.2125574654050744
Validation loss: 2.469298032299569

Epoch: 6| Step: 7
Training loss: 2.308466099342055
Validation loss: 2.4735980577985375

Epoch: 6| Step: 8
Training loss: 2.6877636447489537
Validation loss: 2.4622734197950775

Epoch: 6| Step: 9
Training loss: 2.7272376506168095
Validation loss: 2.4729604267810945

Epoch: 6| Step: 10
Training loss: 3.1743600816220283
Validation loss: 2.4626738059321287

Epoch: 6| Step: 11
Training loss: 2.8882636245383737
Validation loss: 2.4727282280110487

Epoch: 6| Step: 12
Training loss: 2.2686001940993754
Validation loss: 2.45789988516613

Epoch: 6| Step: 13
Training loss: 1.804216860219062
Validation loss: 2.463836028650084

Epoch: 134| Step: 0
Training loss: 2.9184870534076732
Validation loss: 2.462669965684323

Epoch: 6| Step: 1
Training loss: 2.9444480052262696
Validation loss: 2.46980411221251

Epoch: 6| Step: 2
Training loss: 2.2868973318522863
Validation loss: 2.4721131253072146

Epoch: 6| Step: 3
Training loss: 2.5168111149173247
Validation loss: 2.475482436404752

Epoch: 6| Step: 4
Training loss: 2.8000092233778404
Validation loss: 2.476025592354314

Epoch: 6| Step: 5
Training loss: 3.259228442107395
Validation loss: 2.469933793381401

Epoch: 6| Step: 6
Training loss: 1.9938423015789573
Validation loss: 2.4701081576071324

Epoch: 6| Step: 7
Training loss: 2.6047775976094028
Validation loss: 2.4706943436417563

Epoch: 6| Step: 8
Training loss: 1.9896378900793799
Validation loss: 2.461317043201802

Epoch: 6| Step: 9
Training loss: 2.8667239612206172
Validation loss: 2.4659961680536955

Epoch: 6| Step: 10
Training loss: 2.2970881979471205
Validation loss: 2.4722883564488707

Epoch: 6| Step: 11
Training loss: 2.2971935440583855
Validation loss: 2.471820113404206

Epoch: 6| Step: 12
Training loss: 1.822448786681844
Validation loss: 2.469858355341112

Epoch: 6| Step: 13
Training loss: 2.1581565057889116
Validation loss: 2.462783960406883

Epoch: 135| Step: 0
Training loss: 2.0670936753482643
Validation loss: 2.4697675096951945

Epoch: 6| Step: 1
Training loss: 2.631624310253069
Validation loss: 2.468978983886853

Epoch: 6| Step: 2
Training loss: 2.3815688593085897
Validation loss: 2.4682025302389623

Epoch: 6| Step: 3
Training loss: 2.8164399418819546
Validation loss: 2.466598845099354

Epoch: 6| Step: 4
Training loss: 3.033274495598678
Validation loss: 2.4675822171959383

Epoch: 6| Step: 5
Training loss: 2.1184891081568944
Validation loss: 2.465796687954073

Epoch: 6| Step: 6
Training loss: 2.050822288465875
Validation loss: 2.4605926272021597

Epoch: 6| Step: 7
Training loss: 3.0346123049626397
Validation loss: 2.4585807778131694

Epoch: 6| Step: 8
Training loss: 2.9753413862010722
Validation loss: 2.454965941405895

Epoch: 6| Step: 9
Training loss: 2.380971729109125
Validation loss: 2.4538058006457053

Epoch: 6| Step: 10
Training loss: 2.455782962882696
Validation loss: 2.4488881773792825

Epoch: 6| Step: 11
Training loss: 2.7586207947854318
Validation loss: 2.467972387504574

Epoch: 6| Step: 12
Training loss: 1.6431668889919082
Validation loss: 2.4574183253663495

Epoch: 6| Step: 13
Training loss: 2.5540944382213095
Validation loss: 2.455389091647147

Epoch: 136| Step: 0
Training loss: 3.035339742683778
Validation loss: 2.4581095114073763

Epoch: 6| Step: 1
Training loss: 2.072164836880998
Validation loss: 2.4590954542131382

Epoch: 6| Step: 2
Training loss: 2.934905834344558
Validation loss: 2.4597836488989566

Epoch: 6| Step: 3
Training loss: 3.2149463882841056
Validation loss: 2.4657812496905893

Epoch: 6| Step: 4
Training loss: 1.730725133774274
Validation loss: 2.4662060486888637

Epoch: 6| Step: 5
Training loss: 2.680675002112241
Validation loss: 2.4701766869314485

Epoch: 6| Step: 6
Training loss: 2.4151472598842227
Validation loss: 2.470556684534316

Epoch: 6| Step: 7
Training loss: 2.525967112486431
Validation loss: 2.476177245779813

Epoch: 6| Step: 8
Training loss: 2.5667482842023226
Validation loss: 2.4721484473885047

Epoch: 6| Step: 9
Training loss: 2.618551143843867
Validation loss: 2.4799428467420155

Epoch: 6| Step: 10
Training loss: 2.2298775605942356
Validation loss: 2.47876712774559

Epoch: 6| Step: 11
Training loss: 2.2417812710458427
Validation loss: 2.475848089880565

Epoch: 6| Step: 12
Training loss: 2.3358209383151745
Validation loss: 2.469495894024001

Epoch: 6| Step: 13
Training loss: 2.389122983517402
Validation loss: 2.4711062136446422

Epoch: 137| Step: 0
Training loss: 2.8628099165480987
Validation loss: 2.484908056752136

Epoch: 6| Step: 1
Training loss: 2.0752803291408712
Validation loss: 2.4779605389188846

Epoch: 6| Step: 2
Training loss: 2.5097581202769605
Validation loss: 2.4892232200839914

Epoch: 6| Step: 3
Training loss: 2.3158201148319475
Validation loss: 2.479736252008825

Epoch: 6| Step: 4
Training loss: 2.7176453549588824
Validation loss: 2.481243983596951

Epoch: 6| Step: 5
Training loss: 2.9013634074676653
Validation loss: 2.467284721406181

Epoch: 6| Step: 6
Training loss: 2.7779280293412842
Validation loss: 2.4592171605027047

Epoch: 6| Step: 7
Training loss: 2.6230386036552855
Validation loss: 2.469839443182841

Epoch: 6| Step: 8
Training loss: 2.576111718343788
Validation loss: 2.471096163360675

Epoch: 6| Step: 9
Training loss: 2.3787685410803827
Validation loss: 2.473906961543455

Epoch: 6| Step: 10
Training loss: 2.328986706090964
Validation loss: 2.47211534350055

Epoch: 6| Step: 11
Training loss: 2.650217184127911
Validation loss: 2.478959360724909

Epoch: 6| Step: 12
Training loss: 2.5799184398918777
Validation loss: 2.476613538599221

Epoch: 6| Step: 13
Training loss: 2.035811481689071
Validation loss: 2.4779522803953316

Epoch: 138| Step: 0
Training loss: 2.1022722258321176
Validation loss: 2.4804018026613903

Epoch: 6| Step: 1
Training loss: 2.5503061036033334
Validation loss: 2.4742224515504394

Epoch: 6| Step: 2
Training loss: 2.243042148304629
Validation loss: 2.4739362909773934

Epoch: 6| Step: 3
Training loss: 2.669138081048473
Validation loss: 2.475490358051242

Epoch: 6| Step: 4
Training loss: 2.741569949437492
Validation loss: 2.4796717046512224

Epoch: 6| Step: 5
Training loss: 2.520773600561559
Validation loss: 2.467582990158363

Epoch: 6| Step: 6
Training loss: 2.76993548156297
Validation loss: 2.4709780654417406

Epoch: 6| Step: 7
Training loss: 2.2371642303002615
Validation loss: 2.473892666129239

Epoch: 6| Step: 8
Training loss: 2.467179003767927
Validation loss: 2.474390274621232

Epoch: 6| Step: 9
Training loss: 2.3205775870512095
Validation loss: 2.4741871510479245

Epoch: 6| Step: 10
Training loss: 1.9482559547798342
Validation loss: 2.4780079888150124

Epoch: 6| Step: 11
Training loss: 1.8622758820120817
Validation loss: 2.4866977445877954

Epoch: 6| Step: 12
Training loss: 3.454160509153859
Validation loss: 2.48361965508724

Epoch: 6| Step: 13
Training loss: 2.864570275479235
Validation loss: 2.506154162698313

Epoch: 139| Step: 0
Training loss: 2.261650651028439
Validation loss: 2.4944462600121784

Epoch: 6| Step: 1
Training loss: 2.2708424442586783
Validation loss: 2.4834385192492667

Epoch: 6| Step: 2
Training loss: 2.56360425649222
Validation loss: 2.475962585247674

Epoch: 6| Step: 3
Training loss: 2.6760233303187775
Validation loss: 2.479209311837107

Epoch: 6| Step: 4
Training loss: 2.6487750623164494
Validation loss: 2.4660975536439644

Epoch: 6| Step: 5
Training loss: 2.1752956540212103
Validation loss: 2.47353504508275

Epoch: 6| Step: 6
Training loss: 2.1983777567453093
Validation loss: 2.474956886481134

Epoch: 6| Step: 7
Training loss: 2.3668675977632962
Validation loss: 2.4793057816740474

Epoch: 6| Step: 8
Training loss: 2.495304657524268
Validation loss: 2.47118527981297

Epoch: 6| Step: 9
Training loss: 3.022477187203895
Validation loss: 2.4777244946557793

Epoch: 6| Step: 10
Training loss: 2.231673307895631
Validation loss: 2.4750229856920067

Epoch: 6| Step: 11
Training loss: 2.2965948232404885
Validation loss: 2.4710375492902243

Epoch: 6| Step: 12
Training loss: 2.9988195958077712
Validation loss: 2.4681759098379716

Epoch: 6| Step: 13
Training loss: 3.088844803359062
Validation loss: 2.4712358023647774

Epoch: 140| Step: 0
Training loss: 2.419499074779254
Validation loss: 2.4640155898236773

Epoch: 6| Step: 1
Training loss: 2.8940383141333625
Validation loss: 2.4677314830213226

Epoch: 6| Step: 2
Training loss: 2.1800370568441876
Validation loss: 2.4614349024030484

Epoch: 6| Step: 3
Training loss: 2.7644511172298243
Validation loss: 2.4691985322421917

Epoch: 6| Step: 4
Training loss: 2.4466233320149153
Validation loss: 2.46486643253294

Epoch: 6| Step: 5
Training loss: 2.6610710822828763
Validation loss: 2.471954760448183

Epoch: 6| Step: 6
Training loss: 2.2578590678656223
Validation loss: 2.463783160921456

Epoch: 6| Step: 7
Training loss: 2.793077501433878
Validation loss: 2.4713367720146873

Epoch: 6| Step: 8
Training loss: 2.710575486342907
Validation loss: 2.4748457083469653

Epoch: 6| Step: 9
Training loss: 2.6819111575745387
Validation loss: 2.4695839901708667

Epoch: 6| Step: 10
Training loss: 2.7815159016918716
Validation loss: 2.4690381135497885

Epoch: 6| Step: 11
Training loss: 1.8951686769968576
Validation loss: 2.4663554783580635

Epoch: 6| Step: 12
Training loss: 1.7195001525701359
Validation loss: 2.474909482450242

Epoch: 6| Step: 13
Training loss: 2.8553074322806142
Validation loss: 2.4683477822532756

Epoch: 141| Step: 0
Training loss: 2.372669682921618
Validation loss: 2.470945372032825

Epoch: 6| Step: 1
Training loss: 2.7297960579678704
Validation loss: 2.4692934621114535

Epoch: 6| Step: 2
Training loss: 2.922966248428662
Validation loss: 2.4725190215476767

Epoch: 6| Step: 3
Training loss: 2.838164828889835
Validation loss: 2.4713364745546227

Epoch: 6| Step: 4
Training loss: 3.004796009217071
Validation loss: 2.472192287859144

Epoch: 6| Step: 5
Training loss: 2.4656810758956205
Validation loss: 2.471693891215424

Epoch: 6| Step: 6
Training loss: 2.48676669559644
Validation loss: 2.480003269203656

Epoch: 6| Step: 7
Training loss: 2.382757567726183
Validation loss: 2.478996436635224

Epoch: 6| Step: 8
Training loss: 2.5403183868186074
Validation loss: 2.4759441450142914

Epoch: 6| Step: 9
Training loss: 2.3089960719125147
Validation loss: 2.474982318108587

Epoch: 6| Step: 10
Training loss: 2.273159154258315
Validation loss: 2.467740991477483

Epoch: 6| Step: 11
Training loss: 2.463592937384911
Validation loss: 2.472187337260152

Epoch: 6| Step: 12
Training loss: 2.505732829703714
Validation loss: 2.4682999856650754

Epoch: 6| Step: 13
Training loss: 1.7321533545511671
Validation loss: 2.4630337703045373

Epoch: 142| Step: 0
Training loss: 2.4865157782496814
Validation loss: 2.4758670363886908

Epoch: 6| Step: 1
Training loss: 2.9322581495376197
Validation loss: 2.4675896891559024

Epoch: 6| Step: 2
Training loss: 2.356156838596528
Validation loss: 2.4646378081990563

Epoch: 6| Step: 3
Training loss: 2.380274487222321
Validation loss: 2.475972214557782

Epoch: 6| Step: 4
Training loss: 2.9802655591984966
Validation loss: 2.468772920268734

Epoch: 6| Step: 5
Training loss: 1.9777094110657207
Validation loss: 2.4621135021080107

Epoch: 6| Step: 6
Training loss: 2.940047437843066
Validation loss: 2.4690397551261074

Epoch: 6| Step: 7
Training loss: 2.1126184464153193
Validation loss: 2.4675697048330036

Epoch: 6| Step: 8
Training loss: 2.3744283289291324
Validation loss: 2.4659995197100764

Epoch: 6| Step: 9
Training loss: 2.54644416020123
Validation loss: 2.47043182129913

Epoch: 6| Step: 10
Training loss: 2.9488900310907336
Validation loss: 2.4711249633451504

Epoch: 6| Step: 11
Training loss: 1.6659542309449176
Validation loss: 2.4738459886172675

Epoch: 6| Step: 12
Training loss: 2.5435006659154245
Validation loss: 2.475054372967287

Epoch: 6| Step: 13
Training loss: 2.46942844001877
Validation loss: 2.46962102984067

Epoch: 143| Step: 0
Training loss: 2.0739536726659895
Validation loss: 2.4657500505666228

Epoch: 6| Step: 1
Training loss: 1.9518412529150035
Validation loss: 2.4639627904559487

Epoch: 6| Step: 2
Training loss: 2.50141466169714
Validation loss: 2.462077947294247

Epoch: 6| Step: 3
Training loss: 2.247034980267367
Validation loss: 2.4534182687064874

Epoch: 6| Step: 4
Training loss: 2.044754210906538
Validation loss: 2.4612681494709303

Epoch: 6| Step: 5
Training loss: 2.720973716802369
Validation loss: 2.4582694713465765

Epoch: 6| Step: 6
Training loss: 2.947469958280875
Validation loss: 2.4585334782566

Epoch: 6| Step: 7
Training loss: 2.7728186548242753
Validation loss: 2.466563757691465

Epoch: 6| Step: 8
Training loss: 2.415997368659551
Validation loss: 2.470492154689845

Epoch: 6| Step: 9
Training loss: 2.167499773318093
Validation loss: 2.46094433011515

Epoch: 6| Step: 10
Training loss: 2.8255326840669297
Validation loss: 2.4575134354072437

Epoch: 6| Step: 11
Training loss: 2.7120572726467205
Validation loss: 2.4642042971917606

Epoch: 6| Step: 12
Training loss: 2.782679501182058
Validation loss: 2.4549029765020647

Epoch: 6| Step: 13
Training loss: 2.494373761709389
Validation loss: 2.4570099506758893

Epoch: 144| Step: 0
Training loss: 2.170423063533752
Validation loss: 2.467602571792363

Epoch: 6| Step: 1
Training loss: 2.269977676685153
Validation loss: 2.4604752848267024

Epoch: 6| Step: 2
Training loss: 2.253758258688082
Validation loss: 2.4699531552792835

Epoch: 6| Step: 3
Training loss: 2.4895256918987156
Validation loss: 2.4617292634171903

Epoch: 6| Step: 4
Training loss: 2.0819068857234595
Validation loss: 2.4604934533971443

Epoch: 6| Step: 5
Training loss: 2.5079014842565743
Validation loss: 2.469175294064313

Epoch: 6| Step: 6
Training loss: 1.9729415838272
Validation loss: 2.4600302179284577

Epoch: 6| Step: 7
Training loss: 3.121242858609672
Validation loss: 2.4610982691006646

Epoch: 6| Step: 8
Training loss: 2.6860885462250907
Validation loss: 2.4663872176040083

Epoch: 6| Step: 9
Training loss: 2.0444918438120663
Validation loss: 2.462088631545537

Epoch: 6| Step: 10
Training loss: 2.888570189217688
Validation loss: 2.459111047561971

Epoch: 6| Step: 11
Training loss: 2.3757895111070817
Validation loss: 2.469142206641416

Epoch: 6| Step: 12
Training loss: 2.9397428350795187
Validation loss: 2.4669231947256764

Epoch: 6| Step: 13
Training loss: 2.7852838816029046
Validation loss: 2.4708566007328083

Epoch: 145| Step: 0
Training loss: 1.7986795403397098
Validation loss: 2.466600391640283

Epoch: 6| Step: 1
Training loss: 2.2324566909331276
Validation loss: 2.4616963664669274

Epoch: 6| Step: 2
Training loss: 2.5606414754168534
Validation loss: 2.4628066619105544

Epoch: 6| Step: 3
Training loss: 2.956920788010701
Validation loss: 2.4630092881668126

Epoch: 6| Step: 4
Training loss: 2.2631658427870476
Validation loss: 2.4655044726045796

Epoch: 6| Step: 5
Training loss: 2.8797882675117354
Validation loss: 2.4638628491537227

Epoch: 6| Step: 6
Training loss: 2.8010476808966924
Validation loss: 2.469050908159846

Epoch: 6| Step: 7
Training loss: 2.4947668617199357
Validation loss: 2.4696381657293185

Epoch: 6| Step: 8
Training loss: 2.516472430870406
Validation loss: 2.4701643485760694

Epoch: 6| Step: 9
Training loss: 2.0419230656940477
Validation loss: 2.4670532930934708

Epoch: 6| Step: 10
Training loss: 1.9462637662798843
Validation loss: 2.472184106506763

Epoch: 6| Step: 11
Training loss: 2.452368650039594
Validation loss: 2.47047241902945

Epoch: 6| Step: 12
Training loss: 2.948901350107944
Validation loss: 2.46688092778952

Epoch: 6| Step: 13
Training loss: 2.5831901961839057
Validation loss: 2.4625260488871903

Epoch: 146| Step: 0
Training loss: 2.250204818728021
Validation loss: 2.4716862628577507

Epoch: 6| Step: 1
Training loss: 2.2519948381463037
Validation loss: 2.4685381222998686

Epoch: 6| Step: 2
Training loss: 2.3243394836354625
Validation loss: 2.4628103890030997

Epoch: 6| Step: 3
Training loss: 2.5183980123148517
Validation loss: 2.4653056780410902

Epoch: 6| Step: 4
Training loss: 2.6217598672715514
Validation loss: 2.4697157503964595

Epoch: 6| Step: 5
Training loss: 2.468531248807005
Validation loss: 2.461641854703739

Epoch: 6| Step: 6
Training loss: 2.287474931256452
Validation loss: 2.4675036636268657

Epoch: 6| Step: 7
Training loss: 2.3022067927285756
Validation loss: 2.4643481804780443

Epoch: 6| Step: 8
Training loss: 2.99517274947445
Validation loss: 2.4747499638268504

Epoch: 6| Step: 9
Training loss: 2.3101710370970565
Validation loss: 2.4716004442212407

Epoch: 6| Step: 10
Training loss: 2.4584814016287657
Validation loss: 2.466830316046587

Epoch: 6| Step: 11
Training loss: 2.533855463062254
Validation loss: 2.467947688691607

Epoch: 6| Step: 12
Training loss: 2.8613804522732322
Validation loss: 2.471374436601185

Epoch: 6| Step: 13
Training loss: 2.5276964463318343
Validation loss: 2.473839354749352

Epoch: 147| Step: 0
Training loss: 2.304869770665797
Validation loss: 2.4745643007448224

Epoch: 6| Step: 1
Training loss: 2.5768908696839015
Validation loss: 2.4738678657989515

Epoch: 6| Step: 2
Training loss: 2.3133255799389865
Validation loss: 2.4735527000501394

Epoch: 6| Step: 3
Training loss: 2.2889062613328983
Validation loss: 2.4782717930281204

Epoch: 6| Step: 4
Training loss: 2.283774559753351
Validation loss: 2.475922302227697

Epoch: 6| Step: 5
Training loss: 2.0830648122036
Validation loss: 2.475181515456369

Epoch: 6| Step: 6
Training loss: 2.4193286923051884
Validation loss: 2.4698097433208734

Epoch: 6| Step: 7
Training loss: 2.5492686625395433
Validation loss: 2.4723916376717288

Epoch: 6| Step: 8
Training loss: 3.293959354356003
Validation loss: 2.4830447820314103

Epoch: 6| Step: 9
Training loss: 1.6740637027009109
Validation loss: 2.469352785392086

Epoch: 6| Step: 10
Training loss: 2.577376008330541
Validation loss: 2.4772525632226943

Epoch: 6| Step: 11
Training loss: 2.498658010784669
Validation loss: 2.4708159289033866

Epoch: 6| Step: 12
Training loss: 2.896549072366199
Validation loss: 2.4626102313108778

Epoch: 6| Step: 13
Training loss: 2.7388260717025457
Validation loss: 2.4669386580579684

Epoch: 148| Step: 0
Training loss: 2.6616405765574087
Validation loss: 2.464424158041865

Epoch: 6| Step: 1
Training loss: 2.741300433973887
Validation loss: 2.4732391007955496

Epoch: 6| Step: 2
Training loss: 2.847145819737313
Validation loss: 2.477183523844218

Epoch: 6| Step: 3
Training loss: 2.37168361610402
Validation loss: 2.4799856281120447

Epoch: 6| Step: 4
Training loss: 3.103756222482467
Validation loss: 2.4615828218000995

Epoch: 6| Step: 5
Training loss: 2.561066761676406
Validation loss: 2.473843514973684

Epoch: 6| Step: 6
Training loss: 2.047667953999184
Validation loss: 2.4751069036187974

Epoch: 6| Step: 7
Training loss: 2.112068999073691
Validation loss: 2.466954105185847

Epoch: 6| Step: 8
Training loss: 1.9886536614792787
Validation loss: 2.468105473464072

Epoch: 6| Step: 9
Training loss: 3.0667973165738918
Validation loss: 2.4673194200914885

Epoch: 6| Step: 10
Training loss: 2.4174890982254835
Validation loss: 2.4742247320933366

Epoch: 6| Step: 11
Training loss: 2.115511184853956
Validation loss: 2.4714609383664174

Epoch: 6| Step: 12
Training loss: 1.8962471339204738
Validation loss: 2.464314367129051

Epoch: 6| Step: 13
Training loss: 2.7644804401888994
Validation loss: 2.4743202881635113

Epoch: 149| Step: 0
Training loss: 2.509058277479584
Validation loss: 2.4735252135085233

Epoch: 6| Step: 1
Training loss: 2.8040541249818336
Validation loss: 2.4637121151005323

Epoch: 6| Step: 2
Training loss: 1.6939031834324325
Validation loss: 2.473719219230224

Epoch: 6| Step: 3
Training loss: 2.513884327171875
Validation loss: 2.465435893998293

Epoch: 6| Step: 4
Training loss: 2.3112979548478783
Validation loss: 2.4756918739660994

Epoch: 6| Step: 5
Training loss: 2.2901096487655654
Validation loss: 2.4661295701282544

Epoch: 6| Step: 6
Training loss: 2.7526610244369176
Validation loss: 2.4630617207837107

Epoch: 6| Step: 7
Training loss: 2.611028638398497
Validation loss: 2.4789649069188346

Epoch: 6| Step: 8
Training loss: 2.2579811323609196
Validation loss: 2.47582682403801

Epoch: 6| Step: 9
Training loss: 3.079158551347816
Validation loss: 2.468145755266143

Epoch: 6| Step: 10
Training loss: 2.7426644369674813
Validation loss: 2.4682971200941726

Epoch: 6| Step: 11
Training loss: 2.632830973483965
Validation loss: 2.475541073645293

Epoch: 6| Step: 12
Training loss: 2.1781789283151425
Validation loss: 2.4698571486998646

Epoch: 6| Step: 13
Training loss: 1.99590251327533
Validation loss: 2.473051998695694

Epoch: 150| Step: 0
Training loss: 2.8511215077989727
Validation loss: 2.4720385896392822

Epoch: 6| Step: 1
Training loss: 2.2579475547234464
Validation loss: 2.462365776444558

Epoch: 6| Step: 2
Training loss: 2.850676432862546
Validation loss: 2.476261605998273

Epoch: 6| Step: 3
Training loss: 2.220732112483962
Validation loss: 2.4664831417561115

Epoch: 6| Step: 4
Training loss: 2.3959099688228758
Validation loss: 2.4663428308797553

Epoch: 6| Step: 5
Training loss: 2.489988977645316
Validation loss: 2.4750211233143142

Epoch: 6| Step: 6
Training loss: 2.9936854345570616
Validation loss: 2.4749445398455454

Epoch: 6| Step: 7
Training loss: 3.0587836312587466
Validation loss: 2.4792970948945188

Epoch: 6| Step: 8
Training loss: 1.968279343310604
Validation loss: 2.4623336303329997

Epoch: 6| Step: 9
Training loss: 3.186140481077558
Validation loss: 2.470751421912461

Epoch: 6| Step: 10
Training loss: 1.9940167574470111
Validation loss: 2.472775248013888

Epoch: 6| Step: 11
Training loss: 1.8216857314559127
Validation loss: 2.466405342624688

Epoch: 6| Step: 12
Training loss: 2.38298329225895
Validation loss: 2.4662786741373406

Epoch: 6| Step: 13
Training loss: 1.8861847115777328
Validation loss: 2.4766931028054753

Epoch: 151| Step: 0
Training loss: 2.0265510788171444
Validation loss: 2.4736009252606115

Epoch: 6| Step: 1
Training loss: 2.519242617612294
Validation loss: 2.483876256243937

Epoch: 6| Step: 2
Training loss: 1.8464944102008747
Validation loss: 2.47729890386386

Epoch: 6| Step: 3
Training loss: 2.079853113746729
Validation loss: 2.472442505222325

Epoch: 6| Step: 4
Training loss: 2.3630314466375286
Validation loss: 2.4671018466814267

Epoch: 6| Step: 5
Training loss: 1.8834665515786384
Validation loss: 2.480401786641232

Epoch: 6| Step: 6
Training loss: 2.1996464965484415
Validation loss: 2.4711616422364093

Epoch: 6| Step: 7
Training loss: 2.371420119823687
Validation loss: 2.4741547811044318

Epoch: 6| Step: 8
Training loss: 2.7331769662030236
Validation loss: 2.47834926775402

Epoch: 6| Step: 9
Training loss: 2.794757318350798
Validation loss: 2.4742461963958506

Epoch: 6| Step: 10
Training loss: 2.1709757528123883
Validation loss: 2.47293148748707

Epoch: 6| Step: 11
Training loss: 3.161889655883628
Validation loss: 2.4762126462899343

Epoch: 6| Step: 12
Training loss: 2.814137384836363
Validation loss: 2.4735401696949997

Epoch: 6| Step: 13
Training loss: 3.2563347335012174
Validation loss: 2.487131488922019

Epoch: 152| Step: 0
Training loss: 2.2426642465990385
Validation loss: 2.472771511836519

Epoch: 6| Step: 1
Training loss: 2.7990482347590606
Validation loss: 2.4759241318292657

Epoch: 6| Step: 2
Training loss: 2.5191415411423557
Validation loss: 2.479546354908358

Epoch: 6| Step: 3
Training loss: 2.2522514522826005
Validation loss: 2.475203453076064

Epoch: 6| Step: 4
Training loss: 2.8516872430977225
Validation loss: 2.472342778122727

Epoch: 6| Step: 5
Training loss: 2.3312044195469714
Validation loss: 2.4780827618495325

Epoch: 6| Step: 6
Training loss: 2.786252526974805
Validation loss: 2.4790443796296797

Epoch: 6| Step: 7
Training loss: 2.388631051464062
Validation loss: 2.4676566378738207

Epoch: 6| Step: 8
Training loss: 1.677593682710453
Validation loss: 2.4750521413531863

Epoch: 6| Step: 9
Training loss: 2.47739365165638
Validation loss: 2.4646887793492693

Epoch: 6| Step: 10
Training loss: 2.272617572391047
Validation loss: 2.4656392550328325

Epoch: 6| Step: 11
Training loss: 2.502493758979812
Validation loss: 2.4763798932163916

Epoch: 6| Step: 12
Training loss: 2.9464445898107767
Validation loss: 2.4723943940286977

Epoch: 6| Step: 13
Training loss: 2.2976523400941105
Validation loss: 2.479139765959471

Epoch: 153| Step: 0
Training loss: 2.428909324332396
Validation loss: 2.4764361103590757

Epoch: 6| Step: 1
Training loss: 2.4807507452278896
Validation loss: 2.488094081256951

Epoch: 6| Step: 2
Training loss: 2.3293304394880696
Validation loss: 2.487331638357416

Epoch: 6| Step: 3
Training loss: 2.41999300774439
Validation loss: 2.485835527765847

Epoch: 6| Step: 4
Training loss: 2.3190571378484743
Validation loss: 2.493187371939545

Epoch: 6| Step: 5
Training loss: 2.4502445488152858
Validation loss: 2.480711364895795

Epoch: 6| Step: 6
Training loss: 1.9945657334893632
Validation loss: 2.478386569239145

Epoch: 6| Step: 7
Training loss: 2.677845669470964
Validation loss: 2.473304715732171

Epoch: 6| Step: 8
Training loss: 1.7152684409247356
Validation loss: 2.4829552070284024

Epoch: 6| Step: 9
Training loss: 3.0437609286572282
Validation loss: 2.480950432413074

Epoch: 6| Step: 10
Training loss: 2.0010703322266865
Validation loss: 2.4770306486703615

Epoch: 6| Step: 11
Training loss: 2.5857821414989077
Validation loss: 2.4756216032831047

Epoch: 6| Step: 12
Training loss: 2.9000614685910446
Validation loss: 2.4862331902658275

Epoch: 6| Step: 13
Training loss: 2.858203084960537
Validation loss: 2.498422450787085

Epoch: 154| Step: 0
Training loss: 2.473178802282909
Validation loss: 2.4797407068041952

Epoch: 6| Step: 1
Training loss: 2.8466379780928084
Validation loss: 2.4806023429078743

Epoch: 6| Step: 2
Training loss: 1.7998761531821637
Validation loss: 2.4804060880500685

Epoch: 6| Step: 3
Training loss: 2.4231494134672285
Validation loss: 2.4870861383303957

Epoch: 6| Step: 4
Training loss: 2.5489808720095097
Validation loss: 2.4777289450494386

Epoch: 6| Step: 5
Training loss: 2.363442256266494
Validation loss: 2.472716416625809

Epoch: 6| Step: 6
Training loss: 2.2799599540272135
Validation loss: 2.4720224750442545

Epoch: 6| Step: 7
Training loss: 2.5495226618972877
Validation loss: 2.4811391890578443

Epoch: 6| Step: 8
Training loss: 2.5252125641136667
Validation loss: 2.4687958081337364

Epoch: 6| Step: 9
Training loss: 2.826403858125387
Validation loss: 2.4745346094171174

Epoch: 6| Step: 10
Training loss: 2.2367023005065536
Validation loss: 2.476537116689795

Epoch: 6| Step: 11
Training loss: 2.449495290813603
Validation loss: 2.475485341814007

Epoch: 6| Step: 12
Training loss: 2.882685464680677
Validation loss: 2.4710675720892983

Epoch: 6| Step: 13
Training loss: 2.344073362296054
Validation loss: 2.4665247388767146

Epoch: 155| Step: 0
Training loss: 2.064099702925749
Validation loss: 2.468613037301879

Epoch: 6| Step: 1
Training loss: 2.584076825691655
Validation loss: 2.477525140895882

Epoch: 6| Step: 2
Training loss: 1.9854530349821606
Validation loss: 2.4831607978417405

Epoch: 6| Step: 3
Training loss: 3.4314549786152915
Validation loss: 2.473723299339551

Epoch: 6| Step: 4
Training loss: 2.4785799780172475
Validation loss: 2.4792148093883872

Epoch: 6| Step: 5
Training loss: 2.67182797396139
Validation loss: 2.48655122333875

Epoch: 6| Step: 6
Training loss: 2.148001442786217
Validation loss: 2.484423654907554

Epoch: 6| Step: 7
Training loss: 2.623566644885361
Validation loss: 2.473467267472413

Epoch: 6| Step: 8
Training loss: 1.611773435152164
Validation loss: 2.4793550729619924

Epoch: 6| Step: 9
Training loss: 2.68293285422061
Validation loss: 2.4814747289810333

Epoch: 6| Step: 10
Training loss: 2.8098362494165308
Validation loss: 2.4833619393444173

Epoch: 6| Step: 11
Training loss: 1.9873244226024087
Validation loss: 2.4923399556723207

Epoch: 6| Step: 12
Training loss: 2.3077806309157047
Validation loss: 2.4835783602867805

Epoch: 6| Step: 13
Training loss: 2.5765015085379894
Validation loss: 2.500436109015822

Epoch: 156| Step: 0
Training loss: 2.5913875805720226
Validation loss: 2.4932633631836545

Epoch: 6| Step: 1
Training loss: 2.9558748228955722
Validation loss: 2.5046897451890833

Epoch: 6| Step: 2
Training loss: 2.638243374314018
Validation loss: 2.489272562419521

Epoch: 6| Step: 3
Training loss: 3.0622060206476354
Validation loss: 2.5143561470500098

Epoch: 6| Step: 4
Training loss: 2.31187884262108
Validation loss: 2.493469657851537

Epoch: 6| Step: 5
Training loss: 2.4973252292765653
Validation loss: 2.497071768559228

Epoch: 6| Step: 6
Training loss: 2.0069171972599453
Validation loss: 2.4856480309833646

Epoch: 6| Step: 7
Training loss: 2.2373911101201718
Validation loss: 2.4899853550685824

Epoch: 6| Step: 8
Training loss: 2.459412311043118
Validation loss: 2.479208895112606

Epoch: 6| Step: 9
Training loss: 2.69530896172775
Validation loss: 2.476323281657184

Epoch: 6| Step: 10
Training loss: 2.339130171801545
Validation loss: 2.4826665798204997

Epoch: 6| Step: 11
Training loss: 1.8299146190382682
Validation loss: 2.4849727239461417

Epoch: 6| Step: 12
Training loss: 2.5318956846711993
Validation loss: 2.48909377760711

Epoch: 6| Step: 13
Training loss: 2.1111557966935073
Validation loss: 2.476387330608219

Epoch: 157| Step: 0
Training loss: 2.0626044969385227
Validation loss: 2.4736561694412313

Epoch: 6| Step: 1
Training loss: 3.289424921577823
Validation loss: 2.48268971572694

Epoch: 6| Step: 2
Training loss: 2.6193721933424925
Validation loss: 2.4835358888042465

Epoch: 6| Step: 3
Training loss: 2.799776245441077
Validation loss: 2.4808040202079837

Epoch: 6| Step: 4
Training loss: 1.860596327812231
Validation loss: 2.4857900815963476

Epoch: 6| Step: 5
Training loss: 1.9691927578500206
Validation loss: 2.483737503888085

Epoch: 6| Step: 6
Training loss: 2.3764647935875534
Validation loss: 2.4779098648261026

Epoch: 6| Step: 7
Training loss: 2.746702471317631
Validation loss: 2.490072933773236

Epoch: 6| Step: 8
Training loss: 2.342006899822701
Validation loss: 2.4931711230917046

Epoch: 6| Step: 9
Training loss: 2.8768793680612443
Validation loss: 2.4954976547618464

Epoch: 6| Step: 10
Training loss: 1.981388818829471
Validation loss: 2.493456159854048

Epoch: 6| Step: 11
Training loss: 2.511408808971576
Validation loss: 2.49623786458501

Epoch: 6| Step: 12
Training loss: 2.5882522042507445
Validation loss: 2.508578396440026

Epoch: 6| Step: 13
Training loss: 2.216003329711781
Validation loss: 2.4951783015361872

Epoch: 158| Step: 0
Training loss: 2.0947661709542
Validation loss: 2.502256614747205

Epoch: 6| Step: 1
Training loss: 2.0056997382389827
Validation loss: 2.4894379023979343

Epoch: 6| Step: 2
Training loss: 3.023701816409903
Validation loss: 2.488959778356118

Epoch: 6| Step: 3
Training loss: 2.3105687505568415
Validation loss: 2.486405108973836

Epoch: 6| Step: 4
Training loss: 2.2420707432988243
Validation loss: 2.4923262921214677

Epoch: 6| Step: 5
Training loss: 2.2703647888421066
Validation loss: 2.487889121720929

Epoch: 6| Step: 6
Training loss: 2.0192547429935757
Validation loss: 2.495143369175258

Epoch: 6| Step: 7
Training loss: 2.5155789388858607
Validation loss: 2.486485542454262

Epoch: 6| Step: 8
Training loss: 3.0951300731435722
Validation loss: 2.4879606590370225

Epoch: 6| Step: 9
Training loss: 2.9498346961307966
Validation loss: 2.491507737461268

Epoch: 6| Step: 10
Training loss: 2.498884810627222
Validation loss: 2.476196727356164

Epoch: 6| Step: 11
Training loss: 2.060470160190721
Validation loss: 2.487715197125277

Epoch: 6| Step: 12
Training loss: 2.713259183759339
Validation loss: 2.487082487559823

Epoch: 6| Step: 13
Training loss: 2.340677307114862
Validation loss: 2.4949179493288063

Epoch: 159| Step: 0
Training loss: 2.908160494356785
Validation loss: 2.4944494460022004

Epoch: 6| Step: 1
Training loss: 2.0258444826590027
Validation loss: 2.5050005016973604

Epoch: 6| Step: 2
Training loss: 1.9919811665514078
Validation loss: 2.4932124024488918

Epoch: 6| Step: 3
Training loss: 1.9311154908185566
Validation loss: 2.4995798870592183

Epoch: 6| Step: 4
Training loss: 2.6987738898290186
Validation loss: 2.4976442523087843

Epoch: 6| Step: 5
Training loss: 1.8080174493960386
Validation loss: 2.5023000309404475

Epoch: 6| Step: 6
Training loss: 1.9000945845702288
Validation loss: 2.491287563236655

Epoch: 6| Step: 7
Training loss: 2.319293585139627
Validation loss: 2.4936320902421008

Epoch: 6| Step: 8
Training loss: 2.8192170358868385
Validation loss: 2.495669110414105

Epoch: 6| Step: 9
Training loss: 3.0820499704853663
Validation loss: 2.4972405463274705

Epoch: 6| Step: 10
Training loss: 2.5349371158542473
Validation loss: 2.4881176138688943

Epoch: 6| Step: 11
Training loss: 2.7784874730029427
Validation loss: 2.48093500836413

Epoch: 6| Step: 12
Training loss: 2.51777575940108
Validation loss: 2.4946686642029006

Epoch: 6| Step: 13
Training loss: 2.593703395930381
Validation loss: 2.4877649207713146

Epoch: 160| Step: 0
Training loss: 2.3608027300437207
Validation loss: 2.4814899415045404

Epoch: 6| Step: 1
Training loss: 2.567588777576601
Validation loss: 2.4767048310496453

Epoch: 6| Step: 2
Training loss: 2.258353092721829
Validation loss: 2.4828591110498768

Epoch: 6| Step: 3
Training loss: 2.331668486886431
Validation loss: 2.4735664351741957

Epoch: 6| Step: 4
Training loss: 2.005912386333947
Validation loss: 2.4809521461903703

Epoch: 6| Step: 5
Training loss: 2.4988610534263516
Validation loss: 2.4691486600111348

Epoch: 6| Step: 6
Training loss: 1.918321006110007
Validation loss: 2.4776228150157835

Epoch: 6| Step: 7
Training loss: 2.4622200666380687
Validation loss: 2.48135352987696

Epoch: 6| Step: 8
Training loss: 2.5233522760981177
Validation loss: 2.476282482983639

Epoch: 6| Step: 9
Training loss: 2.4567659413721192
Validation loss: 2.4739197068796193

Epoch: 6| Step: 10
Training loss: 2.9360546046072358
Validation loss: 2.4931397487293068

Epoch: 6| Step: 11
Training loss: 2.760003016926319
Validation loss: 2.480991482659711

Epoch: 6| Step: 12
Training loss: 2.5000679006892272
Validation loss: 2.4897186503219855

Epoch: 6| Step: 13
Training loss: 2.7966525879127797
Validation loss: 2.4803130013336125

Epoch: 161| Step: 0
Training loss: 3.1781207449405358
Validation loss: 2.486437822845164

Epoch: 6| Step: 1
Training loss: 2.665030474175425
Validation loss: 2.4916291602978755

Epoch: 6| Step: 2
Training loss: 2.32813892744366
Validation loss: 2.4841468914242593

Epoch: 6| Step: 3
Training loss: 2.148509964154357
Validation loss: 2.4839608509021422

Epoch: 6| Step: 4
Training loss: 2.2712055799458035
Validation loss: 2.4743015947957656

Epoch: 6| Step: 5
Training loss: 2.4781486173372644
Validation loss: 2.477399939175816

Epoch: 6| Step: 6
Training loss: 2.268299181996641
Validation loss: 2.480137215633022

Epoch: 6| Step: 7
Training loss: 2.489176399033988
Validation loss: 2.469934613872052

Epoch: 6| Step: 8
Training loss: 2.0138933890573787
Validation loss: 2.474210615177832

Epoch: 6| Step: 9
Training loss: 2.2874306339940613
Validation loss: 2.4710834597432525

Epoch: 6| Step: 10
Training loss: 2.3712939408835516
Validation loss: 2.4702245517672408

Epoch: 6| Step: 11
Training loss: 2.2154708055394803
Validation loss: 2.4697729639068937

Epoch: 6| Step: 12
Training loss: 2.4817451617156374
Validation loss: 2.472074708454726

Epoch: 6| Step: 13
Training loss: 3.0518015621864043
Validation loss: 2.4709225844870657

Epoch: 162| Step: 0
Training loss: 2.3565560989485177
Validation loss: 2.4628104535414495

Epoch: 6| Step: 1
Training loss: 2.97767262020076
Validation loss: 2.4718455773044052

Epoch: 6| Step: 2
Training loss: 2.4984572418749815
Validation loss: 2.4728223956767508

Epoch: 6| Step: 3
Training loss: 2.4963843903256313
Validation loss: 2.4630510891525317

Epoch: 6| Step: 4
Training loss: 3.0482709767794556
Validation loss: 2.4717071302586815

Epoch: 6| Step: 5
Training loss: 2.3719023530812753
Validation loss: 2.476578352403096

Epoch: 6| Step: 6
Training loss: 2.7744280698289048
Validation loss: 2.470254206427048

Epoch: 6| Step: 7
Training loss: 2.616981612120863
Validation loss: 2.47258791796462

Epoch: 6| Step: 8
Training loss: 2.4174902816940054
Validation loss: 2.472324182310429

Epoch: 6| Step: 9
Training loss: 1.660988704433996
Validation loss: 2.4761198432423566

Epoch: 6| Step: 10
Training loss: 2.0278285628394066
Validation loss: 2.4777905280545918

Epoch: 6| Step: 11
Training loss: 2.7788579705489447
Validation loss: 2.4686418099176564

Epoch: 6| Step: 12
Training loss: 2.144553040218304
Validation loss: 2.487366959993355

Epoch: 6| Step: 13
Training loss: 2.002914093864518
Validation loss: 2.4814800934078622

Epoch: 163| Step: 0
Training loss: 2.7786366046345883
Validation loss: 2.4865181913443615

Epoch: 6| Step: 1
Training loss: 2.533092158114316
Validation loss: 2.4835139287869437

Epoch: 6| Step: 2
Training loss: 2.003408388751315
Validation loss: 2.4819847780591346

Epoch: 6| Step: 3
Training loss: 3.0585981152187878
Validation loss: 2.4762376959371637

Epoch: 6| Step: 4
Training loss: 2.242480322029592
Validation loss: 2.475466336202156

Epoch: 6| Step: 5
Training loss: 2.176058903892643
Validation loss: 2.4860271582348865

Epoch: 6| Step: 6
Training loss: 2.5844270380355487
Validation loss: 2.4770049172307576

Epoch: 6| Step: 7
Training loss: 2.8730282863946583
Validation loss: 2.4710157756983673

Epoch: 6| Step: 8
Training loss: 2.5599398966528684
Validation loss: 2.477213817033322

Epoch: 6| Step: 9
Training loss: 2.404303518947715
Validation loss: 2.4722068984977157

Epoch: 6| Step: 10
Training loss: 1.6447969706737513
Validation loss: 2.473489967315049

Epoch: 6| Step: 11
Training loss: 1.996780068494589
Validation loss: 2.474571751622412

Epoch: 6| Step: 12
Training loss: 2.7286696721624355
Validation loss: 2.4748349105799448

Epoch: 6| Step: 13
Training loss: 2.536681012060011
Validation loss: 2.4784760889096993

Epoch: 164| Step: 0
Training loss: 2.1504034861388788
Validation loss: 2.4741390978711

Epoch: 6| Step: 1
Training loss: 2.731127047008142
Validation loss: 2.476511588711513

Epoch: 6| Step: 2
Training loss: 2.3717981137566144
Validation loss: 2.4824727130989626

Epoch: 6| Step: 3
Training loss: 2.484490733779821
Validation loss: 2.485572078692356

Epoch: 6| Step: 4
Training loss: 1.9697561569146693
Validation loss: 2.501036619800675

Epoch: 6| Step: 5
Training loss: 2.310315517989604
Validation loss: 2.524109679022008

Epoch: 6| Step: 6
Training loss: 2.9005063634315027
Validation loss: 2.5235473482927797

Epoch: 6| Step: 7
Training loss: 2.9765801216464935
Validation loss: 2.52937856809834

Epoch: 6| Step: 8
Training loss: 2.0053886299490444
Validation loss: 2.52299301909737

Epoch: 6| Step: 9
Training loss: 2.8011276903392766
Validation loss: 2.497676612151328

Epoch: 6| Step: 10
Training loss: 1.9510713079766753
Validation loss: 2.488426391903803

Epoch: 6| Step: 11
Training loss: 2.721235783145129
Validation loss: 2.4836980669197803

Epoch: 6| Step: 12
Training loss: 2.412505897949599
Validation loss: 2.4799431191350956

Epoch: 6| Step: 13
Training loss: 2.3511176718304028
Validation loss: 2.4866444680379596

Epoch: 165| Step: 0
Training loss: 2.2012700056459105
Validation loss: 2.478623087512039

Epoch: 6| Step: 1
Training loss: 2.8576154454257043
Validation loss: 2.4823652731712578

Epoch: 6| Step: 2
Training loss: 2.2699236899837865
Validation loss: 2.4793439903208037

Epoch: 6| Step: 3
Training loss: 3.1890503348118964
Validation loss: 2.4799058650978476

Epoch: 6| Step: 4
Training loss: 2.4490201586652627
Validation loss: 2.4754129142413883

Epoch: 6| Step: 5
Training loss: 1.8799288498827125
Validation loss: 2.4819642852500587

Epoch: 6| Step: 6
Training loss: 2.5395875358598925
Validation loss: 2.4736416717784295

Epoch: 6| Step: 7
Training loss: 2.8226467627591045
Validation loss: 2.483613351314761

Epoch: 6| Step: 8
Training loss: 2.475253845452274
Validation loss: 2.4748367730977674

Epoch: 6| Step: 9
Training loss: 2.4679231828454022
Validation loss: 2.4795850646493114

Epoch: 6| Step: 10
Training loss: 2.7250959501960033
Validation loss: 2.4623346631463217

Epoch: 6| Step: 11
Training loss: 2.3863118475706817
Validation loss: 2.470501322791409

Epoch: 6| Step: 12
Training loss: 2.3184100742468714
Validation loss: 2.4591342677334076

Epoch: 6| Step: 13
Training loss: 2.5360475451648514
Validation loss: 2.466327283253858

Epoch: 166| Step: 0
Training loss: 2.0954969718909404
Validation loss: 2.4636088732423005

Epoch: 6| Step: 1
Training loss: 2.313341142419539
Validation loss: 2.4737418525077164

Epoch: 6| Step: 2
Training loss: 2.7080286783872007
Validation loss: 2.468712303421073

Epoch: 6| Step: 3
Training loss: 2.1018812653955505
Validation loss: 2.476646012784425

Epoch: 6| Step: 4
Training loss: 2.630409932987226
Validation loss: 2.4863689426249054

Epoch: 6| Step: 5
Training loss: 2.6625985069140627
Validation loss: 2.4908362923999445

Epoch: 6| Step: 6
Training loss: 2.4387069061710847
Validation loss: 2.4953815875027043

Epoch: 6| Step: 7
Training loss: 1.969236223033886
Validation loss: 2.4924653315962875

Epoch: 6| Step: 8
Training loss: 3.217160323085188
Validation loss: 2.4857274498823214

Epoch: 6| Step: 9
Training loss: 2.6570094201061303
Validation loss: 2.47930898712006

Epoch: 6| Step: 10
Training loss: 2.2789581491695947
Validation loss: 2.4815169395008496

Epoch: 6| Step: 11
Training loss: 2.6010383329929003
Validation loss: 2.4765441925944573

Epoch: 6| Step: 12
Training loss: 2.348378202155455
Validation loss: 2.474583297226775

Epoch: 6| Step: 13
Training loss: 2.3144994803506562
Validation loss: 2.479858932225912

Epoch: 167| Step: 0
Training loss: 2.691954004719507
Validation loss: 2.483791290743755

Epoch: 6| Step: 1
Training loss: 2.9213886366182282
Validation loss: 2.480535038740635

Epoch: 6| Step: 2
Training loss: 2.4420465957107695
Validation loss: 2.471356733915056

Epoch: 6| Step: 3
Training loss: 2.9718884392563836
Validation loss: 2.4843046710218326

Epoch: 6| Step: 4
Training loss: 3.065203504916157
Validation loss: 2.4774490358132253

Epoch: 6| Step: 5
Training loss: 2.029234840245267
Validation loss: 2.4805698003736065

Epoch: 6| Step: 6
Training loss: 2.260437386647787
Validation loss: 2.4793352155263713

Epoch: 6| Step: 7
Training loss: 2.5600505379814367
Validation loss: 2.4870030639991554

Epoch: 6| Step: 8
Training loss: 1.9134784663822568
Validation loss: 2.487566451522155

Epoch: 6| Step: 9
Training loss: 2.715385020794883
Validation loss: 2.4794383554623414

Epoch: 6| Step: 10
Training loss: 2.452155049025336
Validation loss: 2.4890889803556826

Epoch: 6| Step: 11
Training loss: 1.9667551742724216
Validation loss: 2.487539702886158

Epoch: 6| Step: 12
Training loss: 2.4888461203912002
Validation loss: 2.480079840661855

Epoch: 6| Step: 13
Training loss: 1.575786255056426
Validation loss: 2.4914005356431326

Epoch: 168| Step: 0
Training loss: 2.0952176316508777
Validation loss: 2.4941044991270953

Epoch: 6| Step: 1
Training loss: 1.9860772468626116
Validation loss: 2.4829481333901176

Epoch: 6| Step: 2
Training loss: 2.8302125760635026
Validation loss: 2.4870635545936524

Epoch: 6| Step: 3
Training loss: 2.117646452648101
Validation loss: 2.4858159458917655

Epoch: 6| Step: 4
Training loss: 2.141255195464397
Validation loss: 2.4862459603173406

Epoch: 6| Step: 5
Training loss: 2.6703868090009504
Validation loss: 2.4894358113738955

Epoch: 6| Step: 6
Training loss: 2.5220433213266653
Validation loss: 2.489310123237666

Epoch: 6| Step: 7
Training loss: 2.387330721301486
Validation loss: 2.4921323955506707

Epoch: 6| Step: 8
Training loss: 3.1665945212193503
Validation loss: 2.4842362914959755

Epoch: 6| Step: 9
Training loss: 2.422648349467376
Validation loss: 2.4879290832080216

Epoch: 6| Step: 10
Training loss: 1.944995900323857
Validation loss: 2.486365162947384

Epoch: 6| Step: 11
Training loss: 2.1562540911207226
Validation loss: 2.5000684887723477

Epoch: 6| Step: 12
Training loss: 2.477927616912609
Validation loss: 2.495602921138969

Epoch: 6| Step: 13
Training loss: 2.954446648232697
Validation loss: 2.503435333610375

Epoch: 169| Step: 0
Training loss: 3.078898840902339
Validation loss: 2.51058038729047

Epoch: 6| Step: 1
Training loss: 2.3767019498042083
Validation loss: 2.503033768177538

Epoch: 6| Step: 2
Training loss: 2.3729401741057976
Validation loss: 2.4932141077975962

Epoch: 6| Step: 3
Training loss: 2.8126712323091674
Validation loss: 2.4986401515298184

Epoch: 6| Step: 4
Training loss: 2.148008546489002
Validation loss: 2.5024556100333686

Epoch: 6| Step: 5
Training loss: 2.7065470649183103
Validation loss: 2.4980190057817957

Epoch: 6| Step: 6
Training loss: 1.9554530193017707
Validation loss: 2.490202963637165

Epoch: 6| Step: 7
Training loss: 2.2408148521530373
Validation loss: 2.489323787381109

Epoch: 6| Step: 8
Training loss: 2.304730638003327
Validation loss: 2.4911787010309343

Epoch: 6| Step: 9
Training loss: 2.4907596527803926
Validation loss: 2.4878463644549913

Epoch: 6| Step: 10
Training loss: 2.2626201829550787
Validation loss: 2.489750434875195

Epoch: 6| Step: 11
Training loss: 2.3333662802777044
Validation loss: 2.488040642955278

Epoch: 6| Step: 12
Training loss: 1.8554899515647252
Validation loss: 2.495109941306544

Epoch: 6| Step: 13
Training loss: 3.007343364641624
Validation loss: 2.4923747599214354

Epoch: 170| Step: 0
Training loss: 2.1463712987020886
Validation loss: 2.495363051910248

Epoch: 6| Step: 1
Training loss: 3.1627004446806533
Validation loss: 2.492951972448306

Epoch: 6| Step: 2
Training loss: 2.5584676696929383
Validation loss: 2.493686619768227

Epoch: 6| Step: 3
Training loss: 2.4558663570935226
Validation loss: 2.4918474944042734

Epoch: 6| Step: 4
Training loss: 2.5108279343766555
Validation loss: 2.500378778691103

Epoch: 6| Step: 5
Training loss: 2.132750346078108
Validation loss: 2.49403751949802

Epoch: 6| Step: 6
Training loss: 2.3804742065006588
Validation loss: 2.492489548319767

Epoch: 6| Step: 7
Training loss: 1.7513988217623315
Validation loss: 2.4925723202288115

Epoch: 6| Step: 8
Training loss: 2.809134864940202
Validation loss: 2.499520382968924

Epoch: 6| Step: 9
Training loss: 2.5106730561029074
Validation loss: 2.4866136105820114

Epoch: 6| Step: 10
Training loss: 2.0860072206425255
Validation loss: 2.4994443911813176

Epoch: 6| Step: 11
Training loss: 2.8058300188311436
Validation loss: 2.495599195253153

Epoch: 6| Step: 12
Training loss: 2.218930841517431
Validation loss: 2.494142393441645

Epoch: 6| Step: 13
Training loss: 2.2920799807429404
Validation loss: 2.498679320859401

Epoch: 171| Step: 0
Training loss: 2.6539738495723477
Validation loss: 2.492418061277116

Epoch: 6| Step: 1
Training loss: 1.9309089902769367
Validation loss: 2.48476662737982

Epoch: 6| Step: 2
Training loss: 2.1157791690071046
Validation loss: 2.4866506842269205

Epoch: 6| Step: 3
Training loss: 3.0018837101095364
Validation loss: 2.4838796317667637

Epoch: 6| Step: 4
Training loss: 2.125315025764471
Validation loss: 2.4944483786959966

Epoch: 6| Step: 5
Training loss: 2.1980458684132227
Validation loss: 2.4833616993284666

Epoch: 6| Step: 6
Training loss: 2.6365250579899087
Validation loss: 2.492174011002631

Epoch: 6| Step: 7
Training loss: 2.754085800053291
Validation loss: 2.4905205057353412

Epoch: 6| Step: 8
Training loss: 2.3332350801035626
Validation loss: 2.4935685878153184

Epoch: 6| Step: 9
Training loss: 2.3337206064997713
Validation loss: 2.4922439106423493

Epoch: 6| Step: 10
Training loss: 2.8299662460632673
Validation loss: 2.4968195234683717

Epoch: 6| Step: 11
Training loss: 2.083493976757332
Validation loss: 2.4908924943524617

Epoch: 6| Step: 12
Training loss: 2.734515987576195
Validation loss: 2.497193700561285

Epoch: 6| Step: 13
Training loss: 1.9922599031343684
Validation loss: 2.5112753754126955

Epoch: 172| Step: 0
Training loss: 2.6089862830904273
Validation loss: 2.5335762104090342

Epoch: 6| Step: 1
Training loss: 2.772738086463319
Validation loss: 2.5487951517712735

Epoch: 6| Step: 2
Training loss: 2.195786177281461
Validation loss: 2.544242809275372

Epoch: 6| Step: 3
Training loss: 2.2742408827370073
Validation loss: 2.529709225381258

Epoch: 6| Step: 4
Training loss: 2.802993730514216
Validation loss: 2.5111680126588714

Epoch: 6| Step: 5
Training loss: 2.630815422070439
Validation loss: 2.49374755374849

Epoch: 6| Step: 6
Training loss: 2.5577898233069116
Validation loss: 2.489020708319556

Epoch: 6| Step: 7
Training loss: 2.1651499525827744
Validation loss: 2.4834733362437573

Epoch: 6| Step: 8
Training loss: 2.2708771960953973
Validation loss: 2.4793088428750787

Epoch: 6| Step: 9
Training loss: 2.6122145136305646
Validation loss: 2.4815581645222347

Epoch: 6| Step: 10
Training loss: 2.670102072204126
Validation loss: 2.4805832083018546

Epoch: 6| Step: 11
Training loss: 2.6497516803637153
Validation loss: 2.4853910851474406

Epoch: 6| Step: 12
Training loss: 1.8875807536452534
Validation loss: 2.4802880008553427

Epoch: 6| Step: 13
Training loss: 2.545641173141132
Validation loss: 2.479335367783343

Epoch: 173| Step: 0
Training loss: 2.6546608153961597
Validation loss: 2.4856646727140057

Epoch: 6| Step: 1
Training loss: 2.359117102264588
Validation loss: 2.488002791461421

Epoch: 6| Step: 2
Training loss: 2.939295118780706
Validation loss: 2.496679835197784

Epoch: 6| Step: 3
Training loss: 2.5250029535559575
Validation loss: 2.5070868023449018

Epoch: 6| Step: 4
Training loss: 2.070079286503512
Validation loss: 2.5155607021794544

Epoch: 6| Step: 5
Training loss: 1.789354925119644
Validation loss: 2.538013699403649

Epoch: 6| Step: 6
Training loss: 2.7258224576031242
Validation loss: 2.5305790266987986

Epoch: 6| Step: 7
Training loss: 2.6747355178853116
Validation loss: 2.550301413704985

Epoch: 6| Step: 8
Training loss: 2.7584695438586504
Validation loss: 2.5349794707260176

Epoch: 6| Step: 9
Training loss: 2.742074121810341
Validation loss: 2.522985222974663

Epoch: 6| Step: 10
Training loss: 2.6224272699880453
Validation loss: 2.504463566228797

Epoch: 6| Step: 11
Training loss: 2.4078983754483527
Validation loss: 2.482915941679899

Epoch: 6| Step: 12
Training loss: 2.1914230046847245
Validation loss: 2.4792228553452524

Epoch: 6| Step: 13
Training loss: 2.0886446070491895
Validation loss: 2.4736276077595263

Epoch: 174| Step: 0
Training loss: 2.649349719460351
Validation loss: 2.4702615094456757

Epoch: 6| Step: 1
Training loss: 2.683520542351167
Validation loss: 2.4682022806991912

Epoch: 6| Step: 2
Training loss: 2.1760717228891973
Validation loss: 2.470832927847492

Epoch: 6| Step: 3
Training loss: 2.8383839041355663
Validation loss: 2.46573395933521

Epoch: 6| Step: 4
Training loss: 2.1929313805973374
Validation loss: 2.466402668185569

Epoch: 6| Step: 5
Training loss: 2.786072054794498
Validation loss: 2.4610743489640132

Epoch: 6| Step: 6
Training loss: 1.868274579764845
Validation loss: 2.472810102661107

Epoch: 6| Step: 7
Training loss: 3.3652309743163316
Validation loss: 2.4735029798697554

Epoch: 6| Step: 8
Training loss: 2.296286682766214
Validation loss: 2.4828617757649183

Epoch: 6| Step: 9
Training loss: 2.1048885529797268
Validation loss: 2.485433245142867

Epoch: 6| Step: 10
Training loss: 2.432822605864226
Validation loss: 2.4891847879367224

Epoch: 6| Step: 11
Training loss: 2.430559694801318
Validation loss: 2.4802087682611202

Epoch: 6| Step: 12
Training loss: 2.294671071734163
Validation loss: 2.487027030337776

Epoch: 6| Step: 13
Training loss: 2.3401844623599852
Validation loss: 2.465163285248879

Epoch: 175| Step: 0
Training loss: 1.9470905313237004
Validation loss: 2.470353985670727

Epoch: 6| Step: 1
Training loss: 2.310862915403647
Validation loss: 2.4746227831077086

Epoch: 6| Step: 2
Training loss: 2.8133647013297063
Validation loss: 2.4707242258650988

Epoch: 6| Step: 3
Training loss: 3.0166263795414103
Validation loss: 2.467079112221057

Epoch: 6| Step: 4
Training loss: 2.125007517184257
Validation loss: 2.4617026456537956

Epoch: 6| Step: 5
Training loss: 2.0825073384937616
Validation loss: 2.4569328543120883

Epoch: 6| Step: 6
Training loss: 2.9186563154129677
Validation loss: 2.4604185414986786

Epoch: 6| Step: 7
Training loss: 2.062168903940438
Validation loss: 2.471102969417445

Epoch: 6| Step: 8
Training loss: 2.487195986471929
Validation loss: 2.4677962702268643

Epoch: 6| Step: 9
Training loss: 2.190511320160204
Validation loss: 2.4680445021157187

Epoch: 6| Step: 10
Training loss: 2.427413219468271
Validation loss: 2.4678687603193152

Epoch: 6| Step: 11
Training loss: 2.596851654498657
Validation loss: 2.4693679519046814

Epoch: 6| Step: 12
Training loss: 2.8067215793006897
Validation loss: 2.4733661357764305

Epoch: 6| Step: 13
Training loss: 2.4538596444256986
Validation loss: 2.4843910584640536

Epoch: 176| Step: 0
Training loss: 2.8304440595459135
Validation loss: 2.48166332565742

Epoch: 6| Step: 1
Training loss: 2.1522502567319024
Validation loss: 2.4777859975861896

Epoch: 6| Step: 2
Training loss: 2.65588986816496
Validation loss: 2.4833510425968797

Epoch: 6| Step: 3
Training loss: 2.3609051321601853
Validation loss: 2.5035274574181505

Epoch: 6| Step: 4
Training loss: 2.7955247400779153
Validation loss: 2.5111925237346466

Epoch: 6| Step: 5
Training loss: 2.170984977751022
Validation loss: 2.514487710402494

Epoch: 6| Step: 6
Training loss: 2.880325692092701
Validation loss: 2.5066142720426456

Epoch: 6| Step: 7
Training loss: 2.3511186858950346
Validation loss: 2.5113028127035766

Epoch: 6| Step: 8
Training loss: 2.1429261696006643
Validation loss: 2.50419185396202

Epoch: 6| Step: 9
Training loss: 2.3207813136116746
Validation loss: 2.4905050611793644

Epoch: 6| Step: 10
Training loss: 1.8180862369122797
Validation loss: 2.4909559373831676

Epoch: 6| Step: 11
Training loss: 2.498572227944026
Validation loss: 2.487466755681598

Epoch: 6| Step: 12
Training loss: 2.101644294593477
Validation loss: 2.4793075606970962

Epoch: 6| Step: 13
Training loss: 2.882410533141902
Validation loss: 2.4931681107875314

Epoch: 177| Step: 0
Training loss: 2.4923286039293853
Validation loss: 2.4866299741899756

Epoch: 6| Step: 1
Training loss: 2.201978561040609
Validation loss: 2.4909946373170073

Epoch: 6| Step: 2
Training loss: 2.432386463177675
Validation loss: 2.495034436311232

Epoch: 6| Step: 3
Training loss: 2.114655729911747
Validation loss: 2.4888037627522066

Epoch: 6| Step: 4
Training loss: 2.166381694931049
Validation loss: 2.497585672608987

Epoch: 6| Step: 5
Training loss: 2.389789111038725
Validation loss: 2.4886706500174385

Epoch: 6| Step: 6
Training loss: 2.2991215106234755
Validation loss: 2.4873473422493437

Epoch: 6| Step: 7
Training loss: 2.2626038501152057
Validation loss: 2.4989038448480785

Epoch: 6| Step: 8
Training loss: 2.6062104915121718
Validation loss: 2.4794258548517303

Epoch: 6| Step: 9
Training loss: 3.059250333620929
Validation loss: 2.488371571449093

Epoch: 6| Step: 10
Training loss: 2.7117564258909015
Validation loss: 2.483454711772495

Epoch: 6| Step: 11
Training loss: 2.1671279514000226
Validation loss: 2.484918834734671

Epoch: 6| Step: 12
Training loss: 2.9591861265791106
Validation loss: 2.498600695323692

Epoch: 6| Step: 13
Training loss: 2.089117590692122
Validation loss: 2.492024208068625

Epoch: 178| Step: 0
Training loss: 2.7367424879207087
Validation loss: 2.4958248958752836

Epoch: 6| Step: 1
Training loss: 2.1106814259494833
Validation loss: 2.500582213953836

Epoch: 6| Step: 2
Training loss: 2.108761620526272
Validation loss: 2.4943174310966008

Epoch: 6| Step: 3
Training loss: 2.674413534743978
Validation loss: 2.5042107566045346

Epoch: 6| Step: 4
Training loss: 2.226909837902617
Validation loss: 2.490405746247953

Epoch: 6| Step: 5
Training loss: 2.3571738781890064
Validation loss: 2.497383329793095

Epoch: 6| Step: 6
Training loss: 2.3950053456670877
Validation loss: 2.492379208070331

Epoch: 6| Step: 7
Training loss: 2.10653665103171
Validation loss: 2.489339127527545

Epoch: 6| Step: 8
Training loss: 2.4048053318474722
Validation loss: 2.4834728402330173

Epoch: 6| Step: 9
Training loss: 2.174278850046891
Validation loss: 2.4916894588469938

Epoch: 6| Step: 10
Training loss: 2.7005961501759597
Validation loss: 2.494145635581404

Epoch: 6| Step: 11
Training loss: 2.7117498318564954
Validation loss: 2.499265085919468

Epoch: 6| Step: 12
Training loss: 2.10207465642292
Validation loss: 2.500156191079325

Epoch: 6| Step: 13
Training loss: 3.0441408067035267
Validation loss: 2.504983655301373

Epoch: 179| Step: 0
Training loss: 2.9333985285305264
Validation loss: 2.4997393631175813

Epoch: 6| Step: 1
Training loss: 2.162830539204285
Validation loss: 2.4980429141540386

Epoch: 6| Step: 2
Training loss: 2.5969160129508064
Validation loss: 2.514019068502247

Epoch: 6| Step: 3
Training loss: 2.429779541627315
Validation loss: 2.5015571274899244

Epoch: 6| Step: 4
Training loss: 2.353311490271817
Validation loss: 2.509098091856535

Epoch: 6| Step: 5
Training loss: 1.9526466699429164
Validation loss: 2.507686243414466

Epoch: 6| Step: 6
Training loss: 2.7758020771167535
Validation loss: 2.50264511048442

Epoch: 6| Step: 7
Training loss: 2.521811513562527
Validation loss: 2.515017718511194

Epoch: 6| Step: 8
Training loss: 1.7730090594245804
Validation loss: 2.498009572808172

Epoch: 6| Step: 9
Training loss: 2.3853819954252864
Validation loss: 2.5012763421029685

Epoch: 6| Step: 10
Training loss: 2.682036590793091
Validation loss: 2.48793347541865

Epoch: 6| Step: 11
Training loss: 2.1114786466710718
Validation loss: 2.4823479530098957

Epoch: 6| Step: 12
Training loss: 2.4653931986216344
Validation loss: 2.4782071914928907

Epoch: 6| Step: 13
Training loss: 2.602537321909596
Validation loss: 2.485962926070041

Epoch: 180| Step: 0
Training loss: 2.7987695170067455
Validation loss: 2.47832618752967

Epoch: 6| Step: 1
Training loss: 2.4727304938621755
Validation loss: 2.4794502470103525

Epoch: 6| Step: 2
Training loss: 2.4680525361873102
Validation loss: 2.4856357374527684

Epoch: 6| Step: 3
Training loss: 2.7587493083418897
Validation loss: 2.4800127786773714

Epoch: 6| Step: 4
Training loss: 1.7891256662736796
Validation loss: 2.4895869352136413

Epoch: 6| Step: 5
Training loss: 2.9024298386878984
Validation loss: 2.49163303565184

Epoch: 6| Step: 6
Training loss: 3.1613970797206896
Validation loss: 2.4878336984521643

Epoch: 6| Step: 7
Training loss: 2.5578399712655044
Validation loss: 2.494464491785095

Epoch: 6| Step: 8
Training loss: 2.5061868407550794
Validation loss: 2.5019042868690415

Epoch: 6| Step: 9
Training loss: 2.1817538403647396
Validation loss: 2.5106345012277043

Epoch: 6| Step: 10
Training loss: 2.099522163886438
Validation loss: 2.508461017675027

Epoch: 6| Step: 11
Training loss: 2.4923036362903916
Validation loss: 2.51737488724604

Epoch: 6| Step: 12
Training loss: 2.1775646742316117
Validation loss: 2.4997465482028525

Epoch: 6| Step: 13
Training loss: 1.687939763164991
Validation loss: 2.50849387953064

Epoch: 181| Step: 0
Training loss: 2.6402228235363703
Validation loss: 2.49511763341891

Epoch: 6| Step: 1
Training loss: 2.270684531933221
Validation loss: 2.4924892613553626

Epoch: 6| Step: 2
Training loss: 2.341288787471621
Validation loss: 2.5079956780041006

Epoch: 6| Step: 3
Training loss: 1.6770307955203254
Validation loss: 2.508011585228104

Epoch: 6| Step: 4
Training loss: 2.484369625829486
Validation loss: 2.5059707945872147

Epoch: 6| Step: 5
Training loss: 2.4841103082879945
Validation loss: 2.504913635262563

Epoch: 6| Step: 6
Training loss: 2.4974394082784994
Validation loss: 2.507945135457473

Epoch: 6| Step: 7
Training loss: 2.057497373187589
Validation loss: 2.515417433995506

Epoch: 6| Step: 8
Training loss: 2.6031936251786765
Validation loss: 2.505456802407875

Epoch: 6| Step: 9
Training loss: 2.2651184568102765
Validation loss: 2.514243131399279

Epoch: 6| Step: 10
Training loss: 2.790186807674786
Validation loss: 2.5046544536680004

Epoch: 6| Step: 11
Training loss: 2.8305464857873512
Validation loss: 2.501349831793422

Epoch: 6| Step: 12
Training loss: 2.2598196433690543
Validation loss: 2.487368733250865

Epoch: 6| Step: 13
Training loss: 2.4928836627475524
Validation loss: 2.48619344126263

Epoch: 182| Step: 0
Training loss: 2.5636973491230184
Validation loss: 2.4833839887107936

Epoch: 6| Step: 1
Training loss: 2.2500892197615645
Validation loss: 2.4919135123450844

Epoch: 6| Step: 2
Training loss: 2.5595650030646477
Validation loss: 2.487817422623722

Epoch: 6| Step: 3
Training loss: 2.8365696394299817
Validation loss: 2.4942107403607525

Epoch: 6| Step: 4
Training loss: 2.56237727545893
Validation loss: 2.488523614199726

Epoch: 6| Step: 5
Training loss: 1.8737766089404582
Validation loss: 2.4920219278692395

Epoch: 6| Step: 6
Training loss: 2.7603092292654843
Validation loss: 2.4811669115556816

Epoch: 6| Step: 7
Training loss: 2.6639493767221407
Validation loss: 2.487975879817011

Epoch: 6| Step: 8
Training loss: 2.307652728646109
Validation loss: 2.4855715910938514

Epoch: 6| Step: 9
Training loss: 2.1943435431137663
Validation loss: 2.4864974482421136

Epoch: 6| Step: 10
Training loss: 2.2254348844225227
Validation loss: 2.480080946196041

Epoch: 6| Step: 11
Training loss: 2.7834562487691907
Validation loss: 2.4871825502859783

Epoch: 6| Step: 12
Training loss: 2.573552463652647
Validation loss: 2.4796177002333866

Epoch: 6| Step: 13
Training loss: 2.3628276295020507
Validation loss: 2.4757858406330087

Epoch: 183| Step: 0
Training loss: 2.116432759234068
Validation loss: 2.483323888526041

Epoch: 6| Step: 1
Training loss: 2.7426559178585723
Validation loss: 2.502373824036607

Epoch: 6| Step: 2
Training loss: 2.047511460455003
Validation loss: 2.5159481938784416

Epoch: 6| Step: 3
Training loss: 2.801156799590761
Validation loss: 2.522296454639154

Epoch: 6| Step: 4
Training loss: 2.5800960519934537
Validation loss: 2.517388525334894

Epoch: 6| Step: 5
Training loss: 1.662919489202523
Validation loss: 2.510295094650094

Epoch: 6| Step: 6
Training loss: 2.771199013426387
Validation loss: 2.4960195801987846

Epoch: 6| Step: 7
Training loss: 1.6469714257749999
Validation loss: 2.5109693517684413

Epoch: 6| Step: 8
Training loss: 2.1511282422344267
Validation loss: 2.503195000541626

Epoch: 6| Step: 9
Training loss: 2.9669328448722
Validation loss: 2.508492699394326

Epoch: 6| Step: 10
Training loss: 2.4661753302598983
Validation loss: 2.508824739342329

Epoch: 6| Step: 11
Training loss: 2.4656872643561085
Validation loss: 2.4984174169735627

Epoch: 6| Step: 12
Training loss: 2.4627100782294375
Validation loss: 2.5118784361802584

Epoch: 6| Step: 13
Training loss: 2.607868604930758
Validation loss: 2.514219590442316

Epoch: 184| Step: 0
Training loss: 2.707139226348087
Validation loss: 2.5090542548303842

Epoch: 6| Step: 1
Training loss: 2.0103397124061755
Validation loss: 2.5103495867197148

Epoch: 6| Step: 2
Training loss: 2.2480642680962686
Validation loss: 2.4991162486479874

Epoch: 6| Step: 3
Training loss: 2.172499861810502
Validation loss: 2.507679112770071

Epoch: 6| Step: 4
Training loss: 1.905566984290033
Validation loss: 2.5012988928331517

Epoch: 6| Step: 5
Training loss: 2.4747775893029487
Validation loss: 2.502697728869514

Epoch: 6| Step: 6
Training loss: 2.6214261931441625
Validation loss: 2.5068853294421607

Epoch: 6| Step: 7
Training loss: 2.7452025615670737
Validation loss: 2.5174530211291986

Epoch: 6| Step: 8
Training loss: 2.341903162334628
Validation loss: 2.523024100975391

Epoch: 6| Step: 9
Training loss: 1.9229017786818348
Validation loss: 2.5208535127909233

Epoch: 6| Step: 10
Training loss: 2.7519496595524666
Validation loss: 2.522495255265753

Epoch: 6| Step: 11
Training loss: 2.524156969802616
Validation loss: 2.5352492430509996

Epoch: 6| Step: 12
Training loss: 2.8766216182901867
Validation loss: 2.5337576983372063

Epoch: 6| Step: 13
Training loss: 2.320117364249667
Validation loss: 2.5156641339087593

Epoch: 185| Step: 0
Training loss: 2.4241486736253615
Validation loss: 2.5078021848472387

Epoch: 6| Step: 1
Training loss: 2.107085730584186
Validation loss: 2.4961086187183485

Epoch: 6| Step: 2
Training loss: 2.4327589045055764
Validation loss: 2.496920946547507

Epoch: 6| Step: 3
Training loss: 2.294747957173224
Validation loss: 2.4915708299107897

Epoch: 6| Step: 4
Training loss: 2.479865822392476
Validation loss: 2.49014002004149

Epoch: 6| Step: 5
Training loss: 2.1243199775036925
Validation loss: 2.488025502426838

Epoch: 6| Step: 6
Training loss: 2.370460387955618
Validation loss: 2.4980736622431694

Epoch: 6| Step: 7
Training loss: 2.6192545912238963
Validation loss: 2.5074879088637982

Epoch: 6| Step: 8
Training loss: 2.673962764540655
Validation loss: 2.505412980971508

Epoch: 6| Step: 9
Training loss: 1.8871200482258714
Validation loss: 2.505014318195572

Epoch: 6| Step: 10
Training loss: 2.4060880928560153
Validation loss: 2.5067085220853325

Epoch: 6| Step: 11
Training loss: 2.439671844866093
Validation loss: 2.5013762977203653

Epoch: 6| Step: 12
Training loss: 3.129634777125887
Validation loss: 2.501022892544809

Epoch: 6| Step: 13
Training loss: 2.2889065738208756
Validation loss: 2.4981563684299295

Epoch: 186| Step: 0
Training loss: 2.1605030078121015
Validation loss: 2.503844198409245

Epoch: 6| Step: 1
Training loss: 2.171295527813753
Validation loss: 2.5024879949931504

Epoch: 6| Step: 2
Training loss: 1.979942899034745
Validation loss: 2.5110116045243256

Epoch: 6| Step: 3
Training loss: 2.459445173917703
Validation loss: 2.4947975227642947

Epoch: 6| Step: 4
Training loss: 2.3498367618112166
Validation loss: 2.4944356824961242

Epoch: 6| Step: 5
Training loss: 2.379352797015612
Validation loss: 2.5039439880415517

Epoch: 6| Step: 6
Training loss: 2.937974931998196
Validation loss: 2.5116301699414465

Epoch: 6| Step: 7
Training loss: 2.5315675889451303
Validation loss: 2.5111135304372754

Epoch: 6| Step: 8
Training loss: 2.8760713985849344
Validation loss: 2.506360038440865

Epoch: 6| Step: 9
Training loss: 2.175818615905864
Validation loss: 2.5040375054722412

Epoch: 6| Step: 10
Training loss: 2.2760992559367828
Validation loss: 2.502864198278161

Epoch: 6| Step: 11
Training loss: 2.8782671732791534
Validation loss: 2.50041155606471

Epoch: 6| Step: 12
Training loss: 1.8182413654979934
Validation loss: 2.500719825111817

Epoch: 6| Step: 13
Training loss: 2.2419837566675485
Validation loss: 2.507897301306688

Epoch: 187| Step: 0
Training loss: 2.0741982899032103
Validation loss: 2.50630882872731

Epoch: 6| Step: 1
Training loss: 2.1592038695431803
Validation loss: 2.5081763077903223

Epoch: 6| Step: 2
Training loss: 2.396563565190181
Validation loss: 2.5066344919912895

Epoch: 6| Step: 3
Training loss: 2.8807216598439602
Validation loss: 2.499927535596307

Epoch: 6| Step: 4
Training loss: 1.902928444620091
Validation loss: 2.49137547895541

Epoch: 6| Step: 5
Training loss: 2.251150049239156
Validation loss: 2.4890434339439254

Epoch: 6| Step: 6
Training loss: 2.4868994788273504
Validation loss: 2.4949799362425766

Epoch: 6| Step: 7
Training loss: 2.308673682983265
Validation loss: 2.4906184360317143

Epoch: 6| Step: 8
Training loss: 1.8052166579975966
Validation loss: 2.4924812741661855

Epoch: 6| Step: 9
Training loss: 3.4955879740644247
Validation loss: 2.5000524356429312

Epoch: 6| Step: 10
Training loss: 2.873659235917649
Validation loss: 2.5024282027725864

Epoch: 6| Step: 11
Training loss: 2.2002592454232097
Validation loss: 2.5073060567136753

Epoch: 6| Step: 12
Training loss: 2.4343242987664855
Validation loss: 2.509752167147365

Epoch: 6| Step: 13
Training loss: 1.8008512868108382
Validation loss: 2.500180555817159

Epoch: 188| Step: 0
Training loss: 1.7804651371650146
Validation loss: 2.508672200459988

Epoch: 6| Step: 1
Training loss: 2.635986588161774
Validation loss: 2.5052878485503283

Epoch: 6| Step: 2
Training loss: 2.1062094211914273
Validation loss: 2.503559074594229

Epoch: 6| Step: 3
Training loss: 2.047754229923463
Validation loss: 2.5072474570999845

Epoch: 6| Step: 4
Training loss: 2.625775722144862
Validation loss: 2.510763379183993

Epoch: 6| Step: 5
Training loss: 2.1979194990624955
Validation loss: 2.511377377644434

Epoch: 6| Step: 6
Training loss: 2.454160629636359
Validation loss: 2.5129415680765756

Epoch: 6| Step: 7
Training loss: 3.1806087424668017
Validation loss: 2.5116961187961735

Epoch: 6| Step: 8
Training loss: 2.17711758624666
Validation loss: 2.518262645310855

Epoch: 6| Step: 9
Training loss: 2.013540920435699
Validation loss: 2.5105988738441862

Epoch: 6| Step: 10
Training loss: 2.6416095049557122
Validation loss: 2.5172629226886802

Epoch: 6| Step: 11
Training loss: 1.945483587010978
Validation loss: 2.5130483095449176

Epoch: 6| Step: 12
Training loss: 2.3942861011464496
Validation loss: 2.5256994638319408

Epoch: 6| Step: 13
Training loss: 2.9968419937368744
Validation loss: 2.526296092850324

Epoch: 189| Step: 0
Training loss: 1.5779744444688737
Validation loss: 2.523912540597121

Epoch: 6| Step: 1
Training loss: 2.338981660657651
Validation loss: 2.5217615788262244

Epoch: 6| Step: 2
Training loss: 2.603604451844135
Validation loss: 2.514363306169897

Epoch: 6| Step: 3
Training loss: 2.216708681478024
Validation loss: 2.51614602737147

Epoch: 6| Step: 4
Training loss: 2.0423158145628637
Validation loss: 2.509818363254063

Epoch: 6| Step: 5
Training loss: 2.7536683324754856
Validation loss: 2.5154912372037903

Epoch: 6| Step: 6
Training loss: 2.48199636922935
Validation loss: 2.5010799777332404

Epoch: 6| Step: 7
Training loss: 1.8798213007387647
Validation loss: 2.5081082622224025

Epoch: 6| Step: 8
Training loss: 2.62252472930391
Validation loss: 2.501451341239015

Epoch: 6| Step: 9
Training loss: 2.6227165462959117
Validation loss: 2.5037635607835447

Epoch: 6| Step: 10
Training loss: 2.1365313962151222
Validation loss: 2.5139150553747136

Epoch: 6| Step: 11
Training loss: 2.706936216681668
Validation loss: 2.5137678442722704

Epoch: 6| Step: 12
Training loss: 2.2916029025367894
Validation loss: 2.5167101776285885

Epoch: 6| Step: 13
Training loss: 2.9383564775853315
Validation loss: 2.5170725415162685

Epoch: 190| Step: 0
Training loss: 2.784348893819201
Validation loss: 2.5181578054379705

Epoch: 6| Step: 1
Training loss: 2.0267558926884517
Validation loss: 2.5163375445601983

Epoch: 6| Step: 2
Training loss: 3.607047515429268
Validation loss: 2.504845374151669

Epoch: 6| Step: 3
Training loss: 3.002237121610317
Validation loss: 2.5064852837958034

Epoch: 6| Step: 4
Training loss: 2.5358624290312295
Validation loss: 2.5075291268510176

Epoch: 6| Step: 5
Training loss: 1.4113330949726963
Validation loss: 2.497359295771009

Epoch: 6| Step: 6
Training loss: 2.2474639163234147
Validation loss: 2.507349591496702

Epoch: 6| Step: 7
Training loss: 1.8066224133372637
Validation loss: 2.5097557691091135

Epoch: 6| Step: 8
Training loss: 2.3525710873702352
Validation loss: 2.5030421503256726

Epoch: 6| Step: 9
Training loss: 2.138858372469222
Validation loss: 2.5134122290062755

Epoch: 6| Step: 10
Training loss: 2.1707865231007246
Validation loss: 2.517710103949883

Epoch: 6| Step: 11
Training loss: 2.2212761481038896
Validation loss: 2.519413056669344

Epoch: 6| Step: 12
Training loss: 2.3679569617883853
Validation loss: 2.5284577812777296

Epoch: 6| Step: 13
Training loss: 2.230635281039696
Validation loss: 2.5208964825961977

Epoch: 191| Step: 0
Training loss: 2.2806920453558632
Validation loss: 2.5260754664935594

Epoch: 6| Step: 1
Training loss: 2.1562000213580585
Validation loss: 2.532992967737644

Epoch: 6| Step: 2
Training loss: 1.9426113510128535
Validation loss: 2.553168495582802

Epoch: 6| Step: 3
Training loss: 2.4039690179970594
Validation loss: 2.52078283800566

Epoch: 6| Step: 4
Training loss: 1.8488557885617238
Validation loss: 2.502678675870513

Epoch: 6| Step: 5
Training loss: 2.4009223516667317
Validation loss: 2.5064377071519184

Epoch: 6| Step: 6
Training loss: 2.5335310089219245
Validation loss: 2.4961256046083347

Epoch: 6| Step: 7
Training loss: 2.184128806630098
Validation loss: 2.4944191789326937

Epoch: 6| Step: 8
Training loss: 2.418969558883832
Validation loss: 2.4995419400511905

Epoch: 6| Step: 9
Training loss: 2.704066999937118
Validation loss: 2.500391730771294

Epoch: 6| Step: 10
Training loss: 2.805140551685329
Validation loss: 2.500570438790563

Epoch: 6| Step: 11
Training loss: 1.9867527450671203
Validation loss: 2.4999156460835974

Epoch: 6| Step: 12
Training loss: 2.968189387343022
Validation loss: 2.49784096631497

Epoch: 6| Step: 13
Training loss: 2.9212451602763485
Validation loss: 2.507404298131908

Epoch: 192| Step: 0
Training loss: 2.5524495906503772
Validation loss: 2.5114172264562873

Epoch: 6| Step: 1
Training loss: 2.5378557829588457
Validation loss: 2.506195925845091

Epoch: 6| Step: 2
Training loss: 2.2101118615265167
Validation loss: 2.5415119739004997

Epoch: 6| Step: 3
Training loss: 2.6263939017625626
Validation loss: 2.5710525452209785

Epoch: 6| Step: 4
Training loss: 2.455966931210538
Validation loss: 2.600030136545072

Epoch: 6| Step: 5
Training loss: 2.888934821798867
Validation loss: 2.5541062777807935

Epoch: 6| Step: 6
Training loss: 2.130025866714086
Validation loss: 2.54307017634372

Epoch: 6| Step: 7
Training loss: 2.9668682358517793
Validation loss: 2.519833584568608

Epoch: 6| Step: 8
Training loss: 1.7224869763860569
Validation loss: 2.4994085089003364

Epoch: 6| Step: 9
Training loss: 2.416954209771076
Validation loss: 2.496535507376467

Epoch: 6| Step: 10
Training loss: 2.055149041036095
Validation loss: 2.4795296721137206

Epoch: 6| Step: 11
Training loss: 2.755945281400465
Validation loss: 2.4715901869424357

Epoch: 6| Step: 12
Training loss: 2.0096971743004857
Validation loss: 2.4809025903204445

Epoch: 6| Step: 13
Training loss: 1.9949507753614153
Validation loss: 2.466254997589931

Epoch: 193| Step: 0
Training loss: 2.3117664307746453
Validation loss: 2.4706470910353766

Epoch: 6| Step: 1
Training loss: 1.5140707954675514
Validation loss: 2.466348937122603

Epoch: 6| Step: 2
Training loss: 2.44601089205621
Validation loss: 2.463423507684888

Epoch: 6| Step: 3
Training loss: 2.833985048027143
Validation loss: 2.467208992991486

Epoch: 6| Step: 4
Training loss: 2.33955822254903
Validation loss: 2.4690321427090716

Epoch: 6| Step: 5
Training loss: 2.3021035402081433
Validation loss: 2.4696918895897544

Epoch: 6| Step: 6
Training loss: 2.673128425215997
Validation loss: 2.4692197425211226

Epoch: 6| Step: 7
Training loss: 2.160872880323929
Validation loss: 2.468283725920891

Epoch: 6| Step: 8
Training loss: 2.851145089312801
Validation loss: 2.4677778172778044

Epoch: 6| Step: 9
Training loss: 2.6955162081930784
Validation loss: 2.467175267168883

Epoch: 6| Step: 10
Training loss: 2.4947924736727773
Validation loss: 2.469539194276303

Epoch: 6| Step: 11
Training loss: 2.394476188287968
Validation loss: 2.4704148678497733

Epoch: 6| Step: 12
Training loss: 2.95688466523856
Validation loss: 2.472782270405107

Epoch: 6| Step: 13
Training loss: 2.0872145040666825
Validation loss: 2.4845770507797895

Epoch: 194| Step: 0
Training loss: 2.391866722999687
Validation loss: 2.4875560364409885

Epoch: 6| Step: 1
Training loss: 2.818118438679224
Validation loss: 2.494694054166612

Epoch: 6| Step: 2
Training loss: 2.7028469758575575
Validation loss: 2.4920116749189463

Epoch: 6| Step: 3
Training loss: 1.8237541309542604
Validation loss: 2.498974891937422

Epoch: 6| Step: 4
Training loss: 2.6002121361974986
Validation loss: 2.5009577506044423

Epoch: 6| Step: 5
Training loss: 1.9427599111737892
Validation loss: 2.4990825877134197

Epoch: 6| Step: 6
Training loss: 1.5923397332096727
Validation loss: 2.485842864934449

Epoch: 6| Step: 7
Training loss: 1.5317500329532063
Validation loss: 2.5008259839266973

Epoch: 6| Step: 8
Training loss: 3.086253630464874
Validation loss: 2.4884813868004296

Epoch: 6| Step: 9
Training loss: 2.7061551260230954
Validation loss: 2.4890510011236944

Epoch: 6| Step: 10
Training loss: 1.930710864814295
Validation loss: 2.4928739074817874

Epoch: 6| Step: 11
Training loss: 1.9756027122913007
Validation loss: 2.488107512520486

Epoch: 6| Step: 12
Training loss: 2.9984773904553252
Validation loss: 2.483547576734279

Epoch: 6| Step: 13
Training loss: 2.702313604569952
Validation loss: 2.4848568527009594

Epoch: 195| Step: 0
Training loss: 2.149595524200675
Validation loss: 2.489265458843649

Epoch: 6| Step: 1
Training loss: 2.2866437716584445
Validation loss: 2.4857637534494

Epoch: 6| Step: 2
Training loss: 2.6711963884885033
Validation loss: 2.4942303997104602

Epoch: 6| Step: 3
Training loss: 1.8234029575400486
Validation loss: 2.485047191476237

Epoch: 6| Step: 4
Training loss: 2.551545523723092
Validation loss: 2.4913657018344986

Epoch: 6| Step: 5
Training loss: 2.141367094509315
Validation loss: 2.5007914164673264

Epoch: 6| Step: 6
Training loss: 1.7525251426471324
Validation loss: 2.5098485396130763

Epoch: 6| Step: 7
Training loss: 2.8370957544549475
Validation loss: 2.514591075650369

Epoch: 6| Step: 8
Training loss: 2.420458176170944
Validation loss: 2.522401059481552

Epoch: 6| Step: 9
Training loss: 2.4382948924241865
Validation loss: 2.5114364504932083

Epoch: 6| Step: 10
Training loss: 1.793091879878178
Validation loss: 2.5200902195579244

Epoch: 6| Step: 11
Training loss: 2.6262796098727565
Validation loss: 2.515714955745383

Epoch: 6| Step: 12
Training loss: 2.8144416041141715
Validation loss: 2.5387105844613096

Epoch: 6| Step: 13
Training loss: 2.8954796517918115
Validation loss: 2.5350495537874758

Epoch: 196| Step: 0
Training loss: 2.4135508566066632
Validation loss: 2.5167477394670583

Epoch: 6| Step: 1
Training loss: 2.339026000936424
Validation loss: 2.5037971270463912

Epoch: 6| Step: 2
Training loss: 2.1968632444064475
Validation loss: 2.5006371957636784

Epoch: 6| Step: 3
Training loss: 2.697466799272738
Validation loss: 2.4997976539104148

Epoch: 6| Step: 4
Training loss: 2.156783107147507
Validation loss: 2.4992842603363155

Epoch: 6| Step: 5
Training loss: 2.2756747743715353
Validation loss: 2.4949411388581457

Epoch: 6| Step: 6
Training loss: 2.7957006791581014
Validation loss: 2.5032996654489907

Epoch: 6| Step: 7
Training loss: 2.5782362480436736
Validation loss: 2.49414478322566

Epoch: 6| Step: 8
Training loss: 2.3343228784995502
Validation loss: 2.493721261810965

Epoch: 6| Step: 9
Training loss: 2.6375204944266324
Validation loss: 2.502992936554535

Epoch: 6| Step: 10
Training loss: 2.286921101679106
Validation loss: 2.5037815421992264

Epoch: 6| Step: 11
Training loss: 2.2761515249688276
Validation loss: 2.515393738156908

Epoch: 6| Step: 12
Training loss: 2.0493442696201156
Validation loss: 2.5022504849679414

Epoch: 6| Step: 13
Training loss: 2.433542315336022
Validation loss: 2.51135411045596

Epoch: 197| Step: 0
Training loss: 1.8022746019529672
Validation loss: 2.5143972840547635

Epoch: 6| Step: 1
Training loss: 2.199701774497742
Validation loss: 2.522773773489615

Epoch: 6| Step: 2
Training loss: 2.4027031854457332
Validation loss: 2.5362019863005267

Epoch: 6| Step: 3
Training loss: 2.274416263852788
Validation loss: 2.553581472777875

Epoch: 6| Step: 4
Training loss: 2.598372786513766
Validation loss: 2.5579219955469195

Epoch: 6| Step: 5
Training loss: 2.541550670123925
Validation loss: 2.5541340795266687

Epoch: 6| Step: 6
Training loss: 1.9265848769522709
Validation loss: 2.5523264918324275

Epoch: 6| Step: 7
Training loss: 2.5844179973231296
Validation loss: 2.5065706690032252

Epoch: 6| Step: 8
Training loss: 1.4882253401059093
Validation loss: 2.5049379537262455

Epoch: 6| Step: 9
Training loss: 3.0476140617573915
Validation loss: 2.494903535398719

Epoch: 6| Step: 10
Training loss: 2.4231682062712423
Validation loss: 2.4937728017148584

Epoch: 6| Step: 11
Training loss: 2.6719466528849405
Validation loss: 2.4890307740326603

Epoch: 6| Step: 12
Training loss: 2.6842403604583596
Validation loss: 2.4877193660910466

Epoch: 6| Step: 13
Training loss: 2.7427094661035647
Validation loss: 2.4960282087800363

Epoch: 198| Step: 0
Training loss: 2.298947806795879
Validation loss: 2.4885742318433897

Epoch: 6| Step: 1
Training loss: 2.726465174296046
Validation loss: 2.4876570385255854

Epoch: 6| Step: 2
Training loss: 2.4341701357706964
Validation loss: 2.4795598805499557

Epoch: 6| Step: 3
Training loss: 2.7702523867759754
Validation loss: 2.4903576868978896

Epoch: 6| Step: 4
Training loss: 2.5747533772705045
Validation loss: 2.4880563184158655

Epoch: 6| Step: 5
Training loss: 2.2702796214296512
Validation loss: 2.4994830391762375

Epoch: 6| Step: 6
Training loss: 1.945725975369612
Validation loss: 2.4898818620490526

Epoch: 6| Step: 7
Training loss: 2.339934332977681
Validation loss: 2.508261017585991

Epoch: 6| Step: 8
Training loss: 2.3048489788834767
Validation loss: 2.518463113378975

Epoch: 6| Step: 9
Training loss: 2.26783276556621
Validation loss: 2.515657002184271

Epoch: 6| Step: 10
Training loss: 2.3289359299727352
Validation loss: 2.517443187442556

Epoch: 6| Step: 11
Training loss: 1.9861423101694191
Validation loss: 2.5294183925271336

Epoch: 6| Step: 12
Training loss: 2.189775863395425
Validation loss: 2.5104360197173397

Epoch: 6| Step: 13
Training loss: 2.989294979708093
Validation loss: 2.524388011254401

Epoch: 199| Step: 0
Training loss: 2.1950827916200906
Validation loss: 2.51344264678953

Epoch: 6| Step: 1
Training loss: 2.307008770433678
Validation loss: 2.519734708077332

Epoch: 6| Step: 2
Training loss: 2.6277569416699538
Validation loss: 2.51161392175095

Epoch: 6| Step: 3
Training loss: 2.42814140559758
Validation loss: 2.5071772070764595

Epoch: 6| Step: 4
Training loss: 2.550908551391256
Validation loss: 2.5198957785746896

Epoch: 6| Step: 5
Training loss: 2.0496109011691477
Validation loss: 2.51752595968288

Epoch: 6| Step: 6
Training loss: 1.7756475046645754
Validation loss: 2.5143199876517657

Epoch: 6| Step: 7
Training loss: 2.735996484910369
Validation loss: 2.5125562300961217

Epoch: 6| Step: 8
Training loss: 1.9647283501228894
Validation loss: 2.507465500954007

Epoch: 6| Step: 9
Training loss: 2.6185146326162827
Validation loss: 2.5108955501651624

Epoch: 6| Step: 10
Training loss: 2.593757905143733
Validation loss: 2.5165929570887906

Epoch: 6| Step: 11
Training loss: 1.9624865367451896
Validation loss: 2.5186350330022504

Epoch: 6| Step: 12
Training loss: 1.8741632501829133
Validation loss: 2.5328554940893886

Epoch: 6| Step: 13
Training loss: 3.2597844950116652
Validation loss: 2.5548863309271184

Epoch: 200| Step: 0
Training loss: 2.5291234255199315
Validation loss: 2.549856254789615

Epoch: 6| Step: 1
Training loss: 2.390870324805212
Validation loss: 2.543976271154794

Epoch: 6| Step: 2
Training loss: 2.0987101771817844
Validation loss: 2.536660083890871

Epoch: 6| Step: 3
Training loss: 2.3795397686954556
Validation loss: 2.5329126305685774

Epoch: 6| Step: 4
Training loss: 3.06521688344259
Validation loss: 2.524399061422829

Epoch: 6| Step: 5
Training loss: 2.1841189822459715
Validation loss: 2.54221761443768

Epoch: 6| Step: 6
Training loss: 2.3733603188055663
Validation loss: 2.5247743999932566

Epoch: 6| Step: 7
Training loss: 1.9301208133141945
Validation loss: 2.5305418271910085

Epoch: 6| Step: 8
Training loss: 2.6809699990494527
Validation loss: 2.5288083894745124

Epoch: 6| Step: 9
Training loss: 2.4528518816289027
Validation loss: 2.5299658952206077

Epoch: 6| Step: 10
Training loss: 1.7550065087743847
Validation loss: 2.534058037632927

Epoch: 6| Step: 11
Training loss: 2.283607205675269
Validation loss: 2.5475031774274575

Epoch: 6| Step: 12
Training loss: 1.685831587384021
Validation loss: 2.5319551498243498

Epoch: 6| Step: 13
Training loss: 2.989237553784259
Validation loss: 2.496886953644353

Epoch: 201| Step: 0
Training loss: 2.42077513300345
Validation loss: 2.49955098570364

Epoch: 6| Step: 1
Training loss: 2.429785429032806
Validation loss: 2.4982296238301163

Epoch: 6| Step: 2
Training loss: 2.1581668902501203
Validation loss: 2.497047842931919

Epoch: 6| Step: 3
Training loss: 2.0443492185949004
Validation loss: 2.5060624842839205

Epoch: 6| Step: 4
Training loss: 2.248190470069089
Validation loss: 2.4910651762103067

Epoch: 6| Step: 5
Training loss: 2.283072905991722
Validation loss: 2.5040338556125623

Epoch: 6| Step: 6
Training loss: 2.777312245036017
Validation loss: 2.4979739085286337

Epoch: 6| Step: 7
Training loss: 2.1163531133741085
Validation loss: 2.4975707172237525

Epoch: 6| Step: 8
Training loss: 2.2332784456179264
Validation loss: 2.4932982103233465

Epoch: 6| Step: 9
Training loss: 1.9568074416295906
Validation loss: 2.5033818418354996

Epoch: 6| Step: 10
Training loss: 3.1612750549650896
Validation loss: 2.4922840892924536

Epoch: 6| Step: 11
Training loss: 2.804464772341018
Validation loss: 2.504190620227401

Epoch: 6| Step: 12
Training loss: 2.5419319723107203
Validation loss: 2.509444603879042

Epoch: 6| Step: 13
Training loss: 2.7961073519900017
Validation loss: 2.511754994306399

Epoch: 202| Step: 0
Training loss: 2.382754165685797
Validation loss: 2.5238645052554762

Epoch: 6| Step: 1
Training loss: 2.2327215305640857
Validation loss: 2.536506829917631

Epoch: 6| Step: 2
Training loss: 2.3830016014231408
Validation loss: 2.557265851938719

Epoch: 6| Step: 3
Training loss: 2.5623366140985837
Validation loss: 2.5692242576717796

Epoch: 6| Step: 4
Training loss: 2.6265925163446506
Validation loss: 2.6092360834540846

Epoch: 6| Step: 5
Training loss: 2.3670323890755314
Validation loss: 2.5760300727168906

Epoch: 6| Step: 6
Training loss: 1.7412874779429917
Validation loss: 2.5702905006588064

Epoch: 6| Step: 7
Training loss: 1.4964578449443728
Validation loss: 2.5417724702002626

Epoch: 6| Step: 8
Training loss: 2.020535424155824
Validation loss: 2.5365661791382

Epoch: 6| Step: 9
Training loss: 2.5553810041588743
Validation loss: 2.5357138280657043

Epoch: 6| Step: 10
Training loss: 2.4604434531678576
Validation loss: 2.516873446763163

Epoch: 6| Step: 11
Training loss: 2.9444935112789548
Validation loss: 2.51372570107665

Epoch: 6| Step: 12
Training loss: 2.511874987546945
Validation loss: 2.5100085505812295

Epoch: 6| Step: 13
Training loss: 2.8014969809041186
Validation loss: 2.509324074779109

Epoch: 203| Step: 0
Training loss: 2.21314875687197
Validation loss: 2.50137021344142

Epoch: 6| Step: 1
Training loss: 2.9976217061613215
Validation loss: 2.5081693211243863

Epoch: 6| Step: 2
Training loss: 1.6722682597320695
Validation loss: 2.5095267136357844

Epoch: 6| Step: 3
Training loss: 2.560722478901733
Validation loss: 2.5018337676905347

Epoch: 6| Step: 4
Training loss: 2.868657787561324
Validation loss: 2.512439772609969

Epoch: 6| Step: 5
Training loss: 2.149548607393109
Validation loss: 2.5177782214471947

Epoch: 6| Step: 6
Training loss: 3.055976303108572
Validation loss: 2.54032583254391

Epoch: 6| Step: 7
Training loss: 2.7255686175439484
Validation loss: 2.5137981471011757

Epoch: 6| Step: 8
Training loss: 2.1154134715052813
Validation loss: 2.5346449937479134

Epoch: 6| Step: 9
Training loss: 2.489758686184203
Validation loss: 2.5213846176589634

Epoch: 6| Step: 10
Training loss: 1.59065761869969
Validation loss: 2.5432067384706776

Epoch: 6| Step: 11
Training loss: 1.7312731799835832
Validation loss: 2.5364501033913154

Epoch: 6| Step: 12
Training loss: 2.312228831295451
Validation loss: 2.5520819579659215

Epoch: 6| Step: 13
Training loss: 2.268295923616389
Validation loss: 2.532453015636289

Epoch: 204| Step: 0
Training loss: 2.539220998658702
Validation loss: 2.520896190984067

Epoch: 6| Step: 1
Training loss: 1.9491036482408248
Validation loss: 2.50941564987024

Epoch: 6| Step: 2
Training loss: 2.004571934235927
Validation loss: 2.52519635611016

Epoch: 6| Step: 3
Training loss: 2.1422885639994607
Validation loss: 2.509317598046611

Epoch: 6| Step: 4
Training loss: 2.7243484208030604
Validation loss: 2.5196462126928356

Epoch: 6| Step: 5
Training loss: 2.8240788637501644
Validation loss: 2.5152810771880008

Epoch: 6| Step: 6
Training loss: 2.6090034631521184
Validation loss: 2.516394013883664

Epoch: 6| Step: 7
Training loss: 1.7536910504896885
Validation loss: 2.5243776064219645

Epoch: 6| Step: 8
Training loss: 2.6461711177321976
Validation loss: 2.515147928054824

Epoch: 6| Step: 9
Training loss: 2.716340674595406
Validation loss: 2.5200361509858533

Epoch: 6| Step: 10
Training loss: 2.2184064357338187
Validation loss: 2.5214378851030665

Epoch: 6| Step: 11
Training loss: 2.3536047700959393
Validation loss: 2.520248618501766

Epoch: 6| Step: 12
Training loss: 2.198171471263704
Validation loss: 2.5339224408561147

Epoch: 6| Step: 13
Training loss: 2.143556689563416
Validation loss: 2.5337377183638794

Epoch: 205| Step: 0
Training loss: 2.4078082699153707
Validation loss: 2.5284127161677357

Epoch: 6| Step: 1
Training loss: 2.59605452410038
Validation loss: 2.52757090000281

Epoch: 6| Step: 2
Training loss: 2.29464634316706
Validation loss: 2.5447188691886082

Epoch: 6| Step: 3
Training loss: 2.512982419894774
Validation loss: 2.534098305984942

Epoch: 6| Step: 4
Training loss: 2.41749245138479
Validation loss: 2.536742205599974

Epoch: 6| Step: 5
Training loss: 2.147310828513303
Validation loss: 2.532318439182583

Epoch: 6| Step: 6
Training loss: 2.0706297433455116
Validation loss: 2.5421760288410344

Epoch: 6| Step: 7
Training loss: 2.794194818027424
Validation loss: 2.545946712643451

Epoch: 6| Step: 8
Training loss: 2.3155069133183344
Validation loss: 2.537095701960486

Epoch: 6| Step: 9
Training loss: 2.2254126005475436
Validation loss: 2.5317249558924875

Epoch: 6| Step: 10
Training loss: 1.965726619938003
Validation loss: 2.5285194959944333

Epoch: 6| Step: 11
Training loss: 2.070059131017325
Validation loss: 2.5372182085139916

Epoch: 6| Step: 12
Training loss: 2.3018582839628166
Validation loss: 2.536130101914023

Epoch: 6| Step: 13
Training loss: 2.6600569427820098
Validation loss: 2.523990676762913

Epoch: 206| Step: 0
Training loss: 2.5069913381298323
Validation loss: 2.511058224155805

Epoch: 6| Step: 1
Training loss: 2.6898232996880895
Validation loss: 2.524269848558907

Epoch: 6| Step: 2
Training loss: 2.4481942743117733
Validation loss: 2.5067241679945074

Epoch: 6| Step: 3
Training loss: 2.24004429058157
Validation loss: 2.50791870716234

Epoch: 6| Step: 4
Training loss: 1.5872770768687652
Validation loss: 2.507397372705546

Epoch: 6| Step: 5
Training loss: 3.0531181343181024
Validation loss: 2.506026554056284

Epoch: 6| Step: 6
Training loss: 2.058104715765728
Validation loss: 2.5179251349563097

Epoch: 6| Step: 7
Training loss: 2.104507028478703
Validation loss: 2.531284025929015

Epoch: 6| Step: 8
Training loss: 2.1203194850730673
Validation loss: 2.5504328366607147

Epoch: 6| Step: 9
Training loss: 2.698531641640516
Validation loss: 2.558058774507028

Epoch: 6| Step: 10
Training loss: 2.827258151071726
Validation loss: 2.5442624412458086

Epoch: 6| Step: 11
Training loss: 1.4734475516727827
Validation loss: 2.5583179742639928

Epoch: 6| Step: 12
Training loss: 2.5683354249715076
Validation loss: 2.547507131564684

Epoch: 6| Step: 13
Training loss: 2.3997936080561364
Validation loss: 2.536316812210865

Epoch: 207| Step: 0
Training loss: 2.0052547565057086
Validation loss: 2.5190407918797533

Epoch: 6| Step: 1
Training loss: 2.5345271994989518
Validation loss: 2.5027525292493222

Epoch: 6| Step: 2
Training loss: 1.66522384020994
Validation loss: 2.497221531253201

Epoch: 6| Step: 3
Training loss: 2.166871159024461
Validation loss: 2.487124011763209

Epoch: 6| Step: 4
Training loss: 2.0660869733925322
Validation loss: 2.501373597128404

Epoch: 6| Step: 5
Training loss: 2.6344935995716674
Validation loss: 2.489592920601446

Epoch: 6| Step: 6
Training loss: 2.385708409311124
Validation loss: 2.497775725481307

Epoch: 6| Step: 7
Training loss: 2.747728797056815
Validation loss: 2.493425936504967

Epoch: 6| Step: 8
Training loss: 2.48822970015038
Validation loss: 2.4843131963371925

Epoch: 6| Step: 9
Training loss: 3.3408392956107122
Validation loss: 2.484910823212054

Epoch: 6| Step: 10
Training loss: 2.0513352581300692
Validation loss: 2.4892197640086318

Epoch: 6| Step: 11
Training loss: 2.2106752273768078
Validation loss: 2.4919960801485113

Epoch: 6| Step: 12
Training loss: 1.976241979130315
Validation loss: 2.501199037387609

Epoch: 6| Step: 13
Training loss: 2.806074474257254
Validation loss: 2.511640342805651

Epoch: 208| Step: 0
Training loss: 1.321822707853097
Validation loss: 2.5105460570192446

Epoch: 6| Step: 1
Training loss: 1.9296836698548148
Validation loss: 2.550262320495807

Epoch: 6| Step: 2
Training loss: 1.779450561719888
Validation loss: 2.5468692584450876

Epoch: 6| Step: 3
Training loss: 2.633841746379365
Validation loss: 2.5516876900137198

Epoch: 6| Step: 4
Training loss: 2.2563913485984175
Validation loss: 2.5542538787199027

Epoch: 6| Step: 5
Training loss: 2.5922335132564265
Validation loss: 2.516510785772043

Epoch: 6| Step: 6
Training loss: 2.553798509194005
Validation loss: 2.5127645622127237

Epoch: 6| Step: 7
Training loss: 2.6020887604395457
Validation loss: 2.495319491133573

Epoch: 6| Step: 8
Training loss: 3.0271638681437
Validation loss: 2.5067039725473164

Epoch: 6| Step: 9
Training loss: 2.8768183721305776
Validation loss: 2.4970100165805187

Epoch: 6| Step: 10
Training loss: 2.7906693817061066
Validation loss: 2.4945784592494578

Epoch: 6| Step: 11
Training loss: 2.8239505371376374
Validation loss: 2.5138312000050713

Epoch: 6| Step: 12
Training loss: 2.018222524980671
Validation loss: 2.502411855135476

Epoch: 6| Step: 13
Training loss: 1.8998208363033842
Validation loss: 2.518360932672499

Epoch: 209| Step: 0
Training loss: 2.721203190510887
Validation loss: 2.5204889335452445

Epoch: 6| Step: 1
Training loss: 1.654699283374187
Validation loss: 2.5538153447725462

Epoch: 6| Step: 2
Training loss: 2.1209119855864476
Validation loss: 2.5774821086747295

Epoch: 6| Step: 3
Training loss: 2.275890901112861
Validation loss: 2.579407621435734

Epoch: 6| Step: 4
Training loss: 2.559576273958147
Validation loss: 2.599896803666361

Epoch: 6| Step: 5
Training loss: 3.1722986098172776
Validation loss: 2.6196662968896884

Epoch: 6| Step: 6
Training loss: 2.3262816434467797
Validation loss: 2.5798124551498973

Epoch: 6| Step: 7
Training loss: 1.7036647816180301
Validation loss: 2.557865728415958

Epoch: 6| Step: 8
Training loss: 2.014751629537285
Validation loss: 2.5493642737607263

Epoch: 6| Step: 9
Training loss: 2.9694845796574265
Validation loss: 2.5231726067459648

Epoch: 6| Step: 10
Training loss: 2.4125645999462013
Validation loss: 2.5073135687760675

Epoch: 6| Step: 11
Training loss: 1.8684005946502034
Validation loss: 2.4972595294329234

Epoch: 6| Step: 12
Training loss: 2.8390185220993613
Validation loss: 2.498697593308601

Epoch: 6| Step: 13
Training loss: 2.5144588065635087
Validation loss: 2.501083504802061

Epoch: 210| Step: 0
Training loss: 1.978204881643131
Validation loss: 2.4989045842697726

Epoch: 6| Step: 1
Training loss: 1.7960896641708435
Validation loss: 2.5077799381982393

Epoch: 6| Step: 2
Training loss: 2.5706452035515763
Validation loss: 2.5089785834795015

Epoch: 6| Step: 3
Training loss: 1.958630911220059
Validation loss: 2.5185053666349013

Epoch: 6| Step: 4
Training loss: 1.9637831751050532
Validation loss: 2.5252288034846924

Epoch: 6| Step: 5
Training loss: 2.655095197188612
Validation loss: 2.527526227838235

Epoch: 6| Step: 6
Training loss: 2.3232893936986323
Validation loss: 2.5377771028949057

Epoch: 6| Step: 7
Training loss: 2.3997051852667837
Validation loss: 2.542734146039235

Epoch: 6| Step: 8
Training loss: 2.3075042580744016
Validation loss: 2.559340428703802

Epoch: 6| Step: 9
Training loss: 2.562244867789222
Validation loss: 2.5802352745755375

Epoch: 6| Step: 10
Training loss: 2.8376133698657435
Validation loss: 2.565729354861076

Epoch: 6| Step: 11
Training loss: 2.0443480523624147
Validation loss: 2.53666136840922

Epoch: 6| Step: 12
Training loss: 3.1616305577199086
Validation loss: 2.522994105827713

Epoch: 6| Step: 13
Training loss: 2.480648869260024
Validation loss: 2.5187092862179288

Epoch: 211| Step: 0
Training loss: 2.607086182890921
Validation loss: 2.4979356348772037

Epoch: 6| Step: 1
Training loss: 3.1501202878237504
Validation loss: 2.5109352325448206

Epoch: 6| Step: 2
Training loss: 1.9829379908513336
Validation loss: 2.5210625620464313

Epoch: 6| Step: 3
Training loss: 2.2777030229577813
Validation loss: 2.517275724753324

Epoch: 6| Step: 4
Training loss: 1.9739116035774735
Validation loss: 2.543278047861526

Epoch: 6| Step: 5
Training loss: 1.8402633674425255
Validation loss: 2.551556082517142

Epoch: 6| Step: 6
Training loss: 2.952666554868789
Validation loss: 2.561836373840729

Epoch: 6| Step: 7
Training loss: 2.1381260005410003
Validation loss: 2.5578607261428594

Epoch: 6| Step: 8
Training loss: 2.10351777851416
Validation loss: 2.5999420740326107

Epoch: 6| Step: 9
Training loss: 2.5710375844314455
Validation loss: 2.5815120604018658

Epoch: 6| Step: 10
Training loss: 2.100898609451109
Validation loss: 2.5756674565055304

Epoch: 6| Step: 11
Training loss: 2.332170491877906
Validation loss: 2.552976200369864

Epoch: 6| Step: 12
Training loss: 2.0809515753431986
Validation loss: 2.5430425817784976

Epoch: 6| Step: 13
Training loss: 2.538294655531698
Validation loss: 2.5250137492394105

Epoch: 212| Step: 0
Training loss: 2.340330859700703
Validation loss: 2.504555842603531

Epoch: 6| Step: 1
Training loss: 2.4885648508909393
Validation loss: 2.5112876541912326

Epoch: 6| Step: 2
Training loss: 2.545275601376576
Validation loss: 2.5119938044734855

Epoch: 6| Step: 3
Training loss: 2.2480176033878387
Validation loss: 2.513442488693895

Epoch: 6| Step: 4
Training loss: 2.251894365323219
Validation loss: 2.505864322505833

Epoch: 6| Step: 5
Training loss: 1.56305951591029
Validation loss: 2.51211952820762

Epoch: 6| Step: 6
Training loss: 2.0080689737700665
Validation loss: 2.5200559399970706

Epoch: 6| Step: 7
Training loss: 2.767092644020442
Validation loss: 2.5254655213742407

Epoch: 6| Step: 8
Training loss: 2.540370569005367
Validation loss: 2.53052219869508

Epoch: 6| Step: 9
Training loss: 2.2394421081963998
Validation loss: 2.534709763750322

Epoch: 6| Step: 10
Training loss: 2.4815644494964046
Validation loss: 2.5413962725867507

Epoch: 6| Step: 11
Training loss: 2.381216947070832
Validation loss: 2.5243912853834223

Epoch: 6| Step: 12
Training loss: 1.9439764988659998
Validation loss: 2.5298404458085852

Epoch: 6| Step: 13
Training loss: 2.967380890613065
Validation loss: 2.5116226707896634

Epoch: 213| Step: 0
Training loss: 1.4029987048974453
Validation loss: 2.5116342517488293

Epoch: 6| Step: 1
Training loss: 1.325478149006598
Validation loss: 2.510800887551403

Epoch: 6| Step: 2
Training loss: 2.230772622381612
Validation loss: 2.5215651077910692

Epoch: 6| Step: 3
Training loss: 2.320179225806071
Validation loss: 2.514604317978657

Epoch: 6| Step: 4
Training loss: 2.5237734544409527
Validation loss: 2.510148431105061

Epoch: 6| Step: 5
Training loss: 2.3771418901653734
Validation loss: 2.5070484776161046

Epoch: 6| Step: 6
Training loss: 2.473306049220426
Validation loss: 2.5249064355769235

Epoch: 6| Step: 7
Training loss: 3.2589428447851265
Validation loss: 2.5222540522087304

Epoch: 6| Step: 8
Training loss: 2.134878422583222
Validation loss: 2.5184457890235734

Epoch: 6| Step: 9
Training loss: 2.3506500400222783
Validation loss: 2.5524581063095892

Epoch: 6| Step: 10
Training loss: 2.3964350290355614
Validation loss: 2.5624894940540837

Epoch: 6| Step: 11
Training loss: 2.79100451991099
Validation loss: 2.587112881854253

Epoch: 6| Step: 12
Training loss: 2.1177747974639414
Validation loss: 2.5861246400482214

Epoch: 6| Step: 13
Training loss: 2.802909436224835
Validation loss: 2.5614816921844987

Epoch: 214| Step: 0
Training loss: 1.9490936177974418
Validation loss: 2.572049374422379

Epoch: 6| Step: 1
Training loss: 2.735214976312518
Validation loss: 2.5531363410339853

Epoch: 6| Step: 2
Training loss: 1.9760753649497849
Validation loss: 2.5604352773968255

Epoch: 6| Step: 3
Training loss: 2.7099579462258268
Validation loss: 2.568452032276861

Epoch: 6| Step: 4
Training loss: 3.0863369067576145
Validation loss: 2.5621616713931896

Epoch: 6| Step: 5
Training loss: 1.8043253481580352
Validation loss: 2.554245299041097

Epoch: 6| Step: 6
Training loss: 2.5064538620682812
Validation loss: 2.536685852457779

Epoch: 6| Step: 7
Training loss: 2.2850381413120826
Validation loss: 2.5319239029359437

Epoch: 6| Step: 8
Training loss: 2.6002035171378197
Validation loss: 2.5434197701214556

Epoch: 6| Step: 9
Training loss: 1.8702781349027051
Validation loss: 2.529507449306325

Epoch: 6| Step: 10
Training loss: 2.401070109851921
Validation loss: 2.5145905699753524

Epoch: 6| Step: 11
Training loss: 2.6898266679020293
Validation loss: 2.5072971024326876

Epoch: 6| Step: 12
Training loss: 1.7783023470914328
Validation loss: 2.5024545699602956

Epoch: 6| Step: 13
Training loss: 2.0690067420064193
Validation loss: 2.5122708929438677

Epoch: 215| Step: 0
Training loss: 2.413909808518054
Validation loss: 2.512376223626182

Epoch: 6| Step: 1
Training loss: 1.9923094469033817
Validation loss: 2.5071813436806076

Epoch: 6| Step: 2
Training loss: 1.847508237043506
Validation loss: 2.5244340375630165

Epoch: 6| Step: 3
Training loss: 1.9037802283929781
Validation loss: 2.5093553259661436

Epoch: 6| Step: 4
Training loss: 2.2625949987204654
Validation loss: 2.529697680045417

Epoch: 6| Step: 5
Training loss: 2.986444843972731
Validation loss: 2.5345418427500777

Epoch: 6| Step: 6
Training loss: 2.4701537957747233
Validation loss: 2.556033706219426

Epoch: 6| Step: 7
Training loss: 2.8436359759935597
Validation loss: 2.5609887016163344

Epoch: 6| Step: 8
Training loss: 2.0115461849530623
Validation loss: 2.558152861137036

Epoch: 6| Step: 9
Training loss: 2.1826979108044986
Validation loss: 2.5776769691885257

Epoch: 6| Step: 10
Training loss: 2.172828519891864
Validation loss: 2.5657892128930966

Epoch: 6| Step: 11
Training loss: 2.042724594785504
Validation loss: 2.568666528241236

Epoch: 6| Step: 12
Training loss: 2.2279498145103185
Validation loss: 2.557756111146419

Epoch: 6| Step: 13
Training loss: 3.068441116730256
Validation loss: 2.544701442506198

Epoch: 216| Step: 0
Training loss: 2.094833093881979
Validation loss: 2.5445796710131083

Epoch: 6| Step: 1
Training loss: 1.7719093494348819
Validation loss: 2.550650779732806

Epoch: 6| Step: 2
Training loss: 3.156373729735618
Validation loss: 2.5289222783557004

Epoch: 6| Step: 3
Training loss: 1.7527602089903018
Validation loss: 2.5227746397992656

Epoch: 6| Step: 4
Training loss: 2.2172795110620993
Validation loss: 2.5214029304397596

Epoch: 6| Step: 5
Training loss: 2.847904733457496
Validation loss: 2.516925609816455

Epoch: 6| Step: 6
Training loss: 2.680454155602301
Validation loss: 2.5142449331150014

Epoch: 6| Step: 7
Training loss: 2.4796858385509557
Validation loss: 2.5278612851984983

Epoch: 6| Step: 8
Training loss: 2.2419882230559947
Validation loss: 2.5288230658406365

Epoch: 6| Step: 9
Training loss: 1.689399780136858
Validation loss: 2.528084364895735

Epoch: 6| Step: 10
Training loss: 1.929270649106302
Validation loss: 2.5488178978881666

Epoch: 6| Step: 11
Training loss: 2.7732134661385106
Validation loss: 2.5514465523714094

Epoch: 6| Step: 12
Training loss: 2.3014922152662503
Validation loss: 2.542998314220266

Epoch: 6| Step: 13
Training loss: 2.4824597155480386
Validation loss: 2.5467646756294657

Epoch: 217| Step: 0
Training loss: 2.5114449786402457
Validation loss: 2.5623506331912043

Epoch: 6| Step: 1
Training loss: 2.587202609751039
Validation loss: 2.5476297379695114

Epoch: 6| Step: 2
Training loss: 2.4702026342756427
Validation loss: 2.5422328620588326

Epoch: 6| Step: 3
Training loss: 2.0454948373159203
Validation loss: 2.5421870329515888

Epoch: 6| Step: 4
Training loss: 2.3208448011387794
Validation loss: 2.537383712960313

Epoch: 6| Step: 5
Training loss: 2.445106765818712
Validation loss: 2.538801428259718

Epoch: 6| Step: 6
Training loss: 2.4093684017026726
Validation loss: 2.527749753687225

Epoch: 6| Step: 7
Training loss: 1.6561811900690029
Validation loss: 2.527203736315778

Epoch: 6| Step: 8
Training loss: 2.972233705904475
Validation loss: 2.5305397544290282

Epoch: 6| Step: 9
Training loss: 2.0527889632816607
Validation loss: 2.5216499351085897

Epoch: 6| Step: 10
Training loss: 2.1584339967718287
Validation loss: 2.5268012775992603

Epoch: 6| Step: 11
Training loss: 1.8011310758915116
Validation loss: 2.525491592973255

Epoch: 6| Step: 12
Training loss: 2.386350912415242
Validation loss: 2.5419464322150245

Epoch: 6| Step: 13
Training loss: 2.481803186665399
Validation loss: 2.5598703553234174

Epoch: 218| Step: 0
Training loss: 2.449286695690806
Validation loss: 2.551713182244212

Epoch: 6| Step: 1
Training loss: 2.2482180426663705
Validation loss: 2.5573743559500923

Epoch: 6| Step: 2
Training loss: 2.836892043535461
Validation loss: 2.5320114983990103

Epoch: 6| Step: 3
Training loss: 2.06599384656287
Validation loss: 2.529965533975441

Epoch: 6| Step: 4
Training loss: 2.511117154182582
Validation loss: 2.5295705207856707

Epoch: 6| Step: 5
Training loss: 2.6028217555777027
Validation loss: 2.507273607198234

Epoch: 6| Step: 6
Training loss: 2.4184718679353856
Validation loss: 2.5106544751326942

Epoch: 6| Step: 7
Training loss: 2.1913296555241724
Validation loss: 2.5146990349379688

Epoch: 6| Step: 8
Training loss: 1.9120634889795558
Validation loss: 2.514797027049576

Epoch: 6| Step: 9
Training loss: 2.141752516909684
Validation loss: 2.5106780099499417

Epoch: 6| Step: 10
Training loss: 2.513431896263705
Validation loss: 2.5192870344537877

Epoch: 6| Step: 11
Training loss: 2.138609222469852
Validation loss: 2.5187043087256575

Epoch: 6| Step: 12
Training loss: 2.99529660598287
Validation loss: 2.524347493556321

Epoch: 6| Step: 13
Training loss: 2.2056906620584615
Validation loss: 2.551514438878092

Epoch: 219| Step: 0
Training loss: 2.6253250465778915
Validation loss: 2.5668189086185103

Epoch: 6| Step: 1
Training loss: 1.6919842937047118
Validation loss: 2.5748902189438745

Epoch: 6| Step: 2
Training loss: 2.661471989566134
Validation loss: 2.577399735595732

Epoch: 6| Step: 3
Training loss: 2.4374254655446284
Validation loss: 2.5793972074629363

Epoch: 6| Step: 4
Training loss: 2.459390596100386
Validation loss: 2.588786220447575

Epoch: 6| Step: 5
Training loss: 2.609696967996573
Validation loss: 2.5828866700655535

Epoch: 6| Step: 6
Training loss: 2.040823106949111
Validation loss: 2.575570098642343

Epoch: 6| Step: 7
Training loss: 2.083299890885556
Validation loss: 2.5687292105892343

Epoch: 6| Step: 8
Training loss: 1.5593961786884545
Validation loss: 2.5682539730902163

Epoch: 6| Step: 9
Training loss: 2.574883289840304
Validation loss: 2.5539606987287495

Epoch: 6| Step: 10
Training loss: 2.3701142702843088
Validation loss: 2.5372419667708312

Epoch: 6| Step: 11
Training loss: 2.0842175196875585
Validation loss: 2.52056591465051

Epoch: 6| Step: 12
Training loss: 2.8586079553593646
Validation loss: 2.524963437183913

Epoch: 6| Step: 13
Training loss: 2.3723006719660242
Validation loss: 2.5068222578522756

Epoch: 220| Step: 0
Training loss: 2.596912156997165
Validation loss: 2.508387498703771

Epoch: 6| Step: 1
Training loss: 2.890213725757007
Validation loss: 2.508312535965416

Epoch: 6| Step: 2
Training loss: 2.5762125030853853
Validation loss: 2.5013204425308113

Epoch: 6| Step: 3
Training loss: 1.806494398643157
Validation loss: 2.5006670697661995

Epoch: 6| Step: 4
Training loss: 2.2133034491915304
Validation loss: 2.4997332033211777

Epoch: 6| Step: 5
Training loss: 2.9721608695316273
Validation loss: 2.505565060115624

Epoch: 6| Step: 6
Training loss: 1.7701647973794958
Validation loss: 2.5205154586335095

Epoch: 6| Step: 7
Training loss: 2.8315203607074038
Validation loss: 2.5252906600548406

Epoch: 6| Step: 8
Training loss: 2.505641009002949
Validation loss: 2.5174412617401924

Epoch: 6| Step: 9
Training loss: 2.27816291850784
Validation loss: 2.5192425072001354

Epoch: 6| Step: 10
Training loss: 2.3704476143858586
Validation loss: 2.494572071665732

Epoch: 6| Step: 11
Training loss: 2.3440041976409405
Validation loss: 2.4895778054743944

Epoch: 6| Step: 12
Training loss: 1.6030162633117278
Validation loss: 2.4868280228361526

Epoch: 6| Step: 13
Training loss: 2.284360672140002
Validation loss: 2.4779093596835686

Epoch: 221| Step: 0
Training loss: 2.509899091325967
Validation loss: 2.488334124216447

Epoch: 6| Step: 1
Training loss: 1.772662426133743
Validation loss: 2.4817490685153367

Epoch: 6| Step: 2
Training loss: 2.337567631360184
Validation loss: 2.48215000315569

Epoch: 6| Step: 3
Training loss: 3.3366971368252694
Validation loss: 2.4832227902056045

Epoch: 6| Step: 4
Training loss: 1.9027401238990729
Validation loss: 2.4867800701129976

Epoch: 6| Step: 5
Training loss: 2.5879640504029378
Validation loss: 2.486973329440685

Epoch: 6| Step: 6
Training loss: 1.778194751946884
Validation loss: 2.4932909747807814

Epoch: 6| Step: 7
Training loss: 2.5908963235056848
Validation loss: 2.500334431213916

Epoch: 6| Step: 8
Training loss: 2.28082825407058
Validation loss: 2.5106743697438083

Epoch: 6| Step: 9
Training loss: 2.087201824707368
Validation loss: 2.5347973178091854

Epoch: 6| Step: 10
Training loss: 2.4761219294635537
Validation loss: 2.518272602031499

Epoch: 6| Step: 11
Training loss: 2.5989177652274877
Validation loss: 2.5070438256705656

Epoch: 6| Step: 12
Training loss: 1.9659321313050104
Validation loss: 2.5177679471234304

Epoch: 6| Step: 13
Training loss: 2.292474176725258
Validation loss: 2.512696799040482

Epoch: 222| Step: 0
Training loss: 2.685033509171447
Validation loss: 2.517953714942685

Epoch: 6| Step: 1
Training loss: 2.1537786502006324
Validation loss: 2.509819756504231

Epoch: 6| Step: 2
Training loss: 1.8725898511284622
Validation loss: 2.5128062313074224

Epoch: 6| Step: 3
Training loss: 3.0669485985348186
Validation loss: 2.503778209378179

Epoch: 6| Step: 4
Training loss: 1.5230015057451767
Validation loss: 2.5170672687316142

Epoch: 6| Step: 5
Training loss: 2.486564007737423
Validation loss: 2.5132114450114473

Epoch: 6| Step: 6
Training loss: 2.144781824144627
Validation loss: 2.5270176892876024

Epoch: 6| Step: 7
Training loss: 2.469654448735873
Validation loss: 2.542249188087942

Epoch: 6| Step: 8
Training loss: 2.055163890308467
Validation loss: 2.5451009769805086

Epoch: 6| Step: 9
Training loss: 2.147851815587475
Validation loss: 2.5891605816751104

Epoch: 6| Step: 10
Training loss: 2.2907584615965564
Validation loss: 2.592971945501391

Epoch: 6| Step: 11
Training loss: 2.614769390725462
Validation loss: 2.5767327065248224

Epoch: 6| Step: 12
Training loss: 2.3548391838806526
Validation loss: 2.5786166098077836

Epoch: 6| Step: 13
Training loss: 2.4277573551431493
Validation loss: 2.5707981845013

Epoch: 223| Step: 0
Training loss: 1.8543865059243967
Validation loss: 2.5410583007731766

Epoch: 6| Step: 1
Training loss: 2.1597291824321343
Validation loss: 2.5365395242489295

Epoch: 6| Step: 2
Training loss: 1.7976516372110867
Validation loss: 2.526188173010951

Epoch: 6| Step: 3
Training loss: 2.3349686977077235
Validation loss: 2.5182815567347463

Epoch: 6| Step: 4
Training loss: 2.7318833688273085
Validation loss: 2.5187938784176334

Epoch: 6| Step: 5
Training loss: 2.719486619100389
Validation loss: 2.519786606891709

Epoch: 6| Step: 6
Training loss: 3.101372470367139
Validation loss: 2.5242746891429952

Epoch: 6| Step: 7
Training loss: 2.0696368572496553
Validation loss: 2.5370838769928947

Epoch: 6| Step: 8
Training loss: 1.7778364567543106
Validation loss: 2.5313836050683647

Epoch: 6| Step: 9
Training loss: 2.247501681691051
Validation loss: 2.5471500958051334

Epoch: 6| Step: 10
Training loss: 2.755085923781364
Validation loss: 2.5489561942751107

Epoch: 6| Step: 11
Training loss: 2.2129024764549143
Validation loss: 2.5478904353673637

Epoch: 6| Step: 12
Training loss: 2.238345799339198
Validation loss: 2.5702673570867924

Epoch: 6| Step: 13
Training loss: 2.272393370289021
Validation loss: 2.5430533477571764

Epoch: 224| Step: 0
Training loss: 2.337255201933945
Validation loss: 2.5341921453837375

Epoch: 6| Step: 1
Training loss: 2.525306883188371
Validation loss: 2.5250745567166817

Epoch: 6| Step: 2
Training loss: 2.0320241773248333
Validation loss: 2.542590791474681

Epoch: 6| Step: 3
Training loss: 2.3010270354975884
Validation loss: 2.5301643837862207

Epoch: 6| Step: 4
Training loss: 1.8927301084042298
Validation loss: 2.5371048016662336

Epoch: 6| Step: 5
Training loss: 2.209668877250305
Validation loss: 2.519856757692233

Epoch: 6| Step: 6
Training loss: 2.764037716648229
Validation loss: 2.5279760498379087

Epoch: 6| Step: 7
Training loss: 1.818695922257346
Validation loss: 2.532309455657411

Epoch: 6| Step: 8
Training loss: 3.126912104226173
Validation loss: 2.5421192725087467

Epoch: 6| Step: 9
Training loss: 1.6857127862743517
Validation loss: 2.539487394336274

Epoch: 6| Step: 10
Training loss: 2.6207971987838588
Validation loss: 2.5551478508748815

Epoch: 6| Step: 11
Training loss: 1.9872788936056407
Validation loss: 2.5639559013652935

Epoch: 6| Step: 12
Training loss: 2.2856030671275023
Validation loss: 2.5813141643194024

Epoch: 6| Step: 13
Training loss: 2.589895302560058
Validation loss: 2.5867887480756555

Epoch: 225| Step: 0
Training loss: 1.8580617674876463
Validation loss: 2.571231936544474

Epoch: 6| Step: 1
Training loss: 2.2729309146852943
Validation loss: 2.5751561805742527

Epoch: 6| Step: 2
Training loss: 2.1292359263084992
Validation loss: 2.554079782606485

Epoch: 6| Step: 3
Training loss: 2.587872291356049
Validation loss: 2.5350434092530008

Epoch: 6| Step: 4
Training loss: 2.481143985664697
Validation loss: 2.5317659009299343

Epoch: 6| Step: 5
Training loss: 2.2531256687623618
Validation loss: 2.5183087914602966

Epoch: 6| Step: 6
Training loss: 1.5415064582404834
Validation loss: 2.5171260028243605

Epoch: 6| Step: 7
Training loss: 3.0075984730061793
Validation loss: 2.5015573737024237

Epoch: 6| Step: 8
Training loss: 2.1084074839141267
Validation loss: 2.508484699797964

Epoch: 6| Step: 9
Training loss: 2.7997535937742897
Validation loss: 2.511418413129494

Epoch: 6| Step: 10
Training loss: 2.8535804610618407
Validation loss: 2.5203552948798293

Epoch: 6| Step: 11
Training loss: 1.556865374375721
Validation loss: 2.534230929856847

Epoch: 6| Step: 12
Training loss: 2.7535054665977587
Validation loss: 2.5315267152591536

Epoch: 6| Step: 13
Training loss: 1.814282428772808
Validation loss: 2.562360558166156

Epoch: 226| Step: 0
Training loss: 2.5905537962475207
Validation loss: 2.5696493760140533

Epoch: 6| Step: 1
Training loss: 2.237697558498862
Validation loss: 2.5859312458865475

Epoch: 6| Step: 2
Training loss: 2.579957807624678
Validation loss: 2.6370638096456798

Epoch: 6| Step: 3
Training loss: 2.6126998459887223
Validation loss: 2.640079825740568

Epoch: 6| Step: 4
Training loss: 2.473093003303904
Validation loss: 2.6456746982466814

Epoch: 6| Step: 5
Training loss: 2.7874097014029604
Validation loss: 2.660184123471581

Epoch: 6| Step: 6
Training loss: 2.1452693259721567
Validation loss: 2.6382290957839163

Epoch: 6| Step: 7
Training loss: 1.9938666952296353
Validation loss: 2.5975324940660673

Epoch: 6| Step: 8
Training loss: 2.608391673580242
Validation loss: 2.554006417699312

Epoch: 6| Step: 9
Training loss: 2.0387891096507187
Validation loss: 2.519536028717004

Epoch: 6| Step: 10
Training loss: 2.197809828441075
Validation loss: 2.5134909287311706

Epoch: 6| Step: 11
Training loss: 2.0096000106386316
Validation loss: 2.507466570643078

Epoch: 6| Step: 12
Training loss: 2.3272277331879536
Validation loss: 2.5081365659174413

Epoch: 6| Step: 13
Training loss: 2.090040992626842
Validation loss: 2.5029667814227055

Epoch: 227| Step: 0
Training loss: 2.2017841993672986
Validation loss: 2.493365496676181

Epoch: 6| Step: 1
Training loss: 2.4343005970858766
Validation loss: 2.5094088725095656

Epoch: 6| Step: 2
Training loss: 1.8881199532283246
Validation loss: 2.506044979065257

Epoch: 6| Step: 3
Training loss: 1.906312847664831
Validation loss: 2.5121194491181695

Epoch: 6| Step: 4
Training loss: 2.029946246257598
Validation loss: 2.515294939901565

Epoch: 6| Step: 5
Training loss: 2.2718227459172926
Validation loss: 2.5315307335924015

Epoch: 6| Step: 6
Training loss: 2.157848152899193
Validation loss: 2.5234619076456823

Epoch: 6| Step: 7
Training loss: 2.3994009462400965
Validation loss: 2.5272468339987824

Epoch: 6| Step: 8
Training loss: 3.0678631279863358
Validation loss: 2.5291440704023405

Epoch: 6| Step: 9
Training loss: 2.760387482878725
Validation loss: 2.525252879104204

Epoch: 6| Step: 10
Training loss: 2.6812171240438305
Validation loss: 2.539445286775713

Epoch: 6| Step: 11
Training loss: 2.4492411391894326
Validation loss: 2.5564028457175314

Epoch: 6| Step: 12
Training loss: 2.06417143171138
Validation loss: 2.559622785274646

Epoch: 6| Step: 13
Training loss: 2.3223206535216963
Validation loss: 2.558463491759215

Epoch: 228| Step: 0
Training loss: 1.5528077690004845
Validation loss: 2.565312261257284

Epoch: 6| Step: 1
Training loss: 2.180405911968798
Validation loss: 2.5530335091268124

Epoch: 6| Step: 2
Training loss: 2.598572808812598
Validation loss: 2.5613544043303573

Epoch: 6| Step: 3
Training loss: 2.227201992355475
Validation loss: 2.565109041212585

Epoch: 6| Step: 4
Training loss: 2.261690709495328
Validation loss: 2.5740837096479403

Epoch: 6| Step: 5
Training loss: 2.868384670024991
Validation loss: 2.5753528217457498

Epoch: 6| Step: 6
Training loss: 2.3075004351151573
Validation loss: 2.590387531804102

Epoch: 6| Step: 7
Training loss: 2.098057884254186
Validation loss: 2.579352446928053

Epoch: 6| Step: 8
Training loss: 2.6666299300842247
Validation loss: 2.580430127373669

Epoch: 6| Step: 9
Training loss: 2.101784619927078
Validation loss: 2.5374955883520203

Epoch: 6| Step: 10
Training loss: 2.7627430355822016
Validation loss: 2.5201239467848415

Epoch: 6| Step: 11
Training loss: 1.7284968660705247
Validation loss: 2.4996459710264474

Epoch: 6| Step: 12
Training loss: 2.061045509498546
Validation loss: 2.510358886264854

Epoch: 6| Step: 13
Training loss: 2.7918027778201204
Validation loss: 2.4906144474177725

Epoch: 229| Step: 0
Training loss: 2.3351988374075328
Validation loss: 2.4773512906822206

Epoch: 6| Step: 1
Training loss: 2.3644264157921686
Validation loss: 2.485387327964867

Epoch: 6| Step: 2
Training loss: 2.5119682888106847
Validation loss: 2.483798761937047

Epoch: 6| Step: 3
Training loss: 1.7374639411313166
Validation loss: 2.4930074492913348

Epoch: 6| Step: 4
Training loss: 2.4523870244967294
Validation loss: 2.486882605683651

Epoch: 6| Step: 5
Training loss: 3.1166431840906132
Validation loss: 2.485310983982341

Epoch: 6| Step: 6
Training loss: 2.1907799245603026
Validation loss: 2.5144504308673783

Epoch: 6| Step: 7
Training loss: 2.4218054976796357
Validation loss: 2.5230935160496553

Epoch: 6| Step: 8
Training loss: 2.209277712826103
Validation loss: 2.5487273331514007

Epoch: 6| Step: 9
Training loss: 2.4692386191942868
Validation loss: 2.567761191751918

Epoch: 6| Step: 10
Training loss: 2.288663341104588
Validation loss: 2.6058611710121484

Epoch: 6| Step: 11
Training loss: 2.5873424021322693
Validation loss: 2.6373713535796077

Epoch: 6| Step: 12
Training loss: 2.865964706735997
Validation loss: 2.625693517231491

Epoch: 6| Step: 13
Training loss: 1.5514402742830156
Validation loss: 2.6438812403648306

Epoch: 230| Step: 0
Training loss: 2.3075485832745457
Validation loss: 2.602121837159037

Epoch: 6| Step: 1
Training loss: 2.025739031026991
Validation loss: 2.56284367187357

Epoch: 6| Step: 2
Training loss: 2.639635973021348
Validation loss: 2.531939259629188

Epoch: 6| Step: 3
Training loss: 2.148015317183852
Validation loss: 2.5175923933281346

Epoch: 6| Step: 4
Training loss: 2.562322377817629
Validation loss: 2.5034732850934183

Epoch: 6| Step: 5
Training loss: 2.826440551893829
Validation loss: 2.5038740817585956

Epoch: 6| Step: 6
Training loss: 2.4172675821641545
Validation loss: 2.494434519603821

Epoch: 6| Step: 7
Training loss: 2.259398645723107
Validation loss: 2.4996224118235686

Epoch: 6| Step: 8
Training loss: 2.0155798145522708
Validation loss: 2.487442474083449

Epoch: 6| Step: 9
Training loss: 2.1860123071420063
Validation loss: 2.493987865146216

Epoch: 6| Step: 10
Training loss: 2.497573628757898
Validation loss: 2.480794345582244

Epoch: 6| Step: 11
Training loss: 2.294582234674397
Validation loss: 2.490058890748071

Epoch: 6| Step: 12
Training loss: 2.414987232656277
Validation loss: 2.4898237380999135

Epoch: 6| Step: 13
Training loss: 2.6019045859750167
Validation loss: 2.489736661352622

Epoch: 231| Step: 0
Training loss: 2.69815727152732
Validation loss: 2.4886783141319966

Epoch: 6| Step: 1
Training loss: 2.122031213687205
Validation loss: 2.4905304058368096

Epoch: 6| Step: 2
Training loss: 1.8657280233745754
Validation loss: 2.495951290771523

Epoch: 6| Step: 3
Training loss: 3.1044129310227513
Validation loss: 2.486704839519105

Epoch: 6| Step: 4
Training loss: 2.279369258303323
Validation loss: 2.497009889271679

Epoch: 6| Step: 5
Training loss: 1.8604726036123493
Validation loss: 2.501558295013496

Epoch: 6| Step: 6
Training loss: 2.9502457403212516
Validation loss: 2.5070082344353097

Epoch: 6| Step: 7
Training loss: 2.011372893889625
Validation loss: 2.5083298510995142

Epoch: 6| Step: 8
Training loss: 2.3119438121132294
Validation loss: 2.526324971360815

Epoch: 6| Step: 9
Training loss: 2.665401715031007
Validation loss: 2.5402996472705284

Epoch: 6| Step: 10
Training loss: 1.7900147548259224
Validation loss: 2.5834926253604142

Epoch: 6| Step: 11
Training loss: 2.1610352864347933
Validation loss: 2.594448853374858

Epoch: 6| Step: 12
Training loss: 2.0005400643735727
Validation loss: 2.6047945308377165

Epoch: 6| Step: 13
Training loss: 2.664259380325853
Validation loss: 2.599963165291266

Epoch: 232| Step: 0
Training loss: 2.229718457911288
Validation loss: 2.5959795825431597

Epoch: 6| Step: 1
Training loss: 2.7325604330711046
Validation loss: 2.581555367388244

Epoch: 6| Step: 2
Training loss: 2.3008375177157703
Validation loss: 2.569258453465105

Epoch: 6| Step: 3
Training loss: 2.505756141159538
Validation loss: 2.5286483188437527

Epoch: 6| Step: 4
Training loss: 2.506100459405863
Validation loss: 2.52060691878088

Epoch: 6| Step: 5
Training loss: 1.6899359746237834
Validation loss: 2.5205524592859017

Epoch: 6| Step: 6
Training loss: 2.077268036563298
Validation loss: 2.513469317380794

Epoch: 6| Step: 7
Training loss: 2.1487382158152677
Validation loss: 2.504814138084554

Epoch: 6| Step: 8
Training loss: 2.9506606057379603
Validation loss: 2.511362148380192

Epoch: 6| Step: 9
Training loss: 1.6162739260289951
Validation loss: 2.5069791651112214

Epoch: 6| Step: 10
Training loss: 2.183329503102134
Validation loss: 2.510821532740707

Epoch: 6| Step: 11
Training loss: 2.1919242804181045
Validation loss: 2.5102181626556246

Epoch: 6| Step: 12
Training loss: 2.5900878791187023
Validation loss: 2.5320725615435857

Epoch: 6| Step: 13
Training loss: 2.4727358933288324
Validation loss: 2.5333709935685063

Epoch: 233| Step: 0
Training loss: 1.453934146832798
Validation loss: 2.5466575919816807

Epoch: 6| Step: 1
Training loss: 2.8905017723417235
Validation loss: 2.58512376964889

Epoch: 6| Step: 2
Training loss: 3.030970924351254
Validation loss: 2.596431847076339

Epoch: 6| Step: 3
Training loss: 1.9794154629849086
Validation loss: 2.615548291405139

Epoch: 6| Step: 4
Training loss: 2.577493301220097
Validation loss: 2.6126187125677984

Epoch: 6| Step: 5
Training loss: 2.1845216366252336
Validation loss: 2.622668017619602

Epoch: 6| Step: 6
Training loss: 2.0565049868466874
Validation loss: 2.5937860172329477

Epoch: 6| Step: 7
Training loss: 2.171642483127443
Validation loss: 2.5929102476607464

Epoch: 6| Step: 8
Training loss: 2.9287347083480135
Validation loss: 2.573883791227137

Epoch: 6| Step: 9
Training loss: 1.8554813424737169
Validation loss: 2.5362543001823137

Epoch: 6| Step: 10
Training loss: 2.4700624864218748
Validation loss: 2.512585084654321

Epoch: 6| Step: 11
Training loss: 2.2980384215686245
Validation loss: 2.524524875670677

Epoch: 6| Step: 12
Training loss: 2.346671153230424
Validation loss: 2.5004092676220324

Epoch: 6| Step: 13
Training loss: 1.7592341798626947
Validation loss: 2.5100478591257023

Epoch: 234| Step: 0
Training loss: 2.886806460894733
Validation loss: 2.5154319041444992

Epoch: 6| Step: 1
Training loss: 2.154676111756922
Validation loss: 2.500695386177424

Epoch: 6| Step: 2
Training loss: 2.1227648704797755
Validation loss: 2.5062031241303724

Epoch: 6| Step: 3
Training loss: 1.6478899005527863
Validation loss: 2.4959141244267724

Epoch: 6| Step: 4
Training loss: 2.9724836462291275
Validation loss: 2.518664307000324

Epoch: 6| Step: 5
Training loss: 2.630007191637309
Validation loss: 2.52472614496572

Epoch: 6| Step: 6
Training loss: 1.9594746030469397
Validation loss: 2.535672394376407

Epoch: 6| Step: 7
Training loss: 2.052464548192766
Validation loss: 2.5636729370468383

Epoch: 6| Step: 8
Training loss: 2.592989155044562
Validation loss: 2.5847538969748034

Epoch: 6| Step: 9
Training loss: 2.2827003780457424
Validation loss: 2.6112151976281424

Epoch: 6| Step: 10
Training loss: 2.4486547669473726
Validation loss: 2.5945796635433687

Epoch: 6| Step: 11
Training loss: 1.5252579205139623
Validation loss: 2.5808985269959335

Epoch: 6| Step: 12
Training loss: 2.13705079115691
Validation loss: 2.5850500329965964

Epoch: 6| Step: 13
Training loss: 2.543829471930692
Validation loss: 2.563543665416382

Epoch: 235| Step: 0
Training loss: 2.1624267124700896
Validation loss: 2.5682438620154175

Epoch: 6| Step: 1
Training loss: 1.3332830459330494
Validation loss: 2.5722249268498585

Epoch: 6| Step: 2
Training loss: 2.0372385805142086
Validation loss: 2.5783204900433616

Epoch: 6| Step: 3
Training loss: 1.7926633487475414
Validation loss: 2.570700928190976

Epoch: 6| Step: 4
Training loss: 2.603942332459835
Validation loss: 2.539903675515674

Epoch: 6| Step: 5
Training loss: 2.5799642764434956
Validation loss: 2.5133923402566483

Epoch: 6| Step: 6
Training loss: 1.9244671839718255
Validation loss: 2.518415905019323

Epoch: 6| Step: 7
Training loss: 2.6208470508436803
Validation loss: 2.5087951287869035

Epoch: 6| Step: 8
Training loss: 2.5418409902690633
Validation loss: 2.4996210764774847

Epoch: 6| Step: 9
Training loss: 2.2889445928731353
Validation loss: 2.502285881854144

Epoch: 6| Step: 10
Training loss: 2.69641568371193
Validation loss: 2.500887808515214

Epoch: 6| Step: 11
Training loss: 2.214115514234968
Validation loss: 2.4999247221739416

Epoch: 6| Step: 12
Training loss: 2.3888266786957124
Validation loss: 2.5087786563287735

Epoch: 6| Step: 13
Training loss: 2.9078317255187076
Validation loss: 2.5031537191241253

Epoch: 236| Step: 0
Training loss: 2.4919580814393485
Validation loss: 2.5269868059164855

Epoch: 6| Step: 1
Training loss: 3.0239733632645307
Validation loss: 2.503508656754411

Epoch: 6| Step: 2
Training loss: 2.2072396239091794
Validation loss: 2.526116019396766

Epoch: 6| Step: 3
Training loss: 2.27941371222744
Validation loss: 2.5327990623147465

Epoch: 6| Step: 4
Training loss: 2.1918505321972033
Validation loss: 2.5411104638563056

Epoch: 6| Step: 5
Training loss: 2.0790765634505752
Validation loss: 2.553706300535545

Epoch: 6| Step: 6
Training loss: 2.195917120920807
Validation loss: 2.5726663619590964

Epoch: 6| Step: 7
Training loss: 1.6766776152923848
Validation loss: 2.566116231462806

Epoch: 6| Step: 8
Training loss: 2.2995331622156785
Validation loss: 2.5521169439684614

Epoch: 6| Step: 9
Training loss: 2.547338431852993
Validation loss: 2.5511436185536036

Epoch: 6| Step: 10
Training loss: 2.4381284637152763
Validation loss: 2.53551415971952

Epoch: 6| Step: 11
Training loss: 1.905211494099738
Validation loss: 2.5313445493519797

Epoch: 6| Step: 12
Training loss: 2.620923464569102
Validation loss: 2.5276003416954627

Epoch: 6| Step: 13
Training loss: 2.1985821793591778
Validation loss: 2.5070997197703644

Epoch: 237| Step: 0
Training loss: 2.0506105769753846
Validation loss: 2.5283206111141108

Epoch: 6| Step: 1
Training loss: 2.072885088144918
Validation loss: 2.5370615895200386

Epoch: 6| Step: 2
Training loss: 2.8066018884331014
Validation loss: 2.556171557801473

Epoch: 6| Step: 3
Training loss: 1.7400488620781411
Validation loss: 2.561679941472653

Epoch: 6| Step: 4
Training loss: 2.511674325885329
Validation loss: 2.590739191757372

Epoch: 6| Step: 5
Training loss: 2.007300166805095
Validation loss: 2.6311740474657412

Epoch: 6| Step: 6
Training loss: 2.299152205577178
Validation loss: 2.5864076523124164

Epoch: 6| Step: 7
Training loss: 3.1593392238987317
Validation loss: 2.550810988497723

Epoch: 6| Step: 8
Training loss: 2.748164691582021
Validation loss: 2.5120185447694743

Epoch: 6| Step: 9
Training loss: 2.7604975178712072
Validation loss: 2.503996428374911

Epoch: 6| Step: 10
Training loss: 2.6374014415676568
Validation loss: 2.4912238335658836

Epoch: 6| Step: 11
Training loss: 2.6973362498390974
Validation loss: 2.4856412367769622

Epoch: 6| Step: 12
Training loss: 1.7310964853688815
Validation loss: 2.490392455026455

Epoch: 6| Step: 13
Training loss: 1.701494889190289
Validation loss: 2.4937629702556614

Epoch: 238| Step: 0
Training loss: 2.5756318030189993
Validation loss: 2.4769412291639745

Epoch: 6| Step: 1
Training loss: 1.9546175327479187
Validation loss: 2.4992948411808027

Epoch: 6| Step: 2
Training loss: 2.948130102260332
Validation loss: 2.488423709194829

Epoch: 6| Step: 3
Training loss: 2.1683628583222787
Validation loss: 2.502241004424845

Epoch: 6| Step: 4
Training loss: 2.0457777037764986
Validation loss: 2.5096660351815983

Epoch: 6| Step: 5
Training loss: 1.6757526528646056
Validation loss: 2.4962756389637746

Epoch: 6| Step: 6
Training loss: 1.991701193899946
Validation loss: 2.537853528280515

Epoch: 6| Step: 7
Training loss: 2.71701099421327
Validation loss: 2.550265576987686

Epoch: 6| Step: 8
Training loss: 2.349105819053047
Validation loss: 2.5570797388918534

Epoch: 6| Step: 9
Training loss: 2.4040885233837335
Validation loss: 2.5732901581377186

Epoch: 6| Step: 10
Training loss: 2.7154301510914514
Validation loss: 2.5773127499732196

Epoch: 6| Step: 11
Training loss: 2.0830131920567547
Validation loss: 2.599591689571502

Epoch: 6| Step: 12
Training loss: 2.1230861797045915
Validation loss: 2.628687644965083

Epoch: 6| Step: 13
Training loss: 1.9622451859773684
Validation loss: 2.638119790172155

Epoch: 239| Step: 0
Training loss: 1.8896672368654657
Validation loss: 2.632175923258271

Epoch: 6| Step: 1
Training loss: 2.9466127313306614
Validation loss: 2.6423264689325254

Epoch: 6| Step: 2
Training loss: 2.410311355422391
Validation loss: 2.641337725519511

Epoch: 6| Step: 3
Training loss: 2.9552075344475
Validation loss: 2.6487688515583225

Epoch: 6| Step: 4
Training loss: 1.6955464988278852
Validation loss: 2.644299931366397

Epoch: 6| Step: 5
Training loss: 1.914648596889976
Validation loss: 2.6088427611868537

Epoch: 6| Step: 6
Training loss: 2.389947433691655
Validation loss: 2.56162355522788

Epoch: 6| Step: 7
Training loss: 1.7405789737334818
Validation loss: 2.5518159583545414

Epoch: 6| Step: 8
Training loss: 2.341596911422001
Validation loss: 2.5352674870315672

Epoch: 6| Step: 9
Training loss: 2.787343240615231
Validation loss: 2.511496415885197

Epoch: 6| Step: 10
Training loss: 2.2386495610065076
Validation loss: 2.507590833713088

Epoch: 6| Step: 11
Training loss: 2.175326342599625
Validation loss: 2.5087006799461946

Epoch: 6| Step: 12
Training loss: 2.576082009692316
Validation loss: 2.500225184153667

Epoch: 6| Step: 13
Training loss: 2.433263177600665
Validation loss: 2.5076801189844535

Epoch: 240| Step: 0
Training loss: 1.9076384818828815
Validation loss: 2.5123706721079992

Epoch: 6| Step: 1
Training loss: 2.228856454340471
Validation loss: 2.518287568596947

Epoch: 6| Step: 2
Training loss: 2.5866924002275136
Validation loss: 2.526014926939288

Epoch: 6| Step: 3
Training loss: 1.640268559564106
Validation loss: 2.544039358791247

Epoch: 6| Step: 4
Training loss: 2.0405747224885156
Validation loss: 2.5533743466933725

Epoch: 6| Step: 5
Training loss: 2.892494875310712
Validation loss: 2.5958756924556634

Epoch: 6| Step: 6
Training loss: 3.148189866240428
Validation loss: 2.6136192175462334

Epoch: 6| Step: 7
Training loss: 2.32950218481914
Validation loss: 2.6237985343981545

Epoch: 6| Step: 8
Training loss: 2.2149274968321526
Validation loss: 2.6246334607180732

Epoch: 6| Step: 9
Training loss: 2.1392804677741077
Validation loss: 2.615180298234515

Epoch: 6| Step: 10
Training loss: 2.1737945636307505
Validation loss: 2.5841671664440367

Epoch: 6| Step: 11
Training loss: 1.4706328477824384
Validation loss: 2.569299113542457

Epoch: 6| Step: 12
Training loss: 1.927021362407993
Validation loss: 2.5188375143871577

Epoch: 6| Step: 13
Training loss: 2.9474885627453498
Validation loss: 2.5252784650992344

Epoch: 241| Step: 0
Training loss: 2.656739672236472
Validation loss: 2.506036448398081

Epoch: 6| Step: 1
Training loss: 2.1187677433317473
Validation loss: 2.501685130893882

Epoch: 6| Step: 2
Training loss: 1.8745203676295004
Validation loss: 2.5092212368611775

Epoch: 6| Step: 3
Training loss: 2.753950749030995
Validation loss: 2.4935931603388997

Epoch: 6| Step: 4
Training loss: 2.2194021636581085
Validation loss: 2.496223553788214

Epoch: 6| Step: 5
Training loss: 2.2324833899005028
Validation loss: 2.505837459968879

Epoch: 6| Step: 6
Training loss: 1.6116717347884284
Validation loss: 2.522461252560795

Epoch: 6| Step: 7
Training loss: 2.465252487220047
Validation loss: 2.5423849581307687

Epoch: 6| Step: 8
Training loss: 2.762542385967161
Validation loss: 2.5631763217032373

Epoch: 6| Step: 9
Training loss: 2.284978354286825
Validation loss: 2.604633065737861

Epoch: 6| Step: 10
Training loss: 2.2365829122735694
Validation loss: 2.6462862323003784

Epoch: 6| Step: 11
Training loss: 2.352102325425848
Validation loss: 2.6345391804196225

Epoch: 6| Step: 12
Training loss: 2.327199662413561
Validation loss: 2.6334928393846315

Epoch: 6| Step: 13
Training loss: 2.3725267884296706
Validation loss: 2.6119824019944806

Epoch: 242| Step: 0
Training loss: 2.1267793722791395
Validation loss: 2.564128730285844

Epoch: 6| Step: 1
Training loss: 2.829371899299111
Validation loss: 2.5479834705078126

Epoch: 6| Step: 2
Training loss: 2.6058224919744966
Validation loss: 2.5508324937799323

Epoch: 6| Step: 3
Training loss: 2.2936636344595063
Validation loss: 2.523439862040545

Epoch: 6| Step: 4
Training loss: 2.9398751903173634
Validation loss: 2.5306886749158077

Epoch: 6| Step: 5
Training loss: 2.6755668609939325
Validation loss: 2.5184380261589916

Epoch: 6| Step: 6
Training loss: 1.695879090025356
Validation loss: 2.5351077693776665

Epoch: 6| Step: 7
Training loss: 1.616665225995133
Validation loss: 2.529968078396822

Epoch: 6| Step: 8
Training loss: 2.5631139996582557
Validation loss: 2.5153444027047547

Epoch: 6| Step: 9
Training loss: 1.5159925821268785
Validation loss: 2.5326856772417305

Epoch: 6| Step: 10
Training loss: 2.505229534818166
Validation loss: 2.5484070723646908

Epoch: 6| Step: 11
Training loss: 2.2259328922393804
Validation loss: 2.530026866383195

Epoch: 6| Step: 12
Training loss: 1.8459620379949269
Validation loss: 2.552538544416442

Epoch: 6| Step: 13
Training loss: 1.9618172666787153
Validation loss: 2.566994037021378

Epoch: 243| Step: 0
Training loss: 2.2696302067362404
Validation loss: 2.5960675039542167

Epoch: 6| Step: 1
Training loss: 2.8856332929432966
Validation loss: 2.598191101540083

Epoch: 6| Step: 2
Training loss: 2.3224803931124156
Validation loss: 2.598536307420793

Epoch: 6| Step: 3
Training loss: 2.5374549824146166
Validation loss: 2.6017928532218417

Epoch: 6| Step: 4
Training loss: 2.487582074062143
Validation loss: 2.600351213918015

Epoch: 6| Step: 5
Training loss: 1.4767793364987596
Validation loss: 2.5824282711736326

Epoch: 6| Step: 6
Training loss: 2.1540265990220346
Validation loss: 2.58287417012595

Epoch: 6| Step: 7
Training loss: 1.9037014543902386
Validation loss: 2.579404956325397

Epoch: 6| Step: 8
Training loss: 1.8711310842846944
Validation loss: 2.5705806511137936

Epoch: 6| Step: 9
Training loss: 2.2425658009889333
Validation loss: 2.573698416698304

Epoch: 6| Step: 10
Training loss: 2.664104472526077
Validation loss: 2.5714012398730572

Epoch: 6| Step: 11
Training loss: 2.1517643364984607
Validation loss: 2.562224613681915

Epoch: 6| Step: 12
Training loss: 1.9524106359606714
Validation loss: 2.565200940677108

Epoch: 6| Step: 13
Training loss: 2.4287450992772346
Validation loss: 2.5475098924379256

Epoch: 244| Step: 0
Training loss: 2.249496827553409
Validation loss: 2.529296120897571

Epoch: 6| Step: 1
Training loss: 2.36725558444271
Validation loss: 2.5296252024069705

Epoch: 6| Step: 2
Training loss: 2.470218077078952
Validation loss: 2.527802273930872

Epoch: 6| Step: 3
Training loss: 2.2114111726547456
Validation loss: 2.4905096722190185

Epoch: 6| Step: 4
Training loss: 1.9561111815317527
Validation loss: 2.5152027336476825

Epoch: 6| Step: 5
Training loss: 2.4780963756548475
Validation loss: 2.514290481323929

Epoch: 6| Step: 6
Training loss: 1.9546776665334251
Validation loss: 2.5090967140425877

Epoch: 6| Step: 7
Training loss: 1.6733262367908615
Validation loss: 2.517747161612124

Epoch: 6| Step: 8
Training loss: 2.616389184157448
Validation loss: 2.529141650843409

Epoch: 6| Step: 9
Training loss: 1.834542511500201
Validation loss: 2.5540740261318

Epoch: 6| Step: 10
Training loss: 2.520242280212452
Validation loss: 2.5528350164241

Epoch: 6| Step: 11
Training loss: 2.55791845364365
Validation loss: 2.5719700872581255

Epoch: 6| Step: 12
Training loss: 2.0710016219327536
Validation loss: 2.5672108295268328

Epoch: 6| Step: 13
Training loss: 2.836359166095119
Validation loss: 2.574871298897644

Epoch: 245| Step: 0
Training loss: 2.5553116808732885
Validation loss: 2.582000763021091

Epoch: 6| Step: 1
Training loss: 2.5718873367848003
Validation loss: 2.57408333915712

Epoch: 6| Step: 2
Training loss: 1.839403103747564
Validation loss: 2.57335024950005

Epoch: 6| Step: 3
Training loss: 1.91711506228717
Validation loss: 2.55457374871685

Epoch: 6| Step: 4
Training loss: 2.2386559510617348
Validation loss: 2.5416306873547385

Epoch: 6| Step: 5
Training loss: 2.1924028221525624
Validation loss: 2.5414030271866013

Epoch: 6| Step: 6
Training loss: 2.7122242097362443
Validation loss: 2.5448992502022176

Epoch: 6| Step: 7
Training loss: 3.38186907221892
Validation loss: 2.523940816627727

Epoch: 6| Step: 8
Training loss: 2.253167995090273
Validation loss: 2.5252255461773654

Epoch: 6| Step: 9
Training loss: 1.6976551096280827
Validation loss: 2.539146007240547

Epoch: 6| Step: 10
Training loss: 1.721647698272371
Validation loss: 2.561640005868513

Epoch: 6| Step: 11
Training loss: 2.4690145036990607
Validation loss: 2.54370808047434

Epoch: 6| Step: 12
Training loss: 2.4251029867739557
Validation loss: 2.5666682294948164

Epoch: 6| Step: 13
Training loss: 1.8259641478195332
Validation loss: 2.574269056431617

Epoch: 246| Step: 0
Training loss: 1.788922033667623
Validation loss: 2.59595566538369

Epoch: 6| Step: 1
Training loss: 2.5234240835677593
Validation loss: 2.6104718946585357

Epoch: 6| Step: 2
Training loss: 2.1254504231315736
Validation loss: 2.6065154558683714

Epoch: 6| Step: 3
Training loss: 2.2029600690425366
Validation loss: 2.623803925877076

Epoch: 6| Step: 4
Training loss: 2.896157408951861
Validation loss: 2.6181074053562514

Epoch: 6| Step: 5
Training loss: 1.8503105985389787
Validation loss: 2.6438654592566526

Epoch: 6| Step: 6
Training loss: 2.1780680447852965
Validation loss: 2.6261819872854604

Epoch: 6| Step: 7
Training loss: 2.070852302858392
Validation loss: 2.6033559274690226

Epoch: 6| Step: 8
Training loss: 2.2631718475794154
Validation loss: 2.5503706628391463

Epoch: 6| Step: 9
Training loss: 2.6022494672074195
Validation loss: 2.533329647044796

Epoch: 6| Step: 10
Training loss: 2.214494304237095
Validation loss: 2.520107784892784

Epoch: 6| Step: 11
Training loss: 2.5549358282223507
Validation loss: 2.488406191672867

Epoch: 6| Step: 12
Training loss: 2.3721209693798464
Validation loss: 2.4815624479140017

Epoch: 6| Step: 13
Training loss: 2.4755749583706246
Validation loss: 2.4930233405773015

Epoch: 247| Step: 0
Training loss: 2.1099259398782793
Validation loss: 2.4796595737909484

Epoch: 6| Step: 1
Training loss: 1.9212932171301145
Validation loss: 2.4679300258295727

Epoch: 6| Step: 2
Training loss: 1.3013179920326696
Validation loss: 2.476497196014417

Epoch: 6| Step: 3
Training loss: 2.9099183260542967
Validation loss: 2.471628040591527

Epoch: 6| Step: 4
Training loss: 2.565170571230942
Validation loss: 2.4846043430889906

Epoch: 6| Step: 5
Training loss: 2.1309021159639934
Validation loss: 2.4856282078350835

Epoch: 6| Step: 6
Training loss: 2.827014937073601
Validation loss: 2.486191059818457

Epoch: 6| Step: 7
Training loss: 2.7739296919666367
Validation loss: 2.497611557941791

Epoch: 6| Step: 8
Training loss: 1.6720743506112903
Validation loss: 2.511641545194342

Epoch: 6| Step: 9
Training loss: 2.8669927463339944
Validation loss: 2.5407906153378264

Epoch: 6| Step: 10
Training loss: 2.2754736103429516
Validation loss: 2.577418136024305

Epoch: 6| Step: 11
Training loss: 2.387044082170631
Validation loss: 2.614211665228207

Epoch: 6| Step: 12
Training loss: 1.676372148243563
Validation loss: 2.6330674799786067

Epoch: 6| Step: 13
Training loss: 1.9480842545439672
Validation loss: 2.650038768676658

Epoch: 248| Step: 0
Training loss: 2.688381228019335
Validation loss: 2.623088201034904

Epoch: 6| Step: 1
Training loss: 2.744397612243779
Validation loss: 2.6061305130753825

Epoch: 6| Step: 2
Training loss: 2.3310220601835274
Validation loss: 2.5461362223610324

Epoch: 6| Step: 3
Training loss: 2.701754272079161
Validation loss: 2.557727043760994

Epoch: 6| Step: 4
Training loss: 1.8071552265418107
Validation loss: 2.5433735405663134

Epoch: 6| Step: 5
Training loss: 1.727559418933026
Validation loss: 2.523567408946862

Epoch: 6| Step: 6
Training loss: 2.2968874561205617
Validation loss: 2.5191827892864778

Epoch: 6| Step: 7
Training loss: 1.801515640483111
Validation loss: 2.504780141251908

Epoch: 6| Step: 8
Training loss: 2.692475260246336
Validation loss: 2.4872403685060918

Epoch: 6| Step: 9
Training loss: 2.458692028795424
Validation loss: 2.4770429448031925

Epoch: 6| Step: 10
Training loss: 1.977901804115263
Validation loss: 2.4778174300458864

Epoch: 6| Step: 11
Training loss: 1.8559155377991245
Validation loss: 2.494981648346422

Epoch: 6| Step: 12
Training loss: 2.2740121226662806
Validation loss: 2.5012898137858857

Epoch: 6| Step: 13
Training loss: 2.560117777260895
Validation loss: 2.5327984975199884

Epoch: 249| Step: 0
Training loss: 2.114247550675154
Validation loss: 2.5504455812889746

Epoch: 6| Step: 1
Training loss: 2.188393764470092
Validation loss: 2.5649367586039657

Epoch: 6| Step: 2
Training loss: 2.1063405003333924
Validation loss: 2.5798081038448726

Epoch: 6| Step: 3
Training loss: 2.168540755409853
Validation loss: 2.5279409812343494

Epoch: 6| Step: 4
Training loss: 1.9855541420487834
Validation loss: 2.517790168649602

Epoch: 6| Step: 5
Training loss: 2.2373328205073197
Validation loss: 2.527558928286016

Epoch: 6| Step: 6
Training loss: 2.5742321795517014
Validation loss: 2.5246788412377597

Epoch: 6| Step: 7
Training loss: 2.763220825052339
Validation loss: 2.5377126069097256

Epoch: 6| Step: 8
Training loss: 2.3731417162117836
Validation loss: 2.5248436174342106

Epoch: 6| Step: 9
Training loss: 2.1502654466219466
Validation loss: 2.560759798610603

Epoch: 6| Step: 10
Training loss: 2.539324749828015
Validation loss: 2.5542307065202907

Epoch: 6| Step: 11
Training loss: 1.819258224948891
Validation loss: 2.5522051308561116

Epoch: 6| Step: 12
Training loss: 2.5168891715746535
Validation loss: 2.5588122869059324

Epoch: 6| Step: 13
Training loss: 2.054064754204534
Validation loss: 2.539402865558109

Epoch: 250| Step: 0
Training loss: 2.1598909018479944
Validation loss: 2.554333350222607

Epoch: 6| Step: 1
Training loss: 2.4384281640984433
Validation loss: 2.5287329792651048

Epoch: 6| Step: 2
Training loss: 2.4911460494170887
Validation loss: 2.5531704721560855

Epoch: 6| Step: 3
Training loss: 1.91511338637803
Validation loss: 2.554316658067474

Epoch: 6| Step: 4
Training loss: 2.2522719886189972
Validation loss: 2.545051858294939

Epoch: 6| Step: 5
Training loss: 1.8423272802176278
Validation loss: 2.539030166811357

Epoch: 6| Step: 6
Training loss: 1.130722749194901
Validation loss: 2.5466177562773566

Epoch: 6| Step: 7
Training loss: 2.4161104570679655
Validation loss: 2.5688386535196743

Epoch: 6| Step: 8
Training loss: 1.7677374162081747
Validation loss: 2.567032782547029

Epoch: 6| Step: 9
Training loss: 2.598018121968909
Validation loss: 2.5523424652784508

Epoch: 6| Step: 10
Training loss: 2.5673012762228566
Validation loss: 2.566749213076172

Epoch: 6| Step: 11
Training loss: 2.5249680167712567
Validation loss: 2.5318682979010703

Epoch: 6| Step: 12
Training loss: 2.29402149475058
Validation loss: 2.556809892095106

Epoch: 6| Step: 13
Training loss: 2.873979802113108
Validation loss: 2.5538220042868436

Epoch: 251| Step: 0
Training loss: 2.353431744485518
Validation loss: 2.557252379903576

Epoch: 6| Step: 1
Training loss: 2.0222329343202317
Validation loss: 2.573997785223952

Epoch: 6| Step: 2
Training loss: 2.4156449449117994
Validation loss: 2.5667513649659655

Epoch: 6| Step: 3
Training loss: 2.0676434280112104
Validation loss: 2.5735364983298132

Epoch: 6| Step: 4
Training loss: 2.4291681550306556
Validation loss: 2.54613618334463

Epoch: 6| Step: 5
Training loss: 2.6109796946396027
Validation loss: 2.5587416977367994

Epoch: 6| Step: 6
Training loss: 2.7272287336326886
Validation loss: 2.554596334497007

Epoch: 6| Step: 7
Training loss: 2.3725575386040307
Validation loss: 2.58619081729699

Epoch: 6| Step: 8
Training loss: 1.9963027635646649
Validation loss: 2.5955557301744783

Epoch: 6| Step: 9
Training loss: 1.76257073551298
Validation loss: 2.593210156497408

Epoch: 6| Step: 10
Training loss: 1.657520814307522
Validation loss: 2.5712996793035896

Epoch: 6| Step: 11
Training loss: 2.0847053460506824
Validation loss: 2.584271419591249

Epoch: 6| Step: 12
Training loss: 2.325602348809882
Validation loss: 2.5680178029561325

Epoch: 6| Step: 13
Training loss: 2.642158018158627
Validation loss: 2.604192525099482

Epoch: 252| Step: 0
Training loss: 2.0746782444056375
Validation loss: 2.5973170773688072

Epoch: 6| Step: 1
Training loss: 2.448827198130009
Validation loss: 2.6083958629470243

Epoch: 6| Step: 2
Training loss: 1.836670944130423
Validation loss: 2.5662608190135945

Epoch: 6| Step: 3
Training loss: 2.9704665190744675
Validation loss: 2.5747932869613153

Epoch: 6| Step: 4
Training loss: 1.795047660131155
Validation loss: 2.5857010163722176

Epoch: 6| Step: 5
Training loss: 1.8989824054620075
Validation loss: 2.55483806139218

Epoch: 6| Step: 6
Training loss: 2.00768377581649
Validation loss: 2.5396958094394

Epoch: 6| Step: 7
Training loss: 2.578527245786475
Validation loss: 2.5259329126811836

Epoch: 6| Step: 8
Training loss: 2.28714106510923
Validation loss: 2.5495122817125773

Epoch: 6| Step: 9
Training loss: 2.069904330341762
Validation loss: 2.5567543853481447

Epoch: 6| Step: 10
Training loss: 1.9713821980252633
Validation loss: 2.555604620361172

Epoch: 6| Step: 11
Training loss: 2.1829959822306266
Validation loss: 2.5494457914189486

Epoch: 6| Step: 12
Training loss: 2.1576060578235396
Validation loss: 2.5598407220712915

Epoch: 6| Step: 13
Training loss: 2.921968509585328
Validation loss: 2.5694009387712002

Epoch: 253| Step: 0
Training loss: 2.2518576265120687
Validation loss: 2.5688247935845063

Epoch: 6| Step: 1
Training loss: 1.7233171298201735
Validation loss: 2.557932450346825

Epoch: 6| Step: 2
Training loss: 1.8561455385761043
Validation loss: 2.5398340393024705

Epoch: 6| Step: 3
Training loss: 2.1001144014714
Validation loss: 2.544032986058204

Epoch: 6| Step: 4
Training loss: 2.401552445260954
Validation loss: 2.5365731737483195

Epoch: 6| Step: 5
Training loss: 2.3051177059745163
Validation loss: 2.544228799733681

Epoch: 6| Step: 6
Training loss: 2.333522607301901
Validation loss: 2.5740036052045294

Epoch: 6| Step: 7
Training loss: 2.5270418579354423
Validation loss: 2.562098820614148

Epoch: 6| Step: 8
Training loss: 2.420176741238496
Validation loss: 2.5544592768057046

Epoch: 6| Step: 9
Training loss: 2.1625872379412914
Validation loss: 2.556414519147927

Epoch: 6| Step: 10
Training loss: 2.2802134209848117
Validation loss: 2.553104326155906

Epoch: 6| Step: 11
Training loss: 2.71020656262979
Validation loss: 2.571590071291736

Epoch: 6| Step: 12
Training loss: 2.269978516934949
Validation loss: 2.585771353648108

Epoch: 6| Step: 13
Training loss: 2.0062496767608287
Validation loss: 2.605436463086862

Epoch: 254| Step: 0
Training loss: 2.2193381376221164
Validation loss: 2.5988398788051033

Epoch: 6| Step: 1
Training loss: 1.759340969589986
Validation loss: 2.6229993901578657

Epoch: 6| Step: 2
Training loss: 2.4542040547327857
Validation loss: 2.617928456044086

Epoch: 6| Step: 3
Training loss: 2.2360918611549567
Validation loss: 2.59606030993947

Epoch: 6| Step: 4
Training loss: 1.8523326833226261
Validation loss: 2.576423360885868

Epoch: 6| Step: 5
Training loss: 2.3998399045317194
Validation loss: 2.576621802244986

Epoch: 6| Step: 6
Training loss: 1.9274290513613248
Validation loss: 2.5969583515572796

Epoch: 6| Step: 7
Training loss: 2.5439589955846027
Validation loss: 2.584562937042952

Epoch: 6| Step: 8
Training loss: 2.4513446154272116
Validation loss: 2.5547007211387784

Epoch: 6| Step: 9
Training loss: 2.971042430593957
Validation loss: 2.5353746442569647

Epoch: 6| Step: 10
Training loss: 2.08908940185938
Validation loss: 2.5583602371623635

Epoch: 6| Step: 11
Training loss: 1.717780863023142
Validation loss: 2.5469730724962676

Epoch: 6| Step: 12
Training loss: 2.0964275718458203
Validation loss: 2.5784599626051463

Epoch: 6| Step: 13
Training loss: 2.611770535342772
Validation loss: 2.574358367606879

Epoch: 255| Step: 0
Training loss: 1.9063783195956454
Validation loss: 2.5896245327590486

Epoch: 6| Step: 1
Training loss: 1.61416069980215
Validation loss: 2.6036370972371508

Epoch: 6| Step: 2
Training loss: 2.5429553428566023
Validation loss: 2.552988013985859

Epoch: 6| Step: 3
Training loss: 2.5362736336409264
Validation loss: 2.5483842680061146

Epoch: 6| Step: 4
Training loss: 2.4488163911115732
Validation loss: 2.531605934894629

Epoch: 6| Step: 5
Training loss: 2.6070062541820804
Validation loss: 2.5017256979571547

Epoch: 6| Step: 6
Training loss: 2.0402002193331517
Validation loss: 2.536505216338859

Epoch: 6| Step: 7
Training loss: 1.8355155297570347
Validation loss: 2.545272775632365

Epoch: 6| Step: 8
Training loss: 2.1963761220378464
Validation loss: 2.533039355370242

Epoch: 6| Step: 9
Training loss: 2.852553939911135
Validation loss: 2.5344833946644822

Epoch: 6| Step: 10
Training loss: 2.4785515051394738
Validation loss: 2.5402993344221416

Epoch: 6| Step: 11
Training loss: 1.6195696548788492
Validation loss: 2.5458546410234466

Epoch: 6| Step: 12
Training loss: 1.702348724680088
Validation loss: 2.5173713356482748

Epoch: 6| Step: 13
Training loss: 2.6129082611716066
Validation loss: 2.5370039199710606

Epoch: 256| Step: 0
Training loss: 2.5112939359658006
Validation loss: 2.5534278882955763

Epoch: 6| Step: 1
Training loss: 1.7666388107598863
Validation loss: 2.5562637086234887

Epoch: 6| Step: 2
Training loss: 1.832780176578517
Validation loss: 2.5864055475038032

Epoch: 6| Step: 3
Training loss: 2.383679841823954
Validation loss: 2.5773359998740846

Epoch: 6| Step: 4
Training loss: 2.485145497351286
Validation loss: 2.5715792084526323

Epoch: 6| Step: 5
Training loss: 1.7750654772649601
Validation loss: 2.5539024772316665

Epoch: 6| Step: 6
Training loss: 2.5506919856904475
Validation loss: 2.5444588775540065

Epoch: 6| Step: 7
Training loss: 2.2702830869970776
Validation loss: 2.544850221309763

Epoch: 6| Step: 8
Training loss: 2.5288644546199164
Validation loss: 2.52658022353562

Epoch: 6| Step: 9
Training loss: 2.4332041910818023
Validation loss: 2.52255855720436

Epoch: 6| Step: 10
Training loss: 2.0070652146247854
Validation loss: 2.5189345015354236

Epoch: 6| Step: 11
Training loss: 2.066178942114502
Validation loss: 2.5404236260530952

Epoch: 6| Step: 12
Training loss: 1.8145184294709968
Validation loss: 2.5616879223140456

Epoch: 6| Step: 13
Training loss: 2.5562989171950794
Validation loss: 2.546778101725753

Epoch: 257| Step: 0
Training loss: 2.649272505750003
Validation loss: 2.5483551560942206

Epoch: 6| Step: 1
Training loss: 2.541643069631966
Validation loss: 2.547314518174256

Epoch: 6| Step: 2
Training loss: 2.3072423190543834
Validation loss: 2.5882808827696344

Epoch: 6| Step: 3
Training loss: 1.8065700207909883
Validation loss: 2.607789591602344

Epoch: 6| Step: 4
Training loss: 1.5297641941440054
Validation loss: 2.572353600011599

Epoch: 6| Step: 5
Training loss: 2.323827579182099
Validation loss: 2.532274564755645

Epoch: 6| Step: 6
Training loss: 1.8894252911485834
Validation loss: 2.5083703740660037

Epoch: 6| Step: 7
Training loss: 2.165848088299213
Validation loss: 2.510768728512844

Epoch: 6| Step: 8
Training loss: 2.2000266940491446
Validation loss: 2.523025211316623

Epoch: 6| Step: 9
Training loss: 1.9763085122949942
Validation loss: 2.5156315552683335

Epoch: 6| Step: 10
Training loss: 1.737118175459423
Validation loss: 2.499668528516664

Epoch: 6| Step: 11
Training loss: 2.0946732947772615
Validation loss: 2.513656019404353

Epoch: 6| Step: 12
Training loss: 2.720346091915925
Validation loss: 2.529223678884772

Epoch: 6| Step: 13
Training loss: 3.068479655802086
Validation loss: 2.5374862864707866

Epoch: 258| Step: 0
Training loss: 2.1871747456296036
Validation loss: 2.5956008006896067

Epoch: 6| Step: 1
Training loss: 1.4323526357910075
Validation loss: 2.5991095968399835

Epoch: 6| Step: 2
Training loss: 2.2574939965118643
Validation loss: 2.5959871824136185

Epoch: 6| Step: 3
Training loss: 2.4072157668051535
Validation loss: 2.6185286847948923

Epoch: 6| Step: 4
Training loss: 2.9859273178749404
Validation loss: 2.6198411081147235

Epoch: 6| Step: 5
Training loss: 2.3995159098055407
Validation loss: 2.614046282279962

Epoch: 6| Step: 6
Training loss: 1.9464388730837687
Validation loss: 2.5875243113630324

Epoch: 6| Step: 7
Training loss: 2.8688615698301208
Validation loss: 2.5532715710606158

Epoch: 6| Step: 8
Training loss: 1.869133354340287
Validation loss: 2.522495121366725

Epoch: 6| Step: 9
Training loss: 2.60439991224333
Validation loss: 2.488856290587698

Epoch: 6| Step: 10
Training loss: 1.6315355920536387
Validation loss: 2.492034763929504

Epoch: 6| Step: 11
Training loss: 2.43145138413974
Validation loss: 2.492095881803991

Epoch: 6| Step: 12
Training loss: 2.2392654784812085
Validation loss: 2.502185359106049

Epoch: 6| Step: 13
Training loss: 1.7604613289067648
Validation loss: 2.496542033185892

Epoch: 259| Step: 0
Training loss: 2.139809780401349
Validation loss: 2.518904765306735

Epoch: 6| Step: 1
Training loss: 2.5782664867071152
Validation loss: 2.5077908555599087

Epoch: 6| Step: 2
Training loss: 1.9731905072091946
Validation loss: 2.4958313996610544

Epoch: 6| Step: 3
Training loss: 2.4873867373343646
Validation loss: 2.5212994504487987

Epoch: 6| Step: 4
Training loss: 1.7091246454711002
Validation loss: 2.543311201985046

Epoch: 6| Step: 5
Training loss: 2.5148860248805804
Validation loss: 2.545440300936703

Epoch: 6| Step: 6
Training loss: 1.4841783895284824
Validation loss: 2.5756968922445003

Epoch: 6| Step: 7
Training loss: 2.417086093504045
Validation loss: 2.5916611253325494

Epoch: 6| Step: 8
Training loss: 2.07858753076383
Validation loss: 2.5787067951374354

Epoch: 6| Step: 9
Training loss: 2.251717865326768
Validation loss: 2.6106269254487846

Epoch: 6| Step: 10
Training loss: 2.134809962978777
Validation loss: 2.600579290779034

Epoch: 6| Step: 11
Training loss: 2.331370709032472
Validation loss: 2.576020956258257

Epoch: 6| Step: 12
Training loss: 2.642223167968244
Validation loss: 2.585143352471376

Epoch: 6| Step: 13
Training loss: 2.435567432062904
Validation loss: 2.5579738030890455

Epoch: 260| Step: 0
Training loss: 2.441840195809324
Validation loss: 2.5587305706996633

Epoch: 6| Step: 1
Training loss: 1.556315580771035
Validation loss: 2.582364374891144

Epoch: 6| Step: 2
Training loss: 2.274726423645094
Validation loss: 2.5580681569183525

Epoch: 6| Step: 3
Training loss: 2.1031372523411442
Validation loss: 2.5825753074023097

Epoch: 6| Step: 4
Training loss: 2.2139416022934024
Validation loss: 2.610036998233205

Epoch: 6| Step: 5
Training loss: 2.2916108095702166
Validation loss: 2.582113483021684

Epoch: 6| Step: 6
Training loss: 2.0113081726044735
Validation loss: 2.5660535627133085

Epoch: 6| Step: 7
Training loss: 2.23790989536399
Validation loss: 2.5434230353742486

Epoch: 6| Step: 8
Training loss: 2.265908374822786
Validation loss: 2.543764785736127

Epoch: 6| Step: 9
Training loss: 2.2291964829016537
Validation loss: 2.5573784424353883

Epoch: 6| Step: 10
Training loss: 1.7532216118559942
Validation loss: 2.581320783677543

Epoch: 6| Step: 11
Training loss: 2.4595231124310004
Validation loss: 2.5423788469544517

Epoch: 6| Step: 12
Training loss: 2.346544761128371
Validation loss: 2.56638095790994

Epoch: 6| Step: 13
Training loss: 2.6983583793239587
Validation loss: 2.5465443714429847

Epoch: 261| Step: 0
Training loss: 2.22990493195432
Validation loss: 2.551519344577695

Epoch: 6| Step: 1
Training loss: 1.6298733042993332
Validation loss: 2.551518176554836

Epoch: 6| Step: 2
Training loss: 1.6734672878545571
Validation loss: 2.542702765942492

Epoch: 6| Step: 3
Training loss: 1.840181291397992
Validation loss: 2.5598226997947258

Epoch: 6| Step: 4
Training loss: 2.7376120452943606
Validation loss: 2.5543915774550516

Epoch: 6| Step: 5
Training loss: 2.5662276904088217
Validation loss: 2.5704532109387332

Epoch: 6| Step: 6
Training loss: 1.6330693239166332
Validation loss: 2.5676895099643757

Epoch: 6| Step: 7
Training loss: 2.8163313306772078
Validation loss: 2.563156532292698

Epoch: 6| Step: 8
Training loss: 2.957742461893231
Validation loss: 2.5581529077367877

Epoch: 6| Step: 9
Training loss: 1.7499798364840053
Validation loss: 2.590843011742501

Epoch: 6| Step: 10
Training loss: 1.9526894045506908
Validation loss: 2.634132031948486

Epoch: 6| Step: 11
Training loss: 2.4322788366160433
Validation loss: 2.6383397824932935

Epoch: 6| Step: 12
Training loss: 2.38185795910279
Validation loss: 2.644487644514096

Epoch: 6| Step: 13
Training loss: 2.1051840510061917
Validation loss: 2.6391205574426704

Epoch: 262| Step: 0
Training loss: 2.5394606058092397
Validation loss: 2.60306949136511

Epoch: 6| Step: 1
Training loss: 1.952495626134528
Validation loss: 2.5828776393460218

Epoch: 6| Step: 2
Training loss: 1.9362195613825337
Validation loss: 2.579029595014815

Epoch: 6| Step: 3
Training loss: 2.2156553581105687
Validation loss: 2.587809612037777

Epoch: 6| Step: 4
Training loss: 2.5744289839109338
Validation loss: 2.567971946591302

Epoch: 6| Step: 5
Training loss: 2.0885576230118987
Validation loss: 2.5795371455602485

Epoch: 6| Step: 6
Training loss: 2.5722923190528335
Validation loss: 2.5773113777908185

Epoch: 6| Step: 7
Training loss: 2.6838291736823154
Validation loss: 2.5746931257378223

Epoch: 6| Step: 8
Training loss: 2.4165332581978
Validation loss: 2.5784249718829866

Epoch: 6| Step: 9
Training loss: 1.6987974850471839
Validation loss: 2.5959432589879325

Epoch: 6| Step: 10
Training loss: 1.5750358486637077
Validation loss: 2.661392559475492

Epoch: 6| Step: 11
Training loss: 2.4561829186517663
Validation loss: 2.6332839407896054

Epoch: 6| Step: 12
Training loss: 1.7163615884643764
Validation loss: 2.6537404491164645

Epoch: 6| Step: 13
Training loss: 2.4099631456271795
Validation loss: 2.570103088938575

Epoch: 263| Step: 0
Training loss: 2.3416313259222785
Validation loss: 2.5697100628061738

Epoch: 6| Step: 1
Training loss: 2.43922900963983
Validation loss: 2.5215718682373893

Epoch: 6| Step: 2
Training loss: 1.9541307835107482
Validation loss: 2.5043975379842993

Epoch: 6| Step: 3
Training loss: 2.3767210095556406
Validation loss: 2.499811356102911

Epoch: 6| Step: 4
Training loss: 2.049445482015182
Validation loss: 2.498458880026263

Epoch: 6| Step: 5
Training loss: 2.3610815482688614
Validation loss: 2.502582059055348

Epoch: 6| Step: 6
Training loss: 2.6995345067607746
Validation loss: 2.530076637992051

Epoch: 6| Step: 7
Training loss: 2.0311636099417405
Validation loss: 2.523892718847822

Epoch: 6| Step: 8
Training loss: 1.7499688009478258
Validation loss: 2.5590264107435816

Epoch: 6| Step: 9
Training loss: 1.9176092179886493
Validation loss: 2.5606048988656345

Epoch: 6| Step: 10
Training loss: 2.478084253118073
Validation loss: 2.580653836523492

Epoch: 6| Step: 11
Training loss: 2.4646354865400384
Validation loss: 2.5853532205973897

Epoch: 6| Step: 12
Training loss: 2.336656746763903
Validation loss: 2.602308576825815

Epoch: 6| Step: 13
Training loss: 1.8917904248975383
Validation loss: 2.6080645699001654

Epoch: 264| Step: 0
Training loss: 3.3256578927509515
Validation loss: 2.6019010886720793

Epoch: 6| Step: 1
Training loss: 1.9345809728260361
Validation loss: 2.581820188390088

Epoch: 6| Step: 2
Training loss: 2.753884173365634
Validation loss: 2.591342406108896

Epoch: 6| Step: 3
Training loss: 1.8537583991057867
Validation loss: 2.6059324508650406

Epoch: 6| Step: 4
Training loss: 1.9558272322353822
Validation loss: 2.5626283241333403

Epoch: 6| Step: 5
Training loss: 1.9067379686499424
Validation loss: 2.5427631504057713

Epoch: 6| Step: 6
Training loss: 1.5415409483641356
Validation loss: 2.5517437507834666

Epoch: 6| Step: 7
Training loss: 2.111436528785057
Validation loss: 2.5481745207079576

Epoch: 6| Step: 8
Training loss: 1.863410353436459
Validation loss: 2.5365287776201617

Epoch: 6| Step: 9
Training loss: 1.8767289137920364
Validation loss: 2.5285593182384356

Epoch: 6| Step: 10
Training loss: 2.091367362241186
Validation loss: 2.543986486491014

Epoch: 6| Step: 11
Training loss: 2.2279549511065424
Validation loss: 2.52948196892521

Epoch: 6| Step: 12
Training loss: 2.3860021036591252
Validation loss: 2.563339344045721

Epoch: 6| Step: 13
Training loss: 2.3427170575359546
Validation loss: 2.6040953868011756

Epoch: 265| Step: 0
Training loss: 1.9783933098991122
Validation loss: 2.6283249082371816

Epoch: 6| Step: 1
Training loss: 1.5224343151336561
Validation loss: 2.649905942651186

Epoch: 6| Step: 2
Training loss: 2.020284309397046
Validation loss: 2.6372542075420338

Epoch: 6| Step: 3
Training loss: 2.015851858221341
Validation loss: 2.681726567761272

Epoch: 6| Step: 4
Training loss: 2.5166597311501167
Validation loss: 2.707267556420104

Epoch: 6| Step: 5
Training loss: 1.890893586051836
Validation loss: 2.701237675657671

Epoch: 6| Step: 6
Training loss: 2.360331562479913
Validation loss: 2.6257792784480953

Epoch: 6| Step: 7
Training loss: 3.4213142109686125
Validation loss: 2.5508759944937074

Epoch: 6| Step: 8
Training loss: 2.023369983150536
Validation loss: 2.5468293480399344

Epoch: 6| Step: 9
Training loss: 2.248030754449151
Validation loss: 2.5119698865132336

Epoch: 6| Step: 10
Training loss: 2.5132911233705078
Validation loss: 2.5212109390634763

Epoch: 6| Step: 11
Training loss: 2.2690979745894917
Validation loss: 2.5236450913018875

Epoch: 6| Step: 12
Training loss: 1.7312567920758153
Validation loss: 2.51141127725949

Epoch: 6| Step: 13
Training loss: 2.472757105405127
Validation loss: 2.5362850080379946

Epoch: 266| Step: 0
Training loss: 3.028807294920022
Validation loss: 2.530610557132432

Epoch: 6| Step: 1
Training loss: 1.649933195206709
Validation loss: 2.6050511244225327

Epoch: 6| Step: 2
Training loss: 3.2174766021565415
Validation loss: 2.6604745070448805

Epoch: 6| Step: 3
Training loss: 2.1948854295726226
Validation loss: 2.6668645715788983

Epoch: 6| Step: 4
Training loss: 1.7079534418384814
Validation loss: 2.6525143253420165

Epoch: 6| Step: 5
Training loss: 1.662571772123218
Validation loss: 2.68253303602294

Epoch: 6| Step: 6
Training loss: 2.044029995931463
Validation loss: 2.6851284889530134

Epoch: 6| Step: 7
Training loss: 2.455831795924853
Validation loss: 2.604330978296142

Epoch: 6| Step: 8
Training loss: 2.2865184408178725
Validation loss: 2.552799736729171

Epoch: 6| Step: 9
Training loss: 1.8490005989795826
Validation loss: 2.550170404686966

Epoch: 6| Step: 10
Training loss: 2.147574400495606
Validation loss: 2.536960784421571

Epoch: 6| Step: 11
Training loss: 2.190429252117656
Validation loss: 2.514113673164888

Epoch: 6| Step: 12
Training loss: 2.13211204568618
Validation loss: 2.5145957689417617

Epoch: 6| Step: 13
Training loss: 1.9778065743058475
Validation loss: 2.515989612827278

Epoch: 267| Step: 0
Training loss: 2.448895933545352
Validation loss: 2.5195904076701234

Epoch: 6| Step: 1
Training loss: 2.090126203897213
Validation loss: 2.5389880203669604

Epoch: 6| Step: 2
Training loss: 1.6714146060383464
Validation loss: 2.627989323304512

Epoch: 6| Step: 3
Training loss: 2.165882983673981
Validation loss: 2.6807557730166267

Epoch: 6| Step: 4
Training loss: 2.46872585622836
Validation loss: 2.689956141507846

Epoch: 6| Step: 5
Training loss: 2.1190764949253755
Validation loss: 2.6940878477011436

Epoch: 6| Step: 6
Training loss: 2.717912742342512
Validation loss: 2.665668082028849

Epoch: 6| Step: 7
Training loss: 1.7210003079863498
Validation loss: 2.615374689798954

Epoch: 6| Step: 8
Training loss: 1.694446817337348
Validation loss: 2.5337512526958363

Epoch: 6| Step: 9
Training loss: 2.4066700754467325
Validation loss: 2.529817646865704

Epoch: 6| Step: 10
Training loss: 2.8196143134130613
Validation loss: 2.4920332491183794

Epoch: 6| Step: 11
Training loss: 1.6631908014089902
Validation loss: 2.5076449170869584

Epoch: 6| Step: 12
Training loss: 3.092217267988504
Validation loss: 2.5040142573620034

Epoch: 6| Step: 13
Training loss: 2.0924528288452247
Validation loss: 2.4781677947933223

Epoch: 268| Step: 0
Training loss: 2.3289979667736596
Validation loss: 2.4888460964424937

Epoch: 6| Step: 1
Training loss: 3.133655006724875
Validation loss: 2.5144036765869

Epoch: 6| Step: 2
Training loss: 1.5047787203921281
Validation loss: 2.519187221647247

Epoch: 6| Step: 3
Training loss: 1.971257988932307
Validation loss: 2.582905800625211

Epoch: 6| Step: 4
Training loss: 2.2218812151042644
Validation loss: 2.559829918034423

Epoch: 6| Step: 5
Training loss: 1.6424772433442005
Validation loss: 2.5949016143974135

Epoch: 6| Step: 6
Training loss: 1.940826513666882
Validation loss: 2.5990478306550098

Epoch: 6| Step: 7
Training loss: 2.661402025516731
Validation loss: 2.565222201399064

Epoch: 6| Step: 8
Training loss: 1.4280203181993116
Validation loss: 2.5533221345743886

Epoch: 6| Step: 9
Training loss: 2.1228521375298235
Validation loss: 2.5530404508389193

Epoch: 6| Step: 10
Training loss: 2.6152934494354847
Validation loss: 2.5231547162757595

Epoch: 6| Step: 11
Training loss: 2.3186087470202974
Validation loss: 2.5390602620432845

Epoch: 6| Step: 12
Training loss: 2.612716727872304
Validation loss: 2.536944604485648

Epoch: 6| Step: 13
Training loss: 1.8527085503731375
Validation loss: 2.5569385639583286

Epoch: 269| Step: 0
Training loss: 1.9610956743741679
Validation loss: 2.532024594692204

Epoch: 6| Step: 1
Training loss: 2.4040015478525874
Validation loss: 2.5345229350673

Epoch: 6| Step: 2
Training loss: 1.8421336702436688
Validation loss: 2.5097948678733704

Epoch: 6| Step: 3
Training loss: 2.1148423160002756
Validation loss: 2.50783653683497

Epoch: 6| Step: 4
Training loss: 2.513856633531474
Validation loss: 2.515110018442856

Epoch: 6| Step: 5
Training loss: 1.846167385910586
Validation loss: 2.508650753514471

Epoch: 6| Step: 6
Training loss: 2.291843014492086
Validation loss: 2.5356187207579346

Epoch: 6| Step: 7
Training loss: 2.2330968442178047
Validation loss: 2.518108066512317

Epoch: 6| Step: 8
Training loss: 1.5264896434004036
Validation loss: 2.520585250206861

Epoch: 6| Step: 9
Training loss: 2.5066438132454985
Validation loss: 2.5126296508132664

Epoch: 6| Step: 10
Training loss: 2.5166959200878862
Validation loss: 2.5340815354231014

Epoch: 6| Step: 11
Training loss: 2.1237370721110325
Validation loss: 2.583822639845597

Epoch: 6| Step: 12
Training loss: 2.048025026555929
Validation loss: 2.6117204948173747

Epoch: 6| Step: 13
Training loss: 2.722798107069335
Validation loss: 2.6390900599333835

Epoch: 270| Step: 0
Training loss: 2.4938853827036613
Validation loss: 2.626373461521061

Epoch: 6| Step: 1
Training loss: 2.216949914699448
Validation loss: 2.6118668937450815

Epoch: 6| Step: 2
Training loss: 2.4460434476248487
Validation loss: 2.625699358829057

Epoch: 6| Step: 3
Training loss: 1.6355685104859674
Validation loss: 2.624027329330672

Epoch: 6| Step: 4
Training loss: 2.292809034045697
Validation loss: 2.6401688672735193

Epoch: 6| Step: 5
Training loss: 2.259584358614178
Validation loss: 2.659510193737996

Epoch: 6| Step: 6
Training loss: 1.9813179437678003
Validation loss: 2.6700117518848576

Epoch: 6| Step: 7
Training loss: 1.6371727361594077
Validation loss: 2.6994961910212685

Epoch: 6| Step: 8
Training loss: 1.9759070474406766
Validation loss: 2.6230868982446225

Epoch: 6| Step: 9
Training loss: 2.3272983184201252
Validation loss: 2.5922600630034704

Epoch: 6| Step: 10
Training loss: 2.3991682200698974
Validation loss: 2.5551032953850386

Epoch: 6| Step: 11
Training loss: 1.418572247499052
Validation loss: 2.529047521919756

Epoch: 6| Step: 12
Training loss: 3.2260005729471395
Validation loss: 2.51399422934777

Epoch: 6| Step: 13
Training loss: 2.073517359307456
Validation loss: 2.5219956915493658

Epoch: 271| Step: 0
Training loss: 1.2174862887885274
Validation loss: 2.5238015430937764

Epoch: 6| Step: 1
Training loss: 2.1878803467470815
Validation loss: 2.543321185635029

Epoch: 6| Step: 2
Training loss: 2.1650033826559305
Validation loss: 2.5390847073097356

Epoch: 6| Step: 3
Training loss: 2.2985762958124534
Validation loss: 2.5533663632104933

Epoch: 6| Step: 4
Training loss: 2.3635359697762217
Validation loss: 2.564213133576781

Epoch: 6| Step: 5
Training loss: 2.4857595172612794
Validation loss: 2.6014079829887353

Epoch: 6| Step: 6
Training loss: 2.832547434100736
Validation loss: 2.6488017954134464

Epoch: 6| Step: 7
Training loss: 1.9300752937374877
Validation loss: 2.6773478653134712

Epoch: 6| Step: 8
Training loss: 2.506912878183542
Validation loss: 2.6491916749231215

Epoch: 6| Step: 9
Training loss: 2.1300147853929166
Validation loss: 2.638381863009364

Epoch: 6| Step: 10
Training loss: 2.776989706358962
Validation loss: 2.6090280450649246

Epoch: 6| Step: 11
Training loss: 2.1213153983236532
Validation loss: 2.5491706160080057

Epoch: 6| Step: 12
Training loss: 1.4972684944298507
Validation loss: 2.5309087421218273

Epoch: 6| Step: 13
Training loss: 2.3087664182995167
Validation loss: 2.5176590146174442

Epoch: 272| Step: 0
Training loss: 2.4813282836556576
Validation loss: 2.50359237377868

Epoch: 6| Step: 1
Training loss: 1.8188471319210653
Validation loss: 2.4973033030011758

Epoch: 6| Step: 2
Training loss: 2.6315252853242783
Validation loss: 2.4964296117967923

Epoch: 6| Step: 3
Training loss: 1.5775264700287464
Validation loss: 2.521506012208876

Epoch: 6| Step: 4
Training loss: 2.5436761343913976
Validation loss: 2.5178072371105693

Epoch: 6| Step: 5
Training loss: 2.3620396402700425
Validation loss: 2.5083678552611324

Epoch: 6| Step: 6
Training loss: 1.9471429998571497
Validation loss: 2.5492723879216244

Epoch: 6| Step: 7
Training loss: 1.8403764022534725
Validation loss: 2.5513593827628847

Epoch: 6| Step: 8
Training loss: 2.0345994769827014
Validation loss: 2.5508563199565866

Epoch: 6| Step: 9
Training loss: 2.3014018803610115
Validation loss: 2.5583139902392174

Epoch: 6| Step: 10
Training loss: 2.2628545198831316
Validation loss: 2.6127297009934045

Epoch: 6| Step: 11
Training loss: 1.6971866778064606
Validation loss: 2.625649311352964

Epoch: 6| Step: 12
Training loss: 2.130388943975326
Validation loss: 2.681650790097798

Epoch: 6| Step: 13
Training loss: 2.7989256602913124
Validation loss: 2.6565465425003763

Epoch: 273| Step: 0
Training loss: 1.93480913901577
Validation loss: 2.6400159024231655

Epoch: 6| Step: 1
Training loss: 1.8478045091564308
Validation loss: 2.6175922517329346

Epoch: 6| Step: 2
Training loss: 2.693317415769519
Validation loss: 2.551794219995171

Epoch: 6| Step: 3
Training loss: 1.9354282500622222
Validation loss: 2.541611128862131

Epoch: 6| Step: 4
Training loss: 2.042330173449933
Validation loss: 2.5371829700832818

Epoch: 6| Step: 5
Training loss: 2.170826610864736
Validation loss: 2.5598930651215452

Epoch: 6| Step: 6
Training loss: 2.1829317621460445
Validation loss: 2.5493476581782866

Epoch: 6| Step: 7
Training loss: 1.6052720443621145
Validation loss: 2.556109904435182

Epoch: 6| Step: 8
Training loss: 2.2336275144188535
Validation loss: 2.5638299762583414

Epoch: 6| Step: 9
Training loss: 2.6822328628958263
Validation loss: 2.5588635329102214

Epoch: 6| Step: 10
Training loss: 2.6205937779952806
Validation loss: 2.5923473748036954

Epoch: 6| Step: 11
Training loss: 1.9197368358027078
Validation loss: 2.6007000139757137

Epoch: 6| Step: 12
Training loss: 2.07823031739416
Validation loss: 2.574516823259316

Epoch: 6| Step: 13
Training loss: 2.324712313009254
Validation loss: 2.5596560536985185

Epoch: 274| Step: 0
Training loss: 1.8969291063413158
Validation loss: 2.547080119479541

Epoch: 6| Step: 1
Training loss: 1.7096940490786876
Validation loss: 2.5570379210300684

Epoch: 6| Step: 2
Training loss: 2.2760986274441244
Validation loss: 2.5784434112282577

Epoch: 6| Step: 3
Training loss: 2.1894219810591604
Validation loss: 2.565923636708773

Epoch: 6| Step: 4
Training loss: 1.5936395943491257
Validation loss: 2.551242149972684

Epoch: 6| Step: 5
Training loss: 2.003775609091336
Validation loss: 2.569067053243864

Epoch: 6| Step: 6
Training loss: 2.3867315363814616
Validation loss: 2.590577671246042

Epoch: 6| Step: 7
Training loss: 2.520158367327564
Validation loss: 2.597110792366067

Epoch: 6| Step: 8
Training loss: 1.815300652164377
Validation loss: 2.627401948424721

Epoch: 6| Step: 9
Training loss: 2.5001634544343614
Validation loss: 2.658758572096966

Epoch: 6| Step: 10
Training loss: 1.7569127471570827
Validation loss: 2.6233861291493326

Epoch: 6| Step: 11
Training loss: 2.5538633924676697
Validation loss: 2.6349986552766462

Epoch: 6| Step: 12
Training loss: 2.878445592331934
Validation loss: 2.6473625799914076

Epoch: 6| Step: 13
Training loss: 1.9653516837138538
Validation loss: 2.6301590766952736

Epoch: 275| Step: 0
Training loss: 1.6073987363538134
Validation loss: 2.619967298643342

Epoch: 6| Step: 1
Training loss: 1.1729431370695094
Validation loss: 2.6097871374971664

Epoch: 6| Step: 2
Training loss: 2.4504121005629744
Validation loss: 2.583316915726535

Epoch: 6| Step: 3
Training loss: 2.9444186931259773
Validation loss: 2.6030079870649803

Epoch: 6| Step: 4
Training loss: 2.1527123663477576
Validation loss: 2.5827454518444384

Epoch: 6| Step: 5
Training loss: 2.9729799352559665
Validation loss: 2.577131754349105

Epoch: 6| Step: 6
Training loss: 2.260646954831388
Validation loss: 2.591066972053243

Epoch: 6| Step: 7
Training loss: 1.701999747544123
Validation loss: 2.6057679453974845

Epoch: 6| Step: 8
Training loss: 2.9132805560094037
Validation loss: 2.5845841153656286

Epoch: 6| Step: 9
Training loss: 2.161815040906055
Validation loss: 2.5704719470811583

Epoch: 6| Step: 10
Training loss: 1.7536287831662578
Validation loss: 2.5325181711994174

Epoch: 6| Step: 11
Training loss: 1.869201276506657
Validation loss: 2.5555680805627294

Epoch: 6| Step: 12
Training loss: 1.7713182869873834
Validation loss: 2.5545344720051277

Epoch: 6| Step: 13
Training loss: 1.939812971616827
Validation loss: 2.618686106531327

Epoch: 276| Step: 0
Training loss: 1.9439252326700176
Validation loss: 2.669038452950052

Epoch: 6| Step: 1
Training loss: 2.3283145494552135
Validation loss: 2.708419297150075

Epoch: 6| Step: 2
Training loss: 2.2938058290261654
Validation loss: 2.6887071840597634

Epoch: 6| Step: 3
Training loss: 2.564844315174702
Validation loss: 2.7063650951035396

Epoch: 6| Step: 4
Training loss: 2.510310274985301
Validation loss: 2.6741068555190513

Epoch: 6| Step: 5
Training loss: 2.091624761316159
Validation loss: 2.624540629382917

Epoch: 6| Step: 6
Training loss: 1.6611371900892127
Validation loss: 2.6264345094387966

Epoch: 6| Step: 7
Training loss: 2.782997182621902
Validation loss: 2.564160080625324

Epoch: 6| Step: 8
Training loss: 1.8448289849850426
Validation loss: 2.5480604786704415

Epoch: 6| Step: 9
Training loss: 2.0742736924073406
Validation loss: 2.538266288922225

Epoch: 6| Step: 10
Training loss: 2.093071671105828
Validation loss: 2.5222583373836236

Epoch: 6| Step: 11
Training loss: 1.6498532836881385
Validation loss: 2.527855390421496

Epoch: 6| Step: 12
Training loss: 1.816791977483119
Validation loss: 2.541371849555074

Epoch: 6| Step: 13
Training loss: 2.1702977223233058
Validation loss: 2.5372258199507516

Epoch: 277| Step: 0
Training loss: 2.7118719507724687
Validation loss: 2.555322177453905

Epoch: 6| Step: 1
Training loss: 1.1577163882910932
Validation loss: 2.594267153984626

Epoch: 6| Step: 2
Training loss: 1.9149705873626015
Validation loss: 2.5848504554341654

Epoch: 6| Step: 3
Training loss: 2.165818366243264
Validation loss: 2.626927228419443

Epoch: 6| Step: 4
Training loss: 2.1999277493143654
Validation loss: 2.5869022194867406

Epoch: 6| Step: 5
Training loss: 2.9012583863393138
Validation loss: 2.612223625470287

Epoch: 6| Step: 6
Training loss: 2.350320583147519
Validation loss: 2.6174908666199364

Epoch: 6| Step: 7
Training loss: 2.0079514273585772
Validation loss: 2.5808145077192965

Epoch: 6| Step: 8
Training loss: 1.657260946120549
Validation loss: 2.5755383240530465

Epoch: 6| Step: 9
Training loss: 2.153007169691197
Validation loss: 2.557444151600759

Epoch: 6| Step: 10
Training loss: 2.775451187020666
Validation loss: 2.519452486606012

Epoch: 6| Step: 11
Training loss: 2.396863389764192
Validation loss: 2.5011585332747095

Epoch: 6| Step: 12
Training loss: 1.9172867380090124
Validation loss: 2.493568508137481

Epoch: 6| Step: 13
Training loss: 1.5908221858922749
Validation loss: 2.4904203298115344

Epoch: 278| Step: 0
Training loss: 2.5362794618507554
Validation loss: 2.5007796979027614

Epoch: 6| Step: 1
Training loss: 2.6597444772965084
Validation loss: 2.5188994963574545

Epoch: 6| Step: 2
Training loss: 1.9691397871436795
Validation loss: 2.5684857123454483

Epoch: 6| Step: 3
Training loss: 1.993884751121999
Validation loss: 2.6323840569023456

Epoch: 6| Step: 4
Training loss: 2.5217117691628874
Validation loss: 2.6380185236768536

Epoch: 6| Step: 5
Training loss: 1.6131913203928405
Validation loss: 2.6804367070926665

Epoch: 6| Step: 6
Training loss: 2.175985823213453
Validation loss: 2.678791559952846

Epoch: 6| Step: 7
Training loss: 2.224378726245474
Validation loss: 2.6658639568928226

Epoch: 6| Step: 8
Training loss: 2.562207088942261
Validation loss: 2.650943541943552

Epoch: 6| Step: 9
Training loss: 1.6256256366333968
Validation loss: 2.6660371176350544

Epoch: 6| Step: 10
Training loss: 1.6087521579256678
Validation loss: 2.6253003145424065

Epoch: 6| Step: 11
Training loss: 1.9133041436541833
Validation loss: 2.560773671162055

Epoch: 6| Step: 12
Training loss: 2.045915917661005
Validation loss: 2.5779397608937877

Epoch: 6| Step: 13
Training loss: 2.552386726458945
Validation loss: 2.591581947520179

Epoch: 279| Step: 0
Training loss: 2.0797595715949644
Validation loss: 2.569152825506217

Epoch: 6| Step: 1
Training loss: 1.9822947494261025
Validation loss: 2.570714314290572

Epoch: 6| Step: 2
Training loss: 2.9551599343744384
Validation loss: 2.5850675027938346

Epoch: 6| Step: 3
Training loss: 2.826726240873836
Validation loss: 2.5964367291259944

Epoch: 6| Step: 4
Training loss: 1.860954191067373
Validation loss: 2.601004692510459

Epoch: 6| Step: 5
Training loss: 1.4816611125886288
Validation loss: 2.5791194192464864

Epoch: 6| Step: 6
Training loss: 2.578497564965963
Validation loss: 2.570676273471773

Epoch: 6| Step: 7
Training loss: 1.737476359693675
Validation loss: 2.556874559082749

Epoch: 6| Step: 8
Training loss: 2.7138141243912792
Validation loss: 2.5746409832567143

Epoch: 6| Step: 9
Training loss: 1.794791166010643
Validation loss: 2.58772377483946

Epoch: 6| Step: 10
Training loss: 2.4685639902853036
Validation loss: 2.60839485749961

Epoch: 6| Step: 11
Training loss: 1.3666653753290046
Validation loss: 2.6168733778375226

Epoch: 6| Step: 12
Training loss: 1.6942204064988473
Validation loss: 2.623292390264734

Epoch: 6| Step: 13
Training loss: 1.646520575762323
Validation loss: 2.646584979745703

Epoch: 280| Step: 0
Training loss: 2.3701994716222345
Validation loss: 2.6223229881455286

Epoch: 6| Step: 1
Training loss: 1.4124844423635712
Validation loss: 2.606743366860201

Epoch: 6| Step: 2
Training loss: 2.241324335026119
Validation loss: 2.632962366926857

Epoch: 6| Step: 3
Training loss: 2.103219439127728
Validation loss: 2.549848852477606

Epoch: 6| Step: 4
Training loss: 1.5854295189529115
Validation loss: 2.550924876416003

Epoch: 6| Step: 5
Training loss: 2.492808871401082
Validation loss: 2.506958686410094

Epoch: 6| Step: 6
Training loss: 2.404567576213374
Validation loss: 2.495907485531178

Epoch: 6| Step: 7
Training loss: 2.408954240249534
Validation loss: 2.4962618218531847

Epoch: 6| Step: 8
Training loss: 2.234500588042036
Validation loss: 2.4846087331804707

Epoch: 6| Step: 9
Training loss: 1.9325905403354944
Validation loss: 2.4698679038747264

Epoch: 6| Step: 10
Training loss: 2.0074613390248497
Validation loss: 2.4809731598867675

Epoch: 6| Step: 11
Training loss: 2.2679368424544597
Validation loss: 2.489020141573198

Epoch: 6| Step: 12
Training loss: 2.158454762974233
Validation loss: 2.5064528949957467

Epoch: 6| Step: 13
Training loss: 2.2448680419202294
Validation loss: 2.5196418915341505

Epoch: 281| Step: 0
Training loss: 1.359646386428221
Validation loss: 2.5195820648037084

Epoch: 6| Step: 1
Training loss: 1.7658072183480265
Validation loss: 2.5382465322994263

Epoch: 6| Step: 2
Training loss: 2.289226226679868
Validation loss: 2.5668420678023085

Epoch: 6| Step: 3
Training loss: 2.476667432036181
Validation loss: 2.588627210670861

Epoch: 6| Step: 4
Training loss: 1.460303429073975
Validation loss: 2.5997113733991073

Epoch: 6| Step: 5
Training loss: 2.2060855966321817
Validation loss: 2.6279616300204927

Epoch: 6| Step: 6
Training loss: 2.469003302218522
Validation loss: 2.5878764218114565

Epoch: 6| Step: 7
Training loss: 1.7871805479124911
Validation loss: 2.5541882819484436

Epoch: 6| Step: 8
Training loss: 2.816916494933549
Validation loss: 2.5394514519545566

Epoch: 6| Step: 9
Training loss: 2.291969926593536
Validation loss: 2.5401725337986085

Epoch: 6| Step: 10
Training loss: 1.393929872752016
Validation loss: 2.5409181670475904

Epoch: 6| Step: 11
Training loss: 2.5887566725987043
Validation loss: 2.547237581058606

Epoch: 6| Step: 12
Training loss: 2.036348956228574
Validation loss: 2.549927354849958

Epoch: 6| Step: 13
Training loss: 2.2745149032362804
Validation loss: 2.571387331937171

Epoch: 282| Step: 0
Training loss: 1.8683542732043101
Validation loss: 2.557755520791263

Epoch: 6| Step: 1
Training loss: 1.8026507886228702
Validation loss: 2.588702487874876

Epoch: 6| Step: 2
Training loss: 2.033423801139719
Validation loss: 2.614256140511621

Epoch: 6| Step: 3
Training loss: 2.4591468714924876
Validation loss: 2.5975212654856294

Epoch: 6| Step: 4
Training loss: 2.215849363860349
Validation loss: 2.629414539975325

Epoch: 6| Step: 5
Training loss: 1.8473128469444704
Validation loss: 2.6003011675783587

Epoch: 6| Step: 6
Training loss: 2.066015311111481
Validation loss: 2.5816792504496666

Epoch: 6| Step: 7
Training loss: 1.886067532763321
Validation loss: 2.5384661477905905

Epoch: 6| Step: 8
Training loss: 2.8058030823981257
Validation loss: 2.534779336944848

Epoch: 6| Step: 9
Training loss: 2.5067341705458572
Validation loss: 2.5421563494961537

Epoch: 6| Step: 10
Training loss: 1.9369107242427368
Validation loss: 2.5774520303953388

Epoch: 6| Step: 11
Training loss: 1.6608453734032131
Validation loss: 2.6026823671165733

Epoch: 6| Step: 12
Training loss: 2.0608115943701
Validation loss: 2.621067871329843

Epoch: 6| Step: 13
Training loss: 2.385723599561747
Validation loss: 2.6072146825109908

Epoch: 283| Step: 0
Training loss: 2.09326348417015
Validation loss: 2.649373529566832

Epoch: 6| Step: 1
Training loss: 2.536444432235527
Validation loss: 2.6431948028485457

Epoch: 6| Step: 2
Training loss: 2.135961534410944
Validation loss: 2.6082739724746493

Epoch: 6| Step: 3
Training loss: 2.0364793807272985
Validation loss: 2.56873912638817

Epoch: 6| Step: 4
Training loss: 2.069417738546601
Validation loss: 2.513640669574903

Epoch: 6| Step: 5
Training loss: 2.350778442665115
Validation loss: 2.519226828624505

Epoch: 6| Step: 6
Training loss: 2.195332265744537
Validation loss: 2.543621114329038

Epoch: 6| Step: 7
Training loss: 1.7934948517103617
Validation loss: 2.5719780284443443

Epoch: 6| Step: 8
Training loss: 1.1846729558013178
Validation loss: 2.612063243320365

Epoch: 6| Step: 9
Training loss: 2.312821855571222
Validation loss: 2.582812800314121

Epoch: 6| Step: 10
Training loss: 2.7405704610306554
Validation loss: 2.6706431860244675

Epoch: 6| Step: 11
Training loss: 1.720899451635086
Validation loss: 2.6526927240882587

Epoch: 6| Step: 12
Training loss: 2.029749389362678
Validation loss: 2.617858709551577

Epoch: 6| Step: 13
Training loss: 1.9279358361437637
Validation loss: 2.6041239366204643

Epoch: 284| Step: 0
Training loss: 2.376176241673614
Validation loss: 2.520571992006056

Epoch: 6| Step: 1
Training loss: 1.883620346052448
Validation loss: 2.502904849425932

Epoch: 6| Step: 2
Training loss: 2.4346731373066204
Validation loss: 2.5134723844015983

Epoch: 6| Step: 3
Training loss: 2.2267189372469947
Validation loss: 2.511010069511557

Epoch: 6| Step: 4
Training loss: 1.5952833690468202
Validation loss: 2.513382735736546

Epoch: 6| Step: 5
Training loss: 2.531490549972891
Validation loss: 2.5286038071465913

Epoch: 6| Step: 6
Training loss: 1.3653661312327565
Validation loss: 2.607120644150657

Epoch: 6| Step: 7
Training loss: 1.6031155383330906
Validation loss: 2.677636417198899

Epoch: 6| Step: 8
Training loss: 2.2242107620337004
Validation loss: 2.710555739552513

Epoch: 6| Step: 9
Training loss: 2.051884701276254
Validation loss: 2.736203147471955

Epoch: 6| Step: 10
Training loss: 2.801810401377751
Validation loss: 2.8016775232074838

Epoch: 6| Step: 11
Training loss: 2.552402045661646
Validation loss: 2.695455324378616

Epoch: 6| Step: 12
Training loss: 2.470766716542058
Validation loss: 2.609622433441718

Epoch: 6| Step: 13
Training loss: 1.5012075014475326
Validation loss: 2.4985912645461315

Epoch: 285| Step: 0
Training loss: 2.0029273068001454
Validation loss: 2.475501269335374

Epoch: 6| Step: 1
Training loss: 2.6003627817440567
Validation loss: 2.4905883377931484

Epoch: 6| Step: 2
Training loss: 2.7896167193792123
Validation loss: 2.512726150127763

Epoch: 6| Step: 3
Training loss: 1.6026650704097152
Validation loss: 2.48896278777096

Epoch: 6| Step: 4
Training loss: 1.7291166305962677
Validation loss: 2.4945902149094263

Epoch: 6| Step: 5
Training loss: 1.748158166848286
Validation loss: 2.511623746618721

Epoch: 6| Step: 6
Training loss: 2.6641067098489883
Validation loss: 2.4883250218188944

Epoch: 6| Step: 7
Training loss: 2.1447580353105793
Validation loss: 2.501144234745203

Epoch: 6| Step: 8
Training loss: 2.0750315882105346
Validation loss: 2.509751834658328

Epoch: 6| Step: 9
Training loss: 2.172474071844005
Validation loss: 2.5472565347608467

Epoch: 6| Step: 10
Training loss: 2.1293569665161427
Validation loss: 2.5764846052798966

Epoch: 6| Step: 11
Training loss: 2.7360872847481934
Validation loss: 2.580613185972243

Epoch: 6| Step: 12
Training loss: 1.9116099312214003
Validation loss: 2.6393975409014123

Epoch: 6| Step: 13
Training loss: 2.4317513191734887
Validation loss: 2.716878897523216

Epoch: 286| Step: 0
Training loss: 2.52308203493606
Validation loss: 2.6973340400786645

Epoch: 6| Step: 1
Training loss: 2.0879141482392134
Validation loss: 2.6472679263885417

Epoch: 6| Step: 2
Training loss: 1.6414168853633089
Validation loss: 2.6138217977097242

Epoch: 6| Step: 3
Training loss: 2.1968315543468115
Validation loss: 2.551308959461579

Epoch: 6| Step: 4
Training loss: 2.129470498440692
Validation loss: 2.5168273611322687

Epoch: 6| Step: 5
Training loss: 2.3795624127139376
Validation loss: 2.5083060407790714

Epoch: 6| Step: 6
Training loss: 2.111487454058451
Validation loss: 2.4833792044309466

Epoch: 6| Step: 7
Training loss: 1.8290350841329583
Validation loss: 2.482727896303405

Epoch: 6| Step: 8
Training loss: 2.458397320275626
Validation loss: 2.4832975982381993

Epoch: 6| Step: 9
Training loss: 2.171685958429205
Validation loss: 2.5049113271377936

Epoch: 6| Step: 10
Training loss: 2.56700464062927
Validation loss: 2.5133998183184922

Epoch: 6| Step: 11
Training loss: 2.0134882283573554
Validation loss: 2.5155285645002183

Epoch: 6| Step: 12
Training loss: 1.677488511070329
Validation loss: 2.5193348968248985

Epoch: 6| Step: 13
Training loss: 2.1167838637379233
Validation loss: 2.569614721504145

Epoch: 287| Step: 0
Training loss: 1.634003200509195
Validation loss: 2.5683165185251253

Epoch: 6| Step: 1
Training loss: 2.21510994201333
Validation loss: 2.5707456925187366

Epoch: 6| Step: 2
Training loss: 1.9689133591467187
Validation loss: 2.585461421910137

Epoch: 6| Step: 3
Training loss: 2.4120423589501137
Validation loss: 2.54891759488863

Epoch: 6| Step: 4
Training loss: 2.2230700491483417
Validation loss: 2.5664081079949517

Epoch: 6| Step: 5
Training loss: 2.4348788718110486
Validation loss: 2.5367104302573282

Epoch: 6| Step: 6
Training loss: 2.116602067136832
Validation loss: 2.5288127263967084

Epoch: 6| Step: 7
Training loss: 1.3375747196325054
Validation loss: 2.560852373968712

Epoch: 6| Step: 8
Training loss: 2.460709431086052
Validation loss: 2.5694686602118644

Epoch: 6| Step: 9
Training loss: 2.399808709150614
Validation loss: 2.610936571323086

Epoch: 6| Step: 10
Training loss: 2.167374923071554
Validation loss: 2.6012635541346154

Epoch: 6| Step: 11
Training loss: 1.726950899514018
Validation loss: 2.5931759241117334

Epoch: 6| Step: 12
Training loss: 1.634226574549411
Validation loss: 2.606774532431088

Epoch: 6| Step: 13
Training loss: 2.8963194148702076
Validation loss: 2.603895605603259

Epoch: 288| Step: 0
Training loss: 1.9952679921132306
Validation loss: 2.5836537813560834

Epoch: 6| Step: 1
Training loss: 2.35132828366666
Validation loss: 2.556470390774069

Epoch: 6| Step: 2
Training loss: 1.3672428664849487
Validation loss: 2.515313881537093

Epoch: 6| Step: 3
Training loss: 2.7987087780675526
Validation loss: 2.5251978195555256

Epoch: 6| Step: 4
Training loss: 1.9803421010108664
Validation loss: 2.5436745097388056

Epoch: 6| Step: 5
Training loss: 2.1415107175499606
Validation loss: 2.5472120284367987

Epoch: 6| Step: 6
Training loss: 1.5274387339840603
Validation loss: 2.5685690055747643

Epoch: 6| Step: 7
Training loss: 2.3238843148306287
Validation loss: 2.539032170041205

Epoch: 6| Step: 8
Training loss: 2.4090744880064268
Validation loss: 2.589076876557239

Epoch: 6| Step: 9
Training loss: 1.5143063501406893
Validation loss: 2.570339059740799

Epoch: 6| Step: 10
Training loss: 2.137248697064295
Validation loss: 2.5666827822670597

Epoch: 6| Step: 11
Training loss: 2.227617087663791
Validation loss: 2.55321822072131

Epoch: 6| Step: 12
Training loss: 1.8191106536997832
Validation loss: 2.601936786903652

Epoch: 6| Step: 13
Training loss: 2.3626550774917936
Validation loss: 2.598508888987422

Epoch: 289| Step: 0
Training loss: 2.247932437797801
Validation loss: 2.565732645927576

Epoch: 6| Step: 1
Training loss: 2.651220429294681
Validation loss: 2.5540424119638634

Epoch: 6| Step: 2
Training loss: 2.1210784630549497
Validation loss: 2.51746749536213

Epoch: 6| Step: 3
Training loss: 1.792059241763165
Validation loss: 2.516428098570909

Epoch: 6| Step: 4
Training loss: 1.8745161067894394
Validation loss: 2.5238913963427265

Epoch: 6| Step: 5
Training loss: 2.297081555271781
Validation loss: 2.5311738304953955

Epoch: 6| Step: 6
Training loss: 2.286465678858562
Validation loss: 2.565219227232167

Epoch: 6| Step: 7
Training loss: 2.1923709588696814
Validation loss: 2.6176904603100284

Epoch: 6| Step: 8
Training loss: 1.8194630486828967
Validation loss: 2.6077974922810387

Epoch: 6| Step: 9
Training loss: 1.8296718736823383
Validation loss: 2.6163655371017103

Epoch: 6| Step: 10
Training loss: 2.1758031655651213
Validation loss: 2.6034022671669748

Epoch: 6| Step: 11
Training loss: 1.8466184253909983
Validation loss: 2.5671522042496298

Epoch: 6| Step: 12
Training loss: 2.5151247273453468
Validation loss: 2.5549764362848646

Epoch: 6| Step: 13
Training loss: 1.5770730015337744
Validation loss: 2.5057843366306063

Epoch: 290| Step: 0
Training loss: 2.04578120002697
Validation loss: 2.4956867998653713

Epoch: 6| Step: 1
Training loss: 1.8237700798911112
Validation loss: 2.4947251302385043

Epoch: 6| Step: 2
Training loss: 2.4665262371332677
Validation loss: 2.497892126917834

Epoch: 6| Step: 3
Training loss: 2.4604947130797217
Validation loss: 2.508866386761297

Epoch: 6| Step: 4
Training loss: 1.6864857628020924
Validation loss: 2.496187768477855

Epoch: 6| Step: 5
Training loss: 2.340650619957415
Validation loss: 2.5340072857396483

Epoch: 6| Step: 6
Training loss: 2.27202927014476
Validation loss: 2.538458195690067

Epoch: 6| Step: 7
Training loss: 2.0695990718731827
Validation loss: 2.5754158813774897

Epoch: 6| Step: 8
Training loss: 2.3669612763834826
Validation loss: 2.714259374282782

Epoch: 6| Step: 9
Training loss: 1.9419200071601777
Validation loss: 2.764396092720124

Epoch: 6| Step: 10
Training loss: 1.8142738212629035
Validation loss: 2.79982777871956

Epoch: 6| Step: 11
Training loss: 2.3237585301317054
Validation loss: 2.7423404748747204

Epoch: 6| Step: 12
Training loss: 2.3627624446681224
Validation loss: 2.6919108131470306

Epoch: 6| Step: 13
Training loss: 2.105434551916726
Validation loss: 2.6197812944109575

Epoch: 291| Step: 0
Training loss: 1.6065514990313623
Validation loss: 2.5324955768050756

Epoch: 6| Step: 1
Training loss: 1.5570590080393876
Validation loss: 2.511419180511203

Epoch: 6| Step: 2
Training loss: 2.118777195578713
Validation loss: 2.5164837368634743

Epoch: 6| Step: 3
Training loss: 2.4214075437228346
Validation loss: 2.519093903821925

Epoch: 6| Step: 4
Training loss: 2.222977385426069
Validation loss: 2.5143681263163957

Epoch: 6| Step: 5
Training loss: 1.7728481573845645
Validation loss: 2.5227245823645092

Epoch: 6| Step: 6
Training loss: 3.091826177905201
Validation loss: 2.526971851561949

Epoch: 6| Step: 7
Training loss: 1.7416813547102166
Validation loss: 2.503591500831452

Epoch: 6| Step: 8
Training loss: 2.277648591303924
Validation loss: 2.527005203896868

Epoch: 6| Step: 9
Training loss: 2.1485762117863083
Validation loss: 2.577175451023637

Epoch: 6| Step: 10
Training loss: 2.491002485705115
Validation loss: 2.6235460917400357

Epoch: 6| Step: 11
Training loss: 2.916998072370194
Validation loss: 2.6471814953567754

Epoch: 6| Step: 12
Training loss: 2.347024283505759
Validation loss: 2.6369786716023467

Epoch: 6| Step: 13
Training loss: 1.758136431198847
Validation loss: 2.692748098368787

Epoch: 292| Step: 0
Training loss: 1.5002925905330107
Validation loss: 2.6575914025221032

Epoch: 6| Step: 1
Training loss: 2.5238165319779013
Validation loss: 2.6310159079228934

Epoch: 6| Step: 2
Training loss: 1.788483838446384
Validation loss: 2.5954460971658135

Epoch: 6| Step: 3
Training loss: 1.8357341247894543
Validation loss: 2.5590102616263755

Epoch: 6| Step: 4
Training loss: 2.347867781619016
Validation loss: 2.4845050961641846

Epoch: 6| Step: 5
Training loss: 2.3420862014373807
Validation loss: 2.4796921362830546

Epoch: 6| Step: 6
Training loss: 1.6772906568179322
Validation loss: 2.4617589154927035

Epoch: 6| Step: 7
Training loss: 2.0226780707168377
Validation loss: 2.473341563121988

Epoch: 6| Step: 8
Training loss: 2.169163939798785
Validation loss: 2.4855652523045837

Epoch: 6| Step: 9
Training loss: 2.1293031095120614
Validation loss: 2.4917831969893656

Epoch: 6| Step: 10
Training loss: 2.343179455295048
Validation loss: 2.4924628445461887

Epoch: 6| Step: 11
Training loss: 2.023989451181115
Validation loss: 2.5095009353726145

Epoch: 6| Step: 12
Training loss: 2.7119879102971947
Validation loss: 2.5023232790970806

Epoch: 6| Step: 13
Training loss: 2.5329617022764035
Validation loss: 2.5230582378387707

Epoch: 293| Step: 0
Training loss: 1.500865448193859
Validation loss: 2.545281596315232

Epoch: 6| Step: 1
Training loss: 1.6106235882801387
Validation loss: 2.5833082095329365

Epoch: 6| Step: 2
Training loss: 1.4827846641058242
Validation loss: 2.5882549523666953

Epoch: 6| Step: 3
Training loss: 1.7326983346299336
Validation loss: 2.614019505370863

Epoch: 6| Step: 4
Training loss: 2.7186017927792654
Validation loss: 2.5905958170180834

Epoch: 6| Step: 5
Training loss: 2.7518689133894974
Validation loss: 2.5666736945349187

Epoch: 6| Step: 6
Training loss: 2.218375913219465
Validation loss: 2.55581966592596

Epoch: 6| Step: 7
Training loss: 1.5918567107954371
Validation loss: 2.52743380748229

Epoch: 6| Step: 8
Training loss: 2.40541101667026
Validation loss: 2.5184230683768365

Epoch: 6| Step: 9
Training loss: 2.0985262467854113
Validation loss: 2.5318475104385314

Epoch: 6| Step: 10
Training loss: 2.3877702010878528
Validation loss: 2.530049294354642

Epoch: 6| Step: 11
Training loss: 2.204222926363494
Validation loss: 2.5344148795004156

Epoch: 6| Step: 12
Training loss: 2.4373009429249923
Validation loss: 2.5550539801830747

Epoch: 6| Step: 13
Training loss: 2.07678144806186
Validation loss: 2.5931521419913808

Epoch: 294| Step: 0
Training loss: 2.2624978418497994
Validation loss: 2.6205894564968704

Epoch: 6| Step: 1
Training loss: 2.204731132567607
Validation loss: 2.6367128273226306

Epoch: 6| Step: 2
Training loss: 2.203078465612828
Validation loss: 2.6331827297683734

Epoch: 6| Step: 3
Training loss: 2.0649094812537143
Validation loss: 2.6309841761715513

Epoch: 6| Step: 4
Training loss: 2.511509152413395
Validation loss: 2.6303716527006937

Epoch: 6| Step: 5
Training loss: 1.8236709850573685
Validation loss: 2.651101946691892

Epoch: 6| Step: 6
Training loss: 2.3611902996571597
Validation loss: 2.6210610188213797

Epoch: 6| Step: 7
Training loss: 1.6359393829364015
Validation loss: 2.553553649454281

Epoch: 6| Step: 8
Training loss: 2.065733253770298
Validation loss: 2.530902823041727

Epoch: 6| Step: 9
Training loss: 1.2145143902657547
Validation loss: 2.5081780346503315

Epoch: 6| Step: 10
Training loss: 1.8628048717673442
Validation loss: 2.5183230004223804

Epoch: 6| Step: 11
Training loss: 1.9115232479149544
Validation loss: 2.5102847896987024

Epoch: 6| Step: 12
Training loss: 2.4834681361262314
Validation loss: 2.5124911262266933

Epoch: 6| Step: 13
Training loss: 2.3257840054988717
Validation loss: 2.522049560556033

Epoch: 295| Step: 0
Training loss: 2.411550653281976
Validation loss: 2.5126624502421757

Epoch: 6| Step: 1
Training loss: 2.5309540375417576
Validation loss: 2.5388832224618723

Epoch: 6| Step: 2
Training loss: 2.183082042919075
Validation loss: 2.545682819202156

Epoch: 6| Step: 3
Training loss: 1.8034108588194782
Validation loss: 2.5923044243874465

Epoch: 6| Step: 4
Training loss: 1.9762582657874608
Validation loss: 2.6443233586709107

Epoch: 6| Step: 5
Training loss: 2.511901943710561
Validation loss: 2.684477903372132

Epoch: 6| Step: 6
Training loss: 1.7918305950430686
Validation loss: 2.6649548927435656

Epoch: 6| Step: 7
Training loss: 2.2549181274979255
Validation loss: 2.650270066205148

Epoch: 6| Step: 8
Training loss: 2.257581441599417
Validation loss: 2.612799660442359

Epoch: 6| Step: 9
Training loss: 2.8685718489371412
Validation loss: 2.5584363427894776

Epoch: 6| Step: 10
Training loss: 1.8422653557112454
Validation loss: 2.538386328234374

Epoch: 6| Step: 11
Training loss: 2.0783468715998694
Validation loss: 2.5026190549240224

Epoch: 6| Step: 12
Training loss: 1.485433823253251
Validation loss: 2.5076030988406655

Epoch: 6| Step: 13
Training loss: 2.290381770731832
Validation loss: 2.4554648852138383

Epoch: 296| Step: 0
Training loss: 2.721351080836443
Validation loss: 2.481151128507799

Epoch: 6| Step: 1
Training loss: 2.7829494641808226
Validation loss: 2.464222857527268

Epoch: 6| Step: 2
Training loss: 2.134003359161851
Validation loss: 2.4689898314052243

Epoch: 6| Step: 3
Training loss: 2.019592402286786
Validation loss: 2.5017413432619326

Epoch: 6| Step: 4
Training loss: 1.694573729260951
Validation loss: 2.5198705794641

Epoch: 6| Step: 5
Training loss: 2.428999824966795
Validation loss: 2.570129929139001

Epoch: 6| Step: 6
Training loss: 1.8634179662934192
Validation loss: 2.5567908382559175

Epoch: 6| Step: 7
Training loss: 2.7013073581747147
Validation loss: 2.5944545049515413

Epoch: 6| Step: 8
Training loss: 1.7310586789177793
Validation loss: 2.608590729620199

Epoch: 6| Step: 9
Training loss: 2.088787403696359
Validation loss: 2.606846099793313

Epoch: 6| Step: 10
Training loss: 2.0662935222604504
Validation loss: 2.510483346478272

Epoch: 6| Step: 11
Training loss: 2.4305037816906396
Validation loss: 2.5060454706083917

Epoch: 6| Step: 12
Training loss: 1.7106274188815191
Validation loss: 2.484930220327167

Epoch: 6| Step: 13
Training loss: 1.6358923817472877
Validation loss: 2.4950806378040964

Epoch: 297| Step: 0
Training loss: 2.3924734910156062
Validation loss: 2.5199668803384956

Epoch: 6| Step: 1
Training loss: 2.0431579152160535
Validation loss: 2.51089244043274

Epoch: 6| Step: 2
Training loss: 2.594341256646612
Validation loss: 2.487372032145481

Epoch: 6| Step: 3
Training loss: 1.6596445529202823
Validation loss: 2.507609017456351

Epoch: 6| Step: 4
Training loss: 1.8326122281835673
Validation loss: 2.5898550118670896

Epoch: 6| Step: 5
Training loss: 1.5208751550785504
Validation loss: 2.626230632596183

Epoch: 6| Step: 6
Training loss: 2.4419864544941903
Validation loss: 2.6589217568131196

Epoch: 6| Step: 7
Training loss: 1.8179784390101579
Validation loss: 2.66432121564398

Epoch: 6| Step: 8
Training loss: 1.7767585210095322
Validation loss: 2.6510987840855993

Epoch: 6| Step: 9
Training loss: 1.708095053205445
Validation loss: 2.6309524440374945

Epoch: 6| Step: 10
Training loss: 2.3372105220309085
Validation loss: 2.5873054197804755

Epoch: 6| Step: 11
Training loss: 1.9301209986020007
Validation loss: 2.568491823288968

Epoch: 6| Step: 12
Training loss: 2.372551710170221
Validation loss: 2.5596969439267463

Epoch: 6| Step: 13
Training loss: 2.211014062209595
Validation loss: 2.535071169263618

Epoch: 298| Step: 0
Training loss: 2.2944137984787973
Validation loss: 2.538700019197933

Epoch: 6| Step: 1
Training loss: 1.8770901156637068
Validation loss: 2.5262137180738615

Epoch: 6| Step: 2
Training loss: 2.17202044761545
Validation loss: 2.590369047091593

Epoch: 6| Step: 3
Training loss: 2.3685617014744214
Validation loss: 2.58079769429756

Epoch: 6| Step: 4
Training loss: 1.6726925000998052
Validation loss: 2.5608592634525813

Epoch: 6| Step: 5
Training loss: 2.238083542751686
Validation loss: 2.564491289120653

Epoch: 6| Step: 6
Training loss: 2.6668419084983452
Validation loss: 2.555672139869396

Epoch: 6| Step: 7
Training loss: 1.4608056319998297
Validation loss: 2.6175296389004767

Epoch: 6| Step: 8
Training loss: 1.5688598898283919
Validation loss: 2.635485370529525

Epoch: 6| Step: 9
Training loss: 1.7353468225658044
Validation loss: 2.642808632055625

Epoch: 6| Step: 10
Training loss: 2.2686530562777336
Validation loss: 2.603286859029936

Epoch: 6| Step: 11
Training loss: 2.3709622241373087
Validation loss: 2.635657149991657

Epoch: 6| Step: 12
Training loss: 1.9956193871662598
Validation loss: 2.622303175338892

Epoch: 6| Step: 13
Training loss: 1.2852918559131654
Validation loss: 2.578100138843001

Epoch: 299| Step: 0
Training loss: 2.0709432540774473
Validation loss: 2.5753862727042764

Epoch: 6| Step: 1
Training loss: 1.9766257656662598
Validation loss: 2.5852577722143213

Epoch: 6| Step: 2
Training loss: 1.9838965131934265
Validation loss: 2.5549991118198747

Epoch: 6| Step: 3
Training loss: 2.047939460552517
Validation loss: 2.556342674633585

Epoch: 6| Step: 4
Training loss: 1.4576117864961322
Validation loss: 2.5423663744825227

Epoch: 6| Step: 5
Training loss: 1.7854268142370278
Validation loss: 2.54430924812504

Epoch: 6| Step: 6
Training loss: 2.2402439532952387
Validation loss: 2.5820187997830426

Epoch: 6| Step: 7
Training loss: 2.430621393916623
Validation loss: 2.615784757863309

Epoch: 6| Step: 8
Training loss: 2.1560845795356287
Validation loss: 2.6263737489867003

Epoch: 6| Step: 9
Training loss: 1.1606858197588747
Validation loss: 2.587772252476531

Epoch: 6| Step: 10
Training loss: 2.104905883062303
Validation loss: 2.571221698091531

Epoch: 6| Step: 11
Training loss: 2.828402848057263
Validation loss: 2.489871759878542

Epoch: 6| Step: 12
Training loss: 1.685817798398986
Validation loss: 2.524905790327734

Epoch: 6| Step: 13
Training loss: 2.191407120376387
Validation loss: 2.5071681017685705

Epoch: 300| Step: 0
Training loss: 2.1430548917261585
Validation loss: 2.4879356795068803

Epoch: 6| Step: 1
Training loss: 1.6409053018084785
Validation loss: 2.496616967355509

Epoch: 6| Step: 2
Training loss: 2.012828927970265
Validation loss: 2.509574279219916

Epoch: 6| Step: 3
Training loss: 2.3160823190254263
Validation loss: 2.5266054186363456

Epoch: 6| Step: 4
Training loss: 1.8284965854787096
Validation loss: 2.5512247834243604

Epoch: 6| Step: 5
Training loss: 1.217599178715954
Validation loss: 2.521408146878797

Epoch: 6| Step: 6
Training loss: 2.0552747924185404
Validation loss: 2.5082462050639474

Epoch: 6| Step: 7
Training loss: 1.8686802216327532
Validation loss: 2.533692715798206

Epoch: 6| Step: 8
Training loss: 2.503623148941894
Validation loss: 2.538377812330448

Epoch: 6| Step: 9
Training loss: 2.2315772620656906
Validation loss: 2.5454320115737192

Epoch: 6| Step: 10
Training loss: 1.4474753203454052
Validation loss: 2.5395916822597178

Epoch: 6| Step: 11
Training loss: 1.961737602504867
Validation loss: 2.5882162635383232

Epoch: 6| Step: 12
Training loss: 2.4522333164633423
Validation loss: 2.5863422795373006

Epoch: 6| Step: 13
Training loss: 2.1779638332029836
Validation loss: 2.5836703378041586

Epoch: 301| Step: 0
Training loss: 2.072187042903605
Validation loss: 2.615245649082231

Epoch: 6| Step: 1
Training loss: 1.6320625298526026
Validation loss: 2.543615552893645

Epoch: 6| Step: 2
Training loss: 1.5604811023128922
Validation loss: 2.5843997312974576

Epoch: 6| Step: 3
Training loss: 2.115805762723443
Validation loss: 2.5921872344964436

Epoch: 6| Step: 4
Training loss: 2.0187523998328905
Validation loss: 2.6186035804208165

Epoch: 6| Step: 5
Training loss: 2.1312717559688457
Validation loss: 2.6655583065107633

Epoch: 6| Step: 6
Training loss: 2.1887268985420194
Validation loss: 2.618377384695043

Epoch: 6| Step: 7
Training loss: 2.3005939919087615
Validation loss: 2.5790000817564014

Epoch: 6| Step: 8
Training loss: 2.4183937894738268
Validation loss: 2.603727461335342

Epoch: 6| Step: 9
Training loss: 1.6574100534420728
Validation loss: 2.5716382736209367

Epoch: 6| Step: 10
Training loss: 1.7209396286371634
Validation loss: 2.5073898767419553

Epoch: 6| Step: 11
Training loss: 1.8721194074279384
Validation loss: 2.501682843616221

Epoch: 6| Step: 12
Training loss: 1.7555664632890282
Validation loss: 2.4890896348897

Epoch: 6| Step: 13
Training loss: 2.482446077650506
Validation loss: 2.4971482383236285

Epoch: 302| Step: 0
Training loss: 1.5760257468855614
Validation loss: 2.478853676109513

Epoch: 6| Step: 1
Training loss: 1.3006544538221423
Validation loss: 2.5124152499782886

Epoch: 6| Step: 2
Training loss: 1.638710867198486
Validation loss: 2.5590773419072343

Epoch: 6| Step: 3
Training loss: 1.5923779135097276
Validation loss: 2.584424285849232

Epoch: 6| Step: 4
Training loss: 1.2701575040394593
Validation loss: 2.587514068270415

Epoch: 6| Step: 5
Training loss: 2.2334934442926495
Validation loss: 2.6251085728186943

Epoch: 6| Step: 6
Training loss: 2.294558440304827
Validation loss: 2.5921086399560176

Epoch: 6| Step: 7
Training loss: 1.4431318173385845
Validation loss: 2.6328586381893646

Epoch: 6| Step: 8
Training loss: 2.0660690869045966
Validation loss: 2.5856556964540083

Epoch: 6| Step: 9
Training loss: 2.340323524770035
Validation loss: 2.561911461086668

Epoch: 6| Step: 10
Training loss: 2.1342038936364625
Validation loss: 2.5166911675563695

Epoch: 6| Step: 11
Training loss: 3.212020060389905
Validation loss: 2.5005106563370285

Epoch: 6| Step: 12
Training loss: 2.168208038596115
Validation loss: 2.4869682484864777

Epoch: 6| Step: 13
Training loss: 2.0414790891257963
Validation loss: 2.488626477113803

Epoch: 303| Step: 0
Training loss: 1.893204560747422
Validation loss: 2.514738191157141

Epoch: 6| Step: 1
Training loss: 1.834148818048652
Validation loss: 2.505033194803588

Epoch: 6| Step: 2
Training loss: 1.5178019826146476
Validation loss: 2.5274091394721903

Epoch: 6| Step: 3
Training loss: 1.245337086127329
Validation loss: 2.545925189503114

Epoch: 6| Step: 4
Training loss: 2.011752526453403
Validation loss: 2.556875802363771

Epoch: 6| Step: 5
Training loss: 2.7055548182474953
Validation loss: 2.565990211057834

Epoch: 6| Step: 6
Training loss: 2.518080182617565
Validation loss: 2.5683947735995307

Epoch: 6| Step: 7
Training loss: 1.8939549149541945
Validation loss: 2.5608566411061764

Epoch: 6| Step: 8
Training loss: 1.6628155401697096
Validation loss: 2.538813793032634

Epoch: 6| Step: 9
Training loss: 1.8616853993542581
Validation loss: 2.5254944880527406

Epoch: 6| Step: 10
Training loss: 2.289969202859009
Validation loss: 2.50822050869521

Epoch: 6| Step: 11
Training loss: 1.40004297088344
Validation loss: 2.4814624788285276

Epoch: 6| Step: 12
Training loss: 2.6656393714866193
Validation loss: 2.5038650993341993

Epoch: 6| Step: 13
Training loss: 1.9308054538909782
Validation loss: 2.5411155811992

Epoch: 304| Step: 0
Training loss: 1.5617272564273244
Validation loss: 2.518423904626496

Epoch: 6| Step: 1
Training loss: 1.191594743670049
Validation loss: 2.5495465236931905

Epoch: 6| Step: 2
Training loss: 1.5680198064302453
Validation loss: 2.512290482143679

Epoch: 6| Step: 3
Training loss: 2.1104991036896474
Validation loss: 2.5377891595007713

Epoch: 6| Step: 4
Training loss: 1.9535089344321228
Validation loss: 2.5333580532457365

Epoch: 6| Step: 5
Training loss: 2.5679765191118786
Validation loss: 2.5333860670005377

Epoch: 6| Step: 6
Training loss: 1.8947026440674102
Validation loss: 2.520501128026136

Epoch: 6| Step: 7
Training loss: 3.1092167339589674
Validation loss: 2.5162399361780743

Epoch: 6| Step: 8
Training loss: 1.4080551429484203
Validation loss: 2.5282630565216526

Epoch: 6| Step: 9
Training loss: 1.6384793737962382
Validation loss: 2.556001813136708

Epoch: 6| Step: 10
Training loss: 2.1263249698364204
Validation loss: 2.5446129487207285

Epoch: 6| Step: 11
Training loss: 2.43643409702815
Validation loss: 2.559326144704273

Epoch: 6| Step: 12
Training loss: 1.9298093811340065
Validation loss: 2.5694975793058443

Epoch: 6| Step: 13
Training loss: 1.4865494712401386
Validation loss: 2.6018676120672413

Epoch: 305| Step: 0
Training loss: 2.7139545988025615
Validation loss: 2.5985032462287627

Epoch: 6| Step: 1
Training loss: 1.8743351075346464
Validation loss: 2.6543394061478223

Epoch: 6| Step: 2
Training loss: 2.366512794148936
Validation loss: 2.6649088778254377

Epoch: 6| Step: 3
Training loss: 2.2681191231931863
Validation loss: 2.648383898647432

Epoch: 6| Step: 4
Training loss: 1.6061851963374185
Validation loss: 2.5812292810921673

Epoch: 6| Step: 5
Training loss: 1.6930698732489233
Validation loss: 2.5324708168831216

Epoch: 6| Step: 6
Training loss: 2.4774158824571377
Validation loss: 2.503437095486187

Epoch: 6| Step: 7
Training loss: 1.9356800268356036
Validation loss: 2.4984836271130098

Epoch: 6| Step: 8
Training loss: 1.944003051280543
Validation loss: 2.4874910370427226

Epoch: 6| Step: 9
Training loss: 2.1986540752086583
Validation loss: 2.4895576784309736

Epoch: 6| Step: 10
Training loss: 2.2537404863830615
Validation loss: 2.4921446570338235

Epoch: 6| Step: 11
Training loss: 1.1579003284002205
Validation loss: 2.498174350439718

Epoch: 6| Step: 12
Training loss: 1.7653482946115313
Validation loss: 2.5211206435313867

Epoch: 6| Step: 13
Training loss: 1.9454693099096092
Validation loss: 2.6217549565947613

Epoch: 306| Step: 0
Training loss: 1.9984317233648614
Validation loss: 2.6562334396743656

Epoch: 6| Step: 1
Training loss: 1.9748811468746685
Validation loss: 2.741733654753687

Epoch: 6| Step: 2
Training loss: 1.7662851905421766
Validation loss: 2.6855687809831

Epoch: 6| Step: 3
Training loss: 2.519012255776255
Validation loss: 2.6688871874006685

Epoch: 6| Step: 4
Training loss: 2.239978087181812
Validation loss: 2.5101407217318563

Epoch: 6| Step: 5
Training loss: 2.0789811514715155
Validation loss: 2.4839495648486856

Epoch: 6| Step: 6
Training loss: 1.7869656864622516
Validation loss: 2.485031401092344

Epoch: 6| Step: 7
Training loss: 2.414651150830343
Validation loss: 2.495595851504736

Epoch: 6| Step: 8
Training loss: 2.318339012718603
Validation loss: 2.4926265381654513

Epoch: 6| Step: 9
Training loss: 2.1541015315092595
Validation loss: 2.4806764851086807

Epoch: 6| Step: 10
Training loss: 1.7812600386487272
Validation loss: 2.4902094501918484

Epoch: 6| Step: 11
Training loss: 1.7824314281868894
Validation loss: 2.4990059942799707

Epoch: 6| Step: 12
Training loss: 1.523232001113924
Validation loss: 2.4951613808616826

Epoch: 6| Step: 13
Training loss: 2.787631739082126
Validation loss: 2.584788655976

Epoch: 307| Step: 0
Training loss: 2.2265051047975284
Validation loss: 2.623028135670644

Epoch: 6| Step: 1
Training loss: 1.5733095482601656
Validation loss: 2.667596935392656

Epoch: 6| Step: 2
Training loss: 1.9218325726547811
Validation loss: 2.7004066573125596

Epoch: 6| Step: 3
Training loss: 1.774227554521169
Validation loss: 2.690209095260389

Epoch: 6| Step: 4
Training loss: 2.36470147956637
Validation loss: 2.611615511578452

Epoch: 6| Step: 5
Training loss: 2.6046731583464178
Validation loss: 2.5904385596639696

Epoch: 6| Step: 6
Training loss: 1.7145172712068553
Validation loss: 2.559866334907543

Epoch: 6| Step: 7
Training loss: 1.5382775178305093
Validation loss: 2.559663800226988

Epoch: 6| Step: 8
Training loss: 1.8458455348705873
Validation loss: 2.538621193119236

Epoch: 6| Step: 9
Training loss: 1.4544251890747886
Validation loss: 2.5429286924333367

Epoch: 6| Step: 10
Training loss: 2.1949302910790887
Validation loss: 2.5386367832209467

Epoch: 6| Step: 11
Training loss: 2.671753194609123
Validation loss: 2.5800928793559175

Epoch: 6| Step: 12
Training loss: 1.648497232376381
Validation loss: 2.616163389337015

Epoch: 6| Step: 13
Training loss: 2.102688512526972
Validation loss: 2.638442422230513

Epoch: 308| Step: 0
Training loss: 1.4291707757088152
Validation loss: 2.638271946203929

Epoch: 6| Step: 1
Training loss: 2.4204636922444496
Validation loss: 2.60125162369303

Epoch: 6| Step: 2
Training loss: 2.641036684346964
Validation loss: 2.594389212408663

Epoch: 6| Step: 3
Training loss: 1.3333876519264976
Validation loss: 2.5574035516465776

Epoch: 6| Step: 4
Training loss: 1.4446542426524067
Validation loss: 2.569688738702371

Epoch: 6| Step: 5
Training loss: 1.4318432007567534
Validation loss: 2.522962527458084

Epoch: 6| Step: 6
Training loss: 2.079987343969722
Validation loss: 2.5043852333575045

Epoch: 6| Step: 7
Training loss: 2.1445149071909726
Validation loss: 2.5185380343216597

Epoch: 6| Step: 8
Training loss: 1.8340730980810482
Validation loss: 2.4928376277597457

Epoch: 6| Step: 9
Training loss: 2.2527728478811153
Validation loss: 2.498178820074432

Epoch: 6| Step: 10
Training loss: 2.633048570502961
Validation loss: 2.4839108431373034

Epoch: 6| Step: 11
Training loss: 1.87635118754238
Validation loss: 2.512049177157676

Epoch: 6| Step: 12
Training loss: 2.121115331381921
Validation loss: 2.5413099778667583

Epoch: 6| Step: 13
Training loss: 1.896320685601241
Validation loss: 2.633756821015078

Epoch: 309| Step: 0
Training loss: 2.0226837285997985
Validation loss: 2.6815196188501167

Epoch: 6| Step: 1
Training loss: 1.6527755569884752
Validation loss: 2.6273862044509313

Epoch: 6| Step: 2
Training loss: 1.4553518972210373
Validation loss: 2.561407538664434

Epoch: 6| Step: 3
Training loss: 1.9014254944594133
Validation loss: 2.483748270951546

Epoch: 6| Step: 4
Training loss: 2.0026442214141476
Validation loss: 2.473031271185982

Epoch: 6| Step: 5
Training loss: 2.2372977607583193
Validation loss: 2.4671944654969162

Epoch: 6| Step: 6
Training loss: 2.42788423304326
Validation loss: 2.4863905817674192

Epoch: 6| Step: 7
Training loss: 2.3954657120548846
Validation loss: 2.4753314868744773

Epoch: 6| Step: 8
Training loss: 1.721104136750355
Validation loss: 2.5023347204773745

Epoch: 6| Step: 9
Training loss: 2.3447818773410734
Validation loss: 2.54543416587404

Epoch: 6| Step: 10
Training loss: 2.6122650770945532
Validation loss: 2.548153655747422

Epoch: 6| Step: 11
Training loss: 1.857251790278824
Validation loss: 2.6033419460279528

Epoch: 6| Step: 12
Training loss: 1.6279938335629962
Validation loss: 2.631629247812097

Epoch: 6| Step: 13
Training loss: 1.792922806826441
Validation loss: 2.645688921574266

Epoch: 310| Step: 0
Training loss: 1.750636121393823
Validation loss: 2.631668294970939

Epoch: 6| Step: 1
Training loss: 2.39023761477861
Validation loss: 2.609633884036757

Epoch: 6| Step: 2
Training loss: 2.37537491499466
Validation loss: 2.545042755777065

Epoch: 6| Step: 3
Training loss: 1.752128668828676
Validation loss: 2.506180958419199

Epoch: 6| Step: 4
Training loss: 1.9675295240811772
Validation loss: 2.491449436129646

Epoch: 6| Step: 5
Training loss: 1.7283791353464952
Validation loss: 2.4921159405135858

Epoch: 6| Step: 6
Training loss: 2.2322413787897473
Validation loss: 2.50727500186248

Epoch: 6| Step: 7
Training loss: 2.640383827888559
Validation loss: 2.4851600158464606

Epoch: 6| Step: 8
Training loss: 2.173616877159891
Validation loss: 2.511812492112363

Epoch: 6| Step: 9
Training loss: 1.3292641634843891
Validation loss: 2.522052396564279

Epoch: 6| Step: 10
Training loss: 2.312595468560919
Validation loss: 2.5299966951079766

Epoch: 6| Step: 11
Training loss: 1.7345835242483985
Validation loss: 2.5638854615599693

Epoch: 6| Step: 12
Training loss: 2.027787176601047
Validation loss: 2.5908055272107644

Epoch: 6| Step: 13
Training loss: 1.095846455765009
Validation loss: 2.589529026983236

Epoch: 311| Step: 0
Training loss: 1.9872399021995415
Validation loss: 2.5742586834154038

Epoch: 6| Step: 1
Training loss: 1.4168902202069729
Validation loss: 2.556654613156443

Epoch: 6| Step: 2
Training loss: 1.2951628631927352
Validation loss: 2.519738382504396

Epoch: 6| Step: 3
Training loss: 2.5054625912844286
Validation loss: 2.5295601686880955

Epoch: 6| Step: 4
Training loss: 1.8343491846506863
Validation loss: 2.50201115775422

Epoch: 6| Step: 5
Training loss: 2.3049584181007656
Validation loss: 2.5586870715179306

Epoch: 6| Step: 6
Training loss: 2.2737861706759666
Validation loss: 2.5474972111141074

Epoch: 6| Step: 7
Training loss: 2.0198212937347373
Validation loss: 2.547132716957323

Epoch: 6| Step: 8
Training loss: 1.7493581957348996
Validation loss: 2.5874577075002043

Epoch: 6| Step: 9
Training loss: 1.511484527185651
Validation loss: 2.5932720080931526

Epoch: 6| Step: 10
Training loss: 2.0360461612257446
Validation loss: 2.524284126287561

Epoch: 6| Step: 11
Training loss: 1.892112084042677
Validation loss: 2.52032584344304

Epoch: 6| Step: 12
Training loss: 1.8032674115037286
Validation loss: 2.47530489498165

Epoch: 6| Step: 13
Training loss: 2.504476354388754
Validation loss: 2.46973029523904

Epoch: 312| Step: 0
Training loss: 2.461420502266334
Validation loss: 2.4789805035190566

Epoch: 6| Step: 1
Training loss: 2.06180132967582
Validation loss: 2.47506823622276

Epoch: 6| Step: 2
Training loss: 2.190526231397532
Validation loss: 2.50783657644723

Epoch: 6| Step: 3
Training loss: 1.733247957816875
Validation loss: 2.5354987698261575

Epoch: 6| Step: 4
Training loss: 2.1750341259263246
Validation loss: 2.6215532016714302

Epoch: 6| Step: 5
Training loss: 1.9241022369757177
Validation loss: 2.6671508011828666

Epoch: 6| Step: 6
Training loss: 1.7580632687880626
Validation loss: 2.676898079089134

Epoch: 6| Step: 7
Training loss: 1.818176391441743
Validation loss: 2.7000393611487827

Epoch: 6| Step: 8
Training loss: 1.8973229672722227
Validation loss: 2.6699910800227635

Epoch: 6| Step: 9
Training loss: 1.7914026938268781
Validation loss: 2.5724361192280667

Epoch: 6| Step: 10
Training loss: 1.7091809317769868
Validation loss: 2.5553189351813836

Epoch: 6| Step: 11
Training loss: 2.1250420734503885
Validation loss: 2.5193897769450144

Epoch: 6| Step: 12
Training loss: 1.649677840484764
Validation loss: 2.5191961967595824

Epoch: 6| Step: 13
Training loss: 2.9958386169585074
Validation loss: 2.5132297620083386

Epoch: 313| Step: 0
Training loss: 1.8171352441282076
Validation loss: 2.5256766511084483

Epoch: 6| Step: 1
Training loss: 1.9895225502302696
Validation loss: 2.5233882903191267

Epoch: 6| Step: 2
Training loss: 2.261533634074841
Validation loss: 2.525057309195915

Epoch: 6| Step: 3
Training loss: 3.1200788277669353
Validation loss: 2.507446927909534

Epoch: 6| Step: 4
Training loss: 1.5710752542052913
Validation loss: 2.532226295731081

Epoch: 6| Step: 5
Training loss: 1.5621000159427532
Validation loss: 2.514530069966475

Epoch: 6| Step: 6
Training loss: 1.9586720545681433
Validation loss: 2.559005168422117

Epoch: 6| Step: 7
Training loss: 2.1017444631086835
Validation loss: 2.6008241080972327

Epoch: 6| Step: 8
Training loss: 1.8597151501253393
Validation loss: 2.5595138720174786

Epoch: 6| Step: 9
Training loss: 1.8731872060512758
Validation loss: 2.6031159430167308

Epoch: 6| Step: 10
Training loss: 2.0482462010217426
Validation loss: 2.620740886648734

Epoch: 6| Step: 11
Training loss: 1.7704016290165043
Validation loss: 2.639868708847504

Epoch: 6| Step: 12
Training loss: 2.045518381875861
Validation loss: 2.6200531866290375

Epoch: 6| Step: 13
Training loss: 1.8238034806963033
Validation loss: 2.57288231356978

Epoch: 314| Step: 0
Training loss: 1.626948215802355
Validation loss: 2.5704715915285714

Epoch: 6| Step: 1
Training loss: 1.89141431993467
Validation loss: 2.5153038499130256

Epoch: 6| Step: 2
Training loss: 2.277524440395563
Validation loss: 2.498490577246885

Epoch: 6| Step: 3
Training loss: 1.3102486693257775
Validation loss: 2.493446183719216

Epoch: 6| Step: 4
Training loss: 2.5562949999740034
Validation loss: 2.4744194859142077

Epoch: 6| Step: 5
Training loss: 2.460663310928282
Validation loss: 2.460293365627639

Epoch: 6| Step: 6
Training loss: 1.8960677061425986
Validation loss: 2.449900246879542

Epoch: 6| Step: 7
Training loss: 1.175643050984544
Validation loss: 2.4318072036002727

Epoch: 6| Step: 8
Training loss: 1.7574031098791174
Validation loss: 2.462657799481571

Epoch: 6| Step: 9
Training loss: 2.148367585865273
Validation loss: 2.485466347512557

Epoch: 6| Step: 10
Training loss: 1.973079341424194
Validation loss: 2.508287600694962

Epoch: 6| Step: 11
Training loss: 2.1321756718673828
Validation loss: 2.5702419097390146

Epoch: 6| Step: 12
Training loss: 2.353725414502248
Validation loss: 2.6228539004604126

Epoch: 6| Step: 13
Training loss: 1.3474959126058383
Validation loss: 2.6309312236200677

Epoch: 315| Step: 0
Training loss: 2.1646701221366036
Validation loss: 2.622692138135427

Epoch: 6| Step: 1
Training loss: 1.8912855523417997
Validation loss: 2.573560052550387

Epoch: 6| Step: 2
Training loss: 1.991501035413729
Validation loss: 2.5833527861652343

Epoch: 6| Step: 3
Training loss: 1.4019537678332064
Validation loss: 2.542858123326253

Epoch: 6| Step: 4
Training loss: 2.2860589746726028
Validation loss: 2.618068231832462

Epoch: 6| Step: 5
Training loss: 2.49089404176268
Validation loss: 2.6107703036109005

Epoch: 6| Step: 6
Training loss: 1.4554845050444332
Validation loss: 2.5499562072733406

Epoch: 6| Step: 7
Training loss: 1.308691402606382
Validation loss: 2.532672560832666

Epoch: 6| Step: 8
Training loss: 1.5330211750118352
Validation loss: 2.5486383243208564

Epoch: 6| Step: 9
Training loss: 1.7607932355762068
Validation loss: 2.53209944392604

Epoch: 6| Step: 10
Training loss: 2.0939526815669933
Validation loss: 2.539725912429551

Epoch: 6| Step: 11
Training loss: 2.2181803012208827
Validation loss: 2.4998032333505305

Epoch: 6| Step: 12
Training loss: 1.526228006940215
Validation loss: 2.543289406556662

Epoch: 6| Step: 13
Training loss: 2.451642505709093
Validation loss: 2.533558895292054

Epoch: 316| Step: 0
Training loss: 1.8702088495405154
Validation loss: 2.533361472634421

Epoch: 6| Step: 1
Training loss: 1.7899733977232413
Validation loss: 2.5638975348785453

Epoch: 6| Step: 2
Training loss: 1.3838283449787763
Validation loss: 2.5241661791225334

Epoch: 6| Step: 3
Training loss: 2.577550465693784
Validation loss: 2.559041239891259

Epoch: 6| Step: 4
Training loss: 2.0119988996377596
Validation loss: 2.6065534614735872

Epoch: 6| Step: 5
Training loss: 1.2340239013446885
Validation loss: 2.566523904875995

Epoch: 6| Step: 6
Training loss: 1.7753927065057586
Validation loss: 2.55548924611167

Epoch: 6| Step: 7
Training loss: 1.4234335605135524
Validation loss: 2.5601310324413964

Epoch: 6| Step: 8
Training loss: 2.082466466480287
Validation loss: 2.577265216532451

Epoch: 6| Step: 9
Training loss: 1.707391417193951
Validation loss: 2.55537485408697

Epoch: 6| Step: 10
Training loss: 2.6266107612637475
Validation loss: 2.552010988001552

Epoch: 6| Step: 11
Training loss: 1.6913497245805265
Validation loss: 2.544605952786414

Epoch: 6| Step: 12
Training loss: 2.1663312896955227
Validation loss: 2.555667731914478

Epoch: 6| Step: 13
Training loss: 2.1989686325701845
Validation loss: 2.594633312030883

Epoch: 317| Step: 0
Training loss: 2.399322048436653
Validation loss: 2.631117028616449

Epoch: 6| Step: 1
Training loss: 1.9141345574964865
Validation loss: 2.655975911080036

Epoch: 6| Step: 2
Training loss: 1.767115411207168
Validation loss: 2.6869598407694895

Epoch: 6| Step: 3
Training loss: 1.7304509078025228
Validation loss: 2.7163838726910674

Epoch: 6| Step: 4
Training loss: 1.480595565638587
Validation loss: 2.654709223253665

Epoch: 6| Step: 5
Training loss: 2.062709219753562
Validation loss: 2.5689919121925406

Epoch: 6| Step: 6
Training loss: 2.0185186625580083
Validation loss: 2.475838251441771

Epoch: 6| Step: 7
Training loss: 1.8483740156401587
Validation loss: 2.5022996815812553

Epoch: 6| Step: 8
Training loss: 2.2586271406916514
Validation loss: 2.440650159614145

Epoch: 6| Step: 9
Training loss: 2.033986991293089
Validation loss: 2.4321693591149116

Epoch: 6| Step: 10
Training loss: 2.313932439122782
Validation loss: 2.4538725829504506

Epoch: 6| Step: 11
Training loss: 1.6033083448359537
Validation loss: 2.4710049611953546

Epoch: 6| Step: 12
Training loss: 2.1217733457145505
Validation loss: 2.4503059144319366

Epoch: 6| Step: 13
Training loss: 1.7440283932518146
Validation loss: 2.4787779805214787

Epoch: 318| Step: 0
Training loss: 2.22143413821615
Validation loss: 2.4944266103287753

Epoch: 6| Step: 1
Training loss: 1.7741665454946285
Validation loss: 2.4811381880953114

Epoch: 6| Step: 2
Training loss: 1.6729138435666153
Validation loss: 2.492574026015442

Epoch: 6| Step: 3
Training loss: 1.7469965501782878
Validation loss: 2.5222146188053727

Epoch: 6| Step: 4
Training loss: 1.2658065854013827
Validation loss: 2.5565152488451184

Epoch: 6| Step: 5
Training loss: 2.015567039425253
Validation loss: 2.586244793446166

Epoch: 6| Step: 6
Training loss: 1.9760547935788502
Validation loss: 2.556136021019995

Epoch: 6| Step: 7
Training loss: 2.560053890674323
Validation loss: 2.5658505097875968

Epoch: 6| Step: 8
Training loss: 1.7007024491803948
Validation loss: 2.576881540385614

Epoch: 6| Step: 9
Training loss: 1.824327159331432
Validation loss: 2.5696851588952994

Epoch: 6| Step: 10
Training loss: 1.3724118062295645
Validation loss: 2.5849700839182645

Epoch: 6| Step: 11
Training loss: 2.4176453110615
Validation loss: 2.5706118454779383

Epoch: 6| Step: 12
Training loss: 2.3410999829672
Validation loss: 2.58012757024136

Epoch: 6| Step: 13
Training loss: 1.6989724868693183
Validation loss: 2.54104145886256

Epoch: 319| Step: 0
Training loss: 1.9833650196440042
Validation loss: 2.556247262245957

Epoch: 6| Step: 1
Training loss: 2.038048503040256
Validation loss: 2.5186787269422015

Epoch: 6| Step: 2
Training loss: 1.8691116697486212
Validation loss: 2.5394649558346

Epoch: 6| Step: 3
Training loss: 1.8614923298667745
Validation loss: 2.587665621974698

Epoch: 6| Step: 4
Training loss: 1.533641116032178
Validation loss: 2.646781125856674

Epoch: 6| Step: 5
Training loss: 1.9564182440709457
Validation loss: 2.651769741683643

Epoch: 6| Step: 6
Training loss: 1.8745155344370517
Validation loss: 2.603924951143786

Epoch: 6| Step: 7
Training loss: 2.0854285830202697
Validation loss: 2.58835550223406

Epoch: 6| Step: 8
Training loss: 2.7757929725732273
Validation loss: 2.5661165876188563

Epoch: 6| Step: 9
Training loss: 2.0082506228730566
Validation loss: 2.5397925946018027

Epoch: 6| Step: 10
Training loss: 2.00490100701833
Validation loss: 2.5251458588575133

Epoch: 6| Step: 11
Training loss: 2.1049654612120143
Validation loss: 2.5410370489845144

Epoch: 6| Step: 12
Training loss: 1.8994590616657074
Validation loss: 2.5480108400181134

Epoch: 6| Step: 13
Training loss: 1.3739292136869397
Validation loss: 2.5477997674791135

Epoch: 320| Step: 0
Training loss: 2.283716201239807
Validation loss: 2.555116281096681

Epoch: 6| Step: 1
Training loss: 1.711912391257028
Validation loss: 2.5475506110712187

Epoch: 6| Step: 2
Training loss: 2.288911677785137
Validation loss: 2.569968961040912

Epoch: 6| Step: 3
Training loss: 2.219097486337549
Validation loss: 2.5615989682648803

Epoch: 6| Step: 4
Training loss: 2.0771477488098293
Validation loss: 2.60158253949364

Epoch: 6| Step: 5
Training loss: 1.4934642183189144
Validation loss: 2.6094271108331224

Epoch: 6| Step: 6
Training loss: 1.8750652937646564
Validation loss: 2.613170155747343

Epoch: 6| Step: 7
Training loss: 1.973999291416957
Validation loss: 2.643161112593588

Epoch: 6| Step: 8
Training loss: 2.0849408115246426
Validation loss: 2.6368673551149797

Epoch: 6| Step: 9
Training loss: 2.499888799101579
Validation loss: 2.624829657643753

Epoch: 6| Step: 10
Training loss: 2.049906109776476
Validation loss: 2.5965778607749566

Epoch: 6| Step: 11
Training loss: 1.7631865685986396
Validation loss: 2.5024579521810724

Epoch: 6| Step: 12
Training loss: 2.066534892875138
Validation loss: 2.534180455829403

Epoch: 6| Step: 13
Training loss: 1.7657116893990839
Validation loss: 2.5217470819678187

Epoch: 321| Step: 0
Training loss: 1.9235915295108799
Validation loss: 2.4983975519990973

Epoch: 6| Step: 1
Training loss: 1.8902254549412387
Validation loss: 2.4753820773023216

Epoch: 6| Step: 2
Training loss: 1.4100693863509113
Validation loss: 2.4877133921685814

Epoch: 6| Step: 3
Training loss: 2.292872464239576
Validation loss: 2.498440263884612

Epoch: 6| Step: 4
Training loss: 1.6469391435730274
Validation loss: 2.484463736110998

Epoch: 6| Step: 5
Training loss: 2.3182429579289794
Validation loss: 2.4964907334971493

Epoch: 6| Step: 6
Training loss: 1.9882156571096672
Validation loss: 2.524254342885598

Epoch: 6| Step: 7
Training loss: 2.3488449667043385
Validation loss: 2.5632224421414826

Epoch: 6| Step: 8
Training loss: 1.7895536456534034
Validation loss: 2.578064811851686

Epoch: 6| Step: 9
Training loss: 2.177895742690139
Validation loss: 2.5638352148660855

Epoch: 6| Step: 10
Training loss: 1.9251565597084377
Validation loss: 2.61639543380924

Epoch: 6| Step: 11
Training loss: 1.8576527160256688
Validation loss: 2.634904809230082

Epoch: 6| Step: 12
Training loss: 1.8841060769170954
Validation loss: 2.5720533526208054

Epoch: 6| Step: 13
Training loss: 2.1285774186983613
Validation loss: 2.5605836541206295

Epoch: 322| Step: 0
Training loss: 1.3543568208651209
Validation loss: 2.5163270906482182

Epoch: 6| Step: 1
Training loss: 1.8789189391788255
Validation loss: 2.5178039307464455

Epoch: 6| Step: 2
Training loss: 1.6849867861538081
Validation loss: 2.509746641490503

Epoch: 6| Step: 3
Training loss: 2.5942824403209204
Validation loss: 2.5214062242046373

Epoch: 6| Step: 4
Training loss: 1.8584222997515574
Validation loss: 2.5365541637158815

Epoch: 6| Step: 5
Training loss: 1.716443473540774
Validation loss: 2.5498106951662876

Epoch: 6| Step: 6
Training loss: 1.4555794281170702
Validation loss: 2.571251447445702

Epoch: 6| Step: 7
Training loss: 1.6511371075534773
Validation loss: 2.555894852196271

Epoch: 6| Step: 8
Training loss: 2.1036946991731242
Validation loss: 2.555300593327232

Epoch: 6| Step: 9
Training loss: 2.5345404630897703
Validation loss: 2.5834243102102463

Epoch: 6| Step: 10
Training loss: 2.2339519820555416
Validation loss: 2.600540754742486

Epoch: 6| Step: 11
Training loss: 2.073468836049533
Validation loss: 2.6537477413197226

Epoch: 6| Step: 12
Training loss: 1.99521135209746
Validation loss: 2.6091296752610984

Epoch: 6| Step: 13
Training loss: 1.710269884818901
Validation loss: 2.6084047139143567

Epoch: 323| Step: 0
Training loss: 1.6253548748152489
Validation loss: 2.6049552689834705

Epoch: 6| Step: 1
Training loss: 2.16962640297474
Validation loss: 2.5755122113573705

Epoch: 6| Step: 2
Training loss: 2.1503810899680746
Validation loss: 2.566195281408966

Epoch: 6| Step: 3
Training loss: 1.7633522732636333
Validation loss: 2.565083573673419

Epoch: 6| Step: 4
Training loss: 1.55201145833495
Validation loss: 2.555554133106149

Epoch: 6| Step: 5
Training loss: 1.888877249974813
Validation loss: 2.536823745088214

Epoch: 6| Step: 6
Training loss: 2.0484205627905094
Validation loss: 2.5127740663061573

Epoch: 6| Step: 7
Training loss: 1.6400840957526377
Validation loss: 2.5368986798459647

Epoch: 6| Step: 8
Training loss: 2.059208063470841
Validation loss: 2.5140682323920736

Epoch: 6| Step: 9
Training loss: 1.606400713547894
Validation loss: 2.504646640126217

Epoch: 6| Step: 10
Training loss: 1.9701925170087182
Validation loss: 2.5425655047225137

Epoch: 6| Step: 11
Training loss: 1.6617907567243602
Validation loss: 2.5810536560064232

Epoch: 6| Step: 12
Training loss: 2.802042869833502
Validation loss: 2.5870264301829993

Epoch: 6| Step: 13
Training loss: 1.5869641668772847
Validation loss: 2.611108048304211

Epoch: 324| Step: 0
Training loss: 2.0543296125160517
Validation loss: 2.6107696948030794

Epoch: 6| Step: 1
Training loss: 1.954185259092768
Validation loss: 2.6116600919331177

Epoch: 6| Step: 2
Training loss: 1.886536583487851
Validation loss: 2.6410914503810194

Epoch: 6| Step: 3
Training loss: 1.1395121331901745
Validation loss: 2.636547936452079

Epoch: 6| Step: 4
Training loss: 1.6943974288643555
Validation loss: 2.6729418165927092

Epoch: 6| Step: 5
Training loss: 2.0301245285699756
Validation loss: 2.6815994752235097

Epoch: 6| Step: 6
Training loss: 2.1380255292933037
Validation loss: 2.6326918003627435

Epoch: 6| Step: 7
Training loss: 1.767989069762469
Validation loss: 2.569995617102066

Epoch: 6| Step: 8
Training loss: 2.243557926553225
Validation loss: 2.527211865340319

Epoch: 6| Step: 9
Training loss: 1.8815393219061753
Validation loss: 2.4859786865607645

Epoch: 6| Step: 10
Training loss: 1.9413568194906587
Validation loss: 2.5007469174094896

Epoch: 6| Step: 11
Training loss: 1.477539869309512
Validation loss: 2.5336332992680517

Epoch: 6| Step: 12
Training loss: 2.36367174185439
Validation loss: 2.516688862338514

Epoch: 6| Step: 13
Training loss: 2.274069996315973
Validation loss: 2.5143897457450572

Epoch: 325| Step: 0
Training loss: 2.824404297533427
Validation loss: 2.519375660747245

Epoch: 6| Step: 1
Training loss: 1.855665337036453
Validation loss: 2.5207675552193205

Epoch: 6| Step: 2
Training loss: 2.179143147192729
Validation loss: 2.4949095558127943

Epoch: 6| Step: 3
Training loss: 2.2672849690723584
Validation loss: 2.542548133609528

Epoch: 6| Step: 4
Training loss: 2.411513677391766
Validation loss: 2.5771410364852048

Epoch: 6| Step: 5
Training loss: 1.7876932159781627
Validation loss: 2.656410317164389

Epoch: 6| Step: 6
Training loss: 2.010476330545474
Validation loss: 2.6825931614189984

Epoch: 6| Step: 7
Training loss: 2.1875475197126524
Validation loss: 2.687219176295184

Epoch: 6| Step: 8
Training loss: 1.968312411647961
Validation loss: 2.6765912911224463

Epoch: 6| Step: 9
Training loss: 1.9847375733754973
Validation loss: 2.645406092794194

Epoch: 6| Step: 10
Training loss: 1.4468855262192188
Validation loss: 2.620797668804666

Epoch: 6| Step: 11
Training loss: 1.4841314818752294
Validation loss: 2.591260136266899

Epoch: 6| Step: 12
Training loss: 1.690113727873652
Validation loss: 2.5528379661051632

Epoch: 6| Step: 13
Training loss: 1.613861423017245
Validation loss: 2.522105240267951

Epoch: 326| Step: 0
Training loss: 1.9622287222585497
Validation loss: 2.4928207390183483

Epoch: 6| Step: 1
Training loss: 1.8356467158767324
Validation loss: 2.473397977846177

Epoch: 6| Step: 2
Training loss: 2.1158566955182097
Validation loss: 2.491552417479074

Epoch: 6| Step: 3
Training loss: 2.0246873920415327
Validation loss: 2.4758698530744696

Epoch: 6| Step: 4
Training loss: 1.7706474505831453
Validation loss: 2.48287810008293

Epoch: 6| Step: 5
Training loss: 1.5589736819587556
Validation loss: 2.488113836847768

Epoch: 6| Step: 6
Training loss: 1.7075723798611289
Validation loss: 2.503383460891157

Epoch: 6| Step: 7
Training loss: 1.8608975627979352
Validation loss: 2.505766980119729

Epoch: 6| Step: 8
Training loss: 2.111999912998891
Validation loss: 2.5070805417282473

Epoch: 6| Step: 9
Training loss: 1.7879373268860508
Validation loss: 2.5085153040564503

Epoch: 6| Step: 10
Training loss: 1.8782201454067669
Validation loss: 2.6048263375500786

Epoch: 6| Step: 11
Training loss: 2.3234314169993295
Validation loss: 2.5848350057081424

Epoch: 6| Step: 12
Training loss: 1.8201559105839307
Validation loss: 2.5758391139610324

Epoch: 6| Step: 13
Training loss: 2.1964961760392345
Validation loss: 2.5509675733388772

Epoch: 327| Step: 0
Training loss: 2.0096567196713995
Validation loss: 2.569069899218255

Epoch: 6| Step: 1
Training loss: 2.7924147690049526
Validation loss: 2.543454250354434

Epoch: 6| Step: 2
Training loss: 1.7119181013304468
Validation loss: 2.5193054886640502

Epoch: 6| Step: 3
Training loss: 1.705751196643779
Validation loss: 2.5093429031314582

Epoch: 6| Step: 4
Training loss: 1.5326414986980792
Validation loss: 2.4802018950687326

Epoch: 6| Step: 5
Training loss: 1.9229952640802443
Validation loss: 2.4812988414169244

Epoch: 6| Step: 6
Training loss: 1.1776865985852538
Validation loss: 2.4926318148260975

Epoch: 6| Step: 7
Training loss: 1.633767026945317
Validation loss: 2.4660853318416747

Epoch: 6| Step: 8
Training loss: 2.4508960097503834
Validation loss: 2.4917454820838647

Epoch: 6| Step: 9
Training loss: 1.4360330809286688
Validation loss: 2.500629353778878

Epoch: 6| Step: 10
Training loss: 2.039876022872514
Validation loss: 2.5270793369656817

Epoch: 6| Step: 11
Training loss: 1.760865404469135
Validation loss: 2.612763950940293

Epoch: 6| Step: 12
Training loss: 1.5215097603987855
Validation loss: 2.680742847463798

Epoch: 6| Step: 13
Training loss: 1.9349000775858425
Validation loss: 2.7176799787799446

Epoch: 328| Step: 0
Training loss: 2.1358568311637276
Validation loss: 2.8017108532584722

Epoch: 6| Step: 1
Training loss: 1.7254648991930168
Validation loss: 2.7810963220322056

Epoch: 6| Step: 2
Training loss: 2.340076161147736
Validation loss: 2.7788547817465536

Epoch: 6| Step: 3
Training loss: 2.0652509896100884
Validation loss: 2.6783495381198783

Epoch: 6| Step: 4
Training loss: 1.516571064265948
Validation loss: 2.594089424567392

Epoch: 6| Step: 5
Training loss: 2.4262951292766934
Validation loss: 2.521815437076748

Epoch: 6| Step: 6
Training loss: 2.203487068887936
Validation loss: 2.5287471217970183

Epoch: 6| Step: 7
Training loss: 1.7257832283226269
Validation loss: 2.519063664697806

Epoch: 6| Step: 8
Training loss: 1.3570249128001541
Validation loss: 2.5186090718639944

Epoch: 6| Step: 9
Training loss: 1.5230507384156085
Validation loss: 2.5122210928248756

Epoch: 6| Step: 10
Training loss: 2.307965549773842
Validation loss: 2.5325182967232673

Epoch: 6| Step: 11
Training loss: 1.9231461453817238
Validation loss: 2.5413521639829093

Epoch: 6| Step: 12
Training loss: 2.631430424464304
Validation loss: 2.5567315932745496

Epoch: 6| Step: 13
Training loss: 1.496772632005331
Validation loss: 2.541755414153378

Epoch: 329| Step: 0
Training loss: 1.6550695423140473
Validation loss: 2.5545392785737633

Epoch: 6| Step: 1
Training loss: 2.4406233119592433
Validation loss: 2.5977766195531604

Epoch: 6| Step: 2
Training loss: 2.211382170803292
Validation loss: 2.600855780026629

Epoch: 6| Step: 3
Training loss: 2.1769352426004946
Validation loss: 2.6389658303225962

Epoch: 6| Step: 4
Training loss: 2.116702316264314
Validation loss: 2.6462108663104864

Epoch: 6| Step: 5
Training loss: 1.9080832999177602
Validation loss: 2.6712425628591903

Epoch: 6| Step: 6
Training loss: 2.2045302001725675
Validation loss: 2.6520432314621476

Epoch: 6| Step: 7
Training loss: 1.7360253944429376
Validation loss: 2.6112515674401924

Epoch: 6| Step: 8
Training loss: 1.7341839109434436
Validation loss: 2.5300204426488633

Epoch: 6| Step: 9
Training loss: 2.075440357774807
Validation loss: 2.515953105751289

Epoch: 6| Step: 10
Training loss: 1.5019753482995033
Validation loss: 2.5069480903601327

Epoch: 6| Step: 11
Training loss: 1.2142173894124255
Validation loss: 2.4805074693756635

Epoch: 6| Step: 12
Training loss: 1.7382752150527263
Validation loss: 2.4603782785399586

Epoch: 6| Step: 13
Training loss: 2.6200453001576003
Validation loss: 2.4591786229838206

Epoch: 330| Step: 0
Training loss: 1.8465516092880156
Validation loss: 2.4810948340185783

Epoch: 6| Step: 1
Training loss: 2.6405195407010753
Validation loss: 2.438211292427263

Epoch: 6| Step: 2
Training loss: 2.5078112640853165
Validation loss: 2.4643151088670057

Epoch: 6| Step: 3
Training loss: 1.2069322366442174
Validation loss: 2.492462334381759

Epoch: 6| Step: 4
Training loss: 1.943653793652583
Validation loss: 2.557407109800745

Epoch: 6| Step: 5
Training loss: 1.8378729175845636
Validation loss: 2.6043026901324384

Epoch: 6| Step: 6
Training loss: 2.1886665503488016
Validation loss: 2.6821824776853824

Epoch: 6| Step: 7
Training loss: 2.461959771863449
Validation loss: 2.6886230162814924

Epoch: 6| Step: 8
Training loss: 1.5111456679307296
Validation loss: 2.5800642638371984

Epoch: 6| Step: 9
Training loss: 1.4121786815471804
Validation loss: 2.5099033026034285

Epoch: 6| Step: 10
Training loss: 1.3392606751054064
Validation loss: 2.487910747641356

Epoch: 6| Step: 11
Training loss: 2.36659308798232
Validation loss: 2.4956508396746173

Epoch: 6| Step: 12
Training loss: 1.6687813773759235
Validation loss: 2.5062035680768053

Epoch: 6| Step: 13
Training loss: 2.0579055707155702
Validation loss: 2.5030914821912695

Epoch: 331| Step: 0
Training loss: 1.8536449584215726
Validation loss: 2.5108738294345407

Epoch: 6| Step: 1
Training loss: 2.1644526932045904
Validation loss: 2.526318286549787

Epoch: 6| Step: 2
Training loss: 2.0992548301671192
Validation loss: 2.525471610540647

Epoch: 6| Step: 3
Training loss: 1.8657765184787642
Validation loss: 2.5259906934071883

Epoch: 6| Step: 4
Training loss: 1.8683885358719645
Validation loss: 2.527530213227947

Epoch: 6| Step: 5
Training loss: 1.1351836545803788
Validation loss: 2.5106703655109652

Epoch: 6| Step: 6
Training loss: 1.8296303705145887
Validation loss: 2.5173318099731885

Epoch: 6| Step: 7
Training loss: 1.8480520973623633
Validation loss: 2.5152229161501856

Epoch: 6| Step: 8
Training loss: 1.957821380034917
Validation loss: 2.503826669746549

Epoch: 6| Step: 9
Training loss: 2.148849836141682
Validation loss: 2.5593100130046005

Epoch: 6| Step: 10
Training loss: 2.1246854885948547
Validation loss: 2.5593955455633854

Epoch: 6| Step: 11
Training loss: 1.8132371390062936
Validation loss: 2.6337960478515927

Epoch: 6| Step: 12
Training loss: 2.1798382231854396
Validation loss: 2.6309818502689644

Epoch: 6| Step: 13
Training loss: 1.3772639796222144
Validation loss: 2.655745828689363

Epoch: 332| Step: 0
Training loss: 2.2845146126099243
Validation loss: 2.6490873366633076

Epoch: 6| Step: 1
Training loss: 1.9339470434621249
Validation loss: 2.6494474632706546

Epoch: 6| Step: 2
Training loss: 1.524317716966611
Validation loss: 2.5897565149006256

Epoch: 6| Step: 3
Training loss: 1.5340071786963685
Validation loss: 2.5487181813971524

Epoch: 6| Step: 4
Training loss: 2.117650843520304
Validation loss: 2.496645305828226

Epoch: 6| Step: 5
Training loss: 1.8714293495517722
Validation loss: 2.51936040096963

Epoch: 6| Step: 6
Training loss: 1.9780694094977793
Validation loss: 2.5438719130536014

Epoch: 6| Step: 7
Training loss: 1.6557658945501752
Validation loss: 2.489543536731367

Epoch: 6| Step: 8
Training loss: 2.6155609998085465
Validation loss: 2.53288304275591

Epoch: 6| Step: 9
Training loss: 1.9173412034430732
Validation loss: 2.532449689166416

Epoch: 6| Step: 10
Training loss: 1.8768041196301475
Validation loss: 2.522682667555815

Epoch: 6| Step: 11
Training loss: 1.3977068052322845
Validation loss: 2.5357856929122016

Epoch: 6| Step: 12
Training loss: 2.043220577437484
Validation loss: 2.519064737349003

Epoch: 6| Step: 13
Training loss: 1.197110388494654
Validation loss: 2.4827803286177996

Epoch: 333| Step: 0
Training loss: 1.883805515658449
Validation loss: 2.5191445539359756

Epoch: 6| Step: 1
Training loss: 1.7110463983029174
Validation loss: 2.516833155432344

Epoch: 6| Step: 2
Training loss: 1.7552830107637847
Validation loss: 2.533434643309147

Epoch: 6| Step: 3
Training loss: 1.7275839153395112
Validation loss: 2.6116739527688537

Epoch: 6| Step: 4
Training loss: 2.372062673670286
Validation loss: 2.603460907987119

Epoch: 6| Step: 5
Training loss: 1.5537929549229488
Validation loss: 2.5950523844768365

Epoch: 6| Step: 6
Training loss: 2.3388544452614797
Validation loss: 2.6084741800161395

Epoch: 6| Step: 7
Training loss: 1.9239856326306317
Validation loss: 2.583451842594352

Epoch: 6| Step: 8
Training loss: 1.0330124446529192
Validation loss: 2.541428919653053

Epoch: 6| Step: 9
Training loss: 1.2875899718615502
Validation loss: 2.534438836500642

Epoch: 6| Step: 10
Training loss: 1.9990525981973304
Validation loss: 2.537866461338731

Epoch: 6| Step: 11
Training loss: 2.062405208374502
Validation loss: 2.5293410053110006

Epoch: 6| Step: 12
Training loss: 1.8569909848480706
Validation loss: 2.5044682150339534

Epoch: 6| Step: 13
Training loss: 2.0660522388453044
Validation loss: 2.5134640054183817

Epoch: 334| Step: 0
Training loss: 2.1561740364294146
Validation loss: 2.53115058044351

Epoch: 6| Step: 1
Training loss: 1.9662714297029578
Validation loss: 2.501834291826896

Epoch: 6| Step: 2
Training loss: 2.158705929834795
Validation loss: 2.5047877560748706

Epoch: 6| Step: 3
Training loss: 1.9873752290920041
Validation loss: 2.5568002253200492

Epoch: 6| Step: 4
Training loss: 1.41317181435018
Validation loss: 2.5603036539471327

Epoch: 6| Step: 5
Training loss: 1.7272476286867013
Validation loss: 2.6099157934136734

Epoch: 6| Step: 6
Training loss: 1.547033436685721
Validation loss: 2.658633804281123

Epoch: 6| Step: 7
Training loss: 1.6444929757274116
Validation loss: 2.6480841086745306

Epoch: 6| Step: 8
Training loss: 1.9328481142036398
Validation loss: 2.6106085992647565

Epoch: 6| Step: 9
Training loss: 1.6641309124132309
Validation loss: 2.6062537158967016

Epoch: 6| Step: 10
Training loss: 2.0773235869532
Validation loss: 2.567421799793325

Epoch: 6| Step: 11
Training loss: 2.165173627485381
Validation loss: 2.545120282269221

Epoch: 6| Step: 12
Training loss: 1.8946597340855396
Validation loss: 2.5413674715220274

Epoch: 6| Step: 13
Training loss: 1.3674711096743752
Validation loss: 2.5317389953867324

Epoch: 335| Step: 0
Training loss: 1.0877985204747962
Validation loss: 2.5591729593235844

Epoch: 6| Step: 1
Training loss: 1.8972182263427972
Validation loss: 2.5335173008861744

Epoch: 6| Step: 2
Training loss: 1.8920822832510238
Validation loss: 2.557307417459145

Epoch: 6| Step: 3
Training loss: 2.02131747971225
Validation loss: 2.5417970769809917

Epoch: 6| Step: 4
Training loss: 1.9167684306896406
Validation loss: 2.592827337917651

Epoch: 6| Step: 5
Training loss: 1.6364497507680889
Validation loss: 2.626908093223655

Epoch: 6| Step: 6
Training loss: 1.7878011063077828
Validation loss: 2.5749635752475064

Epoch: 6| Step: 7
Training loss: 1.6085585217465048
Validation loss: 2.614772080578147

Epoch: 6| Step: 8
Training loss: 2.485525092941204
Validation loss: 2.566698805702758

Epoch: 6| Step: 9
Training loss: 1.7144352245982528
Validation loss: 2.50310314230835

Epoch: 6| Step: 10
Training loss: 1.6886970371663328
Validation loss: 2.5045462914583836

Epoch: 6| Step: 11
Training loss: 1.8389969028905249
Validation loss: 2.5202917247530054

Epoch: 6| Step: 12
Training loss: 1.8735483908266595
Validation loss: 2.537179007686907

Epoch: 6| Step: 13
Training loss: 1.9639578124485666
Validation loss: 2.5229782458181567

Epoch: 336| Step: 0
Training loss: 1.253138940215163
Validation loss: 2.529228132926555

Epoch: 6| Step: 1
Training loss: 1.222867173596523
Validation loss: 2.499960072516446

Epoch: 6| Step: 2
Training loss: 2.201134181271092
Validation loss: 2.525475937458757

Epoch: 6| Step: 3
Training loss: 1.3802198685457925
Validation loss: 2.4983235460241926

Epoch: 6| Step: 4
Training loss: 1.6706318734623788
Validation loss: 2.53499000447025

Epoch: 6| Step: 5
Training loss: 1.1523696637876786
Validation loss: 2.4893341950662133

Epoch: 6| Step: 6
Training loss: 1.539741017995019
Validation loss: 2.5012556022417356

Epoch: 6| Step: 7
Training loss: 1.8726708250469257
Validation loss: 2.4988773050299344

Epoch: 6| Step: 8
Training loss: 2.572728838737837
Validation loss: 2.5235300352217487

Epoch: 6| Step: 9
Training loss: 1.4645671125502226
Validation loss: 2.5004210276524086

Epoch: 6| Step: 10
Training loss: 2.025717728189329
Validation loss: 2.5087567351206017

Epoch: 6| Step: 11
Training loss: 1.5238347244804302
Validation loss: 2.507374678725855

Epoch: 6| Step: 12
Training loss: 2.5809161249696624
Validation loss: 2.5339779616117384

Epoch: 6| Step: 13
Training loss: 2.179453409948856
Validation loss: 2.551138945770862

Epoch: 337| Step: 0
Training loss: 2.0740255204766944
Validation loss: 2.600159947659544

Epoch: 6| Step: 1
Training loss: 1.7532052931188482
Validation loss: 2.639554470740458

Epoch: 6| Step: 2
Training loss: 1.3965852714315867
Validation loss: 2.6408393366576797

Epoch: 6| Step: 3
Training loss: 1.271551690026377
Validation loss: 2.6173600173191742

Epoch: 6| Step: 4
Training loss: 2.1593011470813006
Validation loss: 2.6121656833636204

Epoch: 6| Step: 5
Training loss: 1.8828954401386373
Validation loss: 2.579693234439409

Epoch: 6| Step: 6
Training loss: 2.3022617829031957
Validation loss: 2.5958930664374313

Epoch: 6| Step: 7
Training loss: 1.9036165401294054
Validation loss: 2.5235061872363747

Epoch: 6| Step: 8
Training loss: 1.509552579112508
Validation loss: 2.5413990400985824

Epoch: 6| Step: 9
Training loss: 2.2996587168378317
Validation loss: 2.556488172445947

Epoch: 6| Step: 10
Training loss: 1.6958996156053363
Validation loss: 2.504003799609266

Epoch: 6| Step: 11
Training loss: 1.9864488113033743
Validation loss: 2.563412155068857

Epoch: 6| Step: 12
Training loss: 1.7856040075855333
Validation loss: 2.5731162998934787

Epoch: 6| Step: 13
Training loss: 1.3220757442480566
Validation loss: 2.5550856751462256

Epoch: 338| Step: 0
Training loss: 2.169842104814694
Validation loss: 2.5278932503698814

Epoch: 6| Step: 1
Training loss: 1.9268610095748282
Validation loss: 2.527008411736144

Epoch: 6| Step: 2
Training loss: 1.5107724088717271
Validation loss: 2.5409972189945966

Epoch: 6| Step: 3
Training loss: 1.8847774525009398
Validation loss: 2.540102607727094

Epoch: 6| Step: 4
Training loss: 2.0546774048067706
Validation loss: 2.5119737463052982

Epoch: 6| Step: 5
Training loss: 1.7261704219786966
Validation loss: 2.513544039376682

Epoch: 6| Step: 6
Training loss: 1.4060959625650635
Validation loss: 2.532390274854139

Epoch: 6| Step: 7
Training loss: 2.029187372977991
Validation loss: 2.540421264162096

Epoch: 6| Step: 8
Training loss: 2.2573845797717347
Validation loss: 2.5375314018423696

Epoch: 6| Step: 9
Training loss: 1.7936358904015124
Validation loss: 2.568689871870906

Epoch: 6| Step: 10
Training loss: 1.6418967268152067
Validation loss: 2.6075863980359006

Epoch: 6| Step: 11
Training loss: 1.1529560078998433
Validation loss: 2.560430249104946

Epoch: 6| Step: 12
Training loss: 1.2779022302466159
Validation loss: 2.590718148109542

Epoch: 6| Step: 13
Training loss: 1.8552308261313872
Validation loss: 2.525882249239141

Epoch: 339| Step: 0
Training loss: 1.6219720506388478
Validation loss: 2.559107449822683

Epoch: 6| Step: 1
Training loss: 1.9327911252418033
Validation loss: 2.5036943081143495

Epoch: 6| Step: 2
Training loss: 1.5802628040250635
Validation loss: 2.563681167429925

Epoch: 6| Step: 3
Training loss: 1.5196804571567055
Validation loss: 2.5322821596679317

Epoch: 6| Step: 4
Training loss: 1.9006489247876976
Validation loss: 2.5215021433697915

Epoch: 6| Step: 5
Training loss: 1.9898157699648675
Validation loss: 2.5690702085631076

Epoch: 6| Step: 6
Training loss: 2.043042854438453
Validation loss: 2.5856388684082874

Epoch: 6| Step: 7
Training loss: 1.2275233787439057
Validation loss: 2.601644581520366

Epoch: 6| Step: 8
Training loss: 1.7967842410842736
Validation loss: 2.605869397762792

Epoch: 6| Step: 9
Training loss: 1.9693092278550774
Validation loss: 2.578959382026135

Epoch: 6| Step: 10
Training loss: 2.0184221597913354
Validation loss: 2.5993754269452123

Epoch: 6| Step: 11
Training loss: 1.833576648634034
Validation loss: 2.576279559619067

Epoch: 6| Step: 12
Training loss: 1.620352481359805
Validation loss: 2.6252258143102685

Epoch: 6| Step: 13
Training loss: 1.754481843495125
Validation loss: 2.5954919044546214

Epoch: 340| Step: 0
Training loss: 1.8563420539404982
Validation loss: 2.5887316218985092

Epoch: 6| Step: 1
Training loss: 1.91039301179186
Validation loss: 2.5799749345572183

Epoch: 6| Step: 2
Training loss: 1.86146805868684
Validation loss: 2.590808195931037

Epoch: 6| Step: 3
Training loss: 1.5712235118784932
Validation loss: 2.5759115176726395

Epoch: 6| Step: 4
Training loss: 1.5728372044312362
Validation loss: 2.526926429722714

Epoch: 6| Step: 5
Training loss: 2.196801166189041
Validation loss: 2.5239239392132715

Epoch: 6| Step: 6
Training loss: 1.2423672336128748
Validation loss: 2.540040407885633

Epoch: 6| Step: 7
Training loss: 1.2545711857716393
Validation loss: 2.5601705337139924

Epoch: 6| Step: 8
Training loss: 1.7801960956055387
Validation loss: 2.519300677964145

Epoch: 6| Step: 9
Training loss: 2.248293123255643
Validation loss: 2.5180190878774087

Epoch: 6| Step: 10
Training loss: 1.2585291745877702
Validation loss: 2.5634814375573685

Epoch: 6| Step: 11
Training loss: 1.7278790179878372
Validation loss: 2.56105023753305

Epoch: 6| Step: 12
Training loss: 1.2884701379254715
Validation loss: 2.5607709711411526

Epoch: 6| Step: 13
Training loss: 2.248986757801739
Validation loss: 2.595010826343059

Epoch: 341| Step: 0
Training loss: 1.9592889794262416
Validation loss: 2.597085057227484

Epoch: 6| Step: 1
Training loss: 2.3005987590442554
Validation loss: 2.609488235422749

Epoch: 6| Step: 2
Training loss: 1.7481367546289168
Validation loss: 2.5923131463532525

Epoch: 6| Step: 3
Training loss: 1.8856037391321254
Validation loss: 2.5924849584983676

Epoch: 6| Step: 4
Training loss: 1.6096314901754465
Validation loss: 2.5915869613689613

Epoch: 6| Step: 5
Training loss: 1.6641521161085924
Validation loss: 2.54708895730458

Epoch: 6| Step: 6
Training loss: 1.850941743087478
Validation loss: 2.5724203941303956

Epoch: 6| Step: 7
Training loss: 1.899121698860107
Validation loss: 2.510126838468241

Epoch: 6| Step: 8
Training loss: 1.8893910314023026
Validation loss: 2.525836917929611

Epoch: 6| Step: 9
Training loss: 1.6963589861946482
Validation loss: 2.466565851995199

Epoch: 6| Step: 10
Training loss: 1.5823343622383634
Validation loss: 2.4588461411101474

Epoch: 6| Step: 11
Training loss: 2.078580419214774
Validation loss: 2.4600349507007064

Epoch: 6| Step: 12
Training loss: 1.253640500247369
Validation loss: 2.4593027326410954

Epoch: 6| Step: 13
Training loss: 1.6177770304867365
Validation loss: 2.482572481442473

Epoch: 342| Step: 0
Training loss: 2.2521543785085005
Validation loss: 2.4528232558966327

Epoch: 6| Step: 1
Training loss: 1.7682795192045657
Validation loss: 2.480867689196142

Epoch: 6| Step: 2
Training loss: 1.9376315410629852
Validation loss: 2.50106087269069

Epoch: 6| Step: 3
Training loss: 1.7192476419130645
Validation loss: 2.4844175291119934

Epoch: 6| Step: 4
Training loss: 2.1143615556244946
Validation loss: 2.4991086324440945

Epoch: 6| Step: 5
Training loss: 1.191863025591129
Validation loss: 2.5405356334751676

Epoch: 6| Step: 6
Training loss: 1.2685473576217219
Validation loss: 2.5475935907114864

Epoch: 6| Step: 7
Training loss: 1.5647037986301144
Validation loss: 2.595680376407167

Epoch: 6| Step: 8
Training loss: 1.9042216281207094
Validation loss: 2.588314842146607

Epoch: 6| Step: 9
Training loss: 1.4989280049019682
Validation loss: 2.6029613960941247

Epoch: 6| Step: 10
Training loss: 2.013850532546481
Validation loss: 2.6021139421538515

Epoch: 6| Step: 11
Training loss: 1.8901331868750908
Validation loss: 2.6094402221325357

Epoch: 6| Step: 12
Training loss: 1.6646163090513872
Validation loss: 2.5902967330152697

Epoch: 6| Step: 13
Training loss: 2.0601309840215705
Validation loss: 2.573981220591819

Epoch: 343| Step: 0
Training loss: 1.6963067720901968
Validation loss: 2.578120930986372

Epoch: 6| Step: 1
Training loss: 1.8085571021698712
Validation loss: 2.547817391317142

Epoch: 6| Step: 2
Training loss: 2.3620224808181094
Validation loss: 2.538637018010903

Epoch: 6| Step: 3
Training loss: 2.183035955002794
Validation loss: 2.522552713045655

Epoch: 6| Step: 4
Training loss: 1.8060355168015407
Validation loss: 2.488380362284933

Epoch: 6| Step: 5
Training loss: 1.6430693083648218
Validation loss: 2.5039810113958754

Epoch: 6| Step: 6
Training loss: 2.2448535978502586
Validation loss: 2.5131527933580697

Epoch: 6| Step: 7
Training loss: 1.3989386060303282
Validation loss: 2.519433686489179

Epoch: 6| Step: 8
Training loss: 1.7309197727169563
Validation loss: 2.513049179207174

Epoch: 6| Step: 9
Training loss: 1.430539737025499
Validation loss: 2.5064363437292863

Epoch: 6| Step: 10
Training loss: 1.642938345329847
Validation loss: 2.4974722799163565

Epoch: 6| Step: 11
Training loss: 1.7023578280829226
Validation loss: 2.4929983161393188

Epoch: 6| Step: 12
Training loss: 1.629605150199471
Validation loss: 2.4892882700299284

Epoch: 6| Step: 13
Training loss: 1.3379203848765855
Validation loss: 2.502160037217818

Epoch: 344| Step: 0
Training loss: 2.159334271235948
Validation loss: 2.506052130215553

Epoch: 6| Step: 1
Training loss: 1.9279357124785554
Validation loss: 2.4886415740682115

Epoch: 6| Step: 2
Training loss: 1.9715319158189586
Validation loss: 2.5472800901942416

Epoch: 6| Step: 3
Training loss: 1.2199441976761582
Validation loss: 2.5565502829796602

Epoch: 6| Step: 4
Training loss: 1.816106431068875
Validation loss: 2.573430513250104

Epoch: 6| Step: 5
Training loss: 1.190398944210538
Validation loss: 2.564363918220066

Epoch: 6| Step: 6
Training loss: 1.3946448528274817
Validation loss: 2.632610958546794

Epoch: 6| Step: 7
Training loss: 2.158938183470663
Validation loss: 2.5949021197352846

Epoch: 6| Step: 8
Training loss: 1.321982506963788
Validation loss: 2.583752510968966

Epoch: 6| Step: 9
Training loss: 1.615918827454333
Validation loss: 2.5225673943027243

Epoch: 6| Step: 10
Training loss: 2.1300502678039273
Validation loss: 2.4684835765025186

Epoch: 6| Step: 11
Training loss: 2.1088821400484274
Validation loss: 2.4683597594277624

Epoch: 6| Step: 12
Training loss: 1.4593723501307998
Validation loss: 2.4876186061423176

Epoch: 6| Step: 13
Training loss: 1.8326231563551816
Validation loss: 2.48819590790985

Epoch: 345| Step: 0
Training loss: 1.0425729179037901
Validation loss: 2.515229899021366

Epoch: 6| Step: 1
Training loss: 2.1866595152218493
Validation loss: 2.5976049203031892

Epoch: 6| Step: 2
Training loss: 1.2763066645941337
Validation loss: 2.6092785115019703

Epoch: 6| Step: 3
Training loss: 2.033526743877839
Validation loss: 2.6510823114922952

Epoch: 6| Step: 4
Training loss: 2.0007904398095278
Validation loss: 2.700019964097236

Epoch: 6| Step: 5
Training loss: 1.745438147575304
Validation loss: 2.680564892433609

Epoch: 6| Step: 6
Training loss: 2.6245483736539157
Validation loss: 2.678007928521725

Epoch: 6| Step: 7
Training loss: 1.720444277671684
Validation loss: 2.648848840208425

Epoch: 6| Step: 8
Training loss: 1.8344248282376445
Validation loss: 2.62209234719753

Epoch: 6| Step: 9
Training loss: 1.1104628910561216
Validation loss: 2.601394647905427

Epoch: 6| Step: 10
Training loss: 1.639456341812799
Validation loss: 2.584502960321462

Epoch: 6| Step: 11
Training loss: 1.2517229603596705
Validation loss: 2.5814129988073744

Epoch: 6| Step: 12
Training loss: 1.9284334007198596
Validation loss: 2.593547054761871

Epoch: 6| Step: 13
Training loss: 1.6395334881674823
Validation loss: 2.575714926868066

Epoch: 346| Step: 0
Training loss: 1.8677309913204099
Validation loss: 2.563298403407274

Epoch: 6| Step: 1
Training loss: 1.5718680501067548
Validation loss: 2.557456177640261

Epoch: 6| Step: 2
Training loss: 2.519457155069657
Validation loss: 2.5623502299882843

Epoch: 6| Step: 3
Training loss: 1.724061837983605
Validation loss: 2.571853716713162

Epoch: 6| Step: 4
Training loss: 1.7195405009192886
Validation loss: 2.6007175390771207

Epoch: 6| Step: 5
Training loss: 1.5170177077917661
Validation loss: 2.582923015700113

Epoch: 6| Step: 6
Training loss: 1.896002192540249
Validation loss: 2.590569978811502

Epoch: 6| Step: 7
Training loss: 2.0344344779371815
Validation loss: 2.559668938692859

Epoch: 6| Step: 8
Training loss: 1.3952103358476469
Validation loss: 2.610373163330122

Epoch: 6| Step: 9
Training loss: 1.494463717365113
Validation loss: 2.5772109752264436

Epoch: 6| Step: 10
Training loss: 1.5598361386535007
Validation loss: 2.575713268428485

Epoch: 6| Step: 11
Training loss: 1.4799868320188592
Validation loss: 2.567142901475306

Epoch: 6| Step: 12
Training loss: 1.0280599092326457
Validation loss: 2.5602985710759376

Epoch: 6| Step: 13
Training loss: 2.126226632126056
Validation loss: 2.5372162899898063

Epoch: 347| Step: 0
Training loss: 2.2491001873031036
Validation loss: 2.5427206282661565

Epoch: 6| Step: 1
Training loss: 1.492361967262972
Validation loss: 2.579508597048646

Epoch: 6| Step: 2
Training loss: 1.7762156501041897
Validation loss: 2.5272811968381643

Epoch: 6| Step: 3
Training loss: 1.0705779922774559
Validation loss: 2.5423530579411944

Epoch: 6| Step: 4
Training loss: 1.7567612280659866
Validation loss: 2.5085370531291327

Epoch: 6| Step: 5
Training loss: 2.151780070244895
Validation loss: 2.5062453700377203

Epoch: 6| Step: 6
Training loss: 1.9283443208720474
Validation loss: 2.5225437971332436

Epoch: 6| Step: 7
Training loss: 1.1284526190726047
Validation loss: 2.546674708816386

Epoch: 6| Step: 8
Training loss: 1.742429228977813
Validation loss: 2.5186784508499973

Epoch: 6| Step: 9
Training loss: 1.90706598296332
Validation loss: 2.4918997029398104

Epoch: 6| Step: 10
Training loss: 1.6312867112979856
Validation loss: 2.5163535411722506

Epoch: 6| Step: 11
Training loss: 1.5569035058032485
Validation loss: 2.5023052236826917

Epoch: 6| Step: 12
Training loss: 1.5695803629367158
Validation loss: 2.5035460119238033

Epoch: 6| Step: 13
Training loss: 1.5830862036468134
Validation loss: 2.4931798571594204

Epoch: 348| Step: 0
Training loss: 1.4008252947000073
Validation loss: 2.5089181619572702

Epoch: 6| Step: 1
Training loss: 1.2911157612480673
Validation loss: 2.5253118555343277

Epoch: 6| Step: 2
Training loss: 1.2715402054724796
Validation loss: 2.551254166308896

Epoch: 6| Step: 3
Training loss: 1.779054861851385
Validation loss: 2.520999750576388

Epoch: 6| Step: 4
Training loss: 1.6117639680437337
Validation loss: 2.5271213125051752

Epoch: 6| Step: 5
Training loss: 1.4068958494792867
Validation loss: 2.596940326748841

Epoch: 6| Step: 6
Training loss: 1.2813266638173029
Validation loss: 2.583040056706432

Epoch: 6| Step: 7
Training loss: 1.7845033749767314
Validation loss: 2.5978210243988626

Epoch: 6| Step: 8
Training loss: 1.7074666810031287
Validation loss: 2.593828943115956

Epoch: 6| Step: 9
Training loss: 2.4463629370706723
Validation loss: 2.597820076042884

Epoch: 6| Step: 10
Training loss: 1.5287743622155714
Validation loss: 2.584703871479471

Epoch: 6| Step: 11
Training loss: 2.2236069722573575
Validation loss: 2.588271978338469

Epoch: 6| Step: 12
Training loss: 1.4884721928857592
Validation loss: 2.5866679440164195

Epoch: 6| Step: 13
Training loss: 2.204008101280541
Validation loss: 2.5489672314720178

Epoch: 349| Step: 0
Training loss: 2.3112240957290817
Validation loss: 2.5652161601189434

Epoch: 6| Step: 1
Training loss: 1.2741438422062161
Validation loss: 2.533142026361971

Epoch: 6| Step: 2
Training loss: 1.3636543178821343
Validation loss: 2.5229409499906836

Epoch: 6| Step: 3
Training loss: 1.348643066013701
Validation loss: 2.506212415278606

Epoch: 6| Step: 4
Training loss: 2.064296979963003
Validation loss: 2.5289056384541837

Epoch: 6| Step: 5
Training loss: 1.680501767113031
Validation loss: 2.4963503582805506

Epoch: 6| Step: 6
Training loss: 1.571479022467115
Validation loss: 2.492384549027154

Epoch: 6| Step: 7
Training loss: 2.1645588770327118
Validation loss: 2.4994090335452848

Epoch: 6| Step: 8
Training loss: 1.1112871480939563
Validation loss: 2.503003335028741

Epoch: 6| Step: 9
Training loss: 1.3045792677523678
Validation loss: 2.5201365924076193

Epoch: 6| Step: 10
Training loss: 1.5132455926966772
Validation loss: 2.582818523506884

Epoch: 6| Step: 11
Training loss: 2.501775301972593
Validation loss: 2.6143079108557314

Epoch: 6| Step: 12
Training loss: 1.7921833653556136
Validation loss: 2.5581065094968696

Epoch: 6| Step: 13
Training loss: 1.6134674482061602
Validation loss: 2.586573542716169

Epoch: 350| Step: 0
Training loss: 1.6867844512709496
Validation loss: 2.5375179189916865

Epoch: 6| Step: 1
Training loss: 1.6303392871588607
Validation loss: 2.486985552448376

Epoch: 6| Step: 2
Training loss: 1.1884839849937692
Validation loss: 2.5150858694298233

Epoch: 6| Step: 3
Training loss: 1.3163262408021905
Validation loss: 2.486411501557028

Epoch: 6| Step: 4
Training loss: 1.0588161896392017
Validation loss: 2.5592837735453866

Epoch: 6| Step: 5
Training loss: 2.2897554461900365
Validation loss: 2.5292482506436555

Epoch: 6| Step: 6
Training loss: 1.494079588597066
Validation loss: 2.5184298530358697

Epoch: 6| Step: 7
Training loss: 1.3372270038115819
Validation loss: 2.536387328316595

Epoch: 6| Step: 8
Training loss: 1.3614532544547946
Validation loss: 2.5177725713634316

Epoch: 6| Step: 9
Training loss: 2.022753389986748
Validation loss: 2.53036563636115

Epoch: 6| Step: 10
Training loss: 2.2661630978047564
Validation loss: 2.5333265256371966

Epoch: 6| Step: 11
Training loss: 1.892122794571951
Validation loss: 2.4942778188900094

Epoch: 6| Step: 12
Training loss: 1.7763140367941732
Validation loss: 2.4814715103193694

Epoch: 6| Step: 13
Training loss: 1.5845870859825737
Validation loss: 2.5046309336436066

Testing loss: 2.1602599712262767
