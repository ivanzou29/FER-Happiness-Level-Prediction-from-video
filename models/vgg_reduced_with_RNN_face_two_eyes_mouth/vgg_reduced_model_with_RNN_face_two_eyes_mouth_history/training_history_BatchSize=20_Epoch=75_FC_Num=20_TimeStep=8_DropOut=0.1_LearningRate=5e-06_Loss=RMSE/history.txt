Epoch: 1| Step: 0
Training loss: 6.402587141213314
Validation loss: 5.893222313805436

Epoch: 5| Step: 1
Training loss: 5.831312683357323
Validation loss: 5.891347019592699

Epoch: 5| Step: 2
Training loss: 5.76443196180553
Validation loss: 5.889625478008311

Epoch: 5| Step: 3
Training loss: 6.591078085810541
Validation loss: 5.887965842497353

Epoch: 5| Step: 4
Training loss: 6.117791741589201
Validation loss: 5.886360290859348

Epoch: 5| Step: 5
Training loss: 6.459590600802846
Validation loss: 5.884718168776112

Epoch: 5| Step: 6
Training loss: 5.4253748610407095
Validation loss: 5.883175869510409

Epoch: 5| Step: 7
Training loss: 5.4786952677766445
Validation loss: 5.88160947916549

Epoch: 5| Step: 8
Training loss: 6.031635489522456
Validation loss: 5.879930402361147

Epoch: 5| Step: 9
Training loss: 6.393775368618722
Validation loss: 5.878350911995187

Epoch: 5| Step: 10
Training loss: 4.96192780470076
Validation loss: 5.876764654719123

Epoch: 5| Step: 11
Training loss: 7.53237438118681
Validation loss: 5.875211867441898

Epoch: 2| Step: 0
Training loss: 7.224002925090684
Validation loss: 5.873466663604477

Epoch: 5| Step: 1
Training loss: 5.866175090539925
Validation loss: 5.871690467261439

Epoch: 5| Step: 2
Training loss: 5.079528051365537
Validation loss: 5.8699142817835295

Epoch: 5| Step: 3
Training loss: 6.3207102345110195
Validation loss: 5.868056353607224

Epoch: 5| Step: 4
Training loss: 5.832293208806149
Validation loss: 5.866080391734542

Epoch: 5| Step: 5
Training loss: 5.544187770619667
Validation loss: 5.864074029935715

Epoch: 5| Step: 6
Training loss: 5.770736785338099
Validation loss: 5.862056623772145

Epoch: 5| Step: 7
Training loss: 6.2318409906357815
Validation loss: 5.859815236825393

Epoch: 5| Step: 8
Training loss: 5.120664670239505
Validation loss: 5.857556168442531

Epoch: 5| Step: 9
Training loss: 5.403419768112569
Validation loss: 5.855149409480555

Epoch: 5| Step: 10
Training loss: 6.929552629571125
Validation loss: 5.852630517767933

Epoch: 5| Step: 11
Training loss: 6.278838496586047
Validation loss: 5.8498707368486125

Epoch: 3| Step: 0
Training loss: 5.356614539116914
Validation loss: 5.847224910833123

Epoch: 5| Step: 1
Training loss: 5.983858011488922
Validation loss: 5.844425427575512

Epoch: 5| Step: 2
Training loss: 6.2739126897202215
Validation loss: 5.8413706540774015

Epoch: 5| Step: 3
Training loss: 5.346311791709302
Validation loss: 5.838174890663642

Epoch: 5| Step: 4
Training loss: 5.719853862682964
Validation loss: 5.834713550042487

Epoch: 5| Step: 5
Training loss: 5.694044435092564
Validation loss: 5.8314124714036

Epoch: 5| Step: 6
Training loss: 6.81289671696448
Validation loss: 5.827656356337357

Epoch: 5| Step: 7
Training loss: 5.494330865662984
Validation loss: 5.823943136931463

Epoch: 5| Step: 8
Training loss: 5.909341638754323
Validation loss: 5.81990011576294

Epoch: 5| Step: 9
Training loss: 6.366884938171725
Validation loss: 5.815725258918381

Epoch: 5| Step: 10
Training loss: 6.010512679031209
Validation loss: 5.811377898983432

Epoch: 5| Step: 11
Training loss: 7.148670697186744
Validation loss: 5.80692329321785

Epoch: 4| Step: 0
Training loss: 6.347160437366916
Validation loss: 5.80215285126584

Epoch: 5| Step: 1
Training loss: 5.923561842329524
Validation loss: 5.7970065147376895

Epoch: 5| Step: 2
Training loss: 4.897070978523915
Validation loss: 5.7919956932556795

Epoch: 5| Step: 3
Training loss: 5.852423610913861
Validation loss: 5.786688190316165

Epoch: 5| Step: 4
Training loss: 6.0962012422640415
Validation loss: 5.781353992523488

Epoch: 5| Step: 5
Training loss: 5.343346831522213
Validation loss: 5.775864644572753

Epoch: 5| Step: 6
Training loss: 5.7463344002334775
Validation loss: 5.769981840183323

Epoch: 5| Step: 7
Training loss: 5.816963041054678
Validation loss: 5.764268834512596

Epoch: 5| Step: 8
Training loss: 6.12421116322961
Validation loss: 5.758040114397858

Epoch: 5| Step: 9
Training loss: 6.1560919881767955
Validation loss: 5.751931792016184

Epoch: 5| Step: 10
Training loss: 6.531367688738557
Validation loss: 5.745551295708696

Epoch: 5| Step: 11
Training loss: 4.661496068137537
Validation loss: 5.739000165036337

Epoch: 5| Step: 0
Training loss: 5.5590691433549
Validation loss: 5.732422353299331

Epoch: 5| Step: 1
Training loss: 5.601316821724076
Validation loss: 5.725814236149342

Epoch: 5| Step: 2
Training loss: 4.681917859503693
Validation loss: 5.718925132918663

Epoch: 5| Step: 3
Training loss: 6.180996029287068
Validation loss: 5.71214539104082

Epoch: 5| Step: 4
Training loss: 6.219357254820303
Validation loss: 5.704927370420956

Epoch: 5| Step: 5
Training loss: 6.389270443050098
Validation loss: 5.697725145188537

Epoch: 5| Step: 6
Training loss: 6.508875143021366
Validation loss: 5.690305381260818

Epoch: 5| Step: 7
Training loss: 5.130950636500423
Validation loss: 5.682558253322957

Epoch: 5| Step: 8
Training loss: 5.6862395849696465
Validation loss: 5.675186738682332

Epoch: 5| Step: 9
Training loss: 6.090953322085646
Validation loss: 5.667632920499002

Epoch: 5| Step: 10
Training loss: 5.867645855306946
Validation loss: 5.659637848654862

Epoch: 5| Step: 11
Training loss: 4.462137091062263
Validation loss: 5.651954973194906

Epoch: 6| Step: 0
Training loss: 5.795208879183661
Validation loss: 5.644351154697031

Epoch: 5| Step: 1
Training loss: 6.516202832403803
Validation loss: 5.636920476816641

Epoch: 5| Step: 2
Training loss: 4.470978507996849
Validation loss: 5.629145832244395

Epoch: 5| Step: 3
Training loss: 5.3510569089979745
Validation loss: 5.621799314256964

Epoch: 5| Step: 4
Training loss: 5.8926130830501
Validation loss: 5.614556889893418

Epoch: 5| Step: 5
Training loss: 6.806865356763525
Validation loss: 5.607040039724613

Epoch: 5| Step: 6
Training loss: 6.264926329207742
Validation loss: 5.599691017175746

Epoch: 5| Step: 7
Training loss: 5.352071072435819
Validation loss: 5.592257437313521

Epoch: 5| Step: 8
Training loss: 5.264474443105349
Validation loss: 5.585066357955209

Epoch: 5| Step: 9
Training loss: 5.29832434166386
Validation loss: 5.578069464000137

Epoch: 5| Step: 10
Training loss: 5.530790148224419
Validation loss: 5.571213059571422

Epoch: 5| Step: 11
Training loss: 6.034432791892959
Validation loss: 5.564097171608648

Epoch: 7| Step: 0
Training loss: 4.788115515122544
Validation loss: 5.557289047264428

Epoch: 5| Step: 1
Training loss: 5.278476144641169
Validation loss: 5.550445925923717

Epoch: 5| Step: 2
Training loss: 6.2322253964642504
Validation loss: 5.543874081065606

Epoch: 5| Step: 3
Training loss: 6.464943470718816
Validation loss: 5.537087142513972

Epoch: 5| Step: 4
Training loss: 5.656352173951997
Validation loss: 5.530284531523983

Epoch: 5| Step: 5
Training loss: 4.841962915353362
Validation loss: 5.523290075540598

Epoch: 5| Step: 6
Training loss: 6.13897294590605
Validation loss: 5.5167470912698935

Epoch: 5| Step: 7
Training loss: 5.675264044849347
Validation loss: 5.509577056820415

Epoch: 5| Step: 8
Training loss: 4.966905167419514
Validation loss: 5.502699232987785

Epoch: 5| Step: 9
Training loss: 5.7555929432312904
Validation loss: 5.4960302056871155

Epoch: 5| Step: 10
Training loss: 5.378107104363112
Validation loss: 5.489376037660102

Epoch: 5| Step: 11
Training loss: 8.131736427670388
Validation loss: 5.483007305776063

Epoch: 8| Step: 0
Training loss: 4.875602293711048
Validation loss: 5.476203039601133

Epoch: 5| Step: 1
Training loss: 5.185021233363436
Validation loss: 5.46982090954969

Epoch: 5| Step: 2
Training loss: 6.338106398002667
Validation loss: 5.463268810206959

Epoch: 5| Step: 3
Training loss: 6.104033415536671
Validation loss: 5.457002443543853

Epoch: 5| Step: 4
Training loss: 5.537716636122887
Validation loss: 5.450570682371193

Epoch: 5| Step: 5
Training loss: 5.35045430758991
Validation loss: 5.4442127709933015

Epoch: 5| Step: 6
Training loss: 5.037364774266258
Validation loss: 5.4375016954207425

Epoch: 5| Step: 7
Training loss: 5.551387359149794
Validation loss: 5.431236737655408

Epoch: 5| Step: 8
Training loss: 5.495843530529281
Validation loss: 5.42546680803534

Epoch: 5| Step: 9
Training loss: 6.402963083509017
Validation loss: 5.419336477747004

Epoch: 5| Step: 10
Training loss: 4.870198550710211
Validation loss: 5.413076812866749

Epoch: 5| Step: 11
Training loss: 6.476958001626534
Validation loss: 5.406904846104327

Epoch: 9| Step: 0
Training loss: 5.780106714972883
Validation loss: 5.400947638649306

Epoch: 5| Step: 1
Training loss: 5.054208629629981
Validation loss: 5.394707318010124

Epoch: 5| Step: 2
Training loss: 4.46012440768816
Validation loss: 5.388692596089684

Epoch: 5| Step: 3
Training loss: 5.532704997102316
Validation loss: 5.382922078693472

Epoch: 5| Step: 4
Training loss: 5.703597877441799
Validation loss: 5.377032073273084

Epoch: 5| Step: 5
Training loss: 5.700554255257876
Validation loss: 5.3703918812249105

Epoch: 5| Step: 6
Training loss: 5.943121246872665
Validation loss: 5.364895178857266

Epoch: 5| Step: 7
Training loss: 5.197902865445679
Validation loss: 5.358679352776542

Epoch: 5| Step: 8
Training loss: 5.687153229255156
Validation loss: 5.352507622416576

Epoch: 5| Step: 9
Training loss: 6.414822234904092
Validation loss: 5.345810624884851

Epoch: 5| Step: 10
Training loss: 4.508553746465226
Validation loss: 5.3393821488888165

Epoch: 5| Step: 11
Training loss: 5.993663620947894
Validation loss: 5.333018616490346

Epoch: 10| Step: 0
Training loss: 5.3528899613872785
Validation loss: 5.326017050409857

Epoch: 5| Step: 1
Training loss: 5.158352694785779
Validation loss: 5.319261899969441

Epoch: 5| Step: 2
Training loss: 5.004929592006991
Validation loss: 5.312555312822398

Epoch: 5| Step: 3
Training loss: 6.015857404703065
Validation loss: 5.305281008972803

Epoch: 5| Step: 4
Training loss: 5.62491861920297
Validation loss: 5.298773358806415

Epoch: 5| Step: 5
Training loss: 5.436428446802381
Validation loss: 5.292938510109265

Epoch: 5| Step: 6
Training loss: 5.465424142138174
Validation loss: 5.285868090922702

Epoch: 5| Step: 7
Training loss: 4.959971993274989
Validation loss: 5.279075505955657

Epoch: 5| Step: 8
Training loss: 5.369148440336255
Validation loss: 5.273346534227003

Epoch: 5| Step: 9
Training loss: 5.3740961068876
Validation loss: 5.26717436170302

Epoch: 5| Step: 10
Training loss: 5.975541809288157
Validation loss: 5.2602429074838986

Epoch: 5| Step: 11
Training loss: 3.771429629449572
Validation loss: 5.253711145647449

Epoch: 11| Step: 0
Training loss: 5.489208732240332
Validation loss: 5.247731581580687

Epoch: 5| Step: 1
Training loss: 5.760544769168768
Validation loss: 5.242326502466003

Epoch: 5| Step: 2
Training loss: 5.158654779249114
Validation loss: 5.2353577104136395

Epoch: 5| Step: 3
Training loss: 4.9043139871764385
Validation loss: 5.229299029413975

Epoch: 5| Step: 4
Training loss: 4.908790270914833
Validation loss: 5.223536293372794

Epoch: 5| Step: 5
Training loss: 5.720181978972224
Validation loss: 5.217369856479347

Epoch: 5| Step: 6
Training loss: 4.904693162130373
Validation loss: 5.210942387995603

Epoch: 5| Step: 7
Training loss: 5.275319759566601
Validation loss: 5.205276197299362

Epoch: 5| Step: 8
Training loss: 5.469683235104462
Validation loss: 5.199731042520937

Epoch: 5| Step: 9
Training loss: 5.25580348818299
Validation loss: 5.1936112450749405

Epoch: 5| Step: 10
Training loss: 5.810621388702895
Validation loss: 5.1879555375804935

Epoch: 5| Step: 11
Training loss: 5.2161699873132825
Validation loss: 5.183126980986524

Epoch: 12| Step: 0
Training loss: 4.868059940429879
Validation loss: 5.176436848894916

Epoch: 5| Step: 1
Training loss: 4.671850095956825
Validation loss: 5.170999082090756

Epoch: 5| Step: 2
Training loss: 4.673036973039225
Validation loss: 5.165696732426279

Epoch: 5| Step: 3
Training loss: 5.6202844139163055
Validation loss: 5.15992684327245

Epoch: 5| Step: 4
Training loss: 4.69316369266692
Validation loss: 5.154158050336654

Epoch: 5| Step: 5
Training loss: 5.856831804848352
Validation loss: 5.148569625370862

Epoch: 5| Step: 6
Training loss: 5.940026318013365
Validation loss: 5.143701060090484

Epoch: 5| Step: 7
Training loss: 5.191617319883869
Validation loss: 5.137865317134495

Epoch: 5| Step: 8
Training loss: 5.066941373471983
Validation loss: 5.131922048033196

Epoch: 5| Step: 9
Training loss: 5.833312806592883
Validation loss: 5.12593374817654

Epoch: 5| Step: 10
Training loss: 5.140491982452192
Validation loss: 5.119847537641671

Epoch: 5| Step: 11
Training loss: 6.150517462073377
Validation loss: 5.114417019669535

Epoch: 13| Step: 0
Training loss: 5.464441138727561
Validation loss: 5.108292436773104

Epoch: 5| Step: 1
Training loss: 4.156654280883968
Validation loss: 5.102326682992915

Epoch: 5| Step: 2
Training loss: 5.4314924355009735
Validation loss: 5.096411549890485

Epoch: 5| Step: 3
Training loss: 5.681020881892448
Validation loss: 5.090338924168495

Epoch: 5| Step: 4
Training loss: 5.164338212725329
Validation loss: 5.084182663092933

Epoch: 5| Step: 5
Training loss: 4.952186278911571
Validation loss: 5.078975915286777

Epoch: 5| Step: 6
Training loss: 5.455624070593005
Validation loss: 5.074944306993496

Epoch: 5| Step: 7
Training loss: 5.418336268627288
Validation loss: 5.068355980236801

Epoch: 5| Step: 8
Training loss: 5.681337140614194
Validation loss: 5.062173448242438

Epoch: 5| Step: 9
Training loss: 5.204252836777949
Validation loss: 5.056842106940172

Epoch: 5| Step: 10
Training loss: 4.423336367190446
Validation loss: 5.051519612850902

Epoch: 5| Step: 11
Training loss: 5.0713555390224645
Validation loss: 5.046230152926734

Epoch: 14| Step: 0
Training loss: 5.461723129233601
Validation loss: 5.040898282896079

Epoch: 5| Step: 1
Training loss: 5.751949477396976
Validation loss: 5.0350006055784196

Epoch: 5| Step: 2
Training loss: 4.178627065025015
Validation loss: 5.03050079453984

Epoch: 5| Step: 3
Training loss: 5.0656589024495915
Validation loss: 5.025161992968237

Epoch: 5| Step: 4
Training loss: 5.467839279636834
Validation loss: 5.0216518331148885

Epoch: 5| Step: 5
Training loss: 5.219812342168171
Validation loss: 5.015366481246707

Epoch: 5| Step: 6
Training loss: 5.155486449147524
Validation loss: 5.0091264402485365

Epoch: 5| Step: 7
Training loss: 4.877557719332486
Validation loss: 5.00467181497562

Epoch: 5| Step: 8
Training loss: 5.3263262176252875
Validation loss: 4.999135014100533

Epoch: 5| Step: 9
Training loss: 4.716010909219149
Validation loss: 4.994544295257091

Epoch: 5| Step: 10
Training loss: 5.022788567994804
Validation loss: 4.989647487262459

Epoch: 5| Step: 11
Training loss: 5.709759425023999
Validation loss: 4.984282537577318

Epoch: 15| Step: 0
Training loss: 4.382362492216224
Validation loss: 4.978172484971831

Epoch: 5| Step: 1
Training loss: 5.430966014044198
Validation loss: 4.973846788470471

Epoch: 5| Step: 2
Training loss: 5.066515613278491
Validation loss: 4.969330016057189

Epoch: 5| Step: 3
Training loss: 4.465239953645037
Validation loss: 4.964191200798098

Epoch: 5| Step: 4
Training loss: 5.4562650455298005
Validation loss: 4.957783206372661

Epoch: 5| Step: 5
Training loss: 5.193179227495581
Validation loss: 4.952886766225955

Epoch: 5| Step: 6
Training loss: 5.418638643134735
Validation loss: 4.948192487022519

Epoch: 5| Step: 7
Training loss: 4.516657833264336
Validation loss: 4.944676853044632

Epoch: 5| Step: 8
Training loss: 4.943339311249288
Validation loss: 4.938611352162419

Epoch: 5| Step: 9
Training loss: 5.755527658939057
Validation loss: 4.932604265897828

Epoch: 5| Step: 10
Training loss: 4.956279339889907
Validation loss: 4.928174156858168

Epoch: 5| Step: 11
Training loss: 5.443279658604035
Validation loss: 4.922263962650253

Epoch: 16| Step: 0
Training loss: 5.3213187231062244
Validation loss: 4.917318764239537

Epoch: 5| Step: 1
Training loss: 4.931338171418451
Validation loss: 4.913455329262109

Epoch: 5| Step: 2
Training loss: 5.128878544705731
Validation loss: 4.907147311302941

Epoch: 5| Step: 3
Training loss: 5.283182546748279
Validation loss: 4.900004402470071

Epoch: 5| Step: 4
Training loss: 5.217332658921849
Validation loss: 4.893496920365774

Epoch: 5| Step: 5
Training loss: 5.1755822485328284
Validation loss: 4.888305211385705

Epoch: 5| Step: 6
Training loss: 4.922207097551021
Validation loss: 4.8830975828235585

Epoch: 5| Step: 7
Training loss: 5.3856114168450695
Validation loss: 4.877410586117774

Epoch: 5| Step: 8
Training loss: 5.014772526915264
Validation loss: 4.87318322979007

Epoch: 5| Step: 9
Training loss: 3.9131283435280224
Validation loss: 4.866590174417871

Epoch: 5| Step: 10
Training loss: 4.669373317713608
Validation loss: 4.860878461387072

Epoch: 5| Step: 11
Training loss: 5.218177261447216
Validation loss: 4.854738114519488

Epoch: 17| Step: 0
Training loss: 5.232871132787277
Validation loss: 4.8486528706719945

Epoch: 5| Step: 1
Training loss: 4.556492442939893
Validation loss: 4.844047389591669

Epoch: 5| Step: 2
Training loss: 4.78323043996131
Validation loss: 4.8388657586242845

Epoch: 5| Step: 3
Training loss: 5.253996281756482
Validation loss: 4.832457268452466

Epoch: 5| Step: 4
Training loss: 4.941773701752837
Validation loss: 4.8273094871182956

Epoch: 5| Step: 5
Training loss: 4.760663160401777
Validation loss: 4.822115865292377

Epoch: 5| Step: 6
Training loss: 4.475929308676527
Validation loss: 4.815906813303473

Epoch: 5| Step: 7
Training loss: 4.959201298672192
Validation loss: 4.809624684086175

Epoch: 5| Step: 8
Training loss: 5.56568337548564
Validation loss: 4.80420310620629

Epoch: 5| Step: 9
Training loss: 4.653388251241978
Validation loss: 4.798551111295518

Epoch: 5| Step: 10
Training loss: 5.438325490444154
Validation loss: 4.79374376418443

Epoch: 5| Step: 11
Training loss: 2.8344140703059324
Validation loss: 4.788065106909826

Epoch: 18| Step: 0
Training loss: 5.078585841469052
Validation loss: 4.782655854159142

Epoch: 5| Step: 1
Training loss: 4.7325175956967245
Validation loss: 4.777846760338074

Epoch: 5| Step: 2
Training loss: 5.399671488058795
Validation loss: 4.771985629768084

Epoch: 5| Step: 3
Training loss: 4.119025093581929
Validation loss: 4.767099379637044

Epoch: 5| Step: 4
Training loss: 5.01839971590727
Validation loss: 4.760776008159782

Epoch: 5| Step: 5
Training loss: 4.604210808773948
Validation loss: 4.755593177400501

Epoch: 5| Step: 6
Training loss: 5.067280713734647
Validation loss: 4.750058776090277

Epoch: 5| Step: 7
Training loss: 4.538749434529666
Validation loss: 4.743951418105756

Epoch: 5| Step: 8
Training loss: 5.428932016629654
Validation loss: 4.738592914878037

Epoch: 5| Step: 9
Training loss: 4.99388225127257
Validation loss: 4.7333079731400645

Epoch: 5| Step: 10
Training loss: 4.446145889654851
Validation loss: 4.729323778049427

Epoch: 5| Step: 11
Training loss: 5.419589481643063
Validation loss: 4.724706322089411

Epoch: 19| Step: 0
Training loss: 4.124797006872022
Validation loss: 4.7181216615264265

Epoch: 5| Step: 1
Training loss: 5.435689164224117
Validation loss: 4.711457602836602

Epoch: 5| Step: 2
Training loss: 4.5947177412574725
Validation loss: 4.704937227704014

Epoch: 5| Step: 3
Training loss: 4.537457443331984
Validation loss: 4.700502604469465

Epoch: 5| Step: 4
Training loss: 4.7174327097967135
Validation loss: 4.694001271260559

Epoch: 5| Step: 5
Training loss: 4.857644119362889
Validation loss: 4.689301047294705

Epoch: 5| Step: 6
Training loss: 4.66933287795446
Validation loss: 4.683799622470261

Epoch: 5| Step: 7
Training loss: 5.1662880953665535
Validation loss: 4.679756329624117

Epoch: 5| Step: 8
Training loss: 4.814392510394289
Validation loss: 4.6749192422973636

Epoch: 5| Step: 9
Training loss: 4.881353883700202
Validation loss: 4.670083237150584

Epoch: 5| Step: 10
Training loss: 5.364973252826154
Validation loss: 4.664174434781939

Epoch: 5| Step: 11
Training loss: 2.722848543357393
Validation loss: 4.658648425769814

Epoch: 20| Step: 0
Training loss: 4.805066002304133
Validation loss: 4.653163911286565

Epoch: 5| Step: 1
Training loss: 4.629901247886994
Validation loss: 4.647305899546517

Epoch: 5| Step: 2
Training loss: 4.922569976665735
Validation loss: 4.64429956900486

Epoch: 5| Step: 3
Training loss: 4.826692732921488
Validation loss: 4.6389268964300525

Epoch: 5| Step: 4
Training loss: 4.754829962705624
Validation loss: 4.631610347716081

Epoch: 5| Step: 5
Training loss: 4.531584628673084
Validation loss: 4.6280961799282325

Epoch: 5| Step: 6
Training loss: 5.214401534972151
Validation loss: 4.623277128497251

Epoch: 5| Step: 7
Training loss: 4.872709469782115
Validation loss: 4.618622713309517

Epoch: 5| Step: 8
Training loss: 5.376572844571021
Validation loss: 4.613524497023112

Epoch: 5| Step: 9
Training loss: 4.303638586618132
Validation loss: 4.607299276965614

Epoch: 5| Step: 10
Training loss: 3.5704479233582282
Validation loss: 4.601770893898283

Epoch: 5| Step: 11
Training loss: 5.91993476264681
Validation loss: 4.597045261489677

Epoch: 21| Step: 0
Training loss: 4.360029492759696
Validation loss: 4.592256800719321

Epoch: 5| Step: 1
Training loss: 4.3459824787318615
Validation loss: 4.587210518056144

Epoch: 5| Step: 2
Training loss: 4.8854748601097775
Validation loss: 4.581677522092531

Epoch: 5| Step: 3
Training loss: 5.034627787555751
Validation loss: 4.5766981329441645

Epoch: 5| Step: 4
Training loss: 5.286174216567251
Validation loss: 4.571641821052625

Epoch: 5| Step: 5
Training loss: 4.595501209108212
Validation loss: 4.566339018593014

Epoch: 5| Step: 6
Training loss: 5.037969047726921
Validation loss: 4.5615037413912125

Epoch: 5| Step: 7
Training loss: 4.59376972220203
Validation loss: 4.55592150626862

Epoch: 5| Step: 8
Training loss: 4.671991353196804
Validation loss: 4.550859259071865

Epoch: 5| Step: 9
Training loss: 4.225566415232521
Validation loss: 4.546647301005254

Epoch: 5| Step: 10
Training loss: 4.604915828370476
Validation loss: 4.541290795524235

Epoch: 5| Step: 11
Training loss: 4.02654873450002
Validation loss: 4.535716882750715

Epoch: 22| Step: 0
Training loss: 4.635223224618316
Validation loss: 4.53096784392827

Epoch: 5| Step: 1
Training loss: 4.972759428549557
Validation loss: 4.525860161282409

Epoch: 5| Step: 2
Training loss: 4.721782594050526
Validation loss: 4.520023329050068

Epoch: 5| Step: 3
Training loss: 4.5277627087883845
Validation loss: 4.515331892380728

Epoch: 5| Step: 4
Training loss: 4.582444792652712
Validation loss: 4.5108055786955275

Epoch: 5| Step: 5
Training loss: 4.514694593203117
Validation loss: 4.505620731008314

Epoch: 5| Step: 6
Training loss: 4.278159480934707
Validation loss: 4.500026826425346

Epoch: 5| Step: 7
Training loss: 5.417038224999295
Validation loss: 4.494479068687702

Epoch: 5| Step: 8
Training loss: 4.348290793835986
Validation loss: 4.489043088951327

Epoch: 5| Step: 9
Training loss: 4.148721171592415
Validation loss: 4.484322542067595

Epoch: 5| Step: 10
Training loss: 4.562377091933974
Validation loss: 4.481173711789758

Epoch: 5| Step: 11
Training loss: 5.262031211722763
Validation loss: 4.4744650302551605

Epoch: 23| Step: 0
Training loss: 4.336716920374322
Validation loss: 4.4703314323784396

Epoch: 5| Step: 1
Training loss: 4.438755985944574
Validation loss: 4.463614053335833

Epoch: 5| Step: 2
Training loss: 5.098441368239511
Validation loss: 4.460558543947353

Epoch: 5| Step: 3
Training loss: 5.531626887870451
Validation loss: 4.456028773455175

Epoch: 5| Step: 4
Training loss: 4.075226553955553
Validation loss: 4.450749273298576

Epoch: 5| Step: 5
Training loss: 4.742332695084682
Validation loss: 4.445366821672273

Epoch: 5| Step: 6
Training loss: 4.191290890260688
Validation loss: 4.4391915585122135

Epoch: 5| Step: 7
Training loss: 4.481789937071913
Validation loss: 4.43277229843941

Epoch: 5| Step: 8
Training loss: 5.1576308742232815
Validation loss: 4.427997430414409

Epoch: 5| Step: 9
Training loss: 3.759720855050006
Validation loss: 4.423179604753552

Epoch: 5| Step: 10
Training loss: 3.9794483318135607
Validation loss: 4.4179424371675

Epoch: 5| Step: 11
Training loss: 5.439559371157166
Validation loss: 4.411016920300138

Epoch: 24| Step: 0
Training loss: 4.889910075915211
Validation loss: 4.406020792056511

Epoch: 5| Step: 1
Training loss: 4.133737038821885
Validation loss: 4.401668971873706

Epoch: 5| Step: 2
Training loss: 4.808467215663566
Validation loss: 4.398150568491101

Epoch: 5| Step: 3
Training loss: 4.349259210408284
Validation loss: 4.392209727510265

Epoch: 5| Step: 4
Training loss: 4.659611864420768
Validation loss: 4.386654571127134

Epoch: 5| Step: 5
Training loss: 4.160354308665647
Validation loss: 4.378814324245811

Epoch: 5| Step: 6
Training loss: 4.389732188612893
Validation loss: 4.372024514307281

Epoch: 5| Step: 7
Training loss: 4.2039422017197605
Validation loss: 4.364537080263252

Epoch: 5| Step: 8
Training loss: 5.346258991011809
Validation loss: 4.358356220058842

Epoch: 5| Step: 9
Training loss: 4.420391359566313
Validation loss: 4.352950522528871

Epoch: 5| Step: 10
Training loss: 4.412801214640936
Validation loss: 4.3445201620970995

Epoch: 5| Step: 11
Training loss: 2.231645530883589
Validation loss: 4.338491646370314

Epoch: 25| Step: 0
Training loss: 4.400343378713295
Validation loss: 4.334463158673318

Epoch: 5| Step: 1
Training loss: 3.869085289349063
Validation loss: 4.329738935745317

Epoch: 5| Step: 2
Training loss: 4.663554561694582
Validation loss: 4.324398387381284

Epoch: 5| Step: 3
Training loss: 4.107895733558495
Validation loss: 4.317137790558963

Epoch: 5| Step: 4
Training loss: 4.904546551290883
Validation loss: 4.311360001193446

Epoch: 5| Step: 5
Training loss: 4.366242936131628
Validation loss: 4.305093791086186

Epoch: 5| Step: 6
Training loss: 4.639106065205722
Validation loss: 4.299055339303245

Epoch: 5| Step: 7
Training loss: 3.5897281864730077
Validation loss: 4.295092954144144

Epoch: 5| Step: 8
Training loss: 4.490349488112326
Validation loss: 4.28801656174753

Epoch: 5| Step: 9
Training loss: 4.825832773396433
Validation loss: 4.282610039122152

Epoch: 5| Step: 10
Training loss: 4.290183443713437
Validation loss: 4.27733634588103

Epoch: 5| Step: 11
Training loss: 6.297704296546344
Validation loss: 4.271852086453865

Epoch: 26| Step: 0
Training loss: 4.374729257108152
Validation loss: 4.265224349474229

Epoch: 5| Step: 1
Training loss: 3.8097267695698145
Validation loss: 4.259323537939665

Epoch: 5| Step: 2
Training loss: 3.9203663390116574
Validation loss: 4.253520713408642

Epoch: 5| Step: 3
Training loss: 4.155782113951319
Validation loss: 4.248547520860834

Epoch: 5| Step: 4
Training loss: 3.765389336140709
Validation loss: 4.243200219881547

Epoch: 5| Step: 5
Training loss: 4.830262929895621
Validation loss: 4.239988601334863

Epoch: 5| Step: 6
Training loss: 4.926739520066388
Validation loss: 4.232433216389012

Epoch: 5| Step: 7
Training loss: 4.35060292592783
Validation loss: 4.226625349196844

Epoch: 5| Step: 8
Training loss: 4.873656650225486
Validation loss: 4.221764408284795

Epoch: 5| Step: 9
Training loss: 3.900278272237907
Validation loss: 4.215889797090207

Epoch: 5| Step: 10
Training loss: 4.8758612630006475
Validation loss: 4.209537393656013

Epoch: 5| Step: 11
Training loss: 4.440008179940602
Validation loss: 4.204365524765973

Epoch: 27| Step: 0
Training loss: 4.367687544745547
Validation loss: 4.198653696766584

Epoch: 5| Step: 1
Training loss: 4.456005356160477
Validation loss: 4.1931340951139076

Epoch: 5| Step: 2
Training loss: 5.2238601974544485
Validation loss: 4.187745746594524

Epoch: 5| Step: 3
Training loss: 4.309268791322855
Validation loss: 4.182791966988885

Epoch: 5| Step: 4
Training loss: 4.918675524136876
Validation loss: 4.177398630103592

Epoch: 5| Step: 5
Training loss: 4.170331462246722
Validation loss: 4.17144427891811

Epoch: 5| Step: 6
Training loss: 3.6889418030075456
Validation loss: 4.165658212058589

Epoch: 5| Step: 7
Training loss: 3.8671527283001152
Validation loss: 4.1605607482356035

Epoch: 5| Step: 8
Training loss: 3.9646972629189077
Validation loss: 4.154912250508776

Epoch: 5| Step: 9
Training loss: 3.572820070849775
Validation loss: 4.150459515168154

Epoch: 5| Step: 10
Training loss: 4.251437673309943
Validation loss: 4.144404292821206

Epoch: 5| Step: 11
Training loss: 5.504497423228048
Validation loss: 4.140224379826061

Epoch: 28| Step: 0
Training loss: 4.326146303536163
Validation loss: 4.133986385089888

Epoch: 5| Step: 1
Training loss: 4.544883895079277
Validation loss: 4.128661428439489

Epoch: 5| Step: 2
Training loss: 4.187548053522672
Validation loss: 4.123563265812889

Epoch: 5| Step: 3
Training loss: 3.4775566137053584
Validation loss: 4.11805926267912

Epoch: 5| Step: 4
Training loss: 4.292905215208878
Validation loss: 4.113731564913515

Epoch: 5| Step: 5
Training loss: 4.614226293708489
Validation loss: 4.109607201652957

Epoch: 5| Step: 6
Training loss: 3.9200189461542156
Validation loss: 4.103387025987473

Epoch: 5| Step: 7
Training loss: 3.475802289162133
Validation loss: 4.098040707871145

Epoch: 5| Step: 8
Training loss: 3.5562636014815685
Validation loss: 4.09386593894728

Epoch: 5| Step: 9
Training loss: 5.377117006220339
Validation loss: 4.0892913649359945

Epoch: 5| Step: 10
Training loss: 4.234772723335993
Validation loss: 4.08435334226883

Epoch: 5| Step: 11
Training loss: 5.366955259315394
Validation loss: 4.0793152749277555

Epoch: 29| Step: 0
Training loss: 3.619035088307096
Validation loss: 4.0744947642933536

Epoch: 5| Step: 1
Training loss: 3.534235814437574
Validation loss: 4.0698696781541805

Epoch: 5| Step: 2
Training loss: 3.9920808363548574
Validation loss: 4.0643500150463705

Epoch: 5| Step: 3
Training loss: 4.074804832605866
Validation loss: 4.06006586070738

Epoch: 5| Step: 4
Training loss: 3.6481538780785616
Validation loss: 4.055546693414792

Epoch: 5| Step: 5
Training loss: 4.0668349392789285
Validation loss: 4.051342387312686

Epoch: 5| Step: 6
Training loss: 4.275519329449819
Validation loss: 4.046651365171618

Epoch: 5| Step: 7
Training loss: 4.501426470686386
Validation loss: 4.040521143114263

Epoch: 5| Step: 8
Training loss: 4.958568578102959
Validation loss: 4.035609177720914

Epoch: 5| Step: 9
Training loss: 4.44886463554581
Validation loss: 4.031362605924853

Epoch: 5| Step: 10
Training loss: 4.353598647354964
Validation loss: 4.026311042067891

Epoch: 5| Step: 11
Training loss: 5.4321136104068355
Validation loss: 4.020874219235228

Epoch: 30| Step: 0
Training loss: 4.054076867254181
Validation loss: 4.015880868480928

Epoch: 5| Step: 1
Training loss: 3.2549313033160376
Validation loss: 4.011080336049078

Epoch: 5| Step: 2
Training loss: 4.49604326711993
Validation loss: 4.006075353083873

Epoch: 5| Step: 3
Training loss: 4.320224643800412
Validation loss: 4.0017686946900355

Epoch: 5| Step: 4
Training loss: 3.9876975175016556
Validation loss: 3.996687053589184

Epoch: 5| Step: 5
Training loss: 4.535053209289169
Validation loss: 3.9926496612725755

Epoch: 5| Step: 6
Training loss: 4.210405701867269
Validation loss: 3.986369238539733

Epoch: 5| Step: 7
Training loss: 4.283179523561286
Validation loss: 3.981710018926854

Epoch: 5| Step: 8
Training loss: 3.437420375942166
Validation loss: 3.976502638530523

Epoch: 5| Step: 9
Training loss: 4.695660621064185
Validation loss: 3.972070956554849

Epoch: 5| Step: 10
Training loss: 4.0981382190188045
Validation loss: 3.9666198059861624

Epoch: 5| Step: 11
Training loss: 2.619208167881426
Validation loss: 3.961176421755197

Epoch: 31| Step: 0
Training loss: 3.947559283477555
Validation loss: 3.9575229752227714

Epoch: 5| Step: 1
Training loss: 4.022613026113913
Validation loss: 3.962187635582865

Epoch: 5| Step: 2
Training loss: 3.936980440284485
Validation loss: 3.955201856145544

Epoch: 5| Step: 3
Training loss: 4.267004439772483
Validation loss: 3.948082085853725

Epoch: 5| Step: 4
Training loss: 3.9533421151469463
Validation loss: 3.9423321309712884

Epoch: 5| Step: 5
Training loss: 5.059235073367108
Validation loss: 3.9378357547327347

Epoch: 5| Step: 6
Training loss: 4.267891864897585
Validation loss: 3.9326209968274997

Epoch: 5| Step: 7
Training loss: 3.2003088504042974
Validation loss: 3.9260778666172067

Epoch: 5| Step: 8
Training loss: 3.461015343059753
Validation loss: 3.9222147213128986

Epoch: 5| Step: 9
Training loss: 4.512990638498359
Validation loss: 3.9183710005239796

Epoch: 5| Step: 10
Training loss: 3.9235550522902125
Validation loss: 3.9130406673393656

Epoch: 5| Step: 11
Training loss: 3.726611762850816
Validation loss: 3.9089579033688318

Epoch: 32| Step: 0
Training loss: 4.513323874038708
Validation loss: 3.90347547034258

Epoch: 5| Step: 1
Training loss: 4.0768568617671495
Validation loss: 3.8983730751682186

Epoch: 5| Step: 2
Training loss: 4.0304160031651
Validation loss: 3.893568245741602

Epoch: 5| Step: 3
Training loss: 4.110849094346478
Validation loss: 3.8892698826051246

Epoch: 5| Step: 4
Training loss: 4.185718214236852
Validation loss: 3.8847038835669943

Epoch: 5| Step: 5
Training loss: 3.972924387537084
Validation loss: 3.8799856988243477

Epoch: 5| Step: 6
Training loss: 4.05716954228243
Validation loss: 3.8755125916782194

Epoch: 5| Step: 7
Training loss: 3.1108963661405853
Validation loss: 3.8699562256823805

Epoch: 5| Step: 8
Training loss: 3.9301320728890987
Validation loss: 3.8658721844798

Epoch: 5| Step: 9
Training loss: 3.7965611457618196
Validation loss: 3.860539702039832

Epoch: 5| Step: 10
Training loss: 4.080857804572781
Validation loss: 3.8561210093468667

Epoch: 5| Step: 11
Training loss: 4.678388361120815
Validation loss: 3.850899464536699

Epoch: 33| Step: 0
Training loss: 3.6056848463308007
Validation loss: 3.846251250250192

Epoch: 5| Step: 1
Training loss: 4.699860818303642
Validation loss: 3.8417813808721513

Epoch: 5| Step: 2
Training loss: 3.393043885792385
Validation loss: 3.8371990224582047

Epoch: 5| Step: 3
Training loss: 3.769385521794509
Validation loss: 3.832558951043715

Epoch: 5| Step: 4
Training loss: 4.331451569858119
Validation loss: 3.827966206689099

Epoch: 5| Step: 5
Training loss: 4.434510634473746
Validation loss: 3.8236985546058615

Epoch: 5| Step: 6
Training loss: 4.167728492225964
Validation loss: 3.8187478260589756

Epoch: 5| Step: 7
Training loss: 3.323931994324352
Validation loss: 3.8142770367495262

Epoch: 5| Step: 8
Training loss: 3.9375767776027684
Validation loss: 3.810195001975185

Epoch: 5| Step: 9
Training loss: 3.629784156540343
Validation loss: 3.806566509414556

Epoch: 5| Step: 10
Training loss: 4.065620515016022
Validation loss: 3.801361928285241

Epoch: 5| Step: 11
Training loss: 3.6394596444948046
Validation loss: 3.7967139943840076

Epoch: 34| Step: 0
Training loss: 3.6403874004582315
Validation loss: 3.79278667208049

Epoch: 5| Step: 1
Training loss: 4.405172662717603
Validation loss: 3.7883271437791732

Epoch: 5| Step: 2
Training loss: 4.774238781394628
Validation loss: 3.783822028208919

Epoch: 5| Step: 3
Training loss: 3.9486791164681314
Validation loss: 3.779610407109957

Epoch: 5| Step: 4
Training loss: 3.8901065343081034
Validation loss: 3.775153655068174

Epoch: 5| Step: 5
Training loss: 3.916090388547539
Validation loss: 3.770181044473663

Epoch: 5| Step: 6
Training loss: 3.522963938216391
Validation loss: 3.765843254507364

Epoch: 5| Step: 7
Training loss: 4.3081795985366105
Validation loss: 3.76171966373146

Epoch: 5| Step: 8
Training loss: 3.744055550513645
Validation loss: 3.757327222254864

Epoch: 5| Step: 9
Training loss: 2.5622525909824616
Validation loss: 3.7530192830116973

Epoch: 5| Step: 10
Training loss: 3.7951951569045432
Validation loss: 3.748621729714454

Epoch: 5| Step: 11
Training loss: 4.221150937170454
Validation loss: 3.744829183858332

Epoch: 35| Step: 0
Training loss: 3.778892854292595
Validation loss: 3.7407372145790028

Epoch: 5| Step: 1
Training loss: 3.142279497542163
Validation loss: 3.736423840171685

Epoch: 5| Step: 2
Training loss: 4.437826655010522
Validation loss: 3.7322120946900883

Epoch: 5| Step: 3
Training loss: 3.9773851304457697
Validation loss: 3.728278883779567

Epoch: 5| Step: 4
Training loss: 4.1983052240339065
Validation loss: 3.7241785406704553

Epoch: 5| Step: 5
Training loss: 3.9303287415200345
Validation loss: 3.719588588546938

Epoch: 5| Step: 6
Training loss: 3.6969865229110503
Validation loss: 3.7158091160208286

Epoch: 5| Step: 7
Training loss: 3.982957415752245
Validation loss: 3.7121466771433678

Epoch: 5| Step: 8
Training loss: 3.7020374101328244
Validation loss: 3.7077386179176948

Epoch: 5| Step: 9
Training loss: 3.017526294053249
Validation loss: 3.703529915220278

Epoch: 5| Step: 10
Training loss: 4.189489091483143
Validation loss: 3.6995400675592967

Epoch: 5| Step: 11
Training loss: 4.392796098415662
Validation loss: 3.6955496649415776

Epoch: 36| Step: 0
Training loss: 3.50210889224125
Validation loss: 3.69119611407756

Epoch: 5| Step: 1
Training loss: 3.908206907286713
Validation loss: 3.6870882483304577

Epoch: 5| Step: 2
Training loss: 3.459750486428859
Validation loss: 3.6828965369676157

Epoch: 5| Step: 3
Training loss: 3.3981745475677534
Validation loss: 3.6787418789157718

Epoch: 5| Step: 4
Training loss: 4.13261450597915
Validation loss: 3.6749506250727944

Epoch: 5| Step: 5
Training loss: 4.220940367435818
Validation loss: 3.670691528063837

Epoch: 5| Step: 6
Training loss: 3.4816328129295
Validation loss: 3.667030731824863

Epoch: 5| Step: 7
Training loss: 3.4572901397146953
Validation loss: 3.66282513621524

Epoch: 5| Step: 8
Training loss: 3.2113498692112183
Validation loss: 3.6589914135515498

Epoch: 5| Step: 9
Training loss: 4.293635586431651
Validation loss: 3.6548751463223854

Epoch: 5| Step: 10
Training loss: 4.189098679280661
Validation loss: 3.650868729628248

Epoch: 5| Step: 11
Training loss: 5.430242847611256
Validation loss: 3.6465929093884

Epoch: 37| Step: 0
Training loss: 4.023941867658736
Validation loss: 3.642549404545824

Epoch: 5| Step: 1
Training loss: 4.000124452562236
Validation loss: 3.638251774019817

Epoch: 5| Step: 2
Training loss: 3.7476715488372068
Validation loss: 3.6337556742626145

Epoch: 5| Step: 3
Training loss: 3.9313135138931674
Validation loss: 3.6290492100473526

Epoch: 5| Step: 4
Training loss: 3.6715542267633032
Validation loss: 3.624854594635832

Epoch: 5| Step: 5
Training loss: 3.917269856424466
Validation loss: 3.6205988288213167

Epoch: 5| Step: 6
Training loss: 3.9044249887137896
Validation loss: 3.616732294758763

Epoch: 5| Step: 7
Training loss: 4.033013010047077
Validation loss: 3.6121994901136283

Epoch: 5| Step: 8
Training loss: 3.7978811932342436
Validation loss: 3.6078832441806123

Epoch: 5| Step: 9
Training loss: 3.279744847538237
Validation loss: 3.603614084885257

Epoch: 5| Step: 10
Training loss: 2.9868438255469614
Validation loss: 3.599753294323965

Epoch: 5| Step: 11
Training loss: 3.2721282598637575
Validation loss: 3.595750721718831

Epoch: 38| Step: 0
Training loss: 3.223748187404447
Validation loss: 3.592115926340624

Epoch: 5| Step: 1
Training loss: 3.633156643225539
Validation loss: 3.5881967512597095

Epoch: 5| Step: 2
Training loss: 2.922293566746261
Validation loss: 3.584392283940348

Epoch: 5| Step: 3
Training loss: 4.0098804990699275
Validation loss: 3.5812973440967606

Epoch: 5| Step: 4
Training loss: 3.580423607938071
Validation loss: 3.577161950854688

Epoch: 5| Step: 5
Training loss: 3.8037683524229027
Validation loss: 3.573564830224515

Epoch: 5| Step: 6
Training loss: 3.7699221077317047
Validation loss: 3.570275577101044

Epoch: 5| Step: 7
Training loss: 4.262808180600521
Validation loss: 3.5659259084095765

Epoch: 5| Step: 8
Training loss: 3.253249231434415
Validation loss: 3.5619749329209864

Epoch: 5| Step: 9
Training loss: 3.9519259477619566
Validation loss: 3.558533964970438

Epoch: 5| Step: 10
Training loss: 4.0891823948916
Validation loss: 3.555134084965493

Epoch: 5| Step: 11
Training loss: 4.076162282496499
Validation loss: 3.550754391743856

Epoch: 39| Step: 0
Training loss: 3.4968877306340818
Validation loss: 3.5469156282537515

Epoch: 5| Step: 1
Training loss: 3.468098897225611
Validation loss: 3.5432748238259566

Epoch: 5| Step: 2
Training loss: 3.730406116538992
Validation loss: 3.539696749568491

Epoch: 5| Step: 3
Training loss: 2.938233953458912
Validation loss: 3.5361500279343665

Epoch: 5| Step: 4
Training loss: 3.5524185484877955
Validation loss: 3.5322240200706796

Epoch: 5| Step: 5
Training loss: 3.5364616892166207
Validation loss: 3.5283371043076244

Epoch: 5| Step: 6
Training loss: 3.4574982580923903
Validation loss: 3.5246939720168573

Epoch: 5| Step: 7
Training loss: 3.8135814696277675
Validation loss: 3.521548665003408

Epoch: 5| Step: 8
Training loss: 4.372671106915421
Validation loss: 3.5181215704167426

Epoch: 5| Step: 9
Training loss: 3.869677056334896
Validation loss: 3.5140198723794347

Epoch: 5| Step: 10
Training loss: 3.951464157117631
Validation loss: 3.5099346818579287

Epoch: 5| Step: 11
Training loss: 3.41382086485786
Validation loss: 3.506223713849382

Epoch: 40| Step: 0
Training loss: 3.910724000365054
Validation loss: 3.5017796374337014

Epoch: 5| Step: 1
Training loss: 3.8314900458404577
Validation loss: 3.4981169034223405

Epoch: 5| Step: 2
Training loss: 4.018908631321949
Validation loss: 3.4937218432352437

Epoch: 5| Step: 3
Training loss: 3.2832625257212036
Validation loss: 3.490050649903903

Epoch: 5| Step: 4
Training loss: 3.177549350934539
Validation loss: 3.486064683664976

Epoch: 5| Step: 5
Training loss: 3.4556308129617554
Validation loss: 3.48195016989237

Epoch: 5| Step: 6
Training loss: 3.6381295619582774
Validation loss: 3.4784779504659573

Epoch: 5| Step: 7
Training loss: 3.4180059986809623
Validation loss: 3.4743690743567086

Epoch: 5| Step: 8
Training loss: 4.207910472410653
Validation loss: 3.470494384441954

Epoch: 5| Step: 9
Training loss: 3.7745861256059188
Validation loss: 3.466563741519304

Epoch: 5| Step: 10
Training loss: 3.2243738024850432
Validation loss: 3.462802378789985

Epoch: 5| Step: 11
Training loss: 1.9229056843299015
Validation loss: 3.458642639361501

Epoch: 41| Step: 0
Training loss: 3.4402350902069343
Validation loss: 3.455197663051601

Epoch: 5| Step: 1
Training loss: 3.533217430612968
Validation loss: 3.4519433751547197

Epoch: 5| Step: 2
Training loss: 3.416045496849808
Validation loss: 3.4484002483956044

Epoch: 5| Step: 3
Training loss: 3.63498129145912
Validation loss: 3.44531049317455

Epoch: 5| Step: 4
Training loss: 3.4477470947855284
Validation loss: 3.443641534194487

Epoch: 5| Step: 5
Training loss: 4.226966147618213
Validation loss: 3.4393284760820615

Epoch: 5| Step: 6
Training loss: 3.227978411851661
Validation loss: 3.4355221867284214

Epoch: 5| Step: 7
Training loss: 3.79143445208641
Validation loss: 3.432938650316801

Epoch: 5| Step: 8
Training loss: 3.8098539331426244
Validation loss: 3.4286474448199336

Epoch: 5| Step: 9
Training loss: 3.6534590543105088
Validation loss: 3.424543835086159

Epoch: 5| Step: 10
Training loss: 2.783426697434778
Validation loss: 3.421427437647188

Epoch: 5| Step: 11
Training loss: 4.431038033348226
Validation loss: 3.4183931853753537

Epoch: 42| Step: 0
Training loss: 3.93552082516968
Validation loss: 3.414656493586508

Epoch: 5| Step: 1
Training loss: 3.509069408722828
Validation loss: 3.411013978551298

Epoch: 5| Step: 2
Training loss: 3.43824787674101
Validation loss: 3.4074428989330756

Epoch: 5| Step: 3
Training loss: 3.463979103553946
Validation loss: 3.403720657394002

Epoch: 5| Step: 4
Training loss: 3.839587803612251
Validation loss: 3.40017657452568

Epoch: 5| Step: 5
Training loss: 3.3145060672701603
Validation loss: 3.396480227601859

Epoch: 5| Step: 6
Training loss: 3.815020869086745
Validation loss: 3.3927474637576647

Epoch: 5| Step: 7
Training loss: 3.4758368602787533
Validation loss: 3.3895044745892955

Epoch: 5| Step: 8
Training loss: 3.6537622318591625
Validation loss: 3.385618548120383

Epoch: 5| Step: 9
Training loss: 3.147891771145291
Validation loss: 3.3821969151282865

Epoch: 5| Step: 10
Training loss: 3.309822583932464
Validation loss: 3.3786908913486338

Epoch: 5| Step: 11
Training loss: 3.068009073037629
Validation loss: 3.3755183822575066

Epoch: 43| Step: 0
Training loss: 4.011650760895392
Validation loss: 3.372002518546211

Epoch: 5| Step: 1
Training loss: 2.613310900692449
Validation loss: 3.368616159501589

Epoch: 5| Step: 2
Training loss: 3.618305206634644
Validation loss: 3.3654893220255944

Epoch: 5| Step: 3
Training loss: 3.5640207357606157
Validation loss: 3.3620793184609497

Epoch: 5| Step: 4
Training loss: 3.7562267740708988
Validation loss: 3.3589240843494075

Epoch: 5| Step: 5
Training loss: 3.2879783311394375
Validation loss: 3.3551203465800223

Epoch: 5| Step: 6
Training loss: 3.7147890682588254
Validation loss: 3.3517664304163497

Epoch: 5| Step: 7
Training loss: 3.7399857640122973
Validation loss: 3.348492091082925

Epoch: 5| Step: 8
Training loss: 3.8606261414570517
Validation loss: 3.345616874169489

Epoch: 5| Step: 9
Training loss: 2.5974756163700015
Validation loss: 3.34208990343627

Epoch: 5| Step: 10
Training loss: 3.3698903717411506
Validation loss: 3.3392835180655673

Epoch: 5| Step: 11
Training loss: 3.4686183045277383
Validation loss: 3.335916720108957

Epoch: 44| Step: 0
Training loss: 3.4832874191640912
Validation loss: 3.3323743970704847

Epoch: 5| Step: 1
Training loss: 3.595191997977206
Validation loss: 3.3291606157428495

Epoch: 5| Step: 2
Training loss: 3.9107383881564597
Validation loss: 3.325450712264783

Epoch: 5| Step: 3
Training loss: 3.297773049063547
Validation loss: 3.322134318477031

Epoch: 5| Step: 4
Training loss: 3.403535934032142
Validation loss: 3.3185041791558034

Epoch: 5| Step: 5
Training loss: 3.3382448886754217
Validation loss: 3.315169464371224

Epoch: 5| Step: 6
Training loss: 3.3040179212328926
Validation loss: 3.312042240686614

Epoch: 5| Step: 7
Training loss: 3.3558208738224717
Validation loss: 3.308806897788541

Epoch: 5| Step: 8
Training loss: 3.108677618137381
Validation loss: 3.3061616524019897

Epoch: 5| Step: 9
Training loss: 3.6806342654339117
Validation loss: 3.302973315444241

Epoch: 5| Step: 10
Training loss: 3.372689197795545
Validation loss: 3.299272048499205

Epoch: 5| Step: 11
Training loss: 3.9182818849583394
Validation loss: 3.2964633787140207

Epoch: 45| Step: 0
Training loss: 3.7390263531376733
Validation loss: 3.293542967990777

Epoch: 5| Step: 1
Training loss: 3.0955561750413954
Validation loss: 3.2898688275605807

Epoch: 5| Step: 2
Training loss: 3.8944923146405035
Validation loss: 3.2860063986720798

Epoch: 5| Step: 3
Training loss: 2.91851074414402
Validation loss: 3.2831543255594084

Epoch: 5| Step: 4
Training loss: 3.4427270162578503
Validation loss: 3.2801070357076774

Epoch: 5| Step: 5
Training loss: 2.8028314341044753
Validation loss: 3.2770027040787237

Epoch: 5| Step: 6
Training loss: 3.675135686536366
Validation loss: 3.274241395018079

Epoch: 5| Step: 7
Training loss: 3.693748998238416
Validation loss: 3.2709296702312525

Epoch: 5| Step: 8
Training loss: 3.8233394683504867
Validation loss: 3.267344641072491

Epoch: 5| Step: 9
Training loss: 2.9261943693547856
Validation loss: 3.2642910436781714

Epoch: 5| Step: 10
Training loss: 3.4909948578236367
Validation loss: 3.261247057890866

Epoch: 5| Step: 11
Training loss: 2.569309119936775
Validation loss: 3.25828790283402

Epoch: 46| Step: 0
Training loss: 3.3640059378227964
Validation loss: 3.2549160248803233

Epoch: 5| Step: 1
Training loss: 3.179418604022901
Validation loss: 3.2515283133380626

Epoch: 5| Step: 2
Training loss: 3.1861901677448854
Validation loss: 3.248399236348828

Epoch: 5| Step: 3
Training loss: 3.8127939079687425
Validation loss: 3.2455983462905227

Epoch: 5| Step: 4
Training loss: 3.053179668768727
Validation loss: 3.2419708547252832

Epoch: 5| Step: 5
Training loss: 3.555898472687189
Validation loss: 3.2388065895212192

Epoch: 5| Step: 6
Training loss: 2.964496818418528
Validation loss: 3.2361199406588432

Epoch: 5| Step: 7
Training loss: 3.8359043096594276
Validation loss: 3.232799680821781

Epoch: 5| Step: 8
Training loss: 3.0055049615418272
Validation loss: 3.229216124043066

Epoch: 5| Step: 9
Training loss: 3.534107233861147
Validation loss: 3.2259639126246578

Epoch: 5| Step: 10
Training loss: 3.655722425169906
Validation loss: 3.22286450570492

Epoch: 5| Step: 11
Training loss: 2.739793650938943
Validation loss: 3.220022184688448

Epoch: 47| Step: 0
Training loss: 3.4607300018039173
Validation loss: 3.217036176781471

Epoch: 5| Step: 1
Training loss: 3.247676018459049
Validation loss: 3.213749300257932

Epoch: 5| Step: 2
Training loss: 3.115933809118483
Validation loss: 3.211313564433182

Epoch: 5| Step: 3
Training loss: 3.5311307633785827
Validation loss: 3.2088965730734347

Epoch: 5| Step: 4
Training loss: 2.860372400647465
Validation loss: 3.2060336421074798

Epoch: 5| Step: 5
Training loss: 3.355754373848381
Validation loss: 3.202680479389402

Epoch: 5| Step: 6
Training loss: 3.2140958154682853
Validation loss: 3.2004339714875374

Epoch: 5| Step: 7
Training loss: 3.025851446707036
Validation loss: 3.1971581250083116

Epoch: 5| Step: 8
Training loss: 3.277902985101348
Validation loss: 3.1941590251892578

Epoch: 5| Step: 9
Training loss: 4.279108110353461
Validation loss: 3.1914695692998656

Epoch: 5| Step: 10
Training loss: 3.3531752043109324
Validation loss: 3.189165833197901

Epoch: 5| Step: 11
Training loss: 2.5855522675550917
Validation loss: 3.186161159006637

Epoch: 48| Step: 0
Training loss: 3.0199506500456157
Validation loss: 3.183575857537351

Epoch: 5| Step: 1
Training loss: 2.8428326479040686
Validation loss: 3.180684285679835

Epoch: 5| Step: 2
Training loss: 3.3514143904391878
Validation loss: 3.178453585612402

Epoch: 5| Step: 3
Training loss: 3.745210513626949
Validation loss: 3.1755707105202746

Epoch: 5| Step: 4
Training loss: 3.020383253221003
Validation loss: 3.172847094600683

Epoch: 5| Step: 5
Training loss: 3.9569656954096075
Validation loss: 3.1704048138284646

Epoch: 5| Step: 6
Training loss: 3.3496643239844235
Validation loss: 3.1673704617985914

Epoch: 5| Step: 7
Training loss: 3.0043846513352297
Validation loss: 3.1649387857303735

Epoch: 5| Step: 8
Training loss: 3.228795938848053
Validation loss: 3.1623344883184

Epoch: 5| Step: 9
Training loss: 3.2982539325992244
Validation loss: 3.1599080695992696

Epoch: 5| Step: 10
Training loss: 3.3748140637077486
Validation loss: 3.1572634262857493

Epoch: 5| Step: 11
Training loss: 3.6193082125256835
Validation loss: 3.154381384568782

Epoch: 49| Step: 0
Training loss: 3.924393411402702
Validation loss: 3.151789720924596

Epoch: 5| Step: 1
Training loss: 3.3055580381353833
Validation loss: 3.1487662030982198

Epoch: 5| Step: 2
Training loss: 3.156202108189794
Validation loss: 3.146009621301721

Epoch: 5| Step: 3
Training loss: 2.976162941214935
Validation loss: 3.142793631015128

Epoch: 5| Step: 4
Training loss: 3.228130707638801
Validation loss: 3.139932742775382

Epoch: 5| Step: 5
Training loss: 3.656812575659433
Validation loss: 3.1372762764934206

Epoch: 5| Step: 6
Training loss: 3.3651340533871195
Validation loss: 3.134595007130347

Epoch: 5| Step: 7
Training loss: 3.2410598448419123
Validation loss: 3.1318189229761746

Epoch: 5| Step: 8
Training loss: 3.136826984823174
Validation loss: 3.1290586182843794

Epoch: 5| Step: 9
Training loss: 3.43639980396212
Validation loss: 3.1265184400949995

Epoch: 5| Step: 10
Training loss: 2.492776544012011
Validation loss: 3.123203632300527

Epoch: 5| Step: 11
Training loss: 3.0788796366364393
Validation loss: 3.1212641415258466

Epoch: 50| Step: 0
Training loss: 3.1003101808969755
Validation loss: 3.1185467082335037

Epoch: 5| Step: 1
Training loss: 2.925618593713779
Validation loss: 3.115828521417366

Epoch: 5| Step: 2
Training loss: 3.173619283994413
Validation loss: 3.113605365929002

Epoch: 5| Step: 3
Training loss: 2.9930335858082793
Validation loss: 3.1104595459019895

Epoch: 5| Step: 4
Training loss: 3.6102867130959053
Validation loss: 3.1080895455273416

Epoch: 5| Step: 5
Training loss: 3.272059330306736
Validation loss: 3.1054675280170714

Epoch: 5| Step: 6
Training loss: 3.1085164020480507
Validation loss: 3.1030499585295774

Epoch: 5| Step: 7
Training loss: 2.9620661937006503
Validation loss: 3.1006270598640717

Epoch: 5| Step: 8
Training loss: 3.610533161048552
Validation loss: 3.0982693245486534

Epoch: 5| Step: 9
Training loss: 3.617527461708931
Validation loss: 3.0957918685884747

Epoch: 5| Step: 10
Training loss: 3.2561414352740865
Validation loss: 3.093581246419922

Epoch: 5| Step: 11
Training loss: 3.1528102146744987
Validation loss: 3.0910121735639877

Epoch: 51| Step: 0
Training loss: 3.7293220075649676
Validation loss: 3.088648636087529

Epoch: 5| Step: 1
Training loss: 3.233295352620956
Validation loss: 3.0855653337202664

Epoch: 5| Step: 2
Training loss: 2.692817838251162
Validation loss: 3.08324218091172

Epoch: 5| Step: 3
Training loss: 2.9493605421730065
Validation loss: 3.0804781270011423

Epoch: 5| Step: 4
Training loss: 3.446480689230008
Validation loss: 3.078294313682958

Epoch: 5| Step: 5
Training loss: 3.2904729650430498
Validation loss: 3.076037375118484

Epoch: 5| Step: 6
Training loss: 2.8733303363309424
Validation loss: 3.0739164741033376

Epoch: 5| Step: 7
Training loss: 3.8920813596166624
Validation loss: 3.0703706096815586

Epoch: 5| Step: 8
Training loss: 2.9342643286296743
Validation loss: 3.0684126621267622

Epoch: 5| Step: 9
Training loss: 3.167699009786372
Validation loss: 3.066139854311709

Epoch: 5| Step: 10
Training loss: 3.0004081448437194
Validation loss: 3.0634368514508084

Epoch: 5| Step: 11
Training loss: 3.078810252484031
Validation loss: 3.060748819270944

Epoch: 52| Step: 0
Training loss: 3.7564383867345037
Validation loss: 3.058858448330631

Epoch: 5| Step: 1
Training loss: 3.0833994024947815
Validation loss: 3.0568048337595766

Epoch: 5| Step: 2
Training loss: 3.4569197986978097
Validation loss: 3.05402200511515

Epoch: 5| Step: 3
Training loss: 3.1513856474126207
Validation loss: 3.051554426816388

Epoch: 5| Step: 4
Training loss: 2.7551161252452547
Validation loss: 3.049842393690688

Epoch: 5| Step: 5
Training loss: 2.4683855970860993
Validation loss: 3.0474757718924366

Epoch: 5| Step: 6
Training loss: 3.121681282211552
Validation loss: 3.044630061552735

Epoch: 5| Step: 7
Training loss: 3.167566238589888
Validation loss: 3.042811809601225

Epoch: 5| Step: 8
Training loss: 3.364462189909636
Validation loss: 3.040468193211109

Epoch: 5| Step: 9
Training loss: 3.4670518722240633
Validation loss: 3.037854344299838

Epoch: 5| Step: 10
Training loss: 3.211153417599711
Validation loss: 3.0362271154888485

Epoch: 5| Step: 11
Training loss: 2.58384956821329
Validation loss: 3.033693839272314

Epoch: 53| Step: 0
Training loss: 3.6492916308152576
Validation loss: 3.031260939378433

Epoch: 5| Step: 1
Training loss: 3.244653559032096
Validation loss: 3.029120929789007

Epoch: 5| Step: 2
Training loss: 2.856710391012305
Validation loss: 3.0270795349986397

Epoch: 5| Step: 3
Training loss: 3.144743690659677
Validation loss: 3.0239379494917724

Epoch: 5| Step: 4
Training loss: 3.335067027961155
Validation loss: 3.022439862713447

Epoch: 5| Step: 5
Training loss: 3.3872057290725657
Validation loss: 3.0204408796286004

Epoch: 5| Step: 6
Training loss: 2.6762767917622963
Validation loss: 3.0184287114154804

Epoch: 5| Step: 7
Training loss: 3.530584762162974
Validation loss: 3.0154094058962277

Epoch: 5| Step: 8
Training loss: 3.059086980305753
Validation loss: 3.013527583856221

Epoch: 5| Step: 9
Training loss: 2.9756216729988227
Validation loss: 3.011069739538659

Epoch: 5| Step: 10
Training loss: 2.7862529548228885
Validation loss: 3.0087991062431256

Epoch: 5| Step: 11
Training loss: 3.1124755123048384
Validation loss: 3.0064864203793853

Epoch: 54| Step: 0
Training loss: 2.823099888184655
Validation loss: 3.0048544866586187

Epoch: 5| Step: 1
Training loss: 2.755680113544312
Validation loss: 3.0022847991960817

Epoch: 5| Step: 2
Training loss: 3.0500912637032593
Validation loss: 3.000296356212835

Epoch: 5| Step: 3
Training loss: 3.1991421384103784
Validation loss: 2.9980228816593435

Epoch: 5| Step: 4
Training loss: 2.9352541515521446
Validation loss: 2.9962701824284594

Epoch: 5| Step: 5
Training loss: 2.69103017983866
Validation loss: 2.994035088988613

Epoch: 5| Step: 6
Training loss: 3.700859696803212
Validation loss: 2.992174684714554

Epoch: 5| Step: 7
Training loss: 3.549919535839862
Validation loss: 2.989881903773163

Epoch: 5| Step: 8
Training loss: 3.1056927678143245
Validation loss: 2.9878685959273086

Epoch: 5| Step: 9
Training loss: 3.5260794265205297
Validation loss: 2.9858543697158755

Epoch: 5| Step: 10
Training loss: 3.0431585093572977
Validation loss: 2.984029140703411

Epoch: 5| Step: 11
Training loss: 2.830420642499763
Validation loss: 2.981803621780937

Epoch: 55| Step: 0
Training loss: 3.443532055502453
Validation loss: 2.980002760549841

Epoch: 5| Step: 1
Training loss: 3.2950742603784655
Validation loss: 2.9779274848640784

Epoch: 5| Step: 2
Training loss: 2.376170723127957
Validation loss: 2.9759021169977227

Epoch: 5| Step: 3
Training loss: 3.3175034072961966
Validation loss: 2.9742011234478247

Epoch: 5| Step: 4
Training loss: 2.3837829614769834
Validation loss: 2.9720680700912316

Epoch: 5| Step: 5
Training loss: 3.283861265646239
Validation loss: 2.9698972760630578

Epoch: 5| Step: 6
Training loss: 3.5135137703711083
Validation loss: 2.9681798086208704

Epoch: 5| Step: 7
Training loss: 2.9536508566304067
Validation loss: 2.966340120877983

Epoch: 5| Step: 8
Training loss: 3.1194616449941877
Validation loss: 2.9648064102951035

Epoch: 5| Step: 9
Training loss: 2.9947014748080942
Validation loss: 2.962225513913904

Epoch: 5| Step: 10
Training loss: 3.485458274056367
Validation loss: 2.960661164794954

Epoch: 5| Step: 11
Training loss: 1.928846538943593
Validation loss: 2.9582293060083127

Epoch: 56| Step: 0
Training loss: 3.270924917182107
Validation loss: 2.9567984082403997

Epoch: 5| Step: 1
Training loss: 3.5557634339227997
Validation loss: 2.9542853482667275

Epoch: 5| Step: 2
Training loss: 3.099875041535114
Validation loss: 2.9522004404218807

Epoch: 5| Step: 3
Training loss: 2.8678159103049046
Validation loss: 2.950588075163962

Epoch: 5| Step: 4
Training loss: 3.318502637477308
Validation loss: 2.9482923488471044

Epoch: 5| Step: 5
Training loss: 2.816973709736684
Validation loss: 2.9465876550099996

Epoch: 5| Step: 6
Training loss: 2.5371644423031783
Validation loss: 2.9442349460334962

Epoch: 5| Step: 7
Training loss: 3.190381412006588
Validation loss: 2.9420491158167175

Epoch: 5| Step: 8
Training loss: 3.1079185563638445
Validation loss: 2.9402567359571026

Epoch: 5| Step: 9
Training loss: 3.249216278654912
Validation loss: 2.9379174598685927

Epoch: 5| Step: 10
Training loss: 2.989132270058532
Validation loss: 2.9362708320219717

Epoch: 5| Step: 11
Training loss: 2.2432706655598165
Validation loss: 2.9359955113830956

Epoch: 57| Step: 0
Training loss: 3.67029527811985
Validation loss: 2.935906813486361

Epoch: 5| Step: 1
Training loss: 2.7326208100831
Validation loss: 2.931999233744271

Epoch: 5| Step: 2
Training loss: 2.8577499357771963
Validation loss: 2.9295402761131046

Epoch: 5| Step: 3
Training loss: 3.514294724447328
Validation loss: 2.9285842852858535

Epoch: 5| Step: 4
Training loss: 2.945209855534856
Validation loss: 2.9248144082750085

Epoch: 5| Step: 5
Training loss: 3.6047168083967143
Validation loss: 2.9232100192496415

Epoch: 5| Step: 6
Training loss: 2.8233752752053904
Validation loss: 2.922367289069542

Epoch: 5| Step: 7
Training loss: 2.6476165489356185
Validation loss: 2.9198821202254237

Epoch: 5| Step: 8
Training loss: 3.1319883408798357
Validation loss: 2.9188498920334816

Epoch: 5| Step: 9
Training loss: 3.0234878102140885
Validation loss: 2.915768349909962

Epoch: 5| Step: 10
Training loss: 2.857303390080211
Validation loss: 2.9157109170556788

Epoch: 5| Step: 11
Training loss: 0.7368865791815253
Validation loss: 2.912402555502806

Epoch: 58| Step: 0
Training loss: 2.9056136552372163
Validation loss: 2.911661128497593

Epoch: 5| Step: 1
Training loss: 3.246909652980307
Validation loss: 2.9106214932286862

Epoch: 5| Step: 2
Training loss: 3.3494368350241217
Validation loss: 2.9079558722345644

Epoch: 5| Step: 3
Training loss: 3.3918273481568293
Validation loss: 2.9067421021391784

Epoch: 5| Step: 4
Training loss: 3.2000315545433677
Validation loss: 2.9056696534522355

Epoch: 5| Step: 5
Training loss: 2.4222629359475985
Validation loss: 2.904714629983839

Epoch: 5| Step: 6
Training loss: 2.6586172886965787
Validation loss: 2.9024480644363537

Epoch: 5| Step: 7
Training loss: 2.777598781116719
Validation loss: 2.9001681361292166

Epoch: 5| Step: 8
Training loss: 3.4225842163335454
Validation loss: 2.898421514557853

Epoch: 5| Step: 9
Training loss: 2.9525575445835344
Validation loss: 2.8963743751853044

Epoch: 5| Step: 10
Training loss: 3.026452269193671
Validation loss: 2.8941083694413177

Epoch: 5| Step: 11
Training loss: 2.9240022962902983
Validation loss: 2.892463099673744

Epoch: 59| Step: 0
Training loss: 3.126572937878863
Validation loss: 2.890877954910793

Epoch: 5| Step: 1
Training loss: 2.899416529396475
Validation loss: 2.889158987191506

Epoch: 5| Step: 2
Training loss: 3.17162167895256
Validation loss: 2.8876891271021603

Epoch: 5| Step: 3
Training loss: 3.434141703379696
Validation loss: 2.886293048639485

Epoch: 5| Step: 4
Training loss: 3.022536190248564
Validation loss: 2.884873622559249

Epoch: 5| Step: 5
Training loss: 3.028752979713199
Validation loss: 2.884495269014831

Epoch: 5| Step: 6
Training loss: 3.2343807496835217
Validation loss: 2.883444264562024

Epoch: 5| Step: 7
Training loss: 2.572906391159316
Validation loss: 2.880553072578131

Epoch: 5| Step: 8
Training loss: 2.6662083370997225
Validation loss: 2.877998778384694

Epoch: 5| Step: 9
Training loss: 2.7773006559266578
Validation loss: 2.8753757818628634

Epoch: 5| Step: 10
Training loss: 3.15266849778428
Validation loss: 2.8738859927751568

Epoch: 5| Step: 11
Training loss: 3.427759554083091
Validation loss: 2.8718552252165104

Epoch: 60| Step: 0
Training loss: 2.971082875033509
Validation loss: 2.8706192454906003

Epoch: 5| Step: 1
Training loss: 2.9149626704290945
Validation loss: 2.868885542244596

Epoch: 5| Step: 2
Training loss: 2.973736560433586
Validation loss: 2.866242439231211

Epoch: 5| Step: 3
Training loss: 2.723539671565357
Validation loss: 2.8674081410841294

Epoch: 5| Step: 4
Training loss: 2.530102410788134
Validation loss: 2.8666547580035466

Epoch: 5| Step: 5
Training loss: 3.253439330526542
Validation loss: 2.865257063734441

Epoch: 5| Step: 6
Training loss: 3.381058658960899
Validation loss: 2.8647498804863543

Epoch: 5| Step: 7
Training loss: 3.1404704345322054
Validation loss: 2.861434701924506

Epoch: 5| Step: 8
Training loss: 3.6734228889177998
Validation loss: 2.857287581289395

Epoch: 5| Step: 9
Training loss: 2.7122871491205847
Validation loss: 2.8555010973363215

Epoch: 5| Step: 10
Training loss: 2.8654675223074726
Validation loss: 2.8538323830827217

Epoch: 5| Step: 11
Training loss: 1.1063673592940289
Validation loss: 2.8525171711120967

Epoch: 61| Step: 0
Training loss: 2.5077519394642036
Validation loss: 2.8513862938633494

Epoch: 5| Step: 1
Training loss: 3.455659100479326
Validation loss: 2.849758298563142

Epoch: 5| Step: 2
Training loss: 2.927477193559505
Validation loss: 2.848039930020626

Epoch: 5| Step: 3
Training loss: 2.867571480216811
Validation loss: 2.846905791265836

Epoch: 5| Step: 4
Training loss: 2.447124066106124
Validation loss: 2.8449658529917414

Epoch: 5| Step: 5
Training loss: 2.896303609813675
Validation loss: 2.843537214373835

Epoch: 5| Step: 6
Training loss: 3.1481338240935464
Validation loss: 2.8419886468631033

Epoch: 5| Step: 7
Training loss: 3.2310422967086203
Validation loss: 2.8398972182244893

Epoch: 5| Step: 8
Training loss: 2.843900404086229
Validation loss: 2.8391634595461164

Epoch: 5| Step: 9
Training loss: 2.7557255356242667
Validation loss: 2.8368190379596028

Epoch: 5| Step: 10
Training loss: 3.453637132598697
Validation loss: 2.835843798417892

Epoch: 5| Step: 11
Training loss: 3.5679501787992436
Validation loss: 2.834161305529504

Epoch: 62| Step: 0
Training loss: 2.74272554775872
Validation loss: 2.832262511183381

Epoch: 5| Step: 1
Training loss: 2.7993247103405743
Validation loss: 2.8308461658451574

Epoch: 5| Step: 2
Training loss: 3.05419558883927
Validation loss: 2.829173619023481

Epoch: 5| Step: 3
Training loss: 2.90657189340102
Validation loss: 2.8276402530462534

Epoch: 5| Step: 4
Training loss: 3.0695740877125046
Validation loss: 2.8258311099841738

Epoch: 5| Step: 5
Training loss: 3.377347624170083
Validation loss: 2.8238633786546696

Epoch: 5| Step: 6
Training loss: 3.09471546868081
Validation loss: 2.8234331191112854

Epoch: 5| Step: 7
Training loss: 2.802068906460934
Validation loss: 2.821305396945032

Epoch: 5| Step: 8
Training loss: 2.815189008584101
Validation loss: 2.8209119390432074

Epoch: 5| Step: 9
Training loss: 3.2166978534774455
Validation loss: 2.8188778864459074

Epoch: 5| Step: 10
Training loss: 2.8819122149236898
Validation loss: 2.818374739490696

Epoch: 5| Step: 11
Training loss: 1.8166551645013962
Validation loss: 2.8180656888113322

Epoch: 63| Step: 0
Training loss: 3.2984833613414493
Validation loss: 2.8141180364454574

Epoch: 5| Step: 1
Training loss: 3.1397672022638274
Validation loss: 2.812214148088154

Epoch: 5| Step: 2
Training loss: 3.3250923488096977
Validation loss: 2.81087235577938

Epoch: 5| Step: 3
Training loss: 2.5925290094884303
Validation loss: 2.810148736263012

Epoch: 5| Step: 4
Training loss: 3.1575213600577894
Validation loss: 2.8095865630368366

Epoch: 5| Step: 5
Training loss: 3.0238913656229234
Validation loss: 2.807620110109439

Epoch: 5| Step: 6
Training loss: 3.1968362248400695
Validation loss: 2.8068397254910322

Epoch: 5| Step: 7
Training loss: 2.958601782712062
Validation loss: 2.8059199254475855

Epoch: 5| Step: 8
Training loss: 2.5626844014134003
Validation loss: 2.803953480280663

Epoch: 5| Step: 9
Training loss: 2.7344656792999853
Validation loss: 2.8028136309716674

Epoch: 5| Step: 10
Training loss: 2.487310822160672
Validation loss: 2.8012630379898398

Epoch: 5| Step: 11
Training loss: 1.9665224097842349
Validation loss: 2.7984165475566107

Epoch: 64| Step: 0
Training loss: 2.702344042912269
Validation loss: 2.7964494406307634

Epoch: 5| Step: 1
Training loss: 3.2271844666216407
Validation loss: 2.795957446766388

Epoch: 5| Step: 2
Training loss: 2.7966265861115596
Validation loss: 2.7946605262505373

Epoch: 5| Step: 3
Training loss: 3.0630520692808956
Validation loss: 2.793475978649035

Epoch: 5| Step: 4
Training loss: 2.742595066311085
Validation loss: 2.7919201534159024

Epoch: 5| Step: 5
Training loss: 3.0374703048698777
Validation loss: 2.7925652450354854

Epoch: 5| Step: 6
Training loss: 3.0269899616862648
Validation loss: 2.789119292463704

Epoch: 5| Step: 7
Training loss: 2.4902683629727145
Validation loss: 2.787801751452908

Epoch: 5| Step: 8
Training loss: 3.158772282221784
Validation loss: 2.7862647384463677

Epoch: 5| Step: 9
Training loss: 2.9985678751293614
Validation loss: 2.7841495301321464

Epoch: 5| Step: 10
Training loss: 3.161189227562706
Validation loss: 2.7831249382235486

Epoch: 5| Step: 11
Training loss: 1.067542843282771
Validation loss: 2.781581762435931

Epoch: 65| Step: 0
Training loss: 2.931557183345751
Validation loss: 2.7802113404489384

Epoch: 5| Step: 1
Training loss: 3.0594255234751846
Validation loss: 2.778007971576864

Epoch: 5| Step: 2
Training loss: 3.074773057456176
Validation loss: 2.776760581984396

Epoch: 5| Step: 3
Training loss: 2.637793201944915
Validation loss: 2.775160488007083

Epoch: 5| Step: 4
Training loss: 2.4172675821641545
Validation loss: 2.774232748575145

Epoch: 5| Step: 5
Training loss: 2.941796265539872
Validation loss: 2.771902202055561

Epoch: 5| Step: 6
Training loss: 2.9699091204472605
Validation loss: 2.770054310921505

Epoch: 5| Step: 7
Training loss: 3.2215426283743485
Validation loss: 2.7714928951047333

Epoch: 5| Step: 8
Training loss: 3.359189050540399
Validation loss: 2.769966069833091

Epoch: 5| Step: 9
Training loss: 2.4474022074441386
Validation loss: 2.7711631977709406

Epoch: 5| Step: 10
Training loss: 2.821985651932758
Validation loss: 2.770999359711502

Epoch: 5| Step: 11
Training loss: 3.0096423639385255
Validation loss: 2.764987972766823

Epoch: 66| Step: 0
Training loss: 3.263170990326645
Validation loss: 2.764066742095366

Epoch: 5| Step: 1
Training loss: 2.7387094203740574
Validation loss: 2.7616258144254004

Epoch: 5| Step: 2
Training loss: 3.019232139231975
Validation loss: 2.7611594598275864

Epoch: 5| Step: 3
Training loss: 3.000762524654378
Validation loss: 2.759239313973654

Epoch: 5| Step: 4
Training loss: 2.709183623034864
Validation loss: 2.7582008909619713

Epoch: 5| Step: 5
Training loss: 2.7756819978121623
Validation loss: 2.7564139453630663

Epoch: 5| Step: 6
Training loss: 2.387528252559286
Validation loss: 2.755259437063061

Epoch: 5| Step: 7
Training loss: 3.0956066995037816
Validation loss: 2.753871414288897

Epoch: 5| Step: 8
Training loss: 3.0695813888295786
Validation loss: 2.7526122676233324

Epoch: 5| Step: 9
Training loss: 2.642130044755723
Validation loss: 2.751998503910765

Epoch: 5| Step: 10
Training loss: 3.0869517530718644
Validation loss: 2.750334311162833

Epoch: 5| Step: 11
Training loss: 2.8462290595301645
Validation loss: 2.748111119498794

Epoch: 67| Step: 0
Training loss: 2.8847166972831118
Validation loss: 2.749980893935676

Epoch: 5| Step: 1
Training loss: 2.9504891394147172
Validation loss: 2.751005480199819

Epoch: 5| Step: 2
Training loss: 2.8356067475102886
Validation loss: 2.752116494240087

Epoch: 5| Step: 3
Training loss: 2.744522361404355
Validation loss: 2.750618482167534

Epoch: 5| Step: 4
Training loss: 2.934987881065186
Validation loss: 2.749643187060509

Epoch: 5| Step: 5
Training loss: 2.4148200861728775
Validation loss: 2.7494611609572033

Epoch: 5| Step: 6
Training loss: 3.0631943518900613
Validation loss: 2.747737379976028

Epoch: 5| Step: 7
Training loss: 2.8718323879795697
Validation loss: 2.745472551520891

Epoch: 5| Step: 8
Training loss: 3.033928385905914
Validation loss: 2.745384757853788

Epoch: 5| Step: 9
Training loss: 2.6622579509334456
Validation loss: 2.7432307933143227

Epoch: 5| Step: 10
Training loss: 3.186701955187571
Validation loss: 2.7409165417617234

Epoch: 5| Step: 11
Training loss: 3.449616319634047
Validation loss: 2.7399608233533

Epoch: 68| Step: 0
Training loss: 3.3632117783729476
Validation loss: 2.737845211529576

Epoch: 5| Step: 1
Training loss: 2.0157185614110764
Validation loss: 2.736203136580102

Epoch: 5| Step: 2
Training loss: 2.471982264452029
Validation loss: 2.734293040909204

Epoch: 5| Step: 3
Training loss: 2.9392224395568185
Validation loss: 2.732553758362887

Epoch: 5| Step: 4
Training loss: 2.8440843322740825
Validation loss: 2.731462020559244

Epoch: 5| Step: 5
Training loss: 3.5323603411993694
Validation loss: 2.730236209104636

Epoch: 5| Step: 6
Training loss: 3.072053139256787
Validation loss: 2.7286545015680272

Epoch: 5| Step: 7
Training loss: 2.645130985384294
Validation loss: 2.7270153584082184

Epoch: 5| Step: 8
Training loss: 2.959724600584269
Validation loss: 2.726259150932074

Epoch: 5| Step: 9
Training loss: 2.683067570037733
Validation loss: 2.7250254360085084

Epoch: 5| Step: 10
Training loss: 2.7430725408315246
Validation loss: 2.7244881004770907

Epoch: 5| Step: 11
Training loss: 2.9346296206049303
Validation loss: 2.7237500402244272

Epoch: 69| Step: 0
Training loss: 2.6115864959012427
Validation loss: 2.7211832616458147

Epoch: 5| Step: 1
Training loss: 2.4521440622160786
Validation loss: 2.720996440148166

Epoch: 5| Step: 2
Training loss: 3.0417893441600463
Validation loss: 2.7210431494632243

Epoch: 5| Step: 3
Training loss: 3.187187478695445
Validation loss: 2.718789593638487

Epoch: 5| Step: 4
Training loss: 3.070411583464034
Validation loss: 2.7166618205731314

Epoch: 5| Step: 5
Training loss: 3.188660354341095
Validation loss: 2.7158631165135425

Epoch: 5| Step: 6
Training loss: 2.611091916935852
Validation loss: 2.714837082962156

Epoch: 5| Step: 7
Training loss: 2.6850612131880522
Validation loss: 2.713982670118185

Epoch: 5| Step: 8
Training loss: 2.655512449303939
Validation loss: 2.7122947234312744

Epoch: 5| Step: 9
Training loss: 2.899930584833124
Validation loss: 2.7114093087788995

Epoch: 5| Step: 10
Training loss: 2.607898042897467
Validation loss: 2.70955482716245

Epoch: 5| Step: 11
Training loss: 3.982171141030978
Validation loss: 2.7089033419538873

Epoch: 70| Step: 0
Training loss: 2.8093438135098565
Validation loss: 2.706209220314684

Epoch: 5| Step: 1
Training loss: 3.412237941195482
Validation loss: 2.7061871510315174

Epoch: 5| Step: 2
Training loss: 2.6282439396600656
Validation loss: 2.70370763772836

Epoch: 5| Step: 3
Training loss: 2.9808843680358663
Validation loss: 2.703148406263677

Epoch: 5| Step: 4
Training loss: 2.2425394346922647
Validation loss: 2.7009837153306457

Epoch: 5| Step: 5
Training loss: 2.85420468344511
Validation loss: 2.699920769105875

Epoch: 5| Step: 6
Training loss: 3.113371461257703
Validation loss: 2.696723336544609

Epoch: 5| Step: 7
Training loss: 2.7633700040800657
Validation loss: 2.6958550427745336

Epoch: 5| Step: 8
Training loss: 2.9848587682594094
Validation loss: 2.6965784499938588

Epoch: 5| Step: 9
Training loss: 3.022661765086885
Validation loss: 2.6927028092721814

Epoch: 5| Step: 10
Training loss: 2.134008945335509
Validation loss: 2.6939340761608084

Epoch: 5| Step: 11
Training loss: 3.123406576181961
Validation loss: 2.695159107948121

Epoch: 71| Step: 0
Training loss: 2.5146001777832727
Validation loss: 2.689717298510822

Epoch: 5| Step: 1
Training loss: 2.9237610956432425
Validation loss: 2.6917592976538485

Epoch: 5| Step: 2
Training loss: 2.863881213521883
Validation loss: 2.6927515994247746

Epoch: 5| Step: 3
Training loss: 2.4965039604181576
Validation loss: 2.6949588709507855

Epoch: 5| Step: 4
Training loss: 3.258429379685848
Validation loss: 2.69613549756448

Epoch: 5| Step: 5
Training loss: 2.9985839362712143
Validation loss: 2.697490751800381

Epoch: 5| Step: 6
Training loss: 2.530116168736334
Validation loss: 2.699211867710583

Epoch: 5| Step: 7
Training loss: 2.6015608504006593
Validation loss: 2.6949505475401643

Epoch: 5| Step: 8
Training loss: 2.7625920103466424
Validation loss: 2.6911336745089662

Epoch: 5| Step: 9
Training loss: 2.7978807058364366
Validation loss: 2.6886002521026504

Epoch: 5| Step: 10
Training loss: 3.4129072456352474
Validation loss: 2.6872415529225333

Epoch: 5| Step: 11
Training loss: 1.8499412037553207
Validation loss: 2.6849544246186956

Epoch: 72| Step: 0
Training loss: 2.5758562682788693
Validation loss: 2.683293847322682

Epoch: 5| Step: 1
Training loss: 3.0194110723072765
Validation loss: 2.6828391667564255

Epoch: 5| Step: 2
Training loss: 2.726085806987169
Validation loss: 2.684852837786557

Epoch: 5| Step: 3
Training loss: 2.5735683979960235
Validation loss: 2.6879452735724074

Epoch: 5| Step: 4
Training loss: 2.778626136507381
Validation loss: 2.6938915469219724

Epoch: 5| Step: 5
Training loss: 3.2460166288503434
Validation loss: 2.6859111820845216

Epoch: 5| Step: 6
Training loss: 2.58957694910377
Validation loss: 2.6757898001058558

Epoch: 5| Step: 7
Training loss: 3.053074559680417
Validation loss: 2.6728403752996113

Epoch: 5| Step: 8
Training loss: 2.743856851152534
Validation loss: 2.6720703343604097

Epoch: 5| Step: 9
Training loss: 2.9066927992961316
Validation loss: 2.6726015601444217

Epoch: 5| Step: 10
Training loss: 2.7771423524354883
Validation loss: 2.6710702453810895

Epoch: 5| Step: 11
Training loss: 2.5422288137500884
Validation loss: 2.672193006363282

Epoch: 73| Step: 0
Training loss: 2.9161089954387522
Validation loss: 2.670484151098116

Epoch: 5| Step: 1
Training loss: 3.115605691526648
Validation loss: 2.6697244373498847

Epoch: 5| Step: 2
Training loss: 2.168977300072262
Validation loss: 2.6712604842205594

Epoch: 5| Step: 3
Training loss: 2.4287644377714668
Validation loss: 2.671996093444957

Epoch: 5| Step: 4
Training loss: 3.068342280446493
Validation loss: 2.677819085352153

Epoch: 5| Step: 5
Training loss: 2.597166270459705
Validation loss: 2.6721143224959416

Epoch: 5| Step: 6
Training loss: 2.909386367857591
Validation loss: 2.666198912341391

Epoch: 5| Step: 7
Training loss: 2.8011753544528486
Validation loss: 2.6657475673258153

Epoch: 5| Step: 8
Training loss: 2.7634188371075794
Validation loss: 2.663760804873887

Epoch: 5| Step: 9
Training loss: 3.2646244834411355
Validation loss: 2.6623608700573285

Epoch: 5| Step: 10
Training loss: 2.7151563725128733
Validation loss: 2.6618981169113103

Epoch: 5| Step: 11
Training loss: 2.655480217186415
Validation loss: 2.660688741886856

Epoch: 74| Step: 0
Training loss: 2.936633530111195
Validation loss: 2.660057988454942

Epoch: 5| Step: 1
Training loss: 2.8506684038152774
Validation loss: 2.6611829019201267

Epoch: 5| Step: 2
Training loss: 2.798430367295096
Validation loss: 2.6598745412567544

Epoch: 5| Step: 3
Training loss: 3.1284816420499504
Validation loss: 2.658852726969888

Epoch: 5| Step: 4
Training loss: 2.878348680848107
Validation loss: 2.6580317748239324

Epoch: 5| Step: 5
Training loss: 2.6964716533442026
Validation loss: 2.6555525705610266

Epoch: 5| Step: 6
Training loss: 2.6337138367837465
Validation loss: 2.6550334949679453

Epoch: 5| Step: 7
Training loss: 2.3011961273070596
Validation loss: 2.6536300266881985

Epoch: 5| Step: 8
Training loss: 2.8388367852366736
Validation loss: 2.653895834594568

Epoch: 5| Step: 9
Training loss: 2.675849145181042
Validation loss: 2.652593276019422

Epoch: 5| Step: 10
Training loss: 3.014945156174283
Validation loss: 2.6503204283932864

Epoch: 5| Step: 11
Training loss: 2.2793976043174466
Validation loss: 2.64931510255848

Epoch: 75| Step: 0
Training loss: 3.025555640018403
Validation loss: 2.648256278800597

Epoch: 5| Step: 1
Training loss: 2.7162931895432125
Validation loss: 2.64777410595147

Epoch: 5| Step: 2
Training loss: 2.4640884814105135
Validation loss: 2.649192736134311

Epoch: 5| Step: 3
Training loss: 2.6709108453493786
Validation loss: 2.646019460984736

Epoch: 5| Step: 4
Training loss: 2.6038594687786425
Validation loss: 2.644900312642391

Epoch: 5| Step: 5
Training loss: 3.3467070436764925
Validation loss: 2.6433486886398256

Epoch: 5| Step: 6
Training loss: 2.2327411787042273
Validation loss: 2.6421796672636515

Epoch: 5| Step: 7
Training loss: 3.1633678285937497
Validation loss: 2.642022254148402

Epoch: 5| Step: 8
Training loss: 2.867559507595623
Validation loss: 2.6407546099995387

Epoch: 5| Step: 9
Training loss: 2.816194777677473
Validation loss: 2.641852088090658

Epoch: 5| Step: 10
Training loss: 2.717722468389966
Validation loss: 2.643127527146279

Epoch: 5| Step: 11
Training loss: 1.5620227847910217
Validation loss: 2.64031866655545

Testing loss: 2.1955644737426123
