Epoch: 1| Step: 0
Training loss: 6.191140174865723
Validation loss: 5.2425989508628845

Epoch: 5| Step: 1
Training loss: 5.698415279388428
Validation loss: 5.24030989408493

Epoch: 5| Step: 2
Training loss: 4.20650577545166
Validation loss: 5.238027373949687

Epoch: 5| Step: 3
Training loss: 5.104312896728516
Validation loss: 5.235774179299672

Epoch: 5| Step: 4
Training loss: 4.545342922210693
Validation loss: 5.233434240023295

Epoch: 5| Step: 5
Training loss: 5.994915962219238
Validation loss: 5.2311708728472395

Epoch: 5| Step: 6
Training loss: 5.101327419281006
Validation loss: 5.228883862495422

Epoch: 5| Step: 7
Training loss: 5.146411895751953
Validation loss: 5.226534307003021

Epoch: 5| Step: 8
Training loss: 6.242383003234863
Validation loss: 5.224177261193593

Epoch: 5| Step: 9
Training loss: 5.554271697998047
Validation loss: 5.221697608629863

Epoch: 5| Step: 10
Training loss: 4.8959808349609375
Validation loss: 5.219260315100352

Epoch: 5| Step: 11
Training loss: 3.408602714538574
Validation loss: 5.216635167598724

Epoch: 2| Step: 0
Training loss: 5.655505180358887
Validation loss: 5.213930110136668

Epoch: 5| Step: 1
Training loss: 5.417173385620117
Validation loss: 5.211128791173299

Epoch: 5| Step: 2
Training loss: 6.503151893615723
Validation loss: 5.208266655604045

Epoch: 5| Step: 3
Training loss: 5.644136905670166
Validation loss: 5.20516836643219

Epoch: 5| Step: 4
Training loss: 4.881766319274902
Validation loss: 5.202038804690043

Epoch: 5| Step: 5
Training loss: 5.439945697784424
Validation loss: 5.1986522277196245

Epoch: 5| Step: 6
Training loss: 5.473690986633301
Validation loss: 5.195189754168193

Epoch: 5| Step: 7
Training loss: 4.587322235107422
Validation loss: 5.191535731156667

Epoch: 5| Step: 8
Training loss: 4.93516206741333
Validation loss: 5.187690754731496

Epoch: 5| Step: 9
Training loss: 5.793088436126709
Validation loss: 5.183582425117493

Epoch: 5| Step: 10
Training loss: 3.6161861419677734
Validation loss: 5.1791130900383

Epoch: 5| Step: 11
Training loss: 5.258874416351318
Validation loss: 5.174714148044586

Epoch: 3| Step: 0
Training loss: 5.027592182159424
Validation loss: 5.169910430908203

Epoch: 5| Step: 1
Training loss: 4.375317096710205
Validation loss: 5.164766728878021

Epoch: 5| Step: 2
Training loss: 4.490544319152832
Validation loss: 5.1595291296641035

Epoch: 5| Step: 3
Training loss: 5.452300548553467
Validation loss: 5.153992116451263

Epoch: 5| Step: 4
Training loss: 5.815635681152344
Validation loss: 5.147802074750264

Epoch: 5| Step: 5
Training loss: 4.77537727355957
Validation loss: 5.1414239803949995

Epoch: 5| Step: 6
Training loss: 5.631146430969238
Validation loss: 5.134942313035329

Epoch: 5| Step: 7
Training loss: 5.092360019683838
Validation loss: 5.127998769283295

Epoch: 5| Step: 8
Training loss: 5.042843818664551
Validation loss: 5.120710045099258

Epoch: 5| Step: 9
Training loss: 5.887916564941406
Validation loss: 5.113174676895142

Epoch: 5| Step: 10
Training loss: 5.4857497215271
Validation loss: 5.1052334904670715

Epoch: 5| Step: 11
Training loss: 6.4280242919921875
Validation loss: 5.096980591615041

Epoch: 4| Step: 0
Training loss: 4.931406021118164
Validation loss: 5.088382999102275

Epoch: 5| Step: 1
Training loss: 4.534365653991699
Validation loss: 5.079442183176677

Epoch: 5| Step: 2
Training loss: 4.7221879959106445
Validation loss: 5.07021035750707

Epoch: 5| Step: 3
Training loss: 5.196646213531494
Validation loss: 5.060593366622925

Epoch: 5| Step: 4
Training loss: 5.793239593505859
Validation loss: 5.050773998101552

Epoch: 5| Step: 5
Training loss: 5.36616849899292
Validation loss: 5.04064138730367

Epoch: 5| Step: 6
Training loss: 4.5096330642700195
Validation loss: 5.029911518096924

Epoch: 5| Step: 7
Training loss: 5.087186336517334
Validation loss: 5.019212702910106

Epoch: 5| Step: 8
Training loss: 4.630573272705078
Validation loss: 5.00785897175471

Epoch: 5| Step: 9
Training loss: 5.171420574188232
Validation loss: 4.996542791525523

Epoch: 5| Step: 10
Training loss: 5.810791969299316
Validation loss: 4.9848025639851885

Epoch: 5| Step: 11
Training loss: 7.587953567504883
Validation loss: 4.9725480278333025

Epoch: 5| Step: 0
Training loss: 4.263797760009766
Validation loss: 4.960567951202393

Epoch: 5| Step: 1
Training loss: 4.422442436218262
Validation loss: 4.947843333085378

Epoch: 5| Step: 2
Training loss: 4.975010871887207
Validation loss: 4.935443381468455

Epoch: 5| Step: 3
Training loss: 5.610112190246582
Validation loss: 4.9224250713984175

Epoch: 5| Step: 4
Training loss: 4.688773155212402
Validation loss: 4.909524341424306

Epoch: 5| Step: 5
Training loss: 4.475148677825928
Validation loss: 4.896702349185944

Epoch: 5| Step: 6
Training loss: 6.441060543060303
Validation loss: 4.883821566899617

Epoch: 5| Step: 7
Training loss: 4.713368892669678
Validation loss: 4.8713545600573225

Epoch: 5| Step: 8
Training loss: 5.861359596252441
Validation loss: 4.858742078145345

Epoch: 5| Step: 9
Training loss: 3.8673927783966064
Validation loss: 4.846077819665273

Epoch: 5| Step: 10
Training loss: 5.16489315032959
Validation loss: 4.833763202031453

Epoch: 5| Step: 11
Training loss: 6.376287460327148
Validation loss: 4.821387579043706

Epoch: 6| Step: 0
Training loss: 4.477694511413574
Validation loss: 4.809390554825465

Epoch: 5| Step: 1
Training loss: 5.436382293701172
Validation loss: 4.797597428162892

Epoch: 5| Step: 2
Training loss: 5.402373313903809
Validation loss: 4.785800993442535

Epoch: 5| Step: 3
Training loss: 5.183609962463379
Validation loss: 4.773768603801727

Epoch: 5| Step: 4
Training loss: 5.325135231018066
Validation loss: 4.762488226095836

Epoch: 5| Step: 5
Training loss: 4.2343950271606445
Validation loss: 4.751560529073079

Epoch: 5| Step: 6
Training loss: 4.89109468460083
Validation loss: 4.740418116251628

Epoch: 5| Step: 7
Training loss: 4.347586631774902
Validation loss: 4.729704638322194

Epoch: 5| Step: 8
Training loss: 5.104864120483398
Validation loss: 4.71912282705307

Epoch: 5| Step: 9
Training loss: 3.960475206375122
Validation loss: 4.708898524443309

Epoch: 5| Step: 10
Training loss: 5.1101179122924805
Validation loss: 4.69913003842036

Epoch: 5| Step: 11
Training loss: 3.8532462120056152
Validation loss: 4.689360996087392

Epoch: 7| Step: 0
Training loss: 4.658639430999756
Validation loss: 4.679747422536214

Epoch: 5| Step: 1
Training loss: 5.017969131469727
Validation loss: 4.669304986794789

Epoch: 5| Step: 2
Training loss: 4.806048393249512
Validation loss: 4.6595762968063354

Epoch: 5| Step: 3
Training loss: 3.5108635425567627
Validation loss: 4.649239579836528

Epoch: 5| Step: 4
Training loss: 5.040597438812256
Validation loss: 4.639071524143219

Epoch: 5| Step: 5
Training loss: 5.050252914428711
Validation loss: 4.6285761793454485

Epoch: 5| Step: 6
Training loss: 5.4623517990112305
Validation loss: 4.619022071361542

Epoch: 5| Step: 7
Training loss: 3.621603012084961
Validation loss: 4.610719134410222

Epoch: 5| Step: 8
Training loss: 5.217961311340332
Validation loss: 4.602647006511688

Epoch: 5| Step: 9
Training loss: 5.530063629150391
Validation loss: 4.594611883163452

Epoch: 5| Step: 10
Training loss: 4.315834999084473
Validation loss: 4.586814820766449

Epoch: 5| Step: 11
Training loss: 3.649473190307617
Validation loss: 4.579101641972859

Epoch: 8| Step: 0
Training loss: 5.035952091217041
Validation loss: 4.571283181508382

Epoch: 5| Step: 1
Training loss: 4.906588554382324
Validation loss: 4.563163638114929

Epoch: 5| Step: 2
Training loss: 4.708032608032227
Validation loss: 4.555400530497233

Epoch: 5| Step: 3
Training loss: 5.475356101989746
Validation loss: 4.547220269838969

Epoch: 5| Step: 4
Training loss: 4.670783519744873
Validation loss: 4.5390384296576185

Epoch: 5| Step: 5
Training loss: 3.999971866607666
Validation loss: 4.530896107355754

Epoch: 5| Step: 6
Training loss: 4.631848335266113
Validation loss: 4.522728621959686

Epoch: 5| Step: 7
Training loss: 5.114169120788574
Validation loss: 4.51446807384491

Epoch: 5| Step: 8
Training loss: 4.459453105926514
Validation loss: 4.5058415333429975

Epoch: 5| Step: 9
Training loss: 4.059613227844238
Validation loss: 4.497556269168854

Epoch: 5| Step: 10
Training loss: 4.402891635894775
Validation loss: 4.489747633536656

Epoch: 5| Step: 11
Training loss: 2.3212637901306152
Validation loss: 4.4810463190078735

Epoch: 9| Step: 0
Training loss: 4.889098167419434
Validation loss: 4.4738438328107195

Epoch: 5| Step: 1
Training loss: 5.0787529945373535
Validation loss: 4.4662792682647705

Epoch: 5| Step: 2
Training loss: 4.295336723327637
Validation loss: 4.458686649799347

Epoch: 5| Step: 3
Training loss: 4.408061504364014
Validation loss: 4.451341440280278

Epoch: 5| Step: 4
Training loss: 4.036619186401367
Validation loss: 4.444029599428177

Epoch: 5| Step: 5
Training loss: 3.878004550933838
Validation loss: 4.436848481496175

Epoch: 5| Step: 6
Training loss: 4.625239372253418
Validation loss: 4.4293514887491865

Epoch: 5| Step: 7
Training loss: 4.563209533691406
Validation loss: 4.422190884749095

Epoch: 5| Step: 8
Training loss: 4.626607894897461
Validation loss: 4.415590862433116

Epoch: 5| Step: 9
Training loss: 5.822096824645996
Validation loss: 4.407788693904877

Epoch: 5| Step: 10
Training loss: 3.871981143951416
Validation loss: 4.400705059369405

Epoch: 5| Step: 11
Training loss: 4.355922698974609
Validation loss: 4.393535594145457

Epoch: 10| Step: 0
Training loss: 4.028843879699707
Validation loss: 4.385911216338475

Epoch: 5| Step: 1
Training loss: 4.326186656951904
Validation loss: 4.378678898016612

Epoch: 5| Step: 2
Training loss: 4.227415084838867
Validation loss: 4.370730211337407

Epoch: 5| Step: 3
Training loss: 4.4993438720703125
Validation loss: 4.363185822963715

Epoch: 5| Step: 4
Training loss: 5.416890621185303
Validation loss: 4.355839143196742

Epoch: 5| Step: 5
Training loss: 4.279144763946533
Validation loss: 4.348449349403381

Epoch: 5| Step: 6
Training loss: 3.717141628265381
Validation loss: 4.341390897830327

Epoch: 5| Step: 7
Training loss: 4.600769996643066
Validation loss: 4.3339144587516785

Epoch: 5| Step: 8
Training loss: 5.427023887634277
Validation loss: 4.3268142739931745

Epoch: 5| Step: 9
Training loss: 3.365703582763672
Validation loss: 4.319505353768666

Epoch: 5| Step: 10
Training loss: 4.805528163909912
Validation loss: 4.312320381402969

Epoch: 5| Step: 11
Training loss: 6.910645008087158
Validation loss: 4.306162426869075

Epoch: 11| Step: 0
Training loss: 4.959543704986572
Validation loss: 4.298804779847463

Epoch: 5| Step: 1
Training loss: 4.493142127990723
Validation loss: 4.29245537519455

Epoch: 5| Step: 2
Training loss: 5.012401580810547
Validation loss: 4.286335329214732

Epoch: 5| Step: 3
Training loss: 4.095560073852539
Validation loss: 4.279850075642268

Epoch: 5| Step: 4
Training loss: 3.5949153900146484
Validation loss: 4.273811390002568

Epoch: 5| Step: 5
Training loss: 5.083959102630615
Validation loss: 4.2670471866925554

Epoch: 5| Step: 6
Training loss: 4.133513450622559
Validation loss: 4.260395894447963

Epoch: 5| Step: 7
Training loss: 3.8111705780029297
Validation loss: 4.253359804550807

Epoch: 5| Step: 8
Training loss: 3.834390163421631
Validation loss: 4.246762325366338

Epoch: 5| Step: 9
Training loss: 4.341170787811279
Validation loss: 4.239903450012207

Epoch: 5| Step: 10
Training loss: 4.755084037780762
Validation loss: 4.233981758356094

Epoch: 5| Step: 11
Training loss: 5.450398921966553
Validation loss: 4.227439999580383

Epoch: 12| Step: 0
Training loss: 4.651041507720947
Validation loss: 4.220305969317754

Epoch: 5| Step: 1
Training loss: 4.330502510070801
Validation loss: 4.212984989086787

Epoch: 5| Step: 2
Training loss: 4.562039375305176
Validation loss: 4.206239193677902

Epoch: 5| Step: 3
Training loss: 4.469832897186279
Validation loss: 4.198965907096863

Epoch: 5| Step: 4
Training loss: 3.8328826427459717
Validation loss: 4.192152818044026

Epoch: 5| Step: 5
Training loss: 4.140949249267578
Validation loss: 4.185280164082845

Epoch: 5| Step: 6
Training loss: 5.050547122955322
Validation loss: 4.178942342599233

Epoch: 5| Step: 7
Training loss: 4.032265663146973
Validation loss: 4.17153533299764

Epoch: 5| Step: 8
Training loss: 4.618003845214844
Validation loss: 4.164871623118718

Epoch: 5| Step: 9
Training loss: 3.9250049591064453
Validation loss: 4.157961527506511

Epoch: 5| Step: 10
Training loss: 3.8848776817321777
Validation loss: 4.150889327128728

Epoch: 5| Step: 11
Training loss: 4.504845142364502
Validation loss: 4.144446104764938

Epoch: 13| Step: 0
Training loss: 3.676098346710205
Validation loss: 4.136931826670964

Epoch: 5| Step: 1
Training loss: 3.5209994316101074
Validation loss: 4.130437483390172

Epoch: 5| Step: 2
Training loss: 4.6183671951293945
Validation loss: 4.1242847839991255

Epoch: 5| Step: 3
Training loss: 4.285569190979004
Validation loss: 4.117858707904816

Epoch: 5| Step: 4
Training loss: 4.648137092590332
Validation loss: 4.111412803332011

Epoch: 5| Step: 5
Training loss: 3.6067910194396973
Validation loss: 4.104270319143931

Epoch: 5| Step: 6
Training loss: 5.5710625648498535
Validation loss: 4.0972132086753845

Epoch: 5| Step: 7
Training loss: 4.509982109069824
Validation loss: 4.090490688880284

Epoch: 5| Step: 8
Training loss: 5.536678791046143
Validation loss: 4.083704243103663

Epoch: 5| Step: 9
Training loss: 3.8461616039276123
Validation loss: 4.0766234795252485

Epoch: 5| Step: 10
Training loss: 3.1650989055633545
Validation loss: 4.070546398560206

Epoch: 5| Step: 11
Training loss: 2.765625238418579
Validation loss: 4.063807239135106

Epoch: 14| Step: 0
Training loss: 4.418424129486084
Validation loss: 4.057690819104512

Epoch: 5| Step: 1
Training loss: 3.4506797790527344
Validation loss: 4.051935156186421

Epoch: 5| Step: 2
Training loss: 4.395293235778809
Validation loss: 4.045602987209956

Epoch: 5| Step: 3
Training loss: 4.68442440032959
Validation loss: 4.03901602824529

Epoch: 5| Step: 4
Training loss: 4.402401924133301
Validation loss: 4.032876749833425

Epoch: 5| Step: 5
Training loss: 4.048333644866943
Validation loss: 4.026159554719925

Epoch: 5| Step: 6
Training loss: 3.8619494438171387
Validation loss: 4.020472784837087

Epoch: 5| Step: 7
Training loss: 4.30060338973999
Validation loss: 4.014958908160527

Epoch: 5| Step: 8
Training loss: 4.623332977294922
Validation loss: 4.00890467564265

Epoch: 5| Step: 9
Training loss: 3.643758773803711
Validation loss: 4.002382804950078

Epoch: 5| Step: 10
Training loss: 3.7740516662597656
Validation loss: 3.9969080785910287

Epoch: 5| Step: 11
Training loss: 5.540166854858398
Validation loss: 3.989388942718506

Epoch: 15| Step: 0
Training loss: 4.152797222137451
Validation loss: 3.9850620230038962

Epoch: 5| Step: 1
Training loss: 3.5242843627929688
Validation loss: 3.9822152256965637

Epoch: 5| Step: 2
Training loss: 4.274781227111816
Validation loss: 3.9768888652324677

Epoch: 5| Step: 3
Training loss: 3.671410322189331
Validation loss: 3.9703080455462136

Epoch: 5| Step: 4
Training loss: 3.5934479236602783
Validation loss: 3.964313526948293

Epoch: 5| Step: 5
Training loss: 3.901961088180542
Validation loss: 3.956963708003362

Epoch: 5| Step: 6
Training loss: 4.972269535064697
Validation loss: 3.9500752687454224

Epoch: 5| Step: 7
Training loss: 4.841790676116943
Validation loss: 3.94476510087649

Epoch: 5| Step: 8
Training loss: 4.53371524810791
Validation loss: 3.9396680990854898

Epoch: 5| Step: 9
Training loss: 3.3892531394958496
Validation loss: 3.9363674918810525

Epoch: 5| Step: 10
Training loss: 3.902651309967041
Validation loss: 3.9301912585894265

Epoch: 5| Step: 11
Training loss: 6.042448043823242
Validation loss: 3.922206620375315

Epoch: 16| Step: 0
Training loss: 3.724271297454834
Validation loss: 3.9159154196580253

Epoch: 5| Step: 1
Training loss: 4.685057640075684
Validation loss: 3.910702417294184

Epoch: 5| Step: 2
Training loss: 4.185273170471191
Validation loss: 3.9053415258725486

Epoch: 5| Step: 3
Training loss: 3.3931617736816406
Validation loss: 3.898606220881144

Epoch: 5| Step: 4
Training loss: 3.8166909217834473
Validation loss: 3.890450656414032

Epoch: 5| Step: 5
Training loss: 4.350067615509033
Validation loss: 3.8828293283780417

Epoch: 5| Step: 6
Training loss: 5.074287414550781
Validation loss: 3.874792734781901

Epoch: 5| Step: 7
Training loss: 3.940596103668213
Validation loss: 3.8685892124970755

Epoch: 5| Step: 8
Training loss: 3.682033061981201
Validation loss: 3.8634613951047263

Epoch: 5| Step: 9
Training loss: 3.812131881713867
Validation loss: 3.859314809242884

Epoch: 5| Step: 10
Training loss: 4.359854221343994
Validation loss: 3.854877084493637

Epoch: 5| Step: 11
Training loss: 0.9085913896560669
Validation loss: 3.8473747769991555

Epoch: 17| Step: 0
Training loss: 4.042321681976318
Validation loss: 3.842630704243978

Epoch: 5| Step: 1
Training loss: 3.4902539253234863
Validation loss: 3.8350023329257965

Epoch: 5| Step: 2
Training loss: 4.254453659057617
Validation loss: 3.830133636792501

Epoch: 5| Step: 3
Training loss: 3.7436795234680176
Validation loss: 3.8258956372737885

Epoch: 5| Step: 4
Training loss: 4.6055588722229
Validation loss: 3.8236160576343536

Epoch: 5| Step: 5
Training loss: 4.031500816345215
Validation loss: 3.818006624778112

Epoch: 5| Step: 6
Training loss: 3.608485460281372
Validation loss: 3.8134946127732596

Epoch: 5| Step: 7
Training loss: 4.143026828765869
Validation loss: 3.8077383240063987

Epoch: 5| Step: 8
Training loss: 3.700835704803467
Validation loss: 3.802525748809179

Epoch: 5| Step: 9
Training loss: 3.7095229625701904
Validation loss: 3.79573721686999

Epoch: 5| Step: 10
Training loss: 3.9936511516571045
Validation loss: 3.790008952220281

Epoch: 5| Step: 11
Training loss: 5.667357921600342
Validation loss: 3.784167488416036

Epoch: 18| Step: 0
Training loss: 3.5711982250213623
Validation loss: 3.7783738474051156

Epoch: 5| Step: 1
Training loss: 4.533083915710449
Validation loss: 3.7739768425623574

Epoch: 5| Step: 2
Training loss: 4.486964225769043
Validation loss: 3.7672144969304404

Epoch: 5| Step: 3
Training loss: 3.8492209911346436
Validation loss: 3.761752257744471

Epoch: 5| Step: 4
Training loss: 4.191465854644775
Validation loss: 3.7570811410744986

Epoch: 5| Step: 5
Training loss: 2.982332944869995
Validation loss: 3.7515923281510672

Epoch: 5| Step: 6
Training loss: 3.7369415760040283
Validation loss: 3.746364325284958

Epoch: 5| Step: 7
Training loss: 3.3811001777648926
Validation loss: 3.740626404682795

Epoch: 5| Step: 8
Training loss: 3.998492479324341
Validation loss: 3.7352824111779532

Epoch: 5| Step: 9
Training loss: 4.23854923248291
Validation loss: 3.7304710745811462

Epoch: 5| Step: 10
Training loss: 4.029555797576904
Validation loss: 3.7266778647899628

Epoch: 5| Step: 11
Training loss: 3.862973690032959
Validation loss: 3.721502979596456

Epoch: 19| Step: 0
Training loss: 4.019224643707275
Validation loss: 3.7193952103455863

Epoch: 5| Step: 1
Training loss: 4.291914939880371
Validation loss: 3.7118086218833923

Epoch: 5| Step: 2
Training loss: 4.489603042602539
Validation loss: 3.705863058567047

Epoch: 5| Step: 3
Training loss: 3.3227362632751465
Validation loss: 3.6999922891457877

Epoch: 5| Step: 4
Training loss: 3.4697391986846924
Validation loss: 3.6954268415768943

Epoch: 5| Step: 5
Training loss: 4.072751522064209
Validation loss: 3.6893376111984253

Epoch: 5| Step: 6
Training loss: 3.5983810424804688
Validation loss: 3.6844658056894937

Epoch: 5| Step: 7
Training loss: 3.5340142250061035
Validation loss: 3.679312139749527

Epoch: 5| Step: 8
Training loss: 3.4960315227508545
Validation loss: 3.6746384302775064

Epoch: 5| Step: 9
Training loss: 4.643408298492432
Validation loss: 3.6695223649342856

Epoch: 5| Step: 10
Training loss: 3.621011257171631
Validation loss: 3.6669455567995706

Epoch: 5| Step: 11
Training loss: 2.831728458404541
Validation loss: 3.660734256108602

Epoch: 20| Step: 0
Training loss: 4.255051612854004
Validation loss: 3.6560810605684915

Epoch: 5| Step: 1
Training loss: 4.660057067871094
Validation loss: 3.6507446567217507

Epoch: 5| Step: 2
Training loss: 3.2704856395721436
Validation loss: 3.6458873947461448

Epoch: 5| Step: 3
Training loss: 3.9934401512145996
Validation loss: 3.6429722905158997

Epoch: 5| Step: 4
Training loss: 3.7460296154022217
Validation loss: 3.637215425570806

Epoch: 5| Step: 5
Training loss: 3.3418707847595215
Validation loss: 3.6312521596749625

Epoch: 5| Step: 6
Training loss: 3.403979778289795
Validation loss: 3.625852515300115

Epoch: 5| Step: 7
Training loss: 3.7132153511047363
Validation loss: 3.6233857572078705

Epoch: 5| Step: 8
Training loss: 3.1934852600097656
Validation loss: 3.6177510221799216

Epoch: 5| Step: 9
Training loss: 4.003718376159668
Validation loss: 3.6134800016880035

Epoch: 5| Step: 10
Training loss: 4.2753071784973145
Validation loss: 3.6084083020687103

Epoch: 5| Step: 11
Training loss: 3.1619155406951904
Validation loss: 3.6042382518450418

Epoch: 21| Step: 0
Training loss: 3.930751323699951
Validation loss: 3.5996389389038086

Epoch: 5| Step: 1
Training loss: 3.6872901916503906
Validation loss: 3.5979400078455606

Epoch: 5| Step: 2
Training loss: 3.6460280418395996
Validation loss: 3.5923989514509835

Epoch: 5| Step: 3
Training loss: 4.065570831298828
Validation loss: 3.584602495034536

Epoch: 5| Step: 4
Training loss: 3.2354464530944824
Validation loss: 3.5806138714154563

Epoch: 5| Step: 5
Training loss: 4.012879371643066
Validation loss: 3.577401081720988

Epoch: 5| Step: 6
Training loss: 3.152677059173584
Validation loss: 3.5725713769594827

Epoch: 5| Step: 7
Training loss: 3.8355941772460938
Validation loss: 3.5684319535891214

Epoch: 5| Step: 8
Training loss: 4.3149614334106445
Validation loss: 3.564965178569158

Epoch: 5| Step: 9
Training loss: 4.19699764251709
Validation loss: 3.5587288538614907

Epoch: 5| Step: 10
Training loss: 3.541870594024658
Validation loss: 3.553941935300827

Epoch: 5| Step: 11
Training loss: 1.3991248607635498
Validation loss: 3.5510883231957755

Epoch: 22| Step: 0
Training loss: 3.7230892181396484
Validation loss: 3.548812876145045

Epoch: 5| Step: 1
Training loss: 2.8959012031555176
Validation loss: 3.541750262180964

Epoch: 5| Step: 2
Training loss: 4.122729778289795
Validation loss: 3.536917418241501

Epoch: 5| Step: 3
Training loss: 4.277107238769531
Validation loss: 3.5313924749692283

Epoch: 5| Step: 4
Training loss: 3.8726089000701904
Validation loss: 3.5267049173514047

Epoch: 5| Step: 5
Training loss: 3.583569049835205
Validation loss: 3.522054672241211

Epoch: 5| Step: 6
Training loss: 4.04232120513916
Validation loss: 3.5170629223187766

Epoch: 5| Step: 7
Training loss: 3.734112501144409
Validation loss: 3.5135815143585205

Epoch: 5| Step: 8
Training loss: 3.1195976734161377
Validation loss: 3.508836438258489

Epoch: 5| Step: 9
Training loss: 3.297438859939575
Validation loss: 3.505192836125692

Epoch: 5| Step: 10
Training loss: 3.848433017730713
Validation loss: 3.501069257656733

Epoch: 5| Step: 11
Training loss: 3.936502456665039
Validation loss: 3.4969834685325623

Epoch: 23| Step: 0
Training loss: 4.060186862945557
Validation loss: 3.4901415407657623

Epoch: 5| Step: 1
Training loss: 4.6995391845703125
Validation loss: 3.487008422613144

Epoch: 5| Step: 2
Training loss: 3.8017208576202393
Validation loss: 3.4838682810465493

Epoch: 5| Step: 3
Training loss: 3.2494022846221924
Validation loss: 3.479924043019613

Epoch: 5| Step: 4
Training loss: 2.593721866607666
Validation loss: 3.4753112296263375

Epoch: 5| Step: 5
Training loss: 3.7774150371551514
Validation loss: 3.4681977927684784

Epoch: 5| Step: 6
Training loss: 2.8789315223693848
Validation loss: 3.462926169236501

Epoch: 5| Step: 7
Training loss: 4.828063011169434
Validation loss: 3.457248777151108

Epoch: 5| Step: 8
Training loss: 3.31164813041687
Validation loss: 3.4536525309085846

Epoch: 5| Step: 9
Training loss: 3.6471493244171143
Validation loss: 3.449863483508428

Epoch: 5| Step: 10
Training loss: 3.235537052154541
Validation loss: 3.446623424688975

Epoch: 5| Step: 11
Training loss: 3.1666860580444336
Validation loss: 3.4415639340877533

Epoch: 24| Step: 0
Training loss: 2.9241268634796143
Validation loss: 3.436914016803106

Epoch: 5| Step: 1
Training loss: 2.829613447189331
Validation loss: 3.432211567958196

Epoch: 5| Step: 2
Training loss: 2.8605384826660156
Validation loss: 3.4283311863740287

Epoch: 5| Step: 3
Training loss: 3.009209156036377
Validation loss: 3.4229831298192344

Epoch: 5| Step: 4
Training loss: 4.322164058685303
Validation loss: 3.420764605204264

Epoch: 5| Step: 5
Training loss: 3.914438247680664
Validation loss: 3.4158680140972137

Epoch: 5| Step: 6
Training loss: 3.570146083831787
Validation loss: 3.4123701552549996

Epoch: 5| Step: 7
Training loss: 4.5705485343933105
Validation loss: 3.4119503994782767

Epoch: 5| Step: 8
Training loss: 3.6886494159698486
Validation loss: 3.4043711920579276

Epoch: 5| Step: 9
Training loss: 3.1034302711486816
Validation loss: 3.3983764549096427

Epoch: 5| Step: 10
Training loss: 4.389718532562256
Validation loss: 3.395139674345652

Epoch: 5| Step: 11
Training loss: 4.578798294067383
Validation loss: 3.389858235915502

Epoch: 25| Step: 0
Training loss: 3.44983172416687
Validation loss: 3.3855844835440316

Epoch: 5| Step: 1
Training loss: 3.625736713409424
Validation loss: 3.38076181213061

Epoch: 5| Step: 2
Training loss: 3.937525510787964
Validation loss: 3.377293278773626

Epoch: 5| Step: 3
Training loss: 3.279069185256958
Validation loss: 3.373004804054896

Epoch: 5| Step: 4
Training loss: 3.775704860687256
Validation loss: 3.366046021382014

Epoch: 5| Step: 5
Training loss: 3.6507110595703125
Validation loss: 3.3604341248671212

Epoch: 5| Step: 6
Training loss: 3.1357791423797607
Validation loss: 3.3565880954265594

Epoch: 5| Step: 7
Training loss: 2.819355010986328
Validation loss: 3.353037804365158

Epoch: 5| Step: 8
Training loss: 3.455190658569336
Validation loss: 3.348256746927897

Epoch: 5| Step: 9
Training loss: 3.703284502029419
Validation loss: 3.344189782937368

Epoch: 5| Step: 10
Training loss: 4.034849643707275
Validation loss: 3.340840846300125

Epoch: 5| Step: 11
Training loss: 3.4390368461608887
Validation loss: 3.336027830839157

Epoch: 26| Step: 0
Training loss: 3.865295886993408
Validation loss: 3.331338802973429

Epoch: 5| Step: 1
Training loss: 3.4780616760253906
Validation loss: 3.326291153828303

Epoch: 5| Step: 2
Training loss: 3.5175583362579346
Validation loss: 3.3214178383350372

Epoch: 5| Step: 3
Training loss: 3.990736484527588
Validation loss: 3.3164780139923096

Epoch: 5| Step: 4
Training loss: 2.985410213470459
Validation loss: 3.3127269446849823

Epoch: 5| Step: 5
Training loss: 3.3394298553466797
Validation loss: 3.307699908812841

Epoch: 5| Step: 6
Training loss: 2.734800100326538
Validation loss: 3.3035501341025033

Epoch: 5| Step: 7
Training loss: 3.5856430530548096
Validation loss: 3.300170054038366

Epoch: 5| Step: 8
Training loss: 3.2442195415496826
Validation loss: 3.2948759496212006

Epoch: 5| Step: 9
Training loss: 3.9932701587677
Validation loss: 3.29264435172081

Epoch: 5| Step: 10
Training loss: 3.7469964027404785
Validation loss: 3.2880136966705322

Epoch: 5| Step: 11
Training loss: 2.5846619606018066
Validation loss: 3.2830422123273215

Epoch: 27| Step: 0
Training loss: 3.9916062355041504
Validation loss: 3.280043085416158

Epoch: 5| Step: 1
Training loss: 3.2948250770568848
Validation loss: 3.2763797541459403

Epoch: 5| Step: 2
Training loss: 3.6641738414764404
Validation loss: 3.2736934224764505

Epoch: 5| Step: 3
Training loss: 3.4467854499816895
Validation loss: 3.2722974717617035

Epoch: 5| Step: 4
Training loss: 2.7131214141845703
Validation loss: 3.2666714986165366

Epoch: 5| Step: 5
Training loss: 2.9649219512939453
Validation loss: 3.262452850739161

Epoch: 5| Step: 6
Training loss: 3.7075672149658203
Validation loss: 3.2570939560731254

Epoch: 5| Step: 7
Training loss: 3.097386121749878
Validation loss: 3.252628207206726

Epoch: 5| Step: 8
Training loss: 3.196668863296509
Validation loss: 3.2510925034681954

Epoch: 5| Step: 9
Training loss: 4.344104290008545
Validation loss: 3.2472013433774314

Epoch: 5| Step: 10
Training loss: 3.5151524543762207
Validation loss: 3.240761160850525

Epoch: 5| Step: 11
Training loss: 2.7265219688415527
Validation loss: 3.2383713324864707

Epoch: 28| Step: 0
Training loss: 3.2788474559783936
Validation loss: 3.2331061959266663

Epoch: 5| Step: 1
Training loss: 3.9135773181915283
Validation loss: 3.2305320103963218

Epoch: 5| Step: 2
Training loss: 2.8844382762908936
Validation loss: 3.2259292900562286

Epoch: 5| Step: 3
Training loss: 4.063784599304199
Validation loss: 3.2211608489354453

Epoch: 5| Step: 4
Training loss: 4.706328392028809
Validation loss: 3.2171924114227295

Epoch: 5| Step: 5
Training loss: 2.7898993492126465
Validation loss: 3.2134377360343933

Epoch: 5| Step: 6
Training loss: 2.8767778873443604
Validation loss: 3.2085620065530143

Epoch: 5| Step: 7
Training loss: 2.8480052947998047
Validation loss: 3.203561762968699

Epoch: 5| Step: 8
Training loss: 3.3293464183807373
Validation loss: 3.201121677954992

Epoch: 5| Step: 9
Training loss: 3.23046612739563
Validation loss: 3.196365555127462

Epoch: 5| Step: 10
Training loss: 3.186518907546997
Validation loss: 3.1918873886267343

Epoch: 5| Step: 11
Training loss: 4.350719928741455
Validation loss: 3.188055624564489

Epoch: 29| Step: 0
Training loss: 3.3515026569366455
Validation loss: 3.1833981970945993

Epoch: 5| Step: 1
Training loss: 3.5436089038848877
Validation loss: 3.1782367626825967

Epoch: 5| Step: 2
Training loss: 2.1979479789733887
Validation loss: 3.1746658384799957

Epoch: 5| Step: 3
Training loss: 3.428910493850708
Validation loss: 3.17220339179039

Epoch: 5| Step: 4
Training loss: 2.563967227935791
Validation loss: 3.167512059211731

Epoch: 5| Step: 5
Training loss: 2.880618095397949
Validation loss: 3.161965231100718

Epoch: 5| Step: 6
Training loss: 3.507450819015503
Validation loss: 3.15825946132342

Epoch: 5| Step: 7
Training loss: 3.272686719894409
Validation loss: 3.1595543920993805

Epoch: 5| Step: 8
Training loss: 4.053101539611816
Validation loss: 3.154342303673426

Epoch: 5| Step: 9
Training loss: 4.11048698425293
Validation loss: 3.1486613849798837

Epoch: 5| Step: 10
Training loss: 3.797170639038086
Validation loss: 3.144392281770706

Epoch: 5| Step: 11
Training loss: 3.731048107147217
Validation loss: 3.1403597394625344

Epoch: 30| Step: 0
Training loss: 3.767643690109253
Validation loss: 3.1363964776198068

Epoch: 5| Step: 1
Training loss: 3.7839629650115967
Validation loss: 3.131296008825302

Epoch: 5| Step: 2
Training loss: 2.3540029525756836
Validation loss: 3.128125339746475

Epoch: 5| Step: 3
Training loss: 3.7221405506134033
Validation loss: 3.1231541136900582

Epoch: 5| Step: 4
Training loss: 3.8837292194366455
Validation loss: 3.118851621945699

Epoch: 5| Step: 5
Training loss: 3.751887083053589
Validation loss: 3.1135462721188865

Epoch: 5| Step: 6
Training loss: 3.613274097442627
Validation loss: 3.1103086372216544

Epoch: 5| Step: 7
Training loss: 2.2097878456115723
Validation loss: 3.104801058769226

Epoch: 5| Step: 8
Training loss: 3.4302985668182373
Validation loss: 3.1014392177263894

Epoch: 5| Step: 9
Training loss: 2.5971789360046387
Validation loss: 3.0977430840333304

Epoch: 5| Step: 10
Training loss: 3.4680137634277344
Validation loss: 3.091284374396006

Epoch: 5| Step: 11
Training loss: 1.9214112758636475
Validation loss: 3.0880359411239624

Epoch: 31| Step: 0
Training loss: 3.554145336151123
Validation loss: 3.0855757892131805

Epoch: 5| Step: 1
Training loss: 2.989865779876709
Validation loss: 3.0827946265538535

Epoch: 5| Step: 2
Training loss: 3.301173448562622
Validation loss: 3.078689157962799

Epoch: 5| Step: 3
Training loss: 2.9440784454345703
Validation loss: 3.076005051533381

Epoch: 5| Step: 4
Training loss: 3.423403263092041
Validation loss: 3.071804324785868

Epoch: 5| Step: 5
Training loss: 3.359205722808838
Validation loss: 3.0673520267009735

Epoch: 5| Step: 6
Training loss: 3.086214780807495
Validation loss: 3.062715023756027

Epoch: 5| Step: 7
Training loss: 2.806565523147583
Validation loss: 3.0593793392181396

Epoch: 5| Step: 8
Training loss: 3.7274138927459717
Validation loss: 3.0554704666137695

Epoch: 5| Step: 9
Training loss: 3.742724657058716
Validation loss: 3.05282269914945

Epoch: 5| Step: 10
Training loss: 3.1581485271453857
Validation loss: 3.0490444004535675

Epoch: 5| Step: 11
Training loss: 1.8236733675003052
Validation loss: 3.0463313460350037

Epoch: 32| Step: 0
Training loss: 3.6258933544158936
Validation loss: 3.04191521803538

Epoch: 5| Step: 1
Training loss: 2.8611490726470947
Validation loss: 3.0392229159673056

Epoch: 5| Step: 2
Training loss: 2.751893997192383
Validation loss: 3.034841368595759

Epoch: 5| Step: 3
Training loss: 2.490504741668701
Validation loss: 3.0307666659355164

Epoch: 5| Step: 4
Training loss: 3.1971476078033447
Validation loss: 3.028219719727834

Epoch: 5| Step: 5
Training loss: 3.5641467571258545
Validation loss: 3.0234241088231406

Epoch: 5| Step: 6
Training loss: 3.47686767578125
Validation loss: 3.0208985606829324

Epoch: 5| Step: 7
Training loss: 3.7166919708251953
Validation loss: 3.0175830125808716

Epoch: 5| Step: 8
Training loss: 4.097929000854492
Validation loss: 3.014309157927831

Epoch: 5| Step: 9
Training loss: 3.2767539024353027
Validation loss: 3.0093675752480826

Epoch: 5| Step: 10
Training loss: 2.4902679920196533
Validation loss: 3.0059474607308707

Epoch: 5| Step: 11
Training loss: 2.2684507369995117
Validation loss: 3.0012160340944924

Epoch: 33| Step: 0
Training loss: 4.0969557762146
Validation loss: 3.0012043615182242

Epoch: 5| Step: 1
Training loss: 3.6246020793914795
Validation loss: 2.9960338473320007

Epoch: 5| Step: 2
Training loss: 2.4513707160949707
Validation loss: 2.9928785463174186

Epoch: 5| Step: 3
Training loss: 3.2695953845977783
Validation loss: 2.987624208132426

Epoch: 5| Step: 4
Training loss: 2.5421535968780518
Validation loss: 2.984619051218033

Epoch: 5| Step: 5
Training loss: 3.5211997032165527
Validation loss: 2.978551040093104

Epoch: 5| Step: 6
Training loss: 2.9774649143218994
Validation loss: 2.978096882502238

Epoch: 5| Step: 7
Training loss: 3.571338653564453
Validation loss: 2.9714943865935006

Epoch: 5| Step: 8
Training loss: 2.908712863922119
Validation loss: 2.9685766895612082

Epoch: 5| Step: 9
Training loss: 3.3708279132843018
Validation loss: 2.9651947915554047

Epoch: 5| Step: 10
Training loss: 2.380371570587158
Validation loss: 2.9627412656943

Epoch: 5| Step: 11
Training loss: 4.253225803375244
Validation loss: 2.9594365457693734

Epoch: 34| Step: 0
Training loss: 3.175910234451294
Validation loss: 2.955548803011576

Epoch: 5| Step: 1
Training loss: 3.0868821144104004
Validation loss: 2.9515685786803565

Epoch: 5| Step: 2
Training loss: 3.609801769256592
Validation loss: 2.9486984809239707

Epoch: 5| Step: 3
Training loss: 3.500108003616333
Validation loss: 2.944991131623586

Epoch: 5| Step: 4
Training loss: 2.838440418243408
Validation loss: 2.941260735193888

Epoch: 5| Step: 5
Training loss: 3.002704381942749
Validation loss: 2.9372767210006714

Epoch: 5| Step: 6
Training loss: 3.040071487426758
Validation loss: 2.9341036677360535

Epoch: 5| Step: 7
Training loss: 3.1221461296081543
Validation loss: 2.930774003267288

Epoch: 5| Step: 8
Training loss: 2.8388142585754395
Validation loss: 2.92951500415802

Epoch: 5| Step: 9
Training loss: 3.2366836071014404
Validation loss: 2.925953378280004

Epoch: 5| Step: 10
Training loss: 3.2434420585632324
Validation loss: 2.9239013393719993

Epoch: 5| Step: 11
Training loss: 2.1875827312469482
Validation loss: 2.9168318013350167

Epoch: 35| Step: 0
Training loss: 4.232567310333252
Validation loss: 2.913405408461889

Epoch: 5| Step: 1
Training loss: 3.0496904850006104
Validation loss: 2.9118967751661935

Epoch: 5| Step: 2
Training loss: 2.6714720726013184
Validation loss: 2.9071992933750153

Epoch: 5| Step: 3
Training loss: 3.2282612323760986
Validation loss: 2.9053508043289185

Epoch: 5| Step: 4
Training loss: 2.6116838455200195
Validation loss: 2.901561290025711

Epoch: 5| Step: 5
Training loss: 3.113389492034912
Validation loss: 2.896904875834783

Epoch: 5| Step: 6
Training loss: 3.0997045040130615
Validation loss: 2.8930992682774863

Epoch: 5| Step: 7
Training loss: 2.65686297416687
Validation loss: 2.8892968197663627

Epoch: 5| Step: 8
Training loss: 2.5904018878936768
Validation loss: 2.886238614718119

Epoch: 5| Step: 9
Training loss: 3.3488717079162598
Validation loss: 2.8828850189844766

Epoch: 5| Step: 10
Training loss: 3.6304850578308105
Validation loss: 2.8801597158114114

Epoch: 5| Step: 11
Training loss: 2.4757351875305176
Validation loss: 2.8751431107521057

Epoch: 36| Step: 0
Training loss: 3.087480068206787
Validation loss: 2.8725470205148063

Epoch: 5| Step: 1
Training loss: 3.0478687286376953
Validation loss: 2.8718959788481393

Epoch: 5| Step: 2
Training loss: 2.580335855484009
Validation loss: 2.8700102070967355

Epoch: 5| Step: 3
Training loss: 2.648014783859253
Validation loss: 2.8692080875237784

Epoch: 5| Step: 4
Training loss: 2.798191547393799
Validation loss: 2.8624928494294486

Epoch: 5| Step: 5
Training loss: 3.529423236846924
Validation loss: 2.8588123420874276

Epoch: 5| Step: 6
Training loss: 2.966292381286621
Validation loss: 2.8548334340254464

Epoch: 5| Step: 7
Training loss: 2.7221527099609375
Validation loss: 2.8504500091075897

Epoch: 5| Step: 8
Training loss: 2.8568620681762695
Validation loss: 2.8505313098430634

Epoch: 5| Step: 9
Training loss: 4.054588317871094
Validation loss: 2.8467053870360055

Epoch: 5| Step: 10
Training loss: 3.375572919845581
Validation loss: 2.8423083126544952

Epoch: 5| Step: 11
Training loss: 3.192399501800537
Validation loss: 2.8440997302532196

Epoch: 37| Step: 0
Training loss: 2.691845417022705
Validation loss: 2.848430643479029

Epoch: 5| Step: 1
Training loss: 3.332473039627075
Validation loss: 2.846106708049774

Epoch: 5| Step: 2
Training loss: 3.0956876277923584
Validation loss: 2.833394229412079

Epoch: 5| Step: 3
Training loss: 3.627408504486084
Validation loss: 2.831802189350128

Epoch: 5| Step: 4
Training loss: 2.5942025184631348
Validation loss: 2.8313531478246055

Epoch: 5| Step: 5
Training loss: 3.271088123321533
Validation loss: 2.8290597399075827

Epoch: 5| Step: 6
Training loss: 2.795583724975586
Validation loss: 2.824660837650299

Epoch: 5| Step: 7
Training loss: 2.608168125152588
Validation loss: 2.820532282193502

Epoch: 5| Step: 8
Training loss: 3.5572447776794434
Validation loss: 2.81604873140653

Epoch: 5| Step: 9
Training loss: 2.758179187774658
Validation loss: 2.813146650791168

Epoch: 5| Step: 10
Training loss: 3.1331887245178223
Validation loss: 2.8111525774002075

Epoch: 5| Step: 11
Training loss: 2.6042861938476562
Validation loss: 2.8089667161305747

Epoch: 38| Step: 0
Training loss: 3.1455471515655518
Validation loss: 2.8070809642473855

Epoch: 5| Step: 1
Training loss: 2.779247283935547
Validation loss: 2.8066326479117074

Epoch: 5| Step: 2
Training loss: 2.7287862300872803
Validation loss: 2.8033843437830606

Epoch: 5| Step: 3
Training loss: 2.7605271339416504
Validation loss: 2.8014629085858664

Epoch: 5| Step: 4
Training loss: 3.159641742706299
Validation loss: 2.7948693335056305

Epoch: 5| Step: 5
Training loss: 2.607332229614258
Validation loss: 2.79077077905337

Epoch: 5| Step: 6
Training loss: 2.9631881713867188
Validation loss: 2.784668952226639

Epoch: 5| Step: 7
Training loss: 2.9784140586853027
Validation loss: 2.783359785874685

Epoch: 5| Step: 8
Training loss: 3.033747434616089
Validation loss: 2.780527651309967

Epoch: 5| Step: 9
Training loss: 3.5875244140625
Validation loss: 2.776982049147288

Epoch: 5| Step: 10
Training loss: 3.0032944679260254
Validation loss: 2.7737740774949393

Epoch: 5| Step: 11
Training loss: 4.192433834075928
Validation loss: 2.769453595081965

Epoch: 39| Step: 0
Training loss: 3.382112979888916
Validation loss: 2.7664589087168374

Epoch: 5| Step: 1
Training loss: 2.58081316947937
Validation loss: 2.76459305981795

Epoch: 5| Step: 2
Training loss: 2.9181666374206543
Validation loss: 2.7606734335422516

Epoch: 5| Step: 3
Training loss: 2.596440076828003
Validation loss: 2.756716161966324

Epoch: 5| Step: 4
Training loss: 3.03548264503479
Validation loss: 2.7553368409474692

Epoch: 5| Step: 5
Training loss: 3.0521163940429688
Validation loss: 2.75232587258021

Epoch: 5| Step: 6
Training loss: 2.7627851963043213
Validation loss: 2.7482506533463797

Epoch: 5| Step: 7
Training loss: 2.990520715713501
Validation loss: 2.7457958261171975

Epoch: 5| Step: 8
Training loss: 3.1669535636901855
Validation loss: 2.741728792587916

Epoch: 5| Step: 9
Training loss: 3.3818535804748535
Validation loss: 2.7397632201512656

Epoch: 5| Step: 10
Training loss: 2.544900894165039
Validation loss: 2.737572173277537

Epoch: 5| Step: 11
Training loss: 3.7068116664886475
Validation loss: 2.7345415453116098

Epoch: 40| Step: 0
Training loss: 3.0412888526916504
Validation loss: 2.7304097414016724

Epoch: 5| Step: 1
Training loss: 2.4989964962005615
Validation loss: 2.726760039726893

Epoch: 5| Step: 2
Training loss: 2.7715446949005127
Validation loss: 2.725233276685079

Epoch: 5| Step: 3
Training loss: 3.043297052383423
Validation loss: 2.724260538816452

Epoch: 5| Step: 4
Training loss: 3.1128334999084473
Validation loss: 2.7184403936068215

Epoch: 5| Step: 5
Training loss: 3.3648884296417236
Validation loss: 2.7134077151616416

Epoch: 5| Step: 6
Training loss: 3.563816785812378
Validation loss: 2.7097783784071603

Epoch: 5| Step: 7
Training loss: 2.843726396560669
Validation loss: 2.706817110379537

Epoch: 5| Step: 8
Training loss: 2.4280524253845215
Validation loss: 2.7033484180768332

Epoch: 5| Step: 9
Training loss: 2.8542048931121826
Validation loss: 2.699155330657959

Epoch: 5| Step: 10
Training loss: 2.7741637229919434
Validation loss: 2.6959526439507804

Epoch: 5| Step: 11
Training loss: 2.080435276031494
Validation loss: 2.6918867329756417

Epoch: 41| Step: 0
Training loss: 3.1349270343780518
Validation loss: 2.690432290236155

Epoch: 5| Step: 1
Training loss: 3.0663347244262695
Validation loss: 2.6882334550221763

Epoch: 5| Step: 2
Training loss: 3.2880306243896484
Validation loss: 2.6836266418298087

Epoch: 5| Step: 3
Training loss: 2.4647786617279053
Validation loss: 2.6846171617507935

Epoch: 5| Step: 4
Training loss: 2.4220335483551025
Validation loss: 2.677784740924835

Epoch: 5| Step: 5
Training loss: 3.211271286010742
Validation loss: 2.6752591331799827

Epoch: 5| Step: 6
Training loss: 2.7341482639312744
Validation loss: 2.6733234028021493

Epoch: 5| Step: 7
Training loss: 2.8263027667999268
Validation loss: 2.674946496884028

Epoch: 5| Step: 8
Training loss: 3.1727118492126465
Validation loss: 2.672359307607015

Epoch: 5| Step: 9
Training loss: 2.573172092437744
Validation loss: 2.6669355630874634

Epoch: 5| Step: 10
Training loss: 2.884146213531494
Validation loss: 2.6596340437730155

Epoch: 5| Step: 11
Training loss: 2.4814069271087646
Validation loss: 2.6586108903090158

Epoch: 42| Step: 0
Training loss: 3.001595973968506
Validation loss: 2.658285230398178

Epoch: 5| Step: 1
Training loss: 2.8045027256011963
Validation loss: 2.658233260114988

Epoch: 5| Step: 2
Training loss: 2.9186325073242188
Validation loss: 2.6538985470930734

Epoch: 5| Step: 3
Training loss: 2.8119759559631348
Validation loss: 2.6519234478473663

Epoch: 5| Step: 4
Training loss: 2.967869281768799
Validation loss: 2.654251217842102

Epoch: 5| Step: 5
Training loss: 2.719482421875
Validation loss: 2.648650815089544

Epoch: 5| Step: 6
Training loss: 2.719078540802002
Validation loss: 2.6426936785380044

Epoch: 5| Step: 7
Training loss: 3.089315414428711
Validation loss: 2.6365242501099906

Epoch: 5| Step: 8
Training loss: 2.7246689796447754
Validation loss: 2.635031054417292

Epoch: 5| Step: 9
Training loss: 2.8926851749420166
Validation loss: 2.6349151829878488

Epoch: 5| Step: 10
Training loss: 2.7525429725646973
Validation loss: 2.6341048181056976

Epoch: 5| Step: 11
Training loss: 2.4391775131225586
Validation loss: 2.6321870485941568

Epoch: 43| Step: 0
Training loss: 2.9348819255828857
Validation loss: 2.6298444867134094

Epoch: 5| Step: 1
Training loss: 2.547246217727661
Validation loss: 2.623906989892324

Epoch: 5| Step: 2
Training loss: 2.8138246536254883
Validation loss: 2.6201078792413077

Epoch: 5| Step: 3
Training loss: 2.6386706829071045
Validation loss: 2.616602808237076

Epoch: 5| Step: 4
Training loss: 3.007025957107544
Validation loss: 2.610976457595825

Epoch: 5| Step: 5
Training loss: 2.1090736389160156
Validation loss: 2.6100600759188333

Epoch: 5| Step: 6
Training loss: 3.1949286460876465
Validation loss: 2.606610973676046

Epoch: 5| Step: 7
Training loss: 2.738581895828247
Validation loss: 2.606514592965444

Epoch: 5| Step: 8
Training loss: 3.0769200325012207
Validation loss: 2.604236533244451

Epoch: 5| Step: 9
Training loss: 2.8685073852539062
Validation loss: 2.599746818343798

Epoch: 5| Step: 10
Training loss: 3.2741000652313232
Validation loss: 2.5958635210990906

Epoch: 5| Step: 11
Training loss: 1.7144570350646973
Validation loss: 2.594856987396876

Epoch: 44| Step: 0
Training loss: 2.5568366050720215
Validation loss: 2.5947073698043823

Epoch: 5| Step: 1
Training loss: 2.5657966136932373
Validation loss: 2.5936237275600433

Epoch: 5| Step: 2
Training loss: 2.7701573371887207
Validation loss: 2.5947935779889426

Epoch: 5| Step: 3
Training loss: 3.1605896949768066
Validation loss: 2.59154682358106

Epoch: 5| Step: 4
Training loss: 2.465427875518799
Validation loss: 2.588518222173055

Epoch: 5| Step: 5
Training loss: 3.3143601417541504
Validation loss: 2.5851572354634604

Epoch: 5| Step: 6
Training loss: 2.6442716121673584
Validation loss: 2.5810763835906982

Epoch: 5| Step: 7
Training loss: 2.746091604232788
Validation loss: 2.5763786832491555

Epoch: 5| Step: 8
Training loss: 2.4370298385620117
Validation loss: 2.570635666449865

Epoch: 5| Step: 9
Training loss: 2.7864673137664795
Validation loss: 2.57132222255071

Epoch: 5| Step: 10
Training loss: 3.2767486572265625
Validation loss: 2.5704966882864633

Epoch: 5| Step: 11
Training loss: 2.400223970413208
Validation loss: 2.5689616998036704

Epoch: 45| Step: 0
Training loss: 2.9078497886657715
Validation loss: 2.5724072257677713

Epoch: 5| Step: 1
Training loss: 2.4442248344421387
Validation loss: 2.5745162268479667

Epoch: 5| Step: 2
Training loss: 3.2413291931152344
Validation loss: 2.571902811527252

Epoch: 5| Step: 3
Training loss: 2.963822841644287
Validation loss: 2.5625184079011283

Epoch: 5| Step: 4
Training loss: 1.812267541885376
Validation loss: 2.548407862583796

Epoch: 5| Step: 5
Training loss: 3.0963072776794434
Validation loss: 2.544687936703364

Epoch: 5| Step: 6
Training loss: 2.7557168006896973
Validation loss: 2.541502724091212

Epoch: 5| Step: 7
Training loss: 3.1285433769226074
Validation loss: 2.539471447467804

Epoch: 5| Step: 8
Training loss: 2.7339327335357666
Validation loss: 2.5369399090607962

Epoch: 5| Step: 9
Training loss: 2.5923640727996826
Validation loss: 2.5342934926350913

Epoch: 5| Step: 10
Training loss: 2.686579942703247
Validation loss: 2.533019036054611

Epoch: 5| Step: 11
Training loss: 2.4961228370666504
Validation loss: 2.5297935754060745

Epoch: 46| Step: 0
Training loss: 2.533576488494873
Validation loss: 2.527444119254748

Epoch: 5| Step: 1
Training loss: 2.4770617485046387
Validation loss: 2.5250129948059716

Epoch: 5| Step: 2
Training loss: 3.1385440826416016
Validation loss: 2.5211239655812583

Epoch: 5| Step: 3
Training loss: 2.8192012310028076
Validation loss: 2.5198333660761514

Epoch: 5| Step: 4
Training loss: 2.6427512168884277
Validation loss: 2.5150953928629556

Epoch: 5| Step: 5
Training loss: 2.7420594692230225
Validation loss: 2.514616916577021

Epoch: 5| Step: 6
Training loss: 3.0570461750030518
Validation loss: 2.509267032146454

Epoch: 5| Step: 7
Training loss: 2.6502623558044434
Validation loss: 2.5064855217933655

Epoch: 5| Step: 8
Training loss: 2.5166819095611572
Validation loss: 2.5044102370738983

Epoch: 5| Step: 9
Training loss: 2.6141607761383057
Validation loss: 2.5003379384676614

Epoch: 5| Step: 10
Training loss: 2.5772037506103516
Validation loss: 2.4949644953012466

Epoch: 5| Step: 11
Training loss: 2.9646646976470947
Validation loss: 2.494588871796926

Epoch: 47| Step: 0
Training loss: 2.5181877613067627
Validation loss: 2.492722521225611

Epoch: 5| Step: 1
Training loss: 2.553518772125244
Validation loss: 2.4894898732503257

Epoch: 5| Step: 2
Training loss: 2.5624241828918457
Validation loss: 2.4883645673592887

Epoch: 5| Step: 3
Training loss: 2.651510715484619
Validation loss: 2.4854321777820587

Epoch: 5| Step: 4
Training loss: 2.8771634101867676
Validation loss: 2.482668489217758

Epoch: 5| Step: 5
Training loss: 2.870793104171753
Validation loss: 2.480441073576609

Epoch: 5| Step: 6
Training loss: 2.9459638595581055
Validation loss: 2.4753834505875907

Epoch: 5| Step: 7
Training loss: 2.393494129180908
Validation loss: 2.4722260932127633

Epoch: 5| Step: 8
Training loss: 2.978557825088501
Validation loss: 2.471111983060837

Epoch: 5| Step: 9
Training loss: 2.649519681930542
Validation loss: 2.467627535263697

Epoch: 5| Step: 10
Training loss: 2.3679866790771484
Validation loss: 2.4636307458082833

Epoch: 5| Step: 11
Training loss: 2.988018274307251
Validation loss: 2.4608068267504373

Epoch: 48| Step: 0
Training loss: 2.623215436935425
Validation loss: 2.461169019341469

Epoch: 5| Step: 1
Training loss: 2.322819948196411
Validation loss: 2.4674786726633706

Epoch: 5| Step: 2
Training loss: 2.7318873405456543
Validation loss: 2.49067231019338

Epoch: 5| Step: 3
Training loss: 2.2157037258148193
Validation loss: 2.503686845302582

Epoch: 5| Step: 4
Training loss: 2.666076183319092
Validation loss: 2.489982694387436

Epoch: 5| Step: 5
Training loss: 3.1022326946258545
Validation loss: 2.4858611623446145

Epoch: 5| Step: 6
Training loss: 2.899174690246582
Validation loss: 2.4819586277008057

Epoch: 5| Step: 7
Training loss: 2.557816982269287
Validation loss: 2.4761284391085305

Epoch: 5| Step: 8
Training loss: 2.3891189098358154
Validation loss: 2.4767524699370065

Epoch: 5| Step: 9
Training loss: 2.8712246417999268
Validation loss: 2.4726511240005493

Epoch: 5| Step: 10
Training loss: 2.9091556072235107
Validation loss: 2.470338001847267

Epoch: 5| Step: 11
Training loss: 3.2489054203033447
Validation loss: 2.4672673841317496

Epoch: 49| Step: 0
Training loss: 2.370175838470459
Validation loss: 2.463308572769165

Epoch: 5| Step: 1
Training loss: 2.5975341796875
Validation loss: 2.46171901623408

Epoch: 5| Step: 2
Training loss: 2.7530500888824463
Validation loss: 2.459478199481964

Epoch: 5| Step: 3
Training loss: 2.411081552505493
Validation loss: 2.4561660289764404

Epoch: 5| Step: 4
Training loss: 2.279662609100342
Validation loss: 2.4523593882719674

Epoch: 5| Step: 5
Training loss: 2.784048557281494
Validation loss: 2.448613484700521

Epoch: 5| Step: 6
Training loss: 1.9798784255981445
Validation loss: 2.4487894475460052

Epoch: 5| Step: 7
Training loss: 2.5347695350646973
Validation loss: 2.4480105539162955

Epoch: 5| Step: 8
Training loss: 2.987560749053955
Validation loss: 2.444805383682251

Epoch: 5| Step: 9
Training loss: 3.1939480304718018
Validation loss: 2.4448739290237427

Epoch: 5| Step: 10
Training loss: 3.122828960418701
Validation loss: 2.440785671273867

Epoch: 5| Step: 11
Training loss: 3.03402042388916
Validation loss: 2.438325449824333

Epoch: 50| Step: 0
Training loss: 3.222891330718994
Validation loss: 2.433273340264956

Epoch: 5| Step: 1
Training loss: 3.1849935054779053
Validation loss: 2.4260163803895316

Epoch: 5| Step: 2
Training loss: 2.2480661869049072
Validation loss: 2.423316260178884

Epoch: 5| Step: 3
Training loss: 2.032477855682373
Validation loss: 2.419393246372541

Epoch: 5| Step: 4
Training loss: 2.3735663890838623
Validation loss: 2.4187403420607247

Epoch: 5| Step: 5
Training loss: 2.839404582977295
Validation loss: 2.4161700109640756

Epoch: 5| Step: 6
Training loss: 2.078449249267578
Validation loss: 2.4111349880695343

Epoch: 5| Step: 7
Training loss: 2.062427282333374
Validation loss: 2.4089467028776803

Epoch: 5| Step: 8
Training loss: 2.4073476791381836
Validation loss: 2.404666324456533

Epoch: 5| Step: 9
Training loss: 3.447232723236084
Validation loss: 2.4037027060985565

Epoch: 5| Step: 10
Training loss: 2.742058277130127
Validation loss: 2.4036973218123117

Epoch: 5| Step: 11
Training loss: 2.555874824523926
Validation loss: 2.40070370833079

Epoch: 51| Step: 0
Training loss: 2.5548489093780518
Validation loss: 2.394911915063858

Epoch: 5| Step: 1
Training loss: 2.4222919940948486
Validation loss: 2.393332024415334

Epoch: 5| Step: 2
Training loss: 2.52874493598938
Validation loss: 2.3900096118450165

Epoch: 5| Step: 3
Training loss: 2.3208868503570557
Validation loss: 2.3901645292838416

Epoch: 5| Step: 4
Training loss: 2.848334550857544
Validation loss: 2.3861147363980613

Epoch: 5| Step: 5
Training loss: 2.337656021118164
Validation loss: 2.381342122952143

Epoch: 5| Step: 6
Training loss: 2.3194079399108887
Validation loss: 2.381700317064921

Epoch: 5| Step: 7
Training loss: 2.6391172409057617
Validation loss: 2.3858050207297006

Epoch: 5| Step: 8
Training loss: 3.2378668785095215
Validation loss: 2.380452439188957

Epoch: 5| Step: 9
Training loss: 2.5582969188690186
Validation loss: 2.377201279004415

Epoch: 5| Step: 10
Training loss: 2.404470443725586
Validation loss: 2.366930812597275

Epoch: 5| Step: 11
Training loss: 2.769681453704834
Validation loss: 2.3657017846902213

Epoch: 52| Step: 0
Training loss: 2.852090835571289
Validation loss: 2.3596633672714233

Epoch: 5| Step: 1
Training loss: 3.0648343563079834
Validation loss: 2.35329033434391

Epoch: 5| Step: 2
Training loss: 2.9844746589660645
Validation loss: 2.353042483329773

Epoch: 5| Step: 3
Training loss: 2.0667028427124023
Validation loss: 2.3455377171436944

Epoch: 5| Step: 4
Training loss: 2.15623140335083
Validation loss: 2.3399650553862252

Epoch: 5| Step: 5
Training loss: 2.0150787830352783
Validation loss: 2.324322501818339

Epoch: 5| Step: 6
Training loss: 2.7095911502838135
Validation loss: 2.322004641095797

Epoch: 5| Step: 7
Training loss: 2.730482578277588
Validation loss: 2.321433112025261

Epoch: 5| Step: 8
Training loss: 2.31219220161438
Validation loss: 2.3192676107088723

Epoch: 5| Step: 9
Training loss: 2.0704822540283203
Validation loss: 2.3136504540840783

Epoch: 5| Step: 10
Training loss: 2.654020309448242
Validation loss: 2.3135879784822464

Epoch: 5| Step: 11
Training loss: 2.6520261764526367
Validation loss: 2.3115962147712708

Epoch: 53| Step: 0
Training loss: 2.7345967292785645
Validation loss: 2.3096961776415506

Epoch: 5| Step: 1
Training loss: 2.2681965827941895
Validation loss: 2.3081131229797998

Epoch: 5| Step: 2
Training loss: 2.345003604888916
Validation loss: 2.3082368473211923

Epoch: 5| Step: 3
Training loss: 2.4418551921844482
Validation loss: 2.3049057771762214

Epoch: 5| Step: 4
Training loss: 2.3875415325164795
Validation loss: 2.30700113872687

Epoch: 5| Step: 5
Training loss: 2.4506900310516357
Validation loss: 2.3060116469860077

Epoch: 5| Step: 6
Training loss: 2.087517261505127
Validation loss: 2.293796877066294

Epoch: 5| Step: 7
Training loss: 2.4600753784179688
Validation loss: 2.2895276149113974

Epoch: 5| Step: 8
Training loss: 2.687500476837158
Validation loss: 2.285321762164434

Epoch: 5| Step: 9
Training loss: 2.336353302001953
Validation loss: 2.2882004181543985

Epoch: 5| Step: 10
Training loss: 3.0813145637512207
Validation loss: 2.2865023712317147

Epoch: 5| Step: 11
Training loss: 2.140883445739746
Validation loss: 2.283026879032453

Epoch: 54| Step: 0
Training loss: 2.577753782272339
Validation loss: 2.281294713417689

Epoch: 5| Step: 1
Training loss: 2.0492472648620605
Validation loss: 2.278688540061315

Epoch: 5| Step: 2
Training loss: 2.7100346088409424
Validation loss: 2.2755951484044394

Epoch: 5| Step: 3
Training loss: 2.9316201210021973
Validation loss: 2.2736428479353585

Epoch: 5| Step: 4
Training loss: 2.166585922241211
Validation loss: 2.2712577084700265

Epoch: 5| Step: 5
Training loss: 2.5841612815856934
Validation loss: 2.2698646833499274

Epoch: 5| Step: 6
Training loss: 2.8767285346984863
Validation loss: 2.2667219787836075

Epoch: 5| Step: 7
Training loss: 1.8620612621307373
Validation loss: 2.264034777879715

Epoch: 5| Step: 8
Training loss: 1.923844575881958
Validation loss: 2.2610359688599906

Epoch: 5| Step: 9
Training loss: 2.4742777347564697
Validation loss: 2.259766230980555

Epoch: 5| Step: 10
Training loss: 2.6229407787323
Validation loss: 2.2573157846927643

Epoch: 5| Step: 11
Training loss: 2.5763518810272217
Validation loss: 2.254557281732559

Epoch: 55| Step: 0
Training loss: 2.5665128231048584
Validation loss: 2.2511872202157974

Epoch: 5| Step: 1
Training loss: 2.7480056285858154
Validation loss: 2.247475509842237

Epoch: 5| Step: 2
Training loss: 2.182588815689087
Validation loss: 2.248373582959175

Epoch: 5| Step: 3
Training loss: 2.040898084640503
Validation loss: 2.2478959957758584

Epoch: 5| Step: 4
Training loss: 2.2334609031677246
Validation loss: 2.2512510816256204

Epoch: 5| Step: 5
Training loss: 2.505892276763916
Validation loss: 2.2483284175395966

Epoch: 5| Step: 6
Training loss: 2.5343620777130127
Validation loss: 2.2499332278966904

Epoch: 5| Step: 7
Training loss: 2.176022529602051
Validation loss: 2.241726726293564

Epoch: 5| Step: 8
Training loss: 2.650987148284912
Validation loss: 2.237411061922709

Epoch: 5| Step: 9
Training loss: 2.0125632286071777
Validation loss: 2.2306229372819266

Epoch: 5| Step: 10
Training loss: 2.5238871574401855
Validation loss: 2.227884034315745

Epoch: 5| Step: 11
Training loss: 3.7711968421936035
Validation loss: 2.2290824949741364

Epoch: 56| Step: 0
Training loss: 2.320289134979248
Validation loss: 2.231011832753817

Epoch: 5| Step: 1
Training loss: 1.8550083637237549
Validation loss: 2.233359605073929

Epoch: 5| Step: 2
Training loss: 2.929975986480713
Validation loss: 2.2295561929543815

Epoch: 5| Step: 3
Training loss: 2.3496005535125732
Validation loss: 2.2316515843073526

Epoch: 5| Step: 4
Training loss: 2.4479172229766846
Validation loss: 2.2303214967250824

Epoch: 5| Step: 5
Training loss: 1.720327615737915
Validation loss: 2.230487192670504

Epoch: 5| Step: 6
Training loss: 2.3688976764678955
Validation loss: 2.231594999631246

Epoch: 5| Step: 7
Training loss: 2.2093968391418457
Validation loss: 2.230466350913048

Epoch: 5| Step: 8
Training loss: 2.716588258743286
Validation loss: 2.227049251397451

Epoch: 5| Step: 9
Training loss: 2.8657472133636475
Validation loss: 2.2260524183511734

Epoch: 5| Step: 10
Training loss: 2.342648506164551
Validation loss: 2.2201219499111176

Epoch: 5| Step: 11
Training loss: 3.149064064025879
Validation loss: 2.218319982290268

Epoch: 57| Step: 0
Training loss: 2.828874111175537
Validation loss: 2.2124256690343223

Epoch: 5| Step: 1
Training loss: 2.599947690963745
Validation loss: 2.207396229108175

Epoch: 5| Step: 2
Training loss: 2.2156105041503906
Validation loss: 2.204176892836889

Epoch: 5| Step: 3
Training loss: 2.250094175338745
Validation loss: 2.203565647204717

Epoch: 5| Step: 4
Training loss: 2.456617593765259
Validation loss: 2.196679800748825

Epoch: 5| Step: 5
Training loss: 2.1513428688049316
Validation loss: 2.197660267353058

Epoch: 5| Step: 6
Training loss: 2.2063260078430176
Validation loss: 2.194468935330709

Epoch: 5| Step: 7
Training loss: 2.323892593383789
Validation loss: 2.189343959093094

Epoch: 5| Step: 8
Training loss: 2.295149803161621
Validation loss: 2.1914494832356772

Epoch: 5| Step: 9
Training loss: 2.2615885734558105
Validation loss: 2.191491777698199

Epoch: 5| Step: 10
Training loss: 2.1095173358917236
Validation loss: 2.1912417511145272

Epoch: 5| Step: 11
Training loss: 3.111262321472168
Validation loss: 2.198163171609243

Epoch: 58| Step: 0
Training loss: 2.5910587310791016
Validation loss: 2.2108429074287415

Epoch: 5| Step: 1
Training loss: 2.7430338859558105
Validation loss: 2.2142459551493325

Epoch: 5| Step: 2
Training loss: 2.470923662185669
Validation loss: 2.206729749838511

Epoch: 5| Step: 3
Training loss: 2.399562358856201
Validation loss: 2.190911754965782

Epoch: 5| Step: 4
Training loss: 1.7052862644195557
Validation loss: 2.178334484497706

Epoch: 5| Step: 5
Training loss: 2.8668150901794434
Validation loss: 2.17673023045063

Epoch: 5| Step: 6
Training loss: 2.6279549598693848
Validation loss: 2.1766081154346466

Epoch: 5| Step: 7
Training loss: 2.3308842182159424
Validation loss: 2.1760951479276023

Epoch: 5| Step: 8
Training loss: 1.851377248764038
Validation loss: 2.17777311305205

Epoch: 5| Step: 9
Training loss: 2.2856810092926025
Validation loss: 2.1815569748481116

Epoch: 5| Step: 10
Training loss: 2.4483304023742676
Validation loss: 2.1875393440326056

Epoch: 5| Step: 11
Training loss: 0.9471969604492188
Validation loss: 2.1922294199466705

Epoch: 59| Step: 0
Training loss: 2.3251850605010986
Validation loss: 2.1965195139249167

Epoch: 5| Step: 1
Training loss: 2.7390239238739014
Validation loss: 2.189920743306478

Epoch: 5| Step: 2
Training loss: 2.7754905223846436
Validation loss: 2.1913185516993203

Epoch: 5| Step: 3
Training loss: 2.414435863494873
Validation loss: 2.1923691779375076

Epoch: 5| Step: 4
Training loss: 2.008028030395508
Validation loss: 2.1895464062690735

Epoch: 5| Step: 5
Training loss: 2.0094120502471924
Validation loss: 2.182770679394404

Epoch: 5| Step: 6
Training loss: 2.345939874649048
Validation loss: 2.179035176833471

Epoch: 5| Step: 7
Training loss: 2.092115640640259
Validation loss: 2.1743732690811157

Epoch: 5| Step: 8
Training loss: 2.0612640380859375
Validation loss: 2.172168011466662

Epoch: 5| Step: 9
Training loss: 2.3531510829925537
Validation loss: 2.1704040418068566

Epoch: 5| Step: 10
Training loss: 2.3696694374084473
Validation loss: 2.1639729142189026

Epoch: 5| Step: 11
Training loss: 3.73366641998291
Validation loss: 2.162387102842331

Epoch: 60| Step: 0
Training loss: 2.432918071746826
Validation loss: 2.160659526785215

Epoch: 5| Step: 1
Training loss: 2.852257490158081
Validation loss: 2.1582536498705545

Epoch: 5| Step: 2
Training loss: 2.0059521198272705
Validation loss: 2.158459876974424

Epoch: 5| Step: 3
Training loss: 2.326371908187866
Validation loss: 2.1586902340253196

Epoch: 5| Step: 4
Training loss: 1.9341840744018555
Validation loss: 2.1568207194407782

Epoch: 5| Step: 5
Training loss: 1.9679546356201172
Validation loss: 2.1559943507115045

Epoch: 5| Step: 6
Training loss: 2.4110054969787598
Validation loss: 2.1532941857973733

Epoch: 5| Step: 7
Training loss: 2.6850533485412598
Validation loss: 2.162143260240555

Epoch: 5| Step: 8
Training loss: 2.079009532928467
Validation loss: 2.1596588442722955

Epoch: 5| Step: 9
Training loss: 2.695707082748413
Validation loss: 2.1553917775551477

Epoch: 5| Step: 10
Training loss: 2.179124355316162
Validation loss: 2.1523254911104837

Epoch: 5| Step: 11
Training loss: 2.243194103240967
Validation loss: 2.1526749233404794

Epoch: 61| Step: 0
Training loss: 2.2958779335021973
Validation loss: 2.153126542766889

Epoch: 5| Step: 1
Training loss: 2.538064479827881
Validation loss: 2.150187775492668

Epoch: 5| Step: 2
Training loss: 2.673326253890991
Validation loss: 2.1418407559394836

Epoch: 5| Step: 3
Training loss: 2.1882476806640625
Validation loss: 2.1372518241405487

Epoch: 5| Step: 4
Training loss: 2.012021541595459
Validation loss: 2.13007819155852

Epoch: 5| Step: 5
Training loss: 2.4296364784240723
Validation loss: 2.1381674458583197

Epoch: 5| Step: 6
Training loss: 2.926450252532959
Validation loss: 2.1308309932549796

Epoch: 5| Step: 7
Training loss: 2.024354934692383
Validation loss: 2.129016493757566

Epoch: 5| Step: 8
Training loss: 2.354492664337158
Validation loss: 2.127831369638443

Epoch: 5| Step: 9
Training loss: 2.0299201011657715
Validation loss: 2.12522292137146

Epoch: 5| Step: 10
Training loss: 1.926232099533081
Validation loss: 2.1282524466514587

Epoch: 5| Step: 11
Training loss: 2.463362455368042
Validation loss: 2.1263432105382285

Epoch: 62| Step: 0
Training loss: 2.157050371170044
Validation loss: 2.125110516945521

Epoch: 5| Step: 1
Training loss: 2.269124984741211
Validation loss: 2.119898408651352

Epoch: 5| Step: 2
Training loss: 2.3132457733154297
Validation loss: 2.124506339430809

Epoch: 5| Step: 3
Training loss: 2.3328516483306885
Validation loss: 2.118828018506368

Epoch: 5| Step: 4
Training loss: 2.332624912261963
Validation loss: 2.1192976286013923

Epoch: 5| Step: 5
Training loss: 1.7738335132598877
Validation loss: 2.1124512453873954

Epoch: 5| Step: 6
Training loss: 1.861675500869751
Validation loss: 2.110987181464831

Epoch: 5| Step: 7
Training loss: 3.0336861610412598
Validation loss: 2.11002246538798

Epoch: 5| Step: 8
Training loss: 2.3398263454437256
Validation loss: 2.1090969492991767

Epoch: 5| Step: 9
Training loss: 2.4170470237731934
Validation loss: 2.109303509195646

Epoch: 5| Step: 10
Training loss: 2.4586997032165527
Validation loss: 2.1048764089743295

Epoch: 5| Step: 11
Training loss: 1.6694241762161255
Validation loss: 2.0974198331435523

Epoch: 63| Step: 0
Training loss: 2.2101311683654785
Validation loss: 2.104475647211075

Epoch: 5| Step: 1
Training loss: 2.5859687328338623
Validation loss: 2.107923835515976

Epoch: 5| Step: 2
Training loss: 2.643808126449585
Validation loss: 2.114056333899498

Epoch: 5| Step: 3
Training loss: 2.4671385288238525
Validation loss: 2.1125277231136956

Epoch: 5| Step: 4
Training loss: 2.1434669494628906
Validation loss: 2.1165311535199485

Epoch: 5| Step: 5
Training loss: 2.1238112449645996
Validation loss: 2.111899028221766

Epoch: 5| Step: 6
Training loss: 2.154542922973633
Validation loss: 2.1148969183365502

Epoch: 5| Step: 7
Training loss: 2.2303519248962402
Validation loss: 2.118328794836998

Epoch: 5| Step: 8
Training loss: 1.8765357732772827
Validation loss: 2.114613821109136

Epoch: 5| Step: 9
Training loss: 2.4210264682769775
Validation loss: 2.1134522358576455

Epoch: 5| Step: 10
Training loss: 2.230952501296997
Validation loss: 2.118505651752154

Epoch: 5| Step: 11
Training loss: 2.4788684844970703
Validation loss: 2.1147629717985788

Epoch: 64| Step: 0
Training loss: 2.132357120513916
Validation loss: 2.1055588523546853

Epoch: 5| Step: 1
Training loss: 2.222869396209717
Validation loss: 2.1092486133178077

Epoch: 5| Step: 2
Training loss: 2.5137362480163574
Validation loss: 2.106908395886421

Epoch: 5| Step: 3
Training loss: 2.020130157470703
Validation loss: 2.10080049932003

Epoch: 5| Step: 4
Training loss: 2.5322861671447754
Validation loss: 2.1021801034609475

Epoch: 5| Step: 5
Training loss: 2.4390971660614014
Validation loss: 2.099814067284266

Epoch: 5| Step: 6
Training loss: 2.443310499191284
Validation loss: 2.0958436528841653

Epoch: 5| Step: 7
Training loss: 2.087230682373047
Validation loss: 2.094800442457199

Epoch: 5| Step: 8
Training loss: 1.6392605304718018
Validation loss: 2.0896108547846475

Epoch: 5| Step: 9
Training loss: 2.3032498359680176
Validation loss: 2.0871821641921997

Epoch: 5| Step: 10
Training loss: 2.7967987060546875
Validation loss: 2.0927834610144296

Epoch: 5| Step: 11
Training loss: 2.006270408630371
Validation loss: 2.082414527734121

Epoch: 65| Step: 0
Training loss: 2.222808837890625
Validation loss: 2.084931413332621

Epoch: 5| Step: 1
Training loss: 2.717755079269409
Validation loss: 2.0820923099915185

Epoch: 5| Step: 2
Training loss: 2.157763957977295
Validation loss: 2.0764600932598114

Epoch: 5| Step: 3
Training loss: 2.248684883117676
Validation loss: 2.070962538321813

Epoch: 5| Step: 4
Training loss: 1.8329126834869385
Validation loss: 2.0760335276524224

Epoch: 5| Step: 5
Training loss: 2.3740344047546387
Validation loss: 2.071569323539734

Epoch: 5| Step: 6
Training loss: 2.098841905593872
Validation loss: 2.0751696825027466

Epoch: 5| Step: 7
Training loss: 2.7196426391601562
Validation loss: 2.0782962888479233

Epoch: 5| Step: 8
Training loss: 2.294079303741455
Validation loss: 2.063224568963051

Epoch: 5| Step: 9
Training loss: 2.50222110748291
Validation loss: 2.0729086101055145

Epoch: 5| Step: 10
Training loss: 1.7715930938720703
Validation loss: 2.0662091970443726

Epoch: 5| Step: 11
Training loss: 1.9471855163574219
Validation loss: 2.067884544531504

Epoch: 66| Step: 0
Training loss: 2.345022678375244
Validation loss: 2.0704036752382913

Epoch: 5| Step: 1
Training loss: 2.4042978286743164
Validation loss: 2.070343161622683

Epoch: 5| Step: 2
Training loss: 2.7135181427001953
Validation loss: 2.082928935686747

Epoch: 5| Step: 3
Training loss: 2.285360336303711
Validation loss: 2.0839139819145203

Epoch: 5| Step: 4
Training loss: 2.487196445465088
Validation loss: 2.082648033897082

Epoch: 5| Step: 5
Training loss: 2.3876075744628906
Validation loss: 2.0831705580155053

Epoch: 5| Step: 6
Training loss: 2.0546255111694336
Validation loss: 2.0769526412089667

Epoch: 5| Step: 7
Training loss: 2.1788723468780518
Validation loss: 2.07587922612826

Epoch: 5| Step: 8
Training loss: 1.789442777633667
Validation loss: 2.068590392669042

Epoch: 5| Step: 9
Training loss: 2.0264923572540283
Validation loss: 2.0627003957827887

Epoch: 5| Step: 10
Training loss: 2.0489614009857178
Validation loss: 2.0626402695973716

Epoch: 5| Step: 11
Training loss: 2.6871447563171387
Validation loss: 2.0582485496997833

Epoch: 67| Step: 0
Training loss: 2.0770843029022217
Validation loss: 2.0660410126050315

Epoch: 5| Step: 1
Training loss: 2.1673195362091064
Validation loss: 2.0643347998460135

Epoch: 5| Step: 2
Training loss: 2.132314920425415
Validation loss: 2.064529890815417

Epoch: 5| Step: 3
Training loss: 2.146104097366333
Validation loss: 2.066191484530767

Epoch: 5| Step: 4
Training loss: 2.2189719676971436
Validation loss: 2.062325651446978

Epoch: 5| Step: 5
Training loss: 2.2371621131896973
Validation loss: 2.0652396082878113

Epoch: 5| Step: 6
Training loss: 2.244913339614868
Validation loss: 2.0662311812241874

Epoch: 5| Step: 7
Training loss: 2.353644371032715
Validation loss: 2.064660688241323

Epoch: 5| Step: 8
Training loss: 2.6332693099975586
Validation loss: 2.0591500252485275

Epoch: 5| Step: 9
Training loss: 2.1652979850769043
Validation loss: 2.057439257701238

Epoch: 5| Step: 10
Training loss: 2.2266101837158203
Validation loss: 2.0517597695191703

Epoch: 5| Step: 11
Training loss: 2.474018096923828
Validation loss: 2.055996298789978

Epoch: 68| Step: 0
Training loss: 2.4025473594665527
Validation loss: 2.056631331642469

Epoch: 5| Step: 1
Training loss: 2.135802745819092
Validation loss: 2.0530771563450494

Epoch: 5| Step: 2
Training loss: 2.171856641769409
Validation loss: 2.0444302360216775

Epoch: 5| Step: 3
Training loss: 2.2349436283111572
Validation loss: 2.043960134188334

Epoch: 5| Step: 4
Training loss: 2.00717830657959
Validation loss: 2.0479418138662973

Epoch: 5| Step: 5
Training loss: 2.012251377105713
Validation loss: 2.0469241638978324

Epoch: 5| Step: 6
Training loss: 2.0487136840820312
Validation loss: 2.0441756546497345

Epoch: 5| Step: 7
Training loss: 2.217529773712158
Validation loss: 2.0461711237827935

Epoch: 5| Step: 8
Training loss: 2.283886432647705
Validation loss: 2.0547733505566916

Epoch: 5| Step: 9
Training loss: 2.1405110359191895
Validation loss: 2.0469528983036676

Epoch: 5| Step: 10
Training loss: 2.629815101623535
Validation loss: 2.0479797273874283

Epoch: 5| Step: 11
Training loss: 3.3239529132843018
Validation loss: 2.0494771103064218

Epoch: 69| Step: 0
Training loss: 2.389429807662964
Validation loss: 2.0340257485707602

Epoch: 5| Step: 1
Training loss: 2.163695812225342
Validation loss: 2.0454909602801004

Epoch: 5| Step: 2
Training loss: 2.164635181427002
Validation loss: 2.0445469419161477

Epoch: 5| Step: 3
Training loss: 2.3428385257720947
Validation loss: 2.0506809800863266

Epoch: 5| Step: 4
Training loss: 1.1472785472869873
Validation loss: 2.055270860592524

Epoch: 5| Step: 5
Training loss: 2.8423912525177
Validation loss: 2.0609811196724572

Epoch: 5| Step: 6
Training loss: 2.3973774909973145
Validation loss: 2.06147238612175

Epoch: 5| Step: 7
Training loss: 2.001683473587036
Validation loss: 2.0729163785775504

Epoch: 5| Step: 8
Training loss: 2.574073553085327
Validation loss: 2.0737014611562095

Epoch: 5| Step: 9
Training loss: 2.3806254863739014
Validation loss: 2.073868677020073

Epoch: 5| Step: 10
Training loss: 2.371333360671997
Validation loss: 2.07050821185112

Epoch: 5| Step: 11
Training loss: 2.0849733352661133
Validation loss: 2.0745199670394263

Epoch: 70| Step: 0
Training loss: 2.4223828315734863
Validation loss: 2.0726983547210693

Epoch: 5| Step: 1
Training loss: 2.080498218536377
Validation loss: 2.0714070399602256

Epoch: 5| Step: 2
Training loss: 2.379246473312378
Validation loss: 2.0648245165745416

Epoch: 5| Step: 3
Training loss: 2.3740735054016113
Validation loss: 2.058650260170301

Epoch: 5| Step: 4
Training loss: 2.6260383129119873
Validation loss: 2.0596863130728402

Epoch: 5| Step: 5
Training loss: 2.1013023853302
Validation loss: 2.0528093179066977

Epoch: 5| Step: 6
Training loss: 2.461759090423584
Validation loss: 2.051867256561915

Epoch: 5| Step: 7
Training loss: 2.1384568214416504
Validation loss: 2.048902988433838

Epoch: 5| Step: 8
Training loss: 1.6765358448028564
Validation loss: 2.04495436946551

Epoch: 5| Step: 9
Training loss: 2.1777496337890625
Validation loss: 2.038530429204305

Epoch: 5| Step: 10
Training loss: 2.2203521728515625
Validation loss: 2.0335956066846848

Epoch: 5| Step: 11
Training loss: 2.100008487701416
Validation loss: 2.031214783589045

Epoch: 71| Step: 0
Training loss: 2.1262032985687256
Validation loss: 2.0458208322525024

Epoch: 5| Step: 1
Training loss: 1.757385015487671
Validation loss: 2.0342020839452744

Epoch: 5| Step: 2
Training loss: 2.8279995918273926
Validation loss: 2.0406949867804847

Epoch: 5| Step: 3
Training loss: 2.2255544662475586
Validation loss: 2.0363250573476157

Epoch: 5| Step: 4
Training loss: 1.727251410484314
Validation loss: 2.035929133494695

Epoch: 5| Step: 5
Training loss: 2.980052947998047
Validation loss: 2.044744888941447

Epoch: 5| Step: 6
Training loss: 2.135345935821533
Validation loss: 2.0436955640713372

Epoch: 5| Step: 7
Training loss: 2.0562567710876465
Validation loss: 2.0350288252035775

Epoch: 5| Step: 8
Training loss: 2.145299196243286
Validation loss: 2.0357163002093634

Epoch: 5| Step: 9
Training loss: 2.1773927211761475
Validation loss: 2.0361029158035913

Epoch: 5| Step: 10
Training loss: 2.118062973022461
Validation loss: 2.037102942665418

Epoch: 5| Step: 11
Training loss: 1.9503713846206665
Validation loss: 2.0375840912262597

Epoch: 72| Step: 0
Training loss: 2.4177160263061523
Validation loss: 2.039503420392672

Epoch: 5| Step: 1
Training loss: 2.324206590652466
Validation loss: 2.0407519787549973

Epoch: 5| Step: 2
Training loss: 1.9900200366973877
Validation loss: 2.043732369939486

Epoch: 5| Step: 3
Training loss: 2.6036288738250732
Validation loss: 2.031741723418236

Epoch: 5| Step: 4
Training loss: 2.0747017860412598
Validation loss: 2.0323661118745804

Epoch: 5| Step: 5
Training loss: 1.7709367275238037
Validation loss: 2.0357879598935447

Epoch: 5| Step: 6
Training loss: 2.238475799560547
Validation loss: 2.037701124946276

Epoch: 5| Step: 7
Training loss: 1.8854678869247437
Validation loss: 2.0413005153338113

Epoch: 5| Step: 8
Training loss: 2.2447705268859863
Validation loss: 2.0365398824214935

Epoch: 5| Step: 9
Training loss: 2.1478018760681152
Validation loss: 2.037773201862971

Epoch: 5| Step: 10
Training loss: 2.622729539871216
Validation loss: 2.0358483095963797

Epoch: 5| Step: 11
Training loss: 2.206204414367676
Validation loss: 2.041682874162992

Epoch: 73| Step: 0
Training loss: 2.3172454833984375
Validation loss: 2.038928339878718

Epoch: 5| Step: 1
Training loss: 2.389446258544922
Validation loss: 2.037291333079338

Epoch: 5| Step: 2
Training loss: 2.5220134258270264
Validation loss: 2.0244063983360925

Epoch: 5| Step: 3
Training loss: 1.8856544494628906
Validation loss: 2.0295356810092926

Epoch: 5| Step: 4
Training loss: 2.3597865104675293
Validation loss: 2.0361207673947015

Epoch: 5| Step: 5
Training loss: 1.629154920578003
Validation loss: 2.052639603614807

Epoch: 5| Step: 6
Training loss: 2.516345500946045
Validation loss: 2.055469805995623

Epoch: 5| Step: 7
Training loss: 2.711916208267212
Validation loss: 2.0552646070718765

Epoch: 5| Step: 8
Training loss: 1.8545329570770264
Validation loss: 2.039506663878759

Epoch: 5| Step: 9
Training loss: 1.9843904972076416
Validation loss: 2.0318036526441574

Epoch: 5| Step: 10
Training loss: 2.3453316688537598
Validation loss: 2.0333856344223022

Epoch: 5| Step: 11
Training loss: 1.1287598609924316
Validation loss: 2.0293780068556466

Epoch: 74| Step: 0
Training loss: 2.3604397773742676
Validation loss: 2.031674474477768

Epoch: 5| Step: 1
Training loss: 2.892063856124878
Validation loss: 2.0398687024911246

Epoch: 5| Step: 2
Training loss: 1.6908066272735596
Validation loss: 2.035659581422806

Epoch: 5| Step: 3
Training loss: 2.173804759979248
Validation loss: 2.0375328361988068

Epoch: 5| Step: 4
Training loss: 1.863448143005371
Validation loss: 2.034373472134272

Epoch: 5| Step: 5
Training loss: 2.3799424171447754
Validation loss: 2.0309513906637826

Epoch: 5| Step: 6
Training loss: 1.8341710567474365
Validation loss: 2.030971253911654

Epoch: 5| Step: 7
Training loss: 2.0961406230926514
Validation loss: 2.0350455194711685

Epoch: 5| Step: 8
Training loss: 2.2191596031188965
Validation loss: 2.034329707423846

Epoch: 5| Step: 9
Training loss: 2.5710549354553223
Validation loss: 2.0318236152331033

Epoch: 5| Step: 10
Training loss: 2.294341564178467
Validation loss: 2.0222058147192

Epoch: 5| Step: 11
Training loss: 1.1901603937149048
Validation loss: 2.028824324409167

Epoch: 75| Step: 0
Training loss: 2.0744898319244385
Validation loss: 2.0310024867455163

Epoch: 5| Step: 1
Training loss: 2.5451884269714355
Validation loss: 2.051193058490753

Epoch: 5| Step: 2
Training loss: 1.7131931781768799
Validation loss: 2.041790391008059

Epoch: 5| Step: 3
Training loss: 2.502890110015869
Validation loss: 2.0567940324544907

Epoch: 5| Step: 4
Training loss: 2.6407265663146973
Validation loss: 2.0654131273428598

Epoch: 5| Step: 5
Training loss: 1.9251006841659546
Validation loss: 2.0484879662593207

Epoch: 5| Step: 6
Training loss: 2.102846145629883
Validation loss: 2.0541085650523505

Epoch: 5| Step: 7
Training loss: 2.1590425968170166
Validation loss: 2.0317198038101196

Epoch: 5| Step: 8
Training loss: 2.4787888526916504
Validation loss: 2.02680271367232

Epoch: 5| Step: 9
Training loss: 2.1029765605926514
Validation loss: 2.0334122627973557

Epoch: 5| Step: 10
Training loss: 2.1074631214141846
Validation loss: 2.0387772719065347

Epoch: 5| Step: 11
Training loss: 1.2850379943847656
Validation loss: 2.0370939671993256

Epoch: 76| Step: 0
Training loss: 2.2504682540893555
Validation loss: 2.0620802839597068

Epoch: 5| Step: 1
Training loss: 2.2526097297668457
Validation loss: 2.0970651855071387

Epoch: 5| Step: 2
Training loss: 2.5761940479278564
Validation loss: 2.181387409567833

Epoch: 5| Step: 3
Training loss: 2.886354923248291
Validation loss: 2.244111120700836

Epoch: 5| Step: 4
Training loss: 2.1032934188842773
Validation loss: 2.2583894232908883

Epoch: 5| Step: 5
Training loss: 2.491363048553467
Validation loss: 2.254333515961965

Epoch: 5| Step: 6
Training loss: 2.266824245452881
Validation loss: 2.1952352225780487

Epoch: 5| Step: 7
Training loss: 2.105717420578003
Validation loss: 2.14204474290212

Epoch: 5| Step: 8
Training loss: 1.8388181924819946
Validation loss: 2.083477353056272

Epoch: 5| Step: 9
Training loss: 2.0931358337402344
Validation loss: 2.0400866170724234

Epoch: 5| Step: 10
Training loss: 2.7009739875793457
Validation loss: 2.032226790984472

Epoch: 5| Step: 11
Training loss: 1.6284387111663818
Validation loss: 2.028339038292567

Epoch: 77| Step: 0
Training loss: 2.5023906230926514
Validation loss: 2.02264703810215

Epoch: 5| Step: 1
Training loss: 2.61187744140625
Validation loss: 2.025996670126915

Epoch: 5| Step: 2
Training loss: 1.9536540508270264
Validation loss: 2.0375900169213614

Epoch: 5| Step: 3
Training loss: 2.4435951709747314
Validation loss: 2.0347494234641395

Epoch: 5| Step: 4
Training loss: 2.3837571144104004
Validation loss: 2.0383508453766503

Epoch: 5| Step: 5
Training loss: 2.214318037033081
Validation loss: 2.0473903864622116

Epoch: 5| Step: 6
Training loss: 2.3921797275543213
Validation loss: 2.0531411518653235

Epoch: 5| Step: 7
Training loss: 2.4866998195648193
Validation loss: 2.0515639881292977

Epoch: 5| Step: 8
Training loss: 1.6820272207260132
Validation loss: 2.046763484676679

Epoch: 5| Step: 9
Training loss: 1.4508191347122192
Validation loss: 2.0449564258257547

Epoch: 5| Step: 10
Training loss: 2.222672700881958
Validation loss: 2.039573868115743

Epoch: 5| Step: 11
Training loss: 2.68192195892334
Validation loss: 2.0393527150154114

Epoch: 78| Step: 0
Training loss: 2.2335593700408936
Validation loss: 2.0367321819067

Epoch: 5| Step: 1
Training loss: 2.1749765872955322
Validation loss: 2.0382101188103356

Epoch: 5| Step: 2
Training loss: 1.6648792028427124
Validation loss: 2.03196290632089

Epoch: 5| Step: 3
Training loss: 2.1762733459472656
Validation loss: 2.032644435763359

Epoch: 5| Step: 4
Training loss: 2.11478853225708
Validation loss: 2.0213542183240256

Epoch: 5| Step: 5
Training loss: 2.3637475967407227
Validation loss: 2.018351510167122

Epoch: 5| Step: 6
Training loss: 2.5509769916534424
Validation loss: 2.010305563608805

Epoch: 5| Step: 7
Training loss: 2.65464448928833
Validation loss: 2.010490506887436

Epoch: 5| Step: 8
Training loss: 2.173110246658325
Validation loss: 2.010617256164551

Epoch: 5| Step: 9
Training loss: 2.1286492347717285
Validation loss: 2.028959944844246

Epoch: 5| Step: 10
Training loss: 1.9524415731430054
Validation loss: 2.0293626685937247

Epoch: 5| Step: 11
Training loss: 2.3213109970092773
Validation loss: 2.0397522350152335

Epoch: 79| Step: 0
Training loss: 2.1727194786071777
Validation loss: 2.0324513812859855

Epoch: 5| Step: 1
Training loss: 2.507438898086548
Validation loss: 2.0308269610007605

Epoch: 5| Step: 2
Training loss: 1.6096347570419312
Validation loss: 2.028465082248052

Epoch: 5| Step: 3
Training loss: 2.60516357421875
Validation loss: 2.018226439754168

Epoch: 5| Step: 4
Training loss: 2.4628117084503174
Validation loss: 2.0142115453879037

Epoch: 5| Step: 5
Training loss: 2.497051239013672
Validation loss: 2.0073949992656708

Epoch: 5| Step: 6
Training loss: 2.2011494636535645
Validation loss: 2.010564908385277

Epoch: 5| Step: 7
Training loss: 2.227386236190796
Validation loss: 2.010836740334829

Epoch: 5| Step: 8
Training loss: 2.485670566558838
Validation loss: 2.01463620364666

Epoch: 5| Step: 9
Training loss: 1.8226425647735596
Validation loss: 2.016594817241033

Epoch: 5| Step: 10
Training loss: 1.4233416318893433
Validation loss: 2.0164973189433417

Epoch: 5| Step: 11
Training loss: 2.8913166522979736
Validation loss: 2.015502691268921

Epoch: 80| Step: 0
Training loss: 1.701472282409668
Validation loss: 2.0169443637132645

Epoch: 5| Step: 1
Training loss: 2.7472548484802246
Validation loss: 2.008515621225039

Epoch: 5| Step: 2
Training loss: 2.0436348915100098
Validation loss: 2.014253154397011

Epoch: 5| Step: 3
Training loss: 2.498870372772217
Validation loss: 2.0175649325052896

Epoch: 5| Step: 4
Training loss: 2.16810941696167
Validation loss: 2.0152562310298285

Epoch: 5| Step: 5
Training loss: 2.693809986114502
Validation loss: 2.015482281645139

Epoch: 5| Step: 6
Training loss: 1.9912903308868408
Validation loss: 2.0137421836455665

Epoch: 5| Step: 7
Training loss: 1.5053104162216187
Validation loss: 2.005208099881808

Epoch: 5| Step: 8
Training loss: 1.788973093032837
Validation loss: 2.0141386638085046

Epoch: 5| Step: 9
Training loss: 2.1543662548065186
Validation loss: 2.011022984981537

Epoch: 5| Step: 10
Training loss: 2.5429940223693848
Validation loss: 2.0123355289300284

Epoch: 5| Step: 11
Training loss: 3.377589225769043
Validation loss: 2.0149293889602027

Epoch: 81| Step: 0
Training loss: 1.9351131916046143
Validation loss: 2.011902009447416

Epoch: 5| Step: 1
Training loss: 2.043971538543701
Validation loss: 2.022609586517016

Epoch: 5| Step: 2
Training loss: 1.9110748767852783
Validation loss: 2.013987362384796

Epoch: 5| Step: 3
Training loss: 2.5914266109466553
Validation loss: 2.0178888688484826

Epoch: 5| Step: 4
Training loss: 1.7927615642547607
Validation loss: 2.017470379670461

Epoch: 5| Step: 5
Training loss: 1.8997188806533813
Validation loss: 2.019918069243431

Epoch: 5| Step: 6
Training loss: 2.50949764251709
Validation loss: 2.01994626224041

Epoch: 5| Step: 7
Training loss: 2.204624891281128
Validation loss: 2.0183936953544617

Epoch: 5| Step: 8
Training loss: 2.576894521713257
Validation loss: 2.0200032591819763

Epoch: 5| Step: 9
Training loss: 1.9042831659317017
Validation loss: 2.0265471984942756

Epoch: 5| Step: 10
Training loss: 2.3769125938415527
Validation loss: 2.0305035461982093

Epoch: 5| Step: 11
Training loss: 3.080559253692627
Validation loss: 2.0328512837489447

Epoch: 82| Step: 0
Training loss: 2.3290958404541016
Validation loss: 2.037632460395495

Epoch: 5| Step: 1
Training loss: 2.2158381938934326
Validation loss: 2.0245297253131866

Epoch: 5| Step: 2
Training loss: 1.6670926809310913
Validation loss: 2.0284412602583566

Epoch: 5| Step: 3
Training loss: 2.260761260986328
Validation loss: 2.0242589314778647

Epoch: 5| Step: 4
Training loss: 2.2336764335632324
Validation loss: 2.024559880296389

Epoch: 5| Step: 5
Training loss: 2.4125165939331055
Validation loss: 2.0271010994911194

Epoch: 5| Step: 6
Training loss: 1.8687105178833008
Validation loss: 2.0342815617720285

Epoch: 5| Step: 7
Training loss: 2.5341248512268066
Validation loss: 2.0355524023373923

Epoch: 5| Step: 8
Training loss: 1.960405945777893
Validation loss: 2.0342932840188346

Epoch: 5| Step: 9
Training loss: 1.9536243677139282
Validation loss: 2.0284192065397897

Epoch: 5| Step: 10
Training loss: 2.2270631790161133
Validation loss: 2.0313056806723275

Epoch: 5| Step: 11
Training loss: 2.654818296432495
Validation loss: 2.0207647333542504

Epoch: 83| Step: 0
Training loss: 1.9335544109344482
Validation loss: 2.0205735762914023

Epoch: 5| Step: 1
Training loss: 2.4656968116760254
Validation loss: 2.020649900039037

Epoch: 5| Step: 2
Training loss: 1.6898292303085327
Validation loss: 2.021663968761762

Epoch: 5| Step: 3
Training loss: 2.5632050037384033
Validation loss: 2.021700253089269

Epoch: 5| Step: 4
Training loss: 1.8947455883026123
Validation loss: 2.023180976510048

Epoch: 5| Step: 5
Training loss: 2.2235023975372314
Validation loss: 2.0214086224635444

Epoch: 5| Step: 6
Training loss: 2.1369271278381348
Validation loss: 2.02346999446551

Epoch: 5| Step: 7
Training loss: 2.453925609588623
Validation loss: 2.02523406346639

Epoch: 5| Step: 8
Training loss: 2.29127836227417
Validation loss: 2.0298618177572885

Epoch: 5| Step: 9
Training loss: 2.725292205810547
Validation loss: 2.0256086587905884

Epoch: 5| Step: 10
Training loss: 1.9138740301132202
Validation loss: 2.0210947543382645

Epoch: 5| Step: 11
Training loss: 1.4635576009750366
Validation loss: 2.0252266774574914

Epoch: 84| Step: 0
Training loss: 1.9052174091339111
Validation loss: 2.018492639064789

Epoch: 5| Step: 1
Training loss: 1.765393853187561
Validation loss: 2.012962813178698

Epoch: 5| Step: 2
Training loss: 1.6896088123321533
Validation loss: 2.027282918492953

Epoch: 5| Step: 3
Training loss: 2.365854263305664
Validation loss: 2.03363037109375

Epoch: 5| Step: 4
Training loss: 2.2464065551757812
Validation loss: 2.0479952494303384

Epoch: 5| Step: 5
Training loss: 2.281276226043701
Validation loss: 2.046344041824341

Epoch: 5| Step: 6
Training loss: 1.9895226955413818
Validation loss: 2.050136610865593

Epoch: 5| Step: 7
Training loss: 2.4125351905822754
Validation loss: 2.0436927527189255

Epoch: 5| Step: 8
Training loss: 2.3648250102996826
Validation loss: 2.0550606995821

Epoch: 5| Step: 9
Training loss: 2.2069625854492188
Validation loss: 2.046692987283071

Epoch: 5| Step: 10
Training loss: 2.490016222000122
Validation loss: 2.0437843749920526

Epoch: 5| Step: 11
Training loss: 3.3550057411193848
Validation loss: 2.0420727829138436

Epoch: 85| Step: 0
Training loss: 2.0223355293273926
Validation loss: 2.0452038248380027

Epoch: 5| Step: 1
Training loss: 2.3995509147644043
Validation loss: 2.0511097460985184

Epoch: 5| Step: 2
Training loss: 2.4818577766418457
Validation loss: 2.0545534491539

Epoch: 5| Step: 3
Training loss: 1.8408654928207397
Validation loss: 2.0481529931227365

Epoch: 5| Step: 4
Training loss: 2.4622156620025635
Validation loss: 2.0432203064362207

Epoch: 5| Step: 5
Training loss: 2.2030906677246094
Validation loss: 2.0377627263466516

Epoch: 5| Step: 6
Training loss: 2.6115829944610596
Validation loss: 2.034069910645485

Epoch: 5| Step: 7
Training loss: 1.926282525062561
Validation loss: 2.0298674205938974

Epoch: 5| Step: 8
Training loss: 2.1741795539855957
Validation loss: 2.026426022251447

Epoch: 5| Step: 9
Training loss: 1.4414647817611694
Validation loss: 2.0267015298207602

Epoch: 5| Step: 10
Training loss: 2.29190993309021
Validation loss: 2.0329619447390237

Epoch: 5| Step: 11
Training loss: 2.093733787536621
Validation loss: 2.028099154432615

Epoch: 86| Step: 0
Training loss: 2.1458511352539062
Validation loss: 2.0207311560710273

Epoch: 5| Step: 1
Training loss: 1.5872000455856323
Validation loss: 2.0343042661746344

Epoch: 5| Step: 2
Training loss: 2.2650537490844727
Validation loss: 2.033496061960856

Epoch: 5| Step: 3
Training loss: 2.653944492340088
Validation loss: 2.035798892378807

Epoch: 5| Step: 4
Training loss: 2.448072910308838
Validation loss: 2.0477049748102822

Epoch: 5| Step: 5
Training loss: 2.231419801712036
Validation loss: 2.0465133686860404

Epoch: 5| Step: 6
Training loss: 1.7178008556365967
Validation loss: 2.044510617852211

Epoch: 5| Step: 7
Training loss: 2.061941385269165
Validation loss: 2.0493662854035697

Epoch: 5| Step: 8
Training loss: 2.1138041019439697
Validation loss: 2.0476729025443396

Epoch: 5| Step: 9
Training loss: 2.1836326122283936
Validation loss: 2.0468873729308448

Epoch: 5| Step: 10
Training loss: 2.1817092895507812
Validation loss: 2.0491397827863693

Epoch: 5| Step: 11
Training loss: 3.134701728820801
Validation loss: 2.044360503554344

Epoch: 87| Step: 0
Training loss: 2.1252541542053223
Validation loss: 2.0422385980685553

Epoch: 5| Step: 1
Training loss: 1.7894595861434937
Validation loss: 2.0368688503901162

Epoch: 5| Step: 2
Training loss: 2.5610873699188232
Validation loss: 2.03154123822848

Epoch: 5| Step: 3
Training loss: 2.2544448375701904
Validation loss: 2.03010264535745

Epoch: 5| Step: 4
Training loss: 2.8997950553894043
Validation loss: 2.031191368897756

Epoch: 5| Step: 5
Training loss: 2.5349764823913574
Validation loss: 2.0218217174212136

Epoch: 5| Step: 6
Training loss: 1.8509082794189453
Validation loss: 2.0187749614318213

Epoch: 5| Step: 7
Training loss: 1.6944555044174194
Validation loss: 2.024908870458603

Epoch: 5| Step: 8
Training loss: 2.4779303073883057
Validation loss: 2.0386872589588165

Epoch: 5| Step: 9
Training loss: 1.2050120830535889
Validation loss: 2.0292457143465676

Epoch: 5| Step: 10
Training loss: 2.2145304679870605
Validation loss: 2.035183067123095

Epoch: 5| Step: 11
Training loss: 1.9506494998931885
Validation loss: 2.032219558954239

Epoch: 88| Step: 0
Training loss: 2.0081372261047363
Validation loss: 2.0220586707194648

Epoch: 5| Step: 1
Training loss: 2.3320517539978027
Validation loss: 2.0240394324064255

Epoch: 5| Step: 2
Training loss: 2.565797805786133
Validation loss: 2.027248124281565

Epoch: 5| Step: 3
Training loss: 2.3437228202819824
Validation loss: 2.025434950987498

Epoch: 5| Step: 4
Training loss: 2.034255266189575
Validation loss: 2.0258049964904785

Epoch: 5| Step: 5
Training loss: 1.9684470891952515
Validation loss: 2.0233221302429834

Epoch: 5| Step: 6
Training loss: 2.2180564403533936
Validation loss: 2.024178018172582

Epoch: 5| Step: 7
Training loss: 1.9969074726104736
Validation loss: 2.026402086019516

Epoch: 5| Step: 8
Training loss: 2.230851650238037
Validation loss: 2.0182873755693436

Epoch: 5| Step: 9
Training loss: 1.6367477178573608
Validation loss: 2.0148274848858514

Epoch: 5| Step: 10
Training loss: 2.3933117389678955
Validation loss: 2.0112535059452057

Epoch: 5| Step: 11
Training loss: 1.8343945741653442
Validation loss: 2.0143959671258926

Epoch: 89| Step: 0
Training loss: 2.0456831455230713
Validation loss: 2.0116274505853653

Epoch: 5| Step: 1
Training loss: 2.2520251274108887
Validation loss: 2.015888601541519

Epoch: 5| Step: 2
Training loss: 2.4582748413085938
Validation loss: 2.0240258425474167

Epoch: 5| Step: 3
Training loss: 2.401231288909912
Validation loss: 2.029879460732142

Epoch: 5| Step: 4
Training loss: 1.6225268840789795
Validation loss: 2.0244008203347525

Epoch: 5| Step: 5
Training loss: 2.3196988105773926
Validation loss: 2.0341632117827735

Epoch: 5| Step: 6
Training loss: 2.7840678691864014
Validation loss: 2.0280210425456366

Epoch: 5| Step: 7
Training loss: 2.154111385345459
Validation loss: 2.0327431013186774

Epoch: 5| Step: 8
Training loss: 1.6602180004119873
Validation loss: 2.039012427131335

Epoch: 5| Step: 9
Training loss: 2.197603464126587
Validation loss: 2.0234878808259964

Epoch: 5| Step: 10
Training loss: 1.7726150751113892
Validation loss: 2.027576516071955

Epoch: 5| Step: 11
Training loss: 2.3710684776306152
Validation loss: 2.023408353328705

Epoch: 90| Step: 0
Training loss: 2.491824150085449
Validation loss: 2.019464666644732

Epoch: 5| Step: 1
Training loss: 2.260469913482666
Validation loss: 2.0121374229590097

Epoch: 5| Step: 2
Training loss: 2.3853206634521484
Validation loss: 2.0128808269898095

Epoch: 5| Step: 3
Training loss: 2.2552340030670166
Validation loss: 2.0224482963482537

Epoch: 5| Step: 4
Training loss: 2.0505313873291016
Validation loss: 2.019484892487526

Epoch: 5| Step: 5
Training loss: 2.1747207641601562
Validation loss: 2.0205071369806924

Epoch: 5| Step: 6
Training loss: 2.2620949745178223
Validation loss: 2.020154277483622

Epoch: 5| Step: 7
Training loss: 2.0874390602111816
Validation loss: 2.0222351302703223

Epoch: 5| Step: 8
Training loss: 1.9416100978851318
Validation loss: 2.0180731117725372

Epoch: 5| Step: 9
Training loss: 1.6621322631835938
Validation loss: 2.0194317201773324

Epoch: 5| Step: 10
Training loss: 2.282435417175293
Validation loss: 2.0179591327905655

Epoch: 5| Step: 11
Training loss: 1.6420615911483765
Validation loss: 2.0196792036294937

Epoch: 91| Step: 0
Training loss: 1.9457743167877197
Validation loss: 2.02433417737484

Epoch: 5| Step: 1
Training loss: 2.5045926570892334
Validation loss: 2.0269596378008523

Epoch: 5| Step: 2
Training loss: 2.1827855110168457
Validation loss: 2.033591866493225

Epoch: 5| Step: 3
Training loss: 2.1582024097442627
Validation loss: 2.0344489067792892

Epoch: 5| Step: 4
Training loss: 1.620453119277954
Validation loss: 2.046859090526899

Epoch: 5| Step: 5
Training loss: 2.014575481414795
Validation loss: 2.0516259521245956

Epoch: 5| Step: 6
Training loss: 1.7448089122772217
Validation loss: 2.0543765922387442

Epoch: 5| Step: 7
Training loss: 2.139097213745117
Validation loss: 2.047688881556193

Epoch: 5| Step: 8
Training loss: 2.2698779106140137
Validation loss: 2.0529151807228723

Epoch: 5| Step: 9
Training loss: 2.6519265174865723
Validation loss: 2.060492922862371

Epoch: 5| Step: 10
Training loss: 2.5238401889801025
Validation loss: 2.051779796679815

Epoch: 5| Step: 11
Training loss: 1.5344834327697754
Validation loss: 2.0600401709477105

Epoch: 92| Step: 0
Training loss: 2.0591206550598145
Validation loss: 2.051630809903145

Epoch: 5| Step: 1
Training loss: 2.261183023452759
Validation loss: 2.052544037501017

Epoch: 5| Step: 2
Training loss: 1.7524263858795166
Validation loss: 2.04800579448541

Epoch: 5| Step: 3
Training loss: 2.513730764389038
Validation loss: 2.0375213474035263

Epoch: 5| Step: 4
Training loss: 2.5045459270477295
Validation loss: 2.023761068781217

Epoch: 5| Step: 5
Training loss: 2.0619285106658936
Validation loss: 2.019845649600029

Epoch: 5| Step: 6
Training loss: 2.0936479568481445
Validation loss: 2.0215232322613397

Epoch: 5| Step: 7
Training loss: 2.6933257579803467
Validation loss: 2.03017221391201

Epoch: 5| Step: 8
Training loss: 2.100343942642212
Validation loss: 2.023937448859215

Epoch: 5| Step: 9
Training loss: 2.1700260639190674
Validation loss: 2.0197159250577292

Epoch: 5| Step: 10
Training loss: 1.8427941799163818
Validation loss: 2.02692278722922

Epoch: 5| Step: 11
Training loss: 1.552787184715271
Validation loss: 2.018941894173622

Epoch: 93| Step: 0
Training loss: 2.044299602508545
Validation loss: 2.0183213303486505

Epoch: 5| Step: 1
Training loss: 2.1765246391296387
Validation loss: 2.0189334700504937

Epoch: 5| Step: 2
Training loss: 1.893202543258667
Validation loss: 2.0260602682828903

Epoch: 5| Step: 3
Training loss: 2.314241409301758
Validation loss: 2.0264147222042084

Epoch: 5| Step: 4
Training loss: 2.2016680240631104
Validation loss: 2.022518515586853

Epoch: 5| Step: 5
Training loss: 2.3701703548431396
Validation loss: 2.0196958482265472

Epoch: 5| Step: 6
Training loss: 2.2075562477111816
Validation loss: 2.0335258642832437

Epoch: 5| Step: 7
Training loss: 1.9990485906600952
Validation loss: 2.0338089764118195

Epoch: 5| Step: 8
Training loss: 2.366142749786377
Validation loss: 2.0446115881204605

Epoch: 5| Step: 9
Training loss: 2.207314968109131
Validation loss: 2.046126733223597

Epoch: 5| Step: 10
Training loss: 2.0169875621795654
Validation loss: 2.052523652712504

Epoch: 5| Step: 11
Training loss: 2.0697994232177734
Validation loss: 2.0410312612851462

Epoch: 94| Step: 0
Training loss: 2.2993130683898926
Validation loss: 2.0352937976519265

Epoch: 5| Step: 1
Training loss: 2.0640432834625244
Validation loss: 2.0335020472606025

Epoch: 5| Step: 2
Training loss: 1.5814166069030762
Validation loss: 2.017963796854019

Epoch: 5| Step: 3
Training loss: 2.7494466304779053
Validation loss: 2.021022622783979

Epoch: 5| Step: 4
Training loss: 2.3452706336975098
Validation loss: 2.028564060727755

Epoch: 5| Step: 5
Training loss: 2.653510093688965
Validation loss: 2.0314290523529053

Epoch: 5| Step: 6
Training loss: 2.3328161239624023
Validation loss: 2.0290806144475937

Epoch: 5| Step: 7
Training loss: 1.7964637279510498
Validation loss: 2.0349893470605216

Epoch: 5| Step: 8
Training loss: 1.5885465145111084
Validation loss: 2.029459993044535

Epoch: 5| Step: 9
Training loss: 1.976088285446167
Validation loss: 2.0239350150028863

Epoch: 5| Step: 10
Training loss: 2.4893910884857178
Validation loss: 2.020781303445498

Epoch: 5| Step: 11
Training loss: 1.828065276145935
Validation loss: 2.0212294111649194

Epoch: 95| Step: 0
Training loss: 2.361677646636963
Validation loss: 2.0200468202432

Epoch: 5| Step: 1
Training loss: 2.4998199939727783
Validation loss: 2.0228743255138397

Epoch: 5| Step: 2
Training loss: 1.926198959350586
Validation loss: 2.0338225911060968

Epoch: 5| Step: 3
Training loss: 2.078235149383545
Validation loss: 2.0279789566993713

Epoch: 5| Step: 4
Training loss: 1.985345482826233
Validation loss: 2.027059942483902

Epoch: 5| Step: 5
Training loss: 1.9924014806747437
Validation loss: 2.035888652006785

Epoch: 5| Step: 6
Training loss: 2.110964775085449
Validation loss: 2.0293183624744415

Epoch: 5| Step: 7
Training loss: 1.2971463203430176
Validation loss: 2.0282842417558036

Epoch: 5| Step: 8
Training loss: 2.6311206817626953
Validation loss: 2.02667406698068

Epoch: 5| Step: 9
Training loss: 2.054100513458252
Validation loss: 2.038862685362498

Epoch: 5| Step: 10
Training loss: 2.195885181427002
Validation loss: 2.0274653931458793

Epoch: 5| Step: 11
Training loss: 3.621145248413086
Validation loss: 2.02699547012647

Epoch: 96| Step: 0
Training loss: 2.7881197929382324
Validation loss: 2.0258967330058417

Epoch: 5| Step: 1
Training loss: 2.089627742767334
Validation loss: 2.01838510731856

Epoch: 5| Step: 2
Training loss: 2.133272886276245
Validation loss: 2.0176226447025933

Epoch: 5| Step: 3
Training loss: 2.1596152782440186
Validation loss: 2.0209727386633554

Epoch: 5| Step: 4
Training loss: 2.1501975059509277
Validation loss: 2.020595615108808

Epoch: 5| Step: 5
Training loss: 2.1444265842437744
Validation loss: 2.023356189330419

Epoch: 5| Step: 6
Training loss: 1.3340203762054443
Validation loss: 2.037351926167806

Epoch: 5| Step: 7
Training loss: 2.3901429176330566
Validation loss: 2.0161140809456506

Epoch: 5| Step: 8
Training loss: 2.4084393978118896
Validation loss: 2.022048388918241

Epoch: 5| Step: 9
Training loss: 1.8195232152938843
Validation loss: 2.0294041633605957

Epoch: 5| Step: 10
Training loss: 1.9800723791122437
Validation loss: 2.0308632055918374

Epoch: 5| Step: 11
Training loss: 2.2694003582000732
Validation loss: 2.028503249088923

Epoch: 97| Step: 0
Training loss: 2.4659571647644043
Validation loss: 2.0329217861096063

Epoch: 5| Step: 1
Training loss: 1.9807097911834717
Validation loss: 2.0350589553515115

Epoch: 5| Step: 2
Training loss: 1.9144433736801147
Validation loss: 2.03115776181221

Epoch: 5| Step: 3
Training loss: 1.6611080169677734
Validation loss: 2.0404524902502694

Epoch: 5| Step: 4
Training loss: 1.922115683555603
Validation loss: 2.0325984805822372

Epoch: 5| Step: 5
Training loss: 2.44978666305542
Validation loss: 2.032247910896937

Epoch: 5| Step: 6
Training loss: 2.298217296600342
Validation loss: 2.0288456032673516

Epoch: 5| Step: 7
Training loss: 2.4864864349365234
Validation loss: 2.029556542634964

Epoch: 5| Step: 8
Training loss: 1.8944867849349976
Validation loss: 2.0291065722703934

Epoch: 5| Step: 9
Training loss: 2.297476291656494
Validation loss: 2.0207545161247253

Epoch: 5| Step: 10
Training loss: 2.224191188812256
Validation loss: 2.019655858476957

Epoch: 5| Step: 11
Training loss: 1.5192337036132812
Validation loss: 2.0286492109298706

Epoch: 98| Step: 0
Training loss: 2.1774046421051025
Validation loss: 2.0200441032648087

Epoch: 5| Step: 1
Training loss: 1.7575490474700928
Validation loss: 2.0350527316331863

Epoch: 5| Step: 2
Training loss: 2.3662455081939697
Validation loss: 2.023563285668691

Epoch: 5| Step: 3
Training loss: 2.370115280151367
Validation loss: 2.032933607697487

Epoch: 5| Step: 4
Training loss: 2.5578269958496094
Validation loss: 2.034861147403717

Epoch: 5| Step: 5
Training loss: 1.811367392539978
Validation loss: 2.0283208390076957

Epoch: 5| Step: 6
Training loss: 1.8586740493774414
Validation loss: 2.036869684855143

Epoch: 5| Step: 7
Training loss: 2.34021258354187
Validation loss: 2.0332400550444922

Epoch: 5| Step: 8
Training loss: 1.7432997226715088
Validation loss: 2.0339876959721246

Epoch: 5| Step: 9
Training loss: 2.338822364807129
Validation loss: 2.024377425511678

Epoch: 5| Step: 10
Training loss: 2.0227694511413574
Validation loss: 2.0198774139086404

Epoch: 5| Step: 11
Training loss: 2.831216812133789
Validation loss: 2.017241949836413

Epoch: 99| Step: 0
Training loss: 1.6822364330291748
Validation loss: 2.0164442360401154

Epoch: 5| Step: 1
Training loss: 2.263190746307373
Validation loss: 2.017780909935633

Epoch: 5| Step: 2
Training loss: 1.5383435487747192
Validation loss: 2.0219807724157968

Epoch: 5| Step: 3
Training loss: 1.821986436843872
Validation loss: 2.0250015457471213

Epoch: 5| Step: 4
Training loss: 2.652038097381592
Validation loss: 2.039089019099871

Epoch: 5| Step: 5
Training loss: 2.412555456161499
Validation loss: 2.041858742634455

Epoch: 5| Step: 6
Training loss: 2.288794755935669
Validation loss: 2.041127542654673

Epoch: 5| Step: 7
Training loss: 2.0794076919555664
Validation loss: 2.034993588924408

Epoch: 5| Step: 8
Training loss: 1.809048056602478
Validation loss: 2.0302677055199942

Epoch: 5| Step: 9
Training loss: 2.698624610900879
Validation loss: 2.0329516331354776

Epoch: 5| Step: 10
Training loss: 2.285989761352539
Validation loss: 2.0337831179300943

Epoch: 5| Step: 11
Training loss: 2.9101171493530273
Validation loss: 2.0114154517650604

Epoch: 100| Step: 0
Training loss: 2.1710362434387207
Validation loss: 2.0109633207321167

Epoch: 5| Step: 1
Training loss: 2.5585575103759766
Validation loss: 2.015641992290815

Epoch: 5| Step: 2
Training loss: 2.1800999641418457
Validation loss: 2.025285621484121

Epoch: 5| Step: 3
Training loss: 2.269671678543091
Validation loss: 2.031038915117582

Epoch: 5| Step: 4
Training loss: 1.8685905933380127
Validation loss: 2.032590225338936

Epoch: 5| Step: 5
Training loss: 1.9644181728363037
Validation loss: 2.0344839294751487

Epoch: 5| Step: 6
Training loss: 2.3726449012756348
Validation loss: 2.0290776838858924

Epoch: 5| Step: 7
Training loss: 1.926276445388794
Validation loss: 2.034120559692383

Epoch: 5| Step: 8
Training loss: 2.0289108753204346
Validation loss: 2.0285394887129464

Epoch: 5| Step: 9
Training loss: 2.194805860519409
Validation loss: 2.0304100116093955

Epoch: 5| Step: 10
Training loss: 2.088503122329712
Validation loss: 2.028269107143084

Epoch: 5| Step: 11
Training loss: 3.3682196140289307
Validation loss: 2.0298832009236016

Epoch: 101| Step: 0
Training loss: 2.5004477500915527
Validation loss: 2.024965768059095

Epoch: 5| Step: 1
Training loss: 2.476454257965088
Validation loss: 2.0256248166163764

Epoch: 5| Step: 2
Training loss: 2.135929822921753
Validation loss: 2.02445059021314

Epoch: 5| Step: 3
Training loss: 1.5189300775527954
Validation loss: 2.0228247990210853

Epoch: 5| Step: 4
Training loss: 2.221741199493408
Validation loss: 2.018130898475647

Epoch: 5| Step: 5
Training loss: 2.113182783126831
Validation loss: 2.015522579352061

Epoch: 5| Step: 6
Training loss: 1.7254972457885742
Validation loss: 2.0166103740533194

Epoch: 5| Step: 7
Training loss: 2.473433017730713
Validation loss: 2.0034206906954446

Epoch: 5| Step: 8
Training loss: 2.3535640239715576
Validation loss: 2.004226644833883

Epoch: 5| Step: 9
Training loss: 1.8675825595855713
Validation loss: 2.014275694886843

Epoch: 5| Step: 10
Training loss: 2.0873398780822754
Validation loss: 2.0115957309802375

Epoch: 5| Step: 11
Training loss: 2.5059385299682617
Validation loss: 2.0196003019809723

Epoch: 102| Step: 0
Training loss: 1.9255332946777344
Validation loss: 2.0186648666858673

Epoch: 5| Step: 1
Training loss: 2.0356106758117676
Validation loss: 2.0288295845190683

Epoch: 5| Step: 2
Training loss: 1.9263967275619507
Validation loss: 2.0288447787364325

Epoch: 5| Step: 3
Training loss: 1.960129976272583
Validation loss: 2.0427789787451425

Epoch: 5| Step: 4
Training loss: 2.466745615005493
Validation loss: 2.040695145726204

Epoch: 5| Step: 5
Training loss: 2.5562260150909424
Validation loss: 2.03492463628451

Epoch: 5| Step: 6
Training loss: 2.0261988639831543
Validation loss: 2.0357710917790732

Epoch: 5| Step: 7
Training loss: 1.6258189678192139
Validation loss: 2.0285523335138955

Epoch: 5| Step: 8
Training loss: 3.042738437652588
Validation loss: 2.037039359410604

Epoch: 5| Step: 9
Training loss: 1.9393295049667358
Validation loss: 2.038811837633451

Epoch: 5| Step: 10
Training loss: 2.134246826171875
Validation loss: 2.02995236714681

Epoch: 5| Step: 11
Training loss: 0.7144023180007935
Validation loss: 2.032250722249349

Epoch: 103| Step: 0
Training loss: 1.635125756263733
Validation loss: 2.0356404185295105

Epoch: 5| Step: 1
Training loss: 1.9128261804580688
Validation loss: 2.0300081272919974

Epoch: 5| Step: 2
Training loss: 2.0268232822418213
Validation loss: 2.0266406486431756

Epoch: 5| Step: 3
Training loss: 2.363124132156372
Validation loss: 2.0333878149588904

Epoch: 5| Step: 4
Training loss: 2.218020439147949
Validation loss: 2.0332757333914437

Epoch: 5| Step: 5
Training loss: 2.790388584136963
Validation loss: 2.036442816257477

Epoch: 5| Step: 6
Training loss: 1.9757617712020874
Validation loss: 2.0323113252719245

Epoch: 5| Step: 7
Training loss: 2.328406572341919
Validation loss: 2.0266713549693427

Epoch: 5| Step: 8
Training loss: 1.7118980884552002
Validation loss: 2.0304504384597144

Epoch: 5| Step: 9
Training loss: 2.3079066276550293
Validation loss: 2.0151141534248986

Epoch: 5| Step: 10
Training loss: 2.0045924186706543
Validation loss: 2.025830715894699

Epoch: 5| Step: 11
Training loss: 2.847066879272461
Validation loss: 2.0217119554678598

Epoch: 104| Step: 0
Training loss: 1.90304696559906
Validation loss: 2.0231966773668923

Epoch: 5| Step: 1
Training loss: 2.607320785522461
Validation loss: 2.02102825542291

Epoch: 5| Step: 2
Training loss: 1.8956636190414429
Validation loss: 2.030403951803843

Epoch: 5| Step: 3
Training loss: 2.3709616661071777
Validation loss: 2.0253922442595163

Epoch: 5| Step: 4
Training loss: 1.7569572925567627
Validation loss: 2.025788734356562

Epoch: 5| Step: 5
Training loss: 2.59621524810791
Validation loss: 2.019911840558052

Epoch: 5| Step: 6
Training loss: 1.7414629459381104
Validation loss: 2.018286054333051

Epoch: 5| Step: 7
Training loss: 2.1120645999908447
Validation loss: 2.025100534160932

Epoch: 5| Step: 8
Training loss: 2.364264965057373
Validation loss: 2.0291425387064614

Epoch: 5| Step: 9
Training loss: 2.1690590381622314
Validation loss: 2.030536691347758

Epoch: 5| Step: 10
Training loss: 1.9879661798477173
Validation loss: 2.033405597011248

Epoch: 5| Step: 11
Training loss: 1.0660878419876099
Validation loss: 2.0284119496742883

Epoch: 105| Step: 0
Training loss: 2.01920747756958
Validation loss: 2.044230654835701

Epoch: 5| Step: 1
Training loss: 1.8916959762573242
Validation loss: 2.035029669602712

Epoch: 5| Step: 2
Training loss: 2.5013914108276367
Validation loss: 2.0434372623761496

Epoch: 5| Step: 3
Training loss: 3.283796787261963
Validation loss: 2.0550267000993094

Epoch: 5| Step: 4
Training loss: 1.4788415431976318
Validation loss: 2.0443562865257263

Epoch: 5| Step: 5
Training loss: 1.9540640115737915
Validation loss: 2.0440022150675454

Epoch: 5| Step: 6
Training loss: 2.108330488204956
Validation loss: 2.03234455982844

Epoch: 5| Step: 7
Training loss: 1.8707672357559204
Validation loss: 2.023456960916519

Epoch: 5| Step: 8
Training loss: 2.0399208068847656
Validation loss: 2.0096886356671653

Epoch: 5| Step: 9
Training loss: 2.265687942504883
Validation loss: 2.013970226049423

Epoch: 5| Step: 10
Training loss: 2.0874106884002686
Validation loss: 2.017379874984423

Epoch: 5| Step: 11
Training loss: 2.1866393089294434
Validation loss: 2.016761446992556

Epoch: 106| Step: 0
Training loss: 1.7702659368515015
Validation loss: 2.0191110173861184

Epoch: 5| Step: 1
Training loss: 2.329754114151001
Validation loss: 2.0219403505325317

Epoch: 5| Step: 2
Training loss: 1.9167585372924805
Validation loss: 2.0250249803066254

Epoch: 5| Step: 3
Training loss: 2.609570026397705
Validation loss: 2.027677208185196

Epoch: 5| Step: 4
Training loss: 2.1457087993621826
Validation loss: 2.0298873682816825

Epoch: 5| Step: 5
Training loss: 2.134580612182617
Validation loss: 2.027905136346817

Epoch: 5| Step: 6
Training loss: 2.4037556648254395
Validation loss: 2.0202138324578605

Epoch: 5| Step: 7
Training loss: 2.0597915649414062
Validation loss: 2.022970125079155

Epoch: 5| Step: 8
Training loss: 2.215339183807373
Validation loss: 2.021370659271876

Epoch: 5| Step: 9
Training loss: 2.0734853744506836
Validation loss: 2.0196626782417297

Epoch: 5| Step: 10
Training loss: 2.2529337406158447
Validation loss: 2.0142705837885537

Epoch: 5| Step: 11
Training loss: 1.6305077075958252
Validation loss: 2.0107268591721854

Epoch: 107| Step: 0
Training loss: 2.2903895378112793
Validation loss: 2.010666852196058

Epoch: 5| Step: 1
Training loss: 2.4517061710357666
Validation loss: 2.009879007935524

Epoch: 5| Step: 2
Training loss: 1.899888277053833
Validation loss: 2.0133625815312066

Epoch: 5| Step: 3
Training loss: 1.7502902746200562
Validation loss: 2.013667330145836

Epoch: 5| Step: 4
Training loss: 2.3552069664001465
Validation loss: 2.0172546754280725

Epoch: 5| Step: 5
Training loss: 1.7494910955429077
Validation loss: 2.0243021796147027

Epoch: 5| Step: 6
Training loss: 2.227968215942383
Validation loss: 2.016215165456136

Epoch: 5| Step: 7
Training loss: 2.2159762382507324
Validation loss: 2.021652032931646

Epoch: 5| Step: 8
Training loss: 2.2944178581237793
Validation loss: 2.028709431489309

Epoch: 5| Step: 9
Training loss: 2.307856321334839
Validation loss: 2.026264190673828

Epoch: 5| Step: 10
Training loss: 1.7306129932403564
Validation loss: 2.023749361435572

Epoch: 5| Step: 11
Training loss: 1.8814411163330078
Validation loss: 2.024231826265653

Epoch: 108| Step: 0
Training loss: 1.853751540184021
Validation loss: 2.0280037919680276

Epoch: 5| Step: 1
Training loss: 1.7813055515289307
Validation loss: 2.0224908788998923

Epoch: 5| Step: 2
Training loss: 2.4916558265686035
Validation loss: 2.0209937741359076

Epoch: 5| Step: 3
Training loss: 2.2770161628723145
Validation loss: 2.0240786522626877

Epoch: 5| Step: 4
Training loss: 2.5720906257629395
Validation loss: 2.038656751314799

Epoch: 5| Step: 5
Training loss: 2.8438663482666016
Validation loss: 2.030035749077797

Epoch: 5| Step: 6
Training loss: 2.3285036087036133
Validation loss: 2.0209801296393075

Epoch: 5| Step: 7
Training loss: 1.8432481288909912
Validation loss: 2.0259482065836587

Epoch: 5| Step: 8
Training loss: 1.6769851446151733
Validation loss: 2.024570350845655

Epoch: 5| Step: 9
Training loss: 1.8683420419692993
Validation loss: 2.0367662211259208

Epoch: 5| Step: 10
Training loss: 1.9034827947616577
Validation loss: 2.024104028940201

Epoch: 5| Step: 11
Training loss: 1.1800527572631836
Validation loss: 2.0355477233727775

Epoch: 109| Step: 0
Training loss: 2.5973010063171387
Validation loss: 2.0314568479855857

Epoch: 5| Step: 1
Training loss: 2.182636022567749
Validation loss: 2.0397936503092446

Epoch: 5| Step: 2
Training loss: 2.2382776737213135
Validation loss: 2.02388163904349

Epoch: 5| Step: 3
Training loss: 2.1274735927581787
Validation loss: 2.039408400654793

Epoch: 5| Step: 4
Training loss: 1.897369623184204
Validation loss: 2.0383846908807755

Epoch: 5| Step: 5
Training loss: 2.328178882598877
Validation loss: 2.0249219288428626

Epoch: 5| Step: 6
Training loss: 2.088257074356079
Validation loss: 2.028408298889796

Epoch: 5| Step: 7
Training loss: 1.751072883605957
Validation loss: 2.028200998902321

Epoch: 5| Step: 8
Training loss: 2.114285945892334
Validation loss: 2.0342711905638375

Epoch: 5| Step: 9
Training loss: 1.943291425704956
Validation loss: 2.026270404458046

Epoch: 5| Step: 10
Training loss: 2.162415027618408
Validation loss: 2.03599913418293

Epoch: 5| Step: 11
Training loss: 1.3567970991134644
Validation loss: 2.033949082096418

Epoch: 110| Step: 0
Training loss: 2.2097227573394775
Validation loss: 2.038678968946139

Epoch: 5| Step: 1
Training loss: 1.5291169881820679
Validation loss: 2.0299765964349112

Epoch: 5| Step: 2
Training loss: 2.509948492050171
Validation loss: 2.0376592377821603

Epoch: 5| Step: 3
Training loss: 1.8298404216766357
Validation loss: 2.0324069956938424

Epoch: 5| Step: 4
Training loss: 2.2279930114746094
Validation loss: 2.0289642065763474

Epoch: 5| Step: 5
Training loss: 2.408857583999634
Validation loss: 2.030866096417109

Epoch: 5| Step: 6
Training loss: 2.2087604999542236
Validation loss: 2.0339908401171365

Epoch: 5| Step: 7
Training loss: 1.4771125316619873
Validation loss: 2.0274491161108017

Epoch: 5| Step: 8
Training loss: 2.3243536949157715
Validation loss: 2.0288930535316467

Epoch: 5| Step: 9
Training loss: 2.525423526763916
Validation loss: 2.0261872013409934

Epoch: 5| Step: 10
Training loss: 2.133666753768921
Validation loss: 2.0342658211787543

Epoch: 5| Step: 11
Training loss: 1.883083701133728
Validation loss: 2.0287322998046875

Epoch: 111| Step: 0
Training loss: 2.140117883682251
Validation loss: 2.0298137615124383

Epoch: 5| Step: 1
Training loss: 2.158461570739746
Validation loss: 2.0326282928387323

Epoch: 5| Step: 2
Training loss: 2.6356441974639893
Validation loss: 2.0334418465693793

Epoch: 5| Step: 3
Training loss: 2.2265965938568115
Validation loss: 2.0268770257631936

Epoch: 5| Step: 4
Training loss: 1.981133222579956
Validation loss: 2.030376151204109

Epoch: 5| Step: 5
Training loss: 2.0150773525238037
Validation loss: 2.027922183275223

Epoch: 5| Step: 6
Training loss: 2.130002498626709
Validation loss: 2.0344749987125397

Epoch: 5| Step: 7
Training loss: 1.8710267543792725
Validation loss: 2.0318468610445657

Epoch: 5| Step: 8
Training loss: 2.079730987548828
Validation loss: 2.0297825584808984

Epoch: 5| Step: 9
Training loss: 1.944908857345581
Validation loss: 2.039048304160436

Epoch: 5| Step: 10
Training loss: 1.9464263916015625
Validation loss: 2.037869473298391

Epoch: 5| Step: 11
Training loss: 2.48091459274292
Validation loss: 2.0304552714029946

Epoch: 112| Step: 0
Training loss: 2.1522164344787598
Validation loss: 2.029410163561503

Epoch: 5| Step: 1
Training loss: 2.4466586112976074
Validation loss: 2.0373521943887076

Epoch: 5| Step: 2
Training loss: 1.8129889965057373
Validation loss: 2.0399233599503837

Epoch: 5| Step: 3
Training loss: 2.4193217754364014
Validation loss: 2.036108190814654

Epoch: 5| Step: 4
Training loss: 1.9417165517807007
Validation loss: 2.0296177566051483

Epoch: 5| Step: 5
Training loss: 2.336348056793213
Validation loss: 2.0325696617364883

Epoch: 5| Step: 6
Training loss: 2.469564914703369
Validation loss: 2.0321521212657294

Epoch: 5| Step: 7
Training loss: 2.01823353767395
Validation loss: 2.039970417817434

Epoch: 5| Step: 8
Training loss: 2.284606695175171
Validation loss: 2.0297208527723947

Epoch: 5| Step: 9
Training loss: 1.2778515815734863
Validation loss: 2.028186316291491

Epoch: 5| Step: 10
Training loss: 2.0398120880126953
Validation loss: 2.0216306845347085

Epoch: 5| Step: 11
Training loss: 2.1167430877685547
Validation loss: 2.0246709883213043

Epoch: 113| Step: 0
Training loss: 1.821272850036621
Validation loss: 2.0181728651126227

Epoch: 5| Step: 1
Training loss: 2.2460222244262695
Validation loss: 2.0156599630912146

Epoch: 5| Step: 2
Training loss: 1.9958235025405884
Validation loss: 2.0154021779696145

Epoch: 5| Step: 3
Training loss: 2.344316244125366
Validation loss: 2.0173584719498954

Epoch: 5| Step: 4
Training loss: 2.102006196975708
Validation loss: 2.020186414321264

Epoch: 5| Step: 5
Training loss: 1.8179962635040283
Validation loss: 2.0206559697786965

Epoch: 5| Step: 6
Training loss: 2.1357357501983643
Validation loss: 2.0346452246109643

Epoch: 5| Step: 7
Training loss: 2.2528014183044434
Validation loss: 2.0152195443709693

Epoch: 5| Step: 8
Training loss: 2.0256123542785645
Validation loss: 2.023930932084719

Epoch: 5| Step: 9
Training loss: 2.315575361251831
Validation loss: 2.027114654580752

Epoch: 5| Step: 10
Training loss: 2.0505669116973877
Validation loss: 2.0205803414185843

Epoch: 5| Step: 11
Training loss: 2.315105676651001
Validation loss: 2.0146533846855164

Epoch: 114| Step: 0
Training loss: 2.1824588775634766
Validation loss: 2.022422874967257

Epoch: 5| Step: 1
Training loss: 1.8741490840911865
Validation loss: 2.027673363685608

Epoch: 5| Step: 2
Training loss: 2.1290230751037598
Validation loss: 2.029003918170929

Epoch: 5| Step: 3
Training loss: 1.7571319341659546
Validation loss: 2.0345063557227454

Epoch: 5| Step: 4
Training loss: 2.640860080718994
Validation loss: 2.0220720320940018

Epoch: 5| Step: 5
Training loss: 2.37789249420166
Validation loss: 2.0164248098929725

Epoch: 5| Step: 6
Training loss: 2.2253599166870117
Validation loss: 2.0132073014974594

Epoch: 5| Step: 7
Training loss: 2.0806853771209717
Validation loss: 2.0137883921464286

Epoch: 5| Step: 8
Training loss: 1.9216572046279907
Validation loss: 2.0223667869965234

Epoch: 5| Step: 9
Training loss: 2.090508460998535
Validation loss: 2.021236980954806

Epoch: 5| Step: 10
Training loss: 2.20208740234375
Validation loss: 2.036674901843071

Epoch: 5| Step: 11
Training loss: 3.0364561080932617
Validation loss: 2.025907208522161

Epoch: 115| Step: 0
Training loss: 2.3172993659973145
Validation loss: 2.031371752421061

Epoch: 5| Step: 1
Training loss: 1.7677030563354492
Validation loss: 2.0322835395733514

Epoch: 5| Step: 2
Training loss: 1.8553717136383057
Validation loss: 2.0279080222050347

Epoch: 5| Step: 3
Training loss: 2.418398380279541
Validation loss: 2.0272994885842004

Epoch: 5| Step: 4
Training loss: 2.3984830379486084
Validation loss: 2.0273269712924957

Epoch: 5| Step: 5
Training loss: 1.9214515686035156
Validation loss: 2.0221097071965537

Epoch: 5| Step: 6
Training loss: 2.163504123687744
Validation loss: 2.008021508653959

Epoch: 5| Step: 7
Training loss: 2.512220859527588
Validation loss: 2.0102972239255905

Epoch: 5| Step: 8
Training loss: 2.444962739944458
Validation loss: 2.006022418538729

Epoch: 5| Step: 9
Training loss: 0.9649839401245117
Validation loss: 2.0181434700886407

Epoch: 5| Step: 10
Training loss: 2.5547471046447754
Validation loss: 2.0188547670841217

Epoch: 5| Step: 11
Training loss: 1.7658398151397705
Validation loss: 2.0335087726513543

Epoch: 116| Step: 0
Training loss: 2.4113049507141113
Validation loss: 2.0226855874061584

Epoch: 5| Step: 1
Training loss: 2.437450885772705
Validation loss: 2.028885473807653

Epoch: 5| Step: 2
Training loss: 2.487370729446411
Validation loss: 2.0238550206025443

Epoch: 5| Step: 3
Training loss: 1.9178905487060547
Validation loss: 2.024774432182312

Epoch: 5| Step: 4
Training loss: 1.6854074001312256
Validation loss: 2.019083693623543

Epoch: 5| Step: 5
Training loss: 2.0100769996643066
Validation loss: 2.0113427142302194

Epoch: 5| Step: 6
Training loss: 2.0456130504608154
Validation loss: 2.0065037608146667

Epoch: 5| Step: 7
Training loss: 1.906137228012085
Validation loss: 2.008225147922834

Epoch: 5| Step: 8
Training loss: 2.0870754718780518
Validation loss: 2.012691080570221

Epoch: 5| Step: 9
Training loss: 2.2219183444976807
Validation loss: 2.0150019178787866

Epoch: 5| Step: 10
Training loss: 1.8814923763275146
Validation loss: 2.007039358218511

Epoch: 5| Step: 11
Training loss: 2.7820723056793213
Validation loss: 2.005836859345436

Epoch: 117| Step: 0
Training loss: 2.565106153488159
Validation loss: 1.9989169736703236

Epoch: 5| Step: 1
Training loss: 1.8176162242889404
Validation loss: 2.0022760331630707

Epoch: 5| Step: 2
Training loss: 1.9741220474243164
Validation loss: 2.0068386991818747

Epoch: 5| Step: 3
Training loss: 1.9918102025985718
Validation loss: 2.0160676538944244

Epoch: 5| Step: 4
Training loss: 1.735060453414917
Validation loss: 2.0073696821928024

Epoch: 5| Step: 5
Training loss: 1.8560030460357666
Validation loss: 2.0088178515434265

Epoch: 5| Step: 6
Training loss: 2.104663372039795
Validation loss: 2.014494001865387

Epoch: 5| Step: 7
Training loss: 3.0544610023498535
Validation loss: 2.0322058498859406

Epoch: 5| Step: 8
Training loss: 2.094935655593872
Validation loss: 2.04002246260643

Epoch: 5| Step: 9
Training loss: 1.9796745777130127
Validation loss: 2.0327967703342438

Epoch: 5| Step: 10
Training loss: 2.1296181678771973
Validation loss: 2.030513256788254

Epoch: 5| Step: 11
Training loss: 2.5811562538146973
Validation loss: 2.0353469600280127

Epoch: 118| Step: 0
Training loss: 2.105621099472046
Validation loss: 2.0173499385515847

Epoch: 5| Step: 1
Training loss: 2.305906295776367
Validation loss: 2.0107874870300293

Epoch: 5| Step: 2
Training loss: 1.846540093421936
Validation loss: 2.010125165184339

Epoch: 5| Step: 3
Training loss: 1.7868726253509521
Validation loss: 2.0147114992141724

Epoch: 5| Step: 4
Training loss: 2.506319046020508
Validation loss: 2.019340361158053

Epoch: 5| Step: 5
Training loss: 2.697929620742798
Validation loss: 2.0199214965105057

Epoch: 5| Step: 6
Training loss: 2.079580783843994
Validation loss: 2.0245573421319327

Epoch: 5| Step: 7
Training loss: 1.8313878774642944
Validation loss: 2.03106090426445

Epoch: 5| Step: 8
Training loss: 2.201143980026245
Validation loss: 2.0290726025899253

Epoch: 5| Step: 9
Training loss: 2.1151630878448486
Validation loss: 2.0298092116912207

Epoch: 5| Step: 10
Training loss: 1.9774351119995117
Validation loss: 2.0244410037994385

Epoch: 5| Step: 11
Training loss: 3.227452278137207
Validation loss: 2.0182839979728064

Epoch: 119| Step: 0
Training loss: 1.9573380947113037
Validation loss: 2.0190702428420386

Epoch: 5| Step: 1
Training loss: 2.144855260848999
Validation loss: 2.0172874877850213

Epoch: 5| Step: 2
Training loss: 2.4335899353027344
Validation loss: 2.007611259818077

Epoch: 5| Step: 3
Training loss: 2.3221240043640137
Validation loss: 2.010935033361117

Epoch: 5| Step: 4
Training loss: 2.1953816413879395
Validation loss: 2.0042280356089273

Epoch: 5| Step: 5
Training loss: 1.8078933954238892
Validation loss: 2.0058617095152536

Epoch: 5| Step: 6
Training loss: 2.1679959297180176
Validation loss: 2.010691687464714

Epoch: 5| Step: 7
Training loss: 1.8543710708618164
Validation loss: 2.0123097697893777

Epoch: 5| Step: 8
Training loss: 2.220353126525879
Validation loss: 2.020788292090098

Epoch: 5| Step: 9
Training loss: 1.6579513549804688
Validation loss: 2.0251165628433228

Epoch: 5| Step: 10
Training loss: 2.265352249145508
Validation loss: 2.030248229702314

Epoch: 5| Step: 11
Training loss: 2.641408920288086
Validation loss: 2.0463349421819053

Epoch: 120| Step: 0
Training loss: 1.6354938745498657
Validation loss: 2.0274177193641663

Epoch: 5| Step: 1
Training loss: 2.7882161140441895
Validation loss: 2.012905567884445

Epoch: 5| Step: 2
Training loss: 2.0642757415771484
Validation loss: 2.0142371902863183

Epoch: 5| Step: 3
Training loss: 2.126210927963257
Validation loss: 2.0068598041931787

Epoch: 5| Step: 4
Training loss: 2.001936912536621
Validation loss: 2.0131699591875076

Epoch: 5| Step: 5
Training loss: 2.6488423347473145
Validation loss: 2.0112634102503457

Epoch: 5| Step: 6
Training loss: 2.1236724853515625
Validation loss: 2.0127960840861

Epoch: 5| Step: 7
Training loss: 2.3447563648223877
Validation loss: 2.0140920132398605

Epoch: 5| Step: 8
Training loss: 2.1851372718811035
Validation loss: 2.0138682276010513

Epoch: 5| Step: 9
Training loss: 1.245938777923584
Validation loss: 2.0104180177052817

Epoch: 5| Step: 10
Training loss: 2.070655345916748
Validation loss: 2.0119859874248505

Epoch: 5| Step: 11
Training loss: 1.5356656312942505
Validation loss: 2.0173386385043464

Epoch: 121| Step: 0
Training loss: 2.079937219619751
Validation loss: 2.0304329097270966

Epoch: 5| Step: 1
Training loss: 2.149827003479004
Validation loss: 2.0218822906414666

Epoch: 5| Step: 2
Training loss: 2.1398210525512695
Validation loss: 2.025978446006775

Epoch: 5| Step: 3
Training loss: 1.8106520175933838
Validation loss: 2.0240918000539145

Epoch: 5| Step: 4
Training loss: 2.309385299682617
Validation loss: 2.029268503189087

Epoch: 5| Step: 5
Training loss: 1.7350364923477173
Validation loss: 2.0207021733125052

Epoch: 5| Step: 6
Training loss: 2.60925555229187
Validation loss: 2.0227062751849494

Epoch: 5| Step: 7
Training loss: 1.8761688470840454
Validation loss: 2.0198062509298325

Epoch: 5| Step: 8
Training loss: 2.283447504043579
Validation loss: 2.025624692440033

Epoch: 5| Step: 9
Training loss: 2.0704524517059326
Validation loss: 2.021928384900093

Epoch: 5| Step: 10
Training loss: 2.1542348861694336
Validation loss: 2.025003661712011

Epoch: 5| Step: 11
Training loss: 1.687559962272644
Validation loss: 2.0215681344270706

Epoch: 122| Step: 0
Training loss: 2.2828688621520996
Validation loss: 2.0337345600128174

Epoch: 5| Step: 1
Training loss: 1.6285396814346313
Validation loss: 2.0344841678937278

Epoch: 5| Step: 2
Training loss: 1.876786470413208
Validation loss: 2.0294647216796875

Epoch: 5| Step: 3
Training loss: 2.1567635536193848
Validation loss: 2.040347213546435

Epoch: 5| Step: 4
Training loss: 2.5441675186157227
Validation loss: 2.0327107161283493

Epoch: 5| Step: 5
Training loss: 1.9649416208267212
Validation loss: 2.0314032385746636

Epoch: 5| Step: 6
Training loss: 2.2605693340301514
Validation loss: 2.0253625363111496

Epoch: 5| Step: 7
Training loss: 2.1870222091674805
Validation loss: 2.0279220392306647

Epoch: 5| Step: 8
Training loss: 2.061861515045166
Validation loss: 2.0282715360323587

Epoch: 5| Step: 9
Training loss: 2.5136971473693848
Validation loss: 2.0228139013051987

Epoch: 5| Step: 10
Training loss: 1.8023821115493774
Validation loss: 2.0307836482922235

Epoch: 5| Step: 11
Training loss: 1.1930357217788696
Validation loss: 2.0240123520294824

Epoch: 123| Step: 0
Training loss: 2.0897088050842285
Validation loss: 2.026327798763911

Epoch: 5| Step: 1
Training loss: 2.146371841430664
Validation loss: 2.030834053953489

Epoch: 5| Step: 2
Training loss: 2.091115713119507
Validation loss: 2.0362903773784637

Epoch: 5| Step: 3
Training loss: 1.1430362462997437
Validation loss: 2.0448933442433677

Epoch: 5| Step: 4
Training loss: 1.93416428565979
Validation loss: 2.051262075702349

Epoch: 5| Step: 5
Training loss: 2.2503013610839844
Validation loss: 2.048949549595515

Epoch: 5| Step: 6
Training loss: 1.9338645935058594
Validation loss: 2.0562297205130258

Epoch: 5| Step: 7
Training loss: 2.5085885524749756
Validation loss: 2.0500638534625373

Epoch: 5| Step: 8
Training loss: 2.607191801071167
Validation loss: 2.03291417658329

Epoch: 5| Step: 9
Training loss: 2.3338873386383057
Validation loss: 2.0349414497613907

Epoch: 5| Step: 10
Training loss: 1.9073024988174438
Validation loss: 2.0268147041400275

Epoch: 5| Step: 11
Training loss: 1.9607353210449219
Validation loss: 2.0389583706855774

Epoch: 124| Step: 0
Training loss: 1.6652895212173462
Validation loss: 2.038904547691345

Epoch: 5| Step: 1
Training loss: 1.7171388864517212
Validation loss: 2.0274712344010672

Epoch: 5| Step: 2
Training loss: 2.9561386108398438
Validation loss: 2.0351370871067047

Epoch: 5| Step: 3
Training loss: 2.1039538383483887
Validation loss: 2.0372448414564133

Epoch: 5| Step: 4
Training loss: 2.2781310081481934
Validation loss: 2.0343628923098245

Epoch: 5| Step: 5
Training loss: 2.1379570960998535
Validation loss: 2.0395844131708145

Epoch: 5| Step: 6
Training loss: 2.0197746753692627
Validation loss: 2.036720022559166

Epoch: 5| Step: 7
Training loss: 2.71311092376709
Validation loss: 2.0331259022156396

Epoch: 5| Step: 8
Training loss: 2.046903371810913
Validation loss: 2.03982175886631

Epoch: 5| Step: 9
Training loss: 2.3402838706970215
Validation loss: 2.0381543189287186

Epoch: 5| Step: 10
Training loss: 1.6460508108139038
Validation loss: 2.040875797470411

Epoch: 5| Step: 11
Training loss: 2.1583619117736816
Validation loss: 2.040531739592552

Epoch: 125| Step: 0
Training loss: 2.202284336090088
Validation loss: 2.0281009872754416

Epoch: 5| Step: 1
Training loss: 2.3444342613220215
Validation loss: 2.013428876797358

Epoch: 5| Step: 2
Training loss: 1.9120838642120361
Validation loss: 2.011550893386205

Epoch: 5| Step: 3
Training loss: 2.24090838432312
Validation loss: 2.012440949678421

Epoch: 5| Step: 4
Training loss: 1.2267282009124756
Validation loss: 2.0182851403951645

Epoch: 5| Step: 5
Training loss: 2.011215925216675
Validation loss: 2.018761192758878

Epoch: 5| Step: 6
Training loss: 2.7888476848602295
Validation loss: 2.021900236606598

Epoch: 5| Step: 7
Training loss: 2.3127896785736084
Validation loss: 2.026158129175504

Epoch: 5| Step: 8
Training loss: 2.7052736282348633
Validation loss: 2.0359807362159095

Epoch: 5| Step: 9
Training loss: 1.8719584941864014
Validation loss: 2.0420444905757904

Epoch: 5| Step: 10
Training loss: 2.089120864868164
Validation loss: 2.0429486831029258

Epoch: 5| Step: 11
Training loss: 1.6692616939544678
Validation loss: 2.041513830423355

Epoch: 126| Step: 0
Training loss: 2.2762222290039062
Validation loss: 2.0342703809340796

Epoch: 5| Step: 1
Training loss: 1.993531584739685
Validation loss: 2.032245154182116

Epoch: 5| Step: 2
Training loss: 1.916825532913208
Validation loss: 2.0289262533187866

Epoch: 5| Step: 3
Training loss: 2.5852837562561035
Validation loss: 2.0231363028287888

Epoch: 5| Step: 4
Training loss: 1.912427306175232
Validation loss: 2.0152797202269235

Epoch: 5| Step: 5
Training loss: 1.9818767309188843
Validation loss: 2.022154485185941

Epoch: 5| Step: 6
Training loss: 2.4098403453826904
Validation loss: 2.0080416003863015

Epoch: 5| Step: 7
Training loss: 2.288958787918091
Validation loss: 2.016436214248339

Epoch: 5| Step: 8
Training loss: 2.3364205360412598
Validation loss: 2.0220175286134086

Epoch: 5| Step: 9
Training loss: 1.9681867361068726
Validation loss: 2.0160027096668878

Epoch: 5| Step: 10
Training loss: 1.8260142803192139
Validation loss: 2.021168698867162

Epoch: 5| Step: 11
Training loss: 1.0668587684631348
Validation loss: 2.021546259522438

Epoch: 127| Step: 0
Training loss: 2.3163437843322754
Validation loss: 2.031734054287275

Epoch: 5| Step: 1
Training loss: 2.2426400184631348
Validation loss: 2.0283869157234826

Epoch: 5| Step: 2
Training loss: 2.4694533348083496
Validation loss: 2.024843081831932

Epoch: 5| Step: 3
Training loss: 1.8954744338989258
Validation loss: 2.023854374885559

Epoch: 5| Step: 4
Training loss: 1.8319575786590576
Validation loss: 2.0254767686128616

Epoch: 5| Step: 5
Training loss: 2.1089463233947754
Validation loss: 2.0233327001333237

Epoch: 5| Step: 6
Training loss: 2.334291934967041
Validation loss: 2.020326405763626

Epoch: 5| Step: 7
Training loss: 1.9085994958877563
Validation loss: 2.025808736681938

Epoch: 5| Step: 8
Training loss: 1.7110847234725952
Validation loss: 2.0327028930187225

Epoch: 5| Step: 9
Training loss: 2.181501865386963
Validation loss: 2.042681430776914

Epoch: 5| Step: 10
Training loss: 2.0549890995025635
Validation loss: 2.0530812491973243

Epoch: 5| Step: 11
Training loss: 2.2501649856567383
Validation loss: 2.039475550254186

Epoch: 128| Step: 0
Training loss: 2.2294249534606934
Validation loss: 2.047606443365415

Epoch: 5| Step: 1
Training loss: 1.6520239114761353
Validation loss: 2.044048806031545

Epoch: 5| Step: 2
Training loss: 2.6170265674591064
Validation loss: 2.0488113264242807

Epoch: 5| Step: 3
Training loss: 2.602790355682373
Validation loss: 2.040263374646505

Epoch: 5| Step: 4
Training loss: 1.9738765954971313
Validation loss: 2.0423510124286017

Epoch: 5| Step: 5
Training loss: 1.965476632118225
Validation loss: 2.0412847846746445

Epoch: 5| Step: 6
Training loss: 2.007697582244873
Validation loss: 2.05148783326149

Epoch: 5| Step: 7
Training loss: 1.8305000066757202
Validation loss: 2.042150601744652

Epoch: 5| Step: 8
Training loss: 2.0903453826904297
Validation loss: 2.03785107533137

Epoch: 5| Step: 9
Training loss: 2.101081132888794
Validation loss: 2.0473943849404654

Epoch: 5| Step: 10
Training loss: 2.1085009574890137
Validation loss: 2.0386850237846375

Epoch: 5| Step: 11
Training loss: 0.6975024938583374
Validation loss: 2.027922198176384

Epoch: 129| Step: 0
Training loss: 2.0129199028015137
Validation loss: 2.026704783240954

Epoch: 5| Step: 1
Training loss: 2.1883339881896973
Validation loss: 2.0263370722532272

Epoch: 5| Step: 2
Training loss: 2.1000475883483887
Validation loss: 2.0273036311070123

Epoch: 5| Step: 3
Training loss: 2.153658628463745
Validation loss: 2.0226824581623077

Epoch: 5| Step: 4
Training loss: 2.9105377197265625
Validation loss: 2.03125753502051

Epoch: 5| Step: 5
Training loss: 2.3092689514160156
Validation loss: 2.0373649497826896

Epoch: 5| Step: 6
Training loss: 2.4635586738586426
Validation loss: 2.0457137127717337

Epoch: 5| Step: 7
Training loss: 2.054835081100464
Validation loss: 2.041465232769648

Epoch: 5| Step: 8
Training loss: 1.1797960996627808
Validation loss: 2.034861534833908

Epoch: 5| Step: 9
Training loss: 1.5623358488082886
Validation loss: 2.0390431980292

Epoch: 5| Step: 10
Training loss: 1.9577181339263916
Validation loss: 2.0309453159570694

Epoch: 5| Step: 11
Training loss: 3.148568630218506
Validation loss: 2.04216605424881

Epoch: 130| Step: 0
Training loss: 1.4420377016067505
Validation loss: 2.045165831844012

Epoch: 5| Step: 1
Training loss: 1.9771229028701782
Validation loss: 2.0450522204240165

Epoch: 5| Step: 2
Training loss: 1.732926368713379
Validation loss: 2.0469693740208945

Epoch: 5| Step: 3
Training loss: 2.4271318912506104
Validation loss: 2.0366627474625907

Epoch: 5| Step: 4
Training loss: 3.0771918296813965
Validation loss: 2.039834419886271

Epoch: 5| Step: 5
Training loss: 1.6630918979644775
Validation loss: 2.042811239759127

Epoch: 5| Step: 6
Training loss: 2.027635097503662
Validation loss: 2.043609857559204

Epoch: 5| Step: 7
Training loss: 2.645752429962158
Validation loss: 2.023196508487066

Epoch: 5| Step: 8
Training loss: 2.052696704864502
Validation loss: 2.019574219981829

Epoch: 5| Step: 9
Training loss: 2.3237671852111816
Validation loss: 2.029025048017502

Epoch: 5| Step: 10
Training loss: 1.695946455001831
Validation loss: 2.019198328256607

Epoch: 5| Step: 11
Training loss: 1.5991891622543335
Validation loss: 2.0302711129188538

Epoch: 131| Step: 0
Training loss: 1.957578420639038
Validation loss: 2.022967219352722

Epoch: 5| Step: 1
Training loss: 1.9861246347427368
Validation loss: 2.0277311305205026

Epoch: 5| Step: 2
Training loss: 2.0935237407684326
Validation loss: 2.0307705104351044

Epoch: 5| Step: 3
Training loss: 2.1625020503997803
Validation loss: 2.037661130229632

Epoch: 5| Step: 4
Training loss: 2.0852410793304443
Validation loss: 2.038233702381452

Epoch: 5| Step: 5
Training loss: 2.3125619888305664
Validation loss: 2.042771344383558

Epoch: 5| Step: 6
Training loss: 2.758984327316284
Validation loss: 2.0485343982776008

Epoch: 5| Step: 7
Training loss: 2.1376144886016846
Validation loss: 2.0424658060073853

Epoch: 5| Step: 8
Training loss: 2.0042738914489746
Validation loss: 2.046073392033577

Epoch: 5| Step: 9
Training loss: 2.176924228668213
Validation loss: 2.045304074883461

Epoch: 5| Step: 10
Training loss: 1.4826205968856812
Validation loss: 2.043391431371371

Epoch: 5| Step: 11
Training loss: 1.3678327798843384
Validation loss: 2.0404125948747

Epoch: 132| Step: 0
Training loss: 2.2300524711608887
Validation loss: 2.0508665641148887

Epoch: 5| Step: 1
Training loss: 1.8135764598846436
Validation loss: 2.0733342270056405

Epoch: 5| Step: 2
Training loss: 2.2098772525787354
Validation loss: 2.0889230519533157

Epoch: 5| Step: 3
Training loss: 2.2688872814178467
Validation loss: 2.0997591515382132

Epoch: 5| Step: 4
Training loss: 2.34574818611145
Validation loss: 2.0980010827382407

Epoch: 5| Step: 5
Training loss: 2.370480537414551
Validation loss: 2.118009696404139

Epoch: 5| Step: 6
Training loss: 1.795910120010376
Validation loss: 2.1134591102600098

Epoch: 5| Step: 7
Training loss: 2.2529759407043457
Validation loss: 2.088785797357559

Epoch: 5| Step: 8
Training loss: 1.9797605276107788
Validation loss: 2.0758538444836936

Epoch: 5| Step: 9
Training loss: 2.0982604026794434
Validation loss: 2.062908058365186

Epoch: 5| Step: 10
Training loss: 2.1830997467041016
Validation loss: 2.031137153506279

Epoch: 5| Step: 11
Training loss: 2.0707294940948486
Validation loss: 2.019569839040438

Epoch: 133| Step: 0
Training loss: 2.589585304260254
Validation loss: 2.0183183948198953

Epoch: 5| Step: 1
Training loss: 2.0460574626922607
Validation loss: 2.0125659654537835

Epoch: 5| Step: 2
Training loss: 2.2582755088806152
Validation loss: 2.00911937157313

Epoch: 5| Step: 3
Training loss: 1.8195598125457764
Validation loss: 2.015672321120898

Epoch: 5| Step: 4
Training loss: 2.520359992980957
Validation loss: 2.022036467989286

Epoch: 5| Step: 5
Training loss: 1.7681831121444702
Validation loss: 2.0236368079980216

Epoch: 5| Step: 6
Training loss: 1.9622348546981812
Validation loss: 2.0252658128738403

Epoch: 5| Step: 7
Training loss: 1.6809937953948975
Validation loss: 2.0238041132688522

Epoch: 5| Step: 8
Training loss: 2.3331949710845947
Validation loss: 2.021813382705053

Epoch: 5| Step: 9
Training loss: 2.1452536582946777
Validation loss: 2.0311608215173087

Epoch: 5| Step: 10
Training loss: 2.2537262439727783
Validation loss: 2.0213118543227515

Epoch: 5| Step: 11
Training loss: 2.2565693855285645
Validation loss: 2.0220841765403748

Epoch: 134| Step: 0
Training loss: 2.279869794845581
Validation loss: 2.0245354572931924

Epoch: 5| Step: 1
Training loss: 2.8442776203155518
Validation loss: 2.0277483065923056

Epoch: 5| Step: 2
Training loss: 2.112560749053955
Validation loss: 2.033378228545189

Epoch: 5| Step: 3
Training loss: 1.2430932521820068
Validation loss: 2.0306173662344613

Epoch: 5| Step: 4
Training loss: 2.270568370819092
Validation loss: 2.0461417138576508

Epoch: 5| Step: 5
Training loss: 1.8849680423736572
Validation loss: 2.051146740714709

Epoch: 5| Step: 6
Training loss: 1.9874433279037476
Validation loss: 2.0683245062828064

Epoch: 5| Step: 7
Training loss: 1.9297653436660767
Validation loss: 2.0766780078411102

Epoch: 5| Step: 8
Training loss: 2.460967540740967
Validation loss: 2.080172076821327

Epoch: 5| Step: 9
Training loss: 1.9199399948120117
Validation loss: 2.0847646991411843

Epoch: 5| Step: 10
Training loss: 2.2549099922180176
Validation loss: 2.0988325575987496

Epoch: 5| Step: 11
Training loss: 1.5176279544830322
Validation loss: 2.081818679968516

Epoch: 135| Step: 0
Training loss: 1.7358356714248657
Validation loss: 2.0675503065188727

Epoch: 5| Step: 1
Training loss: 2.1512932777404785
Validation loss: 2.058422490954399

Epoch: 5| Step: 2
Training loss: 2.238713264465332
Validation loss: 2.0362971226374307

Epoch: 5| Step: 3
Training loss: 2.174107074737549
Validation loss: 2.0423492987950644

Epoch: 5| Step: 4
Training loss: 2.1550660133361816
Validation loss: 2.025885393222173

Epoch: 5| Step: 5
Training loss: 1.8438926935195923
Validation loss: 2.027031804124514

Epoch: 5| Step: 6
Training loss: 2.0677223205566406
Validation loss: 2.0173598577578864

Epoch: 5| Step: 7
Training loss: 2.1169075965881348
Validation loss: 2.0176780621210733

Epoch: 5| Step: 8
Training loss: 2.364964485168457
Validation loss: 2.0175044387578964

Epoch: 5| Step: 9
Training loss: 2.1139962673187256
Validation loss: 2.0232347597678504

Epoch: 5| Step: 10
Training loss: 2.2681357860565186
Validation loss: 2.023633380730947

Epoch: 5| Step: 11
Training loss: 1.9638129472732544
Validation loss: 2.0299391696850457

Epoch: 136| Step: 0
Training loss: 1.8428516387939453
Validation loss: 2.0342715034882226

Epoch: 5| Step: 1
Training loss: 1.9434553384780884
Validation loss: 2.036400521794955

Epoch: 5| Step: 2
Training loss: 2.0074117183685303
Validation loss: 2.035297781229019

Epoch: 5| Step: 3
Training loss: 2.4918670654296875
Validation loss: 2.0384737998247147

Epoch: 5| Step: 4
Training loss: 2.175166606903076
Validation loss: 2.0407998313506446

Epoch: 5| Step: 5
Training loss: 1.7098405361175537
Validation loss: 2.041873882214228

Epoch: 5| Step: 6
Training loss: 1.9585233926773071
Validation loss: 2.0350937942663827

Epoch: 5| Step: 7
Training loss: 2.1492598056793213
Validation loss: 2.031867961088816

Epoch: 5| Step: 8
Training loss: 2.0259737968444824
Validation loss: 2.031840994954109

Epoch: 5| Step: 9
Training loss: 2.83015775680542
Validation loss: 2.025194158156713

Epoch: 5| Step: 10
Training loss: 2.340956449508667
Validation loss: 2.0222670088211694

Epoch: 5| Step: 11
Training loss: 1.643409013748169
Validation loss: 2.0218086342016854

Epoch: 137| Step: 0
Training loss: 2.39374041557312
Validation loss: 2.019209936261177

Epoch: 5| Step: 1
Training loss: 1.8056453466415405
Validation loss: 2.01672355333964

Epoch: 5| Step: 2
Training loss: 2.202070713043213
Validation loss: 2.01486104230086

Epoch: 5| Step: 3
Training loss: 2.448856830596924
Validation loss: 2.026118357976278

Epoch: 5| Step: 4
Training loss: 1.8309011459350586
Validation loss: 2.028872162103653

Epoch: 5| Step: 5
Training loss: 2.4641311168670654
Validation loss: 2.0371428976456323

Epoch: 5| Step: 6
Training loss: 1.6734950542449951
Validation loss: 2.0464222381512323

Epoch: 5| Step: 7
Training loss: 2.3665902614593506
Validation loss: 2.046200841665268

Epoch: 5| Step: 8
Training loss: 2.179971694946289
Validation loss: 2.037292550007502

Epoch: 5| Step: 9
Training loss: 2.0609829425811768
Validation loss: 2.0425354838371277

Epoch: 5| Step: 10
Training loss: 2.0392181873321533
Validation loss: 2.0413180540005365

Epoch: 5| Step: 11
Training loss: 0.8597897291183472
Validation loss: 2.035263498624166

Epoch: 138| Step: 0
Training loss: 2.2649917602539062
Validation loss: 2.037534470359484

Epoch: 5| Step: 1
Training loss: 2.0013434886932373
Validation loss: 2.0349467049042382

Epoch: 5| Step: 2
Training loss: 1.788995385169983
Validation loss: 2.0376380582650504

Epoch: 5| Step: 3
Training loss: 2.5726990699768066
Validation loss: 2.040827905138334

Epoch: 5| Step: 4
Training loss: 1.4911020994186401
Validation loss: 2.027377570668856

Epoch: 5| Step: 5
Training loss: 2.212169647216797
Validation loss: 2.0310634275277457

Epoch: 5| Step: 6
Training loss: 2.5106377601623535
Validation loss: 2.022358869512876

Epoch: 5| Step: 7
Training loss: 1.8485130071640015
Validation loss: 2.027591437101364

Epoch: 5| Step: 8
Training loss: 1.3266321420669556
Validation loss: 2.031337400277456

Epoch: 5| Step: 9
Training loss: 2.566816806793213
Validation loss: 2.0251458982626596

Epoch: 5| Step: 10
Training loss: 2.5611917972564697
Validation loss: 2.0191317250331244

Epoch: 5| Step: 11
Training loss: 1.5225001573562622
Validation loss: 2.031909311811129

Epoch: 139| Step: 0
Training loss: 2.0075902938842773
Validation loss: 2.0418798526128135

Epoch: 5| Step: 1
Training loss: 2.1741223335266113
Validation loss: 2.046810661753019

Epoch: 5| Step: 2
Training loss: 1.7738492488861084
Validation loss: 2.058449308077494

Epoch: 5| Step: 3
Training loss: 1.8561958074569702
Validation loss: 2.0514760265747705

Epoch: 5| Step: 4
Training loss: 2.089251756668091
Validation loss: 2.052533263961474

Epoch: 5| Step: 5
Training loss: 2.0021755695343018
Validation loss: 2.034178505341212

Epoch: 5| Step: 6
Training loss: 2.1798832416534424
Validation loss: 2.0493856271107993

Epoch: 5| Step: 7
Training loss: 2.597745180130005
Validation loss: 2.0432833085457482

Epoch: 5| Step: 8
Training loss: 1.9250681400299072
Validation loss: 2.0388499200344086

Epoch: 5| Step: 9
Training loss: 1.8431975841522217
Validation loss: 2.0410708685715995

Epoch: 5| Step: 10
Training loss: 2.3337981700897217
Validation loss: 2.0462449540694556

Epoch: 5| Step: 11
Training loss: 3.0490798950195312
Validation loss: 2.0321975151697793

Epoch: 140| Step: 0
Training loss: 2.135219097137451
Validation loss: 2.0421054710944495

Epoch: 5| Step: 1
Training loss: 2.259422540664673
Validation loss: 2.0367503662904105

Epoch: 5| Step: 2
Training loss: 2.290522813796997
Validation loss: 2.0374126931031546

Epoch: 5| Step: 3
Training loss: 2.341700792312622
Validation loss: 2.0333829571803412

Epoch: 5| Step: 4
Training loss: 1.667175054550171
Validation loss: 2.041863595445951

Epoch: 5| Step: 5
Training loss: 2.067823886871338
Validation loss: 2.0241379340489707

Epoch: 5| Step: 6
Training loss: 1.5301506519317627
Validation loss: 2.036386107405027

Epoch: 5| Step: 7
Training loss: 1.92635178565979
Validation loss: 2.0317843705415726

Epoch: 5| Step: 8
Training loss: 2.452814817428589
Validation loss: 2.025618940591812

Epoch: 5| Step: 9
Training loss: 2.299008369445801
Validation loss: 2.0298159768184028

Epoch: 5| Step: 10
Training loss: 1.8263285160064697
Validation loss: 2.040128211180369

Epoch: 5| Step: 11
Training loss: 1.8770883083343506
Validation loss: 2.0440493722756705

Epoch: 141| Step: 0
Training loss: 1.860236406326294
Validation loss: 2.026848534742991

Epoch: 5| Step: 1
Training loss: 2.270216226577759
Validation loss: 2.0221339215834937

Epoch: 5| Step: 2
Training loss: 2.110494613647461
Validation loss: 2.0242334504922233

Epoch: 5| Step: 3
Training loss: 1.6734802722930908
Validation loss: 2.02508711318175

Epoch: 5| Step: 4
Training loss: 2.4186019897460938
Validation loss: 2.01704640686512

Epoch: 5| Step: 5
Training loss: 2.4585678577423096
Validation loss: 2.0157653391361237

Epoch: 5| Step: 6
Training loss: 2.3728911876678467
Validation loss: 2.0277038514614105

Epoch: 5| Step: 7
Training loss: 2.11185359954834
Validation loss: 2.018539403875669

Epoch: 5| Step: 8
Training loss: 1.7286970615386963
Validation loss: 2.02793517212073

Epoch: 5| Step: 9
Training loss: 2.0995616912841797
Validation loss: 2.022921234369278

Epoch: 5| Step: 10
Training loss: 1.9148660898208618
Validation loss: 2.0278624445199966

Epoch: 5| Step: 11
Training loss: 1.6708029508590698
Validation loss: 2.031073992451032

Epoch: 142| Step: 0
Training loss: 2.2469983100891113
Validation loss: 2.0336464792490005

Epoch: 5| Step: 1
Training loss: 2.1850268840789795
Validation loss: 2.033512915174166

Epoch: 5| Step: 2
Training loss: 1.0824910402297974
Validation loss: 2.0371074080467224

Epoch: 5| Step: 3
Training loss: 1.6695178747177124
Validation loss: 2.0555457522471747

Epoch: 5| Step: 4
Training loss: 2.3937935829162598
Validation loss: 2.0688177595535913

Epoch: 5| Step: 5
Training loss: 1.694196343421936
Validation loss: 2.067188267906507

Epoch: 5| Step: 6
Training loss: 2.7588415145874023
Validation loss: 2.0620140631993613

Epoch: 5| Step: 7
Training loss: 2.4182701110839844
Validation loss: 2.0606574515501657

Epoch: 5| Step: 8
Training loss: 1.9296432733535767
Validation loss: 2.04930013914903

Epoch: 5| Step: 9
Training loss: 2.0053069591522217
Validation loss: 2.0515227913856506

Epoch: 5| Step: 10
Training loss: 2.595752000808716
Validation loss: 2.0440865655740104

Epoch: 5| Step: 11
Training loss: 1.9098100662231445
Validation loss: 2.035368720690409

Epoch: 143| Step: 0
Training loss: 2.5911316871643066
Validation loss: 2.040424863497416

Epoch: 5| Step: 1
Training loss: 2.1727848052978516
Validation loss: 2.043345878521601

Epoch: 5| Step: 2
Training loss: 1.6657686233520508
Validation loss: 2.043313299616178

Epoch: 5| Step: 3
Training loss: 1.7017444372177124
Validation loss: 2.0299238910277686

Epoch: 5| Step: 4
Training loss: 2.38122296333313
Validation loss: 2.036840428908666

Epoch: 5| Step: 5
Training loss: 1.6606029272079468
Validation loss: 2.0403872231642404

Epoch: 5| Step: 6
Training loss: 2.013835906982422
Validation loss: 2.035678098599116

Epoch: 5| Step: 7
Training loss: 2.1008241176605225
Validation loss: 2.045604800184568

Epoch: 5| Step: 8
Training loss: 1.9457309246063232
Validation loss: 2.0491978774468103

Epoch: 5| Step: 9
Training loss: 2.2489633560180664
Validation loss: 2.036204149325689

Epoch: 5| Step: 10
Training loss: 2.2806193828582764
Validation loss: 2.0404591411352158

Epoch: 5| Step: 11
Training loss: 1.6814583539962769
Validation loss: 2.032214894890785

Epoch: 144| Step: 0
Training loss: 1.8260345458984375
Validation loss: 2.039766093095144

Epoch: 5| Step: 1
Training loss: 2.3452560901641846
Validation loss: 2.031549642483393

Epoch: 5| Step: 2
Training loss: 2.0237514972686768
Validation loss: 2.029830982287725

Epoch: 5| Step: 3
Training loss: 1.998685598373413
Validation loss: 2.03845943013827

Epoch: 5| Step: 4
Training loss: 1.9586687088012695
Validation loss: 2.0355955163637796

Epoch: 5| Step: 5
Training loss: 2.2724814414978027
Validation loss: 2.040169989069303

Epoch: 5| Step: 6
Training loss: 2.283484935760498
Validation loss: 2.0281369388103485

Epoch: 5| Step: 7
Training loss: 1.3580257892608643
Validation loss: 2.0320548713207245

Epoch: 5| Step: 8
Training loss: 2.678525686264038
Validation loss: 2.043518970410029

Epoch: 5| Step: 9
Training loss: 1.8036448955535889
Validation loss: 2.040231709678968

Epoch: 5| Step: 10
Training loss: 1.8926454782485962
Validation loss: 2.0387972245613732

Epoch: 5| Step: 11
Training loss: 2.8589882850646973
Validation loss: 2.050058667858442

Epoch: 145| Step: 0
Training loss: 2.0522944927215576
Validation loss: 2.049915373325348

Epoch: 5| Step: 1
Training loss: 1.5871758460998535
Validation loss: 2.0522943486769996

Epoch: 5| Step: 2
Training loss: 2.059962511062622
Validation loss: 2.0460352152585983

Epoch: 5| Step: 3
Training loss: 2.1634106636047363
Validation loss: 2.05363367497921

Epoch: 5| Step: 4
Training loss: 2.281254291534424
Validation loss: 2.064770609140396

Epoch: 5| Step: 5
Training loss: 2.0491580963134766
Validation loss: 2.052601551016172

Epoch: 5| Step: 6
Training loss: 2.7121481895446777
Validation loss: 2.056143969297409

Epoch: 5| Step: 7
Training loss: 1.1373112201690674
Validation loss: 2.05013736585776

Epoch: 5| Step: 8
Training loss: 1.8505065441131592
Validation loss: 2.0509180625279746

Epoch: 5| Step: 9
Training loss: 2.262902021408081
Validation loss: 2.0535438458124795

Epoch: 5| Step: 10
Training loss: 2.5623281002044678
Validation loss: 2.0594637294610343

Epoch: 5| Step: 11
Training loss: 2.101243257522583
Validation loss: 2.0541169246037803

Epoch: 146| Step: 0
Training loss: 2.0016746520996094
Validation loss: 2.0492520928382874

Epoch: 5| Step: 1
Training loss: 2.05668306350708
Validation loss: 2.042475620905558

Epoch: 5| Step: 2
Training loss: 1.823171854019165
Validation loss: 2.043723007043203

Epoch: 5| Step: 3
Training loss: 1.8128458261489868
Validation loss: 2.04369193315506

Epoch: 5| Step: 4
Training loss: 2.1856532096862793
Validation loss: 2.028349911173185

Epoch: 5| Step: 5
Training loss: 1.8772380352020264
Validation loss: 2.043315370877584

Epoch: 5| Step: 6
Training loss: 1.660466194152832
Validation loss: 2.041678244868914

Epoch: 5| Step: 7
Training loss: 2.0025248527526855
Validation loss: 2.0384588042894998

Epoch: 5| Step: 8
Training loss: 2.3907222747802734
Validation loss: 2.0446521441141763

Epoch: 5| Step: 9
Training loss: 2.5401477813720703
Validation loss: 2.0452306667963662

Epoch: 5| Step: 10
Training loss: 2.5172348022460938
Validation loss: 2.042448416352272

Epoch: 5| Step: 11
Training loss: 1.6808750629425049
Validation loss: 2.0469084878762565

Epoch: 147| Step: 0
Training loss: 1.9873120784759521
Validation loss: 2.042156050602595

Epoch: 5| Step: 1
Training loss: 1.9556715488433838
Validation loss: 2.0436099419991174

Epoch: 5| Step: 2
Training loss: 2.173309326171875
Validation loss: 2.0316644509633384

Epoch: 5| Step: 3
Training loss: 1.9769912958145142
Validation loss: 2.038709968328476

Epoch: 5| Step: 4
Training loss: 1.949379324913025
Validation loss: 2.02867783109347

Epoch: 5| Step: 5
Training loss: 2.15029239654541
Validation loss: 2.040151705344518

Epoch: 5| Step: 6
Training loss: 1.7438195943832397
Validation loss: 2.03667514026165

Epoch: 5| Step: 7
Training loss: 2.507436752319336
Validation loss: 2.0471536119778952

Epoch: 5| Step: 8
Training loss: 2.279076099395752
Validation loss: 2.047904913624128

Epoch: 5| Step: 9
Training loss: 1.9969635009765625
Validation loss: 2.0335391958554587

Epoch: 5| Step: 10
Training loss: 2.031952381134033
Validation loss: 2.034699648618698

Epoch: 5| Step: 11
Training loss: 2.1670150756835938
Validation loss: 2.031870345274607

Epoch: 148| Step: 0
Training loss: 2.424189567565918
Validation loss: 2.032382438580195

Epoch: 5| Step: 1
Training loss: 1.953688383102417
Validation loss: 2.0340303083260856

Epoch: 5| Step: 2
Training loss: 2.42301082611084
Validation loss: 2.0401708285013833

Epoch: 5| Step: 3
Training loss: 2.1550259590148926
Validation loss: 2.0341928750276566

Epoch: 5| Step: 4
Training loss: 1.8749473094940186
Validation loss: 2.0430527528127036

Epoch: 5| Step: 5
Training loss: 1.968271255493164
Validation loss: 2.04076257844766

Epoch: 5| Step: 6
Training loss: 2.343906879425049
Validation loss: 2.046160558859507

Epoch: 5| Step: 7
Training loss: 1.9221264123916626
Validation loss: 2.037370274464289

Epoch: 5| Step: 8
Training loss: 2.310338258743286
Validation loss: 2.0377338528633118

Epoch: 5| Step: 9
Training loss: 1.9053682088851929
Validation loss: 2.036382704973221

Epoch: 5| Step: 10
Training loss: 2.027115821838379
Validation loss: 2.0352831532557807

Epoch: 5| Step: 11
Training loss: 0.8290328979492188
Validation loss: 2.028342271844546

Epoch: 149| Step: 0
Training loss: 2.533618927001953
Validation loss: 2.0265090068181357

Epoch: 5| Step: 1
Training loss: 1.8040424585342407
Validation loss: 2.03070268034935

Epoch: 5| Step: 2
Training loss: 1.8081352710723877
Validation loss: 2.0161528984705606

Epoch: 5| Step: 3
Training loss: 2.2348990440368652
Validation loss: 2.0310842245817184

Epoch: 5| Step: 4
Training loss: 1.927628755569458
Validation loss: 2.03611758351326

Epoch: 5| Step: 5
Training loss: 2.29518461227417
Validation loss: 2.026118124524752

Epoch: 5| Step: 6
Training loss: 2.045156955718994
Validation loss: 2.0330683241287866

Epoch: 5| Step: 7
Training loss: 2.1985971927642822
Validation loss: 2.029113695025444

Epoch: 5| Step: 8
Training loss: 2.1427712440490723
Validation loss: 2.0280518382787704

Epoch: 5| Step: 9
Training loss: 2.173027515411377
Validation loss: 2.028507133324941

Epoch: 5| Step: 10
Training loss: 1.8813072443008423
Validation loss: 2.0219305207331977

Epoch: 5| Step: 11
Training loss: 1.858427882194519
Validation loss: 2.01985856393973

Epoch: 150| Step: 0
Training loss: 2.121962308883667
Validation loss: 2.0304663379987082

Epoch: 5| Step: 1
Training loss: 2.2464399337768555
Validation loss: 2.030470257004102

Epoch: 5| Step: 2
Training loss: 2.470186948776245
Validation loss: 2.0269054671128592

Epoch: 5| Step: 3
Training loss: 1.5115725994110107
Validation loss: 2.021090805530548

Epoch: 5| Step: 4
Training loss: 1.7727687358856201
Validation loss: 2.016914740204811

Epoch: 5| Step: 5
Training loss: 2.248317241668701
Validation loss: 2.021511882543564

Epoch: 5| Step: 6
Training loss: 2.2225823402404785
Validation loss: 2.0251635114351907

Epoch: 5| Step: 7
Training loss: 2.2676591873168945
Validation loss: 2.029374122619629

Epoch: 5| Step: 8
Training loss: 1.9962431192398071
Validation loss: 2.025788272420565

Epoch: 5| Step: 9
Training loss: 2.0314648151397705
Validation loss: 2.0335928748051324

Epoch: 5| Step: 10
Training loss: 1.937567949295044
Validation loss: 2.0199356277783713

Epoch: 5| Step: 11
Training loss: 1.4456530809402466
Validation loss: 2.0384656886259713

Testing loss: 1.6539396656502923
