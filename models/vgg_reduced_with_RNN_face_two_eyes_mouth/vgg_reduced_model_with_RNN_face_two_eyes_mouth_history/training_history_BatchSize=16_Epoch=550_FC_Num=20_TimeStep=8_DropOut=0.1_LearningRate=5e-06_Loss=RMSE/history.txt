Epoch: 1| Step: 0
Training loss: 5.652422036430904
Validation loss: 5.877880012778482

Epoch: 6| Step: 1
Training loss: 5.853984173773201
Validation loss: 5.87650644995268

Epoch: 6| Step: 2
Training loss: 5.4744083450648455
Validation loss: 5.875251304716679

Epoch: 6| Step: 3
Training loss: 5.477906675715785
Validation loss: 5.873934926555026

Epoch: 6| Step: 4
Training loss: 6.813380753164882
Validation loss: 5.872677716061219

Epoch: 6| Step: 5
Training loss: 5.504528435545546
Validation loss: 5.8714396463050385

Epoch: 6| Step: 6
Training loss: 6.430064527505214
Validation loss: 5.870127882942691

Epoch: 6| Step: 7
Training loss: 5.4956856191747985
Validation loss: 5.868855313408026

Epoch: 6| Step: 8
Training loss: 6.635712222269539
Validation loss: 5.867543920399451

Epoch: 6| Step: 9
Training loss: 6.016948920873955
Validation loss: 5.866167314186338

Epoch: 6| Step: 10
Training loss: 6.7813920388530216
Validation loss: 5.864815833280767

Epoch: 6| Step: 11
Training loss: 5.991199078660839
Validation loss: 5.86336143687881

Epoch: 6| Step: 12
Training loss: 5.627205310428338
Validation loss: 5.861831516308357

Epoch: 6| Step: 13
Training loss: 5.7857862666528455
Validation loss: 5.860263821475247

Epoch: 2| Step: 0
Training loss: 6.370574611934976
Validation loss: 5.85869266860417

Epoch: 6| Step: 1
Training loss: 5.960918941443915
Validation loss: 5.857032056529153

Epoch: 6| Step: 2
Training loss: 5.3654156776793265
Validation loss: 5.855251560165858

Epoch: 6| Step: 3
Training loss: 5.936225834707145
Validation loss: 5.853429818078673

Epoch: 6| Step: 4
Training loss: 5.616411391587662
Validation loss: 5.85145069621578

Epoch: 6| Step: 5
Training loss: 5.59043675335494
Validation loss: 5.849458622674872

Epoch: 6| Step: 6
Training loss: 5.808801930743161
Validation loss: 5.8472825251369525

Epoch: 6| Step: 7
Training loss: 6.501880960473663
Validation loss: 5.844938432746129

Epoch: 6| Step: 8
Training loss: 6.251507081480026
Validation loss: 5.842557761685266

Epoch: 6| Step: 9
Training loss: 5.479661616994938
Validation loss: 5.839953680290229

Epoch: 6| Step: 10
Training loss: 6.772814588932336
Validation loss: 5.837121668882676

Epoch: 6| Step: 11
Training loss: 6.922499101114542
Validation loss: 5.834178164021762

Epoch: 6| Step: 12
Training loss: 5.703160450446328
Validation loss: 5.830945925128693

Epoch: 6| Step: 13
Training loss: 4.817170292133452
Validation loss: 5.8277250669164555

Epoch: 3| Step: 0
Training loss: 6.265877050338679
Validation loss: 5.82417936970569

Epoch: 6| Step: 1
Training loss: 5.28207625748093
Validation loss: 5.820489321760027

Epoch: 6| Step: 2
Training loss: 6.824103596266554
Validation loss: 5.816624972276899

Epoch: 6| Step: 3
Training loss: 5.812284404078699
Validation loss: 5.812629206051969

Epoch: 6| Step: 4
Training loss: 5.926290431115048
Validation loss: 5.808334088245637

Epoch: 6| Step: 5
Training loss: 6.232946705514902
Validation loss: 5.80372422013701

Epoch: 6| Step: 6
Training loss: 6.320572629651464
Validation loss: 5.798937818672408

Epoch: 6| Step: 7
Training loss: 5.192393557064067
Validation loss: 5.793964927113338

Epoch: 6| Step: 8
Training loss: 5.296299185723675
Validation loss: 5.788522877942133

Epoch: 6| Step: 9
Training loss: 5.169345202419485
Validation loss: 5.783178389321468

Epoch: 6| Step: 10
Training loss: 5.614520165177133
Validation loss: 5.777658945271728

Epoch: 6| Step: 11
Training loss: 6.350702994774045
Validation loss: 5.77171520926918

Epoch: 6| Step: 12
Training loss: 5.686440840810283
Validation loss: 5.765500778059245

Epoch: 6| Step: 13
Training loss: 6.467203001347996
Validation loss: 5.759066413702671

Epoch: 4| Step: 0
Training loss: 5.333245554837444
Validation loss: 5.752277033979058

Epoch: 6| Step: 1
Training loss: 5.453814356387238
Validation loss: 5.745290624462592

Epoch: 6| Step: 2
Training loss: 6.207966258144117
Validation loss: 5.738346204223439

Epoch: 6| Step: 3
Training loss: 6.1888167396295355
Validation loss: 5.7305689904569155

Epoch: 6| Step: 4
Training loss: 5.125505375949451
Validation loss: 5.723006090878046

Epoch: 6| Step: 5
Training loss: 5.765611105801348
Validation loss: 5.715144120182196

Epoch: 6| Step: 6
Training loss: 6.108842675318059
Validation loss: 5.707073053985397

Epoch: 6| Step: 7
Training loss: 6.401750873441223
Validation loss: 5.698530183872892

Epoch: 6| Step: 8
Training loss: 5.046563200870555
Validation loss: 5.690341756532027

Epoch: 6| Step: 9
Training loss: 5.962789545286413
Validation loss: 5.681112510324023

Epoch: 6| Step: 10
Training loss: 5.996953826751988
Validation loss: 5.67232691678279

Epoch: 6| Step: 11
Training loss: 5.443141247143283
Validation loss: 5.663006170581238

Epoch: 6| Step: 12
Training loss: 6.114984537075451
Validation loss: 5.653707870876332

Epoch: 6| Step: 13
Training loss: 6.066146854865527
Validation loss: 5.644256409110403

Epoch: 5| Step: 0
Training loss: 4.769400080096388
Validation loss: 5.634633581596643

Epoch: 6| Step: 1
Training loss: 6.293077256008991
Validation loss: 5.624723554811756

Epoch: 6| Step: 2
Training loss: 6.692847849854992
Validation loss: 5.614815824527774

Epoch: 6| Step: 3
Training loss: 5.341341959605597
Validation loss: 5.604752700209472

Epoch: 6| Step: 4
Training loss: 4.630319783514679
Validation loss: 5.594890314867336

Epoch: 6| Step: 5
Training loss: 6.859398635441199
Validation loss: 5.58502983775147

Epoch: 6| Step: 6
Training loss: 4.78453938147608
Validation loss: 5.5750025853263665

Epoch: 6| Step: 7
Training loss: 5.6334053817445415
Validation loss: 5.565155195669571

Epoch: 6| Step: 8
Training loss: 5.984796016215832
Validation loss: 5.554909116434739

Epoch: 6| Step: 9
Training loss: 5.686460295163993
Validation loss: 5.545301473876562

Epoch: 6| Step: 10
Training loss: 5.278677229057884
Validation loss: 5.535453104634561

Epoch: 6| Step: 11
Training loss: 5.664370950652999
Validation loss: 5.525890045051419

Epoch: 6| Step: 12
Training loss: 5.61309198260857
Validation loss: 5.51645966032938

Epoch: 6| Step: 13
Training loss: 5.8921825666869765
Validation loss: 5.5067860036824

Epoch: 6| Step: 0
Training loss: 6.920151747875407
Validation loss: 5.497875670347291

Epoch: 6| Step: 1
Training loss: 5.189493370833308
Validation loss: 5.488526196064928

Epoch: 6| Step: 2
Training loss: 5.840157286733728
Validation loss: 5.479898507832812

Epoch: 6| Step: 3
Training loss: 5.925483831939644
Validation loss: 5.471215816626621

Epoch: 6| Step: 4
Training loss: 5.599740342523618
Validation loss: 5.462606296043393

Epoch: 6| Step: 5
Training loss: 6.061930521537608
Validation loss: 5.454380215203444

Epoch: 6| Step: 6
Training loss: 5.346378505358426
Validation loss: 5.446060370120099

Epoch: 6| Step: 7
Training loss: 4.755027118529317
Validation loss: 5.437947748099422

Epoch: 6| Step: 8
Training loss: 5.195448519424782
Validation loss: 5.429870543836481

Epoch: 6| Step: 9
Training loss: 4.601951284774906
Validation loss: 5.42241830879468

Epoch: 6| Step: 10
Training loss: 4.920054071640991
Validation loss: 5.415102728012798

Epoch: 6| Step: 11
Training loss: 5.404389518823287
Validation loss: 5.407889262788653

Epoch: 6| Step: 12
Training loss: 5.977518561193604
Validation loss: 5.4011370344825345

Epoch: 6| Step: 13
Training loss: 5.763453790668228
Validation loss: 5.394659034860002

Epoch: 7| Step: 0
Training loss: 5.345974286372564
Validation loss: 5.387291656265584

Epoch: 6| Step: 1
Training loss: 5.799527694939908
Validation loss: 5.380653749426727

Epoch: 6| Step: 2
Training loss: 5.131100628963613
Validation loss: 5.373599764574015

Epoch: 6| Step: 3
Training loss: 6.094558114485401
Validation loss: 5.366688889799052

Epoch: 6| Step: 4
Training loss: 5.371265622250088
Validation loss: 5.359438644639257

Epoch: 6| Step: 5
Training loss: 4.954215811102552
Validation loss: 5.352457280779167

Epoch: 6| Step: 6
Training loss: 6.07317301589186
Validation loss: 5.345731371618071

Epoch: 6| Step: 7
Training loss: 5.7738719152151745
Validation loss: 5.3391825171915555

Epoch: 6| Step: 8
Training loss: 5.179218714056891
Validation loss: 5.332032710670206

Epoch: 6| Step: 9
Training loss: 5.034417523631318
Validation loss: 5.325255515306663

Epoch: 6| Step: 10
Training loss: 5.064424690493355
Validation loss: 5.318537045678451

Epoch: 6| Step: 11
Training loss: 6.503995107782642
Validation loss: 5.312298221122071

Epoch: 6| Step: 12
Training loss: 4.463509000512517
Validation loss: 5.304946585963667

Epoch: 6| Step: 13
Training loss: 5.378212611866279
Validation loss: 5.298421058340539

Epoch: 8| Step: 0
Training loss: 5.246798674600266
Validation loss: 5.292088148898127

Epoch: 6| Step: 1
Training loss: 5.6084716409498645
Validation loss: 5.285835758124276

Epoch: 6| Step: 2
Training loss: 5.4174100316863605
Validation loss: 5.2788913433215825

Epoch: 6| Step: 3
Training loss: 5.450386299651584
Validation loss: 5.27227601623604

Epoch: 6| Step: 4
Training loss: 6.085412841433488
Validation loss: 5.265527348881637

Epoch: 6| Step: 5
Training loss: 5.464460510820478
Validation loss: 5.258282773137034

Epoch: 6| Step: 6
Training loss: 4.9448340306524186
Validation loss: 5.251012432024828

Epoch: 6| Step: 7
Training loss: 5.7709747554191875
Validation loss: 5.244258253695119

Epoch: 6| Step: 8
Training loss: 5.7955613614334744
Validation loss: 5.237766029077869

Epoch: 6| Step: 9
Training loss: 4.099370228851422
Validation loss: 5.230764451427492

Epoch: 6| Step: 10
Training loss: 4.889151354208158
Validation loss: 5.223742291999431

Epoch: 6| Step: 11
Training loss: 6.109195482197085
Validation loss: 5.2168368794192626

Epoch: 6| Step: 12
Training loss: 5.284732550690169
Validation loss: 5.209975428800918

Epoch: 6| Step: 13
Training loss: 4.670534075435558
Validation loss: 5.202466768436351

Epoch: 9| Step: 0
Training loss: 4.604193202614011
Validation loss: 5.196034745037308

Epoch: 6| Step: 1
Training loss: 5.863334599607388
Validation loss: 5.1894216999542495

Epoch: 6| Step: 2
Training loss: 5.726596140014597
Validation loss: 5.182632215291321

Epoch: 6| Step: 3
Training loss: 5.050633592800086
Validation loss: 5.1749175343108735

Epoch: 6| Step: 4
Training loss: 5.8219750404465005
Validation loss: 5.167514157262762

Epoch: 6| Step: 5
Training loss: 5.447028919875043
Validation loss: 5.1601782429390335

Epoch: 6| Step: 6
Training loss: 4.822067262842559
Validation loss: 5.153269883357813

Epoch: 6| Step: 7
Training loss: 5.713681502414635
Validation loss: 5.147095076382547

Epoch: 6| Step: 8
Training loss: 5.432896386267724
Validation loss: 5.139301535503356

Epoch: 6| Step: 9
Training loss: 4.337395500221509
Validation loss: 5.132440360952689

Epoch: 6| Step: 10
Training loss: 5.733564023248664
Validation loss: 5.1255707771848344

Epoch: 6| Step: 11
Training loss: 4.6391381344615334
Validation loss: 5.119229673610266

Epoch: 6| Step: 12
Training loss: 6.070151308489681
Validation loss: 5.113132724299944

Epoch: 6| Step: 13
Training loss: 4.104521347185559
Validation loss: 5.107002788633819

Epoch: 10| Step: 0
Training loss: 5.281710452260108
Validation loss: 5.102052533622833

Epoch: 6| Step: 1
Training loss: 4.920347527736346
Validation loss: 5.0966922866812725

Epoch: 6| Step: 2
Training loss: 4.973998171129185
Validation loss: 5.091145229746075

Epoch: 6| Step: 3
Training loss: 4.975732467635045
Validation loss: 5.085352522671972

Epoch: 6| Step: 4
Training loss: 5.260529268274538
Validation loss: 5.078428883385523

Epoch: 6| Step: 5
Training loss: 5.316106492111838
Validation loss: 5.072434524507122

Epoch: 6| Step: 6
Training loss: 4.774474285804726
Validation loss: 5.065810388855206

Epoch: 6| Step: 7
Training loss: 5.238001054272103
Validation loss: 5.058814508636197

Epoch: 6| Step: 8
Training loss: 5.737055263860192
Validation loss: 5.05273921943219

Epoch: 6| Step: 9
Training loss: 4.970500517727417
Validation loss: 5.046609027101695

Epoch: 6| Step: 10
Training loss: 4.637033633408151
Validation loss: 5.0400335435911625

Epoch: 6| Step: 11
Training loss: 5.148370444247497
Validation loss: 5.0344467274792954

Epoch: 6| Step: 12
Training loss: 5.706085690726359
Validation loss: 5.028211382907642

Epoch: 6| Step: 13
Training loss: 5.543966212996757
Validation loss: 5.021687678966162

Epoch: 11| Step: 0
Training loss: 5.0363315486104865
Validation loss: 5.015815105380817

Epoch: 6| Step: 1
Training loss: 5.5605223494036755
Validation loss: 5.010656666972231

Epoch: 6| Step: 2
Training loss: 4.867850318218613
Validation loss: 5.004041278336482

Epoch: 6| Step: 3
Training loss: 4.569431422149644
Validation loss: 4.99853863023053

Epoch: 6| Step: 4
Training loss: 4.863315762929746
Validation loss: 4.991902374578431

Epoch: 6| Step: 5
Training loss: 5.6485087494425725
Validation loss: 4.9865942531740615

Epoch: 6| Step: 6
Training loss: 5.097971284566216
Validation loss: 4.980465399049118

Epoch: 6| Step: 7
Training loss: 5.294082850921572
Validation loss: 4.974956482867869

Epoch: 6| Step: 8
Training loss: 5.0788581201572764
Validation loss: 4.969922261336901

Epoch: 6| Step: 9
Training loss: 4.958052149047133
Validation loss: 4.964171885629143

Epoch: 6| Step: 10
Training loss: 5.150321742997857
Validation loss: 4.957138344940774

Epoch: 6| Step: 11
Training loss: 5.569794062260838
Validation loss: 4.951992896311672

Epoch: 6| Step: 12
Training loss: 4.290980954001943
Validation loss: 4.946033427243639

Epoch: 6| Step: 13
Training loss: 5.294215432055596
Validation loss: 4.942180169858189

Epoch: 12| Step: 0
Training loss: 4.942293954354597
Validation loss: 4.937091247121278

Epoch: 6| Step: 1
Training loss: 4.329476816756955
Validation loss: 4.930416579220596

Epoch: 6| Step: 2
Training loss: 4.5236609738083855
Validation loss: 4.925380366784612

Epoch: 6| Step: 3
Training loss: 5.174294081745332
Validation loss: 4.919398093272962

Epoch: 6| Step: 4
Training loss: 5.561796508194054
Validation loss: 4.914601873039711

Epoch: 6| Step: 5
Training loss: 5.312972642405586
Validation loss: 4.9094069057555325

Epoch: 6| Step: 6
Training loss: 4.1911928206086495
Validation loss: 4.903756562973351

Epoch: 6| Step: 7
Training loss: 5.555029835728164
Validation loss: 4.898448532392215

Epoch: 6| Step: 8
Training loss: 4.7909425713575295
Validation loss: 4.893635173829224

Epoch: 6| Step: 9
Training loss: 5.4460620336904615
Validation loss: 4.8882366682176555

Epoch: 6| Step: 10
Training loss: 4.533667820389982
Validation loss: 4.881938756460412

Epoch: 6| Step: 11
Training loss: 5.132737436427914
Validation loss: 4.876519284336459

Epoch: 6| Step: 12
Training loss: 5.386047719829746
Validation loss: 4.873132168540038

Epoch: 6| Step: 13
Training loss: 5.222597451403305
Validation loss: 4.866326237011202

Epoch: 13| Step: 0
Training loss: 5.125065686805134
Validation loss: 4.860678053442872

Epoch: 6| Step: 1
Training loss: 3.985771144025812
Validation loss: 4.854781323375399

Epoch: 6| Step: 2
Training loss: 4.901444918845918
Validation loss: 4.849778031975481

Epoch: 6| Step: 3
Training loss: 4.717293015443782
Validation loss: 4.844701333093365

Epoch: 6| Step: 4
Training loss: 4.192754836051635
Validation loss: 4.838853227201944

Epoch: 6| Step: 5
Training loss: 5.06059021896239
Validation loss: 4.833850876734056

Epoch: 6| Step: 6
Training loss: 4.8765608416270005
Validation loss: 4.82840745216991

Epoch: 6| Step: 7
Training loss: 4.890903062807051
Validation loss: 4.823565753186887

Epoch: 6| Step: 8
Training loss: 5.810868885510139
Validation loss: 4.818427163873823

Epoch: 6| Step: 9
Training loss: 4.455931732668396
Validation loss: 4.812047994945602

Epoch: 6| Step: 10
Training loss: 5.337051208353349
Validation loss: 4.808034435129862

Epoch: 6| Step: 11
Training loss: 6.139469727223528
Validation loss: 4.80438975830511

Epoch: 6| Step: 12
Training loss: 4.6148640681423805
Validation loss: 4.7972504078510045

Epoch: 6| Step: 13
Training loss: 4.797244377701095
Validation loss: 4.793069794368803

Epoch: 14| Step: 0
Training loss: 5.817464697599161
Validation loss: 4.787393350633407

Epoch: 6| Step: 1
Training loss: 5.32826818905836
Validation loss: 4.781734317359929

Epoch: 6| Step: 2
Training loss: 4.486376378917139
Validation loss: 4.774947872842662

Epoch: 6| Step: 3
Training loss: 4.879186153400099
Validation loss: 4.769957227375186

Epoch: 6| Step: 4
Training loss: 4.453384124176883
Validation loss: 4.766745313693623

Epoch: 6| Step: 5
Training loss: 4.4265551921489275
Validation loss: 4.759693360696472

Epoch: 6| Step: 6
Training loss: 4.3995539872656675
Validation loss: 4.754765897002785

Epoch: 6| Step: 7
Training loss: 4.546448363118826
Validation loss: 4.749585484939455

Epoch: 6| Step: 8
Training loss: 5.1956217967729845
Validation loss: 4.744304186683188

Epoch: 6| Step: 9
Training loss: 4.993218973545366
Validation loss: 4.739110980407951

Epoch: 6| Step: 10
Training loss: 5.2384886106771615
Validation loss: 4.734536532257703

Epoch: 6| Step: 11
Training loss: 5.279035115076979
Validation loss: 4.729430282348315

Epoch: 6| Step: 12
Training loss: 2.9890529857749293
Validation loss: 4.724070229794545

Epoch: 6| Step: 13
Training loss: 5.641036000164453
Validation loss: 4.7196338827846045

Epoch: 15| Step: 0
Training loss: 4.774356035678521
Validation loss: 4.71453234411366

Epoch: 6| Step: 1
Training loss: 4.048481861550177
Validation loss: 4.709780068496789

Epoch: 6| Step: 2
Training loss: 5.1039921114391245
Validation loss: 4.705413194134495

Epoch: 6| Step: 3
Training loss: 4.635601368628252
Validation loss: 4.700415082958924

Epoch: 6| Step: 4
Training loss: 4.640273983199716
Validation loss: 4.695957133238846

Epoch: 6| Step: 5
Training loss: 5.15694316481923
Validation loss: 4.690378381937112

Epoch: 6| Step: 6
Training loss: 4.165689175705954
Validation loss: 4.684540590053198

Epoch: 6| Step: 7
Training loss: 5.20367575356753
Validation loss: 4.680876498565215

Epoch: 6| Step: 8
Training loss: 4.798286354618487
Validation loss: 4.674387312671113

Epoch: 6| Step: 9
Training loss: 4.158457693152858
Validation loss: 4.670307164270512

Epoch: 6| Step: 10
Training loss: 4.998093050661063
Validation loss: 4.665177187047003

Epoch: 6| Step: 11
Training loss: 5.537959453044456
Validation loss: 4.660109300955135

Epoch: 6| Step: 12
Training loss: 4.909869760001854
Validation loss: 4.654338982151903

Epoch: 6| Step: 13
Training loss: 4.946476755601018
Validation loss: 4.649431805095058

Epoch: 16| Step: 0
Training loss: 5.315358189654407
Validation loss: 4.644328205706413

Epoch: 6| Step: 1
Training loss: 4.3621482641741665
Validation loss: 4.638613246614145

Epoch: 6| Step: 2
Training loss: 4.756008564138442
Validation loss: 4.634554024769183

Epoch: 6| Step: 3
Training loss: 5.393577054854716
Validation loss: 4.629786034096708

Epoch: 6| Step: 4
Training loss: 4.855159587024768
Validation loss: 4.62610094180918

Epoch: 6| Step: 5
Training loss: 4.258513954547316
Validation loss: 4.61884322496072

Epoch: 6| Step: 6
Training loss: 5.235344002833331
Validation loss: 4.614119489907557

Epoch: 6| Step: 7
Training loss: 4.407752680381041
Validation loss: 4.609293619073255

Epoch: 6| Step: 8
Training loss: 4.741937721876395
Validation loss: 4.604470854271895

Epoch: 6| Step: 9
Training loss: 5.301721746659656
Validation loss: 4.59902827323821

Epoch: 6| Step: 10
Training loss: 5.007251821187072
Validation loss: 4.5943606223829905

Epoch: 6| Step: 11
Training loss: 4.246899090629106
Validation loss: 4.590258043137433

Epoch: 6| Step: 12
Training loss: 3.731501539176614
Validation loss: 4.585027774517281

Epoch: 6| Step: 13
Training loss: 4.425106310240873
Validation loss: 4.579461120820275

Epoch: 17| Step: 0
Training loss: 4.989331307414011
Validation loss: 4.575797990088041

Epoch: 6| Step: 1
Training loss: 5.37867256493561
Validation loss: 4.571472559799568

Epoch: 6| Step: 2
Training loss: 5.090741913391383
Validation loss: 4.566399097029123

Epoch: 6| Step: 3
Training loss: 4.72512164892799
Validation loss: 4.561030774035627

Epoch: 6| Step: 4
Training loss: 3.964625701170089
Validation loss: 4.555224989447625

Epoch: 6| Step: 5
Training loss: 4.9892366908745025
Validation loss: 4.552707021252777

Epoch: 6| Step: 6
Training loss: 4.264420223921583
Validation loss: 4.548363685511296

Epoch: 6| Step: 7
Training loss: 4.173555757081808
Validation loss: 4.54156295704619

Epoch: 6| Step: 8
Training loss: 3.9808785449399218
Validation loss: 4.536891783698008

Epoch: 6| Step: 9
Training loss: 5.239771734026878
Validation loss: 4.533224513112872

Epoch: 6| Step: 10
Training loss: 4.2100333125955265
Validation loss: 4.5277294118647395

Epoch: 6| Step: 11
Training loss: 5.281697090681635
Validation loss: 4.523752450821989

Epoch: 6| Step: 12
Training loss: 4.7182030771364225
Validation loss: 4.51882838545718

Epoch: 6| Step: 13
Training loss: 4.04944637894517
Validation loss: 4.513669163499384

Epoch: 18| Step: 0
Training loss: 4.900082350058366
Validation loss: 4.509342526754899

Epoch: 6| Step: 1
Training loss: 3.60364768347114
Validation loss: 4.505100820798384

Epoch: 6| Step: 2
Training loss: 4.685007068217512
Validation loss: 4.500995949628728

Epoch: 6| Step: 3
Training loss: 4.869143562912772
Validation loss: 4.496609611535729

Epoch: 6| Step: 4
Training loss: 5.111533359463881
Validation loss: 4.491194622499267

Epoch: 6| Step: 5
Training loss: 2.5515568300407283
Validation loss: 4.487581743577913

Epoch: 6| Step: 6
Training loss: 4.44827531117607
Validation loss: 4.484356870182618

Epoch: 6| Step: 7
Training loss: 5.543120497063969
Validation loss: 4.48004448147671

Epoch: 6| Step: 8
Training loss: 4.560002309564374
Validation loss: 4.479092560384274

Epoch: 6| Step: 9
Training loss: 4.634242951459742
Validation loss: 4.4763823024127785

Epoch: 6| Step: 10
Training loss: 4.2994998197408
Validation loss: 4.473925032693419

Epoch: 6| Step: 11
Training loss: 5.206157911569271
Validation loss: 4.4666029923203885

Epoch: 6| Step: 12
Training loss: 4.018495713608884
Validation loss: 4.460386528377756

Epoch: 6| Step: 13
Training loss: 5.292136984922773
Validation loss: 4.455790260857762

Epoch: 19| Step: 0
Training loss: 5.073229310769269
Validation loss: 4.451412563224651

Epoch: 6| Step: 1
Training loss: 4.447689768284468
Validation loss: 4.446899756413826

Epoch: 6| Step: 2
Training loss: 4.907381741172054
Validation loss: 4.443058901957094

Epoch: 6| Step: 3
Training loss: 4.4219125267566195
Validation loss: 4.43841169062993

Epoch: 6| Step: 4
Training loss: 4.650818799849463
Validation loss: 4.432469556789631

Epoch: 6| Step: 5
Training loss: 4.549426434594702
Validation loss: 4.426576269693679

Epoch: 6| Step: 6
Training loss: 4.796164792447044
Validation loss: 4.421214545254008

Epoch: 6| Step: 7
Training loss: 4.132439811069758
Validation loss: 4.4163920958961524

Epoch: 6| Step: 8
Training loss: 4.2640181089378135
Validation loss: 4.411435766361288

Epoch: 6| Step: 9
Training loss: 4.44347613170777
Validation loss: 4.406646097474755

Epoch: 6| Step: 10
Training loss: 5.212789638165689
Validation loss: 4.402019607268034

Epoch: 6| Step: 11
Training loss: 3.9631052800415687
Validation loss: 4.3969355763607485

Epoch: 6| Step: 12
Training loss: 4.3790338720530455
Validation loss: 4.392665094939709

Epoch: 6| Step: 13
Training loss: 4.2863496354861015
Validation loss: 4.389392901639424

Epoch: 20| Step: 0
Training loss: 4.384047390368413
Validation loss: 4.384480186862807

Epoch: 6| Step: 1
Training loss: 4.713308266047428
Validation loss: 4.380106479883334

Epoch: 6| Step: 2
Training loss: 3.748225746041203
Validation loss: 4.37491809223341

Epoch: 6| Step: 3
Training loss: 5.5514230914103235
Validation loss: 4.37145405529512

Epoch: 6| Step: 4
Training loss: 5.433245167085165
Validation loss: 4.36708357157872

Epoch: 6| Step: 5
Training loss: 3.1960973545185616
Validation loss: 4.362061706065702

Epoch: 6| Step: 6
Training loss: 4.147160507757038
Validation loss: 4.358167364827353

Epoch: 6| Step: 7
Training loss: 4.445634290582781
Validation loss: 4.353974528233357

Epoch: 6| Step: 8
Training loss: 4.605901100889149
Validation loss: 4.349392818592217

Epoch: 6| Step: 9
Training loss: 3.905982656867164
Validation loss: 4.3442242041067445

Epoch: 6| Step: 10
Training loss: 5.046031775170009
Validation loss: 4.340510013046876

Epoch: 6| Step: 11
Training loss: 3.815259091439853
Validation loss: 4.336185079385325

Epoch: 6| Step: 12
Training loss: 4.315361511009608
Validation loss: 4.331407534774326

Epoch: 6| Step: 13
Training loss: 4.866120688412816
Validation loss: 4.325719906495602

Epoch: 21| Step: 0
Training loss: 4.324205296882303
Validation loss: 4.32243768573924

Epoch: 6| Step: 1
Training loss: 5.007405709394493
Validation loss: 4.317543581897427

Epoch: 6| Step: 2
Training loss: 3.83303704706208
Validation loss: 4.313148210248677

Epoch: 6| Step: 3
Training loss: 4.550625332629434
Validation loss: 4.308778234908884

Epoch: 6| Step: 4
Training loss: 3.685711701815725
Validation loss: 4.304542645222815

Epoch: 6| Step: 5
Training loss: 4.735480553995603
Validation loss: 4.300214175131981

Epoch: 6| Step: 6
Training loss: 4.558778891444407
Validation loss: 4.295979058463867

Epoch: 6| Step: 7
Training loss: 4.510818616240631
Validation loss: 4.291262536634783

Epoch: 6| Step: 8
Training loss: 4.184605295397821
Validation loss: 4.288340579008368

Epoch: 6| Step: 9
Training loss: 4.188596439580566
Validation loss: 4.283524625986822

Epoch: 6| Step: 10
Training loss: 4.587194631116085
Validation loss: 4.278607186227841

Epoch: 6| Step: 11
Training loss: 4.374639441755323
Validation loss: 4.274536772498957

Epoch: 6| Step: 12
Training loss: 4.839370421139308
Validation loss: 4.269644477182811

Epoch: 6| Step: 13
Training loss: 4.3714921239655204
Validation loss: 4.2656779489735905

Epoch: 22| Step: 0
Training loss: 4.279925733260632
Validation loss: 4.2614223285062565

Epoch: 6| Step: 1
Training loss: 3.636550653590285
Validation loss: 4.257243173782127

Epoch: 6| Step: 2
Training loss: 4.964595377282205
Validation loss: 4.252767017405429

Epoch: 6| Step: 3
Training loss: 4.569451249313055
Validation loss: 4.2487212108457095

Epoch: 6| Step: 4
Training loss: 3.8354080363101755
Validation loss: 4.244665275829533

Epoch: 6| Step: 5
Training loss: 3.7918786349451272
Validation loss: 4.240469475192081

Epoch: 6| Step: 6
Training loss: 4.784274073656863
Validation loss: 4.235601962955986

Epoch: 6| Step: 7
Training loss: 4.350933693838451
Validation loss: 4.231284502302901

Epoch: 6| Step: 8
Training loss: 3.8618718151864067
Validation loss: 4.226742311085558

Epoch: 6| Step: 9
Training loss: 4.641272091945238
Validation loss: 4.222616839511684

Epoch: 6| Step: 10
Training loss: 5.039884373080255
Validation loss: 4.2186791684833125

Epoch: 6| Step: 11
Training loss: 4.467157466930239
Validation loss: 4.213975498167459

Epoch: 6| Step: 12
Training loss: 4.247340323784969
Validation loss: 4.2096431443811815

Epoch: 6| Step: 13
Training loss: 4.332414725334466
Validation loss: 4.205247080979304

Epoch: 23| Step: 0
Training loss: 4.614049784497167
Validation loss: 4.200569557747702

Epoch: 6| Step: 1
Training loss: 4.3017397443931
Validation loss: 4.196728098730009

Epoch: 6| Step: 2
Training loss: 4.364781243959104
Validation loss: 4.191930979187182

Epoch: 6| Step: 3
Training loss: 4.252888315133151
Validation loss: 4.187652547154856

Epoch: 6| Step: 4
Training loss: 4.885753801611471
Validation loss: 4.182884633493577

Epoch: 6| Step: 5
Training loss: 4.53049352184877
Validation loss: 4.178019576453373

Epoch: 6| Step: 6
Training loss: 3.8823824055211507
Validation loss: 4.173812149771769

Epoch: 6| Step: 7
Training loss: 4.087128620600057
Validation loss: 4.169932604976193

Epoch: 6| Step: 8
Training loss: 4.013732701789697
Validation loss: 4.165997769388599

Epoch: 6| Step: 9
Training loss: 4.126834808112298
Validation loss: 4.162624986545787

Epoch: 6| Step: 10
Training loss: 3.104018308093949
Validation loss: 4.156587457939711

Epoch: 6| Step: 11
Training loss: 4.289983820673526
Validation loss: 4.152773615063495

Epoch: 6| Step: 12
Training loss: 4.588981385077509
Validation loss: 4.148559223695297

Epoch: 6| Step: 13
Training loss: 4.907245316350981
Validation loss: 4.144314850464806

Epoch: 24| Step: 0
Training loss: 3.794378268209529
Validation loss: 4.139954729830899

Epoch: 6| Step: 1
Training loss: 4.326287826465303
Validation loss: 4.135947525709774

Epoch: 6| Step: 2
Training loss: 3.813476687540011
Validation loss: 4.130967457276441

Epoch: 6| Step: 3
Training loss: 4.1967934493310075
Validation loss: 4.127626488401623

Epoch: 6| Step: 4
Training loss: 4.428842830691751
Validation loss: 4.1232712716376705

Epoch: 6| Step: 5
Training loss: 3.8384298086582347
Validation loss: 4.119326880753758

Epoch: 6| Step: 6
Training loss: 4.518330011332571
Validation loss: 4.114295460090877

Epoch: 6| Step: 7
Training loss: 4.870347762018442
Validation loss: 4.110210473982047

Epoch: 6| Step: 8
Training loss: 4.112641519355125
Validation loss: 4.105826679552366

Epoch: 6| Step: 9
Training loss: 4.342600059608294
Validation loss: 4.101282019334676

Epoch: 6| Step: 10
Training loss: 4.103802866553083
Validation loss: 4.096795189509528

Epoch: 6| Step: 11
Training loss: 4.312273987085847
Validation loss: 4.093302073737288

Epoch: 6| Step: 12
Training loss: 4.493409947460015
Validation loss: 4.088603504790452

Epoch: 6| Step: 13
Training loss: 4.130040181775012
Validation loss: 4.083705178022514

Epoch: 25| Step: 0
Training loss: 4.182200480314632
Validation loss: 4.07953032034112

Epoch: 6| Step: 1
Training loss: 4.453484129227612
Validation loss: 4.074839880202152

Epoch: 6| Step: 2
Training loss: 4.738345253457878
Validation loss: 4.0705699680582805

Epoch: 6| Step: 3
Training loss: 5.100785901720004
Validation loss: 4.065906172658497

Epoch: 6| Step: 4
Training loss: 4.483296015322961
Validation loss: 4.06079229995743

Epoch: 6| Step: 5
Training loss: 3.8419214877159367
Validation loss: 4.05593999727247

Epoch: 6| Step: 6
Training loss: 4.087196287485058
Validation loss: 4.050938867134535

Epoch: 6| Step: 7
Training loss: 3.5318389671484405
Validation loss: 4.046140861936691

Epoch: 6| Step: 8
Training loss: 4.159119956023599
Validation loss: 4.041583240604965

Epoch: 6| Step: 9
Training loss: 3.148507772944044
Validation loss: 4.037030887809708

Epoch: 6| Step: 10
Training loss: 3.780516624265802
Validation loss: 4.033282336918872

Epoch: 6| Step: 11
Training loss: 4.595300114474553
Validation loss: 4.028710326763722

Epoch: 6| Step: 12
Training loss: 3.972381132158753
Validation loss: 4.025700458051762

Epoch: 6| Step: 13
Training loss: 4.113051477808957
Validation loss: 4.020564898818469

Epoch: 26| Step: 0
Training loss: 5.059438274098624
Validation loss: 4.016692894075697

Epoch: 6| Step: 1
Training loss: 3.8174706246695393
Validation loss: 4.012000421022625

Epoch: 6| Step: 2
Training loss: 3.7362507853502382
Validation loss: 4.007643093125361

Epoch: 6| Step: 3
Training loss: 4.197794544093818
Validation loss: 4.003433522175874

Epoch: 6| Step: 4
Training loss: 3.8984274701618222
Validation loss: 3.999609868574629

Epoch: 6| Step: 5
Training loss: 3.177162461259546
Validation loss: 3.9951985469874036

Epoch: 6| Step: 6
Training loss: 3.853661017713016
Validation loss: 3.99078995640785

Epoch: 6| Step: 7
Training loss: 4.540774313144735
Validation loss: 3.986502065917913

Epoch: 6| Step: 8
Training loss: 3.99963579904013
Validation loss: 3.982196187198442

Epoch: 6| Step: 9
Training loss: 3.9356234483865746
Validation loss: 3.9782751526005575

Epoch: 6| Step: 10
Training loss: 5.263303884689993
Validation loss: 3.974325793847976

Epoch: 6| Step: 11
Training loss: 4.4750586308735505
Validation loss: 3.9704592170614403

Epoch: 6| Step: 12
Training loss: 2.98664873197257
Validation loss: 3.9654699673520453

Epoch: 6| Step: 13
Training loss: 4.169854178314657
Validation loss: 3.961484350894241

Epoch: 27| Step: 0
Training loss: 3.8430852547806813
Validation loss: 3.9572962489866814

Epoch: 6| Step: 1
Training loss: 3.4319194925731313
Validation loss: 3.9532738457804117

Epoch: 6| Step: 2
Training loss: 4.149758913322109
Validation loss: 3.9497284502132537

Epoch: 6| Step: 3
Training loss: 3.9029065280974167
Validation loss: 3.945288831180292

Epoch: 6| Step: 4
Training loss: 3.70428551625183
Validation loss: 3.941636975091208

Epoch: 6| Step: 5
Training loss: 4.776071973376558
Validation loss: 3.937520768852561

Epoch: 6| Step: 6
Training loss: 4.054178488943826
Validation loss: 3.9331917783082453

Epoch: 6| Step: 7
Training loss: 3.751150082023673
Validation loss: 3.9290782944148837

Epoch: 6| Step: 8
Training loss: 4.205163851164032
Validation loss: 3.925474847631612

Epoch: 6| Step: 9
Training loss: 4.281225496764962
Validation loss: 3.9215914153858127

Epoch: 6| Step: 10
Training loss: 4.086773001037826
Validation loss: 3.9170980756990996

Epoch: 6| Step: 11
Training loss: 3.7025249011060746
Validation loss: 3.9129554060992904

Epoch: 6| Step: 12
Training loss: 4.112354663263474
Validation loss: 3.909146570107815

Epoch: 6| Step: 13
Training loss: 4.678276651761834
Validation loss: 3.904664066076973

Epoch: 28| Step: 0
Training loss: 4.080052881085143
Validation loss: 3.9004267507989927

Epoch: 6| Step: 1
Training loss: 4.366798997771534
Validation loss: 3.896493838752083

Epoch: 6| Step: 2
Training loss: 4.2209622834451626
Validation loss: 3.8922179815221036

Epoch: 6| Step: 3
Training loss: 3.9205762680919474
Validation loss: 3.888023538284059

Epoch: 6| Step: 4
Training loss: 4.540435110743578
Validation loss: 3.8839026800502614

Epoch: 6| Step: 5
Training loss: 3.928521956095127
Validation loss: 3.8798128818342352

Epoch: 6| Step: 6
Training loss: 4.123662558394881
Validation loss: 3.875765181435533

Epoch: 6| Step: 7
Training loss: 2.842700135659633
Validation loss: 3.8714116206893148

Epoch: 6| Step: 8
Training loss: 4.12880600561257
Validation loss: 3.867312486471923

Epoch: 6| Step: 9
Training loss: 4.414393265745938
Validation loss: 3.863176108466931

Epoch: 6| Step: 10
Training loss: 4.240341431168115
Validation loss: 3.8592851347763273

Epoch: 6| Step: 11
Training loss: 3.8396467932543277
Validation loss: 3.8552522041293553

Epoch: 6| Step: 12
Training loss: 3.5655491144662275
Validation loss: 3.850845755121113

Epoch: 6| Step: 13
Training loss: 3.611099029586014
Validation loss: 3.847002653580641

Epoch: 29| Step: 0
Training loss: 3.716040898717007
Validation loss: 3.8430668707125237

Epoch: 6| Step: 1
Training loss: 3.7419800511719914
Validation loss: 3.8390907540146575

Epoch: 6| Step: 2
Training loss: 3.235674168708865
Validation loss: 3.8352770576713673

Epoch: 6| Step: 3
Training loss: 4.184168159096112
Validation loss: 3.8314403268855837

Epoch: 6| Step: 4
Training loss: 3.744544829756437
Validation loss: 3.82755739324733

Epoch: 6| Step: 5
Training loss: 4.112974729646291
Validation loss: 3.8240417501851915

Epoch: 6| Step: 6
Training loss: 4.414681450313177
Validation loss: 3.820213436202284

Epoch: 6| Step: 7
Training loss: 4.230983826056599
Validation loss: 3.816554201681853

Epoch: 6| Step: 8
Training loss: 3.6697298317401876
Validation loss: 3.8122737379629

Epoch: 6| Step: 9
Training loss: 4.135004107878004
Validation loss: 3.8084516658526284

Epoch: 6| Step: 10
Training loss: 3.855225838504035
Validation loss: 3.8041513889057494

Epoch: 6| Step: 11
Training loss: 3.964422675262102
Validation loss: 3.8002459994380513

Epoch: 6| Step: 12
Training loss: 3.755576501470638
Validation loss: 3.7960929326806765

Epoch: 6| Step: 13
Training loss: 4.393526577864901
Validation loss: 3.792010483856034

Epoch: 30| Step: 0
Training loss: 3.741392811790703
Validation loss: 3.788335377773321

Epoch: 6| Step: 1
Training loss: 4.253471527445557
Validation loss: 3.784132728203256

Epoch: 6| Step: 2
Training loss: 4.058378270792753
Validation loss: 3.7798954452708022

Epoch: 6| Step: 3
Training loss: 3.8969149932399825
Validation loss: 3.7756085307437703

Epoch: 6| Step: 4
Training loss: 3.562589142336613
Validation loss: 3.771900461569758

Epoch: 6| Step: 5
Training loss: 3.575231323227548
Validation loss: 3.7679332870954325

Epoch: 6| Step: 6
Training loss: 3.696247909901363
Validation loss: 3.7640100712210725

Epoch: 6| Step: 7
Training loss: 3.627523924776941
Validation loss: 3.7601968942317767

Epoch: 6| Step: 8
Training loss: 4.020370351328447
Validation loss: 3.7565965277874924

Epoch: 6| Step: 9
Training loss: 4.532622030964631
Validation loss: 3.7528087058127424

Epoch: 6| Step: 10
Training loss: 3.118114056471482
Validation loss: 3.7486382449101163

Epoch: 6| Step: 11
Training loss: 3.5436370454847426
Validation loss: 3.7442998160765515

Epoch: 6| Step: 12
Training loss: 4.277150439767044
Validation loss: 3.7404904482890826

Epoch: 6| Step: 13
Training loss: 4.4081371405534515
Validation loss: 3.736756463232389

Epoch: 31| Step: 0
Training loss: 3.5363698657079694
Validation loss: 3.732862669079493

Epoch: 6| Step: 1
Training loss: 3.4385771017589835
Validation loss: 3.7288346524614275

Epoch: 6| Step: 2
Training loss: 4.143542374002149
Validation loss: 3.7251786302239562

Epoch: 6| Step: 3
Training loss: 3.8611943825235406
Validation loss: 3.7215117983292982

Epoch: 6| Step: 4
Training loss: 4.106694148413451
Validation loss: 3.717536942128058

Epoch: 6| Step: 5
Training loss: 4.1023029930518
Validation loss: 3.713737528996268

Epoch: 6| Step: 6
Training loss: 3.442197329887661
Validation loss: 3.709594483538572

Epoch: 6| Step: 7
Training loss: 3.694629823882558
Validation loss: 3.70585859782622

Epoch: 6| Step: 8
Training loss: 4.786399710887382
Validation loss: 3.702258270172005

Epoch: 6| Step: 9
Training loss: 2.831603887474645
Validation loss: 3.6979638253370437

Epoch: 6| Step: 10
Training loss: 3.6364614885342554
Validation loss: 3.6940612179912846

Epoch: 6| Step: 11
Training loss: 4.344838397112312
Validation loss: 3.6904241315038226

Epoch: 6| Step: 12
Training loss: 2.9388713476390276
Validation loss: 3.6864432636494437

Epoch: 6| Step: 13
Training loss: 4.4274965818920755
Validation loss: 3.682847423061496

Epoch: 32| Step: 0
Training loss: 3.4522692970799
Validation loss: 3.6788877359128134

Epoch: 6| Step: 1
Training loss: 3.4191390295644912
Validation loss: 3.675232973737136

Epoch: 6| Step: 2
Training loss: 3.2906470027235075
Validation loss: 3.6712355469490725

Epoch: 6| Step: 3
Training loss: 3.5251633842967234
Validation loss: 3.6678575763639345

Epoch: 6| Step: 4
Training loss: 3.6715812403270185
Validation loss: 3.66398959978646

Epoch: 6| Step: 5
Training loss: 4.114119079409412
Validation loss: 3.6604492982131056

Epoch: 6| Step: 6
Training loss: 3.582679215691635
Validation loss: 3.6567997315386047

Epoch: 6| Step: 7
Training loss: 4.287398997193148
Validation loss: 3.653365276909373

Epoch: 6| Step: 8
Training loss: 3.6238513310487033
Validation loss: 3.6494518669714817

Epoch: 6| Step: 9
Training loss: 3.728155343507004
Validation loss: 3.6455439788798354

Epoch: 6| Step: 10
Training loss: 4.512343960333412
Validation loss: 3.6419357319705177

Epoch: 6| Step: 11
Training loss: 3.1339218953130996
Validation loss: 3.638257895710007

Epoch: 6| Step: 12
Training loss: 4.558971974455117
Validation loss: 3.6344684067299062

Epoch: 6| Step: 13
Training loss: 3.8240890714734275
Validation loss: 3.630649877300895

Epoch: 33| Step: 0
Training loss: 3.5076556266251564
Validation loss: 3.6265871804539964

Epoch: 6| Step: 1
Training loss: 2.9295450811737638
Validation loss: 3.622945444447205

Epoch: 6| Step: 2
Training loss: 3.8929385005503727
Validation loss: 3.618790405258694

Epoch: 6| Step: 3
Training loss: 3.6972565970736317
Validation loss: 3.615577553690825

Epoch: 6| Step: 4
Training loss: 3.2932781829797984
Validation loss: 3.611618775767712

Epoch: 6| Step: 5
Training loss: 4.365264305336429
Validation loss: 3.6084315840902597

Epoch: 6| Step: 6
Training loss: 4.07244032523949
Validation loss: 3.605006195518048

Epoch: 6| Step: 7
Training loss: 3.8692018753433692
Validation loss: 3.6016982929395187

Epoch: 6| Step: 8
Training loss: 3.730060718850109
Validation loss: 3.5970614007441504

Epoch: 6| Step: 9
Training loss: 3.5650984004967676
Validation loss: 3.593465069518728

Epoch: 6| Step: 10
Training loss: 3.7319561774081986
Validation loss: 3.5894993287166583

Epoch: 6| Step: 11
Training loss: 3.3410859235158004
Validation loss: 3.585627102628777

Epoch: 6| Step: 12
Training loss: 3.7410813132154512
Validation loss: 3.581960274573156

Epoch: 6| Step: 13
Training loss: 4.335797611763697
Validation loss: 3.5781567168183543

Epoch: 34| Step: 0
Training loss: 2.8644639053880563
Validation loss: 3.5743775935218376

Epoch: 6| Step: 1
Training loss: 4.0126913910375706
Validation loss: 3.5705274187506144

Epoch: 6| Step: 2
Training loss: 4.124405557976209
Validation loss: 3.5670558954737337

Epoch: 6| Step: 3
Training loss: 3.7050127457001794
Validation loss: 3.563119421754209

Epoch: 6| Step: 4
Training loss: 3.9673096453571097
Validation loss: 3.559321005715629

Epoch: 6| Step: 5
Training loss: 3.654215841857768
Validation loss: 3.555628881758003

Epoch: 6| Step: 6
Training loss: 3.0978769846676917
Validation loss: 3.5516681745488086

Epoch: 6| Step: 7
Training loss: 3.3554272543636188
Validation loss: 3.547894100372055

Epoch: 6| Step: 8
Training loss: 4.116854862333567
Validation loss: 3.5440144704260668

Epoch: 6| Step: 9
Training loss: 4.406622688277918
Validation loss: 3.5402702140319913

Epoch: 6| Step: 10
Training loss: 3.4351765496472075
Validation loss: 3.5362901418220516

Epoch: 6| Step: 11
Training loss: 2.7194347177066795
Validation loss: 3.5326910763749266

Epoch: 6| Step: 12
Training loss: 4.014464689414233
Validation loss: 3.5296852223261035

Epoch: 6| Step: 13
Training loss: 3.7117749363479176
Validation loss: 3.5257786925543466

Epoch: 35| Step: 0
Training loss: 3.2678518779155357
Validation loss: 3.522221346198881

Epoch: 6| Step: 1
Training loss: 3.0721959362626228
Validation loss: 3.518716201936107

Epoch: 6| Step: 2
Training loss: 3.3254016604935535
Validation loss: 3.515047740874342

Epoch: 6| Step: 3
Training loss: 4.058797234582565
Validation loss: 3.511776095874355

Epoch: 6| Step: 4
Training loss: 3.352532377605846
Validation loss: 3.508051942669122

Epoch: 6| Step: 5
Training loss: 3.4617322435505606
Validation loss: 3.5045228980418397

Epoch: 6| Step: 6
Training loss: 3.3174585620675288
Validation loss: 3.501233337718608

Epoch: 6| Step: 7
Training loss: 4.3276587279865275
Validation loss: 3.498058280024563

Epoch: 6| Step: 8
Training loss: 4.077120251586705
Validation loss: 3.4940844453659774

Epoch: 6| Step: 9
Training loss: 3.720715171814487
Validation loss: 3.491111265240229

Epoch: 6| Step: 10
Training loss: 4.192328558676727
Validation loss: 3.487329299741627

Epoch: 6| Step: 11
Training loss: 3.190615160232899
Validation loss: 3.4836514666871192

Epoch: 6| Step: 12
Training loss: 3.9882737177405
Validation loss: 3.480335008967963

Epoch: 6| Step: 13
Training loss: 3.2281206631331285
Validation loss: 3.476684796757544

Epoch: 36| Step: 0
Training loss: 3.395890888748296
Validation loss: 3.4724800056557497

Epoch: 6| Step: 1
Training loss: 4.222454789655372
Validation loss: 3.469380020800438

Epoch: 6| Step: 2
Training loss: 3.9401928609516235
Validation loss: 3.4653309648331283

Epoch: 6| Step: 3
Training loss: 3.5489842533247002
Validation loss: 3.461512716583414

Epoch: 6| Step: 4
Training loss: 3.4256849286273554
Validation loss: 3.457450194755182

Epoch: 6| Step: 5
Training loss: 3.6384548546392668
Validation loss: 3.4537037843365774

Epoch: 6| Step: 6
Training loss: 4.07087665536111
Validation loss: 3.4500995575550313

Epoch: 6| Step: 7
Training loss: 3.173698915639117
Validation loss: 3.44638392021607

Epoch: 6| Step: 8
Training loss: 3.4847918205529544
Validation loss: 3.442775077384445

Epoch: 6| Step: 9
Training loss: 3.8158045970942442
Validation loss: 3.4389939269699688

Epoch: 6| Step: 10
Training loss: 3.578198028219007
Validation loss: 3.4353137144104355

Epoch: 6| Step: 11
Training loss: 3.296840432514649
Validation loss: 3.431563065125879

Epoch: 6| Step: 12
Training loss: 3.3889307808154188
Validation loss: 3.4278875101195028

Epoch: 6| Step: 13
Training loss: 3.085784676546198
Validation loss: 3.424498343565107

Epoch: 37| Step: 0
Training loss: 3.5267529505058004
Validation loss: 3.4210942973046228

Epoch: 6| Step: 1
Training loss: 3.4805753372603108
Validation loss: 3.4177998935224796

Epoch: 6| Step: 2
Training loss: 3.1487494756645926
Validation loss: 3.41433109533367

Epoch: 6| Step: 3
Training loss: 4.324238598785747
Validation loss: 3.4109847033629346

Epoch: 6| Step: 4
Training loss: 4.042874159144062
Validation loss: 3.407583249913693

Epoch: 6| Step: 5
Training loss: 2.9499601329113925
Validation loss: 3.4039710701102712

Epoch: 6| Step: 6
Training loss: 3.41105145461953
Validation loss: 3.4003469547255305

Epoch: 6| Step: 7
Training loss: 3.2391886250901742
Validation loss: 3.397529638636911

Epoch: 6| Step: 8
Training loss: 3.0176204740151324
Validation loss: 3.3937922157205067

Epoch: 6| Step: 9
Training loss: 3.351610587959943
Validation loss: 3.390469361467255

Epoch: 6| Step: 10
Training loss: 3.3861425629023403
Validation loss: 3.387192859778569

Epoch: 6| Step: 11
Training loss: 3.305489517179135
Validation loss: 3.3838125252839157

Epoch: 6| Step: 12
Training loss: 4.045180507258448
Validation loss: 3.3809330089475917

Epoch: 6| Step: 13
Training loss: 3.9834184283713254
Validation loss: 3.37810587729077

Epoch: 38| Step: 0
Training loss: 2.8324910389151574
Validation loss: 3.3746505838998395

Epoch: 6| Step: 1
Training loss: 3.4138957316784677
Validation loss: 3.3708540329142394

Epoch: 6| Step: 2
Training loss: 3.784158896112238
Validation loss: 3.367941928969985

Epoch: 6| Step: 3
Training loss: 3.9009568630044456
Validation loss: 3.363844744197264

Epoch: 6| Step: 4
Training loss: 3.1412216303038023
Validation loss: 3.3609820285071863

Epoch: 6| Step: 5
Training loss: 3.168255323813881
Validation loss: 3.357516024284535

Epoch: 6| Step: 6
Training loss: 3.1042252264110317
Validation loss: 3.3540121402251586

Epoch: 6| Step: 7
Training loss: 3.395095058453094
Validation loss: 3.351327658178794

Epoch: 6| Step: 8
Training loss: 3.6784834461034124
Validation loss: 3.34772298205531

Epoch: 6| Step: 9
Training loss: 3.821031623667538
Validation loss: 3.343262467538163

Epoch: 6| Step: 10
Training loss: 3.5738905458943764
Validation loss: 3.340184196981845

Epoch: 6| Step: 11
Training loss: 3.514891687843383
Validation loss: 3.3365411740794255

Epoch: 6| Step: 12
Training loss: 3.4493101287177277
Validation loss: 3.333558198178869

Epoch: 6| Step: 13
Training loss: 3.8999720058903646
Validation loss: 3.330181817522027

Epoch: 39| Step: 0
Training loss: 3.6389021173548954
Validation loss: 3.3268367679952084

Epoch: 6| Step: 1
Training loss: 3.0660946049835096
Validation loss: 3.323254084820357

Epoch: 6| Step: 2
Training loss: 3.258597958511053
Validation loss: 3.3197396535941284

Epoch: 6| Step: 3
Training loss: 3.882643145239326
Validation loss: 3.3158349577414103

Epoch: 6| Step: 4
Training loss: 3.5570516584461482
Validation loss: 3.312942523307652

Epoch: 6| Step: 5
Training loss: 2.838051924614249
Validation loss: 3.3099200200063303

Epoch: 6| Step: 6
Training loss: 3.3257108000304916
Validation loss: 3.3072310474677504

Epoch: 6| Step: 7
Training loss: 3.6597820729897763
Validation loss: 3.3037964782255154

Epoch: 6| Step: 8
Training loss: 3.150432702272475
Validation loss: 3.3004628405964826

Epoch: 6| Step: 9
Training loss: 3.930548692988563
Validation loss: 3.296961079659416

Epoch: 6| Step: 10
Training loss: 3.5912636822162027
Validation loss: 3.293745535281085

Epoch: 6| Step: 11
Training loss: 3.1851070622006827
Validation loss: 3.2903164657659207

Epoch: 6| Step: 12
Training loss: 3.5180902272462964
Validation loss: 3.2870480370573794

Epoch: 6| Step: 13
Training loss: 3.4534551540327736
Validation loss: 3.2836644568867794

Epoch: 40| Step: 0
Training loss: 3.6487454074100185
Validation loss: 3.280270263694567

Epoch: 6| Step: 1
Training loss: 2.980009871088871
Validation loss: 3.2772675339782658

Epoch: 6| Step: 2
Training loss: 3.9310061477694576
Validation loss: 3.2740292496039753

Epoch: 6| Step: 3
Training loss: 3.5550177452191773
Validation loss: 3.27099746648647

Epoch: 6| Step: 4
Training loss: 2.9101008672372712
Validation loss: 3.2675320108446577

Epoch: 6| Step: 5
Training loss: 2.9009031928188236
Validation loss: 3.2649664937393896

Epoch: 6| Step: 6
Training loss: 3.3604588379236837
Validation loss: 3.2619978185724743

Epoch: 6| Step: 7
Training loss: 3.516942569943843
Validation loss: 3.258939552661886

Epoch: 6| Step: 8
Training loss: 2.8761229602488667
Validation loss: 3.2556289807966174

Epoch: 6| Step: 9
Training loss: 3.3869378218145503
Validation loss: 3.252645491782155

Epoch: 6| Step: 10
Training loss: 3.346517113108803
Validation loss: 3.249116679731073

Epoch: 6| Step: 11
Training loss: 4.136700537392037
Validation loss: 3.2471850259733706

Epoch: 6| Step: 12
Training loss: 3.4609460421557956
Validation loss: 3.2438215190277244

Epoch: 6| Step: 13
Training loss: 3.309605899640847
Validation loss: 3.2407912714111875

Epoch: 41| Step: 0
Training loss: 3.3493710624954987
Validation loss: 3.236914063482082

Epoch: 6| Step: 1
Training loss: 3.7439045003302067
Validation loss: 3.2346268953528936

Epoch: 6| Step: 2
Training loss: 3.0148486783594564
Validation loss: 3.230836268487528

Epoch: 6| Step: 3
Training loss: 3.8459070867462795
Validation loss: 3.2269727001266797

Epoch: 6| Step: 4
Training loss: 3.2909875161077045
Validation loss: 3.224463555227296

Epoch: 6| Step: 5
Training loss: 3.9678559985949513
Validation loss: 3.220871087593654

Epoch: 6| Step: 6
Training loss: 3.35984280899745
Validation loss: 3.218434352273794

Epoch: 6| Step: 7
Training loss: 3.2190175361925926
Validation loss: 3.2153546223659037

Epoch: 6| Step: 8
Training loss: 3.242246034392544
Validation loss: 3.212303149652684

Epoch: 6| Step: 9
Training loss: 2.495892392724408
Validation loss: 3.2091617299169624

Epoch: 6| Step: 10
Training loss: 3.475477688018168
Validation loss: 3.2064499136485156

Epoch: 6| Step: 11
Training loss: 2.9798148101510287
Validation loss: 3.2030386067966843

Epoch: 6| Step: 12
Training loss: 3.2255812069485446
Validation loss: 3.200269043063079

Epoch: 6| Step: 13
Training loss: 3.537029836298559
Validation loss: 3.197093861913594

Epoch: 42| Step: 0
Training loss: 3.305129867056717
Validation loss: 3.194100645242042

Epoch: 6| Step: 1
Training loss: 3.421495251072664
Validation loss: 3.1907495875978134

Epoch: 6| Step: 2
Training loss: 2.5093356346757627
Validation loss: 3.1877992152975057

Epoch: 6| Step: 3
Training loss: 3.457469158131588
Validation loss: 3.1853018392986194

Epoch: 6| Step: 4
Training loss: 3.519300108166789
Validation loss: 3.1821351873923036

Epoch: 6| Step: 5
Training loss: 3.6392994051351812
Validation loss: 3.1792428020461707

Epoch: 6| Step: 6
Training loss: 3.057179714841424
Validation loss: 3.176476884505321

Epoch: 6| Step: 7
Training loss: 3.219418206344325
Validation loss: 3.173464497398639

Epoch: 6| Step: 8
Training loss: 3.5545343051638865
Validation loss: 3.1702772855173826

Epoch: 6| Step: 9
Training loss: 2.9895572107394397
Validation loss: 3.1672754371804537

Epoch: 6| Step: 10
Training loss: 3.1971747980284015
Validation loss: 3.1642685057840425

Epoch: 6| Step: 11
Training loss: 3.3437451514093057
Validation loss: 3.1620916688488925

Epoch: 6| Step: 12
Training loss: 3.750256466042848
Validation loss: 3.1612893341662276

Epoch: 6| Step: 13
Training loss: 3.2638398908540047
Validation loss: 3.1584141176573004

Epoch: 43| Step: 0
Training loss: 3.650387489966551
Validation loss: 3.1556604294259105

Epoch: 6| Step: 1
Training loss: 3.209366537081101
Validation loss: 3.150313507101108

Epoch: 6| Step: 2
Training loss: 3.048355447123389
Validation loss: 3.147109503344079

Epoch: 6| Step: 3
Training loss: 3.4664034767990937
Validation loss: 3.1444404288814085

Epoch: 6| Step: 4
Training loss: 3.149143338654978
Validation loss: 3.1414039114059755

Epoch: 6| Step: 5
Training loss: 3.757299566652802
Validation loss: 3.1384683799015805

Epoch: 6| Step: 6
Training loss: 3.3909705201343776
Validation loss: 3.135445950562523

Epoch: 6| Step: 7
Training loss: 2.597545558320637
Validation loss: 3.1325770263456842

Epoch: 6| Step: 8
Training loss: 2.6526398303884346
Validation loss: 3.12989144564592

Epoch: 6| Step: 9
Training loss: 3.4178297962826383
Validation loss: 3.127790019378587

Epoch: 6| Step: 10
Training loss: 3.4043328725954636
Validation loss: 3.125098595653282

Epoch: 6| Step: 11
Training loss: 3.065009354146153
Validation loss: 3.123341310898707

Epoch: 6| Step: 12
Training loss: 2.9977806147034176
Validation loss: 3.121038672733486

Epoch: 6| Step: 13
Training loss: 3.792978807272969
Validation loss: 3.1184763526503105

Epoch: 44| Step: 0
Training loss: 3.0660994260807644
Validation loss: 3.115267692236283

Epoch: 6| Step: 1
Training loss: 3.300435679025834
Validation loss: 3.1124318494574448

Epoch: 6| Step: 2
Training loss: 3.7518428089261184
Validation loss: 3.1089619245540177

Epoch: 6| Step: 3
Training loss: 3.771795006182673
Validation loss: 3.1060531354265954

Epoch: 6| Step: 4
Training loss: 2.786445993176287
Validation loss: 3.10333110564084

Epoch: 6| Step: 5
Training loss: 3.618864457555464
Validation loss: 3.0994928021975845

Epoch: 6| Step: 6
Training loss: 2.8140984972950087
Validation loss: 3.096825981072967

Epoch: 6| Step: 7
Training loss: 3.1977646053249975
Validation loss: 3.093722693326

Epoch: 6| Step: 8
Training loss: 3.3030078127309834
Validation loss: 3.0911008622139526

Epoch: 6| Step: 9
Training loss: 2.664514497688525
Validation loss: 3.088657361973394

Epoch: 6| Step: 10
Training loss: 3.7224594976861822
Validation loss: 3.0894495040982304

Epoch: 6| Step: 11
Training loss: 3.2758739208138583
Validation loss: 3.084155145015667

Epoch: 6| Step: 12
Training loss: 3.2102403464016582
Validation loss: 3.0795850953847306

Epoch: 6| Step: 13
Training loss: 2.559260111222486
Validation loss: 3.0773109353582004

Epoch: 45| Step: 0
Training loss: 3.3408382965023113
Validation loss: 3.0750992777028645

Epoch: 6| Step: 1
Training loss: 2.2651192988626083
Validation loss: 3.0742935242661735

Epoch: 6| Step: 2
Training loss: 3.1850426869548563
Validation loss: 3.0749547675923052

Epoch: 6| Step: 3
Training loss: 3.4464506661068994
Validation loss: 3.071252214769686

Epoch: 6| Step: 4
Training loss: 2.7174527811476934
Validation loss: 3.067205382450603

Epoch: 6| Step: 5
Training loss: 3.803800694945475
Validation loss: 3.064527761516071

Epoch: 6| Step: 6
Training loss: 3.684964100055952
Validation loss: 3.062421110006431

Epoch: 6| Step: 7
Training loss: 3.225209541314825
Validation loss: 3.05979457390078

Epoch: 6| Step: 8
Training loss: 3.114850461257505
Validation loss: 3.0575348054989937

Epoch: 6| Step: 9
Training loss: 3.418636792974333
Validation loss: 3.054633931164257

Epoch: 6| Step: 10
Training loss: 3.13294917923869
Validation loss: 3.052077131731592

Epoch: 6| Step: 11
Training loss: 3.5331510304859077
Validation loss: 3.0493329168096186

Epoch: 6| Step: 12
Training loss: 2.5364200868536404
Validation loss: 3.046111697580851

Epoch: 6| Step: 13
Training loss: 3.0394770087056417
Validation loss: 3.0434497588562572

Epoch: 46| Step: 0
Training loss: 3.9290005214241286
Validation loss: 3.0409457950663805

Epoch: 6| Step: 1
Training loss: 2.868410769416063
Validation loss: 3.0381574157395987

Epoch: 6| Step: 2
Training loss: 2.8037021786969163
Validation loss: 3.033952681397719

Epoch: 6| Step: 3
Training loss: 3.1990296024957385
Validation loss: 3.0309605279985012

Epoch: 6| Step: 4
Training loss: 3.4065417243555656
Validation loss: 3.0294709638282904

Epoch: 6| Step: 5
Training loss: 3.3369160630664183
Validation loss: 3.025489196419307

Epoch: 6| Step: 6
Training loss: 2.5860591986563413
Validation loss: 3.022956790215239

Epoch: 6| Step: 7
Training loss: 3.874622818832849
Validation loss: 3.020737710075084

Epoch: 6| Step: 8
Training loss: 2.9505744698013068
Validation loss: 3.017757024472051

Epoch: 6| Step: 9
Training loss: 3.027048561717357
Validation loss: 3.0160307932377046

Epoch: 6| Step: 10
Training loss: 2.3419861323323126
Validation loss: 3.0129281801547054

Epoch: 6| Step: 11
Training loss: 2.7803175145237247
Validation loss: 3.0114687144996606

Epoch: 6| Step: 12
Training loss: 3.6556007265226502
Validation loss: 3.008186825665707

Epoch: 6| Step: 13
Training loss: 3.111142983349013
Validation loss: 3.007505353297635

Epoch: 47| Step: 0
Training loss: 3.481479279725601
Validation loss: 3.005366717329436

Epoch: 6| Step: 1
Training loss: 2.709090601372367
Validation loss: 3.0019807369606157

Epoch: 6| Step: 2
Training loss: 3.0048280648347836
Validation loss: 2.998809538516938

Epoch: 6| Step: 3
Training loss: 3.039195236798375
Validation loss: 2.9972483148186417

Epoch: 6| Step: 4
Training loss: 3.3749875668897147
Validation loss: 2.994491181709714

Epoch: 6| Step: 5
Training loss: 3.792775393742415
Validation loss: 2.991973072466316

Epoch: 6| Step: 6
Training loss: 3.498304228738067
Validation loss: 2.989730769297822

Epoch: 6| Step: 7
Training loss: 3.1951211811420577
Validation loss: 2.986690308833496

Epoch: 6| Step: 8
Training loss: 3.0903069960299923
Validation loss: 2.985073121121487

Epoch: 6| Step: 9
Training loss: 2.157980404231889
Validation loss: 2.982267677636131

Epoch: 6| Step: 10
Training loss: 2.7597417810142995
Validation loss: 2.980693177072535

Epoch: 6| Step: 11
Training loss: 3.2091531738166656
Validation loss: 2.9787737491678494

Epoch: 6| Step: 12
Training loss: 3.0428325735234933
Validation loss: 2.976490063257312

Epoch: 6| Step: 13
Training loss: 3.1740070562542635
Validation loss: 2.9743013111810304

Epoch: 48| Step: 0
Training loss: 3.137073235534584
Validation loss: 2.972284495116282

Epoch: 6| Step: 1
Training loss: 3.378605082766829
Validation loss: 2.970362309107311

Epoch: 6| Step: 2
Training loss: 3.1375361953410508
Validation loss: 2.9674372129538793

Epoch: 6| Step: 3
Training loss: 3.341133734110538
Validation loss: 2.9642867686345844

Epoch: 6| Step: 4
Training loss: 2.984068530259674
Validation loss: 2.9628984974651993

Epoch: 6| Step: 5
Training loss: 3.7249764000061836
Validation loss: 2.958796120206132

Epoch: 6| Step: 6
Training loss: 3.00790952055375
Validation loss: 2.957209915548631

Epoch: 6| Step: 7
Training loss: 2.8890006785486047
Validation loss: 2.9553494561031886

Epoch: 6| Step: 8
Training loss: 2.672913823432233
Validation loss: 2.953062214932431

Epoch: 6| Step: 9
Training loss: 3.291366676148799
Validation loss: 2.950449746003069

Epoch: 6| Step: 10
Training loss: 3.078543697481367
Validation loss: 2.950075462152004

Epoch: 6| Step: 11
Training loss: 2.9475425959155075
Validation loss: 2.9462681981267713

Epoch: 6| Step: 12
Training loss: 2.8934019204842443
Validation loss: 2.944815258952199

Epoch: 6| Step: 13
Training loss: 2.757361529168611
Validation loss: 2.943003915891074

Epoch: 49| Step: 0
Training loss: 2.2355668950388408
Validation loss: 2.941983109403005

Epoch: 6| Step: 1
Training loss: 2.7654013678011773
Validation loss: 2.9391568293315364

Epoch: 6| Step: 2
Training loss: 3.0108307198404822
Validation loss: 2.936058299374529

Epoch: 6| Step: 3
Training loss: 2.8889250834553297
Validation loss: 2.9352664843211915

Epoch: 6| Step: 4
Training loss: 3.0657415556453453
Validation loss: 2.9334645520106832

Epoch: 6| Step: 5
Training loss: 3.5015051194016964
Validation loss: 2.93197049176996

Epoch: 6| Step: 6
Training loss: 2.560274227475066
Validation loss: 2.9292831752246653

Epoch: 6| Step: 7
Training loss: 3.039782284419383
Validation loss: 2.9275294379131394

Epoch: 6| Step: 8
Training loss: 2.8905768313131914
Validation loss: 2.92519847870296

Epoch: 6| Step: 9
Training loss: 3.6755748532731802
Validation loss: 2.9230682737947085

Epoch: 6| Step: 10
Training loss: 3.461914888927969
Validation loss: 2.9211686040322276

Epoch: 6| Step: 11
Training loss: 2.8536706943662518
Validation loss: 2.9188463694791165

Epoch: 6| Step: 12
Training loss: 3.071707760361242
Validation loss: 2.9172935947385596

Epoch: 6| Step: 13
Training loss: 3.581939529692337
Validation loss: 2.9148489919407616

Epoch: 50| Step: 0
Training loss: 3.195369953114673
Validation loss: 2.9133908586111232

Epoch: 6| Step: 1
Training loss: 2.9141798225900737
Validation loss: 2.9109722862274183

Epoch: 6| Step: 2
Training loss: 2.9945982939721216
Validation loss: 2.9086825127471263

Epoch: 6| Step: 3
Training loss: 3.58975143230895
Validation loss: 2.9066996893042236

Epoch: 6| Step: 4
Training loss: 3.002139282411143
Validation loss: 2.9050911401140205

Epoch: 6| Step: 5
Training loss: 2.846110276188123
Validation loss: 2.9025389245024695

Epoch: 6| Step: 6
Training loss: 2.944373023968339
Validation loss: 2.9000230207296847

Epoch: 6| Step: 7
Training loss: 2.9522067463952983
Validation loss: 2.8979752301337203

Epoch: 6| Step: 8
Training loss: 3.273269976788102
Validation loss: 2.8959796831944553

Epoch: 6| Step: 9
Training loss: 2.6514467680563887
Validation loss: 2.8935096300341816

Epoch: 6| Step: 10
Training loss: 3.0577236998874695
Validation loss: 2.890076662584549

Epoch: 6| Step: 11
Training loss: 2.664327390148315
Validation loss: 2.8887998025150914

Epoch: 6| Step: 12
Training loss: 3.4187762717958363
Validation loss: 2.8856176221440766

Epoch: 6| Step: 13
Training loss: 2.9176054579005695
Validation loss: 2.886572889635766

Epoch: 51| Step: 0
Training loss: 3.4412172505919303
Validation loss: 2.883581112448354

Epoch: 6| Step: 1
Training loss: 3.6222186763982704
Validation loss: 2.8840498917717703

Epoch: 6| Step: 2
Training loss: 2.547767061679665
Validation loss: 2.878865035101506

Epoch: 6| Step: 3
Training loss: 2.6037337490092916
Validation loss: 2.875840672303346

Epoch: 6| Step: 4
Training loss: 3.0166063046256024
Validation loss: 2.8751817590507076

Epoch: 6| Step: 5
Training loss: 2.6225554573297436
Validation loss: 2.872871025300132

Epoch: 6| Step: 6
Training loss: 3.1426412458701263
Validation loss: 2.8722003767665467

Epoch: 6| Step: 7
Training loss: 3.0122918401321863
Validation loss: 2.870550859466853

Epoch: 6| Step: 8
Training loss: 2.63692382015036
Validation loss: 2.869724879840602

Epoch: 6| Step: 9
Training loss: 3.7176683920591183
Validation loss: 2.8695302706899475

Epoch: 6| Step: 10
Training loss: 3.1290962837793312
Validation loss: 2.8664305308767357

Epoch: 6| Step: 11
Training loss: 3.091483470770761
Validation loss: 2.8626232770336024

Epoch: 6| Step: 12
Training loss: 2.6166481487161564
Validation loss: 2.8608220092196697

Epoch: 6| Step: 13
Training loss: 2.6704901067553726
Validation loss: 2.858462453841464

Epoch: 52| Step: 0
Training loss: 2.7436582962734635
Validation loss: 2.856158311124858

Epoch: 6| Step: 1
Training loss: 2.8346270431280396
Validation loss: 2.85682095831703

Epoch: 6| Step: 2
Training loss: 3.1997111666981706
Validation loss: 2.85335996230644

Epoch: 6| Step: 3
Training loss: 2.8560177631413475
Validation loss: 2.8492470594386883

Epoch: 6| Step: 4
Training loss: 3.2360785232089198
Validation loss: 2.848249208857191

Epoch: 6| Step: 5
Training loss: 2.724660740303232
Validation loss: 2.8471917504848405

Epoch: 6| Step: 6
Training loss: 3.093264146666865
Validation loss: 2.844612060784757

Epoch: 6| Step: 7
Training loss: 3.272081335460526
Validation loss: 2.843491455174399

Epoch: 6| Step: 8
Training loss: 3.2492758604416054
Validation loss: 2.8427521488498155

Epoch: 6| Step: 9
Training loss: 3.730456734682875
Validation loss: 2.8406083635627097

Epoch: 6| Step: 10
Training loss: 2.436222132703976
Validation loss: 2.841095870033526

Epoch: 6| Step: 11
Training loss: 2.9595605874605115
Validation loss: 2.8408044924120133

Epoch: 6| Step: 12
Training loss: 2.487545174039942
Validation loss: 2.8355931685142757

Epoch: 6| Step: 13
Training loss: 2.7295384821096373
Validation loss: 2.832683367134626

Epoch: 53| Step: 0
Training loss: 2.913754362531004
Validation loss: 2.829923812910059

Epoch: 6| Step: 1
Training loss: 3.308684977204894
Validation loss: 2.8295055272615226

Epoch: 6| Step: 2
Training loss: 3.493562909680323
Validation loss: 2.829184079198574

Epoch: 6| Step: 3
Training loss: 2.9262440701196057
Validation loss: 2.8315301982453294

Epoch: 6| Step: 4
Training loss: 2.757540162555735
Validation loss: 2.829993429906473

Epoch: 6| Step: 5
Training loss: 2.859807883259012
Validation loss: 2.8268589818133623

Epoch: 6| Step: 6
Training loss: 2.9415307493572223
Validation loss: 2.824492550737954

Epoch: 6| Step: 7
Training loss: 2.671081782155479
Validation loss: 2.8208818785539225

Epoch: 6| Step: 8
Training loss: 2.8939219874772872
Validation loss: 2.8189386771267664

Epoch: 6| Step: 9
Training loss: 3.032079524162374
Validation loss: 2.8169915961773397

Epoch: 6| Step: 10
Training loss: 2.764412134461451
Validation loss: 2.81440266430049

Epoch: 6| Step: 11
Training loss: 3.110498426673981
Validation loss: 2.812411328083522

Epoch: 6| Step: 12
Training loss: 2.833303526179283
Validation loss: 2.8102046501057667

Epoch: 6| Step: 13
Training loss: 2.906187159361354
Validation loss: 2.8092880275164815

Epoch: 54| Step: 0
Training loss: 3.07825047580948
Validation loss: 2.8077264046918318

Epoch: 6| Step: 1
Training loss: 2.780619517668423
Validation loss: 2.805677743859133

Epoch: 6| Step: 2
Training loss: 2.8331099777446154
Validation loss: 2.803772163320521

Epoch: 6| Step: 3
Training loss: 2.631174364611229
Validation loss: 2.8026347888085783

Epoch: 6| Step: 4
Training loss: 2.7755961009880945
Validation loss: 2.8004450540835397

Epoch: 6| Step: 5
Training loss: 2.74429075434524
Validation loss: 2.798544600279877

Epoch: 6| Step: 6
Training loss: 3.385122026190806
Validation loss: 2.795693217109797

Epoch: 6| Step: 7
Training loss: 3.5993839054623455
Validation loss: 2.79728591997526

Epoch: 6| Step: 8
Training loss: 2.946773743330961
Validation loss: 2.7966272397117105

Epoch: 6| Step: 9
Training loss: 2.619320492751889
Validation loss: 2.7940530019551124

Epoch: 6| Step: 10
Training loss: 2.5565598652136794
Validation loss: 2.7921277751914224

Epoch: 6| Step: 11
Training loss: 3.3969547939667106
Validation loss: 2.791736307746371

Epoch: 6| Step: 12
Training loss: 2.961566787721453
Validation loss: 2.787221249155323

Epoch: 6| Step: 13
Training loss: 2.583772150322136
Validation loss: 2.785968692338912

Epoch: 55| Step: 0
Training loss: 2.980204919259548
Validation loss: 2.785578042612335

Epoch: 6| Step: 1
Training loss: 3.3363131237954518
Validation loss: 2.784120642692593

Epoch: 6| Step: 2
Training loss: 2.285341643287539
Validation loss: 2.784123911098766

Epoch: 6| Step: 3
Training loss: 2.3970312910587843
Validation loss: 2.783384539843171

Epoch: 6| Step: 4
Training loss: 2.921687645438808
Validation loss: 2.7831076658063028

Epoch: 6| Step: 5
Training loss: 3.408001650563588
Validation loss: 2.7816926982462316

Epoch: 6| Step: 6
Training loss: 2.6432625503812144
Validation loss: 2.7798032676829987

Epoch: 6| Step: 7
Training loss: 3.0815735683816854
Validation loss: 2.777814622210821

Epoch: 6| Step: 8
Training loss: 2.786756999804298
Validation loss: 2.7751574130847225

Epoch: 6| Step: 9
Training loss: 3.0128521598656364
Validation loss: 2.772105782874405

Epoch: 6| Step: 10
Training loss: 2.4611502419205666
Validation loss: 2.7693933363823784

Epoch: 6| Step: 11
Training loss: 2.8471878566580524
Validation loss: 2.767922246551134

Epoch: 6| Step: 12
Training loss: 3.1270650525525543
Validation loss: 2.765137681574123

Epoch: 6| Step: 13
Training loss: 3.2899626816137495
Validation loss: 2.762228710495658

Epoch: 56| Step: 0
Training loss: 2.723154205803036
Validation loss: 2.767867807874627

Epoch: 6| Step: 1
Training loss: 2.7802261010854386
Validation loss: 2.7644074484426953

Epoch: 6| Step: 2
Training loss: 2.515141221436588
Validation loss: 2.7627654009985707

Epoch: 6| Step: 3
Training loss: 3.162269366754293
Validation loss: 2.769260351995712

Epoch: 6| Step: 4
Training loss: 2.617829474669285
Validation loss: 2.773065762389017

Epoch: 6| Step: 5
Training loss: 2.4862807539796994
Validation loss: 2.769331910097947

Epoch: 6| Step: 6
Training loss: 2.8728496968792805
Validation loss: 2.7698823735846387

Epoch: 6| Step: 7
Training loss: 3.2942139792782092
Validation loss: 2.7694661823730256

Epoch: 6| Step: 8
Training loss: 2.8532632850652546
Validation loss: 2.752090179950785

Epoch: 6| Step: 9
Training loss: 2.871744053691434
Validation loss: 2.7515765497187235

Epoch: 6| Step: 10
Training loss: 2.7645007935893866
Validation loss: 2.75042042263934

Epoch: 6| Step: 11
Training loss: 3.167223898062621
Validation loss: 2.749092024404348

Epoch: 6| Step: 12
Training loss: 2.8559167513107733
Validation loss: 2.747378053050187

Epoch: 6| Step: 13
Training loss: 3.3214118125012226
Validation loss: 2.749672169362814

Epoch: 57| Step: 0
Training loss: 2.6158095646758963
Validation loss: 2.7479639029522027

Epoch: 6| Step: 1
Training loss: 3.0419354428896903
Validation loss: 2.7482039048174016

Epoch: 6| Step: 2
Training loss: 2.856475527350881
Validation loss: 2.7504020165874494

Epoch: 6| Step: 3
Training loss: 2.9899578502325066
Validation loss: 2.7515285896379362

Epoch: 6| Step: 4
Training loss: 3.360594346295245
Validation loss: 2.7461153394014124

Epoch: 6| Step: 5
Training loss: 2.8168113723993344
Validation loss: 2.7417821340005677

Epoch: 6| Step: 6
Training loss: 3.064168047606823
Validation loss: 2.737572665825038

Epoch: 6| Step: 7
Training loss: 2.5367672919400848
Validation loss: 2.732979627340469

Epoch: 6| Step: 8
Training loss: 2.886790934113143
Validation loss: 2.7321098318517105

Epoch: 6| Step: 9
Training loss: 2.985485569295664
Validation loss: 2.72930411849283

Epoch: 6| Step: 10
Training loss: 2.7445939419278207
Validation loss: 2.7299984593788804

Epoch: 6| Step: 11
Training loss: 2.665426402950548
Validation loss: 2.728997310207966

Epoch: 6| Step: 12
Training loss: 2.931752039490572
Validation loss: 2.7315302555904473

Epoch: 6| Step: 13
Training loss: 2.742940945920345
Validation loss: 2.7264420447207063

Epoch: 58| Step: 0
Training loss: 3.253954022664766
Validation loss: 2.7260168598947625

Epoch: 6| Step: 1
Training loss: 2.603334115777608
Validation loss: 2.7226124654612454

Epoch: 6| Step: 2
Training loss: 3.1819832127366254
Validation loss: 2.7204156063259086

Epoch: 6| Step: 3
Training loss: 2.5893125147442575
Validation loss: 2.7200793089477253

Epoch: 6| Step: 4
Training loss: 2.7564946556932113
Validation loss: 2.7193239417397512

Epoch: 6| Step: 5
Training loss: 3.325588495476787
Validation loss: 2.716402128909677

Epoch: 6| Step: 6
Training loss: 2.867147086791566
Validation loss: 2.7165994579294144

Epoch: 6| Step: 7
Training loss: 3.077550534314549
Validation loss: 2.715293382327181

Epoch: 6| Step: 8
Training loss: 2.611205777916406
Validation loss: 2.71403650224877

Epoch: 6| Step: 9
Training loss: 2.962195619808835
Validation loss: 2.7135682547078805

Epoch: 6| Step: 10
Training loss: 1.595381854994167
Validation loss: 2.7136308846966113

Epoch: 6| Step: 11
Training loss: 3.347312811702427
Validation loss: 2.7090840448527627

Epoch: 6| Step: 12
Training loss: 2.5295136701248784
Validation loss: 2.7082571801458672

Epoch: 6| Step: 13
Training loss: 2.789330990474269
Validation loss: 2.7066895754162563

Epoch: 59| Step: 0
Training loss: 2.3238878030531507
Validation loss: 2.7069193645803202

Epoch: 6| Step: 1
Training loss: 3.229050238366466
Validation loss: 2.7043074739196955

Epoch: 6| Step: 2
Training loss: 2.903231293833753
Validation loss: 2.7057966873120094

Epoch: 6| Step: 3
Training loss: 3.5399633612595567
Validation loss: 2.701424462531746

Epoch: 6| Step: 4
Training loss: 2.69835970467712
Validation loss: 2.699007429949651

Epoch: 6| Step: 5
Training loss: 2.793512464832458
Validation loss: 2.69948186847881

Epoch: 6| Step: 6
Training loss: 3.143070919643431
Validation loss: 2.699309285435576

Epoch: 6| Step: 7
Training loss: 3.2158685026661815
Validation loss: 2.6990416450750376

Epoch: 6| Step: 8
Training loss: 2.4372257176159122
Validation loss: 2.7005615868922113

Epoch: 6| Step: 9
Training loss: 2.865577349583807
Validation loss: 2.703084647698833

Epoch: 6| Step: 10
Training loss: 2.7396202133268477
Validation loss: 2.7008236476493432

Epoch: 6| Step: 11
Training loss: 2.590297469358847
Validation loss: 2.7007577780521204

Epoch: 6| Step: 12
Training loss: 2.5782839639380204
Validation loss: 2.695324913401744

Epoch: 6| Step: 13
Training loss: 2.482225940094048
Validation loss: 2.693955703752555

Epoch: 60| Step: 0
Training loss: 3.10121425720307
Validation loss: 2.6901759199314146

Epoch: 6| Step: 1
Training loss: 2.595987664579876
Validation loss: 2.6898198428325553

Epoch: 6| Step: 2
Training loss: 3.019839173638814
Validation loss: 2.687117349751713

Epoch: 6| Step: 3
Training loss: 2.873807245043592
Validation loss: 2.6874776144352186

Epoch: 6| Step: 4
Training loss: 2.8055069345304577
Validation loss: 2.6894419846942323

Epoch: 6| Step: 5
Training loss: 3.115778324865578
Validation loss: 2.6951140694667344

Epoch: 6| Step: 6
Training loss: 2.5697907727047578
Validation loss: 2.6914201578298584

Epoch: 6| Step: 7
Training loss: 2.4171758531858227
Validation loss: 2.6941432019797014

Epoch: 6| Step: 8
Training loss: 2.78394050333421
Validation loss: 2.6934671912906385

Epoch: 6| Step: 9
Training loss: 2.722933827593973
Validation loss: 2.6910160927973537

Epoch: 6| Step: 10
Training loss: 2.9857048546882665
Validation loss: 2.683230283389354

Epoch: 6| Step: 11
Training loss: 2.929638834231217
Validation loss: 2.6799455672282746

Epoch: 6| Step: 12
Training loss: 3.0830215777626657
Validation loss: 2.6822154852162625

Epoch: 6| Step: 13
Training loss: 2.4220252205805823
Validation loss: 2.6799147558651972

Epoch: 61| Step: 0
Training loss: 2.925555680139699
Validation loss: 2.679171661759897

Epoch: 6| Step: 1
Training loss: 2.3089998923954664
Validation loss: 2.677806627897265

Epoch: 6| Step: 2
Training loss: 2.6697470238671968
Validation loss: 2.675882319933873

Epoch: 6| Step: 3
Training loss: 2.931346860802208
Validation loss: 2.6759648392338864

Epoch: 6| Step: 4
Training loss: 2.802957155099588
Validation loss: 2.675552603426741

Epoch: 6| Step: 5
Training loss: 2.306214218068825
Validation loss: 2.6722892603679114

Epoch: 6| Step: 6
Training loss: 2.8878457394979944
Validation loss: 2.6726274230288527

Epoch: 6| Step: 7
Training loss: 2.834046292828079
Validation loss: 2.671271451186508

Epoch: 6| Step: 8
Training loss: 2.877452633465391
Validation loss: 2.672029948063872

Epoch: 6| Step: 9
Training loss: 2.6805817026851666
Validation loss: 2.669100802829004

Epoch: 6| Step: 10
Training loss: 3.090575467938368
Validation loss: 2.6677772077144697

Epoch: 6| Step: 11
Training loss: 2.9545552660372354
Validation loss: 2.6664812401040634

Epoch: 6| Step: 12
Training loss: 2.4446956356146785
Validation loss: 2.6659614455012526

Epoch: 6| Step: 13
Training loss: 3.4409564587056325
Validation loss: 2.6632344291124643

Epoch: 62| Step: 0
Training loss: 2.68974432272604
Validation loss: 2.6631906822428904

Epoch: 6| Step: 1
Training loss: 3.013266950933875
Validation loss: 2.6627254169778545

Epoch: 6| Step: 2
Training loss: 2.677370365256534
Validation loss: 2.661402085239282

Epoch: 6| Step: 3
Training loss: 2.7024574116924986
Validation loss: 2.6608927972562504

Epoch: 6| Step: 4
Training loss: 2.7711545332594842
Validation loss: 2.6577806587861024

Epoch: 6| Step: 5
Training loss: 2.52903452805087
Validation loss: 2.6582826204953554

Epoch: 6| Step: 6
Training loss: 2.689012855723198
Validation loss: 2.657034903851593

Epoch: 6| Step: 7
Training loss: 3.242635158289534
Validation loss: 2.65670980325935

Epoch: 6| Step: 8
Training loss: 2.923372914891962
Validation loss: 2.6540785946049774

Epoch: 6| Step: 9
Training loss: 1.6809419427725407
Validation loss: 2.6542939856716785

Epoch: 6| Step: 10
Training loss: 2.917511481595104
Validation loss: 2.6521199749505255

Epoch: 6| Step: 11
Training loss: 3.0504800450001057
Validation loss: 2.650920323041141

Epoch: 6| Step: 12
Training loss: 2.5151529757804294
Validation loss: 2.653252859221112

Epoch: 6| Step: 13
Training loss: 3.368392976374065
Validation loss: 2.6466994832772515

Epoch: 63| Step: 0
Training loss: 2.3219686948783607
Validation loss: 2.6481877512095955

Epoch: 6| Step: 1
Training loss: 3.0486725028848527
Validation loss: 2.648085129063838

Epoch: 6| Step: 2
Training loss: 2.983273287831287
Validation loss: 2.647729724694867

Epoch: 6| Step: 3
Training loss: 2.9161557612948763
Validation loss: 2.6474458531506135

Epoch: 6| Step: 4
Training loss: 2.807031698463122
Validation loss: 2.647229559644591

Epoch: 6| Step: 5
Training loss: 2.705300310285227
Validation loss: 2.64921579393608

Epoch: 6| Step: 6
Training loss: 2.8246465546275585
Validation loss: 2.6477883142496546

Epoch: 6| Step: 7
Training loss: 2.905430503895054
Validation loss: 2.6488978343139813

Epoch: 6| Step: 8
Training loss: 2.854469301834789
Validation loss: 2.6490086002558257

Epoch: 6| Step: 9
Training loss: 2.356381569991065
Validation loss: 2.6488505428663007

Epoch: 6| Step: 10
Training loss: 2.7034612898484838
Validation loss: 2.646334838396189

Epoch: 6| Step: 11
Training loss: 2.3986224870449426
Validation loss: 2.6429382364554685

Epoch: 6| Step: 12
Training loss: 3.1125076845372948
Validation loss: 2.6415758696956013

Epoch: 6| Step: 13
Training loss: 2.9036489352678685
Validation loss: 2.6402229740404426

Epoch: 64| Step: 0
Training loss: 2.858243624629786
Validation loss: 2.6379781244454037

Epoch: 6| Step: 1
Training loss: 3.150139663264359
Validation loss: 2.6352219541086437

Epoch: 6| Step: 2
Training loss: 2.958683655820562
Validation loss: 2.6352993985548587

Epoch: 6| Step: 3
Training loss: 2.550318911188773
Validation loss: 2.633862324790598

Epoch: 6| Step: 4
Training loss: 2.9185339445408225
Validation loss: 2.633503461927354

Epoch: 6| Step: 5
Training loss: 2.438989624264127
Validation loss: 2.6335453783042366

Epoch: 6| Step: 6
Training loss: 2.490377312840132
Validation loss: 2.6330633298658945

Epoch: 6| Step: 7
Training loss: 2.4599781891390906
Validation loss: 2.633725273162297

Epoch: 6| Step: 8
Training loss: 2.756160857473984
Validation loss: 2.631648937557803

Epoch: 6| Step: 9
Training loss: 2.6698397196120163
Validation loss: 2.6308492100063074

Epoch: 6| Step: 10
Training loss: 2.9888049096935063
Validation loss: 2.6273905752657947

Epoch: 6| Step: 11
Training loss: 2.4636736478930716
Validation loss: 2.6299450179131685

Epoch: 6| Step: 12
Training loss: 2.882087926599463
Validation loss: 2.6295806186085566

Epoch: 6| Step: 13
Training loss: 2.990260367651154
Validation loss: 2.6294051779056544

Epoch: 65| Step: 0
Training loss: 3.002469318115605
Validation loss: 2.6254935935848014

Epoch: 6| Step: 1
Training loss: 3.01573995262407
Validation loss: 2.625640730392649

Epoch: 6| Step: 2
Training loss: 2.6891787409109917
Validation loss: 2.622175922788763

Epoch: 6| Step: 3
Training loss: 3.1232922274538657
Validation loss: 2.622555896731841

Epoch: 6| Step: 4
Training loss: 3.1676779353648414
Validation loss: 2.622749332567401

Epoch: 6| Step: 5
Training loss: 2.3216122669858104
Validation loss: 2.618950746135986

Epoch: 6| Step: 6
Training loss: 1.9465776488883908
Validation loss: 2.6204745930060707

Epoch: 6| Step: 7
Training loss: 2.536465205523341
Validation loss: 2.6176413830474785

Epoch: 6| Step: 8
Training loss: 2.889868064957521
Validation loss: 2.622974431677171

Epoch: 6| Step: 9
Training loss: 2.3508894961667712
Validation loss: 2.6233161490756887

Epoch: 6| Step: 10
Training loss: 2.5341157114997768
Validation loss: 2.6229767192321765

Epoch: 6| Step: 11
Training loss: 2.5598450840330256
Validation loss: 2.6133944682184684

Epoch: 6| Step: 12
Training loss: 3.2663103324494767
Validation loss: 2.617304481435097

Epoch: 6| Step: 13
Training loss: 2.7698349456638574
Validation loss: 2.6140228116461257

Epoch: 66| Step: 0
Training loss: 2.6307469990383376
Validation loss: 2.6155902448538084

Epoch: 6| Step: 1
Training loss: 2.7464421405347195
Validation loss: 2.615883467227152

Epoch: 6| Step: 2
Training loss: 2.6653258608620596
Validation loss: 2.6139229526883425

Epoch: 6| Step: 3
Training loss: 2.795569258913876
Validation loss: 2.6141649091246704

Epoch: 6| Step: 4
Training loss: 2.532559562351719
Validation loss: 2.6114107973397767

Epoch: 6| Step: 5
Training loss: 2.999231240002321
Validation loss: 2.61030562018236

Epoch: 6| Step: 6
Training loss: 2.970761551241691
Validation loss: 2.611006342925587

Epoch: 6| Step: 7
Training loss: 2.7908377674151468
Validation loss: 2.6091384019014194

Epoch: 6| Step: 8
Training loss: 2.8705494475020283
Validation loss: 2.6083252217062043

Epoch: 6| Step: 9
Training loss: 2.4716210390365085
Validation loss: 2.6073284156232415

Epoch: 6| Step: 10
Training loss: 2.6693469128195018
Validation loss: 2.6071655299823893

Epoch: 6| Step: 11
Training loss: 2.7833035206673347
Validation loss: 2.604732502817619

Epoch: 6| Step: 12
Training loss: 2.7095116815112816
Validation loss: 2.6035911585350338

Epoch: 6| Step: 13
Training loss: 2.6972970042243776
Validation loss: 2.6053282372419297

Epoch: 67| Step: 0
Training loss: 2.7550851449426728
Validation loss: 2.6030265499455583

Epoch: 6| Step: 1
Training loss: 2.5637267363044725
Validation loss: 2.6035860304435765

Epoch: 6| Step: 2
Training loss: 3.108050346958446
Validation loss: 2.6033124412776134

Epoch: 6| Step: 3
Training loss: 2.7209682842005876
Validation loss: 2.6057376903877683

Epoch: 6| Step: 4
Training loss: 2.6681505088274813
Validation loss: 2.6028365642088445

Epoch: 6| Step: 5
Training loss: 2.844982844135066
Validation loss: 2.6041219834626834

Epoch: 6| Step: 6
Training loss: 2.5582981550384707
Validation loss: 2.60362013358822

Epoch: 6| Step: 7
Training loss: 2.7011965007859304
Validation loss: 2.6032040660706826

Epoch: 6| Step: 8
Training loss: 2.593359492675852
Validation loss: 2.5998683602680073

Epoch: 6| Step: 9
Training loss: 2.7878363128455836
Validation loss: 2.596129540024427

Epoch: 6| Step: 10
Training loss: 2.769833051973209
Validation loss: 2.5952843260532474

Epoch: 6| Step: 11
Training loss: 2.7463986483918665
Validation loss: 2.5958862087034524

Epoch: 6| Step: 12
Training loss: 2.5704158309990404
Validation loss: 2.5966040294308907

Epoch: 6| Step: 13
Training loss: 2.762832956401238
Validation loss: 2.593318060639559

Epoch: 68| Step: 0
Training loss: 2.675904743101449
Validation loss: 2.5932732415857567

Epoch: 6| Step: 1
Training loss: 2.6237134051122135
Validation loss: 2.5925904481805784

Epoch: 6| Step: 2
Training loss: 2.8160486510148957
Validation loss: 2.590047606763417

Epoch: 6| Step: 3
Training loss: 2.6411062851607054
Validation loss: 2.5933223816150894

Epoch: 6| Step: 4
Training loss: 3.1702511393708432
Validation loss: 2.590057379579173

Epoch: 6| Step: 5
Training loss: 2.9094807704952848
Validation loss: 2.590649908457591

Epoch: 6| Step: 6
Training loss: 2.401978305220003
Validation loss: 2.586797811224921

Epoch: 6| Step: 7
Training loss: 2.375840791146214
Validation loss: 2.5894605104674184

Epoch: 6| Step: 8
Training loss: 2.7140559748174207
Validation loss: 2.589876645561572

Epoch: 6| Step: 9
Training loss: 2.5147251391518273
Validation loss: 2.596827232756991

Epoch: 6| Step: 10
Training loss: 2.7703998962834135
Validation loss: 2.600475523330023

Epoch: 6| Step: 11
Training loss: 2.9896940594060215
Validation loss: 2.5999034292064076

Epoch: 6| Step: 12
Training loss: 2.8943098346488947
Validation loss: 2.5951811584028186

Epoch: 6| Step: 13
Training loss: 2.4806726086565942
Validation loss: 2.5918588446438737

Epoch: 69| Step: 0
Training loss: 3.0154893281292714
Validation loss: 2.5876078056446126

Epoch: 6| Step: 1
Training loss: 2.6831443443640657
Validation loss: 2.584067968283627

Epoch: 6| Step: 2
Training loss: 2.5000293729963907
Validation loss: 2.5832039482776454

Epoch: 6| Step: 3
Training loss: 3.126784768656447
Validation loss: 2.5843250360544716

Epoch: 6| Step: 4
Training loss: 2.995211276083693
Validation loss: 2.585881089500886

Epoch: 6| Step: 5
Training loss: 2.8047186124558294
Validation loss: 2.5878307407576058

Epoch: 6| Step: 6
Training loss: 2.587001800489297
Validation loss: 2.5908019995877947

Epoch: 6| Step: 7
Training loss: 2.7558946722137145
Validation loss: 2.585404263286568

Epoch: 6| Step: 8
Training loss: 2.582910246710058
Validation loss: 2.588453484510079

Epoch: 6| Step: 9
Training loss: 2.6198235289277383
Validation loss: 2.581999116313851

Epoch: 6| Step: 10
Training loss: 2.429318317196635
Validation loss: 2.5819408806834447

Epoch: 6| Step: 11
Training loss: 2.337218478788479
Validation loss: 2.5797226396459036

Epoch: 6| Step: 12
Training loss: 2.742986665872004
Validation loss: 2.5792088089695873

Epoch: 6| Step: 13
Training loss: 2.7008987696919586
Validation loss: 2.576059612289303

Epoch: 70| Step: 0
Training loss: 2.683140345755464
Validation loss: 2.5780833231322005

Epoch: 6| Step: 1
Training loss: 2.8903765597417395
Validation loss: 2.576150280464522

Epoch: 6| Step: 2
Training loss: 3.0385142324571603
Validation loss: 2.578762723096537

Epoch: 6| Step: 3
Training loss: 3.045554163324495
Validation loss: 2.5764425317252937

Epoch: 6| Step: 4
Training loss: 2.900418738026631
Validation loss: 2.5758033857164815

Epoch: 6| Step: 5
Training loss: 2.252455748738344
Validation loss: 2.5754595763067343

Epoch: 6| Step: 6
Training loss: 1.9611109318731632
Validation loss: 2.576521357386538

Epoch: 6| Step: 7
Training loss: 2.2851239063549746
Validation loss: 2.5780691121526833

Epoch: 6| Step: 8
Training loss: 3.193622319306336
Validation loss: 2.5780154734764427

Epoch: 6| Step: 9
Training loss: 2.6628591554921797
Validation loss: 2.578654872503729

Epoch: 6| Step: 10
Training loss: 2.7218843129258192
Validation loss: 2.579870862045332

Epoch: 6| Step: 11
Training loss: 2.5413282408821716
Validation loss: 2.580425646217212

Epoch: 6| Step: 12
Training loss: 2.885747144665793
Validation loss: 2.5799074118903174

Epoch: 6| Step: 13
Training loss: 2.595306297262681
Validation loss: 2.5728353315051034

Epoch: 71| Step: 0
Training loss: 3.150373218769723
Validation loss: 2.5733739830011744

Epoch: 6| Step: 1
Training loss: 2.3089031392990567
Validation loss: 2.5730191003174756

Epoch: 6| Step: 2
Training loss: 2.970153797932697
Validation loss: 2.566842083282977

Epoch: 6| Step: 3
Training loss: 2.7536230496283585
Validation loss: 2.5688805267758137

Epoch: 6| Step: 4
Training loss: 2.161763757168919
Validation loss: 2.5688842082485133

Epoch: 6| Step: 5
Training loss: 2.64019762903371
Validation loss: 2.5664509963378603

Epoch: 6| Step: 6
Training loss: 2.630635705854945
Validation loss: 2.5665761271109213

Epoch: 6| Step: 7
Training loss: 2.5829428305862017
Validation loss: 2.568557333237218

Epoch: 6| Step: 8
Training loss: 2.4734544957071645
Validation loss: 2.5703872159632257

Epoch: 6| Step: 9
Training loss: 2.663962264426631
Validation loss: 2.5732180821678896

Epoch: 6| Step: 10
Training loss: 2.8049272100078433
Validation loss: 2.567238512575219

Epoch: 6| Step: 11
Training loss: 2.9250490624641263
Validation loss: 2.56482649847808

Epoch: 6| Step: 12
Training loss: 2.878882730250771
Validation loss: 2.565446059522408

Epoch: 6| Step: 13
Training loss: 2.631858584955897
Validation loss: 2.5671841368108548

Epoch: 72| Step: 0
Training loss: 2.7540056359504206
Validation loss: 2.5669370399434994

Epoch: 6| Step: 1
Training loss: 3.0439664603151324
Validation loss: 2.564599766331283

Epoch: 6| Step: 2
Training loss: 2.6641910108071136
Validation loss: 2.5644261014220997

Epoch: 6| Step: 3
Training loss: 3.3750740325719963
Validation loss: 2.5635512296913423

Epoch: 6| Step: 4
Training loss: 2.8852859265469144
Validation loss: 2.5608990793408646

Epoch: 6| Step: 5
Training loss: 2.6277173827285254
Validation loss: 2.560530719953447

Epoch: 6| Step: 6
Training loss: 2.482569776401491
Validation loss: 2.5627538818879736

Epoch: 6| Step: 7
Training loss: 2.483554248669677
Validation loss: 2.5596353599513924

Epoch: 6| Step: 8
Training loss: 2.7324281573819844
Validation loss: 2.5605215483110535

Epoch: 6| Step: 9
Training loss: 3.082290851214319
Validation loss: 2.5607963574321313

Epoch: 6| Step: 10
Training loss: 2.1890380901579474
Validation loss: 2.5581327532649123

Epoch: 6| Step: 11
Training loss: 2.558594215917181
Validation loss: 2.560749339836443

Epoch: 6| Step: 12
Training loss: 2.0297269539819753
Validation loss: 2.5562047001463104

Epoch: 6| Step: 13
Training loss: 2.4549330347565816
Validation loss: 2.5531363565977565

Epoch: 73| Step: 0
Training loss: 2.3981663056674516
Validation loss: 2.5578914231676926

Epoch: 6| Step: 1
Training loss: 2.4002398450533518
Validation loss: 2.5557918514205893

Epoch: 6| Step: 2
Training loss: 3.1579056731252195
Validation loss: 2.5536947236479386

Epoch: 6| Step: 3
Training loss: 2.803137730938464
Validation loss: 2.5577494774109053

Epoch: 6| Step: 4
Training loss: 2.8392536541961535
Validation loss: 2.551981364697845

Epoch: 6| Step: 5
Training loss: 2.3113516972203536
Validation loss: 2.5609797178073768

Epoch: 6| Step: 6
Training loss: 2.9447788392525127
Validation loss: 2.560850155054421

Epoch: 6| Step: 7
Training loss: 2.9626115480177693
Validation loss: 2.564819185850252

Epoch: 6| Step: 8
Training loss: 2.1012756832625064
Validation loss: 2.5547849304098795

Epoch: 6| Step: 9
Training loss: 2.348058986553254
Validation loss: 2.553111921360193

Epoch: 6| Step: 10
Training loss: 2.966742228142207
Validation loss: 2.551346673848674

Epoch: 6| Step: 11
Training loss: 2.831929887733467
Validation loss: 2.553616158140979

Epoch: 6| Step: 12
Training loss: 2.465609327297899
Validation loss: 2.551805400635799

Epoch: 6| Step: 13
Training loss: 2.7821336692547813
Validation loss: 2.5517066573786784

Epoch: 74| Step: 0
Training loss: 2.886397616187082
Validation loss: 2.5507652823555462

Epoch: 6| Step: 1
Training loss: 2.4040582756938584
Validation loss: 2.5531335317717385

Epoch: 6| Step: 2
Training loss: 2.216726535571833
Validation loss: 2.5539132441077466

Epoch: 6| Step: 3
Training loss: 2.8556013376579354
Validation loss: 2.5548743938867937

Epoch: 6| Step: 4
Training loss: 3.3598635296127832
Validation loss: 2.5521035693138385

Epoch: 6| Step: 5
Training loss: 2.529478795641525
Validation loss: 2.555228655288902

Epoch: 6| Step: 6
Training loss: 1.8465504472474443
Validation loss: 2.5560929751492654

Epoch: 6| Step: 7
Training loss: 3.475457931094915
Validation loss: 2.5515633864361322

Epoch: 6| Step: 8
Training loss: 2.6391919101495125
Validation loss: 2.5533392378570308

Epoch: 6| Step: 9
Training loss: 3.32326399722861
Validation loss: 2.552038937137092

Epoch: 6| Step: 10
Training loss: 1.9084522471241514
Validation loss: 2.5498143340441723

Epoch: 6| Step: 11
Training loss: 2.2214522763075206
Validation loss: 2.550289696711954

Epoch: 6| Step: 12
Training loss: 2.4881538106960255
Validation loss: 2.5437883735030535

Epoch: 6| Step: 13
Training loss: 2.704520333962458
Validation loss: 2.5442365932340643

Epoch: 75| Step: 0
Training loss: 2.927291012022444
Validation loss: 2.5434942605871416

Epoch: 6| Step: 1
Training loss: 2.9768335414244462
Validation loss: 2.541647619165642

Epoch: 6| Step: 2
Training loss: 2.6335297012348993
Validation loss: 2.541421727327722

Epoch: 6| Step: 3
Training loss: 2.635478223802968
Validation loss: 2.546316807275743

Epoch: 6| Step: 4
Training loss: 2.4171793054147113
Validation loss: 2.5487312308221077

Epoch: 6| Step: 5
Training loss: 2.6516043035373587
Validation loss: 2.5458107813592243

Epoch: 6| Step: 6
Training loss: 2.693097605996408
Validation loss: 2.5505981068002312

Epoch: 6| Step: 7
Training loss: 2.660564912167239
Validation loss: 2.5483340743092704

Epoch: 6| Step: 8
Training loss: 2.9222101845471173
Validation loss: 2.5449275584924704

Epoch: 6| Step: 9
Training loss: 2.598920150405001
Validation loss: 2.5431779266597476

Epoch: 6| Step: 10
Training loss: 2.2851822289188353
Validation loss: 2.542528058612728

Epoch: 6| Step: 11
Training loss: 2.7998292121571513
Validation loss: 2.5441131907379404

Epoch: 6| Step: 12
Training loss: 2.719240341692634
Validation loss: 2.5407866898464704

Epoch: 6| Step: 13
Training loss: 2.297862975760542
Validation loss: 2.5388468332886047

Epoch: 76| Step: 0
Training loss: 2.8066842879454232
Validation loss: 2.539255614150524

Epoch: 6| Step: 1
Training loss: 2.196561736213789
Validation loss: 2.5376667744619685

Epoch: 6| Step: 2
Training loss: 2.5947936382819647
Validation loss: 2.541313746188048

Epoch: 6| Step: 3
Training loss: 2.9194289796151236
Validation loss: 2.5390404489977962

Epoch: 6| Step: 4
Training loss: 2.746598828073639
Validation loss: 2.540331706204669

Epoch: 6| Step: 5
Training loss: 3.065447887161249
Validation loss: 2.540188161308466

Epoch: 6| Step: 6
Training loss: 2.787191666455517
Validation loss: 2.5400994946424644

Epoch: 6| Step: 7
Training loss: 2.756269244691265
Validation loss: 2.538587946437966

Epoch: 6| Step: 8
Training loss: 2.908422498966599
Validation loss: 2.541637034842772

Epoch: 6| Step: 9
Training loss: 2.8228506570866188
Validation loss: 2.5408413412114514

Epoch: 6| Step: 10
Training loss: 2.5232997419707375
Validation loss: 2.542588165915081

Epoch: 6| Step: 11
Training loss: 2.2191758083031545
Validation loss: 2.5390803409829923

Epoch: 6| Step: 12
Training loss: 2.2782737442666314
Validation loss: 2.539636533355723

Epoch: 6| Step: 13
Training loss: 2.506800652416504
Validation loss: 2.53841082695308

Epoch: 77| Step: 0
Training loss: 2.6822303740279114
Validation loss: 2.536373432051842

Epoch: 6| Step: 1
Training loss: 2.529798491825134
Validation loss: 2.5355881458763823

Epoch: 6| Step: 2
Training loss: 3.1693846599331597
Validation loss: 2.533003713680115

Epoch: 6| Step: 3
Training loss: 2.8084923058707156
Validation loss: 2.535079884370826

Epoch: 6| Step: 4
Training loss: 2.9280599320224194
Validation loss: 2.532773097314415

Epoch: 6| Step: 5
Training loss: 2.466725545472583
Validation loss: 2.531588229591844

Epoch: 6| Step: 6
Training loss: 2.6587638179561663
Validation loss: 2.5325954927125345

Epoch: 6| Step: 7
Training loss: 2.2086282809040614
Validation loss: 2.52734906423522

Epoch: 6| Step: 8
Training loss: 2.4775651412391264
Validation loss: 2.5279880745944485

Epoch: 6| Step: 9
Training loss: 2.9982868707381423
Validation loss: 2.5311891210950797

Epoch: 6| Step: 10
Training loss: 3.2614143640719444
Validation loss: 2.5316819344420773

Epoch: 6| Step: 11
Training loss: 2.659469269315514
Validation loss: 2.530336270030078

Epoch: 6| Step: 12
Training loss: 1.9594709528010912
Validation loss: 2.5315152566957244

Epoch: 6| Step: 13
Training loss: 2.0888020138339645
Validation loss: 2.52776748587594

Epoch: 78| Step: 0
Training loss: 2.8098362494165308
Validation loss: 2.530281572366876

Epoch: 6| Step: 1
Training loss: 2.8770741154336363
Validation loss: 2.5267978650589957

Epoch: 6| Step: 2
Training loss: 2.2397581756711684
Validation loss: 2.5268691028466717

Epoch: 6| Step: 3
Training loss: 2.208087067698001
Validation loss: 2.5275349453787737

Epoch: 6| Step: 4
Training loss: 2.9424422872453304
Validation loss: 2.5287393591281826

Epoch: 6| Step: 5
Training loss: 2.8193108214319005
Validation loss: 2.526131324881082

Epoch: 6| Step: 6
Training loss: 2.6152155037185545
Validation loss: 2.526664284861842

Epoch: 6| Step: 7
Training loss: 2.457156131160405
Validation loss: 2.526111552002565

Epoch: 6| Step: 8
Training loss: 2.487000907017351
Validation loss: 2.525795330083484

Epoch: 6| Step: 9
Training loss: 3.1086727096833746
Validation loss: 2.524096124477113

Epoch: 6| Step: 10
Training loss: 2.663247350117239
Validation loss: 2.526770800463539

Epoch: 6| Step: 11
Training loss: 2.6109873649908
Validation loss: 2.522747154011701

Epoch: 6| Step: 12
Training loss: 2.3056204249232444
Validation loss: 2.5262484488780554

Epoch: 6| Step: 13
Training loss: 2.7271969994232776
Validation loss: 2.526707549011844

Epoch: 79| Step: 0
Training loss: 2.736396434729085
Validation loss: 2.52408430158003

Epoch: 6| Step: 1
Training loss: 3.0342035749985024
Validation loss: 2.528345018769303

Epoch: 6| Step: 2
Training loss: 2.4140348463727594
Validation loss: 2.5320290673472203

Epoch: 6| Step: 3
Training loss: 2.7058282466269254
Validation loss: 2.530480444452128

Epoch: 6| Step: 4
Training loss: 2.9924886766058543
Validation loss: 2.530440479704413

Epoch: 6| Step: 5
Training loss: 3.0271496913608766
Validation loss: 2.5302527547187537

Epoch: 6| Step: 6
Training loss: 2.8138592296600877
Validation loss: 2.5224054546804155

Epoch: 6| Step: 7
Training loss: 2.08426224662383
Validation loss: 2.524157914349795

Epoch: 6| Step: 8
Training loss: 2.538234446555789
Validation loss: 2.525854710742579

Epoch: 6| Step: 9
Training loss: 2.171132022373453
Validation loss: 2.5217495401366334

Epoch: 6| Step: 10
Training loss: 2.5707010363929843
Validation loss: 2.5224585272836193

Epoch: 6| Step: 11
Training loss: 2.6139380480685888
Validation loss: 2.5204948219024654

Epoch: 6| Step: 12
Training loss: 2.2625361992906514
Validation loss: 2.5198807032922543

Epoch: 6| Step: 13
Training loss: 2.916140881331097
Validation loss: 2.5195083814268204

Epoch: 80| Step: 0
Training loss: 2.5719760508749716
Validation loss: 2.515900906740615

Epoch: 6| Step: 1
Training loss: 2.645104215187769
Validation loss: 2.514946042323219

Epoch: 6| Step: 2
Training loss: 2.7580718439937093
Validation loss: 2.5231876544860214

Epoch: 6| Step: 3
Training loss: 2.6029318564981208
Validation loss: 2.5192172226884137

Epoch: 6| Step: 4
Training loss: 2.5024977604172904
Validation loss: 2.5209617161701905

Epoch: 6| Step: 5
Training loss: 2.4582580511775403
Validation loss: 2.516598388764612

Epoch: 6| Step: 6
Training loss: 2.76419633937025
Validation loss: 2.51502768807815

Epoch: 6| Step: 7
Training loss: 2.7429350353006248
Validation loss: 2.5163860551966684

Epoch: 6| Step: 8
Training loss: 2.612347582883799
Validation loss: 2.519424065569756

Epoch: 6| Step: 9
Training loss: 2.343799132785788
Validation loss: 2.519691056104678

Epoch: 6| Step: 10
Training loss: 2.5337506410647817
Validation loss: 2.5179055027953856

Epoch: 6| Step: 11
Training loss: 2.3780094955806583
Validation loss: 2.5211681164677477

Epoch: 6| Step: 12
Training loss: 2.856393395628624
Validation loss: 2.5209249264389473

Epoch: 6| Step: 13
Training loss: 3.1121597471741635
Validation loss: 2.5218244973774278

Epoch: 81| Step: 0
Training loss: 2.0830369992900697
Validation loss: 2.5198977812466365

Epoch: 6| Step: 1
Training loss: 2.874581513838094
Validation loss: 2.520848571058726

Epoch: 6| Step: 2
Training loss: 2.710793087325641
Validation loss: 2.517860012091458

Epoch: 6| Step: 3
Training loss: 2.601446017386902
Validation loss: 2.5174993478521004

Epoch: 6| Step: 4
Training loss: 2.525844783910129
Validation loss: 2.5187202508650937

Epoch: 6| Step: 5
Training loss: 2.8535547273373223
Validation loss: 2.5123204073764698

Epoch: 6| Step: 6
Training loss: 2.981414764777586
Validation loss: 2.5153786516900336

Epoch: 6| Step: 7
Training loss: 2.558660841200523
Validation loss: 2.5132429008336823

Epoch: 6| Step: 8
Training loss: 2.4405107732752698
Validation loss: 2.5140316420945856

Epoch: 6| Step: 9
Training loss: 2.963141675257274
Validation loss: 2.5174864837879656

Epoch: 6| Step: 10
Training loss: 2.6976704331684425
Validation loss: 2.5152055062828667

Epoch: 6| Step: 11
Training loss: 2.288520827015475
Validation loss: 2.5164825525788728

Epoch: 6| Step: 12
Training loss: 2.822566011804013
Validation loss: 2.514879309663642

Epoch: 6| Step: 13
Training loss: 2.401415637855068
Validation loss: 2.513373969109615

Epoch: 82| Step: 0
Training loss: 2.718651429943563
Validation loss: 2.510050154611692

Epoch: 6| Step: 1
Training loss: 2.9800066708483692
Validation loss: 2.5182660694173244

Epoch: 6| Step: 2
Training loss: 3.146440729445895
Validation loss: 2.527402300306302

Epoch: 6| Step: 3
Training loss: 3.153774385906079
Validation loss: 2.531764052826079

Epoch: 6| Step: 4
Training loss: 2.8344796797528184
Validation loss: 2.5348742719592448

Epoch: 6| Step: 5
Training loss: 2.8867569070444175
Validation loss: 2.54348063749384

Epoch: 6| Step: 6
Training loss: 2.9637685643084892
Validation loss: 2.5469977226411893

Epoch: 6| Step: 7
Training loss: 2.693186753725388
Validation loss: 2.5412864609138723

Epoch: 6| Step: 8
Training loss: 2.380078157055227
Validation loss: 2.5293646019075493

Epoch: 6| Step: 9
Training loss: 2.14222601724467
Validation loss: 2.524228959027001

Epoch: 6| Step: 10
Training loss: 2.2659752936704005
Validation loss: 2.5158015913812544

Epoch: 6| Step: 11
Training loss: 2.1889177360290493
Validation loss: 2.517066897741859

Epoch: 6| Step: 12
Training loss: 2.598349847192591
Validation loss: 2.514957726479109

Epoch: 6| Step: 13
Training loss: 1.836231159505667
Validation loss: 2.5139526273633632

Epoch: 83| Step: 0
Training loss: 2.7509138149570913
Validation loss: 2.513122783167539

Epoch: 6| Step: 1
Training loss: 2.2043978213542266
Validation loss: 2.511244614910088

Epoch: 6| Step: 2
Training loss: 1.8274697327618772
Validation loss: 2.5130687623402967

Epoch: 6| Step: 3
Training loss: 2.516048893251807
Validation loss: 2.5104674232596373

Epoch: 6| Step: 4
Training loss: 2.8538778859714915
Validation loss: 2.511151460822278

Epoch: 6| Step: 5
Training loss: 2.164577491710761
Validation loss: 2.509443693380708

Epoch: 6| Step: 6
Training loss: 3.1789872431755604
Validation loss: 2.5068123507606765

Epoch: 6| Step: 7
Training loss: 2.6635679977442246
Validation loss: 2.5070247343760683

Epoch: 6| Step: 8
Training loss: 2.885146769950408
Validation loss: 2.508216136167292

Epoch: 6| Step: 9
Training loss: 2.609487382673001
Validation loss: 2.5061556848297784

Epoch: 6| Step: 10
Training loss: 2.5373286034337332
Validation loss: 2.505343052234987

Epoch: 6| Step: 11
Training loss: 2.802074607258839
Validation loss: 2.510071953708496

Epoch: 6| Step: 12
Training loss: 2.341340924975543
Validation loss: 2.507807635563047

Epoch: 6| Step: 13
Training loss: 3.0930563409152723
Validation loss: 2.5036912846643893

Epoch: 84| Step: 0
Training loss: 2.0701980271271143
Validation loss: 2.509528027876751

Epoch: 6| Step: 1
Training loss: 2.550302457636593
Validation loss: 2.5083917442018024

Epoch: 6| Step: 2
Training loss: 2.5699074840592093
Validation loss: 2.5127085648192273

Epoch: 6| Step: 3
Training loss: 2.9874896827423836
Validation loss: 2.513174881767775

Epoch: 6| Step: 4
Training loss: 2.664153424722192
Validation loss: 2.510847083795901

Epoch: 6| Step: 5
Training loss: 2.3530761308395562
Validation loss: 2.5077159225231984

Epoch: 6| Step: 6
Training loss: 2.829442007368075
Validation loss: 2.508318365776886

Epoch: 6| Step: 7
Training loss: 2.3641178384318535
Validation loss: 2.5105096211510216

Epoch: 6| Step: 8
Training loss: 2.7205114687352037
Validation loss: 2.5066314007513726

Epoch: 6| Step: 9
Training loss: 2.4492692714025277
Validation loss: 2.5088158300785097

Epoch: 6| Step: 10
Training loss: 2.715757630580579
Validation loss: 2.5058909310395365

Epoch: 6| Step: 11
Training loss: 2.754491259616592
Validation loss: 2.507070120540538

Epoch: 6| Step: 12
Training loss: 2.954322208960199
Validation loss: 2.506794311827744

Epoch: 6| Step: 13
Training loss: 2.622664366190525
Validation loss: 2.5064533864588845

Epoch: 85| Step: 0
Training loss: 2.5717656164443317
Validation loss: 2.5029968816296058

Epoch: 6| Step: 1
Training loss: 2.1303432829128166
Validation loss: 2.507426690741151

Epoch: 6| Step: 2
Training loss: 2.8550694469550186
Validation loss: 2.506826482224227

Epoch: 6| Step: 3
Training loss: 2.2351380225794713
Validation loss: 2.505423559723577

Epoch: 6| Step: 4
Training loss: 2.8208619319606143
Validation loss: 2.504804698972905

Epoch: 6| Step: 5
Training loss: 2.5880839034546
Validation loss: 2.505925214085382

Epoch: 6| Step: 6
Training loss: 2.7259846159626147
Validation loss: 2.5024495521971075

Epoch: 6| Step: 7
Training loss: 2.6831080900948296
Validation loss: 2.502713018796305

Epoch: 6| Step: 8
Training loss: 2.2754490922611668
Validation loss: 2.5004818769801394

Epoch: 6| Step: 9
Training loss: 2.800949623654536
Validation loss: 2.5011625686226915

Epoch: 6| Step: 10
Training loss: 2.9496361847584733
Validation loss: 2.4949677364732556

Epoch: 6| Step: 11
Training loss: 3.01206309209149
Validation loss: 2.4972640882209176

Epoch: 6| Step: 12
Training loss: 2.4653591578368714
Validation loss: 2.505059447328681

Epoch: 6| Step: 13
Training loss: 2.371537143533016
Validation loss: 2.4998054587647665

Epoch: 86| Step: 0
Training loss: 2.538516129615848
Validation loss: 2.498849826718706

Epoch: 6| Step: 1
Training loss: 2.820026583985904
Validation loss: 2.5044105406802504

Epoch: 6| Step: 2
Training loss: 2.4331056157341164
Validation loss: 2.500371905320685

Epoch: 6| Step: 3
Training loss: 2.6650973013458383
Validation loss: 2.4977017488095057

Epoch: 6| Step: 4
Training loss: 2.4837553583095984
Validation loss: 2.497726026126558

Epoch: 6| Step: 5
Training loss: 2.911995080231084
Validation loss: 2.4930132192584336

Epoch: 6| Step: 6
Training loss: 3.2363329871813957
Validation loss: 2.4977377033365586

Epoch: 6| Step: 7
Training loss: 2.5732421875
Validation loss: 2.5037022039835115

Epoch: 6| Step: 8
Training loss: 2.5961893399847193
Validation loss: 2.5042440312558694

Epoch: 6| Step: 9
Training loss: 3.045563870542002
Validation loss: 2.505267601871809

Epoch: 6| Step: 10
Training loss: 1.8517802307619475
Validation loss: 2.505915255876179

Epoch: 6| Step: 11
Training loss: 2.5695083426930037
Validation loss: 2.5093408762003966

Epoch: 6| Step: 12
Training loss: 2.366566793814914
Validation loss: 2.510484470280145

Epoch: 6| Step: 13
Training loss: 2.4697391122036825
Validation loss: 2.509426021730225

Epoch: 87| Step: 0
Training loss: 2.7240485814001416
Validation loss: 2.5070284274315093

Epoch: 6| Step: 1
Training loss: 2.7598214329437765
Validation loss: 2.5067803941791778

Epoch: 6| Step: 2
Training loss: 2.514118952144028
Validation loss: 2.5030544377420907

Epoch: 6| Step: 3
Training loss: 2.6530113672156017
Validation loss: 2.4995457554446165

Epoch: 6| Step: 4
Training loss: 3.1399772317631878
Validation loss: 2.49358600532946

Epoch: 6| Step: 5
Training loss: 2.076226536057258
Validation loss: 2.4979810827845643

Epoch: 6| Step: 6
Training loss: 2.134805607399483
Validation loss: 2.495536682339292

Epoch: 6| Step: 7
Training loss: 2.1779544188859026
Validation loss: 2.4942921886431333

Epoch: 6| Step: 8
Training loss: 2.9383524205768383
Validation loss: 2.4937826411023956

Epoch: 6| Step: 9
Training loss: 2.5817295654232866
Validation loss: 2.496538388284682

Epoch: 6| Step: 10
Training loss: 3.0763071956843384
Validation loss: 2.4960388909859827

Epoch: 6| Step: 11
Training loss: 2.576185109275853
Validation loss: 2.492569307200977

Epoch: 6| Step: 12
Training loss: 2.668955228182047
Validation loss: 2.500874128109575

Epoch: 6| Step: 13
Training loss: 2.3279644187489072
Validation loss: 2.4910347723099124

Epoch: 88| Step: 0
Training loss: 2.7153801038301006
Validation loss: 2.498321001184865

Epoch: 6| Step: 1
Training loss: 2.453005842485713
Validation loss: 2.4931314209493323

Epoch: 6| Step: 2
Training loss: 2.4778941331959983
Validation loss: 2.497345755150909

Epoch: 6| Step: 3
Training loss: 2.229323859926261
Validation loss: 2.4983368586726784

Epoch: 6| Step: 4
Training loss: 2.1729726967638934
Validation loss: 2.492808871401082

Epoch: 6| Step: 5
Training loss: 2.7788903159520424
Validation loss: 2.49969617268973

Epoch: 6| Step: 6
Training loss: 2.580002164913718
Validation loss: 2.493251178921335

Epoch: 6| Step: 7
Training loss: 2.633912714063003
Validation loss: 2.4974450088979085

Epoch: 6| Step: 8
Training loss: 2.6581850072283926
Validation loss: 2.4975342670746272

Epoch: 6| Step: 9
Training loss: 2.2597559184374507
Validation loss: 2.4938027659150275

Epoch: 6| Step: 10
Training loss: 3.311013806027703
Validation loss: 2.4917620830914617

Epoch: 6| Step: 11
Training loss: 2.8599501067924744
Validation loss: 2.493050548391411

Epoch: 6| Step: 12
Training loss: 3.203269694712037
Validation loss: 2.494255125025918

Epoch: 6| Step: 13
Training loss: 1.749466542270996
Validation loss: 2.4970836000035517

Epoch: 89| Step: 0
Training loss: 2.2407909124389636
Validation loss: 2.4917622106684214

Epoch: 6| Step: 1
Training loss: 2.504265198591293
Validation loss: 2.4887415421765455

Epoch: 6| Step: 2
Training loss: 2.6586676870641917
Validation loss: 2.4917466302839157

Epoch: 6| Step: 3
Training loss: 2.489122568903529
Validation loss: 2.4962647985873905

Epoch: 6| Step: 4
Training loss: 2.728332644466188
Validation loss: 2.4968570980724105

Epoch: 6| Step: 5
Training loss: 2.9458638694579777
Validation loss: 2.496736574055835

Epoch: 6| Step: 6
Training loss: 2.1196729422149088
Validation loss: 2.4983838738624096

Epoch: 6| Step: 7
Training loss: 2.5606262055073667
Validation loss: 2.4972460678323714

Epoch: 6| Step: 8
Training loss: 2.560837555308844
Validation loss: 2.4954975910688506

Epoch: 6| Step: 9
Training loss: 2.5487906149957817
Validation loss: 2.49350298022198

Epoch: 6| Step: 10
Training loss: 3.1915357883268967
Validation loss: 2.4959996006203196

Epoch: 6| Step: 11
Training loss: 2.6449273628399905
Validation loss: 2.492023713759844

Epoch: 6| Step: 12
Training loss: 2.523322796650518
Validation loss: 2.492001294361756

Epoch: 6| Step: 13
Training loss: 2.4615069018229803
Validation loss: 2.4927666448608043

Epoch: 90| Step: 0
Training loss: 2.5949487329023673
Validation loss: 2.4908242478199116

Epoch: 6| Step: 1
Training loss: 2.5075164334946254
Validation loss: 2.496583782045967

Epoch: 6| Step: 2
Training loss: 2.5052943436310993
Validation loss: 2.49239041609489

Epoch: 6| Step: 3
Training loss: 3.138171551937862
Validation loss: 2.50233172714421

Epoch: 6| Step: 4
Training loss: 1.9115572357229973
Validation loss: 2.49731479920368

Epoch: 6| Step: 5
Training loss: 3.246984696944595
Validation loss: 2.493754708294419

Epoch: 6| Step: 6
Training loss: 2.993347261930258
Validation loss: 2.493598124214232

Epoch: 6| Step: 7
Training loss: 2.4330042925764253
Validation loss: 2.4938845461925165

Epoch: 6| Step: 8
Training loss: 2.642916345485536
Validation loss: 2.4862043735005686

Epoch: 6| Step: 9
Training loss: 3.117263372353576
Validation loss: 2.491842710427555

Epoch: 6| Step: 10
Training loss: 2.101373713639485
Validation loss: 2.486159972972195

Epoch: 6| Step: 11
Training loss: 2.5294581534910696
Validation loss: 2.488338803155214

Epoch: 6| Step: 12
Training loss: 2.2314964906261903
Validation loss: 2.4924416566918346

Epoch: 6| Step: 13
Training loss: 1.8977570118699825
Validation loss: 2.4938546307761738

Epoch: 91| Step: 0
Training loss: 2.225226178621065
Validation loss: 2.4941934068671534

Epoch: 6| Step: 1
Training loss: 3.057968523960028
Validation loss: 2.496260309607175

Epoch: 6| Step: 2
Training loss: 2.8166409843071514
Validation loss: 2.49732344717719

Epoch: 6| Step: 3
Training loss: 2.4117737818482876
Validation loss: 2.498778394417226

Epoch: 6| Step: 4
Training loss: 2.288819179687353
Validation loss: 2.4988899468598316

Epoch: 6| Step: 5
Training loss: 2.461359090872104
Validation loss: 2.4969018494678674

Epoch: 6| Step: 6
Training loss: 2.316594802876172
Validation loss: 2.5004737405143755

Epoch: 6| Step: 7
Training loss: 2.8550509083179083
Validation loss: 2.496087207099088

Epoch: 6| Step: 8
Training loss: 2.603122827499234
Validation loss: 2.4954523208609514

Epoch: 6| Step: 9
Training loss: 3.0926644318392946
Validation loss: 2.492447093171266

Epoch: 6| Step: 10
Training loss: 2.2378571592875978
Validation loss: 2.494467725541301

Epoch: 6| Step: 11
Training loss: 2.635768148231496
Validation loss: 2.4931722387589934

Epoch: 6| Step: 12
Training loss: 2.813098080939995
Validation loss: 2.4904589582910064

Epoch: 6| Step: 13
Training loss: 2.537303890674188
Validation loss: 2.4862517459761606

Epoch: 92| Step: 0
Training loss: 2.2599987809844655
Validation loss: 2.4887036215092992

Epoch: 6| Step: 1
Training loss: 2.459941359650657
Validation loss: 2.4886170644237464

Epoch: 6| Step: 2
Training loss: 2.807479361426838
Validation loss: 2.486874744293514

Epoch: 6| Step: 3
Training loss: 2.7005594239133868
Validation loss: 2.490554410029037

Epoch: 6| Step: 4
Training loss: 2.522230396967042
Validation loss: 2.4864412747967113

Epoch: 6| Step: 5
Training loss: 3.0568053569827627
Validation loss: 2.4882904164351536

Epoch: 6| Step: 6
Training loss: 2.483103588750296
Validation loss: 2.48670220289159

Epoch: 6| Step: 7
Training loss: 2.906883416829035
Validation loss: 2.4903949920117863

Epoch: 6| Step: 8
Training loss: 2.044546652164831
Validation loss: 2.4879977445520645

Epoch: 6| Step: 9
Training loss: 2.092453056729517
Validation loss: 2.4886214713873906

Epoch: 6| Step: 10
Training loss: 2.116283716517903
Validation loss: 2.490614008669849

Epoch: 6| Step: 11
Training loss: 3.3104719755538987
Validation loss: 2.482266985255223

Epoch: 6| Step: 12
Training loss: 2.5483435393038207
Validation loss: 2.486924628546856

Epoch: 6| Step: 13
Training loss: 2.561729315258691
Validation loss: 2.488696699927257

Epoch: 93| Step: 0
Training loss: 3.2138835080108246
Validation loss: 2.485307922179994

Epoch: 6| Step: 1
Training loss: 2.737865552489439
Validation loss: 2.487024026569328

Epoch: 6| Step: 2
Training loss: 2.302683951850665
Validation loss: 2.4894964343963113

Epoch: 6| Step: 3
Training loss: 2.9463832537976584
Validation loss: 2.4909322002754757

Epoch: 6| Step: 4
Training loss: 2.244857633702695
Validation loss: 2.4927708691410873

Epoch: 6| Step: 5
Training loss: 2.4694973743870414
Validation loss: 2.4912170864673846

Epoch: 6| Step: 6
Training loss: 2.3543797849439945
Validation loss: 2.487077510680148

Epoch: 6| Step: 7
Training loss: 2.113649459604392
Validation loss: 2.4965771290147614

Epoch: 6| Step: 8
Training loss: 2.1003947931396945
Validation loss: 2.4925864128609097

Epoch: 6| Step: 9
Training loss: 2.5768463663142898
Validation loss: 2.491264339698601

Epoch: 6| Step: 10
Training loss: 2.224527707497333
Validation loss: 2.4972876935397763

Epoch: 6| Step: 11
Training loss: 2.9453602592178076
Validation loss: 2.492059734262297

Epoch: 6| Step: 12
Training loss: 2.5104177852221854
Validation loss: 2.4881940553919017

Epoch: 6| Step: 13
Training loss: 3.1557536726383772
Validation loss: 2.486200425753525

Epoch: 94| Step: 0
Training loss: 2.307910488891965
Validation loss: 2.4833535387723438

Epoch: 6| Step: 1
Training loss: 2.7401149992930196
Validation loss: 2.4875960991218267

Epoch: 6| Step: 2
Training loss: 2.6718985573248784
Validation loss: 2.4948913193286875

Epoch: 6| Step: 3
Training loss: 2.467901929220644
Validation loss: 2.4902314070141625

Epoch: 6| Step: 4
Training loss: 2.178434716073636
Validation loss: 2.4864333480860257

Epoch: 6| Step: 5
Training loss: 3.0262663468396434
Validation loss: 2.483018692830138

Epoch: 6| Step: 6
Training loss: 2.2475561008940934
Validation loss: 2.4817019463365546

Epoch: 6| Step: 7
Training loss: 2.6303775745494
Validation loss: 2.481681002858779

Epoch: 6| Step: 8
Training loss: 2.6998662986147126
Validation loss: 2.482055124742957

Epoch: 6| Step: 9
Training loss: 2.7410375025847733
Validation loss: 2.4839469492924793

Epoch: 6| Step: 10
Training loss: 2.4853227834777782
Validation loss: 2.4821329056179953

Epoch: 6| Step: 11
Training loss: 2.977352167746727
Validation loss: 2.480863973214564

Epoch: 6| Step: 12
Training loss: 2.5767093355199884
Validation loss: 2.4853623065828674

Epoch: 6| Step: 13
Training loss: 2.3987360964119193
Validation loss: 2.486090525631299

Epoch: 95| Step: 0
Training loss: 2.900238382473223
Validation loss: 2.4869494424744607

Epoch: 6| Step: 1
Training loss: 2.996333902176545
Validation loss: 2.4839679696479706

Epoch: 6| Step: 2
Training loss: 2.040911424523128
Validation loss: 2.486301802550545

Epoch: 6| Step: 3
Training loss: 2.5927440117209684
Validation loss: 2.4850333279243104

Epoch: 6| Step: 4
Training loss: 2.1454081314676765
Validation loss: 2.4820308702512808

Epoch: 6| Step: 5
Training loss: 2.7994384100261147
Validation loss: 2.483865697706902

Epoch: 6| Step: 6
Training loss: 2.6824061890878563
Validation loss: 2.487125881055019

Epoch: 6| Step: 7
Training loss: 2.172411735681939
Validation loss: 2.4865081234503985

Epoch: 6| Step: 8
Training loss: 2.6097423728862843
Validation loss: 2.486436208736546

Epoch: 6| Step: 9
Training loss: 2.3800804610235438
Validation loss: 2.486905742313679

Epoch: 6| Step: 10
Training loss: 2.7816524428759544
Validation loss: 2.4884668717149365

Epoch: 6| Step: 11
Training loss: 3.1974180414762796
Validation loss: 2.491027450433755

Epoch: 6| Step: 12
Training loss: 2.467305303929587
Validation loss: 2.4958117210798307

Epoch: 6| Step: 13
Training loss: 2.2435531444848116
Validation loss: 2.499264418151056

Epoch: 96| Step: 0
Training loss: 2.992170607715862
Validation loss: 2.5062255908922153

Epoch: 6| Step: 1
Training loss: 2.961548754724684
Validation loss: 2.5087725583240545

Epoch: 6| Step: 2
Training loss: 2.2566624652742675
Validation loss: 2.5135580223321785

Epoch: 6| Step: 3
Training loss: 2.5292610548863177
Validation loss: 2.507402443957846

Epoch: 6| Step: 4
Training loss: 2.7494911243207363
Validation loss: 2.5158382507036925

Epoch: 6| Step: 5
Training loss: 2.548868534162435
Validation loss: 2.512369960374012

Epoch: 6| Step: 6
Training loss: 2.4087321372525428
Validation loss: 2.502731595217187

Epoch: 6| Step: 7
Training loss: 2.623183575644908
Validation loss: 2.4960293550099877

Epoch: 6| Step: 8
Training loss: 2.800852924956748
Validation loss: 2.492282893508648

Epoch: 6| Step: 9
Training loss: 2.7325056389055065
Validation loss: 2.4890902415308305

Epoch: 6| Step: 10
Training loss: 2.979040040924205
Validation loss: 2.4910573439713453

Epoch: 6| Step: 11
Training loss: 2.5768133352498936
Validation loss: 2.483539056790716

Epoch: 6| Step: 12
Training loss: 1.759354656637146
Validation loss: 2.484380158233086

Epoch: 6| Step: 13
Training loss: 2.316290352351994
Validation loss: 2.4829233354876994

Epoch: 97| Step: 0
Training loss: 2.6429405217660533
Validation loss: 2.4839932130361526

Epoch: 6| Step: 1
Training loss: 2.4759280959613608
Validation loss: 2.483741423552549

Epoch: 6| Step: 2
Training loss: 2.157558431176697
Validation loss: 2.487102442909926

Epoch: 6| Step: 3
Training loss: 2.447607261637467
Validation loss: 2.4837816277537903

Epoch: 6| Step: 4
Training loss: 2.7987620205469863
Validation loss: 2.481947018326066

Epoch: 6| Step: 5
Training loss: 2.3074504260919824
Validation loss: 2.47887288017106

Epoch: 6| Step: 6
Training loss: 3.0053459854378666
Validation loss: 2.4905138604396795

Epoch: 6| Step: 7
Training loss: 2.65478654825982
Validation loss: 2.4974022083910477

Epoch: 6| Step: 8
Training loss: 2.5092900281987482
Validation loss: 2.4912012554375833

Epoch: 6| Step: 9
Training loss: 2.3946901551831408
Validation loss: 2.4937473625354

Epoch: 6| Step: 10
Training loss: 2.621956650527635
Validation loss: 2.503164402671051

Epoch: 6| Step: 11
Training loss: 2.6318865769420876
Validation loss: 2.4945713070660847

Epoch: 6| Step: 12
Training loss: 2.9515206959532128
Validation loss: 2.4842289335868815

Epoch: 6| Step: 13
Training loss: 2.811208386009314
Validation loss: 2.4794139311336494

Epoch: 98| Step: 0
Training loss: 2.7403373019191988
Validation loss: 2.4836124393463517

Epoch: 6| Step: 1
Training loss: 2.332000169914331
Validation loss: 2.4822807842170302

Epoch: 6| Step: 2
Training loss: 2.6093725330089854
Validation loss: 2.4882065279214713

Epoch: 6| Step: 3
Training loss: 2.4367760781469636
Validation loss: 2.493285842951521

Epoch: 6| Step: 4
Training loss: 3.0784555635279536
Validation loss: 2.4918263013176327

Epoch: 6| Step: 5
Training loss: 2.36624207202613
Validation loss: 2.504939032426276

Epoch: 6| Step: 6
Training loss: 3.002469635745584
Validation loss: 2.5054265731530236

Epoch: 6| Step: 7
Training loss: 2.3353295188885
Validation loss: 2.507803690133312

Epoch: 6| Step: 8
Training loss: 2.9966943330375186
Validation loss: 2.5134352795223784

Epoch: 6| Step: 9
Training loss: 2.6510922789972877
Validation loss: 2.519568241449116

Epoch: 6| Step: 10
Training loss: 2.2212794754571425
Validation loss: 2.5249967373616005

Epoch: 6| Step: 11
Training loss: 3.038807679307199
Validation loss: 2.526841818854034

Epoch: 6| Step: 12
Training loss: 2.416991792929261
Validation loss: 2.52044656376873

Epoch: 6| Step: 13
Training loss: 2.16989132973832
Validation loss: 2.5161731035990327

Epoch: 99| Step: 0
Training loss: 2.7189999169549233
Validation loss: 2.512289200981464

Epoch: 6| Step: 1
Training loss: 2.8512852364135104
Validation loss: 2.5084307612595573

Epoch: 6| Step: 2
Training loss: 2.5020360285225514
Validation loss: 2.5034219210916966

Epoch: 6| Step: 3
Training loss: 2.6101216601375103
Validation loss: 2.502029310580763

Epoch: 6| Step: 4
Training loss: 2.1264749905577376
Validation loss: 2.4997012436693167

Epoch: 6| Step: 5
Training loss: 2.4648172464774576
Validation loss: 2.4969412370345876

Epoch: 6| Step: 6
Training loss: 2.8244221931932967
Validation loss: 2.4928242379222585

Epoch: 6| Step: 7
Training loss: 2.5970333413740563
Validation loss: 2.489359032862806

Epoch: 6| Step: 8
Training loss: 2.6351608534183777
Validation loss: 2.489362744144679

Epoch: 6| Step: 9
Training loss: 2.9928658217035378
Validation loss: 2.488104909320495

Epoch: 6| Step: 10
Training loss: 2.4706952121291272
Validation loss: 2.480895046337465

Epoch: 6| Step: 11
Training loss: 2.789920194161263
Validation loss: 2.4764611096089926

Epoch: 6| Step: 12
Training loss: 2.5160518307828132
Validation loss: 2.4751533647023582

Epoch: 6| Step: 13
Training loss: 2.2764547454739614
Validation loss: 2.4777435952077727

Epoch: 100| Step: 0
Training loss: 2.4622270384411276
Validation loss: 2.475920617067161

Epoch: 6| Step: 1
Training loss: 2.8710127008117983
Validation loss: 2.4765262701390927

Epoch: 6| Step: 2
Training loss: 2.6885872349405466
Validation loss: 2.4776224381197656

Epoch: 6| Step: 3
Training loss: 2.9060135611882574
Validation loss: 2.4743096085506076

Epoch: 6| Step: 4
Training loss: 3.077964972194478
Validation loss: 2.474848413802399

Epoch: 6| Step: 5
Training loss: 2.357707767170214
Validation loss: 2.4744890681053766

Epoch: 6| Step: 6
Training loss: 2.878644871848171
Validation loss: 2.482534306478976

Epoch: 6| Step: 7
Training loss: 1.740381373780584
Validation loss: 2.4835742723681773

Epoch: 6| Step: 8
Training loss: 2.3313762313580177
Validation loss: 2.486787883865369

Epoch: 6| Step: 9
Training loss: 2.204721724408792
Validation loss: 2.4767879379466264

Epoch: 6| Step: 10
Training loss: 2.7362768044515953
Validation loss: 2.4782471166910973

Epoch: 6| Step: 11
Training loss: 2.6095822189193054
Validation loss: 2.479398673819356

Epoch: 6| Step: 12
Training loss: 2.8211514818046504
Validation loss: 2.4803035971461056

Epoch: 6| Step: 13
Training loss: 2.1793328547033277
Validation loss: 2.4810550026937332

Epoch: 101| Step: 0
Training loss: 2.337679210463646
Validation loss: 2.4875179539324885

Epoch: 6| Step: 1
Training loss: 2.2203696343562678
Validation loss: 2.487126136684559

Epoch: 6| Step: 2
Training loss: 2.964552793437095
Validation loss: 2.4849998839856124

Epoch: 6| Step: 3
Training loss: 2.520031404753684
Validation loss: 2.4906248098235335

Epoch: 6| Step: 4
Training loss: 2.548363560692112
Validation loss: 2.4853403307268103

Epoch: 6| Step: 5
Training loss: 1.923752588638438
Validation loss: 2.485012476484881

Epoch: 6| Step: 6
Training loss: 2.5745906763753545
Validation loss: 2.4831214797350825

Epoch: 6| Step: 7
Training loss: 2.4579832722193227
Validation loss: 2.4832115568048163

Epoch: 6| Step: 8
Training loss: 2.879990268796799
Validation loss: 2.4770476851746945

Epoch: 6| Step: 9
Training loss: 2.9885277739918044
Validation loss: 2.483740439637357

Epoch: 6| Step: 10
Training loss: 2.2948940324108906
Validation loss: 2.4783003492881854

Epoch: 6| Step: 11
Training loss: 2.442381153006983
Validation loss: 2.4720480574171964

Epoch: 6| Step: 12
Training loss: 3.1218942086026926
Validation loss: 2.4770282905009253

Epoch: 6| Step: 13
Training loss: 2.649941346581057
Validation loss: 2.47653308935181

Epoch: 102| Step: 0
Training loss: 1.854694020003546
Validation loss: 2.4720668321225188

Epoch: 6| Step: 1
Training loss: 3.0846151488403017
Validation loss: 2.473360528830683

Epoch: 6| Step: 2
Training loss: 2.289539274486573
Validation loss: 2.472259111938802

Epoch: 6| Step: 3
Training loss: 2.6485518259224547
Validation loss: 2.4705664635860116

Epoch: 6| Step: 4
Training loss: 2.6115498873031875
Validation loss: 2.4744168040781576

Epoch: 6| Step: 5
Training loss: 2.7912253320392333
Validation loss: 2.469544407633399

Epoch: 6| Step: 6
Training loss: 1.17164945339258
Validation loss: 2.4705990655066845

Epoch: 6| Step: 7
Training loss: 2.150572336888528
Validation loss: 2.471770101154849

Epoch: 6| Step: 8
Training loss: 3.088925385507304
Validation loss: 2.4689220094915147

Epoch: 6| Step: 9
Training loss: 2.5759376263204827
Validation loss: 2.4702906569613634

Epoch: 6| Step: 10
Training loss: 2.4210252809398143
Validation loss: 2.472042109920874

Epoch: 6| Step: 11
Training loss: 2.8621824063354575
Validation loss: 2.4721577941938313

Epoch: 6| Step: 12
Training loss: 3.042278402466282
Validation loss: 2.475119281553166

Epoch: 6| Step: 13
Training loss: 2.7231084155334364
Validation loss: 2.4791352780275755

Epoch: 103| Step: 0
Training loss: 3.178880893833963
Validation loss: 2.473804691295466

Epoch: 6| Step: 1
Training loss: 2.617510693081034
Validation loss: 2.4760905557207713

Epoch: 6| Step: 2
Training loss: 2.820895063512747
Validation loss: 2.475269930983627

Epoch: 6| Step: 3
Training loss: 2.207205166336213
Validation loss: 2.4725639643429314

Epoch: 6| Step: 4
Training loss: 2.285715409687311
Validation loss: 2.477025290649486

Epoch: 6| Step: 5
Training loss: 2.4578193407393973
Validation loss: 2.4762117075250063

Epoch: 6| Step: 6
Training loss: 2.2631011585748593
Validation loss: 2.4741318544804147

Epoch: 6| Step: 7
Training loss: 2.46950065692801
Validation loss: 2.476705906002215

Epoch: 6| Step: 8
Training loss: 2.687498669291322
Validation loss: 2.489578380074355

Epoch: 6| Step: 9
Training loss: 2.97073522747283
Validation loss: 2.4803447702416976

Epoch: 6| Step: 10
Training loss: 2.741390014495998
Validation loss: 2.482247615353435

Epoch: 6| Step: 11
Training loss: 2.129669780475567
Validation loss: 2.47327909012545

Epoch: 6| Step: 12
Training loss: 2.0737193740321587
Validation loss: 2.473989536021705

Epoch: 6| Step: 13
Training loss: 2.9921008065117265
Validation loss: 2.4786547818910445

Epoch: 104| Step: 0
Training loss: 2.5884252838027026
Validation loss: 2.4779950881136537

Epoch: 6| Step: 1
Training loss: 2.6486812693169903
Validation loss: 2.475568906987566

Epoch: 6| Step: 2
Training loss: 2.591318668498999
Validation loss: 2.485256606450817

Epoch: 6| Step: 3
Training loss: 2.7308519610213065
Validation loss: 2.4785663668681726

Epoch: 6| Step: 4
Training loss: 2.227065715476264
Validation loss: 2.4809860050616996

Epoch: 6| Step: 5
Training loss: 2.0539874490653465
Validation loss: 2.481514417458472

Epoch: 6| Step: 6
Training loss: 2.2999996807264025
Validation loss: 2.4799919411056592

Epoch: 6| Step: 7
Training loss: 2.979032357840797
Validation loss: 2.4782770361168134

Epoch: 6| Step: 8
Training loss: 2.4379585030507913
Validation loss: 2.478472770158099

Epoch: 6| Step: 9
Training loss: 2.3230617688851205
Validation loss: 2.479870901875103

Epoch: 6| Step: 10
Training loss: 2.7702568620924333
Validation loss: 2.4716642538287408

Epoch: 6| Step: 11
Training loss: 2.8991093024090095
Validation loss: 2.473687943523021

Epoch: 6| Step: 12
Training loss: 2.816275457342488
Validation loss: 2.4757056132726443

Epoch: 6| Step: 13
Training loss: 2.6254148609579158
Validation loss: 2.4756619072467703

Epoch: 105| Step: 0
Training loss: 2.9834976904009713
Validation loss: 2.4780136654230454

Epoch: 6| Step: 1
Training loss: 2.2349178481738288
Validation loss: 2.4750435680831786

Epoch: 6| Step: 2
Training loss: 2.434954071708406
Validation loss: 2.4712647454364225

Epoch: 6| Step: 3
Training loss: 2.2572229797118317
Validation loss: 2.4718105322223223

Epoch: 6| Step: 4
Training loss: 2.797239397062096
Validation loss: 2.474915286582736

Epoch: 6| Step: 5
Training loss: 2.3550445022751765
Validation loss: 2.4722962963660624

Epoch: 6| Step: 6
Training loss: 2.5355574139094066
Validation loss: 2.475507228585732

Epoch: 6| Step: 7
Training loss: 2.364365611086704
Validation loss: 2.4728805496505006

Epoch: 6| Step: 8
Training loss: 2.8844508862664315
Validation loss: 2.4718017387223727

Epoch: 6| Step: 9
Training loss: 2.84594105581336
Validation loss: 2.466704974220706

Epoch: 6| Step: 10
Training loss: 2.378231660754342
Validation loss: 2.469166507272482

Epoch: 6| Step: 11
Training loss: 2.520535243881627
Validation loss: 2.473934572339979

Epoch: 6| Step: 12
Training loss: 2.819125530661839
Validation loss: 2.4640177669266476

Epoch: 6| Step: 13
Training loss: 2.349381966180969
Validation loss: 2.474290256653395

Epoch: 106| Step: 0
Training loss: 2.8617070594859153
Validation loss: 2.4753768120291455

Epoch: 6| Step: 1
Training loss: 2.6055012347757054
Validation loss: 2.4737863474175934

Epoch: 6| Step: 2
Training loss: 2.671774165163708
Validation loss: 2.4784121660864833

Epoch: 6| Step: 3
Training loss: 2.2882720311514113
Validation loss: 2.4789059499216846

Epoch: 6| Step: 4
Training loss: 2.198196092051969
Validation loss: 2.4774134925754288

Epoch: 6| Step: 5
Training loss: 2.532606350171056
Validation loss: 2.4763935083600677

Epoch: 6| Step: 6
Training loss: 2.752119807873496
Validation loss: 2.4752875735769573

Epoch: 6| Step: 7
Training loss: 1.957166838374706
Validation loss: 2.477191544316892

Epoch: 6| Step: 8
Training loss: 2.926170740826272
Validation loss: 2.473515542542809

Epoch: 6| Step: 9
Training loss: 2.1868795332380584
Validation loss: 2.4709197380392736

Epoch: 6| Step: 10
Training loss: 2.377915951416949
Validation loss: 2.474948995238053

Epoch: 6| Step: 11
Training loss: 2.3618676363609907
Validation loss: 2.4722696155715393

Epoch: 6| Step: 12
Training loss: 2.953339422605737
Validation loss: 2.4749064238355256

Epoch: 6| Step: 13
Training loss: 2.947179875222913
Validation loss: 2.4728603027742064

Epoch: 107| Step: 0
Training loss: 2.953789853131052
Validation loss: 2.4799581167314475

Epoch: 6| Step: 1
Training loss: 2.1116130117912615
Validation loss: 2.4757975491000965

Epoch: 6| Step: 2
Training loss: 2.4365297978687024
Validation loss: 2.4773484355810425

Epoch: 6| Step: 3
Training loss: 2.8244062390491798
Validation loss: 2.4765376301348043

Epoch: 6| Step: 4
Training loss: 2.251796958517556
Validation loss: 2.4747132578348796

Epoch: 6| Step: 5
Training loss: 2.3652261092831415
Validation loss: 2.476832723065035

Epoch: 6| Step: 6
Training loss: 2.488159943263149
Validation loss: 2.4735685315811584

Epoch: 6| Step: 7
Training loss: 2.1874881199105416
Validation loss: 2.474219030732152

Epoch: 6| Step: 8
Training loss: 3.1860038387469425
Validation loss: 2.472278407407326

Epoch: 6| Step: 9
Training loss: 2.5340332929777056
Validation loss: 2.4724699073711363

Epoch: 6| Step: 10
Training loss: 2.453702044802997
Validation loss: 2.4692048164902616

Epoch: 6| Step: 11
Training loss: 2.9592586377639694
Validation loss: 2.4682889660778673

Epoch: 6| Step: 12
Training loss: 2.0718835016366746
Validation loss: 2.474981130020699

Epoch: 6| Step: 13
Training loss: 2.6458956693580045
Validation loss: 2.4643020961709268

Epoch: 108| Step: 0
Training loss: 2.695482331605978
Validation loss: 2.4677362090748147

Epoch: 6| Step: 1
Training loss: 2.345038504863925
Validation loss: 2.4650610874800942

Epoch: 6| Step: 2
Training loss: 2.0423927443322034
Validation loss: 2.4660963290494977

Epoch: 6| Step: 3
Training loss: 2.56099898873711
Validation loss: 2.4633178905016764

Epoch: 6| Step: 4
Training loss: 2.75667715071407
Validation loss: 2.4681692526804184

Epoch: 6| Step: 5
Training loss: 2.5372528669908854
Validation loss: 2.4746587518042706

Epoch: 6| Step: 6
Training loss: 2.0717275713772993
Validation loss: 2.4775639704283106

Epoch: 6| Step: 7
Training loss: 2.710002111173701
Validation loss: 2.4720054440937362

Epoch: 6| Step: 8
Training loss: 2.196554789533011
Validation loss: 2.470990383652825

Epoch: 6| Step: 9
Training loss: 2.30623902935944
Validation loss: 2.4660059490766333

Epoch: 6| Step: 10
Training loss: 3.23200850595167
Validation loss: 2.460926641208165

Epoch: 6| Step: 11
Training loss: 2.300251665029969
Validation loss: 2.465350051202546

Epoch: 6| Step: 12
Training loss: 3.027601110532408
Validation loss: 2.471111166409546

Epoch: 6| Step: 13
Training loss: 2.775154549358855
Validation loss: 2.4720745798617485

Epoch: 109| Step: 0
Training loss: 2.6556571747699715
Validation loss: 2.4782507884942975

Epoch: 6| Step: 1
Training loss: 2.66387813523073
Validation loss: 2.478080244329637

Epoch: 6| Step: 2
Training loss: 2.6077821175535036
Validation loss: 2.4783899843051533

Epoch: 6| Step: 3
Training loss: 2.4069761691528293
Validation loss: 2.4790042909505807

Epoch: 6| Step: 4
Training loss: 2.33452142258793
Validation loss: 2.481429523216115

Epoch: 6| Step: 5
Training loss: 2.263196604011283
Validation loss: 2.4832577942447105

Epoch: 6| Step: 6
Training loss: 2.0814058033587814
Validation loss: 2.476490842021191

Epoch: 6| Step: 7
Training loss: 2.3109786725712866
Validation loss: 2.4775457987319736

Epoch: 6| Step: 8
Training loss: 2.3585353140274683
Validation loss: 2.4766844068621774

Epoch: 6| Step: 9
Training loss: 2.755045943110772
Validation loss: 2.471001736936598

Epoch: 6| Step: 10
Training loss: 3.0547722612021437
Validation loss: 2.4746939813511593

Epoch: 6| Step: 11
Training loss: 2.5265369572053102
Validation loss: 2.469259281985665

Epoch: 6| Step: 12
Training loss: 2.949380428101463
Validation loss: 2.471986476025834

Epoch: 6| Step: 13
Training loss: 2.7351793250619933
Validation loss: 2.4678980810068936

Epoch: 110| Step: 0
Training loss: 2.6240327051962318
Validation loss: 2.4678348019871357

Epoch: 6| Step: 1
Training loss: 2.3127709307347666
Validation loss: 2.4658324630991886

Epoch: 6| Step: 2
Training loss: 2.042069596474842
Validation loss: 2.464680323193107

Epoch: 6| Step: 3
Training loss: 2.4020319046201255
Validation loss: 2.468515553991601

Epoch: 6| Step: 4
Training loss: 2.6561598818582373
Validation loss: 2.47199546176428

Epoch: 6| Step: 5
Training loss: 2.7488640259619133
Validation loss: 2.4691580584046955

Epoch: 6| Step: 6
Training loss: 2.8173985525448537
Validation loss: 2.4717936686089668

Epoch: 6| Step: 7
Training loss: 2.3804772111762986
Validation loss: 2.4645858363710937

Epoch: 6| Step: 8
Training loss: 2.5033718258894795
Validation loss: 2.470208940098656

Epoch: 6| Step: 9
Training loss: 2.7860352572300315
Validation loss: 2.4701005887001473

Epoch: 6| Step: 10
Training loss: 2.9220639743994994
Validation loss: 2.471943749115974

Epoch: 6| Step: 11
Training loss: 2.2768725894200026
Validation loss: 2.476575608725206

Epoch: 6| Step: 12
Training loss: 2.68122370424692
Validation loss: 2.4807025308652046

Epoch: 6| Step: 13
Training loss: 2.44370507006306
Validation loss: 2.4790539168249297

Epoch: 111| Step: 0
Training loss: 2.783891602072071
Validation loss: 2.4819932793232446

Epoch: 6| Step: 1
Training loss: 3.070008706940969
Validation loss: 2.4834691281494923

Epoch: 6| Step: 2
Training loss: 2.518524962564506
Validation loss: 2.48282437346692

Epoch: 6| Step: 3
Training loss: 2.802074607258839
Validation loss: 2.4807016178267047

Epoch: 6| Step: 4
Training loss: 2.4341977565425004
Validation loss: 2.47877504691023

Epoch: 6| Step: 5
Training loss: 2.351210051323432
Validation loss: 2.4742825720613553

Epoch: 6| Step: 6
Training loss: 2.8006889721766806
Validation loss: 2.466687817955404

Epoch: 6| Step: 7
Training loss: 2.335400165518849
Validation loss: 2.466092937241912

Epoch: 6| Step: 8
Training loss: 2.3700106565018593
Validation loss: 2.466710145240648

Epoch: 6| Step: 9
Training loss: 2.26868290237116
Validation loss: 2.4643890880440344

Epoch: 6| Step: 10
Training loss: 2.6562254063084807
Validation loss: 2.4675922334819336

Epoch: 6| Step: 11
Training loss: 2.213487859333764
Validation loss: 2.464391893662227

Epoch: 6| Step: 12
Training loss: 2.9049374477460583
Validation loss: 2.4623406421586815

Epoch: 6| Step: 13
Training loss: 2.3436572247262863
Validation loss: 2.4709884860733955

Epoch: 112| Step: 0
Training loss: 2.821124015567582
Validation loss: 2.4647647544748628

Epoch: 6| Step: 1
Training loss: 2.3695769383886565
Validation loss: 2.4703516050424907

Epoch: 6| Step: 2
Training loss: 2.2211782572875536
Validation loss: 2.473757208964166

Epoch: 6| Step: 3
Training loss: 2.894595167352652
Validation loss: 2.471071141996149

Epoch: 6| Step: 4
Training loss: 2.843165075489704
Validation loss: 2.475807435850297

Epoch: 6| Step: 5
Training loss: 2.2742794614529283
Validation loss: 2.472945852731431

Epoch: 6| Step: 6
Training loss: 2.762136986127418
Validation loss: 2.47519195852607

Epoch: 6| Step: 7
Training loss: 2.202777591666296
Validation loss: 2.4772836495636725

Epoch: 6| Step: 8
Training loss: 2.348356678803573
Validation loss: 2.472322012522008

Epoch: 6| Step: 9
Training loss: 2.7402804011247333
Validation loss: 2.469217401031143

Epoch: 6| Step: 10
Training loss: 3.0434425778399983
Validation loss: 2.473321127227352

Epoch: 6| Step: 11
Training loss: 1.844206414062281
Validation loss: 2.4681039922661725

Epoch: 6| Step: 12
Training loss: 2.693437980406617
Validation loss: 2.465448997414081

Epoch: 6| Step: 13
Training loss: 2.5680168126467984
Validation loss: 2.468378159731794

Epoch: 113| Step: 0
Training loss: 2.3782222372018733
Validation loss: 2.466373168607456

Epoch: 6| Step: 1
Training loss: 2.5435788408661817
Validation loss: 2.4639669512291085

Epoch: 6| Step: 2
Training loss: 2.245358660282509
Validation loss: 2.463783056088042

Epoch: 6| Step: 3
Training loss: 2.8686441572356594
Validation loss: 2.460636156796642

Epoch: 6| Step: 4
Training loss: 2.7846488329908663
Validation loss: 2.466364629614028

Epoch: 6| Step: 5
Training loss: 2.8120991739119043
Validation loss: 2.4636317768244043

Epoch: 6| Step: 6
Training loss: 2.5428717106881
Validation loss: 2.4613399923264816

Epoch: 6| Step: 7
Training loss: 2.732492899977106
Validation loss: 2.460731618837184

Epoch: 6| Step: 8
Training loss: 2.1976052254924716
Validation loss: 2.4631665988014144

Epoch: 6| Step: 9
Training loss: 2.184064619855006
Validation loss: 2.461676439224126

Epoch: 6| Step: 10
Training loss: 2.6277196510325465
Validation loss: 2.4669506259663176

Epoch: 6| Step: 11
Training loss: 2.3710064691256627
Validation loss: 2.4667743551958505

Epoch: 6| Step: 12
Training loss: 2.696469266037636
Validation loss: 2.460704618869085

Epoch: 6| Step: 13
Training loss: 2.633550704563533
Validation loss: 2.4703216057130435

Epoch: 114| Step: 0
Training loss: 2.5214009762422966
Validation loss: 2.4645676737847046

Epoch: 6| Step: 1
Training loss: 2.564348531015097
Validation loss: 2.4638738159622737

Epoch: 6| Step: 2
Training loss: 2.276654356685365
Validation loss: 2.468741871623247

Epoch: 6| Step: 3
Training loss: 2.491773038739065
Validation loss: 2.4664907781507304

Epoch: 6| Step: 4
Training loss: 2.5847107896296313
Validation loss: 2.4703573314146405

Epoch: 6| Step: 5
Training loss: 2.692380864333263
Validation loss: 2.4735501457905884

Epoch: 6| Step: 6
Training loss: 2.6314856018275554
Validation loss: 2.4685092921348377

Epoch: 6| Step: 7
Training loss: 2.961350706553033
Validation loss: 2.4664284296803656

Epoch: 6| Step: 8
Training loss: 2.3070388437282427
Validation loss: 2.4599216362636893

Epoch: 6| Step: 9
Training loss: 1.8019234103058532
Validation loss: 2.462245629819442

Epoch: 6| Step: 10
Training loss: 2.6733626301112228
Validation loss: 2.464183801645823

Epoch: 6| Step: 11
Training loss: 2.9237764260939505
Validation loss: 2.460120252109865

Epoch: 6| Step: 12
Training loss: 2.5081971250877273
Validation loss: 2.4647848663309353

Epoch: 6| Step: 13
Training loss: 2.4943463293696495
Validation loss: 2.465363912614878

Epoch: 115| Step: 0
Training loss: 2.3967150738018512
Validation loss: 2.4615387520155676

Epoch: 6| Step: 1
Training loss: 2.733674488254436
Validation loss: 2.460446893138661

Epoch: 6| Step: 2
Training loss: 3.280953384798421
Validation loss: 2.4603175436968185

Epoch: 6| Step: 3
Training loss: 2.314132320527852
Validation loss: 2.456744283910496

Epoch: 6| Step: 4
Training loss: 2.3982520016188964
Validation loss: 2.4664891590437197

Epoch: 6| Step: 5
Training loss: 3.0367237496341013
Validation loss: 2.4616039604881848

Epoch: 6| Step: 6
Training loss: 2.659716419936298
Validation loss: 2.4654437834556244

Epoch: 6| Step: 7
Training loss: 2.5809839291639416
Validation loss: 2.4627115304010365

Epoch: 6| Step: 8
Training loss: 1.6752624419990898
Validation loss: 2.4639613228947472

Epoch: 6| Step: 9
Training loss: 2.234602589787152
Validation loss: 2.4601035829513145

Epoch: 6| Step: 10
Training loss: 2.827887762246199
Validation loss: 2.4636231960707

Epoch: 6| Step: 11
Training loss: 2.333749926934346
Validation loss: 2.462571262806589

Epoch: 6| Step: 12
Training loss: 2.203170992323845
Validation loss: 2.4624540873344465

Epoch: 6| Step: 13
Training loss: 2.5493567609122856
Validation loss: 2.4657943835012563

Epoch: 116| Step: 0
Training loss: 2.8080247666117164
Validation loss: 2.4639743857714085

Epoch: 6| Step: 1
Training loss: 3.347717213381603
Validation loss: 2.468040847329005

Epoch: 6| Step: 2
Training loss: 2.760983726749178
Validation loss: 2.4673680328616574

Epoch: 6| Step: 3
Training loss: 2.4260833601250966
Validation loss: 2.4686005945507383

Epoch: 6| Step: 4
Training loss: 2.0857582729650597
Validation loss: 2.4668872582113566

Epoch: 6| Step: 5
Training loss: 1.5823112334229648
Validation loss: 2.469199594369749

Epoch: 6| Step: 6
Training loss: 2.5164849369379687
Validation loss: 2.4669992379500614

Epoch: 6| Step: 7
Training loss: 3.3158034640648846
Validation loss: 2.460286210682515

Epoch: 6| Step: 8
Training loss: 2.8398981522041558
Validation loss: 2.461222193160325

Epoch: 6| Step: 9
Training loss: 2.259397062877182
Validation loss: 2.467256126230509

Epoch: 6| Step: 10
Training loss: 2.43668743185579
Validation loss: 2.4649914970792937

Epoch: 6| Step: 11
Training loss: 2.1427029735873377
Validation loss: 2.465351388993413

Epoch: 6| Step: 12
Training loss: 2.439192844307307
Validation loss: 2.4642144723365313

Epoch: 6| Step: 13
Training loss: 2.021286458080021
Validation loss: 2.4621928651204703

Epoch: 117| Step: 0
Training loss: 2.5346833480106774
Validation loss: 2.4645911488821577

Epoch: 6| Step: 1
Training loss: 2.681320093479156
Validation loss: 2.462992525627059

Epoch: 6| Step: 2
Training loss: 2.755462596292657
Validation loss: 2.4545362912005926

Epoch: 6| Step: 3
Training loss: 2.3767163951035273
Validation loss: 2.4627868162578705

Epoch: 6| Step: 4
Training loss: 2.7736034075046816
Validation loss: 2.4601747006769976

Epoch: 6| Step: 5
Training loss: 2.1093461776459685
Validation loss: 2.4659668247521083

Epoch: 6| Step: 6
Training loss: 2.6729105231040307
Validation loss: 2.45782299455818

Epoch: 6| Step: 7
Training loss: 2.8031214004884744
Validation loss: 2.46674428014394

Epoch: 6| Step: 8
Training loss: 3.207119567621467
Validation loss: 2.469763736789494

Epoch: 6| Step: 9
Training loss: 2.01893143443825
Validation loss: 2.465823422672337

Epoch: 6| Step: 10
Training loss: 2.276593930584497
Validation loss: 2.4748450018774037

Epoch: 6| Step: 11
Training loss: 1.883081630608724
Validation loss: 2.476434569960583

Epoch: 6| Step: 12
Training loss: 2.778182663549742
Validation loss: 2.477684464809719

Epoch: 6| Step: 13
Training loss: 2.521232279165363
Validation loss: 2.478260104267527

Epoch: 118| Step: 0
Training loss: 2.3640331238751306
Validation loss: 2.4783906015818404

Epoch: 6| Step: 1
Training loss: 2.6133358982456363
Validation loss: 2.4803856062283374

Epoch: 6| Step: 2
Training loss: 2.7676911475686876
Validation loss: 2.475734961524283

Epoch: 6| Step: 3
Training loss: 2.4302501946833672
Validation loss: 2.475514299408289

Epoch: 6| Step: 4
Training loss: 2.478542366815448
Validation loss: 2.476987318953866

Epoch: 6| Step: 5
Training loss: 2.203500810318762
Validation loss: 2.477811752988283

Epoch: 6| Step: 6
Training loss: 2.8675450406116596
Validation loss: 2.473622732321402

Epoch: 6| Step: 7
Training loss: 2.13632929458907
Validation loss: 2.4703340558811226

Epoch: 6| Step: 8
Training loss: 2.5973114932171404
Validation loss: 2.4669948728972266

Epoch: 6| Step: 9
Training loss: 3.098404282907864
Validation loss: 2.4678596468440834

Epoch: 6| Step: 10
Training loss: 2.1272869145943605
Validation loss: 2.4605317442293964

Epoch: 6| Step: 11
Training loss: 2.5664372783393525
Validation loss: 2.459282083141595

Epoch: 6| Step: 12
Training loss: 2.122181313249684
Validation loss: 2.4577610729129646

Epoch: 6| Step: 13
Training loss: 2.921706740486592
Validation loss: 2.456634489449997

Epoch: 119| Step: 0
Training loss: 2.45335727248053
Validation loss: 2.46706846568902

Epoch: 6| Step: 1
Training loss: 2.6140033539660767
Validation loss: 2.4598063296295676

Epoch: 6| Step: 2
Training loss: 2.6090583837606673
Validation loss: 2.4648602742539496

Epoch: 6| Step: 3
Training loss: 2.3712170237338084
Validation loss: 2.455596262199812

Epoch: 6| Step: 4
Training loss: 2.437143935582004
Validation loss: 2.467776770640433

Epoch: 6| Step: 5
Training loss: 2.2837496088003606
Validation loss: 2.4647781435884877

Epoch: 6| Step: 6
Training loss: 2.3611011380253015
Validation loss: 2.4604923390620193

Epoch: 6| Step: 7
Training loss: 2.596371165034679
Validation loss: 2.4691462621275977

Epoch: 6| Step: 8
Training loss: 2.962435461701418
Validation loss: 2.4691451677907126

Epoch: 6| Step: 9
Training loss: 2.3570955899276025
Validation loss: 2.4657487452227707

Epoch: 6| Step: 10
Training loss: 2.578825884251238
Validation loss: 2.4686238381385017

Epoch: 6| Step: 11
Training loss: 2.4950931077605185
Validation loss: 2.467999340164451

Epoch: 6| Step: 12
Training loss: 2.5782535405337663
Validation loss: 2.474818958699632

Epoch: 6| Step: 13
Training loss: 2.820035714809352
Validation loss: 2.470983742118446

Epoch: 120| Step: 0
Training loss: 2.321046038958689
Validation loss: 2.4625614681414554

Epoch: 6| Step: 1
Training loss: 2.5375905626794975
Validation loss: 2.4672799703298294

Epoch: 6| Step: 2
Training loss: 2.4497190509004754
Validation loss: 2.462195277845093

Epoch: 6| Step: 3
Training loss: 3.004787439835595
Validation loss: 2.4581515573657153

Epoch: 6| Step: 4
Training loss: 2.4588568717253763
Validation loss: 2.4698191070212134

Epoch: 6| Step: 5
Training loss: 2.5334688986929623
Validation loss: 2.4646714478254528

Epoch: 6| Step: 6
Training loss: 2.8320307448814206
Validation loss: 2.4725697739813155

Epoch: 6| Step: 7
Training loss: 2.0888701550791215
Validation loss: 2.472439998031081

Epoch: 6| Step: 8
Training loss: 2.051238439551769
Validation loss: 2.4750926632986645

Epoch: 6| Step: 9
Training loss: 2.5754507355493046
Validation loss: 2.475246597296947

Epoch: 6| Step: 10
Training loss: 3.1666731248756275
Validation loss: 2.4819383648062217

Epoch: 6| Step: 11
Training loss: 2.3806987454786532
Validation loss: 2.4776954586479647

Epoch: 6| Step: 12
Training loss: 2.857953161049347
Validation loss: 2.4729512677962955

Epoch: 6| Step: 13
Training loss: 2.3239256601902256
Validation loss: 2.471185038614351

Epoch: 121| Step: 0
Training loss: 2.4999217974829278
Validation loss: 2.464097125048599

Epoch: 6| Step: 1
Training loss: 2.8409200147938947
Validation loss: 2.4657620725898597

Epoch: 6| Step: 2
Training loss: 2.918344904950909
Validation loss: 2.460259754971076

Epoch: 6| Step: 3
Training loss: 2.069071617365645
Validation loss: 2.470806295580401

Epoch: 6| Step: 4
Training loss: 2.524200890872533
Validation loss: 2.4715609663262685

Epoch: 6| Step: 5
Training loss: 2.627124653147671
Validation loss: 2.475943326515109

Epoch: 6| Step: 6
Training loss: 2.4000973999604422
Validation loss: 2.4682503045658026

Epoch: 6| Step: 7
Training loss: 2.342223216898492
Validation loss: 2.463837012450024

Epoch: 6| Step: 8
Training loss: 2.704475903181367
Validation loss: 2.467095500703648

Epoch: 6| Step: 9
Training loss: 2.3632274779200246
Validation loss: 2.471737032390511

Epoch: 6| Step: 10
Training loss: 2.524977364769125
Validation loss: 2.474717344333796

Epoch: 6| Step: 11
Training loss: 2.813928368573791
Validation loss: 2.476329371313045

Epoch: 6| Step: 12
Training loss: 3.010915923820754
Validation loss: 2.4723844373778014

Epoch: 6| Step: 13
Training loss: 1.8417505964369085
Validation loss: 2.4737287448293097

Epoch: 122| Step: 0
Training loss: 2.554508214603222
Validation loss: 2.4680389152809785

Epoch: 6| Step: 1
Training loss: 2.8183830614475895
Validation loss: 2.46647002772369

Epoch: 6| Step: 2
Training loss: 2.46041360758549
Validation loss: 2.467948026812619

Epoch: 6| Step: 3
Training loss: 2.609180009146436
Validation loss: 2.4643164633444337

Epoch: 6| Step: 4
Training loss: 1.9784438034533232
Validation loss: 2.465416617506047

Epoch: 6| Step: 5
Training loss: 2.4277154211284953
Validation loss: 2.4576244194172747

Epoch: 6| Step: 6
Training loss: 2.5130915234889732
Validation loss: 2.4575980320648587

Epoch: 6| Step: 7
Training loss: 2.5001954002311817
Validation loss: 2.4538818374353797

Epoch: 6| Step: 8
Training loss: 2.01120776751497
Validation loss: 2.4594385012063267

Epoch: 6| Step: 9
Training loss: 2.9334476195815418
Validation loss: 2.458339324771455

Epoch: 6| Step: 10
Training loss: 2.4284362514926094
Validation loss: 2.460237772933398

Epoch: 6| Step: 11
Training loss: 1.9431184705622708
Validation loss: 2.461877859178019

Epoch: 6| Step: 12
Training loss: 3.2152791985622384
Validation loss: 2.458771542647239

Epoch: 6| Step: 13
Training loss: 2.869934927704427
Validation loss: 2.4640227823195042

Epoch: 123| Step: 0
Training loss: 2.683912855163395
Validation loss: 2.463267229747869

Epoch: 6| Step: 1
Training loss: 2.492738477495684
Validation loss: 2.470062518596307

Epoch: 6| Step: 2
Training loss: 2.5653230886743854
Validation loss: 2.4640459481414934

Epoch: 6| Step: 3
Training loss: 2.532301225308123
Validation loss: 2.4687531306250956

Epoch: 6| Step: 4
Training loss: 1.8146030458532179
Validation loss: 2.4633704697937384

Epoch: 6| Step: 5
Training loss: 2.011734393901552
Validation loss: 2.4631591214902167

Epoch: 6| Step: 6
Training loss: 2.3966762773677455
Validation loss: 2.460381532870965

Epoch: 6| Step: 7
Training loss: 3.018001746407845
Validation loss: 2.4585863457345924

Epoch: 6| Step: 8
Training loss: 2.1192205036068605
Validation loss: 2.4580514767809656

Epoch: 6| Step: 9
Training loss: 2.0251545929473367
Validation loss: 2.4585594191819555

Epoch: 6| Step: 10
Training loss: 2.1104951498106477
Validation loss: 2.456451978459837

Epoch: 6| Step: 11
Training loss: 2.858127175803058
Validation loss: 2.457023632723064

Epoch: 6| Step: 12
Training loss: 3.4801837706001155
Validation loss: 2.453620617604082

Epoch: 6| Step: 13
Training loss: 2.8447910960217944
Validation loss: 2.4556194832431504

Epoch: 124| Step: 0
Training loss: 2.956524058375217
Validation loss: 2.4587759707820966

Epoch: 6| Step: 1
Training loss: 2.456064103641244
Validation loss: 2.456175266387574

Epoch: 6| Step: 2
Training loss: 2.489272562419521
Validation loss: 2.4561881118238222

Epoch: 6| Step: 3
Training loss: 2.429523818215489
Validation loss: 2.4527445212596466

Epoch: 6| Step: 4
Training loss: 2.2144958115152873
Validation loss: 2.4606622774134435

Epoch: 6| Step: 5
Training loss: 2.9646896704240304
Validation loss: 2.4512055292136874

Epoch: 6| Step: 6
Training loss: 2.4013032474204037
Validation loss: 2.460467226013395

Epoch: 6| Step: 7
Training loss: 2.4832642189324665
Validation loss: 2.4654549688738214

Epoch: 6| Step: 8
Training loss: 2.145584042583525
Validation loss: 2.4652979654431784

Epoch: 6| Step: 9
Training loss: 2.7441143862735777
Validation loss: 2.459777865602277

Epoch: 6| Step: 10
Training loss: 2.3642414758961605
Validation loss: 2.460995644180223

Epoch: 6| Step: 11
Training loss: 2.428191383662111
Validation loss: 2.4600624587495936

Epoch: 6| Step: 12
Training loss: 2.3004800958864706
Validation loss: 2.4641669342157835

Epoch: 6| Step: 13
Training loss: 2.8933776945530982
Validation loss: 2.463358452229668

Epoch: 125| Step: 0
Training loss: 2.5371999628987463
Validation loss: 2.4626473113275087

Epoch: 6| Step: 1
Training loss: 2.7015456508554516
Validation loss: 2.4628483533950027

Epoch: 6| Step: 2
Training loss: 2.6545300469004793
Validation loss: 2.4674260255082396

Epoch: 6| Step: 3
Training loss: 2.990336271277835
Validation loss: 2.468179548325201

Epoch: 6| Step: 4
Training loss: 2.512392229644124
Validation loss: 2.4649883858572834

Epoch: 6| Step: 5
Training loss: 2.801987987914603
Validation loss: 2.4632860068531284

Epoch: 6| Step: 6
Training loss: 2.571924139135099
Validation loss: 2.4695096356207205

Epoch: 6| Step: 7
Training loss: 1.9103012185970347
Validation loss: 2.4680516828703265

Epoch: 6| Step: 8
Training loss: 2.6686140539488106
Validation loss: 2.464418353387035

Epoch: 6| Step: 9
Training loss: 2.4763233538666296
Validation loss: 2.4622674809648477

Epoch: 6| Step: 10
Training loss: 2.8859186573580358
Validation loss: 2.4613942040414005

Epoch: 6| Step: 11
Training loss: 2.321240172234408
Validation loss: 2.461087604768765

Epoch: 6| Step: 12
Training loss: 1.968455337998323
Validation loss: 2.4572199600923823

Epoch: 6| Step: 13
Training loss: 2.3183290371922447
Validation loss: 2.463965838464882

Epoch: 126| Step: 0
Training loss: 2.1276847484803794
Validation loss: 2.45855734230175

Epoch: 6| Step: 1
Training loss: 2.389074782844539
Validation loss: 2.4490912737366273

Epoch: 6| Step: 2
Training loss: 1.9477912400063273
Validation loss: 2.4556233183351037

Epoch: 6| Step: 3
Training loss: 2.695350713044333
Validation loss: 2.4590081134727964

Epoch: 6| Step: 4
Training loss: 2.3081754508807037
Validation loss: 2.466940719828284

Epoch: 6| Step: 5
Training loss: 2.6858488821663946
Validation loss: 2.471514075960791

Epoch: 6| Step: 6
Training loss: 2.9251842016923595
Validation loss: 2.4717614521964966

Epoch: 6| Step: 7
Training loss: 2.3740646126494074
Validation loss: 2.476188687613823

Epoch: 6| Step: 8
Training loss: 2.556157054004137
Validation loss: 2.4781166278558184

Epoch: 6| Step: 9
Training loss: 2.279396139956348
Validation loss: 2.47362119820297

Epoch: 6| Step: 10
Training loss: 2.5277935022929334
Validation loss: 2.4730075709135417

Epoch: 6| Step: 11
Training loss: 3.205257840787186
Validation loss: 2.4683104498002306

Epoch: 6| Step: 12
Training loss: 2.7125376615239
Validation loss: 2.460805641153713

Epoch: 6| Step: 13
Training loss: 2.6567134677237894
Validation loss: 2.4659539657982172

Epoch: 127| Step: 0
Training loss: 2.5067825816962572
Validation loss: 2.4624468015033276

Epoch: 6| Step: 1
Training loss: 2.4247681103765615
Validation loss: 2.4668261601030386

Epoch: 6| Step: 2
Training loss: 2.4600022249289273
Validation loss: 2.4624897577424543

Epoch: 6| Step: 3
Training loss: 2.857102121335232
Validation loss: 2.460111255300917

Epoch: 6| Step: 4
Training loss: 1.8412545337090287
Validation loss: 2.4607016314142203

Epoch: 6| Step: 5
Training loss: 2.1677723288694346
Validation loss: 2.4585685186441983

Epoch: 6| Step: 6
Training loss: 2.6349068752966573
Validation loss: 2.457530510196558

Epoch: 6| Step: 7
Training loss: 2.4641344407053194
Validation loss: 2.4584057091441527

Epoch: 6| Step: 8
Training loss: 3.041347556597564
Validation loss: 2.457140590092679

Epoch: 6| Step: 9
Training loss: 3.1838253007243074
Validation loss: 2.460232426794616

Epoch: 6| Step: 10
Training loss: 2.742534648081762
Validation loss: 2.453184730466735

Epoch: 6| Step: 11
Training loss: 1.7331136980042483
Validation loss: 2.460369306900427

Epoch: 6| Step: 12
Training loss: 3.080666359492027
Validation loss: 2.45358299628905

Epoch: 6| Step: 13
Training loss: 1.7799388677836312
Validation loss: 2.4588072745590863

Epoch: 128| Step: 0
Training loss: 2.347115097259859
Validation loss: 2.4657431370709504

Epoch: 6| Step: 1
Training loss: 2.038526208734813
Validation loss: 2.462760710106969

Epoch: 6| Step: 2
Training loss: 2.9880939100794843
Validation loss: 2.459382533732811

Epoch: 6| Step: 3
Training loss: 3.074601998972778
Validation loss: 2.467501932457113

Epoch: 6| Step: 4
Training loss: 2.278170244267367
Validation loss: 2.467267585277619

Epoch: 6| Step: 5
Training loss: 2.6466901298014616
Validation loss: 2.4667647705244176

Epoch: 6| Step: 6
Training loss: 2.880371383457457
Validation loss: 2.463610663600404

Epoch: 6| Step: 7
Training loss: 1.1140789720941315
Validation loss: 2.4640831597525823

Epoch: 6| Step: 8
Training loss: 2.329018031127893
Validation loss: 2.4633430148163717

Epoch: 6| Step: 9
Training loss: 2.279764187982524
Validation loss: 2.458131350824212

Epoch: 6| Step: 10
Training loss: 2.517905960460044
Validation loss: 2.4605104429078555

Epoch: 6| Step: 11
Training loss: 2.3392818330256255
Validation loss: 2.4607454416727

Epoch: 6| Step: 12
Training loss: 2.683083387150378
Validation loss: 2.464181479559057

Epoch: 6| Step: 13
Training loss: 3.157805408920941
Validation loss: 2.4597292886042914

Epoch: 129| Step: 0
Training loss: 2.015995435164597
Validation loss: 2.4537516965777635

Epoch: 6| Step: 1
Training loss: 2.636526776142184
Validation loss: 2.4571582334825184

Epoch: 6| Step: 2
Training loss: 1.968860199281291
Validation loss: 2.4565295751908285

Epoch: 6| Step: 3
Training loss: 2.4501417936437804
Validation loss: 2.45733994817473

Epoch: 6| Step: 4
Training loss: 2.501796363130305
Validation loss: 2.4560141103134145

Epoch: 6| Step: 5
Training loss: 2.6095394608071683
Validation loss: 2.4543755213062863

Epoch: 6| Step: 6
Training loss: 2.3059236993465877
Validation loss: 2.458801602092151

Epoch: 6| Step: 7
Training loss: 2.9251527404030546
Validation loss: 2.458583840575571

Epoch: 6| Step: 8
Training loss: 2.609537633521809
Validation loss: 2.4549357864362378

Epoch: 6| Step: 9
Training loss: 2.5940707824155704
Validation loss: 2.4598513027675253

Epoch: 6| Step: 10
Training loss: 2.847226710949179
Validation loss: 2.461622887490916

Epoch: 6| Step: 11
Training loss: 2.2788817772190413
Validation loss: 2.4686756525232396

Epoch: 6| Step: 12
Training loss: 2.876587470928926
Validation loss: 2.4697765195959405

Epoch: 6| Step: 13
Training loss: 2.561727267731341
Validation loss: 2.469957563367769

Epoch: 130| Step: 0
Training loss: 2.481412933150367
Validation loss: 2.473011427244529

Epoch: 6| Step: 1
Training loss: 2.5214173347194975
Validation loss: 2.468716520573357

Epoch: 6| Step: 2
Training loss: 2.397954438611072
Validation loss: 2.4707348325200065

Epoch: 6| Step: 3
Training loss: 2.4412841766355897
Validation loss: 2.469506867998491

Epoch: 6| Step: 4
Training loss: 2.5333593551236238
Validation loss: 2.4681982558606927

Epoch: 6| Step: 5
Training loss: 1.8140767572517906
Validation loss: 2.468820643319645

Epoch: 6| Step: 6
Training loss: 2.424886099116609
Validation loss: 2.467496964395776

Epoch: 6| Step: 7
Training loss: 2.7993744491982007
Validation loss: 2.465007077310757

Epoch: 6| Step: 8
Training loss: 2.6075595776489497
Validation loss: 2.468516688850831

Epoch: 6| Step: 9
Training loss: 2.74849139361867
Validation loss: 2.4620743804870435

Epoch: 6| Step: 10
Training loss: 1.9497610801658787
Validation loss: 2.459444899254396

Epoch: 6| Step: 11
Training loss: 2.877355522817349
Validation loss: 2.459472195790172

Epoch: 6| Step: 12
Training loss: 2.5250384563879007
Validation loss: 2.4589366872868372

Epoch: 6| Step: 13
Training loss: 2.9826925438429273
Validation loss: 2.456227424265462

Epoch: 131| Step: 0
Training loss: 2.118743774945052
Validation loss: 2.4571997620614083

Epoch: 6| Step: 1
Training loss: 2.430253922653054
Validation loss: 2.465997392697901

Epoch: 6| Step: 2
Training loss: 2.7116452922889134
Validation loss: 2.4626259314905106

Epoch: 6| Step: 3
Training loss: 2.528848898552261
Validation loss: 2.4583949119053843

Epoch: 6| Step: 4
Training loss: 2.837254242190266
Validation loss: 2.466595131786185

Epoch: 6| Step: 5
Training loss: 2.6294399133589432
Validation loss: 2.467096475150535

Epoch: 6| Step: 6
Training loss: 2.5110224920106354
Validation loss: 2.465529034724874

Epoch: 6| Step: 7
Training loss: 3.0405445554781227
Validation loss: 2.4635918002575434

Epoch: 6| Step: 8
Training loss: 1.9064526059402287
Validation loss: 2.461262143636116

Epoch: 6| Step: 9
Training loss: 2.892601698239106
Validation loss: 2.4655245461929485

Epoch: 6| Step: 10
Training loss: 2.5473761504281263
Validation loss: 2.4607892511512115

Epoch: 6| Step: 11
Training loss: 2.447475463931234
Validation loss: 2.46485419656562

Epoch: 6| Step: 12
Training loss: 2.7107873704658574
Validation loss: 2.4558167157119537

Epoch: 6| Step: 13
Training loss: 1.8155843864796566
Validation loss: 2.458107377567939

Epoch: 132| Step: 0
Training loss: 2.4666618497474997
Validation loss: 2.4547732054351736

Epoch: 6| Step: 1
Training loss: 2.48701998425819
Validation loss: 2.4589596828668254

Epoch: 6| Step: 2
Training loss: 2.6309287919456454
Validation loss: 2.452317074438906

Epoch: 6| Step: 3
Training loss: 3.0071548337409895
Validation loss: 2.457384804748372

Epoch: 6| Step: 4
Training loss: 2.3100926008283422
Validation loss: 2.4632052352473415

Epoch: 6| Step: 5
Training loss: 2.280382592408833
Validation loss: 2.469518598190027

Epoch: 6| Step: 6
Training loss: 2.3617226749833
Validation loss: 2.4704737057928785

Epoch: 6| Step: 7
Training loss: 2.617202895389654
Validation loss: 2.4777739697537813

Epoch: 6| Step: 8
Training loss: 2.2713454016225008
Validation loss: 2.4744046313965526

Epoch: 6| Step: 9
Training loss: 2.2067089824518415
Validation loss: 2.476439961351116

Epoch: 6| Step: 10
Training loss: 2.598817952759853
Validation loss: 2.4706981714171357

Epoch: 6| Step: 11
Training loss: 2.79655241571088
Validation loss: 2.465979425817312

Epoch: 6| Step: 12
Training loss: 2.563903238300668
Validation loss: 2.46935951981793

Epoch: 6| Step: 13
Training loss: 2.744408037181851
Validation loss: 2.458958551676774

Epoch: 133| Step: 0
Training loss: 2.5327291993851637
Validation loss: 2.4612167845797166

Epoch: 6| Step: 1
Training loss: 2.2640718595470575
Validation loss: 2.4602215083602874

Epoch: 6| Step: 2
Training loss: 2.703079840663239
Validation loss: 2.458665911489579

Epoch: 6| Step: 3
Training loss: 2.6683771091788264
Validation loss: 2.4559261422364482

Epoch: 6| Step: 4
Training loss: 2.4722086183361798
Validation loss: 2.461933899047622

Epoch: 6| Step: 5
Training loss: 2.4740973396734414
Validation loss: 2.459311360784364

Epoch: 6| Step: 6
Training loss: 2.3753791305697987
Validation loss: 2.4633115751039405

Epoch: 6| Step: 7
Training loss: 1.949462630738281
Validation loss: 2.4600209461912446

Epoch: 6| Step: 8
Training loss: 2.4958853239101075
Validation loss: 2.463374857399836

Epoch: 6| Step: 9
Training loss: 2.7989570071566616
Validation loss: 2.4713782472445556

Epoch: 6| Step: 10
Training loss: 2.6579200431330654
Validation loss: 2.4650075850972955

Epoch: 6| Step: 11
Training loss: 2.719093213396188
Validation loss: 2.464498633775096

Epoch: 6| Step: 12
Training loss: 2.842823590301757
Validation loss: 2.4605805960710065

Epoch: 6| Step: 13
Training loss: 2.3209424945720545
Validation loss: 2.4567372965483116

Epoch: 134| Step: 0
Training loss: 2.887425812267754
Validation loss: 2.4639089900585827

Epoch: 6| Step: 1
Training loss: 2.6790977251626487
Validation loss: 2.464848344559778

Epoch: 6| Step: 2
Training loss: 2.4817569781647504
Validation loss: 2.4649619483718985

Epoch: 6| Step: 3
Training loss: 1.8936878962137877
Validation loss: 2.4730176134295947

Epoch: 6| Step: 4
Training loss: 2.9521489220662023
Validation loss: 2.472038541416212

Epoch: 6| Step: 5
Training loss: 3.0556791993373085
Validation loss: 2.474473748307882

Epoch: 6| Step: 6
Training loss: 2.012451275537764
Validation loss: 2.4764550764369933

Epoch: 6| Step: 7
Training loss: 2.1999876802272906
Validation loss: 2.4792451017992416

Epoch: 6| Step: 8
Training loss: 2.81694027815113
Validation loss: 2.4818679827915378

Epoch: 6| Step: 9
Training loss: 2.513821731522738
Validation loss: 2.4775403295545555

Epoch: 6| Step: 10
Training loss: 2.284401480420808
Validation loss: 2.477764491780712

Epoch: 6| Step: 11
Training loss: 2.9039405752990475
Validation loss: 2.4811543395774263

Epoch: 6| Step: 12
Training loss: 2.25918220763265
Validation loss: 2.4768588974780856

Epoch: 6| Step: 13
Training loss: 2.220047262565025
Validation loss: 2.4718900741972725

Epoch: 135| Step: 0
Training loss: 2.2119075951892206
Validation loss: 2.4661167442488705

Epoch: 6| Step: 1
Training loss: 2.791394623743674
Validation loss: 2.4645407400269166

Epoch: 6| Step: 2
Training loss: 2.673434689028147
Validation loss: 2.4563551125591268

Epoch: 6| Step: 3
Training loss: 2.892988898289276
Validation loss: 2.4577665052659388

Epoch: 6| Step: 4
Training loss: 3.3959481779622
Validation loss: 2.48075500598697

Epoch: 6| Step: 5
Training loss: 2.2712444201638644
Validation loss: 2.485424555797692

Epoch: 6| Step: 6
Training loss: 2.273558098914163
Validation loss: 2.4616629202454128

Epoch: 6| Step: 7
Training loss: 2.586522615278932
Validation loss: 2.459870582487043

Epoch: 6| Step: 8
Training loss: 2.3797435571050523
Validation loss: 2.460874679813173

Epoch: 6| Step: 9
Training loss: 2.41049256289082
Validation loss: 2.467744630605963

Epoch: 6| Step: 10
Training loss: 2.6246027873008093
Validation loss: 2.4667062468403267

Epoch: 6| Step: 11
Training loss: 2.641363548513582
Validation loss: 2.472695172060288

Epoch: 6| Step: 12
Training loss: 1.9864615936599272
Validation loss: 2.4719885175113183

Epoch: 6| Step: 13
Training loss: 2.0242812117226454
Validation loss: 2.4708119565694107

Epoch: 136| Step: 0
Training loss: 2.8767887024467735
Validation loss: 2.4807741632945173

Epoch: 6| Step: 1
Training loss: 2.20143777075674
Validation loss: 2.4765060370233227

Epoch: 6| Step: 2
Training loss: 2.8494400277387286
Validation loss: 2.4837443033020907

Epoch: 6| Step: 3
Training loss: 2.7294648471070326
Validation loss: 2.484520434075409

Epoch: 6| Step: 4
Training loss: 1.8276802239219878
Validation loss: 2.4847540896069535

Epoch: 6| Step: 5
Training loss: 2.4386482468596453
Validation loss: 2.4749130548432214

Epoch: 6| Step: 6
Training loss: 2.4632427741281275
Validation loss: 2.477761316411068

Epoch: 6| Step: 7
Training loss: 2.508749243218688
Validation loss: 2.4691794621469394

Epoch: 6| Step: 8
Training loss: 2.7168834900092627
Validation loss: 2.474174575724498

Epoch: 6| Step: 9
Training loss: 2.4981390702665234
Validation loss: 2.473399311284151

Epoch: 6| Step: 10
Training loss: 2.705647432759026
Validation loss: 2.4698165328115995

Epoch: 6| Step: 11
Training loss: 2.757513532562113
Validation loss: 2.460849417265629

Epoch: 6| Step: 12
Training loss: 2.185973043200525
Validation loss: 2.464573913410035

Epoch: 6| Step: 13
Training loss: 2.726698033153188
Validation loss: 2.4557833188593463

Epoch: 137| Step: 0
Training loss: 2.411218640888354
Validation loss: 2.4587218144683605

Epoch: 6| Step: 1
Training loss: 2.582605895302111
Validation loss: 2.457219232383981

Epoch: 6| Step: 2
Training loss: 2.6228138130591034
Validation loss: 2.4587958326465444

Epoch: 6| Step: 3
Training loss: 2.474301819630925
Validation loss: 2.4706518517201164

Epoch: 6| Step: 4
Training loss: 2.996039796664223
Validation loss: 2.4555178753976317

Epoch: 6| Step: 5
Training loss: 1.692817927016104
Validation loss: 2.4627542077284374

Epoch: 6| Step: 6
Training loss: 2.6247607530830868
Validation loss: 2.4610789828527193

Epoch: 6| Step: 7
Training loss: 2.768551931766706
Validation loss: 2.4670365177637645

Epoch: 6| Step: 8
Training loss: 2.5324803882378006
Validation loss: 2.4623105290905585

Epoch: 6| Step: 9
Training loss: 2.250581136465145
Validation loss: 2.4609591609263934

Epoch: 6| Step: 10
Training loss: 2.5406205781379687
Validation loss: 2.4573740838753495

Epoch: 6| Step: 11
Training loss: 2.479357372824203
Validation loss: 2.460853567155414

Epoch: 6| Step: 12
Training loss: 2.806999932148127
Validation loss: 2.4637178246474316

Epoch: 6| Step: 13
Training loss: 2.352936403536163
Validation loss: 2.4672398676598326

Epoch: 138| Step: 0
Training loss: 1.7998937045607124
Validation loss: 2.471023221194865

Epoch: 6| Step: 1
Training loss: 2.602194036404777
Validation loss: 2.4678527473090894

Epoch: 6| Step: 2
Training loss: 2.3792999893841977
Validation loss: 2.469443227922359

Epoch: 6| Step: 3
Training loss: 2.8367965700175057
Validation loss: 2.4712480067346534

Epoch: 6| Step: 4
Training loss: 2.37846483166019
Validation loss: 2.474247449076666

Epoch: 6| Step: 5
Training loss: 2.497141539057982
Validation loss: 2.471098253823107

Epoch: 6| Step: 6
Training loss: 3.291154861900638
Validation loss: 2.4696132422238093

Epoch: 6| Step: 7
Training loss: 2.7568068791640714
Validation loss: 2.4695875461319963

Epoch: 6| Step: 8
Training loss: 2.438409684455343
Validation loss: 2.469339227979695

Epoch: 6| Step: 9
Training loss: 2.5281698064994775
Validation loss: 2.4687259849957686

Epoch: 6| Step: 10
Training loss: 2.579914466120212
Validation loss: 2.4621930829920218

Epoch: 6| Step: 11
Training loss: 2.794023648030194
Validation loss: 2.472309942034622

Epoch: 6| Step: 12
Training loss: 2.1728593530408093
Validation loss: 2.4588335358095503

Epoch: 6| Step: 13
Training loss: 1.8676133567999122
Validation loss: 2.464843895091492

Epoch: 139| Step: 0
Training loss: 2.9622353801767343
Validation loss: 2.4645015360096774

Epoch: 6| Step: 1
Training loss: 2.933632435143566
Validation loss: 2.4631469093063987

Epoch: 6| Step: 2
Training loss: 2.465527713147203
Validation loss: 2.464936445602065

Epoch: 6| Step: 3
Training loss: 1.8455311205608584
Validation loss: 2.4646204118258517

Epoch: 6| Step: 4
Training loss: 1.860855795142042
Validation loss: 2.470995473339608

Epoch: 6| Step: 5
Training loss: 2.3236427939865045
Validation loss: 2.4687196270969585

Epoch: 6| Step: 6
Training loss: 2.0369031441480314
Validation loss: 2.4690016606179666

Epoch: 6| Step: 7
Training loss: 2.424329731915164
Validation loss: 2.466794120442717

Epoch: 6| Step: 8
Training loss: 2.5636392247499478
Validation loss: 2.4708747412142587

Epoch: 6| Step: 9
Training loss: 2.7503444282543126
Validation loss: 2.460638296517564

Epoch: 6| Step: 10
Training loss: 2.2302863853179637
Validation loss: 2.462350010055736

Epoch: 6| Step: 11
Training loss: 2.952945441383087
Validation loss: 2.4554394860930517

Epoch: 6| Step: 12
Training loss: 2.8778248053610844
Validation loss: 2.457977727181256

Epoch: 6| Step: 13
Training loss: 2.584878295453604
Validation loss: 2.4526936988153114

Epoch: 140| Step: 0
Training loss: 2.169394414403278
Validation loss: 2.452840306634778

Epoch: 6| Step: 1
Training loss: 2.444527789583131
Validation loss: 2.4635347174021565

Epoch: 6| Step: 2
Training loss: 2.4829135650941447
Validation loss: 2.459676300296028

Epoch: 6| Step: 3
Training loss: 2.2274051610963075
Validation loss: 2.451359577261869

Epoch: 6| Step: 4
Training loss: 2.2509204253439234
Validation loss: 2.4641571136416722

Epoch: 6| Step: 5
Training loss: 2.202338328495234
Validation loss: 2.464186680062839

Epoch: 6| Step: 6
Training loss: 3.0930874818355987
Validation loss: 2.465143474687523

Epoch: 6| Step: 7
Training loss: 2.2029771687575193
Validation loss: 2.45901753446417

Epoch: 6| Step: 8
Training loss: 2.1964047792854062
Validation loss: 2.4517445334804715

Epoch: 6| Step: 9
Training loss: 2.556216281211464
Validation loss: 2.456408067362097

Epoch: 6| Step: 10
Training loss: 2.8305768086346075
Validation loss: 2.4597066071632923

Epoch: 6| Step: 11
Training loss: 2.949041217235213
Validation loss: 2.46087539836698

Epoch: 6| Step: 12
Training loss: 2.4904549534661613
Validation loss: 2.4702339058521527

Epoch: 6| Step: 13
Training loss: 2.7209873858814517
Validation loss: 2.476619218403445

Epoch: 141| Step: 0
Training loss: 2.2542623836857882
Validation loss: 2.475106550421318

Epoch: 6| Step: 1
Training loss: 2.0445593628282506
Validation loss: 2.480255358070082

Epoch: 6| Step: 2
Training loss: 2.1129827094609546
Validation loss: 2.481568116391179

Epoch: 6| Step: 3
Training loss: 2.5321645144309466
Validation loss: 2.4843342455834083

Epoch: 6| Step: 4
Training loss: 3.114049723321914
Validation loss: 2.486368654954091

Epoch: 6| Step: 5
Training loss: 2.7824951984813078
Validation loss: 2.4823308888510365

Epoch: 6| Step: 6
Training loss: 2.6737349433350146
Validation loss: 2.480207855040851

Epoch: 6| Step: 7
Training loss: 2.013284906895447
Validation loss: 2.478862973586937

Epoch: 6| Step: 8
Training loss: 2.363208813778836
Validation loss: 2.4804174703268522

Epoch: 6| Step: 9
Training loss: 2.5859914353384466
Validation loss: 2.481536090926317

Epoch: 6| Step: 10
Training loss: 3.292380501005818
Validation loss: 2.4742653960687213

Epoch: 6| Step: 11
Training loss: 2.1421680318781102
Validation loss: 2.4649355267236377

Epoch: 6| Step: 12
Training loss: 2.403301364493825
Validation loss: 2.4627570636139264

Epoch: 6| Step: 13
Training loss: 2.8661239272887604
Validation loss: 2.457009966848567

Epoch: 142| Step: 0
Training loss: 2.462760516488005
Validation loss: 2.456702165342848

Epoch: 6| Step: 1
Training loss: 2.3194300967728942
Validation loss: 2.478132726874538

Epoch: 6| Step: 2
Training loss: 2.2825510155950393
Validation loss: 2.476511251759694

Epoch: 6| Step: 3
Training loss: 2.1556477465802306
Validation loss: 2.4822807842170302

Epoch: 6| Step: 4
Training loss: 2.5795421057982244
Validation loss: 2.486304663352417

Epoch: 6| Step: 5
Training loss: 2.666966441312015
Validation loss: 2.4698254299121882

Epoch: 6| Step: 6
Training loss: 2.523087515638779
Validation loss: 2.4792079494682864

Epoch: 6| Step: 7
Training loss: 2.3086716175663327
Validation loss: 2.4651016285846494

Epoch: 6| Step: 8
Training loss: 2.5749285678770177
Validation loss: 2.4626761213727644

Epoch: 6| Step: 9
Training loss: 2.8829446571058313
Validation loss: 2.46272798828598

Epoch: 6| Step: 10
Training loss: 2.7588782480053182
Validation loss: 2.4608000701798876

Epoch: 6| Step: 11
Training loss: 2.8563813761541086
Validation loss: 2.4633565165091675

Epoch: 6| Step: 12
Training loss: 2.151741511281518
Validation loss: 2.4634753749925906

Epoch: 6| Step: 13
Training loss: 2.612011976153271
Validation loss: 2.46740484812381

Epoch: 143| Step: 0
Training loss: 2.8074455620098284
Validation loss: 2.469529346793983

Epoch: 6| Step: 1
Training loss: 2.7521659817487336
Validation loss: 2.4779374791279376

Epoch: 6| Step: 2
Training loss: 2.480125391466621
Validation loss: 2.4807864008282583

Epoch: 6| Step: 3
Training loss: 2.018464210523694
Validation loss: 2.4805291596513217

Epoch: 6| Step: 4
Training loss: 2.619941560515726
Validation loss: 2.487636352840297

Epoch: 6| Step: 5
Training loss: 2.5096311065604096
Validation loss: 2.4844894702698737

Epoch: 6| Step: 6
Training loss: 2.3290229448209483
Validation loss: 2.481060944600626

Epoch: 6| Step: 7
Training loss: 2.656727467427105
Validation loss: 2.4866031275890697

Epoch: 6| Step: 8
Training loss: 2.946521136658764
Validation loss: 2.4882690014180886

Epoch: 6| Step: 9
Training loss: 2.530798601002832
Validation loss: 2.48190232549345

Epoch: 6| Step: 10
Training loss: 3.485592069314686
Validation loss: 2.4823930299985406

Epoch: 6| Step: 11
Training loss: 2.3985260689252907
Validation loss: 2.476736702392979

Epoch: 6| Step: 12
Training loss: 1.6305494185243206
Validation loss: 2.474364587990429

Epoch: 6| Step: 13
Training loss: 2.14720712283299
Validation loss: 2.4697576953016234

Epoch: 144| Step: 0
Training loss: 2.465448997414081
Validation loss: 2.4697884415747993

Epoch: 6| Step: 1
Training loss: 2.8608951384211885
Validation loss: 2.4624702968193732

Epoch: 6| Step: 2
Training loss: 2.8239309499311855
Validation loss: 2.464499778545811

Epoch: 6| Step: 3
Training loss: 2.503583342728098
Validation loss: 2.4556595976850204

Epoch: 6| Step: 4
Training loss: 2.506286537113369
Validation loss: 2.4573534666803827

Epoch: 6| Step: 5
Training loss: 1.6460194864707127
Validation loss: 2.464609464462249

Epoch: 6| Step: 6
Training loss: 2.992726728093123
Validation loss: 2.463441670641816

Epoch: 6| Step: 7
Training loss: 2.6136325662758724
Validation loss: 2.4746416827960385

Epoch: 6| Step: 8
Training loss: 2.328040204648109
Validation loss: 2.469258783119686

Epoch: 6| Step: 9
Training loss: 2.965199485616769
Validation loss: 2.4674028833686643

Epoch: 6| Step: 10
Training loss: 2.2178458937277847
Validation loss: 2.454266778515597

Epoch: 6| Step: 11
Training loss: 1.931694315442847
Validation loss: 2.46025445733411

Epoch: 6| Step: 12
Training loss: 2.3385720594395125
Validation loss: 2.4579838299556953

Epoch: 6| Step: 13
Training loss: 2.9086152982976645
Validation loss: 2.4616411767292887

Epoch: 145| Step: 0
Training loss: 1.7085432605932112
Validation loss: 2.461830937718469

Epoch: 6| Step: 1
Training loss: 2.43729321507437
Validation loss: 2.4614820089881846

Epoch: 6| Step: 2
Training loss: 2.6088428982698026
Validation loss: 2.464736815247354

Epoch: 6| Step: 3
Training loss: 2.5632641281025803
Validation loss: 2.4613007776883977

Epoch: 6| Step: 4
Training loss: 2.6864819039864716
Validation loss: 2.4611212767751534

Epoch: 6| Step: 5
Training loss: 2.3480867064224196
Validation loss: 2.4600497789179454

Epoch: 6| Step: 6
Training loss: 2.9974157010681326
Validation loss: 2.4634081190712926

Epoch: 6| Step: 7
Training loss: 2.971822654351369
Validation loss: 2.4676763557969736

Epoch: 6| Step: 8
Training loss: 2.26283745119615
Validation loss: 2.465527213526191

Epoch: 6| Step: 9
Training loss: 2.3942496552663766
Validation loss: 2.4671077819275964

Epoch: 6| Step: 10
Training loss: 2.606911049856284
Validation loss: 2.4578402450363286

Epoch: 6| Step: 11
Training loss: 2.3815350219278626
Validation loss: 2.461400984457769

Epoch: 6| Step: 12
Training loss: 2.281260137666098
Validation loss: 2.4600875274728238

Epoch: 6| Step: 13
Training loss: 2.406669183854806
Validation loss: 2.4605063085890526

Epoch: 146| Step: 0
Training loss: 2.5445587297266927
Validation loss: 2.4526601622297273

Epoch: 6| Step: 1
Training loss: 2.4465909790611184
Validation loss: 2.4589077445470457

Epoch: 6| Step: 2
Training loss: 2.4723771888464396
Validation loss: 2.456273029145018

Epoch: 6| Step: 3
Training loss: 2.783189247498297
Validation loss: 2.4592250779894544

Epoch: 6| Step: 4
Training loss: 2.218173314759034
Validation loss: 2.451139144374974

Epoch: 6| Step: 5
Training loss: 2.8172149132163375
Validation loss: 2.4591681199913507

Epoch: 6| Step: 6
Training loss: 2.352722287515127
Validation loss: 2.457962272140331

Epoch: 6| Step: 7
Training loss: 2.251554270192552
Validation loss: 2.4611660482859157

Epoch: 6| Step: 8
Training loss: 2.607484235267859
Validation loss: 2.4555224388597496

Epoch: 6| Step: 9
Training loss: 2.946155862449359
Validation loss: 2.4597917261061992

Epoch: 6| Step: 10
Training loss: 2.5103140740120757
Validation loss: 2.4561588131299152

Epoch: 6| Step: 11
Training loss: 2.4535992400873115
Validation loss: 2.4577138626731876

Epoch: 6| Step: 12
Training loss: 2.877239184586047
Validation loss: 2.4539757486464833

Epoch: 6| Step: 13
Training loss: 1.5394374177756238
Validation loss: 2.460369403803999

Epoch: 147| Step: 0
Training loss: 2.318154921350142
Validation loss: 2.4589173194442333

Epoch: 6| Step: 1
Training loss: 2.2562547213433657
Validation loss: 2.458101962133778

Epoch: 6| Step: 2
Training loss: 2.306429343758231
Validation loss: 2.4570070881102826

Epoch: 6| Step: 3
Training loss: 2.5662200720854056
Validation loss: 2.4623035817307595

Epoch: 6| Step: 4
Training loss: 2.371600679760554
Validation loss: 2.455579432874367

Epoch: 6| Step: 5
Training loss: 2.566616380702601
Validation loss: 2.4551190737291253

Epoch: 6| Step: 6
Training loss: 2.606286876975598
Validation loss: 2.4624604049313557

Epoch: 6| Step: 7
Training loss: 2.4344148919065294
Validation loss: 2.461399087557452

Epoch: 6| Step: 8
Training loss: 2.0011220407172776
Validation loss: 2.4630241307439342

Epoch: 6| Step: 9
Training loss: 2.715951553569966
Validation loss: 2.4670441443920352

Epoch: 6| Step: 10
Training loss: 2.71944567669832
Validation loss: 2.466506775837496

Epoch: 6| Step: 11
Training loss: 2.8951281962892796
Validation loss: 2.4612560893523168

Epoch: 6| Step: 12
Training loss: 2.647908475809662
Validation loss: 2.4669823414480203

Epoch: 6| Step: 13
Training loss: 2.701241691608353
Validation loss: 2.4639585329133493

Epoch: 148| Step: 0
Training loss: 2.7013956171740303
Validation loss: 2.466498253417078

Epoch: 6| Step: 1
Training loss: 2.6253672751574726
Validation loss: 2.467005777461257

Epoch: 6| Step: 2
Training loss: 2.3918246581454294
Validation loss: 2.4728067280971024

Epoch: 6| Step: 3
Training loss: 2.502120453884479
Validation loss: 2.469040608101607

Epoch: 6| Step: 4
Training loss: 2.77234535742262
Validation loss: 2.46553504628266

Epoch: 6| Step: 5
Training loss: 1.9082223662828526
Validation loss: 2.464873316245432

Epoch: 6| Step: 6
Training loss: 2.603593646266239
Validation loss: 2.4619466821571723

Epoch: 6| Step: 7
Training loss: 1.9990435936102176
Validation loss: 2.469684858411235

Epoch: 6| Step: 8
Training loss: 2.6577883585304973
Validation loss: 2.466233955159676

Epoch: 6| Step: 9
Training loss: 1.9408095611431102
Validation loss: 2.4649215419965294

Epoch: 6| Step: 10
Training loss: 2.9107937313006564
Validation loss: 2.4697998325615664

Epoch: 6| Step: 11
Training loss: 2.578190288295007
Validation loss: 2.463392375484526

Epoch: 6| Step: 12
Training loss: 2.7951498838304527
Validation loss: 2.4619155312815844

Epoch: 6| Step: 13
Training loss: 2.502371616785983
Validation loss: 2.460697126002456

Epoch: 149| Step: 0
Training loss: 2.6765459958718396
Validation loss: 2.462549882309338

Epoch: 6| Step: 1
Training loss: 2.1819456155364954
Validation loss: 2.460174038450107

Epoch: 6| Step: 2
Training loss: 2.2777992172576154
Validation loss: 2.452485651174522

Epoch: 6| Step: 3
Training loss: 2.3351638176119955
Validation loss: 2.456271775386147

Epoch: 6| Step: 4
Training loss: 2.842533731788846
Validation loss: 2.4573724749318475

Epoch: 6| Step: 5
Training loss: 2.2744963497150184
Validation loss: 2.469500801745893

Epoch: 6| Step: 6
Training loss: 2.542518681370343
Validation loss: 2.471561183372009

Epoch: 6| Step: 7
Training loss: 2.748470574679294
Validation loss: 2.4697612992801874

Epoch: 6| Step: 8
Training loss: 2.427967112549423
Validation loss: 2.464091456696075

Epoch: 6| Step: 9
Training loss: 2.8709607151895375
Validation loss: 2.4648267419936594

Epoch: 6| Step: 10
Training loss: 2.6918587048251927
Validation loss: 2.459713876878695

Epoch: 6| Step: 11
Training loss: 2.5724633212574846
Validation loss: 2.468997878494886

Epoch: 6| Step: 12
Training loss: 2.4485808641519307
Validation loss: 2.4680577043838703

Epoch: 6| Step: 13
Training loss: 1.9612725568146459
Validation loss: 2.470091531720394

Epoch: 150| Step: 0
Training loss: 2.5963183636175224
Validation loss: 2.468552295800259

Epoch: 6| Step: 1
Training loss: 2.618837935034233
Validation loss: 2.473667622936362

Epoch: 6| Step: 2
Training loss: 2.4726216342425436
Validation loss: 2.465700438956589

Epoch: 6| Step: 3
Training loss: 2.1075286696758977
Validation loss: 2.470956210918735

Epoch: 6| Step: 4
Training loss: 3.0546718899457286
Validation loss: 2.4712641344195236

Epoch: 6| Step: 5
Training loss: 2.66085792731645
Validation loss: 2.477585012861601

Epoch: 6| Step: 6
Training loss: 2.9306795195464588
Validation loss: 2.4696199357141637

Epoch: 6| Step: 7
Training loss: 2.2657340187941077
Validation loss: 2.4708846154983615

Epoch: 6| Step: 8
Training loss: 2.306143711194276
Validation loss: 2.469636194705924

Epoch: 6| Step: 9
Training loss: 1.7833525980446594
Validation loss: 2.464546971658827

Epoch: 6| Step: 10
Training loss: 2.844669905889631
Validation loss: 2.473886707005211

Epoch: 6| Step: 11
Training loss: 2.7130304441954927
Validation loss: 2.470480573881343

Epoch: 6| Step: 12
Training loss: 2.356810331628326
Validation loss: 2.465821440542234

Epoch: 6| Step: 13
Training loss: 2.158266865751325
Validation loss: 2.46868745104908

Epoch: 151| Step: 0
Training loss: 2.5718057579091766
Validation loss: 2.475283752898623

Epoch: 6| Step: 1
Training loss: 2.665325055794444
Validation loss: 2.4769942812770824

Epoch: 6| Step: 2
Training loss: 2.6567901959611384
Validation loss: 2.4719749665170716

Epoch: 6| Step: 3
Training loss: 2.4260440505919503
Validation loss: 2.4744184260272535

Epoch: 6| Step: 4
Training loss: 2.760892709434583
Validation loss: 2.4655918733138584

Epoch: 6| Step: 5
Training loss: 2.9670681656739637
Validation loss: 2.469164270336968

Epoch: 6| Step: 6
Training loss: 2.651820719727794
Validation loss: 2.4614238117222498

Epoch: 6| Step: 7
Training loss: 2.079312207690216
Validation loss: 2.46333216662846

Epoch: 6| Step: 8
Training loss: 2.4125264536934115
Validation loss: 2.475123503843467

Epoch: 6| Step: 9
Training loss: 2.694954049421105
Validation loss: 2.4692286900500067

Epoch: 6| Step: 10
Training loss: 2.401007055555826
Validation loss: 2.4730969077041096

Epoch: 6| Step: 11
Training loss: 2.1213416978554065
Validation loss: 2.4703257236050375

Epoch: 6| Step: 12
Training loss: 2.3661883672313984
Validation loss: 2.4691666360169107

Epoch: 6| Step: 13
Training loss: 2.105913048118405
Validation loss: 2.471754571590914

Epoch: 152| Step: 0
Training loss: 3.1229473238902012
Validation loss: 2.4723397404412526

Epoch: 6| Step: 1
Training loss: 2.440411906885507
Validation loss: 2.4704139590515273

Epoch: 6| Step: 2
Training loss: 2.88674055408714
Validation loss: 2.46647940410287

Epoch: 6| Step: 3
Training loss: 2.063472980689331
Validation loss: 2.469563185282099

Epoch: 6| Step: 4
Training loss: 2.663704319476755
Validation loss: 2.4771662636989507

Epoch: 6| Step: 5
Training loss: 2.1299229984961205
Validation loss: 2.478675662766531

Epoch: 6| Step: 6
Training loss: 2.2243836567199273
Validation loss: 2.4670760036317314

Epoch: 6| Step: 7
Training loss: 2.170359569942685
Validation loss: 2.4698180773376897

Epoch: 6| Step: 8
Training loss: 2.0595825831634227
Validation loss: 2.471762448918147

Epoch: 6| Step: 9
Training loss: 2.4510823875597225
Validation loss: 2.4741300074927004

Epoch: 6| Step: 10
Training loss: 2.7417984819658883
Validation loss: 2.4757642853527706

Epoch: 6| Step: 11
Training loss: 2.915444872035807
Validation loss: 2.474852403741663

Epoch: 6| Step: 12
Training loss: 2.1438166082505266
Validation loss: 2.4758798117583254

Epoch: 6| Step: 13
Training loss: 2.6151074698484997
Validation loss: 2.4745986163460714

Epoch: 153| Step: 0
Training loss: 2.1538782759251838
Validation loss: 2.4740309908721385

Epoch: 6| Step: 1
Training loss: 3.4618792146077544
Validation loss: 2.4706517713032206

Epoch: 6| Step: 2
Training loss: 2.1252375077303514
Validation loss: 2.481486386586345

Epoch: 6| Step: 3
Training loss: 2.704140356687232
Validation loss: 2.472964066263005

Epoch: 6| Step: 4
Training loss: 2.3056229067033143
Validation loss: 2.470345299583645

Epoch: 6| Step: 5
Training loss: 2.310292195257089
Validation loss: 2.4759099443571304

Epoch: 6| Step: 6
Training loss: 2.679821667217955
Validation loss: 2.4766042487218645

Epoch: 6| Step: 7
Training loss: 2.2607963934511224
Validation loss: 2.4847213695598818

Epoch: 6| Step: 8
Training loss: 2.2486190796804446
Validation loss: 2.4824906566504232

Epoch: 6| Step: 9
Training loss: 2.568888446576096
Validation loss: 2.487182662121357

Epoch: 6| Step: 10
Training loss: 2.745559575312799
Validation loss: 2.4764944522466146

Epoch: 6| Step: 11
Training loss: 2.204211569066099
Validation loss: 2.4756583439598168

Epoch: 6| Step: 12
Training loss: 2.6508956799035306
Validation loss: 2.479726332849377

Epoch: 6| Step: 13
Training loss: 2.0260899659768157
Validation loss: 2.474085599068625

Epoch: 154| Step: 0
Training loss: 2.140082631699465
Validation loss: 2.4773063064162724

Epoch: 6| Step: 1
Training loss: 2.6075363534092073
Validation loss: 2.482300866211751

Epoch: 6| Step: 2
Training loss: 1.9173176392499633
Validation loss: 2.4849832298076238

Epoch: 6| Step: 3
Training loss: 2.390107541398136
Validation loss: 2.481150632032822

Epoch: 6| Step: 4
Training loss: 2.019554034755717
Validation loss: 2.475975167538712

Epoch: 6| Step: 5
Training loss: 2.560598179399969
Validation loss: 2.476768140147364

Epoch: 6| Step: 6
Training loss: 3.4033672488244777
Validation loss: 2.469946720099486

Epoch: 6| Step: 7
Training loss: 2.2867788960503783
Validation loss: 2.4727232945549598

Epoch: 6| Step: 8
Training loss: 1.9778658825231976
Validation loss: 2.4712839763121415

Epoch: 6| Step: 9
Training loss: 2.253694044995839
Validation loss: 2.479682906013757

Epoch: 6| Step: 10
Training loss: 3.295509815051546
Validation loss: 2.479829047909815

Epoch: 6| Step: 11
Training loss: 2.627854384779061
Validation loss: 2.4811070379394695

Epoch: 6| Step: 12
Training loss: 2.8745519869488163
Validation loss: 2.49218757972199

Epoch: 6| Step: 13
Training loss: 2.2190635352165193
Validation loss: 2.4854147472731243

Epoch: 155| Step: 0
Training loss: 2.4823790395719096
Validation loss: 2.477377948827689

Epoch: 6| Step: 1
Training loss: 2.7699845431340697
Validation loss: 2.4848938246264254

Epoch: 6| Step: 2
Training loss: 2.7204932400928454
Validation loss: 2.473384820148588

Epoch: 6| Step: 3
Training loss: 2.528344452979577
Validation loss: 2.4733426395362854

Epoch: 6| Step: 4
Training loss: 2.7226683344087093
Validation loss: 2.4728288876498965

Epoch: 6| Step: 5
Training loss: 2.956872570461774
Validation loss: 2.474306139673942

Epoch: 6| Step: 6
Training loss: 2.180642195787141
Validation loss: 2.477836802506113

Epoch: 6| Step: 7
Training loss: 2.0269151649883055
Validation loss: 2.474180967787049

Epoch: 6| Step: 8
Training loss: 2.227134657846195
Validation loss: 2.4737785729134254

Epoch: 6| Step: 9
Training loss: 2.553658654460015
Validation loss: 2.4818333834397355

Epoch: 6| Step: 10
Training loss: 2.3958310555709845
Validation loss: 2.4778188252529674

Epoch: 6| Step: 11
Training loss: 2.625136962223985
Validation loss: 2.476117765043339

Epoch: 6| Step: 12
Training loss: 2.1999366360989447
Validation loss: 2.4769658382987685

Epoch: 6| Step: 13
Training loss: 2.2947099303726346
Validation loss: 2.4805504893053847

Epoch: 156| Step: 0
Training loss: 2.386575397987573
Validation loss: 2.476072148536775

Epoch: 6| Step: 1
Training loss: 2.578124260179818
Validation loss: 2.47425392928076

Epoch: 6| Step: 2
Training loss: 2.9992748019760636
Validation loss: 2.4757553855192587

Epoch: 6| Step: 3
Training loss: 2.222184437854402
Validation loss: 2.4768450683099448

Epoch: 6| Step: 4
Training loss: 2.3355206273874245
Validation loss: 2.4781847112388093

Epoch: 6| Step: 5
Training loss: 2.7370159365685156
Validation loss: 2.4830888741988484

Epoch: 6| Step: 6
Training loss: 2.5432737199822197
Validation loss: 2.486503457047625

Epoch: 6| Step: 7
Training loss: 2.4832088204559017
Validation loss: 2.486864965456467

Epoch: 6| Step: 8
Training loss: 2.370422569943008
Validation loss: 2.4822065698719644

Epoch: 6| Step: 9
Training loss: 2.229584580460724
Validation loss: 2.4751665129985696

Epoch: 6| Step: 10
Training loss: 2.830187135312121
Validation loss: 2.475690589914863

Epoch: 6| Step: 11
Training loss: 2.5485873404585924
Validation loss: 2.4745775806338512

Epoch: 6| Step: 12
Training loss: 2.862448286230725
Validation loss: 2.4670782263540314

Epoch: 6| Step: 13
Training loss: 1.9352810366287536
Validation loss: 2.478145137799649

Epoch: 157| Step: 0
Training loss: 1.9793107900512443
Validation loss: 2.478530855685653

Epoch: 6| Step: 1
Training loss: 2.172496679235451
Validation loss: 2.477773079691863

Epoch: 6| Step: 2
Training loss: 2.9094493032897284
Validation loss: 2.478966606039346

Epoch: 6| Step: 3
Training loss: 2.7612487306673956
Validation loss: 2.47560239005155

Epoch: 6| Step: 4
Training loss: 2.7239390871572757
Validation loss: 2.474999641649625

Epoch: 6| Step: 5
Training loss: 2.1127046655231165
Validation loss: 2.474931936259342

Epoch: 6| Step: 6
Training loss: 2.4741980399736643
Validation loss: 2.4765773736645484

Epoch: 6| Step: 7
Training loss: 2.2018641117031383
Validation loss: 2.4754990501630565

Epoch: 6| Step: 8
Training loss: 2.2614770209970745
Validation loss: 2.4753993177830673

Epoch: 6| Step: 9
Training loss: 2.7158905426239404
Validation loss: 2.482610831883902

Epoch: 6| Step: 10
Training loss: 2.939955152052756
Validation loss: 2.4732572961011536

Epoch: 6| Step: 11
Training loss: 2.408340536808562
Validation loss: 2.4809111753772024

Epoch: 6| Step: 12
Training loss: 2.5056888703683646
Validation loss: 2.476330253870623

Epoch: 6| Step: 13
Training loss: 2.377142090758001
Validation loss: 2.475992484133174

Epoch: 158| Step: 0
Training loss: 2.2761627328013803
Validation loss: 2.47388439402598

Epoch: 6| Step: 1
Training loss: 2.806636462543669
Validation loss: 2.475371787535458

Epoch: 6| Step: 2
Training loss: 2.85268900319509
Validation loss: 2.4798799071152597

Epoch: 6| Step: 3
Training loss: 2.598967853495579
Validation loss: 2.4732901919099235

Epoch: 6| Step: 4
Training loss: 2.46966448879708
Validation loss: 2.4745229511780615

Epoch: 6| Step: 5
Training loss: 2.360298329748555
Validation loss: 2.4732196119886245

Epoch: 6| Step: 6
Training loss: 2.6459896512049035
Validation loss: 2.473027045323535

Epoch: 6| Step: 7
Training loss: 2.4037931706384916
Validation loss: 2.472996853495425

Epoch: 6| Step: 8
Training loss: 2.4311242470666308
Validation loss: 2.471745440290378

Epoch: 6| Step: 9
Training loss: 2.3915799296885547
Validation loss: 2.478299988528951

Epoch: 6| Step: 10
Training loss: 2.523507226506198
Validation loss: 2.474062406793602

Epoch: 6| Step: 11
Training loss: 2.453369614377784
Validation loss: 2.468640176124958

Epoch: 6| Step: 12
Training loss: 2.080427915864991
Validation loss: 2.4688917191788025

Epoch: 6| Step: 13
Training loss: 2.3304775563967874
Validation loss: 2.4750402126192284

Epoch: 159| Step: 0
Training loss: 2.6361937049581607
Validation loss: 2.474677121329764

Epoch: 6| Step: 1
Training loss: 2.781187249665185
Validation loss: 2.4792183355081563

Epoch: 6| Step: 2
Training loss: 3.0107608761177995
Validation loss: 2.4713048149516723

Epoch: 6| Step: 3
Training loss: 2.2945251901174446
Validation loss: 2.4856284955915924

Epoch: 6| Step: 4
Training loss: 2.1651703240261395
Validation loss: 2.4893323433953585

Epoch: 6| Step: 5
Training loss: 2.2533506240783256
Validation loss: 2.477615597848034

Epoch: 6| Step: 6
Training loss: 2.8680338844627964
Validation loss: 2.4736346919869243

Epoch: 6| Step: 7
Training loss: 2.1722923262076144
Validation loss: 2.4752008684123514

Epoch: 6| Step: 8
Training loss: 2.706538784485648
Validation loss: 2.470729645799073

Epoch: 6| Step: 9
Training loss: 2.4845689421953514
Validation loss: 2.47675833745074

Epoch: 6| Step: 10
Training loss: 1.6808630090204804
Validation loss: 2.4740344761959827

Epoch: 6| Step: 11
Training loss: 2.676995084225826
Validation loss: 2.4690747268799536

Epoch: 6| Step: 12
Training loss: 2.55661525961443
Validation loss: 2.480668091460983

Epoch: 6| Step: 13
Training loss: 2.1884050949118254
Validation loss: 2.480335782709883

Epoch: 160| Step: 0
Training loss: 2.258460984604767
Validation loss: 2.4793228987077334

Epoch: 6| Step: 1
Training loss: 2.532825121180383
Validation loss: 2.476480316178359

Epoch: 6| Step: 2
Training loss: 2.6605828345095945
Validation loss: 2.4783684757240616

Epoch: 6| Step: 3
Training loss: 2.454770453573272
Validation loss: 2.4776013238321326

Epoch: 6| Step: 4
Training loss: 3.079576798631103
Validation loss: 2.479488830043287

Epoch: 6| Step: 5
Training loss: 2.3371272804815098
Validation loss: 2.473752791583218

Epoch: 6| Step: 6
Training loss: 2.6874621189020407
Validation loss: 2.474403828447112

Epoch: 6| Step: 7
Training loss: 2.4964628946582637
Validation loss: 2.4778512996785924

Epoch: 6| Step: 8
Training loss: 2.4649946405379586
Validation loss: 2.4739595968678243

Epoch: 6| Step: 9
Training loss: 2.1142321014602947
Validation loss: 2.4755380479141977

Epoch: 6| Step: 10
Training loss: 2.321721224101603
Validation loss: 2.4770157015278054

Epoch: 6| Step: 11
Training loss: 2.503865686525471
Validation loss: 2.4850753500789198

Epoch: 6| Step: 12
Training loss: 2.322331741200323
Validation loss: 2.4702216160411137

Epoch: 6| Step: 13
Training loss: 2.5292733091928232
Validation loss: 2.4746095516342264

Epoch: 161| Step: 0
Training loss: 1.7939107576966
Validation loss: 2.467765305906625

Epoch: 6| Step: 1
Training loss: 2.720526191780251
Validation loss: 2.4686656084404364

Epoch: 6| Step: 2
Training loss: 2.9801121169639395
Validation loss: 2.455574578239824

Epoch: 6| Step: 3
Training loss: 2.560660842000343
Validation loss: 2.470827250824293

Epoch: 6| Step: 4
Training loss: 2.5714270311684007
Validation loss: 2.469160343625121

Epoch: 6| Step: 5
Training loss: 1.9628750776747461
Validation loss: 2.471063769007182

Epoch: 6| Step: 6
Training loss: 1.8733074178068339
Validation loss: 2.4703566719174006

Epoch: 6| Step: 7
Training loss: 2.0834947777818376
Validation loss: 2.4759457820118436

Epoch: 6| Step: 8
Training loss: 2.9069621536421004
Validation loss: 2.472426811127591

Epoch: 6| Step: 9
Training loss: 2.3741059879338495
Validation loss: 2.4740847317713945

Epoch: 6| Step: 10
Training loss: 2.4168540838069954
Validation loss: 2.4662578897016476

Epoch: 6| Step: 11
Training loss: 2.9082837935840162
Validation loss: 2.467437846113739

Epoch: 6| Step: 12
Training loss: 2.679543716532461
Validation loss: 2.4772918782356945

Epoch: 6| Step: 13
Training loss: 2.3224138705048
Validation loss: 2.4720324331530334

Epoch: 162| Step: 0
Training loss: 2.7546384879526937
Validation loss: 2.464301144806312

Epoch: 6| Step: 1
Training loss: 2.712787096150475
Validation loss: 2.463890846674085

Epoch: 6| Step: 2
Training loss: 1.9662106804332677
Validation loss: 2.46880699446032

Epoch: 6| Step: 3
Training loss: 2.5360786629038214
Validation loss: 2.469226992274986

Epoch: 6| Step: 4
Training loss: 2.4325276055489713
Validation loss: 2.4674346413502684

Epoch: 6| Step: 5
Training loss: 2.1813800762052526
Validation loss: 2.4679733374539823

Epoch: 6| Step: 6
Training loss: 2.4299775468707314
Validation loss: 2.470570983167548

Epoch: 6| Step: 7
Training loss: 2.580971181372374
Validation loss: 2.464949325984662

Epoch: 6| Step: 8
Training loss: 2.4263238223291634
Validation loss: 2.4646155508154677

Epoch: 6| Step: 9
Training loss: 2.742331215768577
Validation loss: 2.4725219465103936

Epoch: 6| Step: 10
Training loss: 2.733031722229794
Validation loss: 2.47412435409565

Epoch: 6| Step: 11
Training loss: 2.2351139153928408
Validation loss: 2.4742821785967526

Epoch: 6| Step: 12
Training loss: 1.7538626820477874
Validation loss: 2.494707043725041

Epoch: 6| Step: 13
Training loss: 3.0026945093376134
Validation loss: 2.4778270842213224

Epoch: 163| Step: 0
Training loss: 2.8494785166364145
Validation loss: 2.4776680100460133

Epoch: 6| Step: 1
Training loss: 2.2514385287207817
Validation loss: 2.4680499359846375

Epoch: 6| Step: 2
Training loss: 2.7396094220639235
Validation loss: 2.467600019425357

Epoch: 6| Step: 3
Training loss: 2.332446599678188
Validation loss: 2.463339175611837

Epoch: 6| Step: 4
Training loss: 2.8713314035889064
Validation loss: 2.458963399630472

Epoch: 6| Step: 5
Training loss: 2.284472449607646
Validation loss: 2.467891294288941

Epoch: 6| Step: 6
Training loss: 2.575347421411896
Validation loss: 2.4631591214902167

Epoch: 6| Step: 7
Training loss: 2.4643283311148205
Validation loss: 2.462871022036752

Epoch: 6| Step: 8
Training loss: 2.132287488323591
Validation loss: 2.466803962735595

Epoch: 6| Step: 9
Training loss: 2.414236315546738
Validation loss: 2.467770603521984

Epoch: 6| Step: 10
Training loss: 2.611734111899323
Validation loss: 2.47185126806442

Epoch: 6| Step: 11
Training loss: 1.8603221500504648
Validation loss: 2.471772207123398

Epoch: 6| Step: 12
Training loss: 2.421861611606139
Validation loss: 2.47548151341491

Epoch: 6| Step: 13
Training loss: 2.7356432779950857
Validation loss: 2.475186395851076

Epoch: 164| Step: 0
Training loss: 1.6274580338043847
Validation loss: 2.4716885296640703

Epoch: 6| Step: 1
Training loss: 2.622664093469477
Validation loss: 2.4737521008647563

Epoch: 6| Step: 2
Training loss: 2.0823852925118653
Validation loss: 2.475786346208811

Epoch: 6| Step: 3
Training loss: 2.368841518757895
Validation loss: 2.4708891586207082

Epoch: 6| Step: 4
Training loss: 3.21844599501106
Validation loss: 2.4733138412759725

Epoch: 6| Step: 5
Training loss: 2.5365707612757875
Validation loss: 2.4742688168229057

Epoch: 6| Step: 6
Training loss: 2.0010914208738253
Validation loss: 2.475824223975294

Epoch: 6| Step: 7
Training loss: 1.9942933564912146
Validation loss: 2.4725854912748315

Epoch: 6| Step: 8
Training loss: 2.816428767734619
Validation loss: 2.472799866469425

Epoch: 6| Step: 9
Training loss: 2.830930551187106
Validation loss: 2.4746516383937

Epoch: 6| Step: 10
Training loss: 2.252156601618842
Validation loss: 2.4711427480925496

Epoch: 6| Step: 11
Training loss: 2.9632467560051587
Validation loss: 2.474464932155007

Epoch: 6| Step: 12
Training loss: 2.378921483684804
Validation loss: 2.4758626789454037

Epoch: 6| Step: 13
Training loss: 2.298261366785465
Validation loss: 2.4735935357157395

Epoch: 165| Step: 0
Training loss: 2.635169448615914
Validation loss: 2.469433653609685

Epoch: 6| Step: 1
Training loss: 2.316704304707275
Validation loss: 2.4717083681498115

Epoch: 6| Step: 2
Training loss: 2.7562066176410682
Validation loss: 2.4706881838059016

Epoch: 6| Step: 3
Training loss: 2.548126381337341
Validation loss: 2.466176715940781

Epoch: 6| Step: 4
Training loss: 3.207325929956555
Validation loss: 2.466383077025039

Epoch: 6| Step: 5
Training loss: 2.3001623179338395
Validation loss: 2.4691120316838813

Epoch: 6| Step: 6
Training loss: 2.0111243101193854
Validation loss: 2.465111010168718

Epoch: 6| Step: 7
Training loss: 2.2900739394665575
Validation loss: 2.46885965803914

Epoch: 6| Step: 8
Training loss: 3.0139599883037915
Validation loss: 2.46775264955155

Epoch: 6| Step: 9
Training loss: 2.785215829262819
Validation loss: 2.4675277227347205

Epoch: 6| Step: 10
Training loss: 2.277610383692963
Validation loss: 2.4671857280213474

Epoch: 6| Step: 11
Training loss: 1.8549645310992748
Validation loss: 2.4790777195807476

Epoch: 6| Step: 12
Training loss: 1.9357140215811703
Validation loss: 2.4747776214160804

Epoch: 6| Step: 13
Training loss: 2.155872477778288
Validation loss: 2.4732176839861872

Epoch: 166| Step: 0
Training loss: 2.6013330123538796
Validation loss: 2.4842560697675062

Epoch: 6| Step: 1
Training loss: 2.0984970481984497
Validation loss: 2.4908827791467565

Epoch: 6| Step: 2
Training loss: 2.5612989262552373
Validation loss: 2.4884592069491647

Epoch: 6| Step: 3
Training loss: 2.2697755875761247
Validation loss: 2.487969555139047

Epoch: 6| Step: 4
Training loss: 2.3219379935056006
Validation loss: 2.4904716428530937

Epoch: 6| Step: 5
Training loss: 2.686628422129672
Validation loss: 2.48258003633422

Epoch: 6| Step: 6
Training loss: 2.9496610802397707
Validation loss: 2.4797708085120926

Epoch: 6| Step: 7
Training loss: 2.603751421564953
Validation loss: 2.476982450128652

Epoch: 6| Step: 8
Training loss: 2.7649885404325176
Validation loss: 2.473443973008259

Epoch: 6| Step: 9
Training loss: 2.3455348021934745
Validation loss: 2.468251978864108

Epoch: 6| Step: 10
Training loss: 2.6346908796268615
Validation loss: 2.46612038577417

Epoch: 6| Step: 11
Training loss: 2.2267573756550534
Validation loss: 2.4653636869646034

Epoch: 6| Step: 12
Training loss: 2.6122439026222475
Validation loss: 2.4729150171657377

Epoch: 6| Step: 13
Training loss: 1.9509867445721762
Validation loss: 2.4698986970408323

Epoch: 167| Step: 0
Training loss: 2.3216092888213136
Validation loss: 2.4711221492911113

Epoch: 6| Step: 1
Training loss: 2.7779157561895804
Validation loss: 2.4714774585729797

Epoch: 6| Step: 2
Training loss: 2.255206547854615
Validation loss: 2.4647648915101086

Epoch: 6| Step: 3
Training loss: 2.1271860434766894
Validation loss: 2.474015363069374

Epoch: 6| Step: 4
Training loss: 2.7039046734196592
Validation loss: 2.4714404547647417

Epoch: 6| Step: 5
Training loss: 1.8789453958410733
Validation loss: 2.462966760461419

Epoch: 6| Step: 6
Training loss: 2.3408508680734146
Validation loss: 2.4959623633536534

Epoch: 6| Step: 7
Training loss: 2.172233058038446
Validation loss: 2.5184520213873745

Epoch: 6| Step: 8
Training loss: 2.415965000322228
Validation loss: 2.511741966349882

Epoch: 6| Step: 9
Training loss: 2.7156960007282813
Validation loss: 2.489233963419247

Epoch: 6| Step: 10
Training loss: 2.5387570241420536
Validation loss: 2.4724111330051706

Epoch: 6| Step: 11
Training loss: 2.686376913630815
Validation loss: 2.4704184226149235

Epoch: 6| Step: 12
Training loss: 2.67375759257433
Validation loss: 2.4723164192808524

Epoch: 6| Step: 13
Training loss: 3.061539791373785
Validation loss: 2.4721021307543443

Epoch: 168| Step: 0
Training loss: 2.2152279044675494
Validation loss: 2.4737823637904106

Epoch: 6| Step: 1
Training loss: 2.8342031004067914
Validation loss: 2.483272827827984

Epoch: 6| Step: 2
Training loss: 2.3063726955950394
Validation loss: 2.4775127108261

Epoch: 6| Step: 3
Training loss: 2.4432598432215564
Validation loss: 2.4896877910667627

Epoch: 6| Step: 4
Training loss: 2.502194966905014
Validation loss: 2.488704244211238

Epoch: 6| Step: 5
Training loss: 3.0455529107780466
Validation loss: 2.48312940101544

Epoch: 6| Step: 6
Training loss: 2.2062256549648316
Validation loss: 2.484062095146484

Epoch: 6| Step: 7
Training loss: 1.8824974207968097
Validation loss: 2.484743518807971

Epoch: 6| Step: 8
Training loss: 2.9823027601356626
Validation loss: 2.485823682748611

Epoch: 6| Step: 9
Training loss: 2.853793340246103
Validation loss: 2.488192011232565

Epoch: 6| Step: 10
Training loss: 2.5017023012934363
Validation loss: 2.485222294111839

Epoch: 6| Step: 11
Training loss: 2.6135948004452234
Validation loss: 2.4735045863532434

Epoch: 6| Step: 12
Training loss: 2.6008600426446984
Validation loss: 2.4695099252554256

Epoch: 6| Step: 13
Training loss: 2.136214787888876
Validation loss: 2.476637348764803

Epoch: 169| Step: 0
Training loss: 1.9845084198080856
Validation loss: 2.4819346984584647

Epoch: 6| Step: 1
Training loss: 2.2694779880596667
Validation loss: 2.4780613708665418

Epoch: 6| Step: 2
Training loss: 2.9449893359264823
Validation loss: 2.4693447555508854

Epoch: 6| Step: 3
Training loss: 2.1617818444752994
Validation loss: 2.4856408051443983

Epoch: 6| Step: 4
Training loss: 2.6677156610374597
Validation loss: 2.4869077555737915

Epoch: 6| Step: 5
Training loss: 1.9207647574782698
Validation loss: 2.5026961252476885

Epoch: 6| Step: 6
Training loss: 2.576811577282218
Validation loss: 2.506484332588845

Epoch: 6| Step: 7
Training loss: 2.984892315990901
Validation loss: 2.5123688611400126

Epoch: 6| Step: 8
Training loss: 2.816995884392291
Validation loss: 2.498414275805167

Epoch: 6| Step: 9
Training loss: 2.1375296830464228
Validation loss: 2.4801160987217585

Epoch: 6| Step: 10
Training loss: 2.3899661882953636
Validation loss: 2.4844342510587314

Epoch: 6| Step: 11
Training loss: 3.085587339211981
Validation loss: 2.478011179904179

Epoch: 6| Step: 12
Training loss: 2.271208309280121
Validation loss: 2.4775784531588103

Epoch: 6| Step: 13
Training loss: 2.1767262678568984
Validation loss: 2.48719777582772

Epoch: 170| Step: 0
Training loss: 2.0946928719610036
Validation loss: 2.4783887257015618

Epoch: 6| Step: 1
Training loss: 2.987159109418665
Validation loss: 2.4812087669758034

Epoch: 6| Step: 2
Training loss: 2.419366534215079
Validation loss: 2.4788393210564865

Epoch: 6| Step: 3
Training loss: 2.0786010655802962
Validation loss: 2.476594878585742

Epoch: 6| Step: 4
Training loss: 1.955984661888568
Validation loss: 2.4852892874739267

Epoch: 6| Step: 5
Training loss: 2.7535459025657483
Validation loss: 2.4842652750476253

Epoch: 6| Step: 6
Training loss: 2.253058156623771
Validation loss: 2.482200214485174

Epoch: 6| Step: 7
Training loss: 2.573402657472746
Validation loss: 2.484718155103861

Epoch: 6| Step: 8
Training loss: 2.308377896462886
Validation loss: 2.4793999238969575

Epoch: 6| Step: 9
Training loss: 2.5982841478561363
Validation loss: 2.481004263674706

Epoch: 6| Step: 10
Training loss: 2.4394558615627164
Validation loss: 2.4814599006841536

Epoch: 6| Step: 11
Training loss: 2.190430558264428
Validation loss: 2.4768728388699

Epoch: 6| Step: 12
Training loss: 2.81099100957876
Validation loss: 2.478827194137869

Epoch: 6| Step: 13
Training loss: 2.7818470003411195
Validation loss: 2.4750783907873712

Epoch: 171| Step: 0
Training loss: 2.3533363115689863
Validation loss: 2.4659310193279413

Epoch: 6| Step: 1
Training loss: 2.225658567883002
Validation loss: 2.4650399864982306

Epoch: 6| Step: 2
Training loss: 2.353215241949845
Validation loss: 2.4682903747203184

Epoch: 6| Step: 3
Training loss: 2.2779707658882935
Validation loss: 2.469244412517724

Epoch: 6| Step: 4
Training loss: 2.1959348183427285
Validation loss: 2.4663225625563383

Epoch: 6| Step: 5
Training loss: 2.316710788206026
Validation loss: 2.4656943875127544

Epoch: 6| Step: 6
Training loss: 2.272245009146636
Validation loss: 2.466616743029325

Epoch: 6| Step: 7
Training loss: 2.4339864790516605
Validation loss: 2.4683123816357164

Epoch: 6| Step: 8
Training loss: 2.560380757149614
Validation loss: 2.4722706763797095

Epoch: 6| Step: 9
Training loss: 2.5361298042194327
Validation loss: 2.4728993501729124

Epoch: 6| Step: 10
Training loss: 2.379137751397449
Validation loss: 2.469584497016318

Epoch: 6| Step: 11
Training loss: 2.793742807536926
Validation loss: 2.476412121752988

Epoch: 6| Step: 12
Training loss: 3.044064834886757
Validation loss: 2.46652901615511

Epoch: 6| Step: 13
Training loss: 2.7071126289851226
Validation loss: 2.468664779479854

Epoch: 172| Step: 0
Training loss: 2.4369640250135425
Validation loss: 2.472707626347386

Epoch: 6| Step: 1
Training loss: 2.7654491303985806
Validation loss: 2.473752052675089

Epoch: 6| Step: 2
Training loss: 2.8696444843486684
Validation loss: 2.4693103588915375

Epoch: 6| Step: 3
Training loss: 2.4496062487833363
Validation loss: 2.467875555149973

Epoch: 6| Step: 4
Training loss: 2.893083835983888
Validation loss: 2.473073368736999

Epoch: 6| Step: 5
Training loss: 2.645822139526077
Validation loss: 2.4695924536717517

Epoch: 6| Step: 6
Training loss: 2.0761213466922896
Validation loss: 2.4711807774348666

Epoch: 6| Step: 7
Training loss: 2.6886622554945596
Validation loss: 2.469936359424785

Epoch: 6| Step: 8
Training loss: 2.525210109315937
Validation loss: 2.472072779559363

Epoch: 6| Step: 9
Training loss: 2.1309220316177653
Validation loss: 2.469175575691739

Epoch: 6| Step: 10
Training loss: 2.107056198000709
Validation loss: 2.4691492071788637

Epoch: 6| Step: 11
Training loss: 2.019597478551683
Validation loss: 2.474657065783298

Epoch: 6| Step: 12
Training loss: 2.0966536471877917
Validation loss: 2.4723895643749576

Epoch: 6| Step: 13
Training loss: 2.6876476158587552
Validation loss: 2.4705076358941973

Epoch: 173| Step: 0
Training loss: 1.7619270827439528
Validation loss: 2.47112869397185

Epoch: 6| Step: 1
Training loss: 2.4040575814801155
Validation loss: 2.477737035924822

Epoch: 6| Step: 2
Training loss: 2.5629431178597235
Validation loss: 2.471930487227399

Epoch: 6| Step: 3
Training loss: 2.426155884542177
Validation loss: 2.4771950412348485

Epoch: 6| Step: 4
Training loss: 2.672324159580831
Validation loss: 2.469729032222367

Epoch: 6| Step: 5
Training loss: 2.481639003287779
Validation loss: 2.4744966476766126

Epoch: 6| Step: 6
Training loss: 2.3213182318318744
Validation loss: 2.4829788283532293

Epoch: 6| Step: 7
Training loss: 2.165838291073984
Validation loss: 2.468216649319093

Epoch: 6| Step: 8
Training loss: 2.578104469911155
Validation loss: 2.4722715202040657

Epoch: 6| Step: 9
Training loss: 2.8666951850832847
Validation loss: 2.4681928786662164

Epoch: 6| Step: 10
Training loss: 2.6731275333074125
Validation loss: 2.468193120157238

Epoch: 6| Step: 11
Training loss: 2.5238284348518807
Validation loss: 2.4738328654279313

Epoch: 6| Step: 12
Training loss: 2.154843742564784
Validation loss: 2.4722800548685058

Epoch: 6| Step: 13
Training loss: 2.65952287883639
Validation loss: 2.464511387458239

Epoch: 174| Step: 0
Training loss: 2.6129022388995704
Validation loss: 2.466824549270323

Epoch: 6| Step: 1
Training loss: 2.656015453081103
Validation loss: 2.471649704289982

Epoch: 6| Step: 2
Training loss: 2.865324074888944
Validation loss: 2.4682371355260706

Epoch: 6| Step: 3
Training loss: 2.6906598167514972
Validation loss: 2.4647663182883934

Epoch: 6| Step: 4
Training loss: 1.975165917875561
Validation loss: 2.472499237780426

Epoch: 6| Step: 5
Training loss: 2.3066949926779667
Validation loss: 2.464409388393266

Epoch: 6| Step: 6
Training loss: 2.445570277072924
Validation loss: 2.4703612401385695

Epoch: 6| Step: 7
Training loss: 2.3165685587173
Validation loss: 2.4735482180457846

Epoch: 6| Step: 8
Training loss: 2.259501844884428
Validation loss: 2.471096163360675

Epoch: 6| Step: 9
Training loss: 2.5405711225777035
Validation loss: 2.485607824997606

Epoch: 6| Step: 10
Training loss: 2.1198175852047876
Validation loss: 2.481311052341583

Epoch: 6| Step: 11
Training loss: 2.6909514154976577
Validation loss: 2.477861202289134

Epoch: 6| Step: 12
Training loss: 2.46223904538901
Validation loss: 2.477263663240617

Epoch: 6| Step: 13
Training loss: 2.2168316136801787
Validation loss: 2.470287286998518

Epoch: 175| Step: 0
Training loss: 2.4944259492301284
Validation loss: 2.4787383604457713

Epoch: 6| Step: 1
Training loss: 2.305877481784003
Validation loss: 2.4802517693401165

Epoch: 6| Step: 2
Training loss: 2.508538827262213
Validation loss: 2.4773364858241123

Epoch: 6| Step: 3
Training loss: 2.3186549164640837
Validation loss: 2.475844462662982

Epoch: 6| Step: 4
Training loss: 2.564931878566566
Validation loss: 2.4746635850580256

Epoch: 6| Step: 5
Training loss: 2.0582096675320667
Validation loss: 2.4723088169529017

Epoch: 6| Step: 6
Training loss: 2.7476895770410064
Validation loss: 2.476449588805017

Epoch: 6| Step: 7
Training loss: 2.5533987171709196
Validation loss: 2.4696563312504582

Epoch: 6| Step: 8
Training loss: 2.86378930386663
Validation loss: 2.4800986026317666

Epoch: 6| Step: 9
Training loss: 2.4296600242116084
Validation loss: 2.4696126307983053

Epoch: 6| Step: 10
Training loss: 2.1621341858967695
Validation loss: 2.463563920311022

Epoch: 6| Step: 11
Training loss: 2.4898644026637964
Validation loss: 2.464586973039826

Epoch: 6| Step: 12
Training loss: 2.591134096563138
Validation loss: 2.460486121385752

Epoch: 6| Step: 13
Training loss: 2.237888801082561
Validation loss: 2.459329651055389

Epoch: 176| Step: 0
Training loss: 2.657252403057927
Validation loss: 2.463901248897538

Epoch: 6| Step: 1
Training loss: 2.2914449642330244
Validation loss: 2.46751261737848

Epoch: 6| Step: 2
Training loss: 2.0240523534570225
Validation loss: 2.4655140621754135

Epoch: 6| Step: 3
Training loss: 2.254393209283915
Validation loss: 2.4657651828356575

Epoch: 6| Step: 4
Training loss: 2.4723858677950052
Validation loss: 2.4669924729202375

Epoch: 6| Step: 5
Training loss: 2.49771041930697
Validation loss: 2.466289009898097

Epoch: 6| Step: 6
Training loss: 2.93341267073874
Validation loss: 2.4704267626207748

Epoch: 6| Step: 7
Training loss: 2.3940737911187653
Validation loss: 2.475475180892715

Epoch: 6| Step: 8
Training loss: 2.422042151804883
Validation loss: 2.487361272780561

Epoch: 6| Step: 9
Training loss: 2.3789686874439147
Validation loss: 2.4907480864381726

Epoch: 6| Step: 10
Training loss: 1.9011381429638936
Validation loss: 2.4895041438533867

Epoch: 6| Step: 11
Training loss: 2.7079611498075793
Validation loss: 2.493430661666487

Epoch: 6| Step: 12
Training loss: 2.9613141547516237
Validation loss: 2.479898942995725

Epoch: 6| Step: 13
Training loss: 2.5034145878262475
Validation loss: 2.4831192073631234

Epoch: 177| Step: 0
Training loss: 2.561486020325744
Validation loss: 2.480463079010496

Epoch: 6| Step: 1
Training loss: 2.295746195040082
Validation loss: 2.470190167358792

Epoch: 6| Step: 2
Training loss: 1.7940958839317833
Validation loss: 2.475737521554893

Epoch: 6| Step: 3
Training loss: 3.006681948141551
Validation loss: 2.473846735528643

Epoch: 6| Step: 4
Training loss: 2.2392397121624543
Validation loss: 2.480747717841991

Epoch: 6| Step: 5
Training loss: 2.593359492675852
Validation loss: 2.4780799957845403

Epoch: 6| Step: 6
Training loss: 2.472233499603648
Validation loss: 2.4780579072417313

Epoch: 6| Step: 7
Training loss: 2.3324214538563615
Validation loss: 2.4807976051664884

Epoch: 6| Step: 8
Training loss: 2.276613723712714
Validation loss: 2.474528370820818

Epoch: 6| Step: 9
Training loss: 2.2774257219850083
Validation loss: 2.476015513892762

Epoch: 6| Step: 10
Training loss: 2.3433148806710475
Validation loss: 2.481450484829771

Epoch: 6| Step: 11
Training loss: 2.0328461464656384
Validation loss: 2.486014802643153

Epoch: 6| Step: 12
Training loss: 3.1010663382757886
Validation loss: 2.4844262219792705

Epoch: 6| Step: 13
Training loss: 2.596091075692649
Validation loss: 2.4886693886296554

Epoch: 178| Step: 0
Training loss: 1.847166097197869
Validation loss: 2.494189726670565

Epoch: 6| Step: 1
Training loss: 2.2405120225246264
Validation loss: 2.4869841144505895

Epoch: 6| Step: 2
Training loss: 2.179626901529389
Validation loss: 2.4771557407260967

Epoch: 6| Step: 3
Training loss: 2.636934489148533
Validation loss: 2.487458321048056

Epoch: 6| Step: 4
Training loss: 3.17892514399222
Validation loss: 2.4754551398380227

Epoch: 6| Step: 5
Training loss: 2.3811455571055573
Validation loss: 2.488999371427521

Epoch: 6| Step: 6
Training loss: 2.0640086811681533
Validation loss: 2.480886381139748

Epoch: 6| Step: 7
Training loss: 2.355013017233733
Validation loss: 2.4859367436140705

Epoch: 6| Step: 8
Training loss: 2.4996567490492825
Validation loss: 2.476987848347793

Epoch: 6| Step: 9
Training loss: 2.23871186326695
Validation loss: 2.4772926160879907

Epoch: 6| Step: 10
Training loss: 2.5127255808211406
Validation loss: 2.488275133701315

Epoch: 6| Step: 11
Training loss: 2.527138467319868
Validation loss: 2.48386438588553

Epoch: 6| Step: 12
Training loss: 2.715063467671407
Validation loss: 2.4859879094385056

Epoch: 6| Step: 13
Training loss: 2.4310077379826143
Validation loss: 2.4825207490236383

Epoch: 179| Step: 0
Training loss: 2.857991535299698
Validation loss: 2.489778604124992

Epoch: 6| Step: 1
Training loss: 1.6783788506789075
Validation loss: 2.4798785130677663

Epoch: 6| Step: 2
Training loss: 3.1530068230765353
Validation loss: 2.4892553302268134

Epoch: 6| Step: 3
Training loss: 3.445307379132745
Validation loss: 2.4859857995284185

Epoch: 6| Step: 4
Training loss: 2.4439972579241416
Validation loss: 2.477391694823096

Epoch: 6| Step: 5
Training loss: 1.7978960536277586
Validation loss: 2.4776366879569682

Epoch: 6| Step: 6
Training loss: 2.513953939290557
Validation loss: 2.4947847646300554

Epoch: 6| Step: 7
Training loss: 2.5408280557753002
Validation loss: 2.4820621128743

Epoch: 6| Step: 8
Training loss: 1.9748069596411923
Validation loss: 2.489631561918786

Epoch: 6| Step: 9
Training loss: 2.074470461642688
Validation loss: 2.486894637397262

Epoch: 6| Step: 10
Training loss: 2.484908520494187
Validation loss: 2.4885062171409222

Epoch: 6| Step: 11
Training loss: 2.212980155783453
Validation loss: 2.4868348457576066

Epoch: 6| Step: 12
Training loss: 1.9502312547545444
Validation loss: 2.484262651826184

Epoch: 6| Step: 13
Training loss: 2.281829342370958
Validation loss: 2.4841198260338

Epoch: 180| Step: 0
Training loss: 2.1424970029010977
Validation loss: 2.492462334381759

Epoch: 6| Step: 1
Training loss: 2.7368440652176176
Validation loss: 2.486451231093079

Epoch: 6| Step: 2
Training loss: 2.3712879082560923
Validation loss: 2.4861094819909506

Epoch: 6| Step: 3
Training loss: 2.389757086088767
Validation loss: 2.481750973878533

Epoch: 6| Step: 4
Training loss: 2.33201376750278
Validation loss: 2.484762053658783

Epoch: 6| Step: 5
Training loss: 2.4223831135961222
Validation loss: 2.4869218163926283

Epoch: 6| Step: 6
Training loss: 2.5171303361952737
Validation loss: 2.492098975129036

Epoch: 6| Step: 7
Training loss: 2.7768552541020006
Validation loss: 2.4857600288013604

Epoch: 6| Step: 8
Training loss: 2.3063940938785974
Validation loss: 2.4843117727875064

Epoch: 6| Step: 9
Training loss: 2.7996515738456678
Validation loss: 2.4830116193727125

Epoch: 6| Step: 10
Training loss: 2.4290201429754488
Validation loss: 2.4743311765033473

Epoch: 6| Step: 11
Training loss: 1.9778018729686404
Validation loss: 2.4789345149061752

Epoch: 6| Step: 12
Training loss: 2.2813336082709523
Validation loss: 2.484187241022988

Epoch: 6| Step: 13
Training loss: 2.515672671417245
Validation loss: 2.480029634470415

Epoch: 181| Step: 0
Training loss: 2.7232396555663567
Validation loss: 2.481804563620686

Epoch: 6| Step: 1
Training loss: 2.0266831926040125
Validation loss: 2.485906213051591

Epoch: 6| Step: 2
Training loss: 2.389948630798416
Validation loss: 2.4863179364711097

Epoch: 6| Step: 3
Training loss: 2.496317249016891
Validation loss: 2.4833171839690316

Epoch: 6| Step: 4
Training loss: 2.3570695944130486
Validation loss: 2.482787274696046

Epoch: 6| Step: 5
Training loss: 2.3769286506289298
Validation loss: 2.476035414000306

Epoch: 6| Step: 6
Training loss: 2.2569584798784
Validation loss: 2.4844165054788867

Epoch: 6| Step: 7
Training loss: 2.523231899518948
Validation loss: 2.4869461430192863

Epoch: 6| Step: 8
Training loss: 2.091445337670547
Validation loss: 2.4895725542630527

Epoch: 6| Step: 9
Training loss: 2.9087002177582875
Validation loss: 2.4928353961251593

Epoch: 6| Step: 10
Training loss: 2.7356414477886855
Validation loss: 2.49621974923555

Epoch: 6| Step: 11
Training loss: 2.5931868343929345
Validation loss: 2.5121792953932354

Epoch: 6| Step: 12
Training loss: 2.345312081171109
Validation loss: 2.492789950046227

Epoch: 6| Step: 13
Training loss: 2.028186777170283
Validation loss: 2.4894378624929114

Epoch: 182| Step: 0
Training loss: 2.059499928414459
Validation loss: 2.493062151867975

Epoch: 6| Step: 1
Training loss: 2.15029793382769
Validation loss: 2.492336862646365

Epoch: 6| Step: 2
Training loss: 2.1742770955806665
Validation loss: 2.4796245429947255

Epoch: 6| Step: 3
Training loss: 2.5020133494410555
Validation loss: 2.476489510247817

Epoch: 6| Step: 4
Training loss: 2.549527244127543
Validation loss: 2.4721851271681152

Epoch: 6| Step: 5
Training loss: 2.669203465549775
Validation loss: 2.4701751989322753

Epoch: 6| Step: 6
Training loss: 1.7500940706309873
Validation loss: 2.4682827116956747

Epoch: 6| Step: 7
Training loss: 2.768696001271146
Validation loss: 2.4703664678460915

Epoch: 6| Step: 8
Training loss: 2.781104523358036
Validation loss: 2.4783225559221758

Epoch: 6| Step: 9
Training loss: 1.9440021314570042
Validation loss: 2.48230231492649

Epoch: 6| Step: 10
Training loss: 2.4809243091752005
Validation loss: 2.4764011543095217

Epoch: 6| Step: 11
Training loss: 2.7392713903406807
Validation loss: 2.4875099348064733

Epoch: 6| Step: 12
Training loss: 2.9915919097089163
Validation loss: 2.4932968476842263

Epoch: 6| Step: 13
Training loss: 2.1980085549574224
Validation loss: 2.4812716008294258

Epoch: 183| Step: 0
Training loss: 2.3374703267707884
Validation loss: 2.4650841871255627

Epoch: 6| Step: 1
Training loss: 2.9037156078126327
Validation loss: 2.4906349169167954

Epoch: 6| Step: 2
Training loss: 2.084035513481922
Validation loss: 2.467700686965589

Epoch: 6| Step: 3
Training loss: 2.3004243376339746
Validation loss: 2.4753031291350056

Epoch: 6| Step: 4
Training loss: 2.1021911361569887
Validation loss: 2.473617816713433

Epoch: 6| Step: 5
Training loss: 2.7868333130460763
Validation loss: 2.480237911026105

Epoch: 6| Step: 6
Training loss: 2.401606153440121
Validation loss: 2.483187713663235

Epoch: 6| Step: 7
Training loss: 2.2420212953221426
Validation loss: 2.4789246245980694

Epoch: 6| Step: 8
Training loss: 2.9283637960112725
Validation loss: 2.489267933125186

Epoch: 6| Step: 9
Training loss: 2.7684278348088087
Validation loss: 2.4872199349753457

Epoch: 6| Step: 10
Training loss: 1.8761107651437798
Validation loss: 2.495864141228451

Epoch: 6| Step: 11
Training loss: 2.367061095435161
Validation loss: 2.491287515386181

Epoch: 6| Step: 12
Training loss: 2.039442472753377
Validation loss: 2.495250195207312

Epoch: 6| Step: 13
Training loss: 2.5338644959937415
Validation loss: 2.4931971817615954

Epoch: 184| Step: 0
Training loss: 2.529765788911461
Validation loss: 2.491896322334711

Epoch: 6| Step: 1
Training loss: 2.3174564753357685
Validation loss: 2.493342770602816

Epoch: 6| Step: 2
Training loss: 2.244902133805068
Validation loss: 2.4961928147470855

Epoch: 6| Step: 3
Training loss: 2.7366238311066717
Validation loss: 2.497518038552495

Epoch: 6| Step: 4
Training loss: 2.536728757715765
Validation loss: 2.4936435316617436

Epoch: 6| Step: 5
Training loss: 2.0579348818131256
Validation loss: 2.496545375667041

Epoch: 6| Step: 6
Training loss: 2.50454308658092
Validation loss: 2.4985140039859313

Epoch: 6| Step: 7
Training loss: 2.6072406377204533
Validation loss: 2.4919931939890887

Epoch: 6| Step: 8
Training loss: 2.1931597923721675
Validation loss: 2.4845201781777706

Epoch: 6| Step: 9
Training loss: 2.304741499963246
Validation loss: 2.4939054588869665

Epoch: 6| Step: 10
Training loss: 2.567546341579058
Validation loss: 2.475918843635072

Epoch: 6| Step: 11
Training loss: 2.0467158830836523
Validation loss: 2.475029182904238

Epoch: 6| Step: 12
Training loss: 3.0268242371780616
Validation loss: 2.467460762466905

Epoch: 6| Step: 13
Training loss: 2.405296731356704
Validation loss: 2.4800586591725624

Epoch: 185| Step: 0
Training loss: 2.71868677175377
Validation loss: 2.4729330702390016

Epoch: 6| Step: 1
Training loss: 2.966389410228818
Validation loss: 2.4787639536603523

Epoch: 6| Step: 2
Training loss: 2.4636095829339566
Validation loss: 2.4753296488083714

Epoch: 6| Step: 3
Training loss: 2.0324955569285574
Validation loss: 2.4757946922071343

Epoch: 6| Step: 4
Training loss: 2.5016794285797106
Validation loss: 2.476219241705293

Epoch: 6| Step: 5
Training loss: 2.3826374927727785
Validation loss: 2.4767561715469077

Epoch: 6| Step: 6
Training loss: 2.3828052958395194
Validation loss: 2.481149494944598

Epoch: 6| Step: 7
Training loss: 2.6843330886286796
Validation loss: 2.4918361404178944

Epoch: 6| Step: 8
Training loss: 2.2807377279265686
Validation loss: 2.483784475460038

Epoch: 6| Step: 9
Training loss: 2.650592298712984
Validation loss: 2.4877435810950743

Epoch: 6| Step: 10
Training loss: 1.9046070335358456
Validation loss: 2.4787804332101855

Epoch: 6| Step: 11
Training loss: 2.5654982727199607
Validation loss: 2.490426313196393

Epoch: 6| Step: 12
Training loss: 2.3151182868678526
Validation loss: 2.4822060736080904

Epoch: 6| Step: 13
Training loss: 2.3525190974077583
Validation loss: 2.4875230177895844

Epoch: 186| Step: 0
Training loss: 2.447330410062533
Validation loss: 2.4926510243271487

Epoch: 6| Step: 1
Training loss: 2.4631095867550727
Validation loss: 2.4862091763179732

Epoch: 6| Step: 2
Training loss: 2.5884743777048334
Validation loss: 2.489866078387071

Epoch: 6| Step: 3
Training loss: 2.0695520695884393
Validation loss: 2.4934469964729082

Epoch: 6| Step: 4
Training loss: 2.3557943495484706
Validation loss: 2.4857074515217965

Epoch: 6| Step: 5
Training loss: 2.443935603827715
Validation loss: 2.491053738899922

Epoch: 6| Step: 6
Training loss: 2.2730122066829592
Validation loss: 2.482950277888921

Epoch: 6| Step: 7
Training loss: 2.2136458667838115
Validation loss: 2.4778328253908724

Epoch: 6| Step: 8
Training loss: 2.4901121102031962
Validation loss: 2.4829310333464516

Epoch: 6| Step: 9
Training loss: 2.770447916937156
Validation loss: 2.4897825461985508

Epoch: 6| Step: 10
Training loss: 2.1090658455812408
Validation loss: 2.4874567715005265

Epoch: 6| Step: 11
Training loss: 2.424196373617725
Validation loss: 2.4911872187728594

Epoch: 6| Step: 12
Training loss: 1.8867720760288786
Validation loss: 2.487936046854729

Epoch: 6| Step: 13
Training loss: 3.060731649754928
Validation loss: 2.488451063109664

Epoch: 187| Step: 0
Training loss: 2.5839124973763914
Validation loss: 2.484585799065078

Epoch: 6| Step: 1
Training loss: 1.823982435844581
Validation loss: 2.4790148221057926

Epoch: 6| Step: 2
Training loss: 2.446798537266649
Validation loss: 2.4756790173730434

Epoch: 6| Step: 3
Training loss: 1.6923211070509394
Validation loss: 2.4685262747686165

Epoch: 6| Step: 4
Training loss: 2.4515281387945587
Validation loss: 2.4722923103379473

Epoch: 6| Step: 5
Training loss: 2.120975273293943
Validation loss: 2.471225591811394

Epoch: 6| Step: 6
Training loss: 2.116560163847241
Validation loss: 2.4685680386729296

Epoch: 6| Step: 7
Training loss: 2.6357127891503787
Validation loss: 2.475540078445023

Epoch: 6| Step: 8
Training loss: 2.759305641624604
Validation loss: 2.473400227018247

Epoch: 6| Step: 9
Training loss: 2.6603322692086366
Validation loss: 2.4841974862776195

Epoch: 6| Step: 10
Training loss: 2.8140408851348355
Validation loss: 2.489216619215336

Epoch: 6| Step: 11
Training loss: 2.905574925270781
Validation loss: 2.490209210835887

Epoch: 6| Step: 12
Training loss: 2.5085813110385313
Validation loss: 2.4915677997234993

Epoch: 6| Step: 13
Training loss: 2.0190360607688658
Validation loss: 2.496252334484116

Epoch: 188| Step: 0
Training loss: 2.2222977334014784
Validation loss: 2.4912512444625277

Epoch: 6| Step: 1
Training loss: 1.7700415542810954
Validation loss: 2.4888479245264215

Epoch: 6| Step: 2
Training loss: 2.685903829260348
Validation loss: 2.493980233281087

Epoch: 6| Step: 3
Training loss: 2.714780167308492
Validation loss: 2.4958432927089502

Epoch: 6| Step: 4
Training loss: 2.4402637951944293
Validation loss: 2.4983980927611023

Epoch: 6| Step: 5
Training loss: 1.9947696482054902
Validation loss: 2.485004357328375

Epoch: 6| Step: 6
Training loss: 2.183955781845334
Validation loss: 2.4856444740187995

Epoch: 6| Step: 7
Training loss: 2.89972290162163
Validation loss: 2.480581446212673

Epoch: 6| Step: 8
Training loss: 2.599035003285493
Validation loss: 2.467331909566141

Epoch: 6| Step: 9
Training loss: 2.1563061693035075
Validation loss: 2.4748399201074545

Epoch: 6| Step: 10
Training loss: 2.7373055584974533
Validation loss: 2.4877481014160256

Epoch: 6| Step: 11
Training loss: 2.5754764708634856
Validation loss: 2.4766104419773076

Epoch: 6| Step: 12
Training loss: 2.411901204010586
Validation loss: 2.473224335588245

Epoch: 6| Step: 13
Training loss: 2.5665355632375877
Validation loss: 2.474573036254212

Epoch: 189| Step: 0
Training loss: 2.5312127946544734
Validation loss: 2.4758609776947456

Epoch: 6| Step: 1
Training loss: 2.240292057003146
Validation loss: 2.471150209286619

Epoch: 6| Step: 2
Training loss: 2.6947507411079155
Validation loss: 2.470427960941385

Epoch: 6| Step: 3
Training loss: 2.6192763461934043
Validation loss: 2.473700055477092

Epoch: 6| Step: 4
Training loss: 2.7923150424613983
Validation loss: 2.4684567981555916

Epoch: 6| Step: 5
Training loss: 2.1824947314291654
Validation loss: 2.4723069927121673

Epoch: 6| Step: 6
Training loss: 2.375755290347783
Validation loss: 2.4761663816051787

Epoch: 6| Step: 7
Training loss: 2.0311666618270583
Validation loss: 2.47151774168917

Epoch: 6| Step: 8
Training loss: 2.4238032386602653
Validation loss: 2.477372800074652

Epoch: 6| Step: 9
Training loss: 2.4835239128188826
Validation loss: 2.4783151644220522

Epoch: 6| Step: 10
Training loss: 2.4848228386833404
Validation loss: 2.4782766513033416

Epoch: 6| Step: 11
Training loss: 2.570737299266656
Validation loss: 2.489514486938421

Epoch: 6| Step: 12
Training loss: 1.8989274762342976
Validation loss: 2.490255102931503

Epoch: 6| Step: 13
Training loss: 2.404420429590858
Validation loss: 2.4915550330255214

Epoch: 190| Step: 0
Training loss: 2.060615603489462
Validation loss: 2.4955982558195267

Epoch: 6| Step: 1
Training loss: 2.8562508280479517
Validation loss: 2.5200782359558076

Epoch: 6| Step: 2
Training loss: 2.416923235285401
Validation loss: 2.508433295842398

Epoch: 6| Step: 3
Training loss: 2.88980668315644
Validation loss: 2.5041921752882996

Epoch: 6| Step: 4
Training loss: 3.0872334909667236
Validation loss: 2.4929414921992543

Epoch: 6| Step: 5
Training loss: 2.720030209149171
Validation loss: 2.4897908133608864

Epoch: 6| Step: 6
Training loss: 2.7185768861574813
Validation loss: 2.488730413518523

Epoch: 6| Step: 7
Training loss: 2.453213441068462
Validation loss: 2.4861662063555587

Epoch: 6| Step: 8
Training loss: 2.2349476113889284
Validation loss: 2.4772172738179563

Epoch: 6| Step: 9
Training loss: 2.720470015924444
Validation loss: 2.483482728428435

Epoch: 6| Step: 10
Training loss: 1.8881208371391482
Validation loss: 2.473734816777206

Epoch: 6| Step: 11
Training loss: 2.0774989511645594
Validation loss: 2.4792006728033216

Epoch: 6| Step: 12
Training loss: 1.7979673962676248
Validation loss: 2.48515920038257

Epoch: 6| Step: 13
Training loss: 2.018661695503621
Validation loss: 2.4835761683312625

Epoch: 191| Step: 0
Training loss: 1.709094444000086
Validation loss: 2.4882475383077813

Epoch: 6| Step: 1
Training loss: 2.5352247137808583
Validation loss: 2.4852389386933122

Epoch: 6| Step: 2
Training loss: 2.6679367577350717
Validation loss: 2.4867407772723724

Epoch: 6| Step: 3
Training loss: 2.4392167916820617
Validation loss: 2.4941192283499225

Epoch: 6| Step: 4
Training loss: 1.946526267473416
Validation loss: 2.4850470155839055

Epoch: 6| Step: 5
Training loss: 2.714140656904621
Validation loss: 2.500984037964818

Epoch: 6| Step: 6
Training loss: 2.2678287706005653
Validation loss: 2.4944833924732204

Epoch: 6| Step: 7
Training loss: 2.39780459922345
Validation loss: 2.494966127883032

Epoch: 6| Step: 8
Training loss: 2.2949287317051823
Validation loss: 2.506970907079269

Epoch: 6| Step: 9
Training loss: 2.446828743800689
Validation loss: 2.5080953579128633

Epoch: 6| Step: 10
Training loss: 2.3749094494071348
Validation loss: 2.5143876596679386

Epoch: 6| Step: 11
Training loss: 2.5656716792033833
Validation loss: 2.4943645379772543

Epoch: 6| Step: 12
Training loss: 2.9707817754422496
Validation loss: 2.50685472113568

Epoch: 6| Step: 13
Training loss: 2.3782037909910865
Validation loss: 2.4974272523454313

Epoch: 192| Step: 0
Training loss: 2.666009901550633
Validation loss: 2.487125721286543

Epoch: 6| Step: 1
Training loss: 2.3654141975924374
Validation loss: 2.5053152483188748

Epoch: 6| Step: 2
Training loss: 2.3781438398178882
Validation loss: 2.490090726810695

Epoch: 6| Step: 3
Training loss: 2.126769619286322
Validation loss: 2.491187027363248

Epoch: 6| Step: 4
Training loss: 2.1372792626337755
Validation loss: 2.4780981395110766

Epoch: 6| Step: 5
Training loss: 2.5104800858671723
Validation loss: 2.4772092534285868

Epoch: 6| Step: 6
Training loss: 2.4057920936755828
Validation loss: 2.4796779703695484

Epoch: 6| Step: 7
Training loss: 2.5346096019605437
Validation loss: 2.477468459271475

Epoch: 6| Step: 8
Training loss: 2.6635236894410883
Validation loss: 2.480827277597612

Epoch: 6| Step: 9
Training loss: 2.3191352709245296
Validation loss: 2.4718008866996914

Epoch: 6| Step: 10
Training loss: 2.363282662383359
Validation loss: 2.474724658266877

Epoch: 6| Step: 11
Training loss: 2.3574806338796153
Validation loss: 2.469672887663082

Epoch: 6| Step: 12
Training loss: 2.623413333020388
Validation loss: 2.478226809436724

Epoch: 6| Step: 13
Training loss: 2.9501519956063578
Validation loss: 2.4681644630577706

Epoch: 193| Step: 0
Training loss: 2.7326051924579042
Validation loss: 2.4726645101416302

Epoch: 6| Step: 1
Training loss: 2.6472653295959514
Validation loss: 2.4795281496628956

Epoch: 6| Step: 2
Training loss: 2.85885131709774
Validation loss: 2.4758395514661045

Epoch: 6| Step: 3
Training loss: 2.5534493248525303
Validation loss: 2.494033146003447

Epoch: 6| Step: 4
Training loss: 2.361901351729215
Validation loss: 2.489219947587813

Epoch: 6| Step: 5
Training loss: 2.6526044175343695
Validation loss: 2.4932475770220526

Epoch: 6| Step: 6
Training loss: 2.152723441583331
Validation loss: 2.516940560710179

Epoch: 6| Step: 7
Training loss: 1.7338405851147516
Validation loss: 2.5174455551073773

Epoch: 6| Step: 8
Training loss: 2.6559529755519966
Validation loss: 2.5013301330825866

Epoch: 6| Step: 9
Training loss: 2.55599466181811
Validation loss: 2.501378823565502

Epoch: 6| Step: 10
Training loss: 2.3349047773333
Validation loss: 2.4996615498645527

Epoch: 6| Step: 11
Training loss: 2.3269584856776846
Validation loss: 2.480731267378902

Epoch: 6| Step: 12
Training loss: 2.1775208783380573
Validation loss: 2.4707556838324316

Epoch: 6| Step: 13
Training loss: 2.505680497074192
Validation loss: 2.4654610450811676

Epoch: 194| Step: 0
Training loss: 2.4640419407037037
Validation loss: 2.4702951287904047

Epoch: 6| Step: 1
Training loss: 2.5115672491488397
Validation loss: 2.4662710531979246

Epoch: 6| Step: 2
Training loss: 1.8252804788851278
Validation loss: 2.4605961073371816

Epoch: 6| Step: 3
Training loss: 3.207317901698956
Validation loss: 2.4628888341184756

Epoch: 6| Step: 4
Training loss: 2.027083834118469
Validation loss: 2.4615352812847355

Epoch: 6| Step: 5
Training loss: 2.800917447873944
Validation loss: 2.4606367543038035

Epoch: 6| Step: 6
Training loss: 2.3558586139579685
Validation loss: 2.468393404674193

Epoch: 6| Step: 7
Training loss: 2.1165801018062274
Validation loss: 2.476441437563144

Epoch: 6| Step: 8
Training loss: 2.6420973786652167
Validation loss: 2.478436608303732

Epoch: 6| Step: 9
Training loss: 2.63943093293218
Validation loss: 2.486486205664078

Epoch: 6| Step: 10
Training loss: 2.7380806363745136
Validation loss: 2.4857692604831643

Epoch: 6| Step: 11
Training loss: 2.3154760233000773
Validation loss: 2.4977448305441716

Epoch: 6| Step: 12
Training loss: 1.8134858311430144
Validation loss: 2.4924797755689574

Epoch: 6| Step: 13
Training loss: 2.4437925837482224
Validation loss: 2.5063732449867526

Epoch: 195| Step: 0
Training loss: 2.2907261970513146
Validation loss: 2.4791391087985226

Epoch: 6| Step: 1
Training loss: 2.4910863279179325
Validation loss: 2.5055425874309165

Epoch: 6| Step: 2
Training loss: 2.3053033555469855
Validation loss: 2.4941742331426906

Epoch: 6| Step: 3
Training loss: 2.391543243183132
Validation loss: 2.4963178220655733

Epoch: 6| Step: 4
Training loss: 2.6513319374958777
Validation loss: 2.4879615135113986

Epoch: 6| Step: 5
Training loss: 2.3192031211971504
Validation loss: 2.493289795417228

Epoch: 6| Step: 6
Training loss: 2.348653724244221
Validation loss: 2.494156763975005

Epoch: 6| Step: 7
Training loss: 2.5374939754019943
Validation loss: 2.4961607222111764

Epoch: 6| Step: 8
Training loss: 2.4499611832015495
Validation loss: 2.4951021695416027

Epoch: 6| Step: 9
Training loss: 1.8265665046119355
Validation loss: 2.4999162500976384

Epoch: 6| Step: 10
Training loss: 2.4163071156642055
Validation loss: 2.4996581956535295

Epoch: 6| Step: 11
Training loss: 2.5994089738625616
Validation loss: 2.505466254922679

Epoch: 6| Step: 12
Training loss: 2.725026394777468
Validation loss: 2.512931440011948

Epoch: 6| Step: 13
Training loss: 2.2488879528638446
Validation loss: 2.5157817057260927

Epoch: 196| Step: 0
Training loss: 2.323663828023073
Validation loss: 2.511862569263912

Epoch: 6| Step: 1
Training loss: 3.02225220780675
Validation loss: 2.498756369575803

Epoch: 6| Step: 2
Training loss: 2.2810211066808512
Validation loss: 2.497433863334694

Epoch: 6| Step: 3
Training loss: 2.0873904079519865
Validation loss: 2.4996766358101428

Epoch: 6| Step: 4
Training loss: 3.2447811185727597
Validation loss: 2.5022621251836226

Epoch: 6| Step: 5
Training loss: 2.1598503903392663
Validation loss: 2.4970701692810136

Epoch: 6| Step: 6
Training loss: 2.6089601472477035
Validation loss: 2.5054420050270156

Epoch: 6| Step: 7
Training loss: 2.2650297237913244
Validation loss: 2.504562807618306

Epoch: 6| Step: 8
Training loss: 2.3420542367963435
Validation loss: 2.499350463410971

Epoch: 6| Step: 9
Training loss: 2.102430313352541
Validation loss: 2.5057596299301883

Epoch: 6| Step: 10
Training loss: 2.1450514865911616
Validation loss: 2.51246221523436

Epoch: 6| Step: 11
Training loss: 2.240878902930472
Validation loss: 2.499512640815093

Epoch: 6| Step: 12
Training loss: 2.071043180685088
Validation loss: 2.504934852461069

Epoch: 6| Step: 13
Training loss: 2.5177822932874085
Validation loss: 2.5121147749272392

Epoch: 197| Step: 0
Training loss: 2.31613080347456
Validation loss: 2.5131006705823515

Epoch: 6| Step: 1
Training loss: 2.8136242632774486
Validation loss: 2.513678877987971

Epoch: 6| Step: 2
Training loss: 1.7834045363261244
Validation loss: 2.5197429637031656

Epoch: 6| Step: 3
Training loss: 2.5354092182268384
Validation loss: 2.510486907820508

Epoch: 6| Step: 4
Training loss: 2.3950993173668746
Validation loss: 2.5267798272696065

Epoch: 6| Step: 5
Training loss: 2.2981279549827387
Validation loss: 2.518063060774796

Epoch: 6| Step: 6
Training loss: 2.2378719681294874
Validation loss: 2.5178688577896704

Epoch: 6| Step: 7
Training loss: 1.8337244859206339
Validation loss: 2.5137444727486105

Epoch: 6| Step: 8
Training loss: 2.2204241816481267
Validation loss: 2.5132097927595876

Epoch: 6| Step: 9
Training loss: 2.533397752377808
Validation loss: 2.5198140776637534

Epoch: 6| Step: 10
Training loss: 2.6034694704742374
Validation loss: 2.512304385084219

Epoch: 6| Step: 11
Training loss: 2.2913846160252382
Validation loss: 2.506974188104818

Epoch: 6| Step: 12
Training loss: 3.1349222969999655
Validation loss: 2.5011700117573037

Epoch: 6| Step: 13
Training loss: 2.16062516543228
Validation loss: 2.485780434369043

Epoch: 198| Step: 0
Training loss: 2.6558857387530836
Validation loss: 2.488922483661208

Epoch: 6| Step: 1
Training loss: 2.671497519079103
Validation loss: 2.4810262539135777

Epoch: 6| Step: 2
Training loss: 2.4570262041631414
Validation loss: 2.477254953259657

Epoch: 6| Step: 3
Training loss: 2.873924883631333
Validation loss: 2.489162446733526

Epoch: 6| Step: 4
Training loss: 2.263509038510656
Validation loss: 2.4879554842700444

Epoch: 6| Step: 5
Training loss: 2.4729953430909375
Validation loss: 2.505847640491978

Epoch: 6| Step: 6
Training loss: 1.9714077161590138
Validation loss: 2.504351008565043

Epoch: 6| Step: 7
Training loss: 2.2792106814786575
Validation loss: 2.50991676756158

Epoch: 6| Step: 8
Training loss: 2.350667079639164
Validation loss: 2.523317851880386

Epoch: 6| Step: 9
Training loss: 2.171518859205185
Validation loss: 2.524381588912063

Epoch: 6| Step: 10
Training loss: 2.3780676455104333
Validation loss: 2.5168875138431352

Epoch: 6| Step: 11
Training loss: 2.234127110955528
Validation loss: 2.5171825491763586

Epoch: 6| Step: 12
Training loss: 2.6296132739647424
Validation loss: 2.51820528689045

Epoch: 6| Step: 13
Training loss: 2.1928614716200885
Validation loss: 2.5007588029700347

Epoch: 199| Step: 0
Training loss: 1.7468123696006517
Validation loss: 2.5086794708378672

Epoch: 6| Step: 1
Training loss: 2.305229097512133
Validation loss: 2.500578495487214

Epoch: 6| Step: 2
Training loss: 2.742736065979465
Validation loss: 2.4874400459105974

Epoch: 6| Step: 3
Training loss: 2.8205458103375824
Validation loss: 2.490011143870101

Epoch: 6| Step: 4
Training loss: 2.5105876837975383
Validation loss: 2.48973208080158

Epoch: 6| Step: 5
Training loss: 2.4797956379397124
Validation loss: 2.484125456683058

Epoch: 6| Step: 6
Training loss: 2.2094097992612816
Validation loss: 2.4843008802061695

Epoch: 6| Step: 7
Training loss: 2.3460728642172026
Validation loss: 2.4895977248623136

Epoch: 6| Step: 8
Training loss: 2.20930566314716
Validation loss: 2.4939088049018046

Epoch: 6| Step: 9
Training loss: 2.421123954237417
Validation loss: 2.495000672528234

Epoch: 6| Step: 10
Training loss: 2.3239551042038182
Validation loss: 2.4933642376635112

Epoch: 6| Step: 11
Training loss: 2.8806930235339903
Validation loss: 2.5024059162879726

Epoch: 6| Step: 12
Training loss: 1.842410619423359
Validation loss: 2.493198265541355

Epoch: 6| Step: 13
Training loss: 2.5712025501433224
Validation loss: 2.5037552921456983

Epoch: 200| Step: 0
Training loss: 2.896891631538524
Validation loss: 2.5269229151375074

Epoch: 6| Step: 1
Training loss: 2.9681461724019975
Validation loss: 2.527586809800018

Epoch: 6| Step: 2
Training loss: 2.356844523983178
Validation loss: 2.5349115803212934

Epoch: 6| Step: 3
Training loss: 2.3923851963031026
Validation loss: 2.520633206160625

Epoch: 6| Step: 4
Training loss: 2.657029161057048
Validation loss: 2.5402813299325846

Epoch: 6| Step: 5
Training loss: 2.438771136498766
Validation loss: 2.5408824325710295

Epoch: 6| Step: 6
Training loss: 2.2201930981073024
Validation loss: 2.515904594663913

Epoch: 6| Step: 7
Training loss: 2.879060283044334
Validation loss: 2.5191360203069992

Epoch: 6| Step: 8
Training loss: 2.442897688976133
Validation loss: 2.521817312167734

Epoch: 6| Step: 9
Training loss: 1.7405734261725914
Validation loss: 2.5183962766841974

Epoch: 6| Step: 10
Training loss: 1.7518267633804074
Validation loss: 2.511180972385941

Epoch: 6| Step: 11
Training loss: 2.04854579613081
Validation loss: 2.510741253732364

Epoch: 6| Step: 12
Training loss: 1.8276388712041494
Validation loss: 2.503134058421203

Epoch: 6| Step: 13
Training loss: 2.6099480096893215
Validation loss: 2.499274068977185

Epoch: 201| Step: 0
Training loss: 2.2342243277159115
Validation loss: 2.501250987182199

Epoch: 6| Step: 1
Training loss: 2.694579447699284
Validation loss: 2.509910205283533

Epoch: 6| Step: 2
Training loss: 2.579183742567323
Validation loss: 2.497759514436815

Epoch: 6| Step: 3
Training loss: 2.3243184557132732
Validation loss: 2.4973795110960046

Epoch: 6| Step: 4
Training loss: 3.100687436822935
Validation loss: 2.4985335340526293

Epoch: 6| Step: 5
Training loss: 2.3084247869376733
Validation loss: 2.5024472656181405

Epoch: 6| Step: 6
Training loss: 2.5688722975824665
Validation loss: 2.5038686224797644

Epoch: 6| Step: 7
Training loss: 2.4021533921660017
Validation loss: 2.4978998263705843

Epoch: 6| Step: 8
Training loss: 2.5180442976263047
Validation loss: 2.493734599028462

Epoch: 6| Step: 9
Training loss: 1.6697769548319739
Validation loss: 2.4887741854207963

Epoch: 6| Step: 10
Training loss: 2.740094551766126
Validation loss: 2.4890861387181973

Epoch: 6| Step: 11
Training loss: 1.9970064409483532
Validation loss: 2.4944809870838647

Epoch: 6| Step: 12
Training loss: 1.940951810337833
Validation loss: 2.49686066293559

Epoch: 6| Step: 13
Training loss: 2.1988986986808983
Validation loss: 2.5088580319912874

Epoch: 202| Step: 0
Training loss: 2.1312543046745613
Validation loss: 2.527201456410583

Epoch: 6| Step: 1
Training loss: 2.266335948023368
Validation loss: 2.5353223749168525

Epoch: 6| Step: 2
Training loss: 1.823634051898275
Validation loss: 2.5208567993921402

Epoch: 6| Step: 3
Training loss: 2.79122635704513
Validation loss: 2.5240438577224005

Epoch: 6| Step: 4
Training loss: 2.2356949755323523
Validation loss: 2.5241348358125375

Epoch: 6| Step: 5
Training loss: 2.3426139621432855
Validation loss: 2.5240708098708295

Epoch: 6| Step: 6
Training loss: 1.8986041462914762
Validation loss: 2.526294441291542

Epoch: 6| Step: 7
Training loss: 2.4557138377116075
Validation loss: 2.513025555910934

Epoch: 6| Step: 8
Training loss: 1.9353115273597474
Validation loss: 2.525963384195283

Epoch: 6| Step: 9
Training loss: 2.790078798090556
Validation loss: 2.5141155777080413

Epoch: 6| Step: 10
Training loss: 2.7301654783686873
Validation loss: 2.527203846380115

Epoch: 6| Step: 11
Training loss: 2.696738576256407
Validation loss: 2.529318853844941

Epoch: 6| Step: 12
Training loss: 2.603792718105622
Validation loss: 2.5204136606825878

Epoch: 6| Step: 13
Training loss: 2.604242542433042
Validation loss: 2.5183224954967285

Epoch: 203| Step: 0
Training loss: 2.135747322596136
Validation loss: 2.519347775109595

Epoch: 6| Step: 1
Training loss: 1.7991039217947462
Validation loss: 2.5170566047276925

Epoch: 6| Step: 2
Training loss: 2.460081308773425
Validation loss: 2.511261300630715

Epoch: 6| Step: 3
Training loss: 2.0197221381693513
Validation loss: 2.5064211716390163

Epoch: 6| Step: 4
Training loss: 2.3999495818882255
Validation loss: 2.51592335007883

Epoch: 6| Step: 5
Training loss: 2.2520924481240687
Validation loss: 2.509107229752876

Epoch: 6| Step: 6
Training loss: 2.634144069917039
Validation loss: 2.4972062077030586

Epoch: 6| Step: 7
Training loss: 2.700540177739801
Validation loss: 2.5194954251051445

Epoch: 6| Step: 8
Training loss: 2.120387288111989
Validation loss: 2.5071863202757876

Epoch: 6| Step: 9
Training loss: 2.5179529258806017
Validation loss: 2.5219845048023544

Epoch: 6| Step: 10
Training loss: 2.610140659590571
Validation loss: 2.5220507737377287

Epoch: 6| Step: 11
Training loss: 2.7159430384554764
Validation loss: 2.5081073908469302

Epoch: 6| Step: 12
Training loss: 2.214650194433336
Validation loss: 2.523783121759213

Epoch: 6| Step: 13
Training loss: 2.6326936870446374
Validation loss: 2.517453289463609

Epoch: 204| Step: 0
Training loss: 1.858283997067543
Validation loss: 2.508197235986109

Epoch: 6| Step: 1
Training loss: 2.2365777954925976
Validation loss: 2.5059147484504467

Epoch: 6| Step: 2
Training loss: 2.5160131688099328
Validation loss: 2.519599002843872

Epoch: 6| Step: 3
Training loss: 1.500817076351239
Validation loss: 2.4996662632387863

Epoch: 6| Step: 4
Training loss: 2.0352279445445127
Validation loss: 2.500360335766653

Epoch: 6| Step: 5
Training loss: 2.520731038521741
Validation loss: 2.500768519532711

Epoch: 6| Step: 6
Training loss: 2.233664659813554
Validation loss: 2.4963325939417627

Epoch: 6| Step: 7
Training loss: 3.4223975213746756
Validation loss: 2.493322124120264

Epoch: 6| Step: 8
Training loss: 2.092568704805717
Validation loss: 2.4973739978417795

Epoch: 6| Step: 9
Training loss: 3.2450836850324474
Validation loss: 2.506854847944557

Epoch: 6| Step: 10
Training loss: 2.308274196964386
Validation loss: 2.4883155600808813

Epoch: 6| Step: 11
Training loss: 1.9438945704234145
Validation loss: 2.51367421460086

Epoch: 6| Step: 12
Training loss: 2.293297713173132
Validation loss: 2.511049077534646

Epoch: 6| Step: 13
Training loss: 2.462762259058132
Validation loss: 2.508048762425419

Epoch: 205| Step: 0
Training loss: 2.4774370544628743
Validation loss: 2.5150185716927966

Epoch: 6| Step: 1
Training loss: 1.9812626498326946
Validation loss: 2.519852744396866

Epoch: 6| Step: 2
Training loss: 2.367234635591979
Validation loss: 2.5230378108992046

Epoch: 6| Step: 3
Training loss: 2.881045743442069
Validation loss: 2.531107596328069

Epoch: 6| Step: 4
Training loss: 2.16113678405645
Validation loss: 2.5312758393401276

Epoch: 6| Step: 5
Training loss: 2.5923493061761436
Validation loss: 2.5344643297613403

Epoch: 6| Step: 6
Training loss: 2.491383198547424
Validation loss: 2.528014953255189

Epoch: 6| Step: 7
Training loss: 2.1615824345883725
Validation loss: 2.511419773847415

Epoch: 6| Step: 8
Training loss: 2.3830890432506973
Validation loss: 2.5190754007390006

Epoch: 6| Step: 9
Training loss: 2.3421038123430287
Validation loss: 2.5038239559272304

Epoch: 6| Step: 10
Training loss: 2.519356087206953
Validation loss: 2.5083290273264005

Epoch: 6| Step: 11
Training loss: 2.435090855150862
Validation loss: 2.509558967760437

Epoch: 6| Step: 12
Training loss: 1.9548377499973488
Validation loss: 2.5150220160155836

Epoch: 6| Step: 13
Training loss: 2.499765957367563
Validation loss: 2.514097883577289

Epoch: 206| Step: 0
Training loss: 2.2396008394725198
Validation loss: 2.5101606520752586

Epoch: 6| Step: 1
Training loss: 2.109392632304778
Validation loss: 2.5195604268437397

Epoch: 6| Step: 2
Training loss: 2.485015114905214
Validation loss: 2.5148645677245076

Epoch: 6| Step: 3
Training loss: 2.2739721764076024
Validation loss: 2.509708048633813

Epoch: 6| Step: 4
Training loss: 2.6780832899444404
Validation loss: 2.5248546734777055

Epoch: 6| Step: 5
Training loss: 2.2354893606500545
Validation loss: 2.5375996371221063

Epoch: 6| Step: 6
Training loss: 2.344448850074152
Validation loss: 2.524350051511038

Epoch: 6| Step: 7
Training loss: 2.0510569941107977
Validation loss: 2.5226772489802944

Epoch: 6| Step: 8
Training loss: 2.959808698091293
Validation loss: 2.519137503046826

Epoch: 6| Step: 9
Training loss: 2.298205762185318
Validation loss: 2.506073377415336

Epoch: 6| Step: 10
Training loss: 2.542893744093528
Validation loss: 2.520635476242328

Epoch: 6| Step: 11
Training loss: 2.2051114264812655
Validation loss: 2.5224142056718355

Epoch: 6| Step: 12
Training loss: 2.9403244400065787
Validation loss: 2.5199618186026083

Epoch: 6| Step: 13
Training loss: 1.555010891351858
Validation loss: 2.5078486819246844

Epoch: 207| Step: 0
Training loss: 2.4239130120547943
Validation loss: 2.5170636377656996

Epoch: 6| Step: 1
Training loss: 2.261563152435955
Validation loss: 2.505203974053178

Epoch: 6| Step: 2
Training loss: 2.3828020939834254
Validation loss: 2.499587311060859

Epoch: 6| Step: 3
Training loss: 2.4233323173398387
Validation loss: 2.5146686797577265

Epoch: 6| Step: 4
Training loss: 2.688226823330635
Validation loss: 2.506254018905601

Epoch: 6| Step: 5
Training loss: 2.6066885270505344
Validation loss: 2.5140964136706954

Epoch: 6| Step: 6
Training loss: 2.4114927175444714
Validation loss: 2.5179050609121885

Epoch: 6| Step: 7
Training loss: 2.727378395229859
Validation loss: 2.5082969078849424

Epoch: 6| Step: 8
Training loss: 2.1486761896883264
Validation loss: 2.510518928017343

Epoch: 6| Step: 9
Training loss: 2.20951673600712
Validation loss: 2.5167011462832796

Epoch: 6| Step: 10
Training loss: 2.226095371434514
Validation loss: 2.5151682926823464

Epoch: 6| Step: 11
Training loss: 2.11073722651691
Validation loss: 2.524026650388328

Epoch: 6| Step: 12
Training loss: 2.4817239303933487
Validation loss: 2.5183801037046885

Epoch: 6| Step: 13
Training loss: 2.263000230655161
Validation loss: 2.5352638194377697

Epoch: 208| Step: 0
Training loss: 2.3624811000168893
Validation loss: 2.5322188104975987

Epoch: 6| Step: 1
Training loss: 2.167699518755605
Validation loss: 2.513729858520083

Epoch: 6| Step: 2
Training loss: 2.699152590966296
Validation loss: 2.5175364875359056

Epoch: 6| Step: 3
Training loss: 2.2041239536620187
Validation loss: 2.5202172580041813

Epoch: 6| Step: 4
Training loss: 1.6015172440252263
Validation loss: 2.518522611692111

Epoch: 6| Step: 5
Training loss: 2.5111183884701824
Validation loss: 2.513788836568207

Epoch: 6| Step: 6
Training loss: 2.476277524514966
Validation loss: 2.5218003102413316

Epoch: 6| Step: 7
Training loss: 3.0517404687007157
Validation loss: 2.509811761137637

Epoch: 6| Step: 8
Training loss: 2.90806801650564
Validation loss: 2.503378889437193

Epoch: 6| Step: 9
Training loss: 2.5582651640749123
Validation loss: 2.500991815284414

Epoch: 6| Step: 10
Training loss: 2.151148192298023
Validation loss: 2.5019671647935833

Epoch: 6| Step: 11
Training loss: 2.496613879628293
Validation loss: 2.5003139775522962

Epoch: 6| Step: 12
Training loss: 1.9308931237014313
Validation loss: 2.501688561806452

Epoch: 6| Step: 13
Training loss: 1.9822323262214214
Validation loss: 2.501782187370583

Epoch: 209| Step: 0
Training loss: 2.320296881523613
Validation loss: 2.500921047934645

Epoch: 6| Step: 1
Training loss: 2.462606390963933
Validation loss: 2.4993152634354194

Epoch: 6| Step: 2
Training loss: 2.412605710258389
Validation loss: 2.508513577428617

Epoch: 6| Step: 3
Training loss: 2.3372415328305474
Validation loss: 2.5148877392330906

Epoch: 6| Step: 4
Training loss: 2.7622505765830248
Validation loss: 2.509035226345283

Epoch: 6| Step: 5
Training loss: 2.6913812688767176
Validation loss: 2.5194879572497832

Epoch: 6| Step: 6
Training loss: 2.5134218413185225
Validation loss: 2.521281641249536

Epoch: 6| Step: 7
Training loss: 1.9436831104017158
Validation loss: 2.529001139629364

Epoch: 6| Step: 8
Training loss: 2.3195606387863275
Validation loss: 2.5266682480209086

Epoch: 6| Step: 9
Training loss: 2.378826472004869
Validation loss: 2.5229851048514065

Epoch: 6| Step: 10
Training loss: 2.5967358787169554
Validation loss: 2.5131389741683785

Epoch: 6| Step: 11
Training loss: 1.9231882338221062
Validation loss: 2.5248909495508554

Epoch: 6| Step: 12
Training loss: 2.431581304967958
Validation loss: 2.5231965445006406

Epoch: 6| Step: 13
Training loss: 2.037319797901974
Validation loss: 2.533044877277366

Epoch: 210| Step: 0
Training loss: 2.144787604569128
Validation loss: 2.5201408811829795

Epoch: 6| Step: 1
Training loss: 2.7430491601625295
Validation loss: 2.5295125704863484

Epoch: 6| Step: 2
Training loss: 2.046270033564107
Validation loss: 2.525691565933058

Epoch: 6| Step: 3
Training loss: 2.252880054550541
Validation loss: 2.514818429478727

Epoch: 6| Step: 4
Training loss: 2.5311603294784373
Validation loss: 2.522540599368994

Epoch: 6| Step: 5
Training loss: 2.286360776959094
Validation loss: 2.5209713469837434

Epoch: 6| Step: 6
Training loss: 2.057675701625575
Validation loss: 2.5235900832775413

Epoch: 6| Step: 7
Training loss: 2.6555840947822476
Validation loss: 2.5117487374152545

Epoch: 6| Step: 8
Training loss: 2.7474856586446466
Validation loss: 2.5083641800192975

Epoch: 6| Step: 9
Training loss: 2.3149955274897107
Validation loss: 2.5134375402954965

Epoch: 6| Step: 10
Training loss: 2.089814087844402
Validation loss: 2.504404241640124

Epoch: 6| Step: 11
Training loss: 2.4983704024150573
Validation loss: 2.515019661868868

Epoch: 6| Step: 12
Training loss: 2.242269268605113
Validation loss: 2.5031858648741676

Epoch: 6| Step: 13
Training loss: 2.4114494131320123
Validation loss: 2.508711664578196

Epoch: 211| Step: 0
Training loss: 1.6338677897527325
Validation loss: 2.5132829414150915

Epoch: 6| Step: 1
Training loss: 1.9140745201511922
Validation loss: 2.524899290613283

Epoch: 6| Step: 2
Training loss: 2.520927763712391
Validation loss: 2.5170462879910422

Epoch: 6| Step: 3
Training loss: 2.7552709350012115
Validation loss: 2.5327077835717096

Epoch: 6| Step: 4
Training loss: 2.662273264798789
Validation loss: 2.5176897914478853

Epoch: 6| Step: 5
Training loss: 2.5008614963096947
Validation loss: 2.5220178758248366

Epoch: 6| Step: 6
Training loss: 2.404203461134631
Validation loss: 2.5225434190726572

Epoch: 6| Step: 7
Training loss: 2.9959387310165213
Validation loss: 2.515074091073395

Epoch: 6| Step: 8
Training loss: 3.0088803464122464
Validation loss: 2.5248431531580153

Epoch: 6| Step: 9
Training loss: 2.479447762931586
Validation loss: 2.5233095055903476

Epoch: 6| Step: 10
Training loss: 2.1547600947620604
Validation loss: 2.519430658269323

Epoch: 6| Step: 11
Training loss: 1.6983040989739007
Validation loss: 2.506461027905598

Epoch: 6| Step: 12
Training loss: 1.9668505148974262
Validation loss: 2.5090995805282255

Epoch: 6| Step: 13
Training loss: 1.9332328074179277
Validation loss: 2.5188918926447523

Epoch: 212| Step: 0
Training loss: 2.6771544114311494
Validation loss: 2.5102917704768477

Epoch: 6| Step: 1
Training loss: 2.771136981894673
Validation loss: 2.52039152535085

Epoch: 6| Step: 2
Training loss: 2.9006437968208294
Validation loss: 2.517060235703753

Epoch: 6| Step: 3
Training loss: 2.224126828769362
Validation loss: 2.516323695486193

Epoch: 6| Step: 4
Training loss: 1.8248644059902763
Validation loss: 2.525447615678402

Epoch: 6| Step: 5
Training loss: 2.8976488711380672
Validation loss: 2.509040967372427

Epoch: 6| Step: 6
Training loss: 1.9041341076271654
Validation loss: 2.5233737949325565

Epoch: 6| Step: 7
Training loss: 2.0236465169403726
Validation loss: 2.518741154556582

Epoch: 6| Step: 8
Training loss: 2.061744898507033
Validation loss: 2.514713841053787

Epoch: 6| Step: 9
Training loss: 2.889200880451219
Validation loss: 2.512556775718411

Epoch: 6| Step: 10
Training loss: 1.9060517505052816
Validation loss: 2.5164091732178315

Epoch: 6| Step: 11
Training loss: 1.915116436458813
Validation loss: 2.5048746268750266

Epoch: 6| Step: 12
Training loss: 2.2913161500995516
Validation loss: 2.5075861590039707

Epoch: 6| Step: 13
Training loss: 2.331171078407108
Validation loss: 2.507942022066673

Epoch: 213| Step: 0
Training loss: 2.05278431752697
Validation loss: 2.5067868933185347

Epoch: 6| Step: 1
Training loss: 2.1720070558647637
Validation loss: 2.50790202296931

Epoch: 6| Step: 2
Training loss: 2.075131432840342
Validation loss: 2.5095603690716253

Epoch: 6| Step: 3
Training loss: 1.781407734094287
Validation loss: 2.5117185759754426

Epoch: 6| Step: 4
Training loss: 2.1656250528442906
Validation loss: 2.5046019319199035

Epoch: 6| Step: 5
Training loss: 2.5554674923507967
Validation loss: 2.514336471218171

Epoch: 6| Step: 6
Training loss: 2.702778523902315
Validation loss: 2.511301768383114

Epoch: 6| Step: 7
Training loss: 2.4028551999397387
Validation loss: 2.5121430334818897

Epoch: 6| Step: 8
Training loss: 3.4253987323857755
Validation loss: 2.5152839129287865

Epoch: 6| Step: 9
Training loss: 2.033751136296476
Validation loss: 2.51053596677419

Epoch: 6| Step: 10
Training loss: 2.087620659727456
Validation loss: 2.5069498418419367

Epoch: 6| Step: 11
Training loss: 1.9960380292606554
Validation loss: 2.5223002828747716

Epoch: 6| Step: 12
Training loss: 2.3774561980471507
Validation loss: 2.517747098481988

Epoch: 6| Step: 13
Training loss: 2.7620497185543407
Validation loss: 2.5268330281561915

Epoch: 214| Step: 0
Training loss: 2.136734929276325
Validation loss: 2.527634790123533

Epoch: 6| Step: 1
Training loss: 2.518291316141582
Validation loss: 2.535437742180684

Epoch: 6| Step: 2
Training loss: 1.9081297814477662
Validation loss: 2.550286993382116

Epoch: 6| Step: 3
Training loss: 2.5074356128644926
Validation loss: 2.529873532575876

Epoch: 6| Step: 4
Training loss: 2.0219434723616843
Validation loss: 2.52142640433044

Epoch: 6| Step: 5
Training loss: 2.420780352889798
Validation loss: 2.5294789056068674

Epoch: 6| Step: 6
Training loss: 2.7664427329595807
Validation loss: 2.525523863481364

Epoch: 6| Step: 7
Training loss: 2.1940703763984772
Validation loss: 2.5176568207674737

Epoch: 6| Step: 8
Training loss: 1.6332720242236731
Validation loss: 2.5117843405789997

Epoch: 6| Step: 9
Training loss: 2.902538595936895
Validation loss: 2.505232318491066

Epoch: 6| Step: 10
Training loss: 2.973848161588549
Validation loss: 2.5052320885011143

Epoch: 6| Step: 11
Training loss: 2.801434513876912
Validation loss: 2.502626588994198

Epoch: 6| Step: 12
Training loss: 1.9597672697976205
Validation loss: 2.5076581802501767

Epoch: 6| Step: 13
Training loss: 2.013982650795756
Validation loss: 2.5152885575335286

Epoch: 215| Step: 0
Training loss: 2.3536290818088412
Validation loss: 2.512972853339263

Epoch: 6| Step: 1
Training loss: 2.6701283239037936
Validation loss: 2.517576183617245

Epoch: 6| Step: 2
Training loss: 1.7691532093290347
Validation loss: 2.5256359180849133

Epoch: 6| Step: 3
Training loss: 2.124611314119358
Validation loss: 2.532791516018826

Epoch: 6| Step: 4
Training loss: 1.9143489701123244
Validation loss: 2.5389060104269525

Epoch: 6| Step: 5
Training loss: 2.032397137017909
Validation loss: 2.53433439925442

Epoch: 6| Step: 6
Training loss: 2.2819777072683523
Validation loss: 2.541031497531413

Epoch: 6| Step: 7
Training loss: 2.4464597113321003
Validation loss: 2.5228685932530115

Epoch: 6| Step: 8
Training loss: 1.9120747735513612
Validation loss: 2.545169454278003

Epoch: 6| Step: 9
Training loss: 2.002964207329908
Validation loss: 2.5347667957259508

Epoch: 6| Step: 10
Training loss: 2.561222316132481
Validation loss: 2.540150085705798

Epoch: 6| Step: 11
Training loss: 2.9525522150886183
Validation loss: 2.5444017973309934

Epoch: 6| Step: 12
Training loss: 2.5550675882257226
Validation loss: 2.53116343785849

Epoch: 6| Step: 13
Training loss: 2.956134695502162
Validation loss: 2.544025551182811

Epoch: 216| Step: 0
Training loss: 2.349781363035941
Validation loss: 2.527826175703793

Epoch: 6| Step: 1
Training loss: 2.125532195822617
Validation loss: 2.5279439049464663

Epoch: 6| Step: 2
Training loss: 2.188596069395713
Validation loss: 2.532571926218992

Epoch: 6| Step: 3
Training loss: 2.833652216600258
Validation loss: 2.52621488206688

Epoch: 6| Step: 4
Training loss: 2.8285732862403132
Validation loss: 2.5203022725858935

Epoch: 6| Step: 5
Training loss: 2.3745511283326106
Validation loss: 2.526157200848684

Epoch: 6| Step: 6
Training loss: 1.8746610970981898
Validation loss: 2.528745487552928

Epoch: 6| Step: 7
Training loss: 2.304803153546767
Validation loss: 2.534090810600286

Epoch: 6| Step: 8
Training loss: 1.920894589829967
Validation loss: 2.5331798778870183

Epoch: 6| Step: 9
Training loss: 2.124113346696225
Validation loss: 2.5203102740888705

Epoch: 6| Step: 10
Training loss: 2.462352721171748
Validation loss: 2.524478063995664

Epoch: 6| Step: 11
Training loss: 2.2812281568343695
Validation loss: 2.5124577077466066

Epoch: 6| Step: 12
Training loss: 2.8334125806908164
Validation loss: 2.505964110978789

Epoch: 6| Step: 13
Training loss: 2.2632641297530016
Validation loss: 2.5192988640913043

Epoch: 217| Step: 0
Training loss: 2.2993711026390167
Validation loss: 2.5134338724667544

Epoch: 6| Step: 1
Training loss: 2.243964258871512
Validation loss: 2.521754921311924

Epoch: 6| Step: 2
Training loss: 2.6465187886946078
Validation loss: 2.5213294736371017

Epoch: 6| Step: 3
Training loss: 2.3621177646695517
Validation loss: 2.5269688481004713

Epoch: 6| Step: 4
Training loss: 3.2278726425572963
Validation loss: 2.5238448248285477

Epoch: 6| Step: 5
Training loss: 1.973685300224405
Validation loss: 2.537756794430591

Epoch: 6| Step: 6
Training loss: 1.9827527000361727
Validation loss: 2.542897150659738

Epoch: 6| Step: 7
Training loss: 2.079105576080849
Validation loss: 2.5428759454921903

Epoch: 6| Step: 8
Training loss: 2.4285740892411734
Validation loss: 2.5512110147047227

Epoch: 6| Step: 9
Training loss: 2.1952762261377066
Validation loss: 2.530838889814182

Epoch: 6| Step: 10
Training loss: 2.5716869076887994
Validation loss: 2.525446427730119

Epoch: 6| Step: 11
Training loss: 1.8298859551335886
Validation loss: 2.524664219476914

Epoch: 6| Step: 12
Training loss: 2.6234898537551747
Validation loss: 2.539215505831583

Epoch: 6| Step: 13
Training loss: 2.1901380707924605
Validation loss: 2.544601752093399

Epoch: 218| Step: 0
Training loss: 2.4723174961414838
Validation loss: 2.535195889625937

Epoch: 6| Step: 1
Training loss: 2.6115251465385927
Validation loss: 2.537195640313163

Epoch: 6| Step: 2
Training loss: 2.1658793510586607
Validation loss: 2.5313046610389427

Epoch: 6| Step: 3
Training loss: 1.8732409809241108
Validation loss: 2.5295203622004836

Epoch: 6| Step: 4
Training loss: 2.022929831192548
Validation loss: 2.5283139315795142

Epoch: 6| Step: 5
Training loss: 2.877206536117463
Validation loss: 2.5240587979383586

Epoch: 6| Step: 6
Training loss: 1.8678560855573858
Validation loss: 2.5204372620294233

Epoch: 6| Step: 7
Training loss: 2.5646925129544553
Validation loss: 2.5194248857151393

Epoch: 6| Step: 8
Training loss: 2.8786544793233046
Validation loss: 2.514377316176659

Epoch: 6| Step: 9
Training loss: 2.4101615918067827
Validation loss: 2.5127177370278835

Epoch: 6| Step: 10
Training loss: 2.525267702018523
Validation loss: 2.510738199201908

Epoch: 6| Step: 11
Training loss: 2.295647948638762
Validation loss: 2.4914595478521786

Epoch: 6| Step: 12
Training loss: 1.7950317880477573
Validation loss: 2.5107664495102298

Epoch: 6| Step: 13
Training loss: 2.3372471432931063
Validation loss: 2.5023978892938805

Epoch: 219| Step: 0
Training loss: 2.309494952853515
Validation loss: 2.5110138200050165

Epoch: 6| Step: 1
Training loss: 2.1946201522381643
Validation loss: 2.531216326831024

Epoch: 6| Step: 2
Training loss: 2.270471374875631
Validation loss: 2.5216372104049674

Epoch: 6| Step: 3
Training loss: 2.479188315246265
Validation loss: 2.5351168135214315

Epoch: 6| Step: 4
Training loss: 2.6900872485111056
Validation loss: 2.5377943109421754

Epoch: 6| Step: 5
Training loss: 1.7164486823829457
Validation loss: 2.5289391066999864

Epoch: 6| Step: 6
Training loss: 2.828647965610866
Validation loss: 2.5494900093718273

Epoch: 6| Step: 7
Training loss: 2.965631875290453
Validation loss: 2.5495781624380975

Epoch: 6| Step: 8
Training loss: 2.3700715175734857
Validation loss: 2.5637019680166766

Epoch: 6| Step: 9
Training loss: 2.9374623397685617
Validation loss: 2.5544546256439307

Epoch: 6| Step: 10
Training loss: 2.000080822265256
Validation loss: 2.5268236712975183

Epoch: 6| Step: 11
Training loss: 2.20530008933916
Validation loss: 2.5068922087304513

Epoch: 6| Step: 12
Training loss: 1.41987998092534
Validation loss: 2.4978258374658004

Epoch: 6| Step: 13
Training loss: 2.2560080739343515
Validation loss: 2.5040695208612105

Epoch: 220| Step: 0
Training loss: 2.694661910554796
Validation loss: 2.503817766503745

Epoch: 6| Step: 1
Training loss: 2.1443053301992916
Validation loss: 2.500512181903853

Epoch: 6| Step: 2
Training loss: 2.355781698867645
Validation loss: 2.4917941684910527

Epoch: 6| Step: 3
Training loss: 2.3720403601057685
Validation loss: 2.496213588713291

Epoch: 6| Step: 4
Training loss: 2.9914549884626456
Validation loss: 2.4824683752539416

Epoch: 6| Step: 5
Training loss: 2.7164481053653624
Validation loss: 2.4966165774107876

Epoch: 6| Step: 6
Training loss: 2.2081351161264013
Validation loss: 2.490316966563383

Epoch: 6| Step: 7
Training loss: 2.3693795205578536
Validation loss: 2.4994012910465377

Epoch: 6| Step: 8
Training loss: 2.917312732168169
Validation loss: 2.5013119275231817

Epoch: 6| Step: 9
Training loss: 1.4771194618588068
Validation loss: 2.507953120930711

Epoch: 6| Step: 10
Training loss: 2.509609636142217
Validation loss: 2.5028361683675544

Epoch: 6| Step: 11
Training loss: 1.9476009527834388
Validation loss: 2.5096328799200713

Epoch: 6| Step: 12
Training loss: 2.0637264651014218
Validation loss: 2.5205516237424384

Epoch: 6| Step: 13
Training loss: 2.247758384508209
Validation loss: 2.515976669972564

Epoch: 221| Step: 0
Training loss: 2.3612538113823294
Validation loss: 2.508140978191529

Epoch: 6| Step: 1
Training loss: 1.3465954129722086
Validation loss: 2.5079874074752615

Epoch: 6| Step: 2
Training loss: 2.181946161880427
Validation loss: 2.517268210849046

Epoch: 6| Step: 3
Training loss: 2.1448918718592256
Validation loss: 2.5096333865940306

Epoch: 6| Step: 4
Training loss: 2.096932909829596
Validation loss: 2.521199370572331

Epoch: 6| Step: 5
Training loss: 2.609003737301122
Validation loss: 2.5298373436565424

Epoch: 6| Step: 6
Training loss: 2.3404981306297175
Validation loss: 2.5176282137358514

Epoch: 6| Step: 7
Training loss: 2.1221151404247536
Validation loss: 2.5159917686471283

Epoch: 6| Step: 8
Training loss: 2.7529546297424536
Validation loss: 2.5107689500824324

Epoch: 6| Step: 9
Training loss: 2.7451019015271667
Validation loss: 2.5147524123933196

Epoch: 6| Step: 10
Training loss: 2.477100879381395
Validation loss: 2.5170894175102694

Epoch: 6| Step: 11
Training loss: 2.2848560625146415
Validation loss: 2.5150755130107

Epoch: 6| Step: 12
Training loss: 2.634385270249155
Validation loss: 2.5273721920341017

Epoch: 6| Step: 13
Training loss: 2.659146872215353
Validation loss: 2.52481661845122

Epoch: 222| Step: 0
Training loss: 2.6268687181490695
Validation loss: 2.531179937327087

Epoch: 6| Step: 1
Training loss: 2.936026995209949
Validation loss: 2.535160685781743

Epoch: 6| Step: 2
Training loss: 2.35791859928404
Validation loss: 2.533161116903441

Epoch: 6| Step: 3
Training loss: 2.820109521213565
Validation loss: 2.5398481826016046

Epoch: 6| Step: 4
Training loss: 2.2313549198732106
Validation loss: 2.543853293406329

Epoch: 6| Step: 5
Training loss: 2.124889034291094
Validation loss: 2.5319923756491165

Epoch: 6| Step: 6
Training loss: 1.6096969578738585
Validation loss: 2.516247484736821

Epoch: 6| Step: 7
Training loss: 2.4879633103023533
Validation loss: 2.527302407069538

Epoch: 6| Step: 8
Training loss: 2.539085223756488
Validation loss: 2.509059180199188

Epoch: 6| Step: 9
Training loss: 2.398132006545739
Validation loss: 2.5114200744710424

Epoch: 6| Step: 10
Training loss: 2.341449880463942
Validation loss: 2.5207730803631883

Epoch: 6| Step: 11
Training loss: 2.2571120710153156
Validation loss: 2.507169742152852

Epoch: 6| Step: 12
Training loss: 2.20860777055347
Validation loss: 2.5216495096396607

Epoch: 6| Step: 13
Training loss: 2.084852300667984
Validation loss: 2.5176378336263463

Epoch: 223| Step: 0
Training loss: 1.9550602594830264
Validation loss: 2.5220266045274573

Epoch: 6| Step: 1
Training loss: 1.7584805045827374
Validation loss: 2.5406789475985563

Epoch: 6| Step: 2
Training loss: 2.510404679096984
Validation loss: 2.5350961859297745

Epoch: 6| Step: 3
Training loss: 2.3525462579993217
Validation loss: 2.5472753167266617

Epoch: 6| Step: 4
Training loss: 2.104819457767954
Validation loss: 2.5587142799467077

Epoch: 6| Step: 5
Training loss: 2.6699433064245923
Validation loss: 2.563137672912031

Epoch: 6| Step: 6
Training loss: 2.367025338337455
Validation loss: 2.5609823477858007

Epoch: 6| Step: 7
Training loss: 2.983603972052648
Validation loss: 2.5511430733960583

Epoch: 6| Step: 8
Training loss: 2.2345006947408548
Validation loss: 2.533028091897369

Epoch: 6| Step: 9
Training loss: 2.52910551429821
Validation loss: 2.5299320321885914

Epoch: 6| Step: 10
Training loss: 2.516363379117118
Validation loss: 2.5155559396050786

Epoch: 6| Step: 11
Training loss: 1.7964151208596657
Validation loss: 2.503696649103281

Epoch: 6| Step: 12
Training loss: 2.357888264889189
Validation loss: 2.5006395952313176

Epoch: 6| Step: 13
Training loss: 2.7971906430598943
Validation loss: 2.4929660948130827

Epoch: 224| Step: 0
Training loss: 2.043310658306783
Validation loss: 2.497745936214066

Epoch: 6| Step: 1
Training loss: 2.3695829753720066
Validation loss: 2.500638896048932

Epoch: 6| Step: 2
Training loss: 2.4967626591738985
Validation loss: 2.5048267182234403

Epoch: 6| Step: 3
Training loss: 1.9444967497496588
Validation loss: 2.5031695936201848

Epoch: 6| Step: 4
Training loss: 2.7237096688802134
Validation loss: 2.5056601504870875

Epoch: 6| Step: 5
Training loss: 2.2954429262212255
Validation loss: 2.513427738327414

Epoch: 6| Step: 6
Training loss: 2.107012068081601
Validation loss: 2.5261371371655796

Epoch: 6| Step: 7
Training loss: 2.4893585699498404
Validation loss: 2.5141761272034526

Epoch: 6| Step: 8
Training loss: 2.5077788448749314
Validation loss: 2.519062931193416

Epoch: 6| Step: 9
Training loss: 2.599046194748474
Validation loss: 2.5120683884493795

Epoch: 6| Step: 10
Training loss: 2.8958475309248035
Validation loss: 2.5159176326534762

Epoch: 6| Step: 11
Training loss: 1.4457172548747146
Validation loss: 2.52238336833484

Epoch: 6| Step: 12
Training loss: 2.842834157501648
Validation loss: 2.531978831915333

Epoch: 6| Step: 13
Training loss: 2.1138017334294887
Validation loss: 2.5318290927139873

Epoch: 225| Step: 0
Training loss: 2.4800627128301236
Validation loss: 2.521855483359726

Epoch: 6| Step: 1
Training loss: 2.3095250970071866
Validation loss: 2.5445445657611447

Epoch: 6| Step: 2
Training loss: 2.7371458129286625
Validation loss: 2.5280811112676576

Epoch: 6| Step: 3
Training loss: 2.293972335143093
Validation loss: 2.524026044272409

Epoch: 6| Step: 4
Training loss: 2.7715386566158458
Validation loss: 2.5316179110177073

Epoch: 6| Step: 5
Training loss: 2.0629713502448723
Validation loss: 2.529948790990679

Epoch: 6| Step: 6
Training loss: 1.874376066028868
Validation loss: 2.5247045196149664

Epoch: 6| Step: 7
Training loss: 2.3661692226383835
Validation loss: 2.515357325116528

Epoch: 6| Step: 8
Training loss: 2.310726723076317
Validation loss: 2.498283575842116

Epoch: 6| Step: 9
Training loss: 1.7549110711762053
Validation loss: 2.5031591799621293

Epoch: 6| Step: 10
Training loss: 1.7097505258089996
Validation loss: 2.517005257429377

Epoch: 6| Step: 11
Training loss: 2.541714829368989
Validation loss: 2.506540167826004

Epoch: 6| Step: 12
Training loss: 2.8812969741798518
Validation loss: 2.5096074352556363

Epoch: 6| Step: 13
Training loss: 2.357471026245583
Validation loss: 2.512576022666529

Epoch: 226| Step: 0
Training loss: 1.837872139232718
Validation loss: 2.513498264216784

Epoch: 6| Step: 1
Training loss: 2.7323196097508617
Validation loss: 2.5054794820395685

Epoch: 6| Step: 2
Training loss: 1.9718755706931375
Validation loss: 2.5123428036176927

Epoch: 6| Step: 3
Training loss: 2.7112133754228074
Validation loss: 2.5159219917966356

Epoch: 6| Step: 4
Training loss: 2.175577643848093
Validation loss: 2.5009336953223777

Epoch: 6| Step: 5
Training loss: 2.350636448810734
Validation loss: 2.514719008162267

Epoch: 6| Step: 6
Training loss: 2.422918574779893
Validation loss: 2.503316427936523

Epoch: 6| Step: 7
Training loss: 2.742767707325959
Validation loss: 2.5179432046154475

Epoch: 6| Step: 8
Training loss: 1.886973425062982
Validation loss: 2.5122448027711997

Epoch: 6| Step: 9
Training loss: 2.1852172930322817
Validation loss: 2.527336824182595

Epoch: 6| Step: 10
Training loss: 2.0506489447649314
Validation loss: 2.519786788243942

Epoch: 6| Step: 11
Training loss: 3.0383698524823526
Validation loss: 2.5369742075814794

Epoch: 6| Step: 12
Training loss: 1.7978264984588448
Validation loss: 2.5227955965266284

Epoch: 6| Step: 13
Training loss: 2.5378369939115504
Validation loss: 2.5232194898852054

Epoch: 227| Step: 0
Training loss: 2.0849710004148263
Validation loss: 2.521222948803304

Epoch: 6| Step: 1
Training loss: 2.178256751389878
Validation loss: 2.5246332128793214

Epoch: 6| Step: 2
Training loss: 2.2389992832116246
Validation loss: 2.5234139109671285

Epoch: 6| Step: 3
Training loss: 2.534693506737196
Validation loss: 2.518671169893242

Epoch: 6| Step: 4
Training loss: 2.18663203867189
Validation loss: 2.5142719191850347

Epoch: 6| Step: 5
Training loss: 2.752574409220557
Validation loss: 2.5210515918246825

Epoch: 6| Step: 6
Training loss: 2.4107148992951433
Validation loss: 2.5368173463968993

Epoch: 6| Step: 7
Training loss: 2.8922141166134105
Validation loss: 2.54113647267397

Epoch: 6| Step: 8
Training loss: 1.9984016588231663
Validation loss: 2.535189102814225

Epoch: 6| Step: 9
Training loss: 2.3648595662591556
Validation loss: 2.537225021220806

Epoch: 6| Step: 10
Training loss: 2.0365026782997178
Validation loss: 2.5530572525056776

Epoch: 6| Step: 11
Training loss: 2.7604648705838106
Validation loss: 2.540562942453918

Epoch: 6| Step: 12
Training loss: 1.9763375859211858
Validation loss: 2.5371255852091124

Epoch: 6| Step: 13
Training loss: 2.1257773828664064
Validation loss: 2.5404499664635183

Epoch: 228| Step: 0
Training loss: 2.052851912221323
Validation loss: 2.5285956668820955

Epoch: 6| Step: 1
Training loss: 1.9393745706098586
Validation loss: 2.5223834392257025

Epoch: 6| Step: 2
Training loss: 1.9898045668172004
Validation loss: 2.5216203412097222

Epoch: 6| Step: 3
Training loss: 2.476950052545504
Validation loss: 2.524066260141665

Epoch: 6| Step: 4
Training loss: 1.7576958511643006
Validation loss: 2.5165115121251818

Epoch: 6| Step: 5
Training loss: 1.8815412859820808
Validation loss: 2.5066154451370277

Epoch: 6| Step: 6
Training loss: 2.0656353787206165
Validation loss: 2.504995853880029

Epoch: 6| Step: 7
Training loss: 1.951465664760186
Validation loss: 2.519739651994046

Epoch: 6| Step: 8
Training loss: 2.2497634763376553
Validation loss: 2.5219080869638426

Epoch: 6| Step: 9
Training loss: 2.3815688593085897
Validation loss: 2.5289265050932275

Epoch: 6| Step: 10
Training loss: 2.3846538495636573
Validation loss: 2.5349771821388933

Epoch: 6| Step: 11
Training loss: 2.7262814439781864
Validation loss: 2.5298295293579547

Epoch: 6| Step: 12
Training loss: 2.946182082133415
Validation loss: 2.5278820189849345

Epoch: 6| Step: 13
Training loss: 3.3508872038760997
Validation loss: 2.5314827957166446

Epoch: 229| Step: 0
Training loss: 2.4185081459588043
Validation loss: 2.522653684342081

Epoch: 6| Step: 1
Training loss: 2.478360555260295
Validation loss: 2.5386853842789905

Epoch: 6| Step: 2
Training loss: 2.7180525663456123
Validation loss: 2.533637745557884

Epoch: 6| Step: 3
Training loss: 1.797556275294588
Validation loss: 2.5521429612855697

Epoch: 6| Step: 4
Training loss: 2.317581984830028
Validation loss: 2.546788719291582

Epoch: 6| Step: 5
Training loss: 2.5204376246402425
Validation loss: 2.537588918471583

Epoch: 6| Step: 6
Training loss: 2.1293752171253466
Validation loss: 2.5500949249800278

Epoch: 6| Step: 7
Training loss: 2.1492547717554507
Validation loss: 2.555142594456119

Epoch: 6| Step: 8
Training loss: 2.784512096245183
Validation loss: 2.5744383684018115

Epoch: 6| Step: 9
Training loss: 2.4468486214454566
Validation loss: 2.5621044194752796

Epoch: 6| Step: 10
Training loss: 1.6593592986030337
Validation loss: 2.564556847029346

Epoch: 6| Step: 11
Training loss: 2.9381456680074023
Validation loss: 2.5952407352355755

Epoch: 6| Step: 12
Training loss: 2.12281743330251
Validation loss: 2.5651140525872647

Epoch: 6| Step: 13
Training loss: 1.8988832178149588
Validation loss: 2.5317081146748257

Epoch: 230| Step: 0
Training loss: 2.774129260120276
Validation loss: 2.515046663325399

Epoch: 6| Step: 1
Training loss: 2.1802992970505763
Validation loss: 2.514955467072535

Epoch: 6| Step: 2
Training loss: 1.944834577689428
Validation loss: 2.5054360733621333

Epoch: 6| Step: 3
Training loss: 2.4282510810628923
Validation loss: 2.4925035776503535

Epoch: 6| Step: 4
Training loss: 2.0831673619598043
Validation loss: 2.490612780175252

Epoch: 6| Step: 5
Training loss: 1.9756771109978413
Validation loss: 2.4938931423270048

Epoch: 6| Step: 6
Training loss: 2.3306386805752
Validation loss: 2.4902806096989596

Epoch: 6| Step: 7
Training loss: 2.279747664224403
Validation loss: 2.485113358090003

Epoch: 6| Step: 8
Training loss: 2.422758372004908
Validation loss: 2.491341155190558

Epoch: 6| Step: 9
Training loss: 2.876373957847926
Validation loss: 2.4907988742458262

Epoch: 6| Step: 10
Training loss: 2.7502498513207745
Validation loss: 2.5016250732779706

Epoch: 6| Step: 11
Training loss: 1.9337865868172972
Validation loss: 2.506960762818526

Epoch: 6| Step: 12
Training loss: 2.7449628473765877
Validation loss: 2.5080714423840353

Epoch: 6| Step: 13
Training loss: 2.0557178771162667
Validation loss: 2.5145877571562187

Epoch: 231| Step: 0
Training loss: 2.456922374065786
Validation loss: 2.518134103826265

Epoch: 6| Step: 1
Training loss: 2.189715544111503
Validation loss: 2.520578345231077

Epoch: 6| Step: 2
Training loss: 2.5975349111110937
Validation loss: 2.5237654560454095

Epoch: 6| Step: 3
Training loss: 2.2524960765740945
Validation loss: 2.5410514983436077

Epoch: 6| Step: 4
Training loss: 1.9879160247697223
Validation loss: 2.546462121117152

Epoch: 6| Step: 5
Training loss: 2.271606966812244
Validation loss: 2.537883637465489

Epoch: 6| Step: 6
Training loss: 2.4364433932869045
Validation loss: 2.535613815637748

Epoch: 6| Step: 7
Training loss: 2.0983342330643855
Validation loss: 2.5289423199425354

Epoch: 6| Step: 8
Training loss: 2.1513054588213505
Validation loss: 2.5290271669238185

Epoch: 6| Step: 9
Training loss: 2.319099186107326
Validation loss: 2.529202516187544

Epoch: 6| Step: 10
Training loss: 1.8913859577815775
Validation loss: 2.520817801267415

Epoch: 6| Step: 11
Training loss: 3.1782532252548368
Validation loss: 2.5188149708082097

Epoch: 6| Step: 12
Training loss: 2.875428706837975
Validation loss: 2.528011778130034

Epoch: 6| Step: 13
Training loss: 1.6224567612116332
Validation loss: 2.5188950634903913

Epoch: 232| Step: 0
Training loss: 1.8495341590806262
Validation loss: 2.5315042768318325

Epoch: 6| Step: 1
Training loss: 1.9127769045360437
Validation loss: 2.5321258473893056

Epoch: 6| Step: 2
Training loss: 2.212239128293864
Validation loss: 2.5120798091723455

Epoch: 6| Step: 3
Training loss: 2.252399225044693
Validation loss: 2.532458436831365

Epoch: 6| Step: 4
Training loss: 3.5385844263535158
Validation loss: 2.5184766509070804

Epoch: 6| Step: 5
Training loss: 2.2242720752644054
Validation loss: 2.521024039965309

Epoch: 6| Step: 6
Training loss: 2.418368452865675
Validation loss: 2.52963600978085

Epoch: 6| Step: 7
Training loss: 1.935418333525773
Validation loss: 2.5254332815896245

Epoch: 6| Step: 8
Training loss: 2.5097701848207605
Validation loss: 2.52182675062976

Epoch: 6| Step: 9
Training loss: 2.0118683102020407
Validation loss: 2.5197201522470816

Epoch: 6| Step: 10
Training loss: 2.4797733323277997
Validation loss: 2.5196693717692047

Epoch: 6| Step: 11
Training loss: 1.934559836977885
Validation loss: 2.532817794602869

Epoch: 6| Step: 12
Training loss: 2.5090300554502796
Validation loss: 2.526406430260502

Epoch: 6| Step: 13
Training loss: 2.30968840541107
Validation loss: 2.5363770902078384

Epoch: 233| Step: 0
Training loss: 1.9897840175642068
Validation loss: 2.559996009540428

Epoch: 6| Step: 1
Training loss: 2.2122796503891364
Validation loss: 2.5259775894270318

Epoch: 6| Step: 2
Training loss: 2.3536359700818403
Validation loss: 2.540964582020001

Epoch: 6| Step: 3
Training loss: 2.6232753719468698
Validation loss: 2.546638056492832

Epoch: 6| Step: 4
Training loss: 2.3213599310148543
Validation loss: 2.546998089271291

Epoch: 6| Step: 5
Training loss: 2.2477764162486995
Validation loss: 2.523942249313496

Epoch: 6| Step: 6
Training loss: 2.3520473854780084
Validation loss: 2.5240894180203184

Epoch: 6| Step: 7
Training loss: 2.647440404752543
Validation loss: 2.517925608398815

Epoch: 6| Step: 8
Training loss: 2.3112378155483593
Validation loss: 2.5376029176934582

Epoch: 6| Step: 9
Training loss: 1.9444576974447398
Validation loss: 2.535590692491304

Epoch: 6| Step: 10
Training loss: 2.233814942921358
Validation loss: 2.5504932094888155

Epoch: 6| Step: 11
Training loss: 2.3363900145022285
Validation loss: 2.558890071725436

Epoch: 6| Step: 12
Training loss: 2.468142664119969
Validation loss: 2.55069326314239

Epoch: 6| Step: 13
Training loss: 2.407566948709487
Validation loss: 2.551859699234228

Epoch: 234| Step: 0
Training loss: 3.111670791903845
Validation loss: 2.564204649207424

Epoch: 6| Step: 1
Training loss: 2.5444654053884777
Validation loss: 2.5570485270742362

Epoch: 6| Step: 2
Training loss: 2.2872433252632263
Validation loss: 2.569310125213802

Epoch: 6| Step: 3
Training loss: 1.9327290769072887
Validation loss: 2.5735523555705235

Epoch: 6| Step: 4
Training loss: 1.6461811261552792
Validation loss: 2.574311551402449

Epoch: 6| Step: 5
Training loss: 2.1229839859590727
Validation loss: 2.567020011913014

Epoch: 6| Step: 6
Training loss: 1.989218859883414
Validation loss: 2.5601400657920643

Epoch: 6| Step: 7
Training loss: 2.4214349162279443
Validation loss: 2.5654940133028346

Epoch: 6| Step: 8
Training loss: 2.2019232319712305
Validation loss: 2.5648028175727813

Epoch: 6| Step: 9
Training loss: 2.4689979911539552
Validation loss: 2.5570490787427294

Epoch: 6| Step: 10
Training loss: 1.9605586077241581
Validation loss: 2.553042684322994

Epoch: 6| Step: 11
Training loss: 3.0090874682131497
Validation loss: 2.537547578036749

Epoch: 6| Step: 12
Training loss: 2.253108314738085
Validation loss: 2.5237075692638014

Epoch: 6| Step: 13
Training loss: 2.123514890628897
Validation loss: 2.528981766286703

Epoch: 235| Step: 0
Training loss: 2.5977970400638974
Validation loss: 2.51659387289542

Epoch: 6| Step: 1
Training loss: 2.66582969604066
Validation loss: 2.5167065461474825

Epoch: 6| Step: 2
Training loss: 1.4200841503998693
Validation loss: 2.524809898169833

Epoch: 6| Step: 3
Training loss: 2.2618102481761997
Validation loss: 2.52878903036879

Epoch: 6| Step: 4
Training loss: 1.619600127283319
Validation loss: 2.527759122837896

Epoch: 6| Step: 5
Training loss: 1.7916226122858927
Validation loss: 2.5314729851357383

Epoch: 6| Step: 6
Training loss: 2.6216561954755604
Validation loss: 2.5256168650623803

Epoch: 6| Step: 7
Training loss: 2.603528720281911
Validation loss: 2.522022161401017

Epoch: 6| Step: 8
Training loss: 2.629053346959637
Validation loss: 2.525787707799492

Epoch: 6| Step: 9
Training loss: 2.5742996967190575
Validation loss: 2.532278299446765

Epoch: 6| Step: 10
Training loss: 2.4326573708920196
Validation loss: 2.521481955970571

Epoch: 6| Step: 11
Training loss: 2.385230666548123
Validation loss: 2.521082737042268

Epoch: 6| Step: 12
Training loss: 2.806200984535265
Validation loss: 2.53975017918525

Epoch: 6| Step: 13
Training loss: 1.56265990392721
Validation loss: 2.527470596801499

Epoch: 236| Step: 0
Training loss: 2.8304278866426493
Validation loss: 2.555466808169467

Epoch: 6| Step: 1
Training loss: 2.091156449217748
Validation loss: 2.5691803948300316

Epoch: 6| Step: 2
Training loss: 2.079966023607788
Validation loss: 2.5544178516118583

Epoch: 6| Step: 3
Training loss: 1.848993055707106
Validation loss: 2.5556829381606945

Epoch: 6| Step: 4
Training loss: 2.4111061141064374
Validation loss: 2.5618106411011667

Epoch: 6| Step: 5
Training loss: 2.4883922031164545
Validation loss: 2.539446491646867

Epoch: 6| Step: 6
Training loss: 2.24701503269547
Validation loss: 2.5321498731246557

Epoch: 6| Step: 7
Training loss: 2.229206857289258
Validation loss: 2.5106561369797524

Epoch: 6| Step: 8
Training loss: 2.831555388361386
Validation loss: 2.496119459773005

Epoch: 6| Step: 9
Training loss: 2.571209504620421
Validation loss: 2.497790146699876

Epoch: 6| Step: 10
Training loss: 1.9551098922907704
Validation loss: 2.4903983188093894

Epoch: 6| Step: 11
Training loss: 2.4515150095981784
Validation loss: 2.500354821138955

Epoch: 6| Step: 12
Training loss: 2.423202249408936
Validation loss: 2.490163892359365

Epoch: 6| Step: 13
Training loss: 2.003050980412894
Validation loss: 2.4910436893369954

Epoch: 237| Step: 0
Training loss: 2.0091619446850726
Validation loss: 2.4971075809837

Epoch: 6| Step: 1
Training loss: 2.5136941643521777
Validation loss: 2.5078162235854284

Epoch: 6| Step: 2
Training loss: 1.61671079529512
Validation loss: 2.4976524616300626

Epoch: 6| Step: 3
Training loss: 2.354204689551526
Validation loss: 2.512096607980746

Epoch: 6| Step: 4
Training loss: 1.9555404375616585
Validation loss: 2.5097619359722807

Epoch: 6| Step: 5
Training loss: 2.3877811845499006
Validation loss: 2.510457285213442

Epoch: 6| Step: 6
Training loss: 2.4596800482870544
Validation loss: 2.5246429083842608

Epoch: 6| Step: 7
Training loss: 2.4823698192934045
Validation loss: 2.517741132676968

Epoch: 6| Step: 8
Training loss: 3.0549956261436506
Validation loss: 2.525409018874147

Epoch: 6| Step: 9
Training loss: 2.6537692883905035
Validation loss: 2.5321890419601423

Epoch: 6| Step: 10
Training loss: 1.815981185563551
Validation loss: 2.539987170745209

Epoch: 6| Step: 11
Training loss: 2.242113171983668
Validation loss: 2.5341739955830827

Epoch: 6| Step: 12
Training loss: 2.3193079768051446
Validation loss: 2.562812693055956

Epoch: 6| Step: 13
Training loss: 2.123246086200542
Validation loss: 2.575149344770692

Epoch: 238| Step: 0
Training loss: 2.082993848479331
Validation loss: 2.5630969616015955

Epoch: 6| Step: 1
Training loss: 2.4504372031480965
Validation loss: 2.5732312235396564

Epoch: 6| Step: 2
Training loss: 1.9099346882703219
Validation loss: 2.5701544808741073

Epoch: 6| Step: 3
Training loss: 2.3475240203636005
Validation loss: 2.5715103218414894

Epoch: 6| Step: 4
Training loss: 2.552193547159119
Validation loss: 2.5483461745266895

Epoch: 6| Step: 5
Training loss: 2.9345535760234056
Validation loss: 2.5596125081472807

Epoch: 6| Step: 6
Training loss: 2.0412041535984295
Validation loss: 2.5327192838076

Epoch: 6| Step: 7
Training loss: 2.0354727647196675
Validation loss: 2.519251671392819

Epoch: 6| Step: 8
Training loss: 2.2768941602337907
Validation loss: 2.5204336832154945

Epoch: 6| Step: 9
Training loss: 2.668851067016258
Validation loss: 2.519814661138442

Epoch: 6| Step: 10
Training loss: 2.180640665109029
Validation loss: 2.5096366403884227

Epoch: 6| Step: 11
Training loss: 2.672675654149361
Validation loss: 2.4952724978290726

Epoch: 6| Step: 12
Training loss: 2.4519047709108186
Validation loss: 2.506935512941277

Epoch: 6| Step: 13
Training loss: 1.9089130498348619
Validation loss: 2.4940439164170725

Epoch: 239| Step: 0
Training loss: 2.0222442525611495
Validation loss: 2.5079203708222257

Epoch: 6| Step: 1
Training loss: 2.2984638557504895
Validation loss: 2.5070515841916237

Epoch: 6| Step: 2
Training loss: 2.06743101731413
Validation loss: 2.517701802201192

Epoch: 6| Step: 3
Training loss: 1.612010612448127
Validation loss: 2.5045851780358896

Epoch: 6| Step: 4
Training loss: 3.163754747282436
Validation loss: 2.516709482910869

Epoch: 6| Step: 5
Training loss: 1.5160860756415753
Validation loss: 2.5293158374600875

Epoch: 6| Step: 6
Training loss: 2.2228526479505413
Validation loss: 2.5326036828806453

Epoch: 6| Step: 7
Training loss: 1.9219174264086127
Validation loss: 2.5407966364980403

Epoch: 6| Step: 8
Training loss: 2.4914919082782734
Validation loss: 2.540536063601679

Epoch: 6| Step: 9
Training loss: 1.7970886103500037
Validation loss: 2.5406024195194323

Epoch: 6| Step: 10
Training loss: 2.410725580421106
Validation loss: 2.5599971116069553

Epoch: 6| Step: 11
Training loss: 2.7505189232632095
Validation loss: 2.537722612585131

Epoch: 6| Step: 12
Training loss: 2.6353601643130666
Validation loss: 2.546484903677936

Epoch: 6| Step: 13
Training loss: 2.7875221764747233
Validation loss: 2.555404531351688

Epoch: 240| Step: 0
Training loss: 2.6465858130352165
Validation loss: 2.5570192107731016

Epoch: 6| Step: 1
Training loss: 1.862748555745123
Validation loss: 2.5347648675080414

Epoch: 6| Step: 2
Training loss: 2.4723092991308446
Validation loss: 2.53372281953711

Epoch: 6| Step: 3
Training loss: 2.1724936063999434
Validation loss: 2.513555445490376

Epoch: 6| Step: 4
Training loss: 2.6746454877436414
Validation loss: 2.5197418676856294

Epoch: 6| Step: 5
Training loss: 2.341543150480367
Validation loss: 2.4972602772974932

Epoch: 6| Step: 6
Training loss: 2.5319899431182584
Validation loss: 2.491875177502536

Epoch: 6| Step: 7
Training loss: 2.938483540256338
Validation loss: 2.4839690974474036

Epoch: 6| Step: 8
Training loss: 2.368295743761626
Validation loss: 2.4782955551945154

Epoch: 6| Step: 9
Training loss: 1.797776966111815
Validation loss: 2.4985700809497247

Epoch: 6| Step: 10
Training loss: 2.142614734653331
Validation loss: 2.494458557911202

Epoch: 6| Step: 11
Training loss: 2.2792818122895606
Validation loss: 2.4915546183659023

Epoch: 6| Step: 12
Training loss: 2.166467755308174
Validation loss: 2.5121682468357793

Epoch: 6| Step: 13
Training loss: 2.2350076700032027
Validation loss: 2.5182636788550035

Epoch: 241| Step: 0
Training loss: 2.372806339082591
Validation loss: 2.5273003709579416

Epoch: 6| Step: 1
Training loss: 2.285766937296579
Validation loss: 2.525606433825655

Epoch: 6| Step: 2
Training loss: 2.5785669121440407
Validation loss: 2.518308302310813

Epoch: 6| Step: 3
Training loss: 2.205574783873424
Validation loss: 2.5302574032553116

Epoch: 6| Step: 4
Training loss: 2.3619938141615036
Validation loss: 2.5374593593681554

Epoch: 6| Step: 5
Training loss: 2.4652493924460392
Validation loss: 2.531620092769284

Epoch: 6| Step: 6
Training loss: 2.9409125776271563
Validation loss: 2.5189534473526924

Epoch: 6| Step: 7
Training loss: 1.5433734604471063
Validation loss: 2.5264819413684783

Epoch: 6| Step: 8
Training loss: 2.7672634982373396
Validation loss: 2.525328487645703

Epoch: 6| Step: 9
Training loss: 2.079403591481136
Validation loss: 2.5178754624521926

Epoch: 6| Step: 10
Training loss: 2.5912139628030317
Validation loss: 2.512084950062551

Epoch: 6| Step: 11
Training loss: 2.1561610991354065
Validation loss: 2.502397420853272

Epoch: 6| Step: 12
Training loss: 2.300229484056165
Validation loss: 2.500217650793774

Epoch: 6| Step: 13
Training loss: 1.4552966881782416
Validation loss: 2.508590458737391

Epoch: 242| Step: 0
Training loss: 2.6130814411772736
Validation loss: 2.512738089723034

Epoch: 6| Step: 1
Training loss: 2.174787475901527
Validation loss: 2.501908654545586

Epoch: 6| Step: 2
Training loss: 2.1085280236780686
Validation loss: 2.5125666917897975

Epoch: 6| Step: 3
Training loss: 1.9159875647991471
Validation loss: 2.5161754803551704

Epoch: 6| Step: 4
Training loss: 2.4659734636845125
Validation loss: 2.5303580671041384

Epoch: 6| Step: 5
Training loss: 2.8808002840867735
Validation loss: 2.526693395063934

Epoch: 6| Step: 6
Training loss: 1.6289208866623581
Validation loss: 2.535076921864723

Epoch: 6| Step: 7
Training loss: 2.323790438640297
Validation loss: 2.5332691788915693

Epoch: 6| Step: 8
Training loss: 2.3028064357363496
Validation loss: 2.5278187010204025

Epoch: 6| Step: 9
Training loss: 2.504123243906459
Validation loss: 2.531196028522554

Epoch: 6| Step: 10
Training loss: 2.139417321569141
Validation loss: 2.5444665297984663

Epoch: 6| Step: 11
Training loss: 2.3193521792194476
Validation loss: 2.542414513510195

Epoch: 6| Step: 12
Training loss: 2.590855097474268
Validation loss: 2.542730270430718

Epoch: 6| Step: 13
Training loss: 2.057504209975319
Validation loss: 2.540582540297267

Epoch: 243| Step: 0
Training loss: 2.4489257247832916
Validation loss: 2.531360615954566

Epoch: 6| Step: 1
Training loss: 2.5051980338939033
Validation loss: 2.553897187131413

Epoch: 6| Step: 2
Training loss: 2.175176512472631
Validation loss: 2.5409151331553175

Epoch: 6| Step: 3
Training loss: 2.016611020710265
Validation loss: 2.5370666719581725

Epoch: 6| Step: 4
Training loss: 2.7501532772003277
Validation loss: 2.5191754782401974

Epoch: 6| Step: 5
Training loss: 2.336286639910536
Validation loss: 2.5271390333795964

Epoch: 6| Step: 6
Training loss: 2.3140109513006326
Validation loss: 2.5245283385038837

Epoch: 6| Step: 7
Training loss: 2.0748133839717022
Validation loss: 2.5262704857032277

Epoch: 6| Step: 8
Training loss: 2.80926666899554
Validation loss: 2.5340869139323496

Epoch: 6| Step: 9
Training loss: 1.8270343885604403
Validation loss: 2.5691795905678316

Epoch: 6| Step: 10
Training loss: 2.0336334330159827
Validation loss: 2.583985166965247

Epoch: 6| Step: 11
Training loss: 2.2292819364697927
Validation loss: 2.581890585218301

Epoch: 6| Step: 12
Training loss: 2.2310270823190415
Validation loss: 2.600827606848373

Epoch: 6| Step: 13
Training loss: 2.238576606583134
Validation loss: 2.6018115164075217

Epoch: 244| Step: 0
Training loss: 2.159422379013964
Validation loss: 2.582390110549678

Epoch: 6| Step: 1
Training loss: 2.1823109798138227
Validation loss: 2.56595776808652

Epoch: 6| Step: 2
Training loss: 2.300554196305303
Validation loss: 2.5638318361203045

Epoch: 6| Step: 3
Training loss: 2.8716454215951113
Validation loss: 2.53129497535215

Epoch: 6| Step: 4
Training loss: 2.6388585429091993
Validation loss: 2.5272377774142427

Epoch: 6| Step: 5
Training loss: 2.2749987088713284
Validation loss: 2.5267255086849496

Epoch: 6| Step: 6
Training loss: 2.152750021916235
Validation loss: 2.515655967569183

Epoch: 6| Step: 7
Training loss: 2.8403041209331175
Validation loss: 2.518316538944287

Epoch: 6| Step: 8
Training loss: 1.574768576195562
Validation loss: 2.4977922227757814

Epoch: 6| Step: 9
Training loss: 2.3682743007524985
Validation loss: 2.5103409994495682

Epoch: 6| Step: 10
Training loss: 2.2523272452541963
Validation loss: 2.495393594161797

Epoch: 6| Step: 11
Training loss: 1.9318574758603062
Validation loss: 2.5233862746701394

Epoch: 6| Step: 12
Training loss: 2.522104011357185
Validation loss: 2.532218543727863

Epoch: 6| Step: 13
Training loss: 2.149914708774486
Validation loss: 2.535757345247178

Epoch: 245| Step: 0
Training loss: 2.533184866151911
Validation loss: 2.54743672048674

Epoch: 6| Step: 1
Training loss: 2.2301871795102435
Validation loss: 2.549882435425998

Epoch: 6| Step: 2
Training loss: 2.35041837011784
Validation loss: 2.561497499948106

Epoch: 6| Step: 3
Training loss: 2.3925877909562403
Validation loss: 2.5677145647717445

Epoch: 6| Step: 4
Training loss: 2.3356883448788874
Validation loss: 2.5694215770654676

Epoch: 6| Step: 5
Training loss: 2.452790450105036
Validation loss: 2.58056640625

Epoch: 6| Step: 6
Training loss: 3.0339467745332453
Validation loss: 2.583272599972767

Epoch: 6| Step: 7
Training loss: 1.9774954783970276
Validation loss: 2.567804103919763

Epoch: 6| Step: 8
Training loss: 1.5447026421516499
Validation loss: 2.5508010808963446

Epoch: 6| Step: 9
Training loss: 2.255829676312894
Validation loss: 2.5391783859020878

Epoch: 6| Step: 10
Training loss: 1.9552846946159814
Validation loss: 2.525125842216128

Epoch: 6| Step: 11
Training loss: 2.4902477787629467
Validation loss: 2.522786799605152

Epoch: 6| Step: 12
Training loss: 2.030096342685119
Validation loss: 2.511358240180088

Epoch: 6| Step: 13
Training loss: 2.198095437925691
Validation loss: 2.5139469528752043

Epoch: 246| Step: 0
Training loss: 2.565341025839922
Validation loss: 2.5072818880058216

Epoch: 6| Step: 1
Training loss: 2.6640247331106908
Validation loss: 2.495504501749405

Epoch: 6| Step: 2
Training loss: 2.88368703918116
Validation loss: 2.4934062947173476

Epoch: 6| Step: 3
Training loss: 1.780892185612628
Validation loss: 2.4810437674858785

Epoch: 6| Step: 4
Training loss: 2.1777058005062
Validation loss: 2.4981939785980942

Epoch: 6| Step: 5
Training loss: 2.6609577422343693
Validation loss: 2.511554417986569

Epoch: 6| Step: 6
Training loss: 2.3530260771973404
Validation loss: 2.517073394001373

Epoch: 6| Step: 7
Training loss: 2.014131687772296
Validation loss: 2.5337880600672653

Epoch: 6| Step: 8
Training loss: 2.7756381907640324
Validation loss: 2.53638218968416

Epoch: 6| Step: 9
Training loss: 2.4727873805079197
Validation loss: 2.5390570068299954

Epoch: 6| Step: 10
Training loss: 2.755590391921582
Validation loss: 2.553668239764146

Epoch: 6| Step: 11
Training loss: 1.920617289057508
Validation loss: 2.5580004521072026

Epoch: 6| Step: 12
Training loss: 1.781526109142769
Validation loss: 2.5464361393863904

Epoch: 6| Step: 13
Training loss: 1.806757412821489
Validation loss: 2.532176456526982

Epoch: 247| Step: 0
Training loss: 2.2190641798628956
Validation loss: 2.522439576286343

Epoch: 6| Step: 1
Training loss: 2.602493257101597
Validation loss: 2.519128795881315

Epoch: 6| Step: 2
Training loss: 2.6528048444590953
Validation loss: 2.507668670300913

Epoch: 6| Step: 3
Training loss: 2.5520581821577673
Validation loss: 2.5112292028704926

Epoch: 6| Step: 4
Training loss: 1.6860032684819408
Validation loss: 2.500695322616815

Epoch: 6| Step: 5
Training loss: 2.116752101145204
Validation loss: 2.4946807778282345

Epoch: 6| Step: 6
Training loss: 2.277584527767944
Validation loss: 2.508927458889095

Epoch: 6| Step: 7
Training loss: 2.3521719614861
Validation loss: 2.5006095858296438

Epoch: 6| Step: 8
Training loss: 1.6790415386721156
Validation loss: 2.501313960960474

Epoch: 6| Step: 9
Training loss: 2.541529375547814
Validation loss: 2.5122708138591827

Epoch: 6| Step: 10
Training loss: 2.2444126903797237
Validation loss: 2.5172364027915335

Epoch: 6| Step: 11
Training loss: 2.5016252956574148
Validation loss: 2.5301659699986354

Epoch: 6| Step: 12
Training loss: 2.046957931585708
Validation loss: 2.5458406871766446

Epoch: 6| Step: 13
Training loss: 2.611868757435353
Validation loss: 2.5688777888704273

Epoch: 248| Step: 0
Training loss: 2.7991256608956694
Validation loss: 2.580268323434758

Epoch: 6| Step: 1
Training loss: 1.7681519646474593
Validation loss: 2.55640115143359

Epoch: 6| Step: 2
Training loss: 1.894006526682
Validation loss: 2.5593053396058156

Epoch: 6| Step: 3
Training loss: 2.357536357384887
Validation loss: 2.542561597599933

Epoch: 6| Step: 4
Training loss: 2.4663557200289916
Validation loss: 2.5360174846903827

Epoch: 6| Step: 5
Training loss: 1.8802073329877085
Validation loss: 2.529556932667112

Epoch: 6| Step: 6
Training loss: 1.9653251771037312
Validation loss: 2.5216599887609044

Epoch: 6| Step: 7
Training loss: 1.7033810204376922
Validation loss: 2.5097241270837647

Epoch: 6| Step: 8
Training loss: 2.8364191828470546
Validation loss: 2.5283865882513803

Epoch: 6| Step: 9
Training loss: 2.1775079583812036
Validation loss: 2.5168627582558942

Epoch: 6| Step: 10
Training loss: 2.6712661852634114
Validation loss: 2.5081551417765477

Epoch: 6| Step: 11
Training loss: 2.1422637458437728
Validation loss: 2.5127150644395075

Epoch: 6| Step: 12
Training loss: 3.129259182459302
Validation loss: 2.4957046165666847

Epoch: 6| Step: 13
Training loss: 1.9828167301310213
Validation loss: 2.502490662624991

Epoch: 249| Step: 0
Training loss: 1.9610122727200217
Validation loss: 2.508075086368043

Epoch: 6| Step: 1
Training loss: 2.5999620801654664
Validation loss: 2.5053772951965168

Epoch: 6| Step: 2
Training loss: 1.8535121519741566
Validation loss: 2.5062831442045304

Epoch: 6| Step: 3
Training loss: 2.5368561063985346
Validation loss: 2.4895212226898296

Epoch: 6| Step: 4
Training loss: 2.484514148582051
Validation loss: 2.495295819422052

Epoch: 6| Step: 5
Training loss: 1.8749070462391872
Validation loss: 2.5044166017064238

Epoch: 6| Step: 6
Training loss: 2.4631865381869718
Validation loss: 2.508019681396

Epoch: 6| Step: 7
Training loss: 2.6748812533252515
Validation loss: 2.5337617131323023

Epoch: 6| Step: 8
Training loss: 2.116018500422059
Validation loss: 2.5231711421259706

Epoch: 6| Step: 9
Training loss: 2.5403136941233817
Validation loss: 2.555607325840368

Epoch: 6| Step: 10
Training loss: 2.3862218261462322
Validation loss: 2.566013966176219

Epoch: 6| Step: 11
Training loss: 2.6986117750127656
Validation loss: 2.610270028791971

Epoch: 6| Step: 12
Training loss: 2.216306388468968
Validation loss: 2.5856506403677626

Epoch: 6| Step: 13
Training loss: 1.7853006183503326
Validation loss: 2.591564161311703

Epoch: 250| Step: 0
Training loss: 1.916166931462005
Validation loss: 2.573193636875952

Epoch: 6| Step: 1
Training loss: 2.805993756190101
Validation loss: 2.559033149864278

Epoch: 6| Step: 2
Training loss: 2.3872870784704
Validation loss: 2.5611788592706697

Epoch: 6| Step: 3
Training loss: 2.1261843578470487
Validation loss: 2.5314141836411537

Epoch: 6| Step: 4
Training loss: 1.8126755333450115
Validation loss: 2.5291195761891223

Epoch: 6| Step: 5
Training loss: 2.2916498241383625
Validation loss: 2.5223811785938928

Epoch: 6| Step: 6
Training loss: 2.6027876801394583
Validation loss: 2.533013659519092

Epoch: 6| Step: 7
Training loss: 1.9466706709080277
Validation loss: 2.5562876163068453

Epoch: 6| Step: 8
Training loss: 2.3040271912268304
Validation loss: 2.5450669796441785

Epoch: 6| Step: 9
Training loss: 2.532787656573969
Validation loss: 2.5622035141908257

Epoch: 6| Step: 10
Training loss: 1.5403012939590341
Validation loss: 2.5364063004333697

Epoch: 6| Step: 11
Training loss: 2.0756653879354783
Validation loss: 2.5212399073411214

Epoch: 6| Step: 12
Training loss: 2.316065951434467
Validation loss: 2.53986346791488

Epoch: 6| Step: 13
Training loss: 2.8626656696736568
Validation loss: 2.527950546161695

Epoch: 251| Step: 0
Training loss: 2.2365470945609363
Validation loss: 2.5320087912478706

Epoch: 6| Step: 1
Training loss: 1.9211001811437634
Validation loss: 2.5387560693745614

Epoch: 6| Step: 2
Training loss: 1.9136994932400557
Validation loss: 2.528282003160363

Epoch: 6| Step: 3
Training loss: 2.2048907407303315
Validation loss: 2.5184442112075067

Epoch: 6| Step: 4
Training loss: 1.8606097825632248
Validation loss: 2.5252393464312903

Epoch: 6| Step: 5
Training loss: 2.6131961278352147
Validation loss: 2.539432768600032

Epoch: 6| Step: 6
Training loss: 2.1254639960456467
Validation loss: 2.5369895885245373

Epoch: 6| Step: 7
Training loss: 2.0821068268705565
Validation loss: 2.542657539165593

Epoch: 6| Step: 8
Training loss: 2.9266348027932865
Validation loss: 2.5316385041663407

Epoch: 6| Step: 9
Training loss: 2.520885204275428
Validation loss: 2.5389039131914592

Epoch: 6| Step: 10
Training loss: 1.3932091352026914
Validation loss: 2.523068222882436

Epoch: 6| Step: 11
Training loss: 2.7692991517255856
Validation loss: 2.5308212262482543

Epoch: 6| Step: 12
Training loss: 2.3940477987758486
Validation loss: 2.5375854734610708

Epoch: 6| Step: 13
Training loss: 2.4432055869367733
Validation loss: 2.5466004206078328

Epoch: 252| Step: 0
Training loss: 2.7552043912363002
Validation loss: 2.541554266106688

Epoch: 6| Step: 1
Training loss: 2.6024188674167763
Validation loss: 2.546890765806364

Epoch: 6| Step: 2
Training loss: 2.8029817372331727
Validation loss: 2.5433474960366116

Epoch: 6| Step: 3
Training loss: 2.1556800420717868
Validation loss: 2.5371423591425493

Epoch: 6| Step: 4
Training loss: 2.116936362598899
Validation loss: 2.5570403141925957

Epoch: 6| Step: 5
Training loss: 2.169638380867962
Validation loss: 2.5493367784980947

Epoch: 6| Step: 6
Training loss: 1.7756057457851764
Validation loss: 2.5394316106656634

Epoch: 6| Step: 7
Training loss: 2.3153489580243227
Validation loss: 2.5710708287949395

Epoch: 6| Step: 8
Training loss: 1.87119103419703
Validation loss: 2.5662650384476255

Epoch: 6| Step: 9
Training loss: 2.5870053025741706
Validation loss: 2.56966569795622

Epoch: 6| Step: 10
Training loss: 2.5205182175419676
Validation loss: 2.559243373568011

Epoch: 6| Step: 11
Training loss: 1.395746294790492
Validation loss: 2.530577181653787

Epoch: 6| Step: 12
Training loss: 1.6599020370624415
Validation loss: 2.51056967199111

Epoch: 6| Step: 13
Training loss: 2.628135715603387
Validation loss: 2.4987436793624123

Epoch: 253| Step: 0
Training loss: 2.0881075768655877
Validation loss: 2.4954019064304043

Epoch: 6| Step: 1
Training loss: 2.22892897815261
Validation loss: 2.4907326353165242

Epoch: 6| Step: 2
Training loss: 2.174174018205072
Validation loss: 2.488249813981153

Epoch: 6| Step: 3
Training loss: 2.7558074665114884
Validation loss: 2.496480793364181

Epoch: 6| Step: 4
Training loss: 2.38156705733002
Validation loss: 2.496910140801219

Epoch: 6| Step: 5
Training loss: 2.2159443699089123
Validation loss: 2.499998585382697

Epoch: 6| Step: 6
Training loss: 1.8641194951184563
Validation loss: 2.526856648173034

Epoch: 6| Step: 7
Training loss: 2.4744384513903834
Validation loss: 2.537584283365443

Epoch: 6| Step: 8
Training loss: 3.006858614978222
Validation loss: 2.5396746244808632

Epoch: 6| Step: 9
Training loss: 2.1974667876666416
Validation loss: 2.5584658680569277

Epoch: 6| Step: 10
Training loss: 2.0418901386055923
Validation loss: 2.5362159383412726

Epoch: 6| Step: 11
Training loss: 2.006111938859986
Validation loss: 2.5272539251560366

Epoch: 6| Step: 12
Training loss: 2.0386223445853755
Validation loss: 2.504657111059905

Epoch: 6| Step: 13
Training loss: 2.2108257791174664
Validation loss: 2.5054725988723474

Epoch: 254| Step: 0
Training loss: 1.8839573841823065
Validation loss: 2.4819438403023946

Epoch: 6| Step: 1
Training loss: 2.0944455258371995
Validation loss: 2.490454698178304

Epoch: 6| Step: 2
Training loss: 2.1160802444357145
Validation loss: 2.4931202800097525

Epoch: 6| Step: 3
Training loss: 2.8163712032428476
Validation loss: 2.492910521411117

Epoch: 6| Step: 4
Training loss: 2.00735409027047
Validation loss: 2.494194346829914

Epoch: 6| Step: 5
Training loss: 2.296735486834384
Validation loss: 2.496237999892486

Epoch: 6| Step: 6
Training loss: 2.6751235933362074
Validation loss: 2.4971095223668405

Epoch: 6| Step: 7
Training loss: 1.9723199236613116
Validation loss: 2.508850643342115

Epoch: 6| Step: 8
Training loss: 2.5583378554644884
Validation loss: 2.4944808198216046

Epoch: 6| Step: 9
Training loss: 2.2254004943103847
Validation loss: 2.525810456591337

Epoch: 6| Step: 10
Training loss: 2.026995737418542
Validation loss: 2.534114143440277

Epoch: 6| Step: 11
Training loss: 2.7663786125364638
Validation loss: 2.5358834107922443

Epoch: 6| Step: 12
Training loss: 2.1538416363333392
Validation loss: 2.5450951845846927

Epoch: 6| Step: 13
Training loss: 2.142769066953318
Validation loss: 2.543520545764507

Epoch: 255| Step: 0
Training loss: 2.2215734435447945
Validation loss: 2.530169864852623

Epoch: 6| Step: 1
Training loss: 1.8049057997746532
Validation loss: 2.512221045373124

Epoch: 6| Step: 2
Training loss: 2.9748276989191886
Validation loss: 2.4996220620901393

Epoch: 6| Step: 3
Training loss: 2.0962834758963105
Validation loss: 2.521566762447438

Epoch: 6| Step: 4
Training loss: 2.3567561084153836
Validation loss: 2.526657459406655

Epoch: 6| Step: 5
Training loss: 2.659810989089387
Validation loss: 2.524304078766468

Epoch: 6| Step: 6
Training loss: 1.8339429044249642
Validation loss: 2.552451676755993

Epoch: 6| Step: 7
Training loss: 2.0615606769937087
Validation loss: 2.554733524821738

Epoch: 6| Step: 8
Training loss: 2.2537423905653027
Validation loss: 2.5650311816267832

Epoch: 6| Step: 9
Training loss: 2.479163984623161
Validation loss: 2.55705966143078

Epoch: 6| Step: 10
Training loss: 2.3216294170311538
Validation loss: 2.5408512329124995

Epoch: 6| Step: 11
Training loss: 1.6061557311660561
Validation loss: 2.511025609494388

Epoch: 6| Step: 12
Training loss: 2.3523242008305294
Validation loss: 2.4887302698196003

Epoch: 6| Step: 13
Training loss: 2.2182534965213287
Validation loss: 2.4901762752362475

Epoch: 256| Step: 0
Training loss: 2.236553490623119
Validation loss: 2.484728102312498

Epoch: 6| Step: 1
Training loss: 2.6062508342933692
Validation loss: 2.4908346013763287

Epoch: 6| Step: 2
Training loss: 2.727708810563292
Validation loss: 2.5044310084846333

Epoch: 6| Step: 3
Training loss: 2.2800019913380276
Validation loss: 2.499768151022892

Epoch: 6| Step: 4
Training loss: 1.9184107378012492
Validation loss: 2.5340742830419734

Epoch: 6| Step: 5
Training loss: 2.6437851995915986
Validation loss: 2.500402179793227

Epoch: 6| Step: 6
Training loss: 2.668749760576367
Validation loss: 2.5116613370623257

Epoch: 6| Step: 7
Training loss: 2.153711123478159
Validation loss: 2.532019368737913

Epoch: 6| Step: 8
Training loss: 1.549490441887701
Validation loss: 2.547641755746871

Epoch: 6| Step: 9
Training loss: 1.6991132330744156
Validation loss: 2.5505038583284216

Epoch: 6| Step: 10
Training loss: 2.324675186602543
Validation loss: 2.5524609240991607

Epoch: 6| Step: 11
Training loss: 2.489412586523162
Validation loss: 2.5778684854534113

Epoch: 6| Step: 12
Training loss: 2.145125287716314
Validation loss: 2.571740678359647

Epoch: 6| Step: 13
Training loss: 2.0794269814169772
Validation loss: 2.567707701419239

Epoch: 257| Step: 0
Training loss: 1.7791709143463577
Validation loss: 2.522048095283856

Epoch: 6| Step: 1
Training loss: 1.9893298428677848
Validation loss: 2.5232147338926443

Epoch: 6| Step: 2
Training loss: 2.5276621127185885
Validation loss: 2.491110111410867

Epoch: 6| Step: 3
Training loss: 2.7822493568630127
Validation loss: 2.4806938249493395

Epoch: 6| Step: 4
Training loss: 1.975917726074199
Validation loss: 2.4873431806477613

Epoch: 6| Step: 5
Training loss: 1.8465819511996584
Validation loss: 2.4954888651130704

Epoch: 6| Step: 6
Training loss: 3.033361584318741
Validation loss: 2.4918173233040783

Epoch: 6| Step: 7
Training loss: 2.0576905326643637
Validation loss: 2.4835984397892705

Epoch: 6| Step: 8
Training loss: 2.3299190086401094
Validation loss: 2.4988743950147523

Epoch: 6| Step: 9
Training loss: 2.3836169276428127
Validation loss: 2.522006689176227

Epoch: 6| Step: 10
Training loss: 2.121371256341677
Validation loss: 2.568107269639341

Epoch: 6| Step: 11
Training loss: 2.49349835878161
Validation loss: 2.5423872244200423

Epoch: 6| Step: 12
Training loss: 2.2763401653399353
Validation loss: 2.5367927069770393

Epoch: 6| Step: 13
Training loss: 2.153471109728331
Validation loss: 2.5176978880592333

Epoch: 258| Step: 0
Training loss: 1.4974190442041642
Validation loss: 2.51405999764586

Epoch: 6| Step: 1
Training loss: 2.3957199954439217
Validation loss: 2.4938116252426594

Epoch: 6| Step: 2
Training loss: 2.34056566720891
Validation loss: 2.503698458408481

Epoch: 6| Step: 3
Training loss: 2.059644861441222
Validation loss: 2.4925962409898683

Epoch: 6| Step: 4
Training loss: 2.6575423743098514
Validation loss: 2.5022927420271914

Epoch: 6| Step: 5
Training loss: 2.8782502750796524
Validation loss: 2.4976825622439023

Epoch: 6| Step: 6
Training loss: 2.5384770584076612
Validation loss: 2.5126086330177753

Epoch: 6| Step: 7
Training loss: 2.3013688326462867
Validation loss: 2.525015212790611

Epoch: 6| Step: 8
Training loss: 1.6967823319396103
Validation loss: 2.5035208228395534

Epoch: 6| Step: 9
Training loss: 1.7055850679134008
Validation loss: 2.5522625503413314

Epoch: 6| Step: 10
Training loss: 2.8941325583637076
Validation loss: 2.5314139324839493

Epoch: 6| Step: 11
Training loss: 2.505253992966562
Validation loss: 2.5595322768281474

Epoch: 6| Step: 12
Training loss: 1.9017823191765326
Validation loss: 2.548349402281165

Epoch: 6| Step: 13
Training loss: 1.8589813072081485
Validation loss: 2.553346349925369

Epoch: 259| Step: 0
Training loss: 2.3297164904954477
Validation loss: 2.5513101431551326

Epoch: 6| Step: 1
Training loss: 2.0601854920436646
Validation loss: 2.557081494885209

Epoch: 6| Step: 2
Training loss: 2.594046610223016
Validation loss: 2.524352215932236

Epoch: 6| Step: 3
Training loss: 2.6345824679203793
Validation loss: 2.515711844072694

Epoch: 6| Step: 4
Training loss: 2.2999431851874803
Validation loss: 2.4968771981049414

Epoch: 6| Step: 5
Training loss: 2.6407781251830516
Validation loss: 2.494733842937514

Epoch: 6| Step: 6
Training loss: 2.4510363780714552
Validation loss: 2.4986789550909947

Epoch: 6| Step: 7
Training loss: 2.263256650401889
Validation loss: 2.4827656201529464

Epoch: 6| Step: 8
Training loss: 1.6423284497372643
Validation loss: 2.4741524603455

Epoch: 6| Step: 9
Training loss: 2.256520677217788
Validation loss: 2.491857684244067

Epoch: 6| Step: 10
Training loss: 1.5674584106087273
Validation loss: 2.468276578039059

Epoch: 6| Step: 11
Training loss: 2.2458060702318736
Validation loss: 2.480139522780869

Epoch: 6| Step: 12
Training loss: 2.2541406466615257
Validation loss: 2.497656534461613

Epoch: 6| Step: 13
Training loss: 1.9853493408550962
Validation loss: 2.4930702965836895

Epoch: 260| Step: 0
Training loss: 1.8393067307137894
Validation loss: 2.4982027587292293

Epoch: 6| Step: 1
Training loss: 1.8014053951158495
Validation loss: 2.514263408528917

Epoch: 6| Step: 2
Training loss: 2.6558203854667655
Validation loss: 2.532219014497966

Epoch: 6| Step: 3
Training loss: 2.6700231369673406
Validation loss: 2.559944708594622

Epoch: 6| Step: 4
Training loss: 1.72520013284026
Validation loss: 2.553965397466197

Epoch: 6| Step: 5
Training loss: 2.3124063833721684
Validation loss: 2.554894410755334

Epoch: 6| Step: 6
Training loss: 2.2077266171564527
Validation loss: 2.523264907587773

Epoch: 6| Step: 7
Training loss: 2.104420246921483
Validation loss: 2.5227478076886354

Epoch: 6| Step: 8
Training loss: 2.227129519358067
Validation loss: 2.528425391056666

Epoch: 6| Step: 9
Training loss: 1.9691944528890957
Validation loss: 2.5296675519684912

Epoch: 6| Step: 10
Training loss: 2.806152046380161
Validation loss: 2.5321240583966267

Epoch: 6| Step: 11
Training loss: 2.5727551573024336
Validation loss: 2.5265631907502826

Epoch: 6| Step: 12
Training loss: 2.029569194537964
Validation loss: 2.54263649609417

Epoch: 6| Step: 13
Training loss: 2.4351797553731025
Validation loss: 2.5482333798720576

Epoch: 261| Step: 0
Training loss: 1.5882080061236727
Validation loss: 2.5399598712204243

Epoch: 6| Step: 1
Training loss: 2.043906352277394
Validation loss: 2.5500391707808894

Epoch: 6| Step: 2
Training loss: 2.3563613339133527
Validation loss: 2.538961101365724

Epoch: 6| Step: 3
Training loss: 2.525688938538911
Validation loss: 2.5475025768972035

Epoch: 6| Step: 4
Training loss: 2.0775219034998127
Validation loss: 2.5272495305276657

Epoch: 6| Step: 5
Training loss: 2.435943106301679
Validation loss: 2.5394292400281135

Epoch: 6| Step: 6
Training loss: 3.3224592382314446
Validation loss: 2.5294123835558553

Epoch: 6| Step: 7
Training loss: 2.1845091946356634
Validation loss: 2.518752292603616

Epoch: 6| Step: 8
Training loss: 1.9362249793645707
Validation loss: 2.510318062984002

Epoch: 6| Step: 9
Training loss: 2.3524869704823153
Validation loss: 2.493165624438488

Epoch: 6| Step: 10
Training loss: 2.315958272449347
Validation loss: 2.512380952687551

Epoch: 6| Step: 11
Training loss: 1.8535252722598647
Validation loss: 2.4869489072120543

Epoch: 6| Step: 12
Training loss: 2.0557277352445915
Validation loss: 2.5035969607145674

Epoch: 6| Step: 13
Training loss: 1.7984745369816912
Validation loss: 2.4891516871257555

Epoch: 262| Step: 0
Training loss: 2.065597289299165
Validation loss: 2.501075306742553

Epoch: 6| Step: 1
Training loss: 1.9130838188716575
Validation loss: 2.522613564093997

Epoch: 6| Step: 2
Training loss: 2.376348112871122
Validation loss: 2.5243731989157174

Epoch: 6| Step: 3
Training loss: 1.9743983668206198
Validation loss: 2.508970237001974

Epoch: 6| Step: 4
Training loss: 2.7550387603747053
Validation loss: 2.520043751245992

Epoch: 6| Step: 5
Training loss: 2.070458403430432
Validation loss: 2.5274290672810635

Epoch: 6| Step: 6
Training loss: 1.816974509984684
Validation loss: 2.5086933462718113

Epoch: 6| Step: 7
Training loss: 1.710368858843256
Validation loss: 2.521010815596339

Epoch: 6| Step: 8
Training loss: 2.3340174716534148
Validation loss: 2.4930007867160273

Epoch: 6| Step: 9
Training loss: 1.9170176834222126
Validation loss: 2.4781577571132605

Epoch: 6| Step: 10
Training loss: 2.5563931152274915
Validation loss: 2.5083409561683516

Epoch: 6| Step: 11
Training loss: 2.6671869743896397
Validation loss: 2.5127573352823425

Epoch: 6| Step: 12
Training loss: 2.4014354942755602
Validation loss: 2.510033437093286

Epoch: 6| Step: 13
Training loss: 2.4228355225751304
Validation loss: 2.555222590381168

Epoch: 263| Step: 0
Training loss: 1.5687228075079593
Validation loss: 2.547290744666411

Epoch: 6| Step: 1
Training loss: 2.4098487793897707
Validation loss: 2.557732085135057

Epoch: 6| Step: 2
Training loss: 2.23720067755288
Validation loss: 2.5622637725121473

Epoch: 6| Step: 3
Training loss: 3.187062252129725
Validation loss: 2.5785327011026093

Epoch: 6| Step: 4
Training loss: 2.472288276085206
Validation loss: 2.587881012904712

Epoch: 6| Step: 5
Training loss: 2.0398333616076196
Validation loss: 2.595479028891289

Epoch: 6| Step: 6
Training loss: 2.6135276598432755
Validation loss: 2.5967288854863217

Epoch: 6| Step: 7
Training loss: 1.8879583168641279
Validation loss: 2.588538130841568

Epoch: 6| Step: 8
Training loss: 2.0855470213288956
Validation loss: 2.6084326224477428

Epoch: 6| Step: 9
Training loss: 2.1751988725615115
Validation loss: 2.602311569682174

Epoch: 6| Step: 10
Training loss: 1.8808740791546206
Validation loss: 2.5835971595011866

Epoch: 6| Step: 11
Training loss: 2.5806874805295323
Validation loss: 2.558508454665254

Epoch: 6| Step: 12
Training loss: 1.8681350283004206
Validation loss: 2.5358965105938407

Epoch: 6| Step: 13
Training loss: 2.1616724360184847
Validation loss: 2.5193454565500324

Epoch: 264| Step: 0
Training loss: 1.871140513303617
Validation loss: 2.538240841674714

Epoch: 6| Step: 1
Training loss: 1.9865306049623057
Validation loss: 2.5046268959511018

Epoch: 6| Step: 2
Training loss: 2.1155948067655994
Validation loss: 2.4971269151828874

Epoch: 6| Step: 3
Training loss: 1.8224766518100644
Validation loss: 2.5254957467819166

Epoch: 6| Step: 4
Training loss: 2.7729911337544624
Validation loss: 2.540594106551273

Epoch: 6| Step: 5
Training loss: 2.9675595757819977
Validation loss: 2.5456137625432738

Epoch: 6| Step: 6
Training loss: 2.170304093917925
Validation loss: 2.563496698209609

Epoch: 6| Step: 7
Training loss: 2.1057580526180524
Validation loss: 2.5555209590002876

Epoch: 6| Step: 8
Training loss: 1.7381805733661395
Validation loss: 2.5505142500573457

Epoch: 6| Step: 9
Training loss: 2.480400697270212
Validation loss: 2.54871422134339

Epoch: 6| Step: 10
Training loss: 1.810019275288665
Validation loss: 2.5458360514857823

Epoch: 6| Step: 11
Training loss: 2.3057416153968027
Validation loss: 2.5510464696396307

Epoch: 6| Step: 12
Training loss: 2.1570664117994442
Validation loss: 2.5445947561283013

Epoch: 6| Step: 13
Training loss: 2.8378879365954233
Validation loss: 2.5274240362119933

Epoch: 265| Step: 0
Training loss: 1.8154926586669817
Validation loss: 2.4986685545234644

Epoch: 6| Step: 1
Training loss: 1.941536728218051
Validation loss: 2.495204673671616

Epoch: 6| Step: 2
Training loss: 1.5519732067115675
Validation loss: 2.4649618838898806

Epoch: 6| Step: 3
Training loss: 2.273521395574014
Validation loss: 2.484118618321857

Epoch: 6| Step: 4
Training loss: 2.4502109787076383
Validation loss: 2.4729999064378507

Epoch: 6| Step: 5
Training loss: 2.21877299552069
Validation loss: 2.483634150503361

Epoch: 6| Step: 6
Training loss: 3.011255765523811
Validation loss: 2.461515393095556

Epoch: 6| Step: 7
Training loss: 2.4352967501688694
Validation loss: 2.4714538157518064

Epoch: 6| Step: 8
Training loss: 2.001037566938541
Validation loss: 2.4969149468973892

Epoch: 6| Step: 9
Training loss: 2.470904026231724
Validation loss: 2.48715511851331

Epoch: 6| Step: 10
Training loss: 1.9141741038891944
Validation loss: 2.5021074154658622

Epoch: 6| Step: 11
Training loss: 2.5668400553146804
Validation loss: 2.5068590009317173

Epoch: 6| Step: 12
Training loss: 2.4833974774501684
Validation loss: 2.494267662833851

Epoch: 6| Step: 13
Training loss: 2.2266236413960003
Validation loss: 2.490215019200716

Epoch: 266| Step: 0
Training loss: 1.662686204162765
Validation loss: 2.4997083334856

Epoch: 6| Step: 1
Training loss: 2.3130966653972074
Validation loss: 2.5083212806775395

Epoch: 6| Step: 2
Training loss: 2.4171511942646573
Validation loss: 2.5291542356668453

Epoch: 6| Step: 3
Training loss: 1.5779355379192819
Validation loss: 2.532882823120801

Epoch: 6| Step: 4
Training loss: 2.3294993190891295
Validation loss: 2.5310508743894418

Epoch: 6| Step: 5
Training loss: 1.9028753834152512
Validation loss: 2.5328357893923994

Epoch: 6| Step: 6
Training loss: 2.2381397888325627
Validation loss: 2.5116539171077115

Epoch: 6| Step: 7
Training loss: 2.5843977017310804
Validation loss: 2.5349642578529625

Epoch: 6| Step: 8
Training loss: 2.6425789369975194
Validation loss: 2.5126435360625297

Epoch: 6| Step: 9
Training loss: 2.5411644319537943
Validation loss: 2.5387254070604053

Epoch: 6| Step: 10
Training loss: 1.9102646498550828
Validation loss: 2.531576174846753

Epoch: 6| Step: 11
Training loss: 2.412459251573574
Validation loss: 2.539964298613146

Epoch: 6| Step: 12
Training loss: 2.431650625920699
Validation loss: 2.5452668743442834

Epoch: 6| Step: 13
Training loss: 2.192397602260805
Validation loss: 2.5841494829708953

Epoch: 267| Step: 0
Training loss: 2.283624223524702
Validation loss: 2.5476609871921756

Epoch: 6| Step: 1
Training loss: 2.1705579537873465
Validation loss: 2.5475072719481413

Epoch: 6| Step: 2
Training loss: 1.8012706563216532
Validation loss: 2.556640057700929

Epoch: 6| Step: 3
Training loss: 1.5951423546814274
Validation loss: 2.5425324502760205

Epoch: 6| Step: 4
Training loss: 2.3273459545584765
Validation loss: 2.566469436556668

Epoch: 6| Step: 5
Training loss: 2.363477260563332
Validation loss: 2.546272440583451

Epoch: 6| Step: 6
Training loss: 1.8015369476332546
Validation loss: 2.551728902585608

Epoch: 6| Step: 7
Training loss: 2.3268736478159684
Validation loss: 2.537244926749012

Epoch: 6| Step: 8
Training loss: 3.0254136362302737
Validation loss: 2.520231542924777

Epoch: 6| Step: 9
Training loss: 2.230825098436005
Validation loss: 2.524145257388233

Epoch: 6| Step: 10
Training loss: 1.5804997319019432
Validation loss: 2.559863199289235

Epoch: 6| Step: 11
Training loss: 2.175069312383372
Validation loss: 2.54205834909227

Epoch: 6| Step: 12
Training loss: 2.5951100655735986
Validation loss: 2.545485134838896

Epoch: 6| Step: 13
Training loss: 2.351656585534772
Validation loss: 2.5179501010363166

Epoch: 268| Step: 0
Training loss: 1.8431953630440387
Validation loss: 2.5103571925630286

Epoch: 6| Step: 1
Training loss: 1.9163561721522808
Validation loss: 2.518195345683373

Epoch: 6| Step: 2
Training loss: 2.325765348411482
Validation loss: 2.5176837465924176

Epoch: 6| Step: 3
Training loss: 1.8828925911105003
Validation loss: 2.5197730606315227

Epoch: 6| Step: 4
Training loss: 2.7242606428648584
Validation loss: 2.5145763162190002

Epoch: 6| Step: 5
Training loss: 1.9523205130279198
Validation loss: 2.502063273323782

Epoch: 6| Step: 6
Training loss: 2.2402310757999353
Validation loss: 2.514207634175341

Epoch: 6| Step: 7
Training loss: 2.5572907136396092
Validation loss: 2.5210261835990373

Epoch: 6| Step: 8
Training loss: 2.438892455835807
Validation loss: 2.5168781989504883

Epoch: 6| Step: 9
Training loss: 1.6930181914161657
Validation loss: 2.5525423895653434

Epoch: 6| Step: 10
Training loss: 2.0164443132546537
Validation loss: 2.575444463684664

Epoch: 6| Step: 11
Training loss: 2.983942609690207
Validation loss: 2.5956960218268748

Epoch: 6| Step: 12
Training loss: 2.197062924678107
Validation loss: 2.564572868253509

Epoch: 6| Step: 13
Training loss: 2.213562394587387
Validation loss: 2.5337801560155424

Epoch: 269| Step: 0
Training loss: 1.770157254878993
Validation loss: 2.523023620614849

Epoch: 6| Step: 1
Training loss: 1.7079819883964724
Validation loss: 2.5110315279554314

Epoch: 6| Step: 2
Training loss: 2.2774150438092744
Validation loss: 2.49345110804635

Epoch: 6| Step: 3
Training loss: 2.2986569920238167
Validation loss: 2.5042385886512033

Epoch: 6| Step: 4
Training loss: 2.5941001931445813
Validation loss: 2.494237090863833

Epoch: 6| Step: 5
Training loss: 2.008410413009493
Validation loss: 2.491997307961175

Epoch: 6| Step: 6
Training loss: 1.9882215329778463
Validation loss: 2.510409047812987

Epoch: 6| Step: 7
Training loss: 2.908177546689061
Validation loss: 2.5217556461545705

Epoch: 6| Step: 8
Training loss: 2.161625560741234
Validation loss: 2.5465992503288604

Epoch: 6| Step: 9
Training loss: 2.228097700938897
Validation loss: 2.5510114689560055

Epoch: 6| Step: 10
Training loss: 3.20163748091568
Validation loss: 2.560412122341145

Epoch: 6| Step: 11
Training loss: 1.4655032695003651
Validation loss: 2.5464024329622585

Epoch: 6| Step: 12
Training loss: 2.404985962824789
Validation loss: 2.559658351268526

Epoch: 6| Step: 13
Training loss: 2.101683659233999
Validation loss: 2.5551564508503075

Epoch: 270| Step: 0
Training loss: 2.052070604727008
Validation loss: 2.5535315679766644

Epoch: 6| Step: 1
Training loss: 1.9006129229888518
Validation loss: 2.505369206350187

Epoch: 6| Step: 2
Training loss: 1.9095557893612602
Validation loss: 2.500445882453547

Epoch: 6| Step: 3
Training loss: 1.8482824961920676
Validation loss: 2.482241228055161

Epoch: 6| Step: 4
Training loss: 2.1630942040967884
Validation loss: 2.4988822425069586

Epoch: 6| Step: 5
Training loss: 2.907367450451243
Validation loss: 2.5169714726248618

Epoch: 6| Step: 6
Training loss: 2.1484922089980323
Validation loss: 2.479573702589702

Epoch: 6| Step: 7
Training loss: 2.4027063607815533
Validation loss: 2.4942823831276613

Epoch: 6| Step: 8
Training loss: 1.8701855838708323
Validation loss: 2.5163446032949333

Epoch: 6| Step: 9
Training loss: 2.1709669671201035
Validation loss: 2.513812326233694

Epoch: 6| Step: 10
Training loss: 2.58307713089289
Validation loss: 2.5244276625600772

Epoch: 6| Step: 11
Training loss: 1.7013811055046464
Validation loss: 2.535918228536867

Epoch: 6| Step: 12
Training loss: 2.422328389706004
Validation loss: 2.5259510194434815

Epoch: 6| Step: 13
Training loss: 2.6794874822854853
Validation loss: 2.545387262597167

Epoch: 271| Step: 0
Training loss: 2.744404996579004
Validation loss: 2.5637296037065664

Epoch: 6| Step: 1
Training loss: 2.0785292612254724
Validation loss: 2.580140776526889

Epoch: 6| Step: 2
Training loss: 2.349952729743994
Validation loss: 2.561807182129728

Epoch: 6| Step: 3
Training loss: 1.7865928695630369
Validation loss: 2.576146100358529

Epoch: 6| Step: 4
Training loss: 2.1396874372444126
Validation loss: 2.57330023394267

Epoch: 6| Step: 5
Training loss: 2.259494669635088
Validation loss: 2.5541205754148186

Epoch: 6| Step: 6
Training loss: 2.739660332084796
Validation loss: 2.541822543341208

Epoch: 6| Step: 7
Training loss: 1.9887642564148682
Validation loss: 2.5237234168174396

Epoch: 6| Step: 8
Training loss: 2.602498020900593
Validation loss: 2.513781833886563

Epoch: 6| Step: 9
Training loss: 2.5883275537698562
Validation loss: 2.5007817794416307

Epoch: 6| Step: 10
Training loss: 1.9737578384987862
Validation loss: 2.5137113633767796

Epoch: 6| Step: 11
Training loss: 2.0436347765624823
Validation loss: 2.504957084719622

Epoch: 6| Step: 12
Training loss: 1.7366339604061396
Validation loss: 2.480493404235867

Epoch: 6| Step: 13
Training loss: 1.5433961686730764
Validation loss: 2.49213127144549

Epoch: 272| Step: 0
Training loss: 2.218489510732137
Validation loss: 2.515958688849136

Epoch: 6| Step: 1
Training loss: 2.7916748464284216
Validation loss: 2.500399954910087

Epoch: 6| Step: 2
Training loss: 1.8822121830512009
Validation loss: 2.517914403568984

Epoch: 6| Step: 3
Training loss: 1.9949543009330513
Validation loss: 2.5195800382242366

Epoch: 6| Step: 4
Training loss: 2.1697574968679896
Validation loss: 2.5507134218724823

Epoch: 6| Step: 5
Training loss: 2.3483060169278205
Validation loss: 2.5452277194196573

Epoch: 6| Step: 6
Training loss: 2.1235772025865836
Validation loss: 2.5252160732114057

Epoch: 6| Step: 7
Training loss: 1.9174906023931677
Validation loss: 2.5349352191169356

Epoch: 6| Step: 8
Training loss: 2.191825513800489
Validation loss: 2.5415040000600366

Epoch: 6| Step: 9
Training loss: 2.1654468061228624
Validation loss: 2.538034044953254

Epoch: 6| Step: 10
Training loss: 3.024714710244446
Validation loss: 2.501549193080604

Epoch: 6| Step: 11
Training loss: 2.0066617644156124
Validation loss: 2.510102633598094

Epoch: 6| Step: 12
Training loss: 1.5622607238665183
Validation loss: 2.496240347873987

Epoch: 6| Step: 13
Training loss: 2.173069906515553
Validation loss: 2.494508561308827

Epoch: 273| Step: 0
Training loss: 2.0828333699811257
Validation loss: 2.500888761850797

Epoch: 6| Step: 1
Training loss: 2.3964228913644128
Validation loss: 2.5349489194851254

Epoch: 6| Step: 2
Training loss: 2.1437991478627265
Validation loss: 2.5157859861305902

Epoch: 6| Step: 3
Training loss: 2.1861947661500776
Validation loss: 2.5610523631800013

Epoch: 6| Step: 4
Training loss: 1.7025051563873852
Validation loss: 2.5473466058182477

Epoch: 6| Step: 5
Training loss: 2.3863612030479278
Validation loss: 2.5459884317439414

Epoch: 6| Step: 6
Training loss: 2.3739921037370695
Validation loss: 2.5519050354209547

Epoch: 6| Step: 7
Training loss: 2.358160957084529
Validation loss: 2.536523012646024

Epoch: 6| Step: 8
Training loss: 2.2335860987102247
Validation loss: 2.5294986364538525

Epoch: 6| Step: 9
Training loss: 2.1685112901516415
Validation loss: 2.544289538426329

Epoch: 6| Step: 10
Training loss: 1.344348508040894
Validation loss: 2.524526843190127

Epoch: 6| Step: 11
Training loss: 2.3047921884326907
Validation loss: 2.5287838448688778

Epoch: 6| Step: 12
Training loss: 2.149055752662494
Validation loss: 2.518327213391842

Epoch: 6| Step: 13
Training loss: 2.45572849784726
Validation loss: 2.509169333308828

Epoch: 274| Step: 0
Training loss: 1.961723018324085
Validation loss: 2.5229337994607763

Epoch: 6| Step: 1
Training loss: 2.2628485142486894
Validation loss: 2.5264152224426977

Epoch: 6| Step: 2
Training loss: 2.128751024659247
Validation loss: 2.5039377671756196

Epoch: 6| Step: 3
Training loss: 1.9752674308020308
Validation loss: 2.4872535966913687

Epoch: 6| Step: 4
Training loss: 2.226252376977079
Validation loss: 2.491755289608927

Epoch: 6| Step: 5
Training loss: 2.564672712002438
Validation loss: 2.5076487993821392

Epoch: 6| Step: 6
Training loss: 1.9398275976165333
Validation loss: 2.4914103764248323

Epoch: 6| Step: 7
Training loss: 2.1694212300774467
Validation loss: 2.5102659367518725

Epoch: 6| Step: 8
Training loss: 2.357741542023976
Validation loss: 2.521421952266591

Epoch: 6| Step: 9
Training loss: 2.2525046501154007
Validation loss: 2.5011086548828434

Epoch: 6| Step: 10
Training loss: 2.3349931013507756
Validation loss: 2.498501026267609

Epoch: 6| Step: 11
Training loss: 1.8351625146024073
Validation loss: 2.505908706904926

Epoch: 6| Step: 12
Training loss: 2.4783720030479572
Validation loss: 2.510103108516038

Epoch: 6| Step: 13
Training loss: 2.0376466241981706
Validation loss: 2.5403582821990596

Epoch: 275| Step: 0
Training loss: 2.0551927764762663
Validation loss: 2.5323357157064788

Epoch: 6| Step: 1
Training loss: 2.256346546759763
Validation loss: 2.5614789463706695

Epoch: 6| Step: 2
Training loss: 1.7494807154096006
Validation loss: 2.583689424111951

Epoch: 6| Step: 3
Training loss: 2.4674581696927205
Validation loss: 2.613305107429753

Epoch: 6| Step: 4
Training loss: 1.7718109200006418
Validation loss: 2.5360767043464145

Epoch: 6| Step: 5
Training loss: 2.2907273419300513
Validation loss: 2.5680022983818027

Epoch: 6| Step: 6
Training loss: 2.2727780778581588
Validation loss: 2.54577706665527

Epoch: 6| Step: 7
Training loss: 1.9867336043126176
Validation loss: 2.5210345216864263

Epoch: 6| Step: 8
Training loss: 2.15089425851147
Validation loss: 2.522027896498925

Epoch: 6| Step: 9
Training loss: 1.6549699263130833
Validation loss: 2.503350404963928

Epoch: 6| Step: 10
Training loss: 2.2639221105757827
Validation loss: 2.491281621795776

Epoch: 6| Step: 11
Training loss: 2.8006671791841975
Validation loss: 2.4873469428636974

Epoch: 6| Step: 12
Training loss: 2.7006235179795532
Validation loss: 2.468212648652935

Epoch: 6| Step: 13
Training loss: 2.029775818157946
Validation loss: 2.455652364512182

Epoch: 276| Step: 0
Training loss: 2.0741790940109253
Validation loss: 2.4570554763416297

Epoch: 6| Step: 1
Training loss: 2.487476643975032
Validation loss: 2.46463418060588

Epoch: 6| Step: 2
Training loss: 1.9177090533115486
Validation loss: 2.4722458597784343

Epoch: 6| Step: 3
Training loss: 2.7951056995093126
Validation loss: 2.4759626975898414

Epoch: 6| Step: 4
Training loss: 1.7783967975254713
Validation loss: 2.4702041303014366

Epoch: 6| Step: 5
Training loss: 2.1386144621645906
Validation loss: 2.4591814587840966

Epoch: 6| Step: 6
Training loss: 2.3178892486484863
Validation loss: 2.47385874229883

Epoch: 6| Step: 7
Training loss: 2.299004845320817
Validation loss: 2.4763150577898623

Epoch: 6| Step: 8
Training loss: 1.5360517923047314
Validation loss: 2.4842807583958066

Epoch: 6| Step: 9
Training loss: 2.6139032966395965
Validation loss: 2.4757388055817886

Epoch: 6| Step: 10
Training loss: 1.8608595107077022
Validation loss: 2.4753660727634683

Epoch: 6| Step: 11
Training loss: 2.3222272274606275
Validation loss: 2.4791143048524296

Epoch: 6| Step: 12
Training loss: 1.7921216372266606
Validation loss: 2.481625809223213

Epoch: 6| Step: 13
Training loss: 2.931198015545086
Validation loss: 2.4651923399135933

Epoch: 277| Step: 0
Training loss: 2.3452998822385536
Validation loss: 2.518427470518152

Epoch: 6| Step: 1
Training loss: 1.9347079062983852
Validation loss: 2.494277388751999

Epoch: 6| Step: 2
Training loss: 2.352581019045226
Validation loss: 2.513326246186677

Epoch: 6| Step: 3
Training loss: 2.6673907747224557
Validation loss: 2.516563580045899

Epoch: 6| Step: 4
Training loss: 1.657231310071647
Validation loss: 2.5166594074683517

Epoch: 6| Step: 5
Training loss: 2.506136991088681
Validation loss: 2.5243257075477117

Epoch: 6| Step: 6
Training loss: 1.9273496976404227
Validation loss: 2.515082654283676

Epoch: 6| Step: 7
Training loss: 2.328713157145319
Validation loss: 2.501585251154504

Epoch: 6| Step: 8
Training loss: 1.8474262892868405
Validation loss: 2.5329403354923428

Epoch: 6| Step: 9
Training loss: 1.9364373769407655
Validation loss: 2.5521843922646226

Epoch: 6| Step: 10
Training loss: 2.9872633453231945
Validation loss: 2.53923199992629

Epoch: 6| Step: 11
Training loss: 1.9563779063959696
Validation loss: 2.570869617319456

Epoch: 6| Step: 12
Training loss: 1.7486826843219405
Validation loss: 2.552243151169506

Epoch: 6| Step: 13
Training loss: 2.3283394324355453
Validation loss: 2.571781314643753

Epoch: 278| Step: 0
Training loss: 2.3852984358848817
Validation loss: 2.5597034484244734

Epoch: 6| Step: 1
Training loss: 1.9746100390817072
Validation loss: 2.580346154443962

Epoch: 6| Step: 2
Training loss: 1.7425280866726418
Validation loss: 2.556008669055969

Epoch: 6| Step: 3
Training loss: 2.2629525042988963
Validation loss: 2.5330097533503966

Epoch: 6| Step: 4
Training loss: 2.0186109087477773
Validation loss: 2.544768696974217

Epoch: 6| Step: 5
Training loss: 2.658267522812434
Validation loss: 2.5226510537839166

Epoch: 6| Step: 6
Training loss: 2.0198137391963007
Validation loss: 2.502993142936886

Epoch: 6| Step: 7
Training loss: 2.2739953474200183
Validation loss: 2.503812529287307

Epoch: 6| Step: 8
Training loss: 2.027930261229212
Validation loss: 2.487712018483847

Epoch: 6| Step: 9
Training loss: 2.4703941182135694
Validation loss: 2.526518351354536

Epoch: 6| Step: 10
Training loss: 1.873872799606207
Validation loss: 2.5355351757061153

Epoch: 6| Step: 11
Training loss: 2.4820797472122034
Validation loss: 2.5529481214110183

Epoch: 6| Step: 12
Training loss: 1.987866791282256
Validation loss: 2.548502559989136

Epoch: 6| Step: 13
Training loss: 2.2808302401697187
Validation loss: 2.5511383694603977

Epoch: 279| Step: 0
Training loss: 2.621924096831077
Validation loss: 2.542537201390755

Epoch: 6| Step: 1
Training loss: 2.3804070009310987
Validation loss: 2.5243993290189004

Epoch: 6| Step: 2
Training loss: 1.989681148288247
Validation loss: 2.5247963631225825

Epoch: 6| Step: 3
Training loss: 2.4954380374064904
Validation loss: 2.5200186955298376

Epoch: 6| Step: 4
Training loss: 1.6112292080196897
Validation loss: 2.5328820073330887

Epoch: 6| Step: 5
Training loss: 2.251808605205229
Validation loss: 2.5349951145744525

Epoch: 6| Step: 6
Training loss: 1.6418144637188354
Validation loss: 2.5399806157571434

Epoch: 6| Step: 7
Training loss: 2.3603852995235823
Validation loss: 2.5635756119257147

Epoch: 6| Step: 8
Training loss: 1.9299156270336981
Validation loss: 2.5545171978383348

Epoch: 6| Step: 9
Training loss: 2.1185160054765233
Validation loss: 2.5501750948262463

Epoch: 6| Step: 10
Training loss: 2.2787606230387203
Validation loss: 2.543625019824153

Epoch: 6| Step: 11
Training loss: 1.6617934826688086
Validation loss: 2.5196692456052525

Epoch: 6| Step: 12
Training loss: 1.7748204691183045
Validation loss: 2.5079138904646374

Epoch: 6| Step: 13
Training loss: 2.892326555252999
Validation loss: 2.4787811866500196

Epoch: 280| Step: 0
Training loss: 2.1617373979575483
Validation loss: 2.4929534707616807

Epoch: 6| Step: 1
Training loss: 1.7340604479680146
Validation loss: 2.5028870284123554

Epoch: 6| Step: 2
Training loss: 2.048811135162516
Validation loss: 2.5112026509007572

Epoch: 6| Step: 3
Training loss: 2.1051392023085294
Validation loss: 2.5227499104795514

Epoch: 6| Step: 4
Training loss: 2.3364477716604894
Validation loss: 2.510223734764054

Epoch: 6| Step: 5
Training loss: 2.957560281534206
Validation loss: 2.5186889659974163

Epoch: 6| Step: 6
Training loss: 1.9034705614078622
Validation loss: 2.5267224105718173

Epoch: 6| Step: 7
Training loss: 2.2415479219697305
Validation loss: 2.5448202726234803

Epoch: 6| Step: 8
Training loss: 1.8421361293214507
Validation loss: 2.5411942126268805

Epoch: 6| Step: 9
Training loss: 1.713188049870758
Validation loss: 2.5353326251212627

Epoch: 6| Step: 10
Training loss: 2.599675040845137
Validation loss: 2.565312725954235

Epoch: 6| Step: 11
Training loss: 1.9913606012139997
Validation loss: 2.578544335989706

Epoch: 6| Step: 12
Training loss: 2.4550035415282023
Validation loss: 2.5446081234020204

Epoch: 6| Step: 13
Training loss: 2.5134555157408602
Validation loss: 2.5462956461921658

Epoch: 281| Step: 0
Training loss: 1.8746183006867434
Validation loss: 2.509269219968242

Epoch: 6| Step: 1
Training loss: 2.119471820317303
Validation loss: 2.4970166366312174

Epoch: 6| Step: 2
Training loss: 1.7264964923927963
Validation loss: 2.496405926735604

Epoch: 6| Step: 3
Training loss: 2.597946632618272
Validation loss: 2.4965754498378154

Epoch: 6| Step: 4
Training loss: 2.3746230177590184
Validation loss: 2.498241362309259

Epoch: 6| Step: 5
Training loss: 1.9957559975418446
Validation loss: 2.511155464287977

Epoch: 6| Step: 6
Training loss: 2.632108147013892
Validation loss: 2.506796087194213

Epoch: 6| Step: 7
Training loss: 1.3600967069911478
Validation loss: 2.552188642755437

Epoch: 6| Step: 8
Training loss: 2.0039264759730973
Validation loss: 2.5482231269825872

Epoch: 6| Step: 9
Training loss: 2.1983441363520626
Validation loss: 2.5647986731982115

Epoch: 6| Step: 10
Training loss: 2.3265797652198956
Validation loss: 2.551308320889829

Epoch: 6| Step: 11
Training loss: 2.707655709421968
Validation loss: 2.5734299033291608

Epoch: 6| Step: 12
Training loss: 2.434660406851825
Validation loss: 2.5680167507524523

Epoch: 6| Step: 13
Training loss: 2.095833609892547
Validation loss: 2.5629425597078006

Epoch: 282| Step: 0
Training loss: 2.69586105293122
Validation loss: 2.544079406679605

Epoch: 6| Step: 1
Training loss: 2.551159957649971
Validation loss: 2.5369993307844276

Epoch: 6| Step: 2
Training loss: 2.3929191003842747
Validation loss: 2.542544593732541

Epoch: 6| Step: 3
Training loss: 1.8939814133462218
Validation loss: 2.5241613304591413

Epoch: 6| Step: 4
Training loss: 2.283756394651383
Validation loss: 2.505532643560443

Epoch: 6| Step: 5
Training loss: 1.7095588459688074
Validation loss: 2.4758236622329908

Epoch: 6| Step: 6
Training loss: 2.2285280352689063
Validation loss: 2.459709967389971

Epoch: 6| Step: 7
Training loss: 2.3655212379587476
Validation loss: 2.4384766602735763

Epoch: 6| Step: 8
Training loss: 2.246107655357772
Validation loss: 2.4245930585869933

Epoch: 6| Step: 9
Training loss: 1.8302906609134857
Validation loss: 2.42276797495741

Epoch: 6| Step: 10
Training loss: 1.720392309515163
Validation loss: 2.4283917765325285

Epoch: 6| Step: 11
Training loss: 1.8892904568457358
Validation loss: 2.459537572144753

Epoch: 6| Step: 12
Training loss: 2.5190234241736706
Validation loss: 2.4704845789170906

Epoch: 6| Step: 13
Training loss: 1.9526365966491586
Validation loss: 2.4671359600589002

Epoch: 283| Step: 0
Training loss: 1.9141370486319507
Validation loss: 2.491717430754366

Epoch: 6| Step: 1
Training loss: 1.481191574425238
Validation loss: 2.5107025891167027

Epoch: 6| Step: 2
Training loss: 2.3776122333658565
Validation loss: 2.5241968451285146

Epoch: 6| Step: 3
Training loss: 2.3329182891467606
Validation loss: 2.515681311567471

Epoch: 6| Step: 4
Training loss: 2.037011060966533
Validation loss: 2.52144691524165

Epoch: 6| Step: 5
Training loss: 2.0293720660997616
Validation loss: 2.511817783837691

Epoch: 6| Step: 6
Training loss: 1.9684691455875367
Validation loss: 2.5273540482859076

Epoch: 6| Step: 7
Training loss: 2.2564600289352827
Validation loss: 2.557456146565296

Epoch: 6| Step: 8
Training loss: 2.2702429701048623
Validation loss: 2.521907882129411

Epoch: 6| Step: 9
Training loss: 2.2825057871349292
Validation loss: 2.5269201946722237

Epoch: 6| Step: 10
Training loss: 2.3886626922605587
Validation loss: 2.503408095804925

Epoch: 6| Step: 11
Training loss: 2.030131574980045
Validation loss: 2.533834887931434

Epoch: 6| Step: 12
Training loss: 1.9158578354688895
Validation loss: 2.5447787217508284

Epoch: 6| Step: 13
Training loss: 2.4853626902992536
Validation loss: 2.552605156521131

Epoch: 284| Step: 0
Training loss: 1.3810530422860683
Validation loss: 2.539437353389037

Epoch: 6| Step: 1
Training loss: 2.381877578177417
Validation loss: 2.5403359608852063

Epoch: 6| Step: 2
Training loss: 2.5579139796535633
Validation loss: 2.5220989066445156

Epoch: 6| Step: 3
Training loss: 1.8994408612947207
Validation loss: 2.512273415744015

Epoch: 6| Step: 4
Training loss: 1.4414072424412234
Validation loss: 2.5211082707899015

Epoch: 6| Step: 5
Training loss: 1.855426924384673
Validation loss: 2.5256836837424186

Epoch: 6| Step: 6
Training loss: 2.262547685320871
Validation loss: 2.4863079237036096

Epoch: 6| Step: 7
Training loss: 2.2571048881689766
Validation loss: 2.498429265902344

Epoch: 6| Step: 8
Training loss: 2.2127979659826233
Validation loss: 2.5224012091389874

Epoch: 6| Step: 9
Training loss: 3.0829139286762413
Validation loss: 2.5260056063775322

Epoch: 6| Step: 10
Training loss: 2.434839410519119
Validation loss: 2.5572186140411173

Epoch: 6| Step: 11
Training loss: 2.085829371246505
Validation loss: 2.5480599874349816

Epoch: 6| Step: 12
Training loss: 1.8123762154238647
Validation loss: 2.557569148178249

Epoch: 6| Step: 13
Training loss: 1.9474252771187237
Validation loss: 2.556727645632568

Epoch: 285| Step: 0
Training loss: 2.4152006657478498
Validation loss: 2.5174018160865104

Epoch: 6| Step: 1
Training loss: 1.546511983179384
Validation loss: 2.4880269717648584

Epoch: 6| Step: 2
Training loss: 2.349318133511051
Validation loss: 2.487108226576346

Epoch: 6| Step: 3
Training loss: 2.540172721517015
Validation loss: 2.515084439598752

Epoch: 6| Step: 4
Training loss: 1.9010411998452088
Validation loss: 2.484270313544454

Epoch: 6| Step: 5
Training loss: 2.2347714799291856
Validation loss: 2.5108753487048707

Epoch: 6| Step: 6
Training loss: 2.5406714403475807
Validation loss: 2.52286547465302

Epoch: 6| Step: 7
Training loss: 2.346389301698879
Validation loss: 2.5307893765647145

Epoch: 6| Step: 8
Training loss: 1.9666860751902344
Validation loss: 2.52739506806477

Epoch: 6| Step: 9
Training loss: 2.110857407344377
Validation loss: 2.5094786087759045

Epoch: 6| Step: 10
Training loss: 1.9268403458549197
Validation loss: 2.536065532706047

Epoch: 6| Step: 11
Training loss: 2.2192214679815523
Validation loss: 2.519945009151296

Epoch: 6| Step: 12
Training loss: 1.9364519668756257
Validation loss: 2.484375847710359

Epoch: 6| Step: 13
Training loss: 2.3091784154821835
Validation loss: 2.5026696415227905

Epoch: 286| Step: 0
Training loss: 1.977268379429867
Validation loss: 2.502556026655992

Epoch: 6| Step: 1
Training loss: 2.4328652358418505
Validation loss: 2.511312891956023

Epoch: 6| Step: 2
Training loss: 2.374281724431668
Validation loss: 2.496547906399791

Epoch: 6| Step: 3
Training loss: 1.7570108577889971
Validation loss: 2.500976864378927

Epoch: 6| Step: 4
Training loss: 1.9321466136137349
Validation loss: 2.495142461421042

Epoch: 6| Step: 5
Training loss: 2.3473808139692665
Validation loss: 2.509305293792373

Epoch: 6| Step: 6
Training loss: 1.7230240824871155
Validation loss: 2.495594927992479

Epoch: 6| Step: 7
Training loss: 2.1873870820465457
Validation loss: 2.518110370430954

Epoch: 6| Step: 8
Training loss: 2.0186390187844827
Validation loss: 2.4877276560826798

Epoch: 6| Step: 9
Training loss: 1.7989194434696116
Validation loss: 2.531669150291197

Epoch: 6| Step: 10
Training loss: 2.417730415196282
Validation loss: 2.547588833428981

Epoch: 6| Step: 11
Training loss: 2.3286272569662123
Validation loss: 2.560123101071146

Epoch: 6| Step: 12
Training loss: 2.2229009134961286
Validation loss: 2.5540509689869197

Epoch: 6| Step: 13
Training loss: 2.0894004850804557
Validation loss: 2.5796222539114053

Epoch: 287| Step: 0
Training loss: 1.751601916506865
Validation loss: 2.5943803595751986

Epoch: 6| Step: 1
Training loss: 2.7060108986611815
Validation loss: 2.6079391975930895

Epoch: 6| Step: 2
Training loss: 1.8193604431303843
Validation loss: 2.625399029391042

Epoch: 6| Step: 3
Training loss: 1.4791201284188595
Validation loss: 2.670325084379099

Epoch: 6| Step: 4
Training loss: 2.7322477076595275
Validation loss: 2.669434948349795

Epoch: 6| Step: 5
Training loss: 2.295026905010148
Validation loss: 2.604227879122705

Epoch: 6| Step: 6
Training loss: 2.4683797051579095
Validation loss: 2.5248132504435805

Epoch: 6| Step: 7
Training loss: 2.175371278665489
Validation loss: 2.4799200777793744

Epoch: 6| Step: 8
Training loss: 1.57201198640772
Validation loss: 2.4786340210765343

Epoch: 6| Step: 9
Training loss: 2.437809459898077
Validation loss: 2.4835168968006305

Epoch: 6| Step: 10
Training loss: 2.2359963250036183
Validation loss: 2.4800101509578676

Epoch: 6| Step: 11
Training loss: 1.3678455621925627
Validation loss: 2.4586906146538516

Epoch: 6| Step: 12
Training loss: 2.068287445633143
Validation loss: 2.4696387288785706

Epoch: 6| Step: 13
Training loss: 2.461344367407922
Validation loss: 2.474167348498204

Epoch: 288| Step: 0
Training loss: 1.5912363013122122
Validation loss: 2.4762546576620297

Epoch: 6| Step: 1
Training loss: 2.2236589740995045
Validation loss: 2.4889353277234636

Epoch: 6| Step: 2
Training loss: 1.973040492338809
Validation loss: 2.496845193938848

Epoch: 6| Step: 3
Training loss: 2.9771109648895564
Validation loss: 2.5382304701456895

Epoch: 6| Step: 4
Training loss: 2.325314047328053
Validation loss: 2.51417491812443

Epoch: 6| Step: 5
Training loss: 2.5807797721779573
Validation loss: 2.5197934824976556

Epoch: 6| Step: 6
Training loss: 2.183799884053882
Validation loss: 2.521449878002586

Epoch: 6| Step: 7
Training loss: 2.034582837060663
Validation loss: 2.5228418645209447

Epoch: 6| Step: 8
Training loss: 1.9744670148747405
Validation loss: 2.5290345751871532

Epoch: 6| Step: 9
Training loss: 1.5399424559505983
Validation loss: 2.5039418615227933

Epoch: 6| Step: 10
Training loss: 2.114397638996378
Validation loss: 2.5022606006836954

Epoch: 6| Step: 11
Training loss: 2.3220440604065287
Validation loss: 2.5163241850214653

Epoch: 6| Step: 12
Training loss: 1.9794829132660765
Validation loss: 2.48959033491568

Epoch: 6| Step: 13
Training loss: 2.2051025605516106
Validation loss: 2.4888631398802885

Epoch: 289| Step: 0
Training loss: 2.23698411673789
Validation loss: 2.4823237654104293

Epoch: 6| Step: 1
Training loss: 2.7318628596880674
Validation loss: 2.4716262158483295

Epoch: 6| Step: 2
Training loss: 2.0899484768590093
Validation loss: 2.4464916112399804

Epoch: 6| Step: 3
Training loss: 1.8886279443249168
Validation loss: 2.4900138408271104

Epoch: 6| Step: 4
Training loss: 2.1277374138695713
Validation loss: 2.4994539141281855

Epoch: 6| Step: 5
Training loss: 2.2697797891960514
Validation loss: 2.4897825461985508

Epoch: 6| Step: 6
Training loss: 2.3268493639455685
Validation loss: 2.4802605969656644

Epoch: 6| Step: 7
Training loss: 2.051795694036899
Validation loss: 2.483293613867185

Epoch: 6| Step: 8
Training loss: 1.9906338486407409
Validation loss: 2.4717220009877385

Epoch: 6| Step: 9
Training loss: 2.2168319363279076
Validation loss: 2.5011320570997855

Epoch: 6| Step: 10
Training loss: 1.7191292777767198
Validation loss: 2.4781450255564184

Epoch: 6| Step: 11
Training loss: 2.527384125329542
Validation loss: 2.4862165683233037

Epoch: 6| Step: 12
Training loss: 1.9985213774376893
Validation loss: 2.4928773983410797

Epoch: 6| Step: 13
Training loss: 1.8129198969142468
Validation loss: 2.4942018505877224

Epoch: 290| Step: 0
Training loss: 1.4980822861128043
Validation loss: 2.5291735212766295

Epoch: 6| Step: 1
Training loss: 2.8533231133726584
Validation loss: 2.5471239494864086

Epoch: 6| Step: 2
Training loss: 2.2325861245488006
Validation loss: 2.562359177976628

Epoch: 6| Step: 3
Training loss: 1.844273121216619
Validation loss: 2.54417674353668

Epoch: 6| Step: 4
Training loss: 2.388964506426135
Validation loss: 2.592569120681819

Epoch: 6| Step: 5
Training loss: 2.0037249209809116
Validation loss: 2.573833400072296

Epoch: 6| Step: 6
Training loss: 2.6442472454704804
Validation loss: 2.544924217100083

Epoch: 6| Step: 7
Training loss: 1.9853019651868713
Validation loss: 2.516662352181414

Epoch: 6| Step: 8
Training loss: 2.1586065269199763
Validation loss: 2.475111270419831

Epoch: 6| Step: 9
Training loss: 2.087554876097338
Validation loss: 2.4530380136411276

Epoch: 6| Step: 10
Training loss: 2.0939342360785766
Validation loss: 2.4604573745223943

Epoch: 6| Step: 11
Training loss: 2.0823060618353515
Validation loss: 2.4689083611925726

Epoch: 6| Step: 12
Training loss: 1.6011258158000077
Validation loss: 2.482007215890019

Epoch: 6| Step: 13
Training loss: 2.2181240864502203
Validation loss: 2.4815660747801283

Epoch: 291| Step: 0
Training loss: 2.8745511575374345
Validation loss: 2.502295711587007

Epoch: 6| Step: 1
Training loss: 2.5337475358586876
Validation loss: 2.5142797818361617

Epoch: 6| Step: 2
Training loss: 1.7049491282953497
Validation loss: 2.5052514710284495

Epoch: 6| Step: 3
Training loss: 1.9830933885191844
Validation loss: 2.5254128974626697

Epoch: 6| Step: 4
Training loss: 1.985562607430633
Validation loss: 2.5260835362271137

Epoch: 6| Step: 5
Training loss: 1.7979368969724703
Validation loss: 2.5440933545675883

Epoch: 6| Step: 6
Training loss: 2.2467899736172217
Validation loss: 2.572940955002362

Epoch: 6| Step: 7
Training loss: 2.2765565430950074
Validation loss: 2.5747004952056276

Epoch: 6| Step: 8
Training loss: 2.490824168054287
Validation loss: 2.580048346510058

Epoch: 6| Step: 9
Training loss: 1.9934453247127242
Validation loss: 2.571157731950802

Epoch: 6| Step: 10
Training loss: 2.461084173766466
Validation loss: 2.571522235741342

Epoch: 6| Step: 11
Training loss: 1.4722546907759264
Validation loss: 2.5847045171742695

Epoch: 6| Step: 12
Training loss: 1.6745977601987065
Validation loss: 2.5044567913334763

Epoch: 6| Step: 13
Training loss: 2.2179609158153513
Validation loss: 2.476111851394121

Epoch: 292| Step: 0
Training loss: 1.9003912522882445
Validation loss: 2.4871805212718034

Epoch: 6| Step: 1
Training loss: 2.1067805405916915
Validation loss: 2.46004195292554

Epoch: 6| Step: 2
Training loss: 1.6761571644813364
Validation loss: 2.451154269576964

Epoch: 6| Step: 3
Training loss: 2.0691106798778836
Validation loss: 2.4384267707969007

Epoch: 6| Step: 4
Training loss: 2.1457029383277497
Validation loss: 2.457180857588967

Epoch: 6| Step: 5
Training loss: 2.4361164372307513
Validation loss: 2.4598797497912424

Epoch: 6| Step: 6
Training loss: 2.458173574224246
Validation loss: 2.4705281674405057

Epoch: 6| Step: 7
Training loss: 1.7561947986982342
Validation loss: 2.4852131483385413

Epoch: 6| Step: 8
Training loss: 1.8263321913253594
Validation loss: 2.4990488309217285

Epoch: 6| Step: 9
Training loss: 1.7749635289703292
Validation loss: 2.5331971328495855

Epoch: 6| Step: 10
Training loss: 1.9081708266961765
Validation loss: 2.528700474712789

Epoch: 6| Step: 11
Training loss: 2.91505901898529
Validation loss: 2.5388384597921223

Epoch: 6| Step: 12
Training loss: 2.1511102870189953
Validation loss: 2.538408024875184

Epoch: 6| Step: 13
Training loss: 2.3829009493061397
Validation loss: 2.5661675793641456

Epoch: 293| Step: 0
Training loss: 1.7031483079907752
Validation loss: 2.5701647931513403

Epoch: 6| Step: 1
Training loss: 1.9734929189504231
Validation loss: 2.5559821003230905

Epoch: 6| Step: 2
Training loss: 1.749694116289997
Validation loss: 2.5580608327376244

Epoch: 6| Step: 3
Training loss: 2.335758266143234
Validation loss: 2.5966625177189493

Epoch: 6| Step: 4
Training loss: 2.727546929533499
Validation loss: 2.593675129740547

Epoch: 6| Step: 5
Training loss: 2.3256312590066064
Validation loss: 2.5681971432271316

Epoch: 6| Step: 6
Training loss: 2.3364259343162175
Validation loss: 2.5453607625271033

Epoch: 6| Step: 7
Training loss: 2.2770927905985405
Validation loss: 2.5058695712914067

Epoch: 6| Step: 8
Training loss: 2.245339334920865
Validation loss: 2.4900506563919356

Epoch: 6| Step: 9
Training loss: 1.970735487279961
Validation loss: 2.462435021487143

Epoch: 6| Step: 10
Training loss: 1.929712457534077
Validation loss: 2.468558195365021

Epoch: 6| Step: 11
Training loss: 1.7312708388633995
Validation loss: 2.4418288045783076

Epoch: 6| Step: 12
Training loss: 2.0947122213232854
Validation loss: 2.4631604766033153

Epoch: 6| Step: 13
Training loss: 2.4568342605974482
Validation loss: 2.4681408931490623

Epoch: 294| Step: 0
Training loss: 2.0024827805444305
Validation loss: 2.481430788284145

Epoch: 6| Step: 1
Training loss: 2.218907847632569
Validation loss: 2.4748569395802966

Epoch: 6| Step: 2
Training loss: 2.0627136119850373
Validation loss: 2.48416202360033

Epoch: 6| Step: 3
Training loss: 2.032700710169607
Validation loss: 2.548228896674513

Epoch: 6| Step: 4
Training loss: 2.3048126703959424
Validation loss: 2.5435702486130225

Epoch: 6| Step: 5
Training loss: 2.4260216438730566
Validation loss: 2.556916985705947

Epoch: 6| Step: 6
Training loss: 1.5543621240319523
Validation loss: 2.560143783115256

Epoch: 6| Step: 7
Training loss: 1.8703189910291629
Validation loss: 2.563872876730923

Epoch: 6| Step: 8
Training loss: 2.391110838346848
Validation loss: 2.568053608571478

Epoch: 6| Step: 9
Training loss: 1.8703411077798868
Validation loss: 2.5741353308475725

Epoch: 6| Step: 10
Training loss: 2.5584987011209708
Validation loss: 2.570389148377079

Epoch: 6| Step: 11
Training loss: 2.418645465178902
Validation loss: 2.603396238168628

Epoch: 6| Step: 12
Training loss: 1.9635493297747793
Validation loss: 2.5676963733655063

Epoch: 6| Step: 13
Training loss: 1.691211222269616
Validation loss: 2.5463614540882715

Epoch: 295| Step: 0
Training loss: 1.5983301807222643
Validation loss: 2.5267472740021

Epoch: 6| Step: 1
Training loss: 1.6850443739665517
Validation loss: 2.521341971373357

Epoch: 6| Step: 2
Training loss: 2.537928777087643
Validation loss: 2.5003849527892315

Epoch: 6| Step: 3
Training loss: 1.8749423971864667
Validation loss: 2.4617278429495184

Epoch: 6| Step: 4
Training loss: 2.2096818249575225
Validation loss: 2.462122911217021

Epoch: 6| Step: 5
Training loss: 2.361434643837919
Validation loss: 2.4739522887038956

Epoch: 6| Step: 6
Training loss: 2.070228315837073
Validation loss: 2.447992645599604

Epoch: 6| Step: 7
Training loss: 2.252334866752665
Validation loss: 2.4510570646149015

Epoch: 6| Step: 8
Training loss: 2.2001309442565002
Validation loss: 2.4549230639385797

Epoch: 6| Step: 9
Training loss: 2.3171179773212227
Validation loss: 2.466200336846294

Epoch: 6| Step: 10
Training loss: 1.7076346511584843
Validation loss: 2.4776012676982

Epoch: 6| Step: 11
Training loss: 1.8164677435197358
Validation loss: 2.4729263616134567

Epoch: 6| Step: 12
Training loss: 1.8163131854099106
Validation loss: 2.4791426510542562

Epoch: 6| Step: 13
Training loss: 2.481101896924994
Validation loss: 2.4596418976719403

Epoch: 296| Step: 0
Training loss: 2.0347225144364023
Validation loss: 2.4841140354096036

Epoch: 6| Step: 1
Training loss: 2.650795665986211
Validation loss: 2.532775795804185

Epoch: 6| Step: 2
Training loss: 1.6116971050071953
Validation loss: 2.5415087843673168

Epoch: 6| Step: 3
Training loss: 2.370127749802639
Validation loss: 2.545018195990946

Epoch: 6| Step: 4
Training loss: 1.9289341741852788
Validation loss: 2.5705838354914072

Epoch: 6| Step: 5
Training loss: 2.022869133382641
Validation loss: 2.5756217594769684

Epoch: 6| Step: 6
Training loss: 2.3732045062422427
Validation loss: 2.5978638224260715

Epoch: 6| Step: 7
Training loss: 2.25506762857801
Validation loss: 2.579219639675281

Epoch: 6| Step: 8
Training loss: 1.984619966540339
Validation loss: 2.5340983922287785

Epoch: 6| Step: 9
Training loss: 2.1717026456876227
Validation loss: 2.516870810163667

Epoch: 6| Step: 10
Training loss: 2.0178751842208276
Validation loss: 2.5276436094744708

Epoch: 6| Step: 11
Training loss: 1.6606763316796787
Validation loss: 2.500362274624222

Epoch: 6| Step: 12
Training loss: 1.488527773166506
Validation loss: 2.5011885678641184

Epoch: 6| Step: 13
Training loss: 2.588147466617766
Validation loss: 2.495595198677141

Epoch: 297| Step: 0
Training loss: 2.7803862870055056
Validation loss: 2.5002019164878737

Epoch: 6| Step: 1
Training loss: 1.6576864383381864
Validation loss: 2.494503718717149

Epoch: 6| Step: 2
Training loss: 2.093609477779172
Validation loss: 2.48890480999547

Epoch: 6| Step: 3
Training loss: 2.623613627225972
Validation loss: 2.4794773793989675

Epoch: 6| Step: 4
Training loss: 2.1793306667062233
Validation loss: 2.492601509743776

Epoch: 6| Step: 5
Training loss: 1.9427045015871716
Validation loss: 2.493180622185792

Epoch: 6| Step: 6
Training loss: 2.3398653516584242
Validation loss: 2.4901491636769153

Epoch: 6| Step: 7
Training loss: 2.094525207943367
Validation loss: 2.493043806236678

Epoch: 6| Step: 8
Training loss: 2.0805924760196386
Validation loss: 2.5045542084400836

Epoch: 6| Step: 9
Training loss: 2.07206036182984
Validation loss: 2.5080258129186785

Epoch: 6| Step: 10
Training loss: 1.717809523853474
Validation loss: 2.516700798923197

Epoch: 6| Step: 11
Training loss: 2.259285733265302
Validation loss: 2.5143356178051133

Epoch: 6| Step: 12
Training loss: 1.7895519136891027
Validation loss: 2.4731377187611834

Epoch: 6| Step: 13
Training loss: 2.1169137249837693
Validation loss: 2.508113347880483

Epoch: 298| Step: 0
Training loss: 2.5712082064527904
Validation loss: 2.485109664446779

Epoch: 6| Step: 1
Training loss: 2.394390257625216
Validation loss: 2.482593369381572

Epoch: 6| Step: 2
Training loss: 1.805745264830092
Validation loss: 2.493835900595143

Epoch: 6| Step: 3
Training loss: 1.8837018583609846
Validation loss: 2.4868981765954317

Epoch: 6| Step: 4
Training loss: 1.8356003472007612
Validation loss: 2.5240166533928843

Epoch: 6| Step: 5
Training loss: 1.4338025349019252
Validation loss: 2.537431539354272

Epoch: 6| Step: 6
Training loss: 2.10515958819864
Validation loss: 2.512657231461011

Epoch: 6| Step: 7
Training loss: 1.465006013148339
Validation loss: 2.5267143743317226

Epoch: 6| Step: 8
Training loss: 2.1793963056638215
Validation loss: 2.5511725428883167

Epoch: 6| Step: 9
Training loss: 1.9329206431795356
Validation loss: 2.5372809552013234

Epoch: 6| Step: 10
Training loss: 2.2423342347729007
Validation loss: 2.5492294287918233

Epoch: 6| Step: 11
Training loss: 2.0794798371166894
Validation loss: 2.5317564249691396

Epoch: 6| Step: 12
Training loss: 1.6992621054544372
Validation loss: 2.5326135361512425

Epoch: 6| Step: 13
Training loss: 2.777599381970192
Validation loss: 2.531256404915701

Epoch: 299| Step: 0
Training loss: 2.1584412870571326
Validation loss: 2.5003761485365623

Epoch: 6| Step: 1
Training loss: 1.9931468374133208
Validation loss: 2.540797887646424

Epoch: 6| Step: 2
Training loss: 2.1095139069208413
Validation loss: 2.5759927968409233

Epoch: 6| Step: 3
Training loss: 2.3462839288956263
Validation loss: 2.5862136493609316

Epoch: 6| Step: 4
Training loss: 2.085741355332145
Validation loss: 2.583770673915497

Epoch: 6| Step: 5
Training loss: 2.0066239813555677
Validation loss: 2.5742938311003165

Epoch: 6| Step: 6
Training loss: 2.3340419873904086
Validation loss: 2.5537465469279743

Epoch: 6| Step: 7
Training loss: 1.7184934251186135
Validation loss: 2.5044911574750035

Epoch: 6| Step: 8
Training loss: 2.5312123236972277
Validation loss: 2.4647241272189238

Epoch: 6| Step: 9
Training loss: 1.3862032079753925
Validation loss: 2.474038852920584

Epoch: 6| Step: 10
Training loss: 1.7905441878426076
Validation loss: 2.461628908587926

Epoch: 6| Step: 11
Training loss: 2.195777056538082
Validation loss: 2.4606837469801937

Epoch: 6| Step: 12
Training loss: 1.8669573270909512
Validation loss: 2.4742376123031966

Epoch: 6| Step: 13
Training loss: 2.107379902305899
Validation loss: 2.4844984587697025

Epoch: 300| Step: 0
Training loss: 1.539821147317346
Validation loss: 2.474687719070907

Epoch: 6| Step: 1
Training loss: 1.8853815683150426
Validation loss: 2.4501381770243587

Epoch: 6| Step: 2
Training loss: 2.539063251201812
Validation loss: 2.506139266373358

Epoch: 6| Step: 3
Training loss: 1.8272196166111208
Validation loss: 2.507562214848772

Epoch: 6| Step: 4
Training loss: 1.829557721416204
Validation loss: 2.5351900432511125

Epoch: 6| Step: 5
Training loss: 1.877035053858693
Validation loss: 2.552986278523957

Epoch: 6| Step: 6
Training loss: 2.099343528772873
Validation loss: 2.534976696205745

Epoch: 6| Step: 7
Training loss: 1.9878877801288226
Validation loss: 2.577651949552858

Epoch: 6| Step: 8
Training loss: 2.431807889892268
Validation loss: 2.550220453170008

Epoch: 6| Step: 9
Training loss: 2.2890141713114938
Validation loss: 2.5736945722780105

Epoch: 6| Step: 10
Training loss: 2.4607532250575934
Validation loss: 2.5816561858857368

Epoch: 6| Step: 11
Training loss: 2.2787679468767528
Validation loss: 2.5460933273672475

Epoch: 6| Step: 12
Training loss: 1.8735630887325192
Validation loss: 2.5218135304701983

Epoch: 6| Step: 13
Training loss: 1.984078332546726
Validation loss: 2.500768050786891

Epoch: 301| Step: 0
Training loss: 2.1397351273943404
Validation loss: 2.4920417878574743

Epoch: 6| Step: 1
Training loss: 1.971369922596812
Validation loss: 2.4782241397379265

Epoch: 6| Step: 2
Training loss: 2.1641396188594193
Validation loss: 2.470672631358265

Epoch: 6| Step: 3
Training loss: 1.4783455714364675
Validation loss: 2.4980746723265885

Epoch: 6| Step: 4
Training loss: 2.2624419905670847
Validation loss: 2.4897628676881918

Epoch: 6| Step: 5
Training loss: 1.7772538717831132
Validation loss: 2.5245824840053355

Epoch: 6| Step: 6
Training loss: 2.664560400113777
Validation loss: 2.5169214892271774

Epoch: 6| Step: 7
Training loss: 1.814297409685026
Validation loss: 2.5479273270025025

Epoch: 6| Step: 8
Training loss: 1.9061581949108732
Validation loss: 2.563877875023253

Epoch: 6| Step: 9
Training loss: 1.6393190544957565
Validation loss: 2.53608823631066

Epoch: 6| Step: 10
Training loss: 2.1961794190200727
Validation loss: 2.568186010739379

Epoch: 6| Step: 11
Training loss: 2.1663881880966436
Validation loss: 2.5627716819831634

Epoch: 6| Step: 12
Training loss: 1.9646512917515802
Validation loss: 2.5552692664732297

Epoch: 6| Step: 13
Training loss: 1.8251826417012702
Validation loss: 2.5718605767267038

Epoch: 302| Step: 0
Training loss: 1.2068569711833037
Validation loss: 2.532032755319975

Epoch: 6| Step: 1
Training loss: 2.3622845021615904
Validation loss: 2.5327997055530678

Epoch: 6| Step: 2
Training loss: 1.8034714073493001
Validation loss: 2.5170417334580413

Epoch: 6| Step: 3
Training loss: 1.315285633018496
Validation loss: 2.5119019911683407

Epoch: 6| Step: 4
Training loss: 2.2668346464332196
Validation loss: 2.5054872374749104

Epoch: 6| Step: 5
Training loss: 2.792494598902548
Validation loss: 2.4816566006021

Epoch: 6| Step: 6
Training loss: 1.4151307175716812
Validation loss: 2.519816048861483

Epoch: 6| Step: 7
Training loss: 1.752771430987303
Validation loss: 2.4741028325227745

Epoch: 6| Step: 8
Training loss: 1.9114371219743527
Validation loss: 2.471317316443143

Epoch: 6| Step: 9
Training loss: 2.1481157651496856
Validation loss: 2.4938554752642204

Epoch: 6| Step: 10
Training loss: 2.0817628154229615
Validation loss: 2.5054682849883205

Epoch: 6| Step: 11
Training loss: 2.2873572549943084
Validation loss: 2.5124420342788745

Epoch: 6| Step: 12
Training loss: 2.036226251228337
Validation loss: 2.5191086998808103

Epoch: 6| Step: 13
Training loss: 2.0174847680028556
Validation loss: 2.5141296839267304

Epoch: 303| Step: 0
Training loss: 1.7660901967491889
Validation loss: 2.5017245702207456

Epoch: 6| Step: 1
Training loss: 2.812624102079695
Validation loss: 2.4617875825925033

Epoch: 6| Step: 2
Training loss: 1.7433608683982091
Validation loss: 2.45885124785456

Epoch: 6| Step: 3
Training loss: 1.8233091386006886
Validation loss: 2.460636665485181

Epoch: 6| Step: 4
Training loss: 2.882256017385662
Validation loss: 2.5035477499136536

Epoch: 6| Step: 5
Training loss: 2.186866450526077
Validation loss: 2.49934512144117

Epoch: 6| Step: 6
Training loss: 1.995683064176063
Validation loss: 2.481400970939544

Epoch: 6| Step: 7
Training loss: 2.2323807573244774
Validation loss: 2.507121108661647

Epoch: 6| Step: 8
Training loss: 2.300490563363128
Validation loss: 2.48853280369386

Epoch: 6| Step: 9
Training loss: 1.215923847248309
Validation loss: 2.500488877179984

Epoch: 6| Step: 10
Training loss: 1.8289607819220952
Validation loss: 2.538428922979415

Epoch: 6| Step: 11
Training loss: 1.610419221639971
Validation loss: 2.5430853172888104

Epoch: 6| Step: 12
Training loss: 1.4642441806817605
Validation loss: 2.5492038181969283

Epoch: 6| Step: 13
Training loss: 1.5210790130888823
Validation loss: 2.579328760734456

Epoch: 304| Step: 0
Training loss: 2.22437947653577
Validation loss: 2.5815749387984384

Epoch: 6| Step: 1
Training loss: 2.482851148896301
Validation loss: 2.572173947047662

Epoch: 6| Step: 2
Training loss: 2.346115546136369
Validation loss: 2.561180286640927

Epoch: 6| Step: 3
Training loss: 2.828215202452649
Validation loss: 2.550621257474821

Epoch: 6| Step: 4
Training loss: 1.528195039045102
Validation loss: 2.554107903576726

Epoch: 6| Step: 5
Training loss: 2.150295272778098
Validation loss: 2.565701430959922

Epoch: 6| Step: 6
Training loss: 1.3918903894348764
Validation loss: 2.553069509325755

Epoch: 6| Step: 7
Training loss: 1.4554023535055862
Validation loss: 2.5122709008523363

Epoch: 6| Step: 8
Training loss: 1.5318871554355842
Validation loss: 2.5204108070645543

Epoch: 6| Step: 9
Training loss: 2.047286130660162
Validation loss: 2.5143455900766485

Epoch: 6| Step: 10
Training loss: 2.3163796949231457
Validation loss: 2.5442770440849993

Epoch: 6| Step: 11
Training loss: 1.4811716147498568
Validation loss: 2.5887037619196462

Epoch: 6| Step: 12
Training loss: 1.8960053362389007
Validation loss: 2.5850645898881983

Epoch: 6| Step: 13
Training loss: 2.1728612183774216
Validation loss: 2.5543179803763794

Epoch: 305| Step: 0
Training loss: 1.8565938971393996
Validation loss: 2.484618536890454

Epoch: 6| Step: 1
Training loss: 2.8981229297794258
Validation loss: 2.4639227466868414

Epoch: 6| Step: 2
Training loss: 1.8624718785563141
Validation loss: 2.414495846927326

Epoch: 6| Step: 3
Training loss: 2.2406098135163517
Validation loss: 2.4063942440775334

Epoch: 6| Step: 4
Training loss: 2.0562070152172693
Validation loss: 2.4481148389316982

Epoch: 6| Step: 5
Training loss: 1.3842721767430022
Validation loss: 2.45941986437297

Epoch: 6| Step: 6
Training loss: 2.6715146541204255
Validation loss: 2.509682478065487

Epoch: 6| Step: 7
Training loss: 2.041701790124744
Validation loss: 2.512941836892723

Epoch: 6| Step: 8
Training loss: 1.6252037800881292
Validation loss: 2.5678397036070844

Epoch: 6| Step: 9
Training loss: 1.4277504060317503
Validation loss: 2.5496412205586054

Epoch: 6| Step: 10
Training loss: 2.0264064849352166
Validation loss: 2.5791017859026826

Epoch: 6| Step: 11
Training loss: 2.37910788798057
Validation loss: 2.586208348529598

Epoch: 6| Step: 12
Training loss: 2.0509544662710786
Validation loss: 2.6242250782181564

Epoch: 6| Step: 13
Training loss: 1.5540194202176807
Validation loss: 2.6202795030779225

Epoch: 306| Step: 0
Training loss: 2.0355554580873543
Validation loss: 2.5881397132237303

Epoch: 6| Step: 1
Training loss: 1.5940871536570984
Validation loss: 2.5383593793707018

Epoch: 6| Step: 2
Training loss: 1.8934428755990338
Validation loss: 2.4644585987126417

Epoch: 6| Step: 3
Training loss: 1.5877798119198192
Validation loss: 2.457207621363009

Epoch: 6| Step: 4
Training loss: 2.0614096331389704
Validation loss: 2.426794335073194

Epoch: 6| Step: 5
Training loss: 1.5474296115033386
Validation loss: 2.4008755216121447

Epoch: 6| Step: 6
Training loss: 2.025326704820974
Validation loss: 2.4206796629078893

Epoch: 6| Step: 7
Training loss: 1.576830644743483
Validation loss: 2.4177943481589623

Epoch: 6| Step: 8
Training loss: 2.485444996094921
Validation loss: 2.446196180091728

Epoch: 6| Step: 9
Training loss: 2.3456079875065843
Validation loss: 2.4710080487608934

Epoch: 6| Step: 10
Training loss: 2.0928610437580955
Validation loss: 2.483024454002292

Epoch: 6| Step: 11
Training loss: 1.8573413273848571
Validation loss: 2.5408144809435957

Epoch: 6| Step: 12
Training loss: 2.4795534382511923
Validation loss: 2.6016265739057736

Epoch: 6| Step: 13
Training loss: 2.720945064086845
Validation loss: 2.6277136022174727

Epoch: 307| Step: 0
Training loss: 2.035520319673021
Validation loss: 2.6902291391055027

Epoch: 6| Step: 1
Training loss: 2.5689348511652157
Validation loss: 2.767094726270985

Epoch: 6| Step: 2
Training loss: 2.9029292341405317
Validation loss: 2.806701206446288

Epoch: 6| Step: 3
Training loss: 2.4549688710960345
Validation loss: 2.748582980621488

Epoch: 6| Step: 4
Training loss: 1.8496452094436573
Validation loss: 2.615888912995456

Epoch: 6| Step: 5
Training loss: 1.8116468855343226
Validation loss: 2.560667561301575

Epoch: 6| Step: 6
Training loss: 1.3020642800526547
Validation loss: 2.54163503366599

Epoch: 6| Step: 7
Training loss: 2.3432396905383905
Validation loss: 2.4916341360598917

Epoch: 6| Step: 8
Training loss: 1.641240540337012
Validation loss: 2.4516863968100875

Epoch: 6| Step: 9
Training loss: 2.1565131427692537
Validation loss: 2.4715508616201523

Epoch: 6| Step: 10
Training loss: 2.144438527922081
Validation loss: 2.4540807235081954

Epoch: 6| Step: 11
Training loss: 3.2464257172687843
Validation loss: 2.4679443074789407

Epoch: 6| Step: 12
Training loss: 2.476771589532201
Validation loss: 2.481015715280086

Epoch: 6| Step: 13
Training loss: 2.132594506158579
Validation loss: 2.4801199279777384

Epoch: 308| Step: 0
Training loss: 2.121715250869901
Validation loss: 2.483125720423669

Epoch: 6| Step: 1
Training loss: 2.0629476581614283
Validation loss: 2.4873766090549787

Epoch: 6| Step: 2
Training loss: 1.7485397240803573
Validation loss: 2.4897432049823487

Epoch: 6| Step: 3
Training loss: 2.072511706900117
Validation loss: 2.4925671390940383

Epoch: 6| Step: 4
Training loss: 1.9296587737258024
Validation loss: 2.487025160971668

Epoch: 6| Step: 5
Training loss: 2.6742108045410378
Validation loss: 2.5072796850759467

Epoch: 6| Step: 6
Training loss: 2.231462514464604
Validation loss: 2.525906216375251

Epoch: 6| Step: 7
Training loss: 1.4253188127956253
Validation loss: 2.5611286370520627

Epoch: 6| Step: 8
Training loss: 2.297728295673739
Validation loss: 2.564622465238487

Epoch: 6| Step: 9
Training loss: 1.5044643406950846
Validation loss: 2.5886059656478766

Epoch: 6| Step: 10
Training loss: 2.14147575903013
Validation loss: 2.5564658287605173

Epoch: 6| Step: 11
Training loss: 2.6286696260928855
Validation loss: 2.5544474233265464

Epoch: 6| Step: 12
Training loss: 2.3242942477233814
Validation loss: 2.547338931027195

Epoch: 6| Step: 13
Training loss: 2.308333070757285
Validation loss: 2.5388761481344053

Epoch: 309| Step: 0
Training loss: 1.945075882458661
Validation loss: 2.511000598303773

Epoch: 6| Step: 1
Training loss: 1.7244131942230088
Validation loss: 2.471518883208739

Epoch: 6| Step: 2
Training loss: 2.1754318860840507
Validation loss: 2.4849246714564424

Epoch: 6| Step: 3
Training loss: 2.3072876826152173
Validation loss: 2.4492349659587243

Epoch: 6| Step: 4
Training loss: 2.189289124307708
Validation loss: 2.4640429244214306

Epoch: 6| Step: 5
Training loss: 1.995802169375985
Validation loss: 2.437783404119883

Epoch: 6| Step: 6
Training loss: 1.3497860209107566
Validation loss: 2.4657356917462403

Epoch: 6| Step: 7
Training loss: 2.516459261535108
Validation loss: 2.453180413723792

Epoch: 6| Step: 8
Training loss: 1.892093245964683
Validation loss: 2.4445154193005116

Epoch: 6| Step: 9
Training loss: 1.9298321750785756
Validation loss: 2.4596798382704668

Epoch: 6| Step: 10
Training loss: 1.7238129691834958
Validation loss: 2.434008681844724

Epoch: 6| Step: 11
Training loss: 1.8883423700253896
Validation loss: 2.4165207117225633

Epoch: 6| Step: 12
Training loss: 1.705103154124358
Validation loss: 2.4347991896980656

Epoch: 6| Step: 13
Training loss: 2.5898198145340015
Validation loss: 2.4394092255534687

Epoch: 310| Step: 0
Training loss: 2.291942048144058
Validation loss: 2.4472501510208033

Epoch: 6| Step: 1
Training loss: 2.002978729287465
Validation loss: 2.4613511318174246

Epoch: 6| Step: 2
Training loss: 2.1922333868203996
Validation loss: 2.4805673174159777

Epoch: 6| Step: 3
Training loss: 2.0123402644673036
Validation loss: 2.5022110698109623

Epoch: 6| Step: 4
Training loss: 1.9933126824988023
Validation loss: 2.5000418500576327

Epoch: 6| Step: 5
Training loss: 2.4232249773646837
Validation loss: 2.4881868050066687

Epoch: 6| Step: 6
Training loss: 1.6236900037762865
Validation loss: 2.486975134934491

Epoch: 6| Step: 7
Training loss: 2.217504232202596
Validation loss: 2.499824907211297

Epoch: 6| Step: 8
Training loss: 2.1118948120380043
Validation loss: 2.5007121820117084

Epoch: 6| Step: 9
Training loss: 1.6648806857411453
Validation loss: 2.5198308958732336

Epoch: 6| Step: 10
Training loss: 1.9600739420353126
Validation loss: 2.521546890740597

Epoch: 6| Step: 11
Training loss: 1.908537071157813
Validation loss: 2.5200577060207974

Epoch: 6| Step: 12
Training loss: 1.3373727060511
Validation loss: 2.4815049377588023

Epoch: 6| Step: 13
Training loss: 1.5464589493856633
Validation loss: 2.517881719900225

Epoch: 311| Step: 0
Training loss: 2.0866951584419646
Validation loss: 2.51784925675373

Epoch: 6| Step: 1
Training loss: 2.107700050244469
Validation loss: 2.5172516201952497

Epoch: 6| Step: 2
Training loss: 2.284893940273452
Validation loss: 2.5176430184085223

Epoch: 6| Step: 3
Training loss: 1.7770954335893805
Validation loss: 2.537947518484699

Epoch: 6| Step: 4
Training loss: 1.9627453498790106
Validation loss: 2.5115797400878606

Epoch: 6| Step: 5
Training loss: 1.7047562792475384
Validation loss: 2.49456757963945

Epoch: 6| Step: 6
Training loss: 2.0877165904724206
Validation loss: 2.505835921786559

Epoch: 6| Step: 7
Training loss: 2.3265045466227963
Validation loss: 2.4827594902664614

Epoch: 6| Step: 8
Training loss: 2.1063251063146
Validation loss: 2.4789518749463797

Epoch: 6| Step: 9
Training loss: 1.084052336340836
Validation loss: 2.5018797642089656

Epoch: 6| Step: 10
Training loss: 2.447910963552338
Validation loss: 2.5145811201547796

Epoch: 6| Step: 11
Training loss: 2.3099980609439785
Validation loss: 2.5027889272159456

Epoch: 6| Step: 12
Training loss: 1.4921298190647283
Validation loss: 2.522361171520228

Epoch: 6| Step: 13
Training loss: 1.4973101339833046
Validation loss: 2.54710784971034

Epoch: 312| Step: 0
Training loss: 1.8064777692645897
Validation loss: 2.5623979315550214

Epoch: 6| Step: 1
Training loss: 1.900738487280033
Validation loss: 2.5889576987598337

Epoch: 6| Step: 2
Training loss: 1.573026598526624
Validation loss: 2.555118131749614

Epoch: 6| Step: 3
Training loss: 1.477838358597396
Validation loss: 2.5700929928689784

Epoch: 6| Step: 4
Training loss: 2.0946431318976755
Validation loss: 2.566498915858795

Epoch: 6| Step: 5
Training loss: 2.359279706432625
Validation loss: 2.5608570367858356

Epoch: 6| Step: 6
Training loss: 1.8970834432135917
Validation loss: 2.559122915122722

Epoch: 6| Step: 7
Training loss: 1.9154645494781721
Validation loss: 2.5531701920119336

Epoch: 6| Step: 8
Training loss: 2.247106068578242
Validation loss: 2.497939031170482

Epoch: 6| Step: 9
Training loss: 2.3298174959343
Validation loss: 2.514720959651545

Epoch: 6| Step: 10
Training loss: 2.3406888171308373
Validation loss: 2.5061020132816876

Epoch: 6| Step: 11
Training loss: 1.6752453638538354
Validation loss: 2.517606219639756

Epoch: 6| Step: 12
Training loss: 2.1374011859027053
Validation loss: 2.5104520539339354

Epoch: 6| Step: 13
Training loss: 2.241973547746259
Validation loss: 2.5339950778484837

Epoch: 313| Step: 0
Training loss: 1.8575222497688233
Validation loss: 2.5552449371623136

Epoch: 6| Step: 1
Training loss: 2.084255268827397
Validation loss: 2.5409887743935498

Epoch: 6| Step: 2
Training loss: 2.51372982690457
Validation loss: 2.6100865381882774

Epoch: 6| Step: 3
Training loss: 2.432703237952651
Validation loss: 2.578349880082393

Epoch: 6| Step: 4
Training loss: 1.7782078916406103
Validation loss: 2.557349665981773

Epoch: 6| Step: 5
Training loss: 2.1411330462492804
Validation loss: 2.544769149807657

Epoch: 6| Step: 6
Training loss: 1.8662254376848701
Validation loss: 2.5465442466105057

Epoch: 6| Step: 7
Training loss: 1.5453168940312907
Validation loss: 2.5553509300887334

Epoch: 6| Step: 8
Training loss: 1.3292522807436222
Validation loss: 2.516858148132396

Epoch: 6| Step: 9
Training loss: 2.4660065291690323
Validation loss: 2.535622615071837

Epoch: 6| Step: 10
Training loss: 1.5975740966567002
Validation loss: 2.524109608179628

Epoch: 6| Step: 11
Training loss: 1.9546103970745183
Validation loss: 2.5325149389581383

Epoch: 6| Step: 12
Training loss: 1.815042225580344
Validation loss: 2.511232051098487

Epoch: 6| Step: 13
Training loss: 1.8111967465698353
Validation loss: 2.5172669006491546

Epoch: 314| Step: 0
Training loss: 2.536890879466452
Validation loss: 2.530898136439308

Epoch: 6| Step: 1
Training loss: 1.8326708362462993
Validation loss: 2.491555304149082

Epoch: 6| Step: 2
Training loss: 2.016798757005102
Validation loss: 2.4799561859562345

Epoch: 6| Step: 3
Training loss: 2.123785569475196
Validation loss: 2.4887023042546845

Epoch: 6| Step: 4
Training loss: 1.2812500930413933
Validation loss: 2.5047880733586583

Epoch: 6| Step: 5
Training loss: 1.4490545544829139
Validation loss: 2.4899541560067524

Epoch: 6| Step: 6
Training loss: 1.9038765311318582
Validation loss: 2.5259837638799323

Epoch: 6| Step: 7
Training loss: 1.8380395421536795
Validation loss: 2.5390750826010344

Epoch: 6| Step: 8
Training loss: 2.248237555377037
Validation loss: 2.5330861343274766

Epoch: 6| Step: 9
Training loss: 1.7834776617928625
Validation loss: 2.548183814760939

Epoch: 6| Step: 10
Training loss: 1.9550041619180931
Validation loss: 2.5596779969602936

Epoch: 6| Step: 11
Training loss: 2.2913047042284944
Validation loss: 2.5752651652126692

Epoch: 6| Step: 12
Training loss: 1.9413141424484628
Validation loss: 2.6067020560892393

Epoch: 6| Step: 13
Training loss: 1.9294820205076175
Validation loss: 2.6290174199065626

Epoch: 315| Step: 0
Training loss: 1.260588242803933
Validation loss: 2.607450266479907

Epoch: 6| Step: 1
Training loss: 1.672088324226227
Validation loss: 2.6554250445897907

Epoch: 6| Step: 2
Training loss: 2.098162201116106
Validation loss: 2.592605016378376

Epoch: 6| Step: 3
Training loss: 1.9394187040626294
Validation loss: 2.5551469644381557

Epoch: 6| Step: 4
Training loss: 2.365785895133228
Validation loss: 2.523717654082176

Epoch: 6| Step: 5
Training loss: 1.8192001677064307
Validation loss: 2.513489616562306

Epoch: 6| Step: 6
Training loss: 2.0095283509110375
Validation loss: 2.5247439141291275

Epoch: 6| Step: 7
Training loss: 1.1195436188146985
Validation loss: 2.5059416735864457

Epoch: 6| Step: 8
Training loss: 2.0491898820060257
Validation loss: 2.476088357136679

Epoch: 6| Step: 9
Training loss: 2.492178698676661
Validation loss: 2.48484237241328

Epoch: 6| Step: 10
Training loss: 2.5735364365682174
Validation loss: 2.468316776555813

Epoch: 6| Step: 11
Training loss: 2.2054597644305307
Validation loss: 2.4670731527458503

Epoch: 6| Step: 12
Training loss: 1.671366748027417
Validation loss: 2.491145778248987

Epoch: 6| Step: 13
Training loss: 1.3861903083683726
Validation loss: 2.476736935029014

Epoch: 316| Step: 0
Training loss: 2.147300391551591
Validation loss: 2.5438988425708113

Epoch: 6| Step: 1
Training loss: 1.681022574772975
Validation loss: 2.527015078996907

Epoch: 6| Step: 2
Training loss: 1.2659572589041348
Validation loss: 2.573442248409718

Epoch: 6| Step: 3
Training loss: 2.1261499322827397
Validation loss: 2.582621373749175

Epoch: 6| Step: 4
Training loss: 1.6493623137049414
Validation loss: 2.564335832240146

Epoch: 6| Step: 5
Training loss: 1.995281733646844
Validation loss: 2.5651730962228276

Epoch: 6| Step: 6
Training loss: 2.291812949858136
Validation loss: 2.530468619977589

Epoch: 6| Step: 7
Training loss: 2.319265521135007
Validation loss: 2.4838843670896327

Epoch: 6| Step: 8
Training loss: 2.367527399116045
Validation loss: 2.4604326406461534

Epoch: 6| Step: 9
Training loss: 1.7484273656256506
Validation loss: 2.434327971526921

Epoch: 6| Step: 10
Training loss: 2.222648526733067
Validation loss: 2.41503478452327

Epoch: 6| Step: 11
Training loss: 2.0388216190634116
Validation loss: 2.4390195853779146

Epoch: 6| Step: 12
Training loss: 1.547914098204394
Validation loss: 2.4299300175991037

Epoch: 6| Step: 13
Training loss: 1.9695302234663628
Validation loss: 2.45572391049634

Epoch: 317| Step: 0
Training loss: 2.379060787198808
Validation loss: 2.483246665014006

Epoch: 6| Step: 1
Training loss: 1.8910301341899094
Validation loss: 2.5187065253280263

Epoch: 6| Step: 2
Training loss: 1.8430588930213656
Validation loss: 2.5158085410568747

Epoch: 6| Step: 3
Training loss: 1.8104878141282288
Validation loss: 2.5079433292159528

Epoch: 6| Step: 4
Training loss: 1.836983824910494
Validation loss: 2.5211081289364623

Epoch: 6| Step: 5
Training loss: 1.7047086579769408
Validation loss: 2.5174409302666865

Epoch: 6| Step: 6
Training loss: 1.6089250250324088
Validation loss: 2.5066588175385256

Epoch: 6| Step: 7
Training loss: 1.7954874403324919
Validation loss: 2.473302321877959

Epoch: 6| Step: 8
Training loss: 1.6720208790675557
Validation loss: 2.480023313561449

Epoch: 6| Step: 9
Training loss: 1.5146370253388175
Validation loss: 2.5145285924111547

Epoch: 6| Step: 10
Training loss: 1.5552469138461436
Validation loss: 2.498199307123388

Epoch: 6| Step: 11
Training loss: 2.4971570062189716
Validation loss: 2.547449035546535

Epoch: 6| Step: 12
Training loss: 2.025374733431207
Validation loss: 2.543191504500684

Epoch: 6| Step: 13
Training loss: 2.3402646407435634
Validation loss: 2.5628859841780955

Epoch: 318| Step: 0
Training loss: 2.182033138089946
Validation loss: 2.564601083338215

Epoch: 6| Step: 1
Training loss: 1.7267317883105664
Validation loss: 2.562086025386961

Epoch: 6| Step: 2
Training loss: 2.117259344592245
Validation loss: 2.553937228250174

Epoch: 6| Step: 3
Training loss: 1.355162132388525
Validation loss: 2.5058804335468747

Epoch: 6| Step: 4
Training loss: 2.2596563182563276
Validation loss: 2.521387470174872

Epoch: 6| Step: 5
Training loss: 1.783801476658735
Validation loss: 2.5099603124725656

Epoch: 6| Step: 6
Training loss: 2.5123875796849937
Validation loss: 2.4763753280748544

Epoch: 6| Step: 7
Training loss: 2.4250740826489094
Validation loss: 2.486271867817329

Epoch: 6| Step: 8
Training loss: 1.3495963464486236
Validation loss: 2.489643388819212

Epoch: 6| Step: 9
Training loss: 2.1757461846366497
Validation loss: 2.5320383578895833

Epoch: 6| Step: 10
Training loss: 1.8798819247156995
Validation loss: 2.538584221029415

Epoch: 6| Step: 11
Training loss: 1.6159580735914743
Validation loss: 2.515268620428076

Epoch: 6| Step: 12
Training loss: 1.6308169787715332
Validation loss: 2.5137989137564283

Epoch: 6| Step: 13
Training loss: 1.6151610130615504
Validation loss: 2.5083444651064144

Epoch: 319| Step: 0
Training loss: 2.5684851553979744
Validation loss: 2.4750665585080744

Epoch: 6| Step: 1
Training loss: 1.752639618997294
Validation loss: 2.479303249368767

Epoch: 6| Step: 2
Training loss: 1.9263593258736469
Validation loss: 2.4828926078303786

Epoch: 6| Step: 3
Training loss: 1.9263627294469288
Validation loss: 2.5089295574251587

Epoch: 6| Step: 4
Training loss: 1.9972577368500106
Validation loss: 2.50909449686913

Epoch: 6| Step: 5
Training loss: 1.3501044550857293
Validation loss: 2.4864037665292775

Epoch: 6| Step: 6
Training loss: 1.905971569301557
Validation loss: 2.5098246249575515

Epoch: 6| Step: 7
Training loss: 0.9605799684412375
Validation loss: 2.4865869076272293

Epoch: 6| Step: 8
Training loss: 2.2520473490288935
Validation loss: 2.499394772702508

Epoch: 6| Step: 9
Training loss: 1.1650130723866523
Validation loss: 2.5021702882859134

Epoch: 6| Step: 10
Training loss: 1.740877351668476
Validation loss: 2.472948134451603

Epoch: 6| Step: 11
Training loss: 2.874746726116728
Validation loss: 2.5111183409975935

Epoch: 6| Step: 12
Training loss: 2.064221675028442
Validation loss: 2.502037156118578

Epoch: 6| Step: 13
Training loss: 1.2258601516410959
Validation loss: 2.541588240075334

Epoch: 320| Step: 0
Training loss: 2.0050091004581305
Validation loss: 2.527171109890375

Epoch: 6| Step: 1
Training loss: 2.0817092159779893
Validation loss: 2.492072681743762

Epoch: 6| Step: 2
Training loss: 2.015149437448504
Validation loss: 2.499259870961414

Epoch: 6| Step: 3
Training loss: 1.9595710279124454
Validation loss: 2.4991647914647515

Epoch: 6| Step: 4
Training loss: 2.0626180210447416
Validation loss: 2.5073497975204524

Epoch: 6| Step: 5
Training loss: 2.4568068943176624
Validation loss: 2.5068957751743235

Epoch: 6| Step: 6
Training loss: 1.8842403964779442
Validation loss: 2.538847834976054

Epoch: 6| Step: 7
Training loss: 1.3161388544466974
Validation loss: 2.5372061570257567

Epoch: 6| Step: 8
Training loss: 1.4853990736566451
Validation loss: 2.478278751742815

Epoch: 6| Step: 9
Training loss: 2.2851312097987053
Validation loss: 2.4777180475848413

Epoch: 6| Step: 10
Training loss: 1.8336693571387985
Validation loss: 2.483182480943139

Epoch: 6| Step: 11
Training loss: 1.9645487448221972
Validation loss: 2.459322671038681

Epoch: 6| Step: 12
Training loss: 1.7704298419900562
Validation loss: 2.451396519472267

Epoch: 6| Step: 13
Training loss: 1.2714282607955307
Validation loss: 2.468850290699862

Epoch: 321| Step: 0
Training loss: 1.4142716395378228
Validation loss: 2.481571350940151

Epoch: 6| Step: 1
Training loss: 1.7163339452919628
Validation loss: 2.468336899716387

Epoch: 6| Step: 2
Training loss: 2.174408676619127
Validation loss: 2.4949051838468743

Epoch: 6| Step: 3
Training loss: 2.0232083106130085
Validation loss: 2.4994565691002273

Epoch: 6| Step: 4
Training loss: 1.7787754203390032
Validation loss: 2.492017766101345

Epoch: 6| Step: 5
Training loss: 1.6166840290172861
Validation loss: 2.489907252947515

Epoch: 6| Step: 6
Training loss: 1.8919385020118644
Validation loss: 2.511155005393023

Epoch: 6| Step: 7
Training loss: 2.365626157006972
Validation loss: 2.504094109354159

Epoch: 6| Step: 8
Training loss: 1.9013468109904232
Validation loss: 2.5519725905284787

Epoch: 6| Step: 9
Training loss: 1.6022629857458897
Validation loss: 2.5744895657537645

Epoch: 6| Step: 10
Training loss: 2.1818816923521283
Validation loss: 2.5826456221040015

Epoch: 6| Step: 11
Training loss: 2.1411722416518506
Validation loss: 2.5230869801683484

Epoch: 6| Step: 12
Training loss: 1.335906803603844
Validation loss: 2.476353537230573

Epoch: 6| Step: 13
Training loss: 2.109935996725569
Validation loss: 2.479164168946961

Epoch: 322| Step: 0
Training loss: 1.8574517826275807
Validation loss: 2.511121838142566

Epoch: 6| Step: 1
Training loss: 1.6506475305084836
Validation loss: 2.4560830328881225

Epoch: 6| Step: 2
Training loss: 2.578695708020904
Validation loss: 2.4927213728792554

Epoch: 6| Step: 3
Training loss: 1.538823530360035
Validation loss: 2.4895444465271006

Epoch: 6| Step: 4
Training loss: 1.495946413758295
Validation loss: 2.508021701472957

Epoch: 6| Step: 5
Training loss: 1.5763069482569982
Validation loss: 2.525543247615646

Epoch: 6| Step: 6
Training loss: 1.61757909484112
Validation loss: 2.555109173954892

Epoch: 6| Step: 7
Training loss: 2.171933180215001
Validation loss: 2.589171769777918

Epoch: 6| Step: 8
Training loss: 2.084812961303283
Validation loss: 2.604317703953379

Epoch: 6| Step: 9
Training loss: 2.0883509928612973
Validation loss: 2.5933923589646075

Epoch: 6| Step: 10
Training loss: 2.0330998140704724
Validation loss: 2.6296319965890174

Epoch: 6| Step: 11
Training loss: 2.3007478824909566
Validation loss: 2.635210644857713

Epoch: 6| Step: 12
Training loss: 1.9129771366697361
Validation loss: 2.5695327457227615

Epoch: 6| Step: 13
Training loss: 2.0003292289598122
Validation loss: 2.555048552497846

Epoch: 323| Step: 0
Training loss: 2.128541575704349
Validation loss: 2.5371539019249543

Epoch: 6| Step: 1
Training loss: 2.053874155797176
Validation loss: 2.514898696841113

Epoch: 6| Step: 2
Training loss: 1.8893838386694852
Validation loss: 2.512023891425463

Epoch: 6| Step: 3
Training loss: 1.6000350739687859
Validation loss: 2.5132043142324902

Epoch: 6| Step: 4
Training loss: 1.5338906854277194
Validation loss: 2.5043143714932636

Epoch: 6| Step: 5
Training loss: 1.4866494672290693
Validation loss: 2.5185553817087385

Epoch: 6| Step: 6
Training loss: 2.4272245330558953
Validation loss: 2.51603867503928

Epoch: 6| Step: 7
Training loss: 2.1756869009713573
Validation loss: 2.53993776543035

Epoch: 6| Step: 8
Training loss: 1.9836599909091506
Validation loss: 2.5277834887550688

Epoch: 6| Step: 9
Training loss: 1.4835894463563584
Validation loss: 2.552522976952785

Epoch: 6| Step: 10
Training loss: 1.9773711710173638
Validation loss: 2.5366414269717623

Epoch: 6| Step: 11
Training loss: 1.7342362906860107
Validation loss: 2.5113016417987857

Epoch: 6| Step: 12
Training loss: 1.7123715039237108
Validation loss: 2.5354895154715793

Epoch: 6| Step: 13
Training loss: 2.0468178078618338
Validation loss: 2.530211043143729

Epoch: 324| Step: 0
Training loss: 1.6541812140195848
Validation loss: 2.5383707522487304

Epoch: 6| Step: 1
Training loss: 1.9539267763495682
Validation loss: 2.5364103110360863

Epoch: 6| Step: 2
Training loss: 1.3841366220360272
Validation loss: 2.554405453479177

Epoch: 6| Step: 3
Training loss: 1.9525410504000458
Validation loss: 2.563673154044095

Epoch: 6| Step: 4
Training loss: 1.8587794271678135
Validation loss: 2.558458086838551

Epoch: 6| Step: 5
Training loss: 2.467218141081646
Validation loss: 2.5487888299049297

Epoch: 6| Step: 6
Training loss: 1.9170293119375506
Validation loss: 2.5550334046849543

Epoch: 6| Step: 7
Training loss: 1.6876448109976099
Validation loss: 2.511728503266141

Epoch: 6| Step: 8
Training loss: 2.038666317623916
Validation loss: 2.4905662086149873

Epoch: 6| Step: 9
Training loss: 1.6619883761085534
Validation loss: 2.487426850666689

Epoch: 6| Step: 10
Training loss: 2.391719293403028
Validation loss: 2.495324435650413

Epoch: 6| Step: 11
Training loss: 1.6089270255288686
Validation loss: 2.468277463475995

Epoch: 6| Step: 12
Training loss: 2.056886837559231
Validation loss: 2.4704293683641785

Epoch: 6| Step: 13
Training loss: 1.6808681862804287
Validation loss: 2.483875472354094

Epoch: 325| Step: 0
Training loss: 1.8341971082066235
Validation loss: 2.4807680765405955

Epoch: 6| Step: 1
Training loss: 2.1490475430064477
Validation loss: 2.4707247807253547

Epoch: 6| Step: 2
Training loss: 1.7537217754722043
Validation loss: 2.504932417449659

Epoch: 6| Step: 3
Training loss: 1.8568905813615653
Validation loss: 2.5530531201930735

Epoch: 6| Step: 4
Training loss: 2.168586491734039
Validation loss: 2.578832479178927

Epoch: 6| Step: 5
Training loss: 1.1606008788659494
Validation loss: 2.5784341491916627

Epoch: 6| Step: 6
Training loss: 2.0470003278962188
Validation loss: 2.547162287448516

Epoch: 6| Step: 7
Training loss: 2.0954257465114496
Validation loss: 2.5201695937153197

Epoch: 6| Step: 8
Training loss: 1.567389885717101
Validation loss: 2.5662082574456173

Epoch: 6| Step: 9
Training loss: 1.9989499673540765
Validation loss: 2.544214165380884

Epoch: 6| Step: 10
Training loss: 1.7371305278693692
Validation loss: 2.563364828914155

Epoch: 6| Step: 11
Training loss: 2.0735057460244444
Validation loss: 2.5281587099422094

Epoch: 6| Step: 12
Training loss: 1.2592285904131222
Validation loss: 2.537181748475573

Epoch: 6| Step: 13
Training loss: 2.3261333369498685
Validation loss: 2.5417127110005446

Epoch: 326| Step: 0
Training loss: 1.6471368078494826
Validation loss: 2.5592407029859277

Epoch: 6| Step: 1
Training loss: 1.4774242490142488
Validation loss: 2.5487309034179977

Epoch: 6| Step: 2
Training loss: 2.077600398569873
Validation loss: 2.552088388450962

Epoch: 6| Step: 3
Training loss: 1.3679533203230827
Validation loss: 2.5431950200403204

Epoch: 6| Step: 4
Training loss: 2.0907616996834624
Validation loss: 2.5439219604904295

Epoch: 6| Step: 5
Training loss: 2.397304205034699
Validation loss: 2.5322442790317776

Epoch: 6| Step: 6
Training loss: 1.9464647794682983
Validation loss: 2.541377259542635

Epoch: 6| Step: 7
Training loss: 1.8268788320766771
Validation loss: 2.558744097070636

Epoch: 6| Step: 8
Training loss: 2.262912152090985
Validation loss: 2.5286328714485724

Epoch: 6| Step: 9
Training loss: 1.8884378818863188
Validation loss: 2.5373146340200154

Epoch: 6| Step: 10
Training loss: 1.9140687903476037
Validation loss: 2.46950570141261

Epoch: 6| Step: 11
Training loss: 1.8799926408664247
Validation loss: 2.470934685873984

Epoch: 6| Step: 12
Training loss: 2.1115036008399
Validation loss: 2.5570783247724336

Epoch: 6| Step: 13
Training loss: 2.468408488542485
Validation loss: 2.624945367517073

Epoch: 327| Step: 0
Training loss: 1.824053411730708
Validation loss: 2.6189185343964203

Epoch: 6| Step: 1
Training loss: 2.076975224728731
Validation loss: 2.6174516383248267

Epoch: 6| Step: 2
Training loss: 1.7517519764160225
Validation loss: 2.565126375725093

Epoch: 6| Step: 3
Training loss: 1.6884008757978715
Validation loss: 2.507155335262921

Epoch: 6| Step: 4
Training loss: 2.4844143462514183
Validation loss: 2.469554874540882

Epoch: 6| Step: 5
Training loss: 1.818584686317017
Validation loss: 2.4959591156135903

Epoch: 6| Step: 6
Training loss: 1.3413735600677859
Validation loss: 2.5138652957303242

Epoch: 6| Step: 7
Training loss: 2.14940674159646
Validation loss: 2.534335159697304

Epoch: 6| Step: 8
Training loss: 1.2152628773578102
Validation loss: 2.576063900512391

Epoch: 6| Step: 9
Training loss: 1.9082309873141787
Validation loss: 2.552589682866348

Epoch: 6| Step: 10
Training loss: 2.4287047529889594
Validation loss: 2.5566814080335165

Epoch: 6| Step: 11
Training loss: 1.5708514754700555
Validation loss: 2.56903449445379

Epoch: 6| Step: 12
Training loss: 1.599698503221309
Validation loss: 2.5736239358228237

Epoch: 6| Step: 13
Training loss: 1.7079696345656343
Validation loss: 2.569614613256394

Epoch: 328| Step: 0
Training loss: 2.234320793294605
Validation loss: 2.544398064817634

Epoch: 6| Step: 1
Training loss: 1.8120715851738065
Validation loss: 2.5184965468390517

Epoch: 6| Step: 2
Training loss: 1.5125160184910493
Validation loss: 2.492732690951725

Epoch: 6| Step: 3
Training loss: 2.102633972435477
Validation loss: 2.4627502385261555

Epoch: 6| Step: 4
Training loss: 1.848289461890784
Validation loss: 2.460494341634926

Epoch: 6| Step: 5
Training loss: 1.3150747566585657
Validation loss: 2.4387489770639146

Epoch: 6| Step: 6
Training loss: 2.0982766255216907
Validation loss: 2.4272293952792636

Epoch: 6| Step: 7
Training loss: 1.8670117922034029
Validation loss: 2.45121570968441

Epoch: 6| Step: 8
Training loss: 1.4800222725094456
Validation loss: 2.4529549120597682

Epoch: 6| Step: 9
Training loss: 1.026571585558396
Validation loss: 2.4528235637019824

Epoch: 6| Step: 10
Training loss: 2.0121478465687894
Validation loss: 2.4945293094776004

Epoch: 6| Step: 11
Training loss: 1.976141602102764
Validation loss: 2.44283629179198

Epoch: 6| Step: 12
Training loss: 1.955342369247734
Validation loss: 2.4356152999798324

Epoch: 6| Step: 13
Training loss: 2.0247499193784275
Validation loss: 2.4507301368202876

Epoch: 329| Step: 0
Training loss: 1.0499625153889656
Validation loss: 2.4407368874067883

Epoch: 6| Step: 1
Training loss: 1.6821958752770356
Validation loss: 2.465435507180532

Epoch: 6| Step: 2
Training loss: 1.8019759379525808
Validation loss: 2.5245016116044385

Epoch: 6| Step: 3
Training loss: 1.430056498285069
Validation loss: 2.5015425850248056

Epoch: 6| Step: 4
Training loss: 1.7173695656057186
Validation loss: 2.521147311705273

Epoch: 6| Step: 5
Training loss: 1.9558904981717722
Validation loss: 2.5524430053953457

Epoch: 6| Step: 6
Training loss: 2.2432445201137265
Validation loss: 2.568274527769139

Epoch: 6| Step: 7
Training loss: 2.1914820802457706
Validation loss: 2.573786790463476

Epoch: 6| Step: 8
Training loss: 1.6252924582593984
Validation loss: 2.56346303009821

Epoch: 6| Step: 9
Training loss: 2.168404860063267
Validation loss: 2.555194473902898

Epoch: 6| Step: 10
Training loss: 1.2953750484812196
Validation loss: 2.5452218960879462

Epoch: 6| Step: 11
Training loss: 1.3342523933919532
Validation loss: 2.5944502700991667

Epoch: 6| Step: 12
Training loss: 2.03946445054974
Validation loss: 2.524140455912329

Epoch: 6| Step: 13
Training loss: 2.176285361715337
Validation loss: 2.488286879217227

Epoch: 330| Step: 0
Training loss: 1.8050696558734047
Validation loss: 2.523299710475129

Epoch: 6| Step: 1
Training loss: 1.815777741669989
Validation loss: 2.5011446398713306

Epoch: 6| Step: 2
Training loss: 1.901678889528133
Validation loss: 2.5079163463478458

Epoch: 6| Step: 3
Training loss: 1.5052629172735965
Validation loss: 2.5044507621372167

Epoch: 6| Step: 4
Training loss: 2.2247640206002024
Validation loss: 2.506007462940231

Epoch: 6| Step: 5
Training loss: 1.2287968009037853
Validation loss: 2.515301432838568

Epoch: 6| Step: 6
Training loss: 1.9202067259918745
Validation loss: 2.5263096198625687

Epoch: 6| Step: 7
Training loss: 1.2846059809612485
Validation loss: 2.5075735768622396

Epoch: 6| Step: 8
Training loss: 1.6125594549529194
Validation loss: 2.5228751060744

Epoch: 6| Step: 9
Training loss: 1.594277537681875
Validation loss: 2.4892223021891557

Epoch: 6| Step: 10
Training loss: 1.9554322309814107
Validation loss: 2.4848919136774965

Epoch: 6| Step: 11
Training loss: 1.7070474514748892
Validation loss: 2.477571548611806

Epoch: 6| Step: 12
Training loss: 2.26689112571027
Validation loss: 2.4557494523042194

Epoch: 6| Step: 13
Training loss: 2.0691234700977312
Validation loss: 2.439729795503416

Epoch: 331| Step: 0
Training loss: 1.7652074944749172
Validation loss: 2.4513650319058518

Epoch: 6| Step: 1
Training loss: 1.536471281697514
Validation loss: 2.497979157986215

Epoch: 6| Step: 2
Training loss: 1.8946165714518133
Validation loss: 2.52022544109774

Epoch: 6| Step: 3
Training loss: 1.6396487283166805
Validation loss: 2.514728188839521

Epoch: 6| Step: 4
Training loss: 2.1296518682464365
Validation loss: 2.5278133720528175

Epoch: 6| Step: 5
Training loss: 1.5880662884268995
Validation loss: 2.5409367612875906

Epoch: 6| Step: 6
Training loss: 1.3639559674692832
Validation loss: 2.5285546665800904

Epoch: 6| Step: 7
Training loss: 2.2757934737605656
Validation loss: 2.509602938474176

Epoch: 6| Step: 8
Training loss: 2.019221918554786
Validation loss: 2.5885376549631474

Epoch: 6| Step: 9
Training loss: 2.1029353426119166
Validation loss: 2.586313287603794

Epoch: 6| Step: 10
Training loss: 1.9259934995111747
Validation loss: 2.5997882631478655

Epoch: 6| Step: 11
Training loss: 1.4980063700266775
Validation loss: 2.597384522263431

Epoch: 6| Step: 12
Training loss: 1.7572533290308876
Validation loss: 2.6256864119547574

Epoch: 6| Step: 13
Training loss: 2.0435895104345696
Validation loss: 2.5908168462468173

Epoch: 332| Step: 0
Training loss: 1.557573945691895
Validation loss: 2.5666067818265232

Epoch: 6| Step: 1
Training loss: 1.649032413106273
Validation loss: 2.5698380578323374

Epoch: 6| Step: 2
Training loss: 1.1400223799232052
Validation loss: 2.5198311087612417

Epoch: 6| Step: 3
Training loss: 1.4379334003746362
Validation loss: 2.473956882409457

Epoch: 6| Step: 4
Training loss: 1.6664574094377849
Validation loss: 2.466163568053615

Epoch: 6| Step: 5
Training loss: 1.8389410894436875
Validation loss: 2.4679663979846276

Epoch: 6| Step: 6
Training loss: 1.5886545443427864
Validation loss: 2.4718875584080386

Epoch: 6| Step: 7
Training loss: 2.0999822525001086
Validation loss: 2.4712264761917027

Epoch: 6| Step: 8
Training loss: 1.9983981989857764
Validation loss: 2.512850730291119

Epoch: 6| Step: 9
Training loss: 2.210303117841917
Validation loss: 2.504651050615743

Epoch: 6| Step: 10
Training loss: 2.3054971598183904
Validation loss: 2.4968208284831577

Epoch: 6| Step: 11
Training loss: 2.458173574224246
Validation loss: 2.4794803201923035

Epoch: 6| Step: 12
Training loss: 1.5908972696385317
Validation loss: 2.4760955306118757

Epoch: 6| Step: 13
Training loss: 2.0299507093787583
Validation loss: 2.468861903298171

Epoch: 333| Step: 0
Training loss: 2.0985069325904955
Validation loss: 2.4523421251174744

Epoch: 6| Step: 1
Training loss: 2.205988544825177
Validation loss: 2.4602522930523114

Epoch: 6| Step: 2
Training loss: 1.9206088477615253
Validation loss: 2.4712304237399465

Epoch: 6| Step: 3
Training loss: 1.6162715658473519
Validation loss: 2.492229816073529

Epoch: 6| Step: 4
Training loss: 1.6866431710085612
Validation loss: 2.5167848823479124

Epoch: 6| Step: 5
Training loss: 1.8987108826516106
Validation loss: 2.535566001972355

Epoch: 6| Step: 6
Training loss: 1.9956691462039067
Validation loss: 2.5619665614096743

Epoch: 6| Step: 7
Training loss: 1.6629789164543414
Validation loss: 2.546219669274379

Epoch: 6| Step: 8
Training loss: 1.8907968742494872
Validation loss: 2.548385624578795

Epoch: 6| Step: 9
Training loss: 1.9017010803630403
Validation loss: 2.5202160439398678

Epoch: 6| Step: 10
Training loss: 1.93018695993079
Validation loss: 2.5701136797193427

Epoch: 6| Step: 11
Training loss: 1.6402285142191078
Validation loss: 2.5279307324963556

Epoch: 6| Step: 12
Training loss: 1.5379715359240236
Validation loss: 2.559774205114712

Epoch: 6| Step: 13
Training loss: 1.7241031167198584
Validation loss: 2.549313055022976

Epoch: 334| Step: 0
Training loss: 1.739306269832231
Validation loss: 2.530530097220148

Epoch: 6| Step: 1
Training loss: 1.9308800352219455
Validation loss: 2.511748286538805

Epoch: 6| Step: 2
Training loss: 1.992033709405531
Validation loss: 2.5199759472854613

Epoch: 6| Step: 3
Training loss: 1.5301845502812108
Validation loss: 2.5154184292158424

Epoch: 6| Step: 4
Training loss: 2.070577122312956
Validation loss: 2.528445719465632

Epoch: 6| Step: 5
Training loss: 1.0613774933633529
Validation loss: 2.517820454632609

Epoch: 6| Step: 6
Training loss: 2.7492573342159132
Validation loss: 2.5688174459322957

Epoch: 6| Step: 7
Training loss: 1.789545651958031
Validation loss: 2.5408249435795085

Epoch: 6| Step: 8
Training loss: 1.5072062958762007
Validation loss: 2.544835785712225

Epoch: 6| Step: 9
Training loss: 2.1871940398823613
Validation loss: 2.567943992917071

Epoch: 6| Step: 10
Training loss: 1.4431010055034128
Validation loss: 2.5452033799902742

Epoch: 6| Step: 11
Training loss: 1.3492349417134024
Validation loss: 2.545937675756072

Epoch: 6| Step: 12
Training loss: 1.91703279425997
Validation loss: 2.5350735204645574

Epoch: 6| Step: 13
Training loss: 2.1128897313070074
Validation loss: 2.5335432896278074

Epoch: 335| Step: 0
Training loss: 1.7389658062179694
Validation loss: 2.5052301692738

Epoch: 6| Step: 1
Training loss: 1.4596472770034374
Validation loss: 2.5018246349938855

Epoch: 6| Step: 2
Training loss: 2.053686325934316
Validation loss: 2.483047066473799

Epoch: 6| Step: 3
Training loss: 1.838811305286373
Validation loss: 2.5009508708809496

Epoch: 6| Step: 4
Training loss: 1.5940566422415223
Validation loss: 2.460940826252299

Epoch: 6| Step: 5
Training loss: 1.9247555119209727
Validation loss: 2.490756892816714

Epoch: 6| Step: 6
Training loss: 1.701685445808311
Validation loss: 2.468979531092186

Epoch: 6| Step: 7
Training loss: 1.6180292417526787
Validation loss: 2.5260728473639698

Epoch: 6| Step: 8
Training loss: 1.7331854375074711
Validation loss: 2.551937485763795

Epoch: 6| Step: 9
Training loss: 1.5354862392334372
Validation loss: 2.5277390168493765

Epoch: 6| Step: 10
Training loss: 1.9708478135376097
Validation loss: 2.5836594027165827

Epoch: 6| Step: 11
Training loss: 2.1309958745521773
Validation loss: 2.610051963844261

Epoch: 6| Step: 12
Training loss: 1.8087132457697581
Validation loss: 2.610985812659638

Epoch: 6| Step: 13
Training loss: 1.9603490668494998
Validation loss: 2.6117921700799935

Epoch: 336| Step: 0
Training loss: 1.1779123048507054
Validation loss: 2.6088066395787686

Epoch: 6| Step: 1
Training loss: 1.6573206482021008
Validation loss: 2.62662201677252

Epoch: 6| Step: 2
Training loss: 2.5342099814542873
Validation loss: 2.5978863377599257

Epoch: 6| Step: 3
Training loss: 1.9312646266543858
Validation loss: 2.587231868175003

Epoch: 6| Step: 4
Training loss: 1.719146197344021
Validation loss: 2.5987050398716773

Epoch: 6| Step: 5
Training loss: 1.7834751886770697
Validation loss: 2.5912601746038737

Epoch: 6| Step: 6
Training loss: 1.8577234322233527
Validation loss: 2.5689163822391667

Epoch: 6| Step: 7
Training loss: 1.7018410979167808
Validation loss: 2.5608095470316443

Epoch: 6| Step: 8
Training loss: 1.897436875108783
Validation loss: 2.5269599163195906

Epoch: 6| Step: 9
Training loss: 1.9810776837140718
Validation loss: 2.5351612657243656

Epoch: 6| Step: 10
Training loss: 1.4966096710589987
Validation loss: 2.4987083436166277

Epoch: 6| Step: 11
Training loss: 1.8770969109532816
Validation loss: 2.4961905383556044

Epoch: 6| Step: 12
Training loss: 1.5543000778468195
Validation loss: 2.5108317167941805

Epoch: 6| Step: 13
Training loss: 1.6213348577051985
Validation loss: 2.502888441397128

Epoch: 337| Step: 0
Training loss: 2.429360714245506
Validation loss: 2.574138788689979

Epoch: 6| Step: 1
Training loss: 1.5412145759366507
Validation loss: 2.572999301669632

Epoch: 6| Step: 2
Training loss: 1.566039767879695
Validation loss: 2.623275175027548

Epoch: 6| Step: 3
Training loss: 1.3894033316376129
Validation loss: 2.6682372286246183

Epoch: 6| Step: 4
Training loss: 1.7004009475236943
Validation loss: 2.61585759777406

Epoch: 6| Step: 5
Training loss: 1.3089694266744991
Validation loss: 2.6416634543566824

Epoch: 6| Step: 6
Training loss: 1.807796162339408
Validation loss: 2.6246570787022945

Epoch: 6| Step: 7
Training loss: 2.3659940928033136
Validation loss: 2.6250684744365915

Epoch: 6| Step: 8
Training loss: 1.4251008382889936
Validation loss: 2.607248166664165

Epoch: 6| Step: 9
Training loss: 2.0675127784121927
Validation loss: 2.5644378622917463

Epoch: 6| Step: 10
Training loss: 1.1206625398219106
Validation loss: 2.5232574115184354

Epoch: 6| Step: 11
Training loss: 1.4343596447224543
Validation loss: 2.491903434357095

Epoch: 6| Step: 12
Training loss: 2.085681228039788
Validation loss: 2.4466644547302616

Epoch: 6| Step: 13
Training loss: 2.1590790917105087
Validation loss: 2.4398143736004925

Epoch: 338| Step: 0
Training loss: 1.5450029701525338
Validation loss: 2.4424323039205444

Epoch: 6| Step: 1
Training loss: 2.013502556002794
Validation loss: 2.4355483352097957

Epoch: 6| Step: 2
Training loss: 2.05826306808736
Validation loss: 2.447333608679088

Epoch: 6| Step: 3
Training loss: 2.410490386899411
Validation loss: 2.465786156748282

Epoch: 6| Step: 4
Training loss: 1.9430629484981108
Validation loss: 2.4348258159722556

Epoch: 6| Step: 5
Training loss: 1.9784472981862418
Validation loss: 2.450494396514391

Epoch: 6| Step: 6
Training loss: 1.9194857003905776
Validation loss: 2.5686940641106233

Epoch: 6| Step: 7
Training loss: 1.3398965986411224
Validation loss: 2.561323151518889

Epoch: 6| Step: 8
Training loss: 1.7436301925136646
Validation loss: 2.556092306681129

Epoch: 6| Step: 9
Training loss: 1.5098104729351198
Validation loss: 2.584828210874027

Epoch: 6| Step: 10
Training loss: 2.2742894205260353
Validation loss: 2.5650152252320453

Epoch: 6| Step: 11
Training loss: 1.9250820043362282
Validation loss: 2.5407826392334947

Epoch: 6| Step: 12
Training loss: 1.015033667151664
Validation loss: 2.5225622275181347

Epoch: 6| Step: 13
Training loss: 1.239486637137314
Validation loss: 2.5065925300656273

Epoch: 339| Step: 0
Training loss: 1.5365096089056123
Validation loss: 2.5129281667645342

Epoch: 6| Step: 1
Training loss: 1.2635158813982004
Validation loss: 2.4675480375216425

Epoch: 6| Step: 2
Training loss: 1.688089691549865
Validation loss: 2.4832743399822004

Epoch: 6| Step: 3
Training loss: 1.8763079214082456
Validation loss: 2.4431544603451893

Epoch: 6| Step: 4
Training loss: 2.3755628019368475
Validation loss: 2.4376249851885183

Epoch: 6| Step: 5
Training loss: 2.093870928104694
Validation loss: 2.43654701970677

Epoch: 6| Step: 6
Training loss: 1.7069750324830137
Validation loss: 2.4531548694646834

Epoch: 6| Step: 7
Training loss: 1.6034599415337427
Validation loss: 2.4688347427696176

Epoch: 6| Step: 8
Training loss: 1.526275495336538
Validation loss: 2.5273145057837616

Epoch: 6| Step: 9
Training loss: 2.0239068742520074
Validation loss: 2.5467546352659967

Epoch: 6| Step: 10
Training loss: 1.594209791691268
Validation loss: 2.5810819218603918

Epoch: 6| Step: 11
Training loss: 2.265443570995371
Validation loss: 2.5503744878855814

Epoch: 6| Step: 12
Training loss: 1.6625200743646391
Validation loss: 2.5711594551474732

Epoch: 6| Step: 13
Training loss: 1.8277737532741734
Validation loss: 2.5491810443477285

Epoch: 340| Step: 0
Training loss: 1.459048431910386
Validation loss: 2.5454762524189105

Epoch: 6| Step: 1
Training loss: 1.7307794778471606
Validation loss: 2.571410929023933

Epoch: 6| Step: 2
Training loss: 1.3729014855540655
Validation loss: 2.529920880534312

Epoch: 6| Step: 3
Training loss: 1.4236922336611708
Validation loss: 2.5398368710976515

Epoch: 6| Step: 4
Training loss: 1.8292406378570711
Validation loss: 2.523233647571589

Epoch: 6| Step: 5
Training loss: 1.7100701071215625
Validation loss: 2.522888265544908

Epoch: 6| Step: 6
Training loss: 1.7241981162879212
Validation loss: 2.4721882052230297

Epoch: 6| Step: 7
Training loss: 1.1406533747239895
Validation loss: 2.5332477676430454

Epoch: 6| Step: 8
Training loss: 2.199092448048116
Validation loss: 2.547961028849525

Epoch: 6| Step: 9
Training loss: 1.9218606715714923
Validation loss: 2.564548991324836

Epoch: 6| Step: 10
Training loss: 1.4738436093744136
Validation loss: 2.5650615914518085

Epoch: 6| Step: 11
Training loss: 1.9507291213202427
Validation loss: 2.514277703569963

Epoch: 6| Step: 12
Training loss: 2.4172921412676067
Validation loss: 2.539555334531945

Epoch: 6| Step: 13
Training loss: 1.2993424164621081
Validation loss: 2.503639671191658

Epoch: 341| Step: 0
Training loss: 2.164291755293743
Validation loss: 2.53385814471715

Epoch: 6| Step: 1
Training loss: 1.7164454181770339
Validation loss: 2.5188965779227206

Epoch: 6| Step: 2
Training loss: 1.362527371052885
Validation loss: 2.5558077254710763

Epoch: 6| Step: 3
Training loss: 1.890595995467729
Validation loss: 2.588069501728731

Epoch: 6| Step: 4
Training loss: 1.8205964354066044
Validation loss: 2.5897819316039583

Epoch: 6| Step: 5
Training loss: 1.2475264871724765
Validation loss: 2.575698388706521

Epoch: 6| Step: 6
Training loss: 1.9341598760882026
Validation loss: 2.593291123331889

Epoch: 6| Step: 7
Training loss: 1.85114801974682
Validation loss: 2.55164340113476

Epoch: 6| Step: 8
Training loss: 2.08466954931034
Validation loss: 2.5505623833079696

Epoch: 6| Step: 9
Training loss: 1.1301940647519564
Validation loss: 2.52528693076499

Epoch: 6| Step: 10
Training loss: 1.8161022301017815
Validation loss: 2.5092042604398586

Epoch: 6| Step: 11
Training loss: 1.5440544847451376
Validation loss: 2.488593177267621

Epoch: 6| Step: 12
Training loss: 1.9769341643335654
Validation loss: 2.5027785675432392

Epoch: 6| Step: 13
Training loss: 1.7351593443505025
Validation loss: 2.4893402129869795

Epoch: 342| Step: 0
Training loss: 1.8253303751358423
Validation loss: 2.4684888484301926

Epoch: 6| Step: 1
Training loss: 2.2248703265175065
Validation loss: 2.474683608437306

Epoch: 6| Step: 2
Training loss: 1.41927813140206
Validation loss: 2.5054847078416853

Epoch: 6| Step: 3
Training loss: 1.5770790486380435
Validation loss: 2.533549735798259

Epoch: 6| Step: 4
Training loss: 1.2973204617510299
Validation loss: 2.5125782209527827

Epoch: 6| Step: 5
Training loss: 1.6661897771759595
Validation loss: 2.5587126027231646

Epoch: 6| Step: 6
Training loss: 1.8417838006147158
Validation loss: 2.548286374567792

Epoch: 6| Step: 7
Training loss: 1.6445345844588375
Validation loss: 2.5330921267404634

Epoch: 6| Step: 8
Training loss: 1.6434860713822288
Validation loss: 2.528128783573295

Epoch: 6| Step: 9
Training loss: 1.6949861977164353
Validation loss: 2.5453087138691677

Epoch: 6| Step: 10
Training loss: 1.9276414286459636
Validation loss: 2.545322795524718

Epoch: 6| Step: 11
Training loss: 2.045991779829201
Validation loss: 2.542872843616084

Epoch: 6| Step: 12
Training loss: 1.851255560434505
Validation loss: 2.5077845095521245

Epoch: 6| Step: 13
Training loss: 1.1238978072949384
Validation loss: 2.512755753894367

Epoch: 343| Step: 0
Training loss: 1.9409922843477094
Validation loss: 2.524648259783378

Epoch: 6| Step: 1
Training loss: 1.7566654786329698
Validation loss: 2.5334200877677477

Epoch: 6| Step: 2
Training loss: 1.581836829778116
Validation loss: 2.522087507657787

Epoch: 6| Step: 3
Training loss: 1.735345792143614
Validation loss: 2.601880730915806

Epoch: 6| Step: 4
Training loss: 1.8440452597891293
Validation loss: 2.5553748618620387

Epoch: 6| Step: 5
Training loss: 1.5446760944220885
Validation loss: 2.5558646908894804

Epoch: 6| Step: 6
Training loss: 2.222588348692335
Validation loss: 2.5460424954348224

Epoch: 6| Step: 7
Training loss: 1.120462060200067
Validation loss: 2.5404939030368467

Epoch: 6| Step: 8
Training loss: 1.5961017087494305
Validation loss: 2.526097599209946

Epoch: 6| Step: 9
Training loss: 1.795774106010075
Validation loss: 2.5262118147868238

Epoch: 6| Step: 10
Training loss: 1.563937632085507
Validation loss: 2.527168216731598

Epoch: 6| Step: 11
Training loss: 1.7436565141673384
Validation loss: 2.512393811260914

Epoch: 6| Step: 12
Training loss: 1.4452270482551524
Validation loss: 2.550523262939376

Epoch: 6| Step: 13
Training loss: 1.2943691264948993
Validation loss: 2.5168030312416625

Epoch: 344| Step: 0
Training loss: 0.9929881132265309
Validation loss: 2.490619744295696

Epoch: 6| Step: 1
Training loss: 1.7767640897772687
Validation loss: 2.524701788889745

Epoch: 6| Step: 2
Training loss: 1.5096591847788068
Validation loss: 2.521527869856273

Epoch: 6| Step: 3
Training loss: 1.2533097794446701
Validation loss: 2.5164053676019016

Epoch: 6| Step: 4
Training loss: 2.061003517788287
Validation loss: 2.5452096873439003

Epoch: 6| Step: 5
Training loss: 1.8631682611591658
Validation loss: 2.5242500374863175

Epoch: 6| Step: 6
Training loss: 1.8456469976378274
Validation loss: 2.5597407053722105

Epoch: 6| Step: 7
Training loss: 1.0303960211989487
Validation loss: 2.5861526891446154

Epoch: 6| Step: 8
Training loss: 1.9707775876936595
Validation loss: 2.535063237863032

Epoch: 6| Step: 9
Training loss: 1.897381586996399
Validation loss: 2.5588182190716817

Epoch: 6| Step: 10
Training loss: 1.6828445927385351
Validation loss: 2.539495640514057

Epoch: 6| Step: 11
Training loss: 1.8829259561252003
Validation loss: 2.5377672696726488

Epoch: 6| Step: 12
Training loss: 1.8612250092354934
Validation loss: 2.5270591233601487

Epoch: 6| Step: 13
Training loss: 1.7526770279482429
Validation loss: 2.5457518817922504

Epoch: 345| Step: 0
Training loss: 1.7230125975588326
Validation loss: 2.550612564312096

Epoch: 6| Step: 1
Training loss: 1.7456313508789267
Validation loss: 2.5224241066219215

Epoch: 6| Step: 2
Training loss: 1.5511134486073026
Validation loss: 2.556035626165642

Epoch: 6| Step: 3
Training loss: 1.6562144437608084
Validation loss: 2.468719755864692

Epoch: 6| Step: 4
Training loss: 2.0371670737649095
Validation loss: 2.502476260555037

Epoch: 6| Step: 5
Training loss: 1.6124786523396515
Validation loss: 2.4782766673372376

Epoch: 6| Step: 6
Training loss: 1.7421007348594826
Validation loss: 2.52546152485911

Epoch: 6| Step: 7
Training loss: 1.218151826049353
Validation loss: 2.521834999406961

Epoch: 6| Step: 8
Training loss: 1.3375524385814561
Validation loss: 2.5426594145144157

Epoch: 6| Step: 9
Training loss: 1.6318210347726148
Validation loss: 2.528146497385915

Epoch: 6| Step: 10
Training loss: 2.027667128216345
Validation loss: 2.5725365150684993

Epoch: 6| Step: 11
Training loss: 1.5097462799688433
Validation loss: 2.5714348195015218

Epoch: 6| Step: 12
Training loss: 1.8482432813982814
Validation loss: 2.586333237837744

Epoch: 6| Step: 13
Training loss: 1.6134214178713875
Validation loss: 2.5970472190725076

Epoch: 346| Step: 0
Training loss: 2.0128648178486457
Validation loss: 2.5976610532634945

Epoch: 6| Step: 1
Training loss: 1.858624859966817
Validation loss: 2.5917291543752152

Epoch: 6| Step: 2
Training loss: 1.2659664870733436
Validation loss: 2.5944975116683744

Epoch: 6| Step: 3
Training loss: 1.659717887897587
Validation loss: 2.578858242379668

Epoch: 6| Step: 4
Training loss: 1.5325172007654888
Validation loss: 2.609362132027395

Epoch: 6| Step: 5
Training loss: 1.5229165776048765
Validation loss: 2.559483419566457

Epoch: 6| Step: 6
Training loss: 1.4543819118805998
Validation loss: 2.52269684400648

Epoch: 6| Step: 7
Training loss: 1.5018851831593367
Validation loss: 2.5227577860853856

Epoch: 6| Step: 8
Training loss: 1.3802925899866911
Validation loss: 2.4614385750701735

Epoch: 6| Step: 9
Training loss: 1.1754502752602405
Validation loss: 2.506342995076515

Epoch: 6| Step: 10
Training loss: 1.8491677035855583
Validation loss: 2.462526742754467

Epoch: 6| Step: 11
Training loss: 1.405331672060948
Validation loss: 2.501121301321907

Epoch: 6| Step: 12
Training loss: 1.936083368035426
Validation loss: 2.479057042452365

Epoch: 6| Step: 13
Training loss: 2.1059922963406335
Validation loss: 2.499000500514996

Epoch: 347| Step: 0
Training loss: 1.7179927198013754
Validation loss: 2.517266482332178

Epoch: 6| Step: 1
Training loss: 1.5163011910523234
Validation loss: 2.550088777742011

Epoch: 6| Step: 2
Training loss: 1.9468502722772534
Validation loss: 2.547312076876094

Epoch: 6| Step: 3
Training loss: 1.652080325508346
Validation loss: 2.568199177860053

Epoch: 6| Step: 4
Training loss: 1.7920404162660182
Validation loss: 2.593143560760386

Epoch: 6| Step: 5
Training loss: 1.8983760870901973
Validation loss: 2.6022254015273947

Epoch: 6| Step: 6
Training loss: 1.7701668850302064
Validation loss: 2.5858551811338613

Epoch: 6| Step: 7
Training loss: 1.313388841387087
Validation loss: 2.553862661178566

Epoch: 6| Step: 8
Training loss: 1.2663153190372427
Validation loss: 2.5710207070726385

Epoch: 6| Step: 9
Training loss: 1.8921725662360342
Validation loss: 2.5631264719400346

Epoch: 6| Step: 10
Training loss: 1.9407246734527268
Validation loss: 2.52842091202692

Epoch: 6| Step: 11
Training loss: 1.4915763841866367
Validation loss: 2.530866067913516

Epoch: 6| Step: 12
Training loss: 1.4806019262639085
Validation loss: 2.5418800566683712

Epoch: 6| Step: 13
Training loss: 1.2078393002950432
Validation loss: 2.551115799794151

Epoch: 348| Step: 0
Training loss: 1.6743728659325385
Validation loss: 2.5626635925672807

Epoch: 6| Step: 1
Training loss: 1.7880352019315944
Validation loss: 2.568366228875321

Epoch: 6| Step: 2
Training loss: 1.2011466170966116
Validation loss: 2.5438871429489947

Epoch: 6| Step: 3
Training loss: 1.2960877844343808
Validation loss: 2.5556466016123123

Epoch: 6| Step: 4
Training loss: 1.809398167384436
Validation loss: 2.574941260707959

Epoch: 6| Step: 5
Training loss: 1.4226859159272673
Validation loss: 2.5218266088167356

Epoch: 6| Step: 6
Training loss: 1.5103318113848219
Validation loss: 2.5154427882956023

Epoch: 6| Step: 7
Training loss: 1.4519034552936543
Validation loss: 2.539900593476971

Epoch: 6| Step: 8
Training loss: 1.6928883461723638
Validation loss: 2.5408965934926453

Epoch: 6| Step: 9
Training loss: 1.7482393126879083
Validation loss: 2.5555605704032605

Epoch: 6| Step: 10
Training loss: 2.2739239463938
Validation loss: 2.520638124668398

Epoch: 6| Step: 11
Training loss: 1.1749800173095115
Validation loss: 2.539684888411942

Epoch: 6| Step: 12
Training loss: 1.6600672080900751
Validation loss: 2.54955193971309

Epoch: 6| Step: 13
Training loss: 1.5784578633283501
Validation loss: 2.5400663768175265

Epoch: 349| Step: 0
Training loss: 1.7188694305540526
Validation loss: 2.55482241461932

Epoch: 6| Step: 1
Training loss: 1.1795758327154482
Validation loss: 2.561740902371268

Epoch: 6| Step: 2
Training loss: 1.594277537681875
Validation loss: 2.5615041084641326

Epoch: 6| Step: 3
Training loss: 1.6325098514697771
Validation loss: 2.5564504561915444

Epoch: 6| Step: 4
Training loss: 1.6833960467953497
Validation loss: 2.563783053044486

Epoch: 6| Step: 5
Training loss: 1.7547578167434854
Validation loss: 2.5692882255513547

Epoch: 6| Step: 6
Training loss: 1.5682086420843473
Validation loss: 2.5638323010855846

Epoch: 6| Step: 7
Training loss: 1.3696101495067037
Validation loss: 2.580767054172228

Epoch: 6| Step: 8
Training loss: 1.7634638159824945
Validation loss: 2.551632671399673

Epoch: 6| Step: 9
Training loss: 2.3096220305057726
Validation loss: 2.538465607737308

Epoch: 6| Step: 10
Training loss: 1.5746438183775526
Validation loss: 2.5634795851916703

Epoch: 6| Step: 11
Training loss: 1.3221368318432076
Validation loss: 2.5214410842658097

Epoch: 6| Step: 12
Training loss: 1.7706321003586705
Validation loss: 2.5616114711916436

Epoch: 6| Step: 13
Training loss: 1.5646909992475257
Validation loss: 2.5554404670489803

Epoch: 350| Step: 0
Training loss: 1.8603796288483267
Validation loss: 2.6267069761536437

Epoch: 6| Step: 1
Training loss: 1.3924492860664506
Validation loss: 2.566245644477905

Epoch: 6| Step: 2
Training loss: 1.531644030885575
Validation loss: 2.5632984499134817

Epoch: 6| Step: 3
Training loss: 1.8526629304471847
Validation loss: 2.5618351329671154

Epoch: 6| Step: 4
Training loss: 1.4866205196032443
Validation loss: 2.547408549271125

Epoch: 6| Step: 5
Training loss: 1.3363881828864626
Validation loss: 2.4403879223898435

Epoch: 6| Step: 6
Training loss: 1.6286732166193447
Validation loss: 2.47629718181625

Epoch: 6| Step: 7
Training loss: 1.8869751307835396
Validation loss: 2.4512535618599407

Epoch: 6| Step: 8
Training loss: 1.5057044438122937
Validation loss: 2.442857462567739

Epoch: 6| Step: 9
Training loss: 1.485172097865537
Validation loss: 2.4677129088188017

Epoch: 6| Step: 10
Training loss: 1.4478375621382742
Validation loss: 2.475603738353366

Epoch: 6| Step: 11
Training loss: 1.8671347638587612
Validation loss: 2.496022461702483

Epoch: 6| Step: 12
Training loss: 1.6822335751860247
Validation loss: 2.502037362579767

Epoch: 6| Step: 13
Training loss: 1.6659596692042948
Validation loss: 2.5505411328118193

Epoch: 351| Step: 0
Training loss: 1.1891718690077169
Validation loss: 2.5904313883660444

Epoch: 6| Step: 1
Training loss: 2.124747654012401
Validation loss: 2.6112341891245765

Epoch: 6| Step: 2
Training loss: 1.7417457602153505
Validation loss: 2.527368080615574

Epoch: 6| Step: 3
Training loss: 1.8873852802302087
Validation loss: 2.561415062707321

Epoch: 6| Step: 4
Training loss: 1.2426199010489778
Validation loss: 2.5458255001848733

Epoch: 6| Step: 5
Training loss: 1.800513125502339
Validation loss: 2.5390843160621257

Epoch: 6| Step: 6
Training loss: 1.516858729403718
Validation loss: 2.5221498745313675

Epoch: 6| Step: 7
Training loss: 1.7364626854847918
Validation loss: 2.5173650532541796

Epoch: 6| Step: 8
Training loss: 1.847082714399387
Validation loss: 2.4768684270455346

Epoch: 6| Step: 9
Training loss: 1.327495605332164
Validation loss: 2.479900593406087

Epoch: 6| Step: 10
Training loss: 1.238385602242415
Validation loss: 2.5059840190410365

Epoch: 6| Step: 11
Training loss: 1.3823011066926043
Validation loss: 2.5060353701704225

Epoch: 6| Step: 12
Training loss: 1.0245187885875717
Validation loss: 2.4898833302915917

Epoch: 6| Step: 13
Training loss: 1.7145564157899955
Validation loss: 2.512817371940721

Epoch: 352| Step: 0
Training loss: 1.263188501089714
Validation loss: 2.528873693936016

Epoch: 6| Step: 1
Training loss: 1.7606956742374424
Validation loss: 2.549639576329344

Epoch: 6| Step: 2
Training loss: 1.3294995095466207
Validation loss: 2.5716967580035632

Epoch: 6| Step: 3
Training loss: 1.4637038207811996
Validation loss: 2.4774142785099365

Epoch: 6| Step: 4
Training loss: 1.8523827518522573
Validation loss: 2.4959159552941537

Epoch: 6| Step: 5
Training loss: 1.6694420911645762
Validation loss: 2.529828869657271

Epoch: 6| Step: 6
Training loss: 1.7557704338656486
Validation loss: 2.5540636488865505

Epoch: 6| Step: 7
Training loss: 1.3472151324597947
Validation loss: 2.574902101772959

Epoch: 6| Step: 8
Training loss: 1.8695290539573592
Validation loss: 2.609088051983398

Epoch: 6| Step: 9
Training loss: 1.8813525986179567
Validation loss: 2.5833414190432435

Epoch: 6| Step: 10
Training loss: 1.8045146908942915
Validation loss: 2.600678653666273

Epoch: 6| Step: 11
Training loss: 1.178122284175262
Validation loss: 2.5780723874667313

Epoch: 6| Step: 12
Training loss: 1.6054745416467158
Validation loss: 2.5545064568409677

Epoch: 6| Step: 13
Training loss: 1.7249227478862748
Validation loss: 2.545118073058402

Epoch: 353| Step: 0
Training loss: 1.8945632145338265
Validation loss: 2.5754823029313174

Epoch: 6| Step: 1
Training loss: 1.8083237514447081
Validation loss: 2.6045847264735023

Epoch: 6| Step: 2
Training loss: 1.3031975924903452
Validation loss: 2.590363394271431

Epoch: 6| Step: 3
Training loss: 1.607842613953971
Validation loss: 2.5582406690965356

Epoch: 6| Step: 4
Training loss: 1.6228515654382671
Validation loss: 2.540524246826865

Epoch: 6| Step: 5
Training loss: 1.4174384184147715
Validation loss: 2.4607564062264897

Epoch: 6| Step: 6
Training loss: 0.917338183111116
Validation loss: 2.518702738959811

Epoch: 6| Step: 7
Training loss: 1.3219274992922303
Validation loss: 2.481419354607892

Epoch: 6| Step: 8
Training loss: 1.7967543188287078
Validation loss: 2.4519731040384927

Epoch: 6| Step: 9
Training loss: 1.216811668342809
Validation loss: 2.4946792327668694

Epoch: 6| Step: 10
Training loss: 1.3507669124868293
Validation loss: 2.52510884683002

Epoch: 6| Step: 11
Training loss: 1.4833238594238398
Validation loss: 2.5823554731402867

Epoch: 6| Step: 12
Training loss: 1.5914897973551225
Validation loss: 2.6018417559822917

Epoch: 6| Step: 13
Training loss: 2.337282335887423
Validation loss: 2.681869804515383

Epoch: 354| Step: 0
Training loss: 1.64116725134869
Validation loss: 2.63897204909436

Epoch: 6| Step: 1
Training loss: 1.5493058650021558
Validation loss: 2.6485780961818937

Epoch: 6| Step: 2
Training loss: 1.5117950814466004
Validation loss: 2.57543387168178

Epoch: 6| Step: 3
Training loss: 1.63122715258036
Validation loss: 2.574274281513983

Epoch: 6| Step: 4
Training loss: 1.6732844178521276
Validation loss: 2.5309387847725056

Epoch: 6| Step: 5
Training loss: 1.2386521226263816
Validation loss: 2.559757206922032

Epoch: 6| Step: 6
Training loss: 1.0943021198189775
Validation loss: 2.547776450798102

Epoch: 6| Step: 7
Training loss: 1.883427183237867
Validation loss: 2.49443494174972

Epoch: 6| Step: 8
Training loss: 1.40714510934081
Validation loss: 2.5639310539255145

Epoch: 6| Step: 9
Training loss: 1.4227223648553913
Validation loss: 2.5134624639986156

Epoch: 6| Step: 10
Training loss: 1.9253352579246334
Validation loss: 2.585745720796457

Epoch: 6| Step: 11
Training loss: 1.0876578008232136
Validation loss: 2.565729478760127

Epoch: 6| Step: 12
Training loss: 1.7012798568493694
Validation loss: 2.586991309566325

Epoch: 6| Step: 13
Training loss: 1.4570866387605832
Validation loss: 2.516858637563716

Epoch: 355| Step: 0
Training loss: 1.3980711131993826
Validation loss: 2.5078196619551485

Epoch: 6| Step: 1
Training loss: 1.477858443954644
Validation loss: 2.5137357864218317

Epoch: 6| Step: 2
Training loss: 1.9088494759190178
Validation loss: 2.543230003301069

Epoch: 6| Step: 3
Training loss: 1.5181765757155092
Validation loss: 2.5252594880576424

Epoch: 6| Step: 4
Training loss: 1.0447208959939627
Validation loss: 2.5178664905229

Epoch: 6| Step: 5
Training loss: 1.8933909966638054
Validation loss: 2.4945844645189923

Epoch: 6| Step: 6
Training loss: 0.9288706356372646
Validation loss: 2.5603146422265577

Epoch: 6| Step: 7
Training loss: 2.006040392232254
Validation loss: 2.4959784427887697

Epoch: 6| Step: 8
Training loss: 1.634740248178931
Validation loss: 2.6007762709883453

Epoch: 6| Step: 9
Training loss: 1.8581987394963162
Validation loss: 2.6065382928367917

Epoch: 6| Step: 10
Training loss: 1.5095368640109401
Validation loss: 2.631549317105275

Epoch: 6| Step: 11
Training loss: 1.3127256835184826
Validation loss: 2.609580802796467

Epoch: 6| Step: 12
Training loss: 1.6829756378749705
Validation loss: 2.619603483343942

Epoch: 6| Step: 13
Training loss: 1.359054176794526
Validation loss: 2.629323214924799

Epoch: 356| Step: 0
Training loss: 1.4701833021618653
Validation loss: 2.516118982438031

Epoch: 6| Step: 1
Training loss: 1.3750211540675659
Validation loss: 2.5227497214647094

Epoch: 6| Step: 2
Training loss: 1.7166131347655076
Validation loss: 2.478515336417684

Epoch: 6| Step: 3
Training loss: 1.2967491088799408
Validation loss: 2.475063138856439

Epoch: 6| Step: 4
Training loss: 1.6943384000117192
Validation loss: 2.4971072070285776

Epoch: 6| Step: 5
Training loss: 1.2347073650765463
Validation loss: 2.4946638458148676

Epoch: 6| Step: 6
Training loss: 1.0872566389318425
Validation loss: 2.493103313490389

Epoch: 6| Step: 7
Training loss: 1.3253278110863702
Validation loss: 2.507333030301378

Epoch: 6| Step: 8
Training loss: 1.3622233048608103
Validation loss: 2.49515394369127

Epoch: 6| Step: 9
Training loss: 1.7071170043355843
Validation loss: 2.4961343044594275

Epoch: 6| Step: 10
Training loss: 1.8220963149004845
Validation loss: 2.4604895289972886

Epoch: 6| Step: 11
Training loss: 1.7345492988501658
Validation loss: 2.5244663294602265

Epoch: 6| Step: 12
Training loss: 1.932737095193804
Validation loss: 2.5548427973994663

Epoch: 6| Step: 13
Training loss: 1.3950607192248288
Validation loss: 2.553212213291219

Epoch: 357| Step: 0
Training loss: 1.3876903729817305
Validation loss: 2.577124954623537

Epoch: 6| Step: 1
Training loss: 1.6600930594591536
Validation loss: 2.5808647163789655

Epoch: 6| Step: 2
Training loss: 1.325478238943415
Validation loss: 2.6090888820186593

Epoch: 6| Step: 3
Training loss: 1.2322562177411824
Validation loss: 2.5294321856150574

Epoch: 6| Step: 4
Training loss: 1.1241878120878752
Validation loss: 2.5102140152259804

Epoch: 6| Step: 5
Training loss: 1.9362598264776099
Validation loss: 2.520244755615897

Epoch: 6| Step: 6
Training loss: 1.5039801245045712
Validation loss: 2.5157224742888893

Epoch: 6| Step: 7
Training loss: 1.8137526294313244
Validation loss: 2.5142464661528012

Epoch: 6| Step: 8
Training loss: 1.1789570751319414
Validation loss: 2.5476721391803334

Epoch: 6| Step: 9
Training loss: 2.007093723938871
Validation loss: 2.5025219118147914

Epoch: 6| Step: 10
Training loss: 1.319710001517672
Validation loss: 2.549520199334769

Epoch: 6| Step: 11
Training loss: 1.2066181550013078
Validation loss: 2.5556080255327975

Epoch: 6| Step: 12
Training loss: 1.285204483564851
Validation loss: 2.565089956073158

Epoch: 6| Step: 13
Training loss: 1.7969380906680468
Validation loss: 2.544659827230748

Epoch: 358| Step: 0
Training loss: 1.8285995910702486
Validation loss: 2.529036633470675

Epoch: 6| Step: 1
Training loss: 1.6726906471332588
Validation loss: 2.5851957903585974

Epoch: 6| Step: 2
Training loss: 1.330072568190026
Validation loss: 2.5355559094282314

Epoch: 6| Step: 3
Training loss: 1.4154341141631657
Validation loss: 2.5412696830611456

Epoch: 6| Step: 4
Training loss: 1.5834804349460891
Validation loss: 2.6005965416587373

Epoch: 6| Step: 5
Training loss: 1.3009048265747503
Validation loss: 2.556652755844522

Epoch: 6| Step: 6
Training loss: 1.4110614692578451
Validation loss: 2.5455605951321574

Epoch: 6| Step: 7
Training loss: 1.0986960702274657
Validation loss: 2.572468573177792

Epoch: 6| Step: 8
Training loss: 1.712039609963325
Validation loss: 2.576620499093251

Epoch: 6| Step: 9
Training loss: 1.5710795033405058
Validation loss: 2.594992987072631

Epoch: 6| Step: 10
Training loss: 1.7141439274213253
Validation loss: 2.5802085856957455

Epoch: 6| Step: 11
Training loss: 1.2669628278101186
Validation loss: 2.5652221704181764

Epoch: 6| Step: 12
Training loss: 1.2061397877681215
Validation loss: 2.6390418398740856

Epoch: 6| Step: 13
Training loss: 1.7579934260187928
Validation loss: 2.6511309120929716

Epoch: 359| Step: 0
Training loss: 1.6499711987842778
Validation loss: 2.6190057615964712

Epoch: 6| Step: 1
Training loss: 1.3928195909880652
Validation loss: 2.6235998976251125

Epoch: 6| Step: 2
Training loss: 1.520976578049959
Validation loss: 2.5919488221745928

Epoch: 6| Step: 3
Training loss: 1.5085586520062682
Validation loss: 2.5551853764142014

Epoch: 6| Step: 4
Training loss: 1.6790891069369795
Validation loss: 2.5958922857588074

Epoch: 6| Step: 5
Training loss: 1.4350564339469967
Validation loss: 2.6060960310990735

Epoch: 6| Step: 6
Training loss: 1.1277187662131238
Validation loss: 2.5544038200946013

Epoch: 6| Step: 7
Training loss: 1.7757648539426054
Validation loss: 2.5382956887465893

Epoch: 6| Step: 8
Training loss: 1.4668084968279183
Validation loss: 2.601650542028614

Epoch: 6| Step: 9
Training loss: 1.3552983861271446
Validation loss: 2.5972088038822645

Epoch: 6| Step: 10
Training loss: 1.6101901758313364
Validation loss: 2.550370436919727

Epoch: 6| Step: 11
Training loss: 0.9683807961578648
Validation loss: 2.5359878155849827

Epoch: 6| Step: 12
Training loss: 1.3380948321573443
Validation loss: 2.5854584863945087

Epoch: 6| Step: 13
Training loss: 1.1421698990286298
Validation loss: 2.589499487610264

Epoch: 360| Step: 0
Training loss: 1.625782338132407
Validation loss: 2.5743714877224497

Epoch: 6| Step: 1
Training loss: 1.5459702282909866
Validation loss: 2.5072404599213813

Epoch: 6| Step: 2
Training loss: 1.3385323649082
Validation loss: 2.5883583116482654

Epoch: 6| Step: 3
Training loss: 1.5446282456177065
Validation loss: 2.600320445084007

Epoch: 6| Step: 4
Training loss: 0.8736542502727397
Validation loss: 2.539720373756485

Epoch: 6| Step: 5
Training loss: 1.2883322757126061
Validation loss: 2.5519890177419686

Epoch: 6| Step: 6
Training loss: 1.2276250039836611
Validation loss: 2.533167971894319

Epoch: 6| Step: 7
Training loss: 1.8218220357900856
Validation loss: 2.5053740200099237

Epoch: 6| Step: 8
Training loss: 1.0432393155276432
Validation loss: 2.557940171026012

Epoch: 6| Step: 9
Training loss: 2.5383713001493446
Validation loss: 2.5380757610395417

Epoch: 6| Step: 10
Training loss: 1.1189175528253867
Validation loss: 2.538199817137476

Epoch: 6| Step: 11
Training loss: 1.455125313832138
Validation loss: 2.6120193696406484

Epoch: 6| Step: 12
Training loss: 1.3331467329025224
Validation loss: 2.6275378326925054

Epoch: 6| Step: 13
Training loss: 1.5170253301629333
Validation loss: 2.664778179792374

Epoch: 361| Step: 0
Training loss: 1.2932210255475565
Validation loss: 2.648040981861082

Epoch: 6| Step: 1
Training loss: 1.6021554733060495
Validation loss: 2.7106864292583346

Epoch: 6| Step: 2
Training loss: 1.2339292759683336
Validation loss: 2.703970304706044

Epoch: 6| Step: 3
Training loss: 1.6787171865794102
Validation loss: 2.6908981589239565

Epoch: 6| Step: 4
Training loss: 1.6867518709295901
Validation loss: 2.6152914742315807

Epoch: 6| Step: 5
Training loss: 1.1957357318050033
Validation loss: 2.6603501931182696

Epoch: 6| Step: 6
Training loss: 1.4190992152427668
Validation loss: 2.618012096259059

Epoch: 6| Step: 7
Training loss: 1.6475700518659788
Validation loss: 2.6339627553893696

Epoch: 6| Step: 8
Training loss: 1.174953790527084
Validation loss: 2.61031766147104

Epoch: 6| Step: 9
Training loss: 1.7412802211222866
Validation loss: 2.5860837528171587

Epoch: 6| Step: 10
Training loss: 1.8198325379849085
Validation loss: 2.578037360657278

Epoch: 6| Step: 11
Training loss: 1.7516848763857178
Validation loss: 2.5435596801018305

Epoch: 6| Step: 12
Training loss: 1.4648722327960033
Validation loss: 2.5610332478097035

Epoch: 6| Step: 13
Training loss: 1.2143212080824932
Validation loss: 2.5514633645341642

Epoch: 362| Step: 0
Training loss: 1.4708684699136536
Validation loss: 2.584237806867794

Epoch: 6| Step: 1
Training loss: 1.5638771092069275
Validation loss: 2.583539359788398

Epoch: 6| Step: 2
Training loss: 1.1212163452745267
Validation loss: 2.631059276044528

Epoch: 6| Step: 3
Training loss: 1.523225740240494
Validation loss: 2.645166858825555

Epoch: 6| Step: 4
Training loss: 1.532177858083078
Validation loss: 2.6259527596647674

Epoch: 6| Step: 5
Training loss: 1.6261931220743686
Validation loss: 2.617705943820853

Epoch: 6| Step: 6
Training loss: 2.435514472800952
Validation loss: 2.6094691322388237

Epoch: 6| Step: 7
Training loss: 1.7962910905888572
Validation loss: 2.6318636428610915

Epoch: 6| Step: 8
Training loss: 1.8759794855765228
Validation loss: 2.62933456461138

Epoch: 6| Step: 9
Training loss: 1.1826670326671729
Validation loss: 2.6397335496494603

Epoch: 6| Step: 10
Training loss: 1.587863072605557
Validation loss: 2.659100577468506

Epoch: 6| Step: 11
Training loss: 1.2412726434215415
Validation loss: 2.6117721784936596

Epoch: 6| Step: 12
Training loss: 1.5415390150816557
Validation loss: 2.5490408427409768

Epoch: 6| Step: 13
Training loss: 1.2268276049592457
Validation loss: 2.574285804442487

Epoch: 363| Step: 0
Training loss: 1.9107853452255081
Validation loss: 2.557993492786779

Epoch: 6| Step: 1
Training loss: 1.7552531280989565
Validation loss: 2.524256082359276

Epoch: 6| Step: 2
Training loss: 2.3146350386710326
Validation loss: 2.6132106799987813

Epoch: 6| Step: 3
Training loss: 1.6642236765859415
Validation loss: 2.55552807277147

Epoch: 6| Step: 4
Training loss: 1.2028874744924787
Validation loss: 2.5439973890523087

Epoch: 6| Step: 5
Training loss: 0.8531077652192914
Validation loss: 2.4817356188511686

Epoch: 6| Step: 6
Training loss: 1.5885317025627776
Validation loss: 2.526831439851531

Epoch: 6| Step: 7
Training loss: 1.43619486398335
Validation loss: 2.553827107828103

Epoch: 6| Step: 8
Training loss: 1.3432729007168167
Validation loss: 2.525301187007869

Epoch: 6| Step: 9
Training loss: 1.8110857740760902
Validation loss: 2.6055393771808237

Epoch: 6| Step: 10
Training loss: 1.5060745263675994
Validation loss: 2.562985847129448

Epoch: 6| Step: 11
Training loss: 1.9106799072921352
Validation loss: 2.5993956132374

Epoch: 6| Step: 12
Training loss: 1.4863603666119514
Validation loss: 2.623374405345091

Epoch: 6| Step: 13
Training loss: 1.2948508955200317
Validation loss: 2.5229530302451697

Epoch: 364| Step: 0
Training loss: 1.3534524745989143
Validation loss: 2.588941920528161

Epoch: 6| Step: 1
Training loss: 1.3129542336778788
Validation loss: 2.562161896272913

Epoch: 6| Step: 2
Training loss: 1.2981690534409012
Validation loss: 2.611954029351496

Epoch: 6| Step: 3
Training loss: 1.1095129652602382
Validation loss: 2.6069687124495835

Epoch: 6| Step: 4
Training loss: 1.2591440485991587
Validation loss: 2.6235885458490165

Epoch: 6| Step: 5
Training loss: 1.782866029328602
Validation loss: 2.5826152808526546

Epoch: 6| Step: 6
Training loss: 1.2397673921682466
Validation loss: 2.550391688838158

Epoch: 6| Step: 7
Training loss: 1.5477683830173885
Validation loss: 2.550775034314187

Epoch: 6| Step: 8
Training loss: 1.7534460470765973
Validation loss: 2.5385017440927156

Epoch: 6| Step: 9
Training loss: 1.0692698279721526
Validation loss: 2.5656865164056777

Epoch: 6| Step: 10
Training loss: 1.1729213874861921
Validation loss: 2.595514715937945

Epoch: 6| Step: 11
Training loss: 2.092018436270415
Validation loss: 2.5895698444713844

Epoch: 6| Step: 12
Training loss: 1.6179514384391198
Validation loss: 2.5997310450412185

Epoch: 6| Step: 13
Training loss: 1.6448866942554057
Validation loss: 2.6603331803436228

Epoch: 365| Step: 0
Training loss: 1.387528819566705
Validation loss: 2.7034850569817035

Epoch: 6| Step: 1
Training loss: 1.731860563396304
Validation loss: 2.645755561426508

Epoch: 6| Step: 2
Training loss: 1.284228421871135
Validation loss: 2.6662900827658502

Epoch: 6| Step: 3
Training loss: 1.4316912508102033
Validation loss: 2.6446160848018057

Epoch: 6| Step: 4
Training loss: 1.2246966901250875
Validation loss: 2.646057409775233

Epoch: 6| Step: 5
Training loss: 1.7891663100596575
Validation loss: 2.5913193202127682

Epoch: 6| Step: 6
Training loss: 1.2149978000322683
Validation loss: 2.6021776818018876

Epoch: 6| Step: 7
Training loss: 1.8242322770133843
Validation loss: 2.5731346305745393

Epoch: 6| Step: 8
Training loss: 2.021591581736021
Validation loss: 2.632574551750258

Epoch: 6| Step: 9
Training loss: 1.434696532137721
Validation loss: 2.6559925552971424

Epoch: 6| Step: 10
Training loss: 1.1260043005988214
Validation loss: 2.6005094915430846

Epoch: 6| Step: 11
Training loss: 1.294230787347202
Validation loss: 2.6344806732909083

Epoch: 6| Step: 12
Training loss: 1.1965441871610587
Validation loss: 2.7481380285758608

Epoch: 6| Step: 13
Training loss: 1.5835907961004378
Validation loss: 2.7494703707608807

Epoch: 366| Step: 0
Training loss: 1.2111254146345682
Validation loss: 2.714230460366999

Epoch: 6| Step: 1
Training loss: 0.8798436570002365
Validation loss: 2.6757327926963033

Epoch: 6| Step: 2
Training loss: 1.5419584805728548
Validation loss: 2.6302752092880035

Epoch: 6| Step: 3
Training loss: 1.8169493160789343
Validation loss: 2.6232574976712715

Epoch: 6| Step: 4
Training loss: 1.6495401753195604
Validation loss: 2.5607514967681415

Epoch: 6| Step: 5
Training loss: 1.6380184721411672
Validation loss: 2.6268107965383316

Epoch: 6| Step: 6
Training loss: 1.216748427992574
Validation loss: 2.590167792959328

Epoch: 6| Step: 7
Training loss: 1.4374834142640323
Validation loss: 2.6083420252629774

Epoch: 6| Step: 8
Training loss: 1.3478267838207438
Validation loss: 2.5488473319040055

Epoch: 6| Step: 9
Training loss: 1.6481714983193692
Validation loss: 2.597733881275571

Epoch: 6| Step: 10
Training loss: 1.2343246836004245
Validation loss: 2.6217523496885304

Epoch: 6| Step: 11
Training loss: 1.0800455650678265
Validation loss: 2.600726950939858

Epoch: 6| Step: 12
Training loss: 1.6173439134522698
Validation loss: 2.619970529162419

Epoch: 6| Step: 13
Training loss: 1.4094180978076716
Validation loss: 2.59762409544048

Epoch: 367| Step: 0
Training loss: 1.2035602921588815
Validation loss: 2.5924473904133825

Epoch: 6| Step: 1
Training loss: 1.2587007975503577
Validation loss: 2.552551870089913

Epoch: 6| Step: 2
Training loss: 1.223991177165577
Validation loss: 2.6314569109510995

Epoch: 6| Step: 3
Training loss: 1.5182437885119044
Validation loss: 2.5839448456300844

Epoch: 6| Step: 4
Training loss: 1.011157377171972
Validation loss: 2.5657175069867226

Epoch: 6| Step: 5
Training loss: 1.6792048980803203
Validation loss: 2.606181949303378

Epoch: 6| Step: 6
Training loss: 1.9070354781988859
Validation loss: 2.6232446826495686

Epoch: 6| Step: 7
Training loss: 1.1414339515201848
Validation loss: 2.6218884282455943

Epoch: 6| Step: 8
Training loss: 1.2959615408877707
Validation loss: 2.692677441732758

Epoch: 6| Step: 9
Training loss: 1.3676676751645267
Validation loss: 2.75527324251516

Epoch: 6| Step: 10
Training loss: 1.6925929886081441
Validation loss: 2.707871798779342

Epoch: 6| Step: 11
Training loss: 1.3997978541347267
Validation loss: 2.673500161669343

Epoch: 6| Step: 12
Training loss: 1.2969349766845921
Validation loss: 2.591451645381551

Epoch: 6| Step: 13
Training loss: 1.6636680887810211
Validation loss: 2.625887569358486

Epoch: 368| Step: 0
Training loss: 1.4058066622938867
Validation loss: 2.57270846637768

Epoch: 6| Step: 1
Training loss: 1.5998270447949823
Validation loss: 2.579308733214063

Epoch: 6| Step: 2
Training loss: 1.2242819608474071
Validation loss: 2.549720469593314

Epoch: 6| Step: 3
Training loss: 1.264294384032997
Validation loss: 2.536068024001781

Epoch: 6| Step: 4
Training loss: 1.3645827412300668
Validation loss: 2.5312388933982035

Epoch: 6| Step: 5
Training loss: 1.3093931119480988
Validation loss: 2.5470633719899913

Epoch: 6| Step: 6
Training loss: 1.3989519419728853
Validation loss: 2.5864856672948693

Epoch: 6| Step: 7
Training loss: 2.118190401158858
Validation loss: 2.6099617578182173

Epoch: 6| Step: 8
Training loss: 1.5520306606017016
Validation loss: 2.615032071414725

Epoch: 6| Step: 9
Training loss: 1.340822179561018
Validation loss: 2.6384668654119787

Epoch: 6| Step: 10
Training loss: 1.3212503567120406
Validation loss: 2.6456728208218045

Epoch: 6| Step: 11
Training loss: 1.010904934814073
Validation loss: 2.635630999708987

Epoch: 6| Step: 12
Training loss: 1.1471963001018646
Validation loss: 2.635403151848157

Epoch: 6| Step: 13
Training loss: 1.1110944720187985
Validation loss: 2.6398578409731623

Epoch: 369| Step: 0
Training loss: 1.741761433458315
Validation loss: 2.653089056232086

Epoch: 6| Step: 1
Training loss: 1.0011048174312263
Validation loss: 2.6000928269223538

Epoch: 6| Step: 2
Training loss: 1.5793369285303185
Validation loss: 2.6030984951225427

Epoch: 6| Step: 3
Training loss: 1.3077806366351121
Validation loss: 2.5821429760836225

Epoch: 6| Step: 4
Training loss: 1.538388874557068
Validation loss: 2.5705004220460204

Epoch: 6| Step: 5
Training loss: 1.0637620835116646
Validation loss: 2.538746286900064

Epoch: 6| Step: 6
Training loss: 1.0355784580820653
Validation loss: 2.559169512314137

Epoch: 6| Step: 7
Training loss: 1.2147581309478017
Validation loss: 2.5641821790524952

Epoch: 6| Step: 8
Training loss: 1.483418929741397
Validation loss: 2.6332466077003756

Epoch: 6| Step: 9
Training loss: 1.252407997087296
Validation loss: 2.598363029680576

Epoch: 6| Step: 10
Training loss: 1.6091821054949063
Validation loss: 2.618708571817221

Epoch: 6| Step: 11
Training loss: 1.5355938392120094
Validation loss: 2.598177275833368

Epoch: 6| Step: 12
Training loss: 1.643987207738851
Validation loss: 2.587539422538076

Epoch: 6| Step: 13
Training loss: 1.313790096030417
Validation loss: 2.5759510777627868

Epoch: 370| Step: 0
Training loss: 1.3421158723736633
Validation loss: 2.5965050309458935

Epoch: 6| Step: 1
Training loss: 1.245775475110054
Validation loss: 2.5878205142330675

Epoch: 6| Step: 2
Training loss: 1.594631699160087
Validation loss: 2.6435342146014134

Epoch: 6| Step: 3
Training loss: 1.5457796784966236
Validation loss: 2.609779570200208

Epoch: 6| Step: 4
Training loss: 1.0405004203388588
Validation loss: 2.5777077077060517

Epoch: 6| Step: 5
Training loss: 1.4836924539669176
Validation loss: 2.6028581052734205

Epoch: 6| Step: 6
Training loss: 1.3899534940143738
Validation loss: 2.6140460086597974

Epoch: 6| Step: 7
Training loss: 1.5041650326509486
Validation loss: 2.616816282753203

Epoch: 6| Step: 8
Training loss: 1.2666128565417822
Validation loss: 2.6516799807818683

Epoch: 6| Step: 9
Training loss: 1.1736074230630225
Validation loss: 2.713007185436557

Epoch: 6| Step: 10
Training loss: 1.821479979625735
Validation loss: 2.759228797458088

Epoch: 6| Step: 11
Training loss: 1.6302556365181413
Validation loss: 2.799917132990614

Epoch: 6| Step: 12
Training loss: 1.3233619100878682
Validation loss: 2.6617033684512545

Epoch: 6| Step: 13
Training loss: 1.7414237088696929
Validation loss: 2.678769858140273

Epoch: 371| Step: 0
Training loss: 1.4545739446093153
Validation loss: 2.622257510606029

Epoch: 6| Step: 1
Training loss: 1.5352774613456814
Validation loss: 2.5836285504478482

Epoch: 6| Step: 2
Training loss: 1.543692966905731
Validation loss: 2.5786477146643922

Epoch: 6| Step: 3
Training loss: 1.0314755048704876
Validation loss: 2.5743391812468976

Epoch: 6| Step: 4
Training loss: 1.7280893608405479
Validation loss: 2.5706681891455965

Epoch: 6| Step: 5
Training loss: 1.7883161295584435
Validation loss: 2.5287969657344327

Epoch: 6| Step: 6
Training loss: 0.8179485227457587
Validation loss: 2.527969432267753

Epoch: 6| Step: 7
Training loss: 1.5344525537100853
Validation loss: 2.5641571517171067

Epoch: 6| Step: 8
Training loss: 1.3167361064096061
Validation loss: 2.5526729188159893

Epoch: 6| Step: 9
Training loss: 1.3947419934286547
Validation loss: 2.6348452168388774

Epoch: 6| Step: 10
Training loss: 0.914216248713077
Validation loss: 2.6238552049514667

Epoch: 6| Step: 11
Training loss: 1.264896041609148
Validation loss: 2.686783554628167

Epoch: 6| Step: 12
Training loss: 1.467189853004137
Validation loss: 2.704246376598717

Epoch: 6| Step: 13
Training loss: 1.465499527690685
Validation loss: 2.655844227333895

Epoch: 372| Step: 0
Training loss: 1.350976629561902
Validation loss: 2.6830781295998727

Epoch: 6| Step: 1
Training loss: 1.3395038763106226
Validation loss: 2.6802844243689763

Epoch: 6| Step: 2
Training loss: 0.8638715150100742
Validation loss: 2.671184547251968

Epoch: 6| Step: 3
Training loss: 1.717084875676179
Validation loss: 2.6747119261213914

Epoch: 6| Step: 4
Training loss: 1.6519722306686238
Validation loss: 2.729935535326535

Epoch: 6| Step: 5
Training loss: 1.2893276057591159
Validation loss: 2.685393350547819

Epoch: 6| Step: 6
Training loss: 1.3264043095853437
Validation loss: 2.6258744947846684

Epoch: 6| Step: 7
Training loss: 1.275212087008199
Validation loss: 2.571065149000382

Epoch: 6| Step: 8
Training loss: 1.4540038373809927
Validation loss: 2.583556862871453

Epoch: 6| Step: 9
Training loss: 1.001416157283454
Validation loss: 2.5607579287587146

Epoch: 6| Step: 10
Training loss: 0.8698797619153879
Validation loss: 2.553902788413693

Epoch: 6| Step: 11
Training loss: 1.2880095371728446
Validation loss: 2.6012108520270103

Epoch: 6| Step: 12
Training loss: 1.1097759543088899
Validation loss: 2.531895339395712

Epoch: 6| Step: 13
Training loss: 1.5135015182613525
Validation loss: 2.5639972034534315

Epoch: 373| Step: 0
Training loss: 1.413942742940688
Validation loss: 2.5707638391616072

Epoch: 6| Step: 1
Training loss: 0.9455800269022494
Validation loss: 2.575330726593908

Epoch: 6| Step: 2
Training loss: 1.7217889449255737
Validation loss: 2.606634745569057

Epoch: 6| Step: 3
Training loss: 1.3908075791418761
Validation loss: 2.6132933840163455

Epoch: 6| Step: 4
Training loss: 1.4856521733631012
Validation loss: 2.6320872982402497

Epoch: 6| Step: 5
Training loss: 1.137276843472213
Validation loss: 2.6280239489493282

Epoch: 6| Step: 6
Training loss: 1.3722031932846475
Validation loss: 2.623411500251746

Epoch: 6| Step: 7
Training loss: 0.8515627099833099
Validation loss: 2.6686707555603117

Epoch: 6| Step: 8
Training loss: 1.0772683983801055
Validation loss: 2.6473663624627792

Epoch: 6| Step: 9
Training loss: 1.2227435096095822
Validation loss: 2.6923377091268037

Epoch: 6| Step: 10
Training loss: 1.1579464504167607
Validation loss: 2.6907463427395357

Epoch: 6| Step: 11
Training loss: 1.6920658085427567
Validation loss: 2.6884860514214584

Epoch: 6| Step: 12
Training loss: 1.3587526234002218
Validation loss: 2.6820564882946827

Epoch: 6| Step: 13
Training loss: 1.5707771031495623
Validation loss: 2.6754014685432352

Epoch: 374| Step: 0
Training loss: 0.9941777070629666
Validation loss: 2.627533038675994

Epoch: 6| Step: 1
Training loss: 1.7259599143331834
Validation loss: 2.6002123042994425

Epoch: 6| Step: 2
Training loss: 1.5093619336180681
Validation loss: 2.6373158774809125

Epoch: 6| Step: 3
Training loss: 1.215801683152959
Validation loss: 2.6149834609131672

Epoch: 6| Step: 4
Training loss: 1.6287117894595071
Validation loss: 2.607801994971496

Epoch: 6| Step: 5
Training loss: 1.8161745641470795
Validation loss: 2.5928410388972374

Epoch: 6| Step: 6
Training loss: 1.1382632953848426
Validation loss: 2.5823086711225702

Epoch: 6| Step: 7
Training loss: 1.0110136542902757
Validation loss: 2.6108269221177105

Epoch: 6| Step: 8
Training loss: 0.9248376214065543
Validation loss: 2.6364095775045397

Epoch: 6| Step: 9
Training loss: 1.3507301545945458
Validation loss: 2.660901130133532

Epoch: 6| Step: 10
Training loss: 1.2931318381909067
Validation loss: 2.7152507229947944

Epoch: 6| Step: 11
Training loss: 1.3686331816688377
Validation loss: 2.661635694671931

Epoch: 6| Step: 12
Training loss: 1.0669012353193257
Validation loss: 2.5686619646838067

Epoch: 6| Step: 13
Training loss: 1.324614699141237
Validation loss: 2.540894724662121

Epoch: 375| Step: 0
Training loss: 1.5352256700966733
Validation loss: 2.552106169514114

Epoch: 6| Step: 1
Training loss: 1.784636373801211
Validation loss: 2.5079704385462254

Epoch: 6| Step: 2
Training loss: 1.0186393022365243
Validation loss: 2.5433707986382847

Epoch: 6| Step: 3
Training loss: 1.5757976782665344
Validation loss: 2.5724285038440473

Epoch: 6| Step: 4
Training loss: 1.488149241602872
Validation loss: 2.571223011706641

Epoch: 6| Step: 5
Training loss: 1.0489024556848687
Validation loss: 2.5930680523651666

Epoch: 6| Step: 6
Training loss: 0.996320033082816
Validation loss: 2.6620055281268584

Epoch: 6| Step: 7
Training loss: 1.3005853912173635
Validation loss: 2.6787389665009416

Epoch: 6| Step: 8
Training loss: 0.9875168388476213
Validation loss: 2.7363504739702287

Epoch: 6| Step: 9
Training loss: 1.7523210664353284
Validation loss: 2.7903502097970816

Epoch: 6| Step: 10
Training loss: 1.7758999168531302
Validation loss: 2.8244946188096325

Epoch: 6| Step: 11
Training loss: 1.0996809236547198
Validation loss: 2.724281573886246

Epoch: 6| Step: 12
Training loss: 0.8484123830432049
Validation loss: 2.650958981126965

Epoch: 6| Step: 13
Training loss: 0.9713456236162767
Validation loss: 2.621632368571143

Epoch: 376| Step: 0
Training loss: 1.3392774981292113
Validation loss: 2.5808746009494157

Epoch: 6| Step: 1
Training loss: 1.077550209628029
Validation loss: 2.525631032909931

Epoch: 6| Step: 2
Training loss: 1.5726273967523627
Validation loss: 2.5737389603153096

Epoch: 6| Step: 3
Training loss: 1.1303884418383945
Validation loss: 2.5582119023418146

Epoch: 6| Step: 4
Training loss: 1.2114267652908135
Validation loss: 2.5202648662079112

Epoch: 6| Step: 5
Training loss: 1.2443534154088118
Validation loss: 2.572017378668759

Epoch: 6| Step: 6
Training loss: 1.0823484981670068
Validation loss: 2.5680210214588315

Epoch: 6| Step: 7
Training loss: 0.9659169518053994
Validation loss: 2.586839547385544

Epoch: 6| Step: 8
Training loss: 1.4951524288078033
Validation loss: 2.579843260639286

Epoch: 6| Step: 9
Training loss: 1.20323938593888
Validation loss: 2.617038506209645

Epoch: 6| Step: 10
Training loss: 1.8047030889985527
Validation loss: 2.615113167948915

Epoch: 6| Step: 11
Training loss: 0.9829117329144706
Validation loss: 2.6086820493219074

Epoch: 6| Step: 12
Training loss: 1.0435644156109478
Validation loss: 2.64827688024556

Epoch: 6| Step: 13
Training loss: 1.4923791412799612
Validation loss: 2.6604686969955647

Epoch: 377| Step: 0
Training loss: 1.0547034368370587
Validation loss: 2.6445763423048545

Epoch: 6| Step: 1
Training loss: 0.99779508815045
Validation loss: 2.6448442657957583

Epoch: 6| Step: 2
Training loss: 1.3952299873244185
Validation loss: 2.660910821923924

Epoch: 6| Step: 3
Training loss: 1.4126640697153539
Validation loss: 2.6317033704823825

Epoch: 6| Step: 4
Training loss: 1.1752205459094518
Validation loss: 2.6733912502786694

Epoch: 6| Step: 5
Training loss: 1.4272415834473722
Validation loss: 2.6462619664578293

Epoch: 6| Step: 6
Training loss: 0.8551267175298918
Validation loss: 2.6194962827322756

Epoch: 6| Step: 7
Training loss: 1.407426511495906
Validation loss: 2.65830097677057

Epoch: 6| Step: 8
Training loss: 1.4492161177536742
Validation loss: 2.615377941184209

Epoch: 6| Step: 9
Training loss: 1.4534106230234565
Validation loss: 2.637541172194369

Epoch: 6| Step: 10
Training loss: 1.6464959593305406
Validation loss: 2.650481344088643

Epoch: 6| Step: 11
Training loss: 1.3053875261535155
Validation loss: 2.6169172460600354

Epoch: 6| Step: 12
Training loss: 0.898280387077773
Validation loss: 2.5662725637329347

Epoch: 6| Step: 13
Training loss: 1.3844004850431362
Validation loss: 2.5316853403989477

Epoch: 378| Step: 0
Training loss: 1.1531847971890261
Validation loss: 2.5226379482077554

Epoch: 6| Step: 1
Training loss: 1.0175167951205306
Validation loss: 2.549030445005357

Epoch: 6| Step: 2
Training loss: 1.2512646000302816
Validation loss: 2.591379867540552

Epoch: 6| Step: 3
Training loss: 1.1183886173434445
Validation loss: 2.575331096905277

Epoch: 6| Step: 4
Training loss: 1.2217352082270554
Validation loss: 2.544608623111826

Epoch: 6| Step: 5
Training loss: 1.5943642722755487
Validation loss: 2.5673573675160735

Epoch: 6| Step: 6
Training loss: 1.2287711891993944
Validation loss: 2.6279699387923694

Epoch: 6| Step: 7
Training loss: 1.20741162278788
Validation loss: 2.682073674402114

Epoch: 6| Step: 8
Training loss: 1.3334309671338944
Validation loss: 2.7659878681300207

Epoch: 6| Step: 9
Training loss: 1.1651178478835464
Validation loss: 2.7530814448478886

Epoch: 6| Step: 10
Training loss: 1.8853717046894891
Validation loss: 2.840090006803445

Epoch: 6| Step: 11
Training loss: 1.6107559205366353
Validation loss: 2.742669160135508

Epoch: 6| Step: 12
Training loss: 1.1230131724732355
Validation loss: 2.65122249763465

Epoch: 6| Step: 13
Training loss: 1.3572873714415166
Validation loss: 2.6476580993039556

Epoch: 379| Step: 0
Training loss: 1.1662940327140165
Validation loss: 2.685917854348192

Epoch: 6| Step: 1
Training loss: 1.137613265717764
Validation loss: 2.64692503016005

Epoch: 6| Step: 2
Training loss: 1.7782099698485825
Validation loss: 2.6865186599953357

Epoch: 6| Step: 3
Training loss: 2.104514392284249
Validation loss: 2.6783946990187784

Epoch: 6| Step: 4
Training loss: 2.081248524524979
Validation loss: 2.6388382293344788

Epoch: 6| Step: 5
Training loss: 1.1206699859729592
Validation loss: 2.5966108546627016

Epoch: 6| Step: 6
Training loss: 1.2182694490298331
Validation loss: 2.5510874745025864

Epoch: 6| Step: 7
Training loss: 1.4496879537836191
Validation loss: 2.583019996426841

Epoch: 6| Step: 8
Training loss: 1.7218836567794384
Validation loss: 2.6050133562142217

Epoch: 6| Step: 9
Training loss: 0.9943203267161036
Validation loss: 2.616145884165585

Epoch: 6| Step: 10
Training loss: 1.6326552319877168
Validation loss: 2.7855737202966786

Epoch: 6| Step: 11
Training loss: 1.6280702783097918
Validation loss: 2.8694062063527825

Epoch: 6| Step: 12
Training loss: 1.386926511862561
Validation loss: 2.837460069753525

Epoch: 6| Step: 13
Training loss: 1.1092832285572731
Validation loss: 2.813173326496593

Epoch: 380| Step: 0
Training loss: 1.6275642410467646
Validation loss: 2.6884782105004446

Epoch: 6| Step: 1
Training loss: 1.0992908185746346
Validation loss: 2.667894681662916

Epoch: 6| Step: 2
Training loss: 1.0249093224958925
Validation loss: 2.6337377505265755

Epoch: 6| Step: 3
Training loss: 1.0371444322655918
Validation loss: 2.6229757345233127

Epoch: 6| Step: 4
Training loss: 1.1374615212104966
Validation loss: 2.590049340405323

Epoch: 6| Step: 5
Training loss: 1.3520544843530002
Validation loss: 2.641709430440705

Epoch: 6| Step: 6
Training loss: 1.9466020224345648
Validation loss: 2.6256414416902487

Epoch: 6| Step: 7
Training loss: 0.9061465368733341
Validation loss: 2.6112976148521096

Epoch: 6| Step: 8
Training loss: 1.9109484194227577
Validation loss: 2.604274279596197

Epoch: 6| Step: 9
Training loss: 1.0974128426113374
Validation loss: 2.612374186794542

Epoch: 6| Step: 10
Training loss: 1.8305488884739631
Validation loss: 2.574968050477662

Epoch: 6| Step: 11
Training loss: 1.0831384055512663
Validation loss: 2.581566149768251

Epoch: 6| Step: 12
Training loss: 1.2151784159897583
Validation loss: 2.6381479115332094

Epoch: 6| Step: 13
Training loss: 0.9578373841978374
Validation loss: 2.6994768489469756

Epoch: 381| Step: 0
Training loss: 1.2649273303422426
Validation loss: 2.690733524250212

Epoch: 6| Step: 1
Training loss: 1.4149301301400365
Validation loss: 2.772966400395976

Epoch: 6| Step: 2
Training loss: 1.65872698126131
Validation loss: 2.6722720708138725

Epoch: 6| Step: 3
Training loss: 1.3096126859609751
Validation loss: 2.646678576786939

Epoch: 6| Step: 4
Training loss: 0.9733408468154603
Validation loss: 2.611172344513334

Epoch: 6| Step: 5
Training loss: 1.5433099683279616
Validation loss: 2.588615605752169

Epoch: 6| Step: 6
Training loss: 1.3045017772675613
Validation loss: 2.6224908795726964

Epoch: 6| Step: 7
Training loss: 0.9301800745266734
Validation loss: 2.635357887507194

Epoch: 6| Step: 8
Training loss: 1.2498573221794815
Validation loss: 2.6573967122711784

Epoch: 6| Step: 9
Training loss: 1.9224252300827696
Validation loss: 2.6671552260207387

Epoch: 6| Step: 10
Training loss: 1.150330676344798
Validation loss: 2.6717605863765796

Epoch: 6| Step: 11
Training loss: 1.2218821942442009
Validation loss: 2.666213717338207

Epoch: 6| Step: 12
Training loss: 1.0023057105323319
Validation loss: 2.660264097502558

Epoch: 6| Step: 13
Training loss: 0.9750267465297371
Validation loss: 2.711523339020743

Epoch: 382| Step: 0
Training loss: 0.9997004417924438
Validation loss: 2.7029730693478977

Epoch: 6| Step: 1
Training loss: 1.0406601748091924
Validation loss: 2.712443392466168

Epoch: 6| Step: 2
Training loss: 1.0204388316810449
Validation loss: 2.6343331553498404

Epoch: 6| Step: 3
Training loss: 1.1688183402414343
Validation loss: 2.667961437090583

Epoch: 6| Step: 4
Training loss: 1.0664053557116213
Validation loss: 2.5986871877335975

Epoch: 6| Step: 5
Training loss: 1.1985268849208905
Validation loss: 2.624436090843493

Epoch: 6| Step: 6
Training loss: 1.08080969207916
Validation loss: 2.6222584501240584

Epoch: 6| Step: 7
Training loss: 1.1604615911055187
Validation loss: 2.595359754658489

Epoch: 6| Step: 8
Training loss: 1.310558427057646
Validation loss: 2.5927824490780305

Epoch: 6| Step: 9
Training loss: 1.4559017436231612
Validation loss: 2.594065796344861

Epoch: 6| Step: 10
Training loss: 1.2248573356387886
Validation loss: 2.6669386089264506

Epoch: 6| Step: 11
Training loss: 1.5168298081627853
Validation loss: 2.5690991476093306

Epoch: 6| Step: 12
Training loss: 1.0590773037584669
Validation loss: 2.58487551300242

Epoch: 6| Step: 13
Training loss: 1.5689270588323343
Validation loss: 2.652211968318169

Epoch: 383| Step: 0
Training loss: 1.8084582284201174
Validation loss: 2.6076879167977842

Epoch: 6| Step: 1
Training loss: 1.1531204450977377
Validation loss: 2.7029191308098275

Epoch: 6| Step: 2
Training loss: 1.2791126380635451
Validation loss: 2.708692531730096

Epoch: 6| Step: 3
Training loss: 1.4018912687815999
Validation loss: 2.724592646794712

Epoch: 6| Step: 4
Training loss: 1.1684834548634186
Validation loss: 2.680002674070609

Epoch: 6| Step: 5
Training loss: 1.5224987561200451
Validation loss: 2.6740464278598486

Epoch: 6| Step: 6
Training loss: 1.122200343314271
Validation loss: 2.6631693456849455

Epoch: 6| Step: 7
Training loss: 0.9954902166885027
Validation loss: 2.6282058394945813

Epoch: 6| Step: 8
Training loss: 1.2031057281932311
Validation loss: 2.6035755681899486

Epoch: 6| Step: 9
Training loss: 0.8739052122489487
Validation loss: 2.5879978603961478

Epoch: 6| Step: 10
Training loss: 1.2166991952353718
Validation loss: 2.557448890550725

Epoch: 6| Step: 11
Training loss: 1.0052667445998906
Validation loss: 2.5333491361484874

Epoch: 6| Step: 12
Training loss: 1.3097606409685125
Validation loss: 2.5831433246835407

Epoch: 6| Step: 13
Training loss: 1.0857118330924218
Validation loss: 2.6025450018742813

Epoch: 384| Step: 0
Training loss: 1.269327000546753
Validation loss: 2.568761077139206

Epoch: 6| Step: 1
Training loss: 0.9385115570307906
Validation loss: 2.5883493230472783

Epoch: 6| Step: 2
Training loss: 1.3022732812298372
Validation loss: 2.663137803075645

Epoch: 6| Step: 3
Training loss: 1.261305608515926
Validation loss: 2.666220200436639

Epoch: 6| Step: 4
Training loss: 1.1903085623526046
Validation loss: 2.7388249255258508

Epoch: 6| Step: 5
Training loss: 1.113830645003769
Validation loss: 2.6495028203337436

Epoch: 6| Step: 6
Training loss: 1.6968648808354971
Validation loss: 2.678345235629203

Epoch: 6| Step: 7
Training loss: 1.0450994893220342
Validation loss: 2.655506344086085

Epoch: 6| Step: 8
Training loss: 1.3708567183489424
Validation loss: 2.566462051195268

Epoch: 6| Step: 9
Training loss: 0.9682229977404878
Validation loss: 2.589378871400741

Epoch: 6| Step: 10
Training loss: 1.1689583658941185
Validation loss: 2.5525007230986176

Epoch: 6| Step: 11
Training loss: 1.1881731033018859
Validation loss: 2.5965016947123143

Epoch: 6| Step: 12
Training loss: 1.310299208955978
Validation loss: 2.579891701527353

Epoch: 6| Step: 13
Training loss: 0.6311239626613954
Validation loss: 2.5971250215543766

Epoch: 385| Step: 0
Training loss: 1.6722637687090038
Validation loss: 2.597547225767604

Epoch: 6| Step: 1
Training loss: 0.726986955924465
Validation loss: 2.6090554824096888

Epoch: 6| Step: 2
Training loss: 1.2560291798415366
Validation loss: 2.673504828670401

Epoch: 6| Step: 3
Training loss: 0.7354230909274062
Validation loss: 2.711620482966072

Epoch: 6| Step: 4
Training loss: 1.0104994330312582
Validation loss: 2.7068189103745

Epoch: 6| Step: 5
Training loss: 1.3437861504238626
Validation loss: 2.7572302847614614

Epoch: 6| Step: 6
Training loss: 1.250929248638704
Validation loss: 2.71961877907218

Epoch: 6| Step: 7
Training loss: 1.0276436023650177
Validation loss: 2.6997051693220016

Epoch: 6| Step: 8
Training loss: 1.1540407261265062
Validation loss: 2.661159092951271

Epoch: 6| Step: 9
Training loss: 1.3459320538022912
Validation loss: 2.602763894242105

Epoch: 6| Step: 10
Training loss: 0.9946879321165402
Validation loss: 2.5907492380449995

Epoch: 6| Step: 11
Training loss: 1.1421791880001186
Validation loss: 2.607014561150938

Epoch: 6| Step: 12
Training loss: 1.1995582721226066
Validation loss: 2.526395860727272

Epoch: 6| Step: 13
Training loss: 1.1551661179548165
Validation loss: 2.5025125275716555

Epoch: 386| Step: 0
Training loss: 0.8139338679103371
Validation loss: 2.584094109851838

Epoch: 6| Step: 1
Training loss: 1.2072227844564274
Validation loss: 2.5567529244235074

Epoch: 6| Step: 2
Training loss: 0.8444093670970144
Validation loss: 2.5551784716319283

Epoch: 6| Step: 3
Training loss: 1.3401077054991726
Validation loss: 2.613881800992488

Epoch: 6| Step: 4
Training loss: 1.0634236528390182
Validation loss: 2.60640177113313

Epoch: 6| Step: 5
Training loss: 1.1199305544338254
Validation loss: 2.6427370762768683

Epoch: 6| Step: 6
Training loss: 0.8650836684163841
Validation loss: 2.6643579641739055

Epoch: 6| Step: 7
Training loss: 1.2013648397627086
Validation loss: 2.6812231558972797

Epoch: 6| Step: 8
Training loss: 0.9836581814291263
Validation loss: 2.6958562256451795

Epoch: 6| Step: 9
Training loss: 1.207713702702471
Validation loss: 2.690617933570482

Epoch: 6| Step: 10
Training loss: 1.537489963901918
Validation loss: 2.6601688872049776

Epoch: 6| Step: 11
Training loss: 1.146922974791407
Validation loss: 2.6496060474436156

Epoch: 6| Step: 12
Training loss: 1.465290133809347
Validation loss: 2.6688015309703332

Epoch: 6| Step: 13
Training loss: 1.079094492341092
Validation loss: 2.619824628578355

Epoch: 387| Step: 0
Training loss: 1.1908097571852596
Validation loss: 2.6604055921721868

Epoch: 6| Step: 1
Training loss: 1.3964070758900373
Validation loss: 2.65890764910604

Epoch: 6| Step: 2
Training loss: 1.58763805600105
Validation loss: 2.6392265092693776

Epoch: 6| Step: 3
Training loss: 0.8293620173365963
Validation loss: 2.6932467593152873

Epoch: 6| Step: 4
Training loss: 0.7591151024286099
Validation loss: 2.6703889666584035

Epoch: 6| Step: 5
Training loss: 1.4030899995036503
Validation loss: 2.7333832022917086

Epoch: 6| Step: 6
Training loss: 1.498803058540923
Validation loss: 2.63328434822137

Epoch: 6| Step: 7
Training loss: 1.2064856620218014
Validation loss: 2.7070901120287743

Epoch: 6| Step: 8
Training loss: 1.140276346090897
Validation loss: 2.5880906897411435

Epoch: 6| Step: 9
Training loss: 1.325403004663532
Validation loss: 2.5813195059888057

Epoch: 6| Step: 10
Training loss: 0.8557279707903563
Validation loss: 2.527437030499606

Epoch: 6| Step: 11
Training loss: 0.8469605293580128
Validation loss: 2.551472584311448

Epoch: 6| Step: 12
Training loss: 1.4680162585550884
Validation loss: 2.534888356714226

Epoch: 6| Step: 13
Training loss: 1.0610050455201723
Validation loss: 2.5748449556653568

Epoch: 388| Step: 0
Training loss: 1.041141466618525
Validation loss: 2.594214907119117

Epoch: 6| Step: 1
Training loss: 1.2902562942513967
Validation loss: 2.5640837729511303

Epoch: 6| Step: 2
Training loss: 1.4274741795437702
Validation loss: 2.59282769806737

Epoch: 6| Step: 3
Training loss: 1.171112320990021
Validation loss: 2.573766889647959

Epoch: 6| Step: 4
Training loss: 1.09362307220753
Validation loss: 2.611433530633158

Epoch: 6| Step: 5
Training loss: 1.2206157683586425
Validation loss: 2.6070551506016133

Epoch: 6| Step: 6
Training loss: 1.436262427293683
Validation loss: 2.674583341407647

Epoch: 6| Step: 7
Training loss: 0.6680206590972757
Validation loss: 2.711785673903555

Epoch: 6| Step: 8
Training loss: 0.9244228972740821
Validation loss: 2.692406382254052

Epoch: 6| Step: 9
Training loss: 1.3300829647833203
Validation loss: 2.6517368946410333

Epoch: 6| Step: 10
Training loss: 1.1887504619352804
Validation loss: 2.6782788873806758

Epoch: 6| Step: 11
Training loss: 1.0958735967474615
Validation loss: 2.7355528991972795

Epoch: 6| Step: 12
Training loss: 1.0107858252204336
Validation loss: 2.7596339333608757

Epoch: 6| Step: 13
Training loss: 1.0098713979901182
Validation loss: 2.7377972939297623

Epoch: 389| Step: 0
Training loss: 1.119384685753473
Validation loss: 2.727372640287172

Epoch: 6| Step: 1
Training loss: 1.2369974984935486
Validation loss: 2.669740415377129

Epoch: 6| Step: 2
Training loss: 1.4641007230119187
Validation loss: 2.6134416790401622

Epoch: 6| Step: 3
Training loss: 1.1793656067911304
Validation loss: 2.6356298538849603

Epoch: 6| Step: 4
Training loss: 0.6857096812932364
Validation loss: 2.684307035060206

Epoch: 6| Step: 5
Training loss: 0.6153427270814235
Validation loss: 2.68309142896122

Epoch: 6| Step: 6
Training loss: 1.0721514976369677
Validation loss: 2.6412473919469397

Epoch: 6| Step: 7
Training loss: 0.9553610415818403
Validation loss: 2.5816639356637707

Epoch: 6| Step: 8
Training loss: 1.0966147915669266
Validation loss: 2.601416445308554

Epoch: 6| Step: 9
Training loss: 1.329677302929949
Validation loss: 2.5697959836983624

Epoch: 6| Step: 10
Training loss: 1.1342017763987948
Validation loss: 2.562744780223585

Epoch: 6| Step: 11
Training loss: 1.12417747310443
Validation loss: 2.6009905151014343

Epoch: 6| Step: 12
Training loss: 1.0368934880793388
Validation loss: 2.6158476023443322

Epoch: 6| Step: 13
Training loss: 1.1300732345818072
Validation loss: 2.68304206696872

Epoch: 390| Step: 0
Training loss: 1.2660101787163978
Validation loss: 2.6538799857673303

Epoch: 6| Step: 1
Training loss: 1.2152985828374758
Validation loss: 2.6778647893954837

Epoch: 6| Step: 2
Training loss: 1.2780577737527856
Validation loss: 2.6773796709164985

Epoch: 6| Step: 3
Training loss: 1.0247633404948757
Validation loss: 2.680595725971334

Epoch: 6| Step: 4
Training loss: 1.1091937602111477
Validation loss: 2.710321090639471

Epoch: 6| Step: 5
Training loss: 1.3594254670695531
Validation loss: 2.6601403563141814

Epoch: 6| Step: 6
Training loss: 1.168656672867128
Validation loss: 2.658134054070923

Epoch: 6| Step: 7
Training loss: 1.130292101215356
Validation loss: 2.5655476349763937

Epoch: 6| Step: 8
Training loss: 0.9528291587086453
Validation loss: 2.5892160459519697

Epoch: 6| Step: 9
Training loss: 0.7608825397421835
Validation loss: 2.6855819866312656

Epoch: 6| Step: 10
Training loss: 1.067215162061137
Validation loss: 2.6236171637414176

Epoch: 6| Step: 11
Training loss: 0.9334920404806932
Validation loss: 2.6057141220407725

Epoch: 6| Step: 12
Training loss: 1.0172005976289291
Validation loss: 2.589123356713425

Epoch: 6| Step: 13
Training loss: 0.7674677723383986
Validation loss: 2.6454454322877647

Epoch: 391| Step: 0
Training loss: 0.8913783852236495
Validation loss: 2.634174586976777

Epoch: 6| Step: 1
Training loss: 1.451177707419092
Validation loss: 2.670143726566619

Epoch: 6| Step: 2
Training loss: 0.9153999911424346
Validation loss: 2.7309541502756125

Epoch: 6| Step: 3
Training loss: 1.0277265408491736
Validation loss: 2.7251239322629757

Epoch: 6| Step: 4
Training loss: 0.698630485072217
Validation loss: 2.67356655419503

Epoch: 6| Step: 5
Training loss: 1.5804430112378711
Validation loss: 2.63220464403817

Epoch: 6| Step: 6
Training loss: 1.098403838986261
Validation loss: 2.656144009139757

Epoch: 6| Step: 7
Training loss: 0.8304682274975573
Validation loss: 2.6448024233198284

Epoch: 6| Step: 8
Training loss: 0.8977148051872218
Validation loss: 2.623651582042141

Epoch: 6| Step: 9
Training loss: 1.2076485546023337
Validation loss: 2.667622578672677

Epoch: 6| Step: 10
Training loss: 1.0084864410827938
Validation loss: 2.6336353499013487

Epoch: 6| Step: 11
Training loss: 0.8858318514795072
Validation loss: 2.6156843964863956

Epoch: 6| Step: 12
Training loss: 1.1188066926369349
Validation loss: 2.5793010764978686

Epoch: 6| Step: 13
Training loss: 1.417438838924299
Validation loss: 2.620973291485877

Epoch: 392| Step: 0
Training loss: 1.102379245848935
Validation loss: 2.6709526061167974

Epoch: 6| Step: 1
Training loss: 1.062021428206334
Validation loss: 2.6858350934354163

Epoch: 6| Step: 2
Training loss: 1.2451968418148684
Validation loss: 2.7831108640135738

Epoch: 6| Step: 3
Training loss: 1.1013793793105127
Validation loss: 2.784849245361746

Epoch: 6| Step: 4
Training loss: 1.160297886072949
Validation loss: 2.8350162463476742

Epoch: 6| Step: 5
Training loss: 1.2295112881074408
Validation loss: 2.7377184236384715

Epoch: 6| Step: 6
Training loss: 1.2277925968474532
Validation loss: 2.628493799557483

Epoch: 6| Step: 7
Training loss: 0.9361782292969553
Validation loss: 2.591329302913782

Epoch: 6| Step: 8
Training loss: 1.1590702612630666
Validation loss: 2.5874630211293206

Epoch: 6| Step: 9
Training loss: 0.9186717811037475
Validation loss: 2.588960599611029

Epoch: 6| Step: 10
Training loss: 1.1600632549994745
Validation loss: 2.549706957690195

Epoch: 6| Step: 11
Training loss: 1.1452307012264722
Validation loss: 2.6398014838545656

Epoch: 6| Step: 12
Training loss: 2.0300786088653333
Validation loss: 2.6169731773568383

Epoch: 6| Step: 13
Training loss: 1.2936570101872884
Validation loss: 2.6359024253551273

Epoch: 393| Step: 0
Training loss: 1.2835044100707569
Validation loss: 2.6213345291510746

Epoch: 6| Step: 1
Training loss: 0.732476885954944
Validation loss: 2.693313417510562

Epoch: 6| Step: 2
Training loss: 1.3492990404723137
Validation loss: 2.819360630520544

Epoch: 6| Step: 3
Training loss: 1.2540521269463618
Validation loss: 2.889626902880007

Epoch: 6| Step: 4
Training loss: 1.4888898751427972
Validation loss: 2.8255634826160274

Epoch: 6| Step: 5
Training loss: 1.388762909685866
Validation loss: 2.8144676389900165

Epoch: 6| Step: 6
Training loss: 1.1893093479497017
Validation loss: 2.7429894328027977

Epoch: 6| Step: 7
Training loss: 0.9618685793894733
Validation loss: 2.694465747456272

Epoch: 6| Step: 8
Training loss: 1.551861672499753
Validation loss: 2.6427669979245643

Epoch: 6| Step: 9
Training loss: 0.9843117829868283
Validation loss: 2.6286029763554803

Epoch: 6| Step: 10
Training loss: 1.1566818049610084
Validation loss: 2.592695581065831

Epoch: 6| Step: 11
Training loss: 0.9853331126516953
Validation loss: 2.6138503477079578

Epoch: 6| Step: 12
Training loss: 1.1423976136121214
Validation loss: 2.6127862162067013

Epoch: 6| Step: 13
Training loss: 1.3319586680933126
Validation loss: 2.557877232053467

Epoch: 394| Step: 0
Training loss: 0.8099986968795279
Validation loss: 2.5687786035731874

Epoch: 6| Step: 1
Training loss: 1.1945953711196016
Validation loss: 2.595619447161629

Epoch: 6| Step: 2
Training loss: 1.3826906829453867
Validation loss: 2.6413710253252063

Epoch: 6| Step: 3
Training loss: 1.5169538198142272
Validation loss: 2.6691595038791207

Epoch: 6| Step: 4
Training loss: 1.3560949632481214
Validation loss: 2.643149484019017

Epoch: 6| Step: 5
Training loss: 1.3467135463162179
Validation loss: 2.7162774634110303

Epoch: 6| Step: 6
Training loss: 1.35433934895798
Validation loss: 2.7501865237008696

Epoch: 6| Step: 7
Training loss: 1.0970159543319495
Validation loss: 2.770367078822616

Epoch: 6| Step: 8
Training loss: 0.963471552729269
Validation loss: 2.7450698528191753

Epoch: 6| Step: 9
Training loss: 1.0319450232662621
Validation loss: 2.7743472617500697

Epoch: 6| Step: 10
Training loss: 0.9626577532904648
Validation loss: 2.8287699404856648

Epoch: 6| Step: 11
Training loss: 1.1570897532527542
Validation loss: 2.7617295412017335

Epoch: 6| Step: 12
Training loss: 0.942382496255614
Validation loss: 2.662134347202855

Epoch: 6| Step: 13
Training loss: 1.2639591415266038
Validation loss: 2.706410698821785

Epoch: 395| Step: 0
Training loss: 0.801024683725591
Validation loss: 2.7027402688543045

Epoch: 6| Step: 1
Training loss: 0.7908219465341078
Validation loss: 2.7153494750365033

Epoch: 6| Step: 2
Training loss: 1.1498762188513203
Validation loss: 2.6581270355090045

Epoch: 6| Step: 3
Training loss: 0.971405021147605
Validation loss: 2.7025531759332595

Epoch: 6| Step: 4
Training loss: 0.7877919004259755
Validation loss: 2.666306133534824

Epoch: 6| Step: 5
Training loss: 1.1145881343750035
Validation loss: 2.667587483886294

Epoch: 6| Step: 6
Training loss: 0.9595731959191902
Validation loss: 2.6179303381870143

Epoch: 6| Step: 7
Training loss: 1.5361706825433694
Validation loss: 2.7017284747550194

Epoch: 6| Step: 8
Training loss: 0.9708556395056939
Validation loss: 2.690150410395324

Epoch: 6| Step: 9
Training loss: 1.159630910180901
Validation loss: 2.7310695178285296

Epoch: 6| Step: 10
Training loss: 1.2783437658246477
Validation loss: 2.740305792017684

Epoch: 6| Step: 11
Training loss: 1.0386908877706733
Validation loss: 2.7573308623184163

Epoch: 6| Step: 12
Training loss: 1.0230302073026538
Validation loss: 2.7477491443887105

Epoch: 6| Step: 13
Training loss: 1.3035794423971179
Validation loss: 2.703950597852564

Epoch: 396| Step: 0
Training loss: 1.005722658810269
Validation loss: 2.6769993591991823

Epoch: 6| Step: 1
Training loss: 1.0306429376654733
Validation loss: 2.6602425283518216

Epoch: 6| Step: 2
Training loss: 1.0677253473678538
Validation loss: 2.626422897583554

Epoch: 6| Step: 3
Training loss: 0.826181181726725
Validation loss: 2.616889595043881

Epoch: 6| Step: 4
Training loss: 1.266568573909627
Validation loss: 2.6373854710208504

Epoch: 6| Step: 5
Training loss: 1.1498268183630385
Validation loss: 2.5986262219486527

Epoch: 6| Step: 6
Training loss: 1.0444324523719803
Validation loss: 2.630676097003541

Epoch: 6| Step: 7
Training loss: 1.4509595918503786
Validation loss: 2.613119267649987

Epoch: 6| Step: 8
Training loss: 1.3908580627589493
Validation loss: 2.5724853483573082

Epoch: 6| Step: 9
Training loss: 1.1825510600318785
Validation loss: 2.5715579771097206

Epoch: 6| Step: 10
Training loss: 1.1488762880130703
Validation loss: 2.6546838818353877

Epoch: 6| Step: 11
Training loss: 0.9345254119961125
Validation loss: 2.6621042999271447

Epoch: 6| Step: 12
Training loss: 1.1307895882638934
Validation loss: 2.695794826234517

Epoch: 6| Step: 13
Training loss: 0.949834459086488
Validation loss: 2.7646362347537345

Epoch: 397| Step: 0
Training loss: 1.0600214265961017
Validation loss: 2.7511398380726435

Epoch: 6| Step: 1
Training loss: 0.7958193499816247
Validation loss: 2.7791611617537564

Epoch: 6| Step: 2
Training loss: 1.0252412233049084
Validation loss: 2.757797529343846

Epoch: 6| Step: 3
Training loss: 1.0593813960689682
Validation loss: 2.7558083893375986

Epoch: 6| Step: 4
Training loss: 1.2254021860196884
Validation loss: 2.654173544291434

Epoch: 6| Step: 5
Training loss: 1.0178469487686024
Validation loss: 2.6359562503650555

Epoch: 6| Step: 6
Training loss: 1.6064288384888583
Validation loss: 2.618652738283891

Epoch: 6| Step: 7
Training loss: 1.0127957183003127
Validation loss: 2.5807231103625226

Epoch: 6| Step: 8
Training loss: 1.6634954641570985
Validation loss: 2.651460465862246

Epoch: 6| Step: 9
Training loss: 1.2492215593698865
Validation loss: 2.627721722748508

Epoch: 6| Step: 10
Training loss: 1.1482597784468582
Validation loss: 2.6585688100058475

Epoch: 6| Step: 11
Training loss: 1.1900660246476369
Validation loss: 2.693034380437756

Epoch: 6| Step: 12
Training loss: 0.7364038079421816
Validation loss: 2.6985458735129852

Epoch: 6| Step: 13
Training loss: 0.8853149729652754
Validation loss: 2.7822789921121367

Epoch: 398| Step: 0
Training loss: 1.1733968389910339
Validation loss: 2.7972548384934135

Epoch: 6| Step: 1
Training loss: 1.1920550971546595
Validation loss: 2.730161985265672

Epoch: 6| Step: 2
Training loss: 1.2796081630161413
Validation loss: 2.702345116335474

Epoch: 6| Step: 3
Training loss: 0.9620506538192616
Validation loss: 2.6862274528256553

Epoch: 6| Step: 4
Training loss: 0.9716932439577258
Validation loss: 2.645867164775989

Epoch: 6| Step: 5
Training loss: 0.8164412203513228
Validation loss: 2.6192578377928806

Epoch: 6| Step: 6
Training loss: 1.1338299621512475
Validation loss: 2.6158715123208482

Epoch: 6| Step: 7
Training loss: 0.8908304011085815
Validation loss: 2.618077110811154

Epoch: 6| Step: 8
Training loss: 1.233728118594225
Validation loss: 2.649927595936817

Epoch: 6| Step: 9
Training loss: 1.220915167130495
Validation loss: 2.6285175642646146

Epoch: 6| Step: 10
Training loss: 0.7117704186386433
Validation loss: 2.637335313835146

Epoch: 6| Step: 11
Training loss: 0.8166050646053783
Validation loss: 2.6499127055731093

Epoch: 6| Step: 12
Training loss: 1.4867460888801063
Validation loss: 2.6772096260254536

Epoch: 6| Step: 13
Training loss: 1.0263267676091923
Validation loss: 2.706147094015183

Epoch: 399| Step: 0
Training loss: 1.3961190979742575
Validation loss: 2.6757405595864454

Epoch: 6| Step: 1
Training loss: 1.1268744218076894
Validation loss: 2.7126143049072606

Epoch: 6| Step: 2
Training loss: 1.0689871720060884
Validation loss: 2.7127652122120955

Epoch: 6| Step: 3
Training loss: 0.7840779049615473
Validation loss: 2.6440314267118805

Epoch: 6| Step: 4
Training loss: 0.810063302898458
Validation loss: 2.6303848257745557

Epoch: 6| Step: 5
Training loss: 0.7671914716256508
Validation loss: 2.6855563298839247

Epoch: 6| Step: 6
Training loss: 0.9317796391511163
Validation loss: 2.642567358490786

Epoch: 6| Step: 7
Training loss: 1.0468055929832614
Validation loss: 2.6605083813214163

Epoch: 6| Step: 8
Training loss: 1.113476652430765
Validation loss: 2.706957032111503

Epoch: 6| Step: 9
Training loss: 1.390188169984365
Validation loss: 2.642076834314865

Epoch: 6| Step: 10
Training loss: 1.0170720282435144
Validation loss: 2.667144931184596

Epoch: 6| Step: 11
Training loss: 1.0045562895767577
Validation loss: 2.7319954827337867

Epoch: 6| Step: 12
Training loss: 0.7922294063882911
Validation loss: 2.7288525354468574

Epoch: 6| Step: 13
Training loss: 1.1383926284747068
Validation loss: 2.7426275351262146

Epoch: 400| Step: 0
Training loss: 1.1819372388084906
Validation loss: 2.7281337753917994

Epoch: 6| Step: 1
Training loss: 0.5830941447837226
Validation loss: 2.6610608087066865

Epoch: 6| Step: 2
Training loss: 1.000299587672899
Validation loss: 2.6795169194000463

Epoch: 6| Step: 3
Training loss: 0.9223936529293528
Validation loss: 2.6202894816015974

Epoch: 6| Step: 4
Training loss: 0.9119756302400985
Validation loss: 2.6326793633218672

Epoch: 6| Step: 5
Training loss: 1.0625427461888945
Validation loss: 2.653807590534731

Epoch: 6| Step: 6
Training loss: 0.7989023262761686
Validation loss: 2.6084810351232646

Epoch: 6| Step: 7
Training loss: 0.9074633795335197
Validation loss: 2.6130022281082956

Epoch: 6| Step: 8
Training loss: 0.9968205511834862
Validation loss: 2.6089562938641295

Epoch: 6| Step: 9
Training loss: 0.8907389651548342
Validation loss: 2.635389581674305

Epoch: 6| Step: 10
Training loss: 1.122748346871565
Validation loss: 2.611922902762363

Epoch: 6| Step: 11
Training loss: 0.9316586666639473
Validation loss: 2.6216770968883485

Epoch: 6| Step: 12
Training loss: 1.120715140500681
Validation loss: 2.596860713131406

Epoch: 6| Step: 13
Training loss: 1.35173130634999
Validation loss: 2.6199043254758396

Epoch: 401| Step: 0
Training loss: 1.073085339568151
Validation loss: 2.651186683650523

Epoch: 6| Step: 1
Training loss: 0.7744123307313353
Validation loss: 2.6743613826639487

Epoch: 6| Step: 2
Training loss: 0.7696791376053789
Validation loss: 2.7330918852844657

Epoch: 6| Step: 3
Training loss: 0.9079686672333414
Validation loss: 2.705590595494534

Epoch: 6| Step: 4
Training loss: 1.0828592045387286
Validation loss: 2.616597487715626

Epoch: 6| Step: 5
Training loss: 0.8748554382797041
Validation loss: 2.7164215552639672

Epoch: 6| Step: 6
Training loss: 1.0628050198021164
Validation loss: 2.6256374765820216

Epoch: 6| Step: 7
Training loss: 0.7770000829070647
Validation loss: 2.6370756986156634

Epoch: 6| Step: 8
Training loss: 1.5841686738931433
Validation loss: 2.6727270660191924

Epoch: 6| Step: 9
Training loss: 1.009367873695184
Validation loss: 2.6257480887479585

Epoch: 6| Step: 10
Training loss: 0.9471718653260399
Validation loss: 2.6362053868254085

Epoch: 6| Step: 11
Training loss: 1.2306898614733779
Validation loss: 2.6573829329152874

Epoch: 6| Step: 12
Training loss: 0.985256920192743
Validation loss: 2.610663623093353

Epoch: 6| Step: 13
Training loss: 0.8156580074252348
Validation loss: 2.663466132302257

Epoch: 402| Step: 0
Training loss: 0.9500665842112407
Validation loss: 2.661094533662477

Epoch: 6| Step: 1
Training loss: 0.8167677813492691
Validation loss: 2.631605964195705

Epoch: 6| Step: 2
Training loss: 1.3432083812622537
Validation loss: 2.6540153827599937

Epoch: 6| Step: 3
Training loss: 0.8215921865434379
Validation loss: 2.690671646121433

Epoch: 6| Step: 4
Training loss: 0.9914224934430897
Validation loss: 2.702383847512162

Epoch: 6| Step: 5
Training loss: 1.2023524987371559
Validation loss: 2.711311790872533

Epoch: 6| Step: 6
Training loss: 0.807544525088151
Validation loss: 2.738288694363432

Epoch: 6| Step: 7
Training loss: 0.9752511336831684
Validation loss: 2.667880502249461

Epoch: 6| Step: 8
Training loss: 0.9393361865443189
Validation loss: 2.6834996487824747

Epoch: 6| Step: 9
Training loss: 1.232674888598549
Validation loss: 2.6900185457226096

Epoch: 6| Step: 10
Training loss: 0.8425752444299827
Validation loss: 2.6696795911975806

Epoch: 6| Step: 11
Training loss: 1.2990519624731893
Validation loss: 2.7200112468356066

Epoch: 6| Step: 12
Training loss: 0.8285450859533219
Validation loss: 2.7183174870830418

Epoch: 6| Step: 13
Training loss: 0.9982193351791421
Validation loss: 2.5981192651801144

Epoch: 403| Step: 0
Training loss: 1.1015586041320735
Validation loss: 2.6747238408795555

Epoch: 6| Step: 1
Training loss: 1.0150682537262705
Validation loss: 2.632368705013668

Epoch: 6| Step: 2
Training loss: 0.6422235501976685
Validation loss: 2.5915188519273435

Epoch: 6| Step: 3
Training loss: 0.638550446425582
Validation loss: 2.671481097894704

Epoch: 6| Step: 4
Training loss: 1.0567146317659661
Validation loss: 2.6051649443622926

Epoch: 6| Step: 5
Training loss: 1.0896879242003796
Validation loss: 2.6614395608756265

Epoch: 6| Step: 6
Training loss: 0.9373861243705363
Validation loss: 2.5857240141211633

Epoch: 6| Step: 7
Training loss: 0.7980293440048569
Validation loss: 2.639594303902156

Epoch: 6| Step: 8
Training loss: 1.0521854250382985
Validation loss: 2.6416757814107705

Epoch: 6| Step: 9
Training loss: 1.0621530302896178
Validation loss: 2.638355265309532

Epoch: 6| Step: 10
Training loss: 1.4716534425538061
Validation loss: 2.5714961054425878

Epoch: 6| Step: 11
Training loss: 1.0914931309825062
Validation loss: 2.6928906160755406

Epoch: 6| Step: 12
Training loss: 0.6694473498911439
Validation loss: 2.652805084123483

Epoch: 6| Step: 13
Training loss: 0.9259575784535932
Validation loss: 2.6734224118004457

Epoch: 404| Step: 0
Training loss: 0.883292042618897
Validation loss: 2.6981645320505536

Epoch: 6| Step: 1
Training loss: 0.8001262684355975
Validation loss: 2.678406604812235

Epoch: 6| Step: 2
Training loss: 0.9355687594790809
Validation loss: 2.6753399932937496

Epoch: 6| Step: 3
Training loss: 0.758256840952656
Validation loss: 2.6732439545921256

Epoch: 6| Step: 4
Training loss: 1.0439240727347032
Validation loss: 2.652513531366626

Epoch: 6| Step: 5
Training loss: 1.0539202124347302
Validation loss: 2.647751110632914

Epoch: 6| Step: 6
Training loss: 1.0313897471674487
Validation loss: 2.6234722762977056

Epoch: 6| Step: 7
Training loss: 0.7887588898872647
Validation loss: 2.6358817422694694

Epoch: 6| Step: 8
Training loss: 0.9195646333427939
Validation loss: 2.575754158294845

Epoch: 6| Step: 9
Training loss: 1.4918143719618222
Validation loss: 2.590420129004755

Epoch: 6| Step: 10
Training loss: 0.9692828036058871
Validation loss: 2.6559257907850946

Epoch: 6| Step: 11
Training loss: 0.8327372246766945
Validation loss: 2.633292210133078

Epoch: 6| Step: 12
Training loss: 1.1782396538998738
Validation loss: 2.669613035023003

Epoch: 6| Step: 13
Training loss: 1.2300084297542602
Validation loss: 2.6706891319001684

Epoch: 405| Step: 0
Training loss: 0.5367349325125353
Validation loss: 2.734230575380448

Epoch: 6| Step: 1
Training loss: 1.5888478301966968
Validation loss: 2.787113245832379

Epoch: 6| Step: 2
Training loss: 1.0318037915859075
Validation loss: 2.769802494513293

Epoch: 6| Step: 3
Training loss: 1.0719193696828686
Validation loss: 2.7775761059561375

Epoch: 6| Step: 4
Training loss: 0.9004130660630422
Validation loss: 2.7972335159425645

Epoch: 6| Step: 5
Training loss: 0.9667762522954372
Validation loss: 2.7538896564678126

Epoch: 6| Step: 6
Training loss: 0.9247132269196219
Validation loss: 2.737744128578134

Epoch: 6| Step: 7
Training loss: 0.837978794109546
Validation loss: 2.6758591837799073

Epoch: 6| Step: 8
Training loss: 1.171871643061598
Validation loss: 2.7111813365026376

Epoch: 6| Step: 9
Training loss: 0.8752353896550844
Validation loss: 2.618265914785577

Epoch: 6| Step: 10
Training loss: 1.161051446551884
Validation loss: 2.694921227402671

Epoch: 6| Step: 11
Training loss: 0.9378199984877688
Validation loss: 2.6762242305535886

Epoch: 6| Step: 12
Training loss: 0.9885510163154797
Validation loss: 2.6834422239477687

Epoch: 6| Step: 13
Training loss: 0.9952017286812312
Validation loss: 2.6299920222907187

Epoch: 406| Step: 0
Training loss: 0.7692362418346871
Validation loss: 2.6805236964948658

Epoch: 6| Step: 1
Training loss: 1.0152970591527781
Validation loss: 2.659095287442894

Epoch: 6| Step: 2
Training loss: 1.1283628746590675
Validation loss: 2.689113132813597

Epoch: 6| Step: 3
Training loss: 0.9512382969781754
Validation loss: 2.6431133877557835

Epoch: 6| Step: 4
Training loss: 1.0234939326678125
Validation loss: 2.642060440831395

Epoch: 6| Step: 5
Training loss: 0.9853790854021294
Validation loss: 2.621382263950621

Epoch: 6| Step: 6
Training loss: 1.2381277861701008
Validation loss: 2.6440574713696985

Epoch: 6| Step: 7
Training loss: 1.4755017542477982
Validation loss: 2.6345448968237233

Epoch: 6| Step: 8
Training loss: 0.827627104306711
Validation loss: 2.6555401769917224

Epoch: 6| Step: 9
Training loss: 0.9223566575062423
Validation loss: 2.6649495025082723

Epoch: 6| Step: 10
Training loss: 1.094251790063312
Validation loss: 2.6981748116220445

Epoch: 6| Step: 11
Training loss: 0.9996968048130117
Validation loss: 2.6973240224753297

Epoch: 6| Step: 12
Training loss: 0.6789820287486384
Validation loss: 2.718839008145862

Epoch: 6| Step: 13
Training loss: 0.8206083581635917
Validation loss: 2.726491320536244

Epoch: 407| Step: 0
Training loss: 1.4099943538309234
Validation loss: 2.699206398670223

Epoch: 6| Step: 1
Training loss: 0.9890346143506753
Validation loss: 2.7064291544545673

Epoch: 6| Step: 2
Training loss: 0.9765773924645709
Validation loss: 2.6246824677983014

Epoch: 6| Step: 3
Training loss: 0.9577544924422302
Validation loss: 2.6637885436657673

Epoch: 6| Step: 4
Training loss: 1.2182731673748128
Validation loss: 2.6777561000440726

Epoch: 6| Step: 5
Training loss: 0.8885136054655103
Validation loss: 2.647975059803838

Epoch: 6| Step: 6
Training loss: 0.9113832969659335
Validation loss: 2.6790885144626717

Epoch: 6| Step: 7
Training loss: 0.7540704419903087
Validation loss: 2.7255309885395804

Epoch: 6| Step: 8
Training loss: 0.8442694160187528
Validation loss: 2.6971899597913414

Epoch: 6| Step: 9
Training loss: 0.9753279550116825
Validation loss: 2.71481914554854

Epoch: 6| Step: 10
Training loss: 0.9337753055519004
Validation loss: 2.716658814736781

Epoch: 6| Step: 11
Training loss: 0.9239185764800737
Validation loss: 2.710435232635956

Epoch: 6| Step: 12
Training loss: 0.6908432559538198
Validation loss: 2.655027684236819

Epoch: 6| Step: 13
Training loss: 0.8038867558821042
Validation loss: 2.6303629965050015

Epoch: 408| Step: 0
Training loss: 1.0522633703809359
Validation loss: 2.6500028262333224

Epoch: 6| Step: 1
Training loss: 1.0083083478075656
Validation loss: 2.653324236239201

Epoch: 6| Step: 2
Training loss: 0.6979583376689998
Validation loss: 2.661495937571966

Epoch: 6| Step: 3
Training loss: 0.8402617722730523
Validation loss: 2.639305868722628

Epoch: 6| Step: 4
Training loss: 1.0454396328786024
Validation loss: 2.661636470996826

Epoch: 6| Step: 5
Training loss: 0.9573643007558433
Validation loss: 2.646145589429761

Epoch: 6| Step: 6
Training loss: 0.7767741738011783
Validation loss: 2.7000071307665063

Epoch: 6| Step: 7
Training loss: 1.1369802691946074
Validation loss: 2.677133319749248

Epoch: 6| Step: 8
Training loss: 1.473221647566199
Validation loss: 2.663609649860779

Epoch: 6| Step: 9
Training loss: 1.2825859362270324
Validation loss: 2.768045964224145

Epoch: 6| Step: 10
Training loss: 0.7429588325231676
Validation loss: 2.722649623985018

Epoch: 6| Step: 11
Training loss: 1.0483251747416307
Validation loss: 2.659659691770824

Epoch: 6| Step: 12
Training loss: 0.7025336852091913
Validation loss: 2.6530853118743725

Epoch: 6| Step: 13
Training loss: 0.8626689551906309
Validation loss: 2.6389623369625377

Epoch: 409| Step: 0
Training loss: 0.9278012542711197
Validation loss: 2.706321634309211

Epoch: 6| Step: 1
Training loss: 1.1385811038340372
Validation loss: 2.6274550250360402

Epoch: 6| Step: 2
Training loss: 0.6081552524628056
Validation loss: 2.6806957249951595

Epoch: 6| Step: 3
Training loss: 0.9887629906708829
Validation loss: 2.7052735185805616

Epoch: 6| Step: 4
Training loss: 0.9850616482259696
Validation loss: 2.667041548564668

Epoch: 6| Step: 5
Training loss: 0.9296653809039869
Validation loss: 2.642476081992529

Epoch: 6| Step: 6
Training loss: 0.9316321158670307
Validation loss: 2.627852933139145

Epoch: 6| Step: 7
Training loss: 1.2616948459120572
Validation loss: 2.677527369820275

Epoch: 6| Step: 8
Training loss: 1.0312835225523287
Validation loss: 2.637466573277402

Epoch: 6| Step: 9
Training loss: 0.9373349044390065
Validation loss: 2.6521414303665383

Epoch: 6| Step: 10
Training loss: 1.2458472890082866
Validation loss: 2.674937851798865

Epoch: 6| Step: 11
Training loss: 0.9803623582481371
Validation loss: 2.7262573800153977

Epoch: 6| Step: 12
Training loss: 0.7030996529990783
Validation loss: 2.6682998057142764

Epoch: 6| Step: 13
Training loss: 0.9297194916165498
Validation loss: 2.6840785966092118

Epoch: 410| Step: 0
Training loss: 1.2707065248018805
Validation loss: 2.693794169288801

Epoch: 6| Step: 1
Training loss: 0.6150519206452546
Validation loss: 2.708113813062426

Epoch: 6| Step: 2
Training loss: 1.27960494896533
Validation loss: 2.6667874030755265

Epoch: 6| Step: 3
Training loss: 0.924518899556277
Validation loss: 2.686727826871382

Epoch: 6| Step: 4
Training loss: 0.6662227498720892
Validation loss: 2.6899570352226427

Epoch: 6| Step: 5
Training loss: 1.077295509458903
Validation loss: 2.5804298655881106

Epoch: 6| Step: 6
Training loss: 0.7048208765991948
Validation loss: 2.656123603356664

Epoch: 6| Step: 7
Training loss: 1.3416324609143662
Validation loss: 2.6312871753667

Epoch: 6| Step: 8
Training loss: 0.9023607260688361
Validation loss: 2.6657789411736594

Epoch: 6| Step: 9
Training loss: 0.9057311183973492
Validation loss: 2.64026262403948

Epoch: 6| Step: 10
Training loss: 0.6815358166060417
Validation loss: 2.6418563108833775

Epoch: 6| Step: 11
Training loss: 0.8111673944322519
Validation loss: 2.6815797521503515

Epoch: 6| Step: 12
Training loss: 0.8316344985270391
Validation loss: 2.667749398682671

Epoch: 6| Step: 13
Training loss: 0.7451337060059774
Validation loss: 2.6845494937101044

Epoch: 411| Step: 0
Training loss: 1.1415399513555238
Validation loss: 2.6661558605754956

Epoch: 6| Step: 1
Training loss: 0.9336227987071696
Validation loss: 2.6459338151569627

Epoch: 6| Step: 2
Training loss: 0.9461379427554402
Validation loss: 2.6857950287810803

Epoch: 6| Step: 3
Training loss: 0.8467398053465858
Validation loss: 2.6373564676578987

Epoch: 6| Step: 4
Training loss: 0.8396621152833454
Validation loss: 2.6449413047388233

Epoch: 6| Step: 5
Training loss: 0.6418813156515528
Validation loss: 2.606808586241016

Epoch: 6| Step: 6
Training loss: 0.8695434322686254
Validation loss: 2.6789183407126207

Epoch: 6| Step: 7
Training loss: 0.9174306388019937
Validation loss: 2.648122583081617

Epoch: 6| Step: 8
Training loss: 0.7236436850777328
Validation loss: 2.6490691265458177

Epoch: 6| Step: 9
Training loss: 0.7131780593617635
Validation loss: 2.628038471927868

Epoch: 6| Step: 10
Training loss: 0.9053289073422504
Validation loss: 2.64572567357776

Epoch: 6| Step: 11
Training loss: 0.7991101203248008
Validation loss: 2.643123813778321

Epoch: 6| Step: 12
Training loss: 1.4479610610120541
Validation loss: 2.603045364572246

Epoch: 6| Step: 13
Training loss: 1.0217942885508973
Validation loss: 2.685083130532854

Epoch: 412| Step: 0
Training loss: 0.9356614841031812
Validation loss: 2.641389980527441

Epoch: 6| Step: 1
Training loss: 1.0638619837555747
Validation loss: 2.6388152803784775

Epoch: 6| Step: 2
Training loss: 1.181102434659565
Validation loss: 2.6853865216094484

Epoch: 6| Step: 3
Training loss: 0.5551915095239363
Validation loss: 2.710214362681104

Epoch: 6| Step: 4
Training loss: 1.1166739717405896
Validation loss: 2.7149190695580745

Epoch: 6| Step: 5
Training loss: 0.9531477628397375
Validation loss: 2.7429425104940215

Epoch: 6| Step: 6
Training loss: 0.9149044430452954
Validation loss: 2.7779171151076483

Epoch: 6| Step: 7
Training loss: 0.9662077987555143
Validation loss: 2.7090116507273927

Epoch: 6| Step: 8
Training loss: 0.9498211240513088
Validation loss: 2.7319530696589442

Epoch: 6| Step: 9
Training loss: 0.5351834255474592
Validation loss: 2.749909139345917

Epoch: 6| Step: 10
Training loss: 1.1472351631274171
Validation loss: 2.699851227417388

Epoch: 6| Step: 11
Training loss: 0.8647330663853202
Validation loss: 2.7179865441137787

Epoch: 6| Step: 12
Training loss: 0.7680494884997112
Validation loss: 2.709277844181181

Epoch: 6| Step: 13
Training loss: 0.7840758904613226
Validation loss: 2.6536452443450087

Epoch: 413| Step: 0
Training loss: 0.7864752171874592
Validation loss: 2.6570071020303017

Epoch: 6| Step: 1
Training loss: 0.7049109136487437
Validation loss: 2.6904174804410568

Epoch: 6| Step: 2
Training loss: 1.051768523350319
Validation loss: 2.6360299423400426

Epoch: 6| Step: 3
Training loss: 1.1326351684679687
Validation loss: 2.663849576941321

Epoch: 6| Step: 4
Training loss: 1.3263746508266316
Validation loss: 2.670586332860633

Epoch: 6| Step: 5
Training loss: 0.8463996679350448
Validation loss: 2.7250617705643885

Epoch: 6| Step: 6
Training loss: 1.0554198936375923
Validation loss: 2.750350915309453

Epoch: 6| Step: 7
Training loss: 0.8195497508910844
Validation loss: 2.6984383558585985

Epoch: 6| Step: 8
Training loss: 0.8294268397995108
Validation loss: 2.674939782959252

Epoch: 6| Step: 9
Training loss: 1.0470366851296684
Validation loss: 2.6621865596949443

Epoch: 6| Step: 10
Training loss: 0.9671995923298591
Validation loss: 2.6586299631090773

Epoch: 6| Step: 11
Training loss: 1.130201237153777
Validation loss: 2.6857446660117827

Epoch: 6| Step: 12
Training loss: 0.8139283756171458
Validation loss: 2.592990748798792

Epoch: 6| Step: 13
Training loss: 0.7795372307862042
Validation loss: 2.616243319271262

Epoch: 414| Step: 0
Training loss: 0.6156903469433057
Validation loss: 2.6074974630117342

Epoch: 6| Step: 1
Training loss: 1.1260497176135145
Validation loss: 2.5954056400226717

Epoch: 6| Step: 2
Training loss: 1.0168830122863568
Validation loss: 2.6463848099976817

Epoch: 6| Step: 3
Training loss: 0.9657776671773468
Validation loss: 2.613277767922249

Epoch: 6| Step: 4
Training loss: 1.098820621967974
Validation loss: 2.6159930639806914

Epoch: 6| Step: 5
Training loss: 0.5323886169659047
Validation loss: 2.6446580955027352

Epoch: 6| Step: 6
Training loss: 0.7813310962548415
Validation loss: 2.5911513949898435

Epoch: 6| Step: 7
Training loss: 1.0741142083363615
Validation loss: 2.6265592409772167

Epoch: 6| Step: 8
Training loss: 0.818762704881709
Validation loss: 2.678826626624973

Epoch: 6| Step: 9
Training loss: 0.9224178203171529
Validation loss: 2.6730775339227573

Epoch: 6| Step: 10
Training loss: 1.0362980717091195
Validation loss: 2.6969226542683185

Epoch: 6| Step: 11
Training loss: 0.7972526777263756
Validation loss: 2.713604673116637

Epoch: 6| Step: 12
Training loss: 1.570747429128726
Validation loss: 2.703317198048646

Epoch: 6| Step: 13
Training loss: 0.8111730523786549
Validation loss: 2.759286762006135

Epoch: 415| Step: 0
Training loss: 1.0195361608628135
Validation loss: 2.7404884661045688

Epoch: 6| Step: 1
Training loss: 0.9292587766338063
Validation loss: 2.765671120814013

Epoch: 6| Step: 2
Training loss: 1.019619583454081
Validation loss: 2.675057180037149

Epoch: 6| Step: 3
Training loss: 0.8973769189070427
Validation loss: 2.7203599905579137

Epoch: 6| Step: 4
Training loss: 1.1430474776338835
Validation loss: 2.7021230704023655

Epoch: 6| Step: 5
Training loss: 0.8311577810316474
Validation loss: 2.690649493700781

Epoch: 6| Step: 6
Training loss: 0.8091123825025303
Validation loss: 2.6837780337149524

Epoch: 6| Step: 7
Training loss: 0.9722381673746596
Validation loss: 2.6903445027845456

Epoch: 6| Step: 8
Training loss: 0.6039368477357621
Validation loss: 2.679554334469846

Epoch: 6| Step: 9
Training loss: 0.8443846964473494
Validation loss: 2.7203563607039825

Epoch: 6| Step: 10
Training loss: 1.0373843990405296
Validation loss: 2.6735683525816785

Epoch: 6| Step: 11
Training loss: 1.2596742582086522
Validation loss: 2.7534139567417717

Epoch: 6| Step: 12
Training loss: 0.9131098943005267
Validation loss: 2.709238639547474

Epoch: 6| Step: 13
Training loss: 0.8083166854822005
Validation loss: 2.609015434298439

Epoch: 416| Step: 0
Training loss: 0.8811657493304659
Validation loss: 2.6324557506975874

Epoch: 6| Step: 1
Training loss: 1.275407823151656
Validation loss: 2.6011674292708236

Epoch: 6| Step: 2
Training loss: 0.7181361521094825
Validation loss: 2.5933678280351264

Epoch: 6| Step: 3
Training loss: 0.9475576363599686
Validation loss: 2.658115599473849

Epoch: 6| Step: 4
Training loss: 0.7328962493735973
Validation loss: 2.611187509057125

Epoch: 6| Step: 5
Training loss: 1.1176659153227457
Validation loss: 2.610467358518381

Epoch: 6| Step: 6
Training loss: 0.901332602452183
Validation loss: 2.6352558815702327

Epoch: 6| Step: 7
Training loss: 1.194717059457005
Validation loss: 2.649559615988315

Epoch: 6| Step: 8
Training loss: 0.7553681741570516
Validation loss: 2.64924864223861

Epoch: 6| Step: 9
Training loss: 1.0029050235259986
Validation loss: 2.6702217653594507

Epoch: 6| Step: 10
Training loss: 1.0131542964514184
Validation loss: 2.65034147857475

Epoch: 6| Step: 11
Training loss: 0.889766111662659
Validation loss: 2.710563377340765

Epoch: 6| Step: 12
Training loss: 0.5930026018333288
Validation loss: 2.6779947226199097

Epoch: 6| Step: 13
Training loss: 0.5852216289345766
Validation loss: 2.6834859220191047

Epoch: 417| Step: 0
Training loss: 0.9512283966378371
Validation loss: 2.6571980448796277

Epoch: 6| Step: 1
Training loss: 0.8471912215941555
Validation loss: 2.635981553242285

Epoch: 6| Step: 2
Training loss: 0.7703229056191363
Validation loss: 2.6681012129585224

Epoch: 6| Step: 3
Training loss: 0.6466326586721266
Validation loss: 2.5556370703739533

Epoch: 6| Step: 4
Training loss: 1.0448283786478725
Validation loss: 2.6504653174253985

Epoch: 6| Step: 5
Training loss: 0.8190173870006366
Validation loss: 2.6438906037778245

Epoch: 6| Step: 6
Training loss: 0.5016800846584512
Validation loss: 2.698093781616492

Epoch: 6| Step: 7
Training loss: 0.843442401624403
Validation loss: 2.6703408281621663

Epoch: 6| Step: 8
Training loss: 1.3066321402646324
Validation loss: 2.6826469753941287

Epoch: 6| Step: 9
Training loss: 1.148838621919753
Validation loss: 2.777583630982632

Epoch: 6| Step: 10
Training loss: 0.75310544981848
Validation loss: 2.7953819395637414

Epoch: 6| Step: 11
Training loss: 0.9545780112857616
Validation loss: 2.732707781463852

Epoch: 6| Step: 12
Training loss: 0.7174593906673568
Validation loss: 2.7852075401744636

Epoch: 6| Step: 13
Training loss: 0.9215663781251022
Validation loss: 2.736321720875469

Epoch: 418| Step: 0
Training loss: 1.0617573330389976
Validation loss: 2.6591298218552204

Epoch: 6| Step: 1
Training loss: 0.6823567560806955
Validation loss: 2.6603186394881906

Epoch: 6| Step: 2
Training loss: 0.7406528870044423
Validation loss: 2.6672455983761005

Epoch: 6| Step: 3
Training loss: 1.034827644445144
Validation loss: 2.7092264512348607

Epoch: 6| Step: 4
Training loss: 0.8173964122155855
Validation loss: 2.6509948806281574

Epoch: 6| Step: 5
Training loss: 1.3338117138671846
Validation loss: 2.642520713135505

Epoch: 6| Step: 6
Training loss: 0.8151908844632832
Validation loss: 2.648579236404273

Epoch: 6| Step: 7
Training loss: 0.6945672488242901
Validation loss: 2.6449864200995794

Epoch: 6| Step: 8
Training loss: 1.110916463703731
Validation loss: 2.657698412163479

Epoch: 6| Step: 9
Training loss: 1.0244696850217503
Validation loss: 2.668084949589864

Epoch: 6| Step: 10
Training loss: 0.8065283006691542
Validation loss: 2.6983005932931854

Epoch: 6| Step: 11
Training loss: 0.644625547042298
Validation loss: 2.7244513644724684

Epoch: 6| Step: 12
Training loss: 0.7795026311554708
Validation loss: 2.6439439655811614

Epoch: 6| Step: 13
Training loss: 0.8923945332035268
Validation loss: 2.7269536186902323

Epoch: 419| Step: 0
Training loss: 0.8810588331723292
Validation loss: 2.7315861458011867

Epoch: 6| Step: 1
Training loss: 1.1610191039288738
Validation loss: 2.751833817237878

Epoch: 6| Step: 2
Training loss: 0.9467767141968639
Validation loss: 2.7012479729551386

Epoch: 6| Step: 3
Training loss: 0.868742776744645
Validation loss: 2.7303283975499375

Epoch: 6| Step: 4
Training loss: 1.0840830165211495
Validation loss: 2.7448849936633617

Epoch: 6| Step: 5
Training loss: 0.7966892923616397
Validation loss: 2.6862010478107634

Epoch: 6| Step: 6
Training loss: 0.593379507420169
Validation loss: 2.69413705156047

Epoch: 6| Step: 7
Training loss: 0.6419649299983675
Validation loss: 2.716377670229898

Epoch: 6| Step: 8
Training loss: 0.6095610603527511
Validation loss: 2.744225928088263

Epoch: 6| Step: 9
Training loss: 1.2168227877238074
Validation loss: 2.7001346077743436

Epoch: 6| Step: 10
Training loss: 1.1271960229765594
Validation loss: 2.7055621029798314

Epoch: 6| Step: 11
Training loss: 0.6719903403351408
Validation loss: 2.655967787168099

Epoch: 6| Step: 12
Training loss: 0.867110859001547
Validation loss: 2.711888464391439

Epoch: 6| Step: 13
Training loss: 0.6942293109386709
Validation loss: 2.724327957040042

Epoch: 420| Step: 0
Training loss: 0.8446677479637931
Validation loss: 2.692535606368445

Epoch: 6| Step: 1
Training loss: 0.9673674469961153
Validation loss: 2.6382892367914486

Epoch: 6| Step: 2
Training loss: 0.5781168550484629
Validation loss: 2.6284217482479484

Epoch: 6| Step: 3
Training loss: 0.5722126334070069
Validation loss: 2.6003007702600525

Epoch: 6| Step: 4
Training loss: 0.9036546243172201
Validation loss: 2.6670017379613955

Epoch: 6| Step: 5
Training loss: 0.8466003451190969
Validation loss: 2.5861765817257645

Epoch: 6| Step: 6
Training loss: 0.9113411455659068
Validation loss: 2.6164932620749477

Epoch: 6| Step: 7
Training loss: 1.0036436694916522
Validation loss: 2.712556895818101

Epoch: 6| Step: 8
Training loss: 0.79472063596273
Validation loss: 2.693101243080828

Epoch: 6| Step: 9
Training loss: 1.320084907734205
Validation loss: 2.673096479837991

Epoch: 6| Step: 10
Training loss: 0.8491395199198442
Validation loss: 2.67182776574812

Epoch: 6| Step: 11
Training loss: 0.8344272625732102
Validation loss: 2.710131522643437

Epoch: 6| Step: 12
Training loss: 1.143902029554139
Validation loss: 2.7371644968476674

Epoch: 6| Step: 13
Training loss: 0.9652081623786716
Validation loss: 2.676717760430545

Epoch: 421| Step: 0
Training loss: 1.1171447105482935
Validation loss: 2.7540731898001183

Epoch: 6| Step: 1
Training loss: 0.9085777248501149
Validation loss: 2.7446670552197006

Epoch: 6| Step: 2
Training loss: 1.2905411071851671
Validation loss: 2.695068790640677

Epoch: 6| Step: 3
Training loss: 0.6633797220881834
Validation loss: 2.6938316220738674

Epoch: 6| Step: 4
Training loss: 0.7604991441354444
Validation loss: 2.719809913841895

Epoch: 6| Step: 5
Training loss: 0.9742385678696126
Validation loss: 2.7206872271867235

Epoch: 6| Step: 6
Training loss: 0.8203858115724617
Validation loss: 2.6341682965391144

Epoch: 6| Step: 7
Training loss: 1.0097403015857214
Validation loss: 2.670246765863342

Epoch: 6| Step: 8
Training loss: 0.49663253122299034
Validation loss: 2.641808509829242

Epoch: 6| Step: 9
Training loss: 0.9228582149851163
Validation loss: 2.6726336526830723

Epoch: 6| Step: 10
Training loss: 0.8938724140550722
Validation loss: 2.646669103127262

Epoch: 6| Step: 11
Training loss: 1.039105407287843
Validation loss: 2.6436141436865874

Epoch: 6| Step: 12
Training loss: 0.8748330570091392
Validation loss: 2.6410480137872847

Epoch: 6| Step: 13
Training loss: 1.2928489790931923
Validation loss: 2.644925785357585

Epoch: 422| Step: 0
Training loss: 1.182028462469088
Validation loss: 2.586816213928613

Epoch: 6| Step: 1
Training loss: 0.6147392581623289
Validation loss: 2.608734394862134

Epoch: 6| Step: 2
Training loss: 0.8024505336168564
Validation loss: 2.626451280346923

Epoch: 6| Step: 3
Training loss: 1.103092348734008
Validation loss: 2.643930612080656

Epoch: 6| Step: 4
Training loss: 0.9215997187930247
Validation loss: 2.701368154224448

Epoch: 6| Step: 5
Training loss: 0.7152618686260642
Validation loss: 2.710429236470621

Epoch: 6| Step: 6
Training loss: 0.6301631806226812
Validation loss: 2.6677713539894965

Epoch: 6| Step: 7
Training loss: 1.3424612119246335
Validation loss: 2.6806367132740787

Epoch: 6| Step: 8
Training loss: 1.0707613706837804
Validation loss: 2.6680408205544106

Epoch: 6| Step: 9
Training loss: 0.9247088115746307
Validation loss: 2.6509855572971284

Epoch: 6| Step: 10
Training loss: 0.8495052580780164
Validation loss: 2.7275561805531208

Epoch: 6| Step: 11
Training loss: 0.6543613003569209
Validation loss: 2.7315421407205838

Epoch: 6| Step: 12
Training loss: 0.7512087618003014
Validation loss: 2.6745070939183

Epoch: 6| Step: 13
Training loss: 0.9114610544799875
Validation loss: 2.7435384032992145

Epoch: 423| Step: 0
Training loss: 0.9075490257324786
Validation loss: 2.697993057720885

Epoch: 6| Step: 1
Training loss: 0.8725743049526351
Validation loss: 2.728235330932391

Epoch: 6| Step: 2
Training loss: 1.0850363635636513
Validation loss: 2.6936712160560243

Epoch: 6| Step: 3
Training loss: 1.009897780486196
Validation loss: 2.6811307647916753

Epoch: 6| Step: 4
Training loss: 0.7013829798077064
Validation loss: 2.7113009748742325

Epoch: 6| Step: 5
Training loss: 0.6190049898334713
Validation loss: 2.701920978038163

Epoch: 6| Step: 6
Training loss: 0.8659763298015427
Validation loss: 2.7652670705900833

Epoch: 6| Step: 7
Training loss: 0.8874908312471688
Validation loss: 2.6987702235797673

Epoch: 6| Step: 8
Training loss: 0.8310980421293604
Validation loss: 2.714868807962895

Epoch: 6| Step: 9
Training loss: 0.7472655197119551
Validation loss: 2.677965728759842

Epoch: 6| Step: 10
Training loss: 0.9168131595655749
Validation loss: 2.710622661092023

Epoch: 6| Step: 11
Training loss: 1.4948636169485052
Validation loss: 2.72286687298062

Epoch: 6| Step: 12
Training loss: 0.7927101728407127
Validation loss: 2.740461322416139

Epoch: 6| Step: 13
Training loss: 0.6721426408555102
Validation loss: 2.713358667296003

Epoch: 424| Step: 0
Training loss: 0.6858211305659795
Validation loss: 2.72802558126416

Epoch: 6| Step: 1
Training loss: 0.8031828803791241
Validation loss: 2.6979971079574026

Epoch: 6| Step: 2
Training loss: 0.7349211102920954
Validation loss: 2.6683109896135573

Epoch: 6| Step: 3
Training loss: 0.8860620091591586
Validation loss: 2.6702195926855574

Epoch: 6| Step: 4
Training loss: 0.5508792330114203
Validation loss: 2.632813737606735

Epoch: 6| Step: 5
Training loss: 1.0589423362298633
Validation loss: 2.633077892959888

Epoch: 6| Step: 6
Training loss: 1.0321097980094438
Validation loss: 2.684956966460201

Epoch: 6| Step: 7
Training loss: 0.8551269266379792
Validation loss: 2.6569355996141932

Epoch: 6| Step: 8
Training loss: 0.7685824514025036
Validation loss: 2.7070939284752353

Epoch: 6| Step: 9
Training loss: 1.0241495814707662
Validation loss: 2.7356843992144837

Epoch: 6| Step: 10
Training loss: 1.096643435387714
Validation loss: 2.6802909623856253

Epoch: 6| Step: 11
Training loss: 1.1956303491786817
Validation loss: 2.680592761223503

Epoch: 6| Step: 12
Training loss: 1.460403589615476
Validation loss: 2.670086059135872

Epoch: 6| Step: 13
Training loss: 0.9708356862728655
Validation loss: 2.6789360364383628

Epoch: 425| Step: 0
Training loss: 1.0701539416405936
Validation loss: 2.7464228541837747

Epoch: 6| Step: 1
Training loss: 1.0398169051903225
Validation loss: 2.7468283888356066

Epoch: 6| Step: 2
Training loss: 1.1912784695500669
Validation loss: 2.7387551239118957

Epoch: 6| Step: 3
Training loss: 0.8407492790389224
Validation loss: 2.6978593965046267

Epoch: 6| Step: 4
Training loss: 1.2893424452621112
Validation loss: 2.757866618460234

Epoch: 6| Step: 5
Training loss: 0.7861329262300966
Validation loss: 2.721602978199655

Epoch: 6| Step: 6
Training loss: 0.8003302443867211
Validation loss: 2.7937476861476207

Epoch: 6| Step: 7
Training loss: 0.9059708921838693
Validation loss: 2.8078946590697984

Epoch: 6| Step: 8
Training loss: 0.8441529901067559
Validation loss: 2.8545926650924915

Epoch: 6| Step: 9
Training loss: 1.0843819653729823
Validation loss: 2.7567533597110714

Epoch: 6| Step: 10
Training loss: 0.9467924528996827
Validation loss: 2.8148901778955557

Epoch: 6| Step: 11
Training loss: 0.8400113315612693
Validation loss: 2.740783331896176

Epoch: 6| Step: 12
Training loss: 0.7830445849756138
Validation loss: 2.676124302018941

Epoch: 6| Step: 13
Training loss: 0.9103844483448446
Validation loss: 2.7058629776020315

Epoch: 426| Step: 0
Training loss: 0.866935452785334
Validation loss: 2.656756678108975

Epoch: 6| Step: 1
Training loss: 0.8231578706798006
Validation loss: 2.635302957084534

Epoch: 6| Step: 2
Training loss: 0.6791915180090607
Validation loss: 2.600972579346106

Epoch: 6| Step: 3
Training loss: 0.8115027249443856
Validation loss: 2.6114490664581065

Epoch: 6| Step: 4
Training loss: 0.8089750561069224
Validation loss: 2.594003917720545

Epoch: 6| Step: 5
Training loss: 0.5962422917025711
Validation loss: 2.5990882693256916

Epoch: 6| Step: 6
Training loss: 0.8366819970244952
Validation loss: 2.5894293436763496

Epoch: 6| Step: 7
Training loss: 1.0082909091715573
Validation loss: 2.615455183185456

Epoch: 6| Step: 8
Training loss: 1.0951745701467275
Validation loss: 2.6630573408724487

Epoch: 6| Step: 9
Training loss: 0.8798543267079239
Validation loss: 2.6780255857493716

Epoch: 6| Step: 10
Training loss: 1.1754050936304408
Validation loss: 2.6702590353702504

Epoch: 6| Step: 11
Training loss: 0.9455521650181323
Validation loss: 2.6647648039446947

Epoch: 6| Step: 12
Training loss: 1.0429752649682404
Validation loss: 2.7513138060253075

Epoch: 6| Step: 13
Training loss: 0.6475625857369813
Validation loss: 2.790522943661776

Epoch: 427| Step: 0
Training loss: 0.7831799891377091
Validation loss: 2.7808250073963783

Epoch: 6| Step: 1
Training loss: 0.9214098775325511
Validation loss: 2.789233247889061

Epoch: 6| Step: 2
Training loss: 1.128322727701971
Validation loss: 2.761637929752672

Epoch: 6| Step: 3
Training loss: 0.9108651801530524
Validation loss: 2.788730384293731

Epoch: 6| Step: 4
Training loss: 0.9083810939539788
Validation loss: 2.75617802843859

Epoch: 6| Step: 5
Training loss: 1.0628971030960708
Validation loss: 2.7697672023795064

Epoch: 6| Step: 6
Training loss: 0.9014662732582135
Validation loss: 2.752085097546028

Epoch: 6| Step: 7
Training loss: 0.7454372533518112
Validation loss: 2.741164506610285

Epoch: 6| Step: 8
Training loss: 1.0364725057632966
Validation loss: 2.7034169445521186

Epoch: 6| Step: 9
Training loss: 1.07318537165141
Validation loss: 2.6941757384962726

Epoch: 6| Step: 10
Training loss: 1.0773975848495014
Validation loss: 2.7107425000271888

Epoch: 6| Step: 11
Training loss: 0.8136760196955656
Validation loss: 2.6912955089240715

Epoch: 6| Step: 12
Training loss: 0.7498438195691371
Validation loss: 2.6933642805283955

Epoch: 6| Step: 13
Training loss: 1.4889998816085983
Validation loss: 2.73585124537956

Epoch: 428| Step: 0
Training loss: 0.9211947307286064
Validation loss: 2.7261563411193013

Epoch: 6| Step: 1
Training loss: 0.664964713759457
Validation loss: 2.7223626903917313

Epoch: 6| Step: 2
Training loss: 0.6338458160711269
Validation loss: 2.707662783044402

Epoch: 6| Step: 3
Training loss: 0.8107573454268575
Validation loss: 2.6945753775788313

Epoch: 6| Step: 4
Training loss: 1.0309225776381001
Validation loss: 2.7589149324853333

Epoch: 6| Step: 5
Training loss: 1.4342035560954283
Validation loss: 2.80156199960018

Epoch: 6| Step: 6
Training loss: 1.3787272826162258
Validation loss: 2.761876340521759

Epoch: 6| Step: 7
Training loss: 0.9859295634631907
Validation loss: 2.7422256829337663

Epoch: 6| Step: 8
Training loss: 1.0150572143364456
Validation loss: 2.6782623297350177

Epoch: 6| Step: 9
Training loss: 0.6811946076437857
Validation loss: 2.713362474925505

Epoch: 6| Step: 10
Training loss: 1.1849551790348067
Validation loss: 2.7610143386346913

Epoch: 6| Step: 11
Training loss: 0.9476976805433658
Validation loss: 2.7111692155498623

Epoch: 6| Step: 12
Training loss: 0.8241410783807497
Validation loss: 2.7527449231112353

Epoch: 6| Step: 13
Training loss: 0.9301443500164495
Validation loss: 2.756519464770162

Epoch: 429| Step: 0
Training loss: 0.9290303063227933
Validation loss: 2.7350236395837664

Epoch: 6| Step: 1
Training loss: 0.9782115593290608
Validation loss: 2.6884300633446276

Epoch: 6| Step: 2
Training loss: 1.0251667468582029
Validation loss: 2.693970645680424

Epoch: 6| Step: 3
Training loss: 1.0722451129890014
Validation loss: 2.673726011397206

Epoch: 6| Step: 4
Training loss: 0.6290962453509096
Validation loss: 2.729772068657773

Epoch: 6| Step: 5
Training loss: 0.933969047162151
Validation loss: 2.708172167359849

Epoch: 6| Step: 6
Training loss: 0.8684059037936069
Validation loss: 2.7878390922770455

Epoch: 6| Step: 7
Training loss: 1.0913059174848336
Validation loss: 2.785073698656435

Epoch: 6| Step: 8
Training loss: 0.8857944729649571
Validation loss: 2.7492429673852854

Epoch: 6| Step: 9
Training loss: 0.9407512554714839
Validation loss: 2.740668126763385

Epoch: 6| Step: 10
Training loss: 0.93830884373577
Validation loss: 2.655996317997835

Epoch: 6| Step: 11
Training loss: 0.7973653369323432
Validation loss: 2.6576349574762346

Epoch: 6| Step: 12
Training loss: 1.276992516247023
Validation loss: 2.756796933532311

Epoch: 6| Step: 13
Training loss: 1.4366276623475436
Validation loss: 2.714578014513974

Epoch: 430| Step: 0
Training loss: 0.713530036850057
Validation loss: 2.728664371383575

Epoch: 6| Step: 1
Training loss: 1.1294381231792099
Validation loss: 2.699365842779687

Epoch: 6| Step: 2
Training loss: 0.9501481078792852
Validation loss: 2.78144574280189

Epoch: 6| Step: 3
Training loss: 0.9849057053680275
Validation loss: 2.7735257631683243

Epoch: 6| Step: 4
Training loss: 1.2858434074898877
Validation loss: 2.814421145954358

Epoch: 6| Step: 5
Training loss: 0.9968738866817751
Validation loss: 2.8611715263070185

Epoch: 6| Step: 6
Training loss: 1.0572402014522975
Validation loss: 2.914494309464355

Epoch: 6| Step: 7
Training loss: 0.7824998775762395
Validation loss: 2.801698046056

Epoch: 6| Step: 8
Training loss: 0.7558490446897842
Validation loss: 2.735134484310619

Epoch: 6| Step: 9
Training loss: 0.9181310631932891
Validation loss: 2.7066062164211573

Epoch: 6| Step: 10
Training loss: 0.7930647693246521
Validation loss: 2.6426272955109913

Epoch: 6| Step: 11
Training loss: 1.112848137378895
Validation loss: 2.667049161976871

Epoch: 6| Step: 12
Training loss: 0.8716586894028318
Validation loss: 2.6326745484808005

Epoch: 6| Step: 13
Training loss: 0.8532970855757895
Validation loss: 2.653751679400624

Epoch: 431| Step: 0
Training loss: 0.9798478063816642
Validation loss: 2.6415778854164556

Epoch: 6| Step: 1
Training loss: 0.8027154405128913
Validation loss: 2.624603211220174

Epoch: 6| Step: 2
Training loss: 0.4804928781297181
Validation loss: 2.600207245954379

Epoch: 6| Step: 3
Training loss: 1.0951259133045894
Validation loss: 2.6441667719745907

Epoch: 6| Step: 4
Training loss: 0.8924175092898761
Validation loss: 2.6348263578246773

Epoch: 6| Step: 5
Training loss: 0.7598543875261676
Validation loss: 2.6581638098768017

Epoch: 6| Step: 6
Training loss: 0.6738825237043096
Validation loss: 2.6786655742509486

Epoch: 6| Step: 7
Training loss: 1.0009740615441318
Validation loss: 2.760588497835712

Epoch: 6| Step: 8
Training loss: 1.097399698596744
Validation loss: 2.783515507528721

Epoch: 6| Step: 9
Training loss: 0.7192988580597884
Validation loss: 2.7774893377805028

Epoch: 6| Step: 10
Training loss: 0.9000453328265656
Validation loss: 2.737026200886984

Epoch: 6| Step: 11
Training loss: 0.651889025792387
Validation loss: 2.788302106878161

Epoch: 6| Step: 12
Training loss: 0.9265820866230539
Validation loss: 2.7426394735854163

Epoch: 6| Step: 13
Training loss: 1.0052740968265155
Validation loss: 2.6949742938899397

Epoch: 432| Step: 0
Training loss: 0.49486250788528147
Validation loss: 2.7186817730640924

Epoch: 6| Step: 1
Training loss: 0.5823401840915514
Validation loss: 2.740401132647955

Epoch: 6| Step: 2
Training loss: 0.9239580575167744
Validation loss: 2.776461375693231

Epoch: 6| Step: 3
Training loss: 0.6658045862275974
Validation loss: 2.74112595373318

Epoch: 6| Step: 4
Training loss: 0.851458551904476
Validation loss: 2.746848048460189

Epoch: 6| Step: 5
Training loss: 0.6971876811425262
Validation loss: 2.759039874983407

Epoch: 6| Step: 6
Training loss: 0.7984434661343726
Validation loss: 2.740254589467567

Epoch: 6| Step: 7
Training loss: 0.698556959787082
Validation loss: 2.718437600731277

Epoch: 6| Step: 8
Training loss: 1.0099167848997164
Validation loss: 2.6696454835050436

Epoch: 6| Step: 9
Training loss: 0.8921602969857663
Validation loss: 2.6826918862034606

Epoch: 6| Step: 10
Training loss: 0.877519861958354
Validation loss: 2.6999416680569293

Epoch: 6| Step: 11
Training loss: 0.7701368708154601
Validation loss: 2.6716812836914885

Epoch: 6| Step: 12
Training loss: 0.6555636995311669
Validation loss: 2.700354411270792

Epoch: 6| Step: 13
Training loss: 0.9207883346287655
Validation loss: 2.6922069109753615

Epoch: 433| Step: 0
Training loss: 0.9203902103276457
Validation loss: 2.6413179199469323

Epoch: 6| Step: 1
Training loss: 0.4263124914030894
Validation loss: 2.640525394645286

Epoch: 6| Step: 2
Training loss: 0.5943874902144923
Validation loss: 2.6592960992950925

Epoch: 6| Step: 3
Training loss: 1.0025255973382832
Validation loss: 2.693811442772685

Epoch: 6| Step: 4
Training loss: 0.7845858119642503
Validation loss: 2.5905127028179775

Epoch: 6| Step: 5
Training loss: 1.280230418863933
Validation loss: 2.6778981246611

Epoch: 6| Step: 6
Training loss: 0.6515611534196217
Validation loss: 2.6419916622916837

Epoch: 6| Step: 7
Training loss: 1.131142378266449
Validation loss: 2.6705745707555915

Epoch: 6| Step: 8
Training loss: 0.7059379470573857
Validation loss: 2.7116203217706745

Epoch: 6| Step: 9
Training loss: 0.6416190738697859
Validation loss: 2.6983187067846135

Epoch: 6| Step: 10
Training loss: 0.9020409013901541
Validation loss: 2.754852118056878

Epoch: 6| Step: 11
Training loss: 0.6912485578635764
Validation loss: 2.745438766687736

Epoch: 6| Step: 12
Training loss: 0.765813843150834
Validation loss: 2.738127017972078

Epoch: 6| Step: 13
Training loss: 0.6456002358250619
Validation loss: 2.7785754684982042

Epoch: 434| Step: 0
Training loss: 0.7029091185718687
Validation loss: 2.837290102383597

Epoch: 6| Step: 1
Training loss: 0.6305644287721142
Validation loss: 2.7197226615069643

Epoch: 6| Step: 2
Training loss: 0.8546031945194537
Validation loss: 2.7722455252655633

Epoch: 6| Step: 3
Training loss: 0.8487236931253533
Validation loss: 2.7012190448047053

Epoch: 6| Step: 4
Training loss: 0.8820204430890349
Validation loss: 2.696221048302533

Epoch: 6| Step: 5
Training loss: 1.038014794367354
Validation loss: 2.7700826493245922

Epoch: 6| Step: 6
Training loss: 0.8438753458801292
Validation loss: 2.6792214361814968

Epoch: 6| Step: 7
Training loss: 0.7111156785300056
Validation loss: 2.6461386366788373

Epoch: 6| Step: 8
Training loss: 0.7365623121945154
Validation loss: 2.621573671917452

Epoch: 6| Step: 9
Training loss: 0.5436785058999791
Validation loss: 2.601867436436107

Epoch: 6| Step: 10
Training loss: 0.9739548926199182
Validation loss: 2.5912846258106983

Epoch: 6| Step: 11
Training loss: 0.5624129969811142
Validation loss: 2.6291285246567577

Epoch: 6| Step: 12
Training loss: 0.815706089709663
Validation loss: 2.645494173995083

Epoch: 6| Step: 13
Training loss: 1.1316852090708835
Validation loss: 2.6353724680776547

Epoch: 435| Step: 0
Training loss: 0.8100539581552489
Validation loss: 2.6422875341619547

Epoch: 6| Step: 1
Training loss: 0.6665299742355274
Validation loss: 2.7258568172051607

Epoch: 6| Step: 2
Training loss: 0.7023582940722675
Validation loss: 2.701341970755967

Epoch: 6| Step: 3
Training loss: 1.117345625350759
Validation loss: 2.708154471922483

Epoch: 6| Step: 4
Training loss: 0.7300317446456063
Validation loss: 2.748781830292699

Epoch: 6| Step: 5
Training loss: 0.9669998110087544
Validation loss: 2.742970643694311

Epoch: 6| Step: 6
Training loss: 0.8008007140236453
Validation loss: 2.725609161813787

Epoch: 6| Step: 7
Training loss: 0.6773383662835938
Validation loss: 2.7037755958684744

Epoch: 6| Step: 8
Training loss: 0.6943886437779553
Validation loss: 2.683227203078952

Epoch: 6| Step: 9
Training loss: 0.8107045950889584
Validation loss: 2.647396291827434

Epoch: 6| Step: 10
Training loss: 0.8034478054624629
Validation loss: 2.588351364867151

Epoch: 6| Step: 11
Training loss: 1.057698339164983
Validation loss: 2.626727103681319

Epoch: 6| Step: 12
Training loss: 0.9489576192463025
Validation loss: 2.636355573343884

Epoch: 6| Step: 13
Training loss: 0.8003041032129451
Validation loss: 2.6679709394007536

Epoch: 436| Step: 0
Training loss: 1.0932615006699202
Validation loss: 2.5649627155992434

Epoch: 6| Step: 1
Training loss: 0.6513857631522498
Validation loss: 2.643784711112395

Epoch: 6| Step: 2
Training loss: 0.5509806062535775
Validation loss: 2.6808162273121705

Epoch: 6| Step: 3
Training loss: 0.9059431937895086
Validation loss: 2.734380057193984

Epoch: 6| Step: 4
Training loss: 0.7484894481621032
Validation loss: 2.7412502502079477

Epoch: 6| Step: 5
Training loss: 0.9985339624075993
Validation loss: 2.7917455382141934

Epoch: 6| Step: 6
Training loss: 0.8488681058776446
Validation loss: 2.801452939241622

Epoch: 6| Step: 7
Training loss: 0.755120125365693
Validation loss: 2.733285101798423

Epoch: 6| Step: 8
Training loss: 1.060677255164842
Validation loss: 2.7429357451551364

Epoch: 6| Step: 9
Training loss: 0.7645916485312625
Validation loss: 2.726473583677131

Epoch: 6| Step: 10
Training loss: 0.9796884174738091
Validation loss: 2.7109069675921185

Epoch: 6| Step: 11
Training loss: 0.6964154871036365
Validation loss: 2.665933960349701

Epoch: 6| Step: 12
Training loss: 0.6227298515977726
Validation loss: 2.744680345703956

Epoch: 6| Step: 13
Training loss: 0.5161472334651902
Validation loss: 2.6638741524529292

Epoch: 437| Step: 0
Training loss: 0.808138327492362
Validation loss: 2.6406851767279913

Epoch: 6| Step: 1
Training loss: 0.8080060730625652
Validation loss: 2.6502406790738884

Epoch: 6| Step: 2
Training loss: 0.7385126790615748
Validation loss: 2.6688375999135316

Epoch: 6| Step: 3
Training loss: 0.9469404153920599
Validation loss: 2.6615304856246573

Epoch: 6| Step: 4
Training loss: 0.6112952177800773
Validation loss: 2.6186999301782152

Epoch: 6| Step: 5
Training loss: 0.5760389271602596
Validation loss: 2.626017562491286

Epoch: 6| Step: 6
Training loss: 0.8149939554961557
Validation loss: 2.6595786088816555

Epoch: 6| Step: 7
Training loss: 0.6717427589330045
Validation loss: 2.698835891386331

Epoch: 6| Step: 8
Training loss: 0.733935569614463
Validation loss: 2.667403750078953

Epoch: 6| Step: 9
Training loss: 0.8581271041099718
Validation loss: 2.772371844949281

Epoch: 6| Step: 10
Training loss: 0.6442815123412866
Validation loss: 2.678868797991992

Epoch: 6| Step: 11
Training loss: 0.986717645760807
Validation loss: 2.669997673009842

Epoch: 6| Step: 12
Training loss: 0.5197544908957985
Validation loss: 2.6853133332402037

Epoch: 6| Step: 13
Training loss: 0.9408568365868473
Validation loss: 2.6875761597953494

Epoch: 438| Step: 0
Training loss: 0.916771972994202
Validation loss: 2.6394945015796725

Epoch: 6| Step: 1
Training loss: 0.5251799093522094
Validation loss: 2.6672616284972346

Epoch: 6| Step: 2
Training loss: 0.7169650761386686
Validation loss: 2.6929754915402966

Epoch: 6| Step: 3
Training loss: 0.9295082239994792
Validation loss: 2.6828163349862555

Epoch: 6| Step: 4
Training loss: 0.8716067185097898
Validation loss: 2.7095942032023226

Epoch: 6| Step: 5
Training loss: 0.6394228005836115
Validation loss: 2.6545334149885726

Epoch: 6| Step: 6
Training loss: 0.726078569595446
Validation loss: 2.7026460697387913

Epoch: 6| Step: 7
Training loss: 0.6352859008144448
Validation loss: 2.642930764077461

Epoch: 6| Step: 8
Training loss: 0.7422362863668497
Validation loss: 2.6734216091710055

Epoch: 6| Step: 9
Training loss: 0.8633819107125927
Validation loss: 2.727895161435338

Epoch: 6| Step: 10
Training loss: 0.7344035285115923
Validation loss: 2.700593825371261

Epoch: 6| Step: 11
Training loss: 0.7291671662101851
Validation loss: 2.687182917852185

Epoch: 6| Step: 12
Training loss: 0.9813461025824383
Validation loss: 2.7125083044250218

Epoch: 6| Step: 13
Training loss: 0.9339682494286714
Validation loss: 2.6906398647250707

Epoch: 439| Step: 0
Training loss: 0.9684412987367734
Validation loss: 2.642170132354919

Epoch: 6| Step: 1
Training loss: 0.6665674647393593
Validation loss: 2.6906227776388634

Epoch: 6| Step: 2
Training loss: 0.7911856009504769
Validation loss: 2.675691344149944

Epoch: 6| Step: 3
Training loss: 0.6094464969262369
Validation loss: 2.700209866715033

Epoch: 6| Step: 4
Training loss: 0.5989914484130067
Validation loss: 2.73189284516127

Epoch: 6| Step: 5
Training loss: 1.0755231671003955
Validation loss: 2.710727474640795

Epoch: 6| Step: 6
Training loss: 0.7183142875556873
Validation loss: 2.7507020025404403

Epoch: 6| Step: 7
Training loss: 0.546937829904301
Validation loss: 2.7319295938261976

Epoch: 6| Step: 8
Training loss: 0.845283033946815
Validation loss: 2.7761582761014316

Epoch: 6| Step: 9
Training loss: 1.0621599326353979
Validation loss: 2.773940707838441

Epoch: 6| Step: 10
Training loss: 0.7869601806397041
Validation loss: 2.731810080673919

Epoch: 6| Step: 11
Training loss: 0.6870018498105683
Validation loss: 2.783064289757252

Epoch: 6| Step: 12
Training loss: 0.8676260105814707
Validation loss: 2.701761706781073

Epoch: 6| Step: 13
Training loss: 1.0273335967631891
Validation loss: 2.7422282187834055

Epoch: 440| Step: 0
Training loss: 0.9239740881424242
Validation loss: 2.6903523825762443

Epoch: 6| Step: 1
Training loss: 0.6771033259643482
Validation loss: 2.645018885256021

Epoch: 6| Step: 2
Training loss: 0.5174168749404532
Validation loss: 2.663654986076855

Epoch: 6| Step: 3
Training loss: 0.9461722759541741
Validation loss: 2.655311583263336

Epoch: 6| Step: 4
Training loss: 0.6336431585160636
Validation loss: 2.635953348470551

Epoch: 6| Step: 5
Training loss: 0.6681964999088691
Validation loss: 2.674340580980786

Epoch: 6| Step: 6
Training loss: 0.9111254202163612
Validation loss: 2.670364399021147

Epoch: 6| Step: 7
Training loss: 0.7044289683506554
Validation loss: 2.637582369056045

Epoch: 6| Step: 8
Training loss: 0.6027302492782991
Validation loss: 2.628071017926165

Epoch: 6| Step: 9
Training loss: 1.0840176413990312
Validation loss: 2.645324227520565

Epoch: 6| Step: 10
Training loss: 0.8814594060581298
Validation loss: 2.66611794448895

Epoch: 6| Step: 11
Training loss: 0.5710036388020724
Validation loss: 2.70147472420649

Epoch: 6| Step: 12
Training loss: 0.47497916238654475
Validation loss: 2.722426139780109

Epoch: 6| Step: 13
Training loss: 1.1169323930045667
Validation loss: 2.7628392703091174

Epoch: 441| Step: 0
Training loss: 0.8851832063346297
Validation loss: 2.703207260967587

Epoch: 6| Step: 1
Training loss: 0.7677718444667953
Validation loss: 2.777981140851755

Epoch: 6| Step: 2
Training loss: 0.8688773452953241
Validation loss: 2.7099403064389223

Epoch: 6| Step: 3
Training loss: 0.9841682580283077
Validation loss: 2.7648810124102745

Epoch: 6| Step: 4
Training loss: 0.8361586518851769
Validation loss: 2.7663746767810777

Epoch: 6| Step: 5
Training loss: 1.0735905700556552
Validation loss: 2.756560260152085

Epoch: 6| Step: 6
Training loss: 0.9262050189938079
Validation loss: 2.7585845673425458

Epoch: 6| Step: 7
Training loss: 0.7910422238245896
Validation loss: 2.7911455654953983

Epoch: 6| Step: 8
Training loss: 0.950860256401207
Validation loss: 2.872534122867502

Epoch: 6| Step: 9
Training loss: 0.9742288094913589
Validation loss: 2.8281573580020067

Epoch: 6| Step: 10
Training loss: 0.7423514335682716
Validation loss: 2.8119165451124695

Epoch: 6| Step: 11
Training loss: 0.9185211467520166
Validation loss: 2.7863680435716063

Epoch: 6| Step: 12
Training loss: 1.0614912630063913
Validation loss: 2.7356055261088605

Epoch: 6| Step: 13
Training loss: 0.7415742850542714
Validation loss: 2.712184490951297

Epoch: 442| Step: 0
Training loss: 0.8032655466797178
Validation loss: 2.661870925684045

Epoch: 6| Step: 1
Training loss: 0.575345057115898
Validation loss: 2.684486607106607

Epoch: 6| Step: 2
Training loss: 1.1275498844792349
Validation loss: 2.7034578210348204

Epoch: 6| Step: 3
Training loss: 0.47609213770864756
Validation loss: 2.6872270430705942

Epoch: 6| Step: 4
Training loss: 0.8703774556381864
Validation loss: 2.663646736404938

Epoch: 6| Step: 5
Training loss: 0.5730593648120191
Validation loss: 2.7147582701620805

Epoch: 6| Step: 6
Training loss: 0.8556987505518601
Validation loss: 2.6640755213981393

Epoch: 6| Step: 7
Training loss: 0.6805364196275492
Validation loss: 2.6675142838519608

Epoch: 6| Step: 8
Training loss: 0.5355735321422249
Validation loss: 2.743439985182096

Epoch: 6| Step: 9
Training loss: 0.9741402760388108
Validation loss: 2.7285102947950355

Epoch: 6| Step: 10
Training loss: 0.65835807176377
Validation loss: 2.7254907784365163

Epoch: 6| Step: 11
Training loss: 0.7684344303027905
Validation loss: 2.662315340160496

Epoch: 6| Step: 12
Training loss: 0.7698883544809116
Validation loss: 2.6883753156921504

Epoch: 6| Step: 13
Training loss: 0.9607933990856846
Validation loss: 2.7239253161868544

Epoch: 443| Step: 0
Training loss: 0.694410574934792
Validation loss: 2.68991930690497

Epoch: 6| Step: 1
Training loss: 0.6358034540941143
Validation loss: 2.7472191679984372

Epoch: 6| Step: 2
Training loss: 1.0798168452690402
Validation loss: 2.71588207121156

Epoch: 6| Step: 3
Training loss: 0.8513469598252661
Validation loss: 2.776891014229813

Epoch: 6| Step: 4
Training loss: 0.5423971776601905
Validation loss: 2.755053616213754

Epoch: 6| Step: 5
Training loss: 0.7524207308513667
Validation loss: 2.706006412541267

Epoch: 6| Step: 6
Training loss: 0.8697156739683047
Validation loss: 2.6808083194905246

Epoch: 6| Step: 7
Training loss: 0.6059271768966422
Validation loss: 2.654121713142837

Epoch: 6| Step: 8
Training loss: 0.7351128138683642
Validation loss: 2.656372007672065

Epoch: 6| Step: 9
Training loss: 1.0351913734091336
Validation loss: 2.7191727262104624

Epoch: 6| Step: 10
Training loss: 0.6140706030235787
Validation loss: 2.6261965128847313

Epoch: 6| Step: 11
Training loss: 0.7854885328149074
Validation loss: 2.6729186178206716

Epoch: 6| Step: 12
Training loss: 1.1039085566340683
Validation loss: 2.683933523435979

Epoch: 6| Step: 13
Training loss: 0.5549142132433846
Validation loss: 2.70159817538397

Epoch: 444| Step: 0
Training loss: 0.7160599165732745
Validation loss: 2.65990226828984

Epoch: 6| Step: 1
Training loss: 1.0540838704118505
Validation loss: 2.7414105973091925

Epoch: 6| Step: 2
Training loss: 0.974348503471913
Validation loss: 2.807592447807668

Epoch: 6| Step: 3
Training loss: 0.5242345918402138
Validation loss: 2.7965059658509577

Epoch: 6| Step: 4
Training loss: 1.0486445488275646
Validation loss: 2.8671224311284575

Epoch: 6| Step: 5
Training loss: 0.8882126512435187
Validation loss: 2.8261071412802017

Epoch: 6| Step: 6
Training loss: 0.6957765809250929
Validation loss: 2.705400541809649

Epoch: 6| Step: 7
Training loss: 0.6511592504493818
Validation loss: 2.615527166301457

Epoch: 6| Step: 8
Training loss: 0.8366529308827889
Validation loss: 2.644151954365494

Epoch: 6| Step: 9
Training loss: 0.9140131032263242
Validation loss: 2.6500642744702723

Epoch: 6| Step: 10
Training loss: 0.7585539189576463
Validation loss: 2.665858330004751

Epoch: 6| Step: 11
Training loss: 1.2392314550363912
Validation loss: 2.63997520261736

Epoch: 6| Step: 12
Training loss: 0.7441263272571438
Validation loss: 2.6337193890159467

Epoch: 6| Step: 13
Training loss: 0.6353955708321435
Validation loss: 2.577976654100423

Epoch: 445| Step: 0
Training loss: 0.8338544328932582
Validation loss: 2.686830111857225

Epoch: 6| Step: 1
Training loss: 0.7475503015338595
Validation loss: 2.747554631035736

Epoch: 6| Step: 2
Training loss: 0.5865169711523464
Validation loss: 2.749044555799767

Epoch: 6| Step: 3
Training loss: 0.9740061756698054
Validation loss: 2.7632162232962925

Epoch: 6| Step: 4
Training loss: 0.8129280869936208
Validation loss: 2.78427956271632

Epoch: 6| Step: 5
Training loss: 0.7044894014012065
Validation loss: 2.7086654801760055

Epoch: 6| Step: 6
Training loss: 0.8002014666435417
Validation loss: 2.736439650207641

Epoch: 6| Step: 7
Training loss: 0.8366245761735186
Validation loss: 2.7233426411476276

Epoch: 6| Step: 8
Training loss: 0.8907861731071509
Validation loss: 2.697406217284151

Epoch: 6| Step: 9
Training loss: 0.35698310310383297
Validation loss: 2.72704393277266

Epoch: 6| Step: 10
Training loss: 0.41817002485960875
Validation loss: 2.7688317825719317

Epoch: 6| Step: 11
Training loss: 1.022773235906568
Validation loss: 2.6618171544569686

Epoch: 6| Step: 12
Training loss: 0.7252194286295098
Validation loss: 2.6924285497367655

Epoch: 6| Step: 13
Training loss: 0.7732732193769369
Validation loss: 2.768042863454228

Epoch: 446| Step: 0
Training loss: 0.660377961798544
Validation loss: 2.689290625622541

Epoch: 6| Step: 1
Training loss: 0.9934953195282145
Validation loss: 2.7462322838659943

Epoch: 6| Step: 2
Training loss: 0.865526550423449
Validation loss: 2.7172269830363267

Epoch: 6| Step: 3
Training loss: 0.7766121339958685
Validation loss: 2.795272723377464

Epoch: 6| Step: 4
Training loss: 0.6979073528598275
Validation loss: 2.702029923318275

Epoch: 6| Step: 5
Training loss: 0.7944667928800839
Validation loss: 2.7157046629382444

Epoch: 6| Step: 6
Training loss: 0.7158756416868115
Validation loss: 2.7292413385867684

Epoch: 6| Step: 7
Training loss: 0.6901127628774691
Validation loss: 2.7741363218081587

Epoch: 6| Step: 8
Training loss: 0.6510746655048527
Validation loss: 2.7661001009288992

Epoch: 6| Step: 9
Training loss: 0.5813506070098503
Validation loss: 2.7237604675978835

Epoch: 6| Step: 10
Training loss: 0.7542448321207467
Validation loss: 2.695996316604475

Epoch: 6| Step: 11
Training loss: 0.8988431926792277
Validation loss: 2.71864090623885

Epoch: 6| Step: 12
Training loss: 0.9187437641165725
Validation loss: 2.731787876382665

Epoch: 6| Step: 13
Training loss: 0.6840399893258564
Validation loss: 2.6797182694903077

Epoch: 447| Step: 0
Training loss: 0.9331344049060263
Validation loss: 2.712208818959241

Epoch: 6| Step: 1
Training loss: 0.6849198911282863
Validation loss: 2.72567050920629

Epoch: 6| Step: 2
Training loss: 0.9727540177689017
Validation loss: 2.72479664513323

Epoch: 6| Step: 3
Training loss: 0.5822490310300542
Validation loss: 2.7084930421738562

Epoch: 6| Step: 4
Training loss: 0.8004903869861821
Validation loss: 2.6858461155490105

Epoch: 6| Step: 5
Training loss: 0.662681602383427
Validation loss: 2.688367422715092

Epoch: 6| Step: 6
Training loss: 0.6037369849893173
Validation loss: 2.695538630190856

Epoch: 6| Step: 7
Training loss: 0.9564693747810769
Validation loss: 2.711980760042853

Epoch: 6| Step: 8
Training loss: 0.4153724677634046
Validation loss: 2.63868769469885

Epoch: 6| Step: 9
Training loss: 0.9969281759399423
Validation loss: 2.674928463368506

Epoch: 6| Step: 10
Training loss: 0.5683951874556753
Validation loss: 2.7213729103331152

Epoch: 6| Step: 11
Training loss: 0.505090844037727
Validation loss: 2.66511763842077

Epoch: 6| Step: 12
Training loss: 1.1139439266926727
Validation loss: 2.6847621367670667

Epoch: 6| Step: 13
Training loss: 0.5208250871641315
Validation loss: 2.702265314245178

Epoch: 448| Step: 0
Training loss: 0.6215729694050518
Validation loss: 2.708551659709507

Epoch: 6| Step: 1
Training loss: 0.6167648655012603
Validation loss: 2.7431124207816695

Epoch: 6| Step: 2
Training loss: 0.7782647892042742
Validation loss: 2.6813592469101186

Epoch: 6| Step: 3
Training loss: 0.9636381393112815
Validation loss: 2.736475604501004

Epoch: 6| Step: 4
Training loss: 0.4630298002881618
Validation loss: 2.68094158577377

Epoch: 6| Step: 5
Training loss: 0.7099022926340833
Validation loss: 2.7561919698567734

Epoch: 6| Step: 6
Training loss: 0.8033429365916324
Validation loss: 2.752005799265229

Epoch: 6| Step: 7
Training loss: 0.7121841901942462
Validation loss: 2.6819353823775125

Epoch: 6| Step: 8
Training loss: 0.7960600332021398
Validation loss: 2.6887187633890157

Epoch: 6| Step: 9
Training loss: 1.1075086340987466
Validation loss: 2.6760668822561033

Epoch: 6| Step: 10
Training loss: 0.5390099209560698
Validation loss: 2.685575565069288

Epoch: 6| Step: 11
Training loss: 0.7651621139392032
Validation loss: 2.6402811281719307

Epoch: 6| Step: 12
Training loss: 0.4151408530679789
Validation loss: 2.632506008400963

Epoch: 6| Step: 13
Training loss: 0.6665526878754288
Validation loss: 2.69086191313605

Epoch: 449| Step: 0
Training loss: 0.5372564495901284
Validation loss: 2.6125587639291314

Epoch: 6| Step: 1
Training loss: 0.5568700217335959
Validation loss: 2.6320047016565598

Epoch: 6| Step: 2
Training loss: 0.5413535814965366
Validation loss: 2.615858615543637

Epoch: 6| Step: 3
Training loss: 0.7240466788929719
Validation loss: 2.6158736086107828

Epoch: 6| Step: 4
Training loss: 0.8593716361240094
Validation loss: 2.677078519190951

Epoch: 6| Step: 5
Training loss: 0.665759845739625
Validation loss: 2.6236549443337784

Epoch: 6| Step: 6
Training loss: 0.3293494131729043
Validation loss: 2.694909254491409

Epoch: 6| Step: 7
Training loss: 0.8208699466717657
Validation loss: 2.746513685492237

Epoch: 6| Step: 8
Training loss: 0.8238526747162662
Validation loss: 2.7040615627590356

Epoch: 6| Step: 9
Training loss: 0.6771113805586023
Validation loss: 2.7139189025336816

Epoch: 6| Step: 10
Training loss: 0.632153367928076
Validation loss: 2.784186552430191

Epoch: 6| Step: 11
Training loss: 0.8650305789988868
Validation loss: 2.7084047797144786

Epoch: 6| Step: 12
Training loss: 0.9000201673367403
Validation loss: 2.717673589197509

Epoch: 6| Step: 13
Training loss: 0.8060518568362204
Validation loss: 2.7209739650661695

Epoch: 450| Step: 0
Training loss: 0.7165159251751932
Validation loss: 2.653585181823757

Epoch: 6| Step: 1
Training loss: 0.8249852381454829
Validation loss: 2.7213863875871125

Epoch: 6| Step: 2
Training loss: 0.9671793479760764
Validation loss: 2.709986832411942

Epoch: 6| Step: 3
Training loss: 0.4859502465640079
Validation loss: 2.6714372778270525

Epoch: 6| Step: 4
Training loss: 0.4072465411438016
Validation loss: 2.7222699147110028

Epoch: 6| Step: 5
Training loss: 0.5632854382151583
Validation loss: 2.734435380541485

Epoch: 6| Step: 6
Training loss: 0.6694085960256252
Validation loss: 2.7171257399562854

Epoch: 6| Step: 7
Training loss: 0.5910182904916425
Validation loss: 2.7964371350895068

Epoch: 6| Step: 8
Training loss: 0.9288700260321275
Validation loss: 2.6891427157619723

Epoch: 6| Step: 9
Training loss: 0.5410300848505508
Validation loss: 2.729608126357736

Epoch: 6| Step: 10
Training loss: 0.9175648876289301
Validation loss: 2.7649651870007568

Epoch: 6| Step: 11
Training loss: 0.7288285470577542
Validation loss: 2.7505898421061024

Epoch: 6| Step: 12
Training loss: 0.4390622922957937
Validation loss: 2.716721929288432

Epoch: 6| Step: 13
Training loss: 0.7973891077104743
Validation loss: 2.6851067495643806

Epoch: 451| Step: 0
Training loss: 0.6623559453282012
Validation loss: 2.7545452053039625

Epoch: 6| Step: 1
Training loss: 0.747919295863327
Validation loss: 2.67480548971442

Epoch: 6| Step: 2
Training loss: 0.6374932709507066
Validation loss: 2.7158382798795864

Epoch: 6| Step: 3
Training loss: 0.9912760295072043
Validation loss: 2.6676035566407585

Epoch: 6| Step: 4
Training loss: 0.6385325708617855
Validation loss: 2.7080913631235135

Epoch: 6| Step: 5
Training loss: 0.7473035660168458
Validation loss: 2.723842397134812

Epoch: 6| Step: 6
Training loss: 0.9717997874506035
Validation loss: 2.717118339981898

Epoch: 6| Step: 7
Training loss: 0.9341080657473538
Validation loss: 2.707574625604165

Epoch: 6| Step: 8
Training loss: 0.853282800689445
Validation loss: 2.7989979932213833

Epoch: 6| Step: 9
Training loss: 0.5504699801437488
Validation loss: 2.7501273559210673

Epoch: 6| Step: 10
Training loss: 0.7504770827838465
Validation loss: 2.6956632524124937

Epoch: 6| Step: 11
Training loss: 0.7089961447671473
Validation loss: 2.695098367192181

Epoch: 6| Step: 12
Training loss: 0.6884974699701103
Validation loss: 2.70834040029533

Epoch: 6| Step: 13
Training loss: 0.7109710350092121
Validation loss: 2.6834935628151464

Epoch: 452| Step: 0
Training loss: 0.9236047325455792
Validation loss: 2.662226009449346

Epoch: 6| Step: 1
Training loss: 0.7732865928084551
Validation loss: 2.6798821944824587

Epoch: 6| Step: 2
Training loss: 0.9551539478745402
Validation loss: 2.694975930544651

Epoch: 6| Step: 3
Training loss: 0.6227773723275806
Validation loss: 2.73307917816671

Epoch: 6| Step: 4
Training loss: 0.5867986327546099
Validation loss: 2.692250968611527

Epoch: 6| Step: 5
Training loss: 0.43699586296087384
Validation loss: 2.737384731008387

Epoch: 6| Step: 6
Training loss: 0.4936813361071305
Validation loss: 2.6907456486523915

Epoch: 6| Step: 7
Training loss: 0.5906697735643732
Validation loss: 2.82679752506547

Epoch: 6| Step: 8
Training loss: 0.7263614007073621
Validation loss: 2.805019249240878

Epoch: 6| Step: 9
Training loss: 0.8772015124249238
Validation loss: 2.7063361115297084

Epoch: 6| Step: 10
Training loss: 0.7408596407535748
Validation loss: 2.7659241825211702

Epoch: 6| Step: 11
Training loss: 0.7660246603908019
Validation loss: 2.7510735843708223

Epoch: 6| Step: 12
Training loss: 0.7401802626989337
Validation loss: 2.6744649726369687

Epoch: 6| Step: 13
Training loss: 0.820295824153883
Validation loss: 2.729293766896242

Epoch: 453| Step: 0
Training loss: 0.44535715314281904
Validation loss: 2.723125532253967

Epoch: 6| Step: 1
Training loss: 0.553851209092962
Validation loss: 2.739421054012859

Epoch: 6| Step: 2
Training loss: 0.7706263925952812
Validation loss: 2.737935405808917

Epoch: 6| Step: 3
Training loss: 0.8130095058110662
Validation loss: 2.694361031334662

Epoch: 6| Step: 4
Training loss: 0.8655510316499833
Validation loss: 2.6781308107672865

Epoch: 6| Step: 5
Training loss: 0.7334562195061898
Validation loss: 2.714582003409898

Epoch: 6| Step: 6
Training loss: 0.5369941726595708
Validation loss: 2.702466439818925

Epoch: 6| Step: 7
Training loss: 0.8302102735457649
Validation loss: 2.745368814804478

Epoch: 6| Step: 8
Training loss: 0.6197814753573402
Validation loss: 2.6899962106604756

Epoch: 6| Step: 9
Training loss: 0.8424563203576255
Validation loss: 2.7378375700239777

Epoch: 6| Step: 10
Training loss: 0.661273800398154
Validation loss: 2.7280126320564175

Epoch: 6| Step: 11
Training loss: 0.7128336844501013
Validation loss: 2.68399823660397

Epoch: 6| Step: 12
Training loss: 0.8536928459908871
Validation loss: 2.7058801593572435

Epoch: 6| Step: 13
Training loss: 0.6105704929618583
Validation loss: 2.6669030208946776

Epoch: 454| Step: 0
Training loss: 0.7051981562260906
Validation loss: 2.6869958656079524

Epoch: 6| Step: 1
Training loss: 0.5080390131549007
Validation loss: 2.7184943009490383

Epoch: 6| Step: 2
Training loss: 0.4944836477598023
Validation loss: 2.6934710122868863

Epoch: 6| Step: 3
Training loss: 0.7645674817332954
Validation loss: 2.6785096452036257

Epoch: 6| Step: 4
Training loss: 0.7776184363481379
Validation loss: 2.6985855942498844

Epoch: 6| Step: 5
Training loss: 0.7939988009181925
Validation loss: 2.699835464385642

Epoch: 6| Step: 6
Training loss: 0.6302342580291802
Validation loss: 2.7401418708818

Epoch: 6| Step: 7
Training loss: 0.8901399328829794
Validation loss: 2.744824220487223

Epoch: 6| Step: 8
Training loss: 0.8615542437213501
Validation loss: 2.756515486106962

Epoch: 6| Step: 9
Training loss: 0.7203988774406841
Validation loss: 2.802368622240444

Epoch: 6| Step: 10
Training loss: 0.8553169150581739
Validation loss: 2.7999984803649776

Epoch: 6| Step: 11
Training loss: 0.5159981562208162
Validation loss: 2.7872313143300307

Epoch: 6| Step: 12
Training loss: 0.41393195199567506
Validation loss: 2.8559839816209673

Epoch: 6| Step: 13
Training loss: 0.9573484556824303
Validation loss: 2.8181912236974984

Epoch: 455| Step: 0
Training loss: 0.7556254890004888
Validation loss: 2.8618026044888425

Epoch: 6| Step: 1
Training loss: 0.8337251854539537
Validation loss: 2.8492887724910183

Epoch: 6| Step: 2
Training loss: 1.0671899172754125
Validation loss: 2.7732104857758553

Epoch: 6| Step: 3
Training loss: 0.772927395385422
Validation loss: 2.718335803405213

Epoch: 6| Step: 4
Training loss: 0.48607371466463334
Validation loss: 2.6983609711250884

Epoch: 6| Step: 5
Training loss: 0.9363915248090525
Validation loss: 2.760076614643364

Epoch: 6| Step: 6
Training loss: 0.8618231840650615
Validation loss: 2.7681880216988826

Epoch: 6| Step: 7
Training loss: 0.8488029072469958
Validation loss: 2.735264500852341

Epoch: 6| Step: 8
Training loss: 1.0397862373342275
Validation loss: 2.7044868934028368

Epoch: 6| Step: 9
Training loss: 0.5126021527619837
Validation loss: 2.7463834997692085

Epoch: 6| Step: 10
Training loss: 0.614447390074258
Validation loss: 2.7354102799708313

Epoch: 6| Step: 11
Training loss: 0.6981929735032852
Validation loss: 2.857124721662548

Epoch: 6| Step: 12
Training loss: 0.9795414768645947
Validation loss: 2.8906810308301294

Epoch: 6| Step: 13
Training loss: 1.0342533420345537
Validation loss: 2.9082510700633213

Epoch: 456| Step: 0
Training loss: 0.6739364315839221
Validation loss: 2.8724458931612618

Epoch: 6| Step: 1
Training loss: 0.7896249862460748
Validation loss: 2.6824932479417902

Epoch: 6| Step: 2
Training loss: 0.5067871305453013
Validation loss: 2.7263167743297365

Epoch: 6| Step: 3
Training loss: 1.019172108267363
Validation loss: 2.7111921969475468

Epoch: 6| Step: 4
Training loss: 0.875212915946249
Validation loss: 2.647126750240722

Epoch: 6| Step: 5
Training loss: 0.6533321043127852
Validation loss: 2.6714686183220273

Epoch: 6| Step: 6
Training loss: 0.7995602114145288
Validation loss: 2.6320291970753478

Epoch: 6| Step: 7
Training loss: 0.6596045587136347
Validation loss: 2.617955413058863

Epoch: 6| Step: 8
Training loss: 0.6924323533685776
Validation loss: 2.6198313023101285

Epoch: 6| Step: 9
Training loss: 0.6524513292978324
Validation loss: 2.6757615434426776

Epoch: 6| Step: 10
Training loss: 0.6554250754899983
Validation loss: 2.6732893206555763

Epoch: 6| Step: 11
Training loss: 0.943513845745436
Validation loss: 2.6988286326692212

Epoch: 6| Step: 12
Training loss: 0.850247759332932
Validation loss: 2.7918897558624645

Epoch: 6| Step: 13
Training loss: 0.497290272188036
Validation loss: 2.77588315777214

Epoch: 457| Step: 0
Training loss: 0.43382835914389795
Validation loss: 2.7667277377255446

Epoch: 6| Step: 1
Training loss: 0.6157402259927551
Validation loss: 2.7621979394387375

Epoch: 6| Step: 2
Training loss: 0.47216078901700187
Validation loss: 2.827505138605037

Epoch: 6| Step: 3
Training loss: 0.6261986682130827
Validation loss: 2.7639757256681774

Epoch: 6| Step: 4
Training loss: 0.8126412048883476
Validation loss: 2.6981065504102952

Epoch: 6| Step: 5
Training loss: 0.6076345286137194
Validation loss: 2.721097057310218

Epoch: 6| Step: 6
Training loss: 0.6293677774903234
Validation loss: 2.742956403289651

Epoch: 6| Step: 7
Training loss: 0.9339709936289818
Validation loss: 2.692320145763338

Epoch: 6| Step: 8
Training loss: 0.7028118283822805
Validation loss: 2.6357209453407555

Epoch: 6| Step: 9
Training loss: 0.7185910090530852
Validation loss: 2.6879550045955276

Epoch: 6| Step: 10
Training loss: 0.8235352923179287
Validation loss: 2.6728804929034276

Epoch: 6| Step: 11
Training loss: 0.8137976480998931
Validation loss: 2.6959795435111444

Epoch: 6| Step: 12
Training loss: 0.5459606701585613
Validation loss: 2.7247920805676564

Epoch: 6| Step: 13
Training loss: 0.8582548644174964
Validation loss: 2.677032193141967

Epoch: 458| Step: 0
Training loss: 0.6383303040946351
Validation loss: 2.6908037741384194

Epoch: 6| Step: 1
Training loss: 0.8970947846991281
Validation loss: 2.709591020876965

Epoch: 6| Step: 2
Training loss: 0.7510371189976189
Validation loss: 2.6949220678636556

Epoch: 6| Step: 3
Training loss: 0.635135976883093
Validation loss: 2.7575343552792684

Epoch: 6| Step: 4
Training loss: 0.6519461236558369
Validation loss: 2.680021793433441

Epoch: 6| Step: 5
Training loss: 0.5779523849542383
Validation loss: 2.747969340026113

Epoch: 6| Step: 6
Training loss: 0.5765078324863604
Validation loss: 2.7533901876378604

Epoch: 6| Step: 7
Training loss: 0.6685359844118046
Validation loss: 2.738349975362007

Epoch: 6| Step: 8
Training loss: 0.74529531207149
Validation loss: 2.735174269345814

Epoch: 6| Step: 9
Training loss: 0.6200158464421706
Validation loss: 2.7269013275384055

Epoch: 6| Step: 10
Training loss: 0.6592286720442397
Validation loss: 2.817926695724646

Epoch: 6| Step: 11
Training loss: 0.3030960383786548
Validation loss: 2.7186934074270384

Epoch: 6| Step: 12
Training loss: 0.7593213427389282
Validation loss: 2.7788256533687887

Epoch: 6| Step: 13
Training loss: 0.6142212776514416
Validation loss: 2.7112204397632276

Epoch: 459| Step: 0
Training loss: 0.9702074408668726
Validation loss: 2.7513750713227583

Epoch: 6| Step: 1
Training loss: 0.5853961732836399
Validation loss: 2.7838470820499457

Epoch: 6| Step: 2
Training loss: 0.8034276265947604
Validation loss: 2.727361072087159

Epoch: 6| Step: 3
Training loss: 0.4785165280703373
Validation loss: 2.7162271464908305

Epoch: 6| Step: 4
Training loss: 0.8319781290925625
Validation loss: 2.7484814612693467

Epoch: 6| Step: 5
Training loss: 0.5115876357440367
Validation loss: 2.7653040582964343

Epoch: 6| Step: 6
Training loss: 0.5423687425820822
Validation loss: 2.660850370858118

Epoch: 6| Step: 7
Training loss: 0.46260498182807175
Validation loss: 2.740596385706389

Epoch: 6| Step: 8
Training loss: 0.6024429764018356
Validation loss: 2.675377942062305

Epoch: 6| Step: 9
Training loss: 0.633820002525079
Validation loss: 2.7006977922122326

Epoch: 6| Step: 10
Training loss: 0.7307133800480736
Validation loss: 2.7009604429445835

Epoch: 6| Step: 11
Training loss: 0.6504774980692144
Validation loss: 2.685884300535039

Epoch: 6| Step: 12
Training loss: 0.8021565606184525
Validation loss: 2.7322581207818355

Epoch: 6| Step: 13
Training loss: 0.63067267522191
Validation loss: 2.8071513073051118

Epoch: 460| Step: 0
Training loss: 0.5578377683243068
Validation loss: 2.741251402618425

Epoch: 6| Step: 1
Training loss: 0.6975756257941956
Validation loss: 2.8023792781798598

Epoch: 6| Step: 2
Training loss: 0.42232972822153536
Validation loss: 2.814416303179785

Epoch: 6| Step: 3
Training loss: 0.7748366137524233
Validation loss: 2.8336003589088534

Epoch: 6| Step: 4
Training loss: 0.653327018121767
Validation loss: 2.8190847667495103

Epoch: 6| Step: 5
Training loss: 0.45891729635751105
Validation loss: 2.7872603406076477

Epoch: 6| Step: 6
Training loss: 0.4016029797645794
Validation loss: 2.7641670349606935

Epoch: 6| Step: 7
Training loss: 0.9514907521727073
Validation loss: 2.763637669220187

Epoch: 6| Step: 8
Training loss: 0.8503671358129831
Validation loss: 2.6849592752049847

Epoch: 6| Step: 9
Training loss: 0.7457566223617781
Validation loss: 2.667967722321476

Epoch: 6| Step: 10
Training loss: 0.6649676269166094
Validation loss: 2.7442079293718393

Epoch: 6| Step: 11
Training loss: 0.5322847387033448
Validation loss: 2.7115276328302635

Epoch: 6| Step: 12
Training loss: 1.0158150128367691
Validation loss: 2.7128617404382336

Epoch: 6| Step: 13
Training loss: 0.7033541411972354
Validation loss: 2.7031857698698776

Epoch: 461| Step: 0
Training loss: 0.5020984483820636
Validation loss: 2.7284990663783746

Epoch: 6| Step: 1
Training loss: 0.7150111601698819
Validation loss: 2.740178835200175

Epoch: 6| Step: 2
Training loss: 0.6244318048261177
Validation loss: 2.789266285009627

Epoch: 6| Step: 3
Training loss: 0.8161663451271703
Validation loss: 2.790580842002311

Epoch: 6| Step: 4
Training loss: 0.5564741722327339
Validation loss: 2.779574914903396

Epoch: 6| Step: 5
Training loss: 0.7489439761749206
Validation loss: 2.7210177905739377

Epoch: 6| Step: 6
Training loss: 0.8150991169505974
Validation loss: 2.7685714084270563

Epoch: 6| Step: 7
Training loss: 0.6724320918756632
Validation loss: 2.7378294132556262

Epoch: 6| Step: 8
Training loss: 0.8487776620595989
Validation loss: 2.688872836877744

Epoch: 6| Step: 9
Training loss: 0.4503412072364895
Validation loss: 2.705877192942341

Epoch: 6| Step: 10
Training loss: 0.40494562702410714
Validation loss: 2.7423195657690154

Epoch: 6| Step: 11
Training loss: 0.8104488083677153
Validation loss: 2.768529885801607

Epoch: 6| Step: 12
Training loss: 0.7441621311714505
Validation loss: 2.7319444807856685

Epoch: 6| Step: 13
Training loss: 0.9244400159399115
Validation loss: 2.8622659962387296

Epoch: 462| Step: 0
Training loss: 0.6254649816814559
Validation loss: 2.831059922889728

Epoch: 6| Step: 1
Training loss: 0.7467462372814355
Validation loss: 2.8965531330517584

Epoch: 6| Step: 2
Training loss: 0.37913140754806485
Validation loss: 2.8859466910581624

Epoch: 6| Step: 3
Training loss: 0.7007111547279874
Validation loss: 2.824201556549569

Epoch: 6| Step: 4
Training loss: 0.6894599114535198
Validation loss: 2.7957108701518965

Epoch: 6| Step: 5
Training loss: 0.7283759507368962
Validation loss: 2.718051630700739

Epoch: 6| Step: 6
Training loss: 0.6455382831901505
Validation loss: 2.669006622388182

Epoch: 6| Step: 7
Training loss: 0.6939643262453413
Validation loss: 2.7335223076398973

Epoch: 6| Step: 8
Training loss: 1.0167109039458826
Validation loss: 2.7380029497922544

Epoch: 6| Step: 9
Training loss: 0.6170347000454518
Validation loss: 2.7487178905971463

Epoch: 6| Step: 10
Training loss: 0.9851411532425868
Validation loss: 2.721588056573334

Epoch: 6| Step: 11
Training loss: 0.8413669700981804
Validation loss: 2.7477257022824015

Epoch: 6| Step: 12
Training loss: 0.6570681966402048
Validation loss: 2.715737936102724

Epoch: 6| Step: 13
Training loss: 0.7557667520239384
Validation loss: 2.7411139144551533

Epoch: 463| Step: 0
Training loss: 0.5272881372585614
Validation loss: 2.77282827070671

Epoch: 6| Step: 1
Training loss: 0.824118983300729
Validation loss: 2.904064436818538

Epoch: 6| Step: 2
Training loss: 0.7594687462856028
Validation loss: 2.8673992996914563

Epoch: 6| Step: 3
Training loss: 0.8599985807983753
Validation loss: 2.7847822169127414

Epoch: 6| Step: 4
Training loss: 0.602736083823728
Validation loss: 2.818722770880817

Epoch: 6| Step: 5
Training loss: 0.6140250051373928
Validation loss: 2.7175896605644847

Epoch: 6| Step: 6
Training loss: 0.6998529381903665
Validation loss: 2.7939980342032515

Epoch: 6| Step: 7
Training loss: 0.9668506954124527
Validation loss: 2.795602718645125

Epoch: 6| Step: 8
Training loss: 0.9086820918635331
Validation loss: 2.736425012783273

Epoch: 6| Step: 9
Training loss: 1.454730387873921
Validation loss: 2.7192370537515185

Epoch: 6| Step: 10
Training loss: 0.8620382482712377
Validation loss: 2.76592855709275

Epoch: 6| Step: 11
Training loss: 0.8234809357336231
Validation loss: 2.8738019354309916

Epoch: 6| Step: 12
Training loss: 0.9542478919681794
Validation loss: 2.8666171027120093

Epoch: 6| Step: 13
Training loss: 1.0085142782445957
Validation loss: 2.8710812661381797

Epoch: 464| Step: 0
Training loss: 1.6377776369206647
Validation loss: 2.8173045058802844

Epoch: 6| Step: 1
Training loss: 0.5961602880056502
Validation loss: 2.7670408600994603

Epoch: 6| Step: 2
Training loss: 0.6756051997371997
Validation loss: 2.7364561753009777

Epoch: 6| Step: 3
Training loss: 1.1271392827181939
Validation loss: 2.638915635413989

Epoch: 6| Step: 4
Training loss: 0.6999948126736945
Validation loss: 2.6089993204525577

Epoch: 6| Step: 5
Training loss: 0.990006761142493
Validation loss: 2.656034707712994

Epoch: 6| Step: 6
Training loss: 0.756630004430153
Validation loss: 2.7093751713020477

Epoch: 6| Step: 7
Training loss: 0.5827037075660609
Validation loss: 2.69545365853095

Epoch: 6| Step: 8
Training loss: 1.1913064883629645
Validation loss: 2.8320544292334473

Epoch: 6| Step: 9
Training loss: 0.9711077823376969
Validation loss: 2.897889406764813

Epoch: 6| Step: 10
Training loss: 1.057073310641142
Validation loss: 2.812716624076764

Epoch: 6| Step: 11
Training loss: 0.8458047149464545
Validation loss: 2.8026546240967374

Epoch: 6| Step: 12
Training loss: 0.8454999084878666
Validation loss: 2.698594517530557

Epoch: 6| Step: 13
Training loss: 0.5535611281337581
Validation loss: 2.7091990089969653

Epoch: 465| Step: 0
Training loss: 0.7941051289458948
Validation loss: 2.6233301300924374

Epoch: 6| Step: 1
Training loss: 0.5176038051928188
Validation loss: 2.6632865155974503

Epoch: 6| Step: 2
Training loss: 1.0454848439647324
Validation loss: 2.6211329237866834

Epoch: 6| Step: 3
Training loss: 0.8417157269018682
Validation loss: 2.6647914362797387

Epoch: 6| Step: 4
Training loss: 0.6854521857182635
Validation loss: 2.6648611324074793

Epoch: 6| Step: 5
Training loss: 0.7225508741927182
Validation loss: 2.643376363529907

Epoch: 6| Step: 6
Training loss: 0.7457105841046286
Validation loss: 2.697097732581727

Epoch: 6| Step: 7
Training loss: 0.43433286201766685
Validation loss: 2.6367294499686444

Epoch: 6| Step: 8
Training loss: 0.829634460363093
Validation loss: 2.701829294710406

Epoch: 6| Step: 9
Training loss: 0.4832836438676886
Validation loss: 2.698115313273038

Epoch: 6| Step: 10
Training loss: 0.9545864095406577
Validation loss: 2.6811427547700424

Epoch: 6| Step: 11
Training loss: 0.7052034599515214
Validation loss: 2.7732913413062907

Epoch: 6| Step: 12
Training loss: 0.8750592620399542
Validation loss: 2.7870072629241056

Epoch: 6| Step: 13
Training loss: 0.7498933398380218
Validation loss: 2.7487865284933797

Epoch: 466| Step: 0
Training loss: 0.6027064160570209
Validation loss: 2.772776393270515

Epoch: 6| Step: 1
Training loss: 0.9846746200644083
Validation loss: 2.734091680471805

Epoch: 6| Step: 2
Training loss: 0.835693751654615
Validation loss: 2.66932797006382

Epoch: 6| Step: 3
Training loss: 0.8017545785966487
Validation loss: 2.671433960800136

Epoch: 6| Step: 4
Training loss: 0.8100853030887145
Validation loss: 2.6818217609721566

Epoch: 6| Step: 5
Training loss: 0.8104674886410901
Validation loss: 2.7091641007779597

Epoch: 6| Step: 6
Training loss: 0.8295894126599086
Validation loss: 2.7060256565481957

Epoch: 6| Step: 7
Training loss: 1.269062507364498
Validation loss: 2.732469879593989

Epoch: 6| Step: 8
Training loss: 0.7097445949363413
Validation loss: 2.704360099089051

Epoch: 6| Step: 9
Training loss: 0.5382936772433137
Validation loss: 2.6674148632502965

Epoch: 6| Step: 10
Training loss: 0.7933316457420586
Validation loss: 2.8573386579360993

Epoch: 6| Step: 11
Training loss: 0.5596419949246262
Validation loss: 2.8276107348617985

Epoch: 6| Step: 12
Training loss: 0.7616905011538707
Validation loss: 2.9005928080396517

Epoch: 6| Step: 13
Training loss: 1.244426221420817
Validation loss: 2.8660604148215123

Epoch: 467| Step: 0
Training loss: 0.5687292409608686
Validation loss: 2.7990382262737543

Epoch: 6| Step: 1
Training loss: 0.5067341432165369
Validation loss: 2.7540609113402326

Epoch: 6| Step: 2
Training loss: 0.7784518677539067
Validation loss: 2.7740447476533676

Epoch: 6| Step: 3
Training loss: 1.3374393342422377
Validation loss: 2.7724391806065563

Epoch: 6| Step: 4
Training loss: 0.7557552374337467
Validation loss: 2.743287679988409

Epoch: 6| Step: 5
Training loss: 0.7193017583262604
Validation loss: 2.7730866402784398

Epoch: 6| Step: 6
Training loss: 0.9165266031128404
Validation loss: 2.6709645376447044

Epoch: 6| Step: 7
Training loss: 0.9526969073358612
Validation loss: 2.682140476940991

Epoch: 6| Step: 8
Training loss: 0.7080444326467017
Validation loss: 2.6893484279446627

Epoch: 6| Step: 9
Training loss: 0.823002102597727
Validation loss: 2.7031291307480254

Epoch: 6| Step: 10
Training loss: 0.7304896387387624
Validation loss: 2.7633396339881524

Epoch: 6| Step: 11
Training loss: 0.8337607876881868
Validation loss: 2.782119115127359

Epoch: 6| Step: 12
Training loss: 0.792174782735559
Validation loss: 2.829079665324338

Epoch: 6| Step: 13
Training loss: 0.8753682792021
Validation loss: 2.842737010467762

Epoch: 468| Step: 0
Training loss: 0.6120751785824018
Validation loss: 2.8301393420239593

Epoch: 6| Step: 1
Training loss: 0.5419476190061588
Validation loss: 2.7758749982794613

Epoch: 6| Step: 2
Training loss: 0.6545595922683243
Validation loss: 2.825676843698737

Epoch: 6| Step: 3
Training loss: 0.9482608875823291
Validation loss: 2.8328165022381135

Epoch: 6| Step: 4
Training loss: 0.8064867293110911
Validation loss: 2.822456552279776

Epoch: 6| Step: 5
Training loss: 0.7683967709228724
Validation loss: 2.753304100489508

Epoch: 6| Step: 6
Training loss: 0.6776509082417413
Validation loss: 2.733910279519651

Epoch: 6| Step: 7
Training loss: 0.8966858747497749
Validation loss: 2.7472131653334166

Epoch: 6| Step: 8
Training loss: 0.923963863409295
Validation loss: 2.7669562603777216

Epoch: 6| Step: 9
Training loss: 0.7034552328483559
Validation loss: 2.70162045865448

Epoch: 6| Step: 10
Training loss: 0.46550120813886997
Validation loss: 2.7062189774353964

Epoch: 6| Step: 11
Training loss: 0.715607615430471
Validation loss: 2.7903586402553273

Epoch: 6| Step: 12
Training loss: 0.6366883253071777
Validation loss: 2.764470514977034

Epoch: 6| Step: 13
Training loss: 0.6332478144487872
Validation loss: 2.8440201879009277

Epoch: 469| Step: 0
Training loss: 1.0587667063506305
Validation loss: 2.8549274952684787

Epoch: 6| Step: 1
Training loss: 0.6494565562636317
Validation loss: 2.8403721544731373

Epoch: 6| Step: 2
Training loss: 0.8286429171188193
Validation loss: 2.838812513582778

Epoch: 6| Step: 3
Training loss: 0.6331484103228879
Validation loss: 2.800263793757857

Epoch: 6| Step: 4
Training loss: 0.4196184703442736
Validation loss: 2.7566833634045778

Epoch: 6| Step: 5
Training loss: 0.3360551805413893
Validation loss: 2.7943343729768597

Epoch: 6| Step: 6
Training loss: 0.7200219468242193
Validation loss: 2.779835702148553

Epoch: 6| Step: 7
Training loss: 0.6804010438575788
Validation loss: 2.754977230386398

Epoch: 6| Step: 8
Training loss: 0.4712195511550615
Validation loss: 2.7498151688161827

Epoch: 6| Step: 9
Training loss: 0.7466782282745926
Validation loss: 2.7747563767816295

Epoch: 6| Step: 10
Training loss: 0.6623549554501951
Validation loss: 2.7731576339570294

Epoch: 6| Step: 11
Training loss: 0.74772872334382
Validation loss: 2.7487810496678082

Epoch: 6| Step: 12
Training loss: 0.6490784200773865
Validation loss: 2.757583637485113

Epoch: 6| Step: 13
Training loss: 0.758540089336775
Validation loss: 2.7540425007619644

Epoch: 470| Step: 0
Training loss: 0.8635973804632923
Validation loss: 2.667484178004583

Epoch: 6| Step: 1
Training loss: 0.6905873292686376
Validation loss: 2.7022725196163773

Epoch: 6| Step: 2
Training loss: 0.7436037304443514
Validation loss: 2.7175691020406916

Epoch: 6| Step: 3
Training loss: 0.7103408153980635
Validation loss: 2.7993413752275065

Epoch: 6| Step: 4
Training loss: 0.5026235593174132
Validation loss: 2.7639468861623167

Epoch: 6| Step: 5
Training loss: 0.7037687957042474
Validation loss: 2.8179103099663494

Epoch: 6| Step: 6
Training loss: 0.7563874521738785
Validation loss: 2.8438447650029155

Epoch: 6| Step: 7
Training loss: 0.43500515901860604
Validation loss: 2.834570913613306

Epoch: 6| Step: 8
Training loss: 0.365240046003245
Validation loss: 2.810643565352917

Epoch: 6| Step: 9
Training loss: 0.5456419531601574
Validation loss: 2.7788526225105694

Epoch: 6| Step: 10
Training loss: 0.8902833517544472
Validation loss: 2.8707004269054184

Epoch: 6| Step: 11
Training loss: 0.5235991441886529
Validation loss: 2.881403798531058

Epoch: 6| Step: 12
Training loss: 0.6617845396734773
Validation loss: 2.7847778862272885

Epoch: 6| Step: 13
Training loss: 0.5076175315418376
Validation loss: 2.8134245306603978

Epoch: 471| Step: 0
Training loss: 0.7091055101889868
Validation loss: 2.8392757668082433

Epoch: 6| Step: 1
Training loss: 0.44489524768328437
Validation loss: 2.7661564777858754

Epoch: 6| Step: 2
Training loss: 0.6488136900800942
Validation loss: 2.7888927960167917

Epoch: 6| Step: 3
Training loss: 0.41237545011553056
Validation loss: 2.755406498167491

Epoch: 6| Step: 4
Training loss: 0.682052269400876
Validation loss: 2.7876035291893086

Epoch: 6| Step: 5
Training loss: 0.4578612200751212
Validation loss: 2.7633626200945844

Epoch: 6| Step: 6
Training loss: 0.5848526894296149
Validation loss: 2.7716569226250996

Epoch: 6| Step: 7
Training loss: 0.48976643330867414
Validation loss: 2.739301367247411

Epoch: 6| Step: 8
Training loss: 0.5876655274409163
Validation loss: 2.742596370286973

Epoch: 6| Step: 9
Training loss: 0.585793286696179
Validation loss: 2.7389329687065858

Epoch: 6| Step: 10
Training loss: 0.7579890959742998
Validation loss: 2.7813563380111423

Epoch: 6| Step: 11
Training loss: 1.0054606119462328
Validation loss: 2.726274739321832

Epoch: 6| Step: 12
Training loss: 0.7452386079702582
Validation loss: 2.761580460614353

Epoch: 6| Step: 13
Training loss: 0.5712607613098752
Validation loss: 2.771097017710555

Epoch: 472| Step: 0
Training loss: 0.6883036511312312
Validation loss: 2.8535650180699403

Epoch: 6| Step: 1
Training loss: 0.8423759079846336
Validation loss: 2.8378025084132963

Epoch: 6| Step: 2
Training loss: 0.5554602170307585
Validation loss: 2.8246732269611874

Epoch: 6| Step: 3
Training loss: 0.5902039141971471
Validation loss: 2.8748271171447626

Epoch: 6| Step: 4
Training loss: 0.5891586771598218
Validation loss: 2.8337570369158

Epoch: 6| Step: 5
Training loss: 0.7659951697015481
Validation loss: 2.7389627099378804

Epoch: 6| Step: 6
Training loss: 0.5571429211578053
Validation loss: 2.7673641849906523

Epoch: 6| Step: 7
Training loss: 0.5579064682742297
Validation loss: 2.7018304124597954

Epoch: 6| Step: 8
Training loss: 0.9050931452664286
Validation loss: 2.731273948977621

Epoch: 6| Step: 9
Training loss: 0.6032242302969006
Validation loss: 2.6971720302437077

Epoch: 6| Step: 10
Training loss: 0.496730680919395
Validation loss: 2.7033481248559896

Epoch: 6| Step: 11
Training loss: 0.7030123726392244
Validation loss: 2.746020276753967

Epoch: 6| Step: 12
Training loss: 0.8331086968603207
Validation loss: 2.734114745334124

Epoch: 6| Step: 13
Training loss: 0.5562301460751944
Validation loss: 2.784408119310092

Epoch: 473| Step: 0
Training loss: 0.5398520064654155
Validation loss: 2.7548726002890302

Epoch: 6| Step: 1
Training loss: 0.5884933676917172
Validation loss: 2.7515637257862267

Epoch: 6| Step: 2
Training loss: 0.6678918716181643
Validation loss: 2.713901325096687

Epoch: 6| Step: 3
Training loss: 0.5302071714357287
Validation loss: 2.7651902196478604

Epoch: 6| Step: 4
Training loss: 0.7454237401067653
Validation loss: 2.6975333458221433

Epoch: 6| Step: 5
Training loss: 0.548618344434973
Validation loss: 2.7066825726547536

Epoch: 6| Step: 6
Training loss: 0.8324820501666327
Validation loss: 2.7305158430048624

Epoch: 6| Step: 7
Training loss: 0.952397835175987
Validation loss: 2.7588039701616025

Epoch: 6| Step: 8
Training loss: 0.7032383721397562
Validation loss: 2.8475769757546687

Epoch: 6| Step: 9
Training loss: 0.4724849358937596
Validation loss: 2.822018221138702

Epoch: 6| Step: 10
Training loss: 0.6089375466283392
Validation loss: 2.8465885346237263

Epoch: 6| Step: 11
Training loss: 0.48581156432693423
Validation loss: 2.798739005722162

Epoch: 6| Step: 12
Training loss: 0.6810438500415356
Validation loss: 2.7995243275866186

Epoch: 6| Step: 13
Training loss: 0.5848893518221797
Validation loss: 2.8272922196004835

Epoch: 474| Step: 0
Training loss: 0.6122228150942763
Validation loss: 2.7787802656856093

Epoch: 6| Step: 1
Training loss: 0.8116533563320192
Validation loss: 2.7654469606955856

Epoch: 6| Step: 2
Training loss: 0.821745900795243
Validation loss: 2.7669851259613707

Epoch: 6| Step: 3
Training loss: 0.5047468817767128
Validation loss: 2.765037402359347

Epoch: 6| Step: 4
Training loss: 0.5572886660010818
Validation loss: 2.7450410318232086

Epoch: 6| Step: 5
Training loss: 0.5449366687147483
Validation loss: 2.750833283957599

Epoch: 6| Step: 6
Training loss: 0.5516616602475515
Validation loss: 2.775632292507355

Epoch: 6| Step: 7
Training loss: 0.6013939113446375
Validation loss: 2.749186236460368

Epoch: 6| Step: 8
Training loss: 0.6922724626464124
Validation loss: 2.7586735289921442

Epoch: 6| Step: 9
Training loss: 0.31339335302787985
Validation loss: 2.7842910228756836

Epoch: 6| Step: 10
Training loss: 0.8860954749329872
Validation loss: 2.81854654890349

Epoch: 6| Step: 11
Training loss: 0.6536017981865192
Validation loss: 2.7585447094034325

Epoch: 6| Step: 12
Training loss: 0.5586026064297366
Validation loss: 2.798657053803571

Epoch: 6| Step: 13
Training loss: 0.4869782418906939
Validation loss: 2.82456908244974

Epoch: 475| Step: 0
Training loss: 0.5943546479006918
Validation loss: 2.777693428242372

Epoch: 6| Step: 1
Training loss: 0.581605025534844
Validation loss: 2.879001003381365

Epoch: 6| Step: 2
Training loss: 0.7397680096794816
Validation loss: 2.800876802014263

Epoch: 6| Step: 3
Training loss: 0.5496865614839125
Validation loss: 2.781517587426366

Epoch: 6| Step: 4
Training loss: 0.8362409807297582
Validation loss: 2.7682080176841364

Epoch: 6| Step: 5
Training loss: 0.7840044293692086
Validation loss: 2.8136394735597277

Epoch: 6| Step: 6
Training loss: 0.3748671375784465
Validation loss: 2.6956167740390082

Epoch: 6| Step: 7
Training loss: 0.5770534688977699
Validation loss: 2.7395005787774958

Epoch: 6| Step: 8
Training loss: 0.6106267202034873
Validation loss: 2.718430350502144

Epoch: 6| Step: 9
Training loss: 0.546047183604086
Validation loss: 2.713644883626667

Epoch: 6| Step: 10
Training loss: 0.7079677807244152
Validation loss: 2.7247846284968857

Epoch: 6| Step: 11
Training loss: 0.67922683977777
Validation loss: 2.695593335544801

Epoch: 6| Step: 12
Training loss: 0.8170415423371091
Validation loss: 2.7063149095698997

Epoch: 6| Step: 13
Training loss: 0.6276213510358228
Validation loss: 2.699720557787186

Epoch: 476| Step: 0
Training loss: 0.718327398039629
Validation loss: 2.8263601061589245

Epoch: 6| Step: 1
Training loss: 0.8327322142873873
Validation loss: 2.8219060226543244

Epoch: 6| Step: 2
Training loss: 0.5942380806414
Validation loss: 2.841903995622993

Epoch: 6| Step: 3
Training loss: 0.7374998124979072
Validation loss: 2.876967019822112

Epoch: 6| Step: 4
Training loss: 0.7620266023282553
Validation loss: 2.814174069105027

Epoch: 6| Step: 5
Training loss: 0.5055783054306567
Validation loss: 2.776739556415619

Epoch: 6| Step: 6
Training loss: 0.5906679319491228
Validation loss: 2.736139509265605

Epoch: 6| Step: 7
Training loss: 0.5183455050696254
Validation loss: 2.774727205379856

Epoch: 6| Step: 8
Training loss: 0.9078888380090354
Validation loss: 2.727451110434313

Epoch: 6| Step: 9
Training loss: 0.6447934628791832
Validation loss: 2.7785337521448734

Epoch: 6| Step: 10
Training loss: 0.9244863088985588
Validation loss: 2.830468346805177

Epoch: 6| Step: 11
Training loss: 0.6095371519662072
Validation loss: 2.7679144512050695

Epoch: 6| Step: 12
Training loss: 0.6406895674755039
Validation loss: 2.7540418947690517

Epoch: 6| Step: 13
Training loss: 0.47738841670406446
Validation loss: 2.793171567155239

Epoch: 477| Step: 0
Training loss: 0.48495205991303375
Validation loss: 2.855218377989272

Epoch: 6| Step: 1
Training loss: 0.8265238704199798
Validation loss: 2.9403594418381274

Epoch: 6| Step: 2
Training loss: 0.5726504805665867
Validation loss: 2.9671045662376856

Epoch: 6| Step: 3
Training loss: 1.088583049565531
Validation loss: 2.892800201744819

Epoch: 6| Step: 4
Training loss: 0.7868453498811038
Validation loss: 2.9111617226686337

Epoch: 6| Step: 5
Training loss: 0.6676346685169772
Validation loss: 2.814800056642842

Epoch: 6| Step: 6
Training loss: 0.6132505129747077
Validation loss: 2.836209707095812

Epoch: 6| Step: 7
Training loss: 0.6326518384648235
Validation loss: 2.852276271167116

Epoch: 6| Step: 8
Training loss: 0.9056472747148446
Validation loss: 2.8073010606673447

Epoch: 6| Step: 9
Training loss: 0.5023240081087774
Validation loss: 2.8045905759705887

Epoch: 6| Step: 10
Training loss: 0.6493975873879418
Validation loss: 2.836834670163468

Epoch: 6| Step: 11
Training loss: 0.8681160019915647
Validation loss: 2.8059655184794394

Epoch: 6| Step: 12
Training loss: 1.101596425934107
Validation loss: 2.761185684088261

Epoch: 6| Step: 13
Training loss: 0.4925111886994918
Validation loss: 2.716559781173691

Epoch: 478| Step: 0
Training loss: 0.6967461625134826
Validation loss: 2.783538790979397

Epoch: 6| Step: 1
Training loss: 0.782068205578567
Validation loss: 2.8092619870728925

Epoch: 6| Step: 2
Training loss: 0.619547015611278
Validation loss: 2.7913221649621907

Epoch: 6| Step: 3
Training loss: 0.48646273913896754
Validation loss: 2.7784009192136705

Epoch: 6| Step: 4
Training loss: 0.7500657211754571
Validation loss: 2.773193534902339

Epoch: 6| Step: 5
Training loss: 0.8659080827466393
Validation loss: 2.722633744835027

Epoch: 6| Step: 6
Training loss: 0.693313124282681
Validation loss: 2.722155225236427

Epoch: 6| Step: 7
Training loss: 0.5470407507255806
Validation loss: 2.728601241810778

Epoch: 6| Step: 8
Training loss: 0.7119895779886309
Validation loss: 2.6995088133428147

Epoch: 6| Step: 9
Training loss: 0.6369131996595802
Validation loss: 2.6855562706985263

Epoch: 6| Step: 10
Training loss: 0.5972975109263706
Validation loss: 2.7488079232749314

Epoch: 6| Step: 11
Training loss: 0.5700491728402661
Validation loss: 2.774500540155764

Epoch: 6| Step: 12
Training loss: 0.5688774133847736
Validation loss: 2.7507798360734097

Epoch: 6| Step: 13
Training loss: 0.6230309224253906
Validation loss: 2.7739872490558417

Epoch: 479| Step: 0
Training loss: 0.6404645765456622
Validation loss: 2.7590164279925666

Epoch: 6| Step: 1
Training loss: 0.6272154167284004
Validation loss: 2.798116127984515

Epoch: 6| Step: 2
Training loss: 0.5043083479187136
Validation loss: 2.762259481209795

Epoch: 6| Step: 3
Training loss: 0.6724988569370468
Validation loss: 2.8517180796643986

Epoch: 6| Step: 4
Training loss: 0.7186105012278735
Validation loss: 2.824623328671979

Epoch: 6| Step: 5
Training loss: 0.6524848328577847
Validation loss: 2.757682040751711

Epoch: 6| Step: 6
Training loss: 0.5808527747922761
Validation loss: 2.7389138180842907

Epoch: 6| Step: 7
Training loss: 0.5553291800016599
Validation loss: 2.716768368375598

Epoch: 6| Step: 8
Training loss: 0.6389966599700987
Validation loss: 2.7391563319665146

Epoch: 6| Step: 9
Training loss: 0.5653651172618432
Validation loss: 2.7856734171513944

Epoch: 6| Step: 10
Training loss: 0.6360818216455902
Validation loss: 2.7038099857988582

Epoch: 6| Step: 11
Training loss: 0.7561533353834266
Validation loss: 2.7220231446200844

Epoch: 6| Step: 12
Training loss: 0.6321437033069541
Validation loss: 2.7609065119053717

Epoch: 6| Step: 13
Training loss: 0.9350367610762993
Validation loss: 2.7445254163556094

Epoch: 480| Step: 0
Training loss: 0.4997877027898494
Validation loss: 2.7622813182828487

Epoch: 6| Step: 1
Training loss: 0.7582862788752268
Validation loss: 2.7920450030118396

Epoch: 6| Step: 2
Training loss: 0.6473627490681504
Validation loss: 2.8507435497949283

Epoch: 6| Step: 3
Training loss: 0.49417599638140197
Validation loss: 2.7897147476508235

Epoch: 6| Step: 4
Training loss: 0.662946458846803
Validation loss: 2.8890211174935727

Epoch: 6| Step: 5
Training loss: 0.5284221501661712
Validation loss: 2.8663646546301447

Epoch: 6| Step: 6
Training loss: 0.7772122755960097
Validation loss: 2.8875886108101265

Epoch: 6| Step: 7
Training loss: 0.6021077793486762
Validation loss: 2.8808068635971606

Epoch: 6| Step: 8
Training loss: 0.685825671593137
Validation loss: 2.8637946181676823

Epoch: 6| Step: 9
Training loss: 0.5195574933070903
Validation loss: 2.7573548856740837

Epoch: 6| Step: 10
Training loss: 0.559887248720109
Validation loss: 2.8414158446588993

Epoch: 6| Step: 11
Training loss: 0.45210898703055363
Validation loss: 2.7843730265749165

Epoch: 6| Step: 12
Training loss: 0.40597642343401835
Validation loss: 2.7618298254198157

Epoch: 6| Step: 13
Training loss: 0.7748497294283521
Validation loss: 2.7889376771778918

Epoch: 481| Step: 0
Training loss: 0.42445134342802
Validation loss: 2.749279187842489

Epoch: 6| Step: 1
Training loss: 0.7281616414555141
Validation loss: 2.781053364692661

Epoch: 6| Step: 2
Training loss: 0.5813966658349978
Validation loss: 2.8119590521626066

Epoch: 6| Step: 3
Training loss: 0.45760426912133645
Validation loss: 2.731908794128018

Epoch: 6| Step: 4
Training loss: 0.5149496452935547
Validation loss: 2.7262824788258504

Epoch: 6| Step: 5
Training loss: 0.5572496796474845
Validation loss: 2.8264422530110034

Epoch: 6| Step: 6
Training loss: 0.7097606770033829
Validation loss: 2.801757982692135

Epoch: 6| Step: 7
Training loss: 0.498060652598381
Validation loss: 2.801537064598005

Epoch: 6| Step: 8
Training loss: 0.763108379736016
Validation loss: 2.7823481874046205

Epoch: 6| Step: 9
Training loss: 0.6185549303300656
Validation loss: 2.761116778762121

Epoch: 6| Step: 10
Training loss: 0.7656521695045689
Validation loss: 2.7665120442588638

Epoch: 6| Step: 11
Training loss: 0.5260002258394576
Validation loss: 2.7759463858699296

Epoch: 6| Step: 12
Training loss: 0.4849151091904886
Validation loss: 2.72096714510529

Epoch: 6| Step: 13
Training loss: 0.7804969209736141
Validation loss: 2.7189755693305924

Epoch: 482| Step: 0
Training loss: 0.3539443393445927
Validation loss: 2.7455183849016724

Epoch: 6| Step: 1
Training loss: 0.9330980589056915
Validation loss: 2.7018117636331676

Epoch: 6| Step: 2
Training loss: 0.7104850419179306
Validation loss: 2.810923989563712

Epoch: 6| Step: 3
Training loss: 0.5468240441697265
Validation loss: 2.784753557210177

Epoch: 6| Step: 4
Training loss: 0.42356182117359914
Validation loss: 2.8049083045459993

Epoch: 6| Step: 5
Training loss: 0.5831611214476141
Validation loss: 2.8450172311610755

Epoch: 6| Step: 6
Training loss: 0.4213913334917594
Validation loss: 2.8597407428458124

Epoch: 6| Step: 7
Training loss: 0.6445015177949327
Validation loss: 2.888761699965897

Epoch: 6| Step: 8
Training loss: 0.5793525705039015
Validation loss: 2.9374599454056267

Epoch: 6| Step: 9
Training loss: 0.7548129702060653
Validation loss: 2.8799174175078424

Epoch: 6| Step: 10
Training loss: 0.679995236941093
Validation loss: 2.80080051672643

Epoch: 6| Step: 11
Training loss: 0.5901115769417353
Validation loss: 2.7580174846311634

Epoch: 6| Step: 12
Training loss: 0.7126702372979241
Validation loss: 2.7311623146769084

Epoch: 6| Step: 13
Training loss: 0.5975062362792359
Validation loss: 2.6869832510540337

Epoch: 483| Step: 0
Training loss: 0.696738805420197
Validation loss: 2.688794260575535

Epoch: 6| Step: 1
Training loss: 0.8813752484427418
Validation loss: 2.7207812617305644

Epoch: 6| Step: 2
Training loss: 0.7583275843671369
Validation loss: 2.7323826534136657

Epoch: 6| Step: 3
Training loss: 0.3373137936138788
Validation loss: 2.811737932169976

Epoch: 6| Step: 4
Training loss: 0.4067583754614449
Validation loss: 2.880043167611963

Epoch: 6| Step: 5
Training loss: 0.5404103883992812
Validation loss: 2.8687346439324566

Epoch: 6| Step: 6
Training loss: 0.6365224149402553
Validation loss: 2.834916630774416

Epoch: 6| Step: 7
Training loss: 0.75132245455428
Validation loss: 2.8217319569147583

Epoch: 6| Step: 8
Training loss: 0.6439230621446171
Validation loss: 2.8290008537531213

Epoch: 6| Step: 9
Training loss: 0.5089477174546767
Validation loss: 2.823095918902115

Epoch: 6| Step: 10
Training loss: 0.43734179769927267
Validation loss: 2.849550946869655

Epoch: 6| Step: 11
Training loss: 0.4893768987947656
Validation loss: 2.819174342275152

Epoch: 6| Step: 12
Training loss: 0.588535170955314
Validation loss: 2.748459615757575

Epoch: 6| Step: 13
Training loss: 0.6130564818365423
Validation loss: 2.7350840058056876

Epoch: 484| Step: 0
Training loss: 0.571304920987156
Validation loss: 2.824388357357262

Epoch: 6| Step: 1
Training loss: 0.6060543550815587
Validation loss: 2.765382184937359

Epoch: 6| Step: 2
Training loss: 0.656190142853568
Validation loss: 2.782029803392719

Epoch: 6| Step: 3
Training loss: 0.8096029645457479
Validation loss: 2.790393543790317

Epoch: 6| Step: 4
Training loss: 0.5239883200657753
Validation loss: 2.809670968142682

Epoch: 6| Step: 5
Training loss: 0.6273452863282505
Validation loss: 2.733647320514915

Epoch: 6| Step: 6
Training loss: 0.582123205102304
Validation loss: 2.8657996537327017

Epoch: 6| Step: 7
Training loss: 0.6543773772406913
Validation loss: 2.8020902347597882

Epoch: 6| Step: 8
Training loss: 0.43275800699311556
Validation loss: 2.827117937326482

Epoch: 6| Step: 9
Training loss: 0.6512590859085026
Validation loss: 2.8067803893378183

Epoch: 6| Step: 10
Training loss: 0.5507440216252529
Validation loss: 2.811060628973812

Epoch: 6| Step: 11
Training loss: 0.5781459289061706
Validation loss: 2.820465520509949

Epoch: 6| Step: 12
Training loss: 0.6696857670251138
Validation loss: 2.8604005388516947

Epoch: 6| Step: 13
Training loss: 0.6471683307057824
Validation loss: 2.83544431379089

Epoch: 485| Step: 0
Training loss: 0.5670410019600204
Validation loss: 2.821712847191113

Epoch: 6| Step: 1
Training loss: 0.5244554613420217
Validation loss: 2.7540795093621293

Epoch: 6| Step: 2
Training loss: 0.7835845018717758
Validation loss: 2.7299237232591183

Epoch: 6| Step: 3
Training loss: 0.5067118233658116
Validation loss: 2.763964756340242

Epoch: 6| Step: 4
Training loss: 0.8189679707422908
Validation loss: 2.771515673800505

Epoch: 6| Step: 5
Training loss: 0.6404269773025149
Validation loss: 2.636945549900501

Epoch: 6| Step: 6
Training loss: 0.6251726388916359
Validation loss: 2.775291747144577

Epoch: 6| Step: 7
Training loss: 0.3735962661920082
Validation loss: 2.7618499537645365

Epoch: 6| Step: 8
Training loss: 1.0485043727508887
Validation loss: 2.7691862234855575

Epoch: 6| Step: 9
Training loss: 0.5698416346852502
Validation loss: 2.7989125564025135

Epoch: 6| Step: 10
Training loss: 0.6864340928871967
Validation loss: 2.872571223355112

Epoch: 6| Step: 11
Training loss: 0.8033628579078771
Validation loss: 2.9154534859481487

Epoch: 6| Step: 12
Training loss: 0.716516632262381
Validation loss: 2.894095445945259

Epoch: 6| Step: 13
Training loss: 0.5297717114689454
Validation loss: 2.899211660198458

Epoch: 486| Step: 0
Training loss: 0.5562890531996496
Validation loss: 2.9200565847157294

Epoch: 6| Step: 1
Training loss: 0.8571997074449781
Validation loss: 2.8816758889895926

Epoch: 6| Step: 2
Training loss: 0.5476245647847515
Validation loss: 2.8895021749447456

Epoch: 6| Step: 3
Training loss: 0.35175726052282763
Validation loss: 2.8435198792071863

Epoch: 6| Step: 4
Training loss: 0.4461388199414019
Validation loss: 2.79514308847516

Epoch: 6| Step: 5
Training loss: 0.669628846612321
Validation loss: 2.799335342379554

Epoch: 6| Step: 6
Training loss: 0.5132620739657071
Validation loss: 2.778135963764448

Epoch: 6| Step: 7
Training loss: 0.6983680024869288
Validation loss: 2.751885851219836

Epoch: 6| Step: 8
Training loss: 0.47657549168122576
Validation loss: 2.7764381044508224

Epoch: 6| Step: 9
Training loss: 0.8774531241065958
Validation loss: 2.7761261994527344

Epoch: 6| Step: 10
Training loss: 0.471812006554072
Validation loss: 2.776132082346447

Epoch: 6| Step: 11
Training loss: 0.5981059408389986
Validation loss: 2.811385873598349

Epoch: 6| Step: 12
Training loss: 0.786753609575368
Validation loss: 2.7671201870422877

Epoch: 6| Step: 13
Training loss: 0.6150566692139875
Validation loss: 2.8546435985589333

Epoch: 487| Step: 0
Training loss: 0.727998360684404
Validation loss: 2.9059880456488214

Epoch: 6| Step: 1
Training loss: 0.7355556736691826
Validation loss: 2.8284993705463344

Epoch: 6| Step: 2
Training loss: 0.49967712169698153
Validation loss: 2.7771697671712663

Epoch: 6| Step: 3
Training loss: 0.6517561590432652
Validation loss: 2.8036053623370782

Epoch: 6| Step: 4
Training loss: 0.5967496340846014
Validation loss: 2.749322085196903

Epoch: 6| Step: 5
Training loss: 0.6731568904679041
Validation loss: 2.8237914152965438

Epoch: 6| Step: 6
Training loss: 0.5554400698182876
Validation loss: 2.787247153362801

Epoch: 6| Step: 7
Training loss: 0.43181225225607417
Validation loss: 2.785961860326302

Epoch: 6| Step: 8
Training loss: 0.4635059918023538
Validation loss: 2.7338950907679007

Epoch: 6| Step: 9
Training loss: 0.8461199431446486
Validation loss: 2.766117404127738

Epoch: 6| Step: 10
Training loss: 0.5138050385390334
Validation loss: 2.8255982184763413

Epoch: 6| Step: 11
Training loss: 0.5168492493217237
Validation loss: 2.8539264234429775

Epoch: 6| Step: 12
Training loss: 0.6985391478849107
Validation loss: 2.7755116761358902

Epoch: 6| Step: 13
Training loss: 0.6505559991677945
Validation loss: 2.851842370081722

Epoch: 488| Step: 0
Training loss: 0.6316261945690921
Validation loss: 2.8431145653261

Epoch: 6| Step: 1
Training loss: 0.4975860408441397
Validation loss: 2.7875554619533185

Epoch: 6| Step: 2
Training loss: 0.6570452004855599
Validation loss: 2.752189602606158

Epoch: 6| Step: 3
Training loss: 0.3625263862214544
Validation loss: 2.761140553308711

Epoch: 6| Step: 4
Training loss: 0.7345812487631258
Validation loss: 2.7520788455977563

Epoch: 6| Step: 5
Training loss: 0.4681809149785601
Validation loss: 2.740992214028064

Epoch: 6| Step: 6
Training loss: 0.7193614183563966
Validation loss: 2.7700152133473384

Epoch: 6| Step: 7
Training loss: 0.7712959542332444
Validation loss: 2.7893680579660165

Epoch: 6| Step: 8
Training loss: 0.4542613742960014
Validation loss: 2.752145840331811

Epoch: 6| Step: 9
Training loss: 0.8170080203009352
Validation loss: 2.7147560745828447

Epoch: 6| Step: 10
Training loss: 0.8328508092718412
Validation loss: 2.725460263266947

Epoch: 6| Step: 11
Training loss: 0.46239380390535123
Validation loss: 2.726761308798092

Epoch: 6| Step: 12
Training loss: 0.46211215846302844
Validation loss: 2.850343807854171

Epoch: 6| Step: 13
Training loss: 0.6280911061645843
Validation loss: 2.8318271186309447

Epoch: 489| Step: 0
Training loss: 0.41078990853152625
Validation loss: 2.836682966912396

Epoch: 6| Step: 1
Training loss: 0.49186150790448
Validation loss: 2.833751112392652

Epoch: 6| Step: 2
Training loss: 0.5327159346613916
Validation loss: 2.8806384261581157

Epoch: 6| Step: 3
Training loss: 0.48492953643966097
Validation loss: 2.805310306803888

Epoch: 6| Step: 4
Training loss: 0.6921795975899231
Validation loss: 2.7633451702277005

Epoch: 6| Step: 5
Training loss: 0.4841357994116106
Validation loss: 2.708300668568355

Epoch: 6| Step: 6
Training loss: 0.6975275397247546
Validation loss: 2.7839136548491656

Epoch: 6| Step: 7
Training loss: 0.6623489261613021
Validation loss: 2.681578492595297

Epoch: 6| Step: 8
Training loss: 0.6150057897837957
Validation loss: 2.7622602724111083

Epoch: 6| Step: 9
Training loss: 0.8465805259635762
Validation loss: 2.746886137678288

Epoch: 6| Step: 10
Training loss: 0.5386236864960564
Validation loss: 2.7684963285203543

Epoch: 6| Step: 11
Training loss: 0.7723611605667323
Validation loss: 2.747513629623822

Epoch: 6| Step: 12
Training loss: 0.5203613017797127
Validation loss: 2.7729760730856143

Epoch: 6| Step: 13
Training loss: 0.47163958013702206
Validation loss: 2.837890723014702

Epoch: 490| Step: 0
Training loss: 0.5066741802835913
Validation loss: 2.782490757129692

Epoch: 6| Step: 1
Training loss: 0.7560672129266329
Validation loss: 2.832813752909301

Epoch: 6| Step: 2
Training loss: 0.6584217376343114
Validation loss: 2.8511745241202244

Epoch: 6| Step: 3
Training loss: 0.5713121719250908
Validation loss: 2.8394444467822413

Epoch: 6| Step: 4
Training loss: 0.6304091272913909
Validation loss: 2.8286619993808615

Epoch: 6| Step: 5
Training loss: 0.4898480112477569
Validation loss: 2.8942447028022515

Epoch: 6| Step: 6
Training loss: 0.4508397419762518
Validation loss: 2.8611990525229034

Epoch: 6| Step: 7
Training loss: 0.6412992418355786
Validation loss: 2.8217088055454345

Epoch: 6| Step: 8
Training loss: 0.5135107331570338
Validation loss: 2.7956385232410854

Epoch: 6| Step: 9
Training loss: 0.7811753046567267
Validation loss: 2.8456449517993727

Epoch: 6| Step: 10
Training loss: 0.5002148285930909
Validation loss: 2.8310507855142277

Epoch: 6| Step: 11
Training loss: 0.5779582375928852
Validation loss: 2.7797962346859353

Epoch: 6| Step: 12
Training loss: 0.30005779206409017
Validation loss: 2.8133426957931333

Epoch: 6| Step: 13
Training loss: 0.5992348461152752
Validation loss: 2.802790943598335

Epoch: 491| Step: 0
Training loss: 0.6144955028124165
Validation loss: 2.8393271289831397

Epoch: 6| Step: 1
Training loss: 0.5078685142728264
Validation loss: 2.7926954300176945

Epoch: 6| Step: 2
Training loss: 0.5405429193445972
Validation loss: 2.8237899940228606

Epoch: 6| Step: 3
Training loss: 0.6563816846697116
Validation loss: 2.7645734163483495

Epoch: 6| Step: 4
Training loss: 0.6749312065531228
Validation loss: 2.7897405432422233

Epoch: 6| Step: 5
Training loss: 0.5476427411251276
Validation loss: 2.769036783789858

Epoch: 6| Step: 6
Training loss: 0.39261171567316827
Validation loss: 2.82823554678268

Epoch: 6| Step: 7
Training loss: 0.7474194876264976
Validation loss: 2.7822348176229617

Epoch: 6| Step: 8
Training loss: 0.4826976127103557
Validation loss: 2.864282354090828

Epoch: 6| Step: 9
Training loss: 0.6571239374307101
Validation loss: 2.832752621735527

Epoch: 6| Step: 10
Training loss: 0.47101196667276635
Validation loss: 2.817535695953037

Epoch: 6| Step: 11
Training loss: 0.4136797377403762
Validation loss: 2.7675536304252293

Epoch: 6| Step: 12
Training loss: 0.4260384369084959
Validation loss: 2.733959100974071

Epoch: 6| Step: 13
Training loss: 0.5611445467206972
Validation loss: 2.801781270551777

Epoch: 492| Step: 0
Training loss: 0.8804156418550818
Validation loss: 2.805454754880811

Epoch: 6| Step: 1
Training loss: 0.6768623480490564
Validation loss: 2.7436006677724545

Epoch: 6| Step: 2
Training loss: 0.49606521404226095
Validation loss: 2.750697842111415

Epoch: 6| Step: 3
Training loss: 0.6530032450520851
Validation loss: 2.788972427523661

Epoch: 6| Step: 4
Training loss: 0.318369250934217
Validation loss: 2.776712366401997

Epoch: 6| Step: 5
Training loss: 0.5189735746602157
Validation loss: 2.8694167172016654

Epoch: 6| Step: 6
Training loss: 0.5776057102009611
Validation loss: 2.82063367710854

Epoch: 6| Step: 7
Training loss: 0.5873551575693807
Validation loss: 2.868133970784007

Epoch: 6| Step: 8
Training loss: 0.6587626176237378
Validation loss: 2.8828347884973198

Epoch: 6| Step: 9
Training loss: 0.4002545195198675
Validation loss: 2.8481349603745127

Epoch: 6| Step: 10
Training loss: 0.5976137632340087
Validation loss: 2.805311765769479

Epoch: 6| Step: 11
Training loss: 0.6504308556380174
Validation loss: 2.8704075691816184

Epoch: 6| Step: 12
Training loss: 0.4891233278417044
Validation loss: 2.885030167420273

Epoch: 6| Step: 13
Training loss: 0.41394505544612914
Validation loss: 2.8977997138974976

Epoch: 493| Step: 0
Training loss: 0.4926437806094904
Validation loss: 2.870214778404386

Epoch: 6| Step: 1
Training loss: 0.4084885252037807
Validation loss: 2.8379951067508866

Epoch: 6| Step: 2
Training loss: 0.5411850151095717
Validation loss: 2.7697580923451217

Epoch: 6| Step: 3
Training loss: 0.7499235432118745
Validation loss: 2.830992353335804

Epoch: 6| Step: 4
Training loss: 0.5955044274313689
Validation loss: 2.7487348189317093

Epoch: 6| Step: 5
Training loss: 0.45890110965040976
Validation loss: 2.8028203262104716

Epoch: 6| Step: 6
Training loss: 0.40160561415483065
Validation loss: 2.8509328486663765

Epoch: 6| Step: 7
Training loss: 0.4809681227900954
Validation loss: 2.771129654453759

Epoch: 6| Step: 8
Training loss: 0.6847358536110318
Validation loss: 2.7686888970032877

Epoch: 6| Step: 9
Training loss: 0.34534503688543144
Validation loss: 2.7696491641404712

Epoch: 6| Step: 10
Training loss: 0.544587035858519
Validation loss: 2.770407785038149

Epoch: 6| Step: 11
Training loss: 0.8234720327819937
Validation loss: 2.7504732851757003

Epoch: 6| Step: 12
Training loss: 0.7866972798180312
Validation loss: 2.7688642881527588

Epoch: 6| Step: 13
Training loss: 0.5401759327730589
Validation loss: 2.7877350968920496

Epoch: 494| Step: 0
Training loss: 0.6805671174068515
Validation loss: 2.8244615998244433

Epoch: 6| Step: 1
Training loss: 0.45823148296568855
Validation loss: 2.9035681789717174

Epoch: 6| Step: 2
Training loss: 0.6799552214829248
Validation loss: 2.9177351266124893

Epoch: 6| Step: 3
Training loss: 0.6259954393132348
Validation loss: 2.876608274345324

Epoch: 6| Step: 4
Training loss: 0.5953842310104748
Validation loss: 2.8734620306735597

Epoch: 6| Step: 5
Training loss: 0.34856657793471885
Validation loss: 2.851585297515177

Epoch: 6| Step: 6
Training loss: 0.6776306116884723
Validation loss: 2.859259848021778

Epoch: 6| Step: 7
Training loss: 0.6793856553450208
Validation loss: 2.819744359326413

Epoch: 6| Step: 8
Training loss: 0.5101362612957504
Validation loss: 2.862871877177153

Epoch: 6| Step: 9
Training loss: 0.7971521905236917
Validation loss: 2.768487343482088

Epoch: 6| Step: 10
Training loss: 0.5449287660224567
Validation loss: 2.84138190351951

Epoch: 6| Step: 11
Training loss: 0.6312049415294625
Validation loss: 2.794314905241542

Epoch: 6| Step: 12
Training loss: 0.4389888090692833
Validation loss: 2.811927807847568

Epoch: 6| Step: 13
Training loss: 0.4672834342518232
Validation loss: 2.87482916282935

Epoch: 495| Step: 0
Training loss: 0.680772529180221
Validation loss: 2.8931160717871256

Epoch: 6| Step: 1
Training loss: 0.6140044983316959
Validation loss: 2.8795073876687725

Epoch: 6| Step: 2
Training loss: 0.6039543162336531
Validation loss: 2.8788208519645844

Epoch: 6| Step: 3
Training loss: 0.7613796555297389
Validation loss: 2.82103957282032

Epoch: 6| Step: 4
Training loss: 0.5505002975844187
Validation loss: 2.8725701305437203

Epoch: 6| Step: 5
Training loss: 0.4981198425696062
Validation loss: 2.796206659064406

Epoch: 6| Step: 6
Training loss: 0.6653228244007294
Validation loss: 2.7020738796126595

Epoch: 6| Step: 7
Training loss: 0.3259881695783101
Validation loss: 2.766744125001954

Epoch: 6| Step: 8
Training loss: 0.41671178891318406
Validation loss: 2.7800509836475458

Epoch: 6| Step: 9
Training loss: 0.6040557370347502
Validation loss: 2.7120341520606557

Epoch: 6| Step: 10
Training loss: 0.4969098744659348
Validation loss: 2.7032969572612213

Epoch: 6| Step: 11
Training loss: 0.5613472570929753
Validation loss: 2.766900797401183

Epoch: 6| Step: 12
Training loss: 0.45417273179067047
Validation loss: 2.8539824925237434

Epoch: 6| Step: 13
Training loss: 0.679660577350458
Validation loss: 2.7478325422905203

Epoch: 496| Step: 0
Training loss: 0.46141283128115906
Validation loss: 2.889993423335634

Epoch: 6| Step: 1
Training loss: 0.3697100289542827
Validation loss: 2.790533303081727

Epoch: 6| Step: 2
Training loss: 0.32527574340691967
Validation loss: 2.845715510739139

Epoch: 6| Step: 3
Training loss: 0.48435312652421514
Validation loss: 2.849524911801384

Epoch: 6| Step: 4
Training loss: 0.6252722147366437
Validation loss: 2.888418836947766

Epoch: 6| Step: 5
Training loss: 0.5081887831779046
Validation loss: 2.8910121143012035

Epoch: 6| Step: 6
Training loss: 0.8907597088580431
Validation loss: 2.8776140353808906

Epoch: 6| Step: 7
Training loss: 0.5618213957696455
Validation loss: 2.8701090328537253

Epoch: 6| Step: 8
Training loss: 0.5419181704456564
Validation loss: 2.7707963859752613

Epoch: 6| Step: 9
Training loss: 0.8172718916254268
Validation loss: 2.785187580633298

Epoch: 6| Step: 10
Training loss: 0.7198373613514968
Validation loss: 2.7747538849802025

Epoch: 6| Step: 11
Training loss: 0.5707185423307088
Validation loss: 2.7291640555876455

Epoch: 6| Step: 12
Training loss: 0.37990250328044534
Validation loss: 2.7924563633700505

Epoch: 6| Step: 13
Training loss: 0.6286435970802849
Validation loss: 2.7638247893571983

Epoch: 497| Step: 0
Training loss: 0.5588625814533752
Validation loss: 2.8060177735980014

Epoch: 6| Step: 1
Training loss: 0.3861337919324109
Validation loss: 2.8281026034934866

Epoch: 6| Step: 2
Training loss: 0.6069621710828026
Validation loss: 2.74653033805521

Epoch: 6| Step: 3
Training loss: 0.4508556066635519
Validation loss: 2.83062568248455

Epoch: 6| Step: 4
Training loss: 0.405692818824976
Validation loss: 2.8058300613174265

Epoch: 6| Step: 5
Training loss: 0.6246722315591622
Validation loss: 2.8005775083161444

Epoch: 6| Step: 6
Training loss: 0.36388726089483836
Validation loss: 2.7760116737754217

Epoch: 6| Step: 7
Training loss: 0.6453136665758575
Validation loss: 2.8111506015364305

Epoch: 6| Step: 8
Training loss: 0.5718587268536018
Validation loss: 2.7461901847218333

Epoch: 6| Step: 9
Training loss: 0.6290224335252692
Validation loss: 2.77733673938952

Epoch: 6| Step: 10
Training loss: 0.5363508382212281
Validation loss: 2.784125081444148

Epoch: 6| Step: 11
Training loss: 0.7436694959138986
Validation loss: 2.811280586660898

Epoch: 6| Step: 12
Training loss: 0.42938384684148345
Validation loss: 2.8193612083797364

Epoch: 6| Step: 13
Training loss: 0.5798459085944951
Validation loss: 2.790631405950116

Epoch: 498| Step: 0
Training loss: 0.49609313424139784
Validation loss: 2.7584760838321682

Epoch: 6| Step: 1
Training loss: 0.5415256726333642
Validation loss: 2.7848185815626105

Epoch: 6| Step: 2
Training loss: 0.9266049225794794
Validation loss: 2.767233544226331

Epoch: 6| Step: 3
Training loss: 0.6764083774856592
Validation loss: 2.724616171259818

Epoch: 6| Step: 4
Training loss: 0.4696105845576505
Validation loss: 2.7464309709616304

Epoch: 6| Step: 5
Training loss: 0.641728009866986
Validation loss: 2.7809915744005047

Epoch: 6| Step: 6
Training loss: 0.5896455040044049
Validation loss: 2.7341502360654713

Epoch: 6| Step: 7
Training loss: 0.3001726855534692
Validation loss: 2.779047018522986

Epoch: 6| Step: 8
Training loss: 0.5024279415598952
Validation loss: 2.7910796777214966

Epoch: 6| Step: 9
Training loss: 0.6373038382821208
Validation loss: 2.7715848223938955

Epoch: 6| Step: 10
Training loss: 0.4305692814960027
Validation loss: 2.8011137455955555

Epoch: 6| Step: 11
Training loss: 0.6877389622589148
Validation loss: 2.8144979515273794

Epoch: 6| Step: 12
Training loss: 0.38000260844715705
Validation loss: 2.7891164110175386

Epoch: 6| Step: 13
Training loss: 0.6292213929819205
Validation loss: 2.85365615697113

Epoch: 499| Step: 0
Training loss: 0.361994855069645
Validation loss: 2.82514657678378

Epoch: 6| Step: 1
Training loss: 0.41943917143091786
Validation loss: 2.8654410355540207

Epoch: 6| Step: 2
Training loss: 0.5279743803683111
Validation loss: 2.869166842159724

Epoch: 6| Step: 3
Training loss: 0.67778914172603
Validation loss: 2.8265823737507727

Epoch: 6| Step: 4
Training loss: 0.801648335759466
Validation loss: 2.821413820192521

Epoch: 6| Step: 5
Training loss: 0.5620445420849179
Validation loss: 2.8476689481866377

Epoch: 6| Step: 6
Training loss: 0.31504773851096673
Validation loss: 2.7789473413248635

Epoch: 6| Step: 7
Training loss: 0.4346258235152317
Validation loss: 2.8594168571368566

Epoch: 6| Step: 8
Training loss: 0.529744877141042
Validation loss: 2.7756253992618833

Epoch: 6| Step: 9
Training loss: 0.3316034365810103
Validation loss: 2.841385189968122

Epoch: 6| Step: 10
Training loss: 0.7221642133655104
Validation loss: 2.7828421875107106

Epoch: 6| Step: 11
Training loss: 0.7102514876659245
Validation loss: 2.8212000893462696

Epoch: 6| Step: 12
Training loss: 0.5942104712367716
Validation loss: 2.8678002945611585

Epoch: 6| Step: 13
Training loss: 0.5629155690201063
Validation loss: 2.743271464020605

Epoch: 500| Step: 0
Training loss: 0.48052258693866573
Validation loss: 2.783376487998903

Epoch: 6| Step: 1
Training loss: 0.7573274456179239
Validation loss: 2.7826301921948384

Epoch: 6| Step: 2
Training loss: 0.5159305476385094
Validation loss: 2.796376771788738

Epoch: 6| Step: 3
Training loss: 0.4745268102343346
Validation loss: 2.7518676715666324

Epoch: 6| Step: 4
Training loss: 0.6206581459529278
Validation loss: 2.7828891652916776

Epoch: 6| Step: 5
Training loss: 0.7200188838946
Validation loss: 2.744010399096203

Epoch: 6| Step: 6
Training loss: 0.3746373688199572
Validation loss: 2.7379631986037296

Epoch: 6| Step: 7
Training loss: 0.3557983798400247
Validation loss: 2.770897503638003

Epoch: 6| Step: 8
Training loss: 0.42493946962703827
Validation loss: 2.75460308808957

Epoch: 6| Step: 9
Training loss: 0.6306878674628646
Validation loss: 2.798896002539795

Epoch: 6| Step: 10
Training loss: 0.5561871739600996
Validation loss: 2.8233882937060457

Epoch: 6| Step: 11
Training loss: 0.509229941278778
Validation loss: 2.703676729730594

Epoch: 6| Step: 12
Training loss: 0.545010631265103
Validation loss: 2.7998442348228103

Epoch: 6| Step: 13
Training loss: 0.7798358707263048
Validation loss: 2.7451257423965107

Epoch: 501| Step: 0
Training loss: 0.6444380721739988
Validation loss: 2.7917316818258047

Epoch: 6| Step: 1
Training loss: 0.5316752246638278
Validation loss: 2.7562446784489265

Epoch: 6| Step: 2
Training loss: 0.5392620988707939
Validation loss: 2.7766221508916593

Epoch: 6| Step: 3
Training loss: 0.4327657715674287
Validation loss: 2.8883296066527215

Epoch: 6| Step: 4
Training loss: 0.5838387604404117
Validation loss: 2.9284587809643923

Epoch: 6| Step: 5
Training loss: 0.7616030874225803
Validation loss: 2.8278730361006046

Epoch: 6| Step: 6
Training loss: 0.6487247336434314
Validation loss: 2.8586345540766285

Epoch: 6| Step: 7
Training loss: 0.4065934526710517
Validation loss: 2.802984473293532

Epoch: 6| Step: 8
Training loss: 0.4872380977535249
Validation loss: 2.765419630913417

Epoch: 6| Step: 9
Training loss: 0.38755076906425423
Validation loss: 2.712577170052155

Epoch: 6| Step: 10
Training loss: 0.7600446252520787
Validation loss: 2.7374062294192067

Epoch: 6| Step: 11
Training loss: 0.6928436295360102
Validation loss: 2.791471294190115

Epoch: 6| Step: 12
Training loss: 0.6071822009441915
Validation loss: 2.7521250201602396

Epoch: 6| Step: 13
Training loss: 0.41227167558449873
Validation loss: 2.7382910306994397

Epoch: 502| Step: 0
Training loss: 0.6332366134382227
Validation loss: 2.760872300649557

Epoch: 6| Step: 1
Training loss: 0.46545853551417954
Validation loss: 2.7090447200699637

Epoch: 6| Step: 2
Training loss: 0.4018629590213616
Validation loss: 2.832929559061038

Epoch: 6| Step: 3
Training loss: 0.6794421750770087
Validation loss: 2.786230350092514

Epoch: 6| Step: 4
Training loss: 0.6571794014004091
Validation loss: 2.7617327785540313

Epoch: 6| Step: 5
Training loss: 0.6061477053750431
Validation loss: 2.8283714692851603

Epoch: 6| Step: 6
Training loss: 0.447515026671373
Validation loss: 2.8594644390077724

Epoch: 6| Step: 7
Training loss: 0.6304509402646624
Validation loss: 2.783392948570565

Epoch: 6| Step: 8
Training loss: 0.44058962199715584
Validation loss: 2.844825960276427

Epoch: 6| Step: 9
Training loss: 0.5274040187728146
Validation loss: 2.776465225590915

Epoch: 6| Step: 10
Training loss: 0.5062700762123455
Validation loss: 2.8517033023996543

Epoch: 6| Step: 11
Training loss: 0.4387209069151238
Validation loss: 2.8491977170323564

Epoch: 6| Step: 12
Training loss: 0.7984741471273045
Validation loss: 2.8072621633551686

Epoch: 6| Step: 13
Training loss: 0.6747719609099019
Validation loss: 2.7850590885544064

Epoch: 503| Step: 0
Training loss: 0.6511389290954124
Validation loss: 2.8634635863766746

Epoch: 6| Step: 1
Training loss: 0.5181548162700119
Validation loss: 2.808881084403464

Epoch: 6| Step: 2
Training loss: 0.6427949811952546
Validation loss: 2.8693957231621217

Epoch: 6| Step: 3
Training loss: 0.337745756724772
Validation loss: 2.863000457859569

Epoch: 6| Step: 4
Training loss: 0.5979598527081434
Validation loss: 2.8761775466301414

Epoch: 6| Step: 5
Training loss: 0.4340305190529616
Validation loss: 2.812712597759105

Epoch: 6| Step: 6
Training loss: 0.7587262965966567
Validation loss: 2.8745752863990903

Epoch: 6| Step: 7
Training loss: 0.6216894448030265
Validation loss: 2.8279126756747752

Epoch: 6| Step: 8
Training loss: 0.48037839830850754
Validation loss: 2.848198133138959

Epoch: 6| Step: 9
Training loss: 0.4439156021803366
Validation loss: 2.733367116552626

Epoch: 6| Step: 10
Training loss: 0.47487607769945506
Validation loss: 2.73625247985997

Epoch: 6| Step: 11
Training loss: 0.5711366368588322
Validation loss: 2.716540070569916

Epoch: 6| Step: 12
Training loss: 0.6761937729029497
Validation loss: 2.705356169548621

Epoch: 6| Step: 13
Training loss: 0.6711534129434171
Validation loss: 2.7581688035681653

Epoch: 504| Step: 0
Training loss: 0.5912864674618777
Validation loss: 2.7197137637153967

Epoch: 6| Step: 1
Training loss: 0.5720854335569471
Validation loss: 2.827032689704712

Epoch: 6| Step: 2
Training loss: 0.654956200751413
Validation loss: 2.8677788591471116

Epoch: 6| Step: 3
Training loss: 0.47793455070761903
Validation loss: 2.836175073177841

Epoch: 6| Step: 4
Training loss: 0.561664384484489
Validation loss: 2.9425414631660116

Epoch: 6| Step: 5
Training loss: 0.5944981629717833
Validation loss: 2.8694692743305614

Epoch: 6| Step: 6
Training loss: 0.598208801553473
Validation loss: 2.860660354410232

Epoch: 6| Step: 7
Training loss: 0.46124263943637583
Validation loss: 2.820431454052855

Epoch: 6| Step: 8
Training loss: 0.523144113107172
Validation loss: 2.795135255314984

Epoch: 6| Step: 9
Training loss: 0.5116299268204314
Validation loss: 2.829938022891919

Epoch: 6| Step: 10
Training loss: 0.4505480131502363
Validation loss: 2.771913358587084

Epoch: 6| Step: 11
Training loss: 0.652531853698536
Validation loss: 2.8431782269926997

Epoch: 6| Step: 12
Training loss: 0.8840158413939131
Validation loss: 2.828953419674612

Epoch: 6| Step: 13
Training loss: 0.48517114060504724
Validation loss: 2.780456301132592

Epoch: 505| Step: 0
Training loss: 0.3770778627508133
Validation loss: 2.8342572463591997

Epoch: 6| Step: 1
Training loss: 0.4069913921500373
Validation loss: 2.801361676472035

Epoch: 6| Step: 2
Training loss: 0.47326883704656453
Validation loss: 2.8340774755698814

Epoch: 6| Step: 3
Training loss: 0.4029007731652528
Validation loss: 2.806022460933705

Epoch: 6| Step: 4
Training loss: 0.35996260495143756
Validation loss: 2.817356522479881

Epoch: 6| Step: 5
Training loss: 0.438592262550933
Validation loss: 2.813510995636727

Epoch: 6| Step: 6
Training loss: 0.4730045832055052
Validation loss: 2.8132399821801255

Epoch: 6| Step: 7
Training loss: 0.32388318172442715
Validation loss: 2.824638887691805

Epoch: 6| Step: 8
Training loss: 0.7011664132673228
Validation loss: 2.8218929832338904

Epoch: 6| Step: 9
Training loss: 0.9282525793687494
Validation loss: 2.8551177275703252

Epoch: 6| Step: 10
Training loss: 0.652820960830489
Validation loss: 2.7670902602006553

Epoch: 6| Step: 11
Training loss: 0.561199698626056
Validation loss: 2.735935470722636

Epoch: 6| Step: 12
Training loss: 0.5122571253395019
Validation loss: 2.733600790227877

Epoch: 6| Step: 13
Training loss: 0.6594272854942802
Validation loss: 2.7241415298934335

Epoch: 506| Step: 0
Training loss: 0.39921766456411656
Validation loss: 2.7352760937362515

Epoch: 6| Step: 1
Training loss: 0.6677999896750688
Validation loss: 2.7451716720365273

Epoch: 6| Step: 2
Training loss: 0.48356531518711054
Validation loss: 2.7637706941117126

Epoch: 6| Step: 3
Training loss: 0.6587773656499408
Validation loss: 2.7669374616839675

Epoch: 6| Step: 4
Training loss: 0.5210534647821359
Validation loss: 2.79753387760198

Epoch: 6| Step: 5
Training loss: 0.42688655002657294
Validation loss: 2.8455528022337044

Epoch: 6| Step: 6
Training loss: 0.7551498039628766
Validation loss: 2.8108877293872205

Epoch: 6| Step: 7
Training loss: 0.591876084468698
Validation loss: 2.73735032739333

Epoch: 6| Step: 8
Training loss: 0.6409806683090526
Validation loss: 2.7319051578008846

Epoch: 6| Step: 9
Training loss: 0.5392371461439001
Validation loss: 2.8574531781178325

Epoch: 6| Step: 10
Training loss: 0.2556125236301914
Validation loss: 2.8394998782109115

Epoch: 6| Step: 11
Training loss: 0.5005955427649571
Validation loss: 2.8291026159198287

Epoch: 6| Step: 12
Training loss: 0.5483570452851371
Validation loss: 2.8057446909143886

Epoch: 6| Step: 13
Training loss: 0.44591822335937414
Validation loss: 2.741216735869951

Epoch: 507| Step: 0
Training loss: 0.4111000283550957
Validation loss: 2.775567425173154

Epoch: 6| Step: 1
Training loss: 0.7063326255605169
Validation loss: 2.7584935140823323

Epoch: 6| Step: 2
Training loss: 0.4452106459734123
Validation loss: 2.8150102644982216

Epoch: 6| Step: 3
Training loss: 0.49002733456020636
Validation loss: 2.7375820281165844

Epoch: 6| Step: 4
Training loss: 0.5061763521477192
Validation loss: 2.7935019528776057

Epoch: 6| Step: 5
Training loss: 0.6474166555782335
Validation loss: 2.793097859846365

Epoch: 6| Step: 6
Training loss: 0.46732456914018344
Validation loss: 2.784819195127281

Epoch: 6| Step: 7
Training loss: 0.7209922810060623
Validation loss: 2.7832251689550995

Epoch: 6| Step: 8
Training loss: 0.6415545999418705
Validation loss: 2.8198450181862773

Epoch: 6| Step: 9
Training loss: 0.674130490782007
Validation loss: 2.8498194971981503

Epoch: 6| Step: 10
Training loss: 0.48340087273494864
Validation loss: 2.9203936651797804

Epoch: 6| Step: 11
Training loss: 0.508256981801247
Validation loss: 2.8646447377414974

Epoch: 6| Step: 12
Training loss: 0.4525995167214261
Validation loss: 2.8306156382508045

Epoch: 6| Step: 13
Training loss: 0.46146643726934133
Validation loss: 2.8409938800758834

Epoch: 508| Step: 0
Training loss: 0.5040913914478745
Validation loss: 2.7798867903100493

Epoch: 6| Step: 1
Training loss: 0.730423339411418
Validation loss: 2.794316049987949

Epoch: 6| Step: 2
Training loss: 0.5147942584363759
Validation loss: 2.7577028333780036

Epoch: 6| Step: 3
Training loss: 0.6417965063000002
Validation loss: 2.786768763472762

Epoch: 6| Step: 4
Training loss: 0.7501740253728572
Validation loss: 2.808622428171091

Epoch: 6| Step: 5
Training loss: 0.5131445088551871
Validation loss: 2.7638326321813205

Epoch: 6| Step: 6
Training loss: 0.4707859647041894
Validation loss: 2.7527012418424976

Epoch: 6| Step: 7
Training loss: 0.7096062657146294
Validation loss: 2.760419713624436

Epoch: 6| Step: 8
Training loss: 0.3548716466193669
Validation loss: 2.79401756103429

Epoch: 6| Step: 9
Training loss: 0.36536841559309224
Validation loss: 2.8403172297226216

Epoch: 6| Step: 10
Training loss: 0.45427114950144415
Validation loss: 2.8894552114878924

Epoch: 6| Step: 11
Training loss: 0.3063358322843447
Validation loss: 2.8343658576097286

Epoch: 6| Step: 12
Training loss: 0.5014660620744238
Validation loss: 2.8653290535111

Epoch: 6| Step: 13
Training loss: 0.5905218458164175
Validation loss: 2.9102991124530666

Epoch: 509| Step: 0
Training loss: 0.626993813783831
Validation loss: 2.896479106957448

Epoch: 6| Step: 1
Training loss: 0.586871788292365
Validation loss: 2.8851612588560243

Epoch: 6| Step: 2
Training loss: 0.6708292030025668
Validation loss: 2.826345020571308

Epoch: 6| Step: 3
Training loss: 0.6159186539072314
Validation loss: 2.8228446181746425

Epoch: 6| Step: 4
Training loss: 0.4683230840193859
Validation loss: 2.7871910248995126

Epoch: 6| Step: 5
Training loss: 0.4942113350798318
Validation loss: 2.78742715030467

Epoch: 6| Step: 6
Training loss: 0.7392827663468161
Validation loss: 2.7849561593550485

Epoch: 6| Step: 7
Training loss: 0.6398428352172423
Validation loss: 2.793716963559163

Epoch: 6| Step: 8
Training loss: 0.3812953116896795
Validation loss: 2.831449546266106

Epoch: 6| Step: 9
Training loss: 0.7750683169863762
Validation loss: 2.90834046793794

Epoch: 6| Step: 10
Training loss: 0.5812132290519941
Validation loss: 2.8601823511211726

Epoch: 6| Step: 11
Training loss: 0.4190280005742743
Validation loss: 2.898103268006934

Epoch: 6| Step: 12
Training loss: 0.46738634438939725
Validation loss: 2.8184162926340393

Epoch: 6| Step: 13
Training loss: 0.4366420951541402
Validation loss: 2.7926220089524576

Epoch: 510| Step: 0
Training loss: 0.6108867526624521
Validation loss: 2.8402325181741195

Epoch: 6| Step: 1
Training loss: 0.5495194665916138
Validation loss: 2.813882417369086

Epoch: 6| Step: 2
Training loss: 0.7072384356850795
Validation loss: 2.82196458665169

Epoch: 6| Step: 3
Training loss: 0.5165344079254768
Validation loss: 2.8463982348624053

Epoch: 6| Step: 4
Training loss: 0.480338846649324
Validation loss: 2.7878570801203284

Epoch: 6| Step: 5
Training loss: 0.42172496388264646
Validation loss: 2.7785315354544773

Epoch: 6| Step: 6
Training loss: 0.42244145546415984
Validation loss: 2.7448827497991712

Epoch: 6| Step: 7
Training loss: 0.7110720496658401
Validation loss: 2.761610317664471

Epoch: 6| Step: 8
Training loss: 0.8943156686399192
Validation loss: 2.814757472500119

Epoch: 6| Step: 9
Training loss: 0.570256896770402
Validation loss: 2.7951138597293155

Epoch: 6| Step: 10
Training loss: 0.5263323374236101
Validation loss: 2.8416048419823436

Epoch: 6| Step: 11
Training loss: 0.8796561538775921
Validation loss: 2.8454330829372667

Epoch: 6| Step: 12
Training loss: 0.7537038264516192
Validation loss: 2.8796975347958473

Epoch: 6| Step: 13
Training loss: 0.6404791875371705
Validation loss: 2.8473891702930696

Epoch: 511| Step: 0
Training loss: 0.48379337091725894
Validation loss: 2.9245768276268507

Epoch: 6| Step: 1
Training loss: 0.7295909646196299
Validation loss: 2.9336679231669667

Epoch: 6| Step: 2
Training loss: 0.6759947952064496
Validation loss: 2.907923705283849

Epoch: 6| Step: 3
Training loss: 0.48472862256125965
Validation loss: 2.872133207837695

Epoch: 6| Step: 4
Training loss: 0.4891187885298496
Validation loss: 2.884717413573241

Epoch: 6| Step: 5
Training loss: 0.5641154034603642
Validation loss: 2.8557297030294246

Epoch: 6| Step: 6
Training loss: 0.5784409664798283
Validation loss: 2.8186584440870477

Epoch: 6| Step: 7
Training loss: 0.6209014018930886
Validation loss: 2.8382377018463423

Epoch: 6| Step: 8
Training loss: 0.5880154702071813
Validation loss: 2.7673842587228177

Epoch: 6| Step: 9
Training loss: 0.39295857531986683
Validation loss: 2.8157770068550487

Epoch: 6| Step: 10
Training loss: 0.6712371548608161
Validation loss: 2.8298028988041777

Epoch: 6| Step: 11
Training loss: 0.7093257029877081
Validation loss: 2.8572359404841454

Epoch: 6| Step: 12
Training loss: 0.6058377771813636
Validation loss: 2.815132293890015

Epoch: 6| Step: 13
Training loss: 0.7310947856663386
Validation loss: 2.8025606356301855

Epoch: 512| Step: 0
Training loss: 0.5033168154599816
Validation loss: 2.862257083430585

Epoch: 6| Step: 1
Training loss: 0.6682678802130372
Validation loss: 2.8362993021827396

Epoch: 6| Step: 2
Training loss: 0.46687485430611786
Validation loss: 2.873115184325426

Epoch: 6| Step: 3
Training loss: 0.6509290877598497
Validation loss: 2.9034629433458363

Epoch: 6| Step: 4
Training loss: 0.4370455936537071
Validation loss: 2.828367654917742

Epoch: 6| Step: 5
Training loss: 0.364346245470277
Validation loss: 2.7837719859074506

Epoch: 6| Step: 6
Training loss: 0.48203804407015105
Validation loss: 2.7249065059406825

Epoch: 6| Step: 7
Training loss: 0.5309628103059946
Validation loss: 2.727224071145723

Epoch: 6| Step: 8
Training loss: 0.8260076192707627
Validation loss: 2.706425322388424

Epoch: 6| Step: 9
Training loss: 0.44311234234162994
Validation loss: 2.7637863944222483

Epoch: 6| Step: 10
Training loss: 0.6231658248001265
Validation loss: 2.8088464671875344

Epoch: 6| Step: 11
Training loss: 0.6615642452802598
Validation loss: 2.6940453540766875

Epoch: 6| Step: 12
Training loss: 0.8404198378460701
Validation loss: 2.79307866802756

Epoch: 6| Step: 13
Training loss: 0.4836963852784584
Validation loss: 2.784474036513704

Epoch: 513| Step: 0
Training loss: 0.39582039995982143
Validation loss: 2.9284570169861968

Epoch: 6| Step: 1
Training loss: 0.5011510712370946
Validation loss: 2.9730475523663924

Epoch: 6| Step: 2
Training loss: 0.42417571761074574
Validation loss: 2.938922821570943

Epoch: 6| Step: 3
Training loss: 0.7194245945914061
Validation loss: 2.93632458105597

Epoch: 6| Step: 4
Training loss: 0.5251214000575785
Validation loss: 2.9086298069139382

Epoch: 6| Step: 5
Training loss: 0.5812993408098327
Validation loss: 2.862179435315727

Epoch: 6| Step: 6
Training loss: 0.5862874321282985
Validation loss: 2.827132906346768

Epoch: 6| Step: 7
Training loss: 0.6550667859019047
Validation loss: 2.8949607430949515

Epoch: 6| Step: 8
Training loss: 0.8598715648003008
Validation loss: 2.8224211864432056

Epoch: 6| Step: 9
Training loss: 0.7032850719077696
Validation loss: 2.8628044893771545

Epoch: 6| Step: 10
Training loss: 0.6467545051579998
Validation loss: 2.8153468805794577

Epoch: 6| Step: 11
Training loss: 0.632730596446059
Validation loss: 2.7961485929920444

Epoch: 6| Step: 12
Training loss: 0.557208337228377
Validation loss: 2.7839204918882716

Epoch: 6| Step: 13
Training loss: 0.37724119257773525
Validation loss: 2.897975271269092

Epoch: 514| Step: 0
Training loss: 0.7764171272386468
Validation loss: 2.869146081734444

Epoch: 6| Step: 1
Training loss: 0.31507752308503084
Validation loss: 2.928883163240413

Epoch: 6| Step: 2
Training loss: 0.6774158443815566
Validation loss: 2.824002220256498

Epoch: 6| Step: 3
Training loss: 0.44936511101804444
Validation loss: 2.869379202019045

Epoch: 6| Step: 4
Training loss: 0.5963442494818539
Validation loss: 2.899625933846248

Epoch: 6| Step: 5
Training loss: 0.5627756503007314
Validation loss: 2.877744083829164

Epoch: 6| Step: 6
Training loss: 0.4240109449292011
Validation loss: 2.7824681789592813

Epoch: 6| Step: 7
Training loss: 0.35871268483728863
Validation loss: 2.7551070244569367

Epoch: 6| Step: 8
Training loss: 0.5639550674714063
Validation loss: 2.7507618513491363

Epoch: 6| Step: 9
Training loss: 0.4661666254560234
Validation loss: 2.7543773635936057

Epoch: 6| Step: 10
Training loss: 0.47083575014602497
Validation loss: 2.763020943591625

Epoch: 6| Step: 11
Training loss: 0.5405729390032948
Validation loss: 2.738263212208964

Epoch: 6| Step: 12
Training loss: 0.6748685903144127
Validation loss: 2.7495956557124392

Epoch: 6| Step: 13
Training loss: 0.6557282917197654
Validation loss: 2.747901115537363

Epoch: 515| Step: 0
Training loss: 0.3269974659120147
Validation loss: 2.7490066699459033

Epoch: 6| Step: 1
Training loss: 0.7780072241817931
Validation loss: 2.889754045573549

Epoch: 6| Step: 2
Training loss: 0.7679050904255413
Validation loss: 2.8984616013833278

Epoch: 6| Step: 3
Training loss: 0.38159837674394476
Validation loss: 2.9964113096193237

Epoch: 6| Step: 4
Training loss: 0.3964285223947345
Validation loss: 2.950744261310757

Epoch: 6| Step: 5
Training loss: 0.7492045316649746
Validation loss: 2.987909404416174

Epoch: 6| Step: 6
Training loss: 0.5777061078917978
Validation loss: 2.9385101394197113

Epoch: 6| Step: 7
Training loss: 0.7788668332701044
Validation loss: 2.8848900067601773

Epoch: 6| Step: 8
Training loss: 0.5195359824976096
Validation loss: 2.8134108587253106

Epoch: 6| Step: 9
Training loss: 0.652311861092537
Validation loss: 2.7480663668499967

Epoch: 6| Step: 10
Training loss: 0.46775484944087237
Validation loss: 2.8174876175399324

Epoch: 6| Step: 11
Training loss: 0.5825857043351963
Validation loss: 2.8135443267376576

Epoch: 6| Step: 12
Training loss: 0.7252126069579043
Validation loss: 2.8231611016970057

Epoch: 6| Step: 13
Training loss: 0.8719388001865451
Validation loss: 2.84200714137455

Epoch: 516| Step: 0
Training loss: 0.7807874454651744
Validation loss: 2.842831781282874

Epoch: 6| Step: 1
Training loss: 0.5003010320451131
Validation loss: 2.851623813196427

Epoch: 6| Step: 2
Training loss: 0.6160093966346392
Validation loss: 2.843353020203722

Epoch: 6| Step: 3
Training loss: 0.3794379681989772
Validation loss: 2.8655337242529773

Epoch: 6| Step: 4
Training loss: 0.44584164218052724
Validation loss: 2.9177921076583555

Epoch: 6| Step: 5
Training loss: 0.6348222677927753
Validation loss: 2.989029973795826

Epoch: 6| Step: 6
Training loss: 0.869299644753096
Validation loss: 2.9940027585506366

Epoch: 6| Step: 7
Training loss: 0.6453141514939427
Validation loss: 2.951381511803676

Epoch: 6| Step: 8
Training loss: 0.5338953017847434
Validation loss: 2.9440517408577063

Epoch: 6| Step: 9
Training loss: 0.6045085060492994
Validation loss: 2.820377831657787

Epoch: 6| Step: 10
Training loss: 0.6167022390888157
Validation loss: 2.7939988733051333

Epoch: 6| Step: 11
Training loss: 0.561692028444652
Validation loss: 2.783552952247158

Epoch: 6| Step: 12
Training loss: 0.566454865572567
Validation loss: 2.7255376804462172

Epoch: 6| Step: 13
Training loss: 0.7664742333671772
Validation loss: 2.7528205047928704

Epoch: 517| Step: 0
Training loss: 0.8755995195208852
Validation loss: 2.7338482885333257

Epoch: 6| Step: 1
Training loss: 0.5685722765074143
Validation loss: 2.7865178229615712

Epoch: 6| Step: 2
Training loss: 0.4255540924272598
Validation loss: 2.758243977308491

Epoch: 6| Step: 3
Training loss: 0.7106466012588806
Validation loss: 2.8638945473920208

Epoch: 6| Step: 4
Training loss: 0.3871797068552834
Validation loss: 2.8773251405421942

Epoch: 6| Step: 5
Training loss: 0.6531833567854297
Validation loss: 2.9256857299151746

Epoch: 6| Step: 6
Training loss: 0.505522450066473
Validation loss: 2.9648072144573785

Epoch: 6| Step: 7
Training loss: 0.6805032679740698
Validation loss: 2.937878584307685

Epoch: 6| Step: 8
Training loss: 0.5331988212216133
Validation loss: 2.9160927253234465

Epoch: 6| Step: 9
Training loss: 0.5260726019446945
Validation loss: 2.846582245944768

Epoch: 6| Step: 10
Training loss: 0.3139628266407672
Validation loss: 2.8106790228327188

Epoch: 6| Step: 11
Training loss: 0.431327550936391
Validation loss: 2.8257770381154677

Epoch: 6| Step: 12
Training loss: 0.697843744729018
Validation loss: 2.829660599410599

Epoch: 6| Step: 13
Training loss: 0.6495072147417978
Validation loss: 2.8070715474096515

Epoch: 518| Step: 0
Training loss: 0.5540624508586072
Validation loss: 2.8374152698834014

Epoch: 6| Step: 1
Training loss: 0.543744527855008
Validation loss: 2.874223783999645

Epoch: 6| Step: 2
Training loss: 0.6133058142146514
Validation loss: 2.8418201283905087

Epoch: 6| Step: 3
Training loss: 0.6687246585215734
Validation loss: 2.841279042749067

Epoch: 6| Step: 4
Training loss: 0.304925617680804
Validation loss: 2.8766689777438654

Epoch: 6| Step: 5
Training loss: 0.4744864096509197
Validation loss: 2.876434341551271

Epoch: 6| Step: 6
Training loss: 0.4796514926281548
Validation loss: 2.8637026502296092

Epoch: 6| Step: 7
Training loss: 0.6229507946204373
Validation loss: 2.8515707912934185

Epoch: 6| Step: 8
Training loss: 0.4480598760446347
Validation loss: 2.8512886508104147

Epoch: 6| Step: 9
Training loss: 0.7782049344840917
Validation loss: 2.880113822025594

Epoch: 6| Step: 10
Training loss: 0.7383920091975713
Validation loss: 2.8759877125340947

Epoch: 6| Step: 11
Training loss: 0.52021979116039
Validation loss: 2.8571854009185627

Epoch: 6| Step: 12
Training loss: 0.5785194031091684
Validation loss: 2.7852297680012144

Epoch: 6| Step: 13
Training loss: 0.44866801793458005
Validation loss: 2.73327796364349

Epoch: 519| Step: 0
Training loss: 0.5118731491465287
Validation loss: 2.761966044978485

Epoch: 6| Step: 1
Training loss: 0.6591641346544842
Validation loss: 2.81467554227019

Epoch: 6| Step: 2
Training loss: 0.7843763738977323
Validation loss: 2.7782486283407537

Epoch: 6| Step: 3
Training loss: 0.5293188336874365
Validation loss: 2.8366167220153997

Epoch: 6| Step: 4
Training loss: 0.33750906110891843
Validation loss: 2.8975619547169194

Epoch: 6| Step: 5
Training loss: 0.5159818397105976
Validation loss: 2.925581446074012

Epoch: 6| Step: 6
Training loss: 0.6607662520168979
Validation loss: 2.9517186094122514

Epoch: 6| Step: 7
Training loss: 0.7978359487025984
Validation loss: 3.0029291317326723

Epoch: 6| Step: 8
Training loss: 0.5591058317890435
Validation loss: 2.922529721811886

Epoch: 6| Step: 9
Training loss: 0.6399314196171352
Validation loss: 2.864937699102685

Epoch: 6| Step: 10
Training loss: 0.5948900020124088
Validation loss: 2.821207272655777

Epoch: 6| Step: 11
Training loss: 0.40134940374845013
Validation loss: 2.745504476123635

Epoch: 6| Step: 12
Training loss: 0.5753520758431858
Validation loss: 2.7488835047898967

Epoch: 6| Step: 13
Training loss: 0.6221442784960582
Validation loss: 2.734501158210852

Epoch: 520| Step: 0
Training loss: 0.6650018219456775
Validation loss: 2.8103011118606047

Epoch: 6| Step: 1
Training loss: 0.5075202687918563
Validation loss: 2.7764835876688707

Epoch: 6| Step: 2
Training loss: 0.8105352561761373
Validation loss: 2.7813906830485844

Epoch: 6| Step: 3
Training loss: 0.4005284886151509
Validation loss: 2.7338147415939518

Epoch: 6| Step: 4
Training loss: 0.4784431558345719
Validation loss: 2.7878011207275635

Epoch: 6| Step: 5
Training loss: 0.7173775547830915
Validation loss: 2.797537485439138

Epoch: 6| Step: 6
Training loss: 0.7785032050275642
Validation loss: 2.8252330768275153

Epoch: 6| Step: 7
Training loss: 0.3806210481347698
Validation loss: 2.844880253238851

Epoch: 6| Step: 8
Training loss: 0.4518361506507353
Validation loss: 2.789650820275929

Epoch: 6| Step: 9
Training loss: 0.49637025351405617
Validation loss: 2.863818039826092

Epoch: 6| Step: 10
Training loss: 0.6859821557040212
Validation loss: 2.6984359261147937

Epoch: 6| Step: 11
Training loss: 0.6869112875380445
Validation loss: 2.9085500222907568

Epoch: 6| Step: 12
Training loss: 0.4472749034468909
Validation loss: 2.9002604685477364

Epoch: 6| Step: 13
Training loss: 0.6284931792903482
Validation loss: 2.8997401269033762

Epoch: 521| Step: 0
Training loss: 0.6783073268079063
Validation loss: 2.943889351669358

Epoch: 6| Step: 1
Training loss: 0.6288127000309996
Validation loss: 3.004978155690379

Epoch: 6| Step: 2
Training loss: 0.45040112670936217
Validation loss: 2.928535173769912

Epoch: 6| Step: 3
Training loss: 0.43513767195925557
Validation loss: 2.954568674867701

Epoch: 6| Step: 4
Training loss: 0.6645924641291865
Validation loss: 2.8814202507289406

Epoch: 6| Step: 5
Training loss: 0.4212208020083658
Validation loss: 2.829748119966658

Epoch: 6| Step: 6
Training loss: 0.5233229041983921
Validation loss: 2.8496207118707617

Epoch: 6| Step: 7
Training loss: 0.9561106087809348
Validation loss: 2.8571439561387626

Epoch: 6| Step: 8
Training loss: 0.39101295279733994
Validation loss: 2.870093955696282

Epoch: 6| Step: 9
Training loss: 0.4746447420482611
Validation loss: 2.8262990322299846

Epoch: 6| Step: 10
Training loss: 0.5085669561732117
Validation loss: 2.825047386807255

Epoch: 6| Step: 11
Training loss: 0.4007893507586801
Validation loss: 2.7935825624861925

Epoch: 6| Step: 12
Training loss: 0.45733420609348274
Validation loss: 2.795094610670429

Epoch: 6| Step: 13
Training loss: 0.5714967007979834
Validation loss: 2.7864071469938416

Epoch: 522| Step: 0
Training loss: 0.7127495613056654
Validation loss: 2.7380235435545477

Epoch: 6| Step: 1
Training loss: 0.569026149529343
Validation loss: 2.764744419060878

Epoch: 6| Step: 2
Training loss: 0.837344865522373
Validation loss: 2.816338822699171

Epoch: 6| Step: 3
Training loss: 0.49524813393265826
Validation loss: 2.830689042458282

Epoch: 6| Step: 4
Training loss: 0.42496050903624116
Validation loss: 2.870008572356285

Epoch: 6| Step: 5
Training loss: 0.5164475671164847
Validation loss: 2.8647272085414

Epoch: 6| Step: 6
Training loss: 0.3455082511144326
Validation loss: 2.8597174545362796

Epoch: 6| Step: 7
Training loss: 0.38565696064520594
Validation loss: 2.9345970689989307

Epoch: 6| Step: 8
Training loss: 0.5458805306488362
Validation loss: 2.9710179282715004

Epoch: 6| Step: 9
Training loss: 0.5228083231064236
Validation loss: 2.8974628026339353

Epoch: 6| Step: 10
Training loss: 0.584005502171921
Validation loss: 2.946121482479185

Epoch: 6| Step: 11
Training loss: 0.5558465212249261
Validation loss: 2.961706848308451

Epoch: 6| Step: 12
Training loss: 0.556813236711798
Validation loss: 2.976297682148281

Epoch: 6| Step: 13
Training loss: 0.6556750685535403
Validation loss: 2.9571835652088403

Epoch: 523| Step: 0
Training loss: 0.47608655082184753
Validation loss: 2.827419424823027

Epoch: 6| Step: 1
Training loss: 0.38089648334970927
Validation loss: 2.768763383268987

Epoch: 6| Step: 2
Training loss: 0.6211053619258959
Validation loss: 2.8242102095675747

Epoch: 6| Step: 3
Training loss: 0.5285044576588633
Validation loss: 2.811915004785091

Epoch: 6| Step: 4
Training loss: 0.644872886973685
Validation loss: 2.8241479775973617

Epoch: 6| Step: 5
Training loss: 0.4799353577379358
Validation loss: 2.8434167044812977

Epoch: 6| Step: 6
Training loss: 0.44712170946650326
Validation loss: 2.8320766962723893

Epoch: 6| Step: 7
Training loss: 0.5621061535730365
Validation loss: 2.7816831844320156

Epoch: 6| Step: 8
Training loss: 0.6641995681221996
Validation loss: 2.854322294646971

Epoch: 6| Step: 9
Training loss: 0.5836030614638608
Validation loss: 2.7942972362701273

Epoch: 6| Step: 10
Training loss: 0.6150554336205499
Validation loss: 2.789073555832721

Epoch: 6| Step: 11
Training loss: 0.41521049997874876
Validation loss: 2.835935958707757

Epoch: 6| Step: 12
Training loss: 0.5384870581422098
Validation loss: 2.796942875214333

Epoch: 6| Step: 13
Training loss: 0.47215343559487255
Validation loss: 2.8911735082992425

Epoch: 524| Step: 0
Training loss: 0.38763507980482254
Validation loss: 2.8537059096457273

Epoch: 6| Step: 1
Training loss: 0.4209290424734857
Validation loss: 2.849290808619031

Epoch: 6| Step: 2
Training loss: 0.7400446424679115
Validation loss: 2.860324722742376

Epoch: 6| Step: 3
Training loss: 0.5051098429315757
Validation loss: 2.8972416250355972

Epoch: 6| Step: 4
Training loss: 0.4929148733741125
Validation loss: 2.9863067819129125

Epoch: 6| Step: 5
Training loss: 0.36568720687778833
Validation loss: 2.8771628937619083

Epoch: 6| Step: 6
Training loss: 0.5259523189947952
Validation loss: 2.941028113036138

Epoch: 6| Step: 7
Training loss: 0.3730307171103471
Validation loss: 2.8569931922041936

Epoch: 6| Step: 8
Training loss: 0.7640312110407512
Validation loss: 2.9236490232577306

Epoch: 6| Step: 9
Training loss: 0.5303648418520911
Validation loss: 2.837553966529971

Epoch: 6| Step: 10
Training loss: 0.45483837442946445
Validation loss: 2.827384472416955

Epoch: 6| Step: 11
Training loss: 0.47558125331067974
Validation loss: 2.8587612890129885

Epoch: 6| Step: 12
Training loss: 0.6552654783217492
Validation loss: 2.929632608535248

Epoch: 6| Step: 13
Training loss: 0.5190436864724136
Validation loss: 2.884911879764431

Epoch: 525| Step: 0
Training loss: 0.4316019412006336
Validation loss: 2.885255930769619

Epoch: 6| Step: 1
Training loss: 0.43466840344186375
Validation loss: 2.8796862818356095

Epoch: 6| Step: 2
Training loss: 0.4958754832787319
Validation loss: 2.885638291607395

Epoch: 6| Step: 3
Training loss: 0.5055149923925557
Validation loss: 2.885479486839714

Epoch: 6| Step: 4
Training loss: 0.6160361741919507
Validation loss: 2.7856590669583143

Epoch: 6| Step: 5
Training loss: 0.4558146986851453
Validation loss: 2.81853053330404

Epoch: 6| Step: 6
Training loss: 0.41142987100527456
Validation loss: 2.783141803623623

Epoch: 6| Step: 7
Training loss: 0.5909553814809593
Validation loss: 2.784414669714726

Epoch: 6| Step: 8
Training loss: 0.7397060471575699
Validation loss: 2.7495413744571446

Epoch: 6| Step: 9
Training loss: 0.48812969144454466
Validation loss: 2.7784699250550515

Epoch: 6| Step: 10
Training loss: 0.6253056732369376
Validation loss: 2.8488207173047386

Epoch: 6| Step: 11
Training loss: 0.580756128366677
Validation loss: 2.8434644981964268

Epoch: 6| Step: 12
Training loss: 0.40467938006292964
Validation loss: 2.857093776553801

Epoch: 6| Step: 13
Training loss: 0.3823346054985269
Validation loss: 2.846742013169381

Epoch: 526| Step: 0
Training loss: 0.6879916167330652
Validation loss: 2.914657572922593

Epoch: 6| Step: 1
Training loss: 0.6401203773210945
Validation loss: 2.931704153464979

Epoch: 6| Step: 2
Training loss: 0.4705745790582738
Validation loss: 2.903563142748021

Epoch: 6| Step: 3
Training loss: 0.5914733304438783
Validation loss: 2.909519598700439

Epoch: 6| Step: 4
Training loss: 0.4371183979102003
Validation loss: 2.908508462378673

Epoch: 6| Step: 5
Training loss: 0.5336513102861772
Validation loss: 2.870100947409077

Epoch: 6| Step: 6
Training loss: 0.3514136741128723
Validation loss: 2.8759539168825823

Epoch: 6| Step: 7
Training loss: 0.28413369766865676
Validation loss: 2.788141349602593

Epoch: 6| Step: 8
Training loss: 0.5807737552876616
Validation loss: 2.7943060956556756

Epoch: 6| Step: 9
Training loss: 0.3495639366585537
Validation loss: 2.8279022634902056

Epoch: 6| Step: 10
Training loss: 0.6195025183616479
Validation loss: 2.859372845980696

Epoch: 6| Step: 11
Training loss: 0.49459822202745474
Validation loss: 2.789030685742009

Epoch: 6| Step: 12
Training loss: 0.4623785768098823
Validation loss: 2.8231945299920156

Epoch: 6| Step: 13
Training loss: 0.44924158784614593
Validation loss: 2.7344546351870895

Epoch: 527| Step: 0
Training loss: 0.49416468867034197
Validation loss: 2.846587571430736

Epoch: 6| Step: 1
Training loss: 0.6248042038357894
Validation loss: 2.8562381262779373

Epoch: 6| Step: 2
Training loss: 0.2953184127215697
Validation loss: 2.860121985526079

Epoch: 6| Step: 3
Training loss: 0.5053988389217353
Validation loss: 2.8608587198958038

Epoch: 6| Step: 4
Training loss: 0.5906664435161632
Validation loss: 2.8745087881209934

Epoch: 6| Step: 5
Training loss: 0.4977824387989676
Validation loss: 2.876191016914139

Epoch: 6| Step: 6
Training loss: 0.4677541963765202
Validation loss: 2.8288000716698467

Epoch: 6| Step: 7
Training loss: 0.6435417671816883
Validation loss: 2.83856119038345

Epoch: 6| Step: 8
Training loss: 0.48501598339191077
Validation loss: 2.7735781495155187

Epoch: 6| Step: 9
Training loss: 0.502463263359698
Validation loss: 2.8428193410462828

Epoch: 6| Step: 10
Training loss: 0.41966706462653885
Validation loss: 2.832394252620139

Epoch: 6| Step: 11
Training loss: 0.4142456369440762
Validation loss: 2.8312244607813524

Epoch: 6| Step: 12
Training loss: 0.4779770759438474
Validation loss: 2.825690104721669

Epoch: 6| Step: 13
Training loss: 0.48512520683105276
Validation loss: 2.8451682665719855

Epoch: 528| Step: 0
Training loss: 0.40971263328294266
Validation loss: 2.8408973205206975

Epoch: 6| Step: 1
Training loss: 0.4824089326551025
Validation loss: 2.9093884575324624

Epoch: 6| Step: 2
Training loss: 0.6265909450095903
Validation loss: 2.87261746687892

Epoch: 6| Step: 3
Training loss: 0.39857259965662056
Validation loss: 2.9163788562642505

Epoch: 6| Step: 4
Training loss: 0.5904977974329738
Validation loss: 2.893448037087376

Epoch: 6| Step: 5
Training loss: 0.5374563310316111
Validation loss: 2.8903537932316916

Epoch: 6| Step: 6
Training loss: 0.4399247923157962
Validation loss: 2.8380012534400656

Epoch: 6| Step: 7
Training loss: 0.3778045604871803
Validation loss: 2.8254201258747087

Epoch: 6| Step: 8
Training loss: 0.5147039104872686
Validation loss: 2.817099074648999

Epoch: 6| Step: 9
Training loss: 0.5414733327725716
Validation loss: 2.8368346841707806

Epoch: 6| Step: 10
Training loss: 0.4671801027458702
Validation loss: 2.7899766807538717

Epoch: 6| Step: 11
Training loss: 0.4751688481435449
Validation loss: 2.778675487947587

Epoch: 6| Step: 12
Training loss: 0.47570951137055495
Validation loss: 2.794943975809519

Epoch: 6| Step: 13
Training loss: 0.40830017834308435
Validation loss: 2.7509367387764705

Epoch: 529| Step: 0
Training loss: 0.45986506602908395
Validation loss: 2.787363883260358

Epoch: 6| Step: 1
Training loss: 0.567234118308634
Validation loss: 2.8499574437784445

Epoch: 6| Step: 2
Training loss: 0.5162762084293617
Validation loss: 2.82084767625807

Epoch: 6| Step: 3
Training loss: 0.6763810599455171
Validation loss: 2.9062685812079265

Epoch: 6| Step: 4
Training loss: 0.41419671240698674
Validation loss: 2.9069094166166916

Epoch: 6| Step: 5
Training loss: 0.4344860037984624
Validation loss: 2.918333154246617

Epoch: 6| Step: 6
Training loss: 0.5133385682871204
Validation loss: 2.9536196447476155

Epoch: 6| Step: 7
Training loss: 0.5564641036840459
Validation loss: 2.9507600575653035

Epoch: 6| Step: 8
Training loss: 0.37542593132015806
Validation loss: 2.9093928554053927

Epoch: 6| Step: 9
Training loss: 0.42140063354574014
Validation loss: 2.8999550848804074

Epoch: 6| Step: 10
Training loss: 0.54623233635668
Validation loss: 2.890438905516467

Epoch: 6| Step: 11
Training loss: 0.5293661825263153
Validation loss: 2.842818753977593

Epoch: 6| Step: 12
Training loss: 0.6068439248611872
Validation loss: 2.853030296444718

Epoch: 6| Step: 13
Training loss: 0.31022934905001076
Validation loss: 2.8006245149377755

Epoch: 530| Step: 0
Training loss: 0.5271939948043131
Validation loss: 2.8763198587200196

Epoch: 6| Step: 1
Training loss: 0.5467550691161187
Validation loss: 2.803093190546055

Epoch: 6| Step: 2
Training loss: 0.41792093876981157
Validation loss: 2.824419449762232

Epoch: 6| Step: 3
Training loss: 0.41897312596612907
Validation loss: 2.809524191012753

Epoch: 6| Step: 4
Training loss: 0.5308682809381606
Validation loss: 2.877865910888638

Epoch: 6| Step: 5
Training loss: 0.6009157345262485
Validation loss: 2.9236591624109023

Epoch: 6| Step: 6
Training loss: 0.40972836291386483
Validation loss: 2.842761751826005

Epoch: 6| Step: 7
Training loss: 0.4617545919174521
Validation loss: 2.9211484308286453

Epoch: 6| Step: 8
Training loss: 0.4581863608387107
Validation loss: 2.909099180352489

Epoch: 6| Step: 9
Training loss: 0.6123064883751677
Validation loss: 2.8176191436885882

Epoch: 6| Step: 10
Training loss: 0.29496339164706137
Validation loss: 2.888658297844086

Epoch: 6| Step: 11
Training loss: 0.5269062063765673
Validation loss: 2.844828306893603

Epoch: 6| Step: 12
Training loss: 0.5806271815592636
Validation loss: 2.89555381322369

Epoch: 6| Step: 13
Training loss: 0.4402231209914958
Validation loss: 2.861237716548446

Epoch: 531| Step: 0
Training loss: 0.44272278780808055
Validation loss: 2.855747096267306

Epoch: 6| Step: 1
Training loss: 0.2953509310788884
Validation loss: 2.8346150785507116

Epoch: 6| Step: 2
Training loss: 0.5126918247649226
Validation loss: 2.847347694568267

Epoch: 6| Step: 3
Training loss: 0.4212309194595926
Validation loss: 2.9249555970215217

Epoch: 6| Step: 4
Training loss: 0.33838135028963817
Validation loss: 2.8853689159936278

Epoch: 6| Step: 5
Training loss: 0.440213304639922
Validation loss: 2.927614433100006

Epoch: 6| Step: 6
Training loss: 0.5531471786793958
Validation loss: 2.952420778086496

Epoch: 6| Step: 7
Training loss: 0.6176554197792671
Validation loss: 2.9045342333630204

Epoch: 6| Step: 8
Training loss: 0.5671248514344641
Validation loss: 2.8986416425215538

Epoch: 6| Step: 9
Training loss: 0.4135709399889402
Validation loss: 2.833630571949104

Epoch: 6| Step: 10
Training loss: 0.3350461289864904
Validation loss: 2.8524827839507094

Epoch: 6| Step: 11
Training loss: 0.46522403836878384
Validation loss: 2.773324410725264

Epoch: 6| Step: 12
Training loss: 0.6198042432860736
Validation loss: 2.7775136588945637

Epoch: 6| Step: 13
Training loss: 0.5450581205944679
Validation loss: 2.8125047471748132

Epoch: 532| Step: 0
Training loss: 0.663226937091096
Validation loss: 2.794721303407859

Epoch: 6| Step: 1
Training loss: 0.6151699698509443
Validation loss: 2.8331035679796828

Epoch: 6| Step: 2
Training loss: 0.3699276723276506
Validation loss: 2.848018586558867

Epoch: 6| Step: 3
Training loss: 0.3109901671158429
Validation loss: 2.8983344019455903

Epoch: 6| Step: 4
Training loss: 0.5595547073078989
Validation loss: 2.901226501238195

Epoch: 6| Step: 5
Training loss: 0.3758344902026408
Validation loss: 2.8996620573252834

Epoch: 6| Step: 6
Training loss: 0.39123278065043554
Validation loss: 2.879815505396707

Epoch: 6| Step: 7
Training loss: 0.6619722342459556
Validation loss: 2.9315701958458007

Epoch: 6| Step: 8
Training loss: 0.5801743450060335
Validation loss: 2.84331313470044

Epoch: 6| Step: 9
Training loss: 0.4408108569522527
Validation loss: 2.866541846093596

Epoch: 6| Step: 10
Training loss: 0.4396012289764626
Validation loss: 2.849058903808377

Epoch: 6| Step: 11
Training loss: 0.4653937507999578
Validation loss: 2.8233662677752074

Epoch: 6| Step: 12
Training loss: 0.6868272437449203
Validation loss: 2.79165127498502

Epoch: 6| Step: 13
Training loss: 0.3368718659886813
Validation loss: 2.760495704143148

Epoch: 533| Step: 0
Training loss: 0.529866323977329
Validation loss: 2.8328252131041287

Epoch: 6| Step: 1
Training loss: 0.4385137733353776
Validation loss: 2.833369806466305

Epoch: 6| Step: 2
Training loss: 0.45830124684929335
Validation loss: 2.7920801985661914

Epoch: 6| Step: 3
Training loss: 0.2934447681067203
Validation loss: 2.850575440855653

Epoch: 6| Step: 4
Training loss: 0.5719931412699112
Validation loss: 2.8101087648015417

Epoch: 6| Step: 5
Training loss: 0.3268425949474554
Validation loss: 2.8487208730612674

Epoch: 6| Step: 6
Training loss: 0.6072424964127092
Validation loss: 2.8598216390679845

Epoch: 6| Step: 7
Training loss: 0.4074607559919022
Validation loss: 2.875093513847634

Epoch: 6| Step: 8
Training loss: 0.4785102999643919
Validation loss: 2.871013821897117

Epoch: 6| Step: 9
Training loss: 0.35114167776320443
Validation loss: 2.90887933832318

Epoch: 6| Step: 10
Training loss: 0.6436182896584136
Validation loss: 2.8625177091358887

Epoch: 6| Step: 11
Training loss: 0.39318906398517317
Validation loss: 2.8364014469363066

Epoch: 6| Step: 12
Training loss: 0.36599912494283826
Validation loss: 2.874318878373568

Epoch: 6| Step: 13
Training loss: 0.4848730234202698
Validation loss: 2.8310547155718204

Epoch: 534| Step: 0
Training loss: 0.44243059047687594
Validation loss: 2.8777589966330104

Epoch: 6| Step: 1
Training loss: 0.46702557312420895
Validation loss: 2.8978803635569133

Epoch: 6| Step: 2
Training loss: 0.5767757031914504
Validation loss: 2.8590159234164676

Epoch: 6| Step: 3
Training loss: 0.3773638015063508
Validation loss: 2.852353199762304

Epoch: 6| Step: 4
Training loss: 0.5923689290025583
Validation loss: 2.857049284549407

Epoch: 6| Step: 5
Training loss: 0.4973679047045129
Validation loss: 2.8745161838063744

Epoch: 6| Step: 6
Training loss: 0.3548624086366652
Validation loss: 2.824621921884768

Epoch: 6| Step: 7
Training loss: 0.5781775785713857
Validation loss: 2.8862879960400876

Epoch: 6| Step: 8
Training loss: 0.3587402044680214
Validation loss: 2.819587987827634

Epoch: 6| Step: 9
Training loss: 0.4115444668618602
Validation loss: 2.8392039561717675

Epoch: 6| Step: 10
Training loss: 0.5058938386584524
Validation loss: 2.8851168002721423

Epoch: 6| Step: 11
Training loss: 0.4581444705192739
Validation loss: 2.9859618250669313

Epoch: 6| Step: 12
Training loss: 0.4370060925680958
Validation loss: 2.8101903120600813

Epoch: 6| Step: 13
Training loss: 0.5917566871216876
Validation loss: 2.925807421388531

Epoch: 535| Step: 0
Training loss: 0.7821393863329734
Validation loss: 2.9010043504233725

Epoch: 6| Step: 1
Training loss: 0.3900951606855163
Validation loss: 2.896462218975197

Epoch: 6| Step: 2
Training loss: 0.4041992843712668
Validation loss: 2.9381448565479342

Epoch: 6| Step: 3
Training loss: 0.3626989394228953
Validation loss: 2.916978742161744

Epoch: 6| Step: 4
Training loss: 0.2881293054039731
Validation loss: 2.8719082254474038

Epoch: 6| Step: 5
Training loss: 0.382267973405558
Validation loss: 2.8356840582640457

Epoch: 6| Step: 6
Training loss: 0.3509565960146171
Validation loss: 2.8863127977476477

Epoch: 6| Step: 7
Training loss: 0.5389968445089259
Validation loss: 2.9205879191765716

Epoch: 6| Step: 8
Training loss: 0.47300919840278316
Validation loss: 2.9006600029007505

Epoch: 6| Step: 9
Training loss: 0.3835132957352017
Validation loss: 2.8901300779853805

Epoch: 6| Step: 10
Training loss: 0.4722976269855609
Validation loss: 2.7916443145388516

Epoch: 6| Step: 11
Training loss: 0.560022753738606
Validation loss: 2.8228403669980904

Epoch: 6| Step: 12
Training loss: 0.5700829971688695
Validation loss: 2.873228079939889

Epoch: 6| Step: 13
Training loss: 0.4015249420295181
Validation loss: 2.8743434100963343

Epoch: 536| Step: 0
Training loss: 0.42825035431909014
Validation loss: 2.892799439378947

Epoch: 6| Step: 1
Training loss: 0.28160462275003867
Validation loss: 2.916927616616678

Epoch: 6| Step: 2
Training loss: 0.5876801579791749
Validation loss: 2.88182289691949

Epoch: 6| Step: 3
Training loss: 0.31914361651172973
Validation loss: 2.9501601983878323

Epoch: 6| Step: 4
Training loss: 0.4755826162735354
Validation loss: 2.7983289807278027

Epoch: 6| Step: 5
Training loss: 0.34804237011735223
Validation loss: 2.897644044040106

Epoch: 6| Step: 6
Training loss: 0.5348790418396834
Validation loss: 2.883387920840473

Epoch: 6| Step: 7
Training loss: 0.44870971366029333
Validation loss: 2.9206039465612013

Epoch: 6| Step: 8
Training loss: 0.49016304561049673
Validation loss: 2.8220580978387946

Epoch: 6| Step: 9
Training loss: 0.4234394805411441
Validation loss: 2.8693558811488886

Epoch: 6| Step: 10
Training loss: 0.49145068163357314
Validation loss: 2.839247748140239

Epoch: 6| Step: 11
Training loss: 0.6350288666899647
Validation loss: 2.9315258175613477

Epoch: 6| Step: 12
Training loss: 0.3952044041421024
Validation loss: 2.8569427457054464

Epoch: 6| Step: 13
Training loss: 0.4337525807119764
Validation loss: 2.7897000621468515

Epoch: 537| Step: 0
Training loss: 0.4064211668205097
Validation loss: 2.8395268868209373

Epoch: 6| Step: 1
Training loss: 0.427641784540397
Validation loss: 2.811998039945821

Epoch: 6| Step: 2
Training loss: 0.514208437254896
Validation loss: 2.879730479291737

Epoch: 6| Step: 3
Training loss: 0.4268483430350134
Validation loss: 2.8576116631406916

Epoch: 6| Step: 4
Training loss: 0.26414929718430974
Validation loss: 2.8257344436179053

Epoch: 6| Step: 5
Training loss: 0.5527030477643724
Validation loss: 2.8566311593744165

Epoch: 6| Step: 6
Training loss: 0.38823025021181345
Validation loss: 2.8429183512419964

Epoch: 6| Step: 7
Training loss: 0.5515485788809269
Validation loss: 2.872637870231109

Epoch: 6| Step: 8
Training loss: 0.3672937280110579
Validation loss: 2.825647944859475

Epoch: 6| Step: 9
Training loss: 0.5025237880598993
Validation loss: 2.8615940981554076

Epoch: 6| Step: 10
Training loss: 0.4695306317774405
Validation loss: 2.8508118220542373

Epoch: 6| Step: 11
Training loss: 0.40128854691212285
Validation loss: 2.8814993385668535

Epoch: 6| Step: 12
Training loss: 0.6823654911394075
Validation loss: 2.829386673820293

Epoch: 6| Step: 13
Training loss: 0.4978109661205581
Validation loss: 2.8089372604323954

Epoch: 538| Step: 0
Training loss: 0.4155848247069642
Validation loss: 2.7928245809554917

Epoch: 6| Step: 1
Training loss: 0.39584313765313045
Validation loss: 2.9085917182264285

Epoch: 6| Step: 2
Training loss: 0.32408309304589833
Validation loss: 2.8593797110430152

Epoch: 6| Step: 3
Training loss: 0.5828967220210954
Validation loss: 2.8823604487759837

Epoch: 6| Step: 4
Training loss: 0.5103780349073164
Validation loss: 2.8905335420453806

Epoch: 6| Step: 5
Training loss: 0.4457031845106107
Validation loss: 2.8397678818116043

Epoch: 6| Step: 6
Training loss: 0.3944763674190549
Validation loss: 2.8879302239658213

Epoch: 6| Step: 7
Training loss: 0.4492127293722309
Validation loss: 2.8316231128770144

Epoch: 6| Step: 8
Training loss: 0.6589331045596643
Validation loss: 2.820998829523254

Epoch: 6| Step: 9
Training loss: 0.48034027366777465
Validation loss: 2.853252366542322

Epoch: 6| Step: 10
Training loss: 0.4632318582950548
Validation loss: 2.839472113651785

Epoch: 6| Step: 11
Training loss: 0.33119806206385005
Validation loss: 2.849010185778713

Epoch: 6| Step: 12
Training loss: 0.552528585669717
Validation loss: 2.9275022774808837

Epoch: 6| Step: 13
Training loss: 0.48816665830652334
Validation loss: 2.954774076557409

Epoch: 539| Step: 0
Training loss: 0.4657028817961873
Validation loss: 2.955280465953492

Epoch: 6| Step: 1
Training loss: 0.5682231044941254
Validation loss: 3.0434419641887325

Epoch: 6| Step: 2
Training loss: 0.37409609893094525
Validation loss: 3.010943308417025

Epoch: 6| Step: 3
Training loss: 0.6049379052067111
Validation loss: 2.938191082331702

Epoch: 6| Step: 4
Training loss: 0.3956612748424372
Validation loss: 2.879973587670012

Epoch: 6| Step: 5
Training loss: 0.3531017515243307
Validation loss: 2.913660330203372

Epoch: 6| Step: 6
Training loss: 0.6398474929569675
Validation loss: 2.7941551409706555

Epoch: 6| Step: 7
Training loss: 0.44985735738511895
Validation loss: 2.805357857359759

Epoch: 6| Step: 8
Training loss: 0.4462991792629832
Validation loss: 2.8210690682056097

Epoch: 6| Step: 9
Training loss: 0.5449126594885376
Validation loss: 2.835809639954961

Epoch: 6| Step: 10
Training loss: 0.4789645522008266
Validation loss: 2.788824404287189

Epoch: 6| Step: 11
Training loss: 0.6200335108253071
Validation loss: 2.8438385890254922

Epoch: 6| Step: 12
Training loss: 0.22283698158807294
Validation loss: 2.8510183572890657

Epoch: 6| Step: 13
Training loss: 0.4199043802564799
Validation loss: 2.8771835272871957

Epoch: 540| Step: 0
Training loss: 0.4433960416310858
Validation loss: 2.8296566323096317

Epoch: 6| Step: 1
Training loss: 0.40266612942661884
Validation loss: 2.877039793892654

Epoch: 6| Step: 2
Training loss: 0.6162450330584381
Validation loss: 2.8839373784561353

Epoch: 6| Step: 3
Training loss: 0.5240575619341519
Validation loss: 2.833956107715676

Epoch: 6| Step: 4
Training loss: 0.4001170828946785
Validation loss: 2.8952415785635583

Epoch: 6| Step: 5
Training loss: 0.5237384329636097
Validation loss: 2.828546257329065

Epoch: 6| Step: 6
Training loss: 0.6050117737042185
Validation loss: 2.840241667982488

Epoch: 6| Step: 7
Training loss: 0.49576671964967034
Validation loss: 2.816805532143514

Epoch: 6| Step: 8
Training loss: 0.520906106315262
Validation loss: 2.8402533080630707

Epoch: 6| Step: 9
Training loss: 0.32814652508568753
Validation loss: 2.796679285685548

Epoch: 6| Step: 10
Training loss: 0.3745508285453207
Validation loss: 2.812989171191384

Epoch: 6| Step: 11
Training loss: 0.4745646797139161
Validation loss: 2.8579709856746427

Epoch: 6| Step: 12
Training loss: 0.37923759052138856
Validation loss: 2.823581607858569

Epoch: 6| Step: 13
Training loss: 0.43805740814580557
Validation loss: 2.8379049071066116

Epoch: 541| Step: 0
Training loss: 0.4821704719093102
Validation loss: 2.8364130747576106

Epoch: 6| Step: 1
Training loss: 0.4252282847848445
Validation loss: 2.769794761844401

Epoch: 6| Step: 2
Training loss: 0.28586558078515445
Validation loss: 2.797389887011102

Epoch: 6| Step: 3
Training loss: 0.39417995260454847
Validation loss: 2.8558309858446256

Epoch: 6| Step: 4
Training loss: 0.37934101370423157
Validation loss: 2.783085335363836

Epoch: 6| Step: 5
Training loss: 0.6219241271430447
Validation loss: 2.8218714525687

Epoch: 6| Step: 6
Training loss: 0.318108863796054
Validation loss: 2.8405169179321135

Epoch: 6| Step: 7
Training loss: 0.3857011217880848
Validation loss: 2.848594061084768

Epoch: 6| Step: 8
Training loss: 0.47301556194565714
Validation loss: 2.8601526616885082

Epoch: 6| Step: 9
Training loss: 0.6683209031947633
Validation loss: 2.800933606744702

Epoch: 6| Step: 10
Training loss: 0.48098835334833984
Validation loss: 2.813246253580824

Epoch: 6| Step: 11
Training loss: 0.5683265493030932
Validation loss: 2.778987950455719

Epoch: 6| Step: 12
Training loss: 0.4116442256414537
Validation loss: 2.8200249494526606

Epoch: 6| Step: 13
Training loss: 0.48688646613980807
Validation loss: 2.799543248115894

Epoch: 542| Step: 0
Training loss: 0.44811468035362145
Validation loss: 2.8526092907214893

Epoch: 6| Step: 1
Training loss: 0.6001646471615478
Validation loss: 2.8442884221930482

Epoch: 6| Step: 2
Training loss: 0.4141291078938905
Validation loss: 2.7867276260638154

Epoch: 6| Step: 3
Training loss: 0.4957223237680831
Validation loss: 2.8371874924257874

Epoch: 6| Step: 4
Training loss: 0.4261369182120674
Validation loss: 2.8428269309948573

Epoch: 6| Step: 5
Training loss: 0.5991975444836336
Validation loss: 2.8276621894741023

Epoch: 6| Step: 6
Training loss: 0.3955702744128456
Validation loss: 2.8364161988508734

Epoch: 6| Step: 7
Training loss: 0.4277689323226375
Validation loss: 2.8330737069799135

Epoch: 6| Step: 8
Training loss: 0.5831083789267916
Validation loss: 2.850342148883588

Epoch: 6| Step: 9
Training loss: 0.5448415006476821
Validation loss: 2.918273555797691

Epoch: 6| Step: 10
Training loss: 0.49387121583767657
Validation loss: 2.9012658371028115

Epoch: 6| Step: 11
Training loss: 0.3128968103680866
Validation loss: 2.8314780771488075

Epoch: 6| Step: 12
Training loss: 0.2540834542110811
Validation loss: 2.792814550166754

Epoch: 6| Step: 13
Training loss: 0.46231840473512886
Validation loss: 2.875260686803837

Epoch: 543| Step: 0
Training loss: 0.6191313348789165
Validation loss: 2.856860794324711

Epoch: 6| Step: 1
Training loss: 0.6386989622758971
Validation loss: 2.867532735303489

Epoch: 6| Step: 2
Training loss: 0.346963352687401
Validation loss: 2.926176131949865

Epoch: 6| Step: 3
Training loss: 0.41663525780869337
Validation loss: 2.8418579794135836

Epoch: 6| Step: 4
Training loss: 0.4122901267006392
Validation loss: 2.903097555402414

Epoch: 6| Step: 5
Training loss: 0.6366656696684588
Validation loss: 2.8976670755331724

Epoch: 6| Step: 6
Training loss: 0.37046455448498816
Validation loss: 2.902351211668326

Epoch: 6| Step: 7
Training loss: 0.3545432145986069
Validation loss: 2.9279487570393834

Epoch: 6| Step: 8
Training loss: 0.3725083943515649
Validation loss: 2.920633130325156

Epoch: 6| Step: 9
Training loss: 0.3274580671677675
Validation loss: 2.9212465477377423

Epoch: 6| Step: 10
Training loss: 0.35497694262992513
Validation loss: 2.9316705934745104

Epoch: 6| Step: 11
Training loss: 0.29896871214250653
Validation loss: 2.9266433837706

Epoch: 6| Step: 12
Training loss: 0.3328590284427296
Validation loss: 2.8297932237674526

Epoch: 6| Step: 13
Training loss: 0.474634758541282
Validation loss: 2.794783764085226

Epoch: 544| Step: 0
Training loss: 0.4068967183201311
Validation loss: 2.8307730569861462

Epoch: 6| Step: 1
Training loss: 0.3208662340811747
Validation loss: 2.7988361607871237

Epoch: 6| Step: 2
Training loss: 0.5134183018462329
Validation loss: 2.8220896664934236

Epoch: 6| Step: 3
Training loss: 0.4405196577994423
Validation loss: 2.7778761327073167

Epoch: 6| Step: 4
Training loss: 0.5108125247990322
Validation loss: 2.8393940663577477

Epoch: 6| Step: 5
Training loss: 0.4362471899034995
Validation loss: 2.8532034694302744

Epoch: 6| Step: 6
Training loss: 0.41912276060175646
Validation loss: 2.84492520093778

Epoch: 6| Step: 7
Training loss: 0.44673581790240746
Validation loss: 2.8315121510383214

Epoch: 6| Step: 8
Training loss: 0.45616504714384715
Validation loss: 2.90919949295492

Epoch: 6| Step: 9
Training loss: 0.4051573621600003
Validation loss: 2.839960682668438

Epoch: 6| Step: 10
Training loss: 0.5053537559299498
Validation loss: 2.8821614399506346

Epoch: 6| Step: 11
Training loss: 0.3647087925805242
Validation loss: 2.8550544017189408

Epoch: 6| Step: 12
Training loss: 0.40627950781249217
Validation loss: 2.8164525550707578

Epoch: 6| Step: 13
Training loss: 0.6465832960159338
Validation loss: 2.821249653809582

Epoch: 545| Step: 0
Training loss: 0.4681967649468659
Validation loss: 2.8540535693257074

Epoch: 6| Step: 1
Training loss: 0.5128771359601171
Validation loss: 2.906011933998165

Epoch: 6| Step: 2
Training loss: 0.6308995992869364
Validation loss: 2.8433161813353536

Epoch: 6| Step: 3
Training loss: 0.4054689969629848
Validation loss: 2.890025281124569

Epoch: 6| Step: 4
Training loss: 0.5746701600620596
Validation loss: 2.9267940423534924

Epoch: 6| Step: 5
Training loss: 0.43450911873290626
Validation loss: 2.875193216216714

Epoch: 6| Step: 6
Training loss: 0.35422554181238086
Validation loss: 2.8543831170049305

Epoch: 6| Step: 7
Training loss: 0.45513735537166683
Validation loss: 2.8096229248636613

Epoch: 6| Step: 8
Training loss: 0.5448878834831875
Validation loss: 2.8258058231386727

Epoch: 6| Step: 9
Training loss: 0.4702249844765811
Validation loss: 2.8233312370430625

Epoch: 6| Step: 10
Training loss: 0.34622588207929383
Validation loss: 2.8608003965089868

Epoch: 6| Step: 11
Training loss: 0.43767937320963296
Validation loss: 2.843940742439577

Epoch: 6| Step: 12
Training loss: 0.6003432364987568
Validation loss: 2.8180206229188753

Epoch: 6| Step: 13
Training loss: 0.3923168926397234
Validation loss: 2.8825175230051108

Epoch: 546| Step: 0
Training loss: 0.45289132242377733
Validation loss: 2.8188588208086975

Epoch: 6| Step: 1
Training loss: 0.6251567167257956
Validation loss: 2.85193941595209

Epoch: 6| Step: 2
Training loss: 0.35993453708812917
Validation loss: 2.8924814122646016

Epoch: 6| Step: 3
Training loss: 0.45291201749074805
Validation loss: 2.887592986840379

Epoch: 6| Step: 4
Training loss: 0.4532725488563308
Validation loss: 2.917450967424064

Epoch: 6| Step: 5
Training loss: 0.356275293221961
Validation loss: 2.8794395335877243

Epoch: 6| Step: 6
Training loss: 0.3973801739341758
Validation loss: 2.9132145115723613

Epoch: 6| Step: 7
Training loss: 0.4910262501977415
Validation loss: 2.896929489989479

Epoch: 6| Step: 8
Training loss: 0.39933072738733866
Validation loss: 2.790958376369179

Epoch: 6| Step: 9
Training loss: 0.5700101181437259
Validation loss: 2.7880069362940856

Epoch: 6| Step: 10
Training loss: 0.5260311887345941
Validation loss: 2.802625374441126

Epoch: 6| Step: 11
Training loss: 0.6279414103171627
Validation loss: 2.7572296866750317

Epoch: 6| Step: 12
Training loss: 0.44983925465030034
Validation loss: 2.756009976178418

Epoch: 6| Step: 13
Training loss: 0.5495174328344394
Validation loss: 2.774414248691952

Epoch: 547| Step: 0
Training loss: 0.5431969252394002
Validation loss: 2.7631934157297677

Epoch: 6| Step: 1
Training loss: 0.45993940946895634
Validation loss: 2.855040483761132

Epoch: 6| Step: 2
Training loss: 0.5481045116914672
Validation loss: 2.9322630687197657

Epoch: 6| Step: 3
Training loss: 0.5008575119533707
Validation loss: 2.9440884664864497

Epoch: 6| Step: 4
Training loss: 0.20213675350018104
Validation loss: 2.901405631244766

Epoch: 6| Step: 5
Training loss: 0.4518783124957942
Validation loss: 2.948365562597773

Epoch: 6| Step: 6
Training loss: 0.5105712196015514
Validation loss: 2.8962237737524927

Epoch: 6| Step: 7
Training loss: 0.2946227874980291
Validation loss: 2.9093453252462464

Epoch: 6| Step: 8
Training loss: 0.4627809354332952
Validation loss: 2.910038355545062

Epoch: 6| Step: 9
Training loss: 0.5740710736809307
Validation loss: 2.8937106872041336

Epoch: 6| Step: 10
Training loss: 0.3804577788664798
Validation loss: 2.8817162914941648

Epoch: 6| Step: 11
Training loss: 0.7141075721055068
Validation loss: 2.87255271467063

Epoch: 6| Step: 12
Training loss: 0.5244292358249194
Validation loss: 2.865889363659514

Epoch: 6| Step: 13
Training loss: 0.5221553586225888
Validation loss: 2.8844238023634863

Epoch: 548| Step: 0
Training loss: 0.5557075309176531
Validation loss: 2.9004031128619876

Epoch: 6| Step: 1
Training loss: 0.6805863849205127
Validation loss: 2.8869513184394124

Epoch: 6| Step: 2
Training loss: 0.3468494805408133
Validation loss: 2.840474936169406

Epoch: 6| Step: 3
Training loss: 0.4498345839271155
Validation loss: 2.8666697839416884

Epoch: 6| Step: 4
Training loss: 0.5091386351956979
Validation loss: 2.8108845910575537

Epoch: 6| Step: 5
Training loss: 0.37829686349682284
Validation loss: 2.803922869517115

Epoch: 6| Step: 6
Training loss: 0.5725252779748118
Validation loss: 2.7842986581985167

Epoch: 6| Step: 7
Training loss: 0.5593561957837537
Validation loss: 2.8046211227737254

Epoch: 6| Step: 8
Training loss: 0.4648839147830502
Validation loss: 2.80170444257308

Epoch: 6| Step: 9
Training loss: 0.49787594723162426
Validation loss: 2.8148904461092634

Epoch: 6| Step: 10
Training loss: 0.48532393010343355
Validation loss: 2.82176228999074

Epoch: 6| Step: 11
Training loss: 0.3121792577776229
Validation loss: 2.8397317240717124

Epoch: 6| Step: 12
Training loss: 0.35532361515612426
Validation loss: 2.8839199072218262

Epoch: 6| Step: 13
Training loss: 0.3680897442915248
Validation loss: 2.889737090787444

Epoch: 549| Step: 0
Training loss: 0.636452999706573
Validation loss: 2.9103015974303377

Epoch: 6| Step: 1
Training loss: 0.4964042953150144
Validation loss: 2.9485390795750237

Epoch: 6| Step: 2
Training loss: 0.34456683773048397
Validation loss: 2.837911488053115

Epoch: 6| Step: 3
Training loss: 0.5148885264628402
Validation loss: 2.876060055447467

Epoch: 6| Step: 4
Training loss: 0.6028216671481461
Validation loss: 2.8623757797673943

Epoch: 6| Step: 5
Training loss: 0.5515400954929209
Validation loss: 2.8222273422513493

Epoch: 6| Step: 6
Training loss: 0.39149582117780923
Validation loss: 2.846068237313202

Epoch: 6| Step: 7
Training loss: 0.5858823114471614
Validation loss: 2.8748949833362603

Epoch: 6| Step: 8
Training loss: 0.8289444665611038
Validation loss: 2.7689508817317643

Epoch: 6| Step: 9
Training loss: 0.6332411079851695
Validation loss: 2.7963340847132447

Epoch: 6| Step: 10
Training loss: 0.37963404024003455
Validation loss: 2.7634141781633934

Epoch: 6| Step: 11
Training loss: 0.3146065758125208
Validation loss: 2.9140440434884725

Epoch: 6| Step: 12
Training loss: 0.2081085462624576
Validation loss: 2.9317605512751244

Epoch: 6| Step: 13
Training loss: 0.6724742833790052
Validation loss: 2.978008890040074

Epoch: 550| Step: 0
Training loss: 0.5339122151395201
Validation loss: 2.940987390396254

Epoch: 6| Step: 1
Training loss: 0.45002127570613876
Validation loss: 3.0206021626032293

Epoch: 6| Step: 2
Training loss: 0.6553449748028118
Validation loss: 2.931077984911978

Epoch: 6| Step: 3
Training loss: 0.2778786618432892
Validation loss: 2.923989617035744

Epoch: 6| Step: 4
Training loss: 0.4554467406934052
Validation loss: 2.8470681084169454

Epoch: 6| Step: 5
Training loss: 0.2898822835925898
Validation loss: 2.8340321595299516

Epoch: 6| Step: 6
Training loss: 0.35699443585603696
Validation loss: 2.7711167059149098

Epoch: 6| Step: 7
Training loss: 0.42912088662322617
Validation loss: 2.847714172806793

Epoch: 6| Step: 8
Training loss: 0.4182458119704302
Validation loss: 2.81046912726626

Epoch: 6| Step: 9
Training loss: 0.4119070378984713
Validation loss: 2.8576332304414267

Epoch: 6| Step: 10
Training loss: 0.44819702386319066
Validation loss: 2.8692990045739264

Epoch: 6| Step: 11
Training loss: 0.4922857640585603
Validation loss: 2.8340191338386087

Epoch: 6| Step: 12
Training loss: 0.5924024347865717
Validation loss: 2.8545741372792532

Epoch: 6| Step: 13
Training loss: 0.41773511470959623
Validation loss: 2.8257565354628804

Testing loss: 2.572153561901367
