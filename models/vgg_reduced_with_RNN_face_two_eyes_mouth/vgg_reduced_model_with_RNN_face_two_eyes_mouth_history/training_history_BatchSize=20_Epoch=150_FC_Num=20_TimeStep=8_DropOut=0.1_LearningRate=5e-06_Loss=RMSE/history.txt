Epoch: 1| Step: 0
Training loss: 6.332951718260634
Validation loss: 5.937843841501606

Epoch: 5| Step: 1
Training loss: 6.516492022087173
Validation loss: 5.935839852586507

Epoch: 5| Step: 2
Training loss: 6.556655170150682
Validation loss: 5.933920795400648

Epoch: 5| Step: 3
Training loss: 6.831553839987821
Validation loss: 5.932062048036429

Epoch: 5| Step: 4
Training loss: 5.620617833777175
Validation loss: 5.9303115630254215

Epoch: 5| Step: 5
Training loss: 5.864449625427751
Validation loss: 5.928661232496304

Epoch: 5| Step: 6
Training loss: 5.751641412394168
Validation loss: 5.927016583576905

Epoch: 5| Step: 7
Training loss: 5.992969844829453
Validation loss: 5.925432476994278

Epoch: 5| Step: 8
Training loss: 5.990777238912288
Validation loss: 5.923896665896649

Epoch: 5| Step: 9
Training loss: 5.292545495934644
Validation loss: 5.922148108580242

Epoch: 5| Step: 10
Training loss: 5.621633581943835
Validation loss: 5.9204888914975005

Epoch: 5| Step: 11
Training loss: 5.782865721223953
Validation loss: 5.918773520025821

Epoch: 2| Step: 0
Training loss: 6.172529509401603
Validation loss: 5.917005115106033

Epoch: 5| Step: 1
Training loss: 5.962018916077343
Validation loss: 5.915087350311609

Epoch: 5| Step: 2
Training loss: 5.905524638204586
Validation loss: 5.913162492192986

Epoch: 5| Step: 3
Training loss: 5.5796735735067555
Validation loss: 5.911111892653934

Epoch: 5| Step: 4
Training loss: 5.575148528305851
Validation loss: 5.908919429180472

Epoch: 5| Step: 5
Training loss: 5.558144911165561
Validation loss: 5.906790646359841

Epoch: 5| Step: 6
Training loss: 6.447226870055438
Validation loss: 5.904553157869359

Epoch: 5| Step: 7
Training loss: 5.869146149643822
Validation loss: 5.9020900709672794

Epoch: 5| Step: 8
Training loss: 6.560091285070432
Validation loss: 5.899412001388586

Epoch: 5| Step: 9
Training loss: 6.4751552253881215
Validation loss: 5.896706003187624

Epoch: 5| Step: 10
Training loss: 6.241987050911753
Validation loss: 5.893824442895278

Epoch: 5| Step: 11
Training loss: 4.786090868548356
Validation loss: 5.89067164637869

Epoch: 3| Step: 0
Training loss: 5.7561619125402395
Validation loss: 5.88760411844701

Epoch: 5| Step: 1
Training loss: 5.5803138007524415
Validation loss: 5.884160921156756

Epoch: 5| Step: 2
Training loss: 6.420358000663939
Validation loss: 5.880642163401668

Epoch: 5| Step: 3
Training loss: 6.048511845440463
Validation loss: 5.876988818321303

Epoch: 5| Step: 4
Training loss: 5.715935353174485
Validation loss: 5.873201169252823

Epoch: 5| Step: 5
Training loss: 5.911657048273055
Validation loss: 5.86904146488353

Epoch: 5| Step: 6
Training loss: 5.958924519836232
Validation loss: 5.86471819906059

Epoch: 5| Step: 7
Training loss: 6.294443423001838
Validation loss: 5.860197689369447

Epoch: 5| Step: 8
Training loss: 5.5662832360310865
Validation loss: 5.855523480513083

Epoch: 5| Step: 9
Training loss: 6.1060247967363654
Validation loss: 5.850366433668318

Epoch: 5| Step: 10
Training loss: 6.35710354665784
Validation loss: 5.845466300533745

Epoch: 5| Step: 11
Training loss: 6.083476792128914
Validation loss: 5.839802454161317

Epoch: 4| Step: 0
Training loss: 6.263542457054804
Validation loss: 5.8343295904189425

Epoch: 5| Step: 1
Training loss: 6.645157288353895
Validation loss: 5.828441594228946

Epoch: 5| Step: 2
Training loss: 5.036097684911183
Validation loss: 5.822394047885941

Epoch: 5| Step: 3
Training loss: 6.08297387023461
Validation loss: 5.816078253644607

Epoch: 5| Step: 4
Training loss: 6.245450920153398
Validation loss: 5.809743391630655

Epoch: 5| Step: 5
Training loss: 6.373357224572597
Validation loss: 5.802950394207998

Epoch: 5| Step: 6
Training loss: 6.216473186574083
Validation loss: 5.795960216198322

Epoch: 5| Step: 7
Training loss: 5.220435686893032
Validation loss: 5.788757268123612

Epoch: 5| Step: 8
Training loss: 5.294577491336544
Validation loss: 5.781700749051691

Epoch: 5| Step: 9
Training loss: 5.796427830314203
Validation loss: 5.774245292097799

Epoch: 5| Step: 10
Training loss: 5.839257456459876
Validation loss: 5.767075029790756

Epoch: 5| Step: 11
Training loss: 5.1034236860260584
Validation loss: 5.759590471376378

Epoch: 5| Step: 0
Training loss: 6.62674359103609
Validation loss: 5.752122549466538

Epoch: 5| Step: 1
Training loss: 6.474023705600238
Validation loss: 5.744474513503786

Epoch: 5| Step: 2
Training loss: 6.314074329420835
Validation loss: 5.736855014791566

Epoch: 5| Step: 3
Training loss: 4.72061726591087
Validation loss: 5.728816922234114

Epoch: 5| Step: 4
Training loss: 4.909716893753309
Validation loss: 5.721706501653279

Epoch: 5| Step: 5
Training loss: 5.629823778013338
Validation loss: 5.71402243507226

Epoch: 5| Step: 6
Training loss: 5.878817677385101
Validation loss: 5.706812045608955

Epoch: 5| Step: 7
Training loss: 5.728197975338992
Validation loss: 5.699536425160467

Epoch: 5| Step: 8
Training loss: 6.192110443983399
Validation loss: 5.691956000655954

Epoch: 5| Step: 9
Training loss: 5.742560176044155
Validation loss: 5.685010861397877

Epoch: 5| Step: 10
Training loss: 5.391157483324871
Validation loss: 5.677656304612554

Epoch: 5| Step: 11
Training loss: 6.837227556843673
Validation loss: 5.670809937409463

Epoch: 6| Step: 0
Training loss: 5.816401331113601
Validation loss: 5.664056143921542

Epoch: 5| Step: 1
Training loss: 5.682761765243866
Validation loss: 5.657208854936881

Epoch: 5| Step: 2
Training loss: 4.552568469467478
Validation loss: 5.65053385432044

Epoch: 5| Step: 3
Training loss: 6.500247657166009
Validation loss: 5.643884479642686

Epoch: 5| Step: 4
Training loss: 6.2630716576896575
Validation loss: 5.637330851868456

Epoch: 5| Step: 5
Training loss: 5.32429290518333
Validation loss: 5.631166229020113

Epoch: 5| Step: 6
Training loss: 6.256117001700403
Validation loss: 5.624953573529834

Epoch: 5| Step: 7
Training loss: 5.774022218572284
Validation loss: 5.618916308721433

Epoch: 5| Step: 8
Training loss: 5.664433244870637
Validation loss: 5.6125441359021435

Epoch: 5| Step: 9
Training loss: 5.933063335204739
Validation loss: 5.606593087711822

Epoch: 5| Step: 10
Training loss: 5.247865878903441
Validation loss: 5.600401463196236

Epoch: 5| Step: 11
Training loss: 5.6284281139095365
Validation loss: 5.594259185632094

Epoch: 7| Step: 0
Training loss: 6.24466996847205
Validation loss: 5.588099021007884

Epoch: 5| Step: 1
Training loss: 5.995273954035424
Validation loss: 5.582122930116879

Epoch: 5| Step: 2
Training loss: 5.472850025566546
Validation loss: 5.5758489886062055

Epoch: 5| Step: 3
Training loss: 5.833686527277169
Validation loss: 5.569570505338574

Epoch: 5| Step: 4
Training loss: 5.9624930135817955
Validation loss: 5.563568926912694

Epoch: 5| Step: 5
Training loss: 3.505583260801701
Validation loss: 5.557058880645793

Epoch: 5| Step: 6
Training loss: 5.967752263426886
Validation loss: 5.550854905472221

Epoch: 5| Step: 7
Training loss: 5.443912101635818
Validation loss: 5.544773781968729

Epoch: 5| Step: 8
Training loss: 5.439191357873289
Validation loss: 5.538437435462459

Epoch: 5| Step: 9
Training loss: 6.4647334063468325
Validation loss: 5.532190074166224

Epoch: 5| Step: 10
Training loss: 5.606661934746655
Validation loss: 5.525843497799909

Epoch: 5| Step: 11
Training loss: 5.543640741176897
Validation loss: 5.519548765722993

Epoch: 8| Step: 0
Training loss: 5.262183086067875
Validation loss: 5.513325529788736

Epoch: 5| Step: 1
Training loss: 5.042275804444452
Validation loss: 5.5070408851011425

Epoch: 5| Step: 2
Training loss: 5.880013457302342
Validation loss: 5.500920327087236

Epoch: 5| Step: 3
Training loss: 6.064322286229498
Validation loss: 5.4950536897447035

Epoch: 5| Step: 4
Training loss: 5.4446157614468005
Validation loss: 5.488746516551603

Epoch: 5| Step: 5
Training loss: 5.807542881571264
Validation loss: 5.483030837371712

Epoch: 5| Step: 6
Training loss: 4.968234821218652
Validation loss: 5.476776634017001

Epoch: 5| Step: 7
Training loss: 6.7958815276095486
Validation loss: 5.471004239463663

Epoch: 5| Step: 8
Training loss: 4.834468291750441
Validation loss: 5.464960569197001

Epoch: 5| Step: 9
Training loss: 5.074678442779151
Validation loss: 5.459025203254167

Epoch: 5| Step: 10
Training loss: 5.876377999234952
Validation loss: 5.453119338068168

Epoch: 5| Step: 11
Training loss: 6.789066433219516
Validation loss: 5.446964350872316

Epoch: 9| Step: 0
Training loss: 5.9575752185038215
Validation loss: 5.440569818586796

Epoch: 5| Step: 1
Training loss: 5.557974699804945
Validation loss: 5.4340529715130375

Epoch: 5| Step: 2
Training loss: 5.1743984001728105
Validation loss: 5.427428436533777

Epoch: 5| Step: 3
Training loss: 6.180447653448857
Validation loss: 5.420997262753821

Epoch: 5| Step: 4
Training loss: 6.0607130425576585
Validation loss: 5.414578514591121

Epoch: 5| Step: 5
Training loss: 5.53032767154561
Validation loss: 5.408234424989554

Epoch: 5| Step: 6
Training loss: 5.934981605096349
Validation loss: 5.401561622520245

Epoch: 5| Step: 7
Training loss: 5.424247288673484
Validation loss: 5.394888830798424

Epoch: 5| Step: 8
Training loss: 5.025546045194309
Validation loss: 5.38837545883242

Epoch: 5| Step: 9
Training loss: 4.855555759917797
Validation loss: 5.382114854254544

Epoch: 5| Step: 10
Training loss: 5.360341866252162
Validation loss: 5.375480896484447

Epoch: 5| Step: 11
Training loss: 2.857705384463572
Validation loss: 5.369416449159669

Epoch: 10| Step: 0
Training loss: 4.928593969194824
Validation loss: 5.363187169979161

Epoch: 5| Step: 1
Training loss: 4.970248206405428
Validation loss: 5.357271958869388

Epoch: 5| Step: 2
Training loss: 4.969808789572012
Validation loss: 5.350749660864141

Epoch: 5| Step: 3
Training loss: 5.408545210831414
Validation loss: 5.3448783991880235

Epoch: 5| Step: 4
Training loss: 5.741929070502665
Validation loss: 5.338495560113558

Epoch: 5| Step: 5
Training loss: 6.14966583584654
Validation loss: 5.332453352134992

Epoch: 5| Step: 6
Training loss: 5.496918248390837
Validation loss: 5.326097727325784

Epoch: 5| Step: 7
Training loss: 5.907280726033923
Validation loss: 5.319911252658288

Epoch: 5| Step: 8
Training loss: 5.265938497657221
Validation loss: 5.313375071840667

Epoch: 5| Step: 9
Training loss: 5.004246434389361
Validation loss: 5.307055289932237

Epoch: 5| Step: 10
Training loss: 5.814425569929669
Validation loss: 5.301000580716205

Epoch: 5| Step: 11
Training loss: 6.145971402271496
Validation loss: 5.294597620025274

Epoch: 11| Step: 0
Training loss: 5.734257252495127
Validation loss: 5.288313120913458

Epoch: 5| Step: 1
Training loss: 4.889553159802955
Validation loss: 5.282226803225329

Epoch: 5| Step: 2
Training loss: 5.548157621569021
Validation loss: 5.2755001225759965

Epoch: 5| Step: 3
Training loss: 5.893525479551692
Validation loss: 5.269748111124353

Epoch: 5| Step: 4
Training loss: 5.597884711896152
Validation loss: 5.264188304472385

Epoch: 5| Step: 5
Training loss: 5.60830414732792
Validation loss: 5.257657612318393

Epoch: 5| Step: 6
Training loss: 4.737052135384369
Validation loss: 5.251735256674901

Epoch: 5| Step: 7
Training loss: 4.927901583815913
Validation loss: 5.245946340982381

Epoch: 5| Step: 8
Training loss: 5.732842097566006
Validation loss: 5.240417158797067

Epoch: 5| Step: 9
Training loss: 5.518419460191754
Validation loss: 5.2345329754272605

Epoch: 5| Step: 10
Training loss: 4.9309279729517925
Validation loss: 5.228962991808331

Epoch: 5| Step: 11
Training loss: 4.885439918099431
Validation loss: 5.223418350177017

Epoch: 12| Step: 0
Training loss: 5.7029771759523635
Validation loss: 5.217798865897296

Epoch: 5| Step: 1
Training loss: 5.080235063415919
Validation loss: 5.212384215181199

Epoch: 5| Step: 2
Training loss: 5.414750665082802
Validation loss: 5.207005471396827

Epoch: 5| Step: 3
Training loss: 4.067604262241363
Validation loss: 5.20166030139446

Epoch: 5| Step: 4
Training loss: 5.477572055553382
Validation loss: 5.196313120152956

Epoch: 5| Step: 5
Training loss: 5.378743132512174
Validation loss: 5.190862936728656

Epoch: 5| Step: 6
Training loss: 5.217531713033824
Validation loss: 5.185425408635549

Epoch: 5| Step: 7
Training loss: 5.215328351196214
Validation loss: 5.179831340282774

Epoch: 5| Step: 8
Training loss: 5.647488378451186
Validation loss: 5.1747955727243475

Epoch: 5| Step: 9
Training loss: 5.218155330195607
Validation loss: 5.169638612157041

Epoch: 5| Step: 10
Training loss: 5.539237080178093
Validation loss: 5.164144679813672

Epoch: 5| Step: 11
Training loss: 6.652897093288511
Validation loss: 5.159275993446202

Epoch: 13| Step: 0
Training loss: 5.418643747099766
Validation loss: 5.153446599094752

Epoch: 5| Step: 1
Training loss: 6.129920695602432
Validation loss: 5.147389576860616

Epoch: 5| Step: 2
Training loss: 5.7097537461607635
Validation loss: 5.141663899516264

Epoch: 5| Step: 3
Training loss: 4.933791880733083
Validation loss: 5.135566588013087

Epoch: 5| Step: 4
Training loss: 5.4149775096535455
Validation loss: 5.130623198127965

Epoch: 5| Step: 5
Training loss: 4.390358261748568
Validation loss: 5.124839477816415

Epoch: 5| Step: 6
Training loss: 5.062614157060706
Validation loss: 5.119003160152664

Epoch: 5| Step: 7
Training loss: 5.7718293837235395
Validation loss: 5.113145873568011

Epoch: 5| Step: 8
Training loss: 5.365309740779367
Validation loss: 5.106985507507556

Epoch: 5| Step: 9
Training loss: 4.598910177748425
Validation loss: 5.101760159412325

Epoch: 5| Step: 10
Training loss: 4.47568853611536
Validation loss: 5.096358132754735

Epoch: 5| Step: 11
Training loss: 6.002207032235101
Validation loss: 5.090061318740773

Epoch: 14| Step: 0
Training loss: 5.599471932445167
Validation loss: 5.0838348761399255

Epoch: 5| Step: 1
Training loss: 5.749478523822699
Validation loss: 5.0789752346240435

Epoch: 5| Step: 2
Training loss: 5.265236316677437
Validation loss: 5.073366598219891

Epoch: 5| Step: 3
Training loss: 4.82013206206045
Validation loss: 5.068368775267756

Epoch: 5| Step: 4
Training loss: 5.29931908318053
Validation loss: 5.062545006948335

Epoch: 5| Step: 5
Training loss: 5.472405307415818
Validation loss: 5.056579833084586

Epoch: 5| Step: 6
Training loss: 4.981158997818465
Validation loss: 5.051181558046054

Epoch: 5| Step: 7
Training loss: 5.12723659930607
Validation loss: 5.046147438728745

Epoch: 5| Step: 8
Training loss: 4.814664477802527
Validation loss: 5.041034661500585

Epoch: 5| Step: 9
Training loss: 4.817284125819958
Validation loss: 5.0356659790280665

Epoch: 5| Step: 10
Training loss: 5.03548599003947
Validation loss: 5.030351467733262

Epoch: 5| Step: 11
Training loss: 4.763010777594406
Validation loss: 5.024394860213954

Epoch: 15| Step: 0
Training loss: 4.571711816698043
Validation loss: 5.0195042709634885

Epoch: 5| Step: 1
Training loss: 5.403126955666306
Validation loss: 5.014467115631084

Epoch: 5| Step: 2
Training loss: 5.405094971506141
Validation loss: 5.009418477999901

Epoch: 5| Step: 3
Training loss: 4.751448962414691
Validation loss: 5.004445229854563

Epoch: 5| Step: 4
Training loss: 5.547544455090123
Validation loss: 4.999215223395885

Epoch: 5| Step: 5
Training loss: 5.356498992011108
Validation loss: 4.993290317211753

Epoch: 5| Step: 6
Training loss: 5.157289527374339
Validation loss: 4.9882913747200295

Epoch: 5| Step: 7
Training loss: 4.400705081626591
Validation loss: 4.983525107062936

Epoch: 5| Step: 8
Training loss: 5.042363184376379
Validation loss: 4.97791111118033

Epoch: 5| Step: 9
Training loss: 5.293867759790973
Validation loss: 4.972571057361251

Epoch: 5| Step: 10
Training loss: 5.057688746265587
Validation loss: 4.9676281844227494

Epoch: 5| Step: 11
Training loss: 5.948581353330178
Validation loss: 4.963261157739274

Epoch: 16| Step: 0
Training loss: 5.29298514613466
Validation loss: 4.958402155016533

Epoch: 5| Step: 1
Training loss: 6.040340234129446
Validation loss: 4.952630966049294

Epoch: 5| Step: 2
Training loss: 5.712951054701762
Validation loss: 4.947265616968002

Epoch: 5| Step: 3
Training loss: 4.516175338841719
Validation loss: 4.942462069530361

Epoch: 5| Step: 4
Training loss: 5.765945549714755
Validation loss: 4.938583810376084

Epoch: 5| Step: 5
Training loss: 4.615575518694762
Validation loss: 4.932565807013753

Epoch: 5| Step: 6
Training loss: 4.426918415662926
Validation loss: 4.92656071359699

Epoch: 5| Step: 7
Training loss: 4.32841584368003
Validation loss: 4.922240002535205

Epoch: 5| Step: 8
Training loss: 4.609823948607821
Validation loss: 4.917301228624976

Epoch: 5| Step: 9
Training loss: 4.451626923865825
Validation loss: 4.912822702435784

Epoch: 5| Step: 10
Training loss: 5.453823099566687
Validation loss: 4.907820820672319

Epoch: 5| Step: 11
Training loss: 5.179637787869475
Validation loss: 4.903021193427213

Epoch: 17| Step: 0
Training loss: 5.902334055460272
Validation loss: 4.898029454386343

Epoch: 5| Step: 1
Training loss: 4.231036119112593
Validation loss: 4.892982085525147

Epoch: 5| Step: 2
Training loss: 4.9651864186428085
Validation loss: 4.888550933020595

Epoch: 5| Step: 3
Training loss: 4.224556550900676
Validation loss: 4.883492490086517

Epoch: 5| Step: 4
Training loss: 5.124146367134851
Validation loss: 4.878727058762643

Epoch: 5| Step: 5
Training loss: 5.232537063635045
Validation loss: 4.873326870322128

Epoch: 5| Step: 6
Training loss: 4.389754782673168
Validation loss: 4.86872944662239

Epoch: 5| Step: 7
Training loss: 5.449351231868487
Validation loss: 4.8636760709711435

Epoch: 5| Step: 8
Training loss: 5.007731373050942
Validation loss: 4.859171741482728

Epoch: 5| Step: 9
Training loss: 5.613363648979859
Validation loss: 4.853683630468003

Epoch: 5| Step: 10
Training loss: 4.938700083463694
Validation loss: 4.848554119740525

Epoch: 5| Step: 11
Training loss: 2.269582304651111
Validation loss: 4.843567022333565

Epoch: 18| Step: 0
Training loss: 5.6700234661928635
Validation loss: 4.840406810488532

Epoch: 5| Step: 1
Training loss: 4.167230542493073
Validation loss: 4.834622123597933

Epoch: 5| Step: 2
Training loss: 4.4780705493244035
Validation loss: 4.829413142372292

Epoch: 5| Step: 3
Training loss: 4.858664310407294
Validation loss: 4.82507703716334

Epoch: 5| Step: 4
Training loss: 5.316448404900378
Validation loss: 4.821074373532589

Epoch: 5| Step: 5
Training loss: 5.280280571621082
Validation loss: 4.815610458414779

Epoch: 5| Step: 6
Training loss: 5.363615177036285
Validation loss: 4.810407142194678

Epoch: 5| Step: 7
Training loss: 4.194140506761081
Validation loss: 4.8065693961224785

Epoch: 5| Step: 8
Training loss: 4.407176900998454
Validation loss: 4.801452142879161

Epoch: 5| Step: 9
Training loss: 5.286737784780828
Validation loss: 4.796719050486979

Epoch: 5| Step: 10
Training loss: 5.1629992153618565
Validation loss: 4.791940742062599

Epoch: 5| Step: 11
Training loss: 4.363128686763187
Validation loss: 4.786802579049111

Epoch: 19| Step: 0
Training loss: 4.37369953990958
Validation loss: 4.78230406168857

Epoch: 5| Step: 1
Training loss: 5.154325183763204
Validation loss: 4.779545266083498

Epoch: 5| Step: 2
Training loss: 5.0782861302561475
Validation loss: 4.775606377531242

Epoch: 5| Step: 3
Training loss: 4.492057997453977
Validation loss: 4.769473955256534

Epoch: 5| Step: 4
Training loss: 4.975643150891616
Validation loss: 4.763984172573751

Epoch: 5| Step: 5
Training loss: 4.9887897707224385
Validation loss: 4.759231176309293

Epoch: 5| Step: 6
Training loss: 4.814133205965564
Validation loss: 4.7548674607148245

Epoch: 5| Step: 7
Training loss: 3.9840284009786737
Validation loss: 4.750617898939831

Epoch: 5| Step: 8
Training loss: 5.617883716035729
Validation loss: 4.746098003202398

Epoch: 5| Step: 9
Training loss: 4.832857349679744
Validation loss: 4.739866758263154

Epoch: 5| Step: 10
Training loss: 5.341616556028767
Validation loss: 4.735739088627111

Epoch: 5| Step: 11
Training loss: 4.227202136139254
Validation loss: 4.731085563029463

Epoch: 20| Step: 0
Training loss: 5.040478695131467
Validation loss: 4.727140062422428

Epoch: 5| Step: 1
Training loss: 5.653436962353493
Validation loss: 4.722385875197336

Epoch: 5| Step: 2
Training loss: 5.2857874051489855
Validation loss: 4.717296090044432

Epoch: 5| Step: 3
Training loss: 4.466004281724858
Validation loss: 4.711172643120711

Epoch: 5| Step: 4
Training loss: 4.408311510422648
Validation loss: 4.706078532397915

Epoch: 5| Step: 5
Training loss: 4.9897716807877694
Validation loss: 4.701651459572067

Epoch: 5| Step: 6
Training loss: 4.4730063488798155
Validation loss: 4.697888023926342

Epoch: 5| Step: 7
Training loss: 4.503523400900781
Validation loss: 4.691966696451624

Epoch: 5| Step: 8
Training loss: 5.0183778617722075
Validation loss: 4.687266017584174

Epoch: 5| Step: 9
Training loss: 4.569816471145866
Validation loss: 4.6825352719606625

Epoch: 5| Step: 10
Training loss: 4.709621467038828
Validation loss: 4.678134743394305

Epoch: 5| Step: 11
Training loss: 3.9643750444556867
Validation loss: 4.673057321491452

Epoch: 21| Step: 0
Training loss: 4.621181664553628
Validation loss: 4.66857631671796

Epoch: 5| Step: 1
Training loss: 4.449049627423848
Validation loss: 4.66373077354534

Epoch: 5| Step: 2
Training loss: 5.078754843752497
Validation loss: 4.65918011393159

Epoch: 5| Step: 3
Training loss: 4.883640554786908
Validation loss: 4.654567371810351

Epoch: 5| Step: 4
Training loss: 4.70014103616984
Validation loss: 4.6495410111569875

Epoch: 5| Step: 5
Training loss: 4.990980405340632
Validation loss: 4.644984944746559

Epoch: 5| Step: 6
Training loss: 4.797001044888171
Validation loss: 4.640357663795448

Epoch: 5| Step: 7
Training loss: 3.7746203604278463
Validation loss: 4.635048042241792

Epoch: 5| Step: 8
Training loss: 4.997552463395421
Validation loss: 4.630519099868483

Epoch: 5| Step: 9
Training loss: 4.852090459774424
Validation loss: 4.625113941198135

Epoch: 5| Step: 10
Training loss: 4.741877588140913
Validation loss: 4.620677637974869

Epoch: 5| Step: 11
Training loss: 6.676398644377265
Validation loss: 4.615572961760553

Epoch: 22| Step: 0
Training loss: 5.150729096291968
Validation loss: 4.610751800951535

Epoch: 5| Step: 1
Training loss: 4.566246271390356
Validation loss: 4.605352122539816

Epoch: 5| Step: 2
Training loss: 5.005641234456463
Validation loss: 4.599394887362913

Epoch: 5| Step: 3
Training loss: 4.746438146583784
Validation loss: 4.593777312632221

Epoch: 5| Step: 4
Training loss: 4.924178102335507
Validation loss: 4.5889792722576255

Epoch: 5| Step: 5
Training loss: 4.817466650047139
Validation loss: 4.583976183226929

Epoch: 5| Step: 6
Training loss: 4.4864344104736915
Validation loss: 4.57813462569925

Epoch: 5| Step: 7
Training loss: 5.3438709981504084
Validation loss: 4.572352779382858

Epoch: 5| Step: 8
Training loss: 4.099902472848011
Validation loss: 4.566713025328809

Epoch: 5| Step: 9
Training loss: 4.693281956485386
Validation loss: 4.562362285608456

Epoch: 5| Step: 10
Training loss: 3.8789412851278424
Validation loss: 4.555879392233497

Epoch: 5| Step: 11
Training loss: 4.292935649824054
Validation loss: 4.549191692013496

Epoch: 23| Step: 0
Training loss: 3.9879715787129264
Validation loss: 4.542438986786121

Epoch: 5| Step: 1
Training loss: 4.650957620109822
Validation loss: 4.535398263796103

Epoch: 5| Step: 2
Training loss: 4.875792805689018
Validation loss: 4.5296693829370085

Epoch: 5| Step: 3
Training loss: 3.5207793703778045
Validation loss: 4.523871779252478

Epoch: 5| Step: 4
Training loss: 4.450029977418889
Validation loss: 4.518467647477332

Epoch: 5| Step: 5
Training loss: 3.757204764030699
Validation loss: 4.513261460281839

Epoch: 5| Step: 6
Training loss: 5.404632502791876
Validation loss: 4.508712493596653

Epoch: 5| Step: 7
Training loss: 5.134197634641902
Validation loss: 4.5031351629844485

Epoch: 5| Step: 8
Training loss: 5.328882963350289
Validation loss: 4.4979868200337165

Epoch: 5| Step: 9
Training loss: 4.849449692800003
Validation loss: 4.491834057158269

Epoch: 5| Step: 10
Training loss: 4.880142824865771
Validation loss: 4.486786179719734

Epoch: 5| Step: 11
Training loss: 3.330256536184826
Validation loss: 4.481616546380866

Epoch: 24| Step: 0
Training loss: 4.46609225968536
Validation loss: 4.47612165107784

Epoch: 5| Step: 1
Training loss: 4.727893585169356
Validation loss: 4.471341313243855

Epoch: 5| Step: 2
Training loss: 4.908114911040742
Validation loss: 4.46591978993231

Epoch: 5| Step: 3
Training loss: 4.758829643879656
Validation loss: 4.460181466710252

Epoch: 5| Step: 4
Training loss: 3.930645259077695
Validation loss: 4.455008223455041

Epoch: 5| Step: 5
Training loss: 4.466643363740022
Validation loss: 4.4494569807881135

Epoch: 5| Step: 6
Training loss: 4.355336933963848
Validation loss: 4.44425034082596

Epoch: 5| Step: 7
Training loss: 4.359002866551086
Validation loss: 4.43918505092963

Epoch: 5| Step: 8
Training loss: 5.011876877559486
Validation loss: 4.434504299236718

Epoch: 5| Step: 9
Training loss: 5.0682184394542835
Validation loss: 4.429125939173279

Epoch: 5| Step: 10
Training loss: 4.123358428763581
Validation loss: 4.424429623972145

Epoch: 5| Step: 11
Training loss: 4.764045828905523
Validation loss: 4.4193593205360076

Epoch: 25| Step: 0
Training loss: 4.080187513492937
Validation loss: 4.414241028722812

Epoch: 5| Step: 1
Training loss: 5.113861633887534
Validation loss: 4.408449679043045

Epoch: 5| Step: 2
Training loss: 4.960821387666767
Validation loss: 4.403757774814655

Epoch: 5| Step: 3
Training loss: 4.082441946295507
Validation loss: 4.39752313337084

Epoch: 5| Step: 4
Training loss: 3.9364467604864837
Validation loss: 4.393099104744862

Epoch: 5| Step: 5
Training loss: 4.6471813395945905
Validation loss: 4.387571619360382

Epoch: 5| Step: 6
Training loss: 4.792606803328797
Validation loss: 4.382822509319007

Epoch: 5| Step: 7
Training loss: 5.280772892997019
Validation loss: 4.377378897815459

Epoch: 5| Step: 8
Training loss: 4.738543095158348
Validation loss: 4.3726217481524134

Epoch: 5| Step: 9
Training loss: 4.080669909811598
Validation loss: 4.3671187985133955

Epoch: 5| Step: 10
Training loss: 3.9204018550342585
Validation loss: 4.36200973575945

Epoch: 5| Step: 11
Training loss: 3.2760686746928416
Validation loss: 4.357091303240462

Epoch: 26| Step: 0
Training loss: 4.397806505166498
Validation loss: 4.352855697959011

Epoch: 5| Step: 1
Training loss: 4.3028443089110855
Validation loss: 4.347821475005814

Epoch: 5| Step: 2
Training loss: 5.547926252440154
Validation loss: 4.342920256113658

Epoch: 5| Step: 3
Training loss: 3.781863706613176
Validation loss: 4.338054215920345

Epoch: 5| Step: 4
Training loss: 4.79374110334185
Validation loss: 4.332944021098583

Epoch: 5| Step: 5
Training loss: 4.289271726525347
Validation loss: 4.328885035797609

Epoch: 5| Step: 6
Training loss: 4.054548727905843
Validation loss: 4.323267822097712

Epoch: 5| Step: 7
Training loss: 4.3745507145840445
Validation loss: 4.318559011384984

Epoch: 5| Step: 8
Training loss: 4.525098953429646
Validation loss: 4.313713630884786

Epoch: 5| Step: 9
Training loss: 4.233808754084448
Validation loss: 4.308506374216738

Epoch: 5| Step: 10
Training loss: 4.573752127806155
Validation loss: 4.303855118580807

Epoch: 5| Step: 11
Training loss: 4.143360083921524
Validation loss: 4.299100597712185

Epoch: 27| Step: 0
Training loss: 4.479227228272752
Validation loss: 4.294061176401729

Epoch: 5| Step: 1
Training loss: 4.918706740076404
Validation loss: 4.289354176612263

Epoch: 5| Step: 2
Training loss: 4.429803110057158
Validation loss: 4.284478086663852

Epoch: 5| Step: 3
Training loss: 4.28105196529608
Validation loss: 4.279217476560159

Epoch: 5| Step: 4
Training loss: 4.366864733292863
Validation loss: 4.274380800046452

Epoch: 5| Step: 5
Training loss: 3.992843544164518
Validation loss: 4.269401573917866

Epoch: 5| Step: 6
Training loss: 4.759230228659333
Validation loss: 4.26446888292842

Epoch: 5| Step: 7
Training loss: 4.487439321463674
Validation loss: 4.259658641891409

Epoch: 5| Step: 8
Training loss: 4.317257233704364
Validation loss: 4.255023399763842

Epoch: 5| Step: 9
Training loss: 4.049004778617287
Validation loss: 4.250006689739572

Epoch: 5| Step: 10
Training loss: 4.152380956588952
Validation loss: 4.245635521760247

Epoch: 5| Step: 11
Training loss: 4.809867039545932
Validation loss: 4.2409343285258645

Epoch: 28| Step: 0
Training loss: 3.4906582823065695
Validation loss: 4.235868169596392

Epoch: 5| Step: 1
Training loss: 4.907422939945061
Validation loss: 4.231091825345163

Epoch: 5| Step: 2
Training loss: 3.57345769732213
Validation loss: 4.2260694797958696

Epoch: 5| Step: 3
Training loss: 5.507014569860538
Validation loss: 4.221386323587104

Epoch: 5| Step: 4
Training loss: 4.11727436126056
Validation loss: 4.216688076098124

Epoch: 5| Step: 5
Training loss: 3.8837971657257686
Validation loss: 4.211632109227146

Epoch: 5| Step: 6
Training loss: 4.06099590921466
Validation loss: 4.206468460093237

Epoch: 5| Step: 7
Training loss: 4.623578445952228
Validation loss: 4.2014946215787825

Epoch: 5| Step: 8
Training loss: 4.355401309735724
Validation loss: 4.197171964764563

Epoch: 5| Step: 9
Training loss: 4.457336575801247
Validation loss: 4.191793636588213

Epoch: 5| Step: 10
Training loss: 4.084712645417041
Validation loss: 4.186600783102028

Epoch: 5| Step: 11
Training loss: 5.647239969657952
Validation loss: 4.1823263234198595

Epoch: 29| Step: 0
Training loss: 4.181577907414421
Validation loss: 4.1772406715701225

Epoch: 5| Step: 1
Training loss: 4.1918048651319335
Validation loss: 4.172623975484097

Epoch: 5| Step: 2
Training loss: 3.8345830511156387
Validation loss: 4.167341619501545

Epoch: 5| Step: 3
Training loss: 4.52085494403977
Validation loss: 4.162293583865849

Epoch: 5| Step: 4
Training loss: 3.7357836504583917
Validation loss: 4.157689975642501

Epoch: 5| Step: 5
Training loss: 4.139644175547759
Validation loss: 4.152810722115499

Epoch: 5| Step: 6
Training loss: 4.164328160498439
Validation loss: 4.148123145540578

Epoch: 5| Step: 7
Training loss: 4.28498176490705
Validation loss: 4.1436486534356405

Epoch: 5| Step: 8
Training loss: 4.440301145358793
Validation loss: 4.138462235963657

Epoch: 5| Step: 9
Training loss: 5.296030342925584
Validation loss: 4.133874157099503

Epoch: 5| Step: 10
Training loss: 4.219939113738162
Validation loss: 4.129185441273113

Epoch: 5| Step: 11
Training loss: 3.828488951528728
Validation loss: 4.123669024278825

Epoch: 30| Step: 0
Training loss: 4.740164361349448
Validation loss: 4.118864327225059

Epoch: 5| Step: 1
Training loss: 4.148957013433184
Validation loss: 4.1135973831516

Epoch: 5| Step: 2
Training loss: 4.203868700904366
Validation loss: 4.109072878408143

Epoch: 5| Step: 3
Training loss: 4.648600394335988
Validation loss: 4.104233909030268

Epoch: 5| Step: 4
Training loss: 4.665127273246244
Validation loss: 4.099582826511153

Epoch: 5| Step: 5
Training loss: 3.7475150458076465
Validation loss: 4.094053305729708

Epoch: 5| Step: 6
Training loss: 4.034931955815553
Validation loss: 4.089257189428482

Epoch: 5| Step: 7
Training loss: 4.443916946472834
Validation loss: 4.083798647986722

Epoch: 5| Step: 8
Training loss: 3.241954381444123
Validation loss: 4.079115200529831

Epoch: 5| Step: 9
Training loss: 4.1623781386857654
Validation loss: 4.074287270115767

Epoch: 5| Step: 10
Training loss: 4.281857858093721
Validation loss: 4.069822829867383

Epoch: 5| Step: 11
Training loss: 3.968521111563758
Validation loss: 4.065516584330399

Epoch: 31| Step: 0
Training loss: 4.666677588495462
Validation loss: 4.060149495844226

Epoch: 5| Step: 1
Training loss: 3.728109938150631
Validation loss: 4.055083170397313

Epoch: 5| Step: 2
Training loss: 3.4505030831894077
Validation loss: 4.050395362300128

Epoch: 5| Step: 3
Training loss: 3.861855887127889
Validation loss: 4.045885394645683

Epoch: 5| Step: 4
Training loss: 4.26609872276509
Validation loss: 4.041212349686878

Epoch: 5| Step: 5
Training loss: 4.188981662355865
Validation loss: 4.036859847577452

Epoch: 5| Step: 6
Training loss: 4.223448221219166
Validation loss: 4.033061012553795

Epoch: 5| Step: 7
Training loss: 4.539377434682738
Validation loss: 4.027827216900939

Epoch: 5| Step: 8
Training loss: 4.298377090079523
Validation loss: 4.022854483130585

Epoch: 5| Step: 9
Training loss: 3.5994466992202208
Validation loss: 4.018218774920129

Epoch: 5| Step: 10
Training loss: 4.7388739533590885
Validation loss: 4.013390088612076

Epoch: 5| Step: 11
Training loss: 4.476303865374424
Validation loss: 4.008426938910314

Epoch: 32| Step: 0
Training loss: 4.467182231204811
Validation loss: 4.003680319265564

Epoch: 5| Step: 1
Training loss: 4.071608675651627
Validation loss: 3.9986338368577883

Epoch: 5| Step: 2
Training loss: 3.5613235404983103
Validation loss: 3.993543689395665

Epoch: 5| Step: 3
Training loss: 3.4119529928477665
Validation loss: 3.9884496361247135

Epoch: 5| Step: 4
Training loss: 4.011399000995841
Validation loss: 3.9838960845945643

Epoch: 5| Step: 5
Training loss: 4.64847853185672
Validation loss: 3.9794719472421116

Epoch: 5| Step: 6
Training loss: 4.421498852155158
Validation loss: 3.9744178069716285

Epoch: 5| Step: 7
Training loss: 3.680594751561183
Validation loss: 3.969348687098887

Epoch: 5| Step: 8
Training loss: 3.1093820543065394
Validation loss: 3.9647104826580497

Epoch: 5| Step: 9
Training loss: 4.944480307707339
Validation loss: 3.960022268200568

Epoch: 5| Step: 10
Training loss: 4.547549063411066
Validation loss: 3.9553006634682415

Epoch: 5| Step: 11
Training loss: 3.8369994393100484
Validation loss: 3.950634625513724

Epoch: 33| Step: 0
Training loss: 4.292586416308877
Validation loss: 3.9454441212268163

Epoch: 5| Step: 1
Training loss: 4.480206296462509
Validation loss: 3.94062217169793

Epoch: 5| Step: 2
Training loss: 4.160904422160111
Validation loss: 3.9357788825295206

Epoch: 5| Step: 3
Training loss: 3.548935883837967
Validation loss: 3.9309068510841656

Epoch: 5| Step: 4
Training loss: 3.7859906201133064
Validation loss: 3.9259182528096583

Epoch: 5| Step: 5
Training loss: 4.126894429155479
Validation loss: 3.9210154945442275

Epoch: 5| Step: 6
Training loss: 3.6069458552929703
Validation loss: 3.9163457032170474

Epoch: 5| Step: 7
Training loss: 4.50437481470109
Validation loss: 3.911458294390574

Epoch: 5| Step: 8
Training loss: 4.4194935562875735
Validation loss: 3.906863294140554

Epoch: 5| Step: 9
Training loss: 3.897308736614123
Validation loss: 3.901809991908792

Epoch: 5| Step: 10
Training loss: 4.0108169686159085
Validation loss: 3.897011653499654

Epoch: 5| Step: 11
Training loss: 1.3563558879951039
Validation loss: 3.892529456840358

Epoch: 34| Step: 0
Training loss: 3.8192822524033163
Validation loss: 3.887885036596718

Epoch: 5| Step: 1
Training loss: 4.578627835413641
Validation loss: 3.883673083228491

Epoch: 5| Step: 2
Training loss: 3.590850323677959
Validation loss: 3.879008486124885

Epoch: 5| Step: 3
Training loss: 4.015636874526461
Validation loss: 3.874768845011208

Epoch: 5| Step: 4
Training loss: 3.6841117680729125
Validation loss: 3.870305627481301

Epoch: 5| Step: 5
Training loss: 3.8551814350027094
Validation loss: 3.8660816756536076

Epoch: 5| Step: 6
Training loss: 4.570601494936164
Validation loss: 3.861859797122498

Epoch: 5| Step: 7
Training loss: 3.9052713617852075
Validation loss: 3.8573179438629372

Epoch: 5| Step: 8
Training loss: 4.137407542691003
Validation loss: 3.8528369499918176

Epoch: 5| Step: 9
Training loss: 3.9617153509987144
Validation loss: 3.8480892499310455

Epoch: 5| Step: 10
Training loss: 3.9044810447745686
Validation loss: 3.8435744992433443

Epoch: 5| Step: 11
Training loss: 3.1385665904381805
Validation loss: 3.8389392924615042

Epoch: 35| Step: 0
Training loss: 3.1131020450109514
Validation loss: 3.8344121050833464

Epoch: 5| Step: 1
Training loss: 3.92978918349743
Validation loss: 3.830022738541118

Epoch: 5| Step: 2
Training loss: 3.8059523592927507
Validation loss: 3.8255065578387364

Epoch: 5| Step: 3
Training loss: 3.0942866312721784
Validation loss: 3.8209575584348743

Epoch: 5| Step: 4
Training loss: 3.7916556697029242
Validation loss: 3.8166281753720233

Epoch: 5| Step: 5
Training loss: 4.0169711101804575
Validation loss: 3.8124089308321016

Epoch: 5| Step: 6
Training loss: 4.13055831497489
Validation loss: 3.807987993109898

Epoch: 5| Step: 7
Training loss: 4.375549063969693
Validation loss: 3.8035534180918984

Epoch: 5| Step: 8
Training loss: 4.485353369767489
Validation loss: 3.7995121069620414

Epoch: 5| Step: 9
Training loss: 4.717048388739402
Validation loss: 3.794765922730619

Epoch: 5| Step: 10
Training loss: 3.745993953962686
Validation loss: 3.7898825528191105

Epoch: 5| Step: 11
Training loss: 3.1737895129862816
Validation loss: 3.785065137083472

Epoch: 36| Step: 0
Training loss: 3.8987674917481185
Validation loss: 3.7802520622582647

Epoch: 5| Step: 1
Training loss: 4.325133463834436
Validation loss: 3.7755095990533443

Epoch: 5| Step: 2
Training loss: 3.833874802425268
Validation loss: 3.7708390887446592

Epoch: 5| Step: 3
Training loss: 5.119746795592197
Validation loss: 3.7659271087389166

Epoch: 5| Step: 4
Training loss: 3.2221705955081923
Validation loss: 3.761095649659911

Epoch: 5| Step: 5
Training loss: 3.7869670933657917
Validation loss: 3.7561491617894887

Epoch: 5| Step: 6
Training loss: 3.590192941777906
Validation loss: 3.751452577911745

Epoch: 5| Step: 7
Training loss: 3.668816514200208
Validation loss: 3.7471205570715376

Epoch: 5| Step: 8
Training loss: 4.25496652663946
Validation loss: 3.7424634434866757

Epoch: 5| Step: 9
Training loss: 3.691176053090292
Validation loss: 3.7378111902179416

Epoch: 5| Step: 10
Training loss: 3.184923065310338
Validation loss: 3.733254034329821

Epoch: 5| Step: 11
Training loss: 3.238564252278731
Validation loss: 3.728804132041123

Epoch: 37| Step: 0
Training loss: 3.516167628479186
Validation loss: 3.724508933953608

Epoch: 5| Step: 1
Training loss: 3.6137433720530874
Validation loss: 3.7202006964484005

Epoch: 5| Step: 2
Training loss: 4.45939585541177
Validation loss: 3.7157535020634267

Epoch: 5| Step: 3
Training loss: 3.9072163111431375
Validation loss: 3.7116095379436995

Epoch: 5| Step: 4
Training loss: 3.361523034641702
Validation loss: 3.7071175600381046

Epoch: 5| Step: 5
Training loss: 3.858034464807258
Validation loss: 3.70300774583136

Epoch: 5| Step: 6
Training loss: 4.007076441226816
Validation loss: 3.6982844568306055

Epoch: 5| Step: 7
Training loss: 3.6661274831429758
Validation loss: 3.69396743328091

Epoch: 5| Step: 8
Training loss: 4.195447979947005
Validation loss: 3.68962980176863

Epoch: 5| Step: 9
Training loss: 3.6863097516711902
Validation loss: 3.685046063742997

Epoch: 5| Step: 10
Training loss: 4.155493186940508
Validation loss: 3.6807474336251382

Epoch: 5| Step: 11
Training loss: 1.204037506057956
Validation loss: 3.6760400565448252

Epoch: 38| Step: 0
Training loss: 4.0236901657618755
Validation loss: 3.6721006229423137

Epoch: 5| Step: 1
Training loss: 3.459234158647759
Validation loss: 3.6674925820401962

Epoch: 5| Step: 2
Training loss: 3.1232986396428726
Validation loss: 3.6635566313416894

Epoch: 5| Step: 3
Training loss: 3.6281297261472636
Validation loss: 3.659614292164247

Epoch: 5| Step: 4
Training loss: 4.1679458689039235
Validation loss: 3.6555110532450628

Epoch: 5| Step: 5
Training loss: 3.9733610025078265
Validation loss: 3.6514166323345942

Epoch: 5| Step: 6
Training loss: 4.345361863356231
Validation loss: 3.6472454043111076

Epoch: 5| Step: 7
Training loss: 3.767333849892766
Validation loss: 3.6427851477488913

Epoch: 5| Step: 8
Training loss: 3.8136608670251735
Validation loss: 3.6385361732654764

Epoch: 5| Step: 9
Training loss: 3.5285585662448513
Validation loss: 3.634121654161467

Epoch: 5| Step: 10
Training loss: 3.829888011799087
Validation loss: 3.6296885796538625

Epoch: 5| Step: 11
Training loss: 2.921161911386738
Validation loss: 3.62554492910465

Epoch: 39| Step: 0
Training loss: 3.802392412277539
Validation loss: 3.6207588093020147

Epoch: 5| Step: 1
Training loss: 3.5599310463217444
Validation loss: 3.616677585415392

Epoch: 5| Step: 2
Training loss: 3.345427475601113
Validation loss: 3.6124013898297767

Epoch: 5| Step: 3
Training loss: 3.509703808103709
Validation loss: 3.6083205252956754

Epoch: 5| Step: 4
Training loss: 3.846129510509089
Validation loss: 3.6042213693043315

Epoch: 5| Step: 5
Training loss: 3.7860933921164865
Validation loss: 3.6002585587545597

Epoch: 5| Step: 6
Training loss: 3.976207544938982
Validation loss: 3.5957845567789075

Epoch: 5| Step: 7
Training loss: 4.113742378665955
Validation loss: 3.5915486435111337

Epoch: 5| Step: 8
Training loss: 3.19062113822382
Validation loss: 3.587288759128739

Epoch: 5| Step: 9
Training loss: 4.328812417206291
Validation loss: 3.583045979370443

Epoch: 5| Step: 10
Training loss: 3.472953929521961
Validation loss: 3.5786064301602734

Epoch: 5| Step: 11
Training loss: 3.801675908803402
Validation loss: 3.5740696943710484

Epoch: 40| Step: 0
Training loss: 3.3626132704932
Validation loss: 3.5698247196539965

Epoch: 5| Step: 1
Training loss: 4.065539352840185
Validation loss: 3.5656354390826523

Epoch: 5| Step: 2
Training loss: 3.278287294805059
Validation loss: 3.56136390908228

Epoch: 5| Step: 3
Training loss: 3.2754501674019254
Validation loss: 3.5566815439042396

Epoch: 5| Step: 4
Training loss: 3.216225977013631
Validation loss: 3.552510505265218

Epoch: 5| Step: 5
Training loss: 4.360347516270519
Validation loss: 3.548095453939051

Epoch: 5| Step: 6
Training loss: 3.555595533490602
Validation loss: 3.5440341422906325

Epoch: 5| Step: 7
Training loss: 3.8040487704996426
Validation loss: 3.539478735064015

Epoch: 5| Step: 8
Training loss: 3.4576524424235666
Validation loss: 3.535445210992199

Epoch: 5| Step: 9
Training loss: 3.910500982828996
Validation loss: 3.531268235106071

Epoch: 5| Step: 10
Training loss: 3.7121099607524792
Validation loss: 3.5270580797066846

Epoch: 5| Step: 11
Training loss: 5.175827129808446
Validation loss: 3.522521566023101

Epoch: 41| Step: 0
Training loss: 4.223174311276736
Validation loss: 3.5184120151414366

Epoch: 5| Step: 1
Training loss: 3.322898808892715
Validation loss: 3.5137903498519165

Epoch: 5| Step: 2
Training loss: 3.8012005064080734
Validation loss: 3.509526067139218

Epoch: 5| Step: 3
Training loss: 3.5918689614758463
Validation loss: 3.5051643440618947

Epoch: 5| Step: 4
Training loss: 4.146114295116446
Validation loss: 3.50086716853875

Epoch: 5| Step: 5
Training loss: 3.134723641658115
Validation loss: 3.496274355977536

Epoch: 5| Step: 6
Training loss: 3.854778687968394
Validation loss: 3.4924465825795576

Epoch: 5| Step: 7
Training loss: 4.011140330364662
Validation loss: 3.488209033430693

Epoch: 5| Step: 8
Training loss: 3.005098143639451
Validation loss: 3.48377438715883

Epoch: 5| Step: 9
Training loss: 3.471845465670959
Validation loss: 3.4797069887604146

Epoch: 5| Step: 10
Training loss: 2.948588767565739
Validation loss: 3.475211520355436

Epoch: 5| Step: 11
Training loss: 4.525079142684533
Validation loss: 3.4710542797792616

Epoch: 42| Step: 0
Training loss: 3.346984297306095
Validation loss: 3.466762276776814

Epoch: 5| Step: 1
Training loss: 3.6225539537917615
Validation loss: 3.462608129371444

Epoch: 5| Step: 2
Training loss: 4.470816394575915
Validation loss: 3.458313066737222

Epoch: 5| Step: 3
Training loss: 3.097683188476419
Validation loss: 3.453808488133136

Epoch: 5| Step: 4
Training loss: 3.578102611488363
Validation loss: 3.4494798330338714

Epoch: 5| Step: 5
Training loss: 3.7709571157691157
Validation loss: 3.44553692260483

Epoch: 5| Step: 6
Training loss: 3.1233987902198117
Validation loss: 3.441034661393852

Epoch: 5| Step: 7
Training loss: 2.752209122868347
Validation loss: 3.4370474286253643

Epoch: 5| Step: 8
Training loss: 3.689499910783954
Validation loss: 3.4330994557994594

Epoch: 5| Step: 9
Training loss: 3.5268205527159404
Validation loss: 3.4293616624520302

Epoch: 5| Step: 10
Training loss: 4.20848473506306
Validation loss: 3.425396931403514

Epoch: 5| Step: 11
Training loss: 3.134235011556411
Validation loss: 3.4214366765651083

Epoch: 43| Step: 0
Training loss: 3.1719486622642616
Validation loss: 3.417415526168581

Epoch: 5| Step: 1
Training loss: 3.25952542507404
Validation loss: 3.4138260271361434

Epoch: 5| Step: 2
Training loss: 3.063909245324741
Validation loss: 3.4101222307125836

Epoch: 5| Step: 3
Training loss: 3.9566166953380923
Validation loss: 3.4063250040551685

Epoch: 5| Step: 4
Training loss: 4.129119434465071
Validation loss: 3.40265311036566

Epoch: 5| Step: 5
Training loss: 3.532325513327515
Validation loss: 3.3985796200789395

Epoch: 5| Step: 6
Training loss: 3.445136448520694
Validation loss: 3.3946676047637983

Epoch: 5| Step: 7
Training loss: 3.8305899021845526
Validation loss: 3.390610394541608

Epoch: 5| Step: 8
Training loss: 3.1023483241750465
Validation loss: 3.386963506563953

Epoch: 5| Step: 9
Training loss: 3.814841880071347
Validation loss: 3.383199257065361

Epoch: 5| Step: 10
Training loss: 3.5745258470359293
Validation loss: 3.3795619321068764

Epoch: 5| Step: 11
Training loss: 2.7139059299422903
Validation loss: 3.3757407764756207

Epoch: 44| Step: 0
Training loss: 3.5763284095827212
Validation loss: 3.37205821032451

Epoch: 5| Step: 1
Training loss: 3.420699801764116
Validation loss: 3.3683278187869115

Epoch: 5| Step: 2
Training loss: 2.809356713155905
Validation loss: 3.3645369208631517

Epoch: 5| Step: 3
Training loss: 3.3657767400653364
Validation loss: 3.361250086456067

Epoch: 5| Step: 4
Training loss: 3.441887292571566
Validation loss: 3.3575891701244234

Epoch: 5| Step: 5
Training loss: 3.910021616688167
Validation loss: 3.353890150925913

Epoch: 5| Step: 6
Training loss: 3.9094383960343584
Validation loss: 3.350269954631743

Epoch: 5| Step: 7
Training loss: 3.7596436161209827
Validation loss: 3.3465824608417227

Epoch: 5| Step: 8
Training loss: 3.529765804616081
Validation loss: 3.342579984513943

Epoch: 5| Step: 9
Training loss: 3.524387679790073
Validation loss: 3.339175053628725

Epoch: 5| Step: 10
Training loss: 3.043868395874133
Validation loss: 3.335629880064235

Epoch: 5| Step: 11
Training loss: 3.390077326970126
Validation loss: 3.331847745933831

Epoch: 45| Step: 0
Training loss: 3.435197371097264
Validation loss: 3.3281656540371123

Epoch: 5| Step: 1
Training loss: 3.486390356368601
Validation loss: 3.3246731714608666

Epoch: 5| Step: 2
Training loss: 4.17637819853252
Validation loss: 3.321087573971566

Epoch: 5| Step: 3
Training loss: 3.082355206655313
Validation loss: 3.3172143042342883

Epoch: 5| Step: 4
Training loss: 3.0794941137436895
Validation loss: 3.3136673585776326

Epoch: 5| Step: 5
Training loss: 2.9167731311077403
Validation loss: 3.3099255364158475

Epoch: 5| Step: 6
Training loss: 3.7149269263164646
Validation loss: 3.3064376309089454

Epoch: 5| Step: 7
Training loss: 3.9511514796109175
Validation loss: 3.303034688484286

Epoch: 5| Step: 8
Training loss: 2.4351721186972934
Validation loss: 3.2994625670214446

Epoch: 5| Step: 9
Training loss: 3.6581348223402004
Validation loss: 3.296287622903715

Epoch: 5| Step: 10
Training loss: 3.489426581814417
Validation loss: 3.2925546430235504

Epoch: 5| Step: 11
Training loss: 4.233351467624381
Validation loss: 3.289274817445185

Epoch: 46| Step: 0
Training loss: 3.6608757036621133
Validation loss: 3.285304891313274

Epoch: 5| Step: 1
Training loss: 3.5100491536059693
Validation loss: 3.2817230004789804

Epoch: 5| Step: 2
Training loss: 3.9392802740029094
Validation loss: 3.2781026550345986

Epoch: 5| Step: 3
Training loss: 2.955521030351848
Validation loss: 3.2743731476347153

Epoch: 5| Step: 4
Training loss: 2.916509097248122
Validation loss: 3.270780439414848

Epoch: 5| Step: 5
Training loss: 3.0198630166723346
Validation loss: 3.2672253813722283

Epoch: 5| Step: 6
Training loss: 3.498767226961444
Validation loss: 3.2638438780817065

Epoch: 5| Step: 7
Training loss: 3.8217012030572484
Validation loss: 3.2603995086088444

Epoch: 5| Step: 8
Training loss: 2.5424724510598327
Validation loss: 3.25690801370106

Epoch: 5| Step: 9
Training loss: 3.4119469833816627
Validation loss: 3.253707418667521

Epoch: 5| Step: 10
Training loss: 3.793779909119707
Validation loss: 3.250456423376754

Epoch: 5| Step: 11
Training loss: 3.960880918681795
Validation loss: 3.247030686827449

Epoch: 47| Step: 0
Training loss: 3.4216215135580756
Validation loss: 3.2433183283587805

Epoch: 5| Step: 1
Training loss: 3.126473499043638
Validation loss: 3.2394752034645826

Epoch: 5| Step: 2
Training loss: 3.5115145240949364
Validation loss: 3.235943731709977

Epoch: 5| Step: 3
Training loss: 3.925794853832151
Validation loss: 3.2323848111427758

Epoch: 5| Step: 4
Training loss: 3.7453510713719678
Validation loss: 3.228793554387631

Epoch: 5| Step: 5
Training loss: 3.051692343047741
Validation loss: 3.2249391919694603

Epoch: 5| Step: 6
Training loss: 2.711871159522895
Validation loss: 3.2212877978573338

Epoch: 5| Step: 7
Training loss: 3.160927507476173
Validation loss: 3.217894986856874

Epoch: 5| Step: 8
Training loss: 3.555765579563918
Validation loss: 3.214404404053441

Epoch: 5| Step: 9
Training loss: 3.666082740295342
Validation loss: 3.211167719400515

Epoch: 5| Step: 10
Training loss: 3.259798098905802
Validation loss: 3.207879626820873

Epoch: 5| Step: 11
Training loss: 1.4479645188289234
Validation loss: 3.2044865389437174

Epoch: 48| Step: 0
Training loss: 3.530082171945298
Validation loss: 3.2015611816423397

Epoch: 5| Step: 1
Training loss: 2.888298294227587
Validation loss: 3.198370194142367

Epoch: 5| Step: 2
Training loss: 3.3087773547971104
Validation loss: 3.195438559734021

Epoch: 5| Step: 3
Training loss: 3.1318112721198967
Validation loss: 3.192665657807857

Epoch: 5| Step: 4
Training loss: 3.2400471803974047
Validation loss: 3.189786910286329

Epoch: 5| Step: 5
Training loss: 3.761640411226733
Validation loss: 3.186957309999353

Epoch: 5| Step: 6
Training loss: 3.3574238633465607
Validation loss: 3.1840987914604195

Epoch: 5| Step: 7
Training loss: 3.13140791991607
Validation loss: 3.1812286516134027

Epoch: 5| Step: 8
Training loss: 2.879699846097381
Validation loss: 3.177992591612807

Epoch: 5| Step: 9
Training loss: 3.4150542819846024
Validation loss: 3.1752130955049536

Epoch: 5| Step: 10
Training loss: 3.6678078060570254
Validation loss: 3.1721705657604184

Epoch: 5| Step: 11
Training loss: 4.049757236693017
Validation loss: 3.168851611021193

Epoch: 49| Step: 0
Training loss: 3.2824434562281435
Validation loss: 3.166131737768607

Epoch: 5| Step: 1
Training loss: 3.3331470119537028
Validation loss: 3.162769081519507

Epoch: 5| Step: 2
Training loss: 3.95802793161214
Validation loss: 3.1599527363421496

Epoch: 5| Step: 3
Training loss: 2.935828362304683
Validation loss: 3.156761140634879

Epoch: 5| Step: 4
Training loss: 2.985156051927254
Validation loss: 3.1538590638167547

Epoch: 5| Step: 5
Training loss: 3.1549610489800117
Validation loss: 3.150776271310094

Epoch: 5| Step: 6
Training loss: 3.3622576034134304
Validation loss: 3.147705721945709

Epoch: 5| Step: 7
Training loss: 2.9638009027802124
Validation loss: 3.1447893435627683

Epoch: 5| Step: 8
Training loss: 3.2279058804883105
Validation loss: 3.1418053542436977

Epoch: 5| Step: 9
Training loss: 3.6411924779442777
Validation loss: 3.1390117974725475

Epoch: 5| Step: 10
Training loss: 2.9354731283359787
Validation loss: 3.13594589118234

Epoch: 5| Step: 11
Training loss: 4.464588067851342
Validation loss: 3.1331587177600357

Epoch: 50| Step: 0
Training loss: 3.22851665886818
Validation loss: 3.129882238014077

Epoch: 5| Step: 1
Training loss: 3.2240550941322326
Validation loss: 3.126523946473229

Epoch: 5| Step: 2
Training loss: 3.8567280823860064
Validation loss: 3.1235447833217136

Epoch: 5| Step: 3
Training loss: 2.872595071439413
Validation loss: 3.120481549610289

Epoch: 5| Step: 4
Training loss: 3.421181943897388
Validation loss: 3.1172736912079304

Epoch: 5| Step: 5
Training loss: 3.434212100579989
Validation loss: 3.1141506626009523

Epoch: 5| Step: 6
Training loss: 2.488051471251387
Validation loss: 3.1111735472961097

Epoch: 5| Step: 7
Training loss: 3.891837915305414
Validation loss: 3.108076747875412

Epoch: 5| Step: 8
Training loss: 3.1634685194301038
Validation loss: 3.105171304529114

Epoch: 5| Step: 9
Training loss: 2.775229119817041
Validation loss: 3.1021642925867052

Epoch: 5| Step: 10
Training loss: 3.1917712447627014
Validation loss: 3.099069959836614

Epoch: 5| Step: 11
Training loss: 3.253675290047611
Validation loss: 3.096281743252023

Epoch: 51| Step: 0
Training loss: 3.5885098939918425
Validation loss: 3.093424879516503

Epoch: 5| Step: 1
Training loss: 3.700021336468186
Validation loss: 3.0903157397354253

Epoch: 5| Step: 2
Training loss: 3.654793865063522
Validation loss: 3.0872665504919916

Epoch: 5| Step: 3
Training loss: 2.984492114899774
Validation loss: 3.084094457290374

Epoch: 5| Step: 4
Training loss: 3.081730314195444
Validation loss: 3.081145149108019

Epoch: 5| Step: 5
Training loss: 2.9555521683765145
Validation loss: 3.0781794380240988

Epoch: 5| Step: 6
Training loss: 3.0301138724908063
Validation loss: 3.075548932008783

Epoch: 5| Step: 7
Training loss: 3.376091674572417
Validation loss: 3.0724373341225757

Epoch: 5| Step: 8
Training loss: 2.8226976954893432
Validation loss: 3.0695342775483483

Epoch: 5| Step: 9
Training loss: 2.8196810282231626
Validation loss: 3.0667481833141825

Epoch: 5| Step: 10
Training loss: 3.2172759300999334
Validation loss: 3.0641495518020108

Epoch: 5| Step: 11
Training loss: 3.465712996278082
Validation loss: 3.061355925321774

Epoch: 52| Step: 0
Training loss: 3.0573600141866932
Validation loss: 3.058788061161087

Epoch: 5| Step: 1
Training loss: 3.2969032033283443
Validation loss: 3.0560618379706352

Epoch: 5| Step: 2
Training loss: 3.658289804974474
Validation loss: 3.053270848882846

Epoch: 5| Step: 3
Training loss: 3.0814763912575946
Validation loss: 3.050488573949874

Epoch: 5| Step: 4
Training loss: 2.801570850196049
Validation loss: 3.047767593186985

Epoch: 5| Step: 5
Training loss: 2.9575041741723007
Validation loss: 3.045183990595917

Epoch: 5| Step: 6
Training loss: 2.6581641088533168
Validation loss: 3.0426328585487306

Epoch: 5| Step: 7
Training loss: 2.745569561651096
Validation loss: 3.0400199591353716

Epoch: 5| Step: 8
Training loss: 3.380053234019714
Validation loss: 3.0378914140017885

Epoch: 5| Step: 9
Training loss: 3.401714840562969
Validation loss: 3.035327299413109

Epoch: 5| Step: 10
Training loss: 3.7985320066544936
Validation loss: 3.0327533323742233

Epoch: 5| Step: 11
Training loss: 3.2422320627114467
Validation loss: 3.0301094990218624

Epoch: 53| Step: 0
Training loss: 2.9707512785791557
Validation loss: 3.027783148266951

Epoch: 5| Step: 1
Training loss: 3.142123344142022
Validation loss: 3.025438492627981

Epoch: 5| Step: 2
Training loss: 3.1673392200686923
Validation loss: 3.0229691956782765

Epoch: 5| Step: 3
Training loss: 3.1421464110219848
Validation loss: 3.0206174389653575

Epoch: 5| Step: 4
Training loss: 3.569686333903994
Validation loss: 3.018180173136697

Epoch: 5| Step: 5
Training loss: 3.41748936370333
Validation loss: 3.015437863197974

Epoch: 5| Step: 6
Training loss: 2.6161033092771375
Validation loss: 3.0130700865961817

Epoch: 5| Step: 7
Training loss: 3.4226799283822724
Validation loss: 3.0106159109071187

Epoch: 5| Step: 8
Training loss: 3.035463845316822
Validation loss: 3.0082054244840366

Epoch: 5| Step: 9
Training loss: 3.2093503421775953
Validation loss: 3.0058512779491977

Epoch: 5| Step: 10
Training loss: 2.965013903734824
Validation loss: 3.0036017301172606

Epoch: 5| Step: 11
Training loss: 3.0856664610996556
Validation loss: 3.001329627362326

Epoch: 54| Step: 0
Training loss: 2.9160316502615586
Validation loss: 2.9992066003119944

Epoch: 5| Step: 1
Training loss: 2.768919797904772
Validation loss: 2.997219741160517

Epoch: 5| Step: 2
Training loss: 3.2861074188747676
Validation loss: 2.995283293245864

Epoch: 5| Step: 3
Training loss: 3.222056496037844
Validation loss: 2.9931183206320804

Epoch: 5| Step: 4
Training loss: 3.198314795215892
Validation loss: 2.9910960252695364

Epoch: 5| Step: 5
Training loss: 3.246309238814323
Validation loss: 2.9890250084495413

Epoch: 5| Step: 6
Training loss: 3.5024517191595868
Validation loss: 2.9870879173713667

Epoch: 5| Step: 7
Training loss: 3.0624694822698206
Validation loss: 2.9847249063943546

Epoch: 5| Step: 8
Training loss: 3.058779266304711
Validation loss: 2.982704647159894

Epoch: 5| Step: 9
Training loss: 3.1569267529414584
Validation loss: 2.980189292408662

Epoch: 5| Step: 10
Training loss: 3.0515810886330597
Validation loss: 2.9781008238743447

Epoch: 5| Step: 11
Training loss: 2.679645504636309
Validation loss: 2.9759823575027777

Epoch: 55| Step: 0
Training loss: 2.8799096355566727
Validation loss: 2.9737044235484795

Epoch: 5| Step: 1
Training loss: 3.160754926295546
Validation loss: 2.971698992839162

Epoch: 5| Step: 2
Training loss: 3.725212316414752
Validation loss: 2.9696937834362678

Epoch: 5| Step: 3
Training loss: 3.3205613704984556
Validation loss: 2.9676461794499285

Epoch: 5| Step: 4
Training loss: 3.447454984397302
Validation loss: 2.9654133902417255

Epoch: 5| Step: 5
Training loss: 2.994297170310325
Validation loss: 2.9632542654616274

Epoch: 5| Step: 6
Training loss: 2.6062804734897855
Validation loss: 2.960817470482992

Epoch: 5| Step: 7
Training loss: 3.527303600399615
Validation loss: 2.95900412239225

Epoch: 5| Step: 8
Training loss: 2.691505286355933
Validation loss: 2.9565902911976267

Epoch: 5| Step: 9
Training loss: 3.0403016219335117
Validation loss: 2.954501915907678

Epoch: 5| Step: 10
Training loss: 2.5477717406466662
Validation loss: 2.9525444731726167

Epoch: 5| Step: 11
Training loss: 3.0133987668902864
Validation loss: 2.949984237661116

Epoch: 56| Step: 0
Training loss: 3.807362330972917
Validation loss: 2.9481259845696686

Epoch: 5| Step: 1
Training loss: 3.144290132933581
Validation loss: 2.9461571066757513

Epoch: 5| Step: 2
Training loss: 3.0502568183712038
Validation loss: 2.9436365852186834

Epoch: 5| Step: 3
Training loss: 3.0722799040116366
Validation loss: 2.941523488390323

Epoch: 5| Step: 4
Training loss: 3.5142753214355693
Validation loss: 2.939624694345791

Epoch: 5| Step: 5
Training loss: 2.9183063439457926
Validation loss: 2.937319800754447

Epoch: 5| Step: 6
Training loss: 2.5033089673735467
Validation loss: 2.935345918431386

Epoch: 5| Step: 7
Training loss: 2.8285700832435303
Validation loss: 2.933376719052795

Epoch: 5| Step: 8
Training loss: 3.454506852194378
Validation loss: 2.931291319224439

Epoch: 5| Step: 9
Training loss: 2.778434271059186
Validation loss: 2.929431565019872

Epoch: 5| Step: 10
Training loss: 2.7189750139800752
Validation loss: 2.927516906275744

Epoch: 5| Step: 11
Training loss: 2.2956868945968396
Validation loss: 2.9256209230656025

Epoch: 57| Step: 0
Training loss: 2.810645276031072
Validation loss: 2.9234328035622377

Epoch: 5| Step: 1
Training loss: 3.509339813572351
Validation loss: 2.9218467806237074

Epoch: 5| Step: 2
Training loss: 3.174341905529889
Validation loss: 2.91997641828238

Epoch: 5| Step: 3
Training loss: 3.3084438609790556
Validation loss: 2.91780685663401

Epoch: 5| Step: 4
Training loss: 3.537634015998877
Validation loss: 2.9156030498031367

Epoch: 5| Step: 5
Training loss: 3.0886694295788346
Validation loss: 2.9133493660502756

Epoch: 5| Step: 6
Training loss: 2.6108981501081265
Validation loss: 2.911058300608435

Epoch: 5| Step: 7
Training loss: 2.465897662771949
Validation loss: 2.9089635431711605

Epoch: 5| Step: 8
Training loss: 2.942657326225295
Validation loss: 2.9068544811978243

Epoch: 5| Step: 9
Training loss: 3.1186805916135953
Validation loss: 2.904665364548239

Epoch: 5| Step: 10
Training loss: 3.0016233502583907
Validation loss: 2.9028919227695003

Epoch: 5| Step: 11
Training loss: 2.3799333030907914
Validation loss: 2.9010593452576994

Epoch: 58| Step: 0
Training loss: 3.4083091741201534
Validation loss: 2.899277026530377

Epoch: 5| Step: 1
Training loss: 2.800487295390623
Validation loss: 2.897382991656483

Epoch: 5| Step: 2
Training loss: 3.302793713199582
Validation loss: 2.8954744162303445

Epoch: 5| Step: 3
Training loss: 3.3165677124546074
Validation loss: 2.8938555836210935

Epoch: 5| Step: 4
Training loss: 2.8485593266468503
Validation loss: 2.8918685849917423

Epoch: 5| Step: 5
Training loss: 3.02149936743816
Validation loss: 2.8900035843172476

Epoch: 5| Step: 6
Training loss: 2.486747424661145
Validation loss: 2.8883441105465613

Epoch: 5| Step: 7
Training loss: 3.097965027859865
Validation loss: 2.886544314815148

Epoch: 5| Step: 8
Training loss: 2.945913238376927
Validation loss: 2.8846782067582106

Epoch: 5| Step: 9
Training loss: 3.2733870982657662
Validation loss: 2.882784680488149

Epoch: 5| Step: 10
Training loss: 2.7390434303642635
Validation loss: 2.880961926030482

Epoch: 5| Step: 11
Training loss: 2.938349986369054
Validation loss: 2.8791442696785468

Epoch: 59| Step: 0
Training loss: 3.1290717491928306
Validation loss: 2.8773245915867722

Epoch: 5| Step: 1
Training loss: 2.8219229625457474
Validation loss: 2.875571474001245

Epoch: 5| Step: 2
Training loss: 3.2856633614805375
Validation loss: 2.87395682275522

Epoch: 5| Step: 3
Training loss: 3.045590330381001
Validation loss: 2.8722357314800706

Epoch: 5| Step: 4
Training loss: 2.930098929443872
Validation loss: 2.8703547696631913

Epoch: 5| Step: 5
Training loss: 3.174992424663007
Validation loss: 2.868585192171701

Epoch: 5| Step: 6
Training loss: 2.781152102001135
Validation loss: 2.8670709986495986

Epoch: 5| Step: 7
Training loss: 2.9041014902544715
Validation loss: 2.8653340667945852

Epoch: 5| Step: 8
Training loss: 2.45683532807027
Validation loss: 2.863602030897133

Epoch: 5| Step: 9
Training loss: 3.3743750382105624
Validation loss: 2.861795672341741

Epoch: 5| Step: 10
Training loss: 3.244880311754174
Validation loss: 2.8599887703350544

Epoch: 5| Step: 11
Training loss: 2.1750888236313557
Validation loss: 2.8584212673793

Epoch: 60| Step: 0
Training loss: 3.2445311383055153
Validation loss: 2.8563677359368667

Epoch: 5| Step: 1
Training loss: 2.7464928370933945
Validation loss: 2.854678293765569

Epoch: 5| Step: 2
Training loss: 2.715814694011628
Validation loss: 2.8530326711333007

Epoch: 5| Step: 3
Training loss: 3.4615830622351
Validation loss: 2.85127118508199

Epoch: 5| Step: 4
Training loss: 2.784017150694537
Validation loss: 2.849173404635056

Epoch: 5| Step: 5
Training loss: 2.6083409436229634
Validation loss: 2.847594097838903

Epoch: 5| Step: 6
Training loss: 2.7604888810602506
Validation loss: 2.845899461245076

Epoch: 5| Step: 7
Training loss: 2.7450664655354924
Validation loss: 2.84598699902317

Epoch: 5| Step: 8
Training loss: 2.963913682450385
Validation loss: 2.859493972304385

Epoch: 5| Step: 9
Training loss: 3.2997486192151375
Validation loss: 2.840301214467058

Epoch: 5| Step: 10
Training loss: 3.447888853454584
Validation loss: 2.838978211784533

Epoch: 5| Step: 11
Training loss: 2.8037433363299153
Validation loss: 2.8380863851163123

Epoch: 61| Step: 0
Training loss: 2.9958298627880158
Validation loss: 2.8398864057259154

Epoch: 5| Step: 1
Training loss: 3.302949633314502
Validation loss: 2.8366586137927006

Epoch: 5| Step: 2
Training loss: 2.5514493712781285
Validation loss: 2.833262009050175

Epoch: 5| Step: 3
Training loss: 3.0651604132189636
Validation loss: 2.831504460591674

Epoch: 5| Step: 4
Training loss: 3.0176321672952002
Validation loss: 2.82994337618921

Epoch: 5| Step: 5
Training loss: 3.167811454508604
Validation loss: 2.8288366641216403

Epoch: 5| Step: 6
Training loss: 2.9172749747844167
Validation loss: 2.8274855830496497

Epoch: 5| Step: 7
Training loss: 2.6277202861573214
Validation loss: 2.8256710393448876

Epoch: 5| Step: 8
Training loss: 3.2859136953321504
Validation loss: 2.8236654116797726

Epoch: 5| Step: 9
Training loss: 2.697848069977107
Validation loss: 2.8216264293488296

Epoch: 5| Step: 10
Training loss: 3.143582901201442
Validation loss: 2.820590663306174

Epoch: 5| Step: 11
Training loss: 1.8245742745474776
Validation loss: 2.8193764018057617

Epoch: 62| Step: 0
Training loss: 3.3154880793827037
Validation loss: 2.8180504777431308

Epoch: 5| Step: 1
Training loss: 2.8957945091517456
Validation loss: 2.816377263089732

Epoch: 5| Step: 2
Training loss: 2.8906756422400863
Validation loss: 2.814826289368153

Epoch: 5| Step: 3
Training loss: 3.214267757910572
Validation loss: 2.812744048797665

Epoch: 5| Step: 4
Training loss: 2.9096839880018206
Validation loss: 2.811081680549847

Epoch: 5| Step: 5
Training loss: 2.5804153903453138
Validation loss: 2.809720364743537

Epoch: 5| Step: 6
Training loss: 2.8338543095045585
Validation loss: 2.808673417151242

Epoch: 5| Step: 7
Training loss: 2.9436171127097683
Validation loss: 2.806206216732539

Epoch: 5| Step: 8
Training loss: 3.0528782318251824
Validation loss: 2.8038273362769415

Epoch: 5| Step: 9
Training loss: 2.9753655858167574
Validation loss: 2.8020047185049415

Epoch: 5| Step: 10
Training loss: 2.836864309481967
Validation loss: 2.8003611229582215

Epoch: 5| Step: 11
Training loss: 2.88088800965642
Validation loss: 2.7992097000428613

Epoch: 63| Step: 0
Training loss: 2.8290794827301147
Validation loss: 2.797652997687284

Epoch: 5| Step: 1
Training loss: 2.8918988694359493
Validation loss: 2.7962578993111475

Epoch: 5| Step: 2
Training loss: 3.032937592762066
Validation loss: 2.7946692316339123

Epoch: 5| Step: 3
Training loss: 3.3825658131221243
Validation loss: 2.793034063255805

Epoch: 5| Step: 4
Training loss: 2.6933744235099
Validation loss: 2.7910298729068606

Epoch: 5| Step: 5
Training loss: 2.457949225811526
Validation loss: 2.790637884790194

Epoch: 5| Step: 6
Training loss: 2.8669653034645415
Validation loss: 2.789005489105061

Epoch: 5| Step: 7
Training loss: 3.067292336893936
Validation loss: 2.7875985685520637

Epoch: 5| Step: 8
Training loss: 2.9349510009418704
Validation loss: 2.7861956475525522

Epoch: 5| Step: 9
Training loss: 2.8247713891085624
Validation loss: 2.7850398805766012

Epoch: 5| Step: 10
Training loss: 3.252335809408845
Validation loss: 2.7836408411454285

Epoch: 5| Step: 11
Training loss: 2.5715108472286388
Validation loss: 2.7820006225579754

Epoch: 64| Step: 0
Training loss: 3.296547100520438
Validation loss: 2.7805722836080076

Epoch: 5| Step: 1
Training loss: 2.8442472924347597
Validation loss: 2.779499671169508

Epoch: 5| Step: 2
Training loss: 2.6904130273985083
Validation loss: 2.778238037178361

Epoch: 5| Step: 3
Training loss: 3.1253576455499705
Validation loss: 2.7764982965646063

Epoch: 5| Step: 4
Training loss: 2.9625751727260417
Validation loss: 2.775114081016746

Epoch: 5| Step: 5
Training loss: 2.955641547205345
Validation loss: 2.7728961469969144

Epoch: 5| Step: 6
Training loss: 2.921969162346784
Validation loss: 2.7718498485446217

Epoch: 5| Step: 7
Training loss: 3.0876352010306456
Validation loss: 2.770355320811288

Epoch: 5| Step: 8
Training loss: 2.6338146803942757
Validation loss: 2.768941740310093

Epoch: 5| Step: 9
Training loss: 2.7051107356450403
Validation loss: 2.7678981641726867

Epoch: 5| Step: 10
Training loss: 2.6459017967517613
Validation loss: 2.7664534626432937

Epoch: 5| Step: 11
Training loss: 3.559686855088046
Validation loss: 2.7651440512939245

Epoch: 65| Step: 0
Training loss: 3.175233613077883
Validation loss: 2.76396864520919

Epoch: 5| Step: 1
Training loss: 2.949726551119509
Validation loss: 2.7620355585335887

Epoch: 5| Step: 2
Training loss: 3.032865113672135
Validation loss: 2.760871969617245

Epoch: 5| Step: 3
Training loss: 3.0743676504600606
Validation loss: 2.7596688403206913

Epoch: 5| Step: 4
Training loss: 2.278107765247682
Validation loss: 2.7583206292193103

Epoch: 5| Step: 5
Training loss: 2.9043919355975296
Validation loss: 2.7564000266916895

Epoch: 5| Step: 6
Training loss: 3.3378104819134635
Validation loss: 2.7552891895470095

Epoch: 5| Step: 7
Training loss: 2.7385289492383773
Validation loss: 2.7538700940078615

Epoch: 5| Step: 8
Training loss: 2.97227156727869
Validation loss: 2.752878759444667

Epoch: 5| Step: 9
Training loss: 2.603206630493892
Validation loss: 2.751818005412534

Epoch: 5| Step: 10
Training loss: 2.7710280577038606
Validation loss: 2.7590904264786253

Epoch: 5| Step: 11
Training loss: 2.5373441075136185
Validation loss: 2.7581692069589776

Epoch: 66| Step: 0
Training loss: 3.1900174540457766
Validation loss: 2.757142090832613

Epoch: 5| Step: 1
Training loss: 2.6187680155059296
Validation loss: 2.750035119554931

Epoch: 5| Step: 2
Training loss: 3.026142024588158
Validation loss: 2.746315156305221

Epoch: 5| Step: 3
Training loss: 2.582830585247953
Validation loss: 2.746268392103951

Epoch: 5| Step: 4
Training loss: 3.1845201513509616
Validation loss: 2.74830298370189

Epoch: 5| Step: 5
Training loss: 2.4680677026399525
Validation loss: 2.7559964916165853

Epoch: 5| Step: 6
Training loss: 2.928907773843462
Validation loss: 2.75657781062977

Epoch: 5| Step: 7
Training loss: 3.069868759431627
Validation loss: 2.7485885646553507

Epoch: 5| Step: 8
Training loss: 2.7042777189033362
Validation loss: 2.7448058601509464

Epoch: 5| Step: 9
Training loss: 2.9466297229620086
Validation loss: 2.7414933763445233

Epoch: 5| Step: 10
Training loss: 2.845639449999689
Validation loss: 2.7394734506847076

Epoch: 5| Step: 11
Training loss: 3.423753057550219
Validation loss: 2.738036410949137

Epoch: 67| Step: 0
Training loss: 2.774533079576069
Validation loss: 2.736852849240714

Epoch: 5| Step: 1
Training loss: 3.2954205382694104
Validation loss: 2.7351109122940978

Epoch: 5| Step: 2
Training loss: 2.9190913521513147
Validation loss: 2.7330957199436945

Epoch: 5| Step: 3
Training loss: 3.1667005302893982
Validation loss: 2.73190022693356

Epoch: 5| Step: 4
Training loss: 2.6620113945308
Validation loss: 2.730403206274613

Epoch: 5| Step: 5
Training loss: 2.334277223227076
Validation loss: 2.728859867197215

Epoch: 5| Step: 6
Training loss: 3.4291895893824824
Validation loss: 2.7280994189775587

Epoch: 5| Step: 7
Training loss: 2.810684889956301
Validation loss: 2.726793270309985

Epoch: 5| Step: 8
Training loss: 2.823963961049805
Validation loss: 2.724732004047129

Epoch: 5| Step: 9
Training loss: 2.7992161164416425
Validation loss: 2.7230944980865215

Epoch: 5| Step: 10
Training loss: 2.5101103430882796
Validation loss: 2.722372473546028

Epoch: 5| Step: 11
Training loss: 2.20442734771084
Validation loss: 2.7211774169372456

Epoch: 68| Step: 0
Training loss: 2.7584616785836187
Validation loss: 2.7203389745859536

Epoch: 5| Step: 1
Training loss: 2.421397894348706
Validation loss: 2.718931703597615

Epoch: 5| Step: 2
Training loss: 2.6512188105927104
Validation loss: 2.717799904946065

Epoch: 5| Step: 3
Training loss: 2.858457657878592
Validation loss: 2.7171210199156612

Epoch: 5| Step: 4
Training loss: 2.9287529433883224
Validation loss: 2.716354249959903

Epoch: 5| Step: 5
Training loss: 2.841001754636669
Validation loss: 2.714995272499404

Epoch: 5| Step: 6
Training loss: 2.8177422728877204
Validation loss: 2.713819509084891

Epoch: 5| Step: 7
Training loss: 3.1248945599887628
Validation loss: 2.7143797333825614

Epoch: 5| Step: 8
Training loss: 2.584320761539277
Validation loss: 2.7134526702481394

Epoch: 5| Step: 9
Training loss: 3.013894647064412
Validation loss: 2.7129438526414518

Epoch: 5| Step: 10
Training loss: 3.206033865204238
Validation loss: 2.71219411303051

Epoch: 5| Step: 11
Training loss: 3.466285998889681
Validation loss: 2.712158569405506

Epoch: 69| Step: 0
Training loss: 2.0127280064666304
Validation loss: 2.7107067248117334

Epoch: 5| Step: 1
Training loss: 2.991642436688272
Validation loss: 2.7124211468346724

Epoch: 5| Step: 2
Training loss: 2.7678234608090664
Validation loss: 2.712641804148379

Epoch: 5| Step: 3
Training loss: 3.0770193525070857
Validation loss: 2.71280166703497

Epoch: 5| Step: 4
Training loss: 2.7298339629771595
Validation loss: 2.709520209504629

Epoch: 5| Step: 5
Training loss: 3.08866232796599
Validation loss: 2.7056108117798177

Epoch: 5| Step: 6
Training loss: 3.1972723362502107
Validation loss: 2.704334969467843

Epoch: 5| Step: 7
Training loss: 2.565130325932734
Validation loss: 2.7023045538759507

Epoch: 5| Step: 8
Training loss: 2.7722805135132824
Validation loss: 2.7011123617571147

Epoch: 5| Step: 9
Training loss: 2.8364860907821643
Validation loss: 2.70051248905336

Epoch: 5| Step: 10
Training loss: 2.903495713987713
Validation loss: 2.6991219215672895

Epoch: 5| Step: 11
Training loss: 3.6428562906942785
Validation loss: 2.6987958025583003

Epoch: 70| Step: 0
Training loss: 3.1074493426170524
Validation loss: 2.696521078957154

Epoch: 5| Step: 1
Training loss: 2.511887896168434
Validation loss: 2.6944115538135414

Epoch: 5| Step: 2
Training loss: 3.2087573146996755
Validation loss: 2.6936814869593078

Epoch: 5| Step: 3
Training loss: 3.05859156738827
Validation loss: 2.6915875998026135

Epoch: 5| Step: 4
Training loss: 3.032672037274876
Validation loss: 2.689765474331143

Epoch: 5| Step: 5
Training loss: 2.885129581496534
Validation loss: 2.6885457850388605

Epoch: 5| Step: 6
Training loss: 2.3339542402931706
Validation loss: 2.687000279948413

Epoch: 5| Step: 7
Training loss: 2.577895368117407
Validation loss: 2.6864536895258215

Epoch: 5| Step: 8
Training loss: 2.808095407642057
Validation loss: 2.6852819952528226

Epoch: 5| Step: 9
Training loss: 2.942810128850955
Validation loss: 2.6848571002483763

Epoch: 5| Step: 10
Training loss: 2.611712111528263
Validation loss: 2.6828761948385846

Epoch: 5| Step: 11
Training loss: 2.5795981157738135
Validation loss: 2.6830795772785394

Epoch: 71| Step: 0
Training loss: 3.0031673876959486
Validation loss: 2.6822507552696564

Epoch: 5| Step: 1
Training loss: 2.64502615643496
Validation loss: 2.6823235494453304

Epoch: 5| Step: 2
Training loss: 2.823119227800597
Validation loss: 2.6816771991677797

Epoch: 5| Step: 3
Training loss: 2.6018035135521522
Validation loss: 2.6816893904461914

Epoch: 5| Step: 4
Training loss: 3.0329363350052083
Validation loss: 2.681214463799484

Epoch: 5| Step: 5
Training loss: 3.0105972675854162
Validation loss: 2.6807143428420543

Epoch: 5| Step: 6
Training loss: 2.5284504420451706
Validation loss: 2.680250114345557

Epoch: 5| Step: 7
Training loss: 2.54069058379373
Validation loss: 2.678864170002435

Epoch: 5| Step: 8
Training loss: 2.9014178065888947
Validation loss: 2.6785040115016407

Epoch: 5| Step: 9
Training loss: 2.7250190454219942
Validation loss: 2.677561414211975

Epoch: 5| Step: 10
Training loss: 3.0467278860718063
Validation loss: 2.6763880169335907

Epoch: 5| Step: 11
Training loss: 3.345410371477447
Validation loss: 2.6752283272195236

Epoch: 72| Step: 0
Training loss: 2.4488999252028343
Validation loss: 2.674062015993616

Epoch: 5| Step: 1
Training loss: 3.185174729661103
Validation loss: 2.6737542375563987

Epoch: 5| Step: 2
Training loss: 2.737870777399436
Validation loss: 2.671208467685759

Epoch: 5| Step: 3
Training loss: 3.1034537057719467
Validation loss: 2.6711345524073593

Epoch: 5| Step: 4
Training loss: 2.6774182734763388
Validation loss: 2.6693015244122904

Epoch: 5| Step: 5
Training loss: 2.7302039895331798
Validation loss: 2.6673936386914736

Epoch: 5| Step: 6
Training loss: 3.011750098633054
Validation loss: 2.6672134410071155

Epoch: 5| Step: 7
Training loss: 2.887585996197691
Validation loss: 2.66457126044033

Epoch: 5| Step: 8
Training loss: 2.885764164203542
Validation loss: 2.66423708286801

Epoch: 5| Step: 9
Training loss: 2.359367117963345
Validation loss: 2.673778543692959

Epoch: 5| Step: 10
Training loss: 2.9067567773144316
Validation loss: 2.684771609215256

Epoch: 5| Step: 11
Training loss: 2.2590667514336227
Validation loss: 2.6677732903376015

Epoch: 73| Step: 0
Training loss: 2.9738015012703047
Validation loss: 2.6605246088588554

Epoch: 5| Step: 1
Training loss: 2.1939812693183205
Validation loss: 2.660065102754514

Epoch: 5| Step: 2
Training loss: 2.7705808730067507
Validation loss: 2.662345717143362

Epoch: 5| Step: 3
Training loss: 2.8251121026136263
Validation loss: 2.6622768656339644

Epoch: 5| Step: 4
Training loss: 2.810393667916392
Validation loss: 2.6629899887446373

Epoch: 5| Step: 5
Training loss: 3.6446143301339142
Validation loss: 2.6628029345014634

Epoch: 5| Step: 6
Training loss: 2.975468632307883
Validation loss: 2.663098877876642

Epoch: 5| Step: 7
Training loss: 2.889470380149066
Validation loss: 2.662281492606729

Epoch: 5| Step: 8
Training loss: 2.5203292174473653
Validation loss: 2.6621641553176225

Epoch: 5| Step: 9
Training loss: 2.511979013962767
Validation loss: 2.6614536253009717

Epoch: 5| Step: 10
Training loss: 2.464565352059619
Validation loss: 2.6607532662187596

Epoch: 5| Step: 11
Training loss: 2.679871844743335
Validation loss: 2.6599013159248273

Epoch: 74| Step: 0
Training loss: 2.6707582872850106
Validation loss: 2.6601185770303357

Epoch: 5| Step: 1
Training loss: 3.086531724335123
Validation loss: 2.658695355690602

Epoch: 5| Step: 2
Training loss: 2.572420872990388
Validation loss: 2.6579124297340337

Epoch: 5| Step: 3
Training loss: 2.833030703221034
Validation loss: 2.658036928682904

Epoch: 5| Step: 4
Training loss: 2.3210322743957312
Validation loss: 2.6562275904289843

Epoch: 5| Step: 5
Training loss: 2.699508894302121
Validation loss: 2.655514660197383

Epoch: 5| Step: 6
Training loss: 2.627262956577695
Validation loss: 2.654705963908786

Epoch: 5| Step: 7
Training loss: 2.8810982091147057
Validation loss: 2.654241254877326

Epoch: 5| Step: 8
Training loss: 2.9532412551521783
Validation loss: 2.6529463250661416

Epoch: 5| Step: 9
Training loss: 2.670644287068298
Validation loss: 2.652312932610264

Epoch: 5| Step: 10
Training loss: 3.244983469446336
Validation loss: 2.650785940960444

Epoch: 5| Step: 11
Training loss: 3.11937374994692
Validation loss: 2.6505413120343437

Epoch: 75| Step: 0
Training loss: 2.4780739585363127
Validation loss: 2.6493069582216466

Epoch: 5| Step: 1
Training loss: 2.9826850300364134
Validation loss: 2.6486410177198585

Epoch: 5| Step: 2
Training loss: 2.858970405011811
Validation loss: 2.647166889764762

Epoch: 5| Step: 3
Training loss: 2.814321140262743
Validation loss: 2.6468136891031473

Epoch: 5| Step: 4
Training loss: 2.7805673854532613
Validation loss: 2.6455812309087676

Epoch: 5| Step: 5
Training loss: 2.8416992170719997
Validation loss: 2.644918660383666

Epoch: 5| Step: 6
Training loss: 2.8651301931255357
Validation loss: 2.643791497207714

Epoch: 5| Step: 7
Training loss: 3.1142097342635635
Validation loss: 2.6424650556683265

Epoch: 5| Step: 8
Training loss: 2.4806814508029174
Validation loss: 2.6413820750211396

Epoch: 5| Step: 9
Training loss: 2.5883580429885686
Validation loss: 2.640511974948041

Epoch: 5| Step: 10
Training loss: 2.6872673821135087
Validation loss: 2.6398255381351565

Epoch: 5| Step: 11
Training loss: 3.1308098763534904
Validation loss: 2.639556318645137

Epoch: 76| Step: 0
Training loss: 2.907451094316932
Validation loss: 2.637871275136529

Epoch: 5| Step: 1
Training loss: 2.7585540725417137
Validation loss: 2.6350986938494123

Epoch: 5| Step: 2
Training loss: 2.8214549447977513
Validation loss: 2.634965591628255

Epoch: 5| Step: 3
Training loss: 2.9292877331418223
Validation loss: 2.634500748969258

Epoch: 5| Step: 4
Training loss: 2.7215906846543554
Validation loss: 2.6369696490689707

Epoch: 5| Step: 5
Training loss: 2.771104287879509
Validation loss: 2.632896478598397

Epoch: 5| Step: 6
Training loss: 2.948983654226572
Validation loss: 2.6334472140201726

Epoch: 5| Step: 7
Training loss: 2.516148104094487
Validation loss: 2.634303405651654

Epoch: 5| Step: 8
Training loss: 2.7448425481279743
Validation loss: 2.6350984733091676

Epoch: 5| Step: 9
Training loss: 2.8547627924034447
Validation loss: 2.6353040276581994

Epoch: 5| Step: 10
Training loss: 2.7827950804227832
Validation loss: 2.6357784525508388

Epoch: 5| Step: 11
Training loss: 1.25070633005645
Validation loss: 2.63620823945416

Epoch: 77| Step: 0
Training loss: 2.3716084206086605
Validation loss: 2.6438667330210217

Epoch: 5| Step: 1
Training loss: 2.6204283732462454
Validation loss: 2.6469825679234833

Epoch: 5| Step: 2
Training loss: 2.600770388689678
Validation loss: 2.6388743276082787

Epoch: 5| Step: 3
Training loss: 3.0435420660474355
Validation loss: 2.6342707782671795

Epoch: 5| Step: 4
Training loss: 2.5142723854132747
Validation loss: 2.6330193307231937

Epoch: 5| Step: 5
Training loss: 2.9671964093838397
Validation loss: 2.6311131812532205

Epoch: 5| Step: 6
Training loss: 3.14863498721507
Validation loss: 2.6309432762340252

Epoch: 5| Step: 7
Training loss: 2.7071721644420195
Validation loss: 2.6298447889621688

Epoch: 5| Step: 8
Training loss: 2.9472080273116115
Validation loss: 2.6290299498432597

Epoch: 5| Step: 9
Training loss: 2.843504507346662
Validation loss: 2.6280903185333786

Epoch: 5| Step: 10
Training loss: 2.844829144970697
Validation loss: 2.627869849986829

Epoch: 5| Step: 11
Training loss: 1.3310279087834977
Validation loss: 2.6262101683878623

Epoch: 78| Step: 0
Training loss: 2.6338444620146895
Validation loss: 2.625461329687826

Epoch: 5| Step: 1
Training loss: 3.039573959813733
Validation loss: 2.6251421579590053

Epoch: 5| Step: 2
Training loss: 2.437781391040663
Validation loss: 2.6238502300467705

Epoch: 5| Step: 3
Training loss: 2.8598782456097522
Validation loss: 2.62365397502492

Epoch: 5| Step: 4
Training loss: 2.9512665567414325
Validation loss: 2.6232508137212496

Epoch: 5| Step: 5
Training loss: 2.9564201902794025
Validation loss: 2.622197683829278

Epoch: 5| Step: 6
Training loss: 2.410904680029923
Validation loss: 2.6224880499032643

Epoch: 5| Step: 7
Training loss: 2.9342129761120903
Validation loss: 2.620610669678593

Epoch: 5| Step: 8
Training loss: 2.6758715092270076
Validation loss: 2.6201472120144134

Epoch: 5| Step: 9
Training loss: 2.8142220205688617
Validation loss: 2.619591697103907

Epoch: 5| Step: 10
Training loss: 2.796976780238244
Validation loss: 2.619545840996269

Epoch: 5| Step: 11
Training loss: 1.467037907490935
Validation loss: 2.6191136953556295

Epoch: 79| Step: 0
Training loss: 2.5153915581285444
Validation loss: 2.6181286272655355

Epoch: 5| Step: 1
Training loss: 2.7769641214373815
Validation loss: 2.617981846145876

Epoch: 5| Step: 2
Training loss: 2.9544842533628675
Validation loss: 2.61781453075211

Epoch: 5| Step: 3
Training loss: 2.869310471381018
Validation loss: 2.6170274068728374

Epoch: 5| Step: 4
Training loss: 2.886701570906258
Validation loss: 2.616575513049784

Epoch: 5| Step: 5
Training loss: 2.749068362477053
Validation loss: 2.616035481172952

Epoch: 5| Step: 6
Training loss: 2.5826760553134522
Validation loss: 2.6160152144230246

Epoch: 5| Step: 7
Training loss: 2.4343090200236004
Validation loss: 2.614996168262648

Epoch: 5| Step: 8
Training loss: 2.790268752030372
Validation loss: 2.613436167353743

Epoch: 5| Step: 9
Training loss: 2.601180773157132
Validation loss: 2.6125869855134174

Epoch: 5| Step: 10
Training loss: 3.0255539063830423
Validation loss: 2.612206375316129

Epoch: 5| Step: 11
Training loss: 3.077566957961647
Validation loss: 2.6109609524069084

Epoch: 80| Step: 0
Training loss: 2.366317438050282
Validation loss: 2.6116338839499056

Epoch: 5| Step: 1
Training loss: 2.9846742489959652
Validation loss: 2.610345560969132

Epoch: 5| Step: 2
Training loss: 2.53376851945008
Validation loss: 2.6111826736087966

Epoch: 5| Step: 3
Training loss: 3.063900530014757
Validation loss: 2.609531043863354

Epoch: 5| Step: 4
Training loss: 2.6494098330055165
Validation loss: 2.6071580617651664

Epoch: 5| Step: 5
Training loss: 2.521002950295126
Validation loss: 2.6069374272595236

Epoch: 5| Step: 6
Training loss: 3.0101315760448975
Validation loss: 2.606147155440176

Epoch: 5| Step: 7
Training loss: 2.78151495882298
Validation loss: 2.6067649023170847

Epoch: 5| Step: 8
Training loss: 2.954430024353061
Validation loss: 2.6050420599499398

Epoch: 5| Step: 9
Training loss: 2.6826964631533565
Validation loss: 2.6038584882855975

Epoch: 5| Step: 10
Training loss: 2.6783198211208803
Validation loss: 2.6037950339583804

Epoch: 5| Step: 11
Training loss: 2.1698990210317644
Validation loss: 2.6037518526944536

Epoch: 81| Step: 0
Training loss: 2.3914659803595963
Validation loss: 2.6050182488754725

Epoch: 5| Step: 1
Training loss: 2.9200487600462024
Validation loss: 2.6016571096452066

Epoch: 5| Step: 2
Training loss: 2.925244352127412
Validation loss: 2.603081558493972

Epoch: 5| Step: 3
Training loss: 2.6474904755591226
Validation loss: 2.59878232254177

Epoch: 5| Step: 4
Training loss: 2.2823707231426904
Validation loss: 2.600194397560856

Epoch: 5| Step: 5
Training loss: 3.0689451944150523
Validation loss: 2.6022078369526023

Epoch: 5| Step: 6
Training loss: 2.4452383986875423
Validation loss: 2.6001289167599477

Epoch: 5| Step: 7
Training loss: 2.5508958402309414
Validation loss: 2.5961122058905377

Epoch: 5| Step: 8
Training loss: 3.2735499542512736
Validation loss: 2.5978607976780035

Epoch: 5| Step: 9
Training loss: 2.7186290670223547
Validation loss: 2.595828085619019

Epoch: 5| Step: 10
Training loss: 2.7639941563413375
Validation loss: 2.596466273747869

Epoch: 5| Step: 11
Training loss: 2.5554409024416085
Validation loss: 2.597017195259457

Epoch: 82| Step: 0
Training loss: 2.649776154186871
Validation loss: 2.5980014695921283

Epoch: 5| Step: 1
Training loss: 2.804107521041764
Validation loss: 2.59824569248075

Epoch: 5| Step: 2
Training loss: 2.7922894271920917
Validation loss: 2.59897792913252

Epoch: 5| Step: 3
Training loss: 2.373951429485634
Validation loss: 2.599213732221641

Epoch: 5| Step: 4
Training loss: 2.2989021749569885
Validation loss: 2.599060787915725

Epoch: 5| Step: 5
Training loss: 2.3610426712090096
Validation loss: 2.5979301900952687

Epoch: 5| Step: 6
Training loss: 3.2181766332654127
Validation loss: 2.597828129409659

Epoch: 5| Step: 7
Training loss: 2.893014940536428
Validation loss: 2.597605536020806

Epoch: 5| Step: 8
Training loss: 2.4320787640227444
Validation loss: 2.5959701152011037

Epoch: 5| Step: 9
Training loss: 3.035303453486741
Validation loss: 2.5953952251725907

Epoch: 5| Step: 10
Training loss: 2.9583205281011833
Validation loss: 2.594152966951378

Epoch: 5| Step: 11
Training loss: 3.237827688004263
Validation loss: 2.5942551147826163

Epoch: 83| Step: 0
Training loss: 2.7906404193652956
Validation loss: 2.5927900659826553

Epoch: 5| Step: 1
Training loss: 2.8150607848846203
Validation loss: 2.5927351839221364

Epoch: 5| Step: 2
Training loss: 2.805679528379319
Validation loss: 2.5907331294558005

Epoch: 5| Step: 3
Training loss: 2.3287330191909956
Validation loss: 2.590195951683536

Epoch: 5| Step: 4
Training loss: 2.8864375946683896
Validation loss: 2.590183279911996

Epoch: 5| Step: 5
Training loss: 2.8847143831137867
Validation loss: 2.5886452741759065

Epoch: 5| Step: 6
Training loss: 2.6146422806334844
Validation loss: 2.586932379894273

Epoch: 5| Step: 7
Training loss: 2.6809595942228808
Validation loss: 2.58723954173707

Epoch: 5| Step: 8
Training loss: 2.745157486474923
Validation loss: 2.5845506450802547

Epoch: 5| Step: 9
Training loss: 2.8047285581680916
Validation loss: 2.5841027826431042

Epoch: 5| Step: 10
Training loss: 2.607879027106037
Validation loss: 2.5866734282496977

Epoch: 5| Step: 11
Training loss: 2.747378920854096
Validation loss: 2.584345266869947

Epoch: 84| Step: 0
Training loss: 3.1224652500830294
Validation loss: 2.5859383374661324

Epoch: 5| Step: 1
Training loss: 2.4953403918021833
Validation loss: 2.5827244161458083

Epoch: 5| Step: 2
Training loss: 2.983607647891662
Validation loss: 2.582893743081502

Epoch: 5| Step: 3
Training loss: 2.7911759604761732
Validation loss: 2.5813817579433924

Epoch: 5| Step: 4
Training loss: 2.795437917779725
Validation loss: 2.580467231358139

Epoch: 5| Step: 5
Training loss: 2.6411620728155154
Validation loss: 2.5801500401375668

Epoch: 5| Step: 6
Training loss: 2.838141307536143
Validation loss: 2.5795343496455088

Epoch: 5| Step: 7
Training loss: 2.495621279802805
Validation loss: 2.579649445630267

Epoch: 5| Step: 8
Training loss: 2.8942528306338127
Validation loss: 2.579751228147635

Epoch: 5| Step: 9
Training loss: 2.1165741317026145
Validation loss: 2.5799516776337836

Epoch: 5| Step: 10
Training loss: 2.631309374504075
Validation loss: 2.5795310761877617

Epoch: 5| Step: 11
Training loss: 2.542817704597539
Validation loss: 2.5774564974505685

Epoch: 85| Step: 0
Training loss: 2.8525800169839055
Validation loss: 2.577556377858676

Epoch: 5| Step: 1
Training loss: 2.804985094353822
Validation loss: 2.574169366852009

Epoch: 5| Step: 2
Training loss: 2.7588418655068456
Validation loss: 2.576123950310995

Epoch: 5| Step: 3
Training loss: 2.495815016775367
Validation loss: 2.575976572835268

Epoch: 5| Step: 4
Training loss: 2.7343342805282824
Validation loss: 2.5761829652660815

Epoch: 5| Step: 5
Training loss: 2.3310386295988073
Validation loss: 2.5741197820769353

Epoch: 5| Step: 6
Training loss: 2.598811714353342
Validation loss: 2.574407282144755

Epoch: 5| Step: 7
Training loss: 2.7858059033150218
Validation loss: 2.5754348205665534

Epoch: 5| Step: 8
Training loss: 2.6642183946208013
Validation loss: 2.573776461820479

Epoch: 5| Step: 9
Training loss: 3.0903054530205827
Validation loss: 2.5730304937370634

Epoch: 5| Step: 10
Training loss: 2.788158109836452
Validation loss: 2.5714350551600433

Epoch: 5| Step: 11
Training loss: 2.011330339286446
Validation loss: 2.5722974747733063

Epoch: 86| Step: 0
Training loss: 1.9401343494772743
Validation loss: 2.5722036622158018

Epoch: 5| Step: 1
Training loss: 2.6269078360698765
Validation loss: 2.5698229237482586

Epoch: 5| Step: 2
Training loss: 2.48857538949039
Validation loss: 2.5706578634300636

Epoch: 5| Step: 3
Training loss: 2.679901737290605
Validation loss: 2.571684786969038

Epoch: 5| Step: 4
Training loss: 2.7238814061658334
Validation loss: 2.5693208971191095

Epoch: 5| Step: 5
Training loss: 2.7836051998497147
Validation loss: 2.5673650443747715

Epoch: 5| Step: 6
Training loss: 2.894075386093643
Validation loss: 2.567014849462928

Epoch: 5| Step: 7
Training loss: 2.995536026153646
Validation loss: 2.5669652213021856

Epoch: 5| Step: 8
Training loss: 2.5442350782669214
Validation loss: 2.567196825366149

Epoch: 5| Step: 9
Training loss: 2.9553446829133514
Validation loss: 2.5658825475956175

Epoch: 5| Step: 10
Training loss: 3.051831405362657
Validation loss: 2.5664079221955167

Epoch: 5| Step: 11
Training loss: 2.144468991013386
Validation loss: 2.566899852615345

Epoch: 87| Step: 0
Training loss: 2.724839942501166
Validation loss: 2.56592924658187

Epoch: 5| Step: 1
Training loss: 2.4200046331187894
Validation loss: 2.5659550270625147

Epoch: 5| Step: 2
Training loss: 2.4152849676098187
Validation loss: 2.5663198943296797

Epoch: 5| Step: 3
Training loss: 2.819794160757006
Validation loss: 2.5662647945722696

Epoch: 5| Step: 4
Training loss: 2.653892098861576
Validation loss: 2.5681237251660445

Epoch: 5| Step: 5
Training loss: 2.9556254140426463
Validation loss: 2.5637722501218576

Epoch: 5| Step: 6
Training loss: 2.6879121331317757
Validation loss: 2.563293047436686

Epoch: 5| Step: 7
Training loss: 2.82741364864097
Validation loss: 2.564546268163267

Epoch: 5| Step: 8
Training loss: 2.9560353303999523
Validation loss: 2.566916772548797

Epoch: 5| Step: 9
Training loss: 2.729541364578233
Validation loss: 2.5665977634949204

Epoch: 5| Step: 10
Training loss: 2.6449071709941485
Validation loss: 2.570813038486726

Epoch: 5| Step: 11
Training loss: 2.2443688179510985
Validation loss: 2.569566914214351

Epoch: 88| Step: 0
Training loss: 2.593725549054086
Validation loss: 2.569918365561161

Epoch: 5| Step: 1
Training loss: 2.6922147336568716
Validation loss: 2.5703310941663244

Epoch: 5| Step: 2
Training loss: 2.786802599784128
Validation loss: 2.5699279018164636

Epoch: 5| Step: 3
Training loss: 2.7961074372580352
Validation loss: 2.569395777238571

Epoch: 5| Step: 4
Training loss: 2.589275130828124
Validation loss: 2.5677937279997294

Epoch: 5| Step: 5
Training loss: 3.211772429607584
Validation loss: 2.5657639573103017

Epoch: 5| Step: 6
Training loss: 2.385318026661827
Validation loss: 2.5652822765085315

Epoch: 5| Step: 7
Training loss: 2.6342057070744946
Validation loss: 2.564660990944335

Epoch: 5| Step: 8
Training loss: 2.794472968240532
Validation loss: 2.5619340093212815

Epoch: 5| Step: 9
Training loss: 2.346986494196946
Validation loss: 2.562359441608393

Epoch: 5| Step: 10
Training loss: 2.8350790106310964
Validation loss: 2.5609148480303987

Epoch: 5| Step: 11
Training loss: 2.6415393758565173
Validation loss: 2.5610005442144455

Epoch: 89| Step: 0
Training loss: 2.673088289035093
Validation loss: 2.561036587579289

Epoch: 5| Step: 1
Training loss: 2.8399092340068655
Validation loss: 2.559632464676356

Epoch: 5| Step: 2
Training loss: 2.448046536078094
Validation loss: 2.5618919682396437

Epoch: 5| Step: 3
Training loss: 2.7521069864724073
Validation loss: 2.5569259643635123

Epoch: 5| Step: 4
Training loss: 2.771957303344505
Validation loss: 2.557139935365582

Epoch: 5| Step: 5
Training loss: 2.7608452134395405
Validation loss: 2.555840689853031

Epoch: 5| Step: 6
Training loss: 2.509298769504387
Validation loss: 2.5557834051728348

Epoch: 5| Step: 7
Training loss: 2.4418071936397117
Validation loss: 2.556068614813826

Epoch: 5| Step: 8
Training loss: 2.346164121280601
Validation loss: 2.5560566094514354

Epoch: 5| Step: 9
Training loss: 3.034394825360859
Validation loss: 2.5556547490048502

Epoch: 5| Step: 10
Training loss: 2.9348051005805402
Validation loss: 2.5551234504253713

Epoch: 5| Step: 11
Training loss: 2.9088849663989294
Validation loss: 2.5539112525502747

Epoch: 90| Step: 0
Training loss: 2.6730887349959698
Validation loss: 2.554119311345395

Epoch: 5| Step: 1
Training loss: 2.3341309569229747
Validation loss: 2.5536984075624227

Epoch: 5| Step: 2
Training loss: 2.9666067317380405
Validation loss: 2.553961756723366

Epoch: 5| Step: 3
Training loss: 2.652297186688572
Validation loss: 2.555379736825419

Epoch: 5| Step: 4
Training loss: 2.638047444446902
Validation loss: 2.5543997677407386

Epoch: 5| Step: 5
Training loss: 2.5749998629671818
Validation loss: 2.555274670363518

Epoch: 5| Step: 6
Training loss: 2.9365836804283654
Validation loss: 2.5550736379494103

Epoch: 5| Step: 7
Training loss: 2.8013716199177967
Validation loss: 2.5560150469099274

Epoch: 5| Step: 8
Training loss: 2.4846894647002533
Validation loss: 2.557521372084628

Epoch: 5| Step: 9
Training loss: 2.4908043541939584
Validation loss: 2.5543419296056613

Epoch: 5| Step: 10
Training loss: 2.862153251335585
Validation loss: 2.553712244562285

Epoch: 5| Step: 11
Training loss: 3.2249357172747177
Validation loss: 2.5522763951256

Epoch: 91| Step: 0
Training loss: 2.7502692697649405
Validation loss: 2.5510324663084853

Epoch: 5| Step: 1
Training loss: 2.732702648469755
Validation loss: 2.5493315490650903

Epoch: 5| Step: 2
Training loss: 2.7767954095926153
Validation loss: 2.5502270013149677

Epoch: 5| Step: 3
Training loss: 2.818566624667224
Validation loss: 2.54748481049656

Epoch: 5| Step: 4
Training loss: 2.567361639319311
Validation loss: 2.5473461885410766

Epoch: 5| Step: 5
Training loss: 2.754715344769181
Validation loss: 2.5483499480363485

Epoch: 5| Step: 6
Training loss: 2.7545962504107746
Validation loss: 2.546506582031542

Epoch: 5| Step: 7
Training loss: 2.390245993496031
Validation loss: 2.5459743147511085

Epoch: 5| Step: 8
Training loss: 2.9075749156218853
Validation loss: 2.544505981438532

Epoch: 5| Step: 9
Training loss: 2.676439814030011
Validation loss: 2.5452793970018117

Epoch: 5| Step: 10
Training loss: 2.524981047304238
Validation loss: 2.5456647552288088

Epoch: 5| Step: 11
Training loss: 1.7723612607561559
Validation loss: 2.547926675886538

Epoch: 92| Step: 0
Training loss: 2.667972771346942
Validation loss: 2.544957439557624

Epoch: 5| Step: 1
Training loss: 2.638048528969611
Validation loss: 2.5451821745215466

Epoch: 5| Step: 2
Training loss: 2.6481423902807153
Validation loss: 2.5587561674716146

Epoch: 5| Step: 3
Training loss: 2.5429471860284822
Validation loss: 2.555137458551307

Epoch: 5| Step: 4
Training loss: 3.1950787969433176
Validation loss: 2.5519201434114174

Epoch: 5| Step: 5
Training loss: 2.6616262443911136
Validation loss: 2.5440752519747862

Epoch: 5| Step: 6
Training loss: 2.7190446365132668
Validation loss: 2.5429962437984854

Epoch: 5| Step: 7
Training loss: 2.4141507919609504
Validation loss: 2.5420462541158697

Epoch: 5| Step: 8
Training loss: 2.527280166981776
Validation loss: 2.5407605366919865

Epoch: 5| Step: 9
Training loss: 2.6684031098023007
Validation loss: 2.549935037433687

Epoch: 5| Step: 10
Training loss: 2.821006118989547
Validation loss: 2.551191794444673

Epoch: 5| Step: 11
Training loss: 2.3935210195638037
Validation loss: 2.553880871381874

Epoch: 93| Step: 0
Training loss: 2.391640540942827
Validation loss: 2.558453120669341

Epoch: 5| Step: 1
Training loss: 2.5566856665902056
Validation loss: 2.569547560630304

Epoch: 5| Step: 2
Training loss: 3.096608392381349
Validation loss: 2.573071387628661

Epoch: 5| Step: 3
Training loss: 2.8274415597180087
Validation loss: 2.560294679374606

Epoch: 5| Step: 4
Training loss: 3.454499536419008
Validation loss: 2.5540332598070195

Epoch: 5| Step: 5
Training loss: 3.0264732241326042
Validation loss: 2.5475888022336566

Epoch: 5| Step: 6
Training loss: 2.686794188323046
Validation loss: 2.5427167956127943

Epoch: 5| Step: 7
Training loss: 2.7058517726892175
Validation loss: 2.541865647193017

Epoch: 5| Step: 8
Training loss: 2.5928640116300734
Validation loss: 2.550643991201625

Epoch: 5| Step: 9
Training loss: 1.9614214660885754
Validation loss: 2.556662007420442

Epoch: 5| Step: 10
Training loss: 2.175581698623721
Validation loss: 2.5611500983662276

Epoch: 5| Step: 11
Training loss: 2.4014205026932736
Validation loss: 2.5637107640411507

Epoch: 94| Step: 0
Training loss: 2.6548693490793767
Validation loss: 2.5704648437495052

Epoch: 5| Step: 1
Training loss: 2.418776566706995
Validation loss: 2.582407275206561

Epoch: 5| Step: 2
Training loss: 2.8945954968198855
Validation loss: 2.59573123133062

Epoch: 5| Step: 3
Training loss: 2.7750288575192688
Validation loss: 2.6166661782375615

Epoch: 5| Step: 4
Training loss: 2.4627787166040735
Validation loss: 2.605402479039073

Epoch: 5| Step: 5
Training loss: 2.935906485271421
Validation loss: 2.5812127397755957

Epoch: 5| Step: 6
Training loss: 2.9619863459177727
Validation loss: 2.5525283788734305

Epoch: 5| Step: 7
Training loss: 2.634851498119918
Validation loss: 2.5416677206589644

Epoch: 5| Step: 8
Training loss: 2.6250205266240783
Validation loss: 2.5403079924870173

Epoch: 5| Step: 9
Training loss: 2.5647032035457498
Validation loss: 2.5414620978989966

Epoch: 5| Step: 10
Training loss: 2.8021944064185704
Validation loss: 2.544776765985595

Epoch: 5| Step: 11
Training loss: 3.204129094241285
Validation loss: 2.5529192677800014

Epoch: 95| Step: 0
Training loss: 2.641931786054346
Validation loss: 2.5453273618985097

Epoch: 5| Step: 1
Training loss: 2.8234277992102994
Validation loss: 2.5445129971683556

Epoch: 5| Step: 2
Training loss: 3.068268772781147
Validation loss: 2.5468356942730326

Epoch: 5| Step: 3
Training loss: 2.4037654980553143
Validation loss: 2.5447019012073646

Epoch: 5| Step: 4
Training loss: 2.9339193069501457
Validation loss: 2.541400373037528

Epoch: 5| Step: 5
Training loss: 2.5047250917389654
Validation loss: 2.538776792444034

Epoch: 5| Step: 6
Training loss: 2.553979618095735
Validation loss: 2.5365754648118304

Epoch: 5| Step: 7
Training loss: 2.567112934239293
Validation loss: 2.5357709236458934

Epoch: 5| Step: 8
Training loss: 2.9604614197160135
Validation loss: 2.5375811280434126

Epoch: 5| Step: 9
Training loss: 2.563159671633591
Validation loss: 2.5379180911414054

Epoch: 5| Step: 10
Training loss: 2.391172558277778
Validation loss: 2.536834098872777

Epoch: 5| Step: 11
Training loss: 2.4859426099148063
Validation loss: 2.537831505917737

Epoch: 96| Step: 0
Training loss: 2.7384492874283604
Validation loss: 2.5374294996255196

Epoch: 5| Step: 1
Training loss: 3.264144196681721
Validation loss: 2.5358874653134262

Epoch: 5| Step: 2
Training loss: 2.45693518324964
Validation loss: 2.5374151431773404

Epoch: 5| Step: 3
Training loss: 2.5682979213774364
Validation loss: 2.5414933096023185

Epoch: 5| Step: 4
Training loss: 2.5586794773329093
Validation loss: 2.5428138916241845

Epoch: 5| Step: 5
Training loss: 2.6216309134859945
Validation loss: 2.5447725109223094

Epoch: 5| Step: 6
Training loss: 2.369837520840428
Validation loss: 2.543710654108302

Epoch: 5| Step: 7
Training loss: 2.9374873384243414
Validation loss: 2.5422035976432475

Epoch: 5| Step: 8
Training loss: 2.5244990616734513
Validation loss: 2.5362129223254914

Epoch: 5| Step: 9
Training loss: 2.7109640598370217
Validation loss: 2.5295611347809364

Epoch: 5| Step: 10
Training loss: 2.7203367141268227
Validation loss: 2.5292982810862203

Epoch: 5| Step: 11
Training loss: 2.166054150003991
Validation loss: 2.5287067525160234

Epoch: 97| Step: 0
Training loss: 2.959836246755043
Validation loss: 2.5311400719308392

Epoch: 5| Step: 1
Training loss: 2.368346884051363
Validation loss: 2.530978725951841

Epoch: 5| Step: 2
Training loss: 2.496361468886969
Validation loss: 2.532923843568989

Epoch: 5| Step: 3
Training loss: 2.9164899681699636
Validation loss: 2.5310374433650886

Epoch: 5| Step: 4
Training loss: 2.1257248932343784
Validation loss: 2.529468113271148

Epoch: 5| Step: 5
Training loss: 2.725851846241591
Validation loss: 2.530893277122108

Epoch: 5| Step: 6
Training loss: 2.4376461278689234
Validation loss: 2.529199705871726

Epoch: 5| Step: 7
Training loss: 2.8665544606213236
Validation loss: 2.5263261353025745

Epoch: 5| Step: 8
Training loss: 2.59388943952301
Validation loss: 2.5254321919752676

Epoch: 5| Step: 9
Training loss: 2.9252604898385792
Validation loss: 2.525331080010811

Epoch: 5| Step: 10
Training loss: 2.6475976383118587
Validation loss: 2.5235069981818037

Epoch: 5| Step: 11
Training loss: 3.0979961194382875
Validation loss: 2.528340127041448

Epoch: 98| Step: 0
Training loss: 2.056708440722199
Validation loss: 2.524589531492096

Epoch: 5| Step: 1
Training loss: 2.3869733659003867
Validation loss: 2.522268554030422

Epoch: 5| Step: 2
Training loss: 2.739330923155356
Validation loss: 2.522564507678187

Epoch: 5| Step: 3
Training loss: 2.958879787497761
Validation loss: 2.5218596352791027

Epoch: 5| Step: 4
Training loss: 3.1278470612330707
Validation loss: 2.5233114228773412

Epoch: 5| Step: 5
Training loss: 2.8733014604020637
Validation loss: 2.5276754005424946

Epoch: 5| Step: 6
Training loss: 2.5831629686682516
Validation loss: 2.5226041600801694

Epoch: 5| Step: 7
Training loss: 2.5204692188783
Validation loss: 2.5224035879033395

Epoch: 5| Step: 8
Training loss: 2.673435937556619
Validation loss: 2.522863836598955

Epoch: 5| Step: 9
Training loss: 2.2511884941243547
Validation loss: 2.5203638480297204

Epoch: 5| Step: 10
Training loss: 2.80054612283401
Validation loss: 2.523307041067349

Epoch: 5| Step: 11
Training loss: 3.1586881983409474
Validation loss: 2.519768290248985

Epoch: 99| Step: 0
Training loss: 3.052303388732463
Validation loss: 2.5188187925033083

Epoch: 5| Step: 1
Training loss: 2.507344615225584
Validation loss: 2.520829690715165

Epoch: 5| Step: 2
Training loss: 2.9593093945362203
Validation loss: 2.5180474182521575

Epoch: 5| Step: 3
Training loss: 2.2785235272235678
Validation loss: 2.5186118170836087

Epoch: 5| Step: 4
Training loss: 3.0395290928568595
Validation loss: 2.514381203880435

Epoch: 5| Step: 5
Training loss: 2.0148400249350624
Validation loss: 2.5160892721578225

Epoch: 5| Step: 6
Training loss: 2.56058114012161
Validation loss: 2.5200559281710144

Epoch: 5| Step: 7
Training loss: 2.7591209873607005
Validation loss: 2.5205680291147208

Epoch: 5| Step: 8
Training loss: 2.5592949525194824
Validation loss: 2.51691070817073

Epoch: 5| Step: 9
Training loss: 2.7937964860091036
Validation loss: 2.518593278904526

Epoch: 5| Step: 10
Training loss: 2.619022830416466
Validation loss: 2.5206893033793034

Epoch: 5| Step: 11
Training loss: 1.9208554921006429
Validation loss: 2.517363297180162

Epoch: 100| Step: 0
Training loss: 2.693007215862048
Validation loss: 2.5184887328527914

Epoch: 5| Step: 1
Training loss: 2.869230036579085
Validation loss: 2.5206183244632725

Epoch: 5| Step: 2
Training loss: 2.371994727207647
Validation loss: 2.5163989169908008

Epoch: 5| Step: 3
Training loss: 2.745594483919538
Validation loss: 2.5179808545825244

Epoch: 5| Step: 4
Training loss: 2.3784253365628283
Validation loss: 2.518927209487427

Epoch: 5| Step: 5
Training loss: 2.805523421058391
Validation loss: 2.5164674805348257

Epoch: 5| Step: 6
Training loss: 2.8083304970233605
Validation loss: 2.5157813542903447

Epoch: 5| Step: 7
Training loss: 2.606954399807519
Validation loss: 2.5135327675876997

Epoch: 5| Step: 8
Training loss: 2.4937146330120528
Validation loss: 2.5162878367685058

Epoch: 5| Step: 9
Training loss: 2.7587005655053667
Validation loss: 2.515314098756857

Epoch: 5| Step: 10
Training loss: 2.496315529870054
Validation loss: 2.5144568627723647

Epoch: 5| Step: 11
Training loss: 2.7623383556731684
Validation loss: 2.5143274629546197

Epoch: 101| Step: 0
Training loss: 2.8548828859910538
Validation loss: 2.5166669074009995

Epoch: 5| Step: 1
Training loss: 2.504652081844188
Validation loss: 2.513958641674575

Epoch: 5| Step: 2
Training loss: 2.699459700036128
Validation loss: 2.5135165514575877

Epoch: 5| Step: 3
Training loss: 2.4882997425296445
Validation loss: 2.515280800722851

Epoch: 5| Step: 4
Training loss: 2.5394032411086997
Validation loss: 2.515979066656297

Epoch: 5| Step: 5
Training loss: 2.712000218067892
Validation loss: 2.5128685952886305

Epoch: 5| Step: 6
Training loss: 2.506984300610656
Validation loss: 2.513211464775219

Epoch: 5| Step: 7
Training loss: 2.3592771800396535
Validation loss: 2.514017029535402

Epoch: 5| Step: 8
Training loss: 2.914683421563483
Validation loss: 2.5113816972007523

Epoch: 5| Step: 9
Training loss: 2.3961118674425093
Validation loss: 2.5133660957197796

Epoch: 5| Step: 10
Training loss: 2.9858503439742803
Validation loss: 2.5125101404001247

Epoch: 5| Step: 11
Training loss: 2.825162653333742
Validation loss: 2.514452244286973

Epoch: 102| Step: 0
Training loss: 2.9039011661956105
Validation loss: 2.513935184989159

Epoch: 5| Step: 1
Training loss: 2.8705077526982543
Validation loss: 2.5144433905200865

Epoch: 5| Step: 2
Training loss: 2.746473825993555
Validation loss: 2.5168356026122924

Epoch: 5| Step: 3
Training loss: 2.761014036403348
Validation loss: 2.5160770405013126

Epoch: 5| Step: 4
Training loss: 2.0774211408610874
Validation loss: 2.516935157401128

Epoch: 5| Step: 5
Training loss: 2.8780508025605003
Validation loss: 2.516068263520699

Epoch: 5| Step: 6
Training loss: 2.3937572827738838
Validation loss: 2.5150716500791463

Epoch: 5| Step: 7
Training loss: 2.646963333763675
Validation loss: 2.513247236947188

Epoch: 5| Step: 8
Training loss: 2.735107846827407
Validation loss: 2.5137735033572595

Epoch: 5| Step: 9
Training loss: 2.234109289202539
Validation loss: 2.5108824030131354

Epoch: 5| Step: 10
Training loss: 2.6635843782030126
Validation loss: 2.5082143301209276

Epoch: 5| Step: 11
Training loss: 2.8586072881294102
Validation loss: 2.5087193704232735

Epoch: 103| Step: 0
Training loss: 2.799141418427959
Validation loss: 2.5090399181512058

Epoch: 5| Step: 1
Training loss: 2.8182922059195312
Validation loss: 2.5108573627007877

Epoch: 5| Step: 2
Training loss: 3.087877190287425
Validation loss: 2.511468126321942

Epoch: 5| Step: 3
Training loss: 2.4073398648538498
Validation loss: 2.507452316008274

Epoch: 5| Step: 4
Training loss: 2.4404884993788816
Validation loss: 2.508650698075305

Epoch: 5| Step: 5
Training loss: 2.590746507912675
Validation loss: 2.5098719830371614

Epoch: 5| Step: 6
Training loss: 2.1715956034808537
Validation loss: 2.5103001125604183

Epoch: 5| Step: 7
Training loss: 2.515418192258655
Validation loss: 2.5085839405103645

Epoch: 5| Step: 8
Training loss: 2.492208068188783
Validation loss: 2.5101163943091125

Epoch: 5| Step: 9
Training loss: 2.6672375683814336
Validation loss: 2.510030191728796

Epoch: 5| Step: 10
Training loss: 2.955688655536438
Validation loss: 2.5088473608109307

Epoch: 5| Step: 11
Training loss: 2.086256367174858
Validation loss: 2.5077997922327793

Epoch: 104| Step: 0
Training loss: 2.226298212796256
Validation loss: 2.5071642543896333

Epoch: 5| Step: 1
Training loss: 2.3466443310382687
Validation loss: 2.5037631084691285

Epoch: 5| Step: 2
Training loss: 3.1543624823865892
Validation loss: 2.5053565119634538

Epoch: 5| Step: 3
Training loss: 2.734320329392079
Validation loss: 2.5037502968277408

Epoch: 5| Step: 4
Training loss: 2.536151144132583
Validation loss: 2.5085275270426655

Epoch: 5| Step: 5
Training loss: 2.5899306522938805
Validation loss: 2.5040527039068134

Epoch: 5| Step: 6
Training loss: 2.4521844117607117
Validation loss: 2.5055398715052988

Epoch: 5| Step: 7
Training loss: 2.560499480366817
Validation loss: 2.5056826419405636

Epoch: 5| Step: 8
Training loss: 2.50770088494073
Validation loss: 2.502949016415543

Epoch: 5| Step: 9
Training loss: 2.7745007693079455
Validation loss: 2.506162153878191

Epoch: 5| Step: 10
Training loss: 2.6888575119450744
Validation loss: 2.5050910332725542

Epoch: 5| Step: 11
Training loss: 3.940683198358404
Validation loss: 2.5053243702737378

Epoch: 105| Step: 0
Training loss: 2.4213742630659927
Validation loss: 2.5041765532295783

Epoch: 5| Step: 1
Training loss: 2.600952901816379
Validation loss: 2.5046245320338048

Epoch: 5| Step: 2
Training loss: 3.056310042277113
Validation loss: 2.5013494902445155

Epoch: 5| Step: 3
Training loss: 2.3305811886545382
Validation loss: 2.5056748276403753

Epoch: 5| Step: 4
Training loss: 2.4786287466797416
Validation loss: 2.508503934427924

Epoch: 5| Step: 5
Training loss: 3.0843868174225078
Validation loss: 2.5088118189196265

Epoch: 5| Step: 6
Training loss: 2.5575717894321883
Validation loss: 2.5097664918415634

Epoch: 5| Step: 7
Training loss: 3.0583103092446056
Validation loss: 2.510041855232594

Epoch: 5| Step: 8
Training loss: 2.4766970817508986
Validation loss: 2.5040839098004732

Epoch: 5| Step: 9
Training loss: 2.519407284074831
Validation loss: 2.5016872315341967

Epoch: 5| Step: 10
Training loss: 2.449049169580303
Validation loss: 2.504689971262632

Epoch: 5| Step: 11
Training loss: 1.740493292765199
Validation loss: 2.504330619442256

Epoch: 106| Step: 0
Training loss: 2.645103584237108
Validation loss: 2.50489972699399

Epoch: 5| Step: 1
Training loss: 2.9397306697770182
Validation loss: 2.511992448021183

Epoch: 5| Step: 2
Training loss: 2.749386805747272
Validation loss: 2.512355642615804

Epoch: 5| Step: 3
Training loss: 2.9304110434659147
Validation loss: 2.515802854960068

Epoch: 5| Step: 4
Training loss: 2.06718110121748
Validation loss: 2.5110357096404194

Epoch: 5| Step: 5
Training loss: 2.9791003844528254
Validation loss: 2.511376827810267

Epoch: 5| Step: 6
Training loss: 2.717861512676355
Validation loss: 2.5097385073531444

Epoch: 5| Step: 7
Training loss: 2.1445770536718287
Validation loss: 2.5101651359849613

Epoch: 5| Step: 8
Training loss: 2.453772003961313
Validation loss: 2.509909255374553

Epoch: 5| Step: 9
Training loss: 2.5259199185215544
Validation loss: 2.508416454679483

Epoch: 5| Step: 10
Training loss: 2.482268874212763
Validation loss: 2.505856064764281

Epoch: 5| Step: 11
Training loss: 3.52815137638744
Validation loss: 2.505861805146313

Epoch: 107| Step: 0
Training loss: 2.539080810480852
Validation loss: 2.5027198579519103

Epoch: 5| Step: 1
Training loss: 2.685625709070188
Validation loss: 2.5014102852152367

Epoch: 5| Step: 2
Training loss: 2.488720051208278
Validation loss: 2.5000366844028887

Epoch: 5| Step: 3
Training loss: 2.7141506710016454
Validation loss: 2.4956063962389954

Epoch: 5| Step: 4
Training loss: 2.797277325724376
Validation loss: 2.4953751143926337

Epoch: 5| Step: 5
Training loss: 2.3782211344432933
Validation loss: 2.5002710990146473

Epoch: 5| Step: 6
Training loss: 2.5106287084489876
Validation loss: 2.5021285016199157

Epoch: 5| Step: 7
Training loss: 3.1767355973516205
Validation loss: 2.49229597535229

Epoch: 5| Step: 8
Training loss: 2.5015310367699986
Validation loss: 2.495612000972026

Epoch: 5| Step: 9
Training loss: 2.3174288006064234
Validation loss: 2.496095298165651

Epoch: 5| Step: 10
Training loss: 2.893797087646723
Validation loss: 2.49735420412459

Epoch: 5| Step: 11
Training loss: 1.9358152632650643
Validation loss: 2.497107131441897

Epoch: 108| Step: 0
Training loss: 2.879701336368431
Validation loss: 2.5022990940225034

Epoch: 5| Step: 1
Training loss: 2.61211959040501
Validation loss: 2.502100419794249

Epoch: 5| Step: 2
Training loss: 2.4967455662109024
Validation loss: 2.500291517268419

Epoch: 5| Step: 3
Training loss: 2.9641411593411
Validation loss: 2.5001801704015953

Epoch: 5| Step: 4
Training loss: 2.7387629587275164
Validation loss: 2.5021372242718654

Epoch: 5| Step: 5
Training loss: 2.333929315021316
Validation loss: 2.5023079589990056

Epoch: 5| Step: 6
Training loss: 2.568179187328314
Validation loss: 2.503882286524451

Epoch: 5| Step: 7
Training loss: 2.8023875377457426
Validation loss: 2.5036733978279866

Epoch: 5| Step: 8
Training loss: 2.2624857232923716
Validation loss: 2.503707124009995

Epoch: 5| Step: 9
Training loss: 2.606392440745595
Validation loss: 2.5035299890290337

Epoch: 5| Step: 10
Training loss: 2.582488280691641
Validation loss: 2.5004333478140963

Epoch: 5| Step: 11
Training loss: 2.4421374881477997
Validation loss: 2.5000228006594742

Epoch: 109| Step: 0
Training loss: 2.3337302097488757
Validation loss: 2.4965762257609523

Epoch: 5| Step: 1
Training loss: 2.73244464856597
Validation loss: 2.497412248278396

Epoch: 5| Step: 2
Training loss: 2.966793339057307
Validation loss: 2.497224089147143

Epoch: 5| Step: 3
Training loss: 2.496394418388866
Validation loss: 2.490941041895956

Epoch: 5| Step: 4
Training loss: 2.370149176043402
Validation loss: 2.4879387540469833

Epoch: 5| Step: 5
Training loss: 2.780288187087676
Validation loss: 2.492839931123349

Epoch: 5| Step: 6
Training loss: 2.2009801501878647
Validation loss: 2.490863029564163

Epoch: 5| Step: 7
Training loss: 2.6349577271691675
Validation loss: 2.491464189023385

Epoch: 5| Step: 8
Training loss: 3.225546614580169
Validation loss: 2.4904130121123105

Epoch: 5| Step: 9
Training loss: 2.246323655013616
Validation loss: 2.491813675478495

Epoch: 5| Step: 10
Training loss: 2.644822435674569
Validation loss: 2.492113405280189

Epoch: 5| Step: 11
Training loss: 2.661104680183868
Validation loss: 2.4935066335442104

Epoch: 110| Step: 0
Training loss: 2.711921799030196
Validation loss: 2.4888478167573185

Epoch: 5| Step: 1
Training loss: 2.5396216143715877
Validation loss: 2.4851095605130156

Epoch: 5| Step: 2
Training loss: 2.291046948881397
Validation loss: 2.4921398776137225

Epoch: 5| Step: 3
Training loss: 2.876102733596994
Validation loss: 2.4909259229850513

Epoch: 5| Step: 4
Training loss: 2.6733719943129515
Validation loss: 2.487084261020158

Epoch: 5| Step: 5
Training loss: 2.5188814493338785
Validation loss: 2.4874665799603575

Epoch: 5| Step: 6
Training loss: 3.141580161228395
Validation loss: 2.4916010079828412

Epoch: 5| Step: 7
Training loss: 2.8911236307158323
Validation loss: 2.485959077841738

Epoch: 5| Step: 8
Training loss: 2.486466013642558
Validation loss: 2.4896732431134976

Epoch: 5| Step: 9
Training loss: 2.2785371300336306
Validation loss: 2.486978670023657

Epoch: 5| Step: 10
Training loss: 2.3861860564243567
Validation loss: 2.4957407033561747

Epoch: 5| Step: 11
Training loss: 1.9077254666808152
Validation loss: 2.4914319917168988

Epoch: 111| Step: 0
Training loss: 3.0001772192426888
Validation loss: 2.496380792947098

Epoch: 5| Step: 1
Training loss: 2.1721531532062572
Validation loss: 2.49228532892106

Epoch: 5| Step: 2
Training loss: 2.8162644518580056
Validation loss: 2.4885734454415

Epoch: 5| Step: 3
Training loss: 2.7563983003678905
Validation loss: 2.493889035465707

Epoch: 5| Step: 4
Training loss: 2.7525416679589245
Validation loss: 2.495015022191837

Epoch: 5| Step: 5
Training loss: 2.181784765934087
Validation loss: 2.492302097727189

Epoch: 5| Step: 6
Training loss: 2.2367162642496776
Validation loss: 2.4919148079695397

Epoch: 5| Step: 7
Training loss: 2.8524289003783894
Validation loss: 2.4923302461088794

Epoch: 5| Step: 8
Training loss: 2.6939203620020176
Validation loss: 2.493191113383134

Epoch: 5| Step: 9
Training loss: 2.277349089261269
Validation loss: 2.4917596830486914

Epoch: 5| Step: 10
Training loss: 2.8624322941531455
Validation loss: 2.4887189854366336

Epoch: 5| Step: 11
Training loss: 2.135005508165602
Validation loss: 2.4918781275841604

Epoch: 112| Step: 0
Training loss: 3.0368512500839944
Validation loss: 2.487877078844757

Epoch: 5| Step: 1
Training loss: 2.919246695036151
Validation loss: 2.486000381048485

Epoch: 5| Step: 2
Training loss: 2.6086458569418154
Validation loss: 2.4853588211563125

Epoch: 5| Step: 3
Training loss: 2.8848137254262562
Validation loss: 2.4851725115979044

Epoch: 5| Step: 4
Training loss: 2.3521353698686767
Validation loss: 2.4867842266647977

Epoch: 5| Step: 5
Training loss: 2.3234983209218507
Validation loss: 2.491489966505072

Epoch: 5| Step: 6
Training loss: 2.7234885477434894
Validation loss: 2.4872292570956134

Epoch: 5| Step: 7
Training loss: 2.1489622272919067
Validation loss: 2.4887410392325293

Epoch: 5| Step: 8
Training loss: 2.279577818147847
Validation loss: 2.4830591887861555

Epoch: 5| Step: 9
Training loss: 2.7232838677622393
Validation loss: 2.4835939399148783

Epoch: 5| Step: 10
Training loss: 2.605041743436444
Validation loss: 2.4832419984831264

Epoch: 5| Step: 11
Training loss: 2.3594964608765916
Validation loss: 2.4866098951970383

Epoch: 113| Step: 0
Training loss: 2.228240655623301
Validation loss: 2.490191095512133

Epoch: 5| Step: 1
Training loss: 1.9825394318400478
Validation loss: 2.494579737560696

Epoch: 5| Step: 2
Training loss: 2.728291048325409
Validation loss: 2.4917932156626983

Epoch: 5| Step: 3
Training loss: 2.8213443295144947
Validation loss: 2.492938611119266

Epoch: 5| Step: 4
Training loss: 2.527320732000088
Validation loss: 2.49641122326325

Epoch: 5| Step: 5
Training loss: 2.6499398170690847
Validation loss: 2.4938624263460034

Epoch: 5| Step: 6
Training loss: 2.5064031615986444
Validation loss: 2.4969604452104313

Epoch: 5| Step: 7
Training loss: 2.212499060334259
Validation loss: 2.493410318706724

Epoch: 5| Step: 8
Training loss: 2.90054943536178
Validation loss: 2.494591174633963

Epoch: 5| Step: 9
Training loss: 2.8729336818074094
Validation loss: 2.494233649701483

Epoch: 5| Step: 10
Training loss: 3.068250589852287
Validation loss: 2.4952789512995404

Epoch: 5| Step: 11
Training loss: 2.9091811626695656
Validation loss: 2.4929462501580866

Epoch: 114| Step: 0
Training loss: 2.5874890976828175
Validation loss: 2.4894238917052323

Epoch: 5| Step: 1
Training loss: 2.153817836868769
Validation loss: 2.4886902972471447

Epoch: 5| Step: 2
Training loss: 2.7894153532049173
Validation loss: 2.4851719479713132

Epoch: 5| Step: 3
Training loss: 2.474782309928868
Validation loss: 2.482968630081848

Epoch: 5| Step: 4
Training loss: 2.451615081476076
Validation loss: 2.4824177691698073

Epoch: 5| Step: 5
Training loss: 2.3206965581380117
Validation loss: 2.47893359720907

Epoch: 5| Step: 6
Training loss: 2.8039824468250996
Validation loss: 2.477968625029113

Epoch: 5| Step: 7
Training loss: 2.684363819671902
Validation loss: 2.4758168330413652

Epoch: 5| Step: 8
Training loss: 2.7223485173449298
Validation loss: 2.478467246911888

Epoch: 5| Step: 9
Training loss: 2.401558997524589
Validation loss: 2.479469326254949

Epoch: 5| Step: 10
Training loss: 2.878693240190445
Validation loss: 2.4820902172909105

Epoch: 5| Step: 11
Training loss: 3.777182164330847
Validation loss: 2.4849630855387215

Epoch: 115| Step: 0
Training loss: 2.9211036357523614
Validation loss: 2.4795887625157333

Epoch: 5| Step: 1
Training loss: 2.679213234440855
Validation loss: 2.484367224643144

Epoch: 5| Step: 2
Training loss: 3.242599571422722
Validation loss: 2.4845174792557665

Epoch: 5| Step: 3
Training loss: 2.431301549840604
Validation loss: 2.4878607953140497

Epoch: 5| Step: 4
Training loss: 2.34246923420345
Validation loss: 2.4836633170721396

Epoch: 5| Step: 5
Training loss: 2.3964702478317306
Validation loss: 2.4869021751642792

Epoch: 5| Step: 6
Training loss: 2.507664471116686
Validation loss: 2.4848805439007653

Epoch: 5| Step: 7
Training loss: 2.162072654350267
Validation loss: 2.4860697949443566

Epoch: 5| Step: 8
Training loss: 2.629414252842126
Validation loss: 2.4867136881804055

Epoch: 5| Step: 9
Training loss: 2.794966232832837
Validation loss: 2.488221679325752

Epoch: 5| Step: 10
Training loss: 2.5088183325949203
Validation loss: 2.48462229923381

Epoch: 5| Step: 11
Training loss: 1.5496184556260835
Validation loss: 2.482554002272441

Epoch: 116| Step: 0
Training loss: 2.825170670476702
Validation loss: 2.4824631770329963

Epoch: 5| Step: 1
Training loss: 1.838176190267591
Validation loss: 2.4790545900373253

Epoch: 5| Step: 2
Training loss: 2.6371879103726146
Validation loss: 2.4828076806890897

Epoch: 5| Step: 3
Training loss: 2.1700252642237565
Validation loss: 2.4819805474286207

Epoch: 5| Step: 4
Training loss: 2.658196846578276
Validation loss: 2.481148774254609

Epoch: 5| Step: 5
Training loss: 2.388034289428561
Validation loss: 2.480379484477769

Epoch: 5| Step: 6
Training loss: 2.927307138450748
Validation loss: 2.478174785869154

Epoch: 5| Step: 7
Training loss: 2.6268342285477435
Validation loss: 2.4812652630660823

Epoch: 5| Step: 8
Training loss: 2.9756777592392383
Validation loss: 2.4832465930058807

Epoch: 5| Step: 9
Training loss: 2.377189129261809
Validation loss: 2.485292225387314

Epoch: 5| Step: 10
Training loss: 2.817695142864348
Validation loss: 2.4812157014386793

Epoch: 5| Step: 11
Training loss: 3.230315235923191
Validation loss: 2.4887682419713015

Epoch: 117| Step: 0
Training loss: 2.731722520680436
Validation loss: 2.491224627106409

Epoch: 5| Step: 1
Training loss: 2.1126643777130494
Validation loss: 2.4854881943554252

Epoch: 5| Step: 2
Training loss: 2.3956669514697784
Validation loss: 2.4882924605136494

Epoch: 5| Step: 3
Training loss: 2.2469030895785247
Validation loss: 2.4875733762490717

Epoch: 5| Step: 4
Training loss: 2.961695108643856
Validation loss: 2.480002800538676

Epoch: 5| Step: 5
Training loss: 2.560437558748218
Validation loss: 2.4834969846408788

Epoch: 5| Step: 6
Training loss: 2.462584123287978
Validation loss: 2.481388936609021

Epoch: 5| Step: 7
Training loss: 2.364167153008023
Validation loss: 2.4824772390159

Epoch: 5| Step: 8
Training loss: 2.7652016870706237
Validation loss: 2.4732443987360946

Epoch: 5| Step: 9
Training loss: 3.1900010114327384
Validation loss: 2.4758991793176643

Epoch: 5| Step: 10
Training loss: 2.534537264783441
Validation loss: 2.475387812103123

Epoch: 5| Step: 11
Training loss: 3.009688310168552
Validation loss: 2.480253503626563

Epoch: 118| Step: 0
Training loss: 2.6578983353575043
Validation loss: 2.476786112994037

Epoch: 5| Step: 1
Training loss: 2.3873624791987877
Validation loss: 2.481731275714879

Epoch: 5| Step: 2
Training loss: 2.752377262826415
Validation loss: 2.4795528513120715

Epoch: 5| Step: 3
Training loss: 3.0409914774049294
Validation loss: 2.480331371037408

Epoch: 5| Step: 4
Training loss: 2.0044929582448825
Validation loss: 2.478930130795539

Epoch: 5| Step: 5
Training loss: 2.6579697371253346
Validation loss: 2.476717289239975

Epoch: 5| Step: 6
Training loss: 2.2590422663624863
Validation loss: 2.480351975463158

Epoch: 5| Step: 7
Training loss: 2.350308917417815
Validation loss: 2.4803149718828648

Epoch: 5| Step: 8
Training loss: 2.7271381633969076
Validation loss: 2.4789132414778425

Epoch: 5| Step: 9
Training loss: 3.227464748340751
Validation loss: 2.4786796745998143

Epoch: 5| Step: 10
Training loss: 2.1688053750655754
Validation loss: 2.476458642588974

Epoch: 5| Step: 11
Training loss: 2.3730828427701174
Validation loss: 2.476087807490351

Epoch: 119| Step: 0
Training loss: 2.4426088834796715
Validation loss: 2.4773599562149458

Epoch: 5| Step: 1
Training loss: 2.8314393575978976
Validation loss: 2.4785107912417774

Epoch: 5| Step: 2
Training loss: 2.471043257991942
Validation loss: 2.481962780302723

Epoch: 5| Step: 3
Training loss: 2.3182900602396073
Validation loss: 2.4797264370087695

Epoch: 5| Step: 4
Training loss: 2.2465974723883884
Validation loss: 2.481880102857616

Epoch: 5| Step: 5
Training loss: 2.8055109286981796
Validation loss: 2.478374808870198

Epoch: 5| Step: 6
Training loss: 3.099374917290531
Validation loss: 2.477798466377483

Epoch: 5| Step: 7
Training loss: 2.530893277122108
Validation loss: 2.4823174343353833

Epoch: 5| Step: 8
Training loss: 1.7903991104033428
Validation loss: 2.480059644548429

Epoch: 5| Step: 9
Training loss: 3.0592180689150403
Validation loss: 2.4774093984941903

Epoch: 5| Step: 10
Training loss: 2.450281329448687
Validation loss: 2.480389118668522

Epoch: 5| Step: 11
Training loss: 3.0711289890221014
Validation loss: 2.47645995833329

Epoch: 120| Step: 0
Training loss: 2.7539410528053536
Validation loss: 2.47976003219073

Epoch: 5| Step: 1
Training loss: 2.7041744774782517
Validation loss: 2.4844071728044677

Epoch: 5| Step: 2
Training loss: 2.0016684725221507
Validation loss: 2.4806298671670497

Epoch: 5| Step: 3
Training loss: 3.28626891898669
Validation loss: 2.482076965589831

Epoch: 5| Step: 4
Training loss: 2.5141721522551985
Validation loss: 2.480091400679742

Epoch: 5| Step: 5
Training loss: 2.5833635225890585
Validation loss: 2.4815086687935684

Epoch: 5| Step: 6
Training loss: 2.8203622913984705
Validation loss: 2.4817061734390724

Epoch: 5| Step: 7
Training loss: 2.416543420301686
Validation loss: 2.4819463058727504

Epoch: 5| Step: 8
Training loss: 2.4096043973535584
Validation loss: 2.480747405492442

Epoch: 5| Step: 9
Training loss: 2.5297072618924865
Validation loss: 2.4726915763754076

Epoch: 5| Step: 10
Training loss: 2.296676627175814
Validation loss: 2.4769057067140743

Epoch: 5| Step: 11
Training loss: 1.8471909435112985
Validation loss: 2.47922223827578

Epoch: 121| Step: 0
Training loss: 3.0044662290958346
Validation loss: 2.473980049573385

Epoch: 5| Step: 1
Training loss: 2.2567847001364076
Validation loss: 2.4717065394467874

Epoch: 5| Step: 2
Training loss: 2.3685155989085125
Validation loss: 2.473367786529526

Epoch: 5| Step: 3
Training loss: 2.5192326804986536
Validation loss: 2.4791184361892706

Epoch: 5| Step: 4
Training loss: 2.5894482340804617
Validation loss: 2.4731809110686505

Epoch: 5| Step: 5
Training loss: 2.628456927554135
Validation loss: 2.4714535504621526

Epoch: 5| Step: 6
Training loss: 2.7815313304101434
Validation loss: 2.4750822438918934

Epoch: 5| Step: 7
Training loss: 2.4128914866261413
Validation loss: 2.4785160658895844

Epoch: 5| Step: 8
Training loss: 2.670220292108168
Validation loss: 2.4776226105296533

Epoch: 5| Step: 9
Training loss: 2.7818652554754664
Validation loss: 2.4785222102789928

Epoch: 5| Step: 10
Training loss: 2.208643825463945
Validation loss: 2.48204467853055

Epoch: 5| Step: 11
Training loss: 2.840143620795111
Validation loss: 2.481067683282395

Epoch: 122| Step: 0
Training loss: 2.139937241605523
Validation loss: 2.481765328101303

Epoch: 5| Step: 1
Training loss: 2.729574905807194
Validation loss: 2.4781719677945144

Epoch: 5| Step: 2
Training loss: 2.356843006581499
Validation loss: 2.4836140792893038

Epoch: 5| Step: 3
Training loss: 2.982308036465253
Validation loss: 2.479998754794567

Epoch: 5| Step: 4
Training loss: 2.2945027459685736
Validation loss: 2.4814357444621757

Epoch: 5| Step: 5
Training loss: 3.0900594874708154
Validation loss: 2.4824069082957965

Epoch: 5| Step: 6
Training loss: 2.482012411063469
Validation loss: 2.481439231395714

Epoch: 5| Step: 7
Training loss: 2.6805433680422563
Validation loss: 2.4790793865665313

Epoch: 5| Step: 8
Training loss: 2.587209797677979
Validation loss: 2.4780539545343547

Epoch: 5| Step: 9
Training loss: 2.3191443177422384
Validation loss: 2.476311078230601

Epoch: 5| Step: 10
Training loss: 2.377264549397792
Validation loss: 2.4748514363626133

Epoch: 5| Step: 11
Training loss: 3.3254248899730903
Validation loss: 2.471230375501106

Epoch: 123| Step: 0
Training loss: 2.243339428754048
Validation loss: 2.4723604777666117

Epoch: 5| Step: 1
Training loss: 2.631240873706059
Validation loss: 2.4727379462479573

Epoch: 5| Step: 2
Training loss: 2.6842583911867983
Validation loss: 2.476669561917943

Epoch: 5| Step: 3
Training loss: 2.3607905101651316
Validation loss: 2.473674586571223

Epoch: 5| Step: 4
Training loss: 2.2990274529263632
Validation loss: 2.470649483441439

Epoch: 5| Step: 5
Training loss: 2.12568014143478
Validation loss: 2.4677187983134115

Epoch: 5| Step: 6
Training loss: 3.0554700858752835
Validation loss: 2.4768611996580923

Epoch: 5| Step: 7
Training loss: 3.0992606050334968
Validation loss: 2.4705856677294906

Epoch: 5| Step: 8
Training loss: 2.368516907509002
Validation loss: 2.469722105730912

Epoch: 5| Step: 9
Training loss: 2.8531895842246153
Validation loss: 2.475346979951685

Epoch: 5| Step: 10
Training loss: 2.4235852509448503
Validation loss: 2.4730878215286793

Epoch: 5| Step: 11
Training loss: 2.8090453229203516
Validation loss: 2.473534563143748

Epoch: 124| Step: 0
Training loss: 2.708751049596058
Validation loss: 2.477806212231667

Epoch: 5| Step: 1
Training loss: 2.5309443348129235
Validation loss: 2.47861366088106

Epoch: 5| Step: 2
Training loss: 2.4676339246278247
Validation loss: 2.4778090547776723

Epoch: 5| Step: 3
Training loss: 2.8351360270918673
Validation loss: 2.479671860893752

Epoch: 5| Step: 4
Training loss: 2.3977288308194025
Validation loss: 2.4813840263772233

Epoch: 5| Step: 5
Training loss: 2.6778746943085237
Validation loss: 2.47929019513374

Epoch: 5| Step: 6
Training loss: 2.4344486798361267
Validation loss: 2.4782004530501145

Epoch: 5| Step: 7
Training loss: 2.3692554468066334
Validation loss: 2.4772351952841634

Epoch: 5| Step: 8
Training loss: 2.3924252581904897
Validation loss: 2.478694747973331

Epoch: 5| Step: 9
Training loss: 2.828459493340633
Validation loss: 2.4730840376208425

Epoch: 5| Step: 10
Training loss: 2.9099922287565203
Validation loss: 2.477752983051052

Epoch: 5| Step: 11
Training loss: 1.5222021327042767
Validation loss: 2.4754997444070512

Epoch: 125| Step: 0
Training loss: 2.3036437693882825
Validation loss: 2.473058568396284

Epoch: 5| Step: 1
Training loss: 3.0490206474988835
Validation loss: 2.472746194064366

Epoch: 5| Step: 2
Training loss: 2.6929356806766163
Validation loss: 2.47177362181882

Epoch: 5| Step: 3
Training loss: 2.408042834316
Validation loss: 2.474304334972874

Epoch: 5| Step: 4
Training loss: 2.706976027152507
Validation loss: 2.48053909962934

Epoch: 5| Step: 5
Training loss: 2.8911181879734795
Validation loss: 2.486768013876357

Epoch: 5| Step: 6
Training loss: 2.523463198882298
Validation loss: 2.478117882588874

Epoch: 5| Step: 7
Training loss: 2.6087426430160248
Validation loss: 2.468228884716599

Epoch: 5| Step: 8
Training loss: 2.2406530147062065
Validation loss: 2.4729887591627264

Epoch: 5| Step: 9
Training loss: 2.7314942798446373
Validation loss: 2.475699301386904

Epoch: 5| Step: 10
Training loss: 2.2751200633802626
Validation loss: 2.4745666652768326

Epoch: 5| Step: 11
Training loss: 2.409307345814701
Validation loss: 2.482170854628172

Epoch: 126| Step: 0
Training loss: 2.575206422402087
Validation loss: 2.4790064869485864

Epoch: 5| Step: 1
Training loss: 2.3025156941329445
Validation loss: 2.476151553614867

Epoch: 5| Step: 2
Training loss: 2.4599074372655876
Validation loss: 2.4751807809882407

Epoch: 5| Step: 3
Training loss: 2.1981632281187884
Validation loss: 2.4730357099405675

Epoch: 5| Step: 4
Training loss: 2.5056559479368175
Validation loss: 2.4646985333160543

Epoch: 5| Step: 5
Training loss: 2.963891963446692
Validation loss: 2.4659387944023563

Epoch: 5| Step: 6
Training loss: 2.3738174506031084
Validation loss: 2.4701462833109282

Epoch: 5| Step: 7
Training loss: 2.3561765704868205
Validation loss: 2.47502378844058

Epoch: 5| Step: 8
Training loss: 2.7964671599466633
Validation loss: 2.468937846574021

Epoch: 5| Step: 9
Training loss: 2.3408671642161525
Validation loss: 2.4722048089727386

Epoch: 5| Step: 10
Training loss: 3.4116485930912783
Validation loss: 2.466451806513758

Epoch: 5| Step: 11
Training loss: 2.396561575518957
Validation loss: 2.4656192992208545

Epoch: 127| Step: 0
Training loss: 2.9013997284442397
Validation loss: 2.4701043450043874

Epoch: 5| Step: 1
Training loss: 2.558397125376601
Validation loss: 2.4744288401998364

Epoch: 5| Step: 2
Training loss: 2.427815590172877
Validation loss: 2.4749089887370985

Epoch: 5| Step: 3
Training loss: 2.6654884795349787
Validation loss: 2.4792859278504777

Epoch: 5| Step: 4
Training loss: 2.712796236377694
Validation loss: 2.478381963702535

Epoch: 5| Step: 5
Training loss: 2.3456920461528026
Validation loss: 2.4784410934925623

Epoch: 5| Step: 6
Training loss: 2.398028509700709
Validation loss: 2.4801240416174815

Epoch: 5| Step: 7
Training loss: 2.297509345864764
Validation loss: 2.4834066579114893

Epoch: 5| Step: 8
Training loss: 2.4709889363466124
Validation loss: 2.478028582492763

Epoch: 5| Step: 9
Training loss: 2.913551101605647
Validation loss: 2.481815259014809

Epoch: 5| Step: 10
Training loss: 2.702066203121649
Validation loss: 2.4819443326161514

Epoch: 5| Step: 11
Training loss: 2.3801352547432217
Validation loss: 2.4791829017834184

Epoch: 128| Step: 0
Training loss: 2.5324761517410117
Validation loss: 2.473622431120214

Epoch: 5| Step: 1
Training loss: 2.652485412500018
Validation loss: 2.4770898267587604

Epoch: 5| Step: 2
Training loss: 2.408727980049337
Validation loss: 2.473368063663149

Epoch: 5| Step: 3
Training loss: 2.7354585081233287
Validation loss: 2.47056386602918

Epoch: 5| Step: 4
Training loss: 2.1964931367783853
Validation loss: 2.4730898259530965

Epoch: 5| Step: 5
Training loss: 2.7880429239512576
Validation loss: 2.475145666735834

Epoch: 5| Step: 6
Training loss: 2.4749302825356243
Validation loss: 2.4672013105022432

Epoch: 5| Step: 7
Training loss: 2.7916340232952335
Validation loss: 2.469042418661832

Epoch: 5| Step: 8
Training loss: 2.4162376505323513
Validation loss: 2.465964649369884

Epoch: 5| Step: 9
Training loss: 2.964073593770423
Validation loss: 2.468059270135988

Epoch: 5| Step: 10
Training loss: 2.458420013796137
Validation loss: 2.469714342566995

Epoch: 5| Step: 11
Training loss: 1.8080960406645565
Validation loss: 2.4741712150668973

Epoch: 129| Step: 0
Training loss: 2.526681521413143
Validation loss: 2.473126351182048

Epoch: 5| Step: 1
Training loss: 2.951397102693585
Validation loss: 2.4648270281482914

Epoch: 5| Step: 2
Training loss: 2.8982155604360105
Validation loss: 2.468461691845734

Epoch: 5| Step: 3
Training loss: 2.6141810215304675
Validation loss: 2.464003740705452

Epoch: 5| Step: 4
Training loss: 2.6282238917846974
Validation loss: 2.468273108733096

Epoch: 5| Step: 5
Training loss: 2.377500623027026
Validation loss: 2.467376266418871

Epoch: 5| Step: 6
Training loss: 2.6957608499663284
Validation loss: 2.470336396312689

Epoch: 5| Step: 7
Training loss: 2.467749767242782
Validation loss: 2.4719376848248453

Epoch: 5| Step: 8
Training loss: 2.763894957041083
Validation loss: 2.4681687535941226

Epoch: 5| Step: 9
Training loss: 2.0001970432491167
Validation loss: 2.473384306049093

Epoch: 5| Step: 10
Training loss: 2.228496581521942
Validation loss: 2.479261099328512

Epoch: 5| Step: 11
Training loss: 2.819442318903514
Validation loss: 2.4773195876466296

Epoch: 130| Step: 0
Training loss: 2.2895401075573605
Validation loss: 2.4650285372458867

Epoch: 5| Step: 1
Training loss: 2.237812732173938
Validation loss: 2.4616952849601175

Epoch: 5| Step: 2
Training loss: 3.087119810349075
Validation loss: 2.4585830607432895

Epoch: 5| Step: 3
Training loss: 2.3518987776390397
Validation loss: 2.463687077210205

Epoch: 5| Step: 4
Training loss: 2.7984186952471375
Validation loss: 2.466189549564511

Epoch: 5| Step: 5
Training loss: 2.3945270681422497
Validation loss: 2.462390192362319

Epoch: 5| Step: 6
Training loss: 2.736825945358599
Validation loss: 2.4650657340242175

Epoch: 5| Step: 7
Training loss: 2.571118816762397
Validation loss: 2.4631276269998894

Epoch: 5| Step: 8
Training loss: 2.6250118981954587
Validation loss: 2.46187375136666

Epoch: 5| Step: 9
Training loss: 2.5668592822473966
Validation loss: 2.4651995571842837

Epoch: 5| Step: 10
Training loss: 2.6469813482004265
Validation loss: 2.468627781800305

Epoch: 5| Step: 11
Training loss: 2.5356053687791484
Validation loss: 2.466418457001042

Epoch: 131| Step: 0
Training loss: 2.356676389934044
Validation loss: 2.4681309112892773

Epoch: 5| Step: 1
Training loss: 2.8648256141623256
Validation loss: 2.4671518106196473

Epoch: 5| Step: 2
Training loss: 2.3682319175201427
Validation loss: 2.4653247901899316

Epoch: 5| Step: 3
Training loss: 2.750602222739238
Validation loss: 2.47017612189403

Epoch: 5| Step: 4
Training loss: 2.7047457384068343
Validation loss: 2.470037092620185

Epoch: 5| Step: 5
Training loss: 2.2348753895680566
Validation loss: 2.466779107246029

Epoch: 5| Step: 6
Training loss: 2.5697319511420282
Validation loss: 2.4642900226817304

Epoch: 5| Step: 7
Training loss: 2.6544246011280355
Validation loss: 2.466561562698143

Epoch: 5| Step: 8
Training loss: 2.7647639081711888
Validation loss: 2.4657673825667157

Epoch: 5| Step: 9
Training loss: 2.063290993415796
Validation loss: 2.464250653424234

Epoch: 5| Step: 10
Training loss: 2.635332571102733
Validation loss: 2.463476967852507

Epoch: 5| Step: 11
Training loss: 3.314085526950662
Validation loss: 2.463643063211988

Epoch: 132| Step: 0
Training loss: 2.6605840890690384
Validation loss: 2.462648227025816

Epoch: 5| Step: 1
Training loss: 2.4989968194471914
Validation loss: 2.4632992104277744

Epoch: 5| Step: 2
Training loss: 2.7955156997679205
Validation loss: 2.460818958959593

Epoch: 5| Step: 3
Training loss: 2.4468108148061116
Validation loss: 2.4623318430807974

Epoch: 5| Step: 4
Training loss: 2.5213843339831716
Validation loss: 2.4607586669531547

Epoch: 5| Step: 5
Training loss: 2.783555521824311
Validation loss: 2.4633797248912064

Epoch: 5| Step: 6
Training loss: 2.6323543342363505
Validation loss: 2.4616973470864973

Epoch: 5| Step: 7
Training loss: 2.164903277732013
Validation loss: 2.46484311320946

Epoch: 5| Step: 8
Training loss: 3.1881372151442746
Validation loss: 2.462066786882551

Epoch: 5| Step: 9
Training loss: 2.349157377100405
Validation loss: 2.4605349983574274

Epoch: 5| Step: 10
Training loss: 2.069470273851613
Validation loss: 2.4628929402367974

Epoch: 5| Step: 11
Training loss: 1.9214166234172168
Validation loss: 2.4656802419026875

Epoch: 133| Step: 0
Training loss: 2.788535615964093
Validation loss: 2.4633487695791905

Epoch: 5| Step: 1
Training loss: 2.482547687790863
Validation loss: 2.465128290243864

Epoch: 5| Step: 2
Training loss: 2.630889824434035
Validation loss: 2.461866066351463

Epoch: 5| Step: 3
Training loss: 2.6377279427186164
Validation loss: 2.4638430684557564

Epoch: 5| Step: 4
Training loss: 2.083619504983247
Validation loss: 2.4618948996621635

Epoch: 5| Step: 5
Training loss: 2.3363883817702895
Validation loss: 2.4596232300687517

Epoch: 5| Step: 6
Training loss: 2.6051693219529746
Validation loss: 2.461023654136099

Epoch: 5| Step: 7
Training loss: 2.3560778081898377
Validation loss: 2.46464751803052

Epoch: 5| Step: 8
Training loss: 2.4658667229543316
Validation loss: 2.4656557820134757

Epoch: 5| Step: 9
Training loss: 2.5461769317495273
Validation loss: 2.4647066105386704

Epoch: 5| Step: 10
Training loss: 2.864393988622743
Validation loss: 2.463484561142709

Epoch: 5| Step: 11
Training loss: 3.560245670671431
Validation loss: 2.4714550457307394

Epoch: 134| Step: 0
Training loss: 2.643349770987522
Validation loss: 2.46948864707093

Epoch: 5| Step: 1
Training loss: 2.6794673729170233
Validation loss: 2.4651887292554466

Epoch: 5| Step: 2
Training loss: 2.4584820804745857
Validation loss: 2.4639050630351336

Epoch: 5| Step: 3
Training loss: 2.793521596972224
Validation loss: 2.4631494945194516

Epoch: 5| Step: 4
Training loss: 2.7817354957227804
Validation loss: 2.4652565329864586

Epoch: 5| Step: 5
Training loss: 2.9508559779329184
Validation loss: 2.4629641105222406

Epoch: 5| Step: 6
Training loss: 2.5102703848570442
Validation loss: 2.469647369180997

Epoch: 5| Step: 7
Training loss: 2.3108354712319437
Validation loss: 2.463070045367289

Epoch: 5| Step: 8
Training loss: 1.777515847394345
Validation loss: 2.4665682604422945

Epoch: 5| Step: 9
Training loss: 2.8236231934409375
Validation loss: 2.468307362884973

Epoch: 5| Step: 10
Training loss: 2.396657674752223
Validation loss: 2.469345877960118

Epoch: 5| Step: 11
Training loss: 1.4839363654700717
Validation loss: 2.4662141129179798

Epoch: 135| Step: 0
Training loss: 2.5568487608651203
Validation loss: 2.4636719200804027

Epoch: 5| Step: 1
Training loss: 2.618919778568941
Validation loss: 2.462433012423963

Epoch: 5| Step: 2
Training loss: 2.533147877463513
Validation loss: 2.460689205177904

Epoch: 5| Step: 3
Training loss: 2.363926318696983
Validation loss: 2.460302955321117

Epoch: 5| Step: 4
Training loss: 2.7935726339887514
Validation loss: 2.4625865174762036

Epoch: 5| Step: 5
Training loss: 2.3327351439132453
Validation loss: 2.4530234913163156

Epoch: 5| Step: 6
Training loss: 2.431400590562384
Validation loss: 2.459973734900228

Epoch: 5| Step: 7
Training loss: 2.4851643010248594
Validation loss: 2.461007063755416

Epoch: 5| Step: 8
Training loss: 2.8331687168844217
Validation loss: 2.4553109531269053

Epoch: 5| Step: 9
Training loss: 2.6091361479028756
Validation loss: 2.464252407034486

Epoch: 5| Step: 10
Training loss: 2.6248238822348147
Validation loss: 2.4609282114973827

Epoch: 5| Step: 11
Training loss: 1.9685943178657024
Validation loss: 2.466889138810643

Epoch: 136| Step: 0
Training loss: 2.6299229734621496
Validation loss: 2.4633627269403844

Epoch: 5| Step: 1
Training loss: 2.6721262674249697
Validation loss: 2.463094413972026

Epoch: 5| Step: 2
Training loss: 2.544262253829146
Validation loss: 2.466223474157868

Epoch: 5| Step: 3
Training loss: 2.5815810649348827
Validation loss: 2.4686380876051306

Epoch: 5| Step: 4
Training loss: 2.7698549154136947
Validation loss: 2.466468513322335

Epoch: 5| Step: 5
Training loss: 2.251870014016812
Validation loss: 2.4696271038429725

Epoch: 5| Step: 6
Training loss: 2.3215490058427672
Validation loss: 2.4683788117085546

Epoch: 5| Step: 7
Training loss: 2.145602933001807
Validation loss: 2.4664584924729134

Epoch: 5| Step: 8
Training loss: 2.799444542012742
Validation loss: 2.4687266489526114

Epoch: 5| Step: 9
Training loss: 2.838862820344078
Validation loss: 2.464834448005386

Epoch: 5| Step: 10
Training loss: 2.73044220525366
Validation loss: 2.4641191008781065

Epoch: 5| Step: 11
Training loss: 0.5257718996574088
Validation loss: 2.4595174456540727

Epoch: 137| Step: 0
Training loss: 2.6744431317114037
Validation loss: 2.4641164844302392

Epoch: 5| Step: 1
Training loss: 2.44163621963769
Validation loss: 2.4569403667450853

Epoch: 5| Step: 2
Training loss: 2.891033081942126
Validation loss: 2.4615403824502224

Epoch: 5| Step: 3
Training loss: 2.2507348450071363
Validation loss: 2.4574673482446823

Epoch: 5| Step: 4
Training loss: 2.8188050698189406
Validation loss: 2.467415811267757

Epoch: 5| Step: 5
Training loss: 2.80704426899117
Validation loss: 2.461259217400806

Epoch: 5| Step: 6
Training loss: 2.3592045198199987
Validation loss: 2.4650080807935772

Epoch: 5| Step: 7
Training loss: 2.107207137967752
Validation loss: 2.457589664692658

Epoch: 5| Step: 8
Training loss: 2.532658408841438
Validation loss: 2.460718671969594

Epoch: 5| Step: 9
Training loss: 2.586761804220656
Validation loss: 2.4573302013830376

Epoch: 5| Step: 10
Training loss: 2.6875948334751127
Validation loss: 2.4592250860685096

Epoch: 5| Step: 11
Training loss: 2.2484907810666033
Validation loss: 2.4657499820763764

Epoch: 138| Step: 0
Training loss: 2.9501631481509643
Validation loss: 2.4688157503410166

Epoch: 5| Step: 1
Training loss: 2.47347020737885
Validation loss: 2.4721418330758507

Epoch: 5| Step: 2
Training loss: 2.5147723535912676
Validation loss: 2.470348846406226

Epoch: 5| Step: 3
Training loss: 2.594210572312848
Validation loss: 2.4709694820566566

Epoch: 5| Step: 4
Training loss: 2.166693344930093
Validation loss: 2.4720499340904314

Epoch: 5| Step: 5
Training loss: 2.471382668869795
Validation loss: 2.472125530286777

Epoch: 5| Step: 6
Training loss: 2.6575170748602592
Validation loss: 2.4677191042607993

Epoch: 5| Step: 7
Training loss: 2.6387285273051884
Validation loss: 2.469546125303427

Epoch: 5| Step: 8
Training loss: 2.2446754820835335
Validation loss: 2.4670742681352102

Epoch: 5| Step: 9
Training loss: 2.841595179161072
Validation loss: 2.4653344086663087

Epoch: 5| Step: 10
Training loss: 2.565281544602107
Validation loss: 2.467956485860714

Epoch: 5| Step: 11
Training loss: 2.7203941197122417
Validation loss: 2.4635096232700704

Epoch: 139| Step: 0
Training loss: 2.4409817990410154
Validation loss: 2.466234293515641

Epoch: 5| Step: 1
Training loss: 2.8850431418540152
Validation loss: 2.4649616481274865

Epoch: 5| Step: 2
Training loss: 3.0402730771438864
Validation loss: 2.4588431917988114

Epoch: 5| Step: 3
Training loss: 2.036958976014146
Validation loss: 2.4606576427400015

Epoch: 5| Step: 4
Training loss: 2.3806165238057027
Validation loss: 2.4591747288026147

Epoch: 5| Step: 5
Training loss: 2.1942509701368
Validation loss: 2.4645521028678403

Epoch: 5| Step: 6
Training loss: 2.5918084656744407
Validation loss: 2.4542809089555395

Epoch: 5| Step: 7
Training loss: 2.6085720997037876
Validation loss: 2.4549853768401997

Epoch: 5| Step: 8
Training loss: 2.5853257853119267
Validation loss: 2.458761397501638

Epoch: 5| Step: 9
Training loss: 2.8216985535401866
Validation loss: 2.460067760838163

Epoch: 5| Step: 10
Training loss: 2.5361418373202924
Validation loss: 2.4570938207505924

Epoch: 5| Step: 11
Training loss: 2.2194537269080943
Validation loss: 2.459565647173023

Epoch: 140| Step: 0
Training loss: 2.3458919655590935
Validation loss: 2.4619872382311248

Epoch: 5| Step: 1
Training loss: 2.559979757884583
Validation loss: 2.4639604681608973

Epoch: 5| Step: 2
Training loss: 2.504892711359583
Validation loss: 2.4688055478860487

Epoch: 5| Step: 3
Training loss: 2.929321266171455
Validation loss: 2.468721767859652

Epoch: 5| Step: 4
Training loss: 2.6319128474673734
Validation loss: 2.4716414025741735

Epoch: 5| Step: 5
Training loss: 2.6784674978529126
Validation loss: 2.4775075663628443

Epoch: 5| Step: 6
Training loss: 2.7281287648807515
Validation loss: 2.4748825889892485

Epoch: 5| Step: 7
Training loss: 2.3539000391126472
Validation loss: 2.475061067797517

Epoch: 5| Step: 8
Training loss: 2.380425730542831
Validation loss: 2.4760816129276777

Epoch: 5| Step: 9
Training loss: 2.7904465604421365
Validation loss: 2.472727922683433

Epoch: 5| Step: 10
Training loss: 2.3902884851107875
Validation loss: 2.4704214948286474

Epoch: 5| Step: 11
Training loss: 2.0824111677734254
Validation loss: 2.4660464827046398

Epoch: 141| Step: 0
Training loss: 2.201958854956122
Validation loss: 2.461430154161

Epoch: 5| Step: 1
Training loss: 2.554020972605652
Validation loss: 2.458371660504897

Epoch: 5| Step: 2
Training loss: 2.9384116523447243
Validation loss: 2.460376287985497

Epoch: 5| Step: 3
Training loss: 2.5669103676008307
Validation loss: 2.455848538574206

Epoch: 5| Step: 4
Training loss: 2.9797095135424216
Validation loss: 2.4529901090819872

Epoch: 5| Step: 5
Training loss: 2.382548133067678
Validation loss: 2.4562678037973704

Epoch: 5| Step: 6
Training loss: 2.8187073765680677
Validation loss: 2.460687497473857

Epoch: 5| Step: 7
Training loss: 2.8145967932623277
Validation loss: 2.4589394950861516

Epoch: 5| Step: 8
Training loss: 2.3013481128338866
Validation loss: 2.4638309725573104

Epoch: 5| Step: 9
Training loss: 2.1641527287922213
Validation loss: 2.462334461425004

Epoch: 5| Step: 10
Training loss: 2.1906446469632628
Validation loss: 2.4610500330147564

Epoch: 5| Step: 11
Training loss: 2.553726902286378
Validation loss: 2.461070675753352

Epoch: 142| Step: 0
Training loss: 2.289282257675986
Validation loss: 2.4559376379678737

Epoch: 5| Step: 1
Training loss: 2.6266706690620616
Validation loss: 2.455231978623981

Epoch: 5| Step: 2
Training loss: 2.644685140665258
Validation loss: 2.4504815293395414

Epoch: 5| Step: 3
Training loss: 2.21460357924711
Validation loss: 2.4552597144642645

Epoch: 5| Step: 4
Training loss: 2.847317815483654
Validation loss: 2.4578547550682934

Epoch: 5| Step: 5
Training loss: 2.697923451615176
Validation loss: 2.463187998143731

Epoch: 5| Step: 6
Training loss: 2.3450918806738663
Validation loss: 2.455923177283618

Epoch: 5| Step: 7
Training loss: 2.300703737154618
Validation loss: 2.453358738286537

Epoch: 5| Step: 8
Training loss: 2.8056225931280925
Validation loss: 2.4544295468642656

Epoch: 5| Step: 9
Training loss: 2.6060628370963688
Validation loss: 2.4582648321618734

Epoch: 5| Step: 10
Training loss: 2.603158547138323
Validation loss: 2.4646837209752612

Epoch: 5| Step: 11
Training loss: 3.10706093716173
Validation loss: 2.467051678382347

Epoch: 143| Step: 0
Training loss: 2.5254152655229163
Validation loss: 2.46697919246845

Epoch: 5| Step: 1
Training loss: 2.28302392835605
Validation loss: 2.4623621293666615

Epoch: 5| Step: 2
Training loss: 2.282608046047837
Validation loss: 2.4632466013841157

Epoch: 5| Step: 3
Training loss: 2.5337799991888703
Validation loss: 2.458370852318791

Epoch: 5| Step: 4
Training loss: 2.97385746149575
Validation loss: 2.4602378859936094

Epoch: 5| Step: 5
Training loss: 2.9231910393713805
Validation loss: 2.4625465219237386

Epoch: 5| Step: 6
Training loss: 2.0453599753818503
Validation loss: 2.4640743588339795

Epoch: 5| Step: 7
Training loss: 2.152499046192556
Validation loss: 2.4606364999595565

Epoch: 5| Step: 8
Training loss: 2.821357681321989
Validation loss: 2.4622056468855384

Epoch: 5| Step: 9
Training loss: 3.0132623617991108
Validation loss: 2.4616547563605216

Epoch: 5| Step: 10
Training loss: 2.485685374807467
Validation loss: 2.4611755699978657

Epoch: 5| Step: 11
Training loss: 1.735904397314086
Validation loss: 2.456320206412906

Epoch: 144| Step: 0
Training loss: 2.587536274383886
Validation loss: 2.4549631007361503

Epoch: 5| Step: 1
Training loss: 2.994424407111862
Validation loss: 2.456464308852574

Epoch: 5| Step: 2
Training loss: 2.918639651056589
Validation loss: 2.460156864906348

Epoch: 5| Step: 3
Training loss: 2.5967776540787817
Validation loss: 2.4633845641440124

Epoch: 5| Step: 4
Training loss: 2.1079266131980066
Validation loss: 2.460025093440389

Epoch: 5| Step: 5
Training loss: 2.1123463365996233
Validation loss: 2.455882990291594

Epoch: 5| Step: 6
Training loss: 2.743363261501857
Validation loss: 2.4618147764823863

Epoch: 5| Step: 7
Training loss: 2.6432935785171923
Validation loss: 2.4570597660611413

Epoch: 5| Step: 8
Training loss: 2.7398004385399464
Validation loss: 2.4570030449328395

Epoch: 5| Step: 9
Training loss: 2.5962382870714342
Validation loss: 2.4639231377739192

Epoch: 5| Step: 10
Training loss: 1.7265188634545114
Validation loss: 2.4565903794216175

Epoch: 5| Step: 11
Training loss: 1.9263522711753303
Validation loss: 2.4578973510154807

Epoch: 145| Step: 0
Training loss: 2.529512633322849
Validation loss: 2.4573636075321117

Epoch: 5| Step: 1
Training loss: 2.702916396366312
Validation loss: 2.465898331518929

Epoch: 5| Step: 2
Training loss: 2.7565733635583145
Validation loss: 2.4605151949434445

Epoch: 5| Step: 3
Training loss: 2.509677656836261
Validation loss: 2.4487270995421477

Epoch: 5| Step: 4
Training loss: 2.3889552250111667
Validation loss: 2.448666321157335

Epoch: 5| Step: 5
Training loss: 2.611028638398497
Validation loss: 2.4587743425546047

Epoch: 5| Step: 6
Training loss: 2.254911043395981
Validation loss: 2.451174156724899

Epoch: 5| Step: 7
Training loss: 2.442404971504587
Validation loss: 2.454335114689497

Epoch: 5| Step: 8
Training loss: 2.529043295384482
Validation loss: 2.451477919238504

Epoch: 5| Step: 9
Training loss: 2.459652325942461
Validation loss: 2.4513315298257785

Epoch: 5| Step: 10
Training loss: 2.5714731117962644
Validation loss: 2.4618348075218024

Epoch: 5| Step: 11
Training loss: 3.346335294004823
Validation loss: 2.4557237992509506

Epoch: 146| Step: 0
Training loss: 2.3404911018239924
Validation loss: 2.460625409717379

Epoch: 5| Step: 1
Training loss: 1.6738647314495498
Validation loss: 2.4502030726371107

Epoch: 5| Step: 2
Training loss: 2.751887454027026
Validation loss: 2.4588038403748267

Epoch: 5| Step: 3
Training loss: 2.264770978249973
Validation loss: 2.4586501294558736

Epoch: 5| Step: 4
Training loss: 2.7417151758913416
Validation loss: 2.4587486624766597

Epoch: 5| Step: 5
Training loss: 2.3755977279996503
Validation loss: 2.462840011927695

Epoch: 5| Step: 6
Training loss: 2.3586699588135205
Validation loss: 2.4595325072155867

Epoch: 5| Step: 7
Training loss: 2.302621827355867
Validation loss: 2.4596681540501457

Epoch: 5| Step: 8
Training loss: 2.634601833944798
Validation loss: 2.453418876069673

Epoch: 5| Step: 9
Training loss: 2.845413559821492
Validation loss: 2.451663545739007

Epoch: 5| Step: 10
Training loss: 3.4448935325348575
Validation loss: 2.452469355443259

Epoch: 5| Step: 11
Training loss: 2.014511155495962
Validation loss: 2.4497423114330896

Epoch: 147| Step: 0
Training loss: 2.8229409436147392
Validation loss: 2.450314821562389

Epoch: 5| Step: 1
Training loss: 2.6220870431263257
Validation loss: 2.452281543679576

Epoch: 5| Step: 2
Training loss: 2.409661191179045
Validation loss: 2.455231383847607

Epoch: 5| Step: 3
Training loss: 2.383585319891732
Validation loss: 2.459375763908762

Epoch: 5| Step: 4
Training loss: 1.9572477240008965
Validation loss: 2.458030832935838

Epoch: 5| Step: 5
Training loss: 2.7650003536010295
Validation loss: 2.4549887354359905

Epoch: 5| Step: 6
Training loss: 2.7887932997436486
Validation loss: 2.4591049718233027

Epoch: 5| Step: 7
Training loss: 2.5451339668433346
Validation loss: 2.4514011270783724

Epoch: 5| Step: 8
Training loss: 2.502225552809452
Validation loss: 2.4566272995855747

Epoch: 5| Step: 9
Training loss: 2.3433454037170502
Validation loss: 2.4565619468777307

Epoch: 5| Step: 10
Training loss: 2.6108192512951467
Validation loss: 2.461260440365779

Epoch: 5| Step: 11
Training loss: 2.9314784564886254
Validation loss: 2.4550987491636644

Epoch: 148| Step: 0
Training loss: 2.393363431388863
Validation loss: 2.4684554379011807

Epoch: 5| Step: 1
Training loss: 2.7488386996652503
Validation loss: 2.473766883000889

Epoch: 5| Step: 2
Training loss: 2.750262334622049
Validation loss: 2.4789868631529055

Epoch: 5| Step: 3
Training loss: 3.0562248556588845
Validation loss: 2.4861511063570103

Epoch: 5| Step: 4
Training loss: 2.562687843695055
Validation loss: 2.497175094878563

Epoch: 5| Step: 5
Training loss: 2.5073167542640835
Validation loss: 2.508688554820705

Epoch: 5| Step: 6
Training loss: 2.7011836142019403
Validation loss: 2.5138782534072828

Epoch: 5| Step: 7
Training loss: 2.5703619398562476
Validation loss: 2.5136291946862275

Epoch: 5| Step: 8
Training loss: 2.50510952464533
Validation loss: 2.5225175769219987

Epoch: 5| Step: 9
Training loss: 2.475633994695035
Validation loss: 2.527012633812514

Epoch: 5| Step: 10
Training loss: 2.439013084873887
Validation loss: 2.5243865119222657

Epoch: 5| Step: 11
Training loss: 2.8504198267056315
Validation loss: 2.5325603507854124

Epoch: 149| Step: 0
Training loss: 2.4943738572919267
Validation loss: 2.5290547533638206

Epoch: 5| Step: 1
Training loss: 3.0117462988161234
Validation loss: 2.5305017299373582

Epoch: 5| Step: 2
Training loss: 2.4706757193391113
Validation loss: 2.534766482194683

Epoch: 5| Step: 3
Training loss: 2.7306292354370156
Validation loss: 2.5318390117778544

Epoch: 5| Step: 4
Training loss: 2.0215952377510815
Validation loss: 2.534476033684747

Epoch: 5| Step: 5
Training loss: 2.634292684515688
Validation loss: 2.5335505474499453

Epoch: 5| Step: 6
Training loss: 2.401539142125247
Validation loss: 2.533658569303509

Epoch: 5| Step: 7
Training loss: 2.245202566069063
Validation loss: 2.534417248948765

Epoch: 5| Step: 8
Training loss: 2.812566290180147
Validation loss: 2.5359645900818886

Epoch: 5| Step: 9
Training loss: 2.9206104500079775
Validation loss: 2.5342848210218776

Epoch: 5| Step: 10
Training loss: 2.930020326146783
Validation loss: 2.5270710266853516

Epoch: 5| Step: 11
Training loss: 3.994790499544864
Validation loss: 2.5274910232895174

Epoch: 150| Step: 0
Training loss: 2.376046803318499
Validation loss: 2.5292660940842895

Epoch: 5| Step: 1
Training loss: 2.505922550109727
Validation loss: 2.5362034003092746

Epoch: 5| Step: 2
Training loss: 2.476868138271302
Validation loss: 2.537496316528152

Epoch: 5| Step: 3
Training loss: 2.954615141306858
Validation loss: 2.5339818035622526

Epoch: 5| Step: 4
Training loss: 2.6928222651823073
Validation loss: 2.5247347383942857

Epoch: 5| Step: 5
Training loss: 3.1845593819288798
Validation loss: 2.5379199973922546

Epoch: 5| Step: 6
Training loss: 2.923709721738344
Validation loss: 2.5405260299042824

Epoch: 5| Step: 7
Training loss: 2.5298474982818604
Validation loss: 2.5662130073089773

Epoch: 5| Step: 8
Training loss: 2.0775509378406367
Validation loss: 2.553295362804823

Epoch: 5| Step: 9
Training loss: 3.0794044585199964
Validation loss: 2.5213892037464998

Epoch: 5| Step: 10
Training loss: 2.4631831504386716
Validation loss: 2.5070065741326637

Epoch: 5| Step: 11
Training loss: 1.5872329156833096
Validation loss: 2.4978632895520274

Testing loss: 2.079467642622007
