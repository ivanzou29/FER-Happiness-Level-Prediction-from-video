Epoch: 1| Step: 0
Training loss: 5.363532066345215
Validation loss: 5.331335703531901

Epoch: 6| Step: 1
Training loss: 5.567121982574463
Validation loss: 5.329139868418376

Epoch: 6| Step: 2
Training loss: 5.628268241882324
Validation loss: 5.3267637093861895

Epoch: 6| Step: 3
Training loss: 5.537456512451172
Validation loss: 5.3243545691172285

Epoch: 6| Step: 4
Training loss: 5.323125839233398
Validation loss: 5.32188351949056

Epoch: 6| Step: 5
Training loss: 4.559542655944824
Validation loss: 5.319361925125122

Epoch: 6| Step: 6
Training loss: 6.215561389923096
Validation loss: 5.3167574008305865

Epoch: 6| Step: 7
Training loss: 5.059066295623779
Validation loss: 5.3139402866363525

Epoch: 6| Step: 8
Training loss: 6.040677070617676
Validation loss: 5.311215877532959

Epoch: 6| Step: 9
Training loss: 5.213812828063965
Validation loss: 5.308114687601726

Epoch: 6| Step: 10
Training loss: 5.216836929321289
Validation loss: 5.305068174997966

Epoch: 6| Step: 11
Training loss: 6.08491325378418
Validation loss: 5.301830768585205

Epoch: 6| Step: 12
Training loss: 6.0232648849487305
Validation loss: 5.2986524899800616

Epoch: 6| Step: 13
Training loss: 3.537890911102295
Validation loss: 5.295114676157634

Epoch: 2| Step: 0
Training loss: 5.154593467712402
Validation loss: 5.291467746098836

Epoch: 6| Step: 1
Training loss: 4.772336006164551
Validation loss: 5.28784966468811

Epoch: 6| Step: 2
Training loss: 4.793292045593262
Validation loss: 5.284043550491333

Epoch: 6| Step: 3
Training loss: 6.865715026855469
Validation loss: 5.279854695002238

Epoch: 6| Step: 4
Training loss: 5.615046501159668
Validation loss: 5.275493780771892

Epoch: 6| Step: 5
Training loss: 5.551661014556885
Validation loss: 5.271114428838094

Epoch: 6| Step: 6
Training loss: 6.031984329223633
Validation loss: 5.2662092844645185

Epoch: 6| Step: 7
Training loss: 5.054924488067627
Validation loss: 5.261217912038167

Epoch: 6| Step: 8
Training loss: 5.00814151763916
Validation loss: 5.255743662516276

Epoch: 6| Step: 9
Training loss: 4.806387901306152
Validation loss: 5.250284194946289

Epoch: 6| Step: 10
Training loss: 5.215240478515625
Validation loss: 5.2440996170043945

Epoch: 6| Step: 11
Training loss: 5.312945365905762
Validation loss: 5.237929662068685

Epoch: 6| Step: 12
Training loss: 5.094955921173096
Validation loss: 5.231234073638916

Epoch: 6| Step: 13
Training loss: 5.361791133880615
Validation loss: 5.2243592739105225

Epoch: 3| Step: 0
Training loss: 3.6609318256378174
Validation loss: 5.2172160148620605

Epoch: 6| Step: 1
Training loss: 6.3941192626953125
Validation loss: 5.209914843241374

Epoch: 6| Step: 2
Training loss: 4.974085807800293
Validation loss: 5.202099959055583

Epoch: 6| Step: 3
Training loss: 5.599154472351074
Validation loss: 5.194209734598796

Epoch: 6| Step: 4
Training loss: 6.061460971832275
Validation loss: 5.185978809992473

Epoch: 6| Step: 5
Training loss: 6.096893310546875
Validation loss: 5.177364985148112

Epoch: 6| Step: 6
Training loss: 4.7031145095825195
Validation loss: 5.168534596761067

Epoch: 6| Step: 7
Training loss: 5.56170654296875
Validation loss: 5.159517288208008

Epoch: 6| Step: 8
Training loss: 5.555567741394043
Validation loss: 5.149954319000244

Epoch: 6| Step: 9
Training loss: 5.858510494232178
Validation loss: 5.140113194783528

Epoch: 6| Step: 10
Training loss: 4.92598819732666
Validation loss: 5.130481878916423

Epoch: 6| Step: 11
Training loss: 3.9924612045288086
Validation loss: 5.119917631149292

Epoch: 6| Step: 12
Training loss: 5.176242828369141
Validation loss: 5.109581629435222

Epoch: 6| Step: 13
Training loss: 4.708895683288574
Validation loss: 5.098674615224202

Epoch: 4| Step: 0
Training loss: 5.5134148597717285
Validation loss: 5.087461392084758

Epoch: 6| Step: 1
Training loss: 5.412517547607422
Validation loss: 5.076186498006185

Epoch: 6| Step: 2
Training loss: 4.1775360107421875
Validation loss: 5.064438501993815

Epoch: 6| Step: 3
Training loss: 4.918636798858643
Validation loss: 5.052538951237996

Epoch: 6| Step: 4
Training loss: 4.074695110321045
Validation loss: 5.040287017822266

Epoch: 6| Step: 5
Training loss: 7.011046409606934
Validation loss: 5.028278549512227

Epoch: 6| Step: 6
Training loss: 6.216070175170898
Validation loss: 5.0155430634816485

Epoch: 6| Step: 7
Training loss: 4.440082550048828
Validation loss: 5.002873023351033

Epoch: 6| Step: 8
Training loss: 4.418996810913086
Validation loss: 4.989858706792195

Epoch: 6| Step: 9
Training loss: 4.476604461669922
Validation loss: 4.977196931838989

Epoch: 6| Step: 10
Training loss: 5.225411415100098
Validation loss: 4.963863372802734

Epoch: 6| Step: 11
Training loss: 5.05941104888916
Validation loss: 4.951070785522461

Epoch: 6| Step: 12
Training loss: 4.168086051940918
Validation loss: 4.938119093577067

Epoch: 6| Step: 13
Training loss: 6.109070777893066
Validation loss: 4.925263683001201

Epoch: 5| Step: 0
Training loss: 4.804643630981445
Validation loss: 4.911966641743978

Epoch: 6| Step: 1
Training loss: 5.5924248695373535
Validation loss: 4.899293422698975

Epoch: 6| Step: 2
Training loss: 4.445048809051514
Validation loss: 4.887171665827434

Epoch: 6| Step: 3
Training loss: 5.25267219543457
Validation loss: 4.8743172486623125

Epoch: 6| Step: 4
Training loss: 4.6144537925720215
Validation loss: 4.86209511756897

Epoch: 6| Step: 5
Training loss: 5.150604248046875
Validation loss: 4.84997554620107

Epoch: 6| Step: 6
Training loss: 6.02332878112793
Validation loss: 4.83817474047343

Epoch: 6| Step: 7
Training loss: 4.1617841720581055
Validation loss: 4.826146841049194

Epoch: 6| Step: 8
Training loss: 4.3242974281311035
Validation loss: 4.81415057182312

Epoch: 6| Step: 9
Training loss: 5.428741455078125
Validation loss: 4.802343050638835

Epoch: 6| Step: 10
Training loss: 4.425500869750977
Validation loss: 4.790637811024983

Epoch: 6| Step: 11
Training loss: 4.62428092956543
Validation loss: 4.7784905433654785

Epoch: 6| Step: 12
Training loss: 4.915558338165283
Validation loss: 4.767107645670573

Epoch: 6| Step: 13
Training loss: 5.111120223999023
Validation loss: 4.755601008733113

Epoch: 6| Step: 0
Training loss: 5.047002792358398
Validation loss: 4.744204600652059

Epoch: 6| Step: 1
Training loss: 4.658479690551758
Validation loss: 4.732538263003032

Epoch: 6| Step: 2
Training loss: 5.333549499511719
Validation loss: 4.72083059946696

Epoch: 6| Step: 3
Training loss: 5.658944129943848
Validation loss: 4.708925724029541

Epoch: 6| Step: 4
Training loss: 4.5858869552612305
Validation loss: 4.696798801422119

Epoch: 6| Step: 5
Training loss: 4.109519958496094
Validation loss: 4.684850851694743

Epoch: 6| Step: 6
Training loss: 4.336423873901367
Validation loss: 4.672771135965983

Epoch: 6| Step: 7
Training loss: 5.406228065490723
Validation loss: 4.660625298817952

Epoch: 6| Step: 8
Training loss: 5.462594509124756
Validation loss: 4.649276892344157

Epoch: 6| Step: 9
Training loss: 5.957359313964844
Validation loss: 4.6372653643290205

Epoch: 6| Step: 10
Training loss: 3.8400039672851562
Validation loss: 4.6252923011779785

Epoch: 6| Step: 11
Training loss: 4.543060302734375
Validation loss: 4.614046414693196

Epoch: 6| Step: 12
Training loss: 3.56075382232666
Validation loss: 4.601820230484009

Epoch: 6| Step: 13
Training loss: 4.228051662445068
Validation loss: 4.591216444969177

Epoch: 7| Step: 0
Training loss: 4.424691200256348
Validation loss: 4.580449104309082

Epoch: 6| Step: 1
Training loss: 5.012767314910889
Validation loss: 4.56932258605957

Epoch: 6| Step: 2
Training loss: 4.939279556274414
Validation loss: 4.559434652328491

Epoch: 6| Step: 3
Training loss: 5.160691261291504
Validation loss: 4.5487156709035235

Epoch: 6| Step: 4
Training loss: 4.840095520019531
Validation loss: 4.539166331291199

Epoch: 6| Step: 5
Training loss: 3.9783437252044678
Validation loss: 4.528930902481079

Epoch: 6| Step: 6
Training loss: 3.9576220512390137
Validation loss: 4.519185145696004

Epoch: 6| Step: 7
Training loss: 4.578330039978027
Validation loss: 4.508919914563497

Epoch: 6| Step: 8
Training loss: 4.542758941650391
Validation loss: 4.499558528264363

Epoch: 6| Step: 9
Training loss: 4.648416042327881
Validation loss: 4.490249713261922

Epoch: 6| Step: 10
Training loss: 5.087228775024414
Validation loss: 4.481074611345927

Epoch: 6| Step: 11
Training loss: 5.089414596557617
Validation loss: 4.47235922018687

Epoch: 6| Step: 12
Training loss: 4.413228988647461
Validation loss: 4.463073968887329

Epoch: 6| Step: 13
Training loss: 4.063483238220215
Validation loss: 4.454982360204061

Epoch: 8| Step: 0
Training loss: 5.591795921325684
Validation loss: 4.447070002555847

Epoch: 6| Step: 1
Training loss: 3.552807569503784
Validation loss: 4.4388719002405805

Epoch: 6| Step: 2
Training loss: 2.993070602416992
Validation loss: 4.430488348007202

Epoch: 6| Step: 3
Training loss: 4.095934867858887
Validation loss: 4.422573049863179

Epoch: 6| Step: 4
Training loss: 4.6636810302734375
Validation loss: 4.414174834887187

Epoch: 6| Step: 5
Training loss: 5.477304935455322
Validation loss: 4.4057395458221436

Epoch: 6| Step: 6
Training loss: 3.1777868270874023
Validation loss: 4.396795352300008

Epoch: 6| Step: 7
Training loss: 4.733514785766602
Validation loss: 4.3884520928064985

Epoch: 6| Step: 8
Training loss: 4.162507057189941
Validation loss: 4.380897045135498

Epoch: 6| Step: 9
Training loss: 6.053104877471924
Validation loss: 4.372936725616455

Epoch: 6| Step: 10
Training loss: 4.16176176071167
Validation loss: 4.364506721496582

Epoch: 6| Step: 11
Training loss: 4.458688735961914
Validation loss: 4.356506745020549

Epoch: 6| Step: 12
Training loss: 4.769015789031982
Validation loss: 4.348684509595235

Epoch: 6| Step: 13
Training loss: 5.257508754730225
Validation loss: 4.3408230145772295

Epoch: 9| Step: 0
Training loss: 3.934715509414673
Validation loss: 4.332591891288757

Epoch: 6| Step: 1
Training loss: 4.791581630706787
Validation loss: 4.323972980181376

Epoch: 6| Step: 2
Training loss: 4.197325229644775
Validation loss: 4.315493226051331

Epoch: 6| Step: 3
Training loss: 4.358676910400391
Validation loss: 4.307414770126343

Epoch: 6| Step: 4
Training loss: 4.517910957336426
Validation loss: 4.2989176114400225

Epoch: 6| Step: 5
Training loss: 4.55223274230957
Validation loss: 4.29159688949585

Epoch: 6| Step: 6
Training loss: 4.389388561248779
Validation loss: 4.283608595530192

Epoch: 6| Step: 7
Training loss: 4.888472557067871
Validation loss: 4.276647130648295

Epoch: 6| Step: 8
Training loss: 4.184314250946045
Validation loss: 4.269020477930705

Epoch: 6| Step: 9
Training loss: 4.803500652313232
Validation loss: 4.261595169703166

Epoch: 6| Step: 10
Training loss: 4.128646373748779
Validation loss: 4.254883368810018

Epoch: 6| Step: 11
Training loss: 3.780317544937134
Validation loss: 4.247956871986389

Epoch: 6| Step: 12
Training loss: 4.262166976928711
Validation loss: 4.240072131156921

Epoch: 6| Step: 13
Training loss: 4.928369998931885
Validation loss: 4.2321633497873945

Epoch: 10| Step: 0
Training loss: 3.4689292907714844
Validation loss: 4.224513133366902

Epoch: 6| Step: 1
Training loss: 4.656623840332031
Validation loss: 4.216657280921936

Epoch: 6| Step: 2
Training loss: 3.8286805152893066
Validation loss: 4.209446827570598

Epoch: 6| Step: 3
Training loss: 3.4995365142822266
Validation loss: 4.201852560043335

Epoch: 6| Step: 4
Training loss: 3.266836643218994
Validation loss: 4.193937102953593

Epoch: 6| Step: 5
Training loss: 4.899654388427734
Validation loss: 4.186934153238933

Epoch: 6| Step: 6
Training loss: 4.27622127532959
Validation loss: 4.179874300956726

Epoch: 6| Step: 7
Training loss: 5.051460266113281
Validation loss: 4.172698100407918

Epoch: 6| Step: 8
Training loss: 5.0262556076049805
Validation loss: 4.165733973185222

Epoch: 6| Step: 9
Training loss: 5.201546669006348
Validation loss: 4.158610065778096

Epoch: 6| Step: 10
Training loss: 5.057661056518555
Validation loss: 4.152138312657674

Epoch: 6| Step: 11
Training loss: 3.9744486808776855
Validation loss: 4.144232749938965

Epoch: 6| Step: 12
Training loss: 3.943307399749756
Validation loss: 4.137723485628764

Epoch: 6| Step: 13
Training loss: 4.224237442016602
Validation loss: 4.1320027112960815

Epoch: 11| Step: 0
Training loss: 4.421023845672607
Validation loss: 4.1240869363149

Epoch: 6| Step: 1
Training loss: 3.942505121231079
Validation loss: 4.117700298627217

Epoch: 6| Step: 2
Training loss: 4.532160758972168
Validation loss: 4.112329602241516

Epoch: 6| Step: 3
Training loss: 3.7434206008911133
Validation loss: 4.104372024536133

Epoch: 6| Step: 4
Training loss: 4.460623264312744
Validation loss: 4.097481767336528

Epoch: 6| Step: 5
Training loss: 3.72312068939209
Validation loss: 4.090530633926392

Epoch: 6| Step: 6
Training loss: 4.040558815002441
Validation loss: 4.0831453402837115

Epoch: 6| Step: 7
Training loss: 3.548682928085327
Validation loss: 4.076977650324504

Epoch: 6| Step: 8
Training loss: 5.238106727600098
Validation loss: 4.070430278778076

Epoch: 6| Step: 9
Training loss: 4.403831481933594
Validation loss: 4.063960870107015

Epoch: 6| Step: 10
Training loss: 5.026210784912109
Validation loss: 4.057146906852722

Epoch: 6| Step: 11
Training loss: 3.743565320968628
Validation loss: 4.051087021827698

Epoch: 6| Step: 12
Training loss: 3.912703037261963
Validation loss: 4.044857939084371

Epoch: 6| Step: 13
Training loss: 4.378756046295166
Validation loss: 4.039423584938049

Epoch: 12| Step: 0
Training loss: 4.590829849243164
Validation loss: 4.0343295733133955

Epoch: 6| Step: 1
Training loss: 4.041994571685791
Validation loss: 4.02768353621165

Epoch: 6| Step: 2
Training loss: 3.5663013458251953
Validation loss: 4.021867911020915

Epoch: 6| Step: 3
Training loss: 4.750718116760254
Validation loss: 4.014732360839844

Epoch: 6| Step: 4
Training loss: 4.262951374053955
Validation loss: 4.007629474004109

Epoch: 6| Step: 5
Training loss: 4.2191243171691895
Validation loss: 4.0018289883931475

Epoch: 6| Step: 6
Training loss: 4.827226638793945
Validation loss: 3.9963700771331787

Epoch: 6| Step: 7
Training loss: 3.823396682739258
Validation loss: 3.990115682284037

Epoch: 6| Step: 8
Training loss: 4.15824556350708
Validation loss: 3.9841228326161704

Epoch: 6| Step: 9
Training loss: 4.234167098999023
Validation loss: 3.9776877562204995

Epoch: 6| Step: 10
Training loss: 4.3404998779296875
Validation loss: 3.9719318548838296

Epoch: 6| Step: 11
Training loss: 3.929178237915039
Validation loss: 3.9652722676595054

Epoch: 6| Step: 12
Training loss: 3.234945297241211
Validation loss: 3.959090312321981

Epoch: 6| Step: 13
Training loss: 3.9584217071533203
Validation loss: 3.9555122454961142

Epoch: 13| Step: 0
Training loss: 4.199746131896973
Validation loss: 3.9474095503489175

Epoch: 6| Step: 1
Training loss: 4.242049694061279
Validation loss: 3.941942731539408

Epoch: 6| Step: 2
Training loss: 5.4190449714660645
Validation loss: 3.935952623685201

Epoch: 6| Step: 3
Training loss: 4.299686431884766
Validation loss: 3.9286745389302573

Epoch: 6| Step: 4
Training loss: 4.440604209899902
Validation loss: 3.9218717018763223

Epoch: 6| Step: 5
Training loss: 3.631481885910034
Validation loss: 3.916861613591512

Epoch: 6| Step: 6
Training loss: 4.11944580078125
Validation loss: 3.9108020861943564

Epoch: 6| Step: 7
Training loss: 3.7319955825805664
Validation loss: 3.9044565757115683

Epoch: 6| Step: 8
Training loss: 4.127062797546387
Validation loss: 3.8982170820236206

Epoch: 6| Step: 9
Training loss: 4.503470420837402
Validation loss: 3.8916215896606445

Epoch: 6| Step: 10
Training loss: 3.3133583068847656
Validation loss: 3.885631243387858

Epoch: 6| Step: 11
Training loss: 4.402157306671143
Validation loss: 3.880476156870524

Epoch: 6| Step: 12
Training loss: 3.2084803581237793
Validation loss: 3.8739728132883706

Epoch: 6| Step: 13
Training loss: 3.1756200790405273
Validation loss: 3.8694984912872314

Epoch: 14| Step: 0
Training loss: 2.994953155517578
Validation loss: 3.8636030753453574

Epoch: 6| Step: 1
Training loss: 3.941690683364868
Validation loss: 3.857775847117106

Epoch: 6| Step: 2
Training loss: 5.406253337860107
Validation loss: 3.8564260005950928

Epoch: 6| Step: 3
Training loss: 4.688669204711914
Validation loss: 3.8476226329803467

Epoch: 6| Step: 4
Training loss: 3.3641510009765625
Validation loss: 3.8409773906071982

Epoch: 6| Step: 5
Training loss: 4.092496395111084
Validation loss: 3.8359143336613974

Epoch: 6| Step: 6
Training loss: 3.124072551727295
Validation loss: 3.830394983291626

Epoch: 6| Step: 7
Training loss: 4.1601080894470215
Validation loss: 3.824273665746053

Epoch: 6| Step: 8
Training loss: 3.230616807937622
Validation loss: 3.8182162046432495

Epoch: 6| Step: 9
Training loss: 3.711488723754883
Validation loss: 3.812306523323059

Epoch: 6| Step: 10
Training loss: 4.275358200073242
Validation loss: 3.806986610094706

Epoch: 6| Step: 11
Training loss: 3.942967176437378
Validation loss: 3.8028539419174194

Epoch: 6| Step: 12
Training loss: 5.419851303100586
Validation loss: 3.7970025142033896

Epoch: 6| Step: 13
Training loss: 3.373408317565918
Validation loss: 3.7907148202260337

Epoch: 15| Step: 0
Training loss: 4.681156158447266
Validation loss: 3.7859609921773276

Epoch: 6| Step: 1
Training loss: 4.080081939697266
Validation loss: 3.7800040245056152

Epoch: 6| Step: 2
Training loss: 4.751594543457031
Validation loss: 3.774964213371277

Epoch: 6| Step: 3
Training loss: 2.5983121395111084
Validation loss: 3.769480586051941

Epoch: 6| Step: 4
Training loss: 4.36480712890625
Validation loss: 3.7633612553278604

Epoch: 6| Step: 5
Training loss: 4.328363418579102
Validation loss: 3.7584009170532227

Epoch: 6| Step: 6
Training loss: 3.0351505279541016
Validation loss: 3.7537655035654702

Epoch: 6| Step: 7
Training loss: 4.057222843170166
Validation loss: 3.7508559624354043

Epoch: 6| Step: 8
Training loss: 3.896432638168335
Validation loss: 3.7452982664108276

Epoch: 6| Step: 9
Training loss: 4.14641809463501
Validation loss: 3.739758094151815

Epoch: 6| Step: 10
Training loss: 2.827862024307251
Validation loss: 3.7356783946355185

Epoch: 6| Step: 11
Training loss: 3.6491379737854004
Validation loss: 3.7298166354497275

Epoch: 6| Step: 12
Training loss: 3.909346342086792
Validation loss: 3.7250436544418335

Epoch: 6| Step: 13
Training loss: 4.417989253997803
Validation loss: 3.7197095155715942

Epoch: 16| Step: 0
Training loss: 4.52834415435791
Validation loss: 3.715593179066976

Epoch: 6| Step: 1
Training loss: 4.113616943359375
Validation loss: 3.7104835907618203

Epoch: 6| Step: 2
Training loss: 3.9575722217559814
Validation loss: 3.7059220472971597

Epoch: 6| Step: 3
Training loss: 3.9271349906921387
Validation loss: 3.700773278872172

Epoch: 6| Step: 4
Training loss: 3.8971800804138184
Validation loss: 3.697887738545736

Epoch: 6| Step: 5
Training loss: 4.438340187072754
Validation loss: 3.695219079653422

Epoch: 6| Step: 6
Training loss: 3.152451276779175
Validation loss: 3.6924153168996177

Epoch: 6| Step: 7
Training loss: 3.203186511993408
Validation loss: 3.689182003339132

Epoch: 6| Step: 8
Training loss: 4.103043556213379
Validation loss: 3.6788652737935386

Epoch: 6| Step: 9
Training loss: 2.8314037322998047
Validation loss: 3.6758528550465903

Epoch: 6| Step: 10
Training loss: 3.8186962604522705
Validation loss: 3.674540321032206

Epoch: 6| Step: 11
Training loss: 4.3596296310424805
Validation loss: 3.6672765413920083

Epoch: 6| Step: 12
Training loss: 3.81669545173645
Validation loss: 3.662623882293701

Epoch: 6| Step: 13
Training loss: 3.711721420288086
Validation loss: 3.658103585243225

Epoch: 17| Step: 0
Training loss: 3.4766955375671387
Validation loss: 3.654569149017334

Epoch: 6| Step: 1
Training loss: 3.982189893722534
Validation loss: 3.651508371035258

Epoch: 6| Step: 2
Training loss: 3.170302629470825
Validation loss: 3.647386391957601

Epoch: 6| Step: 3
Training loss: 4.50227165222168
Validation loss: 3.642411708831787

Epoch: 6| Step: 4
Training loss: 3.1765623092651367
Validation loss: 3.636782089869181

Epoch: 6| Step: 5
Training loss: 3.951287269592285
Validation loss: 3.6317343711853027

Epoch: 6| Step: 6
Training loss: 4.486749172210693
Validation loss: 3.6272994677225747

Epoch: 6| Step: 7
Training loss: 4.2160325050354
Validation loss: 3.622855623563131

Epoch: 6| Step: 8
Training loss: 2.4247124195098877
Validation loss: 3.6193215449651084

Epoch: 6| Step: 9
Training loss: 4.920338153839111
Validation loss: 3.6151203711827598

Epoch: 6| Step: 10
Training loss: 3.502403497695923
Validation loss: 3.6106093724568686

Epoch: 6| Step: 11
Training loss: 3.882481336593628
Validation loss: 3.605588436126709

Epoch: 6| Step: 12
Training loss: 3.8993823528289795
Validation loss: 3.5996302366256714

Epoch: 6| Step: 13
Training loss: 3.427485942840576
Validation loss: 3.5962382555007935

Epoch: 18| Step: 0
Training loss: 3.8361525535583496
Validation loss: 3.591319481531779

Epoch: 6| Step: 1
Training loss: 4.865460395812988
Validation loss: 3.585791230201721

Epoch: 6| Step: 2
Training loss: 4.075572967529297
Validation loss: 3.581197500228882

Epoch: 6| Step: 3
Training loss: 3.600790500640869
Validation loss: 3.5766030152638755

Epoch: 6| Step: 4
Training loss: 3.860959529876709
Validation loss: 3.5721643765767417

Epoch: 6| Step: 5
Training loss: 3.3354320526123047
Validation loss: 3.5673470497131348

Epoch: 6| Step: 6
Training loss: 3.7358620166778564
Validation loss: 3.562379002571106

Epoch: 6| Step: 7
Training loss: 5.140498161315918
Validation loss: 3.557888905207316

Epoch: 6| Step: 8
Training loss: 3.5005650520324707
Validation loss: 3.5529112021128335

Epoch: 6| Step: 9
Training loss: 2.338550329208374
Validation loss: 3.547867178916931

Epoch: 6| Step: 10
Training loss: 4.476207733154297
Validation loss: 3.5431344509124756

Epoch: 6| Step: 11
Training loss: 2.8946101665496826
Validation loss: 3.538315256436666

Epoch: 6| Step: 12
Training loss: 3.0819878578186035
Validation loss: 3.534258166948954

Epoch: 6| Step: 13
Training loss: 3.444222927093506
Validation loss: 3.5299234787623086

Epoch: 19| Step: 0
Training loss: 4.666479110717773
Validation loss: 3.525726636250814

Epoch: 6| Step: 1
Training loss: 4.713876247406006
Validation loss: 3.5212040742238364

Epoch: 6| Step: 2
Training loss: 3.095283031463623
Validation loss: 3.5165251096089682

Epoch: 6| Step: 3
Training loss: 3.167882204055786
Validation loss: 3.512926975886027

Epoch: 6| Step: 4
Training loss: 3.713009834289551
Validation loss: 3.508715867996216

Epoch: 6| Step: 5
Training loss: 2.726801633834839
Validation loss: 3.504458745320638

Epoch: 6| Step: 6
Training loss: 3.6147093772888184
Validation loss: 3.500598986943563

Epoch: 6| Step: 7
Training loss: 3.9895687103271484
Validation loss: 3.4958656231562295

Epoch: 6| Step: 8
Training loss: 3.6060686111450195
Validation loss: 3.491132974624634

Epoch: 6| Step: 9
Training loss: 3.1813933849334717
Validation loss: 3.4874037504196167

Epoch: 6| Step: 10
Training loss: 3.7447593212127686
Validation loss: 3.4828776518503823

Epoch: 6| Step: 11
Training loss: 3.801978588104248
Validation loss: 3.478674332300822

Epoch: 6| Step: 12
Training loss: 3.467205762863159
Validation loss: 3.4739646911621094

Epoch: 6| Step: 13
Training loss: 3.8023643493652344
Validation loss: 3.4696430365244546

Epoch: 20| Step: 0
Training loss: 3.063720703125
Validation loss: 3.465511123339335

Epoch: 6| Step: 1
Training loss: 4.451955318450928
Validation loss: 3.4601058959960938

Epoch: 6| Step: 2
Training loss: 3.8050742149353027
Validation loss: 3.455959439277649

Epoch: 6| Step: 3
Training loss: 3.8536558151245117
Validation loss: 3.4512956142425537

Epoch: 6| Step: 4
Training loss: 4.023150444030762
Validation loss: 3.4461981455485025

Epoch: 6| Step: 5
Training loss: 2.851060390472412
Validation loss: 3.4416046142578125

Epoch: 6| Step: 6
Training loss: 3.516602039337158
Validation loss: 3.436984101931254

Epoch: 6| Step: 7
Training loss: 3.5789151191711426
Validation loss: 3.432248512903849

Epoch: 6| Step: 8
Training loss: 3.9595537185668945
Validation loss: 3.427891969680786

Epoch: 6| Step: 9
Training loss: 3.815584182739258
Validation loss: 3.422915776570638

Epoch: 6| Step: 10
Training loss: 3.1772513389587402
Validation loss: 3.4183608293533325

Epoch: 6| Step: 11
Training loss: 4.016714572906494
Validation loss: 3.4144897063573203

Epoch: 6| Step: 12
Training loss: 2.658745765686035
Validation loss: 3.4094666242599487

Epoch: 6| Step: 13
Training loss: 3.670395851135254
Validation loss: 3.4047968784968057

Epoch: 21| Step: 0
Training loss: 3.7942843437194824
Validation loss: 3.40058970451355

Epoch: 6| Step: 1
Training loss: 3.9030041694641113
Validation loss: 3.395359516143799

Epoch: 6| Step: 2
Training loss: 4.6910200119018555
Validation loss: 3.391441226005554

Epoch: 6| Step: 3
Training loss: 3.456653118133545
Validation loss: 3.3872047662734985

Epoch: 6| Step: 4
Training loss: 3.2609915733337402
Validation loss: 3.38248872756958

Epoch: 6| Step: 5
Training loss: 3.1123390197753906
Validation loss: 3.3777743180592856

Epoch: 6| Step: 6
Training loss: 3.5888986587524414
Validation loss: 3.373568852742513

Epoch: 6| Step: 7
Training loss: 2.4547204971313477
Validation loss: 3.3699243466059365

Epoch: 6| Step: 8
Training loss: 3.619813919067383
Validation loss: 3.3650094270706177

Epoch: 6| Step: 9
Training loss: 3.6426663398742676
Validation loss: 3.361186385154724

Epoch: 6| Step: 10
Training loss: 4.002994060516357
Validation loss: 3.3562243779500327

Epoch: 6| Step: 11
Training loss: 2.5470657348632812
Validation loss: 3.352101683616638

Epoch: 6| Step: 12
Training loss: 3.55576491355896
Validation loss: 3.347460667292277

Epoch: 6| Step: 13
Training loss: 3.933932065963745
Validation loss: 3.3437761465708413

Epoch: 22| Step: 0
Training loss: 3.1859638690948486
Validation loss: 3.339097817738851

Epoch: 6| Step: 1
Training loss: 3.926750659942627
Validation loss: 3.3345696131388345

Epoch: 6| Step: 2
Training loss: 3.63166880607605
Validation loss: 3.3300110499064126

Epoch: 6| Step: 3
Training loss: 4.37517786026001
Validation loss: 3.325681686401367

Epoch: 6| Step: 4
Training loss: 3.477426767349243
Validation loss: 3.3212218284606934

Epoch: 6| Step: 5
Training loss: 2.2975850105285645
Validation loss: 3.316820740699768

Epoch: 6| Step: 6
Training loss: 3.05505633354187
Validation loss: 3.3126112620035806

Epoch: 6| Step: 7
Training loss: 3.4313313961029053
Validation loss: 3.3079676230748496

Epoch: 6| Step: 8
Training loss: 3.6708767414093018
Validation loss: 3.3032588958740234

Epoch: 6| Step: 9
Training loss: 3.1935648918151855
Validation loss: 3.2994314432144165

Epoch: 6| Step: 10
Training loss: 4.297975540161133
Validation loss: 3.295174320538839

Epoch: 6| Step: 11
Training loss: 2.700711250305176
Validation loss: 3.2919105291366577

Epoch: 6| Step: 12
Training loss: 3.1864216327667236
Validation loss: 3.2875888347625732

Epoch: 6| Step: 13
Training loss: 4.345688819885254
Validation loss: 3.282958984375

Epoch: 23| Step: 0
Training loss: 2.9104154109954834
Validation loss: 3.2796579202016196

Epoch: 6| Step: 1
Training loss: 4.820302963256836
Validation loss: 3.2778589328130088

Epoch: 6| Step: 2
Training loss: 3.4206390380859375
Validation loss: 3.2713186740875244

Epoch: 6| Step: 3
Training loss: 2.8432257175445557
Validation loss: 3.268182396888733

Epoch: 6| Step: 4
Training loss: 3.5584399700164795
Validation loss: 3.265087842941284

Epoch: 6| Step: 5
Training loss: 3.6485018730163574
Validation loss: 3.263513366381327

Epoch: 6| Step: 6
Training loss: 4.030518531799316
Validation loss: 3.256655136744181

Epoch: 6| Step: 7
Training loss: 3.392406940460205
Validation loss: 3.2520354986190796

Epoch: 6| Step: 8
Training loss: 3.7752163410186768
Validation loss: 3.2487018505732217

Epoch: 6| Step: 9
Training loss: 3.723891019821167
Validation loss: 3.2439080079396567

Epoch: 6| Step: 10
Training loss: 2.8835628032684326
Validation loss: 3.240713596343994

Epoch: 6| Step: 11
Training loss: 3.616414785385132
Validation loss: 3.237761894861857

Epoch: 6| Step: 12
Training loss: 2.6471753120422363
Validation loss: 3.2339017391204834

Epoch: 6| Step: 13
Training loss: 2.769813299179077
Validation loss: 3.2287273009618125

Epoch: 24| Step: 0
Training loss: 2.787372589111328
Validation loss: 3.223199407259623

Epoch: 6| Step: 1
Training loss: 3.451294422149658
Validation loss: 3.2199490070343018

Epoch: 6| Step: 2
Training loss: 3.179851531982422
Validation loss: 3.21535317103068

Epoch: 6| Step: 3
Training loss: 2.1530375480651855
Validation loss: 3.2112865646680198

Epoch: 6| Step: 4
Training loss: 2.839895725250244
Validation loss: 3.2079683939615884

Epoch: 6| Step: 5
Training loss: 3.201371192932129
Validation loss: 3.204195578893026

Epoch: 6| Step: 6
Training loss: 3.582174301147461
Validation loss: 3.2002191146214805

Epoch: 6| Step: 7
Training loss: 4.174129962921143
Validation loss: 3.1962122917175293

Epoch: 6| Step: 8
Training loss: 3.7342050075531006
Validation loss: 3.192533493041992

Epoch: 6| Step: 9
Training loss: 3.7402405738830566
Validation loss: 3.188008944193522

Epoch: 6| Step: 10
Training loss: 2.941868305206299
Validation loss: 3.1840049823125205

Epoch: 6| Step: 11
Training loss: 3.3279025554656982
Validation loss: 3.179959853490194

Epoch: 6| Step: 12
Training loss: 4.111917018890381
Validation loss: 3.1756622791290283

Epoch: 6| Step: 13
Training loss: 4.056120872497559
Validation loss: 3.1715950965881348

Epoch: 25| Step: 0
Training loss: 3.5692543983459473
Validation loss: 3.1675976514816284

Epoch: 6| Step: 1
Training loss: 4.1352338790893555
Validation loss: 3.163476347923279

Epoch: 6| Step: 2
Training loss: 3.1677119731903076
Validation loss: 3.1617965698242188

Epoch: 6| Step: 3
Training loss: 2.9134678840637207
Validation loss: 3.156705379486084

Epoch: 6| Step: 4
Training loss: 3.057398796081543
Validation loss: 3.151904900868734

Epoch: 6| Step: 5
Training loss: 3.759319305419922
Validation loss: 3.147588094075521

Epoch: 6| Step: 6
Training loss: 3.3352437019348145
Validation loss: 3.1436607837677

Epoch: 6| Step: 7
Training loss: 2.4018425941467285
Validation loss: 3.140105883280436

Epoch: 6| Step: 8
Training loss: 3.5080013275146484
Validation loss: 3.1360928217569985

Epoch: 6| Step: 9
Training loss: 3.742152690887451
Validation loss: 3.132400711377462

Epoch: 6| Step: 10
Training loss: 3.8719091415405273
Validation loss: 3.1285276412963867

Epoch: 6| Step: 11
Training loss: 3.5214085578918457
Validation loss: 3.1241376797358194

Epoch: 6| Step: 12
Training loss: 3.055001735687256
Validation loss: 3.1208242972691855

Epoch: 6| Step: 13
Training loss: 2.539473056793213
Validation loss: 3.1162487665812173

Epoch: 26| Step: 0
Training loss: 2.5988380908966064
Validation loss: 3.1126601696014404

Epoch: 6| Step: 1
Training loss: 2.981611490249634
Validation loss: 3.108588536580404

Epoch: 6| Step: 2
Training loss: 2.9456489086151123
Validation loss: 3.1057984431584678

Epoch: 6| Step: 3
Training loss: 3.1864013671875
Validation loss: 3.1020015875498452

Epoch: 6| Step: 4
Training loss: 3.3048949241638184
Validation loss: 3.098109722137451

Epoch: 6| Step: 5
Training loss: 3.3204362392425537
Validation loss: 3.0942430893580117

Epoch: 6| Step: 6
Training loss: 4.217184543609619
Validation loss: 3.0904809633890786

Epoch: 6| Step: 7
Training loss: 3.527127981185913
Validation loss: 3.0873674949010215

Epoch: 6| Step: 8
Training loss: 3.6530251502990723
Validation loss: 3.0829906860987344

Epoch: 6| Step: 9
Training loss: 3.48429012298584
Validation loss: 3.0794533491134644

Epoch: 6| Step: 10
Training loss: 2.6177597045898438
Validation loss: 3.0763896306355796

Epoch: 6| Step: 11
Training loss: 3.4657223224639893
Validation loss: 3.0722883145014444

Epoch: 6| Step: 12
Training loss: 2.3243184089660645
Validation loss: 3.0672358671824136

Epoch: 6| Step: 13
Training loss: 4.2539544105529785
Validation loss: 3.065609574317932

Epoch: 27| Step: 0
Training loss: 3.7041373252868652
Validation loss: 3.0616244077682495

Epoch: 6| Step: 1
Training loss: 3.6898913383483887
Validation loss: 3.0578576723734536

Epoch: 6| Step: 2
Training loss: 2.459353446960449
Validation loss: 3.0568542083104453

Epoch: 6| Step: 3
Training loss: 3.283290386199951
Validation loss: 3.0521495739618936

Epoch: 6| Step: 4
Training loss: 3.1211161613464355
Validation loss: 3.0515553951263428

Epoch: 6| Step: 5
Training loss: 3.2144627571105957
Validation loss: 3.04457950592041

Epoch: 6| Step: 6
Training loss: 3.6003644466400146
Validation loss: 3.0402914683024087

Epoch: 6| Step: 7
Training loss: 3.7187302112579346
Validation loss: 3.036062796910604

Epoch: 6| Step: 8
Training loss: 2.9791297912597656
Validation loss: 3.0327078104019165

Epoch: 6| Step: 9
Training loss: 2.725560188293457
Validation loss: 3.0289474527041116

Epoch: 6| Step: 10
Training loss: 2.6348752975463867
Validation loss: 3.0253167152404785

Epoch: 6| Step: 11
Training loss: 4.245003700256348
Validation loss: 3.022146145502726

Epoch: 6| Step: 12
Training loss: 2.544861316680908
Validation loss: 3.0192362467447915

Epoch: 6| Step: 13
Training loss: 3.2844157218933105
Validation loss: 3.015772223472595

Epoch: 28| Step: 0
Training loss: 2.8127455711364746
Validation loss: 3.0117584069569907

Epoch: 6| Step: 1
Training loss: 3.360447406768799
Validation loss: 3.009003003438314

Epoch: 6| Step: 2
Training loss: 4.030383110046387
Validation loss: 3.004580537478129

Epoch: 6| Step: 3
Training loss: 3.5388600826263428
Validation loss: 3.000242451826731

Epoch: 6| Step: 4
Training loss: 3.026425838470459
Validation loss: 2.997147480646769

Epoch: 6| Step: 5
Training loss: 3.2936248779296875
Validation loss: 2.9940298000971475

Epoch: 6| Step: 6
Training loss: 3.094714641571045
Validation loss: 2.989595333735148

Epoch: 6| Step: 7
Training loss: 3.47125244140625
Validation loss: 2.9855499267578125

Epoch: 6| Step: 8
Training loss: 4.147462368011475
Validation loss: 2.982427795728048

Epoch: 6| Step: 9
Training loss: 3.0016117095947266
Validation loss: 2.9782758553822837

Epoch: 6| Step: 10
Training loss: 2.6575570106506348
Validation loss: 2.975285013516744

Epoch: 6| Step: 11
Training loss: 3.0406007766723633
Validation loss: 2.972212771574656

Epoch: 6| Step: 12
Training loss: 2.431065797805786
Validation loss: 2.968486467997233

Epoch: 6| Step: 13
Training loss: 2.6543257236480713
Validation loss: 2.965188463528951

Epoch: 29| Step: 0
Training loss: 3.2239980697631836
Validation loss: 2.9610748291015625

Epoch: 6| Step: 1
Training loss: 3.0964300632476807
Validation loss: 2.959189494450887

Epoch: 6| Step: 2
Training loss: 2.6623377799987793
Validation loss: 2.9596704244613647

Epoch: 6| Step: 3
Training loss: 3.4304251670837402
Validation loss: 2.9581554730733237

Epoch: 6| Step: 4
Training loss: 4.332218647003174
Validation loss: 2.9533687829971313

Epoch: 6| Step: 5
Training loss: 2.978646755218506
Validation loss: 2.946895202000936

Epoch: 6| Step: 6
Training loss: 3.848116397857666
Validation loss: 2.9425884087880454

Epoch: 6| Step: 7
Training loss: 3.5070929527282715
Validation loss: 2.93727707862854

Epoch: 6| Step: 8
Training loss: 2.748812675476074
Validation loss: 2.932795524597168

Epoch: 6| Step: 9
Training loss: 2.104607582092285
Validation loss: 2.929342826207479

Epoch: 6| Step: 10
Training loss: 2.498455286026001
Validation loss: 2.928326408068339

Epoch: 6| Step: 11
Training loss: 2.938076972961426
Validation loss: 2.92294712861379

Epoch: 6| Step: 12
Training loss: 3.8186733722686768
Validation loss: 2.9194942315419516

Epoch: 6| Step: 13
Training loss: 2.7734053134918213
Validation loss: 2.9156439701716104

Epoch: 30| Step: 0
Training loss: 3.886296272277832
Validation loss: 2.9123555421829224

Epoch: 6| Step: 1
Training loss: 3.9083547592163086
Validation loss: 2.908644715944926

Epoch: 6| Step: 2
Training loss: 2.599121332168579
Validation loss: 2.9053184191385903

Epoch: 6| Step: 3
Training loss: 3.275806188583374
Validation loss: 2.9044001499811807

Epoch: 6| Step: 4
Training loss: 2.16984486579895
Validation loss: 2.8989254236221313

Epoch: 6| Step: 5
Training loss: 3.2311155796051025
Validation loss: 2.896726608276367

Epoch: 6| Step: 6
Training loss: 2.901162624359131
Validation loss: 2.8923767805099487

Epoch: 6| Step: 7
Training loss: 3.7420477867126465
Validation loss: 2.8890151977539062

Epoch: 6| Step: 8
Training loss: 2.801703453063965
Validation loss: 2.885076642036438

Epoch: 6| Step: 9
Training loss: 2.450847625732422
Validation loss: 2.882644295692444

Epoch: 6| Step: 10
Training loss: 2.9024605751037598
Validation loss: 2.8785712718963623

Epoch: 6| Step: 11
Training loss: 2.8722333908081055
Validation loss: 2.875365455945333

Epoch: 6| Step: 12
Training loss: 3.5579309463500977
Validation loss: 2.8719769716262817

Epoch: 6| Step: 13
Training loss: 3.0711865425109863
Validation loss: 2.8699729442596436

Epoch: 31| Step: 0
Training loss: 3.9481163024902344
Validation loss: 2.867509444554647

Epoch: 6| Step: 1
Training loss: 2.316650867462158
Validation loss: 2.863159696261088

Epoch: 6| Step: 2
Training loss: 3.2376317977905273
Validation loss: 2.8628517389297485

Epoch: 6| Step: 3
Training loss: 2.2978591918945312
Validation loss: 2.8635801474253335

Epoch: 6| Step: 4
Training loss: 2.7199716567993164
Validation loss: 2.857674558957418

Epoch: 6| Step: 5
Training loss: 2.479918956756592
Validation loss: 2.851812799771627

Epoch: 6| Step: 6
Training loss: 2.7381949424743652
Validation loss: 2.848462462425232

Epoch: 6| Step: 7
Training loss: 3.061859607696533
Validation loss: 2.848040223121643

Epoch: 6| Step: 8
Training loss: 3.3421831130981445
Validation loss: 2.8443109591801963

Epoch: 6| Step: 9
Training loss: 2.882862091064453
Validation loss: 2.845168113708496

Epoch: 6| Step: 10
Training loss: 4.0552568435668945
Validation loss: 2.838565230369568

Epoch: 6| Step: 11
Training loss: 3.345247507095337
Validation loss: 2.832851072152456

Epoch: 6| Step: 12
Training loss: 3.042898654937744
Validation loss: 2.8277622063954673

Epoch: 6| Step: 13
Training loss: 3.340456008911133
Validation loss: 2.8254563411076865

Epoch: 32| Step: 0
Training loss: 3.225675582885742
Validation loss: 2.8218596378962197

Epoch: 6| Step: 1
Training loss: 3.2970504760742188
Validation loss: 2.821546276410421

Epoch: 6| Step: 2
Training loss: 2.728792905807495
Validation loss: 2.8193734089533486

Epoch: 6| Step: 3
Training loss: 2.0197691917419434
Validation loss: 2.8145347038904824

Epoch: 6| Step: 4
Training loss: 2.764845371246338
Validation loss: 2.8137927850087485

Epoch: 6| Step: 5
Training loss: 3.292941093444824
Validation loss: 2.813219447930654

Epoch: 6| Step: 6
Training loss: 4.648188591003418
Validation loss: 2.8179728984832764

Epoch: 6| Step: 7
Training loss: 2.1605653762817383
Validation loss: 2.8033622105916343

Epoch: 6| Step: 8
Training loss: 2.5158586502075195
Validation loss: 2.7994172970453897

Epoch: 6| Step: 9
Training loss: 3.526188850402832
Validation loss: 2.796574672063192

Epoch: 6| Step: 10
Training loss: 3.2678394317626953
Validation loss: 2.7918893297513327

Epoch: 6| Step: 11
Training loss: 2.0813660621643066
Validation loss: 2.789542039235433

Epoch: 6| Step: 12
Training loss: 3.329824924468994
Validation loss: 2.790440320968628

Epoch: 6| Step: 13
Training loss: 3.372539520263672
Validation loss: 2.792782266934713

Epoch: 33| Step: 0
Training loss: 3.1518473625183105
Validation loss: 2.786618153254191

Epoch: 6| Step: 1
Training loss: 3.378182888031006
Validation loss: 2.7787135442097983

Epoch: 6| Step: 2
Training loss: 2.5849390029907227
Validation loss: 2.774892807006836

Epoch: 6| Step: 3
Training loss: 2.7367706298828125
Validation loss: 2.771518111228943

Epoch: 6| Step: 4
Training loss: 2.9685873985290527
Validation loss: 2.768655260403951

Epoch: 6| Step: 5
Training loss: 3.3593273162841797
Validation loss: 2.766045610109965

Epoch: 6| Step: 6
Training loss: 2.542219638824463
Validation loss: 2.7635836203893027

Epoch: 6| Step: 7
Training loss: 3.0588464736938477
Validation loss: 2.764435569445292

Epoch: 6| Step: 8
Training loss: 2.9385178089141846
Validation loss: 2.7598912715911865

Epoch: 6| Step: 9
Training loss: 2.9351019859313965
Validation loss: 2.7592418591181436

Epoch: 6| Step: 10
Training loss: 3.072167158126831
Validation loss: 2.7565797170003257

Epoch: 6| Step: 11
Training loss: 2.788893461227417
Validation loss: 2.7524802684783936

Epoch: 6| Step: 12
Training loss: 2.7112555503845215
Validation loss: 2.7473522424697876

Epoch: 6| Step: 13
Training loss: 3.3732705116271973
Validation loss: 2.743764599164327

Epoch: 34| Step: 0
Training loss: 2.6847126483917236
Validation loss: 2.739483634630839

Epoch: 6| Step: 1
Training loss: 2.901613235473633
Validation loss: 2.7366624673207602

Epoch: 6| Step: 2
Training loss: 2.129998207092285
Validation loss: 2.7331297794977822

Epoch: 6| Step: 3
Training loss: 1.9814119338989258
Validation loss: 2.7344395319620767

Epoch: 6| Step: 4
Training loss: 3.115558385848999
Validation loss: 2.7494716246922812

Epoch: 6| Step: 5
Training loss: 3.3447320461273193
Validation loss: 2.748722513516744

Epoch: 6| Step: 6
Training loss: 2.822561025619507
Validation loss: 2.72726301352183

Epoch: 6| Step: 7
Training loss: 3.2231667041778564
Validation loss: 2.7171169916788735

Epoch: 6| Step: 8
Training loss: 3.791466236114502
Validation loss: 2.716688553492228

Epoch: 6| Step: 9
Training loss: 2.417393207550049
Validation loss: 2.7188608249028525

Epoch: 6| Step: 10
Training loss: 2.4763143062591553
Validation loss: 2.728620767593384

Epoch: 6| Step: 11
Training loss: 2.66542387008667
Validation loss: 2.753195842107137

Epoch: 6| Step: 12
Training loss: 3.5656301975250244
Validation loss: 2.7206164995829263

Epoch: 6| Step: 13
Training loss: 3.9931159019470215
Validation loss: 2.7092319329579673

Epoch: 35| Step: 0
Training loss: 2.591688394546509
Validation loss: 2.7013825178146362

Epoch: 6| Step: 1
Training loss: 2.2168259620666504
Validation loss: 2.6957892974217734

Epoch: 6| Step: 2
Training loss: 3.5153050422668457
Validation loss: 2.692811369895935

Epoch: 6| Step: 3
Training loss: 3.3085150718688965
Validation loss: 2.690338750680288

Epoch: 6| Step: 4
Training loss: 3.176175594329834
Validation loss: 2.6886778473854065

Epoch: 6| Step: 5
Training loss: 3.347838878631592
Validation loss: 2.689440886179606

Epoch: 6| Step: 6
Training loss: 2.8913564682006836
Validation loss: 2.68585995833079

Epoch: 6| Step: 7
Training loss: 2.580843925476074
Validation loss: 2.6873244841893515

Epoch: 6| Step: 8
Training loss: 2.7563135623931885
Validation loss: 2.6870916287104287

Epoch: 6| Step: 9
Training loss: 2.4712257385253906
Validation loss: 2.6841785510381064

Epoch: 6| Step: 10
Training loss: 2.8353941440582275
Validation loss: 2.6736241976420083

Epoch: 6| Step: 11
Training loss: 3.309671401977539
Validation loss: 2.6665326754252114

Epoch: 6| Step: 12
Training loss: 2.6961846351623535
Validation loss: 2.6622825463612876

Epoch: 6| Step: 13
Training loss: 2.7570395469665527
Validation loss: 2.659249782562256

Epoch: 36| Step: 0
Training loss: 3.3586316108703613
Validation loss: 2.6563742955525718

Epoch: 6| Step: 1
Training loss: 2.352229356765747
Validation loss: 2.6520050764083862

Epoch: 6| Step: 2
Training loss: 2.580820083618164
Validation loss: 2.649784962336222

Epoch: 6| Step: 3
Training loss: 3.0431106090545654
Validation loss: 2.645533482233683

Epoch: 6| Step: 4
Training loss: 2.5460636615753174
Validation loss: 2.6442252000172934

Epoch: 6| Step: 5
Training loss: 2.862541437149048
Validation loss: 2.6374608278274536

Epoch: 6| Step: 6
Training loss: 2.803919792175293
Validation loss: 2.6340827544530234

Epoch: 6| Step: 7
Training loss: 3.674285411834717
Validation loss: 2.6311935981114707

Epoch: 6| Step: 8
Training loss: 2.7837655544281006
Validation loss: 2.6298400163650513

Epoch: 6| Step: 9
Training loss: 2.5938143730163574
Validation loss: 2.6257845958073935

Epoch: 6| Step: 10
Training loss: 2.357206344604492
Validation loss: 2.6225874423980713

Epoch: 6| Step: 11
Training loss: 3.4136383533477783
Validation loss: 2.6209022601445517

Epoch: 6| Step: 12
Training loss: 2.8829400539398193
Validation loss: 2.6152048905690513

Epoch: 6| Step: 13
Training loss: 2.472060203552246
Validation loss: 2.6146883964538574

Epoch: 37| Step: 0
Training loss: 3.011042833328247
Validation loss: 2.6097302039464316

Epoch: 6| Step: 1
Training loss: 2.6697731018066406
Validation loss: 2.606338640054067

Epoch: 6| Step: 2
Training loss: 3.2745351791381836
Validation loss: 2.604137579600016

Epoch: 6| Step: 3
Training loss: 3.1278934478759766
Validation loss: 2.599909504254659

Epoch: 6| Step: 4
Training loss: 2.808710813522339
Validation loss: 2.5956905682881675

Epoch: 6| Step: 5
Training loss: 2.4287519454956055
Validation loss: 2.591315587361654

Epoch: 6| Step: 6
Training loss: 3.005664587020874
Validation loss: 2.5883702437082925

Epoch: 6| Step: 7
Training loss: 2.6165363788604736
Validation loss: 2.584691127141317

Epoch: 6| Step: 8
Training loss: 2.982602834701538
Validation loss: 2.5831551551818848

Epoch: 6| Step: 9
Training loss: 2.5353071689605713
Validation loss: 2.57945982615153

Epoch: 6| Step: 10
Training loss: 3.0966849327087402
Validation loss: 2.573586861292521

Epoch: 6| Step: 11
Training loss: 2.2664906978607178
Validation loss: 2.572043458620707

Epoch: 6| Step: 12
Training loss: 2.1679434776306152
Validation loss: 2.57081405321757

Epoch: 6| Step: 13
Training loss: 3.105950355529785
Validation loss: 2.570092419783274

Epoch: 38| Step: 0
Training loss: 3.020354747772217
Validation loss: 2.567455768585205

Epoch: 6| Step: 1
Training loss: 2.9289755821228027
Validation loss: 2.563292940457662

Epoch: 6| Step: 2
Training loss: 2.8597702980041504
Validation loss: 2.5609697898228965

Epoch: 6| Step: 3
Training loss: 2.925624370574951
Validation loss: 2.5566733678181968

Epoch: 6| Step: 4
Training loss: 3.1455161571502686
Validation loss: 2.5526663859685264

Epoch: 6| Step: 5
Training loss: 2.5165157318115234
Validation loss: 2.551712473233541

Epoch: 6| Step: 6
Training loss: 1.6799588203430176
Validation loss: 2.5486436684926352

Epoch: 6| Step: 7
Training loss: 2.192626953125
Validation loss: 2.545764406522115

Epoch: 6| Step: 8
Training loss: 2.863222599029541
Validation loss: 2.5443918307622275

Epoch: 6| Step: 9
Training loss: 3.24169921875
Validation loss: 2.542584180831909

Epoch: 6| Step: 10
Training loss: 2.328120231628418
Validation loss: 2.539364536603292

Epoch: 6| Step: 11
Training loss: 3.299574375152588
Validation loss: 2.5358418424924216

Epoch: 6| Step: 12
Training loss: 2.727224349975586
Validation loss: 2.5314040978749595

Epoch: 6| Step: 13
Training loss: 2.709669828414917
Validation loss: 2.53070334593455

Epoch: 39| Step: 0
Training loss: 2.387763738632202
Validation loss: 2.5276779333750405

Epoch: 6| Step: 1
Training loss: 3.0597221851348877
Validation loss: 2.5284897089004517

Epoch: 6| Step: 2
Training loss: 2.9774112701416016
Validation loss: 2.534562905629476

Epoch: 6| Step: 3
Training loss: 2.8523550033569336
Validation loss: 2.5347206592559814

Epoch: 6| Step: 4
Training loss: 2.343048095703125
Validation loss: 2.5401949882507324

Epoch: 6| Step: 5
Training loss: 2.779639720916748
Validation loss: 2.530600627263387

Epoch: 6| Step: 6
Training loss: 2.6856565475463867
Validation loss: 2.508706529935201

Epoch: 6| Step: 7
Training loss: 2.74593186378479
Validation loss: 2.506095806757609

Epoch: 6| Step: 8
Training loss: 3.22615385055542
Validation loss: 2.504837075869242

Epoch: 6| Step: 9
Training loss: 2.828282594680786
Validation loss: 2.5031574169794717

Epoch: 6| Step: 10
Training loss: 2.726073980331421
Validation loss: 2.5085091590881348

Epoch: 6| Step: 11
Training loss: 2.6167855262756348
Validation loss: 2.5234078963597617

Epoch: 6| Step: 12
Training loss: 2.7819557189941406
Validation loss: 2.5214993556340537

Epoch: 6| Step: 13
Training loss: 1.9721614122390747
Validation loss: 2.518858273824056

Epoch: 40| Step: 0
Training loss: 2.7213287353515625
Validation loss: 2.509469906489054

Epoch: 6| Step: 1
Training loss: 3.2001311779022217
Validation loss: 2.4922186136245728

Epoch: 6| Step: 2
Training loss: 2.7649645805358887
Validation loss: 2.4880851109822593

Epoch: 6| Step: 3
Training loss: 3.0606069564819336
Validation loss: 2.4826943079630532

Epoch: 6| Step: 4
Training loss: 2.6635541915893555
Validation loss: 2.4798453648885093

Epoch: 6| Step: 5
Training loss: 2.2294692993164062
Validation loss: 2.4760560989379883

Epoch: 6| Step: 6
Training loss: 2.437199592590332
Validation loss: 2.4735451340675354

Epoch: 6| Step: 7
Training loss: 2.7262659072875977
Validation loss: 2.470390955607096

Epoch: 6| Step: 8
Training loss: 2.5879948139190674
Validation loss: 2.4675437013308206

Epoch: 6| Step: 9
Training loss: 2.347313404083252
Validation loss: 2.4664875666300454

Epoch: 6| Step: 10
Training loss: 2.6761608123779297
Validation loss: 2.461906353632609

Epoch: 6| Step: 11
Training loss: 2.82395601272583
Validation loss: 2.4615767002105713

Epoch: 6| Step: 12
Training loss: 2.0360312461853027
Validation loss: 2.458928028742472

Epoch: 6| Step: 13
Training loss: 3.0739872455596924
Validation loss: 2.4521973927815757

Epoch: 41| Step: 0
Training loss: 2.4419093132019043
Validation loss: 2.4531803131103516

Epoch: 6| Step: 1
Training loss: 2.9938509464263916
Validation loss: 2.4549182653427124

Epoch: 6| Step: 2
Training loss: 2.2703919410705566
Validation loss: 2.454620917638143

Epoch: 6| Step: 3
Training loss: 2.6154158115386963
Validation loss: 2.44404798746109

Epoch: 6| Step: 4
Training loss: 2.6071770191192627
Validation loss: 2.4398394425710044

Epoch: 6| Step: 5
Training loss: 2.251967430114746
Validation loss: 2.4377147555351257

Epoch: 6| Step: 6
Training loss: 3.0466957092285156
Validation loss: 2.432327707608541

Epoch: 6| Step: 7
Training loss: 2.523261070251465
Validation loss: 2.4301533301671348

Epoch: 6| Step: 8
Training loss: 2.2565622329711914
Validation loss: 2.4286033312479653

Epoch: 6| Step: 9
Training loss: 2.733689069747925
Validation loss: 2.4257291158040366

Epoch: 6| Step: 10
Training loss: 2.7775933742523193
Validation loss: 2.419715662797292

Epoch: 6| Step: 11
Training loss: 2.297135353088379
Validation loss: 2.422822038332621

Epoch: 6| Step: 12
Training loss: 2.8175597190856934
Validation loss: 2.417942444483439

Epoch: 6| Step: 13
Training loss: 3.055032730102539
Validation loss: 2.4198833306630454

Epoch: 42| Step: 0
Training loss: 2.2211339473724365
Validation loss: 2.4143142302831015

Epoch: 6| Step: 1
Training loss: 2.725029468536377
Validation loss: 2.409522612889608

Epoch: 6| Step: 2
Training loss: 2.1981163024902344
Validation loss: 2.407585302988688

Epoch: 6| Step: 3
Training loss: 2.6813106536865234
Validation loss: 2.403751254081726

Epoch: 6| Step: 4
Training loss: 2.7564170360565186
Validation loss: 2.3983203768730164

Epoch: 6| Step: 5
Training loss: 1.8853938579559326
Validation loss: 2.397928774356842

Epoch: 6| Step: 6
Training loss: 2.538813352584839
Validation loss: 2.394630193710327

Epoch: 6| Step: 7
Training loss: 2.2421116828918457
Validation loss: 2.389636198679606

Epoch: 6| Step: 8
Training loss: 2.8728716373443604
Validation loss: 2.391706347465515

Epoch: 6| Step: 9
Training loss: 3.1553072929382324
Validation loss: 2.3807501594225564

Epoch: 6| Step: 10
Training loss: 3.1880993843078613
Validation loss: 2.3791406551996865

Epoch: 6| Step: 11
Training loss: 2.603355884552002
Validation loss: 2.3779050509134927

Epoch: 6| Step: 12
Training loss: 2.420368194580078
Validation loss: 2.3754583994547525

Epoch: 6| Step: 13
Training loss: 2.573976516723633
Validation loss: 2.3723080158233643

Epoch: 43| Step: 0
Training loss: 2.6669652462005615
Validation loss: 2.3734621008237204

Epoch: 6| Step: 1
Training loss: 2.464085578918457
Validation loss: 2.3688305616378784

Epoch: 6| Step: 2
Training loss: 2.5163090229034424
Validation loss: 2.3661844730377197

Epoch: 6| Step: 3
Training loss: 2.700814723968506
Validation loss: 2.365759332974752

Epoch: 6| Step: 4
Training loss: 2.332271099090576
Validation loss: 2.364376405874888

Epoch: 6| Step: 5
Training loss: 2.2023696899414062
Validation loss: 2.3629980087280273

Epoch: 6| Step: 6
Training loss: 2.0436854362487793
Validation loss: 2.3603347341219583

Epoch: 6| Step: 7
Training loss: 2.2656421661376953
Validation loss: 2.3573355277379355

Epoch: 6| Step: 8
Training loss: 2.523963689804077
Validation loss: 2.3557985424995422

Epoch: 6| Step: 9
Training loss: 3.1434876918792725
Validation loss: 2.3523224592208862

Epoch: 6| Step: 10
Training loss: 2.238663673400879
Validation loss: 2.349019169807434

Epoch: 6| Step: 11
Training loss: 2.698216438293457
Validation loss: 2.345416307449341

Epoch: 6| Step: 12
Training loss: 2.650024890899658
Validation loss: 2.343884587287903

Epoch: 6| Step: 13
Training loss: 3.1205413341522217
Validation loss: 2.34181942542394

Epoch: 44| Step: 0
Training loss: 2.2439188957214355
Validation loss: 2.3351875146230063

Epoch: 6| Step: 1
Training loss: 2.526552438735962
Validation loss: 2.3351497650146484

Epoch: 6| Step: 2
Training loss: 3.013108253479004
Validation loss: 2.337486147880554

Epoch: 6| Step: 3
Training loss: 2.6977338790893555
Validation loss: 2.3316311041514077

Epoch: 6| Step: 4
Training loss: 2.8702807426452637
Validation loss: 2.329904794692993

Epoch: 6| Step: 5
Training loss: 2.226323366165161
Validation loss: 2.3247986833254495

Epoch: 6| Step: 6
Training loss: 2.071908712387085
Validation loss: 2.327273945013682

Epoch: 6| Step: 7
Training loss: 2.5781140327453613
Validation loss: 2.334090848763784

Epoch: 6| Step: 8
Training loss: 2.767075777053833
Validation loss: 2.3327606519063315

Epoch: 6| Step: 9
Training loss: 1.9459599256515503
Validation loss: 2.325909694035848

Epoch: 6| Step: 10
Training loss: 2.335841178894043
Validation loss: 2.312800725301107

Epoch: 6| Step: 11
Training loss: 2.132596969604492
Validation loss: 2.308365225791931

Epoch: 6| Step: 12
Training loss: 2.8199353218078613
Validation loss: 2.3053695956865945

Epoch: 6| Step: 13
Training loss: 2.720991849899292
Validation loss: 2.3034114837646484

Epoch: 45| Step: 0
Training loss: 2.4143013954162598
Validation loss: 2.301938513914744

Epoch: 6| Step: 1
Training loss: 2.7804555892944336
Validation loss: 2.2994836370150247

Epoch: 6| Step: 2
Training loss: 2.0764389038085938
Validation loss: 2.2984432379404702

Epoch: 6| Step: 3
Training loss: 2.8818256855010986
Validation loss: 2.2935006618499756

Epoch: 6| Step: 4
Training loss: 2.175455093383789
Validation loss: 2.2919667760531106

Epoch: 6| Step: 5
Training loss: 3.0467796325683594
Validation loss: 2.2849690119425454

Epoch: 6| Step: 6
Training loss: 3.264951229095459
Validation loss: 2.2791760762532554

Epoch: 6| Step: 7
Training loss: 2.0963289737701416
Validation loss: 2.2824451327323914

Epoch: 6| Step: 8
Training loss: 1.854895830154419
Validation loss: 2.280069649219513

Epoch: 6| Step: 9
Training loss: 2.61556339263916
Validation loss: 2.274335265159607

Epoch: 6| Step: 10
Training loss: 1.809164047241211
Validation loss: 2.273957987626394

Epoch: 6| Step: 11
Training loss: 2.6346659660339355
Validation loss: 2.26988156636556

Epoch: 6| Step: 12
Training loss: 2.371635913848877
Validation loss: 2.2668473521868386

Epoch: 6| Step: 13
Training loss: 2.3021838665008545
Validation loss: 2.261615057786306

Epoch: 46| Step: 0
Training loss: 2.946113109588623
Validation loss: 2.2616117795308432

Epoch: 6| Step: 1
Training loss: 1.9248454570770264
Validation loss: 2.25851837793986

Epoch: 6| Step: 2
Training loss: 2.8277673721313477
Validation loss: 2.2611443201700845

Epoch: 6| Step: 3
Training loss: 2.4715890884399414
Validation loss: 2.252394954363505

Epoch: 6| Step: 4
Training loss: 2.5435876846313477
Validation loss: 2.257174253463745

Epoch: 6| Step: 5
Training loss: 2.2867233753204346
Validation loss: 2.2528489430745444

Epoch: 6| Step: 6
Training loss: 2.6808691024780273
Validation loss: 2.2461498975753784

Epoch: 6| Step: 7
Training loss: 1.856508731842041
Validation loss: 2.243559797604879

Epoch: 6| Step: 8
Training loss: 2.165774345397949
Validation loss: 2.2451791564623513

Epoch: 6| Step: 9
Training loss: 2.6947288513183594
Validation loss: 2.246551811695099

Epoch: 6| Step: 10
Training loss: 2.608194351196289
Validation loss: 2.243318339188894

Epoch: 6| Step: 11
Training loss: 2.175062656402588
Validation loss: 2.24883496761322

Epoch: 6| Step: 12
Training loss: 2.2186684608459473
Validation loss: 2.2482560873031616

Epoch: 6| Step: 13
Training loss: 2.459023952484131
Validation loss: 2.245304544766744

Epoch: 47| Step: 0
Training loss: 2.451831340789795
Validation loss: 2.241083284219106

Epoch: 6| Step: 1
Training loss: 1.9095460176467896
Validation loss: 2.2394246657689414

Epoch: 6| Step: 2
Training loss: 3.063359260559082
Validation loss: 2.240392525990804

Epoch: 6| Step: 3
Training loss: 2.089756488800049
Validation loss: 2.23701411485672

Epoch: 6| Step: 4
Training loss: 2.6779747009277344
Validation loss: 2.2347387870152793

Epoch: 6| Step: 5
Training loss: 2.6432671546936035
Validation loss: 2.231940825780233

Epoch: 6| Step: 6
Training loss: 2.041914224624634
Validation loss: 2.228741010030111

Epoch: 6| Step: 7
Training loss: 2.4172210693359375
Validation loss: 2.228677292664846

Epoch: 6| Step: 8
Training loss: 2.4577555656433105
Validation loss: 2.2242823441823325

Epoch: 6| Step: 9
Training loss: 2.648672342300415
Validation loss: 2.2197193106015525

Epoch: 6| Step: 10
Training loss: 2.1159424781799316
Validation loss: 2.216310958067576

Epoch: 6| Step: 11
Training loss: 2.658468008041382
Validation loss: 2.2146554986635842

Epoch: 6| Step: 12
Training loss: 2.337780237197876
Validation loss: 2.214372913042704

Epoch: 6| Step: 13
Training loss: 1.9899230003356934
Validation loss: 2.2118005553881326

Epoch: 48| Step: 0
Training loss: 2.7130815982818604
Validation loss: 2.207702418168386

Epoch: 6| Step: 1
Training loss: 2.577094793319702
Validation loss: 2.201321522394816

Epoch: 6| Step: 2
Training loss: 1.9744523763656616
Validation loss: 2.202319343884786

Epoch: 6| Step: 3
Training loss: 1.8565502166748047
Validation loss: 2.1993455489476523

Epoch: 6| Step: 4
Training loss: 1.9873557090759277
Validation loss: 2.1992903550465903

Epoch: 6| Step: 5
Training loss: 2.438817262649536
Validation loss: 2.200978954633077

Epoch: 6| Step: 6
Training loss: 2.0813307762145996
Validation loss: 2.1961881518363953

Epoch: 6| Step: 7
Training loss: 2.6803383827209473
Validation loss: 2.188709338506063

Epoch: 6| Step: 8
Training loss: 1.880566120147705
Validation loss: 2.1837966044743857

Epoch: 6| Step: 9
Training loss: 2.31181001663208
Validation loss: 2.1882810990015664

Epoch: 6| Step: 10
Training loss: 2.6270570755004883
Validation loss: 2.183192809422811

Epoch: 6| Step: 11
Training loss: 2.7449302673339844
Validation loss: 2.183435241381327

Epoch: 6| Step: 12
Training loss: 2.8316752910614014
Validation loss: 2.181430776913961

Epoch: 6| Step: 13
Training loss: 2.3291735649108887
Validation loss: 2.1783572832743325

Epoch: 49| Step: 0
Training loss: 2.8566370010375977
Validation loss: 2.181105593840281

Epoch: 6| Step: 1
Training loss: 2.3800289630889893
Validation loss: 2.170864462852478

Epoch: 6| Step: 2
Training loss: 2.7053794860839844
Validation loss: 2.1736482779184976

Epoch: 6| Step: 3
Training loss: 2.654636859893799
Validation loss: 2.175902565320333

Epoch: 6| Step: 4
Training loss: 2.482301950454712
Validation loss: 2.172531088193258

Epoch: 6| Step: 5
Training loss: 2.217315196990967
Validation loss: 2.178170601526896

Epoch: 6| Step: 6
Training loss: 1.8594216108322144
Validation loss: 2.1782256364822388

Epoch: 6| Step: 7
Training loss: 2.0227267742156982
Validation loss: 2.1876325408617654

Epoch: 6| Step: 8
Training loss: 2.7087271213531494
Validation loss: 2.1866019566853843

Epoch: 6| Step: 9
Training loss: 2.1497716903686523
Validation loss: 2.179803490638733

Epoch: 6| Step: 10
Training loss: 1.8842883110046387
Validation loss: 2.162575840950012

Epoch: 6| Step: 11
Training loss: 2.1319329738616943
Validation loss: 2.177928348382314

Epoch: 6| Step: 12
Training loss: 1.9956883192062378
Validation loss: 2.15654448668162

Epoch: 6| Step: 13
Training loss: 2.6746082305908203
Validation loss: 2.1564191579818726

Epoch: 50| Step: 0
Training loss: 1.8200945854187012
Validation loss: 2.1505550146102905

Epoch: 6| Step: 1
Training loss: 2.430314540863037
Validation loss: 2.1580850084622702

Epoch: 6| Step: 2
Training loss: 1.7628620862960815
Validation loss: 2.15987761815389

Epoch: 6| Step: 3
Training loss: 2.7788498401641846
Validation loss: 2.1576616962750754

Epoch: 6| Step: 4
Training loss: 2.776765823364258
Validation loss: 2.1613127986590066

Epoch: 6| Step: 5
Training loss: 1.968152642250061
Validation loss: 2.1709773739178977

Epoch: 6| Step: 6
Training loss: 2.09954571723938
Validation loss: 2.1684336264928183

Epoch: 6| Step: 7
Training loss: 2.1657421588897705
Validation loss: 2.1771956284840903

Epoch: 6| Step: 8
Training loss: 2.385392665863037
Validation loss: 2.166176656881968

Epoch: 6| Step: 9
Training loss: 2.5315918922424316
Validation loss: 2.1588727235794067

Epoch: 6| Step: 10
Training loss: 2.1039743423461914
Validation loss: 2.1556941668192544

Epoch: 6| Step: 11
Training loss: 2.328533172607422
Validation loss: 2.1529340346654258

Epoch: 6| Step: 12
Training loss: 2.4015965461730957
Validation loss: 2.156575361887614

Epoch: 6| Step: 13
Training loss: 3.1175765991210938
Validation loss: 2.154854396979014

Epoch: 51| Step: 0
Training loss: 2.5288493633270264
Validation loss: 2.159679730733236

Epoch: 6| Step: 1
Training loss: 2.5871076583862305
Validation loss: 2.151533007621765

Epoch: 6| Step: 2
Training loss: 2.257270097732544
Validation loss: 2.1552525758743286

Epoch: 6| Step: 3
Training loss: 1.8382346630096436
Validation loss: 2.14390895764033

Epoch: 6| Step: 4
Training loss: 2.8522744178771973
Validation loss: 2.130262076854706

Epoch: 6| Step: 5
Training loss: 2.5386962890625
Validation loss: 2.127550959587097

Epoch: 6| Step: 6
Training loss: 2.1695141792297363
Validation loss: 2.12529585758845

Epoch: 6| Step: 7
Training loss: 2.6846566200256348
Validation loss: 2.1253830989201865

Epoch: 6| Step: 8
Training loss: 2.4377458095550537
Validation loss: 2.1242597301801047

Epoch: 6| Step: 9
Training loss: 2.122837543487549
Validation loss: 2.1262693206469216

Epoch: 6| Step: 10
Training loss: 1.130868911743164
Validation loss: 2.1289771795272827

Epoch: 6| Step: 11
Training loss: 2.5662479400634766
Validation loss: 2.122713625431061

Epoch: 6| Step: 12
Training loss: 2.3409910202026367
Validation loss: 2.1263795097668967

Epoch: 6| Step: 13
Training loss: 2.416836738586426
Validation loss: 2.1238003373146057

Epoch: 52| Step: 0
Training loss: 2.559453248977661
Validation loss: 2.1176215211550393

Epoch: 6| Step: 1
Training loss: 1.9544086456298828
Validation loss: 2.12314635515213

Epoch: 6| Step: 2
Training loss: 3.0091700553894043
Validation loss: 2.120110273361206

Epoch: 6| Step: 3
Training loss: 1.9404475688934326
Validation loss: 2.1159415443738303

Epoch: 6| Step: 4
Training loss: 2.2257182598114014
Validation loss: 2.123080591360728

Epoch: 6| Step: 5
Training loss: 1.9353270530700684
Validation loss: 2.1242027282714844

Epoch: 6| Step: 6
Training loss: 2.56282901763916
Validation loss: 2.128917853037516

Epoch: 6| Step: 7
Training loss: 1.9995124340057373
Validation loss: 2.1331849296887717

Epoch: 6| Step: 8
Training loss: 2.425065040588379
Validation loss: 2.1225560704867044

Epoch: 6| Step: 9
Training loss: 2.4755373001098633
Validation loss: 2.1560546358426413

Epoch: 6| Step: 10
Training loss: 2.5503251552581787
Validation loss: 2.130392332871755

Epoch: 6| Step: 11
Training loss: 1.8014761209487915
Validation loss: 2.1110390424728394

Epoch: 6| Step: 12
Training loss: 2.164595127105713
Validation loss: 2.1096062064170837

Epoch: 6| Step: 13
Training loss: 2.462224006652832
Validation loss: 2.1045637329419455

Epoch: 53| Step: 0
Training loss: 1.800284743309021
Validation loss: 2.10831481218338

Epoch: 6| Step: 1
Training loss: 2.591144323348999
Validation loss: 2.105987628300985

Epoch: 6| Step: 2
Training loss: 2.244612216949463
Validation loss: 2.109092652797699

Epoch: 6| Step: 3
Training loss: 1.9537042379379272
Validation loss: 2.111897349357605

Epoch: 6| Step: 4
Training loss: 2.221965789794922
Validation loss: 2.1096712549527488

Epoch: 6| Step: 5
Training loss: 2.5381686687469482
Validation loss: 2.110961596171061

Epoch: 6| Step: 6
Training loss: 2.150364398956299
Validation loss: 2.110336204369863

Epoch: 6| Step: 7
Training loss: 2.423798084259033
Validation loss: 2.112227141857147

Epoch: 6| Step: 8
Training loss: 2.619917869567871
Validation loss: 2.1057608922322593

Epoch: 6| Step: 9
Training loss: 2.316214084625244
Validation loss: 2.1010897954305015

Epoch: 6| Step: 10
Training loss: 2.7250375747680664
Validation loss: 2.099785089492798

Epoch: 6| Step: 11
Training loss: 1.9446240663528442
Validation loss: 2.1005374590555825

Epoch: 6| Step: 12
Training loss: 2.00571870803833
Validation loss: 2.100061317284902

Epoch: 6| Step: 13
Training loss: 2.4856295585632324
Validation loss: 2.092866321404775

Epoch: 54| Step: 0
Training loss: 2.8604559898376465
Validation loss: 2.0901443560918174

Epoch: 6| Step: 1
Training loss: 2.0811407566070557
Validation loss: 2.0940502882003784

Epoch: 6| Step: 2
Training loss: 2.501067638397217
Validation loss: 2.0935502847035727

Epoch: 6| Step: 3
Training loss: 2.6150994300842285
Validation loss: 2.093176027139028

Epoch: 6| Step: 4
Training loss: 1.9717656373977661
Validation loss: 2.0809104839960733

Epoch: 6| Step: 5
Training loss: 2.085570812225342
Validation loss: 2.071629504362742

Epoch: 6| Step: 6
Training loss: 2.0789005756378174
Validation loss: 2.081684668858846

Epoch: 6| Step: 7
Training loss: 2.368725299835205
Validation loss: 2.081309894720713

Epoch: 6| Step: 8
Training loss: 1.882450819015503
Validation loss: 2.0805844267209372

Epoch: 6| Step: 9
Training loss: 2.0828094482421875
Validation loss: 2.0846517086029053

Epoch: 6| Step: 10
Training loss: 2.7511990070343018
Validation loss: 2.07773627837499

Epoch: 6| Step: 11
Training loss: 2.0212044715881348
Validation loss: 2.0660585363705954

Epoch: 6| Step: 12
Training loss: 2.7090559005737305
Validation loss: 2.0658522844314575

Epoch: 6| Step: 13
Training loss: 1.7328453063964844
Validation loss: 2.0651646852493286

Epoch: 55| Step: 0
Training loss: 2.3988609313964844
Validation loss: 2.0694424907366433

Epoch: 6| Step: 1
Training loss: 1.9699299335479736
Validation loss: 2.073465943336487

Epoch: 6| Step: 2
Training loss: 2.683527946472168
Validation loss: 2.067672153313955

Epoch: 6| Step: 3
Training loss: 2.278233766555786
Validation loss: 2.0686805645624795

Epoch: 6| Step: 4
Training loss: 2.3029918670654297
Validation loss: 2.060913562774658

Epoch: 6| Step: 5
Training loss: 2.0446290969848633
Validation loss: 2.0645615657170615

Epoch: 6| Step: 6
Training loss: 1.681067705154419
Validation loss: 2.0585270126660666

Epoch: 6| Step: 7
Training loss: 2.477477550506592
Validation loss: 2.0576719443003335

Epoch: 6| Step: 8
Training loss: 2.406501054763794
Validation loss: 2.0619256099065146

Epoch: 6| Step: 9
Training loss: 2.235128879547119
Validation loss: 2.065487821896871

Epoch: 6| Step: 10
Training loss: 2.8213534355163574
Validation loss: 2.0635236303011575

Epoch: 6| Step: 11
Training loss: 2.116054058074951
Validation loss: 2.0651626586914062

Epoch: 6| Step: 12
Training loss: 2.3842074871063232
Validation loss: 2.058373669783274

Epoch: 6| Step: 13
Training loss: 1.759891152381897
Validation loss: 2.065356413523356

Epoch: 56| Step: 0
Training loss: 2.5274481773376465
Validation loss: 2.0600247383117676

Epoch: 6| Step: 1
Training loss: 2.444518566131592
Validation loss: 2.062403678894043

Epoch: 6| Step: 2
Training loss: 1.744271993637085
Validation loss: 2.0658926963806152

Epoch: 6| Step: 3
Training loss: 2.4302971363067627
Validation loss: 2.0669926603635154

Epoch: 6| Step: 4
Training loss: 2.2008657455444336
Validation loss: 2.0697938005129495

Epoch: 6| Step: 5
Training loss: 2.5700435638427734
Validation loss: 2.0702237685521445

Epoch: 6| Step: 6
Training loss: 1.739515781402588
Validation loss: 2.0650728146235147

Epoch: 6| Step: 7
Training loss: 2.0797669887542725
Validation loss: 2.061860223611196

Epoch: 6| Step: 8
Training loss: 2.7756316661834717
Validation loss: 2.0624209443728128

Epoch: 6| Step: 9
Training loss: 2.4940834045410156
Validation loss: 2.0555514891942344

Epoch: 6| Step: 10
Training loss: 1.8450865745544434
Validation loss: 2.0542287031809487

Epoch: 6| Step: 11
Training loss: 2.42333722114563
Validation loss: 2.055118223031362

Epoch: 6| Step: 12
Training loss: 2.063906669616699
Validation loss: 2.051887889703115

Epoch: 6| Step: 13
Training loss: 2.040234327316284
Validation loss: 2.049776275952657

Epoch: 57| Step: 0
Training loss: 2.1972851753234863
Validation loss: 2.0533366203308105

Epoch: 6| Step: 1
Training loss: 2.2230002880096436
Validation loss: 2.0692070722579956

Epoch: 6| Step: 2
Training loss: 1.800050973892212
Validation loss: 2.0641548236211142

Epoch: 6| Step: 3
Training loss: 2.1120080947875977
Validation loss: 2.0655290285746255

Epoch: 6| Step: 4
Training loss: 2.0849828720092773
Validation loss: 2.0544392267862954

Epoch: 6| Step: 5
Training loss: 2.474609851837158
Validation loss: 2.046862761179606

Epoch: 6| Step: 6
Training loss: 2.0548524856567383
Validation loss: 2.0451499223709106

Epoch: 6| Step: 7
Training loss: 2.5782880783081055
Validation loss: 2.0532953341801963

Epoch: 6| Step: 8
Training loss: 2.332089424133301
Validation loss: 2.050495207309723

Epoch: 6| Step: 9
Training loss: 2.421430826187134
Validation loss: 2.0537394483884177

Epoch: 6| Step: 10
Training loss: 1.4927995204925537
Validation loss: 2.0619877179463706

Epoch: 6| Step: 11
Training loss: 2.7826790809631348
Validation loss: 2.0569304625193277

Epoch: 6| Step: 12
Training loss: 1.9648635387420654
Validation loss: 2.0582433144251504

Epoch: 6| Step: 13
Training loss: 2.847898244857788
Validation loss: 2.0606032808621726

Epoch: 58| Step: 0
Training loss: 2.921685218811035
Validation loss: 2.0582842429478965

Epoch: 6| Step: 1
Training loss: 1.7420281171798706
Validation loss: 2.056284745534261

Epoch: 6| Step: 2
Training loss: 2.2264022827148438
Validation loss: 2.0548752546310425

Epoch: 6| Step: 3
Training loss: 2.488144874572754
Validation loss: 2.0597329139709473

Epoch: 6| Step: 4
Training loss: 2.0172135829925537
Validation loss: 2.0495736598968506

Epoch: 6| Step: 5
Training loss: 1.91893470287323
Validation loss: 2.0422728061676025

Epoch: 6| Step: 6
Training loss: 2.4761056900024414
Validation loss: 2.0358768701553345

Epoch: 6| Step: 7
Training loss: 2.337830066680908
Validation loss: 2.046944578488668

Epoch: 6| Step: 8
Training loss: 1.8868699073791504
Validation loss: 2.055586040019989

Epoch: 6| Step: 9
Training loss: 2.869497060775757
Validation loss: 2.092698613802592

Epoch: 6| Step: 10
Training loss: 2.545942783355713
Validation loss: 2.104743162790934

Epoch: 6| Step: 11
Training loss: 2.196103096008301
Validation loss: 2.098933219909668

Epoch: 6| Step: 12
Training loss: 1.864050030708313
Validation loss: 2.0736743013064065

Epoch: 6| Step: 13
Training loss: 2.106173515319824
Validation loss: 2.0474963784217834

Epoch: 59| Step: 0
Training loss: 2.49808406829834
Validation loss: 2.0418322682380676

Epoch: 6| Step: 1
Training loss: 2.0147013664245605
Validation loss: 2.041355768839518

Epoch: 6| Step: 2
Training loss: 1.937809944152832
Validation loss: 2.0397993326187134

Epoch: 6| Step: 3
Training loss: 2.6185929775238037
Validation loss: 2.0463873545328775

Epoch: 6| Step: 4
Training loss: 2.616623878479004
Validation loss: 2.0447977781295776

Epoch: 6| Step: 5
Training loss: 1.8727896213531494
Validation loss: 2.0556604464848838

Epoch: 6| Step: 6
Training loss: 2.0759787559509277
Validation loss: 2.047536253929138

Epoch: 6| Step: 7
Training loss: 1.506361722946167
Validation loss: 2.0521188577016196

Epoch: 6| Step: 8
Training loss: 2.5821845531463623
Validation loss: 2.0658541123072305

Epoch: 6| Step: 9
Training loss: 2.3948159217834473
Validation loss: 2.0630072752634683

Epoch: 6| Step: 10
Training loss: 2.6297764778137207
Validation loss: 2.063283145427704

Epoch: 6| Step: 11
Training loss: 2.172750473022461
Validation loss: 2.0554810762405396

Epoch: 6| Step: 12
Training loss: 2.26458740234375
Validation loss: 2.048370639483134

Epoch: 6| Step: 13
Training loss: 2.0075812339782715
Validation loss: 2.0427653193473816

Epoch: 60| Step: 0
Training loss: 2.4328677654266357
Validation loss: 2.0389543771743774

Epoch: 6| Step: 1
Training loss: 2.1874961853027344
Validation loss: 2.029203991095225

Epoch: 6| Step: 2
Training loss: 2.395697593688965
Validation loss: 2.034221669038137

Epoch: 6| Step: 3
Training loss: 2.033684730529785
Validation loss: 2.026399870713552

Epoch: 6| Step: 4
Training loss: 1.9180474281311035
Validation loss: 2.0392664074897766

Epoch: 6| Step: 5
Training loss: 2.405463457107544
Validation loss: 2.046204686164856

Epoch: 6| Step: 6
Training loss: 2.063694953918457
Validation loss: 2.0666739344596863

Epoch: 6| Step: 7
Training loss: 2.521780490875244
Validation loss: 2.0821247696876526

Epoch: 6| Step: 8
Training loss: 2.2992420196533203
Validation loss: 2.0698277155558267

Epoch: 6| Step: 9
Training loss: 2.456521511077881
Validation loss: 2.0510603984196982

Epoch: 6| Step: 10
Training loss: 2.3409676551818848
Validation loss: 2.051347633202871

Epoch: 6| Step: 11
Training loss: 2.3032655715942383
Validation loss: 2.026087840398153

Epoch: 6| Step: 12
Training loss: 2.1223387718200684
Validation loss: 2.022412439187368

Epoch: 6| Step: 13
Training loss: 1.6208598613739014
Validation loss: 2.038675546646118

Epoch: 61| Step: 0
Training loss: 2.9872355461120605
Validation loss: 2.029344916343689

Epoch: 6| Step: 1
Training loss: 2.533998489379883
Validation loss: 2.0436794757843018

Epoch: 6| Step: 2
Training loss: 1.3774371147155762
Validation loss: 2.040469984213511

Epoch: 6| Step: 3
Training loss: 2.786848783493042
Validation loss: 2.0452841321627298

Epoch: 6| Step: 4
Training loss: 2.001974582672119
Validation loss: 2.039999087651571

Epoch: 6| Step: 5
Training loss: 2.042635440826416
Validation loss: 2.0423854986826577

Epoch: 6| Step: 6
Training loss: 2.167092800140381
Validation loss: 2.0445308685302734

Epoch: 6| Step: 7
Training loss: 2.126413583755493
Validation loss: 2.0500269730885825

Epoch: 6| Step: 8
Training loss: 2.85333251953125
Validation loss: 2.0380635460217795

Epoch: 6| Step: 9
Training loss: 2.170833110809326
Validation loss: 2.0373728473981223

Epoch: 6| Step: 10
Training loss: 2.1583075523376465
Validation loss: 2.04010663429896

Epoch: 6| Step: 11
Training loss: 2.0429091453552246
Validation loss: 2.03426726659139

Epoch: 6| Step: 12
Training loss: 2.3635318279266357
Validation loss: 2.033202270666758

Epoch: 6| Step: 13
Training loss: 1.5240182876586914
Validation loss: 2.0320557951927185

Epoch: 62| Step: 0
Training loss: 2.2468090057373047
Validation loss: 2.034271856149038

Epoch: 6| Step: 1
Training loss: 1.91097891330719
Validation loss: 2.021199584007263

Epoch: 6| Step: 2
Training loss: 1.7920693159103394
Validation loss: 2.0260969201723733

Epoch: 6| Step: 3
Training loss: 2.514256715774536
Validation loss: 2.0292758544286094

Epoch: 6| Step: 4
Training loss: 2.389496326446533
Validation loss: 2.0225104490915933

Epoch: 6| Step: 5
Training loss: 2.4726390838623047
Validation loss: 2.030911405881246

Epoch: 6| Step: 6
Training loss: 2.248946189880371
Validation loss: 2.021349310874939

Epoch: 6| Step: 7
Training loss: 2.3404059410095215
Validation loss: 2.034320652484894

Epoch: 6| Step: 8
Training loss: 1.7753132581710815
Validation loss: 2.0413819750150046

Epoch: 6| Step: 9
Training loss: 2.1785717010498047
Validation loss: 2.058332602183024

Epoch: 6| Step: 10
Training loss: 1.851811170578003
Validation loss: 2.0541712641716003

Epoch: 6| Step: 11
Training loss: 3.012758255004883
Validation loss: 2.069823702176412

Epoch: 6| Step: 12
Training loss: 2.315613269805908
Validation loss: 2.07382603486379

Epoch: 6| Step: 13
Training loss: 1.6730003356933594
Validation loss: 2.0531217058499656

Epoch: 63| Step: 0
Training loss: 2.058232307434082
Validation loss: 2.0514744321505227

Epoch: 6| Step: 1
Training loss: 2.0927140712738037
Validation loss: 2.023076812426249

Epoch: 6| Step: 2
Training loss: 2.7568016052246094
Validation loss: 2.0245151122411094

Epoch: 6| Step: 3
Training loss: 2.695984363555908
Validation loss: 2.0243884523709617

Epoch: 6| Step: 4
Training loss: 3.002535343170166
Validation loss: 2.0253667632738748

Epoch: 6| Step: 5
Training loss: 1.7671666145324707
Validation loss: 2.032873729864756

Epoch: 6| Step: 6
Training loss: 2.154733419418335
Validation loss: 2.0270831187566123

Epoch: 6| Step: 7
Training loss: 2.0813212394714355
Validation loss: 2.0202839970588684

Epoch: 6| Step: 8
Training loss: 2.2112722396850586
Validation loss: 2.019239068031311

Epoch: 6| Step: 9
Training loss: 1.9465324878692627
Validation loss: 2.022441864013672

Epoch: 6| Step: 10
Training loss: 1.3355299234390259
Validation loss: 2.0183151960372925

Epoch: 6| Step: 11
Training loss: 2.231078863143921
Validation loss: 2.009094854195913

Epoch: 6| Step: 12
Training loss: 2.0552010536193848
Validation loss: 2.0167430440584817

Epoch: 6| Step: 13
Training loss: 2.5524744987487793
Validation loss: 2.0112247665723166

Epoch: 64| Step: 0
Training loss: 1.6644266843795776
Validation loss: 2.0132843255996704

Epoch: 6| Step: 1
Training loss: 2.1929075717926025
Validation loss: 2.011747717857361

Epoch: 6| Step: 2
Training loss: 2.479128360748291
Validation loss: 2.009771784146627

Epoch: 6| Step: 3
Training loss: 2.4525132179260254
Validation loss: 2.034706711769104

Epoch: 6| Step: 4
Training loss: 2.55576491355896
Validation loss: 2.0521472295125327

Epoch: 6| Step: 5
Training loss: 2.350799560546875
Validation loss: 2.0403871138890586

Epoch: 6| Step: 6
Training loss: 1.6252684593200684
Validation loss: 2.0239452521006265

Epoch: 6| Step: 7
Training loss: 1.8491923809051514
Validation loss: 2.0091014305750527

Epoch: 6| Step: 8
Training loss: 2.3158698081970215
Validation loss: 2.024829089641571

Epoch: 6| Step: 9
Training loss: 2.29677677154541
Validation loss: 2.0283963680267334

Epoch: 6| Step: 10
Training loss: 2.0637354850769043
Validation loss: 2.0277416507403054

Epoch: 6| Step: 11
Training loss: 1.9004722833633423
Validation loss: 2.0296525359153748

Epoch: 6| Step: 12
Training loss: 2.6117773056030273
Validation loss: 2.0285499691963196

Epoch: 6| Step: 13
Training loss: 2.6348929405212402
Validation loss: 2.0235215226809182

Epoch: 65| Step: 0
Training loss: 2.098436117172241
Validation loss: 2.027685046195984

Epoch: 6| Step: 1
Training loss: 2.2503035068511963
Validation loss: 2.024235804875692

Epoch: 6| Step: 2
Training loss: 2.605888843536377
Validation loss: 2.0228781700134277

Epoch: 6| Step: 3
Training loss: 1.9412156343460083
Validation loss: 2.0189081033070884

Epoch: 6| Step: 4
Training loss: 2.0711960792541504
Validation loss: 2.017009913921356

Epoch: 6| Step: 5
Training loss: 1.9933196306228638
Validation loss: 2.0185346802075705

Epoch: 6| Step: 6
Training loss: 2.635408878326416
Validation loss: 2.0212706128756204

Epoch: 6| Step: 7
Training loss: 2.096209764480591
Validation loss: 2.0162683924039206

Epoch: 6| Step: 8
Training loss: 1.5673084259033203
Validation loss: 2.0136688947677612

Epoch: 6| Step: 9
Training loss: 2.4801039695739746
Validation loss: 2.0108746886253357

Epoch: 6| Step: 10
Training loss: 2.1635379791259766
Validation loss: 2.0273135900497437

Epoch: 6| Step: 11
Training loss: 2.1619651317596436
Validation loss: 2.021902084350586

Epoch: 6| Step: 12
Training loss: 2.175201892852783
Validation loss: 2.0296236276626587

Epoch: 6| Step: 13
Training loss: 2.6148486137390137
Validation loss: 2.0603310465812683

Epoch: 66| Step: 0
Training loss: 2.0414626598358154
Validation loss: 2.051647901535034

Epoch: 6| Step: 1
Training loss: 2.1616013050079346
Validation loss: 2.060357689857483

Epoch: 6| Step: 2
Training loss: 2.3469600677490234
Validation loss: 2.0636106133461

Epoch: 6| Step: 3
Training loss: 2.5483405590057373
Validation loss: 2.0555293957392373

Epoch: 6| Step: 4
Training loss: 2.512462615966797
Validation loss: 2.0470276474952698

Epoch: 6| Step: 5
Training loss: 1.8056764602661133
Validation loss: 2.0387070973714194

Epoch: 6| Step: 6
Training loss: 2.131619930267334
Validation loss: 2.025735775629679

Epoch: 6| Step: 7
Training loss: 2.3984198570251465
Validation loss: 2.026237885157267

Epoch: 6| Step: 8
Training loss: 2.3465757369995117
Validation loss: 2.02364989121755

Epoch: 6| Step: 9
Training loss: 1.582197666168213
Validation loss: 2.017960250377655

Epoch: 6| Step: 10
Training loss: 1.6670067310333252
Validation loss: 2.0190277099609375

Epoch: 6| Step: 11
Training loss: 2.5753533840179443
Validation loss: 2.027256647745768

Epoch: 6| Step: 12
Training loss: 2.418781280517578
Validation loss: 2.0256941517194114

Epoch: 6| Step: 13
Training loss: 1.894420862197876
Validation loss: 2.0352028012275696

Epoch: 67| Step: 0
Training loss: 2.421832323074341
Validation loss: 2.0338167548179626

Epoch: 6| Step: 1
Training loss: 2.08388614654541
Validation loss: 2.034233788649241

Epoch: 6| Step: 2
Training loss: 2.034844398498535
Validation loss: 2.0356974999109902

Epoch: 6| Step: 3
Training loss: 2.061582326889038
Validation loss: 2.0308929284413657

Epoch: 6| Step: 4
Training loss: 2.2345874309539795
Validation loss: 2.028598745663961

Epoch: 6| Step: 5
Training loss: 2.31858229637146
Validation loss: 2.0314188798268638

Epoch: 6| Step: 6
Training loss: 2.422092914581299
Validation loss: 2.023448904355367

Epoch: 6| Step: 7
Training loss: 2.2476563453674316
Validation loss: 2.020316779613495

Epoch: 6| Step: 8
Training loss: 2.340963125228882
Validation loss: 2.016706387201945

Epoch: 6| Step: 9
Training loss: 1.9895483255386353
Validation loss: 2.0218104124069214

Epoch: 6| Step: 10
Training loss: 1.6683785915374756
Validation loss: 2.0390931566556296

Epoch: 6| Step: 11
Training loss: 1.987488865852356
Validation loss: 2.0464993715286255

Epoch: 6| Step: 12
Training loss: 2.583528757095337
Validation loss: 2.037470499674479

Epoch: 6| Step: 13
Training loss: 2.2501044273376465
Validation loss: 2.032852292060852

Epoch: 68| Step: 0
Training loss: 2.021596670150757
Validation loss: 2.019127289454142

Epoch: 6| Step: 1
Training loss: 2.0950045585632324
Validation loss: 2.0165794690450034

Epoch: 6| Step: 2
Training loss: 2.149507999420166
Validation loss: 2.0297866463661194

Epoch: 6| Step: 3
Training loss: 2.5773184299468994
Validation loss: 2.024661203225454

Epoch: 6| Step: 4
Training loss: 1.7227530479431152
Validation loss: 2.0278977751731873

Epoch: 6| Step: 5
Training loss: 2.2543118000030518
Validation loss: 2.028351366519928

Epoch: 6| Step: 6
Training loss: 2.4277920722961426
Validation loss: 2.0274458726247153

Epoch: 6| Step: 7
Training loss: 2.7496914863586426
Validation loss: 2.025113046169281

Epoch: 6| Step: 8
Training loss: 1.5597617626190186
Validation loss: 2.0329299370447793

Epoch: 6| Step: 9
Training loss: 2.258995294570923
Validation loss: 2.024810036023458

Epoch: 6| Step: 10
Training loss: 2.1943843364715576
Validation loss: 2.02647457520167

Epoch: 6| Step: 11
Training loss: 2.231250762939453
Validation loss: 2.014925181865692

Epoch: 6| Step: 12
Training loss: 2.1855568885803223
Validation loss: 2.0156424244244895

Epoch: 6| Step: 13
Training loss: 2.148165702819824
Validation loss: 2.011460999647776

Epoch: 69| Step: 0
Training loss: 1.5362610816955566
Validation loss: 2.007218619187673

Epoch: 6| Step: 1
Training loss: 2.139160394668579
Validation loss: 2.014661888281504

Epoch: 6| Step: 2
Training loss: 2.535289764404297
Validation loss: 2.013118783632914

Epoch: 6| Step: 3
Training loss: 2.635216474533081
Validation loss: 2.007031242052714

Epoch: 6| Step: 4
Training loss: 2.8510167598724365
Validation loss: 2.014678657054901

Epoch: 6| Step: 5
Training loss: 2.508307456970215
Validation loss: 2.0114214420318604

Epoch: 6| Step: 6
Training loss: 1.4417555332183838
Validation loss: 2.0076360503832498

Epoch: 6| Step: 7
Training loss: 2.2731027603149414
Validation loss: 2.0207893451054892

Epoch: 6| Step: 8
Training loss: 2.4580092430114746
Validation loss: 2.025476078192393

Epoch: 6| Step: 9
Training loss: 1.9282331466674805
Validation loss: 2.018314083417257

Epoch: 6| Step: 10
Training loss: 1.887485146522522
Validation loss: 2.0267869432767234

Epoch: 6| Step: 11
Training loss: 1.3456404209136963
Validation loss: 2.0205713709195456

Epoch: 6| Step: 12
Training loss: 2.1552114486694336
Validation loss: 2.0178720553716025

Epoch: 6| Step: 13
Training loss: 2.6383261680603027
Validation loss: 2.033888657887777

Epoch: 70| Step: 0
Training loss: 2.252901792526245
Validation loss: 2.0305447975794473

Epoch: 6| Step: 1
Training loss: 2.483841896057129
Validation loss: 2.040524423122406

Epoch: 6| Step: 2
Training loss: 1.79868745803833
Validation loss: 2.033473273118337

Epoch: 6| Step: 3
Training loss: 1.7550467252731323
Validation loss: 2.047519326210022

Epoch: 6| Step: 4
Training loss: 1.612318515777588
Validation loss: 2.043019930521647

Epoch: 6| Step: 5
Training loss: 2.111875295639038
Validation loss: 2.0394678910573325

Epoch: 6| Step: 6
Training loss: 2.4002327919006348
Validation loss: 2.035090684890747

Epoch: 6| Step: 7
Training loss: 2.089977264404297
Validation loss: 2.0273178617159524

Epoch: 6| Step: 8
Training loss: 2.0534472465515137
Validation loss: 2.0306798020998635

Epoch: 6| Step: 9
Training loss: 2.160806179046631
Validation loss: 2.038170635700226

Epoch: 6| Step: 10
Training loss: 2.93707013130188
Validation loss: 2.024693508942922

Epoch: 6| Step: 11
Training loss: 1.6989409923553467
Validation loss: 2.0208688775698342

Epoch: 6| Step: 12
Training loss: 2.770697832107544
Validation loss: 2.022219638029734

Epoch: 6| Step: 13
Training loss: 1.94435453414917
Validation loss: 2.0156608621279397

Epoch: 71| Step: 0
Training loss: 1.911158561706543
Validation loss: 2.022331118583679

Epoch: 6| Step: 1
Training loss: 1.9275225400924683
Validation loss: 2.0273984471956887

Epoch: 6| Step: 2
Training loss: 1.8703669309616089
Validation loss: 2.0280479391415915

Epoch: 6| Step: 3
Training loss: 1.9262595176696777
Validation loss: 2.0210694471995034

Epoch: 6| Step: 4
Training loss: 2.281003713607788
Validation loss: 2.0121949513753257

Epoch: 6| Step: 5
Training loss: 2.4359869956970215
Validation loss: 2.0116962989171348

Epoch: 6| Step: 6
Training loss: 2.4491751194000244
Validation loss: 2.010018984476725

Epoch: 6| Step: 7
Training loss: 2.098418712615967
Validation loss: 2.0171852310498557

Epoch: 6| Step: 8
Training loss: 2.3774917125701904
Validation loss: 2.010969579219818

Epoch: 6| Step: 9
Training loss: 2.6945528984069824
Validation loss: 2.0106637279192605

Epoch: 6| Step: 10
Training loss: 2.1272940635681152
Validation loss: 2.0099086364110312

Epoch: 6| Step: 11
Training loss: 2.127121686935425
Validation loss: 2.016469577948252

Epoch: 6| Step: 12
Training loss: 1.8323688507080078
Validation loss: 2.0192468563715615

Epoch: 6| Step: 13
Training loss: 2.373774290084839
Validation loss: 2.0224972565968833

Epoch: 72| Step: 0
Training loss: 2.2507457733154297
Validation loss: 2.014803946018219

Epoch: 6| Step: 1
Training loss: 2.266768217086792
Validation loss: 2.0122557083765664

Epoch: 6| Step: 2
Training loss: 1.95968496799469
Validation loss: 2.0029695431391397

Epoch: 6| Step: 3
Training loss: 1.9398114681243896
Validation loss: 2.022344648838043

Epoch: 6| Step: 4
Training loss: 1.3947629928588867
Validation loss: 2.016652762889862

Epoch: 6| Step: 5
Training loss: 2.772456169128418
Validation loss: 2.00908229748408

Epoch: 6| Step: 6
Training loss: 2.491053581237793
Validation loss: 2.01267542441686

Epoch: 6| Step: 7
Training loss: 2.111025333404541
Validation loss: 2.0239725708961487

Epoch: 6| Step: 8
Training loss: 2.473698854446411
Validation loss: 2.034744143486023

Epoch: 6| Step: 9
Training loss: 1.8055567741394043
Validation loss: 2.036371966203054

Epoch: 6| Step: 10
Training loss: 2.2761473655700684
Validation loss: 2.035253643989563

Epoch: 6| Step: 11
Training loss: 1.7177644968032837
Validation loss: 2.02336718638738

Epoch: 6| Step: 12
Training loss: 2.143688917160034
Validation loss: 2.0228301088015237

Epoch: 6| Step: 13
Training loss: 2.632622480392456
Validation loss: 2.0192084908485413

Epoch: 73| Step: 0
Training loss: 2.540402889251709
Validation loss: 2.0162639021873474

Epoch: 6| Step: 1
Training loss: 2.2760021686553955
Validation loss: 2.023953159650167

Epoch: 6| Step: 2
Training loss: 1.6978740692138672
Validation loss: 2.013958911101023

Epoch: 6| Step: 3
Training loss: 1.7162312269210815
Validation loss: 2.0215418140093484

Epoch: 6| Step: 4
Training loss: 2.580730438232422
Validation loss: 2.018394668896993

Epoch: 6| Step: 5
Training loss: 2.092364549636841
Validation loss: 2.0188158750534058

Epoch: 6| Step: 6
Training loss: 1.9956562519073486
Validation loss: 2.028947174549103

Epoch: 6| Step: 7
Training loss: 2.593940019607544
Validation loss: 2.029555002848307

Epoch: 6| Step: 8
Training loss: 2.065105438232422
Validation loss: 2.032062272230784

Epoch: 6| Step: 9
Training loss: 2.2889084815979004
Validation loss: 2.0369324882825217

Epoch: 6| Step: 10
Training loss: 2.048585891723633
Validation loss: 2.030441701412201

Epoch: 6| Step: 11
Training loss: 2.4745535850524902
Validation loss: 2.0204235712687173

Epoch: 6| Step: 12
Training loss: 1.9381437301635742
Validation loss: 2.0140124559402466

Epoch: 6| Step: 13
Training loss: 1.7975358963012695
Validation loss: 2.033896247545878

Epoch: 74| Step: 0
Training loss: 2.441047191619873
Validation loss: 2.03142511844635

Epoch: 6| Step: 1
Training loss: 2.503124952316284
Validation loss: 2.0259164373079934

Epoch: 6| Step: 2
Training loss: 2.4635448455810547
Validation loss: 2.02466744184494

Epoch: 6| Step: 3
Training loss: 1.6857391595840454
Validation loss: 2.0305731892585754

Epoch: 6| Step: 4
Training loss: 2.2988295555114746
Validation loss: 2.0285151600837708

Epoch: 6| Step: 5
Training loss: 2.24501895904541
Validation loss: 2.038909673690796

Epoch: 6| Step: 6
Training loss: 2.266244411468506
Validation loss: 2.033090611298879

Epoch: 6| Step: 7
Training loss: 2.225811243057251
Validation loss: 2.0328038334846497

Epoch: 6| Step: 8
Training loss: 2.1613426208496094
Validation loss: 2.0161949594815574

Epoch: 6| Step: 9
Training loss: 1.4598145484924316
Validation loss: 2.016225516796112

Epoch: 6| Step: 10
Training loss: 1.9635800123214722
Validation loss: 2.017861088116964

Epoch: 6| Step: 11
Training loss: 1.7272944450378418
Validation loss: 2.0146605173746743

Epoch: 6| Step: 12
Training loss: 2.5164923667907715
Validation loss: 2.0210305651028952

Epoch: 6| Step: 13
Training loss: 2.1647462844848633
Validation loss: 2.014863908290863

Epoch: 75| Step: 0
Training loss: 2.512127161026001
Validation loss: 2.0187663038571677

Epoch: 6| Step: 1
Training loss: 1.9729129076004028
Validation loss: 2.01881742477417

Epoch: 6| Step: 2
Training loss: 2.287853240966797
Validation loss: 2.019483228524526

Epoch: 6| Step: 3
Training loss: 2.0774741172790527
Validation loss: 2.0047407746315002

Epoch: 6| Step: 4
Training loss: 1.6396428346633911
Validation loss: 2.009258965651194

Epoch: 6| Step: 5
Training loss: 1.9186238050460815
Validation loss: 2.011459489663442

Epoch: 6| Step: 6
Training loss: 2.109600067138672
Validation loss: 2.010818044344584

Epoch: 6| Step: 7
Training loss: 2.0465455055236816
Validation loss: 2.0244594613711038

Epoch: 6| Step: 8
Training loss: 2.0744709968566895
Validation loss: 2.020744780699412

Epoch: 6| Step: 9
Training loss: 1.799354076385498
Validation loss: 2.0239372650782266

Epoch: 6| Step: 10
Training loss: 2.51479434967041
Validation loss: 2.0283347169558206

Epoch: 6| Step: 11
Training loss: 1.772266149520874
Validation loss: 2.034689644972483

Epoch: 6| Step: 12
Training loss: 2.9569623470306396
Validation loss: 2.03763755162557

Epoch: 6| Step: 13
Training loss: 2.4415035247802734
Validation loss: 2.034007986386617

Epoch: 76| Step: 0
Training loss: 1.9290080070495605
Validation loss: 2.0309552947680154

Epoch: 6| Step: 1
Training loss: 2.1468701362609863
Validation loss: 2.02581258614858

Epoch: 6| Step: 2
Training loss: 2.5924181938171387
Validation loss: 2.0356107155481973

Epoch: 6| Step: 3
Training loss: 1.682812213897705
Validation loss: 2.015802880128225

Epoch: 6| Step: 4
Training loss: 2.376807928085327
Validation loss: 2.0147274931271872

Epoch: 6| Step: 5
Training loss: 1.718977689743042
Validation loss: 2.009038209915161

Epoch: 6| Step: 6
Training loss: 2.215636730194092
Validation loss: 2.008618871370951

Epoch: 6| Step: 7
Training loss: 2.793443202972412
Validation loss: 2.0072640776634216

Epoch: 6| Step: 8
Training loss: 2.533155918121338
Validation loss: 2.0145545999209085

Epoch: 6| Step: 9
Training loss: 1.9837090969085693
Validation loss: 2.0080960988998413

Epoch: 6| Step: 10
Training loss: 1.7481944561004639
Validation loss: 2.0101823012034097

Epoch: 6| Step: 11
Training loss: 1.8629117012023926
Validation loss: 2.007537305355072

Epoch: 6| Step: 12
Training loss: 2.501749038696289
Validation loss: 2.0018991033236184

Epoch: 6| Step: 13
Training loss: 2.033256769180298
Validation loss: 2.0136678218841553

Epoch: 77| Step: 0
Training loss: 1.9821882247924805
Validation loss: 2.0325456658999124

Epoch: 6| Step: 1
Training loss: 2.454026699066162
Validation loss: 2.048964579900106

Epoch: 6| Step: 2
Training loss: 1.468658208847046
Validation loss: 2.077388902505239

Epoch: 6| Step: 3
Training loss: 2.5309176445007324
Validation loss: 2.0834073026974997

Epoch: 6| Step: 4
Training loss: 2.4515562057495117
Validation loss: 2.0718799034754434

Epoch: 6| Step: 5
Training loss: 2.2251105308532715
Validation loss: 2.066712578137716

Epoch: 6| Step: 6
Training loss: 1.8758392333984375
Validation loss: 2.072705388069153

Epoch: 6| Step: 7
Training loss: 1.9759219884872437
Validation loss: 2.0818663239479065

Epoch: 6| Step: 8
Training loss: 1.4933925867080688
Validation loss: 2.0706862807273865

Epoch: 6| Step: 9
Training loss: 2.371586561203003
Validation loss: 2.0575425028800964

Epoch: 6| Step: 10
Training loss: 2.8448002338409424
Validation loss: 2.040525197982788

Epoch: 6| Step: 11
Training loss: 2.0606422424316406
Validation loss: 2.0315186182657876

Epoch: 6| Step: 12
Training loss: 2.198749303817749
Validation loss: 2.0083633859952292

Epoch: 6| Step: 13
Training loss: 2.289576530456543
Validation loss: 2.000481685002645

Epoch: 78| Step: 0
Training loss: 1.982932448387146
Validation loss: 1.9975857734680176

Epoch: 6| Step: 1
Training loss: 3.0785088539123535
Validation loss: 2.010563691457113

Epoch: 6| Step: 2
Training loss: 1.7209045886993408
Validation loss: 2.013350248336792

Epoch: 6| Step: 3
Training loss: 2.780318021774292
Validation loss: 2.0223121643066406

Epoch: 6| Step: 4
Training loss: 2.4486494064331055
Validation loss: 2.0320895115534463

Epoch: 6| Step: 5
Training loss: 1.8572826385498047
Validation loss: 2.0331398646036782

Epoch: 6| Step: 6
Training loss: 1.5867516994476318
Validation loss: 2.0278862516085305

Epoch: 6| Step: 7
Training loss: 1.9408087730407715
Validation loss: 2.0269447565078735

Epoch: 6| Step: 8
Training loss: 2.506831645965576
Validation loss: 2.0217426419258118

Epoch: 6| Step: 9
Training loss: 2.051370859146118
Validation loss: 2.0220207969347634

Epoch: 6| Step: 10
Training loss: 1.8509429693222046
Validation loss: 2.0173643032709756

Epoch: 6| Step: 11
Training loss: 2.7088897228240967
Validation loss: 2.0164857705434165

Epoch: 6| Step: 12
Training loss: 1.9079645872116089
Validation loss: 2.014253874619802

Epoch: 6| Step: 13
Training loss: 2.253675937652588
Validation loss: 2.015479783217112

Epoch: 79| Step: 0
Training loss: 1.6217681169509888
Validation loss: 2.0121325850486755

Epoch: 6| Step: 1
Training loss: 2.0580193996429443
Validation loss: 2.009785989920298

Epoch: 6| Step: 2
Training loss: 2.9504172801971436
Validation loss: 2.0111676851908364

Epoch: 6| Step: 3
Training loss: 1.9759001731872559
Validation loss: 2.0041212240854898

Epoch: 6| Step: 4
Training loss: 2.3014326095581055
Validation loss: 2.0079795320828757

Epoch: 6| Step: 5
Training loss: 1.9366042613983154
Validation loss: 2.027085463205973

Epoch: 6| Step: 6
Training loss: 2.457976818084717
Validation loss: 2.0244082609812417

Epoch: 6| Step: 7
Training loss: 1.6221634149551392
Validation loss: 2.0393221577008567

Epoch: 6| Step: 8
Training loss: 2.1584250926971436
Validation loss: 2.040565093358358

Epoch: 6| Step: 9
Training loss: 1.9544811248779297
Validation loss: 2.047475357850393

Epoch: 6| Step: 10
Training loss: 2.678685188293457
Validation loss: 2.054847796758016

Epoch: 6| Step: 11
Training loss: 2.350888252258301
Validation loss: 2.0577255288759866

Epoch: 6| Step: 12
Training loss: 1.676267147064209
Validation loss: 2.0583234429359436

Epoch: 6| Step: 13
Training loss: 2.263026237487793
Validation loss: 2.0489686528841653

Epoch: 80| Step: 0
Training loss: 2.2745742797851562
Validation loss: 2.0442994435628257

Epoch: 6| Step: 1
Training loss: 1.6797126531600952
Validation loss: 2.0495150685310364

Epoch: 6| Step: 2
Training loss: 2.4547297954559326
Validation loss: 2.024159928162893

Epoch: 6| Step: 3
Training loss: 2.10390043258667
Validation loss: 2.0112858215967813

Epoch: 6| Step: 4
Training loss: 2.759061813354492
Validation loss: 2.0134496490160623

Epoch: 6| Step: 5
Training loss: 2.3607184886932373
Validation loss: 2.0164376894632974

Epoch: 6| Step: 6
Training loss: 1.684584617614746
Validation loss: 2.0198506315549216

Epoch: 6| Step: 7
Training loss: 2.416046142578125
Validation loss: 2.028494437535604

Epoch: 6| Step: 8
Training loss: 2.045872449874878
Validation loss: 2.032727281252543

Epoch: 6| Step: 9
Training loss: 2.028759241104126
Validation loss: 2.0329904357592263

Epoch: 6| Step: 10
Training loss: 2.1110055446624756
Validation loss: 2.0234485069910684

Epoch: 6| Step: 11
Training loss: 2.0463337898254395
Validation loss: 2.027973473072052

Epoch: 6| Step: 12
Training loss: 1.6246469020843506
Validation loss: 2.0286567409833274

Epoch: 6| Step: 13
Training loss: 2.621577501296997
Validation loss: 2.018947203954061

Epoch: 81| Step: 0
Training loss: 2.4949820041656494
Validation loss: 2.023909091949463

Epoch: 6| Step: 1
Training loss: 1.9878675937652588
Validation loss: 2.0238508184750876

Epoch: 6| Step: 2
Training loss: 2.2892606258392334
Validation loss: 2.0115140080451965

Epoch: 6| Step: 3
Training loss: 2.5323705673217773
Validation loss: 2.0296402970949807

Epoch: 6| Step: 4
Training loss: 2.081787586212158
Validation loss: 2.0470457077026367

Epoch: 6| Step: 5
Training loss: 2.104896306991577
Validation loss: 2.0504110852877298

Epoch: 6| Step: 6
Training loss: 2.5793814659118652
Validation loss: 2.053431769212087

Epoch: 6| Step: 7
Training loss: 1.8606441020965576
Validation loss: 2.0548498034477234

Epoch: 6| Step: 8
Training loss: 2.193941831588745
Validation loss: 2.055828551451365

Epoch: 6| Step: 9
Training loss: 1.7333807945251465
Validation loss: 2.033953766028086

Epoch: 6| Step: 10
Training loss: 2.1097936630249023
Validation loss: 2.027927498022715

Epoch: 6| Step: 11
Training loss: 1.8735498189926147
Validation loss: 2.0275235176086426

Epoch: 6| Step: 12
Training loss: 2.3150691986083984
Validation loss: 2.0154354770978293

Epoch: 6| Step: 13
Training loss: 2.0745139122009277
Validation loss: 2.014216899871826

Epoch: 82| Step: 0
Training loss: 2.3814358711242676
Validation loss: 2.021441558996836

Epoch: 6| Step: 1
Training loss: 2.364574432373047
Validation loss: 2.0244160493214927

Epoch: 6| Step: 2
Training loss: 2.087894916534424
Validation loss: 2.0236825545628867

Epoch: 6| Step: 3
Training loss: 1.7428441047668457
Validation loss: 2.0252089500427246

Epoch: 6| Step: 4
Training loss: 2.1406779289245605
Validation loss: 2.0294315814971924

Epoch: 6| Step: 5
Training loss: 1.8691697120666504
Validation loss: 2.019761343797048

Epoch: 6| Step: 6
Training loss: 2.424879550933838
Validation loss: 2.0219707687695823

Epoch: 6| Step: 7
Training loss: 2.5692572593688965
Validation loss: 2.0270293156305947

Epoch: 6| Step: 8
Training loss: 2.291934013366699
Validation loss: 2.023325562477112

Epoch: 6| Step: 9
Training loss: 2.1200997829437256
Validation loss: 2.0186842481295266

Epoch: 6| Step: 10
Training loss: 2.6803343296051025
Validation loss: 2.01915713151296

Epoch: 6| Step: 11
Training loss: 1.8710461854934692
Validation loss: 2.0184505780537925

Epoch: 6| Step: 12
Training loss: 1.7884020805358887
Validation loss: 2.023295203844706

Epoch: 6| Step: 13
Training loss: 1.963754415512085
Validation loss: 2.015393157800039

Epoch: 83| Step: 0
Training loss: 1.9650380611419678
Validation loss: 2.020378569761912

Epoch: 6| Step: 1
Training loss: 2.13909912109375
Validation loss: 2.0128429532051086

Epoch: 6| Step: 2
Training loss: 1.8524270057678223
Validation loss: 2.0243430932362876

Epoch: 6| Step: 3
Training loss: 1.9710071086883545
Validation loss: 2.0206029613812766

Epoch: 6| Step: 4
Training loss: 2.7622056007385254
Validation loss: 2.017676293849945

Epoch: 6| Step: 5
Training loss: 1.8576079607009888
Validation loss: 2.024474859237671

Epoch: 6| Step: 6
Training loss: 2.1225552558898926
Validation loss: 2.013006885846456

Epoch: 6| Step: 7
Training loss: 1.7546895742416382
Validation loss: 2.007823924223582

Epoch: 6| Step: 8
Training loss: 1.8895022869110107
Validation loss: 2.0144034226735434

Epoch: 6| Step: 9
Training loss: 2.568755626678467
Validation loss: 2.029055635134379

Epoch: 6| Step: 10
Training loss: 1.6051855087280273
Validation loss: 2.0267485777537027

Epoch: 6| Step: 11
Training loss: 2.5888147354125977
Validation loss: 2.0408127109209695

Epoch: 6| Step: 12
Training loss: 2.127810478210449
Validation loss: 2.037755072116852

Epoch: 6| Step: 13
Training loss: 2.686800479888916
Validation loss: 2.043315291404724

Epoch: 84| Step: 0
Training loss: 2.7949137687683105
Validation loss: 2.039006471633911

Epoch: 6| Step: 1
Training loss: 1.754239559173584
Validation loss: 2.049960712591807

Epoch: 6| Step: 2
Training loss: 1.846367359161377
Validation loss: 2.0459081331888833

Epoch: 6| Step: 3
Training loss: 1.5545169115066528
Validation loss: 2.041296124458313

Epoch: 6| Step: 4
Training loss: 2.0182228088378906
Validation loss: 2.0517486929893494

Epoch: 6| Step: 5
Training loss: 2.4074485301971436
Validation loss: 2.041736622651418

Epoch: 6| Step: 6
Training loss: 1.8592658042907715
Validation loss: 2.046704649925232

Epoch: 6| Step: 7
Training loss: 2.7775464057922363
Validation loss: 2.0210187435150146

Epoch: 6| Step: 8
Training loss: 2.2155961990356445
Validation loss: 2.0248230497042337

Epoch: 6| Step: 9
Training loss: 1.8215439319610596
Validation loss: 2.0144567489624023

Epoch: 6| Step: 10
Training loss: 1.8856487274169922
Validation loss: 2.0202966928482056

Epoch: 6| Step: 11
Training loss: 2.2841739654541016
Validation loss: 2.0152726769447327

Epoch: 6| Step: 12
Training loss: 2.367823600769043
Validation loss: 2.022097110748291

Epoch: 6| Step: 13
Training loss: 2.4062609672546387
Validation loss: 2.02327561378479

Epoch: 85| Step: 0
Training loss: 2.4702260494232178
Validation loss: 2.0293724139531455

Epoch: 6| Step: 1
Training loss: 2.3502001762390137
Validation loss: 2.0326470931371055

Epoch: 6| Step: 2
Training loss: 2.3619532585144043
Validation loss: 2.0346152782440186

Epoch: 6| Step: 3
Training loss: 2.0374090671539307
Validation loss: 2.0389204819997153

Epoch: 6| Step: 4
Training loss: 1.5473761558532715
Validation loss: 2.040274679660797

Epoch: 6| Step: 5
Training loss: 2.029627561569214
Validation loss: 2.04598460594813

Epoch: 6| Step: 6
Training loss: 1.680533528327942
Validation loss: 2.039030690987905

Epoch: 6| Step: 7
Training loss: 2.7269046306610107
Validation loss: 2.040546794732412

Epoch: 6| Step: 8
Training loss: 2.855553150177002
Validation loss: 2.0432903369267783

Epoch: 6| Step: 9
Training loss: 2.2858355045318604
Validation loss: 2.0395463903745017

Epoch: 6| Step: 10
Training loss: 2.096482276916504
Validation loss: 2.047556142012278

Epoch: 6| Step: 11
Training loss: 1.992092251777649
Validation loss: 2.0367231567700705

Epoch: 6| Step: 12
Training loss: 1.552248477935791
Validation loss: 2.037614345550537

Epoch: 6| Step: 13
Training loss: 1.9006037712097168
Validation loss: 2.0375482042630515

Epoch: 86| Step: 0
Training loss: 1.677575945854187
Validation loss: 2.0361178318659463

Epoch: 6| Step: 1
Training loss: 2.5147948265075684
Validation loss: 2.040909230709076

Epoch: 6| Step: 2
Training loss: 1.789193868637085
Validation loss: 2.018733024597168

Epoch: 6| Step: 3
Training loss: 2.0716116428375244
Validation loss: 2.0233304699261985

Epoch: 6| Step: 4
Training loss: 2.3804728984832764
Validation loss: 2.0255351066589355

Epoch: 6| Step: 5
Training loss: 1.7750952243804932
Validation loss: 2.024374226729075

Epoch: 6| Step: 6
Training loss: 2.3068904876708984
Validation loss: 2.0258498986562095

Epoch: 6| Step: 7
Training loss: 2.171133041381836
Validation loss: 2.024357775847117

Epoch: 6| Step: 8
Training loss: 2.101475715637207
Validation loss: 2.0232842167218528

Epoch: 6| Step: 9
Training loss: 2.708184003829956
Validation loss: 2.022980729738871

Epoch: 6| Step: 10
Training loss: 2.2050740718841553
Validation loss: 2.013683875401815

Epoch: 6| Step: 11
Training loss: 2.090789318084717
Validation loss: 2.0154850482940674

Epoch: 6| Step: 12
Training loss: 2.3141520023345947
Validation loss: 2.0269492069880166

Epoch: 6| Step: 13
Training loss: 1.837857961654663
Validation loss: 2.0264309843381247

Epoch: 87| Step: 0
Training loss: 2.0806469917297363
Validation loss: 2.033075968424479

Epoch: 6| Step: 1
Training loss: 2.1050446033477783
Validation loss: 2.04018763701121

Epoch: 6| Step: 2
Training loss: 1.5295829772949219
Validation loss: 2.0406511425971985

Epoch: 6| Step: 3
Training loss: 2.533625364303589
Validation loss: 2.034693201382955

Epoch: 6| Step: 4
Training loss: 2.2162742614746094
Validation loss: 2.031550665696462

Epoch: 6| Step: 5
Training loss: 2.207198143005371
Validation loss: 2.0407972733179727

Epoch: 6| Step: 6
Training loss: 1.933906078338623
Validation loss: 2.0433817903200784

Epoch: 6| Step: 7
Training loss: 1.7203583717346191
Validation loss: 2.0422319769859314

Epoch: 6| Step: 8
Training loss: 1.9652987718582153
Validation loss: 2.0527769724527993

Epoch: 6| Step: 9
Training loss: 2.244903802871704
Validation loss: 2.0569485425949097

Epoch: 6| Step: 10
Training loss: 2.633129835128784
Validation loss: 2.0507039030392966

Epoch: 6| Step: 11
Training loss: 2.418703556060791
Validation loss: 2.0502041975657144

Epoch: 6| Step: 12
Training loss: 1.69563889503479
Validation loss: 2.058878481388092

Epoch: 6| Step: 13
Training loss: 2.327970027923584
Validation loss: 2.046695351600647

Epoch: 88| Step: 0
Training loss: 2.2726356983184814
Validation loss: 2.0484727223714194

Epoch: 6| Step: 1
Training loss: 1.3604347705841064
Validation loss: 2.0429621934890747

Epoch: 6| Step: 2
Training loss: 2.822492837905884
Validation loss: 2.0352093974749246

Epoch: 6| Step: 3
Training loss: 2.133511543273926
Validation loss: 2.042590618133545

Epoch: 6| Step: 4
Training loss: 1.760764241218567
Validation loss: 2.0544092257817588

Epoch: 6| Step: 5
Training loss: 2.0364437103271484
Validation loss: 2.050868193308512

Epoch: 6| Step: 6
Training loss: 2.672067165374756
Validation loss: 2.0498006542523703

Epoch: 6| Step: 7
Training loss: 2.0413832664489746
Validation loss: 2.042922576268514

Epoch: 6| Step: 8
Training loss: 1.9313116073608398
Validation loss: 2.036439041296641

Epoch: 6| Step: 9
Training loss: 1.6260517835617065
Validation loss: 2.0363807678222656

Epoch: 6| Step: 10
Training loss: 2.6137118339538574
Validation loss: 2.0387496948242188

Epoch: 6| Step: 11
Training loss: 2.0857725143432617
Validation loss: 2.0429744720458984

Epoch: 6| Step: 12
Training loss: 2.0876564979553223
Validation loss: 2.042233407497406

Epoch: 6| Step: 13
Training loss: 2.29921293258667
Validation loss: 2.0465378165245056

Epoch: 89| Step: 0
Training loss: 2.008561134338379
Validation loss: 2.0417194167772927

Epoch: 6| Step: 1
Training loss: 2.150327682495117
Validation loss: 2.0363245010375977

Epoch: 6| Step: 2
Training loss: 1.4735498428344727
Validation loss: 2.0408403078715005

Epoch: 6| Step: 3
Training loss: 2.6260995864868164
Validation loss: 2.057095448176066

Epoch: 6| Step: 4
Training loss: 1.2839722633361816
Validation loss: 2.0472572247187295

Epoch: 6| Step: 5
Training loss: 1.99233078956604
Validation loss: 2.0496851603190103

Epoch: 6| Step: 6
Training loss: 2.249894857406616
Validation loss: 2.0441518425941467

Epoch: 6| Step: 7
Training loss: 2.745041608810425
Validation loss: 2.0320504903793335

Epoch: 6| Step: 8
Training loss: 1.7694368362426758
Validation loss: 2.024175743261973

Epoch: 6| Step: 9
Training loss: 2.2496471405029297
Validation loss: 2.019766092300415

Epoch: 6| Step: 10
Training loss: 1.8740140199661255
Validation loss: 2.0254514813423157

Epoch: 6| Step: 11
Training loss: 2.688498020172119
Validation loss: 2.023181895414988

Epoch: 6| Step: 12
Training loss: 2.050966501235962
Validation loss: 2.026162048180898

Epoch: 6| Step: 13
Training loss: 2.539687156677246
Validation loss: 2.0181280771891275

Epoch: 90| Step: 0
Training loss: 2.15769624710083
Validation loss: 2.018444220225016

Epoch: 6| Step: 1
Training loss: 2.144437789916992
Validation loss: 2.0099794467290244

Epoch: 6| Step: 2
Training loss: 1.887840986251831
Validation loss: 2.019009013970693

Epoch: 6| Step: 3
Training loss: 2.0591607093811035
Validation loss: 2.010873635609945

Epoch: 6| Step: 4
Training loss: 1.7346004247665405
Validation loss: 2.021420975526174

Epoch: 6| Step: 5
Training loss: 2.174112319946289
Validation loss: 2.0148539344469705

Epoch: 6| Step: 6
Training loss: 1.92399001121521
Validation loss: 2.02972678343455

Epoch: 6| Step: 7
Training loss: 2.4320619106292725
Validation loss: 2.0275460282961526

Epoch: 6| Step: 8
Training loss: 2.2954981327056885
Validation loss: 2.020556072394053

Epoch: 6| Step: 9
Training loss: 1.7299437522888184
Validation loss: 2.0324078798294067

Epoch: 6| Step: 10
Training loss: 2.7652649879455566
Validation loss: 2.04023285706838

Epoch: 6| Step: 11
Training loss: 2.03808331489563
Validation loss: 2.029401659965515

Epoch: 6| Step: 12
Training loss: 2.2615623474121094
Validation loss: 2.032024085521698

Epoch: 6| Step: 13
Training loss: 2.2361607551574707
Validation loss: 2.0411006212234497

Epoch: 91| Step: 0
Training loss: 2.2477266788482666
Validation loss: 2.0304711063702903

Epoch: 6| Step: 1
Training loss: 2.0100150108337402
Validation loss: 2.0221500396728516

Epoch: 6| Step: 2
Training loss: 1.308689832687378
Validation loss: 2.033606708049774

Epoch: 6| Step: 3
Training loss: 1.793959379196167
Validation loss: 2.021292587121328

Epoch: 6| Step: 4
Training loss: 2.3456621170043945
Validation loss: 2.029057780901591

Epoch: 6| Step: 5
Training loss: 2.4795291423797607
Validation loss: 2.0347110629081726

Epoch: 6| Step: 6
Training loss: 1.7437289953231812
Validation loss: 2.0322299202283225

Epoch: 6| Step: 7
Training loss: 2.0999698638916016
Validation loss: 2.0339244405428567

Epoch: 6| Step: 8
Training loss: 1.804152011871338
Validation loss: 2.03127392133077

Epoch: 6| Step: 9
Training loss: 2.712571859359741
Validation loss: 2.037297169367472

Epoch: 6| Step: 10
Training loss: 2.384883403778076
Validation loss: 2.0364951690038047

Epoch: 6| Step: 11
Training loss: 2.9113404750823975
Validation loss: 2.033926089604696

Epoch: 6| Step: 12
Training loss: 1.6852293014526367
Validation loss: 2.041561464468638

Epoch: 6| Step: 13
Training loss: 2.087769031524658
Validation loss: 2.041267454624176

Epoch: 92| Step: 0
Training loss: 1.5966755151748657
Validation loss: 2.0276297529538474

Epoch: 6| Step: 1
Training loss: 2.0996062755584717
Validation loss: 2.0315168698628745

Epoch: 6| Step: 2
Training loss: 2.6886162757873535
Validation loss: 2.0280252496401467

Epoch: 6| Step: 3
Training loss: 2.5539944171905518
Validation loss: 2.0207506815592446

Epoch: 6| Step: 4
Training loss: 2.2581913471221924
Validation loss: 2.017473797003428

Epoch: 6| Step: 5
Training loss: 1.945439338684082
Validation loss: 2.0184821486473083

Epoch: 6| Step: 6
Training loss: 2.304802417755127
Validation loss: 2.020895560582479

Epoch: 6| Step: 7
Training loss: 2.6723616123199463
Validation loss: 2.03166397412618

Epoch: 6| Step: 8
Training loss: 2.0688161849975586
Validation loss: 2.0407440463701882

Epoch: 6| Step: 9
Training loss: 2.103654623031616
Validation loss: 2.0352683464686074

Epoch: 6| Step: 10
Training loss: 2.0951104164123535
Validation loss: 2.03723015387853

Epoch: 6| Step: 11
Training loss: 1.8269826173782349
Validation loss: 2.0447423458099365

Epoch: 6| Step: 12
Training loss: 2.315058946609497
Validation loss: 2.0442104935646057

Epoch: 6| Step: 13
Training loss: 1.405220627784729
Validation loss: 2.0398444135983786

Epoch: 93| Step: 0
Training loss: 2.138643264770508
Validation loss: 2.028477410475413

Epoch: 6| Step: 1
Training loss: 1.7738144397735596
Validation loss: 2.024905343850454

Epoch: 6| Step: 2
Training loss: 2.0599288940429688
Validation loss: 2.028365512688955

Epoch: 6| Step: 3
Training loss: 2.3080389499664307
Validation loss: 2.030580163002014

Epoch: 6| Step: 4
Training loss: 2.186091423034668
Validation loss: 2.030789315700531

Epoch: 6| Step: 5
Training loss: 2.2549080848693848
Validation loss: 2.0257321198781333

Epoch: 6| Step: 6
Training loss: 2.1959705352783203
Validation loss: 2.0218452612559

Epoch: 6| Step: 7
Training loss: 2.0082364082336426
Validation loss: 2.0121079683303833

Epoch: 6| Step: 8
Training loss: 2.2418510913848877
Validation loss: 2.0142180720965066

Epoch: 6| Step: 9
Training loss: 1.9763166904449463
Validation loss: 2.0162039001782737

Epoch: 6| Step: 10
Training loss: 1.9853378534317017
Validation loss: 2.0303388039271035

Epoch: 6| Step: 11
Training loss: 2.0994577407836914
Validation loss: 2.0316878954569497

Epoch: 6| Step: 12
Training loss: 2.0427284240722656
Validation loss: 2.0181206663449607

Epoch: 6| Step: 13
Training loss: 2.4968085289001465
Validation loss: 2.036535660425822

Epoch: 94| Step: 0
Training loss: 2.5020976066589355
Validation loss: 2.047094682852427

Epoch: 6| Step: 1
Training loss: 2.172727108001709
Validation loss: 2.0365655223528543

Epoch: 6| Step: 2
Training loss: 1.753791093826294
Validation loss: 2.036036968231201

Epoch: 6| Step: 3
Training loss: 1.8085899353027344
Validation loss: 2.028960704803467

Epoch: 6| Step: 4
Training loss: 1.8780689239501953
Validation loss: 2.0287956992785134

Epoch: 6| Step: 5
Training loss: 2.214168071746826
Validation loss: 2.0325559775034585

Epoch: 6| Step: 6
Training loss: 1.7675591707229614
Validation loss: 2.0256047447522483

Epoch: 6| Step: 7
Training loss: 2.133458375930786
Validation loss: 2.02031817038854

Epoch: 6| Step: 8
Training loss: 2.1564698219299316
Validation loss: 2.0164828300476074

Epoch: 6| Step: 9
Training loss: 2.75935435295105
Validation loss: 2.028006652990977

Epoch: 6| Step: 10
Training loss: 2.2350895404815674
Validation loss: 2.0195958018302917

Epoch: 6| Step: 11
Training loss: 1.9466516971588135
Validation loss: 2.020913620789846

Epoch: 6| Step: 12
Training loss: 1.8079111576080322
Validation loss: 2.0307679772377014

Epoch: 6| Step: 13
Training loss: 2.3838443756103516
Validation loss: 2.0324765841166177

Epoch: 95| Step: 0
Training loss: 2.6574862003326416
Validation loss: 2.03084788719813

Epoch: 6| Step: 1
Training loss: 2.008446216583252
Validation loss: 2.0358099937438965

Epoch: 6| Step: 2
Training loss: 1.3083194494247437
Validation loss: 2.0313406387964883

Epoch: 6| Step: 3
Training loss: 2.4478769302368164
Validation loss: 2.0274893244107566

Epoch: 6| Step: 4
Training loss: 2.2002668380737305
Validation loss: 2.046211004257202

Epoch: 6| Step: 5
Training loss: 1.798327088356018
Validation loss: 2.0420897404352822

Epoch: 6| Step: 6
Training loss: 2.217485189437866
Validation loss: 2.0417270263036094

Epoch: 6| Step: 7
Training loss: 2.322737455368042
Validation loss: 2.0395572185516357

Epoch: 6| Step: 8
Training loss: 1.999000072479248
Validation loss: 2.033080220222473

Epoch: 6| Step: 9
Training loss: 1.3603808879852295
Validation loss: 2.0196078618367515

Epoch: 6| Step: 10
Training loss: 2.2056353092193604
Validation loss: 2.0272944370905557

Epoch: 6| Step: 11
Training loss: 2.6565914154052734
Validation loss: 2.028968850771586

Epoch: 6| Step: 12
Training loss: 1.8303638696670532
Validation loss: 2.0243327617645264

Epoch: 6| Step: 13
Training loss: 2.5415873527526855
Validation loss: 2.0324727495511374

Epoch: 96| Step: 0
Training loss: 2.21756911277771
Validation loss: 2.0408021807670593

Epoch: 6| Step: 1
Training loss: 2.2983686923980713
Validation loss: 2.0380747318267822

Epoch: 6| Step: 2
Training loss: 1.8313424587249756
Validation loss: 2.0311166842778525

Epoch: 6| Step: 3
Training loss: 2.26021146774292
Validation loss: 2.0488739609718323

Epoch: 6| Step: 4
Training loss: 2.4942498207092285
Validation loss: 2.042534669240316

Epoch: 6| Step: 5
Training loss: 2.1787776947021484
Validation loss: 2.032411436239878

Epoch: 6| Step: 6
Training loss: 2.032466411590576
Validation loss: 2.041561245918274

Epoch: 6| Step: 7
Training loss: 2.7923901081085205
Validation loss: 2.034239629904429

Epoch: 6| Step: 8
Training loss: 2.120418071746826
Validation loss: 2.04326597849528

Epoch: 6| Step: 9
Training loss: 2.3915324211120605
Validation loss: 2.0408426324526467

Epoch: 6| Step: 10
Training loss: 1.3675905466079712
Validation loss: 2.028101682662964

Epoch: 6| Step: 11
Training loss: 2.0452892780303955
Validation loss: 2.0156398018201194

Epoch: 6| Step: 12
Training loss: 2.200838088989258
Validation loss: 2.0130209724108377

Epoch: 6| Step: 13
Training loss: 1.2336390018463135
Validation loss: 2.007335344950358

Epoch: 97| Step: 0
Training loss: 2.5765857696533203
Validation loss: 2.022239923477173

Epoch: 6| Step: 1
Training loss: 1.7836569547653198
Validation loss: 2.009153723716736

Epoch: 6| Step: 2
Training loss: 2.500107765197754
Validation loss: 2.0080188711484275

Epoch: 6| Step: 3
Training loss: 2.1066510677337646
Validation loss: 2.005758305390676

Epoch: 6| Step: 4
Training loss: 2.0363917350769043
Validation loss: 2.0024150808652244

Epoch: 6| Step: 5
Training loss: 1.9758145809173584
Validation loss: 2.003593385219574

Epoch: 6| Step: 6
Training loss: 1.818680763244629
Validation loss: 2.0057515303293862

Epoch: 6| Step: 7
Training loss: 2.365239143371582
Validation loss: 2.0109663208325705

Epoch: 6| Step: 8
Training loss: 1.6300090551376343
Validation loss: 2.03381210565567

Epoch: 6| Step: 9
Training loss: 2.2738354206085205
Validation loss: 2.014107426007589

Epoch: 6| Step: 10
Training loss: 1.9352049827575684
Validation loss: 2.037072996298472

Epoch: 6| Step: 11
Training loss: 2.3439364433288574
Validation loss: 2.039958397547404

Epoch: 6| Step: 12
Training loss: 2.2298121452331543
Validation loss: 2.0416045784950256

Epoch: 6| Step: 13
Training loss: 2.095086097717285
Validation loss: 2.0384331345558167

Epoch: 98| Step: 0
Training loss: 2.2046775817871094
Validation loss: 2.034911255041758

Epoch: 6| Step: 1
Training loss: 2.8646626472473145
Validation loss: 2.0273494720458984

Epoch: 6| Step: 2
Training loss: 2.0780062675476074
Validation loss: 2.026574432849884

Epoch: 6| Step: 3
Training loss: 1.6506870985031128
Validation loss: 2.0238061944643655

Epoch: 6| Step: 4
Training loss: 2.0277061462402344
Validation loss: 2.017927328745524

Epoch: 6| Step: 5
Training loss: 2.0974717140197754
Validation loss: 2.0149868528048196

Epoch: 6| Step: 6
Training loss: 2.1280345916748047
Validation loss: 2.019006907939911

Epoch: 6| Step: 7
Training loss: 2.340933322906494
Validation loss: 2.0181284745534263

Epoch: 6| Step: 8
Training loss: 1.8403112888336182
Validation loss: 2.0251986384391785

Epoch: 6| Step: 9
Training loss: 2.0650081634521484
Validation loss: 2.0178288221359253

Epoch: 6| Step: 10
Training loss: 1.9832241535186768
Validation loss: 2.021872023741404

Epoch: 6| Step: 11
Training loss: 1.66964590549469
Validation loss: 2.0156484842300415

Epoch: 6| Step: 12
Training loss: 2.2174692153930664
Validation loss: 2.025551517804464

Epoch: 6| Step: 13
Training loss: 2.2555084228515625
Validation loss: 2.0195751587549844

Epoch: 99| Step: 0
Training loss: 2.585144519805908
Validation loss: 2.039517899354299

Epoch: 6| Step: 1
Training loss: 2.2837133407592773
Validation loss: 2.047631641228994

Epoch: 6| Step: 2
Training loss: 2.4999613761901855
Validation loss: 2.0672093431154885

Epoch: 6| Step: 3
Training loss: 1.9255974292755127
Validation loss: 2.05255119005839

Epoch: 6| Step: 4
Training loss: 1.811965823173523
Validation loss: 2.040239950021108

Epoch: 6| Step: 5
Training loss: 1.4781646728515625
Validation loss: 2.033451020717621

Epoch: 6| Step: 6
Training loss: 2.1068716049194336
Validation loss: 2.0288557410240173

Epoch: 6| Step: 7
Training loss: 2.213409423828125
Validation loss: 2.026975472768148

Epoch: 6| Step: 8
Training loss: 1.844919204711914
Validation loss: 2.013713558514913

Epoch: 6| Step: 9
Training loss: 2.5966155529022217
Validation loss: 2.014887829621633

Epoch: 6| Step: 10
Training loss: 1.967816710472107
Validation loss: 2.0240761439005532

Epoch: 6| Step: 11
Training loss: 1.759251594543457
Validation loss: 2.026544471581777

Epoch: 6| Step: 12
Training loss: 1.8975706100463867
Validation loss: 2.020914594332377

Epoch: 6| Step: 13
Training loss: 2.9854183197021484
Validation loss: 2.0267566045125327

Epoch: 100| Step: 0
Training loss: 2.5778322219848633
Validation loss: 2.0250383416811624

Epoch: 6| Step: 1
Training loss: 2.0384154319763184
Validation loss: 2.0311249494552612

Epoch: 6| Step: 2
Training loss: 2.2288990020751953
Validation loss: 2.032026489575704

Epoch: 6| Step: 3
Training loss: 2.044072151184082
Validation loss: 2.026093045870463

Epoch: 6| Step: 4
Training loss: 1.942579746246338
Validation loss: 2.0247888366381326

Epoch: 6| Step: 5
Training loss: 2.260084629058838
Validation loss: 2.016356647014618

Epoch: 6| Step: 6
Training loss: 2.0496649742126465
Validation loss: 2.024108052253723

Epoch: 6| Step: 7
Training loss: 2.915560722351074
Validation loss: 2.012024462223053

Epoch: 6| Step: 8
Training loss: 2.426809310913086
Validation loss: 2.0097442865371704

Epoch: 6| Step: 9
Training loss: 2.1636457443237305
Validation loss: 2.0122657418251038

Epoch: 6| Step: 10
Training loss: 1.9865097999572754
Validation loss: 2.023155411084493

Epoch: 6| Step: 11
Training loss: 2.14729642868042
Validation loss: 2.028840263684591

Epoch: 6| Step: 12
Training loss: 1.416521668434143
Validation loss: 2.0417360266049704

Epoch: 6| Step: 13
Training loss: 1.5115777254104614
Validation loss: 2.033804416656494

Epoch: 101| Step: 0
Training loss: 2.5787341594696045
Validation loss: 2.040300269921621

Epoch: 6| Step: 1
Training loss: 1.6502571105957031
Validation loss: 2.062926967938741

Epoch: 6| Step: 2
Training loss: 1.5547168254852295
Validation loss: 2.0626752773920694

Epoch: 6| Step: 3
Training loss: 2.326869487762451
Validation loss: 2.0688670674959817

Epoch: 6| Step: 4
Training loss: 2.5308871269226074
Validation loss: 2.0691028436024985

Epoch: 6| Step: 5
Training loss: 2.12785005569458
Validation loss: 2.056782682736715

Epoch: 6| Step: 6
Training loss: 1.8018465042114258
Validation loss: 2.054090440273285

Epoch: 6| Step: 7
Training loss: 2.305147647857666
Validation loss: 2.066115140914917

Epoch: 6| Step: 8
Training loss: 1.5396673679351807
Validation loss: 2.0469907919565835

Epoch: 6| Step: 9
Training loss: 1.838366985321045
Validation loss: 2.059663712978363

Epoch: 6| Step: 10
Training loss: 2.089667320251465
Validation loss: 2.0574839115142822

Epoch: 6| Step: 11
Training loss: 2.7016589641571045
Validation loss: 2.04556135336558

Epoch: 6| Step: 12
Training loss: 2.3066651821136475
Validation loss: 2.0357515017191568

Epoch: 6| Step: 13
Training loss: 2.2315993309020996
Validation loss: 2.033747752507528

Epoch: 102| Step: 0
Training loss: 1.4377593994140625
Validation loss: 2.01610791683197

Epoch: 6| Step: 1
Training loss: 2.0234761238098145
Validation loss: 2.0204614798227944

Epoch: 6| Step: 2
Training loss: 2.3312058448791504
Validation loss: 2.0252864956855774

Epoch: 6| Step: 3
Training loss: 2.42117977142334
Validation loss: 2.0221848487854004

Epoch: 6| Step: 4
Training loss: 1.6152068376541138
Validation loss: 2.0227625966072083

Epoch: 6| Step: 5
Training loss: 1.96767258644104
Validation loss: 2.0259627302487693

Epoch: 6| Step: 6
Training loss: 2.061854362487793
Validation loss: 2.029160221417745

Epoch: 6| Step: 7
Training loss: 2.344783067703247
Validation loss: 2.021064301331838

Epoch: 6| Step: 8
Training loss: 1.6645281314849854
Validation loss: 2.029814124107361

Epoch: 6| Step: 9
Training loss: 2.971116065979004
Validation loss: 2.0367818673451743

Epoch: 6| Step: 10
Training loss: 2.0402746200561523
Validation loss: 2.0377226074536643

Epoch: 6| Step: 11
Training loss: 1.8874764442443848
Validation loss: 2.0420538584391275

Epoch: 6| Step: 12
Training loss: 2.9935522079467773
Validation loss: 2.046409010887146

Epoch: 6| Step: 13
Training loss: 1.9028403759002686
Validation loss: 2.0480465292930603

Epoch: 103| Step: 0
Training loss: 1.9659154415130615
Validation loss: 2.0434844493865967

Epoch: 6| Step: 1
Training loss: 2.5165152549743652
Validation loss: 2.039073646068573

Epoch: 6| Step: 2
Training loss: 2.5974292755126953
Validation loss: 2.0290608406066895

Epoch: 6| Step: 3
Training loss: 1.6750801801681519
Validation loss: 2.0326762596766152

Epoch: 6| Step: 4
Training loss: 2.232642650604248
Validation loss: 2.026748021443685

Epoch: 6| Step: 5
Training loss: 2.380817413330078
Validation loss: 2.018515666325887

Epoch: 6| Step: 6
Training loss: 2.6739296913146973
Validation loss: 2.0298049449920654

Epoch: 6| Step: 7
Training loss: 2.3322229385375977
Validation loss: 2.025605340798696

Epoch: 6| Step: 8
Training loss: 2.015308141708374
Validation loss: 2.022316853205363

Epoch: 6| Step: 9
Training loss: 2.035973310470581
Validation loss: 2.0316867232322693

Epoch: 6| Step: 10
Training loss: 1.7730844020843506
Validation loss: 2.0302347540855408

Epoch: 6| Step: 11
Training loss: 1.20802903175354
Validation loss: 2.033417503039042

Epoch: 6| Step: 12
Training loss: 1.9259827136993408
Validation loss: 2.040931244691213

Epoch: 6| Step: 13
Training loss: 2.130478620529175
Validation loss: 2.0211798946062722

Epoch: 104| Step: 0
Training loss: 2.134023666381836
Validation loss: 2.038699130217234

Epoch: 6| Step: 1
Training loss: 1.4300098419189453
Validation loss: 2.0395676294962564

Epoch: 6| Step: 2
Training loss: 1.5840682983398438
Validation loss: 2.054558575153351

Epoch: 6| Step: 3
Training loss: 2.086544990539551
Validation loss: 2.0687736670176187

Epoch: 6| Step: 4
Training loss: 2.384841203689575
Validation loss: 2.1048545837402344

Epoch: 6| Step: 5
Training loss: 2.0581367015838623
Validation loss: 2.097780466079712

Epoch: 6| Step: 6
Training loss: 1.438328742980957
Validation loss: 2.0656380653381348

Epoch: 6| Step: 7
Training loss: 2.7275986671447754
Validation loss: 2.0746669371922812

Epoch: 6| Step: 8
Training loss: 2.185424566268921
Validation loss: 2.054822544256846

Epoch: 6| Step: 9
Training loss: 2.9353532791137695
Validation loss: 2.0517551501592

Epoch: 6| Step: 10
Training loss: 2.1171951293945312
Validation loss: 2.0486093560854592

Epoch: 6| Step: 11
Training loss: 1.9854204654693604
Validation loss: 2.035356104373932

Epoch: 6| Step: 12
Training loss: 2.4351751804351807
Validation loss: 2.025572935740153

Epoch: 6| Step: 13
Training loss: 2.2928781509399414
Validation loss: 2.036483645439148

Epoch: 105| Step: 0
Training loss: 2.3907246589660645
Validation loss: 2.0244426925977073

Epoch: 6| Step: 1
Training loss: 2.64642071723938
Validation loss: 2.0271632075309753

Epoch: 6| Step: 2
Training loss: 1.95656156539917
Validation loss: 2.032501995563507

Epoch: 6| Step: 3
Training loss: 1.7679085731506348
Validation loss: 2.0221471389134726

Epoch: 6| Step: 4
Training loss: 2.5764694213867188
Validation loss: 2.028094013532003

Epoch: 6| Step: 5
Training loss: 2.3227758407592773
Validation loss: 2.0281497836112976

Epoch: 6| Step: 6
Training loss: 2.5843935012817383
Validation loss: 2.021314521630605

Epoch: 6| Step: 7
Training loss: 1.8158711194992065
Validation loss: 2.0232178568840027

Epoch: 6| Step: 8
Training loss: 1.8941266536712646
Validation loss: 2.026378850142161

Epoch: 6| Step: 9
Training loss: 1.8541820049285889
Validation loss: 2.035103460152944

Epoch: 6| Step: 10
Training loss: 1.4945659637451172
Validation loss: 2.0405192971229553

Epoch: 6| Step: 11
Training loss: 1.4890449047088623
Validation loss: 2.0259504516919455

Epoch: 6| Step: 12
Training loss: 2.551570177078247
Validation loss: 2.0250327785809836

Epoch: 6| Step: 13
Training loss: 2.3957571983337402
Validation loss: 2.033950626850128

Epoch: 106| Step: 0
Training loss: 2.308732271194458
Validation loss: 2.025270402431488

Epoch: 6| Step: 1
Training loss: 2.414161205291748
Validation loss: 2.0203344424565635

Epoch: 6| Step: 2
Training loss: 1.8268040418624878
Validation loss: 2.0187737345695496

Epoch: 6| Step: 3
Training loss: 2.153728485107422
Validation loss: 2.030640800793966

Epoch: 6| Step: 4
Training loss: 2.381422996520996
Validation loss: 2.0214328169822693

Epoch: 6| Step: 5
Training loss: 1.8340952396392822
Validation loss: 2.020714362462362

Epoch: 6| Step: 6
Training loss: 2.4221763610839844
Validation loss: 2.023063321908315

Epoch: 6| Step: 7
Training loss: 1.768261194229126
Validation loss: 2.018081704775492

Epoch: 6| Step: 8
Training loss: 1.9528461694717407
Validation loss: 2.0264869332313538

Epoch: 6| Step: 9
Training loss: 1.9143892526626587
Validation loss: 2.01913454135259

Epoch: 6| Step: 10
Training loss: 2.4570910930633545
Validation loss: 2.0217758615811667

Epoch: 6| Step: 11
Training loss: 2.5436782836914062
Validation loss: 2.035639842351278

Epoch: 6| Step: 12
Training loss: 1.943941593170166
Validation loss: 2.0343335469563804

Epoch: 6| Step: 13
Training loss: 1.6662209033966064
Validation loss: 2.034967084725698

Epoch: 107| Step: 0
Training loss: 2.4355058670043945
Validation loss: 2.0376009941101074

Epoch: 6| Step: 1
Training loss: 2.0540575981140137
Validation loss: 2.0437960823376975

Epoch: 6| Step: 2
Training loss: 1.859053134918213
Validation loss: 2.0525519251823425

Epoch: 6| Step: 3
Training loss: 2.3315958976745605
Validation loss: 2.062889834245046

Epoch: 6| Step: 4
Training loss: 2.610062599182129
Validation loss: 2.04803866147995

Epoch: 6| Step: 5
Training loss: 1.691580891609192
Validation loss: 2.03422079483668

Epoch: 6| Step: 6
Training loss: 2.162100076675415
Validation loss: 2.027513563632965

Epoch: 6| Step: 7
Training loss: 2.0243587493896484
Validation loss: 2.0271990100542703

Epoch: 6| Step: 8
Training loss: 2.3351292610168457
Validation loss: 2.0248973965644836

Epoch: 6| Step: 9
Training loss: 2.265979290008545
Validation loss: 2.0314249793688455

Epoch: 6| Step: 10
Training loss: 1.9747519493103027
Validation loss: 2.0300058325131736

Epoch: 6| Step: 11
Training loss: 1.923839807510376
Validation loss: 2.0246771772702536

Epoch: 6| Step: 12
Training loss: 2.127084255218506
Validation loss: 2.0345880587895713

Epoch: 6| Step: 13
Training loss: 1.6463834047317505
Validation loss: 2.038303275903066

Epoch: 108| Step: 0
Training loss: 2.197537899017334
Validation loss: 2.026763598124186

Epoch: 6| Step: 1
Training loss: 1.8649393320083618
Validation loss: 2.0436798731486

Epoch: 6| Step: 2
Training loss: 1.814117670059204
Validation loss: 2.0313230951627097

Epoch: 6| Step: 3
Training loss: 2.144455909729004
Validation loss: 2.0324583053588867

Epoch: 6| Step: 4
Training loss: 1.456225872039795
Validation loss: 2.0383361180623374

Epoch: 6| Step: 5
Training loss: 2.4582254886627197
Validation loss: 2.049389044443766

Epoch: 6| Step: 6
Training loss: 1.9291504621505737
Validation loss: 2.049215316772461

Epoch: 6| Step: 7
Training loss: 2.193291187286377
Validation loss: 2.0560975273450217

Epoch: 6| Step: 8
Training loss: 2.601956844329834
Validation loss: 2.04882949590683

Epoch: 6| Step: 9
Training loss: 2.199863910675049
Validation loss: 2.042408366998037

Epoch: 6| Step: 10
Training loss: 2.0560851097106934
Validation loss: 2.0424607396125793

Epoch: 6| Step: 11
Training loss: 1.7806129455566406
Validation loss: 2.038139581680298

Epoch: 6| Step: 12
Training loss: 2.423135280609131
Validation loss: 2.024038294951121

Epoch: 6| Step: 13
Training loss: 2.1581337451934814
Validation loss: 2.0164014299710593

Epoch: 109| Step: 0
Training loss: 2.436734437942505
Validation loss: 2.0050064524014792

Epoch: 6| Step: 1
Training loss: 2.380052089691162
Validation loss: 2.0111203789711

Epoch: 6| Step: 2
Training loss: 1.9930047988891602
Validation loss: 2.00994211435318

Epoch: 6| Step: 3
Training loss: 1.6535084247589111
Validation loss: 2.0129647453626

Epoch: 6| Step: 4
Training loss: 1.8405286073684692
Validation loss: 2.011569102605184

Epoch: 6| Step: 5
Training loss: 1.7256627082824707
Validation loss: 2.022485335667928

Epoch: 6| Step: 6
Training loss: 2.1410350799560547
Validation loss: 2.035604457060496

Epoch: 6| Step: 7
Training loss: 2.0238075256347656
Validation loss: 2.0306532979011536

Epoch: 6| Step: 8
Training loss: 2.1503658294677734
Validation loss: 2.041664401690165

Epoch: 6| Step: 9
Training loss: 2.5427513122558594
Validation loss: 2.033196528752645

Epoch: 6| Step: 10
Training loss: 2.351651906967163
Validation loss: 2.0376837452252707

Epoch: 6| Step: 11
Training loss: 2.3308234214782715
Validation loss: 2.0263157288233438

Epoch: 6| Step: 12
Training loss: 1.9763855934143066
Validation loss: 2.0301311016082764

Epoch: 6| Step: 13
Training loss: 2.5125296115875244
Validation loss: 2.017510175704956

Epoch: 110| Step: 0
Training loss: 2.4565377235412598
Validation loss: 2.003282447655996

Epoch: 6| Step: 1
Training loss: 1.7129075527191162
Validation loss: 2.0035259127616882

Epoch: 6| Step: 2
Training loss: 1.7634820938110352
Validation loss: 2.0059306025505066

Epoch: 6| Step: 3
Training loss: 2.7910220623016357
Validation loss: 2.0054519176483154

Epoch: 6| Step: 4
Training loss: 2.4265289306640625
Validation loss: 2.011673927307129

Epoch: 6| Step: 5
Training loss: 2.538588523864746
Validation loss: 2.024150232474009

Epoch: 6| Step: 6
Training loss: 2.439903736114502
Validation loss: 2.030067423979441

Epoch: 6| Step: 7
Training loss: 1.8098883628845215
Validation loss: 2.0514317750930786

Epoch: 6| Step: 8
Training loss: 1.7975447177886963
Validation loss: 2.0452489455540976

Epoch: 6| Step: 9
Training loss: 2.0298569202423096
Validation loss: 2.0406495134035745

Epoch: 6| Step: 10
Training loss: 1.6121231317520142
Validation loss: 2.037508765856425

Epoch: 6| Step: 11
Training loss: 2.333364248275757
Validation loss: 2.0284995834032693

Epoch: 6| Step: 12
Training loss: 1.8686447143554688
Validation loss: 2.018359045187632

Epoch: 6| Step: 13
Training loss: 2.044919013977051
Validation loss: 2.010422666867574

Epoch: 111| Step: 0
Training loss: 2.0668835639953613
Validation loss: 2.0054054260253906

Epoch: 6| Step: 1
Training loss: 2.498608350753784
Validation loss: 2.0119020342826843

Epoch: 6| Step: 2
Training loss: 1.6989237070083618
Validation loss: 2.0101433197657266

Epoch: 6| Step: 3
Training loss: 1.9439444541931152
Validation loss: 2.0162692268689475

Epoch: 6| Step: 4
Training loss: 2.2479772567749023
Validation loss: 2.0169531305631003

Epoch: 6| Step: 5
Training loss: 2.043569326400757
Validation loss: 2.018861730893453

Epoch: 6| Step: 6
Training loss: 1.6789414882659912
Validation loss: 2.0168838500976562

Epoch: 6| Step: 7
Training loss: 2.747138023376465
Validation loss: 2.019130289554596

Epoch: 6| Step: 8
Training loss: 2.1871254444122314
Validation loss: 2.0256123542785645

Epoch: 6| Step: 9
Training loss: 1.7033052444458008
Validation loss: 2.0215437610944114

Epoch: 6| Step: 10
Training loss: 2.141092300415039
Validation loss: 2.019612669944763

Epoch: 6| Step: 11
Training loss: 1.9283552169799805
Validation loss: 2.0235636234283447

Epoch: 6| Step: 12
Training loss: 2.0356953144073486
Validation loss: 2.0235135356585183

Epoch: 6| Step: 13
Training loss: 2.3762173652648926
Validation loss: 2.036236604054769

Epoch: 112| Step: 0
Training loss: 1.9015599489212036
Validation loss: 2.0445788701375327

Epoch: 6| Step: 1
Training loss: 2.443805694580078
Validation loss: 2.05347873767217

Epoch: 6| Step: 2
Training loss: 1.9607899188995361
Validation loss: 2.0440308650334678

Epoch: 6| Step: 3
Training loss: 1.9161587953567505
Validation loss: 2.020512799421946

Epoch: 6| Step: 4
Training loss: 2.2996513843536377
Validation loss: 2.0265630880991616

Epoch: 6| Step: 5
Training loss: 2.541616916656494
Validation loss: 2.025560180346171

Epoch: 6| Step: 6
Training loss: 2.2733983993530273
Validation loss: 2.0166818698247275

Epoch: 6| Step: 7
Training loss: 2.016432046890259
Validation loss: 2.0081568559010825

Epoch: 6| Step: 8
Training loss: 2.046844244003296
Validation loss: 2.0128501852353415

Epoch: 6| Step: 9
Training loss: 2.097470283508301
Validation loss: 2.021161377429962

Epoch: 6| Step: 10
Training loss: 1.6107470989227295
Validation loss: 2.0215558211008706

Epoch: 6| Step: 11
Training loss: 1.975854754447937
Validation loss: 2.0210907459259033

Epoch: 6| Step: 12
Training loss: 1.7361981868743896
Validation loss: 2.029087781906128

Epoch: 6| Step: 13
Training loss: 2.3668441772460938
Validation loss: 2.019696851571401

Epoch: 113| Step: 0
Training loss: 1.2934693098068237
Validation loss: 2.0149068236351013

Epoch: 6| Step: 1
Training loss: 2.209407329559326
Validation loss: 2.0243838826815286

Epoch: 6| Step: 2
Training loss: 1.8682118654251099
Validation loss: 2.0275327563285828

Epoch: 6| Step: 3
Training loss: 2.379286289215088
Validation loss: 2.025733788808187

Epoch: 6| Step: 4
Training loss: 2.279196262359619
Validation loss: 2.024662812550863

Epoch: 6| Step: 5
Training loss: 2.5691781044006348
Validation loss: 2.023905416329702

Epoch: 6| Step: 6
Training loss: 1.425713300704956
Validation loss: 2.03077232837677

Epoch: 6| Step: 7
Training loss: 2.569700241088867
Validation loss: 2.03471847375234

Epoch: 6| Step: 8
Training loss: 2.4063613414764404
Validation loss: 2.0473798513412476

Epoch: 6| Step: 9
Training loss: 1.9977824687957764
Validation loss: 2.0454449454943338

Epoch: 6| Step: 10
Training loss: 2.3086938858032227
Validation loss: 2.038770377635956

Epoch: 6| Step: 11
Training loss: 1.626082181930542
Validation loss: 2.039588510990143

Epoch: 6| Step: 12
Training loss: 1.5953048467636108
Validation loss: 2.034079988797506

Epoch: 6| Step: 13
Training loss: 2.292128562927246
Validation loss: 2.034593403339386

Epoch: 114| Step: 0
Training loss: 1.8614130020141602
Validation loss: 2.043476382891337

Epoch: 6| Step: 1
Training loss: 1.7887752056121826
Validation loss: 2.0340981483459473

Epoch: 6| Step: 2
Training loss: 2.0362887382507324
Validation loss: 2.0362525582313538

Epoch: 6| Step: 3
Training loss: 2.133209705352783
Validation loss: 2.027327597141266

Epoch: 6| Step: 4
Training loss: 2.514345169067383
Validation loss: 2.0272836883862815

Epoch: 6| Step: 5
Training loss: 2.2040953636169434
Validation loss: 2.0269092520078025

Epoch: 6| Step: 6
Training loss: 1.8028042316436768
Validation loss: 2.031598965326945

Epoch: 6| Step: 7
Training loss: 2.4207663536071777
Validation loss: 2.030152897040049

Epoch: 6| Step: 8
Training loss: 1.9237232208251953
Validation loss: 2.0295368234316506

Epoch: 6| Step: 9
Training loss: 1.892091989517212
Validation loss: 2.030509293079376

Epoch: 6| Step: 10
Training loss: 2.3246493339538574
Validation loss: 2.037266433238983

Epoch: 6| Step: 11
Training loss: 2.2159481048583984
Validation loss: 2.03041535615921

Epoch: 6| Step: 12
Training loss: 1.6901013851165771
Validation loss: 2.0378071467081704

Epoch: 6| Step: 13
Training loss: 2.403048515319824
Validation loss: 2.027400811513265

Epoch: 115| Step: 0
Training loss: 2.3287858963012695
Validation loss: 2.0373733043670654

Epoch: 6| Step: 1
Training loss: 1.7864718437194824
Validation loss: 2.036969304084778

Epoch: 6| Step: 2
Training loss: 2.489543914794922
Validation loss: 2.0389817357063293

Epoch: 6| Step: 3
Training loss: 2.003162384033203
Validation loss: 2.0346489747365317

Epoch: 6| Step: 4
Training loss: 2.027479648590088
Validation loss: 2.029934585094452

Epoch: 6| Step: 5
Training loss: 2.316990375518799
Validation loss: 2.038168748219808

Epoch: 6| Step: 6
Training loss: 1.974297285079956
Validation loss: 2.034543832143148

Epoch: 6| Step: 7
Training loss: 1.9183268547058105
Validation loss: 2.0267189145088196

Epoch: 6| Step: 8
Training loss: 2.344101905822754
Validation loss: 2.027288019657135

Epoch: 6| Step: 9
Training loss: 1.9821137189865112
Validation loss: 2.0272111892700195

Epoch: 6| Step: 10
Training loss: 2.132096767425537
Validation loss: 2.036095221837362

Epoch: 6| Step: 11
Training loss: 1.9018586874008179
Validation loss: 2.0243705113728843

Epoch: 6| Step: 12
Training loss: 2.144606113433838
Validation loss: 2.028275787830353

Epoch: 6| Step: 13
Training loss: 1.8859167098999023
Validation loss: 2.023439129193624

Epoch: 116| Step: 0
Training loss: 2.1193783283233643
Validation loss: 2.0248665809631348

Epoch: 6| Step: 1
Training loss: 2.054097890853882
Validation loss: 2.033877670764923

Epoch: 6| Step: 2
Training loss: 2.324343681335449
Validation loss: 2.0387496948242188

Epoch: 6| Step: 3
Training loss: 1.94521164894104
Validation loss: 2.0376418034235635

Epoch: 6| Step: 4
Training loss: 1.8373124599456787
Validation loss: 2.046280801296234

Epoch: 6| Step: 5
Training loss: 1.612447738647461
Validation loss: 2.0459823409716287

Epoch: 6| Step: 6
Training loss: 1.955214023590088
Validation loss: 2.03529820839564

Epoch: 6| Step: 7
Training loss: 2.2030258178710938
Validation loss: 2.0320290525754294

Epoch: 6| Step: 8
Training loss: 1.9360575675964355
Validation loss: 2.0283210476239524

Epoch: 6| Step: 9
Training loss: 2.469874143600464
Validation loss: 2.0248482823371887

Epoch: 6| Step: 10
Training loss: 2.1512300968170166
Validation loss: 2.017036259174347

Epoch: 6| Step: 11
Training loss: 1.9247198104858398
Validation loss: 2.0200421611467996

Epoch: 6| Step: 12
Training loss: 1.830740213394165
Validation loss: 2.0298499862353006

Epoch: 6| Step: 13
Training loss: 2.715773582458496
Validation loss: 2.027379353841146

Epoch: 117| Step: 0
Training loss: 2.260385036468506
Validation loss: 2.024631460507711

Epoch: 6| Step: 1
Training loss: 1.8259892463684082
Validation loss: 2.0268155932426453

Epoch: 6| Step: 2
Training loss: 2.108181953430176
Validation loss: 2.0285513202349343

Epoch: 6| Step: 3
Training loss: 2.680812120437622
Validation loss: 2.02739417552948

Epoch: 6| Step: 4
Training loss: 2.127239942550659
Validation loss: 2.028765559196472

Epoch: 6| Step: 5
Training loss: 1.803804874420166
Validation loss: 2.0354370872179666

Epoch: 6| Step: 6
Training loss: 2.1631901264190674
Validation loss: 2.0371967951456704

Epoch: 6| Step: 7
Training loss: 2.219572067260742
Validation loss: 2.033018112182617

Epoch: 6| Step: 8
Training loss: 2.477354049682617
Validation loss: 2.0384612679481506

Epoch: 6| Step: 9
Training loss: 1.9524242877960205
Validation loss: 2.048588772614797

Epoch: 6| Step: 10
Training loss: 1.551698923110962
Validation loss: 2.0353086789449057

Epoch: 6| Step: 11
Training loss: 2.429427146911621
Validation loss: 2.0456350445747375

Epoch: 6| Step: 12
Training loss: 1.4826852083206177
Validation loss: 2.0360160072644553

Epoch: 6| Step: 13
Training loss: 1.9866894483566284
Validation loss: 2.036807060241699

Epoch: 118| Step: 0
Training loss: 1.9898054599761963
Validation loss: 2.037850856781006

Epoch: 6| Step: 1
Training loss: 2.1879429817199707
Validation loss: 2.029104312260946

Epoch: 6| Step: 2
Training loss: 2.0480990409851074
Validation loss: 2.0214804808298745

Epoch: 6| Step: 3
Training loss: 2.0412628650665283
Validation loss: 2.042269229888916

Epoch: 6| Step: 4
Training loss: 2.1889848709106445
Validation loss: 2.052061895529429

Epoch: 6| Step: 5
Training loss: 2.2039124965667725
Validation loss: 2.0404251416524253

Epoch: 6| Step: 6
Training loss: 1.9666974544525146
Validation loss: 2.0412433544794717

Epoch: 6| Step: 7
Training loss: 2.199493408203125
Validation loss: 2.0486204425493875

Epoch: 6| Step: 8
Training loss: 1.6521685123443604
Validation loss: 2.0600881377855935

Epoch: 6| Step: 9
Training loss: 2.15354585647583
Validation loss: 2.056807299455007

Epoch: 6| Step: 10
Training loss: 2.061345338821411
Validation loss: 2.0786943435668945

Epoch: 6| Step: 11
Training loss: 2.431241750717163
Validation loss: 2.062007784843445

Epoch: 6| Step: 12
Training loss: 2.303041934967041
Validation loss: 2.0485428174336753

Epoch: 6| Step: 13
Training loss: 1.7603058815002441
Validation loss: 2.037345588207245

Epoch: 119| Step: 0
Training loss: 2.0638818740844727
Validation loss: 2.0511701504389444

Epoch: 6| Step: 1
Training loss: 1.9819591045379639
Validation loss: 2.047001679738363

Epoch: 6| Step: 2
Training loss: 2.004807949066162
Validation loss: 2.050998051961263

Epoch: 6| Step: 3
Training loss: 1.5385985374450684
Validation loss: 2.054436425367991

Epoch: 6| Step: 4
Training loss: 2.2483019828796387
Validation loss: 2.049063523610433

Epoch: 6| Step: 5
Training loss: 2.302738666534424
Validation loss: 2.035527467727661

Epoch: 6| Step: 6
Training loss: 2.713684558868408
Validation loss: 2.033905804157257

Epoch: 6| Step: 7
Training loss: 2.2069814205169678
Validation loss: 2.050853192806244

Epoch: 6| Step: 8
Training loss: 1.701465129852295
Validation loss: 2.0425740281740823

Epoch: 6| Step: 9
Training loss: 2.5965323448181152
Validation loss: 2.039637565612793

Epoch: 6| Step: 10
Training loss: 2.3626532554626465
Validation loss: 2.039774159590403

Epoch: 6| Step: 11
Training loss: 1.533543586730957
Validation loss: 2.0313555002212524

Epoch: 6| Step: 12
Training loss: 1.7750879526138306
Validation loss: 2.039135197798411

Epoch: 6| Step: 13
Training loss: 2.11309552192688
Validation loss: 2.040301203727722

Epoch: 120| Step: 0
Training loss: 2.3018746376037598
Validation loss: 2.024745504061381

Epoch: 6| Step: 1
Training loss: 1.9449717998504639
Validation loss: 2.0451430479685464

Epoch: 6| Step: 2
Training loss: 1.4657728672027588
Validation loss: 2.037327766418457

Epoch: 6| Step: 3
Training loss: 2.406035900115967
Validation loss: 2.038956046104431

Epoch: 6| Step: 4
Training loss: 1.7530938386917114
Validation loss: 2.0392614006996155

Epoch: 6| Step: 5
Training loss: 2.5473508834838867
Validation loss: 2.0435600678126016

Epoch: 6| Step: 6
Training loss: 1.4806292057037354
Validation loss: 2.0327452421188354

Epoch: 6| Step: 7
Training loss: 2.278115749359131
Validation loss: 2.0373273491859436

Epoch: 6| Step: 8
Training loss: 2.0349457263946533
Validation loss: 2.0415488481521606

Epoch: 6| Step: 9
Training loss: 2.0828237533569336
Validation loss: 2.0366217891375222

Epoch: 6| Step: 10
Training loss: 1.8555588722229004
Validation loss: 2.0576318502426147

Epoch: 6| Step: 11
Training loss: 3.141117572784424
Validation loss: 2.0573998292287192

Epoch: 6| Step: 12
Training loss: 1.9414383172988892
Validation loss: 2.0490136543909707

Epoch: 6| Step: 13
Training loss: 1.3954752683639526
Validation loss: 2.037859320640564

Epoch: 121| Step: 0
Training loss: 2.0276548862457275
Validation loss: 2.0401890873908997

Epoch: 6| Step: 1
Training loss: 1.988348126411438
Validation loss: 2.035939037799835

Epoch: 6| Step: 2
Training loss: 2.151991128921509
Validation loss: 2.0344520608584085

Epoch: 6| Step: 3
Training loss: 2.0088279247283936
Validation loss: 2.029673933982849

Epoch: 6| Step: 4
Training loss: 1.7676455974578857
Validation loss: 2.0231348077456155

Epoch: 6| Step: 5
Training loss: 2.2391445636749268
Validation loss: 2.0292104482650757

Epoch: 6| Step: 6
Training loss: 1.8319458961486816
Validation loss: 2.0218686858812966

Epoch: 6| Step: 7
Training loss: 1.698362112045288
Validation loss: 2.0263914863268533

Epoch: 6| Step: 8
Training loss: 2.4671578407287598
Validation loss: 2.025376876195272

Epoch: 6| Step: 9
Training loss: 2.1365411281585693
Validation loss: 2.035117268562317

Epoch: 6| Step: 10
Training loss: 1.7228765487670898
Validation loss: 2.0375288128852844

Epoch: 6| Step: 11
Training loss: 2.6765389442443848
Validation loss: 2.0346173842748008

Epoch: 6| Step: 12
Training loss: 2.039557933807373
Validation loss: 2.0473225911458335

Epoch: 6| Step: 13
Training loss: 2.312688112258911
Validation loss: 2.045015295346578

Epoch: 122| Step: 0
Training loss: 2.02848482131958
Validation loss: 2.05955179532369

Epoch: 6| Step: 1
Training loss: 2.2313425540924072
Validation loss: 2.059497078259786

Epoch: 6| Step: 2
Training loss: 1.5410230159759521
Validation loss: 2.0697322487831116

Epoch: 6| Step: 3
Training loss: 3.057595729827881
Validation loss: 2.0770377119382224

Epoch: 6| Step: 4
Training loss: 2.0605039596557617
Validation loss: 2.1000484625498452

Epoch: 6| Step: 5
Training loss: 2.0281858444213867
Validation loss: 2.078942676385244

Epoch: 6| Step: 6
Training loss: 2.0487680435180664
Validation loss: 2.100018242994944

Epoch: 6| Step: 7
Training loss: 1.7644904851913452
Validation loss: 2.0731828610102334

Epoch: 6| Step: 8
Training loss: 2.127732038497925
Validation loss: 2.0712176163991294

Epoch: 6| Step: 9
Training loss: 2.411468982696533
Validation loss: 2.057073791821798

Epoch: 6| Step: 10
Training loss: 1.7532095909118652
Validation loss: 2.044265568256378

Epoch: 6| Step: 11
Training loss: 2.538646697998047
Validation loss: 2.044730802377065

Epoch: 6| Step: 12
Training loss: 1.766066312789917
Validation loss: 2.0370174646377563

Epoch: 6| Step: 13
Training loss: 2.0290987491607666
Validation loss: 2.038436015446981

Epoch: 123| Step: 0
Training loss: 1.9883469343185425
Validation loss: 2.0326239267985025

Epoch: 6| Step: 1
Training loss: 2.0777740478515625
Validation loss: 2.0442358255386353

Epoch: 6| Step: 2
Training loss: 1.7824723720550537
Validation loss: 2.0397793451944985

Epoch: 6| Step: 3
Training loss: 2.4159929752349854
Validation loss: 2.0331082145373025

Epoch: 6| Step: 4
Training loss: 2.597782611846924
Validation loss: 2.0280429323514304

Epoch: 6| Step: 5
Training loss: 2.178562641143799
Validation loss: 2.0268787145614624

Epoch: 6| Step: 6
Training loss: 2.664337158203125
Validation loss: 2.0345340768496194

Epoch: 6| Step: 7
Training loss: 2.2164981365203857
Validation loss: 2.0243838826815286

Epoch: 6| Step: 8
Training loss: 1.8059909343719482
Validation loss: 2.019363443056742

Epoch: 6| Step: 9
Training loss: 2.064974784851074
Validation loss: 2.0070263544718423

Epoch: 6| Step: 10
Training loss: 2.1362662315368652
Validation loss: 2.0233054757118225

Epoch: 6| Step: 11
Training loss: 1.6651502847671509
Validation loss: 2.019587238629659

Epoch: 6| Step: 12
Training loss: 2.0400383472442627
Validation loss: 2.005159854888916

Epoch: 6| Step: 13
Training loss: 1.704434871673584
Validation loss: 2.007471183935801

Epoch: 124| Step: 0
Training loss: 2.365365982055664
Validation loss: 2.005114515622457

Epoch: 6| Step: 1
Training loss: 2.3893184661865234
Validation loss: 2.007095774014791

Epoch: 6| Step: 2
Training loss: 1.8613280057907104
Validation loss: 2.016170342763265

Epoch: 6| Step: 3
Training loss: 1.5830390453338623
Validation loss: 2.0056737661361694

Epoch: 6| Step: 4
Training loss: 1.4965198040008545
Validation loss: 2.0185797810554504

Epoch: 6| Step: 5
Training loss: 2.4209039211273193
Validation loss: 2.024489998817444

Epoch: 6| Step: 6
Training loss: 2.0995137691497803
Validation loss: 2.031212091445923

Epoch: 6| Step: 7
Training loss: 2.1124024391174316
Validation loss: 2.02772319316864

Epoch: 6| Step: 8
Training loss: 2.3985254764556885
Validation loss: 2.030283570289612

Epoch: 6| Step: 9
Training loss: 1.4491870403289795
Validation loss: 2.029380659262339

Epoch: 6| Step: 10
Training loss: 2.708986282348633
Validation loss: 2.026383618513743

Epoch: 6| Step: 11
Training loss: 1.5936614274978638
Validation loss: 2.025044580300649

Epoch: 6| Step: 12
Training loss: 1.9760702848434448
Validation loss: 2.0506684382756553

Epoch: 6| Step: 13
Training loss: 2.4007275104522705
Validation loss: 2.0377795497576394

Epoch: 125| Step: 0
Training loss: 2.3896543979644775
Validation loss: 2.04210497935613

Epoch: 6| Step: 1
Training loss: 2.090750217437744
Validation loss: 2.060239553451538

Epoch: 6| Step: 2
Training loss: 1.8606325387954712
Validation loss: 2.0638365348180137

Epoch: 6| Step: 3
Training loss: 2.5133450031280518
Validation loss: 2.059230546156565

Epoch: 6| Step: 4
Training loss: 2.0650439262390137
Validation loss: 2.0544437567392984

Epoch: 6| Step: 5
Training loss: 2.0914533138275146
Validation loss: 2.055540402730306

Epoch: 6| Step: 6
Training loss: 2.0325751304626465
Validation loss: 2.0628578861554465

Epoch: 6| Step: 7
Training loss: 1.6435271501541138
Validation loss: 2.0361233750979104

Epoch: 6| Step: 8
Training loss: 1.6699581146240234
Validation loss: 2.0329135060310364

Epoch: 6| Step: 9
Training loss: 1.345534086227417
Validation loss: 2.038018743197123

Epoch: 6| Step: 10
Training loss: 2.7224953174591064
Validation loss: 2.0396148562431335

Epoch: 6| Step: 11
Training loss: 2.0552048683166504
Validation loss: 2.032896041870117

Epoch: 6| Step: 12
Training loss: 2.4280359745025635
Validation loss: 2.030956228574117

Epoch: 6| Step: 13
Training loss: 2.0917558670043945
Validation loss: 2.0378283063570657

Testing loss: 1.7249241947270126
