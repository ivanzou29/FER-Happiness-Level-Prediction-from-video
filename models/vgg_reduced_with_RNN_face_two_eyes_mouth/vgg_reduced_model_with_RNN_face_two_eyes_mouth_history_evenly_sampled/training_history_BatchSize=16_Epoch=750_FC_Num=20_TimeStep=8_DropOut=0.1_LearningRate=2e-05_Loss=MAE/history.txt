Epoch: 1| Step: 0
Training loss: 6.133469581604004
Validation loss: 5.144486058142878

Epoch: 6| Step: 1
Training loss: 5.088831901550293
Validation loss: 5.119442432157455

Epoch: 6| Step: 2
Training loss: 4.52566385269165
Validation loss: 5.09626236782279

Epoch: 6| Step: 3
Training loss: 4.359365463256836
Validation loss: 5.071960603037188

Epoch: 6| Step: 4
Training loss: 6.694247722625732
Validation loss: 5.046353524731051

Epoch: 6| Step: 5
Training loss: 4.326328754425049
Validation loss: 5.015597743372763

Epoch: 6| Step: 6
Training loss: 4.061681747436523
Validation loss: 4.9814273618882705

Epoch: 6| Step: 7
Training loss: 4.697494029998779
Validation loss: 4.942438710120417

Epoch: 6| Step: 8
Training loss: 5.092329978942871
Validation loss: 4.89788495340655

Epoch: 6| Step: 9
Training loss: 5.025724411010742
Validation loss: 4.849159963669315

Epoch: 6| Step: 10
Training loss: 3.9270639419555664
Validation loss: 4.795321895230201

Epoch: 6| Step: 11
Training loss: 4.576525688171387
Validation loss: 4.735288266212709

Epoch: 6| Step: 12
Training loss: 2.7708487510681152
Validation loss: 4.672290061109809

Epoch: 6| Step: 13
Training loss: 5.184597969055176
Validation loss: 4.604293843751313

Epoch: 2| Step: 0
Training loss: 5.712935447692871
Validation loss: 4.534607259176111

Epoch: 6| Step: 1
Training loss: 5.0137200355529785
Validation loss: 4.461408738167055

Epoch: 6| Step: 2
Training loss: 4.023714065551758
Validation loss: 4.387672009006623

Epoch: 6| Step: 3
Training loss: 3.5788016319274902
Validation loss: 4.314555419388638

Epoch: 6| Step: 4
Training loss: 3.348280429840088
Validation loss: 4.243938938263924

Epoch: 6| Step: 5
Training loss: 2.384995937347412
Validation loss: 4.175359238860428

Epoch: 6| Step: 6
Training loss: 5.027548313140869
Validation loss: 4.113388917779409

Epoch: 6| Step: 7
Training loss: 3.467813491821289
Validation loss: 4.048703683319912

Epoch: 6| Step: 8
Training loss: 4.320794582366943
Validation loss: 3.990705192729991

Epoch: 6| Step: 9
Training loss: 4.287188529968262
Validation loss: 3.9396237506661365

Epoch: 6| Step: 10
Training loss: 3.4434006214141846
Validation loss: 3.8925290364091114

Epoch: 6| Step: 11
Training loss: 3.3668792247772217
Validation loss: 3.845007881041496

Epoch: 6| Step: 12
Training loss: 3.4232215881347656
Validation loss: 3.8038799378179733

Epoch: 6| Step: 13
Training loss: 4.00497579574585
Validation loss: 3.7644499194237495

Epoch: 3| Step: 0
Training loss: 3.4066667556762695
Validation loss: 3.7301428138568835

Epoch: 6| Step: 1
Training loss: 2.500889778137207
Validation loss: 3.6978567031122025

Epoch: 6| Step: 2
Training loss: 3.696660041809082
Validation loss: 3.6716843779369066

Epoch: 6| Step: 3
Training loss: 3.695300817489624
Validation loss: 3.648210005093646

Epoch: 6| Step: 4
Training loss: 3.1232025623321533
Validation loss: 3.621974596413233

Epoch: 6| Step: 5
Training loss: 3.861107349395752
Validation loss: 3.5986444129738757

Epoch: 6| Step: 6
Training loss: 3.234779119491577
Validation loss: 3.5772127925708728

Epoch: 6| Step: 7
Training loss: 3.17826509475708
Validation loss: 3.5557985715968634

Epoch: 6| Step: 8
Training loss: 4.270808219909668
Validation loss: 3.537243704642019

Epoch: 6| Step: 9
Training loss: 3.9062294960021973
Validation loss: 3.511058489481608

Epoch: 6| Step: 10
Training loss: 3.7584481239318848
Validation loss: 3.48370167773257

Epoch: 6| Step: 11
Training loss: 2.34444260597229
Validation loss: 3.4582875313297397

Epoch: 6| Step: 12
Training loss: 4.462884902954102
Validation loss: 3.4403686061982186

Epoch: 6| Step: 13
Training loss: 3.19604754447937
Validation loss: 3.4189027150472007

Epoch: 4| Step: 0
Training loss: 3.7751216888427734
Validation loss: 3.4016059034614154

Epoch: 6| Step: 1
Training loss: 3.346954822540283
Validation loss: 3.384488103210285

Epoch: 6| Step: 2
Training loss: 2.1634812355041504
Validation loss: 3.3647762908730456

Epoch: 6| Step: 3
Training loss: 4.104128360748291
Validation loss: 3.344177640894408

Epoch: 6| Step: 4
Training loss: 3.300908088684082
Validation loss: 3.328909038215555

Epoch: 6| Step: 5
Training loss: 3.385103702545166
Validation loss: 3.325460136577647

Epoch: 6| Step: 6
Training loss: 3.8199522495269775
Validation loss: 3.300069785887195

Epoch: 6| Step: 7
Training loss: 4.339018821716309
Validation loss: 3.285127870498165

Epoch: 6| Step: 8
Training loss: 3.0440516471862793
Validation loss: 3.2758109236276276

Epoch: 6| Step: 9
Training loss: 2.138050079345703
Validation loss: 3.261612481968377

Epoch: 6| Step: 10
Training loss: 2.1874327659606934
Validation loss: 3.247566843545565

Epoch: 6| Step: 11
Training loss: 3.646705389022827
Validation loss: 3.23624825221236

Epoch: 6| Step: 12
Training loss: 3.206354856491089
Validation loss: 3.2250822026242494

Epoch: 6| Step: 13
Training loss: 3.550816774368286
Validation loss: 3.2197902305151826

Epoch: 5| Step: 0
Training loss: 3.237471103668213
Validation loss: 3.2081314543242097

Epoch: 6| Step: 1
Training loss: 2.6590728759765625
Validation loss: 3.1932037184315343

Epoch: 6| Step: 2
Training loss: 3.4281272888183594
Validation loss: 3.178171391128212

Epoch: 6| Step: 3
Training loss: 3.775463104248047
Validation loss: 3.16925488492494

Epoch: 6| Step: 4
Training loss: 3.9380247592926025
Validation loss: 3.1518610728684293

Epoch: 6| Step: 5
Training loss: 2.731685161590576
Validation loss: 3.13249473674323

Epoch: 6| Step: 6
Training loss: 3.162580966949463
Validation loss: 3.1178775756589827

Epoch: 6| Step: 7
Training loss: 3.7431912422180176
Validation loss: 3.103004494021016

Epoch: 6| Step: 8
Training loss: 2.547750473022461
Validation loss: 3.0975875880128596

Epoch: 6| Step: 9
Training loss: 2.899158239364624
Validation loss: 3.0834432494255806

Epoch: 6| Step: 10
Training loss: 2.7191741466522217
Validation loss: 3.112071660257155

Epoch: 6| Step: 11
Training loss: 2.764901638031006
Validation loss: 3.0642259608032885

Epoch: 6| Step: 12
Training loss: 2.8512001037597656
Validation loss: 3.1087444597674954

Epoch: 6| Step: 13
Training loss: 3.8786723613739014
Validation loss: 3.052178223927816

Epoch: 6| Step: 0
Training loss: 2.8453493118286133
Validation loss: 3.0815030579925864

Epoch: 6| Step: 1
Training loss: 3.1550567150115967
Validation loss: 3.1866700495443037

Epoch: 6| Step: 2
Training loss: 2.8195807933807373
Validation loss: 3.142365583809473

Epoch: 6| Step: 3
Training loss: 3.4160172939300537
Validation loss: 3.0727006799431256

Epoch: 6| Step: 4
Training loss: 3.099843978881836
Validation loss: 3.0545467945837204

Epoch: 6| Step: 5
Training loss: 2.9729743003845215
Validation loss: 3.0386217512110227

Epoch: 6| Step: 6
Training loss: 2.3552794456481934
Validation loss: 3.022657532845774

Epoch: 6| Step: 7
Training loss: 2.882780075073242
Validation loss: 3.0138271136950423

Epoch: 6| Step: 8
Training loss: 2.5792603492736816
Validation loss: 3.0352088764149654

Epoch: 6| Step: 9
Training loss: 3.539323568344116
Validation loss: 2.9970735785781697

Epoch: 6| Step: 10
Training loss: 3.2072672843933105
Validation loss: 2.984497977841285

Epoch: 6| Step: 11
Training loss: 2.9094078540802
Validation loss: 2.983012996694093

Epoch: 6| Step: 12
Training loss: 3.7593750953674316
Validation loss: 2.978985132709626

Epoch: 6| Step: 13
Training loss: 4.001758098602295
Validation loss: 2.97353220242326

Epoch: 7| Step: 0
Training loss: 2.9441685676574707
Validation loss: 2.9636880582378757

Epoch: 6| Step: 1
Training loss: 2.3827128410339355
Validation loss: 2.949862200726745

Epoch: 6| Step: 2
Training loss: 3.1823437213897705
Validation loss: 2.938473019548642

Epoch: 6| Step: 3
Training loss: 2.4718122482299805
Validation loss: 2.9305559871017293

Epoch: 6| Step: 4
Training loss: 2.826585292816162
Validation loss: 2.92459810421031

Epoch: 6| Step: 5
Training loss: 3.6510009765625
Validation loss: 2.9200432813295754

Epoch: 6| Step: 6
Training loss: 2.253237724304199
Validation loss: 2.9162437556892313

Epoch: 6| Step: 7
Training loss: 2.845909595489502
Validation loss: 2.90990049095564

Epoch: 6| Step: 8
Training loss: 3.082253932952881
Validation loss: 2.8996465154873428

Epoch: 6| Step: 9
Training loss: 3.7858657836914062
Validation loss: 2.9037848595649964

Epoch: 6| Step: 10
Training loss: 3.1112422943115234
Validation loss: 2.905288627070765

Epoch: 6| Step: 11
Training loss: 3.332968235015869
Validation loss: 2.878001438674106

Epoch: 6| Step: 12
Training loss: 3.129131555557251
Validation loss: 2.8675972620646157

Epoch: 6| Step: 13
Training loss: 2.984621286392212
Validation loss: 2.857932970088015

Epoch: 8| Step: 0
Training loss: 2.914348840713501
Validation loss: 2.852820140059276

Epoch: 6| Step: 1
Training loss: 2.3442370891571045
Validation loss: 2.8538443503841275

Epoch: 6| Step: 2
Training loss: 2.227736473083496
Validation loss: 2.8517471282712874

Epoch: 6| Step: 3
Training loss: 2.9423670768737793
Validation loss: 2.844437337690784

Epoch: 6| Step: 4
Training loss: 2.99489688873291
Validation loss: 2.833174149195353

Epoch: 6| Step: 5
Training loss: 2.7706170082092285
Validation loss: 2.825597440042803

Epoch: 6| Step: 6
Training loss: 3.463271379470825
Validation loss: 2.82097722894402

Epoch: 6| Step: 7
Training loss: 2.6974079608917236
Validation loss: 2.814500306242256

Epoch: 6| Step: 8
Training loss: 2.8121378421783447
Validation loss: 2.8191788658019035

Epoch: 6| Step: 9
Training loss: 3.1784777641296387
Validation loss: 2.817041225330804

Epoch: 6| Step: 10
Training loss: 3.1420791149139404
Validation loss: 2.8169185551263953

Epoch: 6| Step: 11
Training loss: 2.7552103996276855
Validation loss: 2.7996045517665085

Epoch: 6| Step: 12
Training loss: 3.679985284805298
Validation loss: 2.7872149200849634

Epoch: 6| Step: 13
Training loss: 3.5925800800323486
Validation loss: 2.786731643061484

Epoch: 9| Step: 0
Training loss: 3.166694164276123
Validation loss: 2.786504989029259

Epoch: 6| Step: 1
Training loss: 3.759822130203247
Validation loss: 2.77717839517901

Epoch: 6| Step: 2
Training loss: 3.5019023418426514
Validation loss: 2.77277285052884

Epoch: 6| Step: 3
Training loss: 2.155614137649536
Validation loss: 2.771015972219488

Epoch: 6| Step: 4
Training loss: 2.0905752182006836
Validation loss: 2.764422619214622

Epoch: 6| Step: 5
Training loss: 3.339660882949829
Validation loss: 2.75926366929085

Epoch: 6| Step: 6
Training loss: 2.61968731880188
Validation loss: 2.7485083636417182

Epoch: 6| Step: 7
Training loss: 2.9893808364868164
Validation loss: 2.744568578658565

Epoch: 6| Step: 8
Training loss: 3.0742859840393066
Validation loss: 2.7452238452049995

Epoch: 6| Step: 9
Training loss: 1.9694963693618774
Validation loss: 2.7375188719841743

Epoch: 6| Step: 10
Training loss: 3.0608038902282715
Validation loss: 2.738053312865637

Epoch: 6| Step: 11
Training loss: 2.9129600524902344
Validation loss: 2.7228650995480117

Epoch: 6| Step: 12
Training loss: 2.7726821899414062
Validation loss: 2.7223146577035227

Epoch: 6| Step: 13
Training loss: 3.4901230335235596
Validation loss: 2.722396466039842

Epoch: 10| Step: 0
Training loss: 3.3777031898498535
Validation loss: 2.7234860440736175

Epoch: 6| Step: 1
Training loss: 3.0984387397766113
Validation loss: 2.7180768648783364

Epoch: 6| Step: 2
Training loss: 3.234508991241455
Validation loss: 2.7119567599347842

Epoch: 6| Step: 3
Training loss: 2.505943536758423
Validation loss: 2.7052204121825514

Epoch: 6| Step: 4
Training loss: 3.175966501235962
Validation loss: 2.699237446631155

Epoch: 6| Step: 5
Training loss: 2.7191858291625977
Validation loss: 2.6977250755474134

Epoch: 6| Step: 6
Training loss: 1.6876518726348877
Validation loss: 2.6922958845733316

Epoch: 6| Step: 7
Training loss: 3.3354263305664062
Validation loss: 2.688774985651816

Epoch: 6| Step: 8
Training loss: 3.4006757736206055
Validation loss: 2.6871456074458298

Epoch: 6| Step: 9
Training loss: 2.7025766372680664
Validation loss: 2.6856308137216875

Epoch: 6| Step: 10
Training loss: 2.5142641067504883
Validation loss: 2.704146441592965

Epoch: 6| Step: 11
Training loss: 2.814807176589966
Validation loss: 2.6751106887735348

Epoch: 6| Step: 12
Training loss: 2.621800184249878
Validation loss: 2.693756011224562

Epoch: 6| Step: 13
Training loss: 3.022707939147949
Validation loss: 2.721017583723991

Epoch: 11| Step: 0
Training loss: 3.4428458213806152
Validation loss: 2.7204678289351927

Epoch: 6| Step: 1
Training loss: 3.5118021965026855
Validation loss: 2.6836321148821103

Epoch: 6| Step: 2
Training loss: 2.8262929916381836
Validation loss: 2.67689468783717

Epoch: 6| Step: 3
Training loss: 2.719144821166992
Validation loss: 2.7280039889838106

Epoch: 6| Step: 4
Training loss: 2.595582962036133
Validation loss: 2.780579241373206

Epoch: 6| Step: 5
Training loss: 2.7328736782073975
Validation loss: 2.7719668008947886

Epoch: 6| Step: 6
Training loss: 2.425368547439575
Validation loss: 2.7355679670969644

Epoch: 6| Step: 7
Training loss: 3.2471964359283447
Validation loss: 2.7147754392316266

Epoch: 6| Step: 8
Training loss: 2.887685775756836
Validation loss: 2.6934239043984363

Epoch: 6| Step: 9
Training loss: 2.5326027870178223
Validation loss: 2.6802411669044086

Epoch: 6| Step: 10
Training loss: 2.9308383464813232
Validation loss: 2.6780303985841813

Epoch: 6| Step: 11
Training loss: 2.9341328144073486
Validation loss: 2.6795543470690326

Epoch: 6| Step: 12
Training loss: 2.8250529766082764
Validation loss: 2.681737825434695

Epoch: 6| Step: 13
Training loss: 2.4065568447113037
Validation loss: 2.682069747678695

Epoch: 12| Step: 0
Training loss: 2.2933201789855957
Validation loss: 2.6743385714869343

Epoch: 6| Step: 1
Training loss: 2.4297592639923096
Validation loss: 2.6706335442040556

Epoch: 6| Step: 2
Training loss: 2.2394495010375977
Validation loss: 2.6640400476353143

Epoch: 6| Step: 3
Training loss: 2.600355625152588
Validation loss: 2.652875333703974

Epoch: 6| Step: 4
Training loss: 3.2082247734069824
Validation loss: 2.646985971799461

Epoch: 6| Step: 5
Training loss: 2.969789505004883
Validation loss: 2.6379739981825634

Epoch: 6| Step: 6
Training loss: 3.4470345973968506
Validation loss: 2.6326223650286273

Epoch: 6| Step: 7
Training loss: 2.2146246433258057
Validation loss: 2.6292578917677685

Epoch: 6| Step: 8
Training loss: 2.491241931915283
Validation loss: 2.6310251810217418

Epoch: 6| Step: 9
Training loss: 3.290531635284424
Validation loss: 2.6447123045562417

Epoch: 6| Step: 10
Training loss: 3.23586368560791
Validation loss: 2.64046795393831

Epoch: 6| Step: 11
Training loss: 3.290477752685547
Validation loss: 2.642587060569435

Epoch: 6| Step: 12
Training loss: 3.14936900138855
Validation loss: 2.634134823276151

Epoch: 6| Step: 13
Training loss: 2.739443063735962
Validation loss: 2.6276256833025204

Epoch: 13| Step: 0
Training loss: 2.8292269706726074
Validation loss: 2.6183445351098174

Epoch: 6| Step: 1
Training loss: 3.9819588661193848
Validation loss: 2.6092111320905786

Epoch: 6| Step: 2
Training loss: 2.9582457542419434
Validation loss: 2.5987131262338288

Epoch: 6| Step: 3
Training loss: 2.388732433319092
Validation loss: 2.59810378730938

Epoch: 6| Step: 4
Training loss: 2.9627602100372314
Validation loss: 2.595086592499928

Epoch: 6| Step: 5
Training loss: 2.887570858001709
Validation loss: 2.5966324344758065

Epoch: 6| Step: 6
Training loss: 3.1868419647216797
Validation loss: 2.604172340003393

Epoch: 6| Step: 7
Training loss: 2.9584341049194336
Validation loss: 2.628775527400355

Epoch: 6| Step: 8
Training loss: 2.719681978225708
Validation loss: 2.608634989748719

Epoch: 6| Step: 9
Training loss: 1.947731852531433
Validation loss: 2.578533790444815

Epoch: 6| Step: 10
Training loss: 2.295212984085083
Validation loss: 2.570779541487335

Epoch: 6| Step: 11
Training loss: 2.5383760929107666
Validation loss: 2.5663890351531324

Epoch: 6| Step: 12
Training loss: 2.613247871398926
Validation loss: 2.56381578599253

Epoch: 6| Step: 13
Training loss: 3.0690572261810303
Validation loss: 2.5699697130469867

Epoch: 14| Step: 0
Training loss: 2.5169613361358643
Validation loss: 2.5714075539701726

Epoch: 6| Step: 1
Training loss: 2.7915236949920654
Validation loss: 2.5731604381274154

Epoch: 6| Step: 2
Training loss: 2.897899627685547
Validation loss: 2.563209907982939

Epoch: 6| Step: 3
Training loss: 3.1731653213500977
Validation loss: 2.5588117978906118

Epoch: 6| Step: 4
Training loss: 2.8910224437713623
Validation loss: 2.565442003229613

Epoch: 6| Step: 5
Training loss: 1.990020751953125
Validation loss: 2.5552694182242117

Epoch: 6| Step: 6
Training loss: 2.7925729751586914
Validation loss: 2.5651926097049507

Epoch: 6| Step: 7
Training loss: 2.773679494857788
Validation loss: 2.5467110936359694

Epoch: 6| Step: 8
Training loss: 3.4281997680664062
Validation loss: 2.5474462509155273

Epoch: 6| Step: 9
Training loss: 2.4797475337982178
Validation loss: 2.550023014827441

Epoch: 6| Step: 10
Training loss: 3.3103489875793457
Validation loss: 2.5471849620983167

Epoch: 6| Step: 11
Training loss: 2.5823159217834473
Validation loss: 2.546989015353623

Epoch: 6| Step: 12
Training loss: 2.5916800498962402
Validation loss: 2.5472826752611386

Epoch: 6| Step: 13
Training loss: 2.4523086547851562
Validation loss: 2.5439266850871425

Epoch: 15| Step: 0
Training loss: 2.550114870071411
Validation loss: 2.5453716811313423

Epoch: 6| Step: 1
Training loss: 3.1714859008789062
Validation loss: 2.5430895154194166

Epoch: 6| Step: 2
Training loss: 2.527318000793457
Validation loss: 2.5388113170541744

Epoch: 6| Step: 3
Training loss: 2.76138973236084
Validation loss: 2.5370193937773347

Epoch: 6| Step: 4
Training loss: 2.3496437072753906
Validation loss: 2.576057964755643

Epoch: 6| Step: 5
Training loss: 1.8929784297943115
Validation loss: 2.540102151132399

Epoch: 6| Step: 6
Training loss: 2.926424980163574
Validation loss: 2.531126750412808

Epoch: 6| Step: 7
Training loss: 3.120570182800293
Validation loss: 2.5323475945380425

Epoch: 6| Step: 8
Training loss: 2.7016775608062744
Validation loss: 2.5329122158788864

Epoch: 6| Step: 9
Training loss: 3.0442841053009033
Validation loss: 2.5306954973487445

Epoch: 6| Step: 10
Training loss: 2.4289379119873047
Validation loss: 2.525064335074476

Epoch: 6| Step: 11
Training loss: 2.5671801567077637
Validation loss: 2.5222728354956514

Epoch: 6| Step: 12
Training loss: 3.306384325027466
Validation loss: 2.5217591485669537

Epoch: 6| Step: 13
Training loss: 3.9293293952941895
Validation loss: 2.5213062545304656

Epoch: 16| Step: 0
Training loss: 2.489964485168457
Validation loss: 2.520280043284098

Epoch: 6| Step: 1
Training loss: 2.534961223602295
Validation loss: 2.516269350564608

Epoch: 6| Step: 2
Training loss: 3.490238904953003
Validation loss: 2.5269367720491145

Epoch: 6| Step: 3
Training loss: 2.485241413116455
Validation loss: 2.522548790900938

Epoch: 6| Step: 4
Training loss: 2.8125033378601074
Validation loss: 2.520114673081265

Epoch: 6| Step: 5
Training loss: 2.528632879257202
Validation loss: 2.519900257869433

Epoch: 6| Step: 6
Training loss: 2.8078041076660156
Validation loss: 2.515197092486966

Epoch: 6| Step: 7
Training loss: 2.827258586883545
Validation loss: 2.511917560331283

Epoch: 6| Step: 8
Training loss: 3.247298240661621
Validation loss: 2.51401872275978

Epoch: 6| Step: 9
Training loss: 3.771596908569336
Validation loss: 2.531221587170837

Epoch: 6| Step: 10
Training loss: 2.6701390743255615
Validation loss: 2.5121031345859652

Epoch: 6| Step: 11
Training loss: 2.120758056640625
Validation loss: 2.5133665736003588

Epoch: 6| Step: 12
Training loss: 2.215467929840088
Validation loss: 2.509967029735606

Epoch: 6| Step: 13
Training loss: 2.2267138957977295
Validation loss: 2.517351876022995

Epoch: 17| Step: 0
Training loss: 3.71000599861145
Validation loss: 2.5364828519923712

Epoch: 6| Step: 1
Training loss: 1.9558055400848389
Validation loss: 2.514640777341781

Epoch: 6| Step: 2
Training loss: 3.156416893005371
Validation loss: 2.508530086086642

Epoch: 6| Step: 3
Training loss: 3.349275827407837
Validation loss: 2.5037101571277907

Epoch: 6| Step: 4
Training loss: 2.3190107345581055
Validation loss: 2.503207383617278

Epoch: 6| Step: 5
Training loss: 2.281680107116699
Validation loss: 2.5050652616767475

Epoch: 6| Step: 6
Training loss: 2.9732275009155273
Validation loss: 2.5107905941624797

Epoch: 6| Step: 7
Training loss: 2.3149242401123047
Validation loss: 2.524973274559103

Epoch: 6| Step: 8
Training loss: 3.112117052078247
Validation loss: 2.539010186349192

Epoch: 6| Step: 9
Training loss: 2.6772913932800293
Validation loss: 2.5268930286489506

Epoch: 6| Step: 10
Training loss: 2.632171154022217
Validation loss: 2.5125511743689097

Epoch: 6| Step: 11
Training loss: 2.582390308380127
Validation loss: 2.5006333679281254

Epoch: 6| Step: 12
Training loss: 2.901890277862549
Validation loss: 2.4991038896704234

Epoch: 6| Step: 13
Training loss: 2.2633063793182373
Validation loss: 2.496014182285596

Epoch: 18| Step: 0
Training loss: 3.706218719482422
Validation loss: 2.5119514542241252

Epoch: 6| Step: 1
Training loss: 2.802079916000366
Validation loss: 2.512062313736126

Epoch: 6| Step: 2
Training loss: 2.550355911254883
Validation loss: 2.5193708173690306

Epoch: 6| Step: 3
Training loss: 2.9703633785247803
Validation loss: 2.561112706379224

Epoch: 6| Step: 4
Training loss: 2.7636733055114746
Validation loss: 2.5185048503260457

Epoch: 6| Step: 5
Training loss: 2.3891589641571045
Validation loss: 2.5267299016316733

Epoch: 6| Step: 6
Training loss: 3.23740553855896
Validation loss: 2.5402853232558056

Epoch: 6| Step: 7
Training loss: 2.4958181381225586
Validation loss: 2.53679229879892

Epoch: 6| Step: 8
Training loss: 2.8293464183807373
Validation loss: 2.562711400370444

Epoch: 6| Step: 9
Training loss: 2.310952663421631
Validation loss: 2.5988647604501374

Epoch: 6| Step: 10
Training loss: 3.2073097229003906
Validation loss: 2.5953891969496206

Epoch: 6| Step: 11
Training loss: 2.50395131111145
Validation loss: 2.5925544308077906

Epoch: 6| Step: 12
Training loss: 2.3078560829162598
Validation loss: 2.5813750220883276

Epoch: 6| Step: 13
Training loss: 2.4115777015686035
Validation loss: 2.5682605466535016

Epoch: 19| Step: 0
Training loss: 2.7407429218292236
Validation loss: 2.53810211407241

Epoch: 6| Step: 1
Training loss: 2.976815700531006
Validation loss: 2.5261814722450833

Epoch: 6| Step: 2
Training loss: 2.4992594718933105
Validation loss: 2.5126287655163835

Epoch: 6| Step: 3
Training loss: 2.083716869354248
Validation loss: 2.5052408120965444

Epoch: 6| Step: 4
Training loss: 3.43499755859375
Validation loss: 2.4992961460544216

Epoch: 6| Step: 5
Training loss: 3.1348936557769775
Validation loss: 2.4884585693318355

Epoch: 6| Step: 6
Training loss: 2.6016602516174316
Validation loss: 2.5190551896249094

Epoch: 6| Step: 7
Training loss: 1.786527156829834
Validation loss: 2.6039126047524075

Epoch: 6| Step: 8
Training loss: 3.402209520339966
Validation loss: 2.665520168119861

Epoch: 6| Step: 9
Training loss: 2.5689315795898438
Validation loss: 2.6795585719488

Epoch: 6| Step: 10
Training loss: 3.34285306930542
Validation loss: 2.647155718136859

Epoch: 6| Step: 11
Training loss: 2.769251823425293
Validation loss: 2.6363909449628604

Epoch: 6| Step: 12
Training loss: 2.8532209396362305
Validation loss: 2.6043554275266585

Epoch: 6| Step: 13
Training loss: 2.783924102783203
Validation loss: 2.5802204044916297

Epoch: 20| Step: 0
Training loss: 2.080852508544922
Validation loss: 2.5578748487657115

Epoch: 6| Step: 1
Training loss: 2.6603667736053467
Validation loss: 2.554871141269643

Epoch: 6| Step: 2
Training loss: 2.291853427886963
Validation loss: 2.5517848101995324

Epoch: 6| Step: 3
Training loss: 2.7225699424743652
Validation loss: 2.5427424548774638

Epoch: 6| Step: 4
Training loss: 1.9340648651123047
Validation loss: 2.5667200037228164

Epoch: 6| Step: 5
Training loss: 2.4302868843078613
Validation loss: 2.5678509460982455

Epoch: 6| Step: 6
Training loss: 2.941525936126709
Validation loss: 2.5166112299888366

Epoch: 6| Step: 7
Training loss: 1.7945257425308228
Validation loss: 2.502818215277887

Epoch: 6| Step: 8
Training loss: 3.217878580093384
Validation loss: 2.5000023534221034

Epoch: 6| Step: 9
Training loss: 3.7293176651000977
Validation loss: 2.5004708126027095

Epoch: 6| Step: 10
Training loss: 3.2807929515838623
Validation loss: 2.4973514297957062

Epoch: 6| Step: 11
Training loss: 3.145293951034546
Validation loss: 2.517166668368924

Epoch: 6| Step: 12
Training loss: 2.9071884155273438
Validation loss: 2.5412152915872555

Epoch: 6| Step: 13
Training loss: 3.6636548042297363
Validation loss: 2.4866473367137294

Epoch: 21| Step: 0
Training loss: 2.649109125137329
Validation loss: 2.4639571764135875

Epoch: 6| Step: 1
Training loss: 2.255025625228882
Validation loss: 2.4612596560549993

Epoch: 6| Step: 2
Training loss: 3.1825945377349854
Validation loss: 2.4695953861359627

Epoch: 6| Step: 3
Training loss: 2.5523667335510254
Validation loss: 2.481705081078314

Epoch: 6| Step: 4
Training loss: 2.5520448684692383
Validation loss: 2.4897523567240727

Epoch: 6| Step: 5
Training loss: 2.502345323562622
Validation loss: 2.473571785034672

Epoch: 6| Step: 6
Training loss: 3.059361219406128
Validation loss: 2.4680850095646356

Epoch: 6| Step: 7
Training loss: 3.327258586883545
Validation loss: 2.4762167110238025

Epoch: 6| Step: 8
Training loss: 2.433746576309204
Validation loss: 2.4744049272229596

Epoch: 6| Step: 9
Training loss: 2.481851577758789
Validation loss: 2.4744850563746628

Epoch: 6| Step: 10
Training loss: 2.52482271194458
Validation loss: 2.480388943867017

Epoch: 6| Step: 11
Training loss: 2.066953659057617
Validation loss: 2.489532273302796

Epoch: 6| Step: 12
Training loss: 3.2888379096984863
Validation loss: 2.4911160904874086

Epoch: 6| Step: 13
Training loss: 3.261763572692871
Validation loss: 2.490076172736383

Epoch: 22| Step: 0
Training loss: 2.8972840309143066
Validation loss: 2.4456395590177147

Epoch: 6| Step: 1
Training loss: 2.134319305419922
Validation loss: 2.4427029971153504

Epoch: 6| Step: 2
Training loss: 2.1927566528320312
Validation loss: 2.4393523841775875

Epoch: 6| Step: 3
Training loss: 2.5216917991638184
Validation loss: 2.4628138542175293

Epoch: 6| Step: 4
Training loss: 2.758071184158325
Validation loss: 2.4856568049359065

Epoch: 6| Step: 5
Training loss: 3.159118890762329
Validation loss: 2.5059550603230796

Epoch: 6| Step: 6
Training loss: 3.1487765312194824
Validation loss: 2.4842118806736444

Epoch: 6| Step: 7
Training loss: 2.9185149669647217
Validation loss: 2.4414014354828866

Epoch: 6| Step: 8
Training loss: 2.492610454559326
Validation loss: 2.433934057912519

Epoch: 6| Step: 9
Training loss: 2.651120901107788
Validation loss: 2.4300852796082855

Epoch: 6| Step: 10
Training loss: 2.904688835144043
Validation loss: 2.429328255755927

Epoch: 6| Step: 11
Training loss: 2.6521759033203125
Validation loss: 2.43127506009994

Epoch: 6| Step: 12
Training loss: 2.6839823722839355
Validation loss: 2.4535068286362516

Epoch: 6| Step: 13
Training loss: 2.515232801437378
Validation loss: 2.452984167683509

Epoch: 23| Step: 0
Training loss: 2.5455403327941895
Validation loss: 2.442714445052608

Epoch: 6| Step: 1
Training loss: 2.1413156986236572
Validation loss: 2.434379898091798

Epoch: 6| Step: 2
Training loss: 3.6225850582122803
Validation loss: 2.442435400460356

Epoch: 6| Step: 3
Training loss: 2.8199760913848877
Validation loss: 2.4412932267753025

Epoch: 6| Step: 4
Training loss: 2.1646690368652344
Validation loss: 2.4674328450233705

Epoch: 6| Step: 5
Training loss: 2.7324671745300293
Validation loss: 2.4664544469566754

Epoch: 6| Step: 6
Training loss: 2.6891939640045166
Validation loss: 2.473695444804366

Epoch: 6| Step: 7
Training loss: 3.001600742340088
Validation loss: 2.510825293038481

Epoch: 6| Step: 8
Training loss: 2.643831729888916
Validation loss: 2.4844019387357976

Epoch: 6| Step: 9
Training loss: 2.791274070739746
Validation loss: 2.4648103252533944

Epoch: 6| Step: 10
Training loss: 2.899898052215576
Validation loss: 2.4614176058000132

Epoch: 6| Step: 11
Training loss: 2.7965810298919678
Validation loss: 2.4659706033686155

Epoch: 6| Step: 12
Training loss: 2.3051035404205322
Validation loss: 2.4508690885318223

Epoch: 6| Step: 13
Training loss: 2.2660720348358154
Validation loss: 2.453190424109018

Epoch: 24| Step: 0
Training loss: 2.4701790809631348
Validation loss: 2.451444628418133

Epoch: 6| Step: 1
Training loss: 2.553067922592163
Validation loss: 2.4456178039632817

Epoch: 6| Step: 2
Training loss: 3.172262668609619
Validation loss: 2.447948609628985

Epoch: 6| Step: 3
Training loss: 1.704892635345459
Validation loss: 2.4507435752499487

Epoch: 6| Step: 4
Training loss: 2.6360270977020264
Validation loss: 2.437290378796157

Epoch: 6| Step: 5
Training loss: 2.9324655532836914
Validation loss: 2.430346360770605

Epoch: 6| Step: 6
Training loss: 2.8715391159057617
Validation loss: 2.4312736065157

Epoch: 6| Step: 7
Training loss: 2.91804838180542
Validation loss: 2.44656027260647

Epoch: 6| Step: 8
Training loss: 2.581242084503174
Validation loss: 2.4367602204763763

Epoch: 6| Step: 9
Training loss: 2.6073732376098633
Validation loss: 2.425405416437375

Epoch: 6| Step: 10
Training loss: 2.7248587608337402
Validation loss: 2.4261488555580057

Epoch: 6| Step: 11
Training loss: 3.3153157234191895
Validation loss: 2.424574521280104

Epoch: 6| Step: 12
Training loss: 2.456617593765259
Validation loss: 2.4274490853791595

Epoch: 6| Step: 13
Training loss: 2.097141742706299
Validation loss: 2.4597142101615987

Epoch: 25| Step: 0
Training loss: 2.4260950088500977
Validation loss: 2.438479500432168

Epoch: 6| Step: 1
Training loss: 2.16339111328125
Validation loss: 2.4184701852901007

Epoch: 6| Step: 2
Training loss: 3.603379726409912
Validation loss: 2.4145671629136607

Epoch: 6| Step: 3
Training loss: 2.840254306793213
Validation loss: 2.400951562389251

Epoch: 6| Step: 4
Training loss: 2.2174015045166016
Validation loss: 2.403034364023516

Epoch: 6| Step: 5
Training loss: 2.477118492126465
Validation loss: 2.403715241339899

Epoch: 6| Step: 6
Training loss: 3.0919086933135986
Validation loss: 2.400691822010984

Epoch: 6| Step: 7
Training loss: 2.1571059226989746
Validation loss: 2.4046640755027853

Epoch: 6| Step: 8
Training loss: 2.681706190109253
Validation loss: 2.4139059077027025

Epoch: 6| Step: 9
Training loss: 2.7691893577575684
Validation loss: 2.422157831089471

Epoch: 6| Step: 10
Training loss: 2.6085829734802246
Validation loss: 2.419884943193005

Epoch: 6| Step: 11
Training loss: 3.015867233276367
Validation loss: 2.412653141124274

Epoch: 6| Step: 12
Training loss: 2.7430758476257324
Validation loss: 2.4049196743196055

Epoch: 6| Step: 13
Training loss: 2.182267665863037
Validation loss: 2.4137658252510974

Epoch: 26| Step: 0
Training loss: 2.7133309841156006
Validation loss: 2.4133887624227874

Epoch: 6| Step: 1
Training loss: 2.8032264709472656
Validation loss: 2.403812393065422

Epoch: 6| Step: 2
Training loss: 2.3920493125915527
Validation loss: 2.395164321827632

Epoch: 6| Step: 3
Training loss: 2.261063814163208
Validation loss: 2.3942808310190835

Epoch: 6| Step: 4
Training loss: 2.464662551879883
Validation loss: 2.3910145580127673

Epoch: 6| Step: 5
Training loss: 2.608438491821289
Validation loss: 2.388837727167273

Epoch: 6| Step: 6
Training loss: 3.60037899017334
Validation loss: 2.387897999055924

Epoch: 6| Step: 7
Training loss: 2.6185860633850098
Validation loss: 2.386710105403777

Epoch: 6| Step: 8
Training loss: 2.235527515411377
Validation loss: 2.3888684600912113

Epoch: 6| Step: 9
Training loss: 2.4693644046783447
Validation loss: 2.4049761500409854

Epoch: 6| Step: 10
Training loss: 2.061619997024536
Validation loss: 2.4047589327699397

Epoch: 6| Step: 11
Training loss: 2.7576677799224854
Validation loss: 2.4023753955800045

Epoch: 6| Step: 12
Training loss: 3.155970811843872
Validation loss: 2.411956553818077

Epoch: 6| Step: 13
Training loss: 2.9311556816101074
Validation loss: 2.40767381780891

Epoch: 27| Step: 0
Training loss: 2.9184024333953857
Validation loss: 2.4154893659776255

Epoch: 6| Step: 1
Training loss: 2.555553913116455
Validation loss: 2.406739096487722

Epoch: 6| Step: 2
Training loss: 2.3126602172851562
Validation loss: 2.396282280645063

Epoch: 6| Step: 3
Training loss: 3.175739049911499
Validation loss: 2.3966806652725383

Epoch: 6| Step: 4
Training loss: 2.065001964569092
Validation loss: 2.396629674460298

Epoch: 6| Step: 5
Training loss: 2.536677837371826
Validation loss: 2.3979856352652273

Epoch: 6| Step: 6
Training loss: 2.557086944580078
Validation loss: 2.3935412412048667

Epoch: 6| Step: 7
Training loss: 3.525174617767334
Validation loss: 2.3850728414391957

Epoch: 6| Step: 8
Training loss: 2.1793417930603027
Validation loss: 2.3859706899171234

Epoch: 6| Step: 9
Training loss: 2.5794057846069336
Validation loss: 2.3823373676628194

Epoch: 6| Step: 10
Training loss: 3.1939761638641357
Validation loss: 2.3744549212917203

Epoch: 6| Step: 11
Training loss: 1.8399269580841064
Validation loss: 2.3757327782210482

Epoch: 6| Step: 12
Training loss: 3.020859718322754
Validation loss: 2.3764837121450775

Epoch: 6| Step: 13
Training loss: 2.5524091720581055
Validation loss: 2.386375327264109

Epoch: 28| Step: 0
Training loss: 2.7609970569610596
Validation loss: 2.4126463526038715

Epoch: 6| Step: 1
Training loss: 2.841665267944336
Validation loss: 2.427170438151206

Epoch: 6| Step: 2
Training loss: 2.419581413269043
Validation loss: 2.4177288188729236

Epoch: 6| Step: 3
Training loss: 2.3259475231170654
Validation loss: 2.4390871063355477

Epoch: 6| Step: 4
Training loss: 3.463898181915283
Validation loss: 2.43512967325026

Epoch: 6| Step: 5
Training loss: 3.0076534748077393
Validation loss: 2.4308715148638655

Epoch: 6| Step: 6
Training loss: 2.519890308380127
Validation loss: 2.41212603610049

Epoch: 6| Step: 7
Training loss: 1.5375205278396606
Validation loss: 2.3890133596235708

Epoch: 6| Step: 8
Training loss: 3.0860960483551025
Validation loss: 2.3811471539158977

Epoch: 6| Step: 9
Training loss: 2.9946208000183105
Validation loss: 2.3731118081718363

Epoch: 6| Step: 10
Training loss: 2.2309041023254395
Validation loss: 2.377382747588619

Epoch: 6| Step: 11
Training loss: 3.288644552230835
Validation loss: 2.3838237075395483

Epoch: 6| Step: 12
Training loss: 2.455066204071045
Validation loss: 2.3720101720543316

Epoch: 6| Step: 13
Training loss: 1.6161978244781494
Validation loss: 2.3663045488378054

Epoch: 29| Step: 0
Training loss: 2.6362104415893555
Validation loss: 2.36606526887545

Epoch: 6| Step: 1
Training loss: 3.052607536315918
Validation loss: 2.384691628076697

Epoch: 6| Step: 2
Training loss: 2.550800085067749
Validation loss: 2.4351705299910678

Epoch: 6| Step: 3
Training loss: 3.1117959022521973
Validation loss: 2.449097940998693

Epoch: 6| Step: 4
Training loss: 3.033236265182495
Validation loss: 2.40743839099843

Epoch: 6| Step: 5
Training loss: 2.3828468322753906
Validation loss: 2.3954796662894626

Epoch: 6| Step: 6
Training loss: 1.7973036766052246
Validation loss: 2.378380103777814

Epoch: 6| Step: 7
Training loss: 3.133699417114258
Validation loss: 2.3737231941633326

Epoch: 6| Step: 8
Training loss: 2.386948585510254
Validation loss: 2.368000799609769

Epoch: 6| Step: 9
Training loss: 2.921649694442749
Validation loss: 2.368539376925397

Epoch: 6| Step: 10
Training loss: 2.7240500450134277
Validation loss: 2.370540234350389

Epoch: 6| Step: 11
Training loss: 2.8397507667541504
Validation loss: 2.3682564073993313

Epoch: 6| Step: 12
Training loss: 1.6527085304260254
Validation loss: 2.371395149538594

Epoch: 6| Step: 13
Training loss: 2.633493185043335
Validation loss: 2.377386298230899

Epoch: 30| Step: 0
Training loss: 2.0528180599212646
Validation loss: 2.393946768135153

Epoch: 6| Step: 1
Training loss: 1.641234040260315
Validation loss: 2.4128425685308312

Epoch: 6| Step: 2
Training loss: 2.3100390434265137
Validation loss: 2.418271997923492

Epoch: 6| Step: 3
Training loss: 2.79970645904541
Validation loss: 2.4243751930934128

Epoch: 6| Step: 4
Training loss: 2.1890311241149902
Validation loss: 2.4035654119265977

Epoch: 6| Step: 5
Training loss: 2.4780211448669434
Validation loss: 2.392056175457534

Epoch: 6| Step: 6
Training loss: 2.2573163509368896
Validation loss: 2.3826312403525076

Epoch: 6| Step: 7
Training loss: 3.341728687286377
Validation loss: 2.390121013887467

Epoch: 6| Step: 8
Training loss: 2.7964913845062256
Validation loss: 2.380554332528063

Epoch: 6| Step: 9
Training loss: 3.3075144290924072
Validation loss: 2.37412332206644

Epoch: 6| Step: 10
Training loss: 2.7343544960021973
Validation loss: 2.3613211442065496

Epoch: 6| Step: 11
Training loss: 3.107795238494873
Validation loss: 2.3553851830062045

Epoch: 6| Step: 12
Training loss: 3.2431180477142334
Validation loss: 2.3583261607795634

Epoch: 6| Step: 13
Training loss: 2.360182046890259
Validation loss: 2.351760141311153

Epoch: 31| Step: 0
Training loss: 2.481346845626831
Validation loss: 2.348405791867164

Epoch: 6| Step: 1
Training loss: 3.1223273277282715
Validation loss: 2.3500751859398297

Epoch: 6| Step: 2
Training loss: 2.0428712368011475
Validation loss: 2.351503695211103

Epoch: 6| Step: 3
Training loss: 2.069547176361084
Validation loss: 2.367967679936399

Epoch: 6| Step: 4
Training loss: 3.0630970001220703
Validation loss: 2.4150746765957085

Epoch: 6| Step: 5
Training loss: 2.759309768676758
Validation loss: 2.4472145880422285

Epoch: 6| Step: 6
Training loss: 2.784114360809326
Validation loss: 2.4709725379943848

Epoch: 6| Step: 7
Training loss: 3.10780930519104
Validation loss: 2.479860198113226

Epoch: 6| Step: 8
Training loss: 2.5187439918518066
Validation loss: 2.4370161999938307

Epoch: 6| Step: 9
Training loss: 2.8427271842956543
Validation loss: 2.3686536127521145

Epoch: 6| Step: 10
Training loss: 2.584444522857666
Validation loss: 2.341193934922577

Epoch: 6| Step: 11
Training loss: 2.4974429607391357
Validation loss: 2.3450510501861572

Epoch: 6| Step: 12
Training loss: 2.589712142944336
Validation loss: 2.3695350231662875

Epoch: 6| Step: 13
Training loss: 2.17874813079834
Validation loss: 2.3803411632455806

Epoch: 32| Step: 0
Training loss: 2.8007583618164062
Validation loss: 2.3910604933256745

Epoch: 6| Step: 1
Training loss: 2.9971814155578613
Validation loss: 2.4007160304695048

Epoch: 6| Step: 2
Training loss: 2.424234390258789
Validation loss: 2.3843490282694497

Epoch: 6| Step: 3
Training loss: 3.154827117919922
Validation loss: 2.3599751226363646

Epoch: 6| Step: 4
Training loss: 2.53511381149292
Validation loss: 2.3434407557210615

Epoch: 6| Step: 5
Training loss: 2.45200777053833
Validation loss: 2.340971657024917

Epoch: 6| Step: 6
Training loss: 2.817263126373291
Validation loss: 2.3593416803626606

Epoch: 6| Step: 7
Training loss: 1.9283249378204346
Validation loss: 2.426626536153978

Epoch: 6| Step: 8
Training loss: 2.8587241172790527
Validation loss: 2.5068981621855047

Epoch: 6| Step: 9
Training loss: 2.441906452178955
Validation loss: 2.530081736144199

Epoch: 6| Step: 10
Training loss: 2.76595139503479
Validation loss: 2.5115468245680614

Epoch: 6| Step: 11
Training loss: 3.4774928092956543
Validation loss: 2.4375774040017077

Epoch: 6| Step: 12
Training loss: 1.7713996171951294
Validation loss: 2.3715312070744012

Epoch: 6| Step: 13
Training loss: 2.8342835903167725
Validation loss: 2.3474199387335006

Epoch: 33| Step: 0
Training loss: 2.518031358718872
Validation loss: 2.336112588964483

Epoch: 6| Step: 1
Training loss: 2.1449060440063477
Validation loss: 2.331388129982897

Epoch: 6| Step: 2
Training loss: 2.983689069747925
Validation loss: 2.3316615960931264

Epoch: 6| Step: 3
Training loss: 1.9911798238754272
Validation loss: 2.33488723539537

Epoch: 6| Step: 4
Training loss: 3.018310070037842
Validation loss: 2.331631156706041

Epoch: 6| Step: 5
Training loss: 2.687328338623047
Validation loss: 2.3262285263307634

Epoch: 6| Step: 6
Training loss: 2.921522378921509
Validation loss: 2.3255956147306707

Epoch: 6| Step: 7
Training loss: 2.539961338043213
Validation loss: 2.3333851150287095

Epoch: 6| Step: 8
Training loss: 3.173841953277588
Validation loss: 2.3572542257206415

Epoch: 6| Step: 9
Training loss: 2.0219650268554688
Validation loss: 2.3817289285762335

Epoch: 6| Step: 10
Training loss: 2.664790153503418
Validation loss: 2.3962487687346754

Epoch: 6| Step: 11
Training loss: 2.788252353668213
Validation loss: 2.383086081474058

Epoch: 6| Step: 12
Training loss: 2.3385586738586426
Validation loss: 2.3494716510977796

Epoch: 6| Step: 13
Training loss: 2.856678009033203
Validation loss: 2.327790606406427

Epoch: 34| Step: 0
Training loss: 1.8421776294708252
Validation loss: 2.3262704444187943

Epoch: 6| Step: 1
Training loss: 3.2374937534332275
Validation loss: 2.320474250342256

Epoch: 6| Step: 2
Training loss: 2.4571399688720703
Validation loss: 2.3169647391124437

Epoch: 6| Step: 3
Training loss: 2.116258144378662
Validation loss: 2.320244117449689

Epoch: 6| Step: 4
Training loss: 3.069593667984009
Validation loss: 2.3176385100169847

Epoch: 6| Step: 5
Training loss: 2.627042055130005
Validation loss: 2.3116613562389086

Epoch: 6| Step: 6
Training loss: 3.043735980987549
Validation loss: 2.312627079666302

Epoch: 6| Step: 7
Training loss: 3.1000537872314453
Validation loss: 2.3136383051513345

Epoch: 6| Step: 8
Training loss: 2.2772367000579834
Validation loss: 2.3100340930364465

Epoch: 6| Step: 9
Training loss: 2.244513750076294
Validation loss: 2.309918717671466

Epoch: 6| Step: 10
Training loss: 2.2444467544555664
Validation loss: 2.3173741332946287

Epoch: 6| Step: 11
Training loss: 2.519479751586914
Validation loss: 2.3188730004013225

Epoch: 6| Step: 12
Training loss: 3.429518699645996
Validation loss: 2.3198710641553326

Epoch: 6| Step: 13
Training loss: 2.0174684524536133
Validation loss: 2.316874324634511

Epoch: 35| Step: 0
Training loss: 2.111186981201172
Validation loss: 2.326121284115699

Epoch: 6| Step: 1
Training loss: 2.454348087310791
Validation loss: 2.3632652093005437

Epoch: 6| Step: 2
Training loss: 2.4967386722564697
Validation loss: 2.3939886887868247

Epoch: 6| Step: 3
Training loss: 2.4569735527038574
Validation loss: 2.4140150700846026

Epoch: 6| Step: 4
Training loss: 2.514146566390991
Validation loss: 2.367996402966079

Epoch: 6| Step: 5
Training loss: 2.0969982147216797
Validation loss: 2.334824228799471

Epoch: 6| Step: 6
Training loss: 3.3611221313476562
Validation loss: 2.3251988413513347

Epoch: 6| Step: 7
Training loss: 2.841179609298706
Validation loss: 2.3095663619297806

Epoch: 6| Step: 8
Training loss: 2.594792366027832
Validation loss: 2.321088831911805

Epoch: 6| Step: 9
Training loss: 2.815098285675049
Validation loss: 2.3216353718952467

Epoch: 6| Step: 10
Training loss: 3.1473641395568848
Validation loss: 2.3289917617715816

Epoch: 6| Step: 11
Training loss: 3.089096784591675
Validation loss: 2.3322380332536596

Epoch: 6| Step: 12
Training loss: 1.8492408990859985
Validation loss: 2.331039503056516

Epoch: 6| Step: 13
Training loss: 2.561537981033325
Validation loss: 2.3241788738517353

Epoch: 36| Step: 0
Training loss: 3.0858302116394043
Validation loss: 2.329177389862717

Epoch: 6| Step: 1
Training loss: 2.6862001419067383
Validation loss: 2.314069160851099

Epoch: 6| Step: 2
Training loss: 3.2292582988739014
Validation loss: 2.3040571802405903

Epoch: 6| Step: 3
Training loss: 2.1122968196868896
Validation loss: 2.2964465413042294

Epoch: 6| Step: 4
Training loss: 1.9640731811523438
Validation loss: 2.2993814394038212

Epoch: 6| Step: 5
Training loss: 2.602015733718872
Validation loss: 2.2965039335271364

Epoch: 6| Step: 6
Training loss: 2.576732873916626
Validation loss: 2.300900331107519

Epoch: 6| Step: 7
Training loss: 2.994279146194458
Validation loss: 2.296623706817627

Epoch: 6| Step: 8
Training loss: 2.9688591957092285
Validation loss: 2.294428922796762

Epoch: 6| Step: 9
Training loss: 1.6591215133666992
Validation loss: 2.2984254975472727

Epoch: 6| Step: 10
Training loss: 3.2407290935516357
Validation loss: 2.3051497320975027

Epoch: 6| Step: 11
Training loss: 1.87580406665802
Validation loss: 2.3129669799599597

Epoch: 6| Step: 12
Training loss: 2.677112579345703
Validation loss: 2.3438149946992115

Epoch: 6| Step: 13
Training loss: 2.610913038253784
Validation loss: 2.3728981466703516

Epoch: 37| Step: 0
Training loss: 2.6180295944213867
Validation loss: 2.3797072928438903

Epoch: 6| Step: 1
Training loss: 2.5584402084350586
Validation loss: 2.3811076482137046

Epoch: 6| Step: 2
Training loss: 3.4897842407226562
Validation loss: 2.365209993495736

Epoch: 6| Step: 3
Training loss: 2.055070400238037
Validation loss: 2.3300585182764197

Epoch: 6| Step: 4
Training loss: 2.8016014099121094
Validation loss: 2.30025403986695

Epoch: 6| Step: 5
Training loss: 2.7433054447174072
Validation loss: 2.293018335937172

Epoch: 6| Step: 6
Training loss: 3.0249781608581543
Validation loss: 2.2922437806283273

Epoch: 6| Step: 7
Training loss: 2.781709671020508
Validation loss: 2.289284401042487

Epoch: 6| Step: 8
Training loss: 1.5391660928726196
Validation loss: 2.2921832607638453

Epoch: 6| Step: 9
Training loss: 3.080169677734375
Validation loss: 2.289407016128622

Epoch: 6| Step: 10
Training loss: 3.027083158493042
Validation loss: 2.294928999357326

Epoch: 6| Step: 11
Training loss: 2.101125717163086
Validation loss: 2.303784224294847

Epoch: 6| Step: 12
Training loss: 2.1779112815856934
Validation loss: 2.324350477546774

Epoch: 6| Step: 13
Training loss: 1.8806966543197632
Validation loss: 2.362559995343608

Epoch: 38| Step: 0
Training loss: 3.0272016525268555
Validation loss: 2.3365189324143114

Epoch: 6| Step: 1
Training loss: 2.9739127159118652
Validation loss: 2.306484535176267

Epoch: 6| Step: 2
Training loss: 2.6777756214141846
Validation loss: 2.283858235164355

Epoch: 6| Step: 3
Training loss: 2.391148090362549
Validation loss: 2.281349879439159

Epoch: 6| Step: 4
Training loss: 1.5355366468429565
Validation loss: 2.2800326603715138

Epoch: 6| Step: 5
Training loss: 2.875082015991211
Validation loss: 2.274758461982973

Epoch: 6| Step: 6
Training loss: 2.0193066596984863
Validation loss: 2.288477031133508

Epoch: 6| Step: 7
Training loss: 2.904290199279785
Validation loss: 2.296237091864309

Epoch: 6| Step: 8
Training loss: 2.945819854736328
Validation loss: 2.2970142210683515

Epoch: 6| Step: 9
Training loss: 2.2444300651550293
Validation loss: 2.308643110336796

Epoch: 6| Step: 10
Training loss: 2.9768214225769043
Validation loss: 2.3276496087351153

Epoch: 6| Step: 11
Training loss: 2.322126865386963
Validation loss: 2.345447617192422

Epoch: 6| Step: 12
Training loss: 2.9549946784973145
Validation loss: 2.3433454036712646

Epoch: 6| Step: 13
Training loss: 2.1943697929382324
Validation loss: 2.308028887676936

Epoch: 39| Step: 0
Training loss: 2.4839611053466797
Validation loss: 2.303470775645266

Epoch: 6| Step: 1
Training loss: 1.940269947052002
Validation loss: 2.2872426381675144

Epoch: 6| Step: 2
Training loss: 2.394798994064331
Validation loss: 2.2913178423399567

Epoch: 6| Step: 3
Training loss: 2.2965097427368164
Validation loss: 2.2815272910620576

Epoch: 6| Step: 4
Training loss: 2.749044418334961
Validation loss: 2.2954246459468717

Epoch: 6| Step: 5
Training loss: 2.9204015731811523
Validation loss: 2.302131329813311

Epoch: 6| Step: 6
Training loss: 2.2472684383392334
Validation loss: 2.3132657133122927

Epoch: 6| Step: 7
Training loss: 2.4763681888580322
Validation loss: 2.2918382626707836

Epoch: 6| Step: 8
Training loss: 3.5454063415527344
Validation loss: 2.2728754679361978

Epoch: 6| Step: 9
Training loss: 2.241466522216797
Validation loss: 2.2798436957020916

Epoch: 6| Step: 10
Training loss: 2.6099700927734375
Validation loss: 2.291094723568168

Epoch: 6| Step: 11
Training loss: 3.5967915058135986
Validation loss: 2.3109514444105086

Epoch: 6| Step: 12
Training loss: 2.326448440551758
Validation loss: 2.3238290638052006

Epoch: 6| Step: 13
Training loss: 2.5288186073303223
Validation loss: 2.3057219136145806

Epoch: 40| Step: 0
Training loss: 2.2792959213256836
Validation loss: 2.2991488005525325

Epoch: 6| Step: 1
Training loss: 2.969850540161133
Validation loss: 2.2887929588235836

Epoch: 6| Step: 2
Training loss: 2.822021245956421
Validation loss: 2.2804508234864924

Epoch: 6| Step: 3
Training loss: 2.4941554069519043
Validation loss: 2.2789925170201126

Epoch: 6| Step: 4
Training loss: 2.6318790912628174
Validation loss: 2.275070946703675

Epoch: 6| Step: 5
Training loss: 1.883898377418518
Validation loss: 2.2732985763139624

Epoch: 6| Step: 6
Training loss: 2.014587879180908
Validation loss: 2.2856671758877334

Epoch: 6| Step: 7
Training loss: 2.2549681663513184
Validation loss: 2.3298181615849978

Epoch: 6| Step: 8
Training loss: 3.0488455295562744
Validation loss: 2.394475834344023

Epoch: 6| Step: 9
Training loss: 2.331773519515991
Validation loss: 2.4135758261526785

Epoch: 6| Step: 10
Training loss: 2.555588483810425
Validation loss: 2.4622005467773764

Epoch: 6| Step: 11
Training loss: 4.003251075744629
Validation loss: 2.496673837784798

Epoch: 6| Step: 12
Training loss: 2.8657588958740234
Validation loss: 2.3909463754264255

Epoch: 6| Step: 13
Training loss: 1.4734835624694824
Validation loss: 2.3176437167711157

Epoch: 41| Step: 0
Training loss: 2.5268332958221436
Validation loss: 2.2913552099658596

Epoch: 6| Step: 1
Training loss: 2.662269115447998
Validation loss: 2.2846521972328104

Epoch: 6| Step: 2
Training loss: 1.9234566688537598
Validation loss: 2.274848717515187

Epoch: 6| Step: 3
Training loss: 2.729156017303467
Validation loss: 2.2780644765464206

Epoch: 6| Step: 4
Training loss: 2.254899740219116
Validation loss: 2.2814123040886334

Epoch: 6| Step: 5
Training loss: 2.4678101539611816
Validation loss: 2.3010972263992473

Epoch: 6| Step: 6
Training loss: 2.7494735717773438
Validation loss: 2.333051694336758

Epoch: 6| Step: 7
Training loss: 2.028465747833252
Validation loss: 2.3605403182327107

Epoch: 6| Step: 8
Training loss: 3.2804858684539795
Validation loss: 2.38242014761894

Epoch: 6| Step: 9
Training loss: 3.3144099712371826
Validation loss: 2.4198059010249313

Epoch: 6| Step: 10
Training loss: 3.0694172382354736
Validation loss: 2.414066663352392

Epoch: 6| Step: 11
Training loss: 2.412321090698242
Validation loss: 2.3898422436047624

Epoch: 6| Step: 12
Training loss: 2.224297523498535
Validation loss: 2.3344320481823337

Epoch: 6| Step: 13
Training loss: 2.7745373249053955
Validation loss: 2.3052992974558184

Epoch: 42| Step: 0
Training loss: 2.5804548263549805
Validation loss: 2.282989691662532

Epoch: 6| Step: 1
Training loss: 2.484683036804199
Validation loss: 2.272446611876129

Epoch: 6| Step: 2
Training loss: 2.3583991527557373
Validation loss: 2.2682119697652836

Epoch: 6| Step: 3
Training loss: 2.203433036804199
Validation loss: 2.270878807190926

Epoch: 6| Step: 4
Training loss: 3.1212708950042725
Validation loss: 2.280957878276866

Epoch: 6| Step: 5
Training loss: 2.273573637008667
Validation loss: 2.298883520146852

Epoch: 6| Step: 6
Training loss: 2.7761287689208984
Validation loss: 2.319463465803413

Epoch: 6| Step: 7
Training loss: 2.47225022315979
Validation loss: 2.3156226796488606

Epoch: 6| Step: 8
Training loss: 2.561814785003662
Validation loss: 2.2927154828143377

Epoch: 6| Step: 9
Training loss: 2.9021120071411133
Validation loss: 2.2808888086708645

Epoch: 6| Step: 10
Training loss: 2.5608067512512207
Validation loss: 2.284156621143382

Epoch: 6| Step: 11
Training loss: 2.2039239406585693
Validation loss: 2.2729240463626

Epoch: 6| Step: 12
Training loss: 3.2151849269866943
Validation loss: 2.27456670935436

Epoch: 6| Step: 13
Training loss: 2.0066819190979004
Validation loss: 2.260126588165119

Epoch: 43| Step: 0
Training loss: 2.5855884552001953
Validation loss: 2.262254850838774

Epoch: 6| Step: 1
Training loss: 2.4887452125549316
Validation loss: 2.2573332530195995

Epoch: 6| Step: 2
Training loss: 3.1556308269500732
Validation loss: 2.2526354712824666

Epoch: 6| Step: 3
Training loss: 2.2888450622558594
Validation loss: 2.2500715909465665

Epoch: 6| Step: 4
Training loss: 1.820007085800171
Validation loss: 2.2542714982904415

Epoch: 6| Step: 5
Training loss: 2.0228424072265625
Validation loss: 2.2451622691205753

Epoch: 6| Step: 6
Training loss: 3.725440740585327
Validation loss: 2.2535528341929116

Epoch: 6| Step: 7
Training loss: 1.8184049129486084
Validation loss: 2.2487585083130868

Epoch: 6| Step: 8
Training loss: 3.092167615890503
Validation loss: 2.2676028154229604

Epoch: 6| Step: 9
Training loss: 2.629683017730713
Validation loss: 2.291666620521135

Epoch: 6| Step: 10
Training loss: 3.1568167209625244
Validation loss: 2.3211730257157357

Epoch: 6| Step: 11
Training loss: 2.584174871444702
Validation loss: 2.339972472959949

Epoch: 6| Step: 12
Training loss: 2.355358839035034
Validation loss: 2.327434024503154

Epoch: 6| Step: 13
Training loss: 1.8066191673278809
Validation loss: 2.2994483619607906

Epoch: 44| Step: 0
Training loss: 1.9921789169311523
Validation loss: 2.2610603993938816

Epoch: 6| Step: 1
Training loss: 2.836019277572632
Validation loss: 2.2408769156343196

Epoch: 6| Step: 2
Training loss: 2.551273822784424
Validation loss: 2.229461964740548

Epoch: 6| Step: 3
Training loss: 2.5700552463531494
Validation loss: 2.227942218062698

Epoch: 6| Step: 4
Training loss: 2.3137803077697754
Validation loss: 2.226771837921553

Epoch: 6| Step: 5
Training loss: 2.219205141067505
Validation loss: 2.2334761235021774

Epoch: 6| Step: 6
Training loss: 3.0036087036132812
Validation loss: 2.235557358752015

Epoch: 6| Step: 7
Training loss: 2.661393165588379
Validation loss: 2.239616970862112

Epoch: 6| Step: 8
Training loss: 2.7602527141571045
Validation loss: 2.2453987213873092

Epoch: 6| Step: 9
Training loss: 2.3800032138824463
Validation loss: 2.2446050823375745

Epoch: 6| Step: 10
Training loss: 3.1065289974212646
Validation loss: 2.2420231026987874

Epoch: 6| Step: 11
Training loss: 2.5641233921051025
Validation loss: 2.250616878591558

Epoch: 6| Step: 12
Training loss: 2.321639060974121
Validation loss: 2.2514834275809665

Epoch: 6| Step: 13
Training loss: 1.9896177053451538
Validation loss: 2.245970461958198

Epoch: 45| Step: 0
Training loss: 2.9280121326446533
Validation loss: 2.2601674859241774

Epoch: 6| Step: 1
Training loss: 2.7657113075256348
Validation loss: 2.2605346223359466

Epoch: 6| Step: 2
Training loss: 2.549224853515625
Validation loss: 2.2505240491641465

Epoch: 6| Step: 3
Training loss: 2.4645581245422363
Validation loss: 2.25450764548394

Epoch: 6| Step: 4
Training loss: 1.7801425457000732
Validation loss: 2.244058547481414

Epoch: 6| Step: 5
Training loss: 2.5232272148132324
Validation loss: 2.2261219921932427

Epoch: 6| Step: 6
Training loss: 2.0518646240234375
Validation loss: 2.2127880101562827

Epoch: 6| Step: 7
Training loss: 2.307985305786133
Validation loss: 2.210542699342133

Epoch: 6| Step: 8
Training loss: 2.820164680480957
Validation loss: 2.2113688145914385

Epoch: 6| Step: 9
Training loss: 2.4054994583129883
Validation loss: 2.2119093761649182

Epoch: 6| Step: 10
Training loss: 2.965738296508789
Validation loss: 2.2100904116066555

Epoch: 6| Step: 11
Training loss: 2.6250152587890625
Validation loss: 2.209491078571607

Epoch: 6| Step: 12
Training loss: 2.597090005874634
Validation loss: 2.20771340785488

Epoch: 6| Step: 13
Training loss: 3.094468593597412
Validation loss: 2.2366647976700977

Epoch: 46| Step: 0
Training loss: 1.9275741577148438
Validation loss: 2.2535645731033815

Epoch: 6| Step: 1
Training loss: 1.8412177562713623
Validation loss: 2.2829049530849663

Epoch: 6| Step: 2
Training loss: 2.6028246879577637
Validation loss: 2.3216476312247654

Epoch: 6| Step: 3
Training loss: 2.8050155639648438
Validation loss: 2.365971624210317

Epoch: 6| Step: 4
Training loss: 2.7676944732666016
Validation loss: 2.40312603212172

Epoch: 6| Step: 5
Training loss: 2.2962605953216553
Validation loss: 2.398690495439755

Epoch: 6| Step: 6
Training loss: 2.17995548248291
Validation loss: 2.3520234118225756

Epoch: 6| Step: 7
Training loss: 3.2659194469451904
Validation loss: 2.2634299224422825

Epoch: 6| Step: 8
Training loss: 2.324934959411621
Validation loss: 2.212026551205625

Epoch: 6| Step: 9
Training loss: 2.8034467697143555
Validation loss: 2.209821429303897

Epoch: 6| Step: 10
Training loss: 3.235581398010254
Validation loss: 2.214553754816773

Epoch: 6| Step: 11
Training loss: 2.386298656463623
Validation loss: 2.227013462333269

Epoch: 6| Step: 12
Training loss: 2.539477825164795
Validation loss: 2.2341010544889714

Epoch: 6| Step: 13
Training loss: 3.189335823059082
Validation loss: 2.226531086429473

Epoch: 47| Step: 0
Training loss: 2.5703072547912598
Validation loss: 2.2379325205279934

Epoch: 6| Step: 1
Training loss: 3.0747227668762207
Validation loss: 2.2294775696210962

Epoch: 6| Step: 2
Training loss: 2.0903966426849365
Validation loss: 2.2149427783104683

Epoch: 6| Step: 3
Training loss: 2.2564516067504883
Validation loss: 2.218593120574951

Epoch: 6| Step: 4
Training loss: 2.7423300743103027
Validation loss: 2.2263090020866803

Epoch: 6| Step: 5
Training loss: 1.64479398727417
Validation loss: 2.241044759750366

Epoch: 6| Step: 6
Training loss: 2.10459041595459
Validation loss: 2.260951244702903

Epoch: 6| Step: 7
Training loss: 2.8945412635803223
Validation loss: 2.2726382119681245

Epoch: 6| Step: 8
Training loss: 2.9717674255371094
Validation loss: 2.242362851737648

Epoch: 6| Step: 9
Training loss: 3.312052011489868
Validation loss: 2.230223309609198

Epoch: 6| Step: 10
Training loss: 2.501437187194824
Validation loss: 2.2278572256847093

Epoch: 6| Step: 11
Training loss: 2.72641658782959
Validation loss: 2.2225603467674664

Epoch: 6| Step: 12
Training loss: 1.9520156383514404
Validation loss: 2.218717594300547

Epoch: 6| Step: 13
Training loss: 2.953449010848999
Validation loss: 2.226024255957655

Epoch: 48| Step: 0
Training loss: 3.667012929916382
Validation loss: 2.2290920724150953

Epoch: 6| Step: 1
Training loss: 2.1520352363586426
Validation loss: 2.2211135023383686

Epoch: 6| Step: 2
Training loss: 2.196115493774414
Validation loss: 2.2217938079628894

Epoch: 6| Step: 3
Training loss: 2.2739334106445312
Validation loss: 2.2178404331207275

Epoch: 6| Step: 4
Training loss: 3.540173053741455
Validation loss: 2.2171425306668846

Epoch: 6| Step: 5
Training loss: 2.722313642501831
Validation loss: 2.202221416657971

Epoch: 6| Step: 6
Training loss: 2.1014301776885986
Validation loss: 2.196216566588289

Epoch: 6| Step: 7
Training loss: 2.037254810333252
Validation loss: 2.1853547198798067

Epoch: 6| Step: 8
Training loss: 2.4509029388427734
Validation loss: 2.203740546780248

Epoch: 6| Step: 9
Training loss: 2.6742782592773438
Validation loss: 2.2248301685497327

Epoch: 6| Step: 10
Training loss: 2.770811080932617
Validation loss: 2.2234461333162043

Epoch: 6| Step: 11
Training loss: 2.2394304275512695
Validation loss: 2.2242917373616207

Epoch: 6| Step: 12
Training loss: 1.7584635019302368
Validation loss: 2.2248402616029144

Epoch: 6| Step: 13
Training loss: 2.772629737854004
Validation loss: 2.214092739166752

Epoch: 49| Step: 0
Training loss: 1.8463283777236938
Validation loss: 2.2183007988878476

Epoch: 6| Step: 1
Training loss: 2.9488673210144043
Validation loss: 2.2264724162317093

Epoch: 6| Step: 2
Training loss: 2.9669623374938965
Validation loss: 2.213221831988263

Epoch: 6| Step: 3
Training loss: 1.8262052536010742
Validation loss: 2.196588344471429

Epoch: 6| Step: 4
Training loss: 2.8312010765075684
Validation loss: 2.186720237937025

Epoch: 6| Step: 5
Training loss: 2.3543527126312256
Validation loss: 2.18565361730514

Epoch: 6| Step: 6
Training loss: 2.7278075218200684
Validation loss: 2.1873808522378244

Epoch: 6| Step: 7
Training loss: 1.912198781967163
Validation loss: 2.188369740722

Epoch: 6| Step: 8
Training loss: 2.8581857681274414
Validation loss: 2.188141369050549

Epoch: 6| Step: 9
Training loss: 2.7951064109802246
Validation loss: 2.199644047726867

Epoch: 6| Step: 10
Training loss: 2.578856945037842
Validation loss: 2.192932580107002

Epoch: 6| Step: 11
Training loss: 1.6295784711837769
Validation loss: 2.211817620902933

Epoch: 6| Step: 12
Training loss: 2.9972338676452637
Validation loss: 2.2866901351559545

Epoch: 6| Step: 13
Training loss: 3.10876727104187
Validation loss: 2.3358413788580124

Epoch: 50| Step: 0
Training loss: 2.3396151065826416
Validation loss: 2.386390855235438

Epoch: 6| Step: 1
Training loss: 3.3914690017700195
Validation loss: 2.4006786910436486

Epoch: 6| Step: 2
Training loss: 2.8937015533447266
Validation loss: 2.3347118413576515

Epoch: 6| Step: 3
Training loss: 2.4637131690979004
Validation loss: 2.2867774514741797

Epoch: 6| Step: 4
Training loss: 2.763031244277954
Validation loss: 2.26491633794641

Epoch: 6| Step: 5
Training loss: 2.6961417198181152
Validation loss: 2.2114336285539853

Epoch: 6| Step: 6
Training loss: 2.5078792572021484
Validation loss: 2.17853218765669

Epoch: 6| Step: 7
Training loss: 1.737168550491333
Validation loss: 2.1812442041212514

Epoch: 6| Step: 8
Training loss: 2.1689138412475586
Validation loss: 2.1763945676947154

Epoch: 6| Step: 9
Training loss: 2.5751953125
Validation loss: 2.1739024090510544

Epoch: 6| Step: 10
Training loss: 2.5345003604888916
Validation loss: 2.1730062474486647

Epoch: 6| Step: 11
Training loss: 2.639021396636963
Validation loss: 2.178408653505387

Epoch: 6| Step: 12
Training loss: 2.52260160446167
Validation loss: 2.1787985101822884

Epoch: 6| Step: 13
Training loss: 2.9625749588012695
Validation loss: 2.182794346604296

Epoch: 51| Step: 0
Training loss: 2.696193218231201
Validation loss: 2.1913940060523247

Epoch: 6| Step: 1
Training loss: 1.815523624420166
Validation loss: 2.2097532518448366

Epoch: 6| Step: 2
Training loss: 2.5461506843566895
Validation loss: 2.219984887748636

Epoch: 6| Step: 3
Training loss: 3.150644302368164
Validation loss: 2.234412803444811

Epoch: 6| Step: 4
Training loss: 2.2878952026367188
Validation loss: 2.279325141701647

Epoch: 6| Step: 5
Training loss: 2.8842458724975586
Validation loss: 2.331426376937538

Epoch: 6| Step: 6
Training loss: 3.412062883377075
Validation loss: 2.414264194426998

Epoch: 6| Step: 7
Training loss: 2.5191171169281006
Validation loss: 2.3792186924206313

Epoch: 6| Step: 8
Training loss: 3.063018798828125
Validation loss: 2.3244477882180163

Epoch: 6| Step: 9
Training loss: 2.314336061477661
Validation loss: 2.2832932472229004

Epoch: 6| Step: 10
Training loss: 2.3055057525634766
Validation loss: 2.2611360498653945

Epoch: 6| Step: 11
Training loss: 2.490185260772705
Validation loss: 2.2739993551725983

Epoch: 6| Step: 12
Training loss: 2.0151238441467285
Validation loss: 2.264345589504447

Epoch: 6| Step: 13
Training loss: 1.8127954006195068
Validation loss: 2.252566688804216

Epoch: 52| Step: 0
Training loss: 2.1094870567321777
Validation loss: 2.2339628229859056

Epoch: 6| Step: 1
Training loss: 2.5768017768859863
Validation loss: 2.2201785810532106

Epoch: 6| Step: 2
Training loss: 2.4811043739318848
Validation loss: 2.2082151930819274

Epoch: 6| Step: 3
Training loss: 3.0543012619018555
Validation loss: 2.1952385876768377

Epoch: 6| Step: 4
Training loss: 1.8060834407806396
Validation loss: 2.1937179078337965

Epoch: 6| Step: 5
Training loss: 2.613105058670044
Validation loss: 2.198897164355042

Epoch: 6| Step: 6
Training loss: 2.899674654006958
Validation loss: 2.1943329329131753

Epoch: 6| Step: 7
Training loss: 2.541036367416382
Validation loss: 2.198923906972331

Epoch: 6| Step: 8
Training loss: 2.264400005340576
Validation loss: 2.2140695048916723

Epoch: 6| Step: 9
Training loss: 2.2794349193573
Validation loss: 2.252415080224314

Epoch: 6| Step: 10
Training loss: 3.153841733932495
Validation loss: 2.276201499405728

Epoch: 6| Step: 11
Training loss: 2.713059425354004
Validation loss: 2.310207241324968

Epoch: 6| Step: 12
Training loss: 2.444737434387207
Validation loss: 2.301718532398183

Epoch: 6| Step: 13
Training loss: 2.4200992584228516
Validation loss: 2.2770642695888395

Epoch: 53| Step: 0
Training loss: 1.9667446613311768
Validation loss: 2.272351029098675

Epoch: 6| Step: 1
Training loss: 2.270996332168579
Validation loss: 2.250689087375518

Epoch: 6| Step: 2
Training loss: 2.5422377586364746
Validation loss: 2.2325304990173667

Epoch: 6| Step: 3
Training loss: 2.6835272312164307
Validation loss: 2.223857605329124

Epoch: 6| Step: 4
Training loss: 2.721529006958008
Validation loss: 2.2055608995499147

Epoch: 6| Step: 5
Training loss: 2.8116774559020996
Validation loss: 2.192609597277898

Epoch: 6| Step: 6
Training loss: 2.641861915588379
Validation loss: 2.1945433591001775

Epoch: 6| Step: 7
Training loss: 1.8607401847839355
Validation loss: 2.1899169696274625

Epoch: 6| Step: 8
Training loss: 2.459074020385742
Validation loss: 2.195072591945689

Epoch: 6| Step: 9
Training loss: 2.667649745941162
Validation loss: 2.2002355462761334

Epoch: 6| Step: 10
Training loss: 2.3851423263549805
Validation loss: 2.2020091446497108

Epoch: 6| Step: 11
Training loss: 3.171109676361084
Validation loss: 2.201842095262261

Epoch: 6| Step: 12
Training loss: 2.1937179565429688
Validation loss: 2.1905908969140824

Epoch: 6| Step: 13
Training loss: 2.5029215812683105
Validation loss: 2.175668852303618

Epoch: 54| Step: 0
Training loss: 2.163851261138916
Validation loss: 2.1704472828936834

Epoch: 6| Step: 1
Training loss: 2.560633659362793
Validation loss: 2.1667660282504175

Epoch: 6| Step: 2
Training loss: 2.573906660079956
Validation loss: 2.165377314372729

Epoch: 6| Step: 3
Training loss: 2.9814558029174805
Validation loss: 2.1653915566782795

Epoch: 6| Step: 4
Training loss: 2.403616428375244
Validation loss: 2.1721622302968013

Epoch: 6| Step: 5
Training loss: 2.4737532138824463
Validation loss: 2.1612517577345653

Epoch: 6| Step: 6
Training loss: 2.402653455734253
Validation loss: 2.157852795816237

Epoch: 6| Step: 7
Training loss: 2.037839651107788
Validation loss: 2.1542016536958757

Epoch: 6| Step: 8
Training loss: 2.3881726264953613
Validation loss: 2.155666623064267

Epoch: 6| Step: 9
Training loss: 2.024721145629883
Validation loss: 2.153419808674884

Epoch: 6| Step: 10
Training loss: 2.7783265113830566
Validation loss: 2.152915347007013

Epoch: 6| Step: 11
Training loss: 2.5736396312713623
Validation loss: 2.1677079021289782

Epoch: 6| Step: 12
Training loss: 2.2140002250671387
Validation loss: 2.1682331331314577

Epoch: 6| Step: 13
Training loss: 3.668896198272705
Validation loss: 2.1692124284723753

Epoch: 55| Step: 0
Training loss: 3.7529420852661133
Validation loss: 2.159240327855592

Epoch: 6| Step: 1
Training loss: 2.684237241744995
Validation loss: 2.148904936287993

Epoch: 6| Step: 2
Training loss: 2.7455315589904785
Validation loss: 2.1470272182136454

Epoch: 6| Step: 3
Training loss: 2.92763614654541
Validation loss: 2.1481279045022945

Epoch: 6| Step: 4
Training loss: 2.41195011138916
Validation loss: 2.15126101175944

Epoch: 6| Step: 5
Training loss: 2.8089561462402344
Validation loss: 2.1561915925754014

Epoch: 6| Step: 6
Training loss: 2.53381085395813
Validation loss: 2.154350390998266

Epoch: 6| Step: 7
Training loss: 2.2218096256256104
Validation loss: 2.1599385558917956

Epoch: 6| Step: 8
Training loss: 1.7331606149673462
Validation loss: 2.144116679827372

Epoch: 6| Step: 9
Training loss: 1.9100347757339478
Validation loss: 2.140578480177028

Epoch: 6| Step: 10
Training loss: 1.537874460220337
Validation loss: 2.1609235194421585

Epoch: 6| Step: 11
Training loss: 2.7112035751342773
Validation loss: 2.175212157669888

Epoch: 6| Step: 12
Training loss: 2.400953531265259
Validation loss: 2.1952862521653533

Epoch: 6| Step: 13
Training loss: 2.3342103958129883
Validation loss: 2.240058578470702

Epoch: 56| Step: 0
Training loss: 2.583056926727295
Validation loss: 2.301718898998794

Epoch: 6| Step: 1
Training loss: 2.49351167678833
Validation loss: 2.34950848292279

Epoch: 6| Step: 2
Training loss: 3.227543354034424
Validation loss: 2.374338706334432

Epoch: 6| Step: 3
Training loss: 2.299482583999634
Validation loss: 2.3221350203278246

Epoch: 6| Step: 4
Training loss: 2.573430299758911
Validation loss: 2.2864819316453833

Epoch: 6| Step: 5
Training loss: 2.166060447692871
Validation loss: 2.23159364474717

Epoch: 6| Step: 6
Training loss: 3.2587225437164307
Validation loss: 2.2409242071131223

Epoch: 6| Step: 7
Training loss: 2.216066837310791
Validation loss: 2.2059899401921097

Epoch: 6| Step: 8
Training loss: 2.657869338989258
Validation loss: 2.2153340860079695

Epoch: 6| Step: 9
Training loss: 2.0009186267852783
Validation loss: 2.228806890467162

Epoch: 6| Step: 10
Training loss: 2.3236513137817383
Validation loss: 2.278672146540816

Epoch: 6| Step: 11
Training loss: 2.597999334335327
Validation loss: 2.2762672978062786

Epoch: 6| Step: 12
Training loss: 2.3949358463287354
Validation loss: 2.2549039445897585

Epoch: 6| Step: 13
Training loss: 2.356837749481201
Validation loss: 2.2306444952564854

Epoch: 57| Step: 0
Training loss: 2.930572509765625
Validation loss: 2.1940259446379957

Epoch: 6| Step: 1
Training loss: 2.1833713054656982
Validation loss: 2.1629722682378625

Epoch: 6| Step: 2
Training loss: 2.7381813526153564
Validation loss: 2.149655529247817

Epoch: 6| Step: 3
Training loss: 2.510732650756836
Validation loss: 2.1411385126011346

Epoch: 6| Step: 4
Training loss: 2.7581875324249268
Validation loss: 2.1353533960157827

Epoch: 6| Step: 5
Training loss: 2.2295050621032715
Validation loss: 2.136925928054317

Epoch: 6| Step: 6
Training loss: 2.3776512145996094
Validation loss: 2.1377561438468193

Epoch: 6| Step: 7
Training loss: 2.163163900375366
Validation loss: 2.1393941371671614

Epoch: 6| Step: 8
Training loss: 2.295595645904541
Validation loss: 2.1469251737799695

Epoch: 6| Step: 9
Training loss: 3.348097562789917
Validation loss: 2.149115805984825

Epoch: 6| Step: 10
Training loss: 1.9998221397399902
Validation loss: 2.1522086281930246

Epoch: 6| Step: 11
Training loss: 2.8126533031463623
Validation loss: 2.1544987617000455

Epoch: 6| Step: 12
Training loss: 1.7710871696472168
Validation loss: 2.149949392964763

Epoch: 6| Step: 13
Training loss: 2.724613666534424
Validation loss: 2.1675773077113654

Epoch: 58| Step: 0
Training loss: 2.8939740657806396
Validation loss: 2.169345150711716

Epoch: 6| Step: 1
Training loss: 2.534249782562256
Validation loss: 2.161282088166924

Epoch: 6| Step: 2
Training loss: 2.767944812774658
Validation loss: 2.1529292445028982

Epoch: 6| Step: 3
Training loss: 2.4565305709838867
Validation loss: 2.1481199213253555

Epoch: 6| Step: 4
Training loss: 2.442535161972046
Validation loss: 2.1285585485478884

Epoch: 6| Step: 5
Training loss: 1.9657994508743286
Validation loss: 2.128558897203015

Epoch: 6| Step: 6
Training loss: 2.26320743560791
Validation loss: 2.1411677111861525

Epoch: 6| Step: 7
Training loss: 2.6251511573791504
Validation loss: 2.1456097915608394

Epoch: 6| Step: 8
Training loss: 1.8640530109405518
Validation loss: 2.1376304626464844

Epoch: 6| Step: 9
Training loss: 2.5743916034698486
Validation loss: 2.136181057140391

Epoch: 6| Step: 10
Training loss: 2.616685628890991
Validation loss: 2.151850367105135

Epoch: 6| Step: 11
Training loss: 2.2172718048095703
Validation loss: 2.1708042211430048

Epoch: 6| Step: 12
Training loss: 2.522660255432129
Validation loss: 2.230705531694556

Epoch: 6| Step: 13
Training loss: 2.985417366027832
Validation loss: 2.2767953462498163

Epoch: 59| Step: 0
Training loss: 2.9736857414245605
Validation loss: 2.315700702769782

Epoch: 6| Step: 1
Training loss: 3.1172311305999756
Validation loss: 2.2718086434948828

Epoch: 6| Step: 2
Training loss: 2.2347068786621094
Validation loss: 2.1852651783215102

Epoch: 6| Step: 3
Training loss: 1.4988486766815186
Validation loss: 2.1399237109768774

Epoch: 6| Step: 4
Training loss: 2.346351385116577
Validation loss: 2.1341090702241465

Epoch: 6| Step: 5
Training loss: 2.721951484680176
Validation loss: 2.130594999559464

Epoch: 6| Step: 6
Training loss: 2.7046656608581543
Validation loss: 2.1298952923026135

Epoch: 6| Step: 7
Training loss: 2.222716808319092
Validation loss: 2.140309154346425

Epoch: 6| Step: 8
Training loss: 2.435415267944336
Validation loss: 2.1545517367701374

Epoch: 6| Step: 9
Training loss: 2.4005253314971924
Validation loss: 2.1892881624160276

Epoch: 6| Step: 10
Training loss: 2.4729764461517334
Validation loss: 2.1800823339851956

Epoch: 6| Step: 11
Training loss: 2.4327571392059326
Validation loss: 2.1834894918626353

Epoch: 6| Step: 12
Training loss: 2.8011703491210938
Validation loss: 2.1665629789393437

Epoch: 6| Step: 13
Training loss: 2.768432855606079
Validation loss: 2.1253710485273793

Epoch: 60| Step: 0
Training loss: 2.608919143676758
Validation loss: 2.121375440269388

Epoch: 6| Step: 1
Training loss: 2.8034229278564453
Validation loss: 2.1143540823331444

Epoch: 6| Step: 2
Training loss: 2.4652607440948486
Validation loss: 2.1189383383720153

Epoch: 6| Step: 3
Training loss: 2.265094518661499
Validation loss: 2.1113889345558743

Epoch: 6| Step: 4
Training loss: 2.9314680099487305
Validation loss: 2.1210976813429143

Epoch: 6| Step: 5
Training loss: 2.359041690826416
Validation loss: 2.1281532318361345

Epoch: 6| Step: 6
Training loss: 3.0933308601379395
Validation loss: 2.1469402364505235

Epoch: 6| Step: 7
Training loss: 1.6711864471435547
Validation loss: 2.169974583451466

Epoch: 6| Step: 8
Training loss: 2.678220510482788
Validation loss: 2.2248383337451565

Epoch: 6| Step: 9
Training loss: 2.307168483734131
Validation loss: 2.2330491747907413

Epoch: 6| Step: 10
Training loss: 2.2079267501831055
Validation loss: 2.267398665028234

Epoch: 6| Step: 11
Training loss: 2.7918646335601807
Validation loss: 2.256290542182102

Epoch: 6| Step: 12
Training loss: 1.939528226852417
Validation loss: 2.2182201390625327

Epoch: 6| Step: 13
Training loss: 2.766407012939453
Validation loss: 2.19062384482353

Epoch: 61| Step: 0
Training loss: 2.3145055770874023
Validation loss: 2.1544403927300566

Epoch: 6| Step: 1
Training loss: 3.07704496383667
Validation loss: 2.139293201508061

Epoch: 6| Step: 2
Training loss: 2.138273239135742
Validation loss: 2.1354895958336453

Epoch: 6| Step: 3
Training loss: 2.1970713138580322
Validation loss: 2.127953403739519

Epoch: 6| Step: 4
Training loss: 2.521624803543091
Validation loss: 2.1194644807487406

Epoch: 6| Step: 5
Training loss: 2.445244312286377
Validation loss: 2.1087487474564584

Epoch: 6| Step: 6
Training loss: 2.6681337356567383
Validation loss: 2.117308311564948

Epoch: 6| Step: 7
Training loss: 1.8400518894195557
Validation loss: 2.1251289459966842

Epoch: 6| Step: 8
Training loss: 3.41621732711792
Validation loss: 2.1279068544346798

Epoch: 6| Step: 9
Training loss: 2.1081018447875977
Validation loss: 2.1310140471304617

Epoch: 6| Step: 10
Training loss: 2.5042366981506348
Validation loss: 2.1260810693105063

Epoch: 6| Step: 11
Training loss: 2.9667768478393555
Validation loss: 2.141064477223222

Epoch: 6| Step: 12
Training loss: 1.8177440166473389
Validation loss: 2.12006220253565

Epoch: 6| Step: 13
Training loss: 1.901817798614502
Validation loss: 2.116281719617946

Epoch: 62| Step: 0
Training loss: 2.712526321411133
Validation loss: 2.1022612048733618

Epoch: 6| Step: 1
Training loss: 2.463186264038086
Validation loss: 2.0948337303694857

Epoch: 6| Step: 2
Training loss: 2.644158363342285
Validation loss: 2.0968795566148657

Epoch: 6| Step: 3
Training loss: 2.522806167602539
Validation loss: 2.0969992055687854

Epoch: 6| Step: 4
Training loss: 1.9980193376541138
Validation loss: 2.0916112263997397

Epoch: 6| Step: 5
Training loss: 2.3330986499786377
Validation loss: 2.1047515458958124

Epoch: 6| Step: 6
Training loss: 2.620795249938965
Validation loss: 2.1259288659659763

Epoch: 6| Step: 7
Training loss: 2.6970343589782715
Validation loss: 2.171849363593645

Epoch: 6| Step: 8
Training loss: 2.6637990474700928
Validation loss: 2.1899202767238823

Epoch: 6| Step: 9
Training loss: 2.0310049057006836
Validation loss: 2.205713656640822

Epoch: 6| Step: 10
Training loss: 2.6680197715759277
Validation loss: 2.2015548572745374

Epoch: 6| Step: 11
Training loss: 2.7033796310424805
Validation loss: 2.1837938588152648

Epoch: 6| Step: 12
Training loss: 1.6299710273742676
Validation loss: 2.167818243785571

Epoch: 6| Step: 13
Training loss: 2.5437073707580566
Validation loss: 2.1709006627400718

Epoch: 63| Step: 0
Training loss: 2.359872817993164
Validation loss: 2.1762298255838375

Epoch: 6| Step: 1
Training loss: 2.5218656063079834
Validation loss: 2.1624879888308945

Epoch: 6| Step: 2
Training loss: 2.2222671508789062
Validation loss: 2.1495129062283422

Epoch: 6| Step: 3
Training loss: 2.1966898441314697
Validation loss: 2.1522567220913467

Epoch: 6| Step: 4
Training loss: 1.948600172996521
Validation loss: 2.1753784225833033

Epoch: 6| Step: 5
Training loss: 2.1940691471099854
Validation loss: 2.1777953845198437

Epoch: 6| Step: 6
Training loss: 2.7656216621398926
Validation loss: 2.1617429769167336

Epoch: 6| Step: 7
Training loss: 2.1794285774230957
Validation loss: 2.137526117345338

Epoch: 6| Step: 8
Training loss: 2.8538243770599365
Validation loss: 2.1183291865933325

Epoch: 6| Step: 9
Training loss: 2.272732734680176
Validation loss: 2.1164329846700034

Epoch: 6| Step: 10
Training loss: 2.6046228408813477
Validation loss: 2.137884009268976

Epoch: 6| Step: 11
Training loss: 3.3685052394866943
Validation loss: 2.1344998754480833

Epoch: 6| Step: 12
Training loss: 2.3526697158813477
Validation loss: 2.1256512826488865

Epoch: 6| Step: 13
Training loss: 2.2799525260925293
Validation loss: 2.1077886153292913

Epoch: 64| Step: 0
Training loss: 2.159670829772949
Validation loss: 2.1050869470001548

Epoch: 6| Step: 1
Training loss: 2.8282666206359863
Validation loss: 2.106734129690355

Epoch: 6| Step: 2
Training loss: 2.5328197479248047
Validation loss: 2.112090876025538

Epoch: 6| Step: 3
Training loss: 2.6401495933532715
Validation loss: 2.1086216024173203

Epoch: 6| Step: 4
Training loss: 2.4068353176116943
Validation loss: 2.098728290168188

Epoch: 6| Step: 5
Training loss: 2.3204827308654785
Validation loss: 2.1049860408229213

Epoch: 6| Step: 6
Training loss: 2.753650426864624
Validation loss: 2.095118494443996

Epoch: 6| Step: 7
Training loss: 2.7751998901367188
Validation loss: 2.0917453022413355

Epoch: 6| Step: 8
Training loss: 1.8952730894088745
Validation loss: 2.0881638962735414

Epoch: 6| Step: 9
Training loss: 2.002713203430176
Validation loss: 2.08617111175291

Epoch: 6| Step: 10
Training loss: 2.4250524044036865
Validation loss: 2.097522812504922

Epoch: 6| Step: 11
Training loss: 2.598038673400879
Validation loss: 2.135972240919708

Epoch: 6| Step: 12
Training loss: 2.343210458755493
Validation loss: 2.166324766733313

Epoch: 6| Step: 13
Training loss: 2.9073245525360107
Validation loss: 2.1785728059789187

Epoch: 65| Step: 0
Training loss: 2.7318923473358154
Validation loss: 2.1567410461364256

Epoch: 6| Step: 1
Training loss: 2.3122000694274902
Validation loss: 2.1420060101375786

Epoch: 6| Step: 2
Training loss: 2.3171021938323975
Validation loss: 2.1272059486758326

Epoch: 6| Step: 3
Training loss: 2.8202431201934814
Validation loss: 2.120042784239656

Epoch: 6| Step: 4
Training loss: 3.010481357574463
Validation loss: 2.1257672822603615

Epoch: 6| Step: 5
Training loss: 2.100574493408203
Validation loss: 2.123133215852963

Epoch: 6| Step: 6
Training loss: 2.5033133029937744
Validation loss: 2.142779234916933

Epoch: 6| Step: 7
Training loss: 2.1395859718322754
Validation loss: 2.1347129742304483

Epoch: 6| Step: 8
Training loss: 1.5710705518722534
Validation loss: 2.147602963191207

Epoch: 6| Step: 9
Training loss: 2.539135456085205
Validation loss: 2.1555921505856257

Epoch: 6| Step: 10
Training loss: 2.109109401702881
Validation loss: 2.1490383814739924

Epoch: 6| Step: 11
Training loss: 2.72096848487854
Validation loss: 2.155061266755545

Epoch: 6| Step: 12
Training loss: 2.6620397567749023
Validation loss: 2.134670208859187

Epoch: 6| Step: 13
Training loss: 2.458721876144409
Validation loss: 2.1180498523096882

Epoch: 66| Step: 0
Training loss: 1.9299017190933228
Validation loss: 2.1092302722315632

Epoch: 6| Step: 1
Training loss: 2.1154961585998535
Validation loss: 2.0974341336116997

Epoch: 6| Step: 2
Training loss: 3.4009008407592773
Validation loss: 2.101798349811185

Epoch: 6| Step: 3
Training loss: 1.9963676929473877
Validation loss: 2.1018526502834853

Epoch: 6| Step: 4
Training loss: 2.408816337585449
Validation loss: 2.093176363616861

Epoch: 6| Step: 5
Training loss: 2.403661012649536
Validation loss: 2.108640214448334

Epoch: 6| Step: 6
Training loss: 1.8458752632141113
Validation loss: 2.131527302085712

Epoch: 6| Step: 7
Training loss: 2.2417283058166504
Validation loss: 2.1773241104618197

Epoch: 6| Step: 8
Training loss: 2.1158974170684814
Validation loss: 2.231950395850725

Epoch: 6| Step: 9
Training loss: 2.3999125957489014
Validation loss: 2.2845289745638446

Epoch: 6| Step: 10
Training loss: 2.43727970123291
Validation loss: 2.3466283762326805

Epoch: 6| Step: 11
Training loss: 2.864902973175049
Validation loss: 2.269780769143053

Epoch: 6| Step: 12
Training loss: 2.9484052658081055
Validation loss: 2.1805641420425905

Epoch: 6| Step: 13
Training loss: 3.721576690673828
Validation loss: 2.1203574160093903

Epoch: 67| Step: 0
Training loss: 1.881847858428955
Validation loss: 2.1013989256274317

Epoch: 6| Step: 1
Training loss: 2.9838900566101074
Validation loss: 2.0866770641778105

Epoch: 6| Step: 2
Training loss: 3.048407554626465
Validation loss: 2.0807029201138403

Epoch: 6| Step: 3
Training loss: 2.476332187652588
Validation loss: 2.087017087526219

Epoch: 6| Step: 4
Training loss: 1.9941887855529785
Validation loss: 2.0900734060554096

Epoch: 6| Step: 5
Training loss: 3.0411429405212402
Validation loss: 2.095906123038261

Epoch: 6| Step: 6
Training loss: 2.256279230117798
Validation loss: 2.091574917557419

Epoch: 6| Step: 7
Training loss: 2.5664734840393066
Validation loss: 2.1065263543077695

Epoch: 6| Step: 8
Training loss: 2.374338388442993
Validation loss: 2.111838217704527

Epoch: 6| Step: 9
Training loss: 2.4668853282928467
Validation loss: 2.133137220977455

Epoch: 6| Step: 10
Training loss: 2.416027545928955
Validation loss: 2.1408672435309297

Epoch: 6| Step: 11
Training loss: 2.0872137546539307
Validation loss: 2.160403508012013

Epoch: 6| Step: 12
Training loss: 2.842500925064087
Validation loss: 2.1672798741248345

Epoch: 6| Step: 13
Training loss: 1.4907419681549072
Validation loss: 2.153322268557805

Epoch: 68| Step: 0
Training loss: 3.486081600189209
Validation loss: 2.1485576527093047

Epoch: 6| Step: 1
Training loss: 1.8661220073699951
Validation loss: 2.1153190443592687

Epoch: 6| Step: 2
Training loss: 2.927558422088623
Validation loss: 2.1055427007777716

Epoch: 6| Step: 3
Training loss: 2.2262089252471924
Validation loss: 2.092813112402475

Epoch: 6| Step: 4
Training loss: 1.977338433265686
Validation loss: 2.0844123568586124

Epoch: 6| Step: 5
Training loss: 2.2273459434509277
Validation loss: 2.0904003907275457

Epoch: 6| Step: 6
Training loss: 2.5951623916625977
Validation loss: 2.095687720083421

Epoch: 6| Step: 7
Training loss: 2.0375773906707764
Validation loss: 2.099883835802796

Epoch: 6| Step: 8
Training loss: 2.0579633712768555
Validation loss: 2.113160338453067

Epoch: 6| Step: 9
Training loss: 2.2694759368896484
Validation loss: 2.10928157068068

Epoch: 6| Step: 10
Training loss: 2.4505820274353027
Validation loss: 2.1344383044909407

Epoch: 6| Step: 11
Training loss: 2.3453726768493652
Validation loss: 2.1414218769278577

Epoch: 6| Step: 12
Training loss: 2.8923792839050293
Validation loss: 2.1255032631658737

Epoch: 6| Step: 13
Training loss: 2.680288314819336
Validation loss: 2.1186335676459858

Epoch: 69| Step: 0
Training loss: 2.935166835784912
Validation loss: 2.0952690339857534

Epoch: 6| Step: 1
Training loss: 2.3330347537994385
Validation loss: 2.0712850093841553

Epoch: 6| Step: 2
Training loss: 2.287651538848877
Validation loss: 2.06328684027477

Epoch: 6| Step: 3
Training loss: 1.7590630054473877
Validation loss: 2.0541391013770975

Epoch: 6| Step: 4
Training loss: 3.2138590812683105
Validation loss: 2.0595863057721044

Epoch: 6| Step: 5
Training loss: 2.4990768432617188
Validation loss: 2.0525394947298112

Epoch: 6| Step: 6
Training loss: 2.7856502532958984
Validation loss: 2.049499207927335

Epoch: 6| Step: 7
Training loss: 2.557053327560425
Validation loss: 2.053845385069488

Epoch: 6| Step: 8
Training loss: 2.4702887535095215
Validation loss: 2.0605918079294185

Epoch: 6| Step: 9
Training loss: 1.9766671657562256
Validation loss: 2.072184334519089

Epoch: 6| Step: 10
Training loss: 2.298410654067993
Validation loss: 2.081331278688164

Epoch: 6| Step: 11
Training loss: 2.0870089530944824
Validation loss: 2.1044678559867283

Epoch: 6| Step: 12
Training loss: 1.8553082942962646
Validation loss: 2.112804728169595

Epoch: 6| Step: 13
Training loss: 3.2522599697113037
Validation loss: 2.1067578613117175

Epoch: 70| Step: 0
Training loss: 1.7859089374542236
Validation loss: 2.110658948139478

Epoch: 6| Step: 1
Training loss: 2.606137752532959
Validation loss: 2.099271716610078

Epoch: 6| Step: 2
Training loss: 3.2084975242614746
Validation loss: 2.0741949414694183

Epoch: 6| Step: 3
Training loss: 2.652722120285034
Validation loss: 2.061801351526732

Epoch: 6| Step: 4
Training loss: 2.887815475463867
Validation loss: 2.0546591615164154

Epoch: 6| Step: 5
Training loss: 1.630291223526001
Validation loss: 2.0375654543599775

Epoch: 6| Step: 6
Training loss: 2.2854738235473633
Validation loss: 2.0388503895011

Epoch: 6| Step: 7
Training loss: 2.652609348297119
Validation loss: 2.036992821642148

Epoch: 6| Step: 8
Training loss: 2.683074951171875
Validation loss: 2.037962785331152

Epoch: 6| Step: 9
Training loss: 2.1237733364105225
Validation loss: 2.048084592306486

Epoch: 6| Step: 10
Training loss: 2.797664165496826
Validation loss: 2.0707269201996508

Epoch: 6| Step: 11
Training loss: 1.6587612628936768
Validation loss: 2.0994973682588145

Epoch: 6| Step: 12
Training loss: 2.467230796813965
Validation loss: 2.139183025206289

Epoch: 6| Step: 13
Training loss: 2.0462939739227295
Validation loss: 2.1993233952471005

Epoch: 71| Step: 0
Training loss: 2.0443644523620605
Validation loss: 2.2695079798339517

Epoch: 6| Step: 1
Training loss: 2.1894803047180176
Validation loss: 2.2643332519838886

Epoch: 6| Step: 2
Training loss: 2.265169620513916
Validation loss: 2.279757776568013

Epoch: 6| Step: 3
Training loss: 2.8117778301239014
Validation loss: 2.234445696235985

Epoch: 6| Step: 4
Training loss: 2.618903398513794
Validation loss: 2.1747137577302995

Epoch: 6| Step: 5
Training loss: 1.9237266778945923
Validation loss: 2.121095939349103

Epoch: 6| Step: 6
Training loss: 2.539719581604004
Validation loss: 2.08723359979609

Epoch: 6| Step: 7
Training loss: 2.3334033489227295
Validation loss: 2.074844506479079

Epoch: 6| Step: 8
Training loss: 2.7215352058410645
Validation loss: 2.062401210108111

Epoch: 6| Step: 9
Training loss: 1.8263211250305176
Validation loss: 2.056737325524771

Epoch: 6| Step: 10
Training loss: 3.0064339637756348
Validation loss: 2.064012207010741

Epoch: 6| Step: 11
Training loss: 2.5743203163146973
Validation loss: 2.0532502487141597

Epoch: 6| Step: 12
Training loss: 2.7506752014160156
Validation loss: 2.0627950083824897

Epoch: 6| Step: 13
Training loss: 2.0075066089630127
Validation loss: 2.0790666457145446

Epoch: 72| Step: 0
Training loss: 2.6827287673950195
Validation loss: 2.091024080912272

Epoch: 6| Step: 1
Training loss: 2.9127001762390137
Validation loss: 2.0962382478098713

Epoch: 6| Step: 2
Training loss: 1.899427056312561
Validation loss: 2.101487946766679

Epoch: 6| Step: 3
Training loss: 2.5954160690307617
Validation loss: 2.10263850099297

Epoch: 6| Step: 4
Training loss: 2.639352560043335
Validation loss: 2.135057782614103

Epoch: 6| Step: 5
Training loss: 2.0196685791015625
Validation loss: 2.189726662892167

Epoch: 6| Step: 6
Training loss: 2.546785593032837
Validation loss: 2.1366275933481034

Epoch: 6| Step: 7
Training loss: 2.6420788764953613
Validation loss: 2.113379127235823

Epoch: 6| Step: 8
Training loss: 2.612736701965332
Validation loss: 2.0955148281589633

Epoch: 6| Step: 9
Training loss: 1.9368540048599243
Validation loss: 2.0892305822782617

Epoch: 6| Step: 10
Training loss: 2.0742597579956055
Validation loss: 2.081397762862585

Epoch: 6| Step: 11
Training loss: 2.131688117980957
Validation loss: 2.079620357482664

Epoch: 6| Step: 12
Training loss: 2.9001526832580566
Validation loss: 2.07221007603471

Epoch: 6| Step: 13
Training loss: 1.7542502880096436
Validation loss: 2.0758406423753306

Epoch: 73| Step: 0
Training loss: 2.6054158210754395
Validation loss: 2.094739801140242

Epoch: 6| Step: 1
Training loss: 2.547794818878174
Validation loss: 2.07577266488024

Epoch: 6| Step: 2
Training loss: 2.988974094390869
Validation loss: 2.0714936358954317

Epoch: 6| Step: 3
Training loss: 2.2902934551239014
Validation loss: 2.0644818416205784

Epoch: 6| Step: 4
Training loss: 2.2253007888793945
Validation loss: 2.0809076652731946

Epoch: 6| Step: 5
Training loss: 2.3636302947998047
Validation loss: 2.099889686030726

Epoch: 6| Step: 6
Training loss: 2.566676616668701
Validation loss: 2.148188970422232

Epoch: 6| Step: 7
Training loss: 2.107621908187866
Validation loss: 2.149212496255034

Epoch: 6| Step: 8
Training loss: 2.487476110458374
Validation loss: 2.1584261976262575

Epoch: 6| Step: 9
Training loss: 2.4877729415893555
Validation loss: 2.1343485334868073

Epoch: 6| Step: 10
Training loss: 1.475751519203186
Validation loss: 2.0674799719164447

Epoch: 6| Step: 11
Training loss: 2.3739333152770996
Validation loss: 2.033813202252952

Epoch: 6| Step: 12
Training loss: 2.531068801879883
Validation loss: 2.0309373460790163

Epoch: 6| Step: 13
Training loss: 2.3730759620666504
Validation loss: 2.024879595284821

Epoch: 74| Step: 0
Training loss: 2.02976393699646
Validation loss: 2.0374460579246603

Epoch: 6| Step: 1
Training loss: 2.1283035278320312
Validation loss: 2.053252850809405

Epoch: 6| Step: 2
Training loss: 2.9915056228637695
Validation loss: 2.0660896993452504

Epoch: 6| Step: 3
Training loss: 2.7419426441192627
Validation loss: 2.0495130938868367

Epoch: 6| Step: 4
Training loss: 2.1448593139648438
Validation loss: 2.0479377520981656

Epoch: 6| Step: 5
Training loss: 2.2275586128234863
Validation loss: 2.0301037757627425

Epoch: 6| Step: 6
Training loss: 2.8580498695373535
Validation loss: 2.0404321532095633

Epoch: 6| Step: 7
Training loss: 2.199293851852417
Validation loss: 2.0748125814622447

Epoch: 6| Step: 8
Training loss: 2.5325565338134766
Validation loss: 2.142507404409429

Epoch: 6| Step: 9
Training loss: 3.1693756580352783
Validation loss: 2.294118901734711

Epoch: 6| Step: 10
Training loss: 2.604741334915161
Validation loss: 2.33363159753943

Epoch: 6| Step: 11
Training loss: 2.5100560188293457
Validation loss: 2.3163878122965493

Epoch: 6| Step: 12
Training loss: 2.7118067741394043
Validation loss: 2.2290974176058205

Epoch: 6| Step: 13
Training loss: 1.310849905014038
Validation loss: 2.1354330406394055

Epoch: 75| Step: 0
Training loss: 1.6033564805984497
Validation loss: 2.060151761577975

Epoch: 6| Step: 1
Training loss: 2.2065441608428955
Validation loss: 2.048200984154978

Epoch: 6| Step: 2
Training loss: 2.633256673812866
Validation loss: 2.0526546483398764

Epoch: 6| Step: 3
Training loss: 2.5043232440948486
Validation loss: 2.0530312176673644

Epoch: 6| Step: 4
Training loss: 2.6833136081695557
Validation loss: 2.058324852297383

Epoch: 6| Step: 5
Training loss: 2.182182788848877
Validation loss: 2.060973782693186

Epoch: 6| Step: 6
Training loss: 2.121187686920166
Validation loss: 2.0619693392066547

Epoch: 6| Step: 7
Training loss: 3.016385555267334
Validation loss: 2.04923616814357

Epoch: 6| Step: 8
Training loss: 3.3979721069335938
Validation loss: 2.045181801242213

Epoch: 6| Step: 9
Training loss: 2.6029820442199707
Validation loss: 2.04110090322392

Epoch: 6| Step: 10
Training loss: 1.7736012935638428
Validation loss: 2.041146524490849

Epoch: 6| Step: 11
Training loss: 3.010226249694824
Validation loss: 2.033095916112264

Epoch: 6| Step: 12
Training loss: 1.8793139457702637
Validation loss: 2.02980387339028

Epoch: 6| Step: 13
Training loss: 2.721496343612671
Validation loss: 2.051702671153571

Epoch: 76| Step: 0
Training loss: 2.3107361793518066
Validation loss: 2.084826784749185

Epoch: 6| Step: 1
Training loss: 2.1062865257263184
Validation loss: 2.113490694312639

Epoch: 6| Step: 2
Training loss: 3.2934813499450684
Validation loss: 2.1384945966864146

Epoch: 6| Step: 3
Training loss: 2.1955723762512207
Validation loss: 2.116974505045081

Epoch: 6| Step: 4
Training loss: 2.2082009315490723
Validation loss: 2.144355479107108

Epoch: 6| Step: 5
Training loss: 3.126621961593628
Validation loss: 2.1747545414073493

Epoch: 6| Step: 6
Training loss: 2.648876905441284
Validation loss: 2.1735728607382825

Epoch: 6| Step: 7
Training loss: 2.1577224731445312
Validation loss: 2.1819612210796726

Epoch: 6| Step: 8
Training loss: 2.0445477962493896
Validation loss: 2.166713824836157

Epoch: 6| Step: 9
Training loss: 1.978383183479309
Validation loss: 2.1226177356576406

Epoch: 6| Step: 10
Training loss: 1.8435691595077515
Validation loss: 2.1117801589350544

Epoch: 6| Step: 11
Training loss: 2.657804489135742
Validation loss: 2.084743451046687

Epoch: 6| Step: 12
Training loss: 2.4858453273773193
Validation loss: 2.0657433258589877

Epoch: 6| Step: 13
Training loss: 2.4781274795532227
Validation loss: 2.059819193296535

Epoch: 77| Step: 0
Training loss: 2.379763126373291
Validation loss: 2.043791514570995

Epoch: 6| Step: 1
Training loss: 3.0583982467651367
Validation loss: 2.0630886388081375

Epoch: 6| Step: 2
Training loss: 2.2995762825012207
Validation loss: 2.042587314882586

Epoch: 6| Step: 3
Training loss: 2.0297155380249023
Validation loss: 2.0496818519407705

Epoch: 6| Step: 4
Training loss: 2.4546539783477783
Validation loss: 2.046754957527243

Epoch: 6| Step: 5
Training loss: 2.550689220428467
Validation loss: 2.042482263298445

Epoch: 6| Step: 6
Training loss: 2.2812376022338867
Validation loss: 2.0669140226097515

Epoch: 6| Step: 7
Training loss: 2.8033299446105957
Validation loss: 2.0632294788155505

Epoch: 6| Step: 8
Training loss: 2.880424737930298
Validation loss: 2.0708811565112044

Epoch: 6| Step: 9
Training loss: 2.445923089981079
Validation loss: 2.096769530286071

Epoch: 6| Step: 10
Training loss: 2.295858860015869
Validation loss: 2.1087226842039373

Epoch: 6| Step: 11
Training loss: 1.7412770986557007
Validation loss: 2.1407333291986936

Epoch: 6| Step: 12
Training loss: 2.606605052947998
Validation loss: 2.2093847643944526

Epoch: 6| Step: 13
Training loss: 0.9398629665374756
Validation loss: 2.229511043076874

Epoch: 78| Step: 0
Training loss: 2.392786741256714
Validation loss: 2.2537112133477324

Epoch: 6| Step: 1
Training loss: 2.199800491333008
Validation loss: 2.2660128647281277

Epoch: 6| Step: 2
Training loss: 3.075901508331299
Validation loss: 2.203375367708104

Epoch: 6| Step: 3
Training loss: 2.2849647998809814
Validation loss: 2.1390926812284734

Epoch: 6| Step: 4
Training loss: 1.706784725189209
Validation loss: 2.09562784882002

Epoch: 6| Step: 5
Training loss: 2.3797712326049805
Validation loss: 2.053703902870096

Epoch: 6| Step: 6
Training loss: 2.9865894317626953
Validation loss: 2.021063326507486

Epoch: 6| Step: 7
Training loss: 2.6975321769714355
Validation loss: 2.0155650954092703

Epoch: 6| Step: 8
Training loss: 1.6613330841064453
Validation loss: 2.01968781153361

Epoch: 6| Step: 9
Training loss: 2.4118285179138184
Validation loss: 2.0295274014114053

Epoch: 6| Step: 10
Training loss: 3.1582999229431152
Validation loss: 2.0442678005464616

Epoch: 6| Step: 11
Training loss: 1.9755518436431885
Validation loss: 2.0487444221332507

Epoch: 6| Step: 12
Training loss: 2.3624038696289062
Validation loss: 2.0544290029874412

Epoch: 6| Step: 13
Training loss: 2.7886881828308105
Validation loss: 2.0484326526682866

Epoch: 79| Step: 0
Training loss: 2.7183313369750977
Validation loss: 2.0418773633177563

Epoch: 6| Step: 1
Training loss: 2.536977767944336
Validation loss: 2.030986411597139

Epoch: 6| Step: 2
Training loss: 2.3767647743225098
Validation loss: 2.024205635952693

Epoch: 6| Step: 3
Training loss: 2.536825656890869
Validation loss: 2.031748881904028

Epoch: 6| Step: 4
Training loss: 3.0193240642547607
Validation loss: 2.055061250604609

Epoch: 6| Step: 5
Training loss: 2.083070755004883
Validation loss: 2.065045569532661

Epoch: 6| Step: 6
Training loss: 1.8207383155822754
Validation loss: 2.0714151244009695

Epoch: 6| Step: 7
Training loss: 2.172485589981079
Validation loss: 2.1030137590182725

Epoch: 6| Step: 8
Training loss: 2.864013910293579
Validation loss: 2.0903574728196666

Epoch: 6| Step: 9
Training loss: 2.7231764793395996
Validation loss: 2.0637013502018426

Epoch: 6| Step: 10
Training loss: 2.336048126220703
Validation loss: 2.0444179196511545

Epoch: 6| Step: 11
Training loss: 2.1357274055480957
Validation loss: 2.033487609637681

Epoch: 6| Step: 12
Training loss: 2.079789638519287
Validation loss: 2.022457198430133

Epoch: 6| Step: 13
Training loss: 2.2942941188812256
Validation loss: 2.0245714943896056

Epoch: 80| Step: 0
Training loss: 1.703879475593567
Validation loss: 2.0253217861216557

Epoch: 6| Step: 1
Training loss: 2.530390739440918
Validation loss: 2.0357555189440326

Epoch: 6| Step: 2
Training loss: 1.8200323581695557
Validation loss: 2.0437282669928765

Epoch: 6| Step: 3
Training loss: 2.0861082077026367
Validation loss: 2.058185144137311

Epoch: 6| Step: 4
Training loss: 2.9927492141723633
Validation loss: 2.040572098506394

Epoch: 6| Step: 5
Training loss: 2.617125988006592
Validation loss: 2.020163482235324

Epoch: 6| Step: 6
Training loss: 3.3371472358703613
Validation loss: 2.019597081727879

Epoch: 6| Step: 7
Training loss: 2.2400062084198
Validation loss: 2.0064401716314335

Epoch: 6| Step: 8
Training loss: 2.646864652633667
Validation loss: 2.012645036943497

Epoch: 6| Step: 9
Training loss: 1.8586540222167969
Validation loss: 2.003896777347852

Epoch: 6| Step: 10
Training loss: 3.026707410812378
Validation loss: 2.0079049474449566

Epoch: 6| Step: 11
Training loss: 2.375417709350586
Validation loss: 2.0045415239949382

Epoch: 6| Step: 12
Training loss: 2.651589870452881
Validation loss: 2.0116870044380106

Epoch: 6| Step: 13
Training loss: 0.8332909345626831
Validation loss: 2.002715524806771

Epoch: 81| Step: 0
Training loss: 2.057039976119995
Validation loss: 2.024837770769673

Epoch: 6| Step: 1
Training loss: 1.7837679386138916
Validation loss: 2.07006073510775

Epoch: 6| Step: 2
Training loss: 2.802626609802246
Validation loss: 2.100132747363019

Epoch: 6| Step: 3
Training loss: 2.8185324668884277
Validation loss: 2.102987745756744

Epoch: 6| Step: 4
Training loss: 2.677316904067993
Validation loss: 2.115732249393258

Epoch: 6| Step: 5
Training loss: 2.862827777862549
Validation loss: 2.1478045832726265

Epoch: 6| Step: 6
Training loss: 1.8178761005401611
Validation loss: 2.1258213032958326

Epoch: 6| Step: 7
Training loss: 1.4094008207321167
Validation loss: 2.091902358557588

Epoch: 6| Step: 8
Training loss: 2.572661876678467
Validation loss: 2.0809891390544113

Epoch: 6| Step: 9
Training loss: 2.312288522720337
Validation loss: 2.1290410410973335

Epoch: 6| Step: 10
Training loss: 2.846491813659668
Validation loss: 2.217637018490863

Epoch: 6| Step: 11
Training loss: 3.281947374343872
Validation loss: 2.2574804982831402

Epoch: 6| Step: 12
Training loss: 2.1114463806152344
Validation loss: 2.319207701631772

Epoch: 6| Step: 13
Training loss: 2.3666982650756836
Validation loss: 2.2593658354974564

Epoch: 82| Step: 0
Training loss: 2.7340898513793945
Validation loss: 2.1720927351264545

Epoch: 6| Step: 1
Training loss: 2.455801010131836
Validation loss: 2.0941780177495812

Epoch: 6| Step: 2
Training loss: 2.405661106109619
Validation loss: 2.0588838849016415

Epoch: 6| Step: 3
Training loss: 2.8271124362945557
Validation loss: 2.028811345818222

Epoch: 6| Step: 4
Training loss: 2.902287483215332
Validation loss: 2.0196289734173845

Epoch: 6| Step: 5
Training loss: 1.9183063507080078
Validation loss: 2.00960075342527

Epoch: 6| Step: 6
Training loss: 2.879737377166748
Validation loss: 2.0103677318942164

Epoch: 6| Step: 7
Training loss: 1.737895131111145
Validation loss: 2.0176953442635073

Epoch: 6| Step: 8
Training loss: 2.221529960632324
Validation loss: 2.014179232299969

Epoch: 6| Step: 9
Training loss: 1.6401164531707764
Validation loss: 2.0190951465278544

Epoch: 6| Step: 10
Training loss: 2.3936052322387695
Validation loss: 2.005301057651479

Epoch: 6| Step: 11
Training loss: 2.1510543823242188
Validation loss: 2.014497117329669

Epoch: 6| Step: 12
Training loss: 2.2005929946899414
Validation loss: 2.032642641375142

Epoch: 6| Step: 13
Training loss: 2.84572696685791
Validation loss: 2.043488887048537

Epoch: 83| Step: 0
Training loss: 2.2672152519226074
Validation loss: 2.0518223265165925

Epoch: 6| Step: 1
Training loss: 2.985935688018799
Validation loss: 2.0808220832578597

Epoch: 6| Step: 2
Training loss: 2.636631965637207
Validation loss: 2.080094941200749

Epoch: 6| Step: 3
Training loss: 2.369856357574463
Validation loss: 2.0660245777458273

Epoch: 6| Step: 4
Training loss: 1.987231731414795
Validation loss: 2.0619030947326333

Epoch: 6| Step: 5
Training loss: 1.7511106729507446
Validation loss: 2.04568697175672

Epoch: 6| Step: 6
Training loss: 2.2452893257141113
Validation loss: 2.0364344889117825

Epoch: 6| Step: 7
Training loss: 2.771310806274414
Validation loss: 2.04188471968456

Epoch: 6| Step: 8
Training loss: 2.7957980632781982
Validation loss: 2.0610381967277935

Epoch: 6| Step: 9
Training loss: 2.27427339553833
Validation loss: 2.058340500759822

Epoch: 6| Step: 10
Training loss: 1.7916135787963867
Validation loss: 2.07019591587846

Epoch: 6| Step: 11
Training loss: 2.4800479412078857
Validation loss: 2.0743690229231313

Epoch: 6| Step: 12
Training loss: 2.0162312984466553
Validation loss: 2.086772449554936

Epoch: 6| Step: 13
Training loss: 2.661644697189331
Validation loss: 2.1040201520407074

Epoch: 84| Step: 0
Training loss: 1.914894938468933
Validation loss: 2.105940349640385

Epoch: 6| Step: 1
Training loss: 2.4316258430480957
Validation loss: 2.104196083161139

Epoch: 6| Step: 2
Training loss: 2.0633630752563477
Validation loss: 2.0939575856731785

Epoch: 6| Step: 3
Training loss: 2.6354832649230957
Validation loss: 2.0793970797651555

Epoch: 6| Step: 4
Training loss: 2.2549381256103516
Validation loss: 2.049917072378179

Epoch: 6| Step: 5
Training loss: 2.0266318321228027
Validation loss: 2.0235711784772974

Epoch: 6| Step: 6
Training loss: 2.4069981575012207
Validation loss: 2.0061264781541723

Epoch: 6| Step: 7
Training loss: 2.260517120361328
Validation loss: 2.008116031205782

Epoch: 6| Step: 8
Training loss: 2.7439630031585693
Validation loss: 2.007612902631042

Epoch: 6| Step: 9
Training loss: 1.6918907165527344
Validation loss: 2.0055737303149317

Epoch: 6| Step: 10
Training loss: 2.7105751037597656
Validation loss: 1.9958591320181405

Epoch: 6| Step: 11
Training loss: 2.6624794006347656
Validation loss: 2.003941459040488

Epoch: 6| Step: 12
Training loss: 2.858776330947876
Validation loss: 2.0007769023218462

Epoch: 6| Step: 13
Training loss: 2.263413667678833
Validation loss: 2.028534386747627

Epoch: 85| Step: 0
Training loss: 2.332407236099243
Validation loss: 2.085005073137181

Epoch: 6| Step: 1
Training loss: 2.257063865661621
Validation loss: 2.1901962475110124

Epoch: 6| Step: 2
Training loss: 2.5684666633605957
Validation loss: 2.282782531553699

Epoch: 6| Step: 3
Training loss: 2.2265381813049316
Validation loss: 2.301123921589185

Epoch: 6| Step: 4
Training loss: 1.8914499282836914
Validation loss: 2.248193556262601

Epoch: 6| Step: 5
Training loss: 2.403583526611328
Validation loss: 2.1754107936736076

Epoch: 6| Step: 6
Training loss: 2.5676376819610596
Validation loss: 2.100123167037964

Epoch: 6| Step: 7
Training loss: 2.4039487838745117
Validation loss: 2.0547772120403986

Epoch: 6| Step: 8
Training loss: 2.281627655029297
Validation loss: 2.0326698390386437

Epoch: 6| Step: 9
Training loss: 2.565446376800537
Validation loss: 2.025033163767989

Epoch: 6| Step: 10
Training loss: 2.7735037803649902
Validation loss: 2.0308296936814503

Epoch: 6| Step: 11
Training loss: 2.567819118499756
Validation loss: 2.031454442649759

Epoch: 6| Step: 12
Training loss: 2.2468411922454834
Validation loss: 2.023129975923928

Epoch: 6| Step: 13
Training loss: 2.0959808826446533
Validation loss: 2.011795308000298

Epoch: 86| Step: 0
Training loss: 2.304495096206665
Validation loss: 2.0031672190594416

Epoch: 6| Step: 1
Training loss: 2.9673445224761963
Validation loss: 2.007081993164555

Epoch: 6| Step: 2
Training loss: 1.882563591003418
Validation loss: 2.0263133433557328

Epoch: 6| Step: 3
Training loss: 2.9033870697021484
Validation loss: 2.0529385766675396

Epoch: 6| Step: 4
Training loss: 2.0133094787597656
Validation loss: 2.069108672039483

Epoch: 6| Step: 5
Training loss: 2.6029651165008545
Validation loss: 2.082509438196818

Epoch: 6| Step: 6
Training loss: 1.9718419313430786
Validation loss: 2.1288421897478003

Epoch: 6| Step: 7
Training loss: 2.8669939041137695
Validation loss: 2.1801279744794293

Epoch: 6| Step: 8
Training loss: 1.815583348274231
Validation loss: 2.229715081953233

Epoch: 6| Step: 9
Training loss: 1.770397663116455
Validation loss: 2.222193758974793

Epoch: 6| Step: 10
Training loss: 2.092074394226074
Validation loss: 2.144331314230478

Epoch: 6| Step: 11
Training loss: 2.3120040893554688
Validation loss: 2.0671323166098645

Epoch: 6| Step: 12
Training loss: 2.6432511806488037
Validation loss: 2.0443657752006286

Epoch: 6| Step: 13
Training loss: 3.154245615005493
Validation loss: 2.025379246281039

Epoch: 87| Step: 0
Training loss: 2.523509979248047
Validation loss: 2.026362262746339

Epoch: 6| Step: 1
Training loss: 2.0039162635803223
Validation loss: 2.0218507051467896

Epoch: 6| Step: 2
Training loss: 3.0083532333374023
Validation loss: 2.0169817234880183

Epoch: 6| Step: 3
Training loss: 2.2252955436706543
Validation loss: 2.0023754104491203

Epoch: 6| Step: 4
Training loss: 2.714841842651367
Validation loss: 2.00887865917657

Epoch: 6| Step: 5
Training loss: 2.294924736022949
Validation loss: 2.0108398570809314

Epoch: 6| Step: 6
Training loss: 2.2516043186187744
Validation loss: 2.0151496933352564

Epoch: 6| Step: 7
Training loss: 1.7805899381637573
Validation loss: 2.046563220280473

Epoch: 6| Step: 8
Training loss: 1.8923667669296265
Validation loss: 2.08741496968013

Epoch: 6| Step: 9
Training loss: 2.880608558654785
Validation loss: 2.0940044926058863

Epoch: 6| Step: 10
Training loss: 2.199401617050171
Validation loss: 2.1409383666130806

Epoch: 6| Step: 11
Training loss: 2.991436719894409
Validation loss: 2.1448288412504297

Epoch: 6| Step: 12
Training loss: 1.8415347337722778
Validation loss: 2.1712247735710553

Epoch: 6| Step: 13
Training loss: 2.3995230197906494
Validation loss: 2.1911003615266536

Epoch: 88| Step: 0
Training loss: 2.107672691345215
Validation loss: 2.1956128612641366

Epoch: 6| Step: 1
Training loss: 3.1284072399139404
Validation loss: 2.1509178479512534

Epoch: 6| Step: 2
Training loss: 2.5781636238098145
Validation loss: 2.1042927542040424

Epoch: 6| Step: 3
Training loss: 2.249225616455078
Validation loss: 2.0978306160178235

Epoch: 6| Step: 4
Training loss: 1.8409113883972168
Validation loss: 2.094528176451242

Epoch: 6| Step: 5
Training loss: 1.89227294921875
Validation loss: 2.088990056386558

Epoch: 6| Step: 6
Training loss: 2.294389247894287
Validation loss: 2.0972156370839765

Epoch: 6| Step: 7
Training loss: 1.954456090927124
Validation loss: 2.0817772470494753

Epoch: 6| Step: 8
Training loss: 2.894075393676758
Validation loss: 2.0824040661575975

Epoch: 6| Step: 9
Training loss: 1.537827491760254
Validation loss: 2.097773103303807

Epoch: 6| Step: 10
Training loss: 1.8231438398361206
Validation loss: 2.146624649724653

Epoch: 6| Step: 11
Training loss: 2.265085220336914
Validation loss: 2.1787974706260105

Epoch: 6| Step: 12
Training loss: 2.9597744941711426
Validation loss: 2.1665873809527327

Epoch: 6| Step: 13
Training loss: 3.998387575149536
Validation loss: 2.136468425873787

Epoch: 89| Step: 0
Training loss: 2.8669581413269043
Validation loss: 2.0752643821060017

Epoch: 6| Step: 1
Training loss: 2.227407455444336
Validation loss: 2.0533686055931994

Epoch: 6| Step: 2
Training loss: 2.3361902236938477
Validation loss: 2.0403651114433043

Epoch: 6| Step: 3
Training loss: 1.995250940322876
Validation loss: 2.0192868696746005

Epoch: 6| Step: 4
Training loss: 1.6126995086669922
Validation loss: 2.0259783062883603

Epoch: 6| Step: 5
Training loss: 3.11696457862854
Validation loss: 2.017012365402714

Epoch: 6| Step: 6
Training loss: 2.8977930545806885
Validation loss: 2.0313935151664158

Epoch: 6| Step: 7
Training loss: 1.9574812650680542
Validation loss: 2.048545934820688

Epoch: 6| Step: 8
Training loss: 2.6001663208007812
Validation loss: 2.0354153699772333

Epoch: 6| Step: 9
Training loss: 1.7778940200805664
Validation loss: 2.0427904000846286

Epoch: 6| Step: 10
Training loss: 2.1729161739349365
Validation loss: 2.0399606304783977

Epoch: 6| Step: 11
Training loss: 2.124678134918213
Validation loss: 2.052595152649828

Epoch: 6| Step: 12
Training loss: 2.6051745414733887
Validation loss: 2.070088945409303

Epoch: 6| Step: 13
Training loss: 2.35204815864563
Validation loss: 2.078227348225091

Epoch: 90| Step: 0
Training loss: 1.9053772687911987
Validation loss: 2.1010010909008723

Epoch: 6| Step: 1
Training loss: 2.5845818519592285
Validation loss: 2.105712172805622

Epoch: 6| Step: 2
Training loss: 3.0441036224365234
Validation loss: 2.1056635008063367

Epoch: 6| Step: 3
Training loss: 2.0987424850463867
Validation loss: 2.098673382113057

Epoch: 6| Step: 4
Training loss: 1.7360625267028809
Validation loss: 2.096635869754258

Epoch: 6| Step: 5
Training loss: 1.824641466140747
Validation loss: 2.0821174344708844

Epoch: 6| Step: 6
Training loss: 1.9628993272781372
Validation loss: 2.078830921521751

Epoch: 6| Step: 7
Training loss: 2.21755313873291
Validation loss: 2.0752592778974965

Epoch: 6| Step: 8
Training loss: 2.6374478340148926
Validation loss: 2.078556819628644

Epoch: 6| Step: 9
Training loss: 2.155632257461548
Validation loss: 2.0613340613662556

Epoch: 6| Step: 10
Training loss: 2.7352681159973145
Validation loss: 2.0474870768926476

Epoch: 6| Step: 11
Training loss: 2.0287747383117676
Validation loss: 2.02715310101868

Epoch: 6| Step: 12
Training loss: 2.3921926021575928
Validation loss: 2.0075588739046486

Epoch: 6| Step: 13
Training loss: 3.4009199142456055
Validation loss: 2.0049249369611024

Epoch: 91| Step: 0
Training loss: 2.318203926086426
Validation loss: 2.0128268208554996

Epoch: 6| Step: 1
Training loss: 2.258434295654297
Validation loss: 2.041559244996758

Epoch: 6| Step: 2
Training loss: 2.320892810821533
Validation loss: 2.0612226532351587

Epoch: 6| Step: 3
Training loss: 2.42870831489563
Validation loss: 2.0665447122307232

Epoch: 6| Step: 4
Training loss: 2.417275905609131
Validation loss: 2.0520018633975776

Epoch: 6| Step: 5
Training loss: 1.9880709648132324
Validation loss: 2.0799659964858845

Epoch: 6| Step: 6
Training loss: 1.8879255056381226
Validation loss: 2.1001063931372856

Epoch: 6| Step: 7
Training loss: 2.2375001907348633
Validation loss: 2.142039027265323

Epoch: 6| Step: 8
Training loss: 1.816373348236084
Validation loss: 2.1828669617252965

Epoch: 6| Step: 9
Training loss: 2.8176655769348145
Validation loss: 2.21879796443447

Epoch: 6| Step: 10
Training loss: 2.162985324859619
Validation loss: 2.1762972031870196

Epoch: 6| Step: 11
Training loss: 2.665776014328003
Validation loss: 2.13038113809401

Epoch: 6| Step: 12
Training loss: 2.29062557220459
Validation loss: 2.103047170946675

Epoch: 6| Step: 13
Training loss: 2.4199938774108887
Validation loss: 2.0610146368703535

Epoch: 92| Step: 0
Training loss: 2.9812116622924805
Validation loss: 2.059140977039132

Epoch: 6| Step: 1
Training loss: 2.0170605182647705
Validation loss: 2.034280878241344

Epoch: 6| Step: 2
Training loss: 2.9795384407043457
Validation loss: 2.0523797324908677

Epoch: 6| Step: 3
Training loss: 2.1841981410980225
Validation loss: 2.064169842709777

Epoch: 6| Step: 4
Training loss: 2.035573959350586
Validation loss: 2.064006295255435

Epoch: 6| Step: 5
Training loss: 2.2680649757385254
Validation loss: 2.096252050451053

Epoch: 6| Step: 6
Training loss: 2.1179733276367188
Validation loss: 2.066817545121716

Epoch: 6| Step: 7
Training loss: 1.5693490505218506
Validation loss: 2.0660425463030414

Epoch: 6| Step: 8
Training loss: 2.3170440196990967
Validation loss: 2.04939240794028

Epoch: 6| Step: 9
Training loss: 2.3997223377227783
Validation loss: 2.018945647824195

Epoch: 6| Step: 10
Training loss: 2.2563793659210205
Validation loss: 1.992365934515512

Epoch: 6| Step: 11
Training loss: 2.1791255474090576
Validation loss: 1.9870568449779222

Epoch: 6| Step: 12
Training loss: 2.468061923980713
Validation loss: 1.9912159404447

Epoch: 6| Step: 13
Training loss: 2.2443997859954834
Validation loss: 1.9983344001154746

Epoch: 93| Step: 0
Training loss: 1.716002345085144
Validation loss: 1.9942863820701517

Epoch: 6| Step: 1
Training loss: 1.9514904022216797
Validation loss: 2.0376533051972747

Epoch: 6| Step: 2
Training loss: 2.3388309478759766
Validation loss: 2.0833194614738546

Epoch: 6| Step: 3
Training loss: 1.6127431392669678
Validation loss: 2.137468784086166

Epoch: 6| Step: 4
Training loss: 2.219127655029297
Validation loss: 2.1662157761153353

Epoch: 6| Step: 5
Training loss: 2.4841010570526123
Validation loss: 2.1591161194668023

Epoch: 6| Step: 6
Training loss: 2.5594053268432617
Validation loss: 2.190608387352318

Epoch: 6| Step: 7
Training loss: 2.708679676055908
Validation loss: 2.186363502215314

Epoch: 6| Step: 8
Training loss: 3.0217533111572266
Validation loss: 2.1529953274675595

Epoch: 6| Step: 9
Training loss: 2.6867589950561523
Validation loss: 2.0874569467318955

Epoch: 6| Step: 10
Training loss: 1.9708160161972046
Validation loss: 2.014932974692314

Epoch: 6| Step: 11
Training loss: 2.0824999809265137
Validation loss: 1.9967223854475125

Epoch: 6| Step: 12
Training loss: 2.3856425285339355
Validation loss: 1.997748605666622

Epoch: 6| Step: 13
Training loss: 2.092510938644409
Validation loss: 1.998324683917466

Epoch: 94| Step: 0
Training loss: 2.4603538513183594
Validation loss: 1.995811762348298

Epoch: 6| Step: 1
Training loss: 1.9787110090255737
Validation loss: 1.9790705455246793

Epoch: 6| Step: 2
Training loss: 2.0665464401245117
Validation loss: 1.9870648845549552

Epoch: 6| Step: 3
Training loss: 2.068295955657959
Validation loss: 1.9861423353995047

Epoch: 6| Step: 4
Training loss: 2.2079527378082275
Validation loss: 1.992200433567006

Epoch: 6| Step: 5
Training loss: 2.3817572593688965
Validation loss: 2.029314661538729

Epoch: 6| Step: 6
Training loss: 2.31744647026062
Validation loss: 2.0609724496000554

Epoch: 6| Step: 7
Training loss: 2.0894975662231445
Validation loss: 2.1627535230369976

Epoch: 6| Step: 8
Training loss: 2.721982479095459
Validation loss: 2.2238095473217707

Epoch: 6| Step: 9
Training loss: 2.7479114532470703
Validation loss: 2.3219135627951673

Epoch: 6| Step: 10
Training loss: 1.9116237163543701
Validation loss: 2.189849086987075

Epoch: 6| Step: 11
Training loss: 2.963470220565796
Validation loss: 2.127960212769047

Epoch: 6| Step: 12
Training loss: 2.1243932247161865
Validation loss: 2.051440651698779

Epoch: 6| Step: 13
Training loss: 2.0038890838623047
Validation loss: 1.9799022136196014

Epoch: 95| Step: 0
Training loss: 2.4750595092773438
Validation loss: 1.9842151967428063

Epoch: 6| Step: 1
Training loss: 2.63747501373291
Validation loss: 1.9826950552642986

Epoch: 6| Step: 2
Training loss: 2.532759189605713
Validation loss: 1.9789774776786886

Epoch: 6| Step: 3
Training loss: 2.3913917541503906
Validation loss: 1.9756026396187403

Epoch: 6| Step: 4
Training loss: 1.907336950302124
Validation loss: 1.9729029132473854

Epoch: 6| Step: 5
Training loss: 1.8632745742797852
Validation loss: 1.9665644425217823

Epoch: 6| Step: 6
Training loss: 1.9337997436523438
Validation loss: 1.9921006515461912

Epoch: 6| Step: 7
Training loss: 2.128793478012085
Validation loss: 2.019239276968023

Epoch: 6| Step: 8
Training loss: 2.683837413787842
Validation loss: 2.0709736295925674

Epoch: 6| Step: 9
Training loss: 2.451582193374634
Validation loss: 2.0967223862166047

Epoch: 6| Step: 10
Training loss: 2.0618691444396973
Validation loss: 2.1336375282656763

Epoch: 6| Step: 11
Training loss: 1.9985992908477783
Validation loss: 2.146832791707849

Epoch: 6| Step: 12
Training loss: 1.92057466506958
Validation loss: 2.145380744370081

Epoch: 6| Step: 13
Training loss: 3.0714776515960693
Validation loss: 2.087040193619267

Epoch: 96| Step: 0
Training loss: 1.9028362035751343
Validation loss: 2.035834541884802

Epoch: 6| Step: 1
Training loss: 2.5569710731506348
Validation loss: 1.9745890376388386

Epoch: 6| Step: 2
Training loss: 2.577554702758789
Validation loss: 1.9642222619825793

Epoch: 6| Step: 3
Training loss: 2.8002512454986572
Validation loss: 1.9598838283169655

Epoch: 6| Step: 4
Training loss: 2.8756327629089355
Validation loss: 1.9599016904830933

Epoch: 6| Step: 5
Training loss: 2.1180853843688965
Validation loss: 1.9764567908420358

Epoch: 6| Step: 6
Training loss: 2.1072428226470947
Validation loss: 1.974144067815555

Epoch: 6| Step: 7
Training loss: 2.224872589111328
Validation loss: 1.978052923756261

Epoch: 6| Step: 8
Training loss: 2.8917813301086426
Validation loss: 1.9733305233781055

Epoch: 6| Step: 9
Training loss: 1.9085530042648315
Validation loss: 1.9799153561233191

Epoch: 6| Step: 10
Training loss: 1.7306684255599976
Validation loss: 2.0007668746415006

Epoch: 6| Step: 11
Training loss: 2.5032541751861572
Validation loss: 2.091267530636121

Epoch: 6| Step: 12
Training loss: 2.3847148418426514
Validation loss: 2.169391914080548

Epoch: 6| Step: 13
Training loss: 1.6135544776916504
Validation loss: 2.181189469111863

Epoch: 97| Step: 0
Training loss: 1.566689133644104
Validation loss: 2.185292843849428

Epoch: 6| Step: 1
Training loss: 2.370262861251831
Validation loss: 2.2076851706351004

Epoch: 6| Step: 2
Training loss: 2.4292044639587402
Validation loss: 2.195967020527009

Epoch: 6| Step: 3
Training loss: 1.9642771482467651
Validation loss: 2.1689815559694843

Epoch: 6| Step: 4
Training loss: 2.0449280738830566
Validation loss: 2.1197598570136615

Epoch: 6| Step: 5
Training loss: 1.725076675415039
Validation loss: 2.0795657147643385

Epoch: 6| Step: 6
Training loss: 2.2617461681365967
Validation loss: 2.04137493718055

Epoch: 6| Step: 7
Training loss: 3.267038345336914
Validation loss: 2.0036291178836616

Epoch: 6| Step: 8
Training loss: 1.684274673461914
Validation loss: 1.9733618920849216

Epoch: 6| Step: 9
Training loss: 3.003925323486328
Validation loss: 1.9528474038647068

Epoch: 6| Step: 10
Training loss: 1.8766077756881714
Validation loss: 1.9606753241631292

Epoch: 6| Step: 11
Training loss: 2.7722814083099365
Validation loss: 1.9635448122537265

Epoch: 6| Step: 12
Training loss: 2.3842177391052246
Validation loss: 1.9666402621935772

Epoch: 6| Step: 13
Training loss: 2.601945161819458
Validation loss: 1.971609482201197

Epoch: 98| Step: 0
Training loss: 2.6629223823547363
Validation loss: 1.9654069241657053

Epoch: 6| Step: 1
Training loss: 1.489591360092163
Validation loss: 1.9590284029642742

Epoch: 6| Step: 2
Training loss: 2.388601303100586
Validation loss: 1.9669505127014653

Epoch: 6| Step: 3
Training loss: 2.7062625885009766
Validation loss: 1.9871746314469205

Epoch: 6| Step: 4
Training loss: 1.29403817653656
Validation loss: 2.003807971554418

Epoch: 6| Step: 5
Training loss: 2.4768874645233154
Validation loss: 2.0349094534433014

Epoch: 6| Step: 6
Training loss: 1.6106650829315186
Validation loss: 2.0359135737983127

Epoch: 6| Step: 7
Training loss: 2.3688840866088867
Validation loss: 2.0233294220380884

Epoch: 6| Step: 8
Training loss: 2.899466037750244
Validation loss: 2.031412829634964

Epoch: 6| Step: 9
Training loss: 2.172670602798462
Validation loss: 2.032812222357719

Epoch: 6| Step: 10
Training loss: 2.7123541831970215
Validation loss: 2.0359155401106803

Epoch: 6| Step: 11
Training loss: 2.4106829166412354
Validation loss: 2.0301826718033

Epoch: 6| Step: 12
Training loss: 2.0117597579956055
Validation loss: 2.0324299207297702

Epoch: 6| Step: 13
Training loss: 2.0290534496307373
Validation loss: 2.0118959360225226

Epoch: 99| Step: 0
Training loss: 2.520014524459839
Validation loss: 2.0031140773527083

Epoch: 6| Step: 1
Training loss: 2.546555519104004
Validation loss: 2.015234278094384

Epoch: 6| Step: 2
Training loss: 1.7916607856750488
Validation loss: 2.0022242094880793

Epoch: 6| Step: 3
Training loss: 1.5856324434280396
Validation loss: 2.009375197913057

Epoch: 6| Step: 4
Training loss: 2.3703250885009766
Validation loss: 2.012559167800411

Epoch: 6| Step: 5
Training loss: 2.681623935699463
Validation loss: 2.0200430385528074

Epoch: 6| Step: 6
Training loss: 1.8000761270523071
Validation loss: 2.0196812332317395

Epoch: 6| Step: 7
Training loss: 2.3661484718322754
Validation loss: 2.01702719606379

Epoch: 6| Step: 8
Training loss: 2.3102664947509766
Validation loss: 2.0360022616642777

Epoch: 6| Step: 9
Training loss: 2.132119655609131
Validation loss: 2.0511039098103843

Epoch: 6| Step: 10
Training loss: 2.0401082038879395
Validation loss: 2.0700891697278587

Epoch: 6| Step: 11
Training loss: 2.541048049926758
Validation loss: 2.0611489613850913

Epoch: 6| Step: 12
Training loss: 2.0711450576782227
Validation loss: 2.038621356410365

Epoch: 6| Step: 13
Training loss: 1.9678813219070435
Validation loss: 2.02512946051936

Epoch: 100| Step: 0
Training loss: 2.12508487701416
Validation loss: 2.0199680264278124

Epoch: 6| Step: 1
Training loss: 2.6528735160827637
Validation loss: 2.010130836117652

Epoch: 6| Step: 2
Training loss: 2.6101274490356445
Validation loss: 2.0086536048561014

Epoch: 6| Step: 3
Training loss: 1.847778558731079
Validation loss: 2.01081141220626

Epoch: 6| Step: 4
Training loss: 2.12674880027771
Validation loss: 2.012665980605669

Epoch: 6| Step: 5
Training loss: 2.281362533569336
Validation loss: 2.0197100767525296

Epoch: 6| Step: 6
Training loss: 1.8692035675048828
Validation loss: 2.0091280296284664

Epoch: 6| Step: 7
Training loss: 1.891492247581482
Validation loss: 2.013616669562555

Epoch: 6| Step: 8
Training loss: 2.2096927165985107
Validation loss: 2.0039388351542975

Epoch: 6| Step: 9
Training loss: 1.9967319965362549
Validation loss: 2.0167309725156395

Epoch: 6| Step: 10
Training loss: 1.9720838069915771
Validation loss: 2.0314986218688307

Epoch: 6| Step: 11
Training loss: 1.4627571105957031
Validation loss: 2.062016124366432

Epoch: 6| Step: 12
Training loss: 2.9289660453796387
Validation loss: 2.061648045816729

Epoch: 6| Step: 13
Training loss: 3.113341808319092
Validation loss: 2.08299115268133

Epoch: 101| Step: 0
Training loss: 1.6846743822097778
Validation loss: 2.1130142417005313

Epoch: 6| Step: 1
Training loss: 1.9530620574951172
Validation loss: 2.1218528798831406

Epoch: 6| Step: 2
Training loss: 2.2817742824554443
Validation loss: 2.1074019542304416

Epoch: 6| Step: 3
Training loss: 3.0552518367767334
Validation loss: 2.096722356734737

Epoch: 6| Step: 4
Training loss: 2.599135637283325
Validation loss: 2.092175947722568

Epoch: 6| Step: 5
Training loss: 2.3824033737182617
Validation loss: 2.0793462350804317

Epoch: 6| Step: 6
Training loss: 2.0073580741882324
Validation loss: 2.061422727441275

Epoch: 6| Step: 7
Training loss: 2.460745334625244
Validation loss: 2.052612607197095

Epoch: 6| Step: 8
Training loss: 2.1888656616210938
Validation loss: 2.02093259749874

Epoch: 6| Step: 9
Training loss: 1.9550416469573975
Validation loss: 2.015203597725079

Epoch: 6| Step: 10
Training loss: 1.8272695541381836
Validation loss: 1.9840462746158722

Epoch: 6| Step: 11
Training loss: 2.269925117492676
Validation loss: 1.9936828459462812

Epoch: 6| Step: 12
Training loss: 1.9608006477355957
Validation loss: 1.9972641993594427

Epoch: 6| Step: 13
Training loss: 1.985034465789795
Validation loss: 1.9927938599740305

Epoch: 102| Step: 0
Training loss: 2.913839340209961
Validation loss: 2.008572114411221

Epoch: 6| Step: 1
Training loss: 2.211564064025879
Validation loss: 2.021538906199958

Epoch: 6| Step: 2
Training loss: 2.617164134979248
Validation loss: 2.047006883928853

Epoch: 6| Step: 3
Training loss: 2.1749556064605713
Validation loss: 2.0608972939111854

Epoch: 6| Step: 4
Training loss: 2.03781795501709
Validation loss: 2.066808318579069

Epoch: 6| Step: 5
Training loss: 1.8848905563354492
Validation loss: 2.058425631574405

Epoch: 6| Step: 6
Training loss: 1.9386497735977173
Validation loss: 2.042796301585372

Epoch: 6| Step: 7
Training loss: 2.193857192993164
Validation loss: 2.0351608132803314

Epoch: 6| Step: 8
Training loss: 1.918168544769287
Validation loss: 2.0541458386246876

Epoch: 6| Step: 9
Training loss: 2.5621767044067383
Validation loss: 2.0550370524006505

Epoch: 6| Step: 10
Training loss: 2.221895456314087
Validation loss: 2.0589597045734362

Epoch: 6| Step: 11
Training loss: 2.5965237617492676
Validation loss: 2.0479602659902265

Epoch: 6| Step: 12
Training loss: 1.5148117542266846
Validation loss: 2.0624032892206663

Epoch: 6| Step: 13
Training loss: 1.8957123756408691
Validation loss: 2.121332614652572

Epoch: 103| Step: 0
Training loss: 2.6058473587036133
Validation loss: 2.1316110498161724

Epoch: 6| Step: 1
Training loss: 2.736414909362793
Validation loss: 2.1855178917607954

Epoch: 6| Step: 2
Training loss: 2.705709934234619
Validation loss: 2.24252180130251

Epoch: 6| Step: 3
Training loss: 1.8195595741271973
Validation loss: 2.229637094723281

Epoch: 6| Step: 4
Training loss: 2.075045585632324
Validation loss: 2.1285812060038247

Epoch: 6| Step: 5
Training loss: 1.7958115339279175
Validation loss: 2.0723623434702554

Epoch: 6| Step: 6
Training loss: 2.859400987625122
Validation loss: 2.020007856430546

Epoch: 6| Step: 7
Training loss: 2.005363941192627
Validation loss: 2.003040805939705

Epoch: 6| Step: 8
Training loss: 1.878244161605835
Validation loss: 2.0085809730714366

Epoch: 6| Step: 9
Training loss: 2.792692184448242
Validation loss: 2.0086455806609123

Epoch: 6| Step: 10
Training loss: 1.763465166091919
Validation loss: 2.0276994346290507

Epoch: 6| Step: 11
Training loss: 1.8399949073791504
Validation loss: 2.020862651127641

Epoch: 6| Step: 12
Training loss: 2.1239094734191895
Validation loss: 2.018957616180502

Epoch: 6| Step: 13
Training loss: 2.189833879470825
Validation loss: 2.0365114327399962

Epoch: 104| Step: 0
Training loss: 2.2895989418029785
Validation loss: 2.070745598885321

Epoch: 6| Step: 1
Training loss: 1.9220540523529053
Validation loss: 2.1426541292539207

Epoch: 6| Step: 2
Training loss: 2.4723172187805176
Validation loss: 2.1967704911385812

Epoch: 6| Step: 3
Training loss: 2.628434419631958
Validation loss: 2.2287236413648053

Epoch: 6| Step: 4
Training loss: 2.3884119987487793
Validation loss: 2.2226007151347336

Epoch: 6| Step: 5
Training loss: 2.081131935119629
Validation loss: 2.2028620345618135

Epoch: 6| Step: 6
Training loss: 1.914987564086914
Validation loss: 2.203153174410584

Epoch: 6| Step: 7
Training loss: 2.5423407554626465
Validation loss: 2.172489171387047

Epoch: 6| Step: 8
Training loss: 2.2336959838867188
Validation loss: 2.142648717408539

Epoch: 6| Step: 9
Training loss: 2.3026914596557617
Validation loss: 2.1189213773255706

Epoch: 6| Step: 10
Training loss: 2.110067844390869
Validation loss: 2.0638245587707846

Epoch: 6| Step: 11
Training loss: 1.7736462354660034
Validation loss: 2.014405071094472

Epoch: 6| Step: 12
Training loss: 1.574289083480835
Validation loss: 2.007100646213819

Epoch: 6| Step: 13
Training loss: 2.492072343826294
Validation loss: 1.9955016259224183

Epoch: 105| Step: 0
Training loss: 1.9185923337936401
Validation loss: 1.9984504920180126

Epoch: 6| Step: 1
Training loss: 2.410494565963745
Validation loss: 1.9946613311767578

Epoch: 6| Step: 2
Training loss: 2.36124587059021
Validation loss: 2.0150117617781445

Epoch: 6| Step: 3
Training loss: 2.0675299167633057
Validation loss: 2.022419209121376

Epoch: 6| Step: 4
Training loss: 2.657766103744507
Validation loss: 2.038480776612477

Epoch: 6| Step: 5
Training loss: 2.640899658203125
Validation loss: 2.042151294728761

Epoch: 6| Step: 6
Training loss: 1.9693431854248047
Validation loss: 2.061436806955645

Epoch: 6| Step: 7
Training loss: 1.0893088579177856
Validation loss: 2.0630565074182328

Epoch: 6| Step: 8
Training loss: 2.092008113861084
Validation loss: 2.083364675121923

Epoch: 6| Step: 9
Training loss: 2.2326364517211914
Validation loss: 2.0961487472698255

Epoch: 6| Step: 10
Training loss: 2.2721447944641113
Validation loss: 2.1118597343403804

Epoch: 6| Step: 11
Training loss: 2.1676840782165527
Validation loss: 2.109545450056753

Epoch: 6| Step: 12
Training loss: 2.201634645462036
Validation loss: 2.0884803982191187

Epoch: 6| Step: 13
Training loss: 1.6658377647399902
Validation loss: 2.058190171436597

Epoch: 106| Step: 0
Training loss: 1.7621362209320068
Validation loss: 2.029145258729176

Epoch: 6| Step: 1
Training loss: 1.9726223945617676
Validation loss: 2.033485879180252

Epoch: 6| Step: 2
Training loss: 2.0650694370269775
Validation loss: 2.0075659085345525

Epoch: 6| Step: 3
Training loss: 1.512939214706421
Validation loss: 2.0180465175259497

Epoch: 6| Step: 4
Training loss: 2.380486488342285
Validation loss: 2.0115352881852018

Epoch: 6| Step: 5
Training loss: 2.0638697147369385
Validation loss: 2.00759397527223

Epoch: 6| Step: 6
Training loss: 2.344075918197632
Validation loss: 1.995177343327512

Epoch: 6| Step: 7
Training loss: 2.643260955810547
Validation loss: 2.016541665600192

Epoch: 6| Step: 8
Training loss: 1.43038809299469
Validation loss: 2.027584110536883

Epoch: 6| Step: 9
Training loss: 3.3044776916503906
Validation loss: 2.039698261086659

Epoch: 6| Step: 10
Training loss: 1.736299991607666
Validation loss: 2.044416654494501

Epoch: 6| Step: 11
Training loss: 2.2568202018737793
Validation loss: 2.049149486326402

Epoch: 6| Step: 12
Training loss: 2.160735607147217
Validation loss: 2.0096565549091627

Epoch: 6| Step: 13
Training loss: 1.7665016651153564
Validation loss: 2.013411045074463

Epoch: 107| Step: 0
Training loss: 2.1380317211151123
Validation loss: 1.9994926709000782

Epoch: 6| Step: 1
Training loss: 2.1047415733337402
Validation loss: 1.9930506265291603

Epoch: 6| Step: 2
Training loss: 1.4800995588302612
Validation loss: 1.9787319565332064

Epoch: 6| Step: 3
Training loss: 1.693110704421997
Validation loss: 1.9792824842596566

Epoch: 6| Step: 4
Training loss: 2.96932315826416
Validation loss: 1.9974803258013982

Epoch: 6| Step: 5
Training loss: 2.7846877574920654
Validation loss: 1.992081715214637

Epoch: 6| Step: 6
Training loss: 2.159027099609375
Validation loss: 2.004851964212233

Epoch: 6| Step: 7
Training loss: 2.4893856048583984
Validation loss: 2.019860940594827

Epoch: 6| Step: 8
Training loss: 2.215552568435669
Validation loss: 2.0400345504924817

Epoch: 6| Step: 9
Training loss: 1.656891107559204
Validation loss: 2.0705176373963714

Epoch: 6| Step: 10
Training loss: 1.8602056503295898
Validation loss: 2.070985318512045

Epoch: 6| Step: 11
Training loss: 2.159261703491211
Validation loss: 2.0895955818955616

Epoch: 6| Step: 12
Training loss: 1.2897708415985107
Validation loss: 2.0968454153307023

Epoch: 6| Step: 13
Training loss: 2.4636497497558594
Validation loss: 2.03583675302485

Epoch: 108| Step: 0
Training loss: 1.9669922590255737
Validation loss: 2.0082096745890956

Epoch: 6| Step: 1
Training loss: 1.9433765411376953
Validation loss: 2.0023079469639766

Epoch: 6| Step: 2
Training loss: 1.8829338550567627
Validation loss: 2.0001463044074272

Epoch: 6| Step: 3
Training loss: 1.8948932886123657
Validation loss: 2.004187713387192

Epoch: 6| Step: 4
Training loss: 2.0039079189300537
Validation loss: 1.9994881870926067

Epoch: 6| Step: 5
Training loss: 1.9579545259475708
Validation loss: 2.0166179236545356

Epoch: 6| Step: 6
Training loss: 2.21761417388916
Validation loss: 2.0144579308007353

Epoch: 6| Step: 7
Training loss: 2.3190555572509766
Validation loss: 2.0339532667590725

Epoch: 6| Step: 8
Training loss: 2.696411609649658
Validation loss: 2.063728235101187

Epoch: 6| Step: 9
Training loss: 2.3491344451904297
Validation loss: 2.0799374477837675

Epoch: 6| Step: 10
Training loss: 2.2334465980529785
Validation loss: 2.0725646095891155

Epoch: 6| Step: 11
Training loss: 1.2438077926635742
Validation loss: 2.0934157115156933

Epoch: 6| Step: 12
Training loss: 1.6581627130508423
Validation loss: 2.0902869650112685

Epoch: 6| Step: 13
Training loss: 3.6361935138702393
Validation loss: 2.104400313028725

Epoch: 109| Step: 0
Training loss: 1.7431858777999878
Validation loss: 2.1171426798707698

Epoch: 6| Step: 1
Training loss: 2.2368106842041016
Validation loss: 2.1007591857705066

Epoch: 6| Step: 2
Training loss: 1.9815948009490967
Validation loss: 2.1101935871185793

Epoch: 6| Step: 3
Training loss: 1.6055634021759033
Validation loss: 2.101704999964724

Epoch: 6| Step: 4
Training loss: 2.42075777053833
Validation loss: 2.072289598885403

Epoch: 6| Step: 5
Training loss: 2.455038547515869
Validation loss: 2.0834563111746185

Epoch: 6| Step: 6
Training loss: 1.9318952560424805
Validation loss: 2.087715624481119

Epoch: 6| Step: 7
Training loss: 2.164458751678467
Validation loss: 2.1156388098193752

Epoch: 6| Step: 8
Training loss: 2.3179845809936523
Validation loss: 2.1039080286538727

Epoch: 6| Step: 9
Training loss: 2.0382232666015625
Validation loss: 2.06695637395305

Epoch: 6| Step: 10
Training loss: 2.423631429672241
Validation loss: 2.040019340412591

Epoch: 6| Step: 11
Training loss: 1.9225943088531494
Validation loss: 2.0365907030720867

Epoch: 6| Step: 12
Training loss: 1.8537436723709106
Validation loss: 2.0348375048688663

Epoch: 6| Step: 13
Training loss: 1.9842156171798706
Validation loss: 2.0183436729574717

Epoch: 110| Step: 0
Training loss: 2.5662879943847656
Validation loss: 2.0378698789945213

Epoch: 6| Step: 1
Training loss: 2.4994091987609863
Validation loss: 2.0400486300068517

Epoch: 6| Step: 2
Training loss: 2.1259076595306396
Validation loss: 2.0534410656139417

Epoch: 6| Step: 3
Training loss: 2.0077438354492188
Validation loss: 2.0663139204825125

Epoch: 6| Step: 4
Training loss: 1.9816951751708984
Validation loss: 2.084181733028863

Epoch: 6| Step: 5
Training loss: 1.2397631406784058
Validation loss: 2.111147875426918

Epoch: 6| Step: 6
Training loss: 2.2061777114868164
Validation loss: 2.144903882857292

Epoch: 6| Step: 7
Training loss: 2.3043289184570312
Validation loss: 2.1488782052070863

Epoch: 6| Step: 8
Training loss: 2.441150665283203
Validation loss: 2.154337244649087

Epoch: 6| Step: 9
Training loss: 1.6951861381530762
Validation loss: 2.0992812430986794

Epoch: 6| Step: 10
Training loss: 1.8826286792755127
Validation loss: 2.05961589659414

Epoch: 6| Step: 11
Training loss: 1.6022416353225708
Validation loss: 2.0387853435290757

Epoch: 6| Step: 12
Training loss: 2.7061045169830322
Validation loss: 2.019857216906804

Epoch: 6| Step: 13
Training loss: 2.2830569744110107
Validation loss: 2.013100148529135

Epoch: 111| Step: 0
Training loss: 2.587813377380371
Validation loss: 1.996202689345165

Epoch: 6| Step: 1
Training loss: 1.710423231124878
Validation loss: 1.9983738981267458

Epoch: 6| Step: 2
Training loss: 1.688103437423706
Validation loss: 2.00132816965862

Epoch: 6| Step: 3
Training loss: 2.4829366207122803
Validation loss: 2.0070752918079333

Epoch: 6| Step: 4
Training loss: 1.6415917873382568
Validation loss: 2.0141278492507113

Epoch: 6| Step: 5
Training loss: 2.1079626083374023
Validation loss: 2.032306742924516

Epoch: 6| Step: 6
Training loss: 2.051623821258545
Validation loss: 2.05922584508055

Epoch: 6| Step: 7
Training loss: 2.198620557785034
Validation loss: 2.0683889094219414

Epoch: 6| Step: 8
Training loss: 2.530700206756592
Validation loss: 2.086070760603874

Epoch: 6| Step: 9
Training loss: 1.960561990737915
Validation loss: 2.120881087036543

Epoch: 6| Step: 10
Training loss: 1.8823139667510986
Validation loss: 2.140875498453776

Epoch: 6| Step: 11
Training loss: 2.875819206237793
Validation loss: 2.1744234536283757

Epoch: 6| Step: 12
Training loss: 1.5617456436157227
Validation loss: 2.0922976450253556

Epoch: 6| Step: 13
Training loss: 1.7725478410720825
Validation loss: 2.056922274251138

Epoch: 112| Step: 0
Training loss: 2.5023045539855957
Validation loss: 2.040033326354078

Epoch: 6| Step: 1
Training loss: 2.02315354347229
Validation loss: 2.01075836407241

Epoch: 6| Step: 2
Training loss: 1.9380258321762085
Validation loss: 2.0259862715198147

Epoch: 6| Step: 3
Training loss: 2.5855894088745117
Validation loss: 2.026716063099523

Epoch: 6| Step: 4
Training loss: 1.8835861682891846
Validation loss: 2.0294382392719226

Epoch: 6| Step: 5
Training loss: 1.8926446437835693
Validation loss: 2.0383350951697237

Epoch: 6| Step: 6
Training loss: 2.4494152069091797
Validation loss: 2.0418887881822485

Epoch: 6| Step: 7
Training loss: 2.1675519943237305
Validation loss: 2.064127504184682

Epoch: 6| Step: 8
Training loss: 1.7628889083862305
Validation loss: 2.076838477965324

Epoch: 6| Step: 9
Training loss: 1.5276949405670166
Validation loss: 2.0808037147727063

Epoch: 6| Step: 10
Training loss: 1.708387851715088
Validation loss: 2.095001735994893

Epoch: 6| Step: 11
Training loss: 1.949495553970337
Validation loss: 2.090940829246275

Epoch: 6| Step: 12
Training loss: 2.1014559268951416
Validation loss: 2.0940049335520756

Epoch: 6| Step: 13
Training loss: 2.6748266220092773
Validation loss: 2.0764419442863873

Epoch: 113| Step: 0
Training loss: 2.590066909790039
Validation loss: 2.0573268910889984

Epoch: 6| Step: 1
Training loss: 2.058793783187866
Validation loss: 2.058077850649434

Epoch: 6| Step: 2
Training loss: 1.2793262004852295
Validation loss: 2.0687011134239937

Epoch: 6| Step: 3
Training loss: 1.841158390045166
Validation loss: 2.0501696217444634

Epoch: 6| Step: 4
Training loss: 2.540774345397949
Validation loss: 2.0613652839455554

Epoch: 6| Step: 5
Training loss: 1.806680679321289
Validation loss: 2.09769199227774

Epoch: 6| Step: 6
Training loss: 2.0108981132507324
Validation loss: 2.149908044004953

Epoch: 6| Step: 7
Training loss: 2.29702091217041
Validation loss: 2.1665729271468295

Epoch: 6| Step: 8
Training loss: 1.4862844944000244
Validation loss: 2.143237417744052

Epoch: 6| Step: 9
Training loss: 2.467306137084961
Validation loss: 2.1113114062175957

Epoch: 6| Step: 10
Training loss: 2.2304883003234863
Validation loss: 2.0774271052370787

Epoch: 6| Step: 11
Training loss: 1.8465524911880493
Validation loss: 2.046527013983778

Epoch: 6| Step: 12
Training loss: 1.7752861976623535
Validation loss: 2.0212966883054344

Epoch: 6| Step: 13
Training loss: 2.2641470432281494
Validation loss: 2.015049725450495

Epoch: 114| Step: 0
Training loss: 2.479764223098755
Validation loss: 2.0095189886708416

Epoch: 6| Step: 1
Training loss: 1.9044198989868164
Validation loss: 2.011556403611296

Epoch: 6| Step: 2
Training loss: 1.8959150314331055
Validation loss: 2.010463337744436

Epoch: 6| Step: 3
Training loss: 1.6000382900238037
Validation loss: 2.0330689671219035

Epoch: 6| Step: 4
Training loss: 2.342374324798584
Validation loss: 2.0493241125537502

Epoch: 6| Step: 5
Training loss: 1.9434924125671387
Validation loss: 2.051721179357139

Epoch: 6| Step: 6
Training loss: 1.709230899810791
Validation loss: 2.0596615729793424

Epoch: 6| Step: 7
Training loss: 1.6032761335372925
Validation loss: 2.06457043463184

Epoch: 6| Step: 8
Training loss: 1.7537285089492798
Validation loss: 2.051669692480436

Epoch: 6| Step: 9
Training loss: 2.371490955352783
Validation loss: 2.0781273944403535

Epoch: 6| Step: 10
Training loss: 1.9712128639221191
Validation loss: 2.0818088951931206

Epoch: 6| Step: 11
Training loss: 2.2357349395751953
Validation loss: 2.0676243023205827

Epoch: 6| Step: 12
Training loss: 2.5255613327026367
Validation loss: 2.038135709301118

Epoch: 6| Step: 13
Training loss: 1.3827269077301025
Validation loss: 2.0539321386685936

Epoch: 115| Step: 0
Training loss: 1.3015711307525635
Validation loss: 2.046105513008692

Epoch: 6| Step: 1
Training loss: 2.1731646060943604
Validation loss: 2.0715118928622176

Epoch: 6| Step: 2
Training loss: 1.8203123807907104
Validation loss: 2.129230349294601

Epoch: 6| Step: 3
Training loss: 2.681267261505127
Validation loss: 2.2283142484644407

Epoch: 6| Step: 4
Training loss: 2.2192654609680176
Validation loss: 2.262703222613181

Epoch: 6| Step: 5
Training loss: 2.0383124351501465
Validation loss: 2.219217413215227

Epoch: 6| Step: 6
Training loss: 1.47245454788208
Validation loss: 2.162793092830207

Epoch: 6| Step: 7
Training loss: 1.853193998336792
Validation loss: 2.1179418294660506

Epoch: 6| Step: 8
Training loss: 2.064878225326538
Validation loss: 2.0834094119328324

Epoch: 6| Step: 9
Training loss: 1.6119362115859985
Validation loss: 2.06107577969951

Epoch: 6| Step: 10
Training loss: 2.2982616424560547
Validation loss: 2.0489511400140743

Epoch: 6| Step: 11
Training loss: 2.1623988151550293
Validation loss: 2.0440670059573267

Epoch: 6| Step: 12
Training loss: 2.191445827484131
Validation loss: 2.0520128998705136

Epoch: 6| Step: 13
Training loss: 3.001492500305176
Validation loss: 2.039768247194188

Epoch: 116| Step: 0
Training loss: 1.6207971572875977
Validation loss: 2.0432230580237603

Epoch: 6| Step: 1
Training loss: 1.7382583618164062
Validation loss: 2.0375862865037817

Epoch: 6| Step: 2
Training loss: 2.1333155632019043
Validation loss: 2.04835194541562

Epoch: 6| Step: 3
Training loss: 2.687561273574829
Validation loss: 2.044960750046597

Epoch: 6| Step: 4
Training loss: 2.1538422107696533
Validation loss: 2.0563218260324128

Epoch: 6| Step: 5
Training loss: 2.4392693042755127
Validation loss: 2.0565971918003534

Epoch: 6| Step: 6
Training loss: 1.5360336303710938
Validation loss: 2.047685043786162

Epoch: 6| Step: 7
Training loss: 2.0837783813476562
Validation loss: 2.0597061572536344

Epoch: 6| Step: 8
Training loss: 1.7389209270477295
Validation loss: 2.06311430469636

Epoch: 6| Step: 9
Training loss: 2.032083749771118
Validation loss: 2.07938680982077

Epoch: 6| Step: 10
Training loss: 1.8233247995376587
Validation loss: 2.0831640202512025

Epoch: 6| Step: 11
Training loss: 1.5938646793365479
Validation loss: 2.078089698668449

Epoch: 6| Step: 12
Training loss: 2.16060209274292
Validation loss: 2.1040469651581137

Epoch: 6| Step: 13
Training loss: 1.955863118171692
Validation loss: 2.085911262419916

Epoch: 117| Step: 0
Training loss: 2.216686725616455
Validation loss: 2.1075888782419185

Epoch: 6| Step: 1
Training loss: 2.0332775115966797
Validation loss: 2.103917044977988

Epoch: 6| Step: 2
Training loss: 1.8808457851409912
Validation loss: 2.1217708203100387

Epoch: 6| Step: 3
Training loss: 1.8824574947357178
Validation loss: 2.1139672417794504

Epoch: 6| Step: 4
Training loss: 1.9467471837997437
Validation loss: 2.1224786543077037

Epoch: 6| Step: 5
Training loss: 2.3077619075775146
Validation loss: 2.1258595771687006

Epoch: 6| Step: 6
Training loss: 2.407419443130493
Validation loss: 2.1133755432662142

Epoch: 6| Step: 7
Training loss: 1.9362950325012207
Validation loss: 2.0599372592023624

Epoch: 6| Step: 8
Training loss: 1.7068965435028076
Validation loss: 2.025772443381689

Epoch: 6| Step: 9
Training loss: 1.8332141637802124
Validation loss: 2.0327779708370084

Epoch: 6| Step: 10
Training loss: 1.2822681665420532
Validation loss: 2.0258836694943008

Epoch: 6| Step: 11
Training loss: 1.9856117963790894
Validation loss: 2.049038901123949

Epoch: 6| Step: 12
Training loss: 2.231675624847412
Validation loss: 2.0994737994286323

Epoch: 6| Step: 13
Training loss: 2.0140609741210938
Validation loss: 2.1364323169954362

Epoch: 118| Step: 0
Training loss: 2.63000750541687
Validation loss: 2.219900490135275

Epoch: 6| Step: 1
Training loss: 1.8585710525512695
Validation loss: 2.327602812038955

Epoch: 6| Step: 2
Training loss: 2.6637215614318848
Validation loss: 2.37113158933578

Epoch: 6| Step: 3
Training loss: 2.326643943786621
Validation loss: 2.3130978166416125

Epoch: 6| Step: 4
Training loss: 1.885867714881897
Validation loss: 2.2154670940932406

Epoch: 6| Step: 5
Training loss: 2.02042293548584
Validation loss: 2.127436348187026

Epoch: 6| Step: 6
Training loss: 1.9493427276611328
Validation loss: 2.078795281789636

Epoch: 6| Step: 7
Training loss: 1.9199607372283936
Validation loss: 2.0040850306069977

Epoch: 6| Step: 8
Training loss: 1.5161614418029785
Validation loss: 1.9851203964602562

Epoch: 6| Step: 9
Training loss: 2.6388649940490723
Validation loss: 1.987343216455111

Epoch: 6| Step: 10
Training loss: 1.8138973712921143
Validation loss: 1.9792357260181057

Epoch: 6| Step: 11
Training loss: 2.236219882965088
Validation loss: 1.9918258292700655

Epoch: 6| Step: 12
Training loss: 2.1633753776550293
Validation loss: 1.9928822017485095

Epoch: 6| Step: 13
Training loss: 1.4498088359832764
Validation loss: 2.007778427934134

Epoch: 119| Step: 0
Training loss: 1.6952967643737793
Validation loss: 2.0194019963664394

Epoch: 6| Step: 1
Training loss: 1.989190697669983
Validation loss: 2.0512910760859007

Epoch: 6| Step: 2
Training loss: 1.432600736618042
Validation loss: 2.0607192131780807

Epoch: 6| Step: 3
Training loss: 1.713227391242981
Validation loss: 2.1022376962887344

Epoch: 6| Step: 4
Training loss: 1.816654086112976
Validation loss: 2.1600262913652646

Epoch: 6| Step: 5
Training loss: 2.126526117324829
Validation loss: 2.204147561903923

Epoch: 6| Step: 6
Training loss: 1.9677574634552002
Validation loss: 2.2078710563721193

Epoch: 6| Step: 7
Training loss: 2.0956242084503174
Validation loss: 2.1875345245484383

Epoch: 6| Step: 8
Training loss: 2.3798303604125977
Validation loss: 2.1524624734796505

Epoch: 6| Step: 9
Training loss: 2.521713972091675
Validation loss: 2.1149130482827463

Epoch: 6| Step: 10
Training loss: 2.0508604049682617
Validation loss: 2.0823624890337706

Epoch: 6| Step: 11
Training loss: 1.633276343345642
Validation loss: 2.07900329302716

Epoch: 6| Step: 12
Training loss: 2.4647328853607178
Validation loss: 2.0400638323958202

Epoch: 6| Step: 13
Training loss: 1.9354701042175293
Validation loss: 2.018209849634478

Epoch: 120| Step: 0
Training loss: 1.8246053457260132
Validation loss: 1.9876463541420557

Epoch: 6| Step: 1
Training loss: 2.2842345237731934
Validation loss: 1.9893106516971384

Epoch: 6| Step: 2
Training loss: 1.6469213962554932
Validation loss: 2.002105971818329

Epoch: 6| Step: 3
Training loss: 1.9006959199905396
Validation loss: 2.017895815193012

Epoch: 6| Step: 4
Training loss: 1.7350168228149414
Validation loss: 2.013557610973235

Epoch: 6| Step: 5
Training loss: 1.7951266765594482
Validation loss: 2.031036207752843

Epoch: 6| Step: 6
Training loss: 1.9513626098632812
Validation loss: 2.02112732138685

Epoch: 6| Step: 7
Training loss: 2.3372583389282227
Validation loss: 1.988342826084424

Epoch: 6| Step: 8
Training loss: 1.4493169784545898
Validation loss: 1.988969692619898

Epoch: 6| Step: 9
Training loss: 2.2737207412719727
Validation loss: 1.9925434538113174

Epoch: 6| Step: 10
Training loss: 2.5326895713806152
Validation loss: 2.0110454328598513

Epoch: 6| Step: 11
Training loss: 1.7396094799041748
Validation loss: 2.0326008207054547

Epoch: 6| Step: 12
Training loss: 1.4646238088607788
Validation loss: 2.0502687833642446

Epoch: 6| Step: 13
Training loss: 2.5271432399749756
Validation loss: 2.0791939432903

Epoch: 121| Step: 0
Training loss: 1.4095606803894043
Validation loss: 2.15492776004217

Epoch: 6| Step: 1
Training loss: 1.5617671012878418
Validation loss: 2.219670359806348

Epoch: 6| Step: 2
Training loss: 2.893967628479004
Validation loss: 2.2857474973124843

Epoch: 6| Step: 3
Training loss: 1.8142554759979248
Validation loss: 2.2961774385103615

Epoch: 6| Step: 4
Training loss: 2.1236157417297363
Validation loss: 2.2540116181937595

Epoch: 6| Step: 5
Training loss: 2.370845317840576
Validation loss: 2.183037578418691

Epoch: 6| Step: 6
Training loss: 1.8857464790344238
Validation loss: 2.1307089482584307

Epoch: 6| Step: 7
Training loss: 2.101243019104004
Validation loss: 2.0918809957401727

Epoch: 6| Step: 8
Training loss: 1.7492287158966064
Validation loss: 2.0573634703954062

Epoch: 6| Step: 9
Training loss: 2.1977715492248535
Validation loss: 2.0405674403713596

Epoch: 6| Step: 10
Training loss: 1.035954236984253
Validation loss: 2.041431327019968

Epoch: 6| Step: 11
Training loss: 1.6937766075134277
Validation loss: 2.0276266836350962

Epoch: 6| Step: 12
Training loss: 2.0915682315826416
Validation loss: 2.0242637434313373

Epoch: 6| Step: 13
Training loss: 2.361240863800049
Validation loss: 2.0120120561251076

Epoch: 122| Step: 0
Training loss: 1.8460514545440674
Validation loss: 2.0046359595432075

Epoch: 6| Step: 1
Training loss: 2.0813422203063965
Validation loss: 1.986295195036037

Epoch: 6| Step: 2
Training loss: 1.828473448753357
Validation loss: 1.9985151572894024

Epoch: 6| Step: 3
Training loss: 1.8269201517105103
Validation loss: 2.0029574235280356

Epoch: 6| Step: 4
Training loss: 2.2745954990386963
Validation loss: 2.0017578524927937

Epoch: 6| Step: 5
Training loss: 1.7746199369430542
Validation loss: 2.0217924964043403

Epoch: 6| Step: 6
Training loss: 1.8574975728988647
Validation loss: 2.0316619719228437

Epoch: 6| Step: 7
Training loss: 1.9738709926605225
Validation loss: 2.0658717488729827

Epoch: 6| Step: 8
Training loss: 1.8035050630569458
Validation loss: 2.0969380870942147

Epoch: 6| Step: 9
Training loss: 1.9130960702896118
Validation loss: 2.1084826466857747

Epoch: 6| Step: 10
Training loss: 1.810882568359375
Validation loss: 2.1097715644426245

Epoch: 6| Step: 11
Training loss: 1.3477022647857666
Validation loss: 2.100560913803757

Epoch: 6| Step: 12
Training loss: 2.6685690879821777
Validation loss: 2.0918818699416293

Epoch: 6| Step: 13
Training loss: 2.441936492919922
Validation loss: 2.091591488930487

Epoch: 123| Step: 0
Training loss: 2.4513723850250244
Validation loss: 2.0786128287674277

Epoch: 6| Step: 1
Training loss: 1.185948371887207
Validation loss: 2.0837612818646174

Epoch: 6| Step: 2
Training loss: 1.7147537469863892
Validation loss: 2.0682964658224456

Epoch: 6| Step: 3
Training loss: 2.0690760612487793
Validation loss: 2.080576476230416

Epoch: 6| Step: 4
Training loss: 2.154388427734375
Validation loss: 2.0765694161897064

Epoch: 6| Step: 5
Training loss: 2.168060302734375
Validation loss: 2.0552872791085193

Epoch: 6| Step: 6
Training loss: 2.1421585083007812
Validation loss: 2.0539085557383876

Epoch: 6| Step: 7
Training loss: 1.0914595127105713
Validation loss: 2.0723286777414303

Epoch: 6| Step: 8
Training loss: 1.9067000150680542
Validation loss: 2.0746037011505454

Epoch: 6| Step: 9
Training loss: 3.0794754028320312
Validation loss: 2.0728262893615232

Epoch: 6| Step: 10
Training loss: 1.7846723794937134
Validation loss: 2.0987417313360397

Epoch: 6| Step: 11
Training loss: 1.4901187419891357
Validation loss: 2.0895256175789783

Epoch: 6| Step: 12
Training loss: 1.6639575958251953
Validation loss: 2.0814685949715237

Epoch: 6| Step: 13
Training loss: 1.9067366123199463
Validation loss: 2.0555900143038843

Epoch: 124| Step: 0
Training loss: 1.8147456645965576
Validation loss: 2.054806045306626

Epoch: 6| Step: 1
Training loss: 2.5819568634033203
Validation loss: 2.0558835075747584

Epoch: 6| Step: 2
Training loss: 1.204593300819397
Validation loss: 2.0545668576353338

Epoch: 6| Step: 3
Training loss: 1.5244197845458984
Validation loss: 2.0726456629332675

Epoch: 6| Step: 4
Training loss: 2.39792537689209
Validation loss: 2.0812562050357943

Epoch: 6| Step: 5
Training loss: 1.676607608795166
Validation loss: 2.095140746844712

Epoch: 6| Step: 6
Training loss: 1.8700391054153442
Validation loss: 2.1160523686357724

Epoch: 6| Step: 7
Training loss: 2.1371283531188965
Validation loss: 2.1291194205643027

Epoch: 6| Step: 8
Training loss: 2.197373390197754
Validation loss: 2.1155845554926063

Epoch: 6| Step: 9
Training loss: 1.6347668170928955
Validation loss: 2.0880021279858005

Epoch: 6| Step: 10
Training loss: 2.4134974479675293
Validation loss: 2.0560844636732534

Epoch: 6| Step: 11
Training loss: 1.4639254808425903
Validation loss: 2.0130478412874284

Epoch: 6| Step: 12
Training loss: 1.725937008857727
Validation loss: 1.9927463877585627

Epoch: 6| Step: 13
Training loss: 1.2679133415222168
Validation loss: 2.028722258024318

Epoch: 125| Step: 0
Training loss: 1.8136168718338013
Validation loss: 2.0229424956024333

Epoch: 6| Step: 1
Training loss: 1.940830945968628
Validation loss: 2.022794387673819

Epoch: 6| Step: 2
Training loss: 2.069838047027588
Validation loss: 2.0290721513891734

Epoch: 6| Step: 3
Training loss: 1.9782084226608276
Validation loss: 2.03890033178432

Epoch: 6| Step: 4
Training loss: 1.9329845905303955
Validation loss: 2.036986143358292

Epoch: 6| Step: 5
Training loss: 1.6009272336959839
Validation loss: 2.0295261644547984

Epoch: 6| Step: 6
Training loss: 1.470439076423645
Validation loss: 2.0461201257603143

Epoch: 6| Step: 7
Training loss: 2.29252290725708
Validation loss: 2.046009527739658

Epoch: 6| Step: 8
Training loss: 2.426499128341675
Validation loss: 2.047144728322183

Epoch: 6| Step: 9
Training loss: 1.9551985263824463
Validation loss: 2.0672177832613707

Epoch: 6| Step: 10
Training loss: 2.0017921924591064
Validation loss: 2.0602986979228195

Epoch: 6| Step: 11
Training loss: 1.8466954231262207
Validation loss: 2.052837775599572

Epoch: 6| Step: 12
Training loss: 1.6364161968231201
Validation loss: 2.0466801863844677

Epoch: 6| Step: 13
Training loss: 1.0555648803710938
Validation loss: 2.0103308308509087

Epoch: 126| Step: 0
Training loss: 2.5768351554870605
Validation loss: 2.025984025770618

Epoch: 6| Step: 1
Training loss: 1.5842862129211426
Validation loss: 2.0018125605839554

Epoch: 6| Step: 2
Training loss: 1.320796251296997
Validation loss: 2.006962146810306

Epoch: 6| Step: 3
Training loss: 2.1508359909057617
Validation loss: 2.005258863972079

Epoch: 6| Step: 4
Training loss: 2.3725643157958984
Validation loss: 2.0089595471659014

Epoch: 6| Step: 5
Training loss: 2.187958240509033
Validation loss: 2.028376581848309

Epoch: 6| Step: 6
Training loss: 1.628302812576294
Validation loss: 2.03893881715754

Epoch: 6| Step: 7
Training loss: 1.7619175910949707
Validation loss: 2.0428768537377797

Epoch: 6| Step: 8
Training loss: 1.0301710367202759
Validation loss: 2.038293711600765

Epoch: 6| Step: 9
Training loss: 1.2994519472122192
Validation loss: 2.033208909855094

Epoch: 6| Step: 10
Training loss: 2.564915657043457
Validation loss: 2.0572114682966665

Epoch: 6| Step: 11
Training loss: 1.6472091674804688
Validation loss: 2.0633665592439714

Epoch: 6| Step: 12
Training loss: 1.613235354423523
Validation loss: 2.1123386557384203

Epoch: 6| Step: 13
Training loss: 1.3967264890670776
Validation loss: 2.1905030768404723

Epoch: 127| Step: 0
Training loss: 2.3470468521118164
Validation loss: 2.2563908023218953

Epoch: 6| Step: 1
Training loss: 2.586122989654541
Validation loss: 2.2353526776836765

Epoch: 6| Step: 2
Training loss: 1.950629472732544
Validation loss: 2.1968974682592575

Epoch: 6| Step: 3
Training loss: 1.6594061851501465
Validation loss: 2.1338194698415776

Epoch: 6| Step: 4
Training loss: 2.270294189453125
Validation loss: 2.090665077650419

Epoch: 6| Step: 5
Training loss: 1.92698335647583
Validation loss: 2.073068190646428

Epoch: 6| Step: 6
Training loss: 1.9397162199020386
Validation loss: 2.04018110229123

Epoch: 6| Step: 7
Training loss: 1.7005842924118042
Validation loss: 2.019438175744908

Epoch: 6| Step: 8
Training loss: 1.765690803527832
Validation loss: 1.986973931712489

Epoch: 6| Step: 9
Training loss: 1.5435059070587158
Validation loss: 1.988102920593754

Epoch: 6| Step: 10
Training loss: 1.1079262495040894
Validation loss: 1.9917697060492732

Epoch: 6| Step: 11
Training loss: 1.9827725887298584
Validation loss: 2.0095236006603447

Epoch: 6| Step: 12
Training loss: 1.1450293064117432
Validation loss: 2.0273368025338776

Epoch: 6| Step: 13
Training loss: 2.077223300933838
Validation loss: 2.0545532652126846

Epoch: 128| Step: 0
Training loss: 1.8748464584350586
Validation loss: 2.0846895376841226

Epoch: 6| Step: 1
Training loss: 1.68598210811615
Validation loss: 2.1124686502641246

Epoch: 6| Step: 2
Training loss: 1.3778107166290283
Validation loss: 2.1191831711799867

Epoch: 6| Step: 3
Training loss: 1.5052101612091064
Validation loss: 2.0980111014458442

Epoch: 6| Step: 4
Training loss: 1.6661564111709595
Validation loss: 2.058129334962496

Epoch: 6| Step: 5
Training loss: 2.051598072052002
Validation loss: 2.064891534466897

Epoch: 6| Step: 6
Training loss: 1.738823652267456
Validation loss: 2.0579100449879966

Epoch: 6| Step: 7
Training loss: 2.5824427604675293
Validation loss: 2.042681183866275

Epoch: 6| Step: 8
Training loss: 1.7268680334091187
Validation loss: 2.0456621211062194

Epoch: 6| Step: 9
Training loss: 1.7866162061691284
Validation loss: 2.0254544442699802

Epoch: 6| Step: 10
Training loss: 2.0180532932281494
Validation loss: 2.0512680571566344

Epoch: 6| Step: 11
Training loss: 2.183420181274414
Validation loss: 2.0237242226959555

Epoch: 6| Step: 12
Training loss: 1.4563277959823608
Validation loss: 2.0360925261692335

Epoch: 6| Step: 13
Training loss: 2.0143508911132812
Validation loss: 2.0409907089766635

Epoch: 129| Step: 0
Training loss: 2.2955522537231445
Validation loss: 2.0875490403944448

Epoch: 6| Step: 1
Training loss: 1.7427895069122314
Validation loss: 2.110482470963591

Epoch: 6| Step: 2
Training loss: 1.6372430324554443
Validation loss: 2.1325318608232724

Epoch: 6| Step: 3
Training loss: 2.328670024871826
Validation loss: 2.1377896826754332

Epoch: 6| Step: 4
Training loss: 1.0777920484542847
Validation loss: 2.1756794196303173

Epoch: 6| Step: 5
Training loss: 1.3377033472061157
Validation loss: 2.1533967756455943

Epoch: 6| Step: 6
Training loss: 2.0158257484436035
Validation loss: 2.130913690854144

Epoch: 6| Step: 7
Training loss: 2.0389862060546875
Validation loss: 2.132661296475318

Epoch: 6| Step: 8
Training loss: 1.3149890899658203
Validation loss: 2.103938336013466

Epoch: 6| Step: 9
Training loss: 1.7760111093521118
Validation loss: 2.0836805605119273

Epoch: 6| Step: 10
Training loss: 1.3707356452941895
Validation loss: 2.0578140315189155

Epoch: 6| Step: 11
Training loss: 1.9475476741790771
Validation loss: 2.0266612396445325

Epoch: 6| Step: 12
Training loss: 2.065420150756836
Validation loss: 2.0137188332055205

Epoch: 6| Step: 13
Training loss: 2.368866205215454
Validation loss: 2.003016648753997

Epoch: 130| Step: 0
Training loss: 2.0519211292266846
Validation loss: 1.9838307416567238

Epoch: 6| Step: 1
Training loss: 1.5885881185531616
Validation loss: 1.9916872991028653

Epoch: 6| Step: 2
Training loss: 1.7231197357177734
Validation loss: 1.9900407739864883

Epoch: 6| Step: 3
Training loss: 2.437309503555298
Validation loss: 2.0027250282226072

Epoch: 6| Step: 4
Training loss: 1.5765800476074219
Validation loss: 2.03303002542065

Epoch: 6| Step: 5
Training loss: 1.4701459407806396
Validation loss: 2.055106794962319

Epoch: 6| Step: 6
Training loss: 1.856273889541626
Validation loss: 2.088804893596198

Epoch: 6| Step: 7
Training loss: 1.233752727508545
Validation loss: 2.1056652056273593

Epoch: 6| Step: 8
Training loss: 0.9925892949104309
Validation loss: 2.1247121441748833

Epoch: 6| Step: 9
Training loss: 2.290752649307251
Validation loss: 2.121502696826894

Epoch: 6| Step: 10
Training loss: 2.239269256591797
Validation loss: 2.1098217566808066

Epoch: 6| Step: 11
Training loss: 1.929352045059204
Validation loss: 2.0860072156434417

Epoch: 6| Step: 12
Training loss: 1.9863700866699219
Validation loss: 2.0689891640857985

Epoch: 6| Step: 13
Training loss: 1.9433165788650513
Validation loss: 2.0255514985771588

Epoch: 131| Step: 0
Training loss: 1.5440820455551147
Validation loss: 2.040325126340312

Epoch: 6| Step: 1
Training loss: 1.8739677667617798
Validation loss: 2.0494939819458993

Epoch: 6| Step: 2
Training loss: 1.9638456106185913
Validation loss: 2.056196149959359

Epoch: 6| Step: 3
Training loss: 1.555678367614746
Validation loss: 2.059501496694421

Epoch: 6| Step: 4
Training loss: 1.9631125926971436
Validation loss: 2.0666470207193846

Epoch: 6| Step: 5
Training loss: 1.5214108228683472
Validation loss: 2.073916244250472

Epoch: 6| Step: 6
Training loss: 1.740124225616455
Validation loss: 2.073771022981213

Epoch: 6| Step: 7
Training loss: 1.4094805717468262
Validation loss: 2.063618552300238

Epoch: 6| Step: 8
Training loss: 2.41757869720459
Validation loss: 2.0624468403477825

Epoch: 6| Step: 9
Training loss: 1.7610207796096802
Validation loss: 2.0933520435005106

Epoch: 6| Step: 10
Training loss: 2.4154469966888428
Validation loss: 2.107052873539668

Epoch: 6| Step: 11
Training loss: 1.833359956741333
Validation loss: 2.1301798589767946

Epoch: 6| Step: 12
Training loss: 1.5923811197280884
Validation loss: 2.1157836491061794

Epoch: 6| Step: 13
Training loss: 1.2694249153137207
Validation loss: 2.0949517091115317

Epoch: 132| Step: 0
Training loss: 1.567757248878479
Validation loss: 2.0869382273766304

Epoch: 6| Step: 1
Training loss: 1.8471670150756836
Validation loss: 2.041975744308964

Epoch: 6| Step: 2
Training loss: 1.4761605262756348
Validation loss: 2.013148315491215

Epoch: 6| Step: 3
Training loss: 1.5008559226989746
Validation loss: 2.0016047826377292

Epoch: 6| Step: 4
Training loss: 2.275158643722534
Validation loss: 2.0026230658254316

Epoch: 6| Step: 5
Training loss: 2.042177200317383
Validation loss: 1.9990874951885593

Epoch: 6| Step: 6
Training loss: 2.014470338821411
Validation loss: 2.008813045358145

Epoch: 6| Step: 7
Training loss: 1.2224528789520264
Validation loss: 2.0124013347010457

Epoch: 6| Step: 8
Training loss: 1.6049318313598633
Validation loss: 2.019943191159156

Epoch: 6| Step: 9
Training loss: 1.9083043336868286
Validation loss: 2.043875111046658

Epoch: 6| Step: 10
Training loss: 0.9292266964912415
Validation loss: 2.0584828007605767

Epoch: 6| Step: 11
Training loss: 1.9998964071273804
Validation loss: 2.087418422904066

Epoch: 6| Step: 12
Training loss: 1.5857982635498047
Validation loss: 2.101372234282955

Epoch: 6| Step: 13
Training loss: 2.19120192527771
Validation loss: 2.1344465017318726

Epoch: 133| Step: 0
Training loss: 2.1816954612731934
Validation loss: 2.152013204431021

Epoch: 6| Step: 1
Training loss: 1.6045130491256714
Validation loss: 2.1293482857365764

Epoch: 6| Step: 2
Training loss: 1.2625892162322998
Validation loss: 2.0871702906905965

Epoch: 6| Step: 3
Training loss: 1.9944055080413818
Validation loss: 2.0637476521153606

Epoch: 6| Step: 4
Training loss: 1.789160966873169
Validation loss: 2.0370926395539315

Epoch: 6| Step: 5
Training loss: 2.4648420810699463
Validation loss: 2.009773700468002

Epoch: 6| Step: 6
Training loss: 1.2433602809906006
Validation loss: 2.013691007450063

Epoch: 6| Step: 7
Training loss: 1.620028018951416
Validation loss: 2.0309618775562575

Epoch: 6| Step: 8
Training loss: 2.2072391510009766
Validation loss: 2.0485377798798265

Epoch: 6| Step: 9
Training loss: 1.1706122159957886
Validation loss: 2.0410122512489237

Epoch: 6| Step: 10
Training loss: 1.9565000534057617
Validation loss: 2.0505825152961155

Epoch: 6| Step: 11
Training loss: 0.7671005725860596
Validation loss: 2.0827616042988275

Epoch: 6| Step: 12
Training loss: 1.808091163635254
Validation loss: 2.0983141135143977

Epoch: 6| Step: 13
Training loss: 2.0583691596984863
Validation loss: 2.115598419661163

Epoch: 134| Step: 0
Training loss: 1.7902024984359741
Validation loss: 2.1187031704892396

Epoch: 6| Step: 1
Training loss: 1.114320993423462
Validation loss: 2.103114287058512

Epoch: 6| Step: 2
Training loss: 1.6603838205337524
Validation loss: 2.0902748415547032

Epoch: 6| Step: 3
Training loss: 2.246403694152832
Validation loss: 2.0479042606969036

Epoch: 6| Step: 4
Training loss: 2.137510299682617
Validation loss: 2.063447331869474

Epoch: 6| Step: 5
Training loss: 1.8069775104522705
Validation loss: 2.04581356048584

Epoch: 6| Step: 6
Training loss: 1.7459163665771484
Validation loss: 2.0462918050827517

Epoch: 6| Step: 7
Training loss: 1.9775729179382324
Validation loss: 2.053952063283613

Epoch: 6| Step: 8
Training loss: 1.6480185985565186
Validation loss: 2.032693455296178

Epoch: 6| Step: 9
Training loss: 1.2344200611114502
Validation loss: 2.0322192022877354

Epoch: 6| Step: 10
Training loss: 1.3423755168914795
Validation loss: 2.03193917582112

Epoch: 6| Step: 11
Training loss: 1.470781922340393
Validation loss: 2.050599067441879

Epoch: 6| Step: 12
Training loss: 1.6824541091918945
Validation loss: 2.021780042238133

Epoch: 6| Step: 13
Training loss: 1.9504168033599854
Validation loss: 2.0351888825816493

Epoch: 135| Step: 0
Training loss: 1.5744600296020508
Validation loss: 2.0117695844301613

Epoch: 6| Step: 1
Training loss: 1.758176326751709
Validation loss: 1.994904225872409

Epoch: 6| Step: 2
Training loss: 1.3851933479309082
Validation loss: 1.9960487452886437

Epoch: 6| Step: 3
Training loss: 1.3676426410675049
Validation loss: 2.003607702511613

Epoch: 6| Step: 4
Training loss: 1.981545090675354
Validation loss: 1.992400187318043

Epoch: 6| Step: 5
Training loss: 1.5624277591705322
Validation loss: 1.9943826544669367

Epoch: 6| Step: 6
Training loss: 1.7776504755020142
Validation loss: 1.9840677451061945

Epoch: 6| Step: 7
Training loss: 1.4548641443252563
Validation loss: 2.0004877544218496

Epoch: 6| Step: 8
Training loss: 1.9697239398956299
Validation loss: 2.0188812414805093

Epoch: 6| Step: 9
Training loss: 2.219452381134033
Validation loss: 2.0053215065310077

Epoch: 6| Step: 10
Training loss: 1.3408054113388062
Validation loss: 2.015293445638431

Epoch: 6| Step: 11
Training loss: 1.5030075311660767
Validation loss: 1.9987134023379254

Epoch: 6| Step: 12
Training loss: 1.747050404548645
Validation loss: 2.004069250117066

Epoch: 6| Step: 13
Training loss: 1.3476333618164062
Validation loss: 2.012778200129027

Epoch: 136| Step: 0
Training loss: 1.3606650829315186
Validation loss: 2.0287540433227376

Epoch: 6| Step: 1
Training loss: 1.6858012676239014
Validation loss: 2.0315533876419067

Epoch: 6| Step: 2
Training loss: 2.24312424659729
Validation loss: 2.0533871817332443

Epoch: 6| Step: 3
Training loss: 1.538415551185608
Validation loss: 2.0465132459517448

Epoch: 6| Step: 4
Training loss: 1.259333848953247
Validation loss: 2.0583651655463764

Epoch: 6| Step: 5
Training loss: 2.1341214179992676
Validation loss: 2.0758868955796763

Epoch: 6| Step: 6
Training loss: 1.792053461074829
Validation loss: 2.0560274559964418

Epoch: 6| Step: 7
Training loss: 1.442784070968628
Validation loss: 2.0592330886471655

Epoch: 6| Step: 8
Training loss: 1.7274010181427002
Validation loss: 2.0306978776890743

Epoch: 6| Step: 9
Training loss: 2.370762825012207
Validation loss: 2.007784285852986

Epoch: 6| Step: 10
Training loss: 1.7340058088302612
Validation loss: 1.9945551567180182

Epoch: 6| Step: 11
Training loss: 0.8632029891014099
Validation loss: 1.995380134992702

Epoch: 6| Step: 12
Training loss: 1.0024638175964355
Validation loss: 2.0119649582011725

Epoch: 6| Step: 13
Training loss: 2.1015539169311523
Validation loss: 2.0360772609710693

Epoch: 137| Step: 0
Training loss: 2.0860800743103027
Validation loss: 2.0780012607574463

Epoch: 6| Step: 1
Training loss: 2.129643201828003
Validation loss: 2.0969173113505044

Epoch: 6| Step: 2
Training loss: 1.5933847427368164
Validation loss: 2.0942177528976114

Epoch: 6| Step: 3
Training loss: 1.3161835670471191
Validation loss: 2.081163811427291

Epoch: 6| Step: 4
Training loss: 1.1866875886917114
Validation loss: 2.043317461526522

Epoch: 6| Step: 5
Training loss: 1.4188458919525146
Validation loss: 2.019078923809913

Epoch: 6| Step: 6
Training loss: 1.940014123916626
Validation loss: 2.018580711016091

Epoch: 6| Step: 7
Training loss: 1.8394138813018799
Validation loss: 2.0084168436706706

Epoch: 6| Step: 8
Training loss: 1.6340177059173584
Validation loss: 2.003185975936151

Epoch: 6| Step: 9
Training loss: 1.0058871507644653
Validation loss: 2.0320313899747786

Epoch: 6| Step: 10
Training loss: 1.4993970394134521
Validation loss: 2.0368776782866447

Epoch: 6| Step: 11
Training loss: 1.2913306951522827
Validation loss: 2.0666530593749015

Epoch: 6| Step: 12
Training loss: 1.655051589012146
Validation loss: 2.079904774183868

Epoch: 6| Step: 13
Training loss: 2.7282299995422363
Validation loss: 2.110299471885927

Epoch: 138| Step: 0
Training loss: 0.9375478029251099
Validation loss: 2.128825626065654

Epoch: 6| Step: 1
Training loss: 1.9219739437103271
Validation loss: 2.1237315644500074

Epoch: 6| Step: 2
Training loss: 1.946624994277954
Validation loss: 2.0752969159874866

Epoch: 6| Step: 3
Training loss: 1.7059924602508545
Validation loss: 2.07489844804169

Epoch: 6| Step: 4
Training loss: 1.1991393566131592
Validation loss: 2.0447604707492295

Epoch: 6| Step: 5
Training loss: 1.3065764904022217
Validation loss: 2.0275144935936056

Epoch: 6| Step: 6
Training loss: 2.5431084632873535
Validation loss: 2.02472702405786

Epoch: 6| Step: 7
Training loss: 2.316525936126709
Validation loss: 2.0039131769569973

Epoch: 6| Step: 8
Training loss: 1.4104396104812622
Validation loss: 1.9703328314647879

Epoch: 6| Step: 9
Training loss: 1.54915189743042
Validation loss: 2.0162718014050554

Epoch: 6| Step: 10
Training loss: 1.5171430110931396
Validation loss: 1.9946386660298994

Epoch: 6| Step: 11
Training loss: 1.843508005142212
Validation loss: 2.0003852241782734

Epoch: 6| Step: 12
Training loss: 1.1315678358078003
Validation loss: 2.006532843394946

Epoch: 6| Step: 13
Training loss: 1.2466284036636353
Validation loss: 2.043417792166433

Epoch: 139| Step: 0
Training loss: 1.8896416425704956
Validation loss: 2.0821201609027002

Epoch: 6| Step: 1
Training loss: 2.052117347717285
Validation loss: 2.084668779885897

Epoch: 6| Step: 2
Training loss: 2.9329206943511963
Validation loss: 2.0732809433373074

Epoch: 6| Step: 3
Training loss: 1.1391814947128296
Validation loss: 2.055506529346589

Epoch: 6| Step: 4
Training loss: 1.990670919418335
Validation loss: 2.0415859350594143

Epoch: 6| Step: 5
Training loss: 0.9528958201408386
Validation loss: 2.0128003256295317

Epoch: 6| Step: 6
Training loss: 1.2433104515075684
Validation loss: 1.999846976290467

Epoch: 6| Step: 7
Training loss: 1.4102652072906494
Validation loss: 1.974615353409962

Epoch: 6| Step: 8
Training loss: 1.3022494316101074
Validation loss: 1.9692866392033075

Epoch: 6| Step: 9
Training loss: 1.509055733680725
Validation loss: 1.9754177754925144

Epoch: 6| Step: 10
Training loss: 2.0234837532043457
Validation loss: 1.9610668613064675

Epoch: 6| Step: 11
Training loss: 1.4445130825042725
Validation loss: 1.9830733909401843

Epoch: 6| Step: 12
Training loss: 1.1845173835754395
Validation loss: 1.9651556476469962

Epoch: 6| Step: 13
Training loss: 1.4203256368637085
Validation loss: 1.97539319017882

Epoch: 140| Step: 0
Training loss: 1.9217060804367065
Validation loss: 2.040847247646701

Epoch: 6| Step: 1
Training loss: 1.1704670190811157
Validation loss: 2.1240421251584123

Epoch: 6| Step: 2
Training loss: 1.753042459487915
Validation loss: 2.1294127715531217

Epoch: 6| Step: 3
Training loss: 1.4253323078155518
Validation loss: 2.1343908271481915

Epoch: 6| Step: 4
Training loss: 1.132406234741211
Validation loss: 2.0964294377193657

Epoch: 6| Step: 5
Training loss: 1.8928930759429932
Validation loss: 2.034830229256743

Epoch: 6| Step: 6
Training loss: 2.151580810546875
Validation loss: 1.997621472163867

Epoch: 6| Step: 7
Training loss: 1.2950870990753174
Validation loss: 1.980948975009303

Epoch: 6| Step: 8
Training loss: 1.5403010845184326
Validation loss: 1.9666334531640495

Epoch: 6| Step: 9
Training loss: 1.700993537902832
Validation loss: 1.964512235374861

Epoch: 6| Step: 10
Training loss: 1.3879735469818115
Validation loss: 1.9661155054646153

Epoch: 6| Step: 11
Training loss: 2.080049753189087
Validation loss: 1.9908841925282632

Epoch: 6| Step: 12
Training loss: 1.5582571029663086
Validation loss: 1.9921979852901992

Epoch: 6| Step: 13
Training loss: 1.495699405670166
Validation loss: 1.992871606221763

Epoch: 141| Step: 0
Training loss: 1.244539499282837
Validation loss: 2.032818070022009

Epoch: 6| Step: 1
Training loss: 1.077876329421997
Validation loss: 2.0511179406155824

Epoch: 6| Step: 2
Training loss: 1.9153156280517578
Validation loss: 2.0578882771153606

Epoch: 6| Step: 3
Training loss: 1.4578006267547607
Validation loss: 2.0750629414794264

Epoch: 6| Step: 4
Training loss: 1.1780070066452026
Validation loss: 2.095645304649107

Epoch: 6| Step: 5
Training loss: 1.530019760131836
Validation loss: 2.0782122919636388

Epoch: 6| Step: 6
Training loss: 1.2873806953430176
Validation loss: 2.0883909938155965

Epoch: 6| Step: 7
Training loss: 1.873376727104187
Validation loss: 2.0492616084314164

Epoch: 6| Step: 8
Training loss: 1.3823964595794678
Validation loss: 2.037575155176142

Epoch: 6| Step: 9
Training loss: 2.1956591606140137
Validation loss: 2.0153188500353085

Epoch: 6| Step: 10
Training loss: 1.9977096319198608
Validation loss: 2.0121617432563537

Epoch: 6| Step: 11
Training loss: 1.6431324481964111
Validation loss: 1.9898987829044301

Epoch: 6| Step: 12
Training loss: 1.625069499015808
Validation loss: 1.9826553034526047

Epoch: 6| Step: 13
Training loss: 1.2287644147872925
Validation loss: 1.967643271210373

Epoch: 142| Step: 0
Training loss: 2.126072883605957
Validation loss: 1.960091124298752

Epoch: 6| Step: 1
Training loss: 1.3523895740509033
Validation loss: 1.9779411067244828

Epoch: 6| Step: 2
Training loss: 1.5251121520996094
Validation loss: 1.956681574544599

Epoch: 6| Step: 3
Training loss: 1.2851670980453491
Validation loss: 1.958798695636052

Epoch: 6| Step: 4
Training loss: 1.7998261451721191
Validation loss: 1.9519925758402834

Epoch: 6| Step: 5
Training loss: 1.5145232677459717
Validation loss: 1.9735778275356497

Epoch: 6| Step: 6
Training loss: 0.9749350547790527
Validation loss: 1.977855792609594

Epoch: 6| Step: 7
Training loss: 1.3755379915237427
Validation loss: 1.9805503814451155

Epoch: 6| Step: 8
Training loss: 0.8871350288391113
Validation loss: 1.9941898981730144

Epoch: 6| Step: 9
Training loss: 1.5540417432785034
Validation loss: 1.9976178433305474

Epoch: 6| Step: 10
Training loss: 2.350254535675049
Validation loss: 2.004694031130883

Epoch: 6| Step: 11
Training loss: 1.3699533939361572
Validation loss: 1.9968130306531024

Epoch: 6| Step: 12
Training loss: 1.415758490562439
Validation loss: 2.007568367065922

Epoch: 6| Step: 13
Training loss: 1.9737184047698975
Validation loss: 1.9792697596293625

Epoch: 143| Step: 0
Training loss: 1.4417535066604614
Validation loss: 1.9874187028536232

Epoch: 6| Step: 1
Training loss: 1.5891547203063965
Validation loss: 1.9690486590067546

Epoch: 6| Step: 2
Training loss: 1.8583452701568604
Validation loss: 1.968477725982666

Epoch: 6| Step: 3
Training loss: 1.115027904510498
Validation loss: 1.9748605284639584

Epoch: 6| Step: 4
Training loss: 1.649627685546875
Validation loss: 1.9815070680392686

Epoch: 6| Step: 5
Training loss: 1.4606651067733765
Validation loss: 1.989145161003195

Epoch: 6| Step: 6
Training loss: 1.885857343673706
Validation loss: 1.9698072633435648

Epoch: 6| Step: 7
Training loss: 1.2721728086471558
Validation loss: 1.9905811279050765

Epoch: 6| Step: 8
Training loss: 1.8581511974334717
Validation loss: 2.0071683878539712

Epoch: 6| Step: 9
Training loss: 1.3519201278686523
Validation loss: 2.010355503328385

Epoch: 6| Step: 10
Training loss: 1.0139565467834473
Validation loss: 1.9952480792999268

Epoch: 6| Step: 11
Training loss: 1.4910879135131836
Validation loss: 1.991854936845841

Epoch: 6| Step: 12
Training loss: 1.3994927406311035
Validation loss: 1.9994773787836875

Epoch: 6| Step: 13
Training loss: 1.5457642078399658
Validation loss: 1.9934262767914803

Epoch: 144| Step: 0
Training loss: 1.8719881772994995
Validation loss: 1.9927211102618967

Epoch: 6| Step: 1
Training loss: 1.1464903354644775
Validation loss: 1.9654002894637406

Epoch: 6| Step: 2
Training loss: 1.5057227611541748
Validation loss: 1.9827284684745214

Epoch: 6| Step: 3
Training loss: 1.068964958190918
Validation loss: 1.9787332409171647

Epoch: 6| Step: 4
Training loss: 1.2948980331420898
Validation loss: 1.9732830716717629

Epoch: 6| Step: 5
Training loss: 2.2496442794799805
Validation loss: 1.9876304826428812

Epoch: 6| Step: 6
Training loss: 1.6515989303588867
Validation loss: 1.9599847332123788

Epoch: 6| Step: 7
Training loss: 1.8524255752563477
Validation loss: 1.985706977946784

Epoch: 6| Step: 8
Training loss: 1.2319915294647217
Validation loss: 1.9636747811430244

Epoch: 6| Step: 9
Training loss: 1.3954646587371826
Validation loss: 1.9720894239282096

Epoch: 6| Step: 10
Training loss: 1.3780287504196167
Validation loss: 1.9757313894969162

Epoch: 6| Step: 11
Training loss: 1.5055534839630127
Validation loss: 1.9504373406851163

Epoch: 6| Step: 12
Training loss: 1.0558507442474365
Validation loss: 1.931548906910804

Epoch: 6| Step: 13
Training loss: 1.4865477085113525
Validation loss: 1.9367414084813928

Epoch: 145| Step: 0
Training loss: 0.7430495023727417
Validation loss: 1.9484497936823035

Epoch: 6| Step: 1
Training loss: 1.767366647720337
Validation loss: 1.9422616727890507

Epoch: 6| Step: 2
Training loss: 1.037394404411316
Validation loss: 1.9326553652363438

Epoch: 6| Step: 3
Training loss: 1.509432077407837
Validation loss: 1.9294005645218717

Epoch: 6| Step: 4
Training loss: 1.1989076137542725
Validation loss: 1.9200213660476029

Epoch: 6| Step: 5
Training loss: 1.8797612190246582
Validation loss: 1.9261452869702411

Epoch: 6| Step: 6
Training loss: 1.5108556747436523
Validation loss: 1.9297864719103741

Epoch: 6| Step: 7
Training loss: 1.0948851108551025
Validation loss: 1.9679837739595802

Epoch: 6| Step: 8
Training loss: 0.8402799367904663
Validation loss: 1.941796233577113

Epoch: 6| Step: 9
Training loss: 1.711568832397461
Validation loss: 1.9391102239649782

Epoch: 6| Step: 10
Training loss: 1.6029014587402344
Validation loss: 1.941199041181995

Epoch: 6| Step: 11
Training loss: 1.4212933778762817
Validation loss: 1.9482603355120587

Epoch: 6| Step: 12
Training loss: 2.2102184295654297
Validation loss: 1.9447379240425684

Epoch: 6| Step: 13
Training loss: 1.9229397773742676
Validation loss: 1.955142705671249

Epoch: 146| Step: 0
Training loss: 1.4966297149658203
Validation loss: 1.9445436641734133

Epoch: 6| Step: 1
Training loss: 1.09553062915802
Validation loss: 1.974315163909748

Epoch: 6| Step: 2
Training loss: 0.7803950309753418
Validation loss: 2.001824750695177

Epoch: 6| Step: 3
Training loss: 1.5347340106964111
Validation loss: 2.0048477470233874

Epoch: 6| Step: 4
Training loss: 2.6337766647338867
Validation loss: 2.0103111267089844

Epoch: 6| Step: 5
Training loss: 1.6440463066101074
Validation loss: 2.0360846673288653

Epoch: 6| Step: 6
Training loss: 1.7463593482971191
Validation loss: 2.0753224742028022

Epoch: 6| Step: 7
Training loss: 1.4507136344909668
Validation loss: 2.06425985469613

Epoch: 6| Step: 8
Training loss: 0.931835412979126
Validation loss: 2.038772508662234

Epoch: 6| Step: 9
Training loss: 0.7715021967887878
Validation loss: 1.9752666104224421

Epoch: 6| Step: 10
Training loss: 1.67631196975708
Validation loss: 1.9618205754987654

Epoch: 6| Step: 11
Training loss: 1.7326321601867676
Validation loss: 1.9515866079638082

Epoch: 6| Step: 12
Training loss: 1.5126423835754395
Validation loss: 1.9566817539994434

Epoch: 6| Step: 13
Training loss: 1.602769374847412
Validation loss: 1.9615958493242982

Epoch: 147| Step: 0
Training loss: 1.3864006996154785
Validation loss: 1.9393309598327966

Epoch: 6| Step: 1
Training loss: 1.7818500995635986
Validation loss: 1.9770492853656891

Epoch: 6| Step: 2
Training loss: 1.7665047645568848
Validation loss: 2.0325625019688762

Epoch: 6| Step: 3
Training loss: 1.6472642421722412
Validation loss: 2.0751044006757837

Epoch: 6| Step: 4
Training loss: 1.4597856998443604
Validation loss: 2.082558669069762

Epoch: 6| Step: 5
Training loss: 1.3574553728103638
Validation loss: 2.0864834734188613

Epoch: 6| Step: 6
Training loss: 1.972717523574829
Validation loss: 2.064052762523774

Epoch: 6| Step: 7
Training loss: 1.1413369178771973
Validation loss: 2.02837787905047

Epoch: 6| Step: 8
Training loss: 1.243230938911438
Validation loss: 1.9861261703634774

Epoch: 6| Step: 9
Training loss: 2.1481735706329346
Validation loss: 1.9821051243812806

Epoch: 6| Step: 10
Training loss: 1.2203803062438965
Validation loss: 1.974684516588847

Epoch: 6| Step: 11
Training loss: 1.3460698127746582
Validation loss: 1.9770082555791384

Epoch: 6| Step: 12
Training loss: 0.967038631439209
Validation loss: 1.9947269373042609

Epoch: 6| Step: 13
Training loss: 1.2079622745513916
Validation loss: 1.9979629042328044

Epoch: 148| Step: 0
Training loss: 1.6885302066802979
Validation loss: 1.9941732498907274

Epoch: 6| Step: 1
Training loss: 1.00584077835083
Validation loss: 2.0253114264498473

Epoch: 6| Step: 2
Training loss: 1.052182674407959
Validation loss: 2.0350502639688473

Epoch: 6| Step: 3
Training loss: 1.4019885063171387
Validation loss: 2.0908822128849645

Epoch: 6| Step: 4
Training loss: 2.2045233249664307
Validation loss: 2.0597405792564474

Epoch: 6| Step: 5
Training loss: 1.9045689105987549
Validation loss: 1.9641068968721616

Epoch: 6| Step: 6
Training loss: 1.3145575523376465
Validation loss: 1.9304080240188106

Epoch: 6| Step: 7
Training loss: 1.6637649536132812
Validation loss: 1.9111182382029872

Epoch: 6| Step: 8
Training loss: 1.8668262958526611
Validation loss: 1.9358883442417267

Epoch: 6| Step: 9
Training loss: 1.456810712814331
Validation loss: 1.9342748195894304

Epoch: 6| Step: 10
Training loss: 1.4668514728546143
Validation loss: 1.9493832075467674

Epoch: 6| Step: 11
Training loss: 1.7196717262268066
Validation loss: 1.9584460784030218

Epoch: 6| Step: 12
Training loss: 1.2046003341674805
Validation loss: 1.9612250584428028

Epoch: 6| Step: 13
Training loss: 1.135109782218933
Validation loss: 1.9622693343829083

Epoch: 149| Step: 0
Training loss: 0.9789225459098816
Validation loss: 1.9826640082943825

Epoch: 6| Step: 1
Training loss: 0.940827488899231
Validation loss: 2.043359774415211

Epoch: 6| Step: 2
Training loss: 1.6114346981048584
Validation loss: 2.0867167301075433

Epoch: 6| Step: 3
Training loss: 2.1411383152008057
Validation loss: 2.1616574397651096

Epoch: 6| Step: 4
Training loss: 1.4369876384735107
Validation loss: 2.1816559119891097

Epoch: 6| Step: 5
Training loss: 1.4723758697509766
Validation loss: 2.165574050718738

Epoch: 6| Step: 6
Training loss: 1.542678713798523
Validation loss: 2.150211748256478

Epoch: 6| Step: 7
Training loss: 1.7529057264328003
Validation loss: 2.1546034697563416

Epoch: 6| Step: 8
Training loss: 1.164175033569336
Validation loss: 2.0806824481615456

Epoch: 6| Step: 9
Training loss: 1.259204626083374
Validation loss: 1.9937276083935973

Epoch: 6| Step: 10
Training loss: 0.8051080107688904
Validation loss: 1.9755866860830655

Epoch: 6| Step: 11
Training loss: 1.6883829832077026
Validation loss: 1.9558211782927155

Epoch: 6| Step: 12
Training loss: 2.3607337474823
Validation loss: 1.9436768703563239

Epoch: 6| Step: 13
Training loss: 2.039655923843384
Validation loss: 1.8939200934543405

Epoch: 150| Step: 0
Training loss: 1.2164549827575684
Validation loss: 1.881787443673739

Epoch: 6| Step: 1
Training loss: 1.7247154712677002
Validation loss: 1.85457779002446

Epoch: 6| Step: 2
Training loss: 1.26063871383667
Validation loss: 1.8662133229676114

Epoch: 6| Step: 3
Training loss: 2.082475185394287
Validation loss: 1.8711108007738668

Epoch: 6| Step: 4
Training loss: 1.6460436582565308
Validation loss: 1.8879414655828988

Epoch: 6| Step: 5
Training loss: 1.4671516418457031
Validation loss: 1.9120239916668142

Epoch: 6| Step: 6
Training loss: 1.4791655540466309
Validation loss: 1.8971258696689401

Epoch: 6| Step: 7
Training loss: 1.0240247249603271
Validation loss: 1.8941685435592488

Epoch: 6| Step: 8
Training loss: 1.474393606185913
Validation loss: 1.9026759157898605

Epoch: 6| Step: 9
Training loss: 1.3842291831970215
Validation loss: 1.8799350800052765

Epoch: 6| Step: 10
Training loss: 1.2167458534240723
Validation loss: 1.8895945010646698

Epoch: 6| Step: 11
Training loss: 1.7653238773345947
Validation loss: 1.8907864170689737

Epoch: 6| Step: 12
Training loss: 1.2502707242965698
Validation loss: 1.9354962892429803

Epoch: 6| Step: 13
Training loss: 1.5349922180175781
Validation loss: 1.917085354046155

Epoch: 151| Step: 0
Training loss: 1.6709342002868652
Validation loss: 1.9192688183117939

Epoch: 6| Step: 1
Training loss: 1.22050142288208
Validation loss: 1.9513548933049685

Epoch: 6| Step: 2
Training loss: 0.732321560382843
Validation loss: 1.960734317379613

Epoch: 6| Step: 3
Training loss: 1.2868797779083252
Validation loss: 1.9615383609648673

Epoch: 6| Step: 4
Training loss: 1.8981684446334839
Validation loss: 1.9687920462700628

Epoch: 6| Step: 5
Training loss: 1.488717794418335
Validation loss: 1.967997238200198

Epoch: 6| Step: 6
Training loss: 1.5211384296417236
Validation loss: 1.9520588074961016

Epoch: 6| Step: 7
Training loss: 1.565859079360962
Validation loss: 1.965754585881387

Epoch: 6| Step: 8
Training loss: 1.0392348766326904
Validation loss: 1.9783410372272614

Epoch: 6| Step: 9
Training loss: 1.7525229454040527
Validation loss: 1.9507176876068115

Epoch: 6| Step: 10
Training loss: 1.2219316959381104
Validation loss: 1.9442502452481178

Epoch: 6| Step: 11
Training loss: 1.584869384765625
Validation loss: 1.9316143989562988

Epoch: 6| Step: 12
Training loss: 0.9580647945404053
Validation loss: 1.926707120351894

Epoch: 6| Step: 13
Training loss: 1.811293125152588
Validation loss: 1.932611919218494

Epoch: 152| Step: 0
Training loss: 1.0158518552780151
Validation loss: 1.9312397510774675

Epoch: 6| Step: 1
Training loss: 1.240943431854248
Validation loss: 1.9518635067888486

Epoch: 6| Step: 2
Training loss: 1.862847924232483
Validation loss: 1.965318456772835

Epoch: 6| Step: 3
Training loss: 1.6386449337005615
Validation loss: 1.9726092969217608

Epoch: 6| Step: 4
Training loss: 1.0361781120300293
Validation loss: 1.9792279620324411

Epoch: 6| Step: 5
Training loss: 1.3308470249176025
Validation loss: 1.9646102536109187

Epoch: 6| Step: 6
Training loss: 1.275288462638855
Validation loss: 1.9754039126057779

Epoch: 6| Step: 7
Training loss: 1.4099647998809814
Validation loss: 1.9628488556031258

Epoch: 6| Step: 8
Training loss: 1.7446268796920776
Validation loss: 1.9910470324177896

Epoch: 6| Step: 9
Training loss: 1.5582945346832275
Validation loss: 1.9619326976037794

Epoch: 6| Step: 10
Training loss: 1.0859482288360596
Validation loss: 1.941555933285785

Epoch: 6| Step: 11
Training loss: 1.338963508605957
Validation loss: 1.9678569839846702

Epoch: 6| Step: 12
Training loss: 1.4978697299957275
Validation loss: 1.9426119571091027

Epoch: 6| Step: 13
Training loss: 1.0268372297286987
Validation loss: 1.9244668509370537

Epoch: 153| Step: 0
Training loss: 1.1694353818893433
Validation loss: 1.9431317916480444

Epoch: 6| Step: 1
Training loss: 1.2326856851577759
Validation loss: 1.9364694562009586

Epoch: 6| Step: 2
Training loss: 1.5906845331192017
Validation loss: 1.9356456277190999

Epoch: 6| Step: 3
Training loss: 1.0507358312606812
Validation loss: 1.9197227570318407

Epoch: 6| Step: 4
Training loss: 1.1881325244903564
Validation loss: 1.9093658706193328

Epoch: 6| Step: 5
Training loss: 1.430165410041809
Validation loss: 1.883141335620675

Epoch: 6| Step: 6
Training loss: 0.9539976119995117
Validation loss: 1.88572661594678

Epoch: 6| Step: 7
Training loss: 1.3005778789520264
Validation loss: 1.9202620842123543

Epoch: 6| Step: 8
Training loss: 1.373806118965149
Validation loss: 1.920821189880371

Epoch: 6| Step: 9
Training loss: 1.2714183330535889
Validation loss: 1.9079396545246083

Epoch: 6| Step: 10
Training loss: 1.301839828491211
Validation loss: 1.8899840898411249

Epoch: 6| Step: 11
Training loss: 1.6516376733779907
Validation loss: 1.906633657793845

Epoch: 6| Step: 12
Training loss: 1.6427969932556152
Validation loss: 1.891747659252536

Epoch: 6| Step: 13
Training loss: 1.5530056953430176
Validation loss: 1.9053836227745138

Epoch: 154| Step: 0
Training loss: 1.2505528926849365
Validation loss: 1.9340882532058223

Epoch: 6| Step: 1
Training loss: 1.5179917812347412
Validation loss: 1.9464718577682332

Epoch: 6| Step: 2
Training loss: 1.7020279169082642
Validation loss: 1.9381487625901417

Epoch: 6| Step: 3
Training loss: 1.0815808773040771
Validation loss: 1.9468703603231778

Epoch: 6| Step: 4
Training loss: 1.764617919921875
Validation loss: 1.953347998280679

Epoch: 6| Step: 5
Training loss: 1.4075926542282104
Validation loss: 1.9554806857980707

Epoch: 6| Step: 6
Training loss: 1.4875942468643188
Validation loss: 1.9487318505523026

Epoch: 6| Step: 7
Training loss: 0.960205614566803
Validation loss: 1.9444556672085997

Epoch: 6| Step: 8
Training loss: 1.395809531211853
Validation loss: 1.948252006243634

Epoch: 6| Step: 9
Training loss: 0.8675012588500977
Validation loss: 1.938600229960616

Epoch: 6| Step: 10
Training loss: 0.5596193671226501
Validation loss: 1.9444349183831164

Epoch: 6| Step: 11
Training loss: 1.0967633724212646
Validation loss: 1.974370171946864

Epoch: 6| Step: 12
Training loss: 1.4881517887115479
Validation loss: 1.940517625501079

Epoch: 6| Step: 13
Training loss: 2.586757183074951
Validation loss: 1.935146830415213

Epoch: 155| Step: 0
Training loss: 1.2374277114868164
Validation loss: 1.9367329010399439

Epoch: 6| Step: 1
Training loss: 0.8969404101371765
Validation loss: 1.9558666111320577

Epoch: 6| Step: 2
Training loss: 0.8473805785179138
Validation loss: 1.96486363744223

Epoch: 6| Step: 3
Training loss: 1.4295859336853027
Validation loss: 1.9615562026218702

Epoch: 6| Step: 4
Training loss: 1.1310133934020996
Validation loss: 1.9380954029739543

Epoch: 6| Step: 5
Training loss: 1.4922962188720703
Validation loss: 1.9381446710196875

Epoch: 6| Step: 6
Training loss: 1.4550682306289673
Validation loss: 1.9077950267381565

Epoch: 6| Step: 7
Training loss: 1.5974535942077637
Validation loss: 1.894539345977127

Epoch: 6| Step: 8
Training loss: 1.6543924808502197
Validation loss: 1.8894928911680817

Epoch: 6| Step: 9
Training loss: 1.5750207901000977
Validation loss: 1.890152536412721

Epoch: 6| Step: 10
Training loss: 1.5920078754425049
Validation loss: 1.8750804419158607

Epoch: 6| Step: 11
Training loss: 0.9482149481773376
Validation loss: 1.8589733646761986

Epoch: 6| Step: 12
Training loss: 1.4612011909484863
Validation loss: 1.8528838029471777

Epoch: 6| Step: 13
Training loss: 1.0042612552642822
Validation loss: 1.8462472590067054

Epoch: 156| Step: 0
Training loss: 1.4276721477508545
Validation loss: 1.8729961097881358

Epoch: 6| Step: 1
Training loss: 2.082583427429199
Validation loss: 1.8473402941098778

Epoch: 6| Step: 2
Training loss: 1.3912675380706787
Validation loss: 1.8914060131196053

Epoch: 6| Step: 3
Training loss: 2.092839002609253
Validation loss: 1.8986317983237646

Epoch: 6| Step: 4
Training loss: 0.9619163274765015
Validation loss: 1.9365710648157264

Epoch: 6| Step: 5
Training loss: 1.0901405811309814
Validation loss: 1.9157010355303365

Epoch: 6| Step: 6
Training loss: 0.8822222352027893
Validation loss: 1.9527060165200183

Epoch: 6| Step: 7
Training loss: 0.8721907138824463
Validation loss: 1.9980614492970128

Epoch: 6| Step: 8
Training loss: 1.326164960861206
Validation loss: 2.004816080934258

Epoch: 6| Step: 9
Training loss: 1.0646710395812988
Validation loss: 1.9838722623804563

Epoch: 6| Step: 10
Training loss: 1.3270037174224854
Validation loss: 1.935030270648259

Epoch: 6| Step: 11
Training loss: 1.8767898082733154
Validation loss: 1.891767042939381

Epoch: 6| Step: 12
Training loss: 1.046895980834961
Validation loss: 1.868217856653275

Epoch: 6| Step: 13
Training loss: 1.3725130558013916
Validation loss: 1.886535502890105

Epoch: 157| Step: 0
Training loss: 0.8595727682113647
Validation loss: 1.8612234028436805

Epoch: 6| Step: 1
Training loss: 1.780146598815918
Validation loss: 1.8401859011701358

Epoch: 6| Step: 2
Training loss: 1.6894303560256958
Validation loss: 1.8363815828036236

Epoch: 6| Step: 3
Training loss: 1.3513665199279785
Validation loss: 1.8595453077746975

Epoch: 6| Step: 4
Training loss: 1.0581690073013306
Validation loss: 1.8515111284871255

Epoch: 6| Step: 5
Training loss: 1.1708390712738037
Validation loss: 1.8394066787535144

Epoch: 6| Step: 6
Training loss: 0.7438379526138306
Validation loss: 1.86175750917004

Epoch: 6| Step: 7
Training loss: 1.7478848695755005
Validation loss: 1.890955291768556

Epoch: 6| Step: 8
Training loss: 1.3662303686141968
Validation loss: 1.881407231412908

Epoch: 6| Step: 9
Training loss: 1.2861340045928955
Validation loss: 1.8985029984545965

Epoch: 6| Step: 10
Training loss: 0.9922226667404175
Validation loss: 1.9659988931430283

Epoch: 6| Step: 11
Training loss: 0.9389795064926147
Validation loss: 1.971081413248534

Epoch: 6| Step: 12
Training loss: 1.6393845081329346
Validation loss: 1.9693310196681688

Epoch: 6| Step: 13
Training loss: 1.7132169008255005
Validation loss: 1.9690819389076644

Epoch: 158| Step: 0
Training loss: 1.5815857648849487
Validation loss: 1.9694350227232902

Epoch: 6| Step: 1
Training loss: 1.5591996908187866
Validation loss: 1.9693709317074026

Epoch: 6| Step: 2
Training loss: 0.7139014601707458
Validation loss: 1.977851075510825

Epoch: 6| Step: 3
Training loss: 1.1115987300872803
Validation loss: 1.9609048392183037

Epoch: 6| Step: 4
Training loss: 1.1010522842407227
Validation loss: 1.9193192220503283

Epoch: 6| Step: 5
Training loss: 1.390416145324707
Validation loss: 1.9451232341028029

Epoch: 6| Step: 6
Training loss: 1.1775482892990112
Validation loss: 1.9327368018447713

Epoch: 6| Step: 7
Training loss: 0.8322441577911377
Validation loss: 1.9254403550137755

Epoch: 6| Step: 8
Training loss: 1.08455228805542
Validation loss: 1.9294529538000784

Epoch: 6| Step: 9
Training loss: 2.0013489723205566
Validation loss: 1.9186363656033751

Epoch: 6| Step: 10
Training loss: 1.2647606134414673
Validation loss: 1.9170686621819772

Epoch: 6| Step: 11
Training loss: 1.0675476789474487
Validation loss: 1.923199333170409

Epoch: 6| Step: 12
Training loss: 1.5860899686813354
Validation loss: 1.913216176853385

Epoch: 6| Step: 13
Training loss: 1.587515950202942
Validation loss: 1.9155949174716909

Epoch: 159| Step: 0
Training loss: 0.9805383086204529
Validation loss: 1.9329934966179632

Epoch: 6| Step: 1
Training loss: 1.249952793121338
Validation loss: 1.9281299191136514

Epoch: 6| Step: 2
Training loss: 1.4310758113861084
Validation loss: 1.9560069550750077

Epoch: 6| Step: 3
Training loss: 1.7300786972045898
Validation loss: 1.9510008083876742

Epoch: 6| Step: 4
Training loss: 1.2410573959350586
Validation loss: 1.9116786551731888

Epoch: 6| Step: 5
Training loss: 1.3193857669830322
Validation loss: 1.8977388989540838

Epoch: 6| Step: 6
Training loss: 0.9622377157211304
Validation loss: 1.8897401440528132

Epoch: 6| Step: 7
Training loss: 1.2770862579345703
Validation loss: 1.909147935528909

Epoch: 6| Step: 8
Training loss: 0.8620090484619141
Validation loss: 1.904470779562509

Epoch: 6| Step: 9
Training loss: 1.193763256072998
Validation loss: 1.9315116251668623

Epoch: 6| Step: 10
Training loss: 1.1115212440490723
Validation loss: 1.9517344531192575

Epoch: 6| Step: 11
Training loss: 1.4554102420806885
Validation loss: 1.985307865245368

Epoch: 6| Step: 12
Training loss: 0.9522991180419922
Validation loss: 1.9955951218963952

Epoch: 6| Step: 13
Training loss: 2.102753162384033
Validation loss: 1.9814330018976682

Epoch: 160| Step: 0
Training loss: 1.7819023132324219
Validation loss: 1.975052523356612

Epoch: 6| Step: 1
Training loss: 1.4188463687896729
Validation loss: 1.9622709161491805

Epoch: 6| Step: 2
Training loss: 1.2719817161560059
Validation loss: 1.9688302983519852

Epoch: 6| Step: 3
Training loss: 1.7307612895965576
Validation loss: 1.918324548711059

Epoch: 6| Step: 4
Training loss: 1.1467032432556152
Validation loss: 1.9251555383846324

Epoch: 6| Step: 5
Training loss: 0.9042919874191284
Validation loss: 1.899586009722884

Epoch: 6| Step: 6
Training loss: 0.9946510791778564
Validation loss: 1.8707210145970827

Epoch: 6| Step: 7
Training loss: 2.009800910949707
Validation loss: 1.8966673561321792

Epoch: 6| Step: 8
Training loss: 0.9538843631744385
Validation loss: 1.8939556537135955

Epoch: 6| Step: 9
Training loss: 0.9583549499511719
Validation loss: 1.8894315073567052

Epoch: 6| Step: 10
Training loss: 0.9213881492614746
Validation loss: 1.871212658061776

Epoch: 6| Step: 11
Training loss: 0.772053062915802
Validation loss: 1.8811661043474752

Epoch: 6| Step: 12
Training loss: 0.8181899785995483
Validation loss: 1.9310224953518118

Epoch: 6| Step: 13
Training loss: 1.5123168230056763
Validation loss: 1.9995260777011994

Epoch: 161| Step: 0
Training loss: 1.4182007312774658
Validation loss: 2.0058293393863145

Epoch: 6| Step: 1
Training loss: 0.9225121140480042
Validation loss: 1.9681344878289007

Epoch: 6| Step: 2
Training loss: 1.0204888582229614
Validation loss: 1.9017857800247848

Epoch: 6| Step: 3
Training loss: 0.7897995710372925
Validation loss: 1.8670739589198944

Epoch: 6| Step: 4
Training loss: 0.9973635077476501
Validation loss: 1.8793256205897177

Epoch: 6| Step: 5
Training loss: 1.4959120750427246
Validation loss: 1.9125269484776322

Epoch: 6| Step: 6
Training loss: 1.2315164804458618
Validation loss: 1.875692908481885

Epoch: 6| Step: 7
Training loss: 1.17617666721344
Validation loss: 1.887257190160854

Epoch: 6| Step: 8
Training loss: 1.0284955501556396
Validation loss: 1.896815264096824

Epoch: 6| Step: 9
Training loss: 1.310504674911499
Validation loss: 1.8833445220865228

Epoch: 6| Step: 10
Training loss: 0.9592052698135376
Validation loss: 1.8751003562763173

Epoch: 6| Step: 11
Training loss: 1.8601179122924805
Validation loss: 1.9119882352890507

Epoch: 6| Step: 12
Training loss: 1.650868535041809
Validation loss: 1.9757787437849148

Epoch: 6| Step: 13
Training loss: 1.690689206123352
Validation loss: 1.9765019057899393

Epoch: 162| Step: 0
Training loss: 0.9943638443946838
Validation loss: 1.931685515629348

Epoch: 6| Step: 1
Training loss: 1.6011199951171875
Validation loss: 1.9006516779622724

Epoch: 6| Step: 2
Training loss: 0.8858010768890381
Validation loss: 1.8975753156087731

Epoch: 6| Step: 3
Training loss: 1.43638014793396
Validation loss: 1.9035449412561232

Epoch: 6| Step: 4
Training loss: 1.2739614248275757
Validation loss: 1.8760394627048123

Epoch: 6| Step: 5
Training loss: 1.2056916952133179
Validation loss: 1.8761856978939426

Epoch: 6| Step: 6
Training loss: 0.6811255216598511
Validation loss: 1.8672152475644184

Epoch: 6| Step: 7
Training loss: 1.3236509561538696
Validation loss: 1.8679723021804646

Epoch: 6| Step: 8
Training loss: 1.1888469457626343
Validation loss: 1.8573811246502785

Epoch: 6| Step: 9
Training loss: 1.1405692100524902
Validation loss: 1.87201819240406

Epoch: 6| Step: 10
Training loss: 1.4956555366516113
Validation loss: 1.8471890764851724

Epoch: 6| Step: 11
Training loss: 1.1322178840637207
Validation loss: 1.8719593824878815

Epoch: 6| Step: 12
Training loss: 1.7367088794708252
Validation loss: 1.8949995476712462

Epoch: 6| Step: 13
Training loss: 0.8775634765625
Validation loss: 1.9296795014412171

Epoch: 163| Step: 0
Training loss: 1.381392240524292
Validation loss: 1.973823651190727

Epoch: 6| Step: 1
Training loss: 1.6298224925994873
Validation loss: 1.9487551668638825

Epoch: 6| Step: 2
Training loss: 1.1487131118774414
Validation loss: 1.9274612767722017

Epoch: 6| Step: 3
Training loss: 1.5258933305740356
Validation loss: 1.9582474667538878

Epoch: 6| Step: 4
Training loss: 1.1419428586959839
Validation loss: 1.9323713599994619

Epoch: 6| Step: 5
Training loss: 0.7488678693771362
Validation loss: 1.9430573345512472

Epoch: 6| Step: 6
Training loss: 1.0123217105865479
Validation loss: 1.9352997233790736

Epoch: 6| Step: 7
Training loss: 1.4735132455825806
Validation loss: 1.9052154223124187

Epoch: 6| Step: 8
Training loss: 1.2322087287902832
Validation loss: 1.8588950710911905

Epoch: 6| Step: 9
Training loss: 1.5111615657806396
Validation loss: 1.8526311510352678

Epoch: 6| Step: 10
Training loss: 1.2678401470184326
Validation loss: 1.8698941738374772

Epoch: 6| Step: 11
Training loss: 0.914387583732605
Validation loss: 1.845441270900029

Epoch: 6| Step: 12
Training loss: 1.051503300666809
Validation loss: 1.8484607012041154

Epoch: 6| Step: 13
Training loss: 0.9198221564292908
Validation loss: 1.854828808897285

Epoch: 164| Step: 0
Training loss: 1.099601149559021
Validation loss: 1.8748209694380402

Epoch: 6| Step: 1
Training loss: 1.8279461860656738
Validation loss: 1.8957074329417238

Epoch: 6| Step: 2
Training loss: 1.0098273754119873
Validation loss: 1.899352373615388

Epoch: 6| Step: 3
Training loss: 1.4722425937652588
Validation loss: 1.9255536499843802

Epoch: 6| Step: 4
Training loss: 1.0328896045684814
Validation loss: 1.9014900627956595

Epoch: 6| Step: 5
Training loss: 1.5125010013580322
Validation loss: 1.882586895778615

Epoch: 6| Step: 6
Training loss: 1.029498815536499
Validation loss: 1.8316313348790652

Epoch: 6| Step: 7
Training loss: 0.9778813719749451
Validation loss: 1.7953705133930329

Epoch: 6| Step: 8
Training loss: 1.137689232826233
Validation loss: 1.8150741579712077

Epoch: 6| Step: 9
Training loss: 1.3771579265594482
Validation loss: 1.8300422737675328

Epoch: 6| Step: 10
Training loss: 0.8141930103302002
Validation loss: 1.8151950220907889

Epoch: 6| Step: 11
Training loss: 1.3359994888305664
Validation loss: 1.8096008890418596

Epoch: 6| Step: 12
Training loss: 1.4245275259017944
Validation loss: 1.8337457872206164

Epoch: 6| Step: 13
Training loss: 0.8091171383857727
Validation loss: 1.858794564841896

Epoch: 165| Step: 0
Training loss: 1.2638641595840454
Validation loss: 1.900560776392619

Epoch: 6| Step: 1
Training loss: 1.120808482170105
Validation loss: 1.9133623543606009

Epoch: 6| Step: 2
Training loss: 0.9836369752883911
Validation loss: 1.8843364715576172

Epoch: 6| Step: 3
Training loss: 0.9055162668228149
Validation loss: 1.8806226535509991

Epoch: 6| Step: 4
Training loss: 1.0133581161499023
Validation loss: 1.9177207459685623

Epoch: 6| Step: 5
Training loss: 1.5580651760101318
Validation loss: 1.8959865967432659

Epoch: 6| Step: 6
Training loss: 1.4175128936767578
Validation loss: 1.8628881131449053

Epoch: 6| Step: 7
Training loss: 1.205481767654419
Validation loss: 1.8723270764914892

Epoch: 6| Step: 8
Training loss: 0.7672922611236572
Validation loss: 1.8667617164632326

Epoch: 6| Step: 9
Training loss: 1.428830623626709
Validation loss: 1.916967402222336

Epoch: 6| Step: 10
Training loss: 1.1065125465393066
Validation loss: 1.9738645835589337

Epoch: 6| Step: 11
Training loss: 1.4591459035873413
Validation loss: 2.018145174108526

Epoch: 6| Step: 12
Training loss: 1.1755485534667969
Validation loss: 2.0154166708710375

Epoch: 6| Step: 13
Training loss: 0.9317707419395447
Validation loss: 1.9461476136279363

Epoch: 166| Step: 0
Training loss: 0.8587599992752075
Validation loss: 1.9870425936996297

Epoch: 6| Step: 1
Training loss: 1.2869209051132202
Validation loss: 1.9540080870351484

Epoch: 6| Step: 2
Training loss: 1.7460602521896362
Validation loss: 1.9024990476587766

Epoch: 6| Step: 3
Training loss: 1.5286152362823486
Validation loss: 1.89185639350645

Epoch: 6| Step: 4
Training loss: 1.2536863088607788
Validation loss: 1.8632423390624344

Epoch: 6| Step: 5
Training loss: 0.7100852727890015
Validation loss: 1.8898205026503532

Epoch: 6| Step: 6
Training loss: 0.9506627321243286
Validation loss: 1.9165387512535177

Epoch: 6| Step: 7
Training loss: 1.2003189325332642
Validation loss: 1.919860593734249

Epoch: 6| Step: 8
Training loss: 1.5250407457351685
Validation loss: 1.9219612254891345

Epoch: 6| Step: 9
Training loss: 1.226975917816162
Validation loss: 1.9279503207052908

Epoch: 6| Step: 10
Training loss: 0.5619069933891296
Validation loss: 2.018314310299453

Epoch: 6| Step: 11
Training loss: 1.025733232498169
Validation loss: 2.084626172178535

Epoch: 6| Step: 12
Training loss: 1.5411113500595093
Validation loss: 2.105394535167243

Epoch: 6| Step: 13
Training loss: 0.476336807012558
Validation loss: 2.1061810062777613

Epoch: 167| Step: 0
Training loss: 0.6021161079406738
Validation loss: 2.066435101211712

Epoch: 6| Step: 1
Training loss: 1.1535544395446777
Validation loss: 2.018335735926064

Epoch: 6| Step: 2
Training loss: 1.4603872299194336
Validation loss: 2.001089490869994

Epoch: 6| Step: 3
Training loss: 1.612290620803833
Validation loss: 1.9389836057539909

Epoch: 6| Step: 4
Training loss: 1.3529319763183594
Validation loss: 1.9485212500377367

Epoch: 6| Step: 5
Training loss: 1.6520835161209106
Validation loss: 1.9431005767596665

Epoch: 6| Step: 6
Training loss: 0.966616153717041
Validation loss: 1.921895469388654

Epoch: 6| Step: 7
Training loss: 1.715062141418457
Validation loss: 1.916846111256589

Epoch: 6| Step: 8
Training loss: 1.33302640914917
Validation loss: 1.9320704167889011

Epoch: 6| Step: 9
Training loss: 1.0355675220489502
Validation loss: 1.9042796242621638

Epoch: 6| Step: 10
Training loss: 0.7850469350814819
Validation loss: 1.9274305605119275

Epoch: 6| Step: 11
Training loss: 0.731270968914032
Validation loss: 1.962271790350637

Epoch: 6| Step: 12
Training loss: 0.6440781354904175
Validation loss: 1.9854543311621553

Epoch: 6| Step: 13
Training loss: 1.5360134840011597
Validation loss: 2.0072395186270438

Epoch: 168| Step: 0
Training loss: 1.5916101932525635
Validation loss: 2.0602362745551654

Epoch: 6| Step: 1
Training loss: 0.6975678205490112
Validation loss: 2.0304519091883013

Epoch: 6| Step: 2
Training loss: 0.7185454368591309
Validation loss: 1.9797130656498734

Epoch: 6| Step: 3
Training loss: 1.1515295505523682
Validation loss: 1.923106639615951

Epoch: 6| Step: 4
Training loss: 1.0772584676742554
Validation loss: 1.9183538267689366

Epoch: 6| Step: 5
Training loss: 1.407717227935791
Validation loss: 1.9263205733350528

Epoch: 6| Step: 6
Training loss: 1.2689765691757202
Validation loss: 1.9269715073288127

Epoch: 6| Step: 7
Training loss: 1.039562463760376
Validation loss: 1.9055377180858324

Epoch: 6| Step: 8
Training loss: 0.6898398399353027
Validation loss: 1.8780019206385459

Epoch: 6| Step: 9
Training loss: 1.2149858474731445
Validation loss: 1.89310194600013

Epoch: 6| Step: 10
Training loss: 1.252976894378662
Validation loss: 1.860527237256368

Epoch: 6| Step: 11
Training loss: 1.0112192630767822
Validation loss: 1.8741889051211778

Epoch: 6| Step: 12
Training loss: 1.2208516597747803
Validation loss: 1.8516095428056614

Epoch: 6| Step: 13
Training loss: 0.458600252866745
Validation loss: 1.851445100640738

Epoch: 169| Step: 0
Training loss: 0.8942419290542603
Validation loss: 1.8462030746603524

Epoch: 6| Step: 1
Training loss: 1.3186068534851074
Validation loss: 1.8511090996444866

Epoch: 6| Step: 2
Training loss: 0.6125563979148865
Validation loss: 1.812859131443885

Epoch: 6| Step: 3
Training loss: 0.9342247247695923
Validation loss: 1.8307557106018066

Epoch: 6| Step: 4
Training loss: 1.722877025604248
Validation loss: 1.8575523412355812

Epoch: 6| Step: 5
Training loss: 0.5394620299339294
Validation loss: 1.9037846531919254

Epoch: 6| Step: 6
Training loss: 1.3137842416763306
Validation loss: 1.9247678377295052

Epoch: 6| Step: 7
Training loss: 0.9505068063735962
Validation loss: 1.9471797250932263

Epoch: 6| Step: 8
Training loss: 1.6212596893310547
Validation loss: 1.9523678723201956

Epoch: 6| Step: 9
Training loss: 1.1888766288757324
Validation loss: 1.9889050696485786

Epoch: 6| Step: 10
Training loss: 1.0614635944366455
Validation loss: 1.9774195148098854

Epoch: 6| Step: 11
Training loss: 0.9986327290534973
Validation loss: 1.9533212774543351

Epoch: 6| Step: 12
Training loss: 0.8683813810348511
Validation loss: 1.8950171727006153

Epoch: 6| Step: 13
Training loss: 1.5784670114517212
Validation loss: 1.892608554132523

Epoch: 170| Step: 0
Training loss: 0.6114902496337891
Validation loss: 1.8830450798875542

Epoch: 6| Step: 1
Training loss: 1.1830863952636719
Validation loss: 1.8608992971399778

Epoch: 6| Step: 2
Training loss: 0.9907443523406982
Validation loss: 1.8572385952036867

Epoch: 6| Step: 3
Training loss: 1.6297712326049805
Validation loss: 1.8482408779923634

Epoch: 6| Step: 4
Training loss: 0.9270642995834351
Validation loss: 1.8333490305049445

Epoch: 6| Step: 5
Training loss: 0.6860007643699646
Validation loss: 1.8699616206589567

Epoch: 6| Step: 6
Training loss: 1.1431818008422852
Validation loss: 1.8447424506628385

Epoch: 6| Step: 7
Training loss: 1.3085013628005981
Validation loss: 1.868757519670712

Epoch: 6| Step: 8
Training loss: 0.9379001259803772
Validation loss: 1.8705016771952312

Epoch: 6| Step: 9
Training loss: 0.8614990711212158
Validation loss: 1.8986717988086004

Epoch: 6| Step: 10
Training loss: 1.2195502519607544
Validation loss: 1.9284372650166994

Epoch: 6| Step: 11
Training loss: 0.9959157705307007
Validation loss: 1.9489969309940134

Epoch: 6| Step: 12
Training loss: 1.028380274772644
Validation loss: 1.9711713278165428

Epoch: 6| Step: 13
Training loss: 1.311630129814148
Validation loss: 1.9555492196031796

Epoch: 171| Step: 0
Training loss: 0.813592791557312
Validation loss: 1.9666225064185359

Epoch: 6| Step: 1
Training loss: 1.3625530004501343
Validation loss: 1.912776506075295

Epoch: 6| Step: 2
Training loss: 1.2222445011138916
Validation loss: 1.8785051222770446

Epoch: 6| Step: 3
Training loss: 1.2855733633041382
Validation loss: 1.865626637653638

Epoch: 6| Step: 4
Training loss: 1.150766372680664
Validation loss: 1.8321720964165145

Epoch: 6| Step: 5
Training loss: 0.5468407869338989
Validation loss: 1.8534560472734514

Epoch: 6| Step: 6
Training loss: 1.1734867095947266
Validation loss: 1.879776511141049

Epoch: 6| Step: 7
Training loss: 1.3204071521759033
Validation loss: 1.9248535427995908

Epoch: 6| Step: 8
Training loss: 0.8729734420776367
Validation loss: 1.9210536044131044

Epoch: 6| Step: 9
Training loss: 1.158203363418579
Validation loss: 1.9876199473616898

Epoch: 6| Step: 10
Training loss: 1.0625534057617188
Validation loss: 1.9922971904918712

Epoch: 6| Step: 11
Training loss: 0.9898509383201599
Validation loss: 1.996905739589404

Epoch: 6| Step: 12
Training loss: 1.0130250453948975
Validation loss: 1.9812049788813437

Epoch: 6| Step: 13
Training loss: 0.9421162009239197
Validation loss: 1.9675723942377235

Epoch: 172| Step: 0
Training loss: 1.2631499767303467
Validation loss: 1.8951438216752903

Epoch: 6| Step: 1
Training loss: 0.9000986814498901
Validation loss: 1.897274286516251

Epoch: 6| Step: 2
Training loss: 1.42799973487854
Validation loss: 1.8163416936833372

Epoch: 6| Step: 3
Training loss: 1.156217098236084
Validation loss: 1.8411781172598563

Epoch: 6| Step: 4
Training loss: 1.4402036666870117
Validation loss: 1.8098010670754217

Epoch: 6| Step: 5
Training loss: 1.214609146118164
Validation loss: 1.8028139029779742

Epoch: 6| Step: 6
Training loss: 1.1420519351959229
Validation loss: 1.829722878753498

Epoch: 6| Step: 7
Training loss: 0.8880718350410461
Validation loss: 1.8081604126961

Epoch: 6| Step: 8
Training loss: 0.6109293699264526
Validation loss: 1.8477147791975288

Epoch: 6| Step: 9
Training loss: 1.3377032279968262
Validation loss: 1.8396682739257812

Epoch: 6| Step: 10
Training loss: 0.8144418001174927
Validation loss: 1.88639816417489

Epoch: 6| Step: 11
Training loss: 1.1640892028808594
Validation loss: 1.931412067464603

Epoch: 6| Step: 12
Training loss: 0.6631842851638794
Validation loss: 1.9420028553214124

Epoch: 6| Step: 13
Training loss: 0.4079892635345459
Validation loss: 1.9335542878796976

Epoch: 173| Step: 0
Training loss: 0.9071224927902222
Validation loss: 1.8635582334251815

Epoch: 6| Step: 1
Training loss: 0.5002920627593994
Validation loss: 1.8619775977185977

Epoch: 6| Step: 2
Training loss: 0.9215424060821533
Validation loss: 1.8327676878180554

Epoch: 6| Step: 3
Training loss: 1.1714444160461426
Validation loss: 1.8755462233738234

Epoch: 6| Step: 4
Training loss: 1.3142540454864502
Validation loss: 1.8776851572016233

Epoch: 6| Step: 5
Training loss: 1.2568244934082031
Validation loss: 1.938936148920367

Epoch: 6| Step: 6
Training loss: 0.7862799167633057
Validation loss: 1.9605915969417942

Epoch: 6| Step: 7
Training loss: 0.6564078330993652
Validation loss: 1.9598803033110916

Epoch: 6| Step: 8
Training loss: 1.6694802045822144
Validation loss: 1.9598677927447903

Epoch: 6| Step: 9
Training loss: 0.960754930973053
Validation loss: 1.9825050574477001

Epoch: 6| Step: 10
Training loss: 1.1209192276000977
Validation loss: 1.9948011572642992

Epoch: 6| Step: 11
Training loss: 1.3106460571289062
Validation loss: 1.9597106877193655

Epoch: 6| Step: 12
Training loss: 1.1669303178787231
Validation loss: 1.9705808213962022

Epoch: 6| Step: 13
Training loss: 1.367187738418579
Validation loss: 1.916004083489859

Epoch: 174| Step: 0
Training loss: 1.2293082475662231
Validation loss: 1.8879411489732805

Epoch: 6| Step: 1
Training loss: 0.594803512096405
Validation loss: 1.8668837649847871

Epoch: 6| Step: 2
Training loss: 0.6706385612487793
Validation loss: 1.8818825406412925

Epoch: 6| Step: 3
Training loss: 1.3357311487197876
Validation loss: 1.8798677793113134

Epoch: 6| Step: 4
Training loss: 1.0728344917297363
Validation loss: 1.8665265190985896

Epoch: 6| Step: 5
Training loss: 0.7557203769683838
Validation loss: 1.8709249265732304

Epoch: 6| Step: 6
Training loss: 1.1734331846237183
Validation loss: 1.8850149467427244

Epoch: 6| Step: 7
Training loss: 1.0433416366577148
Validation loss: 1.8660663020226262

Epoch: 6| Step: 8
Training loss: 0.932577908039093
Validation loss: 1.8652857990675076

Epoch: 6| Step: 9
Training loss: 1.2300434112548828
Validation loss: 1.8671169229733047

Epoch: 6| Step: 10
Training loss: 1.0868947505950928
Validation loss: 1.8686168155362528

Epoch: 6| Step: 11
Training loss: 1.2984545230865479
Validation loss: 1.9448610608295729

Epoch: 6| Step: 12
Training loss: 0.8837646245956421
Validation loss: 1.9282929974217569

Epoch: 6| Step: 13
Training loss: 0.8289851546287537
Validation loss: 1.9387912698971328

Epoch: 175| Step: 0
Training loss: 1.376744270324707
Validation loss: 1.946353276570638

Epoch: 6| Step: 1
Training loss: 0.7253825068473816
Validation loss: 1.9164812462304228

Epoch: 6| Step: 2
Training loss: 1.3393534421920776
Validation loss: 1.894442028896783

Epoch: 6| Step: 3
Training loss: 1.0581154823303223
Validation loss: 1.8758669284082228

Epoch: 6| Step: 4
Training loss: 0.8999230861663818
Validation loss: 1.8583006987007715

Epoch: 6| Step: 5
Training loss: 0.8152258396148682
Validation loss: 1.8152073198749172

Epoch: 6| Step: 6
Training loss: 1.332440733909607
Validation loss: 1.834898260331923

Epoch: 6| Step: 7
Training loss: 0.5677585601806641
Validation loss: 1.8371070687488844

Epoch: 6| Step: 8
Training loss: 1.130361557006836
Validation loss: 1.8838331212279618

Epoch: 6| Step: 9
Training loss: 1.4488413333892822
Validation loss: 1.9249914589748587

Epoch: 6| Step: 10
Training loss: 0.5725473165512085
Validation loss: 1.969891760938911

Epoch: 6| Step: 11
Training loss: 0.8608953952789307
Validation loss: 1.9602376261065084

Epoch: 6| Step: 12
Training loss: 0.7103219628334045
Validation loss: 1.9494330857389717

Epoch: 6| Step: 13
Training loss: 1.0180388689041138
Validation loss: 1.9070753435934744

Epoch: 176| Step: 0
Training loss: 0.7031492590904236
Validation loss: 1.8639003179406608

Epoch: 6| Step: 1
Training loss: 0.995521605014801
Validation loss: 1.8882233763253817

Epoch: 6| Step: 2
Training loss: 0.5904581546783447
Validation loss: 1.8450378102640952

Epoch: 6| Step: 3
Training loss: 0.9963690042495728
Validation loss: 1.8401257402153426

Epoch: 6| Step: 4
Training loss: 1.1150676012039185
Validation loss: 1.8123619043698875

Epoch: 6| Step: 5
Training loss: 1.2435264587402344
Validation loss: 1.820060101888513

Epoch: 6| Step: 6
Training loss: 1.2343292236328125
Validation loss: 1.8139815022868495

Epoch: 6| Step: 7
Training loss: 0.8169407844543457
Validation loss: 1.8492358089775167

Epoch: 6| Step: 8
Training loss: 0.7568607926368713
Validation loss: 1.868462363878886

Epoch: 6| Step: 9
Training loss: 1.302103042602539
Validation loss: 1.9127818820297078

Epoch: 6| Step: 10
Training loss: 0.635839581489563
Validation loss: 1.9551155464623564

Epoch: 6| Step: 11
Training loss: 0.8548429012298584
Validation loss: 1.984789502236151

Epoch: 6| Step: 12
Training loss: 1.2482703924179077
Validation loss: 2.0160274979888753

Epoch: 6| Step: 13
Training loss: 0.9157055616378784
Validation loss: 1.998931215655419

Epoch: 177| Step: 0
Training loss: 0.9429225325584412
Validation loss: 2.0238985066772788

Epoch: 6| Step: 1
Training loss: 0.8961511254310608
Validation loss: 2.012486219406128

Epoch: 6| Step: 2
Training loss: 0.6872653961181641
Validation loss: 2.000671253409437

Epoch: 6| Step: 3
Training loss: 1.3146636486053467
Validation loss: 1.9452425587561823

Epoch: 6| Step: 4
Training loss: 0.8458290100097656
Validation loss: 1.8928713670340918

Epoch: 6| Step: 5
Training loss: 1.0294862985610962
Validation loss: 1.8483912867884482

Epoch: 6| Step: 6
Training loss: 1.144269347190857
Validation loss: 1.8358842108839302

Epoch: 6| Step: 7
Training loss: 1.2512294054031372
Validation loss: 1.8066911530751053

Epoch: 6| Step: 8
Training loss: 0.8832288980484009
Validation loss: 1.8117199892638831

Epoch: 6| Step: 9
Training loss: 0.73004549741745
Validation loss: 1.8433601753686064

Epoch: 6| Step: 10
Training loss: 0.6122798919677734
Validation loss: 1.8814659528834845

Epoch: 6| Step: 11
Training loss: 1.2112599611282349
Validation loss: 1.9177594325875724

Epoch: 6| Step: 12
Training loss: 1.0699944496154785
Validation loss: 2.0036275886720225

Epoch: 6| Step: 13
Training loss: 0.7119337320327759
Validation loss: 2.0336861328412126

Epoch: 178| Step: 0
Training loss: 0.9570748209953308
Validation loss: 2.0762726312042563

Epoch: 6| Step: 1
Training loss: 0.7863413095474243
Validation loss: 2.075931461908484

Epoch: 6| Step: 2
Training loss: 1.031883955001831
Validation loss: 1.9931142227624052

Epoch: 6| Step: 3
Training loss: 0.9561243057250977
Validation loss: 1.9138160905530375

Epoch: 6| Step: 4
Training loss: 1.3122966289520264
Validation loss: 1.847896093963295

Epoch: 6| Step: 5
Training loss: 0.7891455888748169
Validation loss: 1.8205070521241875

Epoch: 6| Step: 6
Training loss: 1.4175488948822021
Validation loss: 1.8056393964316255

Epoch: 6| Step: 7
Training loss: 0.6255843639373779
Validation loss: 1.78406229711348

Epoch: 6| Step: 8
Training loss: 0.8177070617675781
Validation loss: 1.8114604027040544

Epoch: 6| Step: 9
Training loss: 1.4505455493927002
Validation loss: 1.817455530166626

Epoch: 6| Step: 10
Training loss: 1.1421732902526855
Validation loss: 1.8675873535935597

Epoch: 6| Step: 11
Training loss: 0.904792845249176
Validation loss: 1.8917328080823343

Epoch: 6| Step: 12
Training loss: 0.9472583532333374
Validation loss: 1.8920008956745107

Epoch: 6| Step: 13
Training loss: 1.1162480115890503
Validation loss: 1.928426791262883

Epoch: 179| Step: 0
Training loss: 0.555486798286438
Validation loss: 1.9416615924527567

Epoch: 6| Step: 1
Training loss: 1.050062656402588
Validation loss: 1.9760402094933294

Epoch: 6| Step: 2
Training loss: 0.471287339925766
Validation loss: 2.0238982554404967

Epoch: 6| Step: 3
Training loss: 1.439078450202942
Validation loss: 2.015413353520055

Epoch: 6| Step: 4
Training loss: 1.0556690692901611
Validation loss: 1.9616701410662742

Epoch: 6| Step: 5
Training loss: 1.1575841903686523
Validation loss: 1.8869331447027062

Epoch: 6| Step: 6
Training loss: 0.7747316360473633
Validation loss: 1.807740492205466

Epoch: 6| Step: 7
Training loss: 1.135353684425354
Validation loss: 1.7905922077035392

Epoch: 6| Step: 8
Training loss: 0.8509926199913025
Validation loss: 1.7883994425496748

Epoch: 6| Step: 9
Training loss: 1.4450232982635498
Validation loss: 1.7991121494641868

Epoch: 6| Step: 10
Training loss: 1.2463436126708984
Validation loss: 1.7754484658600183

Epoch: 6| Step: 11
Training loss: 1.2384164333343506
Validation loss: 1.7745785200467674

Epoch: 6| Step: 12
Training loss: 1.1234115362167358
Validation loss: 1.8056656852845223

Epoch: 6| Step: 13
Training loss: 0.8872677683830261
Validation loss: 1.8081438861867434

Epoch: 180| Step: 0
Training loss: 0.8521878123283386
Validation loss: 1.825074827799233

Epoch: 6| Step: 1
Training loss: 0.8183237314224243
Validation loss: 1.8227165052967687

Epoch: 6| Step: 2
Training loss: 0.8855820894241333
Validation loss: 1.8659483873715965

Epoch: 6| Step: 3
Training loss: 0.590100884437561
Validation loss: 1.8718112335410169

Epoch: 6| Step: 4
Training loss: 1.0657196044921875
Validation loss: 1.8886286674007293

Epoch: 6| Step: 5
Training loss: 1.0561814308166504
Validation loss: 1.8957918651642338

Epoch: 6| Step: 6
Training loss: 1.067169427871704
Validation loss: 1.8784073014413156

Epoch: 6| Step: 7
Training loss: 0.71225905418396
Validation loss: 1.8904223160077167

Epoch: 6| Step: 8
Training loss: 0.7439443469047546
Validation loss: 1.9315259520725538

Epoch: 6| Step: 9
Training loss: 0.9517940878868103
Validation loss: 1.898186009417298

Epoch: 6| Step: 10
Training loss: 0.9806212186813354
Validation loss: 1.8922418291850756

Epoch: 6| Step: 11
Training loss: 1.2210193872451782
Validation loss: 1.8993701460540935

Epoch: 6| Step: 12
Training loss: 0.8307691812515259
Validation loss: 1.8380363320791593

Epoch: 6| Step: 13
Training loss: 1.0238566398620605
Validation loss: 1.8479155930139686

Epoch: 181| Step: 0
Training loss: 0.9649039506912231
Validation loss: 1.8044919275468396

Epoch: 6| Step: 1
Training loss: 1.3938899040222168
Validation loss: 1.8287249060087307

Epoch: 6| Step: 2
Training loss: 1.0265161991119385
Validation loss: 1.825037069218133

Epoch: 6| Step: 3
Training loss: 0.9483810067176819
Validation loss: 1.8399735830163444

Epoch: 6| Step: 4
Training loss: 1.094151496887207
Validation loss: 1.87845782567096

Epoch: 6| Step: 5
Training loss: 1.1132946014404297
Validation loss: 1.8683180206565446

Epoch: 6| Step: 6
Training loss: 0.7473827600479126
Validation loss: 1.916167397652903

Epoch: 6| Step: 7
Training loss: 1.02839994430542
Validation loss: 1.9276546970490487

Epoch: 6| Step: 8
Training loss: 0.6836835145950317
Validation loss: 1.9158621039441837

Epoch: 6| Step: 9
Training loss: 0.5996281504631042
Validation loss: 1.9389993606075164

Epoch: 6| Step: 10
Training loss: 0.8154864311218262
Validation loss: 1.9091743807638846

Epoch: 6| Step: 11
Training loss: 0.845659077167511
Validation loss: 1.905072182737371

Epoch: 6| Step: 12
Training loss: 0.7023917436599731
Validation loss: 1.8890397292311474

Epoch: 6| Step: 13
Training loss: 0.7589035034179688
Validation loss: 1.8758553253707064

Epoch: 182| Step: 0
Training loss: 0.956304132938385
Validation loss: 1.8779075299539874

Epoch: 6| Step: 1
Training loss: 0.7844035625457764
Validation loss: 1.8374226785475207

Epoch: 6| Step: 2
Training loss: 0.8718656301498413
Validation loss: 1.7968401729419667

Epoch: 6| Step: 3
Training loss: 1.136117935180664
Validation loss: 1.8083960599796747

Epoch: 6| Step: 4
Training loss: 0.949828028678894
Validation loss: 1.84294040741459

Epoch: 6| Step: 5
Training loss: 0.787436842918396
Validation loss: 1.8449000357299723

Epoch: 6| Step: 6
Training loss: 0.9141296744346619
Validation loss: 1.872167182225053

Epoch: 6| Step: 7
Training loss: 0.47128552198410034
Validation loss: 1.8920732845542252

Epoch: 6| Step: 8
Training loss: 1.298366665840149
Validation loss: 1.8548369997291154

Epoch: 6| Step: 9
Training loss: 0.8632820844650269
Validation loss: 1.835153438711679

Epoch: 6| Step: 10
Training loss: 0.521381139755249
Validation loss: 1.8691809638853996

Epoch: 6| Step: 11
Training loss: 1.0163483619689941
Validation loss: 1.8639565962617115

Epoch: 6| Step: 12
Training loss: 0.7992210388183594
Validation loss: 1.8511731829694522

Epoch: 6| Step: 13
Training loss: 1.3929170370101929
Validation loss: 1.860763257549655

Epoch: 183| Step: 0
Training loss: 0.9043887853622437
Validation loss: 1.8364574819482782

Epoch: 6| Step: 1
Training loss: 1.0005388259887695
Validation loss: 1.8404457697304346

Epoch: 6| Step: 2
Training loss: 0.49939367175102234
Validation loss: 1.8242420522115563

Epoch: 6| Step: 3
Training loss: 0.8994004726409912
Validation loss: 1.8067131965391097

Epoch: 6| Step: 4
Training loss: 1.0477972030639648
Validation loss: 1.8520593079187537

Epoch: 6| Step: 5
Training loss: 0.8227377533912659
Validation loss: 1.858373772713446

Epoch: 6| Step: 6
Training loss: 0.704025387763977
Validation loss: 1.8801880139176563

Epoch: 6| Step: 7
Training loss: 0.9782557487487793
Validation loss: 1.8863929625480407

Epoch: 6| Step: 8
Training loss: 0.7148380279541016
Validation loss: 1.881026683315154

Epoch: 6| Step: 9
Training loss: 0.7341949343681335
Validation loss: 1.880445154764319

Epoch: 6| Step: 10
Training loss: 0.9667327404022217
Validation loss: 1.9056204339509368

Epoch: 6| Step: 11
Training loss: 0.9841184616088867
Validation loss: 1.9026208667344944

Epoch: 6| Step: 12
Training loss: 0.7315537929534912
Validation loss: 1.912737536173995

Epoch: 6| Step: 13
Training loss: 0.8044927716255188
Validation loss: 1.8932612121746104

Epoch: 184| Step: 0
Training loss: 1.027951955795288
Validation loss: 1.899104236274637

Epoch: 6| Step: 1
Training loss: 0.8959434628486633
Validation loss: 1.9254823833383539

Epoch: 6| Step: 2
Training loss: 0.6115337014198303
Validation loss: 1.9221168192484046

Epoch: 6| Step: 3
Training loss: 0.5005596876144409
Validation loss: 1.9110838931093934

Epoch: 6| Step: 4
Training loss: 0.943722128868103
Validation loss: 1.8783838877113916

Epoch: 6| Step: 5
Training loss: 0.6933444738388062
Validation loss: 1.8803534635933496

Epoch: 6| Step: 6
Training loss: 0.7983717918395996
Validation loss: 1.8869733054150817

Epoch: 6| Step: 7
Training loss: 0.9934755563735962
Validation loss: 1.9100776333962717

Epoch: 6| Step: 8
Training loss: 0.6397335529327393
Validation loss: 1.911532082865315

Epoch: 6| Step: 9
Training loss: 1.1449558734893799
Validation loss: 1.9046364022839455

Epoch: 6| Step: 10
Training loss: 0.8389982581138611
Validation loss: 1.922023037428497

Epoch: 6| Step: 11
Training loss: 0.8853313326835632
Validation loss: 1.9157086879976335

Epoch: 6| Step: 12
Training loss: 0.7546262145042419
Validation loss: 1.9254660221838182

Epoch: 6| Step: 13
Training loss: 1.0017610788345337
Validation loss: 1.9295305577657555

Epoch: 185| Step: 0
Training loss: 0.5211822390556335
Validation loss: 1.9255646403117845

Epoch: 6| Step: 1
Training loss: 0.6689282059669495
Validation loss: 1.9090895037497244

Epoch: 6| Step: 2
Training loss: 0.788925051689148
Validation loss: 1.9214472283599198

Epoch: 6| Step: 3
Training loss: 0.7533305883407593
Validation loss: 1.9063222805658977

Epoch: 6| Step: 4
Training loss: 0.5176281929016113
Validation loss: 1.9003432232846496

Epoch: 6| Step: 5
Training loss: 0.7324427366256714
Validation loss: 1.928676966697939

Epoch: 6| Step: 6
Training loss: 0.9042019844055176
Validation loss: 1.9314208671610842

Epoch: 6| Step: 7
Training loss: 0.8538199663162231
Validation loss: 1.92645352373841

Epoch: 6| Step: 8
Training loss: 0.9093406796455383
Validation loss: 1.9003582949279456

Epoch: 6| Step: 9
Training loss: 0.8944827318191528
Validation loss: 1.9409155230368338

Epoch: 6| Step: 10
Training loss: 0.8823977112770081
Validation loss: 1.9509337256031651

Epoch: 6| Step: 11
Training loss: 1.4674103260040283
Validation loss: 1.9858839127325243

Epoch: 6| Step: 12
Training loss: 0.8964509963989258
Validation loss: 1.991582525673733

Epoch: 6| Step: 13
Training loss: 1.2508291006088257
Validation loss: 1.951307108325343

Epoch: 186| Step: 0
Training loss: 0.9324633479118347
Validation loss: 1.8897385545956191

Epoch: 6| Step: 1
Training loss: 0.9608978629112244
Validation loss: 1.8854985826758928

Epoch: 6| Step: 2
Training loss: 0.7903757095336914
Validation loss: 1.889302174250285

Epoch: 6| Step: 3
Training loss: 0.5513639450073242
Validation loss: 1.8821682878719863

Epoch: 6| Step: 4
Training loss: 1.0363764762878418
Validation loss: 1.876962334878983

Epoch: 6| Step: 5
Training loss: 0.6938633322715759
Validation loss: 1.845566024062454

Epoch: 6| Step: 6
Training loss: 0.6924381256103516
Validation loss: 1.846479388975328

Epoch: 6| Step: 7
Training loss: 0.7433924078941345
Validation loss: 1.8686454539657922

Epoch: 6| Step: 8
Training loss: 1.3063178062438965
Validation loss: 1.9281698298710648

Epoch: 6| Step: 9
Training loss: 0.8004122376441956
Validation loss: 2.026845360314974

Epoch: 6| Step: 10
Training loss: 1.2414474487304688
Validation loss: 2.087910900833786

Epoch: 6| Step: 11
Training loss: 0.6699814200401306
Validation loss: 2.05487242052632

Epoch: 6| Step: 12
Training loss: 1.2486549615859985
Validation loss: 1.997393346601917

Epoch: 6| Step: 13
Training loss: 0.5687196254730225
Validation loss: 1.9188987426860358

Epoch: 187| Step: 0
Training loss: 1.0469987392425537
Validation loss: 1.9017487187539377

Epoch: 6| Step: 1
Training loss: 1.3405871391296387
Validation loss: 1.8705634968255156

Epoch: 6| Step: 2
Training loss: 1.0481815338134766
Validation loss: 1.8869307528259933

Epoch: 6| Step: 3
Training loss: 0.9746346473693848
Validation loss: 1.8561078797104538

Epoch: 6| Step: 4
Training loss: 1.0085580348968506
Validation loss: 1.890107867538288

Epoch: 6| Step: 5
Training loss: 0.5525623559951782
Validation loss: 1.8622213140610726

Epoch: 6| Step: 6
Training loss: 0.7394277453422546
Validation loss: 1.9052317873124154

Epoch: 6| Step: 7
Training loss: 0.6999759674072266
Validation loss: 1.9317997835015739

Epoch: 6| Step: 8
Training loss: 0.9907333850860596
Validation loss: 1.9285515828799176

Epoch: 6| Step: 9
Training loss: 0.7461167573928833
Validation loss: 1.9608402098378828

Epoch: 6| Step: 10
Training loss: 1.0577023029327393
Validation loss: 1.9426107022070116

Epoch: 6| Step: 11
Training loss: 0.4824367165565491
Validation loss: 1.9500084538613596

Epoch: 6| Step: 12
Training loss: 0.42004477977752686
Validation loss: 1.9258066056877055

Epoch: 6| Step: 13
Training loss: 1.3569846153259277
Validation loss: 1.8942002455393474

Epoch: 188| Step: 0
Training loss: 0.4728410840034485
Validation loss: 1.8879784230263001

Epoch: 6| Step: 1
Training loss: 1.0637001991271973
Validation loss: 1.8544734370323919

Epoch: 6| Step: 2
Training loss: 0.8503555059432983
Validation loss: 1.8506358644013763

Epoch: 6| Step: 3
Training loss: 0.6445280909538269
Validation loss: 1.837139420611884

Epoch: 6| Step: 4
Training loss: 0.7127320766448975
Validation loss: 1.8805197220976635

Epoch: 6| Step: 5
Training loss: 0.6806668043136597
Validation loss: 1.8806969914385068

Epoch: 6| Step: 6
Training loss: 0.8183916211128235
Validation loss: 1.8547868574819257

Epoch: 6| Step: 7
Training loss: 0.6573479175567627
Validation loss: 1.872051388986649

Epoch: 6| Step: 8
Training loss: 0.9385719895362854
Validation loss: 1.8939765050847044

Epoch: 6| Step: 9
Training loss: 0.9290599822998047
Validation loss: 1.8897445586419874

Epoch: 6| Step: 10
Training loss: 0.7618236541748047
Validation loss: 1.8538646339088358

Epoch: 6| Step: 11
Training loss: 1.1054953336715698
Validation loss: 1.8317555714679021

Epoch: 6| Step: 12
Training loss: 1.0919249057769775
Validation loss: 1.8086930372381722

Epoch: 6| Step: 13
Training loss: 0.7590517401695251
Validation loss: 1.8082386062991234

Epoch: 189| Step: 0
Training loss: 0.5843202471733093
Validation loss: 1.8192998952763055

Epoch: 6| Step: 1
Training loss: 1.1441073417663574
Validation loss: 1.7852147830429899

Epoch: 6| Step: 2
Training loss: 0.692044198513031
Validation loss: 1.8184243940537976

Epoch: 6| Step: 3
Training loss: 0.8624444007873535
Validation loss: 1.809941303345465

Epoch: 6| Step: 4
Training loss: 0.9805265069007874
Validation loss: 1.7801034219803349

Epoch: 6| Step: 5
Training loss: 0.6619992852210999
Validation loss: 1.775429851265364

Epoch: 6| Step: 6
Training loss: 0.795438289642334
Validation loss: 1.7963125218627274

Epoch: 6| Step: 7
Training loss: 1.3943455219268799
Validation loss: 1.8055693654603855

Epoch: 6| Step: 8
Training loss: 0.5213537812232971
Validation loss: 1.7833590943326232

Epoch: 6| Step: 9
Training loss: 0.8764053583145142
Validation loss: 1.8387800634548228

Epoch: 6| Step: 10
Training loss: 0.5688081979751587
Validation loss: 1.8587098711280412

Epoch: 6| Step: 11
Training loss: 0.7863979935646057
Validation loss: 1.916951612759662

Epoch: 6| Step: 12
Training loss: 0.3566744923591614
Validation loss: 1.9202096462249756

Epoch: 6| Step: 13
Training loss: 0.7350440621376038
Validation loss: 1.907854514737283

Epoch: 190| Step: 0
Training loss: 0.6026644706726074
Validation loss: 1.8631122496820265

Epoch: 6| Step: 1
Training loss: 0.6181364059448242
Validation loss: 1.8489124390386766

Epoch: 6| Step: 2
Training loss: 0.6812885999679565
Validation loss: 1.7753341210785734

Epoch: 6| Step: 3
Training loss: 0.8930770754814148
Validation loss: 1.7988130648930867

Epoch: 6| Step: 4
Training loss: 0.8666137456893921
Validation loss: 1.8266282799423381

Epoch: 6| Step: 5
Training loss: 1.125460147857666
Validation loss: 1.818233056734967

Epoch: 6| Step: 6
Training loss: 0.9095402956008911
Validation loss: 1.8226248628349715

Epoch: 6| Step: 7
Training loss: 0.9488521218299866
Validation loss: 1.8425173977369904

Epoch: 6| Step: 8
Training loss: 0.6204491257667542
Validation loss: 1.8403928536240772

Epoch: 6| Step: 9
Training loss: 0.7335629463195801
Validation loss: 1.8468995696754866

Epoch: 6| Step: 10
Training loss: 0.5090771913528442
Validation loss: 1.8875528227898382

Epoch: 6| Step: 11
Training loss: 1.1013896465301514
Validation loss: 1.8744423927799347

Epoch: 6| Step: 12
Training loss: 0.5699621438980103
Validation loss: 1.8991456262526973

Epoch: 6| Step: 13
Training loss: 1.0000873804092407
Validation loss: 1.847592011574776

Epoch: 191| Step: 0
Training loss: 0.5659275650978088
Validation loss: 1.8837929220609768

Epoch: 6| Step: 1
Training loss: 0.9690510034561157
Validation loss: 1.831612761302661

Epoch: 6| Step: 2
Training loss: 0.41135719418525696
Validation loss: 1.8103157627967097

Epoch: 6| Step: 3
Training loss: 0.44428467750549316
Validation loss: 1.7989086592069237

Epoch: 6| Step: 4
Training loss: 0.7860192060470581
Validation loss: 1.8202051526756697

Epoch: 6| Step: 5
Training loss: 0.785681962966919
Validation loss: 1.8317447836681078

Epoch: 6| Step: 6
Training loss: 0.587653398513794
Validation loss: 1.8196354143081173

Epoch: 6| Step: 7
Training loss: 0.7658990621566772
Validation loss: 1.8312013418443742

Epoch: 6| Step: 8
Training loss: 0.5077540874481201
Validation loss: 1.8237721458558114

Epoch: 6| Step: 9
Training loss: 0.8917896151542664
Validation loss: 1.8102867308483328

Epoch: 6| Step: 10
Training loss: 1.0478774309158325
Validation loss: 1.806485427323208

Epoch: 6| Step: 11
Training loss: 0.784294843673706
Validation loss: 1.8119796053055794

Epoch: 6| Step: 12
Training loss: 0.8592597246170044
Validation loss: 1.841820381020987

Epoch: 6| Step: 13
Training loss: 1.4124287366867065
Validation loss: 1.8500036616479196

Epoch: 192| Step: 0
Training loss: 0.8020592331886292
Validation loss: 1.866799036661784

Epoch: 6| Step: 1
Training loss: 1.0279076099395752
Validation loss: 1.8890547470379901

Epoch: 6| Step: 2
Training loss: 0.5412470102310181
Validation loss: 1.8770000216781453

Epoch: 6| Step: 3
Training loss: 0.79195636510849
Validation loss: 1.9050604989451747

Epoch: 6| Step: 4
Training loss: 0.9373434782028198
Validation loss: 1.8558171205623175

Epoch: 6| Step: 5
Training loss: 0.8609886169433594
Validation loss: 1.8495284459924186

Epoch: 6| Step: 6
Training loss: 0.6886404752731323
Validation loss: 1.862922405683866

Epoch: 6| Step: 7
Training loss: 0.6398448348045349
Validation loss: 1.872789406007336

Epoch: 6| Step: 8
Training loss: 0.7031336426734924
Validation loss: 1.8399556003591067

Epoch: 6| Step: 9
Training loss: 0.7738612294197083
Validation loss: 1.8099847044996036

Epoch: 6| Step: 10
Training loss: 0.6948053240776062
Validation loss: 1.8312199846390755

Epoch: 6| Step: 11
Training loss: 0.9721313714981079
Validation loss: 1.8265089604162401

Epoch: 6| Step: 12
Training loss: 0.5285788774490356
Validation loss: 1.8105963199369368

Epoch: 6| Step: 13
Training loss: 0.8547455072402954
Validation loss: 1.802256327803417

Epoch: 193| Step: 0
Training loss: 0.647861123085022
Validation loss: 1.8071967645358014

Epoch: 6| Step: 1
Training loss: 0.7874372601509094
Validation loss: 1.7779759809535036

Epoch: 6| Step: 2
Training loss: 0.6803197860717773
Validation loss: 1.7927267487331102

Epoch: 6| Step: 3
Training loss: 0.7102279663085938
Validation loss: 1.7778834194265387

Epoch: 6| Step: 4
Training loss: 0.8098195195198059
Validation loss: 1.7809787847662484

Epoch: 6| Step: 5
Training loss: 0.4174237847328186
Validation loss: 1.7865579064174364

Epoch: 6| Step: 6
Training loss: 0.6588262319564819
Validation loss: 1.7965905666351318

Epoch: 6| Step: 7
Training loss: 1.0488651990890503
Validation loss: 1.8014021201800274

Epoch: 6| Step: 8
Training loss: 0.6806307435035706
Validation loss: 1.7974117930217455

Epoch: 6| Step: 9
Training loss: 0.8573874235153198
Validation loss: 1.8365474170254124

Epoch: 6| Step: 10
Training loss: 0.6021820306777954
Validation loss: 1.818943306963931

Epoch: 6| Step: 11
Training loss: 0.5704541206359863
Validation loss: 1.852335036441844

Epoch: 6| Step: 12
Training loss: 0.5988892316818237
Validation loss: 1.8414262776733727

Epoch: 6| Step: 13
Training loss: 1.1563725471496582
Validation loss: 1.8392422865795832

Epoch: 194| Step: 0
Training loss: 1.002663254737854
Validation loss: 1.814529372799781

Epoch: 6| Step: 1
Training loss: 0.7148193120956421
Validation loss: 1.8170593592428392

Epoch: 6| Step: 2
Training loss: 0.6519324779510498
Validation loss: 1.8183435868191462

Epoch: 6| Step: 3
Training loss: 0.589812159538269
Validation loss: 1.8284596538030973

Epoch: 6| Step: 4
Training loss: 1.0271869897842407
Validation loss: 1.8166776523795178

Epoch: 6| Step: 5
Training loss: 0.5604126453399658
Validation loss: 1.8263616074797928

Epoch: 6| Step: 6
Training loss: 0.532803475856781
Validation loss: 1.8505117175399617

Epoch: 6| Step: 7
Training loss: 0.4749048352241516
Validation loss: 1.8310987603279851

Epoch: 6| Step: 8
Training loss: 0.30388325452804565
Validation loss: 1.8307600777636293

Epoch: 6| Step: 9
Training loss: 0.518369197845459
Validation loss: 1.8146525570141372

Epoch: 6| Step: 10
Training loss: 0.8020074367523193
Validation loss: 1.8250853182167135

Epoch: 6| Step: 11
Training loss: 0.8615509867668152
Validation loss: 1.8071000883656163

Epoch: 6| Step: 12
Training loss: 0.6087133884429932
Validation loss: 1.80301675873418

Epoch: 6| Step: 13
Training loss: 1.0956960916519165
Validation loss: 1.7807887933587516

Epoch: 195| Step: 0
Training loss: 0.7546618580818176
Validation loss: 1.7950644134193339

Epoch: 6| Step: 1
Training loss: 0.530803382396698
Validation loss: 1.8115855852762859

Epoch: 6| Step: 2
Training loss: 0.7370696067810059
Validation loss: 1.8045077567459435

Epoch: 6| Step: 3
Training loss: 0.3701104521751404
Validation loss: 1.7791389726823377

Epoch: 6| Step: 4
Training loss: 0.7983527779579163
Validation loss: 1.83407792481043

Epoch: 6| Step: 5
Training loss: 0.7081214189529419
Validation loss: 1.8160517856638918

Epoch: 6| Step: 6
Training loss: 0.33596426248550415
Validation loss: 1.8168087749071018

Epoch: 6| Step: 7
Training loss: 0.6679742336273193
Validation loss: 1.7961420064331384

Epoch: 6| Step: 8
Training loss: 0.6487640738487244
Validation loss: 1.7993574591093167

Epoch: 6| Step: 9
Training loss: 0.9799696803092957
Validation loss: 1.8036003394793438

Epoch: 6| Step: 10
Training loss: 0.7945824861526489
Validation loss: 1.7867677955217258

Epoch: 6| Step: 11
Training loss: 0.9256809949874878
Validation loss: 1.8032793767990605

Epoch: 6| Step: 12
Training loss: 0.9568933248519897
Validation loss: 1.8150019440599667

Epoch: 6| Step: 13
Training loss: 0.5119703412055969
Validation loss: 1.7830389545809837

Epoch: 196| Step: 0
Training loss: 0.6482325792312622
Validation loss: 1.7580604117403749

Epoch: 6| Step: 1
Training loss: 0.6976838707923889
Validation loss: 1.783618264300849

Epoch: 6| Step: 2
Training loss: 0.6234874129295349
Validation loss: 1.7969700803038895

Epoch: 6| Step: 3
Training loss: 0.8122143745422363
Validation loss: 1.836199624564058

Epoch: 6| Step: 4
Training loss: 0.7053624987602234
Validation loss: 1.8062904163073468

Epoch: 6| Step: 5
Training loss: 0.7386212348937988
Validation loss: 1.830615807605046

Epoch: 6| Step: 6
Training loss: 0.6665768623352051
Validation loss: 1.836218777523246

Epoch: 6| Step: 7
Training loss: 0.5093848705291748
Validation loss: 1.8213221078277917

Epoch: 6| Step: 8
Training loss: 0.8325978517532349
Validation loss: 1.7878426313400269

Epoch: 6| Step: 9
Training loss: 0.41100892424583435
Validation loss: 1.8020827398505261

Epoch: 6| Step: 10
Training loss: 0.6070768237113953
Validation loss: 1.7801414689710062

Epoch: 6| Step: 11
Training loss: 0.5938045978546143
Validation loss: 1.8197027585839713

Epoch: 6| Step: 12
Training loss: 0.7555084228515625
Validation loss: 1.8048538956590878

Epoch: 6| Step: 13
Training loss: 0.5168311595916748
Validation loss: 1.8349261822239045

Epoch: 197| Step: 0
Training loss: 0.4680349826812744
Validation loss: 1.7921226293809953

Epoch: 6| Step: 1
Training loss: 0.7553527355194092
Validation loss: 1.7687594916230889

Epoch: 6| Step: 2
Training loss: 0.5733450651168823
Validation loss: 1.7432813913591447

Epoch: 6| Step: 3
Training loss: 0.967787504196167
Validation loss: 1.7705570626002487

Epoch: 6| Step: 4
Training loss: 0.5248763561248779
Validation loss: 1.7757462455380348

Epoch: 6| Step: 5
Training loss: 0.789023756980896
Validation loss: 1.8392138788777013

Epoch: 6| Step: 6
Training loss: 0.6191244125366211
Validation loss: 1.8400866946866434

Epoch: 6| Step: 7
Training loss: 0.5477551221847534
Validation loss: 1.8441580251980854

Epoch: 6| Step: 8
Training loss: 0.669126033782959
Validation loss: 1.8339432772769724

Epoch: 6| Step: 9
Training loss: 0.5863586664199829
Validation loss: 1.8037662236921248

Epoch: 6| Step: 10
Training loss: 0.5355122685432434
Validation loss: 1.750719843372222

Epoch: 6| Step: 11
Training loss: 0.6378096342086792
Validation loss: 1.7728892654500983

Epoch: 6| Step: 12
Training loss: 0.9221745729446411
Validation loss: 1.7687447917076848

Epoch: 6| Step: 13
Training loss: 1.23325514793396
Validation loss: 1.7664807176077237

Epoch: 198| Step: 0
Training loss: 0.4896935224533081
Validation loss: 1.773771785920666

Epoch: 6| Step: 1
Training loss: 0.7278544902801514
Validation loss: 1.7719881239757742

Epoch: 6| Step: 2
Training loss: 0.7698537707328796
Validation loss: 1.8047615097415062

Epoch: 6| Step: 3
Training loss: 0.780336320400238
Validation loss: 1.819680388255786

Epoch: 6| Step: 4
Training loss: 0.7379955053329468
Validation loss: 1.8497408141372025

Epoch: 6| Step: 5
Training loss: 0.8428616523742676
Validation loss: 1.8586399247569423

Epoch: 6| Step: 6
Training loss: 0.5918130278587341
Validation loss: 1.8773681258642545

Epoch: 6| Step: 7
Training loss: 0.6000834703445435
Validation loss: 1.8448057046500586

Epoch: 6| Step: 8
Training loss: 0.8524804711341858
Validation loss: 1.7656699931749733

Epoch: 6| Step: 9
Training loss: 0.7601400017738342
Validation loss: 1.7655393718391337

Epoch: 6| Step: 10
Training loss: 0.36316174268722534
Validation loss: 1.7771044149193713

Epoch: 6| Step: 11
Training loss: 0.8064106106758118
Validation loss: 1.7691129407575052

Epoch: 6| Step: 12
Training loss: 0.6926677227020264
Validation loss: 1.7907790099420855

Epoch: 6| Step: 13
Training loss: 0.22652816772460938
Validation loss: 1.8258111271806943

Epoch: 199| Step: 0
Training loss: 0.6752521991729736
Validation loss: 1.8191597512973252

Epoch: 6| Step: 1
Training loss: 0.6029801368713379
Validation loss: 1.8543182162828342

Epoch: 6| Step: 2
Training loss: 0.7242107391357422
Validation loss: 1.8714563231314383

Epoch: 6| Step: 3
Training loss: 0.49461400508880615
Validation loss: 1.9010380237333235

Epoch: 6| Step: 4
Training loss: 0.6891667246818542
Validation loss: 1.915276781205208

Epoch: 6| Step: 5
Training loss: 0.6646293997764587
Validation loss: 1.8819277126302

Epoch: 6| Step: 6
Training loss: 0.6711581945419312
Validation loss: 1.8773283958435059

Epoch: 6| Step: 7
Training loss: 0.29798662662506104
Validation loss: 1.8425495547633017

Epoch: 6| Step: 8
Training loss: 1.1695599555969238
Validation loss: 1.8034572742318595

Epoch: 6| Step: 9
Training loss: 0.7446050643920898
Validation loss: 1.7764604988918509

Epoch: 6| Step: 10
Training loss: 0.595678985118866
Validation loss: 1.7859883026410175

Epoch: 6| Step: 11
Training loss: 0.8094228506088257
Validation loss: 1.8012652717610842

Epoch: 6| Step: 12
Training loss: 0.5837153196334839
Validation loss: 1.7784454373903171

Epoch: 6| Step: 13
Training loss: 0.6665246486663818
Validation loss: 1.8283085541058612

Epoch: 200| Step: 0
Training loss: 0.6417226791381836
Validation loss: 1.8077460809420514

Epoch: 6| Step: 1
Training loss: 0.27933308482170105
Validation loss: 1.8430650939223587

Epoch: 6| Step: 2
Training loss: 0.4949858486652374
Validation loss: 1.8295856932158112

Epoch: 6| Step: 3
Training loss: 1.0540552139282227
Validation loss: 1.8043155811166252

Epoch: 6| Step: 4
Training loss: 0.5649300217628479
Validation loss: 1.811235789329775

Epoch: 6| Step: 5
Training loss: 0.8566840291023254
Validation loss: 1.8093919382300427

Epoch: 6| Step: 6
Training loss: 0.6293308138847351
Validation loss: 1.7894241758572158

Epoch: 6| Step: 7
Training loss: 0.7297660112380981
Validation loss: 1.8286376268632951

Epoch: 6| Step: 8
Training loss: 0.9680215120315552
Validation loss: 1.7795801611356838

Epoch: 6| Step: 9
Training loss: 0.5446237325668335
Validation loss: 1.8027621635826685

Epoch: 6| Step: 10
Training loss: 0.4637303352355957
Validation loss: 1.8119607945924163

Epoch: 6| Step: 11
Training loss: 0.5445315837860107
Validation loss: 1.8216508152664348

Epoch: 6| Step: 12
Training loss: 0.6396744847297668
Validation loss: 1.835184351090462

Epoch: 6| Step: 13
Training loss: 0.44559013843536377
Validation loss: 1.841340007320527

Epoch: 201| Step: 0
Training loss: 0.6958090662956238
Validation loss: 1.8557068365876392

Epoch: 6| Step: 1
Training loss: 0.5844519138336182
Validation loss: 1.835900149037761

Epoch: 6| Step: 2
Training loss: 0.585533082485199
Validation loss: 1.764852354603429

Epoch: 6| Step: 3
Training loss: 0.9107412695884705
Validation loss: 1.7628112326386154

Epoch: 6| Step: 4
Training loss: 0.4293426275253296
Validation loss: 1.7466375443243212

Epoch: 6| Step: 5
Training loss: 0.6739250421524048
Validation loss: 1.7583299862441195

Epoch: 6| Step: 6
Training loss: 0.6327183842658997
Validation loss: 1.7634556934397707

Epoch: 6| Step: 7
Training loss: 1.0463776588439941
Validation loss: 1.7793585485027683

Epoch: 6| Step: 8
Training loss: 0.7074116468429565
Validation loss: 1.7612942726381364

Epoch: 6| Step: 9
Training loss: 0.600569486618042
Validation loss: 1.8093636484556301

Epoch: 6| Step: 10
Training loss: 0.48411768674850464
Validation loss: 1.8009478122957292

Epoch: 6| Step: 11
Training loss: 0.4179539382457733
Validation loss: 1.8343222089993056

Epoch: 6| Step: 12
Training loss: 0.4566386640071869
Validation loss: 1.8557031667360695

Epoch: 6| Step: 13
Training loss: 0.9667521715164185
Validation loss: 1.8435996501676497

Epoch: 202| Step: 0
Training loss: 0.6167932152748108
Validation loss: 1.8459665095934303

Epoch: 6| Step: 1
Training loss: 0.6717911958694458
Validation loss: 1.8642874251129806

Epoch: 6| Step: 2
Training loss: 0.6678544878959656
Validation loss: 1.841968305649296

Epoch: 6| Step: 3
Training loss: 0.6470358371734619
Validation loss: 1.8384043683287918

Epoch: 6| Step: 4
Training loss: 0.5219082236289978
Validation loss: 1.8224329307515135

Epoch: 6| Step: 5
Training loss: 0.8477720022201538
Validation loss: 1.8366129423982354

Epoch: 6| Step: 6
Training loss: 0.6814889907836914
Validation loss: 1.8131977204353578

Epoch: 6| Step: 7
Training loss: 0.5838976502418518
Validation loss: 1.8122191506047403

Epoch: 6| Step: 8
Training loss: 0.5476027131080627
Validation loss: 1.7703709410082908

Epoch: 6| Step: 9
Training loss: 0.5470684170722961
Validation loss: 1.7667125822395406

Epoch: 6| Step: 10
Training loss: 0.7594757080078125
Validation loss: 1.7599187589460803

Epoch: 6| Step: 11
Training loss: 0.6034254431724548
Validation loss: 1.7789796680532477

Epoch: 6| Step: 12
Training loss: 0.9128941893577576
Validation loss: 1.7507639610639183

Epoch: 6| Step: 13
Training loss: 0.2278478443622589
Validation loss: 1.7584954025924846

Epoch: 203| Step: 0
Training loss: 0.3658563494682312
Validation loss: 1.746070127333364

Epoch: 6| Step: 1
Training loss: 0.4172135293483734
Validation loss: 1.7965484511467718

Epoch: 6| Step: 2
Training loss: 0.6547217965126038
Validation loss: 1.76944258136134

Epoch: 6| Step: 3
Training loss: 0.5975234508514404
Validation loss: 1.8026212030841458

Epoch: 6| Step: 4
Training loss: 0.5561797618865967
Validation loss: 1.7883704259831419

Epoch: 6| Step: 5
Training loss: 0.5480385422706604
Validation loss: 1.7856610962139663

Epoch: 6| Step: 6
Training loss: 0.5942277908325195
Validation loss: 1.795845095829297

Epoch: 6| Step: 7
Training loss: 0.9162499904632568
Validation loss: 1.785636519873014

Epoch: 6| Step: 8
Training loss: 0.5280183553695679
Validation loss: 1.8247126879230622

Epoch: 6| Step: 9
Training loss: 0.9148592948913574
Validation loss: 1.818871032807135

Epoch: 6| Step: 10
Training loss: 0.44627201557159424
Validation loss: 1.8493171391948577

Epoch: 6| Step: 11
Training loss: 0.7498873472213745
Validation loss: 1.840511739894908

Epoch: 6| Step: 12
Training loss: 0.45772141218185425
Validation loss: 1.8025110114005305

Epoch: 6| Step: 13
Training loss: 0.7879793047904968
Validation loss: 1.7253848096375823

Epoch: 204| Step: 0
Training loss: 0.6842797994613647
Validation loss: 1.753503058546333

Epoch: 6| Step: 1
Training loss: 0.7113786935806274
Validation loss: 1.7522857727543

Epoch: 6| Step: 2
Training loss: 0.5003787875175476
Validation loss: 1.737569453895733

Epoch: 6| Step: 3
Training loss: 0.6942687630653381
Validation loss: 1.7446257401538152

Epoch: 6| Step: 4
Training loss: 0.5763134360313416
Validation loss: 1.7889078483786633

Epoch: 6| Step: 5
Training loss: 0.8388533592224121
Validation loss: 1.8117731219978743

Epoch: 6| Step: 6
Training loss: 0.7230349779129028
Validation loss: 1.8807340283547678

Epoch: 6| Step: 7
Training loss: 0.6693762540817261
Validation loss: 1.8980650747975996

Epoch: 6| Step: 8
Training loss: 0.4188443422317505
Validation loss: 1.8775444287125782

Epoch: 6| Step: 9
Training loss: 0.5460302829742432
Validation loss: 1.8803943408432828

Epoch: 6| Step: 10
Training loss: 0.48101624846458435
Validation loss: 1.8603506767621605

Epoch: 6| Step: 11
Training loss: 0.555974543094635
Validation loss: 1.8016934933200959

Epoch: 6| Step: 12
Training loss: 0.7001287341117859
Validation loss: 1.7741347820528093

Epoch: 6| Step: 13
Training loss: 0.5465316772460938
Validation loss: 1.7702468287560247

Epoch: 205| Step: 0
Training loss: 0.5148718953132629
Validation loss: 1.7927559511635893

Epoch: 6| Step: 1
Training loss: 0.4644966423511505
Validation loss: 1.7756651370756087

Epoch: 6| Step: 2
Training loss: 0.73117995262146
Validation loss: 1.7948520798836984

Epoch: 6| Step: 3
Training loss: 0.6464998126029968
Validation loss: 1.7960550259518366

Epoch: 6| Step: 4
Training loss: 0.644377589225769
Validation loss: 1.7730759843703239

Epoch: 6| Step: 5
Training loss: 0.7730620503425598
Validation loss: 1.7794114338454379

Epoch: 6| Step: 6
Training loss: 1.2951040267944336
Validation loss: 1.7664730318130986

Epoch: 6| Step: 7
Training loss: 0.3172363042831421
Validation loss: 1.7954875025697934

Epoch: 6| Step: 8
Training loss: 0.6947358846664429
Validation loss: 1.7946640240248812

Epoch: 6| Step: 9
Training loss: 0.41911187767982483
Validation loss: 1.8222891246118853

Epoch: 6| Step: 10
Training loss: 0.3212212920188904
Validation loss: 1.8225057714728898

Epoch: 6| Step: 11
Training loss: 0.5177508592605591
Validation loss: 1.8360666728788806

Epoch: 6| Step: 12
Training loss: 0.45688146352767944
Validation loss: 1.889343834692432

Epoch: 6| Step: 13
Training loss: 0.7724373936653137
Validation loss: 1.8357710966499903

Epoch: 206| Step: 0
Training loss: 0.6700159311294556
Validation loss: 1.8132880836404779

Epoch: 6| Step: 1
Training loss: 0.569858968257904
Validation loss: 1.8047307345174974

Epoch: 6| Step: 2
Training loss: 0.48032236099243164
Validation loss: 1.7932809399020286

Epoch: 6| Step: 3
Training loss: 0.2837425470352173
Validation loss: 1.7410129731701267

Epoch: 6| Step: 4
Training loss: 0.6362684369087219
Validation loss: 1.7550269788311375

Epoch: 6| Step: 5
Training loss: 0.4164090156555176
Validation loss: 1.7538325017498386

Epoch: 6| Step: 6
Training loss: 0.477659672498703
Validation loss: 1.7706150649696268

Epoch: 6| Step: 7
Training loss: 0.8566530346870422
Validation loss: 1.796898139420376

Epoch: 6| Step: 8
Training loss: 0.6901767253875732
Validation loss: 1.7888535120153939

Epoch: 6| Step: 9
Training loss: 0.3383724093437195
Validation loss: 1.7692171091674476

Epoch: 6| Step: 10
Training loss: 0.7094907760620117
Validation loss: 1.7663374921326995

Epoch: 6| Step: 11
Training loss: 0.5394180417060852
Validation loss: 1.803868273253082

Epoch: 6| Step: 12
Training loss: 0.8213558197021484
Validation loss: 1.7979564769293672

Epoch: 6| Step: 13
Training loss: 0.7335377931594849
Validation loss: 1.812575130052464

Epoch: 207| Step: 0
Training loss: 0.3168962895870209
Validation loss: 1.798898725099461

Epoch: 6| Step: 1
Training loss: 0.7248225212097168
Validation loss: 1.795425945712674

Epoch: 6| Step: 2
Training loss: 0.3648114800453186
Validation loss: 1.7872524197383592

Epoch: 6| Step: 3
Training loss: 0.5023407936096191
Validation loss: 1.773533926215223

Epoch: 6| Step: 4
Training loss: 0.368381530046463
Validation loss: 1.799567045704011

Epoch: 6| Step: 5
Training loss: 0.4485836625099182
Validation loss: 1.8101594845453899

Epoch: 6| Step: 6
Training loss: 0.4011514484882355
Validation loss: 1.8109391453445598

Epoch: 6| Step: 7
Training loss: 0.7447490692138672
Validation loss: 1.8531355191302556

Epoch: 6| Step: 8
Training loss: 0.8062556982040405
Validation loss: 1.8216254531696279

Epoch: 6| Step: 9
Training loss: 0.9950884580612183
Validation loss: 1.8277155891541512

Epoch: 6| Step: 10
Training loss: 0.7330953478813171
Validation loss: 1.7701679968064832

Epoch: 6| Step: 11
Training loss: 0.372946560382843
Validation loss: 1.7605065940528788

Epoch: 6| Step: 12
Training loss: 0.6648634672164917
Validation loss: 1.7923478670017694

Epoch: 6| Step: 13
Training loss: 0.5933451652526855
Validation loss: 1.7759038145824144

Epoch: 208| Step: 0
Training loss: 0.4135226011276245
Validation loss: 1.748146091738055

Epoch: 6| Step: 1
Training loss: 0.6632479429244995
Validation loss: 1.7639660912175332

Epoch: 6| Step: 2
Training loss: 0.7621728181838989
Validation loss: 1.7399301182839177

Epoch: 6| Step: 3
Training loss: 0.4702076315879822
Validation loss: 1.7484057205979542

Epoch: 6| Step: 4
Training loss: 0.6543242335319519
Validation loss: 1.7642870474887151

Epoch: 6| Step: 5
Training loss: 0.7176926136016846
Validation loss: 1.7965498124399493

Epoch: 6| Step: 6
Training loss: 0.5601974129676819
Validation loss: 1.8350076957415509

Epoch: 6| Step: 7
Training loss: 0.5429470539093018
Validation loss: 1.8142970338944466

Epoch: 6| Step: 8
Training loss: 0.461195170879364
Validation loss: 1.8182713447078582

Epoch: 6| Step: 9
Training loss: 0.6907888650894165
Validation loss: 1.8009335866538427

Epoch: 6| Step: 10
Training loss: 0.3167218565940857
Validation loss: 1.7973399111019668

Epoch: 6| Step: 11
Training loss: 0.6201722621917725
Validation loss: 1.8030375947234452

Epoch: 6| Step: 12
Training loss: 0.6230412721633911
Validation loss: 1.79770367376266

Epoch: 6| Step: 13
Training loss: 0.5067564845085144
Validation loss: 1.7566850621213195

Epoch: 209| Step: 0
Training loss: 0.7705165147781372
Validation loss: 1.7826948024893319

Epoch: 6| Step: 1
Training loss: 0.6207287907600403
Validation loss: 1.7529330779147405

Epoch: 6| Step: 2
Training loss: 0.7251541614532471
Validation loss: 1.7322020735791934

Epoch: 6| Step: 3
Training loss: 0.400834858417511
Validation loss: 1.7950808873740576

Epoch: 6| Step: 4
Training loss: 0.4902619421482086
Validation loss: 1.7644116340144989

Epoch: 6| Step: 5
Training loss: 0.6606659889221191
Validation loss: 1.7829524150458715

Epoch: 6| Step: 6
Training loss: 0.42208465933799744
Validation loss: 1.77051902714596

Epoch: 6| Step: 7
Training loss: 0.4992114305496216
Validation loss: 1.792054460894677

Epoch: 6| Step: 8
Training loss: 0.6693071126937866
Validation loss: 1.7958739919047202

Epoch: 6| Step: 9
Training loss: 0.4359310269355774
Validation loss: 1.7806343147831578

Epoch: 6| Step: 10
Training loss: 0.3984759747982025
Validation loss: 1.7743626230506486

Epoch: 6| Step: 11
Training loss: 0.6226933002471924
Validation loss: 1.804112684342169

Epoch: 6| Step: 12
Training loss: 0.6395189762115479
Validation loss: 1.7663939922086653

Epoch: 6| Step: 13
Training loss: 0.3237653970718384
Validation loss: 1.7762566176793908

Epoch: 210| Step: 0
Training loss: 0.7879884839057922
Validation loss: 1.7865225525312527

Epoch: 6| Step: 1
Training loss: 0.3104885220527649
Validation loss: 1.8273220241710704

Epoch: 6| Step: 2
Training loss: 0.38663583993911743
Validation loss: 1.8083359144067253

Epoch: 6| Step: 3
Training loss: 0.9212487936019897
Validation loss: 1.778704135648666

Epoch: 6| Step: 4
Training loss: 0.5944364070892334
Validation loss: 1.738120686623358

Epoch: 6| Step: 5
Training loss: 0.5747965574264526
Validation loss: 1.7174605900241482

Epoch: 6| Step: 6
Training loss: 0.5705068707466125
Validation loss: 1.7288450182125132

Epoch: 6| Step: 7
Training loss: 0.4730149507522583
Validation loss: 1.779288100939925

Epoch: 6| Step: 8
Training loss: 0.303845077753067
Validation loss: 1.7839028976296867

Epoch: 6| Step: 9
Training loss: 0.5616834163665771
Validation loss: 1.8147557204769504

Epoch: 6| Step: 10
Training loss: 0.8985263705253601
Validation loss: 1.824870119812668

Epoch: 6| Step: 11
Training loss: 0.4020768404006958
Validation loss: 1.8225180243933072

Epoch: 6| Step: 12
Training loss: 0.4904702305793762
Validation loss: 1.8556303977966309

Epoch: 6| Step: 13
Training loss: 0.7210521697998047
Validation loss: 1.818956349485664

Epoch: 211| Step: 0
Training loss: 0.5537706017494202
Validation loss: 1.8256002113383303

Epoch: 6| Step: 1
Training loss: 0.4360659122467041
Validation loss: 1.8244874554295694

Epoch: 6| Step: 2
Training loss: 0.40102580189704895
Validation loss: 1.8059397192411526

Epoch: 6| Step: 3
Training loss: 0.5553568601608276
Validation loss: 1.7957967686396774

Epoch: 6| Step: 4
Training loss: 0.24672624468803406
Validation loss: 1.7780577956989247

Epoch: 6| Step: 5
Training loss: 0.3433379530906677
Validation loss: 1.7615751117788336

Epoch: 6| Step: 6
Training loss: 0.38039320707321167
Validation loss: 1.7742497062170377

Epoch: 6| Step: 7
Training loss: 0.5785888433456421
Validation loss: 1.8032522432265743

Epoch: 6| Step: 8
Training loss: 0.45949500799179077
Validation loss: 1.814929380211779

Epoch: 6| Step: 9
Training loss: 0.5265144109725952
Validation loss: 1.7877033025987688

Epoch: 6| Step: 10
Training loss: 0.8975406885147095
Validation loss: 1.729127639083452

Epoch: 6| Step: 11
Training loss: 0.797524631023407
Validation loss: 1.8025710172550653

Epoch: 6| Step: 12
Training loss: 1.0213967561721802
Validation loss: 1.7880040009816487

Epoch: 6| Step: 13
Training loss: 0.3330242931842804
Validation loss: 1.7822906048067155

Epoch: 212| Step: 0
Training loss: 0.5925414562225342
Validation loss: 1.7757850193208264

Epoch: 6| Step: 1
Training loss: 0.3912948966026306
Validation loss: 1.7756404338344451

Epoch: 6| Step: 2
Training loss: 0.9177919030189514
Validation loss: 1.7598919971014864

Epoch: 6| Step: 3
Training loss: 0.5688174962997437
Validation loss: 1.7375482718149822

Epoch: 6| Step: 4
Training loss: 0.44748321175575256
Validation loss: 1.7292724963157409

Epoch: 6| Step: 5
Training loss: 0.41217559576034546
Validation loss: 1.7117536132053663

Epoch: 6| Step: 6
Training loss: 0.49205783009529114
Validation loss: 1.7098530800111833

Epoch: 6| Step: 7
Training loss: 0.8985419273376465
Validation loss: 1.7575752722319735

Epoch: 6| Step: 8
Training loss: 0.4523044228553772
Validation loss: 1.7927465618297618

Epoch: 6| Step: 9
Training loss: 0.3049218952655792
Validation loss: 1.812967997725292

Epoch: 6| Step: 10
Training loss: 0.5612649321556091
Validation loss: 1.8026102025021788

Epoch: 6| Step: 11
Training loss: 0.47477173805236816
Validation loss: 1.790124003605176

Epoch: 6| Step: 12
Training loss: 0.4270991384983063
Validation loss: 1.8404447276105163

Epoch: 6| Step: 13
Training loss: 0.4512427747249603
Validation loss: 1.799020077592583

Epoch: 213| Step: 0
Training loss: 0.4279634654521942
Validation loss: 1.7884710988690775

Epoch: 6| Step: 1
Training loss: 0.363877534866333
Validation loss: 1.782958745956421

Epoch: 6| Step: 2
Training loss: 0.3912056088447571
Validation loss: 1.7308548188978625

Epoch: 6| Step: 3
Training loss: 0.41585007309913635
Validation loss: 1.759425978506765

Epoch: 6| Step: 4
Training loss: 0.6501190662384033
Validation loss: 1.7523391810796594

Epoch: 6| Step: 5
Training loss: 0.4907692074775696
Validation loss: 1.7601908394085464

Epoch: 6| Step: 6
Training loss: 0.5121069550514221
Validation loss: 1.7786400766782864

Epoch: 6| Step: 7
Training loss: 0.5322912931442261
Validation loss: 1.817830975337695

Epoch: 6| Step: 8
Training loss: 0.4118841290473938
Validation loss: 1.8324595112954416

Epoch: 6| Step: 9
Training loss: 0.5993978977203369
Validation loss: 1.8308306881176528

Epoch: 6| Step: 10
Training loss: 0.39934468269348145
Validation loss: 1.812014172154088

Epoch: 6| Step: 11
Training loss: 0.6327682733535767
Validation loss: 1.8166688872921852

Epoch: 6| Step: 12
Training loss: 0.9323824644088745
Validation loss: 1.7841807744836296

Epoch: 6| Step: 13
Training loss: 0.39353325963020325
Validation loss: 1.801749990832421

Epoch: 214| Step: 0
Training loss: 0.4531184136867523
Validation loss: 1.793160798729107

Epoch: 6| Step: 1
Training loss: 0.6571021676063538
Validation loss: 1.7553192043817172

Epoch: 6| Step: 2
Training loss: 0.45544567704200745
Validation loss: 1.7585433913815407

Epoch: 6| Step: 3
Training loss: 0.6423683166503906
Validation loss: 1.8213197262056413

Epoch: 6| Step: 4
Training loss: 0.3932275176048279
Validation loss: 1.736262265072074

Epoch: 6| Step: 5
Training loss: 0.5599607229232788
Validation loss: 1.8024385975253197

Epoch: 6| Step: 6
Training loss: 0.4056094288825989
Validation loss: 1.7796472131565053

Epoch: 6| Step: 7
Training loss: 0.3452354669570923
Validation loss: 1.7436679050486574

Epoch: 6| Step: 8
Training loss: 0.6386131048202515
Validation loss: 1.7394980999731249

Epoch: 6| Step: 9
Training loss: 0.4775599241256714
Validation loss: 1.711097030229466

Epoch: 6| Step: 10
Training loss: 0.4352046251296997
Validation loss: 1.7323020228775599

Epoch: 6| Step: 11
Training loss: 0.4466398060321808
Validation loss: 1.6975211892076718

Epoch: 6| Step: 12
Training loss: 0.8108358979225159
Validation loss: 1.7066598848630024

Epoch: 6| Step: 13
Training loss: 0.3469715416431427
Validation loss: 1.7308324742060837

Epoch: 215| Step: 0
Training loss: 0.5734484791755676
Validation loss: 1.729948668069737

Epoch: 6| Step: 1
Training loss: 0.45896419882774353
Validation loss: 1.7212100298173967

Epoch: 6| Step: 2
Training loss: 0.6433905363082886
Validation loss: 1.739070894897625

Epoch: 6| Step: 3
Training loss: 1.024218201637268
Validation loss: 1.7716451460315334

Epoch: 6| Step: 4
Training loss: 0.6428647637367249
Validation loss: 1.8133002532425748

Epoch: 6| Step: 5
Training loss: 0.4537477493286133
Validation loss: 1.8061179038017028

Epoch: 6| Step: 6
Training loss: 0.738429069519043
Validation loss: 1.8468860990257674

Epoch: 6| Step: 7
Training loss: 0.5551151633262634
Validation loss: 1.8358668832368747

Epoch: 6| Step: 8
Training loss: 0.40143629908561707
Validation loss: 1.835577141854071

Epoch: 6| Step: 9
Training loss: 0.6572960615158081
Validation loss: 1.8158832737194595

Epoch: 6| Step: 10
Training loss: 0.5527504682540894
Validation loss: 1.8244340663315148

Epoch: 6| Step: 11
Training loss: 0.5353130102157593
Validation loss: 1.7862947115334131

Epoch: 6| Step: 12
Training loss: 0.4901602864265442
Validation loss: 1.823105460853987

Epoch: 6| Step: 13
Training loss: 0.34345942735671997
Validation loss: 1.7814634346192884

Epoch: 216| Step: 0
Training loss: 0.446341335773468
Validation loss: 1.7566781197824786

Epoch: 6| Step: 1
Training loss: 0.24117828905582428
Validation loss: 1.7720139462460753

Epoch: 6| Step: 2
Training loss: 0.49853289127349854
Validation loss: 1.7917524614641744

Epoch: 6| Step: 3
Training loss: 0.45215439796447754
Validation loss: 1.7894874336898967

Epoch: 6| Step: 4
Training loss: 0.7508885264396667
Validation loss: 1.7909780586919477

Epoch: 6| Step: 5
Training loss: 0.6673641204833984
Validation loss: 1.7910134882055304

Epoch: 6| Step: 6
Training loss: 0.31349918246269226
Validation loss: 1.7672261538044098

Epoch: 6| Step: 7
Training loss: 0.482509970664978
Validation loss: 1.7550036099649244

Epoch: 6| Step: 8
Training loss: 0.34365421533584595
Validation loss: 1.7597681655678699

Epoch: 6| Step: 9
Training loss: 0.5800674557685852
Validation loss: 1.7485218509551017

Epoch: 6| Step: 10
Training loss: 0.8250501155853271
Validation loss: 1.7609152499065603

Epoch: 6| Step: 11
Training loss: 0.47036808729171753
Validation loss: 1.7444976177266849

Epoch: 6| Step: 12
Training loss: 0.5674429535865784
Validation loss: 1.7700415965049499

Epoch: 6| Step: 13
Training loss: 0.588767945766449
Validation loss: 1.801112695406842

Epoch: 217| Step: 0
Training loss: 0.46046704053878784
Validation loss: 1.8495697308612127

Epoch: 6| Step: 1
Training loss: 0.6681816577911377
Validation loss: 1.8684693767178444

Epoch: 6| Step: 2
Training loss: 0.643493115901947
Validation loss: 1.873994783688617

Epoch: 6| Step: 3
Training loss: 0.7319003343582153
Validation loss: 1.8259625742512364

Epoch: 6| Step: 4
Training loss: 0.396281898021698
Validation loss: 1.7957944023993708

Epoch: 6| Step: 5
Training loss: 0.4330361485481262
Validation loss: 1.7270605910208918

Epoch: 6| Step: 6
Training loss: 0.39990729093551636
Validation loss: 1.7369040635324293

Epoch: 6| Step: 7
Training loss: 0.744269847869873
Validation loss: 1.7681152051494968

Epoch: 6| Step: 8
Training loss: 0.44327110052108765
Validation loss: 1.7956383561575284

Epoch: 6| Step: 9
Training loss: 0.386757493019104
Validation loss: 1.7682770221464095

Epoch: 6| Step: 10
Training loss: 0.5106024146080017
Validation loss: 1.7228670889331448

Epoch: 6| Step: 11
Training loss: 0.43076109886169434
Validation loss: 1.7380706571763562

Epoch: 6| Step: 12
Training loss: 0.4650900661945343
Validation loss: 1.79411026482941

Epoch: 6| Step: 13
Training loss: 0.636849045753479
Validation loss: 1.8002469334551083

Epoch: 218| Step: 0
Training loss: 0.7047930955886841
Validation loss: 1.7882017089474587

Epoch: 6| Step: 1
Training loss: 0.3783947229385376
Validation loss: 1.81716949196272

Epoch: 6| Step: 2
Training loss: 0.3966909945011139
Validation loss: 1.7570042635804863

Epoch: 6| Step: 3
Training loss: 0.4352341890335083
Validation loss: 1.7324749551793581

Epoch: 6| Step: 4
Training loss: 0.3858450651168823
Validation loss: 1.6969423217158164

Epoch: 6| Step: 5
Training loss: 0.5395982265472412
Validation loss: 1.6888156219195294

Epoch: 6| Step: 6
Training loss: 0.4229157567024231
Validation loss: 1.6851618764221028

Epoch: 6| Step: 7
Training loss: 0.31386688351631165
Validation loss: 1.6878235570846065

Epoch: 6| Step: 8
Training loss: 0.5206636190414429
Validation loss: 1.6791790980164722

Epoch: 6| Step: 9
Training loss: 0.4663504362106323
Validation loss: 1.6950473605945546

Epoch: 6| Step: 10
Training loss: 0.7514181137084961
Validation loss: 1.708104661715928

Epoch: 6| Step: 11
Training loss: 0.7195926904678345
Validation loss: 1.7165771504884124

Epoch: 6| Step: 12
Training loss: 0.5948500037193298
Validation loss: 1.6929643436144757

Epoch: 6| Step: 13
Training loss: 0.3381431996822357
Validation loss: 1.7182510168321672

Epoch: 219| Step: 0
Training loss: 0.4778338074684143
Validation loss: 1.7083242657364055

Epoch: 6| Step: 1
Training loss: 0.28716450929641724
Validation loss: 1.753517461079423

Epoch: 6| Step: 2
Training loss: 0.6307218074798584
Validation loss: 1.714000726258883

Epoch: 6| Step: 3
Training loss: 0.5011634826660156
Validation loss: 1.7310644029289164

Epoch: 6| Step: 4
Training loss: 0.5760271549224854
Validation loss: 1.7280324543676069

Epoch: 6| Step: 5
Training loss: 0.6542122960090637
Validation loss: 1.7842049752512286

Epoch: 6| Step: 6
Training loss: 0.4857311248779297
Validation loss: 1.7492610998051141

Epoch: 6| Step: 7
Training loss: 0.49970078468322754
Validation loss: 1.7619623086785758

Epoch: 6| Step: 8
Training loss: 0.3353550434112549
Validation loss: 1.7411970989678496

Epoch: 6| Step: 9
Training loss: 0.47014832496643066
Validation loss: 1.7279524713434198

Epoch: 6| Step: 10
Training loss: 0.45287853479385376
Validation loss: 1.7146174330865183

Epoch: 6| Step: 11
Training loss: 0.6459088325500488
Validation loss: 1.7211483422146048

Epoch: 6| Step: 12
Training loss: 0.3911527395248413
Validation loss: 1.7521572548856017

Epoch: 6| Step: 13
Training loss: 0.5486788153648376
Validation loss: 1.7471539282029676

Epoch: 220| Step: 0
Training loss: 0.5104080438613892
Validation loss: 1.7696112150787024

Epoch: 6| Step: 1
Training loss: 0.6527774333953857
Validation loss: 1.770256305253634

Epoch: 6| Step: 2
Training loss: 0.5278611183166504
Validation loss: 1.7530910276597547

Epoch: 6| Step: 3
Training loss: 0.2595105469226837
Validation loss: 1.7892840241873136

Epoch: 6| Step: 4
Training loss: 0.2765536606311798
Validation loss: 1.7962650727200251

Epoch: 6| Step: 5
Training loss: 0.6448019742965698
Validation loss: 1.7527875131176365

Epoch: 6| Step: 6
Training loss: 0.3686143755912781
Validation loss: 1.7832877674410421

Epoch: 6| Step: 7
Training loss: 0.6121887564659119
Validation loss: 1.7937274158641856

Epoch: 6| Step: 8
Training loss: 0.38600999116897583
Validation loss: 1.761565463517302

Epoch: 6| Step: 9
Training loss: 0.7670005559921265
Validation loss: 1.7391661559381792

Epoch: 6| Step: 10
Training loss: 0.2828930616378784
Validation loss: 1.7450424304572485

Epoch: 6| Step: 11
Training loss: 0.3478069305419922
Validation loss: 1.7806695148509035

Epoch: 6| Step: 12
Training loss: 0.29189491271972656
Validation loss: 1.7847922502025482

Epoch: 6| Step: 13
Training loss: 0.7675547003746033
Validation loss: 1.74988773176747

Epoch: 221| Step: 0
Training loss: 0.5409992337226868
Validation loss: 1.7464316826994701

Epoch: 6| Step: 1
Training loss: 0.3927862048149109
Validation loss: 1.7303295007316015

Epoch: 6| Step: 2
Training loss: 0.8186252117156982
Validation loss: 1.7099586597052954

Epoch: 6| Step: 3
Training loss: 0.3945174217224121
Validation loss: 1.7307782467975412

Epoch: 6| Step: 4
Training loss: 0.354093074798584
Validation loss: 1.7032116382352767

Epoch: 6| Step: 5
Training loss: 0.31078648567199707
Validation loss: 1.7450183950444704

Epoch: 6| Step: 6
Training loss: 0.46174266934394836
Validation loss: 1.75878894200889

Epoch: 6| Step: 7
Training loss: 0.524634599685669
Validation loss: 1.732852009034926

Epoch: 6| Step: 8
Training loss: 0.5879356861114502
Validation loss: 1.7351115621546263

Epoch: 6| Step: 9
Training loss: 0.2592202425003052
Validation loss: 1.7241857897850774

Epoch: 6| Step: 10
Training loss: 0.4984932839870453
Validation loss: 1.7457006451904133

Epoch: 6| Step: 11
Training loss: 0.3451848030090332
Validation loss: 1.7393465926570277

Epoch: 6| Step: 12
Training loss: 0.3989527225494385
Validation loss: 1.7187382944168583

Epoch: 6| Step: 13
Training loss: 0.6401358246803284
Validation loss: 1.754036134289157

Epoch: 222| Step: 0
Training loss: 0.3559550940990448
Validation loss: 1.7400670807848695

Epoch: 6| Step: 1
Training loss: 0.27790433168411255
Validation loss: 1.714952729081595

Epoch: 6| Step: 2
Training loss: 0.7735244035720825
Validation loss: 1.7282621681049306

Epoch: 6| Step: 3
Training loss: 0.28056949377059937
Validation loss: 1.7210415819639802

Epoch: 6| Step: 4
Training loss: 0.3209715187549591
Validation loss: 1.727792178430865

Epoch: 6| Step: 5
Training loss: 0.3901999890804291
Validation loss: 1.712060906553781

Epoch: 6| Step: 6
Training loss: 0.392570436000824
Validation loss: 1.7049009607684227

Epoch: 6| Step: 7
Training loss: 0.4434729814529419
Validation loss: 1.7374618668710031

Epoch: 6| Step: 8
Training loss: 0.4870731234550476
Validation loss: 1.7398113268677906

Epoch: 6| Step: 9
Training loss: 0.3697115480899811
Validation loss: 1.7132769169345978

Epoch: 6| Step: 10
Training loss: 0.3822007179260254
Validation loss: 1.7047100118411485

Epoch: 6| Step: 11
Training loss: 0.6617987155914307
Validation loss: 1.727967687832412

Epoch: 6| Step: 12
Training loss: 0.6349421739578247
Validation loss: 1.739152213578583

Epoch: 6| Step: 13
Training loss: 0.5990245938301086
Validation loss: 1.74857888555014

Epoch: 223| Step: 0
Training loss: 0.3510734736919403
Validation loss: 1.7210875672678794

Epoch: 6| Step: 1
Training loss: 0.6782432794570923
Validation loss: 1.7638981521770518

Epoch: 6| Step: 2
Training loss: 0.4235835075378418
Validation loss: 1.768527461636451

Epoch: 6| Step: 3
Training loss: 0.4858395457267761
Validation loss: 1.767293526280311

Epoch: 6| Step: 4
Training loss: 0.3614997863769531
Validation loss: 1.7609698644248388

Epoch: 6| Step: 5
Training loss: 0.5459720492362976
Validation loss: 1.7981439598145024

Epoch: 6| Step: 6
Training loss: 0.4691176414489746
Validation loss: 1.7696803680030249

Epoch: 6| Step: 7
Training loss: 0.474279522895813
Validation loss: 1.7750535754747288

Epoch: 6| Step: 8
Training loss: 0.5371952056884766
Validation loss: 1.7555564449679466

Epoch: 6| Step: 9
Training loss: 0.5444090366363525
Validation loss: 1.7210128691888624

Epoch: 6| Step: 10
Training loss: 0.530304491519928
Validation loss: 1.748865233954563

Epoch: 6| Step: 11
Training loss: 0.24792839586734772
Validation loss: 1.7059625182100522

Epoch: 6| Step: 12
Training loss: 0.3217446804046631
Validation loss: 1.7454809975880448

Epoch: 6| Step: 13
Training loss: 0.4478742778301239
Validation loss: 1.704255529629287

Epoch: 224| Step: 0
Training loss: 0.4062413275241852
Validation loss: 1.685483617167319

Epoch: 6| Step: 1
Training loss: 0.5408149361610413
Validation loss: 1.728620111301381

Epoch: 6| Step: 2
Training loss: 0.46265125274658203
Validation loss: 1.7138788174557429

Epoch: 6| Step: 3
Training loss: 0.5186784863471985
Validation loss: 1.7169503511921052

Epoch: 6| Step: 4
Training loss: 0.33309245109558105
Validation loss: 1.694560145819059

Epoch: 6| Step: 5
Training loss: 0.27467066049575806
Validation loss: 1.7089829367976035

Epoch: 6| Step: 6
Training loss: 0.5923175811767578
Validation loss: 1.7408940048627957

Epoch: 6| Step: 7
Training loss: 0.45904088020324707
Validation loss: 1.7463216153524255

Epoch: 6| Step: 8
Training loss: 0.2656249403953552
Validation loss: 1.7741893183800481

Epoch: 6| Step: 9
Training loss: 0.7601414322853088
Validation loss: 1.7852295419221282

Epoch: 6| Step: 10
Training loss: 0.5107825398445129
Validation loss: 1.7708881529428626

Epoch: 6| Step: 11
Training loss: 0.5167531967163086
Validation loss: 1.8203327681428643

Epoch: 6| Step: 12
Training loss: 0.5263080596923828
Validation loss: 1.7838047883843864

Epoch: 6| Step: 13
Training loss: 0.34670618176460266
Validation loss: 1.7686452404145272

Epoch: 225| Step: 0
Training loss: 0.2629191279411316
Validation loss: 1.7182112099021993

Epoch: 6| Step: 1
Training loss: 0.6418643593788147
Validation loss: 1.750785821227617

Epoch: 6| Step: 2
Training loss: 0.5458511114120483
Validation loss: 1.7439073055021224

Epoch: 6| Step: 3
Training loss: 1.0195443630218506
Validation loss: 1.728015588816776

Epoch: 6| Step: 4
Training loss: 0.4182354211807251
Validation loss: 1.7089113637965212

Epoch: 6| Step: 5
Training loss: 0.48921680450439453
Validation loss: 1.7449628614610242

Epoch: 6| Step: 6
Training loss: 0.33799415826797485
Validation loss: 1.6956974152595765

Epoch: 6| Step: 7
Training loss: 0.30660703778266907
Validation loss: 1.7540506137314664

Epoch: 6| Step: 8
Training loss: 0.4511248469352722
Validation loss: 1.7604831546865485

Epoch: 6| Step: 9
Training loss: 0.5438433885574341
Validation loss: 1.766394922810216

Epoch: 6| Step: 10
Training loss: 0.44192197918891907
Validation loss: 1.741536739051983

Epoch: 6| Step: 11
Training loss: 0.3060462474822998
Validation loss: 1.7642579360674786

Epoch: 6| Step: 12
Training loss: 0.4140617251396179
Validation loss: 1.7196440209624588

Epoch: 6| Step: 13
Training loss: 0.5099024176597595
Validation loss: 1.7444380252592024

Epoch: 226| Step: 0
Training loss: 0.4480710029602051
Validation loss: 1.7381012029545282

Epoch: 6| Step: 1
Training loss: 0.7350310683250427
Validation loss: 1.7673495251645324

Epoch: 6| Step: 2
Training loss: 0.4366559386253357
Validation loss: 1.7505647367046726

Epoch: 6| Step: 3
Training loss: 0.36905616521835327
Validation loss: 1.7703358075952018

Epoch: 6| Step: 4
Training loss: 0.1666087806224823
Validation loss: 1.7962774102405836

Epoch: 6| Step: 5
Training loss: 0.20000793039798737
Validation loss: 1.7934457294402584

Epoch: 6| Step: 6
Training loss: 0.5721540451049805
Validation loss: 1.818567273437336

Epoch: 6| Step: 7
Training loss: 0.4504307210445404
Validation loss: 1.7999992165514218

Epoch: 6| Step: 8
Training loss: 0.46893957257270813
Validation loss: 1.798231404314759

Epoch: 6| Step: 9
Training loss: 0.5487437844276428
Validation loss: 1.7982929752719017

Epoch: 6| Step: 10
Training loss: 0.7187352180480957
Validation loss: 1.7695012682227678

Epoch: 6| Step: 11
Training loss: 0.45366430282592773
Validation loss: 1.7606298154400242

Epoch: 6| Step: 12
Training loss: 0.534982442855835
Validation loss: 1.7275376499340098

Epoch: 6| Step: 13
Training loss: 0.2408938705921173
Validation loss: 1.714951035796955

Epoch: 227| Step: 0
Training loss: 0.3397923409938812
Validation loss: 1.749365827088715

Epoch: 6| Step: 1
Training loss: 0.4446116089820862
Validation loss: 1.77306798068426

Epoch: 6| Step: 2
Training loss: 0.5170271396636963
Validation loss: 1.7776074281302832

Epoch: 6| Step: 3
Training loss: 0.45039552450180054
Validation loss: 1.8035763156029485

Epoch: 6| Step: 4
Training loss: 0.43002456426620483
Validation loss: 1.7955721501381166

Epoch: 6| Step: 5
Training loss: 0.3315337598323822
Validation loss: 1.7627131823570497

Epoch: 6| Step: 6
Training loss: 0.4016834795475006
Validation loss: 1.7441787924817813

Epoch: 6| Step: 7
Training loss: 0.530463457107544
Validation loss: 1.7519747659724245

Epoch: 6| Step: 8
Training loss: 0.33774295449256897
Validation loss: 1.7654513056560228

Epoch: 6| Step: 9
Training loss: 0.5443848371505737
Validation loss: 1.7896989865969586

Epoch: 6| Step: 10
Training loss: 1.1863923072814941
Validation loss: 1.791489613953457

Epoch: 6| Step: 11
Training loss: 0.5094383358955383
Validation loss: 1.8147590121915262

Epoch: 6| Step: 12
Training loss: 0.3509405255317688
Validation loss: 1.7769861887860041

Epoch: 6| Step: 13
Training loss: 0.403633713722229
Validation loss: 1.7531780581320486

Epoch: 228| Step: 0
Training loss: 0.5770554542541504
Validation loss: 1.7369915593054988

Epoch: 6| Step: 1
Training loss: 0.37044090032577515
Validation loss: 1.7815441162355485

Epoch: 6| Step: 2
Training loss: 0.25998154282569885
Validation loss: 1.8079495955539007

Epoch: 6| Step: 3
Training loss: 0.6685201525688171
Validation loss: 1.7967803144967684

Epoch: 6| Step: 4
Training loss: 0.6203202605247498
Validation loss: 1.7860050509052892

Epoch: 6| Step: 5
Training loss: 0.3708643913269043
Validation loss: 1.7827988055444532

Epoch: 6| Step: 6
Training loss: 0.4099797308444977
Validation loss: 1.7369538840427194

Epoch: 6| Step: 7
Training loss: 0.6449193954467773
Validation loss: 1.7422113392942695

Epoch: 6| Step: 8
Training loss: 0.251811683177948
Validation loss: 1.7674194971720378

Epoch: 6| Step: 9
Training loss: 0.28099489212036133
Validation loss: 1.7447992422247445

Epoch: 6| Step: 10
Training loss: 0.5791423916816711
Validation loss: 1.7868454802420832

Epoch: 6| Step: 11
Training loss: 0.33231550455093384
Validation loss: 1.7864705926628524

Epoch: 6| Step: 12
Training loss: 0.5233403444290161
Validation loss: 1.7463363896134079

Epoch: 6| Step: 13
Training loss: 0.3715995252132416
Validation loss: 1.7491743974788214

Epoch: 229| Step: 0
Training loss: 0.4667710065841675
Validation loss: 1.7296783449829265

Epoch: 6| Step: 1
Training loss: 0.4385662078857422
Validation loss: 1.7243400722421625

Epoch: 6| Step: 2
Training loss: 0.36144012212753296
Validation loss: 1.704034862979766

Epoch: 6| Step: 3
Training loss: 0.45021089911460876
Validation loss: 1.7057813841809508

Epoch: 6| Step: 4
Training loss: 0.3982895016670227
Validation loss: 1.6986241814910725

Epoch: 6| Step: 5
Training loss: 0.37231677770614624
Validation loss: 1.6784295933220976

Epoch: 6| Step: 6
Training loss: 0.34155896306037903
Validation loss: 1.7102598951708885

Epoch: 6| Step: 7
Training loss: 0.41239628195762634
Validation loss: 1.7193547621850045

Epoch: 6| Step: 8
Training loss: 0.3095664978027344
Validation loss: 1.7111092203406877

Epoch: 6| Step: 9
Training loss: 0.3420533537864685
Validation loss: 1.745558468244409

Epoch: 6| Step: 10
Training loss: 0.37688785791397095
Validation loss: 1.7865765517757786

Epoch: 6| Step: 11
Training loss: 0.4067944884300232
Validation loss: 1.7520179299898044

Epoch: 6| Step: 12
Training loss: 0.4381304085254669
Validation loss: 1.7910146508165585

Epoch: 6| Step: 13
Training loss: 0.9258711934089661
Validation loss: 1.752143067698325

Epoch: 230| Step: 0
Training loss: 0.3542434275150299
Validation loss: 1.677934572260867

Epoch: 6| Step: 1
Training loss: 0.4007357060909271
Validation loss: 1.7110818880860523

Epoch: 6| Step: 2
Training loss: 0.3788412809371948
Validation loss: 1.7131170598409509

Epoch: 6| Step: 3
Training loss: 0.7184123992919922
Validation loss: 1.7119665004873788

Epoch: 6| Step: 4
Training loss: 0.27527809143066406
Validation loss: 1.700611024774531

Epoch: 6| Step: 5
Training loss: 0.2559485137462616
Validation loss: 1.6943420953648065

Epoch: 6| Step: 6
Training loss: 0.2436327338218689
Validation loss: 1.7345767315997873

Epoch: 6| Step: 7
Training loss: 0.37091830372810364
Validation loss: 1.7255513744969522

Epoch: 6| Step: 8
Training loss: 0.26984453201293945
Validation loss: 1.7775920501319311

Epoch: 6| Step: 9
Training loss: 0.2807433009147644
Validation loss: 1.7376819387558968

Epoch: 6| Step: 10
Training loss: 0.6898747086524963
Validation loss: 1.722248839434757

Epoch: 6| Step: 11
Training loss: 0.48696357011795044
Validation loss: 1.732983886554677

Epoch: 6| Step: 12
Training loss: 0.6753716468811035
Validation loss: 1.7159460545868002

Epoch: 6| Step: 13
Training loss: 0.19453290104866028
Validation loss: 1.7374559192247288

Epoch: 231| Step: 0
Training loss: 0.37592843174934387
Validation loss: 1.7663473236945368

Epoch: 6| Step: 1
Training loss: 0.34815606474876404
Validation loss: 1.755165607698502

Epoch: 6| Step: 2
Training loss: 0.3828311562538147
Validation loss: 1.7742424318867345

Epoch: 6| Step: 3
Training loss: 0.22766494750976562
Validation loss: 1.804666930629361

Epoch: 6| Step: 4
Training loss: 0.49518269300460815
Validation loss: 1.7921553632264495

Epoch: 6| Step: 5
Training loss: 0.2948164939880371
Validation loss: 1.8252041032237392

Epoch: 6| Step: 6
Training loss: 0.47643300890922546
Validation loss: 1.7826112367773568

Epoch: 6| Step: 7
Training loss: 0.37581825256347656
Validation loss: 1.7610664342039375

Epoch: 6| Step: 8
Training loss: 0.4011009931564331
Validation loss: 1.724125837766996

Epoch: 6| Step: 9
Training loss: 0.21479542553424835
Validation loss: 1.736011520508797

Epoch: 6| Step: 10
Training loss: 0.45847946405410767
Validation loss: 1.6992281265156244

Epoch: 6| Step: 11
Training loss: 0.3859010338783264
Validation loss: 1.7339688334413754

Epoch: 6| Step: 12
Training loss: 0.4951005280017853
Validation loss: 1.7327945475937219

Epoch: 6| Step: 13
Training loss: 1.1679803133010864
Validation loss: 1.7377789456357238

Epoch: 232| Step: 0
Training loss: 0.1324623078107834
Validation loss: 1.7724474258320306

Epoch: 6| Step: 1
Training loss: 0.28780826926231384
Validation loss: 1.7790429169131863

Epoch: 6| Step: 2
Training loss: 0.3336203098297119
Validation loss: 1.789656017416267

Epoch: 6| Step: 3
Training loss: 0.3374593257904053
Validation loss: 1.8303725296451199

Epoch: 6| Step: 4
Training loss: 0.5403629541397095
Validation loss: 1.786017103861737

Epoch: 6| Step: 5
Training loss: 0.2301771342754364
Validation loss: 1.7534805574724752

Epoch: 6| Step: 6
Training loss: 0.590384840965271
Validation loss: 1.7587297244738507

Epoch: 6| Step: 7
Training loss: 0.3945440948009491
Validation loss: 1.7076085049618956

Epoch: 6| Step: 8
Training loss: 0.4035206735134125
Validation loss: 1.7438951871728385

Epoch: 6| Step: 9
Training loss: 0.49943453073501587
Validation loss: 1.7113750032199326

Epoch: 6| Step: 10
Training loss: 0.3819856345653534
Validation loss: 1.7464266566820041

Epoch: 6| Step: 11
Training loss: 0.7024811506271362
Validation loss: 1.7813068846220612

Epoch: 6| Step: 12
Training loss: 0.24795302748680115
Validation loss: 1.7955216669267224

Epoch: 6| Step: 13
Training loss: 0.5719642043113708
Validation loss: 1.8243586094148698

Epoch: 233| Step: 0
Training loss: 0.2889239192008972
Validation loss: 1.8383631629328574

Epoch: 6| Step: 1
Training loss: 0.3739975690841675
Validation loss: 1.7777447367227206

Epoch: 6| Step: 2
Training loss: 0.2177022397518158
Validation loss: 1.7826851106459094

Epoch: 6| Step: 3
Training loss: 0.3099175989627838
Validation loss: 1.7474047419845418

Epoch: 6| Step: 4
Training loss: 0.7792848944664001
Validation loss: 1.7590958661930536

Epoch: 6| Step: 5
Training loss: 0.2449982613325119
Validation loss: 1.7199281915541618

Epoch: 6| Step: 6
Training loss: 0.29709216952323914
Validation loss: 1.7681630247382707

Epoch: 6| Step: 7
Training loss: 0.43861180543899536
Validation loss: 1.7996413656460342

Epoch: 6| Step: 8
Training loss: 0.49961552023887634
Validation loss: 1.7830128131374237

Epoch: 6| Step: 9
Training loss: 0.4315955936908722
Validation loss: 1.7660554121899348

Epoch: 6| Step: 10
Training loss: 0.5085222721099854
Validation loss: 1.7963235749993274

Epoch: 6| Step: 11
Training loss: 0.45565956830978394
Validation loss: 1.754276479444196

Epoch: 6| Step: 12
Training loss: 0.38415956497192383
Validation loss: 1.7293623211563274

Epoch: 6| Step: 13
Training loss: 0.42621496319770813
Validation loss: 1.6800568116608487

Epoch: 234| Step: 0
Training loss: 0.44864773750305176
Validation loss: 1.6932241519292195

Epoch: 6| Step: 1
Training loss: 0.44103407859802246
Validation loss: 1.6720215723078737

Epoch: 6| Step: 2
Training loss: 0.49206942319869995
Validation loss: 1.6988926164565548

Epoch: 6| Step: 3
Training loss: 0.37755268812179565
Validation loss: 1.6591760984031103

Epoch: 6| Step: 4
Training loss: 0.7593771815299988
Validation loss: 1.6775952218681254

Epoch: 6| Step: 5
Training loss: 0.4121900200843811
Validation loss: 1.6463939656493485

Epoch: 6| Step: 6
Training loss: 0.20914074778556824
Validation loss: 1.7174897732273224

Epoch: 6| Step: 7
Training loss: 0.30884018540382385
Validation loss: 1.7214376721330868

Epoch: 6| Step: 8
Training loss: 0.37567004561424255
Validation loss: 1.7492278955316032

Epoch: 6| Step: 9
Training loss: 0.4186590909957886
Validation loss: 1.7836853611853816

Epoch: 6| Step: 10
Training loss: 0.28249961137771606
Validation loss: 1.8104064554296515

Epoch: 6| Step: 11
Training loss: 0.4282863736152649
Validation loss: 1.8059057228026851

Epoch: 6| Step: 12
Training loss: 0.19256705045700073
Validation loss: 1.7728191421877952

Epoch: 6| Step: 13
Training loss: 0.3407541811466217
Validation loss: 1.7055596446478238

Epoch: 235| Step: 0
Training loss: 0.3406255841255188
Validation loss: 1.6923870437888688

Epoch: 6| Step: 1
Training loss: 0.3391454815864563
Validation loss: 1.662492831548055

Epoch: 6| Step: 2
Training loss: 0.38612163066864014
Validation loss: 1.6707192697832662

Epoch: 6| Step: 3
Training loss: 0.4264829754829407
Validation loss: 1.6832440476263724

Epoch: 6| Step: 4
Training loss: 0.2754775285720825
Validation loss: 1.668795854814591

Epoch: 6| Step: 5
Training loss: 0.3901835083961487
Validation loss: 1.706308203358804

Epoch: 6| Step: 6
Training loss: 0.24933597445487976
Validation loss: 1.7054079117313508

Epoch: 6| Step: 7
Training loss: 0.26765960454940796
Validation loss: 1.717566741410122

Epoch: 6| Step: 8
Training loss: 0.40194663405418396
Validation loss: 1.7292876987047092

Epoch: 6| Step: 9
Training loss: 0.3492559790611267
Validation loss: 1.7194724518765685

Epoch: 6| Step: 10
Training loss: 0.7775368690490723
Validation loss: 1.767314713488343

Epoch: 6| Step: 11
Training loss: 0.25256943702697754
Validation loss: 1.7538484386218491

Epoch: 6| Step: 12
Training loss: 0.4055793285369873
Validation loss: 1.7797606311818606

Epoch: 6| Step: 13
Training loss: 0.32973384857177734
Validation loss: 1.791787103940082

Epoch: 236| Step: 0
Training loss: 0.5189628601074219
Validation loss: 1.7878046317767071

Epoch: 6| Step: 1
Training loss: 0.19231289625167847
Validation loss: 1.7993009910788587

Epoch: 6| Step: 2
Training loss: 0.15245984494686127
Validation loss: 1.7419322145882474

Epoch: 6| Step: 3
Training loss: 0.3275620937347412
Validation loss: 1.706433940959233

Epoch: 6| Step: 4
Training loss: 0.2133556604385376
Validation loss: 1.685656911583357

Epoch: 6| Step: 5
Training loss: 0.789155125617981
Validation loss: 1.6899854560052194

Epoch: 6| Step: 6
Training loss: 0.33322250843048096
Validation loss: 1.703376732846742

Epoch: 6| Step: 7
Training loss: 0.39583614468574524
Validation loss: 1.7224993808295137

Epoch: 6| Step: 8
Training loss: 0.40910208225250244
Validation loss: 1.7118462349778862

Epoch: 6| Step: 9
Training loss: 0.5077675580978394
Validation loss: 1.6910389213151829

Epoch: 6| Step: 10
Training loss: 0.3439003825187683
Validation loss: 1.7311218118154874

Epoch: 6| Step: 11
Training loss: 0.2120862454175949
Validation loss: 1.7122051215940906

Epoch: 6| Step: 12
Training loss: 0.4845896065235138
Validation loss: 1.7034437964039464

Epoch: 6| Step: 13
Training loss: 0.27015283703804016
Validation loss: 1.7145924414357832

Epoch: 237| Step: 0
Training loss: 0.4246169328689575
Validation loss: 1.7224241610496276

Epoch: 6| Step: 1
Training loss: 0.23445039987564087
Validation loss: 1.7436840136845906

Epoch: 6| Step: 2
Training loss: 0.33930647373199463
Validation loss: 1.7545419867320726

Epoch: 6| Step: 3
Training loss: 0.3164564371109009
Validation loss: 1.725758444878363

Epoch: 6| Step: 4
Training loss: 0.5000446438789368
Validation loss: 1.7372044324874878

Epoch: 6| Step: 5
Training loss: 0.7357133030891418
Validation loss: 1.7115614298851258

Epoch: 6| Step: 6
Training loss: 0.42220252752304077
Validation loss: 1.7200779017581735

Epoch: 6| Step: 7
Training loss: 0.20942898094654083
Validation loss: 1.7287689883221862

Epoch: 6| Step: 8
Training loss: 0.31965968012809753
Validation loss: 1.7723588661480976

Epoch: 6| Step: 9
Training loss: 0.42897236347198486
Validation loss: 1.7616558677406722

Epoch: 6| Step: 10
Training loss: 0.3422195017337799
Validation loss: 1.7512804090335805

Epoch: 6| Step: 11
Training loss: 0.19846639037132263
Validation loss: 1.7486826860776512

Epoch: 6| Step: 12
Training loss: 0.3099074363708496
Validation loss: 1.7500260414615754

Epoch: 6| Step: 13
Training loss: 0.4377533197402954
Validation loss: 1.7508920315773255

Epoch: 238| Step: 0
Training loss: 0.20214545726776123
Validation loss: 1.7273496940571775

Epoch: 6| Step: 1
Training loss: 0.3874308168888092
Validation loss: 1.7676803834976689

Epoch: 6| Step: 2
Training loss: 0.25250327587127686
Validation loss: 1.7843088885789276

Epoch: 6| Step: 3
Training loss: 0.6762521266937256
Validation loss: 1.8083844370739435

Epoch: 6| Step: 4
Training loss: 0.36156368255615234
Validation loss: 1.8246032217497468

Epoch: 6| Step: 5
Training loss: 0.3815804719924927
Validation loss: 1.8142684916014313

Epoch: 6| Step: 6
Training loss: 0.34627246856689453
Validation loss: 1.8115300593837615

Epoch: 6| Step: 7
Training loss: 0.3465242087841034
Validation loss: 1.759131117533612

Epoch: 6| Step: 8
Training loss: 0.8511857986450195
Validation loss: 1.6991522735165012

Epoch: 6| Step: 9
Training loss: 0.2010592222213745
Validation loss: 1.662807365899445

Epoch: 6| Step: 10
Training loss: 0.2860625982284546
Validation loss: 1.6320333121925272

Epoch: 6| Step: 11
Training loss: 0.4070686995983124
Validation loss: 1.6568015660009077

Epoch: 6| Step: 12
Training loss: 0.3760223686695099
Validation loss: 1.6402257911620601

Epoch: 6| Step: 13
Training loss: 0.20136143267154694
Validation loss: 1.6743858706566594

Epoch: 239| Step: 0
Training loss: 0.5579907298088074
Validation loss: 1.7223988861166022

Epoch: 6| Step: 1
Training loss: 0.23079964518547058
Validation loss: 1.7531024191969184

Epoch: 6| Step: 2
Training loss: 0.3089818060398102
Validation loss: 1.7820699522572179

Epoch: 6| Step: 3
Training loss: 0.6824747920036316
Validation loss: 1.7754594100418912

Epoch: 6| Step: 4
Training loss: 0.3781520128250122
Validation loss: 1.7599295967368669

Epoch: 6| Step: 5
Training loss: 0.46255844831466675
Validation loss: 1.7545676949203655

Epoch: 6| Step: 6
Training loss: 0.26001378893852234
Validation loss: 1.6816598664047897

Epoch: 6| Step: 7
Training loss: 0.36204859614372253
Validation loss: 1.6578296980550211

Epoch: 6| Step: 8
Training loss: 0.4545438885688782
Validation loss: 1.6690499859471475

Epoch: 6| Step: 9
Training loss: 0.320086270570755
Validation loss: 1.6747653939390694

Epoch: 6| Step: 10
Training loss: 0.41221392154693604
Validation loss: 1.6980458805637975

Epoch: 6| Step: 11
Training loss: 0.5385002493858337
Validation loss: 1.6815180778503418

Epoch: 6| Step: 12
Training loss: 0.3466234803199768
Validation loss: 1.6829394255914996

Epoch: 6| Step: 13
Training loss: 0.3873004913330078
Validation loss: 1.6989742530289518

Epoch: 240| Step: 0
Training loss: 0.3386024236679077
Validation loss: 1.7253978111410653

Epoch: 6| Step: 1
Training loss: 0.30780667066574097
Validation loss: 1.7841014580060077

Epoch: 6| Step: 2
Training loss: 0.4221039414405823
Validation loss: 1.8017786497710853

Epoch: 6| Step: 3
Training loss: 0.31594911217689514
Validation loss: 1.8325067886742212

Epoch: 6| Step: 4
Training loss: 0.47596117854118347
Validation loss: 1.7951011298805155

Epoch: 6| Step: 5
Training loss: 0.46625328063964844
Validation loss: 1.802231082352259

Epoch: 6| Step: 6
Training loss: 0.3694876432418823
Validation loss: 1.7994853065859886

Epoch: 6| Step: 7
Training loss: 0.419715940952301
Validation loss: 1.769875886619732

Epoch: 6| Step: 8
Training loss: 0.1943317949771881
Validation loss: 1.7328912519639539

Epoch: 6| Step: 9
Training loss: 0.33908846974372864
Validation loss: 1.723190817781674

Epoch: 6| Step: 10
Training loss: 0.4063764214515686
Validation loss: 1.7024383057830155

Epoch: 6| Step: 11
Training loss: 0.1723504662513733
Validation loss: 1.7238169562432073

Epoch: 6| Step: 12
Training loss: 0.42005282640457153
Validation loss: 1.7304262384291618

Epoch: 6| Step: 13
Training loss: 1.0380849838256836
Validation loss: 1.7048449413750761

Epoch: 241| Step: 0
Training loss: 0.24864070117473602
Validation loss: 1.7183012616249822

Epoch: 6| Step: 1
Training loss: 0.28581681847572327
Validation loss: 1.6917294718885934

Epoch: 6| Step: 2
Training loss: 0.38291651010513306
Validation loss: 1.7071031332015991

Epoch: 6| Step: 3
Training loss: 0.2383638471364975
Validation loss: 1.7065573046284337

Epoch: 6| Step: 4
Training loss: 0.44662120938301086
Validation loss: 1.741707742855113

Epoch: 6| Step: 5
Training loss: 0.3118745982646942
Validation loss: 1.7359682327957564

Epoch: 6| Step: 6
Training loss: 0.2933744788169861
Validation loss: 1.727666977913149

Epoch: 6| Step: 7
Training loss: 0.46683022379875183
Validation loss: 1.7584506773179578

Epoch: 6| Step: 8
Training loss: 0.2595178484916687
Validation loss: 1.7426327287509877

Epoch: 6| Step: 9
Training loss: 0.3379996120929718
Validation loss: 1.777095389622514

Epoch: 6| Step: 10
Training loss: 0.37944740056991577
Validation loss: 1.7320827155984857

Epoch: 6| Step: 11
Training loss: 0.27290070056915283
Validation loss: 1.7141266304959533

Epoch: 6| Step: 12
Training loss: 0.6876148581504822
Validation loss: 1.6860528633158693

Epoch: 6| Step: 13
Training loss: 0.14358915388584137
Validation loss: 1.6921482945001254

Epoch: 242| Step: 0
Training loss: 0.3750087320804596
Validation loss: 1.690393094093569

Epoch: 6| Step: 1
Training loss: 0.13810157775878906
Validation loss: 1.7115656111830024

Epoch: 6| Step: 2
Training loss: 0.34208551049232483
Validation loss: 1.7330685866776334

Epoch: 6| Step: 3
Training loss: 0.1727500855922699
Validation loss: 1.731570266908215

Epoch: 6| Step: 4
Training loss: 0.45871809124946594
Validation loss: 1.7109889740584998

Epoch: 6| Step: 5
Training loss: 0.3666880428791046
Validation loss: 1.7503378442538682

Epoch: 6| Step: 6
Training loss: 0.42071881890296936
Validation loss: 1.7134980783667615

Epoch: 6| Step: 7
Training loss: 0.3673010468482971
Validation loss: 1.7389795831454697

Epoch: 6| Step: 8
Training loss: 0.2851639986038208
Validation loss: 1.7136773345290974

Epoch: 6| Step: 9
Training loss: 0.22813665866851807
Validation loss: 1.73918181080972

Epoch: 6| Step: 10
Training loss: 0.531556248664856
Validation loss: 1.7107681689723846

Epoch: 6| Step: 11
Training loss: 0.4002107083797455
Validation loss: 1.7053302295746342

Epoch: 6| Step: 12
Training loss: 0.588723361492157
Validation loss: 1.7585520513596073

Epoch: 6| Step: 13
Training loss: 0.86866295337677
Validation loss: 1.7392503125693208

Epoch: 243| Step: 0
Training loss: 0.29754307866096497
Validation loss: 1.7646000795466925

Epoch: 6| Step: 1
Training loss: 0.32238829135894775
Validation loss: 1.7353046350581671

Epoch: 6| Step: 2
Training loss: 0.46375858783721924
Validation loss: 1.7633041540781658

Epoch: 6| Step: 3
Training loss: 0.36564016342163086
Validation loss: 1.8156808986458728

Epoch: 6| Step: 4
Training loss: 0.7100661993026733
Validation loss: 1.836946996309424

Epoch: 6| Step: 5
Training loss: 0.3254223167896271
Validation loss: 1.7937421234705115

Epoch: 6| Step: 6
Training loss: 0.29444026947021484
Validation loss: 1.7814610658153411

Epoch: 6| Step: 7
Training loss: 0.3842150866985321
Validation loss: 1.7220780118819206

Epoch: 6| Step: 8
Training loss: 0.38809293508529663
Validation loss: 1.7408877982888171

Epoch: 6| Step: 9
Training loss: 0.33644235134124756
Validation loss: 1.7326812257048905

Epoch: 6| Step: 10
Training loss: 0.5506157875061035
Validation loss: 1.724059271556075

Epoch: 6| Step: 11
Training loss: 0.37297946214675903
Validation loss: 1.7023458576971484

Epoch: 6| Step: 12
Training loss: 0.3883357346057892
Validation loss: 1.7037800435096986

Epoch: 6| Step: 13
Training loss: 0.39489564299583435
Validation loss: 1.6729414398952196

Epoch: 244| Step: 0
Training loss: 0.4814111888408661
Validation loss: 1.651767196193818

Epoch: 6| Step: 1
Training loss: 0.3705386519432068
Validation loss: 1.7074391816252021

Epoch: 6| Step: 2
Training loss: 0.25102606415748596
Validation loss: 1.7433976716892694

Epoch: 6| Step: 3
Training loss: 0.37790393829345703
Validation loss: 1.745007607244676

Epoch: 6| Step: 4
Training loss: 0.27561062574386597
Validation loss: 1.7744331295772264

Epoch: 6| Step: 5
Training loss: 0.1896769106388092
Validation loss: 1.8074290547319638

Epoch: 6| Step: 6
Training loss: 0.3206571042537689
Validation loss: 1.715084304091751

Epoch: 6| Step: 7
Training loss: 0.45948582887649536
Validation loss: 1.6999709272897372

Epoch: 6| Step: 8
Training loss: 0.6221727132797241
Validation loss: 1.7061374187469482

Epoch: 6| Step: 9
Training loss: 0.3762754797935486
Validation loss: 1.7039053119638914

Epoch: 6| Step: 10
Training loss: 0.46059179306030273
Validation loss: 1.7426930037877892

Epoch: 6| Step: 11
Training loss: 0.2631872296333313
Validation loss: 1.7219967778011034

Epoch: 6| Step: 12
Training loss: 0.3417632281780243
Validation loss: 1.71145426201564

Epoch: 6| Step: 13
Training loss: 0.5123679637908936
Validation loss: 1.6847001955073366

Epoch: 245| Step: 0
Training loss: 0.3302069902420044
Validation loss: 1.6884425667024427

Epoch: 6| Step: 1
Training loss: 0.22821617126464844
Validation loss: 1.6901902152645973

Epoch: 6| Step: 2
Training loss: 0.8693388104438782
Validation loss: 1.7108318382693875

Epoch: 6| Step: 3
Training loss: 0.3427201807498932
Validation loss: 1.7129373524778633

Epoch: 6| Step: 4
Training loss: 0.3617996871471405
Validation loss: 1.7046802120824014

Epoch: 6| Step: 5
Training loss: 0.3623490333557129
Validation loss: 1.7000007373030468

Epoch: 6| Step: 6
Training loss: 0.4079228937625885
Validation loss: 1.6664067891336256

Epoch: 6| Step: 7
Training loss: 0.27387523651123047
Validation loss: 1.6894568307425386

Epoch: 6| Step: 8
Training loss: 0.2767113745212555
Validation loss: 1.6714980563809794

Epoch: 6| Step: 9
Training loss: 0.2275211662054062
Validation loss: 1.6629754035703597

Epoch: 6| Step: 10
Training loss: 0.22863271832466125
Validation loss: 1.7202717757994128

Epoch: 6| Step: 11
Training loss: 0.34715625643730164
Validation loss: 1.7261270656380603

Epoch: 6| Step: 12
Training loss: 0.3616666793823242
Validation loss: 1.7202641041048112

Epoch: 6| Step: 13
Training loss: 0.437714546918869
Validation loss: 1.7097980476194812

Epoch: 246| Step: 0
Training loss: 0.24788066744804382
Validation loss: 1.7003478760360389

Epoch: 6| Step: 1
Training loss: 0.2445213794708252
Validation loss: 1.6591843892169256

Epoch: 6| Step: 2
Training loss: 0.22481101751327515
Validation loss: 1.7073833711685673

Epoch: 6| Step: 3
Training loss: 0.35877352952957153
Validation loss: 1.7272169846360401

Epoch: 6| Step: 4
Training loss: 0.3507153391838074
Validation loss: 1.7175855790415118

Epoch: 6| Step: 5
Training loss: 0.19077914953231812
Validation loss: 1.6988828002765615

Epoch: 6| Step: 6
Training loss: 0.7098357081413269
Validation loss: 1.699768489406955

Epoch: 6| Step: 7
Training loss: 0.2806187868118286
Validation loss: 1.6838628489484069

Epoch: 6| Step: 8
Training loss: 0.25358864665031433
Validation loss: 1.684692039284655

Epoch: 6| Step: 9
Training loss: 0.22527945041656494
Validation loss: 1.701873739560445

Epoch: 6| Step: 10
Training loss: 0.2027043104171753
Validation loss: 1.6967036365180888

Epoch: 6| Step: 11
Training loss: 0.3869144916534424
Validation loss: 1.7174142727287867

Epoch: 6| Step: 12
Training loss: 0.5262446403503418
Validation loss: 1.7472384706620248

Epoch: 6| Step: 13
Training loss: 0.4377174377441406
Validation loss: 1.7870313095790085

Epoch: 247| Step: 0
Training loss: 0.2999802529811859
Validation loss: 1.8121765441791986

Epoch: 6| Step: 1
Training loss: 0.4049212336540222
Validation loss: 1.7862655155120357

Epoch: 6| Step: 2
Training loss: 0.4819897413253784
Validation loss: 1.7859029128987303

Epoch: 6| Step: 3
Training loss: 0.2208622843027115
Validation loss: 1.7418047151257914

Epoch: 6| Step: 4
Training loss: 0.3045656383037567
Validation loss: 1.749016696406949

Epoch: 6| Step: 5
Training loss: 0.27910229563713074
Validation loss: 1.764762250326013

Epoch: 6| Step: 6
Training loss: 0.2859523296356201
Validation loss: 1.733069190415003

Epoch: 6| Step: 7
Training loss: 0.32923033833503723
Validation loss: 1.7686883211135864

Epoch: 6| Step: 8
Training loss: 0.1901874840259552
Validation loss: 1.7114396428549161

Epoch: 6| Step: 9
Training loss: 0.6855361461639404
Validation loss: 1.7213360507001159

Epoch: 6| Step: 10
Training loss: 0.30418074131011963
Validation loss: 1.7112542826642272

Epoch: 6| Step: 11
Training loss: 0.24054963886737823
Validation loss: 1.723961580184198

Epoch: 6| Step: 12
Training loss: 0.22604745626449585
Validation loss: 1.699051482703096

Epoch: 6| Step: 13
Training loss: 0.47997379302978516
Validation loss: 1.7270232733859812

Epoch: 248| Step: 0
Training loss: 0.2967361807823181
Validation loss: 1.721794161745297

Epoch: 6| Step: 1
Training loss: 0.35916000604629517
Validation loss: 1.7151688401417067

Epoch: 6| Step: 2
Training loss: 0.3534606397151947
Validation loss: 1.723142118864162

Epoch: 6| Step: 3
Training loss: 0.1557784229516983
Validation loss: 1.6965701054501277

Epoch: 6| Step: 4
Training loss: 0.22877469658851624
Validation loss: 1.7129330942707677

Epoch: 6| Step: 5
Training loss: 0.30562007427215576
Validation loss: 1.7151798279054704

Epoch: 6| Step: 6
Training loss: 0.32840511202812195
Validation loss: 1.718654691532094

Epoch: 6| Step: 7
Training loss: 0.34738844633102417
Validation loss: 1.7302768217620028

Epoch: 6| Step: 8
Training loss: 0.25849372148513794
Validation loss: 1.7467756835363244

Epoch: 6| Step: 9
Training loss: 0.24405860900878906
Validation loss: 1.7472977433153378

Epoch: 6| Step: 10
Training loss: 0.4272997975349426
Validation loss: 1.7726069047886839

Epoch: 6| Step: 11
Training loss: 0.39519211649894714
Validation loss: 1.7024580637613933

Epoch: 6| Step: 12
Training loss: 0.6363728046417236
Validation loss: 1.6986194964378112

Epoch: 6| Step: 13
Training loss: 0.23567992448806763
Validation loss: 1.740915939372073

Epoch: 249| Step: 0
Training loss: 0.176661878824234
Validation loss: 1.742018944473677

Epoch: 6| Step: 1
Training loss: 0.23588049411773682
Validation loss: 1.7341312939120876

Epoch: 6| Step: 2
Training loss: 0.2893778383731842
Validation loss: 1.7716503656038673

Epoch: 6| Step: 3
Training loss: 0.375377893447876
Validation loss: 1.7237466342987553

Epoch: 6| Step: 4
Training loss: 0.2432064265012741
Validation loss: 1.7329963932755172

Epoch: 6| Step: 5
Training loss: 0.2510031461715698
Validation loss: 1.737941441997405

Epoch: 6| Step: 6
Training loss: 0.3651110529899597
Validation loss: 1.7173217804201188

Epoch: 6| Step: 7
Training loss: 0.19551901519298553
Validation loss: 1.7372327901983773

Epoch: 6| Step: 8
Training loss: 0.43628424406051636
Validation loss: 1.7387973480327155

Epoch: 6| Step: 9
Training loss: 0.3733174204826355
Validation loss: 1.757906085701399

Epoch: 6| Step: 10
Training loss: 0.26165980100631714
Validation loss: 1.7812724164737168

Epoch: 6| Step: 11
Training loss: 0.23719239234924316
Validation loss: 1.7361807541180683

Epoch: 6| Step: 12
Training loss: 0.7390587329864502
Validation loss: 1.7771086795355684

Epoch: 6| Step: 13
Training loss: 0.28862571716308594
Validation loss: 1.8016562782308108

Epoch: 250| Step: 0
Training loss: 0.36634695529937744
Validation loss: 1.7969343316170476

Epoch: 6| Step: 1
Training loss: 0.2726708650588989
Validation loss: 1.8127115080433507

Epoch: 6| Step: 2
Training loss: 0.29395946860313416
Validation loss: 1.7996555066877795

Epoch: 6| Step: 3
Training loss: 0.5515745878219604
Validation loss: 1.7679490991818008

Epoch: 6| Step: 4
Training loss: 0.28483283519744873
Validation loss: 1.7471610000056605

Epoch: 6| Step: 5
Training loss: 0.49214857816696167
Validation loss: 1.7329414672749017

Epoch: 6| Step: 6
Training loss: 0.2706594467163086
Validation loss: 1.7184833352283766

Epoch: 6| Step: 7
Training loss: 0.3447291851043701
Validation loss: 1.7347101844767088

Epoch: 6| Step: 8
Training loss: 0.3690931797027588
Validation loss: 1.720858125276463

Epoch: 6| Step: 9
Training loss: 0.23693843185901642
Validation loss: 1.7555920000999206

Epoch: 6| Step: 10
Training loss: 0.5630743503570557
Validation loss: 1.7538264413033762

Epoch: 6| Step: 11
Training loss: 0.26098713278770447
Validation loss: 1.753033984091974

Epoch: 6| Step: 12
Training loss: 0.4259914755821228
Validation loss: 1.739344350753292

Epoch: 6| Step: 13
Training loss: 0.1687970757484436
Validation loss: 1.7336833643656906

Epoch: 251| Step: 0
Training loss: 0.19641824066638947
Validation loss: 1.7101833563978954

Epoch: 6| Step: 1
Training loss: 0.242378830909729
Validation loss: 1.7437938080039075

Epoch: 6| Step: 2
Training loss: 0.27382516860961914
Validation loss: 1.733820306357517

Epoch: 6| Step: 3
Training loss: 0.6787570714950562
Validation loss: 1.7511828791710637

Epoch: 6| Step: 4
Training loss: 0.3931443393230438
Validation loss: 1.729775385190082

Epoch: 6| Step: 5
Training loss: 0.28682613372802734
Validation loss: 1.7237433105386712

Epoch: 6| Step: 6
Training loss: 0.3020026385784149
Validation loss: 1.7619322307648198

Epoch: 6| Step: 7
Training loss: 0.2834179997444153
Validation loss: 1.727237352119979

Epoch: 6| Step: 8
Training loss: 0.39847612380981445
Validation loss: 1.7164802474360312

Epoch: 6| Step: 9
Training loss: 0.3165907859802246
Validation loss: 1.6908075899206183

Epoch: 6| Step: 10
Training loss: 0.23567068576812744
Validation loss: 1.722262208179761

Epoch: 6| Step: 11
Training loss: 0.21041220426559448
Validation loss: 1.723947778824837

Epoch: 6| Step: 12
Training loss: 0.5919402241706848
Validation loss: 1.7159558855077273

Epoch: 6| Step: 13
Training loss: 0.3961177468299866
Validation loss: 1.7064827757496988

Epoch: 252| Step: 0
Training loss: 0.35302603244781494
Validation loss: 1.6974419701483943

Epoch: 6| Step: 1
Training loss: 0.337430864572525
Validation loss: 1.6750505931915776

Epoch: 6| Step: 2
Training loss: 0.13638801872730255
Validation loss: 1.742927279523624

Epoch: 6| Step: 3
Training loss: 0.2647745609283447
Validation loss: 1.7751287183453959

Epoch: 6| Step: 4
Training loss: 0.2531321048736572
Validation loss: 1.785789466673328

Epoch: 6| Step: 5
Training loss: 0.8148409128189087
Validation loss: 1.79034391526253

Epoch: 6| Step: 6
Training loss: 0.4740715026855469
Validation loss: 1.7426166611333047

Epoch: 6| Step: 7
Training loss: 0.2332371473312378
Validation loss: 1.653645110386674

Epoch: 6| Step: 8
Training loss: 0.33266380429267883
Validation loss: 1.6348322899110856

Epoch: 6| Step: 9
Training loss: 0.4004499614238739
Validation loss: 1.597407946022608

Epoch: 6| Step: 10
Training loss: 0.3308492600917816
Validation loss: 1.626408951256865

Epoch: 6| Step: 11
Training loss: 0.6606974601745605
Validation loss: 1.6351830420955535

Epoch: 6| Step: 12
Training loss: 0.5471864342689514
Validation loss: 1.6633154897279636

Epoch: 6| Step: 13
Training loss: 0.2387096881866455
Validation loss: 1.6632112520997242

Epoch: 253| Step: 0
Training loss: 0.4060693681240082
Validation loss: 1.6675968323984454

Epoch: 6| Step: 1
Training loss: 0.2814035415649414
Validation loss: 1.6334339085445608

Epoch: 6| Step: 2
Training loss: 0.28242549300193787
Validation loss: 1.6724555466764717

Epoch: 6| Step: 3
Training loss: 0.3390280604362488
Validation loss: 1.6815211862646124

Epoch: 6| Step: 4
Training loss: 0.21712109446525574
Validation loss: 1.7092409633821057

Epoch: 6| Step: 5
Training loss: 0.36603283882141113
Validation loss: 1.7417480766132314

Epoch: 6| Step: 6
Training loss: 0.4930950999259949
Validation loss: 1.7370299421330935

Epoch: 6| Step: 7
Training loss: 0.7172291278839111
Validation loss: 1.7396754064867574

Epoch: 6| Step: 8
Training loss: 0.44754475355148315
Validation loss: 1.7449969348087107

Epoch: 6| Step: 9
Training loss: 0.33911818265914917
Validation loss: 1.7395678745803012

Epoch: 6| Step: 10
Training loss: 0.24205313622951508
Validation loss: 1.6944421516951693

Epoch: 6| Step: 11
Training loss: 0.23124785721302032
Validation loss: 1.6906780453138455

Epoch: 6| Step: 12
Training loss: 0.43326863646507263
Validation loss: 1.698064547713085

Epoch: 6| Step: 13
Training loss: 0.2463764101266861
Validation loss: 1.7096719280365975

Epoch: 254| Step: 0
Training loss: 0.47514253854751587
Validation loss: 1.7185159229463147

Epoch: 6| Step: 1
Training loss: 0.3108839988708496
Validation loss: 1.7454097950330345

Epoch: 6| Step: 2
Training loss: 0.6838715076446533
Validation loss: 1.739666884945285

Epoch: 6| Step: 3
Training loss: 0.2732335329055786
Validation loss: 1.721626268920078

Epoch: 6| Step: 4
Training loss: 0.2205551564693451
Validation loss: 1.7651593691559249

Epoch: 6| Step: 5
Training loss: 0.2715318202972412
Validation loss: 1.7435721812709686

Epoch: 6| Step: 6
Training loss: 0.3326783776283264
Validation loss: 1.7069067852471465

Epoch: 6| Step: 7
Training loss: 0.3899148106575012
Validation loss: 1.700778054934676

Epoch: 6| Step: 8
Training loss: 0.42809438705444336
Validation loss: 1.6889079052914855

Epoch: 6| Step: 9
Training loss: 0.2796652317047119
Validation loss: 1.7203693941075315

Epoch: 6| Step: 10
Training loss: 0.42840224504470825
Validation loss: 1.6777341827269523

Epoch: 6| Step: 11
Training loss: 0.28111112117767334
Validation loss: 1.6453730393481512

Epoch: 6| Step: 12
Training loss: 0.44805872440338135
Validation loss: 1.679804596849667

Epoch: 6| Step: 13
Training loss: 0.3691474199295044
Validation loss: 1.6897626717885335

Epoch: 255| Step: 0
Training loss: 0.2649337947368622
Validation loss: 1.6766649881998699

Epoch: 6| Step: 1
Training loss: 0.36393100023269653
Validation loss: 1.6783868164144538

Epoch: 6| Step: 2
Training loss: 0.7483206391334534
Validation loss: 1.672667718702747

Epoch: 6| Step: 3
Training loss: 0.27967917919158936
Validation loss: 1.7158053716023762

Epoch: 6| Step: 4
Training loss: 0.18046459555625916
Validation loss: 1.7604703826289023

Epoch: 6| Step: 5
Training loss: 0.1954651176929474
Validation loss: 1.763740752332954

Epoch: 6| Step: 6
Training loss: 0.26836109161376953
Validation loss: 1.8073060531770029

Epoch: 6| Step: 7
Training loss: 0.3330969214439392
Validation loss: 1.8120694762916976

Epoch: 6| Step: 8
Training loss: 0.39450332522392273
Validation loss: 1.816145299583353

Epoch: 6| Step: 9
Training loss: 0.37501442432403564
Validation loss: 1.7814633513009677

Epoch: 6| Step: 10
Training loss: 0.43129950761795044
Validation loss: 1.6993712379086403

Epoch: 6| Step: 11
Training loss: 0.29624617099761963
Validation loss: 1.7328708274390108

Epoch: 6| Step: 12
Training loss: 0.40523725748062134
Validation loss: 1.7078627847856092

Epoch: 6| Step: 13
Training loss: 0.263588547706604
Validation loss: 1.6978473342874998

Epoch: 256| Step: 0
Training loss: 0.2657267451286316
Validation loss: 1.6807672246809928

Epoch: 6| Step: 1
Training loss: 0.1980968564748764
Validation loss: 1.689821361213602

Epoch: 6| Step: 2
Training loss: 0.32943546772003174
Validation loss: 1.670532944381878

Epoch: 6| Step: 3
Training loss: 0.2535240650177002
Validation loss: 1.6731656264233332

Epoch: 6| Step: 4
Training loss: 0.27572739124298096
Validation loss: 1.6653176956279303

Epoch: 6| Step: 5
Training loss: 0.3323650658130646
Validation loss: 1.662658255587342

Epoch: 6| Step: 6
Training loss: 0.7083200216293335
Validation loss: 1.7056332326704455

Epoch: 6| Step: 7
Training loss: 0.1797257512807846
Validation loss: 1.7222239637887606

Epoch: 6| Step: 8
Training loss: 0.2287674993276596
Validation loss: 1.7266902974856797

Epoch: 6| Step: 9
Training loss: 0.2674933969974518
Validation loss: 1.7296507268823602

Epoch: 6| Step: 10
Training loss: 0.2781527638435364
Validation loss: 1.7300768795833792

Epoch: 6| Step: 11
Training loss: 0.299776554107666
Validation loss: 1.6972107682176816

Epoch: 6| Step: 12
Training loss: 0.3095989227294922
Validation loss: 1.7181485295295715

Epoch: 6| Step: 13
Training loss: 0.35651323199272156
Validation loss: 1.7011636341771772

Epoch: 257| Step: 0
Training loss: 0.3192887306213379
Validation loss: 1.6671533892231603

Epoch: 6| Step: 1
Training loss: 0.34728187322616577
Validation loss: 1.6773647377567906

Epoch: 6| Step: 2
Training loss: 0.28513675928115845
Validation loss: 1.6837689197191628

Epoch: 6| Step: 3
Training loss: 0.3233133554458618
Validation loss: 1.6777718285078644

Epoch: 6| Step: 4
Training loss: 0.26774874329566956
Validation loss: 1.66094764970964

Epoch: 6| Step: 5
Training loss: 0.4024057388305664
Validation loss: 1.686890370102339

Epoch: 6| Step: 6
Training loss: 0.24264681339263916
Validation loss: 1.6839108159465175

Epoch: 6| Step: 7
Training loss: 0.25942111015319824
Validation loss: 1.7017236191739318

Epoch: 6| Step: 8
Training loss: 0.20641963183879852
Validation loss: 1.6797854092813307

Epoch: 6| Step: 9
Training loss: 0.3075060248374939
Validation loss: 1.7013250268915647

Epoch: 6| Step: 10
Training loss: 0.1543157398700714
Validation loss: 1.690181964828122

Epoch: 6| Step: 11
Training loss: 0.25232994556427
Validation loss: 1.7105340573095507

Epoch: 6| Step: 12
Training loss: 0.24132421612739563
Validation loss: 1.7328289016600578

Epoch: 6| Step: 13
Training loss: 0.8708919286727905
Validation loss: 1.7799419036475561

Epoch: 258| Step: 0
Training loss: 0.34873658418655396
Validation loss: 1.7116548245952976

Epoch: 6| Step: 1
Training loss: 0.2361300140619278
Validation loss: 1.7223574064111198

Epoch: 6| Step: 2
Training loss: 0.22548474371433258
Validation loss: 1.6892669034260575

Epoch: 6| Step: 3
Training loss: 0.5548122525215149
Validation loss: 1.6867380142211914

Epoch: 6| Step: 4
Training loss: 0.3093132972717285
Validation loss: 1.6355465099375734

Epoch: 6| Step: 5
Training loss: 0.20588736236095428
Validation loss: 1.6545846513522569

Epoch: 6| Step: 6
Training loss: 0.292292058467865
Validation loss: 1.644110316871315

Epoch: 6| Step: 7
Training loss: 0.35650521516799927
Validation loss: 1.6510713356797413

Epoch: 6| Step: 8
Training loss: 0.19503454864025116
Validation loss: 1.6597810727293774

Epoch: 6| Step: 9
Training loss: 0.3078312277793884
Validation loss: 1.6422658927979008

Epoch: 6| Step: 10
Training loss: 0.25741997361183167
Validation loss: 1.6429572848863498

Epoch: 6| Step: 11
Training loss: 0.34581682085990906
Validation loss: 1.6764465916541316

Epoch: 6| Step: 12
Training loss: 0.34604185819625854
Validation loss: 1.6850160116790442

Epoch: 6| Step: 13
Training loss: 0.21172600984573364
Validation loss: 1.6992750962575276

Epoch: 259| Step: 0
Training loss: 0.38222846388816833
Validation loss: 1.6910347925719393

Epoch: 6| Step: 1
Training loss: 0.2617303133010864
Validation loss: 1.7453434800588956

Epoch: 6| Step: 2
Training loss: 0.17246581614017487
Validation loss: 1.733465648466541

Epoch: 6| Step: 3
Training loss: 0.09063740074634552
Validation loss: 1.7124744166610062

Epoch: 6| Step: 4
Training loss: 0.39832228422164917
Validation loss: 1.7136580251878308

Epoch: 6| Step: 5
Training loss: 0.12500685453414917
Validation loss: 1.6961449423143942

Epoch: 6| Step: 6
Training loss: 0.27972596883773804
Validation loss: 1.6967727663696452

Epoch: 6| Step: 7
Training loss: 0.4134054183959961
Validation loss: 1.7107504362701087

Epoch: 6| Step: 8
Training loss: 0.32279878854751587
Validation loss: 1.7282060782114665

Epoch: 6| Step: 9
Training loss: 0.522758960723877
Validation loss: 1.717759330426493

Epoch: 6| Step: 10
Training loss: 0.2394978106021881
Validation loss: 1.6995840303359493

Epoch: 6| Step: 11
Training loss: 0.33033573627471924
Validation loss: 1.748256028339427

Epoch: 6| Step: 12
Training loss: 0.22612446546554565
Validation loss: 1.6855792980040274

Epoch: 6| Step: 13
Training loss: 0.387859046459198
Validation loss: 1.7221548044553368

Epoch: 260| Step: 0
Training loss: 0.1603820025920868
Validation loss: 1.7051034460785568

Epoch: 6| Step: 1
Training loss: 0.21121948957443237
Validation loss: 1.713442128191712

Epoch: 6| Step: 2
Training loss: 0.40423133969306946
Validation loss: 1.7132146486672022

Epoch: 6| Step: 3
Training loss: 0.319897323846817
Validation loss: 1.7116143754733506

Epoch: 6| Step: 4
Training loss: 0.23920294642448425
Validation loss: 1.7140289275876937

Epoch: 6| Step: 5
Training loss: 0.3755687177181244
Validation loss: 1.7413987369947537

Epoch: 6| Step: 6
Training loss: 0.35286641120910645
Validation loss: 1.7141626458014212

Epoch: 6| Step: 7
Training loss: 0.27522969245910645
Validation loss: 1.7137846010987476

Epoch: 6| Step: 8
Training loss: 0.22439011931419373
Validation loss: 1.7206843130050167

Epoch: 6| Step: 9
Training loss: 0.39117127656936646
Validation loss: 1.7487201652219218

Epoch: 6| Step: 10
Training loss: 0.4786859154701233
Validation loss: 1.7145745908060381

Epoch: 6| Step: 11
Training loss: 0.22117771208286285
Validation loss: 1.688286692224523

Epoch: 6| Step: 12
Training loss: 0.18920564651489258
Validation loss: 1.71550081622216

Epoch: 6| Step: 13
Training loss: 0.22272419929504395
Validation loss: 1.7015116368570635

Epoch: 261| Step: 0
Training loss: 0.33060935139656067
Validation loss: 1.739803864750811

Epoch: 6| Step: 1
Training loss: 0.1645812690258026
Validation loss: 1.7452459412236367

Epoch: 6| Step: 2
Training loss: 0.36960333585739136
Validation loss: 1.7191234788587015

Epoch: 6| Step: 3
Training loss: 0.29791033267974854
Validation loss: 1.7754082410566268

Epoch: 6| Step: 4
Training loss: 0.4366914927959442
Validation loss: 1.758185173875542

Epoch: 6| Step: 5
Training loss: 0.14246705174446106
Validation loss: 1.738994368942835

Epoch: 6| Step: 6
Training loss: 0.1811031997203827
Validation loss: 1.748761889755085

Epoch: 6| Step: 7
Training loss: 0.33647966384887695
Validation loss: 1.6675905066151773

Epoch: 6| Step: 8
Training loss: 0.2971343398094177
Validation loss: 1.713835185573947

Epoch: 6| Step: 9
Training loss: 0.32999947667121887
Validation loss: 1.6999167960177186

Epoch: 6| Step: 10
Training loss: 0.37131091952323914
Validation loss: 1.7206753018081828

Epoch: 6| Step: 11
Training loss: 0.27057668566703796
Validation loss: 1.7705193847738288

Epoch: 6| Step: 12
Training loss: 0.28675851225852966
Validation loss: 1.744074075452743

Epoch: 6| Step: 13
Training loss: 0.3239988088607788
Validation loss: 1.750120080927367

Epoch: 262| Step: 0
Training loss: 0.31017884612083435
Validation loss: 1.680604532200803

Epoch: 6| Step: 1
Training loss: 0.17735306918621063
Validation loss: 1.67048349559948

Epoch: 6| Step: 2
Training loss: 0.20214277505874634
Validation loss: 1.650558566534391

Epoch: 6| Step: 3
Training loss: 0.3214331865310669
Validation loss: 1.6466750111631168

Epoch: 6| Step: 4
Training loss: 0.2690756022930145
Validation loss: 1.6309886158153575

Epoch: 6| Step: 5
Training loss: 0.1144404411315918
Validation loss: 1.6366383003932174

Epoch: 6| Step: 6
Training loss: 0.5628708600997925
Validation loss: 1.6780490913698751

Epoch: 6| Step: 7
Training loss: 0.23530447483062744
Validation loss: 1.657688106259992

Epoch: 6| Step: 8
Training loss: 0.29572004079818726
Validation loss: 1.6850757368149296

Epoch: 6| Step: 9
Training loss: 0.49134665727615356
Validation loss: 1.7249404743153562

Epoch: 6| Step: 10
Training loss: 0.2418176233768463
Validation loss: 1.7461511960593603

Epoch: 6| Step: 11
Training loss: 0.6468613147735596
Validation loss: 1.7258934436305877

Epoch: 6| Step: 12
Training loss: 0.36598843336105347
Validation loss: 1.7287947952106435

Epoch: 6| Step: 13
Training loss: 0.28041213750839233
Validation loss: 1.7094526521621212

Epoch: 263| Step: 0
Training loss: 0.19181284308433533
Validation loss: 1.7068417456842238

Epoch: 6| Step: 1
Training loss: 0.2715795338153839
Validation loss: 1.7498385662673621

Epoch: 6| Step: 2
Training loss: 0.40824800729751587
Validation loss: 1.7532509616626206

Epoch: 6| Step: 3
Training loss: 0.18592491745948792
Validation loss: 1.728140281092736

Epoch: 6| Step: 4
Training loss: 0.16820688545703888
Validation loss: 1.6956932237071376

Epoch: 6| Step: 5
Training loss: 0.3808729946613312
Validation loss: 1.72289772764329

Epoch: 6| Step: 6
Training loss: 0.48864346742630005
Validation loss: 1.7167273221477386

Epoch: 6| Step: 7
Training loss: 0.2811747193336487
Validation loss: 1.6507913245949695

Epoch: 6| Step: 8
Training loss: 0.34162184596061707
Validation loss: 1.6634683429553945

Epoch: 6| Step: 9
Training loss: 0.49048787355422974
Validation loss: 1.680112716972187

Epoch: 6| Step: 10
Training loss: 0.3642420768737793
Validation loss: 1.6673753851203508

Epoch: 6| Step: 11
Training loss: 0.4380352795124054
Validation loss: 1.6411075720223047

Epoch: 6| Step: 12
Training loss: 0.17652317881584167
Validation loss: 1.6549711086416756

Epoch: 6| Step: 13
Training loss: 0.3227360248565674
Validation loss: 1.704015387001858

Epoch: 264| Step: 0
Training loss: 0.26210305094718933
Validation loss: 1.7056947382547523

Epoch: 6| Step: 1
Training loss: 0.19299304485321045
Validation loss: 1.7281328093621038

Epoch: 6| Step: 2
Training loss: 0.25114646553993225
Validation loss: 1.7410675787156629

Epoch: 6| Step: 3
Training loss: 0.6806669235229492
Validation loss: 1.7239638643880044

Epoch: 6| Step: 4
Training loss: 0.3566996157169342
Validation loss: 1.7189487077856576

Epoch: 6| Step: 5
Training loss: 0.2089800238609314
Validation loss: 1.7430819196085776

Epoch: 6| Step: 6
Training loss: 0.30260974168777466
Validation loss: 1.7289232823156542

Epoch: 6| Step: 7
Training loss: 0.20804047584533691
Validation loss: 1.7187986450810586

Epoch: 6| Step: 8
Training loss: 0.3679627776145935
Validation loss: 1.7406907196967834

Epoch: 6| Step: 9
Training loss: 0.25313800573349
Validation loss: 1.753307467506778

Epoch: 6| Step: 10
Training loss: 0.2731451690196991
Validation loss: 1.7097696693994666

Epoch: 6| Step: 11
Training loss: 0.19849976897239685
Validation loss: 1.6806895758516045

Epoch: 6| Step: 12
Training loss: 0.21103452146053314
Validation loss: 1.6737162015771354

Epoch: 6| Step: 13
Training loss: 0.2845885157585144
Validation loss: 1.649755657360118

Epoch: 265| Step: 0
Training loss: 0.21535345911979675
Validation loss: 1.6351683293619463

Epoch: 6| Step: 1
Training loss: 0.2296491414308548
Validation loss: 1.6444475907151417

Epoch: 6| Step: 2
Training loss: 0.29349029064178467
Validation loss: 1.6155879894892375

Epoch: 6| Step: 3
Training loss: 0.45950573682785034
Validation loss: 1.6246634491028324

Epoch: 6| Step: 4
Training loss: 0.3615173101425171
Validation loss: 1.6495682706115067

Epoch: 6| Step: 5
Training loss: 0.20240294933319092
Validation loss: 1.6381136178970337

Epoch: 6| Step: 6
Training loss: 0.3042536973953247
Validation loss: 1.6526918001072382

Epoch: 6| Step: 7
Training loss: 0.40199995040893555
Validation loss: 1.655024851522138

Epoch: 6| Step: 8
Training loss: 0.27194735407829285
Validation loss: 1.7003266542188582

Epoch: 6| Step: 9
Training loss: 0.31839272379875183
Validation loss: 1.6484650373458862

Epoch: 6| Step: 10
Training loss: 0.4517585337162018
Validation loss: 1.6377928538988995

Epoch: 6| Step: 11
Training loss: 0.31167787313461304
Validation loss: 1.6291064459790465

Epoch: 6| Step: 12
Training loss: 0.17215606570243835
Validation loss: 1.6254218630893256

Epoch: 6| Step: 13
Training loss: 0.23257777094841003
Validation loss: 1.6125969797052362

Epoch: 266| Step: 0
Training loss: 0.2857874035835266
Validation loss: 1.6126461035461837

Epoch: 6| Step: 1
Training loss: 0.21116405725479126
Validation loss: 1.6124340244518813

Epoch: 6| Step: 2
Training loss: 0.24339967966079712
Validation loss: 1.6592514822559972

Epoch: 6| Step: 3
Training loss: 0.3349408507347107
Validation loss: 1.656893527635964

Epoch: 6| Step: 4
Training loss: 0.36201155185699463
Validation loss: 1.6439260116187475

Epoch: 6| Step: 5
Training loss: 0.24725238978862762
Validation loss: 1.6626963000143729

Epoch: 6| Step: 6
Training loss: 0.3120453357696533
Validation loss: 1.7429312198392806

Epoch: 6| Step: 7
Training loss: 0.1461677849292755
Validation loss: 1.6943628634175947

Epoch: 6| Step: 8
Training loss: 0.2549424171447754
Validation loss: 1.695354724443087

Epoch: 6| Step: 9
Training loss: 0.3271734118461609
Validation loss: 1.722859755639107

Epoch: 6| Step: 10
Training loss: 0.3231574296951294
Validation loss: 1.6428740652658607

Epoch: 6| Step: 11
Training loss: 0.1458365023136139
Validation loss: 1.6386785853293635

Epoch: 6| Step: 12
Training loss: 0.12979435920715332
Validation loss: 1.6316581464582873

Epoch: 6| Step: 13
Training loss: 0.7454677820205688
Validation loss: 1.6409072952885781

Epoch: 267| Step: 0
Training loss: 0.19822415709495544
Validation loss: 1.6359430936075026

Epoch: 6| Step: 1
Training loss: 0.28697049617767334
Validation loss: 1.639293554008648

Epoch: 6| Step: 2
Training loss: 0.6223241090774536
Validation loss: 1.614721357181508

Epoch: 6| Step: 3
Training loss: 0.35246556997299194
Validation loss: 1.6727594637101697

Epoch: 6| Step: 4
Training loss: 0.21964269876480103
Validation loss: 1.684048802621903

Epoch: 6| Step: 5
Training loss: 0.2878180146217346
Validation loss: 1.6992291647900817

Epoch: 6| Step: 6
Training loss: 0.274919331073761
Validation loss: 1.7242005499460364

Epoch: 6| Step: 7
Training loss: 0.16949577629566193
Validation loss: 1.7070500196949128

Epoch: 6| Step: 8
Training loss: 0.24289432168006897
Validation loss: 1.6635818340445077

Epoch: 6| Step: 9
Training loss: 0.15976455807685852
Validation loss: 1.6690055901004421

Epoch: 6| Step: 10
Training loss: 0.24090249836444855
Validation loss: 1.688454484426847

Epoch: 6| Step: 11
Training loss: 0.17684400081634521
Validation loss: 1.6375392726672593

Epoch: 6| Step: 12
Training loss: 0.3369254767894745
Validation loss: 1.6650800346046366

Epoch: 6| Step: 13
Training loss: 0.429233580827713
Validation loss: 1.6363603363754928

Epoch: 268| Step: 0
Training loss: 0.1970658302307129
Validation loss: 1.6891565758694884

Epoch: 6| Step: 1
Training loss: 0.2500483989715576
Validation loss: 1.665400848593763

Epoch: 6| Step: 2
Training loss: 0.2956055998802185
Validation loss: 1.6904660809424616

Epoch: 6| Step: 3
Training loss: 0.33813074231147766
Validation loss: 1.695254393803176

Epoch: 6| Step: 4
Training loss: 0.47243261337280273
Validation loss: 1.6671848476573985

Epoch: 6| Step: 5
Training loss: 0.3141412138938904
Validation loss: 1.667437981533748

Epoch: 6| Step: 6
Training loss: 0.19563335180282593
Validation loss: 1.683496141946444

Epoch: 6| Step: 7
Training loss: 0.23063841462135315
Validation loss: 1.6870195109357116

Epoch: 6| Step: 8
Training loss: 0.18951472640037537
Validation loss: 1.6411645386808662

Epoch: 6| Step: 9
Training loss: 0.4192997217178345
Validation loss: 1.6396614748944518

Epoch: 6| Step: 10
Training loss: 0.10238885134458542
Validation loss: 1.6496969910078152

Epoch: 6| Step: 11
Training loss: 0.2894461154937744
Validation loss: 1.6040141967035109

Epoch: 6| Step: 12
Training loss: 0.16506770253181458
Validation loss: 1.6102498128849974

Epoch: 6| Step: 13
Training loss: 0.13990601897239685
Validation loss: 1.6028645448787238

Epoch: 269| Step: 0
Training loss: 0.19617760181427002
Validation loss: 1.621657076702323

Epoch: 6| Step: 1
Training loss: 0.20903705060482025
Validation loss: 1.6173945332086215

Epoch: 6| Step: 2
Training loss: 0.3057280480861664
Validation loss: 1.5975883186504405

Epoch: 6| Step: 3
Training loss: 0.19132865965366364
Validation loss: 1.641249249058385

Epoch: 6| Step: 4
Training loss: 0.20206759870052338
Validation loss: 1.6449701324585946

Epoch: 6| Step: 5
Training loss: 0.3659087121486664
Validation loss: 1.669549031924176

Epoch: 6| Step: 6
Training loss: 0.22006991505622864
Validation loss: 1.6595593370417112

Epoch: 6| Step: 7
Training loss: 0.15703490376472473
Validation loss: 1.6568474128682127

Epoch: 6| Step: 8
Training loss: 0.3826149106025696
Validation loss: 1.6638012291282736

Epoch: 6| Step: 9
Training loss: 0.33061087131500244
Validation loss: 1.677440804819907

Epoch: 6| Step: 10
Training loss: 0.2758655548095703
Validation loss: 1.6388640865202873

Epoch: 6| Step: 11
Training loss: 0.1894712746143341
Validation loss: 1.6212874394591137

Epoch: 6| Step: 12
Training loss: 0.22830766439437866
Validation loss: 1.6033765500591648

Epoch: 6| Step: 13
Training loss: 0.1794310212135315
Validation loss: 1.6363208499006046

Epoch: 270| Step: 0
Training loss: 0.16834628582000732
Validation loss: 1.6741496811630905

Epoch: 6| Step: 1
Training loss: 0.2010900378227234
Validation loss: 1.6708769452187322

Epoch: 6| Step: 2
Training loss: 0.2245476245880127
Validation loss: 1.6688588883287163

Epoch: 6| Step: 3
Training loss: 0.33174458146095276
Validation loss: 1.6683977316784602

Epoch: 6| Step: 4
Training loss: 0.5544900894165039
Validation loss: 1.6567269371401878

Epoch: 6| Step: 5
Training loss: 0.24943168461322784
Validation loss: 1.679314256996237

Epoch: 6| Step: 6
Training loss: 0.3576078712940216
Validation loss: 1.660505251217914

Epoch: 6| Step: 7
Training loss: 0.171940416097641
Validation loss: 1.632217421326586

Epoch: 6| Step: 8
Training loss: 0.2667781710624695
Validation loss: 1.6722004528968566

Epoch: 6| Step: 9
Training loss: 0.27119264006614685
Validation loss: 1.678524737717003

Epoch: 6| Step: 10
Training loss: 0.26461270451545715
Validation loss: 1.7012037295167164

Epoch: 6| Step: 11
Training loss: 0.3602268695831299
Validation loss: 1.6871502245626142

Epoch: 6| Step: 12
Training loss: 0.25134217739105225
Validation loss: 1.7043766462674705

Epoch: 6| Step: 13
Training loss: 0.15470510721206665
Validation loss: 1.6883357904290641

Epoch: 271| Step: 0
Training loss: 0.21900877356529236
Validation loss: 1.7138622512099564

Epoch: 6| Step: 1
Training loss: 0.28306037187576294
Validation loss: 1.683139306242748

Epoch: 6| Step: 2
Training loss: 0.24798299372196198
Validation loss: 1.6935163377433695

Epoch: 6| Step: 3
Training loss: 0.15814407169818878
Validation loss: 1.7103591939454437

Epoch: 6| Step: 4
Training loss: 0.28455883264541626
Validation loss: 1.6983964802116476

Epoch: 6| Step: 5
Training loss: 0.14870527386665344
Validation loss: 1.7021714333565003

Epoch: 6| Step: 6
Training loss: 0.2809680104255676
Validation loss: 1.7136664518745996

Epoch: 6| Step: 7
Training loss: 0.29628118872642517
Validation loss: 1.7500693080245808

Epoch: 6| Step: 8
Training loss: 0.3134182095527649
Validation loss: 1.7274479353299705

Epoch: 6| Step: 9
Training loss: 0.2759360074996948
Validation loss: 1.7416222864581692

Epoch: 6| Step: 10
Training loss: 0.21632187068462372
Validation loss: 1.7322921265837967

Epoch: 6| Step: 11
Training loss: 0.5018332004547119
Validation loss: 1.6879410564258535

Epoch: 6| Step: 12
Training loss: 0.2302086353302002
Validation loss: 1.6834597010766306

Epoch: 6| Step: 13
Training loss: 0.2488643079996109
Validation loss: 1.6410837455462384

Epoch: 272| Step: 0
Training loss: 0.3015086054801941
Validation loss: 1.6892856333845405

Epoch: 6| Step: 1
Training loss: 0.22117435932159424
Validation loss: 1.6642626024061633

Epoch: 6| Step: 2
Training loss: 0.21959424018859863
Validation loss: 1.6848070724036104

Epoch: 6| Step: 3
Training loss: 0.24341529607772827
Validation loss: 1.657306481433171

Epoch: 6| Step: 4
Training loss: 0.47488105297088623
Validation loss: 1.6618940804594307

Epoch: 6| Step: 5
Training loss: 0.42967596650123596
Validation loss: 1.6599641358980568

Epoch: 6| Step: 6
Training loss: 0.30175265669822693
Validation loss: 1.6602912308067403

Epoch: 6| Step: 7
Training loss: 0.27923649549484253
Validation loss: 1.6937550088410736

Epoch: 6| Step: 8
Training loss: 0.27769702672958374
Validation loss: 1.714621074738041

Epoch: 6| Step: 9
Training loss: 0.24487629532814026
Validation loss: 1.71434538338774

Epoch: 6| Step: 10
Training loss: 0.26469695568084717
Validation loss: 1.733217154779742

Epoch: 6| Step: 11
Training loss: 0.373832643032074
Validation loss: 1.750156347469617

Epoch: 6| Step: 12
Training loss: 0.29139775037765503
Validation loss: 1.7353499115154307

Epoch: 6| Step: 13
Training loss: 0.4025122821331024
Validation loss: 1.7144197802389822

Epoch: 273| Step: 0
Training loss: 0.34804201126098633
Validation loss: 1.7138366058308592

Epoch: 6| Step: 1
Training loss: 0.24931921064853668
Validation loss: 1.7043085431539884

Epoch: 6| Step: 2
Training loss: 0.295473575592041
Validation loss: 1.6830888755859867

Epoch: 6| Step: 3
Training loss: 0.2900259494781494
Validation loss: 1.680135937147243

Epoch: 6| Step: 4
Training loss: 0.2553190290927887
Validation loss: 1.673675125645053

Epoch: 6| Step: 5
Training loss: 0.35478365421295166
Validation loss: 1.7042944687668995

Epoch: 6| Step: 6
Training loss: 0.3410462737083435
Validation loss: 1.6625592426587177

Epoch: 6| Step: 7
Training loss: 0.3560296893119812
Validation loss: 1.695641581730176

Epoch: 6| Step: 8
Training loss: 0.24483048915863037
Validation loss: 1.6935516172839749

Epoch: 6| Step: 9
Training loss: 0.20264968276023865
Validation loss: 1.7002490797350485

Epoch: 6| Step: 10
Training loss: 0.24652504920959473
Validation loss: 1.7066005417095718

Epoch: 6| Step: 11
Training loss: 0.19963881373405457
Validation loss: 1.7096348872748754

Epoch: 6| Step: 12
Training loss: 0.6142774224281311
Validation loss: 1.7394727647945445

Epoch: 6| Step: 13
Training loss: 0.3107278347015381
Validation loss: 1.7234336035225981

Epoch: 274| Step: 0
Training loss: 0.16311387717723846
Validation loss: 1.7183530593431124

Epoch: 6| Step: 1
Training loss: 0.16219262778759003
Validation loss: 1.7071742883292578

Epoch: 6| Step: 2
Training loss: 0.26365721225738525
Validation loss: 1.7331172125313872

Epoch: 6| Step: 3
Training loss: 0.3368169665336609
Validation loss: 1.7141192536200247

Epoch: 6| Step: 4
Training loss: 0.32914426922798157
Validation loss: 1.7136121975478305

Epoch: 6| Step: 5
Training loss: 0.22394272685050964
Validation loss: 1.7022517573448919

Epoch: 6| Step: 6
Training loss: 0.24839258193969727
Validation loss: 1.7134458467524538

Epoch: 6| Step: 7
Training loss: 0.3490118384361267
Validation loss: 1.6954240516949726

Epoch: 6| Step: 8
Training loss: 0.20507735013961792
Validation loss: 1.7202706285702285

Epoch: 6| Step: 9
Training loss: 0.2963806688785553
Validation loss: 1.7320665223624117

Epoch: 6| Step: 10
Training loss: 0.4586697816848755
Validation loss: 1.754469266501806

Epoch: 6| Step: 11
Training loss: 0.2240520417690277
Validation loss: 1.7207769501593806

Epoch: 6| Step: 12
Training loss: 0.19939467310905457
Validation loss: 1.6925727128982544

Epoch: 6| Step: 13
Training loss: 0.26448529958724976
Validation loss: 1.6420803723796722

Epoch: 275| Step: 0
Training loss: 0.5267617702484131
Validation loss: 1.6783756863686345

Epoch: 6| Step: 1
Training loss: 0.27326202392578125
Validation loss: 1.6704152540494037

Epoch: 6| Step: 2
Training loss: 0.19908611476421356
Validation loss: 1.6045818328857422

Epoch: 6| Step: 3
Training loss: 0.17680464684963226
Validation loss: 1.6349540282321233

Epoch: 6| Step: 4
Training loss: 0.24741283059120178
Validation loss: 1.6587270639275993

Epoch: 6| Step: 5
Training loss: 0.29086965322494507
Validation loss: 1.634440747640466

Epoch: 6| Step: 6
Training loss: 0.21531009674072266
Validation loss: 1.6537646760222733

Epoch: 6| Step: 7
Training loss: 0.2958946228027344
Validation loss: 1.6859665609175158

Epoch: 6| Step: 8
Training loss: 0.2543228268623352
Validation loss: 1.662978974721765

Epoch: 6| Step: 9
Training loss: 0.11451951414346695
Validation loss: 1.6352119381709764

Epoch: 6| Step: 10
Training loss: 0.24432416260242462
Validation loss: 1.6268975747528898

Epoch: 6| Step: 11
Training loss: 0.2540784478187561
Validation loss: 1.6445088078898769

Epoch: 6| Step: 12
Training loss: 0.18381406366825104
Validation loss: 1.6039784672439739

Epoch: 6| Step: 13
Training loss: 0.2624760866165161
Validation loss: 1.6119175290548673

Epoch: 276| Step: 0
Training loss: 0.22852598130702972
Validation loss: 1.6237707112425117

Epoch: 6| Step: 1
Training loss: 0.33079132437705994
Validation loss: 1.6253118348378006

Epoch: 6| Step: 2
Training loss: 0.5580763220787048
Validation loss: 1.6479354032906153

Epoch: 6| Step: 3
Training loss: 0.317289263010025
Validation loss: 1.7034237307886924

Epoch: 6| Step: 4
Training loss: 0.22164028882980347
Validation loss: 1.6804617207537416

Epoch: 6| Step: 5
Training loss: 0.3008200526237488
Validation loss: 1.6920545690803117

Epoch: 6| Step: 6
Training loss: 0.18431882560253143
Validation loss: 1.6457240440512215

Epoch: 6| Step: 7
Training loss: 0.22831755876541138
Validation loss: 1.6583088777398551

Epoch: 6| Step: 8
Training loss: 0.2273496687412262
Validation loss: 1.6494172901235602

Epoch: 6| Step: 9
Training loss: 0.22350451350212097
Validation loss: 1.6452036467931603

Epoch: 6| Step: 10
Training loss: 0.25654929876327515
Validation loss: 1.6501617675186486

Epoch: 6| Step: 11
Training loss: 0.1998976767063141
Validation loss: 1.6605878517191897

Epoch: 6| Step: 12
Training loss: 0.14833948016166687
Validation loss: 1.6639901989249772

Epoch: 6| Step: 13
Training loss: 0.18775242567062378
Validation loss: 1.6441149327062792

Epoch: 277| Step: 0
Training loss: 0.16732116043567657
Validation loss: 1.652623261174848

Epoch: 6| Step: 1
Training loss: 0.20378264784812927
Validation loss: 1.6763814085273332

Epoch: 6| Step: 2
Training loss: 0.21537421643733978
Validation loss: 1.6489916962961997

Epoch: 6| Step: 3
Training loss: 0.09414234757423401
Validation loss: 1.6928314098747828

Epoch: 6| Step: 4
Training loss: 0.2600354552268982
Validation loss: 1.6560797409344745

Epoch: 6| Step: 5
Training loss: 0.44007688760757446
Validation loss: 1.6778291694579586

Epoch: 6| Step: 6
Training loss: 0.2098964899778366
Validation loss: 1.6628324024138912

Epoch: 6| Step: 7
Training loss: 0.2184450477361679
Validation loss: 1.6539566491239814

Epoch: 6| Step: 8
Training loss: 0.13399125635623932
Validation loss: 1.6560455996503112

Epoch: 6| Step: 9
Training loss: 0.27754586935043335
Validation loss: 1.6615216885843584

Epoch: 6| Step: 10
Training loss: 0.3073422312736511
Validation loss: 1.680749274069263

Epoch: 6| Step: 11
Training loss: 0.21656394004821777
Validation loss: 1.6539591345735776

Epoch: 6| Step: 12
Training loss: 0.2008102536201477
Validation loss: 1.6095886704742268

Epoch: 6| Step: 13
Training loss: 0.28448617458343506
Validation loss: 1.6188200340476087

Epoch: 278| Step: 0
Training loss: 0.21440716087818146
Validation loss: 1.6217056153922953

Epoch: 6| Step: 1
Training loss: 0.20854640007019043
Validation loss: 1.630304148120265

Epoch: 6| Step: 2
Training loss: 0.39087405800819397
Validation loss: 1.5956870048276839

Epoch: 6| Step: 3
Training loss: 0.24807585775852203
Validation loss: 1.6316203301952732

Epoch: 6| Step: 4
Training loss: 0.2589966654777527
Validation loss: 1.5959470630973898

Epoch: 6| Step: 5
Training loss: 0.24781854450702667
Validation loss: 1.588691137170279

Epoch: 6| Step: 6
Training loss: 0.26344242691993713
Validation loss: 1.6328555358353483

Epoch: 6| Step: 7
Training loss: 0.23768222332000732
Validation loss: 1.609283899748197

Epoch: 6| Step: 8
Training loss: 0.2562636137008667
Validation loss: 1.659708091007766

Epoch: 6| Step: 9
Training loss: 0.18528789281845093
Validation loss: 1.6685398214606828

Epoch: 6| Step: 10
Training loss: 0.16724295914173126
Validation loss: 1.6502513321497108

Epoch: 6| Step: 11
Training loss: 0.1366245150566101
Validation loss: 1.6353343443203998

Epoch: 6| Step: 12
Training loss: 0.33150431513786316
Validation loss: 1.6848729297678957

Epoch: 6| Step: 13
Training loss: 0.2951204180717468
Validation loss: 1.6813537587401688

Epoch: 279| Step: 0
Training loss: 0.18466803431510925
Validation loss: 1.6768630140571184

Epoch: 6| Step: 1
Training loss: 0.20621003210544586
Validation loss: 1.7265267397767754

Epoch: 6| Step: 2
Training loss: 0.3651133179664612
Validation loss: 1.6720392973192277

Epoch: 6| Step: 3
Training loss: 0.3025371730327606
Validation loss: 1.7238144848936348

Epoch: 6| Step: 4
Training loss: 0.2566341459751129
Validation loss: 1.711800531674457

Epoch: 6| Step: 5
Training loss: 0.19305956363677979
Validation loss: 1.655432830574692

Epoch: 6| Step: 6
Training loss: 0.23357033729553223
Validation loss: 1.6866173616019629

Epoch: 6| Step: 7
Training loss: 0.30709853768348694
Validation loss: 1.6589462475110126

Epoch: 6| Step: 8
Training loss: 0.15579184889793396
Validation loss: 1.6362290536203692

Epoch: 6| Step: 9
Training loss: 0.19309228658676147
Validation loss: 1.6227843505080028

Epoch: 6| Step: 10
Training loss: 0.30391255021095276
Validation loss: 1.6528215715962071

Epoch: 6| Step: 11
Training loss: 0.18039272725582123
Validation loss: 1.657531710081203

Epoch: 6| Step: 12
Training loss: 0.333138644695282
Validation loss: 1.635145378369157

Epoch: 6| Step: 13
Training loss: 0.3030000925064087
Validation loss: 1.63105942356971

Epoch: 280| Step: 0
Training loss: 0.387217253446579
Validation loss: 1.6536442233670143

Epoch: 6| Step: 1
Training loss: 0.17946334183216095
Validation loss: 1.672962224611672

Epoch: 6| Step: 2
Training loss: 0.11372388899326324
Validation loss: 1.6536814846018308

Epoch: 6| Step: 3
Training loss: 0.12634561955928802
Validation loss: 1.6387737604879564

Epoch: 6| Step: 4
Training loss: 0.20887790620326996
Validation loss: 1.6842123116216352

Epoch: 6| Step: 5
Training loss: 0.24380815029144287
Validation loss: 1.6471143384133615

Epoch: 6| Step: 6
Training loss: 0.19910433888435364
Validation loss: 1.6965258993128294

Epoch: 6| Step: 7
Training loss: 0.21630805730819702
Validation loss: 1.6745719217484998

Epoch: 6| Step: 8
Training loss: 0.5016865730285645
Validation loss: 1.6866862132985105

Epoch: 6| Step: 9
Training loss: 0.22358423471450806
Validation loss: 1.681686402649008

Epoch: 6| Step: 10
Training loss: 0.15808577835559845
Validation loss: 1.6833859130900393

Epoch: 6| Step: 11
Training loss: 0.15055058896541595
Validation loss: 1.6706407941797727

Epoch: 6| Step: 12
Training loss: 0.24496635794639587
Validation loss: 1.6513338576080978

Epoch: 6| Step: 13
Training loss: 0.24707701802253723
Validation loss: 1.640394474229505

Epoch: 281| Step: 0
Training loss: 0.21374621987342834
Validation loss: 1.6570528425196165

Epoch: 6| Step: 1
Training loss: 0.1914728879928589
Validation loss: 1.6512379723210489

Epoch: 6| Step: 2
Training loss: 0.3593635559082031
Validation loss: 1.705670913060506

Epoch: 6| Step: 3
Training loss: 0.22625836730003357
Validation loss: 1.636741748420141

Epoch: 6| Step: 4
Training loss: 0.21179187297821045
Validation loss: 1.6661088171825613

Epoch: 6| Step: 5
Training loss: 0.4861292541027069
Validation loss: 1.714224680777519

Epoch: 6| Step: 6
Training loss: 0.25981926918029785
Validation loss: 1.683295621666857

Epoch: 6| Step: 7
Training loss: 0.14492711424827576
Validation loss: 1.706677738056388

Epoch: 6| Step: 8
Training loss: 0.27762845158576965
Validation loss: 1.7036498233836184

Epoch: 6| Step: 9
Training loss: 0.15721344947814941
Validation loss: 1.7161054444569412

Epoch: 6| Step: 10
Training loss: 0.18420958518981934
Validation loss: 1.6888570439430974

Epoch: 6| Step: 11
Training loss: 0.2547433078289032
Validation loss: 1.6961259290736208

Epoch: 6| Step: 12
Training loss: 0.3543357253074646
Validation loss: 1.6920853519952426

Epoch: 6| Step: 13
Training loss: 0.2107677161693573
Validation loss: 1.6682305528271584

Epoch: 282| Step: 0
Training loss: 0.13740335404872894
Validation loss: 1.6674992128085064

Epoch: 6| Step: 1
Training loss: 0.25332361459732056
Validation loss: 1.6784561808391283

Epoch: 6| Step: 2
Training loss: 0.409273236989975
Validation loss: 1.635683984525742

Epoch: 6| Step: 3
Training loss: 0.30454158782958984
Validation loss: 1.6313121793090657

Epoch: 6| Step: 4
Training loss: 0.25086939334869385
Validation loss: 1.6306393774606849

Epoch: 6| Step: 5
Training loss: 0.1617463231086731
Validation loss: 1.6527159137110556

Epoch: 6| Step: 6
Training loss: 0.20352189242839813
Validation loss: 1.6468542339981243

Epoch: 6| Step: 7
Training loss: 0.2946542203426361
Validation loss: 1.6735205727238809

Epoch: 6| Step: 8
Training loss: 0.22711403667926788
Validation loss: 1.6578215527278122

Epoch: 6| Step: 9
Training loss: 0.31269371509552
Validation loss: 1.7057280719921153

Epoch: 6| Step: 10
Training loss: 0.26249784231185913
Validation loss: 1.6789093902034145

Epoch: 6| Step: 11
Training loss: 0.1983264535665512
Validation loss: 1.654595705770677

Epoch: 6| Step: 12
Training loss: 0.16410402953624725
Validation loss: 1.6492902360936648

Epoch: 6| Step: 13
Training loss: 0.22902512550354004
Validation loss: 1.6918099439272316

Epoch: 283| Step: 0
Training loss: 0.22133761644363403
Validation loss: 1.639468103326777

Epoch: 6| Step: 1
Training loss: 0.2557365894317627
Validation loss: 1.6527662110585037

Epoch: 6| Step: 2
Training loss: 0.3131510615348816
Validation loss: 1.6160481373469036

Epoch: 6| Step: 3
Training loss: 0.19664010405540466
Validation loss: 1.6163503226413523

Epoch: 6| Step: 4
Training loss: 0.25797972083091736
Validation loss: 1.6018906331831408

Epoch: 6| Step: 5
Training loss: 0.23957733809947968
Validation loss: 1.5992160074172481

Epoch: 6| Step: 6
Training loss: 0.2242116928100586
Validation loss: 1.62259082640371

Epoch: 6| Step: 7
Training loss: 0.35331130027770996
Validation loss: 1.6481413020882556

Epoch: 6| Step: 8
Training loss: 0.23927530646324158
Validation loss: 1.656582087598821

Epoch: 6| Step: 9
Training loss: 0.2377261221408844
Validation loss: 1.6778687456602692

Epoch: 6| Step: 10
Training loss: 0.22101539373397827
Validation loss: 1.6910708463320168

Epoch: 6| Step: 11
Training loss: 0.3422134220600128
Validation loss: 1.6569164401741439

Epoch: 6| Step: 12
Training loss: 0.23137915134429932
Validation loss: 1.6431387867978824

Epoch: 6| Step: 13
Training loss: 0.212130606174469
Validation loss: 1.6633450395317488

Epoch: 284| Step: 0
Training loss: 0.1475042849779129
Validation loss: 1.6069442200404342

Epoch: 6| Step: 1
Training loss: 0.23724132776260376
Validation loss: 1.606031830592822

Epoch: 6| Step: 2
Training loss: 0.13468140363693237
Validation loss: 1.5971363398336595

Epoch: 6| Step: 3
Training loss: 0.24134239554405212
Validation loss: 1.6373079733182025

Epoch: 6| Step: 4
Training loss: 0.15472999215126038
Validation loss: 1.621432888892389

Epoch: 6| Step: 5
Training loss: 0.1893887221813202
Validation loss: 1.6149000711338495

Epoch: 6| Step: 6
Training loss: 0.2944747805595398
Validation loss: 1.6868080144287438

Epoch: 6| Step: 7
Training loss: 0.2498343586921692
Validation loss: 1.7150756620591687

Epoch: 6| Step: 8
Training loss: 0.21062111854553223
Validation loss: 1.7644270402128979

Epoch: 6| Step: 9
Training loss: 0.4110527038574219
Validation loss: 1.7271544830773466

Epoch: 6| Step: 10
Training loss: 0.23384058475494385
Validation loss: 1.717037832865151

Epoch: 6| Step: 11
Training loss: 0.15477488934993744
Validation loss: 1.6535200893238027

Epoch: 6| Step: 12
Training loss: 0.23153351247310638
Validation loss: 1.6575937476209415

Epoch: 6| Step: 13
Training loss: 0.2801550626754761
Validation loss: 1.6258447952167963

Epoch: 285| Step: 0
Training loss: 0.3265380561351776
Validation loss: 1.627584074133186

Epoch: 6| Step: 1
Training loss: 0.16263887286186218
Validation loss: 1.6181632934078094

Epoch: 6| Step: 2
Training loss: 0.1894926130771637
Validation loss: 1.6533976972744029

Epoch: 6| Step: 3
Training loss: 0.20774231851100922
Validation loss: 1.6668634055763163

Epoch: 6| Step: 4
Training loss: 0.22815516591072083
Validation loss: 1.6676738877450266

Epoch: 6| Step: 5
Training loss: 0.3872942328453064
Validation loss: 1.68162440869116

Epoch: 6| Step: 6
Training loss: 0.2640787661075592
Validation loss: 1.70251121956815

Epoch: 6| Step: 7
Training loss: 0.13199324905872345
Validation loss: 1.7235261701768445

Epoch: 6| Step: 8
Training loss: 0.17746056616306305
Validation loss: 1.682979235085108

Epoch: 6| Step: 9
Training loss: 0.17474663257598877
Validation loss: 1.6542640270725373

Epoch: 6| Step: 10
Training loss: 0.23904487490653992
Validation loss: 1.631246656499883

Epoch: 6| Step: 11
Training loss: 0.12110091745853424
Validation loss: 1.6139061656049503

Epoch: 6| Step: 12
Training loss: 0.19324743747711182
Validation loss: 1.6298465664668749

Epoch: 6| Step: 13
Training loss: 0.21258902549743652
Validation loss: 1.5821963446114653

Epoch: 286| Step: 0
Training loss: 0.16846969723701477
Validation loss: 1.6229692966707292

Epoch: 6| Step: 1
Training loss: 0.2627265453338623
Validation loss: 1.6166364967182119

Epoch: 6| Step: 2
Training loss: 0.2372887134552002
Validation loss: 1.6019121728917605

Epoch: 6| Step: 3
Training loss: 0.17759624123573303
Validation loss: 1.6132773455753122

Epoch: 6| Step: 4
Training loss: 0.3741203546524048
Validation loss: 1.6639315159090105

Epoch: 6| Step: 5
Training loss: 0.2674694359302521
Validation loss: 1.6916940942887337

Epoch: 6| Step: 6
Training loss: 0.23577341437339783
Validation loss: 1.7199222041714577

Epoch: 6| Step: 7
Training loss: 0.2952956259250641
Validation loss: 1.7158412600076327

Epoch: 6| Step: 8
Training loss: 0.20788703858852386
Validation loss: 1.7424105982626639

Epoch: 6| Step: 9
Training loss: 0.3033275008201599
Validation loss: 1.7272635377863401

Epoch: 6| Step: 10
Training loss: 0.3201349377632141
Validation loss: 1.7074671496627152

Epoch: 6| Step: 11
Training loss: 0.1923840194940567
Validation loss: 1.670609002472252

Epoch: 6| Step: 12
Training loss: 0.20452557504177094
Validation loss: 1.6332058406645251

Epoch: 6| Step: 13
Training loss: 0.10104499012231827
Validation loss: 1.5954359757002963

Epoch: 287| Step: 0
Training loss: 0.17917609214782715
Validation loss: 1.607300837834676

Epoch: 6| Step: 1
Training loss: 0.25269269943237305
Validation loss: 1.5900551939523349

Epoch: 6| Step: 2
Training loss: 0.1821589320898056
Validation loss: 1.5984618433060185

Epoch: 6| Step: 3
Training loss: 0.17792420089244843
Validation loss: 1.6011281936399397

Epoch: 6| Step: 4
Training loss: 0.25973498821258545
Validation loss: 1.588507204927424

Epoch: 6| Step: 5
Training loss: 0.2529742419719696
Validation loss: 1.5810781518618267

Epoch: 6| Step: 6
Training loss: 0.32154688239097595
Validation loss: 1.6649010514700284

Epoch: 6| Step: 7
Training loss: 0.2642219066619873
Validation loss: 1.6713971732765116

Epoch: 6| Step: 8
Training loss: 0.23926717042922974
Validation loss: 1.6594885728692497

Epoch: 6| Step: 9
Training loss: 0.21426057815551758
Validation loss: 1.7293246971663607

Epoch: 6| Step: 10
Training loss: 0.20043452084064484
Validation loss: 1.6863638047249085

Epoch: 6| Step: 11
Training loss: 0.19217118620872498
Validation loss: 1.6511663416380524

Epoch: 6| Step: 12
Training loss: 0.3805778920650482
Validation loss: 1.6342310674728886

Epoch: 6| Step: 13
Training loss: 0.28067442774772644
Validation loss: 1.5899261466918453

Epoch: 288| Step: 0
Training loss: 0.19690200686454773
Validation loss: 1.620406936573726

Epoch: 6| Step: 1
Training loss: 0.2619269788265228
Validation loss: 1.622346293541693

Epoch: 6| Step: 2
Training loss: 0.5654390454292297
Validation loss: 1.620982802042397

Epoch: 6| Step: 3
Training loss: 0.14561161398887634
Validation loss: 1.5712350363372474

Epoch: 6| Step: 4
Training loss: 0.21072296798229218
Validation loss: 1.6061251471119542

Epoch: 6| Step: 5
Training loss: 0.14877426624298096
Validation loss: 1.6268534660339355

Epoch: 6| Step: 6
Training loss: 0.24497856199741364
Validation loss: 1.6553147428779191

Epoch: 6| Step: 7
Training loss: 0.2780853509902954
Validation loss: 1.6405598361005065

Epoch: 6| Step: 8
Training loss: 0.24390381574630737
Validation loss: 1.6733172785851262

Epoch: 6| Step: 9
Training loss: 0.17328399419784546
Validation loss: 1.678646259410407

Epoch: 6| Step: 10
Training loss: 0.26402366161346436
Validation loss: 1.671837717615148

Epoch: 6| Step: 11
Training loss: 0.17886102199554443
Validation loss: 1.7143441464311333

Epoch: 6| Step: 12
Training loss: 0.21133440732955933
Validation loss: 1.712663124966365

Epoch: 6| Step: 13
Training loss: 0.17916332185268402
Validation loss: 1.645609971015684

Epoch: 289| Step: 0
Training loss: 0.16750146448612213
Validation loss: 1.6462843072029851

Epoch: 6| Step: 1
Training loss: 0.20455944538116455
Validation loss: 1.6361509112901584

Epoch: 6| Step: 2
Training loss: 0.18690744042396545
Validation loss: 1.6099228948675177

Epoch: 6| Step: 3
Training loss: 0.30525851249694824
Validation loss: 1.6075864838015648

Epoch: 6| Step: 4
Training loss: 0.25605228543281555
Validation loss: 1.5619296655859998

Epoch: 6| Step: 5
Training loss: 0.1412578672170639
Validation loss: 1.5928920456158218

Epoch: 6| Step: 6
Training loss: 0.41601264476776123
Validation loss: 1.5847925140011696

Epoch: 6| Step: 7
Training loss: 0.24660217761993408
Validation loss: 1.5574563395592473

Epoch: 6| Step: 8
Training loss: 0.2884030342102051
Validation loss: 1.5646808455067296

Epoch: 6| Step: 9
Training loss: 0.22109083831310272
Validation loss: 1.5619577605237243

Epoch: 6| Step: 10
Training loss: 0.22332139313220978
Validation loss: 1.5732491631661691

Epoch: 6| Step: 11
Training loss: 0.15005534887313843
Validation loss: 1.5984049202293478

Epoch: 6| Step: 12
Training loss: 0.20753908157348633
Validation loss: 1.6214678736143215

Epoch: 6| Step: 13
Training loss: 0.13044840097427368
Validation loss: 1.6517682306228145

Epoch: 290| Step: 0
Training loss: 0.30509769916534424
Validation loss: 1.644912632562781

Epoch: 6| Step: 1
Training loss: 0.2449750155210495
Validation loss: 1.6409240512437717

Epoch: 6| Step: 2
Training loss: 0.24860599637031555
Validation loss: 1.632793112467694

Epoch: 6| Step: 3
Training loss: 0.1769442856311798
Validation loss: 1.6299313832354803

Epoch: 6| Step: 4
Training loss: 0.14948484301567078
Validation loss: 1.6254053846482308

Epoch: 6| Step: 5
Training loss: 0.2080308049917221
Validation loss: 1.6131973638329455

Epoch: 6| Step: 6
Training loss: 0.11608244478702545
Validation loss: 1.6255671055086198

Epoch: 6| Step: 7
Training loss: 0.1309405267238617
Validation loss: 1.6294715199419247

Epoch: 6| Step: 8
Training loss: 0.20134514570236206
Validation loss: 1.6347398681025351

Epoch: 6| Step: 9
Training loss: 0.3911390006542206
Validation loss: 1.6064953445106425

Epoch: 6| Step: 10
Training loss: 0.22044427692890167
Validation loss: 1.6209484466942408

Epoch: 6| Step: 11
Training loss: 0.23427824676036835
Validation loss: 1.621846850200366

Epoch: 6| Step: 12
Training loss: 0.2045673280954361
Validation loss: 1.5784986429317023

Epoch: 6| Step: 13
Training loss: 0.3605872690677643
Validation loss: 1.5956363703614922

Epoch: 291| Step: 0
Training loss: 0.25762617588043213
Validation loss: 1.6137126825189079

Epoch: 6| Step: 1
Training loss: 0.3272525668144226
Validation loss: 1.5832078418424052

Epoch: 6| Step: 2
Training loss: 0.20355994999408722
Validation loss: 1.6133296169260496

Epoch: 6| Step: 3
Training loss: 0.35811465978622437
Validation loss: 1.640190916676675

Epoch: 6| Step: 4
Training loss: 0.17598813772201538
Validation loss: 1.6333491590715223

Epoch: 6| Step: 5
Training loss: 0.2034721076488495
Validation loss: 1.6367809170035905

Epoch: 6| Step: 6
Training loss: 0.13748574256896973
Validation loss: 1.603128690873423

Epoch: 6| Step: 7
Training loss: 0.2868354320526123
Validation loss: 1.5994419103027673

Epoch: 6| Step: 8
Training loss: 0.16869765520095825
Validation loss: 1.6114888139950332

Epoch: 6| Step: 9
Training loss: 0.29076308012008667
Validation loss: 1.6029652280192221

Epoch: 6| Step: 10
Training loss: 0.2058548629283905
Validation loss: 1.595044198856559

Epoch: 6| Step: 11
Training loss: 0.18839067220687866
Validation loss: 1.5638465996711486

Epoch: 6| Step: 12
Training loss: 0.2256980985403061
Validation loss: 1.5780887872942033

Epoch: 6| Step: 13
Training loss: 0.08081437647342682
Validation loss: 1.5782839277739167

Epoch: 292| Step: 0
Training loss: 0.1858433187007904
Validation loss: 1.5285925352445213

Epoch: 6| Step: 1
Training loss: 0.13621756434440613
Validation loss: 1.612549369053174

Epoch: 6| Step: 2
Training loss: 0.22241191565990448
Validation loss: 1.6287098956364456

Epoch: 6| Step: 3
Training loss: 0.21444013714790344
Validation loss: 1.679785979691372

Epoch: 6| Step: 4
Training loss: 0.24290499091148376
Validation loss: 1.691243783120186

Epoch: 6| Step: 5
Training loss: 0.275145947933197
Validation loss: 1.6786754374863

Epoch: 6| Step: 6
Training loss: 0.17914068698883057
Validation loss: 1.659324235813592

Epoch: 6| Step: 7
Training loss: 0.15832602977752686
Validation loss: 1.6595639528766755

Epoch: 6| Step: 8
Training loss: 0.3583483099937439
Validation loss: 1.6650822970174974

Epoch: 6| Step: 9
Training loss: 0.3031473457813263
Validation loss: 1.6837319174120504

Epoch: 6| Step: 10
Training loss: 0.1473258137702942
Validation loss: 1.6741401995382001

Epoch: 6| Step: 11
Training loss: 0.12896722555160522
Validation loss: 1.6352526910843388

Epoch: 6| Step: 12
Training loss: 0.16913241147994995
Validation loss: 1.6235538182720062

Epoch: 6| Step: 13
Training loss: 0.17947877943515778
Validation loss: 1.6470145487016248

Epoch: 293| Step: 0
Training loss: 0.32884490489959717
Validation loss: 1.635938125271951

Epoch: 6| Step: 1
Training loss: 0.1425180435180664
Validation loss: 1.6465106869256625

Epoch: 6| Step: 2
Training loss: 0.10290609300136566
Validation loss: 1.6213693259864725

Epoch: 6| Step: 3
Training loss: 0.20418938994407654
Validation loss: 1.6130707302401144

Epoch: 6| Step: 4
Training loss: 0.331476628780365
Validation loss: 1.619911632230205

Epoch: 6| Step: 5
Training loss: 0.12355749309062958
Validation loss: 1.6094953783096806

Epoch: 6| Step: 6
Training loss: 0.30072492361068726
Validation loss: 1.6346406077825895

Epoch: 6| Step: 7
Training loss: 0.34804296493530273
Validation loss: 1.6028509486106135

Epoch: 6| Step: 8
Training loss: 0.17519599199295044
Validation loss: 1.6072851227175804

Epoch: 6| Step: 9
Training loss: 0.35700348019599915
Validation loss: 1.633794153890302

Epoch: 6| Step: 10
Training loss: 0.18312819302082062
Validation loss: 1.6135257315892044

Epoch: 6| Step: 11
Training loss: 0.16066783666610718
Validation loss: 1.601936947914862

Epoch: 6| Step: 12
Training loss: 0.27448770403862
Validation loss: 1.6083955444315428

Epoch: 6| Step: 13
Training loss: 0.17086850106716156
Validation loss: 1.622025377647851

Epoch: 294| Step: 0
Training loss: 0.20889835059642792
Validation loss: 1.6438747862333893

Epoch: 6| Step: 1
Training loss: 0.18416328728199005
Validation loss: 1.5851434200040755

Epoch: 6| Step: 2
Training loss: 0.2510945498943329
Validation loss: 1.6072079020161782

Epoch: 6| Step: 3
Training loss: 0.22568565607070923
Validation loss: 1.5815404743276618

Epoch: 6| Step: 4
Training loss: 0.18203429877758026
Validation loss: 1.5942427522392684

Epoch: 6| Step: 5
Training loss: 0.3111591339111328
Validation loss: 1.5707096656163533

Epoch: 6| Step: 6
Training loss: 0.17420408129692078
Validation loss: 1.6109550127419092

Epoch: 6| Step: 7
Training loss: 0.26411449909210205
Validation loss: 1.6077447168288692

Epoch: 6| Step: 8
Training loss: 0.24857556819915771
Validation loss: 1.6269918821191276

Epoch: 6| Step: 9
Training loss: 0.23434603214263916
Validation loss: 1.6604349241461804

Epoch: 6| Step: 10
Training loss: 0.21465453505516052
Validation loss: 1.6369998865230109

Epoch: 6| Step: 11
Training loss: 0.25059497356414795
Validation loss: 1.6670972634387273

Epoch: 6| Step: 12
Training loss: 0.24319590628147125
Validation loss: 1.6595094601313274

Epoch: 6| Step: 13
Training loss: 0.2534622550010681
Validation loss: 1.6464243576090822

Epoch: 295| Step: 0
Training loss: 0.12322389334440231
Validation loss: 1.6303710194044216

Epoch: 6| Step: 1
Training loss: 0.37875446677207947
Validation loss: 1.6209720860245407

Epoch: 6| Step: 2
Training loss: 0.1312847137451172
Validation loss: 1.5848891504349247

Epoch: 6| Step: 3
Training loss: 0.11670298129320145
Validation loss: 1.5969330610767487

Epoch: 6| Step: 4
Training loss: 0.11529507488012314
Validation loss: 1.5550655575208767

Epoch: 6| Step: 5
Training loss: 0.17037630081176758
Validation loss: 1.5702533798833047

Epoch: 6| Step: 6
Training loss: 0.24335025250911713
Validation loss: 1.5715151602222073

Epoch: 6| Step: 7
Training loss: 0.268950879573822
Validation loss: 1.5636471292024017

Epoch: 6| Step: 8
Training loss: 0.3018021583557129
Validation loss: 1.588068353232517

Epoch: 6| Step: 9
Training loss: 0.21444430947303772
Validation loss: 1.5908435762569468

Epoch: 6| Step: 10
Training loss: 0.18630820512771606
Validation loss: 1.574647129222911

Epoch: 6| Step: 11
Training loss: 0.16598378121852875
Validation loss: 1.5988175984351867

Epoch: 6| Step: 12
Training loss: 0.195557102560997
Validation loss: 1.6093680768884637

Epoch: 6| Step: 13
Training loss: 0.1868768334388733
Validation loss: 1.5781628213902956

Epoch: 296| Step: 0
Training loss: 0.24392534792423248
Validation loss: 1.55385967352057

Epoch: 6| Step: 1
Training loss: 0.3131709098815918
Validation loss: 1.5554167493697135

Epoch: 6| Step: 2
Training loss: 0.3505137264728546
Validation loss: 1.5421772669720393

Epoch: 6| Step: 3
Training loss: 0.1824420988559723
Validation loss: 1.5343328137551584

Epoch: 6| Step: 4
Training loss: 0.1966991275548935
Validation loss: 1.4958853080708494

Epoch: 6| Step: 5
Training loss: 0.16769945621490479
Validation loss: 1.5298146663173553

Epoch: 6| Step: 6
Training loss: 0.15447860956192017
Validation loss: 1.546150625392955

Epoch: 6| Step: 7
Training loss: 0.14589068293571472
Validation loss: 1.5785329418797647

Epoch: 6| Step: 8
Training loss: 0.15458433330059052
Validation loss: 1.6054730722981114

Epoch: 6| Step: 9
Training loss: 0.30191168189048767
Validation loss: 1.6174868998988983

Epoch: 6| Step: 10
Training loss: 0.2357732057571411
Validation loss: 1.6132140659516858

Epoch: 6| Step: 11
Training loss: 0.1551012396812439
Validation loss: 1.605075418308217

Epoch: 6| Step: 12
Training loss: 0.13152894377708435
Validation loss: 1.5721153418223064

Epoch: 6| Step: 13
Training loss: 0.15928326547145844
Validation loss: 1.5901006191007552

Epoch: 297| Step: 0
Training loss: 0.22979438304901123
Validation loss: 1.6269321454468595

Epoch: 6| Step: 1
Training loss: 0.206746444106102
Validation loss: 1.6131688984491492

Epoch: 6| Step: 2
Training loss: 0.2620527744293213
Validation loss: 1.5951688956188899

Epoch: 6| Step: 3
Training loss: 0.206215038895607
Validation loss: 1.6456301468674854

Epoch: 6| Step: 4
Training loss: 0.1840360462665558
Validation loss: 1.6241029052324192

Epoch: 6| Step: 5
Training loss: 0.3896319270133972
Validation loss: 1.6056452515304729

Epoch: 6| Step: 6
Training loss: 0.11311738193035126
Validation loss: 1.6302824892023557

Epoch: 6| Step: 7
Training loss: 0.08774873614311218
Validation loss: 1.6057382322126819

Epoch: 6| Step: 8
Training loss: 0.16332735121250153
Validation loss: 1.6035758641458326

Epoch: 6| Step: 9
Training loss: 0.10753998160362244
Validation loss: 1.6422211585506317

Epoch: 6| Step: 10
Training loss: 0.1878231018781662
Validation loss: 1.604938349416179

Epoch: 6| Step: 11
Training loss: 0.1568640172481537
Validation loss: 1.6164277740704116

Epoch: 6| Step: 12
Training loss: 0.17787829041481018
Validation loss: 1.607859698675012

Epoch: 6| Step: 13
Training loss: 0.38707026839256287
Validation loss: 1.6167919789591143

Epoch: 298| Step: 0
Training loss: 0.30957430601119995
Validation loss: 1.608358899752299

Epoch: 6| Step: 1
Training loss: 0.13226300477981567
Validation loss: 1.6261142915295017

Epoch: 6| Step: 2
Training loss: 0.15595607459545135
Validation loss: 1.6151772333729653

Epoch: 6| Step: 3
Training loss: 0.10520047694444656
Validation loss: 1.6269899901523386

Epoch: 6| Step: 4
Training loss: 0.24542728066444397
Validation loss: 1.6312264498843942

Epoch: 6| Step: 5
Training loss: 0.333950936794281
Validation loss: 1.5987678291977092

Epoch: 6| Step: 6
Training loss: 0.187536358833313
Validation loss: 1.6204465973761775

Epoch: 6| Step: 7
Training loss: 0.16093891859054565
Validation loss: 1.602983723404587

Epoch: 6| Step: 8
Training loss: 0.1675187349319458
Validation loss: 1.6388663220149216

Epoch: 6| Step: 9
Training loss: 0.16265498101711273
Validation loss: 1.6082888175082464

Epoch: 6| Step: 10
Training loss: 0.3238324522972107
Validation loss: 1.651183492393904

Epoch: 6| Step: 11
Training loss: 0.22995106875896454
Validation loss: 1.585970785028191

Epoch: 6| Step: 12
Training loss: 0.20449241995811462
Validation loss: 1.5923390946080607

Epoch: 6| Step: 13
Training loss: 0.15123677253723145
Validation loss: 1.59216062484249

Epoch: 299| Step: 0
Training loss: 0.141516774892807
Validation loss: 1.5699031583724483

Epoch: 6| Step: 1
Training loss: 0.1634795069694519
Validation loss: 1.6057388705592002

Epoch: 6| Step: 2
Training loss: 0.1619521975517273
Validation loss: 1.6189852042864727

Epoch: 6| Step: 3
Training loss: 0.17188921570777893
Validation loss: 1.6016348536296556

Epoch: 6| Step: 4
Training loss: 0.23630747199058533
Validation loss: 1.5988803922489125

Epoch: 6| Step: 5
Training loss: 0.2084018588066101
Validation loss: 1.5834685461495512

Epoch: 6| Step: 6
Training loss: 0.1518152356147766
Validation loss: 1.5833679591455767

Epoch: 6| Step: 7
Training loss: 0.12593504786491394
Validation loss: 1.589738489479147

Epoch: 6| Step: 8
Training loss: 0.14350707828998566
Validation loss: 1.5782449335180304

Epoch: 6| Step: 9
Training loss: 0.21195971965789795
Validation loss: 1.6027047300851474

Epoch: 6| Step: 10
Training loss: 0.2981739640235901
Validation loss: 1.5693061659413

Epoch: 6| Step: 11
Training loss: 0.14405591785907745
Validation loss: 1.5744970408819055

Epoch: 6| Step: 12
Training loss: 0.24921011924743652
Validation loss: 1.5746040549329532

Epoch: 6| Step: 13
Training loss: 0.27756550908088684
Validation loss: 1.5637850556322324

Epoch: 300| Step: 0
Training loss: 0.08960451185703278
Validation loss: 1.5419543109914309

Epoch: 6| Step: 1
Training loss: 0.26043200492858887
Validation loss: 1.5602298116171232

Epoch: 6| Step: 2
Training loss: 0.17635402083396912
Validation loss: 1.533746611687445

Epoch: 6| Step: 3
Training loss: 0.1668643355369568
Validation loss: 1.5620601484852452

Epoch: 6| Step: 4
Training loss: 0.30599483847618103
Validation loss: 1.5866899195537771

Epoch: 6| Step: 5
Training loss: 0.15719740092754364
Validation loss: 1.6075817461936706

Epoch: 6| Step: 6
Training loss: 0.3225766718387604
Validation loss: 1.544468020880094

Epoch: 6| Step: 7
Training loss: 0.13459531962871552
Validation loss: 1.5835328102111816

Epoch: 6| Step: 8
Training loss: 0.2032104730606079
Validation loss: 1.5811450994142922

Epoch: 6| Step: 9
Training loss: 0.15414921939373016
Validation loss: 1.6025292572154795

Epoch: 6| Step: 10
Training loss: 0.2277706414461136
Validation loss: 1.6041284850848618

Epoch: 6| Step: 11
Training loss: 0.21072189509868622
Validation loss: 1.5849563511469031

Epoch: 6| Step: 12
Training loss: 0.25253158807754517
Validation loss: 1.562469151712233

Epoch: 6| Step: 13
Training loss: 0.24072329699993134
Validation loss: 1.5776636831222042

Epoch: 301| Step: 0
Training loss: 0.14793159067630768
Validation loss: 1.5692114291652557

Epoch: 6| Step: 1
Training loss: 0.14533191919326782
Validation loss: 1.5681659983050438

Epoch: 6| Step: 2
Training loss: 0.19845646619796753
Validation loss: 1.5729927721843924

Epoch: 6| Step: 3
Training loss: 0.13656409084796906
Validation loss: 1.5728454218115857

Epoch: 6| Step: 4
Training loss: 0.13907203078269958
Validation loss: 1.5633026194828812

Epoch: 6| Step: 5
Training loss: 0.1759042739868164
Validation loss: 1.5943188757024787

Epoch: 6| Step: 6
Training loss: 0.23266971111297607
Validation loss: 1.5967354082292127

Epoch: 6| Step: 7
Training loss: 0.295914888381958
Validation loss: 1.608642993434783

Epoch: 6| Step: 8
Training loss: 0.1363724023103714
Validation loss: 1.6145263615474905

Epoch: 6| Step: 9
Training loss: 0.23548801243305206
Validation loss: 1.5986599524815877

Epoch: 6| Step: 10
Training loss: 0.23963382840156555
Validation loss: 1.5819923800806845

Epoch: 6| Step: 11
Training loss: 0.18524284660816193
Validation loss: 1.6291837781988165

Epoch: 6| Step: 12
Training loss: 0.19921481609344482
Validation loss: 1.68704939657642

Epoch: 6| Step: 13
Training loss: 0.20662158727645874
Validation loss: 1.6460071250956545

Epoch: 302| Step: 0
Training loss: 0.17528553307056427
Validation loss: 1.697173874865296

Epoch: 6| Step: 1
Training loss: 0.12903480231761932
Validation loss: 1.649175158110998

Epoch: 6| Step: 2
Training loss: 0.15367260575294495
Validation loss: 1.6345036991180912

Epoch: 6| Step: 3
Training loss: 0.18983136117458344
Validation loss: 1.5753956828066098

Epoch: 6| Step: 4
Training loss: 0.19969847798347473
Validation loss: 1.5833972884762673

Epoch: 6| Step: 5
Training loss: 0.38907691836357117
Validation loss: 1.5618509195184196

Epoch: 6| Step: 6
Training loss: 0.14598461985588074
Validation loss: 1.5700554206807127

Epoch: 6| Step: 7
Training loss: 0.1215696930885315
Validation loss: 1.5727136006919287

Epoch: 6| Step: 8
Training loss: 0.20993494987487793
Validation loss: 1.6008063964946295

Epoch: 6| Step: 9
Training loss: 0.29939690232276917
Validation loss: 1.572782067842381

Epoch: 6| Step: 10
Training loss: 0.2348719835281372
Validation loss: 1.6220686076789774

Epoch: 6| Step: 11
Training loss: 0.27535516023635864
Validation loss: 1.6630281594491774

Epoch: 6| Step: 12
Training loss: 0.0933779627084732
Validation loss: 1.6907285515980055

Epoch: 6| Step: 13
Training loss: 0.1964445263147354
Validation loss: 1.689635847204475

Epoch: 303| Step: 0
Training loss: 0.35460424423217773
Validation loss: 1.6450814406077068

Epoch: 6| Step: 1
Training loss: 0.19944199919700623
Validation loss: 1.6546512534541469

Epoch: 6| Step: 2
Training loss: 0.17137567698955536
Validation loss: 1.6040620880742227

Epoch: 6| Step: 3
Training loss: 0.17508915066719055
Validation loss: 1.6007523831500803

Epoch: 6| Step: 4
Training loss: 0.28763464093208313
Validation loss: 1.581285866357947

Epoch: 6| Step: 5
Training loss: 0.11627611517906189
Validation loss: 1.5759916331178399

Epoch: 6| Step: 6
Training loss: 0.23986154794692993
Validation loss: 1.5540104245626798

Epoch: 6| Step: 7
Training loss: 0.18418622016906738
Validation loss: 1.5305664154791063

Epoch: 6| Step: 8
Training loss: 0.16316333413124084
Validation loss: 1.532377698088205

Epoch: 6| Step: 9
Training loss: 0.18062210083007812
Validation loss: 1.5387894786814207

Epoch: 6| Step: 10
Training loss: 0.16052067279815674
Validation loss: 1.5626218703485304

Epoch: 6| Step: 11
Training loss: 0.23510879278182983
Validation loss: 1.5479172096457532

Epoch: 6| Step: 12
Training loss: 0.17557279765605927
Validation loss: 1.5602533509654384

Epoch: 6| Step: 13
Training loss: 0.09870670735836029
Validation loss: 1.5310355950427312

Epoch: 304| Step: 0
Training loss: 0.1039830669760704
Validation loss: 1.5521475345857683

Epoch: 6| Step: 1
Training loss: 0.21082347631454468
Validation loss: 1.5568906517438992

Epoch: 6| Step: 2
Training loss: 0.17057977616786957
Validation loss: 1.5810300278407272

Epoch: 6| Step: 3
Training loss: 0.3127710521221161
Validation loss: 1.6096681625612321

Epoch: 6| Step: 4
Training loss: 0.19279766082763672
Validation loss: 1.5960864046568513

Epoch: 6| Step: 5
Training loss: 0.17031532526016235
Validation loss: 1.5891651607328845

Epoch: 6| Step: 6
Training loss: 0.28030791878700256
Validation loss: 1.6488102712938864

Epoch: 6| Step: 7
Training loss: 0.14556249976158142
Validation loss: 1.6029021073413152

Epoch: 6| Step: 8
Training loss: 0.1712782382965088
Validation loss: 1.624810136774535

Epoch: 6| Step: 9
Training loss: 0.2054179310798645
Validation loss: 1.5901794792503439

Epoch: 6| Step: 10
Training loss: 0.15636220574378967
Validation loss: 1.5705207765743296

Epoch: 6| Step: 11
Training loss: 0.21808560192584991
Validation loss: 1.5601862258808588

Epoch: 6| Step: 12
Training loss: 0.17218461632728577
Validation loss: 1.539828372258012

Epoch: 6| Step: 13
Training loss: 0.12169868499040604
Validation loss: 1.5683453672675676

Epoch: 305| Step: 0
Training loss: 0.18879884481430054
Validation loss: 1.5546832494838263

Epoch: 6| Step: 1
Training loss: 0.2027590572834015
Validation loss: 1.57381300516026

Epoch: 6| Step: 2
Training loss: 0.22077882289886475
Validation loss: 1.5754786018402345

Epoch: 6| Step: 3
Training loss: 0.22161149978637695
Validation loss: 1.6066530891644057

Epoch: 6| Step: 4
Training loss: 0.2110777199268341
Validation loss: 1.6017829372036843

Epoch: 6| Step: 5
Training loss: 0.17565599083900452
Validation loss: 1.6128702394423946

Epoch: 6| Step: 6
Training loss: 0.13941249251365662
Validation loss: 1.591686293643008

Epoch: 6| Step: 7
Training loss: 0.16649863123893738
Validation loss: 1.6016371352698213

Epoch: 6| Step: 8
Training loss: 0.2222622185945511
Validation loss: 1.5746157015523603

Epoch: 6| Step: 9
Training loss: 0.20032939314842224
Validation loss: 1.5791188068287347

Epoch: 6| Step: 10
Training loss: 0.28368493914604187
Validation loss: 1.5490418659743441

Epoch: 6| Step: 11
Training loss: 0.19393688440322876
Validation loss: 1.5750306690892866

Epoch: 6| Step: 12
Training loss: 0.22222134470939636
Validation loss: 1.5328791679874543

Epoch: 6| Step: 13
Training loss: 0.22333714365959167
Validation loss: 1.5231796406930493

Epoch: 306| Step: 0
Training loss: 0.1563674658536911
Validation loss: 1.5340188331501459

Epoch: 6| Step: 1
Training loss: 0.1383056640625
Validation loss: 1.535904158828079

Epoch: 6| Step: 2
Training loss: 0.2190035879611969
Validation loss: 1.5780624266593688

Epoch: 6| Step: 3
Training loss: 0.20695674419403076
Validation loss: 1.5872777251787082

Epoch: 6| Step: 4
Training loss: 0.17654380202293396
Validation loss: 1.560328334890386

Epoch: 6| Step: 5
Training loss: 0.24653595685958862
Validation loss: 1.6177103801440167

Epoch: 6| Step: 6
Training loss: 0.13957396149635315
Validation loss: 1.6015636305655203

Epoch: 6| Step: 7
Training loss: 0.28437942266464233
Validation loss: 1.6147687217240692

Epoch: 6| Step: 8
Training loss: 0.1853533834218979
Validation loss: 1.5923323118558494

Epoch: 6| Step: 9
Training loss: 0.14961960911750793
Validation loss: 1.5802287094054683

Epoch: 6| Step: 10
Training loss: 0.15378165245056152
Validation loss: 1.5845899428090742

Epoch: 6| Step: 11
Training loss: 0.11024400591850281
Validation loss: 1.5939630257186068

Epoch: 6| Step: 12
Training loss: 0.43515145778656006
Validation loss: 1.5832567881512385

Epoch: 6| Step: 13
Training loss: 0.2653874158859253
Validation loss: 1.597258544737293

Epoch: 307| Step: 0
Training loss: 0.1482848823070526
Validation loss: 1.5746255972052132

Epoch: 6| Step: 1
Training loss: 0.33237573504447937
Validation loss: 1.5555729840391426

Epoch: 6| Step: 2
Training loss: 0.10017912089824677
Validation loss: 1.5381673946175525

Epoch: 6| Step: 3
Training loss: 0.16026774048805237
Validation loss: 1.545828693656511

Epoch: 6| Step: 4
Training loss: 0.20858871936798096
Validation loss: 1.556268758671258

Epoch: 6| Step: 5
Training loss: 0.21077167987823486
Validation loss: 1.5478919212536146

Epoch: 6| Step: 6
Training loss: 0.2780226469039917
Validation loss: 1.4851705040982974

Epoch: 6| Step: 7
Training loss: 0.268189936876297
Validation loss: 1.5320800401831185

Epoch: 6| Step: 8
Training loss: 0.21039021015167236
Validation loss: 1.5555326746356102

Epoch: 6| Step: 9
Training loss: 0.30919939279556274
Validation loss: 1.5211292953901394

Epoch: 6| Step: 10
Training loss: 0.15168993175029755
Validation loss: 1.5336466425208635

Epoch: 6| Step: 11
Training loss: 0.11405149102210999
Validation loss: 1.5576280201635053

Epoch: 6| Step: 12
Training loss: 0.1588945984840393
Validation loss: 1.5288655732267646

Epoch: 6| Step: 13
Training loss: 0.10932087898254395
Validation loss: 1.5878417504731046

Epoch: 308| Step: 0
Training loss: 0.2503829896450043
Validation loss: 1.60222505241312

Epoch: 6| Step: 1
Training loss: 0.20037345588207245
Validation loss: 1.580845607224331

Epoch: 6| Step: 2
Training loss: 0.21356505155563354
Validation loss: 1.5853480703087264

Epoch: 6| Step: 3
Training loss: 0.10428165644407272
Validation loss: 1.579215657326483

Epoch: 6| Step: 4
Training loss: 0.09635225683450699
Validation loss: 1.5560886680438955

Epoch: 6| Step: 5
Training loss: 0.13741979002952576
Validation loss: 1.5554793932104622

Epoch: 6| Step: 6
Training loss: 0.17236749827861786
Validation loss: 1.5449296492402271

Epoch: 6| Step: 7
Training loss: 0.19134394824504852
Validation loss: 1.5655900432217507

Epoch: 6| Step: 8
Training loss: 0.18767103552818298
Validation loss: 1.585912492967421

Epoch: 6| Step: 9
Training loss: 0.18119877576828003
Validation loss: 1.569405455743113

Epoch: 6| Step: 10
Training loss: 0.2651033401489258
Validation loss: 1.575913344660113

Epoch: 6| Step: 11
Training loss: 0.20689058303833008
Validation loss: 1.5694533137864963

Epoch: 6| Step: 12
Training loss: 0.16724726557731628
Validation loss: 1.5764757176881194

Epoch: 6| Step: 13
Training loss: 0.10266755521297455
Validation loss: 1.551542079576882

Epoch: 309| Step: 0
Training loss: 0.18030689656734467
Validation loss: 1.5886709331184306

Epoch: 6| Step: 1
Training loss: 0.13540920615196228
Validation loss: 1.5799862723196707

Epoch: 6| Step: 2
Training loss: 0.09265746921300888
Validation loss: 1.5724070559265793

Epoch: 6| Step: 3
Training loss: 0.19299711287021637
Validation loss: 1.5691994159452376

Epoch: 6| Step: 4
Training loss: 0.16138309240341187
Validation loss: 1.592407049671296

Epoch: 6| Step: 5
Training loss: 0.24253393709659576
Validation loss: 1.557534715180756

Epoch: 6| Step: 6
Training loss: 0.3231474757194519
Validation loss: 1.5866706730217062

Epoch: 6| Step: 7
Training loss: 0.2324732542037964
Validation loss: 1.5868144868522562

Epoch: 6| Step: 8
Training loss: 0.14333027601242065
Validation loss: 1.567090198557864

Epoch: 6| Step: 9
Training loss: 0.22224867343902588
Validation loss: 1.5760208624665455

Epoch: 6| Step: 10
Training loss: 0.20228657126426697
Validation loss: 1.522044881697624

Epoch: 6| Step: 11
Training loss: 0.13359472155570984
Validation loss: 1.5444850588357577

Epoch: 6| Step: 12
Training loss: 0.2262450009584427
Validation loss: 1.5454956767379597

Epoch: 6| Step: 13
Training loss: 0.1005740687251091
Validation loss: 1.5900195439656575

Epoch: 310| Step: 0
Training loss: 0.13730967044830322
Validation loss: 1.5852891322105163

Epoch: 6| Step: 1
Training loss: 0.2211364209651947
Validation loss: 1.601263028319164

Epoch: 6| Step: 2
Training loss: 0.16350021958351135
Validation loss: 1.6266066258953464

Epoch: 6| Step: 3
Training loss: 0.258685827255249
Validation loss: 1.6181213842925204

Epoch: 6| Step: 4
Training loss: 0.19880789518356323
Validation loss: 1.597202157461515

Epoch: 6| Step: 5
Training loss: 0.19418995082378387
Validation loss: 1.573994154571205

Epoch: 6| Step: 6
Training loss: 0.20536282658576965
Validation loss: 1.5548903096106745

Epoch: 6| Step: 7
Training loss: 0.16026103496551514
Validation loss: 1.530173582415427

Epoch: 6| Step: 8
Training loss: 0.2035876363515854
Validation loss: 1.552940648089173

Epoch: 6| Step: 9
Training loss: 0.1270015984773636
Validation loss: 1.546372789208607

Epoch: 6| Step: 10
Training loss: 0.24547898769378662
Validation loss: 1.5383609514082632

Epoch: 6| Step: 11
Training loss: 0.24703527987003326
Validation loss: 1.5515121593270251

Epoch: 6| Step: 12
Training loss: 0.2228952795267105
Validation loss: 1.5735628797161965

Epoch: 6| Step: 13
Training loss: 0.11660635471343994
Validation loss: 1.5900528674484582

Epoch: 311| Step: 0
Training loss: 0.18813326954841614
Validation loss: 1.5748728500899447

Epoch: 6| Step: 1
Training loss: 0.15967321395874023
Validation loss: 1.607987380155953

Epoch: 6| Step: 2
Training loss: 0.11905030161142349
Validation loss: 1.6104490192987586

Epoch: 6| Step: 3
Training loss: 0.1779920756816864
Validation loss: 1.6338328648638982

Epoch: 6| Step: 4
Training loss: 0.2585424780845642
Validation loss: 1.6078564043967956

Epoch: 6| Step: 5
Training loss: 0.19904935359954834
Validation loss: 1.5890968486826906

Epoch: 6| Step: 6
Training loss: 0.1978454291820526
Validation loss: 1.5893014951418805

Epoch: 6| Step: 7
Training loss: 0.24251599609851837
Validation loss: 1.5849305275947816

Epoch: 6| Step: 8
Training loss: 0.350050687789917
Validation loss: 1.5945973178391815

Epoch: 6| Step: 9
Training loss: 0.21231740713119507
Validation loss: 1.593090611119424

Epoch: 6| Step: 10
Training loss: 0.1665257215499878
Validation loss: 1.6316651105880737

Epoch: 6| Step: 11
Training loss: 0.22327521443367004
Validation loss: 1.6354436976935274

Epoch: 6| Step: 12
Training loss: 0.12211469560861588
Validation loss: 1.676752867237214

Epoch: 6| Step: 13
Training loss: 0.09760212153196335
Validation loss: 1.644659467922744

Epoch: 312| Step: 0
Training loss: 0.14585357904434204
Validation loss: 1.6280109792627313

Epoch: 6| Step: 1
Training loss: 0.1349579393863678
Validation loss: 1.5992530533062514

Epoch: 6| Step: 2
Training loss: 0.20681217312812805
Validation loss: 1.6139100995115054

Epoch: 6| Step: 3
Training loss: 0.22300785779953003
Validation loss: 1.5892918135530205

Epoch: 6| Step: 4
Training loss: 0.11656425893306732
Validation loss: 1.6115070184071858

Epoch: 6| Step: 5
Training loss: 0.13542041182518005
Validation loss: 1.5519216458002727

Epoch: 6| Step: 6
Training loss: 0.11721111834049225
Validation loss: 1.5751427194123626

Epoch: 6| Step: 7
Training loss: 0.1638958901166916
Validation loss: 1.5421000879297975

Epoch: 6| Step: 8
Training loss: 0.22011452913284302
Validation loss: 1.5637833546566706

Epoch: 6| Step: 9
Training loss: 0.17633408308029175
Validation loss: 1.5865758926637712

Epoch: 6| Step: 10
Training loss: 0.33008286356925964
Validation loss: 1.5649722519741263

Epoch: 6| Step: 11
Training loss: 0.177342027425766
Validation loss: 1.5837945592018865

Epoch: 6| Step: 12
Training loss: 0.27262377738952637
Validation loss: 1.5612608360987839

Epoch: 6| Step: 13
Training loss: 0.12066502124071121
Validation loss: 1.584843825268489

Epoch: 313| Step: 0
Training loss: 0.10498692095279694
Validation loss: 1.589170007295506

Epoch: 6| Step: 1
Training loss: 0.09936100989580154
Validation loss: 1.56962755931321

Epoch: 6| Step: 2
Training loss: 0.1670873463153839
Validation loss: 1.5642384713695896

Epoch: 6| Step: 3
Training loss: 0.17817319929599762
Validation loss: 1.5981622959977837

Epoch: 6| Step: 4
Training loss: 0.1416725367307663
Validation loss: 1.5813555486740605

Epoch: 6| Step: 5
Training loss: 0.21463407576084137
Validation loss: 1.550685017339645

Epoch: 6| Step: 6
Training loss: 0.22076737880706787
Validation loss: 1.5483571803697975

Epoch: 6| Step: 7
Training loss: 0.1946946233510971
Validation loss: 1.5609653175518077

Epoch: 6| Step: 8
Training loss: 0.08926109969615936
Validation loss: 1.5708987828223937

Epoch: 6| Step: 9
Training loss: 0.22280491888523102
Validation loss: 1.5513464737963933

Epoch: 6| Step: 10
Training loss: 0.2854005992412567
Validation loss: 1.5826945189506776

Epoch: 6| Step: 11
Training loss: 0.19921721518039703
Validation loss: 1.587463754479603

Epoch: 6| Step: 12
Training loss: 0.17444846034049988
Validation loss: 1.590670907369224

Epoch: 6| Step: 13
Training loss: 0.10646817088127136
Validation loss: 1.617817424958752

Epoch: 314| Step: 0
Training loss: 0.21116425096988678
Validation loss: 1.638880987321177

Epoch: 6| Step: 1
Training loss: 0.2839062213897705
Validation loss: 1.6388255485924341

Epoch: 6| Step: 2
Training loss: 0.17498919367790222
Validation loss: 1.6689380048423685

Epoch: 6| Step: 3
Training loss: 0.19381853938102722
Validation loss: 1.6367106604319748

Epoch: 6| Step: 4
Training loss: 0.32188689708709717
Validation loss: 1.6193969095906904

Epoch: 6| Step: 5
Training loss: 0.16935886442661285
Validation loss: 1.6391773390513595

Epoch: 6| Step: 6
Training loss: 0.15503951907157898
Validation loss: 1.5961671772823538

Epoch: 6| Step: 7
Training loss: 0.2122834324836731
Validation loss: 1.5706623254283782

Epoch: 6| Step: 8
Training loss: 0.13966301083564758
Validation loss: 1.5563225630790956

Epoch: 6| Step: 9
Training loss: 0.1902356743812561
Validation loss: 1.551502994311753

Epoch: 6| Step: 10
Training loss: 0.15841802954673767
Validation loss: 1.5613256000703382

Epoch: 6| Step: 11
Training loss: 0.18348613381385803
Validation loss: 1.4958579732525734

Epoch: 6| Step: 12
Training loss: 0.19505205750465393
Validation loss: 1.5438691826276882

Epoch: 6| Step: 13
Training loss: 0.1799202710390091
Validation loss: 1.5486482971458024

Epoch: 315| Step: 0
Training loss: 0.16905201971530914
Validation loss: 1.555078507751547

Epoch: 6| Step: 1
Training loss: 0.16424883902072906
Validation loss: 1.5680221293562202

Epoch: 6| Step: 2
Training loss: 0.17981013655662537
Validation loss: 1.6104393909054417

Epoch: 6| Step: 3
Training loss: 0.16842889785766602
Validation loss: 1.6133051700489496

Epoch: 6| Step: 4
Training loss: 0.15773583948612213
Validation loss: 1.5522056318098498

Epoch: 6| Step: 5
Training loss: 0.134495347738266
Validation loss: 1.620253010462689

Epoch: 6| Step: 6
Training loss: 0.133909210562706
Validation loss: 1.6252543772420576

Epoch: 6| Step: 7
Training loss: 0.32957613468170166
Validation loss: 1.61761006616777

Epoch: 6| Step: 8
Training loss: 0.23443752527236938
Validation loss: 1.606274813734075

Epoch: 6| Step: 9
Training loss: 0.10222333669662476
Validation loss: 1.5998094966334682

Epoch: 6| Step: 10
Training loss: 0.1696208268404007
Validation loss: 1.58118603562796

Epoch: 6| Step: 11
Training loss: 0.26389801502227783
Validation loss: 1.5738765731934579

Epoch: 6| Step: 12
Training loss: 0.125331312417984
Validation loss: 1.5805068016052246

Epoch: 6| Step: 13
Training loss: 0.08773410320281982
Validation loss: 1.5668843446239349

Epoch: 316| Step: 0
Training loss: 0.14682261645793915
Validation loss: 1.5734573218130297

Epoch: 6| Step: 1
Training loss: 0.10724371671676636
Validation loss: 1.585619027896594

Epoch: 6| Step: 2
Training loss: 0.09690026938915253
Validation loss: 1.569136747749903

Epoch: 6| Step: 3
Training loss: 0.1656588613986969
Validation loss: 1.5998755270434963

Epoch: 6| Step: 4
Training loss: 0.11962242424488068
Validation loss: 1.5791834913274294

Epoch: 6| Step: 5
Training loss: 0.14389878511428833
Validation loss: 1.6136850567274197

Epoch: 6| Step: 6
Training loss: 0.23315075039863586
Validation loss: 1.5863673084525651

Epoch: 6| Step: 7
Training loss: 0.1570640504360199
Validation loss: 1.5878960970909364

Epoch: 6| Step: 8
Training loss: 0.2531449794769287
Validation loss: 1.5677418003800094

Epoch: 6| Step: 9
Training loss: 0.1860651969909668
Validation loss: 1.5891704328598515

Epoch: 6| Step: 10
Training loss: 0.20411020517349243
Validation loss: 1.6056256435250724

Epoch: 6| Step: 11
Training loss: 0.14372152090072632
Validation loss: 1.5747943257772794

Epoch: 6| Step: 12
Training loss: 0.1789793223142624
Validation loss: 1.5945790275450675

Epoch: 6| Step: 13
Training loss: 0.1849735975265503
Validation loss: 1.5846516175936627

Epoch: 317| Step: 0
Training loss: 0.15307612717151642
Validation loss: 1.543454639373287

Epoch: 6| Step: 1
Training loss: 0.16416841745376587
Validation loss: 1.5818085555107362

Epoch: 6| Step: 2
Training loss: 0.2173120528459549
Validation loss: 1.5576336614547237

Epoch: 6| Step: 3
Training loss: 0.11999598145484924
Validation loss: 1.5754393223793275

Epoch: 6| Step: 4
Training loss: 0.2799748182296753
Validation loss: 1.5701826041744602

Epoch: 6| Step: 5
Training loss: 0.1925341784954071
Validation loss: 1.566841761271159

Epoch: 6| Step: 6
Training loss: 0.08990343660116196
Validation loss: 1.5041065626246954

Epoch: 6| Step: 7
Training loss: 0.19570380449295044
Validation loss: 1.5740154071520733

Epoch: 6| Step: 8
Training loss: 0.20454560220241547
Validation loss: 1.5175326716515325

Epoch: 6| Step: 9
Training loss: 0.18883556127548218
Validation loss: 1.5218179738649757

Epoch: 6| Step: 10
Training loss: 0.1352899968624115
Validation loss: 1.533211834969059

Epoch: 6| Step: 11
Training loss: 0.16199563443660736
Validation loss: 1.5263338012080039

Epoch: 6| Step: 12
Training loss: 0.13092461228370667
Validation loss: 1.5759632074704735

Epoch: 6| Step: 13
Training loss: 0.20343446731567383
Validation loss: 1.525412227517815

Epoch: 318| Step: 0
Training loss: 0.18264657258987427
Validation loss: 1.5369516534190024

Epoch: 6| Step: 1
Training loss: 0.2678951323032379
Validation loss: 1.5581704903674383

Epoch: 6| Step: 2
Training loss: 0.19590453803539276
Validation loss: 1.5527325983970397

Epoch: 6| Step: 3
Training loss: 0.22850152850151062
Validation loss: 1.5583139158064319

Epoch: 6| Step: 4
Training loss: 0.16215571761131287
Validation loss: 1.5422526674885904

Epoch: 6| Step: 5
Training loss: 0.10729049891233444
Validation loss: 1.5224126564559115

Epoch: 6| Step: 6
Training loss: 0.14702743291854858
Validation loss: 1.5445621987824798

Epoch: 6| Step: 7
Training loss: 0.17167794704437256
Validation loss: 1.5482470630317606

Epoch: 6| Step: 8
Training loss: 0.2117159366607666
Validation loss: 1.5221458609386156

Epoch: 6| Step: 9
Training loss: 0.16598168015480042
Validation loss: 1.541992522055103

Epoch: 6| Step: 10
Training loss: 0.17272299528121948
Validation loss: 1.5578193664550781

Epoch: 6| Step: 11
Training loss: 0.17281106114387512
Validation loss: 1.5805656525396532

Epoch: 6| Step: 12
Training loss: 0.1054970920085907
Validation loss: 1.585917785603513

Epoch: 6| Step: 13
Training loss: 0.07827737927436829
Validation loss: 1.5538144662816038

Epoch: 319| Step: 0
Training loss: 0.17193280160427094
Validation loss: 1.5701226021653862

Epoch: 6| Step: 1
Training loss: 0.19823896884918213
Validation loss: 1.5800181691364577

Epoch: 6| Step: 2
Training loss: 0.17039324343204498
Validation loss: 1.5297796598044775

Epoch: 6| Step: 3
Training loss: 0.10568846762180328
Validation loss: 1.532905032557826

Epoch: 6| Step: 4
Training loss: 0.14031340181827545
Validation loss: 1.4996039021399714

Epoch: 6| Step: 5
Training loss: 0.13533926010131836
Validation loss: 1.548679595352501

Epoch: 6| Step: 6
Training loss: 0.2862510681152344
Validation loss: 1.5208913395481725

Epoch: 6| Step: 7
Training loss: 0.22612178325653076
Validation loss: 1.5276877700641591

Epoch: 6| Step: 8
Training loss: 0.12806877493858337
Validation loss: 1.5563015341758728

Epoch: 6| Step: 9
Training loss: 0.15193608403205872
Validation loss: 1.533844909360332

Epoch: 6| Step: 10
Training loss: 0.31130465865135193
Validation loss: 1.5387631206102268

Epoch: 6| Step: 11
Training loss: 0.27970826625823975
Validation loss: 1.5737140896499797

Epoch: 6| Step: 12
Training loss: 0.21088367700576782
Validation loss: 1.5997334975068287

Epoch: 6| Step: 13
Training loss: 0.2203321009874344
Validation loss: 1.5887831052144368

Epoch: 320| Step: 0
Training loss: 0.20661014318466187
Validation loss: 1.6845189730326335

Epoch: 6| Step: 1
Training loss: 0.27622896432876587
Validation loss: 1.7102911946594075

Epoch: 6| Step: 2
Training loss: 0.23743706941604614
Validation loss: 1.6957938850566905

Epoch: 6| Step: 3
Training loss: 0.23922693729400635
Validation loss: 1.6837832940522062

Epoch: 6| Step: 4
Training loss: 0.14900392293930054
Validation loss: 1.685821630621469

Epoch: 6| Step: 5
Training loss: 0.31976163387298584
Validation loss: 1.6674643870322936

Epoch: 6| Step: 6
Training loss: 0.15183661878108978
Validation loss: 1.6416796471482964

Epoch: 6| Step: 7
Training loss: 0.12104128301143646
Validation loss: 1.6460870645379508

Epoch: 6| Step: 8
Training loss: 0.11624370515346527
Validation loss: 1.5904230328016384

Epoch: 6| Step: 9
Training loss: 0.1440797746181488
Validation loss: 1.5955749519409672

Epoch: 6| Step: 10
Training loss: 0.14241650700569153
Validation loss: 1.5718593494866484

Epoch: 6| Step: 11
Training loss: 0.2114039659500122
Validation loss: 1.565787543532669

Epoch: 6| Step: 12
Training loss: 0.18203717470169067
Validation loss: 1.5532632181721349

Epoch: 6| Step: 13
Training loss: 0.20800644159317017
Validation loss: 1.5668834153042044

Epoch: 321| Step: 0
Training loss: 0.18316400051116943
Validation loss: 1.5872337151599187

Epoch: 6| Step: 1
Training loss: 0.16027423739433289
Validation loss: 1.5721449121352165

Epoch: 6| Step: 2
Training loss: 0.11120469123125076
Validation loss: 1.600767933553265

Epoch: 6| Step: 3
Training loss: 0.14104095101356506
Validation loss: 1.6078051072294994

Epoch: 6| Step: 4
Training loss: 0.09405767917633057
Validation loss: 1.6197833066345544

Epoch: 6| Step: 5
Training loss: 0.25392264127731323
Validation loss: 1.6159936356288132

Epoch: 6| Step: 6
Training loss: 0.17736344039440155
Validation loss: 1.6209777503885248

Epoch: 6| Step: 7
Training loss: 0.1222577691078186
Validation loss: 1.6318296693986463

Epoch: 6| Step: 8
Training loss: 0.245949849486351
Validation loss: 1.6089896489215154

Epoch: 6| Step: 9
Training loss: 0.21089327335357666
Validation loss: 1.5627708511967813

Epoch: 6| Step: 10
Training loss: 0.18770883977413177
Validation loss: 1.5698166893374534

Epoch: 6| Step: 11
Training loss: 0.1300196796655655
Validation loss: 1.5603037149675432

Epoch: 6| Step: 12
Training loss: 0.24004897475242615
Validation loss: 1.5461725688749743

Epoch: 6| Step: 13
Training loss: 0.18499621748924255
Validation loss: 1.5401442371388918

Epoch: 322| Step: 0
Training loss: 0.09393400698900223
Validation loss: 1.515591380416706

Epoch: 6| Step: 1
Training loss: 0.2009030282497406
Validation loss: 1.5381282093704387

Epoch: 6| Step: 2
Training loss: 0.1551239937543869
Validation loss: 1.5878003681859663

Epoch: 6| Step: 3
Training loss: 0.17221564054489136
Validation loss: 1.5649306645957373

Epoch: 6| Step: 4
Training loss: 0.21112555265426636
Validation loss: 1.6091116346338743

Epoch: 6| Step: 5
Training loss: 0.20243752002716064
Validation loss: 1.5931711530172696

Epoch: 6| Step: 6
Training loss: 0.19468766450881958
Validation loss: 1.6163610912138415

Epoch: 6| Step: 7
Training loss: 0.15247249603271484
Validation loss: 1.6186942400470856

Epoch: 6| Step: 8
Training loss: 0.1963045597076416
Validation loss: 1.6251834169510873

Epoch: 6| Step: 9
Training loss: 0.2227008193731308
Validation loss: 1.6239190383624005

Epoch: 6| Step: 10
Training loss: 0.1475197970867157
Validation loss: 1.604458519207534

Epoch: 6| Step: 11
Training loss: 0.1571841537952423
Validation loss: 1.6317155630357805

Epoch: 6| Step: 12
Training loss: 0.14053882658481598
Validation loss: 1.5762216730784344

Epoch: 6| Step: 13
Training loss: 0.1496151238679886
Validation loss: 1.578863343884868

Epoch: 323| Step: 0
Training loss: 0.367928683757782
Validation loss: 1.556065038968158

Epoch: 6| Step: 1
Training loss: 0.21077808737754822
Validation loss: 1.5626738725170013

Epoch: 6| Step: 2
Training loss: 0.18874670565128326
Validation loss: 1.5659627158154723

Epoch: 6| Step: 3
Training loss: 0.23470374941825867
Validation loss: 1.5246747501434819

Epoch: 6| Step: 4
Training loss: 0.1863979697227478
Validation loss: 1.514038549956455

Epoch: 6| Step: 5
Training loss: 0.22139811515808105
Validation loss: 1.5181099753226004

Epoch: 6| Step: 6
Training loss: 0.15386594831943512
Validation loss: 1.5616201200792867

Epoch: 6| Step: 7
Training loss: 0.27668002247810364
Validation loss: 1.522304533630289

Epoch: 6| Step: 8
Training loss: 0.18514972925186157
Validation loss: 1.5766009887059529

Epoch: 6| Step: 9
Training loss: 0.20335248112678528
Validation loss: 1.5828265195251794

Epoch: 6| Step: 10
Training loss: 0.23325535655021667
Validation loss: 1.5845505447797879

Epoch: 6| Step: 11
Training loss: 0.26611965894699097
Validation loss: 1.547202951164656

Epoch: 6| Step: 12
Training loss: 0.11320880055427551
Validation loss: 1.5859163999557495

Epoch: 6| Step: 13
Training loss: 0.17655406892299652
Validation loss: 1.5933509013986076

Epoch: 324| Step: 0
Training loss: 0.1308487355709076
Validation loss: 1.6081478095823718

Epoch: 6| Step: 1
Training loss: 0.27701571583747864
Validation loss: 1.6385950375628728

Epoch: 6| Step: 2
Training loss: 0.15312615036964417
Validation loss: 1.5645712434604604

Epoch: 6| Step: 3
Training loss: 0.25264590978622437
Validation loss: 1.5607021854769798

Epoch: 6| Step: 4
Training loss: 0.19156520068645477
Validation loss: 1.5389698807911207

Epoch: 6| Step: 5
Training loss: 0.1387181580066681
Validation loss: 1.533424703664677

Epoch: 6| Step: 6
Training loss: 0.13790737092494965
Validation loss: 1.552597124089477

Epoch: 6| Step: 7
Training loss: 0.4093480110168457
Validation loss: 1.526349603488881

Epoch: 6| Step: 8
Training loss: 0.15307605266571045
Validation loss: 1.5558666580466813

Epoch: 6| Step: 9
Training loss: 0.19685819745063782
Validation loss: 1.5595248591515325

Epoch: 6| Step: 10
Training loss: 0.1449974924325943
Validation loss: 1.548829545256912

Epoch: 6| Step: 11
Training loss: 0.2654262185096741
Validation loss: 1.566412850092816

Epoch: 6| Step: 12
Training loss: 0.14531472325325012
Validation loss: 1.6111677167236165

Epoch: 6| Step: 13
Training loss: 0.1756136268377304
Validation loss: 1.6017266268371253

Epoch: 325| Step: 0
Training loss: 0.19252702593803406
Validation loss: 1.5869034054458782

Epoch: 6| Step: 1
Training loss: 0.12601995468139648
Validation loss: 1.58581708323571

Epoch: 6| Step: 2
Training loss: 0.19166900217533112
Validation loss: 1.5853668502582017

Epoch: 6| Step: 3
Training loss: 0.20865720510482788
Validation loss: 1.6111545165379841

Epoch: 6| Step: 4
Training loss: 0.11293104290962219
Validation loss: 1.595522531899073

Epoch: 6| Step: 5
Training loss: 0.27743396162986755
Validation loss: 1.6180396951654905

Epoch: 6| Step: 6
Training loss: 0.10145051032304764
Validation loss: 1.5826175430769562

Epoch: 6| Step: 7
Training loss: 0.1388143002986908
Validation loss: 1.5716089920331073

Epoch: 6| Step: 8
Training loss: 0.18212859332561493
Validation loss: 1.5676732165839082

Epoch: 6| Step: 9
Training loss: 0.16975420713424683
Validation loss: 1.5849778370190692

Epoch: 6| Step: 10
Training loss: 0.13908061385154724
Validation loss: 1.5551988386338758

Epoch: 6| Step: 11
Training loss: 0.15453559160232544
Validation loss: 1.5309475532142065

Epoch: 6| Step: 12
Training loss: 0.11572451889514923
Validation loss: 1.5111516496186614

Epoch: 6| Step: 13
Training loss: 0.1619580239057541
Validation loss: 1.4984498934079242

Epoch: 326| Step: 0
Training loss: 0.14515231549739838
Validation loss: 1.524962668777794

Epoch: 6| Step: 1
Training loss: 0.11239252984523773
Validation loss: 1.551703142863448

Epoch: 6| Step: 2
Training loss: 0.09444869309663773
Validation loss: 1.525718823555977

Epoch: 6| Step: 3
Training loss: 0.2057407796382904
Validation loss: 1.5508755753117223

Epoch: 6| Step: 4
Training loss: 0.20362111926078796
Validation loss: 1.5775030441181634

Epoch: 6| Step: 5
Training loss: 0.12957994639873505
Validation loss: 1.5972810970839633

Epoch: 6| Step: 6
Training loss: 0.13694168627262115
Validation loss: 1.5911826074764293

Epoch: 6| Step: 7
Training loss: 0.1791255623102188
Validation loss: 1.5601601113555252

Epoch: 6| Step: 8
Training loss: 0.1532248854637146
Validation loss: 1.579016136866744

Epoch: 6| Step: 9
Training loss: 0.15721195936203003
Validation loss: 1.5908146660815004

Epoch: 6| Step: 10
Training loss: 0.12149397283792496
Validation loss: 1.5407905783704532

Epoch: 6| Step: 11
Training loss: 0.31852012872695923
Validation loss: 1.5282822642275082

Epoch: 6| Step: 12
Training loss: 0.1645391285419464
Validation loss: 1.5459916937735774

Epoch: 6| Step: 13
Training loss: 0.1086110770702362
Validation loss: 1.5377658323575092

Epoch: 327| Step: 0
Training loss: 0.27374279499053955
Validation loss: 1.5079694922252367

Epoch: 6| Step: 1
Training loss: 0.18518787622451782
Validation loss: 1.5119426301730576

Epoch: 6| Step: 2
Training loss: 0.21799637377262115
Validation loss: 1.527015406598327

Epoch: 6| Step: 3
Training loss: 0.16880515217781067
Validation loss: 1.5430817988611036

Epoch: 6| Step: 4
Training loss: 0.20040664076805115
Validation loss: 1.5379323395349647

Epoch: 6| Step: 5
Training loss: 0.12134303152561188
Validation loss: 1.5115560036833569

Epoch: 6| Step: 6
Training loss: 0.13723088800907135
Validation loss: 1.5693422594378073

Epoch: 6| Step: 7
Training loss: 0.11503598093986511
Validation loss: 1.5277314532187678

Epoch: 6| Step: 8
Training loss: 0.10526320338249207
Validation loss: 1.5620355093350975

Epoch: 6| Step: 9
Training loss: 0.07760210335254669
Validation loss: 1.5758950646205614

Epoch: 6| Step: 10
Training loss: 0.19361016154289246
Validation loss: 1.5779009134538713

Epoch: 6| Step: 11
Training loss: 0.16992811858654022
Validation loss: 1.5607823633378552

Epoch: 6| Step: 12
Training loss: 0.3781241774559021
Validation loss: 1.5790029828266432

Epoch: 6| Step: 13
Training loss: 0.17848175764083862
Validation loss: 1.5755803995234992

Epoch: 328| Step: 0
Training loss: 0.11840851604938507
Validation loss: 1.5905876531395862

Epoch: 6| Step: 1
Training loss: 0.32549428939819336
Validation loss: 1.5650418727628645

Epoch: 6| Step: 2
Training loss: 0.14413273334503174
Validation loss: 1.596851486031727

Epoch: 6| Step: 3
Training loss: 0.14950478076934814
Validation loss: 1.54785031144337

Epoch: 6| Step: 4
Training loss: 0.16369058191776276
Validation loss: 1.599643035601544

Epoch: 6| Step: 5
Training loss: 0.15012088418006897
Validation loss: 1.598295005418921

Epoch: 6| Step: 6
Training loss: 0.1382291167974472
Validation loss: 1.5936194517279183

Epoch: 6| Step: 7
Training loss: 0.1180354654788971
Validation loss: 1.6070466708111506

Epoch: 6| Step: 8
Training loss: 0.07983201742172241
Validation loss: 1.5912957383740334

Epoch: 6| Step: 9
Training loss: 0.17878060042858124
Validation loss: 1.5813985076001895

Epoch: 6| Step: 10
Training loss: 0.1862173229455948
Validation loss: 1.5660488913136144

Epoch: 6| Step: 11
Training loss: 0.197703555226326
Validation loss: 1.5511030202270837

Epoch: 6| Step: 12
Training loss: 0.1472761034965515
Validation loss: 1.551058433389151

Epoch: 6| Step: 13
Training loss: 0.17874854803085327
Validation loss: 1.548679961953112

Epoch: 329| Step: 0
Training loss: 0.1101122498512268
Validation loss: 1.5404688171161118

Epoch: 6| Step: 1
Training loss: 0.17450371384620667
Validation loss: 1.5302052318408925

Epoch: 6| Step: 2
Training loss: 0.15804924070835114
Validation loss: 1.4897752051712365

Epoch: 6| Step: 3
Training loss: 0.14692050218582153
Validation loss: 1.5079401693036478

Epoch: 6| Step: 4
Training loss: 0.1631559133529663
Validation loss: 1.477382722721305

Epoch: 6| Step: 5
Training loss: 0.13225145637989044
Validation loss: 1.4841881131613126

Epoch: 6| Step: 6
Training loss: 0.15233135223388672
Validation loss: 1.4816051196026545

Epoch: 6| Step: 7
Training loss: 0.1736372411251068
Validation loss: 1.4714207328775877

Epoch: 6| Step: 8
Training loss: 0.2136497050523758
Validation loss: 1.516294930570869

Epoch: 6| Step: 9
Training loss: 0.07898132503032684
Validation loss: 1.486583132897654

Epoch: 6| Step: 10
Training loss: 0.11523474752902985
Validation loss: 1.4943875202568628

Epoch: 6| Step: 11
Training loss: 0.09136328101158142
Validation loss: 1.513532594967914

Epoch: 6| Step: 12
Training loss: 0.12140937149524689
Validation loss: 1.5097863648527412

Epoch: 6| Step: 13
Training loss: 0.11691151559352875
Validation loss: 1.5372180733629452

Epoch: 330| Step: 0
Training loss: 0.12710857391357422
Validation loss: 1.566278039768178

Epoch: 6| Step: 1
Training loss: 0.11805253475904465
Validation loss: 1.5633679795008835

Epoch: 6| Step: 2
Training loss: 0.16923603415489197
Validation loss: 1.563391863658864

Epoch: 6| Step: 3
Training loss: 0.1623707413673401
Validation loss: 1.5713757872581482

Epoch: 6| Step: 4
Training loss: 0.10669201612472534
Validation loss: 1.5942401757804296

Epoch: 6| Step: 5
Training loss: 0.12454929947853088
Validation loss: 1.5758978141251432

Epoch: 6| Step: 6
Training loss: 0.1683385819196701
Validation loss: 1.6057324537666895

Epoch: 6| Step: 7
Training loss: 0.3649437427520752
Validation loss: 1.5919064732008084

Epoch: 6| Step: 8
Training loss: 0.08722350001335144
Validation loss: 1.5949823035988757

Epoch: 6| Step: 9
Training loss: 0.16999536752700806
Validation loss: 1.584676017043411

Epoch: 6| Step: 10
Training loss: 0.21883711218833923
Validation loss: 1.5785544995338685

Epoch: 6| Step: 11
Training loss: 0.13048440217971802
Validation loss: 1.5837231836011332

Epoch: 6| Step: 12
Training loss: 0.17178168892860413
Validation loss: 1.571372801257718

Epoch: 6| Step: 13
Training loss: 0.12680980563163757
Validation loss: 1.5527940257903068

Epoch: 331| Step: 0
Training loss: 0.1263914406299591
Validation loss: 1.554736195072051

Epoch: 6| Step: 1
Training loss: 0.13657160103321075
Validation loss: 1.5352835950031076

Epoch: 6| Step: 2
Training loss: 0.08726140856742859
Validation loss: 1.5273444691011984

Epoch: 6| Step: 3
Training loss: 0.15383154153823853
Validation loss: 1.540550334479219

Epoch: 6| Step: 4
Training loss: 0.15331195294857025
Validation loss: 1.5424277372257684

Epoch: 6| Step: 5
Training loss: 0.14303988218307495
Validation loss: 1.5289886625864173

Epoch: 6| Step: 6
Training loss: 0.13684144616127014
Validation loss: 1.5480075920781782

Epoch: 6| Step: 7
Training loss: 0.16619017720222473
Validation loss: 1.5657070913622457

Epoch: 6| Step: 8
Training loss: 0.29555171728134155
Validation loss: 1.5561359825954642

Epoch: 6| Step: 9
Training loss: 0.12744027376174927
Validation loss: 1.5645344039445281

Epoch: 6| Step: 10
Training loss: 0.19556471705436707
Validation loss: 1.5706307964940225

Epoch: 6| Step: 11
Training loss: 0.10503304749727249
Validation loss: 1.5589726227585987

Epoch: 6| Step: 12
Training loss: 0.07850606739521027
Validation loss: 1.5041912871022378

Epoch: 6| Step: 13
Training loss: 0.21257826685905457
Validation loss: 1.5004096864372172

Epoch: 332| Step: 0
Training loss: 0.18877752125263214
Validation loss: 1.505281562446266

Epoch: 6| Step: 1
Training loss: 0.134137362241745
Validation loss: 1.5161115225925241

Epoch: 6| Step: 2
Training loss: 0.14454713463783264
Validation loss: 1.5360476406671668

Epoch: 6| Step: 3
Training loss: 0.24962779879570007
Validation loss: 1.5201352129700363

Epoch: 6| Step: 4
Training loss: 0.22815418243408203
Validation loss: 1.5416357055787118

Epoch: 6| Step: 5
Training loss: 0.12588724493980408
Validation loss: 1.5192829511498893

Epoch: 6| Step: 6
Training loss: 0.2570568919181824
Validation loss: 1.519092687996485

Epoch: 6| Step: 7
Training loss: 0.17103531956672668
Validation loss: 1.5071876997588782

Epoch: 6| Step: 8
Training loss: 0.16509327292442322
Validation loss: 1.5392484100916053

Epoch: 6| Step: 9
Training loss: 0.1557425558567047
Validation loss: 1.5398795861069874

Epoch: 6| Step: 10
Training loss: 0.17115750908851624
Validation loss: 1.5453731616338093

Epoch: 6| Step: 11
Training loss: 0.11507248878479004
Validation loss: 1.5509447410542478

Epoch: 6| Step: 12
Training loss: 0.13217037916183472
Validation loss: 1.5479379905167447

Epoch: 6| Step: 13
Training loss: 0.09094853699207306
Validation loss: 1.5570454674382364

Epoch: 333| Step: 0
Training loss: 0.1655121147632599
Validation loss: 1.5586864550908406

Epoch: 6| Step: 1
Training loss: 0.22287186980247498
Validation loss: 1.5704122871480963

Epoch: 6| Step: 2
Training loss: 0.16138190031051636
Validation loss: 1.537448553628819

Epoch: 6| Step: 3
Training loss: 0.22204065322875977
Validation loss: 1.5381573259189565

Epoch: 6| Step: 4
Training loss: 0.17099593579769135
Validation loss: 1.5460870304415304

Epoch: 6| Step: 5
Training loss: 0.09009312093257904
Validation loss: 1.521435300509135

Epoch: 6| Step: 6
Training loss: 0.15432575345039368
Validation loss: 1.5593340063607821

Epoch: 6| Step: 7
Training loss: 0.3085523843765259
Validation loss: 1.536606704035113

Epoch: 6| Step: 8
Training loss: 0.10565689951181412
Validation loss: 1.536623977845715

Epoch: 6| Step: 9
Training loss: 0.14200842380523682
Validation loss: 1.5354279125890424

Epoch: 6| Step: 10
Training loss: 0.22578291594982147
Validation loss: 1.5349331068736252

Epoch: 6| Step: 11
Training loss: 0.19487926363945007
Validation loss: 1.5239559142820296

Epoch: 6| Step: 12
Training loss: 0.21018554270267487
Validation loss: 1.5273453048480454

Epoch: 6| Step: 13
Training loss: 0.1266288459300995
Validation loss: 1.5135614897615166

Epoch: 334| Step: 0
Training loss: 0.14619538187980652
Validation loss: 1.5002351140463224

Epoch: 6| Step: 1
Training loss: 0.18983662128448486
Validation loss: 1.5232673896256315

Epoch: 6| Step: 2
Training loss: 0.1783233880996704
Validation loss: 1.5179701223168323

Epoch: 6| Step: 3
Training loss: 0.13010841608047485
Validation loss: 1.491806649392651

Epoch: 6| Step: 4
Training loss: 0.15727849304676056
Validation loss: 1.5133733986526408

Epoch: 6| Step: 5
Training loss: 0.10111106187105179
Validation loss: 1.5285279840551398

Epoch: 6| Step: 6
Training loss: 0.21699553728103638
Validation loss: 1.5175706199420396

Epoch: 6| Step: 7
Training loss: 0.32344305515289307
Validation loss: 1.5378978675411594

Epoch: 6| Step: 8
Training loss: 0.26405802369117737
Validation loss: 1.5346927847913516

Epoch: 6| Step: 9
Training loss: 0.1829390525817871
Validation loss: 1.5493976813490673

Epoch: 6| Step: 10
Training loss: 0.08802490681409836
Validation loss: 1.5683423947262507

Epoch: 6| Step: 11
Training loss: 0.10943803191184998
Validation loss: 1.5710438361731909

Epoch: 6| Step: 12
Training loss: 0.12376951426267624
Validation loss: 1.546807283996254

Epoch: 6| Step: 13
Training loss: 0.1632101982831955
Validation loss: 1.5238451855157011

Epoch: 335| Step: 0
Training loss: 0.1713193655014038
Validation loss: 1.507324158504445

Epoch: 6| Step: 1
Training loss: 0.1010894849896431
Validation loss: 1.5525282839293122

Epoch: 6| Step: 2
Training loss: 0.26992395520210266
Validation loss: 1.5097778285703352

Epoch: 6| Step: 3
Training loss: 0.20649656653404236
Validation loss: 1.5129978285040906

Epoch: 6| Step: 4
Training loss: 0.14738473296165466
Validation loss: 1.497446374226642

Epoch: 6| Step: 5
Training loss: 0.11923213303089142
Validation loss: 1.5264928302457255

Epoch: 6| Step: 6
Training loss: 0.1281808763742447
Validation loss: 1.5386335977943995

Epoch: 6| Step: 7
Training loss: 0.16090478003025055
Validation loss: 1.5313078697009752

Epoch: 6| Step: 8
Training loss: 0.14900508522987366
Validation loss: 1.575466344433446

Epoch: 6| Step: 9
Training loss: 0.1322706788778305
Validation loss: 1.5479952981395106

Epoch: 6| Step: 10
Training loss: 0.11654612421989441
Validation loss: 1.557513576681896

Epoch: 6| Step: 11
Training loss: 0.15343812108039856
Validation loss: 1.5405961262282504

Epoch: 6| Step: 12
Training loss: 0.17796602845191956
Validation loss: 1.5545181253904938

Epoch: 6| Step: 13
Training loss: 0.044258516281843185
Validation loss: 1.542968362249354

Epoch: 336| Step: 0
Training loss: 0.1556001901626587
Validation loss: 1.5015810625527495

Epoch: 6| Step: 1
Training loss: 0.08306892961263657
Validation loss: 1.5414049727942354

Epoch: 6| Step: 2
Training loss: 0.17093002796173096
Validation loss: 1.5876291772370696

Epoch: 6| Step: 3
Training loss: 0.11954669654369354
Validation loss: 1.542382178768035

Epoch: 6| Step: 4
Training loss: 0.1869490146636963
Validation loss: 1.5534595366447204

Epoch: 6| Step: 5
Training loss: 0.14263002574443817
Validation loss: 1.5637215286172845

Epoch: 6| Step: 6
Training loss: 0.16791194677352905
Validation loss: 1.5672911149199291

Epoch: 6| Step: 7
Training loss: 0.1588563323020935
Validation loss: 1.5852241746840938

Epoch: 6| Step: 8
Training loss: 0.12452588975429535
Validation loss: 1.574858585993449

Epoch: 6| Step: 9
Training loss: 0.10198090970516205
Validation loss: 1.5799278879678378

Epoch: 6| Step: 10
Training loss: 0.19353516399860382
Validation loss: 1.6080123019474808

Epoch: 6| Step: 11
Training loss: 0.20676155388355255
Validation loss: 1.5977018353759602

Epoch: 6| Step: 12
Training loss: 0.1584099531173706
Validation loss: 1.609044680672307

Epoch: 6| Step: 13
Training loss: 0.20690405368804932
Validation loss: 1.635335264667388

Epoch: 337| Step: 0
Training loss: 0.14236238598823547
Validation loss: 1.6194257326023553

Epoch: 6| Step: 1
Training loss: 0.1755009889602661
Validation loss: 1.6237304877209406

Epoch: 6| Step: 2
Training loss: 0.37781643867492676
Validation loss: 1.5990477460686878

Epoch: 6| Step: 3
Training loss: 0.16326352953910828
Validation loss: 1.6159760234176472

Epoch: 6| Step: 4
Training loss: 0.12087253481149673
Validation loss: 1.5649376940983597

Epoch: 6| Step: 5
Training loss: 0.11774664372205734
Validation loss: 1.5482838487112394

Epoch: 6| Step: 6
Training loss: 0.14435267448425293
Validation loss: 1.5304223760481803

Epoch: 6| Step: 7
Training loss: 0.15227195620536804
Validation loss: 1.5016639014726043

Epoch: 6| Step: 8
Training loss: 0.16916164755821228
Validation loss: 1.5235837364709506

Epoch: 6| Step: 9
Training loss: 0.15944479405879974
Validation loss: 1.4910427447288268

Epoch: 6| Step: 10
Training loss: 0.16802740097045898
Validation loss: 1.50353701396655

Epoch: 6| Step: 11
Training loss: 0.09733474254608154
Validation loss: 1.500365423899825

Epoch: 6| Step: 12
Training loss: 0.09136133641004562
Validation loss: 1.4702458881562757

Epoch: 6| Step: 13
Training loss: 0.14123067259788513
Validation loss: 1.5007829976979123

Epoch: 338| Step: 0
Training loss: 0.12584178149700165
Validation loss: 1.5285294402030207

Epoch: 6| Step: 1
Training loss: 0.15194450318813324
Validation loss: 1.5289531651363577

Epoch: 6| Step: 2
Training loss: 0.18636825680732727
Validation loss: 1.535659405492967

Epoch: 6| Step: 3
Training loss: 0.18070083856582642
Validation loss: 1.5003366649791758

Epoch: 6| Step: 4
Training loss: 0.2327728569507599
Validation loss: 1.5156423071379304

Epoch: 6| Step: 5
Training loss: 0.2946537733078003
Validation loss: 1.5195185407515495

Epoch: 6| Step: 6
Training loss: 0.08804979175329208
Validation loss: 1.5236083205028246

Epoch: 6| Step: 7
Training loss: 0.14328697323799133
Validation loss: 1.5228299620330974

Epoch: 6| Step: 8
Training loss: 0.16304869949817657
Validation loss: 1.5679423527051044

Epoch: 6| Step: 9
Training loss: 0.15908589959144592
Validation loss: 1.561142836847613

Epoch: 6| Step: 10
Training loss: 0.1987399160861969
Validation loss: 1.5833874722962737

Epoch: 6| Step: 11
Training loss: 0.08945584297180176
Validation loss: 1.5640645565525177

Epoch: 6| Step: 12
Training loss: 0.1413184106349945
Validation loss: 1.5711054635304276

Epoch: 6| Step: 13
Training loss: 0.10128694027662277
Validation loss: 1.5649491638265631

Epoch: 339| Step: 0
Training loss: 0.14217910170555115
Validation loss: 1.544197847766261

Epoch: 6| Step: 1
Training loss: 0.15301479399204254
Validation loss: 1.5521118756263488

Epoch: 6| Step: 2
Training loss: 0.11168739199638367
Validation loss: 1.5157219889343425

Epoch: 6| Step: 3
Training loss: 0.10066312551498413
Validation loss: 1.5395360672345726

Epoch: 6| Step: 4
Training loss: 0.33606669306755066
Validation loss: 1.519996452075179

Epoch: 6| Step: 5
Training loss: 0.17298392951488495
Validation loss: 1.5245392694268176

Epoch: 6| Step: 6
Training loss: 0.16540822386741638
Validation loss: 1.5030946141930037

Epoch: 6| Step: 7
Training loss: 0.11717382818460464
Validation loss: 1.5566375755494641

Epoch: 6| Step: 8
Training loss: 0.10295070707798004
Validation loss: 1.5302872234775173

Epoch: 6| Step: 9
Training loss: 0.10964174568653107
Validation loss: 1.5602597293033396

Epoch: 6| Step: 10
Training loss: 0.10732003301382065
Validation loss: 1.5476519958947295

Epoch: 6| Step: 11
Training loss: 0.15934933722019196
Validation loss: 1.5407734147963985

Epoch: 6| Step: 12
Training loss: 0.13588443398475647
Validation loss: 1.549097086793633

Epoch: 6| Step: 13
Training loss: 0.13326337933540344
Validation loss: 1.5394480927016145

Epoch: 340| Step: 0
Training loss: 0.13058115541934967
Validation loss: 1.5537933021463373

Epoch: 6| Step: 1
Training loss: 0.10903014987707138
Validation loss: 1.557427881866373

Epoch: 6| Step: 2
Training loss: 0.12367334216833115
Validation loss: 1.5494423271507345

Epoch: 6| Step: 3
Training loss: 0.1300077587366104
Validation loss: 1.5477838157325663

Epoch: 6| Step: 4
Training loss: 0.11497417092323303
Validation loss: 1.535504097579628

Epoch: 6| Step: 5
Training loss: 0.1157311350107193
Validation loss: 1.493804213821247

Epoch: 6| Step: 6
Training loss: 0.12629760801792145
Validation loss: 1.4770997339679348

Epoch: 6| Step: 7
Training loss: 0.1510869562625885
Validation loss: 1.520532520868445

Epoch: 6| Step: 8
Training loss: 0.24305535852909088
Validation loss: 1.5135533476388583

Epoch: 6| Step: 9
Training loss: 0.25714758038520813
Validation loss: 1.5253220681221253

Epoch: 6| Step: 10
Training loss: 0.21382084488868713
Validation loss: 1.5290439987695346

Epoch: 6| Step: 11
Training loss: 0.1518770158290863
Validation loss: 1.4999263594227452

Epoch: 6| Step: 12
Training loss: 0.10525108873844147
Validation loss: 1.5212734745394798

Epoch: 6| Step: 13
Training loss: 0.12852253019809723
Validation loss: 1.5271443782314178

Epoch: 341| Step: 0
Training loss: 0.1752878874540329
Validation loss: 1.5536774050804876

Epoch: 6| Step: 1
Training loss: 0.21662193536758423
Validation loss: 1.5278677363549509

Epoch: 6| Step: 2
Training loss: 0.12367761135101318
Validation loss: 1.5230477958597162

Epoch: 6| Step: 3
Training loss: 0.11565767228603363
Validation loss: 1.548391293453914

Epoch: 6| Step: 4
Training loss: 0.10523802042007446
Validation loss: 1.4733245577863467

Epoch: 6| Step: 5
Training loss: 0.09470489621162415
Validation loss: 1.5255354700549957

Epoch: 6| Step: 6
Training loss: 0.115187868475914
Validation loss: 1.5090324519782938

Epoch: 6| Step: 7
Training loss: 0.09652762115001678
Validation loss: 1.526025108111802

Epoch: 6| Step: 8
Training loss: 0.11062147468328476
Validation loss: 1.5593735940994755

Epoch: 6| Step: 9
Training loss: 0.25413939356803894
Validation loss: 1.554288928226758

Epoch: 6| Step: 10
Training loss: 0.2193480134010315
Validation loss: 1.5490373642213884

Epoch: 6| Step: 11
Training loss: 0.12121744453907013
Validation loss: 1.5463069228715793

Epoch: 6| Step: 12
Training loss: 0.16366657614707947
Validation loss: 1.5340367145435785

Epoch: 6| Step: 13
Training loss: 0.2513016164302826
Validation loss: 1.5415068236730431

Epoch: 342| Step: 0
Training loss: 0.1819605678319931
Validation loss: 1.52397568251497

Epoch: 6| Step: 1
Training loss: 0.13646626472473145
Validation loss: 1.5101312104091849

Epoch: 6| Step: 2
Training loss: 0.08937583863735199
Validation loss: 1.5074227420232629

Epoch: 6| Step: 3
Training loss: 0.11583899706602097
Validation loss: 1.5297107145350466

Epoch: 6| Step: 4
Training loss: 0.10056041181087494
Validation loss: 1.5316706806100824

Epoch: 6| Step: 5
Training loss: 0.0932086855173111
Validation loss: 1.5405311430654218

Epoch: 6| Step: 6
Training loss: 0.12228681147098541
Validation loss: 1.534852175302403

Epoch: 6| Step: 7
Training loss: 0.21025905013084412
Validation loss: 1.5172382029153968

Epoch: 6| Step: 8
Training loss: 0.10706886649131775
Validation loss: 1.5129470312467186

Epoch: 6| Step: 9
Training loss: 0.17923206090927124
Validation loss: 1.5620989171407555

Epoch: 6| Step: 10
Training loss: 0.09847401827573776
Validation loss: 1.5371839205423992

Epoch: 6| Step: 11
Training loss: 0.14425376057624817
Validation loss: 1.5177972880742883

Epoch: 6| Step: 12
Training loss: 0.24019239842891693
Validation loss: 1.5123000375686153

Epoch: 6| Step: 13
Training loss: 0.10530286282300949
Validation loss: 1.4994226514652211

Epoch: 343| Step: 0
Training loss: 0.1428089439868927
Validation loss: 1.5049883607895143

Epoch: 6| Step: 1
Training loss: 0.14977651834487915
Validation loss: 1.5171565778793827

Epoch: 6| Step: 2
Training loss: 0.1472349315881729
Validation loss: 1.5387634846471971

Epoch: 6| Step: 3
Training loss: 0.1293662190437317
Validation loss: 1.5181546134333457

Epoch: 6| Step: 4
Training loss: 0.15628290176391602
Validation loss: 1.50033022767754

Epoch: 6| Step: 5
Training loss: 0.1819232851266861
Validation loss: 1.512804369772634

Epoch: 6| Step: 6
Training loss: 0.16927556693553925
Validation loss: 1.4824927878636185

Epoch: 6| Step: 7
Training loss: 0.11315611004829407
Validation loss: 1.4986551269408195

Epoch: 6| Step: 8
Training loss: 0.2018626481294632
Validation loss: 1.4844641467576385

Epoch: 6| Step: 9
Training loss: 0.14668339490890503
Validation loss: 1.5013329771257216

Epoch: 6| Step: 10
Training loss: 0.09543292969465256
Validation loss: 1.4698749114108343

Epoch: 6| Step: 11
Training loss: 0.12986546754837036
Validation loss: 1.5130778833102154

Epoch: 6| Step: 12
Training loss: 0.07451190054416656
Validation loss: 1.5087320138049383

Epoch: 6| Step: 13
Training loss: 0.13150733709335327
Validation loss: 1.5259699834290372

Epoch: 344| Step: 0
Training loss: 0.07288802415132523
Validation loss: 1.532896843648726

Epoch: 6| Step: 1
Training loss: 0.18401950597763062
Validation loss: 1.510035373831308

Epoch: 6| Step: 2
Training loss: 0.2275412380695343
Validation loss: 1.5340289262033278

Epoch: 6| Step: 3
Training loss: 0.14641137421131134
Validation loss: 1.521511657263643

Epoch: 6| Step: 4
Training loss: 0.16661623120307922
Validation loss: 1.5347333749135335

Epoch: 6| Step: 5
Training loss: 0.2003711760044098
Validation loss: 1.517173041579544

Epoch: 6| Step: 6
Training loss: 0.13800984621047974
Validation loss: 1.567413644124103

Epoch: 6| Step: 7
Training loss: 0.17506185173988342
Validation loss: 1.5357708623332362

Epoch: 6| Step: 8
Training loss: 0.2481951266527176
Validation loss: 1.5169936495442544

Epoch: 6| Step: 9
Training loss: 0.12731918692588806
Validation loss: 1.4895905627999255

Epoch: 6| Step: 10
Training loss: 0.06163809821009636
Validation loss: 1.4682091577078706

Epoch: 6| Step: 11
Training loss: 0.12299267202615738
Validation loss: 1.4821337237153003

Epoch: 6| Step: 12
Training loss: 0.12890741229057312
Validation loss: 1.474504937407791

Epoch: 6| Step: 13
Training loss: 0.07330692559480667
Validation loss: 1.4730803094884402

Epoch: 345| Step: 0
Training loss: 0.1848786473274231
Validation loss: 1.4641017260089997

Epoch: 6| Step: 1
Training loss: 0.07532430440187454
Validation loss: 1.4494396050771077

Epoch: 6| Step: 2
Training loss: 0.18018490076065063
Validation loss: 1.4633440433009979

Epoch: 6| Step: 3
Training loss: 0.11826661229133606
Validation loss: 1.4726957480112712

Epoch: 6| Step: 4
Training loss: 0.14285437762737274
Validation loss: 1.4481078578579811

Epoch: 6| Step: 5
Training loss: 0.0986122190952301
Validation loss: 1.4600622397597118

Epoch: 6| Step: 6
Training loss: 0.16819356381893158
Validation loss: 1.4493786609301003

Epoch: 6| Step: 7
Training loss: 0.24189135432243347
Validation loss: 1.4759593702131701

Epoch: 6| Step: 8
Training loss: 0.11985956877470016
Validation loss: 1.4759442883153115

Epoch: 6| Step: 9
Training loss: 0.09263800829648972
Validation loss: 1.4825765509759226

Epoch: 6| Step: 10
Training loss: 0.09373950213193893
Validation loss: 1.4601291828258063

Epoch: 6| Step: 11
Training loss: 0.1719668209552765
Validation loss: 1.4903764378639959

Epoch: 6| Step: 12
Training loss: 0.15440361201763153
Validation loss: 1.4945157240795832

Epoch: 6| Step: 13
Training loss: 0.04136776551604271
Validation loss: 1.5088807139345395

Epoch: 346| Step: 0
Training loss: 0.09808776527643204
Validation loss: 1.4879244091690227

Epoch: 6| Step: 1
Training loss: 0.0884309634566307
Validation loss: 1.5151382133524904

Epoch: 6| Step: 2
Training loss: 0.06987205147743225
Validation loss: 1.4512348918504612

Epoch: 6| Step: 3
Training loss: 0.1681070625782013
Validation loss: 1.458891095653657

Epoch: 6| Step: 4
Training loss: 0.14480936527252197
Validation loss: 1.5212176051191104

Epoch: 6| Step: 5
Training loss: 0.06296516954898834
Validation loss: 1.5219804881721415

Epoch: 6| Step: 6
Training loss: 0.1858704686164856
Validation loss: 1.498980628546848

Epoch: 6| Step: 7
Training loss: 0.0902714878320694
Validation loss: 1.4997433449632378

Epoch: 6| Step: 8
Training loss: 0.11780109256505966
Validation loss: 1.5024050051166165

Epoch: 6| Step: 9
Training loss: 0.09522420912981033
Validation loss: 1.4986166261857556

Epoch: 6| Step: 10
Training loss: 0.09588093310594559
Validation loss: 1.4723046697596067

Epoch: 6| Step: 11
Training loss: 0.2592857778072357
Validation loss: 1.4920033793295584

Epoch: 6| Step: 12
Training loss: 0.16486084461212158
Validation loss: 1.523368376557545

Epoch: 6| Step: 13
Training loss: 0.09916147589683533
Validation loss: 1.50499528197832

Epoch: 347| Step: 0
Training loss: 0.15800634026527405
Validation loss: 1.4932154506765387

Epoch: 6| Step: 1
Training loss: 0.1398315727710724
Validation loss: 1.5235420388560141

Epoch: 6| Step: 2
Training loss: 0.11535276472568512
Validation loss: 1.5556293264512093

Epoch: 6| Step: 3
Training loss: 0.18291303515434265
Validation loss: 1.5573370687423214

Epoch: 6| Step: 4
Training loss: 0.2900369167327881
Validation loss: 1.6140301663388488

Epoch: 6| Step: 5
Training loss: 0.184273362159729
Validation loss: 1.5885752785590388

Epoch: 6| Step: 6
Training loss: 0.19290679693222046
Validation loss: 1.542239499348466

Epoch: 6| Step: 7
Training loss: 0.08143973350524902
Validation loss: 1.5574264129002888

Epoch: 6| Step: 8
Training loss: 0.08800841867923737
Validation loss: 1.5061111539922736

Epoch: 6| Step: 9
Training loss: 0.19327515363693237
Validation loss: 1.4903996170208018

Epoch: 6| Step: 10
Training loss: 0.14254537224769592
Validation loss: 1.506788223020492

Epoch: 6| Step: 11
Training loss: 0.201606884598732
Validation loss: 1.4995769877587595

Epoch: 6| Step: 12
Training loss: 0.07708603888750076
Validation loss: 1.5007031079261535

Epoch: 6| Step: 13
Training loss: 0.13466225564479828
Validation loss: 1.5094521891686223

Epoch: 348| Step: 0
Training loss: 0.24181494116783142
Validation loss: 1.5052881522845196

Epoch: 6| Step: 1
Training loss: 0.11110205203294754
Validation loss: 1.5494060900903517

Epoch: 6| Step: 2
Training loss: 0.13927367329597473
Validation loss: 1.576538016719203

Epoch: 6| Step: 3
Training loss: 0.12227313220500946
Validation loss: 1.5427597235607844

Epoch: 6| Step: 4
Training loss: 0.10957140475511551
Validation loss: 1.553261814578887

Epoch: 6| Step: 5
Training loss: 0.19904276728630066
Validation loss: 1.536687900943141

Epoch: 6| Step: 6
Training loss: 0.19942441582679749
Validation loss: 1.5096046437499344

Epoch: 6| Step: 7
Training loss: 0.12131374329328537
Validation loss: 1.488405518634345

Epoch: 6| Step: 8
Training loss: 0.15858671069145203
Validation loss: 1.4834252512583168

Epoch: 6| Step: 9
Training loss: 0.23687423765659332
Validation loss: 1.495896940590233

Epoch: 6| Step: 10
Training loss: 0.13976126909255981
Validation loss: 1.4980610429599721

Epoch: 6| Step: 11
Training loss: 0.15999585390090942
Validation loss: 1.460158658284013

Epoch: 6| Step: 12
Training loss: 0.29162871837615967
Validation loss: 1.4987442865166614

Epoch: 6| Step: 13
Training loss: 0.13240550458431244
Validation loss: 1.4681101691338323

Epoch: 349| Step: 0
Training loss: 0.15428322553634644
Validation loss: 1.5056328709407518

Epoch: 6| Step: 1
Training loss: 0.08519810438156128
Validation loss: 1.5329729869801512

Epoch: 6| Step: 2
Training loss: 0.1551513522863388
Validation loss: 1.586021202866749

Epoch: 6| Step: 3
Training loss: 0.12624065577983856
Validation loss: 1.5794081252108338

Epoch: 6| Step: 4
Training loss: 0.12159890681505203
Validation loss: 1.5955927820615872

Epoch: 6| Step: 5
Training loss: 0.2929117679595947
Validation loss: 1.5606079537381408

Epoch: 6| Step: 6
Training loss: 0.1681450456380844
Validation loss: 1.5676969251325052

Epoch: 6| Step: 7
Training loss: 0.19280777871608734
Validation loss: 1.5563926478867889

Epoch: 6| Step: 8
Training loss: 0.14634928107261658
Validation loss: 1.5508329009497037

Epoch: 6| Step: 9
Training loss: 0.13788579404354095
Validation loss: 1.5050085616368118

Epoch: 6| Step: 10
Training loss: 0.0812133327126503
Validation loss: 1.513931275695883

Epoch: 6| Step: 11
Training loss: 0.11251695454120636
Validation loss: 1.484191362575818

Epoch: 6| Step: 12
Training loss: 0.21180331707000732
Validation loss: 1.4606258930057607

Epoch: 6| Step: 13
Training loss: 0.0701189786195755
Validation loss: 1.501337828174714

Epoch: 350| Step: 0
Training loss: 0.1468222439289093
Validation loss: 1.4386265239407938

Epoch: 6| Step: 1
Training loss: 0.3148467540740967
Validation loss: 1.4492378786046018

Epoch: 6| Step: 2
Training loss: 0.12978985905647278
Validation loss: 1.4285922332476544

Epoch: 6| Step: 3
Training loss: 0.12598830461502075
Validation loss: 1.4620286341636413

Epoch: 6| Step: 4
Training loss: 0.142226442694664
Validation loss: 1.4489925292230421

Epoch: 6| Step: 5
Training loss: 0.09721705317497253
Validation loss: 1.4712617051216863

Epoch: 6| Step: 6
Training loss: 0.11706399917602539
Validation loss: 1.4963874739985312

Epoch: 6| Step: 7
Training loss: 0.11687427759170532
Validation loss: 1.4775040867508098

Epoch: 6| Step: 8
Training loss: 0.19927243888378143
Validation loss: 1.5121828663733698

Epoch: 6| Step: 9
Training loss: 0.1558915674686432
Validation loss: 1.5231650260186964

Epoch: 6| Step: 10
Training loss: 0.17988072335720062
Validation loss: 1.5450133405705935

Epoch: 6| Step: 11
Training loss: 0.17417651414871216
Validation loss: 1.5594444813266877

Epoch: 6| Step: 12
Training loss: 0.13150842487812042
Validation loss: 1.5624622375734392

Epoch: 6| Step: 13
Training loss: 0.08739933371543884
Validation loss: 1.556204918892153

Epoch: 351| Step: 0
Training loss: 0.1142759844660759
Validation loss: 1.527551552300812

Epoch: 6| Step: 1
Training loss: 0.1750602126121521
Validation loss: 1.5099984932971258

Epoch: 6| Step: 2
Training loss: 0.1607174575328827
Validation loss: 1.5231309783074163

Epoch: 6| Step: 3
Training loss: 0.12816298007965088
Validation loss: 1.4951707650256414

Epoch: 6| Step: 4
Training loss: 0.2597896456718445
Validation loss: 1.5062295224076958

Epoch: 6| Step: 5
Training loss: 0.15674585103988647
Validation loss: 1.5085074081215808

Epoch: 6| Step: 6
Training loss: 0.15894179046154022
Validation loss: 1.512580507545061

Epoch: 6| Step: 7
Training loss: 0.09923293441534042
Validation loss: 1.5529410531443935

Epoch: 6| Step: 8
Training loss: 0.25834542512893677
Validation loss: 1.5678142834735174

Epoch: 6| Step: 9
Training loss: 0.1286427080631256
Validation loss: 1.5534181735848869

Epoch: 6| Step: 10
Training loss: 0.22780120372772217
Validation loss: 1.5781551202138264

Epoch: 6| Step: 11
Training loss: 0.155395969748497
Validation loss: 1.5822946474116335

Epoch: 6| Step: 12
Training loss: 0.19182568788528442
Validation loss: 1.5533132655646211

Epoch: 6| Step: 13
Training loss: 0.0804605782032013
Validation loss: 1.5643961929505872

Epoch: 352| Step: 0
Training loss: 0.12233337759971619
Validation loss: 1.5729686521714734

Epoch: 6| Step: 1
Training loss: 0.10149990767240524
Validation loss: 1.5374057664666125

Epoch: 6| Step: 2
Training loss: 0.13369745016098022
Validation loss: 1.548648065136325

Epoch: 6| Step: 3
Training loss: 0.09020361304283142
Validation loss: 1.5255695824982018

Epoch: 6| Step: 4
Training loss: 0.12666554749011993
Validation loss: 1.5237604789836432

Epoch: 6| Step: 5
Training loss: 0.09613987803459167
Validation loss: 1.5053247085181616

Epoch: 6| Step: 6
Training loss: 0.16151317954063416
Validation loss: 1.5137621805232058

Epoch: 6| Step: 7
Training loss: 0.10647187381982803
Validation loss: 1.5014040380395868

Epoch: 6| Step: 8
Training loss: 0.17776590585708618
Validation loss: 1.4768883579520768

Epoch: 6| Step: 9
Training loss: 0.23297369480133057
Validation loss: 1.4837084918893793

Epoch: 6| Step: 10
Training loss: 0.2225218117237091
Validation loss: 1.4915495502051486

Epoch: 6| Step: 11
Training loss: 0.1659230887889862
Validation loss: 1.5357362352391726

Epoch: 6| Step: 12
Training loss: 0.1832655966281891
Validation loss: 1.5132185618082683

Epoch: 6| Step: 13
Training loss: 0.11809003353118896
Validation loss: 1.5596850918185325

Epoch: 353| Step: 0
Training loss: 0.097437784075737
Validation loss: 1.5288146676555756

Epoch: 6| Step: 1
Training loss: 0.12448526173830032
Validation loss: 1.5321361659675516

Epoch: 6| Step: 2
Training loss: 0.11973389983177185
Validation loss: 1.572840258639346

Epoch: 6| Step: 3
Training loss: 0.09734684973955154
Validation loss: 1.520882260414862

Epoch: 6| Step: 4
Training loss: 0.09938503056764603
Validation loss: 1.558076903384219

Epoch: 6| Step: 5
Training loss: 0.15292078256607056
Validation loss: 1.5501526991526287

Epoch: 6| Step: 6
Training loss: 0.15403404831886292
Validation loss: 1.5511001540768532

Epoch: 6| Step: 7
Training loss: 0.1765245944261551
Validation loss: 1.5622279868331006

Epoch: 6| Step: 8
Training loss: 0.15301944315433502
Validation loss: 1.566039539152576

Epoch: 6| Step: 9
Training loss: 0.10493472963571548
Validation loss: 1.5715257608762352

Epoch: 6| Step: 10
Training loss: 0.24684493243694305
Validation loss: 1.519371428797322

Epoch: 6| Step: 11
Training loss: 0.12442192435264587
Validation loss: 1.552826532753565

Epoch: 6| Step: 12
Training loss: 0.16384831070899963
Validation loss: 1.5125619596050632

Epoch: 6| Step: 13
Training loss: 0.12118205428123474
Validation loss: 1.497749037640069

Epoch: 354| Step: 0
Training loss: 0.1630794107913971
Validation loss: 1.487878381565053

Epoch: 6| Step: 1
Training loss: 0.10623091459274292
Validation loss: 1.502591747109608

Epoch: 6| Step: 2
Training loss: 0.0938742607831955
Validation loss: 1.5060356810528746

Epoch: 6| Step: 3
Training loss: 0.21430443227291107
Validation loss: 1.4824250872417162

Epoch: 6| Step: 4
Training loss: 0.1506892442703247
Validation loss: 1.5019464338979414

Epoch: 6| Step: 5
Training loss: 0.16772472858428955
Validation loss: 1.4777781219892605

Epoch: 6| Step: 6
Training loss: 0.14155253767967224
Validation loss: 1.518898182017829

Epoch: 6| Step: 7
Training loss: 0.11278803646564484
Validation loss: 1.488588071638538

Epoch: 6| Step: 8
Training loss: 0.20937153697013855
Validation loss: 1.5033018935111262

Epoch: 6| Step: 9
Training loss: 0.12154805660247803
Validation loss: 1.4728280100771176

Epoch: 6| Step: 10
Training loss: 0.21982982754707336
Validation loss: 1.4622295748802923

Epoch: 6| Step: 11
Training loss: 0.1063765436410904
Validation loss: 1.466001849020681

Epoch: 6| Step: 12
Training loss: 0.14080193638801575
Validation loss: 1.4533926786914948

Epoch: 6| Step: 13
Training loss: 0.15398550033569336
Validation loss: 1.479950112681235

Epoch: 355| Step: 0
Training loss: 0.174820214509964
Validation loss: 1.4902883832172682

Epoch: 6| Step: 1
Training loss: 0.16600972414016724
Validation loss: 1.486386646506607

Epoch: 6| Step: 2
Training loss: 0.1221274882555008
Validation loss: 1.542882978275258

Epoch: 6| Step: 3
Training loss: 0.09303559362888336
Validation loss: 1.5346876241827523

Epoch: 6| Step: 4
Training loss: 0.10020618140697479
Validation loss: 1.527471976254576

Epoch: 6| Step: 5
Training loss: 0.10119751840829849
Validation loss: 1.5195792490436184

Epoch: 6| Step: 6
Training loss: 0.12476684153079987
Validation loss: 1.5028297247425202

Epoch: 6| Step: 7
Training loss: 0.08128458261489868
Validation loss: 1.5016755275828864

Epoch: 6| Step: 8
Training loss: 0.1228017807006836
Validation loss: 1.5089385932491672

Epoch: 6| Step: 9
Training loss: 0.10347066819667816
Validation loss: 1.5091985412823257

Epoch: 6| Step: 10
Training loss: 0.1818518489599228
Validation loss: 1.4959234704253495

Epoch: 6| Step: 11
Training loss: 0.09019625186920166
Validation loss: 1.5080655223579817

Epoch: 6| Step: 12
Training loss: 0.12056970596313477
Validation loss: 1.5138518284725886

Epoch: 6| Step: 13
Training loss: 0.21570049226284027
Validation loss: 1.5027884052645775

Epoch: 356| Step: 0
Training loss: 0.11719655990600586
Validation loss: 1.5124603227902484

Epoch: 6| Step: 1
Training loss: 0.1271139234304428
Validation loss: 1.4665021934816915

Epoch: 6| Step: 2
Training loss: 0.06478898227214813
Validation loss: 1.5182465968593475

Epoch: 6| Step: 3
Training loss: 0.20843783020973206
Validation loss: 1.4861266305369716

Epoch: 6| Step: 4
Training loss: 0.13818052411079407
Validation loss: 1.4688215909465667

Epoch: 6| Step: 5
Training loss: 0.07029493153095245
Validation loss: 1.4684861193421066

Epoch: 6| Step: 6
Training loss: 0.15012004971504211
Validation loss: 1.4330642197721748

Epoch: 6| Step: 7
Training loss: 0.14379200339317322
Validation loss: 1.4827872886452624

Epoch: 6| Step: 8
Training loss: 0.16817350685596466
Validation loss: 1.4645761161722162

Epoch: 6| Step: 9
Training loss: 0.239442840218544
Validation loss: 1.4515431093913254

Epoch: 6| Step: 10
Training loss: 0.11061915010213852
Validation loss: 1.4200087260174494

Epoch: 6| Step: 11
Training loss: 0.16032588481903076
Validation loss: 1.434491947133054

Epoch: 6| Step: 12
Training loss: 0.1256948560476303
Validation loss: 1.4244112737717167

Epoch: 6| Step: 13
Training loss: 0.10656341165304184
Validation loss: 1.4775475084140737

Epoch: 357| Step: 0
Training loss: 0.12376189231872559
Validation loss: 1.514023102739806

Epoch: 6| Step: 1
Training loss: 0.13829824328422546
Validation loss: 1.5154454656826553

Epoch: 6| Step: 2
Training loss: 0.14371716976165771
Validation loss: 1.5410060139112576

Epoch: 6| Step: 3
Training loss: 0.4703133702278137
Validation loss: 1.5776947313739407

Epoch: 6| Step: 4
Training loss: 0.15351873636245728
Validation loss: 1.563947787848852

Epoch: 6| Step: 5
Training loss: 0.08417614549398422
Validation loss: 1.5068639452739427

Epoch: 6| Step: 6
Training loss: 0.120899498462677
Validation loss: 1.470196541919503

Epoch: 6| Step: 7
Training loss: 0.12376929819583893
Validation loss: 1.5082352879226848

Epoch: 6| Step: 8
Training loss: 0.14086753129959106
Validation loss: 1.5002822875976562

Epoch: 6| Step: 9
Training loss: 0.13215699791908264
Validation loss: 1.5017657087695213

Epoch: 6| Step: 10
Training loss: 0.16409996151924133
Validation loss: 1.4838430753318212

Epoch: 6| Step: 11
Training loss: 0.1476944237947464
Validation loss: 1.4788138917697373

Epoch: 6| Step: 12
Training loss: 0.1763700395822525
Validation loss: 1.4867114892569921

Epoch: 6| Step: 13
Training loss: 0.11062285304069519
Validation loss: 1.4773851850981354

Epoch: 358| Step: 0
Training loss: 0.1097957193851471
Validation loss: 1.4905752815226072

Epoch: 6| Step: 1
Training loss: 0.16057486832141876
Validation loss: 1.4799627046431265

Epoch: 6| Step: 2
Training loss: 0.24016375839710236
Validation loss: 1.4536864795992452

Epoch: 6| Step: 3
Training loss: 0.14104357361793518
Validation loss: 1.493043923890719

Epoch: 6| Step: 4
Training loss: 0.1377301812171936
Validation loss: 1.49354596548183

Epoch: 6| Step: 5
Training loss: 0.15359841287136078
Validation loss: 1.521746394454792

Epoch: 6| Step: 6
Training loss: 0.12839987874031067
Validation loss: 1.4949200537896925

Epoch: 6| Step: 7
Training loss: 0.1374291181564331
Validation loss: 1.481414964122157

Epoch: 6| Step: 8
Training loss: 0.1629357635974884
Validation loss: 1.5002892786456692

Epoch: 6| Step: 9
Training loss: 0.055695950984954834
Validation loss: 1.513501658234545

Epoch: 6| Step: 10
Training loss: 0.14246366918087006
Validation loss: 1.5023516672913746

Epoch: 6| Step: 11
Training loss: 0.12779124081134796
Validation loss: 1.5265094593007078

Epoch: 6| Step: 12
Training loss: 0.1905137002468109
Validation loss: 1.5298995612769999

Epoch: 6| Step: 13
Training loss: 0.2061217576265335
Validation loss: 1.5432610447688768

Epoch: 359| Step: 0
Training loss: 0.11080701649188995
Validation loss: 1.5292110007296327

Epoch: 6| Step: 1
Training loss: 0.14870254695415497
Validation loss: 1.5622566669218

Epoch: 6| Step: 2
Training loss: 0.16905257105827332
Validation loss: 1.5584096870114725

Epoch: 6| Step: 3
Training loss: 0.17762653529644012
Validation loss: 1.5242279691080893

Epoch: 6| Step: 4
Training loss: 0.0948767364025116
Validation loss: 1.5101563392146942

Epoch: 6| Step: 5
Training loss: 0.1680556833744049
Validation loss: 1.4921656629090667

Epoch: 6| Step: 6
Training loss: 0.20280593633651733
Validation loss: 1.5102011542166434

Epoch: 6| Step: 7
Training loss: 0.2446046769618988
Validation loss: 1.5040017674046178

Epoch: 6| Step: 8
Training loss: 0.15737029910087585
Validation loss: 1.4926142923293575

Epoch: 6| Step: 9
Training loss: 0.12601754069328308
Validation loss: 1.5014537085768997

Epoch: 6| Step: 10
Training loss: 0.20081773400306702
Validation loss: 1.4952715340481009

Epoch: 6| Step: 11
Training loss: 0.16195052862167358
Validation loss: 1.5121348391297043

Epoch: 6| Step: 12
Training loss: 0.16887900233268738
Validation loss: 1.4582738760978944

Epoch: 6| Step: 13
Training loss: 0.11029376089572906
Validation loss: 1.4873262682268698

Epoch: 360| Step: 0
Training loss: 0.14189884066581726
Validation loss: 1.484020512591126

Epoch: 6| Step: 1
Training loss: 0.1853550672531128
Validation loss: 1.4861275271702838

Epoch: 6| Step: 2
Training loss: 0.12676844000816345
Validation loss: 1.475610065203841

Epoch: 6| Step: 3
Training loss: 0.13181480765342712
Validation loss: 1.4981646871054044

Epoch: 6| Step: 4
Training loss: 0.13330712914466858
Validation loss: 1.4732257666126374

Epoch: 6| Step: 5
Training loss: 0.09447027742862701
Validation loss: 1.526697522850447

Epoch: 6| Step: 6
Training loss: 0.14943650364875793
Validation loss: 1.5612856944402058

Epoch: 6| Step: 7
Training loss: 0.17760400474071503
Validation loss: 1.5593918113298313

Epoch: 6| Step: 8
Training loss: 0.19033215939998627
Validation loss: 1.569673853535806

Epoch: 6| Step: 9
Training loss: 0.322147011756897
Validation loss: 1.6041756714543989

Epoch: 6| Step: 10
Training loss: 0.24864158034324646
Validation loss: 1.5452175415972227

Epoch: 6| Step: 11
Training loss: 0.24064595997333527
Validation loss: 1.5287315948035127

Epoch: 6| Step: 12
Training loss: 0.1900675892829895
Validation loss: 1.476761443640596

Epoch: 6| Step: 13
Training loss: 0.24447393417358398
Validation loss: 1.497638484483124

Epoch: 361| Step: 0
Training loss: 0.15858696401119232
Validation loss: 1.4607050841854465

Epoch: 6| Step: 1
Training loss: 0.160566046833992
Validation loss: 1.4959531548202678

Epoch: 6| Step: 2
Training loss: 0.14385193586349487
Validation loss: 1.5131747056079168

Epoch: 6| Step: 3
Training loss: 0.20306697487831116
Validation loss: 1.537947606014949

Epoch: 6| Step: 4
Training loss: 0.15983973443508148
Validation loss: 1.54094523127361

Epoch: 6| Step: 5
Training loss: 0.2026953548192978
Validation loss: 1.521917176503007

Epoch: 6| Step: 6
Training loss: 0.3231862783432007
Validation loss: 1.5628608324194466

Epoch: 6| Step: 7
Training loss: 0.29304778575897217
Validation loss: 1.5394134393302343

Epoch: 6| Step: 8
Training loss: 0.16232407093048096
Validation loss: 1.541847441786079

Epoch: 6| Step: 9
Training loss: 0.11430645734071732
Validation loss: 1.5055975708910214

Epoch: 6| Step: 10
Training loss: 0.3081247806549072
Validation loss: 1.5075802533857283

Epoch: 6| Step: 11
Training loss: 0.132236048579216
Validation loss: 1.5035161356772146

Epoch: 6| Step: 12
Training loss: 0.1805420070886612
Validation loss: 1.4926771271613337

Epoch: 6| Step: 13
Training loss: 0.14822521805763245
Validation loss: 1.4852708590927945

Epoch: 362| Step: 0
Training loss: 0.13111934065818787
Validation loss: 1.5085251677420832

Epoch: 6| Step: 1
Training loss: 0.14453403651714325
Validation loss: 1.5212036922413816

Epoch: 6| Step: 2
Training loss: 0.20168428122997284
Validation loss: 1.5308655135093197

Epoch: 6| Step: 3
Training loss: 0.10985392332077026
Validation loss: 1.5497114132809382

Epoch: 6| Step: 4
Training loss: 0.222833514213562
Validation loss: 1.5773588149778304

Epoch: 6| Step: 5
Training loss: 0.1299179196357727
Validation loss: 1.5873976215239494

Epoch: 6| Step: 6
Training loss: 0.34828120470046997
Validation loss: 1.573220060717675

Epoch: 6| Step: 7
Training loss: 0.15117868781089783
Validation loss: 1.5829500870038105

Epoch: 6| Step: 8
Training loss: 0.2156938910484314
Validation loss: 1.520830076227906

Epoch: 6| Step: 9
Training loss: 0.1269683688879013
Validation loss: 1.4988666035795724

Epoch: 6| Step: 10
Training loss: 0.10264278948307037
Validation loss: 1.4921023076580417

Epoch: 6| Step: 11
Training loss: 0.1629127413034439
Validation loss: 1.4581251875046761

Epoch: 6| Step: 12
Training loss: 0.11490872502326965
Validation loss: 1.4583739042282104

Epoch: 6| Step: 13
Training loss: 0.306449830532074
Validation loss: 1.436484888035764

Epoch: 363| Step: 0
Training loss: 0.15838518738746643
Validation loss: 1.4452327336034467

Epoch: 6| Step: 1
Training loss: 0.25113463401794434
Validation loss: 1.468340858336418

Epoch: 6| Step: 2
Training loss: 0.09548088908195496
Validation loss: 1.426470793703551

Epoch: 6| Step: 3
Training loss: 0.12546557188034058
Validation loss: 1.5061750847806212

Epoch: 6| Step: 4
Training loss: 0.16202393174171448
Validation loss: 1.478704765278806

Epoch: 6| Step: 5
Training loss: 0.17904645204544067
Validation loss: 1.5070845221960416

Epoch: 6| Step: 6
Training loss: 0.14770379662513733
Validation loss: 1.510637621725759

Epoch: 6| Step: 7
Training loss: 0.08132127672433853
Validation loss: 1.5144925604584396

Epoch: 6| Step: 8
Training loss: 0.15116116404533386
Validation loss: 1.5239600866071639

Epoch: 6| Step: 9
Training loss: 0.15590953826904297
Validation loss: 1.553834584451491

Epoch: 6| Step: 10
Training loss: 0.18360409140586853
Validation loss: 1.535885618579003

Epoch: 6| Step: 11
Training loss: 0.20943006873130798
Validation loss: 1.5278192822651198

Epoch: 6| Step: 12
Training loss: 0.2207174003124237
Validation loss: 1.5326375679303241

Epoch: 6| Step: 13
Training loss: 0.24541155993938446
Validation loss: 1.4999956757791582

Epoch: 364| Step: 0
Training loss: 0.16140013933181763
Validation loss: 1.4956064160152147

Epoch: 6| Step: 1
Training loss: 0.14638906717300415
Validation loss: 1.4623765330160818

Epoch: 6| Step: 2
Training loss: 0.10895073413848877
Validation loss: 1.4395816967051516

Epoch: 6| Step: 3
Training loss: 0.14877824485301971
Validation loss: 1.4357117491383706

Epoch: 6| Step: 4
Training loss: 0.13857853412628174
Validation loss: 1.4510352105222724

Epoch: 6| Step: 5
Training loss: 0.22429563105106354
Validation loss: 1.4932138176374539

Epoch: 6| Step: 6
Training loss: 0.17804571986198425
Validation loss: 1.5094038991517917

Epoch: 6| Step: 7
Training loss: 0.1537037193775177
Validation loss: 1.5226205356659428

Epoch: 6| Step: 8
Training loss: 0.14685288071632385
Validation loss: 1.5183719806773688

Epoch: 6| Step: 9
Training loss: 0.1942562460899353
Validation loss: 1.5062415138367684

Epoch: 6| Step: 10
Training loss: 0.19421672821044922
Validation loss: 1.4852496475301764

Epoch: 6| Step: 11
Training loss: 0.15283991396427155
Validation loss: 1.5115992830645653

Epoch: 6| Step: 12
Training loss: 0.32384225726127625
Validation loss: 1.5111903939195859

Epoch: 6| Step: 13
Training loss: 0.12202607095241547
Validation loss: 1.5100150710792952

Epoch: 365| Step: 0
Training loss: 0.12416596710681915
Validation loss: 1.4744559821262155

Epoch: 6| Step: 1
Training loss: 0.27754563093185425
Validation loss: 1.4761067648087778

Epoch: 6| Step: 2
Training loss: 0.2797052264213562
Validation loss: 1.499807200124187

Epoch: 6| Step: 3
Training loss: 0.18643280863761902
Validation loss: 1.4852171251850743

Epoch: 6| Step: 4
Training loss: 0.1524055004119873
Validation loss: 1.444737631787536

Epoch: 6| Step: 5
Training loss: 0.11830003559589386
Validation loss: 1.3989710987255137

Epoch: 6| Step: 6
Training loss: 0.1359969824552536
Validation loss: 1.378235738764527

Epoch: 6| Step: 7
Training loss: 0.21796976029872894
Validation loss: 1.4084032466334682

Epoch: 6| Step: 8
Training loss: 0.157380610704422
Validation loss: 1.414769704623889

Epoch: 6| Step: 9
Training loss: 0.0919470340013504
Validation loss: 1.3842260876009542

Epoch: 6| Step: 10
Training loss: 0.14429181814193726
Validation loss: 1.3960432121830602

Epoch: 6| Step: 11
Training loss: 0.12523122131824493
Validation loss: 1.4119317095766786

Epoch: 6| Step: 12
Training loss: 0.15877729654312134
Validation loss: 1.4484602789725027

Epoch: 6| Step: 13
Training loss: 0.16824331879615784
Validation loss: 1.471673281602962

Epoch: 366| Step: 0
Training loss: 0.1237088292837143
Validation loss: 1.4846362997126836

Epoch: 6| Step: 1
Training loss: 0.26729899644851685
Validation loss: 1.4945832349920785

Epoch: 6| Step: 2
Training loss: 0.150746688246727
Validation loss: 1.4865009015606296

Epoch: 6| Step: 3
Training loss: 0.11937160789966583
Validation loss: 1.4731001341214744

Epoch: 6| Step: 4
Training loss: 0.1520974040031433
Validation loss: 1.4780890980074484

Epoch: 6| Step: 5
Training loss: 0.14024318754673004
Validation loss: 1.458839451113055

Epoch: 6| Step: 6
Training loss: 0.13362739980220795
Validation loss: 1.4443926900945685

Epoch: 6| Step: 7
Training loss: 0.15896891057491302
Validation loss: 1.4638628607155175

Epoch: 6| Step: 8
Training loss: 0.08299010246992111
Validation loss: 1.4757707888080227

Epoch: 6| Step: 9
Training loss: 0.15438011288642883
Validation loss: 1.4354866999451832

Epoch: 6| Step: 10
Training loss: 0.2200852334499359
Validation loss: 1.4559476055124754

Epoch: 6| Step: 11
Training loss: 0.18544910848140717
Validation loss: 1.4313982238051712

Epoch: 6| Step: 12
Training loss: 0.12501969933509827
Validation loss: 1.4647475384896802

Epoch: 6| Step: 13
Training loss: 0.08795159310102463
Validation loss: 1.440552035967509

Epoch: 367| Step: 0
Training loss: 0.11184877902269363
Validation loss: 1.446384278676843

Epoch: 6| Step: 1
Training loss: 0.2109573781490326
Validation loss: 1.4456121152447117

Epoch: 6| Step: 2
Training loss: 0.10723796486854553
Validation loss: 1.4581631268224409

Epoch: 6| Step: 3
Training loss: 0.12753264605998993
Validation loss: 1.4605333061628445

Epoch: 6| Step: 4
Training loss: 0.16231192648410797
Validation loss: 1.4919034486175866

Epoch: 6| Step: 5
Training loss: 0.10840605199337006
Validation loss: 1.4944077992951998

Epoch: 6| Step: 6
Training loss: 0.16816122829914093
Validation loss: 1.507822734053417

Epoch: 6| Step: 7
Training loss: 0.1676064282655716
Validation loss: 1.5088514108811655

Epoch: 6| Step: 8
Training loss: 0.21287453174591064
Validation loss: 1.5054283161317148

Epoch: 6| Step: 9
Training loss: 0.08973129093647003
Validation loss: 1.4724004614737727

Epoch: 6| Step: 10
Training loss: 0.13687646389007568
Validation loss: 1.4853807136576662

Epoch: 6| Step: 11
Training loss: 0.06902796030044556
Validation loss: 1.4807644556927424

Epoch: 6| Step: 12
Training loss: 0.10637416690587997
Validation loss: 1.4759230498344666

Epoch: 6| Step: 13
Training loss: 0.12335234135389328
Validation loss: 1.479268879018804

Epoch: 368| Step: 0
Training loss: 0.136987566947937
Validation loss: 1.472014973240514

Epoch: 6| Step: 1
Training loss: 0.09021104872226715
Validation loss: 1.4517933437901158

Epoch: 6| Step: 2
Training loss: 0.10418251156806946
Validation loss: 1.474986687783272

Epoch: 6| Step: 3
Training loss: 0.23064914345741272
Validation loss: 1.4563109451724636

Epoch: 6| Step: 4
Training loss: 0.10878107696771622
Validation loss: 1.4727036286425847

Epoch: 6| Step: 5
Training loss: 0.11736573278903961
Validation loss: 1.4493684204675819

Epoch: 6| Step: 6
Training loss: 0.22688260674476624
Validation loss: 1.464873142139886

Epoch: 6| Step: 7
Training loss: 0.0804024189710617
Validation loss: 1.468220494126761

Epoch: 6| Step: 8
Training loss: 0.09479427337646484
Validation loss: 1.4614585920046734

Epoch: 6| Step: 9
Training loss: 0.08487746119499207
Validation loss: 1.466477717122724

Epoch: 6| Step: 10
Training loss: 0.10573947429656982
Validation loss: 1.4681006413634106

Epoch: 6| Step: 11
Training loss: 0.141791433095932
Validation loss: 1.4640275098944222

Epoch: 6| Step: 12
Training loss: 0.14680147171020508
Validation loss: 1.4798329581496537

Epoch: 6| Step: 13
Training loss: 0.09022825211286545
Validation loss: 1.4466947304305209

Epoch: 369| Step: 0
Training loss: 0.0716295838356018
Validation loss: 1.4647658307065246

Epoch: 6| Step: 1
Training loss: 0.1922411173582077
Validation loss: 1.4805023670196533

Epoch: 6| Step: 2
Training loss: 0.1391046792268753
Validation loss: 1.5141217849587882

Epoch: 6| Step: 3
Training loss: 0.10706936568021774
Validation loss: 1.4931143983717887

Epoch: 6| Step: 4
Training loss: 0.11353486776351929
Validation loss: 1.474028007958525

Epoch: 6| Step: 5
Training loss: 0.11905398219823837
Validation loss: 1.4843820987209198

Epoch: 6| Step: 6
Training loss: 0.08768156170845032
Validation loss: 1.4591346620231547

Epoch: 6| Step: 7
Training loss: 0.095701664686203
Validation loss: 1.4569918763252996

Epoch: 6| Step: 8
Training loss: 0.07418199628591537
Validation loss: 1.4365038794855918

Epoch: 6| Step: 9
Training loss: 0.16668634116649628
Validation loss: 1.4670070512320406

Epoch: 6| Step: 10
Training loss: 0.21080100536346436
Validation loss: 1.4778281206725745

Epoch: 6| Step: 11
Training loss: 0.10797001421451569
Validation loss: 1.4577864023946947

Epoch: 6| Step: 12
Training loss: 0.15379703044891357
Validation loss: 1.4721422951708558

Epoch: 6| Step: 13
Training loss: 0.06753911077976227
Validation loss: 1.4573477106068724

Epoch: 370| Step: 0
Training loss: 0.1379169076681137
Validation loss: 1.460265806926194

Epoch: 6| Step: 1
Training loss: 0.10913703590631485
Validation loss: 1.4303938265769713

Epoch: 6| Step: 2
Training loss: 0.1355009377002716
Validation loss: 1.4686782629259172

Epoch: 6| Step: 3
Training loss: 0.095901720225811
Validation loss: 1.4039946679146058

Epoch: 6| Step: 4
Training loss: 0.2821093201637268
Validation loss: 1.4278224001648605

Epoch: 6| Step: 5
Training loss: 0.16896575689315796
Validation loss: 1.430320990982876

Epoch: 6| Step: 6
Training loss: 0.16672201454639435
Validation loss: 1.4556375357412523

Epoch: 6| Step: 7
Training loss: 0.10382194817066193
Validation loss: 1.4971617972978981

Epoch: 6| Step: 8
Training loss: 0.09620460867881775
Validation loss: 1.466767430305481

Epoch: 6| Step: 9
Training loss: 0.10936984419822693
Validation loss: 1.4512825794117425

Epoch: 6| Step: 10
Training loss: 0.12838798761367798
Validation loss: 1.47782427008434

Epoch: 6| Step: 11
Training loss: 0.11297716200351715
Validation loss: 1.4321170045483498

Epoch: 6| Step: 12
Training loss: 0.1260436326265335
Validation loss: 1.4518496528748543

Epoch: 6| Step: 13
Training loss: 0.12684689462184906
Validation loss: 1.4214474155056862

Epoch: 371| Step: 0
Training loss: 0.11125709861516953
Validation loss: 1.4226965494053339

Epoch: 6| Step: 1
Training loss: 0.1657133251428604
Validation loss: 1.427773767902005

Epoch: 6| Step: 2
Training loss: 0.0639948695898056
Validation loss: 1.4333421273898053

Epoch: 6| Step: 3
Training loss: 0.12571275234222412
Validation loss: 1.3904626446385537

Epoch: 6| Step: 4
Training loss: 0.10635930299758911
Validation loss: 1.4610399443616149

Epoch: 6| Step: 5
Training loss: 0.17506550252437592
Validation loss: 1.4517262212691768

Epoch: 6| Step: 6
Training loss: 0.12537232041358948
Validation loss: 1.449039977083924

Epoch: 6| Step: 7
Training loss: 0.13491901755332947
Validation loss: 1.4457029008096265

Epoch: 6| Step: 8
Training loss: 0.11517210304737091
Validation loss: 1.497535914503118

Epoch: 6| Step: 9
Training loss: 0.11358322948217392
Validation loss: 1.4971044384023195

Epoch: 6| Step: 10
Training loss: 0.12403271347284317
Validation loss: 1.5134686218794955

Epoch: 6| Step: 11
Training loss: 0.10459665954113007
Validation loss: 1.5218420925960745

Epoch: 6| Step: 12
Training loss: 0.20727065205574036
Validation loss: 1.5796439750220186

Epoch: 6| Step: 13
Training loss: 0.056958992034196854
Validation loss: 1.5231167962474208

Epoch: 372| Step: 0
Training loss: 0.12485963106155396
Validation loss: 1.5063724364003828

Epoch: 6| Step: 1
Training loss: 0.13697537779808044
Validation loss: 1.4661907329354236

Epoch: 6| Step: 2
Training loss: 0.07348597049713135
Validation loss: 1.4602484959428028

Epoch: 6| Step: 3
Training loss: 0.09799103438854218
Validation loss: 1.4472450210202126

Epoch: 6| Step: 4
Training loss: 0.17721408605575562
Validation loss: 1.4479584629817674

Epoch: 6| Step: 5
Training loss: 0.1164868026971817
Validation loss: 1.4325331436690463

Epoch: 6| Step: 6
Training loss: 0.1037522405385971
Validation loss: 1.426911198964683

Epoch: 6| Step: 7
Training loss: 0.15690815448760986
Validation loss: 1.4426294629291823

Epoch: 6| Step: 8
Training loss: 0.26958560943603516
Validation loss: 1.453198952059592

Epoch: 6| Step: 9
Training loss: 0.11595909297466278
Validation loss: 1.4427016204403293

Epoch: 6| Step: 10
Training loss: 0.11461062729358673
Validation loss: 1.4708903886938607

Epoch: 6| Step: 11
Training loss: 0.09232905507087708
Validation loss: 1.5212499839003368

Epoch: 6| Step: 12
Training loss: 0.15569446980953217
Validation loss: 1.5449587914251512

Epoch: 6| Step: 13
Training loss: 0.16365814208984375
Validation loss: 1.6096853299807476

Epoch: 373| Step: 0
Training loss: 0.1460285633802414
Validation loss: 1.566511752784893

Epoch: 6| Step: 1
Training loss: 0.13086766004562378
Validation loss: 1.5454287234173025

Epoch: 6| Step: 2
Training loss: 0.13181905448436737
Validation loss: 1.4868905775008663

Epoch: 6| Step: 3
Training loss: 0.10912050306797028
Validation loss: 1.4737343358737167

Epoch: 6| Step: 4
Training loss: 0.25134217739105225
Validation loss: 1.4182302105811335

Epoch: 6| Step: 5
Training loss: 0.1727287471294403
Validation loss: 1.4138616092743412

Epoch: 6| Step: 6
Training loss: 0.08653338998556137
Validation loss: 1.4266613119391984

Epoch: 6| Step: 7
Training loss: 0.1436980664730072
Validation loss: 1.447324824589555

Epoch: 6| Step: 8
Training loss: 0.19111350178718567
Validation loss: 1.4115656204121088

Epoch: 6| Step: 9
Training loss: 0.1778205931186676
Validation loss: 1.4231890170804915

Epoch: 6| Step: 10
Training loss: 0.13153602182865143
Validation loss: 1.393331370046062

Epoch: 6| Step: 11
Training loss: 0.07107570767402649
Validation loss: 1.3799707479374383

Epoch: 6| Step: 12
Training loss: 0.1432262659072876
Validation loss: 1.426200573162366

Epoch: 6| Step: 13
Training loss: 0.06069323793053627
Validation loss: 1.4269362880337624

Epoch: 374| Step: 0
Training loss: 0.11596660315990448
Validation loss: 1.4588133993969168

Epoch: 6| Step: 1
Training loss: 0.2323477864265442
Validation loss: 1.479021687661448

Epoch: 6| Step: 2
Training loss: 0.15130826830863953
Validation loss: 1.4779597995101765

Epoch: 6| Step: 3
Training loss: 0.10631272196769714
Validation loss: 1.4707588252200876

Epoch: 6| Step: 4
Training loss: 0.16179369390010834
Validation loss: 1.5007674347969793

Epoch: 6| Step: 5
Training loss: 0.14503934979438782
Validation loss: 1.4683071682530064

Epoch: 6| Step: 6
Training loss: 0.09083082526922226
Validation loss: 1.4576929762799253

Epoch: 6| Step: 7
Training loss: 0.12468346953392029
Validation loss: 1.4965405874354865

Epoch: 6| Step: 8
Training loss: 0.11293976753950119
Validation loss: 1.4491598401018368

Epoch: 6| Step: 9
Training loss: 0.08317694067955017
Validation loss: 1.4506843654058312

Epoch: 6| Step: 10
Training loss: 0.08469510823488235
Validation loss: 1.415657990722246

Epoch: 6| Step: 11
Training loss: 0.14692378044128418
Validation loss: 1.4081255312888854

Epoch: 6| Step: 12
Training loss: 0.21052032709121704
Validation loss: 1.4111965317879953

Epoch: 6| Step: 13
Training loss: 0.09585808217525482
Validation loss: 1.4417721327914987

Epoch: 375| Step: 0
Training loss: 0.16964516043663025
Validation loss: 1.4120019917847009

Epoch: 6| Step: 1
Training loss: 0.14126627147197723
Validation loss: 1.3591566867725824

Epoch: 6| Step: 2
Training loss: 0.24241848289966583
Validation loss: 1.4111426581618607

Epoch: 6| Step: 3
Training loss: 0.18330715596675873
Validation loss: 1.372128264878386

Epoch: 6| Step: 4
Training loss: 0.18372990190982819
Validation loss: 1.3836778953511228

Epoch: 6| Step: 5
Training loss: 0.0779700055718422
Validation loss: 1.4027241071065266

Epoch: 6| Step: 6
Training loss: 0.14392447471618652
Validation loss: 1.3899718856298795

Epoch: 6| Step: 7
Training loss: 0.13247008621692657
Validation loss: 1.4199722825839955

Epoch: 6| Step: 8
Training loss: 0.22187300026416779
Validation loss: 1.4549326435212167

Epoch: 6| Step: 9
Training loss: 0.10109545290470123
Validation loss: 1.443554594952573

Epoch: 6| Step: 10
Training loss: 0.136153906583786
Validation loss: 1.4635029518476097

Epoch: 6| Step: 11
Training loss: 0.1091795265674591
Validation loss: 1.4620759474333895

Epoch: 6| Step: 12
Training loss: 0.16988439857959747
Validation loss: 1.4902695378949564

Epoch: 6| Step: 13
Training loss: 0.18372341990470886
Validation loss: 1.4620683077842958

Epoch: 376| Step: 0
Training loss: 0.08229929953813553
Validation loss: 1.4525531184288762

Epoch: 6| Step: 1
Training loss: 0.09026619791984558
Validation loss: 1.4176442725684053

Epoch: 6| Step: 2
Training loss: 0.07330276072025299
Validation loss: 1.3841534692754027

Epoch: 6| Step: 3
Training loss: 0.14481835067272186
Validation loss: 1.3891328034862396

Epoch: 6| Step: 4
Training loss: 0.11166848242282867
Validation loss: 1.399932449863803

Epoch: 6| Step: 5
Training loss: 0.25506913661956787
Validation loss: 1.431091457284907

Epoch: 6| Step: 6
Training loss: 0.18262191116809845
Validation loss: 1.412803852429954

Epoch: 6| Step: 7
Training loss: 0.20992442965507507
Validation loss: 1.4064884724155549

Epoch: 6| Step: 8
Training loss: 0.09221472591161728
Validation loss: 1.4150262507059241

Epoch: 6| Step: 9
Training loss: 0.11839593201875687
Validation loss: 1.4275441759376115

Epoch: 6| Step: 10
Training loss: 0.2184629738330841
Validation loss: 1.4693494035351662

Epoch: 6| Step: 11
Training loss: 0.09859436750411987
Validation loss: 1.4700197865886073

Epoch: 6| Step: 12
Training loss: 0.12686777114868164
Validation loss: 1.494173470363822

Epoch: 6| Step: 13
Training loss: 0.13141468167304993
Validation loss: 1.5236484286605672

Epoch: 377| Step: 0
Training loss: 0.14012914896011353
Validation loss: 1.5349574576142013

Epoch: 6| Step: 1
Training loss: 0.1885356307029724
Validation loss: 1.5585527650771602

Epoch: 6| Step: 2
Training loss: 0.181670144200325
Validation loss: 1.4968619596573614

Epoch: 6| Step: 3
Training loss: 0.15945757925510406
Validation loss: 1.4855159187829623

Epoch: 6| Step: 4
Training loss: 0.0996236652135849
Validation loss: 1.485238867421304

Epoch: 6| Step: 5
Training loss: 0.16929934918880463
Validation loss: 1.4680534473029516

Epoch: 6| Step: 6
Training loss: 0.22983884811401367
Validation loss: 1.4705758607515724

Epoch: 6| Step: 7
Training loss: 0.11023473739624023
Validation loss: 1.3734363176489388

Epoch: 6| Step: 8
Training loss: 0.1105160191655159
Validation loss: 1.3985144630555184

Epoch: 6| Step: 9
Training loss: 0.126043900847435
Validation loss: 1.3928965214760072

Epoch: 6| Step: 10
Training loss: 0.16739678382873535
Validation loss: 1.4108138904776624

Epoch: 6| Step: 11
Training loss: 0.15467265248298645
Validation loss: 1.413460426433112

Epoch: 6| Step: 12
Training loss: 0.1511511504650116
Validation loss: 1.412189865625033

Epoch: 6| Step: 13
Training loss: 0.09782971441745758
Validation loss: 1.3915023624256093

Epoch: 378| Step: 0
Training loss: 0.10630834102630615
Validation loss: 1.4185821099947857

Epoch: 6| Step: 1
Training loss: 0.12253139913082123
Validation loss: 1.4573353939158942

Epoch: 6| Step: 2
Training loss: 0.1383899599313736
Validation loss: 1.466147013889846

Epoch: 6| Step: 3
Training loss: 0.14435561001300812
Validation loss: 1.4854761964531356

Epoch: 6| Step: 4
Training loss: 0.10854718089103699
Validation loss: 1.446429911480155

Epoch: 6| Step: 5
Training loss: 0.18240852653980255
Validation loss: 1.4896024222015052

Epoch: 6| Step: 6
Training loss: 0.11605606973171234
Validation loss: 1.5260755195412585

Epoch: 6| Step: 7
Training loss: 0.20788541436195374
Validation loss: 1.5524671308455928

Epoch: 6| Step: 8
Training loss: 0.12786337733268738
Validation loss: 1.497643054172557

Epoch: 6| Step: 9
Training loss: 0.15032804012298584
Validation loss: 1.4989894269615092

Epoch: 6| Step: 10
Training loss: 0.10677807778120041
Validation loss: 1.4923277144790978

Epoch: 6| Step: 11
Training loss: 0.10827568918466568
Validation loss: 1.4864611407761932

Epoch: 6| Step: 12
Training loss: 0.250087708234787
Validation loss: 1.4613437319314608

Epoch: 6| Step: 13
Training loss: 0.0824110135436058
Validation loss: 1.4384327588542816

Epoch: 379| Step: 0
Training loss: 0.15232692658901215
Validation loss: 1.4334232102158249

Epoch: 6| Step: 1
Training loss: 0.10117420554161072
Validation loss: 1.4291560079461785

Epoch: 6| Step: 2
Training loss: 0.11023128032684326
Validation loss: 1.4469912987883373

Epoch: 6| Step: 3
Training loss: 0.11564688384532928
Validation loss: 1.4286289881634455

Epoch: 6| Step: 4
Training loss: 0.11062490940093994
Validation loss: 1.42659624930351

Epoch: 6| Step: 5
Training loss: 0.13690249621868134
Validation loss: 1.44975741704305

Epoch: 6| Step: 6
Training loss: 0.08655420690774918
Validation loss: 1.4568699303493704

Epoch: 6| Step: 7
Training loss: 0.0660691112279892
Validation loss: 1.455825791564039

Epoch: 6| Step: 8
Training loss: 0.16622307896614075
Validation loss: 1.4757730794209305

Epoch: 6| Step: 9
Training loss: 0.1574959009885788
Validation loss: 1.4767648814826884

Epoch: 6| Step: 10
Training loss: 0.10509255528450012
Validation loss: 1.4740333698129142

Epoch: 6| Step: 11
Training loss: 0.22851672768592834
Validation loss: 1.4634047503112464

Epoch: 6| Step: 12
Training loss: 0.05819159746170044
Validation loss: 1.4579874187387445

Epoch: 6| Step: 13
Training loss: 0.12135262042284012
Validation loss: 1.4147393908551944

Epoch: 380| Step: 0
Training loss: 0.07542995363473892
Validation loss: 1.3984831507487963

Epoch: 6| Step: 1
Training loss: 0.12489111721515656
Validation loss: 1.4454496035011866

Epoch: 6| Step: 2
Training loss: 0.1083306223154068
Validation loss: 1.414599057166807

Epoch: 6| Step: 3
Training loss: 0.08798547089099884
Validation loss: 1.401843181220434

Epoch: 6| Step: 4
Training loss: 0.09489259123802185
Validation loss: 1.4057659141479

Epoch: 6| Step: 5
Training loss: 0.14811380207538605
Validation loss: 1.3956182464476554

Epoch: 6| Step: 6
Training loss: 0.08531737327575684
Validation loss: 1.3778693288244226

Epoch: 6| Step: 7
Training loss: 0.10109922289848328
Validation loss: 1.4380156006864322

Epoch: 6| Step: 8
Training loss: 0.18030226230621338
Validation loss: 1.4566668195109214

Epoch: 6| Step: 9
Training loss: 0.12420857697725296
Validation loss: 1.4450435920428204

Epoch: 6| Step: 10
Training loss: 0.10778564214706421
Validation loss: 1.4430368459352882

Epoch: 6| Step: 11
Training loss: 0.15203210711479187
Validation loss: 1.4603830473397368

Epoch: 6| Step: 12
Training loss: 0.2657017111778259
Validation loss: 1.421390296310507

Epoch: 6| Step: 13
Training loss: 0.19278353452682495
Validation loss: 1.428107480848989

Epoch: 381| Step: 0
Training loss: 0.07806594669818878
Validation loss: 1.4319828684611986

Epoch: 6| Step: 1
Training loss: 0.0863836258649826
Validation loss: 1.434580006907063

Epoch: 6| Step: 2
Training loss: 0.09785350412130356
Validation loss: 1.4474992828984414

Epoch: 6| Step: 3
Training loss: 0.19436104595661163
Validation loss: 1.4367815435573619

Epoch: 6| Step: 4
Training loss: 0.16814690828323364
Validation loss: 1.4279762839758268

Epoch: 6| Step: 5
Training loss: 0.25036120414733887
Validation loss: 1.4159346947105982

Epoch: 6| Step: 6
Training loss: 0.12063851952552795
Validation loss: 1.4356807105002864

Epoch: 6| Step: 7
Training loss: 0.15807610750198364
Validation loss: 1.4663322676894486

Epoch: 6| Step: 8
Training loss: 0.084483802318573
Validation loss: 1.4510127780258015

Epoch: 6| Step: 9
Training loss: 0.1442880779504776
Validation loss: 1.465933415197557

Epoch: 6| Step: 10
Training loss: 0.1162763312458992
Validation loss: 1.478507807177882

Epoch: 6| Step: 11
Training loss: 0.13237464427947998
Validation loss: 1.4764387133300945

Epoch: 6| Step: 12
Training loss: 0.16880246996879578
Validation loss: 1.476667490056766

Epoch: 6| Step: 13
Training loss: 0.19860483705997467
Validation loss: 1.4798800022371355

Epoch: 382| Step: 0
Training loss: 0.207398921251297
Validation loss: 1.4904351721527755

Epoch: 6| Step: 1
Training loss: 0.16223004460334778
Validation loss: 1.468310442022098

Epoch: 6| Step: 2
Training loss: 0.07578419148921967
Validation loss: 1.4436429456997943

Epoch: 6| Step: 3
Training loss: 0.3385438621044159
Validation loss: 1.4790855787133659

Epoch: 6| Step: 4
Training loss: 0.10229397565126419
Validation loss: 1.4558674763607722

Epoch: 6| Step: 5
Training loss: 0.15225264430046082
Validation loss: 1.4553970995769705

Epoch: 6| Step: 6
Training loss: 0.15322044491767883
Validation loss: 1.431008195364347

Epoch: 6| Step: 7
Training loss: 0.08276256173849106
Validation loss: 1.4446223243590324

Epoch: 6| Step: 8
Training loss: 0.08440034091472626
Validation loss: 1.475725063713648

Epoch: 6| Step: 9
Training loss: 0.10098949074745178
Validation loss: 1.45708817051303

Epoch: 6| Step: 10
Training loss: 0.09239352494478226
Validation loss: 1.4746181144509265

Epoch: 6| Step: 11
Training loss: 0.08120550215244293
Validation loss: 1.497322771497952

Epoch: 6| Step: 12
Training loss: 0.08290500193834305
Validation loss: 1.5000091675789125

Epoch: 6| Step: 13
Training loss: 0.1175076961517334
Validation loss: 1.529352859784198

Epoch: 383| Step: 0
Training loss: 0.2004033327102661
Validation loss: 1.5568638437537736

Epoch: 6| Step: 1
Training loss: 0.14639128744602203
Validation loss: 1.5318149623050485

Epoch: 6| Step: 2
Training loss: 0.21186962723731995
Validation loss: 1.5297336886006017

Epoch: 6| Step: 3
Training loss: 0.12997521460056305
Validation loss: 1.469681429606612

Epoch: 6| Step: 4
Training loss: 0.11147038638591766
Validation loss: 1.4400459797151628

Epoch: 6| Step: 5
Training loss: 0.13964641094207764
Validation loss: 1.428356912828261

Epoch: 6| Step: 6
Training loss: 0.07702544331550598
Validation loss: 1.4124412818621563

Epoch: 6| Step: 7
Training loss: 0.07709123194217682
Validation loss: 1.3994567900575616

Epoch: 6| Step: 8
Training loss: 0.06319974362850189
Validation loss: 1.419872965863956

Epoch: 6| Step: 9
Training loss: 0.10761977732181549
Validation loss: 1.3804060887264948

Epoch: 6| Step: 10
Training loss: 0.1831672638654709
Validation loss: 1.420202769258971

Epoch: 6| Step: 11
Training loss: 0.08453935384750366
Validation loss: 1.4060548902839742

Epoch: 6| Step: 12
Training loss: 0.08574961125850677
Validation loss: 1.4406259136815225

Epoch: 6| Step: 13
Training loss: 0.1314120888710022
Validation loss: 1.403466551214136

Epoch: 384| Step: 0
Training loss: 0.110542893409729
Validation loss: 1.4183120253265544

Epoch: 6| Step: 1
Training loss: 0.14844468235969543
Validation loss: 1.4365159314806744

Epoch: 6| Step: 2
Training loss: 0.11539767682552338
Validation loss: 1.4749899577069026

Epoch: 6| Step: 3
Training loss: 0.10478433966636658
Validation loss: 1.5071510268795876

Epoch: 6| Step: 4
Training loss: 0.09553565084934235
Validation loss: 1.5235965751832532

Epoch: 6| Step: 5
Training loss: 0.11175548285245895
Validation loss: 1.5162476993376208

Epoch: 6| Step: 6
Training loss: 0.14465433359146118
Validation loss: 1.4788542947461527

Epoch: 6| Step: 7
Training loss: 0.11087140440940857
Validation loss: 1.478818448640967

Epoch: 6| Step: 8
Training loss: 0.17257791757583618
Validation loss: 1.4814005692799885

Epoch: 6| Step: 9
Training loss: 0.09448082000017166
Validation loss: 1.5064413406515633

Epoch: 6| Step: 10
Training loss: 0.304826557636261
Validation loss: 1.4898388129408642

Epoch: 6| Step: 11
Training loss: 0.17181579768657684
Validation loss: 1.4798713422590686

Epoch: 6| Step: 12
Training loss: 0.0799436867237091
Validation loss: 1.475704502033931

Epoch: 6| Step: 13
Training loss: 0.15835988521575928
Validation loss: 1.465755497255633

Epoch: 385| Step: 0
Training loss: 0.1340855211019516
Validation loss: 1.4223426465065248

Epoch: 6| Step: 1
Training loss: 0.1407964676618576
Validation loss: 1.4349497095231087

Epoch: 6| Step: 2
Training loss: 0.25547704100608826
Validation loss: 1.4173017535158383

Epoch: 6| Step: 3
Training loss: 0.07372985780239105
Validation loss: 1.4159973885423394

Epoch: 6| Step: 4
Training loss: 0.1979626715183258
Validation loss: 1.3952728714994205

Epoch: 6| Step: 5
Training loss: 0.24566882848739624
Validation loss: 1.374047552385638

Epoch: 6| Step: 6
Training loss: 0.1175912618637085
Validation loss: 1.4051423175360567

Epoch: 6| Step: 7
Training loss: 0.07131493836641312
Validation loss: 1.4087495752560195

Epoch: 6| Step: 8
Training loss: 0.09521905332803726
Validation loss: 1.446531234248992

Epoch: 6| Step: 9
Training loss: 0.09377416223287582
Validation loss: 1.4948723559738488

Epoch: 6| Step: 10
Training loss: 0.17338448762893677
Validation loss: 1.5706367749039845

Epoch: 6| Step: 11
Training loss: 0.21067240834236145
Validation loss: 1.576195910412778

Epoch: 6| Step: 12
Training loss: 0.18286295235157013
Validation loss: 1.6144158083905455

Epoch: 6| Step: 13
Training loss: 0.597663402557373
Validation loss: 1.5840909455412178

Epoch: 386| Step: 0
Training loss: 0.19368526339530945
Validation loss: 1.570958105466699

Epoch: 6| Step: 1
Training loss: 0.1766068935394287
Validation loss: 1.5180569643615394

Epoch: 6| Step: 2
Training loss: 0.1263713836669922
Validation loss: 1.481479630675367

Epoch: 6| Step: 3
Training loss: 0.10581012815237045
Validation loss: 1.455682268065791

Epoch: 6| Step: 4
Training loss: 0.14534533023834229
Validation loss: 1.4331128110167801

Epoch: 6| Step: 5
Training loss: 0.13489271700382233
Validation loss: 1.4454369416800879

Epoch: 6| Step: 6
Training loss: 0.14321169257164001
Validation loss: 1.455621890483364

Epoch: 6| Step: 7
Training loss: 0.10270663350820541
Validation loss: 1.4278984608188752

Epoch: 6| Step: 8
Training loss: 0.11566120386123657
Validation loss: 1.4285784370155745

Epoch: 6| Step: 9
Training loss: 0.10155008733272552
Validation loss: 1.4450208448594617

Epoch: 6| Step: 10
Training loss: 0.10892312973737717
Validation loss: 1.4485255210630354

Epoch: 6| Step: 11
Training loss: 0.13096202909946442
Validation loss: 1.4287090032331404

Epoch: 6| Step: 12
Training loss: 0.2269309163093567
Validation loss: 1.4271839946828864

Epoch: 6| Step: 13
Training loss: 0.19064122438430786
Validation loss: 1.4273660439316944

Epoch: 387| Step: 0
Training loss: 0.08584173023700714
Validation loss: 1.4190294434947353

Epoch: 6| Step: 1
Training loss: 0.127202570438385
Validation loss: 1.430308384280051

Epoch: 6| Step: 2
Training loss: 0.1567678600549698
Validation loss: 1.4587191945763045

Epoch: 6| Step: 3
Training loss: 0.1742497682571411
Validation loss: 1.4561848896805958

Epoch: 6| Step: 4
Training loss: 0.12293029576539993
Validation loss: 1.4653781934451031

Epoch: 6| Step: 5
Training loss: 0.18672622740268707
Validation loss: 1.4729049295507453

Epoch: 6| Step: 6
Training loss: 0.12710145115852356
Validation loss: 1.46352046151315

Epoch: 6| Step: 7
Training loss: 0.2985897660255432
Validation loss: 1.456584418973615

Epoch: 6| Step: 8
Training loss: 0.13197937607765198
Validation loss: 1.431800611557499

Epoch: 6| Step: 9
Training loss: 0.12152394652366638
Validation loss: 1.4137996678711267

Epoch: 6| Step: 10
Training loss: 0.08462387323379517
Validation loss: 1.3823812507813977

Epoch: 6| Step: 11
Training loss: 0.12836338579654694
Validation loss: 1.3698373276700255

Epoch: 6| Step: 12
Training loss: 0.20215697586536407
Validation loss: 1.392495527062365

Epoch: 6| Step: 13
Training loss: 0.1355636715888977
Validation loss: 1.3833671718515375

Epoch: 388| Step: 0
Training loss: 0.15090930461883545
Validation loss: 1.3820293039403937

Epoch: 6| Step: 1
Training loss: 0.07683512568473816
Validation loss: 1.366554529436173

Epoch: 6| Step: 2
Training loss: 0.11978253722190857
Validation loss: 1.3949183276904527

Epoch: 6| Step: 3
Training loss: 0.12600596249103546
Validation loss: 1.397053885203536

Epoch: 6| Step: 4
Training loss: 0.09946805238723755
Validation loss: 1.3783958586313392

Epoch: 6| Step: 5
Training loss: 0.21456210315227509
Validation loss: 1.386092137264949

Epoch: 6| Step: 6
Training loss: 0.07215238362550735
Validation loss: 1.4078185404500654

Epoch: 6| Step: 7
Training loss: 0.12101498991250992
Validation loss: 1.4515561365312146

Epoch: 6| Step: 8
Training loss: 0.18699543178081512
Validation loss: 1.4342420325484326

Epoch: 6| Step: 9
Training loss: 0.11842253804206848
Validation loss: 1.4678687382769842

Epoch: 6| Step: 10
Training loss: 0.17490363121032715
Validation loss: 1.5226685565005067

Epoch: 6| Step: 11
Training loss: 0.09306081384420395
Validation loss: 1.5253659063769924

Epoch: 6| Step: 12
Training loss: 0.09846831858158112
Validation loss: 1.5068185944711008

Epoch: 6| Step: 13
Training loss: 0.13953927159309387
Validation loss: 1.5169699858593684

Epoch: 389| Step: 0
Training loss: 0.19076669216156006
Validation loss: 1.4904600804851902

Epoch: 6| Step: 1
Training loss: 0.09789064526557922
Validation loss: 1.4788934569205008

Epoch: 6| Step: 2
Training loss: 0.16837891936302185
Validation loss: 1.4929795880471506

Epoch: 6| Step: 3
Training loss: 0.1110190749168396
Validation loss: 1.4868427758575768

Epoch: 6| Step: 4
Training loss: 0.12154266238212585
Validation loss: 1.4708275384800409

Epoch: 6| Step: 5
Training loss: 0.21314245462417603
Validation loss: 1.4732691498212918

Epoch: 6| Step: 6
Training loss: 0.152304008603096
Validation loss: 1.471515247898717

Epoch: 6| Step: 7
Training loss: 0.12426050752401352
Validation loss: 1.4721138836235128

Epoch: 6| Step: 8
Training loss: 0.15249696373939514
Validation loss: 1.467755611224841

Epoch: 6| Step: 9
Training loss: 0.13859923183918
Validation loss: 1.4533462248822695

Epoch: 6| Step: 10
Training loss: 0.08767668902873993
Validation loss: 1.4473168593581005

Epoch: 6| Step: 11
Training loss: 0.10803011059761047
Validation loss: 1.4544787637649044

Epoch: 6| Step: 12
Training loss: 0.1556670069694519
Validation loss: 1.4546509827336958

Epoch: 6| Step: 13
Training loss: 0.16258767247200012
Validation loss: 1.482726118897879

Epoch: 390| Step: 0
Training loss: 0.19090282917022705
Validation loss: 1.5199761480413458

Epoch: 6| Step: 1
Training loss: 0.2317640632390976
Validation loss: 1.5235511609303054

Epoch: 6| Step: 2
Training loss: 0.16855235397815704
Validation loss: 1.529425444141511

Epoch: 6| Step: 3
Training loss: 0.13963274657726288
Validation loss: 1.5217353195272467

Epoch: 6| Step: 4
Training loss: 0.10523588955402374
Validation loss: 1.5153169132048083

Epoch: 6| Step: 5
Training loss: 0.10676989704370499
Validation loss: 1.5093524545751593

Epoch: 6| Step: 6
Training loss: 0.11815378814935684
Validation loss: 1.4926784788408587

Epoch: 6| Step: 7
Training loss: 0.1386919766664505
Validation loss: 1.4711183796646774

Epoch: 6| Step: 8
Training loss: 0.18398401141166687
Validation loss: 1.483815498249505

Epoch: 6| Step: 9
Training loss: 0.12174728512763977
Validation loss: 1.4537728345522316

Epoch: 6| Step: 10
Training loss: 0.05306682735681534
Validation loss: 1.4737344775148618

Epoch: 6| Step: 11
Training loss: 0.08020159602165222
Validation loss: 1.4296402988895294

Epoch: 6| Step: 12
Training loss: 0.19327983260154724
Validation loss: 1.4328393372156287

Epoch: 6| Step: 13
Training loss: 0.1075492724776268
Validation loss: 1.4591341121222383

Epoch: 391| Step: 0
Training loss: 0.24015098810195923
Validation loss: 1.4495568506179317

Epoch: 6| Step: 1
Training loss: 0.10811632871627808
Validation loss: 1.4495242270090247

Epoch: 6| Step: 2
Training loss: 0.16489887237548828
Validation loss: 1.4672190604671356

Epoch: 6| Step: 3
Training loss: 0.07629223167896271
Validation loss: 1.463269014512339

Epoch: 6| Step: 4
Training loss: 0.13844972848892212
Validation loss: 1.4705667854637228

Epoch: 6| Step: 5
Training loss: 0.1566115915775299
Validation loss: 1.4601498047510784

Epoch: 6| Step: 6
Training loss: 0.133255735039711
Validation loss: 1.4616152432657057

Epoch: 6| Step: 7
Training loss: 0.1266341507434845
Validation loss: 1.4496879334090857

Epoch: 6| Step: 8
Training loss: 0.10301659256219864
Validation loss: 1.4483969749942902

Epoch: 6| Step: 9
Training loss: 0.07308436185121536
Validation loss: 1.439175384019011

Epoch: 6| Step: 10
Training loss: 0.16176706552505493
Validation loss: 1.4642257036701325

Epoch: 6| Step: 11
Training loss: 0.10937914252281189
Validation loss: 1.5016294922879947

Epoch: 6| Step: 12
Training loss: 0.12886479496955872
Validation loss: 1.4971979113035305

Epoch: 6| Step: 13
Training loss: 0.12270624190568924
Validation loss: 1.4898447067506853

Epoch: 392| Step: 0
Training loss: 0.15145039558410645
Validation loss: 1.5403600296666544

Epoch: 6| Step: 1
Training loss: 0.12961849570274353
Validation loss: 1.568613088259133

Epoch: 6| Step: 2
Training loss: 0.13068847358226776
Validation loss: 1.5580079722148117

Epoch: 6| Step: 3
Training loss: 0.22415468096733093
Validation loss: 1.5479430742161249

Epoch: 6| Step: 4
Training loss: 0.1135392040014267
Validation loss: 1.5606443689715477

Epoch: 6| Step: 5
Training loss: 0.07075293362140656
Validation loss: 1.5219004397751184

Epoch: 6| Step: 6
Training loss: 0.10597453266382217
Validation loss: 1.4880238425347112

Epoch: 6| Step: 7
Training loss: 0.13819919526576996
Validation loss: 1.475717129245881

Epoch: 6| Step: 8
Training loss: 0.14555230736732483
Validation loss: 1.4587546740808794

Epoch: 6| Step: 9
Training loss: 0.12150725722312927
Validation loss: 1.4590633312861125

Epoch: 6| Step: 10
Training loss: 0.07677668333053589
Validation loss: 1.480529163473396

Epoch: 6| Step: 11
Training loss: 0.20166335999965668
Validation loss: 1.4745240531941897

Epoch: 6| Step: 12
Training loss: 0.13211625814437866
Validation loss: 1.44718901829053

Epoch: 6| Step: 13
Training loss: 0.12891575694084167
Validation loss: 1.478326492412116

Epoch: 393| Step: 0
Training loss: 0.2358742356300354
Validation loss: 1.4683817471227338

Epoch: 6| Step: 1
Training loss: 0.18458139896392822
Validation loss: 1.4492400871810092

Epoch: 6| Step: 2
Training loss: 0.1199314072728157
Validation loss: 1.4397359022530176

Epoch: 6| Step: 3
Training loss: 0.11752118170261383
Validation loss: 1.4760582908507316

Epoch: 6| Step: 4
Training loss: 0.12438129633665085
Validation loss: 1.4363565643628438

Epoch: 6| Step: 5
Training loss: 0.08421213924884796
Validation loss: 1.4399368583515126

Epoch: 6| Step: 6
Training loss: 0.1060117706656456
Validation loss: 1.4711817701657612

Epoch: 6| Step: 7
Training loss: 0.07669223845005035
Validation loss: 1.4551455769487607

Epoch: 6| Step: 8
Training loss: 0.1060284823179245
Validation loss: 1.493883402116837

Epoch: 6| Step: 9
Training loss: 0.13954585790634155
Validation loss: 1.4878142905491654

Epoch: 6| Step: 10
Training loss: 0.07388299703598022
Validation loss: 1.492584897625831

Epoch: 6| Step: 11
Training loss: 0.12272508442401886
Validation loss: 1.5115875364631735

Epoch: 6| Step: 12
Training loss: 0.13728764653205872
Validation loss: 1.485705380798668

Epoch: 6| Step: 13
Training loss: 0.04737807810306549
Validation loss: 1.5141646336483698

Epoch: 394| Step: 0
Training loss: 0.09133125841617584
Validation loss: 1.4925741828897947

Epoch: 6| Step: 1
Training loss: 0.11347297579050064
Validation loss: 1.4955812295277913

Epoch: 6| Step: 2
Training loss: 0.1585128754377365
Validation loss: 1.484330492634927

Epoch: 6| Step: 3
Training loss: 0.09256158769130707
Validation loss: 1.476862274190431

Epoch: 6| Step: 4
Training loss: 0.0901188999414444
Validation loss: 1.4770350340873963

Epoch: 6| Step: 5
Training loss: 0.09886088967323303
Validation loss: 1.4837037581269459

Epoch: 6| Step: 6
Training loss: 0.12025640159845352
Validation loss: 1.495773692284861

Epoch: 6| Step: 7
Training loss: 0.12324618548154831
Validation loss: 1.4906530700704104

Epoch: 6| Step: 8
Training loss: 0.09371317923069
Validation loss: 1.4907406940255115

Epoch: 6| Step: 9
Training loss: 0.08918720483779907
Validation loss: 1.5115799775687597

Epoch: 6| Step: 10
Training loss: 0.1812276691198349
Validation loss: 1.4967000740830616

Epoch: 6| Step: 11
Training loss: 0.15695251524448395
Validation loss: 1.5030263649520053

Epoch: 6| Step: 12
Training loss: 0.19526885449886322
Validation loss: 1.5100667938109367

Epoch: 6| Step: 13
Training loss: 0.09071846306324005
Validation loss: 1.4939523710999438

Epoch: 395| Step: 0
Training loss: 0.17759236693382263
Validation loss: 1.519538265402599

Epoch: 6| Step: 1
Training loss: 0.09831328690052032
Validation loss: 1.498219004241369

Epoch: 6| Step: 2
Training loss: 0.1250520795583725
Validation loss: 1.4890065936632053

Epoch: 6| Step: 3
Training loss: 0.15787142515182495
Validation loss: 1.5115850587044992

Epoch: 6| Step: 4
Training loss: 0.1067356988787651
Validation loss: 1.4621966910618607

Epoch: 6| Step: 5
Training loss: 0.12008820474147797
Validation loss: 1.479181476818618

Epoch: 6| Step: 6
Training loss: 0.10505633056163788
Validation loss: 1.4516673831529514

Epoch: 6| Step: 7
Training loss: 0.10222825407981873
Validation loss: 1.443112459234012

Epoch: 6| Step: 8
Training loss: 0.16009996831417084
Validation loss: 1.433779692137113

Epoch: 6| Step: 9
Training loss: 0.10875461250543594
Validation loss: 1.4635978860239829

Epoch: 6| Step: 10
Training loss: 0.07143905013799667
Validation loss: 1.4955557277125697

Epoch: 6| Step: 11
Training loss: 0.05803447961807251
Validation loss: 1.5110810059373097

Epoch: 6| Step: 12
Training loss: 0.10151046514511108
Validation loss: 1.5061382619283532

Epoch: 6| Step: 13
Training loss: 0.13245756924152374
Validation loss: 1.5027491174718386

Epoch: 396| Step: 0
Training loss: 0.1761467158794403
Validation loss: 1.4916110115666543

Epoch: 6| Step: 1
Training loss: 0.06671538949012756
Validation loss: 1.5208939442070581

Epoch: 6| Step: 2
Training loss: 0.09738998115062714
Validation loss: 1.4818484411444715

Epoch: 6| Step: 3
Training loss: 0.09203244745731354
Validation loss: 1.5196474521390853

Epoch: 6| Step: 4
Training loss: 0.14698350429534912
Validation loss: 1.4837879186035485

Epoch: 6| Step: 5
Training loss: 0.07215454429388046
Validation loss: 1.4944612864525086

Epoch: 6| Step: 6
Training loss: 0.07929359376430511
Validation loss: 1.468652025345833

Epoch: 6| Step: 7
Training loss: 0.10310227423906326
Validation loss: 1.4809667961571806

Epoch: 6| Step: 8
Training loss: 0.1099795252084732
Validation loss: 1.4700397624764392

Epoch: 6| Step: 9
Training loss: 0.15783795714378357
Validation loss: 1.5046753550088534

Epoch: 6| Step: 10
Training loss: 0.09985180199146271
Validation loss: 1.4926459994367374

Epoch: 6| Step: 11
Training loss: 0.14184023439884186
Validation loss: 1.4650321673321467

Epoch: 6| Step: 12
Training loss: 0.11963013559579849
Validation loss: 1.4704861974203458

Epoch: 6| Step: 13
Training loss: 0.07125315070152283
Validation loss: 1.4591635363076323

Epoch: 397| Step: 0
Training loss: 0.09134429693222046
Validation loss: 1.4491908319534794

Epoch: 6| Step: 1
Training loss: 0.05873905494809151
Validation loss: 1.453452153872418

Epoch: 6| Step: 2
Training loss: 0.06626500189304352
Validation loss: 1.449171922540152

Epoch: 6| Step: 3
Training loss: 0.14293289184570312
Validation loss: 1.4407865296127975

Epoch: 6| Step: 4
Training loss: 0.05776923894882202
Validation loss: 1.4452646688748432

Epoch: 6| Step: 5
Training loss: 0.17850445210933685
Validation loss: 1.4239474573443014

Epoch: 6| Step: 6
Training loss: 0.11922303587198257
Validation loss: 1.4586213839951383

Epoch: 6| Step: 7
Training loss: 0.08692248165607452
Validation loss: 1.4662278877791537

Epoch: 6| Step: 8
Training loss: 0.0687033087015152
Validation loss: 1.4431109236132713

Epoch: 6| Step: 9
Training loss: 0.08697320520877838
Validation loss: 1.488663891310333

Epoch: 6| Step: 10
Training loss: 0.09250794351100922
Validation loss: 1.4627667947482037

Epoch: 6| Step: 11
Training loss: 0.09610430151224136
Validation loss: 1.5389026377790718

Epoch: 6| Step: 12
Training loss: 0.10802868753671646
Validation loss: 1.5089201927185059

Epoch: 6| Step: 13
Training loss: 0.1365957260131836
Validation loss: 1.5360301643289545

Epoch: 398| Step: 0
Training loss: 0.12405186891555786
Validation loss: 1.5418129069830782

Epoch: 6| Step: 1
Training loss: 0.10293208807706833
Validation loss: 1.537562765100951

Epoch: 6| Step: 2
Training loss: 0.11673993617296219
Validation loss: 1.5045872247347267

Epoch: 6| Step: 3
Training loss: 0.14196664094924927
Validation loss: 1.490301437275384

Epoch: 6| Step: 4
Training loss: 0.22108407318592072
Validation loss: 1.4492622267815374

Epoch: 6| Step: 5
Training loss: 0.1665620505809784
Validation loss: 1.428414039714362

Epoch: 6| Step: 6
Training loss: 0.1893138587474823
Validation loss: 1.4319152934576875

Epoch: 6| Step: 7
Training loss: 0.15794213116168976
Validation loss: 1.4095844594381188

Epoch: 6| Step: 8
Training loss: 0.12038655579090118
Validation loss: 1.4273556381143548

Epoch: 6| Step: 9
Training loss: 0.12601128220558167
Validation loss: 1.4111236051846576

Epoch: 6| Step: 10
Training loss: 0.11551631987094879
Validation loss: 1.4059362488408242

Epoch: 6| Step: 11
Training loss: 0.08098872005939484
Validation loss: 1.3982151733931674

Epoch: 6| Step: 12
Training loss: 0.1276414841413498
Validation loss: 1.440310328237472

Epoch: 6| Step: 13
Training loss: 0.06395622342824936
Validation loss: 1.4442031832151516

Epoch: 399| Step: 0
Training loss: 0.12035363912582397
Validation loss: 1.444896569816015

Epoch: 6| Step: 1
Training loss: 0.16915945708751678
Validation loss: 1.445784576477543

Epoch: 6| Step: 2
Training loss: 0.15137770771980286
Validation loss: 1.4874464452907603

Epoch: 6| Step: 3
Training loss: 0.14872336387634277
Validation loss: 1.5144134157447404

Epoch: 6| Step: 4
Training loss: 0.23933197557926178
Validation loss: 1.495301237670324

Epoch: 6| Step: 5
Training loss: 0.12177948653697968
Validation loss: 1.4299117339554654

Epoch: 6| Step: 6
Training loss: 0.07337586581707001
Validation loss: 1.4326346048744776

Epoch: 6| Step: 7
Training loss: 0.08821827173233032
Validation loss: 1.4331433350040066

Epoch: 6| Step: 8
Training loss: 0.10413284599781036
Validation loss: 1.4174049977333314

Epoch: 6| Step: 9
Training loss: 0.09825564175844193
Validation loss: 1.416121789204177

Epoch: 6| Step: 10
Training loss: 0.08544540405273438
Validation loss: 1.3939751425097067

Epoch: 6| Step: 11
Training loss: 0.13782180845737457
Validation loss: 1.4657953048265109

Epoch: 6| Step: 12
Training loss: 0.17395877838134766
Validation loss: 1.4301039634212371

Epoch: 6| Step: 13
Training loss: 0.12095002084970474
Validation loss: 1.475457186340004

Epoch: 400| Step: 0
Training loss: 0.09826524555683136
Validation loss: 1.4762232393346808

Epoch: 6| Step: 1
Training loss: 0.1071086972951889
Validation loss: 1.4885829866573375

Epoch: 6| Step: 2
Training loss: 0.07770392298698425
Validation loss: 1.4970005532746673

Epoch: 6| Step: 3
Training loss: 0.11217228323221207
Validation loss: 1.536660768652475

Epoch: 6| Step: 4
Training loss: 0.12856867909431458
Validation loss: 1.5608076023799118

Epoch: 6| Step: 5
Training loss: 0.18086880445480347
Validation loss: 1.5756365817080262

Epoch: 6| Step: 6
Training loss: 0.09420932829380035
Validation loss: 1.5765297592327159

Epoch: 6| Step: 7
Training loss: 0.13215741515159607
Validation loss: 1.555750064311489

Epoch: 6| Step: 8
Training loss: 0.1132451742887497
Validation loss: 1.5852451132189842

Epoch: 6| Step: 9
Training loss: 0.10188936442136765
Validation loss: 1.584800035722794

Epoch: 6| Step: 10
Training loss: 0.23217545449733734
Validation loss: 1.5397609421001968

Epoch: 6| Step: 11
Training loss: 0.13979682326316833
Validation loss: 1.532434344291687

Epoch: 6| Step: 12
Training loss: 0.09368975460529327
Validation loss: 1.5118270817623343

Epoch: 6| Step: 13
Training loss: 0.15314830839633942
Validation loss: 1.5093729854911886

Epoch: 401| Step: 0
Training loss: 0.2009112536907196
Validation loss: 1.5308213874857912

Epoch: 6| Step: 1
Training loss: 0.14782150089740753
Validation loss: 1.516875647729443

Epoch: 6| Step: 2
Training loss: 0.16512468457221985
Validation loss: 1.525653104628286

Epoch: 6| Step: 3
Training loss: 0.14776647090911865
Validation loss: 1.5361321331352316

Epoch: 6| Step: 4
Training loss: 0.1837618350982666
Validation loss: 1.5061192743239864

Epoch: 6| Step: 5
Training loss: 0.12138579040765762
Validation loss: 1.500105373321041

Epoch: 6| Step: 6
Training loss: 0.12842650711536407
Validation loss: 1.4753864247311828

Epoch: 6| Step: 7
Training loss: 0.11582611501216888
Validation loss: 1.4279149655372865

Epoch: 6| Step: 8
Training loss: 0.08767339587211609
Validation loss: 1.4357906413334671

Epoch: 6| Step: 9
Training loss: 0.108676016330719
Validation loss: 1.4296823470823226

Epoch: 6| Step: 10
Training loss: 0.09460947662591934
Validation loss: 1.3915103481661888

Epoch: 6| Step: 11
Training loss: 0.16370460391044617
Validation loss: 1.4297825533856627

Epoch: 6| Step: 12
Training loss: 0.11205127090215683
Validation loss: 1.3972311801807855

Epoch: 6| Step: 13
Training loss: 0.058767396956682205
Validation loss: 1.3854439976394817

Epoch: 402| Step: 0
Training loss: 0.119089275598526
Validation loss: 1.4378381031815723

Epoch: 6| Step: 1
Training loss: 0.09790836274623871
Validation loss: 1.4186007220257995

Epoch: 6| Step: 2
Training loss: 0.10101266205310822
Validation loss: 1.4327611961672384

Epoch: 6| Step: 3
Training loss: 0.08635883033275604
Validation loss: 1.4833088228779454

Epoch: 6| Step: 4
Training loss: 0.1750737428665161
Validation loss: 1.4306424657503765

Epoch: 6| Step: 5
Training loss: 0.17317607998847961
Validation loss: 1.4355021061435822

Epoch: 6| Step: 6
Training loss: 0.1533333659172058
Validation loss: 1.459258443565779

Epoch: 6| Step: 7
Training loss: 0.10296182334423065
Validation loss: 1.4642130815854637

Epoch: 6| Step: 8
Training loss: 0.12963736057281494
Validation loss: 1.4588594462281914

Epoch: 6| Step: 9
Training loss: 0.123538076877594
Validation loss: 1.4448572102413382

Epoch: 6| Step: 10
Training loss: 0.08993212133646011
Validation loss: 1.4537985299223213

Epoch: 6| Step: 11
Training loss: 0.07419990003108978
Validation loss: 1.4386336149707917

Epoch: 6| Step: 12
Training loss: 0.06776434183120728
Validation loss: 1.431272607336762

Epoch: 6| Step: 13
Training loss: 0.21491853892803192
Validation loss: 1.45391494740722

Epoch: 403| Step: 0
Training loss: 0.07087413966655731
Validation loss: 1.4432274430028853

Epoch: 6| Step: 1
Training loss: 0.09229952096939087
Validation loss: 1.4560411796774915

Epoch: 6| Step: 2
Training loss: 0.10781330615282059
Validation loss: 1.452984800902746

Epoch: 6| Step: 3
Training loss: 0.10279065370559692
Validation loss: 1.4520730459561912

Epoch: 6| Step: 4
Training loss: 0.07476221024990082
Validation loss: 1.4740361654630272

Epoch: 6| Step: 5
Training loss: 0.15912652015686035
Validation loss: 1.4793541610881846

Epoch: 6| Step: 6
Training loss: 0.07781617343425751
Validation loss: 1.4340580201918078

Epoch: 6| Step: 7
Training loss: 0.17313286662101746
Validation loss: 1.4476191189981276

Epoch: 6| Step: 8
Training loss: 0.1127222403883934
Validation loss: 1.505047986584325

Epoch: 6| Step: 9
Training loss: 0.08183640241622925
Validation loss: 1.4503061873938448

Epoch: 6| Step: 10
Training loss: 0.08451788127422333
Validation loss: 1.4630971390713927

Epoch: 6| Step: 11
Training loss: 0.08261945843696594
Validation loss: 1.457243375880744

Epoch: 6| Step: 12
Training loss: 0.07236388325691223
Validation loss: 1.4271552357622372

Epoch: 6| Step: 13
Training loss: 0.08733794093132019
Validation loss: 1.444792797488551

Epoch: 404| Step: 0
Training loss: 0.12128591537475586
Validation loss: 1.4447054504066386

Epoch: 6| Step: 1
Training loss: 0.15700209140777588
Validation loss: 1.4205488376719977

Epoch: 6| Step: 2
Training loss: 0.08524636179208755
Validation loss: 1.4535109958341044

Epoch: 6| Step: 3
Training loss: 0.13181468844413757
Validation loss: 1.414778418438409

Epoch: 6| Step: 4
Training loss: 0.06301601231098175
Validation loss: 1.4572127275569464

Epoch: 6| Step: 5
Training loss: 0.10464222729206085
Validation loss: 1.4495377566224785

Epoch: 6| Step: 6
Training loss: 0.06319014728069305
Validation loss: 1.4921089231327016

Epoch: 6| Step: 7
Training loss: 0.1249367743730545
Validation loss: 1.5322377015185613

Epoch: 6| Step: 8
Training loss: 0.19243595004081726
Validation loss: 1.5402547723503524

Epoch: 6| Step: 9
Training loss: 0.09398926794528961
Validation loss: 1.523072628564732

Epoch: 6| Step: 10
Training loss: 0.10501718521118164
Validation loss: 1.538090810980848

Epoch: 6| Step: 11
Training loss: 0.09301973879337311
Validation loss: 1.492225036826185

Epoch: 6| Step: 12
Training loss: 0.08463786542415619
Validation loss: 1.487400823382921

Epoch: 6| Step: 13
Training loss: 0.09691528230905533
Validation loss: 1.4787248155122161

Epoch: 405| Step: 0
Training loss: 0.16231504082679749
Validation loss: 1.4721191954869095

Epoch: 6| Step: 1
Training loss: 0.10331259667873383
Validation loss: 1.501056081505232

Epoch: 6| Step: 2
Training loss: 0.13158413767814636
Validation loss: 1.4747809710041169

Epoch: 6| Step: 3
Training loss: 0.09971803426742554
Validation loss: 1.5216159993602383

Epoch: 6| Step: 4
Training loss: 0.11517225950956345
Validation loss: 1.492015197712888

Epoch: 6| Step: 5
Training loss: 0.11580096185207367
Validation loss: 1.5061678194230603

Epoch: 6| Step: 6
Training loss: 0.19752594828605652
Validation loss: 1.4669672058474632

Epoch: 6| Step: 7
Training loss: 0.05391211435198784
Validation loss: 1.4807823127315891

Epoch: 6| Step: 8
Training loss: 0.10245800763368607
Validation loss: 1.4598537824487174

Epoch: 6| Step: 9
Training loss: 0.11657358705997467
Validation loss: 1.4186620802007697

Epoch: 6| Step: 10
Training loss: 0.06896190345287323
Validation loss: 1.4170769876049412

Epoch: 6| Step: 11
Training loss: 0.14721114933490753
Validation loss: 1.4230583008899484

Epoch: 6| Step: 12
Training loss: 0.09885023534297943
Validation loss: 1.3943406984370241

Epoch: 6| Step: 13
Training loss: 0.11748409271240234
Validation loss: 1.4069662414571291

Epoch: 406| Step: 0
Training loss: 0.13225238025188446
Validation loss: 1.4125856455936228

Epoch: 6| Step: 1
Training loss: 0.10393232107162476
Validation loss: 1.4394442163487917

Epoch: 6| Step: 2
Training loss: 0.06896702945232391
Validation loss: 1.433238697308366

Epoch: 6| Step: 3
Training loss: 0.08348187804222107
Validation loss: 1.4166505798216789

Epoch: 6| Step: 4
Training loss: 0.07749481499195099
Validation loss: 1.455850383286835

Epoch: 6| Step: 5
Training loss: 0.0990058183670044
Validation loss: 1.4751638456057476

Epoch: 6| Step: 6
Training loss: 0.08043985068798065
Validation loss: 1.5016169240397792

Epoch: 6| Step: 7
Training loss: 0.09653520584106445
Validation loss: 1.5309886932373047

Epoch: 6| Step: 8
Training loss: 0.12652935087680817
Validation loss: 1.5180330109852616

Epoch: 6| Step: 9
Training loss: 0.1792970597743988
Validation loss: 1.503668701135984

Epoch: 6| Step: 10
Training loss: 0.11299894750118256
Validation loss: 1.5300962668593212

Epoch: 6| Step: 11
Training loss: 0.17000195384025574
Validation loss: 1.490205608388429

Epoch: 6| Step: 12
Training loss: 0.1938941478729248
Validation loss: 1.4752585246998777

Epoch: 6| Step: 13
Training loss: 0.16908566653728485
Validation loss: 1.4482458778606948

Epoch: 407| Step: 0
Training loss: 0.09555155038833618
Validation loss: 1.4183003017979283

Epoch: 6| Step: 1
Training loss: 0.1990295797586441
Validation loss: 1.4195543796785417

Epoch: 6| Step: 2
Training loss: 0.12468533962965012
Validation loss: 1.3903980460218204

Epoch: 6| Step: 3
Training loss: 0.09497494995594025
Validation loss: 1.3819790681203206

Epoch: 6| Step: 4
Training loss: 0.10599479079246521
Validation loss: 1.4175191733144945

Epoch: 6| Step: 5
Training loss: 0.15986092388629913
Validation loss: 1.4182545818308347

Epoch: 6| Step: 6
Training loss: 0.13889653980731964
Validation loss: 1.4162748026591476

Epoch: 6| Step: 7
Training loss: 0.14690521359443665
Validation loss: 1.404203776390322

Epoch: 6| Step: 8
Training loss: 0.19765637814998627
Validation loss: 1.4232207049605667

Epoch: 6| Step: 9
Training loss: 0.11071966588497162
Validation loss: 1.4581720008645007

Epoch: 6| Step: 10
Training loss: 0.06681439280509949
Validation loss: 1.4787318744967062

Epoch: 6| Step: 11
Training loss: 0.14045831561088562
Validation loss: 1.4855033197710592

Epoch: 6| Step: 12
Training loss: 0.09427367895841599
Validation loss: 1.5016064810496506

Epoch: 6| Step: 13
Training loss: 0.19612950086593628
Validation loss: 1.55569790768367

Epoch: 408| Step: 0
Training loss: 0.1563054770231247
Validation loss: 1.5626571793710031

Epoch: 6| Step: 1
Training loss: 0.2849422097206116
Validation loss: 1.564667820930481

Epoch: 6| Step: 2
Training loss: 0.11972130089998245
Validation loss: 1.5576790148212063

Epoch: 6| Step: 3
Training loss: 0.07349071651697159
Validation loss: 1.5162309190278411

Epoch: 6| Step: 4
Training loss: 0.08980174362659454
Validation loss: 1.4820231506901402

Epoch: 6| Step: 5
Training loss: 0.13972926139831543
Validation loss: 1.4982373278628114

Epoch: 6| Step: 6
Training loss: 0.11300835013389587
Validation loss: 1.4872881776543074

Epoch: 6| Step: 7
Training loss: 0.12058125436306
Validation loss: 1.4644982276424285

Epoch: 6| Step: 8
Training loss: 0.09831631183624268
Validation loss: 1.4648824379008303

Epoch: 6| Step: 9
Training loss: 0.17833760380744934
Validation loss: 1.4642430261899066

Epoch: 6| Step: 10
Training loss: 0.11963652074337006
Validation loss: 1.44185592538567

Epoch: 6| Step: 11
Training loss: 0.23102469742298126
Validation loss: 1.469435247041846

Epoch: 6| Step: 12
Training loss: 0.15260756015777588
Validation loss: 1.4504711948415285

Epoch: 6| Step: 13
Training loss: 0.13042503595352173
Validation loss: 1.4732310797578545

Epoch: 409| Step: 0
Training loss: 0.07371120899915695
Validation loss: 1.475694284644178

Epoch: 6| Step: 1
Training loss: 0.12356577813625336
Validation loss: 1.4681643785968903

Epoch: 6| Step: 2
Training loss: 0.15878018736839294
Validation loss: 1.480962340549756

Epoch: 6| Step: 3
Training loss: 0.07530389726161957
Validation loss: 1.4812340467206893

Epoch: 6| Step: 4
Training loss: 0.20023460686206818
Validation loss: 1.5202737751827444

Epoch: 6| Step: 5
Training loss: 0.15564057230949402
Validation loss: 1.5102310719028595

Epoch: 6| Step: 6
Training loss: 0.0963539183139801
Validation loss: 1.4952887232585619

Epoch: 6| Step: 7
Training loss: 0.15607771277427673
Validation loss: 1.5190790853192728

Epoch: 6| Step: 8
Training loss: 0.09759385883808136
Validation loss: 1.5367915720068

Epoch: 6| Step: 9
Training loss: 0.1278037130832672
Validation loss: 1.5566778003528554

Epoch: 6| Step: 10
Training loss: 0.09361667186021805
Validation loss: 1.5618201244261958

Epoch: 6| Step: 11
Training loss: 0.09665586054325104
Validation loss: 1.5433630597206853

Epoch: 6| Step: 12
Training loss: 0.1733802706003189
Validation loss: 1.5274190248981598

Epoch: 6| Step: 13
Training loss: 0.20469345152378082
Validation loss: 1.5369308776752924

Epoch: 410| Step: 0
Training loss: 0.12611471116542816
Validation loss: 1.54645973508076

Epoch: 6| Step: 1
Training loss: 0.16568505764007568
Validation loss: 1.5036747827324817

Epoch: 6| Step: 2
Training loss: 0.14307323098182678
Validation loss: 1.5055315109991259

Epoch: 6| Step: 3
Training loss: 0.22447051107883453
Validation loss: 1.499264694029285

Epoch: 6| Step: 4
Training loss: 0.10989250987768173
Validation loss: 1.4653866688410442

Epoch: 6| Step: 5
Training loss: 0.08316399902105331
Validation loss: 1.4393731797895124

Epoch: 6| Step: 6
Training loss: 0.08206811547279358
Validation loss: 1.4099067180387435

Epoch: 6| Step: 7
Training loss: 0.0801367461681366
Validation loss: 1.4132353413489558

Epoch: 6| Step: 8
Training loss: 0.13289345800876617
Validation loss: 1.3996774842662196

Epoch: 6| Step: 9
Training loss: 0.13337568938732147
Validation loss: 1.4010916409953948

Epoch: 6| Step: 10
Training loss: 0.11955312639474869
Validation loss: 1.3902843434323546

Epoch: 6| Step: 11
Training loss: 0.1549345850944519
Validation loss: 1.412718524215042

Epoch: 6| Step: 12
Training loss: 0.09001105278730392
Validation loss: 1.4080558912728423

Epoch: 6| Step: 13
Training loss: 0.11901334673166275
Validation loss: 1.456912302201794

Epoch: 411| Step: 0
Training loss: 0.15759681165218353
Validation loss: 1.481406884808694

Epoch: 6| Step: 1
Training loss: 0.07773137837648392
Validation loss: 1.4986886926876601

Epoch: 6| Step: 2
Training loss: 0.0655803233385086
Validation loss: 1.5070793526147002

Epoch: 6| Step: 3
Training loss: 0.16025978326797485
Validation loss: 1.5383779630866101

Epoch: 6| Step: 4
Training loss: 0.07350997626781464
Validation loss: 1.5026760524319065

Epoch: 6| Step: 5
Training loss: 0.1336113065481186
Validation loss: 1.4796146615859

Epoch: 6| Step: 6
Training loss: 0.06299524754285812
Validation loss: 1.4679410303792646

Epoch: 6| Step: 7
Training loss: 0.09875968098640442
Validation loss: 1.458098151350534

Epoch: 6| Step: 8
Training loss: 0.11326349526643753
Validation loss: 1.4236374055185625

Epoch: 6| Step: 9
Training loss: 0.1351480484008789
Validation loss: 1.425179054660182

Epoch: 6| Step: 10
Training loss: 0.1414441019296646
Validation loss: 1.4060708066468597

Epoch: 6| Step: 11
Training loss: 0.19435426592826843
Validation loss: 1.4069607719298332

Epoch: 6| Step: 12
Training loss: 0.08954380452632904
Validation loss: 1.3958335922610374

Epoch: 6| Step: 13
Training loss: 0.13521236181259155
Validation loss: 1.386197022212449

Epoch: 412| Step: 0
Training loss: 0.11448101699352264
Validation loss: 1.406150310270248

Epoch: 6| Step: 1
Training loss: 0.11735299974679947
Validation loss: 1.4106170285132624

Epoch: 6| Step: 2
Training loss: 0.18537911772727966
Validation loss: 1.4048598774017826

Epoch: 6| Step: 3
Training loss: 0.18889591097831726
Validation loss: 1.4344619038284465

Epoch: 6| Step: 4
Training loss: 0.09852133691310883
Validation loss: 1.4397962118989678

Epoch: 6| Step: 5
Training loss: 0.06863029301166534
Validation loss: 1.4358158906300862

Epoch: 6| Step: 6
Training loss: 0.09156358242034912
Validation loss: 1.4837899631069553

Epoch: 6| Step: 7
Training loss: 0.09609588980674744
Validation loss: 1.4506244890151485

Epoch: 6| Step: 8
Training loss: 0.0901060476899147
Validation loss: 1.4802760872789609

Epoch: 6| Step: 9
Training loss: 0.12388358265161514
Validation loss: 1.474683270659498

Epoch: 6| Step: 10
Training loss: 0.0765148177742958
Validation loss: 1.4804992739872267

Epoch: 6| Step: 11
Training loss: 0.08836515247821808
Validation loss: 1.4941699069033387

Epoch: 6| Step: 12
Training loss: 0.15983006358146667
Validation loss: 1.5010469190536007

Epoch: 6| Step: 13
Training loss: 0.08090024441480637
Validation loss: 1.513071370381181

Epoch: 413| Step: 0
Training loss: 0.07602879405021667
Validation loss: 1.4751719979829685

Epoch: 6| Step: 1
Training loss: 0.11656955629587173
Validation loss: 1.4613571269537813

Epoch: 6| Step: 2
Training loss: 0.08838272094726562
Validation loss: 1.4579344641777776

Epoch: 6| Step: 3
Training loss: 0.058408528566360474
Validation loss: 1.4472120500379992

Epoch: 6| Step: 4
Training loss: 0.10801892727613449
Validation loss: 1.4411617030379593

Epoch: 6| Step: 5
Training loss: 0.08883272111415863
Validation loss: 1.4714900062930198

Epoch: 6| Step: 6
Training loss: 0.053264863789081573
Validation loss: 1.4759460482546078

Epoch: 6| Step: 7
Training loss: 0.08187508583068848
Validation loss: 1.470774621091863

Epoch: 6| Step: 8
Training loss: 0.09734802693128586
Validation loss: 1.5131862560908

Epoch: 6| Step: 9
Training loss: 0.170083150267601
Validation loss: 1.4891696386439826

Epoch: 6| Step: 10
Training loss: 0.1486249566078186
Validation loss: 1.5141895073716358

Epoch: 6| Step: 11
Training loss: 0.1841081976890564
Validation loss: 1.489834266324197

Epoch: 6| Step: 12
Training loss: 0.1396002471446991
Validation loss: 1.493858648884681

Epoch: 6| Step: 13
Training loss: 0.11250557005405426
Validation loss: 1.499165109408799

Epoch: 414| Step: 0
Training loss: 0.11494491994380951
Validation loss: 1.4896120845630605

Epoch: 6| Step: 1
Training loss: 0.1488785743713379
Validation loss: 1.4717229309902395

Epoch: 6| Step: 2
Training loss: 0.089241623878479
Validation loss: 1.4452133403029492

Epoch: 6| Step: 3
Training loss: 0.09572494029998779
Validation loss: 1.4740741496445031

Epoch: 6| Step: 4
Training loss: 0.19042423367500305
Validation loss: 1.4639926084908106

Epoch: 6| Step: 5
Training loss: 0.080960214138031
Validation loss: 1.4896537430824772

Epoch: 6| Step: 6
Training loss: 0.09998558461666107
Validation loss: 1.446408857581436

Epoch: 6| Step: 7
Training loss: 0.10431558638811111
Validation loss: 1.4618983550738263

Epoch: 6| Step: 8
Training loss: 0.10204051434993744
Validation loss: 1.4555001835669241

Epoch: 6| Step: 9
Training loss: 0.1713555008172989
Validation loss: 1.4668127388082526

Epoch: 6| Step: 10
Training loss: 0.20090697705745697
Validation loss: 1.4187471597425398

Epoch: 6| Step: 11
Training loss: 0.14373168349266052
Validation loss: 1.432918716502446

Epoch: 6| Step: 12
Training loss: 0.17329725623130798
Validation loss: 1.4271409229565692

Epoch: 6| Step: 13
Training loss: 0.11714431643486023
Validation loss: 1.4687314161690332

Epoch: 415| Step: 0
Training loss: 0.08475132286548615
Validation loss: 1.4731104373931885

Epoch: 6| Step: 1
Training loss: 0.18214574456214905
Validation loss: 1.5118462026760142

Epoch: 6| Step: 2
Training loss: 0.11118650436401367
Validation loss: 1.5048154291286264

Epoch: 6| Step: 3
Training loss: 0.07896887511014938
Validation loss: 1.529344089569584

Epoch: 6| Step: 4
Training loss: 0.15088841319084167
Validation loss: 1.5319705714461624

Epoch: 6| Step: 5
Training loss: 0.0605221651494503
Validation loss: 1.4807004556860974

Epoch: 6| Step: 6
Training loss: 0.11825396865606308
Validation loss: 1.465673280018632

Epoch: 6| Step: 7
Training loss: 0.08416052162647247
Validation loss: 1.4901403996252245

Epoch: 6| Step: 8
Training loss: 0.1423438936471939
Validation loss: 1.4952123068994092

Epoch: 6| Step: 9
Training loss: 0.13359349966049194
Validation loss: 1.4804338908964587

Epoch: 6| Step: 10
Training loss: 0.18922948837280273
Validation loss: 1.482017465817031

Epoch: 6| Step: 11
Training loss: 0.12154451757669449
Validation loss: 1.4582892207689182

Epoch: 6| Step: 12
Training loss: 0.06539274007081985
Validation loss: 1.4719763199488323

Epoch: 6| Step: 13
Training loss: 0.09144870191812515
Validation loss: 1.4807214608756445

Epoch: 416| Step: 0
Training loss: 0.09806307405233383
Validation loss: 1.4830831699473883

Epoch: 6| Step: 1
Training loss: 0.12513026595115662
Validation loss: 1.478393425223648

Epoch: 6| Step: 2
Training loss: 0.10115128010511398
Validation loss: 1.5047970792298675

Epoch: 6| Step: 3
Training loss: 0.11378535628318787
Validation loss: 1.5374130766878846

Epoch: 6| Step: 4
Training loss: 0.13119855523109436
Validation loss: 1.4934724460365951

Epoch: 6| Step: 5
Training loss: 0.14457839727401733
Validation loss: 1.5156985534134733

Epoch: 6| Step: 6
Training loss: 0.14668454229831696
Validation loss: 1.4926377355411489

Epoch: 6| Step: 7
Training loss: 0.05011415481567383
Validation loss: 1.4617923536608297

Epoch: 6| Step: 8
Training loss: 0.18389815092086792
Validation loss: 1.434974499928054

Epoch: 6| Step: 9
Training loss: 0.057210445404052734
Validation loss: 1.4358956557448193

Epoch: 6| Step: 10
Training loss: 0.09342365711927414
Validation loss: 1.4213116348430674

Epoch: 6| Step: 11
Training loss: 0.09664902091026306
Validation loss: 1.4229239968843357

Epoch: 6| Step: 12
Training loss: 0.09704514592885971
Validation loss: 1.402573707283184

Epoch: 6| Step: 13
Training loss: 0.15232843160629272
Validation loss: 1.407136929932461

Epoch: 417| Step: 0
Training loss: 0.09860070049762726
Validation loss: 1.4403038031311446

Epoch: 6| Step: 1
Training loss: 0.11727569997310638
Validation loss: 1.4424593499911729

Epoch: 6| Step: 2
Training loss: 0.13636603951454163
Validation loss: 1.4528712534135388

Epoch: 6| Step: 3
Training loss: 0.22931408882141113
Validation loss: 1.4911192514563119

Epoch: 6| Step: 4
Training loss: 0.21163296699523926
Validation loss: 1.5370048784440564

Epoch: 6| Step: 5
Training loss: 0.093663290143013
Validation loss: 1.5199827237795758

Epoch: 6| Step: 6
Training loss: 0.15843325853347778
Validation loss: 1.5256890161063081

Epoch: 6| Step: 7
Training loss: 0.10491423308849335
Validation loss: 1.5038811481127174

Epoch: 6| Step: 8
Training loss: 0.15811067819595337
Validation loss: 1.500484106361225

Epoch: 6| Step: 9
Training loss: 0.080142542719841
Validation loss: 1.4421397716768327

Epoch: 6| Step: 10
Training loss: 0.12105656415224075
Validation loss: 1.4210662277795936

Epoch: 6| Step: 11
Training loss: 0.08735227584838867
Validation loss: 1.4273422789830033

Epoch: 6| Step: 12
Training loss: 0.13763555884361267
Validation loss: 1.4245603437064795

Epoch: 6| Step: 13
Training loss: 0.14557141065597534
Validation loss: 1.4343073009162821

Epoch: 418| Step: 0
Training loss: 0.07087315618991852
Validation loss: 1.400147707231583

Epoch: 6| Step: 1
Training loss: 0.0847332775592804
Validation loss: 1.4385760573930637

Epoch: 6| Step: 2
Training loss: 0.15904489159584045
Validation loss: 1.4214074893664288

Epoch: 6| Step: 3
Training loss: 0.07609613984823227
Validation loss: 1.4457267042129271

Epoch: 6| Step: 4
Training loss: 0.07309678196907043
Validation loss: 1.4452057423130158

Epoch: 6| Step: 5
Training loss: 0.1339714527130127
Validation loss: 1.4718338751023816

Epoch: 6| Step: 6
Training loss: 0.13988426327705383
Validation loss: 1.4900134648046186

Epoch: 6| Step: 7
Training loss: 0.1335781216621399
Validation loss: 1.4912459337583153

Epoch: 6| Step: 8
Training loss: 0.08284464478492737
Validation loss: 1.5067599588824856

Epoch: 6| Step: 9
Training loss: 0.10272328555583954
Validation loss: 1.478422967336511

Epoch: 6| Step: 10
Training loss: 0.23928138613700867
Validation loss: 1.5102274879332511

Epoch: 6| Step: 11
Training loss: 0.11003187298774719
Validation loss: 1.4974347455527193

Epoch: 6| Step: 12
Training loss: 0.06684599816799164
Validation loss: 1.488566731893888

Epoch: 6| Step: 13
Training loss: 0.11239392310380936
Validation loss: 1.5031168524936964

Epoch: 419| Step: 0
Training loss: 0.07597703486680984
Validation loss: 1.4972431659698486

Epoch: 6| Step: 1
Training loss: 0.10289478302001953
Validation loss: 1.5348415195301015

Epoch: 6| Step: 2
Training loss: 0.08016365766525269
Validation loss: 1.4996658935341785

Epoch: 6| Step: 3
Training loss: 0.08038178086280823
Validation loss: 1.4997480812893118

Epoch: 6| Step: 4
Training loss: 0.08549005538225174
Validation loss: 1.48840416759573

Epoch: 6| Step: 5
Training loss: 0.12336937338113785
Validation loss: 1.4885864155266875

Epoch: 6| Step: 6
Training loss: 0.07946653664112091
Validation loss: 1.4751975690164874

Epoch: 6| Step: 7
Training loss: 0.09206447750329971
Validation loss: 1.4793131812926261

Epoch: 6| Step: 8
Training loss: 0.11249163746833801
Validation loss: 1.4594461251330633

Epoch: 6| Step: 9
Training loss: 0.15307489037513733
Validation loss: 1.4222107792413363

Epoch: 6| Step: 10
Training loss: 0.1550036370754242
Validation loss: 1.425225451428403

Epoch: 6| Step: 11
Training loss: 0.14262473583221436
Validation loss: 1.4129035395960654

Epoch: 6| Step: 12
Training loss: 0.09165488183498383
Validation loss: 1.406289086546949

Epoch: 6| Step: 13
Training loss: 0.10117153078317642
Validation loss: 1.4270823540226105

Epoch: 420| Step: 0
Training loss: 0.12540116906166077
Validation loss: 1.4173769149729

Epoch: 6| Step: 1
Training loss: 0.09493571519851685
Validation loss: 1.40678039673836

Epoch: 6| Step: 2
Training loss: 0.1598946750164032
Validation loss: 1.4402326576171383

Epoch: 6| Step: 3
Training loss: 0.16283825039863586
Validation loss: 1.4360350255043275

Epoch: 6| Step: 4
Training loss: 0.1801753044128418
Validation loss: 1.4484527328962922

Epoch: 6| Step: 5
Training loss: 0.09009909629821777
Validation loss: 1.4407406539045355

Epoch: 6| Step: 6
Training loss: 0.14382338523864746
Validation loss: 1.4855506086862216

Epoch: 6| Step: 7
Training loss: 0.1268416792154312
Validation loss: 1.4759025548094062

Epoch: 6| Step: 8
Training loss: 0.09567984938621521
Validation loss: 1.4965028942272227

Epoch: 6| Step: 9
Training loss: 0.07081446796655655
Validation loss: 1.4733839188852618

Epoch: 6| Step: 10
Training loss: 0.11444365978240967
Validation loss: 1.50550808957828

Epoch: 6| Step: 11
Training loss: 0.08273622393608093
Validation loss: 1.4890532333363768

Epoch: 6| Step: 12
Training loss: 0.2035302370786667
Validation loss: 1.5090094279217463

Epoch: 6| Step: 13
Training loss: 0.11020991206169128
Validation loss: 1.5199337088933556

Epoch: 421| Step: 0
Training loss: 0.14155620336532593
Validation loss: 1.532834561922217

Epoch: 6| Step: 1
Training loss: 0.12021695077419281
Validation loss: 1.5174526873455252

Epoch: 6| Step: 2
Training loss: 0.13792365789413452
Validation loss: 1.516395979030158

Epoch: 6| Step: 3
Training loss: 0.1192302480340004
Validation loss: 1.52314729075278

Epoch: 6| Step: 4
Training loss: 0.13927531242370605
Validation loss: 1.4618507469854047

Epoch: 6| Step: 5
Training loss: 0.09135429561138153
Validation loss: 1.4536087756515832

Epoch: 6| Step: 6
Training loss: 0.07860616594552994
Validation loss: 1.4540606583318403

Epoch: 6| Step: 7
Training loss: 0.09934968501329422
Validation loss: 1.4684933923905896

Epoch: 6| Step: 8
Training loss: 0.06767116487026215
Validation loss: 1.4840987369578371

Epoch: 6| Step: 9
Training loss: 0.11765925586223602
Validation loss: 1.473496085853987

Epoch: 6| Step: 10
Training loss: 0.20419198274612427
Validation loss: 1.4890875649708573

Epoch: 6| Step: 11
Training loss: 0.08221375942230225
Validation loss: 1.4968789508265834

Epoch: 6| Step: 12
Training loss: 0.10876849293708801
Validation loss: 1.457428934753582

Epoch: 6| Step: 13
Training loss: 0.12263238430023193
Validation loss: 1.4495179806986163

Epoch: 422| Step: 0
Training loss: 0.10563746094703674
Validation loss: 1.454110163514332

Epoch: 6| Step: 1
Training loss: 0.13113057613372803
Validation loss: 1.4762971093577724

Epoch: 6| Step: 2
Training loss: 0.13315454125404358
Validation loss: 1.4776498771482898

Epoch: 6| Step: 3
Training loss: 0.07731302827596664
Validation loss: 1.4500046084004063

Epoch: 6| Step: 4
Training loss: 0.08066514134407043
Validation loss: 1.489419767933507

Epoch: 6| Step: 5
Training loss: 0.0911516547203064
Validation loss: 1.5096165569879676

Epoch: 6| Step: 6
Training loss: 0.0827096551656723
Validation loss: 1.460877041021983

Epoch: 6| Step: 7
Training loss: 0.1073756068944931
Validation loss: 1.5065952962444675

Epoch: 6| Step: 8
Training loss: 0.10679216682910919
Validation loss: 1.4982173237749326

Epoch: 6| Step: 9
Training loss: 0.2502519488334656
Validation loss: 1.552725773985668

Epoch: 6| Step: 10
Training loss: 0.10708095878362656
Validation loss: 1.5122171255850023

Epoch: 6| Step: 11
Training loss: 0.09947054088115692
Validation loss: 1.5385350860575193

Epoch: 6| Step: 12
Training loss: 0.06136505305767059
Validation loss: 1.5278318082132647

Epoch: 6| Step: 13
Training loss: 0.08743876963853836
Validation loss: 1.5365705361930273

Epoch: 423| Step: 0
Training loss: 0.09395609050989151
Validation loss: 1.5289374115646526

Epoch: 6| Step: 1
Training loss: 0.13121767342090607
Validation loss: 1.4919071235964376

Epoch: 6| Step: 2
Training loss: 0.08026427775621414
Validation loss: 1.448427192626461

Epoch: 6| Step: 3
Training loss: 0.12963153421878815
Validation loss: 1.4493607615911832

Epoch: 6| Step: 4
Training loss: 0.09322922676801682
Validation loss: 1.4421531840037274

Epoch: 6| Step: 5
Training loss: 0.1425420343875885
Validation loss: 1.435783133711866

Epoch: 6| Step: 6
Training loss: 0.134787917137146
Validation loss: 1.4368963100576913

Epoch: 6| Step: 7
Training loss: 0.09828495979309082
Validation loss: 1.4226086293497393

Epoch: 6| Step: 8
Training loss: 0.18399804830551147
Validation loss: 1.4413213435039725

Epoch: 6| Step: 9
Training loss: 0.141283318400383
Validation loss: 1.4418522452795377

Epoch: 6| Step: 10
Training loss: 0.04615011066198349
Validation loss: 1.4329278520358506

Epoch: 6| Step: 11
Training loss: 0.07913902401924133
Validation loss: 1.4676678360149424

Epoch: 6| Step: 12
Training loss: 0.11657710373401642
Validation loss: 1.4983820223039197

Epoch: 6| Step: 13
Training loss: 0.13528013229370117
Validation loss: 1.506897089301899

Epoch: 424| Step: 0
Training loss: 0.07878023386001587
Validation loss: 1.5030861516152658

Epoch: 6| Step: 1
Training loss: 0.1057329848408699
Validation loss: 1.5591028031482492

Epoch: 6| Step: 2
Training loss: 0.09562462568283081
Validation loss: 1.5523455809521418

Epoch: 6| Step: 3
Training loss: 0.15778404474258423
Validation loss: 1.5761848008760841

Epoch: 6| Step: 4
Training loss: 0.16933788359165192
Validation loss: 1.5735611210587204

Epoch: 6| Step: 5
Training loss: 0.1179923564195633
Validation loss: 1.545131105248646

Epoch: 6| Step: 6
Training loss: 0.11253686994314194
Validation loss: 1.4957739153215963

Epoch: 6| Step: 7
Training loss: 0.07449579238891602
Validation loss: 1.512108040112321

Epoch: 6| Step: 8
Training loss: 0.15601252019405365
Validation loss: 1.5064861928263018

Epoch: 6| Step: 9
Training loss: 0.21206563711166382
Validation loss: 1.4709245748417352

Epoch: 6| Step: 10
Training loss: 0.08371327817440033
Validation loss: 1.4944304522647653

Epoch: 6| Step: 11
Training loss: 0.10944885015487671
Validation loss: 1.4878990323312822

Epoch: 6| Step: 12
Training loss: 0.09174516797065735
Validation loss: 1.4781505100188717

Epoch: 6| Step: 13
Training loss: 0.09171392023563385
Validation loss: 1.497375137062483

Epoch: 425| Step: 0
Training loss: 0.08199427276849747
Validation loss: 1.5066765982617614

Epoch: 6| Step: 1
Training loss: 0.1161031499505043
Validation loss: 1.5082982176093644

Epoch: 6| Step: 2
Training loss: 0.10131821036338806
Validation loss: 1.4873564935499621

Epoch: 6| Step: 3
Training loss: 0.10665450990200043
Validation loss: 1.5005414127021708

Epoch: 6| Step: 4
Training loss: 0.10548504441976547
Validation loss: 1.531974818116875

Epoch: 6| Step: 5
Training loss: 0.1793803572654724
Validation loss: 1.4949543873469036

Epoch: 6| Step: 6
Training loss: 0.0937139093875885
Validation loss: 1.5217907133922781

Epoch: 6| Step: 7
Training loss: 0.06395615637302399
Validation loss: 1.4865667845613213

Epoch: 6| Step: 8
Training loss: 0.0754607766866684
Validation loss: 1.4761818198747532

Epoch: 6| Step: 9
Training loss: 0.09016654640436172
Validation loss: 1.4824258345429615

Epoch: 6| Step: 10
Training loss: 0.09425945580005646
Validation loss: 1.4929629307921215

Epoch: 6| Step: 11
Training loss: 0.14825841784477234
Validation loss: 1.4516688085371448

Epoch: 6| Step: 12
Training loss: 0.08739861845970154
Validation loss: 1.449904344415152

Epoch: 6| Step: 13
Training loss: 0.10719625651836395
Validation loss: 1.425226814003401

Epoch: 426| Step: 0
Training loss: 0.0957169383764267
Validation loss: 1.4252013455155075

Epoch: 6| Step: 1
Training loss: 0.13609588146209717
Validation loss: 1.447127289669488

Epoch: 6| Step: 2
Training loss: 0.06907717138528824
Validation loss: 1.4513290441164406

Epoch: 6| Step: 3
Training loss: 0.09906476736068726
Validation loss: 1.469708950288834

Epoch: 6| Step: 4
Training loss: 0.1114719957113266
Validation loss: 1.4937083259705575

Epoch: 6| Step: 5
Training loss: 0.11230304837226868
Validation loss: 1.502122627791538

Epoch: 6| Step: 6
Training loss: 0.14952422678470612
Validation loss: 1.4959969866660334

Epoch: 6| Step: 7
Training loss: 0.14640671014785767
Validation loss: 1.5236944114008257

Epoch: 6| Step: 8
Training loss: 0.15466156601905823
Validation loss: 1.5670809899607012

Epoch: 6| Step: 9
Training loss: 0.0818667933344841
Validation loss: 1.5041314594207271

Epoch: 6| Step: 10
Training loss: 0.11379396915435791
Validation loss: 1.4971650313305598

Epoch: 6| Step: 11
Training loss: 0.15399952232837677
Validation loss: 1.4881565122194187

Epoch: 6| Step: 12
Training loss: 0.09073159098625183
Validation loss: 1.4710130845346758

Epoch: 6| Step: 13
Training loss: 0.08598019182682037
Validation loss: 1.462454403600385

Epoch: 427| Step: 0
Training loss: 0.08744028210639954
Validation loss: 1.484804932789136

Epoch: 6| Step: 1
Training loss: 0.1355152130126953
Validation loss: 1.4601249717256075

Epoch: 6| Step: 2
Training loss: 0.13783320784568787
Validation loss: 1.4699299444434464

Epoch: 6| Step: 3
Training loss: 0.09610091149806976
Validation loss: 1.4436005700019099

Epoch: 6| Step: 4
Training loss: 0.10555700212717056
Validation loss: 1.4408227859004852

Epoch: 6| Step: 5
Training loss: 0.08500496298074722
Validation loss: 1.4385802797091904

Epoch: 6| Step: 6
Training loss: 0.12186689674854279
Validation loss: 1.4475220441818237

Epoch: 6| Step: 7
Training loss: 0.1051800549030304
Validation loss: 1.4623037128038303

Epoch: 6| Step: 8
Training loss: 0.1432206928730011
Validation loss: 1.4387297245763964

Epoch: 6| Step: 9
Training loss: 0.21762573719024658
Validation loss: 1.490957498550415

Epoch: 6| Step: 10
Training loss: 0.092552050948143
Validation loss: 1.5069461266199748

Epoch: 6| Step: 11
Training loss: 0.11911201477050781
Validation loss: 1.4973892575951033

Epoch: 6| Step: 12
Training loss: 0.07694165408611298
Validation loss: 1.526835690262497

Epoch: 6| Step: 13
Training loss: 0.10783226788043976
Validation loss: 1.509360710779826

Epoch: 428| Step: 0
Training loss: 0.09220340102910995
Validation loss: 1.5459547132574103

Epoch: 6| Step: 1
Training loss: 0.09605060517787933
Validation loss: 1.5683627167055685

Epoch: 6| Step: 2
Training loss: 0.20450517535209656
Validation loss: 1.5760886925522999

Epoch: 6| Step: 3
Training loss: 0.07386379688978195
Validation loss: 1.5372991856708322

Epoch: 6| Step: 4
Training loss: 0.0810554251074791
Validation loss: 1.5578944849711593

Epoch: 6| Step: 5
Training loss: 0.0786832943558693
Validation loss: 1.5391306159316853

Epoch: 6| Step: 6
Training loss: 0.08771941065788269
Validation loss: 1.5669266517444322

Epoch: 6| Step: 7
Training loss: 0.10096415877342224
Validation loss: 1.5737346897843063

Epoch: 6| Step: 8
Training loss: 0.20351816713809967
Validation loss: 1.5708160836209533

Epoch: 6| Step: 9
Training loss: 0.1359749734401703
Validation loss: 1.5376715493458573

Epoch: 6| Step: 10
Training loss: 0.10134965181350708
Validation loss: 1.4907503230597383

Epoch: 6| Step: 11
Training loss: 0.05914217233657837
Validation loss: 1.4816247596535632

Epoch: 6| Step: 12
Training loss: 0.096906878054142
Validation loss: 1.469901628391717

Epoch: 6| Step: 13
Training loss: 0.07205041497945786
Validation loss: 1.454614204745139

Epoch: 429| Step: 0
Training loss: 0.1263471245765686
Validation loss: 1.4312920006372596

Epoch: 6| Step: 1
Training loss: 0.07892873883247375
Validation loss: 1.4315076861330258

Epoch: 6| Step: 2
Training loss: 0.11453688144683838
Validation loss: 1.4751628163040325

Epoch: 6| Step: 3
Training loss: 0.08703465759754181
Validation loss: 1.456379594341401

Epoch: 6| Step: 4
Training loss: 0.0763300359249115
Validation loss: 1.4514527128588768

Epoch: 6| Step: 5
Training loss: 0.1770818829536438
Validation loss: 1.4365198125121414

Epoch: 6| Step: 6
Training loss: 0.04904574900865555
Validation loss: 1.4552245601530998

Epoch: 6| Step: 7
Training loss: 0.07508046925067902
Validation loss: 1.450877611355115

Epoch: 6| Step: 8
Training loss: 0.12672021985054016
Validation loss: 1.4766799147411058

Epoch: 6| Step: 9
Training loss: 0.07480816543102264
Validation loss: 1.478798403534838

Epoch: 6| Step: 10
Training loss: 0.11026625335216522
Validation loss: 1.491004615701655

Epoch: 6| Step: 11
Training loss: 0.09143838286399841
Validation loss: 1.5033702311977264

Epoch: 6| Step: 12
Training loss: 0.08533122390508652
Validation loss: 1.5003945494210849

Epoch: 6| Step: 13
Training loss: 0.06876131147146225
Validation loss: 1.4868096190114175

Epoch: 430| Step: 0
Training loss: 0.11076836287975311
Validation loss: 1.5028601051658712

Epoch: 6| Step: 1
Training loss: 0.07410869747400284
Validation loss: 1.5074524187272595

Epoch: 6| Step: 2
Training loss: 0.04057270288467407
Validation loss: 1.5046462346148748

Epoch: 6| Step: 3
Training loss: 0.10019659996032715
Validation loss: 1.487670583109702

Epoch: 6| Step: 4
Training loss: 0.062237706035375595
Validation loss: 1.4724939894932572

Epoch: 6| Step: 5
Training loss: 0.07269380986690521
Validation loss: 1.4716539447025587

Epoch: 6| Step: 6
Training loss: 0.053621646016836166
Validation loss: 1.4630763633276826

Epoch: 6| Step: 7
Training loss: 0.07324378192424774
Validation loss: 1.444519699901663

Epoch: 6| Step: 8
Training loss: 0.25131022930145264
Validation loss: 1.42881005425607

Epoch: 6| Step: 9
Training loss: 0.09862571954727173
Validation loss: 1.42862485172928

Epoch: 6| Step: 10
Training loss: 0.09420442581176758
Validation loss: 1.4610129556348246

Epoch: 6| Step: 11
Training loss: 0.07324308156967163
Validation loss: 1.4341418807224562

Epoch: 6| Step: 12
Training loss: 0.1563008427619934
Validation loss: 1.4600373955183132

Epoch: 6| Step: 13
Training loss: 0.08307547122240067
Validation loss: 1.4976941424031411

Epoch: 431| Step: 0
Training loss: 0.09627704322338104
Validation loss: 1.5283998635507399

Epoch: 6| Step: 1
Training loss: 0.07447467744350433
Validation loss: 1.5275457264274679

Epoch: 6| Step: 2
Training loss: 0.12490997463464737
Validation loss: 1.519573737216252

Epoch: 6| Step: 3
Training loss: 0.17699091136455536
Validation loss: 1.5457762492600309

Epoch: 6| Step: 4
Training loss: 0.10739162564277649
Validation loss: 1.5201793383526545

Epoch: 6| Step: 5
Training loss: 0.1606198251247406
Validation loss: 1.5111234649535148

Epoch: 6| Step: 6
Training loss: 0.05188431590795517
Validation loss: 1.4860292609019945

Epoch: 6| Step: 7
Training loss: 0.09895923733711243
Validation loss: 1.4755072311688495

Epoch: 6| Step: 8
Training loss: 0.08786818385124207
Validation loss: 1.4421961576707902

Epoch: 6| Step: 9
Training loss: 0.09548595547676086
Validation loss: 1.4646984479760612

Epoch: 6| Step: 10
Training loss: 0.10829522460699081
Validation loss: 1.443488363296755

Epoch: 6| Step: 11
Training loss: 0.0716942548751831
Validation loss: 1.46291454697168

Epoch: 6| Step: 12
Training loss: 0.09501054883003235
Validation loss: 1.4985378416635657

Epoch: 6| Step: 13
Training loss: 0.05756101384758949
Validation loss: 1.4305167698091077

Epoch: 432| Step: 0
Training loss: 0.12493571639060974
Validation loss: 1.4498621879085418

Epoch: 6| Step: 1
Training loss: 0.1458357274532318
Validation loss: 1.4519202798925421

Epoch: 6| Step: 2
Training loss: 0.13576443493366241
Validation loss: 1.4404290273625364

Epoch: 6| Step: 3
Training loss: 0.0729188323020935
Validation loss: 1.4459320781051472

Epoch: 6| Step: 4
Training loss: 0.09042559564113617
Validation loss: 1.451656090315952

Epoch: 6| Step: 5
Training loss: 0.09941122680902481
Validation loss: 1.4587584016143635

Epoch: 6| Step: 6
Training loss: 0.12348082661628723
Validation loss: 1.4441581028763966

Epoch: 6| Step: 7
Training loss: 0.14542730152606964
Validation loss: 1.4673361380894978

Epoch: 6| Step: 8
Training loss: 0.09108612686395645
Validation loss: 1.4591339313855736

Epoch: 6| Step: 9
Training loss: 0.07124225795269012
Validation loss: 1.4731703285248048

Epoch: 6| Step: 10
Training loss: 0.09348083287477493
Validation loss: 1.4564003713669316

Epoch: 6| Step: 11
Training loss: 0.06029565632343292
Validation loss: 1.457205827518176

Epoch: 6| Step: 12
Training loss: 0.10406841337680817
Validation loss: 1.4512068148582213

Epoch: 6| Step: 13
Training loss: 0.054144758731126785
Validation loss: 1.477849918667988

Epoch: 433| Step: 0
Training loss: 0.06293216347694397
Validation loss: 1.4943603648934314

Epoch: 6| Step: 1
Training loss: 0.08686771988868713
Validation loss: 1.4951294276022142

Epoch: 6| Step: 2
Training loss: 0.0676625669002533
Validation loss: 1.4838645124948153

Epoch: 6| Step: 3
Training loss: 0.08953041583299637
Validation loss: 1.511736084056157

Epoch: 6| Step: 4
Training loss: 0.10651683062314987
Validation loss: 1.4786267485669864

Epoch: 6| Step: 5
Training loss: 0.06293121725320816
Validation loss: 1.5098789391979095

Epoch: 6| Step: 6
Training loss: 0.15193113684654236
Validation loss: 1.4840055729753228

Epoch: 6| Step: 7
Training loss: 0.061997607350349426
Validation loss: 1.4756460741002073

Epoch: 6| Step: 8
Training loss: 0.1196126639842987
Validation loss: 1.4873062000479749

Epoch: 6| Step: 9
Training loss: 0.055752627551555634
Validation loss: 1.4652064359316261

Epoch: 6| Step: 10
Training loss: 0.09405997395515442
Validation loss: 1.4537535213655042

Epoch: 6| Step: 11
Training loss: 0.122577004134655
Validation loss: 1.4223382710128702

Epoch: 6| Step: 12
Training loss: 0.08551059663295746
Validation loss: 1.4326390745819255

Epoch: 6| Step: 13
Training loss: 0.10508185625076294
Validation loss: 1.4375467415778869

Epoch: 434| Step: 0
Training loss: 0.08869186043739319
Validation loss: 1.4289267729687434

Epoch: 6| Step: 1
Training loss: 0.122226782143116
Validation loss: 1.417477015526064

Epoch: 6| Step: 2
Training loss: 0.09690923243761063
Validation loss: 1.433631125316825

Epoch: 6| Step: 3
Training loss: 0.09967375546693802
Validation loss: 1.4413469235102336

Epoch: 6| Step: 4
Training loss: 0.12442656606435776
Validation loss: 1.460114574560555

Epoch: 6| Step: 5
Training loss: 0.1475113034248352
Validation loss: 1.500528992504202

Epoch: 6| Step: 6
Training loss: 0.09454798698425293
Validation loss: 1.4742514696172488

Epoch: 6| Step: 7
Training loss: 0.15449216961860657
Validation loss: 1.5138649761035878

Epoch: 6| Step: 8
Training loss: 0.08632833510637283
Validation loss: 1.5267926980090398

Epoch: 6| Step: 9
Training loss: 0.11019348353147507
Validation loss: 1.5230520130485616

Epoch: 6| Step: 10
Training loss: 0.080355204641819
Validation loss: 1.532620976048131

Epoch: 6| Step: 11
Training loss: 0.1485545039176941
Validation loss: 1.5394286763283513

Epoch: 6| Step: 12
Training loss: 0.1057266891002655
Validation loss: 1.5531806304890623

Epoch: 6| Step: 13
Training loss: 0.10949167609214783
Validation loss: 1.5335997509699997

Epoch: 435| Step: 0
Training loss: 0.0834985300898552
Validation loss: 1.5268763021756244

Epoch: 6| Step: 1
Training loss: 0.11529593169689178
Validation loss: 1.474277255355671

Epoch: 6| Step: 2
Training loss: 0.06854978203773499
Validation loss: 1.4615981527554092

Epoch: 6| Step: 3
Training loss: 0.10254288464784622
Validation loss: 1.447855701369624

Epoch: 6| Step: 4
Training loss: 0.08057667315006256
Validation loss: 1.4304383185602003

Epoch: 6| Step: 5
Training loss: 0.06187443435192108
Validation loss: 1.4037821331331808

Epoch: 6| Step: 6
Training loss: 0.094608373939991
Validation loss: 1.4211021751485846

Epoch: 6| Step: 7
Training loss: 0.0679393857717514
Validation loss: 1.4162679731204946

Epoch: 6| Step: 8
Training loss: 0.1436898112297058
Validation loss: 1.4266028186326385

Epoch: 6| Step: 9
Training loss: 0.14583106338977814
Validation loss: 1.4282962173543952

Epoch: 6| Step: 10
Training loss: 0.08724284172058105
Validation loss: 1.4506572818243375

Epoch: 6| Step: 11
Training loss: 0.08810538798570633
Validation loss: 1.4546014788330242

Epoch: 6| Step: 12
Training loss: 0.10526972264051437
Validation loss: 1.4813079064892185

Epoch: 6| Step: 13
Training loss: 0.32214656472206116
Validation loss: 1.5365341812051752

Epoch: 436| Step: 0
Training loss: 0.06583905220031738
Validation loss: 1.562799503726344

Epoch: 6| Step: 1
Training loss: 0.12254157662391663
Validation loss: 1.5288266244754996

Epoch: 6| Step: 2
Training loss: 0.12146414816379547
Validation loss: 1.5152484486179967

Epoch: 6| Step: 3
Training loss: 0.10396629571914673
Validation loss: 1.5449525630602272

Epoch: 6| Step: 4
Training loss: 0.10118575394153595
Validation loss: 1.5159040574104554

Epoch: 6| Step: 5
Training loss: 0.1341630220413208
Validation loss: 1.5283314771549676

Epoch: 6| Step: 6
Training loss: 0.09652730077505112
Validation loss: 1.5238969326019287

Epoch: 6| Step: 7
Training loss: 0.14465662837028503
Validation loss: 1.5304448348219677

Epoch: 6| Step: 8
Training loss: 0.16781587898731232
Validation loss: 1.5069550801348943

Epoch: 6| Step: 9
Training loss: 0.08473797142505646
Validation loss: 1.5154898294838526

Epoch: 6| Step: 10
Training loss: 0.1034700870513916
Validation loss: 1.521578638784347

Epoch: 6| Step: 11
Training loss: 0.14301817119121552
Validation loss: 1.4923847195922688

Epoch: 6| Step: 12
Training loss: 0.13010242581367493
Validation loss: 1.50729904572169

Epoch: 6| Step: 13
Training loss: 0.19524401426315308
Validation loss: 1.4482626286886071

Epoch: 437| Step: 0
Training loss: 0.09726649522781372
Validation loss: 1.4449757004296908

Epoch: 6| Step: 1
Training loss: 0.14618563652038574
Validation loss: 1.4550616279725106

Epoch: 6| Step: 2
Training loss: 0.12267636507749557
Validation loss: 1.4156857120093478

Epoch: 6| Step: 3
Training loss: 0.10022416710853577
Validation loss: 1.4032609206373974

Epoch: 6| Step: 4
Training loss: 0.10897523164749146
Validation loss: 1.4344449274001583

Epoch: 6| Step: 5
Training loss: 0.08778568357229233
Validation loss: 1.4175670800670501

Epoch: 6| Step: 6
Training loss: 0.17269733548164368
Validation loss: 1.441016456132294

Epoch: 6| Step: 7
Training loss: 0.08848981559276581
Validation loss: 1.4398466124329516

Epoch: 6| Step: 8
Training loss: 0.08704856783151627
Validation loss: 1.4949751028450586

Epoch: 6| Step: 9
Training loss: 0.1378130167722702
Validation loss: 1.4503310188170402

Epoch: 6| Step: 10
Training loss: 0.19517163932323456
Validation loss: 1.477429865508951

Epoch: 6| Step: 11
Training loss: 0.08789999783039093
Validation loss: 1.5121270828349616

Epoch: 6| Step: 12
Training loss: 0.12699492275714874
Validation loss: 1.519800006702382

Epoch: 6| Step: 13
Training loss: 0.10387125611305237
Validation loss: 1.5181561311086018

Epoch: 438| Step: 0
Training loss: 0.08714355528354645
Validation loss: 1.51963472366333

Epoch: 6| Step: 1
Training loss: 0.09926922619342804
Validation loss: 1.4981530866315287

Epoch: 6| Step: 2
Training loss: 0.0931691825389862
Validation loss: 1.5136535065148466

Epoch: 6| Step: 3
Training loss: 0.11995946615934372
Validation loss: 1.5020167455878308

Epoch: 6| Step: 4
Training loss: 0.17465564608573914
Validation loss: 1.5210370748273787

Epoch: 6| Step: 5
Training loss: 0.1050720065832138
Validation loss: 1.4891727092445537

Epoch: 6| Step: 6
Training loss: 0.08082762360572815
Validation loss: 1.5018014228472145

Epoch: 6| Step: 7
Training loss: 0.12575030326843262
Validation loss: 1.5031365771447458

Epoch: 6| Step: 8
Training loss: 0.11134667694568634
Validation loss: 1.510035612249887

Epoch: 6| Step: 9
Training loss: 0.09741195291280746
Validation loss: 1.4635015136452132

Epoch: 6| Step: 10
Training loss: 0.12674881517887115
Validation loss: 1.4557572430179966

Epoch: 6| Step: 11
Training loss: 0.0714096799492836
Validation loss: 1.4600120667488343

Epoch: 6| Step: 12
Training loss: 0.10552584379911423
Validation loss: 1.4510988317510134

Epoch: 6| Step: 13
Training loss: 0.14002367854118347
Validation loss: 1.4762513765724756

Epoch: 439| Step: 0
Training loss: 0.09893637150526047
Validation loss: 1.4702734075566775

Epoch: 6| Step: 1
Training loss: 0.07097518444061279
Validation loss: 1.4927851205231042

Epoch: 6| Step: 2
Training loss: 0.07223007827997208
Validation loss: 1.4846011900132703

Epoch: 6| Step: 3
Training loss: 0.08826393634080887
Validation loss: 1.55133693961687

Epoch: 6| Step: 4
Training loss: 0.10550388693809509
Validation loss: 1.507289211596212

Epoch: 6| Step: 5
Training loss: 0.09186210483312607
Validation loss: 1.5305413046190817

Epoch: 6| Step: 6
Training loss: 0.07408913224935532
Validation loss: 1.5198346696874148

Epoch: 6| Step: 7
Training loss: 0.10537075996398926
Validation loss: 1.5100035270055134

Epoch: 6| Step: 8
Training loss: 0.06501329690217972
Validation loss: 1.5016201189769212

Epoch: 6| Step: 9
Training loss: 0.11302340030670166
Validation loss: 1.4623655913978495

Epoch: 6| Step: 10
Training loss: 0.21773378551006317
Validation loss: 1.4916379323569677

Epoch: 6| Step: 11
Training loss: 0.11170487105846405
Validation loss: 1.513725919108237

Epoch: 6| Step: 12
Training loss: 0.07597389817237854
Validation loss: 1.5300992970825524

Epoch: 6| Step: 13
Training loss: 0.14542903006076813
Validation loss: 1.53742092399187

Epoch: 440| Step: 0
Training loss: 0.10207967460155487
Validation loss: 1.5296282217066774

Epoch: 6| Step: 1
Training loss: 0.045725155621767044
Validation loss: 1.4873637947984921

Epoch: 6| Step: 2
Training loss: 0.07813353836536407
Validation loss: 1.455217142258921

Epoch: 6| Step: 3
Training loss: 0.061827726662158966
Validation loss: 1.4302230624742405

Epoch: 6| Step: 4
Training loss: 0.05806255340576172
Validation loss: 1.4533107293549405

Epoch: 6| Step: 5
Training loss: 0.04837379604578018
Validation loss: 1.4747939237984278

Epoch: 6| Step: 6
Training loss: 0.1081373542547226
Validation loss: 1.4379446314227196

Epoch: 6| Step: 7
Training loss: 0.13094958662986755
Validation loss: 1.4401179346986996

Epoch: 6| Step: 8
Training loss: 0.08750174939632416
Validation loss: 1.4292640506580312

Epoch: 6| Step: 9
Training loss: 0.10280773788690567
Validation loss: 1.4548942055753482

Epoch: 6| Step: 10
Training loss: 0.19428656995296478
Validation loss: 1.453036299956742

Epoch: 6| Step: 11
Training loss: 0.06541316956281662
Validation loss: 1.4540223165224957

Epoch: 6| Step: 12
Training loss: 0.08868369460105896
Validation loss: 1.4499334750636932

Epoch: 6| Step: 13
Training loss: 0.12734895944595337
Validation loss: 1.472838076212073

Epoch: 441| Step: 0
Training loss: 0.1172076165676117
Validation loss: 1.4598274256593438

Epoch: 6| Step: 1
Training loss: 0.09866990149021149
Validation loss: 1.4573369615821428

Epoch: 6| Step: 2
Training loss: 0.08035239577293396
Validation loss: 1.4790493237074984

Epoch: 6| Step: 3
Training loss: 0.07964445650577545
Validation loss: 1.466493570676414

Epoch: 6| Step: 4
Training loss: 0.07870525866746902
Validation loss: 1.4326712123809322

Epoch: 6| Step: 5
Training loss: 0.14707429707050323
Validation loss: 1.4620798608308196

Epoch: 6| Step: 6
Training loss: 0.11538922786712646
Validation loss: 1.4460239634718945

Epoch: 6| Step: 7
Training loss: 0.07108975946903229
Validation loss: 1.3972039068898847

Epoch: 6| Step: 8
Training loss: 0.0743182897567749
Validation loss: 1.4407747061021867

Epoch: 6| Step: 9
Training loss: 0.17405520379543304
Validation loss: 1.4240554840334

Epoch: 6| Step: 10
Training loss: 0.0803232192993164
Validation loss: 1.4277883152807913

Epoch: 6| Step: 11
Training loss: 0.12428922951221466
Validation loss: 1.4584504776103522

Epoch: 6| Step: 12
Training loss: 0.1162986010313034
Validation loss: 1.451566114220568

Epoch: 6| Step: 13
Training loss: 0.0676034539937973
Validation loss: 1.4837731174243394

Epoch: 442| Step: 0
Training loss: 0.07927234470844269
Validation loss: 1.5073794562329528

Epoch: 6| Step: 1
Training loss: 0.11571351438760757
Validation loss: 1.5104683214618313

Epoch: 6| Step: 2
Training loss: 0.207802414894104
Validation loss: 1.5549903223591466

Epoch: 6| Step: 3
Training loss: 0.11346181482076645
Validation loss: 1.533087202297744

Epoch: 6| Step: 4
Training loss: 0.12214238941669464
Validation loss: 1.5376211122799945

Epoch: 6| Step: 5
Training loss: 0.12262196838855743
Validation loss: 1.5260913115675732

Epoch: 6| Step: 6
Training loss: 0.1070309579372406
Validation loss: 1.482151166085274

Epoch: 6| Step: 7
Training loss: 0.07198522984981537
Validation loss: 1.4314209312521002

Epoch: 6| Step: 8
Training loss: 0.09755517542362213
Validation loss: 1.483855027024464

Epoch: 6| Step: 9
Training loss: 0.13544665277004242
Validation loss: 1.4664215964655722

Epoch: 6| Step: 10
Training loss: 0.09466418623924255
Validation loss: 1.4151871890150092

Epoch: 6| Step: 11
Training loss: 0.12298691272735596
Validation loss: 1.428487713618945

Epoch: 6| Step: 12
Training loss: 0.159040167927742
Validation loss: 1.4275883436203003

Epoch: 6| Step: 13
Training loss: 0.05624003708362579
Validation loss: 1.4310948329587136

Epoch: 443| Step: 0
Training loss: 0.10372833907604218
Validation loss: 1.4619356714269167

Epoch: 6| Step: 1
Training loss: 0.17941522598266602
Validation loss: 1.4439658529014998

Epoch: 6| Step: 2
Training loss: 0.10068303346633911
Validation loss: 1.4927911168785506

Epoch: 6| Step: 3
Training loss: 0.07197888195514679
Validation loss: 1.5235517050630303

Epoch: 6| Step: 4
Training loss: 0.08124807476997375
Validation loss: 1.5386835650731159

Epoch: 6| Step: 5
Training loss: 0.15763947367668152
Validation loss: 1.5008166816926771

Epoch: 6| Step: 6
Training loss: 0.0760963186621666
Validation loss: 1.528735706883092

Epoch: 6| Step: 7
Training loss: 0.1141265407204628
Validation loss: 1.5264759512357815

Epoch: 6| Step: 8
Training loss: 0.14872069656848907
Validation loss: 1.489727061281922

Epoch: 6| Step: 9
Training loss: 0.09758087992668152
Validation loss: 1.479541668327906

Epoch: 6| Step: 10
Training loss: 0.11363095790147781
Validation loss: 1.4477612010894283

Epoch: 6| Step: 11
Training loss: 0.05224592238664627
Validation loss: 1.487658800617341

Epoch: 6| Step: 12
Training loss: 0.12641142308712006
Validation loss: 1.4576813841378817

Epoch: 6| Step: 13
Training loss: 0.1043543815612793
Validation loss: 1.4326482113971506

Epoch: 444| Step: 0
Training loss: 0.10888108611106873
Validation loss: 1.429078270030278

Epoch: 6| Step: 1
Training loss: 0.09651357680559158
Validation loss: 1.4609373897634528

Epoch: 6| Step: 2
Training loss: 0.08832620829343796
Validation loss: 1.4767249784161967

Epoch: 6| Step: 3
Training loss: 0.07932808250188828
Validation loss: 1.4794841709957327

Epoch: 6| Step: 4
Training loss: 0.12039488554000854
Validation loss: 1.494886384215406

Epoch: 6| Step: 5
Training loss: 0.20042331516742706
Validation loss: 1.5186991742862168

Epoch: 6| Step: 6
Training loss: 0.11415696889162064
Validation loss: 1.5442196797299128

Epoch: 6| Step: 7
Training loss: 0.2112235724925995
Validation loss: 1.4967188886416856

Epoch: 6| Step: 8
Training loss: 0.13534338772296906
Validation loss: 1.4998645308197185

Epoch: 6| Step: 9
Training loss: 0.1411789357662201
Validation loss: 1.4897903806419783

Epoch: 6| Step: 10
Training loss: 0.16887310147285461
Validation loss: 1.4610759032669889

Epoch: 6| Step: 11
Training loss: 0.09822092950344086
Validation loss: 1.4841678206638624

Epoch: 6| Step: 12
Training loss: 0.1268804967403412
Validation loss: 1.4526970001959032

Epoch: 6| Step: 13
Training loss: 0.12360689043998718
Validation loss: 1.4793008014719973

Epoch: 445| Step: 0
Training loss: 0.09643995761871338
Validation loss: 1.502756070065242

Epoch: 6| Step: 1
Training loss: 0.1331295669078827
Validation loss: 1.489349740807728

Epoch: 6| Step: 2
Training loss: 0.09996069222688675
Validation loss: 1.4803507251124228

Epoch: 6| Step: 3
Training loss: 0.25257331132888794
Validation loss: 1.4571727347630326

Epoch: 6| Step: 4
Training loss: 0.1298569291830063
Validation loss: 1.472698619288783

Epoch: 6| Step: 5
Training loss: 0.1446399986743927
Validation loss: 1.4883888434338313

Epoch: 6| Step: 6
Training loss: 0.10216448456048965
Validation loss: 1.5023635202838528

Epoch: 6| Step: 7
Training loss: 0.10056629031896591
Validation loss: 1.5277101480832664

Epoch: 6| Step: 8
Training loss: 0.11913996189832687
Validation loss: 1.5163725960639216

Epoch: 6| Step: 9
Training loss: 0.1147189512848854
Validation loss: 1.5456402045424267

Epoch: 6| Step: 10
Training loss: 0.14562104642391205
Validation loss: 1.5198063010810523

Epoch: 6| Step: 11
Training loss: 0.081094890832901
Validation loss: 1.538107572063323

Epoch: 6| Step: 12
Training loss: 0.08173304796218872
Validation loss: 1.524483185942455

Epoch: 6| Step: 13
Training loss: 0.1138475090265274
Validation loss: 1.4977731858530352

Epoch: 446| Step: 0
Training loss: 0.0876227393746376
Validation loss: 1.4819827669410295

Epoch: 6| Step: 1
Training loss: 0.06884881854057312
Validation loss: 1.459138362638412

Epoch: 6| Step: 2
Training loss: 0.07755720615386963
Validation loss: 1.434650134014827

Epoch: 6| Step: 3
Training loss: 0.22228117287158966
Validation loss: 1.4518589563267206

Epoch: 6| Step: 4
Training loss: 0.09480811655521393
Validation loss: 1.4208439870547223

Epoch: 6| Step: 5
Training loss: 0.06514239311218262
Validation loss: 1.4075513783321585

Epoch: 6| Step: 6
Training loss: 0.09663989394903183
Validation loss: 1.4154448765580372

Epoch: 6| Step: 7
Training loss: 0.1569293886423111
Validation loss: 1.4157196142340218

Epoch: 6| Step: 8
Training loss: 0.08722896873950958
Validation loss: 1.4173891864797121

Epoch: 6| Step: 9
Training loss: 0.09543943405151367
Validation loss: 1.4468902657108922

Epoch: 6| Step: 10
Training loss: 0.16799455881118774
Validation loss: 1.452777434420842

Epoch: 6| Step: 11
Training loss: 0.10460516810417175
Validation loss: 1.4351179484398133

Epoch: 6| Step: 12
Training loss: 0.09940028190612793
Validation loss: 1.444408889739744

Epoch: 6| Step: 13
Training loss: 0.08398380875587463
Validation loss: 1.4451539516448975

Epoch: 447| Step: 0
Training loss: 0.11501812189817429
Validation loss: 1.4555376345111477

Epoch: 6| Step: 1
Training loss: 0.061635710299015045
Validation loss: 1.4455556529824451

Epoch: 6| Step: 2
Training loss: 0.0925208032131195
Validation loss: 1.4555942871237313

Epoch: 6| Step: 3
Training loss: 0.09851232171058655
Validation loss: 1.4409837453596053

Epoch: 6| Step: 4
Training loss: 0.30702751874923706
Validation loss: 1.442759257490917

Epoch: 6| Step: 5
Training loss: 0.07572340965270996
Validation loss: 1.43401204001519

Epoch: 6| Step: 6
Training loss: 0.11440066993236542
Validation loss: 1.420401547544746

Epoch: 6| Step: 7
Training loss: 0.10496377944946289
Validation loss: 1.4258837962663302

Epoch: 6| Step: 8
Training loss: 0.14835813641548157
Validation loss: 1.435977255144427

Epoch: 6| Step: 9
Training loss: 0.06907957047224045
Validation loss: 1.4535092717857772

Epoch: 6| Step: 10
Training loss: 0.12115741521120071
Validation loss: 1.457477520870906

Epoch: 6| Step: 11
Training loss: 0.17965102195739746
Validation loss: 1.415824108226325

Epoch: 6| Step: 12
Training loss: 0.11030881106853485
Validation loss: 1.4314700147157073

Epoch: 6| Step: 13
Training loss: 0.08882182091474533
Validation loss: 1.4497498748123006

Epoch: 448| Step: 0
Training loss: 0.06571920216083527
Validation loss: 1.4631583754734327

Epoch: 6| Step: 1
Training loss: 0.07074853032827377
Validation loss: 1.482725457478595

Epoch: 6| Step: 2
Training loss: 0.07814020663499832
Validation loss: 1.4808357851479643

Epoch: 6| Step: 3
Training loss: 0.09755392372608185
Validation loss: 1.4894523274513982

Epoch: 6| Step: 4
Training loss: 0.1350913643836975
Validation loss: 1.4898702995751494

Epoch: 6| Step: 5
Training loss: 0.048031602054834366
Validation loss: 1.4807876463859313

Epoch: 6| Step: 6
Training loss: 0.10220669209957123
Validation loss: 1.490821244255189

Epoch: 6| Step: 7
Training loss: 0.12474139779806137
Validation loss: 1.5133637484683786

Epoch: 6| Step: 8
Training loss: 0.1553541123867035
Validation loss: 1.4958581187391793

Epoch: 6| Step: 9
Training loss: 0.12701009213924408
Validation loss: 1.5079849381600656

Epoch: 6| Step: 10
Training loss: 0.06740245223045349
Validation loss: 1.4748768934639551

Epoch: 6| Step: 11
Training loss: 0.09724593907594681
Validation loss: 1.4608930310895365

Epoch: 6| Step: 12
Training loss: 0.08503890037536621
Validation loss: 1.4649455560150968

Epoch: 6| Step: 13
Training loss: 0.09316829591989517
Validation loss: 1.4720471482123099

Epoch: 449| Step: 0
Training loss: 0.07721308618783951
Validation loss: 1.4924539583985523

Epoch: 6| Step: 1
Training loss: 0.08987022936344147
Validation loss: 1.444123674464482

Epoch: 6| Step: 2
Training loss: 0.13359403610229492
Validation loss: 1.4576333286941692

Epoch: 6| Step: 3
Training loss: 0.10613350570201874
Validation loss: 1.484009696591285

Epoch: 6| Step: 4
Training loss: 0.04154060035943985
Validation loss: 1.5197248728044572

Epoch: 6| Step: 5
Training loss: 0.06480780243873596
Validation loss: 1.468380299947595

Epoch: 6| Step: 6
Training loss: 0.08920430392026901
Validation loss: 1.4677072853170416

Epoch: 6| Step: 7
Training loss: 0.13282302021980286
Validation loss: 1.4922000554300123

Epoch: 6| Step: 8
Training loss: 0.10068129003047943
Validation loss: 1.4805270189880042

Epoch: 6| Step: 9
Training loss: 0.1223105639219284
Validation loss: 1.4685057811839606

Epoch: 6| Step: 10
Training loss: 0.1214594617486
Validation loss: 1.4546311029823877

Epoch: 6| Step: 11
Training loss: 0.13133203983306885
Validation loss: 1.4451555436657322

Epoch: 6| Step: 12
Training loss: 0.06980317085981369
Validation loss: 1.4441172935629403

Epoch: 6| Step: 13
Training loss: 0.0597558431327343
Validation loss: 1.451141506113032

Epoch: 450| Step: 0
Training loss: 0.12953442335128784
Validation loss: 1.4547126549546436

Epoch: 6| Step: 1
Training loss: 0.1087656170129776
Validation loss: 1.4375312533429874

Epoch: 6| Step: 2
Training loss: 0.09503897279500961
Validation loss: 1.4011232186389226

Epoch: 6| Step: 3
Training loss: 0.0693107545375824
Validation loss: 1.412416140879354

Epoch: 6| Step: 4
Training loss: 0.10275958478450775
Validation loss: 1.4499397457286876

Epoch: 6| Step: 5
Training loss: 0.0978793352842331
Validation loss: 1.4489676401179323

Epoch: 6| Step: 6
Training loss: 0.08833526819944382
Validation loss: 1.4268597710517146

Epoch: 6| Step: 7
Training loss: 0.08343026787042618
Validation loss: 1.4570970368641678

Epoch: 6| Step: 8
Training loss: 0.10400894284248352
Validation loss: 1.4351494049513212

Epoch: 6| Step: 9
Training loss: 0.08212143182754517
Validation loss: 1.4560136718134726

Epoch: 6| Step: 10
Training loss: 0.2575688362121582
Validation loss: 1.482380602949409

Epoch: 6| Step: 11
Training loss: 0.09058989584445953
Validation loss: 1.4974004043045865

Epoch: 6| Step: 12
Training loss: 0.09519200026988983
Validation loss: 1.493402914334369

Epoch: 6| Step: 13
Training loss: 0.12234355509281158
Validation loss: 1.5229313271020049

Epoch: 451| Step: 0
Training loss: 0.14898428320884705
Validation loss: 1.5382621672845656

Epoch: 6| Step: 1
Training loss: 0.11710867285728455
Validation loss: 1.4996432604328278

Epoch: 6| Step: 2
Training loss: 0.05821527540683746
Validation loss: 1.4845044196292918

Epoch: 6| Step: 3
Training loss: 0.11428308486938477
Validation loss: 1.5173490175636866

Epoch: 6| Step: 4
Training loss: 0.08595748245716095
Validation loss: 1.4747933892793552

Epoch: 6| Step: 5
Training loss: 0.05833000689744949
Validation loss: 1.4790145222858717

Epoch: 6| Step: 6
Training loss: 0.0661202073097229
Validation loss: 1.462739367638865

Epoch: 6| Step: 7
Training loss: 0.10299865901470184
Validation loss: 1.477907185913414

Epoch: 6| Step: 8
Training loss: 0.12186296284198761
Validation loss: 1.4615191618601482

Epoch: 6| Step: 9
Training loss: 0.13717021048069
Validation loss: 1.4793031472031788

Epoch: 6| Step: 10
Training loss: 0.11086272448301315
Validation loss: 1.460820838969241

Epoch: 6| Step: 11
Training loss: 0.15368886291980743
Validation loss: 1.4538127183914185

Epoch: 6| Step: 12
Training loss: 0.13125422596931458
Validation loss: 1.4715218159460253

Epoch: 6| Step: 13
Training loss: 0.13754792511463165
Validation loss: 1.4858581994169502

Epoch: 452| Step: 0
Training loss: 0.08375854790210724
Validation loss: 1.4956973137394074

Epoch: 6| Step: 1
Training loss: 0.08174110949039459
Validation loss: 1.4877544667131157

Epoch: 6| Step: 2
Training loss: 0.09206132590770721
Validation loss: 1.4676937826218144

Epoch: 6| Step: 3
Training loss: 0.05212899297475815
Validation loss: 1.4611117173266668

Epoch: 6| Step: 4
Training loss: 0.11530960351228714
Validation loss: 1.4510266204034128

Epoch: 6| Step: 5
Training loss: 0.08775239437818527
Validation loss: 1.4567587003912976

Epoch: 6| Step: 6
Training loss: 0.14771229028701782
Validation loss: 1.461188268917863

Epoch: 6| Step: 7
Training loss: 0.07125481963157654
Validation loss: 1.468844573984864

Epoch: 6| Step: 8
Training loss: 0.1300601214170456
Validation loss: 1.4519286815838148

Epoch: 6| Step: 9
Training loss: 0.0898267924785614
Validation loss: 1.5027683152947375

Epoch: 6| Step: 10
Training loss: 0.15024293959140778
Validation loss: 1.4963698297418573

Epoch: 6| Step: 11
Training loss: 0.07754923403263092
Validation loss: 1.4974820742043116

Epoch: 6| Step: 12
Training loss: 0.08753374963998795
Validation loss: 1.4628957900949704

Epoch: 6| Step: 13
Training loss: 0.18288365006446838
Validation loss: 1.4842651659442532

Epoch: 453| Step: 0
Training loss: 0.10522126406431198
Validation loss: 1.4723276143432946

Epoch: 6| Step: 1
Training loss: 0.04415510594844818
Validation loss: 1.4610894854350756

Epoch: 6| Step: 2
Training loss: 0.09558229148387909
Validation loss: 1.4654438623818018

Epoch: 6| Step: 3
Training loss: 0.07521544396877289
Validation loss: 1.4580770698926782

Epoch: 6| Step: 4
Training loss: 0.08384546637535095
Validation loss: 1.4893358907391947

Epoch: 6| Step: 5
Training loss: 0.10329978168010712
Validation loss: 1.471175052786386

Epoch: 6| Step: 6
Training loss: 0.12761886417865753
Validation loss: 1.468672260161369

Epoch: 6| Step: 7
Training loss: 0.2048625349998474
Validation loss: 1.4630086454012061

Epoch: 6| Step: 8
Training loss: 0.04277634620666504
Validation loss: 1.4708038004495765

Epoch: 6| Step: 9
Training loss: 0.11216788738965988
Validation loss: 1.4442574811238114

Epoch: 6| Step: 10
Training loss: 0.09991185367107391
Validation loss: 1.456036360674007

Epoch: 6| Step: 11
Training loss: 0.12653467059135437
Validation loss: 1.486232570422593

Epoch: 6| Step: 12
Training loss: 0.10014709830284119
Validation loss: 1.461306025904994

Epoch: 6| Step: 13
Training loss: 0.06329968571662903
Validation loss: 1.4654405847672494

Epoch: 454| Step: 0
Training loss: 0.08565883338451385
Validation loss: 1.4781640242504817

Epoch: 6| Step: 1
Training loss: 0.09402389079332352
Validation loss: 1.46543655344235

Epoch: 6| Step: 2
Training loss: 0.09637460112571716
Validation loss: 1.4897282123565674

Epoch: 6| Step: 3
Training loss: 0.10561671853065491
Validation loss: 1.4601377517946306

Epoch: 6| Step: 4
Training loss: 0.06849078834056854
Validation loss: 1.4875103465972408

Epoch: 6| Step: 5
Training loss: 0.04477610066533089
Validation loss: 1.4637659185676164

Epoch: 6| Step: 6
Training loss: 0.08466780930757523
Validation loss: 1.4910029877898514

Epoch: 6| Step: 7
Training loss: 0.0915239006280899
Validation loss: 1.4873454288769794

Epoch: 6| Step: 8
Training loss: 0.11376552283763885
Validation loss: 1.4792990017962713

Epoch: 6| Step: 9
Training loss: 0.06173685938119888
Validation loss: 1.483811366942621

Epoch: 6| Step: 10
Training loss: 0.11511152982711792
Validation loss: 1.4418699677272508

Epoch: 6| Step: 11
Training loss: 0.11391834169626236
Validation loss: 1.443045425158675

Epoch: 6| Step: 12
Training loss: 0.10860154032707214
Validation loss: 1.459591632248253

Epoch: 6| Step: 13
Training loss: 0.06197669729590416
Validation loss: 1.453690194314526

Epoch: 455| Step: 0
Training loss: 0.05955497920513153
Validation loss: 1.4444231756271855

Epoch: 6| Step: 1
Training loss: 0.030349845066666603
Validation loss: 1.4782618668771559

Epoch: 6| Step: 2
Training loss: 0.10967078804969788
Validation loss: 1.4841284969801545

Epoch: 6| Step: 3
Training loss: 0.07825621217489243
Validation loss: 1.476387789172511

Epoch: 6| Step: 4
Training loss: 0.12413682043552399
Validation loss: 1.4873853691162602

Epoch: 6| Step: 5
Training loss: 0.07488321512937546
Validation loss: 1.479035565930028

Epoch: 6| Step: 6
Training loss: 0.05498433858156204
Validation loss: 1.4498314998483146

Epoch: 6| Step: 7
Training loss: 0.0665539801120758
Validation loss: 1.4871232778795305

Epoch: 6| Step: 8
Training loss: 0.13795717060565948
Validation loss: 1.4944146628020911

Epoch: 6| Step: 9
Training loss: 0.12923204898834229
Validation loss: 1.483379102522327

Epoch: 6| Step: 10
Training loss: 0.08582288771867752
Validation loss: 1.4482270210020003

Epoch: 6| Step: 11
Training loss: 0.10612677782773972
Validation loss: 1.4398769294061968

Epoch: 6| Step: 12
Training loss: 0.1000140905380249
Validation loss: 1.4708630474664832

Epoch: 6| Step: 13
Training loss: 0.11636732518672943
Validation loss: 1.4578723625470233

Epoch: 456| Step: 0
Training loss: 0.08453557640314102
Validation loss: 1.4591357067067137

Epoch: 6| Step: 1
Training loss: 0.07759971916675568
Validation loss: 1.4693216982708182

Epoch: 6| Step: 2
Training loss: 0.16144922375679016
Validation loss: 1.47982447249915

Epoch: 6| Step: 3
Training loss: 0.07725149393081665
Validation loss: 1.4916958475625643

Epoch: 6| Step: 4
Training loss: 0.15112030506134033
Validation loss: 1.4827632468233827

Epoch: 6| Step: 5
Training loss: 0.0890415832400322
Validation loss: 1.4645047815897132

Epoch: 6| Step: 6
Training loss: 0.0928376093506813
Validation loss: 1.4566089325053717

Epoch: 6| Step: 7
Training loss: 0.06042424589395523
Validation loss: 1.4544012969540012

Epoch: 6| Step: 8
Training loss: 0.13650216162204742
Validation loss: 1.449690649586339

Epoch: 6| Step: 9
Training loss: 0.05049408972263336
Validation loss: 1.4426522530535215

Epoch: 6| Step: 10
Training loss: 0.11265852302312851
Validation loss: 1.4792469880914176

Epoch: 6| Step: 11
Training loss: 0.1078079417347908
Validation loss: 1.4639072084939608

Epoch: 6| Step: 12
Training loss: 0.1329669952392578
Validation loss: 1.4735286851083078

Epoch: 6| Step: 13
Training loss: 0.09354361146688461
Validation loss: 1.4687370279783845

Epoch: 457| Step: 0
Training loss: 0.14313247799873352
Validation loss: 1.4814686826480332

Epoch: 6| Step: 1
Training loss: 0.05546724423766136
Validation loss: 1.4954437337895876

Epoch: 6| Step: 2
Training loss: 0.07937464863061905
Validation loss: 1.4798031391636017

Epoch: 6| Step: 3
Training loss: 0.07038511335849762
Validation loss: 1.459094742292999

Epoch: 6| Step: 4
Training loss: 0.07729948312044144
Validation loss: 1.480464603311272

Epoch: 6| Step: 5
Training loss: 0.14838995039463043
Validation loss: 1.4540803817010695

Epoch: 6| Step: 6
Training loss: 0.10911846905946732
Validation loss: 1.4577902273465229

Epoch: 6| Step: 7
Training loss: 0.1159791648387909
Validation loss: 1.4442473624342231

Epoch: 6| Step: 8
Training loss: 0.07832281291484833
Validation loss: 1.4241518064211773

Epoch: 6| Step: 9
Training loss: 0.14576908946037292
Validation loss: 1.3977837511288222

Epoch: 6| Step: 10
Training loss: 0.09380275011062622
Validation loss: 1.4118491033072114

Epoch: 6| Step: 11
Training loss: 0.07539641112089157
Validation loss: 1.4305496023547264

Epoch: 6| Step: 12
Training loss: 0.10359060019254684
Validation loss: 1.4374269080418411

Epoch: 6| Step: 13
Training loss: 0.14939798414707184
Validation loss: 1.4079953688447193

Epoch: 458| Step: 0
Training loss: 0.15527167916297913
Validation loss: 1.442906734763935

Epoch: 6| Step: 1
Training loss: 0.10396958142518997
Validation loss: 1.4337552632054975

Epoch: 6| Step: 2
Training loss: 0.08276233077049255
Validation loss: 1.4358856370372157

Epoch: 6| Step: 3
Training loss: 0.09983190894126892
Validation loss: 1.4555030952217758

Epoch: 6| Step: 4
Training loss: 0.07891441881656647
Validation loss: 1.4598179606981174

Epoch: 6| Step: 5
Training loss: 0.076555036008358
Validation loss: 1.4776166472383725

Epoch: 6| Step: 6
Training loss: 0.0872654914855957
Validation loss: 1.4623603384981874

Epoch: 6| Step: 7
Training loss: 0.1412447690963745
Validation loss: 1.482300466106784

Epoch: 6| Step: 8
Training loss: 0.15070712566375732
Validation loss: 1.4705302510210263

Epoch: 6| Step: 9
Training loss: 0.09093943983316422
Validation loss: 1.4856533542756112

Epoch: 6| Step: 10
Training loss: 0.17383816838264465
Validation loss: 1.4658926808705894

Epoch: 6| Step: 11
Training loss: 0.059021055698394775
Validation loss: 1.455014536457677

Epoch: 6| Step: 12
Training loss: 0.06962906569242477
Validation loss: 1.4524061372203212

Epoch: 6| Step: 13
Training loss: 0.03816068172454834
Validation loss: 1.4705875381346671

Epoch: 459| Step: 0
Training loss: 0.11380156874656677
Validation loss: 1.4829207146039574

Epoch: 6| Step: 1
Training loss: 0.07533210515975952
Validation loss: 1.4683678560359503

Epoch: 6| Step: 2
Training loss: 0.10889533162117004
Validation loss: 1.4751707135990102

Epoch: 6| Step: 3
Training loss: 0.06770861148834229
Validation loss: 1.4664438104116788

Epoch: 6| Step: 4
Training loss: 0.1133512482047081
Validation loss: 1.4772696277146697

Epoch: 6| Step: 5
Training loss: 0.07247468084096909
Validation loss: 1.4592735869910127

Epoch: 6| Step: 6
Training loss: 0.06980954855680466
Validation loss: 1.428973081932273

Epoch: 6| Step: 7
Training loss: 0.14799705147743225
Validation loss: 1.4496886371284403

Epoch: 6| Step: 8
Training loss: 0.09705963730812073
Validation loss: 1.4221918685461885

Epoch: 6| Step: 9
Training loss: 0.09259834885597229
Validation loss: 1.4216694806211738

Epoch: 6| Step: 10
Training loss: 0.07015195488929749
Validation loss: 1.430067757124542

Epoch: 6| Step: 11
Training loss: 0.06413811445236206
Validation loss: 1.460469130546816

Epoch: 6| Step: 12
Training loss: 0.06560041755437851
Validation loss: 1.4413531159841886

Epoch: 6| Step: 13
Training loss: 0.10271432995796204
Validation loss: 1.443289779847668

Epoch: 460| Step: 0
Training loss: 0.0656655952334404
Validation loss: 1.4438372658145042

Epoch: 6| Step: 1
Training loss: 0.08332693576812744
Validation loss: 1.4471981448511924

Epoch: 6| Step: 2
Training loss: 0.13127705454826355
Validation loss: 1.4529752295504335

Epoch: 6| Step: 3
Training loss: 0.11171463876962662
Validation loss: 1.4432890158827587

Epoch: 6| Step: 4
Training loss: 0.09217893332242966
Validation loss: 1.444311003531179

Epoch: 6| Step: 5
Training loss: 0.05836033076047897
Validation loss: 1.4300184698515042

Epoch: 6| Step: 6
Training loss: 0.07170072942972183
Validation loss: 1.4672957851040749

Epoch: 6| Step: 7
Training loss: 0.06570936739444733
Validation loss: 1.4380833935993973

Epoch: 6| Step: 8
Training loss: 0.09171241521835327
Validation loss: 1.4289790750831686

Epoch: 6| Step: 9
Training loss: 0.055945996195077896
Validation loss: 1.4579015771547954

Epoch: 6| Step: 10
Training loss: 0.069307841360569
Validation loss: 1.435254131594012

Epoch: 6| Step: 11
Training loss: 0.08356975764036179
Validation loss: 1.4200295735430974

Epoch: 6| Step: 12
Training loss: 0.16015613079071045
Validation loss: 1.4548513402221024

Epoch: 6| Step: 13
Training loss: 0.11156754940748215
Validation loss: 1.4535010181447512

Epoch: 461| Step: 0
Training loss: 0.062223777174949646
Validation loss: 1.4695975447213778

Epoch: 6| Step: 1
Training loss: 0.08070845901966095
Validation loss: 1.4562214202778314

Epoch: 6| Step: 2
Training loss: 0.09054230153560638
Validation loss: 1.4728946929336877

Epoch: 6| Step: 3
Training loss: 0.07809251546859741
Validation loss: 1.4837294983607467

Epoch: 6| Step: 4
Training loss: 0.07927339524030685
Validation loss: 1.4623617799051347

Epoch: 6| Step: 5
Training loss: 0.08558860421180725
Validation loss: 1.466762440178984

Epoch: 6| Step: 6
Training loss: 0.059311650693416595
Validation loss: 1.456116582116773

Epoch: 6| Step: 7
Training loss: 0.07061263918876648
Validation loss: 1.4492006032697615

Epoch: 6| Step: 8
Training loss: 0.06164716184139252
Validation loss: 1.4605036550952541

Epoch: 6| Step: 9
Training loss: 0.06709469854831696
Validation loss: 1.4535096883773804

Epoch: 6| Step: 10
Training loss: 0.14788226783275604
Validation loss: 1.4387440155911189

Epoch: 6| Step: 11
Training loss: 0.0941673144698143
Validation loss: 1.4339296228142195

Epoch: 6| Step: 12
Training loss: 0.08380807936191559
Validation loss: 1.451860616284032

Epoch: 6| Step: 13
Training loss: 0.10219177603721619
Validation loss: 1.4562351331915906

Epoch: 462| Step: 0
Training loss: 0.14051027595996857
Validation loss: 1.4502904094675535

Epoch: 6| Step: 1
Training loss: 0.08290669322013855
Validation loss: 1.4793016308097429

Epoch: 6| Step: 2
Training loss: 0.05822804570198059
Validation loss: 1.52922281014022

Epoch: 6| Step: 3
Training loss: 0.08468841016292572
Validation loss: 1.4816487463571693

Epoch: 6| Step: 4
Training loss: 0.08459359407424927
Validation loss: 1.5314386852325932

Epoch: 6| Step: 5
Training loss: 0.07304731011390686
Validation loss: 1.5484597862407725

Epoch: 6| Step: 6
Training loss: 0.07967577129602432
Validation loss: 1.5660347195081814

Epoch: 6| Step: 7
Training loss: 0.06206468865275383
Validation loss: 1.5650170336487472

Epoch: 6| Step: 8
Training loss: 0.08324594795703888
Validation loss: 1.5254925271516204

Epoch: 6| Step: 9
Training loss: 0.1079525351524353
Validation loss: 1.523220835193511

Epoch: 6| Step: 10
Training loss: 0.1206083744764328
Validation loss: 1.4820042041040236

Epoch: 6| Step: 11
Training loss: 0.11937645077705383
Validation loss: 1.5045879271722609

Epoch: 6| Step: 12
Training loss: 0.13430356979370117
Validation loss: 1.4544162538743788

Epoch: 6| Step: 13
Training loss: 0.08540313690900803
Validation loss: 1.4266806507623324

Epoch: 463| Step: 0
Training loss: 0.04297304153442383
Validation loss: 1.432944095262917

Epoch: 6| Step: 1
Training loss: 0.09554693102836609
Validation loss: 1.3924615780512493

Epoch: 6| Step: 2
Training loss: 0.084787517786026
Validation loss: 1.3872861080272223

Epoch: 6| Step: 3
Training loss: 0.14517167210578918
Validation loss: 1.3846279010977796

Epoch: 6| Step: 4
Training loss: 0.107905313372612
Validation loss: 1.3693348656418503

Epoch: 6| Step: 5
Training loss: 0.11883843690156937
Validation loss: 1.3774905884137718

Epoch: 6| Step: 6
Training loss: 0.11454334110021591
Validation loss: 1.3528030072489092

Epoch: 6| Step: 7
Training loss: 0.0919436365365982
Validation loss: 1.3819219322614773

Epoch: 6| Step: 8
Training loss: 0.07003994286060333
Validation loss: 1.388722753012052

Epoch: 6| Step: 9
Training loss: 0.07521812617778778
Validation loss: 1.4113384613426783

Epoch: 6| Step: 10
Training loss: 0.15262353420257568
Validation loss: 1.429564090185268

Epoch: 6| Step: 11
Training loss: 0.11967843770980835
Validation loss: 1.4414644497697071

Epoch: 6| Step: 12
Training loss: 0.22829164564609528
Validation loss: 1.4475024502764466

Epoch: 6| Step: 13
Training loss: 0.08791106194257736
Validation loss: 1.4463481339075233

Epoch: 464| Step: 0
Training loss: 0.09566352516412735
Validation loss: 1.4629504244814637

Epoch: 6| Step: 1
Training loss: 0.11653125286102295
Validation loss: 1.445355971654256

Epoch: 6| Step: 2
Training loss: 0.10214653611183167
Validation loss: 1.4389638439301522

Epoch: 6| Step: 3
Training loss: 0.09831182658672333
Validation loss: 1.4551680703316965

Epoch: 6| Step: 4
Training loss: 0.1715923547744751
Validation loss: 1.4385747127635504

Epoch: 6| Step: 5
Training loss: 0.08093735575675964
Validation loss: 1.453238606452942

Epoch: 6| Step: 6
Training loss: 0.07217061519622803
Validation loss: 1.4174523289485643

Epoch: 6| Step: 7
Training loss: 0.09795517474412918
Validation loss: 1.4101241686010872

Epoch: 6| Step: 8
Training loss: 0.10964665561914444
Validation loss: 1.4053053323940565

Epoch: 6| Step: 9
Training loss: 0.061624377965927124
Validation loss: 1.3996746770797237

Epoch: 6| Step: 10
Training loss: 0.07564278692007065
Validation loss: 1.4365815859968945

Epoch: 6| Step: 11
Training loss: 0.11551079154014587
Validation loss: 1.3959407729487265

Epoch: 6| Step: 12
Training loss: 0.11856809258460999
Validation loss: 1.4267994844785301

Epoch: 6| Step: 13
Training loss: 0.09436799585819244
Validation loss: 1.4158336834240985

Epoch: 465| Step: 0
Training loss: 0.06306958198547363
Validation loss: 1.4258141017729236

Epoch: 6| Step: 1
Training loss: 0.057834185659885406
Validation loss: 1.4316938154159053

Epoch: 6| Step: 2
Training loss: 0.08316761255264282
Validation loss: 1.4640571148164812

Epoch: 6| Step: 3
Training loss: 0.07039665430784225
Validation loss: 1.4540737008535733

Epoch: 6| Step: 4
Training loss: 0.05515661835670471
Validation loss: 1.4404673473809355

Epoch: 6| Step: 5
Training loss: 0.0674113929271698
Validation loss: 1.4493495969362156

Epoch: 6| Step: 6
Training loss: 0.08788290619850159
Validation loss: 1.4492856161568755

Epoch: 6| Step: 7
Training loss: 0.08159971237182617
Validation loss: 1.4572403161756453

Epoch: 6| Step: 8
Training loss: 0.05253271758556366
Validation loss: 1.462164476353635

Epoch: 6| Step: 9
Training loss: 0.19944122433662415
Validation loss: 1.4494840278420398

Epoch: 6| Step: 10
Training loss: 0.08075814694166183
Validation loss: 1.419694914612719

Epoch: 6| Step: 11
Training loss: 0.11014033854007721
Validation loss: 1.4259318190236245

Epoch: 6| Step: 12
Training loss: 0.05508382245898247
Validation loss: 1.4370321701931696

Epoch: 6| Step: 13
Training loss: 0.05086652189493179
Validation loss: 1.4103563216424757

Epoch: 466| Step: 0
Training loss: 0.05773621425032616
Validation loss: 1.4479481661191551

Epoch: 6| Step: 1
Training loss: 0.06338712573051453
Validation loss: 1.4372870217087448

Epoch: 6| Step: 2
Training loss: 0.08800168335437775
Validation loss: 1.4616766616862307

Epoch: 6| Step: 3
Training loss: 0.07659463584423065
Validation loss: 1.4551426595257175

Epoch: 6| Step: 4
Training loss: 0.099433034658432
Validation loss: 1.4763480527426607

Epoch: 6| Step: 5
Training loss: 0.0909917801618576
Validation loss: 1.459968659185594

Epoch: 6| Step: 6
Training loss: 0.08890469372272491
Validation loss: 1.440539304928113

Epoch: 6| Step: 7
Training loss: 0.0565858893096447
Validation loss: 1.4569647183982275

Epoch: 6| Step: 8
Training loss: 0.07566995918750763
Validation loss: 1.4727102428354242

Epoch: 6| Step: 9
Training loss: 0.07144944369792938
Validation loss: 1.4826071967360794

Epoch: 6| Step: 10
Training loss: 0.06551609933376312
Validation loss: 1.4830640964610602

Epoch: 6| Step: 11
Training loss: 0.24599896371364594
Validation loss: 1.4744705730868923

Epoch: 6| Step: 12
Training loss: 0.06568354368209839
Validation loss: 1.4694858943262408

Epoch: 6| Step: 13
Training loss: 0.07913992553949356
Validation loss: 1.4828073055513444

Epoch: 467| Step: 0
Training loss: 0.0899408608675003
Validation loss: 1.4732414061023342

Epoch: 6| Step: 1
Training loss: 0.0645589828491211
Validation loss: 1.466435815698357

Epoch: 6| Step: 2
Training loss: 0.06614036858081818
Validation loss: 1.4688851756434287

Epoch: 6| Step: 3
Training loss: 0.10017917305231094
Validation loss: 1.4424932413203742

Epoch: 6| Step: 4
Training loss: 0.12983721494674683
Validation loss: 1.4071018907331652

Epoch: 6| Step: 5
Training loss: 0.0812140703201294
Validation loss: 1.4339900080875685

Epoch: 6| Step: 6
Training loss: 0.0865645781159401
Validation loss: 1.3854342660596293

Epoch: 6| Step: 7
Training loss: 0.07189559191465378
Validation loss: 1.3987618761677896

Epoch: 6| Step: 8
Training loss: 0.151271790266037
Validation loss: 1.4307734915005264

Epoch: 6| Step: 9
Training loss: 0.08817952871322632
Validation loss: 1.3843646254590762

Epoch: 6| Step: 10
Training loss: 0.08854833990335464
Validation loss: 1.4242332891751361

Epoch: 6| Step: 11
Training loss: 0.04555873945355415
Validation loss: 1.4212112798485705

Epoch: 6| Step: 12
Training loss: 0.0762554407119751
Validation loss: 1.4248283883576751

Epoch: 6| Step: 13
Training loss: 0.09512437880039215
Validation loss: 1.4423412405034548

Epoch: 468| Step: 0
Training loss: 0.06417809426784515
Validation loss: 1.415359527834

Epoch: 6| Step: 1
Training loss: 0.07978345453739166
Validation loss: 1.4373665022593674

Epoch: 6| Step: 2
Training loss: 0.07963831722736359
Validation loss: 1.478696891056594

Epoch: 6| Step: 3
Training loss: 0.08020856231451035
Validation loss: 1.438011864180206

Epoch: 6| Step: 4
Training loss: 0.06642176955938339
Validation loss: 1.4813548467492546

Epoch: 6| Step: 5
Training loss: 0.06890959292650223
Validation loss: 1.4511582620682255

Epoch: 6| Step: 6
Training loss: 0.05801776796579361
Validation loss: 1.4562590916951497

Epoch: 6| Step: 7
Training loss: 0.05423753708600998
Validation loss: 1.4944084395644486

Epoch: 6| Step: 8
Training loss: 0.05674558877944946
Validation loss: 1.4853610364339684

Epoch: 6| Step: 9
Training loss: 0.06157417595386505
Validation loss: 1.4662113099969842

Epoch: 6| Step: 10
Training loss: 0.08763321489095688
Validation loss: 1.475328165997741

Epoch: 6| Step: 11
Training loss: 0.18141233921051025
Validation loss: 1.5093783383728356

Epoch: 6| Step: 12
Training loss: 0.09863706678152084
Validation loss: 1.497868658393942

Epoch: 6| Step: 13
Training loss: 0.06679022312164307
Validation loss: 1.4975529716860863

Epoch: 469| Step: 0
Training loss: 0.07160414755344391
Validation loss: 1.504710305121637

Epoch: 6| Step: 1
Training loss: 0.10598629713058472
Validation loss: 1.4907496763813881

Epoch: 6| Step: 2
Training loss: 0.09445205330848694
Validation loss: 1.4999973927774737

Epoch: 6| Step: 3
Training loss: 0.08123849332332611
Validation loss: 1.4968742516732985

Epoch: 6| Step: 4
Training loss: 0.06290467083454132
Validation loss: 1.489837097865279

Epoch: 6| Step: 5
Training loss: 0.09458211064338684
Validation loss: 1.4800155829357844

Epoch: 6| Step: 6
Training loss: 0.13710108399391174
Validation loss: 1.5090851706843222

Epoch: 6| Step: 7
Training loss: 0.059274815022945404
Validation loss: 1.4908067385355632

Epoch: 6| Step: 8
Training loss: 0.1645307093858719
Validation loss: 1.487704752593912

Epoch: 6| Step: 9
Training loss: 0.06969652324914932
Validation loss: 1.4605599282890238

Epoch: 6| Step: 10
Training loss: 0.10433105379343033
Validation loss: 1.4437828999693676

Epoch: 6| Step: 11
Training loss: 0.05418258160352707
Validation loss: 1.4474406998644593

Epoch: 6| Step: 12
Training loss: 0.06654097139835358
Validation loss: 1.429776373729911

Epoch: 6| Step: 13
Training loss: 0.11247997730970383
Validation loss: 1.436562866292974

Epoch: 470| Step: 0
Training loss: 0.07613244652748108
Validation loss: 1.43447676268957

Epoch: 6| Step: 1
Training loss: 0.05580740049481392
Validation loss: 1.4910663045862669

Epoch: 6| Step: 2
Training loss: 0.10593534260988235
Validation loss: 1.461588869812668

Epoch: 6| Step: 3
Training loss: 0.04864173009991646
Validation loss: 1.4567312476455525

Epoch: 6| Step: 4
Training loss: 0.1792689859867096
Validation loss: 1.4752281353037844

Epoch: 6| Step: 5
Training loss: 0.06615316867828369
Validation loss: 1.4658789378340527

Epoch: 6| Step: 6
Training loss: 0.042742304503917694
Validation loss: 1.4798257261194208

Epoch: 6| Step: 7
Training loss: 0.047819606959819794
Validation loss: 1.4586276469692108

Epoch: 6| Step: 8
Training loss: 0.06847409904003143
Validation loss: 1.4645628711228729

Epoch: 6| Step: 9
Training loss: 0.10311317443847656
Validation loss: 1.4601185078262

Epoch: 6| Step: 10
Training loss: 0.07948188483715057
Validation loss: 1.4503636270441034

Epoch: 6| Step: 11
Training loss: 0.04835464805364609
Validation loss: 1.4455310875369656

Epoch: 6| Step: 12
Training loss: 0.05316697806119919
Validation loss: 1.4250749131684661

Epoch: 6| Step: 13
Training loss: 0.0863778218626976
Validation loss: 1.4507787342994445

Epoch: 471| Step: 0
Training loss: 0.08399137854576111
Validation loss: 1.4480502413165184

Epoch: 6| Step: 1
Training loss: 0.16945119202136993
Validation loss: 1.397975807548851

Epoch: 6| Step: 2
Training loss: 0.08031211793422699
Validation loss: 1.4312917071004068

Epoch: 6| Step: 3
Training loss: 0.0878620594739914
Validation loss: 1.4249017533435617

Epoch: 6| Step: 4
Training loss: 0.06733766198158264
Validation loss: 1.4338822454534552

Epoch: 6| Step: 5
Training loss: 0.07531952857971191
Validation loss: 1.4358766604495306

Epoch: 6| Step: 6
Training loss: 0.05661875009536743
Validation loss: 1.447056951702282

Epoch: 6| Step: 7
Training loss: 0.09106498211622238
Validation loss: 1.4223631658861715

Epoch: 6| Step: 8
Training loss: 0.06343889981508255
Validation loss: 1.4687212718430387

Epoch: 6| Step: 9
Training loss: 0.05793832987546921
Validation loss: 1.450706365928855

Epoch: 6| Step: 10
Training loss: 0.09001331031322479
Validation loss: 1.4555049506566857

Epoch: 6| Step: 11
Training loss: 0.05148378014564514
Validation loss: 1.4530999910446905

Epoch: 6| Step: 12
Training loss: 0.0936058759689331
Validation loss: 1.4634085175811604

Epoch: 6| Step: 13
Training loss: 0.050082020461559296
Validation loss: 1.435325240576139

Epoch: 472| Step: 0
Training loss: 0.059007678180933
Validation loss: 1.4656892694452757

Epoch: 6| Step: 1
Training loss: 0.03700447827577591
Validation loss: 1.5032362156016852

Epoch: 6| Step: 2
Training loss: 0.042624905705451965
Validation loss: 1.444024625644889

Epoch: 6| Step: 3
Training loss: 0.07346638292074203
Validation loss: 1.4630865422628259

Epoch: 6| Step: 4
Training loss: 0.07493715733289719
Validation loss: 1.4496500312641103

Epoch: 6| Step: 5
Training loss: 0.11280567944049835
Validation loss: 1.4384161054447133

Epoch: 6| Step: 6
Training loss: 0.11097387224435806
Validation loss: 1.4592682943549207

Epoch: 6| Step: 7
Training loss: 0.12536492943763733
Validation loss: 1.481053844574959

Epoch: 6| Step: 8
Training loss: 0.10826387256383896
Validation loss: 1.4638865417049778

Epoch: 6| Step: 9
Training loss: 0.05753204599022865
Validation loss: 1.4420790146755915

Epoch: 6| Step: 10
Training loss: 0.0759962946176529
Validation loss: 1.4838072535812215

Epoch: 6| Step: 11
Training loss: 0.08255326747894287
Validation loss: 1.4610499547373863

Epoch: 6| Step: 12
Training loss: 0.0936979204416275
Validation loss: 1.435105464791739

Epoch: 6| Step: 13
Training loss: 0.062376923859119415
Validation loss: 1.4506517430787444

Epoch: 473| Step: 0
Training loss: 0.06209421157836914
Validation loss: 1.4481585692333918

Epoch: 6| Step: 1
Training loss: 0.06961444020271301
Validation loss: 1.4432417686267565

Epoch: 6| Step: 2
Training loss: 0.16409936547279358
Validation loss: 1.440053584755108

Epoch: 6| Step: 3
Training loss: 0.10990872979164124
Validation loss: 1.4410560554073704

Epoch: 6| Step: 4
Training loss: 0.08853573352098465
Validation loss: 1.4513807207025506

Epoch: 6| Step: 5
Training loss: 0.1304713487625122
Validation loss: 1.4489000125597882

Epoch: 6| Step: 6
Training loss: 0.07643484324216843
Validation loss: 1.4844952706367738

Epoch: 6| Step: 7
Training loss: 0.060933567583560944
Validation loss: 1.4728856202094787

Epoch: 6| Step: 8
Training loss: 0.0765058845281601
Validation loss: 1.4847327227233558

Epoch: 6| Step: 9
Training loss: 0.111171193420887
Validation loss: 1.4903638452611945

Epoch: 6| Step: 10
Training loss: 0.0823533684015274
Validation loss: 1.4705372113053516

Epoch: 6| Step: 11
Training loss: 0.08970943093299866
Validation loss: 1.452551341825916

Epoch: 6| Step: 12
Training loss: 0.0662519559264183
Validation loss: 1.425409504162368

Epoch: 6| Step: 13
Training loss: 0.06045309081673622
Validation loss: 1.418819962009307

Epoch: 474| Step: 0
Training loss: 0.09228375554084778
Validation loss: 1.403998633866669

Epoch: 6| Step: 1
Training loss: 0.07813916355371475
Validation loss: 1.4078370217354066

Epoch: 6| Step: 2
Training loss: 0.12848225235939026
Validation loss: 1.3974540041339012

Epoch: 6| Step: 3
Training loss: 0.14684811234474182
Validation loss: 1.4372921643718597

Epoch: 6| Step: 4
Training loss: 0.07504410296678543
Validation loss: 1.4189849502296858

Epoch: 6| Step: 5
Training loss: 0.07019997388124466
Validation loss: 1.4399524363138343

Epoch: 6| Step: 6
Training loss: 0.07802043855190277
Validation loss: 1.4685844964878534

Epoch: 6| Step: 7
Training loss: 0.04059705510735512
Validation loss: 1.4463208465165989

Epoch: 6| Step: 8
Training loss: 0.09021146595478058
Validation loss: 1.4656649827957153

Epoch: 6| Step: 9
Training loss: 0.07759604603052139
Validation loss: 1.4704821648136261

Epoch: 6| Step: 10
Training loss: 0.08904039114713669
Validation loss: 1.5152712252832228

Epoch: 6| Step: 11
Training loss: 0.09659884124994278
Validation loss: 1.5043467578067575

Epoch: 6| Step: 12
Training loss: 0.08141361176967621
Validation loss: 1.4835622631093508

Epoch: 6| Step: 13
Training loss: 0.09391244500875473
Validation loss: 1.4957485339974845

Epoch: 475| Step: 0
Training loss: 0.11518710106611252
Validation loss: 1.4555223206038117

Epoch: 6| Step: 1
Training loss: 0.07780185341835022
Validation loss: 1.4459024885649323

Epoch: 6| Step: 2
Training loss: 0.08403700590133667
Validation loss: 1.4460004029735443

Epoch: 6| Step: 3
Training loss: 0.07041437923908234
Validation loss: 1.4620136804478143

Epoch: 6| Step: 4
Training loss: 0.10596861690282822
Validation loss: 1.4661235181234216

Epoch: 6| Step: 5
Training loss: 0.08687496930360794
Validation loss: 1.4596732354933215

Epoch: 6| Step: 6
Training loss: 0.0711652934551239
Validation loss: 1.4308791160583496

Epoch: 6| Step: 7
Training loss: 0.17680153250694275
Validation loss: 1.4434681323266798

Epoch: 6| Step: 8
Training loss: 0.1269766241312027
Validation loss: 1.4694064137756184

Epoch: 6| Step: 9
Training loss: 0.09872407466173172
Validation loss: 1.4552724053782802

Epoch: 6| Step: 10
Training loss: 0.10476584732532501
Validation loss: 1.4847736961098128

Epoch: 6| Step: 11
Training loss: 0.08710387349128723
Validation loss: 1.4916666964048981

Epoch: 6| Step: 12
Training loss: 0.05005412548780441
Validation loss: 1.5250837687523133

Epoch: 6| Step: 13
Training loss: 0.03093530423939228
Validation loss: 1.5293747032842329

Epoch: 476| Step: 0
Training loss: 0.08882518857717514
Validation loss: 1.5372605528882755

Epoch: 6| Step: 1
Training loss: 0.06771314144134521
Validation loss: 1.5597787851928382

Epoch: 6| Step: 2
Training loss: 0.11249363422393799
Validation loss: 1.5744481035458144

Epoch: 6| Step: 3
Training loss: 0.10163771361112595
Validation loss: 1.5753498141483595

Epoch: 6| Step: 4
Training loss: 0.10975278913974762
Validation loss: 1.5391969578240507

Epoch: 6| Step: 5
Training loss: 0.0898451954126358
Validation loss: 1.5108109366509221

Epoch: 6| Step: 6
Training loss: 0.0892980620265007
Validation loss: 1.4787876388078094

Epoch: 6| Step: 7
Training loss: 0.13383972644805908
Validation loss: 1.4656204164669078

Epoch: 6| Step: 8
Training loss: 0.11729120463132858
Validation loss: 1.4383319244589856

Epoch: 6| Step: 9
Training loss: 0.10754361003637314
Validation loss: 1.435045192959488

Epoch: 6| Step: 10
Training loss: 0.07407248020172119
Validation loss: 1.4403028577886603

Epoch: 6| Step: 11
Training loss: 0.10937073081731796
Validation loss: 1.4199782411257427

Epoch: 6| Step: 12
Training loss: 0.11169417202472687
Validation loss: 1.451959607421711

Epoch: 6| Step: 13
Training loss: 0.05782090127468109
Validation loss: 1.4341252516674738

Epoch: 477| Step: 0
Training loss: 0.09855689853429794
Validation loss: 1.448075638022474

Epoch: 6| Step: 1
Training loss: 0.09036913514137268
Validation loss: 1.423298466590143

Epoch: 6| Step: 2
Training loss: 0.061500225216150284
Validation loss: 1.4402484291343278

Epoch: 6| Step: 3
Training loss: 0.06140720844268799
Validation loss: 1.4639939723476287

Epoch: 6| Step: 4
Training loss: 0.07733042538166046
Validation loss: 1.486973012647321

Epoch: 6| Step: 5
Training loss: 0.09572118520736694
Validation loss: 1.500705539539296

Epoch: 6| Step: 6
Training loss: 0.12271550297737122
Validation loss: 1.5104191482708018

Epoch: 6| Step: 7
Training loss: 0.04707085341215134
Validation loss: 1.482025473348556

Epoch: 6| Step: 8
Training loss: 0.13447202742099762
Validation loss: 1.5211028809188514

Epoch: 6| Step: 9
Training loss: 0.10724249482154846
Validation loss: 1.5139526372314782

Epoch: 6| Step: 10
Training loss: 0.11223509162664413
Validation loss: 1.500419109098373

Epoch: 6| Step: 11
Training loss: 0.1137162297964096
Validation loss: 1.478286898264321

Epoch: 6| Step: 12
Training loss: 0.09669795632362366
Validation loss: 1.4775455844017766

Epoch: 6| Step: 13
Training loss: 0.1309150606393814
Validation loss: 1.4473591530194847

Epoch: 478| Step: 0
Training loss: 0.1466125249862671
Validation loss: 1.4350161449883574

Epoch: 6| Step: 1
Training loss: 0.08566271513700485
Validation loss: 1.4435278907898934

Epoch: 6| Step: 2
Training loss: 0.10539411008358002
Validation loss: 1.4360377916725733

Epoch: 6| Step: 3
Training loss: 0.12704922258853912
Validation loss: 1.4448531353345482

Epoch: 6| Step: 4
Training loss: 0.0799519419670105
Validation loss: 1.434904408070349

Epoch: 6| Step: 5
Training loss: 0.08710891753435135
Validation loss: 1.434835934510795

Epoch: 6| Step: 6
Training loss: 0.09429675340652466
Validation loss: 1.449492730120177

Epoch: 6| Step: 7
Training loss: 0.07133281230926514
Validation loss: 1.455442060706436

Epoch: 6| Step: 8
Training loss: 0.13333240151405334
Validation loss: 1.4628687212544103

Epoch: 6| Step: 9
Training loss: 0.13464030623435974
Validation loss: 1.5027544395897978

Epoch: 6| Step: 10
Training loss: 0.08194566518068314
Validation loss: 1.490619872846911

Epoch: 6| Step: 11
Training loss: 0.10420237481594086
Validation loss: 1.4832036020935222

Epoch: 6| Step: 12
Training loss: 0.09999255836009979
Validation loss: 1.4788598475917694

Epoch: 6| Step: 13
Training loss: 0.07191554456949234
Validation loss: 1.4824658760460474

Epoch: 479| Step: 0
Training loss: 0.064337819814682
Validation loss: 1.4484343118565057

Epoch: 6| Step: 1
Training loss: 0.07212672382593155
Validation loss: 1.4523714229624758

Epoch: 6| Step: 2
Training loss: 0.07848107069730759
Validation loss: 1.4202176255564536

Epoch: 6| Step: 3
Training loss: 0.13009916245937347
Validation loss: 1.4451442085286623

Epoch: 6| Step: 4
Training loss: 0.05096681788563728
Validation loss: 1.4092890037003385

Epoch: 6| Step: 5
Training loss: 0.07007300108671188
Validation loss: 1.3715544823677308

Epoch: 6| Step: 6
Training loss: 0.08746042847633362
Validation loss: 1.3944289286931355

Epoch: 6| Step: 7
Training loss: 0.0855146050453186
Validation loss: 1.369713693536738

Epoch: 6| Step: 8
Training loss: 0.04078056663274765
Validation loss: 1.3991555436964958

Epoch: 6| Step: 9
Training loss: 0.05415123701095581
Validation loss: 1.398465165527918

Epoch: 6| Step: 10
Training loss: 0.05642301216721535
Validation loss: 1.4047447302008187

Epoch: 6| Step: 11
Training loss: 0.08558276295661926
Validation loss: 1.4505503293006652

Epoch: 6| Step: 12
Training loss: 0.1059960126876831
Validation loss: 1.4767204587177565

Epoch: 6| Step: 13
Training loss: 0.06543966382741928
Validation loss: 1.48266799219193

Epoch: 480| Step: 0
Training loss: 0.08342684060335159
Validation loss: 1.4673257156084942

Epoch: 6| Step: 1
Training loss: 0.051766909658908844
Validation loss: 1.424070116012327

Epoch: 6| Step: 2
Training loss: 0.05164547637104988
Validation loss: 1.424144915355149

Epoch: 6| Step: 3
Training loss: 0.07530610263347626
Validation loss: 1.4183718953081357

Epoch: 6| Step: 4
Training loss: 0.07520663738250732
Validation loss: 1.3842285281868392

Epoch: 6| Step: 5
Training loss: 0.1599903702735901
Validation loss: 1.3493106647204327

Epoch: 6| Step: 6
Training loss: 0.1173493042588234
Validation loss: 1.35440247033232

Epoch: 6| Step: 7
Training loss: 0.058346327394247055
Validation loss: 1.3593977664106636

Epoch: 6| Step: 8
Training loss: 0.07404226064682007
Validation loss: 1.3858374869951637

Epoch: 6| Step: 9
Training loss: 0.08265143632888794
Validation loss: 1.3938962592873523

Epoch: 6| Step: 10
Training loss: 0.09627704322338104
Validation loss: 1.3737150417861117

Epoch: 6| Step: 11
Training loss: 0.13859161734580994
Validation loss: 1.4188927706851755

Epoch: 6| Step: 12
Training loss: 0.13959582149982452
Validation loss: 1.4041270761079685

Epoch: 6| Step: 13
Training loss: 0.07465655356645584
Validation loss: 1.4284817005998345

Epoch: 481| Step: 0
Training loss: 0.08673751354217529
Validation loss: 1.4412855614898026

Epoch: 6| Step: 1
Training loss: 0.07900521159172058
Validation loss: 1.4338379918888051

Epoch: 6| Step: 2
Training loss: 0.061432015150785446
Validation loss: 1.4652648266925608

Epoch: 6| Step: 3
Training loss: 0.06375089287757874
Validation loss: 1.4780183325531662

Epoch: 6| Step: 4
Training loss: 0.17503061890602112
Validation loss: 1.4904180777970182

Epoch: 6| Step: 5
Training loss: 0.07961148023605347
Validation loss: 1.4970658684289584

Epoch: 6| Step: 6
Training loss: 0.03401312977075577
Validation loss: 1.4656962963842577

Epoch: 6| Step: 7
Training loss: 0.05782276391983032
Validation loss: 1.4707579228185839

Epoch: 6| Step: 8
Training loss: 0.10161912441253662
Validation loss: 1.4605552278539187

Epoch: 6| Step: 9
Training loss: 0.04000721871852875
Validation loss: 1.4382326500390166

Epoch: 6| Step: 10
Training loss: 0.14147312939167023
Validation loss: 1.401842160891461

Epoch: 6| Step: 11
Training loss: 0.07946925610303879
Validation loss: 1.4132549096179265

Epoch: 6| Step: 12
Training loss: 0.05653943121433258
Validation loss: 1.4102150086433656

Epoch: 6| Step: 13
Training loss: 0.08137471228837967
Validation loss: 1.3878648281097412

Epoch: 482| Step: 0
Training loss: 0.09525544941425323
Validation loss: 1.3867540705588557

Epoch: 6| Step: 1
Training loss: 0.12732002139091492
Validation loss: 1.413792730659567

Epoch: 6| Step: 2
Training loss: 0.08782877773046494
Validation loss: 1.3758854302026893

Epoch: 6| Step: 3
Training loss: 0.08015988767147064
Validation loss: 1.372315574717778

Epoch: 6| Step: 4
Training loss: 0.07633514702320099
Validation loss: 1.4146648619764595

Epoch: 6| Step: 5
Training loss: 0.08938673138618469
Validation loss: 1.4152160145903145

Epoch: 6| Step: 6
Training loss: 0.057817429304122925
Validation loss: 1.4341631063850977

Epoch: 6| Step: 7
Training loss: 0.04640673100948334
Validation loss: 1.4413335989880305

Epoch: 6| Step: 8
Training loss: 0.08123078942298889
Validation loss: 1.4455015909287237

Epoch: 6| Step: 9
Training loss: 0.08191809803247452
Validation loss: 1.4494427134913783

Epoch: 6| Step: 10
Training loss: 0.13836321234703064
Validation loss: 1.4709355356872722

Epoch: 6| Step: 11
Training loss: 0.07453317940235138
Validation loss: 1.4666302960406068

Epoch: 6| Step: 12
Training loss: 0.1383598893880844
Validation loss: 1.4296382101633216

Epoch: 6| Step: 13
Training loss: 0.05215030163526535
Validation loss: 1.4397968976728377

Epoch: 483| Step: 0
Training loss: 0.1140088364481926
Validation loss: 1.4214750694972214

Epoch: 6| Step: 1
Training loss: 0.08378727734088898
Validation loss: 1.4095984761432936

Epoch: 6| Step: 2
Training loss: 0.04981554299592972
Validation loss: 1.4106318796834638

Epoch: 6| Step: 3
Training loss: 0.048613425344228745
Validation loss: 1.4109751383463542

Epoch: 6| Step: 4
Training loss: 0.10559990257024765
Validation loss: 1.378526670958406

Epoch: 6| Step: 5
Training loss: 0.08833833783864975
Validation loss: 1.3799899316603137

Epoch: 6| Step: 6
Training loss: 0.05512891709804535
Validation loss: 1.3789511880566996

Epoch: 6| Step: 7
Training loss: 0.04626956582069397
Validation loss: 1.393840241175826

Epoch: 6| Step: 8
Training loss: 0.10230779647827148
Validation loss: 1.3807251761036534

Epoch: 6| Step: 9
Training loss: 0.06443311274051666
Validation loss: 1.4225391418703142

Epoch: 6| Step: 10
Training loss: 0.08715195208787918
Validation loss: 1.4133184315055929

Epoch: 6| Step: 11
Training loss: 0.14719749987125397
Validation loss: 1.4479404341789983

Epoch: 6| Step: 12
Training loss: 0.07808151096105576
Validation loss: 1.4699738275620244

Epoch: 6| Step: 13
Training loss: 0.08421921730041504
Validation loss: 1.4620679238791108

Epoch: 484| Step: 0
Training loss: 0.1179840937256813
Validation loss: 1.4908864792957102

Epoch: 6| Step: 1
Training loss: 0.09970558434724808
Validation loss: 1.4360220714281964

Epoch: 6| Step: 2
Training loss: 0.05801694840192795
Validation loss: 1.4607019744893557

Epoch: 6| Step: 3
Training loss: 0.08809821307659149
Validation loss: 1.4556596676508586

Epoch: 6| Step: 4
Training loss: 0.08681926131248474
Validation loss: 1.4884428952329902

Epoch: 6| Step: 5
Training loss: 0.09105914831161499
Validation loss: 1.446791325846026

Epoch: 6| Step: 6
Training loss: 0.048761554062366486
Validation loss: 1.444727554116198

Epoch: 6| Step: 7
Training loss: 0.09007725119590759
Validation loss: 1.4422852070100847

Epoch: 6| Step: 8
Training loss: 0.16673901677131653
Validation loss: 1.425459397736416

Epoch: 6| Step: 9
Training loss: 0.1130739152431488
Validation loss: 1.421873987361949

Epoch: 6| Step: 10
Training loss: 0.08785619586706161
Validation loss: 1.4520065348635438

Epoch: 6| Step: 11
Training loss: 0.06631671637296677
Validation loss: 1.4120221573819396

Epoch: 6| Step: 12
Training loss: 0.10323357582092285
Validation loss: 1.4163645634087183

Epoch: 6| Step: 13
Training loss: 0.1987578421831131
Validation loss: 1.4392475235846736

Epoch: 485| Step: 0
Training loss: 0.06207592040300369
Validation loss: 1.445544494095669

Epoch: 6| Step: 1
Training loss: 0.1489465981721878
Validation loss: 1.441041737474421

Epoch: 6| Step: 2
Training loss: 0.08277536928653717
Validation loss: 1.444544703729691

Epoch: 6| Step: 3
Training loss: 0.10779982805252075
Validation loss: 1.4611755878694597

Epoch: 6| Step: 4
Training loss: 0.07295622676610947
Validation loss: 1.4581258476421397

Epoch: 6| Step: 5
Training loss: 0.05266490578651428
Validation loss: 1.4583845324413751

Epoch: 6| Step: 6
Training loss: 0.09301601350307465
Validation loss: 1.4835340835714852

Epoch: 6| Step: 7
Training loss: 0.10950034111738205
Validation loss: 1.4898937120232532

Epoch: 6| Step: 8
Training loss: 0.0590507835149765
Validation loss: 1.462321791597592

Epoch: 6| Step: 9
Training loss: 0.07436823099851608
Validation loss: 1.4398986485696608

Epoch: 6| Step: 10
Training loss: 0.0895865336060524
Validation loss: 1.452927484307238

Epoch: 6| Step: 11
Training loss: 0.06119677424430847
Validation loss: 1.4330701994639572

Epoch: 6| Step: 12
Training loss: 0.06570008397102356
Validation loss: 1.442324415329964

Epoch: 6| Step: 13
Training loss: 0.13055065274238586
Validation loss: 1.4052528662066306

Epoch: 486| Step: 0
Training loss: 0.08931120485067368
Validation loss: 1.407801902422341

Epoch: 6| Step: 1
Training loss: 0.059064313769340515
Validation loss: 1.386129460027141

Epoch: 6| Step: 2
Training loss: 0.08883430063724518
Validation loss: 1.3893984453652495

Epoch: 6| Step: 3
Training loss: 0.06830307841300964
Validation loss: 1.3914368011618172

Epoch: 6| Step: 4
Training loss: 0.10120721161365509
Validation loss: 1.3663994291777253

Epoch: 6| Step: 5
Training loss: 0.10975615680217743
Validation loss: 1.382445970530151

Epoch: 6| Step: 6
Training loss: 0.09273926913738251
Validation loss: 1.3831605187026403

Epoch: 6| Step: 7
Training loss: 0.14126336574554443
Validation loss: 1.3930019832426501

Epoch: 6| Step: 8
Training loss: 0.06027841567993164
Validation loss: 1.4259100267964024

Epoch: 6| Step: 9
Training loss: 0.06128670647740364
Validation loss: 1.487892714879846

Epoch: 6| Step: 10
Training loss: 0.08529501408338547
Validation loss: 1.4788079877053537

Epoch: 6| Step: 11
Training loss: 0.10453550517559052
Validation loss: 1.4697676666321293

Epoch: 6| Step: 12
Training loss: 0.147422656416893
Validation loss: 1.4718264366990776

Epoch: 6| Step: 13
Training loss: 0.10471941530704498
Validation loss: 1.459918325947177

Epoch: 487| Step: 0
Training loss: 0.06594055891036987
Validation loss: 1.4458242372799945

Epoch: 6| Step: 1
Training loss: 0.05695448815822601
Validation loss: 1.4595690593924573

Epoch: 6| Step: 2
Training loss: 0.06369608640670776
Validation loss: 1.4492158864134101

Epoch: 6| Step: 3
Training loss: 0.07565821707248688
Validation loss: 1.4286894336823495

Epoch: 6| Step: 4
Training loss: 0.09231019020080566
Validation loss: 1.4084423588168236

Epoch: 6| Step: 5
Training loss: 0.1671995371580124
Validation loss: 1.4044854205141786

Epoch: 6| Step: 6
Training loss: 0.1002618670463562
Validation loss: 1.426461196714832

Epoch: 6| Step: 7
Training loss: 0.12471460551023483
Validation loss: 1.3945182914374976

Epoch: 6| Step: 8
Training loss: 0.07742942869663239
Validation loss: 1.3909987647046325

Epoch: 6| Step: 9
Training loss: 0.060234177857637405
Validation loss: 1.40167756747174

Epoch: 6| Step: 10
Training loss: 0.04173269122838974
Validation loss: 1.39828533511008

Epoch: 6| Step: 11
Training loss: 0.11745423078536987
Validation loss: 1.4359990140443206

Epoch: 6| Step: 12
Training loss: 0.06539790332317352
Validation loss: 1.4374417951030116

Epoch: 6| Step: 13
Training loss: 0.046801235526800156
Validation loss: 1.451622466887197

Epoch: 488| Step: 0
Training loss: 0.14379936456680298
Validation loss: 1.4987383939886605

Epoch: 6| Step: 1
Training loss: 0.06502221524715424
Validation loss: 1.4681757342430852

Epoch: 6| Step: 2
Training loss: 0.14688658714294434
Validation loss: 1.4731565457518383

Epoch: 6| Step: 3
Training loss: 0.117341049015522
Validation loss: 1.4527853445340229

Epoch: 6| Step: 4
Training loss: 0.0677102655172348
Validation loss: 1.4577159420136483

Epoch: 6| Step: 5
Training loss: 0.09635022282600403
Validation loss: 1.4742181185753114

Epoch: 6| Step: 6
Training loss: 0.09346078336238861
Validation loss: 1.4247336169724822

Epoch: 6| Step: 7
Training loss: 0.08208142220973969
Validation loss: 1.4370563671153078

Epoch: 6| Step: 8
Training loss: 0.1011565625667572
Validation loss: 1.4501359488374443

Epoch: 6| Step: 9
Training loss: 0.08207586407661438
Validation loss: 1.4532811750647843

Epoch: 6| Step: 10
Training loss: 0.10038483142852783
Validation loss: 1.444196556845019

Epoch: 6| Step: 11
Training loss: 0.12865401804447174
Validation loss: 1.4278800820791593

Epoch: 6| Step: 12
Training loss: 0.13838589191436768
Validation loss: 1.4492041667302449

Epoch: 6| Step: 13
Training loss: 0.04751605540513992
Validation loss: 1.4498011232704244

Epoch: 489| Step: 0
Training loss: 0.12893378734588623
Validation loss: 1.425566452805714

Epoch: 6| Step: 1
Training loss: 0.05045823007822037
Validation loss: 1.4970311426347302

Epoch: 6| Step: 2
Training loss: 0.07560862600803375
Validation loss: 1.503393905137175

Epoch: 6| Step: 3
Training loss: 0.10118818283081055
Validation loss: 1.5233536933058052

Epoch: 6| Step: 4
Training loss: 0.15037158131599426
Validation loss: 1.533965491479443

Epoch: 6| Step: 5
Training loss: 0.08022291213274002
Validation loss: 1.5281073521542292

Epoch: 6| Step: 6
Training loss: 0.08920568227767944
Validation loss: 1.522683879380585

Epoch: 6| Step: 7
Training loss: 0.16461727023124695
Validation loss: 1.4933211764981669

Epoch: 6| Step: 8
Training loss: 0.10208690166473389
Validation loss: 1.4867638118805424

Epoch: 6| Step: 9
Training loss: 0.10502230376005173
Validation loss: 1.4821486626901934

Epoch: 6| Step: 10
Training loss: 0.0856214165687561
Validation loss: 1.4656779548173309

Epoch: 6| Step: 11
Training loss: 0.09302320331335068
Validation loss: 1.4405393215917772

Epoch: 6| Step: 12
Training loss: 0.10512790083885193
Validation loss: 1.4385457654153146

Epoch: 6| Step: 13
Training loss: 0.11014539748430252
Validation loss: 1.4483017075446345

Epoch: 490| Step: 0
Training loss: 0.09593363851308823
Validation loss: 1.4262346067736227

Epoch: 6| Step: 1
Training loss: 0.07296264171600342
Validation loss: 1.3912380779943159

Epoch: 6| Step: 2
Training loss: 0.15301433205604553
Validation loss: 1.3729676918316913

Epoch: 6| Step: 3
Training loss: 0.0785403698682785
Validation loss: 1.3935374764985935

Epoch: 6| Step: 4
Training loss: 0.07869167625904083
Validation loss: 1.3755199178572624

Epoch: 6| Step: 5
Training loss: 0.09659306704998016
Validation loss: 1.4048218996294084

Epoch: 6| Step: 6
Training loss: 0.13272659480571747
Validation loss: 1.4331901932275424

Epoch: 6| Step: 7
Training loss: 0.11369277536869049
Validation loss: 1.4214174888467277

Epoch: 6| Step: 8
Training loss: 0.07683864235877991
Validation loss: 1.4848695634513773

Epoch: 6| Step: 9
Training loss: 0.13281647861003876
Validation loss: 1.4607512104895808

Epoch: 6| Step: 10
Training loss: 0.046880707144737244
Validation loss: 1.4724760017087382

Epoch: 6| Step: 11
Training loss: 0.17252707481384277
Validation loss: 1.496025808395878

Epoch: 6| Step: 12
Training loss: 0.11949890851974487
Validation loss: 1.5093704192869124

Epoch: 6| Step: 13
Training loss: 0.09419790655374527
Validation loss: 1.5112876481907342

Epoch: 491| Step: 0
Training loss: 0.12034370005130768
Validation loss: 1.521276161234866

Epoch: 6| Step: 1
Training loss: 0.2741711735725403
Validation loss: 1.4938372194126088

Epoch: 6| Step: 2
Training loss: 0.09330017864704132
Validation loss: 1.4851333531000281

Epoch: 6| Step: 3
Training loss: 0.12437903881072998
Validation loss: 1.5041800711744575

Epoch: 6| Step: 4
Training loss: 0.0854099839925766
Validation loss: 1.4835144960752098

Epoch: 6| Step: 5
Training loss: 0.09295147657394409
Validation loss: 1.45973805650588

Epoch: 6| Step: 6
Training loss: 0.1342039406299591
Validation loss: 1.419179049871301

Epoch: 6| Step: 7
Training loss: 0.10562915354967117
Validation loss: 1.4262967545499083

Epoch: 6| Step: 8
Training loss: 0.06559160351753235
Validation loss: 1.4299679661309848

Epoch: 6| Step: 9
Training loss: 0.13573497533798218
Validation loss: 1.4503381149743193

Epoch: 6| Step: 10
Training loss: 0.11245186626911163
Validation loss: 1.4511203547959686

Epoch: 6| Step: 11
Training loss: 0.10846315324306488
Validation loss: 1.4692517275451331

Epoch: 6| Step: 12
Training loss: 0.10518770664930344
Validation loss: 1.4754522154408116

Epoch: 6| Step: 13
Training loss: 0.10885915160179138
Validation loss: 1.467194950708779

Epoch: 492| Step: 0
Training loss: 0.11342291533946991
Validation loss: 1.481788025107435

Epoch: 6| Step: 1
Training loss: 0.12439663708209991
Validation loss: 1.4908310790215769

Epoch: 6| Step: 2
Training loss: 0.0877239778637886
Validation loss: 1.4692424715206187

Epoch: 6| Step: 3
Training loss: 0.047473616898059845
Validation loss: 1.430401252162072

Epoch: 6| Step: 4
Training loss: 0.058650821447372437
Validation loss: 1.4290633124689902

Epoch: 6| Step: 5
Training loss: 0.1037876307964325
Validation loss: 1.4601858328747492

Epoch: 6| Step: 6
Training loss: 0.07528697699308395
Validation loss: 1.4154619363046461

Epoch: 6| Step: 7
Training loss: 0.15604525804519653
Validation loss: 1.4153779520783374

Epoch: 6| Step: 8
Training loss: 0.11814051866531372
Validation loss: 1.4132206081062235

Epoch: 6| Step: 9
Training loss: 0.10984179377555847
Validation loss: 1.418928102780414

Epoch: 6| Step: 10
Training loss: 0.10188023746013641
Validation loss: 1.4082294587166078

Epoch: 6| Step: 11
Training loss: 0.11071856319904327
Validation loss: 1.4037934028974144

Epoch: 6| Step: 12
Training loss: 0.08295729756355286
Validation loss: 1.4498627237094346

Epoch: 6| Step: 13
Training loss: 0.1397959142923355
Validation loss: 1.418824698335381

Epoch: 493| Step: 0
Training loss: 0.09538066387176514
Validation loss: 1.4576122286499187

Epoch: 6| Step: 1
Training loss: 0.05807710066437721
Validation loss: 1.4841750385940715

Epoch: 6| Step: 2
Training loss: 0.07492595911026001
Validation loss: 1.4913736261347288

Epoch: 6| Step: 3
Training loss: 0.07315675169229507
Validation loss: 1.4610191827179284

Epoch: 6| Step: 4
Training loss: 0.16124016046524048
Validation loss: 1.5041796609919558

Epoch: 6| Step: 5
Training loss: 0.10703779757022858
Validation loss: 1.4803711598919285

Epoch: 6| Step: 6
Training loss: 0.06726466119289398
Validation loss: 1.4958763519922893

Epoch: 6| Step: 7
Training loss: 0.1318897157907486
Validation loss: 1.4707305098092684

Epoch: 6| Step: 8
Training loss: 0.0839027464389801
Validation loss: 1.4982328799463087

Epoch: 6| Step: 9
Training loss: 0.15666650235652924
Validation loss: 1.4506824413935344

Epoch: 6| Step: 10
Training loss: 0.06015052646398544
Validation loss: 1.464190536929715

Epoch: 6| Step: 11
Training loss: 0.08208724856376648
Validation loss: 1.4405446270460724

Epoch: 6| Step: 12
Training loss: 0.07253508269786835
Validation loss: 1.435599959024819

Epoch: 6| Step: 13
Training loss: 0.08497079461812973
Validation loss: 1.4329041704054801

Epoch: 494| Step: 0
Training loss: 0.11353711038827896
Validation loss: 1.4407572977004512

Epoch: 6| Step: 1
Training loss: 0.09032932668924332
Validation loss: 1.4332966766049784

Epoch: 6| Step: 2
Training loss: 0.09508326649665833
Validation loss: 1.4432262669327438

Epoch: 6| Step: 3
Training loss: 0.09031908214092255
Validation loss: 1.4732271984059324

Epoch: 6| Step: 4
Training loss: 0.1144740879535675
Validation loss: 1.4315879216758154

Epoch: 6| Step: 5
Training loss: 0.12207023054361343
Validation loss: 1.4470397618509108

Epoch: 6| Step: 6
Training loss: 0.0909746065735817
Validation loss: 1.4150667998098558

Epoch: 6| Step: 7
Training loss: 0.13916327059268951
Validation loss: 1.411925491466317

Epoch: 6| Step: 8
Training loss: 0.09026597440242767
Validation loss: 1.40175893358005

Epoch: 6| Step: 9
Training loss: 0.08158353716135025
Validation loss: 1.427611526622567

Epoch: 6| Step: 10
Training loss: 0.10531467199325562
Validation loss: 1.4208193953319261

Epoch: 6| Step: 11
Training loss: 0.08549168705940247
Validation loss: 1.4320581600230227

Epoch: 6| Step: 12
Training loss: 0.15083080530166626
Validation loss: 1.4229503575191702

Epoch: 6| Step: 13
Training loss: 0.055174171924591064
Validation loss: 1.438022332806741

Epoch: 495| Step: 0
Training loss: 0.06849077343940735
Validation loss: 1.443699166338931

Epoch: 6| Step: 1
Training loss: 0.1106155589222908
Validation loss: 1.4416454697168002

Epoch: 6| Step: 2
Training loss: 0.09064333885908127
Validation loss: 1.4407500041428434

Epoch: 6| Step: 3
Training loss: 0.07772926241159439
Validation loss: 1.4755638619904876

Epoch: 6| Step: 4
Training loss: 0.16734881699085236
Validation loss: 1.455983147826246

Epoch: 6| Step: 5
Training loss: 0.0797986313700676
Validation loss: 1.4785580122342674

Epoch: 6| Step: 6
Training loss: 0.1078212782740593
Validation loss: 1.4507975847490373

Epoch: 6| Step: 7
Training loss: 0.16905507445335388
Validation loss: 1.4257652355778603

Epoch: 6| Step: 8
Training loss: 0.12597721815109253
Validation loss: 1.4536956458963373

Epoch: 6| Step: 9
Training loss: 0.11512666940689087
Validation loss: 1.4231932509330012

Epoch: 6| Step: 10
Training loss: 0.10387155413627625
Validation loss: 1.4546598554939352

Epoch: 6| Step: 11
Training loss: 0.06388194859027863
Validation loss: 1.4499705632527669

Epoch: 6| Step: 12
Training loss: 0.10639762878417969
Validation loss: 1.47245692822241

Epoch: 6| Step: 13
Training loss: 0.12941625714302063
Validation loss: 1.5104248946712864

Epoch: 496| Step: 0
Training loss: 0.08189795166254044
Validation loss: 1.5016098894098753

Epoch: 6| Step: 1
Training loss: 0.07663864642381668
Validation loss: 1.5156917418203046

Epoch: 6| Step: 2
Training loss: 0.05458655580878258
Validation loss: 1.521688772145138

Epoch: 6| Step: 3
Training loss: 0.07253089547157288
Validation loss: 1.4859336986336658

Epoch: 6| Step: 4
Training loss: 0.062238775193691254
Validation loss: 1.513248606394696

Epoch: 6| Step: 5
Training loss: 0.10088624060153961
Validation loss: 1.5005136318104242

Epoch: 6| Step: 6
Training loss: 0.0733940452337265
Validation loss: 1.4584271010532175

Epoch: 6| Step: 7
Training loss: 0.08214704692363739
Validation loss: 1.472476742600882

Epoch: 6| Step: 8
Training loss: 0.12838749587535858
Validation loss: 1.4436664376207577

Epoch: 6| Step: 9
Training loss: 0.05114659667015076
Validation loss: 1.4378090943059614

Epoch: 6| Step: 10
Training loss: 0.10463368892669678
Validation loss: 1.4508274306533158

Epoch: 6| Step: 11
Training loss: 0.06747046113014221
Validation loss: 1.4538786962468138

Epoch: 6| Step: 12
Training loss: 0.1131836399435997
Validation loss: 1.4320394441645632

Epoch: 6| Step: 13
Training loss: 0.05475170165300369
Validation loss: 1.4138763719989407

Epoch: 497| Step: 0
Training loss: 0.059142135083675385
Validation loss: 1.4386456179362472

Epoch: 6| Step: 1
Training loss: 0.09493306279182434
Validation loss: 1.4614351411019602

Epoch: 6| Step: 2
Training loss: 0.09810347855091095
Validation loss: 1.4842500379008632

Epoch: 6| Step: 3
Training loss: 0.11349836736917496
Validation loss: 1.4657981472630655

Epoch: 6| Step: 4
Training loss: 0.07025699317455292
Validation loss: 1.4943148602721512

Epoch: 6| Step: 5
Training loss: 0.06410571932792664
Validation loss: 1.5010329792576451

Epoch: 6| Step: 6
Training loss: 0.12120363116264343
Validation loss: 1.5094818120361657

Epoch: 6| Step: 7
Training loss: 0.1604430377483368
Validation loss: 1.5168283434324368

Epoch: 6| Step: 8
Training loss: 0.07281772792339325
Validation loss: 1.533149003982544

Epoch: 6| Step: 9
Training loss: 0.09458265453577042
Validation loss: 1.5254689878033054

Epoch: 6| Step: 10
Training loss: 0.08271785080432892
Validation loss: 1.5194479009156585

Epoch: 6| Step: 11
Training loss: 0.1066294014453888
Validation loss: 1.521880603605701

Epoch: 6| Step: 12
Training loss: 0.06551899760961533
Validation loss: 1.4989223621224845

Epoch: 6| Step: 13
Training loss: 0.05812180042266846
Validation loss: 1.478128324272812

Epoch: 498| Step: 0
Training loss: 0.08125168085098267
Validation loss: 1.4671054373505295

Epoch: 6| Step: 1
Training loss: 0.09235737472772598
Validation loss: 1.4505278423268309

Epoch: 6| Step: 2
Training loss: 0.08496014028787613
Validation loss: 1.4530201611980316

Epoch: 6| Step: 3
Training loss: 0.08995135873556137
Validation loss: 1.4414149010053245

Epoch: 6| Step: 4
Training loss: 0.08788616955280304
Validation loss: 1.3984718040753437

Epoch: 6| Step: 5
Training loss: 0.11627018451690674
Validation loss: 1.4400229530949746

Epoch: 6| Step: 6
Training loss: 0.13267186284065247
Validation loss: 1.4384608563556467

Epoch: 6| Step: 7
Training loss: 0.08638816326856613
Validation loss: 1.4025948906457553

Epoch: 6| Step: 8
Training loss: 0.06614632904529572
Validation loss: 1.419438260857777

Epoch: 6| Step: 9
Training loss: 0.09429176151752472
Validation loss: 1.416786434829876

Epoch: 6| Step: 10
Training loss: 0.06263595819473267
Validation loss: 1.4380494612519459

Epoch: 6| Step: 11
Training loss: 0.0856047123670578
Validation loss: 1.4129791061083476

Epoch: 6| Step: 12
Training loss: 0.08109606057405472
Validation loss: 1.4214366110422278

Epoch: 6| Step: 13
Training loss: 0.03046911023557186
Validation loss: 1.4381423124703028

Epoch: 499| Step: 0
Training loss: 0.12509600818157196
Validation loss: 1.4574455163812126

Epoch: 6| Step: 1
Training loss: 0.06579113751649857
Validation loss: 1.466445392177951

Epoch: 6| Step: 2
Training loss: 0.05410579591989517
Validation loss: 1.487233022207855

Epoch: 6| Step: 3
Training loss: 0.1099029928445816
Validation loss: 1.4400754410733458

Epoch: 6| Step: 4
Training loss: 0.07278275489807129
Validation loss: 1.4772938759096208

Epoch: 6| Step: 5
Training loss: 0.07822255790233612
Validation loss: 1.4739967956337878

Epoch: 6| Step: 6
Training loss: 0.08780737221240997
Validation loss: 1.5012023025943386

Epoch: 6| Step: 7
Training loss: 0.09414231777191162
Validation loss: 1.4866284362731441

Epoch: 6| Step: 8
Training loss: 0.07145561277866364
Validation loss: 1.4841407370823685

Epoch: 6| Step: 9
Training loss: 0.05251510441303253
Validation loss: 1.4791127122858518

Epoch: 6| Step: 10
Training loss: 0.06183306872844696
Validation loss: 1.441580940318364

Epoch: 6| Step: 11
Training loss: 0.06864889711141586
Validation loss: 1.439485861409095

Epoch: 6| Step: 12
Training loss: 0.08169713616371155
Validation loss: 1.4457517163727873

Epoch: 6| Step: 13
Training loss: 0.052517347037792206
Validation loss: 1.4116488131143714

Epoch: 500| Step: 0
Training loss: 0.06209120899438858
Validation loss: 1.437576518263868

Epoch: 6| Step: 1
Training loss: 0.05554705113172531
Validation loss: 1.4380981127421062

Epoch: 6| Step: 2
Training loss: 0.11411959677934647
Validation loss: 1.4636858406887259

Epoch: 6| Step: 3
Training loss: 0.09226211160421371
Validation loss: 1.4869308215315624

Epoch: 6| Step: 4
Training loss: 0.07609057426452637
Validation loss: 1.4796289795188493

Epoch: 6| Step: 5
Training loss: 0.1119566336274147
Validation loss: 1.4856340180161178

Epoch: 6| Step: 6
Training loss: 0.06097514182329178
Validation loss: 1.4829103639048915

Epoch: 6| Step: 7
Training loss: 0.06403462588787079
Validation loss: 1.5072179635365803

Epoch: 6| Step: 8
Training loss: 0.06688647717237473
Validation loss: 1.4914451350447953

Epoch: 6| Step: 9
Training loss: 0.08110497146844864
Validation loss: 1.4743792658211083

Epoch: 6| Step: 10
Training loss: 0.1062002032995224
Validation loss: 1.5016216372930875

Epoch: 6| Step: 11
Training loss: 0.08851738274097443
Validation loss: 1.4820187053372782

Epoch: 6| Step: 12
Training loss: 0.04675929993391037
Validation loss: 1.4734293299336587

Epoch: 6| Step: 13
Training loss: 0.06340682506561279
Validation loss: 1.4778929192532775

Epoch: 501| Step: 0
Training loss: 0.12987181544303894
Validation loss: 1.5239967261591265

Epoch: 6| Step: 1
Training loss: 0.084853395819664
Validation loss: 1.47520060500791

Epoch: 6| Step: 2
Training loss: 0.06297451257705688
Validation loss: 1.5082829011383878

Epoch: 6| Step: 3
Training loss: 0.0780293345451355
Validation loss: 1.5012851658687796

Epoch: 6| Step: 4
Training loss: 0.062009669840335846
Validation loss: 1.498901036477858

Epoch: 6| Step: 5
Training loss: 0.06395328044891357
Validation loss: 1.473915308393458

Epoch: 6| Step: 6
Training loss: 0.0776991993188858
Validation loss: 1.5074097430834206

Epoch: 6| Step: 7
Training loss: 0.08081376552581787
Validation loss: 1.4948349806570238

Epoch: 6| Step: 8
Training loss: 0.10857558995485306
Validation loss: 1.4990491110791442

Epoch: 6| Step: 9
Training loss: 0.03974313288927078
Validation loss: 1.4809335880382086

Epoch: 6| Step: 10
Training loss: 0.07099279761314392
Validation loss: 1.494572618956207

Epoch: 6| Step: 11
Training loss: 0.09697894752025604
Validation loss: 1.4890969414864816

Epoch: 6| Step: 12
Training loss: 0.07871387153863907
Validation loss: 1.466382720137155

Epoch: 6| Step: 13
Training loss: 0.07532359659671783
Validation loss: 1.468546462315385

Epoch: 502| Step: 0
Training loss: 0.06909190863370895
Validation loss: 1.4898551523044545

Epoch: 6| Step: 1
Training loss: 0.0729299783706665
Validation loss: 1.4685821584475938

Epoch: 6| Step: 2
Training loss: 0.07571335881948471
Validation loss: 1.4675825577910229

Epoch: 6| Step: 3
Training loss: 0.08422687649726868
Validation loss: 1.453999839803224

Epoch: 6| Step: 4
Training loss: 0.07823346555233002
Validation loss: 1.4584451324196273

Epoch: 6| Step: 5
Training loss: 0.05952167883515358
Validation loss: 1.4503128515776766

Epoch: 6| Step: 6
Training loss: 0.12395414710044861
Validation loss: 1.467096754299697

Epoch: 6| Step: 7
Training loss: 0.08343829214572906
Validation loss: 1.4750880118339293

Epoch: 6| Step: 8
Training loss: 0.05159824341535568
Validation loss: 1.4559097828403595

Epoch: 6| Step: 9
Training loss: 0.07471039146184921
Validation loss: 1.4956618188529887

Epoch: 6| Step: 10
Training loss: 0.06516512483358383
Validation loss: 1.496060303462449

Epoch: 6| Step: 11
Training loss: 0.062126994132995605
Validation loss: 1.469730769434283

Epoch: 6| Step: 12
Training loss: 0.05230526626110077
Validation loss: 1.5017973133312759

Epoch: 6| Step: 13
Training loss: 0.061540260910987854
Validation loss: 1.4982270335638395

Epoch: 503| Step: 0
Training loss: 0.04486573487520218
Validation loss: 1.4751573326767131

Epoch: 6| Step: 1
Training loss: 0.12647856771945953
Validation loss: 1.4937838764600857

Epoch: 6| Step: 2
Training loss: 0.04730512574315071
Validation loss: 1.4971060458049978

Epoch: 6| Step: 3
Training loss: 0.054725270718336105
Validation loss: 1.4912678977494598

Epoch: 6| Step: 4
Training loss: 0.05764801800251007
Validation loss: 1.440215010796824

Epoch: 6| Step: 5
Training loss: 0.07941490411758423
Validation loss: 1.4567743988447293

Epoch: 6| Step: 6
Training loss: 0.10044188797473907
Validation loss: 1.4592550698147024

Epoch: 6| Step: 7
Training loss: 0.0738038718700409
Validation loss: 1.4348684023785334

Epoch: 6| Step: 8
Training loss: 0.0853835865855217
Validation loss: 1.460502334820327

Epoch: 6| Step: 9
Training loss: 0.07542116940021515
Validation loss: 1.4625798476639615

Epoch: 6| Step: 10
Training loss: 0.06930707395076752
Validation loss: 1.4625454365566213

Epoch: 6| Step: 11
Training loss: 0.04668906331062317
Validation loss: 1.4853228727976482

Epoch: 6| Step: 12
Training loss: 0.08942309767007828
Validation loss: 1.4753648619497977

Epoch: 6| Step: 13
Training loss: 0.048990264534950256
Validation loss: 1.4837746017722673

Epoch: 504| Step: 0
Training loss: 0.06545596569776535
Validation loss: 1.4942348875025266

Epoch: 6| Step: 1
Training loss: 0.062011875212192535
Validation loss: 1.4852140885527416

Epoch: 6| Step: 2
Training loss: 0.10606107115745544
Validation loss: 1.4925696824186592

Epoch: 6| Step: 3
Training loss: 0.0759224072098732
Validation loss: 1.4891514983228458

Epoch: 6| Step: 4
Training loss: 0.07025370001792908
Validation loss: 1.5428278715379777

Epoch: 6| Step: 5
Training loss: 0.08217336237430573
Validation loss: 1.5139130315473002

Epoch: 6| Step: 6
Training loss: 0.10237181931734085
Validation loss: 1.4704085652546217

Epoch: 6| Step: 7
Training loss: 0.046121835708618164
Validation loss: 1.476062895149313

Epoch: 6| Step: 8
Training loss: 0.0670730471611023
Validation loss: 1.4548554228198143

Epoch: 6| Step: 9
Training loss: 0.06555331498384476
Validation loss: 1.4632082677656604

Epoch: 6| Step: 10
Training loss: 0.07316495478153229
Validation loss: 1.4467799560998076

Epoch: 6| Step: 11
Training loss: 0.1062355488538742
Validation loss: 1.4315976981193788

Epoch: 6| Step: 12
Training loss: 0.1504553109407425
Validation loss: 1.4265630334936164

Epoch: 6| Step: 13
Training loss: 0.03636248782277107
Validation loss: 1.4305096762154692

Epoch: 505| Step: 0
Training loss: 0.08655788004398346
Validation loss: 1.4710166826043078

Epoch: 6| Step: 1
Training loss: 0.04596879705786705
Validation loss: 1.4844458795362903

Epoch: 6| Step: 2
Training loss: 0.05020423233509064
Validation loss: 1.4759163471960253

Epoch: 6| Step: 3
Training loss: 0.10412093251943588
Validation loss: 1.4675722686193322

Epoch: 6| Step: 4
Training loss: 0.038288623094558716
Validation loss: 1.5141702121303928

Epoch: 6| Step: 5
Training loss: 0.05233325809240341
Validation loss: 1.4832774669893327

Epoch: 6| Step: 6
Training loss: 0.0650935024023056
Validation loss: 1.4885886542258724

Epoch: 6| Step: 7
Training loss: 0.06469404697418213
Validation loss: 1.4430004601837487

Epoch: 6| Step: 8
Training loss: 0.057550717145204544
Validation loss: 1.454031478974127

Epoch: 6| Step: 9
Training loss: 0.058865465223789215
Validation loss: 1.4739780964389924

Epoch: 6| Step: 10
Training loss: 0.05924893915653229
Validation loss: 1.448363737393451

Epoch: 6| Step: 11
Training loss: 0.09302839636802673
Validation loss: 1.4507306160465363

Epoch: 6| Step: 12
Training loss: 0.11274771392345428
Validation loss: 1.4248192284696846

Epoch: 6| Step: 13
Training loss: 0.04931023344397545
Validation loss: 1.4275896485133837

Epoch: 506| Step: 0
Training loss: 0.10320843756198883
Validation loss: 1.4191100635836202

Epoch: 6| Step: 1
Training loss: 0.07865217328071594
Validation loss: 1.429549087760269

Epoch: 6| Step: 2
Training loss: 0.07739672809839249
Validation loss: 1.3963799707351192

Epoch: 6| Step: 3
Training loss: 0.09400922805070877
Validation loss: 1.4446010217871716

Epoch: 6| Step: 4
Training loss: 0.054963842034339905
Validation loss: 1.4478493954545708

Epoch: 6| Step: 5
Training loss: 0.09088342636823654
Validation loss: 1.5019659098758493

Epoch: 6| Step: 6
Training loss: 0.0745522677898407
Validation loss: 1.4522766541409236

Epoch: 6| Step: 7
Training loss: 0.07668833434581757
Validation loss: 1.490314184978444

Epoch: 6| Step: 8
Training loss: 0.06083810701966286
Validation loss: 1.4723579422120125

Epoch: 6| Step: 9
Training loss: 0.07455995678901672
Validation loss: 1.466546034300199

Epoch: 6| Step: 10
Training loss: 0.06234155595302582
Validation loss: 1.4851274836447932

Epoch: 6| Step: 11
Training loss: 0.13640615344047546
Validation loss: 1.4734223850311772

Epoch: 6| Step: 12
Training loss: 0.06395918130874634
Validation loss: 1.4709017110127274

Epoch: 6| Step: 13
Training loss: 0.0515764020383358
Validation loss: 1.4562894144365865

Epoch: 507| Step: 0
Training loss: 0.07489629089832306
Validation loss: 1.4743000730391471

Epoch: 6| Step: 1
Training loss: 0.08417244255542755
Validation loss: 1.4589828227155952

Epoch: 6| Step: 2
Training loss: 0.08627086877822876
Validation loss: 1.4789338804060412

Epoch: 6| Step: 3
Training loss: 0.12817895412445068
Validation loss: 1.4523587303776895

Epoch: 6| Step: 4
Training loss: 0.054612334817647934
Validation loss: 1.4682453710545775

Epoch: 6| Step: 5
Training loss: 0.09192237257957458
Validation loss: 1.4647664023983864

Epoch: 6| Step: 6
Training loss: 0.06482897698879242
Validation loss: 1.4491504994771813

Epoch: 6| Step: 7
Training loss: 0.12015975266695023
Validation loss: 1.4845682215946976

Epoch: 6| Step: 8
Training loss: 0.07592262327671051
Validation loss: 1.4699574196210472

Epoch: 6| Step: 9
Training loss: 0.11375825852155685
Validation loss: 1.4933933525957086

Epoch: 6| Step: 10
Training loss: 0.16928941011428833
Validation loss: 1.4395089892930881

Epoch: 6| Step: 11
Training loss: 0.04840267449617386
Validation loss: 1.4276140364267493

Epoch: 6| Step: 12
Training loss: 0.08106444776058197
Validation loss: 1.4559564757090744

Epoch: 6| Step: 13
Training loss: 0.07618598639965057
Validation loss: 1.438787277026843

Epoch: 508| Step: 0
Training loss: 0.10322917997837067
Validation loss: 1.4348619381586711

Epoch: 6| Step: 1
Training loss: 0.09112583845853806
Validation loss: 1.4391436025660524

Epoch: 6| Step: 2
Training loss: 0.10317669808864594
Validation loss: 1.4361505021331131

Epoch: 6| Step: 3
Training loss: 0.08530057966709137
Validation loss: 1.4172267580545077

Epoch: 6| Step: 4
Training loss: 0.08350013196468353
Validation loss: 1.4332962433497112

Epoch: 6| Step: 5
Training loss: 0.10758799314498901
Validation loss: 1.4787610012997863

Epoch: 6| Step: 6
Training loss: 0.05082253739237785
Validation loss: 1.4686470736739456

Epoch: 6| Step: 7
Training loss: 0.1184987872838974
Validation loss: 1.4805688819577616

Epoch: 6| Step: 8
Training loss: 0.0863807201385498
Validation loss: 1.4720824405711184

Epoch: 6| Step: 9
Training loss: 0.051647335290908813
Validation loss: 1.4912006649919736

Epoch: 6| Step: 10
Training loss: 0.1569756120443344
Validation loss: 1.4423990621361682

Epoch: 6| Step: 11
Training loss: 0.05256861075758934
Validation loss: 1.4535821535254037

Epoch: 6| Step: 12
Training loss: 0.10191254317760468
Validation loss: 1.4443582847554197

Epoch: 6| Step: 13
Training loss: 0.12989920377731323
Validation loss: 1.4103467874629523

Epoch: 509| Step: 0
Training loss: 0.07991684228181839
Validation loss: 1.4407242523726596

Epoch: 6| Step: 1
Training loss: 0.0926588773727417
Validation loss: 1.4394030160801385

Epoch: 6| Step: 2
Training loss: 0.061343107372522354
Validation loss: 1.4773685316885672

Epoch: 6| Step: 3
Training loss: 0.08421701192855835
Validation loss: 1.4491837601507864

Epoch: 6| Step: 4
Training loss: 0.10004346072673798
Validation loss: 1.4582499015715815

Epoch: 6| Step: 5
Training loss: 0.10121852159500122
Validation loss: 1.44345691768072

Epoch: 6| Step: 6
Training loss: 0.061597250401973724
Validation loss: 1.4417249489856023

Epoch: 6| Step: 7
Training loss: 0.18087442219257355
Validation loss: 1.4316366205933273

Epoch: 6| Step: 8
Training loss: 0.061918437480926514
Validation loss: 1.447323388950799

Epoch: 6| Step: 9
Training loss: 0.10281503200531006
Validation loss: 1.4438850379759265

Epoch: 6| Step: 10
Training loss: 0.13624152541160583
Validation loss: 1.4399038899329402

Epoch: 6| Step: 11
Training loss: 0.08641202002763748
Validation loss: 1.431000086569017

Epoch: 6| Step: 12
Training loss: 0.0693291500210762
Validation loss: 1.4127973318099976

Epoch: 6| Step: 13
Training loss: 0.09034715592861176
Validation loss: 1.4300511678059895

Epoch: 510| Step: 0
Training loss: 0.07675814628601074
Validation loss: 1.4267514367257395

Epoch: 6| Step: 1
Training loss: 0.08678502589464188
Validation loss: 1.3939254360814248

Epoch: 6| Step: 2
Training loss: 0.10964614152908325
Validation loss: 1.4030198217720113

Epoch: 6| Step: 3
Training loss: 0.05605527013540268
Validation loss: 1.4249462876268613

Epoch: 6| Step: 4
Training loss: 0.059270549565553665
Validation loss: 1.4252578212368874

Epoch: 6| Step: 5
Training loss: 0.07603079080581665
Validation loss: 1.4316876960057083

Epoch: 6| Step: 6
Training loss: 0.07174418866634369
Validation loss: 1.440895043393617

Epoch: 6| Step: 7
Training loss: 0.06991472095251083
Validation loss: 1.4166649041637298

Epoch: 6| Step: 8
Training loss: 0.09505876898765564
Validation loss: 1.430559512107603

Epoch: 6| Step: 9
Training loss: 0.10650768131017685
Validation loss: 1.482827507039552

Epoch: 6| Step: 10
Training loss: 0.10708287358283997
Validation loss: 1.483601559874832

Epoch: 6| Step: 11
Training loss: 0.12572155892848969
Validation loss: 1.4743766041212185

Epoch: 6| Step: 12
Training loss: 0.09241573512554169
Validation loss: 1.4775070746739705

Epoch: 6| Step: 13
Training loss: 0.08637753129005432
Validation loss: 1.4318052261106429

Epoch: 511| Step: 0
Training loss: 0.07484932243824005
Validation loss: 1.4362526593669769

Epoch: 6| Step: 1
Training loss: 0.07593479752540588
Validation loss: 1.4448623259862263

Epoch: 6| Step: 2
Training loss: 0.08989982306957245
Validation loss: 1.460398889997954

Epoch: 6| Step: 3
Training loss: 0.14686129987239838
Validation loss: 1.4651425743615756

Epoch: 6| Step: 4
Training loss: 0.09455517679452896
Validation loss: 1.4539261658986409

Epoch: 6| Step: 5
Training loss: 0.1307387799024582
Validation loss: 1.4542631885056854

Epoch: 6| Step: 6
Training loss: 0.07146583497524261
Validation loss: 1.426045140912456

Epoch: 6| Step: 7
Training loss: 0.04715299606323242
Validation loss: 1.419634739557902

Epoch: 6| Step: 8
Training loss: 0.13552767038345337
Validation loss: 1.3855303513106478

Epoch: 6| Step: 9
Training loss: 0.0889546275138855
Validation loss: 1.3657216871938398

Epoch: 6| Step: 10
Training loss: 0.09123026579618454
Validation loss: 1.3749834952815887

Epoch: 6| Step: 11
Training loss: 0.10872260481119156
Validation loss: 1.396993911394509

Epoch: 6| Step: 12
Training loss: 0.0724511444568634
Validation loss: 1.398082330021807

Epoch: 6| Step: 13
Training loss: 0.07250979542732239
Validation loss: 1.3926464473047564

Epoch: 512| Step: 0
Training loss: 0.10481415688991547
Validation loss: 1.436444793337135

Epoch: 6| Step: 1
Training loss: 0.08717641234397888
Validation loss: 1.400391214637346

Epoch: 6| Step: 2
Training loss: 0.11520801484584808
Validation loss: 1.4237272201045867

Epoch: 6| Step: 3
Training loss: 0.08823950588703156
Validation loss: 1.4157231866672475

Epoch: 6| Step: 4
Training loss: 0.06102787330746651
Validation loss: 1.3786894531660183

Epoch: 6| Step: 5
Training loss: 0.09435326606035233
Validation loss: 1.408393108716575

Epoch: 6| Step: 6
Training loss: 0.09600851684808731
Validation loss: 1.4317657998813096

Epoch: 6| Step: 7
Training loss: 0.16801446676254272
Validation loss: 1.3811506520035446

Epoch: 6| Step: 8
Training loss: 0.06167168915271759
Validation loss: 1.4043585023572367

Epoch: 6| Step: 9
Training loss: 0.09494899213314056
Validation loss: 1.395926272997292

Epoch: 6| Step: 10
Training loss: 0.06538204103708267
Validation loss: 1.3856511788983499

Epoch: 6| Step: 11
Training loss: 0.08815272152423859
Validation loss: 1.3836711568217124

Epoch: 6| Step: 12
Training loss: 0.07605339586734772
Validation loss: 1.3673627325283584

Epoch: 6| Step: 13
Training loss: 0.08070782572031021
Validation loss: 1.4102831066295665

Epoch: 513| Step: 0
Training loss: 0.0874122604727745
Validation loss: 1.4479107190203924

Epoch: 6| Step: 1
Training loss: 0.058807000517845154
Validation loss: 1.416751326412283

Epoch: 6| Step: 2
Training loss: 0.07706364244222641
Validation loss: 1.4261776990787958

Epoch: 6| Step: 3
Training loss: 0.07392051070928574
Validation loss: 1.4351135274415374

Epoch: 6| Step: 4
Training loss: 0.047876957803964615
Validation loss: 1.4087890886491345

Epoch: 6| Step: 5
Training loss: 0.056695930659770966
Validation loss: 1.4300970236460369

Epoch: 6| Step: 6
Training loss: 0.09689753502607346
Validation loss: 1.448631214839156

Epoch: 6| Step: 7
Training loss: 0.09245392680168152
Validation loss: 1.4307683872920212

Epoch: 6| Step: 8
Training loss: 0.06251832097768784
Validation loss: 1.4254449041940833

Epoch: 6| Step: 9
Training loss: 0.10516858100891113
Validation loss: 1.4444325136882004

Epoch: 6| Step: 10
Training loss: 0.0866846814751625
Validation loss: 1.411164729825912

Epoch: 6| Step: 11
Training loss: 0.09472168982028961
Validation loss: 1.4249671941162438

Epoch: 6| Step: 12
Training loss: 0.1023431196808815
Validation loss: 1.4379466464442592

Epoch: 6| Step: 13
Training loss: 0.04476626589894295
Validation loss: 1.3965705710072671

Epoch: 514| Step: 0
Training loss: 0.06986808776855469
Validation loss: 1.397533526984594

Epoch: 6| Step: 1
Training loss: 0.05420484393835068
Validation loss: 1.3836995337599067

Epoch: 6| Step: 2
Training loss: 0.10536131262779236
Validation loss: 1.3851138443075202

Epoch: 6| Step: 3
Training loss: 0.09010334312915802
Validation loss: 1.3792068996737081

Epoch: 6| Step: 4
Training loss: 0.0693565160036087
Validation loss: 1.3919483070732446

Epoch: 6| Step: 5
Training loss: 0.06578513979911804
Validation loss: 1.3803436063951062

Epoch: 6| Step: 6
Training loss: 0.06111925467848778
Validation loss: 1.4046526916565434

Epoch: 6| Step: 7
Training loss: 0.06439068168401718
Validation loss: 1.4054016182499547

Epoch: 6| Step: 8
Training loss: 0.10360711812973022
Validation loss: 1.4037646811495545

Epoch: 6| Step: 9
Training loss: 0.05846186727285385
Validation loss: 1.3932103636444255

Epoch: 6| Step: 10
Training loss: 0.12747931480407715
Validation loss: 1.4220990160460114

Epoch: 6| Step: 11
Training loss: 0.06550580263137817
Validation loss: 1.3948700402372627

Epoch: 6| Step: 12
Training loss: 0.0763297826051712
Validation loss: 1.4347971049688195

Epoch: 6| Step: 13
Training loss: 0.11262599378824234
Validation loss: 1.4318854654988935

Epoch: 515| Step: 0
Training loss: 0.05378313735127449
Validation loss: 1.4309504467953917

Epoch: 6| Step: 1
Training loss: 0.0877184122800827
Validation loss: 1.4207343875720937

Epoch: 6| Step: 2
Training loss: 0.05546453967690468
Validation loss: 1.459802786509196

Epoch: 6| Step: 3
Training loss: 0.0722036212682724
Validation loss: 1.49708648907241

Epoch: 6| Step: 4
Training loss: 0.07779093086719513
Validation loss: 1.475650006724942

Epoch: 6| Step: 5
Training loss: 0.11183015257120132
Validation loss: 1.4967335565115816

Epoch: 6| Step: 6
Training loss: 0.05431756377220154
Validation loss: 1.4744912373122347

Epoch: 6| Step: 7
Training loss: 0.08592236042022705
Validation loss: 1.4736484981352282

Epoch: 6| Step: 8
Training loss: 0.05922148749232292
Validation loss: 1.4395519853920065

Epoch: 6| Step: 9
Training loss: 0.09186303615570068
Validation loss: 1.4006356577719412

Epoch: 6| Step: 10
Training loss: 0.15108293294906616
Validation loss: 1.4588063557942708

Epoch: 6| Step: 11
Training loss: 0.030309505760669708
Validation loss: 1.4240791707910516

Epoch: 6| Step: 12
Training loss: 0.07028386741876602
Validation loss: 1.4105568291038595

Epoch: 6| Step: 13
Training loss: 0.04671904072165489
Validation loss: 1.4149441949782833

Epoch: 516| Step: 0
Training loss: 0.10762107372283936
Validation loss: 1.4279899879168438

Epoch: 6| Step: 1
Training loss: 0.0555114671587944
Validation loss: 1.4163315437173332

Epoch: 6| Step: 2
Training loss: 0.13311031460762024
Validation loss: 1.4606741756521247

Epoch: 6| Step: 3
Training loss: 0.06421585381031036
Validation loss: 1.4628610559689101

Epoch: 6| Step: 4
Training loss: 0.06448614597320557
Validation loss: 1.4481053249810332

Epoch: 6| Step: 5
Training loss: 0.126251682639122
Validation loss: 1.4693712495988416

Epoch: 6| Step: 6
Training loss: 0.08765248209238052
Validation loss: 1.476573722336882

Epoch: 6| Step: 7
Training loss: 0.08925916254520416
Validation loss: 1.4269885837390859

Epoch: 6| Step: 8
Training loss: 0.05921584740281105
Validation loss: 1.4593265684702064

Epoch: 6| Step: 9
Training loss: 0.08370383083820343
Validation loss: 1.4215150558820335

Epoch: 6| Step: 10
Training loss: 0.11603923887014389
Validation loss: 1.431725727614536

Epoch: 6| Step: 11
Training loss: 0.0777902752161026
Validation loss: 1.425332070678793

Epoch: 6| Step: 12
Training loss: 0.13023364543914795
Validation loss: 1.4094354003988288

Epoch: 6| Step: 13
Training loss: 0.049702223390340805
Validation loss: 1.4251240209866596

Epoch: 517| Step: 0
Training loss: 0.09144675731658936
Validation loss: 1.3963640056630617

Epoch: 6| Step: 1
Training loss: 0.07107771188020706
Validation loss: 1.423523235064681

Epoch: 6| Step: 2
Training loss: 0.07650991529226303
Validation loss: 1.4270105887484807

Epoch: 6| Step: 3
Training loss: 0.05696426331996918
Validation loss: 1.402752769890652

Epoch: 6| Step: 4
Training loss: 0.05663561075925827
Validation loss: 1.4244907081768077

Epoch: 6| Step: 5
Training loss: 0.06606727093458176
Validation loss: 1.4253380311432706

Epoch: 6| Step: 6
Training loss: 0.05855549871921539
Validation loss: 1.4540817340215046

Epoch: 6| Step: 7
Training loss: 0.1069420725107193
Validation loss: 1.4375947380578646

Epoch: 6| Step: 8
Training loss: 0.05764924734830856
Validation loss: 1.4624447159228786

Epoch: 6| Step: 9
Training loss: 0.08190403878688812
Validation loss: 1.4591693993537658

Epoch: 6| Step: 10
Training loss: 0.09702763706445694
Validation loss: 1.4818087213782853

Epoch: 6| Step: 11
Training loss: 0.14195187389850616
Validation loss: 1.4823089504754672

Epoch: 6| Step: 12
Training loss: 0.09536609053611755
Validation loss: 1.4870894980686966

Epoch: 6| Step: 13
Training loss: 0.08017926663160324
Validation loss: 1.4910120271867322

Epoch: 518| Step: 0
Training loss: 0.09859845042228699
Validation loss: 1.486189317959611

Epoch: 6| Step: 1
Training loss: 0.10445410013198853
Validation loss: 1.4271163966066094

Epoch: 6| Step: 2
Training loss: 0.06340254843235016
Validation loss: 1.3785857808205388

Epoch: 6| Step: 3
Training loss: 0.13024018704891205
Validation loss: 1.3769971619370163

Epoch: 6| Step: 4
Training loss: 0.05867329612374306
Validation loss: 1.3827004996679162

Epoch: 6| Step: 5
Training loss: 0.07223235815763474
Validation loss: 1.3846475680669148

Epoch: 6| Step: 6
Training loss: 0.04305509105324745
Validation loss: 1.3513916609107808

Epoch: 6| Step: 7
Training loss: 0.06233404576778412
Validation loss: 1.3659515009131482

Epoch: 6| Step: 8
Training loss: 0.06872565299272537
Validation loss: 1.3792973314562151

Epoch: 6| Step: 9
Training loss: 0.07451202720403671
Validation loss: 1.3794867595036824

Epoch: 6| Step: 10
Training loss: 0.11473329365253448
Validation loss: 1.3631819973709762

Epoch: 6| Step: 11
Training loss: 0.08663015812635422
Validation loss: 1.3854298681341193

Epoch: 6| Step: 12
Training loss: 0.08079260587692261
Validation loss: 1.3818264379296252

Epoch: 6| Step: 13
Training loss: 0.06495162844657898
Validation loss: 1.3811426931811916

Epoch: 519| Step: 0
Training loss: 0.0567348338663578
Validation loss: 1.3995674399919407

Epoch: 6| Step: 1
Training loss: 0.03881143778562546
Validation loss: 1.4224131197057746

Epoch: 6| Step: 2
Training loss: 0.06309831142425537
Validation loss: 1.4275337919112174

Epoch: 6| Step: 3
Training loss: 0.10110953450202942
Validation loss: 1.4478484135802074

Epoch: 6| Step: 4
Training loss: 0.08387928456068039
Validation loss: 1.4566482677254626

Epoch: 6| Step: 5
Training loss: 0.0638873279094696
Validation loss: 1.4377479296858593

Epoch: 6| Step: 6
Training loss: 0.08183944225311279
Validation loss: 1.4184108024002404

Epoch: 6| Step: 7
Training loss: 0.08813102543354034
Validation loss: 1.4196244170588832

Epoch: 6| Step: 8
Training loss: 0.14756834506988525
Validation loss: 1.4233788399286167

Epoch: 6| Step: 9
Training loss: 0.12094726413488388
Validation loss: 1.4059161088799919

Epoch: 6| Step: 10
Training loss: 0.09025545418262482
Validation loss: 1.41962859963858

Epoch: 6| Step: 11
Training loss: 0.09957879781723022
Validation loss: 1.4079149237243078

Epoch: 6| Step: 12
Training loss: 0.04587876796722412
Validation loss: 1.4267894414163405

Epoch: 6| Step: 13
Training loss: 0.1029449850320816
Validation loss: 1.4423302758124568

Epoch: 520| Step: 0
Training loss: 0.049106694757938385
Validation loss: 1.4127432043834398

Epoch: 6| Step: 1
Training loss: 0.10140553116798401
Validation loss: 1.4212134756067747

Epoch: 6| Step: 2
Training loss: 0.06919066607952118
Validation loss: 1.4586569122088853

Epoch: 6| Step: 3
Training loss: 0.10637518763542175
Validation loss: 1.4563640009972356

Epoch: 6| Step: 4
Training loss: 0.08390866965055466
Validation loss: 1.4365557214265228

Epoch: 6| Step: 5
Training loss: 0.07131195068359375
Validation loss: 1.4676485574373634

Epoch: 6| Step: 6
Training loss: 0.056790418922901154
Validation loss: 1.4419325397860618

Epoch: 6| Step: 7
Training loss: 0.05540503188967705
Validation loss: 1.4364845944989113

Epoch: 6| Step: 8
Training loss: 0.08310634642839432
Validation loss: 1.4453492933704006

Epoch: 6| Step: 9
Training loss: 0.04634593427181244
Validation loss: 1.4269781856126682

Epoch: 6| Step: 10
Training loss: 0.05818701535463333
Validation loss: 1.406294277919236

Epoch: 6| Step: 11
Training loss: 0.12737731635570526
Validation loss: 1.4342737890058948

Epoch: 6| Step: 12
Training loss: 0.0924244225025177
Validation loss: 1.4148180164316648

Epoch: 6| Step: 13
Training loss: 0.14374539256095886
Validation loss: 1.4196395220295075

Epoch: 521| Step: 0
Training loss: 0.10402944684028625
Validation loss: 1.415436589589683

Epoch: 6| Step: 1
Training loss: 0.10417677462100983
Validation loss: 1.421643537859763

Epoch: 6| Step: 2
Training loss: 0.06708638370037079
Validation loss: 1.4203209364286034

Epoch: 6| Step: 3
Training loss: 0.10036663711071014
Validation loss: 1.4216122998986194

Epoch: 6| Step: 4
Training loss: 0.10183174908161163
Validation loss: 1.443290005448044

Epoch: 6| Step: 5
Training loss: 0.11945397406816483
Validation loss: 1.4296358977594683

Epoch: 6| Step: 6
Training loss: 0.08484452217817307
Validation loss: 1.4126279405368272

Epoch: 6| Step: 7
Training loss: 0.05486896261572838
Validation loss: 1.442704027698886

Epoch: 6| Step: 8
Training loss: 0.08106093108654022
Validation loss: 1.471281506681955

Epoch: 6| Step: 9
Training loss: 0.09772387892007828
Validation loss: 1.447290180831827

Epoch: 6| Step: 10
Training loss: 0.030573023483157158
Validation loss: 1.4570008682948288

Epoch: 6| Step: 11
Training loss: 0.061766624450683594
Validation loss: 1.436459114474635

Epoch: 6| Step: 12
Training loss: 0.12456586956977844
Validation loss: 1.4587328203262822

Epoch: 6| Step: 13
Training loss: 0.05551047995686531
Validation loss: 1.4645273855296514

Epoch: 522| Step: 0
Training loss: 0.09125808626413345
Validation loss: 1.453577051880539

Epoch: 6| Step: 1
Training loss: 0.08487589657306671
Validation loss: 1.4314734397395965

Epoch: 6| Step: 2
Training loss: 0.11155039072036743
Validation loss: 1.4180470929350903

Epoch: 6| Step: 3
Training loss: 0.07498535513877869
Validation loss: 1.4276007336954917

Epoch: 6| Step: 4
Training loss: 0.08520248532295227
Validation loss: 1.4094425189879634

Epoch: 6| Step: 5
Training loss: 0.14136219024658203
Validation loss: 1.4190841144131077

Epoch: 6| Step: 6
Training loss: 0.10433723032474518
Validation loss: 1.433830363135184

Epoch: 6| Step: 7
Training loss: 0.047860875725746155
Validation loss: 1.4483542160321308

Epoch: 6| Step: 8
Training loss: 0.04336604103446007
Validation loss: 1.456430403135156

Epoch: 6| Step: 9
Training loss: 0.07681524753570557
Validation loss: 1.5131282114213513

Epoch: 6| Step: 10
Training loss: 0.041526682674884796
Validation loss: 1.5014599766782535

Epoch: 6| Step: 11
Training loss: 0.0568041056394577
Validation loss: 1.5105227578070857

Epoch: 6| Step: 12
Training loss: 0.08103864639997482
Validation loss: 1.5027787429030224

Epoch: 6| Step: 13
Training loss: 0.061150722205638885
Validation loss: 1.5232421980109265

Epoch: 523| Step: 0
Training loss: 0.07586348056793213
Validation loss: 1.4633792074777747

Epoch: 6| Step: 1
Training loss: 0.06577837467193604
Validation loss: 1.4387931964730705

Epoch: 6| Step: 2
Training loss: 0.15551498532295227
Validation loss: 1.4338083395393946

Epoch: 6| Step: 3
Training loss: 0.07946275174617767
Validation loss: 1.437797709177899

Epoch: 6| Step: 4
Training loss: 0.08641479164361954
Validation loss: 1.4483205656851492

Epoch: 6| Step: 5
Training loss: 0.07594139873981476
Validation loss: 1.4767253052803777

Epoch: 6| Step: 6
Training loss: 0.07326953113079071
Validation loss: 1.4719285208691832

Epoch: 6| Step: 7
Training loss: 0.07738301157951355
Validation loss: 1.4739131446807616

Epoch: 6| Step: 8
Training loss: 0.065163254737854
Validation loss: 1.4539478927530267

Epoch: 6| Step: 9
Training loss: 0.09425769746303558
Validation loss: 1.4766786258707765

Epoch: 6| Step: 10
Training loss: 0.06873858720064163
Validation loss: 1.4993939771447131

Epoch: 6| Step: 11
Training loss: 0.10590622574090958
Validation loss: 1.5141760738947059

Epoch: 6| Step: 12
Training loss: 0.05631797015666962
Validation loss: 1.5300064163823281

Epoch: 6| Step: 13
Training loss: 0.09614883363246918
Validation loss: 1.4985402399493801

Epoch: 524| Step: 0
Training loss: 0.10638321936130524
Validation loss: 1.5280651591157401

Epoch: 6| Step: 1
Training loss: 0.08142136037349701
Validation loss: 1.5076597775182417

Epoch: 6| Step: 2
Training loss: 0.08875273913145065
Validation loss: 1.466559560068192

Epoch: 6| Step: 3
Training loss: 0.0592486746609211
Validation loss: 1.4407803576479676

Epoch: 6| Step: 4
Training loss: 0.08605299890041351
Validation loss: 1.4319818212139992

Epoch: 6| Step: 5
Training loss: 0.0768553614616394
Validation loss: 1.4275730720130346

Epoch: 6| Step: 6
Training loss: 0.06953929364681244
Validation loss: 1.4272474114612868

Epoch: 6| Step: 7
Training loss: 0.11796896904706955
Validation loss: 1.4510915945934992

Epoch: 6| Step: 8
Training loss: 0.04535748437047005
Validation loss: 1.4619184693982523

Epoch: 6| Step: 9
Training loss: 0.053468771278858185
Validation loss: 1.4397318247825868

Epoch: 6| Step: 10
Training loss: 0.0837242603302002
Validation loss: 1.436585517339809

Epoch: 6| Step: 11
Training loss: 0.08311284333467484
Validation loss: 1.4725414431223305

Epoch: 6| Step: 12
Training loss: 0.07162448763847351
Validation loss: 1.4798515310851477

Epoch: 6| Step: 13
Training loss: 0.2509521245956421
Validation loss: 1.5036896762027536

Epoch: 525| Step: 0
Training loss: 0.11011506617069244
Validation loss: 1.4950976243583105

Epoch: 6| Step: 1
Training loss: 0.046309664845466614
Validation loss: 1.508086262210723

Epoch: 6| Step: 2
Training loss: 0.09453000128269196
Validation loss: 1.5319380164146423

Epoch: 6| Step: 3
Training loss: 0.084626205265522
Validation loss: 1.4909700860259354

Epoch: 6| Step: 4
Training loss: 0.0452151857316494
Validation loss: 1.489949764743928

Epoch: 6| Step: 5
Training loss: 0.05629106983542442
Validation loss: 1.4985879005924347

Epoch: 6| Step: 6
Training loss: 0.05619902163743973
Validation loss: 1.474267957031086

Epoch: 6| Step: 7
Training loss: 0.09069228172302246
Validation loss: 1.4620148885634638

Epoch: 6| Step: 8
Training loss: 0.0576203316450119
Validation loss: 1.4569462268583235

Epoch: 6| Step: 9
Training loss: 0.09993515908718109
Validation loss: 1.4189101085867932

Epoch: 6| Step: 10
Training loss: 0.04502006620168686
Validation loss: 1.4451524121786958

Epoch: 6| Step: 11
Training loss: 0.06829765439033508
Validation loss: 1.3977408780846545

Epoch: 6| Step: 12
Training loss: 0.07649599760770798
Validation loss: 1.4016019708366805

Epoch: 6| Step: 13
Training loss: 0.05281715840101242
Validation loss: 1.4069987625204108

Epoch: 526| Step: 0
Training loss: 0.06490522623062134
Validation loss: 1.3780626507215603

Epoch: 6| Step: 1
Training loss: 0.07776204496622086
Validation loss: 1.386977570031279

Epoch: 6| Step: 2
Training loss: 0.06371191143989563
Validation loss: 1.3865394790967305

Epoch: 6| Step: 3
Training loss: 0.06820179522037506
Validation loss: 1.4012411025262648

Epoch: 6| Step: 4
Training loss: 0.07572128623723984
Validation loss: 1.4282127221425374

Epoch: 6| Step: 5
Training loss: 0.041481710970401764
Validation loss: 1.4363582211156045

Epoch: 6| Step: 6
Training loss: 0.113910011947155
Validation loss: 1.444384027552861

Epoch: 6| Step: 7
Training loss: 0.08288437128067017
Validation loss: 1.454498302552008

Epoch: 6| Step: 8
Training loss: 0.028811872005462646
Validation loss: 1.4515674626955422

Epoch: 6| Step: 9
Training loss: 0.0812457799911499
Validation loss: 1.4704765658224783

Epoch: 6| Step: 10
Training loss: 0.06345245242118835
Validation loss: 1.4549199317091255

Epoch: 6| Step: 11
Training loss: 0.0703473836183548
Validation loss: 1.445945147545107

Epoch: 6| Step: 12
Training loss: 0.1052674725651741
Validation loss: 1.47385363681342

Epoch: 6| Step: 13
Training loss: 0.04621679335832596
Validation loss: 1.4478717747554983

Epoch: 527| Step: 0
Training loss: 0.07104860246181488
Validation loss: 1.465601477571713

Epoch: 6| Step: 1
Training loss: 0.07847969979047775
Validation loss: 1.4581694615784513

Epoch: 6| Step: 2
Training loss: 0.04177992045879364
Validation loss: 1.4539727395580662

Epoch: 6| Step: 3
Training loss: 0.1273864507675171
Validation loss: 1.44663437720268

Epoch: 6| Step: 4
Training loss: 0.09349142014980316
Validation loss: 1.4394269335654475

Epoch: 6| Step: 5
Training loss: 0.13565751910209656
Validation loss: 1.4326897699345824

Epoch: 6| Step: 6
Training loss: 0.08830803632736206
Validation loss: 1.414716221952951

Epoch: 6| Step: 7
Training loss: 0.09350152313709259
Validation loss: 1.385204574113251

Epoch: 6| Step: 8
Training loss: 0.09891969710588455
Validation loss: 1.409052061778243

Epoch: 6| Step: 9
Training loss: 0.08741037547588348
Validation loss: 1.3939167684124363

Epoch: 6| Step: 10
Training loss: 0.09903990477323532
Validation loss: 1.4352992760237826

Epoch: 6| Step: 11
Training loss: 0.14141632616519928
Validation loss: 1.4238108076075071

Epoch: 6| Step: 12
Training loss: 0.04824046045541763
Validation loss: 1.4656859713215982

Epoch: 6| Step: 13
Training loss: 0.092099629342556
Validation loss: 1.4377171134436002

Epoch: 528| Step: 0
Training loss: 0.13747750222682953
Validation loss: 1.4738430899958457

Epoch: 6| Step: 1
Training loss: 0.07208824157714844
Validation loss: 1.5066101589510519

Epoch: 6| Step: 2
Training loss: 0.09744104743003845
Validation loss: 1.5194968203062653

Epoch: 6| Step: 3
Training loss: 0.18265442550182343
Validation loss: 1.5261985473735358

Epoch: 6| Step: 4
Training loss: 0.08312283456325531
Validation loss: 1.5424685093664354

Epoch: 6| Step: 5
Training loss: 0.09680508077144623
Validation loss: 1.4981861306775002

Epoch: 6| Step: 6
Training loss: 0.09933290630578995
Validation loss: 1.4798820428950812

Epoch: 6| Step: 7
Training loss: 0.13759195804595947
Validation loss: 1.4567185371152815

Epoch: 6| Step: 8
Training loss: 0.1309819370508194
Validation loss: 1.4581412961406093

Epoch: 6| Step: 9
Training loss: 0.12251224368810654
Validation loss: 1.4521224716658234

Epoch: 6| Step: 10
Training loss: 0.16664597392082214
Validation loss: 1.4404256651478429

Epoch: 6| Step: 11
Training loss: 0.13522228598594666
Validation loss: 1.4271098170229184

Epoch: 6| Step: 12
Training loss: 0.12184594571590424
Validation loss: 1.391317488044821

Epoch: 6| Step: 13
Training loss: 0.1959780603647232
Validation loss: 1.404110078529645

Epoch: 529| Step: 0
Training loss: 0.07652043551206589
Validation loss: 1.419427724294765

Epoch: 6| Step: 1
Training loss: 0.11121779680252075
Validation loss: 1.4332898906482163

Epoch: 6| Step: 2
Training loss: 0.09493286907672882
Validation loss: 1.4719335468866492

Epoch: 6| Step: 3
Training loss: 0.08129943907260895
Validation loss: 1.480612422830315

Epoch: 6| Step: 4
Training loss: 0.1496923267841339
Validation loss: 1.5182059836643997

Epoch: 6| Step: 5
Training loss: 0.10808257013559341
Validation loss: 1.5328180533583446

Epoch: 6| Step: 6
Training loss: 0.1787300705909729
Validation loss: 1.5599759676123177

Epoch: 6| Step: 7
Training loss: 0.10920725762844086
Validation loss: 1.4874863099026423

Epoch: 6| Step: 8
Training loss: 0.10844820737838745
Validation loss: 1.4605046600423834

Epoch: 6| Step: 9
Training loss: 0.1309410035610199
Validation loss: 1.440554884172255

Epoch: 6| Step: 10
Training loss: 0.1973438858985901
Validation loss: 1.4409938422582482

Epoch: 6| Step: 11
Training loss: 0.207087904214859
Validation loss: 1.4048116098168075

Epoch: 6| Step: 12
Training loss: 0.10721975564956665
Validation loss: 1.3560544918942194

Epoch: 6| Step: 13
Training loss: 0.1283387839794159
Validation loss: 1.334976512898681

Epoch: 530| Step: 0
Training loss: 0.1486680805683136
Validation loss: 1.3442580943466516

Epoch: 6| Step: 1
Training loss: 0.1009909063577652
Validation loss: 1.3173580925951722

Epoch: 6| Step: 2
Training loss: 0.13981744647026062
Validation loss: 1.353954792022705

Epoch: 6| Step: 3
Training loss: 0.19300323724746704
Validation loss: 1.358673901968105

Epoch: 6| Step: 4
Training loss: 0.14743667840957642
Validation loss: 1.3955161968866985

Epoch: 6| Step: 5
Training loss: 0.12421723455190659
Validation loss: 1.4371205106858285

Epoch: 6| Step: 6
Training loss: 0.18207219243049622
Validation loss: 1.5064604551561418

Epoch: 6| Step: 7
Training loss: 0.11637715250253677
Validation loss: 1.55069572823022

Epoch: 6| Step: 8
Training loss: 0.1133197546005249
Validation loss: 1.5455302128227808

Epoch: 6| Step: 9
Training loss: 0.2596740126609802
Validation loss: 1.550877067350572

Epoch: 6| Step: 10
Training loss: 0.14160136878490448
Validation loss: 1.5594319092330111

Epoch: 6| Step: 11
Training loss: 0.2169601023197174
Validation loss: 1.5521272177337317

Epoch: 6| Step: 12
Training loss: 0.16973811388015747
Validation loss: 1.5060848561666345

Epoch: 6| Step: 13
Training loss: 0.11155419796705246
Validation loss: 1.4696648428517003

Epoch: 531| Step: 0
Training loss: 0.14148035645484924
Validation loss: 1.40570153087698

Epoch: 6| Step: 1
Training loss: 0.13948065042495728
Validation loss: 1.455098957143804

Epoch: 6| Step: 2
Training loss: 0.11467546224594116
Validation loss: 1.3946105011047856

Epoch: 6| Step: 3
Training loss: 0.08309496939182281
Validation loss: 1.3796089554345736

Epoch: 6| Step: 4
Training loss: 0.12334689497947693
Validation loss: 1.3718909166192497

Epoch: 6| Step: 5
Training loss: 0.18443669378757477
Validation loss: 1.3953495820363362

Epoch: 6| Step: 6
Training loss: 0.19873669743537903
Validation loss: 1.4304638472936486

Epoch: 6| Step: 7
Training loss: 0.18852554261684418
Validation loss: 1.4152177405613724

Epoch: 6| Step: 8
Training loss: 0.12013863772153854
Validation loss: 1.4265357268753873

Epoch: 6| Step: 9
Training loss: 0.07783567905426025
Validation loss: 1.4751100501706522

Epoch: 6| Step: 10
Training loss: 0.09644906222820282
Validation loss: 1.4727112721371394

Epoch: 6| Step: 11
Training loss: 0.1424652487039566
Validation loss: 1.4550942868314765

Epoch: 6| Step: 12
Training loss: 0.12919199466705322
Validation loss: 1.423677554694555

Epoch: 6| Step: 13
Training loss: 0.09273669868707657
Validation loss: 1.4169656169670883

Epoch: 532| Step: 0
Training loss: 0.2117970883846283
Validation loss: 1.4318297806606497

Epoch: 6| Step: 1
Training loss: 0.10111567378044128
Validation loss: 1.4375258402157856

Epoch: 6| Step: 2
Training loss: 0.11546299606561661
Validation loss: 1.437253298298005

Epoch: 6| Step: 3
Training loss: 0.07285535335540771
Validation loss: 1.425722610565924

Epoch: 6| Step: 4
Training loss: 0.06802097707986832
Validation loss: 1.3981629036447054

Epoch: 6| Step: 5
Training loss: 0.08271044492721558
Validation loss: 1.4304377071319088

Epoch: 6| Step: 6
Training loss: 0.06564070284366608
Validation loss: 1.4136741186982842

Epoch: 6| Step: 7
Training loss: 0.0841589868068695
Validation loss: 1.4387980366265902

Epoch: 6| Step: 8
Training loss: 0.11807280033826828
Validation loss: 1.4111611484199442

Epoch: 6| Step: 9
Training loss: 0.1857859194278717
Validation loss: 1.4483595650683168

Epoch: 6| Step: 10
Training loss: 0.077982097864151
Validation loss: 1.4118865574559858

Epoch: 6| Step: 11
Training loss: 0.15962012112140656
Validation loss: 1.4234602451324463

Epoch: 6| Step: 12
Training loss: 0.10047639906406403
Validation loss: 1.4136997589501001

Epoch: 6| Step: 13
Training loss: 0.14202551543712616
Validation loss: 1.4647038470032394

Epoch: 533| Step: 0
Training loss: 0.07399079203605652
Validation loss: 1.4202966658017968

Epoch: 6| Step: 1
Training loss: 0.13027434051036835
Validation loss: 1.4117874022453063

Epoch: 6| Step: 2
Training loss: 0.07085372507572174
Validation loss: 1.4428088434280888

Epoch: 6| Step: 3
Training loss: 0.08852027356624603
Validation loss: 1.4378553359739241

Epoch: 6| Step: 4
Training loss: 0.12878598272800446
Validation loss: 1.4506526147165606

Epoch: 6| Step: 5
Training loss: 0.14543935656547546
Validation loss: 1.4322093058657903

Epoch: 6| Step: 6
Training loss: 0.10621324926614761
Validation loss: 1.4131262725399387

Epoch: 6| Step: 7
Training loss: 0.1158304288983345
Validation loss: 1.4179971128381708

Epoch: 6| Step: 8
Training loss: 0.07658423483371735
Validation loss: 1.4387915724067277

Epoch: 6| Step: 9
Training loss: 0.0660485029220581
Validation loss: 1.4072799016070623

Epoch: 6| Step: 10
Training loss: 0.11982905119657516
Validation loss: 1.425320303568276

Epoch: 6| Step: 11
Training loss: 0.09093860536813736
Validation loss: 1.4007668783587794

Epoch: 6| Step: 12
Training loss: 0.0781073197722435
Validation loss: 1.4411448586371638

Epoch: 6| Step: 13
Training loss: 0.10521277785301208
Validation loss: 1.4414217292621572

Epoch: 534| Step: 0
Training loss: 0.08782961964607239
Validation loss: 1.414760697272516

Epoch: 6| Step: 1
Training loss: 0.11376087367534637
Validation loss: 1.44231249952829

Epoch: 6| Step: 2
Training loss: 0.06588546186685562
Validation loss: 1.4342837692588888

Epoch: 6| Step: 3
Training loss: 0.09178029745817184
Validation loss: 1.4301265965225876

Epoch: 6| Step: 4
Training loss: 0.11348425596952438
Validation loss: 1.4555785232974636

Epoch: 6| Step: 5
Training loss: 0.10833745449781418
Validation loss: 1.4343387452504968

Epoch: 6| Step: 6
Training loss: 0.09007309377193451
Validation loss: 1.4644779133540329

Epoch: 6| Step: 7
Training loss: 0.0729256421327591
Validation loss: 1.4770149524493883

Epoch: 6| Step: 8
Training loss: 0.07560514658689499
Validation loss: 1.468444247399607

Epoch: 6| Step: 9
Training loss: 0.10462392121553421
Validation loss: 1.471584798187338

Epoch: 6| Step: 10
Training loss: 0.10144364833831787
Validation loss: 1.4312155323643838

Epoch: 6| Step: 11
Training loss: 0.08019520342350006
Validation loss: 1.444713936057142

Epoch: 6| Step: 12
Training loss: 0.10489989817142487
Validation loss: 1.4609950947505173

Epoch: 6| Step: 13
Training loss: 0.1239565759897232
Validation loss: 1.4636161109452606

Epoch: 535| Step: 0
Training loss: 0.10548670589923859
Validation loss: 1.447722731738962

Epoch: 6| Step: 1
Training loss: 0.13900308310985565
Validation loss: 1.4684159460888113

Epoch: 6| Step: 2
Training loss: 0.09187676012516022
Validation loss: 1.4818082650502522

Epoch: 6| Step: 3
Training loss: 0.10259253531694412
Validation loss: 1.4905942511814896

Epoch: 6| Step: 4
Training loss: 0.10971498489379883
Validation loss: 1.4728070600058443

Epoch: 6| Step: 5
Training loss: 0.07770207524299622
Validation loss: 1.4809371976442234

Epoch: 6| Step: 6
Training loss: 0.08296549320220947
Validation loss: 1.4751343534838768

Epoch: 6| Step: 7
Training loss: 0.08778366446495056
Validation loss: 1.4319127426352551

Epoch: 6| Step: 8
Training loss: 0.05631108582019806
Validation loss: 1.4415419467033879

Epoch: 6| Step: 9
Training loss: 0.0759546235203743
Validation loss: 1.389693949812202

Epoch: 6| Step: 10
Training loss: 0.08142869174480438
Validation loss: 1.4103770166315057

Epoch: 6| Step: 11
Training loss: 0.15446224808692932
Validation loss: 1.3838034784922035

Epoch: 6| Step: 12
Training loss: 0.12483179569244385
Validation loss: 1.3762325176628687

Epoch: 6| Step: 13
Training loss: 0.1144537627696991
Validation loss: 1.378389254693062

Epoch: 536| Step: 0
Training loss: 0.07162347435951233
Validation loss: 1.3933663432316115

Epoch: 6| Step: 1
Training loss: 0.05636220797896385
Validation loss: 1.4071919354059363

Epoch: 6| Step: 2
Training loss: 0.12308558076620102
Validation loss: 1.4081825658839235

Epoch: 6| Step: 3
Training loss: 0.09734715521335602
Validation loss: 1.435526938848598

Epoch: 6| Step: 4
Training loss: 0.07096956670284271
Validation loss: 1.4607675101167412

Epoch: 6| Step: 5
Training loss: 0.11792562901973724
Validation loss: 1.4562030280790021

Epoch: 6| Step: 6
Training loss: 0.05872100964188576
Validation loss: 1.4582362508261075

Epoch: 6| Step: 7
Training loss: 0.07477857172489166
Validation loss: 1.4364348842251686

Epoch: 6| Step: 8
Training loss: 0.09483304619789124
Validation loss: 1.4646735037526777

Epoch: 6| Step: 9
Training loss: 0.15852302312850952
Validation loss: 1.4456929058156989

Epoch: 6| Step: 10
Training loss: 0.06381002068519592
Validation loss: 1.428580778901295

Epoch: 6| Step: 11
Training loss: 0.0845780223608017
Validation loss: 1.4600012212671258

Epoch: 6| Step: 12
Training loss: 0.08335307985544205
Validation loss: 1.4207328980968845

Epoch: 6| Step: 13
Training loss: 0.07391531765460968
Validation loss: 1.3935436561543455

Epoch: 537| Step: 0
Training loss: 0.07057321071624756
Validation loss: 1.4117203143335157

Epoch: 6| Step: 1
Training loss: 0.09379062801599503
Validation loss: 1.407067265561832

Epoch: 6| Step: 2
Training loss: 0.1233019232749939
Validation loss: 1.396289090956411

Epoch: 6| Step: 3
Training loss: 0.08863408118486404
Validation loss: 1.3757761338705659

Epoch: 6| Step: 4
Training loss: 0.08905434608459473
Validation loss: 1.3862862369065643

Epoch: 6| Step: 5
Training loss: 0.059187181293964386
Validation loss: 1.3756067906656573

Epoch: 6| Step: 6
Training loss: 0.0720306932926178
Validation loss: 1.3737305325846518

Epoch: 6| Step: 7
Training loss: 0.05268101394176483
Validation loss: 1.3877955002169455

Epoch: 6| Step: 8
Training loss: 0.08839475363492966
Validation loss: 1.431910523163375

Epoch: 6| Step: 9
Training loss: 0.07099856436252594
Validation loss: 1.4463016089572702

Epoch: 6| Step: 10
Training loss: 0.047891341149806976
Validation loss: 1.4241907801679385

Epoch: 6| Step: 11
Training loss: 0.069697305560112
Validation loss: 1.4435618782556185

Epoch: 6| Step: 12
Training loss: 0.07164843380451202
Validation loss: 1.4348683203420332

Epoch: 6| Step: 13
Training loss: 0.09173567593097687
Validation loss: 1.416405488086003

Epoch: 538| Step: 0
Training loss: 0.06344970315694809
Validation loss: 1.4223667114011702

Epoch: 6| Step: 1
Training loss: 0.050048477947711945
Validation loss: 1.387147476596217

Epoch: 6| Step: 2
Training loss: 0.04459511488676071
Validation loss: 1.4046759214452518

Epoch: 6| Step: 3
Training loss: 0.06810171902179718
Validation loss: 1.3814734771687498

Epoch: 6| Step: 4
Training loss: 0.07563231885433197
Validation loss: 1.3891994453245593

Epoch: 6| Step: 5
Training loss: 0.12149004638195038
Validation loss: 1.3691672958353514

Epoch: 6| Step: 6
Training loss: 0.08939507603645325
Validation loss: 1.4120513303305513

Epoch: 6| Step: 7
Training loss: 0.06798090785741806
Validation loss: 1.368300772482349

Epoch: 6| Step: 8
Training loss: 0.09592180699110031
Validation loss: 1.3880031967675814

Epoch: 6| Step: 9
Training loss: 0.08981971442699432
Validation loss: 1.3912187789076118

Epoch: 6| Step: 10
Training loss: 0.04847141355276108
Validation loss: 1.397677335687863

Epoch: 6| Step: 11
Training loss: 0.1061859205365181
Validation loss: 1.4218287865320842

Epoch: 6| Step: 12
Training loss: 0.07584936171770096
Validation loss: 1.4306644355097125

Epoch: 6| Step: 13
Training loss: 0.07020872831344604
Validation loss: 1.4049365994750813

Epoch: 539| Step: 0
Training loss: 0.0800018459558487
Validation loss: 1.4220827484643588

Epoch: 6| Step: 1
Training loss: 0.124436154961586
Validation loss: 1.414895184578434

Epoch: 6| Step: 2
Training loss: 0.11411471664905548
Validation loss: 1.4250254900224748

Epoch: 6| Step: 3
Training loss: 0.10486767441034317
Validation loss: 1.423299361941635

Epoch: 6| Step: 4
Training loss: 0.11124972999095917
Validation loss: 1.419029220458

Epoch: 6| Step: 5
Training loss: 0.11265845596790314
Validation loss: 1.397175786315754

Epoch: 6| Step: 6
Training loss: 0.03446634113788605
Validation loss: 1.4171474223495812

Epoch: 6| Step: 7
Training loss: 0.05653434246778488
Validation loss: 1.405312458674113

Epoch: 6| Step: 8
Training loss: 0.07146379351615906
Validation loss: 1.395378557584619

Epoch: 6| Step: 9
Training loss: 0.11081667244434357
Validation loss: 1.4168732627745597

Epoch: 6| Step: 10
Training loss: 0.06029145047068596
Validation loss: 1.4135182685749506

Epoch: 6| Step: 11
Training loss: 0.11340789496898651
Validation loss: 1.3972647754094933

Epoch: 6| Step: 12
Training loss: 0.08074107766151428
Validation loss: 1.4275025270318473

Epoch: 6| Step: 13
Training loss: 0.09085962176322937
Validation loss: 1.4289110379834329

Epoch: 540| Step: 0
Training loss: 0.0662899762392044
Validation loss: 1.4431852884190057

Epoch: 6| Step: 1
Training loss: 0.052956223487854004
Validation loss: 1.4273330485948952

Epoch: 6| Step: 2
Training loss: 0.08077864348888397
Validation loss: 1.4052623087360012

Epoch: 6| Step: 3
Training loss: 0.05274377390742302
Validation loss: 1.4198386822977374

Epoch: 6| Step: 4
Training loss: 0.12530294060707092
Validation loss: 1.4056960408405592

Epoch: 6| Step: 5
Training loss: 0.09657501429319382
Validation loss: 1.4394056489390712

Epoch: 6| Step: 6
Training loss: 0.06665333360433578
Validation loss: 1.4241029491988562

Epoch: 6| Step: 7
Training loss: 0.11350545287132263
Validation loss: 1.460297115387455

Epoch: 6| Step: 8
Training loss: 0.11010219156742096
Validation loss: 1.482489308362366

Epoch: 6| Step: 9
Training loss: 0.10826792567968369
Validation loss: 1.4770509901867117

Epoch: 6| Step: 10
Training loss: 0.07704784721136093
Validation loss: 1.4333937206575948

Epoch: 6| Step: 11
Training loss: 0.11467939615249634
Validation loss: 1.4710224802776048

Epoch: 6| Step: 12
Training loss: 0.08474002033472061
Validation loss: 1.4447018895097958

Epoch: 6| Step: 13
Training loss: 0.057434603571891785
Validation loss: 1.4300015357232863

Epoch: 541| Step: 0
Training loss: 0.0847964733839035
Validation loss: 1.4356380034518499

Epoch: 6| Step: 1
Training loss: 0.090544693171978
Validation loss: 1.4440054098765056

Epoch: 6| Step: 2
Training loss: 0.053927917033433914
Validation loss: 1.4033282463268568

Epoch: 6| Step: 3
Training loss: 0.09243501722812653
Validation loss: 1.446682810142476

Epoch: 6| Step: 4
Training loss: 0.05058671534061432
Validation loss: 1.428547352872869

Epoch: 6| Step: 5
Training loss: 0.08749451488256454
Validation loss: 1.4523032813943841

Epoch: 6| Step: 6
Training loss: 0.08552289009094238
Validation loss: 1.4410534033211329

Epoch: 6| Step: 7
Training loss: 0.09517436474561691
Validation loss: 1.4094500144322712

Epoch: 6| Step: 8
Training loss: 0.07601998001337051
Validation loss: 1.434087698818535

Epoch: 6| Step: 9
Training loss: 0.10364842414855957
Validation loss: 1.3861083317828435

Epoch: 6| Step: 10
Training loss: 0.06754680722951889
Validation loss: 1.4259726347461823

Epoch: 6| Step: 11
Training loss: 0.10792364180088043
Validation loss: 1.4178538412176154

Epoch: 6| Step: 12
Training loss: 0.04329625144600868
Validation loss: 1.4271090069124777

Epoch: 6| Step: 13
Training loss: 0.026941820979118347
Validation loss: 1.4394683786617812

Epoch: 542| Step: 0
Training loss: 0.05899311602115631
Validation loss: 1.4050954657216226

Epoch: 6| Step: 1
Training loss: 0.07350769639015198
Validation loss: 1.4397923023469987

Epoch: 6| Step: 2
Training loss: 0.06177590787410736
Validation loss: 1.4549957225399632

Epoch: 6| Step: 3
Training loss: 0.07461456954479218
Validation loss: 1.434388687533717

Epoch: 6| Step: 4
Training loss: 0.05863524228334427
Validation loss: 1.436041356414877

Epoch: 6| Step: 5
Training loss: 0.16935104131698608
Validation loss: 1.4478516283855642

Epoch: 6| Step: 6
Training loss: 0.0468737930059433
Validation loss: 1.4676422931814705

Epoch: 6| Step: 7
Training loss: 0.06600448489189148
Validation loss: 1.433720846329966

Epoch: 6| Step: 8
Training loss: 0.10227799415588379
Validation loss: 1.426381416218255

Epoch: 6| Step: 9
Training loss: 0.06321126222610474
Validation loss: 1.369633525930425

Epoch: 6| Step: 10
Training loss: 0.0613715834915638
Validation loss: 1.4234457438991917

Epoch: 6| Step: 11
Training loss: 0.10117197036743164
Validation loss: 1.422761800468609

Epoch: 6| Step: 12
Training loss: 0.061576999723911285
Validation loss: 1.4348287351669804

Epoch: 6| Step: 13
Training loss: 0.05636550858616829
Validation loss: 1.4321345744594451

Epoch: 543| Step: 0
Training loss: 0.10383682698011398
Validation loss: 1.4518567016047816

Epoch: 6| Step: 1
Training loss: 0.09730564057826996
Validation loss: 1.4452221342312392

Epoch: 6| Step: 2
Training loss: 0.07442253082990646
Validation loss: 1.4762059642422585

Epoch: 6| Step: 3
Training loss: 0.09495081007480621
Validation loss: 1.5060270781158118

Epoch: 6| Step: 4
Training loss: 0.0774681493639946
Validation loss: 1.5035595970769082

Epoch: 6| Step: 5
Training loss: 0.07946743071079254
Validation loss: 1.4902140043115104

Epoch: 6| Step: 6
Training loss: 0.1056915745139122
Validation loss: 1.4725191541897353

Epoch: 6| Step: 7
Training loss: 0.059493470937013626
Validation loss: 1.4492838908267278

Epoch: 6| Step: 8
Training loss: 0.09599621593952179
Validation loss: 1.4580385787512666

Epoch: 6| Step: 9
Training loss: 0.08627152442932129
Validation loss: 1.4488085405800932

Epoch: 6| Step: 10
Training loss: 0.07579256594181061
Validation loss: 1.4252770639234973

Epoch: 6| Step: 11
Training loss: 0.04420330375432968
Validation loss: 1.4513765201773694

Epoch: 6| Step: 12
Training loss: 0.10920204222202301
Validation loss: 1.433961001775598

Epoch: 6| Step: 13
Training loss: 0.13407570123672485
Validation loss: 1.4312536229369461

Epoch: 544| Step: 0
Training loss: 0.06141981855034828
Validation loss: 1.4240219144410984

Epoch: 6| Step: 1
Training loss: 0.12495332956314087
Validation loss: 1.443010720514482

Epoch: 6| Step: 2
Training loss: 0.06041131541132927
Validation loss: 1.4403368875544558

Epoch: 6| Step: 3
Training loss: 0.12284082174301147
Validation loss: 1.449266617657036

Epoch: 6| Step: 4
Training loss: 0.055288828909397125
Validation loss: 1.4255558598426081

Epoch: 6| Step: 5
Training loss: 0.07668572664260864
Validation loss: 1.4603698227995185

Epoch: 6| Step: 6
Training loss: 0.1047302782535553
Validation loss: 1.45539217610513

Epoch: 6| Step: 7
Training loss: 0.047281499952077866
Validation loss: 1.4543705230118127

Epoch: 6| Step: 8
Training loss: 0.07807798683643341
Validation loss: 1.4366289498985454

Epoch: 6| Step: 9
Training loss: 0.05875198915600777
Validation loss: 1.4615790651690574

Epoch: 6| Step: 10
Training loss: 0.14858202636241913
Validation loss: 1.4452889478334816

Epoch: 6| Step: 11
Training loss: 0.0915755033493042
Validation loss: 1.4493068290013138

Epoch: 6| Step: 12
Training loss: 0.0525459349155426
Validation loss: 1.4372310843518985

Epoch: 6| Step: 13
Training loss: 0.060904040932655334
Validation loss: 1.4405952063939904

Epoch: 545| Step: 0
Training loss: 0.050929754972457886
Validation loss: 1.447858202841974

Epoch: 6| Step: 1
Training loss: 0.06139206886291504
Validation loss: 1.404347788262111

Epoch: 6| Step: 2
Training loss: 0.07181958854198456
Validation loss: 1.4164187703081357

Epoch: 6| Step: 3
Training loss: 0.07517662644386292
Validation loss: 1.4227399467140116

Epoch: 6| Step: 4
Training loss: 0.10753897577524185
Validation loss: 1.42954985813428

Epoch: 6| Step: 5
Training loss: 0.07577671110630035
Validation loss: 1.4364322552116968

Epoch: 6| Step: 6
Training loss: 0.07355384528636932
Validation loss: 1.4369182843033985

Epoch: 6| Step: 7
Training loss: 0.053369276225566864
Validation loss: 1.4267103274663289

Epoch: 6| Step: 8
Training loss: 0.07163989543914795
Validation loss: 1.4469896824129167

Epoch: 6| Step: 9
Training loss: 0.13447055220603943
Validation loss: 1.4652161329023299

Epoch: 6| Step: 10
Training loss: 0.07684648036956787
Validation loss: 1.453380928244642

Epoch: 6| Step: 11
Training loss: 0.08991891890764236
Validation loss: 1.45423258825015

Epoch: 6| Step: 12
Training loss: 0.13409879803657532
Validation loss: 1.4429994783093851

Epoch: 6| Step: 13
Training loss: 0.07622974365949631
Validation loss: 1.4408850285314745

Epoch: 546| Step: 0
Training loss: 0.058583591133356094
Validation loss: 1.4222442873062626

Epoch: 6| Step: 1
Training loss: 0.062130723148584366
Validation loss: 1.4429160459067232

Epoch: 6| Step: 2
Training loss: 0.11104284971952438
Validation loss: 1.4279329648581884

Epoch: 6| Step: 3
Training loss: 0.10273215174674988
Validation loss: 1.4149684329186716

Epoch: 6| Step: 4
Training loss: 0.07590148597955704
Validation loss: 1.4079261454202796

Epoch: 6| Step: 5
Training loss: 0.09585655480623245
Validation loss: 1.4143234222166

Epoch: 6| Step: 6
Training loss: 0.08672027289867401
Validation loss: 1.4115006436583817

Epoch: 6| Step: 7
Training loss: 0.06622809171676636
Validation loss: 1.4039192981617425

Epoch: 6| Step: 8
Training loss: 0.07105642557144165
Validation loss: 1.415203695656151

Epoch: 6| Step: 9
Training loss: 0.057937949895858765
Validation loss: 1.4103136351031642

Epoch: 6| Step: 10
Training loss: 0.0736028403043747
Validation loss: 1.4246230766337404

Epoch: 6| Step: 11
Training loss: 0.06639757007360458
Validation loss: 1.421481292734864

Epoch: 6| Step: 12
Training loss: 0.154171884059906
Validation loss: 1.421357899583796

Epoch: 6| Step: 13
Training loss: 0.09044361114501953
Validation loss: 1.3808583892801756

Epoch: 547| Step: 0
Training loss: 0.086751788854599
Validation loss: 1.3706755458667714

Epoch: 6| Step: 1
Training loss: 0.04812443628907204
Validation loss: 1.391888819715028

Epoch: 6| Step: 2
Training loss: 0.1418425738811493
Validation loss: 1.3688491839234547

Epoch: 6| Step: 3
Training loss: 0.06566774100065231
Validation loss: 1.390976708422425

Epoch: 6| Step: 4
Training loss: 0.06430066376924515
Validation loss: 1.3979854647831251

Epoch: 6| Step: 5
Training loss: 0.03988819196820259
Validation loss: 1.4110661001615628

Epoch: 6| Step: 6
Training loss: 0.0642922967672348
Validation loss: 1.4653776518760189

Epoch: 6| Step: 7
Training loss: 0.0358024537563324
Validation loss: 1.4274484406235397

Epoch: 6| Step: 8
Training loss: 0.06211037188768387
Validation loss: 1.4581308691732344

Epoch: 6| Step: 9
Training loss: 0.06261216104030609
Validation loss: 1.4443756867480535

Epoch: 6| Step: 10
Training loss: 0.08167664706707001
Validation loss: 1.4714676398102955

Epoch: 6| Step: 11
Training loss: 0.07487459480762482
Validation loss: 1.4766102888250863

Epoch: 6| Step: 12
Training loss: 0.06005334109067917
Validation loss: 1.448465749781619

Epoch: 6| Step: 13
Training loss: 0.06815120577812195
Validation loss: 1.4532631725393317

Epoch: 548| Step: 0
Training loss: 0.038712721318006516
Validation loss: 1.44774587820935

Epoch: 6| Step: 1
Training loss: 0.04773596674203873
Validation loss: 1.4442953435323571

Epoch: 6| Step: 2
Training loss: 0.11233138293027878
Validation loss: 1.4655738774166311

Epoch: 6| Step: 3
Training loss: 0.06190740317106247
Validation loss: 1.4370875525218185

Epoch: 6| Step: 4
Training loss: 0.042572204023599625
Validation loss: 1.455208734799457

Epoch: 6| Step: 5
Training loss: 0.08771353960037231
Validation loss: 1.422081639689784

Epoch: 6| Step: 6
Training loss: 0.07643182575702667
Validation loss: 1.4278680400181842

Epoch: 6| Step: 7
Training loss: 0.06531357765197754
Validation loss: 1.408117930735311

Epoch: 6| Step: 8
Training loss: 0.09025769680738449
Validation loss: 1.4353545122249152

Epoch: 6| Step: 9
Training loss: 0.055527664721012115
Validation loss: 1.4380024146008235

Epoch: 6| Step: 10
Training loss: 0.04136761650443077
Validation loss: 1.438435330185839

Epoch: 6| Step: 11
Training loss: 0.06032537668943405
Validation loss: 1.4015758716931908

Epoch: 6| Step: 12
Training loss: 0.07951071858406067
Validation loss: 1.419697473126073

Epoch: 6| Step: 13
Training loss: 0.09629876166582108
Validation loss: 1.4442456563313801

Epoch: 549| Step: 0
Training loss: 0.061676714569330215
Validation loss: 1.4215096286548081

Epoch: 6| Step: 1
Training loss: 0.06800210475921631
Validation loss: 1.4437063855509604

Epoch: 6| Step: 2
Training loss: 0.045944955199956894
Validation loss: 1.435968546457188

Epoch: 6| Step: 3
Training loss: 0.07260191440582275
Validation loss: 1.4364948144523046

Epoch: 6| Step: 4
Training loss: 0.06096271425485611
Validation loss: 1.444773305487889

Epoch: 6| Step: 5
Training loss: 0.0703565925359726
Validation loss: 1.4522845680995653

Epoch: 6| Step: 6
Training loss: 0.05138128995895386
Validation loss: 1.4794194121514597

Epoch: 6| Step: 7
Training loss: 0.03318701311945915
Validation loss: 1.4566122101199241

Epoch: 6| Step: 8
Training loss: 0.05049598217010498
Validation loss: 1.4564407371705579

Epoch: 6| Step: 9
Training loss: 0.06908456981182098
Validation loss: 1.4389995656987673

Epoch: 6| Step: 10
Training loss: 0.08663077652454376
Validation loss: 1.4536601048643871

Epoch: 6| Step: 11
Training loss: 0.11593883484601974
Validation loss: 1.4258883704421341

Epoch: 6| Step: 12
Training loss: 0.09078985452651978
Validation loss: 1.4380620013001144

Epoch: 6| Step: 13
Training loss: 0.03419449180364609
Validation loss: 1.4406940270495672

Epoch: 550| Step: 0
Training loss: 0.035751570016145706
Validation loss: 1.451845557458939

Epoch: 6| Step: 1
Training loss: 0.05240673944354057
Validation loss: 1.42895092246353

Epoch: 6| Step: 2
Training loss: 0.03373882547020912
Validation loss: 1.4575008000096967

Epoch: 6| Step: 3
Training loss: 0.0895729660987854
Validation loss: 1.470290772376522

Epoch: 6| Step: 4
Training loss: 0.08071822673082352
Validation loss: 1.440206862265064

Epoch: 6| Step: 5
Training loss: 0.09275813400745392
Validation loss: 1.446948500089748

Epoch: 6| Step: 6
Training loss: 0.061643220484256744
Validation loss: 1.4832969301490373

Epoch: 6| Step: 7
Training loss: 0.05450370907783508
Validation loss: 1.448479244785924

Epoch: 6| Step: 8
Training loss: 0.059803929179906845
Validation loss: 1.4392118312979256

Epoch: 6| Step: 9
Training loss: 0.07943598181009293
Validation loss: 1.403077116576574

Epoch: 6| Step: 10
Training loss: 0.06033305451273918
Validation loss: 1.4056081900032618

Epoch: 6| Step: 11
Training loss: 0.06908898800611496
Validation loss: 1.4095702145689277

Epoch: 6| Step: 12
Training loss: 0.14279353618621826
Validation loss: 1.408813149698319

Epoch: 6| Step: 13
Training loss: 0.06406458467245102
Validation loss: 1.4169585730439873

Epoch: 551| Step: 0
Training loss: 0.09796611964702606
Validation loss: 1.4344098061643622

Epoch: 6| Step: 1
Training loss: 0.08615227788686752
Validation loss: 1.464234677694177

Epoch: 6| Step: 2
Training loss: 0.05362430959939957
Validation loss: 1.4622344772020976

Epoch: 6| Step: 3
Training loss: 0.07542693614959717
Validation loss: 1.4809990153517774

Epoch: 6| Step: 4
Training loss: 0.0697852298617363
Validation loss: 1.4920388306340864

Epoch: 6| Step: 5
Training loss: 0.038140587508678436
Validation loss: 1.4932762948415612

Epoch: 6| Step: 6
Training loss: 0.0991339385509491
Validation loss: 1.4741044429040724

Epoch: 6| Step: 7
Training loss: 0.07902046293020248
Validation loss: 1.4709937072569323

Epoch: 6| Step: 8
Training loss: 0.051590368151664734
Validation loss: 1.4326207304513583

Epoch: 6| Step: 9
Training loss: 0.05309900641441345
Validation loss: 1.4028409543216869

Epoch: 6| Step: 10
Training loss: 0.10556254535913467
Validation loss: 1.3985622544442453

Epoch: 6| Step: 11
Training loss: 0.06309938430786133
Validation loss: 1.4109607492723772

Epoch: 6| Step: 12
Training loss: 0.09655843675136566
Validation loss: 1.3801696313324796

Epoch: 6| Step: 13
Training loss: 0.027817003428936005
Validation loss: 1.3881470746891473

Epoch: 552| Step: 0
Training loss: 0.08487513661384583
Validation loss: 1.4134757082949403

Epoch: 6| Step: 1
Training loss: 0.07106266915798187
Validation loss: 1.4344372467328144

Epoch: 6| Step: 2
Training loss: 0.06557279080152512
Validation loss: 1.397563011415543

Epoch: 6| Step: 3
Training loss: 0.07248742878437042
Validation loss: 1.4249296976673989

Epoch: 6| Step: 4
Training loss: 0.08641733974218369
Validation loss: 1.4365894897009737

Epoch: 6| Step: 5
Training loss: 0.10411880910396576
Validation loss: 1.4440033166639266

Epoch: 6| Step: 6
Training loss: 0.08337999135255814
Validation loss: 1.4291311053819553

Epoch: 6| Step: 7
Training loss: 0.09843558073043823
Validation loss: 1.4339901324241393

Epoch: 6| Step: 8
Training loss: 0.08689585328102112
Validation loss: 1.4612324058368642

Epoch: 6| Step: 9
Training loss: 0.054742999374866486
Validation loss: 1.4353893162101827

Epoch: 6| Step: 10
Training loss: 0.1265646517276764
Validation loss: 1.4117161214992564

Epoch: 6| Step: 11
Training loss: 0.05080411210656166
Validation loss: 1.4509231826310516

Epoch: 6| Step: 12
Training loss: 0.09901292622089386
Validation loss: 1.439966441482626

Epoch: 6| Step: 13
Training loss: 0.07211000472307205
Validation loss: 1.424823511031366

Epoch: 553| Step: 0
Training loss: 0.09412771463394165
Validation loss: 1.3954336893173955

Epoch: 6| Step: 1
Training loss: 0.06227712705731392
Validation loss: 1.3777182448294856

Epoch: 6| Step: 2
Training loss: 0.07089191675186157
Validation loss: 1.409562002587062

Epoch: 6| Step: 3
Training loss: 0.07558548450469971
Validation loss: 1.4075661154203518

Epoch: 6| Step: 4
Training loss: 0.0540945939719677
Validation loss: 1.4097414824270433

Epoch: 6| Step: 5
Training loss: 0.04541529715061188
Validation loss: 1.380497940125004

Epoch: 6| Step: 6
Training loss: 0.08486536145210266
Validation loss: 1.3743787516829788

Epoch: 6| Step: 7
Training loss: 0.06469491124153137
Validation loss: 1.4107273611971127

Epoch: 6| Step: 8
Training loss: 0.05851547792553902
Validation loss: 1.4133593408010339

Epoch: 6| Step: 9
Training loss: 0.07983647286891937
Validation loss: 1.4138088200681953

Epoch: 6| Step: 10
Training loss: 0.0741887092590332
Validation loss: 1.410646866726619

Epoch: 6| Step: 11
Training loss: 0.05352067947387695
Validation loss: 1.4213622686683491

Epoch: 6| Step: 12
Training loss: 0.1393556296825409
Validation loss: 1.4174556732177734

Epoch: 6| Step: 13
Training loss: 0.044231440871953964
Validation loss: 1.4023273170635264

Epoch: 554| Step: 0
Training loss: 0.10270239412784576
Validation loss: 1.4147277685903734

Epoch: 6| Step: 1
Training loss: 0.08560966700315475
Validation loss: 1.4441978918608798

Epoch: 6| Step: 2
Training loss: 0.09864939749240875
Validation loss: 1.4362014467998216

Epoch: 6| Step: 3
Training loss: 0.0733383446931839
Validation loss: 1.4337547953410814

Epoch: 6| Step: 4
Training loss: 0.06245144084095955
Validation loss: 1.4287491818910003

Epoch: 6| Step: 5
Training loss: 0.0683804303407669
Validation loss: 1.4277534459226875

Epoch: 6| Step: 6
Training loss: 0.07396483421325684
Validation loss: 1.4109505786690661

Epoch: 6| Step: 7
Training loss: 0.06671102344989777
Validation loss: 1.4285511419337282

Epoch: 6| Step: 8
Training loss: 0.06053752452135086
Validation loss: 1.4120918127798265

Epoch: 6| Step: 9
Training loss: 0.046068403869867325
Validation loss: 1.4314058724270071

Epoch: 6| Step: 10
Training loss: 0.05669783800840378
Validation loss: 1.4548308849334717

Epoch: 6| Step: 11
Training loss: 0.0822901651263237
Validation loss: 1.4477363081388577

Epoch: 6| Step: 12
Training loss: 0.10124920308589935
Validation loss: 1.4662338649072955

Epoch: 6| Step: 13
Training loss: 0.05390229448676109
Validation loss: 1.4792012809425272

Epoch: 555| Step: 0
Training loss: 0.10632529854774475
Validation loss: 1.4885304307424894

Epoch: 6| Step: 1
Training loss: 0.07220415771007538
Validation loss: 1.50771209245087

Epoch: 6| Step: 2
Training loss: 0.04300354793667793
Validation loss: 1.4908904074340739

Epoch: 6| Step: 3
Training loss: 0.06844007223844528
Validation loss: 1.46757387345837

Epoch: 6| Step: 4
Training loss: 0.05239417031407356
Validation loss: 1.4737065421637667

Epoch: 6| Step: 5
Training loss: 0.10053010284900665
Validation loss: 1.4869676097746818

Epoch: 6| Step: 6
Training loss: 0.054572828114032745
Validation loss: 1.4790592667877034

Epoch: 6| Step: 7
Training loss: 0.08607302606105804
Validation loss: 1.4695925007584274

Epoch: 6| Step: 8
Training loss: 0.07975234091281891
Validation loss: 1.4743713153305875

Epoch: 6| Step: 9
Training loss: 0.057546839118003845
Validation loss: 1.4648153192253524

Epoch: 6| Step: 10
Training loss: 0.05042830854654312
Validation loss: 1.4588199789806078

Epoch: 6| Step: 11
Training loss: 0.06380070745944977
Validation loss: 1.4774443090602916

Epoch: 6| Step: 12
Training loss: 0.06956691294908524
Validation loss: 1.4611166138802805

Epoch: 6| Step: 13
Training loss: 0.06262558698654175
Validation loss: 1.461079893573638

Epoch: 556| Step: 0
Training loss: 0.06695154309272766
Validation loss: 1.4570586027637604

Epoch: 6| Step: 1
Training loss: 0.08452872186899185
Validation loss: 1.4326591478881014

Epoch: 6| Step: 2
Training loss: 0.08619395643472672
Validation loss: 1.4255207430931829

Epoch: 6| Step: 3
Training loss: 0.09470851719379425
Validation loss: 1.4234449337887507

Epoch: 6| Step: 4
Training loss: 0.11145102977752686
Validation loss: 1.4241976404702792

Epoch: 6| Step: 5
Training loss: 0.07706687599420547
Validation loss: 1.4165189984024211

Epoch: 6| Step: 6
Training loss: 0.12300320714712143
Validation loss: 1.4288017211421844

Epoch: 6| Step: 7
Training loss: 0.06612682342529297
Validation loss: 1.4242684584791943

Epoch: 6| Step: 8
Training loss: 0.04477446526288986
Validation loss: 1.4460193739142468

Epoch: 6| Step: 9
Training loss: 0.07772403955459595
Validation loss: 1.4416570317360662

Epoch: 6| Step: 10
Training loss: 0.09918449819087982
Validation loss: 1.4625710441220192

Epoch: 6| Step: 11
Training loss: 0.06666430085897446
Validation loss: 1.4426544238162298

Epoch: 6| Step: 12
Training loss: 0.0480840839445591
Validation loss: 1.4451322638860313

Epoch: 6| Step: 13
Training loss: 0.05895683541893959
Validation loss: 1.4942366538509246

Epoch: 557| Step: 0
Training loss: 0.06778886914253235
Validation loss: 1.5300061677091865

Epoch: 6| Step: 1
Training loss: 0.04500484839081764
Validation loss: 1.4902856260217645

Epoch: 6| Step: 2
Training loss: 0.09309827536344528
Validation loss: 1.497229439596976

Epoch: 6| Step: 3
Training loss: 0.0691085010766983
Validation loss: 1.5131085797022747

Epoch: 6| Step: 4
Training loss: 0.11100292950868607
Validation loss: 1.463479297135466

Epoch: 6| Step: 5
Training loss: 0.05054580420255661
Validation loss: 1.4455053011576335

Epoch: 6| Step: 6
Training loss: 0.11794179677963257
Validation loss: 1.4016939991263933

Epoch: 6| Step: 7
Training loss: 0.07147594541311264
Validation loss: 1.3969717987122074

Epoch: 6| Step: 8
Training loss: 0.07443724572658539
Validation loss: 1.3781297117151239

Epoch: 6| Step: 9
Training loss: 0.07437187433242798
Validation loss: 1.3804786179655342

Epoch: 6| Step: 10
Training loss: 0.09145352989435196
Validation loss: 1.3974777819007955

Epoch: 6| Step: 11
Training loss: 0.06376557052135468
Validation loss: 1.3971627104666926

Epoch: 6| Step: 12
Training loss: 0.11698015034198761
Validation loss: 1.402662184930617

Epoch: 6| Step: 13
Training loss: 0.07553860545158386
Validation loss: 1.4278426272894746

Epoch: 558| Step: 0
Training loss: 0.07449415326118469
Validation loss: 1.4272023349679925

Epoch: 6| Step: 1
Training loss: 0.09415335208177567
Validation loss: 1.4272679225091012

Epoch: 6| Step: 2
Training loss: 0.09244915097951889
Validation loss: 1.4190433230451358

Epoch: 6| Step: 3
Training loss: 0.053387366235256195
Validation loss: 1.4728403296521915

Epoch: 6| Step: 4
Training loss: 0.07849697768688202
Validation loss: 1.4148520346610778

Epoch: 6| Step: 5
Training loss: 0.08669638633728027
Validation loss: 1.4370613559599845

Epoch: 6| Step: 6
Training loss: 0.08031709492206573
Validation loss: 1.461737448169339

Epoch: 6| Step: 7
Training loss: 0.06563103199005127
Validation loss: 1.451019924814983

Epoch: 6| Step: 8
Training loss: 0.08122223615646362
Validation loss: 1.4472200396240398

Epoch: 6| Step: 9
Training loss: 0.07666616141796112
Validation loss: 1.4501960572376047

Epoch: 6| Step: 10
Training loss: 0.11147750169038773
Validation loss: 1.4529924322200078

Epoch: 6| Step: 11
Training loss: 0.03840460628271103
Validation loss: 1.4303940457682456

Epoch: 6| Step: 12
Training loss: 0.1253949999809265
Validation loss: 1.436758691264737

Epoch: 6| Step: 13
Training loss: 0.09018334746360779
Validation loss: 1.4475219788089875

Epoch: 559| Step: 0
Training loss: 0.07882679253816605
Validation loss: 1.460674052597374

Epoch: 6| Step: 1
Training loss: 0.07411569356918335
Validation loss: 1.451288466812462

Epoch: 6| Step: 2
Training loss: 0.07411880791187286
Validation loss: 1.4298435385509203

Epoch: 6| Step: 3
Training loss: 0.05149880796670914
Validation loss: 1.4465928154606973

Epoch: 6| Step: 4
Training loss: 0.06521796435117722
Validation loss: 1.420243892618405

Epoch: 6| Step: 5
Training loss: 0.05144652724266052
Validation loss: 1.4419787288993917

Epoch: 6| Step: 6
Training loss: 0.1029985249042511
Validation loss: 1.4675125409198064

Epoch: 6| Step: 7
Training loss: 0.07534963637590408
Validation loss: 1.4444324585699266

Epoch: 6| Step: 8
Training loss: 0.048398375511169434
Validation loss: 1.4581822759361678

Epoch: 6| Step: 9
Training loss: 0.05617615580558777
Validation loss: 1.4539964160611552

Epoch: 6| Step: 10
Training loss: 0.054103635251522064
Validation loss: 1.4611751482050905

Epoch: 6| Step: 11
Training loss: 0.05138178914785385
Validation loss: 1.4584801594416301

Epoch: 6| Step: 12
Training loss: 0.08349820226430893
Validation loss: 1.485404360678888

Epoch: 6| Step: 13
Training loss: 0.08666570484638214
Validation loss: 1.509322214511133

Epoch: 560| Step: 0
Training loss: 0.047633394598960876
Validation loss: 1.483327878418789

Epoch: 6| Step: 1
Training loss: 0.07208438217639923
Validation loss: 1.4596536954243977

Epoch: 6| Step: 2
Training loss: 0.07981132715940475
Validation loss: 1.4603067982581355

Epoch: 6| Step: 3
Training loss: 0.05516175180673599
Validation loss: 1.46387344021951

Epoch: 6| Step: 4
Training loss: 0.08387553691864014
Validation loss: 1.4445910133341306

Epoch: 6| Step: 5
Training loss: 0.09658676385879517
Validation loss: 1.4234318476851269

Epoch: 6| Step: 6
Training loss: 0.12716326117515564
Validation loss: 1.402711138930372

Epoch: 6| Step: 7
Training loss: 0.09887304902076721
Validation loss: 1.3890603524382397

Epoch: 6| Step: 8
Training loss: 0.07666509598493576
Validation loss: 1.4205556428560646

Epoch: 6| Step: 9
Training loss: 0.05806378647685051
Validation loss: 1.4041199671324862

Epoch: 6| Step: 10
Training loss: 0.08461051434278488
Validation loss: 1.397764462937591

Epoch: 6| Step: 11
Training loss: 0.07042433321475983
Validation loss: 1.3970180967802643

Epoch: 6| Step: 12
Training loss: 0.06935197860002518
Validation loss: 1.4122460285822551

Epoch: 6| Step: 13
Training loss: 0.07296376675367355
Validation loss: 1.4418496906116445

Epoch: 561| Step: 0
Training loss: 0.09170947968959808
Validation loss: 1.4655191206162976

Epoch: 6| Step: 1
Training loss: 0.1086801290512085
Validation loss: 1.4546190192622523

Epoch: 6| Step: 2
Training loss: 0.07893037796020508
Validation loss: 1.4648985869141036

Epoch: 6| Step: 3
Training loss: 0.08803465962409973
Validation loss: 1.4761688427258564

Epoch: 6| Step: 4
Training loss: 0.0881473645567894
Validation loss: 1.4716534470358202

Epoch: 6| Step: 5
Training loss: 0.04679519310593605
Validation loss: 1.470627579637753

Epoch: 6| Step: 6
Training loss: 0.08554472774267197
Validation loss: 1.445539774433259

Epoch: 6| Step: 7
Training loss: 0.05578842759132385
Validation loss: 1.452984312529205

Epoch: 6| Step: 8
Training loss: 0.06313946098089218
Validation loss: 1.4597421397445023

Epoch: 6| Step: 9
Training loss: 0.07450800389051437
Validation loss: 1.4353031907030331

Epoch: 6| Step: 10
Training loss: 0.06990137696266174
Validation loss: 1.4189240637645926

Epoch: 6| Step: 11
Training loss: 0.07546524703502655
Validation loss: 1.4180258025405228

Epoch: 6| Step: 12
Training loss: 0.05070767179131508
Validation loss: 1.411602525300877

Epoch: 6| Step: 13
Training loss: 0.03446272760629654
Validation loss: 1.3902691192524408

Epoch: 562| Step: 0
Training loss: 0.07614490389823914
Validation loss: 1.4216896616002566

Epoch: 6| Step: 1
Training loss: 0.04162722826004028
Validation loss: 1.414927553105098

Epoch: 6| Step: 2
Training loss: 0.1108989492058754
Validation loss: 1.446281261341546

Epoch: 6| Step: 3
Training loss: 0.044603634625673294
Validation loss: 1.4227234714774675

Epoch: 6| Step: 4
Training loss: 0.05973115190863609
Validation loss: 1.4674806723030664

Epoch: 6| Step: 5
Training loss: 0.05021700635552406
Validation loss: 1.4469910539606565

Epoch: 6| Step: 6
Training loss: 0.049998119473457336
Validation loss: 1.4583962655836535

Epoch: 6| Step: 7
Training loss: 0.07992420345544815
Validation loss: 1.4858264371912966

Epoch: 6| Step: 8
Training loss: 0.08485312759876251
Validation loss: 1.503033238072549

Epoch: 6| Step: 9
Training loss: 0.05204086750745773
Validation loss: 1.4896209079732177

Epoch: 6| Step: 10
Training loss: 0.07762201875448227
Validation loss: 1.4814037443489156

Epoch: 6| Step: 11
Training loss: 0.08630342781543732
Validation loss: 1.456753755128512

Epoch: 6| Step: 12
Training loss: 0.02463238313794136
Validation loss: 1.4502572680032382

Epoch: 6| Step: 13
Training loss: 0.05085918679833412
Validation loss: 1.4306005072850052

Epoch: 563| Step: 0
Training loss: 0.14736205339431763
Validation loss: 1.4543454781655343

Epoch: 6| Step: 1
Training loss: 0.05325837805867195
Validation loss: 1.4267741134089809

Epoch: 6| Step: 2
Training loss: 0.057261087000370026
Validation loss: 1.4070505865158573

Epoch: 6| Step: 3
Training loss: 0.08988311886787415
Validation loss: 1.3988572538539927

Epoch: 6| Step: 4
Training loss: 0.06289373338222504
Validation loss: 1.4195438584973734

Epoch: 6| Step: 5
Training loss: 0.07681165635585785
Validation loss: 1.4543546438217163

Epoch: 6| Step: 6
Training loss: 0.08652420341968536
Validation loss: 1.4291407523616668

Epoch: 6| Step: 7
Training loss: 0.05162838473916054
Validation loss: 1.4291228043135775

Epoch: 6| Step: 8
Training loss: 0.047576382756233215
Validation loss: 1.4289034669117262

Epoch: 6| Step: 9
Training loss: 0.03719879686832428
Validation loss: 1.4335004655263757

Epoch: 6| Step: 10
Training loss: 0.041482530534267426
Validation loss: 1.4247871483525922

Epoch: 6| Step: 11
Training loss: 0.05639749765396118
Validation loss: 1.4348189997416672

Epoch: 6| Step: 12
Training loss: 0.0533917173743248
Validation loss: 1.4492528669295772

Epoch: 6| Step: 13
Training loss: 0.04929868504405022
Validation loss: 1.4510410742093158

Epoch: 564| Step: 0
Training loss: 0.05140340328216553
Validation loss: 1.4258208390205138

Epoch: 6| Step: 1
Training loss: 0.060230936855077744
Validation loss: 1.4480958702743694

Epoch: 6| Step: 2
Training loss: 0.03848247602581978
Validation loss: 1.4253020914652015

Epoch: 6| Step: 3
Training loss: 0.11421258002519608
Validation loss: 1.4354944126580351

Epoch: 6| Step: 4
Training loss: 0.041264500468969345
Validation loss: 1.4273345893429172

Epoch: 6| Step: 5
Training loss: 0.0700698047876358
Validation loss: 1.4123232697927823

Epoch: 6| Step: 6
Training loss: 0.090484119951725
Validation loss: 1.4112336379225536

Epoch: 6| Step: 7
Training loss: 0.10871276259422302
Validation loss: 1.4320976682888564

Epoch: 6| Step: 8
Training loss: 0.07660562545061111
Validation loss: 1.4058665216609996

Epoch: 6| Step: 9
Training loss: 0.06022321432828903
Validation loss: 1.4295324478098141

Epoch: 6| Step: 10
Training loss: 0.04123109206557274
Validation loss: 1.4448671674215665

Epoch: 6| Step: 11
Training loss: 0.07957009226083755
Validation loss: 1.444406988800213

Epoch: 6| Step: 12
Training loss: 0.0784495621919632
Validation loss: 1.4575434935990201

Epoch: 6| Step: 13
Training loss: 0.07089381664991379
Validation loss: 1.4311636327415385

Epoch: 565| Step: 0
Training loss: 0.08789275586605072
Validation loss: 1.4480954844464538

Epoch: 6| Step: 1
Training loss: 0.051793575286865234
Validation loss: 1.4488607452761741

Epoch: 6| Step: 2
Training loss: 0.09020019322633743
Validation loss: 1.4077531483865553

Epoch: 6| Step: 3
Training loss: 0.0677565187215805
Validation loss: 1.4393072359023555

Epoch: 6| Step: 4
Training loss: 0.07265110313892365
Validation loss: 1.4061298319088515

Epoch: 6| Step: 5
Training loss: 0.09874361008405685
Validation loss: 1.3825798611487112

Epoch: 6| Step: 6
Training loss: 0.08248458802700043
Validation loss: 1.3888739988368044

Epoch: 6| Step: 7
Training loss: 0.08655436336994171
Validation loss: 1.373080635583529

Epoch: 6| Step: 8
Training loss: 0.07453817874193192
Validation loss: 1.4084785407589329

Epoch: 6| Step: 9
Training loss: 0.040944308042526245
Validation loss: 1.3829571303500925

Epoch: 6| Step: 10
Training loss: 0.09998760372400284
Validation loss: 1.403866611501222

Epoch: 6| Step: 11
Training loss: 0.026768365874886513
Validation loss: 1.4418045423364128

Epoch: 6| Step: 12
Training loss: 0.09859815239906311
Validation loss: 1.4549705238752468

Epoch: 6| Step: 13
Training loss: 0.07535086572170258
Validation loss: 1.4513414047097648

Epoch: 566| Step: 0
Training loss: 0.06347822397947311
Validation loss: 1.4687303676400134

Epoch: 6| Step: 1
Training loss: 0.09361318498849869
Validation loss: 1.459463147706883

Epoch: 6| Step: 2
Training loss: 0.04298538714647293
Validation loss: 1.4548784725127681

Epoch: 6| Step: 3
Training loss: 0.05172930285334587
Validation loss: 1.4695554523057834

Epoch: 6| Step: 4
Training loss: 0.07326363772153854
Validation loss: 1.425869050846305

Epoch: 6| Step: 5
Training loss: 0.07135987281799316
Validation loss: 1.4390273504359747

Epoch: 6| Step: 6
Training loss: 0.10675741732120514
Validation loss: 1.3682026414461033

Epoch: 6| Step: 7
Training loss: 0.07913114130496979
Validation loss: 1.4262383266161847

Epoch: 6| Step: 8
Training loss: 0.0708296000957489
Validation loss: 1.37429932625063

Epoch: 6| Step: 9
Training loss: 0.05487053468823433
Validation loss: 1.391539006463943

Epoch: 6| Step: 10
Training loss: 0.055365629494190216
Validation loss: 1.3776103219678324

Epoch: 6| Step: 11
Training loss: 0.06748640537261963
Validation loss: 1.3888696214204193

Epoch: 6| Step: 12
Training loss: 0.06990757584571838
Validation loss: 1.3925365081397436

Epoch: 6| Step: 13
Training loss: 0.05815859138965607
Validation loss: 1.4033480331461916

Epoch: 567| Step: 0
Training loss: 0.08596210181713104
Validation loss: 1.4108000410500394

Epoch: 6| Step: 1
Training loss: 0.12141482532024384
Validation loss: 1.4277022795010639

Epoch: 6| Step: 2
Training loss: 0.08731348812580109
Validation loss: 1.4335596253795009

Epoch: 6| Step: 3
Training loss: 0.07844145596027374
Validation loss: 1.3816430261058192

Epoch: 6| Step: 4
Training loss: 0.06236669421195984
Validation loss: 1.413099592731845

Epoch: 6| Step: 5
Training loss: 0.04748737812042236
Validation loss: 1.3952567564543856

Epoch: 6| Step: 6
Training loss: 0.05322227627038956
Validation loss: 1.4035193522771199

Epoch: 6| Step: 7
Training loss: 0.08242817223072052
Validation loss: 1.3838992061153534

Epoch: 6| Step: 8
Training loss: 0.06531421840190887
Validation loss: 1.4016019682730398

Epoch: 6| Step: 9
Training loss: 0.06267056614160538
Validation loss: 1.4247677531293643

Epoch: 6| Step: 10
Training loss: 0.05224594473838806
Validation loss: 1.3868567494935886

Epoch: 6| Step: 11
Training loss: 0.10320676118135452
Validation loss: 1.4393744443052559

Epoch: 6| Step: 12
Training loss: 0.05989285930991173
Validation loss: 1.4018935875226093

Epoch: 6| Step: 13
Training loss: 0.11976324021816254
Validation loss: 1.4237243244724889

Epoch: 568| Step: 0
Training loss: 0.13069292902946472
Validation loss: 1.4247471478677565

Epoch: 6| Step: 1
Training loss: 0.043230652809143066
Validation loss: 1.40754993243884

Epoch: 6| Step: 2
Training loss: 0.05820425599813461
Validation loss: 1.394512664887213

Epoch: 6| Step: 3
Training loss: 0.06544028222560883
Validation loss: 1.4372971288619503

Epoch: 6| Step: 4
Training loss: 0.0990917831659317
Validation loss: 1.4102062550924157

Epoch: 6| Step: 5
Training loss: 0.052916910499334335
Validation loss: 1.4070872619587889

Epoch: 6| Step: 6
Training loss: 0.04797278717160225
Validation loss: 1.3923959559009922

Epoch: 6| Step: 7
Training loss: 0.07026716321706772
Validation loss: 1.3700648853855748

Epoch: 6| Step: 8
Training loss: 0.06039794534444809
Validation loss: 1.3494067788124084

Epoch: 6| Step: 9
Training loss: 0.06333345919847488
Validation loss: 1.3853450385473107

Epoch: 6| Step: 10
Training loss: 0.1520504653453827
Validation loss: 1.368071218972565

Epoch: 6| Step: 11
Training loss: 0.1284599006175995
Validation loss: 1.3667809078770299

Epoch: 6| Step: 12
Training loss: 0.065768301486969
Validation loss: 1.3508473327082973

Epoch: 6| Step: 13
Training loss: 0.1529853343963623
Validation loss: 1.3549244044929423

Epoch: 569| Step: 0
Training loss: 0.11576876789331436
Validation loss: 1.3440093442957888

Epoch: 6| Step: 1
Training loss: 0.05998723953962326
Validation loss: 1.3731977247422742

Epoch: 6| Step: 2
Training loss: 0.055089063942432404
Validation loss: 1.3816525038852487

Epoch: 6| Step: 3
Training loss: 0.07835152000188828
Validation loss: 1.3834295529191212

Epoch: 6| Step: 4
Training loss: 0.04271437227725983
Validation loss: 1.4359485590329735

Epoch: 6| Step: 5
Training loss: 0.07698292285203934
Validation loss: 1.430935929539383

Epoch: 6| Step: 6
Training loss: 0.11479155719280243
Validation loss: 1.4598065217336018

Epoch: 6| Step: 7
Training loss: 0.0895017758011818
Validation loss: 1.453962883641643

Epoch: 6| Step: 8
Training loss: 0.09172971546649933
Validation loss: 1.4131235999445761

Epoch: 6| Step: 9
Training loss: 0.07690802216529846
Validation loss: 1.404225072553081

Epoch: 6| Step: 10
Training loss: 0.06471231579780579
Validation loss: 1.4050294955571492

Epoch: 6| Step: 11
Training loss: 0.052119702100753784
Validation loss: 1.4051983792294738

Epoch: 6| Step: 12
Training loss: 0.07893038541078568
Validation loss: 1.3911613956574471

Epoch: 6| Step: 13
Training loss: 0.027731729671359062
Validation loss: 1.3980764829984276

Epoch: 570| Step: 0
Training loss: 0.0676027312874794
Validation loss: 1.399738004771612

Epoch: 6| Step: 1
Training loss: 0.057630397379398346
Validation loss: 1.4116408184010496

Epoch: 6| Step: 2
Training loss: 0.08516838401556015
Validation loss: 1.4202412918049803

Epoch: 6| Step: 3
Training loss: 0.08495183289051056
Validation loss: 1.4246145409922446

Epoch: 6| Step: 4
Training loss: 0.041009288281202316
Validation loss: 1.4376969452827209

Epoch: 6| Step: 5
Training loss: 0.06572555005550385
Validation loss: 1.4021103510292627

Epoch: 6| Step: 6
Training loss: 0.07242055237293243
Validation loss: 1.398723465781058

Epoch: 6| Step: 7
Training loss: 0.054170697927474976
Validation loss: 1.4044978285348544

Epoch: 6| Step: 8
Training loss: 0.05502239614725113
Validation loss: 1.3903769767412575

Epoch: 6| Step: 9
Training loss: 0.06240777298808098
Validation loss: 1.4164102987576557

Epoch: 6| Step: 10
Training loss: 0.06760893762111664
Validation loss: 1.4125810207859162

Epoch: 6| Step: 11
Training loss: 0.06287042051553726
Validation loss: 1.4198377074733857

Epoch: 6| Step: 12
Training loss: 0.07894058525562286
Validation loss: 1.4432296778566094

Epoch: 6| Step: 13
Training loss: 0.037167422473430634
Validation loss: 1.4291617972876436

Epoch: 571| Step: 0
Training loss: 0.07708408683538437
Validation loss: 1.4371896745056234

Epoch: 6| Step: 1
Training loss: 0.05422893539071083
Validation loss: 1.4850361065198017

Epoch: 6| Step: 2
Training loss: 0.09483349323272705
Validation loss: 1.4978962136853127

Epoch: 6| Step: 3
Training loss: 0.11262121051549911
Validation loss: 1.4590934450908373

Epoch: 6| Step: 4
Training loss: 0.12089432775974274
Validation loss: 1.489340998793161

Epoch: 6| Step: 5
Training loss: 0.09395132213830948
Validation loss: 1.4520994899093465

Epoch: 6| Step: 6
Training loss: 0.08356311917304993
Validation loss: 1.4694364224710772

Epoch: 6| Step: 7
Training loss: 0.05917700380086899
Validation loss: 1.4429605622445383

Epoch: 6| Step: 8
Training loss: 0.06994113326072693
Validation loss: 1.443359677509595

Epoch: 6| Step: 9
Training loss: 0.04863027483224869
Validation loss: 1.4388971213371522

Epoch: 6| Step: 10
Training loss: 0.05084101855754852
Validation loss: 1.4200037269182102

Epoch: 6| Step: 11
Training loss: 0.0866750180721283
Validation loss: 1.4044477946014815

Epoch: 6| Step: 12
Training loss: 0.052921030670404434
Validation loss: 1.4055199648744316

Epoch: 6| Step: 13
Training loss: 0.04779670014977455
Validation loss: 1.4226923014528008

Epoch: 572| Step: 0
Training loss: 0.04520627111196518
Validation loss: 1.3862793701951222

Epoch: 6| Step: 1
Training loss: 0.1501053273677826
Validation loss: 1.3944046804981847

Epoch: 6| Step: 2
Training loss: 0.06590911746025085
Validation loss: 1.429161980587949

Epoch: 6| Step: 3
Training loss: 0.06399181485176086
Validation loss: 1.4108291723394906

Epoch: 6| Step: 4
Training loss: 0.06238000467419624
Validation loss: 1.4179107694215671

Epoch: 6| Step: 5
Training loss: 0.04725802689790726
Validation loss: 1.431584801725162

Epoch: 6| Step: 6
Training loss: 0.0952700525522232
Validation loss: 1.472785758715804

Epoch: 6| Step: 7
Training loss: 0.10636940598487854
Validation loss: 1.4665547929784304

Epoch: 6| Step: 8
Training loss: 0.06560714542865753
Validation loss: 1.4913439648125761

Epoch: 6| Step: 9
Training loss: 0.052294135093688965
Validation loss: 1.4915962347420313

Epoch: 6| Step: 10
Training loss: 0.06091153994202614
Validation loss: 1.5224114733357583

Epoch: 6| Step: 11
Training loss: 0.07305707037448883
Validation loss: 1.4780432806220105

Epoch: 6| Step: 12
Training loss: 0.07624243944883347
Validation loss: 1.4714582363764446

Epoch: 6| Step: 13
Training loss: 0.09536043554544449
Validation loss: 1.4623996685909968

Epoch: 573| Step: 0
Training loss: 0.049772486090660095
Validation loss: 1.4579155342553252

Epoch: 6| Step: 1
Training loss: 0.04242870956659317
Validation loss: 1.4455732357117437

Epoch: 6| Step: 2
Training loss: 0.05993577092885971
Validation loss: 1.409110519834744

Epoch: 6| Step: 3
Training loss: 0.08747315406799316
Validation loss: 1.4139151137362245

Epoch: 6| Step: 4
Training loss: 0.053797829896211624
Validation loss: 1.4332385101625997

Epoch: 6| Step: 5
Training loss: 0.06535530090332031
Validation loss: 1.4200624150614585

Epoch: 6| Step: 6
Training loss: 0.08176514506340027
Validation loss: 1.4059518626941148

Epoch: 6| Step: 7
Training loss: 0.05443646013736725
Validation loss: 1.4054308033758593

Epoch: 6| Step: 8
Training loss: 0.07279859483242035
Validation loss: 1.411194715448605

Epoch: 6| Step: 9
Training loss: 0.080149807035923
Validation loss: 1.4316212246494908

Epoch: 6| Step: 10
Training loss: 0.06971871107816696
Validation loss: 1.4598922280855076

Epoch: 6| Step: 11
Training loss: 0.10038220137357712
Validation loss: 1.4415695795448877

Epoch: 6| Step: 12
Training loss: 0.059839505702257156
Validation loss: 1.4352845837993007

Epoch: 6| Step: 13
Training loss: 0.025295235216617584
Validation loss: 1.4188363898184992

Epoch: 574| Step: 0
Training loss: 0.09955836087465286
Validation loss: 1.4169907441703222

Epoch: 6| Step: 1
Training loss: 0.04302163049578667
Validation loss: 1.433927680856438

Epoch: 6| Step: 2
Training loss: 0.08499833941459656
Validation loss: 1.4098103559145363

Epoch: 6| Step: 3
Training loss: 0.048685841262340546
Validation loss: 1.3985773555694088

Epoch: 6| Step: 4
Training loss: 0.08282922208309174
Validation loss: 1.4357182031036706

Epoch: 6| Step: 5
Training loss: 0.05769890919327736
Validation loss: 1.4104654045515164

Epoch: 6| Step: 6
Training loss: 0.06555288285017014
Validation loss: 1.4024588959191435

Epoch: 6| Step: 7
Training loss: 0.05510622262954712
Validation loss: 1.4164888692158524

Epoch: 6| Step: 8
Training loss: 0.07914012670516968
Validation loss: 1.3655532675404702

Epoch: 6| Step: 9
Training loss: 0.04114685580134392
Validation loss: 1.3507784329434878

Epoch: 6| Step: 10
Training loss: 0.059574518352746964
Validation loss: 1.3514491576020435

Epoch: 6| Step: 11
Training loss: 0.08523876965045929
Validation loss: 1.377059571204647

Epoch: 6| Step: 12
Training loss: 0.06932123005390167
Validation loss: 1.3660113035991628

Epoch: 6| Step: 13
Training loss: 0.051275696605443954
Validation loss: 1.364748655467905

Epoch: 575| Step: 0
Training loss: 0.07774830609560013
Validation loss: 1.3724289722340082

Epoch: 6| Step: 1
Training loss: 0.0745479166507721
Validation loss: 1.3729088184654072

Epoch: 6| Step: 2
Training loss: 0.053732797503471375
Validation loss: 1.414935774700616

Epoch: 6| Step: 3
Training loss: 0.05329721421003342
Validation loss: 1.3886390687316976

Epoch: 6| Step: 4
Training loss: 0.07602733373641968
Validation loss: 1.4073538414893612

Epoch: 6| Step: 5
Training loss: 0.06360790878534317
Validation loss: 1.4041815124532229

Epoch: 6| Step: 6
Training loss: 0.048331499099731445
Validation loss: 1.446031020533654

Epoch: 6| Step: 7
Training loss: 0.06896644085645676
Validation loss: 1.4575734702489709

Epoch: 6| Step: 8
Training loss: 0.06111765652894974
Validation loss: 1.4600447595760386

Epoch: 6| Step: 9
Training loss: 0.09238005429506302
Validation loss: 1.4501830723977858

Epoch: 6| Step: 10
Training loss: 0.07627958804368973
Validation loss: 1.4491740554891608

Epoch: 6| Step: 11
Training loss: 0.05074808746576309
Validation loss: 1.4445880638655795

Epoch: 6| Step: 12
Training loss: 0.06398073583841324
Validation loss: 1.422348682598401

Epoch: 6| Step: 13
Training loss: 0.09893891215324402
Validation loss: 1.4053162361985894

Epoch: 576| Step: 0
Training loss: 0.09539896249771118
Validation loss: 1.4067537810212822

Epoch: 6| Step: 1
Training loss: 0.04983438551425934
Validation loss: 1.4133677187786307

Epoch: 6| Step: 2
Training loss: 0.061462804675102234
Validation loss: 1.4110506426903509

Epoch: 6| Step: 3
Training loss: 0.08980800956487656
Validation loss: 1.4170248418725946

Epoch: 6| Step: 4
Training loss: 0.05965372920036316
Validation loss: 1.4088171887141403

Epoch: 6| Step: 5
Training loss: 0.10282403975725174
Validation loss: 1.3928816562057824

Epoch: 6| Step: 6
Training loss: 0.05406811833381653
Validation loss: 1.3869946131142237

Epoch: 6| Step: 7
Training loss: 0.08196951448917389
Validation loss: 1.402545525181678

Epoch: 6| Step: 8
Training loss: 0.07893041521310806
Validation loss: 1.3944814166715067

Epoch: 6| Step: 9
Training loss: 0.04661981016397476
Validation loss: 1.4166177254851147

Epoch: 6| Step: 10
Training loss: 0.07186543196439743
Validation loss: 1.4117216961358183

Epoch: 6| Step: 11
Training loss: 0.0853073000907898
Validation loss: 1.4020831405475576

Epoch: 6| Step: 12
Training loss: 0.08775261044502258
Validation loss: 1.3837876037884784

Epoch: 6| Step: 13
Training loss: 0.10728765279054642
Validation loss: 1.4423361696222776

Epoch: 577| Step: 0
Training loss: 0.10850538313388824
Validation loss: 1.4376569101887364

Epoch: 6| Step: 1
Training loss: 0.0760844349861145
Validation loss: 1.429745291509936

Epoch: 6| Step: 2
Training loss: 0.07901329547166824
Validation loss: 1.4225408146458287

Epoch: 6| Step: 3
Training loss: 0.06311794370412827
Validation loss: 1.4157595993370138

Epoch: 6| Step: 4
Training loss: 0.04158337414264679
Validation loss: 1.418479855342578

Epoch: 6| Step: 5
Training loss: 0.06786240637302399
Validation loss: 1.4090457077949279

Epoch: 6| Step: 6
Training loss: 0.048398006707429886
Validation loss: 1.4100587432102492

Epoch: 6| Step: 7
Training loss: 0.07542341947555542
Validation loss: 1.3794809913122525

Epoch: 6| Step: 8
Training loss: 0.09056612104177475
Validation loss: 1.3629696164079892

Epoch: 6| Step: 9
Training loss: 0.04706388711929321
Validation loss: 1.3915971838017946

Epoch: 6| Step: 10
Training loss: 0.10706406086683273
Validation loss: 1.3815713864500805

Epoch: 6| Step: 11
Training loss: 0.08187750726938248
Validation loss: 1.3665770523009761

Epoch: 6| Step: 12
Training loss: 0.08928735554218292
Validation loss: 1.3667219813152025

Epoch: 6| Step: 13
Training loss: 0.0920107513666153
Validation loss: 1.3810778958823091

Epoch: 578| Step: 0
Training loss: 0.06834627687931061
Validation loss: 1.3664706304509153

Epoch: 6| Step: 1
Training loss: 0.05691228061914444
Validation loss: 1.378421022045997

Epoch: 6| Step: 2
Training loss: 0.039527688175439835
Validation loss: 1.3718229673242057

Epoch: 6| Step: 3
Training loss: 0.05619675666093826
Validation loss: 1.3865997675926454

Epoch: 6| Step: 4
Training loss: 0.09186455607414246
Validation loss: 1.3652398470909364

Epoch: 6| Step: 5
Training loss: 0.07182314246892929
Validation loss: 1.3759678486854798

Epoch: 6| Step: 6
Training loss: 0.048622891306877136
Validation loss: 1.3754001355940295

Epoch: 6| Step: 7
Training loss: 0.04294748231768608
Validation loss: 1.3698274063807663

Epoch: 6| Step: 8
Training loss: 0.062186285853385925
Validation loss: 1.3625569035930019

Epoch: 6| Step: 9
Training loss: 0.060130320489406586
Validation loss: 1.3800370821388819

Epoch: 6| Step: 10
Training loss: 0.0871390774846077
Validation loss: 1.3428898024302658

Epoch: 6| Step: 11
Training loss: 0.06634620577096939
Validation loss: 1.3532753964906097

Epoch: 6| Step: 12
Training loss: 0.06854504346847534
Validation loss: 1.327503570946314

Epoch: 6| Step: 13
Training loss: 0.07371213287115097
Validation loss: 1.342726863840575

Epoch: 579| Step: 0
Training loss: 0.07684921473264694
Validation loss: 1.3501785865394018

Epoch: 6| Step: 1
Training loss: 0.10427166521549225
Validation loss: 1.3493053669570594

Epoch: 6| Step: 2
Training loss: 0.037176575511693954
Validation loss: 1.3565271727500423

Epoch: 6| Step: 3
Training loss: 0.0680665448307991
Validation loss: 1.3982187022445023

Epoch: 6| Step: 4
Training loss: 0.068923220038414
Validation loss: 1.3612887884980889

Epoch: 6| Step: 5
Training loss: 0.07673820108175278
Validation loss: 1.3907742872033069

Epoch: 6| Step: 6
Training loss: 0.06606574356555939
Validation loss: 1.3880048797976585

Epoch: 6| Step: 7
Training loss: 0.04854276776313782
Validation loss: 1.3894846285543134

Epoch: 6| Step: 8
Training loss: 0.08147706091403961
Validation loss: 1.399308728915389

Epoch: 6| Step: 9
Training loss: 0.04175886884331703
Validation loss: 1.3949149821394233

Epoch: 6| Step: 10
Training loss: 0.05354736000299454
Validation loss: 1.398364423423685

Epoch: 6| Step: 11
Training loss: 0.05486017465591431
Validation loss: 1.371754696292262

Epoch: 6| Step: 12
Training loss: 0.07381730526685715
Validation loss: 1.3755859021217591

Epoch: 6| Step: 13
Training loss: 0.025313684716820717
Validation loss: 1.37419641787006

Epoch: 580| Step: 0
Training loss: 0.08377230167388916
Validation loss: 1.3811366006892214

Epoch: 6| Step: 1
Training loss: 0.045366570353507996
Validation loss: 1.359941133888819

Epoch: 6| Step: 2
Training loss: 0.07349918782711029
Validation loss: 1.3256031402977564

Epoch: 6| Step: 3
Training loss: 0.0443996898829937
Validation loss: 1.3306936102528726

Epoch: 6| Step: 4
Training loss: 0.07143175601959229
Validation loss: 1.3233175822483596

Epoch: 6| Step: 5
Training loss: 0.06993089616298676
Validation loss: 1.3671371898343485

Epoch: 6| Step: 6
Training loss: 0.0433507040143013
Validation loss: 1.342611962749112

Epoch: 6| Step: 7
Training loss: 0.05827941745519638
Validation loss: 1.3702208521545574

Epoch: 6| Step: 8
Training loss: 0.04940997064113617
Validation loss: 1.3665939159290765

Epoch: 6| Step: 9
Training loss: 0.05796745792031288
Validation loss: 1.3699647918824227

Epoch: 6| Step: 10
Training loss: 0.02789635956287384
Validation loss: 1.3994510532707296

Epoch: 6| Step: 11
Training loss: 0.08161349594593048
Validation loss: 1.4090455744856147

Epoch: 6| Step: 12
Training loss: 0.06393259018659592
Validation loss: 1.4323002401218619

Epoch: 6| Step: 13
Training loss: 0.07204853743314743
Validation loss: 1.4262375767512987

Epoch: 581| Step: 0
Training loss: 0.08544662594795227
Validation loss: 1.4116438832334293

Epoch: 6| Step: 1
Training loss: 0.08067946135997772
Validation loss: 1.4289595555233698

Epoch: 6| Step: 2
Training loss: 0.05257996916770935
Validation loss: 1.4186776427812473

Epoch: 6| Step: 3
Training loss: 0.1019732728600502
Validation loss: 1.410276230945382

Epoch: 6| Step: 4
Training loss: 0.03533468022942543
Validation loss: 1.4099416604606054

Epoch: 6| Step: 5
Training loss: 0.07439243793487549
Validation loss: 1.407298941125152

Epoch: 6| Step: 6
Training loss: 0.07861556112766266
Validation loss: 1.4241634979042956

Epoch: 6| Step: 7
Training loss: 0.04850948601961136
Validation loss: 1.40268414315357

Epoch: 6| Step: 8
Training loss: 0.05226598307490349
Validation loss: 1.392680415543177

Epoch: 6| Step: 9
Training loss: 0.05446699261665344
Validation loss: 1.3909512354481606

Epoch: 6| Step: 10
Training loss: 0.0615042969584465
Validation loss: 1.3765875344635339

Epoch: 6| Step: 11
Training loss: 0.054549358785152435
Validation loss: 1.378947954024038

Epoch: 6| Step: 12
Training loss: 0.04650804400444031
Validation loss: 1.368011313740925

Epoch: 6| Step: 13
Training loss: 0.07218071818351746
Validation loss: 1.3544807812219024

Epoch: 582| Step: 0
Training loss: 0.10002507269382477
Validation loss: 1.3907796041939848

Epoch: 6| Step: 1
Training loss: 0.04003976285457611
Validation loss: 1.3840585190762755

Epoch: 6| Step: 2
Training loss: 0.05669838935136795
Validation loss: 1.3886856161138064

Epoch: 6| Step: 3
Training loss: 0.06656381487846375
Validation loss: 1.3962246756399832

Epoch: 6| Step: 4
Training loss: 0.1058155745267868
Validation loss: 1.3958019223264468

Epoch: 6| Step: 5
Training loss: 0.07032814621925354
Validation loss: 1.4212802597271499

Epoch: 6| Step: 6
Training loss: 0.08502139896154404
Validation loss: 1.3916913347859536

Epoch: 6| Step: 7
Training loss: 0.08726724237203598
Validation loss: 1.4174412168482298

Epoch: 6| Step: 8
Training loss: 0.0770939290523529
Validation loss: 1.3940079366007159

Epoch: 6| Step: 9
Training loss: 0.06697676330804825
Validation loss: 1.411521304038263

Epoch: 6| Step: 10
Training loss: 0.0627116709947586
Validation loss: 1.3957501021764611

Epoch: 6| Step: 11
Training loss: 0.1309337168931961
Validation loss: 1.3837199249575216

Epoch: 6| Step: 12
Training loss: 0.046100690960884094
Validation loss: 1.396231287269182

Epoch: 6| Step: 13
Training loss: 0.0947556346654892
Validation loss: 1.3778768944483932

Epoch: 583| Step: 0
Training loss: 0.06748616695404053
Validation loss: 1.3981630641927

Epoch: 6| Step: 1
Training loss: 0.09316983073949814
Validation loss: 1.3588894272363314

Epoch: 6| Step: 2
Training loss: 0.06471576541662216
Validation loss: 1.3565645999805902

Epoch: 6| Step: 3
Training loss: 0.044430725276470184
Validation loss: 1.3648505544149747

Epoch: 6| Step: 4
Training loss: 0.07145470380783081
Validation loss: 1.3528820506988033

Epoch: 6| Step: 5
Training loss: 0.09169299155473709
Validation loss: 1.3737551102074244

Epoch: 6| Step: 6
Training loss: 0.0984225869178772
Validation loss: 1.3888335535603185

Epoch: 6| Step: 7
Training loss: 0.09684660285711288
Validation loss: 1.3949593895225114

Epoch: 6| Step: 8
Training loss: 0.07677261531352997
Validation loss: 1.423474116991925

Epoch: 6| Step: 9
Training loss: 0.10083988308906555
Validation loss: 1.4286152201314126

Epoch: 6| Step: 10
Training loss: 0.07518462836742401
Validation loss: 1.4642789498452218

Epoch: 6| Step: 11
Training loss: 0.10182532668113708
Validation loss: 1.4374923526599843

Epoch: 6| Step: 12
Training loss: 0.08278045058250427
Validation loss: 1.443413717772371

Epoch: 6| Step: 13
Training loss: 0.02973032370209694
Validation loss: 1.4108446868517066

Epoch: 584| Step: 0
Training loss: 0.06653934717178345
Validation loss: 1.3988636014282063

Epoch: 6| Step: 1
Training loss: 0.11988363415002823
Validation loss: 1.4033216994295838

Epoch: 6| Step: 2
Training loss: 0.08905243128538132
Validation loss: 1.389443782068068

Epoch: 6| Step: 3
Training loss: 0.0673675537109375
Validation loss: 1.35477453021593

Epoch: 6| Step: 4
Training loss: 0.0858653113245964
Validation loss: 1.3228358427683513

Epoch: 6| Step: 5
Training loss: 0.09859606623649597
Validation loss: 1.3731846764523497

Epoch: 6| Step: 6
Training loss: 0.11221238225698471
Validation loss: 1.3758867671412807

Epoch: 6| Step: 7
Training loss: 0.060508400201797485
Validation loss: 1.3811107720098188

Epoch: 6| Step: 8
Training loss: 0.059740204364061356
Validation loss: 1.377930337382901

Epoch: 6| Step: 9
Training loss: 0.09735678881406784
Validation loss: 1.4226334883320717

Epoch: 6| Step: 10
Training loss: 0.08468149602413177
Validation loss: 1.4067797699282247

Epoch: 6| Step: 11
Training loss: 0.16980862617492676
Validation loss: 1.4184936220927904

Epoch: 6| Step: 12
Training loss: 0.04772917181253433
Validation loss: 1.4121121418091558

Epoch: 6| Step: 13
Training loss: 0.03535603731870651
Validation loss: 1.4213952146550661

Epoch: 585| Step: 0
Training loss: 0.09906826168298721
Validation loss: 1.3797941348885978

Epoch: 6| Step: 1
Training loss: 0.15156637132167816
Validation loss: 1.405614294031615

Epoch: 6| Step: 2
Training loss: 0.08208572864532471
Validation loss: 1.392747599591491

Epoch: 6| Step: 3
Training loss: 0.07279815524816513
Validation loss: 1.3797100923394645

Epoch: 6| Step: 4
Training loss: 0.06435877829790115
Validation loss: 1.3557366741600858

Epoch: 6| Step: 5
Training loss: 0.06165130063891411
Validation loss: 1.3520291441230363

Epoch: 6| Step: 6
Training loss: 0.05947510153055191
Validation loss: 1.3451886971791585

Epoch: 6| Step: 7
Training loss: 0.08185751736164093
Validation loss: 1.3163456686081425

Epoch: 6| Step: 8
Training loss: 0.11525456607341766
Validation loss: 1.3526759545008342

Epoch: 6| Step: 9
Training loss: 0.10681691765785217
Validation loss: 1.387763862968773

Epoch: 6| Step: 10
Training loss: 0.07491093128919601
Validation loss: 1.3627430277486001

Epoch: 6| Step: 11
Training loss: 0.05194196105003357
Validation loss: 1.393130338320168

Epoch: 6| Step: 12
Training loss: 0.10107243061065674
Validation loss: 1.4146161784407913

Epoch: 6| Step: 13
Training loss: 0.0578942708671093
Validation loss: 1.4408522728950746

Epoch: 586| Step: 0
Training loss: 0.10455183684825897
Validation loss: 1.4640718493410336

Epoch: 6| Step: 1
Training loss: 0.07306632399559021
Validation loss: 1.422685048913443

Epoch: 6| Step: 2
Training loss: 0.07173657417297363
Validation loss: 1.418553549756286

Epoch: 6| Step: 3
Training loss: 0.07667554914951324
Validation loss: 1.395023351074547

Epoch: 6| Step: 4
Training loss: 0.051824986934661865
Validation loss: 1.3647011204432415

Epoch: 6| Step: 5
Training loss: 0.07654277235269547
Validation loss: 1.4085892733707224

Epoch: 6| Step: 6
Training loss: 0.08110091090202332
Validation loss: 1.3662069286069563

Epoch: 6| Step: 7
Training loss: 0.0321209542453289
Validation loss: 1.3713449553776813

Epoch: 6| Step: 8
Training loss: 0.1006726622581482
Validation loss: 1.3739814078936012

Epoch: 6| Step: 9
Training loss: 0.06504902243614197
Validation loss: 1.3741762535546416

Epoch: 6| Step: 10
Training loss: 0.10721662640571594
Validation loss: 1.3669717722041632

Epoch: 6| Step: 11
Training loss: 0.08943523466587067
Validation loss: 1.3726974623177641

Epoch: 6| Step: 12
Training loss: 0.0518207922577858
Validation loss: 1.364057162756561

Epoch: 6| Step: 13
Training loss: 0.03840490058064461
Validation loss: 1.3756777932566981

Epoch: 587| Step: 0
Training loss: 0.03593452274799347
Validation loss: 1.4034902447013444

Epoch: 6| Step: 1
Training loss: 0.06898275762796402
Validation loss: 1.428660500434137

Epoch: 6| Step: 2
Training loss: 0.05499017983675003
Validation loss: 1.4328589413755684

Epoch: 6| Step: 3
Training loss: 0.0737902894616127
Validation loss: 1.4569780211294852

Epoch: 6| Step: 4
Training loss: 0.07481811940670013
Validation loss: 1.4538554581262733

Epoch: 6| Step: 5
Training loss: 0.08757837116718292
Validation loss: 1.4441306680761359

Epoch: 6| Step: 6
Training loss: 0.08428585529327393
Validation loss: 1.450461784998576

Epoch: 6| Step: 7
Training loss: 0.0878911167383194
Validation loss: 1.4181519003324612

Epoch: 6| Step: 8
Training loss: 0.06346873939037323
Validation loss: 1.4434944570705455

Epoch: 6| Step: 9
Training loss: 0.07346509397029877
Validation loss: 1.3923182487487793

Epoch: 6| Step: 10
Training loss: 0.08794629573822021
Validation loss: 1.4044035762868903

Epoch: 6| Step: 11
Training loss: 0.08034373819828033
Validation loss: 1.3590993099315192

Epoch: 6| Step: 12
Training loss: 0.11379178613424301
Validation loss: 1.3634638901679748

Epoch: 6| Step: 13
Training loss: 0.06043357402086258
Validation loss: 1.3961111140507523

Epoch: 588| Step: 0
Training loss: 0.09012497961521149
Validation loss: 1.3921424496558406

Epoch: 6| Step: 1
Training loss: 0.10130371153354645
Validation loss: 1.3983403880109069

Epoch: 6| Step: 2
Training loss: 0.06776537746191025
Validation loss: 1.4073027769724529

Epoch: 6| Step: 3
Training loss: 0.07332152873277664
Validation loss: 1.4223047840979792

Epoch: 6| Step: 4
Training loss: 0.07924595475196838
Validation loss: 1.4233226109576482

Epoch: 6| Step: 5
Training loss: 0.05220698565244675
Validation loss: 1.4387189457493443

Epoch: 6| Step: 6
Training loss: 0.06366847455501556
Validation loss: 1.4192214813283694

Epoch: 6| Step: 7
Training loss: 0.06990379840135574
Validation loss: 1.4242513859143822

Epoch: 6| Step: 8
Training loss: 0.05393191799521446
Validation loss: 1.3993304929425638

Epoch: 6| Step: 9
Training loss: 0.06567978858947754
Validation loss: 1.4422497326327908

Epoch: 6| Step: 10
Training loss: 0.07755893468856812
Validation loss: 1.4411661035271102

Epoch: 6| Step: 11
Training loss: 0.08873691409826279
Validation loss: 1.4361909717641852

Epoch: 6| Step: 12
Training loss: 0.09876686334609985
Validation loss: 1.4798067231332102

Epoch: 6| Step: 13
Training loss: 0.06438279151916504
Validation loss: 1.5145217500707155

Epoch: 589| Step: 0
Training loss: 0.06644005328416824
Validation loss: 1.5458998712160255

Epoch: 6| Step: 1
Training loss: 0.0793197751045227
Validation loss: 1.5169306057755665

Epoch: 6| Step: 2
Training loss: 0.07649464905261993
Validation loss: 1.5360584707670315

Epoch: 6| Step: 3
Training loss: 0.07756277173757553
Validation loss: 1.526572726106131

Epoch: 6| Step: 4
Training loss: 0.0657227411866188
Validation loss: 1.5064407599869596

Epoch: 6| Step: 5
Training loss: 0.058634642511606216
Validation loss: 1.5141334072236092

Epoch: 6| Step: 6
Training loss: 0.13941730558872223
Validation loss: 1.4891879263744559

Epoch: 6| Step: 7
Training loss: 0.08055957406759262
Validation loss: 1.4701165383861912

Epoch: 6| Step: 8
Training loss: 0.10217162221670151
Validation loss: 1.4563327604724514

Epoch: 6| Step: 9
Training loss: 0.08793554455041885
Validation loss: 1.4006486887572913

Epoch: 6| Step: 10
Training loss: 0.07239338755607605
Validation loss: 1.3978253231253674

Epoch: 6| Step: 11
Training loss: 0.07875818759202957
Validation loss: 1.3863910128993373

Epoch: 6| Step: 12
Training loss: 0.1158614382147789
Validation loss: 1.3750035724332255

Epoch: 6| Step: 13
Training loss: 0.06845740228891373
Validation loss: 1.3696752299544632

Epoch: 590| Step: 0
Training loss: 0.08410187065601349
Validation loss: 1.3662958452778478

Epoch: 6| Step: 1
Training loss: 0.0814838856458664
Validation loss: 1.399787800927316

Epoch: 6| Step: 2
Training loss: 0.05480623245239258
Validation loss: 1.3933922167747252

Epoch: 6| Step: 3
Training loss: 0.056025683879852295
Validation loss: 1.4031495535245506

Epoch: 6| Step: 4
Training loss: 0.06714026629924774
Validation loss: 1.42354828311551

Epoch: 6| Step: 5
Training loss: 0.08025043457746506
Validation loss: 1.4124801248632453

Epoch: 6| Step: 6
Training loss: 0.09866295009851456
Validation loss: 1.4019935156709404

Epoch: 6| Step: 7
Training loss: 0.11909449100494385
Validation loss: 1.4275417622699533

Epoch: 6| Step: 8
Training loss: 0.0969896912574768
Validation loss: 1.3979867530125443

Epoch: 6| Step: 9
Training loss: 0.1174008846282959
Validation loss: 1.4086211548056653

Epoch: 6| Step: 10
Training loss: 0.05777716264128685
Validation loss: 1.3741751165800198

Epoch: 6| Step: 11
Training loss: 0.06330037862062454
Validation loss: 1.3322606189276582

Epoch: 6| Step: 12
Training loss: 0.07813623547554016
Validation loss: 1.3648479664197533

Epoch: 6| Step: 13
Training loss: 0.05865881219506264
Validation loss: 1.3672947793878534

Epoch: 591| Step: 0
Training loss: 0.05756032094359398
Validation loss: 1.3749937254895446

Epoch: 6| Step: 1
Training loss: 0.0658649206161499
Validation loss: 1.349582746464719

Epoch: 6| Step: 2
Training loss: 0.08130569010972977
Validation loss: 1.3751944072784916

Epoch: 6| Step: 3
Training loss: 0.0716155469417572
Validation loss: 1.3649917341047717

Epoch: 6| Step: 4
Training loss: 0.12233089655637741
Validation loss: 1.3771444328369633

Epoch: 6| Step: 5
Training loss: 0.09244279563426971
Validation loss: 1.380188944519207

Epoch: 6| Step: 6
Training loss: 0.08811506628990173
Validation loss: 1.355436913428768

Epoch: 6| Step: 7
Training loss: 0.05680637061595917
Validation loss: 1.377628368075176

Epoch: 6| Step: 8
Training loss: 0.0660257413983345
Validation loss: 1.3824318903748707

Epoch: 6| Step: 9
Training loss: 0.05716434866189957
Validation loss: 1.421371212569616

Epoch: 6| Step: 10
Training loss: 0.07600582391023636
Validation loss: 1.4404541189952562

Epoch: 6| Step: 11
Training loss: 0.055517714470624924
Validation loss: 1.4134379381774573

Epoch: 6| Step: 12
Training loss: 0.06881316006183624
Validation loss: 1.448728185828014

Epoch: 6| Step: 13
Training loss: 0.0367407388985157
Validation loss: 1.4498900219958315

Epoch: 592| Step: 0
Training loss: 0.0803099051117897
Validation loss: 1.43186693550438

Epoch: 6| Step: 1
Training loss: 0.0661543607711792
Validation loss: 1.4150520204215922

Epoch: 6| Step: 2
Training loss: 0.05587392300367355
Validation loss: 1.3894161274356227

Epoch: 6| Step: 3
Training loss: 0.07005255669355392
Validation loss: 1.3977158428520284

Epoch: 6| Step: 4
Training loss: 0.05720195174217224
Validation loss: 1.384880401754892

Epoch: 6| Step: 5
Training loss: 0.08741355687379837
Validation loss: 1.4032399795388664

Epoch: 6| Step: 6
Training loss: 0.0827404111623764
Validation loss: 1.3821570732260262

Epoch: 6| Step: 7
Training loss: 0.05649325251579285
Validation loss: 1.3680463465311195

Epoch: 6| Step: 8
Training loss: 0.03875432908535004
Validation loss: 1.3844296214401082

Epoch: 6| Step: 9
Training loss: 0.06711877882480621
Validation loss: 1.40067470201882

Epoch: 6| Step: 10
Training loss: 0.07503299415111542
Validation loss: 1.3955052052774737

Epoch: 6| Step: 11
Training loss: 0.04489794373512268
Validation loss: 1.365001283666139

Epoch: 6| Step: 12
Training loss: 0.0744035542011261
Validation loss: 1.3958198453790398

Epoch: 6| Step: 13
Training loss: 0.05662214756011963
Validation loss: 1.423332360482985

Epoch: 593| Step: 0
Training loss: 0.04717171564698219
Validation loss: 1.4031644098220333

Epoch: 6| Step: 1
Training loss: 0.05885208025574684
Validation loss: 1.4383767830428256

Epoch: 6| Step: 2
Training loss: 0.05005226284265518
Validation loss: 1.4334028677273822

Epoch: 6| Step: 3
Training loss: 0.07337291538715363
Validation loss: 1.4235082646851898

Epoch: 6| Step: 4
Training loss: 0.08632471412420273
Validation loss: 1.437089648298038

Epoch: 6| Step: 5
Training loss: 0.04624510556459427
Validation loss: 1.4390433353762473

Epoch: 6| Step: 6
Training loss: 0.08033092319965363
Validation loss: 1.4119324671324862

Epoch: 6| Step: 7
Training loss: 0.06098436564207077
Validation loss: 1.410101576517987

Epoch: 6| Step: 8
Training loss: 0.12185478210449219
Validation loss: 1.3891063967058737

Epoch: 6| Step: 9
Training loss: 0.03969724848866463
Validation loss: 1.3749178571085776

Epoch: 6| Step: 10
Training loss: 0.06739184260368347
Validation loss: 1.3940847496832571

Epoch: 6| Step: 11
Training loss: 0.1098402813076973
Validation loss: 1.4045772193580546

Epoch: 6| Step: 12
Training loss: 0.06852912157773972
Validation loss: 1.3625296969567575

Epoch: 6| Step: 13
Training loss: 0.07620706409215927
Validation loss: 1.3635490293143897

Epoch: 594| Step: 0
Training loss: 0.04929518699645996
Validation loss: 1.3692037187596804

Epoch: 6| Step: 1
Training loss: 0.05796726793050766
Validation loss: 1.3763046854285783

Epoch: 6| Step: 2
Training loss: 0.07271430641412735
Validation loss: 1.4342768551200948

Epoch: 6| Step: 3
Training loss: 0.06790222227573395
Validation loss: 1.432251279072095

Epoch: 6| Step: 4
Training loss: 0.07131621241569519
Validation loss: 1.400764746050681

Epoch: 6| Step: 5
Training loss: 0.05159742385149002
Validation loss: 1.4470237692197163

Epoch: 6| Step: 6
Training loss: 0.06405706703662872
Validation loss: 1.4371195711115354

Epoch: 6| Step: 7
Training loss: 0.08779904246330261
Validation loss: 1.4249977193852907

Epoch: 6| Step: 8
Training loss: 0.06677182018756866
Validation loss: 1.4243861744480748

Epoch: 6| Step: 9
Training loss: 0.0570177286863327
Validation loss: 1.408282906778397

Epoch: 6| Step: 10
Training loss: 0.048198334872722626
Validation loss: 1.396207183919927

Epoch: 6| Step: 11
Training loss: 0.06391561031341553
Validation loss: 1.417549567837869

Epoch: 6| Step: 12
Training loss: 0.0662863627076149
Validation loss: 1.4065056065077424

Epoch: 6| Step: 13
Training loss: 0.07744107395410538
Validation loss: 1.4123089864689817

Epoch: 595| Step: 0
Training loss: 0.05441006273031235
Validation loss: 1.3941171412826867

Epoch: 6| Step: 1
Training loss: 0.06125512346625328
Validation loss: 1.4009892991794053

Epoch: 6| Step: 2
Training loss: 0.06141408532857895
Validation loss: 1.4064389531330397

Epoch: 6| Step: 3
Training loss: 0.06668202579021454
Validation loss: 1.3698553193000056

Epoch: 6| Step: 4
Training loss: 0.050733257085084915
Validation loss: 1.418304108804272

Epoch: 6| Step: 5
Training loss: 0.04914134368300438
Validation loss: 1.4036530903590623

Epoch: 6| Step: 6
Training loss: 0.05575947463512421
Validation loss: 1.4299506987294843

Epoch: 6| Step: 7
Training loss: 0.051003068685531616
Validation loss: 1.4240796463463896

Epoch: 6| Step: 8
Training loss: 0.0731429010629654
Validation loss: 1.4461616187967279

Epoch: 6| Step: 9
Training loss: 0.0486006885766983
Validation loss: 1.4310507069351852

Epoch: 6| Step: 10
Training loss: 0.041041042655706406
Validation loss: 1.462965121833227

Epoch: 6| Step: 11
Training loss: 0.04217160493135452
Validation loss: 1.4295037459301692

Epoch: 6| Step: 12
Training loss: 0.09839476644992828
Validation loss: 1.4338979785160353

Epoch: 6| Step: 13
Training loss: 0.06359627842903137
Validation loss: 1.4225795756104171

Epoch: 596| Step: 0
Training loss: 0.06584978103637695
Validation loss: 1.4551348929764123

Epoch: 6| Step: 1
Training loss: 0.04545675963163376
Validation loss: 1.443866611808859

Epoch: 6| Step: 2
Training loss: 0.06022151559591293
Validation loss: 1.4323602619991507

Epoch: 6| Step: 3
Training loss: 0.054864414036273956
Validation loss: 1.4499361950864074

Epoch: 6| Step: 4
Training loss: 0.06266504526138306
Validation loss: 1.4781130577928276

Epoch: 6| Step: 5
Training loss: 0.07704818248748779
Validation loss: 1.446420797737696

Epoch: 6| Step: 6
Training loss: 0.06948132812976837
Validation loss: 1.4570189035066994

Epoch: 6| Step: 7
Training loss: 0.06867916882038116
Validation loss: 1.4657165568362

Epoch: 6| Step: 8
Training loss: 0.030988384038209915
Validation loss: 1.4364699589949783

Epoch: 6| Step: 9
Training loss: 0.051913946866989136
Validation loss: 1.4465288064813102

Epoch: 6| Step: 10
Training loss: 0.09418769180774689
Validation loss: 1.446165536039619

Epoch: 6| Step: 11
Training loss: 0.05874142050743103
Validation loss: 1.4557892840395692

Epoch: 6| Step: 12
Training loss: 0.0715029239654541
Validation loss: 1.4508551551449684

Epoch: 6| Step: 13
Training loss: 0.054995663464069366
Validation loss: 1.4632027905474427

Epoch: 597| Step: 0
Training loss: 0.03978557884693146
Validation loss: 1.4286315460358896

Epoch: 6| Step: 1
Training loss: 0.04287548363208771
Validation loss: 1.4020383011910222

Epoch: 6| Step: 2
Training loss: 0.05140349268913269
Validation loss: 1.4172963339795348

Epoch: 6| Step: 3
Training loss: 0.05312638729810715
Validation loss: 1.4131437168326428

Epoch: 6| Step: 4
Training loss: 0.05705571547150612
Validation loss: 1.4157851255068215

Epoch: 6| Step: 5
Training loss: 0.07014699280261993
Validation loss: 1.4204097947766703

Epoch: 6| Step: 6
Training loss: 0.06135467812418938
Validation loss: 1.4060571744877806

Epoch: 6| Step: 7
Training loss: 0.04800117015838623
Validation loss: 1.4184884153386599

Epoch: 6| Step: 8
Training loss: 0.07041293382644653
Validation loss: 1.4535996362727175

Epoch: 6| Step: 9
Training loss: 0.04543077573180199
Validation loss: 1.4416875493141912

Epoch: 6| Step: 10
Training loss: 0.09239219129085541
Validation loss: 1.4525475284104705

Epoch: 6| Step: 11
Training loss: 0.1184297502040863
Validation loss: 1.467837978434819

Epoch: 6| Step: 12
Training loss: 0.09192470461130142
Validation loss: 1.4689550207507225

Epoch: 6| Step: 13
Training loss: 0.06308546662330627
Validation loss: 1.480122241922604

Epoch: 598| Step: 0
Training loss: 0.07235389947891235
Validation loss: 1.4713253577550252

Epoch: 6| Step: 1
Training loss: 0.04571787640452385
Validation loss: 1.458675858795002

Epoch: 6| Step: 2
Training loss: 0.036960065364837646
Validation loss: 1.4433921844728532

Epoch: 6| Step: 3
Training loss: 0.05875888094305992
Validation loss: 1.4469281678558679

Epoch: 6| Step: 4
Training loss: 0.06353205442428589
Validation loss: 1.406326206781531

Epoch: 6| Step: 5
Training loss: 0.11498435586690903
Validation loss: 1.3833627867442306

Epoch: 6| Step: 6
Training loss: 0.045924246311187744
Validation loss: 1.4035665194193523

Epoch: 6| Step: 7
Training loss: 0.05210769176483154
Validation loss: 1.4152186557810793

Epoch: 6| Step: 8
Training loss: 0.04909849911928177
Validation loss: 1.3963951987604941

Epoch: 6| Step: 9
Training loss: 0.05293506383895874
Validation loss: 1.3923569879224222

Epoch: 6| Step: 10
Training loss: 0.10494090616703033
Validation loss: 1.4058246586912422

Epoch: 6| Step: 11
Training loss: 0.07265190780162811
Validation loss: 1.3951209206734934

Epoch: 6| Step: 12
Training loss: 0.0764172375202179
Validation loss: 1.4082449751515542

Epoch: 6| Step: 13
Training loss: 0.05060664936900139
Validation loss: 1.4013476756311232

Epoch: 599| Step: 0
Training loss: 0.06276793777942657
Validation loss: 1.4183257369584934

Epoch: 6| Step: 1
Training loss: 0.05447104573249817
Validation loss: 1.388656130401037

Epoch: 6| Step: 2
Training loss: 0.06902654469013214
Validation loss: 1.39647658922339

Epoch: 6| Step: 3
Training loss: 0.05004338175058365
Validation loss: 1.407036687738152

Epoch: 6| Step: 4
Training loss: 0.05392187833786011
Validation loss: 1.4158515366174842

Epoch: 6| Step: 5
Training loss: 0.07259050011634827
Validation loss: 1.4008549541555426

Epoch: 6| Step: 6
Training loss: 0.11350958794355392
Validation loss: 1.4063904759704426

Epoch: 6| Step: 7
Training loss: 0.07380905747413635
Validation loss: 1.392839668899454

Epoch: 6| Step: 8
Training loss: 0.09397713840007782
Validation loss: 1.3913851130393244

Epoch: 6| Step: 9
Training loss: 0.10635419189929962
Validation loss: 1.4091045984657862

Epoch: 6| Step: 10
Training loss: 0.09376639127731323
Validation loss: 1.4085411294814079

Epoch: 6| Step: 11
Training loss: 0.05893776938319206
Validation loss: 1.4090221158919796

Epoch: 6| Step: 12
Training loss: 0.1012977659702301
Validation loss: 1.379887156589057

Epoch: 6| Step: 13
Training loss: 0.03389546647667885
Validation loss: 1.4044247147857503

Epoch: 600| Step: 0
Training loss: 0.0477721244096756
Validation loss: 1.356252674133547

Epoch: 6| Step: 1
Training loss: 0.08735278248786926
Validation loss: 1.369751271381173

Epoch: 6| Step: 2
Training loss: 0.055852338671684265
Validation loss: 1.3734470407168071

Epoch: 6| Step: 3
Training loss: 0.050435297191143036
Validation loss: 1.404045788190698

Epoch: 6| Step: 4
Training loss: 0.06198446452617645
Validation loss: 1.364466957507595

Epoch: 6| Step: 5
Training loss: 0.04316850006580353
Validation loss: 1.424029238762394

Epoch: 6| Step: 6
Training loss: 0.10604828596115112
Validation loss: 1.3956897899668703

Epoch: 6| Step: 7
Training loss: 0.05639022961258888
Validation loss: 1.3814250692244499

Epoch: 6| Step: 8
Training loss: 0.05293416976928711
Validation loss: 1.4065700166968889

Epoch: 6| Step: 9
Training loss: 0.083966463804245
Validation loss: 1.3731715922714562

Epoch: 6| Step: 10
Training loss: 0.04080383852124214
Validation loss: 1.4106198241633754

Epoch: 6| Step: 11
Training loss: 0.09981896728277206
Validation loss: 1.398354313706839

Epoch: 6| Step: 12
Training loss: 0.06740470230579376
Validation loss: 1.4075598133507596

Epoch: 6| Step: 13
Training loss: 0.07994088530540466
Validation loss: 1.4039184149875437

Epoch: 601| Step: 0
Training loss: 0.05115743726491928
Validation loss: 1.417231422598644

Epoch: 6| Step: 1
Training loss: 0.050738848745822906
Validation loss: 1.4058195352554321

Epoch: 6| Step: 2
Training loss: 0.053549155592918396
Validation loss: 1.3932829794063364

Epoch: 6| Step: 3
Training loss: 0.056807391345500946
Validation loss: 1.397226995037448

Epoch: 6| Step: 4
Training loss: 0.04631879925727844
Validation loss: 1.3767072282811648

Epoch: 6| Step: 5
Training loss: 0.06082051992416382
Validation loss: 1.4044658842907156

Epoch: 6| Step: 6
Training loss: 0.06886439025402069
Validation loss: 1.3835421095612228

Epoch: 6| Step: 7
Training loss: 0.08800970762968063
Validation loss: 1.365744347213417

Epoch: 6| Step: 8
Training loss: 0.04998788982629776
Validation loss: 1.3918028313626525

Epoch: 6| Step: 9
Training loss: 0.06281095743179321
Validation loss: 1.3794562637165029

Epoch: 6| Step: 10
Training loss: 0.08742226660251617
Validation loss: 1.387664528303249

Epoch: 6| Step: 11
Training loss: 0.067991703748703
Validation loss: 1.412279725074768

Epoch: 6| Step: 12
Training loss: 0.04436364769935608
Validation loss: 1.383395802590155

Epoch: 6| Step: 13
Training loss: 0.04424593970179558
Validation loss: 1.3718412422364759

Epoch: 602| Step: 0
Training loss: 0.03728094696998596
Validation loss: 1.3846820016061105

Epoch: 6| Step: 1
Training loss: 0.057977911084890366
Validation loss: 1.4086781330006097

Epoch: 6| Step: 2
Training loss: 0.07212746888399124
Validation loss: 1.4156889851375292

Epoch: 6| Step: 3
Training loss: 0.06783302128314972
Validation loss: 1.3884466155882804

Epoch: 6| Step: 4
Training loss: 0.0694720596075058
Validation loss: 1.440401131106961

Epoch: 6| Step: 5
Training loss: 0.08147312700748444
Validation loss: 1.420571889287682

Epoch: 6| Step: 6
Training loss: 0.06840009987354279
Validation loss: 1.4263442062562512

Epoch: 6| Step: 7
Training loss: 0.08553203195333481
Validation loss: 1.413583142783052

Epoch: 6| Step: 8
Training loss: 0.07359214872121811
Validation loss: 1.4415728392139557

Epoch: 6| Step: 9
Training loss: 0.058512717485427856
Validation loss: 1.4632836426458051

Epoch: 6| Step: 10
Training loss: 0.06649467349052429
Validation loss: 1.405829696245091

Epoch: 6| Step: 11
Training loss: 0.06539423018693924
Validation loss: 1.4365850879300026

Epoch: 6| Step: 12
Training loss: 0.06765151023864746
Validation loss: 1.425744870657562

Epoch: 6| Step: 13
Training loss: 0.07383005321025848
Validation loss: 1.442443561810319

Epoch: 603| Step: 0
Training loss: 0.07485780119895935
Validation loss: 1.4157368790718816

Epoch: 6| Step: 1
Training loss: 0.06098368763923645
Validation loss: 1.4319409170458395

Epoch: 6| Step: 2
Training loss: 0.1067255362868309
Validation loss: 1.4052577557102326

Epoch: 6| Step: 3
Training loss: 0.06273949146270752
Validation loss: 1.4034050844048942

Epoch: 6| Step: 4
Training loss: 0.053747497498989105
Validation loss: 1.425388628436673

Epoch: 6| Step: 5
Training loss: 0.0643361508846283
Validation loss: 1.433917740339874

Epoch: 6| Step: 6
Training loss: 0.06613284349441528
Validation loss: 1.4114759275990147

Epoch: 6| Step: 7
Training loss: 0.09608057886362076
Validation loss: 1.4073216351129676

Epoch: 6| Step: 8
Training loss: 0.09608834981918335
Validation loss: 1.4313852505017353

Epoch: 6| Step: 9
Training loss: 0.08017605543136597
Validation loss: 1.4127375669376825

Epoch: 6| Step: 10
Training loss: 0.049775630235672
Validation loss: 1.391716359764017

Epoch: 6| Step: 11
Training loss: 0.05002616345882416
Validation loss: 1.3631365837589386

Epoch: 6| Step: 12
Training loss: 0.04449944570660591
Validation loss: 1.3673982799694102

Epoch: 6| Step: 13
Training loss: 0.06813575327396393
Validation loss: 1.3673826571433776

Epoch: 604| Step: 0
Training loss: 0.07583248615264893
Validation loss: 1.3781146977537422

Epoch: 6| Step: 1
Training loss: 0.1287614107131958
Validation loss: 1.4032057446818198

Epoch: 6| Step: 2
Training loss: 0.0772639662027359
Validation loss: 1.4029662903919016

Epoch: 6| Step: 3
Training loss: 0.15423943102359772
Validation loss: 1.4233296276420675

Epoch: 6| Step: 4
Training loss: 0.07939863204956055
Validation loss: 1.4251912242622786

Epoch: 6| Step: 5
Training loss: 0.0678521990776062
Validation loss: 1.465909839958273

Epoch: 6| Step: 6
Training loss: 0.06364285945892334
Validation loss: 1.4451000805824035

Epoch: 6| Step: 7
Training loss: 0.0665854960680008
Validation loss: 1.4474187435642365

Epoch: 6| Step: 8
Training loss: 0.07705658674240112
Validation loss: 1.4525386812866374

Epoch: 6| Step: 9
Training loss: 0.11987918615341187
Validation loss: 1.4908397569451282

Epoch: 6| Step: 10
Training loss: 0.06844811886548996
Validation loss: 1.4617820311618108

Epoch: 6| Step: 11
Training loss: 0.06278565526008606
Validation loss: 1.4327698817817114

Epoch: 6| Step: 12
Training loss: 0.09198291599750519
Validation loss: 1.4007702091688752

Epoch: 6| Step: 13
Training loss: 0.034349169582128525
Validation loss: 1.382042879699379

Epoch: 605| Step: 0
Training loss: 0.044451143592596054
Validation loss: 1.3805321672911286

Epoch: 6| Step: 1
Training loss: 0.10349365323781967
Validation loss: 1.3911950344680457

Epoch: 6| Step: 2
Training loss: 0.05803024396300316
Validation loss: 1.3551950217575155

Epoch: 6| Step: 3
Training loss: 0.09367979317903519
Validation loss: 1.356365837076659

Epoch: 6| Step: 4
Training loss: 0.0709206610918045
Validation loss: 1.361856516971383

Epoch: 6| Step: 5
Training loss: 0.07443535327911377
Validation loss: 1.3518427507851714

Epoch: 6| Step: 6
Training loss: 0.09197477251291275
Validation loss: 1.3743589257681241

Epoch: 6| Step: 7
Training loss: 0.1104862317442894
Validation loss: 1.3735913961164412

Epoch: 6| Step: 8
Training loss: 0.057909946888685226
Validation loss: 1.388966166844932

Epoch: 6| Step: 9
Training loss: 0.08024150133132935
Validation loss: 1.3866133555289237

Epoch: 6| Step: 10
Training loss: 0.08894847333431244
Validation loss: 1.395925393668554

Epoch: 6| Step: 11
Training loss: 0.10670846700668335
Validation loss: 1.439275930004735

Epoch: 6| Step: 12
Training loss: 0.04530733823776245
Validation loss: 1.4451006381742415

Epoch: 6| Step: 13
Training loss: 0.07343887537717819
Validation loss: 1.4339833874856271

Epoch: 606| Step: 0
Training loss: 0.050513505935668945
Validation loss: 1.4397078534608245

Epoch: 6| Step: 1
Training loss: 0.04658050835132599
Validation loss: 1.4463284784747708

Epoch: 6| Step: 2
Training loss: 0.08590340614318848
Validation loss: 1.4526606311080277

Epoch: 6| Step: 3
Training loss: 0.07558594644069672
Validation loss: 1.4091738821357809

Epoch: 6| Step: 4
Training loss: 0.054289817810058594
Validation loss: 1.4208804663791452

Epoch: 6| Step: 5
Training loss: 0.08010991662740707
Validation loss: 1.4300520753347745

Epoch: 6| Step: 6
Training loss: 0.08156038820743561
Validation loss: 1.418418958622922

Epoch: 6| Step: 7
Training loss: 0.058759238570928574
Validation loss: 1.4049292636174027

Epoch: 6| Step: 8
Training loss: 0.08435342460870743
Validation loss: 1.3858947177087106

Epoch: 6| Step: 9
Training loss: 0.06761228293180466
Validation loss: 1.4500359360889723

Epoch: 6| Step: 10
Training loss: 0.07186973839998245
Validation loss: 1.4243926604588826

Epoch: 6| Step: 11
Training loss: 0.04922612011432648
Validation loss: 1.4481196018957323

Epoch: 6| Step: 12
Training loss: 0.0423947349190712
Validation loss: 1.4496126719700393

Epoch: 6| Step: 13
Training loss: 0.028858019039034843
Validation loss: 1.4553067209900066

Epoch: 607| Step: 0
Training loss: 0.07794062793254852
Validation loss: 1.4479667166227936

Epoch: 6| Step: 1
Training loss: 0.036098070442676544
Validation loss: 1.4424156642729236

Epoch: 6| Step: 2
Training loss: 0.0409085713326931
Validation loss: 1.4675123960741105

Epoch: 6| Step: 3
Training loss: 0.05724678188562393
Validation loss: 1.4162099105055614

Epoch: 6| Step: 4
Training loss: 0.058518633246421814
Validation loss: 1.4531020874618201

Epoch: 6| Step: 5
Training loss: 0.08035163581371307
Validation loss: 1.4562554333799629

Epoch: 6| Step: 6
Training loss: 0.05124273896217346
Validation loss: 1.470437913812617

Epoch: 6| Step: 7
Training loss: 0.06796195358037949
Validation loss: 1.4896461508607353

Epoch: 6| Step: 8
Training loss: 0.04105827584862709
Validation loss: 1.452044315235589

Epoch: 6| Step: 9
Training loss: 0.074466273188591
Validation loss: 1.4446840100390936

Epoch: 6| Step: 10
Training loss: 0.09190917015075684
Validation loss: 1.4457963666608256

Epoch: 6| Step: 11
Training loss: 0.047116342931985855
Validation loss: 1.4488548309572282

Epoch: 6| Step: 12
Training loss: 0.06486769020557404
Validation loss: 1.443186790712418

Epoch: 6| Step: 13
Training loss: 0.06052263453602791
Validation loss: 1.4346156620210218

Epoch: 608| Step: 0
Training loss: 0.05511500686407089
Validation loss: 1.4483538161041916

Epoch: 6| Step: 1
Training loss: 0.06678374111652374
Validation loss: 1.438491476479397

Epoch: 6| Step: 2
Training loss: 0.03771436959505081
Validation loss: 1.4316541251315866

Epoch: 6| Step: 3
Training loss: 0.033231064677238464
Validation loss: 1.4143040833934661

Epoch: 6| Step: 4
Training loss: 0.05947571620345116
Validation loss: 1.4373857872460478

Epoch: 6| Step: 5
Training loss: 0.06423835456371307
Validation loss: 1.4156856062591716

Epoch: 6| Step: 6
Training loss: 0.06064051017165184
Validation loss: 1.4437426597841325

Epoch: 6| Step: 7
Training loss: 0.05178957059979439
Validation loss: 1.4599570997299687

Epoch: 6| Step: 8
Training loss: 0.05486845225095749
Validation loss: 1.4343618846708728

Epoch: 6| Step: 9
Training loss: 0.0582515224814415
Validation loss: 1.4441057623073619

Epoch: 6| Step: 10
Training loss: 0.07477673888206482
Validation loss: 1.4432566704288605

Epoch: 6| Step: 11
Training loss: 0.07535558938980103
Validation loss: 1.4562864867589806

Epoch: 6| Step: 12
Training loss: 0.06859323382377625
Validation loss: 1.447200216272826

Epoch: 6| Step: 13
Training loss: 0.05799996852874756
Validation loss: 1.440263960951118

Epoch: 609| Step: 0
Training loss: 0.06229038164019585
Validation loss: 1.4199158786445536

Epoch: 6| Step: 1
Training loss: 0.0514688640832901
Validation loss: 1.4278863629987162

Epoch: 6| Step: 2
Training loss: 0.06609468907117844
Validation loss: 1.420333654649796

Epoch: 6| Step: 3
Training loss: 0.05162055417895317
Validation loss: 1.4183834432273783

Epoch: 6| Step: 4
Training loss: 0.046486757695674896
Validation loss: 1.4270350369074012

Epoch: 6| Step: 5
Training loss: 0.06215570867061615
Validation loss: 1.4493725735654113

Epoch: 6| Step: 6
Training loss: 0.05062679946422577
Validation loss: 1.4290038994563523

Epoch: 6| Step: 7
Training loss: 0.04572683572769165
Validation loss: 1.441337957177111

Epoch: 6| Step: 8
Training loss: 0.07299131155014038
Validation loss: 1.421233634794912

Epoch: 6| Step: 9
Training loss: 0.09597178548574448
Validation loss: 1.4487211537617508

Epoch: 6| Step: 10
Training loss: 0.056066446006298065
Validation loss: 1.4359433676606865

Epoch: 6| Step: 11
Training loss: 0.05569960176944733
Validation loss: 1.4056108472167805

Epoch: 6| Step: 12
Training loss: 0.08636081963777542
Validation loss: 1.422913651312551

Epoch: 6| Step: 13
Training loss: 0.07721415907144547
Validation loss: 1.42108444757359

Epoch: 610| Step: 0
Training loss: 0.06201670318841934
Validation loss: 1.4073990493692377

Epoch: 6| Step: 1
Training loss: 0.05881292372941971
Validation loss: 1.4194116387315976

Epoch: 6| Step: 2
Training loss: 0.05975659191608429
Validation loss: 1.409476605794763

Epoch: 6| Step: 3
Training loss: 0.0535481795668602
Validation loss: 1.4329215352253248

Epoch: 6| Step: 4
Training loss: 0.03518211096525192
Validation loss: 1.444979566399769

Epoch: 6| Step: 5
Training loss: 0.0691390186548233
Validation loss: 1.4303804059182443

Epoch: 6| Step: 6
Training loss: 0.053685322403907776
Validation loss: 1.420579525732225

Epoch: 6| Step: 7
Training loss: 0.05067878216505051
Validation loss: 1.4485796882260231

Epoch: 6| Step: 8
Training loss: 0.06815670430660248
Validation loss: 1.4095843325379074

Epoch: 6| Step: 9
Training loss: 0.05181726813316345
Validation loss: 1.4260365905300263

Epoch: 6| Step: 10
Training loss: 0.05784894526004791
Validation loss: 1.4191224228951238

Epoch: 6| Step: 11
Training loss: 0.049790237098932266
Validation loss: 1.3971122195643764

Epoch: 6| Step: 12
Training loss: 0.06578340381383896
Validation loss: 1.4126304670046734

Epoch: 6| Step: 13
Training loss: 0.047752346843481064
Validation loss: 1.412294650590548

Epoch: 611| Step: 0
Training loss: 0.03163687884807587
Validation loss: 1.3944214082533313

Epoch: 6| Step: 1
Training loss: 0.042231954634189606
Validation loss: 1.417713644684002

Epoch: 6| Step: 2
Training loss: 0.08058834075927734
Validation loss: 1.381798682674285

Epoch: 6| Step: 3
Training loss: 0.04502787068486214
Validation loss: 1.4155385237868114

Epoch: 6| Step: 4
Training loss: 0.05612603574991226
Validation loss: 1.418921423214738

Epoch: 6| Step: 5
Training loss: 0.031859349459409714
Validation loss: 1.4078107482643538

Epoch: 6| Step: 6
Training loss: 0.048084158450365067
Validation loss: 1.4299928116542038

Epoch: 6| Step: 7
Training loss: 0.035964235663414
Validation loss: 1.4327352239239601

Epoch: 6| Step: 8
Training loss: 0.07954643666744232
Validation loss: 1.3893249534791516

Epoch: 6| Step: 9
Training loss: 0.12288892269134521
Validation loss: 1.3970222985872658

Epoch: 6| Step: 10
Training loss: 0.06573167443275452
Validation loss: 1.4050190961489113

Epoch: 6| Step: 11
Training loss: 0.04754618555307388
Validation loss: 1.3761370117946337

Epoch: 6| Step: 12
Training loss: 0.023369207978248596
Validation loss: 1.3694500512974237

Epoch: 6| Step: 13
Training loss: 0.017611384391784668
Validation loss: 1.3613612055778503

Epoch: 612| Step: 0
Training loss: 0.0833175927400589
Validation loss: 1.357464103288548

Epoch: 6| Step: 1
Training loss: 0.06576757878065109
Validation loss: 1.3569445751046623

Epoch: 6| Step: 2
Training loss: 0.051224298775196075
Validation loss: 1.3818527415234556

Epoch: 6| Step: 3
Training loss: 0.06845223903656006
Validation loss: 1.3898544311523438

Epoch: 6| Step: 4
Training loss: 0.05188281089067459
Validation loss: 1.3821803446738952

Epoch: 6| Step: 5
Training loss: 0.0495133176445961
Validation loss: 1.398626103196093

Epoch: 6| Step: 6
Training loss: 0.058142103254795074
Validation loss: 1.4101793227657196

Epoch: 6| Step: 7
Training loss: 0.05468672886490822
Validation loss: 1.4458278122768606

Epoch: 6| Step: 8
Training loss: 0.06494161486625671
Validation loss: 1.4638374454231673

Epoch: 6| Step: 9
Training loss: 0.05053852126002312
Validation loss: 1.4637820682217997

Epoch: 6| Step: 10
Training loss: 0.07526569813489914
Validation loss: 1.4752353545158141

Epoch: 6| Step: 11
Training loss: 0.06064983457326889
Validation loss: 1.4897802478523665

Epoch: 6| Step: 12
Training loss: 0.04960710555315018
Validation loss: 1.4599188514935073

Epoch: 6| Step: 13
Training loss: 0.030829064548015594
Validation loss: 1.465829139114708

Epoch: 613| Step: 0
Training loss: 0.04272680729627609
Validation loss: 1.4483238830361316

Epoch: 6| Step: 1
Training loss: 0.061233557760715485
Validation loss: 1.4075163308010306

Epoch: 6| Step: 2
Training loss: 0.06788972020149231
Validation loss: 1.4130489967202629

Epoch: 6| Step: 3
Training loss: 0.057975150644779205
Validation loss: 1.3950451625290738

Epoch: 6| Step: 4
Training loss: 0.04400382936000824
Validation loss: 1.4186843069650794

Epoch: 6| Step: 5
Training loss: 0.07381568849086761
Validation loss: 1.3875690621714438

Epoch: 6| Step: 6
Training loss: 0.026877574622631073
Validation loss: 1.3783613058828539

Epoch: 6| Step: 7
Training loss: 0.056896477937698364
Validation loss: 1.4145704866737447

Epoch: 6| Step: 8
Training loss: 0.06175914779305458
Validation loss: 1.3805125092947355

Epoch: 6| Step: 9
Training loss: 0.050924528390169144
Validation loss: 1.3966314087631881

Epoch: 6| Step: 10
Training loss: 0.04743684083223343
Validation loss: 1.3850032238550083

Epoch: 6| Step: 11
Training loss: 0.041238367557525635
Validation loss: 1.382130176790299

Epoch: 6| Step: 12
Training loss: 0.08369845896959305
Validation loss: 1.3692873447172103

Epoch: 6| Step: 13
Training loss: 0.04433181509375572
Validation loss: 1.3486627660771853

Epoch: 614| Step: 0
Training loss: 0.04917202144861221
Validation loss: 1.3583489502629926

Epoch: 6| Step: 1
Training loss: 0.05425911396741867
Validation loss: 1.3831476267947946

Epoch: 6| Step: 2
Training loss: 0.040254589170217514
Validation loss: 1.395496376099125

Epoch: 6| Step: 3
Training loss: 0.07710815966129303
Validation loss: 1.3913481773868683

Epoch: 6| Step: 4
Training loss: 0.06520046293735504
Validation loss: 1.3848441595672278

Epoch: 6| Step: 5
Training loss: 0.05712207406759262
Validation loss: 1.3870653542139197

Epoch: 6| Step: 6
Training loss: 0.07798106223344803
Validation loss: 1.3820766902739001

Epoch: 6| Step: 7
Training loss: 0.043386127799749374
Validation loss: 1.3901074894012944

Epoch: 6| Step: 8
Training loss: 0.04020412266254425
Validation loss: 1.4064441970599595

Epoch: 6| Step: 9
Training loss: 0.03591850399971008
Validation loss: 1.3812426213295228

Epoch: 6| Step: 10
Training loss: 0.045189402997493744
Validation loss: 1.4141063677367343

Epoch: 6| Step: 11
Training loss: 0.06277069449424744
Validation loss: 1.3927952986891552

Epoch: 6| Step: 12
Training loss: 0.04664740711450577
Validation loss: 1.3872918339185818

Epoch: 6| Step: 13
Training loss: 0.06299149990081787
Validation loss: 1.4221758304103729

Epoch: 615| Step: 0
Training loss: 0.026837803423404694
Validation loss: 1.404817988795619

Epoch: 6| Step: 1
Training loss: 0.04550441354513168
Validation loss: 1.3963234719409738

Epoch: 6| Step: 2
Training loss: 0.07743941247463226
Validation loss: 1.376789660863979

Epoch: 6| Step: 3
Training loss: 0.06738646328449249
Validation loss: 1.3701431328250515

Epoch: 6| Step: 4
Training loss: 0.03834875673055649
Validation loss: 1.3830799825729863

Epoch: 6| Step: 5
Training loss: 0.06397378444671631
Validation loss: 1.3712157466078316

Epoch: 6| Step: 6
Training loss: 0.041988663375377655
Validation loss: 1.3741136372730296

Epoch: 6| Step: 7
Training loss: 0.08834600448608398
Validation loss: 1.3794871953225905

Epoch: 6| Step: 8
Training loss: 0.07610651850700378
Validation loss: 1.3731062655807824

Epoch: 6| Step: 9
Training loss: 0.041972286999225616
Validation loss: 1.3814196048244354

Epoch: 6| Step: 10
Training loss: 0.04827999323606491
Validation loss: 1.357040745596732

Epoch: 6| Step: 11
Training loss: 0.05833051726222038
Validation loss: 1.3762346365118538

Epoch: 6| Step: 12
Training loss: 0.05050459876656532
Validation loss: 1.3685625009639288

Epoch: 6| Step: 13
Training loss: 0.08225411921739578
Validation loss: 1.390299786803543

Epoch: 616| Step: 0
Training loss: 0.04576759412884712
Validation loss: 1.3862507932929582

Epoch: 6| Step: 1
Training loss: 0.07266195118427277
Validation loss: 1.3864572278914913

Epoch: 6| Step: 2
Training loss: 0.075651153922081
Validation loss: 1.400546040586246

Epoch: 6| Step: 3
Training loss: 0.047136832028627396
Validation loss: 1.3868798748139413

Epoch: 6| Step: 4
Training loss: 0.04857887700200081
Validation loss: 1.3859755544252292

Epoch: 6| Step: 5
Training loss: 0.07183009386062622
Validation loss: 1.3946678420548797

Epoch: 6| Step: 6
Training loss: 0.04912567138671875
Validation loss: 1.3859988822731921

Epoch: 6| Step: 7
Training loss: 0.04438069090247154
Validation loss: 1.390702506547333

Epoch: 6| Step: 8
Training loss: 0.07220739126205444
Validation loss: 1.4036233476413194

Epoch: 6| Step: 9
Training loss: 0.060903873294591904
Validation loss: 1.4085989870050901

Epoch: 6| Step: 10
Training loss: 0.03877171501517296
Validation loss: 1.404112341583416

Epoch: 6| Step: 11
Training loss: 0.03452814370393753
Validation loss: 1.3976580430102605

Epoch: 6| Step: 12
Training loss: 0.05519488453865051
Validation loss: 1.4192694758856168

Epoch: 6| Step: 13
Training loss: 0.06389822065830231
Validation loss: 1.4259394766182028

Epoch: 617| Step: 0
Training loss: 0.03600497916340828
Validation loss: 1.411621961542355

Epoch: 6| Step: 1
Training loss: 0.0703008696436882
Validation loss: 1.3878760978739748

Epoch: 6| Step: 2
Training loss: 0.054967254400253296
Validation loss: 1.4208204169427194

Epoch: 6| Step: 3
Training loss: 0.04620294272899628
Validation loss: 1.4274848263750795

Epoch: 6| Step: 4
Training loss: 0.06361123919487
Validation loss: 1.4203951230613134

Epoch: 6| Step: 5
Training loss: 0.040725626051425934
Validation loss: 1.387852144497697

Epoch: 6| Step: 6
Training loss: 0.06206369400024414
Validation loss: 1.389917976112776

Epoch: 6| Step: 7
Training loss: 0.039223238825798035
Validation loss: 1.3790702973642657

Epoch: 6| Step: 8
Training loss: 0.051912158727645874
Validation loss: 1.3778146172082553

Epoch: 6| Step: 9
Training loss: 0.06948190182447433
Validation loss: 1.349163423302353

Epoch: 6| Step: 10
Training loss: 0.06470663845539093
Validation loss: 1.3362203695440804

Epoch: 6| Step: 11
Training loss: 0.04966791719198227
Validation loss: 1.3479078110828195

Epoch: 6| Step: 12
Training loss: 0.0685439258813858
Validation loss: 1.3747806959254767

Epoch: 6| Step: 13
Training loss: 0.05575569346547127
Validation loss: 1.3699998483862927

Epoch: 618| Step: 0
Training loss: 0.04430043324828148
Validation loss: 1.3658780461998397

Epoch: 6| Step: 1
Training loss: 0.054430410265922546
Validation loss: 1.3784965263899935

Epoch: 6| Step: 2
Training loss: 0.05070681869983673
Validation loss: 1.3845826925769928

Epoch: 6| Step: 3
Training loss: 0.06214814633131027
Validation loss: 1.389830756571985

Epoch: 6| Step: 4
Training loss: 0.06827609986066818
Validation loss: 1.403879988578058

Epoch: 6| Step: 5
Training loss: 0.055108558386564255
Validation loss: 1.3859637885965326

Epoch: 6| Step: 6
Training loss: 0.04228679835796356
Validation loss: 1.3445982228043258

Epoch: 6| Step: 7
Training loss: 0.09302470833063126
Validation loss: 1.355791655919885

Epoch: 6| Step: 8
Training loss: 0.07041953504085541
Validation loss: 1.3858560330124312

Epoch: 6| Step: 9
Training loss: 0.05463683605194092
Validation loss: 1.3911163242914344

Epoch: 6| Step: 10
Training loss: 0.05656232684850693
Validation loss: 1.389058446371427

Epoch: 6| Step: 11
Training loss: 0.08435004949569702
Validation loss: 1.413252285731736

Epoch: 6| Step: 12
Training loss: 0.07076957821846008
Validation loss: 1.4251886977944324

Epoch: 6| Step: 13
Training loss: 0.06153974309563637
Validation loss: 1.430223713638962

Epoch: 619| Step: 0
Training loss: 0.10582363605499268
Validation loss: 1.4001334764624154

Epoch: 6| Step: 1
Training loss: 0.039956312626600266
Validation loss: 1.4172144615521995

Epoch: 6| Step: 2
Training loss: 0.051732137799263
Validation loss: 1.4042830133950839

Epoch: 6| Step: 3
Training loss: 0.07191494107246399
Validation loss: 1.406226009450933

Epoch: 6| Step: 4
Training loss: 0.04955696314573288
Validation loss: 1.3762049277623494

Epoch: 6| Step: 5
Training loss: 0.0560101643204689
Validation loss: 1.3678914987912743

Epoch: 6| Step: 6
Training loss: 0.13468095660209656
Validation loss: 1.3475300253078502

Epoch: 6| Step: 7
Training loss: 0.10698927938938141
Validation loss: 1.3167536720152824

Epoch: 6| Step: 8
Training loss: 0.06442934274673462
Validation loss: 1.3253463904062908

Epoch: 6| Step: 9
Training loss: 0.05163276195526123
Validation loss: 1.346930052644463

Epoch: 6| Step: 10
Training loss: 0.08299244940280914
Validation loss: 1.318020587326378

Epoch: 6| Step: 11
Training loss: 0.04404527693986893
Validation loss: 1.3416338582192697

Epoch: 6| Step: 12
Training loss: 0.04041567072272301
Validation loss: 1.3615304539280553

Epoch: 6| Step: 13
Training loss: 0.05295872688293457
Validation loss: 1.3595573863675516

Epoch: 620| Step: 0
Training loss: 0.04662972688674927
Validation loss: 1.3860122760136921

Epoch: 6| Step: 1
Training loss: 0.04000012204051018
Validation loss: 1.3710113366444905

Epoch: 6| Step: 2
Training loss: 0.05198073759675026
Validation loss: 1.42550709555226

Epoch: 6| Step: 3
Training loss: 0.04805593192577362
Validation loss: 1.3905893884679323

Epoch: 6| Step: 4
Training loss: 0.06137697398662567
Validation loss: 1.401494328693677

Epoch: 6| Step: 5
Training loss: 0.10446915030479431
Validation loss: 1.423914635053245

Epoch: 6| Step: 6
Training loss: 0.07921873033046722
Validation loss: 1.421272035567991

Epoch: 6| Step: 7
Training loss: 0.06812680512666702
Validation loss: 1.4001044752777263

Epoch: 6| Step: 8
Training loss: 0.060976624488830566
Validation loss: 1.387339743234778

Epoch: 6| Step: 9
Training loss: 0.0792166143655777
Validation loss: 1.3661801840669365

Epoch: 6| Step: 10
Training loss: 0.04327019304037094
Validation loss: 1.3742067557509228

Epoch: 6| Step: 11
Training loss: 0.08579716086387634
Validation loss: 1.3443484396062872

Epoch: 6| Step: 12
Training loss: 0.04984090477228165
Validation loss: 1.364728819939398

Epoch: 6| Step: 13
Training loss: 0.04605895280838013
Validation loss: 1.3512062359881658

Epoch: 621| Step: 0
Training loss: 0.04044971987605095
Validation loss: 1.3371019491585352

Epoch: 6| Step: 1
Training loss: 0.12321518361568451
Validation loss: 1.3271389545932892

Epoch: 6| Step: 2
Training loss: 0.08988973498344421
Validation loss: 1.3313898142947946

Epoch: 6| Step: 3
Training loss: 0.05473167821764946
Validation loss: 1.334325869878133

Epoch: 6| Step: 4
Training loss: 0.05409353971481323
Validation loss: 1.3493456077832047

Epoch: 6| Step: 5
Training loss: 0.06524762511253357
Validation loss: 1.3560130416706044

Epoch: 6| Step: 6
Training loss: 0.08240906894207001
Validation loss: 1.3869239976329188

Epoch: 6| Step: 7
Training loss: 0.057673681527376175
Validation loss: 1.3995949299104753

Epoch: 6| Step: 8
Training loss: 0.05034187063574791
Validation loss: 1.4091668103330879

Epoch: 6| Step: 9
Training loss: 0.08265550434589386
Validation loss: 1.389045520495343

Epoch: 6| Step: 10
Training loss: 0.055231738835573196
Validation loss: 1.3949039892483783

Epoch: 6| Step: 11
Training loss: 0.04819633066654205
Validation loss: 1.386719399882901

Epoch: 6| Step: 12
Training loss: 0.03881559893488884
Validation loss: 1.3926667141658005

Epoch: 6| Step: 13
Training loss: 0.11591961979866028
Validation loss: 1.390468002647482

Epoch: 622| Step: 0
Training loss: 0.06432437896728516
Validation loss: 1.3831766754068353

Epoch: 6| Step: 1
Training loss: 0.0425712876021862
Validation loss: 1.4054819473656275

Epoch: 6| Step: 2
Training loss: 0.09119077771902084
Validation loss: 1.4302140358955628

Epoch: 6| Step: 3
Training loss: 0.05678767338395119
Validation loss: 1.406003261125216

Epoch: 6| Step: 4
Training loss: 0.05016681179404259
Validation loss: 1.3747785783583117

Epoch: 6| Step: 5
Training loss: 0.04458307474851608
Validation loss: 1.3760248243167836

Epoch: 6| Step: 6
Training loss: 0.08969742059707642
Validation loss: 1.3889268854612946

Epoch: 6| Step: 7
Training loss: 0.08456888049840927
Validation loss: 1.3544818855101062

Epoch: 6| Step: 8
Training loss: 0.12341302633285522
Validation loss: 1.360362975187199

Epoch: 6| Step: 9
Training loss: 0.08463393151760101
Validation loss: 1.357731794798246

Epoch: 6| Step: 10
Training loss: 0.08958354592323303
Validation loss: 1.3455444125718967

Epoch: 6| Step: 11
Training loss: 0.10403668880462646
Validation loss: 1.3439398247708556

Epoch: 6| Step: 12
Training loss: 0.06079258769750595
Validation loss: 1.3297659415070728

Epoch: 6| Step: 13
Training loss: 0.12866176664829254
Validation loss: 1.3590542052381782

Epoch: 623| Step: 0
Training loss: 0.08737821131944656
Validation loss: 1.3722109615161855

Epoch: 6| Step: 1
Training loss: 0.0924178883433342
Validation loss: 1.3915401940704675

Epoch: 6| Step: 2
Training loss: 0.09258300065994263
Validation loss: 1.3979564366802093

Epoch: 6| Step: 3
Training loss: 0.09928920865058899
Validation loss: 1.3963941271587084

Epoch: 6| Step: 4
Training loss: 0.07046422362327576
Validation loss: 1.3761655989513601

Epoch: 6| Step: 5
Training loss: 0.07094474136829376
Validation loss: 1.3883723251281246

Epoch: 6| Step: 6
Training loss: 0.06004118546843529
Validation loss: 1.4028297778098815

Epoch: 6| Step: 7
Training loss: 0.07742062211036682
Validation loss: 1.3836846537487482

Epoch: 6| Step: 8
Training loss: 0.0723714679479599
Validation loss: 1.3932434487086471

Epoch: 6| Step: 9
Training loss: 0.09212104976177216
Validation loss: 1.3862225958096084

Epoch: 6| Step: 10
Training loss: 0.10793565213680267
Validation loss: 1.3845275255941576

Epoch: 6| Step: 11
Training loss: 0.052715837955474854
Validation loss: 1.3749360461388864

Epoch: 6| Step: 12
Training loss: 0.05562591180205345
Validation loss: 1.3819964342219855

Epoch: 6| Step: 13
Training loss: 0.02248046174645424
Validation loss: 1.3718340614790558

Epoch: 624| Step: 0
Training loss: 0.08189471065998077
Validation loss: 1.364895257257646

Epoch: 6| Step: 1
Training loss: 0.03265826776623726
Validation loss: 1.347719923142464

Epoch: 6| Step: 2
Training loss: 0.0503658652305603
Validation loss: 1.3614262124543548

Epoch: 6| Step: 3
Training loss: 0.07736726105213165
Validation loss: 1.3643327912976664

Epoch: 6| Step: 4
Training loss: 0.09582048654556274
Validation loss: 1.3503985725423342

Epoch: 6| Step: 5
Training loss: 0.08005960285663605
Validation loss: 1.358421943520987

Epoch: 6| Step: 6
Training loss: 0.09247627854347229
Validation loss: 1.3492815776537823

Epoch: 6| Step: 7
Training loss: 0.06181638687849045
Validation loss: 1.375494546787713

Epoch: 6| Step: 8
Training loss: 0.04444147273898125
Validation loss: 1.361209455356803

Epoch: 6| Step: 9
Training loss: 0.07185621559619904
Validation loss: 1.3713319301605225

Epoch: 6| Step: 10
Training loss: 0.07844475656747818
Validation loss: 1.3928728244637931

Epoch: 6| Step: 11
Training loss: 0.10675276070833206
Validation loss: 1.3784584774765918

Epoch: 6| Step: 12
Training loss: 0.036623600870370865
Validation loss: 1.4115743944721837

Epoch: 6| Step: 13
Training loss: 0.08754037320613861
Validation loss: 1.4372014255933865

Epoch: 625| Step: 0
Training loss: 0.059007156640291214
Validation loss: 1.4149078656268377

Epoch: 6| Step: 1
Training loss: 0.12147749215364456
Validation loss: 1.4117410939226869

Epoch: 6| Step: 2
Training loss: 0.0441632904112339
Validation loss: 1.441457515121788

Epoch: 6| Step: 3
Training loss: 0.07005296647548676
Validation loss: 1.4241131890204646

Epoch: 6| Step: 4
Training loss: 0.05264965072274208
Validation loss: 1.3987556042209748

Epoch: 6| Step: 5
Training loss: 0.0763709545135498
Validation loss: 1.3739049498752882

Epoch: 6| Step: 6
Training loss: 0.0531429648399353
Validation loss: 1.3469051314938454

Epoch: 6| Step: 7
Training loss: 0.08039020001888275
Validation loss: 1.329756828405524

Epoch: 6| Step: 8
Training loss: 0.05752543359994888
Validation loss: 1.3167376556704122

Epoch: 6| Step: 9
Training loss: 0.07102547585964203
Validation loss: 1.3007253613523257

Epoch: 6| Step: 10
Training loss: 0.10860683023929596
Validation loss: 1.3315751142399286

Epoch: 6| Step: 11
Training loss: 0.0717696025967598
Validation loss: 1.3147301686707364

Epoch: 6| Step: 12
Training loss: 0.05468609929084778
Validation loss: 1.3398705810628913

Epoch: 6| Step: 13
Training loss: 0.08980180323123932
Validation loss: 1.3371382823554419

Epoch: 626| Step: 0
Training loss: 0.0564335361123085
Validation loss: 1.3932634060100844

Epoch: 6| Step: 1
Training loss: 0.06978578865528107
Validation loss: 1.375463246017374

Epoch: 6| Step: 2
Training loss: 0.052912525832653046
Validation loss: 1.415811082368256

Epoch: 6| Step: 3
Training loss: 0.04775462672114372
Validation loss: 1.4306490421295166

Epoch: 6| Step: 4
Training loss: 0.06805118173360825
Validation loss: 1.4196490792817966

Epoch: 6| Step: 5
Training loss: 0.07618169486522675
Validation loss: 1.422807628108609

Epoch: 6| Step: 6
Training loss: 0.03927324712276459
Validation loss: 1.448788898606454

Epoch: 6| Step: 7
Training loss: 0.05710889771580696
Validation loss: 1.4465976312596311

Epoch: 6| Step: 8
Training loss: 0.05405425280332565
Validation loss: 1.4525204063743673

Epoch: 6| Step: 9
Training loss: 0.07658450305461884
Validation loss: 1.4417374377609582

Epoch: 6| Step: 10
Training loss: 0.0415986031293869
Validation loss: 1.4307262641127392

Epoch: 6| Step: 11
Training loss: 0.07507723569869995
Validation loss: 1.3987796909065657

Epoch: 6| Step: 12
Training loss: 0.059529997408390045
Validation loss: 1.3853658296728646

Epoch: 6| Step: 13
Training loss: 0.08963806927204132
Validation loss: 1.3802218270558182

Epoch: 627| Step: 0
Training loss: 0.07282152771949768
Validation loss: 1.3643468913211618

Epoch: 6| Step: 1
Training loss: 0.05895146355032921
Validation loss: 1.319530390924023

Epoch: 6| Step: 2
Training loss: 0.05843966826796532
Validation loss: 1.3641408566505677

Epoch: 6| Step: 3
Training loss: 0.06285502761602402
Validation loss: 1.3483731233945457

Epoch: 6| Step: 4
Training loss: 0.10628708451986313
Validation loss: 1.3558079555470457

Epoch: 6| Step: 5
Training loss: 0.056731630116701126
Validation loss: 1.334694254782892

Epoch: 6| Step: 6
Training loss: 0.05448532477021217
Validation loss: 1.3393607883043186

Epoch: 6| Step: 7
Training loss: 0.057699739933013916
Validation loss: 1.3571655981002315

Epoch: 6| Step: 8
Training loss: 0.04391186684370041
Validation loss: 1.348969405697238

Epoch: 6| Step: 9
Training loss: 0.06150447204709053
Validation loss: 1.3592860698699951

Epoch: 6| Step: 10
Training loss: 0.055824972689151764
Validation loss: 1.3522720644550938

Epoch: 6| Step: 11
Training loss: 0.038778018206357956
Validation loss: 1.3772031991712508

Epoch: 6| Step: 12
Training loss: 0.056765615940093994
Validation loss: 1.3681548257027902

Epoch: 6| Step: 13
Training loss: 0.05964319407939911
Validation loss: 1.3975761385374172

Epoch: 628| Step: 0
Training loss: 0.05856303498148918
Validation loss: 1.3945778710867769

Epoch: 6| Step: 1
Training loss: 0.06989923119544983
Validation loss: 1.399428916233842

Epoch: 6| Step: 2
Training loss: 0.06926089525222778
Validation loss: 1.4538372229504328

Epoch: 6| Step: 3
Training loss: 0.06391400098800659
Validation loss: 1.4682592832913963

Epoch: 6| Step: 4
Training loss: 0.07211476564407349
Validation loss: 1.4450193233387445

Epoch: 6| Step: 5
Training loss: 0.05098593980073929
Validation loss: 1.4096112558918614

Epoch: 6| Step: 6
Training loss: 0.07486234605312347
Validation loss: 1.3968451471738919

Epoch: 6| Step: 7
Training loss: 0.03341221064329147
Validation loss: 1.382442908261412

Epoch: 6| Step: 8
Training loss: 0.0657445639371872
Validation loss: 1.3993883914844965

Epoch: 6| Step: 9
Training loss: 0.06966912746429443
Validation loss: 1.364620872723159

Epoch: 6| Step: 10
Training loss: 0.06676679849624634
Validation loss: 1.3693054094109485

Epoch: 6| Step: 11
Training loss: 0.07595348358154297
Validation loss: 1.375364121570382

Epoch: 6| Step: 12
Training loss: 0.093534916639328
Validation loss: 1.370322778660764

Epoch: 6| Step: 13
Training loss: 0.05084804445505142
Validation loss: 1.3808672671676965

Epoch: 629| Step: 0
Training loss: 0.05952388793230057
Validation loss: 1.3472887271194047

Epoch: 6| Step: 1
Training loss: 0.05797760561108589
Validation loss: 1.3696914026814122

Epoch: 6| Step: 2
Training loss: 0.06769490242004395
Validation loss: 1.3788562814394634

Epoch: 6| Step: 3
Training loss: 0.04072538763284683
Validation loss: 1.3849895596504211

Epoch: 6| Step: 4
Training loss: 0.051359012722969055
Validation loss: 1.3830873857262314

Epoch: 6| Step: 5
Training loss: 0.09071636199951172
Validation loss: 1.3863307634989421

Epoch: 6| Step: 6
Training loss: 0.0696583017706871
Validation loss: 1.3939192935984621

Epoch: 6| Step: 7
Training loss: 0.08750900626182556
Validation loss: 1.3816283120903918

Epoch: 6| Step: 8
Training loss: 0.04921960458159447
Validation loss: 1.4352916684201968

Epoch: 6| Step: 9
Training loss: 0.07485330104827881
Validation loss: 1.4018686548356087

Epoch: 6| Step: 10
Training loss: 0.04296654835343361
Validation loss: 1.4168161551157634

Epoch: 6| Step: 11
Training loss: 0.04570095241069794
Validation loss: 1.4136866946374216

Epoch: 6| Step: 12
Training loss: 0.04250039905309677
Validation loss: 1.3802840543049637

Epoch: 6| Step: 13
Training loss: 0.03377079218626022
Validation loss: 1.3860271528203

Epoch: 630| Step: 0
Training loss: 0.034485384821891785
Validation loss: 1.3764152385855233

Epoch: 6| Step: 1
Training loss: 0.07772456109523773
Validation loss: 1.372792177302863

Epoch: 6| Step: 2
Training loss: 0.04545309394598007
Validation loss: 1.3758247360106437

Epoch: 6| Step: 3
Training loss: 0.033018458634614944
Validation loss: 1.37682823083734

Epoch: 6| Step: 4
Training loss: 0.060012415051460266
Validation loss: 1.3819474257448667

Epoch: 6| Step: 5
Training loss: 0.04306025058031082
Validation loss: 1.3885682488000521

Epoch: 6| Step: 6
Training loss: 0.07210268080234528
Validation loss: 1.399177324387335

Epoch: 6| Step: 7
Training loss: 0.0676794946193695
Validation loss: 1.4007761568151496

Epoch: 6| Step: 8
Training loss: 0.036975063383579254
Validation loss: 1.436422360840664

Epoch: 6| Step: 9
Training loss: 0.06745335459709167
Validation loss: 1.4182648569025018

Epoch: 6| Step: 10
Training loss: 0.09086713194847107
Validation loss: 1.4629507551911056

Epoch: 6| Step: 11
Training loss: 0.04734427481889725
Validation loss: 1.4540472312640118

Epoch: 6| Step: 12
Training loss: 0.09208623319864273
Validation loss: 1.4699690470131495

Epoch: 6| Step: 13
Training loss: 0.06582486629486084
Validation loss: 1.4655758847472489

Epoch: 631| Step: 0
Training loss: 0.07611804455518723
Validation loss: 1.441304482439513

Epoch: 6| Step: 1
Training loss: 0.04327600449323654
Validation loss: 1.3986700580966087

Epoch: 6| Step: 2
Training loss: 0.050680972635746
Validation loss: 1.3737630831298007

Epoch: 6| Step: 3
Training loss: 0.06335514783859253
Validation loss: 1.3862975694799935

Epoch: 6| Step: 4
Training loss: 0.03967205062508583
Validation loss: 1.3646735017017653

Epoch: 6| Step: 5
Training loss: 0.041769832372665405
Validation loss: 1.3540659642988635

Epoch: 6| Step: 6
Training loss: 0.08000720292329788
Validation loss: 1.35506611101089

Epoch: 6| Step: 7
Training loss: 0.08042654395103455
Validation loss: 1.3600019242173882

Epoch: 6| Step: 8
Training loss: 0.08421942591667175
Validation loss: 1.360593771421781

Epoch: 6| Step: 9
Training loss: 0.03525236248970032
Validation loss: 1.3954371060094526

Epoch: 6| Step: 10
Training loss: 0.044156514108181
Validation loss: 1.4082452981702742

Epoch: 6| Step: 11
Training loss: 0.07830137014389038
Validation loss: 1.4757389637731737

Epoch: 6| Step: 12
Training loss: 0.06769979000091553
Validation loss: 1.4771003902599376

Epoch: 6| Step: 13
Training loss: 0.08770385384559631
Validation loss: 1.4991207814985705

Epoch: 632| Step: 0
Training loss: 0.06142634153366089
Validation loss: 1.514269636523339

Epoch: 6| Step: 1
Training loss: 0.1128186509013176
Validation loss: 1.5146012049849316

Epoch: 6| Step: 2
Training loss: 0.09356877207756042
Validation loss: 1.4941560940075946

Epoch: 6| Step: 3
Training loss: 0.07908423244953156
Validation loss: 1.4545744875425934

Epoch: 6| Step: 4
Training loss: 0.04878813028335571
Validation loss: 1.4283079408830213

Epoch: 6| Step: 5
Training loss: 0.04544583335518837
Validation loss: 1.4046498203790316

Epoch: 6| Step: 6
Training loss: 0.05604739487171173
Validation loss: 1.3903785392802248

Epoch: 6| Step: 7
Training loss: 0.0635608360171318
Validation loss: 1.3669950090428835

Epoch: 6| Step: 8
Training loss: 0.06820374727249146
Validation loss: 1.3839481030741045

Epoch: 6| Step: 9
Training loss: 0.11497156322002411
Validation loss: 1.36058517425291

Epoch: 6| Step: 10
Training loss: 0.05077415332198143
Validation loss: 1.3743041740950717

Epoch: 6| Step: 11
Training loss: 0.05287082493305206
Validation loss: 1.3841418553424139

Epoch: 6| Step: 12
Training loss: 0.0545027032494545
Validation loss: 1.4015728978700535

Epoch: 6| Step: 13
Training loss: 0.052850112318992615
Validation loss: 1.4283723856813164

Epoch: 633| Step: 0
Training loss: 0.04889439046382904
Validation loss: 1.4569639191832593

Epoch: 6| Step: 1
Training loss: 0.1010134145617485
Validation loss: 1.4270316670017857

Epoch: 6| Step: 2
Training loss: 0.03698865324258804
Validation loss: 1.3973283126790037

Epoch: 6| Step: 3
Training loss: 0.049725670367479324
Validation loss: 1.433123375779839

Epoch: 6| Step: 4
Training loss: 0.07927456498146057
Validation loss: 1.4284484636399053

Epoch: 6| Step: 5
Training loss: 0.03771569952368736
Validation loss: 1.40393280213879

Epoch: 6| Step: 6
Training loss: 0.07531996071338654
Validation loss: 1.3990496281654603

Epoch: 6| Step: 7
Training loss: 0.07395309209823608
Validation loss: 1.3554975807025869

Epoch: 6| Step: 8
Training loss: 0.04702159762382507
Validation loss: 1.3622891992651007

Epoch: 6| Step: 9
Training loss: 0.062485259026288986
Validation loss: 1.3581005706582019

Epoch: 6| Step: 10
Training loss: 0.04279465228319168
Validation loss: 1.3426493547296012

Epoch: 6| Step: 11
Training loss: 0.048184752464294434
Validation loss: 1.32783789660341

Epoch: 6| Step: 12
Training loss: 0.05525371804833412
Validation loss: 1.3599227038762902

Epoch: 6| Step: 13
Training loss: 0.04367939010262489
Validation loss: 1.3810333526262673

Epoch: 634| Step: 0
Training loss: 0.055852048099040985
Validation loss: 1.419077334865447

Epoch: 6| Step: 1
Training loss: 0.05519747734069824
Validation loss: 1.459107522041567

Epoch: 6| Step: 2
Training loss: 0.042505040764808655
Validation loss: 1.4589878448876001

Epoch: 6| Step: 3
Training loss: 0.036381058394908905
Validation loss: 1.463884001137108

Epoch: 6| Step: 4
Training loss: 0.07419490069150925
Validation loss: 1.461477743682041

Epoch: 6| Step: 5
Training loss: 0.07600821554660797
Validation loss: 1.4554047097441971

Epoch: 6| Step: 6
Training loss: 0.051050104200839996
Validation loss: 1.4476575928349649

Epoch: 6| Step: 7
Training loss: 0.05142183229327202
Validation loss: 1.4597831195400608

Epoch: 6| Step: 8
Training loss: 0.057614609599113464
Validation loss: 1.4270565368795907

Epoch: 6| Step: 9
Training loss: 0.11157435923814774
Validation loss: 1.4424945090406684

Epoch: 6| Step: 10
Training loss: 0.037371620535850525
Validation loss: 1.4189385624342068

Epoch: 6| Step: 11
Training loss: 0.06753286719322205
Validation loss: 1.4171261877141974

Epoch: 6| Step: 12
Training loss: 0.07417339086532593
Validation loss: 1.409706029840695

Epoch: 6| Step: 13
Training loss: 0.08542879670858383
Validation loss: 1.3924629098625594

Epoch: 635| Step: 0
Training loss: 0.06499870866537094
Validation loss: 1.3906027296537995

Epoch: 6| Step: 1
Training loss: 0.08612651377916336
Validation loss: 1.353821332736682

Epoch: 6| Step: 2
Training loss: 0.10264267027378082
Validation loss: 1.3470951293104438

Epoch: 6| Step: 3
Training loss: 0.06466198712587357
Validation loss: 1.3538141622338244

Epoch: 6| Step: 4
Training loss: 0.08136480301618576
Validation loss: 1.3371995418302474

Epoch: 6| Step: 5
Training loss: 0.04817188158631325
Validation loss: 1.3594158939135972

Epoch: 6| Step: 6
Training loss: 0.056809231638908386
Validation loss: 1.343333412242192

Epoch: 6| Step: 7
Training loss: 0.06912574172019958
Validation loss: 1.3678515213792042

Epoch: 6| Step: 8
Training loss: 0.052058376371860504
Validation loss: 1.3697891414806407

Epoch: 6| Step: 9
Training loss: 0.054506488144397736
Validation loss: 1.4052556599340131

Epoch: 6| Step: 10
Training loss: 0.07826349884271622
Validation loss: 1.3831283097626061

Epoch: 6| Step: 11
Training loss: 0.07052964717149734
Validation loss: 1.39210654458692

Epoch: 6| Step: 12
Training loss: 0.07279827445745468
Validation loss: 1.3963855671626266

Epoch: 6| Step: 13
Training loss: 0.058561403304338455
Validation loss: 1.4057758046734719

Epoch: 636| Step: 0
Training loss: 0.06560428440570831
Validation loss: 1.4034619818451584

Epoch: 6| Step: 1
Training loss: 0.06131738796830177
Validation loss: 1.4327079096148092

Epoch: 6| Step: 2
Training loss: 0.0470878928899765
Validation loss: 1.4145896229692685

Epoch: 6| Step: 3
Training loss: 0.041027847677469254
Validation loss: 1.4248983513924383

Epoch: 6| Step: 4
Training loss: 0.05864039808511734
Validation loss: 1.4095369564589633

Epoch: 6| Step: 5
Training loss: 0.04003346338868141
Validation loss: 1.4136553720761371

Epoch: 6| Step: 6
Training loss: 0.035668328404426575
Validation loss: 1.3838979723632976

Epoch: 6| Step: 7
Training loss: 0.08693588525056839
Validation loss: 1.3834957192021031

Epoch: 6| Step: 8
Training loss: 0.09166131913661957
Validation loss: 1.359335578897948

Epoch: 6| Step: 9
Training loss: 0.043821707367897034
Validation loss: 1.332147054774787

Epoch: 6| Step: 10
Training loss: 0.05717790499329567
Validation loss: 1.35546673241482

Epoch: 6| Step: 11
Training loss: 0.08904361724853516
Validation loss: 1.3432611509035992

Epoch: 6| Step: 12
Training loss: 0.08837854117155075
Validation loss: 1.3439023251174598

Epoch: 6| Step: 13
Training loss: 0.05083473399281502
Validation loss: 1.3505376936287008

Epoch: 637| Step: 0
Training loss: 0.05424521118402481
Validation loss: 1.3638299312642825

Epoch: 6| Step: 1
Training loss: 0.07137034833431244
Validation loss: 1.3672408326979606

Epoch: 6| Step: 2
Training loss: 0.09397716820240021
Validation loss: 1.3291764618248068

Epoch: 6| Step: 3
Training loss: 0.08510148525238037
Validation loss: 1.3759321179441226

Epoch: 6| Step: 4
Training loss: 0.08261381834745407
Validation loss: 1.368235038172814

Epoch: 6| Step: 5
Training loss: 0.09293584525585175
Validation loss: 1.3786650485889886

Epoch: 6| Step: 6
Training loss: 0.04584937542676926
Validation loss: 1.4196279971830306

Epoch: 6| Step: 7
Training loss: 0.07017651200294495
Validation loss: 1.4461312576006817

Epoch: 6| Step: 8
Training loss: 0.06190287321805954
Validation loss: 1.4429164740347094

Epoch: 6| Step: 9
Training loss: 0.05338800698518753
Validation loss: 1.4404175114888016

Epoch: 6| Step: 10
Training loss: 0.052544835954904556
Validation loss: 1.4101492493383345

Epoch: 6| Step: 11
Training loss: 0.1265886276960373
Validation loss: 1.4138499716276764

Epoch: 6| Step: 12
Training loss: 0.041688233613967896
Validation loss: 1.4681989415999381

Epoch: 6| Step: 13
Training loss: 0.055665094405412674
Validation loss: 1.429577536480401

Epoch: 638| Step: 0
Training loss: 0.09772686660289764
Validation loss: 1.4441034223443718

Epoch: 6| Step: 1
Training loss: 0.05583169311285019
Validation loss: 1.4570693162179762

Epoch: 6| Step: 2
Training loss: 0.049936093389987946
Validation loss: 1.4520090549222884

Epoch: 6| Step: 3
Training loss: 0.07097499072551727
Validation loss: 1.4242046648456204

Epoch: 6| Step: 4
Training loss: 0.06999671459197998
Validation loss: 1.4396780921566872

Epoch: 6| Step: 5
Training loss: 0.0722854882478714
Validation loss: 1.4429042223961122

Epoch: 6| Step: 6
Training loss: 0.051859308034181595
Validation loss: 1.4224053480291878

Epoch: 6| Step: 7
Training loss: 0.06375354528427124
Validation loss: 1.448815405368805

Epoch: 6| Step: 8
Training loss: 0.058887921273708344
Validation loss: 1.4366755562443887

Epoch: 6| Step: 9
Training loss: 0.07428504526615143
Validation loss: 1.4492592337310954

Epoch: 6| Step: 10
Training loss: 0.05969112366437912
Validation loss: 1.4433183541861914

Epoch: 6| Step: 11
Training loss: 0.11292479187250137
Validation loss: 1.4203280095131166

Epoch: 6| Step: 12
Training loss: 0.06629934906959534
Validation loss: 1.4349274558405722

Epoch: 6| Step: 13
Training loss: 0.039448920637369156
Validation loss: 1.3918871520667948

Epoch: 639| Step: 0
Training loss: 0.0459132045507431
Validation loss: 1.388538888705674

Epoch: 6| Step: 1
Training loss: 0.083823062479496
Validation loss: 1.3956705357438774

Epoch: 6| Step: 2
Training loss: 0.0663318932056427
Validation loss: 1.3737827590716782

Epoch: 6| Step: 3
Training loss: 0.05295264720916748
Validation loss: 1.3577444950739543

Epoch: 6| Step: 4
Training loss: 0.06349267810583115
Validation loss: 1.355234674228135

Epoch: 6| Step: 5
Training loss: 0.0604722835123539
Validation loss: 1.372932211045296

Epoch: 6| Step: 6
Training loss: 0.07386869937181473
Validation loss: 1.3987440165653025

Epoch: 6| Step: 7
Training loss: 0.04255520924925804
Validation loss: 1.4229972183063466

Epoch: 6| Step: 8
Training loss: 0.07844683527946472
Validation loss: 1.4155990436512937

Epoch: 6| Step: 9
Training loss: 0.05548093467950821
Validation loss: 1.4242224385661464

Epoch: 6| Step: 10
Training loss: 0.09947468340396881
Validation loss: 1.3759995686110629

Epoch: 6| Step: 11
Training loss: 0.052176740020513535
Validation loss: 1.3704676301248613

Epoch: 6| Step: 12
Training loss: 0.048119135200977325
Validation loss: 1.386522016858542

Epoch: 6| Step: 13
Training loss: 0.10184560716152191
Validation loss: 1.3552344473459388

Epoch: 640| Step: 0
Training loss: 0.07348054647445679
Validation loss: 1.3895114557717436

Epoch: 6| Step: 1
Training loss: 0.06569695472717285
Validation loss: 1.383495621783759

Epoch: 6| Step: 2
Training loss: 0.08759129792451859
Validation loss: 1.4033550344487673

Epoch: 6| Step: 3
Training loss: 0.05397304520010948
Validation loss: 1.407793391135431

Epoch: 6| Step: 4
Training loss: 0.05841158330440521
Validation loss: 1.3966902872567535

Epoch: 6| Step: 5
Training loss: 0.057024091482162476
Validation loss: 1.377711590900216

Epoch: 6| Step: 6
Training loss: 0.0745721310377121
Validation loss: 1.378268967392624

Epoch: 6| Step: 7
Training loss: 0.09814299643039703
Validation loss: 1.3935245185770013

Epoch: 6| Step: 8
Training loss: 0.06890872865915298
Validation loss: 1.4156449712732786

Epoch: 6| Step: 9
Training loss: 0.0686245709657669
Validation loss: 1.3771391376372306

Epoch: 6| Step: 10
Training loss: 0.07694205641746521
Validation loss: 1.4121178042504094

Epoch: 6| Step: 11
Training loss: 0.07744580507278442
Validation loss: 1.4110132584007837

Epoch: 6| Step: 12
Training loss: 0.05855158716440201
Validation loss: 1.3873033690196213

Epoch: 6| Step: 13
Training loss: 0.04281340539455414
Validation loss: 1.3660160674843738

Epoch: 641| Step: 0
Training loss: 0.07738368213176727
Validation loss: 1.398523352479422

Epoch: 6| Step: 1
Training loss: 0.08996813744306564
Validation loss: 1.3886898268935501

Epoch: 6| Step: 2
Training loss: 0.06659992039203644
Validation loss: 1.3779177998983732

Epoch: 6| Step: 3
Training loss: 0.04419388249516487
Validation loss: 1.354251185412048

Epoch: 6| Step: 4
Training loss: 0.05462772399187088
Validation loss: 1.3573680379057442

Epoch: 6| Step: 5
Training loss: 0.033391132950782776
Validation loss: 1.3389389232922626

Epoch: 6| Step: 6
Training loss: 0.04137452691793442
Validation loss: 1.3609516627045088

Epoch: 6| Step: 7
Training loss: 0.03971553221344948
Validation loss: 1.330069403494558

Epoch: 6| Step: 8
Training loss: 0.04964601993560791
Validation loss: 1.3677198015233523

Epoch: 6| Step: 9
Training loss: 0.05322007089853287
Validation loss: 1.3623092136075419

Epoch: 6| Step: 10
Training loss: 0.07227857410907745
Validation loss: 1.355874087220879

Epoch: 6| Step: 11
Training loss: 0.07201239466667175
Validation loss: 1.3627625255174534

Epoch: 6| Step: 12
Training loss: 0.1000734269618988
Validation loss: 1.3469276261586014

Epoch: 6| Step: 13
Training loss: 0.032764285802841187
Validation loss: 1.356363788727791

Epoch: 642| Step: 0
Training loss: 0.06934241205453873
Validation loss: 1.330324944629464

Epoch: 6| Step: 1
Training loss: 0.07347093522548676
Validation loss: 1.3600153346215524

Epoch: 6| Step: 2
Training loss: 0.06545165181159973
Validation loss: 1.3653628364686043

Epoch: 6| Step: 3
Training loss: 0.053153764456510544
Validation loss: 1.356579670342066

Epoch: 6| Step: 4
Training loss: 0.048018887639045715
Validation loss: 1.352222215744757

Epoch: 6| Step: 5
Training loss: 0.08544833958148956
Validation loss: 1.384368481174592

Epoch: 6| Step: 6
Training loss: 0.06181415915489197
Validation loss: 1.3732749915892077

Epoch: 6| Step: 7
Training loss: 0.07756537199020386
Validation loss: 1.3687818499021633

Epoch: 6| Step: 8
Training loss: 0.05277243256568909
Validation loss: 1.3621440472141388

Epoch: 6| Step: 9
Training loss: 0.0904439240694046
Validation loss: 1.3784752712454846

Epoch: 6| Step: 10
Training loss: 0.06462972611188889
Validation loss: 1.3887957347336637

Epoch: 6| Step: 11
Training loss: 0.04971318691968918
Validation loss: 1.395288348197937

Epoch: 6| Step: 12
Training loss: 0.04895862936973572
Validation loss: 1.3902375608362176

Epoch: 6| Step: 13
Training loss: 0.031083008274435997
Validation loss: 1.3840320751231203

Epoch: 643| Step: 0
Training loss: 0.11740975081920624
Validation loss: 1.3891089077918761

Epoch: 6| Step: 1
Training loss: 0.04591655731201172
Validation loss: 1.3717123282852994

Epoch: 6| Step: 2
Training loss: 0.07583906501531601
Validation loss: 1.3831560893725323

Epoch: 6| Step: 3
Training loss: 0.07460357248783112
Validation loss: 1.377618924263985

Epoch: 6| Step: 4
Training loss: 0.08094943314790726
Validation loss: 1.3665198023601244

Epoch: 6| Step: 5
Training loss: 0.058155834674835205
Validation loss: 1.366373582552838

Epoch: 6| Step: 6
Training loss: 0.05695122480392456
Validation loss: 1.365434395369663

Epoch: 6| Step: 7
Training loss: 0.05141524598002434
Validation loss: 1.3465225914473176

Epoch: 6| Step: 8
Training loss: 0.0724809467792511
Validation loss: 1.3619430244609874

Epoch: 6| Step: 9
Training loss: 0.07586504518985748
Validation loss: 1.323578453833057

Epoch: 6| Step: 10
Training loss: 0.051015280187129974
Validation loss: 1.3434728678836618

Epoch: 6| Step: 11
Training loss: 0.08042988181114197
Validation loss: 1.3298980625726844

Epoch: 6| Step: 12
Training loss: 0.06920720636844635
Validation loss: 1.3434047865611252

Epoch: 6| Step: 13
Training loss: 0.06545596569776535
Validation loss: 1.3539454757526357

Epoch: 644| Step: 0
Training loss: 0.07496154308319092
Validation loss: 1.3937688130204395

Epoch: 6| Step: 1
Training loss: 0.048954762518405914
Validation loss: 1.4069018428043654

Epoch: 6| Step: 2
Training loss: 0.07919397205114365
Validation loss: 1.4231496254603069

Epoch: 6| Step: 3
Training loss: 0.08511074632406235
Validation loss: 1.4017244282589163

Epoch: 6| Step: 4
Training loss: 0.05411853641271591
Validation loss: 1.4199283751108314

Epoch: 6| Step: 5
Training loss: 0.0545073077082634
Validation loss: 1.4095026229017524

Epoch: 6| Step: 6
Training loss: 0.05570603162050247
Validation loss: 1.3971749133961175

Epoch: 6| Step: 7
Training loss: 0.09613011032342911
Validation loss: 1.4135969531151555

Epoch: 6| Step: 8
Training loss: 0.06766325980424881
Validation loss: 1.4074294195380261

Epoch: 6| Step: 9
Training loss: 0.0593390166759491
Validation loss: 1.4175524596245057

Epoch: 6| Step: 10
Training loss: 0.06255584955215454
Validation loss: 1.4149729590262137

Epoch: 6| Step: 11
Training loss: 0.07414714246988297
Validation loss: 1.3842775308957664

Epoch: 6| Step: 12
Training loss: 0.0895504355430603
Validation loss: 1.405900743699843

Epoch: 6| Step: 13
Training loss: 0.04199960455298424
Validation loss: 1.3532931407292683

Epoch: 645| Step: 0
Training loss: 0.032930631190538406
Validation loss: 1.3671280030281312

Epoch: 6| Step: 1
Training loss: 0.05794353038072586
Validation loss: 1.3810431752153622

Epoch: 6| Step: 2
Training loss: 0.05332774296402931
Validation loss: 1.3823429794721707

Epoch: 6| Step: 3
Training loss: 0.07960474491119385
Validation loss: 1.386011149293633

Epoch: 6| Step: 4
Training loss: 0.06602474302053452
Validation loss: 1.4059306780497234

Epoch: 6| Step: 5
Training loss: 0.053134359419345856
Validation loss: 1.3866259045498346

Epoch: 6| Step: 6
Training loss: 0.0763319805264473
Validation loss: 1.4045611825040591

Epoch: 6| Step: 7
Training loss: 0.06435845047235489
Validation loss: 1.3940825487977715

Epoch: 6| Step: 8
Training loss: 0.049989983439445496
Validation loss: 1.4224057812844553

Epoch: 6| Step: 9
Training loss: 0.050057001411914825
Validation loss: 1.4383205624036892

Epoch: 6| Step: 10
Training loss: 0.05787273496389389
Validation loss: 1.4042370242457236

Epoch: 6| Step: 11
Training loss: 0.03448032587766647
Validation loss: 1.431021160976861

Epoch: 6| Step: 12
Training loss: 0.0645688846707344
Validation loss: 1.4287364059878933

Epoch: 6| Step: 13
Training loss: 0.0746675580739975
Validation loss: 1.4558108019572433

Epoch: 646| Step: 0
Training loss: 0.052907053381204605
Validation loss: 1.4286881287892659

Epoch: 6| Step: 1
Training loss: 0.02948479726910591
Validation loss: 1.4315743113076815

Epoch: 6| Step: 2
Training loss: 0.0690271183848381
Validation loss: 1.4239852809777824

Epoch: 6| Step: 3
Training loss: 0.07640765607357025
Validation loss: 1.4349917673295545

Epoch: 6| Step: 4
Training loss: 0.06517741829156876
Validation loss: 1.4148903341703518

Epoch: 6| Step: 5
Training loss: 0.06170303374528885
Validation loss: 1.4004800691399524

Epoch: 6| Step: 6
Training loss: 0.055019017308950424
Validation loss: 1.40622418157516

Epoch: 6| Step: 7
Training loss: 0.11633690446615219
Validation loss: 1.3867641713029595

Epoch: 6| Step: 8
Training loss: 0.06446971744298935
Validation loss: 1.393716403874018

Epoch: 6| Step: 9
Training loss: 0.07206161320209503
Validation loss: 1.39036613510501

Epoch: 6| Step: 10
Training loss: 0.08139994740486145
Validation loss: 1.3674821853637695

Epoch: 6| Step: 11
Training loss: 0.056819453835487366
Validation loss: 1.3992342192639586

Epoch: 6| Step: 12
Training loss: 0.07373560220003128
Validation loss: 1.3920675246946272

Epoch: 6| Step: 13
Training loss: 0.05397981405258179
Validation loss: 1.3990830106119956

Epoch: 647| Step: 0
Training loss: 0.08910953998565674
Validation loss: 1.4140029876462874

Epoch: 6| Step: 1
Training loss: 0.06498970836400986
Validation loss: 1.4328424635753836

Epoch: 6| Step: 2
Training loss: 0.06924682855606079
Validation loss: 1.457265805172664

Epoch: 6| Step: 3
Training loss: 0.06271092593669891
Validation loss: 1.4461147048140084

Epoch: 6| Step: 4
Training loss: 0.0755157321691513
Validation loss: 1.4673481218276485

Epoch: 6| Step: 5
Training loss: 0.06309318542480469
Validation loss: 1.44725747646824

Epoch: 6| Step: 6
Training loss: 0.04650312662124634
Validation loss: 1.4207712527244323

Epoch: 6| Step: 7
Training loss: 0.051567912101745605
Validation loss: 1.4006479914470384

Epoch: 6| Step: 8
Training loss: 0.07455404102802277
Validation loss: 1.3877366345415834

Epoch: 6| Step: 9
Training loss: 0.0818827822804451
Validation loss: 1.3930201633002168

Epoch: 6| Step: 10
Training loss: 0.06286545842885971
Validation loss: 1.392167676520604

Epoch: 6| Step: 11
Training loss: 0.07878436148166656
Validation loss: 1.4026973273164483

Epoch: 6| Step: 12
Training loss: 0.07231327891349792
Validation loss: 1.3926946597714578

Epoch: 6| Step: 13
Training loss: 0.04119224101305008
Validation loss: 1.4095344979275939

Epoch: 648| Step: 0
Training loss: 0.08700351417064667
Validation loss: 1.4080922526697959

Epoch: 6| Step: 1
Training loss: 0.06114427000284195
Validation loss: 1.414432071229463

Epoch: 6| Step: 2
Training loss: 0.09532848000526428
Validation loss: 1.390514043069655

Epoch: 6| Step: 3
Training loss: 0.04826509952545166
Validation loss: 1.4239059122659827

Epoch: 6| Step: 4
Training loss: 0.06682106852531433
Validation loss: 1.4068770511175996

Epoch: 6| Step: 5
Training loss: 0.06101404130458832
Validation loss: 1.4266042222258866

Epoch: 6| Step: 6
Training loss: 0.10283742845058441
Validation loss: 1.4011009162472141

Epoch: 6| Step: 7
Training loss: 0.08574750274419785
Validation loss: 1.4067526107193322

Epoch: 6| Step: 8
Training loss: 0.08177396655082703
Validation loss: 1.4253518824936242

Epoch: 6| Step: 9
Training loss: 0.08283063024282455
Validation loss: 1.450875469433364

Epoch: 6| Step: 10
Training loss: 0.047150760889053345
Validation loss: 1.4451007881472189

Epoch: 6| Step: 11
Training loss: 0.060190409421920776
Validation loss: 1.4587032436042704

Epoch: 6| Step: 12
Training loss: 0.0867694541811943
Validation loss: 1.4802965989676855

Epoch: 6| Step: 13
Training loss: 0.15166309475898743
Validation loss: 1.4964398139266557

Epoch: 649| Step: 0
Training loss: 0.09341556578874588
Validation loss: 1.467255861528458

Epoch: 6| Step: 1
Training loss: 0.1084899753332138
Validation loss: 1.451550474730871

Epoch: 6| Step: 2
Training loss: 0.10824514925479889
Validation loss: 1.404564187090884

Epoch: 6| Step: 3
Training loss: 0.10139619559049606
Validation loss: 1.4352535368293844

Epoch: 6| Step: 4
Training loss: 0.06817075610160828
Validation loss: 1.398894138233636

Epoch: 6| Step: 5
Training loss: 0.04593533277511597
Validation loss: 1.3772286727864256

Epoch: 6| Step: 6
Training loss: 0.08166562020778656
Validation loss: 1.3915414669180428

Epoch: 6| Step: 7
Training loss: 0.09095975756645203
Validation loss: 1.3817425363807267

Epoch: 6| Step: 8
Training loss: 0.06324665993452072
Validation loss: 1.3971207295694659

Epoch: 6| Step: 9
Training loss: 0.1446695178747177
Validation loss: 1.407803903343857

Epoch: 6| Step: 10
Training loss: 0.1437486708164215
Validation loss: 1.394743941163504

Epoch: 6| Step: 11
Training loss: 0.16134077310562134
Validation loss: 1.381640822656693

Epoch: 6| Step: 12
Training loss: 0.08462612330913544
Validation loss: 1.3696887044496433

Epoch: 6| Step: 13
Training loss: 0.043499067425727844
Validation loss: 1.3680703627165927

Epoch: 650| Step: 0
Training loss: 0.08235609531402588
Validation loss: 1.351105667570586

Epoch: 6| Step: 1
Training loss: 0.09256207942962646
Validation loss: 1.3424526132563108

Epoch: 6| Step: 2
Training loss: 0.06461173295974731
Validation loss: 1.3611181589864916

Epoch: 6| Step: 3
Training loss: 0.08031655848026276
Validation loss: 1.3695543235348118

Epoch: 6| Step: 4
Training loss: 0.09901793301105499
Validation loss: 1.3445771932601929

Epoch: 6| Step: 5
Training loss: 0.06993795931339264
Validation loss: 1.3840841644553727

Epoch: 6| Step: 6
Training loss: 0.0891561210155487
Validation loss: 1.3984277825201712

Epoch: 6| Step: 7
Training loss: 0.07347770035266876
Validation loss: 1.3575519912986345

Epoch: 6| Step: 8
Training loss: 0.06104154884815216
Validation loss: 1.3723221389196252

Epoch: 6| Step: 9
Training loss: 0.10299424827098846
Validation loss: 1.3344172341849214

Epoch: 6| Step: 10
Training loss: 0.06090134382247925
Validation loss: 1.3569157777294036

Epoch: 6| Step: 11
Training loss: 0.050121091306209564
Validation loss: 1.316300254996105

Epoch: 6| Step: 12
Training loss: 0.09597548097372055
Validation loss: 1.3191075312194003

Epoch: 6| Step: 13
Training loss: 0.119014210999012
Validation loss: 1.3154009862612652

Epoch: 651| Step: 0
Training loss: 0.05127369239926338
Validation loss: 1.3496985691849903

Epoch: 6| Step: 1
Training loss: 0.09589666873216629
Validation loss: 1.352095309124198

Epoch: 6| Step: 2
Training loss: 0.06772841513156891
Validation loss: 1.3548813135393205

Epoch: 6| Step: 3
Training loss: 0.08879470825195312
Validation loss: 1.320255692287158

Epoch: 6| Step: 4
Training loss: 0.05915576219558716
Validation loss: 1.3352784751563944

Epoch: 6| Step: 5
Training loss: 0.053564634174108505
Validation loss: 1.3927157130292667

Epoch: 6| Step: 6
Training loss: 0.06861045211553574
Validation loss: 1.363909411173995

Epoch: 6| Step: 7
Training loss: 0.11296557635068893
Validation loss: 1.3842576985718102

Epoch: 6| Step: 8
Training loss: 0.17407779395580292
Validation loss: 1.3762843660129014

Epoch: 6| Step: 9
Training loss: 0.1159835010766983
Validation loss: 1.3990889646673714

Epoch: 6| Step: 10
Training loss: 0.09909139573574066
Validation loss: 1.3846380825965636

Epoch: 6| Step: 11
Training loss: 0.1123514175415039
Validation loss: 1.371807840562636

Epoch: 6| Step: 12
Training loss: 0.12260933220386505
Validation loss: 1.3856909185327508

Epoch: 6| Step: 13
Training loss: 0.07497363537549973
Validation loss: 1.3749854923576437

Epoch: 652| Step: 0
Training loss: 0.06842697411775589
Validation loss: 1.3922189756106305

Epoch: 6| Step: 1
Training loss: 0.08501887321472168
Validation loss: 1.3706910699926398

Epoch: 6| Step: 2
Training loss: 0.07272244989871979
Validation loss: 1.3643584757722833

Epoch: 6| Step: 3
Training loss: 0.07153832912445068
Validation loss: 1.3587929734619715

Epoch: 6| Step: 4
Training loss: 0.09470440447330475
Validation loss: 1.3531292869198708

Epoch: 6| Step: 5
Training loss: 0.07909319549798965
Validation loss: 1.3623805263990998

Epoch: 6| Step: 6
Training loss: 0.04956375062465668
Validation loss: 1.3608767819660965

Epoch: 6| Step: 7
Training loss: 0.06954085826873779
Validation loss: 1.35462865906377

Epoch: 6| Step: 8
Training loss: 0.08621066808700562
Validation loss: 1.3648446721415366

Epoch: 6| Step: 9
Training loss: 0.1153549775481224
Validation loss: 1.3596115112304688

Epoch: 6| Step: 10
Training loss: 0.11891388893127441
Validation loss: 1.3643290483823387

Epoch: 6| Step: 11
Training loss: 0.05974653735756874
Validation loss: 1.3739801094096193

Epoch: 6| Step: 12
Training loss: 0.06130985915660858
Validation loss: 1.3810948761560584

Epoch: 6| Step: 13
Training loss: 0.08695422112941742
Validation loss: 1.3860593527875922

Epoch: 653| Step: 0
Training loss: 0.04818744212388992
Validation loss: 1.3922705945148264

Epoch: 6| Step: 1
Training loss: 0.07563699036836624
Validation loss: 1.3840484490958593

Epoch: 6| Step: 2
Training loss: 0.09913045167922974
Validation loss: 1.3841928320546304

Epoch: 6| Step: 3
Training loss: 0.10131445527076721
Validation loss: 1.4188770837681268

Epoch: 6| Step: 4
Training loss: 0.08496996015310287
Validation loss: 1.3919510777278612

Epoch: 6| Step: 5
Training loss: 0.08647260069847107
Validation loss: 1.368098885141393

Epoch: 6| Step: 6
Training loss: 0.06237948313355446
Validation loss: 1.3699251438981743

Epoch: 6| Step: 7
Training loss: 0.07264956086874008
Validation loss: 1.374726838963006

Epoch: 6| Step: 8
Training loss: 0.058412034064531326
Validation loss: 1.3805627451148084

Epoch: 6| Step: 9
Training loss: 0.053908612579107285
Validation loss: 1.4069850265338857

Epoch: 6| Step: 10
Training loss: 0.03271006792783737
Validation loss: 1.404198327372151

Epoch: 6| Step: 11
Training loss: 0.06542050093412399
Validation loss: 1.3909905065772354

Epoch: 6| Step: 12
Training loss: 0.11599382013082504
Validation loss: 1.3728020159147118

Epoch: 6| Step: 13
Training loss: 0.09618031978607178
Validation loss: 1.363872298630335

Epoch: 654| Step: 0
Training loss: 0.04995174705982208
Validation loss: 1.3465885910936581

Epoch: 6| Step: 1
Training loss: 0.07903435826301575
Validation loss: 1.3371738477419781

Epoch: 6| Step: 2
Training loss: 0.0651949942111969
Validation loss: 1.3514987364892037

Epoch: 6| Step: 3
Training loss: 0.047147151082754135
Validation loss: 1.3599709874840193

Epoch: 6| Step: 4
Training loss: 0.03985682874917984
Validation loss: 1.3565743386104543

Epoch: 6| Step: 5
Training loss: 0.0960325300693512
Validation loss: 1.369705488604884

Epoch: 6| Step: 6
Training loss: 0.0483589842915535
Validation loss: 1.3828424465271734

Epoch: 6| Step: 7
Training loss: 0.04624529182910919
Validation loss: 1.333583088331325

Epoch: 6| Step: 8
Training loss: 0.045479774475097656
Validation loss: 1.3658302432747298

Epoch: 6| Step: 9
Training loss: 0.05127478018403053
Validation loss: 1.402340171798583

Epoch: 6| Step: 10
Training loss: 0.07161717116832733
Validation loss: 1.3871592347339918

Epoch: 6| Step: 11
Training loss: 0.10537274181842804
Validation loss: 1.3774351484032088

Epoch: 6| Step: 12
Training loss: 0.05245114490389824
Validation loss: 1.369994773659655

Epoch: 6| Step: 13
Training loss: 0.09901162981987
Validation loss: 1.3752824907661767

Epoch: 655| Step: 0
Training loss: 0.05529485642910004
Validation loss: 1.3753377699082898

Epoch: 6| Step: 1
Training loss: 0.05967634916305542
Validation loss: 1.3721962968508403

Epoch: 6| Step: 2
Training loss: 0.04793626070022583
Validation loss: 1.3882368008295696

Epoch: 6| Step: 3
Training loss: 0.07486148178577423
Validation loss: 1.3890048880730905

Epoch: 6| Step: 4
Training loss: 0.06795495748519897
Validation loss: 1.3815912674832087

Epoch: 6| Step: 5
Training loss: 0.06321275234222412
Validation loss: 1.3782530638479418

Epoch: 6| Step: 6
Training loss: 0.07024824619293213
Validation loss: 1.407231379580754

Epoch: 6| Step: 7
Training loss: 0.08995121717453003
Validation loss: 1.4211080240946945

Epoch: 6| Step: 8
Training loss: 0.04546568542718887
Validation loss: 1.4337612018790296

Epoch: 6| Step: 9
Training loss: 0.08272732049226761
Validation loss: 1.447345483687616

Epoch: 6| Step: 10
Training loss: 0.07506900280714035
Validation loss: 1.4666765120721632

Epoch: 6| Step: 11
Training loss: 0.08039246499538422
Validation loss: 1.464125051293322

Epoch: 6| Step: 12
Training loss: 0.055460184812545776
Validation loss: 1.4697811244636454

Epoch: 6| Step: 13
Training loss: 0.044087111949920654
Validation loss: 1.4663389164914367

Epoch: 656| Step: 0
Training loss: 0.04819352552294731
Validation loss: 1.4423051521342287

Epoch: 6| Step: 1
Training loss: 0.05090923607349396
Validation loss: 1.4122331949972338

Epoch: 6| Step: 2
Training loss: 0.03485938161611557
Validation loss: 1.4210175609075895

Epoch: 6| Step: 3
Training loss: 0.05246831476688385
Validation loss: 1.4057010694216656

Epoch: 6| Step: 4
Training loss: 0.08632467687129974
Validation loss: 1.3606970630666262

Epoch: 6| Step: 5
Training loss: 0.05231621861457825
Validation loss: 1.3456185735682005

Epoch: 6| Step: 6
Training loss: 0.07412882149219513
Validation loss: 1.347998729316137

Epoch: 6| Step: 7
Training loss: 0.0667564645409584
Validation loss: 1.3483673782758816

Epoch: 6| Step: 8
Training loss: 0.08246396481990814
Validation loss: 1.3568218190182921

Epoch: 6| Step: 9
Training loss: 0.038896165788173676
Validation loss: 1.32247164428875

Epoch: 6| Step: 10
Training loss: 0.09021806716918945
Validation loss: 1.3675146487451368

Epoch: 6| Step: 11
Training loss: 0.0601143017411232
Validation loss: 1.359521250570974

Epoch: 6| Step: 12
Training loss: 0.07004722952842712
Validation loss: 1.362612275667088

Epoch: 6| Step: 13
Training loss: 0.049629900604486465
Validation loss: 1.3895630336576892

Epoch: 657| Step: 0
Training loss: 0.08857788145542145
Validation loss: 1.3816075427557832

Epoch: 6| Step: 1
Training loss: 0.0572560578584671
Validation loss: 1.3958275420691377

Epoch: 6| Step: 2
Training loss: 0.06123615428805351
Validation loss: 1.4196127589030931

Epoch: 6| Step: 3
Training loss: 0.05772233009338379
Validation loss: 1.407251545177993

Epoch: 6| Step: 4
Training loss: 0.061909258365631104
Validation loss: 1.4089428327416862

Epoch: 6| Step: 5
Training loss: 0.02632947266101837
Validation loss: 1.4200115287175743

Epoch: 6| Step: 6
Training loss: 0.05670389533042908
Validation loss: 1.4477872489601054

Epoch: 6| Step: 7
Training loss: 0.08674420416355133
Validation loss: 1.42708210919493

Epoch: 6| Step: 8
Training loss: 0.04266539216041565
Validation loss: 1.43675277310033

Epoch: 6| Step: 9
Training loss: 0.05505635589361191
Validation loss: 1.462990403175354

Epoch: 6| Step: 10
Training loss: 0.057550303637981415
Validation loss: 1.3963035178440872

Epoch: 6| Step: 11
Training loss: 0.06552259624004364
Validation loss: 1.4021573887076428

Epoch: 6| Step: 12
Training loss: 0.11019892990589142
Validation loss: 1.4129519680494904

Epoch: 6| Step: 13
Training loss: 0.042681124061346054
Validation loss: 1.4270692717644475

Epoch: 658| Step: 0
Training loss: 0.041587553918361664
Validation loss: 1.3988452316612325

Epoch: 6| Step: 1
Training loss: 0.06253418326377869
Validation loss: 1.3991267245302919

Epoch: 6| Step: 2
Training loss: 0.058377381414175034
Validation loss: 1.3943792991740729

Epoch: 6| Step: 3
Training loss: 0.04321761801838875
Validation loss: 1.3658123195812266

Epoch: 6| Step: 4
Training loss: 0.06112394481897354
Validation loss: 1.3378957086993801

Epoch: 6| Step: 5
Training loss: 0.052276868373155594
Validation loss: 1.3907939054632699

Epoch: 6| Step: 6
Training loss: 0.05686582624912262
Validation loss: 1.4020658705824165

Epoch: 6| Step: 7
Training loss: 0.052006520330905914
Validation loss: 1.4135500013187368

Epoch: 6| Step: 8
Training loss: 0.02927563712000847
Validation loss: 1.4115938332773024

Epoch: 6| Step: 9
Training loss: 0.04933605343103409
Validation loss: 1.4162877644262006

Epoch: 6| Step: 10
Training loss: 0.049377866089344025
Validation loss: 1.413268853259343

Epoch: 6| Step: 11
Training loss: 0.05853338912129402
Validation loss: 1.395266802080216

Epoch: 6| Step: 12
Training loss: 0.055391669273376465
Validation loss: 1.3884494330293389

Epoch: 6| Step: 13
Training loss: 0.052010536193847656
Validation loss: 1.4133760236924695

Epoch: 659| Step: 0
Training loss: 0.03277622163295746
Validation loss: 1.398525232909828

Epoch: 6| Step: 1
Training loss: 0.02632782608270645
Validation loss: 1.4182830805419593

Epoch: 6| Step: 2
Training loss: 0.04884973168373108
Validation loss: 1.433138960151262

Epoch: 6| Step: 3
Training loss: 0.06903423368930817
Validation loss: 1.3929182855031823

Epoch: 6| Step: 4
Training loss: 0.05082913115620613
Validation loss: 1.40175643274861

Epoch: 6| Step: 5
Training loss: 0.07776737213134766
Validation loss: 1.41633431501286

Epoch: 6| Step: 6
Training loss: 0.06486213207244873
Validation loss: 1.381246066862537

Epoch: 6| Step: 7
Training loss: 0.04645320773124695
Validation loss: 1.3776623382363269

Epoch: 6| Step: 8
Training loss: 0.04613390564918518
Validation loss: 1.3649948463645032

Epoch: 6| Step: 9
Training loss: 0.05219292640686035
Validation loss: 1.385658170587273

Epoch: 6| Step: 10
Training loss: 0.06075814738869667
Validation loss: 1.3544069374761274

Epoch: 6| Step: 11
Training loss: 0.07241270691156387
Validation loss: 1.3613139903673561

Epoch: 6| Step: 12
Training loss: 0.05111704394221306
Validation loss: 1.3728911633132606

Epoch: 6| Step: 13
Training loss: 0.05890991911292076
Validation loss: 1.369136300138248

Epoch: 660| Step: 0
Training loss: 0.055877685546875
Validation loss: 1.389167436989405

Epoch: 6| Step: 1
Training loss: 0.03348197788000107
Validation loss: 1.3772271435747865

Epoch: 6| Step: 2
Training loss: 0.05019966885447502
Validation loss: 1.3870585733844387

Epoch: 6| Step: 3
Training loss: 0.07366997003555298
Validation loss: 1.3858018190630021

Epoch: 6| Step: 4
Training loss: 0.064938485622406
Validation loss: 1.398770325927324

Epoch: 6| Step: 5
Training loss: 0.04149634391069412
Validation loss: 1.383948515820247

Epoch: 6| Step: 6
Training loss: 0.04358145594596863
Validation loss: 1.39899581286215

Epoch: 6| Step: 7
Training loss: 0.04146743565797806
Validation loss: 1.3968295615206483

Epoch: 6| Step: 8
Training loss: 0.06269161403179169
Validation loss: 1.3919633293664584

Epoch: 6| Step: 9
Training loss: 0.0680021420121193
Validation loss: 1.4020520993458327

Epoch: 6| Step: 10
Training loss: 0.06029987707734108
Validation loss: 1.3672907967721262

Epoch: 6| Step: 11
Training loss: 0.07927069067955017
Validation loss: 1.392534448254493

Epoch: 6| Step: 12
Training loss: 0.04653007537126541
Validation loss: 1.3727960842911915

Epoch: 6| Step: 13
Training loss: 0.04819054901599884
Validation loss: 1.3848718148405834

Epoch: 661| Step: 0
Training loss: 0.10264653712511063
Validation loss: 1.4049169530150711

Epoch: 6| Step: 1
Training loss: 0.0584251694381237
Validation loss: 1.3940415818204162

Epoch: 6| Step: 2
Training loss: 0.05379440635442734
Validation loss: 1.3741887724527748

Epoch: 6| Step: 3
Training loss: 0.04499759525060654
Validation loss: 1.3740017644820675

Epoch: 6| Step: 4
Training loss: 0.062269534915685654
Validation loss: 1.3670956575742332

Epoch: 6| Step: 5
Training loss: 0.05189768970012665
Validation loss: 1.3998093169222596

Epoch: 6| Step: 6
Training loss: 0.06199169531464577
Validation loss: 1.404643234386239

Epoch: 6| Step: 7
Training loss: 0.043993569910526276
Validation loss: 1.4029830168652278

Epoch: 6| Step: 8
Training loss: 0.04802665859460831
Validation loss: 1.4269016993943082

Epoch: 6| Step: 9
Training loss: 0.07680686563253403
Validation loss: 1.4304308481113885

Epoch: 6| Step: 10
Training loss: 0.03995709493756294
Validation loss: 1.4244636175453023

Epoch: 6| Step: 11
Training loss: 0.05635597184300423
Validation loss: 1.4378892913941415

Epoch: 6| Step: 12
Training loss: 0.07877963781356812
Validation loss: 1.4233194576796664

Epoch: 6| Step: 13
Training loss: 0.060377199202775955
Validation loss: 1.4277287067905549

Epoch: 662| Step: 0
Training loss: 0.050916850566864014
Validation loss: 1.435358428185986

Epoch: 6| Step: 1
Training loss: 0.05527973175048828
Validation loss: 1.3990422435986098

Epoch: 6| Step: 2
Training loss: 0.09485328942537308
Validation loss: 1.4210280192795621

Epoch: 6| Step: 3
Training loss: 0.0392853207886219
Validation loss: 1.395294544517353

Epoch: 6| Step: 4
Training loss: 0.040095262229442596
Validation loss: 1.3685878143515637

Epoch: 6| Step: 5
Training loss: 0.04898959770798683
Validation loss: 1.3667559341717792

Epoch: 6| Step: 6
Training loss: 0.070807546377182
Validation loss: 1.3572124601692281

Epoch: 6| Step: 7
Training loss: 0.052992936223745346
Validation loss: 1.352791286924834

Epoch: 6| Step: 8
Training loss: 0.07487548142671585
Validation loss: 1.3500681461826447

Epoch: 6| Step: 9
Training loss: 0.06117688864469528
Validation loss: 1.3567017329636442

Epoch: 6| Step: 10
Training loss: 0.09930869936943054
Validation loss: 1.3636179816338323

Epoch: 6| Step: 11
Training loss: 0.05246247723698616
Validation loss: 1.3726150105076451

Epoch: 6| Step: 12
Training loss: 0.06803205609321594
Validation loss: 1.3623739237426429

Epoch: 6| Step: 13
Training loss: 0.07806281745433807
Validation loss: 1.3874215836166053

Epoch: 663| Step: 0
Training loss: 0.0768265649676323
Validation loss: 1.3922817886516612

Epoch: 6| Step: 1
Training loss: 0.048873696476221085
Validation loss: 1.4071415073128157

Epoch: 6| Step: 2
Training loss: 0.0561797060072422
Validation loss: 1.4405438438538583

Epoch: 6| Step: 3
Training loss: 0.07440625876188278
Validation loss: 1.3814272137098416

Epoch: 6| Step: 4
Training loss: 0.03152836859226227
Validation loss: 1.4240576900461668

Epoch: 6| Step: 5
Training loss: 0.04565687105059624
Validation loss: 1.4122416768022763

Epoch: 6| Step: 6
Training loss: 0.05370565503835678
Validation loss: 1.3986185660926245

Epoch: 6| Step: 7
Training loss: 0.06629340350627899
Validation loss: 1.3990140589334632

Epoch: 6| Step: 8
Training loss: 0.08455511927604675
Validation loss: 1.3839982735213412

Epoch: 6| Step: 9
Training loss: 0.07793676853179932
Validation loss: 1.3618924271675847

Epoch: 6| Step: 10
Training loss: 0.10725925117731094
Validation loss: 1.3752590353770922

Epoch: 6| Step: 11
Training loss: 0.062459174543619156
Validation loss: 1.391068353447863

Epoch: 6| Step: 12
Training loss: 0.0597696453332901
Validation loss: 1.3942853314902193

Epoch: 6| Step: 13
Training loss: 0.06509406864643097
Validation loss: 1.4085466797633837

Epoch: 664| Step: 0
Training loss: 0.0909196138381958
Validation loss: 1.4098235355910433

Epoch: 6| Step: 1
Training loss: 0.07241754233837128
Validation loss: 1.4074797886674122

Epoch: 6| Step: 2
Training loss: 0.04130272567272186
Validation loss: 1.4154340092853834

Epoch: 6| Step: 3
Training loss: 0.09447208046913147
Validation loss: 1.4408788732303086

Epoch: 6| Step: 4
Training loss: 0.0688316822052002
Validation loss: 1.442293850324487

Epoch: 6| Step: 5
Training loss: 0.06862982362508774
Validation loss: 1.4403259215816375

Epoch: 6| Step: 6
Training loss: 0.06151380389928818
Validation loss: 1.4214563113386913

Epoch: 6| Step: 7
Training loss: 0.0698438212275505
Validation loss: 1.4262630349846297

Epoch: 6| Step: 8
Training loss: 0.07354850322008133
Validation loss: 1.4231967349206247

Epoch: 6| Step: 9
Training loss: 0.06939101219177246
Validation loss: 1.406714424010246

Epoch: 6| Step: 10
Training loss: 0.03570304811000824
Validation loss: 1.3895680327569284

Epoch: 6| Step: 11
Training loss: 0.05459265783429146
Validation loss: 1.4090190420868576

Epoch: 6| Step: 12
Training loss: 0.05370736122131348
Validation loss: 1.384631017202972

Epoch: 6| Step: 13
Training loss: 0.021973099559545517
Validation loss: 1.3741020028309157

Epoch: 665| Step: 0
Training loss: 0.05452009662985802
Validation loss: 1.3832780789303523

Epoch: 6| Step: 1
Training loss: 0.05147206783294678
Validation loss: 1.3608429957461614

Epoch: 6| Step: 2
Training loss: 0.04577343165874481
Validation loss: 1.3836005804359273

Epoch: 6| Step: 3
Training loss: 0.041963495314121246
Validation loss: 1.4167968855109265

Epoch: 6| Step: 4
Training loss: 0.09451146423816681
Validation loss: 1.403538534718175

Epoch: 6| Step: 5
Training loss: 0.04182938486337662
Validation loss: 1.4100021303340953

Epoch: 6| Step: 6
Training loss: 0.06766842305660248
Validation loss: 1.4345676104227703

Epoch: 6| Step: 7
Training loss: 0.051211364567279816
Validation loss: 1.430741794647709

Epoch: 6| Step: 8
Training loss: 0.04662773758172989
Validation loss: 1.42998973143998

Epoch: 6| Step: 9
Training loss: 0.057061225175857544
Validation loss: 1.4522349744714715

Epoch: 6| Step: 10
Training loss: 0.05515442416071892
Validation loss: 1.4401713699422858

Epoch: 6| Step: 11
Training loss: 0.0586424358189106
Validation loss: 1.4492662984837767

Epoch: 6| Step: 12
Training loss: 0.07680085301399231
Validation loss: 1.4530975113632858

Epoch: 6| Step: 13
Training loss: 0.027718326076865196
Validation loss: 1.4191834644604755

Epoch: 666| Step: 0
Training loss: 0.05815139785408974
Validation loss: 1.4127770271352542

Epoch: 6| Step: 1
Training loss: 0.07306055724620819
Validation loss: 1.434688118196303

Epoch: 6| Step: 2
Training loss: 0.04187533259391785
Validation loss: 1.41702829253289

Epoch: 6| Step: 3
Training loss: 0.09668291360139847
Validation loss: 1.4093595140723771

Epoch: 6| Step: 4
Training loss: 0.0905642956495285
Validation loss: 1.4056562210923882

Epoch: 6| Step: 5
Training loss: 0.06565725803375244
Validation loss: 1.3979185614534604

Epoch: 6| Step: 6
Training loss: 0.03995772451162338
Validation loss: 1.3906462730899933

Epoch: 6| Step: 7
Training loss: 0.053668178617954254
Validation loss: 1.3745927080031364

Epoch: 6| Step: 8
Training loss: 0.1189546138048172
Validation loss: 1.387681886713992

Epoch: 6| Step: 9
Training loss: 0.04669695720076561
Validation loss: 1.4065810006151918

Epoch: 6| Step: 10
Training loss: 0.04777994006872177
Validation loss: 1.3693569366649916

Epoch: 6| Step: 11
Training loss: 0.05786404013633728
Validation loss: 1.3829200742065266

Epoch: 6| Step: 12
Training loss: 0.05351566523313522
Validation loss: 1.3688251728652625

Epoch: 6| Step: 13
Training loss: 0.03646525368094444
Validation loss: 1.37472072211645

Epoch: 667| Step: 0
Training loss: 0.030060850083827972
Validation loss: 1.3953231368013608

Epoch: 6| Step: 1
Training loss: 0.04720880463719368
Validation loss: 1.4018961178359164

Epoch: 6| Step: 2
Training loss: 0.06692562252283096
Validation loss: 1.4072830407850203

Epoch: 6| Step: 3
Training loss: 0.08002378791570663
Validation loss: 1.405898295423036

Epoch: 6| Step: 4
Training loss: 0.05804531276226044
Validation loss: 1.4320962377773818

Epoch: 6| Step: 5
Training loss: 0.04956858977675438
Validation loss: 1.4616571651991976

Epoch: 6| Step: 6
Training loss: 0.057809971272945404
Validation loss: 1.4141641227147912

Epoch: 6| Step: 7
Training loss: 0.05069105327129364
Validation loss: 1.4329827953410406

Epoch: 6| Step: 8
Training loss: 0.06082833558320999
Validation loss: 1.3986146193678661

Epoch: 6| Step: 9
Training loss: 0.051114365458488464
Validation loss: 1.3887385245292418

Epoch: 6| Step: 10
Training loss: 0.0992085337638855
Validation loss: 1.4139511373735243

Epoch: 6| Step: 11
Training loss: 0.10097004473209381
Validation loss: 1.3996987906835412

Epoch: 6| Step: 12
Training loss: 0.04722101241350174
Validation loss: 1.3664195890067725

Epoch: 6| Step: 13
Training loss: 0.054907627403736115
Validation loss: 1.3921577071630826

Epoch: 668| Step: 0
Training loss: 0.06582429260015488
Validation loss: 1.3696397036634467

Epoch: 6| Step: 1
Training loss: 0.06029059737920761
Validation loss: 1.414264863537204

Epoch: 6| Step: 2
Training loss: 0.04919029772281647
Validation loss: 1.4042813636923348

Epoch: 6| Step: 3
Training loss: 0.0719974935054779
Validation loss: 1.4362242567923762

Epoch: 6| Step: 4
Training loss: 0.06265551596879959
Validation loss: 1.433960610820401

Epoch: 6| Step: 5
Training loss: 0.051935844123363495
Validation loss: 1.4135688825320172

Epoch: 6| Step: 6
Training loss: 0.07453308999538422
Validation loss: 1.4548294698038409

Epoch: 6| Step: 7
Training loss: 0.060978397727012634
Validation loss: 1.4439379143458542

Epoch: 6| Step: 8
Training loss: 0.13323599100112915
Validation loss: 1.4483333018518263

Epoch: 6| Step: 9
Training loss: 0.10805290192365646
Validation loss: 1.4645901918411255

Epoch: 6| Step: 10
Training loss: 0.0961935818195343
Validation loss: 1.4191455661609609

Epoch: 6| Step: 11
Training loss: 0.08180506527423859
Validation loss: 1.4261598715218164

Epoch: 6| Step: 12
Training loss: 0.06549457460641861
Validation loss: 1.393711322097368

Epoch: 6| Step: 13
Training loss: 0.07943863421678543
Validation loss: 1.3823010280568113

Epoch: 669| Step: 0
Training loss: 0.10574109107255936
Validation loss: 1.386733252515075

Epoch: 6| Step: 1
Training loss: 0.07602903246879578
Validation loss: 1.4037857619665002

Epoch: 6| Step: 2
Training loss: 0.10364487022161484
Validation loss: 1.392190226944544

Epoch: 6| Step: 3
Training loss: 0.061007142066955566
Validation loss: 1.4169448088574153

Epoch: 6| Step: 4
Training loss: 0.06756219267845154
Validation loss: 1.4483540468318488

Epoch: 6| Step: 5
Training loss: 0.11439340561628342
Validation loss: 1.4585884181402062

Epoch: 6| Step: 6
Training loss: 0.11165618151426315
Validation loss: 1.4986261988198886

Epoch: 6| Step: 7
Training loss: 0.06852259486913681
Validation loss: 1.4687685915218887

Epoch: 6| Step: 8
Training loss: 0.09432756155729294
Validation loss: 1.4570639364181026

Epoch: 6| Step: 9
Training loss: 0.03984345495700836
Validation loss: 1.4302785153030066

Epoch: 6| Step: 10
Training loss: 0.06392470002174377
Validation loss: 1.4201559943537558

Epoch: 6| Step: 11
Training loss: 0.058462560176849365
Validation loss: 1.397867997487386

Epoch: 6| Step: 12
Training loss: 0.049634695053100586
Validation loss: 1.3992441713169057

Epoch: 6| Step: 13
Training loss: 0.04535527899861336
Validation loss: 1.4047458537163273

Epoch: 670| Step: 0
Training loss: 0.03812222182750702
Validation loss: 1.3773605041606451

Epoch: 6| Step: 1
Training loss: 0.06561023741960526
Validation loss: 1.3403416186250665

Epoch: 6| Step: 2
Training loss: 0.07255212962627411
Validation loss: 1.3513271218986922

Epoch: 6| Step: 3
Training loss: 0.07013633847236633
Validation loss: 1.3484808834650184

Epoch: 6| Step: 4
Training loss: 0.07608114182949066
Validation loss: 1.3517878401663996

Epoch: 6| Step: 5
Training loss: 0.0665256530046463
Validation loss: 1.3410720927740938

Epoch: 6| Step: 6
Training loss: 0.059283703565597534
Validation loss: 1.347179602551204

Epoch: 6| Step: 7
Training loss: 0.06870636343955994
Validation loss: 1.3708791322605585

Epoch: 6| Step: 8
Training loss: 0.0607643723487854
Validation loss: 1.3926405265767088

Epoch: 6| Step: 9
Training loss: 0.1037881076335907
Validation loss: 1.3902313965623097

Epoch: 6| Step: 10
Training loss: 0.06533366441726685
Validation loss: 1.3978018485089785

Epoch: 6| Step: 11
Training loss: 0.04065828025341034
Validation loss: 1.4169156269360614

Epoch: 6| Step: 12
Training loss: 0.021036120131611824
Validation loss: 1.3837777132629066

Epoch: 6| Step: 13
Training loss: 0.0685378685593605
Validation loss: 1.384881055483254

Epoch: 671| Step: 0
Training loss: 0.0804339125752449
Validation loss: 1.3802878613113074

Epoch: 6| Step: 1
Training loss: 0.08320369571447372
Validation loss: 1.3908822946651007

Epoch: 6| Step: 2
Training loss: 0.05649009719491005
Validation loss: 1.4001429157872354

Epoch: 6| Step: 3
Training loss: 0.04855397343635559
Validation loss: 1.3975170863571988

Epoch: 6| Step: 4
Training loss: 0.084877148270607
Validation loss: 1.3981872220193186

Epoch: 6| Step: 5
Training loss: 0.06329260021448135
Validation loss: 1.3906986482681767

Epoch: 6| Step: 6
Training loss: 0.08263137936592102
Validation loss: 1.379310771983157

Epoch: 6| Step: 7
Training loss: 0.0546053946018219
Validation loss: 1.3747766787006008

Epoch: 6| Step: 8
Training loss: 0.04987160116434097
Validation loss: 1.3604441009541994

Epoch: 6| Step: 9
Training loss: 0.06294873356819153
Validation loss: 1.3591638168980997

Epoch: 6| Step: 10
Training loss: 0.07124798744916916
Validation loss: 1.3630256652832031

Epoch: 6| Step: 11
Training loss: 0.06738448143005371
Validation loss: 1.3607654827897266

Epoch: 6| Step: 12
Training loss: 0.11301656067371368
Validation loss: 1.35304517387062

Epoch: 6| Step: 13
Training loss: 0.050654493272304535
Validation loss: 1.3723666655120028

Epoch: 672| Step: 0
Training loss: 0.06053512543439865
Validation loss: 1.3765615096656225

Epoch: 6| Step: 1
Training loss: 0.054995790123939514
Validation loss: 1.42667180620214

Epoch: 6| Step: 2
Training loss: 0.07001769542694092
Validation loss: 1.423071558757495

Epoch: 6| Step: 3
Training loss: 0.061977457255125046
Validation loss: 1.4297923708474765

Epoch: 6| Step: 4
Training loss: 0.05511380732059479
Validation loss: 1.4483980376233336

Epoch: 6| Step: 5
Training loss: 0.07459533214569092
Validation loss: 1.458726265097177

Epoch: 6| Step: 6
Training loss: 0.050449736416339874
Validation loss: 1.4543829720507386

Epoch: 6| Step: 7
Training loss: 0.10302621126174927
Validation loss: 1.4424921312639791

Epoch: 6| Step: 8
Training loss: 0.08300189673900604
Validation loss: 1.4432063570586584

Epoch: 6| Step: 9
Training loss: 0.06989651173353195
Validation loss: 1.42477189084535

Epoch: 6| Step: 10
Training loss: 0.06792288273572922
Validation loss: 1.3975980140829598

Epoch: 6| Step: 11
Training loss: 0.05876658111810684
Validation loss: 1.3674857603606356

Epoch: 6| Step: 12
Training loss: 0.04401169717311859
Validation loss: 1.3741904843238093

Epoch: 6| Step: 13
Training loss: 0.05325866863131523
Validation loss: 1.3827415871363815

Epoch: 673| Step: 0
Training loss: 0.0787653774023056
Validation loss: 1.3906354045355191

Epoch: 6| Step: 1
Training loss: 0.06903230398893356
Validation loss: 1.3755526593936387

Epoch: 6| Step: 2
Training loss: 0.0746907889842987
Validation loss: 1.3835474906429168

Epoch: 6| Step: 3
Training loss: 0.04379219934344292
Validation loss: 1.4085747689329169

Epoch: 6| Step: 4
Training loss: 0.059256602078676224
Validation loss: 1.3918161597303165

Epoch: 6| Step: 5
Training loss: 0.08966884016990662
Validation loss: 1.4182945015609905

Epoch: 6| Step: 6
Training loss: 0.10919098556041718
Validation loss: 1.4157159815552414

Epoch: 6| Step: 7
Training loss: 0.055494993925094604
Validation loss: 1.4287090327150078

Epoch: 6| Step: 8
Training loss: 0.07953484356403351
Validation loss: 1.4555071643603745

Epoch: 6| Step: 9
Training loss: 0.1353277564048767
Validation loss: 1.4313276929240073

Epoch: 6| Step: 10
Training loss: 0.056114256381988525
Validation loss: 1.4171407581657491

Epoch: 6| Step: 11
Training loss: 0.06219077855348587
Validation loss: 1.4014008788652317

Epoch: 6| Step: 12
Training loss: 0.06993265450000763
Validation loss: 1.3754946877879481

Epoch: 6| Step: 13
Training loss: 0.0372549369931221
Validation loss: 1.363379588050227

Epoch: 674| Step: 0
Training loss: 0.08301796764135361
Validation loss: 1.3552268615332983

Epoch: 6| Step: 1
Training loss: 0.046881675720214844
Validation loss: 1.3409638533028223

Epoch: 6| Step: 2
Training loss: 0.07842794805765152
Validation loss: 1.3236225196110305

Epoch: 6| Step: 3
Training loss: 0.05721350014209747
Validation loss: 1.2960516483552995

Epoch: 6| Step: 4
Training loss: 0.04178573936223984
Validation loss: 1.3283139492875786

Epoch: 6| Step: 5
Training loss: 0.062153592705726624
Validation loss: 1.3036387216660283

Epoch: 6| Step: 6
Training loss: 0.0659572184085846
Validation loss: 1.3117271059302873

Epoch: 6| Step: 7
Training loss: 0.036822251975536346
Validation loss: 1.3087140539641022

Epoch: 6| Step: 8
Training loss: 0.08478443324565887
Validation loss: 1.2919022178137174

Epoch: 6| Step: 9
Training loss: 0.04412347823381424
Validation loss: 1.3266816844222367

Epoch: 6| Step: 10
Training loss: 0.07290896773338318
Validation loss: 1.323870297401182

Epoch: 6| Step: 11
Training loss: 0.0665004625916481
Validation loss: 1.3621803265745922

Epoch: 6| Step: 12
Training loss: 0.05789473280310631
Validation loss: 1.3461044026959328

Epoch: 6| Step: 13
Training loss: 0.04481183737516403
Validation loss: 1.3445936236330258

Epoch: 675| Step: 0
Training loss: 0.11470523476600647
Validation loss: 1.3781662782033284

Epoch: 6| Step: 1
Training loss: 0.06562471389770508
Validation loss: 1.332490558265358

Epoch: 6| Step: 2
Training loss: 0.07042065262794495
Validation loss: 1.3539633417642245

Epoch: 6| Step: 3
Training loss: 0.05941187962889671
Validation loss: 1.3344420630444762

Epoch: 6| Step: 4
Training loss: 0.05733337253332138
Validation loss: 1.329477672935814

Epoch: 6| Step: 5
Training loss: 0.07949335873126984
Validation loss: 1.311698946901547

Epoch: 6| Step: 6
Training loss: 0.08639505505561829
Validation loss: 1.2951428076272369

Epoch: 6| Step: 7
Training loss: 0.06481491774320602
Validation loss: 1.3143971286794192

Epoch: 6| Step: 8
Training loss: 0.07720861583948135
Validation loss: 1.3174897201599614

Epoch: 6| Step: 9
Training loss: 0.05338064581155777
Validation loss: 1.3293174864143453

Epoch: 6| Step: 10
Training loss: 0.05840899050235748
Validation loss: 1.3404244043493783

Epoch: 6| Step: 11
Training loss: 0.07032343745231628
Validation loss: 1.3329985526300245

Epoch: 6| Step: 12
Training loss: 0.060712531208992004
Validation loss: 1.3519218826806674

Epoch: 6| Step: 13
Training loss: 0.03985301032662392
Validation loss: 1.373406949863639

Epoch: 676| Step: 0
Training loss: 0.0429072268307209
Validation loss: 1.3699382876837125

Epoch: 6| Step: 1
Training loss: 0.07384108006954193
Validation loss: 1.3973892299077844

Epoch: 6| Step: 2
Training loss: 0.08189097046852112
Validation loss: 1.4222823150696293

Epoch: 6| Step: 3
Training loss: 0.05904527008533478
Validation loss: 1.4194335988772813

Epoch: 6| Step: 4
Training loss: 0.0865962952375412
Validation loss: 1.388827496959317

Epoch: 6| Step: 5
Training loss: 0.06246687099337578
Validation loss: 1.4109985520762782

Epoch: 6| Step: 6
Training loss: 0.07346547394990921
Validation loss: 1.394404512259268

Epoch: 6| Step: 7
Training loss: 0.05487561598420143
Validation loss: 1.3838532701615365

Epoch: 6| Step: 8
Training loss: 0.0616697296500206
Validation loss: 1.3839448228959115

Epoch: 6| Step: 9
Training loss: 0.07287812232971191
Validation loss: 1.368617053954832

Epoch: 6| Step: 10
Training loss: 0.09057506918907166
Validation loss: 1.390135302338549

Epoch: 6| Step: 11
Training loss: 0.06808878481388092
Validation loss: 1.3685254384112615

Epoch: 6| Step: 12
Training loss: 0.07184146344661713
Validation loss: 1.3723149696985881

Epoch: 6| Step: 13
Training loss: 0.0395863838493824
Validation loss: 1.374097478005194

Epoch: 677| Step: 0
Training loss: 0.056344207376241684
Validation loss: 1.3975006265024985

Epoch: 6| Step: 1
Training loss: 0.04130854457616806
Validation loss: 1.3891580450919367

Epoch: 6| Step: 2
Training loss: 0.04790177941322327
Validation loss: 1.3892503733276038

Epoch: 6| Step: 3
Training loss: 0.07684140652418137
Validation loss: 1.3822460187378751

Epoch: 6| Step: 4
Training loss: 0.062248215079307556
Validation loss: 1.3937250760293776

Epoch: 6| Step: 5
Training loss: 0.059725694358348846
Validation loss: 1.3940608309161278

Epoch: 6| Step: 6
Training loss: 0.08352982997894287
Validation loss: 1.3572220417761034

Epoch: 6| Step: 7
Training loss: 0.05351017415523529
Validation loss: 1.3858329608876219

Epoch: 6| Step: 8
Training loss: 0.058105263859033585
Validation loss: 1.3853714363549345

Epoch: 6| Step: 9
Training loss: 0.054510846734046936
Validation loss: 1.3893332660839122

Epoch: 6| Step: 10
Training loss: 0.07227905094623566
Validation loss: 1.359200651927661

Epoch: 6| Step: 11
Training loss: 0.039139412343502045
Validation loss: 1.3845457133426462

Epoch: 6| Step: 12
Training loss: 0.09027023613452911
Validation loss: 1.371303459649445

Epoch: 6| Step: 13
Training loss: 0.035534270107746124
Validation loss: 1.4004642399408485

Epoch: 678| Step: 0
Training loss: 0.04658893495798111
Validation loss: 1.3879693400475286

Epoch: 6| Step: 1
Training loss: 0.042164161801338196
Validation loss: 1.381831310128653

Epoch: 6| Step: 2
Training loss: 0.04647772014141083
Validation loss: 1.380235843760993

Epoch: 6| Step: 3
Training loss: 0.07972297072410583
Validation loss: 1.3716148054727944

Epoch: 6| Step: 4
Training loss: 0.06509968638420105
Validation loss: 1.3646023350377237

Epoch: 6| Step: 5
Training loss: 0.058775100857019424
Validation loss: 1.3665530143245574

Epoch: 6| Step: 6
Training loss: 0.07710757851600647
Validation loss: 1.3901248772939045

Epoch: 6| Step: 7
Training loss: 0.06720803678035736
Validation loss: 1.3875862956047058

Epoch: 6| Step: 8
Training loss: 0.0365370512008667
Validation loss: 1.3955970848760297

Epoch: 6| Step: 9
Training loss: 0.06274308264255524
Validation loss: 1.4032145366873792

Epoch: 6| Step: 10
Training loss: 0.05645596981048584
Validation loss: 1.4168567811289141

Epoch: 6| Step: 11
Training loss: 0.05608576908707619
Validation loss: 1.4158646522029754

Epoch: 6| Step: 12
Training loss: 0.07439003884792328
Validation loss: 1.4248416603252452

Epoch: 6| Step: 13
Training loss: 0.07800789922475815
Validation loss: 1.4095905480846282

Epoch: 679| Step: 0
Training loss: 0.07053352892398834
Validation loss: 1.4029559512292185

Epoch: 6| Step: 1
Training loss: 0.07415427267551422
Validation loss: 1.3724932119410524

Epoch: 6| Step: 2
Training loss: 0.04436395317316055
Validation loss: 1.3708476558808358

Epoch: 6| Step: 3
Training loss: 0.042226120829582214
Validation loss: 1.3844747043425036

Epoch: 6| Step: 4
Training loss: 0.057896360754966736
Validation loss: 1.3675840926426712

Epoch: 6| Step: 5
Training loss: 0.05277884379029274
Validation loss: 1.360218587742057

Epoch: 6| Step: 6
Training loss: 0.0459761805832386
Validation loss: 1.3970414464191725

Epoch: 6| Step: 7
Training loss: 0.0626361072063446
Validation loss: 1.3806330388592136

Epoch: 6| Step: 8
Training loss: 0.03244065120816231
Validation loss: 1.4149617200256677

Epoch: 6| Step: 9
Training loss: 0.044018425047397614
Validation loss: 1.414925621401879

Epoch: 6| Step: 10
Training loss: 0.045453861355781555
Validation loss: 1.4111484635260798

Epoch: 6| Step: 11
Training loss: 0.09026133269071579
Validation loss: 1.436379426269121

Epoch: 6| Step: 12
Training loss: 0.047695815563201904
Validation loss: 1.4184396754028976

Epoch: 6| Step: 13
Training loss: 0.05715799331665039
Validation loss: 1.3941961065415414

Epoch: 680| Step: 0
Training loss: 0.03873798996210098
Validation loss: 1.3822739496025989

Epoch: 6| Step: 1
Training loss: 0.07240999490022659
Validation loss: 1.3968816457256195

Epoch: 6| Step: 2
Training loss: 0.053648658096790314
Validation loss: 1.4101862977909785

Epoch: 6| Step: 3
Training loss: 0.023909078910946846
Validation loss: 1.4005801421339794

Epoch: 6| Step: 4
Training loss: 0.049011074006557465
Validation loss: 1.3934526776754728

Epoch: 6| Step: 5
Training loss: 0.054308149963617325
Validation loss: 1.4030794981987245

Epoch: 6| Step: 6
Training loss: 0.06754975765943527
Validation loss: 1.4071795075170455

Epoch: 6| Step: 7
Training loss: 0.05362057685852051
Validation loss: 1.3793446107577252

Epoch: 6| Step: 8
Training loss: 0.05673050507903099
Validation loss: 1.421525074589637

Epoch: 6| Step: 9
Training loss: 0.08109144866466522
Validation loss: 1.3997995097150084

Epoch: 6| Step: 10
Training loss: 0.02981271781027317
Validation loss: 1.3715543311129335

Epoch: 6| Step: 11
Training loss: 0.04331190884113312
Validation loss: 1.36564221689778

Epoch: 6| Step: 12
Training loss: 0.08283264189958572
Validation loss: 1.3633323600215297

Epoch: 6| Step: 13
Training loss: 0.036733709275722504
Validation loss: 1.3579400457361692

Epoch: 681| Step: 0
Training loss: 0.03901003301143646
Validation loss: 1.3522699558606712

Epoch: 6| Step: 1
Training loss: 0.07017821073532104
Validation loss: 1.354686355078092

Epoch: 6| Step: 2
Training loss: 0.11276257038116455
Validation loss: 1.357546801208168

Epoch: 6| Step: 3
Training loss: 0.04602797329425812
Validation loss: 1.4108434274632444

Epoch: 6| Step: 4
Training loss: 0.08972533047199249
Validation loss: 1.417526856545479

Epoch: 6| Step: 5
Training loss: 0.11047044396400452
Validation loss: 1.4603063278300787

Epoch: 6| Step: 6
Training loss: 0.09888216853141785
Validation loss: 1.4584271254078034

Epoch: 6| Step: 7
Training loss: 0.09869139641523361
Validation loss: 1.4501643783302718

Epoch: 6| Step: 8
Training loss: 0.06191137433052063
Validation loss: 1.448152333177546

Epoch: 6| Step: 9
Training loss: 0.06569699943065643
Validation loss: 1.400267727913395

Epoch: 6| Step: 10
Training loss: 0.05241610109806061
Validation loss: 1.3636736869812012

Epoch: 6| Step: 11
Training loss: 0.06171417981386185
Validation loss: 1.3577527256422146

Epoch: 6| Step: 12
Training loss: 0.06866342574357986
Validation loss: 1.3225310310240714

Epoch: 6| Step: 13
Training loss: 0.10633566975593567
Validation loss: 1.3181742839915778

Epoch: 682| Step: 0
Training loss: 0.12228567153215408
Validation loss: 1.313649680024834

Epoch: 6| Step: 1
Training loss: 0.06404384970664978
Validation loss: 1.3293478322285477

Epoch: 6| Step: 2
Training loss: 0.11084020137786865
Validation loss: 1.351515798158543

Epoch: 6| Step: 3
Training loss: 0.05331014469265938
Validation loss: 1.34826151914494

Epoch: 6| Step: 4
Training loss: 0.06702855229377747
Validation loss: 1.3571025107496528

Epoch: 6| Step: 5
Training loss: 0.08430071920156479
Validation loss: 1.3647577288330242

Epoch: 6| Step: 6
Training loss: 0.0397505946457386
Validation loss: 1.415484950747541

Epoch: 6| Step: 7
Training loss: 0.05020046979188919
Validation loss: 1.404165207698781

Epoch: 6| Step: 8
Training loss: 0.07926462590694427
Validation loss: 1.4561761156205209

Epoch: 6| Step: 9
Training loss: 0.07118535041809082
Validation loss: 1.4595052208951724

Epoch: 6| Step: 10
Training loss: 0.0628255158662796
Validation loss: 1.4792273224041026

Epoch: 6| Step: 11
Training loss: 0.11302293837070465
Validation loss: 1.4506648830188218

Epoch: 6| Step: 12
Training loss: 0.0864824429154396
Validation loss: 1.4430576626972487

Epoch: 6| Step: 13
Training loss: 0.04174674674868584
Validation loss: 1.4450213370784637

Epoch: 683| Step: 0
Training loss: 0.039849232882261276
Validation loss: 1.4061177545978176

Epoch: 6| Step: 1
Training loss: 0.08183778077363968
Validation loss: 1.3852106858325262

Epoch: 6| Step: 2
Training loss: 0.046507954597473145
Validation loss: 1.3752340988446308

Epoch: 6| Step: 3
Training loss: 0.07912316918373108
Validation loss: 1.3507096780243741

Epoch: 6| Step: 4
Training loss: 0.060905225574970245
Validation loss: 1.3507047295570374

Epoch: 6| Step: 5
Training loss: 0.058662474155426025
Validation loss: 1.3802128696954379

Epoch: 6| Step: 6
Training loss: 0.0806334912776947
Validation loss: 1.3521674832990092

Epoch: 6| Step: 7
Training loss: 0.06894654035568237
Validation loss: 1.3731972049641352

Epoch: 6| Step: 8
Training loss: 0.043956153094768524
Validation loss: 1.379131608111884

Epoch: 6| Step: 9
Training loss: 0.06723073124885559
Validation loss: 1.3418592458130212

Epoch: 6| Step: 10
Training loss: 0.07699458301067352
Validation loss: 1.3668092976334274

Epoch: 6| Step: 11
Training loss: 0.04564082995057106
Validation loss: 1.3583243444401731

Epoch: 6| Step: 12
Training loss: 0.06334283947944641
Validation loss: 1.3703016504164665

Epoch: 6| Step: 13
Training loss: 0.058772459626197815
Validation loss: 1.367808718835154

Epoch: 684| Step: 0
Training loss: 0.05496848374605179
Validation loss: 1.3853330676273634

Epoch: 6| Step: 1
Training loss: 0.0598498173058033
Validation loss: 1.3798991813454577

Epoch: 6| Step: 2
Training loss: 0.05520075559616089
Validation loss: 1.3878891173229422

Epoch: 6| Step: 3
Training loss: 0.04962155967950821
Validation loss: 1.378399569501159

Epoch: 6| Step: 4
Training loss: 0.05226346105337143
Validation loss: 1.4035402779938073

Epoch: 6| Step: 5
Training loss: 0.02628394216299057
Validation loss: 1.3525156782519432

Epoch: 6| Step: 6
Training loss: 0.07904358208179474
Validation loss: 1.3292745197972944

Epoch: 6| Step: 7
Training loss: 0.06016072630882263
Validation loss: 1.3562711413188646

Epoch: 6| Step: 8
Training loss: 0.028758428990840912
Validation loss: 1.3267804576504616

Epoch: 6| Step: 9
Training loss: 0.10005071014165878
Validation loss: 1.347945564536638

Epoch: 6| Step: 10
Training loss: 0.06619277596473694
Validation loss: 1.3595129674480808

Epoch: 6| Step: 11
Training loss: 0.058295026421546936
Validation loss: 1.3420404580331617

Epoch: 6| Step: 12
Training loss: 0.056604400277137756
Validation loss: 1.3474014356572142

Epoch: 6| Step: 13
Training loss: 0.04573077708482742
Validation loss: 1.3643911602676555

Epoch: 685| Step: 0
Training loss: 0.052886445075273514
Validation loss: 1.369101301316292

Epoch: 6| Step: 1
Training loss: 0.07838347554206848
Validation loss: 1.3755469296568184

Epoch: 6| Step: 2
Training loss: 0.045220665633678436
Validation loss: 1.3760679626977572

Epoch: 6| Step: 3
Training loss: 0.05680181086063385
Validation loss: 1.358030011576991

Epoch: 6| Step: 4
Training loss: 0.059754692018032074
Validation loss: 1.3644388478289369

Epoch: 6| Step: 5
Training loss: 0.04329695552587509
Validation loss: 1.3641982117006857

Epoch: 6| Step: 6
Training loss: 0.05586545914411545
Validation loss: 1.3810476256955055

Epoch: 6| Step: 7
Training loss: 0.09128470718860626
Validation loss: 1.3487147131273824

Epoch: 6| Step: 8
Training loss: 0.04239581525325775
Validation loss: 1.3535214201096566

Epoch: 6| Step: 9
Training loss: 0.052231889218091965
Validation loss: 1.337755383983735

Epoch: 6| Step: 10
Training loss: 0.08100257813930511
Validation loss: 1.3665898602495912

Epoch: 6| Step: 11
Training loss: 0.07548066228628159
Validation loss: 1.3790547975929834

Epoch: 6| Step: 12
Training loss: 0.07526791095733643
Validation loss: 1.3676035519569152

Epoch: 6| Step: 13
Training loss: 0.08089188486337662
Validation loss: 1.3834479252497356

Epoch: 686| Step: 0
Training loss: 0.05372947081923485
Validation loss: 1.4023734549040436

Epoch: 6| Step: 1
Training loss: 0.05723142996430397
Validation loss: 1.3934984277653437

Epoch: 6| Step: 2
Training loss: 0.051066331565380096
Validation loss: 1.3788711793961064

Epoch: 6| Step: 3
Training loss: 0.07193061709403992
Validation loss: 1.4047783235067963

Epoch: 6| Step: 4
Training loss: 0.06432387232780457
Validation loss: 1.349413909578836

Epoch: 6| Step: 5
Training loss: 0.05036446079611778
Validation loss: 1.3801726237420113

Epoch: 6| Step: 6
Training loss: 0.061268020421266556
Validation loss: 1.335535454493697

Epoch: 6| Step: 7
Training loss: 0.04588671773672104
Validation loss: 1.3459542938458022

Epoch: 6| Step: 8
Training loss: 0.08518656343221664
Validation loss: 1.3086753199177403

Epoch: 6| Step: 9
Training loss: 0.07571519911289215
Validation loss: 1.3276969912231609

Epoch: 6| Step: 10
Training loss: 0.06206415593624115
Validation loss: 1.30671190702787

Epoch: 6| Step: 11
Training loss: 0.044975243508815765
Validation loss: 1.3504527768781107

Epoch: 6| Step: 12
Training loss: 0.07735317200422287
Validation loss: 1.3061594040163103

Epoch: 6| Step: 13
Training loss: 0.031027700752019882
Validation loss: 1.3245953411184332

Epoch: 687| Step: 0
Training loss: 0.04597315937280655
Validation loss: 1.3495633153505222

Epoch: 6| Step: 1
Training loss: 0.059159234166145325
Validation loss: 1.3396837608788603

Epoch: 6| Step: 2
Training loss: 0.04408373683691025
Validation loss: 1.3469905020088278

Epoch: 6| Step: 3
Training loss: 0.045722685754299164
Validation loss: 1.359898328781128

Epoch: 6| Step: 4
Training loss: 0.048837050795555115
Validation loss: 1.3843747556850474

Epoch: 6| Step: 5
Training loss: 0.07363088428974152
Validation loss: 1.3958148917844218

Epoch: 6| Step: 6
Training loss: 0.04839605838060379
Validation loss: 1.4053246949308662

Epoch: 6| Step: 7
Training loss: 0.04657937213778496
Validation loss: 1.409585819449476

Epoch: 6| Step: 8
Training loss: 0.06574264168739319
Validation loss: 1.417188681581969

Epoch: 6| Step: 9
Training loss: 0.05213892459869385
Validation loss: 1.431162658558097

Epoch: 6| Step: 10
Training loss: 0.07672271132469177
Validation loss: 1.4344977755700388

Epoch: 6| Step: 11
Training loss: 0.0718374028801918
Validation loss: 1.4236443247846378

Epoch: 6| Step: 12
Training loss: 0.047584131360054016
Validation loss: 1.4178264807629328

Epoch: 6| Step: 13
Training loss: 0.0716557502746582
Validation loss: 1.3792488049435359

Epoch: 688| Step: 0
Training loss: 0.03427129238843918
Validation loss: 1.358161646832702

Epoch: 6| Step: 1
Training loss: 0.05929473787546158
Validation loss: 1.3484953270163587

Epoch: 6| Step: 2
Training loss: 0.06075882911682129
Validation loss: 1.3302816652482556

Epoch: 6| Step: 3
Training loss: 0.05126243084669113
Validation loss: 1.3324500065977856

Epoch: 6| Step: 4
Training loss: 0.05001839995384216
Validation loss: 1.3087028444454234

Epoch: 6| Step: 5
Training loss: 0.07469156384468079
Validation loss: 1.3151615704259565

Epoch: 6| Step: 6
Training loss: 0.05695297196507454
Validation loss: 1.314938695200028

Epoch: 6| Step: 7
Training loss: 0.06084222346544266
Validation loss: 1.3137670486204085

Epoch: 6| Step: 8
Training loss: 0.07277916371822357
Validation loss: 1.3166198551013906

Epoch: 6| Step: 9
Training loss: 0.057438306510448456
Validation loss: 1.315467346099115

Epoch: 6| Step: 10
Training loss: 0.033173561096191406
Validation loss: 1.3447017528677498

Epoch: 6| Step: 11
Training loss: 0.05027123540639877
Validation loss: 1.3589206946793424

Epoch: 6| Step: 12
Training loss: 0.06524480134248734
Validation loss: 1.363797899215452

Epoch: 6| Step: 13
Training loss: 0.03893336281180382
Validation loss: 1.3740898075924124

Epoch: 689| Step: 0
Training loss: 0.03146737813949585
Validation loss: 1.39653153316949

Epoch: 6| Step: 1
Training loss: 0.052433572709560394
Validation loss: 1.399457532872436

Epoch: 6| Step: 2
Training loss: 0.0618455596268177
Validation loss: 1.4069228441484514

Epoch: 6| Step: 3
Training loss: 0.06289282441139221
Validation loss: 1.386462132136027

Epoch: 6| Step: 4
Training loss: 0.07943273335695267
Validation loss: 1.398653338032384

Epoch: 6| Step: 5
Training loss: 0.047648973762989044
Validation loss: 1.369283862011407

Epoch: 6| Step: 6
Training loss: 0.06624456495046616
Validation loss: 1.3761457563728414

Epoch: 6| Step: 7
Training loss: 0.051875799894332886
Validation loss: 1.3937742376840243

Epoch: 6| Step: 8
Training loss: 0.04377056658267975
Validation loss: 1.3897362575736096

Epoch: 6| Step: 9
Training loss: 0.056353576481342316
Validation loss: 1.3827701198157443

Epoch: 6| Step: 10
Training loss: 0.048003971576690674
Validation loss: 1.3771493806633899

Epoch: 6| Step: 11
Training loss: 0.04262556880712509
Validation loss: 1.3678976323014946

Epoch: 6| Step: 12
Training loss: 0.04555767402052879
Validation loss: 1.3530033839646207

Epoch: 6| Step: 13
Training loss: 0.06943675875663757
Validation loss: 1.3496898156340404

Epoch: 690| Step: 0
Training loss: 0.07429276406764984
Validation loss: 1.3617262660816152

Epoch: 6| Step: 1
Training loss: 0.04804227128624916
Validation loss: 1.351703675203426

Epoch: 6| Step: 2
Training loss: 0.034453555941581726
Validation loss: 1.3473736086199362

Epoch: 6| Step: 3
Training loss: 0.029029380530118942
Validation loss: 1.3814010363753124

Epoch: 6| Step: 4
Training loss: 0.037158362567424774
Validation loss: 1.3866857585086618

Epoch: 6| Step: 5
Training loss: 0.08649294078350067
Validation loss: 1.3929991119651384

Epoch: 6| Step: 6
Training loss: 0.04373379051685333
Validation loss: 1.387396329192705

Epoch: 6| Step: 7
Training loss: 0.05343269184231758
Validation loss: 1.3725372847690378

Epoch: 6| Step: 8
Training loss: 0.028435803949832916
Validation loss: 1.3994507187156267

Epoch: 6| Step: 9
Training loss: 0.037145644426345825
Validation loss: 1.3687682818340998

Epoch: 6| Step: 10
Training loss: 0.056119032204151154
Validation loss: 1.364197830359141

Epoch: 6| Step: 11
Training loss: 0.04419846460223198
Validation loss: 1.3768997820474769

Epoch: 6| Step: 12
Training loss: 0.0704750046133995
Validation loss: 1.3656071437302457

Epoch: 6| Step: 13
Training loss: 0.051641277968883514
Validation loss: 1.373783225654274

Epoch: 691| Step: 0
Training loss: 0.0417884923517704
Validation loss: 1.373672043123553

Epoch: 6| Step: 1
Training loss: 0.03377832472324371
Validation loss: 1.3747727691486318

Epoch: 6| Step: 2
Training loss: 0.04705151915550232
Validation loss: 1.3585500217253161

Epoch: 6| Step: 3
Training loss: 0.03856411576271057
Validation loss: 1.3741638980885988

Epoch: 6| Step: 4
Training loss: 0.02706638164818287
Validation loss: 1.36390124341493

Epoch: 6| Step: 5
Training loss: 0.04054680094122887
Validation loss: 1.3527844080360987

Epoch: 6| Step: 6
Training loss: 0.039217278361320496
Validation loss: 1.3834371707772697

Epoch: 6| Step: 7
Training loss: 0.04866974055767059
Validation loss: 1.3782336916974796

Epoch: 6| Step: 8
Training loss: 0.045634835958480835
Validation loss: 1.371768783497554

Epoch: 6| Step: 9
Training loss: 0.06251677870750427
Validation loss: 1.3778666642404371

Epoch: 6| Step: 10
Training loss: 0.047191500663757324
Validation loss: 1.3869918123368294

Epoch: 6| Step: 11
Training loss: 0.0675947368144989
Validation loss: 1.3958114321513841

Epoch: 6| Step: 12
Training loss: 0.03487074002623558
Validation loss: 1.4070868979218185

Epoch: 6| Step: 13
Training loss: 0.04249231517314911
Validation loss: 1.3671539624532063

Epoch: 692| Step: 0
Training loss: 0.07242320477962494
Validation loss: 1.3836236525607366

Epoch: 6| Step: 1
Training loss: 0.051520392298698425
Validation loss: 1.3811711393376833

Epoch: 6| Step: 2
Training loss: 0.03365635871887207
Validation loss: 1.3683199882507324

Epoch: 6| Step: 3
Training loss: 0.07986076921224594
Validation loss: 1.3548336631508284

Epoch: 6| Step: 4
Training loss: 0.05253969877958298
Validation loss: 1.3807474810590026

Epoch: 6| Step: 5
Training loss: 0.04613841697573662
Validation loss: 1.3592504314197007

Epoch: 6| Step: 6
Training loss: 0.057940952479839325
Validation loss: 1.3670049726322133

Epoch: 6| Step: 7
Training loss: 0.0332263708114624
Validation loss: 1.3403677825004823

Epoch: 6| Step: 8
Training loss: 0.04332354664802551
Validation loss: 1.3493931319123955

Epoch: 6| Step: 9
Training loss: 0.05463537946343422
Validation loss: 1.3734755439143027

Epoch: 6| Step: 10
Training loss: 0.043056100606918335
Validation loss: 1.3548025963126973

Epoch: 6| Step: 11
Training loss: 0.029790416359901428
Validation loss: 1.402156392733256

Epoch: 6| Step: 12
Training loss: 0.0543135330080986
Validation loss: 1.4129632032045754

Epoch: 6| Step: 13
Training loss: 0.032075218856334686
Validation loss: 1.3870599359594367

Epoch: 693| Step: 0
Training loss: 0.06710448861122131
Validation loss: 1.414153028559941

Epoch: 6| Step: 1
Training loss: 0.04089339077472687
Validation loss: 1.401052144265944

Epoch: 6| Step: 2
Training loss: 0.07956237345933914
Validation loss: 1.3650812218266148

Epoch: 6| Step: 3
Training loss: 0.02900734171271324
Validation loss: 1.34710140766636

Epoch: 6| Step: 4
Training loss: 0.03981676325201988
Validation loss: 1.339230175941221

Epoch: 6| Step: 5
Training loss: 0.07399769127368927
Validation loss: 1.360279864521437

Epoch: 6| Step: 6
Training loss: 0.03349365293979645
Validation loss: 1.3540536857420398

Epoch: 6| Step: 7
Training loss: 0.06684059649705887
Validation loss: 1.348299672526698

Epoch: 6| Step: 8
Training loss: 0.05671053007245064
Validation loss: 1.3534311953411307

Epoch: 6| Step: 9
Training loss: 0.036908190697431564
Validation loss: 1.3344486080190188

Epoch: 6| Step: 10
Training loss: 0.06048735976219177
Validation loss: 1.3605117887578986

Epoch: 6| Step: 11
Training loss: 0.049872033298015594
Validation loss: 1.3635206568625666

Epoch: 6| Step: 12
Training loss: 0.06326465308666229
Validation loss: 1.3546690722947479

Epoch: 6| Step: 13
Training loss: 0.06960629671812057
Validation loss: 1.3921166645583285

Epoch: 694| Step: 0
Training loss: 0.04406072944402695
Validation loss: 1.3726052423959136

Epoch: 6| Step: 1
Training loss: 0.03610638901591301
Validation loss: 1.3817609099931614

Epoch: 6| Step: 2
Training loss: 0.03889508545398712
Validation loss: 1.3703835946257397

Epoch: 6| Step: 3
Training loss: 0.044042136520147324
Validation loss: 1.3561584577765515

Epoch: 6| Step: 4
Training loss: 0.04478937387466431
Validation loss: 1.3584169790308962

Epoch: 6| Step: 5
Training loss: 0.06902702897787094
Validation loss: 1.3484714236310733

Epoch: 6| Step: 6
Training loss: 0.03713863715529442
Validation loss: 1.3718007841417867

Epoch: 6| Step: 7
Training loss: 0.049139250069856644
Validation loss: 1.3529210571319825

Epoch: 6| Step: 8
Training loss: 0.06566926836967468
Validation loss: 1.3261614217553088

Epoch: 6| Step: 9
Training loss: 0.06918305158615112
Validation loss: 1.3422316992154686

Epoch: 6| Step: 10
Training loss: 0.07136720418930054
Validation loss: 1.3604800496050107

Epoch: 6| Step: 11
Training loss: 0.050943776965141296
Validation loss: 1.3741515528771184

Epoch: 6| Step: 12
Training loss: 0.05233900249004364
Validation loss: 1.3911080552685646

Epoch: 6| Step: 13
Training loss: 0.05555715039372444
Validation loss: 1.4098233407543552

Epoch: 695| Step: 0
Training loss: 0.060805339366197586
Validation loss: 1.3846120744623163

Epoch: 6| Step: 1
Training loss: 0.05312668904662132
Validation loss: 1.4220805680879982

Epoch: 6| Step: 2
Training loss: 0.03815791383385658
Validation loss: 1.4012708965168204

Epoch: 6| Step: 3
Training loss: 0.03501752018928528
Validation loss: 1.4090434748639342

Epoch: 6| Step: 4
Training loss: 0.07684710621833801
Validation loss: 1.3868088440228534

Epoch: 6| Step: 5
Training loss: 0.03971037268638611
Validation loss: 1.37228819119033

Epoch: 6| Step: 6
Training loss: 0.04667425528168678
Validation loss: 1.361709886981595

Epoch: 6| Step: 7
Training loss: 0.0415247306227684
Validation loss: 1.3446781122556297

Epoch: 6| Step: 8
Training loss: 0.04741388559341431
Validation loss: 1.3253137347518757

Epoch: 6| Step: 9
Training loss: 0.05439198017120361
Validation loss: 1.3203965617764382

Epoch: 6| Step: 10
Training loss: 0.06559284776449203
Validation loss: 1.2855698498346473

Epoch: 6| Step: 11
Training loss: 0.08058905601501465
Validation loss: 1.276228315086775

Epoch: 6| Step: 12
Training loss: 0.08202947676181793
Validation loss: 1.3028648694356282

Epoch: 6| Step: 13
Training loss: 0.052117280662059784
Validation loss: 1.3105079448351296

Epoch: 696| Step: 0
Training loss: 0.05138023942708969
Validation loss: 1.3458692771132275

Epoch: 6| Step: 1
Training loss: 0.06678935885429382
Validation loss: 1.354084090519977

Epoch: 6| Step: 2
Training loss: 0.05707171559333801
Validation loss: 1.3678812134650447

Epoch: 6| Step: 3
Training loss: 0.06457372009754181
Validation loss: 1.393152993212464

Epoch: 6| Step: 4
Training loss: 0.06986435502767563
Validation loss: 1.4004144976215978

Epoch: 6| Step: 5
Training loss: 0.041975587606430054
Validation loss: 1.4170004398592058

Epoch: 6| Step: 6
Training loss: 0.06031772494316101
Validation loss: 1.445404121952672

Epoch: 6| Step: 7
Training loss: 0.041167065501213074
Validation loss: 1.4516166807502828

Epoch: 6| Step: 8
Training loss: 0.055695999413728714
Validation loss: 1.4286764872971403

Epoch: 6| Step: 9
Training loss: 0.06924813240766525
Validation loss: 1.410383935897581

Epoch: 6| Step: 10
Training loss: 0.04038344696164131
Validation loss: 1.3770970618853005

Epoch: 6| Step: 11
Training loss: 0.04849717393517494
Validation loss: 1.368550754362537

Epoch: 6| Step: 12
Training loss: 0.04657468944787979
Validation loss: 1.3673376844775291

Epoch: 6| Step: 13
Training loss: 0.03664058446884155
Validation loss: 1.3688587629666893

Epoch: 697| Step: 0
Training loss: 0.03460460901260376
Validation loss: 1.38219436266089

Epoch: 6| Step: 1
Training loss: 0.043364185839891434
Validation loss: 1.3858989079793294

Epoch: 6| Step: 2
Training loss: 0.06350067257881165
Validation loss: 1.39681194033674

Epoch: 6| Step: 3
Training loss: 0.040574006736278534
Validation loss: 1.3767500436434181

Epoch: 6| Step: 4
Training loss: 0.08520448207855225
Validation loss: 1.3937705268142044

Epoch: 6| Step: 5
Training loss: 0.03168293088674545
Validation loss: 1.3880733943754626

Epoch: 6| Step: 6
Training loss: 0.08513639867305756
Validation loss: 1.3995136868569158

Epoch: 6| Step: 7
Training loss: 0.047134529799222946
Validation loss: 1.3864508213535431

Epoch: 6| Step: 8
Training loss: 0.044118352234363556
Validation loss: 1.4065007855815272

Epoch: 6| Step: 9
Training loss: 0.0572851225733757
Validation loss: 1.3812356379724318

Epoch: 6| Step: 10
Training loss: 0.06353887915611267
Validation loss: 1.3944385580478176

Epoch: 6| Step: 11
Training loss: 0.10567916929721832
Validation loss: 1.3908094116436538

Epoch: 6| Step: 12
Training loss: 0.07118474692106247
Validation loss: 1.3685005121333624

Epoch: 6| Step: 13
Training loss: 0.09533365815877914
Validation loss: 1.3556405818590553

Epoch: 698| Step: 0
Training loss: 0.053428106009960175
Validation loss: 1.3707113977401488

Epoch: 6| Step: 1
Training loss: 0.05740612745285034
Validation loss: 1.367305209559779

Epoch: 6| Step: 2
Training loss: 0.06999872624874115
Validation loss: 1.3783707080348846

Epoch: 6| Step: 3
Training loss: 0.062015753239393234
Validation loss: 1.3587281857767413

Epoch: 6| Step: 4
Training loss: 0.058754123747348785
Validation loss: 1.3818365963556434

Epoch: 6| Step: 5
Training loss: 0.03817502409219742
Validation loss: 1.3559225669471167

Epoch: 6| Step: 6
Training loss: 0.06762009114027023
Validation loss: 1.3851914944187287

Epoch: 6| Step: 7
Training loss: 0.05819020792841911
Validation loss: 1.3780107626350977

Epoch: 6| Step: 8
Training loss: 0.0440235510468483
Validation loss: 1.384658997417778

Epoch: 6| Step: 9
Training loss: 0.04122234135866165
Validation loss: 1.404079584665196

Epoch: 6| Step: 10
Training loss: 0.054291658103466034
Validation loss: 1.381192317572973

Epoch: 6| Step: 11
Training loss: 0.06109855696558952
Validation loss: 1.3887074416683567

Epoch: 6| Step: 12
Training loss: 0.04185345023870468
Validation loss: 1.3447650927369312

Epoch: 6| Step: 13
Training loss: 0.06679236143827438
Validation loss: 1.3462218007733744

Epoch: 699| Step: 0
Training loss: 0.024944378063082695
Validation loss: 1.3202718195094858

Epoch: 6| Step: 1
Training loss: 0.045229993760585785
Validation loss: 1.3352662645360476

Epoch: 6| Step: 2
Training loss: 0.033794015645980835
Validation loss: 1.3421032159559187

Epoch: 6| Step: 3
Training loss: 0.05735176429152489
Validation loss: 1.3220984730669247

Epoch: 6| Step: 4
Training loss: 0.044881440699100494
Validation loss: 1.3288683493932087

Epoch: 6| Step: 5
Training loss: 0.0521702766418457
Validation loss: 1.315529275965947

Epoch: 6| Step: 6
Training loss: 0.07915467023849487
Validation loss: 1.3035334976770545

Epoch: 6| Step: 7
Training loss: 0.049755703657865524
Validation loss: 1.3373758421149304

Epoch: 6| Step: 8
Training loss: 0.059890806674957275
Validation loss: 1.3429568634238294

Epoch: 6| Step: 9
Training loss: 0.057736121118068695
Validation loss: 1.3604940022191694

Epoch: 6| Step: 10
Training loss: 0.04504058137536049
Validation loss: 1.3587542810747701

Epoch: 6| Step: 11
Training loss: 0.03670838475227356
Validation loss: 1.379219203546483

Epoch: 6| Step: 12
Training loss: 0.04642864689230919
Validation loss: 1.3488353888193767

Epoch: 6| Step: 13
Training loss: 0.0669444128870964
Validation loss: 1.3771476284150155

Epoch: 700| Step: 0
Training loss: 0.04125190153717995
Validation loss: 1.3866279714850969

Epoch: 6| Step: 1
Training loss: 0.06000020354986191
Validation loss: 1.3693477197359967

Epoch: 6| Step: 2
Training loss: 0.06724810600280762
Validation loss: 1.3742440221130208

Epoch: 6| Step: 3
Training loss: 0.05239614099264145
Validation loss: 1.3524127467986076

Epoch: 6| Step: 4
Training loss: 0.03137635812163353
Validation loss: 1.3434501783822173

Epoch: 6| Step: 5
Training loss: 0.0434640534222126
Validation loss: 1.357183571143817

Epoch: 6| Step: 6
Training loss: 0.0710354596376419
Validation loss: 1.3338893792962516

Epoch: 6| Step: 7
Training loss: 0.0334535613656044
Validation loss: 1.3646606578621814

Epoch: 6| Step: 8
Training loss: 0.050399526953697205
Validation loss: 1.3453765030830138

Epoch: 6| Step: 9
Training loss: 0.09359484910964966
Validation loss: 1.3389013057113976

Epoch: 6| Step: 10
Training loss: 0.060391560196876526
Validation loss: 1.3455131502561672

Epoch: 6| Step: 11
Training loss: 0.0321679413318634
Validation loss: 1.3445491098588513

Epoch: 6| Step: 12
Training loss: 0.03395234793424606
Validation loss: 1.330878121878511

Epoch: 6| Step: 13
Training loss: 0.03315477818250656
Validation loss: 1.3386379896953542

Epoch: 701| Step: 0
Training loss: 0.046469464898109436
Validation loss: 1.340983057534823

Epoch: 6| Step: 1
Training loss: 0.025156276300549507
Validation loss: 1.3542851901823474

Epoch: 6| Step: 2
Training loss: 0.03076986037194729
Validation loss: 1.3738240362495504

Epoch: 6| Step: 3
Training loss: 0.0550413578748703
Validation loss: 1.370637442476006

Epoch: 6| Step: 4
Training loss: 0.03373710438609123
Validation loss: 1.3443712406260993

Epoch: 6| Step: 5
Training loss: 0.058140166103839874
Validation loss: 1.3551204730105657

Epoch: 6| Step: 6
Training loss: 0.0626804456114769
Validation loss: 1.3615478738661735

Epoch: 6| Step: 7
Training loss: 0.03804117441177368
Validation loss: 1.375840510091474

Epoch: 6| Step: 8
Training loss: 0.04329615458846092
Validation loss: 1.3778194765890799

Epoch: 6| Step: 9
Training loss: 0.06519320607185364
Validation loss: 1.3825257798676849

Epoch: 6| Step: 10
Training loss: 0.04859158396720886
Validation loss: 1.3841377022445842

Epoch: 6| Step: 11
Training loss: 0.06081921607255936
Validation loss: 1.337882085513043

Epoch: 6| Step: 12
Training loss: 0.05728030204772949
Validation loss: 1.3705683497972385

Epoch: 6| Step: 13
Training loss: 0.02788843773305416
Validation loss: 1.3677624640285329

Epoch: 702| Step: 0
Training loss: 0.0665072351694107
Validation loss: 1.359886723179971

Epoch: 6| Step: 1
Training loss: 0.043920163065195084
Validation loss: 1.368074486332555

Epoch: 6| Step: 2
Training loss: 0.038924604654312134
Validation loss: 1.3740235759365944

Epoch: 6| Step: 3
Training loss: 0.04544672742486
Validation loss: 1.3567890236454625

Epoch: 6| Step: 4
Training loss: 0.05560228228569031
Validation loss: 1.323385900066745

Epoch: 6| Step: 5
Training loss: 0.032581936568021774
Validation loss: 1.341197879083695

Epoch: 6| Step: 6
Training loss: 0.028337489813566208
Validation loss: 1.3224444152206503

Epoch: 6| Step: 7
Training loss: 0.08866333961486816
Validation loss: 1.3452016704825944

Epoch: 6| Step: 8
Training loss: 0.04441845417022705
Validation loss: 1.3274342360035065

Epoch: 6| Step: 9
Training loss: 0.04786995053291321
Validation loss: 1.327797093058145

Epoch: 6| Step: 10
Training loss: 0.06279809772968292
Validation loss: 1.3382846604111374

Epoch: 6| Step: 11
Training loss: 0.038089197129011154
Validation loss: 1.3411825888900346

Epoch: 6| Step: 12
Training loss: 0.04021816700696945
Validation loss: 1.3663932264492076

Epoch: 6| Step: 13
Training loss: 0.07734359800815582
Validation loss: 1.3526529919716619

Epoch: 703| Step: 0
Training loss: 0.054437946528196335
Validation loss: 1.382144247331927

Epoch: 6| Step: 1
Training loss: 0.08094209432601929
Validation loss: 1.3740579889666649

Epoch: 6| Step: 2
Training loss: 0.07580514252185822
Validation loss: 1.4198593926686112

Epoch: 6| Step: 3
Training loss: 0.06260310858488083
Validation loss: 1.436671333928262

Epoch: 6| Step: 4
Training loss: 0.06269494444131851
Validation loss: 1.4424538509820097

Epoch: 6| Step: 5
Training loss: 0.04327550530433655
Validation loss: 1.429714915572956

Epoch: 6| Step: 6
Training loss: 0.08152759820222855
Validation loss: 1.4395648023133636

Epoch: 6| Step: 7
Training loss: 0.039102017879486084
Validation loss: 1.4189818302790325

Epoch: 6| Step: 8
Training loss: 0.045244865119457245
Validation loss: 1.410350752133195

Epoch: 6| Step: 9
Training loss: 0.037463292479515076
Validation loss: 1.3706274917048793

Epoch: 6| Step: 10
Training loss: 0.0462762713432312
Validation loss: 1.3942795799624534

Epoch: 6| Step: 11
Training loss: 0.04670535773038864
Validation loss: 1.3295897822226248

Epoch: 6| Step: 12
Training loss: 0.06798689067363739
Validation loss: 1.367523685578377

Epoch: 6| Step: 13
Training loss: 0.061461254954338074
Validation loss: 1.3621260491750573

Epoch: 704| Step: 0
Training loss: 0.05907892435789108
Validation loss: 1.3719640611320414

Epoch: 6| Step: 1
Training loss: 0.053724080324172974
Validation loss: 1.3704230317505457

Epoch: 6| Step: 2
Training loss: 0.05801067873835564
Validation loss: 1.3818788502805976

Epoch: 6| Step: 3
Training loss: 0.07942330837249756
Validation loss: 1.3893521344789894

Epoch: 6| Step: 4
Training loss: 0.06172998249530792
Validation loss: 1.3909800475643528

Epoch: 6| Step: 5
Training loss: 0.06478215754032135
Validation loss: 1.3819831660998765

Epoch: 6| Step: 6
Training loss: 0.04484857618808746
Validation loss: 1.3906399883249754

Epoch: 6| Step: 7
Training loss: 0.04736145958304405
Validation loss: 1.372006836757865

Epoch: 6| Step: 8
Training loss: 0.039843980222940445
Validation loss: 1.3801536713877032

Epoch: 6| Step: 9
Training loss: 0.04613536223769188
Validation loss: 1.3691180861124428

Epoch: 6| Step: 10
Training loss: 0.03013167344033718
Validation loss: 1.3618684372594279

Epoch: 6| Step: 11
Training loss: 0.062457382678985596
Validation loss: 1.3668912290244974

Epoch: 6| Step: 12
Training loss: 0.07339225709438324
Validation loss: 1.3552901232114403

Epoch: 6| Step: 13
Training loss: 0.09026585519313812
Validation loss: 1.348699991421033

Epoch: 705| Step: 0
Training loss: 0.03390398994088173
Validation loss: 1.3466568454619376

Epoch: 6| Step: 1
Training loss: 0.05650147795677185
Validation loss: 1.3895828326543171

Epoch: 6| Step: 2
Training loss: 0.04641694203019142
Validation loss: 1.3789232674465384

Epoch: 6| Step: 3
Training loss: 0.04389271140098572
Validation loss: 1.3793930187020251

Epoch: 6| Step: 4
Training loss: 0.03730916231870651
Validation loss: 1.37375694833776

Epoch: 6| Step: 5
Training loss: 0.05415371060371399
Validation loss: 1.3922142687664236

Epoch: 6| Step: 6
Training loss: 0.05302760750055313
Validation loss: 1.4086691999948153

Epoch: 6| Step: 7
Training loss: 0.025793595239520073
Validation loss: 1.3946823484154158

Epoch: 6| Step: 8
Training loss: 0.06560538709163666
Validation loss: 1.3804777642732025

Epoch: 6| Step: 9
Training loss: 0.06125309690833092
Validation loss: 1.3935787177854968

Epoch: 6| Step: 10
Training loss: 0.04763782024383545
Validation loss: 1.3801861334872503

Epoch: 6| Step: 11
Training loss: 0.07025035470724106
Validation loss: 1.361786437290971

Epoch: 6| Step: 12
Training loss: 0.04404442012310028
Validation loss: 1.3564116301075104

Epoch: 6| Step: 13
Training loss: 0.04208090528845787
Validation loss: 1.3542688315914524

Epoch: 706| Step: 0
Training loss: 0.056801363825798035
Validation loss: 1.3569636319273262

Epoch: 6| Step: 1
Training loss: 0.046630486845970154
Validation loss: 1.3350520608245686

Epoch: 6| Step: 2
Training loss: 0.037412725389003754
Validation loss: 1.3366294753166936

Epoch: 6| Step: 3
Training loss: 0.05166139081120491
Validation loss: 1.3610082377669632

Epoch: 6| Step: 4
Training loss: 0.04471805691719055
Validation loss: 1.3631558725910802

Epoch: 6| Step: 5
Training loss: 0.07264282554388046
Validation loss: 1.3455935011627853

Epoch: 6| Step: 6
Training loss: 0.08412317931652069
Validation loss: 1.3433475250838904

Epoch: 6| Step: 7
Training loss: 0.046582385897636414
Validation loss: 1.3611426263727167

Epoch: 6| Step: 8
Training loss: 0.04670112580060959
Validation loss: 1.3468655591369958

Epoch: 6| Step: 9
Training loss: 0.04019671306014061
Validation loss: 1.3653597036997478

Epoch: 6| Step: 10
Training loss: 0.03101218305528164
Validation loss: 1.3482476113944926

Epoch: 6| Step: 11
Training loss: 0.04399659484624863
Validation loss: 1.3297317117773078

Epoch: 6| Step: 12
Training loss: 0.03976790979504585
Validation loss: 1.3386129307490524

Epoch: 6| Step: 13
Training loss: 0.024449484422802925
Validation loss: 1.3784361065074962

Epoch: 707| Step: 0
Training loss: 0.045216187834739685
Validation loss: 1.3355847994486492

Epoch: 6| Step: 1
Training loss: 0.03305961191654205
Validation loss: 1.3461279478124393

Epoch: 6| Step: 2
Training loss: 0.05628230422735214
Validation loss: 1.3787431178554412

Epoch: 6| Step: 3
Training loss: 0.05370168387889862
Validation loss: 1.3387411922536872

Epoch: 6| Step: 4
Training loss: 0.05601570010185242
Validation loss: 1.3388735837833856

Epoch: 6| Step: 5
Training loss: 0.04938158020377159
Validation loss: 1.3475872778123426

Epoch: 6| Step: 6
Training loss: 0.04915755242109299
Validation loss: 1.342679778734843

Epoch: 6| Step: 7
Training loss: 0.04913531616330147
Validation loss: 1.338058049960803

Epoch: 6| Step: 8
Training loss: 0.055203426629304886
Validation loss: 1.3273383693028522

Epoch: 6| Step: 9
Training loss: 0.06469422578811646
Validation loss: 1.3526652077192902

Epoch: 6| Step: 10
Training loss: 0.06295596063137054
Validation loss: 1.3506496183333858

Epoch: 6| Step: 11
Training loss: 0.06335985660552979
Validation loss: 1.3510908439595213

Epoch: 6| Step: 12
Training loss: 0.07200101017951965
Validation loss: 1.3815372458068274

Epoch: 6| Step: 13
Training loss: 0.0671342983841896
Validation loss: 1.4005460072589178

Epoch: 708| Step: 0
Training loss: 0.055825620889663696
Validation loss: 1.4203220067485687

Epoch: 6| Step: 1
Training loss: 0.05321511626243591
Validation loss: 1.3779508759898524

Epoch: 6| Step: 2
Training loss: 0.06691306829452515
Validation loss: 1.377152354486527

Epoch: 6| Step: 3
Training loss: 0.09552900493144989
Validation loss: 1.3648518029079642

Epoch: 6| Step: 4
Training loss: 0.0542515367269516
Validation loss: 1.3470461432651808

Epoch: 6| Step: 5
Training loss: 0.05552908033132553
Validation loss: 1.34767993034855

Epoch: 6| Step: 6
Training loss: 0.0413934662938118
Validation loss: 1.3340970931514617

Epoch: 6| Step: 7
Training loss: 0.0889059379696846
Validation loss: 1.3320355876799552

Epoch: 6| Step: 8
Training loss: 0.0434192456305027
Validation loss: 1.2867762504085418

Epoch: 6| Step: 9
Training loss: 0.06261582672595978
Validation loss: 1.3065500118399178

Epoch: 6| Step: 10
Training loss: 0.06079956516623497
Validation loss: 1.3018855856310936

Epoch: 6| Step: 11
Training loss: 0.037381529808044434
Validation loss: 1.3255949892023557

Epoch: 6| Step: 12
Training loss: 0.06304152309894562
Validation loss: 1.3335061919304632

Epoch: 6| Step: 13
Training loss: 0.07258936762809753
Validation loss: 1.3331841050937612

Epoch: 709| Step: 0
Training loss: 0.05021251365542412
Validation loss: 1.3364543607158046

Epoch: 6| Step: 1
Training loss: 0.07677712291479111
Validation loss: 1.375745144582564

Epoch: 6| Step: 2
Training loss: 0.044771164655685425
Validation loss: 1.347672571418106

Epoch: 6| Step: 3
Training loss: 0.08665994554758072
Validation loss: 1.3411551252488167

Epoch: 6| Step: 4
Training loss: 0.07228720188140869
Validation loss: 1.3218602653472655

Epoch: 6| Step: 5
Training loss: 0.05576495826244354
Validation loss: 1.3183052027097313

Epoch: 6| Step: 6
Training loss: 0.03743415325880051
Validation loss: 1.3253258569266206

Epoch: 6| Step: 7
Training loss: 0.040511853992938995
Validation loss: 1.341773731734163

Epoch: 6| Step: 8
Training loss: 0.05448116734623909
Validation loss: 1.3512040171571957

Epoch: 6| Step: 9
Training loss: 0.07801474630832672
Validation loss: 1.336766876200194

Epoch: 6| Step: 10
Training loss: 0.06359344720840454
Validation loss: 1.3633616919158607

Epoch: 6| Step: 11
Training loss: 0.06224394589662552
Validation loss: 1.317215577248604

Epoch: 6| Step: 12
Training loss: 0.03048882633447647
Validation loss: 1.336299902649336

Epoch: 6| Step: 13
Training loss: 0.06638961285352707
Validation loss: 1.3350559408946703

Epoch: 710| Step: 0
Training loss: 0.05104741081595421
Validation loss: 1.3244431326466222

Epoch: 6| Step: 1
Training loss: 0.035740770399570465
Validation loss: 1.3499069136957969

Epoch: 6| Step: 2
Training loss: 0.044792503118515015
Validation loss: 1.3816848243436506

Epoch: 6| Step: 3
Training loss: 0.060775965452194214
Validation loss: 1.3689766840268207

Epoch: 6| Step: 4
Training loss: 0.030888766050338745
Validation loss: 1.3584013062138711

Epoch: 6| Step: 5
Training loss: 0.04339694231748581
Validation loss: 1.405037114697118

Epoch: 6| Step: 6
Training loss: 0.026528535410761833
Validation loss: 1.3917448687297043

Epoch: 6| Step: 7
Training loss: 0.04875962436199188
Validation loss: 1.3955214690136653

Epoch: 6| Step: 8
Training loss: 0.03768911585211754
Validation loss: 1.3906998608701973

Epoch: 6| Step: 9
Training loss: 0.04265878349542618
Validation loss: 1.396070808492681

Epoch: 6| Step: 10
Training loss: 0.06827861815690994
Validation loss: 1.4048336872490503

Epoch: 6| Step: 11
Training loss: 0.06852785497903824
Validation loss: 1.3910649117603098

Epoch: 6| Step: 12
Training loss: 0.03841656446456909
Validation loss: 1.4106385259218113

Epoch: 6| Step: 13
Training loss: 0.055997006595134735
Validation loss: 1.3837027395925214

Epoch: 711| Step: 0
Training loss: 0.038539819419384
Validation loss: 1.399040756046131

Epoch: 6| Step: 1
Training loss: 0.046422578394412994
Validation loss: 1.392363025296119

Epoch: 6| Step: 2
Training loss: 0.05486232787370682
Validation loss: 1.3798950320930892

Epoch: 6| Step: 3
Training loss: 0.048711493611335754
Validation loss: 1.358550739544694

Epoch: 6| Step: 4
Training loss: 0.04879918694496155
Validation loss: 1.3563769825043217

Epoch: 6| Step: 5
Training loss: 0.05385406315326691
Validation loss: 1.3638156601177749

Epoch: 6| Step: 6
Training loss: 0.049591876566410065
Validation loss: 1.35597151325595

Epoch: 6| Step: 7
Training loss: 0.05422186478972435
Validation loss: 1.368512689426381

Epoch: 6| Step: 8
Training loss: 0.061712149530649185
Validation loss: 1.3677461852309525

Epoch: 6| Step: 9
Training loss: 0.04767700657248497
Validation loss: 1.3783787841437964

Epoch: 6| Step: 10
Training loss: 0.03544797748327255
Validation loss: 1.3872267129600688

Epoch: 6| Step: 11
Training loss: 0.04983644187450409
Validation loss: 1.3758171194343156

Epoch: 6| Step: 12
Training loss: 0.09292532503604889
Validation loss: 1.3797846430091447

Epoch: 6| Step: 13
Training loss: 0.05870681256055832
Validation loss: 1.4247062270359327

Epoch: 712| Step: 0
Training loss: 0.048597872257232666
Validation loss: 1.389659607282249

Epoch: 6| Step: 1
Training loss: 0.050501879304647446
Validation loss: 1.3871344661199918

Epoch: 6| Step: 2
Training loss: 0.05361180752515793
Validation loss: 1.390849966515777

Epoch: 6| Step: 3
Training loss: 0.05538894981145859
Validation loss: 1.4139314223361272

Epoch: 6| Step: 4
Training loss: 0.039442792534828186
Validation loss: 1.3876158204129947

Epoch: 6| Step: 5
Training loss: 0.03565606847405434
Validation loss: 1.3971756709519254

Epoch: 6| Step: 6
Training loss: 0.043758995831012726
Validation loss: 1.3640551035122206

Epoch: 6| Step: 7
Training loss: 0.045916371047496796
Validation loss: 1.373706430517217

Epoch: 6| Step: 8
Training loss: 0.08103758096694946
Validation loss: 1.3807821863441057

Epoch: 6| Step: 9
Training loss: 0.04895586520433426
Validation loss: 1.3539599180221558

Epoch: 6| Step: 10
Training loss: 0.036211080849170685
Validation loss: 1.358315751757673

Epoch: 6| Step: 11
Training loss: 0.05268600583076477
Validation loss: 1.3899157559999855

Epoch: 6| Step: 12
Training loss: 0.0707477405667305
Validation loss: 1.362650966131559

Epoch: 6| Step: 13
Training loss: 0.036948561668395996
Validation loss: 1.3563884945325955

Epoch: 713| Step: 0
Training loss: 0.04367363825440407
Validation loss: 1.3567867150870703

Epoch: 6| Step: 1
Training loss: 0.0797823816537857
Validation loss: 1.3737404987376223

Epoch: 6| Step: 2
Training loss: 0.050928764045238495
Validation loss: 1.3547013075120988

Epoch: 6| Step: 3
Training loss: 0.05152348801493645
Validation loss: 1.3861286960622317

Epoch: 6| Step: 4
Training loss: 0.060434289276599884
Validation loss: 1.3687596513379006

Epoch: 6| Step: 5
Training loss: 0.0513603501021862
Validation loss: 1.3724641235925819

Epoch: 6| Step: 6
Training loss: 0.05710083991289139
Validation loss: 1.390575207689757

Epoch: 6| Step: 7
Training loss: 0.04227606952190399
Validation loss: 1.393094430687607

Epoch: 6| Step: 8
Training loss: 0.03835529834032059
Validation loss: 1.4047833540106331

Epoch: 6| Step: 9
Training loss: 0.0572376474738121
Validation loss: 1.4092506516364314

Epoch: 6| Step: 10
Training loss: 0.05426905304193497
Validation loss: 1.4130547431207472

Epoch: 6| Step: 11
Training loss: 0.044595927000045776
Validation loss: 1.395790796766999

Epoch: 6| Step: 12
Training loss: 0.037604574114084244
Validation loss: 1.3644808120624994

Epoch: 6| Step: 13
Training loss: 0.060233552008867264
Validation loss: 1.342494821676644

Epoch: 714| Step: 0
Training loss: 0.03657045215368271
Validation loss: 1.33418595662681

Epoch: 6| Step: 1
Training loss: 0.05797002464532852
Validation loss: 1.3317132085882208

Epoch: 6| Step: 2
Training loss: 0.04755771905183792
Validation loss: 1.338147287727684

Epoch: 6| Step: 3
Training loss: 0.06094159185886383
Validation loss: 1.3142295293910529

Epoch: 6| Step: 4
Training loss: 0.0346299484372139
Validation loss: 1.3149972705430881

Epoch: 6| Step: 5
Training loss: 0.04331623762845993
Validation loss: 1.3321784183543215

Epoch: 6| Step: 6
Training loss: 0.05562160164117813
Validation loss: 1.3225229991379606

Epoch: 6| Step: 7
Training loss: 0.027183281257748604
Validation loss: 1.358524832674252

Epoch: 6| Step: 8
Training loss: 0.0433385893702507
Validation loss: 1.3703367133294382

Epoch: 6| Step: 9
Training loss: 0.041847918182611465
Validation loss: 1.3776190524460168

Epoch: 6| Step: 10
Training loss: 0.03862122446298599
Validation loss: 1.3717279165021834

Epoch: 6| Step: 11
Training loss: 0.06836041063070297
Validation loss: 1.3723617817765923

Epoch: 6| Step: 12
Training loss: 0.04530081897974014
Validation loss: 1.389147106037345

Epoch: 6| Step: 13
Training loss: 0.03383735939860344
Validation loss: 1.3932029124229186

Epoch: 715| Step: 0
Training loss: 0.04345046728849411
Validation loss: 1.367835315324927

Epoch: 6| Step: 1
Training loss: 0.03443004935979843
Validation loss: 1.3876309138472362

Epoch: 6| Step: 2
Training loss: 0.05072290077805519
Validation loss: 1.3694124292301875

Epoch: 6| Step: 3
Training loss: 0.03394925221800804
Validation loss: 1.3668535140252882

Epoch: 6| Step: 4
Training loss: 0.038844093680381775
Validation loss: 1.3427226325517059

Epoch: 6| Step: 5
Training loss: 0.030824847519397736
Validation loss: 1.328020332961954

Epoch: 6| Step: 6
Training loss: 0.04579462856054306
Validation loss: 1.3535189179963962

Epoch: 6| Step: 7
Training loss: 0.03174688667058945
Validation loss: 1.350121796131134

Epoch: 6| Step: 8
Training loss: 0.055520329624414444
Validation loss: 1.3498783175663283

Epoch: 6| Step: 9
Training loss: 0.05746450275182724
Validation loss: 1.3302940860871346

Epoch: 6| Step: 10
Training loss: 0.05423910915851593
Validation loss: 1.3220785958792574

Epoch: 6| Step: 11
Training loss: 0.05624929443001747
Validation loss: 1.370723492355757

Epoch: 6| Step: 12
Training loss: 0.029129184782505035
Validation loss: 1.3401954943133938

Epoch: 6| Step: 13
Training loss: 0.0729704424738884
Validation loss: 1.3957091736537155

Epoch: 716| Step: 0
Training loss: 0.04707641154527664
Validation loss: 1.359634231495601

Epoch: 6| Step: 1
Training loss: 0.05639477074146271
Validation loss: 1.3701866544703

Epoch: 6| Step: 2
Training loss: 0.023640763014554977
Validation loss: 1.3747397456117856

Epoch: 6| Step: 3
Training loss: 0.0707753449678421
Validation loss: 1.3793888771405785

Epoch: 6| Step: 4
Training loss: 0.04489031434059143
Validation loss: 1.3833635827546478

Epoch: 6| Step: 5
Training loss: 0.05393775925040245
Validation loss: 1.378746913325402

Epoch: 6| Step: 6
Training loss: 0.052298471331596375
Validation loss: 1.3825952836903193

Epoch: 6| Step: 7
Training loss: 0.04754544049501419
Validation loss: 1.3707641786144626

Epoch: 6| Step: 8
Training loss: 0.04207560420036316
Validation loss: 1.3492123760202879

Epoch: 6| Step: 9
Training loss: 0.02615005150437355
Validation loss: 1.3520744180166593

Epoch: 6| Step: 10
Training loss: 0.06070766597986221
Validation loss: 1.3342616211983465

Epoch: 6| Step: 11
Training loss: 0.07513772696256638
Validation loss: 1.3696012266220585

Epoch: 6| Step: 12
Training loss: 0.05636313557624817
Validation loss: 1.3256427280364498

Epoch: 6| Step: 13
Training loss: 0.028184659779071808
Validation loss: 1.3335042377953887

Epoch: 717| Step: 0
Training loss: 0.04082848131656647
Validation loss: 1.3409047434406896

Epoch: 6| Step: 1
Training loss: 0.05821175128221512
Validation loss: 1.3334058173882064

Epoch: 6| Step: 2
Training loss: 0.070650115609169
Validation loss: 1.3293137319626347

Epoch: 6| Step: 3
Training loss: 0.08918377012014389
Validation loss: 1.3418508998809322

Epoch: 6| Step: 4
Training loss: 0.04822452366352081
Validation loss: 1.3070922948980843

Epoch: 6| Step: 5
Training loss: 0.03302488848567009
Validation loss: 1.3301871771453528

Epoch: 6| Step: 6
Training loss: 0.046370700001716614
Validation loss: 1.3681486216924523

Epoch: 6| Step: 7
Training loss: 0.042844001203775406
Validation loss: 1.3532139690973426

Epoch: 6| Step: 8
Training loss: 0.07665474712848663
Validation loss: 1.3641916987716511

Epoch: 6| Step: 9
Training loss: 0.048173364251852036
Validation loss: 1.381454812583103

Epoch: 6| Step: 10
Training loss: 0.062259018421173096
Validation loss: 1.3898132334473312

Epoch: 6| Step: 11
Training loss: 0.05307494103908539
Validation loss: 1.4093651720272597

Epoch: 6| Step: 12
Training loss: 0.04292838275432587
Validation loss: 1.4163802362257434

Epoch: 6| Step: 13
Training loss: 0.05043596401810646
Validation loss: 1.3745624961391572

Epoch: 718| Step: 0
Training loss: 0.02182871662080288
Validation loss: 1.4062510087925901

Epoch: 6| Step: 1
Training loss: 0.05273422598838806
Validation loss: 1.3807212178425123

Epoch: 6| Step: 2
Training loss: 0.051963865756988525
Validation loss: 1.3785124594165432

Epoch: 6| Step: 3
Training loss: 0.03386778011918068
Validation loss: 1.3782897456999748

Epoch: 6| Step: 4
Training loss: 0.050221387296915054
Validation loss: 1.3772168095393846

Epoch: 6| Step: 5
Training loss: 0.06159205734729767
Validation loss: 1.3826108081366426

Epoch: 6| Step: 6
Training loss: 0.041582874953746796
Validation loss: 1.3427737092459073

Epoch: 6| Step: 7
Training loss: 0.05230952426791191
Validation loss: 1.3573117550983225

Epoch: 6| Step: 8
Training loss: 0.0316866897046566
Validation loss: 1.3689964150869718

Epoch: 6| Step: 9
Training loss: 0.050379179418087006
Validation loss: 1.338741095476253

Epoch: 6| Step: 10
Training loss: 0.056917399168014526
Validation loss: 1.329252339178516

Epoch: 6| Step: 11
Training loss: 0.06348924338817596
Validation loss: 1.3501868914532404

Epoch: 6| Step: 12
Training loss: 0.04079952463507652
Validation loss: 1.329899477061405

Epoch: 6| Step: 13
Training loss: 0.06694836169481277
Validation loss: 1.3311163610027683

Epoch: 719| Step: 0
Training loss: 0.06242017820477486
Validation loss: 1.3125491296091387

Epoch: 6| Step: 1
Training loss: 0.05837059020996094
Validation loss: 1.3277665799663914

Epoch: 6| Step: 2
Training loss: 0.06117311120033264
Validation loss: 1.3287520844449279

Epoch: 6| Step: 3
Training loss: 0.044551704078912735
Validation loss: 1.3779453257078766

Epoch: 6| Step: 4
Training loss: 0.048427700996398926
Validation loss: 1.3469279978864936

Epoch: 6| Step: 5
Training loss: 0.06262568384408951
Validation loss: 1.3647001558734524

Epoch: 6| Step: 6
Training loss: 0.059944771230220795
Validation loss: 1.3415841126954684

Epoch: 6| Step: 7
Training loss: 0.03768695145845413
Validation loss: 1.374976161987551

Epoch: 6| Step: 8
Training loss: 0.04233021289110184
Validation loss: 1.3309134244918823

Epoch: 6| Step: 9
Training loss: 0.07086017727851868
Validation loss: 1.3380624844181923

Epoch: 6| Step: 10
Training loss: 0.04047887772321701
Validation loss: 1.3034737763866302

Epoch: 6| Step: 11
Training loss: 0.056360598653554916
Validation loss: 1.327979996640195

Epoch: 6| Step: 12
Training loss: 0.051883548498153687
Validation loss: 1.3570986473432152

Epoch: 6| Step: 13
Training loss: 0.036124322563409805
Validation loss: 1.324997728870761

Epoch: 720| Step: 0
Training loss: 0.06208404153585434
Validation loss: 1.337256767416513

Epoch: 6| Step: 1
Training loss: 0.036282576620578766
Validation loss: 1.334407442359514

Epoch: 6| Step: 2
Training loss: 0.0607188418507576
Validation loss: 1.3445307952101513

Epoch: 6| Step: 3
Training loss: 0.06619389355182648
Validation loss: 1.3668034281781924

Epoch: 6| Step: 4
Training loss: 0.03267594054341316
Validation loss: 1.3833748320097565

Epoch: 6| Step: 5
Training loss: 0.048806048929691315
Validation loss: 1.3600770170970629

Epoch: 6| Step: 6
Training loss: 0.04859410598874092
Validation loss: 1.3461112085209097

Epoch: 6| Step: 7
Training loss: 0.0425950288772583
Validation loss: 1.3968733600390855

Epoch: 6| Step: 8
Training loss: 0.03378932178020477
Validation loss: 1.3616738460397209

Epoch: 6| Step: 9
Training loss: 0.027021601796150208
Validation loss: 1.3812979017534563

Epoch: 6| Step: 10
Training loss: 0.06604740023612976
Validation loss: 1.3834721401173582

Epoch: 6| Step: 11
Training loss: 0.04672838747501373
Validation loss: 1.3727682444357103

Epoch: 6| Step: 12
Training loss: 0.023842325434088707
Validation loss: 1.365003865252259

Epoch: 6| Step: 13
Training loss: 0.015729913488030434
Validation loss: 1.3508444281034573

Epoch: 721| Step: 0
Training loss: 0.048457711935043335
Validation loss: 1.3711372113996936

Epoch: 6| Step: 1
Training loss: 0.05686739832162857
Validation loss: 1.3545632144456268

Epoch: 6| Step: 2
Training loss: 0.037488050758838654
Validation loss: 1.351158857345581

Epoch: 6| Step: 3
Training loss: 0.04918184131383896
Validation loss: 1.3643320132327337

Epoch: 6| Step: 4
Training loss: 0.081187903881073
Validation loss: 1.364385179294053

Epoch: 6| Step: 5
Training loss: 0.04758748784661293
Validation loss: 1.352387870511701

Epoch: 6| Step: 6
Training loss: 0.05535714700818062
Validation loss: 1.3748909991274598

Epoch: 6| Step: 7
Training loss: 0.05029261112213135
Validation loss: 1.3789085239492438

Epoch: 6| Step: 8
Training loss: 0.04911886900663376
Validation loss: 1.3937859368580643

Epoch: 6| Step: 9
Training loss: 0.03852143883705139
Validation loss: 1.3883275671671795

Epoch: 6| Step: 10
Training loss: 0.04656205326318741
Validation loss: 1.407463554413088

Epoch: 6| Step: 11
Training loss: 0.039255015552043915
Validation loss: 1.4093118457384006

Epoch: 6| Step: 12
Training loss: 0.040380340069532394
Validation loss: 1.3762866566258092

Epoch: 6| Step: 13
Training loss: 0.05125416815280914
Validation loss: 1.3914165009734452

Epoch: 722| Step: 0
Training loss: 0.03710838034749031
Validation loss: 1.368387201780914

Epoch: 6| Step: 1
Training loss: 0.04748084396123886
Validation loss: 1.4179677181346442

Epoch: 6| Step: 2
Training loss: 0.044953830540180206
Validation loss: 1.4071553176449192

Epoch: 6| Step: 3
Training loss: 0.05485605448484421
Validation loss: 1.3958717264154905

Epoch: 6| Step: 4
Training loss: 0.04132843762636185
Validation loss: 1.3913839350464523

Epoch: 6| Step: 5
Training loss: 0.06784359365701675
Validation loss: 1.3832890961759834

Epoch: 6| Step: 6
Training loss: 0.03867461904883385
Validation loss: 1.3420325376654183

Epoch: 6| Step: 7
Training loss: 0.03766511380672455
Validation loss: 1.3826594057903494

Epoch: 6| Step: 8
Training loss: 0.061501238495111465
Validation loss: 1.3689323785484477

Epoch: 6| Step: 9
Training loss: 0.0646723136305809
Validation loss: 1.3498372198433004

Epoch: 6| Step: 10
Training loss: 0.04096527770161629
Validation loss: 1.3659422102794851

Epoch: 6| Step: 11
Training loss: 0.044384442269802094
Validation loss: 1.3472626004167783

Epoch: 6| Step: 12
Training loss: 0.09310860186815262
Validation loss: 1.3722231676501613

Epoch: 6| Step: 13
Training loss: 0.06133425980806351
Validation loss: 1.320490869783586

Epoch: 723| Step: 0
Training loss: 0.05109413340687752
Validation loss: 1.3315413472472981

Epoch: 6| Step: 1
Training loss: 0.043397966772317886
Validation loss: 1.3342799076469996

Epoch: 6| Step: 2
Training loss: 0.03489726036787033
Validation loss: 1.3657743494997743

Epoch: 6| Step: 3
Training loss: 0.04040270298719406
Validation loss: 1.3646452119273524

Epoch: 6| Step: 4
Training loss: 0.03288128972053528
Validation loss: 1.383393399177059

Epoch: 6| Step: 5
Training loss: 0.04880997911095619
Validation loss: 1.401913897965544

Epoch: 6| Step: 6
Training loss: 0.07399046421051025
Validation loss: 1.4231290913397265

Epoch: 6| Step: 7
Training loss: 0.04862245172262192
Validation loss: 1.4395568665637766

Epoch: 6| Step: 8
Training loss: 0.06828749179840088
Validation loss: 1.436790406703949

Epoch: 6| Step: 9
Training loss: 0.045168861746788025
Validation loss: 1.4313747068887115

Epoch: 6| Step: 10
Training loss: 0.05445251986384392
Validation loss: 1.4151593145503794

Epoch: 6| Step: 11
Training loss: 0.04779638722538948
Validation loss: 1.409622525656095

Epoch: 6| Step: 12
Training loss: 0.05670151114463806
Validation loss: 1.3903482165387882

Epoch: 6| Step: 13
Training loss: 0.04684428498148918
Validation loss: 1.3852058995154597

Epoch: 724| Step: 0
Training loss: 0.05672580376267433
Validation loss: 1.3716196167853572

Epoch: 6| Step: 1
Training loss: 0.06214291974902153
Validation loss: 1.3431604485357962

Epoch: 6| Step: 2
Training loss: 0.05612596869468689
Validation loss: 1.3163185234992736

Epoch: 6| Step: 3
Training loss: 0.03869009017944336
Validation loss: 1.3439447456790554

Epoch: 6| Step: 4
Training loss: 0.09176616370677948
Validation loss: 1.3241778375000082

Epoch: 6| Step: 5
Training loss: 0.06593293696641922
Validation loss: 1.3190096001471243

Epoch: 6| Step: 6
Training loss: 0.026298053562641144
Validation loss: 1.3512853332745132

Epoch: 6| Step: 7
Training loss: 0.038178950548172
Validation loss: 1.3776388383039864

Epoch: 6| Step: 8
Training loss: 0.0494425892829895
Validation loss: 1.3820721167390064

Epoch: 6| Step: 9
Training loss: 0.03954397141933441
Validation loss: 1.3937951698098132

Epoch: 6| Step: 10
Training loss: 0.03274859860539436
Validation loss: 1.4059544724802817

Epoch: 6| Step: 11
Training loss: 0.028174107894301414
Validation loss: 1.419507493254959

Epoch: 6| Step: 12
Training loss: 0.03788595646619797
Validation loss: 1.4142890899412093

Epoch: 6| Step: 13
Training loss: 0.07703977078199387
Validation loss: 1.4162154325874903

Epoch: 725| Step: 0
Training loss: 0.06836144626140594
Validation loss: 1.4046715408243158

Epoch: 6| Step: 1
Training loss: 0.035054005682468414
Validation loss: 1.4048339820677234

Epoch: 6| Step: 2
Training loss: 0.03903497755527496
Validation loss: 1.3982093513652842

Epoch: 6| Step: 3
Training loss: 0.05116644129157066
Validation loss: 1.4095049058237383

Epoch: 6| Step: 4
Training loss: 0.045492932200431824
Validation loss: 1.3985236421708138

Epoch: 6| Step: 5
Training loss: 0.04805348813533783
Validation loss: 1.4223252214411253

Epoch: 6| Step: 6
Training loss: 0.053433530032634735
Validation loss: 1.4156431946703183

Epoch: 6| Step: 7
Training loss: 0.04125425964593887
Validation loss: 1.404838982448783

Epoch: 6| Step: 8
Training loss: 0.048947468400001526
Validation loss: 1.3827481962019397

Epoch: 6| Step: 9
Training loss: 0.044508252292871475
Validation loss: 1.368624723085793

Epoch: 6| Step: 10
Training loss: 0.04004061222076416
Validation loss: 1.3552382517886419

Epoch: 6| Step: 11
Training loss: 0.04756297543644905
Validation loss: 1.3720088710067093

Epoch: 6| Step: 12
Training loss: 0.06661432981491089
Validation loss: 1.3660194386718094

Epoch: 6| Step: 13
Training loss: 0.04544984921813011
Validation loss: 1.3739217532578336

Epoch: 726| Step: 0
Training loss: 0.05090940371155739
Validation loss: 1.3730891302067747

Epoch: 6| Step: 1
Training loss: 0.03811910003423691
Validation loss: 1.3701801184684999

Epoch: 6| Step: 2
Training loss: 0.047707244753837585
Validation loss: 1.3843677236187844

Epoch: 6| Step: 3
Training loss: 0.051649145781993866
Validation loss: 1.3675465955529162

Epoch: 6| Step: 4
Training loss: 0.03997546061873436
Validation loss: 1.3426237388323712

Epoch: 6| Step: 5
Training loss: 0.062340348958969116
Validation loss: 1.357078339463921

Epoch: 6| Step: 6
Training loss: 0.04159189760684967
Validation loss: 1.3295030619508477

Epoch: 6| Step: 7
Training loss: 0.04704734683036804
Validation loss: 1.3375578721364338

Epoch: 6| Step: 8
Training loss: 0.06840155273675919
Validation loss: 1.3406432950368492

Epoch: 6| Step: 9
Training loss: 0.052510593086481094
Validation loss: 1.351657872558922

Epoch: 6| Step: 10
Training loss: 0.035945020616054535
Validation loss: 1.340091154780439

Epoch: 6| Step: 11
Training loss: 0.08325459063053131
Validation loss: 1.3280435095551193

Epoch: 6| Step: 12
Training loss: 0.03816046565771103
Validation loss: 1.329064634538466

Epoch: 6| Step: 13
Training loss: 0.07421258091926575
Validation loss: 1.3372096598789256

Epoch: 727| Step: 0
Training loss: 0.03526303917169571
Validation loss: 1.3341715348664152

Epoch: 6| Step: 1
Training loss: 0.03968222439289093
Validation loss: 1.3410245346766647

Epoch: 6| Step: 2
Training loss: 0.05303477868437767
Validation loss: 1.3488806216947493

Epoch: 6| Step: 3
Training loss: 0.06201857328414917
Validation loss: 1.3731544492065266

Epoch: 6| Step: 4
Training loss: 0.03164486959576607
Validation loss: 1.3847175887835923

Epoch: 6| Step: 5
Training loss: 0.037292785942554474
Validation loss: 1.3831346945096088

Epoch: 6| Step: 6
Training loss: 0.043255798518657684
Validation loss: 1.3930323707160128

Epoch: 6| Step: 7
Training loss: 0.06441569328308105
Validation loss: 1.3979696048203336

Epoch: 6| Step: 8
Training loss: 0.03354840725660324
Validation loss: 1.3998979137789818

Epoch: 6| Step: 9
Training loss: 0.07521190494298935
Validation loss: 1.389404640402845

Epoch: 6| Step: 10
Training loss: 0.04834986478090286
Validation loss: 1.3800108528906299

Epoch: 6| Step: 11
Training loss: 0.049195945262908936
Validation loss: 1.3853817870540004

Epoch: 6| Step: 12
Training loss: 0.05099125951528549
Validation loss: 1.360355975807354

Epoch: 6| Step: 13
Training loss: 0.0505308173596859
Validation loss: 1.3675996270231021

Epoch: 728| Step: 0
Training loss: 0.056641388684511185
Validation loss: 1.3574650261991767

Epoch: 6| Step: 1
Training loss: 0.04673381894826889
Validation loss: 1.358306888611086

Epoch: 6| Step: 2
Training loss: 0.04664919525384903
Validation loss: 1.3459591795039434

Epoch: 6| Step: 3
Training loss: 0.049725569784641266
Validation loss: 1.339557110622365

Epoch: 6| Step: 4
Training loss: 0.04478929564356804
Validation loss: 1.322074282553888

Epoch: 6| Step: 5
Training loss: 0.04993367940187454
Validation loss: 1.3467919249688425

Epoch: 6| Step: 6
Training loss: 0.06780613958835602
Validation loss: 1.3230739614014984

Epoch: 6| Step: 7
Training loss: 0.05579419061541557
Validation loss: 1.3281957321269537

Epoch: 6| Step: 8
Training loss: 0.05332174152135849
Validation loss: 1.3359438809015418

Epoch: 6| Step: 9
Training loss: 0.04351979121565819
Validation loss: 1.3536295916444512

Epoch: 6| Step: 10
Training loss: 0.037488047033548355
Validation loss: 1.3799583476076844

Epoch: 6| Step: 11
Training loss: 0.0676528662443161
Validation loss: 1.3717352113416117

Epoch: 6| Step: 12
Training loss: 0.07968170940876007
Validation loss: 1.3728080936657485

Epoch: 6| Step: 13
Training loss: 0.058035798370838165
Validation loss: 1.4129871206898843

Epoch: 729| Step: 0
Training loss: 0.0533328652381897
Validation loss: 1.430043396129403

Epoch: 6| Step: 1
Training loss: 0.061923131346702576
Validation loss: 1.4252105618035922

Epoch: 6| Step: 2
Training loss: 0.052814655005931854
Validation loss: 1.4135984586131187

Epoch: 6| Step: 3
Training loss: 0.0876607894897461
Validation loss: 1.4451474464067848

Epoch: 6| Step: 4
Training loss: 0.07343421876430511
Validation loss: 1.4057501387852493

Epoch: 6| Step: 5
Training loss: 0.030067136511206627
Validation loss: 1.4150608919000114

Epoch: 6| Step: 6
Training loss: 0.03755059838294983
Validation loss: 1.384953882104607

Epoch: 6| Step: 7
Training loss: 0.03987886384129524
Validation loss: 1.3634431721061788

Epoch: 6| Step: 8
Training loss: 0.045327991247177124
Validation loss: 1.32839633059758

Epoch: 6| Step: 9
Training loss: 0.04638606682419777
Validation loss: 1.3083127160226145

Epoch: 6| Step: 10
Training loss: 0.0549083948135376
Validation loss: 1.3106005294348604

Epoch: 6| Step: 11
Training loss: 0.040555842220783234
Validation loss: 1.3174700788272324

Epoch: 6| Step: 12
Training loss: 0.0473107248544693
Validation loss: 1.2906727060194938

Epoch: 6| Step: 13
Training loss: 0.08673903346061707
Validation loss: 1.3055102991801437

Epoch: 730| Step: 0
Training loss: 0.05649098381400108
Validation loss: 1.3183889414674492

Epoch: 6| Step: 1
Training loss: 0.056726809591054916
Validation loss: 1.3374953705777404

Epoch: 6| Step: 2
Training loss: 0.056353550404310226
Validation loss: 1.360785036958674

Epoch: 6| Step: 3
Training loss: 0.0540110245347023
Validation loss: 1.3660202269913049

Epoch: 6| Step: 4
Training loss: 0.04617048799991608
Validation loss: 1.3669043356372463

Epoch: 6| Step: 5
Training loss: 0.0754486545920372
Validation loss: 1.3650156451809792

Epoch: 6| Step: 6
Training loss: 0.049254998564720154
Validation loss: 1.355038332682784

Epoch: 6| Step: 7
Training loss: 0.06244022026658058
Validation loss: 1.3421922370951662

Epoch: 6| Step: 8
Training loss: 0.02820313349366188
Validation loss: 1.3082195020491076

Epoch: 6| Step: 9
Training loss: 0.04877309501171112
Validation loss: 1.2958147096377548

Epoch: 6| Step: 10
Training loss: 0.05938311666250229
Validation loss: 1.3075826244969522

Epoch: 6| Step: 11
Training loss: 0.07916408032178879
Validation loss: 1.3005499032235914

Epoch: 6| Step: 12
Training loss: 0.0680590569972992
Validation loss: 1.3043102692532282

Epoch: 6| Step: 13
Training loss: 0.06177203357219696
Validation loss: 1.2807059339297715

Epoch: 731| Step: 0
Training loss: 0.0299668051302433
Validation loss: 1.2977387917939054

Epoch: 6| Step: 1
Training loss: 0.0768912136554718
Validation loss: 1.2974876614027127

Epoch: 6| Step: 2
Training loss: 0.05216372758150101
Validation loss: 1.3083021499777352

Epoch: 6| Step: 3
Training loss: 0.05727129057049751
Validation loss: 1.312385005335654

Epoch: 6| Step: 4
Training loss: 0.04916325956583023
Validation loss: 1.3351330603322675

Epoch: 6| Step: 5
Training loss: 0.040720850229263306
Validation loss: 1.3322341486971865

Epoch: 6| Step: 6
Training loss: 0.05452212691307068
Validation loss: 1.3627383337225965

Epoch: 6| Step: 7
Training loss: 0.04561905562877655
Validation loss: 1.3495283216558478

Epoch: 6| Step: 8
Training loss: 0.04341285303235054
Validation loss: 1.3488392496621737

Epoch: 6| Step: 9
Training loss: 0.04851065203547478
Validation loss: 1.369089440632892

Epoch: 6| Step: 10
Training loss: 0.05138973519206047
Validation loss: 1.3775176187997222

Epoch: 6| Step: 11
Training loss: 0.05794389918446541
Validation loss: 1.3805146704437912

Epoch: 6| Step: 12
Training loss: 0.053284384310245514
Validation loss: 1.3832315014254661

Epoch: 6| Step: 13
Training loss: 0.07455192506313324
Validation loss: 1.3482224466980144

Epoch: 732| Step: 0
Training loss: 0.05680215358734131
Validation loss: 1.3565840182765838

Epoch: 6| Step: 1
Training loss: 0.035511769354343414
Validation loss: 1.3649262087319487

Epoch: 6| Step: 2
Training loss: 0.037762753665447235
Validation loss: 1.3336157362948182

Epoch: 6| Step: 3
Training loss: 0.0758405402302742
Validation loss: 1.3453088671930375

Epoch: 6| Step: 4
Training loss: 0.040171973407268524
Validation loss: 1.3273006575081938

Epoch: 6| Step: 5
Training loss: 0.04737326130270958
Validation loss: 1.3437950341932234

Epoch: 6| Step: 6
Training loss: 0.05180532485246658
Validation loss: 1.356871981774607

Epoch: 6| Step: 7
Training loss: 0.040269993245601654
Validation loss: 1.3414153866870429

Epoch: 6| Step: 8
Training loss: 0.062175244092941284
Validation loss: 1.3376506041455012

Epoch: 6| Step: 9
Training loss: 0.03707224503159523
Validation loss: 1.3574598604632961

Epoch: 6| Step: 10
Training loss: 0.06652560085058212
Validation loss: 1.3351945825802383

Epoch: 6| Step: 11
Training loss: 0.0765511766076088
Validation loss: 1.332479044955264

Epoch: 6| Step: 12
Training loss: 0.04111938178539276
Validation loss: 1.3751060257675827

Epoch: 6| Step: 13
Training loss: 0.047613900154829025
Validation loss: 1.3557419674370879

Epoch: 733| Step: 0
Training loss: 0.0355750247836113
Validation loss: 1.3614324497920212

Epoch: 6| Step: 1
Training loss: 0.02948930859565735
Validation loss: 1.3747404647129837

Epoch: 6| Step: 2
Training loss: 0.043067567050457
Validation loss: 1.3559915109347271

Epoch: 6| Step: 3
Training loss: 0.05892830342054367
Validation loss: 1.3847545372542513

Epoch: 6| Step: 4
Training loss: 0.04489720240235329
Validation loss: 1.3477839128945464

Epoch: 6| Step: 5
Training loss: 0.046448081731796265
Validation loss: 1.3532894695958784

Epoch: 6| Step: 6
Training loss: 0.06392449885606766
Validation loss: 1.3645064318051903

Epoch: 6| Step: 7
Training loss: 0.03795645758509636
Validation loss: 1.3675398929144746

Epoch: 6| Step: 8
Training loss: 0.04749210178852081
Validation loss: 1.3618525599920621

Epoch: 6| Step: 9
Training loss: 0.04642914980649948
Validation loss: 1.3911900122960408

Epoch: 6| Step: 10
Training loss: 0.05676819384098053
Validation loss: 1.3856528523147746

Epoch: 6| Step: 11
Training loss: 0.06466097384691238
Validation loss: 1.3783353131304505

Epoch: 6| Step: 12
Training loss: 0.04008311778306961
Validation loss: 1.3852123906535487

Epoch: 6| Step: 13
Training loss: 0.08691562712192535
Validation loss: 1.3560485968025782

Epoch: 734| Step: 0
Training loss: 0.03970067575573921
Validation loss: 1.3498976115257508

Epoch: 6| Step: 1
Training loss: 0.07629448175430298
Validation loss: 1.3461574123751732

Epoch: 6| Step: 2
Training loss: 0.053245659917593
Validation loss: 1.345492878267842

Epoch: 6| Step: 3
Training loss: 0.06749266386032104
Validation loss: 1.321079913006034

Epoch: 6| Step: 4
Training loss: 0.028027115389704704
Validation loss: 1.3160607776334208

Epoch: 6| Step: 5
Training loss: 0.031485430896282196
Validation loss: 1.3180635116433586

Epoch: 6| Step: 6
Training loss: 0.057550329715013504
Validation loss: 1.351526347539758

Epoch: 6| Step: 7
Training loss: 0.03997929394245148
Validation loss: 1.311126551320476

Epoch: 6| Step: 8
Training loss: 0.046280842274427414
Validation loss: 1.318462452580852

Epoch: 6| Step: 9
Training loss: 0.07066242396831512
Validation loss: 1.3079187729025399

Epoch: 6| Step: 10
Training loss: 0.03836023807525635
Validation loss: 1.3092904667700491

Epoch: 6| Step: 11
Training loss: 0.0783945694565773
Validation loss: 1.286564862856301

Epoch: 6| Step: 12
Training loss: 0.06269868463277817
Validation loss: 1.2843384653009393

Epoch: 6| Step: 13
Training loss: 0.08137818425893784
Validation loss: 1.3063811858495076

Epoch: 735| Step: 0
Training loss: 0.11272422224283218
Validation loss: 1.3439294894536336

Epoch: 6| Step: 1
Training loss: 0.07120863348245621
Validation loss: 1.368763771749312

Epoch: 6| Step: 2
Training loss: 0.06558573246002197
Validation loss: 1.3871194329313052

Epoch: 6| Step: 3
Training loss: 0.08477387577295303
Validation loss: 1.3948229333405853

Epoch: 6| Step: 4
Training loss: 0.05385342985391617
Validation loss: 1.3945607248172964

Epoch: 6| Step: 5
Training loss: 0.05961458757519722
Validation loss: 1.400801254856971

Epoch: 6| Step: 6
Training loss: 0.06816864013671875
Validation loss: 1.391949422897831

Epoch: 6| Step: 7
Training loss: 0.0711195170879364
Validation loss: 1.4127127483326902

Epoch: 6| Step: 8
Training loss: 0.07388325035572052
Validation loss: 1.3606986627783826

Epoch: 6| Step: 9
Training loss: 0.08250507712364197
Validation loss: 1.3844280255738126

Epoch: 6| Step: 10
Training loss: 0.04092946648597717
Validation loss: 1.3619805138598207

Epoch: 6| Step: 11
Training loss: 0.06151529774069786
Validation loss: 1.3615421736112205

Epoch: 6| Step: 12
Training loss: 0.0746334120631218
Validation loss: 1.3684829255586028

Epoch: 6| Step: 13
Training loss: 0.1377490609884262
Validation loss: 1.3795404921295822

Epoch: 736| Step: 0
Training loss: 0.04916640371084213
Validation loss: 1.3462562484125937

Epoch: 6| Step: 1
Training loss: 0.03566157817840576
Validation loss: 1.3273463229979239

Epoch: 6| Step: 2
Training loss: 0.05059558525681496
Validation loss: 1.3675337895270316

Epoch: 6| Step: 3
Training loss: 0.043475229293107986
Validation loss: 1.369147366093051

Epoch: 6| Step: 4
Training loss: 0.03454992175102234
Validation loss: 1.3478892785246654

Epoch: 6| Step: 5
Training loss: 0.06589864194393158
Validation loss: 1.3933867972384217

Epoch: 6| Step: 6
Training loss: 0.06261785328388214
Validation loss: 1.3772830809316328

Epoch: 6| Step: 7
Training loss: 0.07608163356781006
Validation loss: 1.3868762408533404

Epoch: 6| Step: 8
Training loss: 0.09857690334320068
Validation loss: 1.3420549041481429

Epoch: 6| Step: 9
Training loss: 0.04408939555287361
Validation loss: 1.3421091636021931

Epoch: 6| Step: 10
Training loss: 0.06085706129670143
Validation loss: 1.3116851231103301

Epoch: 6| Step: 11
Training loss: 0.04919281601905823
Validation loss: 1.2947222814765027

Epoch: 6| Step: 12
Training loss: 0.08322452753782272
Validation loss: 1.3068083306794525

Epoch: 6| Step: 13
Training loss: 0.06671511381864548
Validation loss: 1.2837042116349744

Epoch: 737| Step: 0
Training loss: 0.07067226618528366
Validation loss: 1.2649284011574202

Epoch: 6| Step: 1
Training loss: 0.07268857955932617
Validation loss: 1.2693301977649811

Epoch: 6| Step: 2
Training loss: 0.08763236552476883
Validation loss: 1.3211324509753977

Epoch: 6| Step: 3
Training loss: 0.042164579033851624
Validation loss: 1.3255786626569686

Epoch: 6| Step: 4
Training loss: 0.03262866660952568
Validation loss: 1.31587823360197

Epoch: 6| Step: 5
Training loss: 0.06840385496616364
Validation loss: 1.3656672777668122

Epoch: 6| Step: 6
Training loss: 0.05793633311986923
Validation loss: 1.3832981150637391

Epoch: 6| Step: 7
Training loss: 0.04229511320590973
Validation loss: 1.3926579644603114

Epoch: 6| Step: 8
Training loss: 0.04909338802099228
Validation loss: 1.419674760551863

Epoch: 6| Step: 9
Training loss: 0.057261012494564056
Validation loss: 1.4291654838028776

Epoch: 6| Step: 10
Training loss: 0.06278511881828308
Validation loss: 1.4229934805183

Epoch: 6| Step: 11
Training loss: 0.06097977235913277
Validation loss: 1.4645247510684434

Epoch: 6| Step: 12
Training loss: 0.08975408971309662
Validation loss: 1.3995437750252344

Epoch: 6| Step: 13
Training loss: 0.07197383046150208
Validation loss: 1.3700729634172173

Epoch: 738| Step: 0
Training loss: 0.050129566341638565
Validation loss: 1.352451096298874

Epoch: 6| Step: 1
Training loss: 0.04894718900322914
Validation loss: 1.358651150298375

Epoch: 6| Step: 2
Training loss: 0.06912397593259811
Validation loss: 1.3487268654249047

Epoch: 6| Step: 3
Training loss: 0.04902306944131851
Validation loss: 1.3322864668343657

Epoch: 6| Step: 4
Training loss: 0.08020631968975067
Validation loss: 1.3270722717367194

Epoch: 6| Step: 5
Training loss: 0.05068117380142212
Validation loss: 1.3030326353606356

Epoch: 6| Step: 6
Training loss: 0.04172602295875549
Validation loss: 1.3103604906348771

Epoch: 6| Step: 7
Training loss: 0.05027829855680466
Validation loss: 1.3041411228077386

Epoch: 6| Step: 8
Training loss: 0.084476538002491
Validation loss: 1.2905802290926698

Epoch: 6| Step: 9
Training loss: 0.03246767073869705
Validation loss: 1.2842339610540738

Epoch: 6| Step: 10
Training loss: 0.04673932492733002
Validation loss: 1.3025137544960104

Epoch: 6| Step: 11
Training loss: 0.05320364236831665
Validation loss: 1.3192166564285115

Epoch: 6| Step: 12
Training loss: 0.08445146679878235
Validation loss: 1.3388484947143062

Epoch: 6| Step: 13
Training loss: 0.0753120556473732
Validation loss: 1.3376478469499977

Epoch: 739| Step: 0
Training loss: 0.05446793884038925
Validation loss: 1.3743446962807768

Epoch: 6| Step: 1
Training loss: 0.06258964538574219
Validation loss: 1.3791326733045681

Epoch: 6| Step: 2
Training loss: 0.053994350135326385
Validation loss: 1.4027004600853048

Epoch: 6| Step: 3
Training loss: 0.06225735694169998
Validation loss: 1.391751766204834

Epoch: 6| Step: 4
Training loss: 0.028825832530856133
Validation loss: 1.3870003114464462

Epoch: 6| Step: 5
Training loss: 0.05129372328519821
Validation loss: 1.4060539039232398

Epoch: 6| Step: 6
Training loss: 0.05130574107170105
Validation loss: 1.3939673413512528

Epoch: 6| Step: 7
Training loss: 0.04900703206658363
Validation loss: 1.4004809805141982

Epoch: 6| Step: 8
Training loss: 0.047549739480018616
Validation loss: 1.3740184896735734

Epoch: 6| Step: 9
Training loss: 0.0705893412232399
Validation loss: 1.3573621242277083

Epoch: 6| Step: 10
Training loss: 0.04145406186580658
Validation loss: 1.3576137763197704

Epoch: 6| Step: 11
Training loss: 0.049603432416915894
Validation loss: 1.350112872098082

Epoch: 6| Step: 12
Training loss: 0.06492972373962402
Validation loss: 1.384291159850295

Epoch: 6| Step: 13
Training loss: 0.04505605250597
Validation loss: 1.3541461280597153

Epoch: 740| Step: 0
Training loss: 0.05547871068120003
Validation loss: 1.3503107640051073

Epoch: 6| Step: 1
Training loss: 0.03704033046960831
Validation loss: 1.3576328696743134

Epoch: 6| Step: 2
Training loss: 0.054967012256383896
Validation loss: 1.3606502497068016

Epoch: 6| Step: 3
Training loss: 0.04542582482099533
Validation loss: 1.3829464720141502

Epoch: 6| Step: 4
Training loss: 0.031228452920913696
Validation loss: 1.3750015151116155

Epoch: 6| Step: 5
Training loss: 0.06361962854862213
Validation loss: 1.3846496388476381

Epoch: 6| Step: 6
Training loss: 0.05715034902095795
Validation loss: 1.3832243847590622

Epoch: 6| Step: 7
Training loss: 0.06939399242401123
Validation loss: 1.3765460018829634

Epoch: 6| Step: 8
Training loss: 0.06545574963092804
Validation loss: 1.3968070078921575

Epoch: 6| Step: 9
Training loss: 0.03560503572225571
Validation loss: 1.3851980586205759

Epoch: 6| Step: 10
Training loss: 0.04472319036722183
Validation loss: 1.4138083175946308

Epoch: 6| Step: 11
Training loss: 0.04454988241195679
Validation loss: 1.397905049785491

Epoch: 6| Step: 12
Training loss: 0.03801270201802254
Validation loss: 1.3935188234493296

Epoch: 6| Step: 13
Training loss: 0.046475376933813095
Validation loss: 1.384151542058555

Epoch: 741| Step: 0
Training loss: 0.03807411342859268
Validation loss: 1.3586148686947361

Epoch: 6| Step: 1
Training loss: 0.05367423966526985
Validation loss: 1.3625560607961429

Epoch: 6| Step: 2
Training loss: 0.04875805601477623
Validation loss: 1.3433900981821039

Epoch: 6| Step: 3
Training loss: 0.04673266038298607
Validation loss: 1.360780510851132

Epoch: 6| Step: 4
Training loss: 0.07289783656597137
Validation loss: 1.3534761692887993

Epoch: 6| Step: 5
Training loss: 0.03923504799604416
Validation loss: 1.3520264625549316

Epoch: 6| Step: 6
Training loss: 0.04822467267513275
Validation loss: 1.3544642489443544

Epoch: 6| Step: 7
Training loss: 0.03591043874621391
Validation loss: 1.3722054022614674

Epoch: 6| Step: 8
Training loss: 0.055659957230091095
Validation loss: 1.3931362129026843

Epoch: 6| Step: 9
Training loss: 0.03218931704759598
Validation loss: 1.3850141622686898

Epoch: 6| Step: 10
Training loss: 0.061655089259147644
Validation loss: 1.3745717028135895

Epoch: 6| Step: 11
Training loss: 0.05091641843318939
Validation loss: 1.3661421434853667

Epoch: 6| Step: 12
Training loss: 0.05554882064461708
Validation loss: 1.366450446908192

Epoch: 6| Step: 13
Training loss: 0.08432217687368393
Validation loss: 1.3906358531726304

Epoch: 742| Step: 0
Training loss: 0.028495781123638153
Validation loss: 1.3947566196482668

Epoch: 6| Step: 1
Training loss: 0.058768078684806824
Validation loss: 1.374836467927502

Epoch: 6| Step: 2
Training loss: 0.04585273936390877
Validation loss: 1.3630608961146364

Epoch: 6| Step: 3
Training loss: 0.0681455060839653
Validation loss: 1.3790180503681142

Epoch: 6| Step: 4
Training loss: 0.028948156163096428
Validation loss: 1.3527026983999437

Epoch: 6| Step: 5
Training loss: 0.07786628603935242
Validation loss: 1.4091199944096227

Epoch: 6| Step: 6
Training loss: 0.06541313230991364
Validation loss: 1.3940028650786287

Epoch: 6| Step: 7
Training loss: 0.0791250616312027
Validation loss: 1.4351132172410206

Epoch: 6| Step: 8
Training loss: 0.04119719937443733
Validation loss: 1.399087841151863

Epoch: 6| Step: 9
Training loss: 0.04543483629822731
Validation loss: 1.3862513021756244

Epoch: 6| Step: 10
Training loss: 0.023431446403265
Validation loss: 1.377460801473228

Epoch: 6| Step: 11
Training loss: 0.040019866079092026
Validation loss: 1.346684576362692

Epoch: 6| Step: 12
Training loss: 0.08304395526647568
Validation loss: 1.3494202744576238

Epoch: 6| Step: 13
Training loss: 0.02093040943145752
Validation loss: 1.3555110628886888

Epoch: 743| Step: 0
Training loss: 0.038068898022174835
Validation loss: 1.366811337009553

Epoch: 6| Step: 1
Training loss: 0.03144862502813339
Validation loss: 1.4019725591905656

Epoch: 6| Step: 2
Training loss: 0.053044747561216354
Validation loss: 1.3937822311155257

Epoch: 6| Step: 3
Training loss: 0.060417503118515015
Validation loss: 1.368476342129451

Epoch: 6| Step: 4
Training loss: 0.046465031802654266
Validation loss: 1.4056915108875563

Epoch: 6| Step: 5
Training loss: 0.053459376096725464
Validation loss: 1.3882904860281176

Epoch: 6| Step: 6
Training loss: 0.050897784531116486
Validation loss: 1.4011044707349551

Epoch: 6| Step: 7
Training loss: 0.05383681505918503
Validation loss: 1.3771497626458444

Epoch: 6| Step: 8
Training loss: 0.04012949764728546
Validation loss: 1.4323428933338453

Epoch: 6| Step: 9
Training loss: 0.0514480359852314
Validation loss: 1.3958802915388537

Epoch: 6| Step: 10
Training loss: 0.03675158694386482
Validation loss: 1.4077782131010486

Epoch: 6| Step: 11
Training loss: 0.052643097937107086
Validation loss: 1.4176880954414286

Epoch: 6| Step: 12
Training loss: 0.0535210445523262
Validation loss: 1.4088201381826913

Epoch: 6| Step: 13
Training loss: 0.029828032478690147
Validation loss: 1.3892589153782013

Epoch: 744| Step: 0
Training loss: 0.07902678847312927
Validation loss: 1.387883529868177

Epoch: 6| Step: 1
Training loss: 0.06259014457464218
Validation loss: 1.390938239712869

Epoch: 6| Step: 2
Training loss: 0.05134442448616028
Validation loss: 1.3932853155238654

Epoch: 6| Step: 3
Training loss: 0.0490146279335022
Validation loss: 1.3912858347738943

Epoch: 6| Step: 4
Training loss: 0.04518929123878479
Validation loss: 1.386949723125786

Epoch: 6| Step: 5
Training loss: 0.04464935511350632
Validation loss: 1.392132508177911

Epoch: 6| Step: 6
Training loss: 0.05656152963638306
Validation loss: 1.3515518814004877

Epoch: 6| Step: 7
Training loss: 0.05547553300857544
Validation loss: 1.3447774712757399

Epoch: 6| Step: 8
Training loss: 0.06778734922409058
Validation loss: 1.3543411268982837

Epoch: 6| Step: 9
Training loss: 0.05659255385398865
Validation loss: 1.3511407234335457

Epoch: 6| Step: 10
Training loss: 0.06552138179540634
Validation loss: 1.324008087317149

Epoch: 6| Step: 11
Training loss: 0.07866474241018295
Validation loss: 1.3419166873860102

Epoch: 6| Step: 12
Training loss: 0.03584641218185425
Validation loss: 1.3761816268326135

Epoch: 6| Step: 13
Training loss: 0.05993545055389404
Validation loss: 1.3408388386490524

Epoch: 745| Step: 0
Training loss: 0.036691371351480484
Validation loss: 1.3690808383367394

Epoch: 6| Step: 1
Training loss: 0.05392806604504585
Validation loss: 1.3702388450663576

Epoch: 6| Step: 2
Training loss: 0.04388057440519333
Validation loss: 1.3464938158630042

Epoch: 6| Step: 3
Training loss: 0.05599391460418701
Validation loss: 1.350951740818639

Epoch: 6| Step: 4
Training loss: 0.0886002779006958
Validation loss: 1.3775265434736848

Epoch: 6| Step: 5
Training loss: 0.05027315765619278
Validation loss: 1.3667357647290794

Epoch: 6| Step: 6
Training loss: 0.04871329665184021
Validation loss: 1.3739347765522618

Epoch: 6| Step: 7
Training loss: 0.06841300427913666
Validation loss: 1.3711569604053293

Epoch: 6| Step: 8
Training loss: 0.08412136137485504
Validation loss: 1.3750650011083132

Epoch: 6| Step: 9
Training loss: 0.059550635516643524
Validation loss: 1.359448322685816

Epoch: 6| Step: 10
Training loss: 0.0435875728726387
Validation loss: 1.3420024546243812

Epoch: 6| Step: 11
Training loss: 0.05167573690414429
Validation loss: 1.3288913465315295

Epoch: 6| Step: 12
Training loss: 0.07522115856409073
Validation loss: 1.3174014437583186

Epoch: 6| Step: 13
Training loss: 0.04731425270438194
Validation loss: 1.3491170983160696

Epoch: 746| Step: 0
Training loss: 0.08077991753816605
Validation loss: 1.3239703037405526

Epoch: 6| Step: 1
Training loss: 0.042945824563503265
Validation loss: 1.3391867491506761

Epoch: 6| Step: 2
Training loss: 0.05497051030397415
Validation loss: 1.3210111664187523

Epoch: 6| Step: 3
Training loss: 0.03074599616229534
Validation loss: 1.3312799033298288

Epoch: 6| Step: 4
Training loss: 0.08367884159088135
Validation loss: 1.3460562940566771

Epoch: 6| Step: 5
Training loss: 0.05520966649055481
Validation loss: 1.3650708313911193

Epoch: 6| Step: 6
Training loss: 0.07804165780544281
Validation loss: 1.3600642078666276

Epoch: 6| Step: 7
Training loss: 0.030664848163723946
Validation loss: 1.4076565734801754

Epoch: 6| Step: 8
Training loss: 0.04111647605895996
Validation loss: 1.4170149872379918

Epoch: 6| Step: 9
Training loss: 0.06408412754535675
Validation loss: 1.4206474134998937

Epoch: 6| Step: 10
Training loss: 0.07782573997974396
Validation loss: 1.4020553288921234

Epoch: 6| Step: 11
Training loss: 0.07211695611476898
Validation loss: 1.4208993078559957

Epoch: 6| Step: 12
Training loss: 0.12909337878227234
Validation loss: 1.435315619232834

Epoch: 6| Step: 13
Training loss: 0.05158986151218414
Validation loss: 1.4117360268869708

Epoch: 747| Step: 0
Training loss: 0.06199664995074272
Validation loss: 1.3844206384433213

Epoch: 6| Step: 1
Training loss: 0.09478472918272018
Validation loss: 1.343598045969522

Epoch: 6| Step: 2
Training loss: 0.0756191611289978
Validation loss: 1.3437402325291787

Epoch: 6| Step: 3
Training loss: 0.07045668363571167
Validation loss: 1.3054514905457855

Epoch: 6| Step: 4
Training loss: 0.06757623702287674
Validation loss: 1.2983888887589978

Epoch: 6| Step: 5
Training loss: 0.05907786637544632
Validation loss: 1.2937276735100696

Epoch: 6| Step: 6
Training loss: 0.05395882576704025
Validation loss: 1.3360581603101505

Epoch: 6| Step: 7
Training loss: 0.07795803993940353
Validation loss: 1.339606149222261

Epoch: 6| Step: 8
Training loss: 0.0911281555891037
Validation loss: 1.3488855861848401

Epoch: 6| Step: 9
Training loss: 0.0527801513671875
Validation loss: 1.3362893186589724

Epoch: 6| Step: 10
Training loss: 0.06467822194099426
Validation loss: 1.362932639737283

Epoch: 6| Step: 11
Training loss: 0.0577399879693985
Validation loss: 1.3644906840016764

Epoch: 6| Step: 12
Training loss: 0.05681198090314865
Validation loss: 1.3847647597712855

Epoch: 6| Step: 13
Training loss: 0.01870882511138916
Validation loss: 1.3957584199085031

Epoch: 748| Step: 0
Training loss: 0.06328097730875015
Validation loss: 1.3929622647582844

Epoch: 6| Step: 1
Training loss: 0.045773088932037354
Validation loss: 1.401816447575887

Epoch: 6| Step: 2
Training loss: 0.07812884449958801
Validation loss: 1.3921161159392326

Epoch: 6| Step: 3
Training loss: 0.056639302521944046
Validation loss: 1.4025252929297827

Epoch: 6| Step: 4
Training loss: 0.043229710310697556
Validation loss: 1.3992784548831243

Epoch: 6| Step: 5
Training loss: 0.0680941641330719
Validation loss: 1.3757359622627177

Epoch: 6| Step: 6
Training loss: 0.04619395732879639
Validation loss: 1.3956481602884108

Epoch: 6| Step: 7
Training loss: 0.05331743508577347
Validation loss: 1.3877204438691497

Epoch: 6| Step: 8
Training loss: 0.05286511778831482
Validation loss: 1.4173947072798205

Epoch: 6| Step: 9
Training loss: 0.08907834440469742
Validation loss: 1.3867298057002406

Epoch: 6| Step: 10
Training loss: 0.04952211305499077
Validation loss: 1.389482444332492

Epoch: 6| Step: 11
Training loss: 0.07144267857074738
Validation loss: 1.3790110740610348

Epoch: 6| Step: 12
Training loss: 0.06497188657522202
Validation loss: 1.381985810495192

Epoch: 6| Step: 13
Training loss: 0.04688084125518799
Validation loss: 1.4093280428199357

Epoch: 749| Step: 0
Training loss: 0.038118887692689896
Validation loss: 1.4140407462273874

Epoch: 6| Step: 1
Training loss: 0.060675863176584244
Validation loss: 1.4006303189903178

Epoch: 6| Step: 2
Training loss: 0.05090564489364624
Validation loss: 1.4119122098850947

Epoch: 6| Step: 3
Training loss: 0.03698132559657097
Validation loss: 1.3991876186863068

Epoch: 6| Step: 4
Training loss: 0.048245545476675034
Validation loss: 1.395725033616507

Epoch: 6| Step: 5
Training loss: 0.04251618683338165
Validation loss: 1.390992295357489

Epoch: 6| Step: 6
Training loss: 0.13057850301265717
Validation loss: 1.402132050965422

Epoch: 6| Step: 7
Training loss: 0.046803638339042664
Validation loss: 1.4111770045372747

Epoch: 6| Step: 8
Training loss: 0.04823678731918335
Validation loss: 1.3856838621119016

Epoch: 6| Step: 9
Training loss: 0.05310799926519394
Validation loss: 1.3905589779218037

Epoch: 6| Step: 10
Training loss: 0.04004852846264839
Validation loss: 1.3873591461489279

Epoch: 6| Step: 11
Training loss: 0.04319367557764053
Validation loss: 1.3960600181292462

Epoch: 6| Step: 12
Training loss: 0.04704270884394646
Validation loss: 1.3890220811290126

Epoch: 6| Step: 13
Training loss: 0.035797119140625
Validation loss: 1.378470265737144

Epoch: 750| Step: 0
Training loss: 0.05179683119058609
Validation loss: 1.3818789387261996

Epoch: 6| Step: 1
Training loss: 0.05217987298965454
Validation loss: 1.364977789181535

Epoch: 6| Step: 2
Training loss: 0.032968197017908096
Validation loss: 1.3742875899038007

Epoch: 6| Step: 3
Training loss: 0.04469291865825653
Validation loss: 1.369098122401904

Epoch: 6| Step: 4
Training loss: 0.06600186228752136
Validation loss: 1.371709459571428

Epoch: 6| Step: 5
Training loss: 0.03329116106033325
Validation loss: 1.3528046184970486

Epoch: 6| Step: 6
Training loss: 0.051182642579078674
Validation loss: 1.3783414088269716

Epoch: 6| Step: 7
Training loss: 0.053500138223171234
Validation loss: 1.368194266032147

Epoch: 6| Step: 8
Training loss: 0.04089942201972008
Validation loss: 1.3548883994420369

Epoch: 6| Step: 9
Training loss: 0.05950087308883667
Validation loss: 1.385000991564925

Epoch: 6| Step: 10
Training loss: 0.04105192422866821
Validation loss: 1.382760990050531

Epoch: 6| Step: 11
Training loss: 0.050583455711603165
Validation loss: 1.3963354633700462

Epoch: 6| Step: 12
Training loss: 0.08243667334318161
Validation loss: 1.4026230919745661

Epoch: 6| Step: 13
Training loss: 0.04481925070285797
Validation loss: 1.4196860585161435

Testing loss: 2.149886711438497
