Epoch: 1| Step: 0
Training loss: 5.464133793903273
Validation loss: 5.840589499445924

Epoch: 6| Step: 1
Training loss: 4.629466606378138
Validation loss: 5.812992438076919

Epoch: 6| Step: 2
Training loss: 6.553681179269534
Validation loss: 5.785336541815252

Epoch: 6| Step: 3
Training loss: 6.463551962140102
Validation loss: 5.755383208441072

Epoch: 6| Step: 4
Training loss: 5.817168627105599
Validation loss: 5.721751635200713

Epoch: 6| Step: 5
Training loss: 5.310105805285811
Validation loss: 5.683542372252816

Epoch: 6| Step: 6
Training loss: 5.625956305699298
Validation loss: 5.6410519990478045

Epoch: 6| Step: 7
Training loss: 5.589693783201887
Validation loss: 5.592834054854069

Epoch: 6| Step: 8
Training loss: 5.98526161737463
Validation loss: 5.540028327667193

Epoch: 6| Step: 9
Training loss: 6.724513221339136
Validation loss: 5.481463398208089

Epoch: 6| Step: 10
Training loss: 6.580242477633566
Validation loss: 5.416588023382343

Epoch: 6| Step: 11
Training loss: 5.278694030913051
Validation loss: 5.348048020402231

Epoch: 6| Step: 12
Training loss: 3.7332823363862837
Validation loss: 5.274686632566903

Epoch: 6| Step: 13
Training loss: 2.532569353033315
Validation loss: 5.200111508573995

Epoch: 2| Step: 0
Training loss: 4.150693463216229
Validation loss: 5.128354881098155

Epoch: 6| Step: 1
Training loss: 5.36656840611573
Validation loss: 5.056602264346119

Epoch: 6| Step: 2
Training loss: 5.32756688391501
Validation loss: 4.983708020743103

Epoch: 6| Step: 3
Training loss: 4.813754624151814
Validation loss: 4.906736641466702

Epoch: 6| Step: 4
Training loss: 5.638551114159752
Validation loss: 4.8332477190004415

Epoch: 6| Step: 5
Training loss: 4.5450609921096845
Validation loss: 4.757511335418513

Epoch: 6| Step: 6
Training loss: 5.5932775543002045
Validation loss: 4.684384594462626

Epoch: 6| Step: 7
Training loss: 2.4288772262257567
Validation loss: 4.6122610315775585

Epoch: 6| Step: 8
Training loss: 4.70829250801864
Validation loss: 4.547633120952768

Epoch: 6| Step: 9
Training loss: 5.137140919557549
Validation loss: 4.488615442694047

Epoch: 6| Step: 10
Training loss: 4.670622284494226
Validation loss: 4.43298465530473

Epoch: 6| Step: 11
Training loss: 2.5725198560713953
Validation loss: 4.379718513117461

Epoch: 6| Step: 12
Training loss: 5.211048039260477
Validation loss: 4.331332792480959

Epoch: 6| Step: 13
Training loss: 5.561333694771391
Validation loss: 4.282529058576514

Epoch: 3| Step: 0
Training loss: 4.204247987614125
Validation loss: 4.235159035311544

Epoch: 6| Step: 1
Training loss: 4.674550186793649
Validation loss: 4.1902684730209865

Epoch: 6| Step: 2
Training loss: 5.0520678752649575
Validation loss: 4.145761613023983

Epoch: 6| Step: 3
Training loss: 3.547717830322596
Validation loss: 4.10558683964873

Epoch: 6| Step: 4
Training loss: 4.201820142627041
Validation loss: 4.075919188142982

Epoch: 6| Step: 5
Training loss: 3.6945381885640067
Validation loss: 4.052372729635698

Epoch: 6| Step: 6
Training loss: 4.472903795346682
Validation loss: 4.027748043774216

Epoch: 6| Step: 7
Training loss: 3.962559595472156
Validation loss: 4.006343572119989

Epoch: 6| Step: 8
Training loss: 3.9942898524231936
Validation loss: 3.9857123835822668

Epoch: 6| Step: 9
Training loss: 4.654951285692254
Validation loss: 3.9633764000983005

Epoch: 6| Step: 10
Training loss: 4.6292717254189855
Validation loss: 3.9372056563589544

Epoch: 6| Step: 11
Training loss: 3.5942443507645567
Validation loss: 3.9137966416212437

Epoch: 6| Step: 12
Training loss: 3.6318457845137413
Validation loss: 3.8923120163347362

Epoch: 6| Step: 13
Training loss: 3.7292833931554257
Validation loss: 3.8696785442977615

Epoch: 4| Step: 0
Training loss: 3.401505552068371
Validation loss: 3.8479488611547046

Epoch: 6| Step: 1
Training loss: 4.0682913948053026
Validation loss: 3.82260364906136

Epoch: 6| Step: 2
Training loss: 4.708915516916712
Validation loss: 3.793090318203569

Epoch: 6| Step: 3
Training loss: 3.9005405051479474
Validation loss: 3.775344075174103

Epoch: 6| Step: 4
Training loss: 3.5489960768767443
Validation loss: 3.763125365799116

Epoch: 6| Step: 5
Training loss: 3.6003227830926567
Validation loss: 3.7424344193220933

Epoch: 6| Step: 6
Training loss: 4.6562084221743705
Validation loss: 3.7272709941148303

Epoch: 6| Step: 7
Training loss: 3.035762927523166
Validation loss: 3.7125869969214946

Epoch: 6| Step: 8
Training loss: 2.8972907664049212
Validation loss: 3.6976139668598713

Epoch: 6| Step: 9
Training loss: 4.1612752493003216
Validation loss: 3.6881309617412796

Epoch: 6| Step: 10
Training loss: 4.3213052833382
Validation loss: 3.679689626329738

Epoch: 6| Step: 11
Training loss: 4.41026977717308
Validation loss: 3.6557564407103857

Epoch: 6| Step: 12
Training loss: 3.755820779507883
Validation loss: 3.6386063029823226

Epoch: 6| Step: 13
Training loss: 3.7191524768660935
Validation loss: 3.6291762225218327

Epoch: 5| Step: 0
Training loss: 3.2852352101093443
Validation loss: 3.6233776905039634

Epoch: 6| Step: 1
Training loss: 3.8272046286781416
Validation loss: 3.6145146314851027

Epoch: 6| Step: 2
Training loss: 4.601668196340213
Validation loss: 3.5906821833121203

Epoch: 6| Step: 3
Training loss: 3.352980947111011
Validation loss: 3.5721616932444387

Epoch: 6| Step: 4
Training loss: 3.837541854580447
Validation loss: 3.5629137565665023

Epoch: 6| Step: 5
Training loss: 3.809212314552239
Validation loss: 3.566326076525301

Epoch: 6| Step: 6
Training loss: 4.055457481231936
Validation loss: 3.544088955252369

Epoch: 6| Step: 7
Training loss: 3.344494032747406
Validation loss: 3.5353109690855935

Epoch: 6| Step: 8
Training loss: 3.5090749800882493
Validation loss: 3.5162801036026776

Epoch: 6| Step: 9
Training loss: 3.437693087616816
Validation loss: 3.510656216758948

Epoch: 6| Step: 10
Training loss: 3.6322932046519245
Validation loss: 3.5006791186950657

Epoch: 6| Step: 11
Training loss: 3.8269584279589677
Validation loss: 3.493003825967216

Epoch: 6| Step: 12
Training loss: 4.2061098979499825
Validation loss: 3.483339937049465

Epoch: 6| Step: 13
Training loss: 3.403177117683376
Validation loss: 3.4680160770386372

Epoch: 6| Step: 0
Training loss: 2.9222203014965378
Validation loss: 3.463279098463032

Epoch: 6| Step: 1
Training loss: 3.830140746994119
Validation loss: 3.457071477128639

Epoch: 6| Step: 2
Training loss: 4.5310786773916085
Validation loss: 3.4402912594494377

Epoch: 6| Step: 3
Training loss: 3.9979068524729042
Validation loss: 3.43274547403874

Epoch: 6| Step: 4
Training loss: 3.760751063025102
Validation loss: 3.4260725190163335

Epoch: 6| Step: 5
Training loss: 2.357008195308507
Validation loss: 3.419586445736164

Epoch: 6| Step: 6
Training loss: 3.7113108878763748
Validation loss: 3.4133969580420747

Epoch: 6| Step: 7
Training loss: 3.260651812539135
Validation loss: 3.4079179182740225

Epoch: 6| Step: 8
Training loss: 4.039500937655218
Validation loss: 3.400726248455898

Epoch: 6| Step: 9
Training loss: 3.782000254453008
Validation loss: 3.384541951174284

Epoch: 6| Step: 10
Training loss: 3.357525125439353
Validation loss: 3.377824965276062

Epoch: 6| Step: 11
Training loss: 3.5256196092964376
Validation loss: 3.3836147961022696

Epoch: 6| Step: 12
Training loss: 3.18636137129048
Validation loss: 3.3535240157420034

Epoch: 6| Step: 13
Training loss: 4.428771555022032
Validation loss: 3.3590602734005777

Epoch: 7| Step: 0
Training loss: 2.4004058216628903
Validation loss: 3.3416670869963

Epoch: 6| Step: 1
Training loss: 3.1759363490820167
Validation loss: 3.342568523933506

Epoch: 6| Step: 2
Training loss: 4.538166739079181
Validation loss: 3.347534937164648

Epoch: 6| Step: 3
Training loss: 3.788387151879334
Validation loss: 3.3468922925448954

Epoch: 6| Step: 4
Training loss: 3.103791864967759
Validation loss: 3.338123491860052

Epoch: 6| Step: 5
Training loss: 3.603853039335258
Validation loss: 3.3350043681812664

Epoch: 6| Step: 6
Training loss: 3.833253624681682
Validation loss: 3.324440037202914

Epoch: 6| Step: 7
Training loss: 3.6476911479810856
Validation loss: 3.320250757018532

Epoch: 6| Step: 8
Training loss: 3.5777750302206144
Validation loss: 3.3104505229623906

Epoch: 6| Step: 9
Training loss: 3.365275324629336
Validation loss: 3.298337892458737

Epoch: 6| Step: 10
Training loss: 4.055581642891461
Validation loss: 3.2923671298519146

Epoch: 6| Step: 11
Training loss: 3.3272622293059375
Validation loss: 3.2825500694196124

Epoch: 6| Step: 12
Training loss: 3.3428390545524493
Validation loss: 3.2744839414876226

Epoch: 6| Step: 13
Training loss: 3.710471290616103
Validation loss: 3.267071428287709

Epoch: 8| Step: 0
Training loss: 3.3635080861368256
Validation loss: 3.256050427925519

Epoch: 6| Step: 1
Training loss: 3.334165151440474
Validation loss: 3.2507484811010148

Epoch: 6| Step: 2
Training loss: 2.93887832445803
Validation loss: 3.24147309093505

Epoch: 6| Step: 3
Training loss: 3.788446309432552
Validation loss: 3.233768427855716

Epoch: 6| Step: 4
Training loss: 3.6808754851887313
Validation loss: 3.224721157359346

Epoch: 6| Step: 5
Training loss: 4.085289985888251
Validation loss: 3.2171307720288493

Epoch: 6| Step: 6
Training loss: 3.1633516996739517
Validation loss: 3.2266015737683813

Epoch: 6| Step: 7
Training loss: 3.0002001059869916
Validation loss: 3.2025558578316504

Epoch: 6| Step: 8
Training loss: 3.328913492276797
Validation loss: 3.201896085583135

Epoch: 6| Step: 9
Training loss: 3.634260385400193
Validation loss: 3.1966649599639734

Epoch: 6| Step: 10
Training loss: 3.875555921485526
Validation loss: 3.189899616660853

Epoch: 6| Step: 11
Training loss: 3.443863683025323
Validation loss: 3.182173789176567

Epoch: 6| Step: 12
Training loss: 3.46492301910451
Validation loss: 3.1743712023735524

Epoch: 6| Step: 13
Training loss: 3.1225602353518944
Validation loss: 3.1703820046043885

Epoch: 9| Step: 0
Training loss: 2.980113557021635
Validation loss: 3.171474765945782

Epoch: 6| Step: 1
Training loss: 3.1857241002969623
Validation loss: 3.16238838367511

Epoch: 6| Step: 2
Training loss: 3.9965908304442688
Validation loss: 3.151657751812207

Epoch: 6| Step: 3
Training loss: 3.5389728997953402
Validation loss: 3.143255175731931

Epoch: 6| Step: 4
Training loss: 3.9285521791655347
Validation loss: 3.142532690828436

Epoch: 6| Step: 5
Training loss: 3.0639299440865986
Validation loss: 3.1541056854529823

Epoch: 6| Step: 6
Training loss: 3.017348513462901
Validation loss: 3.1396456220774933

Epoch: 6| Step: 7
Training loss: 3.3856006435386465
Validation loss: 3.1352981290417192

Epoch: 6| Step: 8
Training loss: 3.360251946540032
Validation loss: 3.123546306525552

Epoch: 6| Step: 9
Training loss: 3.653635247510428
Validation loss: 3.117977706999872

Epoch: 6| Step: 10
Training loss: 2.866233729413213
Validation loss: 3.114035583152219

Epoch: 6| Step: 11
Training loss: 2.5979022146239545
Validation loss: 3.1138962559091463

Epoch: 6| Step: 12
Training loss: 4.051744984652205
Validation loss: 3.112341888552496

Epoch: 6| Step: 13
Training loss: 3.9068395551197446
Validation loss: 3.110106349778373

Epoch: 10| Step: 0
Training loss: 2.5601518618720975
Validation loss: 3.105141517949643

Epoch: 6| Step: 1
Training loss: 3.406412803189006
Validation loss: 3.1117108239334286

Epoch: 6| Step: 2
Training loss: 3.535705995756397
Validation loss: 3.101957994036547

Epoch: 6| Step: 3
Training loss: 4.356345378428155
Validation loss: 3.103931013105118

Epoch: 6| Step: 4
Training loss: 3.813545458924694
Validation loss: 3.1070483757911234

Epoch: 6| Step: 5
Training loss: 3.0496015820037807
Validation loss: 3.121320741567761

Epoch: 6| Step: 6
Training loss: 3.212663395507608
Validation loss: 3.110161740163782

Epoch: 6| Step: 7
Training loss: 2.7964458455994827
Validation loss: 3.1028097528605336

Epoch: 6| Step: 8
Training loss: 2.7879498824345017
Validation loss: 3.113465480618664

Epoch: 6| Step: 9
Training loss: 3.621710633176183
Validation loss: 3.1232260445547086

Epoch: 6| Step: 10
Training loss: 3.2597885908137227
Validation loss: 3.135877874111145

Epoch: 6| Step: 11
Training loss: 3.581351745118821
Validation loss: 3.0947181236792405

Epoch: 6| Step: 12
Training loss: 3.529071777461268
Validation loss: 3.10149740573027

Epoch: 6| Step: 13
Training loss: 3.5781004792418534
Validation loss: 3.098426594678104

Epoch: 11| Step: 0
Training loss: 2.9643933905317166
Validation loss: 3.0918408922700595

Epoch: 6| Step: 1
Training loss: 3.405121362570716
Validation loss: 3.097557036591878

Epoch: 6| Step: 2
Training loss: 3.504336531638698
Validation loss: 3.1042762811873037

Epoch: 6| Step: 3
Training loss: 3.829911543021348
Validation loss: 3.108811314450763

Epoch: 6| Step: 4
Training loss: 2.8177261963076536
Validation loss: 3.1076184049335946

Epoch: 6| Step: 5
Training loss: 4.333643730979803
Validation loss: 3.10480080075208

Epoch: 6| Step: 6
Training loss: 2.895845554975521
Validation loss: 3.097993322433732

Epoch: 6| Step: 7
Training loss: 3.7220856908806907
Validation loss: 3.08976037241064

Epoch: 6| Step: 8
Training loss: 3.3430892434082717
Validation loss: 3.0827708381158785

Epoch: 6| Step: 9
Training loss: 2.889695136546022
Validation loss: 3.07693629228469

Epoch: 6| Step: 10
Training loss: 3.3651768463052845
Validation loss: 3.0741522895008617

Epoch: 6| Step: 11
Training loss: 3.683703262141339
Validation loss: 3.072896158029325

Epoch: 6| Step: 12
Training loss: 2.649740703060779
Validation loss: 3.084114530045282

Epoch: 6| Step: 13
Training loss: 3.468253435213341
Validation loss: 3.074484460891757

Epoch: 12| Step: 0
Training loss: 2.7812199966012447
Validation loss: 3.066170025942585

Epoch: 6| Step: 1
Training loss: 2.894425486744378
Validation loss: 3.0580632767318483

Epoch: 6| Step: 2
Training loss: 3.42217849012674
Validation loss: 3.053633921806144

Epoch: 6| Step: 3
Training loss: 4.1534405154322815
Validation loss: 3.0509984287048955

Epoch: 6| Step: 4
Training loss: 3.0448629925352217
Validation loss: 3.047607222826566

Epoch: 6| Step: 5
Training loss: 2.919798740610206
Validation loss: 3.045388560094308

Epoch: 6| Step: 6
Training loss: 3.6169267399766887
Validation loss: 3.044624160668023

Epoch: 6| Step: 7
Training loss: 3.2195793490761426
Validation loss: 3.040451163177096

Epoch: 6| Step: 8
Training loss: 3.645614544797725
Validation loss: 3.0390224853263526

Epoch: 6| Step: 9
Training loss: 3.4684538843730444
Validation loss: 3.0349721279021016

Epoch: 6| Step: 10
Training loss: 3.165895435045139
Validation loss: 3.033280831006226

Epoch: 6| Step: 11
Training loss: 3.9625505702886272
Validation loss: 3.0297349400293894

Epoch: 6| Step: 12
Training loss: 3.245925550085334
Validation loss: 3.02687387027909

Epoch: 6| Step: 13
Training loss: 2.215413230600132
Validation loss: 3.0244278215023326

Epoch: 13| Step: 0
Training loss: 3.911240220708377
Validation loss: 3.022110321946944

Epoch: 6| Step: 1
Training loss: 2.871410617080874
Validation loss: 3.018607637973777

Epoch: 6| Step: 2
Training loss: 3.417015492070072
Validation loss: 3.016307923718861

Epoch: 6| Step: 3
Training loss: 3.0399325579139154
Validation loss: 3.0125936755126848

Epoch: 6| Step: 4
Training loss: 3.2842111940486194
Validation loss: 3.010062277363603

Epoch: 6| Step: 5
Training loss: 3.6454909390933503
Validation loss: 3.00689743008901

Epoch: 6| Step: 6
Training loss: 3.7054330578379315
Validation loss: 3.0046452957934986

Epoch: 6| Step: 7
Training loss: 2.4121929941857325
Validation loss: 2.9993652608843804

Epoch: 6| Step: 8
Training loss: 3.1990085854160237
Validation loss: 2.9975236307896687

Epoch: 6| Step: 9
Training loss: 2.862214892985488
Validation loss: 2.9930271652084883

Epoch: 6| Step: 10
Training loss: 3.4982318499128424
Validation loss: 2.9908794057458885

Epoch: 6| Step: 11
Training loss: 3.4528746363123806
Validation loss: 2.9843817347166173

Epoch: 6| Step: 12
Training loss: 3.315813674376344
Validation loss: 2.9811063241058373

Epoch: 6| Step: 13
Training loss: 3.3276222099945074
Validation loss: 2.976556459006853

Epoch: 14| Step: 0
Training loss: 3.2668730618675648
Validation loss: 2.9725119674716174

Epoch: 6| Step: 1
Training loss: 4.153237534628012
Validation loss: 2.9756559934234708

Epoch: 6| Step: 2
Training loss: 3.020022649616923
Validation loss: 2.974638294799591

Epoch: 6| Step: 3
Training loss: 3.534255107866503
Validation loss: 2.9707749684728966

Epoch: 6| Step: 4
Training loss: 2.9570501168177015
Validation loss: 2.976731160543745

Epoch: 6| Step: 5
Training loss: 3.779181048370441
Validation loss: 3.000394062084949

Epoch: 6| Step: 6
Training loss: 3.11516488215985
Validation loss: 2.975638967661323

Epoch: 6| Step: 7
Training loss: 3.125281054255892
Validation loss: 2.973618573623589

Epoch: 6| Step: 8
Training loss: 3.0778033867913233
Validation loss: 2.9732130137611277

Epoch: 6| Step: 9
Training loss: 3.0229586436439453
Validation loss: 2.984423024038606

Epoch: 6| Step: 10
Training loss: 2.7617109803086426
Validation loss: 2.9893233200583853

Epoch: 6| Step: 11
Training loss: 3.1983073407008673
Validation loss: 2.979534861016976

Epoch: 6| Step: 12
Training loss: 3.1297554454388914
Validation loss: 2.970441560626182

Epoch: 6| Step: 13
Training loss: 3.72395050830508
Validation loss: 2.9638504650893487

Epoch: 15| Step: 0
Training loss: 2.8255088887936375
Validation loss: 2.9603230049266114

Epoch: 6| Step: 1
Training loss: 2.9187553193331817
Validation loss: 2.959141262317563

Epoch: 6| Step: 2
Training loss: 3.47848135467046
Validation loss: 2.959489586607838

Epoch: 6| Step: 3
Training loss: 2.773055101278473
Validation loss: 2.958099179762529

Epoch: 6| Step: 4
Training loss: 3.287766298597255
Validation loss: 2.955113183711284

Epoch: 6| Step: 5
Training loss: 3.1696989365342887
Validation loss: 2.955451045364234

Epoch: 6| Step: 6
Training loss: 3.817098626981046
Validation loss: 2.9531149021142498

Epoch: 6| Step: 7
Training loss: 3.0015505916075265
Validation loss: 2.952593864427127

Epoch: 6| Step: 8
Training loss: 3.6630990850120626
Validation loss: 2.949619858826749

Epoch: 6| Step: 9
Training loss: 2.515793883536749
Validation loss: 2.9467143725391827

Epoch: 6| Step: 10
Training loss: 3.676179870330868
Validation loss: 2.948491408799972

Epoch: 6| Step: 11
Training loss: 3.026956880522577
Validation loss: 2.947217164243665

Epoch: 6| Step: 12
Training loss: 3.6285588125861326
Validation loss: 2.9439414253747778

Epoch: 6| Step: 13
Training loss: 3.7892934197917234
Validation loss: 2.9416039641765304

Epoch: 16| Step: 0
Training loss: 2.382122102370449
Validation loss: 2.937761888980409

Epoch: 6| Step: 1
Training loss: 3.4223518213555635
Validation loss: 2.937294638006608

Epoch: 6| Step: 2
Training loss: 2.819057703245628
Validation loss: 2.9349165696415542

Epoch: 6| Step: 3
Training loss: 2.8103566797941455
Validation loss: 2.9348531242527267

Epoch: 6| Step: 4
Training loss: 3.589680233158737
Validation loss: 2.934167452161043

Epoch: 6| Step: 5
Training loss: 3.2225859663263865
Validation loss: 2.9331703403174547

Epoch: 6| Step: 6
Training loss: 3.566555325086358
Validation loss: 2.9468235972378802

Epoch: 6| Step: 7
Training loss: 2.7919483801816387
Validation loss: 2.9614034635586832

Epoch: 6| Step: 8
Training loss: 3.8918004232832866
Validation loss: 2.9593737874188464

Epoch: 6| Step: 9
Training loss: 3.274485854929861
Validation loss: 2.9302091120763016

Epoch: 6| Step: 10
Training loss: 3.4649640291446895
Validation loss: 2.927735879348727

Epoch: 6| Step: 11
Training loss: 3.1182013753444
Validation loss: 2.931315621329092

Epoch: 6| Step: 12
Training loss: 3.9226331244028048
Validation loss: 2.9377539583180803

Epoch: 6| Step: 13
Training loss: 2.4802218096507294
Validation loss: 2.9248460517913952

Epoch: 17| Step: 0
Training loss: 3.0316551960173608
Validation loss: 2.922579094549915

Epoch: 6| Step: 1
Training loss: 3.223031169005636
Validation loss: 2.9239848154491086

Epoch: 6| Step: 2
Training loss: 3.5923455189067592
Validation loss: 2.92275441826692

Epoch: 6| Step: 3
Training loss: 2.947385994062883
Validation loss: 2.9253309552234463

Epoch: 6| Step: 4
Training loss: 3.5900589273445975
Validation loss: 2.9313853342221377

Epoch: 6| Step: 5
Training loss: 3.0575778877025646
Validation loss: 2.923651775730446

Epoch: 6| Step: 6
Training loss: 3.2052251118413078
Validation loss: 2.928577869358607

Epoch: 6| Step: 7
Training loss: 2.9369506322226937
Validation loss: 2.9320269312352067

Epoch: 6| Step: 8
Training loss: 2.98403593204331
Validation loss: 2.9342545397782374

Epoch: 6| Step: 9
Training loss: 3.704923297741922
Validation loss: 2.930749046380301

Epoch: 6| Step: 10
Training loss: 3.2852463862950296
Validation loss: 2.9484149139737545

Epoch: 6| Step: 11
Training loss: 3.4973139674001628
Validation loss: 2.973013892966365

Epoch: 6| Step: 12
Training loss: 3.2094060582456843
Validation loss: 2.927077781704971

Epoch: 6| Step: 13
Training loss: 2.8743104522418417
Validation loss: 2.9149140701626317

Epoch: 18| Step: 0
Training loss: 3.6697161882304528
Validation loss: 2.9111845730261465

Epoch: 6| Step: 1
Training loss: 2.8649359653633315
Validation loss: 2.911563383946371

Epoch: 6| Step: 2
Training loss: 3.3139613544833
Validation loss: 2.9153448728158637

Epoch: 6| Step: 3
Training loss: 2.778324259937881
Validation loss: 2.915142466781465

Epoch: 6| Step: 4
Training loss: 3.369328855702009
Validation loss: 2.9227142190433453

Epoch: 6| Step: 5
Training loss: 3.1894350349207587
Validation loss: 2.92281152424737

Epoch: 6| Step: 6
Training loss: 3.4813282052095715
Validation loss: 2.9248752865753485

Epoch: 6| Step: 7
Training loss: 3.2907579994675347
Validation loss: 2.9153872577088293

Epoch: 6| Step: 8
Training loss: 2.7326209845812017
Validation loss: 2.917242746257172

Epoch: 6| Step: 9
Training loss: 3.0289282017960977
Validation loss: 2.921191713989567

Epoch: 6| Step: 10
Training loss: 3.2985656164054737
Validation loss: 2.912397968959636

Epoch: 6| Step: 11
Training loss: 3.097906230061508
Validation loss: 2.907903099893503

Epoch: 6| Step: 12
Training loss: 3.733209020951842
Validation loss: 2.9093603135436776

Epoch: 6| Step: 13
Training loss: 3.2394861204683423
Validation loss: 2.905859023024905

Epoch: 19| Step: 0
Training loss: 3.1820639837366937
Validation loss: 2.9024750266308383

Epoch: 6| Step: 1
Training loss: 2.542652210041804
Validation loss: 2.896187602520063

Epoch: 6| Step: 2
Training loss: 3.1554354381384915
Validation loss: 2.9011713156097625

Epoch: 6| Step: 3
Training loss: 3.585185585059899
Validation loss: 2.897093896829876

Epoch: 6| Step: 4
Training loss: 3.3872582381008436
Validation loss: 2.896714164560365

Epoch: 6| Step: 5
Training loss: 3.826241290566403
Validation loss: 2.8927280800689803

Epoch: 6| Step: 6
Training loss: 3.676499072693825
Validation loss: 2.891087693175035

Epoch: 6| Step: 7
Training loss: 3.135534459601915
Validation loss: 2.887441128764239

Epoch: 6| Step: 8
Training loss: 2.4473649938674877
Validation loss: 2.8851896322337676

Epoch: 6| Step: 9
Training loss: 3.139468155545238
Validation loss: 2.8844657208458724

Epoch: 6| Step: 10
Training loss: 2.960413259834908
Validation loss: 2.8784918594899453

Epoch: 6| Step: 11
Training loss: 3.3911237921115904
Validation loss: 2.8788652443699227

Epoch: 6| Step: 12
Training loss: 3.350997912819217
Validation loss: 2.8759019122714458

Epoch: 6| Step: 13
Training loss: 2.638302927603097
Validation loss: 2.876355989684747

Epoch: 20| Step: 0
Training loss: 3.4880563763865795
Validation loss: 2.8757828479930256

Epoch: 6| Step: 1
Training loss: 3.907442811045894
Validation loss: 2.8713149056368783

Epoch: 6| Step: 2
Training loss: 3.0331985660280454
Validation loss: 2.8726035889468737

Epoch: 6| Step: 3
Training loss: 2.5315512018783926
Validation loss: 2.8743385260215932

Epoch: 6| Step: 4
Training loss: 3.3686787783537566
Validation loss: 2.8721918513690605

Epoch: 6| Step: 5
Training loss: 2.5971099967532365
Validation loss: 2.873310959047949

Epoch: 6| Step: 6
Training loss: 3.1576489662434857
Validation loss: 2.875781591036476

Epoch: 6| Step: 7
Training loss: 2.826770521346362
Validation loss: 2.8721937338047083

Epoch: 6| Step: 8
Training loss: 3.1586865377749813
Validation loss: 2.8702651917103545

Epoch: 6| Step: 9
Training loss: 3.0733560711342944
Validation loss: 2.869410763336959

Epoch: 6| Step: 10
Training loss: 2.923509599539751
Validation loss: 2.8723184511203335

Epoch: 6| Step: 11
Training loss: 3.3641432876914785
Validation loss: 2.872689569378709

Epoch: 6| Step: 12
Training loss: 3.3801792106294717
Validation loss: 2.870787003268611

Epoch: 6| Step: 13
Training loss: 3.956280922429879
Validation loss: 2.868237069307682

Epoch: 21| Step: 0
Training loss: 3.1686794175332147
Validation loss: 2.8651766779862218

Epoch: 6| Step: 1
Training loss: 3.2215093247904645
Validation loss: 2.8629188294240406

Epoch: 6| Step: 2
Training loss: 3.3415965338471865
Validation loss: 2.862449264237947

Epoch: 6| Step: 3
Training loss: 2.5479186558397275
Validation loss: 2.867931963944793

Epoch: 6| Step: 4
Training loss: 1.616918790303157
Validation loss: 2.8773369896676653

Epoch: 6| Step: 5
Training loss: 3.619281335803465
Validation loss: 2.882492211710239

Epoch: 6| Step: 6
Training loss: 2.8568190527398922
Validation loss: 2.8689167871885797

Epoch: 6| Step: 7
Training loss: 3.624936465002549
Validation loss: 2.8609508419802743

Epoch: 6| Step: 8
Training loss: 4.016400095429052
Validation loss: 2.8623635673260006

Epoch: 6| Step: 9
Training loss: 3.4535643699372107
Validation loss: 2.8596092050651376

Epoch: 6| Step: 10
Training loss: 2.9132982330768393
Validation loss: 2.855405374472935

Epoch: 6| Step: 11
Training loss: 2.248504353497621
Validation loss: 2.854283017801278

Epoch: 6| Step: 12
Training loss: 4.018739672420633
Validation loss: 2.8528361089247896

Epoch: 6| Step: 13
Training loss: 3.0373236773769743
Validation loss: 2.8529051146929536

Epoch: 22| Step: 0
Training loss: 3.4663789910995773
Validation loss: 2.8538885074597533

Epoch: 6| Step: 1
Training loss: 2.6069050137299503
Validation loss: 2.8515850691633373

Epoch: 6| Step: 2
Training loss: 3.285039838436104
Validation loss: 2.8518762856100137

Epoch: 6| Step: 3
Training loss: 3.2341178754982303
Validation loss: 2.8543861908933996

Epoch: 6| Step: 4
Training loss: 3.1523552460679474
Validation loss: 2.8709082035584483

Epoch: 6| Step: 5
Training loss: 3.2323206767580257
Validation loss: 2.9155283334087154

Epoch: 6| Step: 6
Training loss: 3.4793007343219866
Validation loss: 2.927071792731016

Epoch: 6| Step: 7
Training loss: 3.365782265278487
Validation loss: 2.876608672712837

Epoch: 6| Step: 8
Training loss: 3.7126593199173343
Validation loss: 2.8474641417193176

Epoch: 6| Step: 9
Training loss: 2.0534945313645805
Validation loss: 2.8442195255457388

Epoch: 6| Step: 10
Training loss: 3.303680194257267
Validation loss: 2.862183394286165

Epoch: 6| Step: 11
Training loss: 3.396164829167601
Validation loss: 2.864084579289308

Epoch: 6| Step: 12
Training loss: 2.8438623427114034
Validation loss: 2.8416261762169484

Epoch: 6| Step: 13
Training loss: 2.93836735034047
Validation loss: 2.8942880990997084

Epoch: 23| Step: 0
Training loss: 3.265087612781719
Validation loss: 2.9040965397012672

Epoch: 6| Step: 1
Training loss: 3.653942716921003
Validation loss: 2.9345501567314987

Epoch: 6| Step: 2
Training loss: 2.4977838230097613
Validation loss: 2.896790349342801

Epoch: 6| Step: 3
Training loss: 3.845622281241421
Validation loss: 2.8884202419525

Epoch: 6| Step: 4
Training loss: 2.5656023551880147
Validation loss: 2.8681167858466847

Epoch: 6| Step: 5
Training loss: 3.5313272383353236
Validation loss: 2.851441181393062

Epoch: 6| Step: 6
Training loss: 2.9619480310964295
Validation loss: 2.8461027765138365

Epoch: 6| Step: 7
Training loss: 3.2590369249460216
Validation loss: 2.8498716206358776

Epoch: 6| Step: 8
Training loss: 3.1902613926763235
Validation loss: 2.8361695828368396

Epoch: 6| Step: 9
Training loss: 2.8943302635602155
Validation loss: 2.8417356817650354

Epoch: 6| Step: 10
Training loss: 3.4518062783493444
Validation loss: 2.849921962466259

Epoch: 6| Step: 11
Training loss: 2.483065565978867
Validation loss: 2.8537074588583007

Epoch: 6| Step: 12
Training loss: 3.5312267741561967
Validation loss: 2.8435443441857946

Epoch: 6| Step: 13
Training loss: 2.8980261827000864
Validation loss: 2.833015906077783

Epoch: 24| Step: 0
Training loss: 3.1435754685842316
Validation loss: 2.8268710574365863

Epoch: 6| Step: 1
Training loss: 2.4932983218844114
Validation loss: 2.823504791973297

Epoch: 6| Step: 2
Training loss: 2.7647218253185657
Validation loss: 2.8220996895196433

Epoch: 6| Step: 3
Training loss: 3.1650904363213344
Validation loss: 2.8207572454767402

Epoch: 6| Step: 4
Training loss: 3.9781976422002607
Validation loss: 2.81898239331357

Epoch: 6| Step: 5
Training loss: 3.5329323871015497
Validation loss: 2.8140156653229607

Epoch: 6| Step: 6
Training loss: 3.28375816759503
Validation loss: 2.8171783340646512

Epoch: 6| Step: 7
Training loss: 3.3136999008322827
Validation loss: 2.81495655295054

Epoch: 6| Step: 8
Training loss: 3.1534314553907237
Validation loss: 2.8123302248959448

Epoch: 6| Step: 9
Training loss: 3.0534220462166344
Validation loss: 2.816474787533104

Epoch: 6| Step: 10
Training loss: 2.5329691382514854
Validation loss: 2.8118553252246925

Epoch: 6| Step: 11
Training loss: 2.989505053480043
Validation loss: 2.8180256932998766

Epoch: 6| Step: 12
Training loss: 2.566878509036095
Validation loss: 2.8212620019675376

Epoch: 6| Step: 13
Training loss: 3.9495728708458566
Validation loss: 2.8244353017194337

Epoch: 25| Step: 0
Training loss: 3.6146272039178844
Validation loss: 2.822001814169411

Epoch: 6| Step: 1
Training loss: 3.0717325978922876
Validation loss: 2.8170264513856513

Epoch: 6| Step: 2
Training loss: 2.9920058232623057
Validation loss: 2.8060476160007193

Epoch: 6| Step: 3
Training loss: 2.3699837966558195
Validation loss: 2.8007350345793496

Epoch: 6| Step: 4
Training loss: 2.8826293887157934
Validation loss: 2.8054272629006642

Epoch: 6| Step: 5
Training loss: 3.5957622699338567
Validation loss: 2.8031796669079636

Epoch: 6| Step: 6
Training loss: 3.4059263303072878
Validation loss: 2.809110668844193

Epoch: 6| Step: 7
Training loss: 3.2618418413338155
Validation loss: 2.800182823505875

Epoch: 6| Step: 8
Training loss: 2.9228806014678415
Validation loss: 2.7865999069490432

Epoch: 6| Step: 9
Training loss: 3.476879045455639
Validation loss: 2.7821235165276237

Epoch: 6| Step: 10
Training loss: 2.98637027847947
Validation loss: 2.7778449927849307

Epoch: 6| Step: 11
Training loss: 3.05732351846474
Validation loss: 2.7769548702247344

Epoch: 6| Step: 12
Training loss: 2.919032871825755
Validation loss: 2.7772911169133834

Epoch: 6| Step: 13
Training loss: 2.7589020994541578
Validation loss: 2.7770520216524552

Epoch: 26| Step: 0
Training loss: 3.4592611761070433
Validation loss: 2.7803995081740336

Epoch: 6| Step: 1
Training loss: 3.162799347593009
Validation loss: 2.7829080367878287

Epoch: 6| Step: 2
Training loss: 3.360396544807546
Validation loss: 2.783247403402677

Epoch: 6| Step: 3
Training loss: 3.4391732045111425
Validation loss: 2.78447202802521

Epoch: 6| Step: 4
Training loss: 3.218038832236375
Validation loss: 2.776825855016676

Epoch: 6| Step: 5
Training loss: 2.3263374993514314
Validation loss: 2.774534289078628

Epoch: 6| Step: 6
Training loss: 3.3806836343152766
Validation loss: 2.7698473064524833

Epoch: 6| Step: 7
Training loss: 2.5888437955728376
Validation loss: 2.769598663975387

Epoch: 6| Step: 8
Training loss: 2.8406151900421057
Validation loss: 2.7681578994143727

Epoch: 6| Step: 9
Training loss: 3.322045733280008
Validation loss: 2.7663055948829203

Epoch: 6| Step: 10
Training loss: 3.2866544267015114
Validation loss: 2.7665884440419553

Epoch: 6| Step: 11
Training loss: 3.117723920744729
Validation loss: 2.764820571204796

Epoch: 6| Step: 12
Training loss: 3.028327555618555
Validation loss: 2.765743130964526

Epoch: 6| Step: 13
Training loss: 2.526142855056224
Validation loss: 2.7645202501057384

Epoch: 27| Step: 0
Training loss: 2.7119365687083747
Validation loss: 2.7630319565634776

Epoch: 6| Step: 1
Training loss: 2.8245121762551277
Validation loss: 2.764810427226451

Epoch: 6| Step: 2
Training loss: 3.3464281996715006
Validation loss: 2.770066332699761

Epoch: 6| Step: 3
Training loss: 2.9107680119362866
Validation loss: 2.7690934278986123

Epoch: 6| Step: 4
Training loss: 2.978804097198623
Validation loss: 2.7801180309559412

Epoch: 6| Step: 5
Training loss: 3.472518111443302
Validation loss: 2.7936486940602308

Epoch: 6| Step: 6
Training loss: 2.7845362418568653
Validation loss: 2.7779205513908805

Epoch: 6| Step: 7
Training loss: 2.8448511025025818
Validation loss: 2.7720184721513323

Epoch: 6| Step: 8
Training loss: 2.6734415559275284
Validation loss: 2.768979837623392

Epoch: 6| Step: 9
Training loss: 3.3332646044957164
Validation loss: 2.775710865013617

Epoch: 6| Step: 10
Training loss: 3.243747565648924
Validation loss: 2.7686042568953804

Epoch: 6| Step: 11
Training loss: 3.4380182049032397
Validation loss: 2.770235523763037

Epoch: 6| Step: 12
Training loss: 3.135833577333377
Validation loss: 2.7668216897869122

Epoch: 6| Step: 13
Training loss: 3.6972442158816228
Validation loss: 2.7605008286415758

Epoch: 28| Step: 0
Training loss: 3.1870971125878667
Validation loss: 2.755270630744188

Epoch: 6| Step: 1
Training loss: 3.329067902578075
Validation loss: 2.7570946136789205

Epoch: 6| Step: 2
Training loss: 3.541950319188375
Validation loss: 2.757841478021409

Epoch: 6| Step: 3
Training loss: 2.8063895074028378
Validation loss: 2.7528908610006346

Epoch: 6| Step: 4
Training loss: 2.9287251023436216
Validation loss: 2.7574001114196767

Epoch: 6| Step: 5
Training loss: 2.85721527416553
Validation loss: 2.7577126311858575

Epoch: 6| Step: 6
Training loss: 3.1645284427371765
Validation loss: 2.7587378280373134

Epoch: 6| Step: 7
Training loss: 3.3162014991270508
Validation loss: 2.7653464558324505

Epoch: 6| Step: 8
Training loss: 3.948716913744587
Validation loss: 2.7605534763219786

Epoch: 6| Step: 9
Training loss: 2.3006332686653144
Validation loss: 2.758917160290863

Epoch: 6| Step: 10
Training loss: 3.083256041786648
Validation loss: 2.764405514866443

Epoch: 6| Step: 11
Training loss: 2.732737372332471
Validation loss: 2.7619213743471493

Epoch: 6| Step: 12
Training loss: 2.890946653873432
Validation loss: 2.7735319175518707

Epoch: 6| Step: 13
Training loss: 2.4825774593504235
Validation loss: 2.786229168209941

Epoch: 29| Step: 0
Training loss: 3.094851981522965
Validation loss: 2.7963646167373937

Epoch: 6| Step: 1
Training loss: 3.3401424162876623
Validation loss: 2.7997687388575994

Epoch: 6| Step: 2
Training loss: 2.746195328680056
Validation loss: 2.791337772758276

Epoch: 6| Step: 3
Training loss: 3.6685347277830416
Validation loss: 2.7781436316909787

Epoch: 6| Step: 4
Training loss: 2.966194096619984
Validation loss: 2.7563417125283842

Epoch: 6| Step: 5
Training loss: 2.627303066840462
Validation loss: 2.7503330014179084

Epoch: 6| Step: 6
Training loss: 3.0431733950160957
Validation loss: 2.741716661685308

Epoch: 6| Step: 7
Training loss: 2.7791488082594116
Validation loss: 2.742298558811954

Epoch: 6| Step: 8
Training loss: 3.6887716913054094
Validation loss: 2.740231727377384

Epoch: 6| Step: 9
Training loss: 3.1207985672756524
Validation loss: 2.739460217174364

Epoch: 6| Step: 10
Training loss: 2.8182369636498756
Validation loss: 2.740031911494834

Epoch: 6| Step: 11
Training loss: 2.9984711884180975
Validation loss: 2.741719027359377

Epoch: 6| Step: 12
Training loss: 2.8464522046757463
Validation loss: 2.738102952782849

Epoch: 6| Step: 13
Training loss: 3.409681638919414
Validation loss: 2.738508284853247

Epoch: 30| Step: 0
Training loss: 3.945011784641084
Validation loss: 2.7359257233000442

Epoch: 6| Step: 1
Training loss: 3.49058219316509
Validation loss: 2.7368545282949714

Epoch: 6| Step: 2
Training loss: 3.883477812168178
Validation loss: 2.7363095576352077

Epoch: 6| Step: 3
Training loss: 2.975608853138295
Validation loss: 2.7337136992775335

Epoch: 6| Step: 4
Training loss: 3.1788004919700485
Validation loss: 2.7324235919606683

Epoch: 6| Step: 5
Training loss: 2.586594789070031
Validation loss: 2.7271554282628783

Epoch: 6| Step: 6
Training loss: 2.636885935816542
Validation loss: 2.7274836805737865

Epoch: 6| Step: 7
Training loss: 2.9731278114393764
Validation loss: 2.728496794945009

Epoch: 6| Step: 8
Training loss: 3.0831307696913504
Validation loss: 2.7271256282987317

Epoch: 6| Step: 9
Training loss: 2.7543351076204945
Validation loss: 2.727901246784857

Epoch: 6| Step: 10
Training loss: 2.8571271555332887
Validation loss: 2.730990355613746

Epoch: 6| Step: 11
Training loss: 2.6756571274530274
Validation loss: 2.7315719234742115

Epoch: 6| Step: 12
Training loss: 2.532524918097532
Validation loss: 2.74217353739884

Epoch: 6| Step: 13
Training loss: 2.9362171699699045
Validation loss: 2.7423428189768497

Epoch: 31| Step: 0
Training loss: 3.6009698409131414
Validation loss: 2.7573333745137916

Epoch: 6| Step: 1
Training loss: 3.465369974836742
Validation loss: 2.7583421474348553

Epoch: 6| Step: 2
Training loss: 3.001570290630344
Validation loss: 2.7385106205338414

Epoch: 6| Step: 3
Training loss: 2.3764473369918395
Validation loss: 2.7306992968680146

Epoch: 6| Step: 4
Training loss: 3.1756064729350935
Validation loss: 2.7239815356037895

Epoch: 6| Step: 5
Training loss: 2.8991676911998
Validation loss: 2.7285428424257883

Epoch: 6| Step: 6
Training loss: 3.0288272889682775
Validation loss: 2.7228027244087487

Epoch: 6| Step: 7
Training loss: 2.631118727646506
Validation loss: 2.7181323911356965

Epoch: 6| Step: 8
Training loss: 2.8273093380379417
Validation loss: 2.7183572534756233

Epoch: 6| Step: 9
Training loss: 2.59685248079417
Validation loss: 2.7192792385592455

Epoch: 6| Step: 10
Training loss: 3.2575134579196803
Validation loss: 2.71745280095906

Epoch: 6| Step: 11
Training loss: 3.4627094081531733
Validation loss: 2.718135665794044

Epoch: 6| Step: 12
Training loss: 3.399425424383124
Validation loss: 2.714131029092857

Epoch: 6| Step: 13
Training loss: 2.4659348867255333
Validation loss: 2.715095524988084

Epoch: 32| Step: 0
Training loss: 3.863407761649795
Validation loss: 2.726922806829657

Epoch: 6| Step: 1
Training loss: 3.1674459569305493
Validation loss: 2.706930276692536

Epoch: 6| Step: 2
Training loss: 3.4185982958175276
Validation loss: 2.7087433428134817

Epoch: 6| Step: 3
Training loss: 2.637682838791776
Validation loss: 2.709778342635752

Epoch: 6| Step: 4
Training loss: 3.412784572934507
Validation loss: 2.714252885030425

Epoch: 6| Step: 5
Training loss: 2.9234057002170473
Validation loss: 2.7159920219450284

Epoch: 6| Step: 6
Training loss: 3.3386515313141603
Validation loss: 2.725120748317212

Epoch: 6| Step: 7
Training loss: 3.174117474791129
Validation loss: 2.7198185191198

Epoch: 6| Step: 8
Training loss: 3.1709918216057305
Validation loss: 2.7236276864051847

Epoch: 6| Step: 9
Training loss: 2.650499109733992
Validation loss: 2.71182327478651

Epoch: 6| Step: 10
Training loss: 2.5506232827593727
Validation loss: 2.7143170609338374

Epoch: 6| Step: 11
Training loss: 2.075917383567669
Validation loss: 2.7070476866081066

Epoch: 6| Step: 12
Training loss: 2.7258355775701633
Validation loss: 2.7064544423555548

Epoch: 6| Step: 13
Training loss: 3.1529487492551613
Validation loss: 2.7097351012045423

Epoch: 33| Step: 0
Training loss: 3.0548963548525836
Validation loss: 2.714153788946779

Epoch: 6| Step: 1
Training loss: 2.4583654132193877
Validation loss: 2.711707281750426

Epoch: 6| Step: 2
Training loss: 3.722313463854617
Validation loss: 2.716106035821932

Epoch: 6| Step: 3
Training loss: 3.109798690070023
Validation loss: 2.718200109362134

Epoch: 6| Step: 4
Training loss: 3.008151107158032
Validation loss: 2.7113913645258347

Epoch: 6| Step: 5
Training loss: 2.366482972909752
Validation loss: 2.7024435853292466

Epoch: 6| Step: 6
Training loss: 2.5792300543650315
Validation loss: 2.7058895403505825

Epoch: 6| Step: 7
Training loss: 3.1705754065324325
Validation loss: 2.706861470552771

Epoch: 6| Step: 8
Training loss: 2.897856044797959
Validation loss: 2.707931251748716

Epoch: 6| Step: 9
Training loss: 3.037597617005405
Validation loss: 2.7066654821846203

Epoch: 6| Step: 10
Training loss: 3.336492344903932
Validation loss: 2.703717999103597

Epoch: 6| Step: 11
Training loss: 3.1999267986984967
Validation loss: 2.7003803088257023

Epoch: 6| Step: 12
Training loss: 3.0197149025953665
Validation loss: 2.698069947988343

Epoch: 6| Step: 13
Training loss: 3.4269350864305683
Validation loss: 2.7008193467891304

Epoch: 34| Step: 0
Training loss: 3.006936478304473
Validation loss: 2.699817501130584

Epoch: 6| Step: 1
Training loss: 3.2869376162048263
Validation loss: 2.695878942223982

Epoch: 6| Step: 2
Training loss: 2.6437572434057834
Validation loss: 2.6977297560216353

Epoch: 6| Step: 3
Training loss: 2.988948812281904
Validation loss: 2.698481883291272

Epoch: 6| Step: 4
Training loss: 2.8126600431894873
Validation loss: 2.692765848398396

Epoch: 6| Step: 5
Training loss: 2.7985972637362964
Validation loss: 2.6990791328500485

Epoch: 6| Step: 6
Training loss: 2.9310613640641625
Validation loss: 2.6966037182087867

Epoch: 6| Step: 7
Training loss: 2.278806867449662
Validation loss: 2.6959514966766576

Epoch: 6| Step: 8
Training loss: 3.5387822391789134
Validation loss: 2.6967659931897927

Epoch: 6| Step: 9
Training loss: 2.8676843862276185
Validation loss: 2.6964933966563844

Epoch: 6| Step: 10
Training loss: 3.41708149756463
Validation loss: 2.696508989555127

Epoch: 6| Step: 11
Training loss: 3.3806782745039676
Validation loss: 2.6988241899428562

Epoch: 6| Step: 12
Training loss: 2.94022648672052
Validation loss: 2.7017416927475115

Epoch: 6| Step: 13
Training loss: 3.5982201679970016
Validation loss: 2.7052524248541836

Epoch: 35| Step: 0
Training loss: 3.0605961078123736
Validation loss: 2.705627856087597

Epoch: 6| Step: 1
Training loss: 2.6227760885277602
Validation loss: 2.7076528064951395

Epoch: 6| Step: 2
Training loss: 2.46004060417098
Validation loss: 2.7150071613185065

Epoch: 6| Step: 3
Training loss: 2.6416660040083415
Validation loss: 2.725640091045942

Epoch: 6| Step: 4
Training loss: 3.1455014455849875
Validation loss: 2.7354056998453684

Epoch: 6| Step: 5
Training loss: 3.3053254938785375
Validation loss: 2.7245115081079936

Epoch: 6| Step: 6
Training loss: 3.1162693899249945
Validation loss: 2.699619571238138

Epoch: 6| Step: 7
Training loss: 2.0717921313806156
Validation loss: 2.6892759937241566

Epoch: 6| Step: 8
Training loss: 3.2101218122620434
Validation loss: 2.6873969019893718

Epoch: 6| Step: 9
Training loss: 3.0047303100011895
Validation loss: 2.6869511044968872

Epoch: 6| Step: 10
Training loss: 3.1457946134967516
Validation loss: 2.6851541240102437

Epoch: 6| Step: 11
Training loss: 3.6615334182499857
Validation loss: 2.688072122706201

Epoch: 6| Step: 12
Training loss: 3.36031026906298
Validation loss: 2.6861711590344424

Epoch: 6| Step: 13
Training loss: 3.14720898459257
Validation loss: 2.688544874167956

Epoch: 36| Step: 0
Training loss: 3.5519767737789114
Validation loss: 2.6904978857372246

Epoch: 6| Step: 1
Training loss: 2.804661317665918
Validation loss: 2.6873826151283553

Epoch: 6| Step: 2
Training loss: 3.3072658427674555
Validation loss: 2.6863952563913474

Epoch: 6| Step: 3
Training loss: 3.392104568767971
Validation loss: 2.68463950374126

Epoch: 6| Step: 4
Training loss: 2.7683056270247146
Validation loss: 2.683982924910441

Epoch: 6| Step: 5
Training loss: 2.583778332765772
Validation loss: 2.6813721503697376

Epoch: 6| Step: 6
Training loss: 2.6824641397573212
Validation loss: 2.6822240132585966

Epoch: 6| Step: 7
Training loss: 2.808916224614589
Validation loss: 2.681153032671256

Epoch: 6| Step: 8
Training loss: 3.84203318890639
Validation loss: 2.6806155409227257

Epoch: 6| Step: 9
Training loss: 2.5303064165281324
Validation loss: 2.678714398164016

Epoch: 6| Step: 10
Training loss: 2.9617477556446983
Validation loss: 2.6791529437239494

Epoch: 6| Step: 11
Training loss: 3.0325976649923883
Validation loss: 2.6821703442045592

Epoch: 6| Step: 12
Training loss: 2.796599646285468
Validation loss: 2.6826483988172436

Epoch: 6| Step: 13
Training loss: 2.911006685459607
Validation loss: 2.6916130245218426

Epoch: 37| Step: 0
Training loss: 3.52561785105667
Validation loss: 2.696710543495411

Epoch: 6| Step: 1
Training loss: 2.632881412679584
Validation loss: 2.6975142412844604

Epoch: 6| Step: 2
Training loss: 2.752146316797139
Validation loss: 2.7025588698958583

Epoch: 6| Step: 3
Training loss: 3.1475157796571755
Validation loss: 2.695888075112916

Epoch: 6| Step: 4
Training loss: 3.0411166037746575
Validation loss: 2.6900616490282427

Epoch: 6| Step: 5
Training loss: 3.0960675431210127
Validation loss: 2.684118375039076

Epoch: 6| Step: 6
Training loss: 2.345793278444222
Validation loss: 2.6790650897363304

Epoch: 6| Step: 7
Training loss: 3.3746320735867013
Validation loss: 2.677285243083142

Epoch: 6| Step: 8
Training loss: 2.9689946124039848
Validation loss: 2.6761723254666845

Epoch: 6| Step: 9
Training loss: 2.752047989931407
Validation loss: 2.675912217768234

Epoch: 6| Step: 10
Training loss: 3.243594533028125
Validation loss: 2.677329342791001

Epoch: 6| Step: 11
Training loss: 3.4192029021876027
Validation loss: 2.675153195864208

Epoch: 6| Step: 12
Training loss: 2.747487741291998
Validation loss: 2.674314741614006

Epoch: 6| Step: 13
Training loss: 2.7510114890343647
Validation loss: 2.674718953640229

Epoch: 38| Step: 0
Training loss: 2.44980216492635
Validation loss: 2.682460005380361

Epoch: 6| Step: 1
Training loss: 3.5602503583506233
Validation loss: 2.6991644177831136

Epoch: 6| Step: 2
Training loss: 2.620952392040957
Validation loss: 2.719659240482103

Epoch: 6| Step: 3
Training loss: 3.1450625521650997
Validation loss: 2.699822790178583

Epoch: 6| Step: 4
Training loss: 3.461956623283865
Validation loss: 2.6811048326167115

Epoch: 6| Step: 5
Training loss: 2.942131449549912
Validation loss: 2.6803393808020957

Epoch: 6| Step: 6
Training loss: 3.1246508594023847
Validation loss: 2.6743620383457096

Epoch: 6| Step: 7
Training loss: 3.147949938258507
Validation loss: 2.678052375786977

Epoch: 6| Step: 8
Training loss: 2.683518943132665
Validation loss: 2.678655126976

Epoch: 6| Step: 9
Training loss: 3.2854357950882958
Validation loss: 2.6855934765781946

Epoch: 6| Step: 10
Training loss: 2.2675537318347745
Validation loss: 2.6821176958559136

Epoch: 6| Step: 11
Training loss: 3.3147477495010484
Validation loss: 2.679147928686201

Epoch: 6| Step: 12
Training loss: 2.8217056510862486
Validation loss: 2.6717979124028837

Epoch: 6| Step: 13
Training loss: 2.9903252685605946
Validation loss: 2.683127832030734

Epoch: 39| Step: 0
Training loss: 2.7546383148493354
Validation loss: 2.684020332645508

Epoch: 6| Step: 1
Training loss: 2.267090842817597
Validation loss: 2.6792288312661436

Epoch: 6| Step: 2
Training loss: 3.393005941469548
Validation loss: 2.680012904449713

Epoch: 6| Step: 3
Training loss: 2.0073875838522564
Validation loss: 2.6871935666620907

Epoch: 6| Step: 4
Training loss: 2.701811190047343
Validation loss: 2.6943688713111715

Epoch: 6| Step: 5
Training loss: 2.9749834973815203
Validation loss: 2.6903435920461813

Epoch: 6| Step: 6
Training loss: 3.0753340873042
Validation loss: 2.677260202015904

Epoch: 6| Step: 7
Training loss: 2.776313944925641
Validation loss: 2.6722423351569797

Epoch: 6| Step: 8
Training loss: 3.2498154220986093
Validation loss: 2.6702711953730875

Epoch: 6| Step: 9
Training loss: 3.460153736381453
Validation loss: 2.6681990572340006

Epoch: 6| Step: 10
Training loss: 3.3218746325258497
Validation loss: 2.668136294261825

Epoch: 6| Step: 11
Training loss: 3.084970211583876
Validation loss: 2.666707519889989

Epoch: 6| Step: 12
Training loss: 3.2176485121330196
Validation loss: 2.6647713434808713

Epoch: 6| Step: 13
Training loss: 3.4872591543950544
Validation loss: 2.66436421797425

Epoch: 40| Step: 0
Training loss: 2.2325929591186022
Validation loss: 2.660265924637308

Epoch: 6| Step: 1
Training loss: 1.9187268780734796
Validation loss: 2.6593933905339444

Epoch: 6| Step: 2
Training loss: 3.887507771671291
Validation loss: 2.657688031017794

Epoch: 6| Step: 3
Training loss: 2.9828239524625446
Validation loss: 2.660115538382506

Epoch: 6| Step: 4
Training loss: 2.4365889974271027
Validation loss: 2.658220572376423

Epoch: 6| Step: 5
Training loss: 2.918465323114894
Validation loss: 2.6561838816183734

Epoch: 6| Step: 6
Training loss: 3.256079343105544
Validation loss: 2.6588353989632094

Epoch: 6| Step: 7
Training loss: 3.238713252905527
Validation loss: 2.659042756830675

Epoch: 6| Step: 8
Training loss: 2.786942560540923
Validation loss: 2.663367321006944

Epoch: 6| Step: 9
Training loss: 3.1144692560608527
Validation loss: 2.6637449743199086

Epoch: 6| Step: 10
Training loss: 3.6253435695550915
Validation loss: 2.6645933199853333

Epoch: 6| Step: 11
Training loss: 2.4382416012714274
Validation loss: 2.668945995447024

Epoch: 6| Step: 12
Training loss: 2.7724938734999887
Validation loss: 2.6681065485440487

Epoch: 6| Step: 13
Training loss: 4.0381528911090845
Validation loss: 2.6736391853279455

Epoch: 41| Step: 0
Training loss: 1.8338208922950192
Validation loss: 2.6739573246325326

Epoch: 6| Step: 1
Training loss: 3.163766804759393
Validation loss: 2.6812986994457275

Epoch: 6| Step: 2
Training loss: 2.7884999624180153
Validation loss: 2.681965855564103

Epoch: 6| Step: 3
Training loss: 2.9552475501869115
Validation loss: 2.6916025513048476

Epoch: 6| Step: 4
Training loss: 3.548270064602606
Validation loss: 2.7039937322139456

Epoch: 6| Step: 5
Training loss: 2.9741380484684394
Validation loss: 2.7067983822780532

Epoch: 6| Step: 6
Training loss: 2.927224387755741
Validation loss: 2.6757748652771913

Epoch: 6| Step: 7
Training loss: 3.2953030422865406
Validation loss: 2.658634005331396

Epoch: 6| Step: 8
Training loss: 3.32638834026618
Validation loss: 2.6490465560651777

Epoch: 6| Step: 9
Training loss: 2.5862443171457623
Validation loss: 2.651627433787592

Epoch: 6| Step: 10
Training loss: 2.633411373318002
Validation loss: 2.6522315033278345

Epoch: 6| Step: 11
Training loss: 3.0119093699808626
Validation loss: 2.654551837268351

Epoch: 6| Step: 12
Training loss: 3.506254194124539
Validation loss: 2.6555857002042322

Epoch: 6| Step: 13
Training loss: 2.894821831947642
Validation loss: 2.6563551494095203

Epoch: 42| Step: 0
Training loss: 2.4975661828605373
Validation loss: 2.6590895606673834

Epoch: 6| Step: 1
Training loss: 3.3152097738644777
Validation loss: 2.6546595734888663

Epoch: 6| Step: 2
Training loss: 2.1419653490043786
Validation loss: 2.6555095038566603

Epoch: 6| Step: 3
Training loss: 2.5536229893435918
Validation loss: 2.656076887691927

Epoch: 6| Step: 4
Training loss: 2.913458958528049
Validation loss: 2.655219877353256

Epoch: 6| Step: 5
Training loss: 2.7572338156305127
Validation loss: 2.6550305718011167

Epoch: 6| Step: 6
Training loss: 3.0012183894185185
Validation loss: 2.6536422543175155

Epoch: 6| Step: 7
Training loss: 3.3281628243889347
Validation loss: 2.652998309389469

Epoch: 6| Step: 8
Training loss: 3.204509603323187
Validation loss: 2.6486743382245925

Epoch: 6| Step: 9
Training loss: 3.191177938972315
Validation loss: 2.6508561219760858

Epoch: 6| Step: 10
Training loss: 3.302782018894231
Validation loss: 2.645536021519332

Epoch: 6| Step: 11
Training loss: 2.8805713574245724
Validation loss: 2.646922997445565

Epoch: 6| Step: 12
Training loss: 3.5268546237387364
Validation loss: 2.645718073415579

Epoch: 6| Step: 13
Training loss: 3.16442959386696
Validation loss: 2.6442923508591245

Epoch: 43| Step: 0
Training loss: 3.697000710678961
Validation loss: 2.6442575019628456

Epoch: 6| Step: 1
Training loss: 2.965312694509755
Validation loss: 2.6500868261256345

Epoch: 6| Step: 2
Training loss: 2.919516197780304
Validation loss: 2.6581609638115826

Epoch: 6| Step: 3
Training loss: 3.259537128282084
Validation loss: 2.6656918976087836

Epoch: 6| Step: 4
Training loss: 2.479878224644049
Validation loss: 2.7008157530834223

Epoch: 6| Step: 5
Training loss: 2.844069578218344
Validation loss: 2.7478644654811553

Epoch: 6| Step: 6
Training loss: 3.3404918733340074
Validation loss: 2.7596358851440472

Epoch: 6| Step: 7
Training loss: 2.6219660164604326
Validation loss: 2.731485385203327

Epoch: 6| Step: 8
Training loss: 3.0539072118227253
Validation loss: 2.7089100393290257

Epoch: 6| Step: 9
Training loss: 2.178031045865823
Validation loss: 2.669953407556105

Epoch: 6| Step: 10
Training loss: 3.4632089708437204
Validation loss: 2.6539349016569753

Epoch: 6| Step: 11
Training loss: 3.048894281543205
Validation loss: 2.6450381482149976

Epoch: 6| Step: 12
Training loss: 2.7157641270932107
Validation loss: 2.6453486880346335

Epoch: 6| Step: 13
Training loss: 2.8892886810314446
Validation loss: 2.6436101509868952

Epoch: 44| Step: 0
Training loss: 2.7494498482844167
Validation loss: 2.642916090374351

Epoch: 6| Step: 1
Training loss: 3.065721335729914
Validation loss: 2.6423520549918145

Epoch: 6| Step: 2
Training loss: 2.779757838782535
Validation loss: 2.6445592464737238

Epoch: 6| Step: 3
Training loss: 3.4279672396862697
Validation loss: 2.6425634168392564

Epoch: 6| Step: 4
Training loss: 2.7726178744603627
Validation loss: 2.6445792563063835

Epoch: 6| Step: 5
Training loss: 2.9681524378041924
Validation loss: 2.638628709967302

Epoch: 6| Step: 6
Training loss: 3.1697720476375544
Validation loss: 2.6351281515243294

Epoch: 6| Step: 7
Training loss: 2.6239858212204235
Validation loss: 2.635346210638299

Epoch: 6| Step: 8
Training loss: 3.265221675807492
Validation loss: 2.631742376602426

Epoch: 6| Step: 9
Training loss: 2.9216567993287583
Validation loss: 2.6302088356240954

Epoch: 6| Step: 10
Training loss: 2.8189946104433217
Validation loss: 2.630200677448552

Epoch: 6| Step: 11
Training loss: 2.9327332800447987
Validation loss: 2.626943904691118

Epoch: 6| Step: 12
Training loss: 2.901581326507313
Validation loss: 2.6286748417869314

Epoch: 6| Step: 13
Training loss: 3.4724678529112336
Validation loss: 2.6266801362821597

Epoch: 45| Step: 0
Training loss: 2.458903898417511
Validation loss: 2.6307531168889713

Epoch: 6| Step: 1
Training loss: 3.034502624279276
Validation loss: 2.62992930865926

Epoch: 6| Step: 2
Training loss: 2.863563013719957
Validation loss: 2.6299467710700273

Epoch: 6| Step: 3
Training loss: 2.7005292303138098
Validation loss: 2.6302793321232687

Epoch: 6| Step: 4
Training loss: 2.945986561834552
Validation loss: 2.6256031441183785

Epoch: 6| Step: 5
Training loss: 3.749843848474154
Validation loss: 2.631036685774098

Epoch: 6| Step: 6
Training loss: 2.589645631326728
Validation loss: 2.624595308140759

Epoch: 6| Step: 7
Training loss: 3.0407973488619238
Validation loss: 2.627109126588381

Epoch: 6| Step: 8
Training loss: 2.696020857014333
Validation loss: 2.626907208555998

Epoch: 6| Step: 9
Training loss: 3.132990273166805
Validation loss: 2.629925649278147

Epoch: 6| Step: 10
Training loss: 2.742701381776439
Validation loss: 2.6227891805019943

Epoch: 6| Step: 11
Training loss: 2.9778290704639834
Validation loss: 2.624361707722892

Epoch: 6| Step: 12
Training loss: 3.5313501934589797
Validation loss: 2.6261509219522634

Epoch: 6| Step: 13
Training loss: 2.660220959026202
Validation loss: 2.624660877290422

Epoch: 46| Step: 0
Training loss: 2.700748082123633
Validation loss: 2.6251929163910135

Epoch: 6| Step: 1
Training loss: 3.3078814283567333
Validation loss: 2.6233036710053974

Epoch: 6| Step: 2
Training loss: 3.052555364533138
Validation loss: 2.6222780836275077

Epoch: 6| Step: 3
Training loss: 3.239060992522563
Validation loss: 2.624805091618399

Epoch: 6| Step: 4
Training loss: 2.537268841366709
Validation loss: 2.626436546541154

Epoch: 6| Step: 5
Training loss: 2.628038736531105
Validation loss: 2.625144975978409

Epoch: 6| Step: 6
Training loss: 3.032400797631003
Validation loss: 2.6282834009389022

Epoch: 6| Step: 7
Training loss: 3.1154795774385238
Validation loss: 2.6297567322016167

Epoch: 6| Step: 8
Training loss: 3.1816888832474293
Validation loss: 2.6350984583511026

Epoch: 6| Step: 9
Training loss: 3.1655007943342337
Validation loss: 2.6284849372349206

Epoch: 6| Step: 10
Training loss: 2.8256815265485136
Validation loss: 2.631104453324031

Epoch: 6| Step: 11
Training loss: 2.9838930709539038
Validation loss: 2.622110386825578

Epoch: 6| Step: 12
Training loss: 2.779194533071593
Validation loss: 2.6225526136779034

Epoch: 6| Step: 13
Training loss: 2.4391376178324964
Validation loss: 2.6247279509143584

Epoch: 47| Step: 0
Training loss: 2.7212537439729716
Validation loss: 2.633938096186719

Epoch: 6| Step: 1
Training loss: 3.2048174596927
Validation loss: 2.6430025706852125

Epoch: 6| Step: 2
Training loss: 2.5036776195772923
Validation loss: 2.6255168513394516

Epoch: 6| Step: 3
Training loss: 3.1032633309778275
Validation loss: 2.616024984920428

Epoch: 6| Step: 4
Training loss: 3.2101408255515906
Validation loss: 2.6112951128618147

Epoch: 6| Step: 5
Training loss: 2.809519566093239
Validation loss: 2.6096226363031603

Epoch: 6| Step: 6
Training loss: 3.244284078330411
Validation loss: 2.6112857017832676

Epoch: 6| Step: 7
Training loss: 2.9930163796662046
Validation loss: 2.608340987851778

Epoch: 6| Step: 8
Training loss: 2.7129959953832548
Validation loss: 2.6060505956344437

Epoch: 6| Step: 9
Training loss: 3.2043535063149036
Validation loss: 2.610616073323086

Epoch: 6| Step: 10
Training loss: 3.1121142412609437
Validation loss: 2.6131245769247244

Epoch: 6| Step: 11
Training loss: 2.7327180910460953
Validation loss: 2.614943859222623

Epoch: 6| Step: 12
Training loss: 2.5971111901723907
Validation loss: 2.615985598424877

Epoch: 6| Step: 13
Training loss: 3.2081647721305027
Validation loss: 2.6213962821757075

Epoch: 48| Step: 0
Training loss: 3.216333760113417
Validation loss: 2.6267461530897345

Epoch: 6| Step: 1
Training loss: 2.7794146536281663
Validation loss: 2.625063504272734

Epoch: 6| Step: 2
Training loss: 3.213607235099961
Validation loss: 2.6226102779160647

Epoch: 6| Step: 3
Training loss: 2.755817588743489
Validation loss: 2.621213339128395

Epoch: 6| Step: 4
Training loss: 2.9261388012706706
Validation loss: 2.617471546376089

Epoch: 6| Step: 5
Training loss: 2.9324349096803015
Validation loss: 2.619067120243073

Epoch: 6| Step: 6
Training loss: 2.636885664566366
Validation loss: 2.608608446418043

Epoch: 6| Step: 7
Training loss: 2.617237785197894
Validation loss: 2.6063872237401564

Epoch: 6| Step: 8
Training loss: 2.8831652913895076
Validation loss: 2.602764553185996

Epoch: 6| Step: 9
Training loss: 2.8346223330016915
Validation loss: 2.6031781026206224

Epoch: 6| Step: 10
Training loss: 3.382503363247459
Validation loss: 2.6040349665328457

Epoch: 6| Step: 11
Training loss: 3.284599701574754
Validation loss: 2.6008242677811455

Epoch: 6| Step: 12
Training loss: 2.8505958068195887
Validation loss: 2.603870024162247

Epoch: 6| Step: 13
Training loss: 2.7055690939545167
Validation loss: 2.603115156625574

Epoch: 49| Step: 0
Training loss: 2.783276537546053
Validation loss: 2.601026438479261

Epoch: 6| Step: 1
Training loss: 2.8057666285801384
Validation loss: 2.609990158994449

Epoch: 6| Step: 2
Training loss: 2.6202739678622335
Validation loss: 2.615514370743846

Epoch: 6| Step: 3
Training loss: 3.000286724375988
Validation loss: 2.658992818717825

Epoch: 6| Step: 4
Training loss: 3.0701314081653446
Validation loss: 2.718562237426696

Epoch: 6| Step: 5
Training loss: 3.1131303815291615
Validation loss: 2.731273127211751

Epoch: 6| Step: 6
Training loss: 3.238615195951994
Validation loss: 2.6580478189183685

Epoch: 6| Step: 7
Training loss: 3.2949832352022175
Validation loss: 2.6120236959939267

Epoch: 6| Step: 8
Training loss: 2.6817903414370043
Validation loss: 2.6069957370642722

Epoch: 6| Step: 9
Training loss: 3.4161057981058693
Validation loss: 2.619826081975715

Epoch: 6| Step: 10
Training loss: 2.7665332229635315
Validation loss: 2.6184740665993624

Epoch: 6| Step: 11
Training loss: 2.445337362437255
Validation loss: 2.642760881208733

Epoch: 6| Step: 12
Training loss: 3.2348527785796484
Validation loss: 2.624283172661005

Epoch: 6| Step: 13
Training loss: 2.601837418610329
Validation loss: 2.602753892852012

Epoch: 50| Step: 0
Training loss: 3.36006618752457
Validation loss: 2.5996339900247603

Epoch: 6| Step: 1
Training loss: 3.326378305763889
Validation loss: 2.596208941049145

Epoch: 6| Step: 2
Training loss: 3.2143647774554753
Validation loss: 2.592440203658422

Epoch: 6| Step: 3
Training loss: 2.9219817279763967
Validation loss: 2.5944001338919738

Epoch: 6| Step: 4
Training loss: 2.8800551711202145
Validation loss: 2.5957212156828025

Epoch: 6| Step: 5
Training loss: 3.216503062724276
Validation loss: 2.6040831124632478

Epoch: 6| Step: 6
Training loss: 2.6597273560671706
Validation loss: 2.6051725476967795

Epoch: 6| Step: 7
Training loss: 2.5431253177007935
Validation loss: 2.603719037049357

Epoch: 6| Step: 8
Training loss: 2.715784231067626
Validation loss: 2.6141652915870663

Epoch: 6| Step: 9
Training loss: 2.9801081168000234
Validation loss: 2.621864204756563

Epoch: 6| Step: 10
Training loss: 2.962414858596546
Validation loss: 2.6284010867635854

Epoch: 6| Step: 11
Training loss: 2.8384595013313545
Validation loss: 2.627379577717753

Epoch: 6| Step: 12
Training loss: 2.554620771090718
Validation loss: 2.6136075038792734

Epoch: 6| Step: 13
Training loss: 2.687612930409138
Validation loss: 2.6117853187557145

Epoch: 51| Step: 0
Training loss: 3.166682460812449
Validation loss: 2.6098307078441754

Epoch: 6| Step: 1
Training loss: 2.2897900151091273
Validation loss: 2.6222444223320815

Epoch: 6| Step: 2
Training loss: 3.1848744069104153
Validation loss: 2.6261468033739166

Epoch: 6| Step: 3
Training loss: 2.4310544207439397
Validation loss: 2.6264147718165978

Epoch: 6| Step: 4
Training loss: 2.9922420008703274
Validation loss: 2.62989485139741

Epoch: 6| Step: 5
Training loss: 3.5862037044607065
Validation loss: 2.615116345645457

Epoch: 6| Step: 6
Training loss: 3.3628288079915563
Validation loss: 2.60896299637975

Epoch: 6| Step: 7
Training loss: 3.118949067331324
Validation loss: 2.593337907806347

Epoch: 6| Step: 8
Training loss: 2.586638756024641
Validation loss: 2.5887038040081727

Epoch: 6| Step: 9
Training loss: 3.166162166228067
Validation loss: 2.5891788061930505

Epoch: 6| Step: 10
Training loss: 2.228176883558904
Validation loss: 2.5876450838639578

Epoch: 6| Step: 11
Training loss: 2.6627060465714196
Validation loss: 2.590726411319108

Epoch: 6| Step: 12
Training loss: 3.02105350788187
Validation loss: 2.5939143484970484

Epoch: 6| Step: 13
Training loss: 3.02624806911024
Validation loss: 2.593713539955497

Epoch: 52| Step: 0
Training loss: 2.7842195923459987
Validation loss: 2.591568626175901

Epoch: 6| Step: 1
Training loss: 3.0502907411174234
Validation loss: 2.5891215588338112

Epoch: 6| Step: 2
Training loss: 2.9240551327205604
Validation loss: 2.587182128905114

Epoch: 6| Step: 3
Training loss: 2.433184691901452
Validation loss: 2.5912075764833635

Epoch: 6| Step: 4
Training loss: 3.1996062513337824
Validation loss: 2.587730506591755

Epoch: 6| Step: 5
Training loss: 2.6429568496512865
Validation loss: 2.591933352447462

Epoch: 6| Step: 6
Training loss: 3.031930119617558
Validation loss: 2.5981812088459204

Epoch: 6| Step: 7
Training loss: 2.6609537102860155
Validation loss: 2.6022251562194563

Epoch: 6| Step: 8
Training loss: 3.38372128021036
Validation loss: 2.607541747051356

Epoch: 6| Step: 9
Training loss: 2.7026703733366415
Validation loss: 2.609633277419757

Epoch: 6| Step: 10
Training loss: 3.201942039322566
Validation loss: 2.6066767586352544

Epoch: 6| Step: 11
Training loss: 3.0876747359896175
Validation loss: 2.5950057657622607

Epoch: 6| Step: 12
Training loss: 3.0008025685302675
Validation loss: 2.600048570321252

Epoch: 6| Step: 13
Training loss: 2.7647520939923984
Validation loss: 2.5892456177668572

Epoch: 53| Step: 0
Training loss: 2.5550266239100443
Validation loss: 2.5849344397295417

Epoch: 6| Step: 1
Training loss: 2.6801405098363444
Validation loss: 2.587441553525098

Epoch: 6| Step: 2
Training loss: 2.6930111112878867
Validation loss: 2.5846333171926568

Epoch: 6| Step: 3
Training loss: 3.1918686493257113
Validation loss: 2.5880500688306682

Epoch: 6| Step: 4
Training loss: 3.0766725163044257
Validation loss: 2.585492185377991

Epoch: 6| Step: 5
Training loss: 2.2803434896225747
Validation loss: 2.584099210155055

Epoch: 6| Step: 6
Training loss: 3.3752565639605225
Validation loss: 2.5802138074440184

Epoch: 6| Step: 7
Training loss: 2.5446053906122863
Validation loss: 2.5853260887452474

Epoch: 6| Step: 8
Training loss: 2.6012771037503106
Validation loss: 2.5819186115522803

Epoch: 6| Step: 9
Training loss: 2.870411237701481
Validation loss: 2.5837403686968785

Epoch: 6| Step: 10
Training loss: 3.5408718039946345
Validation loss: 2.5896609558325747

Epoch: 6| Step: 11
Training loss: 3.449482234857665
Validation loss: 2.592607631332909

Epoch: 6| Step: 12
Training loss: 3.146643797365695
Validation loss: 2.583698535341965

Epoch: 6| Step: 13
Training loss: 2.44733226103912
Validation loss: 2.582466923617881

Epoch: 54| Step: 0
Training loss: 3.0272649939352614
Validation loss: 2.5835242807857743

Epoch: 6| Step: 1
Training loss: 3.2062588875630658
Validation loss: 2.5857423647320483

Epoch: 6| Step: 2
Training loss: 3.114382291873707
Validation loss: 2.5969636640098113

Epoch: 6| Step: 3
Training loss: 3.255192350221178
Validation loss: 2.5998855621246926

Epoch: 6| Step: 4
Training loss: 3.126853240762991
Validation loss: 2.595898864487265

Epoch: 6| Step: 5
Training loss: 2.434935663614873
Validation loss: 2.613633258771854

Epoch: 6| Step: 6
Training loss: 3.2282222884548637
Validation loss: 2.6021099318347494

Epoch: 6| Step: 7
Training loss: 2.856557155930057
Validation loss: 2.5873624764594028

Epoch: 6| Step: 8
Training loss: 3.2938267505252283
Validation loss: 2.578998372744969

Epoch: 6| Step: 9
Training loss: 2.2784798930463173
Validation loss: 2.571224798421524

Epoch: 6| Step: 10
Training loss: 3.024409174953671
Validation loss: 2.5718362575871434

Epoch: 6| Step: 11
Training loss: 2.8043035812924755
Validation loss: 2.5722354802403524

Epoch: 6| Step: 12
Training loss: 2.4678568129650666
Validation loss: 2.5729904260550316

Epoch: 6| Step: 13
Training loss: 2.331456201346881
Validation loss: 2.5749904795270657

Epoch: 55| Step: 0
Training loss: 2.911123148413597
Validation loss: 2.5719394346673337

Epoch: 6| Step: 1
Training loss: 2.6450696929518718
Validation loss: 2.571041764367543

Epoch: 6| Step: 2
Training loss: 3.040033415811492
Validation loss: 2.5741760876786333

Epoch: 6| Step: 3
Training loss: 3.273508439854454
Validation loss: 2.574612565785984

Epoch: 6| Step: 4
Training loss: 3.113581739831211
Validation loss: 2.5743683035487432

Epoch: 6| Step: 5
Training loss: 3.1411223515943383
Validation loss: 2.5827298026677963

Epoch: 6| Step: 6
Training loss: 3.07513375340299
Validation loss: 2.581663485826248

Epoch: 6| Step: 7
Training loss: 1.900463514508186
Validation loss: 2.573226878789699

Epoch: 6| Step: 8
Training loss: 3.386005401282557
Validation loss: 2.5759422590943144

Epoch: 6| Step: 9
Training loss: 3.220880488502456
Validation loss: 2.5715441358186855

Epoch: 6| Step: 10
Training loss: 2.369711358243176
Validation loss: 2.5815335102826182

Epoch: 6| Step: 11
Training loss: 2.7558174157141946
Validation loss: 2.586486693648653

Epoch: 6| Step: 12
Training loss: 3.060183368998023
Validation loss: 2.595585770028443

Epoch: 6| Step: 13
Training loss: 2.529306018474062
Validation loss: 2.585113805627349

Epoch: 56| Step: 0
Training loss: 3.313860056232013
Validation loss: 2.5842835598641964

Epoch: 6| Step: 1
Training loss: 2.865543902631777
Validation loss: 2.58401904762136

Epoch: 6| Step: 2
Training loss: 3.066073920835064
Validation loss: 2.583500949636444

Epoch: 6| Step: 3
Training loss: 2.4837497908155854
Validation loss: 2.586509100867274

Epoch: 6| Step: 4
Training loss: 2.566574578883249
Validation loss: 2.585896006051344

Epoch: 6| Step: 5
Training loss: 2.9541207708569726
Validation loss: 2.5801042314781837

Epoch: 6| Step: 6
Training loss: 2.965213636964763
Validation loss: 2.5855193407713717

Epoch: 6| Step: 7
Training loss: 3.063598591469006
Validation loss: 2.5961554105380173

Epoch: 6| Step: 8
Training loss: 2.986896667848879
Validation loss: 2.5916573129983753

Epoch: 6| Step: 9
Training loss: 2.5205051639370044
Validation loss: 2.59035011441301

Epoch: 6| Step: 10
Training loss: 2.9205415508316737
Validation loss: 2.5941482675046665

Epoch: 6| Step: 11
Training loss: 3.247905202816414
Validation loss: 2.5769827710424273

Epoch: 6| Step: 12
Training loss: 2.534142807414685
Validation loss: 2.568113621564505

Epoch: 6| Step: 13
Training loss: 3.3365833809665375
Validation loss: 2.5660437344449454

Epoch: 57| Step: 0
Training loss: 3.5150942253408943
Validation loss: 2.5699536906901663

Epoch: 6| Step: 1
Training loss: 2.5338816208379606
Validation loss: 2.5656316126330188

Epoch: 6| Step: 2
Training loss: 2.9359456271819893
Validation loss: 2.5673195211059356

Epoch: 6| Step: 3
Training loss: 2.934144558861639
Validation loss: 2.5660505590386413

Epoch: 6| Step: 4
Training loss: 2.757250244920917
Validation loss: 2.5664079941178803

Epoch: 6| Step: 5
Training loss: 3.1364063378142424
Validation loss: 2.57254330873535

Epoch: 6| Step: 6
Training loss: 3.020154960143
Validation loss: 2.5700314191028726

Epoch: 6| Step: 7
Training loss: 2.706888830889024
Validation loss: 2.5798915584344235

Epoch: 6| Step: 8
Training loss: 3.258568545646202
Validation loss: 2.580247787547589

Epoch: 6| Step: 9
Training loss: 2.7403490473489236
Validation loss: 2.602346343406205

Epoch: 6| Step: 10
Training loss: 2.5987849257316316
Validation loss: 2.623934039578445

Epoch: 6| Step: 11
Training loss: 2.7953856354683277
Validation loss: 2.646994220699456

Epoch: 6| Step: 12
Training loss: 2.929649088289855
Validation loss: 2.616745305987721

Epoch: 6| Step: 13
Training loss: 2.989332305967011
Validation loss: 2.595992881746372

Epoch: 58| Step: 0
Training loss: 2.4707756906339626
Validation loss: 2.5760065706886177

Epoch: 6| Step: 1
Training loss: 3.3877573851602785
Validation loss: 2.573970532181826

Epoch: 6| Step: 2
Training loss: 3.0671814928661565
Validation loss: 2.5714401901675705

Epoch: 6| Step: 3
Training loss: 2.5524713545638744
Validation loss: 2.572326531366046

Epoch: 6| Step: 4
Training loss: 2.6023758083763497
Validation loss: 2.576252306583543

Epoch: 6| Step: 5
Training loss: 2.959665956464097
Validation loss: 2.5782803316826253

Epoch: 6| Step: 6
Training loss: 2.838424894864943
Validation loss: 2.568646893658691

Epoch: 6| Step: 7
Training loss: 3.170707901333873
Validation loss: 2.567377197689857

Epoch: 6| Step: 8
Training loss: 3.3032585643950902
Validation loss: 2.563423404546767

Epoch: 6| Step: 9
Training loss: 2.721473119347508
Validation loss: 2.564245009510253

Epoch: 6| Step: 10
Training loss: 3.216122934772143
Validation loss: 2.562107732458385

Epoch: 6| Step: 11
Training loss: 3.407860611370894
Validation loss: 2.5648582046157107

Epoch: 6| Step: 12
Training loss: 2.37987840454044
Validation loss: 2.5670156621431652

Epoch: 6| Step: 13
Training loss: 2.2717909470741917
Validation loss: 2.5814067895950368

Epoch: 59| Step: 0
Training loss: 2.9465674198347043
Validation loss: 2.5892435910087936

Epoch: 6| Step: 1
Training loss: 3.831625074039449
Validation loss: 2.6282926087454874

Epoch: 6| Step: 2
Training loss: 2.810102755069478
Validation loss: 2.632733182898153

Epoch: 6| Step: 3
Training loss: 2.66620628038519
Validation loss: 2.6234403714616095

Epoch: 6| Step: 4
Training loss: 3.1564595370092827
Validation loss: 2.6062525094500892

Epoch: 6| Step: 5
Training loss: 3.078962802633777
Validation loss: 2.5888536892885923

Epoch: 6| Step: 6
Training loss: 3.160266247168223
Validation loss: 2.567477796091727

Epoch: 6| Step: 7
Training loss: 2.791898765215165
Validation loss: 2.5651326775651597

Epoch: 6| Step: 8
Training loss: 2.819235302748024
Validation loss: 2.5663709278616214

Epoch: 6| Step: 9
Training loss: 2.364146378485789
Validation loss: 2.56806011336607

Epoch: 6| Step: 10
Training loss: 2.73015630896374
Validation loss: 2.558888938124562

Epoch: 6| Step: 11
Training loss: 2.5885181285215233
Validation loss: 2.565812261972137

Epoch: 6| Step: 12
Training loss: 3.1441827616484797
Validation loss: 2.559456789745061

Epoch: 6| Step: 13
Training loss: 1.9815579340529765
Validation loss: 2.559271263253843

Epoch: 60| Step: 0
Training loss: 2.5415897878891363
Validation loss: 2.5628710542397397

Epoch: 6| Step: 1
Training loss: 2.8234853887164726
Validation loss: 2.5601593810937304

Epoch: 6| Step: 2
Training loss: 3.1174977083664266
Validation loss: 2.5581672078076285

Epoch: 6| Step: 3
Training loss: 2.7117230159513857
Validation loss: 2.5640845143228734

Epoch: 6| Step: 4
Training loss: 3.2755996737477324
Validation loss: 2.5689068747870363

Epoch: 6| Step: 5
Training loss: 3.145638179831025
Validation loss: 2.574948801705863

Epoch: 6| Step: 6
Training loss: 3.0284119524186677
Validation loss: 2.578903468024217

Epoch: 6| Step: 7
Training loss: 2.919993075009848
Validation loss: 2.600271869380555

Epoch: 6| Step: 8
Training loss: 3.0862610466266145
Validation loss: 2.5933421714130827

Epoch: 6| Step: 9
Training loss: 2.834436444980258
Validation loss: 2.569672562563844

Epoch: 6| Step: 10
Training loss: 2.4586342341869134
Validation loss: 2.5607245873008275

Epoch: 6| Step: 11
Training loss: 2.7603855827068915
Validation loss: 2.5563796029922226

Epoch: 6| Step: 12
Training loss: 2.8648534104158605
Validation loss: 2.5559627604749195

Epoch: 6| Step: 13
Training loss: 3.2084779252667186
Validation loss: 2.5583150481871675

Epoch: 61| Step: 0
Training loss: 2.9118172430601517
Validation loss: 2.560650252670189

Epoch: 6| Step: 1
Training loss: 3.5880120951981316
Validation loss: 2.560740001787906

Epoch: 6| Step: 2
Training loss: 2.7090363885992077
Validation loss: 2.5608809443832063

Epoch: 6| Step: 3
Training loss: 2.374120850724068
Validation loss: 2.5620873311784695

Epoch: 6| Step: 4
Training loss: 3.186026438266329
Validation loss: 2.562804042247532

Epoch: 6| Step: 5
Training loss: 1.9805264135389211
Validation loss: 2.5621328203366733

Epoch: 6| Step: 6
Training loss: 2.9260012616502253
Validation loss: 2.5623051438977944

Epoch: 6| Step: 7
Training loss: 2.930341561104078
Validation loss: 2.577101965937094

Epoch: 6| Step: 8
Training loss: 2.5228206482898266
Validation loss: 2.573329857651683

Epoch: 6| Step: 9
Training loss: 2.851381060955015
Validation loss: 2.595592762882025

Epoch: 6| Step: 10
Training loss: 3.212727068880301
Validation loss: 2.6069104253961597

Epoch: 6| Step: 11
Training loss: 3.044072353831513
Validation loss: 2.608709749499076

Epoch: 6| Step: 12
Training loss: 2.861895508218876
Validation loss: 2.6100524903131825

Epoch: 6| Step: 13
Training loss: 3.273204858929998
Validation loss: 2.5873122626057103

Epoch: 62| Step: 0
Training loss: 3.6063119020223375
Validation loss: 2.571611739510516

Epoch: 6| Step: 1
Training loss: 2.6388757091884645
Validation loss: 2.5592802615744485

Epoch: 6| Step: 2
Training loss: 3.2420916072038977
Validation loss: 2.552418551969516

Epoch: 6| Step: 3
Training loss: 2.9844617581364328
Validation loss: 2.5519936648586685

Epoch: 6| Step: 4
Training loss: 3.198765761055974
Validation loss: 2.553803931003253

Epoch: 6| Step: 5
Training loss: 2.1285907476578028
Validation loss: 2.553199342904528

Epoch: 6| Step: 6
Training loss: 3.0777804573986938
Validation loss: 2.5578397397416324

Epoch: 6| Step: 7
Training loss: 2.3523911951830123
Validation loss: 2.558737725392851

Epoch: 6| Step: 8
Training loss: 2.5398273900472312
Validation loss: 2.562809175917663

Epoch: 6| Step: 9
Training loss: 3.1671468136493113
Validation loss: 2.57495052609902

Epoch: 6| Step: 10
Training loss: 2.4742397643516734
Validation loss: 2.5731347117738306

Epoch: 6| Step: 11
Training loss: 2.6506063307464696
Validation loss: 2.5735504394779336

Epoch: 6| Step: 12
Training loss: 3.035250668425628
Validation loss: 2.5680077660734875

Epoch: 6| Step: 13
Training loss: 3.174523211145735
Validation loss: 2.557159288742467

Epoch: 63| Step: 0
Training loss: 3.2164004741150776
Validation loss: 2.5684004989757256

Epoch: 6| Step: 1
Training loss: 2.5582799821027002
Validation loss: 2.5571316868112066

Epoch: 6| Step: 2
Training loss: 2.7117800763624165
Validation loss: 2.559112047949247

Epoch: 6| Step: 3
Training loss: 2.8050213883344406
Validation loss: 2.5583844293775613

Epoch: 6| Step: 4
Training loss: 2.9368905591826553
Validation loss: 2.5614128798113547

Epoch: 6| Step: 5
Training loss: 2.7758333415483123
Validation loss: 2.5701770688816894

Epoch: 6| Step: 6
Training loss: 2.7248702167087693
Validation loss: 2.561494103106186

Epoch: 6| Step: 7
Training loss: 3.441210045130496
Validation loss: 2.563032759682316

Epoch: 6| Step: 8
Training loss: 2.702729653791132
Validation loss: 2.565051921293475

Epoch: 6| Step: 9
Training loss: 2.6917148629077046
Validation loss: 2.5566431920079196

Epoch: 6| Step: 10
Training loss: 2.3930093680237063
Validation loss: 2.5573866845551265

Epoch: 6| Step: 11
Training loss: 3.0227354353340163
Validation loss: 2.5554765151003482

Epoch: 6| Step: 12
Training loss: 3.2154272020487116
Validation loss: 2.555408351120459

Epoch: 6| Step: 13
Training loss: 3.27780115438915
Validation loss: 2.55962922936601

Epoch: 64| Step: 0
Training loss: 3.248913656752922
Validation loss: 2.5463308274790752

Epoch: 6| Step: 1
Training loss: 3.042306144763672
Validation loss: 2.545385620655858

Epoch: 6| Step: 2
Training loss: 3.0840459120483388
Validation loss: 2.540725976388636

Epoch: 6| Step: 3
Training loss: 2.419819310118387
Validation loss: 2.541833731534914

Epoch: 6| Step: 4
Training loss: 2.8842124951048502
Validation loss: 2.5437945437768543

Epoch: 6| Step: 5
Training loss: 2.825956746358231
Validation loss: 2.5551361656375975

Epoch: 6| Step: 6
Training loss: 3.315714158451268
Validation loss: 2.563659232682882

Epoch: 6| Step: 7
Training loss: 3.1754543610111523
Validation loss: 2.574197546402766

Epoch: 6| Step: 8
Training loss: 2.9195467398551322
Validation loss: 2.5581282192697907

Epoch: 6| Step: 9
Training loss: 2.875569991953854
Validation loss: 2.5660276684545007

Epoch: 6| Step: 10
Training loss: 2.429641576007912
Validation loss: 2.5658984395238176

Epoch: 6| Step: 11
Training loss: 2.441080544680256
Validation loss: 2.581594956185881

Epoch: 6| Step: 12
Training loss: 2.6232397444566464
Validation loss: 2.600160266615959

Epoch: 6| Step: 13
Training loss: 3.236663156409935
Validation loss: 2.594564763321828

Epoch: 65| Step: 0
Training loss: 2.856085547589807
Validation loss: 2.5755414072423126

Epoch: 6| Step: 1
Training loss: 3.3790967589899243
Validation loss: 2.5791306002135124

Epoch: 6| Step: 2
Training loss: 2.6518406791183287
Validation loss: 2.573446072785063

Epoch: 6| Step: 3
Training loss: 3.2276361263298035
Validation loss: 2.5626685164391154

Epoch: 6| Step: 4
Training loss: 2.694439290447047
Validation loss: 2.56890485892723

Epoch: 6| Step: 5
Training loss: 2.8962441754436905
Validation loss: 2.575891727074076

Epoch: 6| Step: 6
Training loss: 2.729170025151251
Validation loss: 2.557702243934877

Epoch: 6| Step: 7
Training loss: 2.9458086724083143
Validation loss: 2.5506920449899617

Epoch: 6| Step: 8
Training loss: 3.088727631312306
Validation loss: 2.53879967073035

Epoch: 6| Step: 9
Training loss: 2.5722769329312
Validation loss: 2.535076066837996

Epoch: 6| Step: 10
Training loss: 2.269308529035039
Validation loss: 2.536098887258228

Epoch: 6| Step: 11
Training loss: 2.599358985816695
Validation loss: 2.5326903091662234

Epoch: 6| Step: 12
Training loss: 3.3994555822837884
Validation loss: 2.533144826168624

Epoch: 6| Step: 13
Training loss: 2.8932567266644624
Validation loss: 2.533035202799092

Epoch: 66| Step: 0
Training loss: 2.771792243487659
Validation loss: 2.531979875807532

Epoch: 6| Step: 1
Training loss: 2.52277651417731
Validation loss: 2.5323131318326433

Epoch: 6| Step: 2
Training loss: 3.2335069753944117
Validation loss: 2.533621298268626

Epoch: 6| Step: 3
Training loss: 2.7697712480859558
Validation loss: 2.53114396408316

Epoch: 6| Step: 4
Training loss: 3.2006466093043398
Validation loss: 2.53468356344407

Epoch: 6| Step: 5
Training loss: 3.125563456282801
Validation loss: 2.530636416171205

Epoch: 6| Step: 6
Training loss: 3.1872782910601147
Validation loss: 2.5388141903806054

Epoch: 6| Step: 7
Training loss: 3.046953718684639
Validation loss: 2.5433257820622517

Epoch: 6| Step: 8
Training loss: 2.73844415068567
Validation loss: 2.5483480582642146

Epoch: 6| Step: 9
Training loss: 3.011032481494389
Validation loss: 2.561748347377426

Epoch: 6| Step: 10
Training loss: 2.899451559099909
Validation loss: 2.577563053364555

Epoch: 6| Step: 11
Training loss: 2.2053263603078683
Validation loss: 2.616532879506419

Epoch: 6| Step: 12
Training loss: 2.846639150654773
Validation loss: 2.6331364166536537

Epoch: 6| Step: 13
Training loss: 2.674852998206017
Validation loss: 2.6042181801571886

Epoch: 67| Step: 0
Training loss: 2.7245759476556084
Validation loss: 2.5752506952840384

Epoch: 6| Step: 1
Training loss: 2.975463343850114
Validation loss: 2.544522953182067

Epoch: 6| Step: 2
Training loss: 2.927755222157266
Validation loss: 2.536646650478262

Epoch: 6| Step: 3
Training loss: 2.476392192580446
Validation loss: 2.528210338991313

Epoch: 6| Step: 4
Training loss: 3.03142932479395
Validation loss: 2.5284814961255275

Epoch: 6| Step: 5
Training loss: 2.1739929630267425
Validation loss: 2.532569114137895

Epoch: 6| Step: 6
Training loss: 3.1276142629459924
Validation loss: 2.531098427457129

Epoch: 6| Step: 7
Training loss: 3.0977058166155715
Validation loss: 2.533511859442251

Epoch: 6| Step: 8
Training loss: 3.0666331213346503
Validation loss: 2.5363621025245338

Epoch: 6| Step: 9
Training loss: 2.9886160070871237
Validation loss: 2.531155093130648

Epoch: 6| Step: 10
Training loss: 2.9411922544168045
Validation loss: 2.5304751681993993

Epoch: 6| Step: 11
Training loss: 3.243076873498665
Validation loss: 2.533107531255385

Epoch: 6| Step: 12
Training loss: 2.6499249717599613
Validation loss: 2.5391283302828787

Epoch: 6| Step: 13
Training loss: 2.9813472707942403
Validation loss: 2.5465086761517073

Epoch: 68| Step: 0
Training loss: 3.3741934483668765
Validation loss: 2.5601122756949475

Epoch: 6| Step: 1
Training loss: 2.780723950646174
Validation loss: 2.5729954088774605

Epoch: 6| Step: 2
Training loss: 2.9599559435272123
Validation loss: 2.596353684157055

Epoch: 6| Step: 3
Training loss: 2.53988418194902
Validation loss: 2.59671963437139

Epoch: 6| Step: 4
Training loss: 2.798677683991072
Validation loss: 2.603075755022258

Epoch: 6| Step: 5
Training loss: 3.126594136853462
Validation loss: 2.5741849821109413

Epoch: 6| Step: 6
Training loss: 2.83264877426926
Validation loss: 2.567814899364742

Epoch: 6| Step: 7
Training loss: 3.3072211470807695
Validation loss: 2.5624559320141636

Epoch: 6| Step: 8
Training loss: 3.0275713435113745
Validation loss: 2.5387166418591476

Epoch: 6| Step: 9
Training loss: 2.8596064572902637
Validation loss: 2.52783139486092

Epoch: 6| Step: 10
Training loss: 2.3127324786476597
Validation loss: 2.5242461375605973

Epoch: 6| Step: 11
Training loss: 2.2695209548900532
Validation loss: 2.5275838968317594

Epoch: 6| Step: 12
Training loss: 2.828867103623961
Validation loss: 2.5307984733677333

Epoch: 6| Step: 13
Training loss: 3.5948076101719812
Validation loss: 2.5301400255990876

Epoch: 69| Step: 0
Training loss: 2.7903678681601543
Validation loss: 2.5285657096922667

Epoch: 6| Step: 1
Training loss: 2.991864936513653
Validation loss: 2.5300862665338975

Epoch: 6| Step: 2
Training loss: 3.0377925778989403
Validation loss: 2.52903479667699

Epoch: 6| Step: 3
Training loss: 2.6103990566900794
Validation loss: 2.523380837794391

Epoch: 6| Step: 4
Training loss: 2.5671283513114287
Validation loss: 2.524696573671076

Epoch: 6| Step: 5
Training loss: 2.763164050351125
Validation loss: 2.523884541550025

Epoch: 6| Step: 6
Training loss: 2.8229918710373347
Validation loss: 2.541903464752952

Epoch: 6| Step: 7
Training loss: 2.895013560525235
Validation loss: 2.5698614840939515

Epoch: 6| Step: 8
Training loss: 2.6122697318046773
Validation loss: 2.5809161865546617

Epoch: 6| Step: 9
Training loss: 3.487679458430884
Validation loss: 2.593454624105143

Epoch: 6| Step: 10
Training loss: 2.741132832261429
Validation loss: 2.5811217292287774

Epoch: 6| Step: 11
Training loss: 3.425455388890192
Validation loss: 2.578433249880986

Epoch: 6| Step: 12
Training loss: 2.9505484507593365
Validation loss: 2.5441246379063314

Epoch: 6| Step: 13
Training loss: 2.366823174670011
Validation loss: 2.5275146641628465

Epoch: 70| Step: 0
Training loss: 3.240531627225814
Validation loss: 2.522318586974802

Epoch: 6| Step: 1
Training loss: 2.9131692534913425
Validation loss: 2.5249443201980095

Epoch: 6| Step: 2
Training loss: 2.8868115814107758
Validation loss: 2.528363819545137

Epoch: 6| Step: 3
Training loss: 2.820052454575556
Validation loss: 2.531659229802337

Epoch: 6| Step: 4
Training loss: 2.7425811571963723
Validation loss: 2.54090023403816

Epoch: 6| Step: 5
Training loss: 3.207076152528985
Validation loss: 2.5411578744538463

Epoch: 6| Step: 6
Training loss: 2.5440928235183824
Validation loss: 2.5355790053402987

Epoch: 6| Step: 7
Training loss: 2.631493665417573
Validation loss: 2.534551705681033

Epoch: 6| Step: 8
Training loss: 3.0580287133734383
Validation loss: 2.5321003893071556

Epoch: 6| Step: 9
Training loss: 2.9641159028675523
Validation loss: 2.526383640664099

Epoch: 6| Step: 10
Training loss: 2.6378615325900654
Validation loss: 2.527617564129853

Epoch: 6| Step: 11
Training loss: 3.067234972111773
Validation loss: 2.52792188524443

Epoch: 6| Step: 12
Training loss: 2.8490644826879
Validation loss: 2.523161085350528

Epoch: 6| Step: 13
Training loss: 2.365119055559922
Validation loss: 2.5312229095795895

Epoch: 71| Step: 0
Training loss: 3.0435328223982774
Validation loss: 2.5276701545664926

Epoch: 6| Step: 1
Training loss: 2.7819468450342812
Validation loss: 2.5285511058454264

Epoch: 6| Step: 2
Training loss: 3.2631918864107
Validation loss: 2.5308278733348146

Epoch: 6| Step: 3
Training loss: 1.953089904469842
Validation loss: 2.530312458077393

Epoch: 6| Step: 4
Training loss: 2.9252518504689258
Validation loss: 2.53598912369463

Epoch: 6| Step: 5
Training loss: 2.961093546195197
Validation loss: 2.5358051295248005

Epoch: 6| Step: 6
Training loss: 3.494593395326161
Validation loss: 2.5482194528842514

Epoch: 6| Step: 7
Training loss: 2.705809390384379
Validation loss: 2.551515035701036

Epoch: 6| Step: 8
Training loss: 3.0309325376407656
Validation loss: 2.5601018903805177

Epoch: 6| Step: 9
Training loss: 3.030278945017957
Validation loss: 2.560849833704617

Epoch: 6| Step: 10
Training loss: 2.556129911628529
Validation loss: 2.5601884373855905

Epoch: 6| Step: 11
Training loss: 2.5968528480365363
Validation loss: 2.542343747110395

Epoch: 6| Step: 12
Training loss: 2.553538866245149
Validation loss: 2.5488395459639763

Epoch: 6| Step: 13
Training loss: 3.1870475896771904
Validation loss: 2.5484396137744265

Epoch: 72| Step: 0
Training loss: 3.010169277563945
Validation loss: 2.5503095183626034

Epoch: 6| Step: 1
Training loss: 2.4582284700259143
Validation loss: 2.548619558435042

Epoch: 6| Step: 2
Training loss: 2.7161767116021562
Validation loss: 2.5535332742041725

Epoch: 6| Step: 3
Training loss: 3.8166201481767543
Validation loss: 2.5623031108378953

Epoch: 6| Step: 4
Training loss: 2.8172034036247755
Validation loss: 2.548586344610938

Epoch: 6| Step: 5
Training loss: 2.7987236860638918
Validation loss: 2.5341099663273656

Epoch: 6| Step: 6
Training loss: 2.896258005156668
Validation loss: 2.5226542381969366

Epoch: 6| Step: 7
Training loss: 3.020511759161259
Validation loss: 2.516395666337025

Epoch: 6| Step: 8
Training loss: 2.8992111119606845
Validation loss: 2.5226980858394388

Epoch: 6| Step: 9
Training loss: 2.7226413633358266
Validation loss: 2.520814503174227

Epoch: 6| Step: 10
Training loss: 3.126208262510023
Validation loss: 2.5196186360541235

Epoch: 6| Step: 11
Training loss: 1.8158769390069327
Validation loss: 2.5203301186729594

Epoch: 6| Step: 12
Training loss: 2.6127812430386532
Validation loss: 2.519405885951061

Epoch: 6| Step: 13
Training loss: 3.302086783005189
Validation loss: 2.519325717416705

Epoch: 73| Step: 0
Training loss: 3.0774620620285633
Validation loss: 2.523046154023657

Epoch: 6| Step: 1
Training loss: 3.3790837764960937
Validation loss: 2.525248459927993

Epoch: 6| Step: 2
Training loss: 2.468192218590638
Validation loss: 2.526373034504474

Epoch: 6| Step: 3
Training loss: 2.6844392247005406
Validation loss: 2.522412107682786

Epoch: 6| Step: 4
Training loss: 2.9519915953932627
Validation loss: 2.526851733653121

Epoch: 6| Step: 5
Training loss: 2.8014162160506886
Validation loss: 2.5323402439979836

Epoch: 6| Step: 6
Training loss: 2.9665721735389194
Validation loss: 2.5366218876168527

Epoch: 6| Step: 7
Training loss: 2.778941707476032
Validation loss: 2.5360192676511106

Epoch: 6| Step: 8
Training loss: 2.904291621128402
Validation loss: 2.538180080197896

Epoch: 6| Step: 9
Training loss: 2.797021872643935
Validation loss: 2.5414639241980024

Epoch: 6| Step: 10
Training loss: 2.617255457664817
Validation loss: 2.5556989688708787

Epoch: 6| Step: 11
Training loss: 3.226937703999816
Validation loss: 2.5398431887501607

Epoch: 6| Step: 12
Training loss: 2.5008417619738794
Validation loss: 2.5533202002882724

Epoch: 6| Step: 13
Training loss: 2.719445413683038
Validation loss: 2.547040155761826

Epoch: 74| Step: 0
Training loss: 2.866626653465939
Validation loss: 2.5467279017905122

Epoch: 6| Step: 1
Training loss: 2.832681767960382
Validation loss: 2.542211813707409

Epoch: 6| Step: 2
Training loss: 2.1424557173613863
Validation loss: 2.548419909865031

Epoch: 6| Step: 3
Training loss: 3.1563167753804198
Validation loss: 2.5351026579836615

Epoch: 6| Step: 4
Training loss: 3.158239058913538
Validation loss: 2.525181133791525

Epoch: 6| Step: 5
Training loss: 2.7185722380654744
Validation loss: 2.5203185268121744

Epoch: 6| Step: 6
Training loss: 2.944798918045952
Validation loss: 2.5200188135378143

Epoch: 6| Step: 7
Training loss: 2.547658975149953
Validation loss: 2.5169429955630602

Epoch: 6| Step: 8
Training loss: 3.218857254167242
Validation loss: 2.517297281529346

Epoch: 6| Step: 9
Training loss: 1.935920379045718
Validation loss: 2.5129025238835223

Epoch: 6| Step: 10
Training loss: 2.657827559601708
Validation loss: 2.514925382062506

Epoch: 6| Step: 11
Training loss: 3.1637548980011814
Validation loss: 2.5172651056792885

Epoch: 6| Step: 12
Training loss: 3.0812990505809927
Validation loss: 2.5105527128571112

Epoch: 6| Step: 13
Training loss: 3.6076340212813087
Validation loss: 2.5099683798841963

Epoch: 75| Step: 0
Training loss: 2.473423072064383
Validation loss: 2.510583475710332

Epoch: 6| Step: 1
Training loss: 3.0343047804717074
Validation loss: 2.509229955929409

Epoch: 6| Step: 2
Training loss: 2.5371770343172346
Validation loss: 2.5090967002491187

Epoch: 6| Step: 3
Training loss: 3.2471156892975985
Validation loss: 2.511477724128406

Epoch: 6| Step: 4
Training loss: 2.7005532439643414
Validation loss: 2.515852857525097

Epoch: 6| Step: 5
Training loss: 2.66293230442435
Validation loss: 2.517029007865313

Epoch: 6| Step: 6
Training loss: 2.716043989125857
Validation loss: 2.518692687753133

Epoch: 6| Step: 7
Training loss: 2.3411482548232634
Validation loss: 2.5175445617283168

Epoch: 6| Step: 8
Training loss: 2.7230029111209904
Validation loss: 2.5293472949540936

Epoch: 6| Step: 9
Training loss: 3.0487320937991162
Validation loss: 2.524847871560775

Epoch: 6| Step: 10
Training loss: 2.689740333929066
Validation loss: 2.523181811530414

Epoch: 6| Step: 11
Training loss: 3.2642319916015645
Validation loss: 2.512182890303282

Epoch: 6| Step: 12
Training loss: 2.7808182627729
Validation loss: 2.519836779663856

Epoch: 6| Step: 13
Training loss: 3.9947118374019666
Validation loss: 2.5228036861512875

Epoch: 76| Step: 0
Training loss: 2.981562862334246
Validation loss: 2.522787297032032

Epoch: 6| Step: 1
Training loss: 3.29988936614493
Validation loss: 2.5269048746898797

Epoch: 6| Step: 2
Training loss: 1.9733383963279383
Validation loss: 2.53161069790779

Epoch: 6| Step: 3
Training loss: 2.427013434411814
Validation loss: 2.530277718212259

Epoch: 6| Step: 4
Training loss: 2.9947772658734375
Validation loss: 2.525398439583171

Epoch: 6| Step: 5
Training loss: 2.7064220629255944
Validation loss: 2.5333261729669765

Epoch: 6| Step: 6
Training loss: 2.4856001993754453
Validation loss: 2.5307061135047997

Epoch: 6| Step: 7
Training loss: 2.778704389093992
Validation loss: 2.51844136350149

Epoch: 6| Step: 8
Training loss: 2.940930737159419
Validation loss: 2.5268286573990872

Epoch: 6| Step: 9
Training loss: 3.1773964315923964
Validation loss: 2.5243187219093457

Epoch: 6| Step: 10
Training loss: 3.162254136973599
Validation loss: 2.523105411665809

Epoch: 6| Step: 11
Training loss: 2.604502440104492
Validation loss: 2.519208146396059

Epoch: 6| Step: 12
Training loss: 3.2709176281476355
Validation loss: 2.5310357622347013

Epoch: 6| Step: 13
Training loss: 2.8983035814960267
Validation loss: 2.5427505855507424

Epoch: 77| Step: 0
Training loss: 2.6083822589059755
Validation loss: 2.5614592596950656

Epoch: 6| Step: 1
Training loss: 3.2769747538846947
Validation loss: 2.5817663496118537

Epoch: 6| Step: 2
Training loss: 3.1723301753529816
Validation loss: 2.5963652623881903

Epoch: 6| Step: 3
Training loss: 3.0602673547173347
Validation loss: 2.626761572485885

Epoch: 6| Step: 4
Training loss: 2.85404630161251
Validation loss: 2.6456116087735393

Epoch: 6| Step: 5
Training loss: 3.274663363328732
Validation loss: 2.6519861182728945

Epoch: 6| Step: 6
Training loss: 2.5396543781293475
Validation loss: 2.593087062333808

Epoch: 6| Step: 7
Training loss: 1.8051133747369712
Validation loss: 2.5594678287368606

Epoch: 6| Step: 8
Training loss: 2.4572697510064754
Validation loss: 2.537677822876622

Epoch: 6| Step: 9
Training loss: 3.2155826132068817
Validation loss: 2.533626007912587

Epoch: 6| Step: 10
Training loss: 2.8760367473010793
Validation loss: 2.5260024718599383

Epoch: 6| Step: 11
Training loss: 2.4187537969515076
Validation loss: 2.521673425761988

Epoch: 6| Step: 12
Training loss: 2.4996240333142827
Validation loss: 2.5175405027416495

Epoch: 6| Step: 13
Training loss: 3.776718198307397
Validation loss: 2.515905561415033

Epoch: 78| Step: 0
Training loss: 2.93211260305886
Validation loss: 2.522157946660519

Epoch: 6| Step: 1
Training loss: 2.942186391448361
Validation loss: 2.521980828565209

Epoch: 6| Step: 2
Training loss: 2.815647483337935
Validation loss: 2.5209641151060183

Epoch: 6| Step: 3
Training loss: 3.0519251516620876
Validation loss: 2.544979487014378

Epoch: 6| Step: 4
Training loss: 2.3158794144910435
Validation loss: 2.52596116203574

Epoch: 6| Step: 5
Training loss: 2.8121110435255154
Validation loss: 2.530320324329203

Epoch: 6| Step: 6
Training loss: 2.3615880023325895
Validation loss: 2.525363357011357

Epoch: 6| Step: 7
Training loss: 3.1889963564632127
Validation loss: 2.5405553647286263

Epoch: 6| Step: 8
Training loss: 3.019391647605666
Validation loss: 2.5463144599123355

Epoch: 6| Step: 9
Training loss: 3.3130412109464755
Validation loss: 2.551260352440304

Epoch: 6| Step: 10
Training loss: 3.201825134020091
Validation loss: 2.560219839479323

Epoch: 6| Step: 11
Training loss: 2.1303981208354643
Validation loss: 2.546589564425089

Epoch: 6| Step: 12
Training loss: 2.5183860837745793
Validation loss: 2.5454789671524076

Epoch: 6| Step: 13
Training loss: 3.184858237185259
Validation loss: 2.611645470269257

Epoch: 79| Step: 0
Training loss: 3.1925811659279075
Validation loss: 2.6612308455465006

Epoch: 6| Step: 1
Training loss: 3.933788063682163
Validation loss: 2.823436310683871

Epoch: 6| Step: 2
Training loss: 3.031483277458616
Validation loss: 2.778899163107476

Epoch: 6| Step: 3
Training loss: 2.0122064980624446
Validation loss: 2.7014059736566014

Epoch: 6| Step: 4
Training loss: 2.592515674716572
Validation loss: 2.665040881551306

Epoch: 6| Step: 5
Training loss: 3.096694777832989
Validation loss: 2.647191467865183

Epoch: 6| Step: 6
Training loss: 2.9690583721421677
Validation loss: 2.63947036973721

Epoch: 6| Step: 7
Training loss: 3.197649336750788
Validation loss: 2.624658112106346

Epoch: 6| Step: 8
Training loss: 2.3621514764676546
Validation loss: 2.579510779911624

Epoch: 6| Step: 9
Training loss: 2.489312118590392
Validation loss: 2.543549718805808

Epoch: 6| Step: 10
Training loss: 2.53555186613065
Validation loss: 2.502566761157601

Epoch: 6| Step: 11
Training loss: 2.90519235706188
Validation loss: 2.519289270132335

Epoch: 6| Step: 12
Training loss: 2.9257722862116524
Validation loss: 2.5459143918657987

Epoch: 6| Step: 13
Training loss: 3.154414483585334
Validation loss: 2.5562288636194905

Epoch: 80| Step: 0
Training loss: 3.3881504856003266
Validation loss: 2.617190106555447

Epoch: 6| Step: 1
Training loss: 3.6883816715686533
Validation loss: 2.630215386513523

Epoch: 6| Step: 2
Training loss: 3.079429698510165
Validation loss: 2.593552187628735

Epoch: 6| Step: 3
Training loss: 2.207986108604906
Validation loss: 2.5557283336692103

Epoch: 6| Step: 4
Training loss: 3.029674159744112
Validation loss: 2.553077195508068

Epoch: 6| Step: 5
Training loss: 2.4726959755645743
Validation loss: 2.529857129215835

Epoch: 6| Step: 6
Training loss: 2.1406375856795274
Validation loss: 2.5231585665782053

Epoch: 6| Step: 7
Training loss: 3.1304540722823955
Validation loss: 2.519668126408624

Epoch: 6| Step: 8
Training loss: 2.913279901301143
Validation loss: 2.522496698681578

Epoch: 6| Step: 9
Training loss: 2.9728217862089537
Validation loss: 2.520193829562227

Epoch: 6| Step: 10
Training loss: 2.7897631195304093
Validation loss: 2.5297785079437407

Epoch: 6| Step: 11
Training loss: 2.574519369953757
Validation loss: 2.5446393132663774

Epoch: 6| Step: 12
Training loss: 2.3754920449771055
Validation loss: 2.545992516869225

Epoch: 6| Step: 13
Training loss: 3.05101600359205
Validation loss: 2.536951160749794

Epoch: 81| Step: 0
Training loss: 3.0176103608715064
Validation loss: 2.5596130019230796

Epoch: 6| Step: 1
Training loss: 2.3518832675485415
Validation loss: 2.5791765680556593

Epoch: 6| Step: 2
Training loss: 3.454903399252857
Validation loss: 2.6029660561151404

Epoch: 6| Step: 3
Training loss: 3.0560215527238825
Validation loss: 2.6257707525874574

Epoch: 6| Step: 4
Training loss: 2.7046143061861985
Validation loss: 2.642171127617811

Epoch: 6| Step: 5
Training loss: 2.273658348446711
Validation loss: 2.5797751159192974

Epoch: 6| Step: 6
Training loss: 2.2956182454106147
Validation loss: 2.5443629187720895

Epoch: 6| Step: 7
Training loss: 2.9649273806551473
Validation loss: 2.515590179595741

Epoch: 6| Step: 8
Training loss: 3.0583840562596936
Validation loss: 2.4997546516538454

Epoch: 6| Step: 9
Training loss: 2.3845950603802204
Validation loss: 2.494625711754018

Epoch: 6| Step: 10
Training loss: 3.5587640547801445
Validation loss: 2.4937876459780024

Epoch: 6| Step: 11
Training loss: 2.870432335060545
Validation loss: 2.494885417039832

Epoch: 6| Step: 12
Training loss: 3.0626854353836013
Validation loss: 2.5008572862081087

Epoch: 6| Step: 13
Training loss: 2.0019942116591762
Validation loss: 2.504881362260566

Epoch: 82| Step: 0
Training loss: 2.9565284130138183
Validation loss: 2.5113698805450304

Epoch: 6| Step: 1
Training loss: 3.199005902374632
Validation loss: 2.5104411358909426

Epoch: 6| Step: 2
Training loss: 2.5212379530172995
Validation loss: 2.5167794329940825

Epoch: 6| Step: 3
Training loss: 2.916832147172729
Validation loss: 2.5220463220136837

Epoch: 6| Step: 4
Training loss: 3.1128511406941857
Validation loss: 2.509898844144291

Epoch: 6| Step: 5
Training loss: 2.892048748032878
Validation loss: 2.508919826998041

Epoch: 6| Step: 6
Training loss: 2.9065860020821677
Validation loss: 2.5096002768701764

Epoch: 6| Step: 7
Training loss: 3.0225854111586363
Validation loss: 2.5087253811857093

Epoch: 6| Step: 8
Training loss: 3.2339008370733073
Validation loss: 2.4994169950060354

Epoch: 6| Step: 9
Training loss: 1.926235369825409
Validation loss: 2.5053920116112476

Epoch: 6| Step: 10
Training loss: 2.7475720871830784
Validation loss: 2.506057394463928

Epoch: 6| Step: 11
Training loss: 2.745243640919737
Validation loss: 2.508565948552298

Epoch: 6| Step: 12
Training loss: 3.056733287832672
Validation loss: 2.5312270438549582

Epoch: 6| Step: 13
Training loss: 2.1865125334699083
Validation loss: 2.54477554134914

Epoch: 83| Step: 0
Training loss: 3.4499884121465265
Validation loss: 2.5859385528428476

Epoch: 6| Step: 1
Training loss: 2.3938752064442124
Validation loss: 2.586479966588482

Epoch: 6| Step: 2
Training loss: 2.73462732513241
Validation loss: 2.5893405914351075

Epoch: 6| Step: 3
Training loss: 3.1517519483992205
Validation loss: 2.5376026797770397

Epoch: 6| Step: 4
Training loss: 2.6632422473722657
Validation loss: 2.5097165992531982

Epoch: 6| Step: 5
Training loss: 3.132966073474385
Validation loss: 2.5087394403048533

Epoch: 6| Step: 6
Training loss: 3.1470506514893515
Validation loss: 2.504229609069844

Epoch: 6| Step: 7
Training loss: 2.679543271645898
Validation loss: 2.5067873617058973

Epoch: 6| Step: 8
Training loss: 3.0730438895748655
Validation loss: 2.517754670014138

Epoch: 6| Step: 9
Training loss: 2.349240801307796
Validation loss: 2.525315327440155

Epoch: 6| Step: 10
Training loss: 2.890421432337948
Validation loss: 2.560486671640655

Epoch: 6| Step: 11
Training loss: 2.3452795505432893
Validation loss: 2.556834500545474

Epoch: 6| Step: 12
Training loss: 3.204910153038661
Validation loss: 2.5407296431608235

Epoch: 6| Step: 13
Training loss: 2.3557979929319486
Validation loss: 2.5377829271468095

Epoch: 84| Step: 0
Training loss: 2.382980891046654
Validation loss: 2.5412544314262986

Epoch: 6| Step: 1
Training loss: 3.239650680643327
Validation loss: 2.540089902038521

Epoch: 6| Step: 2
Training loss: 3.3179554191017955
Validation loss: 2.5488275939314735

Epoch: 6| Step: 3
Training loss: 2.6616893053455577
Validation loss: 2.543317489335444

Epoch: 6| Step: 4
Training loss: 2.5232636477457437
Validation loss: 2.5491602182988764

Epoch: 6| Step: 5
Training loss: 3.2392558988255575
Validation loss: 2.5557936885444277

Epoch: 6| Step: 6
Training loss: 2.877967961072697
Validation loss: 2.5340831765955008

Epoch: 6| Step: 7
Training loss: 2.571438991813133
Validation loss: 2.517471004053968

Epoch: 6| Step: 8
Training loss: 2.8240862085837932
Validation loss: 2.499000550525982

Epoch: 6| Step: 9
Training loss: 2.4914323864603896
Validation loss: 2.4982914274990247

Epoch: 6| Step: 10
Training loss: 3.275920499775538
Validation loss: 2.5039760801335285

Epoch: 6| Step: 11
Training loss: 3.169962790478396
Validation loss: 2.5135068144366906

Epoch: 6| Step: 12
Training loss: 2.623155581678006
Validation loss: 2.541949635822797

Epoch: 6| Step: 13
Training loss: 2.169673874603612
Validation loss: 2.508535311697746

Epoch: 85| Step: 0
Training loss: 2.7222106656545018
Validation loss: 2.5054392852831566

Epoch: 6| Step: 1
Training loss: 2.9095299373226524
Validation loss: 2.496943759152428

Epoch: 6| Step: 2
Training loss: 2.6883401666386084
Validation loss: 2.497356477402283

Epoch: 6| Step: 3
Training loss: 3.0124298720685365
Validation loss: 2.5145326409667366

Epoch: 6| Step: 4
Training loss: 2.7058717740869196
Validation loss: 2.527457417827365

Epoch: 6| Step: 5
Training loss: 3.2683810782620957
Validation loss: 2.5496891030862217

Epoch: 6| Step: 6
Training loss: 2.980248279341598
Validation loss: 2.58112024733318

Epoch: 6| Step: 7
Training loss: 3.4523052088253743
Validation loss: 2.63116060504128

Epoch: 6| Step: 8
Training loss: 2.6126065830227496
Validation loss: 2.569465081345344

Epoch: 6| Step: 9
Training loss: 2.677259852506024
Validation loss: 2.551575192527157

Epoch: 6| Step: 10
Training loss: 2.436120939168482
Validation loss: 2.528898747579848

Epoch: 6| Step: 11
Training loss: 2.860932473178783
Validation loss: 2.5031667659189334

Epoch: 6| Step: 12
Training loss: 2.8095792227276593
Validation loss: 2.4936994045957044

Epoch: 6| Step: 13
Training loss: 1.9024510284818068
Validation loss: 2.489697023372678

Epoch: 86| Step: 0
Training loss: 2.862137590813048
Validation loss: 2.497178308570469

Epoch: 6| Step: 1
Training loss: 2.888353929954329
Validation loss: 2.508456112082715

Epoch: 6| Step: 2
Training loss: 2.612238061358303
Validation loss: 2.5258020292195797

Epoch: 6| Step: 3
Training loss: 2.7530724095009864
Validation loss: 2.5714122759411264

Epoch: 6| Step: 4
Training loss: 2.9031268330251043
Validation loss: 2.586375324701582

Epoch: 6| Step: 5
Training loss: 2.858012557496659
Validation loss: 2.5545620307468555

Epoch: 6| Step: 6
Training loss: 3.397093338253118
Validation loss: 2.5503020836909918

Epoch: 6| Step: 7
Training loss: 2.6188977475241955
Validation loss: 2.5264725938640153

Epoch: 6| Step: 8
Training loss: 3.098091085347219
Validation loss: 2.5131145534842023

Epoch: 6| Step: 9
Training loss: 2.2503933032986145
Validation loss: 2.5124403276960514

Epoch: 6| Step: 10
Training loss: 2.6828639830335677
Validation loss: 2.513453027021164

Epoch: 6| Step: 11
Training loss: 2.6443116225038947
Validation loss: 2.51768484732436

Epoch: 6| Step: 12
Training loss: 2.9764455537024817
Validation loss: 2.5072011170756356

Epoch: 6| Step: 13
Training loss: 2.9324342592485264
Validation loss: 2.5071323880590524

Epoch: 87| Step: 0
Training loss: 2.237105401903011
Validation loss: 2.500949223086214

Epoch: 6| Step: 1
Training loss: 3.1044305949477526
Validation loss: 2.5118323706623444

Epoch: 6| Step: 2
Training loss: 2.8556510981876055
Validation loss: 2.5130211080918357

Epoch: 6| Step: 3
Training loss: 2.8254079676058543
Validation loss: 2.509949606782721

Epoch: 6| Step: 4
Training loss: 2.92164129454728
Validation loss: 2.507261289078893

Epoch: 6| Step: 5
Training loss: 3.1050851644977757
Validation loss: 2.5152379923394848

Epoch: 6| Step: 6
Training loss: 2.7558113596820424
Validation loss: 2.525522114476174

Epoch: 6| Step: 7
Training loss: 2.529699722081442
Validation loss: 2.5404385400750518

Epoch: 6| Step: 8
Training loss: 2.852224612771445
Validation loss: 2.5387482943931303

Epoch: 6| Step: 9
Training loss: 2.164255732643843
Validation loss: 2.5187855878745515

Epoch: 6| Step: 10
Training loss: 3.299444417712802
Validation loss: 2.512824467854874

Epoch: 6| Step: 11
Training loss: 2.493173051601989
Validation loss: 2.5164601916528744

Epoch: 6| Step: 12
Training loss: 2.8801968915182052
Validation loss: 2.5105394052483376

Epoch: 6| Step: 13
Training loss: 3.3246517773464324
Validation loss: 2.5253635681640327

Epoch: 88| Step: 0
Training loss: 2.41640312029355
Validation loss: 2.543889523792887

Epoch: 6| Step: 1
Training loss: 3.1587962842115864
Validation loss: 2.549065675542145

Epoch: 6| Step: 2
Training loss: 3.0730575443022965
Validation loss: 2.5699915222494822

Epoch: 6| Step: 3
Training loss: 2.8474208069892297
Validation loss: 2.5910487761520327

Epoch: 6| Step: 4
Training loss: 2.722484435430195
Validation loss: 2.5734050802459847

Epoch: 6| Step: 5
Training loss: 1.7048517275688184
Validation loss: 2.556744709088274

Epoch: 6| Step: 6
Training loss: 2.6423990283394905
Validation loss: 2.550521227523964

Epoch: 6| Step: 7
Training loss: 2.7097545318354457
Validation loss: 2.5484721610558414

Epoch: 6| Step: 8
Training loss: 2.778974480873158
Validation loss: 2.5186670959275475

Epoch: 6| Step: 9
Training loss: 2.9553099930203923
Validation loss: 2.507148743516949

Epoch: 6| Step: 10
Training loss: 3.214954100855169
Validation loss: 2.4998895497688345

Epoch: 6| Step: 11
Training loss: 2.8747044286966554
Validation loss: 2.501783274348189

Epoch: 6| Step: 12
Training loss: 3.3722661566626186
Validation loss: 2.505685327273329

Epoch: 6| Step: 13
Training loss: 2.1624972745845135
Validation loss: 2.513725787254561

Epoch: 89| Step: 0
Training loss: 2.8998740201749698
Validation loss: 2.525060991614437

Epoch: 6| Step: 1
Training loss: 3.1695903198063555
Validation loss: 2.557451673270082

Epoch: 6| Step: 2
Training loss: 2.8507732814636677
Validation loss: 2.5730055169729007

Epoch: 6| Step: 3
Training loss: 1.9918612343893307
Validation loss: 2.547967330885969

Epoch: 6| Step: 4
Training loss: 3.1632796461120596
Validation loss: 2.5569273859615587

Epoch: 6| Step: 5
Training loss: 2.8253480544931664
Validation loss: 2.5413089065346686

Epoch: 6| Step: 6
Training loss: 2.860340226484024
Validation loss: 2.5372265873577176

Epoch: 6| Step: 7
Training loss: 3.047992051592298
Validation loss: 2.5440742397494094

Epoch: 6| Step: 8
Training loss: 2.375436843048558
Validation loss: 2.5203665743004144

Epoch: 6| Step: 9
Training loss: 2.659191522421332
Validation loss: 2.5163629868837343

Epoch: 6| Step: 10
Training loss: 2.9664448673044364
Validation loss: 2.5274130451677443

Epoch: 6| Step: 11
Training loss: 2.696931568317185
Validation loss: 2.5320240995862737

Epoch: 6| Step: 12
Training loss: 2.7497516866762544
Validation loss: 2.53084564017608

Epoch: 6| Step: 13
Training loss: 3.1059938382728114
Validation loss: 2.5297096221324815

Epoch: 90| Step: 0
Training loss: 2.365844345506079
Validation loss: 2.529603415233254

Epoch: 6| Step: 1
Training loss: 2.352896479925405
Validation loss: 2.512711271593518

Epoch: 6| Step: 2
Training loss: 2.755115865635228
Validation loss: 2.4992552755526933

Epoch: 6| Step: 3
Training loss: 2.642641730716642
Validation loss: 2.5157160924959823

Epoch: 6| Step: 4
Training loss: 3.4213076604542465
Validation loss: 2.501782316229843

Epoch: 6| Step: 5
Training loss: 3.2837227359681065
Validation loss: 2.5029323024240853

Epoch: 6| Step: 6
Training loss: 2.6133965664953207
Validation loss: 2.488212703116701

Epoch: 6| Step: 7
Training loss: 3.211050361079178
Validation loss: 2.4990014850900746

Epoch: 6| Step: 8
Training loss: 2.584408956579084
Validation loss: 2.5048128479809075

Epoch: 6| Step: 9
Training loss: 2.569214653072653
Validation loss: 2.515227829439395

Epoch: 6| Step: 10
Training loss: 2.982978214318638
Validation loss: 2.5397939239677676

Epoch: 6| Step: 11
Training loss: 2.4984330034722473
Validation loss: 2.5868265920879643

Epoch: 6| Step: 12
Training loss: 2.9936650465218384
Validation loss: 2.6281497631618542

Epoch: 6| Step: 13
Training loss: 2.754246207823354
Validation loss: 2.6738009757542813

Epoch: 91| Step: 0
Training loss: 2.993621721485956
Validation loss: 2.6728448676897467

Epoch: 6| Step: 1
Training loss: 2.0077958755695513
Validation loss: 2.627315870848828

Epoch: 6| Step: 2
Training loss: 2.5682868744222938
Validation loss: 2.5523009534966032

Epoch: 6| Step: 3
Training loss: 3.2517758432814414
Validation loss: 2.539438115584799

Epoch: 6| Step: 4
Training loss: 2.5390887919311815
Validation loss: 2.515175560845714

Epoch: 6| Step: 5
Training loss: 2.4569609954930143
Validation loss: 2.506049752809436

Epoch: 6| Step: 6
Training loss: 2.682347703860694
Validation loss: 2.503402160856908

Epoch: 6| Step: 7
Training loss: 2.5474397934078046
Validation loss: 2.502245249593853

Epoch: 6| Step: 8
Training loss: 3.1441339277323377
Validation loss: 2.5102972632750298

Epoch: 6| Step: 9
Training loss: 3.0166911874129316
Validation loss: 2.5338908843530983

Epoch: 6| Step: 10
Training loss: 3.5062083631141046
Validation loss: 2.5575490875901363

Epoch: 6| Step: 11
Training loss: 2.925790702692507
Validation loss: 2.6227713019355297

Epoch: 6| Step: 12
Training loss: 2.7744396709373405
Validation loss: 2.6712822891471926

Epoch: 6| Step: 13
Training loss: 3.436542030711281
Validation loss: 2.670121362072665

Epoch: 92| Step: 0
Training loss: 2.8845208128073963
Validation loss: 2.665631474662817

Epoch: 6| Step: 1
Training loss: 2.994516765859016
Validation loss: 2.6631554924733947

Epoch: 6| Step: 2
Training loss: 3.0366403689817774
Validation loss: 2.6622634860060517

Epoch: 6| Step: 3
Training loss: 2.651283917603538
Validation loss: 2.6217032228088435

Epoch: 6| Step: 4
Training loss: 2.9043786371519014
Validation loss: 2.60123395780711

Epoch: 6| Step: 5
Training loss: 2.839666096037931
Validation loss: 2.5601353473448327

Epoch: 6| Step: 6
Training loss: 2.7530968308496124
Validation loss: 2.5202764789139285

Epoch: 6| Step: 7
Training loss: 2.498232598219615
Validation loss: 2.5505114203169112

Epoch: 6| Step: 8
Training loss: 2.973156038595012
Validation loss: 2.5394219913099154

Epoch: 6| Step: 9
Training loss: 2.450779175932289
Validation loss: 2.5170190620124098

Epoch: 6| Step: 10
Training loss: 3.071460926481141
Validation loss: 2.5522339442205375

Epoch: 6| Step: 11
Training loss: 2.764190474200563
Validation loss: 2.5604545639385288

Epoch: 6| Step: 12
Training loss: 2.898249782025564
Validation loss: 2.568931591893918

Epoch: 6| Step: 13
Training loss: 2.7323073062504872
Validation loss: 2.5851084802276074

Epoch: 93| Step: 0
Training loss: 3.132125056083068
Validation loss: 2.607738926859143

Epoch: 6| Step: 1
Training loss: 2.9796807083508563
Validation loss: 2.547594226692314

Epoch: 6| Step: 2
Training loss: 2.937719134009776
Validation loss: 2.525495553404612

Epoch: 6| Step: 3
Training loss: 2.968785496549713
Validation loss: 2.514633653937583

Epoch: 6| Step: 4
Training loss: 2.64905939143166
Validation loss: 2.4991733763614743

Epoch: 6| Step: 5
Training loss: 3.1408059746520727
Validation loss: 2.498445138094424

Epoch: 6| Step: 6
Training loss: 2.948677387192474
Validation loss: 2.4908627012436546

Epoch: 6| Step: 7
Training loss: 3.2252901168562533
Validation loss: 2.4947216455614307

Epoch: 6| Step: 8
Training loss: 2.2052526278244984
Validation loss: 2.484718735470566

Epoch: 6| Step: 9
Training loss: 2.8201667557780175
Validation loss: 2.4875153496002196

Epoch: 6| Step: 10
Training loss: 2.719495736810506
Validation loss: 2.4883052153606897

Epoch: 6| Step: 11
Training loss: 2.77576205125907
Validation loss: 2.5065068218885687

Epoch: 6| Step: 12
Training loss: 2.0742247270688363
Validation loss: 2.530011169522103

Epoch: 6| Step: 13
Training loss: 2.5340880507877994
Validation loss: 2.5774868769258057

Epoch: 94| Step: 0
Training loss: 2.564602245402593
Validation loss: 2.611145565377571

Epoch: 6| Step: 1
Training loss: 2.5974337604436766
Validation loss: 2.6083485617794766

Epoch: 6| Step: 2
Training loss: 3.664525765289781
Validation loss: 2.593073177776672

Epoch: 6| Step: 3
Training loss: 2.902184873522033
Validation loss: 2.6289168705969734

Epoch: 6| Step: 4
Training loss: 3.059519348791552
Validation loss: 2.5909924358725585

Epoch: 6| Step: 5
Training loss: 2.771934424347167
Validation loss: 2.553815766388377

Epoch: 6| Step: 6
Training loss: 1.9475174016995291
Validation loss: 2.541744330510865

Epoch: 6| Step: 7
Training loss: 1.9402466041113497
Validation loss: 2.53183642417771

Epoch: 6| Step: 8
Training loss: 3.530719008231594
Validation loss: 2.5282333326678277

Epoch: 6| Step: 9
Training loss: 2.3867489177589123
Validation loss: 2.5168689629635725

Epoch: 6| Step: 10
Training loss: 2.9100014050142757
Validation loss: 2.5088869888589387

Epoch: 6| Step: 11
Training loss: 2.657926681012511
Validation loss: 2.499976534374408

Epoch: 6| Step: 12
Training loss: 2.907706275241888
Validation loss: 2.499618150405576

Epoch: 6| Step: 13
Training loss: 2.2947616716024273
Validation loss: 2.500405975931434

Epoch: 95| Step: 0
Training loss: 2.7818835104900206
Validation loss: 2.503718314090419

Epoch: 6| Step: 1
Training loss: 2.8549615537389705
Validation loss: 2.4970670939207986

Epoch: 6| Step: 2
Training loss: 2.4773831617287403
Validation loss: 2.5037055138671165

Epoch: 6| Step: 3
Training loss: 2.797202661170823
Validation loss: 2.498853966335775

Epoch: 6| Step: 4
Training loss: 3.093181981818083
Validation loss: 2.5042895648116055

Epoch: 6| Step: 5
Training loss: 2.362257857250784
Validation loss: 2.521257365018813

Epoch: 6| Step: 6
Training loss: 2.952478731677968
Validation loss: 2.526996338694313

Epoch: 6| Step: 7
Training loss: 2.075104777436867
Validation loss: 2.547800164431875

Epoch: 6| Step: 8
Training loss: 3.2445518605059616
Validation loss: 2.563082617019393

Epoch: 6| Step: 9
Training loss: 2.626661229136046
Validation loss: 2.5439215780487863

Epoch: 6| Step: 10
Training loss: 2.991368911362687
Validation loss: 2.540884980185699

Epoch: 6| Step: 11
Training loss: 3.079224056247648
Validation loss: 2.5357061650781296

Epoch: 6| Step: 12
Training loss: 3.0653813100973175
Validation loss: 2.5194697958989147

Epoch: 6| Step: 13
Training loss: 1.7166897997485717
Validation loss: 2.534300581949137

Epoch: 96| Step: 0
Training loss: 2.6392410534115096
Validation loss: 2.540671658300341

Epoch: 6| Step: 1
Training loss: 2.4883325113379042
Validation loss: 2.5240718372278925

Epoch: 6| Step: 2
Training loss: 2.6829202353741124
Validation loss: 2.540199614558507

Epoch: 6| Step: 3
Training loss: 3.4581477716752054
Validation loss: 2.5067216567398534

Epoch: 6| Step: 4
Training loss: 2.9309918971188855
Validation loss: 2.497636573109922

Epoch: 6| Step: 5
Training loss: 2.8124155667664814
Validation loss: 2.50175156299784

Epoch: 6| Step: 6
Training loss: 3.176922770127331
Validation loss: 2.504934711482749

Epoch: 6| Step: 7
Training loss: 2.5888513473204577
Validation loss: 2.5174309880779155

Epoch: 6| Step: 8
Training loss: 2.2871973556679395
Validation loss: 2.5249173164536507

Epoch: 6| Step: 9
Training loss: 2.6955907705651385
Validation loss: 2.5376890253027153

Epoch: 6| Step: 10
Training loss: 2.4457258661197154
Validation loss: 2.5547997997305556

Epoch: 6| Step: 11
Training loss: 2.8580068848555693
Validation loss: 2.5811986247362357

Epoch: 6| Step: 12
Training loss: 2.828349910665773
Validation loss: 2.5848913641568068

Epoch: 6| Step: 13
Training loss: 2.7122883797643795
Validation loss: 2.5960454310539536

Epoch: 97| Step: 0
Training loss: 2.400570197717601
Validation loss: 2.5980250678181926

Epoch: 6| Step: 1
Training loss: 2.738407932023048
Validation loss: 2.594196251045702

Epoch: 6| Step: 2
Training loss: 2.5863094926631653
Validation loss: 2.5805841892804877

Epoch: 6| Step: 3
Training loss: 2.3836882435920934
Validation loss: 2.564733506806671

Epoch: 6| Step: 4
Training loss: 2.923277003471597
Validation loss: 2.5498415984423413

Epoch: 6| Step: 5
Training loss: 2.887570969010843
Validation loss: 2.5322841900021955

Epoch: 6| Step: 6
Training loss: 3.2028043260785477
Validation loss: 2.535354567821135

Epoch: 6| Step: 7
Training loss: 2.2852274044077006
Validation loss: 2.51512605140227

Epoch: 6| Step: 8
Training loss: 2.7575833060580153
Validation loss: 2.5226762296933134

Epoch: 6| Step: 9
Training loss: 2.3628475074914266
Validation loss: 2.51488495860217

Epoch: 6| Step: 10
Training loss: 2.9299545776700144
Validation loss: 2.5094151171012933

Epoch: 6| Step: 11
Training loss: 3.411587793742682
Validation loss: 2.4987747194344707

Epoch: 6| Step: 12
Training loss: 2.795715091515014
Validation loss: 2.5124433357707057

Epoch: 6| Step: 13
Training loss: 2.6318077637928465
Validation loss: 2.519651707736939

Epoch: 98| Step: 0
Training loss: 3.304393132944502
Validation loss: 2.5231269369239073

Epoch: 6| Step: 1
Training loss: 2.57511874545469
Validation loss: 2.5225875989305475

Epoch: 6| Step: 2
Training loss: 3.074369821871751
Validation loss: 2.52759285379274

Epoch: 6| Step: 3
Training loss: 2.3279785519821203
Validation loss: 2.5431266070181224

Epoch: 6| Step: 4
Training loss: 2.265491560590857
Validation loss: 2.555807466680358

Epoch: 6| Step: 5
Training loss: 2.645269969726727
Validation loss: 2.6066517768849815

Epoch: 6| Step: 6
Training loss: 2.655079662327604
Validation loss: 2.636602972687435

Epoch: 6| Step: 7
Training loss: 2.9284089006788645
Validation loss: 2.580965587183717

Epoch: 6| Step: 8
Training loss: 2.786686245638073
Validation loss: 2.534206111018675

Epoch: 6| Step: 9
Training loss: 2.682312683220658
Validation loss: 2.5188102624779822

Epoch: 6| Step: 10
Training loss: 2.466834955231115
Validation loss: 2.4935922561327186

Epoch: 6| Step: 11
Training loss: 3.1275958151895074
Validation loss: 2.4910711400364804

Epoch: 6| Step: 12
Training loss: 3.4006633616300954
Validation loss: 2.497494792884149

Epoch: 6| Step: 13
Training loss: 2.232142793927873
Validation loss: 2.4901560650069383

Epoch: 99| Step: 0
Training loss: 2.9862007029102253
Validation loss: 2.4930057216921004

Epoch: 6| Step: 1
Training loss: 2.537815856067067
Validation loss: 2.493726064800657

Epoch: 6| Step: 2
Training loss: 3.050017159835821
Validation loss: 2.497397219484619

Epoch: 6| Step: 3
Training loss: 2.9329730925289823
Validation loss: 2.4839188186655963

Epoch: 6| Step: 4
Training loss: 2.751098586772758
Validation loss: 2.5103539093210827

Epoch: 6| Step: 5
Training loss: 3.2995129196901396
Validation loss: 2.4937206665767953

Epoch: 6| Step: 6
Training loss: 2.664491859359174
Validation loss: 2.504907086742959

Epoch: 6| Step: 7
Training loss: 2.819718655018091
Validation loss: 2.515255002441123

Epoch: 6| Step: 8
Training loss: 2.8798442332211627
Validation loss: 2.515957038401416

Epoch: 6| Step: 9
Training loss: 2.8337844788650126
Validation loss: 2.5365377424119093

Epoch: 6| Step: 10
Training loss: 2.6300187952218543
Validation loss: 2.5726917021195783

Epoch: 6| Step: 11
Training loss: 2.7542083790939262
Validation loss: 2.5649938046279956

Epoch: 6| Step: 12
Training loss: 2.341055478285572
Validation loss: 2.5771069895538394

Epoch: 6| Step: 13
Training loss: 3.063002564591378
Validation loss: 2.607335571419159

Epoch: 100| Step: 0
Training loss: 2.687788038564925
Validation loss: 2.6124117205220267

Epoch: 6| Step: 1
Training loss: 2.2465161797055258
Validation loss: 2.5972904070758163

Epoch: 6| Step: 2
Training loss: 2.2739077995953996
Validation loss: 2.58066423996159

Epoch: 6| Step: 3
Training loss: 2.8086186223527068
Validation loss: 2.5657451669294726

Epoch: 6| Step: 4
Training loss: 2.712801773231127
Validation loss: 2.5460643070682387

Epoch: 6| Step: 5
Training loss: 2.8071939218993984
Validation loss: 2.5523106453479865

Epoch: 6| Step: 6
Training loss: 3.1295188275581625
Validation loss: 2.5282785801973695

Epoch: 6| Step: 7
Training loss: 2.9375214271575563
Validation loss: 2.497576635235391

Epoch: 6| Step: 8
Training loss: 3.006590914677728
Validation loss: 2.49316394219265

Epoch: 6| Step: 9
Training loss: 2.7058153821018616
Validation loss: 2.4872943156426106

Epoch: 6| Step: 10
Training loss: 2.9649014875698065
Validation loss: 2.484311331636569

Epoch: 6| Step: 11
Training loss: 2.7027875215520947
Validation loss: 2.4851981489292645

Epoch: 6| Step: 12
Training loss: 2.813089097104731
Validation loss: 2.488765508255316

Epoch: 6| Step: 13
Training loss: 3.2376291610109575
Validation loss: 2.4962479810451708

Epoch: 101| Step: 0
Training loss: 2.6032430816649312
Validation loss: 2.502454778948173

Epoch: 6| Step: 1
Training loss: 2.2650160398610066
Validation loss: 2.5091313389877907

Epoch: 6| Step: 2
Training loss: 2.609527035241492
Validation loss: 2.5458937168252613

Epoch: 6| Step: 3
Training loss: 2.5658526934043757
Validation loss: 2.5747250001213033

Epoch: 6| Step: 4
Training loss: 2.9265552917815327
Validation loss: 2.59206117657482

Epoch: 6| Step: 5
Training loss: 3.1018705815582197
Validation loss: 2.5502852802078606

Epoch: 6| Step: 6
Training loss: 2.550696098460269
Validation loss: 2.5421378776283103

Epoch: 6| Step: 7
Training loss: 2.8784321740134
Validation loss: 2.5461938972636893

Epoch: 6| Step: 8
Training loss: 2.929369611659872
Validation loss: 2.5228079439717663

Epoch: 6| Step: 9
Training loss: 2.6288650758871666
Validation loss: 2.5222894928560797

Epoch: 6| Step: 10
Training loss: 2.5049153643718216
Validation loss: 2.5154917447360323

Epoch: 6| Step: 11
Training loss: 3.1302936730623627
Validation loss: 2.4936875614640917

Epoch: 6| Step: 12
Training loss: 2.6486909008048847
Validation loss: 2.4921287117961812

Epoch: 6| Step: 13
Training loss: 3.3127275784607217
Validation loss: 2.4961504410713427

Epoch: 102| Step: 0
Training loss: 3.0145242688329468
Validation loss: 2.4905319946461852

Epoch: 6| Step: 1
Training loss: 2.778012309240063
Validation loss: 2.508383625728127

Epoch: 6| Step: 2
Training loss: 3.1652498254513075
Validation loss: 2.5053975678488145

Epoch: 6| Step: 3
Training loss: 3.4056712367572968
Validation loss: 2.49956521898867

Epoch: 6| Step: 4
Training loss: 2.161061985184274
Validation loss: 2.5096964094991088

Epoch: 6| Step: 5
Training loss: 2.412992271047356
Validation loss: 2.5109367895546177

Epoch: 6| Step: 6
Training loss: 2.6971673305315558
Validation loss: 2.4945954365463745

Epoch: 6| Step: 7
Training loss: 2.0483325689866345
Validation loss: 2.4938442923278155

Epoch: 6| Step: 8
Training loss: 3.1225677179914584
Validation loss: 2.4993326434660745

Epoch: 6| Step: 9
Training loss: 2.3856651365538104
Validation loss: 2.5183163987150894

Epoch: 6| Step: 10
Training loss: 1.9408160719125078
Validation loss: 2.5117554041002017

Epoch: 6| Step: 11
Training loss: 3.2509086512413448
Validation loss: 2.5388801725062375

Epoch: 6| Step: 12
Training loss: 2.935623543576323
Validation loss: 2.5434148886136296

Epoch: 6| Step: 13
Training loss: 2.160699758739796
Validation loss: 2.5377082902484447

Epoch: 103| Step: 0
Training loss: 2.468641254589225
Validation loss: 2.544419592311645

Epoch: 6| Step: 1
Training loss: 2.804139660218226
Validation loss: 2.545975956816228

Epoch: 6| Step: 2
Training loss: 2.68545330092659
Validation loss: 2.5374397457381948

Epoch: 6| Step: 3
Training loss: 3.170408313820599
Validation loss: 2.508271257262445

Epoch: 6| Step: 4
Training loss: 2.9652567338358065
Validation loss: 2.4869669692265397

Epoch: 6| Step: 5
Training loss: 2.235603794917682
Validation loss: 2.4886817186806907

Epoch: 6| Step: 6
Training loss: 3.1868016094967406
Validation loss: 2.4771789097321393

Epoch: 6| Step: 7
Training loss: 2.5847142948186446
Validation loss: 2.476945992241403

Epoch: 6| Step: 8
Training loss: 2.794748360867885
Validation loss: 2.4788650828373906

Epoch: 6| Step: 9
Training loss: 2.4365423228539145
Validation loss: 2.484740864107062

Epoch: 6| Step: 10
Training loss: 2.9085120145311203
Validation loss: 2.4697078364381357

Epoch: 6| Step: 11
Training loss: 2.549783087835792
Validation loss: 2.48034786013428

Epoch: 6| Step: 12
Training loss: 2.9954031057489034
Validation loss: 2.4749261505521485

Epoch: 6| Step: 13
Training loss: 2.8081627357200767
Validation loss: 2.4835511942498636

Epoch: 104| Step: 0
Training loss: 2.8712209660378685
Validation loss: 2.4773607215992444

Epoch: 6| Step: 1
Training loss: 3.113714975277221
Validation loss: 2.4853859937381992

Epoch: 6| Step: 2
Training loss: 1.9580772787124083
Validation loss: 2.4920450785085815

Epoch: 6| Step: 3
Training loss: 2.518818599249516
Validation loss: 2.4998149321361502

Epoch: 6| Step: 4
Training loss: 2.801108369119363
Validation loss: 2.5138678799030094

Epoch: 6| Step: 5
Training loss: 3.0096021208022017
Validation loss: 2.5180644235016136

Epoch: 6| Step: 6
Training loss: 2.920048270153152
Validation loss: 2.5468029860333345

Epoch: 6| Step: 7
Training loss: 2.8474335341361776
Validation loss: 2.5717375911122113

Epoch: 6| Step: 8
Training loss: 3.0134913352739203
Validation loss: 2.5857276624416805

Epoch: 6| Step: 9
Training loss: 3.181688583509021
Validation loss: 2.604758972407436

Epoch: 6| Step: 10
Training loss: 3.077734133307279
Validation loss: 2.6446966527085842

Epoch: 6| Step: 11
Training loss: 2.3225128324583255
Validation loss: 2.6717277389844973

Epoch: 6| Step: 12
Training loss: 1.5108117825457454
Validation loss: 2.6749178337777817

Epoch: 6| Step: 13
Training loss: 2.812142073850122
Validation loss: 2.638246198138299

Epoch: 105| Step: 0
Training loss: 3.1068988697989837
Validation loss: 2.558549599703789

Epoch: 6| Step: 1
Training loss: 2.76589705858629
Validation loss: 2.523224626875432

Epoch: 6| Step: 2
Training loss: 2.643363661076952
Validation loss: 2.4893703893936436

Epoch: 6| Step: 3
Training loss: 1.9490258497908837
Validation loss: 2.477889624385108

Epoch: 6| Step: 4
Training loss: 2.9310786085308607
Validation loss: 2.4804839428549514

Epoch: 6| Step: 5
Training loss: 3.3226614508284302
Validation loss: 2.4766478071746647

Epoch: 6| Step: 6
Training loss: 2.7193632639984813
Validation loss: 2.46415188992716

Epoch: 6| Step: 7
Training loss: 2.4170979301363915
Validation loss: 2.4777023597456185

Epoch: 6| Step: 8
Training loss: 2.642762442037257
Validation loss: 2.4844400401626743

Epoch: 6| Step: 9
Training loss: 2.4292605107688447
Validation loss: 2.4961784205028947

Epoch: 6| Step: 10
Training loss: 2.938114994683643
Validation loss: 2.5215545632073253

Epoch: 6| Step: 11
Training loss: 2.8591023299486285
Validation loss: 2.5475133169833004

Epoch: 6| Step: 12
Training loss: 2.771515602113322
Validation loss: 2.5712878102357295

Epoch: 6| Step: 13
Training loss: 3.0724543509262086
Validation loss: 2.56531272045782

Epoch: 106| Step: 0
Training loss: 2.75276010890217
Validation loss: 2.574154428596582

Epoch: 6| Step: 1
Training loss: 2.9986725095378466
Validation loss: 2.5746008578670794

Epoch: 6| Step: 2
Training loss: 3.2185686671464255
Validation loss: 2.568053230222728

Epoch: 6| Step: 3
Training loss: 2.8403524706614798
Validation loss: 2.563007851655265

Epoch: 6| Step: 4
Training loss: 2.8953119993338072
Validation loss: 2.584147146164032

Epoch: 6| Step: 5
Training loss: 2.231854063698052
Validation loss: 2.571490109807314

Epoch: 6| Step: 6
Training loss: 2.454131290545669
Validation loss: 2.544672455698916

Epoch: 6| Step: 7
Training loss: 2.868415257822443
Validation loss: 2.520060181096899

Epoch: 6| Step: 8
Training loss: 2.944724755369794
Validation loss: 2.5204772968985147

Epoch: 6| Step: 9
Training loss: 2.2054063605072467
Validation loss: 2.5084258423219223

Epoch: 6| Step: 10
Training loss: 2.9101110262845187
Validation loss: 2.4959792362299478

Epoch: 6| Step: 11
Training loss: 2.4412165941959825
Validation loss: 2.497443449635812

Epoch: 6| Step: 12
Training loss: 2.683355107031518
Validation loss: 2.4930669664105474

Epoch: 6| Step: 13
Training loss: 2.1797431747271916
Validation loss: 2.4857060597111857

Epoch: 107| Step: 0
Training loss: 2.442783205447909
Validation loss: 2.4941077073961115

Epoch: 6| Step: 1
Training loss: 2.7109558808420906
Validation loss: 2.515582907789569

Epoch: 6| Step: 2
Training loss: 3.0440701608078777
Validation loss: 2.5190604380910497

Epoch: 6| Step: 3
Training loss: 2.6792459819279837
Validation loss: 2.514930707248134

Epoch: 6| Step: 4
Training loss: 2.6338422895066538
Validation loss: 2.519842243007911

Epoch: 6| Step: 5
Training loss: 3.298356722118639
Validation loss: 2.5072901588169327

Epoch: 6| Step: 6
Training loss: 2.1080203757631395
Validation loss: 2.518280334865646

Epoch: 6| Step: 7
Training loss: 2.9694500549504474
Validation loss: 2.524097496134755

Epoch: 6| Step: 8
Training loss: 2.697158225736752
Validation loss: 2.5311834300493947

Epoch: 6| Step: 9
Training loss: 2.9751902543468622
Validation loss: 2.549591474927231

Epoch: 6| Step: 10
Training loss: 2.190173232312143
Validation loss: 2.556099343390208

Epoch: 6| Step: 11
Training loss: 2.323088042319568
Validation loss: 2.581783878616565

Epoch: 6| Step: 12
Training loss: 2.8571869029328507
Validation loss: 2.552620230866022

Epoch: 6| Step: 13
Training loss: 3.2573918132719157
Validation loss: 2.533927794409907

Epoch: 108| Step: 0
Training loss: 1.8303769579090623
Validation loss: 2.5226519353794346

Epoch: 6| Step: 1
Training loss: 2.1528970938264664
Validation loss: 2.5060694553410756

Epoch: 6| Step: 2
Training loss: 2.8419584562632974
Validation loss: 2.5013331827032506

Epoch: 6| Step: 3
Training loss: 3.291709287987184
Validation loss: 2.487050459916402

Epoch: 6| Step: 4
Training loss: 2.526555924651791
Validation loss: 2.4854931494050465

Epoch: 6| Step: 5
Training loss: 2.427563097337067
Validation loss: 2.486808363728361

Epoch: 6| Step: 6
Training loss: 3.125988765693925
Validation loss: 2.478667189167894

Epoch: 6| Step: 7
Training loss: 3.1414016598371712
Validation loss: 2.4878084770298186

Epoch: 6| Step: 8
Training loss: 2.6879015777768327
Validation loss: 2.4857420268587718

Epoch: 6| Step: 9
Training loss: 2.69884721376816
Validation loss: 2.4993151270123684

Epoch: 6| Step: 10
Training loss: 3.0459114311701847
Validation loss: 2.521468355527278

Epoch: 6| Step: 11
Training loss: 2.5270631802461065
Validation loss: 2.530659224706017

Epoch: 6| Step: 12
Training loss: 2.3735234539447427
Validation loss: 2.5278651085561896

Epoch: 6| Step: 13
Training loss: 3.0436020707483227
Validation loss: 2.5644788187281824

Epoch: 109| Step: 0
Training loss: 2.8297244443961995
Validation loss: 2.5882421913573834

Epoch: 6| Step: 1
Training loss: 2.3643720647282924
Validation loss: 2.5785842372138013

Epoch: 6| Step: 2
Training loss: 2.52113109332817
Validation loss: 2.5756590215625472

Epoch: 6| Step: 3
Training loss: 2.7903361684705574
Validation loss: 2.579123234706611

Epoch: 6| Step: 4
Training loss: 2.6908046897229205
Validation loss: 2.595559315537324

Epoch: 6| Step: 5
Training loss: 3.015036095550218
Validation loss: 2.595168879441721

Epoch: 6| Step: 6
Training loss: 2.456538940984449
Validation loss: 2.5884033497617938

Epoch: 6| Step: 7
Training loss: 2.9361809548891085
Validation loss: 2.548737614439463

Epoch: 6| Step: 8
Training loss: 2.9534681009869335
Validation loss: 2.5234773292955257

Epoch: 6| Step: 9
Training loss: 2.570864910836528
Validation loss: 2.5084902645150935

Epoch: 6| Step: 10
Training loss: 2.5037198049369063
Validation loss: 2.493522983403262

Epoch: 6| Step: 11
Training loss: 3.0719381207552057
Validation loss: 2.4832344638655206

Epoch: 6| Step: 12
Training loss: 2.6108065578606854
Validation loss: 2.477232470056101

Epoch: 6| Step: 13
Training loss: 2.402025750675704
Validation loss: 2.499212551182022

Epoch: 110| Step: 0
Training loss: 2.3176097606028083
Validation loss: 2.5110659261179133

Epoch: 6| Step: 1
Training loss: 2.4334547269492344
Validation loss: 2.511382704994077

Epoch: 6| Step: 2
Training loss: 3.103588758774872
Validation loss: 2.542847014496902

Epoch: 6| Step: 3
Training loss: 2.9513529956106077
Validation loss: 2.5381076862015886

Epoch: 6| Step: 4
Training loss: 2.6874740067045573
Validation loss: 2.5421411641925458

Epoch: 6| Step: 5
Training loss: 3.247836933702923
Validation loss: 2.5293991419777404

Epoch: 6| Step: 6
Training loss: 3.2201797124813187
Validation loss: 2.5348229268060725

Epoch: 6| Step: 7
Training loss: 2.051059202704014
Validation loss: 2.500410657400082

Epoch: 6| Step: 8
Training loss: 2.480522864044319
Validation loss: 2.4772712891704063

Epoch: 6| Step: 9
Training loss: 2.4054643413507018
Validation loss: 2.4751968684185486

Epoch: 6| Step: 10
Training loss: 2.975436260388757
Validation loss: 2.4839337922573077

Epoch: 6| Step: 11
Training loss: 2.6129443032671626
Validation loss: 2.5068480856477366

Epoch: 6| Step: 12
Training loss: 2.7038215224937625
Validation loss: 2.513984534074783

Epoch: 6| Step: 13
Training loss: 2.1713155121876686
Validation loss: 2.540953077735869

Epoch: 111| Step: 0
Training loss: 3.012592589668926
Validation loss: 2.5418129234522358

Epoch: 6| Step: 1
Training loss: 3.170832119580979
Validation loss: 2.550147120739532

Epoch: 6| Step: 2
Training loss: 2.5931446334158132
Validation loss: 2.538700332243406

Epoch: 6| Step: 3
Training loss: 2.77601164514699
Validation loss: 2.537394904055587

Epoch: 6| Step: 4
Training loss: 3.0069680353716883
Validation loss: 2.5528645394421736

Epoch: 6| Step: 5
Training loss: 3.0341078667171675
Validation loss: 2.554286166989904

Epoch: 6| Step: 6
Training loss: 2.502499475317108
Validation loss: 2.5471259025687263

Epoch: 6| Step: 7
Training loss: 2.0458716342963834
Validation loss: 2.525574101945635

Epoch: 6| Step: 8
Training loss: 2.806749016587386
Validation loss: 2.50555948020473

Epoch: 6| Step: 9
Training loss: 2.5648900492936964
Validation loss: 2.4787225640028208

Epoch: 6| Step: 10
Training loss: 1.3942577617470941
Validation loss: 2.4904664444808264

Epoch: 6| Step: 11
Training loss: 3.001677362090067
Validation loss: 2.482691683615305

Epoch: 6| Step: 12
Training loss: 2.9272284601871927
Validation loss: 2.4922857752180665

Epoch: 6| Step: 13
Training loss: 3.0010723740501675
Validation loss: 2.503939338775039

Epoch: 112| Step: 0
Training loss: 2.6771363328568363
Validation loss: 2.5043319722389508

Epoch: 6| Step: 1
Training loss: 2.4958581947612597
Validation loss: 2.4834727504246104

Epoch: 6| Step: 2
Training loss: 2.951017081583212
Validation loss: 2.4750629612187947

Epoch: 6| Step: 3
Training loss: 2.6288375051956225
Validation loss: 2.466919299779653

Epoch: 6| Step: 4
Training loss: 3.122600702474578
Validation loss: 2.473652984652318

Epoch: 6| Step: 5
Training loss: 1.7870672168866224
Validation loss: 2.4695841287553475

Epoch: 6| Step: 6
Training loss: 2.500595784721004
Validation loss: 2.481880061539896

Epoch: 6| Step: 7
Training loss: 2.6145611238992803
Validation loss: 2.513633929103251

Epoch: 6| Step: 8
Training loss: 2.5222477898536515
Validation loss: 2.548203419387098

Epoch: 6| Step: 9
Training loss: 2.837927590304675
Validation loss: 2.5686261880089116

Epoch: 6| Step: 10
Training loss: 2.708405381246958
Validation loss: 2.5886355563162753

Epoch: 6| Step: 11
Training loss: 2.953234958115333
Validation loss: 2.631055950254034

Epoch: 6| Step: 12
Training loss: 2.9452422358785584
Validation loss: 2.6913099381397436

Epoch: 6| Step: 13
Training loss: 2.6139243664587726
Validation loss: 2.7043684537349204

Epoch: 113| Step: 0
Training loss: 2.517669699744289
Validation loss: 2.6736990351434646

Epoch: 6| Step: 1
Training loss: 2.6052474767242417
Validation loss: 2.676962043929295

Epoch: 6| Step: 2
Training loss: 2.3956753111984503
Validation loss: 2.6539871015861443

Epoch: 6| Step: 3
Training loss: 2.3810518357531523
Validation loss: 2.593012816064373

Epoch: 6| Step: 4
Training loss: 2.1365928822045412
Validation loss: 2.5672640401221285

Epoch: 6| Step: 5
Training loss: 2.8727074480305532
Validation loss: 2.559720530602022

Epoch: 6| Step: 6
Training loss: 2.980117717184401
Validation loss: 2.548390993018214

Epoch: 6| Step: 7
Training loss: 3.2782634404044444
Validation loss: 2.536766588566884

Epoch: 6| Step: 8
Training loss: 2.22505527813427
Validation loss: 2.525734435666882

Epoch: 6| Step: 9
Training loss: 3.0866738515266303
Validation loss: 2.5065788705675685

Epoch: 6| Step: 10
Training loss: 2.2879105621610294
Validation loss: 2.5056332085133497

Epoch: 6| Step: 11
Training loss: 2.981824813865002
Validation loss: 2.490583533899143

Epoch: 6| Step: 12
Training loss: 2.5403432579585807
Validation loss: 2.4892065187220975

Epoch: 6| Step: 13
Training loss: 2.9040428722674334
Validation loss: 2.500332611271861

Epoch: 114| Step: 0
Training loss: 2.923685910034987
Validation loss: 2.4929035392662224

Epoch: 6| Step: 1
Training loss: 2.9850988658589914
Validation loss: 2.49592028157965

Epoch: 6| Step: 2
Training loss: 2.6067070942090904
Validation loss: 2.4986628145448737

Epoch: 6| Step: 3
Training loss: 2.699639780245638
Validation loss: 2.4955125044312334

Epoch: 6| Step: 4
Training loss: 2.42891177829863
Validation loss: 2.4952406536486547

Epoch: 6| Step: 5
Training loss: 2.726698732661665
Validation loss: 2.5158363889889452

Epoch: 6| Step: 6
Training loss: 2.5976891078161564
Validation loss: 2.5302378743796905

Epoch: 6| Step: 7
Training loss: 2.2263352662967324
Validation loss: 2.5447765235768833

Epoch: 6| Step: 8
Training loss: 2.9732743972730624
Validation loss: 2.5616302144587344

Epoch: 6| Step: 9
Training loss: 3.123687773806393
Validation loss: 2.5839367881829576

Epoch: 6| Step: 10
Training loss: 2.2598556197305144
Validation loss: 2.606525634125039

Epoch: 6| Step: 11
Training loss: 2.5710225617328706
Validation loss: 2.5808008253412678

Epoch: 6| Step: 12
Training loss: 2.477160456820068
Validation loss: 2.5523489654168423

Epoch: 6| Step: 13
Training loss: 2.53385141705125
Validation loss: 2.527969176711865

Epoch: 115| Step: 0
Training loss: 2.832600461385321
Validation loss: 2.4836241349158246

Epoch: 6| Step: 1
Training loss: 2.802823863445056
Validation loss: 2.4748563066610347

Epoch: 6| Step: 2
Training loss: 2.6953203726390913
Validation loss: 2.4687525742832697

Epoch: 6| Step: 3
Training loss: 2.480185857545755
Validation loss: 2.4645192759742933

Epoch: 6| Step: 4
Training loss: 2.968874316373278
Validation loss: 2.47292551205162

Epoch: 6| Step: 5
Training loss: 3.0037338544687087
Validation loss: 2.470597180078621

Epoch: 6| Step: 6
Training loss: 2.399136419694123
Validation loss: 2.4753809018341633

Epoch: 6| Step: 7
Training loss: 2.8367760629624055
Validation loss: 2.4982551022834723

Epoch: 6| Step: 8
Training loss: 2.85645249064269
Validation loss: 2.5036263201819517

Epoch: 6| Step: 9
Training loss: 2.5696063245579093
Validation loss: 2.552081076491469

Epoch: 6| Step: 10
Training loss: 2.66003202576826
Validation loss: 2.594205936587015

Epoch: 6| Step: 11
Training loss: 2.8040496185799304
Validation loss: 2.5914270362296237

Epoch: 6| Step: 12
Training loss: 2.1093404131279025
Validation loss: 2.5451783871241203

Epoch: 6| Step: 13
Training loss: 2.2826768776087385
Validation loss: 2.520602149976466

Epoch: 116| Step: 0
Training loss: 2.8794743095215027
Validation loss: 2.4986066668143336

Epoch: 6| Step: 1
Training loss: 2.7253491344248904
Validation loss: 2.4750591578021566

Epoch: 6| Step: 2
Training loss: 2.035399438895101
Validation loss: 2.4628301236064933

Epoch: 6| Step: 3
Training loss: 2.4377190907145914
Validation loss: 2.4631610399325616

Epoch: 6| Step: 4
Training loss: 2.4914723868098236
Validation loss: 2.4541283285169313

Epoch: 6| Step: 5
Training loss: 2.0973527571564254
Validation loss: 2.4590410823539153

Epoch: 6| Step: 6
Training loss: 2.733354825036139
Validation loss: 2.456421847472798

Epoch: 6| Step: 7
Training loss: 2.8939475270162616
Validation loss: 2.466979641654875

Epoch: 6| Step: 8
Training loss: 2.41362316491754
Validation loss: 2.4748269870944113

Epoch: 6| Step: 9
Training loss: 2.9427616800969747
Validation loss: 2.509141764641598

Epoch: 6| Step: 10
Training loss: 2.4349699338901445
Validation loss: 2.5432329406856105

Epoch: 6| Step: 11
Training loss: 2.9734934606613317
Validation loss: 2.5882037469941386

Epoch: 6| Step: 12
Training loss: 2.921032136327
Validation loss: 2.5940132783380454

Epoch: 6| Step: 13
Training loss: 3.1126572044535394
Validation loss: 2.6230897168838467

Epoch: 117| Step: 0
Training loss: 2.654076797984031
Validation loss: 2.5882618833111573

Epoch: 6| Step: 1
Training loss: 2.6901979433143293
Validation loss: 2.5263052177565566

Epoch: 6| Step: 2
Training loss: 2.5740803752286383
Validation loss: 2.478751609956902

Epoch: 6| Step: 3
Training loss: 2.2705995865189013
Validation loss: 2.4719315803312085

Epoch: 6| Step: 4
Training loss: 2.8305532242259255
Validation loss: 2.467465045655318

Epoch: 6| Step: 5
Training loss: 2.453749656113665
Validation loss: 2.466943477859066

Epoch: 6| Step: 6
Training loss: 2.988657490101475
Validation loss: 2.4765177868569874

Epoch: 6| Step: 7
Training loss: 2.455698692049086
Validation loss: 2.4744056332698765

Epoch: 6| Step: 8
Training loss: 2.465242912750378
Validation loss: 2.4773474561119024

Epoch: 6| Step: 9
Training loss: 3.205696078929484
Validation loss: 2.503919545764929

Epoch: 6| Step: 10
Training loss: 2.4689222831005098
Validation loss: 2.5209890531239676

Epoch: 6| Step: 11
Training loss: 2.849677981203774
Validation loss: 2.507232196103813

Epoch: 6| Step: 12
Training loss: 2.068438333043497
Validation loss: 2.5232644168590572

Epoch: 6| Step: 13
Training loss: 2.930037902222337
Validation loss: 2.502411130836561

Epoch: 118| Step: 0
Training loss: 2.6964957915474312
Validation loss: 2.516421178367673

Epoch: 6| Step: 1
Training loss: 1.8800319543111381
Validation loss: 2.5195768135506165

Epoch: 6| Step: 2
Training loss: 3.04270845800859
Validation loss: 2.530496387624373

Epoch: 6| Step: 3
Training loss: 2.420771587413851
Validation loss: 2.5364359714660814

Epoch: 6| Step: 4
Training loss: 2.7447906918798424
Validation loss: 2.5603719539405008

Epoch: 6| Step: 5
Training loss: 2.2659573015329757
Validation loss: 2.5568619748389567

Epoch: 6| Step: 6
Training loss: 2.99419429404974
Validation loss: 2.565569837864323

Epoch: 6| Step: 7
Training loss: 2.541371865190893
Validation loss: 2.5617991283572157

Epoch: 6| Step: 8
Training loss: 2.5125243228475203
Validation loss: 2.5471171300419204

Epoch: 6| Step: 9
Training loss: 3.166284605033673
Validation loss: 2.5171658665509016

Epoch: 6| Step: 10
Training loss: 2.4207534654303537
Validation loss: 2.4895835818455647

Epoch: 6| Step: 11
Training loss: 2.4457886448622075
Validation loss: 2.4791818761182363

Epoch: 6| Step: 12
Training loss: 2.6136124975449206
Validation loss: 2.472500433282084

Epoch: 6| Step: 13
Training loss: 2.5213675024957394
Validation loss: 2.484641482569307

Epoch: 119| Step: 0
Training loss: 2.3923939661268494
Validation loss: 2.4633902004305854

Epoch: 6| Step: 1
Training loss: 2.357853683203019
Validation loss: 2.474115962051537

Epoch: 6| Step: 2
Training loss: 2.017628583249422
Validation loss: 2.4890115092969602

Epoch: 6| Step: 3
Training loss: 3.110714417855346
Validation loss: 2.5004007848840057

Epoch: 6| Step: 4
Training loss: 2.751338632933302
Validation loss: 2.536240387521235

Epoch: 6| Step: 5
Training loss: 2.6224370888145323
Validation loss: 2.547523495997105

Epoch: 6| Step: 6
Training loss: 2.799699092772436
Validation loss: 2.550727539019634

Epoch: 6| Step: 7
Training loss: 2.3177029613189735
Validation loss: 2.5379125886759635

Epoch: 6| Step: 8
Training loss: 3.0551860431768882
Validation loss: 2.5079592383052915

Epoch: 6| Step: 9
Training loss: 2.113863767768993
Validation loss: 2.5044746367480766

Epoch: 6| Step: 10
Training loss: 3.0726936561136857
Validation loss: 2.49837934097501

Epoch: 6| Step: 11
Training loss: 2.4019667911187295
Validation loss: 2.4726493355963894

Epoch: 6| Step: 12
Training loss: 2.348910537763519
Validation loss: 2.484121471059848

Epoch: 6| Step: 13
Training loss: 2.6176564266241433
Validation loss: 2.4875169583708905

Epoch: 120| Step: 0
Training loss: 2.955178813139224
Validation loss: 2.4956900145749263

Epoch: 6| Step: 1
Training loss: 2.95141261271996
Validation loss: 2.4927456899593774

Epoch: 6| Step: 2
Training loss: 2.2233351490217323
Validation loss: 2.513244301365883

Epoch: 6| Step: 3
Training loss: 2.348707728469938
Validation loss: 2.5159813352057148

Epoch: 6| Step: 4
Training loss: 2.7597003991153093
Validation loss: 2.486085692422204

Epoch: 6| Step: 5
Training loss: 2.7776966326835324
Validation loss: 2.517386276766191

Epoch: 6| Step: 6
Training loss: 2.296849672346538
Validation loss: 2.5066827639310763

Epoch: 6| Step: 7
Training loss: 1.7973777399411652
Validation loss: 2.5052743372241393

Epoch: 6| Step: 8
Training loss: 3.057692510699896
Validation loss: 2.4636242345869874

Epoch: 6| Step: 9
Training loss: 2.559667557051992
Validation loss: 2.4914410545949384

Epoch: 6| Step: 10
Training loss: 2.438131592914475
Validation loss: 2.524531346392099

Epoch: 6| Step: 11
Training loss: 2.43011627829567
Validation loss: 2.565402854085428

Epoch: 6| Step: 12
Training loss: 2.961136380967113
Validation loss: 2.612242004605456

Epoch: 6| Step: 13
Training loss: 2.4635499681221344
Validation loss: 2.5978364635065545

Epoch: 121| Step: 0
Training loss: 2.803977430135795
Validation loss: 2.530226163770449

Epoch: 6| Step: 1
Training loss: 2.6643426026341706
Validation loss: 2.479028470606667

Epoch: 6| Step: 2
Training loss: 2.8338144305307944
Validation loss: 2.4350054081180437

Epoch: 6| Step: 3
Training loss: 2.742122812404752
Validation loss: 2.4489213091957387

Epoch: 6| Step: 4
Training loss: 2.323982701215854
Validation loss: 2.452637502171505

Epoch: 6| Step: 5
Training loss: 2.6471816604760603
Validation loss: 2.4770218804292754

Epoch: 6| Step: 6
Training loss: 2.1691968034352467
Validation loss: 2.5343545004624035

Epoch: 6| Step: 7
Training loss: 2.6765358410792004
Validation loss: 2.645014071069364

Epoch: 6| Step: 8
Training loss: 2.4745390414605306
Validation loss: 2.684973144818588

Epoch: 6| Step: 9
Training loss: 2.9106326948493813
Validation loss: 2.6189244889948746

Epoch: 6| Step: 10
Training loss: 2.36047610426631
Validation loss: 2.5270410666386924

Epoch: 6| Step: 11
Training loss: 1.9711124838091116
Validation loss: 2.489302011533071

Epoch: 6| Step: 12
Training loss: 2.7897842285506806
Validation loss: 2.465649648840258

Epoch: 6| Step: 13
Training loss: 2.8016080394134986
Validation loss: 2.4860966179156145

Epoch: 122| Step: 0
Training loss: 2.5322347538613657
Validation loss: 2.48572369578653

Epoch: 6| Step: 1
Training loss: 2.5344540133312576
Validation loss: 2.472455867534097

Epoch: 6| Step: 2
Training loss: 2.623622442000786
Validation loss: 2.515005729597168

Epoch: 6| Step: 3
Training loss: 2.575031806230864
Validation loss: 2.537318963475497

Epoch: 6| Step: 4
Training loss: 2.1891034380442775
Validation loss: 2.547337335883483

Epoch: 6| Step: 5
Training loss: 2.960576098285642
Validation loss: 2.563866893765941

Epoch: 6| Step: 6
Training loss: 2.4473554468377707
Validation loss: 2.565442530505262

Epoch: 6| Step: 7
Training loss: 3.1092201079314776
Validation loss: 2.604896378857403

Epoch: 6| Step: 8
Training loss: 2.092334211702493
Validation loss: 2.5583642008233567

Epoch: 6| Step: 9
Training loss: 2.5955009525233392
Validation loss: 2.482847675432685

Epoch: 6| Step: 10
Training loss: 2.648405091754148
Validation loss: 2.4414152364585955

Epoch: 6| Step: 11
Training loss: 2.6795825103567106
Validation loss: 2.4159867018207892

Epoch: 6| Step: 12
Training loss: 2.1079698191442047
Validation loss: 2.4234214817676434

Epoch: 6| Step: 13
Training loss: 2.4217125622819
Validation loss: 2.443249424991907

Epoch: 123| Step: 0
Training loss: 2.8231597645569724
Validation loss: 2.4325287748506454

Epoch: 6| Step: 1
Training loss: 3.044909973317022
Validation loss: 2.428444794003669

Epoch: 6| Step: 2
Training loss: 2.36971417534418
Validation loss: 2.4311180022606074

Epoch: 6| Step: 3
Training loss: 2.021373742066208
Validation loss: 2.421384486376819

Epoch: 6| Step: 4
Training loss: 2.156995782557128
Validation loss: 2.433464855788419

Epoch: 6| Step: 5
Training loss: 2.5748434741398945
Validation loss: 2.4298587281469426

Epoch: 6| Step: 6
Training loss: 2.85302061660864
Validation loss: 2.461736275662562

Epoch: 6| Step: 7
Training loss: 2.166586825538089
Validation loss: 2.4739577720308987

Epoch: 6| Step: 8
Training loss: 2.5156410169387713
Validation loss: 2.4886537250141765

Epoch: 6| Step: 9
Training loss: 2.3781358194794326
Validation loss: 2.501025321880971

Epoch: 6| Step: 10
Training loss: 2.6080574775400067
Validation loss: 2.5693359195398995

Epoch: 6| Step: 11
Training loss: 2.8066119973694397
Validation loss: 2.587777954298787

Epoch: 6| Step: 12
Training loss: 2.368060967472439
Validation loss: 2.5754974399674113

Epoch: 6| Step: 13
Training loss: 1.789433336762655
Validation loss: 2.5568145700551224

Epoch: 124| Step: 0
Training loss: 2.1924317488274525
Validation loss: 2.513445323194124

Epoch: 6| Step: 1
Training loss: 2.5713502591939013
Validation loss: 2.488635803751659

Epoch: 6| Step: 2
Training loss: 2.7686234077119387
Validation loss: 2.4219271757107252

Epoch: 6| Step: 3
Training loss: 2.5616460168023156
Validation loss: 2.3964431480612842

Epoch: 6| Step: 4
Training loss: 2.925913584916083
Validation loss: 2.4072417255930705

Epoch: 6| Step: 5
Training loss: 1.8182464794018378
Validation loss: 2.410135834658418

Epoch: 6| Step: 6
Training loss: 2.179271261745377
Validation loss: 2.4210469407857635

Epoch: 6| Step: 7
Training loss: 2.10224897666468
Validation loss: 2.4305410150502227

Epoch: 6| Step: 8
Training loss: 2.622062492714131
Validation loss: 2.488240382351084

Epoch: 6| Step: 9
Training loss: 2.526788712508894
Validation loss: 2.555802639927738

Epoch: 6| Step: 10
Training loss: 2.793834290736997
Validation loss: 2.642821063140146

Epoch: 6| Step: 11
Training loss: 2.3055627227835216
Validation loss: 2.6505812223683067

Epoch: 6| Step: 12
Training loss: 2.8752164344589626
Validation loss: 2.65676869896178

Epoch: 6| Step: 13
Training loss: 2.5979132274206216
Validation loss: 2.6683501292890517

Epoch: 125| Step: 0
Training loss: 2.4341909003517923
Validation loss: 2.600496875449691

Epoch: 6| Step: 1
Training loss: 2.68066441826045
Validation loss: 2.5327994059487717

Epoch: 6| Step: 2
Training loss: 2.314473006408543
Validation loss: 2.5286234591517873

Epoch: 6| Step: 3
Training loss: 2.525183295216107
Validation loss: 2.5241116956168064

Epoch: 6| Step: 4
Training loss: 2.8269577568198634
Validation loss: 2.499811670941718

Epoch: 6| Step: 5
Training loss: 2.619046134865741
Validation loss: 2.4576120801106796

Epoch: 6| Step: 6
Training loss: 2.722408945681985
Validation loss: 2.461880364109118

Epoch: 6| Step: 7
Training loss: 1.6524901990268017
Validation loss: 2.4590880930130723

Epoch: 6| Step: 8
Training loss: 2.956377125883844
Validation loss: 2.482450918978456

Epoch: 6| Step: 9
Training loss: 2.433187337528049
Validation loss: 2.4909298660731696

Epoch: 6| Step: 10
Training loss: 2.188146985969693
Validation loss: 2.5100084075898046

Epoch: 6| Step: 11
Training loss: 2.5044712137466942
Validation loss: 2.507606364726196

Epoch: 6| Step: 12
Training loss: 2.3342642516556724
Validation loss: 2.4759873547602282

Epoch: 6| Step: 13
Training loss: 2.1728310436180047
Validation loss: 2.453441609108415

Epoch: 126| Step: 0
Training loss: 2.2110265707130083
Validation loss: 2.525391422904768

Epoch: 6| Step: 1
Training loss: 2.34987257754038
Validation loss: 2.580917138142043

Epoch: 6| Step: 2
Training loss: 2.3074212881035523
Validation loss: 2.472446719122807

Epoch: 6| Step: 3
Training loss: 2.6803176183519377
Validation loss: 2.46853292187623

Epoch: 6| Step: 4
Training loss: 2.351169287164737
Validation loss: 2.5252911793226107

Epoch: 6| Step: 5
Training loss: 2.3940228020419476
Validation loss: 2.526757071478902

Epoch: 6| Step: 6
Training loss: 2.2122862243824892
Validation loss: 2.571704623026028

Epoch: 6| Step: 7
Training loss: 3.064796987658648
Validation loss: 2.61668566669531

Epoch: 6| Step: 8
Training loss: 2.735483173879905
Validation loss: 2.465866602354821

Epoch: 6| Step: 9
Training loss: 2.1969600481959475
Validation loss: 2.3826777228599916

Epoch: 6| Step: 10
Training loss: 2.954968558207122
Validation loss: 2.4064370844240317

Epoch: 6| Step: 11
Training loss: 2.558969997085524
Validation loss: 2.40822083364124

Epoch: 6| Step: 12
Training loss: 2.363760201337841
Validation loss: 2.417754808426782

Epoch: 6| Step: 13
Training loss: 1.8645764853353501
Validation loss: 2.41339824429055

Epoch: 127| Step: 0
Training loss: 2.8474208069892297
Validation loss: 2.426288849852633

Epoch: 6| Step: 1
Training loss: 2.4697769540010386
Validation loss: 2.423095389295071

Epoch: 6| Step: 2
Training loss: 2.106253341536319
Validation loss: 2.4617642442577794

Epoch: 6| Step: 3
Training loss: 2.5101589740699213
Validation loss: 2.5283084789368613

Epoch: 6| Step: 4
Training loss: 3.3187760691507897
Validation loss: 2.619462420290895

Epoch: 6| Step: 5
Training loss: 2.4432023666517764
Validation loss: 2.671248904670842

Epoch: 6| Step: 6
Training loss: 2.227431706538654
Validation loss: 2.698980520686471

Epoch: 6| Step: 7
Training loss: 2.5601993560654317
Validation loss: 2.65629814533802

Epoch: 6| Step: 8
Training loss: 2.31036463943484
Validation loss: 2.630779466946366

Epoch: 6| Step: 9
Training loss: 2.4867728315842927
Validation loss: 2.609346242855133

Epoch: 6| Step: 10
Training loss: 1.9943770997918915
Validation loss: 2.548342215403844

Epoch: 6| Step: 11
Training loss: 2.512482190424869
Validation loss: 2.5282563464151333

Epoch: 6| Step: 12
Training loss: 2.5165418766568886
Validation loss: 2.5138061129616402

Epoch: 6| Step: 13
Training loss: 2.3268577659884735
Validation loss: 2.4563486323618537

Epoch: 128| Step: 0
Training loss: 1.4132622830882686
Validation loss: 2.4795802857048357

Epoch: 6| Step: 1
Training loss: 2.3570015191974365
Validation loss: 2.4831285404904753

Epoch: 6| Step: 2
Training loss: 2.1087940687675015
Validation loss: 2.514866393460482

Epoch: 6| Step: 3
Training loss: 2.9235484181193887
Validation loss: 2.55250378163721

Epoch: 6| Step: 4
Training loss: 3.0216079420333286
Validation loss: 2.5751132012714977

Epoch: 6| Step: 5
Training loss: 2.4925567449081103
Validation loss: 2.5935545243635656

Epoch: 6| Step: 6
Training loss: 2.1724534396503716
Validation loss: 2.565333674705182

Epoch: 6| Step: 7
Training loss: 2.068121675803959
Validation loss: 2.5745502706413586

Epoch: 6| Step: 8
Training loss: 2.630734311128182
Validation loss: 2.6488861005100186

Epoch: 6| Step: 9
Training loss: 2.6594906056756895
Validation loss: 2.6220512254547725

Epoch: 6| Step: 10
Training loss: 2.793726848873333
Validation loss: 2.546799365249956

Epoch: 6| Step: 11
Training loss: 2.273201317333328
Validation loss: 2.473035540061652

Epoch: 6| Step: 12
Training loss: 2.3367425558343635
Validation loss: 2.432074724729602

Epoch: 6| Step: 13
Training loss: 2.1895175893721253
Validation loss: 2.397950995054229

Epoch: 129| Step: 0
Training loss: 1.9289751475479895
Validation loss: 2.3895528116694518

Epoch: 6| Step: 1
Training loss: 2.4374931530978556
Validation loss: 2.3749236951140626

Epoch: 6| Step: 2
Training loss: 2.517972526109535
Validation loss: 2.3868712035891932

Epoch: 6| Step: 3
Training loss: 2.470126480539914
Validation loss: 2.4091948106336316

Epoch: 6| Step: 4
Training loss: 2.1861029387141824
Validation loss: 2.456777254996793

Epoch: 6| Step: 5
Training loss: 2.4315155119670786
Validation loss: 2.5506014920203124

Epoch: 6| Step: 6
Training loss: 3.1388461261038163
Validation loss: 2.669550986166019

Epoch: 6| Step: 7
Training loss: 2.72941628011065
Validation loss: 2.62859235595318

Epoch: 6| Step: 8
Training loss: 2.370181566518515
Validation loss: 2.4658692472255015

Epoch: 6| Step: 9
Training loss: 2.5426149840034102
Validation loss: 2.3941471406247277

Epoch: 6| Step: 10
Training loss: 2.5007902803648263
Validation loss: 2.3816860441930596

Epoch: 6| Step: 11
Training loss: 2.5333997286913195
Validation loss: 2.3924799336652844

Epoch: 6| Step: 12
Training loss: 2.574117424089369
Validation loss: 2.4147724186048913

Epoch: 6| Step: 13
Training loss: 1.971936508162502
Validation loss: 2.444838338096992

Epoch: 130| Step: 0
Training loss: 2.2184972484778758
Validation loss: 2.4575346682987207

Epoch: 6| Step: 1
Training loss: 2.9512200241149937
Validation loss: 2.5139862982450407

Epoch: 6| Step: 2
Training loss: 2.398459965603763
Validation loss: 2.5725057588586138

Epoch: 6| Step: 3
Training loss: 2.2624708647985945
Validation loss: 2.5813211516398646

Epoch: 6| Step: 4
Training loss: 2.4889235214064245
Validation loss: 2.6070106370395014

Epoch: 6| Step: 5
Training loss: 2.460660597950905
Validation loss: 2.643042244215402

Epoch: 6| Step: 6
Training loss: 2.1142548805551264
Validation loss: 2.640971889672733

Epoch: 6| Step: 7
Training loss: 2.3120263104245193
Validation loss: 2.6191159676850684

Epoch: 6| Step: 8
Training loss: 2.596347014258866
Validation loss: 2.6284555825591673

Epoch: 6| Step: 9
Training loss: 2.446886232625579
Validation loss: 2.6709145675969683

Epoch: 6| Step: 10
Training loss: 2.8551033506376378
Validation loss: 2.6279661132828305

Epoch: 6| Step: 11
Training loss: 2.2386267696609843
Validation loss: 2.5116584888107942

Epoch: 6| Step: 12
Training loss: 2.1077159998063886
Validation loss: 2.4613783179005644

Epoch: 6| Step: 13
Training loss: 2.5842814602696733
Validation loss: 2.433648696189842

Epoch: 131| Step: 0
Training loss: 2.455403332956999
Validation loss: 2.4102376852077163

Epoch: 6| Step: 1
Training loss: 2.474126249269964
Validation loss: 2.4155087472790284

Epoch: 6| Step: 2
Training loss: 2.578106966822585
Validation loss: 2.415397511985191

Epoch: 6| Step: 3
Training loss: 2.9019954261875194
Validation loss: 2.424607809879994

Epoch: 6| Step: 4
Training loss: 1.9658975676029953
Validation loss: 2.434174561265858

Epoch: 6| Step: 5
Training loss: 2.3389925674248624
Validation loss: 2.467080370619299

Epoch: 6| Step: 6
Training loss: 2.55770061716613
Validation loss: 2.4790746193151243

Epoch: 6| Step: 7
Training loss: 2.3891162973537923
Validation loss: 2.4781676489301803

Epoch: 6| Step: 8
Training loss: 1.9664260226723054
Validation loss: 2.509267041770636

Epoch: 6| Step: 9
Training loss: 1.6375868504911766
Validation loss: 2.5692433006254043

Epoch: 6| Step: 10
Training loss: 2.170734352984166
Validation loss: 2.6309585536150952

Epoch: 6| Step: 11
Training loss: 2.82516079672897
Validation loss: 2.6231059757991106

Epoch: 6| Step: 12
Training loss: 2.8910151037971596
Validation loss: 2.6323499030036106

Epoch: 6| Step: 13
Training loss: 2.563073443006104
Validation loss: 2.545209587626997

Epoch: 132| Step: 0
Training loss: 2.2974358736704557
Validation loss: 2.5056524856235214

Epoch: 6| Step: 1
Training loss: 1.807924414544326
Validation loss: 2.4536471417655354

Epoch: 6| Step: 2
Training loss: 2.5987627239934152
Validation loss: 2.4395443378994908

Epoch: 6| Step: 3
Training loss: 2.2158650729557996
Validation loss: 2.4211198299592023

Epoch: 6| Step: 4
Training loss: 2.787139913796645
Validation loss: 2.4288592919060603

Epoch: 6| Step: 5
Training loss: 2.5609695702546933
Validation loss: 2.466425407062135

Epoch: 6| Step: 6
Training loss: 2.1300938085037764
Validation loss: 2.5390387390892837

Epoch: 6| Step: 7
Training loss: 2.616249576865653
Validation loss: 2.561543279810102

Epoch: 6| Step: 8
Training loss: 2.4809737044466558
Validation loss: 2.5370591749857447

Epoch: 6| Step: 9
Training loss: 2.2459830348052625
Validation loss: 2.494339204784721

Epoch: 6| Step: 10
Training loss: 2.558940741618729
Validation loss: 2.5114950526568935

Epoch: 6| Step: 11
Training loss: 2.7551016735832103
Validation loss: 2.5509006501382374

Epoch: 6| Step: 12
Training loss: 1.827232338524966
Validation loss: 2.5856040782019996

Epoch: 6| Step: 13
Training loss: 1.0041638351864817
Validation loss: 2.635031512497112

Epoch: 133| Step: 0
Training loss: 2.5404144913101665
Validation loss: 2.65200142378478

Epoch: 6| Step: 1
Training loss: 1.676161716193034
Validation loss: 2.6659050367827084

Epoch: 6| Step: 2
Training loss: 2.757041585659112
Validation loss: 2.6204647736743603

Epoch: 6| Step: 3
Training loss: 1.996062933577558
Validation loss: 2.5555032433292166

Epoch: 6| Step: 4
Training loss: 2.0328792200420587
Validation loss: 2.5168053180199843

Epoch: 6| Step: 5
Training loss: 1.760744354026676
Validation loss: 2.5236275269692863

Epoch: 6| Step: 6
Training loss: 2.2128222085421667
Validation loss: 2.557428930264625

Epoch: 6| Step: 7
Training loss: 2.87884612518839
Validation loss: 2.5602039141799224

Epoch: 6| Step: 8
Training loss: 2.3241314527001116
Validation loss: 2.4921320859138794

Epoch: 6| Step: 9
Training loss: 1.8183411495881074
Validation loss: 2.463716325723561

Epoch: 6| Step: 10
Training loss: 2.5206567896875023
Validation loss: 2.4770822132071184

Epoch: 6| Step: 11
Training loss: 2.823124210474944
Validation loss: 2.463244921211794

Epoch: 6| Step: 12
Training loss: 1.9115448255658838
Validation loss: 2.4124882908976413

Epoch: 6| Step: 13
Training loss: 2.6074315674562363
Validation loss: 2.4050121727293123

Epoch: 134| Step: 0
Training loss: 2.5865453829630445
Validation loss: 2.393225853782327

Epoch: 6| Step: 1
Training loss: 1.2797174359407744
Validation loss: 2.4142172971166294

Epoch: 6| Step: 2
Training loss: 2.82259439315612
Validation loss: 2.449522643539764

Epoch: 6| Step: 3
Training loss: 1.8648199290051428
Validation loss: 2.52103100575136

Epoch: 6| Step: 4
Training loss: 2.891776190743937
Validation loss: 2.571772273337906

Epoch: 6| Step: 5
Training loss: 2.333730414072895
Validation loss: 2.5454994954997407

Epoch: 6| Step: 6
Training loss: 1.9731424166926
Validation loss: 2.525749682055899

Epoch: 6| Step: 7
Training loss: 2.1472026813643836
Validation loss: 2.5744676797784027

Epoch: 6| Step: 8
Training loss: 2.587229057537618
Validation loss: 2.6129962546178476

Epoch: 6| Step: 9
Training loss: 1.6501609145796503
Validation loss: 2.5193058295594115

Epoch: 6| Step: 10
Training loss: 1.880298946941032
Validation loss: 2.5243126020334907

Epoch: 6| Step: 11
Training loss: 3.0380581566654135
Validation loss: 2.464999721024298

Epoch: 6| Step: 12
Training loss: 2.1538887917050107
Validation loss: 2.4270616780652525

Epoch: 6| Step: 13
Training loss: 2.3625513384049714
Validation loss: 2.4029619295447087

Epoch: 135| Step: 0
Training loss: 2.192310275978491
Validation loss: 2.4145584900475394

Epoch: 6| Step: 1
Training loss: 1.9795338607940691
Validation loss: 2.416356641454072

Epoch: 6| Step: 2
Training loss: 2.4920906837336694
Validation loss: 2.4247282350164494

Epoch: 6| Step: 3
Training loss: 2.167370412928057
Validation loss: 2.4643067988924208

Epoch: 6| Step: 4
Training loss: 1.881324148142611
Validation loss: 2.517293019480036

Epoch: 6| Step: 5
Training loss: 2.0480069823220557
Validation loss: 2.5299419556502443

Epoch: 6| Step: 6
Training loss: 2.2071419747183736
Validation loss: 2.6108343611837093

Epoch: 6| Step: 7
Training loss: 2.3611549585297653
Validation loss: 2.6218425348171155

Epoch: 6| Step: 8
Training loss: 2.675302727227708
Validation loss: 2.5827426598991114

Epoch: 6| Step: 9
Training loss: 2.363917947548971
Validation loss: 2.468147057784239

Epoch: 6| Step: 10
Training loss: 2.844258357292344
Validation loss: 2.4049854149166277

Epoch: 6| Step: 11
Training loss: 2.1942655299952847
Validation loss: 2.395496578723717

Epoch: 6| Step: 12
Training loss: 2.2233875861499834
Validation loss: 2.394042579499072

Epoch: 6| Step: 13
Training loss: 2.0121842225449895
Validation loss: 2.4037947085281317

Epoch: 136| Step: 0
Training loss: 1.9946613584607598
Validation loss: 2.443554462731388

Epoch: 6| Step: 1
Training loss: 2.4365615994631686
Validation loss: 2.4521690770255917

Epoch: 6| Step: 2
Training loss: 2.4063581962535747
Validation loss: 2.5041118626544456

Epoch: 6| Step: 3
Training loss: 1.7585331774616937
Validation loss: 2.543166492870956

Epoch: 6| Step: 4
Training loss: 2.218134190166027
Validation loss: 2.545463776491796

Epoch: 6| Step: 5
Training loss: 2.2118765518342562
Validation loss: 2.5720051670413926

Epoch: 6| Step: 6
Training loss: 2.4045810608981713
Validation loss: 2.5463441302655276

Epoch: 6| Step: 7
Training loss: 2.803605319817082
Validation loss: 2.4882179989255473

Epoch: 6| Step: 8
Training loss: 1.6152804274722703
Validation loss: 2.5040812363155265

Epoch: 6| Step: 9
Training loss: 1.9528978749776351
Validation loss: 2.541751978320143

Epoch: 6| Step: 10
Training loss: 2.6979577394007728
Validation loss: 2.615794316915588

Epoch: 6| Step: 11
Training loss: 1.8440200478587285
Validation loss: 2.6032938046084526

Epoch: 6| Step: 12
Training loss: 1.9816212207062973
Validation loss: 2.5943114988355824

Epoch: 6| Step: 13
Training loss: 2.7214153860893413
Validation loss: 2.5642382720897356

Epoch: 137| Step: 0
Training loss: 2.24134178029015
Validation loss: 2.5030181714078403

Epoch: 6| Step: 1
Training loss: 2.598081258552877
Validation loss: 2.4335065258602424

Epoch: 6| Step: 2
Training loss: 1.799717918121712
Validation loss: 2.395148471429084

Epoch: 6| Step: 3
Training loss: 2.1024661478952886
Validation loss: 2.3758435243672356

Epoch: 6| Step: 4
Training loss: 2.2927298998190278
Validation loss: 2.4416944260366513

Epoch: 6| Step: 5
Training loss: 2.9887945395054243
Validation loss: 2.586544090510089

Epoch: 6| Step: 6
Training loss: 2.289209146326521
Validation loss: 2.6487255703869588

Epoch: 6| Step: 7
Training loss: 2.1995231458413427
Validation loss: 2.584716881553838

Epoch: 6| Step: 8
Training loss: 2.316865666393561
Validation loss: 2.5124641656705267

Epoch: 6| Step: 9
Training loss: 2.459390208331809
Validation loss: 2.427715928003134

Epoch: 6| Step: 10
Training loss: 1.4729891534834556
Validation loss: 2.3704466367090693

Epoch: 6| Step: 11
Training loss: 1.9241998768359863
Validation loss: 2.3886328942640502

Epoch: 6| Step: 12
Training loss: 2.096059180567176
Validation loss: 2.3551628703124337

Epoch: 6| Step: 13
Training loss: 2.2675298641303274
Validation loss: 2.3836583210308557

Epoch: 138| Step: 0
Training loss: 2.0818207654069996
Validation loss: 2.4616827473611727

Epoch: 6| Step: 1
Training loss: 1.6822943751389123
Validation loss: 2.5391661425468004

Epoch: 6| Step: 2
Training loss: 2.5341113836532014
Validation loss: 2.5985663064061573

Epoch: 6| Step: 3
Training loss: 2.153000525432404
Validation loss: 2.5521461641480903

Epoch: 6| Step: 4
Training loss: 1.895997351234131
Validation loss: 2.5133131080520434

Epoch: 6| Step: 5
Training loss: 2.5080794432984943
Validation loss: 2.4651233134989647

Epoch: 6| Step: 6
Training loss: 1.9971359727133902
Validation loss: 2.4844147125721006

Epoch: 6| Step: 7
Training loss: 1.9012836737726164
Validation loss: 2.5126907136054655

Epoch: 6| Step: 8
Training loss: 2.593000188707609
Validation loss: 2.540188853137301

Epoch: 6| Step: 9
Training loss: 2.225679778078675
Validation loss: 2.587926911501916

Epoch: 6| Step: 10
Training loss: 2.1703261746441944
Validation loss: 2.6033636296373497

Epoch: 6| Step: 11
Training loss: 2.307351644753965
Validation loss: 2.5793863899265346

Epoch: 6| Step: 12
Training loss: 2.5424456314680453
Validation loss: 2.527959222181463

Epoch: 6| Step: 13
Training loss: 2.0601079536595166
Validation loss: 2.492510042532676

Epoch: 139| Step: 0
Training loss: 1.7857160295750414
Validation loss: 2.426390138582618

Epoch: 6| Step: 1
Training loss: 1.769129894962734
Validation loss: 2.399229314397369

Epoch: 6| Step: 2
Training loss: 1.330008887282773
Validation loss: 2.4005334189988337

Epoch: 6| Step: 3
Training loss: 2.3431924792626506
Validation loss: 2.420362005095091

Epoch: 6| Step: 4
Training loss: 2.1754521612449857
Validation loss: 2.408309994432013

Epoch: 6| Step: 5
Training loss: 2.700921897326723
Validation loss: 2.4325491861617925

Epoch: 6| Step: 6
Training loss: 1.8334925177852943
Validation loss: 2.43115139944857

Epoch: 6| Step: 7
Training loss: 2.201023695933007
Validation loss: 2.4434457941705108

Epoch: 6| Step: 8
Training loss: 2.010837991737801
Validation loss: 2.4919145653052386

Epoch: 6| Step: 9
Training loss: 2.4977574781058296
Validation loss: 2.494428381907846

Epoch: 6| Step: 10
Training loss: 2.80056502227135
Validation loss: 2.5319391545801744

Epoch: 6| Step: 11
Training loss: 1.8060746579712632
Validation loss: 2.5673623053525088

Epoch: 6| Step: 12
Training loss: 1.9823025070858884
Validation loss: 2.5922535249829006

Epoch: 6| Step: 13
Training loss: 2.560772383221405
Validation loss: 2.592038635367728

Epoch: 140| Step: 0
Training loss: 2.6933537981779194
Validation loss: 2.607202458748412

Epoch: 6| Step: 1
Training loss: 2.2136328345579153
Validation loss: 2.511613753333059

Epoch: 6| Step: 2
Training loss: 2.153984759660252
Validation loss: 2.4826135255211343

Epoch: 6| Step: 3
Training loss: 2.1391663419542213
Validation loss: 2.4529263591216552

Epoch: 6| Step: 4
Training loss: 1.8183321679330384
Validation loss: 2.438306245491948

Epoch: 6| Step: 5
Training loss: 2.3725264869554
Validation loss: 2.4297563168341196

Epoch: 6| Step: 6
Training loss: 2.3442379252857206
Validation loss: 2.4199016659951265

Epoch: 6| Step: 7
Training loss: 1.988136571030821
Validation loss: 2.461536496692008

Epoch: 6| Step: 8
Training loss: 2.780966583555973
Validation loss: 2.43059913908698

Epoch: 6| Step: 9
Training loss: 2.3717442331968757
Validation loss: 2.5367839191810924

Epoch: 6| Step: 10
Training loss: 1.559463296657092
Validation loss: 2.636193145783196

Epoch: 6| Step: 11
Training loss: 1.7441663238238299
Validation loss: 2.6452078693244574

Epoch: 6| Step: 12
Training loss: 2.1511565047699146
Validation loss: 2.6610689310393822

Epoch: 6| Step: 13
Training loss: 1.6743807687122494
Validation loss: 2.637573267063843

Epoch: 141| Step: 0
Training loss: 1.720477467179571
Validation loss: 2.573967598003084

Epoch: 6| Step: 1
Training loss: 1.822349227508474
Validation loss: 2.5750789174659503

Epoch: 6| Step: 2
Training loss: 2.3170755844201576
Validation loss: 2.5324610167097696

Epoch: 6| Step: 3
Training loss: 2.152926440557914
Validation loss: 2.486315830192162

Epoch: 6| Step: 4
Training loss: 2.114481981476265
Validation loss: 2.4943828667005046

Epoch: 6| Step: 5
Training loss: 2.2516127210809684
Validation loss: 2.459830763656606

Epoch: 6| Step: 6
Training loss: 1.306745721670255
Validation loss: 2.440052794991964

Epoch: 6| Step: 7
Training loss: 2.4905787330838787
Validation loss: 2.4269157273280886

Epoch: 6| Step: 8
Training loss: 1.8864553832423037
Validation loss: 2.389726237545055

Epoch: 6| Step: 9
Training loss: 2.1481909038166798
Validation loss: 2.400795606841175

Epoch: 6| Step: 10
Training loss: 2.4258104405512704
Validation loss: 2.4495016028472736

Epoch: 6| Step: 11
Training loss: 2.577100052981054
Validation loss: 2.535578134811334

Epoch: 6| Step: 12
Training loss: 2.3006988666078816
Validation loss: 2.598516562606514

Epoch: 6| Step: 13
Training loss: 2.4446710592285394
Validation loss: 2.6079938943737213

Epoch: 142| Step: 0
Training loss: 1.8725324924843216
Validation loss: 2.6311932792743713

Epoch: 6| Step: 1
Training loss: 2.511184279558328
Validation loss: 2.5962815619498896

Epoch: 6| Step: 2
Training loss: 1.359842680358992
Validation loss: 2.569431994303707

Epoch: 6| Step: 3
Training loss: 2.0073129945449084
Validation loss: 2.5812481927730055

Epoch: 6| Step: 4
Training loss: 2.129705044736403
Validation loss: 2.5760471396796967

Epoch: 6| Step: 5
Training loss: 2.332171514181068
Validation loss: 2.5371499667650923

Epoch: 6| Step: 6
Training loss: 1.6942292721288008
Validation loss: 2.5008093990072275

Epoch: 6| Step: 7
Training loss: 2.6185599756603573
Validation loss: 2.504710567923075

Epoch: 6| Step: 8
Training loss: 1.8175955867686893
Validation loss: 2.4895807397428755

Epoch: 6| Step: 9
Training loss: 2.135895453641282
Validation loss: 2.42800828410864

Epoch: 6| Step: 10
Training loss: 2.0733185447255402
Validation loss: 2.4528584013740007

Epoch: 6| Step: 11
Training loss: 2.4553438102062937
Validation loss: 2.472538180975583

Epoch: 6| Step: 12
Training loss: 2.1652634796438277
Validation loss: 2.5225659247580663

Epoch: 6| Step: 13
Training loss: 2.1855081481502427
Validation loss: 2.5386146108723966

Epoch: 143| Step: 0
Training loss: 1.6040986612280472
Validation loss: 2.631993164294995

Epoch: 6| Step: 1
Training loss: 2.227257978004779
Validation loss: 2.6341653097073388

Epoch: 6| Step: 2
Training loss: 2.4654723996513086
Validation loss: 2.6678454315162132

Epoch: 6| Step: 3
Training loss: 2.008636661695812
Validation loss: 2.6105302131629817

Epoch: 6| Step: 4
Training loss: 2.4563071634954796
Validation loss: 2.5356823949590517

Epoch: 6| Step: 5
Training loss: 1.5618153407199908
Validation loss: 2.4724838382572596

Epoch: 6| Step: 6
Training loss: 2.2859501951103716
Validation loss: 2.4232782856081627

Epoch: 6| Step: 7
Training loss: 1.5926551049841289
Validation loss: 2.41383088683966

Epoch: 6| Step: 8
Training loss: 2.806541319001459
Validation loss: 2.4250535328348573

Epoch: 6| Step: 9
Training loss: 1.9630929111990287
Validation loss: 2.5221364873338263

Epoch: 6| Step: 10
Training loss: 2.2922227936090267
Validation loss: 2.629498580418831

Epoch: 6| Step: 11
Training loss: 2.1844952245980087
Validation loss: 2.6622907163157215

Epoch: 6| Step: 12
Training loss: 1.654336075391514
Validation loss: 2.619696483025814

Epoch: 6| Step: 13
Training loss: 2.024207362706476
Validation loss: 2.5131064466969644

Epoch: 144| Step: 0
Training loss: 1.6057646912554968
Validation loss: 2.456113825612668

Epoch: 6| Step: 1
Training loss: 2.192174113987942
Validation loss: 2.416230701999512

Epoch: 6| Step: 2
Training loss: 1.880069554949594
Validation loss: 2.401327619625426

Epoch: 6| Step: 3
Training loss: 2.7437301600266815
Validation loss: 2.4165800752356303

Epoch: 6| Step: 4
Training loss: 2.282525111182506
Validation loss: 2.427116682878083

Epoch: 6| Step: 5
Training loss: 1.7817281783892458
Validation loss: 2.4680155093338514

Epoch: 6| Step: 6
Training loss: 2.165837520503828
Validation loss: 2.5134361536406264

Epoch: 6| Step: 7
Training loss: 1.6640490320941204
Validation loss: 2.576878567239841

Epoch: 6| Step: 8
Training loss: 1.925481126778468
Validation loss: 2.6516461039406436

Epoch: 6| Step: 9
Training loss: 2.0263457736067325
Validation loss: 2.751994052350518

Epoch: 6| Step: 10
Training loss: 2.4220925510278564
Validation loss: 2.793035909434857

Epoch: 6| Step: 11
Training loss: 2.3681412088136957
Validation loss: 2.7356826557184415

Epoch: 6| Step: 12
Training loss: 1.8176584829000122
Validation loss: 2.6013576421122173

Epoch: 6| Step: 13
Training loss: 2.100485486723901
Validation loss: 2.4864750125248483

Epoch: 145| Step: 0
Training loss: 1.9227024561085764
Validation loss: 2.4110783351295244

Epoch: 6| Step: 1
Training loss: 2.7731885341599285
Validation loss: 2.3986366079499866

Epoch: 6| Step: 2
Training loss: 2.386433036422581
Validation loss: 2.3795493604858

Epoch: 6| Step: 3
Training loss: 2.8019912212977642
Validation loss: 2.379137455071094

Epoch: 6| Step: 4
Training loss: 2.281818266857882
Validation loss: 2.4055751402330183

Epoch: 6| Step: 5
Training loss: 2.22132627254263
Validation loss: 2.4462902571869467

Epoch: 6| Step: 6
Training loss: 1.3396208997633259
Validation loss: 2.5408182716928827

Epoch: 6| Step: 7
Training loss: 1.7533112262134714
Validation loss: 2.62299220037073

Epoch: 6| Step: 8
Training loss: 1.665792076792007
Validation loss: 2.706442739277152

Epoch: 6| Step: 9
Training loss: 1.9508206621312836
Validation loss: 2.6836224490086167

Epoch: 6| Step: 10
Training loss: 1.968656749636204
Validation loss: 2.6420800955337462

Epoch: 6| Step: 11
Training loss: 2.115988979837317
Validation loss: 2.5424092060607224

Epoch: 6| Step: 12
Training loss: 1.9662505132501105
Validation loss: 2.454362715737212

Epoch: 6| Step: 13
Training loss: 1.6265286811295734
Validation loss: 2.387128157313748

Epoch: 146| Step: 0
Training loss: 1.9462023312336056
Validation loss: 2.3448361123238906

Epoch: 6| Step: 1
Training loss: 2.134473552076235
Validation loss: 2.357207077752118

Epoch: 6| Step: 2
Training loss: 2.31699388329197
Validation loss: 2.3842493398221785

Epoch: 6| Step: 3
Training loss: 2.2001839344121574
Validation loss: 2.4273361056119347

Epoch: 6| Step: 4
Training loss: 1.9441775645923354
Validation loss: 2.45219559806958

Epoch: 6| Step: 5
Training loss: 1.634745717354704
Validation loss: 2.4898404981296927

Epoch: 6| Step: 6
Training loss: 2.292213536526144
Validation loss: 2.57223612607505

Epoch: 6| Step: 7
Training loss: 2.142492440387293
Validation loss: 2.6239665277931654

Epoch: 6| Step: 8
Training loss: 2.057239180913428
Validation loss: 2.676033012846106

Epoch: 6| Step: 9
Training loss: 1.5915368365052456
Validation loss: 2.640653670873084

Epoch: 6| Step: 10
Training loss: 2.301790854629988
Validation loss: 2.6069898142217958

Epoch: 6| Step: 11
Training loss: 2.166207362667233
Validation loss: 2.5090875699774964

Epoch: 6| Step: 12
Training loss: 2.128011028806172
Validation loss: 2.457270182406125

Epoch: 6| Step: 13
Training loss: 1.8603718113235288
Validation loss: 2.44477956007656

Epoch: 147| Step: 0
Training loss: 2.1518830015646984
Validation loss: 2.443836005301743

Epoch: 6| Step: 1
Training loss: 2.5630516760978788
Validation loss: 2.4708544929463137

Epoch: 6| Step: 2
Training loss: 2.095894242217519
Validation loss: 2.5135965711214223

Epoch: 6| Step: 3
Training loss: 1.835784581085827
Validation loss: 2.488167309123943

Epoch: 6| Step: 4
Training loss: 1.653177686691795
Validation loss: 2.4965345487844552

Epoch: 6| Step: 5
Training loss: 2.5267539891307456
Validation loss: 2.539921380385386

Epoch: 6| Step: 6
Training loss: 1.7688237474790969
Validation loss: 2.5457897223092254

Epoch: 6| Step: 7
Training loss: 1.8520438940642772
Validation loss: 2.5880043081279505

Epoch: 6| Step: 8
Training loss: 2.267868930198151
Validation loss: 2.6235018379513013

Epoch: 6| Step: 9
Training loss: 1.811116446868796
Validation loss: 2.572163695899049

Epoch: 6| Step: 10
Training loss: 2.0367377464306973
Validation loss: 2.5087374803306206

Epoch: 6| Step: 11
Training loss: 2.1696856324623113
Validation loss: 2.4797860472541724

Epoch: 6| Step: 12
Training loss: 1.8240714493610901
Validation loss: 2.430841998396942

Epoch: 6| Step: 13
Training loss: 1.978155768036164
Validation loss: 2.426452580813005

Epoch: 148| Step: 0
Training loss: 1.3454984777832493
Validation loss: 2.4712170597296312

Epoch: 6| Step: 1
Training loss: 1.9376096386805983
Validation loss: 2.5266291457971084

Epoch: 6| Step: 2
Training loss: 2.4047861972554854
Validation loss: 2.5804122300224113

Epoch: 6| Step: 3
Training loss: 2.087989283800944
Validation loss: 2.6069457125673012

Epoch: 6| Step: 4
Training loss: 2.233936400147682
Validation loss: 2.6010883538146623

Epoch: 6| Step: 5
Training loss: 2.0675048215503122
Validation loss: 2.578269277285043

Epoch: 6| Step: 6
Training loss: 1.9068972629984184
Validation loss: 2.537379811498396

Epoch: 6| Step: 7
Training loss: 2.0304583840951373
Validation loss: 2.547697664043443

Epoch: 6| Step: 8
Training loss: 1.7567725602190578
Validation loss: 2.5438071644470712

Epoch: 6| Step: 9
Training loss: 2.1010246864985587
Validation loss: 2.560144237484984

Epoch: 6| Step: 10
Training loss: 1.7824012649819287
Validation loss: 2.5564123715937312

Epoch: 6| Step: 11
Training loss: 1.8110119202851866
Validation loss: 2.5800249593350504

Epoch: 6| Step: 12
Training loss: 2.5512945292585125
Validation loss: 2.5724348381230344

Epoch: 6| Step: 13
Training loss: 1.8494751830198213
Validation loss: 2.524944942592533

Epoch: 149| Step: 0
Training loss: 2.2810468191302986
Validation loss: 2.5537214742902856

Epoch: 6| Step: 1
Training loss: 2.3562898991695023
Validation loss: 2.5979938305923302

Epoch: 6| Step: 2
Training loss: 1.3874192738461648
Validation loss: 2.544028672563409

Epoch: 6| Step: 3
Training loss: 2.4316212113306355
Validation loss: 2.510312976175628

Epoch: 6| Step: 4
Training loss: 1.8945832235541675
Validation loss: 2.506579203988871

Epoch: 6| Step: 5
Training loss: 2.034725209459261
Validation loss: 2.507722527090473

Epoch: 6| Step: 6
Training loss: 1.8644957992494113
Validation loss: 2.484655812096818

Epoch: 6| Step: 7
Training loss: 1.6283157705468096
Validation loss: 2.500112286476369

Epoch: 6| Step: 8
Training loss: 2.273769498618785
Validation loss: 2.542042144874092

Epoch: 6| Step: 9
Training loss: 1.796378622739299
Validation loss: 2.501354504833718

Epoch: 6| Step: 10
Training loss: 1.9304457807853292
Validation loss: 2.5107802557212993

Epoch: 6| Step: 11
Training loss: 1.755609988959493
Validation loss: 2.521324665782186

Epoch: 6| Step: 12
Training loss: 1.7322346995841411
Validation loss: 2.5517347816454063

Epoch: 6| Step: 13
Training loss: 2.333549682487173
Validation loss: 2.5746207139005404

Epoch: 150| Step: 0
Training loss: 2.000005483619802
Validation loss: 2.547905757707202

Epoch: 6| Step: 1
Training loss: 2.044077701719111
Validation loss: 2.537084859167051

Epoch: 6| Step: 2
Training loss: 1.7477731842087894
Validation loss: 2.524165097974999

Epoch: 6| Step: 3
Training loss: 2.23138077723966
Validation loss: 2.518339690397786

Epoch: 6| Step: 4
Training loss: 2.173447732469398
Validation loss: 2.5091447950616566

Epoch: 6| Step: 5
Training loss: 2.3869588827899575
Validation loss: 2.4996080583542066

Epoch: 6| Step: 6
Training loss: 1.6375663947702652
Validation loss: 2.538744960014942

Epoch: 6| Step: 7
Training loss: 2.078977022969742
Validation loss: 2.558073787651458

Epoch: 6| Step: 8
Training loss: 1.590035691730397
Validation loss: 2.5001479833140565

Epoch: 6| Step: 9
Training loss: 2.0444382001716974
Validation loss: 2.5366868898651393

Epoch: 6| Step: 10
Training loss: 2.3136816356581216
Validation loss: 2.5350693469549817

Epoch: 6| Step: 11
Training loss: 0.9609497503724824
Validation loss: 2.555383841298103

Epoch: 6| Step: 12
Training loss: 1.7764424816110462
Validation loss: 2.6261116170385654

Epoch: 6| Step: 13
Training loss: 1.7664825247519167
Validation loss: 2.6542880751672575

Epoch: 151| Step: 0
Training loss: 1.9043575961873584
Validation loss: 2.630112423280689

Epoch: 6| Step: 1
Training loss: 1.4278416625910544
Validation loss: 2.61047179497942

Epoch: 6| Step: 2
Training loss: 1.8381376678123673
Validation loss: 2.5877385757552043

Epoch: 6| Step: 3
Training loss: 2.025375557441543
Validation loss: 2.556450677311705

Epoch: 6| Step: 4
Training loss: 2.3688004541182157
Validation loss: 2.549171817790977

Epoch: 6| Step: 5
Training loss: 1.7137195838772183
Validation loss: 2.5417880455122477

Epoch: 6| Step: 6
Training loss: 1.855924080644258
Validation loss: 2.5583031629698216

Epoch: 6| Step: 7
Training loss: 2.119548086907302
Validation loss: 2.572574774272879

Epoch: 6| Step: 8
Training loss: 1.4185296412676427
Validation loss: 2.5834142696736397

Epoch: 6| Step: 9
Training loss: 2.2659636145799205
Validation loss: 2.564712097843846

Epoch: 6| Step: 10
Training loss: 2.077611874208827
Validation loss: 2.5286669386768477

Epoch: 6| Step: 11
Training loss: 1.8449129219492164
Validation loss: 2.527593102286845

Epoch: 6| Step: 12
Training loss: 2.000321004855731
Validation loss: 2.524316812623416

Epoch: 6| Step: 13
Training loss: 1.9518325802031735
Validation loss: 2.521661187388635

Epoch: 152| Step: 0
Training loss: 1.6320878022267202
Validation loss: 2.540499958200877

Epoch: 6| Step: 1
Training loss: 1.7142444858248156
Validation loss: 2.58455484259036

Epoch: 6| Step: 2
Training loss: 1.6268286319650795
Validation loss: 2.5915136381194057

Epoch: 6| Step: 3
Training loss: 2.064371589198169
Validation loss: 2.627638592338971

Epoch: 6| Step: 4
Training loss: 1.8143539155213964
Validation loss: 2.649817958274455

Epoch: 6| Step: 5
Training loss: 1.9054105817824296
Validation loss: 2.607732957533152

Epoch: 6| Step: 6
Training loss: 2.04909424194492
Validation loss: 2.571423749134629

Epoch: 6| Step: 7
Training loss: 1.621983663046298
Validation loss: 2.5880545234129637

Epoch: 6| Step: 8
Training loss: 2.236622566929202
Validation loss: 2.5316119090392917

Epoch: 6| Step: 9
Training loss: 2.071012213162117
Validation loss: 2.47695997299031

Epoch: 6| Step: 10
Training loss: 2.299225519230606
Validation loss: 2.4655409538469604

Epoch: 6| Step: 11
Training loss: 2.064643439666759
Validation loss: 2.424950272642595

Epoch: 6| Step: 12
Training loss: 1.5283356784620912
Validation loss: 2.442819838158026

Epoch: 6| Step: 13
Training loss: 1.296608173543248
Validation loss: 2.4597610706190247

Epoch: 153| Step: 0
Training loss: 1.5140953603668508
Validation loss: 2.524348736100604

Epoch: 6| Step: 1
Training loss: 1.1968798365881184
Validation loss: 2.640708058465922

Epoch: 6| Step: 2
Training loss: 1.9226090804804354
Validation loss: 2.7305707841303013

Epoch: 6| Step: 3
Training loss: 1.8188896676146473
Validation loss: 2.797565702377406

Epoch: 6| Step: 4
Training loss: 2.2149349240975593
Validation loss: 2.7790528518768074

Epoch: 6| Step: 5
Training loss: 2.1276907994637186
Validation loss: 2.714448266073729

Epoch: 6| Step: 6
Training loss: 1.8002796591630672
Validation loss: 2.5888255449300077

Epoch: 6| Step: 7
Training loss: 1.4196493314885024
Validation loss: 2.516372929217041

Epoch: 6| Step: 8
Training loss: 2.281959214423589
Validation loss: 2.4892426922484487

Epoch: 6| Step: 9
Training loss: 2.0155303696294027
Validation loss: 2.4697636758063775

Epoch: 6| Step: 10
Training loss: 2.441982256269546
Validation loss: 2.459972753333038

Epoch: 6| Step: 11
Training loss: 1.8943249776963476
Validation loss: 2.4853025564738163

Epoch: 6| Step: 12
Training loss: 2.0408976397566723
Validation loss: 2.500281530340918

Epoch: 6| Step: 13
Training loss: 1.6154010875791285
Validation loss: 2.5540414493597106

Epoch: 154| Step: 0
Training loss: 1.4611994054697552
Validation loss: 2.6170889857776762

Epoch: 6| Step: 1
Training loss: 1.8961670410678053
Validation loss: 2.618867615810792

Epoch: 6| Step: 2
Training loss: 2.191607297762859
Validation loss: 2.624942817006554

Epoch: 6| Step: 3
Training loss: 1.7435783000897038
Validation loss: 2.575197928707064

Epoch: 6| Step: 4
Training loss: 1.7516921581563385
Validation loss: 2.5117892570221256

Epoch: 6| Step: 5
Training loss: 1.9410506293107053
Validation loss: 2.49119343083002

Epoch: 6| Step: 6
Training loss: 2.1215857959007165
Validation loss: 2.4603029067377724

Epoch: 6| Step: 7
Training loss: 1.550066189737044
Validation loss: 2.429553947237743

Epoch: 6| Step: 8
Training loss: 1.7577084658884443
Validation loss: 2.447275134668356

Epoch: 6| Step: 9
Training loss: 1.4537321893547273
Validation loss: 2.4557816235331353

Epoch: 6| Step: 10
Training loss: 2.2490187730629008
Validation loss: 2.4819367054217194

Epoch: 6| Step: 11
Training loss: 1.9932120287972235
Validation loss: 2.5085059734047714

Epoch: 6| Step: 12
Training loss: 2.1260822008808464
Validation loss: 2.5549202011130823

Epoch: 6| Step: 13
Training loss: 1.7617908133170368
Validation loss: 2.6191193632061944

Epoch: 155| Step: 0
Training loss: 2.029954820139567
Validation loss: 2.613821651079879

Epoch: 6| Step: 1
Training loss: 2.0382250238912185
Validation loss: 2.57703646205229

Epoch: 6| Step: 2
Training loss: 1.7527038258695196
Validation loss: 2.57162623838829

Epoch: 6| Step: 3
Training loss: 1.648016925692444
Validation loss: 2.5526792840396615

Epoch: 6| Step: 4
Training loss: 1.300067694442038
Validation loss: 2.553597483550634

Epoch: 6| Step: 5
Training loss: 1.8967116560513808
Validation loss: 2.53986651416634

Epoch: 6| Step: 6
Training loss: 1.70666367263581
Validation loss: 2.55395231305193

Epoch: 6| Step: 7
Training loss: 1.9466091262247573
Validation loss: 2.5727946187014545

Epoch: 6| Step: 8
Training loss: 1.608976740771522
Validation loss: 2.585966194771115

Epoch: 6| Step: 9
Training loss: 2.069659781577811
Validation loss: 2.594974458601837

Epoch: 6| Step: 10
Training loss: 1.9318124291645422
Validation loss: 2.570408165246648

Epoch: 6| Step: 11
Training loss: 1.85704394485827
Validation loss: 2.5480788764140647

Epoch: 6| Step: 12
Training loss: 1.9701372133675994
Validation loss: 2.5403514635143756

Epoch: 6| Step: 13
Training loss: 1.834183654683376
Validation loss: 2.563999147182348

Epoch: 156| Step: 0
Training loss: 1.8704686404823996
Validation loss: 2.590340445134862

Epoch: 6| Step: 1
Training loss: 1.4584064283671867
Validation loss: 2.6261813137174164

Epoch: 6| Step: 2
Training loss: 2.028371914026752
Validation loss: 2.6518904169449593

Epoch: 6| Step: 3
Training loss: 1.49661938868036
Validation loss: 2.70248536586902

Epoch: 6| Step: 4
Training loss: 1.6565942946244931
Validation loss: 2.6634773244666006

Epoch: 6| Step: 5
Training loss: 1.7076084723583433
Validation loss: 2.5764193444095205

Epoch: 6| Step: 6
Training loss: 1.7946787141255742
Validation loss: 2.556852374436037

Epoch: 6| Step: 7
Training loss: 1.3347602699000438
Validation loss: 2.5152580051111495

Epoch: 6| Step: 8
Training loss: 1.8849351875839688
Validation loss: 2.468448033212421

Epoch: 6| Step: 9
Training loss: 1.93105906804999
Validation loss: 2.4841135106303938

Epoch: 6| Step: 10
Training loss: 2.4369684275513963
Validation loss: 2.5132987838089074

Epoch: 6| Step: 11
Training loss: 1.7331152112363162
Validation loss: 2.5202776639587694

Epoch: 6| Step: 12
Training loss: 2.0683153416140287
Validation loss: 2.5844463771579513

Epoch: 6| Step: 13
Training loss: 1.7866282331308911
Validation loss: 2.6338377459222273

Epoch: 157| Step: 0
Training loss: 1.6379700022595047
Validation loss: 2.624039602701382

Epoch: 6| Step: 1
Training loss: 1.9363002138663814
Validation loss: 2.6405290000160275

Epoch: 6| Step: 2
Training loss: 1.149204698550627
Validation loss: 2.554499463414048

Epoch: 6| Step: 3
Training loss: 1.0034595490168308
Validation loss: 2.5109993795279775

Epoch: 6| Step: 4
Training loss: 2.034059547542903
Validation loss: 2.4431832426463713

Epoch: 6| Step: 5
Training loss: 1.872741356078724
Validation loss: 2.445041891430713

Epoch: 6| Step: 6
Training loss: 1.8915416292494638
Validation loss: 2.4274648758799464

Epoch: 6| Step: 7
Training loss: 2.1103617302942235
Validation loss: 2.469853445475272

Epoch: 6| Step: 8
Training loss: 2.1180503747873227
Validation loss: 2.4776621877878466

Epoch: 6| Step: 9
Training loss: 1.5263909297177793
Validation loss: 2.5381807932797016

Epoch: 6| Step: 10
Training loss: 2.33294434938144
Validation loss: 2.6130281189623696

Epoch: 6| Step: 11
Training loss: 1.6484483474446856
Validation loss: 2.6544778238459656

Epoch: 6| Step: 12
Training loss: 1.747611868665281
Validation loss: 2.620440480037601

Epoch: 6| Step: 13
Training loss: 1.762793236545912
Validation loss: 2.6327527373135293

Epoch: 158| Step: 0
Training loss: 2.191568351638795
Validation loss: 2.582557093860148

Epoch: 6| Step: 1
Training loss: 2.155205404489505
Validation loss: 2.4989958469242266

Epoch: 6| Step: 2
Training loss: 1.4847809085997699
Validation loss: 2.475823961483745

Epoch: 6| Step: 3
Training loss: 1.8537348626638326
Validation loss: 2.4573982755401302

Epoch: 6| Step: 4
Training loss: 1.8071107654748417
Validation loss: 2.486133097063329

Epoch: 6| Step: 5
Training loss: 2.157939414919505
Validation loss: 2.5284367531053604

Epoch: 6| Step: 6
Training loss: 1.4582420411372596
Validation loss: 2.598754390154156

Epoch: 6| Step: 7
Training loss: 1.7595460608681923
Validation loss: 2.658512375334865

Epoch: 6| Step: 8
Training loss: 2.411582289957229
Validation loss: 2.655180754610642

Epoch: 6| Step: 9
Training loss: 1.6069504335043274
Validation loss: 2.645305363502924

Epoch: 6| Step: 10
Training loss: 1.208697012180736
Validation loss: 2.5789685894914265

Epoch: 6| Step: 11
Training loss: 1.533835272248953
Validation loss: 2.5042200039584332

Epoch: 6| Step: 12
Training loss: 1.4967415704370333
Validation loss: 2.4408139381459732

Epoch: 6| Step: 13
Training loss: 1.4726903289170687
Validation loss: 2.421572632691996

Epoch: 159| Step: 0
Training loss: 1.699691952115495
Validation loss: 2.419049381162917

Epoch: 6| Step: 1
Training loss: 1.6520831396320064
Validation loss: 2.461047308744712

Epoch: 6| Step: 2
Training loss: 1.5827451249118187
Validation loss: 2.5171822999091464

Epoch: 6| Step: 3
Training loss: 2.014534825474436
Validation loss: 2.6172862054354407

Epoch: 6| Step: 4
Training loss: 1.9578183964840687
Validation loss: 2.7183466069736704

Epoch: 6| Step: 5
Training loss: 1.8147453343822404
Validation loss: 2.736160142819198

Epoch: 6| Step: 6
Training loss: 1.7393352613388455
Validation loss: 2.6321159466948494

Epoch: 6| Step: 7
Training loss: 1.977190724528954
Validation loss: 2.5379902822112794

Epoch: 6| Step: 8
Training loss: 1.8434507482750706
Validation loss: 2.4795411119188966

Epoch: 6| Step: 9
Training loss: 2.0290200537550236
Validation loss: 2.4540452925851386

Epoch: 6| Step: 10
Training loss: 1.6948465155143468
Validation loss: 2.462476004040165

Epoch: 6| Step: 11
Training loss: 1.8726901767857866
Validation loss: 2.4599652311414313

Epoch: 6| Step: 12
Training loss: 1.5993468799332728
Validation loss: 2.4695045768700146

Epoch: 6| Step: 13
Training loss: 1.4347969016455109
Validation loss: 2.4580386374320886

Epoch: 160| Step: 0
Training loss: 1.8215804370645534
Validation loss: 2.4843611910000187

Epoch: 6| Step: 1
Training loss: 1.5290468676602385
Validation loss: 2.513928486862995

Epoch: 6| Step: 2
Training loss: 1.6302219264364604
Validation loss: 2.541572634287096

Epoch: 6| Step: 3
Training loss: 1.7574216959237379
Validation loss: 2.573216549393688

Epoch: 6| Step: 4
Training loss: 1.7748674853652284
Validation loss: 2.558047496426252

Epoch: 6| Step: 5
Training loss: 1.502719004279494
Validation loss: 2.6020128330341996

Epoch: 6| Step: 6
Training loss: 2.094552640652732
Validation loss: 2.5823712246046036

Epoch: 6| Step: 7
Training loss: 1.7536653552900925
Validation loss: 2.579989616965848

Epoch: 6| Step: 8
Training loss: 1.6947763887391631
Validation loss: 2.6155442970286975

Epoch: 6| Step: 9
Training loss: 1.4856650117678487
Validation loss: 2.6002499061142124

Epoch: 6| Step: 10
Training loss: 2.021712226742171
Validation loss: 2.588730516714976

Epoch: 6| Step: 11
Training loss: 1.3122208616335975
Validation loss: 2.5076664390858237

Epoch: 6| Step: 12
Training loss: 2.045827699590049
Validation loss: 2.4774955771467293

Epoch: 6| Step: 13
Training loss: 1.861649796669299
Validation loss: 2.4198960750121237

Epoch: 161| Step: 0
Training loss: 2.0224116608102443
Validation loss: 2.483368876053448

Epoch: 6| Step: 1
Training loss: 1.9176897828881383
Validation loss: 2.5234960251257994

Epoch: 6| Step: 2
Training loss: 1.4375377318364522
Validation loss: 2.5403353460459606

Epoch: 6| Step: 3
Training loss: 1.3423530947191575
Validation loss: 2.550773689062705

Epoch: 6| Step: 4
Training loss: 1.302561186526641
Validation loss: 2.6164613110850685

Epoch: 6| Step: 5
Training loss: 1.532251069728125
Validation loss: 2.6707746034865254

Epoch: 6| Step: 6
Training loss: 2.117661989539624
Validation loss: 2.7364556178769828

Epoch: 6| Step: 7
Training loss: 1.7403385632084505
Validation loss: 2.6769992653490338

Epoch: 6| Step: 8
Training loss: 2.3514857485592997
Validation loss: 2.5626941430284993

Epoch: 6| Step: 9
Training loss: 1.0525144442837948
Validation loss: 2.5388952919904777

Epoch: 6| Step: 10
Training loss: 1.8320244827633543
Validation loss: 2.4607452072643943

Epoch: 6| Step: 11
Training loss: 1.4050272393895122
Validation loss: 2.435566456316836

Epoch: 6| Step: 12
Training loss: 2.278574380390119
Validation loss: 2.425350069049581

Epoch: 6| Step: 13
Training loss: 1.0633864911961728
Validation loss: 2.4518794501860595

Epoch: 162| Step: 0
Training loss: 1.5547362660183104
Validation loss: 2.486123130727884

Epoch: 6| Step: 1
Training loss: 1.5430455442222661
Validation loss: 2.5612072909149446

Epoch: 6| Step: 2
Training loss: 1.2977474908600553
Validation loss: 2.618114906967045

Epoch: 6| Step: 3
Training loss: 1.3248972547029483
Validation loss: 2.6876514828060434

Epoch: 6| Step: 4
Training loss: 1.2123773689785706
Validation loss: 2.681254668848063

Epoch: 6| Step: 5
Training loss: 2.173629162124035
Validation loss: 2.664459831120064

Epoch: 6| Step: 6
Training loss: 1.9656936900352593
Validation loss: 2.601018677644469

Epoch: 6| Step: 7
Training loss: 1.5159592407403906
Validation loss: 2.5064211920955994

Epoch: 6| Step: 8
Training loss: 2.3213248051518303
Validation loss: 2.490681907401099

Epoch: 6| Step: 9
Training loss: 1.719527328881902
Validation loss: 2.4572669894209502

Epoch: 6| Step: 10
Training loss: 1.7886821892318705
Validation loss: 2.491072536568001

Epoch: 6| Step: 11
Training loss: 1.0698092871790037
Validation loss: 2.5281861272635093

Epoch: 6| Step: 12
Training loss: 2.1756635596395992
Validation loss: 2.5815414021890795

Epoch: 6| Step: 13
Training loss: 1.7291966018230396
Validation loss: 2.625211936649472

Epoch: 163| Step: 0
Training loss: 1.670331295753403
Validation loss: 2.603344798846755

Epoch: 6| Step: 1
Training loss: 1.757431192367013
Validation loss: 2.623334932766804

Epoch: 6| Step: 2
Training loss: 1.3689668248505893
Validation loss: 2.5587233358327284

Epoch: 6| Step: 3
Training loss: 1.2284676886638348
Validation loss: 2.5594289802092347

Epoch: 6| Step: 4
Training loss: 1.8343586077761915
Validation loss: 2.5069551788558697

Epoch: 6| Step: 5
Training loss: 1.708661102237241
Validation loss: 2.5177239540527827

Epoch: 6| Step: 6
Training loss: 1.3377714452077911
Validation loss: 2.500356353465376

Epoch: 6| Step: 7
Training loss: 1.8031166803706868
Validation loss: 2.4885110338016596

Epoch: 6| Step: 8
Training loss: 1.8075943692424583
Validation loss: 2.4978917430735272

Epoch: 6| Step: 9
Training loss: 1.78675446868675
Validation loss: 2.536631021868378

Epoch: 6| Step: 10
Training loss: 1.6725759017439916
Validation loss: 2.56256820543921

Epoch: 6| Step: 11
Training loss: 1.4459768057370395
Validation loss: 2.6130934593735193

Epoch: 6| Step: 12
Training loss: 2.096776340852684
Validation loss: 2.646042516525144

Epoch: 6| Step: 13
Training loss: 1.5337237403567856
Validation loss: 2.667808577272857

Epoch: 164| Step: 0
Training loss: 2.1775259149106403
Validation loss: 2.5865981197458856

Epoch: 6| Step: 1
Training loss: 1.4084697582070889
Validation loss: 2.536199895420988

Epoch: 6| Step: 2
Training loss: 1.6342405070588935
Validation loss: 2.529642066105965

Epoch: 6| Step: 3
Training loss: 2.028301270147132
Validation loss: 2.5571472512813296

Epoch: 6| Step: 4
Training loss: 1.1656604526231604
Validation loss: 2.558286792334063

Epoch: 6| Step: 5
Training loss: 1.4614262706731556
Validation loss: 2.564781975686369

Epoch: 6| Step: 6
Training loss: 1.55246226487548
Validation loss: 2.590784488059835

Epoch: 6| Step: 7
Training loss: 1.4769900878542654
Validation loss: 2.5875739296236673

Epoch: 6| Step: 8
Training loss: 1.66304608317998
Validation loss: 2.629376848234318

Epoch: 6| Step: 9
Training loss: 1.604821513224973
Validation loss: 2.562423361755976

Epoch: 6| Step: 10
Training loss: 1.5078776449252869
Validation loss: 2.563925946873973

Epoch: 6| Step: 11
Training loss: 1.8960736160875429
Validation loss: 2.5292450573015555

Epoch: 6| Step: 12
Training loss: 1.6733736113276583
Validation loss: 2.5699412602703764

Epoch: 6| Step: 13
Training loss: 1.628440296300267
Validation loss: 2.607677521385842

Epoch: 165| Step: 0
Training loss: 0.9161560341399227
Validation loss: 2.604892782726123

Epoch: 6| Step: 1
Training loss: 2.0779028752294266
Validation loss: 2.5973007917479083

Epoch: 6| Step: 2
Training loss: 1.3765658219434858
Validation loss: 2.5688745489870013

Epoch: 6| Step: 3
Training loss: 1.432526900886013
Validation loss: 2.5274994578352357

Epoch: 6| Step: 4
Training loss: 1.3712053824079853
Validation loss: 2.4949209322903574

Epoch: 6| Step: 5
Training loss: 1.9202666336926408
Validation loss: 2.492398443690001

Epoch: 6| Step: 6
Training loss: 1.7328122633442833
Validation loss: 2.5299692938612504

Epoch: 6| Step: 7
Training loss: 1.4908908982710591
Validation loss: 2.6121833724798416

Epoch: 6| Step: 8
Training loss: 1.8351391294159018
Validation loss: 2.656949012464142

Epoch: 6| Step: 9
Training loss: 1.881425528717808
Validation loss: 2.6768740059863534

Epoch: 6| Step: 10
Training loss: 1.4084671344436772
Validation loss: 2.6370032338332443

Epoch: 6| Step: 11
Training loss: 1.8115001419913868
Validation loss: 2.540672112368532

Epoch: 6| Step: 12
Training loss: 1.7325038955006147
Validation loss: 2.505087240780064

Epoch: 6| Step: 13
Training loss: 1.6580013156835032
Validation loss: 2.5187811441200125

Epoch: 166| Step: 0
Training loss: 1.4918866078852486
Validation loss: 2.5239899693213332

Epoch: 6| Step: 1
Training loss: 1.0212575394388317
Validation loss: 2.5834707652943756

Epoch: 6| Step: 2
Training loss: 1.8975356985963425
Validation loss: 2.642035833434731

Epoch: 6| Step: 3
Training loss: 1.3972101632986749
Validation loss: 2.6574120418502822

Epoch: 6| Step: 4
Training loss: 1.4743456472051801
Validation loss: 2.637984515613723

Epoch: 6| Step: 5
Training loss: 1.509529519711399
Validation loss: 2.6199367658093107

Epoch: 6| Step: 6
Training loss: 2.15176633092339
Validation loss: 2.596762068487114

Epoch: 6| Step: 7
Training loss: 1.4976961404167286
Validation loss: 2.6051246196997764

Epoch: 6| Step: 8
Training loss: 1.5019388384195367
Validation loss: 2.5610899498522723

Epoch: 6| Step: 9
Training loss: 1.5770090519869657
Validation loss: 2.5194393816898493

Epoch: 6| Step: 10
Training loss: 1.905593196094291
Validation loss: 2.4997725290978283

Epoch: 6| Step: 11
Training loss: 1.8336999122108264
Validation loss: 2.5013905380421626

Epoch: 6| Step: 12
Training loss: 1.7850934775102696
Validation loss: 2.5125411911278914

Epoch: 6| Step: 13
Training loss: 1.2062844740927132
Validation loss: 2.566000813318943

Epoch: 167| Step: 0
Training loss: 1.671857316823832
Validation loss: 2.55163905730297

Epoch: 6| Step: 1
Training loss: 1.9294663275483888
Validation loss: 2.560173274922982

Epoch: 6| Step: 2
Training loss: 1.73544189355412
Validation loss: 2.5917784493016085

Epoch: 6| Step: 3
Training loss: 1.4381874762554117
Validation loss: 2.5987157678662087

Epoch: 6| Step: 4
Training loss: 1.2336430371266833
Validation loss: 2.612121074343017

Epoch: 6| Step: 5
Training loss: 1.5490695529490137
Validation loss: 2.5763905945546806

Epoch: 6| Step: 6
Training loss: 1.8454779593557917
Validation loss: 2.542859868724978

Epoch: 6| Step: 7
Training loss: 1.2423380154762917
Validation loss: 2.541166588863156

Epoch: 6| Step: 8
Training loss: 1.4547458755793943
Validation loss: 2.502518760175901

Epoch: 6| Step: 9
Training loss: 1.2830242804580883
Validation loss: 2.536085843088696

Epoch: 6| Step: 10
Training loss: 1.7170252382293134
Validation loss: 2.5214256333855474

Epoch: 6| Step: 11
Training loss: 1.7833608868808482
Validation loss: 2.4992047849944687

Epoch: 6| Step: 12
Training loss: 1.6073832362410663
Validation loss: 2.495947782898647

Epoch: 6| Step: 13
Training loss: 1.4437991080251111
Validation loss: 2.471683997086557

Epoch: 168| Step: 0
Training loss: 1.5476725670360185
Validation loss: 2.515489763525254

Epoch: 6| Step: 1
Training loss: 1.371060710628455
Validation loss: 2.5494327044230225

Epoch: 6| Step: 2
Training loss: 1.8325678643414525
Validation loss: 2.561507109963812

Epoch: 6| Step: 3
Training loss: 1.9714036042545726
Validation loss: 2.551222726461552

Epoch: 6| Step: 4
Training loss: 1.5836581683312578
Validation loss: 2.587421222201111

Epoch: 6| Step: 5
Training loss: 1.0474916037175208
Validation loss: 2.5772007493356375

Epoch: 6| Step: 6
Training loss: 1.7491102000089969
Validation loss: 2.5454314692215276

Epoch: 6| Step: 7
Training loss: 1.7810986103172592
Validation loss: 2.508502225293683

Epoch: 6| Step: 8
Training loss: 1.5323317463100188
Validation loss: 2.4864941690654456

Epoch: 6| Step: 9
Training loss: 1.7946393908349936
Validation loss: 2.4829410091391013

Epoch: 6| Step: 10
Training loss: 1.421194899001712
Validation loss: 2.555716475041865

Epoch: 6| Step: 11
Training loss: 1.3160870898106662
Validation loss: 2.562684695523086

Epoch: 6| Step: 12
Training loss: 1.487665805070784
Validation loss: 2.574380619980502

Epoch: 6| Step: 13
Training loss: 1.4567486281800115
Validation loss: 2.5768297229927275

Epoch: 169| Step: 0
Training loss: 1.5248009473623594
Validation loss: 2.534490232423749

Epoch: 6| Step: 1
Training loss: 1.8828636574027775
Validation loss: 2.561181212028863

Epoch: 6| Step: 2
Training loss: 1.3333176472853805
Validation loss: 2.554703698519757

Epoch: 6| Step: 3
Training loss: 1.6179754576643008
Validation loss: 2.512281336437328

Epoch: 6| Step: 4
Training loss: 1.7967881554888312
Validation loss: 2.4721714017394

Epoch: 6| Step: 5
Training loss: 1.341754185248739
Validation loss: 2.476880131171396

Epoch: 6| Step: 6
Training loss: 1.7814994102003827
Validation loss: 2.5103586876366313

Epoch: 6| Step: 7
Training loss: 1.1424726910321898
Validation loss: 2.5505044998657493

Epoch: 6| Step: 8
Training loss: 1.2235948171599986
Validation loss: 2.542536414412368

Epoch: 6| Step: 9
Training loss: 0.9822447296665288
Validation loss: 2.601313016271806

Epoch: 6| Step: 10
Training loss: 1.862611790316759
Validation loss: 2.6311720359537625

Epoch: 6| Step: 11
Training loss: 1.6439114306415121
Validation loss: 2.691111198662267

Epoch: 6| Step: 12
Training loss: 1.7573272713531072
Validation loss: 2.644692929426898

Epoch: 6| Step: 13
Training loss: 1.8412875526053487
Validation loss: 2.5960847319831704

Epoch: 170| Step: 0
Training loss: 1.2430362800557557
Validation loss: 2.568583890915811

Epoch: 6| Step: 1
Training loss: 1.386682472291758
Validation loss: 2.572302446853884

Epoch: 6| Step: 2
Training loss: 1.9723202863081941
Validation loss: 2.566888644964399

Epoch: 6| Step: 3
Training loss: 1.3523276043241572
Validation loss: 2.613170907228619

Epoch: 6| Step: 4
Training loss: 1.4212977316967985
Validation loss: 2.63477727379242

Epoch: 6| Step: 5
Training loss: 1.7878436471819337
Validation loss: 2.639808236730669

Epoch: 6| Step: 6
Training loss: 1.9742774873124014
Validation loss: 2.649200702160052

Epoch: 6| Step: 7
Training loss: 1.4025998107562991
Validation loss: 2.6384965250500807

Epoch: 6| Step: 8
Training loss: 1.3656185630105417
Validation loss: 2.5855740373941845

Epoch: 6| Step: 9
Training loss: 1.2297712983367146
Validation loss: 2.5134183244241632

Epoch: 6| Step: 10
Training loss: 1.4948822773796862
Validation loss: 2.483312116181154

Epoch: 6| Step: 11
Training loss: 1.161434458443028
Validation loss: 2.4850232132648884

Epoch: 6| Step: 12
Training loss: 1.8610404113448722
Validation loss: 2.470657185170329

Epoch: 6| Step: 13
Training loss: 1.8489542428271397
Validation loss: 2.473529784169334

Epoch: 171| Step: 0
Training loss: 1.234253020235152
Validation loss: 2.5189496857814437

Epoch: 6| Step: 1
Training loss: 1.4150120197500045
Validation loss: 2.573016961142243

Epoch: 6| Step: 2
Training loss: 2.0062268597465627
Validation loss: 2.6187908826785073

Epoch: 6| Step: 3
Training loss: 1.995746380764101
Validation loss: 2.666245133656511

Epoch: 6| Step: 4
Training loss: 1.4071069437579629
Validation loss: 2.6914153180541946

Epoch: 6| Step: 5
Training loss: 1.8794778125018576
Validation loss: 2.7080432515629096

Epoch: 6| Step: 6
Training loss: 1.1385321032421154
Validation loss: 2.6366491626837645

Epoch: 6| Step: 7
Training loss: 1.5734983551773187
Validation loss: 2.5602475122551605

Epoch: 6| Step: 8
Training loss: 1.5430142552872457
Validation loss: 2.566833311721805

Epoch: 6| Step: 9
Training loss: 1.822457224758603
Validation loss: 2.49666635558265

Epoch: 6| Step: 10
Training loss: 1.2506543354214121
Validation loss: 2.4911207498721537

Epoch: 6| Step: 11
Training loss: 0.9703950757750056
Validation loss: 2.4990700417480216

Epoch: 6| Step: 12
Training loss: 1.5697961214437308
Validation loss: 2.529970655748169

Epoch: 6| Step: 13
Training loss: 1.2850800001719898
Validation loss: 2.598627025482827

Epoch: 172| Step: 0
Training loss: 1.5563183382648715
Validation loss: 2.667067059970333

Epoch: 6| Step: 1
Training loss: 1.5212452300223402
Validation loss: 2.7249253967916847

Epoch: 6| Step: 2
Training loss: 1.6367341908020165
Validation loss: 2.724779426007016

Epoch: 6| Step: 3
Training loss: 1.2132808039284284
Validation loss: 2.7191832200443984

Epoch: 6| Step: 4
Training loss: 1.49229934033591
Validation loss: 2.682005930582365

Epoch: 6| Step: 5
Training loss: 1.6499913562201458
Validation loss: 2.630721954487124

Epoch: 6| Step: 6
Training loss: 1.6107460774041336
Validation loss: 2.524299256265372

Epoch: 6| Step: 7
Training loss: 1.3198998161791506
Validation loss: 2.488396619750471

Epoch: 6| Step: 8
Training loss: 1.5309412119396626
Validation loss: 2.445057635743306

Epoch: 6| Step: 9
Training loss: 1.4207430515337547
Validation loss: 2.424023450466143

Epoch: 6| Step: 10
Training loss: 1.843143686721777
Validation loss: 2.436766455964706

Epoch: 6| Step: 11
Training loss: 1.538788282102587
Validation loss: 2.4716281596133824

Epoch: 6| Step: 12
Training loss: 1.7189142322103546
Validation loss: 2.5178744348577475

Epoch: 6| Step: 13
Training loss: 1.2202364830733048
Validation loss: 2.582844110966468

Epoch: 173| Step: 0
Training loss: 1.5564953438272262
Validation loss: 2.642795126098614

Epoch: 6| Step: 1
Training loss: 1.3788868413753372
Validation loss: 2.656599213182612

Epoch: 6| Step: 2
Training loss: 1.3650282893899894
Validation loss: 2.625205760964293

Epoch: 6| Step: 3
Training loss: 1.411086771388829
Validation loss: 2.535485614381068

Epoch: 6| Step: 4
Training loss: 1.7609854311711375
Validation loss: 2.488531177551718

Epoch: 6| Step: 5
Training loss: 1.135473454073139
Validation loss: 2.469385752939835

Epoch: 6| Step: 6
Training loss: 1.6878091740835892
Validation loss: 2.460310300773102

Epoch: 6| Step: 7
Training loss: 1.1632309061791615
Validation loss: 2.4928632657041025

Epoch: 6| Step: 8
Training loss: 1.3989747363407306
Validation loss: 2.5404689703016228

Epoch: 6| Step: 9
Training loss: 1.675727043075419
Validation loss: 2.6269455754353483

Epoch: 6| Step: 10
Training loss: 1.7406036293457443
Validation loss: 2.649336637781076

Epoch: 6| Step: 11
Training loss: 1.8235388066540203
Validation loss: 2.6811489584237536

Epoch: 6| Step: 12
Training loss: 1.5210057339431657
Validation loss: 2.6651406292672735

Epoch: 6| Step: 13
Training loss: 1.4352086920960883
Validation loss: 2.640842031506501

Epoch: 174| Step: 0
Training loss: 1.8289881567720183
Validation loss: 2.6176543111952606

Epoch: 6| Step: 1
Training loss: 1.4494909149179962
Validation loss: 2.630795374301482

Epoch: 6| Step: 2
Training loss: 1.1726692051588048
Validation loss: 2.59362456118097

Epoch: 6| Step: 3
Training loss: 1.4931209500602385
Validation loss: 2.5700170448953856

Epoch: 6| Step: 4
Training loss: 1.3267725622063982
Validation loss: 2.551728070469116

Epoch: 6| Step: 5
Training loss: 1.1794853795185622
Validation loss: 2.591420441696966

Epoch: 6| Step: 6
Training loss: 1.5882155870636143
Validation loss: 2.582111765149594

Epoch: 6| Step: 7
Training loss: 0.6284493628946706
Validation loss: 2.584595888409551

Epoch: 6| Step: 8
Training loss: 1.469975548625183
Validation loss: 2.578434702498739

Epoch: 6| Step: 9
Training loss: 1.5646861232647136
Validation loss: 2.5775832622858825

Epoch: 6| Step: 10
Training loss: 1.8764811705435631
Validation loss: 2.5535142456117828

Epoch: 6| Step: 11
Training loss: 1.9073149411086823
Validation loss: 2.4989980617729173

Epoch: 6| Step: 12
Training loss: 1.4985573506879146
Validation loss: 2.4724041474067273

Epoch: 6| Step: 13
Training loss: 1.1697684109358522
Validation loss: 2.4597473297996633

Epoch: 175| Step: 0
Training loss: 1.430175031073762
Validation loss: 2.4608079320470035

Epoch: 6| Step: 1
Training loss: 1.4246711485355934
Validation loss: 2.479395791607431

Epoch: 6| Step: 2
Training loss: 1.5866665221596232
Validation loss: 2.486596237533349

Epoch: 6| Step: 3
Training loss: 1.381626806171175
Validation loss: 2.511032965964776

Epoch: 6| Step: 4
Training loss: 0.8176847239850088
Validation loss: 2.583963679148147

Epoch: 6| Step: 5
Training loss: 1.3580175176959761
Validation loss: 2.619653042515783

Epoch: 6| Step: 6
Training loss: 1.4847309689590762
Validation loss: 2.6626953142715504

Epoch: 6| Step: 7
Training loss: 1.4679903541424741
Validation loss: 2.6474030669705475

Epoch: 6| Step: 8
Training loss: 1.1847111931889096
Validation loss: 2.5841440290955062

Epoch: 6| Step: 9
Training loss: 1.5298603525196899
Validation loss: 2.5743620945231678

Epoch: 6| Step: 10
Training loss: 1.6156924796262138
Validation loss: 2.533863577323417

Epoch: 6| Step: 11
Training loss: 1.8647696829934715
Validation loss: 2.506689377868171

Epoch: 6| Step: 12
Training loss: 1.8021556053296073
Validation loss: 2.5225430379631373

Epoch: 6| Step: 13
Training loss: 1.3420489878120156
Validation loss: 2.5083174305959095

Epoch: 176| Step: 0
Training loss: 1.9726545579355368
Validation loss: 2.5222938689378944

Epoch: 6| Step: 1
Training loss: 1.692052986244242
Validation loss: 2.543570004703477

Epoch: 6| Step: 2
Training loss: 1.5604879776364118
Validation loss: 2.602640828374336

Epoch: 6| Step: 3
Training loss: 1.1665084027618444
Validation loss: 2.6317182572077726

Epoch: 6| Step: 4
Training loss: 1.1702579786081238
Validation loss: 2.6522882941958668

Epoch: 6| Step: 5
Training loss: 1.4026181263399538
Validation loss: 2.628206008244612

Epoch: 6| Step: 6
Training loss: 1.2475252927154066
Validation loss: 2.604732943750001

Epoch: 6| Step: 7
Training loss: 1.3932695852340877
Validation loss: 2.6134584457762835

Epoch: 6| Step: 8
Training loss: 1.4400998529940998
Validation loss: 2.6007225077129243

Epoch: 6| Step: 9
Training loss: 1.3053523214346965
Validation loss: 2.595757505309159

Epoch: 6| Step: 10
Training loss: 0.9974634066301495
Validation loss: 2.5921705180822183

Epoch: 6| Step: 11
Training loss: 1.904009142925846
Validation loss: 2.6092272357981714

Epoch: 6| Step: 12
Training loss: 1.138713750838048
Validation loss: 2.638599513806806

Epoch: 6| Step: 13
Training loss: 1.5221796565048575
Validation loss: 2.5946730102983877

Epoch: 177| Step: 0
Training loss: 1.5384941794527405
Validation loss: 2.545260414538341

Epoch: 6| Step: 1
Training loss: 1.4750516720788918
Validation loss: 2.5755708205330463

Epoch: 6| Step: 2
Training loss: 1.1849664464457508
Validation loss: 2.5600955856699996

Epoch: 6| Step: 3
Training loss: 1.009948949940038
Validation loss: 2.573246091874053

Epoch: 6| Step: 4
Training loss: 2.036888161751618
Validation loss: 2.5673654687582004

Epoch: 6| Step: 5
Training loss: 1.6830134619788115
Validation loss: 2.5741951373220773

Epoch: 6| Step: 6
Training loss: 1.386221095231826
Validation loss: 2.6015480457690123

Epoch: 6| Step: 7
Training loss: 1.3807244349566117
Validation loss: 2.611250035392329

Epoch: 6| Step: 8
Training loss: 1.6426850963328643
Validation loss: 2.5208937914751224

Epoch: 6| Step: 9
Training loss: 1.439766299834257
Validation loss: 2.5074614910856323

Epoch: 6| Step: 10
Training loss: 1.2677825621807086
Validation loss: 2.4986333187779537

Epoch: 6| Step: 11
Training loss: 1.2893696736878937
Validation loss: 2.5078412315223733

Epoch: 6| Step: 12
Training loss: 0.9558300966331625
Validation loss: 2.555548032856849

Epoch: 6| Step: 13
Training loss: 1.5953383665014742
Validation loss: 2.6073727897954337

Epoch: 178| Step: 0
Training loss: 0.9411900695526574
Validation loss: 2.6341905920753756

Epoch: 6| Step: 1
Training loss: 1.0404589454657531
Validation loss: 2.6413645239409758

Epoch: 6| Step: 2
Training loss: 1.3618326880301332
Validation loss: 2.6676786916032516

Epoch: 6| Step: 3
Training loss: 1.74354992610862
Validation loss: 2.672768632952115

Epoch: 6| Step: 4
Training loss: 1.3100881214205196
Validation loss: 2.696301281721385

Epoch: 6| Step: 5
Training loss: 1.4410435496783927
Validation loss: 2.6686526132699253

Epoch: 6| Step: 6
Training loss: 1.1327057886834697
Validation loss: 2.596949231073153

Epoch: 6| Step: 7
Training loss: 1.9349809082824254
Validation loss: 2.485715475947099

Epoch: 6| Step: 8
Training loss: 1.1620240765209504
Validation loss: 2.4794439853693655

Epoch: 6| Step: 9
Training loss: 1.3585631917156833
Validation loss: 2.4835538151260326

Epoch: 6| Step: 10
Training loss: 1.642656358450174
Validation loss: 2.4951275463606435

Epoch: 6| Step: 11
Training loss: 1.3379205630774456
Validation loss: 2.505371647844064

Epoch: 6| Step: 12
Training loss: 1.8162594971799022
Validation loss: 2.539444292895391

Epoch: 6| Step: 13
Training loss: 1.328191957468878
Validation loss: 2.5697397785318783

Epoch: 179| Step: 0
Training loss: 1.2419694913136234
Validation loss: 2.6150333772375145

Epoch: 6| Step: 1
Training loss: 1.7357781035741326
Validation loss: 2.6141387701389913

Epoch: 6| Step: 2
Training loss: 1.911644852881566
Validation loss: 2.594266402956667

Epoch: 6| Step: 3
Training loss: 1.6130192061225026
Validation loss: 2.5602783879349387

Epoch: 6| Step: 4
Training loss: 1.1763534420957804
Validation loss: 2.5226753404844944

Epoch: 6| Step: 5
Training loss: 1.411957327649079
Validation loss: 2.50967451878029

Epoch: 6| Step: 6
Training loss: 1.1646887099758994
Validation loss: 2.5305437930714643

Epoch: 6| Step: 7
Training loss: 1.2652368774577754
Validation loss: 2.5451046586025075

Epoch: 6| Step: 8
Training loss: 1.7807959262249493
Validation loss: 2.565877885043794

Epoch: 6| Step: 9
Training loss: 1.1991329100264525
Validation loss: 2.638132442076493

Epoch: 6| Step: 10
Training loss: 1.420300460781191
Validation loss: 2.6828122933654805

Epoch: 6| Step: 11
Training loss: 1.3128936722143212
Validation loss: 2.6867626482672566

Epoch: 6| Step: 12
Training loss: 0.88946494461938
Validation loss: 2.618346560639649

Epoch: 6| Step: 13
Training loss: 1.2675696139057242
Validation loss: 2.5841979453192967

Epoch: 180| Step: 0
Training loss: 1.2951802590006742
Validation loss: 2.536094356580166

Epoch: 6| Step: 1
Training loss: 1.5159787423950901
Validation loss: 2.497902427060139

Epoch: 6| Step: 2
Training loss: 1.4594047788404
Validation loss: 2.4798077975978567

Epoch: 6| Step: 3
Training loss: 1.9523058584992812
Validation loss: 2.4903117112487267

Epoch: 6| Step: 4
Training loss: 1.3992438522293777
Validation loss: 2.5046117116203495

Epoch: 6| Step: 5
Training loss: 1.3272551885903305
Validation loss: 2.551728657195412

Epoch: 6| Step: 6
Training loss: 1.4258541558843032
Validation loss: 2.6261558439328945

Epoch: 6| Step: 7
Training loss: 1.4372452219871876
Validation loss: 2.6973446459618007

Epoch: 6| Step: 8
Training loss: 1.3941549867428429
Validation loss: 2.7713964896785996

Epoch: 6| Step: 9
Training loss: 0.9699508853158116
Validation loss: 2.782256912556975

Epoch: 6| Step: 10
Training loss: 1.326986206109481
Validation loss: 2.754283769829285

Epoch: 6| Step: 11
Training loss: 1.602414681340046
Validation loss: 2.677453662616927

Epoch: 6| Step: 12
Training loss: 1.4027838906174892
Validation loss: 2.577082850239769

Epoch: 6| Step: 13
Training loss: 0.7514546909848586
Validation loss: 2.505289691754094

Epoch: 181| Step: 0
Training loss: 1.4779530592550387
Validation loss: 2.477535587021387

Epoch: 6| Step: 1
Training loss: 1.5576040237492341
Validation loss: 2.4512798977604273

Epoch: 6| Step: 2
Training loss: 1.2181138554743893
Validation loss: 2.473403130209218

Epoch: 6| Step: 3
Training loss: 1.1961859210957797
Validation loss: 2.5255976814605257

Epoch: 6| Step: 4
Training loss: 1.7802889054756925
Validation loss: 2.5929644200906177

Epoch: 6| Step: 5
Training loss: 1.2725426273663116
Validation loss: 2.6249466249476345

Epoch: 6| Step: 6
Training loss: 1.1465810185889245
Validation loss: 2.715846709422507

Epoch: 6| Step: 7
Training loss: 1.0903967544745257
Validation loss: 2.704393896936228

Epoch: 6| Step: 8
Training loss: 1.3532346843992347
Validation loss: 2.689580973553319

Epoch: 6| Step: 9
Training loss: 1.2605069603642696
Validation loss: 2.6844112535469846

Epoch: 6| Step: 10
Training loss: 1.4178138837498586
Validation loss: 2.640926327629726

Epoch: 6| Step: 11
Training loss: 1.7202438798154407
Validation loss: 2.6442392614922268

Epoch: 6| Step: 12
Training loss: 1.3834959162495695
Validation loss: 2.5847452710008425

Epoch: 6| Step: 13
Training loss: 1.3648271512712846
Validation loss: 2.5643367932293692

Epoch: 182| Step: 0
Training loss: 1.6396687218397992
Validation loss: 2.5128721281278894

Epoch: 6| Step: 1
Training loss: 1.2360635145836807
Validation loss: 2.4763706653534316

Epoch: 6| Step: 2
Training loss: 1.3055257331652506
Validation loss: 2.494569350861486

Epoch: 6| Step: 3
Training loss: 1.4894431077093564
Validation loss: 2.542994812018298

Epoch: 6| Step: 4
Training loss: 1.5709037616567894
Validation loss: 2.5790486351504476

Epoch: 6| Step: 5
Training loss: 1.6925972144016412
Validation loss: 2.5652790961681067

Epoch: 6| Step: 6
Training loss: 1.5402635254738954
Validation loss: 2.6166701879243166

Epoch: 6| Step: 7
Training loss: 0.6637192905096398
Validation loss: 2.705756648675755

Epoch: 6| Step: 8
Training loss: 1.286697761813804
Validation loss: 2.7651351236227297

Epoch: 6| Step: 9
Training loss: 1.2188216457337766
Validation loss: 2.793921054594378

Epoch: 6| Step: 10
Training loss: 1.61791614574051
Validation loss: 2.707660171742756

Epoch: 6| Step: 11
Training loss: 1.194845070791431
Validation loss: 2.594305013417571

Epoch: 6| Step: 12
Training loss: 1.4857251100748445
Validation loss: 2.5388934456683305

Epoch: 6| Step: 13
Training loss: 1.2304082462028259
Validation loss: 2.4816898625891946

Epoch: 183| Step: 0
Training loss: 1.2459268966464723
Validation loss: 2.5040940126069784

Epoch: 6| Step: 1
Training loss: 1.6208589314823147
Validation loss: 2.561204325098149

Epoch: 6| Step: 2
Training loss: 1.6568565697438167
Validation loss: 2.557040593912745

Epoch: 6| Step: 3
Training loss: 1.8303098094282781
Validation loss: 2.600649693896938

Epoch: 6| Step: 4
Training loss: 1.1407456007652552
Validation loss: 2.618495735043785

Epoch: 6| Step: 5
Training loss: 1.1629337752553142
Validation loss: 2.6436382920089803

Epoch: 6| Step: 6
Training loss: 0.7903106185027895
Validation loss: 2.602210423908345

Epoch: 6| Step: 7
Training loss: 1.3427599431140114
Validation loss: 2.635461516904358

Epoch: 6| Step: 8
Training loss: 1.4897864232188622
Validation loss: 2.590433577983007

Epoch: 6| Step: 9
Training loss: 1.568614136181215
Validation loss: 2.6087558014859216

Epoch: 6| Step: 10
Training loss: 0.7604957347853096
Validation loss: 2.6382227717716162

Epoch: 6| Step: 11
Training loss: 1.3197537656348433
Validation loss: 2.616709756140442

Epoch: 6| Step: 12
Training loss: 1.4415369982461852
Validation loss: 2.6297631925807896

Epoch: 6| Step: 13
Training loss: 0.9741720927184975
Validation loss: 2.584832208829236

Epoch: 184| Step: 0
Training loss: 0.9727478903377718
Validation loss: 2.5549919571930646

Epoch: 6| Step: 1
Training loss: 1.3426881631303447
Validation loss: 2.545810617217631

Epoch: 6| Step: 2
Training loss: 1.351569556069009
Validation loss: 2.5655796704462084

Epoch: 6| Step: 3
Training loss: 1.4893664311055643
Validation loss: 2.599577952673232

Epoch: 6| Step: 4
Training loss: 1.7863394324176072
Validation loss: 2.642554629350813

Epoch: 6| Step: 5
Training loss: 1.3112000430966522
Validation loss: 2.6673940722691323

Epoch: 6| Step: 6
Training loss: 1.1363382653091778
Validation loss: 2.6641196025660845

Epoch: 6| Step: 7
Training loss: 1.3184098297636928
Validation loss: 2.6489905149246153

Epoch: 6| Step: 8
Training loss: 1.3426469223069581
Validation loss: 2.662332970988101

Epoch: 6| Step: 9
Training loss: 1.5562166907487733
Validation loss: 2.581125887868245

Epoch: 6| Step: 10
Training loss: 0.455928499134264
Validation loss: 2.5295497927314448

Epoch: 6| Step: 11
Training loss: 1.2331452823446127
Validation loss: 2.5004981200999326

Epoch: 6| Step: 12
Training loss: 1.4551606225302658
Validation loss: 2.5043572406885417

Epoch: 6| Step: 13
Training loss: 1.9141158738771642
Validation loss: 2.4951892095631636

Epoch: 185| Step: 0
Training loss: 1.5949771121305205
Validation loss: 2.504180186245427

Epoch: 6| Step: 1
Training loss: 1.5896067899653994
Validation loss: 2.486348815898381

Epoch: 6| Step: 2
Training loss: 1.2782115263435765
Validation loss: 2.5097848080610237

Epoch: 6| Step: 3
Training loss: 1.1107253868746823
Validation loss: 2.5360713866658893

Epoch: 6| Step: 4
Training loss: 1.4263110704912545
Validation loss: 2.602277007055054

Epoch: 6| Step: 5
Training loss: 0.9892294937102292
Validation loss: 2.645144731403247

Epoch: 6| Step: 6
Training loss: 1.3585276100068335
Validation loss: 2.6512707042934327

Epoch: 6| Step: 7
Training loss: 1.1665037018626863
Validation loss: 2.662442184283461

Epoch: 6| Step: 8
Training loss: 1.7214918288348031
Validation loss: 2.638374866478979

Epoch: 6| Step: 9
Training loss: 0.5630349688265561
Validation loss: 2.6531929274398593

Epoch: 6| Step: 10
Training loss: 1.4133728200116833
Validation loss: 2.627900592946244

Epoch: 6| Step: 11
Training loss: 1.3392708223514043
Validation loss: 2.619793517461651

Epoch: 6| Step: 12
Training loss: 1.3792875805468447
Validation loss: 2.596605871741722

Epoch: 6| Step: 13
Training loss: 1.2819299056906126
Validation loss: 2.5614764732841437

Epoch: 186| Step: 0
Training loss: 1.2060985727086504
Validation loss: 2.5327027705801224

Epoch: 6| Step: 1
Training loss: 1.3898686270071519
Validation loss: 2.565158088649938

Epoch: 6| Step: 2
Training loss: 1.4679076031287672
Validation loss: 2.5609392104429425

Epoch: 6| Step: 3
Training loss: 1.3094313943959182
Validation loss: 2.560545627494226

Epoch: 6| Step: 4
Training loss: 1.1127585807063214
Validation loss: 2.591601780284673

Epoch: 6| Step: 5
Training loss: 1.135731061518483
Validation loss: 2.604562756021052

Epoch: 6| Step: 6
Training loss: 1.063579403727405
Validation loss: 2.620535816986067

Epoch: 6| Step: 7
Training loss: 0.9504564167647944
Validation loss: 2.680814891134131

Epoch: 6| Step: 8
Training loss: 1.8455694241008722
Validation loss: 2.658514244174691

Epoch: 6| Step: 9
Training loss: 1.6931696414800592
Validation loss: 2.684456004005797

Epoch: 6| Step: 10
Training loss: 1.3701619951856596
Validation loss: 2.6820467209353267

Epoch: 6| Step: 11
Training loss: 1.2993266360780822
Validation loss: 2.6513936420997988

Epoch: 6| Step: 12
Training loss: 1.2772514939895825
Validation loss: 2.611660295617898

Epoch: 6| Step: 13
Training loss: 0.8308476729257169
Validation loss: 2.5902844348589418

Epoch: 187| Step: 0
Training loss: 1.2990381974440086
Validation loss: 2.571264777836427

Epoch: 6| Step: 1
Training loss: 1.2011072653164747
Validation loss: 2.601915557199114

Epoch: 6| Step: 2
Training loss: 0.9169828924290951
Validation loss: 2.6139860361167226

Epoch: 6| Step: 3
Training loss: 1.4828456026810009
Validation loss: 2.6609822632854847

Epoch: 6| Step: 4
Training loss: 0.7971909962349029
Validation loss: 2.6606468972243746

Epoch: 6| Step: 5
Training loss: 1.8232888704605377
Validation loss: 2.664203624062607

Epoch: 6| Step: 6
Training loss: 1.2938470536837463
Validation loss: 2.6774611645567434

Epoch: 6| Step: 7
Training loss: 1.073134495865894
Validation loss: 2.661934144564667

Epoch: 6| Step: 8
Training loss: 1.243838718259699
Validation loss: 2.6010825900015937

Epoch: 6| Step: 9
Training loss: 0.9653397493724397
Validation loss: 2.5601011874100696

Epoch: 6| Step: 10
Training loss: 1.4328755338858015
Validation loss: 2.5623965248727574

Epoch: 6| Step: 11
Training loss: 1.469757708349387
Validation loss: 2.5487131410533355

Epoch: 6| Step: 12
Training loss: 1.529388074238293
Validation loss: 2.5050582909031958

Epoch: 6| Step: 13
Training loss: 1.4140826482022384
Validation loss: 2.4921758080996863

Epoch: 188| Step: 0
Training loss: 1.6123391418657347
Validation loss: 2.4828092811520395

Epoch: 6| Step: 1
Training loss: 1.1468665348748817
Validation loss: 2.513593241115201

Epoch: 6| Step: 2
Training loss: 0.9894686113750265
Validation loss: 2.5154332555571783

Epoch: 6| Step: 3
Training loss: 1.6314818878805175
Validation loss: 2.6111281608293115

Epoch: 6| Step: 4
Training loss: 1.2350271892257396
Validation loss: 2.6431603824902483

Epoch: 6| Step: 5
Training loss: 1.4998652079736512
Validation loss: 2.6482092176705145

Epoch: 6| Step: 6
Training loss: 1.3889934097803813
Validation loss: 2.701555067302545

Epoch: 6| Step: 7
Training loss: 1.186739376810509
Validation loss: 2.6793799263127673

Epoch: 6| Step: 8
Training loss: 1.3103973257864283
Validation loss: 2.6667096165946282

Epoch: 6| Step: 9
Training loss: 1.184260869629196
Validation loss: 2.6275698587619907

Epoch: 6| Step: 10
Training loss: 1.6254619528648406
Validation loss: 2.604829799431515

Epoch: 6| Step: 11
Training loss: 0.640611439072897
Validation loss: 2.5636446497471934

Epoch: 6| Step: 12
Training loss: 1.116814557763096
Validation loss: 2.6038617362058534

Epoch: 6| Step: 13
Training loss: 1.2443869450224319
Validation loss: 2.579824087246543

Epoch: 189| Step: 0
Training loss: 1.0417356595397362
Validation loss: 2.6612766654104485

Epoch: 6| Step: 1
Training loss: 1.7635900873460655
Validation loss: 2.7237405617968533

Epoch: 6| Step: 2
Training loss: 1.0157727060749364
Validation loss: 2.7593837490348854

Epoch: 6| Step: 3
Training loss: 1.0901647389012936
Validation loss: 2.7625913319904005

Epoch: 6| Step: 4
Training loss: 1.0501110109047465
Validation loss: 2.7396707619485996

Epoch: 6| Step: 5
Training loss: 1.0917911427028353
Validation loss: 2.706103810190804

Epoch: 6| Step: 6
Training loss: 1.5418766840943725
Validation loss: 2.668685585930105

Epoch: 6| Step: 7
Training loss: 1.495033226919762
Validation loss: 2.6159905610912895

Epoch: 6| Step: 8
Training loss: 1.5790040995210624
Validation loss: 2.572211237900442

Epoch: 6| Step: 9
Training loss: 1.2893986119277794
Validation loss: 2.5150443102210764

Epoch: 6| Step: 10
Training loss: 1.5701750889719517
Validation loss: 2.4733600940184797

Epoch: 6| Step: 11
Training loss: 1.1213516842462774
Validation loss: 2.501417304339317

Epoch: 6| Step: 12
Training loss: 1.1471912083245022
Validation loss: 2.476012704361573

Epoch: 6| Step: 13
Training loss: 1.3193437080521537
Validation loss: 2.5476336652438043

Epoch: 190| Step: 0
Training loss: 0.9952677574461261
Validation loss: 2.564870488752083

Epoch: 6| Step: 1
Training loss: 1.3083434819275366
Validation loss: 2.6693348348024344

Epoch: 6| Step: 2
Training loss: 1.7389451034418608
Validation loss: 2.675145271542025

Epoch: 6| Step: 3
Training loss: 1.4037303816527589
Validation loss: 2.700693226310073

Epoch: 6| Step: 4
Training loss: 1.251350769725954
Validation loss: 2.6777426372775275

Epoch: 6| Step: 5
Training loss: 1.3028199312177031
Validation loss: 2.684543200269607

Epoch: 6| Step: 6
Training loss: 0.8488228851732436
Validation loss: 2.6301518545764533

Epoch: 6| Step: 7
Training loss: 1.0636223306930603
Validation loss: 2.6145136876658612

Epoch: 6| Step: 8
Training loss: 1.5102352778817993
Validation loss: 2.5729415707684256

Epoch: 6| Step: 9
Training loss: 1.1280519625619505
Validation loss: 2.5518114445307587

Epoch: 6| Step: 10
Training loss: 1.3346505016932042
Validation loss: 2.5647589898166974

Epoch: 6| Step: 11
Training loss: 1.3102352948760168
Validation loss: 2.533350772735573

Epoch: 6| Step: 12
Training loss: 1.212567665728908
Validation loss: 2.5779216727197283

Epoch: 6| Step: 13
Training loss: 1.0484550281315859
Validation loss: 2.561919222810197

Epoch: 191| Step: 0
Training loss: 1.3636622292782028
Validation loss: 2.6109216046457155

Epoch: 6| Step: 1
Training loss: 1.0406897859768764
Validation loss: 2.6427412829831907

Epoch: 6| Step: 2
Training loss: 1.4814133662662556
Validation loss: 2.677131800505887

Epoch: 6| Step: 3
Training loss: 1.3702069754079282
Validation loss: 2.6862846024385725

Epoch: 6| Step: 4
Training loss: 1.718191229416952
Validation loss: 2.7152699078573277

Epoch: 6| Step: 5
Training loss: 1.0199137587646236
Validation loss: 2.7255683579412935

Epoch: 6| Step: 6
Training loss: 1.293081826051171
Validation loss: 2.68051713131034

Epoch: 6| Step: 7
Training loss: 1.1025909060241057
Validation loss: 2.6067765868639166

Epoch: 6| Step: 8
Training loss: 1.421683665386745
Validation loss: 2.5890124440418982

Epoch: 6| Step: 9
Training loss: 1.364089114354458
Validation loss: 2.564477353206916

Epoch: 6| Step: 10
Training loss: 0.9425870842000007
Validation loss: 2.5773057100082877

Epoch: 6| Step: 11
Training loss: 1.0896325128857973
Validation loss: 2.580447707678538

Epoch: 6| Step: 12
Training loss: 0.7380174437996707
Validation loss: 2.576306170039761

Epoch: 6| Step: 13
Training loss: 1.2502046417570012
Validation loss: 2.6005139114742786

Epoch: 192| Step: 0
Training loss: 0.8683009860322127
Validation loss: 2.6340077317672277

Epoch: 6| Step: 1
Training loss: 0.9752730439628736
Validation loss: 2.6327479362391637

Epoch: 6| Step: 2
Training loss: 1.0158023972738557
Validation loss: 2.6413759999870683

Epoch: 6| Step: 3
Training loss: 1.2534312837114168
Validation loss: 2.5895020735254297

Epoch: 6| Step: 4
Training loss: 1.154142366192503
Validation loss: 2.615306894505895

Epoch: 6| Step: 5
Training loss: 1.1155694835537648
Validation loss: 2.6122669603738

Epoch: 6| Step: 6
Training loss: 1.2992236460159365
Validation loss: 2.6039320422070396

Epoch: 6| Step: 7
Training loss: 1.6106735472047968
Validation loss: 2.5860730177734728

Epoch: 6| Step: 8
Training loss: 0.7645504865598287
Validation loss: 2.615001428017442

Epoch: 6| Step: 9
Training loss: 1.787951795128745
Validation loss: 2.5870733574283205

Epoch: 6| Step: 10
Training loss: 1.1681365335955405
Validation loss: 2.5757701133555377

Epoch: 6| Step: 11
Training loss: 1.1501512780410477
Validation loss: 2.5676720479834074

Epoch: 6| Step: 12
Training loss: 1.524011122475234
Validation loss: 2.5764516820157155

Epoch: 6| Step: 13
Training loss: 1.1596962373199302
Validation loss: 2.6015709953214974

Epoch: 193| Step: 0
Training loss: 0.9716464089680548
Validation loss: 2.637735168877807

Epoch: 6| Step: 1
Training loss: 1.3281130621878467
Validation loss: 2.6377933438406185

Epoch: 6| Step: 2
Training loss: 1.510392033167817
Validation loss: 2.6250000639689373

Epoch: 6| Step: 3
Training loss: 1.3693833510102005
Validation loss: 2.6295456210498296

Epoch: 6| Step: 4
Training loss: 1.5156143817333028
Validation loss: 2.606723186819697

Epoch: 6| Step: 5
Training loss: 0.9360467773734948
Validation loss: 2.5986639710153607

Epoch: 6| Step: 6
Training loss: 1.3372442981472181
Validation loss: 2.634084517980661

Epoch: 6| Step: 7
Training loss: 0.9452622770729417
Validation loss: 2.592563835811598

Epoch: 6| Step: 8
Training loss: 1.021990561294268
Validation loss: 2.642649230589742

Epoch: 6| Step: 9
Training loss: 1.3799539967484749
Validation loss: 2.561150413297159

Epoch: 6| Step: 10
Training loss: 1.3081677099145903
Validation loss: 2.5401795479984632

Epoch: 6| Step: 11
Training loss: 1.465550448020176
Validation loss: 2.546333324336746

Epoch: 6| Step: 12
Training loss: 0.6479566928688301
Validation loss: 2.606939433623673

Epoch: 6| Step: 13
Training loss: 1.0054214857681276
Validation loss: 2.633733358123417

Epoch: 194| Step: 0
Training loss: 1.1101971118770548
Validation loss: 2.642571834678625

Epoch: 6| Step: 1
Training loss: 1.599389365021033
Validation loss: 2.6598764660048646

Epoch: 6| Step: 2
Training loss: 1.2788125089430329
Validation loss: 2.6569528131291884

Epoch: 6| Step: 3
Training loss: 1.0977892812026642
Validation loss: 2.652661913652063

Epoch: 6| Step: 4
Training loss: 1.3567956591462476
Validation loss: 2.6699935351718236

Epoch: 6| Step: 5
Training loss: 0.9260275790698831
Validation loss: 2.6288597903567905

Epoch: 6| Step: 6
Training loss: 1.1362817717454705
Validation loss: 2.5800850754260036

Epoch: 6| Step: 7
Training loss: 1.3474939663244139
Validation loss: 2.5257578279402235

Epoch: 6| Step: 8
Training loss: 1.2465255132788606
Validation loss: 2.509072149796939

Epoch: 6| Step: 9
Training loss: 1.3171642622702302
Validation loss: 2.5215942941433847

Epoch: 6| Step: 10
Training loss: 0.7378723384596567
Validation loss: 2.576499813540628

Epoch: 6| Step: 11
Training loss: 1.2010615104277778
Validation loss: 2.5809465567199794

Epoch: 6| Step: 12
Training loss: 1.1202481899131924
Validation loss: 2.6217955481176105

Epoch: 6| Step: 13
Training loss: 1.4405197270587482
Validation loss: 2.6528982114270656

Epoch: 195| Step: 0
Training loss: 1.369050984842495
Validation loss: 2.655791416913214

Epoch: 6| Step: 1
Training loss: 1.1088660778709727
Validation loss: 2.68135756226595

Epoch: 6| Step: 2
Training loss: 1.12727306458952
Validation loss: 2.684582866293372

Epoch: 6| Step: 3
Training loss: 1.0998919108777547
Validation loss: 2.6337977108424107

Epoch: 6| Step: 4
Training loss: 0.977062982104606
Validation loss: 2.5895091243881945

Epoch: 6| Step: 5
Training loss: 0.8207159231096777
Validation loss: 2.5431913422061205

Epoch: 6| Step: 6
Training loss: 1.217930200149006
Validation loss: 2.5189152278583022

Epoch: 6| Step: 7
Training loss: 1.3554940345010944
Validation loss: 2.5079066219562476

Epoch: 6| Step: 8
Training loss: 1.3464685928840783
Validation loss: 2.491806058173875

Epoch: 6| Step: 9
Training loss: 1.275384970122298
Validation loss: 2.469812080875818

Epoch: 6| Step: 10
Training loss: 1.5234364827470561
Validation loss: 2.4827618760347425

Epoch: 6| Step: 11
Training loss: 1.1328786896409098
Validation loss: 2.5110350313470082

Epoch: 6| Step: 12
Training loss: 1.2382025949425386
Validation loss: 2.524172173922324

Epoch: 6| Step: 13
Training loss: 0.914657138519966
Validation loss: 2.548523472641236

Epoch: 196| Step: 0
Training loss: 1.2697313356449182
Validation loss: 2.6347776736957558

Epoch: 6| Step: 1
Training loss: 1.163976576533387
Validation loss: 2.6658934437077657

Epoch: 6| Step: 2
Training loss: 1.4259982845301429
Validation loss: 2.622965397745725

Epoch: 6| Step: 3
Training loss: 1.1898528431214936
Validation loss: 2.626402039551358

Epoch: 6| Step: 4
Training loss: 1.37600931056887
Validation loss: 2.611144218338208

Epoch: 6| Step: 5
Training loss: 1.1833253562461368
Validation loss: 2.5467556084257494

Epoch: 6| Step: 6
Training loss: 1.2127399443125175
Validation loss: 2.573034728099348

Epoch: 6| Step: 7
Training loss: 0.8397426455653526
Validation loss: 2.56569193507565

Epoch: 6| Step: 8
Training loss: 1.0391716577083234
Validation loss: 2.5383913658547943

Epoch: 6| Step: 9
Training loss: 0.8417791732024367
Validation loss: 2.5724350274734875

Epoch: 6| Step: 10
Training loss: 1.0111100416620302
Validation loss: 2.572619324630377

Epoch: 6| Step: 11
Training loss: 0.9769860226637724
Validation loss: 2.6092123190048584

Epoch: 6| Step: 12
Training loss: 1.7466679595379497
Validation loss: 2.6145090575421572

Epoch: 6| Step: 13
Training loss: 1.0535473347418938
Validation loss: 2.6528605938712437

Epoch: 197| Step: 0
Training loss: 1.132707419947895
Validation loss: 2.634783660562529

Epoch: 6| Step: 1
Training loss: 1.2690326357072588
Validation loss: 2.590789998212364

Epoch: 6| Step: 2
Training loss: 1.0940470155972921
Validation loss: 2.570904021325813

Epoch: 6| Step: 3
Training loss: 1.4381849895964487
Validation loss: 2.5537512136845595

Epoch: 6| Step: 4
Training loss: 1.0584944787581958
Validation loss: 2.518091103681021

Epoch: 6| Step: 5
Training loss: 0.9297417696972933
Validation loss: 2.5038931630322923

Epoch: 6| Step: 6
Training loss: 1.0729078027056609
Validation loss: 2.502575484971062

Epoch: 6| Step: 7
Training loss: 1.6141028725079236
Validation loss: 2.5330152970819975

Epoch: 6| Step: 8
Training loss: 1.0725491397332987
Validation loss: 2.566899578339024

Epoch: 6| Step: 9
Training loss: 1.0325506850911021
Validation loss: 2.615966741382647

Epoch: 6| Step: 10
Training loss: 1.26851545336328
Validation loss: 2.6796103664023727

Epoch: 6| Step: 11
Training loss: 1.3892774160335533
Validation loss: 2.7136961409363995

Epoch: 6| Step: 12
Training loss: 0.9675028371646099
Validation loss: 2.696325323043004

Epoch: 6| Step: 13
Training loss: 1.1639181982116682
Validation loss: 2.6650173463368274

Epoch: 198| Step: 0
Training loss: 1.3593069037558545
Validation loss: 2.6458176809488556

Epoch: 6| Step: 1
Training loss: 1.408765704279833
Validation loss: 2.631705486307929

Epoch: 6| Step: 2
Training loss: 1.1822923612662584
Validation loss: 2.6220589993213848

Epoch: 6| Step: 3
Training loss: 1.1244208646604656
Validation loss: 2.6317724437095045

Epoch: 6| Step: 4
Training loss: 1.3073154867770682
Validation loss: 2.546902558578808

Epoch: 6| Step: 5
Training loss: 0.8623272211364235
Validation loss: 2.5105226971147903

Epoch: 6| Step: 6
Training loss: 1.2664746387802335
Validation loss: 2.4948848693511088

Epoch: 6| Step: 7
Training loss: 1.3171276979457698
Validation loss: 2.4532539370890203

Epoch: 6| Step: 8
Training loss: 1.3344404075011649
Validation loss: 2.4639960639592164

Epoch: 6| Step: 9
Training loss: 1.3760714691115146
Validation loss: 2.5285912276945566

Epoch: 6| Step: 10
Training loss: 0.8991129450855019
Validation loss: 2.574041196474246

Epoch: 6| Step: 11
Training loss: 0.850955641907211
Validation loss: 2.6379782906266662

Epoch: 6| Step: 12
Training loss: 0.9842319990163527
Validation loss: 2.700655230300543

Epoch: 6| Step: 13
Training loss: 1.0790493085128345
Validation loss: 2.726168004237989

Epoch: 199| Step: 0
Training loss: 1.5291514126521815
Validation loss: 2.7360819411844473

Epoch: 6| Step: 1
Training loss: 1.5400481964595176
Validation loss: 2.655347981956414

Epoch: 6| Step: 2
Training loss: 1.213180728440078
Validation loss: 2.6009096243292027

Epoch: 6| Step: 3
Training loss: 1.2297074642281514
Validation loss: 2.583040780231318

Epoch: 6| Step: 4
Training loss: 1.311184087211262
Validation loss: 2.560847713395553

Epoch: 6| Step: 5
Training loss: 1.3226401673368338
Validation loss: 2.542948478460538

Epoch: 6| Step: 6
Training loss: 0.8291088593681959
Validation loss: 2.5139661784726393

Epoch: 6| Step: 7
Training loss: 1.029683744339758
Validation loss: 2.468999273494149

Epoch: 6| Step: 8
Training loss: 1.0092553153400052
Validation loss: 2.465393418030105

Epoch: 6| Step: 9
Training loss: 1.1683421478991054
Validation loss: 2.5084244043510058

Epoch: 6| Step: 10
Training loss: 0.936916901133048
Validation loss: 2.5550818849955554

Epoch: 6| Step: 11
Training loss: 1.2672696201042075
Validation loss: 2.6513192968478143

Epoch: 6| Step: 12
Training loss: 0.8971746442585273
Validation loss: 2.7004758576539207

Epoch: 6| Step: 13
Training loss: 0.998068732752029
Validation loss: 2.7014879927871718

Epoch: 200| Step: 0
Training loss: 1.885249163807652
Validation loss: 2.6850398642399473

Epoch: 6| Step: 1
Training loss: 1.1967016886436144
Validation loss: 2.684972975817119

Epoch: 6| Step: 2
Training loss: 1.4776287770185514
Validation loss: 2.6743483516745625

Epoch: 6| Step: 3
Training loss: 0.5532691983125317
Validation loss: 2.61034790611865

Epoch: 6| Step: 4
Training loss: 1.2292077763466314
Validation loss: 2.5712132774786927

Epoch: 6| Step: 5
Training loss: 1.1577709092715225
Validation loss: 2.546160849143215

Epoch: 6| Step: 6
Training loss: 0.616794316079338
Validation loss: 2.5472345380868204

Epoch: 6| Step: 7
Training loss: 0.9609469901756035
Validation loss: 2.5426968228973243

Epoch: 6| Step: 8
Training loss: 1.3407054387927269
Validation loss: 2.5105791746927757

Epoch: 6| Step: 9
Training loss: 1.071827116138584
Validation loss: 2.552680165809692

Epoch: 6| Step: 10
Training loss: 0.9004938227829774
Validation loss: 2.5810734241589524

Epoch: 6| Step: 11
Training loss: 1.1579533479711415
Validation loss: 2.6163085911435475

Epoch: 6| Step: 12
Training loss: 0.8617523601821703
Validation loss: 2.6740609388866465

Epoch: 6| Step: 13
Training loss: 1.2974114285265164
Validation loss: 2.685654627870988

Epoch: 201| Step: 0
Training loss: 1.015500339780344
Validation loss: 2.688358447369782

Epoch: 6| Step: 1
Training loss: 1.3488588578749492
Validation loss: 2.677283678921007

Epoch: 6| Step: 2
Training loss: 1.0206728569065633
Validation loss: 2.633562539791446

Epoch: 6| Step: 3
Training loss: 1.0924094568089768
Validation loss: 2.5791749757049782

Epoch: 6| Step: 4
Training loss: 0.8460364973118065
Validation loss: 2.5381757769570537

Epoch: 6| Step: 5
Training loss: 0.8886055722497438
Validation loss: 2.535074801741742

Epoch: 6| Step: 6
Training loss: 1.1029137514482015
Validation loss: 2.505291008729389

Epoch: 6| Step: 7
Training loss: 1.4538841315569697
Validation loss: 2.5359461932863874

Epoch: 6| Step: 8
Training loss: 1.5177227329399272
Validation loss: 2.6086415731412083

Epoch: 6| Step: 9
Training loss: 0.7826132515069791
Validation loss: 2.7220129993763

Epoch: 6| Step: 10
Training loss: 1.2959728550187442
Validation loss: 2.7150008154910363

Epoch: 6| Step: 11
Training loss: 1.0189160357951426
Validation loss: 2.749805027751885

Epoch: 6| Step: 12
Training loss: 1.406008890463014
Validation loss: 2.708532469616928

Epoch: 6| Step: 13
Training loss: 1.0943273382957084
Validation loss: 2.637007133242564

Epoch: 202| Step: 0
Training loss: 1.236673797927887
Validation loss: 2.582995071719332

Epoch: 6| Step: 1
Training loss: 0.8620529066431646
Validation loss: 2.4953576823981094

Epoch: 6| Step: 2
Training loss: 1.5105928077155821
Validation loss: 2.527332137560885

Epoch: 6| Step: 3
Training loss: 0.630862587368466
Validation loss: 2.51944055390036

Epoch: 6| Step: 4
Training loss: 1.1735478985458048
Validation loss: 2.5751511113395926

Epoch: 6| Step: 5
Training loss: 1.273388867531991
Validation loss: 2.588966450814558

Epoch: 6| Step: 6
Training loss: 0.9214535412515368
Validation loss: 2.645250266039589

Epoch: 6| Step: 7
Training loss: 0.7754538868193201
Validation loss: 2.6759093608806257

Epoch: 6| Step: 8
Training loss: 1.2382126076141622
Validation loss: 2.6839117796217926

Epoch: 6| Step: 9
Training loss: 0.9776461273005842
Validation loss: 2.654265731129832

Epoch: 6| Step: 10
Training loss: 1.4606810972045585
Validation loss: 2.5983557739432754

Epoch: 6| Step: 11
Training loss: 1.071923206457579
Validation loss: 2.6434767047012193

Epoch: 6| Step: 12
Training loss: 0.8503968196112337
Validation loss: 2.645479589612968

Epoch: 6| Step: 13
Training loss: 1.4272737399231854
Validation loss: 2.6647997680293507

Epoch: 203| Step: 0
Training loss: 1.3520030808498336
Validation loss: 2.599575656362075

Epoch: 6| Step: 1
Training loss: 1.0115746944188604
Validation loss: 2.5747730001351883

Epoch: 6| Step: 2
Training loss: 1.3875549374263423
Validation loss: 2.535824491682181

Epoch: 6| Step: 3
Training loss: 0.9560147550852787
Validation loss: 2.4977514953475786

Epoch: 6| Step: 4
Training loss: 1.5368164248665563
Validation loss: 2.538141446217051

Epoch: 6| Step: 5
Training loss: 1.1708540474540168
Validation loss: 2.602723978084657

Epoch: 6| Step: 6
Training loss: 1.0505334498124297
Validation loss: 2.6777159595075415

Epoch: 6| Step: 7
Training loss: 0.9030727727763653
Validation loss: 2.7654819162993958

Epoch: 6| Step: 8
Training loss: 1.0384672941146196
Validation loss: 2.7592463632487974

Epoch: 6| Step: 9
Training loss: 1.3252639471621595
Validation loss: 2.7427312746932966

Epoch: 6| Step: 10
Training loss: 0.4420702168780651
Validation loss: 2.6225892035875646

Epoch: 6| Step: 11
Training loss: 1.0390462085335848
Validation loss: 2.5090501432818395

Epoch: 6| Step: 12
Training loss: 0.9645757882226159
Validation loss: 2.4834716649813666

Epoch: 6| Step: 13
Training loss: 1.201424573663573
Validation loss: 2.4502482034668454

Epoch: 204| Step: 0
Training loss: 0.9572283483464072
Validation loss: 2.444730154973824

Epoch: 6| Step: 1
Training loss: 0.8439693872133899
Validation loss: 2.483551184959632

Epoch: 6| Step: 2
Training loss: 0.9072762302234457
Validation loss: 2.5150352810483416

Epoch: 6| Step: 3
Training loss: 0.7126992582806254
Validation loss: 2.609328018697899

Epoch: 6| Step: 4
Training loss: 1.1894581360860166
Validation loss: 2.6954956125647223

Epoch: 6| Step: 5
Training loss: 1.301959537979021
Validation loss: 2.741440461284274

Epoch: 6| Step: 6
Training loss: 1.0821787599347805
Validation loss: 2.704033639098368

Epoch: 6| Step: 7
Training loss: 1.1787308104198015
Validation loss: 2.6754243183152253

Epoch: 6| Step: 8
Training loss: 1.3552542305088495
Validation loss: 2.6642264409321195

Epoch: 6| Step: 9
Training loss: 0.9270894589739672
Validation loss: 2.611482585160512

Epoch: 6| Step: 10
Training loss: 0.8628847065865531
Validation loss: 2.5410706964328242

Epoch: 6| Step: 11
Training loss: 1.4916057151545818
Validation loss: 2.5141347696408123

Epoch: 6| Step: 12
Training loss: 1.0368819912427005
Validation loss: 2.509568246995139

Epoch: 6| Step: 13
Training loss: 1.587154579129121
Validation loss: 2.52572440127795

Epoch: 205| Step: 0
Training loss: 0.8785955261288498
Validation loss: 2.5947906051385057

Epoch: 6| Step: 1
Training loss: 1.301575930595941
Validation loss: 2.59446201566496

Epoch: 6| Step: 2
Training loss: 0.5057703772063538
Validation loss: 2.6311605699651

Epoch: 6| Step: 3
Training loss: 0.9014717281137773
Validation loss: 2.6451946944741964

Epoch: 6| Step: 4
Training loss: 1.1326984742753887
Validation loss: 2.642783116865335

Epoch: 6| Step: 5
Training loss: 0.9632914793982718
Validation loss: 2.602028826595035

Epoch: 6| Step: 6
Training loss: 1.196972062679597
Validation loss: 2.5911885460478437

Epoch: 6| Step: 7
Training loss: 1.116079674826539
Validation loss: 2.5686321334398436

Epoch: 6| Step: 8
Training loss: 0.8620772445215397
Validation loss: 2.5463605882523086

Epoch: 6| Step: 9
Training loss: 1.1580390492313624
Validation loss: 2.5288480916008167

Epoch: 6| Step: 10
Training loss: 1.1506032439604048
Validation loss: 2.5082309463116825

Epoch: 6| Step: 11
Training loss: 1.5002755071031937
Validation loss: 2.522022174107293

Epoch: 6| Step: 12
Training loss: 1.057363830258478
Validation loss: 2.5917909020929546

Epoch: 6| Step: 13
Training loss: 0.8073685435125388
Validation loss: 2.6736332495101816

Epoch: 206| Step: 0
Training loss: 1.025757351645581
Validation loss: 2.6921551664357155

Epoch: 6| Step: 1
Training loss: 1.334587485840612
Validation loss: 2.7154796460854675

Epoch: 6| Step: 2
Training loss: 0.7349320591776193
Validation loss: 2.686339112128288

Epoch: 6| Step: 3
Training loss: 1.0272163341108869
Validation loss: 2.6822202053918818

Epoch: 6| Step: 4
Training loss: 1.2361565782755006
Validation loss: 2.6203537217795354

Epoch: 6| Step: 5
Training loss: 1.0575146119030354
Validation loss: 2.585765377232758

Epoch: 6| Step: 6
Training loss: 0.9048433238815493
Validation loss: 2.5563376237501707

Epoch: 6| Step: 7
Training loss: 1.0346567352246776
Validation loss: 2.5527643503461137

Epoch: 6| Step: 8
Training loss: 0.7277775520788656
Validation loss: 2.5593848944041815

Epoch: 6| Step: 9
Training loss: 1.1729405962511419
Validation loss: 2.604028667772332

Epoch: 6| Step: 10
Training loss: 1.1388986142578055
Validation loss: 2.6003761995099453

Epoch: 6| Step: 11
Training loss: 1.4035662154888158
Validation loss: 2.6201880103077393

Epoch: 6| Step: 12
Training loss: 0.8906704405854081
Validation loss: 2.5485171976313548

Epoch: 6| Step: 13
Training loss: 1.1985199722102784
Validation loss: 2.5190838175392476

Epoch: 207| Step: 0
Training loss: 0.9007040210712471
Validation loss: 2.514185773048355

Epoch: 6| Step: 1
Training loss: 1.094524000689769
Validation loss: 2.502600962716717

Epoch: 6| Step: 2
Training loss: 0.8942968736136856
Validation loss: 2.514873263149739

Epoch: 6| Step: 3
Training loss: 0.7489588186150165
Validation loss: 2.5193894187624193

Epoch: 6| Step: 4
Training loss: 1.1009376864144835
Validation loss: 2.5459337154052126

Epoch: 6| Step: 5
Training loss: 0.7125683199602421
Validation loss: 2.587100557662777

Epoch: 6| Step: 6
Training loss: 1.6912492146176519
Validation loss: 2.6429803863439267

Epoch: 6| Step: 7
Training loss: 1.2434091378865153
Validation loss: 2.7232834196660796

Epoch: 6| Step: 8
Training loss: 1.0487312826275477
Validation loss: 2.7710597109018487

Epoch: 6| Step: 9
Training loss: 0.9664355286686216
Validation loss: 2.76826508530112

Epoch: 6| Step: 10
Training loss: 1.1245537508597323
Validation loss: 2.6996061348851033

Epoch: 6| Step: 11
Training loss: 1.3130619571736781
Validation loss: 2.6275712705558543

Epoch: 6| Step: 12
Training loss: 1.0701477592266213
Validation loss: 2.5651968494139035

Epoch: 6| Step: 13
Training loss: 0.8890255402456706
Validation loss: 2.4611685174842384

Epoch: 208| Step: 0
Training loss: 1.0311228355840967
Validation loss: 2.437575774254768

Epoch: 6| Step: 1
Training loss: 1.6019447428761442
Validation loss: 2.4400846284183104

Epoch: 6| Step: 2
Training loss: 1.166540184430905
Validation loss: 2.501560434831452

Epoch: 6| Step: 3
Training loss: 1.2004492594248768
Validation loss: 2.56876510608889

Epoch: 6| Step: 4
Training loss: 1.0107617657373156
Validation loss: 2.609035649423951

Epoch: 6| Step: 5
Training loss: 1.1187065307867123
Validation loss: 2.65864693808728

Epoch: 6| Step: 6
Training loss: 1.2687369811043105
Validation loss: 2.674660758479967

Epoch: 6| Step: 7
Training loss: 1.1299158881117914
Validation loss: 2.6762669386498676

Epoch: 6| Step: 8
Training loss: 1.1541480470296175
Validation loss: 2.627258934393786

Epoch: 6| Step: 9
Training loss: 0.9768257396673816
Validation loss: 2.674497629688178

Epoch: 6| Step: 10
Training loss: 0.7553451326491811
Validation loss: 2.6358295723407075

Epoch: 6| Step: 11
Training loss: 0.9135153021029305
Validation loss: 2.534214381968516

Epoch: 6| Step: 12
Training loss: 0.9881280772808494
Validation loss: 2.4678081846315605

Epoch: 6| Step: 13
Training loss: 0.8470089106243047
Validation loss: 2.4648355853395345

Epoch: 209| Step: 0
Training loss: 1.0968833727394787
Validation loss: 2.449101663451959

Epoch: 6| Step: 1
Training loss: 1.101158067847408
Validation loss: 2.4833404105956154

Epoch: 6| Step: 2
Training loss: 0.9193261681923638
Validation loss: 2.4918224350092237

Epoch: 6| Step: 3
Training loss: 1.259479484294098
Validation loss: 2.58855251015264

Epoch: 6| Step: 4
Training loss: 1.030472664756945
Validation loss: 2.632844628900283

Epoch: 6| Step: 5
Training loss: 0.9793191987130585
Validation loss: 2.6993725041047085

Epoch: 6| Step: 6
Training loss: 1.003589624725753
Validation loss: 2.6907896821008292

Epoch: 6| Step: 7
Training loss: 1.0190534385505223
Validation loss: 2.7339091458166926

Epoch: 6| Step: 8
Training loss: 1.0599833022008032
Validation loss: 2.6477883553989887

Epoch: 6| Step: 9
Training loss: 0.8951922310942045
Validation loss: 2.5775216120856426

Epoch: 6| Step: 10
Training loss: 1.2896258423700713
Validation loss: 2.4885748053873655

Epoch: 6| Step: 11
Training loss: 1.3195516436792494
Validation loss: 2.475583916068028

Epoch: 6| Step: 12
Training loss: 0.6862317872540299
Validation loss: 2.4768867967436496

Epoch: 6| Step: 13
Training loss: 1.2340978963281468
Validation loss: 2.5176273219804

Epoch: 210| Step: 0
Training loss: 0.9527542143473011
Validation loss: 2.5681699526603143

Epoch: 6| Step: 1
Training loss: 1.0814912736305202
Validation loss: 2.632022570100255

Epoch: 6| Step: 2
Training loss: 0.7553619403937979
Validation loss: 2.651281454798371

Epoch: 6| Step: 3
Training loss: 1.1866081301756697
Validation loss: 2.667510905244238

Epoch: 6| Step: 4
Training loss: 0.5435366782118753
Validation loss: 2.6345309655909546

Epoch: 6| Step: 5
Training loss: 0.8438818440036179
Validation loss: 2.631202522691105

Epoch: 6| Step: 6
Training loss: 1.041536068676806
Validation loss: 2.613100236630751

Epoch: 6| Step: 7
Training loss: 1.2976051021924822
Validation loss: 2.586260760114972

Epoch: 6| Step: 8
Training loss: 1.2674114664371423
Validation loss: 2.5969353607485

Epoch: 6| Step: 9
Training loss: 0.9632188651495688
Validation loss: 2.583013769490636

Epoch: 6| Step: 10
Training loss: 0.749985813960381
Validation loss: 2.574665418042832

Epoch: 6| Step: 11
Training loss: 1.135942646418986
Validation loss: 2.5716631670913883

Epoch: 6| Step: 12
Training loss: 1.064387832178971
Validation loss: 2.547329814037778

Epoch: 6| Step: 13
Training loss: 1.6115234256643134
Validation loss: 2.5390088586686352

Epoch: 211| Step: 0
Training loss: 0.9037834011463942
Validation loss: 2.470732737340273

Epoch: 6| Step: 1
Training loss: 1.1299599346721252
Validation loss: 2.495738570104528

Epoch: 6| Step: 2
Training loss: 1.068984272583333
Validation loss: 2.4631962351353818

Epoch: 6| Step: 3
Training loss: 1.138770490141683
Validation loss: 2.529024702397374

Epoch: 6| Step: 4
Training loss: 0.7178901836922377
Validation loss: 2.5445664914879376

Epoch: 6| Step: 5
Training loss: 0.7299587488930105
Validation loss: 2.522041773206594

Epoch: 6| Step: 6
Training loss: 1.0218533201571838
Validation loss: 2.584817530124364

Epoch: 6| Step: 7
Training loss: 0.8010390820273448
Validation loss: 2.616038019543315

Epoch: 6| Step: 8
Training loss: 1.2918179279892357
Validation loss: 2.6558786266513774

Epoch: 6| Step: 9
Training loss: 1.1067916449291773
Validation loss: 2.6868444827584588

Epoch: 6| Step: 10
Training loss: 0.9104103748677346
Validation loss: 2.744764452829692

Epoch: 6| Step: 11
Training loss: 1.1080821926327862
Validation loss: 2.787911810323291

Epoch: 6| Step: 12
Training loss: 1.231612675885357
Validation loss: 2.758637306888354

Epoch: 6| Step: 13
Training loss: 0.8197122466714399
Validation loss: 2.7098554226119367

Epoch: 212| Step: 0
Training loss: 1.0252658150417506
Validation loss: 2.6717338359208633

Epoch: 6| Step: 1
Training loss: 1.0158463456966242
Validation loss: 2.5719850545845198

Epoch: 6| Step: 2
Training loss: 0.74595868550817
Validation loss: 2.5520857706533366

Epoch: 6| Step: 3
Training loss: 1.2912845764257634
Validation loss: 2.5094162403599474

Epoch: 6| Step: 4
Training loss: 0.9078856867114373
Validation loss: 2.4818159727969564

Epoch: 6| Step: 5
Training loss: 1.2356526486627535
Validation loss: 2.4659977747493436

Epoch: 6| Step: 6
Training loss: 0.7033854743837918
Validation loss: 2.532074368037697

Epoch: 6| Step: 7
Training loss: 0.8988682253437335
Validation loss: 2.6222305855969044

Epoch: 6| Step: 8
Training loss: 1.1510170233434553
Validation loss: 2.582248647254433

Epoch: 6| Step: 9
Training loss: 1.1877153101026243
Validation loss: 2.5780170754931193

Epoch: 6| Step: 10
Training loss: 1.0097727673866415
Validation loss: 2.56396380138161

Epoch: 6| Step: 11
Training loss: 0.9468632738249713
Validation loss: 2.523034829681073

Epoch: 6| Step: 12
Training loss: 0.868556582922955
Validation loss: 2.5467638235200494

Epoch: 6| Step: 13
Training loss: 0.4217416764564641
Validation loss: 2.5428436572642794

Epoch: 213| Step: 0
Training loss: 0.5661498179876016
Validation loss: 2.5743909118436403

Epoch: 6| Step: 1
Training loss: 1.2060120856911551
Validation loss: 2.5509082629587665

Epoch: 6| Step: 2
Training loss: 1.2055384716507158
Validation loss: 2.6434311155194474

Epoch: 6| Step: 3
Training loss: 0.7695027457442941
Validation loss: 2.6526021966044007

Epoch: 6| Step: 4
Training loss: 0.8275387686323086
Validation loss: 2.644879120046186

Epoch: 6| Step: 5
Training loss: 0.6327942033171249
Validation loss: 2.639796762609362

Epoch: 6| Step: 6
Training loss: 0.8013940094957398
Validation loss: 2.578048892372292

Epoch: 6| Step: 7
Training loss: 1.1486157129808765
Validation loss: 2.5367478682579008

Epoch: 6| Step: 8
Training loss: 1.3988659591266754
Validation loss: 2.51551421771264

Epoch: 6| Step: 9
Training loss: 1.0490914410282803
Validation loss: 2.4701635234914363

Epoch: 6| Step: 10
Training loss: 0.7292110611252962
Validation loss: 2.4800612842564185

Epoch: 6| Step: 11
Training loss: 0.8234385915672986
Validation loss: 2.500508613531876

Epoch: 6| Step: 12
Training loss: 0.9508560878416954
Validation loss: 2.567656079045373

Epoch: 6| Step: 13
Training loss: 1.3528039776098968
Validation loss: 2.618057575059854

Epoch: 214| Step: 0
Training loss: 0.9652892099857677
Validation loss: 2.6926702563857905

Epoch: 6| Step: 1
Training loss: 0.8165026886119598
Validation loss: 2.719307665596432

Epoch: 6| Step: 2
Training loss: 0.9494650564367655
Validation loss: 2.766017288335017

Epoch: 6| Step: 3
Training loss: 0.9924651831182005
Validation loss: 2.7318096159113274

Epoch: 6| Step: 4
Training loss: 1.1959770698868986
Validation loss: 2.614235222424701

Epoch: 6| Step: 5
Training loss: 0.9973104787348134
Validation loss: 2.447326462983845

Epoch: 6| Step: 6
Training loss: 1.0887226641756595
Validation loss: 2.379145845941652

Epoch: 6| Step: 7
Training loss: 1.265943369441008
Validation loss: 2.3254243567751898

Epoch: 6| Step: 8
Training loss: 1.0971705763904258
Validation loss: 2.346560825447065

Epoch: 6| Step: 9
Training loss: 0.6276326522588576
Validation loss: 2.3837194219377427

Epoch: 6| Step: 10
Training loss: 1.0018456830871394
Validation loss: 2.457521861196343

Epoch: 6| Step: 11
Training loss: 0.9787623842413211
Validation loss: 2.5662792478620466

Epoch: 6| Step: 12
Training loss: 0.8621472120948231
Validation loss: 2.673109018944277

Epoch: 6| Step: 13
Training loss: 1.56093832174438
Validation loss: 2.6987624555225667

Epoch: 215| Step: 0
Training loss: 0.998392571526411
Validation loss: 2.648880800731307

Epoch: 6| Step: 1
Training loss: 0.9390204497965464
Validation loss: 2.5845658130696028

Epoch: 6| Step: 2
Training loss: 0.902198416495535
Validation loss: 2.5028318937280263

Epoch: 6| Step: 3
Training loss: 0.9132599527112728
Validation loss: 2.5015648651096494

Epoch: 6| Step: 4
Training loss: 0.8124291682546477
Validation loss: 2.516209817620968

Epoch: 6| Step: 5
Training loss: 1.1370582728957621
Validation loss: 2.556746006578058

Epoch: 6| Step: 6
Training loss: 1.1909297302841466
Validation loss: 2.5767650986491835

Epoch: 6| Step: 7
Training loss: 0.9255757164053714
Validation loss: 2.6165783940601353

Epoch: 6| Step: 8
Training loss: 0.9192619143189331
Validation loss: 2.674596766879153

Epoch: 6| Step: 9
Training loss: 1.3666327522690889
Validation loss: 2.6914999123836143

Epoch: 6| Step: 10
Training loss: 0.8546702172242306
Validation loss: 2.6764887685816054

Epoch: 6| Step: 11
Training loss: 0.9460340221146292
Validation loss: 2.6721871987680172

Epoch: 6| Step: 12
Training loss: 1.2277876451267453
Validation loss: 2.6130200974803746

Epoch: 6| Step: 13
Training loss: 1.2269853482634625
Validation loss: 2.5136304063862562

Epoch: 216| Step: 0
Training loss: 1.1486765294868355
Validation loss: 2.501471477120065

Epoch: 6| Step: 1
Training loss: 0.7602642551077912
Validation loss: 2.5382968411392417

Epoch: 6| Step: 2
Training loss: 0.8538934844547003
Validation loss: 2.577029895356923

Epoch: 6| Step: 3
Training loss: 1.0020597226433865
Validation loss: 2.6594216171074727

Epoch: 6| Step: 4
Training loss: 1.054333436663423
Validation loss: 2.640311316508498

Epoch: 6| Step: 5
Training loss: 0.8607649919377065
Validation loss: 2.6019344717370063

Epoch: 6| Step: 6
Training loss: 1.021791663548497
Validation loss: 2.557453214991535

Epoch: 6| Step: 7
Training loss: 0.9883896236782767
Validation loss: 2.5030493126154933

Epoch: 6| Step: 8
Training loss: 1.1685950599823225
Validation loss: 2.4751661774172593

Epoch: 6| Step: 9
Training loss: 0.9059233570080504
Validation loss: 2.4694792051012877

Epoch: 6| Step: 10
Training loss: 0.9621270113469634
Validation loss: 2.440721526964285

Epoch: 6| Step: 11
Training loss: 1.2453134419474754
Validation loss: 2.4771067681596834

Epoch: 6| Step: 12
Training loss: 1.1843130613854447
Validation loss: 2.4906215787976707

Epoch: 6| Step: 13
Training loss: 0.33444687124392236
Validation loss: 2.529459779166613

Epoch: 217| Step: 0
Training loss: 0.7854499457380968
Validation loss: 2.5626742245972642

Epoch: 6| Step: 1
Training loss: 0.8119687764643059
Validation loss: 2.573572303867463

Epoch: 6| Step: 2
Training loss: 1.316686402345981
Validation loss: 2.6137427463563156

Epoch: 6| Step: 3
Training loss: 1.0657848182375773
Validation loss: 2.592329003453736

Epoch: 6| Step: 4
Training loss: 0.7380818092571935
Validation loss: 2.57559861006079

Epoch: 6| Step: 5
Training loss: 0.6616813604066959
Validation loss: 2.642131860658695

Epoch: 6| Step: 6
Training loss: 1.1628906188493293
Validation loss: 2.620329193283759

Epoch: 6| Step: 7
Training loss: 0.6444804316051452
Validation loss: 2.598600497378608

Epoch: 6| Step: 8
Training loss: 1.0043025440603561
Validation loss: 2.6065271074781253

Epoch: 6| Step: 9
Training loss: 1.1000407103027712
Validation loss: 2.5796029501773234

Epoch: 6| Step: 10
Training loss: 0.8091580545718138
Validation loss: 2.580609739288651

Epoch: 6| Step: 11
Training loss: 0.827476931650906
Validation loss: 2.5591722335586855

Epoch: 6| Step: 12
Training loss: 1.2374996281632915
Validation loss: 2.55808642907065

Epoch: 6| Step: 13
Training loss: 0.7384163061870864
Validation loss: 2.5371699734202426

Epoch: 218| Step: 0
Training loss: 0.9532886427183292
Validation loss: 2.5794693619736186

Epoch: 6| Step: 1
Training loss: 0.6677131833174584
Validation loss: 2.553362990190261

Epoch: 6| Step: 2
Training loss: 0.9622470337506605
Validation loss: 2.60358117853899

Epoch: 6| Step: 3
Training loss: 1.0066494403611512
Validation loss: 2.5803224468209502

Epoch: 6| Step: 4
Training loss: 0.9521017366351594
Validation loss: 2.61365413557589

Epoch: 6| Step: 5
Training loss: 0.734970176247407
Validation loss: 2.5797493380249668

Epoch: 6| Step: 6
Training loss: 0.8012060759789631
Validation loss: 2.5534171487400315

Epoch: 6| Step: 7
Training loss: 0.5846706937640715
Validation loss: 2.5274273867935317

Epoch: 6| Step: 8
Training loss: 0.5714033485278431
Validation loss: 2.5136627266705878

Epoch: 6| Step: 9
Training loss: 0.9600942680149638
Validation loss: 2.510618405888049

Epoch: 6| Step: 10
Training loss: 1.3839671169134156
Validation loss: 2.508046303860915

Epoch: 6| Step: 11
Training loss: 1.125509199829327
Validation loss: 2.5423231892479867

Epoch: 6| Step: 12
Training loss: 0.8850805130666308
Validation loss: 2.574473160625239

Epoch: 6| Step: 13
Training loss: 1.1083462740685228
Validation loss: 2.572005523129539

Epoch: 219| Step: 0
Training loss: 1.0367138354394099
Validation loss: 2.5732700808797375

Epoch: 6| Step: 1
Training loss: 0.7681361686322915
Validation loss: 2.564925198922237

Epoch: 6| Step: 2
Training loss: 1.0833391348365573
Validation loss: 2.5866200626525435

Epoch: 6| Step: 3
Training loss: 0.5138565427749832
Validation loss: 2.5983090038465915

Epoch: 6| Step: 4
Training loss: 1.0316278170130364
Validation loss: 2.583358018924559

Epoch: 6| Step: 5
Training loss: 0.6752603982282274
Validation loss: 2.5361868537926124

Epoch: 6| Step: 6
Training loss: 0.677795451377651
Validation loss: 2.5174682056549518

Epoch: 6| Step: 7
Training loss: 1.0899640088745062
Validation loss: 2.473748909981319

Epoch: 6| Step: 8
Training loss: 1.281561929832393
Validation loss: 2.4845304868075253

Epoch: 6| Step: 9
Training loss: 1.1247334164433234
Validation loss: 2.502371250020548

Epoch: 6| Step: 10
Training loss: 0.8729284150661468
Validation loss: 2.4753512871019683

Epoch: 6| Step: 11
Training loss: 0.47596927366440167
Validation loss: 2.5130223118601664

Epoch: 6| Step: 12
Training loss: 0.6040489778223792
Validation loss: 2.575596309789261

Epoch: 6| Step: 13
Training loss: 1.1482014316126647
Validation loss: 2.6263788643080335

Epoch: 220| Step: 0
Training loss: 1.1407792496568974
Validation loss: 2.7041622611260436

Epoch: 6| Step: 1
Training loss: 0.5957790138808935
Validation loss: 2.6988860863318433

Epoch: 6| Step: 2
Training loss: 0.9938704867466205
Validation loss: 2.723765816510021

Epoch: 6| Step: 3
Training loss: 0.9551840569348549
Validation loss: 2.669308984435307

Epoch: 6| Step: 4
Training loss: 0.9003117127499487
Validation loss: 2.649914394728799

Epoch: 6| Step: 5
Training loss: 0.9882260635105834
Validation loss: 2.588509414071478

Epoch: 6| Step: 6
Training loss: 0.8985659300189499
Validation loss: 2.5373624799024506

Epoch: 6| Step: 7
Training loss: 0.8326909132156447
Validation loss: 2.518619890373416

Epoch: 6| Step: 8
Training loss: 0.9882410214646182
Validation loss: 2.504597337100574

Epoch: 6| Step: 9
Training loss: 0.26032034364128115
Validation loss: 2.4884604911081407

Epoch: 6| Step: 10
Training loss: 0.6366332997279713
Validation loss: 2.5454881209848064

Epoch: 6| Step: 11
Training loss: 1.0409055154193076
Validation loss: 2.5056114311653936

Epoch: 6| Step: 12
Training loss: 1.1148357046220627
Validation loss: 2.5593974862762447

Epoch: 6| Step: 13
Training loss: 1.0229912869855202
Validation loss: 2.581271646580639

Epoch: 221| Step: 0
Training loss: 1.0866975388695364
Validation loss: 2.6207711812155052

Epoch: 6| Step: 1
Training loss: 1.2896217751306913
Validation loss: 2.5975355230208703

Epoch: 6| Step: 2
Training loss: 0.7132508922187581
Validation loss: 2.5468133359895733

Epoch: 6| Step: 3
Training loss: 0.957092470040482
Validation loss: 2.543544068519022

Epoch: 6| Step: 4
Training loss: 0.8195196770940947
Validation loss: 2.529067037686255

Epoch: 6| Step: 5
Training loss: 0.6933415800148247
Validation loss: 2.520681671757463

Epoch: 6| Step: 6
Training loss: 0.7535938149202442
Validation loss: 2.5103860195493137

Epoch: 6| Step: 7
Training loss: 1.101171437642639
Validation loss: 2.5468686303359105

Epoch: 6| Step: 8
Training loss: 0.7391515778940758
Validation loss: 2.5665088422723192

Epoch: 6| Step: 9
Training loss: 1.002342817584085
Validation loss: 2.503880874612457

Epoch: 6| Step: 10
Training loss: 0.7959436321883512
Validation loss: 2.5054495717932124

Epoch: 6| Step: 11
Training loss: 0.7107630085863323
Validation loss: 2.552539488504733

Epoch: 6| Step: 12
Training loss: 0.8332467669983094
Validation loss: 2.544185804816491

Epoch: 6| Step: 13
Training loss: 0.908957317951226
Validation loss: 2.556926728239137

Epoch: 222| Step: 0
Training loss: 1.0828947071834862
Validation loss: 2.598335417515832

Epoch: 6| Step: 1
Training loss: 0.8626367571120327
Validation loss: 2.577854134061476

Epoch: 6| Step: 2
Training loss: 0.9863571918094831
Validation loss: 2.570268715574894

Epoch: 6| Step: 3
Training loss: 1.1421099885661914
Validation loss: 2.5812447136657957

Epoch: 6| Step: 4
Training loss: 1.092697127254156
Validation loss: 2.560771079762738

Epoch: 6| Step: 5
Training loss: 1.076127233115879
Validation loss: 2.5712559590479063

Epoch: 6| Step: 6
Training loss: 0.7246732863545279
Validation loss: 2.513090343216435

Epoch: 6| Step: 7
Training loss: 0.9967631166626982
Validation loss: 2.4992062549404177

Epoch: 6| Step: 8
Training loss: 0.90152462197107
Validation loss: 2.4787277601136077

Epoch: 6| Step: 9
Training loss: 0.37730995642939097
Validation loss: 2.515748550050067

Epoch: 6| Step: 10
Training loss: 1.0011787024364538
Validation loss: 2.5118835157360033

Epoch: 6| Step: 11
Training loss: 0.5991844386258022
Validation loss: 2.5564580620121182

Epoch: 6| Step: 12
Training loss: 0.46090391004339415
Validation loss: 2.58065413901603

Epoch: 6| Step: 13
Training loss: 0.6266218124055934
Validation loss: 2.61827564004426

Epoch: 223| Step: 0
Training loss: 0.6559730126889061
Validation loss: 2.622996361042473

Epoch: 6| Step: 1
Training loss: 0.8540719879215192
Validation loss: 2.6598573225543363

Epoch: 6| Step: 2
Training loss: 0.93075301714912
Validation loss: 2.6291878768257515

Epoch: 6| Step: 3
Training loss: 0.3768499757040673
Validation loss: 2.6382917948054097

Epoch: 6| Step: 4
Training loss: 0.9738984047034993
Validation loss: 2.609044097812344

Epoch: 6| Step: 5
Training loss: 0.8604929501490204
Validation loss: 2.5356425875228923

Epoch: 6| Step: 6
Training loss: 0.5192368038688105
Validation loss: 2.5159026033337546

Epoch: 6| Step: 7
Training loss: 1.0870991812257873
Validation loss: 2.541936824393097

Epoch: 6| Step: 8
Training loss: 0.6830287669422439
Validation loss: 2.5090771349027823

Epoch: 6| Step: 9
Training loss: 0.3955791644502241
Validation loss: 2.529515966188858

Epoch: 6| Step: 10
Training loss: 1.2271797910816826
Validation loss: 2.5597024909538306

Epoch: 6| Step: 11
Training loss: 1.027132077765942
Validation loss: 2.55141227057916

Epoch: 6| Step: 12
Training loss: 1.1382321904173893
Validation loss: 2.5880340938846556

Epoch: 6| Step: 13
Training loss: 1.0579689687746403
Validation loss: 2.614034555815882

Epoch: 224| Step: 0
Training loss: 0.42834672685505626
Validation loss: 2.6095956472425947

Epoch: 6| Step: 1
Training loss: 1.1132379891539839
Validation loss: 2.578833440482173

Epoch: 6| Step: 2
Training loss: 1.021107124410306
Validation loss: 2.550742868187051

Epoch: 6| Step: 3
Training loss: 0.9322392361920524
Validation loss: 2.5490753223686986

Epoch: 6| Step: 4
Training loss: 0.6496616895281779
Validation loss: 2.534121879528277

Epoch: 6| Step: 5
Training loss: 0.388010603067941
Validation loss: 2.48116173269362

Epoch: 6| Step: 6
Training loss: 0.9248461930529007
Validation loss: 2.5013061925856626

Epoch: 6| Step: 7
Training loss: 0.9792273211800262
Validation loss: 2.4950218823201404

Epoch: 6| Step: 8
Training loss: 0.893119898008025
Validation loss: 2.460845042346

Epoch: 6| Step: 9
Training loss: 0.9962004660493672
Validation loss: 2.4938961619791624

Epoch: 6| Step: 10
Training loss: 0.6854000532075112
Validation loss: 2.5610556309771133

Epoch: 6| Step: 11
Training loss: 1.1942636213765556
Validation loss: 2.5751952965717906

Epoch: 6| Step: 12
Training loss: 0.7393348885471966
Validation loss: 2.601511057432211

Epoch: 6| Step: 13
Training loss: 0.4705949081182716
Validation loss: 2.6319566671330965

Epoch: 225| Step: 0
Training loss: 0.8419046355131096
Validation loss: 2.6935896641579378

Epoch: 6| Step: 1
Training loss: 0.8745233395484351
Validation loss: 2.7035561589439907

Epoch: 6| Step: 2
Training loss: 0.6179186920069374
Validation loss: 2.693715550007496

Epoch: 6| Step: 3
Training loss: 0.992991384612911
Validation loss: 2.6917687464311326

Epoch: 6| Step: 4
Training loss: 0.8739331417219233
Validation loss: 2.648184878449645

Epoch: 6| Step: 5
Training loss: 0.5131779025240438
Validation loss: 2.5435801108037763

Epoch: 6| Step: 6
Training loss: 0.6490046307585194
Validation loss: 2.5372044744254008

Epoch: 6| Step: 7
Training loss: 0.8057294599404733
Validation loss: 2.5259978408656805

Epoch: 6| Step: 8
Training loss: 0.9579326510717013
Validation loss: 2.4648673139945156

Epoch: 6| Step: 9
Training loss: 1.0027242745461786
Validation loss: 2.449258726963149

Epoch: 6| Step: 10
Training loss: 0.9933148384986002
Validation loss: 2.4244037955398587

Epoch: 6| Step: 11
Training loss: 0.8068006601519099
Validation loss: 2.4137387054397137

Epoch: 6| Step: 12
Training loss: 0.8655938979527846
Validation loss: 2.4702435424451217

Epoch: 6| Step: 13
Training loss: 1.1951766591393564
Validation loss: 2.4723116960204483

Epoch: 226| Step: 0
Training loss: 0.7482638928225803
Validation loss: 2.5447681257692953

Epoch: 6| Step: 1
Training loss: 0.7137026825567808
Validation loss: 2.530703118020731

Epoch: 6| Step: 2
Training loss: 0.6839399932283228
Validation loss: 2.5427254485968387

Epoch: 6| Step: 3
Training loss: 0.783930946890214
Validation loss: 2.5392163645125363

Epoch: 6| Step: 4
Training loss: 0.9624889224517262
Validation loss: 2.5185860895660155

Epoch: 6| Step: 5
Training loss: 0.6217315086556943
Validation loss: 2.5476827583031114

Epoch: 6| Step: 6
Training loss: 0.9904409339851513
Validation loss: 2.5545171935731563

Epoch: 6| Step: 7
Training loss: 0.9017649524084657
Validation loss: 2.560348804319855

Epoch: 6| Step: 8
Training loss: 0.8777711786720906
Validation loss: 2.614607528269308

Epoch: 6| Step: 9
Training loss: 0.5565017526964005
Validation loss: 2.6149416548355657

Epoch: 6| Step: 10
Training loss: 1.2018539353070528
Validation loss: 2.662148375697171

Epoch: 6| Step: 11
Training loss: 0.8505560851086806
Validation loss: 2.6465479807972416

Epoch: 6| Step: 12
Training loss: 0.881649297520309
Validation loss: 2.563589186234073

Epoch: 6| Step: 13
Training loss: 0.9467944044805999
Validation loss: 2.523348634872612

Epoch: 227| Step: 0
Training loss: 0.9467115531832941
Validation loss: 2.5140334694551774

Epoch: 6| Step: 1
Training loss: 0.8840983655712742
Validation loss: 2.510861259683527

Epoch: 6| Step: 2
Training loss: 0.8958172611894383
Validation loss: 2.569021436893435

Epoch: 6| Step: 3
Training loss: 0.6519628772040491
Validation loss: 2.573868278163431

Epoch: 6| Step: 4
Training loss: 1.0993319715414718
Validation loss: 2.622596997364946

Epoch: 6| Step: 5
Training loss: 0.7358115329371553
Validation loss: 2.609250353613465

Epoch: 6| Step: 6
Training loss: 0.7332629448170419
Validation loss: 2.636196133234849

Epoch: 6| Step: 7
Training loss: 0.6045225317615501
Validation loss: 2.617489627644774

Epoch: 6| Step: 8
Training loss: 0.8178568095767556
Validation loss: 2.590197152989598

Epoch: 6| Step: 9
Training loss: 0.43460633203626464
Validation loss: 2.580490195777062

Epoch: 6| Step: 10
Training loss: 0.6616814955275613
Validation loss: 2.528317739043143

Epoch: 6| Step: 11
Training loss: 1.1103824822541883
Validation loss: 2.5416882670543917

Epoch: 6| Step: 12
Training loss: 1.015515776409774
Validation loss: 2.527159432241306

Epoch: 6| Step: 13
Training loss: 0.9735819383375205
Validation loss: 2.5829637390764733

Epoch: 228| Step: 0
Training loss: 0.5789357763423503
Validation loss: 2.564294610337107

Epoch: 6| Step: 1
Training loss: 0.6550040679179244
Validation loss: 2.5759752406203833

Epoch: 6| Step: 2
Training loss: 0.8046387592850133
Validation loss: 2.5910914861790526

Epoch: 6| Step: 3
Training loss: 0.7624080180360965
Validation loss: 2.5605124281987264

Epoch: 6| Step: 4
Training loss: 0.8646592409446914
Validation loss: 2.52834092743752

Epoch: 6| Step: 5
Training loss: 0.8340777092551352
Validation loss: 2.5054718483430105

Epoch: 6| Step: 6
Training loss: 1.2551229403034105
Validation loss: 2.5205814056358467

Epoch: 6| Step: 7
Training loss: 0.8091875927147871
Validation loss: 2.5000094300779283

Epoch: 6| Step: 8
Training loss: 0.9906519925263757
Validation loss: 2.5209436066225037

Epoch: 6| Step: 9
Training loss: 0.9161925968439817
Validation loss: 2.5455479025867347

Epoch: 6| Step: 10
Training loss: 0.6894937562722048
Validation loss: 2.540714720505155

Epoch: 6| Step: 11
Training loss: 0.8845982677500541
Validation loss: 2.559131594402904

Epoch: 6| Step: 12
Training loss: 0.5113952720855436
Validation loss: 2.596559350524725

Epoch: 6| Step: 13
Training loss: 0.7905985922040693
Validation loss: 2.584689345783503

Epoch: 229| Step: 0
Training loss: 0.57369441791656
Validation loss: 2.6125656004685367

Epoch: 6| Step: 1
Training loss: 1.0134272344482778
Validation loss: 2.572332636673325

Epoch: 6| Step: 2
Training loss: 0.7641398759289697
Validation loss: 2.549185882129495

Epoch: 6| Step: 3
Training loss: 0.791295244692086
Validation loss: 2.5379865963297625

Epoch: 6| Step: 4
Training loss: 0.9433779191431575
Validation loss: 2.5134466471157695

Epoch: 6| Step: 5
Training loss: 0.7662627230610064
Validation loss: 2.481318382741947

Epoch: 6| Step: 6
Training loss: 0.5726604466720372
Validation loss: 2.464133398242531

Epoch: 6| Step: 7
Training loss: 0.943865085683613
Validation loss: 2.4772562763425605

Epoch: 6| Step: 8
Training loss: 0.9881056075391894
Validation loss: 2.528589528462549

Epoch: 6| Step: 9
Training loss: 0.6552109667225262
Validation loss: 2.5421869588313184

Epoch: 6| Step: 10
Training loss: 0.7386175126557933
Validation loss: 2.5572441142934363

Epoch: 6| Step: 11
Training loss: 0.5861996890605725
Validation loss: 2.586660959741538

Epoch: 6| Step: 12
Training loss: 1.0478147018505048
Validation loss: 2.591786861952861

Epoch: 6| Step: 13
Training loss: 1.0236714801789024
Validation loss: 2.5502952973729833

Epoch: 230| Step: 0
Training loss: 1.1246898011536202
Validation loss: 2.4969110540731427

Epoch: 6| Step: 1
Training loss: 0.8887134584192686
Validation loss: 2.5254831173349026

Epoch: 6| Step: 2
Training loss: 0.8657519168287269
Validation loss: 2.439558776791846

Epoch: 6| Step: 3
Training loss: 0.8084202455877171
Validation loss: 2.4670427160734207

Epoch: 6| Step: 4
Training loss: 0.5887349298091307
Validation loss: 2.4892640535742263

Epoch: 6| Step: 5
Training loss: 0.6434094463381829
Validation loss: 2.4976458817554827

Epoch: 6| Step: 6
Training loss: 0.7828004329764017
Validation loss: 2.553335704657249

Epoch: 6| Step: 7
Training loss: 0.7974237534717744
Validation loss: 2.5926538121127622

Epoch: 6| Step: 8
Training loss: 0.8804869276741096
Validation loss: 2.577682028234466

Epoch: 6| Step: 9
Training loss: 0.8456801836456953
Validation loss: 2.563203076409307

Epoch: 6| Step: 10
Training loss: 0.5615263565651029
Validation loss: 2.5590717564590233

Epoch: 6| Step: 11
Training loss: 0.5962100014375883
Validation loss: 2.5304951344219315

Epoch: 6| Step: 12
Training loss: 0.9884713634632373
Validation loss: 2.5147406133604693

Epoch: 6| Step: 13
Training loss: 0.8194558166174571
Validation loss: 2.51040705084709

Epoch: 231| Step: 0
Training loss: 0.9351704264166208
Validation loss: 2.511934157640867

Epoch: 6| Step: 1
Training loss: 0.6108938508892447
Validation loss: 2.4761471824364145

Epoch: 6| Step: 2
Training loss: 0.9937919199996812
Validation loss: 2.4738802323159677

Epoch: 6| Step: 3
Training loss: 0.5153600705723298
Validation loss: 2.497337150113098

Epoch: 6| Step: 4
Training loss: 0.6551804227802451
Validation loss: 2.456822403583199

Epoch: 6| Step: 5
Training loss: 0.6735568398857891
Validation loss: 2.5212349025608565

Epoch: 6| Step: 6
Training loss: 0.8429432296778816
Validation loss: 2.5519132482537557

Epoch: 6| Step: 7
Training loss: 0.9546002087432806
Validation loss: 2.555135296253406

Epoch: 6| Step: 8
Training loss: 0.6872460589887369
Validation loss: 2.598677851474037

Epoch: 6| Step: 9
Training loss: 0.8353842214497498
Validation loss: 2.617618605239991

Epoch: 6| Step: 10
Training loss: 0.7693162801787435
Validation loss: 2.6230148088556504

Epoch: 6| Step: 11
Training loss: 0.5993411181661764
Validation loss: 2.6282312699044263

Epoch: 6| Step: 12
Training loss: 0.8314381666102659
Validation loss: 2.6088573425467683

Epoch: 6| Step: 13
Training loss: 1.1949159550340902
Validation loss: 2.6003625037264264

Epoch: 232| Step: 0
Training loss: 0.9730813809359705
Validation loss: 2.534512358922164

Epoch: 6| Step: 1
Training loss: 0.8891043480542503
Validation loss: 2.511725202679178

Epoch: 6| Step: 2
Training loss: 0.9001044689581605
Validation loss: 2.471707180562606

Epoch: 6| Step: 3
Training loss: 0.8582935811685998
Validation loss: 2.456652995316528

Epoch: 6| Step: 4
Training loss: 0.5968644375890092
Validation loss: 2.4823752153498897

Epoch: 6| Step: 5
Training loss: 0.8099030293004942
Validation loss: 2.535108976310329

Epoch: 6| Step: 6
Training loss: 0.4147976521025509
Validation loss: 2.5643907825000625

Epoch: 6| Step: 7
Training loss: 1.0015258472895252
Validation loss: 2.6576491143827923

Epoch: 6| Step: 8
Training loss: 0.9412476971966663
Validation loss: 2.6747635815961046

Epoch: 6| Step: 9
Training loss: 0.49391656251186156
Validation loss: 2.670164703040672

Epoch: 6| Step: 10
Training loss: 1.0325261514044308
Validation loss: 2.631655694792852

Epoch: 6| Step: 11
Training loss: 0.7868780738097882
Validation loss: 2.579684991540238

Epoch: 6| Step: 12
Training loss: 0.562856614133007
Validation loss: 2.524424118345984

Epoch: 6| Step: 13
Training loss: 0.5521662457903314
Validation loss: 2.5256584774167052

Epoch: 233| Step: 0
Training loss: 0.8367663044955149
Validation loss: 2.523113380655792

Epoch: 6| Step: 1
Training loss: 0.6726730176229192
Validation loss: 2.5075195885646853

Epoch: 6| Step: 2
Training loss: 0.5341642890119478
Validation loss: 2.5133027527432423

Epoch: 6| Step: 3
Training loss: 0.5884227942089295
Validation loss: 2.5350541970675966

Epoch: 6| Step: 4
Training loss: 0.6843520400145591
Validation loss: 2.5240006433900883

Epoch: 6| Step: 5
Training loss: 0.8982554707433557
Validation loss: 2.5725787245035114

Epoch: 6| Step: 6
Training loss: 0.9056071928496863
Validation loss: 2.5298887821408216

Epoch: 6| Step: 7
Training loss: 0.7725006749171793
Validation loss: 2.532784048144596

Epoch: 6| Step: 8
Training loss: 0.7733429745026562
Validation loss: 2.5687723296395313

Epoch: 6| Step: 9
Training loss: 0.8732567861245822
Validation loss: 2.568901805195995

Epoch: 6| Step: 10
Training loss: 0.941904466417437
Validation loss: 2.5184854509229813

Epoch: 6| Step: 11
Training loss: 0.8123615953965712
Validation loss: 2.491554325120224

Epoch: 6| Step: 12
Training loss: 0.7405744994124445
Validation loss: 2.498519005540355

Epoch: 6| Step: 13
Training loss: 0.8600573171877058
Validation loss: 2.49127661986078

Epoch: 234| Step: 0
Training loss: 0.4782748180855452
Validation loss: 2.5109500664697615

Epoch: 6| Step: 1
Training loss: 0.552541045222091
Validation loss: 2.514635237203061

Epoch: 6| Step: 2
Training loss: 0.5133827178854214
Validation loss: 2.543716042870378

Epoch: 6| Step: 3
Training loss: 0.8486875246450959
Validation loss: 2.55513524734113

Epoch: 6| Step: 4
Training loss: 0.8599645846304923
Validation loss: 2.5952728649944907

Epoch: 6| Step: 5
Training loss: 0.7690657936220971
Validation loss: 2.6419504956138926

Epoch: 6| Step: 6
Training loss: 0.9202249598683351
Validation loss: 2.636649749959005

Epoch: 6| Step: 7
Training loss: 0.7880051960289719
Validation loss: 2.605327174768687

Epoch: 6| Step: 8
Training loss: 0.6760556540391642
Validation loss: 2.604946017559127

Epoch: 6| Step: 9
Training loss: 0.8492558938810955
Validation loss: 2.565397258925374

Epoch: 6| Step: 10
Training loss: 0.7736047506118483
Validation loss: 2.5390733722110075

Epoch: 6| Step: 11
Training loss: 0.728051290751465
Validation loss: 2.5180362372536513

Epoch: 6| Step: 12
Training loss: 1.2158122234764799
Validation loss: 2.455069911155085

Epoch: 6| Step: 13
Training loss: 0.7543511535617506
Validation loss: 2.452762194181202

Epoch: 235| Step: 0
Training loss: 0.734708507372178
Validation loss: 2.4343098204012628

Epoch: 6| Step: 1
Training loss: 0.7294469612533654
Validation loss: 2.4515743581304585

Epoch: 6| Step: 2
Training loss: 0.6149395190714775
Validation loss: 2.466084913159344

Epoch: 6| Step: 3
Training loss: 0.6739562424200327
Validation loss: 2.5489723135550895

Epoch: 6| Step: 4
Training loss: 0.7337032654808012
Validation loss: 2.628064575335681

Epoch: 6| Step: 5
Training loss: 0.9182914004528355
Validation loss: 2.6468195886939543

Epoch: 6| Step: 6
Training loss: 0.8951111292441553
Validation loss: 2.6289394671370805

Epoch: 6| Step: 7
Training loss: 0.5920911504223634
Validation loss: 2.6159378959797985

Epoch: 6| Step: 8
Training loss: 1.0516733686432087
Validation loss: 2.540480609476791

Epoch: 6| Step: 9
Training loss: 0.5620755607608631
Validation loss: 2.5169551091885025

Epoch: 6| Step: 10
Training loss: 0.8222184337565919
Validation loss: 2.438862237202182

Epoch: 6| Step: 11
Training loss: 0.8819767194300755
Validation loss: 2.4196901848862966

Epoch: 6| Step: 12
Training loss: 0.9866184524943303
Validation loss: 2.4033494910493114

Epoch: 6| Step: 13
Training loss: 0.4296228880421081
Validation loss: 2.405041179388435

Epoch: 236| Step: 0
Training loss: 0.6377729102879192
Validation loss: 2.434588688606724

Epoch: 6| Step: 1
Training loss: 0.8269933489863012
Validation loss: 2.5094482328437335

Epoch: 6| Step: 2
Training loss: 0.8340321154185614
Validation loss: 2.600171479856332

Epoch: 6| Step: 3
Training loss: 0.7889444243967265
Validation loss: 2.617664448589156

Epoch: 6| Step: 4
Training loss: 0.8880319827695227
Validation loss: 2.6197552347048543

Epoch: 6| Step: 5
Training loss: 0.9204369659971418
Validation loss: 2.63216565743004

Epoch: 6| Step: 6
Training loss: 0.7688371655429102
Validation loss: 2.5668615484012425

Epoch: 6| Step: 7
Training loss: 0.4930423095278983
Validation loss: 2.5742969491414165

Epoch: 6| Step: 8
Training loss: 0.7763691452289585
Validation loss: 2.534390461010936

Epoch: 6| Step: 9
Training loss: 0.8007551979851394
Validation loss: 2.4962703638435784

Epoch: 6| Step: 10
Training loss: 0.8741070073415845
Validation loss: 2.476927082707912

Epoch: 6| Step: 11
Training loss: 0.7537475577041256
Validation loss: 2.4578359794956786

Epoch: 6| Step: 12
Training loss: 0.5762596192870685
Validation loss: 2.459760705837949

Epoch: 6| Step: 13
Training loss: 0.6442726541265746
Validation loss: 2.445314460488104

Epoch: 237| Step: 0
Training loss: 0.6158430691140048
Validation loss: 2.519218671798551

Epoch: 6| Step: 1
Training loss: 0.5400816916115264
Validation loss: 2.5189001110857343

Epoch: 6| Step: 2
Training loss: 0.8795089350729581
Validation loss: 2.562519959302756

Epoch: 6| Step: 3
Training loss: 0.6198877105240532
Validation loss: 2.5273175884626773

Epoch: 6| Step: 4
Training loss: 0.5811205914732837
Validation loss: 2.508024161594841

Epoch: 6| Step: 5
Training loss: 1.166237252544967
Validation loss: 2.487511305510991

Epoch: 6| Step: 6
Training loss: 0.6950343572234018
Validation loss: 2.4850531728397165

Epoch: 6| Step: 7
Training loss: 0.6191090717157521
Validation loss: 2.4508528534450353

Epoch: 6| Step: 8
Training loss: 0.772799218877749
Validation loss: 2.4610663444567145

Epoch: 6| Step: 9
Training loss: 1.0206975003133867
Validation loss: 2.4635457223536537

Epoch: 6| Step: 10
Training loss: 0.5734840935427676
Validation loss: 2.463576272992281

Epoch: 6| Step: 11
Training loss: 0.7073416687075476
Validation loss: 2.524386987072661

Epoch: 6| Step: 12
Training loss: 0.8224212789112104
Validation loss: 2.517205846003708

Epoch: 6| Step: 13
Training loss: 0.7094242213309359
Validation loss: 2.5217897930725486

Epoch: 238| Step: 0
Training loss: 0.4596543961047405
Validation loss: 2.534540189484026

Epoch: 6| Step: 1
Training loss: 0.6198696813984063
Validation loss: 2.5119852312437785

Epoch: 6| Step: 2
Training loss: 0.7816338931074504
Validation loss: 2.531224576659593

Epoch: 6| Step: 3
Training loss: 0.7645686121328101
Validation loss: 2.5236019191565924

Epoch: 6| Step: 4
Training loss: 0.7738126365193791
Validation loss: 2.5237356279216034

Epoch: 6| Step: 5
Training loss: 0.8524439388311381
Validation loss: 2.5386360288633907

Epoch: 6| Step: 6
Training loss: 0.7216279420381351
Validation loss: 2.5228086819763154

Epoch: 6| Step: 7
Training loss: 0.3786804666994567
Validation loss: 2.523466338585884

Epoch: 6| Step: 8
Training loss: 0.9640978196164457
Validation loss: 2.5345580698860286

Epoch: 6| Step: 9
Training loss: 0.5921525044027586
Validation loss: 2.5231117996622032

Epoch: 6| Step: 10
Training loss: 0.6699014554929432
Validation loss: 2.540246760208103

Epoch: 6| Step: 11
Training loss: 0.8487353509866337
Validation loss: 2.5423242107418127

Epoch: 6| Step: 12
Training loss: 1.113888705315156
Validation loss: 2.562400019066075

Epoch: 6| Step: 13
Training loss: 0.437200886792054
Validation loss: 2.5853205714096283

Epoch: 239| Step: 0
Training loss: 0.603647532445597
Validation loss: 2.5985091149145614

Epoch: 6| Step: 1
Training loss: 0.8363381254693136
Validation loss: 2.6139061462682784

Epoch: 6| Step: 2
Training loss: 0.8515629199665679
Validation loss: 2.6050095550555232

Epoch: 6| Step: 3
Training loss: 0.7633742901449119
Validation loss: 2.582001217764298

Epoch: 6| Step: 4
Training loss: 0.9762622524278989
Validation loss: 2.567343732747321

Epoch: 6| Step: 5
Training loss: 0.7875906559064866
Validation loss: 2.551145187702276

Epoch: 6| Step: 6
Training loss: 0.6172509221193294
Validation loss: 2.514162933348904

Epoch: 6| Step: 7
Training loss: 0.6293291837803306
Validation loss: 2.5175297890627677

Epoch: 6| Step: 8
Training loss: 0.7675984697824625
Validation loss: 2.5413543540223302

Epoch: 6| Step: 9
Training loss: 0.7471415566774589
Validation loss: 2.5240022725807396

Epoch: 6| Step: 10
Training loss: 0.6636089795841592
Validation loss: 2.488688662709445

Epoch: 6| Step: 11
Training loss: 0.7271005422601421
Validation loss: 2.5061030372638475

Epoch: 6| Step: 12
Training loss: 0.6579236758919526
Validation loss: 2.547774664242008

Epoch: 6| Step: 13
Training loss: 0.21233236102676797
Validation loss: 2.5302945947864584

Epoch: 240| Step: 0
Training loss: 0.5820297394803307
Validation loss: 2.5481091932635267

Epoch: 6| Step: 1
Training loss: 0.8110628622835733
Validation loss: 2.530589590916894

Epoch: 6| Step: 2
Training loss: 0.5802263269653426
Validation loss: 2.559507543071787

Epoch: 6| Step: 3
Training loss: 0.579284330349254
Validation loss: 2.558472537510698

Epoch: 6| Step: 4
Training loss: 0.9029816853682098
Validation loss: 2.5821878125968736

Epoch: 6| Step: 5
Training loss: 0.9468156827469865
Validation loss: 2.564880479939549

Epoch: 6| Step: 6
Training loss: 0.7854969557005653
Validation loss: 2.5174027030845996

Epoch: 6| Step: 7
Training loss: 0.5409109517000625
Validation loss: 2.541606033572964

Epoch: 6| Step: 8
Training loss: 0.8905136975793674
Validation loss: 2.5139233431142123

Epoch: 6| Step: 9
Training loss: 0.8011259500108343
Validation loss: 2.497736466029075

Epoch: 6| Step: 10
Training loss: 0.7360312270557771
Validation loss: 2.5210496841320085

Epoch: 6| Step: 11
Training loss: 0.6718721389709592
Validation loss: 2.521070579186084

Epoch: 6| Step: 12
Training loss: 0.5730180708414031
Validation loss: 2.5154660153721338

Epoch: 6| Step: 13
Training loss: 0.1647541589125176
Validation loss: 2.543421369738026

Epoch: 241| Step: 0
Training loss: 0.9042211711001443
Validation loss: 2.5609339879344275

Epoch: 6| Step: 1
Training loss: 0.7046624012133481
Validation loss: 2.5615290906624653

Epoch: 6| Step: 2
Training loss: 0.39381284742002504
Validation loss: 2.5593012802379262

Epoch: 6| Step: 3
Training loss: 0.8452222835889885
Validation loss: 2.5807418424751707

Epoch: 6| Step: 4
Training loss: 0.5037123728536069
Validation loss: 2.588992582530137

Epoch: 6| Step: 5
Training loss: 0.46474660932300277
Validation loss: 2.586635680611964

Epoch: 6| Step: 6
Training loss: 1.0045061508415727
Validation loss: 2.5496054605324354

Epoch: 6| Step: 7
Training loss: 0.9858248493628144
Validation loss: 2.543508715137504

Epoch: 6| Step: 8
Training loss: 0.7312765295970896
Validation loss: 2.526857198062983

Epoch: 6| Step: 9
Training loss: 0.5422671608572676
Validation loss: 2.4993269650179823

Epoch: 6| Step: 10
Training loss: 0.7195653437221361
Validation loss: 2.5006872381042604

Epoch: 6| Step: 11
Training loss: 0.426288512551243
Validation loss: 2.466713425254914

Epoch: 6| Step: 12
Training loss: 0.9568729814723655
Validation loss: 2.5348642231832064

Epoch: 6| Step: 13
Training loss: 0.16339338184900778
Validation loss: 2.53361921588378

Epoch: 242| Step: 0
Training loss: 0.6801126400133485
Validation loss: 2.606066608682742

Epoch: 6| Step: 1
Training loss: 0.30521354746785856
Validation loss: 2.6731509913632006

Epoch: 6| Step: 2
Training loss: 0.8317008638581805
Validation loss: 2.6583597007624458

Epoch: 6| Step: 3
Training loss: 0.6238889355242878
Validation loss: 2.7212897707846695

Epoch: 6| Step: 4
Training loss: 0.7569231143088686
Validation loss: 2.6384474767451387

Epoch: 6| Step: 5
Training loss: 0.7503338706433905
Validation loss: 2.5222957873780567

Epoch: 6| Step: 6
Training loss: 0.9572402103169559
Validation loss: 2.4377468668808304

Epoch: 6| Step: 7
Training loss: 0.9469090370632471
Validation loss: 2.390857215287722

Epoch: 6| Step: 8
Training loss: 0.9411437432343849
Validation loss: 2.4062089243998575

Epoch: 6| Step: 9
Training loss: 0.5025046320839323
Validation loss: 2.405393212737789

Epoch: 6| Step: 10
Training loss: 0.7927480305888129
Validation loss: 2.4078314370374905

Epoch: 6| Step: 11
Training loss: 0.7149436338921722
Validation loss: 2.4897693680029067

Epoch: 6| Step: 12
Training loss: 0.5654649476437088
Validation loss: 2.570014856836696

Epoch: 6| Step: 13
Training loss: 0.4436620275845782
Validation loss: 2.600108383182003

Epoch: 243| Step: 0
Training loss: 0.9430196715150806
Validation loss: 2.598237825411557

Epoch: 6| Step: 1
Training loss: 0.7519911322958571
Validation loss: 2.5794561316278104

Epoch: 6| Step: 2
Training loss: 0.5242407030946653
Validation loss: 2.496066885019882

Epoch: 6| Step: 3
Training loss: 0.7224482056423253
Validation loss: 2.4782124378216746

Epoch: 6| Step: 4
Training loss: 0.7707165724155882
Validation loss: 2.499946960788989

Epoch: 6| Step: 5
Training loss: 0.6157589326195884
Validation loss: 2.5168502046640446

Epoch: 6| Step: 6
Training loss: 0.682704499736131
Validation loss: 2.5192936519344196

Epoch: 6| Step: 7
Training loss: 0.7699387531569141
Validation loss: 2.574881640074697

Epoch: 6| Step: 8
Training loss: 0.4630422223203157
Validation loss: 2.6103206790276445

Epoch: 6| Step: 9
Training loss: 0.8859785914773121
Validation loss: 2.6427621597495063

Epoch: 6| Step: 10
Training loss: 0.6128088230954538
Validation loss: 2.6187932477978526

Epoch: 6| Step: 11
Training loss: 0.970803883041739
Validation loss: 2.5934391697853565

Epoch: 6| Step: 12
Training loss: 0.7529066901152048
Validation loss: 2.577806370927925

Epoch: 6| Step: 13
Training loss: 0.5653728660797932
Validation loss: 2.5433623233631497

Epoch: 244| Step: 0
Training loss: 0.6601772869302063
Validation loss: 2.510374068767357

Epoch: 6| Step: 1
Training loss: 0.5088339289763674
Validation loss: 2.500216093260838

Epoch: 6| Step: 2
Training loss: 0.7058250929799192
Validation loss: 2.5212937731764695

Epoch: 6| Step: 3
Training loss: 0.5660929635590227
Validation loss: 2.494083684723129

Epoch: 6| Step: 4
Training loss: 1.018769721559942
Validation loss: 2.4890814338904663

Epoch: 6| Step: 5
Training loss: 0.6179727556602779
Validation loss: 2.4598344921315722

Epoch: 6| Step: 6
Training loss: 0.7878766355090541
Validation loss: 2.477650399406288

Epoch: 6| Step: 7
Training loss: 0.5729812470075284
Validation loss: 2.4611657352740974

Epoch: 6| Step: 8
Training loss: 0.6310012232742905
Validation loss: 2.477797012442827

Epoch: 6| Step: 9
Training loss: 0.8083317281438351
Validation loss: 2.5112918973384804

Epoch: 6| Step: 10
Training loss: 0.5677509787638
Validation loss: 2.5274733242816754

Epoch: 6| Step: 11
Training loss: 0.9760215176375675
Validation loss: 2.5168826149982055

Epoch: 6| Step: 12
Training loss: 0.5906418207588947
Validation loss: 2.5168512431172205

Epoch: 6| Step: 13
Training loss: 0.5376364601260185
Validation loss: 2.537049998825038

Epoch: 245| Step: 0
Training loss: 0.516118131703201
Validation loss: 2.515198865305591

Epoch: 6| Step: 1
Training loss: 1.004428475362248
Validation loss: 2.520038682289067

Epoch: 6| Step: 2
Training loss: 0.7305717599624423
Validation loss: 2.5423651246102064

Epoch: 6| Step: 3
Training loss: 0.7395645372034991
Validation loss: 2.561339240762782

Epoch: 6| Step: 4
Training loss: 0.8337277591604189
Validation loss: 2.571446925666812

Epoch: 6| Step: 5
Training loss: 0.7559596347603849
Validation loss: 2.5318297058218078

Epoch: 6| Step: 6
Training loss: 0.693507562839495
Validation loss: 2.474825840367446

Epoch: 6| Step: 7
Training loss: 0.5845091385318688
Validation loss: 2.472002331847196

Epoch: 6| Step: 8
Training loss: 0.7069946406038556
Validation loss: 2.4993228918313197

Epoch: 6| Step: 9
Training loss: 0.5888901131945106
Validation loss: 2.494992483252126

Epoch: 6| Step: 10
Training loss: 0.9229878319943571
Validation loss: 2.495171436957593

Epoch: 6| Step: 11
Training loss: 0.29288074443164025
Validation loss: 2.558535022714461

Epoch: 6| Step: 12
Training loss: 0.550491473215921
Validation loss: 2.560912467122796

Epoch: 6| Step: 13
Training loss: 0.1916814305140912
Validation loss: 2.567589520432456

Epoch: 246| Step: 0
Training loss: 0.5179978018736136
Validation loss: 2.5645894211808247

Epoch: 6| Step: 1
Training loss: 0.8935223015924928
Validation loss: 2.558450011000054

Epoch: 6| Step: 2
Training loss: 0.7673167009194364
Validation loss: 2.5704880576009708

Epoch: 6| Step: 3
Training loss: 0.9019912097105046
Validation loss: 2.589328264975627

Epoch: 6| Step: 4
Training loss: 0.5702457388903046
Validation loss: 2.5129636917533493

Epoch: 6| Step: 5
Training loss: 0.6312713694968363
Validation loss: 2.527470870665391

Epoch: 6| Step: 6
Training loss: 0.7750200976565352
Validation loss: 2.4988376448169447

Epoch: 6| Step: 7
Training loss: 0.6126889083474104
Validation loss: 2.5289181991088503

Epoch: 6| Step: 8
Training loss: 0.46328740879744756
Validation loss: 2.526058638354672

Epoch: 6| Step: 9
Training loss: 0.7706137077945929
Validation loss: 2.5104791913173172

Epoch: 6| Step: 10
Training loss: 0.6783995428585365
Validation loss: 2.5632464974526417

Epoch: 6| Step: 11
Training loss: 0.7002702191452792
Validation loss: 2.6070008033800827

Epoch: 6| Step: 12
Training loss: 0.5538678359039921
Validation loss: 2.622339863313326

Epoch: 6| Step: 13
Training loss: 0.6143010886856907
Validation loss: 2.5952495668594753

Epoch: 247| Step: 0
Training loss: 0.6728862869758867
Validation loss: 2.5415835361075634

Epoch: 6| Step: 1
Training loss: 0.8664628171212394
Validation loss: 2.5012183563595043

Epoch: 6| Step: 2
Training loss: 0.5943756571624685
Validation loss: 2.4864504902878513

Epoch: 6| Step: 3
Training loss: 0.4865861231337429
Validation loss: 2.4920596092723777

Epoch: 6| Step: 4
Training loss: 0.6837901242075493
Validation loss: 2.4699387010116483

Epoch: 6| Step: 5
Training loss: 0.8159762988879226
Validation loss: 2.518356143072842

Epoch: 6| Step: 6
Training loss: 0.5057397944089618
Validation loss: 2.51135002155791

Epoch: 6| Step: 7
Training loss: 0.9272398584366115
Validation loss: 2.488986075785943

Epoch: 6| Step: 8
Training loss: 0.9070414014407568
Validation loss: 2.541395356134656

Epoch: 6| Step: 9
Training loss: 0.45135996147125845
Validation loss: 2.5465996202880774

Epoch: 6| Step: 10
Training loss: 0.7685105578926474
Validation loss: 2.5213393125020604

Epoch: 6| Step: 11
Training loss: 0.5738645745861167
Validation loss: 2.505430433304804

Epoch: 6| Step: 12
Training loss: 0.5791985879192606
Validation loss: 2.488793611912458

Epoch: 6| Step: 13
Training loss: 0.19573114350663745
Validation loss: 2.481165866691619

Epoch: 248| Step: 0
Training loss: 0.8494733679639971
Validation loss: 2.489226127993193

Epoch: 6| Step: 1
Training loss: 0.537045866939636
Validation loss: 2.4497009065479913

Epoch: 6| Step: 2
Training loss: 0.7646504642074833
Validation loss: 2.480561377427133

Epoch: 6| Step: 3
Training loss: 0.7305661712797042
Validation loss: 2.525045783709025

Epoch: 6| Step: 4
Training loss: 0.7384387458858562
Validation loss: 2.5242467377839324

Epoch: 6| Step: 5
Training loss: 0.6427434459309094
Validation loss: 2.5261371039293667

Epoch: 6| Step: 6
Training loss: 0.528362646187258
Validation loss: 2.5271384216698847

Epoch: 6| Step: 7
Training loss: 0.4148056630612476
Validation loss: 2.5588585626437803

Epoch: 6| Step: 8
Training loss: 0.5291526851408941
Validation loss: 2.581273731242874

Epoch: 6| Step: 9
Training loss: 0.40294420934516834
Validation loss: 2.510918220746023

Epoch: 6| Step: 10
Training loss: 0.9784435009597194
Validation loss: 2.4840284330116518

Epoch: 6| Step: 11
Training loss: 0.562373941919502
Validation loss: 2.464817593088624

Epoch: 6| Step: 12
Training loss: 0.6854775983362374
Validation loss: 2.425990184930081

Epoch: 6| Step: 13
Training loss: 0.9342069966007058
Validation loss: 2.4557724850365914

Epoch: 249| Step: 0
Training loss: 0.4997152471323571
Validation loss: 2.4680151353853508

Epoch: 6| Step: 1
Training loss: 0.4364745008103837
Validation loss: 2.482940110862522

Epoch: 6| Step: 2
Training loss: 0.8327408035077428
Validation loss: 2.486578707652657

Epoch: 6| Step: 3
Training loss: 0.7218479481702206
Validation loss: 2.466865936944963

Epoch: 6| Step: 4
Training loss: 0.8795251998110464
Validation loss: 2.512661984990571

Epoch: 6| Step: 5
Training loss: 0.2375065137572237
Validation loss: 2.53801656100752

Epoch: 6| Step: 6
Training loss: 0.5327649114841
Validation loss: 2.55224428721993

Epoch: 6| Step: 7
Training loss: 0.6004408498293176
Validation loss: 2.5723412494572884

Epoch: 6| Step: 8
Training loss: 0.8129371054182006
Validation loss: 2.544005336938653

Epoch: 6| Step: 9
Training loss: 0.4592188134960794
Validation loss: 2.5579324137653727

Epoch: 6| Step: 10
Training loss: 0.7309118956427287
Validation loss: 2.5189712862428846

Epoch: 6| Step: 11
Training loss: 0.6421725491827638
Validation loss: 2.539870892767904

Epoch: 6| Step: 12
Training loss: 0.7810310056835063
Validation loss: 2.5337420751791115

Epoch: 6| Step: 13
Training loss: 0.960435069163693
Validation loss: 2.584217533173469

Epoch: 250| Step: 0
Training loss: 0.5310217423091579
Validation loss: 2.583982124855011

Epoch: 6| Step: 1
Training loss: 0.5537312552678706
Validation loss: 2.6053427241283735

Epoch: 6| Step: 2
Training loss: 0.44424375479112965
Validation loss: 2.5960436475964985

Epoch: 6| Step: 3
Training loss: 0.521088782291096
Validation loss: 2.564555214612231

Epoch: 6| Step: 4
Training loss: 0.8692707778689894
Validation loss: 2.534644984392096

Epoch: 6| Step: 5
Training loss: 0.6074662269026917
Validation loss: 2.486985474621277

Epoch: 6| Step: 6
Training loss: 0.7022258519563074
Validation loss: 2.493862787809436

Epoch: 6| Step: 7
Training loss: 0.7421483481269725
Validation loss: 2.51336497677638

Epoch: 6| Step: 8
Training loss: 0.7500715221634505
Validation loss: 2.5494843415808375

Epoch: 6| Step: 9
Training loss: 0.8984077448686016
Validation loss: 2.6367959268654624

Epoch: 6| Step: 10
Training loss: 0.8206549156877985
Validation loss: 2.662216963304894

Epoch: 6| Step: 11
Training loss: 0.40465248059490855
Validation loss: 2.668323191400289

Epoch: 6| Step: 12
Training loss: 0.5525036387517905
Validation loss: 2.659056850323305

Epoch: 6| Step: 13
Training loss: 0.9902620330499343
Validation loss: 2.6207210846249214

Epoch: 251| Step: 0
Training loss: 0.3645954765840667
Validation loss: 2.591010829562015

Epoch: 6| Step: 1
Training loss: 0.6141267039195593
Validation loss: 2.5153511666207353

Epoch: 6| Step: 2
Training loss: 0.6075173207941698
Validation loss: 2.4645053286738037

Epoch: 6| Step: 3
Training loss: 0.41718125356505514
Validation loss: 2.447759941562991

Epoch: 6| Step: 4
Training loss: 0.6833648080283834
Validation loss: 2.4355540768335904

Epoch: 6| Step: 5
Training loss: 0.6323478075731013
Validation loss: 2.443476406216193

Epoch: 6| Step: 6
Training loss: 0.7420971865666587
Validation loss: 2.4465625216042373

Epoch: 6| Step: 7
Training loss: 0.7314060338147745
Validation loss: 2.422801386459654

Epoch: 6| Step: 8
Training loss: 0.7529791631411967
Validation loss: 2.4830826178618026

Epoch: 6| Step: 9
Training loss: 0.6424518913411023
Validation loss: 2.4834509526926962

Epoch: 6| Step: 10
Training loss: 0.6921425901702362
Validation loss: 2.5080097212811974

Epoch: 6| Step: 11
Training loss: 0.7347867095696415
Validation loss: 2.495810151039146

Epoch: 6| Step: 12
Training loss: 0.8617564410131349
Validation loss: 2.5243467699656827

Epoch: 6| Step: 13
Training loss: 0.5129872390152623
Validation loss: 2.499564318481307

Epoch: 252| Step: 0
Training loss: 0.8833407619151962
Validation loss: 2.5374683549702968

Epoch: 6| Step: 1
Training loss: 0.817119305246953
Validation loss: 2.5558391322384737

Epoch: 6| Step: 2
Training loss: 0.4273122856091615
Validation loss: 2.5553891885144666

Epoch: 6| Step: 3
Training loss: 0.35032195457066334
Validation loss: 2.5484235876982497

Epoch: 6| Step: 4
Training loss: 0.4285145442257017
Validation loss: 2.5813993054496036

Epoch: 6| Step: 5
Training loss: 0.6353944216935717
Validation loss: 2.5478915585173976

Epoch: 6| Step: 6
Training loss: 0.42527019382815495
Validation loss: 2.4925392960312887

Epoch: 6| Step: 7
Training loss: 0.8122087470134314
Validation loss: 2.465942581997001

Epoch: 6| Step: 8
Training loss: 0.7620252726111008
Validation loss: 2.486280516823307

Epoch: 6| Step: 9
Training loss: 0.6184130945927131
Validation loss: 2.429666212621933

Epoch: 6| Step: 10
Training loss: 0.5162895717186851
Validation loss: 2.4313739439121305

Epoch: 6| Step: 11
Training loss: 0.7435994420612246
Validation loss: 2.5020734008109398

Epoch: 6| Step: 12
Training loss: 0.7165120985735997
Validation loss: 2.5581196327925126

Epoch: 6| Step: 13
Training loss: 0.7245255496335781
Validation loss: 2.5644256215690753

Epoch: 253| Step: 0
Training loss: 0.8135043319230427
Validation loss: 2.6573016638196774

Epoch: 6| Step: 1
Training loss: 0.21360990647364336
Validation loss: 2.6439836072900866

Epoch: 6| Step: 2
Training loss: 0.6257340650354571
Validation loss: 2.6251240557896103

Epoch: 6| Step: 3
Training loss: 0.7016024529310363
Validation loss: 2.566141300132517

Epoch: 6| Step: 4
Training loss: 0.7472146287537772
Validation loss: 2.5638384571179493

Epoch: 6| Step: 5
Training loss: 0.819717300286363
Validation loss: 2.516963494883629

Epoch: 6| Step: 6
Training loss: 0.3081663527991713
Validation loss: 2.5019736036858475

Epoch: 6| Step: 7
Training loss: 0.6445955880160579
Validation loss: 2.44977371860975

Epoch: 6| Step: 8
Training loss: 0.5150825942111898
Validation loss: 2.4719785542994974

Epoch: 6| Step: 9
Training loss: 0.5007628641309233
Validation loss: 2.4916068299515617

Epoch: 6| Step: 10
Training loss: 0.6433716717803114
Validation loss: 2.5079099452020617

Epoch: 6| Step: 11
Training loss: 0.5588515427081345
Validation loss: 2.5343506160856983

Epoch: 6| Step: 12
Training loss: 0.6131400656526125
Validation loss: 2.5632200682531434

Epoch: 6| Step: 13
Training loss: 1.1272628067788253
Validation loss: 2.5935960969361473

Epoch: 254| Step: 0
Training loss: 0.2627146547138299
Validation loss: 2.5378890937794836

Epoch: 6| Step: 1
Training loss: 0.7439779268958945
Validation loss: 2.564959968264583

Epoch: 6| Step: 2
Training loss: 0.9618918789082247
Validation loss: 2.552437756965553

Epoch: 6| Step: 3
Training loss: 0.8980153294382719
Validation loss: 2.5392808303800547

Epoch: 6| Step: 4
Training loss: 0.6271386035586564
Validation loss: 2.505634087399738

Epoch: 6| Step: 5
Training loss: 0.6195613743119455
Validation loss: 2.4738005356692683

Epoch: 6| Step: 6
Training loss: 0.2990342096522519
Validation loss: 2.4713161989490517

Epoch: 6| Step: 7
Training loss: 0.6717376124947378
Validation loss: 2.476462134977618

Epoch: 6| Step: 8
Training loss: 0.19740608615635952
Validation loss: 2.50726498331963

Epoch: 6| Step: 9
Training loss: 0.5765338084207386
Validation loss: 2.5441676545141125

Epoch: 6| Step: 10
Training loss: 0.6486108846843287
Validation loss: 2.5698008544988538

Epoch: 6| Step: 11
Training loss: 0.6692160399651725
Validation loss: 2.5911780602033097

Epoch: 6| Step: 12
Training loss: 0.5968074380873893
Validation loss: 2.604865382483475

Epoch: 6| Step: 13
Training loss: 0.6950520445527206
Validation loss: 2.575843750893093

Epoch: 255| Step: 0
Training loss: 0.6421184112807845
Validation loss: 2.5650360759673685

Epoch: 6| Step: 1
Training loss: 0.63539517215165
Validation loss: 2.5546739165257404

Epoch: 6| Step: 2
Training loss: 0.6554286903625212
Validation loss: 2.5579192233615857

Epoch: 6| Step: 3
Training loss: 0.7085771888892104
Validation loss: 2.5407142737600004

Epoch: 6| Step: 4
Training loss: 0.6060842523423187
Validation loss: 2.5472770417379054

Epoch: 6| Step: 5
Training loss: 0.5677972747239499
Validation loss: 2.5244430945586256

Epoch: 6| Step: 6
Training loss: 0.6152448623005595
Validation loss: 2.548876980819489

Epoch: 6| Step: 7
Training loss: 0.568746742826085
Validation loss: 2.544331941647361

Epoch: 6| Step: 8
Training loss: 0.7985979042251184
Validation loss: 2.5483286665156073

Epoch: 6| Step: 9
Training loss: 0.34481848120743824
Validation loss: 2.5556268614819473

Epoch: 6| Step: 10
Training loss: 0.5316587166156928
Validation loss: 2.587991296749148

Epoch: 6| Step: 11
Training loss: 0.8523550282823943
Validation loss: 2.611957029313599

Epoch: 6| Step: 12
Training loss: 0.6941188896867881
Validation loss: 2.593845748666086

Epoch: 6| Step: 13
Training loss: 0.6319784154133512
Validation loss: 2.60319397576958

Epoch: 256| Step: 0
Training loss: 0.8119290620043693
Validation loss: 2.6116385596628375

Epoch: 6| Step: 1
Training loss: 0.524335176867627
Validation loss: 2.6225962632474324

Epoch: 6| Step: 2
Training loss: 0.6818371027792002
Validation loss: 2.570482288503599

Epoch: 6| Step: 3
Training loss: 0.6209482946355102
Validation loss: 2.551696344852197

Epoch: 6| Step: 4
Training loss: 0.2781505133681537
Validation loss: 2.5282444501915804

Epoch: 6| Step: 5
Training loss: 0.5935259446480562
Validation loss: 2.53675136064086

Epoch: 6| Step: 6
Training loss: 0.5213209603399117
Validation loss: 2.5142501368746957

Epoch: 6| Step: 7
Training loss: 0.5719776405402573
Validation loss: 2.575978185450048

Epoch: 6| Step: 8
Training loss: 0.43370439646970477
Validation loss: 2.593003678736415

Epoch: 6| Step: 9
Training loss: 0.7304853957620445
Validation loss: 2.5645056858031983

Epoch: 6| Step: 10
Training loss: 0.5839140986894261
Validation loss: 2.6117318463987402

Epoch: 6| Step: 11
Training loss: 0.912417374096873
Validation loss: 2.637234626720103

Epoch: 6| Step: 12
Training loss: 0.6358002901261404
Validation loss: 2.590594886551229

Epoch: 6| Step: 13
Training loss: 0.6651665205517657
Validation loss: 2.5501811968700125

Epoch: 257| Step: 0
Training loss: 0.5571495540446969
Validation loss: 2.5170633541121807

Epoch: 6| Step: 1
Training loss: 0.6465807148583393
Validation loss: 2.5052132957691953

Epoch: 6| Step: 2
Training loss: 0.7380162727324524
Validation loss: 2.492661398578909

Epoch: 6| Step: 3
Training loss: 0.2749200683083429
Validation loss: 2.508089327497403

Epoch: 6| Step: 4
Training loss: 0.6882763510626038
Validation loss: 2.4923321804128715

Epoch: 6| Step: 5
Training loss: 0.5926452196393633
Validation loss: 2.4880953300568636

Epoch: 6| Step: 6
Training loss: 0.5021248609007533
Validation loss: 2.472399006441607

Epoch: 6| Step: 7
Training loss: 0.5960435488699037
Validation loss: 2.4862306021170695

Epoch: 6| Step: 8
Training loss: 0.7575135181970764
Validation loss: 2.5093809992209577

Epoch: 6| Step: 9
Training loss: 0.6761971886015912
Validation loss: 2.596720238575196

Epoch: 6| Step: 10
Training loss: 0.5882370140597499
Validation loss: 2.635779573751337

Epoch: 6| Step: 11
Training loss: 0.7344332326973315
Validation loss: 2.5928516762139053

Epoch: 6| Step: 12
Training loss: 0.6273284691722703
Validation loss: 2.6119680181851064

Epoch: 6| Step: 13
Training loss: 0.5690497698294799
Validation loss: 2.554743628907453

Epoch: 258| Step: 0
Training loss: 0.6566604738338807
Validation loss: 2.5147417918390227

Epoch: 6| Step: 1
Training loss: 0.730324185187731
Validation loss: 2.476280107537259

Epoch: 6| Step: 2
Training loss: 0.5197378909235773
Validation loss: 2.439958017197526

Epoch: 6| Step: 3
Training loss: 0.42685658165222184
Validation loss: 2.4435301266647236

Epoch: 6| Step: 4
Training loss: 0.5862292517058909
Validation loss: 2.4532242621571565

Epoch: 6| Step: 5
Training loss: 0.5258940939804289
Validation loss: 2.534226735739119

Epoch: 6| Step: 6
Training loss: 0.462843445896592
Validation loss: 2.5874932966184603

Epoch: 6| Step: 7
Training loss: 0.5814793421404365
Validation loss: 2.5812011022668044

Epoch: 6| Step: 8
Training loss: 0.539467756002514
Validation loss: 2.636790799182383

Epoch: 6| Step: 9
Training loss: 0.8270882648798231
Validation loss: 2.602962599141668

Epoch: 6| Step: 10
Training loss: 0.6580722576863157
Validation loss: 2.586129921225056

Epoch: 6| Step: 11
Training loss: 0.680809388593706
Validation loss: 2.565944975617007

Epoch: 6| Step: 12
Training loss: 0.872830596692516
Validation loss: 2.5437181704046727

Epoch: 6| Step: 13
Training loss: 0.41820704717166907
Validation loss: 2.493981160475053

Epoch: 259| Step: 0
Training loss: 0.47171622188126944
Validation loss: 2.5053070446644092

Epoch: 6| Step: 1
Training loss: 0.5607881458758746
Validation loss: 2.515600926503084

Epoch: 6| Step: 2
Training loss: 0.6686565360596244
Validation loss: 2.5288996092569596

Epoch: 6| Step: 3
Training loss: 0.7159359202373764
Validation loss: 2.55007375151669

Epoch: 6| Step: 4
Training loss: 0.43421602701964784
Validation loss: 2.58010482466867

Epoch: 6| Step: 5
Training loss: 0.5569745584666721
Validation loss: 2.588601967578887

Epoch: 6| Step: 6
Training loss: 0.8435392469762566
Validation loss: 2.6342110276191897

Epoch: 6| Step: 7
Training loss: 0.6755280213180701
Validation loss: 2.6148233009828354

Epoch: 6| Step: 8
Training loss: 0.7734173858801451
Validation loss: 2.6099299685060795

Epoch: 6| Step: 9
Training loss: 0.7088528766008383
Validation loss: 2.6341503735511935

Epoch: 6| Step: 10
Training loss: 0.2790755882483207
Validation loss: 2.5539406108009337

Epoch: 6| Step: 11
Training loss: 0.1950803903395475
Validation loss: 2.4694417677707023

Epoch: 6| Step: 12
Training loss: 0.7013537455295522
Validation loss: 2.4323296223931195

Epoch: 6| Step: 13
Training loss: 0.7327281260770496
Validation loss: 2.436280913566518

Epoch: 260| Step: 0
Training loss: 0.33004488580139774
Validation loss: 2.3983285316745824

Epoch: 6| Step: 1
Training loss: 0.7793832601982886
Validation loss: 2.4597046143716046

Epoch: 6| Step: 2
Training loss: 0.7947681475184675
Validation loss: 2.448041989049346

Epoch: 6| Step: 3
Training loss: 0.6719345465598647
Validation loss: 2.556898589392005

Epoch: 6| Step: 4
Training loss: 0.5273454171613549
Validation loss: 2.5887031147465747

Epoch: 6| Step: 5
Training loss: 0.6014861516682252
Validation loss: 2.6277763443384115

Epoch: 6| Step: 6
Training loss: 0.6369162411200665
Validation loss: 2.6370943702031258

Epoch: 6| Step: 7
Training loss: 0.7243840774744126
Validation loss: 2.5933527567528047

Epoch: 6| Step: 8
Training loss: 0.6060098506705994
Validation loss: 2.5761733876058397

Epoch: 6| Step: 9
Training loss: 0.61013550863534
Validation loss: 2.515811784571931

Epoch: 6| Step: 10
Training loss: 0.48710573221051373
Validation loss: 2.4841812139731196

Epoch: 6| Step: 11
Training loss: 0.5866510750945633
Validation loss: 2.478950121005087

Epoch: 6| Step: 12
Training loss: 0.6036492604072544
Validation loss: 2.490030124434474

Epoch: 6| Step: 13
Training loss: 0.4664657088419727
Validation loss: 2.463101772306001

Epoch: 261| Step: 0
Training loss: 0.436862412845756
Validation loss: 2.501214535317825

Epoch: 6| Step: 1
Training loss: 0.3458500566039371
Validation loss: 2.4930799868120843

Epoch: 6| Step: 2
Training loss: 0.4656922106271022
Validation loss: 2.5531328843682677

Epoch: 6| Step: 3
Training loss: 0.7738498012659052
Validation loss: 2.5503882764505987

Epoch: 6| Step: 4
Training loss: 0.7635632215703956
Validation loss: 2.5819822172738283

Epoch: 6| Step: 5
Training loss: 0.7250889427611973
Validation loss: 2.579335790208156

Epoch: 6| Step: 6
Training loss: 0.558635096586997
Validation loss: 2.558116089158568

Epoch: 6| Step: 7
Training loss: 0.40635529400707343
Validation loss: 2.5437507483662745

Epoch: 6| Step: 8
Training loss: 0.6181189835489919
Validation loss: 2.5261807926803983

Epoch: 6| Step: 9
Training loss: 0.3922692977286605
Validation loss: 2.521790083818899

Epoch: 6| Step: 10
Training loss: 0.6646562502410529
Validation loss: 2.4935983701844973

Epoch: 6| Step: 11
Training loss: 0.865902679194799
Validation loss: 2.5025046691821466

Epoch: 6| Step: 12
Training loss: 0.6658632881705713
Validation loss: 2.5165582086534597

Epoch: 6| Step: 13
Training loss: 0.23282220167389003
Validation loss: 2.5078032546482656

Epoch: 262| Step: 0
Training loss: 0.6131408919550637
Validation loss: 2.5052424418654407

Epoch: 6| Step: 1
Training loss: 0.25599416429230987
Validation loss: 2.5312689452966977

Epoch: 6| Step: 2
Training loss: 0.5149576897508974
Validation loss: 2.5443795336566017

Epoch: 6| Step: 3
Training loss: 0.733719391062528
Validation loss: 2.577275230294316

Epoch: 6| Step: 4
Training loss: 0.8066480511561349
Validation loss: 2.575454106020109

Epoch: 6| Step: 5
Training loss: 0.5164716878223355
Validation loss: 2.5678524050215716

Epoch: 6| Step: 6
Training loss: 0.41267035030149624
Validation loss: 2.5605885940063757

Epoch: 6| Step: 7
Training loss: 0.34038526865711216
Validation loss: 2.5539102186261764

Epoch: 6| Step: 8
Training loss: 0.6356759923175188
Validation loss: 2.5823393294401114

Epoch: 6| Step: 9
Training loss: 0.7849079707438519
Validation loss: 2.5012105144031227

Epoch: 6| Step: 10
Training loss: 0.8211340287307842
Validation loss: 2.5396721220861846

Epoch: 6| Step: 11
Training loss: 0.6761697523413209
Validation loss: 2.562515004632071

Epoch: 6| Step: 12
Training loss: 0.6246512870730734
Validation loss: 2.5390521568169704

Epoch: 6| Step: 13
Training loss: 0.24919557792538694
Validation loss: 2.5347292070961673

Epoch: 263| Step: 0
Training loss: 0.5110346173954796
Validation loss: 2.578243698614404

Epoch: 6| Step: 1
Training loss: 0.594613150570974
Validation loss: 2.6166141729952797

Epoch: 6| Step: 2
Training loss: 0.6469411935893393
Validation loss: 2.5612614567556062

Epoch: 6| Step: 3
Training loss: 0.612648801828849
Validation loss: 2.561067562480281

Epoch: 6| Step: 4
Training loss: 0.3258200020920679
Validation loss: 2.5449093056927308

Epoch: 6| Step: 5
Training loss: 0.19869416488731817
Validation loss: 2.5649992737353973

Epoch: 6| Step: 6
Training loss: 0.34675547886173097
Validation loss: 2.5395334912218654

Epoch: 6| Step: 7
Training loss: 0.41602343341501946
Validation loss: 2.545434754554666

Epoch: 6| Step: 8
Training loss: 0.7584835109892409
Validation loss: 2.5468885203846345

Epoch: 6| Step: 9
Training loss: 0.4976464550545528
Validation loss: 2.5139446594177337

Epoch: 6| Step: 10
Training loss: 0.6888229256392939
Validation loss: 2.570007177918015

Epoch: 6| Step: 11
Training loss: 0.7826341574352016
Validation loss: 2.5673742479874155

Epoch: 6| Step: 12
Training loss: 0.8497014138365201
Validation loss: 2.5095353831185814

Epoch: 6| Step: 13
Training loss: 0.738496133524304
Validation loss: 2.54185310576325

Epoch: 264| Step: 0
Training loss: 0.5013822879456542
Validation loss: 2.505490472864153

Epoch: 6| Step: 1
Training loss: 0.4386127999425346
Validation loss: 2.469689261788388

Epoch: 6| Step: 2
Training loss: 0.6767324467648899
Validation loss: 2.499504939663656

Epoch: 6| Step: 3
Training loss: 0.38988590891657343
Validation loss: 2.493072573767611

Epoch: 6| Step: 4
Training loss: 0.6998386299233877
Validation loss: 2.4892121574332595

Epoch: 6| Step: 5
Training loss: 0.22374258720383292
Validation loss: 2.537253507584489

Epoch: 6| Step: 6
Training loss: 0.3811814926694853
Validation loss: 2.5668643918272354

Epoch: 6| Step: 7
Training loss: 0.657676440776648
Validation loss: 2.5763306589366635

Epoch: 6| Step: 8
Training loss: 0.5781768569370829
Validation loss: 2.5766547899970496

Epoch: 6| Step: 9
Training loss: 0.5153583357247397
Validation loss: 2.5694999738341395

Epoch: 6| Step: 10
Training loss: 0.748270822971331
Validation loss: 2.5600316514633707

Epoch: 6| Step: 11
Training loss: 0.755630497940041
Validation loss: 2.5383995928693737

Epoch: 6| Step: 12
Training loss: 0.5253059290577644
Validation loss: 2.4940196423183587

Epoch: 6| Step: 13
Training loss: 0.7605209714517301
Validation loss: 2.524080499918525

Epoch: 265| Step: 0
Training loss: 0.7263268529571657
Validation loss: 2.489985522890216

Epoch: 6| Step: 1
Training loss: 0.5687135726665383
Validation loss: 2.52193568253329

Epoch: 6| Step: 2
Training loss: 0.4407292465910737
Validation loss: 2.5184889627773073

Epoch: 6| Step: 3
Training loss: 0.6205366022901464
Validation loss: 2.5196933641718138

Epoch: 6| Step: 4
Training loss: 0.6208825622045834
Validation loss: 2.537749021943764

Epoch: 6| Step: 5
Training loss: 0.5576342364642737
Validation loss: 2.5616154103064925

Epoch: 6| Step: 6
Training loss: 0.45938148364208026
Validation loss: 2.595926631939695

Epoch: 6| Step: 7
Training loss: 0.6260179336373889
Validation loss: 2.5949051942423615

Epoch: 6| Step: 8
Training loss: 0.4443495025240939
Validation loss: 2.598570862334573

Epoch: 6| Step: 9
Training loss: 0.3568778353242763
Validation loss: 2.583108389710497

Epoch: 6| Step: 10
Training loss: 0.8310197941663943
Validation loss: 2.5269968048575384

Epoch: 6| Step: 11
Training loss: 0.5592308412765151
Validation loss: 2.4824498955671275

Epoch: 6| Step: 12
Training loss: 0.5419062915817605
Validation loss: 2.4517095738469923

Epoch: 6| Step: 13
Training loss: 0.31667437789755304
Validation loss: 2.40771667779996

Epoch: 266| Step: 0
Training loss: 0.8262049170124988
Validation loss: 2.4686271997276426

Epoch: 6| Step: 1
Training loss: 0.26167252829894905
Validation loss: 2.480062102947094

Epoch: 6| Step: 2
Training loss: 0.5493541111191705
Validation loss: 2.52725316283603

Epoch: 6| Step: 3
Training loss: 0.5982720437665334
Validation loss: 2.537031426117612

Epoch: 6| Step: 4
Training loss: 0.512402783454196
Validation loss: 2.5567380321192275

Epoch: 6| Step: 5
Training loss: 0.41101799310735426
Validation loss: 2.566904198461684

Epoch: 6| Step: 6
Training loss: 0.7447379210671627
Validation loss: 2.537384815754948

Epoch: 6| Step: 7
Training loss: 0.5871334840008472
Validation loss: 2.5763341596059575

Epoch: 6| Step: 8
Training loss: 0.24290305994447617
Validation loss: 2.5442657865301537

Epoch: 6| Step: 9
Training loss: 0.5724050723005074
Validation loss: 2.5076872892406055

Epoch: 6| Step: 10
Training loss: 0.4538151319643125
Validation loss: 2.4937514561371756

Epoch: 6| Step: 11
Training loss: 0.6873222901674771
Validation loss: 2.479669074502553

Epoch: 6| Step: 12
Training loss: 0.5911746389173946
Validation loss: 2.5036141594733494

Epoch: 6| Step: 13
Training loss: 0.5098333788748391
Validation loss: 2.5338151837684904

Epoch: 267| Step: 0
Training loss: 0.2449896507242546
Validation loss: 2.5411475529146483

Epoch: 6| Step: 1
Training loss: 0.5309404986264857
Validation loss: 2.583418100126089

Epoch: 6| Step: 2
Training loss: 0.5332409073295425
Validation loss: 2.5623728462724045

Epoch: 6| Step: 3
Training loss: 0.8774732648683815
Validation loss: 2.5525682267869536

Epoch: 6| Step: 4
Training loss: 0.5865721507998384
Validation loss: 2.5225969008709375

Epoch: 6| Step: 5
Training loss: 0.3320518711642801
Validation loss: 2.5232785554974395

Epoch: 6| Step: 6
Training loss: 0.570002772215744
Validation loss: 2.518724775135856

Epoch: 6| Step: 7
Training loss: 0.6406650530691927
Validation loss: 2.520838345351729

Epoch: 6| Step: 8
Training loss: 0.5712996522622942
Validation loss: 2.4981952161920793

Epoch: 6| Step: 9
Training loss: 0.6957459116934522
Validation loss: 2.5397640065041474

Epoch: 6| Step: 10
Training loss: 0.4281039448593545
Validation loss: 2.534668849200147

Epoch: 6| Step: 11
Training loss: 0.6397296417175266
Validation loss: 2.5368045562925454

Epoch: 6| Step: 12
Training loss: 0.2122758598373344
Validation loss: 2.565529391981788

Epoch: 6| Step: 13
Training loss: 0.5948710900194436
Validation loss: 2.5407961345250274

Epoch: 268| Step: 0
Training loss: 0.481226254162226
Validation loss: 2.521583356735319

Epoch: 6| Step: 1
Training loss: 0.6475691668930572
Validation loss: 2.531412616946412

Epoch: 6| Step: 2
Training loss: 0.5858639225857677
Validation loss: 2.511249948411332

Epoch: 6| Step: 3
Training loss: 0.6325904786377212
Validation loss: 2.512793061122122

Epoch: 6| Step: 4
Training loss: 0.4176514570972312
Validation loss: 2.533799272608326

Epoch: 6| Step: 5
Training loss: 0.16468671283678574
Validation loss: 2.545059255420301

Epoch: 6| Step: 6
Training loss: 0.3593457666200016
Validation loss: 2.560682545134656

Epoch: 6| Step: 7
Training loss: 0.7858465016887594
Validation loss: 2.5402216630674412

Epoch: 6| Step: 8
Training loss: 0.5523407144206802
Validation loss: 2.5548130253054606

Epoch: 6| Step: 9
Training loss: 0.6029885221641533
Validation loss: 2.553651746553572

Epoch: 6| Step: 10
Training loss: 0.5051966859189304
Validation loss: 2.5409102982919043

Epoch: 6| Step: 11
Training loss: 0.7498029608978639
Validation loss: 2.5519888821255954

Epoch: 6| Step: 12
Training loss: 0.4610534942283143
Validation loss: 2.548005636790217

Epoch: 6| Step: 13
Training loss: 0.42111464255739983
Validation loss: 2.5514957966312

Epoch: 269| Step: 0
Training loss: 0.45739623925539913
Validation loss: 2.549168987817453

Epoch: 6| Step: 1
Training loss: 0.5240991310961107
Validation loss: 2.574671933017297

Epoch: 6| Step: 2
Training loss: 0.8362481796632578
Validation loss: 2.6321856246373376

Epoch: 6| Step: 3
Training loss: 0.6132384364254375
Validation loss: 2.553018275050181

Epoch: 6| Step: 4
Training loss: 0.37254867440513784
Validation loss: 2.5270188513885583

Epoch: 6| Step: 5
Training loss: 0.6589125706616238
Validation loss: 2.5326632047972555

Epoch: 6| Step: 6
Training loss: 0.5461806657902447
Validation loss: 2.5178970454022553

Epoch: 6| Step: 7
Training loss: 0.17368577100182156
Validation loss: 2.534568985694386

Epoch: 6| Step: 8
Training loss: 0.5844836955035825
Validation loss: 2.5370914317414184

Epoch: 6| Step: 9
Training loss: 0.7450703897441657
Validation loss: 2.48143728511376

Epoch: 6| Step: 10
Training loss: 0.4228145239556725
Validation loss: 2.486087244371103

Epoch: 6| Step: 11
Training loss: 0.3295810726552819
Validation loss: 2.553084952458723

Epoch: 6| Step: 12
Training loss: 0.4888164333892
Validation loss: 2.5537587341843793

Epoch: 6| Step: 13
Training loss: 0.6924774148336005
Validation loss: 2.6004711826934597

Epoch: 270| Step: 0
Training loss: 0.6807228621230061
Validation loss: 2.5968420123904803

Epoch: 6| Step: 1
Training loss: 0.4415891319121432
Validation loss: 2.5433516085872374

Epoch: 6| Step: 2
Training loss: 0.4315015819184622
Validation loss: 2.5499429469569543

Epoch: 6| Step: 3
Training loss: 0.6812752780249236
Validation loss: 2.5203799164806955

Epoch: 6| Step: 4
Training loss: 0.4459675104192037
Validation loss: 2.5184705931801745

Epoch: 6| Step: 5
Training loss: 0.35665855822229453
Validation loss: 2.518041854166308

Epoch: 6| Step: 6
Training loss: 0.45488830012757697
Validation loss: 2.518374772070269

Epoch: 6| Step: 7
Training loss: 0.2842388288169844
Validation loss: 2.5345666851046977

Epoch: 6| Step: 8
Training loss: 0.7413908045358764
Validation loss: 2.5281576644722272

Epoch: 6| Step: 9
Training loss: 0.8597366959013073
Validation loss: 2.5151881926154833

Epoch: 6| Step: 10
Training loss: 0.38071544568568355
Validation loss: 2.5597253755058658

Epoch: 6| Step: 11
Training loss: 0.48153602101518944
Validation loss: 2.521334347573506

Epoch: 6| Step: 12
Training loss: 0.48163870125020536
Validation loss: 2.546160471568754

Epoch: 6| Step: 13
Training loss: 0.6075965654680421
Validation loss: 2.4911622535871203

Epoch: 271| Step: 0
Training loss: 0.18299615267125385
Validation loss: 2.5417219270629374

Epoch: 6| Step: 1
Training loss: 0.6846892380093863
Validation loss: 2.5814467255260385

Epoch: 6| Step: 2
Training loss: 0.5582801632212651
Validation loss: 2.5323045874061285

Epoch: 6| Step: 3
Training loss: 0.739126619618172
Validation loss: 2.5578735961268446

Epoch: 6| Step: 4
Training loss: 0.6166011101011466
Validation loss: 2.5739980810288783

Epoch: 6| Step: 5
Training loss: 0.5566555088128008
Validation loss: 2.552626640410927

Epoch: 6| Step: 6
Training loss: 0.530963624173435
Validation loss: 2.5593302651354604

Epoch: 6| Step: 7
Training loss: 0.7445578619412967
Validation loss: 2.5498341061031717

Epoch: 6| Step: 8
Training loss: 0.3335314350754925
Validation loss: 2.4912446126930092

Epoch: 6| Step: 9
Training loss: 0.3374368564382663
Validation loss: 2.5351837524295533

Epoch: 6| Step: 10
Training loss: 0.42605569726214526
Validation loss: 2.5430278034970155

Epoch: 6| Step: 11
Training loss: 0.30755762401545905
Validation loss: 2.546181489795209

Epoch: 6| Step: 12
Training loss: 0.5264001952740559
Validation loss: 2.510526879774962

Epoch: 6| Step: 13
Training loss: 0.6849331186876536
Validation loss: 2.5104950378736093

Epoch: 272| Step: 0
Training loss: 0.5065580278654561
Validation loss: 2.5266568587413647

Epoch: 6| Step: 1
Training loss: 0.5547531518902489
Validation loss: 2.548698077296258

Epoch: 6| Step: 2
Training loss: 0.566873397236065
Validation loss: 2.579231911073771

Epoch: 6| Step: 3
Training loss: 0.3769487370843423
Validation loss: 2.577939514269364

Epoch: 6| Step: 4
Training loss: 0.35836172305615044
Validation loss: 2.5842996973711156

Epoch: 6| Step: 5
Training loss: 0.405343842423243
Validation loss: 2.614978235067472

Epoch: 6| Step: 6
Training loss: 0.7640163103429748
Validation loss: 2.5833863528471057

Epoch: 6| Step: 7
Training loss: 0.3724614287894759
Validation loss: 2.5723161624760147

Epoch: 6| Step: 8
Training loss: 0.5991590965050975
Validation loss: 2.5185024513061802

Epoch: 6| Step: 9
Training loss: 0.4521559844406775
Validation loss: 2.485085136473928

Epoch: 6| Step: 10
Training loss: 0.694539830226699
Validation loss: 2.4584333501304387

Epoch: 6| Step: 11
Training loss: 0.6416427854536195
Validation loss: 2.4679019697335924

Epoch: 6| Step: 12
Training loss: 0.48566472717058035
Validation loss: 2.492637007139776

Epoch: 6| Step: 13
Training loss: 0.542718623888075
Validation loss: 2.543947950767289

Epoch: 273| Step: 0
Training loss: 0.4393839294209946
Validation loss: 2.534218734423636

Epoch: 6| Step: 1
Training loss: 0.5676105718402371
Validation loss: 2.6072242218536053

Epoch: 6| Step: 2
Training loss: 0.4611955502271835
Validation loss: 2.634556800080057

Epoch: 6| Step: 3
Training loss: 0.6519886809402121
Validation loss: 2.642721855345664

Epoch: 6| Step: 4
Training loss: 0.5434083051336082
Validation loss: 2.6200645060223913

Epoch: 6| Step: 5
Training loss: 0.326102723426349
Validation loss: 2.639327617228487

Epoch: 6| Step: 6
Training loss: 0.4007743671264944
Validation loss: 2.5610342928723866

Epoch: 6| Step: 7
Training loss: 0.6919079054439687
Validation loss: 2.533548743146755

Epoch: 6| Step: 8
Training loss: 0.5937487953575362
Validation loss: 2.4934045103310947

Epoch: 6| Step: 9
Training loss: 0.7341356090192838
Validation loss: 2.455477031459813

Epoch: 6| Step: 10
Training loss: 0.4085667282126128
Validation loss: 2.4783306006380728

Epoch: 6| Step: 11
Training loss: 0.5929984305169627
Validation loss: 2.476922360994541

Epoch: 6| Step: 12
Training loss: 0.5663228993089882
Validation loss: 2.547327536546532

Epoch: 6| Step: 13
Training loss: 0.3123641314781485
Validation loss: 2.558160035484532

Epoch: 274| Step: 0
Training loss: 0.3803105042843265
Validation loss: 2.627093008574157

Epoch: 6| Step: 1
Training loss: 0.4725900714037174
Validation loss: 2.653095758860769

Epoch: 6| Step: 2
Training loss: 0.6345038475764668
Validation loss: 2.673842680356866

Epoch: 6| Step: 3
Training loss: 0.35428039276915724
Validation loss: 2.640178732270679

Epoch: 6| Step: 4
Training loss: 0.20520530571777665
Validation loss: 2.587566738249849

Epoch: 6| Step: 5
Training loss: 0.4642493029349357
Validation loss: 2.555375936827753

Epoch: 6| Step: 6
Training loss: 0.6253481610456028
Validation loss: 2.5051976480990157

Epoch: 6| Step: 7
Training loss: 0.4159783360062577
Validation loss: 2.529850520112945

Epoch: 6| Step: 8
Training loss: 0.7286299955779563
Validation loss: 2.477214426323981

Epoch: 6| Step: 9
Training loss: 0.5739354063833128
Validation loss: 2.500793033868393

Epoch: 6| Step: 10
Training loss: 0.15246445202423453
Validation loss: 2.552643462627882

Epoch: 6| Step: 11
Training loss: 0.7197237053533647
Validation loss: 2.556302901602473

Epoch: 6| Step: 12
Training loss: 0.6620102754772146
Validation loss: 2.613311667829142

Epoch: 6| Step: 13
Training loss: 0.7715015264608496
Validation loss: 2.603442461199257

Epoch: 275| Step: 0
Training loss: 0.546131746119042
Validation loss: 2.667981540456673

Epoch: 6| Step: 1
Training loss: 0.5312524963769041
Validation loss: 2.639169577210781

Epoch: 6| Step: 2
Training loss: 0.5788262727707534
Validation loss: 2.6536004694176274

Epoch: 6| Step: 3
Training loss: 0.48528429021846564
Validation loss: 2.6043199109344477

Epoch: 6| Step: 4
Training loss: 0.7855129285825322
Validation loss: 2.5488697793370245

Epoch: 6| Step: 5
Training loss: 0.5528067281970519
Validation loss: 2.5296739335282763

Epoch: 6| Step: 6
Training loss: 0.5178233879109567
Validation loss: 2.4532786720204585

Epoch: 6| Step: 7
Training loss: 0.646010971763018
Validation loss: 2.4476859489077647

Epoch: 6| Step: 8
Training loss: 0.45170540247923663
Validation loss: 2.4429487451220355

Epoch: 6| Step: 9
Training loss: 0.44093174031021964
Validation loss: 2.463026117206884

Epoch: 6| Step: 10
Training loss: 0.5494727696291966
Validation loss: 2.4994091448335927

Epoch: 6| Step: 11
Training loss: 0.4796917843704994
Validation loss: 2.547580256209826

Epoch: 6| Step: 12
Training loss: 0.2971489671141036
Validation loss: 2.5880160792337006

Epoch: 6| Step: 13
Training loss: 0.6380388815266892
Validation loss: 2.548333805202518

Epoch: 276| Step: 0
Training loss: 0.6890225024735749
Validation loss: 2.516717493035277

Epoch: 6| Step: 1
Training loss: 0.5699805770040995
Validation loss: 2.5254442477509356

Epoch: 6| Step: 2
Training loss: 0.3115580428941996
Validation loss: 2.4961614169992297

Epoch: 6| Step: 3
Training loss: 0.31993607756188003
Validation loss: 2.467213214791512

Epoch: 6| Step: 4
Training loss: 0.4737954086745482
Validation loss: 2.452712348867688

Epoch: 6| Step: 5
Training loss: 0.36511561048841945
Validation loss: 2.457291980248474

Epoch: 6| Step: 6
Training loss: 0.37567578459581785
Validation loss: 2.4558709981992823

Epoch: 6| Step: 7
Training loss: 0.47258576742467057
Validation loss: 2.4783777750216847

Epoch: 6| Step: 8
Training loss: 0.720722146545645
Validation loss: 2.5063873014457068

Epoch: 6| Step: 9
Training loss: 0.44463323351829875
Validation loss: 2.508998243087089

Epoch: 6| Step: 10
Training loss: 0.6809414663632591
Validation loss: 2.5085921334486514

Epoch: 6| Step: 11
Training loss: 0.4601400880938383
Validation loss: 2.541446040432544

Epoch: 6| Step: 12
Training loss: 0.6883335911986612
Validation loss: 2.5530197923365585

Epoch: 6| Step: 13
Training loss: 0.40451101262057343
Validation loss: 2.558218689204606

Epoch: 277| Step: 0
Training loss: 0.6923680055054591
Validation loss: 2.5559347664825673

Epoch: 6| Step: 1
Training loss: 0.49700201798226984
Validation loss: 2.5166115823297055

Epoch: 6| Step: 2
Training loss: 0.26476707473857747
Validation loss: 2.5700298380437356

Epoch: 6| Step: 3
Training loss: 0.514286645181699
Validation loss: 2.54604334325455

Epoch: 6| Step: 4
Training loss: 0.6361407599510503
Validation loss: 2.547960543380277

Epoch: 6| Step: 5
Training loss: 0.3250891022317407
Validation loss: 2.533046851082981

Epoch: 6| Step: 6
Training loss: 0.7366612740645808
Validation loss: 2.590554194071128

Epoch: 6| Step: 7
Training loss: 0.14317089470437502
Validation loss: 2.60136392960119

Epoch: 6| Step: 8
Training loss: 0.3712486546103506
Validation loss: 2.6226488865380624

Epoch: 6| Step: 9
Training loss: 0.36347336970120503
Validation loss: 2.6315976500993457

Epoch: 6| Step: 10
Training loss: 0.8300371586283514
Validation loss: 2.641327193446827

Epoch: 6| Step: 11
Training loss: 0.5992692112968406
Validation loss: 2.6530722346032074

Epoch: 6| Step: 12
Training loss: 0.34199659779317576
Validation loss: 2.6238973658336313

Epoch: 6| Step: 13
Training loss: 0.09823659592750167
Validation loss: 2.5833394248670936

Epoch: 278| Step: 0
Training loss: 0.431834561377256
Validation loss: 2.5347464297667903

Epoch: 6| Step: 1
Training loss: 0.3613230112074784
Validation loss: 2.488111105890232

Epoch: 6| Step: 2
Training loss: 0.5248963537539763
Validation loss: 2.4751061677043444

Epoch: 6| Step: 3
Training loss: 0.22467307141258253
Validation loss: 2.465227289032829

Epoch: 6| Step: 4
Training loss: 0.2038839722664071
Validation loss: 2.4743812162478083

Epoch: 6| Step: 5
Training loss: 0.5512980748533738
Validation loss: 2.5460064467245944

Epoch: 6| Step: 6
Training loss: 0.6991742721988127
Validation loss: 2.539781815810387

Epoch: 6| Step: 7
Training loss: 0.766545229257323
Validation loss: 2.5743487263954603

Epoch: 6| Step: 8
Training loss: 0.5641518815252385
Validation loss: 2.5486876967708163

Epoch: 6| Step: 9
Training loss: 0.2895553742891996
Validation loss: 2.5786436869885

Epoch: 6| Step: 10
Training loss: 0.5695042042531001
Validation loss: 2.585151658292262

Epoch: 6| Step: 11
Training loss: 0.6927838368007689
Validation loss: 2.5514911003791534

Epoch: 6| Step: 12
Training loss: 0.439932345721463
Validation loss: 2.5585588119815466

Epoch: 6| Step: 13
Training loss: 0.4409567814807799
Validation loss: 2.470849564568217

Epoch: 279| Step: 0
Training loss: 0.6317178654198653
Validation loss: 2.50141012354071

Epoch: 6| Step: 1
Training loss: 0.31828468710420404
Validation loss: 2.5448589306306504

Epoch: 6| Step: 2
Training loss: 0.6945381353013405
Validation loss: 2.5742436152800954

Epoch: 6| Step: 3
Training loss: 0.5952552988200235
Validation loss: 2.5169360276301767

Epoch: 6| Step: 4
Training loss: 0.5072814218425301
Validation loss: 2.6031133336941275

Epoch: 6| Step: 5
Training loss: 0.3157993901859288
Validation loss: 2.5295528534302525

Epoch: 6| Step: 6
Training loss: 0.5943314816962577
Validation loss: 2.5169725405657046

Epoch: 6| Step: 7
Training loss: 0.6591975456927035
Validation loss: 2.477900991580312

Epoch: 6| Step: 8
Training loss: 0.38924059640775005
Validation loss: 2.439711130271353

Epoch: 6| Step: 9
Training loss: 0.6789140575736978
Validation loss: 2.4159445014243164

Epoch: 6| Step: 10
Training loss: 0.3742531252942669
Validation loss: 2.4037957526287896

Epoch: 6| Step: 11
Training loss: 0.6040052631335179
Validation loss: 2.408033854264328

Epoch: 6| Step: 12
Training loss: 0.35561677973520295
Validation loss: 2.4626964985618227

Epoch: 6| Step: 13
Training loss: 0.2682875396888802
Validation loss: 2.4838368121895016

Epoch: 280| Step: 0
Training loss: 0.5694688278756692
Validation loss: 2.5546411075615088

Epoch: 6| Step: 1
Training loss: 0.5188540296918801
Validation loss: 2.5924137872800954

Epoch: 6| Step: 2
Training loss: 0.3630925991027962
Validation loss: 2.5845771663754915

Epoch: 6| Step: 3
Training loss: 0.49071760032668293
Validation loss: 2.562312121523192

Epoch: 6| Step: 4
Training loss: 0.5082777386370207
Validation loss: 2.537570986686059

Epoch: 6| Step: 5
Training loss: 0.6465277988567228
Validation loss: 2.4997163021976774

Epoch: 6| Step: 6
Training loss: 0.44292759981713875
Validation loss: 2.5020920941741474

Epoch: 6| Step: 7
Training loss: 0.5184123100613198
Validation loss: 2.5051625650757727

Epoch: 6| Step: 8
Training loss: 0.7138299475687613
Validation loss: 2.5466749282686907

Epoch: 6| Step: 9
Training loss: 0.6482456337060494
Validation loss: 2.534193477940444

Epoch: 6| Step: 10
Training loss: 0.6011475704998466
Validation loss: 2.586775894106935

Epoch: 6| Step: 11
Training loss: 0.47764756231920846
Validation loss: 2.5857001394183423

Epoch: 6| Step: 12
Training loss: 0.34621465951923885
Validation loss: 2.6011377596555367

Epoch: 6| Step: 13
Training loss: 0.4783827616687653
Validation loss: 2.61908230000821

Epoch: 281| Step: 0
Training loss: 0.4840819641445684
Validation loss: 2.5546833113684024

Epoch: 6| Step: 1
Training loss: 0.27125282842066795
Validation loss: 2.5743975330698836

Epoch: 6| Step: 2
Training loss: 0.32994136572970645
Validation loss: 2.5339561711419054

Epoch: 6| Step: 3
Training loss: 0.714448037606507
Validation loss: 2.5435928756571573

Epoch: 6| Step: 4
Training loss: 0.4178483379575169
Validation loss: 2.540581393986776

Epoch: 6| Step: 5
Training loss: 0.42417320583051965
Validation loss: 2.5045290018584323

Epoch: 6| Step: 6
Training loss: 0.6882941687559017
Validation loss: 2.5115389889642965

Epoch: 6| Step: 7
Training loss: 0.3271679772761933
Validation loss: 2.49159008643339

Epoch: 6| Step: 8
Training loss: 0.5639534821129623
Validation loss: 2.46698383267199

Epoch: 6| Step: 9
Training loss: 0.5508862118100495
Validation loss: 2.5140936410869976

Epoch: 6| Step: 10
Training loss: 0.30500573875937986
Validation loss: 2.511458737227812

Epoch: 6| Step: 11
Training loss: 0.7942415742748421
Validation loss: 2.4986003587856502

Epoch: 6| Step: 12
Training loss: 0.46225920801187875
Validation loss: 2.5325350743470274

Epoch: 6| Step: 13
Training loss: 0.4494325543660539
Validation loss: 2.5241021801292316

Epoch: 282| Step: 0
Training loss: 0.6852134915562978
Validation loss: 2.54582525095291

Epoch: 6| Step: 1
Training loss: 0.5042674226677699
Validation loss: 2.5062892753725947

Epoch: 6| Step: 2
Training loss: 0.5541077660208976
Validation loss: 2.5050576016528847

Epoch: 6| Step: 3
Training loss: 0.2806783535795809
Validation loss: 2.4794362120618723

Epoch: 6| Step: 4
Training loss: 0.4656641796448871
Validation loss: 2.5101877635020666

Epoch: 6| Step: 5
Training loss: 0.554613511429711
Validation loss: 2.506111818328446

Epoch: 6| Step: 6
Training loss: 0.5264496181397164
Validation loss: 2.5221525330563885

Epoch: 6| Step: 7
Training loss: 0.5979300476420039
Validation loss: 2.538871710766074

Epoch: 6| Step: 8
Training loss: 0.6152441114835968
Validation loss: 2.543637669555681

Epoch: 6| Step: 9
Training loss: 0.3017353061813565
Validation loss: 2.587469908123336

Epoch: 6| Step: 10
Training loss: 0.18935039527238356
Validation loss: 2.564569922323064

Epoch: 6| Step: 11
Training loss: 0.5202584590856578
Validation loss: 2.5769196020191707

Epoch: 6| Step: 12
Training loss: 0.5855003251906354
Validation loss: 2.556273506297769

Epoch: 6| Step: 13
Training loss: 0.2293149466598504
Validation loss: 2.5320895063925106

Epoch: 283| Step: 0
Training loss: 0.30831391889863125
Validation loss: 2.5086882812057056

Epoch: 6| Step: 1
Training loss: 0.5388168106782796
Validation loss: 2.516589180274284

Epoch: 6| Step: 2
Training loss: 0.6335167439392422
Validation loss: 2.457949530367459

Epoch: 6| Step: 3
Training loss: 0.48131082757258775
Validation loss: 2.4719053202971435

Epoch: 6| Step: 4
Training loss: 0.38995506058270757
Validation loss: 2.502596240272086

Epoch: 6| Step: 5
Training loss: 0.6307844938355901
Validation loss: 2.505970851108681

Epoch: 6| Step: 6
Training loss: 0.3207028499327954
Validation loss: 2.5449028338981687

Epoch: 6| Step: 7
Training loss: 0.21452548989650233
Validation loss: 2.533922516482792

Epoch: 6| Step: 8
Training loss: 0.38110062221134977
Validation loss: 2.5651170466147404

Epoch: 6| Step: 9
Training loss: 0.4376068665910678
Validation loss: 2.5838385892360036

Epoch: 6| Step: 10
Training loss: 0.8267755129384008
Validation loss: 2.6074288557745042

Epoch: 6| Step: 11
Training loss: 0.5276833465098244
Validation loss: 2.6012909405763613

Epoch: 6| Step: 12
Training loss: 0.47052878795850417
Validation loss: 2.5759873264426196

Epoch: 6| Step: 13
Training loss: 0.41508192850786674
Validation loss: 2.5513268487003415

Epoch: 284| Step: 0
Training loss: 0.24023420442404544
Validation loss: 2.5016084869950452

Epoch: 6| Step: 1
Training loss: 0.2851377507310059
Validation loss: 2.533989419914739

Epoch: 6| Step: 2
Training loss: 0.5442085656377647
Validation loss: 2.48059207918753

Epoch: 6| Step: 3
Training loss: 0.39020236994308616
Validation loss: 2.4576269824052184

Epoch: 6| Step: 4
Training loss: 0.4099597641926732
Validation loss: 2.4612504001347686

Epoch: 6| Step: 5
Training loss: 0.6014100909686508
Validation loss: 2.4104343318434593

Epoch: 6| Step: 6
Training loss: 0.25919613760838034
Validation loss: 2.4386957841376393

Epoch: 6| Step: 7
Training loss: 0.4856606004251458
Validation loss: 2.504994954301485

Epoch: 6| Step: 8
Training loss: 0.49812977418801413
Validation loss: 2.5094979886409954

Epoch: 6| Step: 9
Training loss: 0.7434884164314444
Validation loss: 2.5804490553429775

Epoch: 6| Step: 10
Training loss: 0.5098345187465325
Validation loss: 2.552517094435511

Epoch: 6| Step: 11
Training loss: 0.5234574840773281
Validation loss: 2.5844059548942897

Epoch: 6| Step: 12
Training loss: 0.4123272974996985
Validation loss: 2.5781996352304914

Epoch: 6| Step: 13
Training loss: 0.8391457429365228
Validation loss: 2.5266389970008154

Epoch: 285| Step: 0
Training loss: 0.3686072315630602
Validation loss: 2.5367167334626872

Epoch: 6| Step: 1
Training loss: 0.3068029132168186
Validation loss: 2.54049887643611

Epoch: 6| Step: 2
Training loss: 0.49253495380370915
Validation loss: 2.50933590260115

Epoch: 6| Step: 3
Training loss: 0.23465241862070094
Validation loss: 2.486346044594164

Epoch: 6| Step: 4
Training loss: 0.4768212194601786
Validation loss: 2.5094722019100666

Epoch: 6| Step: 5
Training loss: 0.5025033569698271
Validation loss: 2.5002997310990067

Epoch: 6| Step: 6
Training loss: 0.1726885743758378
Validation loss: 2.5572065207183403

Epoch: 6| Step: 7
Training loss: 0.5447146660951093
Validation loss: 2.5965685158203358

Epoch: 6| Step: 8
Training loss: 0.5001129678424383
Validation loss: 2.61827225517856

Epoch: 6| Step: 9
Training loss: 0.419351714094622
Validation loss: 2.6654103281284884

Epoch: 6| Step: 10
Training loss: 0.6682225464641343
Validation loss: 2.6612619156127746

Epoch: 6| Step: 11
Training loss: 0.6298618993318451
Validation loss: 2.608130593709296

Epoch: 6| Step: 12
Training loss: 0.4635443276603986
Validation loss: 2.555375102136729

Epoch: 6| Step: 13
Training loss: 0.9214210362353349
Validation loss: 2.4831390773839086

Epoch: 286| Step: 0
Training loss: 0.498341880643174
Validation loss: 2.4561410837564046

Epoch: 6| Step: 1
Training loss: 0.4982177291722796
Validation loss: 2.4077446158779687

Epoch: 6| Step: 2
Training loss: 0.4806254526788492
Validation loss: 2.3906515732441846

Epoch: 6| Step: 3
Training loss: 0.27964414335093213
Validation loss: 2.427461597749752

Epoch: 6| Step: 4
Training loss: 0.34888679805503364
Validation loss: 2.476952263302216

Epoch: 6| Step: 5
Training loss: 0.35164192150311735
Validation loss: 2.5012304303208674

Epoch: 6| Step: 6
Training loss: 0.47280433793974425
Validation loss: 2.5423632762702697

Epoch: 6| Step: 7
Training loss: 0.7088048618350115
Validation loss: 2.5697905751786125

Epoch: 6| Step: 8
Training loss: 0.3324219144469259
Validation loss: 2.5695651630119465

Epoch: 6| Step: 9
Training loss: 0.6152591276487662
Validation loss: 2.5779278214601313

Epoch: 6| Step: 10
Training loss: 0.6259764672813403
Validation loss: 2.5569999669976493

Epoch: 6| Step: 11
Training loss: 0.43150121931896124
Validation loss: 2.4827108311418797

Epoch: 6| Step: 12
Training loss: 0.5433104009654669
Validation loss: 2.495454345717768

Epoch: 6| Step: 13
Training loss: 0.2058212078405871
Validation loss: 2.4957976636080965

Epoch: 287| Step: 0
Training loss: 0.3966705185972979
Validation loss: 2.51136067074746

Epoch: 6| Step: 1
Training loss: 0.5494937322292092
Validation loss: 2.5133677073238

Epoch: 6| Step: 2
Training loss: 0.6747569882969833
Validation loss: 2.5541346345848894

Epoch: 6| Step: 3
Training loss: 0.4756202763687549
Validation loss: 2.5705972022548744

Epoch: 6| Step: 4
Training loss: 0.5999002651928117
Validation loss: 2.5592331019290957

Epoch: 6| Step: 5
Training loss: 0.37799012639759255
Validation loss: 2.5469773050105533

Epoch: 6| Step: 6
Training loss: 0.22828905986505083
Validation loss: 2.531408860217094

Epoch: 6| Step: 7
Training loss: 0.4462585772697136
Validation loss: 2.4753568279163654

Epoch: 6| Step: 8
Training loss: 0.26403512304921345
Validation loss: 2.4743246522084115

Epoch: 6| Step: 9
Training loss: 0.6296762763601531
Validation loss: 2.479242500668197

Epoch: 6| Step: 10
Training loss: 0.472814123727011
Validation loss: 2.473565688955493

Epoch: 6| Step: 11
Training loss: 0.3058337389651388
Validation loss: 2.581494385057729

Epoch: 6| Step: 12
Training loss: 0.41538079049789306
Validation loss: 2.618508283509247

Epoch: 6| Step: 13
Training loss: 0.8540663350113749
Validation loss: 2.637701573630046

Epoch: 288| Step: 0
Training loss: 0.32224831968140194
Validation loss: 2.6272717210531815

Epoch: 6| Step: 1
Training loss: 0.635494553112695
Validation loss: 2.6230927974458598

Epoch: 6| Step: 2
Training loss: 0.38951674604593134
Validation loss: 2.599016510535082

Epoch: 6| Step: 3
Training loss: 0.4874702432304992
Validation loss: 2.582892106000563

Epoch: 6| Step: 4
Training loss: 0.5193428902736273
Validation loss: 2.5526894364280994

Epoch: 6| Step: 5
Training loss: 0.33901765324615774
Validation loss: 2.5035726338331115

Epoch: 6| Step: 6
Training loss: 0.25246874958165344
Validation loss: 2.505826382170497

Epoch: 6| Step: 7
Training loss: 0.5466786168215053
Validation loss: 2.463126022204974

Epoch: 6| Step: 8
Training loss: 0.6882984120267645
Validation loss: 2.4881198319613542

Epoch: 6| Step: 9
Training loss: 0.33960877988213384
Validation loss: 2.4675829761328374

Epoch: 6| Step: 10
Training loss: 0.4099283402610852
Validation loss: 2.5198594468687

Epoch: 6| Step: 11
Training loss: 0.35996666177719666
Validation loss: 2.538290078273573

Epoch: 6| Step: 12
Training loss: 0.5786580643847659
Validation loss: 2.5734068305786857

Epoch: 6| Step: 13
Training loss: 0.5396714295698793
Validation loss: 2.5747793744474214

Epoch: 289| Step: 0
Training loss: 0.44645973130881134
Validation loss: 2.5778762931101102

Epoch: 6| Step: 1
Training loss: 0.5515837268148839
Validation loss: 2.5949073795902926

Epoch: 6| Step: 2
Training loss: 0.4428726246732687
Validation loss: 2.5634446172564713

Epoch: 6| Step: 3
Training loss: 0.39816787422995575
Validation loss: 2.5445280056042106

Epoch: 6| Step: 4
Training loss: 0.3013663978591038
Validation loss: 2.494568720888257

Epoch: 6| Step: 5
Training loss: 0.5799790885460536
Validation loss: 2.499045978553753

Epoch: 6| Step: 6
Training loss: 0.40821964285252865
Validation loss: 2.4816671876490766

Epoch: 6| Step: 7
Training loss: 0.4990859617715131
Validation loss: 2.4821685178673256

Epoch: 6| Step: 8
Training loss: 0.48330934262203223
Validation loss: 2.46147001917767

Epoch: 6| Step: 9
Training loss: 0.5678840563566482
Validation loss: 2.4658213584083004

Epoch: 6| Step: 10
Training loss: 0.385970885651321
Validation loss: 2.503263437487566

Epoch: 6| Step: 11
Training loss: 0.5323068540711967
Validation loss: 2.492427118383928

Epoch: 6| Step: 12
Training loss: 0.33801126255931674
Validation loss: 2.522804470647629

Epoch: 6| Step: 13
Training loss: 0.16340854282488604
Validation loss: 2.5576036997741904

Epoch: 290| Step: 0
Training loss: 0.29886674319787554
Validation loss: 2.568045671222302

Epoch: 6| Step: 1
Training loss: 0.3530848497166565
Validation loss: 2.5723625520708877

Epoch: 6| Step: 2
Training loss: 0.7714220625423659
Validation loss: 2.5997000196229867

Epoch: 6| Step: 3
Training loss: 0.44217009830269555
Validation loss: 2.5918016485678796

Epoch: 6| Step: 4
Training loss: 0.7462207626161632
Validation loss: 2.5665719179271833

Epoch: 6| Step: 5
Training loss: 0.3370270028375057
Validation loss: 2.5681864434721007

Epoch: 6| Step: 6
Training loss: 0.3504540878201715
Validation loss: 2.5545907778877517

Epoch: 6| Step: 7
Training loss: 0.3997702467731184
Validation loss: 2.54339515585684

Epoch: 6| Step: 8
Training loss: 0.32840236793508265
Validation loss: 2.5279875178517655

Epoch: 6| Step: 9
Training loss: 0.40103841342679913
Validation loss: 2.5010136846218067

Epoch: 6| Step: 10
Training loss: 0.5063194038947905
Validation loss: 2.5232229931185985

Epoch: 6| Step: 11
Training loss: 0.3001002988441375
Validation loss: 2.4765765098278254

Epoch: 6| Step: 12
Training loss: 0.3367040006943148
Validation loss: 2.5107168556751343

Epoch: 6| Step: 13
Training loss: 0.1530204014277568
Validation loss: 2.5061219803468577

Epoch: 291| Step: 0
Training loss: 0.4100875615323983
Validation loss: 2.5463517204642425

Epoch: 6| Step: 1
Training loss: 0.5410575161907395
Validation loss: 2.583530999665214

Epoch: 6| Step: 2
Training loss: 0.19039887399065022
Validation loss: 2.577310267710139

Epoch: 6| Step: 3
Training loss: 0.5449280823931701
Validation loss: 2.6075784227355796

Epoch: 6| Step: 4
Training loss: 0.4677069503265301
Validation loss: 2.599544674947046

Epoch: 6| Step: 5
Training loss: 0.5054464237995674
Validation loss: 2.5830880550470585

Epoch: 6| Step: 6
Training loss: 0.5342195206597821
Validation loss: 2.595377550168478

Epoch: 6| Step: 7
Training loss: 0.4304659987013831
Validation loss: 2.5967379618242963

Epoch: 6| Step: 8
Training loss: 0.22352150891641884
Validation loss: 2.587756278292182

Epoch: 6| Step: 9
Training loss: 0.31393102579429877
Validation loss: 2.527426974976287

Epoch: 6| Step: 10
Training loss: 0.4452793544011725
Validation loss: 2.4884684355715043

Epoch: 6| Step: 11
Training loss: 0.50189481760235
Validation loss: 2.462109773960532

Epoch: 6| Step: 12
Training loss: 0.47917484884601524
Validation loss: 2.4984849882059303

Epoch: 6| Step: 13
Training loss: 0.5048614733556362
Validation loss: 2.5141012950013164

Epoch: 292| Step: 0
Training loss: 0.3518427579448865
Validation loss: 2.5212919637878946

Epoch: 6| Step: 1
Training loss: 0.34640214582944817
Validation loss: 2.6012770613724543

Epoch: 6| Step: 2
Training loss: 0.41706218623317154
Validation loss: 2.5965877131740522

Epoch: 6| Step: 3
Training loss: 0.5900843805248959
Validation loss: 2.601066204262834

Epoch: 6| Step: 4
Training loss: 0.3103467668435283
Validation loss: 2.653262681851612

Epoch: 6| Step: 5
Training loss: 0.29499439585745213
Validation loss: 2.5887397740979505

Epoch: 6| Step: 6
Training loss: 0.6213837912042561
Validation loss: 2.6052544003473153

Epoch: 6| Step: 7
Training loss: 0.2523753598141195
Validation loss: 2.5582265748701882

Epoch: 6| Step: 8
Training loss: 0.1579812578065996
Validation loss: 2.515926960782659

Epoch: 6| Step: 9
Training loss: 0.45880191504029727
Validation loss: 2.5158578083057974

Epoch: 6| Step: 10
Training loss: 0.6803597600569732
Validation loss: 2.4591475230498236

Epoch: 6| Step: 11
Training loss: 0.4427706805439091
Validation loss: 2.498126759699348

Epoch: 6| Step: 12
Training loss: 0.4417887018258894
Validation loss: 2.5665780529050712

Epoch: 6| Step: 13
Training loss: 0.3249759793574712
Validation loss: 2.5747399265407718

Epoch: 293| Step: 0
Training loss: 0.5763158585984515
Validation loss: 2.6305112180456387

Epoch: 6| Step: 1
Training loss: 0.3709942332896642
Validation loss: 2.651701901883933

Epoch: 6| Step: 2
Training loss: 0.38380998937807215
Validation loss: 2.7013710197756615

Epoch: 6| Step: 3
Training loss: 0.4821024930169468
Validation loss: 2.6751193958648005

Epoch: 6| Step: 4
Training loss: 0.33600482709573465
Validation loss: 2.6946454041051067

Epoch: 6| Step: 5
Training loss: 0.5304088665472846
Validation loss: 2.63803578677142

Epoch: 6| Step: 6
Training loss: 0.37001350178441034
Validation loss: 2.5892199017329993

Epoch: 6| Step: 7
Training loss: 0.4156868221797645
Validation loss: 2.5909367731408715

Epoch: 6| Step: 8
Training loss: 0.37065455899400807
Validation loss: 2.532865239092455

Epoch: 6| Step: 9
Training loss: 0.4765601079912033
Validation loss: 2.503739677344314

Epoch: 6| Step: 10
Training loss: 0.5872248938866723
Validation loss: 2.479381671564022

Epoch: 6| Step: 11
Training loss: 0.4519089132327691
Validation loss: 2.491873207864578

Epoch: 6| Step: 12
Training loss: 0.22572758178670924
Validation loss: 2.514920198558391

Epoch: 6| Step: 13
Training loss: 0.5276810309205473
Validation loss: 2.5231925916370685

Epoch: 294| Step: 0
Training loss: 0.4536545717235008
Validation loss: 2.56494181354331

Epoch: 6| Step: 1
Training loss: 0.41123578736927163
Validation loss: 2.6076065436224014

Epoch: 6| Step: 2
Training loss: 0.43433046043984813
Validation loss: 2.6535545112093986

Epoch: 6| Step: 3
Training loss: 0.7936125899194916
Validation loss: 2.685204584735814

Epoch: 6| Step: 4
Training loss: 0.18441287395253467
Validation loss: 2.6434256224783916

Epoch: 6| Step: 5
Training loss: 0.40480735359024383
Validation loss: 2.5723822270579277

Epoch: 6| Step: 6
Training loss: 0.3900766147345154
Validation loss: 2.529216514188486

Epoch: 6| Step: 7
Training loss: 0.204911791240309
Validation loss: 2.5188442816453036

Epoch: 6| Step: 8
Training loss: 0.4010113997824855
Validation loss: 2.4668133222567046

Epoch: 6| Step: 9
Training loss: 0.3497071156186085
Validation loss: 2.4815497436391443

Epoch: 6| Step: 10
Training loss: 0.4204025002025008
Validation loss: 2.50932252953922

Epoch: 6| Step: 11
Training loss: 0.4816806983828871
Validation loss: 2.5329675229251487

Epoch: 6| Step: 12
Training loss: 0.5274810894744845
Validation loss: 2.5943835443852694

Epoch: 6| Step: 13
Training loss: 0.6532892695922137
Validation loss: 2.6613368813831904

Epoch: 295| Step: 0
Training loss: 0.5143121999919822
Validation loss: 2.707379507464143

Epoch: 6| Step: 1
Training loss: 0.631295257305698
Validation loss: 2.7394344015325265

Epoch: 6| Step: 2
Training loss: 0.4256760003431515
Validation loss: 2.6878171010158063

Epoch: 6| Step: 3
Training loss: 0.2564816370018193
Validation loss: 2.6555283166261234

Epoch: 6| Step: 4
Training loss: 0.472613750470174
Validation loss: 2.59000145919454

Epoch: 6| Step: 5
Training loss: 0.6228402730947984
Validation loss: 2.527389087502704

Epoch: 6| Step: 6
Training loss: 0.3784186775446991
Validation loss: 2.5084810518100364

Epoch: 6| Step: 7
Training loss: 0.288860675875075
Validation loss: 2.533634259507445

Epoch: 6| Step: 8
Training loss: 0.46433058229780705
Validation loss: 2.5067894438809737

Epoch: 6| Step: 9
Training loss: 0.4893059316640845
Validation loss: 2.5655504523790817

Epoch: 6| Step: 10
Training loss: 0.3254658945135081
Validation loss: 2.520381418832014

Epoch: 6| Step: 11
Training loss: 0.5898671935014171
Validation loss: 2.564337760966397

Epoch: 6| Step: 12
Training loss: 0.41227458516891674
Validation loss: 2.586786393336434

Epoch: 6| Step: 13
Training loss: 0.36886699566224623
Validation loss: 2.5954432223304584

Epoch: 296| Step: 0
Training loss: 0.5082338785634736
Validation loss: 2.5393276412512567

Epoch: 6| Step: 1
Training loss: 0.20862158364606592
Validation loss: 2.5324167033772946

Epoch: 6| Step: 2
Training loss: 0.580488066525155
Validation loss: 2.5346182033494737

Epoch: 6| Step: 3
Training loss: 0.40911116287999916
Validation loss: 2.5427196928830043

Epoch: 6| Step: 4
Training loss: 0.5133613837409932
Validation loss: 2.532633610021668

Epoch: 6| Step: 5
Training loss: 0.30160034416593956
Validation loss: 2.5344870497323257

Epoch: 6| Step: 6
Training loss: 0.5386712409687253
Validation loss: 2.548616990386854

Epoch: 6| Step: 7
Training loss: 0.4676532312175311
Validation loss: 2.5399871924454263

Epoch: 6| Step: 8
Training loss: 0.3373649786258988
Validation loss: 2.5558089411852634

Epoch: 6| Step: 9
Training loss: 0.47412480235981963
Validation loss: 2.57485348736361

Epoch: 6| Step: 10
Training loss: 0.34458502222259996
Validation loss: 2.5541426523021147

Epoch: 6| Step: 11
Training loss: 0.46825522695741156
Validation loss: 2.5812187746532955

Epoch: 6| Step: 12
Training loss: 0.3304008847075849
Validation loss: 2.550663257426372

Epoch: 6| Step: 13
Training loss: 0.46712683344382433
Validation loss: 2.580777917576167

Epoch: 297| Step: 0
Training loss: 0.3012921836411431
Validation loss: 2.511181587982798

Epoch: 6| Step: 1
Training loss: 0.35000271753550427
Validation loss: 2.490878008755382

Epoch: 6| Step: 2
Training loss: 0.31186476755652276
Validation loss: 2.4675410041303314

Epoch: 6| Step: 3
Training loss: 0.5971629282129616
Validation loss: 2.475572635577439

Epoch: 6| Step: 4
Training loss: 0.2745892383035049
Validation loss: 2.4886042792403154

Epoch: 6| Step: 5
Training loss: 0.3846673404236209
Validation loss: 2.524869589096451

Epoch: 6| Step: 6
Training loss: 0.33380721228703564
Validation loss: 2.526843553249171

Epoch: 6| Step: 7
Training loss: 0.5618694002595926
Validation loss: 2.542288444096102

Epoch: 6| Step: 8
Training loss: 0.4804146433812745
Validation loss: 2.5943105373385524

Epoch: 6| Step: 9
Training loss: 0.5665192326953408
Validation loss: 2.585526981551789

Epoch: 6| Step: 10
Training loss: 0.32987482254353123
Validation loss: 2.584226290865456

Epoch: 6| Step: 11
Training loss: 0.5528729538022599
Validation loss: 2.554356030964605

Epoch: 6| Step: 12
Training loss: 0.4353555507143512
Validation loss: 2.524162366920123

Epoch: 6| Step: 13
Training loss: 0.15912346929554105
Validation loss: 2.469855168509478

Epoch: 298| Step: 0
Training loss: 0.5038327599689495
Validation loss: 2.4636854282302405

Epoch: 6| Step: 1
Training loss: 0.31972093151915393
Validation loss: 2.4838149309529403

Epoch: 6| Step: 2
Training loss: 0.4759028825800438
Validation loss: 2.5369570884549195

Epoch: 6| Step: 3
Training loss: 0.2784195304834832
Validation loss: 2.568340750213872

Epoch: 6| Step: 4
Training loss: 0.5348382548017317
Validation loss: 2.6050678196895114

Epoch: 6| Step: 5
Training loss: 0.47686720315501385
Validation loss: 2.6389560054785104

Epoch: 6| Step: 6
Training loss: 0.5095073878957129
Validation loss: 2.632986454477964

Epoch: 6| Step: 7
Training loss: 0.3071276447894901
Validation loss: 2.602368985457746

Epoch: 6| Step: 8
Training loss: 0.29645913259130857
Validation loss: 2.581815542332481

Epoch: 6| Step: 9
Training loss: 0.4249075578682212
Validation loss: 2.511818570744541

Epoch: 6| Step: 10
Training loss: 0.383128911258217
Validation loss: 2.4684258348511063

Epoch: 6| Step: 11
Training loss: 0.40495861648537634
Validation loss: 2.4451678027275086

Epoch: 6| Step: 12
Training loss: 0.6166733882082378
Validation loss: 2.5022123023444456

Epoch: 6| Step: 13
Training loss: 0.19991890037860832
Validation loss: 2.461433453644371

Epoch: 299| Step: 0
Training loss: 0.3857130015474216
Validation loss: 2.5028249991823204

Epoch: 6| Step: 1
Training loss: 0.5852517756679995
Validation loss: 2.55311574706929

Epoch: 6| Step: 2
Training loss: 0.5278621809656485
Validation loss: 2.5746020179073468

Epoch: 6| Step: 3
Training loss: 0.32525373054435053
Validation loss: 2.5837943836340758

Epoch: 6| Step: 4
Training loss: 0.40363980770740837
Validation loss: 2.6105526860305592

Epoch: 6| Step: 5
Training loss: 0.4265974079422641
Validation loss: 2.560197179142335

Epoch: 6| Step: 6
Training loss: 0.3944994092122188
Validation loss: 2.53643129584539

Epoch: 6| Step: 7
Training loss: 0.4653649493619664
Validation loss: 2.5437388238225207

Epoch: 6| Step: 8
Training loss: 0.20044488934336457
Validation loss: 2.515549586434532

Epoch: 6| Step: 9
Training loss: 0.16693432123220509
Validation loss: 2.5243084869011914

Epoch: 6| Step: 10
Training loss: 0.5058536602861023
Validation loss: 2.538764462328961

Epoch: 6| Step: 11
Training loss: 0.3356492780006266
Validation loss: 2.527093340386887

Epoch: 6| Step: 12
Training loss: 0.4997885674235697
Validation loss: 2.5308218730281693

Epoch: 6| Step: 13
Training loss: 0.45349771692632906
Validation loss: 2.5258731443726385

Epoch: 300| Step: 0
Training loss: 0.4675502523402183
Validation loss: 2.511478407023315

Epoch: 6| Step: 1
Training loss: 0.5512845600738717
Validation loss: 2.5122989665742104

Epoch: 6| Step: 2
Training loss: 0.5959918213737577
Validation loss: 2.551789030007324

Epoch: 6| Step: 3
Training loss: 0.3811264666550674
Validation loss: 2.5052148276822126

Epoch: 6| Step: 4
Training loss: 0.4123794068722248
Validation loss: 2.5250365770895598

Epoch: 6| Step: 5
Training loss: 0.46265020444476507
Validation loss: 2.5065924037548597

Epoch: 6| Step: 6
Training loss: 0.15455776804781232
Validation loss: 2.517847629181758

Epoch: 6| Step: 7
Training loss: 0.23543636487875025
Validation loss: 2.473907498850454

Epoch: 6| Step: 8
Training loss: 0.3991575653310147
Validation loss: 2.5256712993507064

Epoch: 6| Step: 9
Training loss: 0.18669481044193675
Validation loss: 2.4970684963389127

Epoch: 6| Step: 10
Training loss: 0.43387929432226635
Validation loss: 2.4813516849069015

Epoch: 6| Step: 11
Training loss: 0.3804631446253137
Validation loss: 2.5040280644568274

Epoch: 6| Step: 12
Training loss: 0.2938279839748378
Validation loss: 2.530456619165993

Epoch: 6| Step: 13
Training loss: 0.41242238672842196
Validation loss: 2.571029616409435

Epoch: 301| Step: 0
Training loss: 0.23956042245839324
Validation loss: 2.5759861013425036

Epoch: 6| Step: 1
Training loss: 0.32474659843586856
Validation loss: 2.579060648917126

Epoch: 6| Step: 2
Training loss: 0.48907630279368275
Validation loss: 2.5753747335463886

Epoch: 6| Step: 3
Training loss: 0.40786868179763336
Validation loss: 2.533010378823597

Epoch: 6| Step: 4
Training loss: 0.4886199081928491
Validation loss: 2.487427503576795

Epoch: 6| Step: 5
Training loss: 0.4043576475898322
Validation loss: 2.421053627714457

Epoch: 6| Step: 6
Training loss: 0.2543067121580712
Validation loss: 2.444940637749093

Epoch: 6| Step: 7
Training loss: 0.4156183306797108
Validation loss: 2.4273823763319777

Epoch: 6| Step: 8
Training loss: 0.35135347722326393
Validation loss: 2.4493396118387096

Epoch: 6| Step: 9
Training loss: 0.4202798249260736
Validation loss: 2.466134598378701

Epoch: 6| Step: 10
Training loss: 0.35660451181834113
Validation loss: 2.4463406410058117

Epoch: 6| Step: 11
Training loss: 0.4784163391496664
Validation loss: 2.5024426811849296

Epoch: 6| Step: 12
Training loss: 0.5164008516846097
Validation loss: 2.4819181546359728

Epoch: 6| Step: 13
Training loss: 0.6620974019186153
Validation loss: 2.502990122992946

Epoch: 302| Step: 0
Training loss: 0.42143289925198046
Validation loss: 2.472305177284106

Epoch: 6| Step: 1
Training loss: 0.4226313627746236
Validation loss: 2.4883044506383625

Epoch: 6| Step: 2
Training loss: 0.22460358653695248
Validation loss: 2.4609460651165964

Epoch: 6| Step: 3
Training loss: 0.3141681374866213
Validation loss: 2.452194036693925

Epoch: 6| Step: 4
Training loss: 0.3536571830460126
Validation loss: 2.4837472743950273

Epoch: 6| Step: 5
Training loss: 0.3269943785534201
Validation loss: 2.466621799387976

Epoch: 6| Step: 6
Training loss: 0.4028103354420298
Validation loss: 2.50330056358854

Epoch: 6| Step: 7
Training loss: 0.2736193733264173
Validation loss: 2.5184125803675745

Epoch: 6| Step: 8
Training loss: 0.3046954716348755
Validation loss: 2.4910595272856866

Epoch: 6| Step: 9
Training loss: 0.5461690433315841
Validation loss: 2.484103548576498

Epoch: 6| Step: 10
Training loss: 0.3869823559218465
Validation loss: 2.474962058905028

Epoch: 6| Step: 11
Training loss: 0.5294277409444522
Validation loss: 2.4733081663194234

Epoch: 6| Step: 12
Training loss: 0.3170209376846853
Validation loss: 2.449559445478441

Epoch: 6| Step: 13
Training loss: 0.6415988916257312
Validation loss: 2.4562997594971736

Epoch: 303| Step: 0
Training loss: 0.5925948802613544
Validation loss: 2.43082689023768

Epoch: 6| Step: 1
Training loss: 0.2236734295070511
Validation loss: 2.4828694412897914

Epoch: 6| Step: 2
Training loss: 0.26544121386698843
Validation loss: 2.499493244042617

Epoch: 6| Step: 3
Training loss: 0.1787884549311257
Validation loss: 2.5526240653465595

Epoch: 6| Step: 4
Training loss: 0.46042015655483765
Validation loss: 2.5627756608287173

Epoch: 6| Step: 5
Training loss: 0.19393620042245616
Validation loss: 2.585204100721389

Epoch: 6| Step: 6
Training loss: 0.48268342746477155
Validation loss: 2.57551566560927

Epoch: 6| Step: 7
Training loss: 0.3012615184243881
Validation loss: 2.5627175045470962

Epoch: 6| Step: 8
Training loss: 0.49866823816923045
Validation loss: 2.502241971076126

Epoch: 6| Step: 9
Training loss: 0.488956686157174
Validation loss: 2.4851729827695204

Epoch: 6| Step: 10
Training loss: 0.36727802702788653
Validation loss: 2.4819112182622645

Epoch: 6| Step: 11
Training loss: 0.40162186536328487
Validation loss: 2.4317282576439743

Epoch: 6| Step: 12
Training loss: 0.3401243213603334
Validation loss: 2.441583051813907

Epoch: 6| Step: 13
Training loss: 0.16986822509062754
Validation loss: 2.4322091340877416

Epoch: 304| Step: 0
Training loss: 0.289646358058099
Validation loss: 2.484329490479551

Epoch: 6| Step: 1
Training loss: 0.393025309623721
Validation loss: 2.515090958052113

Epoch: 6| Step: 2
Training loss: 0.564360719924685
Validation loss: 2.52485607569177

Epoch: 6| Step: 3
Training loss: 0.3167604653617479
Validation loss: 2.581693711158599

Epoch: 6| Step: 4
Training loss: 0.38797492410676376
Validation loss: 2.605080107593518

Epoch: 6| Step: 5
Training loss: 0.23728363508866807
Validation loss: 2.6459171888108046

Epoch: 6| Step: 6
Training loss: 0.2673723863863616
Validation loss: 2.588004830166679

Epoch: 6| Step: 7
Training loss: 0.39929663837077295
Validation loss: 2.5738406313114544

Epoch: 6| Step: 8
Training loss: 0.2987864970215396
Validation loss: 2.523701578693473

Epoch: 6| Step: 9
Training loss: 0.28016462440122697
Validation loss: 2.5545854355232085

Epoch: 6| Step: 10
Training loss: 0.5323485348427378
Validation loss: 2.526360160320349

Epoch: 6| Step: 11
Training loss: 0.3839810888357405
Validation loss: 2.5060590312275894

Epoch: 6| Step: 12
Training loss: 0.39491340333811553
Validation loss: 2.528440274458116

Epoch: 6| Step: 13
Training loss: 0.4407533526322833
Validation loss: 2.4963827194913137

Epoch: 305| Step: 0
Training loss: 0.48834994023677036
Validation loss: 2.4698580987028405

Epoch: 6| Step: 1
Training loss: 0.5053528713313458
Validation loss: 2.469887094247491

Epoch: 6| Step: 2
Training loss: 0.32214478047648326
Validation loss: 2.4791025014012025

Epoch: 6| Step: 3
Training loss: 0.2228309046726602
Validation loss: 2.423754649854841

Epoch: 6| Step: 4
Training loss: 0.4779019527393013
Validation loss: 2.4329453630040585

Epoch: 6| Step: 5
Training loss: 0.5189513505118513
Validation loss: 2.431294956472278

Epoch: 6| Step: 6
Training loss: 0.46578781046529305
Validation loss: 2.4423699123000575

Epoch: 6| Step: 7
Training loss: 0.24612131418536165
Validation loss: 2.4309802771160136

Epoch: 6| Step: 8
Training loss: 0.16313916896619335
Validation loss: 2.4289375579876187

Epoch: 6| Step: 9
Training loss: 0.22579648154601073
Validation loss: 2.419443297050848

Epoch: 6| Step: 10
Training loss: 0.3729752077295515
Validation loss: 2.4631171347316236

Epoch: 6| Step: 11
Training loss: 0.30007422939514
Validation loss: 2.4548700972050477

Epoch: 6| Step: 12
Training loss: 0.4729302613017073
Validation loss: 2.498759790659167

Epoch: 6| Step: 13
Training loss: 0.27535561413435133
Validation loss: 2.458557509401126

Epoch: 306| Step: 0
Training loss: 0.30602237309292213
Validation loss: 2.4910649266452243

Epoch: 6| Step: 1
Training loss: 0.13188306884352033
Validation loss: 2.4841279742685303

Epoch: 6| Step: 2
Training loss: 0.45470911217152693
Validation loss: 2.4894078297916056

Epoch: 6| Step: 3
Training loss: 0.33028502441149526
Validation loss: 2.4835574052780283

Epoch: 6| Step: 4
Training loss: 0.35945974263046543
Validation loss: 2.5241189535165556

Epoch: 6| Step: 5
Training loss: 0.2201604670275715
Validation loss: 2.536473084025942

Epoch: 6| Step: 6
Training loss: 0.5623141882551916
Validation loss: 2.5525311513895717

Epoch: 6| Step: 7
Training loss: 0.36553728323000817
Validation loss: 2.5748675513121326

Epoch: 6| Step: 8
Training loss: 0.49749545818920227
Validation loss: 2.5576075297903635

Epoch: 6| Step: 9
Training loss: 0.2272701721156144
Validation loss: 2.5848855076959465

Epoch: 6| Step: 10
Training loss: 0.25858199274355076
Validation loss: 2.59326914246341

Epoch: 6| Step: 11
Training loss: 0.4232154320189143
Validation loss: 2.558534031740698

Epoch: 6| Step: 12
Training loss: 0.30973419280124526
Validation loss: 2.560273542575609

Epoch: 6| Step: 13
Training loss: 0.39534543318643073
Validation loss: 2.5192126952314986

Epoch: 307| Step: 0
Training loss: 0.5272028416886971
Validation loss: 2.5059612920574352

Epoch: 6| Step: 1
Training loss: 0.21906394228820966
Validation loss: 2.477532442142344

Epoch: 6| Step: 2
Training loss: 0.3868960735023206
Validation loss: 2.5320641927282828

Epoch: 6| Step: 3
Training loss: 0.37143635243869694
Validation loss: 2.5546522787530597

Epoch: 6| Step: 4
Training loss: 0.42558157902411975
Validation loss: 2.5716154001259848

Epoch: 6| Step: 5
Training loss: 0.2748462626573865
Validation loss: 2.5369997440793477

Epoch: 6| Step: 6
Training loss: 0.3860345818737031
Validation loss: 2.536620682920016

Epoch: 6| Step: 7
Training loss: 0.43622426954535415
Validation loss: 2.5093256399401294

Epoch: 6| Step: 8
Training loss: 0.3151914801360476
Validation loss: 2.4866652413579433

Epoch: 6| Step: 9
Training loss: 0.39272155798476344
Validation loss: 2.5158235694100064

Epoch: 6| Step: 10
Training loss: 0.2596862499606347
Validation loss: 2.514656990945496

Epoch: 6| Step: 11
Training loss: 0.33762600630462286
Validation loss: 2.482540183401422

Epoch: 6| Step: 12
Training loss: 0.1604678623189768
Validation loss: 2.4731313146728735

Epoch: 6| Step: 13
Training loss: 0.2197154063465592
Validation loss: 2.4757264540438513

Epoch: 308| Step: 0
Training loss: 0.3336826657118131
Validation loss: 2.5414914552064976

Epoch: 6| Step: 1
Training loss: 0.32613508508118677
Validation loss: 2.4989820992252465

Epoch: 6| Step: 2
Training loss: 0.2656340176790688
Validation loss: 2.4918550669576773

Epoch: 6| Step: 3
Training loss: 0.49610429287017926
Validation loss: 2.5011835762603214

Epoch: 6| Step: 4
Training loss: 0.16527739927393673
Validation loss: 2.5273012925211713

Epoch: 6| Step: 5
Training loss: 0.31047864680266
Validation loss: 2.4714022069126527

Epoch: 6| Step: 6
Training loss: 0.33082445403986355
Validation loss: 2.5077164597423454

Epoch: 6| Step: 7
Training loss: 0.47499081703143553
Validation loss: 2.4936021360710448

Epoch: 6| Step: 8
Training loss: 0.1723474057588862
Validation loss: 2.5199186062445587

Epoch: 6| Step: 9
Training loss: 0.2806197495808319
Validation loss: 2.5244477720725897

Epoch: 6| Step: 10
Training loss: 0.31687889589551926
Validation loss: 2.532220742172874

Epoch: 6| Step: 11
Training loss: 0.3860166321837629
Validation loss: 2.515069593363185

Epoch: 6| Step: 12
Training loss: 0.5222436470879773
Validation loss: 2.54096552939964

Epoch: 6| Step: 13
Training loss: 0.23044136660554526
Validation loss: 2.5580062962079597

Epoch: 309| Step: 0
Training loss: 0.2525966027035146
Validation loss: 2.5385081635332907

Epoch: 6| Step: 1
Training loss: 0.1899833044603469
Validation loss: 2.5457927096083792

Epoch: 6| Step: 2
Training loss: 0.43710315962421603
Validation loss: 2.55688810880799

Epoch: 6| Step: 3
Training loss: 0.4449786222873579
Validation loss: 2.5186711877056944

Epoch: 6| Step: 4
Training loss: 0.5017020343382667
Validation loss: 2.544745036692659

Epoch: 6| Step: 5
Training loss: 0.1528136757257396
Validation loss: 2.5380599745666896

Epoch: 6| Step: 6
Training loss: 0.46362298259363033
Validation loss: 2.520318760765666

Epoch: 6| Step: 7
Training loss: 0.24688511719072623
Validation loss: 2.497633883870762

Epoch: 6| Step: 8
Training loss: 0.3046906422184039
Validation loss: 2.527318035800766

Epoch: 6| Step: 9
Training loss: 0.1660703568837823
Validation loss: 2.5109424856497733

Epoch: 6| Step: 10
Training loss: 0.325099518559474
Validation loss: 2.5250273907423697

Epoch: 6| Step: 11
Training loss: 0.43620889754256886
Validation loss: 2.520872584781205

Epoch: 6| Step: 12
Training loss: 0.21608976226679877
Validation loss: 2.5285600766160994

Epoch: 6| Step: 13
Training loss: 0.4605619225862704
Validation loss: 2.54749087218962

Epoch: 310| Step: 0
Training loss: 0.22002858068393563
Validation loss: 2.530073183259264

Epoch: 6| Step: 1
Training loss: 0.4245133727475614
Validation loss: 2.563364100835722

Epoch: 6| Step: 2
Training loss: 0.5514578484952337
Validation loss: 2.5493393619109694

Epoch: 6| Step: 3
Training loss: 0.14772239772674045
Validation loss: 2.548497749831057

Epoch: 6| Step: 4
Training loss: 0.43522313834951426
Validation loss: 2.520600327377973

Epoch: 6| Step: 5
Training loss: 0.15898978718536264
Validation loss: 2.4973909648600716

Epoch: 6| Step: 6
Training loss: 0.21856848815490393
Validation loss: 2.5234890793509805

Epoch: 6| Step: 7
Training loss: 0.3229831222119389
Validation loss: 2.495100808658273

Epoch: 6| Step: 8
Training loss: 0.33932734311140167
Validation loss: 2.4989610974455045

Epoch: 6| Step: 9
Training loss: 0.2474051607615595
Validation loss: 2.486542372166162

Epoch: 6| Step: 10
Training loss: 0.4545515886348028
Validation loss: 2.4624953920429435

Epoch: 6| Step: 11
Training loss: 0.2624022256320678
Validation loss: 2.4936060325187888

Epoch: 6| Step: 12
Training loss: 0.38656487919808447
Validation loss: 2.476013892472166

Epoch: 6| Step: 13
Training loss: 0.06339818076541835
Validation loss: 2.4897263727343293

Epoch: 311| Step: 0
Training loss: 0.1447062592673102
Validation loss: 2.4860373598144534

Epoch: 6| Step: 1
Training loss: 0.3029785525116756
Validation loss: 2.547384694620742

Epoch: 6| Step: 2
Training loss: 0.413184945436312
Validation loss: 2.501910217172879

Epoch: 6| Step: 3
Training loss: 0.24555704841572323
Validation loss: 2.4999451118514524

Epoch: 6| Step: 4
Training loss: 0.300950361989075
Validation loss: 2.5257035609651033

Epoch: 6| Step: 5
Training loss: 0.5054464532807548
Validation loss: 2.5167329193415293

Epoch: 6| Step: 6
Training loss: 0.38812689217123103
Validation loss: 2.502156609257015

Epoch: 6| Step: 7
Training loss: 0.2616645557602902
Validation loss: 2.515850430278638

Epoch: 6| Step: 8
Training loss: 0.2519273375096569
Validation loss: 2.5244086760760216

Epoch: 6| Step: 9
Training loss: 0.5479611373907747
Validation loss: 2.5034211079922435

Epoch: 6| Step: 10
Training loss: 0.22515564707318597
Validation loss: 2.5278293533439524

Epoch: 6| Step: 11
Training loss: 0.19734817137488347
Validation loss: 2.553840660672097

Epoch: 6| Step: 12
Training loss: 0.33722604874167783
Validation loss: 2.5134283926431236

Epoch: 6| Step: 13
Training loss: 0.2908541852440405
Validation loss: 2.506405859839877

Epoch: 312| Step: 0
Training loss: 0.3721046131573387
Validation loss: 2.5477001293738497

Epoch: 6| Step: 1
Training loss: 0.29466751953220216
Validation loss: 2.4917513732910654

Epoch: 6| Step: 2
Training loss: 0.1658428190344282
Validation loss: 2.535016042330889

Epoch: 6| Step: 3
Training loss: 0.25403336497498796
Validation loss: 2.5458554979686068

Epoch: 6| Step: 4
Training loss: 0.2358885373221953
Validation loss: 2.5283020285290716

Epoch: 6| Step: 5
Training loss: 0.20383134321053256
Validation loss: 2.5399690954091567

Epoch: 6| Step: 6
Training loss: 0.40446188687491647
Validation loss: 2.5560487084406756

Epoch: 6| Step: 7
Training loss: 0.32508694787808223
Validation loss: 2.5528636326302885

Epoch: 6| Step: 8
Training loss: 0.47736803358278435
Validation loss: 2.5250207050343274

Epoch: 6| Step: 9
Training loss: 0.5111098124336707
Validation loss: 2.507135219467934

Epoch: 6| Step: 10
Training loss: 0.30093293266752114
Validation loss: 2.5052748253369366

Epoch: 6| Step: 11
Training loss: 0.3357242972249359
Validation loss: 2.5092470445613846

Epoch: 6| Step: 12
Training loss: 0.12747945984712492
Validation loss: 2.5190809832773877

Epoch: 6| Step: 13
Training loss: 0.4719495929092671
Validation loss: 2.506105695932856

Epoch: 313| Step: 0
Training loss: 0.4227070902992097
Validation loss: 2.5195704074343697

Epoch: 6| Step: 1
Training loss: 0.2220107140329151
Validation loss: 2.558765025458307

Epoch: 6| Step: 2
Training loss: 0.48134542361372623
Validation loss: 2.5453036476368633

Epoch: 6| Step: 3
Training loss: 0.39157922543107393
Validation loss: 2.5850363343596365

Epoch: 6| Step: 4
Training loss: 0.32515571971815244
Validation loss: 2.5414404217832014

Epoch: 6| Step: 5
Training loss: 0.22816391312526207
Validation loss: 2.530412790974936

Epoch: 6| Step: 6
Training loss: 0.31156066145971417
Validation loss: 2.5670061416591814

Epoch: 6| Step: 7
Training loss: 0.2814983225343908
Validation loss: 2.5047795952149903

Epoch: 6| Step: 8
Training loss: 0.37773817468761745
Validation loss: 2.522751657341858

Epoch: 6| Step: 9
Training loss: 0.47019939456646787
Validation loss: 2.54120109311098

Epoch: 6| Step: 10
Training loss: 0.2489510225209515
Validation loss: 2.5244424750869556

Epoch: 6| Step: 11
Training loss: 0.26269532668103035
Validation loss: 2.59462523318591

Epoch: 6| Step: 12
Training loss: 0.3186085433855569
Validation loss: 2.590916542465381

Epoch: 6| Step: 13
Training loss: 0.2520580073447396
Validation loss: 2.573868145940929

Epoch: 314| Step: 0
Training loss: 0.18085241036568794
Validation loss: 2.565509713404409

Epoch: 6| Step: 1
Training loss: 0.48655450293719477
Validation loss: 2.529034992317882

Epoch: 6| Step: 2
Training loss: 0.16194656538203783
Validation loss: 2.4800987339097538

Epoch: 6| Step: 3
Training loss: 0.44969374381284316
Validation loss: 2.4602050774737227

Epoch: 6| Step: 4
Training loss: 0.48680163698740064
Validation loss: 2.417195172877077

Epoch: 6| Step: 5
Training loss: 0.22363255429981768
Validation loss: 2.3943261986829163

Epoch: 6| Step: 6
Training loss: 0.40744810230254636
Validation loss: 2.4088359340963263

Epoch: 6| Step: 7
Training loss: 0.48540806585340746
Validation loss: 2.4525789157680777

Epoch: 6| Step: 8
Training loss: 0.16269719739831842
Validation loss: 2.4934006259064754

Epoch: 6| Step: 9
Training loss: 0.2781169483005154
Validation loss: 2.535308871217922

Epoch: 6| Step: 10
Training loss: 0.17676543646119308
Validation loss: 2.5457232511011068

Epoch: 6| Step: 11
Training loss: 0.16295196832657297
Validation loss: 2.5139868672661665

Epoch: 6| Step: 12
Training loss: 0.4064015692617689
Validation loss: 2.5529995825301937

Epoch: 6| Step: 13
Training loss: 0.3581814225838945
Validation loss: 2.5583237923369433

Epoch: 315| Step: 0
Training loss: 0.34211323946947786
Validation loss: 2.5343034457225144

Epoch: 6| Step: 1
Training loss: 0.5138817420095921
Validation loss: 2.512288055026974

Epoch: 6| Step: 2
Training loss: 0.34165189665565615
Validation loss: 2.4548111620163926

Epoch: 6| Step: 3
Training loss: 0.2597844970272595
Validation loss: 2.4908640474603865

Epoch: 6| Step: 4
Training loss: 0.4420274060521442
Validation loss: 2.4601147983812814

Epoch: 6| Step: 5
Training loss: 0.5445188173382581
Validation loss: 2.464727164925164

Epoch: 6| Step: 6
Training loss: 0.37174697403231
Validation loss: 2.4638239009814327

Epoch: 6| Step: 7
Training loss: 0.25763188884858845
Validation loss: 2.532579310700742

Epoch: 6| Step: 8
Training loss: 0.29989008976289283
Validation loss: 2.606550568890947

Epoch: 6| Step: 9
Training loss: 0.30608351327662514
Validation loss: 2.61244829349148

Epoch: 6| Step: 10
Training loss: 0.13776420330859906
Validation loss: 2.588618912535376

Epoch: 6| Step: 11
Training loss: 0.2972602352500877
Validation loss: 2.5429067896345803

Epoch: 6| Step: 12
Training loss: 0.15832310118573392
Validation loss: 2.569832174548016

Epoch: 6| Step: 13
Training loss: 0.23129937443860962
Validation loss: 2.517474609992219

Epoch: 316| Step: 0
Training loss: 0.43864668708427695
Validation loss: 2.541943263901966

Epoch: 6| Step: 1
Training loss: 0.3427556894603671
Validation loss: 2.597234978025863

Epoch: 6| Step: 2
Training loss: 0.3199075837721898
Validation loss: 2.6078123557258586

Epoch: 6| Step: 3
Training loss: 0.36847485444340183
Validation loss: 2.656318190759195

Epoch: 6| Step: 4
Training loss: 0.4172744510347854
Validation loss: 2.6362274458422617

Epoch: 6| Step: 5
Training loss: 0.3861291803199766
Validation loss: 2.6544738409677446

Epoch: 6| Step: 6
Training loss: 0.3965590646232742
Validation loss: 2.6304914520501397

Epoch: 6| Step: 7
Training loss: 0.24435776781463084
Validation loss: 2.5562402124049797

Epoch: 6| Step: 8
Training loss: 0.32080642486206606
Validation loss: 2.5366789210699983

Epoch: 6| Step: 9
Training loss: 0.5390566397085781
Validation loss: 2.519870179128988

Epoch: 6| Step: 10
Training loss: 0.30968508112219695
Validation loss: 2.466968875706714

Epoch: 6| Step: 11
Training loss: 0.2167654787991276
Validation loss: 2.523002676196611

Epoch: 6| Step: 12
Training loss: 0.13330720879006372
Validation loss: 2.543384299096279

Epoch: 6| Step: 13
Training loss: 0.24035040836686403
Validation loss: 2.530511396625597

Epoch: 317| Step: 0
Training loss: 0.40713898885772737
Validation loss: 2.5382238858755946

Epoch: 6| Step: 1
Training loss: 0.48070735744161125
Validation loss: 2.5238837015230255

Epoch: 6| Step: 2
Training loss: 0.28856262596843135
Validation loss: 2.533566832413896

Epoch: 6| Step: 3
Training loss: 0.12740312198563217
Validation loss: 2.557794646309566

Epoch: 6| Step: 4
Training loss: 0.23619198621702173
Validation loss: 2.540681668971557

Epoch: 6| Step: 5
Training loss: 0.2611900797486272
Validation loss: 2.5387761749551534

Epoch: 6| Step: 6
Training loss: 0.20126926509093668
Validation loss: 2.5135460392049316

Epoch: 6| Step: 7
Training loss: 0.3593485449300117
Validation loss: 2.5295126100125342

Epoch: 6| Step: 8
Training loss: 0.29939124710339304
Validation loss: 2.5248218268219906

Epoch: 6| Step: 9
Training loss: 0.25233531028404815
Validation loss: 2.4782439796975764

Epoch: 6| Step: 10
Training loss: 0.32863413955672643
Validation loss: 2.5027580224607244

Epoch: 6| Step: 11
Training loss: 0.3354289175051164
Validation loss: 2.509874251488645

Epoch: 6| Step: 12
Training loss: 0.37514495035017
Validation loss: 2.524373444680093

Epoch: 6| Step: 13
Training loss: 0.4929210706284596
Validation loss: 2.518095812337843

Epoch: 318| Step: 0
Training loss: 0.3415506184248588
Validation loss: 2.573269757095901

Epoch: 6| Step: 1
Training loss: 0.26965391436157826
Validation loss: 2.5395727177880034

Epoch: 6| Step: 2
Training loss: 0.43779649224651407
Validation loss: 2.60149924884298

Epoch: 6| Step: 3
Training loss: 0.20718953541580093
Validation loss: 2.6176778981305673

Epoch: 6| Step: 4
Training loss: 0.27600858898032565
Validation loss: 2.6040130025175685

Epoch: 6| Step: 5
Training loss: 0.37295115576014065
Validation loss: 2.6034081582898883

Epoch: 6| Step: 6
Training loss: 0.4405052137217881
Validation loss: 2.5995792366736903

Epoch: 6| Step: 7
Training loss: 0.2568205186980382
Validation loss: 2.4981147179438192

Epoch: 6| Step: 8
Training loss: 0.280103026896454
Validation loss: 2.505474368524474

Epoch: 6| Step: 9
Training loss: 0.2186047974685874
Validation loss: 2.4944220180919197

Epoch: 6| Step: 10
Training loss: 0.3171826714585067
Validation loss: 2.494435294522835

Epoch: 6| Step: 11
Training loss: 0.2626336177717469
Validation loss: 2.5030016844882925

Epoch: 6| Step: 12
Training loss: 0.47667717726441244
Validation loss: 2.5562378776642554

Epoch: 6| Step: 13
Training loss: 0.304024463991493
Validation loss: 2.6299446869723906

Epoch: 319| Step: 0
Training loss: 0.42596763940811483
Validation loss: 2.6862559070582432

Epoch: 6| Step: 1
Training loss: 0.5004128599326471
Validation loss: 2.7333321847345484

Epoch: 6| Step: 2
Training loss: 0.3661489205300352
Validation loss: 2.619647016176823

Epoch: 6| Step: 3
Training loss: 0.27657633709102014
Validation loss: 2.5328000152790935

Epoch: 6| Step: 4
Training loss: 0.34975248210277093
Validation loss: 2.460164415038428

Epoch: 6| Step: 5
Training loss: 0.4335374881568073
Validation loss: 2.4395939814797023

Epoch: 6| Step: 6
Training loss: 0.36073194240361717
Validation loss: 2.4531718909884055

Epoch: 6| Step: 7
Training loss: 0.2922336256369142
Validation loss: 2.47085931652201

Epoch: 6| Step: 8
Training loss: 0.20809239024645934
Validation loss: 2.5813363150185995

Epoch: 6| Step: 9
Training loss: 0.34294954215727036
Validation loss: 2.6161193313493123

Epoch: 6| Step: 10
Training loss: 0.4474453793921732
Validation loss: 2.6905245977986576

Epoch: 6| Step: 11
Training loss: 0.4293267556396442
Validation loss: 2.6874451857039996

Epoch: 6| Step: 12
Training loss: 0.3604561051894512
Validation loss: 2.640065898467445

Epoch: 6| Step: 13
Training loss: 0.29516322637080966
Validation loss: 2.6503961940452996

Epoch: 320| Step: 0
Training loss: 0.26397393902835375
Validation loss: 2.5616570663755294

Epoch: 6| Step: 1
Training loss: 0.30887894791010184
Validation loss: 2.48678778902216

Epoch: 6| Step: 2
Training loss: 0.30678632639873527
Validation loss: 2.483262143873441

Epoch: 6| Step: 3
Training loss: 0.38152595288754027
Validation loss: 2.465234418718136

Epoch: 6| Step: 4
Training loss: 0.383856866879673
Validation loss: 2.500999383726612

Epoch: 6| Step: 5
Training loss: 0.37160208168021586
Validation loss: 2.505706224606709

Epoch: 6| Step: 6
Training loss: 0.2892842602020467
Validation loss: 2.6049104090364046

Epoch: 6| Step: 7
Training loss: 0.2837717070657914
Validation loss: 2.605989776043271

Epoch: 6| Step: 8
Training loss: 0.5394183656624594
Validation loss: 2.598708241824703

Epoch: 6| Step: 9
Training loss: 0.3254606979773241
Validation loss: 2.6282990571171014

Epoch: 6| Step: 10
Training loss: 0.5071513052933255
Validation loss: 2.5903425709935832

Epoch: 6| Step: 11
Training loss: 0.26845946964781475
Validation loss: 2.5382364736438334

Epoch: 6| Step: 12
Training loss: 0.22321961055943806
Validation loss: 2.553274223788636

Epoch: 6| Step: 13
Training loss: 0.2527758745557332
Validation loss: 2.518129359099437

Epoch: 321| Step: 0
Training loss: 0.19035561906205448
Validation loss: 2.465827598500095

Epoch: 6| Step: 1
Training loss: 0.39142321094913707
Validation loss: 2.5065301358624965

Epoch: 6| Step: 2
Training loss: 0.2543697674609108
Validation loss: 2.498827916642413

Epoch: 6| Step: 3
Training loss: 0.32487375668518587
Validation loss: 2.527133289592024

Epoch: 6| Step: 4
Training loss: 0.33495505413972054
Validation loss: 2.5658674756068156

Epoch: 6| Step: 5
Training loss: 0.32131361939985237
Validation loss: 2.6068066468960103

Epoch: 6| Step: 6
Training loss: 0.2462926772092097
Validation loss: 2.5905621381603483

Epoch: 6| Step: 7
Training loss: 0.2943583023697282
Validation loss: 2.639334340720395

Epoch: 6| Step: 8
Training loss: 0.29445694914591836
Validation loss: 2.6025525581927123

Epoch: 6| Step: 9
Training loss: 0.36653090676620015
Validation loss: 2.517800767690522

Epoch: 6| Step: 10
Training loss: 0.293508744086808
Validation loss: 2.508598938564401

Epoch: 6| Step: 11
Training loss: 0.4585611867959949
Validation loss: 2.455239364959258

Epoch: 6| Step: 12
Training loss: 0.4398331418968749
Validation loss: 2.4124322320532308

Epoch: 6| Step: 13
Training loss: 0.3538686349175738
Validation loss: 2.4247424428362914

Epoch: 322| Step: 0
Training loss: 0.3861423396708929
Validation loss: 2.4647122291100487

Epoch: 6| Step: 1
Training loss: 0.2987524697269522
Validation loss: 2.488136212452414

Epoch: 6| Step: 2
Training loss: 0.3596619621311812
Validation loss: 2.5516658345195644

Epoch: 6| Step: 3
Training loss: 0.36586181274879187
Validation loss: 2.643395491529238

Epoch: 6| Step: 4
Training loss: 0.2933649054969803
Validation loss: 2.6481652874505928

Epoch: 6| Step: 5
Training loss: 0.43412324003922254
Validation loss: 2.630243220545153

Epoch: 6| Step: 6
Training loss: 0.28833122802298355
Validation loss: 2.5368482412121938

Epoch: 6| Step: 7
Training loss: 0.17740303636630098
Validation loss: 2.4969887841484426

Epoch: 6| Step: 8
Training loss: 0.27118630821702894
Validation loss: 2.4447914283099004

Epoch: 6| Step: 9
Training loss: 0.2237618336531832
Validation loss: 2.4214658139450256

Epoch: 6| Step: 10
Training loss: 0.18850381683790798
Validation loss: 2.4017436523485465

Epoch: 6| Step: 11
Training loss: 0.2569953800669337
Validation loss: 2.436650568071424

Epoch: 6| Step: 12
Training loss: 0.6236298085232052
Validation loss: 2.4516568906036516

Epoch: 6| Step: 13
Training loss: 0.2901114556488657
Validation loss: 2.4958851451865574

Epoch: 323| Step: 0
Training loss: 0.22015731973706296
Validation loss: 2.5224395732373415

Epoch: 6| Step: 1
Training loss: 0.38396314017022065
Validation loss: 2.5584639752355254

Epoch: 6| Step: 2
Training loss: 0.5431685045946101
Validation loss: 2.5928198061546914

Epoch: 6| Step: 3
Training loss: 0.21326333414362594
Validation loss: 2.620503960776783

Epoch: 6| Step: 4
Training loss: 0.3643154681600695
Validation loss: 2.5916082803811067

Epoch: 6| Step: 5
Training loss: 0.20063783072801505
Validation loss: 2.5925397346100074

Epoch: 6| Step: 6
Training loss: 0.2521048983237629
Validation loss: 2.551958827350391

Epoch: 6| Step: 7
Training loss: 0.40209658910546975
Validation loss: 2.4915983702343887

Epoch: 6| Step: 8
Training loss: 0.388167950776841
Validation loss: 2.4880596277329716

Epoch: 6| Step: 9
Training loss: 0.34912416683525105
Validation loss: 2.5149323800309555

Epoch: 6| Step: 10
Training loss: 0.4432822845253287
Validation loss: 2.5132737052215393

Epoch: 6| Step: 11
Training loss: 0.297336282741579
Validation loss: 2.523043533019502

Epoch: 6| Step: 12
Training loss: 0.25023897491333685
Validation loss: 2.5441927590812425

Epoch: 6| Step: 13
Training loss: 0.13634286024803105
Validation loss: 2.5177199116471503

Epoch: 324| Step: 0
Training loss: 0.4470831652952354
Validation loss: 2.541304169264196

Epoch: 6| Step: 1
Training loss: 0.2181995141058039
Validation loss: 2.5409208710123763

Epoch: 6| Step: 2
Training loss: 0.1579084064808981
Validation loss: 2.526402220108987

Epoch: 6| Step: 3
Training loss: 0.21067799393905423
Validation loss: 2.5593648280146777

Epoch: 6| Step: 4
Training loss: 0.35751645863933773
Validation loss: 2.5366408221014454

Epoch: 6| Step: 5
Training loss: 0.3004267944863262
Validation loss: 2.5045997696229287

Epoch: 6| Step: 6
Training loss: 0.3591646117655363
Validation loss: 2.5033268947053444

Epoch: 6| Step: 7
Training loss: 0.20183120936102528
Validation loss: 2.5043730297572386

Epoch: 6| Step: 8
Training loss: 0.44785172154273606
Validation loss: 2.4539904860251514

Epoch: 6| Step: 9
Training loss: 0.2626340433022611
Validation loss: 2.445911152688214

Epoch: 6| Step: 10
Training loss: 0.29625050212720977
Validation loss: 2.446507442627763

Epoch: 6| Step: 11
Training loss: 0.43487164626181124
Validation loss: 2.4675708206472455

Epoch: 6| Step: 12
Training loss: 0.2970534089726113
Validation loss: 2.468522301865738

Epoch: 6| Step: 13
Training loss: 0.15342798522070156
Validation loss: 2.4910820704218137

Epoch: 325| Step: 0
Training loss: 0.26178464487002717
Validation loss: 2.543168923279911

Epoch: 6| Step: 1
Training loss: 0.41099404645816956
Validation loss: 2.551127714978884

Epoch: 6| Step: 2
Training loss: 0.4358180617373237
Validation loss: 2.596326178986151

Epoch: 6| Step: 3
Training loss: 0.38994084527032413
Validation loss: 2.5542689681754576

Epoch: 6| Step: 4
Training loss: 0.18765260526117605
Validation loss: 2.5439103980297357

Epoch: 6| Step: 5
Training loss: 0.3027211709373167
Validation loss: 2.509856280526637

Epoch: 6| Step: 6
Training loss: 0.3283764919890397
Validation loss: 2.517654529162109

Epoch: 6| Step: 7
Training loss: 0.2528487558384422
Validation loss: 2.476078013877576

Epoch: 6| Step: 8
Training loss: 0.19367821732662008
Validation loss: 2.484045458676119

Epoch: 6| Step: 9
Training loss: 0.23734069676598238
Validation loss: 2.479806197265368

Epoch: 6| Step: 10
Training loss: 0.4596856785886611
Validation loss: 2.48292579724601

Epoch: 6| Step: 11
Training loss: 0.22439882942205058
Validation loss: 2.49336523243266

Epoch: 6| Step: 12
Training loss: 0.12912072055424006
Validation loss: 2.473116266865957

Epoch: 6| Step: 13
Training loss: 0.275412930606562
Validation loss: 2.454443716188299

Epoch: 326| Step: 0
Training loss: 0.41925883621521604
Validation loss: 2.4845447994340026

Epoch: 6| Step: 1
Training loss: 0.4255567886433168
Validation loss: 2.496580636260077

Epoch: 6| Step: 2
Training loss: 0.4208937111432085
Validation loss: 2.4965349354046307

Epoch: 6| Step: 3
Training loss: 0.2329435824354193
Validation loss: 2.5180423336955196

Epoch: 6| Step: 4
Training loss: 0.16311406561133537
Validation loss: 2.4777061109920306

Epoch: 6| Step: 5
Training loss: 0.4114429454903788
Validation loss: 2.4622808901651463

Epoch: 6| Step: 6
Training loss: 0.40973460004540163
Validation loss: 2.4726361236300076

Epoch: 6| Step: 7
Training loss: 0.27527836615084367
Validation loss: 2.4894827099280703

Epoch: 6| Step: 8
Training loss: 0.18832230061065394
Validation loss: 2.463855084436464

Epoch: 6| Step: 9
Training loss: 0.24914930565951837
Validation loss: 2.4839976457482256

Epoch: 6| Step: 10
Training loss: 0.20158056762211274
Validation loss: 2.492174494480501

Epoch: 6| Step: 11
Training loss: 0.25867736133136576
Validation loss: 2.5009690836813965

Epoch: 6| Step: 12
Training loss: 0.21453729794639492
Validation loss: 2.5365877051325736

Epoch: 6| Step: 13
Training loss: 0.15104924311763931
Validation loss: 2.5199624549443986

Epoch: 327| Step: 0
Training loss: 0.23463801884593058
Validation loss: 2.533662400734665

Epoch: 6| Step: 1
Training loss: 0.4185741710177767
Validation loss: 2.492667932473814

Epoch: 6| Step: 2
Training loss: 0.3554561738524824
Validation loss: 2.476185361137559

Epoch: 6| Step: 3
Training loss: 0.3372630095231343
Validation loss: 2.4996920467743884

Epoch: 6| Step: 4
Training loss: 0.3188427724654091
Validation loss: 2.522499153070964

Epoch: 6| Step: 5
Training loss: 0.15910147869464739
Validation loss: 2.511865665803105

Epoch: 6| Step: 6
Training loss: 0.3531891806688555
Validation loss: 2.5389702716291804

Epoch: 6| Step: 7
Training loss: 0.3620513688491339
Validation loss: 2.5227039545589385

Epoch: 6| Step: 8
Training loss: 0.13235533795298077
Validation loss: 2.535108074271058

Epoch: 6| Step: 9
Training loss: 0.4359740655528651
Validation loss: 2.558444475786886

Epoch: 6| Step: 10
Training loss: 0.1890861949574518
Validation loss: 2.5673967061815777

Epoch: 6| Step: 11
Training loss: 0.20729983200272536
Validation loss: 2.5346286900456905

Epoch: 6| Step: 12
Training loss: 0.16669428616395643
Validation loss: 2.546410197157809

Epoch: 6| Step: 13
Training loss: 0.22262667576653394
Validation loss: 2.561357460053602

Epoch: 328| Step: 0
Training loss: 0.33840844271780196
Validation loss: 2.5496086158046767

Epoch: 6| Step: 1
Training loss: 0.41218624030926465
Validation loss: 2.569837908194073

Epoch: 6| Step: 2
Training loss: 0.11284620919343477
Validation loss: 2.5112548424208825

Epoch: 6| Step: 3
Training loss: 0.30886179714630063
Validation loss: 2.4614157633051894

Epoch: 6| Step: 4
Training loss: 0.26675986037401833
Validation loss: 2.4865648583100026

Epoch: 6| Step: 5
Training loss: 0.3842101953336759
Validation loss: 2.4723828949734012

Epoch: 6| Step: 6
Training loss: 0.2490472071653985
Validation loss: 2.4580226513816585

Epoch: 6| Step: 7
Training loss: 0.16293418128127699
Validation loss: 2.4742792489801344

Epoch: 6| Step: 8
Training loss: 0.3640739856594514
Validation loss: 2.4752895015206984

Epoch: 6| Step: 9
Training loss: 0.28349715129827185
Validation loss: 2.470955689829515

Epoch: 6| Step: 10
Training loss: 0.2272223531914494
Validation loss: 2.528999411782394

Epoch: 6| Step: 11
Training loss: 0.18465417641989165
Validation loss: 2.5309337345973977

Epoch: 6| Step: 12
Training loss: 0.3773866640886864
Validation loss: 2.5476312556978447

Epoch: 6| Step: 13
Training loss: 0.20649229830472302
Validation loss: 2.525408363601978

Epoch: 329| Step: 0
Training loss: 0.3872368549728821
Validation loss: 2.511530624966589

Epoch: 6| Step: 1
Training loss: 0.2513398980397236
Validation loss: 2.527556698147177

Epoch: 6| Step: 2
Training loss: 0.21138985132530777
Validation loss: 2.525821067143226

Epoch: 6| Step: 3
Training loss: 0.18790346684655626
Validation loss: 2.5297115942334245

Epoch: 6| Step: 4
Training loss: 0.2481495952427269
Validation loss: 2.4919347273230783

Epoch: 6| Step: 5
Training loss: 0.18896401575188024
Validation loss: 2.5003071873118246

Epoch: 6| Step: 6
Training loss: 0.3379285052460382
Validation loss: 2.5115971615636767

Epoch: 6| Step: 7
Training loss: 0.2222333036497617
Validation loss: 2.497568266564407

Epoch: 6| Step: 8
Training loss: 0.1698392360161106
Validation loss: 2.526659356777496

Epoch: 6| Step: 9
Training loss: 0.5684456513980634
Validation loss: 2.4593143702552687

Epoch: 6| Step: 10
Training loss: 0.20509743372526668
Validation loss: 2.463396089722916

Epoch: 6| Step: 11
Training loss: 0.28591466666602167
Validation loss: 2.4607752509345464

Epoch: 6| Step: 12
Training loss: 0.3625748030993878
Validation loss: 2.446486116127498

Epoch: 6| Step: 13
Training loss: 0.18623466506975103
Validation loss: 2.5031291820759574

Epoch: 330| Step: 0
Training loss: 0.18343184819848415
Validation loss: 2.4872275783074267

Epoch: 6| Step: 1
Training loss: 0.15444016141230835
Validation loss: 2.516169895700627

Epoch: 6| Step: 2
Training loss: 0.3181789448572753
Validation loss: 2.4839817787698175

Epoch: 6| Step: 3
Training loss: 0.2498164695365193
Validation loss: 2.4891869190806775

Epoch: 6| Step: 4
Training loss: 0.338040831150151
Validation loss: 2.4581883312806587

Epoch: 6| Step: 5
Training loss: 0.3587414505900168
Validation loss: 2.5259819027920605

Epoch: 6| Step: 6
Training loss: 0.23603351609808781
Validation loss: 2.5396687283545685

Epoch: 6| Step: 7
Training loss: 0.2334154992670785
Validation loss: 2.522912581970491

Epoch: 6| Step: 8
Training loss: 0.2265155102243427
Validation loss: 2.539211950455209

Epoch: 6| Step: 9
Training loss: 0.48996715177670347
Validation loss: 2.4910303922569885

Epoch: 6| Step: 10
Training loss: 0.32176187619904284
Validation loss: 2.494340478208131

Epoch: 6| Step: 11
Training loss: 0.35689960949385535
Validation loss: 2.502682569454843

Epoch: 6| Step: 12
Training loss: 0.4078729380112111
Validation loss: 2.502161573305433

Epoch: 6| Step: 13
Training loss: 0.30767594033734
Validation loss: 2.535541919126063

Epoch: 331| Step: 0
Training loss: 0.34282616538505734
Validation loss: 2.5090512529101674

Epoch: 6| Step: 1
Training loss: 0.3835260786044957
Validation loss: 2.4404525838159468

Epoch: 6| Step: 2
Training loss: 0.3397772493740003
Validation loss: 2.458295404368597

Epoch: 6| Step: 3
Training loss: 0.26162474637900945
Validation loss: 2.501064939203087

Epoch: 6| Step: 4
Training loss: 0.4218043868697278
Validation loss: 2.528370218590817

Epoch: 6| Step: 5
Training loss: 0.17133740316056936
Validation loss: 2.4747902335574437

Epoch: 6| Step: 6
Training loss: 0.2824869637519719
Validation loss: 2.510421994608329

Epoch: 6| Step: 7
Training loss: 0.2539465358759234
Validation loss: 2.5188932859649933

Epoch: 6| Step: 8
Training loss: 0.35413647504285695
Validation loss: 2.55498058379864

Epoch: 6| Step: 9
Training loss: 0.19670207664240072
Validation loss: 2.514638346639765

Epoch: 6| Step: 10
Training loss: 0.26737000383860526
Validation loss: 2.503368266202064

Epoch: 6| Step: 11
Training loss: 0.3164836882972471
Validation loss: 2.5090546885656666

Epoch: 6| Step: 12
Training loss: 0.4526501831554066
Validation loss: 2.4727316508917374

Epoch: 6| Step: 13
Training loss: 0.2402294670161879
Validation loss: 2.5025466622607273

Epoch: 332| Step: 0
Training loss: 0.35925942096555447
Validation loss: 2.5191482607713493

Epoch: 6| Step: 1
Training loss: 0.3137038883200512
Validation loss: 2.559788091019543

Epoch: 6| Step: 2
Training loss: 0.352681540654326
Validation loss: 2.5510504702901438

Epoch: 6| Step: 3
Training loss: 0.2895958336297948
Validation loss: 2.5785105407353424

Epoch: 6| Step: 4
Training loss: 0.3686942979800564
Validation loss: 2.5508519818195747

Epoch: 6| Step: 5
Training loss: 0.19613700404851744
Validation loss: 2.5149718618677137

Epoch: 6| Step: 6
Training loss: 0.34361260008962624
Validation loss: 2.530793713384352

Epoch: 6| Step: 7
Training loss: 0.3979643087509954
Validation loss: 2.543465965070618

Epoch: 6| Step: 8
Training loss: 0.2681997137966734
Validation loss: 2.53711127566943

Epoch: 6| Step: 9
Training loss: 0.14674377362073873
Validation loss: 2.52785127750701

Epoch: 6| Step: 10
Training loss: 0.20763607567235554
Validation loss: 2.5408696389664613

Epoch: 6| Step: 11
Training loss: 0.26667221586344547
Validation loss: 2.5488074494549817

Epoch: 6| Step: 12
Training loss: 0.2505061420222586
Validation loss: 2.554971038536701

Epoch: 6| Step: 13
Training loss: 0.10081507222458692
Validation loss: 2.5381858626189446

Epoch: 333| Step: 0
Training loss: 0.11243126411809
Validation loss: 2.5593084398466655

Epoch: 6| Step: 1
Training loss: 0.157341352461549
Validation loss: 2.5600908511186025

Epoch: 6| Step: 2
Training loss: 0.2595431587017942
Validation loss: 2.552726515552227

Epoch: 6| Step: 3
Training loss: 0.16442465547064736
Validation loss: 2.5755402993848993

Epoch: 6| Step: 4
Training loss: 0.29588723240148457
Validation loss: 2.5694851626431268

Epoch: 6| Step: 5
Training loss: 0.3381527341619867
Validation loss: 2.557145486811539

Epoch: 6| Step: 6
Training loss: 0.26595734393341025
Validation loss: 2.5398746223453483

Epoch: 6| Step: 7
Training loss: 0.4010037821260779
Validation loss: 2.498440658162134

Epoch: 6| Step: 8
Training loss: 0.2149307768297948
Validation loss: 2.4771408586327057

Epoch: 6| Step: 9
Training loss: 0.3056918488081828
Validation loss: 2.471358757248614

Epoch: 6| Step: 10
Training loss: 0.2047625884435309
Validation loss: 2.4290471278482855

Epoch: 6| Step: 11
Training loss: 0.43881331598260054
Validation loss: 2.4682964603061275

Epoch: 6| Step: 12
Training loss: 0.3701940974945871
Validation loss: 2.432091222332695

Epoch: 6| Step: 13
Training loss: 0.2862776692315056
Validation loss: 2.466824416246671

Epoch: 334| Step: 0
Training loss: 0.409732999857444
Validation loss: 2.4739954674378213

Epoch: 6| Step: 1
Training loss: 0.4270574534723897
Validation loss: 2.4994095935767207

Epoch: 6| Step: 2
Training loss: 0.39875263018921525
Validation loss: 2.464000635649353

Epoch: 6| Step: 3
Training loss: 0.14101253860139348
Validation loss: 2.5019001097748856

Epoch: 6| Step: 4
Training loss: 0.2821443959516672
Validation loss: 2.5417818277542543

Epoch: 6| Step: 5
Training loss: 0.3472831095186853
Validation loss: 2.5251945845431814

Epoch: 6| Step: 6
Training loss: 0.23567636324665364
Validation loss: 2.4562958696233186

Epoch: 6| Step: 7
Training loss: 0.24012479376300017
Validation loss: 2.4441226172964363

Epoch: 6| Step: 8
Training loss: 0.1597414693315793
Validation loss: 2.4537002843056177

Epoch: 6| Step: 9
Training loss: 0.2864878148022471
Validation loss: 2.47304198689999

Epoch: 6| Step: 10
Training loss: 0.33956446078384006
Validation loss: 2.504333571230394

Epoch: 6| Step: 11
Training loss: 0.27081493474137447
Validation loss: 2.522305679899584

Epoch: 6| Step: 12
Training loss: 0.23406921147909124
Validation loss: 2.509483952670783

Epoch: 6| Step: 13
Training loss: 0.1658151931331898
Validation loss: 2.5691295057908423

Epoch: 335| Step: 0
Training loss: 0.22333879591508798
Validation loss: 2.584636286873347

Epoch: 6| Step: 1
Training loss: 0.3203602848230766
Validation loss: 2.585317509303111

Epoch: 6| Step: 2
Training loss: 0.39886546992241373
Validation loss: 2.5947732168589077

Epoch: 6| Step: 3
Training loss: 0.4629792076369106
Validation loss: 2.5692775919546573

Epoch: 6| Step: 4
Training loss: 0.3288676168989719
Validation loss: 2.541796685142291

Epoch: 6| Step: 5
Training loss: 0.25750948698659565
Validation loss: 2.5507050446162984

Epoch: 6| Step: 6
Training loss: 0.19967984152004042
Validation loss: 2.4885050164511826

Epoch: 6| Step: 7
Training loss: 0.34661183297632625
Validation loss: 2.5009080837320448

Epoch: 6| Step: 8
Training loss: 0.2541316865603312
Validation loss: 2.516726017548014

Epoch: 6| Step: 9
Training loss: 0.1801300404284845
Validation loss: 2.4981904156375276

Epoch: 6| Step: 10
Training loss: 0.30608901444219094
Validation loss: 2.520783609909894

Epoch: 6| Step: 11
Training loss: 0.3375614083902288
Validation loss: 2.5812878272497217

Epoch: 6| Step: 12
Training loss: 0.2617462343047081
Validation loss: 2.5609197238349544

Epoch: 6| Step: 13
Training loss: 0.223470704072398
Validation loss: 2.5679619537049643

Epoch: 336| Step: 0
Training loss: 0.23027106066278738
Validation loss: 2.6080521911253363

Epoch: 6| Step: 1
Training loss: 0.2786714313312118
Validation loss: 2.558524434605872

Epoch: 6| Step: 2
Training loss: 0.3930750875521327
Validation loss: 2.5889356667409054

Epoch: 6| Step: 3
Training loss: 0.2406863403782711
Validation loss: 2.5139541146900215

Epoch: 6| Step: 4
Training loss: 0.3195967119869867
Validation loss: 2.4635239897319696

Epoch: 6| Step: 5
Training loss: 0.3551759037566164
Validation loss: 2.450599201435657

Epoch: 6| Step: 6
Training loss: 0.43711718773017316
Validation loss: 2.461423583106949

Epoch: 6| Step: 7
Training loss: 0.30208791806041374
Validation loss: 2.424706350867341

Epoch: 6| Step: 8
Training loss: 0.2006401887533488
Validation loss: 2.4433894887021492

Epoch: 6| Step: 9
Training loss: 0.13952434468242758
Validation loss: 2.463798959239909

Epoch: 6| Step: 10
Training loss: 0.12706593123351906
Validation loss: 2.4912779509326692

Epoch: 6| Step: 11
Training loss: 0.23181313046605945
Validation loss: 2.5447295212876884

Epoch: 6| Step: 12
Training loss: 0.29248628944884325
Validation loss: 2.5315534601444165

Epoch: 6| Step: 13
Training loss: 0.27822151438250126
Validation loss: 2.527388411949858

Epoch: 337| Step: 0
Training loss: 0.2351679263590358
Validation loss: 2.506859183474827

Epoch: 6| Step: 1
Training loss: 0.1439544729167404
Validation loss: 2.480099832199727

Epoch: 6| Step: 2
Training loss: 0.3193184734083675
Validation loss: 2.50183564084989

Epoch: 6| Step: 3
Training loss: 0.1549029278290246
Validation loss: 2.4874850342299784

Epoch: 6| Step: 4
Training loss: 0.32290565051495046
Validation loss: 2.462732628952444

Epoch: 6| Step: 5
Training loss: 0.30080921488968776
Validation loss: 2.4933141223766637

Epoch: 6| Step: 6
Training loss: 0.259579599069419
Validation loss: 2.482640266566276

Epoch: 6| Step: 7
Training loss: 0.1624882647971971
Validation loss: 2.480243186135405

Epoch: 6| Step: 8
Training loss: 0.443007325203354
Validation loss: 2.4746863821833847

Epoch: 6| Step: 9
Training loss: 0.2983547775102124
Validation loss: 2.4477920161871154

Epoch: 6| Step: 10
Training loss: 0.3868605228605643
Validation loss: 2.500868105652587

Epoch: 6| Step: 11
Training loss: 0.18835389884415213
Validation loss: 2.462526202443731

Epoch: 6| Step: 12
Training loss: 0.25607951354510905
Validation loss: 2.4506480227006726

Epoch: 6| Step: 13
Training loss: 0.2098812129337622
Validation loss: 2.475762421202852

Epoch: 338| Step: 0
Training loss: 0.0832631811138377
Validation loss: 2.5330502615300525

Epoch: 6| Step: 1
Training loss: 0.20777200935390752
Validation loss: 2.513681616863344

Epoch: 6| Step: 2
Training loss: 0.29943071332743804
Validation loss: 2.5444040668616794

Epoch: 6| Step: 3
Training loss: 0.268471278329124
Validation loss: 2.5689736447584237

Epoch: 6| Step: 4
Training loss: 0.5157689847184085
Validation loss: 2.5159083778557054

Epoch: 6| Step: 5
Training loss: 0.12200298741564135
Validation loss: 2.525936256867508

Epoch: 6| Step: 6
Training loss: 0.28590467295835587
Validation loss: 2.5563859449467783

Epoch: 6| Step: 7
Training loss: 0.21666125617852375
Validation loss: 2.5394836296143275

Epoch: 6| Step: 8
Training loss: 0.3371546784478429
Validation loss: 2.5243229568628758

Epoch: 6| Step: 9
Training loss: 0.30243807412991913
Validation loss: 2.50908551014439

Epoch: 6| Step: 10
Training loss: 0.2680754668714376
Validation loss: 2.5416043672503075

Epoch: 6| Step: 11
Training loss: 0.21298152837669337
Validation loss: 2.524919956834761

Epoch: 6| Step: 12
Training loss: 0.1925261781436521
Validation loss: 2.4845948290049016

Epoch: 6| Step: 13
Training loss: 0.14443314289799003
Validation loss: 2.4692447052982254

Epoch: 339| Step: 0
Training loss: 0.26630397578601017
Validation loss: 2.4578776838472214

Epoch: 6| Step: 1
Training loss: 0.21556747090632433
Validation loss: 2.441543979229998

Epoch: 6| Step: 2
Training loss: 0.17611598356808708
Validation loss: 2.4582666152012473

Epoch: 6| Step: 3
Training loss: 0.34300596821641804
Validation loss: 2.4581000598195537

Epoch: 6| Step: 4
Training loss: 0.503407727053161
Validation loss: 2.4913795023661227

Epoch: 6| Step: 5
Training loss: 0.3205591973045177
Validation loss: 2.5326063147421696

Epoch: 6| Step: 6
Training loss: 0.20435706030710687
Validation loss: 2.573957136124706

Epoch: 6| Step: 7
Training loss: 0.17257779742616067
Validation loss: 2.584186983198861

Epoch: 6| Step: 8
Training loss: 0.305174218746
Validation loss: 2.629603991814469

Epoch: 6| Step: 9
Training loss: 0.32996971562169575
Validation loss: 2.5649019754536324

Epoch: 6| Step: 10
Training loss: 0.14325683210967052
Validation loss: 2.5393008545724447

Epoch: 6| Step: 11
Training loss: 0.28900917953297006
Validation loss: 2.4747340953089623

Epoch: 6| Step: 12
Training loss: 0.3179579702513634
Validation loss: 2.438923661111988

Epoch: 6| Step: 13
Training loss: 0.23911947026566654
Validation loss: 2.4912250455513276

Epoch: 340| Step: 0
Training loss: 0.21972560458504303
Validation loss: 2.5079930944250695

Epoch: 6| Step: 1
Training loss: 0.23247039512865464
Validation loss: 2.5626083359126177

Epoch: 6| Step: 2
Training loss: 0.2669408686109818
Validation loss: 2.600110032716865

Epoch: 6| Step: 3
Training loss: 0.24703072242029012
Validation loss: 2.620117809790964

Epoch: 6| Step: 4
Training loss: 0.4113170908492167
Validation loss: 2.6201309174938845

Epoch: 6| Step: 5
Training loss: 0.14959634619572332
Validation loss: 2.6456609612797575

Epoch: 6| Step: 6
Training loss: 0.1996532078521814
Validation loss: 2.636201960311794

Epoch: 6| Step: 7
Training loss: 0.25974150237317983
Validation loss: 2.5906580843077665

Epoch: 6| Step: 8
Training loss: 0.24534357870249246
Validation loss: 2.549654343687215

Epoch: 6| Step: 9
Training loss: 0.21184089381915808
Validation loss: 2.554830433188459

Epoch: 6| Step: 10
Training loss: 0.40773234986509305
Validation loss: 2.49810834709894

Epoch: 6| Step: 11
Training loss: 0.2629567656843298
Validation loss: 2.479103001388646

Epoch: 6| Step: 12
Training loss: 0.4477011712987922
Validation loss: 2.4434877908154715

Epoch: 6| Step: 13
Training loss: 0.0662331709764694
Validation loss: 2.4763602347599902

Epoch: 341| Step: 0
Training loss: 0.29199744382484083
Validation loss: 2.49750645269865

Epoch: 6| Step: 1
Training loss: 0.31798278440203515
Validation loss: 2.511794872594758

Epoch: 6| Step: 2
Training loss: 0.18737291956860594
Validation loss: 2.529540589329705

Epoch: 6| Step: 3
Training loss: 0.48400377076134277
Validation loss: 2.496356255051849

Epoch: 6| Step: 4
Training loss: 0.2184113964288279
Validation loss: 2.5570286461255645

Epoch: 6| Step: 5
Training loss: 0.1435505159252021
Validation loss: 2.5399852767697193

Epoch: 6| Step: 6
Training loss: 0.15800030387512695
Validation loss: 2.5577554365979864

Epoch: 6| Step: 7
Training loss: 0.2923110318288744
Validation loss: 2.567866994012011

Epoch: 6| Step: 8
Training loss: 0.16611721072295246
Validation loss: 2.5420918612489545

Epoch: 6| Step: 9
Training loss: 0.20308993110171336
Validation loss: 2.5426300626261127

Epoch: 6| Step: 10
Training loss: 0.155285540894758
Validation loss: 2.573255815423389

Epoch: 6| Step: 11
Training loss: 0.2953464533950837
Validation loss: 2.551716666452279

Epoch: 6| Step: 12
Training loss: 0.10619777367076941
Validation loss: 2.5275633152765278

Epoch: 6| Step: 13
Training loss: 0.47498629951796173
Validation loss: 2.508733497020606

Epoch: 342| Step: 0
Training loss: 0.1253853906745162
Validation loss: 2.552329546813188

Epoch: 6| Step: 1
Training loss: 0.36543374561399183
Validation loss: 2.5322754359140958

Epoch: 6| Step: 2
Training loss: 0.3224842370417091
Validation loss: 2.5278553037111258

Epoch: 6| Step: 3
Training loss: 0.16571159573153102
Validation loss: 2.536798675728309

Epoch: 6| Step: 4
Training loss: 0.19650484437285384
Validation loss: 2.535526396948651

Epoch: 6| Step: 5
Training loss: 0.3661837555016251
Validation loss: 2.581550283161799

Epoch: 6| Step: 6
Training loss: 0.33262353690555657
Validation loss: 2.5724834598719992

Epoch: 6| Step: 7
Training loss: 0.36222834438254703
Validation loss: 2.5407595149478737

Epoch: 6| Step: 8
Training loss: 0.21260422506772375
Validation loss: 2.554372649095769

Epoch: 6| Step: 9
Training loss: 0.14937322968666925
Validation loss: 2.5279581096973804

Epoch: 6| Step: 10
Training loss: 0.19682462895592304
Validation loss: 2.5100049890709566

Epoch: 6| Step: 11
Training loss: 0.26996374674966334
Validation loss: 2.5416787787891373

Epoch: 6| Step: 12
Training loss: 0.233746456703319
Validation loss: 2.5500452656099246

Epoch: 6| Step: 13
Training loss: 0.2268484957769153
Validation loss: 2.5263947440031727

Epoch: 343| Step: 0
Training loss: 0.24704498040527928
Validation loss: 2.5680958804574274

Epoch: 6| Step: 1
Training loss: 0.3765162965912842
Validation loss: 2.566764568410864

Epoch: 6| Step: 2
Training loss: 0.21241722493274798
Validation loss: 2.5433940682677445

Epoch: 6| Step: 3
Training loss: 0.29158947837201943
Validation loss: 2.5193479709939455

Epoch: 6| Step: 4
Training loss: 0.33164706723771065
Validation loss: 2.4917132437850884

Epoch: 6| Step: 5
Training loss: 0.38987713749169056
Validation loss: 2.4486376611514094

Epoch: 6| Step: 6
Training loss: 0.13931135028588887
Validation loss: 2.470275029884168

Epoch: 6| Step: 7
Training loss: 0.32799049299915606
Validation loss: 2.4490685678341118

Epoch: 6| Step: 8
Training loss: 0.11645759723745747
Validation loss: 2.4948847347409164

Epoch: 6| Step: 9
Training loss: 0.1542811687539582
Validation loss: 2.4712165794133734

Epoch: 6| Step: 10
Training loss: 0.2629521472243361
Validation loss: 2.535213958545045

Epoch: 6| Step: 11
Training loss: 0.22467986949437224
Validation loss: 2.4944223243612105

Epoch: 6| Step: 12
Training loss: 0.27303954184184825
Validation loss: 2.5563186556457924

Epoch: 6| Step: 13
Training loss: 0.18252168289802242
Validation loss: 2.537124189270916

Epoch: 344| Step: 0
Training loss: 0.26440497316395506
Validation loss: 2.571839934828848

Epoch: 6| Step: 1
Training loss: 0.3101933104043703
Validation loss: 2.5398745920646335

Epoch: 6| Step: 2
Training loss: 0.2517862728536878
Validation loss: 2.5385871870165526

Epoch: 6| Step: 3
Training loss: 0.2581936879244123
Validation loss: 2.5514168735307465

Epoch: 6| Step: 4
Training loss: 0.39123742732361777
Validation loss: 2.513307878381625

Epoch: 6| Step: 5
Training loss: 0.2648039638826213
Validation loss: 2.484626231560743

Epoch: 6| Step: 6
Training loss: 0.2812460793115938
Validation loss: 2.489442722919942

Epoch: 6| Step: 7
Training loss: 0.1828142113075691
Validation loss: 2.495709650972599

Epoch: 6| Step: 8
Training loss: 0.13112681375418261
Validation loss: 2.5393478992939613

Epoch: 6| Step: 9
Training loss: 0.2660025549995359
Validation loss: 2.5979469025066786

Epoch: 6| Step: 10
Training loss: 0.17886786528019682
Validation loss: 2.603989560083254

Epoch: 6| Step: 11
Training loss: 0.2692089641827177
Validation loss: 2.6501363961410602

Epoch: 6| Step: 12
Training loss: 0.19549734905035868
Validation loss: 2.6259457534490247

Epoch: 6| Step: 13
Training loss: 0.4308123517076997
Validation loss: 2.588059569354828

Epoch: 345| Step: 0
Training loss: 0.33211778747198584
Validation loss: 2.5519156432083694

Epoch: 6| Step: 1
Training loss: 0.15977217980254896
Validation loss: 2.513039295133607

Epoch: 6| Step: 2
Training loss: 0.34813436570915424
Validation loss: 2.4713696368522826

Epoch: 6| Step: 3
Training loss: 0.24044577283685353
Validation loss: 2.441302163019752

Epoch: 6| Step: 4
Training loss: 0.17575151933804203
Validation loss: 2.414058428437443

Epoch: 6| Step: 5
Training loss: 0.17453584296143337
Validation loss: 2.476268235965241

Epoch: 6| Step: 6
Training loss: 0.332383384224403
Validation loss: 2.527791496241733

Epoch: 6| Step: 7
Training loss: 0.4028375058813595
Validation loss: 2.5233769619242135

Epoch: 6| Step: 8
Training loss: 0.24151087657157166
Validation loss: 2.535607184636217

Epoch: 6| Step: 9
Training loss: 0.2572543575994733
Validation loss: 2.565515612097053

Epoch: 6| Step: 10
Training loss: 0.3302151999175796
Validation loss: 2.5999970287782466

Epoch: 6| Step: 11
Training loss: 0.16683273064048443
Validation loss: 2.5933476771197808

Epoch: 6| Step: 12
Training loss: 0.18044339699617662
Validation loss: 2.6178850317323588

Epoch: 6| Step: 13
Training loss: 0.09835126558586729
Validation loss: 2.582440476696426

Epoch: 346| Step: 0
Training loss: 0.25254888847335305
Validation loss: 2.5881379545298424

Epoch: 6| Step: 1
Training loss: 0.32654264928178206
Validation loss: 2.6143755609405437

Epoch: 6| Step: 2
Training loss: 0.1463139305317757
Validation loss: 2.59663042786288

Epoch: 6| Step: 3
Training loss: 0.32134450416732413
Validation loss: 2.5826247815164094

Epoch: 6| Step: 4
Training loss: 0.25588907549914736
Validation loss: 2.5355446530901475

Epoch: 6| Step: 5
Training loss: 0.23948534831154594
Validation loss: 2.487864254307711

Epoch: 6| Step: 6
Training loss: 0.20963461601309774
Validation loss: 2.5037331856539646

Epoch: 6| Step: 7
Training loss: 0.16891003940576735
Validation loss: 2.514929709286372

Epoch: 6| Step: 8
Training loss: 0.195181659742422
Validation loss: 2.4804178873650815

Epoch: 6| Step: 9
Training loss: 0.30536900621169716
Validation loss: 2.52361943769982

Epoch: 6| Step: 10
Training loss: 0.20332668452030012
Validation loss: 2.49873757533553

Epoch: 6| Step: 11
Training loss: 0.2614592646522704
Validation loss: 2.4811268238487583

Epoch: 6| Step: 12
Training loss: 0.2949442570763726
Validation loss: 2.5189849085645477

Epoch: 6| Step: 13
Training loss: 0.19326007104048853
Validation loss: 2.531828688194378

Epoch: 347| Step: 0
Training loss: 0.2513808767626709
Validation loss: 2.5326903364961724

Epoch: 6| Step: 1
Training loss: 0.18693321711851327
Validation loss: 2.542712665273597

Epoch: 6| Step: 2
Training loss: 0.2223188621440711
Validation loss: 2.523061467461624

Epoch: 6| Step: 3
Training loss: 0.20735040392400542
Validation loss: 2.5424092171525823

Epoch: 6| Step: 4
Training loss: 0.18321907079799674
Validation loss: 2.5216760436153325

Epoch: 6| Step: 5
Training loss: 0.2114445896020044
Validation loss: 2.5379765346237524

Epoch: 6| Step: 6
Training loss: 0.3336183315573983
Validation loss: 2.5543208272273454

Epoch: 6| Step: 7
Training loss: 0.3195500836966018
Validation loss: 2.5845804892364685

Epoch: 6| Step: 8
Training loss: 0.24594827924030666
Validation loss: 2.547321804062868

Epoch: 6| Step: 9
Training loss: 0.2765760677048426
Validation loss: 2.533366374020007

Epoch: 6| Step: 10
Training loss: 0.305551831296178
Validation loss: 2.5231491381784052

Epoch: 6| Step: 11
Training loss: 0.19068122292611292
Validation loss: 2.548787604555886

Epoch: 6| Step: 12
Training loss: 0.3181937553361853
Validation loss: 2.547083501071601

Epoch: 6| Step: 13
Training loss: 0.10295235585104727
Validation loss: 2.580732240508762

Epoch: 348| Step: 0
Training loss: 0.41150204711998156
Validation loss: 2.5631203899630197

Epoch: 6| Step: 1
Training loss: 0.28772024446747513
Validation loss: 2.5551586290580044

Epoch: 6| Step: 2
Training loss: 0.2017008207022434
Validation loss: 2.5390125572019335

Epoch: 6| Step: 3
Training loss: 0.24448565707038483
Validation loss: 2.511560512299212

Epoch: 6| Step: 4
Training loss: 0.15738515378261972
Validation loss: 2.5185767183551135

Epoch: 6| Step: 5
Training loss: 0.20772942194605593
Validation loss: 2.5007000947838454

Epoch: 6| Step: 6
Training loss: 0.14403830051939565
Validation loss: 2.4808382148816865

Epoch: 6| Step: 7
Training loss: 0.2069543839758729
Validation loss: 2.5212966756180886

Epoch: 6| Step: 8
Training loss: 0.31766556102731064
Validation loss: 2.518834976024548

Epoch: 6| Step: 9
Training loss: 0.27543196131203584
Validation loss: 2.5071667389987655

Epoch: 6| Step: 10
Training loss: 0.19530622472218753
Validation loss: 2.520012954842037

Epoch: 6| Step: 11
Training loss: 0.1929602115301911
Validation loss: 2.5010585574227857

Epoch: 6| Step: 12
Training loss: 0.28288219288688043
Validation loss: 2.5000029774104613

Epoch: 6| Step: 13
Training loss: 0.20282060483540626
Validation loss: 2.5076552425987297

Epoch: 349| Step: 0
Training loss: 0.21004184672103193
Validation loss: 2.559165775293855

Epoch: 6| Step: 1
Training loss: 0.2746993784240256
Validation loss: 2.5482182405916065

Epoch: 6| Step: 2
Training loss: 0.2696257163097079
Validation loss: 2.5381384079956555

Epoch: 6| Step: 3
Training loss: 0.1303803444198532
Validation loss: 2.5551695973239106

Epoch: 6| Step: 4
Training loss: 0.161290305648599
Validation loss: 2.545671946014481

Epoch: 6| Step: 5
Training loss: 0.3643507851591271
Validation loss: 2.574827799090283

Epoch: 6| Step: 6
Training loss: 0.1633664134938839
Validation loss: 2.5861018255377592

Epoch: 6| Step: 7
Training loss: 0.22896701702702785
Validation loss: 2.565705508179187

Epoch: 6| Step: 8
Training loss: 0.22476656844942502
Validation loss: 2.5703374439620874

Epoch: 6| Step: 9
Training loss: 0.1498171784963864
Validation loss: 2.559634763519494

Epoch: 6| Step: 10
Training loss: 0.3112433199567824
Validation loss: 2.5593484546538297

Epoch: 6| Step: 11
Training loss: 0.3246057911846026
Validation loss: 2.5820988402414744

Epoch: 6| Step: 12
Training loss: 0.31529355728518893
Validation loss: 2.6116147719199976

Epoch: 6| Step: 13
Training loss: 0.1504540804964262
Validation loss: 2.6060669195383395

Epoch: 350| Step: 0
Training loss: 0.2524470581366441
Validation loss: 2.613666305133783

Epoch: 6| Step: 1
Training loss: 0.34990511272164176
Validation loss: 2.572525980850783

Epoch: 6| Step: 2
Training loss: 0.24616786809461066
Validation loss: 2.5390657350126724

Epoch: 6| Step: 3
Training loss: 0.17780285867789464
Validation loss: 2.534228790311406

Epoch: 6| Step: 4
Training loss: 0.22091445257683504
Validation loss: 2.5370405548527137

Epoch: 6| Step: 5
Training loss: 0.2682025890083858
Validation loss: 2.5176884305547973

Epoch: 6| Step: 6
Training loss: 0.10669121642586946
Validation loss: 2.5074256851918846

Epoch: 6| Step: 7
Training loss: 0.17136817679675076
Validation loss: 2.527716609454844

Epoch: 6| Step: 8
Training loss: 0.36119361642020936
Validation loss: 2.5435347978286376

Epoch: 6| Step: 9
Training loss: 0.20326477523533423
Validation loss: 2.5038121568455445

Epoch: 6| Step: 10
Training loss: 0.09583373790980369
Validation loss: 2.513912918934422

Epoch: 6| Step: 11
Training loss: 0.27934624829078236
Validation loss: 2.5265965484797275

Epoch: 6| Step: 12
Training loss: 0.2735178148301303
Validation loss: 2.5224920429575115

Epoch: 6| Step: 13
Training loss: 0.16031039774782313
Validation loss: 2.600707912780307

Epoch: 351| Step: 0
Training loss: 0.16796246783019242
Validation loss: 2.546507621100936

Epoch: 6| Step: 1
Training loss: 0.2571253867946195
Validation loss: 2.558836702774396

Epoch: 6| Step: 2
Training loss: 0.25920877070702514
Validation loss: 2.5328519798871447

Epoch: 6| Step: 3
Training loss: 0.20672051484500029
Validation loss: 2.5607495235436226

Epoch: 6| Step: 4
Training loss: 0.17171231069457885
Validation loss: 2.5690737615357513

Epoch: 6| Step: 5
Training loss: 0.32498246750858023
Validation loss: 2.5209046352644937

Epoch: 6| Step: 6
Training loss: 0.1817223149849483
Validation loss: 2.5073523459766127

Epoch: 6| Step: 7
Training loss: 0.29700058238457244
Validation loss: 2.5199548869938178

Epoch: 6| Step: 8
Training loss: 0.1302691428922151
Validation loss: 2.525749227335023

Epoch: 6| Step: 9
Training loss: 0.12658720099215237
Validation loss: 2.5576388843864963

Epoch: 6| Step: 10
Training loss: 0.23616667820963655
Validation loss: 2.5609320068420587

Epoch: 6| Step: 11
Training loss: 0.2534475731876283
Validation loss: 2.5722639904985174

Epoch: 6| Step: 12
Training loss: 0.3079455848005714
Validation loss: 2.5403923425505273

Epoch: 6| Step: 13
Training loss: 0.38220411730843684
Validation loss: 2.549772244701193

Epoch: 352| Step: 0
Training loss: 0.28607643275036737
Validation loss: 2.5518063620741693

Epoch: 6| Step: 1
Training loss: 0.37545520254801235
Validation loss: 2.5146150736870876

Epoch: 6| Step: 2
Training loss: 0.20307749412786727
Validation loss: 2.5281309009019055

Epoch: 6| Step: 3
Training loss: 0.3502875947393816
Validation loss: 2.5429869426315146

Epoch: 6| Step: 4
Training loss: 0.23864541601685416
Validation loss: 2.535749392739854

Epoch: 6| Step: 5
Training loss: 0.2369629946979048
Validation loss: 2.510522020086866

Epoch: 6| Step: 6
Training loss: 0.203516335586801
Validation loss: 2.5464666378792176

Epoch: 6| Step: 7
Training loss: 0.24557760395311026
Validation loss: 2.5623179705475647

Epoch: 6| Step: 8
Training loss: 0.12399643881985047
Validation loss: 2.5639540305946706

Epoch: 6| Step: 9
Training loss: 0.15003239708962315
Validation loss: 2.546385787985563

Epoch: 6| Step: 10
Training loss: 0.19221533829575035
Validation loss: 2.557968167124761

Epoch: 6| Step: 11
Training loss: 0.1890781467047782
Validation loss: 2.5803752844577876

Epoch: 6| Step: 12
Training loss: 0.1767211686398022
Validation loss: 2.5829274007145497

Epoch: 6| Step: 13
Training loss: 0.24686844310020473
Validation loss: 2.5653012918864104

Epoch: 353| Step: 0
Training loss: 0.2582800700027456
Validation loss: 2.519036709352477

Epoch: 6| Step: 1
Training loss: 0.23635107512208348
Validation loss: 2.4893865286572354

Epoch: 6| Step: 2
Training loss: 0.12545286042345535
Validation loss: 2.4794415095559965

Epoch: 6| Step: 3
Training loss: 0.18698053124832173
Validation loss: 2.46631819786507

Epoch: 6| Step: 4
Training loss: 0.23622863819285128
Validation loss: 2.5061336475902865

Epoch: 6| Step: 5
Training loss: 0.2540499353996965
Validation loss: 2.505638677248437

Epoch: 6| Step: 6
Training loss: 0.27326702525837815
Validation loss: 2.5157645213649023

Epoch: 6| Step: 7
Training loss: 0.2780600954253203
Validation loss: 2.5419183398359846

Epoch: 6| Step: 8
Training loss: 0.4166580219166747
Validation loss: 2.5821108130096224

Epoch: 6| Step: 9
Training loss: 0.14164501049787237
Validation loss: 2.568636933090264

Epoch: 6| Step: 10
Training loss: 0.11576372536506131
Validation loss: 2.588984110298384

Epoch: 6| Step: 11
Training loss: 0.17393003112638397
Validation loss: 2.544808627607898

Epoch: 6| Step: 12
Training loss: 0.22825329550017584
Validation loss: 2.534519882393367

Epoch: 6| Step: 13
Training loss: 0.29001533847973693
Validation loss: 2.533559691636227

Epoch: 354| Step: 0
Training loss: 0.17752349835652337
Validation loss: 2.554466224177435

Epoch: 6| Step: 1
Training loss: 0.19891626169520135
Validation loss: 2.537452323251898

Epoch: 6| Step: 2
Training loss: 0.21137866933526422
Validation loss: 2.55272784521261

Epoch: 6| Step: 3
Training loss: 0.3531336644046498
Validation loss: 2.505173490262077

Epoch: 6| Step: 4
Training loss: 0.11179188288666446
Validation loss: 2.535309526459158

Epoch: 6| Step: 5
Training loss: 0.17282289601351292
Validation loss: 2.516626950201654

Epoch: 6| Step: 6
Training loss: 0.2245439351161277
Validation loss: 2.513572173751549

Epoch: 6| Step: 7
Training loss: 0.13627016863155142
Validation loss: 2.534514517446571

Epoch: 6| Step: 8
Training loss: 0.1930463067466681
Validation loss: 2.5169843128392175

Epoch: 6| Step: 9
Training loss: 0.1307256713022485
Validation loss: 2.559933719728739

Epoch: 6| Step: 10
Training loss: 0.43376431246403274
Validation loss: 2.5227382845160937

Epoch: 6| Step: 11
Training loss: 0.16070181686135995
Validation loss: 2.5777386159218176

Epoch: 6| Step: 12
Training loss: 0.12468258223001868
Validation loss: 2.5730395569003535

Epoch: 6| Step: 13
Training loss: 0.3167477636687376
Validation loss: 2.5669872563819096

Epoch: 355| Step: 0
Training loss: 0.23270689694198363
Validation loss: 2.55852819210187

Epoch: 6| Step: 1
Training loss: 0.19905787872807057
Validation loss: 2.5019490868284624

Epoch: 6| Step: 2
Training loss: 0.19582142328677427
Validation loss: 2.5099405858387467

Epoch: 6| Step: 3
Training loss: 0.301242548941434
Validation loss: 2.499585019812308

Epoch: 6| Step: 4
Training loss: 0.28835963809100323
Validation loss: 2.498736809958555

Epoch: 6| Step: 5
Training loss: 0.11638408472262435
Validation loss: 2.5628034230453927

Epoch: 6| Step: 6
Training loss: 0.1649677698218624
Validation loss: 2.5627284384609283

Epoch: 6| Step: 7
Training loss: 0.22683934036574516
Validation loss: 2.5902519759969187

Epoch: 6| Step: 8
Training loss: 0.23500503259454425
Validation loss: 2.611081080488378

Epoch: 6| Step: 9
Training loss: 0.33006985219486207
Validation loss: 2.6056921001116393

Epoch: 6| Step: 10
Training loss: 0.38391441258908054
Validation loss: 2.589158270183974

Epoch: 6| Step: 11
Training loss: 0.10351184622147336
Validation loss: 2.5814579281920293

Epoch: 6| Step: 12
Training loss: 0.16737666680750315
Validation loss: 2.520973232363348

Epoch: 6| Step: 13
Training loss: 0.34369108388766084
Validation loss: 2.475092416784055

Epoch: 356| Step: 0
Training loss: 0.21069901725094475
Validation loss: 2.4781091602218894

Epoch: 6| Step: 1
Training loss: 0.24762025324832324
Validation loss: 2.5044053860837914

Epoch: 6| Step: 2
Training loss: 0.30219932773642805
Validation loss: 2.5470399152041185

Epoch: 6| Step: 3
Training loss: 0.31809101612712476
Validation loss: 2.582271911288463

Epoch: 6| Step: 4
Training loss: 0.34663584257295466
Validation loss: 2.5539001398519097

Epoch: 6| Step: 5
Training loss: 0.26033024625518986
Validation loss: 2.585575266874983

Epoch: 6| Step: 6
Training loss: 0.18693351604510672
Validation loss: 2.5861300689293305

Epoch: 6| Step: 7
Training loss: 0.18747011582324855
Validation loss: 2.5589105621133386

Epoch: 6| Step: 8
Training loss: 0.22030603926904846
Validation loss: 2.5398446513263653

Epoch: 6| Step: 9
Training loss: 0.30092525750409305
Validation loss: 2.522777932789423

Epoch: 6| Step: 10
Training loss: 0.11140597281882968
Validation loss: 2.5155709969832234

Epoch: 6| Step: 11
Training loss: 0.13321560104875677
Validation loss: 2.496483310555964

Epoch: 6| Step: 12
Training loss: 0.20576664828644858
Validation loss: 2.495895195284954

Epoch: 6| Step: 13
Training loss: 0.20724172509726002
Validation loss: 2.483439521607302

Epoch: 357| Step: 0
Training loss: 0.367940273114409
Validation loss: 2.489494865521705

Epoch: 6| Step: 1
Training loss: 0.23468072343025745
Validation loss: 2.479869353789254

Epoch: 6| Step: 2
Training loss: 0.317905183947632
Validation loss: 2.518968602987949

Epoch: 6| Step: 3
Training loss: 0.11867176885895192
Validation loss: 2.4944396041061836

Epoch: 6| Step: 4
Training loss: 0.19414211556612695
Validation loss: 2.513849967064965

Epoch: 6| Step: 5
Training loss: 0.21661496477826497
Validation loss: 2.5186208828015064

Epoch: 6| Step: 6
Training loss: 0.3049684354208023
Validation loss: 2.5421893024426216

Epoch: 6| Step: 7
Training loss: 0.11586455807503668
Validation loss: 2.5142587044207096

Epoch: 6| Step: 8
Training loss: 0.2493654483027126
Validation loss: 2.5522913962042773

Epoch: 6| Step: 9
Training loss: 0.12829655902086343
Validation loss: 2.510900787157205

Epoch: 6| Step: 10
Training loss: 0.17950650096851992
Validation loss: 2.505520438386472

Epoch: 6| Step: 11
Training loss: 0.13405731206694896
Validation loss: 2.5025915997700907

Epoch: 6| Step: 12
Training loss: 0.28620611560290155
Validation loss: 2.5078743256246954

Epoch: 6| Step: 13
Training loss: 0.22517583982870726
Validation loss: 2.495384272491337

Epoch: 358| Step: 0
Training loss: 0.35738693650209813
Validation loss: 2.515117469992476

Epoch: 6| Step: 1
Training loss: 0.1712625330755604
Validation loss: 2.5231849287233867

Epoch: 6| Step: 2
Training loss: 0.2893175597886673
Validation loss: 2.5078322203726566

Epoch: 6| Step: 3
Training loss: 0.1513902339003054
Validation loss: 2.5384918919644632

Epoch: 6| Step: 4
Training loss: 0.2812573378983217
Validation loss: 2.513742076356487

Epoch: 6| Step: 5
Training loss: 0.16311726297833282
Validation loss: 2.5114192905017116

Epoch: 6| Step: 6
Training loss: 0.2031451820470939
Validation loss: 2.514445700090588

Epoch: 6| Step: 7
Training loss: 0.12409604567914229
Validation loss: 2.526075024009782

Epoch: 6| Step: 8
Training loss: 0.10336236584661951
Validation loss: 2.5216224223200823

Epoch: 6| Step: 9
Training loss: 0.1773049753291384
Validation loss: 2.5447145427523163

Epoch: 6| Step: 10
Training loss: 0.23431921136004852
Validation loss: 2.547331442397482

Epoch: 6| Step: 11
Training loss: 0.20444504341067837
Validation loss: 2.5669103256543297

Epoch: 6| Step: 12
Training loss: 0.25523788741642955
Validation loss: 2.564345025980543

Epoch: 6| Step: 13
Training loss: 0.3334126738160857
Validation loss: 2.5368731984163713

Epoch: 359| Step: 0
Training loss: 0.22836235807899785
Validation loss: 2.5000828677974

Epoch: 6| Step: 1
Training loss: 0.2254274645603051
Validation loss: 2.5020194449639135

Epoch: 6| Step: 2
Training loss: 0.2856369669638123
Validation loss: 2.4953704155149663

Epoch: 6| Step: 3
Training loss: 0.39486631008197354
Validation loss: 2.4854455476688564

Epoch: 6| Step: 4
Training loss: 0.14458863304875214
Validation loss: 2.4865156720549035

Epoch: 6| Step: 5
Training loss: 0.11750099053624813
Validation loss: 2.5311399390588507

Epoch: 6| Step: 6
Training loss: 0.2659349456422374
Validation loss: 2.550170599209043

Epoch: 6| Step: 7
Training loss: 0.09068012698413673
Validation loss: 2.536604795421634

Epoch: 6| Step: 8
Training loss: 0.1950079068696059
Validation loss: 2.56273766672793

Epoch: 6| Step: 9
Training loss: 0.15801813353602454
Validation loss: 2.608305484649664

Epoch: 6| Step: 10
Training loss: 0.3225090841189395
Validation loss: 2.5964621132665675

Epoch: 6| Step: 11
Training loss: 0.15184219032447518
Validation loss: 2.583202625372482

Epoch: 6| Step: 12
Training loss: 0.20711279109006778
Validation loss: 2.5516225921692497

Epoch: 6| Step: 13
Training loss: 0.16036083366550583
Validation loss: 2.490845952723434

Epoch: 360| Step: 0
Training loss: 0.1803330869343209
Validation loss: 2.5053983854230633

Epoch: 6| Step: 1
Training loss: 0.1251918691081253
Validation loss: 2.489578595034432

Epoch: 6| Step: 2
Training loss: 0.34961611991641417
Validation loss: 2.5385534349487258

Epoch: 6| Step: 3
Training loss: 0.21004707875916193
Validation loss: 2.567038579869598

Epoch: 6| Step: 4
Training loss: 0.24396197840109127
Validation loss: 2.5658010824178157

Epoch: 6| Step: 5
Training loss: 0.14015287379277808
Validation loss: 2.6077629475562096

Epoch: 6| Step: 6
Training loss: 0.2746821549886121
Validation loss: 2.563854880798019

Epoch: 6| Step: 7
Training loss: 0.22419022136054284
Validation loss: 2.5606106711944427

Epoch: 6| Step: 8
Training loss: 0.21696747262263594
Validation loss: 2.542043683839303

Epoch: 6| Step: 9
Training loss: 0.31971565325843077
Validation loss: 2.5418811918033213

Epoch: 6| Step: 10
Training loss: 0.16360855880794567
Validation loss: 2.5103720411370523

Epoch: 6| Step: 11
Training loss: 0.09583135694386981
Validation loss: 2.523375610702018

Epoch: 6| Step: 12
Training loss: 0.2588498458015568
Validation loss: 2.5439377886868133

Epoch: 6| Step: 13
Training loss: 0.15581204309943544
Validation loss: 2.554193131825752

Epoch: 361| Step: 0
Training loss: 0.2542271859915221
Validation loss: 2.499073702960622

Epoch: 6| Step: 1
Training loss: 0.1897880405741934
Validation loss: 2.474628326071247

Epoch: 6| Step: 2
Training loss: 0.20889032333138807
Validation loss: 2.4853195661893155

Epoch: 6| Step: 3
Training loss: 0.2959080055628693
Validation loss: 2.4979696612321534

Epoch: 6| Step: 4
Training loss: 0.1302689713108566
Validation loss: 2.5117306877496457

Epoch: 6| Step: 5
Training loss: 0.3791406437394149
Validation loss: 2.522106051409717

Epoch: 6| Step: 6
Training loss: 0.14613825278313014
Validation loss: 2.505709629551054

Epoch: 6| Step: 7
Training loss: 0.26417713498534107
Validation loss: 2.5153210919492066

Epoch: 6| Step: 8
Training loss: 0.16167006082163018
Validation loss: 2.510125181888016

Epoch: 6| Step: 9
Training loss: 0.15734663222929976
Validation loss: 2.505387243264947

Epoch: 6| Step: 10
Training loss: 0.2318223626292926
Validation loss: 2.5033325942908617

Epoch: 6| Step: 11
Training loss: 0.14084305678773204
Validation loss: 2.5100178950531875

Epoch: 6| Step: 12
Training loss: 0.10809688034333303
Validation loss: 2.566501287713246

Epoch: 6| Step: 13
Training loss: 0.34395581283007814
Validation loss: 2.5762679878923573

Epoch: 362| Step: 0
Training loss: 0.29387509340571155
Validation loss: 2.558719957350261

Epoch: 6| Step: 1
Training loss: 0.24853101176045791
Validation loss: 2.5761602080024826

Epoch: 6| Step: 2
Training loss: 0.226511028625499
Validation loss: 2.5454015626248845

Epoch: 6| Step: 3
Training loss: 0.12227817385689436
Validation loss: 2.497301682056747

Epoch: 6| Step: 4
Training loss: 0.11882321883060876
Validation loss: 2.506626072764146

Epoch: 6| Step: 5
Training loss: 0.25378375399702
Validation loss: 2.4832462474184687

Epoch: 6| Step: 6
Training loss: 0.3015539721533317
Validation loss: 2.459574807405579

Epoch: 6| Step: 7
Training loss: 0.13802477468105318
Validation loss: 2.443872112413113

Epoch: 6| Step: 8
Training loss: 0.29975714291007116
Validation loss: 2.459167525776044

Epoch: 6| Step: 9
Training loss: 0.14884034504620935
Validation loss: 2.4115114603299044

Epoch: 6| Step: 10
Training loss: 0.3733523052190388
Validation loss: 2.4409270289499663

Epoch: 6| Step: 11
Training loss: 0.22359572856888704
Validation loss: 2.5112698605086092

Epoch: 6| Step: 12
Training loss: 0.2512338558865203
Validation loss: 2.6231931072468604

Epoch: 6| Step: 13
Training loss: 0.25360767709373916
Validation loss: 2.6170535699048565

Epoch: 363| Step: 0
Training loss: 0.32864157567639174
Validation loss: 2.607413309269185

Epoch: 6| Step: 1
Training loss: 0.2302677118238281
Validation loss: 2.5028704090089384

Epoch: 6| Step: 2
Training loss: 0.22444913372629785
Validation loss: 2.4790172874868714

Epoch: 6| Step: 3
Training loss: 0.3034394574912484
Validation loss: 2.4344022580384843

Epoch: 6| Step: 4
Training loss: 0.3719623238752689
Validation loss: 2.412664671220299

Epoch: 6| Step: 5
Training loss: 0.19456115209417074
Validation loss: 2.4467001397512473

Epoch: 6| Step: 6
Training loss: 0.2253125834101127
Validation loss: 2.467315584216978

Epoch: 6| Step: 7
Training loss: 0.2588655035016817
Validation loss: 2.557236422089133

Epoch: 6| Step: 8
Training loss: 0.23332326468530842
Validation loss: 2.5786720786761896

Epoch: 6| Step: 9
Training loss: 0.31537268628463516
Validation loss: 2.5843436527802486

Epoch: 6| Step: 10
Training loss: 0.21625208923951308
Validation loss: 2.576856176760312

Epoch: 6| Step: 11
Training loss: 0.3057608892867547
Validation loss: 2.5332910028471294

Epoch: 6| Step: 12
Training loss: 0.28058651972533305
Validation loss: 2.492029126975737

Epoch: 6| Step: 13
Training loss: 0.1331748787025256
Validation loss: 2.4721339139213723

Epoch: 364| Step: 0
Training loss: 0.20334637939279704
Validation loss: 2.470073831516011

Epoch: 6| Step: 1
Training loss: 0.1464030930393491
Validation loss: 2.4754449422868667

Epoch: 6| Step: 2
Training loss: 0.21830141530043398
Validation loss: 2.5198634868594287

Epoch: 6| Step: 3
Training loss: 0.18503993199445948
Validation loss: 2.57525765873891

Epoch: 6| Step: 4
Training loss: 0.19658736910065844
Validation loss: 2.5553680945336663

Epoch: 6| Step: 5
Training loss: 0.4080488470103995
Validation loss: 2.5858465375182407

Epoch: 6| Step: 6
Training loss: 0.23975490390726578
Validation loss: 2.595549749620198

Epoch: 6| Step: 7
Training loss: 0.24034530900581752
Validation loss: 2.5796140793581634

Epoch: 6| Step: 8
Training loss: 0.20883284628026852
Validation loss: 2.5666754764261333

Epoch: 6| Step: 9
Training loss: 0.17759880722513655
Validation loss: 2.559653026992423

Epoch: 6| Step: 10
Training loss: 0.26946531401483786
Validation loss: 2.5585864325841996

Epoch: 6| Step: 11
Training loss: 0.2147700356689342
Validation loss: 2.4946687438455997

Epoch: 6| Step: 12
Training loss: 0.35345011573084845
Validation loss: 2.468173279383901

Epoch: 6| Step: 13
Training loss: 0.2509520403686136
Validation loss: 2.4411994998142412

Epoch: 365| Step: 0
Training loss: 0.15981371232842148
Validation loss: 2.45823352538808

Epoch: 6| Step: 1
Training loss: 0.21973609055947518
Validation loss: 2.4937128154350794

Epoch: 6| Step: 2
Training loss: 0.16288981952056428
Validation loss: 2.519604782121485

Epoch: 6| Step: 3
Training loss: 0.31825603375854444
Validation loss: 2.5572210120470955

Epoch: 6| Step: 4
Training loss: 0.255457715720697
Validation loss: 2.5833727734029712

Epoch: 6| Step: 5
Training loss: 0.3174847835175992
Validation loss: 2.5228175062583915

Epoch: 6| Step: 6
Training loss: 0.28328556307893127
Validation loss: 2.516548314931666

Epoch: 6| Step: 7
Training loss: 0.27904662011257353
Validation loss: 2.4840030516853284

Epoch: 6| Step: 8
Training loss: 0.2062493349555882
Validation loss: 2.4583744742939984

Epoch: 6| Step: 9
Training loss: 0.328701228578086
Validation loss: 2.4867288133711027

Epoch: 6| Step: 10
Training loss: 0.2263858122647445
Validation loss: 2.50464372964924

Epoch: 6| Step: 11
Training loss: 0.21044966128982073
Validation loss: 2.5236335794284654

Epoch: 6| Step: 12
Training loss: 0.1995809852134122
Validation loss: 2.5577779381547354

Epoch: 6| Step: 13
Training loss: 0.14121587119446646
Validation loss: 2.559474921271482

Epoch: 366| Step: 0
Training loss: 0.28134537775030005
Validation loss: 2.604588697794175

Epoch: 6| Step: 1
Training loss: 0.2933692229506278
Validation loss: 2.5856452293183385

Epoch: 6| Step: 2
Training loss: 0.2338567328294567
Validation loss: 2.5947150322859414

Epoch: 6| Step: 3
Training loss: 0.21946813857264832
Validation loss: 2.5791129219676105

Epoch: 6| Step: 4
Training loss: 0.13006095572448015
Validation loss: 2.5353234300719967

Epoch: 6| Step: 5
Training loss: 0.2386479292374721
Validation loss: 2.5779366875341125

Epoch: 6| Step: 6
Training loss: 0.1298246396802423
Validation loss: 2.565383836087651

Epoch: 6| Step: 7
Training loss: 0.3736488717711312
Validation loss: 2.565907901173462

Epoch: 6| Step: 8
Training loss: 0.128490137628113
Validation loss: 2.585019791371166

Epoch: 6| Step: 9
Training loss: 0.2721888506447428
Validation loss: 2.584578548586987

Epoch: 6| Step: 10
Training loss: 0.25158762480567365
Validation loss: 2.607651047012169

Epoch: 6| Step: 11
Training loss: 0.20472457928453008
Validation loss: 2.584552824056783

Epoch: 6| Step: 12
Training loss: 0.20928496730944082
Validation loss: 2.5628042933294553

Epoch: 6| Step: 13
Training loss: 0.14870643095859137
Validation loss: 2.4672079279288077

Epoch: 367| Step: 0
Training loss: 0.21179345210119127
Validation loss: 2.4802027349026456

Epoch: 6| Step: 1
Training loss: 0.19938331239885101
Validation loss: 2.4295820393943846

Epoch: 6| Step: 2
Training loss: 0.17943580248224744
Validation loss: 2.413672536538849

Epoch: 6| Step: 3
Training loss: 0.2507681073699301
Validation loss: 2.3763455377376728

Epoch: 6| Step: 4
Training loss: 0.2545988905820701
Validation loss: 2.4325433760561705

Epoch: 6| Step: 5
Training loss: 0.2759093141254941
Validation loss: 2.4690354803801817

Epoch: 6| Step: 6
Training loss: 0.22907615449184213
Validation loss: 2.468135488823537

Epoch: 6| Step: 7
Training loss: 0.154455640451095
Validation loss: 2.498157179907757

Epoch: 6| Step: 8
Training loss: 0.23594280230646167
Validation loss: 2.5317001175507583

Epoch: 6| Step: 9
Training loss: 0.3071696098294956
Validation loss: 2.5339576907368864

Epoch: 6| Step: 10
Training loss: 0.28541931663916537
Validation loss: 2.527398197812226

Epoch: 6| Step: 11
Training loss: 0.06888468402726951
Validation loss: 2.4901334512017788

Epoch: 6| Step: 12
Training loss: 0.3206550696886328
Validation loss: 2.4622905667334627

Epoch: 6| Step: 13
Training loss: 0.03317415677745268
Validation loss: 2.4543255909862505

Epoch: 368| Step: 0
Training loss: 0.15697550424667053
Validation loss: 2.431967801189014

Epoch: 6| Step: 1
Training loss: 0.2252282365881427
Validation loss: 2.435228007788195

Epoch: 6| Step: 2
Training loss: 0.4188158595547139
Validation loss: 2.4801256953666995

Epoch: 6| Step: 3
Training loss: 0.2175850416827066
Validation loss: 2.51623549149377

Epoch: 6| Step: 4
Training loss: 0.1505323213155461
Validation loss: 2.590295973908164

Epoch: 6| Step: 5
Training loss: 0.25175379475420323
Validation loss: 2.5827017841438833

Epoch: 6| Step: 6
Training loss: 0.16812217713577768
Validation loss: 2.6123766838259828

Epoch: 6| Step: 7
Training loss: 0.1547405768377235
Validation loss: 2.6664175761952555

Epoch: 6| Step: 8
Training loss: 0.3379392644018807
Validation loss: 2.6001454757721514

Epoch: 6| Step: 9
Training loss: 0.11974638017238445
Validation loss: 2.5936489112706234

Epoch: 6| Step: 10
Training loss: 0.20012476538704552
Validation loss: 2.561144216270115

Epoch: 6| Step: 11
Training loss: 0.11439022314665163
Validation loss: 2.5268143073021765

Epoch: 6| Step: 12
Training loss: 0.20263654410113427
Validation loss: 2.476078547089687

Epoch: 6| Step: 13
Training loss: 0.35205900312285604
Validation loss: 2.446559334029906

Epoch: 369| Step: 0
Training loss: 0.34480581912395974
Validation loss: 2.4680619221352975

Epoch: 6| Step: 1
Training loss: 0.1802419938823908
Validation loss: 2.4712798195593098

Epoch: 6| Step: 2
Training loss: 0.3094516611004426
Validation loss: 2.5003418042726553

Epoch: 6| Step: 3
Training loss: 0.11955277492217571
Validation loss: 2.5370396504687562

Epoch: 6| Step: 4
Training loss: 0.18405804869963885
Validation loss: 2.545105904107622

Epoch: 6| Step: 5
Training loss: 0.2754179487809326
Validation loss: 2.5923629948483846

Epoch: 6| Step: 6
Training loss: 0.1907957031873801
Validation loss: 2.5825573162194053

Epoch: 6| Step: 7
Training loss: 0.30973534742740655
Validation loss: 2.5887630738772622

Epoch: 6| Step: 8
Training loss: 0.1761375524915639
Validation loss: 2.5841358614057532

Epoch: 6| Step: 9
Training loss: 0.21316094691044576
Validation loss: 2.554635851103596

Epoch: 6| Step: 10
Training loss: 0.2426312058341521
Validation loss: 2.522678596511603

Epoch: 6| Step: 11
Training loss: 0.1529921646433717
Validation loss: 2.4893529696744823

Epoch: 6| Step: 12
Training loss: 0.12893686508987623
Validation loss: 2.486095847615765

Epoch: 6| Step: 13
Training loss: 0.21198266320933817
Validation loss: 2.4486457568034363

Epoch: 370| Step: 0
Training loss: 0.25091402038997657
Validation loss: 2.4617918329552455

Epoch: 6| Step: 1
Training loss: 0.3105686827865792
Validation loss: 2.438812223952242

Epoch: 6| Step: 2
Training loss: 0.11534988949831997
Validation loss: 2.4628621726776814

Epoch: 6| Step: 3
Training loss: 0.13781384175484324
Validation loss: 2.478393120338073

Epoch: 6| Step: 4
Training loss: 0.10509747039942959
Validation loss: 2.4952385916315607

Epoch: 6| Step: 5
Training loss: 0.14341398077481018
Validation loss: 2.4571350306327786

Epoch: 6| Step: 6
Training loss: 0.168056104921747
Validation loss: 2.473290352572141

Epoch: 6| Step: 7
Training loss: 0.28087532730321146
Validation loss: 2.4902392485424323

Epoch: 6| Step: 8
Training loss: 0.17768595109198063
Validation loss: 2.488830411020338

Epoch: 6| Step: 9
Training loss: 0.2725064229426985
Validation loss: 2.4488473233659183

Epoch: 6| Step: 10
Training loss: 0.2640381282642346
Validation loss: 2.4987199408263416

Epoch: 6| Step: 11
Training loss: 0.20826424208021713
Validation loss: 2.4954243173644404

Epoch: 6| Step: 12
Training loss: 0.21582704421371862
Validation loss: 2.508613563522431

Epoch: 6| Step: 13
Training loss: 0.14810654487002597
Validation loss: 2.5500091387693335

Epoch: 371| Step: 0
Training loss: 0.19793108314577715
Validation loss: 2.550784462110138

Epoch: 6| Step: 1
Training loss: 0.28072133976364827
Validation loss: 2.5549892701265895

Epoch: 6| Step: 2
Training loss: 0.11118911128353508
Validation loss: 2.5448501523039786

Epoch: 6| Step: 3
Training loss: 0.16531421364831694
Validation loss: 2.5210811344376145

Epoch: 6| Step: 4
Training loss: 0.1951453733658368
Validation loss: 2.5362845036558768

Epoch: 6| Step: 5
Training loss: 0.18926408519132673
Validation loss: 2.5152509917408428

Epoch: 6| Step: 6
Training loss: 0.3024583604228152
Validation loss: 2.49520971037051

Epoch: 6| Step: 7
Training loss: 0.3087016653343153
Validation loss: 2.5048929754105127

Epoch: 6| Step: 8
Training loss: 0.2606430722564191
Validation loss: 2.5200327577690165

Epoch: 6| Step: 9
Training loss: 0.19254250845105628
Validation loss: 2.545980799429517

Epoch: 6| Step: 10
Training loss: 0.12607135459193572
Validation loss: 2.510217539673525

Epoch: 6| Step: 11
Training loss: 0.17244611484166555
Validation loss: 2.5013217426350467

Epoch: 6| Step: 12
Training loss: 0.13892616543287006
Validation loss: 2.519592145021902

Epoch: 6| Step: 13
Training loss: 0.2729095675853107
Validation loss: 2.5374787531040544

Epoch: 372| Step: 0
Training loss: 0.19526076585343802
Validation loss: 2.5254410589887057

Epoch: 6| Step: 1
Training loss: 0.15630113837725415
Validation loss: 2.555878251986656

Epoch: 6| Step: 2
Training loss: 0.20888928005650967
Validation loss: 2.5365288251225238

Epoch: 6| Step: 3
Training loss: 0.16883354679635812
Validation loss: 2.5239164176763116

Epoch: 6| Step: 4
Training loss: 0.1290686335965044
Validation loss: 2.490308797658384

Epoch: 6| Step: 5
Training loss: 0.3422687216389858
Validation loss: 2.511374666114827

Epoch: 6| Step: 6
Training loss: 0.18798631939545496
Validation loss: 2.523898843296909

Epoch: 6| Step: 7
Training loss: 0.20610523055971106
Validation loss: 2.488444021577365

Epoch: 6| Step: 8
Training loss: 0.13032981847813715
Validation loss: 2.543587085370372

Epoch: 6| Step: 9
Training loss: 0.16173579361154963
Validation loss: 2.5443690166185955

Epoch: 6| Step: 10
Training loss: 0.21454486864821654
Validation loss: 2.5179401929297502

Epoch: 6| Step: 11
Training loss: 0.25180339060326884
Validation loss: 2.5525412280367115

Epoch: 6| Step: 12
Training loss: 0.25956808911613455
Validation loss: 2.5355390243968245

Epoch: 6| Step: 13
Training loss: 0.09766202432727042
Validation loss: 2.5104862118912323

Epoch: 373| Step: 0
Training loss: 0.26648726476010026
Validation loss: 2.5243598773336378

Epoch: 6| Step: 1
Training loss: 0.10331066100935217
Validation loss: 2.5312449815893565

Epoch: 6| Step: 2
Training loss: 0.2110058179353818
Validation loss: 2.507194354178987

Epoch: 6| Step: 3
Training loss: 0.143327689242223
Validation loss: 2.520376751063206

Epoch: 6| Step: 4
Training loss: 0.2394751204178839
Validation loss: 2.5140778406665896

Epoch: 6| Step: 5
Training loss: 0.09045344775912131
Validation loss: 2.4933001685534744

Epoch: 6| Step: 6
Training loss: 0.19630141717546898
Validation loss: 2.533626763761818

Epoch: 6| Step: 7
Training loss: 0.09652231393312215
Validation loss: 2.491062001328944

Epoch: 6| Step: 8
Training loss: 0.11677293165248816
Validation loss: 2.5152786904136715

Epoch: 6| Step: 9
Training loss: 0.22632309992001162
Validation loss: 2.4877534590136476

Epoch: 6| Step: 10
Training loss: 0.3034778939732384
Validation loss: 2.482283800438231

Epoch: 6| Step: 11
Training loss: 0.3224265419298979
Validation loss: 2.4913805509214533

Epoch: 6| Step: 12
Training loss: 0.11757977316578849
Validation loss: 2.48828477048381

Epoch: 6| Step: 13
Training loss: 0.1355760847933717
Validation loss: 2.5078203070003475

Epoch: 374| Step: 0
Training loss: 0.2309278425357656
Validation loss: 2.5080602686592526

Epoch: 6| Step: 1
Training loss: 0.13827686733908529
Validation loss: 2.533829630804924

Epoch: 6| Step: 2
Training loss: 0.13117929751154359
Validation loss: 2.506529959432132

Epoch: 6| Step: 3
Training loss: 0.1677796052946979
Validation loss: 2.521259611151921

Epoch: 6| Step: 4
Training loss: 0.2884024739929146
Validation loss: 2.5516990846155996

Epoch: 6| Step: 5
Training loss: 0.28358155321527856
Validation loss: 2.4967468548356666

Epoch: 6| Step: 6
Training loss: 0.1274357206165188
Validation loss: 2.503064314130516

Epoch: 6| Step: 7
Training loss: 0.18062637554621702
Validation loss: 2.4805005515361755

Epoch: 6| Step: 8
Training loss: 0.1103598414328455
Validation loss: 2.4912106946385024

Epoch: 6| Step: 9
Training loss: 0.27661097796721823
Validation loss: 2.495253590789267

Epoch: 6| Step: 10
Training loss: 0.29734483984277904
Validation loss: 2.477401818391826

Epoch: 6| Step: 11
Training loss: 0.1410073671538393
Validation loss: 2.454953745900034

Epoch: 6| Step: 12
Training loss: 0.1989200259739924
Validation loss: 2.5045126374814553

Epoch: 6| Step: 13
Training loss: 0.07197161742331545
Validation loss: 2.452314521059664

Epoch: 375| Step: 0
Training loss: 0.18751009278154399
Validation loss: 2.496306381606402

Epoch: 6| Step: 1
Training loss: 0.1915748301453642
Validation loss: 2.5102653255261513

Epoch: 6| Step: 2
Training loss: 0.264640695381234
Validation loss: 2.508711648994293

Epoch: 6| Step: 3
Training loss: 0.26204706352435914
Validation loss: 2.5587527661137996

Epoch: 6| Step: 4
Training loss: 0.21918093434701336
Validation loss: 2.4884343648071447

Epoch: 6| Step: 5
Training loss: 0.1896891843824686
Validation loss: 2.5151690079563758

Epoch: 6| Step: 6
Training loss: 0.2503656455209821
Validation loss: 2.453150761415941

Epoch: 6| Step: 7
Training loss: 0.3096506634234358
Validation loss: 2.4889802264433456

Epoch: 6| Step: 8
Training loss: 0.19332245753653898
Validation loss: 2.4917034078005864

Epoch: 6| Step: 9
Training loss: 0.24374049394362096
Validation loss: 2.4966451171474455

Epoch: 6| Step: 10
Training loss: 0.15016832890589052
Validation loss: 2.495934193022359

Epoch: 6| Step: 11
Training loss: 0.19977309199980556
Validation loss: 2.5138778275153326

Epoch: 6| Step: 12
Training loss: 0.11950495000486978
Validation loss: 2.509669468973976

Epoch: 6| Step: 13
Training loss: 0.29862393153316025
Validation loss: 2.596176486148426

Epoch: 376| Step: 0
Training loss: 0.13212704484506674
Validation loss: 2.5885964879266163

Epoch: 6| Step: 1
Training loss: 0.13693850431069624
Validation loss: 2.5834754708915844

Epoch: 6| Step: 2
Training loss: 0.15625442260205222
Validation loss: 2.5907273335749808

Epoch: 6| Step: 3
Training loss: 0.21108622958992088
Validation loss: 2.547161316457077

Epoch: 6| Step: 4
Training loss: 0.273670750995999
Validation loss: 2.4878191919534833

Epoch: 6| Step: 5
Training loss: 0.14533724164036738
Validation loss: 2.4328735209658587

Epoch: 6| Step: 6
Training loss: 0.1851173146672646
Validation loss: 2.3766266711909054

Epoch: 6| Step: 7
Training loss: 0.31761968136672647
Validation loss: 2.3711069709493167

Epoch: 6| Step: 8
Training loss: 0.13865298155903766
Validation loss: 2.3718343793276624

Epoch: 6| Step: 9
Training loss: 0.2495948667891709
Validation loss: 2.4118236175694734

Epoch: 6| Step: 10
Training loss: 0.22782243429639898
Validation loss: 2.4388792460040083

Epoch: 6| Step: 11
Training loss: 0.3287974234196953
Validation loss: 2.4979437072560735

Epoch: 6| Step: 12
Training loss: 0.2906664347080813
Validation loss: 2.494295342711154

Epoch: 6| Step: 13
Training loss: 0.3527118650332064
Validation loss: 2.517807595772796

Epoch: 377| Step: 0
Training loss: 0.09039147972553464
Validation loss: 2.467299786595768

Epoch: 6| Step: 1
Training loss: 0.2229217318526838
Validation loss: 2.467806540158338

Epoch: 6| Step: 2
Training loss: 0.2544233778049556
Validation loss: 2.4506981673381243

Epoch: 6| Step: 3
Training loss: 0.20131526392283172
Validation loss: 2.464599551514684

Epoch: 6| Step: 4
Training loss: 0.3765505088384825
Validation loss: 2.4826006237106033

Epoch: 6| Step: 5
Training loss: 0.17081554037180546
Validation loss: 2.509770912103234

Epoch: 6| Step: 6
Training loss: 0.16531652906263702
Validation loss: 2.5891215320995324

Epoch: 6| Step: 7
Training loss: 0.33218342155041447
Validation loss: 2.5979174292441787

Epoch: 6| Step: 8
Training loss: 0.1251310019677988
Validation loss: 2.555011503058334

Epoch: 6| Step: 9
Training loss: 0.3291092144447264
Validation loss: 2.5576997160781287

Epoch: 6| Step: 10
Training loss: 0.1563379695734152
Validation loss: 2.5184189405670865

Epoch: 6| Step: 11
Training loss: 0.13458588265089996
Validation loss: 2.523934617624205

Epoch: 6| Step: 12
Training loss: 0.2354935656901653
Validation loss: 2.4862329381534476

Epoch: 6| Step: 13
Training loss: 0.1370517014386557
Validation loss: 2.4916277805407674

Epoch: 378| Step: 0
Training loss: 0.2904944906171911
Validation loss: 2.5231308710933127

Epoch: 6| Step: 1
Training loss: 0.10809635478871042
Validation loss: 2.5014399862626377

Epoch: 6| Step: 2
Training loss: 0.24577194699471125
Validation loss: 2.54599312908364

Epoch: 6| Step: 3
Training loss: 0.21963603380035282
Validation loss: 2.530972819949976

Epoch: 6| Step: 4
Training loss: 0.17264555384442715
Validation loss: 2.558547374283446

Epoch: 6| Step: 5
Training loss: 0.27627185754480915
Validation loss: 2.5831373000086892

Epoch: 6| Step: 6
Training loss: 0.2145398157553203
Validation loss: 2.5343490845876215

Epoch: 6| Step: 7
Training loss: 0.2941854262966756
Validation loss: 2.4630281848544615

Epoch: 6| Step: 8
Training loss: 0.24884578875691332
Validation loss: 2.4774915875838337

Epoch: 6| Step: 9
Training loss: 0.3235067684985195
Validation loss: 2.419189193893288

Epoch: 6| Step: 10
Training loss: 0.22527789266780407
Validation loss: 2.4311369011329957

Epoch: 6| Step: 11
Training loss: 0.30042156164349687
Validation loss: 2.451883343929753

Epoch: 6| Step: 12
Training loss: 0.1322949648118085
Validation loss: 2.4829437875994294

Epoch: 6| Step: 13
Training loss: 0.2725207628861901
Validation loss: 2.531888291107805

Epoch: 379| Step: 0
Training loss: 0.24095406542134942
Validation loss: 2.5626133499267048

Epoch: 6| Step: 1
Training loss: 0.3398301571287079
Validation loss: 2.5791229553934523

Epoch: 6| Step: 2
Training loss: 0.29408995659290565
Validation loss: 2.5948357146307592

Epoch: 6| Step: 3
Training loss: 0.20381691353179854
Validation loss: 2.5391931290386505

Epoch: 6| Step: 4
Training loss: 0.2175919242468919
Validation loss: 2.4507364056613725

Epoch: 6| Step: 5
Training loss: 0.19431949910171661
Validation loss: 2.3977070993244243

Epoch: 6| Step: 6
Training loss: 0.23977929718622376
Validation loss: 2.3949304242719047

Epoch: 6| Step: 7
Training loss: 0.2765293791168033
Validation loss: 2.4100547044900886

Epoch: 6| Step: 8
Training loss: 0.1871239945149594
Validation loss: 2.4062913793344114

Epoch: 6| Step: 9
Training loss: 0.3126185788246738
Validation loss: 2.426097773989345

Epoch: 6| Step: 10
Training loss: 0.14885977861500455
Validation loss: 2.465248236064432

Epoch: 6| Step: 11
Training loss: 0.18362958030882898
Validation loss: 2.5625279402791565

Epoch: 6| Step: 12
Training loss: 0.1880513964633621
Validation loss: 2.5588586563185145

Epoch: 6| Step: 13
Training loss: 0.27646314485028606
Validation loss: 2.5914345309856395

Epoch: 380| Step: 0
Training loss: 0.21317098687746136
Validation loss: 2.5616304676572814

Epoch: 6| Step: 1
Training loss: 0.14070365613363736
Validation loss: 2.502260489522206

Epoch: 6| Step: 2
Training loss: 0.2752185852303244
Validation loss: 2.4861151633022707

Epoch: 6| Step: 3
Training loss: 0.17677223821121843
Validation loss: 2.4554989945180496

Epoch: 6| Step: 4
Training loss: 0.17817626767462913
Validation loss: 2.426484861812294

Epoch: 6| Step: 5
Training loss: 0.2326045240259109
Validation loss: 2.420515421768304

Epoch: 6| Step: 6
Training loss: 0.2966137414082453
Validation loss: 2.488953146661076

Epoch: 6| Step: 7
Training loss: 0.3533673581443024
Validation loss: 2.485960842435558

Epoch: 6| Step: 8
Training loss: 0.3101796672254065
Validation loss: 2.4986827025473777

Epoch: 6| Step: 9
Training loss: 0.18414663703953965
Validation loss: 2.571143875543057

Epoch: 6| Step: 10
Training loss: 0.21471869557157494
Validation loss: 2.61452926549115

Epoch: 6| Step: 11
Training loss: 0.2791709349196844
Validation loss: 2.639870744808801

Epoch: 6| Step: 12
Training loss: 0.2950258387548275
Validation loss: 2.630740149328543

Epoch: 6| Step: 13
Training loss: 0.20073136923478482
Validation loss: 2.573406623368047

Epoch: 381| Step: 0
Training loss: 0.1628043318949201
Validation loss: 2.556976203331837

Epoch: 6| Step: 1
Training loss: 0.32008834299281985
Validation loss: 2.482264541691833

Epoch: 6| Step: 2
Training loss: 0.23699265832887242
Validation loss: 2.425909066105357

Epoch: 6| Step: 3
Training loss: 0.36920260358157947
Validation loss: 2.3742098743413313

Epoch: 6| Step: 4
Training loss: 0.25388242169589664
Validation loss: 2.450388200871873

Epoch: 6| Step: 5
Training loss: 0.1839980179087765
Validation loss: 2.5396086069708717

Epoch: 6| Step: 6
Training loss: 0.2552303852882238
Validation loss: 2.62400082207351

Epoch: 6| Step: 7
Training loss: 0.1944874695073294
Validation loss: 2.6728199835660695

Epoch: 6| Step: 8
Training loss: 0.2746968560041323
Validation loss: 2.7005316966212485

Epoch: 6| Step: 9
Training loss: 0.3487186379670511
Validation loss: 2.721111728196084

Epoch: 6| Step: 10
Training loss: 0.23932241229452808
Validation loss: 2.6521212876449565

Epoch: 6| Step: 11
Training loss: 0.21216394484710158
Validation loss: 2.5999069979735774

Epoch: 6| Step: 12
Training loss: 0.17666103284796517
Validation loss: 2.520441136317358

Epoch: 6| Step: 13
Training loss: 0.13486152498619555
Validation loss: 2.4431538462330264

Epoch: 382| Step: 0
Training loss: 0.3269592877061285
Validation loss: 2.420879513766356

Epoch: 6| Step: 1
Training loss: 0.37786133219474655
Validation loss: 2.4246319182241503

Epoch: 6| Step: 2
Training loss: 0.2681518168476942
Validation loss: 2.432661259572151

Epoch: 6| Step: 3
Training loss: 0.2835156393589869
Validation loss: 2.469169996347943

Epoch: 6| Step: 4
Training loss: 0.21251002245997452
Validation loss: 2.5231890019987517

Epoch: 6| Step: 5
Training loss: 0.22079186638740692
Validation loss: 2.6385192863408076

Epoch: 6| Step: 6
Training loss: 0.35001194541846076
Validation loss: 2.6536957303780744

Epoch: 6| Step: 7
Training loss: 0.3455315827020239
Validation loss: 2.585534790870081

Epoch: 6| Step: 8
Training loss: 0.2716451895864868
Validation loss: 2.5710535951851434

Epoch: 6| Step: 9
Training loss: 0.2517815530620568
Validation loss: 2.45101577816729

Epoch: 6| Step: 10
Training loss: 0.15157248203598114
Validation loss: 2.4404936813028417

Epoch: 6| Step: 11
Training loss: 0.2574240908722737
Validation loss: 2.4051629626064615

Epoch: 6| Step: 12
Training loss: 0.1608910683437499
Validation loss: 2.4273430276351062

Epoch: 6| Step: 13
Training loss: 0.17257647526938133
Validation loss: 2.4462497863177535

Epoch: 383| Step: 0
Training loss: 0.23763290125048236
Validation loss: 2.483605127587526

Epoch: 6| Step: 1
Training loss: 0.2844300363542544
Validation loss: 2.4672891072467813

Epoch: 6| Step: 2
Training loss: 0.23060736286364084
Validation loss: 2.5088520820905673

Epoch: 6| Step: 3
Training loss: 0.23276745725306072
Validation loss: 2.4789073067684795

Epoch: 6| Step: 4
Training loss: 0.22595273372794855
Validation loss: 2.4862664369108582

Epoch: 6| Step: 5
Training loss: 0.1694625093263113
Validation loss: 2.476554288572647

Epoch: 6| Step: 6
Training loss: 0.14082459351993762
Validation loss: 2.4654269311448362

Epoch: 6| Step: 7
Training loss: 0.27308383958851284
Validation loss: 2.467443767824104

Epoch: 6| Step: 8
Training loss: 0.2306318433387236
Validation loss: 2.4637803129888187

Epoch: 6| Step: 9
Training loss: 0.1683411794154282
Validation loss: 2.4751393576946605

Epoch: 6| Step: 10
Training loss: 0.335849950160809
Validation loss: 2.4580003051546693

Epoch: 6| Step: 11
Training loss: 0.2276588337554616
Validation loss: 2.4090760459361196

Epoch: 6| Step: 12
Training loss: 0.23846266047566356
Validation loss: 2.413989502871445

Epoch: 6| Step: 13
Training loss: 0.17910525069604424
Validation loss: 2.4482629709517423

Epoch: 384| Step: 0
Training loss: 0.2720224550634213
Validation loss: 2.4428818189781327

Epoch: 6| Step: 1
Training loss: 0.24688880646403266
Validation loss: 2.4658715354937972

Epoch: 6| Step: 2
Training loss: 0.1829505570290346
Validation loss: 2.517354057244609

Epoch: 6| Step: 3
Training loss: 0.17495713432728183
Validation loss: 2.5530934273396824

Epoch: 6| Step: 4
Training loss: 0.18674825929943728
Validation loss: 2.5761609802311773

Epoch: 6| Step: 5
Training loss: 0.2938631646325786
Validation loss: 2.5723185304615037

Epoch: 6| Step: 6
Training loss: 0.12157368918605894
Validation loss: 2.6214432633182967

Epoch: 6| Step: 7
Training loss: 0.18474754019172118
Validation loss: 2.588361083669957

Epoch: 6| Step: 8
Training loss: 0.1772501816291309
Validation loss: 2.59175342088445

Epoch: 6| Step: 9
Training loss: 0.29487354312001574
Validation loss: 2.5684262011261847

Epoch: 6| Step: 10
Training loss: 0.3228976900410894
Validation loss: 2.5318304439811503

Epoch: 6| Step: 11
Training loss: 0.18812095617149355
Validation loss: 2.4900308132114213

Epoch: 6| Step: 12
Training loss: 0.21675508972811736
Validation loss: 2.4394075629866365

Epoch: 6| Step: 13
Training loss: 0.1739096503940679
Validation loss: 2.4861212271687374

Epoch: 385| Step: 0
Training loss: 0.22618361559555264
Validation loss: 2.4512605779266825

Epoch: 6| Step: 1
Training loss: 0.1092857354208737
Validation loss: 2.4748106065620585

Epoch: 6| Step: 2
Training loss: 0.13565304800146197
Validation loss: 2.523668949148882

Epoch: 6| Step: 3
Training loss: 0.40797598693226167
Validation loss: 2.550522411080531

Epoch: 6| Step: 4
Training loss: 0.22739845646719772
Validation loss: 2.522789757235855

Epoch: 6| Step: 5
Training loss: 0.2788698493220259
Validation loss: 2.5127020544692744

Epoch: 6| Step: 6
Training loss: 0.10068462215901061
Validation loss: 2.4894387118261228

Epoch: 6| Step: 7
Training loss: 0.17103782963620964
Validation loss: 2.4917470248489546

Epoch: 6| Step: 8
Training loss: 0.1684920398989031
Validation loss: 2.4878551337036354

Epoch: 6| Step: 9
Training loss: 0.1741383388364086
Validation loss: 2.4689952717598747

Epoch: 6| Step: 10
Training loss: 0.2521417931612793
Validation loss: 2.5088401909324602

Epoch: 6| Step: 11
Training loss: 0.2130866591793605
Validation loss: 2.561952415883528

Epoch: 6| Step: 12
Training loss: 0.3061260838783425
Validation loss: 2.5763086856104795

Epoch: 6| Step: 13
Training loss: 0.23229046320211455
Validation loss: 2.601179197726143

Epoch: 386| Step: 0
Training loss: 0.19129005135858415
Validation loss: 2.616816555104023

Epoch: 6| Step: 1
Training loss: 0.2379876657633753
Validation loss: 2.5799691156260764

Epoch: 6| Step: 2
Training loss: 0.29460885318213204
Validation loss: 2.566253695034799

Epoch: 6| Step: 3
Training loss: 0.2479141886704819
Validation loss: 2.5501116678911973

Epoch: 6| Step: 4
Training loss: 0.24555669948769085
Validation loss: 2.5225762267968754

Epoch: 6| Step: 5
Training loss: 0.2384552398571859
Validation loss: 2.4724704346216884

Epoch: 6| Step: 6
Training loss: 0.30032080544569
Validation loss: 2.5013537792037326

Epoch: 6| Step: 7
Training loss: 0.23366258748791144
Validation loss: 2.4923311013995564

Epoch: 6| Step: 8
Training loss: 0.26274706816375976
Validation loss: 2.4353226885966412

Epoch: 6| Step: 9
Training loss: 0.17097603807201142
Validation loss: 2.502254372046823

Epoch: 6| Step: 10
Training loss: 0.25669185237478004
Validation loss: 2.5175350944830632

Epoch: 6| Step: 11
Training loss: 0.2817099968581294
Validation loss: 2.510485877967652

Epoch: 6| Step: 12
Training loss: 0.16593740527910017
Validation loss: 2.5183376147185483

Epoch: 6| Step: 13
Training loss: 0.09235119349111727
Validation loss: 2.504367774252297

Epoch: 387| Step: 0
Training loss: 0.24604945313947743
Validation loss: 2.4723781987997264

Epoch: 6| Step: 1
Training loss: 0.18326790280536076
Validation loss: 2.4397671307930144

Epoch: 6| Step: 2
Training loss: 0.208425737789743
Validation loss: 2.4533012979421307

Epoch: 6| Step: 3
Training loss: 0.2065902096807521
Validation loss: 2.4626642870201154

Epoch: 6| Step: 4
Training loss: 0.3154949439606382
Validation loss: 2.471420116217369

Epoch: 6| Step: 5
Training loss: 0.21629367888892548
Validation loss: 2.4796941822800758

Epoch: 6| Step: 6
Training loss: 0.20474157419905067
Validation loss: 2.500166736703076

Epoch: 6| Step: 7
Training loss: 0.27856040102446267
Validation loss: 2.4842395096713843

Epoch: 6| Step: 8
Training loss: 0.19113178426753266
Validation loss: 2.4728154252359555

Epoch: 6| Step: 9
Training loss: 0.15930942794633404
Validation loss: 2.4429738194569377

Epoch: 6| Step: 10
Training loss: 0.3168418146848055
Validation loss: 2.4464040872173993

Epoch: 6| Step: 11
Training loss: 0.11395391985554441
Validation loss: 2.44072709492579

Epoch: 6| Step: 12
Training loss: 0.2779408059272053
Validation loss: 2.467859897197608

Epoch: 6| Step: 13
Training loss: 0.10717618763009577
Validation loss: 2.4988901792288387

Epoch: 388| Step: 0
Training loss: 0.1335683519637091
Validation loss: 2.4789604383194046

Epoch: 6| Step: 1
Training loss: 0.22936947565156507
Validation loss: 2.487827218326446

Epoch: 6| Step: 2
Training loss: 0.2639625642362642
Validation loss: 2.5021716745244262

Epoch: 6| Step: 3
Training loss: 0.15901938950276195
Validation loss: 2.5003219233149947

Epoch: 6| Step: 4
Training loss: 0.10325817265851456
Validation loss: 2.4943741070398313

Epoch: 6| Step: 5
Training loss: 0.2459235738279563
Validation loss: 2.488335881330782

Epoch: 6| Step: 6
Training loss: 0.16021665155194656
Validation loss: 2.4706446525817065

Epoch: 6| Step: 7
Training loss: 0.20043011363639726
Validation loss: 2.4944504763093933

Epoch: 6| Step: 8
Training loss: 0.2946909575193773
Validation loss: 2.467911055005213

Epoch: 6| Step: 9
Training loss: 0.2710837832330941
Validation loss: 2.4762984660705825

Epoch: 6| Step: 10
Training loss: 0.10611668876682968
Validation loss: 2.514711931101857

Epoch: 6| Step: 11
Training loss: 0.23342588893708452
Validation loss: 2.547852544799646

Epoch: 6| Step: 12
Training loss: 0.13771471603792312
Validation loss: 2.5487736939237573

Epoch: 6| Step: 13
Training loss: 0.168631278325521
Validation loss: 2.572330033498046

Epoch: 389| Step: 0
Training loss: 0.20863123496208594
Validation loss: 2.49561794841106

Epoch: 6| Step: 1
Training loss: 0.20248913273673796
Validation loss: 2.485500323069916

Epoch: 6| Step: 2
Training loss: 0.1517414879579735
Validation loss: 2.436920753481673

Epoch: 6| Step: 3
Training loss: 0.16760970153840796
Validation loss: 2.4645359339906423

Epoch: 6| Step: 4
Training loss: 0.16078922746847354
Validation loss: 2.467861908335377

Epoch: 6| Step: 5
Training loss: 0.3666835735859204
Validation loss: 2.4523824959694718

Epoch: 6| Step: 6
Training loss: 0.2940953274280131
Validation loss: 2.5295249259365735

Epoch: 6| Step: 7
Training loss: 0.1576500278186441
Validation loss: 2.511344502989656

Epoch: 6| Step: 8
Training loss: 0.19745919201359577
Validation loss: 2.5375356309095447

Epoch: 6| Step: 9
Training loss: 0.17782340073316183
Validation loss: 2.5928496977563964

Epoch: 6| Step: 10
Training loss: 0.2272308783853334
Validation loss: 2.6120828842626915

Epoch: 6| Step: 11
Training loss: 0.2013574873533179
Validation loss: 2.5467680578920273

Epoch: 6| Step: 12
Training loss: 0.1696567549874531
Validation loss: 2.557118830637823

Epoch: 6| Step: 13
Training loss: 0.1136343279501795
Validation loss: 2.529226454141175

Epoch: 390| Step: 0
Training loss: 0.29286877515790255
Validation loss: 2.4591475798656153

Epoch: 6| Step: 1
Training loss: 0.27360521350244865
Validation loss: 2.458990892038717

Epoch: 6| Step: 2
Training loss: 0.20898794901991433
Validation loss: 2.403131129750953

Epoch: 6| Step: 3
Training loss: 0.2025326932900706
Validation loss: 2.4396821375647226

Epoch: 6| Step: 4
Training loss: 0.21248850335549016
Validation loss: 2.472592359718355

Epoch: 6| Step: 5
Training loss: 0.18547924214535486
Validation loss: 2.515440490086992

Epoch: 6| Step: 6
Training loss: 0.273273814118185
Validation loss: 2.5094427453383332

Epoch: 6| Step: 7
Training loss: 0.20218457253767402
Validation loss: 2.5531576557806974

Epoch: 6| Step: 8
Training loss: 0.12709436629300455
Validation loss: 2.537740264482398

Epoch: 6| Step: 9
Training loss: 0.20560562774457825
Validation loss: 2.487404398596809

Epoch: 6| Step: 10
Training loss: 0.18186763196289726
Validation loss: 2.4437786104711456

Epoch: 6| Step: 11
Training loss: 0.2161563311559181
Validation loss: 2.4232968816986125

Epoch: 6| Step: 12
Training loss: 0.18060540974119865
Validation loss: 2.428399150549697

Epoch: 6| Step: 13
Training loss: 0.1712319090608468
Validation loss: 2.4464554097063624

Epoch: 391| Step: 0
Training loss: 0.2389652097860572
Validation loss: 2.4642262943028457

Epoch: 6| Step: 1
Training loss: 0.12767658238643223
Validation loss: 2.4473280437016314

Epoch: 6| Step: 2
Training loss: 0.20120607474273272
Validation loss: 2.5103596526939147

Epoch: 6| Step: 3
Training loss: 0.20095752666692984
Validation loss: 2.5036600638934243

Epoch: 6| Step: 4
Training loss: 0.22565992388859996
Validation loss: 2.4612861194952904

Epoch: 6| Step: 5
Training loss: 0.12577626473161152
Validation loss: 2.445410389339664

Epoch: 6| Step: 6
Training loss: 0.2598771451042271
Validation loss: 2.473358420068521

Epoch: 6| Step: 7
Training loss: 0.16430835808002317
Validation loss: 2.508530486986281

Epoch: 6| Step: 8
Training loss: 0.17544343064234832
Validation loss: 2.5247464163426274

Epoch: 6| Step: 9
Training loss: 0.28814443220696523
Validation loss: 2.5348135038661326

Epoch: 6| Step: 10
Training loss: 0.2139944629721598
Validation loss: 2.5502297623851176

Epoch: 6| Step: 11
Training loss: 0.15345547422221434
Validation loss: 2.577098480237661

Epoch: 6| Step: 12
Training loss: 0.20905320647243358
Validation loss: 2.5886509363185706

Epoch: 6| Step: 13
Training loss: 0.10304209074810951
Validation loss: 2.6017567650339073

Epoch: 392| Step: 0
Training loss: 0.1719552632969721
Validation loss: 2.5793739294280202

Epoch: 6| Step: 1
Training loss: 0.16677681380153203
Validation loss: 2.5643375940117914

Epoch: 6| Step: 2
Training loss: 0.19479956028663956
Validation loss: 2.5414046580828518

Epoch: 6| Step: 3
Training loss: 0.2495564459857679
Validation loss: 2.538314188574882

Epoch: 6| Step: 4
Training loss: 0.29301047981613493
Validation loss: 2.515290458893825

Epoch: 6| Step: 5
Training loss: 0.30209026109490633
Validation loss: 2.544267374027255

Epoch: 6| Step: 6
Training loss: 0.22458303545883138
Validation loss: 2.571722881528491

Epoch: 6| Step: 7
Training loss: 0.12872012023122376
Validation loss: 2.590449314965451

Epoch: 6| Step: 8
Training loss: 0.18608441038741086
Validation loss: 2.6488837080619203

Epoch: 6| Step: 9
Training loss: 0.2123198952092988
Validation loss: 2.64400160712285

Epoch: 6| Step: 10
Training loss: 0.17031957410417234
Validation loss: 2.601141940500936

Epoch: 6| Step: 11
Training loss: 0.27391403091442235
Validation loss: 2.5197792469813933

Epoch: 6| Step: 12
Training loss: 0.18771623024504355
Validation loss: 2.482559352749698

Epoch: 6| Step: 13
Training loss: 0.1377579769634796
Validation loss: 2.4999607985509638

Epoch: 393| Step: 0
Training loss: 0.1918752723716766
Validation loss: 2.448536406442364

Epoch: 6| Step: 1
Training loss: 0.28828702471151846
Validation loss: 2.5191132926558826

Epoch: 6| Step: 2
Training loss: 0.18130121000920288
Validation loss: 2.5382591906553262

Epoch: 6| Step: 3
Training loss: 0.17901385540323567
Validation loss: 2.5351343617076694

Epoch: 6| Step: 4
Training loss: 0.10432250961564568
Validation loss: 2.5937673333650513

Epoch: 6| Step: 5
Training loss: 0.23180477379589037
Validation loss: 2.6278437491567344

Epoch: 6| Step: 6
Training loss: 0.326217568217875
Validation loss: 2.6213566194215914

Epoch: 6| Step: 7
Training loss: 0.18078708068887653
Validation loss: 2.5934296830372325

Epoch: 6| Step: 8
Training loss: 0.2803081796625756
Validation loss: 2.5456567756396558

Epoch: 6| Step: 9
Training loss: 0.22918411842277422
Validation loss: 2.4285168826481227

Epoch: 6| Step: 10
Training loss: 0.16529310864471136
Validation loss: 2.4179365991648996

Epoch: 6| Step: 11
Training loss: 0.20360975010872243
Validation loss: 2.382115229207011

Epoch: 6| Step: 12
Training loss: 0.26582162255518615
Validation loss: 2.391835879156454

Epoch: 6| Step: 13
Training loss: 0.36389381282611855
Validation loss: 2.3876927356465742

Epoch: 394| Step: 0
Training loss: 0.18275361906100213
Validation loss: 2.4113914196789774

Epoch: 6| Step: 1
Training loss: 0.1543339008862154
Validation loss: 2.4333628938688414

Epoch: 6| Step: 2
Training loss: 0.100254183013968
Validation loss: 2.4917255150472983

Epoch: 6| Step: 3
Training loss: 0.3177833377395551
Validation loss: 2.519754321407994

Epoch: 6| Step: 4
Training loss: 0.2149858698249182
Validation loss: 2.5863920805538085

Epoch: 6| Step: 5
Training loss: 0.3116631030365155
Validation loss: 2.606820879215865

Epoch: 6| Step: 6
Training loss: 0.18345982150946294
Validation loss: 2.5590864626259364

Epoch: 6| Step: 7
Training loss: 0.1818208313269362
Validation loss: 2.546608581841594

Epoch: 6| Step: 8
Training loss: 0.17627881942328485
Validation loss: 2.5168820395017097

Epoch: 6| Step: 9
Training loss: 0.21683832579932844
Validation loss: 2.465373671189588

Epoch: 6| Step: 10
Training loss: 0.1922819289386579
Validation loss: 2.436842865312867

Epoch: 6| Step: 11
Training loss: 0.19239268785875047
Validation loss: 2.456180118269232

Epoch: 6| Step: 12
Training loss: 0.2981481857400699
Validation loss: 2.4268572245727755

Epoch: 6| Step: 13
Training loss: 0.08283268181028841
Validation loss: 2.4772676443742148

Epoch: 395| Step: 0
Training loss: 0.1754135046820805
Validation loss: 2.500417497085891

Epoch: 6| Step: 1
Training loss: 0.12561727640027953
Validation loss: 2.5080473904235516

Epoch: 6| Step: 2
Training loss: 0.22398993450299828
Validation loss: 2.557096920305136

Epoch: 6| Step: 3
Training loss: 0.21003610906498524
Validation loss: 2.5258616677739796

Epoch: 6| Step: 4
Training loss: 0.24084854702981465
Validation loss: 2.4832877304689402

Epoch: 6| Step: 5
Training loss: 0.2875338549998127
Validation loss: 2.511007944382588

Epoch: 6| Step: 6
Training loss: 0.2196219385923767
Validation loss: 2.4841614565194887

Epoch: 6| Step: 7
Training loss: 0.17435699545977185
Validation loss: 2.462974876671203

Epoch: 6| Step: 8
Training loss: 0.2878418615857182
Validation loss: 2.476772028403326

Epoch: 6| Step: 9
Training loss: 0.13879688430935547
Validation loss: 2.4510037810882355

Epoch: 6| Step: 10
Training loss: 0.180326631246815
Validation loss: 2.4552617013358247

Epoch: 6| Step: 11
Training loss: 0.14954872545431266
Validation loss: 2.4619396121977726

Epoch: 6| Step: 12
Training loss: 0.1305726026321528
Validation loss: 2.4829642527069677

Epoch: 6| Step: 13
Training loss: 0.2638005684334933
Validation loss: 2.485505276032485

Epoch: 396| Step: 0
Training loss: 0.2189241550510058
Validation loss: 2.5110346842240627

Epoch: 6| Step: 1
Training loss: 0.15639708272037625
Validation loss: 2.481824038211063

Epoch: 6| Step: 2
Training loss: 0.17240879225261027
Validation loss: 2.432366881556166

Epoch: 6| Step: 3
Training loss: 0.15703816707047033
Validation loss: 2.4219912254663183

Epoch: 6| Step: 4
Training loss: 0.20340721076284815
Validation loss: 2.4006256322495223

Epoch: 6| Step: 5
Training loss: 0.1368963926724575
Validation loss: 2.4070791651870653

Epoch: 6| Step: 6
Training loss: 0.13591561799031707
Validation loss: 2.421841861261286

Epoch: 6| Step: 7
Training loss: 0.23115348928447305
Validation loss: 2.41612348580115

Epoch: 6| Step: 8
Training loss: 0.19313511221685276
Validation loss: 2.4524029620864063

Epoch: 6| Step: 9
Training loss: 0.1817072264280357
Validation loss: 2.4448424879007016

Epoch: 6| Step: 10
Training loss: 0.12301453664989398
Validation loss: 2.448496838590398

Epoch: 6| Step: 11
Training loss: 0.2099110300054527
Validation loss: 2.452005572343295

Epoch: 6| Step: 12
Training loss: 0.07224644586869702
Validation loss: 2.464085205184928

Epoch: 6| Step: 13
Training loss: 0.455769402680524
Validation loss: 2.4486072041945053

Epoch: 397| Step: 0
Training loss: 0.100831906946329
Validation loss: 2.441020067743087

Epoch: 6| Step: 1
Training loss: 0.21710544826968908
Validation loss: 2.445161741095792

Epoch: 6| Step: 2
Training loss: 0.1609794985497178
Validation loss: 2.429794543404729

Epoch: 6| Step: 3
Training loss: 0.29287767902130735
Validation loss: 2.4374530978090636

Epoch: 6| Step: 4
Training loss: 0.10588392909003128
Validation loss: 2.4166198993976606

Epoch: 6| Step: 5
Training loss: 0.22690754956449993
Validation loss: 2.423009833481972

Epoch: 6| Step: 6
Training loss: 0.12775126966687197
Validation loss: 2.445980607295424

Epoch: 6| Step: 7
Training loss: 0.24586190549980388
Validation loss: 2.471234445455466

Epoch: 6| Step: 8
Training loss: 0.20596712068721565
Validation loss: 2.4781035396965345

Epoch: 6| Step: 9
Training loss: 0.2056440446898423
Validation loss: 2.4964082542772625

Epoch: 6| Step: 10
Training loss: 0.2703384805883871
Validation loss: 2.4825646048547343

Epoch: 6| Step: 11
Training loss: 0.08566890269746152
Validation loss: 2.510038672564654

Epoch: 6| Step: 12
Training loss: 0.24245293745557403
Validation loss: 2.5262554814424427

Epoch: 6| Step: 13
Training loss: 0.2896791787788757
Validation loss: 2.53709969859003

Epoch: 398| Step: 0
Training loss: 0.20933746207782386
Validation loss: 2.5118121458623346

Epoch: 6| Step: 1
Training loss: 0.17383633819207478
Validation loss: 2.4881906429636835

Epoch: 6| Step: 2
Training loss: 0.19754878579352866
Validation loss: 2.5281404724625167

Epoch: 6| Step: 3
Training loss: 0.1941239048533305
Validation loss: 2.529691332495118

Epoch: 6| Step: 4
Training loss: 0.12337882437015611
Validation loss: 2.524610905359161

Epoch: 6| Step: 5
Training loss: 0.23323294226921354
Validation loss: 2.5151709675054903

Epoch: 6| Step: 6
Training loss: 0.13826846155202838
Validation loss: 2.4813636860987476

Epoch: 6| Step: 7
Training loss: 0.24118956961563048
Validation loss: 2.4570051567765456

Epoch: 6| Step: 8
Training loss: 0.1664738390223271
Validation loss: 2.4909468795584524

Epoch: 6| Step: 9
Training loss: 0.37587314521019843
Validation loss: 2.4757208871333676

Epoch: 6| Step: 10
Training loss: 0.13574586492812643
Validation loss: 2.4747054424743147

Epoch: 6| Step: 11
Training loss: 0.08282994118149162
Validation loss: 2.4510526413616907

Epoch: 6| Step: 12
Training loss: 0.17154234968471346
Validation loss: 2.462827828348619

Epoch: 6| Step: 13
Training loss: 0.14677629629079905
Validation loss: 2.4557866656636893

Epoch: 399| Step: 0
Training loss: 0.21791544163239845
Validation loss: 2.4639418252129768

Epoch: 6| Step: 1
Training loss: 0.293025252933489
Validation loss: 2.500895191218485

Epoch: 6| Step: 2
Training loss: 0.22102285535790392
Validation loss: 2.5468577511382806

Epoch: 6| Step: 3
Training loss: 0.16915474848113435
Validation loss: 2.5805215877606567

Epoch: 6| Step: 4
Training loss: 0.18488479746984712
Validation loss: 2.5191095822071827

Epoch: 6| Step: 5
Training loss: 0.24708317357541132
Validation loss: 2.491292537622849

Epoch: 6| Step: 6
Training loss: 0.08602211319674272
Validation loss: 2.4402732439020984

Epoch: 6| Step: 7
Training loss: 0.1451934773080533
Validation loss: 2.4440834027999916

Epoch: 6| Step: 8
Training loss: 0.2474985971675959
Validation loss: 2.402080954707664

Epoch: 6| Step: 9
Training loss: 0.2020650405977754
Validation loss: 2.438622503596622

Epoch: 6| Step: 10
Training loss: 0.16058376287585333
Validation loss: 2.4983637982650393

Epoch: 6| Step: 11
Training loss: 0.16108644569739
Validation loss: 2.4758420029239123

Epoch: 6| Step: 12
Training loss: 0.20116647694576653
Validation loss: 2.4772236476804865

Epoch: 6| Step: 13
Training loss: 0.153291863638824
Validation loss: 2.4720089089394066

Epoch: 400| Step: 0
Training loss: 0.2943113462304397
Validation loss: 2.4983029748233614

Epoch: 6| Step: 1
Training loss: 0.17373243655655124
Validation loss: 2.5208904161925165

Epoch: 6| Step: 2
Training loss: 0.21393613705436343
Validation loss: 2.5074434036572826

Epoch: 6| Step: 3
Training loss: 0.16544145139191418
Validation loss: 2.5048016489731393

Epoch: 6| Step: 4
Training loss: 0.23792888822219316
Validation loss: 2.473134500651868

Epoch: 6| Step: 5
Training loss: 0.17943627998763753
Validation loss: 2.43645026997026

Epoch: 6| Step: 6
Training loss: 0.20991865220202904
Validation loss: 2.4277452114497193

Epoch: 6| Step: 7
Training loss: 0.10995416908370166
Validation loss: 2.411560343652456

Epoch: 6| Step: 8
Training loss: 0.11416413877016444
Validation loss: 2.442658635325767

Epoch: 6| Step: 9
Training loss: 0.18030167396744745
Validation loss: 2.4515000408690684

Epoch: 6| Step: 10
Training loss: 0.1419497451421849
Validation loss: 2.45058418003653

Epoch: 6| Step: 11
Training loss: 0.1290948600587419
Validation loss: 2.471137551075389

Epoch: 6| Step: 12
Training loss: 0.11317117868156844
Validation loss: 2.489817992660575

Epoch: 6| Step: 13
Training loss: 0.1600929111746906
Validation loss: 2.4686328241742443

Epoch: 401| Step: 0
Training loss: 0.20751841825298958
Validation loss: 2.4594577458550675

Epoch: 6| Step: 1
Training loss: 0.06996388571856771
Validation loss: 2.4773152441415993

Epoch: 6| Step: 2
Training loss: 0.12067780661239288
Validation loss: 2.439787082782994

Epoch: 6| Step: 3
Training loss: 0.12575976620701845
Validation loss: 2.43701844445167

Epoch: 6| Step: 4
Training loss: 0.0970998889758318
Validation loss: 2.4730993328554685

Epoch: 6| Step: 5
Training loss: 0.09795607317505299
Validation loss: 2.483732871502463

Epoch: 6| Step: 6
Training loss: 0.12896231674683434
Validation loss: 2.475780401479945

Epoch: 6| Step: 7
Training loss: 0.08144032991385922
Validation loss: 2.4668904106857443

Epoch: 6| Step: 8
Training loss: 0.2099880023634196
Validation loss: 2.4711217239407293

Epoch: 6| Step: 9
Training loss: 0.24862922432131507
Validation loss: 2.4369206419696705

Epoch: 6| Step: 10
Training loss: 0.08521205960940285
Validation loss: 2.4214553914090535

Epoch: 6| Step: 11
Training loss: 0.28805634944720127
Validation loss: 2.417245648500779

Epoch: 6| Step: 12
Training loss: 0.2538606309256846
Validation loss: 2.4050079368771775

Epoch: 6| Step: 13
Training loss: 0.2158498441764529
Validation loss: 2.434390883604739

Epoch: 402| Step: 0
Training loss: 0.12627058685168327
Validation loss: 2.4345795168923807

Epoch: 6| Step: 1
Training loss: 0.07662725349946704
Validation loss: 2.4492147986374664

Epoch: 6| Step: 2
Training loss: 0.17553075319966566
Validation loss: 2.4722854514303516

Epoch: 6| Step: 3
Training loss: 0.16790853574351766
Validation loss: 2.4821211500887754

Epoch: 6| Step: 4
Training loss: 0.09588967844629691
Validation loss: 2.4558315046769827

Epoch: 6| Step: 5
Training loss: 0.10279422075747485
Validation loss: 2.4564067854934715

Epoch: 6| Step: 6
Training loss: 0.12415537987151377
Validation loss: 2.451916569106114

Epoch: 6| Step: 7
Training loss: 0.29917085229359464
Validation loss: 2.4326428963057887

Epoch: 6| Step: 8
Training loss: 0.14452809253027377
Validation loss: 2.430941922076137

Epoch: 6| Step: 9
Training loss: 0.2265609050563051
Validation loss: 2.436836705648202

Epoch: 6| Step: 10
Training loss: 0.16598861699041964
Validation loss: 2.413348221194442

Epoch: 6| Step: 11
Training loss: 0.2045189636829949
Validation loss: 2.4301754051710494

Epoch: 6| Step: 12
Training loss: 0.24657310998471324
Validation loss: 2.4465543085098034

Epoch: 6| Step: 13
Training loss: 0.09712221995171262
Validation loss: 2.4927978827685884

Epoch: 403| Step: 0
Training loss: 0.22595737478022543
Validation loss: 2.485457216819831

Epoch: 6| Step: 1
Training loss: 0.13726503361209275
Validation loss: 2.4876309527377076

Epoch: 6| Step: 2
Training loss: 0.15242312881994224
Validation loss: 2.4763101832429926

Epoch: 6| Step: 3
Training loss: 0.22677272054342262
Validation loss: 2.5005703121756033

Epoch: 6| Step: 4
Training loss: 0.06214065738631094
Validation loss: 2.4887261988617304

Epoch: 6| Step: 5
Training loss: 0.12319700981837003
Validation loss: 2.500749115842641

Epoch: 6| Step: 6
Training loss: 0.3326655220040394
Validation loss: 2.471586870354405

Epoch: 6| Step: 7
Training loss: 0.16216275473814087
Validation loss: 2.4513446237936916

Epoch: 6| Step: 8
Training loss: 0.1266693170744942
Validation loss: 2.4599279778206435

Epoch: 6| Step: 9
Training loss: 0.20949015510934646
Validation loss: 2.466438362821788

Epoch: 6| Step: 10
Training loss: 0.13475018564876726
Validation loss: 2.462916408136901

Epoch: 6| Step: 11
Training loss: 0.17179390771583608
Validation loss: 2.4273483601353765

Epoch: 6| Step: 12
Training loss: 0.12022842126027052
Validation loss: 2.4560051271680963

Epoch: 6| Step: 13
Training loss: 0.26856571521658756
Validation loss: 2.464201726479859

Epoch: 404| Step: 0
Training loss: 0.219667367378959
Validation loss: 2.4610253925973473

Epoch: 6| Step: 1
Training loss: 0.16103387164730706
Validation loss: 2.484884269609161

Epoch: 6| Step: 2
Training loss: 0.2893621206404097
Validation loss: 2.4801046662203547

Epoch: 6| Step: 3
Training loss: 0.1394202629072252
Validation loss: 2.4583792285031225

Epoch: 6| Step: 4
Training loss: 0.2746282400105917
Validation loss: 2.4427126901847793

Epoch: 6| Step: 5
Training loss: 0.09187874288460507
Validation loss: 2.451489150993234

Epoch: 6| Step: 6
Training loss: 0.1378471943700182
Validation loss: 2.4286766000174627

Epoch: 6| Step: 7
Training loss: 0.09769570507289467
Validation loss: 2.4118978792170904

Epoch: 6| Step: 8
Training loss: 0.2083104399182363
Validation loss: 2.3871633576984945

Epoch: 6| Step: 9
Training loss: 0.21129727587936548
Validation loss: 2.402776044262125

Epoch: 6| Step: 10
Training loss: 0.16959821635350886
Validation loss: 2.416659510209036

Epoch: 6| Step: 11
Training loss: 0.22757516009792264
Validation loss: 2.423541577108166

Epoch: 6| Step: 12
Training loss: 0.11435449210514614
Validation loss: 2.410356442657078

Epoch: 6| Step: 13
Training loss: 0.1258190042095507
Validation loss: 2.4560204849237954

Epoch: 405| Step: 0
Training loss: 0.09536013155653798
Validation loss: 2.458964557925092

Epoch: 6| Step: 1
Training loss: 0.20505538087699204
Validation loss: 2.4825254497622438

Epoch: 6| Step: 2
Training loss: 0.13736054463171157
Validation loss: 2.485859961706294

Epoch: 6| Step: 3
Training loss: 0.15536320089052746
Validation loss: 2.470799245784074

Epoch: 6| Step: 4
Training loss: 0.3700513957386577
Validation loss: 2.4690985048769734

Epoch: 6| Step: 5
Training loss: 0.1385835312448894
Validation loss: 2.479790460607553

Epoch: 6| Step: 6
Training loss: 0.14430136698911714
Validation loss: 2.514648767302639

Epoch: 6| Step: 7
Training loss: 0.16875156693260887
Validation loss: 2.4829190415372744

Epoch: 6| Step: 8
Training loss: 0.19323644680042412
Validation loss: 2.4792593503237628

Epoch: 6| Step: 9
Training loss: 0.09283312333209229
Validation loss: 2.4533811014506512

Epoch: 6| Step: 10
Training loss: 0.14818649653171823
Validation loss: 2.4255436120408844

Epoch: 6| Step: 11
Training loss: 0.14586876257184514
Validation loss: 2.4339026490427305

Epoch: 6| Step: 12
Training loss: 0.2028578046238278
Validation loss: 2.4070923237461757

Epoch: 6| Step: 13
Training loss: 0.15619414046292424
Validation loss: 2.4017649865395443

Epoch: 406| Step: 0
Training loss: 0.2511684114920398
Validation loss: 2.4063152138724218

Epoch: 6| Step: 1
Training loss: 0.14438367732917942
Validation loss: 2.3998297924099328

Epoch: 6| Step: 2
Training loss: 0.18118181014691723
Validation loss: 2.38871045478431

Epoch: 6| Step: 3
Training loss: 0.28721405248999776
Validation loss: 2.4134452028724116

Epoch: 6| Step: 4
Training loss: 0.11647087965631038
Validation loss: 2.467111839718878

Epoch: 6| Step: 5
Training loss: 0.1137460676236635
Validation loss: 2.4877334730753566

Epoch: 6| Step: 6
Training loss: 0.20343179642025752
Validation loss: 2.526765891356919

Epoch: 6| Step: 7
Training loss: 0.24986299843803078
Validation loss: 2.518294628737344

Epoch: 6| Step: 8
Training loss: 0.1415774752420205
Validation loss: 2.5255188057773204

Epoch: 6| Step: 9
Training loss: 0.18345086645268469
Validation loss: 2.540239923815157

Epoch: 6| Step: 10
Training loss: 0.2052705770015584
Validation loss: 2.5244592738861797

Epoch: 6| Step: 11
Training loss: 0.12185629584986638
Validation loss: 2.4945940841218723

Epoch: 6| Step: 12
Training loss: 0.11272768302797845
Validation loss: 2.517208025988477

Epoch: 6| Step: 13
Training loss: 0.1555662333552758
Validation loss: 2.4815681721771123

Epoch: 407| Step: 0
Training loss: 0.2081399775319524
Validation loss: 2.43914077043654

Epoch: 6| Step: 1
Training loss: 0.1349653753939405
Validation loss: 2.431888289082313

Epoch: 6| Step: 2
Training loss: 0.2876501893540039
Validation loss: 2.4351093462938374

Epoch: 6| Step: 3
Training loss: 0.23788623429930295
Validation loss: 2.402051612931941

Epoch: 6| Step: 4
Training loss: 0.20155102453167778
Validation loss: 2.407859127306596

Epoch: 6| Step: 5
Training loss: 0.2393834698849397
Validation loss: 2.39825285678847

Epoch: 6| Step: 6
Training loss: 0.14186496570997886
Validation loss: 2.462116680478131

Epoch: 6| Step: 7
Training loss: 0.1113515586617502
Validation loss: 2.5207242987034326

Epoch: 6| Step: 8
Training loss: 0.10515377023332231
Validation loss: 2.5334310474384236

Epoch: 6| Step: 9
Training loss: 0.2179756679599274
Validation loss: 2.5793584265238674

Epoch: 6| Step: 10
Training loss: 0.10534865111167302
Validation loss: 2.57655786171478

Epoch: 6| Step: 11
Training loss: 0.21608711597964367
Validation loss: 2.5709824379540964

Epoch: 6| Step: 12
Training loss: 0.22775842464392107
Validation loss: 2.4837339532189517

Epoch: 6| Step: 13
Training loss: 0.3064563829453723
Validation loss: 2.4766750049407915

Epoch: 408| Step: 0
Training loss: 0.23391275121640392
Validation loss: 2.4533623384026884

Epoch: 6| Step: 1
Training loss: 0.21192409122486394
Validation loss: 2.4174369582267934

Epoch: 6| Step: 2
Training loss: 0.3033216010936476
Validation loss: 2.4088212099401103

Epoch: 6| Step: 3
Training loss: 0.17763795438046276
Validation loss: 2.437393454344203

Epoch: 6| Step: 4
Training loss: 0.17647794834237754
Validation loss: 2.4442104841822885

Epoch: 6| Step: 5
Training loss: 0.16838368463810285
Validation loss: 2.484676768675634

Epoch: 6| Step: 6
Training loss: 0.223504241898838
Validation loss: 2.5118009719375043

Epoch: 6| Step: 7
Training loss: 0.14214844822392184
Validation loss: 2.474752774532621

Epoch: 6| Step: 8
Training loss: 0.3114105546254697
Validation loss: 2.529055468131599

Epoch: 6| Step: 9
Training loss: 0.23316134297374186
Validation loss: 2.524997827290782

Epoch: 6| Step: 10
Training loss: 0.14216345751460138
Validation loss: 2.4795159720904993

Epoch: 6| Step: 11
Training loss: 0.13770046630304622
Validation loss: 2.426416484962289

Epoch: 6| Step: 12
Training loss: 0.13969319299963417
Validation loss: 2.4049448714982726

Epoch: 6| Step: 13
Training loss: 0.10293479577405305
Validation loss: 2.3751285641775617

Epoch: 409| Step: 0
Training loss: 0.2310682678101237
Validation loss: 2.3975845909522855

Epoch: 6| Step: 1
Training loss: 0.1356982564848929
Validation loss: 2.383455331997091

Epoch: 6| Step: 2
Training loss: 0.12229058799993617
Validation loss: 2.4631789363022563

Epoch: 6| Step: 3
Training loss: 0.11774128163335815
Validation loss: 2.4906435752177316

Epoch: 6| Step: 4
Training loss: 0.24589244238322494
Validation loss: 2.510686181248977

Epoch: 6| Step: 5
Training loss: 0.249213770514701
Validation loss: 2.5021646470146868

Epoch: 6| Step: 6
Training loss: 0.2944166390517699
Validation loss: 2.4791393352631332

Epoch: 6| Step: 7
Training loss: 0.12744877234908136
Validation loss: 2.4899616864422867

Epoch: 6| Step: 8
Training loss: 0.23497642599221663
Validation loss: 2.4755539174921752

Epoch: 6| Step: 9
Training loss: 0.20721904766180468
Validation loss: 2.4508640165430227

Epoch: 6| Step: 10
Training loss: 0.16754645112729424
Validation loss: 2.4598633317335987

Epoch: 6| Step: 11
Training loss: 0.18274794196706465
Validation loss: 2.4488205022439398

Epoch: 6| Step: 12
Training loss: 0.11504869938820453
Validation loss: 2.4955292606694592

Epoch: 6| Step: 13
Training loss: 0.2223629525525223
Validation loss: 2.545401328962478

Epoch: 410| Step: 0
Training loss: 0.14850577867106513
Validation loss: 2.517958150994207

Epoch: 6| Step: 1
Training loss: 0.2457537345738289
Validation loss: 2.465233523348928

Epoch: 6| Step: 2
Training loss: 0.21325370904194596
Validation loss: 2.4713637592996505

Epoch: 6| Step: 3
Training loss: 0.18696306756151443
Validation loss: 2.416202255671188

Epoch: 6| Step: 4
Training loss: 0.11891982458479884
Validation loss: 2.387086064803277

Epoch: 6| Step: 5
Training loss: 0.15058026185577364
Validation loss: 2.420828133547956

Epoch: 6| Step: 6
Training loss: 0.12619677968076515
Validation loss: 2.4398295280288935

Epoch: 6| Step: 7
Training loss: 0.135284475459479
Validation loss: 2.431680377520449

Epoch: 6| Step: 8
Training loss: 0.18848094045663774
Validation loss: 2.4445431963729627

Epoch: 6| Step: 9
Training loss: 0.25220612827028005
Validation loss: 2.4394993119663155

Epoch: 6| Step: 10
Training loss: 0.23533321641510696
Validation loss: 2.4533012007593737

Epoch: 6| Step: 11
Training loss: 0.11953397604383162
Validation loss: 2.477826887641124

Epoch: 6| Step: 12
Training loss: 0.1375086513420229
Validation loss: 2.4320279930354385

Epoch: 6| Step: 13
Training loss: 0.24782062334405736
Validation loss: 2.507247262570861

Epoch: 411| Step: 0
Training loss: 0.1733204468096182
Validation loss: 2.5097003402061864

Epoch: 6| Step: 1
Training loss: 0.23555780609982468
Validation loss: 2.4913521656834914

Epoch: 6| Step: 2
Training loss: 0.25969633454628677
Validation loss: 2.5248298335478365

Epoch: 6| Step: 3
Training loss: 0.19849334741922314
Validation loss: 2.5150526742559247

Epoch: 6| Step: 4
Training loss: 0.21039725810578755
Validation loss: 2.54327871062567

Epoch: 6| Step: 5
Training loss: 0.10859273560139393
Validation loss: 2.5143718335660945

Epoch: 6| Step: 6
Training loss: 0.1595679503584691
Validation loss: 2.4903533221249585

Epoch: 6| Step: 7
Training loss: 0.1655224712183558
Validation loss: 2.4460929834105753

Epoch: 6| Step: 8
Training loss: 0.1510492246205728
Validation loss: 2.447026482089481

Epoch: 6| Step: 9
Training loss: 0.15321969417823394
Validation loss: 2.423178379694836

Epoch: 6| Step: 10
Training loss: 0.2539220951711512
Validation loss: 2.417316048955085

Epoch: 6| Step: 11
Training loss: 0.09593756337893751
Validation loss: 2.425648447104735

Epoch: 6| Step: 12
Training loss: 0.1700323666411634
Validation loss: 2.4348276759284886

Epoch: 6| Step: 13
Training loss: 0.11500963424023404
Validation loss: 2.450896463714945

Epoch: 412| Step: 0
Training loss: 0.26407304550873384
Validation loss: 2.4613216987669695

Epoch: 6| Step: 1
Training loss: 0.2253892214250414
Validation loss: 2.4932568187674526

Epoch: 6| Step: 2
Training loss: 0.10225234135556285
Validation loss: 2.496091768798473

Epoch: 6| Step: 3
Training loss: 0.19804268932245694
Validation loss: 2.493612964890844

Epoch: 6| Step: 4
Training loss: 0.13036135662163417
Validation loss: 2.4935290996811297

Epoch: 6| Step: 5
Training loss: 0.09150849863129121
Validation loss: 2.5309704386039886

Epoch: 6| Step: 6
Training loss: 0.11058343309795869
Validation loss: 2.5460957202446184

Epoch: 6| Step: 7
Training loss: 0.22545200351798617
Validation loss: 2.5628423162017713

Epoch: 6| Step: 8
Training loss: 0.1736329139820742
Validation loss: 2.542658164786147

Epoch: 6| Step: 9
Training loss: 0.21984575217825786
Validation loss: 2.512847092212257

Epoch: 6| Step: 10
Training loss: 0.17991510778530387
Validation loss: 2.5009305637211443

Epoch: 6| Step: 11
Training loss: 0.14294065475610337
Validation loss: 2.5154542441462695

Epoch: 6| Step: 12
Training loss: 0.11999213291621239
Validation loss: 2.517247328024939

Epoch: 6| Step: 13
Training loss: 0.12579093238336797
Validation loss: 2.479146603835478

Epoch: 413| Step: 0
Training loss: 0.15862512231225362
Validation loss: 2.427816665125027

Epoch: 6| Step: 1
Training loss: 0.17332018888553788
Validation loss: 2.440811709361621

Epoch: 6| Step: 2
Training loss: 0.13844351031041688
Validation loss: 2.41299877099867

Epoch: 6| Step: 3
Training loss: 0.12442346324766854
Validation loss: 2.4051577845042673

Epoch: 6| Step: 4
Training loss: 0.22566810366574735
Validation loss: 2.437805918051155

Epoch: 6| Step: 5
Training loss: 0.24634961798798752
Validation loss: 2.4395419387652106

Epoch: 6| Step: 6
Training loss: 0.25814716696521056
Validation loss: 2.4827846070614856

Epoch: 6| Step: 7
Training loss: 0.19343965963658694
Validation loss: 2.5005234662507925

Epoch: 6| Step: 8
Training loss: 0.1613251549583612
Validation loss: 2.536303454810068

Epoch: 6| Step: 9
Training loss: 0.22450209833865833
Validation loss: 2.507225721636275

Epoch: 6| Step: 10
Training loss: 0.20672802942487237
Validation loss: 2.4831498103914518

Epoch: 6| Step: 11
Training loss: 0.1350916084986351
Validation loss: 2.4704129034130644

Epoch: 6| Step: 12
Training loss: 0.10993787140753696
Validation loss: 2.4879371965552535

Epoch: 6| Step: 13
Training loss: 0.12317875198325468
Validation loss: 2.476408207568908

Epoch: 414| Step: 0
Training loss: 0.08817957956634132
Validation loss: 2.4870802968887507

Epoch: 6| Step: 1
Training loss: 0.22875641908915315
Validation loss: 2.499078662874432

Epoch: 6| Step: 2
Training loss: 0.08190239993375611
Validation loss: 2.484172842487272

Epoch: 6| Step: 3
Training loss: 0.11558093072065034
Validation loss: 2.511362573550347

Epoch: 6| Step: 4
Training loss: 0.2020805724109409
Validation loss: 2.494141196493049

Epoch: 6| Step: 5
Training loss: 0.1451812895211385
Validation loss: 2.526855888269568

Epoch: 6| Step: 6
Training loss: 0.27925877878158245
Validation loss: 2.520307626208328

Epoch: 6| Step: 7
Training loss: 0.2266855563387279
Validation loss: 2.513629188630594

Epoch: 6| Step: 8
Training loss: 0.19432566246588215
Validation loss: 2.5317777252945595

Epoch: 6| Step: 9
Training loss: 0.1600752311564124
Validation loss: 2.505802977244629

Epoch: 6| Step: 10
Training loss: 0.12416160576649188
Validation loss: 2.516070120224069

Epoch: 6| Step: 11
Training loss: 0.13307450900708365
Validation loss: 2.4747055253493286

Epoch: 6| Step: 12
Training loss: 0.10753313718213448
Validation loss: 2.4662347693448803

Epoch: 6| Step: 13
Training loss: 0.0872248920719767
Validation loss: 2.463738427084133

Epoch: 415| Step: 0
Training loss: 0.15515877430640074
Validation loss: 2.4794851943227547

Epoch: 6| Step: 1
Training loss: 0.10714036728954655
Validation loss: 2.499562774900164

Epoch: 6| Step: 2
Training loss: 0.24543512857135155
Validation loss: 2.482244553129052

Epoch: 6| Step: 3
Training loss: 0.14491928694642797
Validation loss: 2.4782952789998194

Epoch: 6| Step: 4
Training loss: 0.10494184448843619
Validation loss: 2.4546456620100052

Epoch: 6| Step: 5
Training loss: 0.13798537713603673
Validation loss: 2.4200131974478656

Epoch: 6| Step: 6
Training loss: 0.24974893092355271
Validation loss: 2.4133221443151216

Epoch: 6| Step: 7
Training loss: 0.1620612475180932
Validation loss: 2.4277979692845295

Epoch: 6| Step: 8
Training loss: 0.16556735385102944
Validation loss: 2.4576197096461363

Epoch: 6| Step: 9
Training loss: 0.1524595224196071
Validation loss: 2.449704572475698

Epoch: 6| Step: 10
Training loss: 0.2973187292640071
Validation loss: 2.4849685416033007

Epoch: 6| Step: 11
Training loss: 0.09231882137260702
Validation loss: 2.507239802457061

Epoch: 6| Step: 12
Training loss: 0.08953069484498632
Validation loss: 2.507524651390782

Epoch: 6| Step: 13
Training loss: 0.09825437007623654
Validation loss: 2.49904756964307

Epoch: 416| Step: 0
Training loss: 0.13601018672371598
Validation loss: 2.514636201638594

Epoch: 6| Step: 1
Training loss: 0.11597748556569562
Validation loss: 2.5012513387377524

Epoch: 6| Step: 2
Training loss: 0.1441785788254446
Validation loss: 2.502056806741565

Epoch: 6| Step: 3
Training loss: 0.15770704881992412
Validation loss: 2.493523560178467

Epoch: 6| Step: 4
Training loss: 0.17961992154013603
Validation loss: 2.4482135628441326

Epoch: 6| Step: 5
Training loss: 0.14477842047931946
Validation loss: 2.446469061709533

Epoch: 6| Step: 6
Training loss: 0.1896975601959887
Validation loss: 2.463362994402257

Epoch: 6| Step: 7
Training loss: 0.26597363368828214
Validation loss: 2.462270836655568

Epoch: 6| Step: 8
Training loss: 0.1969340341856841
Validation loss: 2.484031837225037

Epoch: 6| Step: 9
Training loss: 0.1953308001527991
Validation loss: 2.4690883960634644

Epoch: 6| Step: 10
Training loss: 0.23805952700177913
Validation loss: 2.518905095060969

Epoch: 6| Step: 11
Training loss: 0.12873887987400176
Validation loss: 2.472319980644338

Epoch: 6| Step: 12
Training loss: 0.1301480789642186
Validation loss: 2.4605063593824523

Epoch: 6| Step: 13
Training loss: 0.08554902923170873
Validation loss: 2.4547071316998905

Epoch: 417| Step: 0
Training loss: 0.10575694868579401
Validation loss: 2.4325248148203973

Epoch: 6| Step: 1
Training loss: 0.12172528907976984
Validation loss: 2.4295845596848635

Epoch: 6| Step: 2
Training loss: 0.1050411492562832
Validation loss: 2.413123188888363

Epoch: 6| Step: 3
Training loss: 0.18161833021278928
Validation loss: 2.397161305303524

Epoch: 6| Step: 4
Training loss: 0.10739320892706515
Validation loss: 2.41977896756673

Epoch: 6| Step: 5
Training loss: 0.1929669492073822
Validation loss: 2.4484597348375514

Epoch: 6| Step: 6
Training loss: 0.12807500753626075
Validation loss: 2.496787659231258

Epoch: 6| Step: 7
Training loss: 0.2802147355228672
Validation loss: 2.5488276039895905

Epoch: 6| Step: 8
Training loss: 0.2786030721682628
Validation loss: 2.546662466267143

Epoch: 6| Step: 9
Training loss: 0.16620195815040859
Validation loss: 2.5248762934809923

Epoch: 6| Step: 10
Training loss: 0.11911011915038254
Validation loss: 2.510526332435062

Epoch: 6| Step: 11
Training loss: 0.11862457405678117
Validation loss: 2.4758968145050737

Epoch: 6| Step: 12
Training loss: 0.23039255660764998
Validation loss: 2.456126892650281

Epoch: 6| Step: 13
Training loss: 0.15320681969692299
Validation loss: 2.4408320309261

Epoch: 418| Step: 0
Training loss: 0.31056102984336265
Validation loss: 2.4113011576162537

Epoch: 6| Step: 1
Training loss: 0.13766010997785835
Validation loss: 2.4425455475518794

Epoch: 6| Step: 2
Training loss: 0.17598156641409324
Validation loss: 2.4154878035246914

Epoch: 6| Step: 3
Training loss: 0.18006095225110227
Validation loss: 2.4188370279898197

Epoch: 6| Step: 4
Training loss: 0.22547392933713237
Validation loss: 2.404295798062435

Epoch: 6| Step: 5
Training loss: 0.16867402516629382
Validation loss: 2.409820655067801

Epoch: 6| Step: 6
Training loss: 0.11100136335766408
Validation loss: 2.426857378801676

Epoch: 6| Step: 7
Training loss: 0.10271836906747771
Validation loss: 2.4339698394632543

Epoch: 6| Step: 8
Training loss: 0.18134423141244677
Validation loss: 2.424386888210673

Epoch: 6| Step: 9
Training loss: 0.14192750184117012
Validation loss: 2.4261511216077007

Epoch: 6| Step: 10
Training loss: 0.1245277394478385
Validation loss: 2.481614382643812

Epoch: 6| Step: 11
Training loss: 0.11425225334011307
Validation loss: 2.473421142147589

Epoch: 6| Step: 12
Training loss: 0.1028257947735106
Validation loss: 2.4736344546544937

Epoch: 6| Step: 13
Training loss: 0.09359476031616251
Validation loss: 2.499893434365729

Epoch: 419| Step: 0
Training loss: 0.22177741127567446
Validation loss: 2.511736454511597

Epoch: 6| Step: 1
Training loss: 0.10925539749171444
Validation loss: 2.510107388390792

Epoch: 6| Step: 2
Training loss: 0.16659897246589148
Validation loss: 2.5185061789360876

Epoch: 6| Step: 3
Training loss: 0.140335898455571
Validation loss: 2.5109056680637742

Epoch: 6| Step: 4
Training loss: 0.1888418364054655
Validation loss: 2.463063157655891

Epoch: 6| Step: 5
Training loss: 0.13330892740587313
Validation loss: 2.4780293119786334

Epoch: 6| Step: 6
Training loss: 0.24176020767916434
Validation loss: 2.471564693183095

Epoch: 6| Step: 7
Training loss: 0.11600231630560286
Validation loss: 2.454559733248561

Epoch: 6| Step: 8
Training loss: 0.12955324048428837
Validation loss: 2.455622453913104

Epoch: 6| Step: 9
Training loss: 0.1654826078474541
Validation loss: 2.484067396707953

Epoch: 6| Step: 10
Training loss: 0.07150014237013727
Validation loss: 2.484618669477331

Epoch: 6| Step: 11
Training loss: 0.24700948848578663
Validation loss: 2.5390999830838004

Epoch: 6| Step: 12
Training loss: 0.14006955999814494
Validation loss: 2.5116170237002633

Epoch: 6| Step: 13
Training loss: 0.21419808729813292
Validation loss: 2.5439587557432763

Epoch: 420| Step: 0
Training loss: 0.09800295320934131
Validation loss: 2.5023624158748468

Epoch: 6| Step: 1
Training loss: 0.25995712105509694
Validation loss: 2.507524678995016

Epoch: 6| Step: 2
Training loss: 0.1301235033905636
Validation loss: 2.4903404954130632

Epoch: 6| Step: 3
Training loss: 0.16046310894048163
Validation loss: 2.4641594419936266

Epoch: 6| Step: 4
Training loss: 0.10890455912367901
Validation loss: 2.423914309785448

Epoch: 6| Step: 5
Training loss: 0.11272248216631384
Validation loss: 2.42355758009721

Epoch: 6| Step: 6
Training loss: 0.19690105061522006
Validation loss: 2.4340963608862034

Epoch: 6| Step: 7
Training loss: 0.16027806464332475
Validation loss: 2.4034702533446177

Epoch: 6| Step: 8
Training loss: 0.17553138988870293
Validation loss: 2.435165909537937

Epoch: 6| Step: 9
Training loss: 0.10216619727411665
Validation loss: 2.4320939334481246

Epoch: 6| Step: 10
Training loss: 0.23682008720761996
Validation loss: 2.4341139116924166

Epoch: 6| Step: 11
Training loss: 0.1606623399133433
Validation loss: 2.445053819203745

Epoch: 6| Step: 12
Training loss: 0.2362813193890354
Validation loss: 2.4679165429252055

Epoch: 6| Step: 13
Training loss: 0.14988339953671706
Validation loss: 2.466204999045553

Epoch: 421| Step: 0
Training loss: 0.0947453244299354
Validation loss: 2.4742579064500205

Epoch: 6| Step: 1
Training loss: 0.21352133809223325
Validation loss: 2.478619500038807

Epoch: 6| Step: 2
Training loss: 0.1605506031039751
Validation loss: 2.4552843549252996

Epoch: 6| Step: 3
Training loss: 0.19308946054104997
Validation loss: 2.4764791753929414

Epoch: 6| Step: 4
Training loss: 0.17060718240734318
Validation loss: 2.462982760220192

Epoch: 6| Step: 5
Training loss: 0.18118306436731324
Validation loss: 2.446929978547565

Epoch: 6| Step: 6
Training loss: 0.12950121242552143
Validation loss: 2.437550752719831

Epoch: 6| Step: 7
Training loss: 0.12273181589057998
Validation loss: 2.4483875129905037

Epoch: 6| Step: 8
Training loss: 0.07660150106311846
Validation loss: 2.486649462537473

Epoch: 6| Step: 9
Training loss: 0.18077615920328094
Validation loss: 2.482261643701026

Epoch: 6| Step: 10
Training loss: 0.2577492029342389
Validation loss: 2.4829208886983434

Epoch: 6| Step: 11
Training loss: 0.08670245889623344
Validation loss: 2.514333052975954

Epoch: 6| Step: 12
Training loss: 0.0993894036818742
Validation loss: 2.513619364972051

Epoch: 6| Step: 13
Training loss: 0.09604410812118529
Validation loss: 2.5074585516701426

Epoch: 422| Step: 0
Training loss: 0.09926646710931344
Validation loss: 2.5101367115411493

Epoch: 6| Step: 1
Training loss: 0.10166938366086582
Validation loss: 2.494122148024684

Epoch: 6| Step: 2
Training loss: 0.14837120483063257
Validation loss: 2.4788880502299597

Epoch: 6| Step: 3
Training loss: 0.14825881065679516
Validation loss: 2.5007000548022478

Epoch: 6| Step: 4
Training loss: 0.09904010639932953
Validation loss: 2.4753037407084286

Epoch: 6| Step: 5
Training loss: 0.16969020989749897
Validation loss: 2.464896663624811

Epoch: 6| Step: 6
Training loss: 0.1831980356839391
Validation loss: 2.4666420205616353

Epoch: 6| Step: 7
Training loss: 0.09399125726414052
Validation loss: 2.449198026995155

Epoch: 6| Step: 8
Training loss: 0.12807362590648744
Validation loss: 2.4530366194933153

Epoch: 6| Step: 9
Training loss: 0.2172431562314789
Validation loss: 2.4473829104222466

Epoch: 6| Step: 10
Training loss: 0.242746431132953
Validation loss: 2.4635613796292937

Epoch: 6| Step: 11
Training loss: 0.18192760807824068
Validation loss: 2.4484297138599205

Epoch: 6| Step: 12
Training loss: 0.2065560266862617
Validation loss: 2.4424043196794125

Epoch: 6| Step: 13
Training loss: 0.1330337294705255
Validation loss: 2.477212430540772

Epoch: 423| Step: 0
Training loss: 0.17253354554082057
Validation loss: 2.4365053558648655

Epoch: 6| Step: 1
Training loss: 0.22162030806956462
Validation loss: 2.440122780913985

Epoch: 6| Step: 2
Training loss: 0.2126487968310329
Validation loss: 2.404479766122223

Epoch: 6| Step: 3
Training loss: 0.18162333498465283
Validation loss: 2.4030586262846505

Epoch: 6| Step: 4
Training loss: 0.11350880573501629
Validation loss: 2.4313475626815326

Epoch: 6| Step: 5
Training loss: 0.1587036832315329
Validation loss: 2.4390348876925563

Epoch: 6| Step: 6
Training loss: 0.14725088480835766
Validation loss: 2.4603111239520983

Epoch: 6| Step: 7
Training loss: 0.09435041209943558
Validation loss: 2.467807682355743

Epoch: 6| Step: 8
Training loss: 0.22720022718154184
Validation loss: 2.5075589805990566

Epoch: 6| Step: 9
Training loss: 0.1529658770461902
Validation loss: 2.5136876330978226

Epoch: 6| Step: 10
Training loss: 0.17426974743331658
Validation loss: 2.5360626264439827

Epoch: 6| Step: 11
Training loss: 0.1357953495786645
Validation loss: 2.4921605023872946

Epoch: 6| Step: 12
Training loss: 0.15451414769635569
Validation loss: 2.4613553746013954

Epoch: 6| Step: 13
Training loss: 0.12012746425799331
Validation loss: 2.42821078463373

Epoch: 424| Step: 0
Training loss: 0.11300117300435389
Validation loss: 2.4240395951638307

Epoch: 6| Step: 1
Training loss: 0.16964531458422805
Validation loss: 2.398278930762396

Epoch: 6| Step: 2
Training loss: 0.14528567363907505
Validation loss: 2.4060727349669326

Epoch: 6| Step: 3
Training loss: 0.11883733402083918
Validation loss: 2.44113234455608

Epoch: 6| Step: 4
Training loss: 0.13511255776335898
Validation loss: 2.435328481544617

Epoch: 6| Step: 5
Training loss: 0.15040003140249775
Validation loss: 2.3900625248266163

Epoch: 6| Step: 6
Training loss: 0.19001823381719526
Validation loss: 2.421517495593821

Epoch: 6| Step: 7
Training loss: 0.20589276138960882
Validation loss: 2.419718897988939

Epoch: 6| Step: 8
Training loss: 0.10552037706241957
Validation loss: 2.406980073761054

Epoch: 6| Step: 9
Training loss: 0.11841622551552416
Validation loss: 2.4228095213551626

Epoch: 6| Step: 10
Training loss: 0.07922986304379756
Validation loss: 2.428817024904007

Epoch: 6| Step: 11
Training loss: 0.2551554102746586
Validation loss: 2.415265988218597

Epoch: 6| Step: 12
Training loss: 0.17420234474639013
Validation loss: 2.4134133696701703

Epoch: 6| Step: 13
Training loss: 0.14756871383772857
Validation loss: 2.479071651412113

Epoch: 425| Step: 0
Training loss: 0.17377718704199074
Validation loss: 2.4849994432147438

Epoch: 6| Step: 1
Training loss: 0.10626078280963061
Validation loss: 2.5046587518092815

Epoch: 6| Step: 2
Training loss: 0.17996942131260393
Validation loss: 2.512691890367217

Epoch: 6| Step: 3
Training loss: 0.051265012451123575
Validation loss: 2.516512133039796

Epoch: 6| Step: 4
Training loss: 0.2307172421645467
Validation loss: 2.5351162032310883

Epoch: 6| Step: 5
Training loss: 0.11065699077057688
Validation loss: 2.459614384658972

Epoch: 6| Step: 6
Training loss: 0.080407905723168
Validation loss: 2.482873009715711

Epoch: 6| Step: 7
Training loss: 0.23419016066190965
Validation loss: 2.496925040079923

Epoch: 6| Step: 8
Training loss: 0.21285109196647822
Validation loss: 2.4824900747301393

Epoch: 6| Step: 9
Training loss: 0.14759567875261148
Validation loss: 2.4806338675721786

Epoch: 6| Step: 10
Training loss: 0.18404513528126132
Validation loss: 2.468823365502092

Epoch: 6| Step: 11
Training loss: 0.15966373402990622
Validation loss: 2.493427614204368

Epoch: 6| Step: 12
Training loss: 0.07739583017634612
Validation loss: 2.49974619592289

Epoch: 6| Step: 13
Training loss: 0.07865372796044842
Validation loss: 2.491247695755408

Epoch: 426| Step: 0
Training loss: 0.17043376420238476
Validation loss: 2.5421752104890847

Epoch: 6| Step: 1
Training loss: 0.1226733912499488
Validation loss: 2.5238205625870163

Epoch: 6| Step: 2
Training loss: 0.06472132613273644
Validation loss: 2.5077163840920824

Epoch: 6| Step: 3
Training loss: 0.120754308403791
Validation loss: 2.4992144611824485

Epoch: 6| Step: 4
Training loss: 0.10401490650298456
Validation loss: 2.5119478803802644

Epoch: 6| Step: 5
Training loss: 0.12317890319797117
Validation loss: 2.482048860377625

Epoch: 6| Step: 6
Training loss: 0.12347449445455902
Validation loss: 2.5026666047986668

Epoch: 6| Step: 7
Training loss: 0.16482072416276644
Validation loss: 2.5089834798759947

Epoch: 6| Step: 8
Training loss: 0.15187873539432178
Validation loss: 2.4974044759791734

Epoch: 6| Step: 9
Training loss: 0.2001934516634172
Validation loss: 2.492979427072645

Epoch: 6| Step: 10
Training loss: 0.2629799134303966
Validation loss: 2.5137924605362585

Epoch: 6| Step: 11
Training loss: 0.1087514910033935
Validation loss: 2.5279854969964877

Epoch: 6| Step: 12
Training loss: 0.18889827689358815
Validation loss: 2.526076256570479

Epoch: 6| Step: 13
Training loss: 0.2611149327413307
Validation loss: 2.492399403872783

Epoch: 427| Step: 0
Training loss: 0.11391716902141177
Validation loss: 2.4789529882227415

Epoch: 6| Step: 1
Training loss: 0.15156121892485983
Validation loss: 2.4349323418467286

Epoch: 6| Step: 2
Training loss: 0.16056015674385385
Validation loss: 2.4168487111805144

Epoch: 6| Step: 3
Training loss: 0.20954432295227318
Validation loss: 2.4393720250869038

Epoch: 6| Step: 4
Training loss: 0.11812046523573333
Validation loss: 2.42379624200847

Epoch: 6| Step: 5
Training loss: 0.09852936484762335
Validation loss: 2.4665026349395403

Epoch: 6| Step: 6
Training loss: 0.19151534649857554
Validation loss: 2.5221238527547403

Epoch: 6| Step: 7
Training loss: 0.20886683500940426
Validation loss: 2.519327054529599

Epoch: 6| Step: 8
Training loss: 0.24552392838417758
Validation loss: 2.5398864953858697

Epoch: 6| Step: 9
Training loss: 0.13626851470073836
Validation loss: 2.589410175920973

Epoch: 6| Step: 10
Training loss: 0.17862198914272126
Validation loss: 2.563496998726464

Epoch: 6| Step: 11
Training loss: 0.09319443797311099
Validation loss: 2.539442373781551

Epoch: 6| Step: 12
Training loss: 0.10688112879212493
Validation loss: 2.513924251735153

Epoch: 6| Step: 13
Training loss: 0.24801663342049
Validation loss: 2.482840764629891

Epoch: 428| Step: 0
Training loss: 0.12585424798743813
Validation loss: 2.454114940060652

Epoch: 6| Step: 1
Training loss: 0.09183190570160511
Validation loss: 2.4471131017568415

Epoch: 6| Step: 2
Training loss: 0.17217440969067693
Validation loss: 2.437058892946534

Epoch: 6| Step: 3
Training loss: 0.1731796491523673
Validation loss: 2.460491789448202

Epoch: 6| Step: 4
Training loss: 0.07990875592328532
Validation loss: 2.508661744241099

Epoch: 6| Step: 5
Training loss: 0.06964570012813484
Validation loss: 2.501065169832491

Epoch: 6| Step: 6
Training loss: 0.24377918955060895
Validation loss: 2.559365775594939

Epoch: 6| Step: 7
Training loss: 0.22860865044415438
Validation loss: 2.5564086270330924

Epoch: 6| Step: 8
Training loss: 0.19848646888868682
Validation loss: 2.5543767760119342

Epoch: 6| Step: 9
Training loss: 0.15814562918362107
Validation loss: 2.548921297650996

Epoch: 6| Step: 10
Training loss: 0.10221331489035684
Validation loss: 2.510060255746453

Epoch: 6| Step: 11
Training loss: 0.13129514048523697
Validation loss: 2.508117567266999

Epoch: 6| Step: 12
Training loss: 0.1854463103971781
Validation loss: 2.4847576362389656

Epoch: 6| Step: 13
Training loss: 0.11726224422982005
Validation loss: 2.442528389000073

Epoch: 429| Step: 0
Training loss: 0.12944474595462946
Validation loss: 2.464232901512535

Epoch: 6| Step: 1
Training loss: 0.1412392288506657
Validation loss: 2.4761562550561247

Epoch: 6| Step: 2
Training loss: 0.2910365922786315
Validation loss: 2.4920306906543077

Epoch: 6| Step: 3
Training loss: 0.12676481806553366
Validation loss: 2.5679024750857047

Epoch: 6| Step: 4
Training loss: 0.11290645669849057
Validation loss: 2.581737060527223

Epoch: 6| Step: 5
Training loss: 0.08446379433160678
Validation loss: 2.599743943427916

Epoch: 6| Step: 6
Training loss: 0.2105413974056514
Validation loss: 2.5779165432886466

Epoch: 6| Step: 7
Training loss: 0.1799672892438847
Validation loss: 2.5889782858705246

Epoch: 6| Step: 8
Training loss: 0.16430039982046177
Validation loss: 2.5364558341667656

Epoch: 6| Step: 9
Training loss: 0.10557689685200357
Validation loss: 2.5114360243147735

Epoch: 6| Step: 10
Training loss: 0.18746581361966505
Validation loss: 2.465863175142976

Epoch: 6| Step: 11
Training loss: 0.11362113606772843
Validation loss: 2.4597551632434085

Epoch: 6| Step: 12
Training loss: 0.15892013498519578
Validation loss: 2.4580495759921055

Epoch: 6| Step: 13
Training loss: 0.15108993734541615
Validation loss: 2.454788366206889

Epoch: 430| Step: 0
Training loss: 0.13846177316736438
Validation loss: 2.4508528346166787

Epoch: 6| Step: 1
Training loss: 0.26296787232350555
Validation loss: 2.4533529714542492

Epoch: 6| Step: 2
Training loss: 0.12869454830871166
Validation loss: 2.517420607955086

Epoch: 6| Step: 3
Training loss: 0.22208873467708984
Validation loss: 2.522852441322446

Epoch: 6| Step: 4
Training loss: 0.1153234848486493
Validation loss: 2.512683694599788

Epoch: 6| Step: 5
Training loss: 0.14587315515235832
Validation loss: 2.52841626264877

Epoch: 6| Step: 6
Training loss: 0.12138839223357212
Validation loss: 2.5132834476082127

Epoch: 6| Step: 7
Training loss: 0.09649234016838162
Validation loss: 2.510444955143482

Epoch: 6| Step: 8
Training loss: 0.09237726348115707
Validation loss: 2.4360298801248947

Epoch: 6| Step: 9
Training loss: 0.16084879495325263
Validation loss: 2.44011695101928

Epoch: 6| Step: 10
Training loss: 0.05558345839748427
Validation loss: 2.476654931931387

Epoch: 6| Step: 11
Training loss: 0.1685204096447803
Validation loss: 2.4585911094399293

Epoch: 6| Step: 12
Training loss: 0.2136282435193819
Validation loss: 2.430226168182397

Epoch: 6| Step: 13
Training loss: 0.1406135289493921
Validation loss: 2.470051647246806

Epoch: 431| Step: 0
Training loss: 0.21495389715744945
Validation loss: 2.4581460559882906

Epoch: 6| Step: 1
Training loss: 0.12340993150854748
Validation loss: 2.4923477885093774

Epoch: 6| Step: 2
Training loss: 0.13846903728058427
Validation loss: 2.4484921489550175

Epoch: 6| Step: 3
Training loss: 0.25013143839311097
Validation loss: 2.4472885830655478

Epoch: 6| Step: 4
Training loss: 0.21561591364194913
Validation loss: 2.4705376495676763

Epoch: 6| Step: 5
Training loss: 0.14682187301487645
Validation loss: 2.437891357363297

Epoch: 6| Step: 6
Training loss: 0.1550741596339522
Validation loss: 2.4593489002043145

Epoch: 6| Step: 7
Training loss: 0.11653656977287662
Validation loss: 2.4442849889920164

Epoch: 6| Step: 8
Training loss: 0.1724244136303653
Validation loss: 2.469864063913938

Epoch: 6| Step: 9
Training loss: 0.0870887789732815
Validation loss: 2.477962550652774

Epoch: 6| Step: 10
Training loss: 0.11087691741551968
Validation loss: 2.494314194576061

Epoch: 6| Step: 11
Training loss: 0.16139737575652083
Validation loss: 2.491367446520625

Epoch: 6| Step: 12
Training loss: 0.09799250885008169
Validation loss: 2.4768954195248707

Epoch: 6| Step: 13
Training loss: 0.10923777214053061
Validation loss: 2.466947880803569

Epoch: 432| Step: 0
Training loss: 0.07701359807739143
Validation loss: 2.468482916245036

Epoch: 6| Step: 1
Training loss: 0.1686361935762372
Validation loss: 2.456285039104954

Epoch: 6| Step: 2
Training loss: 0.1500530293227511
Validation loss: 2.4295938404724176

Epoch: 6| Step: 3
Training loss: 0.2526169393528477
Validation loss: 2.4378979171177835

Epoch: 6| Step: 4
Training loss: 0.14492662581396681
Validation loss: 2.4468813596959307

Epoch: 6| Step: 5
Training loss: 0.10358194260173188
Validation loss: 2.470918298473122

Epoch: 6| Step: 6
Training loss: 0.19945091855972508
Validation loss: 2.4652928697130947

Epoch: 6| Step: 7
Training loss: 0.11263540748400475
Validation loss: 2.494169640441161

Epoch: 6| Step: 8
Training loss: 0.1832276000569831
Validation loss: 2.492706265923535

Epoch: 6| Step: 9
Training loss: 0.13965968106763316
Validation loss: 2.504019934394859

Epoch: 6| Step: 10
Training loss: 0.15879331984214523
Validation loss: 2.5240654343946507

Epoch: 6| Step: 11
Training loss: 0.09353894577108295
Validation loss: 2.5330971101178696

Epoch: 6| Step: 12
Training loss: 0.21772974371390294
Validation loss: 2.5071037844125423

Epoch: 6| Step: 13
Training loss: 0.2002088588690501
Validation loss: 2.4828931584225438

Epoch: 433| Step: 0
Training loss: 0.14702939050574898
Validation loss: 2.4732810999662287

Epoch: 6| Step: 1
Training loss: 0.11786828183894758
Validation loss: 2.4605227895595014

Epoch: 6| Step: 2
Training loss: 0.09189079937872113
Validation loss: 2.450446177673125

Epoch: 6| Step: 3
Training loss: 0.2928953333100008
Validation loss: 2.4621293491447354

Epoch: 6| Step: 4
Training loss: 0.0892837841387296
Validation loss: 2.4316922485390924

Epoch: 6| Step: 5
Training loss: 0.12471350232618435
Validation loss: 2.438438540897566

Epoch: 6| Step: 6
Training loss: 0.11791691272758224
Validation loss: 2.458221131258871

Epoch: 6| Step: 7
Training loss: 0.08002075023993585
Validation loss: 2.4735512247051696

Epoch: 6| Step: 8
Training loss: 0.1095487415275496
Validation loss: 2.463469644330684

Epoch: 6| Step: 9
Training loss: 0.27562093911239405
Validation loss: 2.4968832830648764

Epoch: 6| Step: 10
Training loss: 0.20960972709498227
Validation loss: 2.4777651508582283

Epoch: 6| Step: 11
Training loss: 0.10508931749146383
Validation loss: 2.4811721002226914

Epoch: 6| Step: 12
Training loss: 0.17172259379381188
Validation loss: 2.43683145177333

Epoch: 6| Step: 13
Training loss: 0.1114672619557496
Validation loss: 2.450956687539966

Epoch: 434| Step: 0
Training loss: 0.16452833299867686
Validation loss: 2.424517205310041

Epoch: 6| Step: 1
Training loss: 0.20422704389406035
Validation loss: 2.431531991223391

Epoch: 6| Step: 2
Training loss: 0.13832652379945584
Validation loss: 2.4533287733385842

Epoch: 6| Step: 3
Training loss: 0.11039544389280738
Validation loss: 2.4616483178425046

Epoch: 6| Step: 4
Training loss: 0.1416668445455145
Validation loss: 2.4702893140619464

Epoch: 6| Step: 5
Training loss: 0.14820546913002391
Validation loss: 2.4800801502528245

Epoch: 6| Step: 6
Training loss: 0.228836632906104
Validation loss: 2.5053933152305237

Epoch: 6| Step: 7
Training loss: 0.12610129162477055
Validation loss: 2.4865803634238888

Epoch: 6| Step: 8
Training loss: 0.110704015278652
Validation loss: 2.4607576829643154

Epoch: 6| Step: 9
Training loss: 0.20110453246996998
Validation loss: 2.4471785476964185

Epoch: 6| Step: 10
Training loss: 0.13322271779071107
Validation loss: 2.442543311950968

Epoch: 6| Step: 11
Training loss: 0.06925723484958095
Validation loss: 2.478233174754629

Epoch: 6| Step: 12
Training loss: 0.21636760586975168
Validation loss: 2.4744942896823625

Epoch: 6| Step: 13
Training loss: 0.17865646032267948
Validation loss: 2.50965595084733

Epoch: 435| Step: 0
Training loss: 0.1223274840763135
Validation loss: 2.518228072620195

Epoch: 6| Step: 1
Training loss: 0.24647686670296604
Validation loss: 2.4996295223756113

Epoch: 6| Step: 2
Training loss: 0.11073824978106428
Validation loss: 2.5001240525180024

Epoch: 6| Step: 3
Training loss: 0.21683197768300952
Validation loss: 2.5014110059606605

Epoch: 6| Step: 4
Training loss: 0.23549982996041544
Validation loss: 2.4983305268745735

Epoch: 6| Step: 5
Training loss: 0.18772627171281128
Validation loss: 2.492579461691913

Epoch: 6| Step: 6
Training loss: 0.14759285186423235
Validation loss: 2.503428106373602

Epoch: 6| Step: 7
Training loss: 0.1490212306587934
Validation loss: 2.4907503091356475

Epoch: 6| Step: 8
Training loss: 0.12467834692417828
Validation loss: 2.5036889853962143

Epoch: 6| Step: 9
Training loss: 0.16545990889670956
Validation loss: 2.5248151014775786

Epoch: 6| Step: 10
Training loss: 0.07516937303869287
Validation loss: 2.4979004996353855

Epoch: 6| Step: 11
Training loss: 0.08273091413447473
Validation loss: 2.4812208086377883

Epoch: 6| Step: 12
Training loss: 0.16705857457545212
Validation loss: 2.4413072082775216

Epoch: 6| Step: 13
Training loss: 0.1271559195946624
Validation loss: 2.472555937413237

Epoch: 436| Step: 0
Training loss: 0.14042012867871534
Validation loss: 2.444726918870149

Epoch: 6| Step: 1
Training loss: 0.077424151240857
Validation loss: 2.457561355719702

Epoch: 6| Step: 2
Training loss: 0.1380875189446479
Validation loss: 2.45580702563981

Epoch: 6| Step: 3
Training loss: 0.13919982344805273
Validation loss: 2.4395646679194494

Epoch: 6| Step: 4
Training loss: 0.11043053729577411
Validation loss: 2.4399925731116894

Epoch: 6| Step: 5
Training loss: 0.2788898463193722
Validation loss: 2.457374945594698

Epoch: 6| Step: 6
Training loss: 0.10815976475656461
Validation loss: 2.4570466900294776

Epoch: 6| Step: 7
Training loss: 0.1291565776417451
Validation loss: 2.511748812178574

Epoch: 6| Step: 8
Training loss: 0.1880891207448412
Validation loss: 2.490315226803246

Epoch: 6| Step: 9
Training loss: 0.14848884522682657
Validation loss: 2.4983346252803647

Epoch: 6| Step: 10
Training loss: 0.09177938761427276
Validation loss: 2.4923839889600954

Epoch: 6| Step: 11
Training loss: 0.11588980678929384
Validation loss: 2.4846170866887785

Epoch: 6| Step: 12
Training loss: 0.08314540902898257
Validation loss: 2.4623096040264345

Epoch: 6| Step: 13
Training loss: 0.3017895629376212
Validation loss: 2.4563584001385803

Epoch: 437| Step: 0
Training loss: 0.12231621198474589
Validation loss: 2.49310305718835

Epoch: 6| Step: 1
Training loss: 0.19153718946063658
Validation loss: 2.462916250961551

Epoch: 6| Step: 2
Training loss: 0.16724331694987082
Validation loss: 2.483787307680773

Epoch: 6| Step: 3
Training loss: 0.15710092939176892
Validation loss: 2.460356217068317

Epoch: 6| Step: 4
Training loss: 0.1116782671933825
Validation loss: 2.433634496648711

Epoch: 6| Step: 5
Training loss: 0.23391261584551654
Validation loss: 2.42415354994966

Epoch: 6| Step: 6
Training loss: 0.15798527824499048
Validation loss: 2.4077046236207647

Epoch: 6| Step: 7
Training loss: 0.11560247917195977
Validation loss: 2.437106830449701

Epoch: 6| Step: 8
Training loss: 0.1678671751513663
Validation loss: 2.4216452276213873

Epoch: 6| Step: 9
Training loss: 0.11340095098707913
Validation loss: 2.4539230842813544

Epoch: 6| Step: 10
Training loss: 0.13343531069645803
Validation loss: 2.4698385193816605

Epoch: 6| Step: 11
Training loss: 0.12022536144218125
Validation loss: 2.455313861914534

Epoch: 6| Step: 12
Training loss: 0.1417600074108296
Validation loss: 2.500467428993717

Epoch: 6| Step: 13
Training loss: 0.07811416312397738
Validation loss: 2.5021451852485277

Epoch: 438| Step: 0
Training loss: 0.1610309163050689
Validation loss: 2.510922611030424

Epoch: 6| Step: 1
Training loss: 0.20839283014134571
Validation loss: 2.525117957751946

Epoch: 6| Step: 2
Training loss: 0.20505166564277455
Validation loss: 2.477520837330809

Epoch: 6| Step: 3
Training loss: 0.0986287238907132
Validation loss: 2.444200070004679

Epoch: 6| Step: 4
Training loss: 0.13480164557898974
Validation loss: 2.4144351580131653

Epoch: 6| Step: 5
Training loss: 0.16908315316473924
Validation loss: 2.4417759685192997

Epoch: 6| Step: 6
Training loss: 0.21535763404517247
Validation loss: 2.435438794940157

Epoch: 6| Step: 7
Training loss: 0.10546769035654754
Validation loss: 2.4509624822373604

Epoch: 6| Step: 8
Training loss: 0.11630154531470888
Validation loss: 2.4716736011685683

Epoch: 6| Step: 9
Training loss: 0.1507320368211658
Validation loss: 2.4928778451748297

Epoch: 6| Step: 10
Training loss: 0.10872052429014557
Validation loss: 2.501508896274208

Epoch: 6| Step: 11
Training loss: 0.14496792732477348
Validation loss: 2.5151436860616223

Epoch: 6| Step: 12
Training loss: 0.13787536482620044
Validation loss: 2.518782571089228

Epoch: 6| Step: 13
Training loss: 0.2409848377465979
Validation loss: 2.50264402413723

Epoch: 439| Step: 0
Training loss: 0.0831510430067289
Validation loss: 2.479753040414979

Epoch: 6| Step: 1
Training loss: 0.11396138954975162
Validation loss: 2.4864060652847058

Epoch: 6| Step: 2
Training loss: 0.08689088726741541
Validation loss: 2.473038230133721

Epoch: 6| Step: 3
Training loss: 0.175520104233183
Validation loss: 2.494223333894683

Epoch: 6| Step: 4
Training loss: 0.10912023402978585
Validation loss: 2.47698605472138

Epoch: 6| Step: 5
Training loss: 0.1363238353109005
Validation loss: 2.4885186494738996

Epoch: 6| Step: 6
Training loss: 0.14619890370889096
Validation loss: 2.46779945010805

Epoch: 6| Step: 7
Training loss: 0.1613890373564789
Validation loss: 2.5164565363797604

Epoch: 6| Step: 8
Training loss: 0.12182136327392734
Validation loss: 2.501164822295595

Epoch: 6| Step: 9
Training loss: 0.10192914037556898
Validation loss: 2.525759554959735

Epoch: 6| Step: 10
Training loss: 0.21910414808641454
Validation loss: 2.5511460710074436

Epoch: 6| Step: 11
Training loss: 0.10628373017371355
Validation loss: 2.523913701588449

Epoch: 6| Step: 12
Training loss: 0.08776431544309772
Validation loss: 2.4929489837886183

Epoch: 6| Step: 13
Training loss: 0.3260870269243192
Validation loss: 2.4604457829502144

Epoch: 440| Step: 0
Training loss: 0.08109102239045747
Validation loss: 2.4824693330813425

Epoch: 6| Step: 1
Training loss: 0.19137367633097702
Validation loss: 2.4558069421270368

Epoch: 6| Step: 2
Training loss: 0.15585727212199535
Validation loss: 2.462185877862872

Epoch: 6| Step: 3
Training loss: 0.14905109448853263
Validation loss: 2.462050306615946

Epoch: 6| Step: 4
Training loss: 0.1478337570716655
Validation loss: 2.4581526711975985

Epoch: 6| Step: 5
Training loss: 0.21220115692111374
Validation loss: 2.4363635958250685

Epoch: 6| Step: 6
Training loss: 0.10864783285055991
Validation loss: 2.4572593848726507

Epoch: 6| Step: 7
Training loss: 0.09155977857828812
Validation loss: 2.454871785850604

Epoch: 6| Step: 8
Training loss: 0.07734745045681701
Validation loss: 2.453907913462512

Epoch: 6| Step: 9
Training loss: 0.10413549274638825
Validation loss: 2.443185068958365

Epoch: 6| Step: 10
Training loss: 0.13520142676705246
Validation loss: 2.4461862197743987

Epoch: 6| Step: 11
Training loss: 0.08941340001678692
Validation loss: 2.459650612437415

Epoch: 6| Step: 12
Training loss: 0.1693875032997089
Validation loss: 2.5089854917690295

Epoch: 6| Step: 13
Training loss: 0.08309637842543911
Validation loss: 2.4548716218943456

Epoch: 441| Step: 0
Training loss: 0.12455469025735877
Validation loss: 2.4702332146686587

Epoch: 6| Step: 1
Training loss: 0.09620783031462776
Validation loss: 2.4769166208196918

Epoch: 6| Step: 2
Training loss: 0.12263948878795809
Validation loss: 2.44853360516711

Epoch: 6| Step: 3
Training loss: 0.13057448562584298
Validation loss: 2.458810500993636

Epoch: 6| Step: 4
Training loss: 0.10100289375932801
Validation loss: 2.433201828894068

Epoch: 6| Step: 5
Training loss: 0.26603815260627284
Validation loss: 2.409245211526096

Epoch: 6| Step: 6
Training loss: 0.09128299905197637
Validation loss: 2.3992699463847167

Epoch: 6| Step: 7
Training loss: 0.10076579892200728
Validation loss: 2.4076834458757173

Epoch: 6| Step: 8
Training loss: 0.09580119616061858
Validation loss: 2.4178401928683657

Epoch: 6| Step: 9
Training loss: 0.08670029980904365
Validation loss: 2.443496438081404

Epoch: 6| Step: 10
Training loss: 0.1765506278325442
Validation loss: 2.4393716982436495

Epoch: 6| Step: 11
Training loss: 0.09283715118215807
Validation loss: 2.4649792440523557

Epoch: 6| Step: 12
Training loss: 0.18277381870843928
Validation loss: 2.4831891760560585

Epoch: 6| Step: 13
Training loss: 0.16689047030022183
Validation loss: 2.482252475658646

Epoch: 442| Step: 0
Training loss: 0.09925526431407165
Validation loss: 2.4606299152604554

Epoch: 6| Step: 1
Training loss: 0.1334710064793047
Validation loss: 2.423806785103568

Epoch: 6| Step: 2
Training loss: 0.09689250314931812
Validation loss: 2.4449718366082505

Epoch: 6| Step: 3
Training loss: 0.20188108446854847
Validation loss: 2.404746780518228

Epoch: 6| Step: 4
Training loss: 0.2333496234236859
Validation loss: 2.4101229410892513

Epoch: 6| Step: 5
Training loss: 0.09056541605217439
Validation loss: 2.457195177718029

Epoch: 6| Step: 6
Training loss: 0.14428875530098062
Validation loss: 2.422730444103365

Epoch: 6| Step: 7
Training loss: 0.14103992495830162
Validation loss: 2.439328692225633

Epoch: 6| Step: 8
Training loss: 0.18059007315218753
Validation loss: 2.471076909236687

Epoch: 6| Step: 9
Training loss: 0.16761521904775648
Validation loss: 2.469483520604244

Epoch: 6| Step: 10
Training loss: 0.07163708470602242
Validation loss: 2.5086973066528024

Epoch: 6| Step: 11
Training loss: 0.13175007885364148
Validation loss: 2.5044472116606085

Epoch: 6| Step: 12
Training loss: 0.08949398290397516
Validation loss: 2.5208544064560243

Epoch: 6| Step: 13
Training loss: 0.09548290372528691
Validation loss: 2.4990674166275877

Epoch: 443| Step: 0
Training loss: 0.15550204907651063
Validation loss: 2.5051189887041185

Epoch: 6| Step: 1
Training loss: 0.09872143135251261
Validation loss: 2.5099164736523774

Epoch: 6| Step: 2
Training loss: 0.1564505601209999
Validation loss: 2.484362235294136

Epoch: 6| Step: 3
Training loss: 0.2442460252219773
Validation loss: 2.4501745726432675

Epoch: 6| Step: 4
Training loss: 0.08568931091831006
Validation loss: 2.4506899953019667

Epoch: 6| Step: 5
Training loss: 0.13932069586531734
Validation loss: 2.453961836488168

Epoch: 6| Step: 6
Training loss: 0.13414058309831003
Validation loss: 2.426590593572349

Epoch: 6| Step: 7
Training loss: 0.12300543617140966
Validation loss: 2.4734566235619404

Epoch: 6| Step: 8
Training loss: 0.12140782066198198
Validation loss: 2.4396285076100432

Epoch: 6| Step: 9
Training loss: 0.1064352853234379
Validation loss: 2.472947462686864

Epoch: 6| Step: 10
Training loss: 0.20881112662796852
Validation loss: 2.5220221578432604

Epoch: 6| Step: 11
Training loss: 0.08738789891909166
Validation loss: 2.500764822102251

Epoch: 6| Step: 12
Training loss: 0.19928735598894104
Validation loss: 2.5132764940103587

Epoch: 6| Step: 13
Training loss: 0.12448320623318154
Validation loss: 2.5423061374000104

Epoch: 444| Step: 0
Training loss: 0.18137367690449663
Validation loss: 2.526882048499724

Epoch: 6| Step: 1
Training loss: 0.13998223139836183
Validation loss: 2.5261391052052766

Epoch: 6| Step: 2
Training loss: 0.26113524796028525
Validation loss: 2.475590821239695

Epoch: 6| Step: 3
Training loss: 0.14093197986212982
Validation loss: 2.456546672994416

Epoch: 6| Step: 4
Training loss: 0.19181543520685623
Validation loss: 2.4348070104872415

Epoch: 6| Step: 5
Training loss: 0.11868375590019875
Validation loss: 2.438192591518572

Epoch: 6| Step: 6
Training loss: 0.18151401906609585
Validation loss: 2.4590115502387846

Epoch: 6| Step: 7
Training loss: 0.10316424742815342
Validation loss: 2.4910686804101596

Epoch: 6| Step: 8
Training loss: 0.10173807190646338
Validation loss: 2.482773509010106

Epoch: 6| Step: 9
Training loss: 0.09892339675304045
Validation loss: 2.529202287110273

Epoch: 6| Step: 10
Training loss: 0.18224089914657093
Validation loss: 2.5501420500453293

Epoch: 6| Step: 11
Training loss: 0.131563477308671
Validation loss: 2.5477453421041907

Epoch: 6| Step: 12
Training loss: 0.160226445980663
Validation loss: 2.5136553753467505

Epoch: 6| Step: 13
Training loss: 0.15347994858173342
Validation loss: 2.5105003459063817

Epoch: 445| Step: 0
Training loss: 0.09377433540481966
Validation loss: 2.4524000403072552

Epoch: 6| Step: 1
Training loss: 0.18325702752706594
Validation loss: 2.4365690181972597

Epoch: 6| Step: 2
Training loss: 0.16548538238784974
Validation loss: 2.481528059184829

Epoch: 6| Step: 3
Training loss: 0.20616228449213533
Validation loss: 2.46813418526064

Epoch: 6| Step: 4
Training loss: 0.1312619748783533
Validation loss: 2.440717455758586

Epoch: 6| Step: 5
Training loss: 0.15286550673206448
Validation loss: 2.429442473370742

Epoch: 6| Step: 6
Training loss: 0.10414477108273563
Validation loss: 2.436528625752376

Epoch: 6| Step: 7
Training loss: 0.12022715861059739
Validation loss: 2.4658499626847057

Epoch: 6| Step: 8
Training loss: 0.1114009234344118
Validation loss: 2.4565177798441975

Epoch: 6| Step: 9
Training loss: 0.08834306506521228
Validation loss: 2.465299548416417

Epoch: 6| Step: 10
Training loss: 0.17232739990923007
Validation loss: 2.4524197985749363

Epoch: 6| Step: 11
Training loss: 0.13752686227318756
Validation loss: 2.4804021153128493

Epoch: 6| Step: 12
Training loss: 0.10779109704379296
Validation loss: 2.465658293243931

Epoch: 6| Step: 13
Training loss: 0.23821264592626792
Validation loss: 2.462924268973395

Epoch: 446| Step: 0
Training loss: 0.13568295757759022
Validation loss: 2.46135542042988

Epoch: 6| Step: 1
Training loss: 0.11502719293314308
Validation loss: 2.476629801105802

Epoch: 6| Step: 2
Training loss: 0.19863354055445653
Validation loss: 2.464130662035709

Epoch: 6| Step: 3
Training loss: 0.10790658314860883
Validation loss: 2.466264840215228

Epoch: 6| Step: 4
Training loss: 0.1648821338602545
Validation loss: 2.465763686196058

Epoch: 6| Step: 5
Training loss: 0.11038639143501729
Validation loss: 2.43766068948302

Epoch: 6| Step: 6
Training loss: 0.0743350072131978
Validation loss: 2.472555416920368

Epoch: 6| Step: 7
Training loss: 0.08976767262911377
Validation loss: 2.479605657506545

Epoch: 6| Step: 8
Training loss: 0.17531406520036
Validation loss: 2.485160168520252

Epoch: 6| Step: 9
Training loss: 0.06907652965939122
Validation loss: 2.4869145550823286

Epoch: 6| Step: 10
Training loss: 0.19790508943293042
Validation loss: 2.5300942206292265

Epoch: 6| Step: 11
Training loss: 0.11502434291481953
Validation loss: 2.541778470879763

Epoch: 6| Step: 12
Training loss: 0.123286853380102
Validation loss: 2.544950847381959

Epoch: 6| Step: 13
Training loss: 0.17618394924495273
Validation loss: 2.5400824858998736

Epoch: 447| Step: 0
Training loss: 0.1268584852322506
Validation loss: 2.5094606457072843

Epoch: 6| Step: 1
Training loss: 0.07886299609628185
Validation loss: 2.528957266953488

Epoch: 6| Step: 2
Training loss: 0.14672729694793404
Validation loss: 2.5258599575710856

Epoch: 6| Step: 3
Training loss: 0.10774376931286853
Validation loss: 2.4908151334228585

Epoch: 6| Step: 4
Training loss: 0.24451324256430068
Validation loss: 2.51537733133323

Epoch: 6| Step: 5
Training loss: 0.13441273192789494
Validation loss: 2.500675793030637

Epoch: 6| Step: 6
Training loss: 0.12133467073217102
Validation loss: 2.4987693623833436

Epoch: 6| Step: 7
Training loss: 0.12034938048824141
Validation loss: 2.5301451728561757

Epoch: 6| Step: 8
Training loss: 0.15623947346514727
Validation loss: 2.469296959832286

Epoch: 6| Step: 9
Training loss: 0.09967011114707522
Validation loss: 2.4785596939180166

Epoch: 6| Step: 10
Training loss: 0.12093327256140361
Validation loss: 2.4633837840102712

Epoch: 6| Step: 11
Training loss: 0.19105752005745985
Validation loss: 2.4687940739759937

Epoch: 6| Step: 12
Training loss: 0.0984639289360364
Validation loss: 2.4458700885817612

Epoch: 6| Step: 13
Training loss: 0.11630365135396022
Validation loss: 2.4214354244172696

Epoch: 448| Step: 0
Training loss: 0.0865954414883569
Validation loss: 2.429887221917339

Epoch: 6| Step: 1
Training loss: 0.1104027831785495
Validation loss: 2.456422729616417

Epoch: 6| Step: 2
Training loss: 0.15368522661675488
Validation loss: 2.4707235918871695

Epoch: 6| Step: 3
Training loss: 0.09334305017986093
Validation loss: 2.502589822957501

Epoch: 6| Step: 4
Training loss: 0.10272648349520742
Validation loss: 2.4861963516843772

Epoch: 6| Step: 5
Training loss: 0.078002875959351
Validation loss: 2.4822696575771825

Epoch: 6| Step: 6
Training loss: 0.0810642265543674
Validation loss: 2.4460250747749455

Epoch: 6| Step: 7
Training loss: 0.09112448669414608
Validation loss: 2.446484870713657

Epoch: 6| Step: 8
Training loss: 0.0962405152028872
Validation loss: 2.442298352215638

Epoch: 6| Step: 9
Training loss: 0.1870629362482961
Validation loss: 2.4256000284325574

Epoch: 6| Step: 10
Training loss: 0.13706146609572606
Validation loss: 2.4557739052952257

Epoch: 6| Step: 11
Training loss: 0.2000763981903643
Validation loss: 2.4556292993335758

Epoch: 6| Step: 12
Training loss: 0.12597688039103772
Validation loss: 2.423065719024292

Epoch: 6| Step: 13
Training loss: 0.24194991856372816
Validation loss: 2.4476458498968032

Epoch: 449| Step: 0
Training loss: 0.08061713153494478
Validation loss: 2.4555482315009685

Epoch: 6| Step: 1
Training loss: 0.14633300589808687
Validation loss: 2.43810055730556

Epoch: 6| Step: 2
Training loss: 0.11638646133606917
Validation loss: 2.4829531017687274

Epoch: 6| Step: 3
Training loss: 0.09328423472921679
Validation loss: 2.4651402014239827

Epoch: 6| Step: 4
Training loss: 0.18832691952522052
Validation loss: 2.479485415198325

Epoch: 6| Step: 5
Training loss: 0.14163191239902506
Validation loss: 2.4907205724802055

Epoch: 6| Step: 6
Training loss: 0.1453355627319117
Validation loss: 2.493156681581914

Epoch: 6| Step: 7
Training loss: 0.1318413768635204
Validation loss: 2.5038280097609453

Epoch: 6| Step: 8
Training loss: 0.09095812155717412
Validation loss: 2.4782416190620764

Epoch: 6| Step: 9
Training loss: 0.08141324580659375
Validation loss: 2.5062166240561514

Epoch: 6| Step: 10
Training loss: 0.14700669309566258
Validation loss: 2.4889074818856174

Epoch: 6| Step: 11
Training loss: 0.09765758036660963
Validation loss: 2.4874097218927402

Epoch: 6| Step: 12
Training loss: 0.1828358101451717
Validation loss: 2.520435081150558

Epoch: 6| Step: 13
Training loss: 0.10450488307514744
Validation loss: 2.4872174803017155

Epoch: 450| Step: 0
Training loss: 0.11061384039696198
Validation loss: 2.485639994479453

Epoch: 6| Step: 1
Training loss: 0.1760139567435388
Validation loss: 2.4800100287202578

Epoch: 6| Step: 2
Training loss: 0.08681362488778589
Validation loss: 2.4622500923124093

Epoch: 6| Step: 3
Training loss: 0.22797458536629298
Validation loss: 2.4836879746917537

Epoch: 6| Step: 4
Training loss: 0.09561193267043269
Validation loss: 2.4922802987843946

Epoch: 6| Step: 5
Training loss: 0.09530350885038436
Validation loss: 2.495544690568003

Epoch: 6| Step: 6
Training loss: 0.08664089039021496
Validation loss: 2.4841445668422253

Epoch: 6| Step: 7
Training loss: 0.12280407671640312
Validation loss: 2.491215833829722

Epoch: 6| Step: 8
Training loss: 0.11931896931937463
Validation loss: 2.510400706602013

Epoch: 6| Step: 9
Training loss: 0.10932562769575077
Validation loss: 2.498897666321103

Epoch: 6| Step: 10
Training loss: 0.1532398851189118
Validation loss: 2.5015665417060604

Epoch: 6| Step: 11
Training loss: 0.1725116771740014
Validation loss: 2.4817099010722568

Epoch: 6| Step: 12
Training loss: 0.15381137905929193
Validation loss: 2.5069356837186936

Epoch: 6| Step: 13
Training loss: 0.25924826133829226
Validation loss: 2.5094714040515953

Epoch: 451| Step: 0
Training loss: 0.10039989154069388
Validation loss: 2.4926311776780166

Epoch: 6| Step: 1
Training loss: 0.12272980118745447
Validation loss: 2.490405812129988

Epoch: 6| Step: 2
Training loss: 0.13143580432075577
Validation loss: 2.462761835386775

Epoch: 6| Step: 3
Training loss: 0.15660576254050262
Validation loss: 2.4537543064469323

Epoch: 6| Step: 4
Training loss: 0.13682802465473715
Validation loss: 2.3926737809956427

Epoch: 6| Step: 5
Training loss: 0.14958006544337873
Validation loss: 2.4198184064203874

Epoch: 6| Step: 6
Training loss: 0.18638665741423088
Validation loss: 2.410999368614618

Epoch: 6| Step: 7
Training loss: 0.14300822354059403
Validation loss: 2.4197914648349723

Epoch: 6| Step: 8
Training loss: 0.16281202006864193
Validation loss: 2.4060585884466366

Epoch: 6| Step: 9
Training loss: 0.16423599969225225
Validation loss: 2.4311607918307296

Epoch: 6| Step: 10
Training loss: 0.20372641916961548
Validation loss: 2.418776390765006

Epoch: 6| Step: 11
Training loss: 0.10008011640998857
Validation loss: 2.361389903037154

Epoch: 6| Step: 12
Training loss: 0.14512258778891152
Validation loss: 2.3844200861462004

Epoch: 6| Step: 13
Training loss: 0.19485474349748544
Validation loss: 2.3548400580817708

Epoch: 452| Step: 0
Training loss: 0.10794453483235708
Validation loss: 2.3733145470974306

Epoch: 6| Step: 1
Training loss: 0.0928299982420956
Validation loss: 2.3711127510369723

Epoch: 6| Step: 2
Training loss: 0.18813177799928757
Validation loss: 2.374206957835219

Epoch: 6| Step: 3
Training loss: 0.07153533177251929
Validation loss: 2.354139228927345

Epoch: 6| Step: 4
Training loss: 0.2566631446608086
Validation loss: 2.3897513296408426

Epoch: 6| Step: 5
Training loss: 0.11436996498386047
Validation loss: 2.4249316432432644

Epoch: 6| Step: 6
Training loss: 0.16819459126321512
Validation loss: 2.447194027366292

Epoch: 6| Step: 7
Training loss: 0.12552818821560227
Validation loss: 2.4795507655866262

Epoch: 6| Step: 8
Training loss: 0.13039251572990618
Validation loss: 2.4769562407963317

Epoch: 6| Step: 9
Training loss: 0.11336444397785474
Validation loss: 2.484983801343372

Epoch: 6| Step: 10
Training loss: 0.1087453677366511
Validation loss: 2.502470582069135

Epoch: 6| Step: 11
Training loss: 0.0902775677603129
Validation loss: 2.484327370905585

Epoch: 6| Step: 12
Training loss: 0.14573039881117406
Validation loss: 2.4843732798126617

Epoch: 6| Step: 13
Training loss: 0.18752586663161216
Validation loss: 2.4833766215663586

Epoch: 453| Step: 0
Training loss: 0.153590195625368
Validation loss: 2.483070419520801

Epoch: 6| Step: 1
Training loss: 0.1779779504837671
Validation loss: 2.45841462251371

Epoch: 6| Step: 2
Training loss: 0.15738850303733537
Validation loss: 2.3789020018794997

Epoch: 6| Step: 3
Training loss: 0.19056929337180503
Validation loss: 2.386775653382918

Epoch: 6| Step: 4
Training loss: 0.14257962735573393
Validation loss: 2.404657175237659

Epoch: 6| Step: 5
Training loss: 0.11321081240702822
Validation loss: 2.3892794565076976

Epoch: 6| Step: 6
Training loss: 0.10558691734200847
Validation loss: 2.4231827681343403

Epoch: 6| Step: 7
Training loss: 0.18399966797980125
Validation loss: 2.4839073634148003

Epoch: 6| Step: 8
Training loss: 0.11276239748735402
Validation loss: 2.5113489496948804

Epoch: 6| Step: 9
Training loss: 0.15547282534678022
Validation loss: 2.5413909670457997

Epoch: 6| Step: 10
Training loss: 0.17396147038910995
Validation loss: 2.5396960062778966

Epoch: 6| Step: 11
Training loss: 0.11548612863878606
Validation loss: 2.5399552136938657

Epoch: 6| Step: 12
Training loss: 0.19980190979936935
Validation loss: 2.5309618248182524

Epoch: 6| Step: 13
Training loss: 0.0957543031908914
Validation loss: 2.454023469560454

Epoch: 454| Step: 0
Training loss: 0.09276967793928154
Validation loss: 2.428266064305743

Epoch: 6| Step: 1
Training loss: 0.16472452426126122
Validation loss: 2.3822284135257568

Epoch: 6| Step: 2
Training loss: 0.13991049873115655
Validation loss: 2.342036024571338

Epoch: 6| Step: 3
Training loss: 0.14445160913987287
Validation loss: 2.36797679807285

Epoch: 6| Step: 4
Training loss: 0.18888278529899916
Validation loss: 2.3719845785185334

Epoch: 6| Step: 5
Training loss: 0.12485135822125468
Validation loss: 2.4045311043892323

Epoch: 6| Step: 6
Training loss: 0.1586850913331872
Validation loss: 2.414401201498005

Epoch: 6| Step: 7
Training loss: 0.13296366951960567
Validation loss: 2.4242513049103778

Epoch: 6| Step: 8
Training loss: 0.2149004774628843
Validation loss: 2.4137719373713566

Epoch: 6| Step: 9
Training loss: 0.15581029774195526
Validation loss: 2.411447722783454

Epoch: 6| Step: 10
Training loss: 0.10783036764637685
Validation loss: 2.421034542122789

Epoch: 6| Step: 11
Training loss: 0.0855871014535471
Validation loss: 2.4554212211362745

Epoch: 6| Step: 12
Training loss: 0.18386817267311809
Validation loss: 2.4444961424884504

Epoch: 6| Step: 13
Training loss: 0.06767024365733217
Validation loss: 2.4355402352316022

Epoch: 455| Step: 0
Training loss: 0.10539571564569719
Validation loss: 2.434923586254843

Epoch: 6| Step: 1
Training loss: 0.10814034606650692
Validation loss: 2.448293856795344

Epoch: 6| Step: 2
Training loss: 0.12825174778821863
Validation loss: 2.5052624208979486

Epoch: 6| Step: 3
Training loss: 0.19414551189573517
Validation loss: 2.4856888432743656

Epoch: 6| Step: 4
Training loss: 0.13424163343511364
Validation loss: 2.463178398216154

Epoch: 6| Step: 5
Training loss: 0.11745127555402983
Validation loss: 2.5101884702376727

Epoch: 6| Step: 6
Training loss: 0.10510176371466742
Validation loss: 2.531324200926993

Epoch: 6| Step: 7
Training loss: 0.11582317493497525
Validation loss: 2.5422164514690877

Epoch: 6| Step: 8
Training loss: 0.10711666444087754
Validation loss: 2.5411132920852118

Epoch: 6| Step: 9
Training loss: 0.12792103133873342
Validation loss: 2.526089009910224

Epoch: 6| Step: 10
Training loss: 0.16306117435148945
Validation loss: 2.5063524570348266

Epoch: 6| Step: 11
Training loss: 0.14082944763647692
Validation loss: 2.446314129844148

Epoch: 6| Step: 12
Training loss: 0.13793094575016893
Validation loss: 2.452716181711303

Epoch: 6| Step: 13
Training loss: 0.23891995768020668
Validation loss: 2.399390497841967

Epoch: 456| Step: 0
Training loss: 0.16599915927686992
Validation loss: 2.4250483545217048

Epoch: 6| Step: 1
Training loss: 0.11399062616046192
Validation loss: 2.387335168119805

Epoch: 6| Step: 2
Training loss: 0.10852678107032826
Validation loss: 2.377885072162448

Epoch: 6| Step: 3
Training loss: 0.08968262114197456
Validation loss: 2.38703398162391

Epoch: 6| Step: 4
Training loss: 0.22811832287566364
Validation loss: 2.3998675633600413

Epoch: 6| Step: 5
Training loss: 0.20593540300566424
Validation loss: 2.3880847370333615

Epoch: 6| Step: 6
Training loss: 0.20406214319697408
Validation loss: 2.3936949065654174

Epoch: 6| Step: 7
Training loss: 0.0964634625555539
Validation loss: 2.41487072901348

Epoch: 6| Step: 8
Training loss: 0.19552233867814348
Validation loss: 2.459872236694894

Epoch: 6| Step: 9
Training loss: 0.0713414463512183
Validation loss: 2.4723793311082605

Epoch: 6| Step: 10
Training loss: 0.09953521323884514
Validation loss: 2.4793246932286146

Epoch: 6| Step: 11
Training loss: 0.18588520123964586
Validation loss: 2.483062168184133

Epoch: 6| Step: 12
Training loss: 0.10202562213670395
Validation loss: 2.4607592363017314

Epoch: 6| Step: 13
Training loss: 0.16150720623158873
Validation loss: 2.3983781497323724

Epoch: 457| Step: 0
Training loss: 0.1588173645153504
Validation loss: 2.3963018514781913

Epoch: 6| Step: 1
Training loss: 0.14728984633574926
Validation loss: 2.4009402901901296

Epoch: 6| Step: 2
Training loss: 0.13390608354644934
Validation loss: 2.4037700136556355

Epoch: 6| Step: 3
Training loss: 0.10464761885336682
Validation loss: 2.4253785238289347

Epoch: 6| Step: 4
Training loss: 0.1510367324176603
Validation loss: 2.431630698892664

Epoch: 6| Step: 5
Training loss: 0.17354121801364905
Validation loss: 2.509340571241121

Epoch: 6| Step: 6
Training loss: 0.32367159162762627
Validation loss: 2.520738360565889

Epoch: 6| Step: 7
Training loss: 0.1194659037332048
Validation loss: 2.4768958387086446

Epoch: 6| Step: 8
Training loss: 0.11613443805905452
Validation loss: 2.468907739727986

Epoch: 6| Step: 9
Training loss: 0.1803928194866626
Validation loss: 2.4313991882253765

Epoch: 6| Step: 10
Training loss: 0.19712792680051613
Validation loss: 2.4594880595848423

Epoch: 6| Step: 11
Training loss: 0.266419526717408
Validation loss: 2.4256766214822894

Epoch: 6| Step: 12
Training loss: 0.2934566884982984
Validation loss: 2.4308801530548356

Epoch: 6| Step: 13
Training loss: 0.1735432895005983
Validation loss: 2.4204290566444597

Epoch: 458| Step: 0
Training loss: 0.2615658469994356
Validation loss: 2.453310790484485

Epoch: 6| Step: 1
Training loss: 0.202627930967676
Validation loss: 2.439343941629892

Epoch: 6| Step: 2
Training loss: 0.1693984938001581
Validation loss: 2.4652442765972205

Epoch: 6| Step: 3
Training loss: 0.16346007962460518
Validation loss: 2.436828015812992

Epoch: 6| Step: 4
Training loss: 0.2347984462397845
Validation loss: 2.447929462581818

Epoch: 6| Step: 5
Training loss: 0.21204990656274322
Validation loss: 2.4411065823312605

Epoch: 6| Step: 6
Training loss: 0.26884834186925183
Validation loss: 2.4237467465986016

Epoch: 6| Step: 7
Training loss: 0.17193282845147081
Validation loss: 2.4610338449052587

Epoch: 6| Step: 8
Training loss: 0.14905187552953883
Validation loss: 2.5211053564373556

Epoch: 6| Step: 9
Training loss: 0.3202428393095699
Validation loss: 2.5174031633865845

Epoch: 6| Step: 10
Training loss: 0.27139839347663963
Validation loss: 2.497121667526952

Epoch: 6| Step: 11
Training loss: 0.19123967376581621
Validation loss: 2.5469214614263054

Epoch: 6| Step: 12
Training loss: 0.19056718215244886
Validation loss: 2.5427601555145674

Epoch: 6| Step: 13
Training loss: 0.2054448980549258
Validation loss: 2.564484020522176

Epoch: 459| Step: 0
Training loss: 0.2700386109604241
Validation loss: 2.5768010821802965

Epoch: 6| Step: 1
Training loss: 0.22275342828347294
Validation loss: 2.5145885900935645

Epoch: 6| Step: 2
Training loss: 0.1874586496851447
Validation loss: 2.525126031560735

Epoch: 6| Step: 3
Training loss: 0.20061011721172667
Validation loss: 2.458009166281144

Epoch: 6| Step: 4
Training loss: 0.22375902836981626
Validation loss: 2.4402464661652834

Epoch: 6| Step: 5
Training loss: 0.3322012858611948
Validation loss: 2.4480547389301064

Epoch: 6| Step: 6
Training loss: 0.263121079078148
Validation loss: 2.458951345931805

Epoch: 6| Step: 7
Training loss: 0.2927113228551351
Validation loss: 2.462687271215628

Epoch: 6| Step: 8
Training loss: 0.21248046490690023
Validation loss: 2.4377490090776885

Epoch: 6| Step: 9
Training loss: 0.1874520319933583
Validation loss: 2.4246724591616693

Epoch: 6| Step: 10
Training loss: 0.18477544536663354
Validation loss: 2.480628466694314

Epoch: 6| Step: 11
Training loss: 0.2036520923244541
Validation loss: 2.503111203655327

Epoch: 6| Step: 12
Training loss: 0.20440386784093745
Validation loss: 2.5042783829141237

Epoch: 6| Step: 13
Training loss: 0.08625379788979447
Validation loss: 2.4706274961762342

Epoch: 460| Step: 0
Training loss: 0.16844093135247418
Validation loss: 2.500594997358116

Epoch: 6| Step: 1
Training loss: 0.16995516812617734
Validation loss: 2.467733013529168

Epoch: 6| Step: 2
Training loss: 0.2600656941755637
Validation loss: 2.443815068282773

Epoch: 6| Step: 3
Training loss: 0.18470497869993063
Validation loss: 2.464537534876879

Epoch: 6| Step: 4
Training loss: 0.1479986756505544
Validation loss: 2.469145049947006

Epoch: 6| Step: 5
Training loss: 0.1868974221853398
Validation loss: 2.504155013265954

Epoch: 6| Step: 6
Training loss: 0.31669396399915184
Validation loss: 2.5521693821443567

Epoch: 6| Step: 7
Training loss: 0.2262204070390871
Validation loss: 2.4871346713976674

Epoch: 6| Step: 8
Training loss: 0.26725773529566355
Validation loss: 2.436044840780206

Epoch: 6| Step: 9
Training loss: 0.19995125571448277
Validation loss: 2.4141502609997265

Epoch: 6| Step: 10
Training loss: 0.19671807923024587
Validation loss: 2.388929687251617

Epoch: 6| Step: 11
Training loss: 0.19365229719645238
Validation loss: 2.3652056941610655

Epoch: 6| Step: 12
Training loss: 0.28636270863260954
Validation loss: 2.3609257267175705

Epoch: 6| Step: 13
Training loss: 0.12246078220461014
Validation loss: 2.4036473919374544

Epoch: 461| Step: 0
Training loss: 0.23393620104967988
Validation loss: 2.439881723268329

Epoch: 6| Step: 1
Training loss: 0.2043808299583425
Validation loss: 2.484498712089942

Epoch: 6| Step: 2
Training loss: 0.34048488036027125
Validation loss: 2.535135978687081

Epoch: 6| Step: 3
Training loss: 0.154442272007576
Validation loss: 2.5407948874117467

Epoch: 6| Step: 4
Training loss: 0.16271918283129863
Validation loss: 2.50350996570646

Epoch: 6| Step: 5
Training loss: 0.25505448913893675
Validation loss: 2.5071187729153483

Epoch: 6| Step: 6
Training loss: 0.2442134824759502
Validation loss: 2.4982689996987224

Epoch: 6| Step: 7
Training loss: 0.2180808681368262
Validation loss: 2.4933229505380776

Epoch: 6| Step: 8
Training loss: 0.23484193066408124
Validation loss: 2.483991122073067

Epoch: 6| Step: 9
Training loss: 0.1398743023343623
Validation loss: 2.5037165162548303

Epoch: 6| Step: 10
Training loss: 0.2757186424145342
Validation loss: 2.4947282686017176

Epoch: 6| Step: 11
Training loss: 0.1927247083425449
Validation loss: 2.4692404527099487

Epoch: 6| Step: 12
Training loss: 0.1953812573523679
Validation loss: 2.477911804179329

Epoch: 6| Step: 13
Training loss: 0.1904906835436819
Validation loss: 2.4442270481555473

Epoch: 462| Step: 0
Training loss: 0.21962447443960548
Validation loss: 2.4414831284098684

Epoch: 6| Step: 1
Training loss: 0.24932051497232952
Validation loss: 2.4338091380319504

Epoch: 6| Step: 2
Training loss: 0.23500692689608987
Validation loss: 2.440535070120578

Epoch: 6| Step: 3
Training loss: 0.25468927101970484
Validation loss: 2.4750909190519073

Epoch: 6| Step: 4
Training loss: 0.14938511910938795
Validation loss: 2.406590254823322

Epoch: 6| Step: 5
Training loss: 0.16493833729862814
Validation loss: 2.3820690074345667

Epoch: 6| Step: 6
Training loss: 0.21640463735482238
Validation loss: 2.3461671092518133

Epoch: 6| Step: 7
Training loss: 0.21263564002221647
Validation loss: 2.3673339287289963

Epoch: 6| Step: 8
Training loss: 0.2286821801718085
Validation loss: 2.3419581815303387

Epoch: 6| Step: 9
Training loss: 0.30442751282639086
Validation loss: 2.3554849999733767

Epoch: 6| Step: 10
Training loss: 0.14121348377427745
Validation loss: 2.380773862761967

Epoch: 6| Step: 11
Training loss: 0.33024202600103236
Validation loss: 2.3804492201603824

Epoch: 6| Step: 12
Training loss: 0.23218704830705905
Validation loss: 2.4462361278508764

Epoch: 6| Step: 13
Training loss: 0.1566741669623113
Validation loss: 2.534230108433468

Epoch: 463| Step: 0
Training loss: 0.12689259626719607
Validation loss: 2.5319345516571925

Epoch: 6| Step: 1
Training loss: 0.2379558796323343
Validation loss: 2.515060767125027

Epoch: 6| Step: 2
Training loss: 0.17363063437572862
Validation loss: 2.4945446800454993

Epoch: 6| Step: 3
Training loss: 0.1380064809882345
Validation loss: 2.435623337344187

Epoch: 6| Step: 4
Training loss: 0.2332639186857282
Validation loss: 2.414636303939996

Epoch: 6| Step: 5
Training loss: 0.2444133913269631
Validation loss: 2.419823303124618

Epoch: 6| Step: 6
Training loss: 0.1529049744984535
Validation loss: 2.389080020485619

Epoch: 6| Step: 7
Training loss: 0.1459325952134534
Validation loss: 2.4620890355490612

Epoch: 6| Step: 8
Training loss: 0.14821339303714645
Validation loss: 2.4908581500376643

Epoch: 6| Step: 9
Training loss: 0.1710324878839505
Validation loss: 2.505979755397587

Epoch: 6| Step: 10
Training loss: 0.15728887069713948
Validation loss: 2.5107457877861803

Epoch: 6| Step: 11
Training loss: 0.250645890946744
Validation loss: 2.548958550269077

Epoch: 6| Step: 12
Training loss: 0.19147660461061733
Validation loss: 2.531693309722672

Epoch: 6| Step: 13
Training loss: 0.09730913460644633
Validation loss: 2.5227696609281884

Epoch: 464| Step: 0
Training loss: 0.1558382749018363
Validation loss: 2.519401415816508

Epoch: 6| Step: 1
Training loss: 0.15749736234938863
Validation loss: 2.4679648284080584

Epoch: 6| Step: 2
Training loss: 0.1492242168004296
Validation loss: 2.464890951608201

Epoch: 6| Step: 3
Training loss: 0.18377390605443683
Validation loss: 2.445177574278956

Epoch: 6| Step: 4
Training loss: 0.2994163433468336
Validation loss: 2.4293079637029433

Epoch: 6| Step: 5
Training loss: 0.19270956301082026
Validation loss: 2.4161276862501766

Epoch: 6| Step: 6
Training loss: 0.2035104963275088
Validation loss: 2.416787447543765

Epoch: 6| Step: 7
Training loss: 0.1768076705165177
Validation loss: 2.3912818023061115

Epoch: 6| Step: 8
Training loss: 0.1831144305261335
Validation loss: 2.3899607423529066

Epoch: 6| Step: 9
Training loss: 0.19081486603412934
Validation loss: 2.389849155188218

Epoch: 6| Step: 10
Training loss: 0.19792917278999062
Validation loss: 2.4210537060726565

Epoch: 6| Step: 11
Training loss: 0.23352945712419826
Validation loss: 2.468956171961964

Epoch: 6| Step: 12
Training loss: 0.1800047313214069
Validation loss: 2.518748228947367

Epoch: 6| Step: 13
Training loss: 0.11536493017892242
Validation loss: 2.5038488417091394

Epoch: 465| Step: 0
Training loss: 0.16963818864565253
Validation loss: 2.4601125964616433

Epoch: 6| Step: 1
Training loss: 0.23076726686424495
Validation loss: 2.4601737669943433

Epoch: 6| Step: 2
Training loss: 0.24606990698706405
Validation loss: 2.5007737346764247

Epoch: 6| Step: 3
Training loss: 0.11268129228487131
Validation loss: 2.48792723512834

Epoch: 6| Step: 4
Training loss: 0.19510353353723167
Validation loss: 2.5143737677368287

Epoch: 6| Step: 5
Training loss: 0.11800570951101327
Validation loss: 2.487786772933584

Epoch: 6| Step: 6
Training loss: 0.1782645293911035
Validation loss: 2.5059718782134732

Epoch: 6| Step: 7
Training loss: 0.2157828527193538
Validation loss: 2.507650404948409

Epoch: 6| Step: 8
Training loss: 0.15529576027152783
Validation loss: 2.5039674072721523

Epoch: 6| Step: 9
Training loss: 0.17966361509054177
Validation loss: 2.4349434989688823

Epoch: 6| Step: 10
Training loss: 0.10785646095191144
Validation loss: 2.4500141116604994

Epoch: 6| Step: 11
Training loss: 0.23627872581278908
Validation loss: 2.4406528543946298

Epoch: 6| Step: 12
Training loss: 0.23907816623642264
Validation loss: 2.4491761942751706

Epoch: 6| Step: 13
Training loss: 0.2679483261332662
Validation loss: 2.4688438287622496

Epoch: 466| Step: 0
Training loss: 0.14082482498705928
Validation loss: 2.4653546936924977

Epoch: 6| Step: 1
Training loss: 0.17701686401701286
Validation loss: 2.442799851118916

Epoch: 6| Step: 2
Training loss: 0.20709843714958767
Validation loss: 2.4170156160828564

Epoch: 6| Step: 3
Training loss: 0.19719125271051005
Validation loss: 2.4687454069901453

Epoch: 6| Step: 4
Training loss: 0.20030637312161662
Validation loss: 2.47392933403769

Epoch: 6| Step: 5
Training loss: 0.2106987874026952
Validation loss: 2.468949914337773

Epoch: 6| Step: 6
Training loss: 0.20545905928005476
Validation loss: 2.490270031732652

Epoch: 6| Step: 7
Training loss: 0.20050753925066309
Validation loss: 2.472606705159809

Epoch: 6| Step: 8
Training loss: 0.21538735022976613
Validation loss: 2.456826873839769

Epoch: 6| Step: 9
Training loss: 0.1424627817325864
Validation loss: 2.433550771448537

Epoch: 6| Step: 10
Training loss: 0.13763795835051273
Validation loss: 2.4121693226767853

Epoch: 6| Step: 11
Training loss: 0.14530883215305254
Validation loss: 2.411757346166438

Epoch: 6| Step: 12
Training loss: 0.21720778555782386
Validation loss: 2.4153008411486487

Epoch: 6| Step: 13
Training loss: 0.2717909831093483
Validation loss: 2.43711542146258

Epoch: 467| Step: 0
Training loss: 0.2242053835403688
Validation loss: 2.446135435568851

Epoch: 6| Step: 1
Training loss: 0.19023866119882593
Validation loss: 2.4553464309124178

Epoch: 6| Step: 2
Training loss: 0.1785385259050106
Validation loss: 2.415712814009516

Epoch: 6| Step: 3
Training loss: 0.24283659766325033
Validation loss: 2.4187185679558234

Epoch: 6| Step: 4
Training loss: 0.22830727852459112
Validation loss: 2.4586689196651403

Epoch: 6| Step: 5
Training loss: 0.1828007718750248
Validation loss: 2.459398924770922

Epoch: 6| Step: 6
Training loss: 0.2179216299774287
Validation loss: 2.4572433337629307

Epoch: 6| Step: 7
Training loss: 0.17245267111644305
Validation loss: 2.4708650261542915

Epoch: 6| Step: 8
Training loss: 0.2773492302151676
Validation loss: 2.51735058352417

Epoch: 6| Step: 9
Training loss: 0.21496980610346964
Validation loss: 2.5140872026443577

Epoch: 6| Step: 10
Training loss: 0.24343451813963785
Validation loss: 2.4931247124325377

Epoch: 6| Step: 11
Training loss: 0.19514715825596246
Validation loss: 2.452206792690958

Epoch: 6| Step: 12
Training loss: 0.22183333966184485
Validation loss: 2.462100267965872

Epoch: 6| Step: 13
Training loss: 0.37971122023973375
Validation loss: 2.411887214974802

Epoch: 468| Step: 0
Training loss: 0.1303772156953207
Validation loss: 2.4459962915887408

Epoch: 6| Step: 1
Training loss: 0.26338782374950637
Validation loss: 2.481387756496073

Epoch: 6| Step: 2
Training loss: 0.23761055312018567
Validation loss: 2.505690386132152

Epoch: 6| Step: 3
Training loss: 0.17344706805359528
Validation loss: 2.4730638038133756

Epoch: 6| Step: 4
Training loss: 0.2704678860611453
Validation loss: 2.4598079132707857

Epoch: 6| Step: 5
Training loss: 0.3308814616752289
Validation loss: 2.443459246856803

Epoch: 6| Step: 6
Training loss: 0.14142874333325103
Validation loss: 2.3913183491661862

Epoch: 6| Step: 7
Training loss: 0.3786718685778977
Validation loss: 2.332711207899912

Epoch: 6| Step: 8
Training loss: 0.4181576952389369
Validation loss: 2.391640514144897

Epoch: 6| Step: 9
Training loss: 0.2371129096960208
Validation loss: 2.473375851895596

Epoch: 6| Step: 10
Training loss: 0.34141130770989525
Validation loss: 2.5849225338431405

Epoch: 6| Step: 11
Training loss: 0.33171405226498113
Validation loss: 2.6302690708324135

Epoch: 6| Step: 12
Training loss: 0.6057207383028378
Validation loss: 2.6190461515061085

Epoch: 6| Step: 13
Training loss: 0.2043357673517422
Validation loss: 2.4994427972675535

Epoch: 469| Step: 0
Training loss: 0.3788651316247065
Validation loss: 2.3946461326045463

Epoch: 6| Step: 1
Training loss: 0.3469316238719352
Validation loss: 2.356043748882844

Epoch: 6| Step: 2
Training loss: 0.21963884086071506
Validation loss: 2.3295498573274895

Epoch: 6| Step: 3
Training loss: 0.20111244212599105
Validation loss: 2.364408066877385

Epoch: 6| Step: 4
Training loss: 0.4104628915299689
Validation loss: 2.4316055771730536

Epoch: 6| Step: 5
Training loss: 0.42506961673073235
Validation loss: 2.475454007124066

Epoch: 6| Step: 6
Training loss: 0.4153433368793603
Validation loss: 2.518718317996434

Epoch: 6| Step: 7
Training loss: 0.48999018875828915
Validation loss: 2.4883795919193528

Epoch: 6| Step: 8
Training loss: 0.2536382875096862
Validation loss: 2.414260070189094

Epoch: 6| Step: 9
Training loss: 0.588706125783047
Validation loss: 2.356061551968123

Epoch: 6| Step: 10
Training loss: 0.4721469184104333
Validation loss: 2.427454667615871

Epoch: 6| Step: 11
Training loss: 0.33680585146210423
Validation loss: 2.5125326141540927

Epoch: 6| Step: 12
Training loss: 0.5358250191321846
Validation loss: 2.623086708641182

Epoch: 6| Step: 13
Training loss: 0.12899832615995466
Validation loss: 2.644921391179669

Epoch: 470| Step: 0
Training loss: 0.2610734984912413
Validation loss: 2.579172110067661

Epoch: 6| Step: 1
Training loss: 0.3529775856165178
Validation loss: 2.5109413278497965

Epoch: 6| Step: 2
Training loss: 0.2632113355407305
Validation loss: 2.4494954174521437

Epoch: 6| Step: 3
Training loss: 0.2362553823453371
Validation loss: 2.365680761015099

Epoch: 6| Step: 4
Training loss: 0.29067843058841847
Validation loss: 2.397360475936227

Epoch: 6| Step: 5
Training loss: 0.3656487383839091
Validation loss: 2.3479176689821535

Epoch: 6| Step: 6
Training loss: 0.3430538606290779
Validation loss: 2.4121478551922535

Epoch: 6| Step: 7
Training loss: 0.2625895290741442
Validation loss: 2.4471341603668684

Epoch: 6| Step: 8
Training loss: 0.2663839101513965
Validation loss: 2.4884445274145124

Epoch: 6| Step: 9
Training loss: 0.23559958499220596
Validation loss: 2.450870234048566

Epoch: 6| Step: 10
Training loss: 0.2504571668548743
Validation loss: 2.4571973759920827

Epoch: 6| Step: 11
Training loss: 0.288373383476578
Validation loss: 2.410313416173421

Epoch: 6| Step: 12
Training loss: 0.27845956096314817
Validation loss: 2.367845796867101

Epoch: 6| Step: 13
Training loss: 0.4555901851356281
Validation loss: 2.356660016548528

Epoch: 471| Step: 0
Training loss: 0.36744962629230976
Validation loss: 2.4135749468715457

Epoch: 6| Step: 1
Training loss: 0.19267053920847996
Validation loss: 2.5073132778847276

Epoch: 6| Step: 2
Training loss: 0.2453251826294091
Validation loss: 2.578589680478932

Epoch: 6| Step: 3
Training loss: 0.4011918773326148
Validation loss: 2.6116281407111486

Epoch: 6| Step: 4
Training loss: 0.2867869428568627
Validation loss: 2.5373992343844494

Epoch: 6| Step: 5
Training loss: 0.31020489942922896
Validation loss: 2.486745876217023

Epoch: 6| Step: 6
Training loss: 0.1832744581520231
Validation loss: 2.3751048851276995

Epoch: 6| Step: 7
Training loss: 0.3905956829513673
Validation loss: 2.3311468217078826

Epoch: 6| Step: 8
Training loss: 0.3537017163865687
Validation loss: 2.2971248790749543

Epoch: 6| Step: 9
Training loss: 0.40850670946860845
Validation loss: 2.3101111381291175

Epoch: 6| Step: 10
Training loss: 0.22914047073426697
Validation loss: 2.3872743058032313

Epoch: 6| Step: 11
Training loss: 0.4741903425377594
Validation loss: 2.480877335118451

Epoch: 6| Step: 12
Training loss: 0.4153166437337003
Validation loss: 2.466166235475354

Epoch: 6| Step: 13
Training loss: 0.19378634235031625
Validation loss: 2.4320046036608365

Epoch: 472| Step: 0
Training loss: 0.24202852261153557
Validation loss: 2.400534437819329

Epoch: 6| Step: 1
Training loss: 0.26583937801516194
Validation loss: 2.361869799620848

Epoch: 6| Step: 2
Training loss: 0.2909375540449541
Validation loss: 2.3531764544517983

Epoch: 6| Step: 3
Training loss: 0.39936962673291787
Validation loss: 2.400287649828388

Epoch: 6| Step: 4
Training loss: 0.2299653309499106
Validation loss: 2.41550882953174

Epoch: 6| Step: 5
Training loss: 0.18071907855377858
Validation loss: 2.488183049469846

Epoch: 6| Step: 6
Training loss: 0.24033108757171687
Validation loss: 2.4658911587887506

Epoch: 6| Step: 7
Training loss: 0.24663549164730628
Validation loss: 2.47812983129342

Epoch: 6| Step: 8
Training loss: 0.1619188038830059
Validation loss: 2.4880247904261243

Epoch: 6| Step: 9
Training loss: 0.2175433050540976
Validation loss: 2.479569007886647

Epoch: 6| Step: 10
Training loss: 0.4324892082962763
Validation loss: 2.451303682083278

Epoch: 6| Step: 11
Training loss: 0.30185869376250174
Validation loss: 2.4826587990485605

Epoch: 6| Step: 12
Training loss: 0.13597186985921073
Validation loss: 2.4636727634029794

Epoch: 6| Step: 13
Training loss: 0.40340313742197254
Validation loss: 2.5379076834436036

Epoch: 473| Step: 0
Training loss: 0.17705722340532318
Validation loss: 2.4949087301774173

Epoch: 6| Step: 1
Training loss: 0.3410621593837844
Validation loss: 2.4626170781276437

Epoch: 6| Step: 2
Training loss: 0.25888972214115374
Validation loss: 2.40761605906295

Epoch: 6| Step: 3
Training loss: 0.2546517212432627
Validation loss: 2.4439322072267027

Epoch: 6| Step: 4
Training loss: 0.43614255259631163
Validation loss: 2.4187643800442458

Epoch: 6| Step: 5
Training loss: 0.3210197874028203
Validation loss: 2.4304933330425387

Epoch: 6| Step: 6
Training loss: 0.1834116296218086
Validation loss: 2.376023975280251

Epoch: 6| Step: 7
Training loss: 0.4558046296629011
Validation loss: 2.3529038737220156

Epoch: 6| Step: 8
Training loss: 0.36607260570934985
Validation loss: 2.3172512737999065

Epoch: 6| Step: 9
Training loss: 0.23201271715229552
Validation loss: 2.3193421251509143

Epoch: 6| Step: 10
Training loss: 0.5064739485477572
Validation loss: 2.3495431240342017

Epoch: 6| Step: 11
Training loss: 0.39546229724600906
Validation loss: 2.4098738606315213

Epoch: 6| Step: 12
Training loss: 0.25281592797028873
Validation loss: 2.3881383401694727

Epoch: 6| Step: 13
Training loss: 0.4155085343116773
Validation loss: 2.404794407484184

Epoch: 474| Step: 0
Training loss: 0.3754271617499219
Validation loss: 2.4539742557859348

Epoch: 6| Step: 1
Training loss: 0.3011095558931236
Validation loss: 2.457001464179075

Epoch: 6| Step: 2
Training loss: 0.33090425972786264
Validation loss: 2.460848923987188

Epoch: 6| Step: 3
Training loss: 0.2608340955048741
Validation loss: 2.4505127060396146

Epoch: 6| Step: 4
Training loss: 0.3173551107201543
Validation loss: 2.4591938717895734

Epoch: 6| Step: 5
Training loss: 0.2996948239701444
Validation loss: 2.5427359855397014

Epoch: 6| Step: 6
Training loss: 0.2741653292535397
Validation loss: 2.574785863246087

Epoch: 6| Step: 7
Training loss: 0.29050723735572354
Validation loss: 2.617616343852953

Epoch: 6| Step: 8
Training loss: 0.2811629902505652
Validation loss: 2.576316354205188

Epoch: 6| Step: 9
Training loss: 0.3072340259263863
Validation loss: 2.5598173803671793

Epoch: 6| Step: 10
Training loss: 0.3169577583987937
Validation loss: 2.4904329543507284

Epoch: 6| Step: 11
Training loss: 0.40379512446125576
Validation loss: 2.4349812171806082

Epoch: 6| Step: 12
Training loss: 0.3791082571264974
Validation loss: 2.3409283668278276

Epoch: 6| Step: 13
Training loss: 0.371003631892768
Validation loss: 2.3589863279433554

Epoch: 475| Step: 0
Training loss: 0.23803084145143177
Validation loss: 2.3419657193254824

Epoch: 6| Step: 1
Training loss: 0.22295813423607191
Validation loss: 2.358935019499331

Epoch: 6| Step: 2
Training loss: 0.32669077503072713
Validation loss: 2.443988249490813

Epoch: 6| Step: 3
Training loss: 0.4004942597038569
Validation loss: 2.4457209924504393

Epoch: 6| Step: 4
Training loss: 0.386277206814507
Validation loss: 2.4229374106391224

Epoch: 6| Step: 5
Training loss: 0.2750771950616911
Validation loss: 2.354228298140253

Epoch: 6| Step: 6
Training loss: 0.260241338200947
Validation loss: 2.3414743014113393

Epoch: 6| Step: 7
Training loss: 0.31455027815012593
Validation loss: 2.3504414364820327

Epoch: 6| Step: 8
Training loss: 0.3128876903839221
Validation loss: 2.3771163845670125

Epoch: 6| Step: 9
Training loss: 0.2625059274730834
Validation loss: 2.4116636908307503

Epoch: 6| Step: 10
Training loss: 0.28721149730355433
Validation loss: 2.4672478801931943

Epoch: 6| Step: 11
Training loss: 0.32905757168577926
Validation loss: 2.5104480360710424

Epoch: 6| Step: 12
Training loss: 0.26471920404540494
Validation loss: 2.517790168140497

Epoch: 6| Step: 13
Training loss: 0.321746824724584
Validation loss: 2.523151376023133

Epoch: 476| Step: 0
Training loss: 0.3777625727262162
Validation loss: 2.49128365287231

Epoch: 6| Step: 1
Training loss: 0.21485450891085087
Validation loss: 2.4822226206756266

Epoch: 6| Step: 2
Training loss: 0.2999733937902818
Validation loss: 2.4542576980971735

Epoch: 6| Step: 3
Training loss: 0.27134426535751077
Validation loss: 2.423212350748919

Epoch: 6| Step: 4
Training loss: 0.2905431150114641
Validation loss: 2.4593875856803664

Epoch: 6| Step: 5
Training loss: 0.2261734944287237
Validation loss: 2.514867320089791

Epoch: 6| Step: 6
Training loss: 0.3259117093950809
Validation loss: 2.6148352994081607

Epoch: 6| Step: 7
Training loss: 0.3336692796024319
Validation loss: 2.6107002627765783

Epoch: 6| Step: 8
Training loss: 0.30283303652746896
Validation loss: 2.5898696743942367

Epoch: 6| Step: 9
Training loss: 0.21992683608318667
Validation loss: 2.5012816896851175

Epoch: 6| Step: 10
Training loss: 0.26722426579813774
Validation loss: 2.50266699303245

Epoch: 6| Step: 11
Training loss: 0.44138602826545414
Validation loss: 2.4717889702786557

Epoch: 6| Step: 12
Training loss: 0.24606787076238146
Validation loss: 2.4633074293551167

Epoch: 6| Step: 13
Training loss: 0.22388146249271113
Validation loss: 2.4748649106199987

Epoch: 477| Step: 0
Training loss: 0.4068692879048795
Validation loss: 2.4946913787114946

Epoch: 6| Step: 1
Training loss: 0.26085263316949775
Validation loss: 2.5176623351729885

Epoch: 6| Step: 2
Training loss: 0.2333304813046086
Validation loss: 2.5628525156075836

Epoch: 6| Step: 3
Training loss: 0.296074792662708
Validation loss: 2.5526024895394213

Epoch: 6| Step: 4
Training loss: 0.25442091792174415
Validation loss: 2.5502821730189935

Epoch: 6| Step: 5
Training loss: 0.27719171144539606
Validation loss: 2.4705211599147496

Epoch: 6| Step: 6
Training loss: 0.24894544090556195
Validation loss: 2.4113514538830407

Epoch: 6| Step: 7
Training loss: 0.21464621392609126
Validation loss: 2.390008478936102

Epoch: 6| Step: 8
Training loss: 0.21694078051098728
Validation loss: 2.363322847699074

Epoch: 6| Step: 9
Training loss: 0.38461881828609384
Validation loss: 2.3797458710927892

Epoch: 6| Step: 10
Training loss: 0.192545236483506
Validation loss: 2.476377745874658

Epoch: 6| Step: 11
Training loss: 0.29325852368545463
Validation loss: 2.508951811506595

Epoch: 6| Step: 12
Training loss: 0.24229994593803506
Validation loss: 2.521876264236031

Epoch: 6| Step: 13
Training loss: 0.2178027214580854
Validation loss: 2.4993278322745724

Epoch: 478| Step: 0
Training loss: 0.1788631791321521
Validation loss: 2.462969308001772

Epoch: 6| Step: 1
Training loss: 0.19689542195198412
Validation loss: 2.390408761308124

Epoch: 6| Step: 2
Training loss: 0.2487733969395928
Validation loss: 2.3784992688838367

Epoch: 6| Step: 3
Training loss: 0.21309584604192694
Validation loss: 2.3365974258210387

Epoch: 6| Step: 4
Training loss: 0.1657132368046498
Validation loss: 2.343862545907157

Epoch: 6| Step: 5
Training loss: 0.211513280932895
Validation loss: 2.3345517374791505

Epoch: 6| Step: 6
Training loss: 0.2640810864018816
Validation loss: 2.3498927423990317

Epoch: 6| Step: 7
Training loss: 0.21482828257976194
Validation loss: 2.4148754324531456

Epoch: 6| Step: 8
Training loss: 0.19111987508510445
Validation loss: 2.442108957275007

Epoch: 6| Step: 9
Training loss: 0.19633590556832037
Validation loss: 2.4774508875700674

Epoch: 6| Step: 10
Training loss: 0.22444058586066407
Validation loss: 2.519485254194592

Epoch: 6| Step: 11
Training loss: 0.22562121656262568
Validation loss: 2.511145523246709

Epoch: 6| Step: 12
Training loss: 0.33938852053171975
Validation loss: 2.503142828137441

Epoch: 6| Step: 13
Training loss: 0.20205281709702755
Validation loss: 2.4635938156600017

Epoch: 479| Step: 0
Training loss: 0.1740994211552642
Validation loss: 2.407370382266496

Epoch: 6| Step: 1
Training loss: 0.2964019520095559
Validation loss: 2.394081511774347

Epoch: 6| Step: 2
Training loss: 0.12236689587343823
Validation loss: 2.4004650790783058

Epoch: 6| Step: 3
Training loss: 0.14865062496608553
Validation loss: 2.4603680054746646

Epoch: 6| Step: 4
Training loss: 0.1669368038580721
Validation loss: 2.467093963565507

Epoch: 6| Step: 5
Training loss: 0.18698105921801395
Validation loss: 2.5041866092100395

Epoch: 6| Step: 6
Training loss: 0.13783121504183168
Validation loss: 2.4939955920710637

Epoch: 6| Step: 7
Training loss: 0.2525093090588634
Validation loss: 2.523989582335977

Epoch: 6| Step: 8
Training loss: 0.14165973126273926
Validation loss: 2.531567854264458

Epoch: 6| Step: 9
Training loss: 0.26239308268846984
Validation loss: 2.540266048142874

Epoch: 6| Step: 10
Training loss: 0.1965375816852604
Validation loss: 2.500826860914618

Epoch: 6| Step: 11
Training loss: 0.2009750625658181
Validation loss: 2.4790543558090703

Epoch: 6| Step: 12
Training loss: 0.3192288513751308
Validation loss: 2.432321898246665

Epoch: 6| Step: 13
Training loss: 0.288377840251354
Validation loss: 2.361155469921279

Epoch: 480| Step: 0
Training loss: 0.2006239419534895
Validation loss: 2.3285648700944974

Epoch: 6| Step: 1
Training loss: 0.24615333229428826
Validation loss: 2.2973323414419706

Epoch: 6| Step: 2
Training loss: 0.17915621249246597
Validation loss: 2.3595339672568048

Epoch: 6| Step: 3
Training loss: 0.1589503361959703
Validation loss: 2.379623643568876

Epoch: 6| Step: 4
Training loss: 0.2196419446983835
Validation loss: 2.3994624604085324

Epoch: 6| Step: 5
Training loss: 0.24828738469682574
Validation loss: 2.4252650451945437

Epoch: 6| Step: 6
Training loss: 0.2029156614858991
Validation loss: 2.446643224950196

Epoch: 6| Step: 7
Training loss: 0.11917916831369506
Validation loss: 2.40479656517646

Epoch: 6| Step: 8
Training loss: 0.17388918693544952
Validation loss: 2.410383654555806

Epoch: 6| Step: 9
Training loss: 0.19853967041347662
Validation loss: 2.394784723749501

Epoch: 6| Step: 10
Training loss: 0.26188876195540456
Validation loss: 2.3908148592385556

Epoch: 6| Step: 11
Training loss: 0.1780914450712329
Validation loss: 2.4058838997154135

Epoch: 6| Step: 12
Training loss: 0.10722720974586128
Validation loss: 2.4095675267178462

Epoch: 6| Step: 13
Training loss: 0.19868333712210004
Validation loss: 2.423499579139075

Epoch: 481| Step: 0
Training loss: 0.24176602451802034
Validation loss: 2.4444921861139832

Epoch: 6| Step: 1
Training loss: 0.09926955844538182
Validation loss: 2.4345048972360916

Epoch: 6| Step: 2
Training loss: 0.13609152377089195
Validation loss: 2.3960164171827705

Epoch: 6| Step: 3
Training loss: 0.15640539548261287
Validation loss: 2.445154345287127

Epoch: 6| Step: 4
Training loss: 0.15035925575171544
Validation loss: 2.4259501066814226

Epoch: 6| Step: 5
Training loss: 0.1686916817895499
Validation loss: 2.4607641036276475

Epoch: 6| Step: 6
Training loss: 0.23136881276271026
Validation loss: 2.462516483597143

Epoch: 6| Step: 7
Training loss: 0.1414930190695447
Validation loss: 2.4757365160785287

Epoch: 6| Step: 8
Training loss: 0.18169338731573725
Validation loss: 2.4494554924963237

Epoch: 6| Step: 9
Training loss: 0.17488605054899936
Validation loss: 2.4847171088958047

Epoch: 6| Step: 10
Training loss: 0.15071573044545966
Validation loss: 2.4631103174068754

Epoch: 6| Step: 11
Training loss: 0.13070254393572112
Validation loss: 2.460009052951261

Epoch: 6| Step: 12
Training loss: 0.17265208096886514
Validation loss: 2.468496654133898

Epoch: 6| Step: 13
Training loss: 0.16786809611237705
Validation loss: 2.4589526069256666

Epoch: 482| Step: 0
Training loss: 0.09203930051303465
Validation loss: 2.4457413659901133

Epoch: 6| Step: 1
Training loss: 0.16775977086812682
Validation loss: 2.4333120635463263

Epoch: 6| Step: 2
Training loss: 0.20707663452480157
Validation loss: 2.4751612969826873

Epoch: 6| Step: 3
Training loss: 0.15071283849021827
Validation loss: 2.4571882771904985

Epoch: 6| Step: 4
Training loss: 0.12706965453631014
Validation loss: 2.455521088927776

Epoch: 6| Step: 5
Training loss: 0.1818272237195641
Validation loss: 2.4549912036681105

Epoch: 6| Step: 6
Training loss: 0.18954894995062707
Validation loss: 2.468493960151135

Epoch: 6| Step: 7
Training loss: 0.13954233927515758
Validation loss: 2.4603562999056825

Epoch: 6| Step: 8
Training loss: 0.15815325527902244
Validation loss: 2.462133480738191

Epoch: 6| Step: 9
Training loss: 0.17379457171353524
Validation loss: 2.484382005339704

Epoch: 6| Step: 10
Training loss: 0.22417547359916387
Validation loss: 2.4487854940612004

Epoch: 6| Step: 11
Training loss: 0.1944398075262348
Validation loss: 2.464943152832182

Epoch: 6| Step: 12
Training loss: 0.16965092508950316
Validation loss: 2.3849627280569665

Epoch: 6| Step: 13
Training loss: 0.13320749113472716
Validation loss: 2.3907730166098493

Epoch: 483| Step: 0
Training loss: 0.1388566840769462
Validation loss: 2.4030000366627022

Epoch: 6| Step: 1
Training loss: 0.13804738371171899
Validation loss: 2.3990097766065532

Epoch: 6| Step: 2
Training loss: 0.20968782271404418
Validation loss: 2.4241801020031604

Epoch: 6| Step: 3
Training loss: 0.22448893095820327
Validation loss: 2.457576697491354

Epoch: 6| Step: 4
Training loss: 0.1445675495031069
Validation loss: 2.4569582335604525

Epoch: 6| Step: 5
Training loss: 0.1190030679652886
Validation loss: 2.4560135001996

Epoch: 6| Step: 6
Training loss: 0.13602396308981862
Validation loss: 2.4582693725352143

Epoch: 6| Step: 7
Training loss: 0.09293959945983045
Validation loss: 2.4782203411728663

Epoch: 6| Step: 8
Training loss: 0.17120572937118328
Validation loss: 2.4847599726284004

Epoch: 6| Step: 9
Training loss: 0.23319519642909406
Validation loss: 2.474394993913932

Epoch: 6| Step: 10
Training loss: 0.10454076012371258
Validation loss: 2.412565055810359

Epoch: 6| Step: 11
Training loss: 0.17841815416047682
Validation loss: 2.4434347435443353

Epoch: 6| Step: 12
Training loss: 0.14730808091282369
Validation loss: 2.41451495606757

Epoch: 6| Step: 13
Training loss: 0.24185588652722487
Validation loss: 2.429920652901818

Epoch: 484| Step: 0
Training loss: 0.1029118573129098
Validation loss: 2.4923133485290467

Epoch: 6| Step: 1
Training loss: 0.1237324545143189
Validation loss: 2.553517039144726

Epoch: 6| Step: 2
Training loss: 0.26076216031847804
Validation loss: 2.585775380879726

Epoch: 6| Step: 3
Training loss: 0.24469182924116628
Validation loss: 2.5637560091542078

Epoch: 6| Step: 4
Training loss: 0.26924087251973516
Validation loss: 2.541973395241475

Epoch: 6| Step: 5
Training loss: 0.19674110552206203
Validation loss: 2.451791484853197

Epoch: 6| Step: 6
Training loss: 0.22336882622954815
Validation loss: 2.3697180331660053

Epoch: 6| Step: 7
Training loss: 0.2252543270339019
Validation loss: 2.3555704512972926

Epoch: 6| Step: 8
Training loss: 0.32201903185369624
Validation loss: 2.297885163400767

Epoch: 6| Step: 9
Training loss: 0.19475368666679047
Validation loss: 2.381648302172422

Epoch: 6| Step: 10
Training loss: 0.10137071290987756
Validation loss: 2.415325032836802

Epoch: 6| Step: 11
Training loss: 0.11661960966935286
Validation loss: 2.5002330486823796

Epoch: 6| Step: 12
Training loss: 0.2990726891339476
Validation loss: 2.5679603064810252

Epoch: 6| Step: 13
Training loss: 0.19568409855803462
Validation loss: 2.5733550577844917

Epoch: 485| Step: 0
Training loss: 0.2184192336580616
Validation loss: 2.5639862184577615

Epoch: 6| Step: 1
Training loss: 0.1206114454757621
Validation loss: 2.5592868527766366

Epoch: 6| Step: 2
Training loss: 0.15359265139818457
Validation loss: 2.527236795470779

Epoch: 6| Step: 3
Training loss: 0.14502411652068864
Validation loss: 2.534556191830217

Epoch: 6| Step: 4
Training loss: 0.14861912658080934
Validation loss: 2.5272880041250807

Epoch: 6| Step: 5
Training loss: 0.22306070902825012
Validation loss: 2.50631535261555

Epoch: 6| Step: 6
Training loss: 0.1794456429887643
Validation loss: 2.521907726597549

Epoch: 6| Step: 7
Training loss: 0.19756449352587296
Validation loss: 2.5269190304968325

Epoch: 6| Step: 8
Training loss: 0.17981362063112066
Validation loss: 2.520202579840957

Epoch: 6| Step: 9
Training loss: 0.19075568245751803
Validation loss: 2.518376255258295

Epoch: 6| Step: 10
Training loss: 0.2273109831907542
Validation loss: 2.506037201827284

Epoch: 6| Step: 11
Training loss: 0.2505459486703666
Validation loss: 2.499159175209153

Epoch: 6| Step: 12
Training loss: 0.22339460854901785
Validation loss: 2.495592638728419

Epoch: 6| Step: 13
Training loss: 0.2013486992445147
Validation loss: 2.5125894699855493

Epoch: 486| Step: 0
Training loss: 0.16789793584392862
Validation loss: 2.485495223632919

Epoch: 6| Step: 1
Training loss: 0.18372054490005704
Validation loss: 2.457894390526562

Epoch: 6| Step: 2
Training loss: 0.1018075828600123
Validation loss: 2.420974179533772

Epoch: 6| Step: 3
Training loss: 0.18804098604218422
Validation loss: 2.397675310577159

Epoch: 6| Step: 4
Training loss: 0.2449848151975188
Validation loss: 2.3753580232093214

Epoch: 6| Step: 5
Training loss: 0.192189182103557
Validation loss: 2.3874672512769246

Epoch: 6| Step: 6
Training loss: 0.1934157010122395
Validation loss: 2.333253727454425

Epoch: 6| Step: 7
Training loss: 0.16665140593717115
Validation loss: 2.356269437086803

Epoch: 6| Step: 8
Training loss: 0.21385964506601446
Validation loss: 2.3670135079965684

Epoch: 6| Step: 9
Training loss: 0.14892998361130352
Validation loss: 2.3766358079373773

Epoch: 6| Step: 10
Training loss: 0.14748277565636247
Validation loss: 2.359988335986797

Epoch: 6| Step: 11
Training loss: 0.1079462172379285
Validation loss: 2.397035151974274

Epoch: 6| Step: 12
Training loss: 0.1189894342254855
Validation loss: 2.4186218260826893

Epoch: 6| Step: 13
Training loss: 0.0905126724370724
Validation loss: 2.4165707184779497

Epoch: 487| Step: 0
Training loss: 0.14924621504029056
Validation loss: 2.392946578069374

Epoch: 6| Step: 1
Training loss: 0.21244760666812376
Validation loss: 2.427194844078069

Epoch: 6| Step: 2
Training loss: 0.1617453866482021
Validation loss: 2.4281021536668472

Epoch: 6| Step: 3
Training loss: 0.12530147437394998
Validation loss: 2.426754241846316

Epoch: 6| Step: 4
Training loss: 0.10714285767504148
Validation loss: 2.410100081599631

Epoch: 6| Step: 5
Training loss: 0.11339560442442984
Validation loss: 2.435455394492284

Epoch: 6| Step: 6
Training loss: 0.13165884486135132
Validation loss: 2.408669425090573

Epoch: 6| Step: 7
Training loss: 0.1417854102152635
Validation loss: 2.3879043558388897

Epoch: 6| Step: 8
Training loss: 0.18124245512813625
Validation loss: 2.446326931696403

Epoch: 6| Step: 9
Training loss: 0.19327844987782225
Validation loss: 2.469780393946956

Epoch: 6| Step: 10
Training loss: 0.11650015800182942
Validation loss: 2.483549682522277

Epoch: 6| Step: 11
Training loss: 0.19082526178100892
Validation loss: 2.463720924987248

Epoch: 6| Step: 12
Training loss: 0.20334684655033275
Validation loss: 2.4862943357854403

Epoch: 6| Step: 13
Training loss: 0.13846790733244568
Validation loss: 2.464045686215954

Epoch: 488| Step: 0
Training loss: 0.13003826876782243
Validation loss: 2.465923535064676

Epoch: 6| Step: 1
Training loss: 0.18007699589571857
Validation loss: 2.4392747268556105

Epoch: 6| Step: 2
Training loss: 0.1443689117654837
Validation loss: 2.4094933517800103

Epoch: 6| Step: 3
Training loss: 0.11916600410431734
Validation loss: 2.425416374932959

Epoch: 6| Step: 4
Training loss: 0.14409955739678676
Validation loss: 2.4226563123911253

Epoch: 6| Step: 5
Training loss: 0.16402584756423777
Validation loss: 2.3576712201500776

Epoch: 6| Step: 6
Training loss: 0.16353824846275308
Validation loss: 2.3896699354587825

Epoch: 6| Step: 7
Training loss: 0.12141276070235815
Validation loss: 2.40911483888531

Epoch: 6| Step: 8
Training loss: 0.1760022257933703
Validation loss: 2.4291618682583724

Epoch: 6| Step: 9
Training loss: 0.10936057046666604
Validation loss: 2.4384317208117694

Epoch: 6| Step: 10
Training loss: 0.12789599142309743
Validation loss: 2.44691239918031

Epoch: 6| Step: 11
Training loss: 0.1959558286870456
Validation loss: 2.451843303109698

Epoch: 6| Step: 12
Training loss: 0.13656103710595657
Validation loss: 2.4827571633528387

Epoch: 6| Step: 13
Training loss: 0.2647879961005995
Validation loss: 2.499875413189846

Epoch: 489| Step: 0
Training loss: 0.20195940181341185
Validation loss: 2.4871854069825807

Epoch: 6| Step: 1
Training loss: 0.12520660522043797
Validation loss: 2.4963254072459535

Epoch: 6| Step: 2
Training loss: 0.11575478699231641
Validation loss: 2.5156377436501653

Epoch: 6| Step: 3
Training loss: 0.16758998037519898
Validation loss: 2.4966650735907057

Epoch: 6| Step: 4
Training loss: 0.16974146352836444
Validation loss: 2.499107606621876

Epoch: 6| Step: 5
Training loss: 0.21222485547754527
Validation loss: 2.465940341617148

Epoch: 6| Step: 6
Training loss: 0.10001792523540394
Validation loss: 2.480386155051481

Epoch: 6| Step: 7
Training loss: 0.1589216000580165
Validation loss: 2.458044529116773

Epoch: 6| Step: 8
Training loss: 0.126118306695972
Validation loss: 2.439218416542597

Epoch: 6| Step: 9
Training loss: 0.16545746039833778
Validation loss: 2.4262886321909996

Epoch: 6| Step: 10
Training loss: 0.19309953126588703
Validation loss: 2.408017950920526

Epoch: 6| Step: 11
Training loss: 0.1458789457504213
Validation loss: 2.418766588868176

Epoch: 6| Step: 12
Training loss: 0.16695131950669553
Validation loss: 2.41580819705077

Epoch: 6| Step: 13
Training loss: 0.24019357288256094
Validation loss: 2.3811375813303775

Epoch: 490| Step: 0
Training loss: 0.16326996704980898
Validation loss: 2.4577435162546095

Epoch: 6| Step: 1
Training loss: 0.1294764781070748
Validation loss: 2.4855539077833835

Epoch: 6| Step: 2
Training loss: 0.18013635839868591
Validation loss: 2.476702563141442

Epoch: 6| Step: 3
Training loss: 0.15042466855845518
Validation loss: 2.509579849182586

Epoch: 6| Step: 4
Training loss: 0.1103716131578495
Validation loss: 2.483168915670189

Epoch: 6| Step: 5
Training loss: 0.11876004044850968
Validation loss: 2.4849194728285626

Epoch: 6| Step: 6
Training loss: 0.15784231296165346
Validation loss: 2.458762295358031

Epoch: 6| Step: 7
Training loss: 0.176900331988166
Validation loss: 2.474156739720695

Epoch: 6| Step: 8
Training loss: 0.15561988854727354
Validation loss: 2.465809119382

Epoch: 6| Step: 9
Training loss: 0.20633319816722304
Validation loss: 2.435549698053939

Epoch: 6| Step: 10
Training loss: 0.16885084476847023
Validation loss: 2.4393149256415927

Epoch: 6| Step: 11
Training loss: 0.18392327340871029
Validation loss: 2.4435644883314023

Epoch: 6| Step: 12
Training loss: 0.18657242296497267
Validation loss: 2.4124717803839935

Epoch: 6| Step: 13
Training loss: 0.15448422465679285
Validation loss: 2.451290161588947

Epoch: 491| Step: 0
Training loss: 0.16703839805980789
Validation loss: 2.429051951594913

Epoch: 6| Step: 1
Training loss: 0.1899524577634991
Validation loss: 2.4388990833245288

Epoch: 6| Step: 2
Training loss: 0.161284438954125
Validation loss: 2.4947880591132376

Epoch: 6| Step: 3
Training loss: 0.15417786124756785
Validation loss: 2.497703120079294

Epoch: 6| Step: 4
Training loss: 0.12697721399501447
Validation loss: 2.5051919614550133

Epoch: 6| Step: 5
Training loss: 0.12316817405315544
Validation loss: 2.4994604512930163

Epoch: 6| Step: 6
Training loss: 0.18395491848156137
Validation loss: 2.4666224749541232

Epoch: 6| Step: 7
Training loss: 0.176630042458022
Validation loss: 2.5044821562795425

Epoch: 6| Step: 8
Training loss: 0.12844832319057597
Validation loss: 2.4558763157307277

Epoch: 6| Step: 9
Training loss: 0.12139175263429931
Validation loss: 2.439790879453361

Epoch: 6| Step: 10
Training loss: 0.15314058837563246
Validation loss: 2.429083872725011

Epoch: 6| Step: 11
Training loss: 0.14484578137377585
Validation loss: 2.414894611308992

Epoch: 6| Step: 12
Training loss: 0.13486530929465898
Validation loss: 2.4339286465657843

Epoch: 6| Step: 13
Training loss: 0.16680981342421927
Validation loss: 2.4270437889534078

Epoch: 492| Step: 0
Training loss: 0.11430705875807477
Validation loss: 2.434088080451097

Epoch: 6| Step: 1
Training loss: 0.11078281868226175
Validation loss: 2.4592949613444266

Epoch: 6| Step: 2
Training loss: 0.08238829385131612
Validation loss: 2.472052074432118

Epoch: 6| Step: 3
Training loss: 0.11112187336748679
Validation loss: 2.480551621759087

Epoch: 6| Step: 4
Training loss: 0.235970257701864
Validation loss: 2.5108917093910863

Epoch: 6| Step: 5
Training loss: 0.0912043440434892
Validation loss: 2.5030469047036705

Epoch: 6| Step: 6
Training loss: 0.0990183067121156
Validation loss: 2.470958836335225

Epoch: 6| Step: 7
Training loss: 0.10618000915840135
Validation loss: 2.4881892540875734

Epoch: 6| Step: 8
Training loss: 0.15863759228781302
Validation loss: 2.488702011960555

Epoch: 6| Step: 9
Training loss: 0.14041503490250737
Validation loss: 2.4769077124477086

Epoch: 6| Step: 10
Training loss: 0.11975389296220555
Validation loss: 2.4659610013769386

Epoch: 6| Step: 11
Training loss: 0.13666547009576163
Validation loss: 2.4537839613866708

Epoch: 6| Step: 12
Training loss: 0.19923899117657334
Validation loss: 2.4431999485496787

Epoch: 6| Step: 13
Training loss: 0.20500706849472547
Validation loss: 2.438306088307309

Epoch: 493| Step: 0
Training loss: 0.10535826459110265
Validation loss: 2.4189841481416567

Epoch: 6| Step: 1
Training loss: 0.18848784813174893
Validation loss: 2.4258912762857383

Epoch: 6| Step: 2
Training loss: 0.17358389316561806
Validation loss: 2.437322586456247

Epoch: 6| Step: 3
Training loss: 0.10023237327485751
Validation loss: 2.469163381064988

Epoch: 6| Step: 4
Training loss: 0.14051908902225488
Validation loss: 2.452645632702663

Epoch: 6| Step: 5
Training loss: 0.10933082403700678
Validation loss: 2.4717914802045686

Epoch: 6| Step: 6
Training loss: 0.13168986670146607
Validation loss: 2.4602839932861373

Epoch: 6| Step: 7
Training loss: 0.12947525529357512
Validation loss: 2.4591521438894985

Epoch: 6| Step: 8
Training loss: 0.0905005352566892
Validation loss: 2.4639093958445795

Epoch: 6| Step: 9
Training loss: 0.17614999347645338
Validation loss: 2.4289505485251732

Epoch: 6| Step: 10
Training loss: 0.12057947349708786
Validation loss: 2.446458788133645

Epoch: 6| Step: 11
Training loss: 0.09573739275215937
Validation loss: 2.4441696295989424

Epoch: 6| Step: 12
Training loss: 0.18847003984776844
Validation loss: 2.459141834166583

Epoch: 6| Step: 13
Training loss: 0.10038492802586146
Validation loss: 2.426791954761846

Epoch: 494| Step: 0
Training loss: 0.16738841248873818
Validation loss: 2.4585411633266308

Epoch: 6| Step: 1
Training loss: 0.11709812650424822
Validation loss: 2.449987628738949

Epoch: 6| Step: 2
Training loss: 0.12488555139157895
Validation loss: 2.4384455964649407

Epoch: 6| Step: 3
Training loss: 0.11948652162989376
Validation loss: 2.465069309632951

Epoch: 6| Step: 4
Training loss: 0.09825381557139048
Validation loss: 2.46358446680102

Epoch: 6| Step: 5
Training loss: 0.09940566475254335
Validation loss: 2.4421632741391366

Epoch: 6| Step: 6
Training loss: 0.09379268707554654
Validation loss: 2.462964417971018

Epoch: 6| Step: 7
Training loss: 0.17728799792243144
Validation loss: 2.4698814975681933

Epoch: 6| Step: 8
Training loss: 0.15646200102948776
Validation loss: 2.512265833815016

Epoch: 6| Step: 9
Training loss: 0.08375123566189223
Validation loss: 2.4935544621800942

Epoch: 6| Step: 10
Training loss: 0.12772869744938223
Validation loss: 2.485234047092884

Epoch: 6| Step: 11
Training loss: 0.10145671543904507
Validation loss: 2.501582602540899

Epoch: 6| Step: 12
Training loss: 0.12006766376084431
Validation loss: 2.48571938682014

Epoch: 6| Step: 13
Training loss: 0.10699938574758364
Validation loss: 2.485795839955034

Epoch: 495| Step: 0
Training loss: 0.11520877650792499
Validation loss: 2.4438221896273147

Epoch: 6| Step: 1
Training loss: 0.08928407620732513
Validation loss: 2.4429194130495837

Epoch: 6| Step: 2
Training loss: 0.09308926380696028
Validation loss: 2.3925044817428245

Epoch: 6| Step: 3
Training loss: 0.18735914105084278
Validation loss: 2.412380050770832

Epoch: 6| Step: 4
Training loss: 0.18105090198036694
Validation loss: 2.4148284772660666

Epoch: 6| Step: 5
Training loss: 0.13409029330187883
Validation loss: 2.4271395611331124

Epoch: 6| Step: 6
Training loss: 0.17417503415736102
Validation loss: 2.43406437541708

Epoch: 6| Step: 7
Training loss: 0.17544282548457055
Validation loss: 2.4600873320803296

Epoch: 6| Step: 8
Training loss: 0.1070659549860477
Validation loss: 2.436104771932636

Epoch: 6| Step: 9
Training loss: 0.13900071764750435
Validation loss: 2.4587951533660273

Epoch: 6| Step: 10
Training loss: 0.11603537288684716
Validation loss: 2.4448571639409042

Epoch: 6| Step: 11
Training loss: 0.09713723065503756
Validation loss: 2.4636615626092135

Epoch: 6| Step: 12
Training loss: 0.13916862863549148
Validation loss: 2.464064201447874

Epoch: 6| Step: 13
Training loss: 0.06603368562890305
Validation loss: 2.4610939237900826

Epoch: 496| Step: 0
Training loss: 0.09690357544359515
Validation loss: 2.477660062510176

Epoch: 6| Step: 1
Training loss: 0.06467510779633182
Validation loss: 2.502574106127041

Epoch: 6| Step: 2
Training loss: 0.10950112308754727
Validation loss: 2.502978655673902

Epoch: 6| Step: 3
Training loss: 0.2424738175965968
Validation loss: 2.530846260106372

Epoch: 6| Step: 4
Training loss: 0.15251911902375018
Validation loss: 2.4871591858582054

Epoch: 6| Step: 5
Training loss: 0.12872560443580686
Validation loss: 2.4880618636511214

Epoch: 6| Step: 6
Training loss: 0.08141779286010935
Validation loss: 2.452515925905255

Epoch: 6| Step: 7
Training loss: 0.11041639330968069
Validation loss: 2.4292398317383985

Epoch: 6| Step: 8
Training loss: 0.1349612212557646
Validation loss: 2.396979407130892

Epoch: 6| Step: 9
Training loss: 0.0943177140446007
Validation loss: 2.4331808388272247

Epoch: 6| Step: 10
Training loss: 0.11334581015286674
Validation loss: 2.430609932177439

Epoch: 6| Step: 11
Training loss: 0.13369843970913353
Validation loss: 2.457894009562344

Epoch: 6| Step: 12
Training loss: 0.13608961446152537
Validation loss: 2.46670981058749

Epoch: 6| Step: 13
Training loss: 0.17430443816145577
Validation loss: 2.442129688472134

Epoch: 497| Step: 0
Training loss: 0.06762173009320378
Validation loss: 2.451844335636773

Epoch: 6| Step: 1
Training loss: 0.10469937506266506
Validation loss: 2.4829198055951216

Epoch: 6| Step: 2
Training loss: 0.12833845918913164
Validation loss: 2.471117976704441

Epoch: 6| Step: 3
Training loss: 0.13983448013824126
Validation loss: 2.476716235253053

Epoch: 6| Step: 4
Training loss: 0.11451104215486803
Validation loss: 2.48592228792159

Epoch: 6| Step: 5
Training loss: 0.125327671742663
Validation loss: 2.4401489306938284

Epoch: 6| Step: 6
Training loss: 0.1707889751282115
Validation loss: 2.4475355184531646

Epoch: 6| Step: 7
Training loss: 0.07956852656679078
Validation loss: 2.4306763076280973

Epoch: 6| Step: 8
Training loss: 0.17716164587002445
Validation loss: 2.4358668108109303

Epoch: 6| Step: 9
Training loss: 0.18298472174330752
Validation loss: 2.4293080470713795

Epoch: 6| Step: 10
Training loss: 0.12652913230618076
Validation loss: 2.4395890621960366

Epoch: 6| Step: 11
Training loss: 0.09819793197327145
Validation loss: 2.4431862646384737

Epoch: 6| Step: 12
Training loss: 0.13134023936152267
Validation loss: 2.443357287035742

Epoch: 6| Step: 13
Training loss: 0.123136657929022
Validation loss: 2.3942967602676406

Epoch: 498| Step: 0
Training loss: 0.11335311451719082
Validation loss: 2.415380849413934

Epoch: 6| Step: 1
Training loss: 0.09975296311321574
Validation loss: 2.406087622978942

Epoch: 6| Step: 2
Training loss: 0.1572208285026572
Validation loss: 2.4161765711410643

Epoch: 6| Step: 3
Training loss: 0.13012775470994903
Validation loss: 2.381708813118159

Epoch: 6| Step: 4
Training loss: 0.11730458847407564
Validation loss: 2.3904612012770565

Epoch: 6| Step: 5
Training loss: 0.08832880307063323
Validation loss: 2.4058354881968014

Epoch: 6| Step: 6
Training loss: 0.16307423029926582
Validation loss: 2.4389035128525487

Epoch: 6| Step: 7
Training loss: 0.16150536672485633
Validation loss: 2.4127955260853824

Epoch: 6| Step: 8
Training loss: 0.13061995453193578
Validation loss: 2.4359936262537314

Epoch: 6| Step: 9
Training loss: 0.1719106994747223
Validation loss: 2.437233592941652

Epoch: 6| Step: 10
Training loss: 0.07972101507180297
Validation loss: 2.4382642920790527

Epoch: 6| Step: 11
Training loss: 0.09604719650918479
Validation loss: 2.4513523021184302

Epoch: 6| Step: 12
Training loss: 0.15647829186799322
Validation loss: 2.464789891864069

Epoch: 6| Step: 13
Training loss: 0.09763452765151848
Validation loss: 2.4985320980838694

Epoch: 499| Step: 0
Training loss: 0.15395731925845468
Validation loss: 2.5329663812653123

Epoch: 6| Step: 1
Training loss: 0.14686799996516212
Validation loss: 2.4982983345560132

Epoch: 6| Step: 2
Training loss: 0.10885155969749934
Validation loss: 2.487297555113396

Epoch: 6| Step: 3
Training loss: 0.11838280710232786
Validation loss: 2.4450779094371002

Epoch: 6| Step: 4
Training loss: 0.11186020006018604
Validation loss: 2.417915281225144

Epoch: 6| Step: 5
Training loss: 0.07011321091067917
Validation loss: 2.425702100527312

Epoch: 6| Step: 6
Training loss: 0.10600599572705778
Validation loss: 2.411722547263845

Epoch: 6| Step: 7
Training loss: 0.15006852645998772
Validation loss: 2.398801278905331

Epoch: 6| Step: 8
Training loss: 0.09539408319001817
Validation loss: 2.4356387551998946

Epoch: 6| Step: 9
Training loss: 0.08769888095349736
Validation loss: 2.491182522544098

Epoch: 6| Step: 10
Training loss: 0.09897345084447175
Validation loss: 2.4429810203839284

Epoch: 6| Step: 11
Training loss: 0.233424404726825
Validation loss: 2.4848115134705533

Epoch: 6| Step: 12
Training loss: 0.1845410641701806
Validation loss: 2.44640826947048

Epoch: 6| Step: 13
Training loss: 0.12941458924494614
Validation loss: 2.4456616868897245

Epoch: 500| Step: 0
Training loss: 0.0939992234478234
Validation loss: 2.446394796847371

Epoch: 6| Step: 1
Training loss: 0.10793822342084053
Validation loss: 2.40582721492117

Epoch: 6| Step: 2
Training loss: 0.11339066828027378
Validation loss: 2.4053163185923805

Epoch: 6| Step: 3
Training loss: 0.15511057968109904
Validation loss: 2.4229235890137706

Epoch: 6| Step: 4
Training loss: 0.09505464330474511
Validation loss: 2.4268728333328746

Epoch: 6| Step: 5
Training loss: 0.13615359937115956
Validation loss: 2.447125770049173

Epoch: 6| Step: 6
Training loss: 0.09978730074537555
Validation loss: 2.4536389931339837

Epoch: 6| Step: 7
Training loss: 0.09374882280087476
Validation loss: 2.4529754298370086

Epoch: 6| Step: 8
Training loss: 0.11116701732726866
Validation loss: 2.46770010207705

Epoch: 6| Step: 9
Training loss: 0.1143949044866141
Validation loss: 2.4426367898104546

Epoch: 6| Step: 10
Training loss: 0.07479767505057698
Validation loss: 2.4659824562594084

Epoch: 6| Step: 11
Training loss: 0.19105955761536517
Validation loss: 2.4490712766424614

Epoch: 6| Step: 12
Training loss: 0.14082368748783072
Validation loss: 2.4607443633943076

Epoch: 6| Step: 13
Training loss: 0.08217648297250667
Validation loss: 2.403618524178253

Epoch: 501| Step: 0
Training loss: 0.0989833306646617
Validation loss: 2.4426423360888103

Epoch: 6| Step: 1
Training loss: 0.13045029252660287
Validation loss: 2.399837007422797

Epoch: 6| Step: 2
Training loss: 0.12382401179753631
Validation loss: 2.4091504646377597

Epoch: 6| Step: 3
Training loss: 0.17221364342073944
Validation loss: 2.444735744216031

Epoch: 6| Step: 4
Training loss: 0.09083286321734174
Validation loss: 2.465950039172447

Epoch: 6| Step: 5
Training loss: 0.18967198973062302
Validation loss: 2.430656204385946

Epoch: 6| Step: 6
Training loss: 0.07161427483347711
Validation loss: 2.476262923917855

Epoch: 6| Step: 7
Training loss: 0.10779197400728423
Validation loss: 2.4762657771647585

Epoch: 6| Step: 8
Training loss: 0.05946135718964753
Validation loss: 2.482479141625733

Epoch: 6| Step: 9
Training loss: 0.10620575379758747
Validation loss: 2.474079373069757

Epoch: 6| Step: 10
Training loss: 0.10880707278375788
Validation loss: 2.486374449091552

Epoch: 6| Step: 11
Training loss: 0.14393770930216618
Validation loss: 2.455698806362232

Epoch: 6| Step: 12
Training loss: 0.11821034998725995
Validation loss: 2.4308140352300045

Epoch: 6| Step: 13
Training loss: 0.1083509323912649
Validation loss: 2.4336179915992715

Epoch: 502| Step: 0
Training loss: 0.15626046026502322
Validation loss: 2.4306659440981995

Epoch: 6| Step: 1
Training loss: 0.06226843538606853
Validation loss: 2.407799351807564

Epoch: 6| Step: 2
Training loss: 0.15762313443939616
Validation loss: 2.4116722544842855

Epoch: 6| Step: 3
Training loss: 0.06438873426905478
Validation loss: 2.4748133496069697

Epoch: 6| Step: 4
Training loss: 0.10260019750550521
Validation loss: 2.3979218138920366

Epoch: 6| Step: 5
Training loss: 0.13518671232709187
Validation loss: 2.4208661325747625

Epoch: 6| Step: 6
Training loss: 0.04682216796225133
Validation loss: 2.4433835480402157

Epoch: 6| Step: 7
Training loss: 0.1086363158403543
Validation loss: 2.424988616467977

Epoch: 6| Step: 8
Training loss: 0.13598478032160966
Validation loss: 2.4018606470337467

Epoch: 6| Step: 9
Training loss: 0.10557667190931573
Validation loss: 2.426331887830596

Epoch: 6| Step: 10
Training loss: 0.07578152504114007
Validation loss: 2.411406690006049

Epoch: 6| Step: 11
Training loss: 0.07654496668500173
Validation loss: 2.3868469125459426

Epoch: 6| Step: 12
Training loss: 0.1337713243740551
Validation loss: 2.414595974594078

Epoch: 6| Step: 13
Training loss: 0.08637738084875876
Validation loss: 2.401182051038441

Epoch: 503| Step: 0
Training loss: 0.12070147365070066
Validation loss: 2.3989304283218655

Epoch: 6| Step: 1
Training loss: 0.11511719936996
Validation loss: 2.3914870396173704

Epoch: 6| Step: 2
Training loss: 0.06631124235546172
Validation loss: 2.4181435726068714

Epoch: 6| Step: 3
Training loss: 0.07269695792572864
Validation loss: 2.4677759234611734

Epoch: 6| Step: 4
Training loss: 0.14406747124673586
Validation loss: 2.444660569411434

Epoch: 6| Step: 5
Training loss: 0.11602568085114592
Validation loss: 2.4665992956542206

Epoch: 6| Step: 6
Training loss: 0.16742543575863283
Validation loss: 2.4607887151470615

Epoch: 6| Step: 7
Training loss: 0.11464733175235127
Validation loss: 2.4448639975600286

Epoch: 6| Step: 8
Training loss: 0.09396575400007337
Validation loss: 2.421234474864839

Epoch: 6| Step: 9
Training loss: 0.09745342649976199
Validation loss: 2.4316990084573824

Epoch: 6| Step: 10
Training loss: 0.12097177207165682
Validation loss: 2.442123786735983

Epoch: 6| Step: 11
Training loss: 0.09523946003720059
Validation loss: 2.4424607496711888

Epoch: 6| Step: 12
Training loss: 0.14543621810894047
Validation loss: 2.44760991576501

Epoch: 6| Step: 13
Training loss: 0.05213653807302596
Validation loss: 2.4473260575908484

Epoch: 504| Step: 0
Training loss: 0.16626089154505014
Validation loss: 2.454705732233785

Epoch: 6| Step: 1
Training loss: 0.13512920318492377
Validation loss: 2.446655950685697

Epoch: 6| Step: 2
Training loss: 0.08616290550724516
Validation loss: 2.4517318461822195

Epoch: 6| Step: 3
Training loss: 0.13382191498305976
Validation loss: 2.45444746590266

Epoch: 6| Step: 4
Training loss: 0.08702636546239984
Validation loss: 2.444169266686436

Epoch: 6| Step: 5
Training loss: 0.103344713225027
Validation loss: 2.4158583920563497

Epoch: 6| Step: 6
Training loss: 0.12422581928458598
Validation loss: 2.44232423307845

Epoch: 6| Step: 7
Training loss: 0.11780627917250364
Validation loss: 2.444333490628232

Epoch: 6| Step: 8
Training loss: 0.051654483108683855
Validation loss: 2.455371185484183

Epoch: 6| Step: 9
Training loss: 0.14197905635852778
Validation loss: 2.4557859683261674

Epoch: 6| Step: 10
Training loss: 0.10907691970911186
Validation loss: 2.48705307092025

Epoch: 6| Step: 11
Training loss: 0.12163763804556771
Validation loss: 2.4633428254060417

Epoch: 6| Step: 12
Training loss: 0.1452527530958313
Validation loss: 2.474431029120879

Epoch: 6| Step: 13
Training loss: 0.1295229796080477
Validation loss: 2.4259853968368503

Epoch: 505| Step: 0
Training loss: 0.11055383879358908
Validation loss: 2.441923804243764

Epoch: 6| Step: 1
Training loss: 0.10371061619566951
Validation loss: 2.431149817703309

Epoch: 6| Step: 2
Training loss: 0.09181499302402714
Validation loss: 2.388072474796647

Epoch: 6| Step: 3
Training loss: 0.08238380884171267
Validation loss: 2.4134307702723166

Epoch: 6| Step: 4
Training loss: 0.15101363823615419
Validation loss: 2.397846811490732

Epoch: 6| Step: 5
Training loss: 0.05746090431912603
Validation loss: 2.410495601405351

Epoch: 6| Step: 6
Training loss: 0.10196685534133651
Validation loss: 2.4080301877107804

Epoch: 6| Step: 7
Training loss: 0.10226664914929007
Validation loss: 2.4198302519356174

Epoch: 6| Step: 8
Training loss: 0.08787320282239228
Validation loss: 2.432023277968132

Epoch: 6| Step: 9
Training loss: 0.08856445666670805
Validation loss: 2.436322828527323

Epoch: 6| Step: 10
Training loss: 0.16299231920217333
Validation loss: 2.4591458164904827

Epoch: 6| Step: 11
Training loss: 0.1384954202937132
Validation loss: 2.4510599937475654

Epoch: 6| Step: 12
Training loss: 0.09663459901671777
Validation loss: 2.416340173286724

Epoch: 6| Step: 13
Training loss: 0.21046969851794817
Validation loss: 2.450632492143399

Epoch: 506| Step: 0
Training loss: 0.08496752801085178
Validation loss: 2.442605375880394

Epoch: 6| Step: 1
Training loss: 0.06536245450255167
Validation loss: 2.400343483653927

Epoch: 6| Step: 2
Training loss: 0.049596951648748354
Validation loss: 2.461727184785334

Epoch: 6| Step: 3
Training loss: 0.0795259277571448
Validation loss: 2.449255328323868

Epoch: 6| Step: 4
Training loss: 0.12218550015786157
Validation loss: 2.444998654862736

Epoch: 6| Step: 5
Training loss: 0.08999325917418287
Validation loss: 2.4561359463266017

Epoch: 6| Step: 6
Training loss: 0.1436741066220554
Validation loss: 2.474863716778455

Epoch: 6| Step: 7
Training loss: 0.16290953798523186
Validation loss: 2.4759323909052044

Epoch: 6| Step: 8
Training loss: 0.0906028605416901
Validation loss: 2.453318502364377

Epoch: 6| Step: 9
Training loss: 0.12670228826510216
Validation loss: 2.473678619858529

Epoch: 6| Step: 10
Training loss: 0.14881975746161424
Validation loss: 2.4416974965938203

Epoch: 6| Step: 11
Training loss: 0.1012283108875199
Validation loss: 2.431155392823526

Epoch: 6| Step: 12
Training loss: 0.06619458967282664
Validation loss: 2.4274474797724763

Epoch: 6| Step: 13
Training loss: 0.09893691517120265
Validation loss: 2.416440027731965

Epoch: 507| Step: 0
Training loss: 0.04930335287570488
Validation loss: 2.429501834018317

Epoch: 6| Step: 1
Training loss: 0.08142329474129903
Validation loss: 2.3947281209427618

Epoch: 6| Step: 2
Training loss: 0.06946924986811749
Validation loss: 2.4100835845093247

Epoch: 6| Step: 3
Training loss: 0.09164797597314808
Validation loss: 2.4293461171272512

Epoch: 6| Step: 4
Training loss: 0.16466726374212245
Validation loss: 2.4142072675156787

Epoch: 6| Step: 5
Training loss: 0.076592831904373
Validation loss: 2.4076580130631444

Epoch: 6| Step: 6
Training loss: 0.054493607225689356
Validation loss: 2.430516112008015

Epoch: 6| Step: 7
Training loss: 0.10802789884185666
Validation loss: 2.4345918728999263

Epoch: 6| Step: 8
Training loss: 0.14866257844445097
Validation loss: 2.4301379573324056

Epoch: 6| Step: 9
Training loss: 0.07540391498496338
Validation loss: 2.426166926694846

Epoch: 6| Step: 10
Training loss: 0.06394188228557918
Validation loss: 2.438996742354699

Epoch: 6| Step: 11
Training loss: 0.1347860514322671
Validation loss: 2.4208736099971313

Epoch: 6| Step: 12
Training loss: 0.10334394271268546
Validation loss: 2.444007804609114

Epoch: 6| Step: 13
Training loss: 0.06363539264897264
Validation loss: 2.44482073477679

Epoch: 508| Step: 0
Training loss: 0.1341532185529897
Validation loss: 2.4166449901922666

Epoch: 6| Step: 1
Training loss: 0.061030713873367434
Validation loss: 2.436632211723069

Epoch: 6| Step: 2
Training loss: 0.08881541200584561
Validation loss: 2.4094772314411963

Epoch: 6| Step: 3
Training loss: 0.09368791610677536
Validation loss: 2.411643090527213

Epoch: 6| Step: 4
Training loss: 0.14242935911174942
Validation loss: 2.403714531121309

Epoch: 6| Step: 5
Training loss: 0.08317261772354453
Validation loss: 2.398340216098611

Epoch: 6| Step: 6
Training loss: 0.08290088161359507
Validation loss: 2.415015048940194

Epoch: 6| Step: 7
Training loss: 0.1932507797622741
Validation loss: 2.4163845098742023

Epoch: 6| Step: 8
Training loss: 0.08773240046432004
Validation loss: 2.441567068796064

Epoch: 6| Step: 9
Training loss: 0.09284303965468532
Validation loss: 2.4327862125180726

Epoch: 6| Step: 10
Training loss: 0.10229066097881327
Validation loss: 2.4118603989748997

Epoch: 6| Step: 11
Training loss: 0.06665617529949397
Validation loss: 2.448115515416149

Epoch: 6| Step: 12
Training loss: 0.10324895446169463
Validation loss: 2.4220729274631396

Epoch: 6| Step: 13
Training loss: 0.07213023429059123
Validation loss: 2.4445728025998537

Epoch: 509| Step: 0
Training loss: 0.07093204300850829
Validation loss: 2.4644865660598128

Epoch: 6| Step: 1
Training loss: 0.05555086588975496
Validation loss: 2.505040069967634

Epoch: 6| Step: 2
Training loss: 0.09693190879671691
Validation loss: 2.4805924688092063

Epoch: 6| Step: 3
Training loss: 0.09592506404198027
Validation loss: 2.4598691028442063

Epoch: 6| Step: 4
Training loss: 0.20202571257977878
Validation loss: 2.4864630061032567

Epoch: 6| Step: 5
Training loss: 0.12700684217922512
Validation loss: 2.464145750669959

Epoch: 6| Step: 6
Training loss: 0.08132061938336858
Validation loss: 2.460561196106263

Epoch: 6| Step: 7
Training loss: 0.12601804419960616
Validation loss: 2.425106875939235

Epoch: 6| Step: 8
Training loss: 0.05126439704619011
Validation loss: 2.3978154789873516

Epoch: 6| Step: 9
Training loss: 0.1404424051460357
Validation loss: 2.3947916756303766

Epoch: 6| Step: 10
Training loss: 0.10479897179588307
Validation loss: 2.403387424553841

Epoch: 6| Step: 11
Training loss: 0.09049244632929287
Validation loss: 2.4025597006473944

Epoch: 6| Step: 12
Training loss: 0.135573907184927
Validation loss: 2.4104514803519725

Epoch: 6| Step: 13
Training loss: 0.1124587909073594
Validation loss: 2.4652670937521886

Epoch: 510| Step: 0
Training loss: 0.10037994587721319
Validation loss: 2.446104172423018

Epoch: 6| Step: 1
Training loss: 0.0962722506364458
Validation loss: 2.5152592995400957

Epoch: 6| Step: 2
Training loss: 0.15506257428433085
Validation loss: 2.463762722743689

Epoch: 6| Step: 3
Training loss: 0.20672516418563075
Validation loss: 2.5222164699677436

Epoch: 6| Step: 4
Training loss: 0.11553348902193175
Validation loss: 2.492928923554972

Epoch: 6| Step: 5
Training loss: 0.09470601203041185
Validation loss: 2.464818538273366

Epoch: 6| Step: 6
Training loss: 0.07885980159605589
Validation loss: 2.4633295052441593

Epoch: 6| Step: 7
Training loss: 0.1274951514556349
Validation loss: 2.4388482567002665

Epoch: 6| Step: 8
Training loss: 0.08493213329718376
Validation loss: 2.3935377443422103

Epoch: 6| Step: 9
Training loss: 0.11508733452268893
Validation loss: 2.3830310362914098

Epoch: 6| Step: 10
Training loss: 0.1292872505985367
Validation loss: 2.335544700904126

Epoch: 6| Step: 11
Training loss: 0.07837542689890097
Validation loss: 2.3909433587066404

Epoch: 6| Step: 12
Training loss: 0.10473981820362654
Validation loss: 2.4147177802228366

Epoch: 6| Step: 13
Training loss: 0.09181154417964776
Validation loss: 2.4063519127450625

Epoch: 511| Step: 0
Training loss: 0.10128479826866607
Validation loss: 2.4375144646748907

Epoch: 6| Step: 1
Training loss: 0.12213949531856498
Validation loss: 2.466050426589701

Epoch: 6| Step: 2
Training loss: 0.0721939930431478
Validation loss: 2.4539529388082806

Epoch: 6| Step: 3
Training loss: 0.16167177172184055
Validation loss: 2.497061193181488

Epoch: 6| Step: 4
Training loss: 0.1629961189044923
Validation loss: 2.4762847849230756

Epoch: 6| Step: 5
Training loss: 0.18238701824307355
Validation loss: 2.455400621476438

Epoch: 6| Step: 6
Training loss: 0.1511724265036762
Validation loss: 2.4072415892768846

Epoch: 6| Step: 7
Training loss: 0.09979998359121023
Validation loss: 2.375241253855853

Epoch: 6| Step: 8
Training loss: 0.15031280609742084
Validation loss: 2.367072208563952

Epoch: 6| Step: 9
Training loss: 0.17483146824624518
Validation loss: 2.3893203215400414

Epoch: 6| Step: 10
Training loss: 0.1269435438795559
Validation loss: 2.3600758831233555

Epoch: 6| Step: 11
Training loss: 0.07398364197630725
Validation loss: 2.365473526337425

Epoch: 6| Step: 12
Training loss: 0.0788678259821342
Validation loss: 2.397731969975041

Epoch: 6| Step: 13
Training loss: 0.09278515189649451
Validation loss: 2.410547103484471

Epoch: 512| Step: 0
Training loss: 0.1306600618534009
Validation loss: 2.427258548875464

Epoch: 6| Step: 1
Training loss: 0.14581955407530692
Validation loss: 2.444784686766152

Epoch: 6| Step: 2
Training loss: 0.16541715910039131
Validation loss: 2.409329418514489

Epoch: 6| Step: 3
Training loss: 0.0914023728648787
Validation loss: 2.4167207182149686

Epoch: 6| Step: 4
Training loss: 0.08463039719540204
Validation loss: 2.3951784730752537

Epoch: 6| Step: 5
Training loss: 0.15540482102839234
Validation loss: 2.40808348100716

Epoch: 6| Step: 6
Training loss: 0.0717405237750415
Validation loss: 2.412433750620785

Epoch: 6| Step: 7
Training loss: 0.11580122521840196
Validation loss: 2.3728513416219963

Epoch: 6| Step: 8
Training loss: 0.15652163259609428
Validation loss: 2.384890113517365

Epoch: 6| Step: 9
Training loss: 0.13118552372658326
Validation loss: 2.3680836368119094

Epoch: 6| Step: 10
Training loss: 0.14508860320674796
Validation loss: 2.43395424461724

Epoch: 6| Step: 11
Training loss: 0.061233855112788525
Validation loss: 2.411562330250667

Epoch: 6| Step: 12
Training loss: 0.12096826527354775
Validation loss: 2.4479491731522756

Epoch: 6| Step: 13
Training loss: 0.14863585720878753
Validation loss: 2.4329456180040316

Epoch: 513| Step: 0
Training loss: 0.16563939490831775
Validation loss: 2.43309758901861

Epoch: 6| Step: 1
Training loss: 0.11371363138344905
Validation loss: 2.4352726347626255

Epoch: 6| Step: 2
Training loss: 0.11287419585694534
Validation loss: 2.454296249689329

Epoch: 6| Step: 3
Training loss: 0.10317212819668177
Validation loss: 2.4597174851509633

Epoch: 6| Step: 4
Training loss: 0.11375192989032705
Validation loss: 2.4740983292368988

Epoch: 6| Step: 5
Training loss: 0.13197951093110444
Validation loss: 2.498747661668913

Epoch: 6| Step: 6
Training loss: 0.16537565409530264
Validation loss: 2.5061507171846116

Epoch: 6| Step: 7
Training loss: 0.08876488110036358
Validation loss: 2.4823874418926586

Epoch: 6| Step: 8
Training loss: 0.14094421131792179
Validation loss: 2.4547143232720865

Epoch: 6| Step: 9
Training loss: 0.10524226525115303
Validation loss: 2.4423396170304708

Epoch: 6| Step: 10
Training loss: 0.09494848408200787
Validation loss: 2.43517001950209

Epoch: 6| Step: 11
Training loss: 0.19394939644961304
Validation loss: 2.4364820968031013

Epoch: 6| Step: 12
Training loss: 0.11280630288842235
Validation loss: 2.4581072456369455

Epoch: 6| Step: 13
Training loss: 0.09878580106854899
Validation loss: 2.4552527269232316

Epoch: 514| Step: 0
Training loss: 0.1531448331950806
Validation loss: 2.4454954691473296

Epoch: 6| Step: 1
Training loss: 0.1089646099311657
Validation loss: 2.434020786389364

Epoch: 6| Step: 2
Training loss: 0.11297209251967244
Validation loss: 2.418923509835608

Epoch: 6| Step: 3
Training loss: 0.19453033232568204
Validation loss: 2.420762349052878

Epoch: 6| Step: 4
Training loss: 0.09244060039672751
Validation loss: 2.425263906745112

Epoch: 6| Step: 5
Training loss: 0.1541186220519314
Validation loss: 2.4172905769671664

Epoch: 6| Step: 6
Training loss: 0.1033398106859205
Validation loss: 2.412856683893098

Epoch: 6| Step: 7
Training loss: 0.0904086123433764
Validation loss: 2.3679374081793303

Epoch: 6| Step: 8
Training loss: 0.05494356661718126
Validation loss: 2.418096109704187

Epoch: 6| Step: 9
Training loss: 0.045500885145582565
Validation loss: 2.378726851366564

Epoch: 6| Step: 10
Training loss: 0.11557555204546792
Validation loss: 2.370292106254775

Epoch: 6| Step: 11
Training loss: 0.12026449025875026
Validation loss: 2.3876264816426613

Epoch: 6| Step: 12
Training loss: 0.07682097326126609
Validation loss: 2.3862697954517653

Epoch: 6| Step: 13
Training loss: 0.0938058776033365
Validation loss: 2.411665055744796

Epoch: 515| Step: 0
Training loss: 0.08259530510378366
Validation loss: 2.423502298807951

Epoch: 6| Step: 1
Training loss: 0.09485832371048279
Validation loss: 2.3908111040851523

Epoch: 6| Step: 2
Training loss: 0.05886855058667657
Validation loss: 2.418285074246986

Epoch: 6| Step: 3
Training loss: 0.10997939861077079
Validation loss: 2.4107673686487265

Epoch: 6| Step: 4
Training loss: 0.1349732347839832
Validation loss: 2.3966643462950787

Epoch: 6| Step: 5
Training loss: 0.06627121687953694
Validation loss: 2.389198672889592

Epoch: 6| Step: 6
Training loss: 0.12613991193736382
Validation loss: 2.3822537470928333

Epoch: 6| Step: 7
Training loss: 0.14183852658526006
Validation loss: 2.3932751625460824

Epoch: 6| Step: 8
Training loss: 0.14622466907232246
Validation loss: 2.3841561501622706

Epoch: 6| Step: 9
Training loss: 0.16249585329780458
Validation loss: 2.378966009539578

Epoch: 6| Step: 10
Training loss: 0.09627997488968462
Validation loss: 2.4613494377223097

Epoch: 6| Step: 11
Training loss: 0.10157375548423264
Validation loss: 2.444773534708267

Epoch: 6| Step: 12
Training loss: 0.08381509632086656
Validation loss: 2.4399728854730633

Epoch: 6| Step: 13
Training loss: 0.16238218929087675
Validation loss: 2.4666522121532517

Epoch: 516| Step: 0
Training loss: 0.11194432533484344
Validation loss: 2.4494737437200547

Epoch: 6| Step: 1
Training loss: 0.09690090840504864
Validation loss: 2.456730227250142

Epoch: 6| Step: 2
Training loss: 0.05102705382415353
Validation loss: 2.422779299995947

Epoch: 6| Step: 3
Training loss: 0.06904177657936669
Validation loss: 2.4366659520725316

Epoch: 6| Step: 4
Training loss: 0.0855175317448552
Validation loss: 2.4579340402085275

Epoch: 6| Step: 5
Training loss: 0.08875442519035587
Validation loss: 2.4433660931965084

Epoch: 6| Step: 6
Training loss: 0.12022063212710003
Validation loss: 2.4064696901115243

Epoch: 6| Step: 7
Training loss: 0.09048416626480786
Validation loss: 2.4435808674462796

Epoch: 6| Step: 8
Training loss: 0.20883610180348897
Validation loss: 2.4514924585621873

Epoch: 6| Step: 9
Training loss: 0.11580147453328338
Validation loss: 2.465385227113927

Epoch: 6| Step: 10
Training loss: 0.1362224973034951
Validation loss: 2.4539669638438206

Epoch: 6| Step: 11
Training loss: 0.07223360860258349
Validation loss: 2.443399640359736

Epoch: 6| Step: 12
Training loss: 0.08221560153710729
Validation loss: 2.4513492823497547

Epoch: 6| Step: 13
Training loss: 0.09204647442645213
Validation loss: 2.454696752133223

Epoch: 517| Step: 0
Training loss: 0.0714916134384897
Validation loss: 2.4227238813754335

Epoch: 6| Step: 1
Training loss: 0.08084712684396456
Validation loss: 2.4503487361588494

Epoch: 6| Step: 2
Training loss: 0.13145003175695189
Validation loss: 2.429319065398679

Epoch: 6| Step: 3
Training loss: 0.08527467339267074
Validation loss: 2.410027681413929

Epoch: 6| Step: 4
Training loss: 0.06267403422744407
Validation loss: 2.422345753784851

Epoch: 6| Step: 5
Training loss: 0.15045084305051948
Validation loss: 2.4118409063401702

Epoch: 6| Step: 6
Training loss: 0.11860338621733175
Validation loss: 2.42800833162241

Epoch: 6| Step: 7
Training loss: 0.125539420428197
Validation loss: 2.433229222018107

Epoch: 6| Step: 8
Training loss: 0.15479105267289567
Validation loss: 2.4397572198850095

Epoch: 6| Step: 9
Training loss: 0.09220050279598907
Validation loss: 2.4288900819847745

Epoch: 6| Step: 10
Training loss: 0.08418652690354801
Validation loss: 2.4457427045487363

Epoch: 6| Step: 11
Training loss: 0.14631670574798472
Validation loss: 2.468513585447083

Epoch: 6| Step: 12
Training loss: 0.08936667241800855
Validation loss: 2.435055711695987

Epoch: 6| Step: 13
Training loss: 0.1926217991051165
Validation loss: 2.4256249586946956

Epoch: 518| Step: 0
Training loss: 0.14340128454937523
Validation loss: 2.4319086757253445

Epoch: 6| Step: 1
Training loss: 0.0995638126064062
Validation loss: 2.4423958858226977

Epoch: 6| Step: 2
Training loss: 0.087070725723662
Validation loss: 2.4198861542299093

Epoch: 6| Step: 3
Training loss: 0.09115040177294917
Validation loss: 2.4533499473559406

Epoch: 6| Step: 4
Training loss: 0.08939785811751474
Validation loss: 2.43057595904137

Epoch: 6| Step: 5
Training loss: 0.06241830687297318
Validation loss: 2.455180215180975

Epoch: 6| Step: 6
Training loss: 0.10252180862586234
Validation loss: 2.456992264485005

Epoch: 6| Step: 7
Training loss: 0.07337048102720452
Validation loss: 2.447042699742139

Epoch: 6| Step: 8
Training loss: 0.08461526453525582
Validation loss: 2.4649349240182468

Epoch: 6| Step: 9
Training loss: 0.19859204169258202
Validation loss: 2.403371507531122

Epoch: 6| Step: 10
Training loss: 0.09644302146047597
Validation loss: 2.3872320268638867

Epoch: 6| Step: 11
Training loss: 0.07812318501748396
Validation loss: 2.3545179664869638

Epoch: 6| Step: 12
Training loss: 0.1248759831699124
Validation loss: 2.3714895356483368

Epoch: 6| Step: 13
Training loss: 0.10259218202427467
Validation loss: 2.362409625690705

Epoch: 519| Step: 0
Training loss: 0.11926675982855568
Validation loss: 2.3781218646728473

Epoch: 6| Step: 1
Training loss: 0.10236390912642758
Validation loss: 2.394314766097727

Epoch: 6| Step: 2
Training loss: 0.0992643139063715
Validation loss: 2.406077751277269

Epoch: 6| Step: 3
Training loss: 0.22933141068123444
Validation loss: 2.4007569617765747

Epoch: 6| Step: 4
Training loss: 0.07180601961470946
Validation loss: 2.417448936835359

Epoch: 6| Step: 5
Training loss: 0.08179404385903716
Validation loss: 2.3987919724962694

Epoch: 6| Step: 6
Training loss: 0.08995731577537729
Validation loss: 2.4083497584182

Epoch: 6| Step: 7
Training loss: 0.08595829950396848
Validation loss: 2.402428876500949

Epoch: 6| Step: 8
Training loss: 0.11852645082133953
Validation loss: 2.4480081415899573

Epoch: 6| Step: 9
Training loss: 0.08440222587900303
Validation loss: 2.4293449906154736

Epoch: 6| Step: 10
Training loss: 0.09380647825690759
Validation loss: 2.454420325779479

Epoch: 6| Step: 11
Training loss: 0.09157402299689933
Validation loss: 2.462340748094645

Epoch: 6| Step: 12
Training loss: 0.08914097332029634
Validation loss: 2.454763590092499

Epoch: 6| Step: 13
Training loss: 0.11889114994560357
Validation loss: 2.4439285190035807

Epoch: 520| Step: 0
Training loss: 0.09802427088300449
Validation loss: 2.44323134696538

Epoch: 6| Step: 1
Training loss: 0.06948306364190646
Validation loss: 2.4563358042030874

Epoch: 6| Step: 2
Training loss: 0.05708023182217649
Validation loss: 2.452392495933327

Epoch: 6| Step: 3
Training loss: 0.09354686087121916
Validation loss: 2.421924998349155

Epoch: 6| Step: 4
Training loss: 0.1572907121473575
Validation loss: 2.42882364399814

Epoch: 6| Step: 5
Training loss: 0.10875677043842226
Validation loss: 2.4395391224328655

Epoch: 6| Step: 6
Training loss: 0.09769606732210713
Validation loss: 2.450525719774629

Epoch: 6| Step: 7
Training loss: 0.09365900908966948
Validation loss: 2.4525167843663485

Epoch: 6| Step: 8
Training loss: 0.07601532988966361
Validation loss: 2.4455895454183603

Epoch: 6| Step: 9
Training loss: 0.14911333374937089
Validation loss: 2.439344732998855

Epoch: 6| Step: 10
Training loss: 0.14167333954167385
Validation loss: 2.4274894912857414

Epoch: 6| Step: 11
Training loss: 0.057879531588320064
Validation loss: 2.445474000160977

Epoch: 6| Step: 12
Training loss: 0.07485899398175666
Validation loss: 2.437097192742543

Epoch: 6| Step: 13
Training loss: 0.10538432928189027
Validation loss: 2.413198633830444

Epoch: 521| Step: 0
Training loss: 0.10971694525253252
Validation loss: 2.4179676070550142

Epoch: 6| Step: 1
Training loss: 0.060373305521188206
Validation loss: 2.412258327960516

Epoch: 6| Step: 2
Training loss: 0.09283052996627986
Validation loss: 2.4248172561332786

Epoch: 6| Step: 3
Training loss: 0.09417149049646553
Validation loss: 2.4335702097559833

Epoch: 6| Step: 4
Training loss: 0.1464557492578519
Validation loss: 2.453663529846934

Epoch: 6| Step: 5
Training loss: 0.09226881114584568
Validation loss: 2.4349476156255583

Epoch: 6| Step: 6
Training loss: 0.07595041984864433
Validation loss: 2.4241158419911666

Epoch: 6| Step: 7
Training loss: 0.09898885352489116
Validation loss: 2.4180026797404084

Epoch: 6| Step: 8
Training loss: 0.11733184507708094
Validation loss: 2.3901470397406612

Epoch: 6| Step: 9
Training loss: 0.07275618159173187
Validation loss: 2.405412875391081

Epoch: 6| Step: 10
Training loss: 0.09774578758161001
Validation loss: 2.4023771086106764

Epoch: 6| Step: 11
Training loss: 0.136479461256117
Validation loss: 2.427153897429277

Epoch: 6| Step: 12
Training loss: 0.13749284942413864
Validation loss: 2.419460889515518

Epoch: 6| Step: 13
Training loss: 0.14412391457186172
Validation loss: 2.4388558955303052

Epoch: 522| Step: 0
Training loss: 0.07608161371254292
Validation loss: 2.4300961287499145

Epoch: 6| Step: 1
Training loss: 0.12796478663584465
Validation loss: 2.4205361425000405

Epoch: 6| Step: 2
Training loss: 0.12222006195620486
Validation loss: 2.423794325461779

Epoch: 6| Step: 3
Training loss: 0.07770716571964018
Validation loss: 2.4141830524148444

Epoch: 6| Step: 4
Training loss: 0.13717713488479508
Validation loss: 2.4222686849846657

Epoch: 6| Step: 5
Training loss: 0.09707590275100825
Validation loss: 2.4261984837277994

Epoch: 6| Step: 6
Training loss: 0.10895699854504852
Validation loss: 2.428874383806141

Epoch: 6| Step: 7
Training loss: 0.08504279621725816
Validation loss: 2.4249664941588818

Epoch: 6| Step: 8
Training loss: 0.15706824393571683
Validation loss: 2.435263694063513

Epoch: 6| Step: 9
Training loss: 0.08775114542024716
Validation loss: 2.4531195260169656

Epoch: 6| Step: 10
Training loss: 0.07140279867984277
Validation loss: 2.442493271739868

Epoch: 6| Step: 11
Training loss: 0.10118633999021182
Validation loss: 2.423286092534717

Epoch: 6| Step: 12
Training loss: 0.10424313768178074
Validation loss: 2.4123381767681664

Epoch: 6| Step: 13
Training loss: 0.08665299586112742
Validation loss: 2.421328092464281

Epoch: 523| Step: 0
Training loss: 0.07819686207192084
Validation loss: 2.415149467770331

Epoch: 6| Step: 1
Training loss: 0.14277596008326654
Validation loss: 2.412998652006584

Epoch: 6| Step: 2
Training loss: 0.1119340419410861
Validation loss: 2.4106543624495904

Epoch: 6| Step: 3
Training loss: 0.1116543557577298
Validation loss: 2.443253721769413

Epoch: 6| Step: 4
Training loss: 0.0797229776693251
Validation loss: 2.4459387048099464

Epoch: 6| Step: 5
Training loss: 0.11745329754324355
Validation loss: 2.4479677263501465

Epoch: 6| Step: 6
Training loss: 0.09764525828491628
Validation loss: 2.444287452693608

Epoch: 6| Step: 7
Training loss: 0.10339311331662637
Validation loss: 2.4664768274470728

Epoch: 6| Step: 8
Training loss: 0.06346929948776445
Validation loss: 2.4831141670467956

Epoch: 6| Step: 9
Training loss: 0.0649061394062854
Validation loss: 2.4552314116482172

Epoch: 6| Step: 10
Training loss: 0.17641099869356794
Validation loss: 2.459277257707284

Epoch: 6| Step: 11
Training loss: 0.05380828445401063
Validation loss: 2.4249517283970223

Epoch: 6| Step: 12
Training loss: 0.08041822794164968
Validation loss: 2.4330164806177894

Epoch: 6| Step: 13
Training loss: 0.06931833258623464
Validation loss: 2.4361057243113464

Epoch: 524| Step: 0
Training loss: 0.09014435422717712
Validation loss: 2.412631849073408

Epoch: 6| Step: 1
Training loss: 0.0738869263850014
Validation loss: 2.4184277132510723

Epoch: 6| Step: 2
Training loss: 0.17635484464255569
Validation loss: 2.4386300180335643

Epoch: 6| Step: 3
Training loss: 0.12249492420049496
Validation loss: 2.41024384052157

Epoch: 6| Step: 4
Training loss: 0.07462328848501537
Validation loss: 2.43786308123335

Epoch: 6| Step: 5
Training loss: 0.05796986070504537
Validation loss: 2.427558100078711

Epoch: 6| Step: 6
Training loss: 0.08847918011833132
Validation loss: 2.4488537668820993

Epoch: 6| Step: 7
Training loss: 0.09388831485433535
Validation loss: 2.4435487763639987

Epoch: 6| Step: 8
Training loss: 0.07391781089982369
Validation loss: 2.447821976910229

Epoch: 6| Step: 9
Training loss: 0.06754315000424468
Validation loss: 2.4362353622047377

Epoch: 6| Step: 10
Training loss: 0.05858401972723046
Validation loss: 2.4453576914722963

Epoch: 6| Step: 11
Training loss: 0.15076003592488824
Validation loss: 2.4522619663315

Epoch: 6| Step: 12
Training loss: 0.08455082413339
Validation loss: 2.449203931572585

Epoch: 6| Step: 13
Training loss: 0.08671656414662239
Validation loss: 2.455136320755593

Epoch: 525| Step: 0
Training loss: 0.06994188837451407
Validation loss: 2.4447180966383426

Epoch: 6| Step: 1
Training loss: 0.08533081025000715
Validation loss: 2.394147368704038

Epoch: 6| Step: 2
Training loss: 0.09011245020604276
Validation loss: 2.407548876409486

Epoch: 6| Step: 3
Training loss: 0.07205586340258134
Validation loss: 2.4118026226807774

Epoch: 6| Step: 4
Training loss: 0.1068386108928709
Validation loss: 2.4144642595770875

Epoch: 6| Step: 5
Training loss: 0.07251945906043987
Validation loss: 2.4176210169338157

Epoch: 6| Step: 6
Training loss: 0.07285338839270326
Validation loss: 2.4163134067052994

Epoch: 6| Step: 7
Training loss: 0.1382596510921012
Validation loss: 2.4482860301357685

Epoch: 6| Step: 8
Training loss: 0.12189291079666077
Validation loss: 2.4666033979343083

Epoch: 6| Step: 9
Training loss: 0.1712053649051158
Validation loss: 2.4674318241264865

Epoch: 6| Step: 10
Training loss: 0.11425883137827382
Validation loss: 2.472459923287833

Epoch: 6| Step: 11
Training loss: 0.06841801444358944
Validation loss: 2.490734103314866

Epoch: 6| Step: 12
Training loss: 0.09747805550182388
Validation loss: 2.461493258235236

Epoch: 6| Step: 13
Training loss: 0.038260706916893504
Validation loss: 2.4667440863180126

Epoch: 526| Step: 0
Training loss: 0.05037653563421147
Validation loss: 2.411018803723264

Epoch: 6| Step: 1
Training loss: 0.1145968257661881
Validation loss: 2.399651860674381

Epoch: 6| Step: 2
Training loss: 0.12033819397988442
Validation loss: 2.4150603620405806

Epoch: 6| Step: 3
Training loss: 0.12624187771475706
Validation loss: 2.4122099184335783

Epoch: 6| Step: 4
Training loss: 0.08413599433659681
Validation loss: 2.427269338865073

Epoch: 6| Step: 5
Training loss: 0.08712263209557453
Validation loss: 2.471905102503787

Epoch: 6| Step: 6
Training loss: 0.06984693317818814
Validation loss: 2.4844475965985393

Epoch: 6| Step: 7
Training loss: 0.1342771911620227
Validation loss: 2.5229979726330063

Epoch: 6| Step: 8
Training loss: 0.10135960486244705
Validation loss: 2.5293540107816646

Epoch: 6| Step: 9
Training loss: 0.12085566264703863
Validation loss: 2.5101989476718187

Epoch: 6| Step: 10
Training loss: 0.09607773081298009
Validation loss: 2.482442186405668

Epoch: 6| Step: 11
Training loss: 0.14128949208256236
Validation loss: 2.450168780267699

Epoch: 6| Step: 12
Training loss: 0.10501120361376595
Validation loss: 2.4294409907605417

Epoch: 6| Step: 13
Training loss: 0.145956888963203
Validation loss: 2.4071854455214403

Epoch: 527| Step: 0
Training loss: 0.10264140879679767
Validation loss: 2.401953905463305

Epoch: 6| Step: 1
Training loss: 0.07070775003743843
Validation loss: 2.383562074138884

Epoch: 6| Step: 2
Training loss: 0.10292542193584346
Validation loss: 2.346477121317878

Epoch: 6| Step: 3
Training loss: 0.11351628010607384
Validation loss: 2.3690082429301724

Epoch: 6| Step: 4
Training loss: 0.09225953972732666
Validation loss: 2.374041354663007

Epoch: 6| Step: 5
Training loss: 0.09280204331932414
Validation loss: 2.402746781927677

Epoch: 6| Step: 6
Training loss: 0.08989235869157605
Validation loss: 2.415380903544392

Epoch: 6| Step: 7
Training loss: 0.14227048134514678
Validation loss: 2.4252623560429374

Epoch: 6| Step: 8
Training loss: 0.07440238120039594
Validation loss: 2.407781452673701

Epoch: 6| Step: 9
Training loss: 0.1316878794292131
Validation loss: 2.452611084161375

Epoch: 6| Step: 10
Training loss: 0.07218311083855208
Validation loss: 2.4606933305942613

Epoch: 6| Step: 11
Training loss: 0.06845101276992775
Validation loss: 2.4622729918749346

Epoch: 6| Step: 12
Training loss: 0.11865051487898565
Validation loss: 2.4668504648429312

Epoch: 6| Step: 13
Training loss: 0.08975714157893662
Validation loss: 2.469793133330769

Epoch: 528| Step: 0
Training loss: 0.10753763204136588
Validation loss: 2.4341459065160103

Epoch: 6| Step: 1
Training loss: 0.07053578540436693
Validation loss: 2.4500075105765875

Epoch: 6| Step: 2
Training loss: 0.10460477627993994
Validation loss: 2.4364289674983715

Epoch: 6| Step: 3
Training loss: 0.14595216070946393
Validation loss: 2.432804709586484

Epoch: 6| Step: 4
Training loss: 0.08185147272294213
Validation loss: 2.411712981384114

Epoch: 6| Step: 5
Training loss: 0.1474989848283812
Validation loss: 2.4022150108723936

Epoch: 6| Step: 6
Training loss: 0.08487732653613954
Validation loss: 2.428933088120518

Epoch: 6| Step: 7
Training loss: 0.10356812675179891
Validation loss: 2.4229585624509764

Epoch: 6| Step: 8
Training loss: 0.08810686953865905
Validation loss: 2.4005039595210773

Epoch: 6| Step: 9
Training loss: 0.1144026791583968
Validation loss: 2.432829358426601

Epoch: 6| Step: 10
Training loss: 0.06744022273337912
Validation loss: 2.4642389739710038

Epoch: 6| Step: 11
Training loss: 0.11985283737593698
Validation loss: 2.484872041939671

Epoch: 6| Step: 12
Training loss: 0.11460092573868616
Validation loss: 2.487346213662642

Epoch: 6| Step: 13
Training loss: 0.13497982417446605
Validation loss: 2.5040186239177227

Epoch: 529| Step: 0
Training loss: 0.07824125878329928
Validation loss: 2.4674419012842446

Epoch: 6| Step: 1
Training loss: 0.08488623305414339
Validation loss: 2.4571042893103616

Epoch: 6| Step: 2
Training loss: 0.1284788226853495
Validation loss: 2.429031831742957

Epoch: 6| Step: 3
Training loss: 0.12685658378786452
Validation loss: 2.410780612354109

Epoch: 6| Step: 4
Training loss: 0.0986066160255801
Validation loss: 2.4365163148142988

Epoch: 6| Step: 5
Training loss: 0.05592141141163731
Validation loss: 2.426318800329858

Epoch: 6| Step: 6
Training loss: 0.07069742617112143
Validation loss: 2.409596843467509

Epoch: 6| Step: 7
Training loss: 0.0762024353540535
Validation loss: 2.4124370268552977

Epoch: 6| Step: 8
Training loss: 0.09288699578525808
Validation loss: 2.4068406329310412

Epoch: 6| Step: 9
Training loss: 0.06961637186170438
Validation loss: 2.3874782629773255

Epoch: 6| Step: 10
Training loss: 0.11737777838805721
Validation loss: 2.400472574126682

Epoch: 6| Step: 11
Training loss: 0.15307008770741365
Validation loss: 2.4065036669272524

Epoch: 6| Step: 12
Training loss: 0.08613082424991715
Validation loss: 2.4433678254662654

Epoch: 6| Step: 13
Training loss: 0.06936092665157623
Validation loss: 2.393983630008335

Epoch: 530| Step: 0
Training loss: 0.12919689415695187
Validation loss: 2.4355890236339546

Epoch: 6| Step: 1
Training loss: 0.07203318937198123
Validation loss: 2.4074163541328706

Epoch: 6| Step: 2
Training loss: 0.040933171340993675
Validation loss: 2.4257794861485498

Epoch: 6| Step: 3
Training loss: 0.08482051623452504
Validation loss: 2.4568960292587736

Epoch: 6| Step: 4
Training loss: 0.06540604064423089
Validation loss: 2.4569343229412

Epoch: 6| Step: 5
Training loss: 0.13640134615784458
Validation loss: 2.4138906728155125

Epoch: 6| Step: 6
Training loss: 0.05504077031874907
Validation loss: 2.410960337896522

Epoch: 6| Step: 7
Training loss: 0.11663623131476061
Validation loss: 2.4031084901882727

Epoch: 6| Step: 8
Training loss: 0.1148023183525612
Validation loss: 2.4296015213247837

Epoch: 6| Step: 9
Training loss: 0.05978104573188497
Validation loss: 2.437143668398459

Epoch: 6| Step: 10
Training loss: 0.08791605793352744
Validation loss: 2.4314808556106597

Epoch: 6| Step: 11
Training loss: 0.041362007983506546
Validation loss: 2.4568258397545306

Epoch: 6| Step: 12
Training loss: 0.048143109325743935
Validation loss: 2.4488055086690528

Epoch: 6| Step: 13
Training loss: 0.14548705420179556
Validation loss: 2.44682293407484

Epoch: 531| Step: 0
Training loss: 0.08427398670534242
Validation loss: 2.4331079369229665

Epoch: 6| Step: 1
Training loss: 0.07062258822829869
Validation loss: 2.4375138693878484

Epoch: 6| Step: 2
Training loss: 0.07572245061815475
Validation loss: 2.4417641990199046

Epoch: 6| Step: 3
Training loss: 0.06908060124680317
Validation loss: 2.446962964010351

Epoch: 6| Step: 4
Training loss: 0.11845681677136105
Validation loss: 2.4354937595038195

Epoch: 6| Step: 5
Training loss: 0.07293892063851017
Validation loss: 2.41768996833439

Epoch: 6| Step: 6
Training loss: 0.05618175068285364
Validation loss: 2.441384278294949

Epoch: 6| Step: 7
Training loss: 0.11618894481119715
Validation loss: 2.4407589305862576

Epoch: 6| Step: 8
Training loss: 0.17493157603089582
Validation loss: 2.449142511652564

Epoch: 6| Step: 9
Training loss: 0.08478473335886505
Validation loss: 2.411167403013683

Epoch: 6| Step: 10
Training loss: 0.11264683393102545
Validation loss: 2.4370513063407713

Epoch: 6| Step: 11
Training loss: 0.0657024463001627
Validation loss: 2.432647584879773

Epoch: 6| Step: 12
Training loss: 0.09598321702188166
Validation loss: 2.431834601364807

Epoch: 6| Step: 13
Training loss: 0.07287017441340661
Validation loss: 2.3945799393054736

Epoch: 532| Step: 0
Training loss: 0.051778164047310754
Validation loss: 2.4383875469685217

Epoch: 6| Step: 1
Training loss: 0.11041351284240364
Validation loss: 2.43136071959163

Epoch: 6| Step: 2
Training loss: 0.13653303202694836
Validation loss: 2.45913770901432

Epoch: 6| Step: 3
Training loss: 0.0455133306857768
Validation loss: 2.4549302585332033

Epoch: 6| Step: 4
Training loss: 0.12355234003987778
Validation loss: 2.4508976687080284

Epoch: 6| Step: 5
Training loss: 0.0781177696220072
Validation loss: 2.4608902829835064

Epoch: 6| Step: 6
Training loss: 0.07497421804985774
Validation loss: 2.442042640091841

Epoch: 6| Step: 7
Training loss: 0.08958877269270137
Validation loss: 2.490289500859115

Epoch: 6| Step: 8
Training loss: 0.07076031087263965
Validation loss: 2.4517303362706753

Epoch: 6| Step: 9
Training loss: 0.09043262139127545
Validation loss: 2.4290588259845856

Epoch: 6| Step: 10
Training loss: 0.08108672405136721
Validation loss: 2.422860689729588

Epoch: 6| Step: 11
Training loss: 0.11231477940867475
Validation loss: 2.439359458930648

Epoch: 6| Step: 12
Training loss: 0.04935074545476988
Validation loss: 2.429548977288524

Epoch: 6| Step: 13
Training loss: 0.10175553646946905
Validation loss: 2.4224730680401874

Epoch: 533| Step: 0
Training loss: 0.152321703856195
Validation loss: 2.3878109384196207

Epoch: 6| Step: 1
Training loss: 0.04793567709039947
Validation loss: 2.3891159968998443

Epoch: 6| Step: 2
Training loss: 0.139456410195686
Validation loss: 2.376300604608098

Epoch: 6| Step: 3
Training loss: 0.11585644742079731
Validation loss: 2.4042583405942284

Epoch: 6| Step: 4
Training loss: 0.06941777087917486
Validation loss: 2.378287860657473

Epoch: 6| Step: 5
Training loss: 0.06158639698783851
Validation loss: 2.403897980578569

Epoch: 6| Step: 6
Training loss: 0.1229836740610714
Validation loss: 2.41724016034758

Epoch: 6| Step: 7
Training loss: 0.07148805697396385
Validation loss: 2.448750875878306

Epoch: 6| Step: 8
Training loss: 0.12204841417351298
Validation loss: 2.4626128682276622

Epoch: 6| Step: 9
Training loss: 0.09183742763749565
Validation loss: 2.4577078491959603

Epoch: 6| Step: 10
Training loss: 0.09007334397887642
Validation loss: 2.4752668953408405

Epoch: 6| Step: 11
Training loss: 0.10510315047561436
Validation loss: 2.452205916087458

Epoch: 6| Step: 12
Training loss: 0.06347101994305183
Validation loss: 2.43116145826985

Epoch: 6| Step: 13
Training loss: 0.08343604365606579
Validation loss: 2.402512264935981

Epoch: 534| Step: 0
Training loss: 0.051534223750628494
Validation loss: 2.3812584424667897

Epoch: 6| Step: 1
Training loss: 0.15281438268582184
Validation loss: 2.386184985279766

Epoch: 6| Step: 2
Training loss: 0.06389177677303978
Validation loss: 2.3910225249445882

Epoch: 6| Step: 3
Training loss: 0.07088345600556295
Validation loss: 2.412245490903526

Epoch: 6| Step: 4
Training loss: 0.1301709041840861
Validation loss: 2.4130515625339317

Epoch: 6| Step: 5
Training loss: 0.084574326756906
Validation loss: 2.437238284254895

Epoch: 6| Step: 6
Training loss: 0.07850659873662641
Validation loss: 2.43143071530741

Epoch: 6| Step: 7
Training loss: 0.10504357415153523
Validation loss: 2.470892540731886

Epoch: 6| Step: 8
Training loss: 0.10526923010208793
Validation loss: 2.4993921766428984

Epoch: 6| Step: 9
Training loss: 0.13859867124840863
Validation loss: 2.4989395476633005

Epoch: 6| Step: 10
Training loss: 0.1791850404041678
Validation loss: 2.5021594585912736

Epoch: 6| Step: 11
Training loss: 0.08837056779251766
Validation loss: 2.4594011408805088

Epoch: 6| Step: 12
Training loss: 0.05743231451413993
Validation loss: 2.430738313858109

Epoch: 6| Step: 13
Training loss: 0.08107522623827944
Validation loss: 2.415745273276628

Epoch: 535| Step: 0
Training loss: 0.09289602913628768
Validation loss: 2.3807826936627876

Epoch: 6| Step: 1
Training loss: 0.12070128075261694
Validation loss: 2.3961542357780643

Epoch: 6| Step: 2
Training loss: 0.11354847334952933
Validation loss: 2.3938701758083183

Epoch: 6| Step: 3
Training loss: 0.09620393874732062
Validation loss: 2.393065246055083

Epoch: 6| Step: 4
Training loss: 0.14011174155489536
Validation loss: 2.414299716930223

Epoch: 6| Step: 5
Training loss: 0.12132248886266936
Validation loss: 2.4256673859493487

Epoch: 6| Step: 6
Training loss: 0.11000748389426426
Validation loss: 2.469676249900408

Epoch: 6| Step: 7
Training loss: 0.05799664797736153
Validation loss: 2.5042941509823473

Epoch: 6| Step: 8
Training loss: 0.13427572075990038
Validation loss: 2.4763802407972637

Epoch: 6| Step: 9
Training loss: 0.07839118790001477
Validation loss: 2.4581774861564516

Epoch: 6| Step: 10
Training loss: 0.1347553000434034
Validation loss: 2.462827772138195

Epoch: 6| Step: 11
Training loss: 0.0769686989346535
Validation loss: 2.473345509367492

Epoch: 6| Step: 12
Training loss: 0.09152736566655734
Validation loss: 2.443299729867226

Epoch: 6| Step: 13
Training loss: 0.16316604930863501
Validation loss: 2.4227507310950944

Epoch: 536| Step: 0
Training loss: 0.1337193704342428
Validation loss: 2.4642510418584402

Epoch: 6| Step: 1
Training loss: 0.07803210159233508
Validation loss: 2.452640525057742

Epoch: 6| Step: 2
Training loss: 0.13994394394569507
Validation loss: 2.4679601316182054

Epoch: 6| Step: 3
Training loss: 0.12139602588624981
Validation loss: 2.4702373534642303

Epoch: 6| Step: 4
Training loss: 0.08196212205966237
Validation loss: 2.46110741959237

Epoch: 6| Step: 5
Training loss: 0.07509272252855063
Validation loss: 2.4718523264592926

Epoch: 6| Step: 6
Training loss: 0.040347726760530826
Validation loss: 2.475336295770935

Epoch: 6| Step: 7
Training loss: 0.06895854150329143
Validation loss: 2.469254095020424

Epoch: 6| Step: 8
Training loss: 0.08336341924518746
Validation loss: 2.481863575714869

Epoch: 6| Step: 9
Training loss: 0.10472064134192659
Validation loss: 2.4761589282785974

Epoch: 6| Step: 10
Training loss: 0.15387489464180606
Validation loss: 2.4616099673115697

Epoch: 6| Step: 11
Training loss: 0.07133669764091079
Validation loss: 2.448878334791158

Epoch: 6| Step: 12
Training loss: 0.11531943883152085
Validation loss: 2.428524209837377

Epoch: 6| Step: 13
Training loss: 0.11170336160516006
Validation loss: 2.4156674542481396

Epoch: 537| Step: 0
Training loss: 0.0915206649562214
Validation loss: 2.3779352644930984

Epoch: 6| Step: 1
Training loss: 0.0966819416130157
Validation loss: 2.399238287333741

Epoch: 6| Step: 2
Training loss: 0.14804568780911204
Validation loss: 2.417004378855563

Epoch: 6| Step: 3
Training loss: 0.11273038044155446
Validation loss: 2.394674018696586

Epoch: 6| Step: 4
Training loss: 0.06322789636272803
Validation loss: 2.4318892135953427

Epoch: 6| Step: 5
Training loss: 0.056631603426846644
Validation loss: 2.390915297216789

Epoch: 6| Step: 6
Training loss: 0.07350606748273493
Validation loss: 2.409857921824772

Epoch: 6| Step: 7
Training loss: 0.10308619260304677
Validation loss: 2.4156746718367543

Epoch: 6| Step: 8
Training loss: 0.09320580968643455
Validation loss: 2.447685742575238

Epoch: 6| Step: 9
Training loss: 0.07182416880684654
Validation loss: 2.4155687236212193

Epoch: 6| Step: 10
Training loss: 0.08899125671234841
Validation loss: 2.432740311192386

Epoch: 6| Step: 11
Training loss: 0.15737492213728282
Validation loss: 2.4124490159441145

Epoch: 6| Step: 12
Training loss: 0.08251896976528217
Validation loss: 2.4279479672673334

Epoch: 6| Step: 13
Training loss: 0.08814567540662595
Validation loss: 2.43114967745518

Epoch: 538| Step: 0
Training loss: 0.15120472341672003
Validation loss: 2.440895856374984

Epoch: 6| Step: 1
Training loss: 0.0696458539093125
Validation loss: 2.425311044658306

Epoch: 6| Step: 2
Training loss: 0.08463047147633215
Validation loss: 2.429736087807715

Epoch: 6| Step: 3
Training loss: 0.09679242987505647
Validation loss: 2.426325125109949

Epoch: 6| Step: 4
Training loss: 0.050091618179607625
Validation loss: 2.437241267336377

Epoch: 6| Step: 5
Training loss: 0.1330604202713601
Validation loss: 2.4494929935265435

Epoch: 6| Step: 6
Training loss: 0.06588224219915956
Validation loss: 2.444637218579267

Epoch: 6| Step: 7
Training loss: 0.10690902183784144
Validation loss: 2.4512869487872493

Epoch: 6| Step: 8
Training loss: 0.06004566929701341
Validation loss: 2.4446498289162517

Epoch: 6| Step: 9
Training loss: 0.05959691954331981
Validation loss: 2.4556957700153563

Epoch: 6| Step: 10
Training loss: 0.11893647322359358
Validation loss: 2.4193905602145804

Epoch: 6| Step: 11
Training loss: 0.09313945845238344
Validation loss: 2.4223745803997274

Epoch: 6| Step: 12
Training loss: 0.09127953010709675
Validation loss: 2.3881953444475807

Epoch: 6| Step: 13
Training loss: 0.09252586962308743
Validation loss: 2.443043486642904

Epoch: 539| Step: 0
Training loss: 0.053332119986272325
Validation loss: 2.4311638772736033

Epoch: 6| Step: 1
Training loss: 0.06680891725954424
Validation loss: 2.434728557707737

Epoch: 6| Step: 2
Training loss: 0.10498022922222401
Validation loss: 2.4365757488034405

Epoch: 6| Step: 3
Training loss: 0.08546794141285802
Validation loss: 2.439185313736876

Epoch: 6| Step: 4
Training loss: 0.045002882417281044
Validation loss: 2.4576132254813365

Epoch: 6| Step: 5
Training loss: 0.07518040521662248
Validation loss: 2.4684724959409547

Epoch: 6| Step: 6
Training loss: 0.13772384537311344
Validation loss: 2.4544694574964976

Epoch: 6| Step: 7
Training loss: 0.1486429436598147
Validation loss: 2.4407710867318877

Epoch: 6| Step: 8
Training loss: 0.06582341653766154
Validation loss: 2.4151738753921754

Epoch: 6| Step: 9
Training loss: 0.06056393875119663
Validation loss: 2.3961195847408443

Epoch: 6| Step: 10
Training loss: 0.14468077708870725
Validation loss: 2.3734737343004904

Epoch: 6| Step: 11
Training loss: 0.11107900419704257
Validation loss: 2.3516811070708488

Epoch: 6| Step: 12
Training loss: 0.1615650448607929
Validation loss: 2.369850644947796

Epoch: 6| Step: 13
Training loss: 0.08468088768644262
Validation loss: 2.4140499613919104

Epoch: 540| Step: 0
Training loss: 0.10342172196217424
Validation loss: 2.3964620984096436

Epoch: 6| Step: 1
Training loss: 0.1301261157497352
Validation loss: 2.4320138625638106

Epoch: 6| Step: 2
Training loss: 0.0928704056177809
Validation loss: 2.4294215647899904

Epoch: 6| Step: 3
Training loss: 0.07910517107420757
Validation loss: 2.388336847440094

Epoch: 6| Step: 4
Training loss: 0.1043857674270024
Validation loss: 2.4018703834364423

Epoch: 6| Step: 5
Training loss: 0.11082157539021896
Validation loss: 2.4012290349935523

Epoch: 6| Step: 6
Training loss: 0.05410109048079728
Validation loss: 2.3761657602020514

Epoch: 6| Step: 7
Training loss: 0.13395072748069245
Validation loss: 2.343004027300621

Epoch: 6| Step: 8
Training loss: 0.10125332319139525
Validation loss: 2.3513333121001843

Epoch: 6| Step: 9
Training loss: 0.08987732964627959
Validation loss: 2.3727658033299033

Epoch: 6| Step: 10
Training loss: 0.0984689465505369
Validation loss: 2.3661647739631815

Epoch: 6| Step: 11
Training loss: 0.11359016457399586
Validation loss: 2.3885704894178925

Epoch: 6| Step: 12
Training loss: 0.06195659139491595
Validation loss: 2.416218822391776

Epoch: 6| Step: 13
Training loss: 0.11088542169185978
Validation loss: 2.445125216340588

Epoch: 541| Step: 0
Training loss: 0.12307002969894701
Validation loss: 2.46449689763385

Epoch: 6| Step: 1
Training loss: 0.11798548800731944
Validation loss: 2.4753404995668076

Epoch: 6| Step: 2
Training loss: 0.10819436530175754
Validation loss: 2.42952244012008

Epoch: 6| Step: 3
Training loss: 0.09984016795590625
Validation loss: 2.455121532823976

Epoch: 6| Step: 4
Training loss: 0.08351230742767489
Validation loss: 2.4437316535903264

Epoch: 6| Step: 5
Training loss: 0.0657448331591799
Validation loss: 2.407246555227957

Epoch: 6| Step: 6
Training loss: 0.09439502784603114
Validation loss: 2.4148009847554137

Epoch: 6| Step: 7
Training loss: 0.09686799927765223
Validation loss: 2.3859314134533856

Epoch: 6| Step: 8
Training loss: 0.11774159802920856
Validation loss: 2.3983043759169096

Epoch: 6| Step: 9
Training loss: 0.09259605515758774
Validation loss: 2.3974954215873048

Epoch: 6| Step: 10
Training loss: 0.10500993093433067
Validation loss: 2.4253640364558726

Epoch: 6| Step: 11
Training loss: 0.08445839954529513
Validation loss: 2.4428059516696425

Epoch: 6| Step: 12
Training loss: 0.12410564401486998
Validation loss: 2.424689388817629

Epoch: 6| Step: 13
Training loss: 0.08770606743892034
Validation loss: 2.465051826345407

Epoch: 542| Step: 0
Training loss: 0.09886408592613193
Validation loss: 2.430029425704298

Epoch: 6| Step: 1
Training loss: 0.09982706573044944
Validation loss: 2.4240348497517448

Epoch: 6| Step: 2
Training loss: 0.07841621304324486
Validation loss: 2.435727758568935

Epoch: 6| Step: 3
Training loss: 0.06219507316561994
Validation loss: 2.4461410027354766

Epoch: 6| Step: 4
Training loss: 0.14340362905209111
Validation loss: 2.4554822527479874

Epoch: 6| Step: 5
Training loss: 0.10131673696666711
Validation loss: 2.422851751372419

Epoch: 6| Step: 6
Training loss: 0.1154266103666769
Validation loss: 2.4272629626798685

Epoch: 6| Step: 7
Training loss: 0.06819291283052796
Validation loss: 2.3804870275005645

Epoch: 6| Step: 8
Training loss: 0.10035057679164047
Validation loss: 2.3628544437539127

Epoch: 6| Step: 9
Training loss: 0.0805784216504187
Validation loss: 2.3604121062220726

Epoch: 6| Step: 10
Training loss: 0.1327470449829953
Validation loss: 2.398878642643829

Epoch: 6| Step: 11
Training loss: 0.08156031863722975
Validation loss: 2.3976621548672195

Epoch: 6| Step: 12
Training loss: 0.11432564181104497
Validation loss: 2.380916699451221

Epoch: 6| Step: 13
Training loss: 0.10230572809576446
Validation loss: 2.404337437875324

Epoch: 543| Step: 0
Training loss: 0.11322305269617752
Validation loss: 2.444910455597341

Epoch: 6| Step: 1
Training loss: 0.15474683004307863
Validation loss: 2.4394253703636637

Epoch: 6| Step: 2
Training loss: 0.06741399320014647
Validation loss: 2.4749813397747054

Epoch: 6| Step: 3
Training loss: 0.09325980139553938
Validation loss: 2.471396676422592

Epoch: 6| Step: 4
Training loss: 0.0952418069075411
Validation loss: 2.4843838712771595

Epoch: 6| Step: 5
Training loss: 0.06730924612471555
Validation loss: 2.4667261160421576

Epoch: 6| Step: 6
Training loss: 0.12137060664590762
Validation loss: 2.457115035879368

Epoch: 6| Step: 7
Training loss: 0.09301927519924713
Validation loss: 2.4606775956841727

Epoch: 6| Step: 8
Training loss: 0.08910428372065417
Validation loss: 2.441656453492998

Epoch: 6| Step: 9
Training loss: 0.05228367906349748
Validation loss: 2.4156793190567116

Epoch: 6| Step: 10
Training loss: 0.09587910101772286
Validation loss: 2.4431136308629853

Epoch: 6| Step: 11
Training loss: 0.06707182590907784
Validation loss: 2.4195743839570802

Epoch: 6| Step: 12
Training loss: 0.07821611515180252
Validation loss: 2.46207662178162

Epoch: 6| Step: 13
Training loss: 0.07735564677420195
Validation loss: 2.439936014063841

Epoch: 544| Step: 0
Training loss: 0.08150142193739328
Validation loss: 2.4265741547122

Epoch: 6| Step: 1
Training loss: 0.07546026134237403
Validation loss: 2.435143048788495

Epoch: 6| Step: 2
Training loss: 0.08288938545231443
Validation loss: 2.438233125678578

Epoch: 6| Step: 3
Training loss: 0.13930172996810875
Validation loss: 2.464744684319681

Epoch: 6| Step: 4
Training loss: 0.04774260767572498
Validation loss: 2.4391920791645756

Epoch: 6| Step: 5
Training loss: 0.08978210283041003
Validation loss: 2.428309750826261

Epoch: 6| Step: 6
Training loss: 0.1181156082746652
Validation loss: 2.415192690980301

Epoch: 6| Step: 7
Training loss: 0.07350286506807005
Validation loss: 2.40693412444991

Epoch: 6| Step: 8
Training loss: 0.10782142374176279
Validation loss: 2.386494702232373

Epoch: 6| Step: 9
Training loss: 0.15834001811455414
Validation loss: 2.404637626876984

Epoch: 6| Step: 10
Training loss: 0.09934605593793523
Validation loss: 2.3798798049194843

Epoch: 6| Step: 11
Training loss: 0.05638972568059093
Validation loss: 2.390684403339556

Epoch: 6| Step: 12
Training loss: 0.06589829186523481
Validation loss: 2.3934943051964694

Epoch: 6| Step: 13
Training loss: 0.11383886639400265
Validation loss: 2.391448087616704

Epoch: 545| Step: 0
Training loss: 0.17550557560262534
Validation loss: 2.408952220372243

Epoch: 6| Step: 1
Training loss: 0.1182345188150581
Validation loss: 2.40398968779381

Epoch: 6| Step: 2
Training loss: 0.07527166366961624
Validation loss: 2.4262876379208618

Epoch: 6| Step: 3
Training loss: 0.06975281338781687
Validation loss: 2.4077676585058976

Epoch: 6| Step: 4
Training loss: 0.1188317853287362
Validation loss: 2.4196401679053103

Epoch: 6| Step: 5
Training loss: 0.08238703626456022
Validation loss: 2.4441560895695478

Epoch: 6| Step: 6
Training loss: 0.10983066922517629
Validation loss: 2.3991486253821486

Epoch: 6| Step: 7
Training loss: 0.08580679327752994
Validation loss: 2.402544858264719

Epoch: 6| Step: 8
Training loss: 0.08841396921868698
Validation loss: 2.406773421176097

Epoch: 6| Step: 9
Training loss: 0.09295258040820892
Validation loss: 2.416997263880164

Epoch: 6| Step: 10
Training loss: 0.03461699196640386
Validation loss: 2.417732685934909

Epoch: 6| Step: 11
Training loss: 0.06385494940276969
Validation loss: 2.410522386324872

Epoch: 6| Step: 12
Training loss: 0.09229184181983953
Validation loss: 2.4229827210625676

Epoch: 6| Step: 13
Training loss: 0.05185340654543529
Validation loss: 2.4495858534905364

Epoch: 546| Step: 0
Training loss: 0.07696319020472803
Validation loss: 2.4653024055128574

Epoch: 6| Step: 1
Training loss: 0.14166850119225718
Validation loss: 2.4540012650343344

Epoch: 6| Step: 2
Training loss: 0.06593256188383045
Validation loss: 2.458664805189079

Epoch: 6| Step: 3
Training loss: 0.05361044977003553
Validation loss: 2.442974438598973

Epoch: 6| Step: 4
Training loss: 0.09619349753338202
Validation loss: 2.44128210579864

Epoch: 6| Step: 5
Training loss: 0.07216990420542664
Validation loss: 2.4341326988350227

Epoch: 6| Step: 6
Training loss: 0.11349417964993255
Validation loss: 2.4374920771543414

Epoch: 6| Step: 7
Training loss: 0.08756906974302703
Validation loss: 2.4134064289395813

Epoch: 6| Step: 8
Training loss: 0.08974008176838227
Validation loss: 2.396223151197098

Epoch: 6| Step: 9
Training loss: 0.07238593589870326
Validation loss: 2.3953680891284574

Epoch: 6| Step: 10
Training loss: 0.14540440770270713
Validation loss: 2.3858193928395597

Epoch: 6| Step: 11
Training loss: 0.08840927108208942
Validation loss: 2.364304663043869

Epoch: 6| Step: 12
Training loss: 0.06867474628625718
Validation loss: 2.404056602275827

Epoch: 6| Step: 13
Training loss: 0.08538319898321191
Validation loss: 2.4214568339131515

Epoch: 547| Step: 0
Training loss: 0.09347799199625707
Validation loss: 2.4341563031501727

Epoch: 6| Step: 1
Training loss: 0.09167768979262977
Validation loss: 2.4632254324300598

Epoch: 6| Step: 2
Training loss: 0.14063954940340523
Validation loss: 2.493632669048219

Epoch: 6| Step: 3
Training loss: 0.11451463690092163
Validation loss: 2.474118410554322

Epoch: 6| Step: 4
Training loss: 0.11381427147134492
Validation loss: 2.506552783281463

Epoch: 6| Step: 5
Training loss: 0.07739706658184722
Validation loss: 2.438620520908364

Epoch: 6| Step: 6
Training loss: 0.07842589489130154
Validation loss: 2.446442617957562

Epoch: 6| Step: 7
Training loss: 0.05867822041973834
Validation loss: 2.456846343465315

Epoch: 6| Step: 8
Training loss: 0.08664416884233907
Validation loss: 2.3943259063777425

Epoch: 6| Step: 9
Training loss: 0.06143402611325712
Validation loss: 2.38950340731754

Epoch: 6| Step: 10
Training loss: 0.062398192442234504
Validation loss: 2.403856915445905

Epoch: 6| Step: 11
Training loss: 0.11405162465492827
Validation loss: 2.4174260320890637

Epoch: 6| Step: 12
Training loss: 0.08081978344640427
Validation loss: 2.4177822164539053

Epoch: 6| Step: 13
Training loss: 0.1557621731646854
Validation loss: 2.43745319930489

Epoch: 548| Step: 0
Training loss: 0.13010000411456216
Validation loss: 2.428164163339289

Epoch: 6| Step: 1
Training loss: 0.0745177832719037
Validation loss: 2.4462047742912745

Epoch: 6| Step: 2
Training loss: 0.1443319364000905
Validation loss: 2.4640741311148493

Epoch: 6| Step: 3
Training loss: 0.06622054275112987
Validation loss: 2.453524851982189

Epoch: 6| Step: 4
Training loss: 0.10142661596226907
Validation loss: 2.4973365429088923

Epoch: 6| Step: 5
Training loss: 0.06572133866416363
Validation loss: 2.45120888331427

Epoch: 6| Step: 6
Training loss: 0.0864885958621095
Validation loss: 2.4268735981341867

Epoch: 6| Step: 7
Training loss: 0.08146105438067454
Validation loss: 2.471940210545118

Epoch: 6| Step: 8
Training loss: 0.11872068642530413
Validation loss: 2.4535305230653486

Epoch: 6| Step: 9
Training loss: 0.13678868412482062
Validation loss: 2.4182538904721156

Epoch: 6| Step: 10
Training loss: 0.05843775169042965
Validation loss: 2.3573753911789375

Epoch: 6| Step: 11
Training loss: 0.13842760654557934
Validation loss: 2.350482885126923

Epoch: 6| Step: 12
Training loss: 0.09491551126725671
Validation loss: 2.3631436633260283

Epoch: 6| Step: 13
Training loss: 0.05098333861817171
Validation loss: 2.369212048836694

Epoch: 549| Step: 0
Training loss: 0.12172165479119831
Validation loss: 2.369436224174893

Epoch: 6| Step: 1
Training loss: 0.1702134272942669
Validation loss: 2.4094854868641384

Epoch: 6| Step: 2
Training loss: 0.09015242273447972
Validation loss: 2.440751275129653

Epoch: 6| Step: 3
Training loss: 0.11607388821945873
Validation loss: 2.47871674732448

Epoch: 6| Step: 4
Training loss: 0.12194567611789692
Validation loss: 2.473487084954961

Epoch: 6| Step: 5
Training loss: 0.10711731217689874
Validation loss: 2.4896000319957614

Epoch: 6| Step: 6
Training loss: 0.08595965923373694
Validation loss: 2.4981769123608117

Epoch: 6| Step: 7
Training loss: 0.1117839099689123
Validation loss: 2.47440500437943

Epoch: 6| Step: 8
Training loss: 0.0562325754430201
Validation loss: 2.476553934546424

Epoch: 6| Step: 9
Training loss: 0.06969239388803017
Validation loss: 2.4519612195962184

Epoch: 6| Step: 10
Training loss: 0.10505279001607574
Validation loss: 2.4299787316420622

Epoch: 6| Step: 11
Training loss: 0.09190753597461054
Validation loss: 2.433918251592417

Epoch: 6| Step: 12
Training loss: 0.08048672058769595
Validation loss: 2.4417004737024097

Epoch: 6| Step: 13
Training loss: 0.04423825061872824
Validation loss: 2.4120034062244455

Epoch: 550| Step: 0
Training loss: 0.10166516983319157
Validation loss: 2.4531620791728734

Epoch: 6| Step: 1
Training loss: 0.06594002672524861
Validation loss: 2.4639465135354017

Epoch: 6| Step: 2
Training loss: 0.04888079187064857
Validation loss: 2.4861725351055566

Epoch: 6| Step: 3
Training loss: 0.06753670354620984
Validation loss: 2.4707988608435527

Epoch: 6| Step: 4
Training loss: 0.1508182848280539
Validation loss: 2.4941914226143678

Epoch: 6| Step: 5
Training loss: 0.09096398832988895
Validation loss: 2.4619426028362907

Epoch: 6| Step: 6
Training loss: 0.05169295800162365
Validation loss: 2.476048214903268

Epoch: 6| Step: 7
Training loss: 0.07477712148212781
Validation loss: 2.439928487363177

Epoch: 6| Step: 8
Training loss: 0.058854013821873205
Validation loss: 2.4292393051305274

Epoch: 6| Step: 9
Training loss: 0.09431907175278544
Validation loss: 2.463274761890382

Epoch: 6| Step: 10
Training loss: 0.13390351015579635
Validation loss: 2.420177415998661

Epoch: 6| Step: 11
Training loss: 0.06786805427386831
Validation loss: 2.4270893205821213

Epoch: 6| Step: 12
Training loss: 0.09336113748522772
Validation loss: 2.447612335271036

Epoch: 6| Step: 13
Training loss: 0.11883814514268323
Validation loss: 2.441966204476358

Epoch: 551| Step: 0
Training loss: 0.14783891651490627
Validation loss: 2.433899697155053

Epoch: 6| Step: 1
Training loss: 0.057949795271702735
Validation loss: 2.4298557412773705

Epoch: 6| Step: 2
Training loss: 0.06403690021448273
Validation loss: 2.4284564105881388

Epoch: 6| Step: 3
Training loss: 0.05855722481038039
Validation loss: 2.400111433146014

Epoch: 6| Step: 4
Training loss: 0.07659514215477305
Validation loss: 2.3951829540237934

Epoch: 6| Step: 5
Training loss: 0.09894744338381445
Validation loss: 2.389269634460909

Epoch: 6| Step: 6
Training loss: 0.04894792166207432
Validation loss: 2.3956733272101842

Epoch: 6| Step: 7
Training loss: 0.14307758951581628
Validation loss: 2.4231274687722166

Epoch: 6| Step: 8
Training loss: 0.0728397790670504
Validation loss: 2.415934949077973

Epoch: 6| Step: 9
Training loss: 0.06278959624161032
Validation loss: 2.4004357741543476

Epoch: 6| Step: 10
Training loss: 0.07724062325147746
Validation loss: 2.386051892628538

Epoch: 6| Step: 11
Training loss: 0.11483939415592519
Validation loss: 2.4091911213724524

Epoch: 6| Step: 12
Training loss: 0.08295385065298448
Validation loss: 2.4018166886374788

Epoch: 6| Step: 13
Training loss: 0.10010400612391851
Validation loss: 2.4316381569191035

Epoch: 552| Step: 0
Training loss: 0.11374834379101313
Validation loss: 2.457384654000275

Epoch: 6| Step: 1
Training loss: 0.0862490036810122
Validation loss: 2.4722858402872134

Epoch: 6| Step: 2
Training loss: 0.07486310562742171
Validation loss: 2.4660640886265934

Epoch: 6| Step: 3
Training loss: 0.06483084007231224
Validation loss: 2.457169641287379

Epoch: 6| Step: 4
Training loss: 0.07905637368678003
Validation loss: 2.464684353256328

Epoch: 6| Step: 5
Training loss: 0.06792722754606224
Validation loss: 2.436172033684468

Epoch: 6| Step: 6
Training loss: 0.12418621374874256
Validation loss: 2.445784678524376

Epoch: 6| Step: 7
Training loss: 0.06873213091458591
Validation loss: 2.440880487742804

Epoch: 6| Step: 8
Training loss: 0.12533398058853945
Validation loss: 2.4517911544374584

Epoch: 6| Step: 9
Training loss: 0.10115080157376971
Validation loss: 2.4048866124559427

Epoch: 6| Step: 10
Training loss: 0.07013937378640733
Validation loss: 2.4548007781900743

Epoch: 6| Step: 11
Training loss: 0.0758340816091904
Validation loss: 2.459391565521561

Epoch: 6| Step: 12
Training loss: 0.12504263985070932
Validation loss: 2.440388626753597

Epoch: 6| Step: 13
Training loss: 0.04573154798491807
Validation loss: 2.4285913231599143

Epoch: 553| Step: 0
Training loss: 0.07150306978338196
Validation loss: 2.401202340720675

Epoch: 6| Step: 1
Training loss: 0.10453461293796733
Validation loss: 2.4229768636820794

Epoch: 6| Step: 2
Training loss: 0.08490600673688425
Validation loss: 2.405586698341203

Epoch: 6| Step: 3
Training loss: 0.12242507881081584
Validation loss: 2.4053884571844084

Epoch: 6| Step: 4
Training loss: 0.08737752871169555
Validation loss: 2.3825875253915876

Epoch: 6| Step: 5
Training loss: 0.09149961838095458
Validation loss: 2.3978903657006043

Epoch: 6| Step: 6
Training loss: 0.07852541117625779
Validation loss: 2.379300360036202

Epoch: 6| Step: 7
Training loss: 0.09538762481526569
Validation loss: 2.3857633015802255

Epoch: 6| Step: 8
Training loss: 0.10004254196175454
Validation loss: 2.4650880693714536

Epoch: 6| Step: 9
Training loss: 0.09776595629220915
Validation loss: 2.46225241517944

Epoch: 6| Step: 10
Training loss: 0.08521795312182256
Validation loss: 2.420625934171245

Epoch: 6| Step: 11
Training loss: 0.05974033200732447
Validation loss: 2.441587878618526

Epoch: 6| Step: 12
Training loss: 0.12952871742349584
Validation loss: 2.420114788026182

Epoch: 6| Step: 13
Training loss: 0.06262531978512206
Validation loss: 2.426917729613856

Epoch: 554| Step: 0
Training loss: 0.0770792983288856
Validation loss: 2.4451936508599696

Epoch: 6| Step: 1
Training loss: 0.0812139526282704
Validation loss: 2.45836101458694

Epoch: 6| Step: 2
Training loss: 0.14683519316025667
Validation loss: 2.4437445256205703

Epoch: 6| Step: 3
Training loss: 0.06002553557239819
Validation loss: 2.4245038285989304

Epoch: 6| Step: 4
Training loss: 0.09751844696994605
Validation loss: 2.4491879647920247

Epoch: 6| Step: 5
Training loss: 0.07902509914335104
Validation loss: 2.4186279547594483

Epoch: 6| Step: 6
Training loss: 0.08699457318615153
Validation loss: 2.418049984650348

Epoch: 6| Step: 7
Training loss: 0.059350118788242374
Validation loss: 2.4273361974973273

Epoch: 6| Step: 8
Training loss: 0.11532763166700673
Validation loss: 2.454017292428758

Epoch: 6| Step: 9
Training loss: 0.1425181876881564
Validation loss: 2.448150820628845

Epoch: 6| Step: 10
Training loss: 0.0786071769050286
Validation loss: 2.4380273429954276

Epoch: 6| Step: 11
Training loss: 0.05616440850720525
Validation loss: 2.4213678687103997

Epoch: 6| Step: 12
Training loss: 0.10433376638480787
Validation loss: 2.405970592494932

Epoch: 6| Step: 13
Training loss: 0.11661860742379833
Validation loss: 2.3792188561497447

Epoch: 555| Step: 0
Training loss: 0.06482404127840884
Validation loss: 2.376786752120739

Epoch: 6| Step: 1
Training loss: 0.08978571261154113
Validation loss: 2.391420607722006

Epoch: 6| Step: 2
Training loss: 0.07408399331903696
Validation loss: 2.394967932361296

Epoch: 6| Step: 3
Training loss: 0.08365967826833179
Validation loss: 2.437149531703072

Epoch: 6| Step: 4
Training loss: 0.08263315188599771
Validation loss: 2.4156943112945424

Epoch: 6| Step: 5
Training loss: 0.12146021780629049
Validation loss: 2.414022032568497

Epoch: 6| Step: 6
Training loss: 0.17993472548264022
Validation loss: 2.428732953133711

Epoch: 6| Step: 7
Training loss: 0.055048686472798654
Validation loss: 2.430734579248582

Epoch: 6| Step: 8
Training loss: 0.07618292398280105
Validation loss: 2.465934120523858

Epoch: 6| Step: 9
Training loss: 0.08373529347337588
Validation loss: 2.4553176802559116

Epoch: 6| Step: 10
Training loss: 0.05639044617864742
Validation loss: 2.4395633385813382

Epoch: 6| Step: 11
Training loss: 0.12889789785434821
Validation loss: 2.4340577305513937

Epoch: 6| Step: 12
Training loss: 0.0831130370606087
Validation loss: 2.419895390109197

Epoch: 6| Step: 13
Training loss: 0.08222000510465906
Validation loss: 2.443003442604004

Epoch: 556| Step: 0
Training loss: 0.0945629939462225
Validation loss: 2.420556254064968

Epoch: 6| Step: 1
Training loss: 0.08910248594963648
Validation loss: 2.4611520710455044

Epoch: 6| Step: 2
Training loss: 0.11582598519545403
Validation loss: 2.452513789551001

Epoch: 6| Step: 3
Training loss: 0.06086377879297399
Validation loss: 2.4391144169798205

Epoch: 6| Step: 4
Training loss: 0.1200365788494249
Validation loss: 2.449340595377523

Epoch: 6| Step: 5
Training loss: 0.08919375017583266
Validation loss: 2.4521158950281223

Epoch: 6| Step: 6
Training loss: 0.08505977713005876
Validation loss: 2.482084556203232

Epoch: 6| Step: 7
Training loss: 0.07875332885851431
Validation loss: 2.451531208015114

Epoch: 6| Step: 8
Training loss: 0.07409159534487776
Validation loss: 2.494672748328621

Epoch: 6| Step: 9
Training loss: 0.06568193917369829
Validation loss: 2.4578035999467054

Epoch: 6| Step: 10
Training loss: 0.061155958790687616
Validation loss: 2.4663644393963087

Epoch: 6| Step: 11
Training loss: 0.06194753967726315
Validation loss: 2.4803441061649334

Epoch: 6| Step: 12
Training loss: 0.07178026958912048
Validation loss: 2.447244054739533

Epoch: 6| Step: 13
Training loss: 0.05334076768514215
Validation loss: 2.4457629657505033

Epoch: 557| Step: 0
Training loss: 0.12049387970296141
Validation loss: 2.394748285190377

Epoch: 6| Step: 1
Training loss: 0.09522107910866978
Validation loss: 2.4164384379483526

Epoch: 6| Step: 2
Training loss: 0.10634509014329968
Validation loss: 2.4290798326732763

Epoch: 6| Step: 3
Training loss: 0.054385933290681365
Validation loss: 2.4182039837223015

Epoch: 6| Step: 4
Training loss: 0.05482127228264056
Validation loss: 2.413358563486336

Epoch: 6| Step: 5
Training loss: 0.07917383800931599
Validation loss: 2.4140921094197396

Epoch: 6| Step: 6
Training loss: 0.07388478355485145
Validation loss: 2.392194318225475

Epoch: 6| Step: 7
Training loss: 0.060689991575975676
Validation loss: 2.4077913067430994

Epoch: 6| Step: 8
Training loss: 0.059018562053680904
Validation loss: 2.4177255996116047

Epoch: 6| Step: 9
Training loss: 0.11516962010007363
Validation loss: 2.417278518563015

Epoch: 6| Step: 10
Training loss: 0.09193579328121086
Validation loss: 2.426183719123899

Epoch: 6| Step: 11
Training loss: 0.08453529439019136
Validation loss: 2.452468848065991

Epoch: 6| Step: 12
Training loss: 0.05940807638415989
Validation loss: 2.4430899918913522

Epoch: 6| Step: 13
Training loss: 0.07898550585532438
Validation loss: 2.440110406685851

Epoch: 558| Step: 0
Training loss: 0.087228695761787
Validation loss: 2.4441091179139334

Epoch: 6| Step: 1
Training loss: 0.1296260992875384
Validation loss: 2.468350839387927

Epoch: 6| Step: 2
Training loss: 0.07541779327549987
Validation loss: 2.4592333217392226

Epoch: 6| Step: 3
Training loss: 0.09131089375908928
Validation loss: 2.4434101696893387

Epoch: 6| Step: 4
Training loss: 0.051550607863233844
Validation loss: 2.4447071110119523

Epoch: 6| Step: 5
Training loss: 0.09536134746217312
Validation loss: 2.4667550138154803

Epoch: 6| Step: 6
Training loss: 0.13847962337064873
Validation loss: 2.4435574701009686

Epoch: 6| Step: 7
Training loss: 0.10441149956425869
Validation loss: 2.421818407914534

Epoch: 6| Step: 8
Training loss: 0.06021309379252083
Validation loss: 2.40518280088082

Epoch: 6| Step: 9
Training loss: 0.05384759424210867
Validation loss: 2.420521811491501

Epoch: 6| Step: 10
Training loss: 0.09061970140324872
Validation loss: 2.4577890867443

Epoch: 6| Step: 11
Training loss: 0.04991537304744613
Validation loss: 2.408252787908163

Epoch: 6| Step: 12
Training loss: 0.04795169085871681
Validation loss: 2.4452975006414057

Epoch: 6| Step: 13
Training loss: 0.1601383327138063
Validation loss: 2.460914955745579

Epoch: 559| Step: 0
Training loss: 0.13151306599759074
Validation loss: 2.459531505277188

Epoch: 6| Step: 1
Training loss: 0.04227875359320489
Validation loss: 2.4808491386837024

Epoch: 6| Step: 2
Training loss: 0.07897657067674976
Validation loss: 2.4551270174841924

Epoch: 6| Step: 3
Training loss: 0.04021683630099126
Validation loss: 2.438794878827301

Epoch: 6| Step: 4
Training loss: 0.07327094467190058
Validation loss: 2.468360036214883

Epoch: 6| Step: 5
Training loss: 0.11825531202708105
Validation loss: 2.4525188715884596

Epoch: 6| Step: 6
Training loss: 0.07278373286081219
Validation loss: 2.4379081857586105

Epoch: 6| Step: 7
Training loss: 0.07050532484553348
Validation loss: 2.4436737158949122

Epoch: 6| Step: 8
Training loss: 0.0442657391805553
Validation loss: 2.4463642369084275

Epoch: 6| Step: 9
Training loss: 0.09536263659820345
Validation loss: 2.4581849110930327

Epoch: 6| Step: 10
Training loss: 0.05176283254210295
Validation loss: 2.444947120920418

Epoch: 6| Step: 11
Training loss: 0.1282635184240622
Validation loss: 2.4361319351006276

Epoch: 6| Step: 12
Training loss: 0.10627909903493434
Validation loss: 2.4189115062043385

Epoch: 6| Step: 13
Training loss: 0.08166016363122447
Validation loss: 2.415209144681191

Epoch: 560| Step: 0
Training loss: 0.12225184865735628
Validation loss: 2.4005604159939655

Epoch: 6| Step: 1
Training loss: 0.05231898561788485
Validation loss: 2.407528747762467

Epoch: 6| Step: 2
Training loss: 0.0809995337207201
Validation loss: 2.398453101314195

Epoch: 6| Step: 3
Training loss: 0.09879461557174797
Validation loss: 2.4277187548832915

Epoch: 6| Step: 4
Training loss: 0.07106611584595826
Validation loss: 2.4051695721850987

Epoch: 6| Step: 5
Training loss: 0.08415410168537237
Validation loss: 2.4059938780037804

Epoch: 6| Step: 6
Training loss: 0.10527659944021579
Validation loss: 2.457965793808057

Epoch: 6| Step: 7
Training loss: 0.08179720061946937
Validation loss: 2.417483725949803

Epoch: 6| Step: 8
Training loss: 0.10120916342201842
Validation loss: 2.4133112342050604

Epoch: 6| Step: 9
Training loss: 0.0582762140880119
Validation loss: 2.3964419665011114

Epoch: 6| Step: 10
Training loss: 0.08177299377701504
Validation loss: 2.3772057748261792

Epoch: 6| Step: 11
Training loss: 0.10651206626951515
Validation loss: 2.381789906741497

Epoch: 6| Step: 12
Training loss: 0.11158229440570917
Validation loss: 2.4256138210672797

Epoch: 6| Step: 13
Training loss: 0.08382592668521686
Validation loss: 2.4213002613557086

Epoch: 561| Step: 0
Training loss: 0.09209409240759968
Validation loss: 2.413665292251594

Epoch: 6| Step: 1
Training loss: 0.06810465426295742
Validation loss: 2.422760122183601

Epoch: 6| Step: 2
Training loss: 0.03391576265734468
Validation loss: 2.4492621454849983

Epoch: 6| Step: 3
Training loss: 0.09048089314037489
Validation loss: 2.46656816716016

Epoch: 6| Step: 4
Training loss: 0.09904824008353
Validation loss: 2.487684700755585

Epoch: 6| Step: 5
Training loss: 0.11668431015231477
Validation loss: 2.461101921697284

Epoch: 6| Step: 6
Training loss: 0.06440506935379393
Validation loss: 2.4550372288439575

Epoch: 6| Step: 7
Training loss: 0.08217899890454865
Validation loss: 2.4452990292026042

Epoch: 6| Step: 8
Training loss: 0.06228212662604828
Validation loss: 2.411894693660967

Epoch: 6| Step: 9
Training loss: 0.06273865954137386
Validation loss: 2.4240621132707902

Epoch: 6| Step: 10
Training loss: 0.1252917074852105
Validation loss: 2.4118982251956553

Epoch: 6| Step: 11
Training loss: 0.11861652257401674
Validation loss: 2.409193014952699

Epoch: 6| Step: 12
Training loss: 0.11270124661112411
Validation loss: 2.410350191907071

Epoch: 6| Step: 13
Training loss: 0.06405044244480158
Validation loss: 2.429126607364458

Epoch: 562| Step: 0
Training loss: 0.07140533554151035
Validation loss: 2.446027306669581

Epoch: 6| Step: 1
Training loss: 0.059712997340602106
Validation loss: 2.427904008148531

Epoch: 6| Step: 2
Training loss: 0.06494775898773297
Validation loss: 2.435141339092691

Epoch: 6| Step: 3
Training loss: 0.06120695350087444
Validation loss: 2.433320393505436

Epoch: 6| Step: 4
Training loss: 0.06538239235822199
Validation loss: 2.452768831227406

Epoch: 6| Step: 5
Training loss: 0.11999812466800132
Validation loss: 2.4623405752654537

Epoch: 6| Step: 6
Training loss: 0.06299086129279105
Validation loss: 2.4726675282434813

Epoch: 6| Step: 7
Training loss: 0.12806919731902364
Validation loss: 2.470190120137468

Epoch: 6| Step: 8
Training loss: 0.05548000859456023
Validation loss: 2.4552520043745663

Epoch: 6| Step: 9
Training loss: 0.08726481587573601
Validation loss: 2.459812517757854

Epoch: 6| Step: 10
Training loss: 0.06701089317037813
Validation loss: 2.4895513804262737

Epoch: 6| Step: 11
Training loss: 0.04970920048385263
Validation loss: 2.493515426710443

Epoch: 6| Step: 12
Training loss: 0.09021589700992882
Validation loss: 2.468685875180938

Epoch: 6| Step: 13
Training loss: 0.1475020029348224
Validation loss: 2.4679736475248695

Epoch: 563| Step: 0
Training loss: 0.06534422089312639
Validation loss: 2.4802342214921236

Epoch: 6| Step: 1
Training loss: 0.06490898757252556
Validation loss: 2.451023289124731

Epoch: 6| Step: 2
Training loss: 0.07394871400122144
Validation loss: 2.4557304980412806

Epoch: 6| Step: 3
Training loss: 0.08210187948098403
Validation loss: 2.4555595737043854

Epoch: 6| Step: 4
Training loss: 0.09337241408937008
Validation loss: 2.457163645258265

Epoch: 6| Step: 5
Training loss: 0.12186657497433771
Validation loss: 2.44431778989684

Epoch: 6| Step: 6
Training loss: 0.07086464862272825
Validation loss: 2.432723099289236

Epoch: 6| Step: 7
Training loss: 0.07692305926376608
Validation loss: 2.4808606075390154

Epoch: 6| Step: 8
Training loss: 0.05205766397958167
Validation loss: 2.487219225320841

Epoch: 6| Step: 9
Training loss: 0.07775135094536105
Validation loss: 2.4777921542618118

Epoch: 6| Step: 10
Training loss: 0.13054620933248856
Validation loss: 2.4858984810923337

Epoch: 6| Step: 11
Training loss: 0.11490768660761773
Validation loss: 2.447955948918757

Epoch: 6| Step: 12
Training loss: 0.07295102419782985
Validation loss: 2.424114020877358

Epoch: 6| Step: 13
Training loss: 0.08636419612857689
Validation loss: 2.4123526977339877

Epoch: 564| Step: 0
Training loss: 0.06446051555223133
Validation loss: 2.446098595740093

Epoch: 6| Step: 1
Training loss: 0.07128510398848198
Validation loss: 2.4317493319371564

Epoch: 6| Step: 2
Training loss: 0.12358366726186905
Validation loss: 2.4163199215944924

Epoch: 6| Step: 3
Training loss: 0.07314191311885848
Validation loss: 2.401179319968353

Epoch: 6| Step: 4
Training loss: 0.073281363500373
Validation loss: 2.388430388119722

Epoch: 6| Step: 5
Training loss: 0.061673741437553456
Validation loss: 2.4387249872514127

Epoch: 6| Step: 6
Training loss: 0.06363721471678345
Validation loss: 2.438525846719054

Epoch: 6| Step: 7
Training loss: 0.05276497421125956
Validation loss: 2.447513565110854

Epoch: 6| Step: 8
Training loss: 0.055469618793856396
Validation loss: 2.4306067932947424

Epoch: 6| Step: 9
Training loss: 0.10048948682056304
Validation loss: 2.4294865323340766

Epoch: 6| Step: 10
Training loss: 0.1210480111402297
Validation loss: 2.4366479693419096

Epoch: 6| Step: 11
Training loss: 0.0654366190640633
Validation loss: 2.462263998246558

Epoch: 6| Step: 12
Training loss: 0.12363333438323215
Validation loss: 2.4465087860066284

Epoch: 6| Step: 13
Training loss: 0.10931656332244957
Validation loss: 2.4207934337971744

Epoch: 565| Step: 0
Training loss: 0.0667863095722705
Validation loss: 2.4506308926347726

Epoch: 6| Step: 1
Training loss: 0.05824183442515982
Validation loss: 2.43024262268885

Epoch: 6| Step: 2
Training loss: 0.054691504008307475
Validation loss: 2.411445539680591

Epoch: 6| Step: 3
Training loss: 0.11078872846425665
Validation loss: 2.4119617690837925

Epoch: 6| Step: 4
Training loss: 0.1343806476293339
Validation loss: 2.4422715053591877

Epoch: 6| Step: 5
Training loss: 0.05264855395087822
Validation loss: 2.4217261624259407

Epoch: 6| Step: 6
Training loss: 0.05383805923809161
Validation loss: 2.428743071581649

Epoch: 6| Step: 7
Training loss: 0.06399744964524907
Validation loss: 2.3970511517129007

Epoch: 6| Step: 8
Training loss: 0.07087885728121149
Validation loss: 2.4292698534749078

Epoch: 6| Step: 9
Training loss: 0.05735586599025224
Validation loss: 2.436283083359257

Epoch: 6| Step: 10
Training loss: 0.06895426348972301
Validation loss: 2.4289946544069987

Epoch: 6| Step: 11
Training loss: 0.12120101776863218
Validation loss: 2.465620087745124

Epoch: 6| Step: 12
Training loss: 0.06274180278059255
Validation loss: 2.466812910712885

Epoch: 6| Step: 13
Training loss: 0.12193892083422962
Validation loss: 2.446182185698099

Epoch: 566| Step: 0
Training loss: 0.03843394560099874
Validation loss: 2.456001857382725

Epoch: 6| Step: 1
Training loss: 0.08407067145724802
Validation loss: 2.4378137799348036

Epoch: 6| Step: 2
Training loss: 0.04805525904287509
Validation loss: 2.4329612609367883

Epoch: 6| Step: 3
Training loss: 0.06099464788870003
Validation loss: 2.462163978097395

Epoch: 6| Step: 4
Training loss: 0.0866125938046914
Validation loss: 2.4282769221369986

Epoch: 6| Step: 5
Training loss: 0.11775965095916703
Validation loss: 2.4358557831606236

Epoch: 6| Step: 6
Training loss: 0.1582217676457738
Validation loss: 2.4255386180204046

Epoch: 6| Step: 7
Training loss: 0.0480365001518081
Validation loss: 2.4339068517240943

Epoch: 6| Step: 8
Training loss: 0.10521460306335871
Validation loss: 2.435308994636032

Epoch: 6| Step: 9
Training loss: 0.0853005123449504
Validation loss: 2.4358129302984626

Epoch: 6| Step: 10
Training loss: 0.07033974397865872
Validation loss: 2.4586943988166743

Epoch: 6| Step: 11
Training loss: 0.06774883785737885
Validation loss: 2.4541538501083586

Epoch: 6| Step: 12
Training loss: 0.06340356076870264
Validation loss: 2.4274507896048583

Epoch: 6| Step: 13
Training loss: 0.07742069588002927
Validation loss: 2.443182720617843

Epoch: 567| Step: 0
Training loss: 0.09174502206864212
Validation loss: 2.4143163367906015

Epoch: 6| Step: 1
Training loss: 0.04189178751250546
Validation loss: 2.3974427269985688

Epoch: 6| Step: 2
Training loss: 0.060366049049467074
Validation loss: 2.420422951593284

Epoch: 6| Step: 3
Training loss: 0.10981291146084597
Validation loss: 2.3924502587571523

Epoch: 6| Step: 4
Training loss: 0.10609113758842811
Validation loss: 2.3908914740175824

Epoch: 6| Step: 5
Training loss: 0.049630754287042216
Validation loss: 2.35577165662722

Epoch: 6| Step: 6
Training loss: 0.057484927560235224
Validation loss: 2.394780905237821

Epoch: 6| Step: 7
Training loss: 0.06508612819955518
Validation loss: 2.416722890718238

Epoch: 6| Step: 8
Training loss: 0.08446468470010274
Validation loss: 2.4063323930671703

Epoch: 6| Step: 9
Training loss: 0.13089410121819423
Validation loss: 2.4235108433720467

Epoch: 6| Step: 10
Training loss: 0.14959408629662313
Validation loss: 2.4095898076929063

Epoch: 6| Step: 11
Training loss: 0.0627103298835502
Validation loss: 2.4163846631801262

Epoch: 6| Step: 12
Training loss: 0.0671673661382719
Validation loss: 2.4005777180680137

Epoch: 6| Step: 13
Training loss: 0.04832914021989235
Validation loss: 2.3953111565489165

Epoch: 568| Step: 0
Training loss: 0.06557720194878869
Validation loss: 2.40589835094886

Epoch: 6| Step: 1
Training loss: 0.11810003469061484
Validation loss: 2.402111575751607

Epoch: 6| Step: 2
Training loss: 0.12398131098143127
Validation loss: 2.388139624598915

Epoch: 6| Step: 3
Training loss: 0.07993283699086423
Validation loss: 2.400706263078802

Epoch: 6| Step: 4
Training loss: 0.056462459863555976
Validation loss: 2.412749054252574

Epoch: 6| Step: 5
Training loss: 0.0690009257549918
Validation loss: 2.4292439126816965

Epoch: 6| Step: 6
Training loss: 0.059800442202962024
Validation loss: 2.4106280330999916

Epoch: 6| Step: 7
Training loss: 0.08203550736414972
Validation loss: 2.39405068468621

Epoch: 6| Step: 8
Training loss: 0.11840064034446889
Validation loss: 2.378652554288521

Epoch: 6| Step: 9
Training loss: 0.08316742193694374
Validation loss: 2.4274717605726024

Epoch: 6| Step: 10
Training loss: 0.10901166393081677
Validation loss: 2.424270170599297

Epoch: 6| Step: 11
Training loss: 0.052654256270015985
Validation loss: 2.4464978760094342

Epoch: 6| Step: 12
Training loss: 0.10966879690643976
Validation loss: 2.472557812664153

Epoch: 6| Step: 13
Training loss: 0.05291970896180892
Validation loss: 2.457924243752536

Epoch: 569| Step: 0
Training loss: 0.10829129379584869
Validation loss: 2.5086266309744705

Epoch: 6| Step: 1
Training loss: 0.058956501545324454
Validation loss: 2.46277065127525

Epoch: 6| Step: 2
Training loss: 0.0508082941374498
Validation loss: 2.4307287890631906

Epoch: 6| Step: 3
Training loss: 0.0788086778907374
Validation loss: 2.4634367825893992

Epoch: 6| Step: 4
Training loss: 0.10242247083739411
Validation loss: 2.4865093560349982

Epoch: 6| Step: 5
Training loss: 0.11701376275022118
Validation loss: 2.465429936270167

Epoch: 6| Step: 6
Training loss: 0.044761732487269036
Validation loss: 2.445659656971941

Epoch: 6| Step: 7
Training loss: 0.0947098864791491
Validation loss: 2.4617660130469985

Epoch: 6| Step: 8
Training loss: 0.09092883322732599
Validation loss: 2.4382395173360583

Epoch: 6| Step: 9
Training loss: 0.09116808642350334
Validation loss: 2.427951742063281

Epoch: 6| Step: 10
Training loss: 0.09941894429329892
Validation loss: 2.468366973019682

Epoch: 6| Step: 11
Training loss: 0.07072532842603002
Validation loss: 2.43906843083761

Epoch: 6| Step: 12
Training loss: 0.08342450123250729
Validation loss: 2.4406679505723594

Epoch: 6| Step: 13
Training loss: 0.05922325846839718
Validation loss: 2.4345094011008683

Epoch: 570| Step: 0
Training loss: 0.08718544670476432
Validation loss: 2.4689472873042226

Epoch: 6| Step: 1
Training loss: 0.12845014306883085
Validation loss: 2.4582847161453896

Epoch: 6| Step: 2
Training loss: 0.09066518229820657
Validation loss: 2.4497270179220054

Epoch: 6| Step: 3
Training loss: 0.09148866573341065
Validation loss: 2.4219940251567094

Epoch: 6| Step: 4
Training loss: 0.06899206761771029
Validation loss: 2.4142060208477045

Epoch: 6| Step: 5
Training loss: 0.06075949598604048
Validation loss: 2.4209721105172872

Epoch: 6| Step: 6
Training loss: 0.11756606150996536
Validation loss: 2.4230573009108296

Epoch: 6| Step: 7
Training loss: 0.060635271455802456
Validation loss: 2.4037586937100412

Epoch: 6| Step: 8
Training loss: 0.13313847396387965
Validation loss: 2.4326229689751475

Epoch: 6| Step: 9
Training loss: 0.10554723997921245
Validation loss: 2.399142603489724

Epoch: 6| Step: 10
Training loss: 0.08131769322268724
Validation loss: 2.412887316402057

Epoch: 6| Step: 11
Training loss: 0.08499582166429659
Validation loss: 2.3753020882961233

Epoch: 6| Step: 12
Training loss: 0.09862238762783734
Validation loss: 2.4106639537992485

Epoch: 6| Step: 13
Training loss: 0.08370941084174116
Validation loss: 2.400029137884857

Epoch: 571| Step: 0
Training loss: 0.05269204975473054
Validation loss: 2.4160743892124286

Epoch: 6| Step: 1
Training loss: 0.04890928675665709
Validation loss: 2.426953768362553

Epoch: 6| Step: 2
Training loss: 0.09789166685129916
Validation loss: 2.4270109563439486

Epoch: 6| Step: 3
Training loss: 0.08886812020954667
Validation loss: 2.4475933279443525

Epoch: 6| Step: 4
Training loss: 0.11864782254117522
Validation loss: 2.446020397693998

Epoch: 6| Step: 5
Training loss: 0.05293548172207561
Validation loss: 2.411952378466828

Epoch: 6| Step: 6
Training loss: 0.06187733032914963
Validation loss: 2.4125954157443044

Epoch: 6| Step: 7
Training loss: 0.054541593290734484
Validation loss: 2.4299896947057396

Epoch: 6| Step: 8
Training loss: 0.037807027163576375
Validation loss: 2.4331571923865485

Epoch: 6| Step: 9
Training loss: 0.07598518455045877
Validation loss: 2.4264231856200538

Epoch: 6| Step: 10
Training loss: 0.048380940240169715
Validation loss: 2.4308787345983736

Epoch: 6| Step: 11
Training loss: 0.12844122469390254
Validation loss: 2.4526959962401715

Epoch: 6| Step: 12
Training loss: 0.07180695020468073
Validation loss: 2.4378222822242583

Epoch: 6| Step: 13
Training loss: 0.11471914827225191
Validation loss: 2.428081770433814

Epoch: 572| Step: 0
Training loss: 0.05934794932840223
Validation loss: 2.436924617474614

Epoch: 6| Step: 1
Training loss: 0.07767019809554164
Validation loss: 2.4563872972508216

Epoch: 6| Step: 2
Training loss: 0.06317249978969196
Validation loss: 2.455299755822024

Epoch: 6| Step: 3
Training loss: 0.0853492151631572
Validation loss: 2.461967781536034

Epoch: 6| Step: 4
Training loss: 0.10323461591427745
Validation loss: 2.4161009918545613

Epoch: 6| Step: 5
Training loss: 0.07295251785233198
Validation loss: 2.4488230490592358

Epoch: 6| Step: 6
Training loss: 0.11367384525439928
Validation loss: 2.4606823173137897

Epoch: 6| Step: 7
Training loss: 0.12623213932018537
Validation loss: 2.420400575453454

Epoch: 6| Step: 8
Training loss: 0.07673442790123404
Validation loss: 2.4416122550435606

Epoch: 6| Step: 9
Training loss: 0.062324792434313846
Validation loss: 2.447153505968526

Epoch: 6| Step: 10
Training loss: 0.06507473717557485
Validation loss: 2.435253196358652

Epoch: 6| Step: 11
Training loss: 0.05601420203201148
Validation loss: 2.4260687987647764

Epoch: 6| Step: 12
Training loss: 0.06970083566154263
Validation loss: 2.4531063604002683

Epoch: 6| Step: 13
Training loss: 0.06995860751929768
Validation loss: 2.4215944115051866

Epoch: 573| Step: 0
Training loss: 0.0659398431158246
Validation loss: 2.4275158574161613

Epoch: 6| Step: 1
Training loss: 0.04651693838416127
Validation loss: 2.377551913604015

Epoch: 6| Step: 2
Training loss: 0.06198744035775842
Validation loss: 2.3966510876952163

Epoch: 6| Step: 3
Training loss: 0.050145627825143806
Validation loss: 2.4207303997362004

Epoch: 6| Step: 4
Training loss: 0.09407402211175728
Validation loss: 2.4371703645182614

Epoch: 6| Step: 5
Training loss: 0.05800330372508405
Validation loss: 2.41799570553291

Epoch: 6| Step: 6
Training loss: 0.1129030210955556
Validation loss: 2.405129751357304

Epoch: 6| Step: 7
Training loss: 0.06543284024286437
Validation loss: 2.398354979480979

Epoch: 6| Step: 8
Training loss: 0.05738551836210498
Validation loss: 2.4199356231925284

Epoch: 6| Step: 9
Training loss: 0.1291606084174527
Validation loss: 2.4559727788046404

Epoch: 6| Step: 10
Training loss: 0.05602381966183517
Validation loss: 2.4776151736124294

Epoch: 6| Step: 11
Training loss: 0.08840634252085586
Validation loss: 2.475467254278467

Epoch: 6| Step: 12
Training loss: 0.07285548805521676
Validation loss: 2.465288170432447

Epoch: 6| Step: 13
Training loss: 0.06029597333311513
Validation loss: 2.490879337467253

Epoch: 574| Step: 0
Training loss: 0.05563026372510771
Validation loss: 2.4431116922188334

Epoch: 6| Step: 1
Training loss: 0.061142002045726764
Validation loss: 2.4297087333803096

Epoch: 6| Step: 2
Training loss: 0.11237036401714139
Validation loss: 2.4182849200014305

Epoch: 6| Step: 3
Training loss: 0.14039565298664453
Validation loss: 2.4055909542218283

Epoch: 6| Step: 4
Training loss: 0.13353351216505807
Validation loss: 2.399935479924777

Epoch: 6| Step: 5
Training loss: 0.06704758100042368
Validation loss: 2.403524367181827

Epoch: 6| Step: 6
Training loss: 0.10967466481692136
Validation loss: 2.4114041762320486

Epoch: 6| Step: 7
Training loss: 0.07559127098803212
Validation loss: 2.4400010383902306

Epoch: 6| Step: 8
Training loss: 0.058093927343137855
Validation loss: 2.471850548811987

Epoch: 6| Step: 9
Training loss: 0.07727381622318835
Validation loss: 2.4576779317976754

Epoch: 6| Step: 10
Training loss: 0.07391513347162326
Validation loss: 2.4950627868500095

Epoch: 6| Step: 11
Training loss: 0.10639630510683612
Validation loss: 2.47034808754073

Epoch: 6| Step: 12
Training loss: 0.08399233669423523
Validation loss: 2.452147967039738

Epoch: 6| Step: 13
Training loss: 0.05892300681744578
Validation loss: 2.463647640630037

Epoch: 575| Step: 0
Training loss: 0.07832233421589227
Validation loss: 2.4319668355942854

Epoch: 6| Step: 1
Training loss: 0.06072523203932963
Validation loss: 2.42139277213953

Epoch: 6| Step: 2
Training loss: 0.1078649184396617
Validation loss: 2.413535241355467

Epoch: 6| Step: 3
Training loss: 0.0588015250053344
Validation loss: 2.4114840246186717

Epoch: 6| Step: 4
Training loss: 0.05336711247980147
Validation loss: 2.424168038211657

Epoch: 6| Step: 5
Training loss: 0.050269871565256516
Validation loss: 2.4556803465471266

Epoch: 6| Step: 6
Training loss: 0.13671755108988837
Validation loss: 2.4459013327087336

Epoch: 6| Step: 7
Training loss: 0.11632469764000371
Validation loss: 2.4474384693441182

Epoch: 6| Step: 8
Training loss: 0.08022580543504106
Validation loss: 2.415398321813581

Epoch: 6| Step: 9
Training loss: 0.09283895688635098
Validation loss: 2.4200380544349347

Epoch: 6| Step: 10
Training loss: 0.06810219615997262
Validation loss: 2.435876960667511

Epoch: 6| Step: 11
Training loss: 0.06407867378664017
Validation loss: 2.4440147814241664

Epoch: 6| Step: 12
Training loss: 0.04301070744076727
Validation loss: 2.461913950818415

Epoch: 6| Step: 13
Training loss: 0.058118436071642514
Validation loss: 2.4686629245075453

Epoch: 576| Step: 0
Training loss: 0.09017021015747557
Validation loss: 2.451518912286597

Epoch: 6| Step: 1
Training loss: 0.05903511904059869
Validation loss: 2.432181863866022

Epoch: 6| Step: 2
Training loss: 0.07469526522363308
Validation loss: 2.394344899715591

Epoch: 6| Step: 3
Training loss: 0.06165599544939528
Validation loss: 2.4028670757337514

Epoch: 6| Step: 4
Training loss: 0.11171051491883469
Validation loss: 2.3669946159362105

Epoch: 6| Step: 5
Training loss: 0.08164718957454141
Validation loss: 2.4011790092795735

Epoch: 6| Step: 6
Training loss: 0.12161242246920388
Validation loss: 2.4190229100347733

Epoch: 6| Step: 7
Training loss: 0.06645297412218357
Validation loss: 2.436527281079631

Epoch: 6| Step: 8
Training loss: 0.04895604781174568
Validation loss: 2.4312563311850313

Epoch: 6| Step: 9
Training loss: 0.09425968460772259
Validation loss: 2.457557511134121

Epoch: 6| Step: 10
Training loss: 0.07389220756575177
Validation loss: 2.4440090145720017

Epoch: 6| Step: 11
Training loss: 0.08509481230495418
Validation loss: 2.4661164677297442

Epoch: 6| Step: 12
Training loss: 0.11436232245777854
Validation loss: 2.464105451336201

Epoch: 6| Step: 13
Training loss: 0.07437752066776591
Validation loss: 2.455621162499477

Epoch: 577| Step: 0
Training loss: 0.05924021219363361
Validation loss: 2.432470748037995

Epoch: 6| Step: 1
Training loss: 0.05912016591559191
Validation loss: 2.4635591339620824

Epoch: 6| Step: 2
Training loss: 0.07233359388120116
Validation loss: 2.42624715831229

Epoch: 6| Step: 3
Training loss: 0.1058250079375304
Validation loss: 2.429696602077744

Epoch: 6| Step: 4
Training loss: 0.06711181103300674
Validation loss: 2.470594660638104

Epoch: 6| Step: 5
Training loss: 0.10148179075197218
Validation loss: 2.4558656263743175

Epoch: 6| Step: 6
Training loss: 0.0608103771094015
Validation loss: 2.446259678257313

Epoch: 6| Step: 7
Training loss: 0.06567081458683019
Validation loss: 2.4827106845130515

Epoch: 6| Step: 8
Training loss: 0.1177220273456609
Validation loss: 2.479663182504508

Epoch: 6| Step: 9
Training loss: 0.09638536813672832
Validation loss: 2.4675770905996415

Epoch: 6| Step: 10
Training loss: 0.07414918701368621
Validation loss: 2.4902350328361322

Epoch: 6| Step: 11
Training loss: 0.07909773888000335
Validation loss: 2.45750292008207

Epoch: 6| Step: 12
Training loss: 0.06372633722762837
Validation loss: 2.450563055351689

Epoch: 6| Step: 13
Training loss: 0.04687358933551392
Validation loss: 2.4097021616532115

Epoch: 578| Step: 0
Training loss: 0.0789264400542474
Validation loss: 2.414446615840212

Epoch: 6| Step: 1
Training loss: 0.05330639559740105
Validation loss: 2.4472294569152027

Epoch: 6| Step: 2
Training loss: 0.0794442723649076
Validation loss: 2.463854271806014

Epoch: 6| Step: 3
Training loss: 0.10224929921136236
Validation loss: 2.4586008419787517

Epoch: 6| Step: 4
Training loss: 0.0665678099576097
Validation loss: 2.4441161162045195

Epoch: 6| Step: 5
Training loss: 0.04854015788934935
Validation loss: 2.4708752615423926

Epoch: 6| Step: 6
Training loss: 0.07200468481654175
Validation loss: 2.4877936483566994

Epoch: 6| Step: 7
Training loss: 0.0922895309380165
Validation loss: 2.4683969718275645

Epoch: 6| Step: 8
Training loss: 0.09675110962758775
Validation loss: 2.4493312528222257

Epoch: 6| Step: 9
Training loss: 0.08912710807816415
Validation loss: 2.446805526293402

Epoch: 6| Step: 10
Training loss: 0.09007688005353001
Validation loss: 2.4347746584588656

Epoch: 6| Step: 11
Training loss: 0.12728522951183402
Validation loss: 2.429544502742743

Epoch: 6| Step: 12
Training loss: 0.10559757630007885
Validation loss: 2.445132067558739

Epoch: 6| Step: 13
Training loss: 0.13889427886544298
Validation loss: 2.424913306547777

Epoch: 579| Step: 0
Training loss: 0.08186795523325649
Validation loss: 2.43399845573526

Epoch: 6| Step: 1
Training loss: 0.06517734547430698
Validation loss: 2.4708396289280894

Epoch: 6| Step: 2
Training loss: 0.09423795018113246
Validation loss: 2.444999545059751

Epoch: 6| Step: 3
Training loss: 0.08439223369568802
Validation loss: 2.4617212430752256

Epoch: 6| Step: 4
Training loss: 0.0601832174568052
Validation loss: 2.4488043591787934

Epoch: 6| Step: 5
Training loss: 0.04212796637733942
Validation loss: 2.441447211727946

Epoch: 6| Step: 6
Training loss: 0.1329674097838587
Validation loss: 2.4499445275879914

Epoch: 6| Step: 7
Training loss: 0.09394599375011854
Validation loss: 2.397074659156548

Epoch: 6| Step: 8
Training loss: 0.05468794277556873
Validation loss: 2.4112042842713426

Epoch: 6| Step: 9
Training loss: 0.08082983126849771
Validation loss: 2.416705105411855

Epoch: 6| Step: 10
Training loss: 0.10465517434609352
Validation loss: 2.401237436213335

Epoch: 6| Step: 11
Training loss: 0.12211725095486489
Validation loss: 2.4089946555310244

Epoch: 6| Step: 12
Training loss: 0.06002624927837908
Validation loss: 2.4006670740895544

Epoch: 6| Step: 13
Training loss: 0.07734805851312493
Validation loss: 2.411051125754747

Epoch: 580| Step: 0
Training loss: 0.0643663544775148
Validation loss: 2.38882885403026

Epoch: 6| Step: 1
Training loss: 0.06715558272576537
Validation loss: 2.382397196657265

Epoch: 6| Step: 2
Training loss: 0.09656151861321703
Validation loss: 2.4062611079295886

Epoch: 6| Step: 3
Training loss: 0.06275424801650006
Validation loss: 2.412642249690669

Epoch: 6| Step: 4
Training loss: 0.14107461419354442
Validation loss: 2.4266097780884355

Epoch: 6| Step: 5
Training loss: 0.08481185812485867
Validation loss: 2.4483919012698174

Epoch: 6| Step: 6
Training loss: 0.0893614198964656
Validation loss: 2.4465783294805297

Epoch: 6| Step: 7
Training loss: 0.06312324052898582
Validation loss: 2.4450691754967413

Epoch: 6| Step: 8
Training loss: 0.09580074897477815
Validation loss: 2.4814210195040296

Epoch: 6| Step: 9
Training loss: 0.04335008008236869
Validation loss: 2.416792155208922

Epoch: 6| Step: 10
Training loss: 0.0925238967567802
Validation loss: 2.4176111631647648

Epoch: 6| Step: 11
Training loss: 0.06546377603532078
Validation loss: 2.446171016692906

Epoch: 6| Step: 12
Training loss: 0.0747569951794013
Validation loss: 2.4507659035980125

Epoch: 6| Step: 13
Training loss: 0.08719261409089897
Validation loss: 2.461018355929907

Epoch: 581| Step: 0
Training loss: 0.06502712300544358
Validation loss: 2.450759634570866

Epoch: 6| Step: 1
Training loss: 0.058014829047501756
Validation loss: 2.4442608867484044

Epoch: 6| Step: 2
Training loss: 0.06953808370505
Validation loss: 2.432082852851533

Epoch: 6| Step: 3
Training loss: 0.05418439396024003
Validation loss: 2.441608351219977

Epoch: 6| Step: 4
Training loss: 0.05347952190497468
Validation loss: 2.4354688197361294

Epoch: 6| Step: 5
Training loss: 0.06248948075760661
Validation loss: 2.447540544053426

Epoch: 6| Step: 6
Training loss: 0.05340671211486938
Validation loss: 2.4745111923902376

Epoch: 6| Step: 7
Training loss: 0.05381268703794262
Validation loss: 2.4666232502959655

Epoch: 6| Step: 8
Training loss: 0.11784546043218891
Validation loss: 2.4726469302212797

Epoch: 6| Step: 9
Training loss: 0.10903384442958669
Validation loss: 2.509683801163005

Epoch: 6| Step: 10
Training loss: 0.09078406564282233
Validation loss: 2.4752119833275326

Epoch: 6| Step: 11
Training loss: 0.03506383737118947
Validation loss: 2.456931977829642

Epoch: 6| Step: 12
Training loss: 0.13973943373233363
Validation loss: 2.45665252676246

Epoch: 6| Step: 13
Training loss: 0.09541737461799174
Validation loss: 2.451357734555258

Epoch: 582| Step: 0
Training loss: 0.09558323727353188
Validation loss: 2.446259388489761

Epoch: 6| Step: 1
Training loss: 0.107193995569504
Validation loss: 2.4353426622609824

Epoch: 6| Step: 2
Training loss: 0.06323105578622254
Validation loss: 2.4158844542935216

Epoch: 6| Step: 3
Training loss: 0.07345780424194634
Validation loss: 2.4149108791397262

Epoch: 6| Step: 4
Training loss: 0.06881420188439803
Validation loss: 2.409242068484271

Epoch: 6| Step: 5
Training loss: 0.09526507690895186
Validation loss: 2.4160089893853276

Epoch: 6| Step: 6
Training loss: 0.09282406880946491
Validation loss: 2.414072373563781

Epoch: 6| Step: 7
Training loss: 0.11150101571571969
Validation loss: 2.3935998215420184

Epoch: 6| Step: 8
Training loss: 0.07614241543877583
Validation loss: 2.3953808860632324

Epoch: 6| Step: 9
Training loss: 0.11109616558651823
Validation loss: 2.4288934721785242

Epoch: 6| Step: 10
Training loss: 0.12243367854547078
Validation loss: 2.4393602177151905

Epoch: 6| Step: 11
Training loss: 0.07253132445045177
Validation loss: 2.4592243326313543

Epoch: 6| Step: 12
Training loss: 0.07248023745212845
Validation loss: 2.442211445785944

Epoch: 6| Step: 13
Training loss: 0.06165660909274073
Validation loss: 2.4112321819397127

Epoch: 583| Step: 0
Training loss: 0.04843234834655055
Validation loss: 2.4304740336195354

Epoch: 6| Step: 1
Training loss: 0.08834355263659302
Validation loss: 2.424776050480016

Epoch: 6| Step: 2
Training loss: 0.1391363893257242
Validation loss: 2.3879788030788887

Epoch: 6| Step: 3
Training loss: 0.13077209180808058
Validation loss: 2.396220368470806

Epoch: 6| Step: 4
Training loss: 0.08338364061151496
Validation loss: 2.4358329388842384

Epoch: 6| Step: 5
Training loss: 0.08581362541982594
Validation loss: 2.4713033989505186

Epoch: 6| Step: 6
Training loss: 0.05903578358982431
Validation loss: 2.4837534488071253

Epoch: 6| Step: 7
Training loss: 0.07747995696633213
Validation loss: 2.514885604893345

Epoch: 6| Step: 8
Training loss: 0.10757464036859252
Validation loss: 2.5208653226195796

Epoch: 6| Step: 9
Training loss: 0.053793390881812356
Validation loss: 2.511137519339955

Epoch: 6| Step: 10
Training loss: 0.11730170645341469
Validation loss: 2.5135003948898356

Epoch: 6| Step: 11
Training loss: 0.09031321870953446
Validation loss: 2.490496373574538

Epoch: 6| Step: 12
Training loss: 0.06329087093002997
Validation loss: 2.5050512024126603

Epoch: 6| Step: 13
Training loss: 0.08992006854373033
Validation loss: 2.490022410943299

Epoch: 584| Step: 0
Training loss: 0.06798263002495772
Validation loss: 2.467389131597352

Epoch: 6| Step: 1
Training loss: 0.10988435331227822
Validation loss: 2.4719977708070338

Epoch: 6| Step: 2
Training loss: 0.054690226844515105
Validation loss: 2.4428163161692

Epoch: 6| Step: 3
Training loss: 0.06156228368014366
Validation loss: 2.4584470367694022

Epoch: 6| Step: 4
Training loss: 0.06573288683456943
Validation loss: 2.478586814851798

Epoch: 6| Step: 5
Training loss: 0.1235739982365461
Validation loss: 2.4512421835213383

Epoch: 6| Step: 6
Training loss: 0.06756093145507334
Validation loss: 2.490038753179455

Epoch: 6| Step: 7
Training loss: 0.0950267596891538
Validation loss: 2.4354507481659398

Epoch: 6| Step: 8
Training loss: 0.0749602886955089
Validation loss: 2.475455489619988

Epoch: 6| Step: 9
Training loss: 0.07867989768154633
Validation loss: 2.463619930672948

Epoch: 6| Step: 10
Training loss: 0.09010117905777537
Validation loss: 2.458768774407246

Epoch: 6| Step: 11
Training loss: 0.06407547984980762
Validation loss: 2.4821180624036936

Epoch: 6| Step: 12
Training loss: 0.14576542215397578
Validation loss: 2.500224302340561

Epoch: 6| Step: 13
Training loss: 0.07035314855212133
Validation loss: 2.503621591479613

Epoch: 585| Step: 0
Training loss: 0.057222387662808384
Validation loss: 2.4849085576348147

Epoch: 6| Step: 1
Training loss: 0.0986981505975828
Validation loss: 2.525385670574229

Epoch: 6| Step: 2
Training loss: 0.10582358663259704
Validation loss: 2.5374272358543046

Epoch: 6| Step: 3
Training loss: 0.07040450249351762
Validation loss: 2.531780650651491

Epoch: 6| Step: 4
Training loss: 0.08187931044894496
Validation loss: 2.5305862701020345

Epoch: 6| Step: 5
Training loss: 0.07530588838237326
Validation loss: 2.5052410222776915

Epoch: 6| Step: 6
Training loss: 0.07999150313017471
Validation loss: 2.46086651735014

Epoch: 6| Step: 7
Training loss: 0.04542132209583039
Validation loss: 2.448582302716305

Epoch: 6| Step: 8
Training loss: 0.06799901598089528
Validation loss: 2.407481246768036

Epoch: 6| Step: 9
Training loss: 0.15603178999761727
Validation loss: 2.441694079555347

Epoch: 6| Step: 10
Training loss: 0.07736618963956116
Validation loss: 2.4482930285287208

Epoch: 6| Step: 11
Training loss: 0.14643608568886757
Validation loss: 2.4272791539539367

Epoch: 6| Step: 12
Training loss: 0.07457492717174448
Validation loss: 2.4421092317885527

Epoch: 6| Step: 13
Training loss: 0.08348508394166289
Validation loss: 2.422927757835049

Epoch: 586| Step: 0
Training loss: 0.09712348092086677
Validation loss: 2.4135022194029196

Epoch: 6| Step: 1
Training loss: 0.07430672450918796
Validation loss: 2.4102980168695995

Epoch: 6| Step: 2
Training loss: 0.10317966085430583
Validation loss: 2.4173597541376175

Epoch: 6| Step: 3
Training loss: 0.07759409160093285
Validation loss: 2.4170021366011154

Epoch: 6| Step: 4
Training loss: 0.10556118499660669
Validation loss: 2.385571116693575

Epoch: 6| Step: 5
Training loss: 0.08123391799225892
Validation loss: 2.4315897895133767

Epoch: 6| Step: 6
Training loss: 0.07486620631824446
Validation loss: 2.418455666459058

Epoch: 6| Step: 7
Training loss: 0.052953956114875696
Validation loss: 2.4177904907043035

Epoch: 6| Step: 8
Training loss: 0.07971899401314482
Validation loss: 2.46140308263352

Epoch: 6| Step: 9
Training loss: 0.12140300699760627
Validation loss: 2.453095260804576

Epoch: 6| Step: 10
Training loss: 0.1041986495827429
Validation loss: 2.407606338442206

Epoch: 6| Step: 11
Training loss: 0.06958758665027709
Validation loss: 2.3828960584934133

Epoch: 6| Step: 12
Training loss: 0.11437499729010574
Validation loss: 2.393555408323258

Epoch: 6| Step: 13
Training loss: 0.081017896621294
Validation loss: 2.3938317155916087

Epoch: 587| Step: 0
Training loss: 0.10336210454852923
Validation loss: 2.3692417729665074

Epoch: 6| Step: 1
Training loss: 0.10235779498456989
Validation loss: 2.3960737909365304

Epoch: 6| Step: 2
Training loss: 0.11014793817802127
Validation loss: 2.4105524412345964

Epoch: 6| Step: 3
Training loss: 0.07459460007335389
Validation loss: 2.457712808099147

Epoch: 6| Step: 4
Training loss: 0.1061878327509857
Validation loss: 2.4610148589435044

Epoch: 6| Step: 5
Training loss: 0.08120296026704575
Validation loss: 2.4764633037213484

Epoch: 6| Step: 6
Training loss: 0.06668614905949985
Validation loss: 2.4736069213470335

Epoch: 6| Step: 7
Training loss: 0.06425670837334953
Validation loss: 2.451153385798756

Epoch: 6| Step: 8
Training loss: 0.0919133522794158
Validation loss: 2.455518448571445

Epoch: 6| Step: 9
Training loss: 0.06019280332500764
Validation loss: 2.448087658972241

Epoch: 6| Step: 10
Training loss: 0.12992377818279785
Validation loss: 2.4323610530975532

Epoch: 6| Step: 11
Training loss: 0.08390563223165629
Validation loss: 2.4647366337450918

Epoch: 6| Step: 12
Training loss: 0.06866422186878689
Validation loss: 2.4492268767027996

Epoch: 6| Step: 13
Training loss: 0.06568939350690194
Validation loss: 2.4351785215473125

Epoch: 588| Step: 0
Training loss: 0.12458463665417108
Validation loss: 2.4255042155457587

Epoch: 6| Step: 1
Training loss: 0.12117649143360491
Validation loss: 2.4578121087072446

Epoch: 6| Step: 2
Training loss: 0.09682433549348608
Validation loss: 2.454699074315078

Epoch: 6| Step: 3
Training loss: 0.0774273749023373
Validation loss: 2.414901963906463

Epoch: 6| Step: 4
Training loss: 0.1079122793411673
Validation loss: 2.4321188166453744

Epoch: 6| Step: 5
Training loss: 0.11720050898506922
Validation loss: 2.4432515833497086

Epoch: 6| Step: 6
Training loss: 0.04916363366232619
Validation loss: 2.3989557148180047

Epoch: 6| Step: 7
Training loss: 0.06475345043314885
Validation loss: 2.3857903018420283

Epoch: 6| Step: 8
Training loss: 0.06709388973357455
Validation loss: 2.369635291463569

Epoch: 6| Step: 9
Training loss: 0.16187160358584787
Validation loss: 2.3523049368628297

Epoch: 6| Step: 10
Training loss: 0.13711461929333954
Validation loss: 2.3729432120891953

Epoch: 6| Step: 11
Training loss: 0.06119988527919303
Validation loss: 2.367339596741802

Epoch: 6| Step: 12
Training loss: 0.07718079528183482
Validation loss: 2.4061752246989236

Epoch: 6| Step: 13
Training loss: 0.060650634688847356
Validation loss: 2.4307483453853407

Epoch: 589| Step: 0
Training loss: 0.10198189267433339
Validation loss: 2.475225368492276

Epoch: 6| Step: 1
Training loss: 0.15123262269118
Validation loss: 2.504748764661894

Epoch: 6| Step: 2
Training loss: 0.14670005179503762
Validation loss: 2.465103874406634

Epoch: 6| Step: 3
Training loss: 0.0939513666498162
Validation loss: 2.4918882355095358

Epoch: 6| Step: 4
Training loss: 0.11289018924589436
Validation loss: 2.4881135488635175

Epoch: 6| Step: 5
Training loss: 0.1044546041904616
Validation loss: 2.4969467119726834

Epoch: 6| Step: 6
Training loss: 0.05350739753435247
Validation loss: 2.488205244661742

Epoch: 6| Step: 7
Training loss: 0.10975298961529933
Validation loss: 2.486889125897241

Epoch: 6| Step: 8
Training loss: 0.10857352301670961
Validation loss: 2.4747228482381436

Epoch: 6| Step: 9
Training loss: 0.06901131785302175
Validation loss: 2.4687875225870384

Epoch: 6| Step: 10
Training loss: 0.08762670734812761
Validation loss: 2.4336563813626255

Epoch: 6| Step: 11
Training loss: 0.0987411319698282
Validation loss: 2.421417560439743

Epoch: 6| Step: 12
Training loss: 0.08657640596785358
Validation loss: 2.4417532543057288

Epoch: 6| Step: 13
Training loss: 0.06793230370347395
Validation loss: 2.4716145304067814

Epoch: 590| Step: 0
Training loss: 0.09792967189580232
Validation loss: 2.4918066302023543

Epoch: 6| Step: 1
Training loss: 0.09722318949199309
Validation loss: 2.495095383612029

Epoch: 6| Step: 2
Training loss: 0.11946515534186958
Validation loss: 2.487384449276483

Epoch: 6| Step: 3
Training loss: 0.071461501657176
Validation loss: 2.4654273912723954

Epoch: 6| Step: 4
Training loss: 0.10063162941744762
Validation loss: 2.4289194177698965

Epoch: 6| Step: 5
Training loss: 0.17918271188821872
Validation loss: 2.425021977817142

Epoch: 6| Step: 6
Training loss: 0.07374396105970571
Validation loss: 2.4359800460412817

Epoch: 6| Step: 7
Training loss: 0.12733588838005838
Validation loss: 2.4790359111693347

Epoch: 6| Step: 8
Training loss: 0.14967274556283622
Validation loss: 2.5186315165167126

Epoch: 6| Step: 9
Training loss: 0.1173009085260876
Validation loss: 2.4664288605174978

Epoch: 6| Step: 10
Training loss: 0.17938722523954045
Validation loss: 2.4452925322867123

Epoch: 6| Step: 11
Training loss: 0.16782364565848212
Validation loss: 2.4009916171175942

Epoch: 6| Step: 12
Training loss: 0.11570103761282709
Validation loss: 2.3592362290054933

Epoch: 6| Step: 13
Training loss: 0.1693543350451022
Validation loss: 2.3374731849218993

Epoch: 591| Step: 0
Training loss: 0.17493260886927867
Validation loss: 2.361854614428256

Epoch: 6| Step: 1
Training loss: 0.11419733598858922
Validation loss: 2.40528103480736

Epoch: 6| Step: 2
Training loss: 0.12929397850595448
Validation loss: 2.4596329165715627

Epoch: 6| Step: 3
Training loss: 0.12525558419399688
Validation loss: 2.473911791602759

Epoch: 6| Step: 4
Training loss: 0.1863060028411097
Validation loss: 2.4846037526354112

Epoch: 6| Step: 5
Training loss: 0.11195803505724457
Validation loss: 2.4371571316777434

Epoch: 6| Step: 6
Training loss: 0.08409866607079579
Validation loss: 2.4025852138377752

Epoch: 6| Step: 7
Training loss: 0.12932393289362132
Validation loss: 2.3986521801807648

Epoch: 6| Step: 8
Training loss: 0.1185167542594264
Validation loss: 2.3537457396816626

Epoch: 6| Step: 9
Training loss: 0.1660126573633971
Validation loss: 2.3417465331949394

Epoch: 6| Step: 10
Training loss: 0.19561344802739336
Validation loss: 2.352726026641456

Epoch: 6| Step: 11
Training loss: 0.16229486194712553
Validation loss: 2.366584638522734

Epoch: 6| Step: 12
Training loss: 0.17147155031636252
Validation loss: 2.4096151759631996

Epoch: 6| Step: 13
Training loss: 0.20153893621347363
Validation loss: 2.448079329518747

Epoch: 592| Step: 0
Training loss: 0.14223727544488068
Validation loss: 2.4630952546951255

Epoch: 6| Step: 1
Training loss: 0.11550608622370767
Validation loss: 2.4700331327858147

Epoch: 6| Step: 2
Training loss: 0.11460293706898744
Validation loss: 2.4440060208699284

Epoch: 6| Step: 3
Training loss: 0.21191494146068077
Validation loss: 2.439820446941395

Epoch: 6| Step: 4
Training loss: 0.20903625913763926
Validation loss: 2.4063606252758656

Epoch: 6| Step: 5
Training loss: 0.1844716287627718
Validation loss: 2.4169822245691126

Epoch: 6| Step: 6
Training loss: 0.22513048838650765
Validation loss: 2.4304688514288615

Epoch: 6| Step: 7
Training loss: 0.25090073208069225
Validation loss: 2.428115705616257

Epoch: 6| Step: 8
Training loss: 0.15978769019420783
Validation loss: 2.456235637892608

Epoch: 6| Step: 9
Training loss: 0.13786677243385387
Validation loss: 2.4590092858207813

Epoch: 6| Step: 10
Training loss: 0.17142861009175853
Validation loss: 2.448776948177915

Epoch: 6| Step: 11
Training loss: 0.12809031354264216
Validation loss: 2.412125860361081

Epoch: 6| Step: 12
Training loss: 0.18960985602532768
Validation loss: 2.3694055562963867

Epoch: 6| Step: 13
Training loss: 0.24274990707370145
Validation loss: 2.4219259335457717

Epoch: 593| Step: 0
Training loss: 0.22162767043659096
Validation loss: 2.465564305302006

Epoch: 6| Step: 1
Training loss: 0.2758306950666754
Validation loss: 2.508403932338761

Epoch: 6| Step: 2
Training loss: 0.2837736630970927
Validation loss: 2.503345031334357

Epoch: 6| Step: 3
Training loss: 0.26375496579417557
Validation loss: 2.4622029108791326

Epoch: 6| Step: 4
Training loss: 0.18220685052918967
Validation loss: 2.4188016595072384

Epoch: 6| Step: 5
Training loss: 0.2179881606807876
Validation loss: 2.4401991602833246

Epoch: 6| Step: 6
Training loss: 0.17154933680915113
Validation loss: 2.4241582263893835

Epoch: 6| Step: 7
Training loss: 0.21588944928705742
Validation loss: 2.4207530248755362

Epoch: 6| Step: 8
Training loss: 0.22972538239919146
Validation loss: 2.421824259628381

Epoch: 6| Step: 9
Training loss: 0.15425028278581487
Validation loss: 2.4443010266065057

Epoch: 6| Step: 10
Training loss: 0.2579678731957732
Validation loss: 2.456038527267454

Epoch: 6| Step: 11
Training loss: 0.2524145174739954
Validation loss: 2.441426482611056

Epoch: 6| Step: 12
Training loss: 0.199679832191882
Validation loss: 2.385179003683528

Epoch: 6| Step: 13
Training loss: 0.1610339468314315
Validation loss: 2.307427117730544

Epoch: 594| Step: 0
Training loss: 0.16485075393369272
Validation loss: 2.3028201823281567

Epoch: 6| Step: 1
Training loss: 0.22813942909332235
Validation loss: 2.2565030357364577

Epoch: 6| Step: 2
Training loss: 0.2315468062618171
Validation loss: 2.2848427997089096

Epoch: 6| Step: 3
Training loss: 0.12936359971491587
Validation loss: 2.265107235074924

Epoch: 6| Step: 4
Training loss: 0.13745073823199802
Validation loss: 2.3562900678093137

Epoch: 6| Step: 5
Training loss: 0.24755855612970853
Validation loss: 2.4064479592499914

Epoch: 6| Step: 6
Training loss: 0.20949612110377677
Validation loss: 2.50582004218572

Epoch: 6| Step: 7
Training loss: 0.23272476175154452
Validation loss: 2.5377659821783785

Epoch: 6| Step: 8
Training loss: 0.2484880264053284
Validation loss: 2.560403029373818

Epoch: 6| Step: 9
Training loss: 0.18402130987289272
Validation loss: 2.4968751430864375

Epoch: 6| Step: 10
Training loss: 0.15526422437289664
Validation loss: 2.455431177402567

Epoch: 6| Step: 11
Training loss: 0.19639989466312308
Validation loss: 2.421204682259897

Epoch: 6| Step: 12
Training loss: 0.2715038320032096
Validation loss: 2.3949871229168576

Epoch: 6| Step: 13
Training loss: 0.07827644272946305
Validation loss: 2.4665619580439326

Epoch: 595| Step: 0
Training loss: 0.21043652631184862
Validation loss: 2.5015448439918737

Epoch: 6| Step: 1
Training loss: 0.14154156696419756
Validation loss: 2.5326632908369033

Epoch: 6| Step: 2
Training loss: 0.20372418829594352
Validation loss: 2.5239628050398033

Epoch: 6| Step: 3
Training loss: 0.180678815497061
Validation loss: 2.5223989480149283

Epoch: 6| Step: 4
Training loss: 0.21469647821868043
Validation loss: 2.4646939933446874

Epoch: 6| Step: 5
Training loss: 0.24495033269187227
Validation loss: 2.3993689566251826

Epoch: 6| Step: 6
Training loss: 0.11039508535198087
Validation loss: 2.3803204137362353

Epoch: 6| Step: 7
Training loss: 0.17610874398207893
Validation loss: 2.336606160910166

Epoch: 6| Step: 8
Training loss: 0.29651053543173317
Validation loss: 2.322645129477358

Epoch: 6| Step: 9
Training loss: 0.26358058903371373
Validation loss: 2.3873588877447753

Epoch: 6| Step: 10
Training loss: 0.1677239541564315
Validation loss: 2.433756967402669

Epoch: 6| Step: 11
Training loss: 0.27677799331645886
Validation loss: 2.4879009033214623

Epoch: 6| Step: 12
Training loss: 0.2507875376355802
Validation loss: 2.4517564981798903

Epoch: 6| Step: 13
Training loss: 0.10436198777333408
Validation loss: 2.38330808879007

Epoch: 596| Step: 0
Training loss: 0.42562986009822634
Validation loss: 2.2847222090481742

Epoch: 6| Step: 1
Training loss: 0.15506184153741828
Validation loss: 2.375957535620404

Epoch: 6| Step: 2
Training loss: 0.2791972883117055
Validation loss: 2.411856161597655

Epoch: 6| Step: 3
Training loss: 0.19795693230526284
Validation loss: 2.445192582236514

Epoch: 6| Step: 4
Training loss: 0.2123639653051974
Validation loss: 2.4920503661733195

Epoch: 6| Step: 5
Training loss: 0.19712887168981486
Validation loss: 2.462091162813949

Epoch: 6| Step: 6
Training loss: 0.22353394167642196
Validation loss: 2.4268949105356947

Epoch: 6| Step: 7
Training loss: 0.13745098215635498
Validation loss: 2.4565903168070107

Epoch: 6| Step: 8
Training loss: 0.27875047869705355
Validation loss: 2.4581431618938026

Epoch: 6| Step: 9
Training loss: 0.18091489545255873
Validation loss: 2.463327044976673

Epoch: 6| Step: 10
Training loss: 0.23997609280185314
Validation loss: 2.461493150960926

Epoch: 6| Step: 11
Training loss: 0.17769935807918233
Validation loss: 2.4597198562686504

Epoch: 6| Step: 12
Training loss: 0.2752382113698003
Validation loss: 2.4590693328518

Epoch: 6| Step: 13
Training loss: 0.2669039677481157
Validation loss: 2.4484462834496257

Epoch: 597| Step: 0
Training loss: 0.18400993250648112
Validation loss: 2.4154392469814656

Epoch: 6| Step: 1
Training loss: 0.3549894937787358
Validation loss: 2.3721274689276597

Epoch: 6| Step: 2
Training loss: 0.17249689515747313
Validation loss: 2.3354818517259455

Epoch: 6| Step: 3
Training loss: 0.3402053619172463
Validation loss: 2.301809787622426

Epoch: 6| Step: 4
Training loss: 0.22385602747174982
Validation loss: 2.3345563652677175

Epoch: 6| Step: 5
Training loss: 0.19986781803776152
Validation loss: 2.4071944724027405

Epoch: 6| Step: 6
Training loss: 0.27863139118071123
Validation loss: 2.4805221819288357

Epoch: 6| Step: 7
Training loss: 0.32520514121108973
Validation loss: 2.501410032326551

Epoch: 6| Step: 8
Training loss: 0.2037335230594999
Validation loss: 2.4192267624647497

Epoch: 6| Step: 9
Training loss: 0.08280465565722325
Validation loss: 2.3879487592885473

Epoch: 6| Step: 10
Training loss: 0.22374212100632296
Validation loss: 2.3579084421978678

Epoch: 6| Step: 11
Training loss: 0.2550365963321593
Validation loss: 2.3296641841745713

Epoch: 6| Step: 12
Training loss: 0.20174192013331538
Validation loss: 2.3500974909838592

Epoch: 6| Step: 13
Training loss: 0.23605882260066757
Validation loss: 2.3796383329220734

Epoch: 598| Step: 0
Training loss: 0.19635765812920764
Validation loss: 2.4106855770002666

Epoch: 6| Step: 1
Training loss: 0.1738504009760867
Validation loss: 2.4253223443448397

Epoch: 6| Step: 2
Training loss: 0.15563221034807706
Validation loss: 2.455392583594732

Epoch: 6| Step: 3
Training loss: 0.2442473216559099
Validation loss: 2.4474418118476313

Epoch: 6| Step: 4
Training loss: 0.11453583710111856
Validation loss: 2.450394110428025

Epoch: 6| Step: 5
Training loss: 0.1331801654795684
Validation loss: 2.4739109807213313

Epoch: 6| Step: 6
Training loss: 0.2722705736627279
Validation loss: 2.4713807321729804

Epoch: 6| Step: 7
Training loss: 0.1555549061769695
Validation loss: 2.428337540660852

Epoch: 6| Step: 8
Training loss: 0.230890050615385
Validation loss: 2.383412195810299

Epoch: 6| Step: 9
Training loss: 0.30797364910841113
Validation loss: 2.3694596728865256

Epoch: 6| Step: 10
Training loss: 0.13571404089807
Validation loss: 2.3949398976889698

Epoch: 6| Step: 11
Training loss: 0.1738934554871334
Validation loss: 2.381841193211871

Epoch: 6| Step: 12
Training loss: 0.18326545338310007
Validation loss: 2.4207321757389177

Epoch: 6| Step: 13
Training loss: 0.14400005671215266
Validation loss: 2.434555188779033

Epoch: 599| Step: 0
Training loss: 0.17881976915122205
Validation loss: 2.3722361272954293

Epoch: 6| Step: 1
Training loss: 0.21265895732470835
Validation loss: 2.355977770802114

Epoch: 6| Step: 2
Training loss: 0.19279799222850463
Validation loss: 2.3419900839931524

Epoch: 6| Step: 3
Training loss: 0.1883995214941646
Validation loss: 2.3581213687107665

Epoch: 6| Step: 4
Training loss: 0.3029262918839057
Validation loss: 2.3570337488244935

Epoch: 6| Step: 5
Training loss: 0.21986203573781812
Validation loss: 2.3516248120287253

Epoch: 6| Step: 6
Training loss: 0.22118528412352745
Validation loss: 2.324184315923512

Epoch: 6| Step: 7
Training loss: 0.20997570784313563
Validation loss: 2.377935767963512

Epoch: 6| Step: 8
Training loss: 0.11810532599683878
Validation loss: 2.425098987661104

Epoch: 6| Step: 9
Training loss: 0.35778712803202545
Validation loss: 2.4149947930358016

Epoch: 6| Step: 10
Training loss: 0.16578558523350406
Validation loss: 2.4277102510011375

Epoch: 6| Step: 11
Training loss: 0.1729835932736965
Validation loss: 2.4122526334445147

Epoch: 6| Step: 12
Training loss: 0.30813494509573647
Validation loss: 2.408785430982919

Epoch: 6| Step: 13
Training loss: 0.18661007691447548
Validation loss: 2.371261708312103

Epoch: 600| Step: 0
Training loss: 0.24069554174277896
Validation loss: 2.365341063128662

Epoch: 6| Step: 1
Training loss: 0.26919540268612835
Validation loss: 2.3531978906875355

Epoch: 6| Step: 2
Training loss: 0.12598822783642086
Validation loss: 2.4299020352330767

Epoch: 6| Step: 3
Training loss: 0.15841840295987264
Validation loss: 2.4668886814238795

Epoch: 6| Step: 4
Training loss: 0.14264711252553308
Validation loss: 2.527159132475552

Epoch: 6| Step: 5
Training loss: 0.16095774416770847
Validation loss: 2.5282692525173056

Epoch: 6| Step: 6
Training loss: 0.24966780377167463
Validation loss: 2.5370153562708904

Epoch: 6| Step: 7
Training loss: 0.12722504178884356
Validation loss: 2.491213166473488

Epoch: 6| Step: 8
Training loss: 0.21064772835587983
Validation loss: 2.4495322941073128

Epoch: 6| Step: 9
Training loss: 0.1661361088841672
Validation loss: 2.440441623108643

Epoch: 6| Step: 10
Training loss: 0.16508592132233224
Validation loss: 2.4354322554045034

Epoch: 6| Step: 11
Training loss: 0.2720474879870466
Validation loss: 2.4504555094389993

Epoch: 6| Step: 12
Training loss: 0.1808989261199672
Validation loss: 2.475820834881084

Epoch: 6| Step: 13
Training loss: 0.20223903929206344
Validation loss: 2.474866470641139

Epoch: 601| Step: 0
Training loss: 0.17021916132849754
Validation loss: 2.504705290608717

Epoch: 6| Step: 1
Training loss: 0.2932847543993806
Validation loss: 2.5366110150050543

Epoch: 6| Step: 2
Training loss: 0.2531020707471127
Validation loss: 2.498548733518446

Epoch: 6| Step: 3
Training loss: 0.1356772123203165
Validation loss: 2.413611714865185

Epoch: 6| Step: 4
Training loss: 0.2529621471653087
Validation loss: 2.4024918689380828

Epoch: 6| Step: 5
Training loss: 0.14333319281993492
Validation loss: 2.3817630387300457

Epoch: 6| Step: 6
Training loss: 0.22069571491056092
Validation loss: 2.3786681581930567

Epoch: 6| Step: 7
Training loss: 0.1702304646890661
Validation loss: 2.398364886710875

Epoch: 6| Step: 8
Training loss: 0.22109402161167027
Validation loss: 2.402859526273435

Epoch: 6| Step: 9
Training loss: 0.16728030552375642
Validation loss: 2.4413978956510287

Epoch: 6| Step: 10
Training loss: 0.1272074426251634
Validation loss: 2.5094728996529265

Epoch: 6| Step: 11
Training loss: 0.20852819012558269
Validation loss: 2.6007242850046084

Epoch: 6| Step: 12
Training loss: 0.2485206764664769
Validation loss: 2.5808815676068906

Epoch: 6| Step: 13
Training loss: 0.18385723159187736
Validation loss: 2.558137211589573

Epoch: 602| Step: 0
Training loss: 0.2190356603279917
Validation loss: 2.4908992227753286

Epoch: 6| Step: 1
Training loss: 0.366664026352017
Validation loss: 2.458632543954653

Epoch: 6| Step: 2
Training loss: 0.23523015733356595
Validation loss: 2.304472845254791

Epoch: 6| Step: 3
Training loss: 0.3869662408051941
Validation loss: 2.241069320367783

Epoch: 6| Step: 4
Training loss: 0.3686986022625267
Validation loss: 2.2227327349609505

Epoch: 6| Step: 5
Training loss: 0.13354304589552654
Validation loss: 2.37248727120148

Epoch: 6| Step: 6
Training loss: 0.325017703014344
Validation loss: 2.4958247153498556

Epoch: 6| Step: 7
Training loss: 0.4621264753619936
Validation loss: 2.591691514994635

Epoch: 6| Step: 8
Training loss: 0.3678191210816049
Validation loss: 2.5311445505167165

Epoch: 6| Step: 9
Training loss: 0.16229827629491425
Validation loss: 2.404024541046277

Epoch: 6| Step: 10
Training loss: 0.2693865843935
Validation loss: 2.351693586858195

Epoch: 6| Step: 11
Training loss: 0.5778166489893166
Validation loss: 2.2723143024134886

Epoch: 6| Step: 12
Training loss: 0.4107166639697481
Validation loss: 2.3629258254242758

Epoch: 6| Step: 13
Training loss: 0.14767466460553622
Validation loss: 2.4926173167100494

Epoch: 603| Step: 0
Training loss: 0.4129211602157357
Validation loss: 2.5958714557245544

Epoch: 6| Step: 1
Training loss: 0.24151567367964874
Validation loss: 2.573350297069882

Epoch: 6| Step: 2
Training loss: 0.23782732204308976
Validation loss: 2.5238122616380356

Epoch: 6| Step: 3
Training loss: 0.4325011293583937
Validation loss: 2.4729675792663484

Epoch: 6| Step: 4
Training loss: 0.19539867407423087
Validation loss: 2.347601908174845

Epoch: 6| Step: 5
Training loss: 0.21363642187482051
Validation loss: 2.263749131538157

Epoch: 6| Step: 6
Training loss: 0.22820191164618117
Validation loss: 2.2047407121971494

Epoch: 6| Step: 7
Training loss: 0.2748108299886537
Validation loss: 2.186655711951429

Epoch: 6| Step: 8
Training loss: 0.24689678083984823
Validation loss: 2.246022571436387

Epoch: 6| Step: 9
Training loss: 0.5525644533183015
Validation loss: 2.350374658147757

Epoch: 6| Step: 10
Training loss: 0.39334422653410617
Validation loss: 2.403601383182232

Epoch: 6| Step: 11
Training loss: 0.33906854808704534
Validation loss: 2.428467533067325

Epoch: 6| Step: 12
Training loss: 0.31147988233155993
Validation loss: 2.402463160162563

Epoch: 6| Step: 13
Training loss: 0.22860879710353
Validation loss: 2.3592674292240323

Epoch: 604| Step: 0
Training loss: 0.24384787746262054
Validation loss: 2.353989554089828

Epoch: 6| Step: 1
Training loss: 0.34183457302919257
Validation loss: 2.345947486233083

Epoch: 6| Step: 2
Training loss: 0.3711223390508884
Validation loss: 2.345161777917105

Epoch: 6| Step: 3
Training loss: 0.30444758090325064
Validation loss: 2.389536664093475

Epoch: 6| Step: 4
Training loss: 0.31493958465285943
Validation loss: 2.4256994240141947

Epoch: 6| Step: 5
Training loss: 0.3040667592972557
Validation loss: 2.417679210348761

Epoch: 6| Step: 6
Training loss: 0.2652057817690464
Validation loss: 2.4209272686410523

Epoch: 6| Step: 7
Training loss: 0.2497186716982065
Validation loss: 2.4163410284204545

Epoch: 6| Step: 8
Training loss: 0.3278469997030775
Validation loss: 2.3826864541732697

Epoch: 6| Step: 9
Training loss: 0.5252772496075829
Validation loss: 2.3879435647932055

Epoch: 6| Step: 10
Training loss: 0.32418305993408797
Validation loss: 2.448211362786312

Epoch: 6| Step: 11
Training loss: 0.37965923879176844
Validation loss: 2.4559976137010775

Epoch: 6| Step: 12
Training loss: 0.18326669334368872
Validation loss: 2.514869517902276

Epoch: 6| Step: 13
Training loss: 0.33956316622818444
Validation loss: 2.523946792156117

Epoch: 605| Step: 0
Training loss: 0.4115773423226074
Validation loss: 2.5390095215374755

Epoch: 6| Step: 1
Training loss: 0.2720207295144542
Validation loss: 2.475237801762841

Epoch: 6| Step: 2
Training loss: 0.5357232257687424
Validation loss: 2.4550542195648912

Epoch: 6| Step: 3
Training loss: 0.26344538250371846
Validation loss: 2.481599201874942

Epoch: 6| Step: 4
Training loss: 0.49091853697034205
Validation loss: 2.502414183749945

Epoch: 6| Step: 5
Training loss: 0.2439745834296214
Validation loss: 2.468164493179579

Epoch: 6| Step: 6
Training loss: 0.2038153325106014
Validation loss: 2.4452266835970633

Epoch: 6| Step: 7
Training loss: 0.33516837945077144
Validation loss: 2.41432345754296

Epoch: 6| Step: 8
Training loss: 0.5339627845490318
Validation loss: 2.4125040473502355

Epoch: 6| Step: 9
Training loss: 0.32956206028006646
Validation loss: 2.426404986455204

Epoch: 6| Step: 10
Training loss: 0.49266413664501557
Validation loss: 2.4353368735574756

Epoch: 6| Step: 11
Training loss: 0.1801165972013114
Validation loss: 2.4384461710233576

Epoch: 6| Step: 12
Training loss: 0.24444954210863867
Validation loss: 2.4033725923496485

Epoch: 6| Step: 13
Training loss: 0.41014749426805847
Validation loss: 2.404956389463222

Epoch: 606| Step: 0
Training loss: 0.39912995771249443
Validation loss: 2.409476497293438

Epoch: 6| Step: 1
Training loss: 0.3188708940949698
Validation loss: 2.37401333419923

Epoch: 6| Step: 2
Training loss: 0.33508757707992887
Validation loss: 2.3629394533582615

Epoch: 6| Step: 3
Training loss: 0.5592517844944579
Validation loss: 2.307398299986441

Epoch: 6| Step: 4
Training loss: 0.33291930199814623
Validation loss: 2.411683718528237

Epoch: 6| Step: 5
Training loss: 0.22338111739595629
Validation loss: 2.4972907819737213

Epoch: 6| Step: 6
Training loss: 0.3431279449475481
Validation loss: 2.5767935617752578

Epoch: 6| Step: 7
Training loss: 0.21094362815149723
Validation loss: 2.5813422351477264

Epoch: 6| Step: 8
Training loss: 0.4951011459490652
Validation loss: 2.548380689708973

Epoch: 6| Step: 9
Training loss: 0.2684178229015626
Validation loss: 2.513722706774851

Epoch: 6| Step: 10
Training loss: 0.41244312530071175
Validation loss: 2.4574062338353384

Epoch: 6| Step: 11
Training loss: 0.2826158155765201
Validation loss: 2.3174393309147376

Epoch: 6| Step: 12
Training loss: 0.798893335940464
Validation loss: 2.2511308100374046

Epoch: 6| Step: 13
Training loss: 0.2631063684178109
Validation loss: 2.395285947168866

Epoch: 607| Step: 0
Training loss: 0.41791674923285865
Validation loss: 2.6143209550203137

Epoch: 6| Step: 1
Training loss: 0.8547113976633243
Validation loss: 2.7518217442222124

Epoch: 6| Step: 2
Training loss: 0.21596564495927412
Validation loss: 2.605505305306505

Epoch: 6| Step: 3
Training loss: 0.3402185894077595
Validation loss: 2.4863667247748626

Epoch: 6| Step: 4
Training loss: 0.5769405087258354
Validation loss: 2.377609559324959

Epoch: 6| Step: 5
Training loss: 1.0536643257473126
Validation loss: 2.371431548732155

Epoch: 6| Step: 6
Training loss: 0.6897522922946493
Validation loss: 2.422037826923509

Epoch: 6| Step: 7
Training loss: 0.8002768812255827
Validation loss: 2.5023342638066866

Epoch: 6| Step: 8
Training loss: 0.8769867004899811
Validation loss: 2.61408529492644

Epoch: 6| Step: 9
Training loss: 1.1783816961015448
Validation loss: 2.6531648278518714

Epoch: 6| Step: 10
Training loss: 0.8625223267471214
Validation loss: 2.4628927099362805

Epoch: 6| Step: 11
Training loss: 0.6959349814045231
Validation loss: 2.3420458520535345

Epoch: 6| Step: 12
Training loss: 0.46601532506813187
Validation loss: 2.356629235711741

Epoch: 6| Step: 13
Training loss: 0.9486120035183756
Validation loss: 2.323029967346801

Epoch: 608| Step: 0
Training loss: 0.6837734531167096
Validation loss: 2.426541934857155

Epoch: 6| Step: 1
Training loss: 0.9055133324773245
Validation loss: 2.506544260990589

Epoch: 6| Step: 2
Training loss: 0.7111044048532856
Validation loss: 2.4896957650791514

Epoch: 6| Step: 3
Training loss: 0.41964836972103015
Validation loss: 2.519681929120671

Epoch: 6| Step: 4
Training loss: 0.7613057508552314
Validation loss: 2.5136714986646975

Epoch: 6| Step: 5
Training loss: 0.8964073796337471
Validation loss: 2.5700987613439708

Epoch: 6| Step: 6
Training loss: 1.2033789230509389
Validation loss: 2.5959857408520106

Epoch: 6| Step: 7
Training loss: 0.7654252862280565
Validation loss: 2.5916754526950143

Epoch: 6| Step: 8
Training loss: 0.5400871545165656
Validation loss: 2.5477181523760386

Epoch: 6| Step: 9
Training loss: 0.5664008830901444
Validation loss: 2.5047858098961773

Epoch: 6| Step: 10
Training loss: 0.6961072601480089
Validation loss: 2.430240905325987

Epoch: 6| Step: 11
Training loss: 0.625919857224061
Validation loss: 2.3682735126973764

Epoch: 6| Step: 12
Training loss: 1.05413102905185
Validation loss: 2.330336902025197

Epoch: 6| Step: 13
Training loss: 0.929862286461931
Validation loss: 2.264450477142686

Epoch: 609| Step: 0
Training loss: 0.5530820635925235
Validation loss: 2.297059001058227

Epoch: 6| Step: 1
Training loss: 0.5606393239414535
Validation loss: 2.322444884048712

Epoch: 6| Step: 2
Training loss: 0.5073175218744109
Validation loss: 2.321562121341834

Epoch: 6| Step: 3
Training loss: 0.4971053555170361
Validation loss: 2.3859718490962427

Epoch: 6| Step: 4
Training loss: 0.45481883180925287
Validation loss: 2.507336354818664

Epoch: 6| Step: 5
Training loss: 0.6730406651844169
Validation loss: 2.5776885795934508

Epoch: 6| Step: 6
Training loss: 0.5649826047970832
Validation loss: 2.5776068685421136

Epoch: 6| Step: 7
Training loss: 0.36156115878688083
Validation loss: 2.600895258630649

Epoch: 6| Step: 8
Training loss: 0.6001200039382891
Validation loss: 2.623651948464717

Epoch: 6| Step: 9
Training loss: 0.4521454055058303
Validation loss: 2.5992589664027363

Epoch: 6| Step: 10
Training loss: 0.6517053095424648
Validation loss: 2.5938240255187077

Epoch: 6| Step: 11
Training loss: 0.4937454573506821
Validation loss: 2.566221879266452

Epoch: 6| Step: 12
Training loss: 0.5458054574249774
Validation loss: 2.5417231535488987

Epoch: 6| Step: 13
Training loss: 0.4973228427664331
Validation loss: 2.531286749046998

Epoch: 610| Step: 0
Training loss: 0.8981115330354754
Validation loss: 2.471693392062926

Epoch: 6| Step: 1
Training loss: 0.6024070854879765
Validation loss: 2.510145553050774

Epoch: 6| Step: 2
Training loss: 0.6487602901193916
Validation loss: 2.570536074399588

Epoch: 6| Step: 3
Training loss: 0.7320251204031493
Validation loss: 2.6732490727695932

Epoch: 6| Step: 4
Training loss: 0.6367592827936928
Validation loss: 2.689239904100542

Epoch: 6| Step: 5
Training loss: 0.5578486134355202
Validation loss: 2.5216168062664988

Epoch: 6| Step: 6
Training loss: 0.4213764459058408
Validation loss: 2.404795377060078

Epoch: 6| Step: 7
Training loss: 0.24012288553636435
Validation loss: 2.3363720181780976

Epoch: 6| Step: 8
Training loss: 0.7467193377457177
Validation loss: 2.311069803438018

Epoch: 6| Step: 9
Training loss: 1.0974250088316537
Validation loss: 2.283900024329338

Epoch: 6| Step: 10
Training loss: 0.6918439180306828
Validation loss: 2.401913017357667

Epoch: 6| Step: 11
Training loss: 0.5215674630598078
Validation loss: 2.537095448839561

Epoch: 6| Step: 12
Training loss: 0.6839552005491184
Validation loss: 2.7044634815421147

Epoch: 6| Step: 13
Training loss: 0.4632369568672044
Validation loss: 2.7430189968705316

Epoch: 611| Step: 0
Training loss: 1.0600179965812713
Validation loss: 2.73882497092363

Epoch: 6| Step: 1
Training loss: 0.6744963939533593
Validation loss: 2.540365679619943

Epoch: 6| Step: 2
Training loss: 0.5707780166145927
Validation loss: 2.326582151917679

Epoch: 6| Step: 3
Training loss: 0.8412380266400289
Validation loss: 2.2264540790728042

Epoch: 6| Step: 4
Training loss: 0.46547540655431313
Validation loss: 2.202482591960895

Epoch: 6| Step: 5
Training loss: 0.6810062593614948
Validation loss: 2.2282223898558913

Epoch: 6| Step: 6
Training loss: 0.43262838172637974
Validation loss: 2.342026288996409

Epoch: 6| Step: 7
Training loss: 0.5836850167726214
Validation loss: 2.4992693715318475

Epoch: 6| Step: 8
Training loss: 0.8341440231141125
Validation loss: 2.6677906400500055

Epoch: 6| Step: 9
Training loss: 0.7027897141334624
Validation loss: 2.699909953526588

Epoch: 6| Step: 10
Training loss: 0.503735180582389
Validation loss: 2.62580706919323

Epoch: 6| Step: 11
Training loss: 0.43965278328468244
Validation loss: 2.534651919824827

Epoch: 6| Step: 12
Training loss: 0.4189677021294908
Validation loss: 2.4136219328180393

Epoch: 6| Step: 13
Training loss: 0.8463366032269676
Validation loss: 2.381571338372459

Epoch: 612| Step: 0
Training loss: 0.3629752069786517
Validation loss: 2.415931713665722

Epoch: 6| Step: 1
Training loss: 0.607937707238384
Validation loss: 2.528477779653143

Epoch: 6| Step: 2
Training loss: 0.4402813714573016
Validation loss: 2.5710434415251076

Epoch: 6| Step: 3
Training loss: 0.36803342894655483
Validation loss: 2.6084818675630035

Epoch: 6| Step: 4
Training loss: 0.6509928392537969
Validation loss: 2.648017150333441

Epoch: 6| Step: 5
Training loss: 0.7437312083715367
Validation loss: 2.6719341941963566

Epoch: 6| Step: 6
Training loss: 0.736873677570428
Validation loss: 2.6960825363026153

Epoch: 6| Step: 7
Training loss: 0.5166017355675218
Validation loss: 2.6322168778191806

Epoch: 6| Step: 8
Training loss: 0.505473398367072
Validation loss: 2.6011396273371856

Epoch: 6| Step: 9
Training loss: 0.37434353589539743
Validation loss: 2.5685535682052483

Epoch: 6| Step: 10
Training loss: 0.44463149081927816
Validation loss: 2.487528126982668

Epoch: 6| Step: 11
Training loss: 0.42267437541687863
Validation loss: 2.4464646071074156

Epoch: 6| Step: 12
Training loss: 0.5678499960813785
Validation loss: 2.395483587631041

Epoch: 6| Step: 13
Training loss: 0.5950603832331028
Validation loss: 2.3883701183129804

Epoch: 613| Step: 0
Training loss: 0.46894886249054896
Validation loss: 2.350417960008314

Epoch: 6| Step: 1
Training loss: 0.4274734502489748
Validation loss: 2.359835157890545

Epoch: 6| Step: 2
Training loss: 0.5591129477669031
Validation loss: 2.3523042862270866

Epoch: 6| Step: 3
Training loss: 0.5063605458633936
Validation loss: 2.3831434805741263

Epoch: 6| Step: 4
Training loss: 0.2908733455346976
Validation loss: 2.4237015699827693

Epoch: 6| Step: 5
Training loss: 0.2862675060099856
Validation loss: 2.5029257799604845

Epoch: 6| Step: 6
Training loss: 0.26902604785470874
Validation loss: 2.5393486413252493

Epoch: 6| Step: 7
Training loss: 0.45002976888631824
Validation loss: 2.5970312555422144

Epoch: 6| Step: 8
Training loss: 0.5524247181640796
Validation loss: 2.5599939721431317

Epoch: 6| Step: 9
Training loss: 0.4107105505963009
Validation loss: 2.504184548416845

Epoch: 6| Step: 10
Training loss: 0.26968346319790953
Validation loss: 2.499654826054038

Epoch: 6| Step: 11
Training loss: 0.6298476098447919
Validation loss: 2.503265102705148

Epoch: 6| Step: 12
Training loss: 0.3511954722893863
Validation loss: 2.4392825776993545

Epoch: 6| Step: 13
Training loss: 0.4313726844979692
Validation loss: 2.452524985855905

Epoch: 614| Step: 0
Training loss: 0.4223348442603595
Validation loss: 2.3817830380012026

Epoch: 6| Step: 1
Training loss: 0.4294010247751773
Validation loss: 2.425671275795025

Epoch: 6| Step: 2
Training loss: 0.3302494710373667
Validation loss: 2.396591570707113

Epoch: 6| Step: 3
Training loss: 0.4742070443281359
Validation loss: 2.3981729313225078

Epoch: 6| Step: 4
Training loss: 0.34525550268319566
Validation loss: 2.464860020995567

Epoch: 6| Step: 5
Training loss: 0.37953815662794727
Validation loss: 2.5719659217886495

Epoch: 6| Step: 6
Training loss: 0.4168466497157827
Validation loss: 2.5994583810492236

Epoch: 6| Step: 7
Training loss: 0.34494582165444704
Validation loss: 2.6107931269281246

Epoch: 6| Step: 8
Training loss: 0.277513344718775
Validation loss: 2.5700453473439553

Epoch: 6| Step: 9
Training loss: 0.43002396328268144
Validation loss: 2.5536551407764687

Epoch: 6| Step: 10
Training loss: 0.34570979526787365
Validation loss: 2.465305286523404

Epoch: 6| Step: 11
Training loss: 0.360863711918869
Validation loss: 2.4256475614317727

Epoch: 6| Step: 12
Training loss: 0.39865999928106555
Validation loss: 2.4240290488509397

Epoch: 6| Step: 13
Training loss: 0.37024352401051386
Validation loss: 2.389840001645038

Epoch: 615| Step: 0
Training loss: 0.35940178481090274
Validation loss: 2.367664762448422

Epoch: 6| Step: 1
Training loss: 0.3871875964912005
Validation loss: 2.3259591252702934

Epoch: 6| Step: 2
Training loss: 0.3300029511030774
Validation loss: 2.354965718666917

Epoch: 6| Step: 3
Training loss: 0.2679567929372247
Validation loss: 2.342528310145409

Epoch: 6| Step: 4
Training loss: 0.1511070970243861
Validation loss: 2.3913397195471306

Epoch: 6| Step: 5
Training loss: 0.23906719633239165
Validation loss: 2.408094161029687

Epoch: 6| Step: 6
Training loss: 0.29281993901300246
Validation loss: 2.414832506126993

Epoch: 6| Step: 7
Training loss: 0.21839329041590766
Validation loss: 2.460663283840197

Epoch: 6| Step: 8
Training loss: 0.3198083072810218
Validation loss: 2.494576619692794

Epoch: 6| Step: 9
Training loss: 0.29198301422100903
Validation loss: 2.4892042220379085

Epoch: 6| Step: 10
Training loss: 0.30589740122167886
Validation loss: 2.4997648343875825

Epoch: 6| Step: 11
Training loss: 0.23613102630621197
Validation loss: 2.4910063090323527

Epoch: 6| Step: 12
Training loss: 0.2611726786070204
Validation loss: 2.4960156140815886

Epoch: 6| Step: 13
Training loss: 0.19860086737423652
Validation loss: 2.4831384812907604

Epoch: 616| Step: 0
Training loss: 0.2209250760395903
Validation loss: 2.496881219324115

Epoch: 6| Step: 1
Training loss: 0.1658922410117171
Validation loss: 2.416083539126168

Epoch: 6| Step: 2
Training loss: 0.2174322766068343
Validation loss: 2.4441984851662264

Epoch: 6| Step: 3
Training loss: 0.248468776149698
Validation loss: 2.439478866853943

Epoch: 6| Step: 4
Training loss: 0.2212503283169568
Validation loss: 2.429148565407247

Epoch: 6| Step: 5
Training loss: 0.31217676373369424
Validation loss: 2.443274629235296

Epoch: 6| Step: 6
Training loss: 0.314104823207167
Validation loss: 2.435966937233708

Epoch: 6| Step: 7
Training loss: 0.30143561337359326
Validation loss: 2.4188121316335356

Epoch: 6| Step: 8
Training loss: 0.3209020144262652
Validation loss: 2.425209968787534

Epoch: 6| Step: 9
Training loss: 0.31232983009040505
Validation loss: 2.448250017964695

Epoch: 6| Step: 10
Training loss: 0.3019253164023292
Validation loss: 2.4518527997284054

Epoch: 6| Step: 11
Training loss: 0.24516031562152188
Validation loss: 2.4452156321075686

Epoch: 6| Step: 12
Training loss: 0.22709734039387036
Validation loss: 2.482700618733043

Epoch: 6| Step: 13
Training loss: 0.2133599192117562
Validation loss: 2.446453405072832

Epoch: 617| Step: 0
Training loss: 0.21688928438905522
Validation loss: 2.4449377395572895

Epoch: 6| Step: 1
Training loss: 0.24583364546615916
Validation loss: 2.419405808134078

Epoch: 6| Step: 2
Training loss: 0.2762155015471521
Validation loss: 2.441219080947034

Epoch: 6| Step: 3
Training loss: 0.1788909714017645
Validation loss: 2.4483054294622697

Epoch: 6| Step: 4
Training loss: 0.17414674061903454
Validation loss: 2.4163920685342855

Epoch: 6| Step: 5
Training loss: 0.21495161816517422
Validation loss: 2.380654915379661

Epoch: 6| Step: 6
Training loss: 0.17235928279572346
Validation loss: 2.409772035131319

Epoch: 6| Step: 7
Training loss: 0.11938759346013629
Validation loss: 2.401613896849324

Epoch: 6| Step: 8
Training loss: 0.22538128772349272
Validation loss: 2.4306144991601437

Epoch: 6| Step: 9
Training loss: 0.23739779180433337
Validation loss: 2.4109654689783273

Epoch: 6| Step: 10
Training loss: 0.22536668402393117
Validation loss: 2.4340589586258923

Epoch: 6| Step: 11
Training loss: 0.1651421963929787
Validation loss: 2.4174047226378987

Epoch: 6| Step: 12
Training loss: 0.22132259124990714
Validation loss: 2.457530538883941

Epoch: 6| Step: 13
Training loss: 0.2579079364650752
Validation loss: 2.4265536704265713

Epoch: 618| Step: 0
Training loss: 0.2099156086805935
Validation loss: 2.493349597289021

Epoch: 6| Step: 1
Training loss: 0.18248434896180682
Validation loss: 2.4555709022832826

Epoch: 6| Step: 2
Training loss: 0.2468278245276298
Validation loss: 2.476668757503183

Epoch: 6| Step: 3
Training loss: 0.15004281287358875
Validation loss: 2.4640852634474726

Epoch: 6| Step: 4
Training loss: 0.12549540577416515
Validation loss: 2.4207600928054105

Epoch: 6| Step: 5
Training loss: 0.15892251425661322
Validation loss: 2.402310165756117

Epoch: 6| Step: 6
Training loss: 0.17877176427389485
Validation loss: 2.398354737371434

Epoch: 6| Step: 7
Training loss: 0.23583536558460688
Validation loss: 2.3912594311496362

Epoch: 6| Step: 8
Training loss: 0.18890094908982746
Validation loss: 2.3741405672098486

Epoch: 6| Step: 9
Training loss: 0.12125011316274495
Validation loss: 2.401008350184855

Epoch: 6| Step: 10
Training loss: 0.14439995704796196
Validation loss: 2.4126952296625914

Epoch: 6| Step: 11
Training loss: 0.18894082047298452
Validation loss: 2.4095324993573244

Epoch: 6| Step: 12
Training loss: 0.1946300313240451
Validation loss: 2.4444625369605295

Epoch: 6| Step: 13
Training loss: 0.13991617000500015
Validation loss: 2.4357556647986818

Epoch: 619| Step: 0
Training loss: 0.09807501651212916
Validation loss: 2.4575652394178737

Epoch: 6| Step: 1
Training loss: 0.10500380678031322
Validation loss: 2.4670405016323773

Epoch: 6| Step: 2
Training loss: 0.15470141483105612
Validation loss: 2.497873549401533

Epoch: 6| Step: 3
Training loss: 0.15882879325549737
Validation loss: 2.48684153876919

Epoch: 6| Step: 4
Training loss: 0.18028384227214753
Validation loss: 2.475927313179086

Epoch: 6| Step: 5
Training loss: 0.13844494317412712
Validation loss: 2.5014465351474025

Epoch: 6| Step: 6
Training loss: 0.1651421963929787
Validation loss: 2.4651839312420725

Epoch: 6| Step: 7
Training loss: 0.1653213569633718
Validation loss: 2.457169976718191

Epoch: 6| Step: 8
Training loss: 0.1681451591916876
Validation loss: 2.4519581425495405

Epoch: 6| Step: 9
Training loss: 0.12432026823387396
Validation loss: 2.408643033597913

Epoch: 6| Step: 10
Training loss: 0.16246881048117376
Validation loss: 2.4311584930361594

Epoch: 6| Step: 11
Training loss: 0.21043293263730414
Validation loss: 2.434423963672061

Epoch: 6| Step: 12
Training loss: 0.1361780510145843
Validation loss: 2.420978997260462

Epoch: 6| Step: 13
Training loss: 0.140412249165483
Validation loss: 2.436829157276165

Epoch: 620| Step: 0
Training loss: 0.14222382589723262
Validation loss: 2.4422252773955027

Epoch: 6| Step: 1
Training loss: 0.11731587372198134
Validation loss: 2.4652205830957348

Epoch: 6| Step: 2
Training loss: 0.17882552928715573
Validation loss: 2.4442588593382246

Epoch: 6| Step: 3
Training loss: 0.14735768979374703
Validation loss: 2.4599301262343007

Epoch: 6| Step: 4
Training loss: 0.16406039963240607
Validation loss: 2.4726281298532196

Epoch: 6| Step: 5
Training loss: 0.08430909987359897
Validation loss: 2.4291318821253314

Epoch: 6| Step: 6
Training loss: 0.16159157613097264
Validation loss: 2.4416398588251127

Epoch: 6| Step: 7
Training loss: 0.14570531945710924
Validation loss: 2.4299340812941437

Epoch: 6| Step: 8
Training loss: 0.15198052338270648
Validation loss: 2.4188370772735404

Epoch: 6| Step: 9
Training loss: 0.16613457849901722
Validation loss: 2.4087915527578216

Epoch: 6| Step: 10
Training loss: 0.19270250702547548
Validation loss: 2.3948054123334983

Epoch: 6| Step: 11
Training loss: 0.1046692960483783
Validation loss: 2.399394450053543

Epoch: 6| Step: 12
Training loss: 0.13907488837406506
Validation loss: 2.404005229081789

Epoch: 6| Step: 13
Training loss: 0.22579403151398694
Validation loss: 2.3957766154790883

Epoch: 621| Step: 0
Training loss: 0.11731108665478675
Validation loss: 2.397592474591262

Epoch: 6| Step: 1
Training loss: 0.08720168997628425
Validation loss: 2.4367219036925016

Epoch: 6| Step: 2
Training loss: 0.08543953704481051
Validation loss: 2.4373747465032207

Epoch: 6| Step: 3
Training loss: 0.12613289027065455
Validation loss: 2.4629843704428986

Epoch: 6| Step: 4
Training loss: 0.1683666429035137
Validation loss: 2.4242035245699323

Epoch: 6| Step: 5
Training loss: 0.19611502756132052
Validation loss: 2.4515152051510416

Epoch: 6| Step: 6
Training loss: 0.1844354166839428
Validation loss: 2.4704610186912843

Epoch: 6| Step: 7
Training loss: 0.15668509225551258
Validation loss: 2.4787623412772755

Epoch: 6| Step: 8
Training loss: 0.15411908735410604
Validation loss: 2.428357162163856

Epoch: 6| Step: 9
Training loss: 0.13294953401275147
Validation loss: 2.4674533005063486

Epoch: 6| Step: 10
Training loss: 0.20292762189884078
Validation loss: 2.4390788942536674

Epoch: 6| Step: 11
Training loss: 0.20761047165811347
Validation loss: 2.459559374907972

Epoch: 6| Step: 12
Training loss: 0.16450260940108336
Validation loss: 2.4504431152015607

Epoch: 6| Step: 13
Training loss: 0.16281698515456364
Validation loss: 2.432053136744372

Epoch: 622| Step: 0
Training loss: 0.11006634912524224
Validation loss: 2.4350196122987158

Epoch: 6| Step: 1
Training loss: 0.11461821390040437
Validation loss: 2.455934191942024

Epoch: 6| Step: 2
Training loss: 0.12001169425885386
Validation loss: 2.4679959787588737

Epoch: 6| Step: 3
Training loss: 0.10589361270563996
Validation loss: 2.46109630295665

Epoch: 6| Step: 4
Training loss: 0.1608443076018634
Validation loss: 2.4633498190085716

Epoch: 6| Step: 5
Training loss: 0.08521342031744474
Validation loss: 2.4401243873107092

Epoch: 6| Step: 6
Training loss: 0.1427580208028191
Validation loss: 2.4265619501599347

Epoch: 6| Step: 7
Training loss: 0.0980139380677302
Validation loss: 2.4334336179104508

Epoch: 6| Step: 8
Training loss: 0.11430872899379799
Validation loss: 2.433060182995022

Epoch: 6| Step: 9
Training loss: 0.11042480232598055
Validation loss: 2.4649218755924123

Epoch: 6| Step: 10
Training loss: 0.13139140453463488
Validation loss: 2.438340238666346

Epoch: 6| Step: 11
Training loss: 0.15326383485933792
Validation loss: 2.4564773418039048

Epoch: 6| Step: 12
Training loss: 0.1374300369627773
Validation loss: 2.4583869067556487

Epoch: 6| Step: 13
Training loss: 0.08365694803325029
Validation loss: 2.4320371374781695

Epoch: 623| Step: 0
Training loss: 0.13193365643412966
Validation loss: 2.443099467444902

Epoch: 6| Step: 1
Training loss: 0.12662134097838784
Validation loss: 2.45090761824633

Epoch: 6| Step: 2
Training loss: 0.09637851718843696
Validation loss: 2.4485881019858042

Epoch: 6| Step: 3
Training loss: 0.1609742164394576
Validation loss: 2.4401151449993344

Epoch: 6| Step: 4
Training loss: 0.10511516092077021
Validation loss: 2.44366418290068

Epoch: 6| Step: 5
Training loss: 0.08701863052710938
Validation loss: 2.4123790890255066

Epoch: 6| Step: 6
Training loss: 0.10641230062543137
Validation loss: 2.4321255927702716

Epoch: 6| Step: 7
Training loss: 0.12294677795581048
Validation loss: 2.4109059741291223

Epoch: 6| Step: 8
Training loss: 0.12872828133735426
Validation loss: 2.408782617004674

Epoch: 6| Step: 9
Training loss: 0.15250606937134328
Validation loss: 2.3893046627379557

Epoch: 6| Step: 10
Training loss: 0.15195160916511322
Validation loss: 2.3821527480544313

Epoch: 6| Step: 11
Training loss: 0.1353783706164411
Validation loss: 2.4029958722100435

Epoch: 6| Step: 12
Training loss: 0.10656683223621466
Validation loss: 2.3815429301695996

Epoch: 6| Step: 13
Training loss: 0.13817001923114322
Validation loss: 2.398353965613692

Epoch: 624| Step: 0
Training loss: 0.13008232854517804
Validation loss: 2.3915149035872494

Epoch: 6| Step: 1
Training loss: 0.10061894958384361
Validation loss: 2.390312260694079

Epoch: 6| Step: 2
Training loss: 0.12397404310375817
Validation loss: 2.40008084479762

Epoch: 6| Step: 3
Training loss: 0.1418096329070099
Validation loss: 2.424384851582789

Epoch: 6| Step: 4
Training loss: 0.1344474062348993
Validation loss: 2.4621662500262085

Epoch: 6| Step: 5
Training loss: 0.12878890910210353
Validation loss: 2.4681535698450623

Epoch: 6| Step: 6
Training loss: 0.1756058930884177
Validation loss: 2.4588634235082294

Epoch: 6| Step: 7
Training loss: 0.10220751977501623
Validation loss: 2.4963828242394106

Epoch: 6| Step: 8
Training loss: 0.09799328817646429
Validation loss: 2.4673230195790627

Epoch: 6| Step: 9
Training loss: 0.10731622962963508
Validation loss: 2.4662480436702685

Epoch: 6| Step: 10
Training loss: 0.08412186601672686
Validation loss: 2.4671147534271185

Epoch: 6| Step: 11
Training loss: 0.13201487371921947
Validation loss: 2.4821639176695998

Epoch: 6| Step: 12
Training loss: 0.076620091459208
Validation loss: 2.4597913952017785

Epoch: 6| Step: 13
Training loss: 0.09764140016184296
Validation loss: 2.4350982741545506

Epoch: 625| Step: 0
Training loss: 0.13740114483991453
Validation loss: 2.432191947938879

Epoch: 6| Step: 1
Training loss: 0.09970951656341427
Validation loss: 2.427314259497081

Epoch: 6| Step: 2
Training loss: 0.1488890931011317
Validation loss: 2.430640827173485

Epoch: 6| Step: 3
Training loss: 0.08286606522766973
Validation loss: 2.420841226905002

Epoch: 6| Step: 4
Training loss: 0.13658652041975855
Validation loss: 2.4145926572272174

Epoch: 6| Step: 5
Training loss: 0.12212829738546309
Validation loss: 2.4291239309307913

Epoch: 6| Step: 6
Training loss: 0.09117731050372746
Validation loss: 2.4563454026936147

Epoch: 6| Step: 7
Training loss: 0.1521362211638635
Validation loss: 2.4388125566519876

Epoch: 6| Step: 8
Training loss: 0.11669121399563753
Validation loss: 2.4742308940040463

Epoch: 6| Step: 9
Training loss: 0.10365562149135618
Validation loss: 2.464263400978456

Epoch: 6| Step: 10
Training loss: 0.18168008027150118
Validation loss: 2.4481958220074365

Epoch: 6| Step: 11
Training loss: 0.09093546489031103
Validation loss: 2.443084062043962

Epoch: 6| Step: 12
Training loss: 0.16317579797538237
Validation loss: 2.4530280366880755

Epoch: 6| Step: 13
Training loss: 0.11872005100672044
Validation loss: 2.4504595477268447

Epoch: 626| Step: 0
Training loss: 0.07613561451875302
Validation loss: 2.4498960805287355

Epoch: 6| Step: 1
Training loss: 0.09237939574232004
Validation loss: 2.4129345154804978

Epoch: 6| Step: 2
Training loss: 0.09869186125710251
Validation loss: 2.4048132978864136

Epoch: 6| Step: 3
Training loss: 0.13228475679038482
Validation loss: 2.458324950301065

Epoch: 6| Step: 4
Training loss: 0.13699275216540158
Validation loss: 2.438574390887678

Epoch: 6| Step: 5
Training loss: 0.14963637125852877
Validation loss: 2.3888646700331653

Epoch: 6| Step: 6
Training loss: 0.11968591071485506
Validation loss: 2.4151572717823613

Epoch: 6| Step: 7
Training loss: 0.19184184625156075
Validation loss: 2.412211450292941

Epoch: 6| Step: 8
Training loss: 0.06774863165664803
Validation loss: 2.4149646161311233

Epoch: 6| Step: 9
Training loss: 0.1292626050266407
Validation loss: 2.4699869438498223

Epoch: 6| Step: 10
Training loss: 0.15322086729484774
Validation loss: 2.480167540191301

Epoch: 6| Step: 11
Training loss: 0.13242692234468914
Validation loss: 2.5063427419183917

Epoch: 6| Step: 12
Training loss: 0.12480843662248371
Validation loss: 2.500626989414483

Epoch: 6| Step: 13
Training loss: 0.1953924492282202
Validation loss: 2.5006174883634165

Epoch: 627| Step: 0
Training loss: 0.12242490003946689
Validation loss: 2.490792360407212

Epoch: 6| Step: 1
Training loss: 0.09173153520079601
Validation loss: 2.463389304391059

Epoch: 6| Step: 2
Training loss: 0.06897104650264019
Validation loss: 2.4581752084552795

Epoch: 6| Step: 3
Training loss: 0.08484418838609015
Validation loss: 2.4445103691281402

Epoch: 6| Step: 4
Training loss: 0.09789718470473141
Validation loss: 2.4398250381879483

Epoch: 6| Step: 5
Training loss: 0.1808437793837794
Validation loss: 2.4336258691189605

Epoch: 6| Step: 6
Training loss: 0.13142258871381543
Validation loss: 2.4176903580195317

Epoch: 6| Step: 7
Training loss: 0.10112178070439785
Validation loss: 2.4388836850284368

Epoch: 6| Step: 8
Training loss: 0.1370742535506968
Validation loss: 2.450371012493433

Epoch: 6| Step: 9
Training loss: 0.14355893031487194
Validation loss: 2.4523285559881236

Epoch: 6| Step: 10
Training loss: 0.07634981169918631
Validation loss: 2.442763573884076

Epoch: 6| Step: 11
Training loss: 0.1387535982696379
Validation loss: 2.441231627029526

Epoch: 6| Step: 12
Training loss: 0.10330218677137963
Validation loss: 2.471732260831088

Epoch: 6| Step: 13
Training loss: 0.1438252630368617
Validation loss: 2.4529546894484686

Epoch: 628| Step: 0
Training loss: 0.10552755235435686
Validation loss: 2.427662018124424

Epoch: 6| Step: 1
Training loss: 0.06090678256948474
Validation loss: 2.444323525080504

Epoch: 6| Step: 2
Training loss: 0.10601703860718603
Validation loss: 2.4345169482411446

Epoch: 6| Step: 3
Training loss: 0.11212492944562089
Validation loss: 2.428500230126966

Epoch: 6| Step: 4
Training loss: 0.07656553831689146
Validation loss: 2.4165087518522905

Epoch: 6| Step: 5
Training loss: 0.12756294359889783
Validation loss: 2.4336471966539497

Epoch: 6| Step: 6
Training loss: 0.1266098663798851
Validation loss: 2.4152268592719777

Epoch: 6| Step: 7
Training loss: 0.13920876172816288
Validation loss: 2.4136657808340733

Epoch: 6| Step: 8
Training loss: 0.12767127196127864
Validation loss: 2.4324255679808577

Epoch: 6| Step: 9
Training loss: 0.08226641371114336
Validation loss: 2.4208905545703963

Epoch: 6| Step: 10
Training loss: 0.1174145009941773
Validation loss: 2.4650097842044048

Epoch: 6| Step: 11
Training loss: 0.09941322517417121
Validation loss: 2.463195205805651

Epoch: 6| Step: 12
Training loss: 0.1244849681167387
Validation loss: 2.460745126002843

Epoch: 6| Step: 13
Training loss: 0.13284337161801513
Validation loss: 2.4599503643760263

Epoch: 629| Step: 0
Training loss: 0.09898066321039656
Validation loss: 2.4668634677336825

Epoch: 6| Step: 1
Training loss: 0.08184762395569471
Validation loss: 2.4561307754853474

Epoch: 6| Step: 2
Training loss: 0.11406182328114886
Validation loss: 2.4776256832520964

Epoch: 6| Step: 3
Training loss: 0.11277749421949762
Validation loss: 2.467041675878697

Epoch: 6| Step: 4
Training loss: 0.10507823029410039
Validation loss: 2.4221570726959283

Epoch: 6| Step: 5
Training loss: 0.07747072792798165
Validation loss: 2.4219248205188575

Epoch: 6| Step: 6
Training loss: 0.11172825032634394
Validation loss: 2.4201799529680845

Epoch: 6| Step: 7
Training loss: 0.08967358084905798
Validation loss: 2.4448850330751304

Epoch: 6| Step: 8
Training loss: 0.08894694071750768
Validation loss: 2.4643058896621537

Epoch: 6| Step: 9
Training loss: 0.11682638717257808
Validation loss: 2.4157967138455705

Epoch: 6| Step: 10
Training loss: 0.09286083321194252
Validation loss: 2.4400043427512585

Epoch: 6| Step: 11
Training loss: 0.110727946898087
Validation loss: 2.4297546666541048

Epoch: 6| Step: 12
Training loss: 0.09758281807956189
Validation loss: 2.418050567235641

Epoch: 6| Step: 13
Training loss: 0.05846033603479118
Validation loss: 2.43207286530326

Epoch: 630| Step: 0
Training loss: 0.08333644885954726
Validation loss: 2.439651586669773

Epoch: 6| Step: 1
Training loss: 0.08924469047936183
Validation loss: 2.419963119872954

Epoch: 6| Step: 2
Training loss: 0.09568914973146814
Validation loss: 2.419518310226616

Epoch: 6| Step: 3
Training loss: 0.09499266206328039
Validation loss: 2.440536284431273

Epoch: 6| Step: 4
Training loss: 0.12597556446478522
Validation loss: 2.4167444437967327

Epoch: 6| Step: 5
Training loss: 0.07891715595208401
Validation loss: 2.454260893430575

Epoch: 6| Step: 6
Training loss: 0.11014707574449706
Validation loss: 2.4617152464167043

Epoch: 6| Step: 7
Training loss: 0.10555194293377078
Validation loss: 2.501482136593771

Epoch: 6| Step: 8
Training loss: 0.11511687980613323
Validation loss: 2.476213533030342

Epoch: 6| Step: 9
Training loss: 0.06632885560148918
Validation loss: 2.4705128344958833

Epoch: 6| Step: 10
Training loss: 0.0923972836263788
Validation loss: 2.450960090095891

Epoch: 6| Step: 11
Training loss: 0.13821051641983043
Validation loss: 2.4567897435417274

Epoch: 6| Step: 12
Training loss: 0.11666275396413411
Validation loss: 2.4614177169560456

Epoch: 6| Step: 13
Training loss: 0.11057349902113611
Validation loss: 2.4356686464896056

Epoch: 631| Step: 0
Training loss: 0.09522271735086142
Validation loss: 2.426909982961229

Epoch: 6| Step: 1
Training loss: 0.08144729964029924
Validation loss: 2.4307665568546315

Epoch: 6| Step: 2
Training loss: 0.12174274362959588
Validation loss: 2.4207169224065685

Epoch: 6| Step: 3
Training loss: 0.11296919065471303
Validation loss: 2.4211404724571546

Epoch: 6| Step: 4
Training loss: 0.07984689730583114
Validation loss: 2.4229737651686296

Epoch: 6| Step: 5
Training loss: 0.11589990393132284
Validation loss: 2.440564583686874

Epoch: 6| Step: 6
Training loss: 0.0942319858009691
Validation loss: 2.431816344656413

Epoch: 6| Step: 7
Training loss: 0.08341174298711379
Validation loss: 2.439868034406458

Epoch: 6| Step: 8
Training loss: 0.12353802100919628
Validation loss: 2.407361602040677

Epoch: 6| Step: 9
Training loss: 0.1116418100057915
Validation loss: 2.465819345606246

Epoch: 6| Step: 10
Training loss: 0.09764627405711088
Validation loss: 2.4863172861051535

Epoch: 6| Step: 11
Training loss: 0.06309198374163019
Validation loss: 2.4779285749433257

Epoch: 6| Step: 12
Training loss: 0.08684089613453512
Validation loss: 2.501291474680296

Epoch: 6| Step: 13
Training loss: 0.13215562419197455
Validation loss: 2.472849588346328

Epoch: 632| Step: 0
Training loss: 0.1382627900512249
Validation loss: 2.4574252377665644

Epoch: 6| Step: 1
Training loss: 0.13777718916636633
Validation loss: 2.4768943586273484

Epoch: 6| Step: 2
Training loss: 0.10905090065404471
Validation loss: 2.458437893581628

Epoch: 6| Step: 3
Training loss: 0.11610273725601836
Validation loss: 2.4604831289769273

Epoch: 6| Step: 4
Training loss: 0.11935676449156785
Validation loss: 2.458853098499417

Epoch: 6| Step: 5
Training loss: 0.07400276730895046
Validation loss: 2.4109621864908215

Epoch: 6| Step: 6
Training loss: 0.15069407032946056
Validation loss: 2.4278028987322835

Epoch: 6| Step: 7
Training loss: 0.09975859740500637
Validation loss: 2.429604674432028

Epoch: 6| Step: 8
Training loss: 0.10261001856651301
Validation loss: 2.421318941458289

Epoch: 6| Step: 9
Training loss: 0.09578546076848662
Validation loss: 2.4495031999535297

Epoch: 6| Step: 10
Training loss: 0.08369534126031275
Validation loss: 2.4563573460262824

Epoch: 6| Step: 11
Training loss: 0.08309352600674316
Validation loss: 2.4277097298694295

Epoch: 6| Step: 12
Training loss: 0.13780685398101455
Validation loss: 2.441652069907729

Epoch: 6| Step: 13
Training loss: 0.13513912053791882
Validation loss: 2.437407665118254

Epoch: 633| Step: 0
Training loss: 0.11121187498436468
Validation loss: 2.4550048416207244

Epoch: 6| Step: 1
Training loss: 0.053297873376102735
Validation loss: 2.4346690001793565

Epoch: 6| Step: 2
Training loss: 0.07293049292382708
Validation loss: 2.433836302067352

Epoch: 6| Step: 3
Training loss: 0.09907948508545081
Validation loss: 2.425613186924875

Epoch: 6| Step: 4
Training loss: 0.09859108750485945
Validation loss: 2.4238418251229428

Epoch: 6| Step: 5
Training loss: 0.11765699909422613
Validation loss: 2.4027468099354414

Epoch: 6| Step: 6
Training loss: 0.1009294975728388
Validation loss: 2.4035585626887377

Epoch: 6| Step: 7
Training loss: 0.0835109440943221
Validation loss: 2.382016164233546

Epoch: 6| Step: 8
Training loss: 0.1293399263721389
Validation loss: 2.4079152569512594

Epoch: 6| Step: 9
Training loss: 0.09013234827392094
Validation loss: 2.393686520642348

Epoch: 6| Step: 10
Training loss: 0.07435348478034695
Validation loss: 2.406209709086923

Epoch: 6| Step: 11
Training loss: 0.12148809442621993
Validation loss: 2.4164868635503756

Epoch: 6| Step: 12
Training loss: 0.10551312625642892
Validation loss: 2.4289150344177406

Epoch: 6| Step: 13
Training loss: 0.13546173708933995
Validation loss: 2.434928804237636

Epoch: 634| Step: 0
Training loss: 0.09931861289844697
Validation loss: 2.4637656768314886

Epoch: 6| Step: 1
Training loss: 0.08121764221881668
Validation loss: 2.4501577196801407

Epoch: 6| Step: 2
Training loss: 0.09144246899902522
Validation loss: 2.4475972243169504

Epoch: 6| Step: 3
Training loss: 0.1103781144935601
Validation loss: 2.4773931083791823

Epoch: 6| Step: 4
Training loss: 0.1135544770418939
Validation loss: 2.4608756483892775

Epoch: 6| Step: 5
Training loss: 0.11681457627799935
Validation loss: 2.483794655802547

Epoch: 6| Step: 6
Training loss: 0.08714555333339365
Validation loss: 2.466582075773235

Epoch: 6| Step: 7
Training loss: 0.11521698125397783
Validation loss: 2.4682081829182305

Epoch: 6| Step: 8
Training loss: 0.09432440365402621
Validation loss: 2.4438850581827074

Epoch: 6| Step: 9
Training loss: 0.0998188882119921
Validation loss: 2.430911297720753

Epoch: 6| Step: 10
Training loss: 0.08042823039842897
Validation loss: 2.4412271040623796

Epoch: 6| Step: 11
Training loss: 0.07906627456603565
Validation loss: 2.4552847694456155

Epoch: 6| Step: 12
Training loss: 0.11473564343853289
Validation loss: 2.422161478861977

Epoch: 6| Step: 13
Training loss: 0.09439267472206146
Validation loss: 2.4012663987901695

Epoch: 635| Step: 0
Training loss: 0.10318518926746936
Validation loss: 2.399893929844778

Epoch: 6| Step: 1
Training loss: 0.10123210130656117
Validation loss: 2.386634143760826

Epoch: 6| Step: 2
Training loss: 0.14132261753685604
Validation loss: 2.383345609834518

Epoch: 6| Step: 3
Training loss: 0.11519054613830726
Validation loss: 2.383441598717723

Epoch: 6| Step: 4
Training loss: 0.1396528790174438
Validation loss: 2.389948182419789

Epoch: 6| Step: 5
Training loss: 0.1007405269022969
Validation loss: 2.392003062663002

Epoch: 6| Step: 6
Training loss: 0.046275701183915545
Validation loss: 2.3965895634090293

Epoch: 6| Step: 7
Training loss: 0.09516284207277939
Validation loss: 2.415700283967323

Epoch: 6| Step: 8
Training loss: 0.09027485455564933
Validation loss: 2.4024411823087846

Epoch: 6| Step: 9
Training loss: 0.08510003268478553
Validation loss: 2.4123380253305258

Epoch: 6| Step: 10
Training loss: 0.0962972446006232
Validation loss: 2.410665528780504

Epoch: 6| Step: 11
Training loss: 0.12539290726150376
Validation loss: 2.401160831246819

Epoch: 6| Step: 12
Training loss: 0.12376748354065009
Validation loss: 2.4007028074510997

Epoch: 6| Step: 13
Training loss: 0.06319816132517972
Validation loss: 2.4163567411836446

Epoch: 636| Step: 0
Training loss: 0.09927075461180702
Validation loss: 2.4337986519600943

Epoch: 6| Step: 1
Training loss: 0.08923921161716832
Validation loss: 2.435168286664566

Epoch: 6| Step: 2
Training loss: 0.11231264003294895
Validation loss: 2.414070708414904

Epoch: 6| Step: 3
Training loss: 0.0867646519001684
Validation loss: 2.385270530464824

Epoch: 6| Step: 4
Training loss: 0.12359079608208508
Validation loss: 2.3919142618469325

Epoch: 6| Step: 5
Training loss: 0.10598330897037361
Validation loss: 2.407659724173699

Epoch: 6| Step: 6
Training loss: 0.09946941378686856
Validation loss: 2.4091345782422033

Epoch: 6| Step: 7
Training loss: 0.12369525848008744
Validation loss: 2.4131737637606885

Epoch: 6| Step: 8
Training loss: 0.08646937526239688
Validation loss: 2.439343817617203

Epoch: 6| Step: 9
Training loss: 0.07603651944086649
Validation loss: 2.4141211981280524

Epoch: 6| Step: 10
Training loss: 0.12214252624749733
Validation loss: 2.4332551071543547

Epoch: 6| Step: 11
Training loss: 0.09920479383460376
Validation loss: 2.435893623011455

Epoch: 6| Step: 12
Training loss: 0.07656994754224382
Validation loss: 2.4415071488726783

Epoch: 6| Step: 13
Training loss: 0.09278967865780041
Validation loss: 2.429961640494799

Epoch: 637| Step: 0
Training loss: 0.0674880077385001
Validation loss: 2.460093212606044

Epoch: 6| Step: 1
Training loss: 0.06912679089331086
Validation loss: 2.4735518030280654

Epoch: 6| Step: 2
Training loss: 0.08940157716907221
Validation loss: 2.4393733040840404

Epoch: 6| Step: 3
Training loss: 0.0714981657285591
Validation loss: 2.4651724086922675

Epoch: 6| Step: 4
Training loss: 0.1498904021535947
Validation loss: 2.4630587257794234

Epoch: 6| Step: 5
Training loss: 0.09849751039719605
Validation loss: 2.438397145931968

Epoch: 6| Step: 6
Training loss: 0.1015356009881623
Validation loss: 2.4310772049973637

Epoch: 6| Step: 7
Training loss: 0.1085070804489131
Validation loss: 2.40231086981244

Epoch: 6| Step: 8
Training loss: 0.07628531445321723
Validation loss: 2.4360877679636634

Epoch: 6| Step: 9
Training loss: 0.10568304719855862
Validation loss: 2.4348977046422178

Epoch: 6| Step: 10
Training loss: 0.08231122625961405
Validation loss: 2.413737216369968

Epoch: 6| Step: 11
Training loss: 0.10862337435613226
Validation loss: 2.4317470141955417

Epoch: 6| Step: 12
Training loss: 0.11692782878284108
Validation loss: 2.4100299897266337

Epoch: 6| Step: 13
Training loss: 0.10230728020137392
Validation loss: 2.430692730709444

Epoch: 638| Step: 0
Training loss: 0.05904880882199527
Validation loss: 2.4182263420226846

Epoch: 6| Step: 1
Training loss: 0.09902515372269431
Validation loss: 2.4139452842521605

Epoch: 6| Step: 2
Training loss: 0.09945472230550008
Validation loss: 2.4261134642452338

Epoch: 6| Step: 3
Training loss: 0.1072231187944915
Validation loss: 2.4020513802667964

Epoch: 6| Step: 4
Training loss: 0.08735489489690933
Validation loss: 2.409328984383122

Epoch: 6| Step: 5
Training loss: 0.10477545480888847
Validation loss: 2.4094328182912093

Epoch: 6| Step: 6
Training loss: 0.06786769748670464
Validation loss: 2.415949016014319

Epoch: 6| Step: 7
Training loss: 0.1062359106315023
Validation loss: 2.4212997764313284

Epoch: 6| Step: 8
Training loss: 0.0802393139987717
Validation loss: 2.4326538268130875

Epoch: 6| Step: 9
Training loss: 0.08386568065439194
Validation loss: 2.403048534108341

Epoch: 6| Step: 10
Training loss: 0.12094234799985944
Validation loss: 2.3797963074946153

Epoch: 6| Step: 11
Training loss: 0.07441119916918867
Validation loss: 2.418213512263645

Epoch: 6| Step: 12
Training loss: 0.08128526935407286
Validation loss: 2.442368801767048

Epoch: 6| Step: 13
Training loss: 0.05128532121105745
Validation loss: 2.4227510675876833

Epoch: 639| Step: 0
Training loss: 0.07306402790407067
Validation loss: 2.42881198378306

Epoch: 6| Step: 1
Training loss: 0.11284552006375123
Validation loss: 2.4276960024702054

Epoch: 6| Step: 2
Training loss: 0.09834122756241973
Validation loss: 2.4265396602124043

Epoch: 6| Step: 3
Training loss: 0.08957074503372041
Validation loss: 2.395710604298731

Epoch: 6| Step: 4
Training loss: 0.08883109250475747
Validation loss: 2.4429438328561095

Epoch: 6| Step: 5
Training loss: 0.08221952652899801
Validation loss: 2.4143250375698635

Epoch: 6| Step: 6
Training loss: 0.10330203350748457
Validation loss: 2.4283380970243877

Epoch: 6| Step: 7
Training loss: 0.1072341535830807
Validation loss: 2.452863104609945

Epoch: 6| Step: 8
Training loss: 0.10306453485544749
Validation loss: 2.442055384552398

Epoch: 6| Step: 9
Training loss: 0.07694954222360324
Validation loss: 2.454463593787061

Epoch: 6| Step: 10
Training loss: 0.09253931620358961
Validation loss: 2.435701791826539

Epoch: 6| Step: 11
Training loss: 0.11737806402621082
Validation loss: 2.4485004785746955

Epoch: 6| Step: 12
Training loss: 0.06428840932005488
Validation loss: 2.421984492435836

Epoch: 6| Step: 13
Training loss: 0.0730905234133131
Validation loss: 2.4240421703947153

Epoch: 640| Step: 0
Training loss: 0.1292701915509351
Validation loss: 2.4515016701371555

Epoch: 6| Step: 1
Training loss: 0.06037592982357081
Validation loss: 2.4394804757764765

Epoch: 6| Step: 2
Training loss: 0.09200047174234312
Validation loss: 2.437340618904112

Epoch: 6| Step: 3
Training loss: 0.09428408601596526
Validation loss: 2.4236414262683064

Epoch: 6| Step: 4
Training loss: 0.07448824466498576
Validation loss: 2.4230047427185317

Epoch: 6| Step: 5
Training loss: 0.09383006948287326
Validation loss: 2.4209788537758152

Epoch: 6| Step: 6
Training loss: 0.0795854965146067
Validation loss: 2.41777991448211

Epoch: 6| Step: 7
Training loss: 0.15222899687800065
Validation loss: 2.428809712319783

Epoch: 6| Step: 8
Training loss: 0.10457719037105544
Validation loss: 2.3934399704783935

Epoch: 6| Step: 9
Training loss: 0.10265032317849981
Validation loss: 2.4181082350636043

Epoch: 6| Step: 10
Training loss: 0.09358637159746662
Validation loss: 2.4360872670403864

Epoch: 6| Step: 11
Training loss: 0.06221642460709442
Validation loss: 2.4330632944782518

Epoch: 6| Step: 12
Training loss: 0.09971497118325279
Validation loss: 2.433530050918305

Epoch: 6| Step: 13
Training loss: 0.13257761829843617
Validation loss: 2.4493838055405512

Epoch: 641| Step: 0
Training loss: 0.10654141523730364
Validation loss: 2.448580818084353

Epoch: 6| Step: 1
Training loss: 0.11705973335862403
Validation loss: 2.4398528292565436

Epoch: 6| Step: 2
Training loss: 0.13915081327428916
Validation loss: 2.4426188888212104

Epoch: 6| Step: 3
Training loss: 0.10271335502803439
Validation loss: 2.4382124291685066

Epoch: 6| Step: 4
Training loss: 0.08347019831326709
Validation loss: 2.414852651392414

Epoch: 6| Step: 5
Training loss: 0.10124014167711487
Validation loss: 2.3878201974416062

Epoch: 6| Step: 6
Training loss: 0.11950240161060625
Validation loss: 2.4139764753646986

Epoch: 6| Step: 7
Training loss: 0.05676651808469038
Validation loss: 2.4083833776617425

Epoch: 6| Step: 8
Training loss: 0.10000879483738433
Validation loss: 2.387653249851628

Epoch: 6| Step: 9
Training loss: 0.08573048214098208
Validation loss: 2.3788100199123194

Epoch: 6| Step: 10
Training loss: 0.10469683545037312
Validation loss: 2.4311157582601988

Epoch: 6| Step: 11
Training loss: 0.09798293783648285
Validation loss: 2.4295138465273984

Epoch: 6| Step: 12
Training loss: 0.08458238431831923
Validation loss: 2.444820123442529

Epoch: 6| Step: 13
Training loss: 0.13114966746970547
Validation loss: 2.4216415700315044

Epoch: 642| Step: 0
Training loss: 0.09476762058770255
Validation loss: 2.424535662105389

Epoch: 6| Step: 1
Training loss: 0.09732975741340406
Validation loss: 2.4413335317631315

Epoch: 6| Step: 2
Training loss: 0.11145063820089729
Validation loss: 2.445141505841753

Epoch: 6| Step: 3
Training loss: 0.08374813031486665
Validation loss: 2.4263327537068338

Epoch: 6| Step: 4
Training loss: 0.09650777695132588
Validation loss: 2.459033775203156

Epoch: 6| Step: 5
Training loss: 0.13158681431893623
Validation loss: 2.4557604339446066

Epoch: 6| Step: 6
Training loss: 0.07353013022725681
Validation loss: 2.4231049388055363

Epoch: 6| Step: 7
Training loss: 0.09077912083556629
Validation loss: 2.473010778821554

Epoch: 6| Step: 8
Training loss: 0.08962881251596456
Validation loss: 2.4591356808379823

Epoch: 6| Step: 9
Training loss: 0.08461570479631597
Validation loss: 2.4602864461765614

Epoch: 6| Step: 10
Training loss: 0.08630010929173265
Validation loss: 2.4234070683823554

Epoch: 6| Step: 11
Training loss: 0.06109554164666724
Validation loss: 2.4558316101108035

Epoch: 6| Step: 12
Training loss: 0.09043302303284231
Validation loss: 2.4550584883723676

Epoch: 6| Step: 13
Training loss: 0.06678188194748834
Validation loss: 2.442066460316428

Epoch: 643| Step: 0
Training loss: 0.10469491402150476
Validation loss: 2.416503093079008

Epoch: 6| Step: 1
Training loss: 0.0546136169668839
Validation loss: 2.4091400297915833

Epoch: 6| Step: 2
Training loss: 0.07462072061484246
Validation loss: 2.4198448201129654

Epoch: 6| Step: 3
Training loss: 0.07506313721174317
Validation loss: 2.412891964740544

Epoch: 6| Step: 4
Training loss: 0.08046400324700417
Validation loss: 2.42179091642021

Epoch: 6| Step: 5
Training loss: 0.0452273751065753
Validation loss: 2.420721786581103

Epoch: 6| Step: 6
Training loss: 0.08049281255884222
Validation loss: 2.4005001682624094

Epoch: 6| Step: 7
Training loss: 0.07909002926423618
Validation loss: 2.3689798290847497

Epoch: 6| Step: 8
Training loss: 0.06437750917933333
Validation loss: 2.399713201887873

Epoch: 6| Step: 9
Training loss: 0.09707318767994579
Validation loss: 2.3709314273215436

Epoch: 6| Step: 10
Training loss: 0.10213632967727418
Validation loss: 2.3823988355205703

Epoch: 6| Step: 11
Training loss: 0.10010214074486666
Validation loss: 2.359799481689318

Epoch: 6| Step: 12
Training loss: 0.12687759353307657
Validation loss: 2.369665100619523

Epoch: 6| Step: 13
Training loss: 0.07020646285334939
Validation loss: 2.402556750531401

Epoch: 644| Step: 0
Training loss: 0.049817462292562315
Validation loss: 2.413795345699524

Epoch: 6| Step: 1
Training loss: 0.07734207406781014
Validation loss: 2.384838808766674

Epoch: 6| Step: 2
Training loss: 0.0721553721810263
Validation loss: 2.4151158562010036

Epoch: 6| Step: 3
Training loss: 0.1161860351167482
Validation loss: 2.4132517519056305

Epoch: 6| Step: 4
Training loss: 0.08798237356322239
Validation loss: 2.401614966716657

Epoch: 6| Step: 5
Training loss: 0.11048226507192857
Validation loss: 2.4188591356122116

Epoch: 6| Step: 6
Training loss: 0.1338144960383747
Validation loss: 2.4014402854130785

Epoch: 6| Step: 7
Training loss: 0.06822976017771477
Validation loss: 2.406426798144278

Epoch: 6| Step: 8
Training loss: 0.09971963165799602
Validation loss: 2.41599917679149

Epoch: 6| Step: 9
Training loss: 0.11027331236353499
Validation loss: 2.429443003496002

Epoch: 6| Step: 10
Training loss: 0.0812291657347205
Validation loss: 2.4288311581416626

Epoch: 6| Step: 11
Training loss: 0.09175835470832694
Validation loss: 2.426884935968464

Epoch: 6| Step: 12
Training loss: 0.055988657836509886
Validation loss: 2.4268368895120673

Epoch: 6| Step: 13
Training loss: 0.09516879215173157
Validation loss: 2.4251933392785645

Epoch: 645| Step: 0
Training loss: 0.0873661765598063
Validation loss: 2.413578138707385

Epoch: 6| Step: 1
Training loss: 0.09486686992709914
Validation loss: 2.4191489028277053

Epoch: 6| Step: 2
Training loss: 0.09835076844372631
Validation loss: 2.403387134417391

Epoch: 6| Step: 3
Training loss: 0.08045475766367673
Validation loss: 2.411141707645835

Epoch: 6| Step: 4
Training loss: 0.10038154167613643
Validation loss: 2.3776061682486076

Epoch: 6| Step: 5
Training loss: 0.10215870384426895
Validation loss: 2.4083350121288265

Epoch: 6| Step: 6
Training loss: 0.13692380650085317
Validation loss: 2.3706829329210293

Epoch: 6| Step: 7
Training loss: 0.07035448886899977
Validation loss: 2.4109836390129744

Epoch: 6| Step: 8
Training loss: 0.0859953945390536
Validation loss: 2.429823450988837

Epoch: 6| Step: 9
Training loss: 0.08014999630162652
Validation loss: 2.4143321367942483

Epoch: 6| Step: 10
Training loss: 0.07502580710302352
Validation loss: 2.4197692883902415

Epoch: 6| Step: 11
Training loss: 0.09706781487734444
Validation loss: 2.430719422433539

Epoch: 6| Step: 12
Training loss: 0.08440217070730174
Validation loss: 2.430594433904722

Epoch: 6| Step: 13
Training loss: 0.062136876717163586
Validation loss: 2.4583135791427737

Epoch: 646| Step: 0
Training loss: 0.10298647228050666
Validation loss: 2.4211789801193295

Epoch: 6| Step: 1
Training loss: 0.06950172898638432
Validation loss: 2.4278222098853868

Epoch: 6| Step: 2
Training loss: 0.11539033260837875
Validation loss: 2.4262086116890393

Epoch: 6| Step: 3
Training loss: 0.07702455956806092
Validation loss: 2.4416537897440374

Epoch: 6| Step: 4
Training loss: 0.11029363901195734
Validation loss: 2.437316388560353

Epoch: 6| Step: 5
Training loss: 0.12344778688035712
Validation loss: 2.440516788158855

Epoch: 6| Step: 6
Training loss: 0.05356613276516202
Validation loss: 2.4562599691471374

Epoch: 6| Step: 7
Training loss: 0.07055959728342295
Validation loss: 2.4391145399531196

Epoch: 6| Step: 8
Training loss: 0.09604533476127462
Validation loss: 2.4458968990835617

Epoch: 6| Step: 9
Training loss: 0.045743968942778615
Validation loss: 2.4514903415773954

Epoch: 6| Step: 10
Training loss: 0.10288980532922884
Validation loss: 2.443986164161737

Epoch: 6| Step: 11
Training loss: 0.07180856817037827
Validation loss: 2.4465080703064355

Epoch: 6| Step: 12
Training loss: 0.0954235918625485
Validation loss: 2.4514546823637584

Epoch: 6| Step: 13
Training loss: 0.114497093146346
Validation loss: 2.44013951354847

Epoch: 647| Step: 0
Training loss: 0.08971869016065366
Validation loss: 2.443473410812398

Epoch: 6| Step: 1
Training loss: 0.1200481619646132
Validation loss: 2.4204610750767324

Epoch: 6| Step: 2
Training loss: 0.09754028587658779
Validation loss: 2.459617857579207

Epoch: 6| Step: 3
Training loss: 0.08716838039956577
Validation loss: 2.4342932556894037

Epoch: 6| Step: 4
Training loss: 0.08147836170154105
Validation loss: 2.435972312947851

Epoch: 6| Step: 5
Training loss: 0.10295709592514186
Validation loss: 2.426092282349394

Epoch: 6| Step: 6
Training loss: 0.07983512177663284
Validation loss: 2.417456782736124

Epoch: 6| Step: 7
Training loss: 0.06519107580846917
Validation loss: 2.4362862296605234

Epoch: 6| Step: 8
Training loss: 0.06504857749758963
Validation loss: 2.411434646462116

Epoch: 6| Step: 9
Training loss: 0.09692209852390568
Validation loss: 2.4081531089620962

Epoch: 6| Step: 10
Training loss: 0.1028253373795782
Validation loss: 2.4099199982299835

Epoch: 6| Step: 11
Training loss: 0.08127853208945415
Validation loss: 2.414164755137295

Epoch: 6| Step: 12
Training loss: 0.06360194221423532
Validation loss: 2.385058874356936

Epoch: 6| Step: 13
Training loss: 0.08614944472588537
Validation loss: 2.403614791694384

Epoch: 648| Step: 0
Training loss: 0.07338405856050596
Validation loss: 2.393195077803152

Epoch: 6| Step: 1
Training loss: 0.08147300928513702
Validation loss: 2.4238504927666917

Epoch: 6| Step: 2
Training loss: 0.09815902982441428
Validation loss: 2.442440177153052

Epoch: 6| Step: 3
Training loss: 0.1087401005950091
Validation loss: 2.4508562864796466

Epoch: 6| Step: 4
Training loss: 0.06239901893486203
Validation loss: 2.4293516916380318

Epoch: 6| Step: 5
Training loss: 0.14139348889301362
Validation loss: 2.4457627828401747

Epoch: 6| Step: 6
Training loss: 0.07658314937328878
Validation loss: 2.4321910319732893

Epoch: 6| Step: 7
Training loss: 0.07867083604689137
Validation loss: 2.4480989299741354

Epoch: 6| Step: 8
Training loss: 0.06675838621996782
Validation loss: 2.422444878098402

Epoch: 6| Step: 9
Training loss: 0.10608134909335096
Validation loss: 2.424430802186718

Epoch: 6| Step: 10
Training loss: 0.07261565853723398
Validation loss: 2.4116491253213894

Epoch: 6| Step: 11
Training loss: 0.08927446873554051
Validation loss: 2.441759320068063

Epoch: 6| Step: 12
Training loss: 0.0888710440333356
Validation loss: 2.4409491213501453

Epoch: 6| Step: 13
Training loss: 0.07325575702851396
Validation loss: 2.431011866576863

Epoch: 649| Step: 0
Training loss: 0.06674788753376089
Validation loss: 2.4420059915236814

Epoch: 6| Step: 1
Training loss: 0.11211720864577057
Validation loss: 2.448916390066896

Epoch: 6| Step: 2
Training loss: 0.04549170421826452
Validation loss: 2.4312069718333325

Epoch: 6| Step: 3
Training loss: 0.10679831722907014
Validation loss: 2.413164469222744

Epoch: 6| Step: 4
Training loss: 0.10606766124355596
Validation loss: 2.4278489409224244

Epoch: 6| Step: 5
Training loss: 0.10442547138932848
Validation loss: 2.411453544381427

Epoch: 6| Step: 6
Training loss: 0.06071624792289346
Validation loss: 2.4105350379348054

Epoch: 6| Step: 7
Training loss: 0.06833159018295523
Validation loss: 2.3788884977200353

Epoch: 6| Step: 8
Training loss: 0.14648395538269976
Validation loss: 2.389523198577436

Epoch: 6| Step: 9
Training loss: 0.0704860730352492
Validation loss: 2.3761423674191064

Epoch: 6| Step: 10
Training loss: 0.06892650904369851
Validation loss: 2.4226242044527337

Epoch: 6| Step: 11
Training loss: 0.0892860007068604
Validation loss: 2.406418249914591

Epoch: 6| Step: 12
Training loss: 0.0773707668965646
Validation loss: 2.4142308701957917

Epoch: 6| Step: 13
Training loss: 0.049290340919289084
Validation loss: 2.4252978221612587

Epoch: 650| Step: 0
Training loss: 0.09807624623934806
Validation loss: 2.4230266551970203

Epoch: 6| Step: 1
Training loss: 0.0869186351944814
Validation loss: 2.4168891753030795

Epoch: 6| Step: 2
Training loss: 0.08508864483980098
Validation loss: 2.421620929687739

Epoch: 6| Step: 3
Training loss: 0.177201877680086
Validation loss: 2.422829693407975

Epoch: 6| Step: 4
Training loss: 0.11737207738119042
Validation loss: 2.4092598139142867

Epoch: 6| Step: 5
Training loss: 0.059708409800414516
Validation loss: 2.395969716203384

Epoch: 6| Step: 6
Training loss: 0.06697852715552302
Validation loss: 2.3979982604067582

Epoch: 6| Step: 7
Training loss: 0.10124252422720377
Validation loss: 2.365597461411134

Epoch: 6| Step: 8
Training loss: 0.16449054441806796
Validation loss: 2.3752953281513616

Epoch: 6| Step: 9
Training loss: 0.09642752119058808
Validation loss: 2.357369726667781

Epoch: 6| Step: 10
Training loss: 0.06598529203447488
Validation loss: 2.388846608098819

Epoch: 6| Step: 11
Training loss: 0.08706242510641071
Validation loss: 2.418856930582289

Epoch: 6| Step: 12
Training loss: 0.07473454249337529
Validation loss: 2.431309535036292

Epoch: 6| Step: 13
Training loss: 0.0862771469521913
Validation loss: 2.439816721505442

Epoch: 651| Step: 0
Training loss: 0.08699853681647282
Validation loss: 2.4324474326121654

Epoch: 6| Step: 1
Training loss: 0.06722159380064595
Validation loss: 2.453399483999157

Epoch: 6| Step: 2
Training loss: 0.11468317457664506
Validation loss: 2.4672554116131313

Epoch: 6| Step: 3
Training loss: 0.11595644854501506
Validation loss: 2.4549799183616763

Epoch: 6| Step: 4
Training loss: 0.11771813497061152
Validation loss: 2.4739110377162006

Epoch: 6| Step: 5
Training loss: 0.11127899156489215
Validation loss: 2.4688304899943776

Epoch: 6| Step: 6
Training loss: 0.08427264398265073
Validation loss: 2.45806360998485

Epoch: 6| Step: 7
Training loss: 0.0644094904670219
Validation loss: 2.4463342904256202

Epoch: 6| Step: 8
Training loss: 0.0754419776963203
Validation loss: 2.4269507710517306

Epoch: 6| Step: 9
Training loss: 0.10524000865013743
Validation loss: 2.41257766217351

Epoch: 6| Step: 10
Training loss: 0.08781804160623169
Validation loss: 2.412959024128148

Epoch: 6| Step: 11
Training loss: 0.08412960990292319
Validation loss: 2.3901137635700307

Epoch: 6| Step: 12
Training loss: 0.07489439276778596
Validation loss: 2.391590596851154

Epoch: 6| Step: 13
Training loss: 0.06605983937936372
Validation loss: 2.393781951889822

Epoch: 652| Step: 0
Training loss: 0.10957944869304402
Validation loss: 2.378569808126515

Epoch: 6| Step: 1
Training loss: 0.10269078428631559
Validation loss: 2.3994116275138655

Epoch: 6| Step: 2
Training loss: 0.06816230706083189
Validation loss: 2.392043949757126

Epoch: 6| Step: 3
Training loss: 0.13221844179130593
Validation loss: 2.3955984743273677

Epoch: 6| Step: 4
Training loss: 0.0799438641988353
Validation loss: 2.410078368048218

Epoch: 6| Step: 5
Training loss: 0.09136834968685605
Validation loss: 2.42881109081959

Epoch: 6| Step: 6
Training loss: 0.10031395314700065
Validation loss: 2.436766801042531

Epoch: 6| Step: 7
Training loss: 0.07228608421733962
Validation loss: 2.473788133000744

Epoch: 6| Step: 8
Training loss: 0.08982021604056487
Validation loss: 2.453665311267102

Epoch: 6| Step: 9
Training loss: 0.07309772868334528
Validation loss: 2.4775246442116674

Epoch: 6| Step: 10
Training loss: 0.11458072514888988
Validation loss: 2.4395113939961215

Epoch: 6| Step: 11
Training loss: 0.09964235077844429
Validation loss: 2.46334316988306

Epoch: 6| Step: 12
Training loss: 0.10279568394795609
Validation loss: 2.4504549141571452

Epoch: 6| Step: 13
Training loss: 0.06343213507323937
Validation loss: 2.4500163378284827

Epoch: 653| Step: 0
Training loss: 0.09541558842729979
Validation loss: 2.4294056030663427

Epoch: 6| Step: 1
Training loss: 0.1027770414340359
Validation loss: 2.4213890898171027

Epoch: 6| Step: 2
Training loss: 0.06970790698954174
Validation loss: 2.4213079767224666

Epoch: 6| Step: 3
Training loss: 0.11234700193592954
Validation loss: 2.402909486061236

Epoch: 6| Step: 4
Training loss: 0.09064448163672915
Validation loss: 2.375768253354141

Epoch: 6| Step: 5
Training loss: 0.08797007254831046
Validation loss: 2.399937948562168

Epoch: 6| Step: 6
Training loss: 0.09761218984388273
Validation loss: 2.4013033157470502

Epoch: 6| Step: 7
Training loss: 0.06891004968188087
Validation loss: 2.443811053108826

Epoch: 6| Step: 8
Training loss: 0.10889375347455356
Validation loss: 2.432542712103438

Epoch: 6| Step: 9
Training loss: 0.0922973362388213
Validation loss: 2.425246132277298

Epoch: 6| Step: 10
Training loss: 0.06503555099355592
Validation loss: 2.4343071401881877

Epoch: 6| Step: 11
Training loss: 0.12955275165008928
Validation loss: 2.4410698472451435

Epoch: 6| Step: 12
Training loss: 0.09957871713257242
Validation loss: 2.4332110595352496

Epoch: 6| Step: 13
Training loss: 0.09906484859071212
Validation loss: 2.4389097314169916

Epoch: 654| Step: 0
Training loss: 0.08464809347240353
Validation loss: 2.4549110598470514

Epoch: 6| Step: 1
Training loss: 0.11101655695267003
Validation loss: 2.4281518305807532

Epoch: 6| Step: 2
Training loss: 0.0813111075444079
Validation loss: 2.4463953166185957

Epoch: 6| Step: 3
Training loss: 0.05785662595740178
Validation loss: 2.44616227355513

Epoch: 6| Step: 4
Training loss: 0.06738768090062139
Validation loss: 2.433477295940573

Epoch: 6| Step: 5
Training loss: 0.08647149972693258
Validation loss: 2.417087840365529

Epoch: 6| Step: 6
Training loss: 0.09351412584701381
Validation loss: 2.398958300946192

Epoch: 6| Step: 7
Training loss: 0.12380457888904342
Validation loss: 2.3965814250897406

Epoch: 6| Step: 8
Training loss: 0.09774791230413826
Validation loss: 2.3808485663468795

Epoch: 6| Step: 9
Training loss: 0.08714820099186833
Validation loss: 2.4052405859039823

Epoch: 6| Step: 10
Training loss: 0.07901744431827719
Validation loss: 2.407955116886973

Epoch: 6| Step: 11
Training loss: 0.1289060910541826
Validation loss: 2.391342569059767

Epoch: 6| Step: 12
Training loss: 0.1295001984041491
Validation loss: 2.395016993853847

Epoch: 6| Step: 13
Training loss: 0.05769466186058425
Validation loss: 2.3849944078455505

Epoch: 655| Step: 0
Training loss: 0.06387571137969028
Validation loss: 2.429020873327174

Epoch: 6| Step: 1
Training loss: 0.08219604741458574
Validation loss: 2.415421138059644

Epoch: 6| Step: 2
Training loss: 0.05399494079477136
Validation loss: 2.42205186423672

Epoch: 6| Step: 3
Training loss: 0.06585431734532664
Validation loss: 2.4550283549021543

Epoch: 6| Step: 4
Training loss: 0.06579951486928641
Validation loss: 2.4325149608249323

Epoch: 6| Step: 5
Training loss: 0.081685199159355
Validation loss: 2.439499998196105

Epoch: 6| Step: 6
Training loss: 0.07032177784425701
Validation loss: 2.4499351977998383

Epoch: 6| Step: 7
Training loss: 0.044838291132526076
Validation loss: 2.429944458495584

Epoch: 6| Step: 8
Training loss: 0.0674877110416492
Validation loss: 2.426630167875388

Epoch: 6| Step: 9
Training loss: 0.08910201559658149
Validation loss: 2.437588996408925

Epoch: 6| Step: 10
Training loss: 0.09774953201674612
Validation loss: 2.436435545921067

Epoch: 6| Step: 11
Training loss: 0.09832055168744147
Validation loss: 2.443056639854142

Epoch: 6| Step: 12
Training loss: 0.029997897401965453
Validation loss: 2.4479579858340714

Epoch: 6| Step: 13
Training loss: 0.11983943242597728
Validation loss: 2.4208719209340495

Epoch: 656| Step: 0
Training loss: 0.10666294335951888
Validation loss: 2.4176298717715974

Epoch: 6| Step: 1
Training loss: 0.05312443778497862
Validation loss: 2.433708661593764

Epoch: 6| Step: 2
Training loss: 0.07535163928829412
Validation loss: 2.4018547328062634

Epoch: 6| Step: 3
Training loss: 0.06922332255047796
Validation loss: 2.422767809622195

Epoch: 6| Step: 4
Training loss: 0.09294281104810659
Validation loss: 2.4006608787363968

Epoch: 6| Step: 5
Training loss: 0.11911620999926742
Validation loss: 2.4179318001598533

Epoch: 6| Step: 6
Training loss: 0.061831143808500216
Validation loss: 2.4161741819610993

Epoch: 6| Step: 7
Training loss: 0.08764409617196033
Validation loss: 2.42703068997536

Epoch: 6| Step: 8
Training loss: 0.07907372738444743
Validation loss: 2.410032872455063

Epoch: 6| Step: 9
Training loss: 0.06117585178398215
Validation loss: 2.4303868631243253

Epoch: 6| Step: 10
Training loss: 0.09732780537206026
Validation loss: 2.4233445868204244

Epoch: 6| Step: 11
Training loss: 0.09149586246273793
Validation loss: 2.4302726916382387

Epoch: 6| Step: 12
Training loss: 0.08233846176944376
Validation loss: 2.4339048778340517

Epoch: 6| Step: 13
Training loss: 0.10045594083310876
Validation loss: 2.4257515211639897

Epoch: 657| Step: 0
Training loss: 0.05095284154883899
Validation loss: 2.423768628570442

Epoch: 6| Step: 1
Training loss: 0.11346030061318865
Validation loss: 2.4115149865788608

Epoch: 6| Step: 2
Training loss: 0.09034903082823888
Validation loss: 2.4055753746887634

Epoch: 6| Step: 3
Training loss: 0.07720249430968786
Validation loss: 2.4429969910030103

Epoch: 6| Step: 4
Training loss: 0.054855633179151216
Validation loss: 2.438248372471935

Epoch: 6| Step: 5
Training loss: 0.07720237970754831
Validation loss: 2.462741772851084

Epoch: 6| Step: 6
Training loss: 0.08374362638404458
Validation loss: 2.4336590877059026

Epoch: 6| Step: 7
Training loss: 0.07747286774431368
Validation loss: 2.4571205729524492

Epoch: 6| Step: 8
Training loss: 0.061773258445608575
Validation loss: 2.434451382534316

Epoch: 6| Step: 9
Training loss: 0.08450042400521773
Validation loss: 2.4612434724374235

Epoch: 6| Step: 10
Training loss: 0.05979814891091176
Validation loss: 2.4645540408999382

Epoch: 6| Step: 11
Training loss: 0.10029623291884564
Validation loss: 2.4516055541341246

Epoch: 6| Step: 12
Training loss: 0.1351607928311923
Validation loss: 2.4251123254114866

Epoch: 6| Step: 13
Training loss: 0.08789045015953476
Validation loss: 2.4185915783657177

Epoch: 658| Step: 0
Training loss: 0.10759956229379676
Validation loss: 2.4262191073188175

Epoch: 6| Step: 1
Training loss: 0.09626548354589382
Validation loss: 2.4263782722640386

Epoch: 6| Step: 2
Training loss: 0.08211830322459246
Validation loss: 2.420667733646982

Epoch: 6| Step: 3
Training loss: 0.0892253564219171
Validation loss: 2.398936312890121

Epoch: 6| Step: 4
Training loss: 0.06581413426819956
Validation loss: 2.3926691715947603

Epoch: 6| Step: 5
Training loss: 0.10127609474446887
Validation loss: 2.397622427478291

Epoch: 6| Step: 6
Training loss: 0.0937298713374112
Validation loss: 2.381836012843074

Epoch: 6| Step: 7
Training loss: 0.07557977816402453
Validation loss: 2.383755590835145

Epoch: 6| Step: 8
Training loss: 0.0998274575627755
Validation loss: 2.379795536181967

Epoch: 6| Step: 9
Training loss: 0.04604859595339946
Validation loss: 2.3875223092710494

Epoch: 6| Step: 10
Training loss: 0.06998636851672718
Validation loss: 2.378495469496308

Epoch: 6| Step: 11
Training loss: 0.10126310013570972
Validation loss: 2.3976406689592165

Epoch: 6| Step: 12
Training loss: 0.05593491211957286
Validation loss: 2.405732365388283

Epoch: 6| Step: 13
Training loss: 0.12385083751385664
Validation loss: 2.3846159868036794

Epoch: 659| Step: 0
Training loss: 0.06342904072650385
Validation loss: 2.428975149930498

Epoch: 6| Step: 1
Training loss: 0.07236422758217229
Validation loss: 2.4432837927048165

Epoch: 6| Step: 2
Training loss: 0.08326790396731505
Validation loss: 2.4621358901370214

Epoch: 6| Step: 3
Training loss: 0.09571593062694429
Validation loss: 2.4445696260642555

Epoch: 6| Step: 4
Training loss: 0.09556232527098764
Validation loss: 2.423211730789383

Epoch: 6| Step: 5
Training loss: 0.08001587064441265
Validation loss: 2.417647694811209

Epoch: 6| Step: 6
Training loss: 0.08754850665159504
Validation loss: 2.4066944146070024

Epoch: 6| Step: 7
Training loss: 0.04859570021717674
Validation loss: 2.4329311451327102

Epoch: 6| Step: 8
Training loss: 0.08038119209785176
Validation loss: 2.406098871235518

Epoch: 6| Step: 9
Training loss: 0.11028314680812312
Validation loss: 2.4160907497685633

Epoch: 6| Step: 10
Training loss: 0.056109237711097645
Validation loss: 2.4088843486372817

Epoch: 6| Step: 11
Training loss: 0.09640117467290937
Validation loss: 2.394264912321524

Epoch: 6| Step: 12
Training loss: 0.10179896520135996
Validation loss: 2.4145353593340735

Epoch: 6| Step: 13
Training loss: 0.062339029668233355
Validation loss: 2.41819023151566

Epoch: 660| Step: 0
Training loss: 0.11983358428965386
Validation loss: 2.395531542702671

Epoch: 6| Step: 1
Training loss: 0.13371273285855403
Validation loss: 2.386762886571741

Epoch: 6| Step: 2
Training loss: 0.11474354923754758
Validation loss: 2.4223031461117346

Epoch: 6| Step: 3
Training loss: 0.09472561865267537
Validation loss: 2.397068017631913

Epoch: 6| Step: 4
Training loss: 0.07442594143027322
Validation loss: 2.3871041115989207

Epoch: 6| Step: 5
Training loss: 0.10820207767461708
Validation loss: 2.417925409953758

Epoch: 6| Step: 6
Training loss: 0.06006167760545481
Validation loss: 2.4355697266961296

Epoch: 6| Step: 7
Training loss: 0.05150684202938522
Validation loss: 2.404498197871263

Epoch: 6| Step: 8
Training loss: 0.11276743133243072
Validation loss: 2.4272516762523395

Epoch: 6| Step: 9
Training loss: 0.09132123033524261
Validation loss: 2.408650897007241

Epoch: 6| Step: 10
Training loss: 0.062198754842463566
Validation loss: 2.4161543517027373

Epoch: 6| Step: 11
Training loss: 0.08887994066889768
Validation loss: 2.3876751485476837

Epoch: 6| Step: 12
Training loss: 0.06917739256935371
Validation loss: 2.4376139344669348

Epoch: 6| Step: 13
Training loss: 0.09596125182892493
Validation loss: 2.4083282153715344

Epoch: 661| Step: 0
Training loss: 0.09751876690177474
Validation loss: 2.433123544568792

Epoch: 6| Step: 1
Training loss: 0.0841988995217944
Validation loss: 2.4316918310513205

Epoch: 6| Step: 2
Training loss: 0.08110559255293534
Validation loss: 2.4163383738976374

Epoch: 6| Step: 3
Training loss: 0.1361047308047052
Validation loss: 2.4412089722042163

Epoch: 6| Step: 4
Training loss: 0.08981824595813143
Validation loss: 2.443948997173224

Epoch: 6| Step: 5
Training loss: 0.10405435368438318
Validation loss: 2.4268531026433293

Epoch: 6| Step: 6
Training loss: 0.09580091423935365
Validation loss: 2.416597098978276

Epoch: 6| Step: 7
Training loss: 0.06741317120417209
Validation loss: 2.4440231711457323

Epoch: 6| Step: 8
Training loss: 0.08760522492881234
Validation loss: 2.417806907640905

Epoch: 6| Step: 9
Training loss: 0.07998037186874092
Validation loss: 2.416368775542156

Epoch: 6| Step: 10
Training loss: 0.06846453207936105
Validation loss: 2.4298453615869167

Epoch: 6| Step: 11
Training loss: 0.06937026463598527
Validation loss: 2.421323118336192

Epoch: 6| Step: 12
Training loss: 0.0874316496706851
Validation loss: 2.4338385103794513

Epoch: 6| Step: 13
Training loss: 0.0334454870099151
Validation loss: 2.443243500777855

Epoch: 662| Step: 0
Training loss: 0.08178934122712728
Validation loss: 2.4294840726170674

Epoch: 6| Step: 1
Training loss: 0.07484301177976802
Validation loss: 2.4442907659435575

Epoch: 6| Step: 2
Training loss: 0.08631913561212474
Validation loss: 2.4283020661518875

Epoch: 6| Step: 3
Training loss: 0.08721871506018163
Validation loss: 2.422960825644761

Epoch: 6| Step: 4
Training loss: 0.06182987102648949
Validation loss: 2.4409996616241814

Epoch: 6| Step: 5
Training loss: 0.05703220987165386
Validation loss: 2.425538714201637

Epoch: 6| Step: 6
Training loss: 0.08661683028006315
Validation loss: 2.430369657760417

Epoch: 6| Step: 7
Training loss: 0.1148438625594645
Validation loss: 2.4379448110139914

Epoch: 6| Step: 8
Training loss: 0.087677001953125
Validation loss: 2.409752036493752

Epoch: 6| Step: 9
Training loss: 0.10248692413116646
Validation loss: 2.413990510702859

Epoch: 6| Step: 10
Training loss: 0.07100191486007024
Validation loss: 2.410213466921175

Epoch: 6| Step: 11
Training loss: 0.037016161750099814
Validation loss: 2.4303317572188408

Epoch: 6| Step: 12
Training loss: 0.12124883810941729
Validation loss: 2.4011811147024082

Epoch: 6| Step: 13
Training loss: 0.13907660937793245
Validation loss: 2.4128404255875666

Epoch: 663| Step: 0
Training loss: 0.10647137786487404
Validation loss: 2.3923824359022703

Epoch: 6| Step: 1
Training loss: 0.09456975976119869
Validation loss: 2.408071286007248

Epoch: 6| Step: 2
Training loss: 0.04501872403296215
Validation loss: 2.4051712434964134

Epoch: 6| Step: 3
Training loss: 0.08718583660008801
Validation loss: 2.4250039708488016

Epoch: 6| Step: 4
Training loss: 0.05646123306845765
Validation loss: 2.3994606285967746

Epoch: 6| Step: 5
Training loss: 0.08285328000422894
Validation loss: 2.440490222136092

Epoch: 6| Step: 6
Training loss: 0.07001154786250666
Validation loss: 2.4297669633170527

Epoch: 6| Step: 7
Training loss: 0.08566042275269677
Validation loss: 2.4514913549068056

Epoch: 6| Step: 8
Training loss: 0.1485937576013156
Validation loss: 2.4048636376318444

Epoch: 6| Step: 9
Training loss: 0.12014642220127866
Validation loss: 2.4328096549703973

Epoch: 6| Step: 10
Training loss: 0.10410154711238324
Validation loss: 2.430844512107952

Epoch: 6| Step: 11
Training loss: 0.09407946194463965
Validation loss: 2.4415314211023893

Epoch: 6| Step: 12
Training loss: 0.11768772333734748
Validation loss: 2.4472319862681813

Epoch: 6| Step: 13
Training loss: 0.07900915812139835
Validation loss: 2.3906880991768684

Epoch: 664| Step: 0
Training loss: 0.13705993043375636
Validation loss: 2.403920057089943

Epoch: 6| Step: 1
Training loss: 0.08875694878165238
Validation loss: 2.3879515784932344

Epoch: 6| Step: 2
Training loss: 0.06664529368715323
Validation loss: 2.4038680013731852

Epoch: 6| Step: 3
Training loss: 0.07857481684825741
Validation loss: 2.4082672991767144

Epoch: 6| Step: 4
Training loss: 0.10066208225740529
Validation loss: 2.4090369649015706

Epoch: 6| Step: 5
Training loss: 0.09579565479743984
Validation loss: 2.4379454805935254

Epoch: 6| Step: 6
Training loss: 0.143265198741374
Validation loss: 2.458011357569382

Epoch: 6| Step: 7
Training loss: 0.05959743523292642
Validation loss: 2.4314649495799627

Epoch: 6| Step: 8
Training loss: 0.09665802992406883
Validation loss: 2.4504923339838065

Epoch: 6| Step: 9
Training loss: 0.08821306950553022
Validation loss: 2.4425799430110864

Epoch: 6| Step: 10
Training loss: 0.08010429733844032
Validation loss: 2.4426450213247386

Epoch: 6| Step: 11
Training loss: 0.0566347711103126
Validation loss: 2.4776715652692585

Epoch: 6| Step: 12
Training loss: 0.10619857171043566
Validation loss: 2.43802842396033

Epoch: 6| Step: 13
Training loss: 0.042828383438262355
Validation loss: 2.452120692735845

Epoch: 665| Step: 0
Training loss: 0.061361371887212794
Validation loss: 2.446135557141149

Epoch: 6| Step: 1
Training loss: 0.0539765293752326
Validation loss: 2.434722827562292

Epoch: 6| Step: 2
Training loss: 0.07458477051456198
Validation loss: 2.431275489429512

Epoch: 6| Step: 3
Training loss: 0.11823107655560833
Validation loss: 2.4226806845952273

Epoch: 6| Step: 4
Training loss: 0.08693583087275267
Validation loss: 2.3749693721227683

Epoch: 6| Step: 5
Training loss: 0.09268753692705958
Validation loss: 2.39790977782875

Epoch: 6| Step: 6
Training loss: 0.08519136487900428
Validation loss: 2.4223482122836697

Epoch: 6| Step: 7
Training loss: 0.06965307455624542
Validation loss: 2.406755737036069

Epoch: 6| Step: 8
Training loss: 0.06762929423442415
Validation loss: 2.3914632210417315

Epoch: 6| Step: 9
Training loss: 0.07006183952808014
Validation loss: 2.377957724344691

Epoch: 6| Step: 10
Training loss: 0.11213309405954675
Validation loss: 2.3940965610916205

Epoch: 6| Step: 11
Training loss: 0.0805224501024729
Validation loss: 2.4094679322197305

Epoch: 6| Step: 12
Training loss: 0.09868685025785821
Validation loss: 2.4057669078069686

Epoch: 6| Step: 13
Training loss: 0.08607408928650429
Validation loss: 2.4079042939957978

Epoch: 666| Step: 0
Training loss: 0.09069520270079467
Validation loss: 2.418717215236528

Epoch: 6| Step: 1
Training loss: 0.08026710749818937
Validation loss: 2.4215933962518177

Epoch: 6| Step: 2
Training loss: 0.09976404467371358
Validation loss: 2.4265865345788025

Epoch: 6| Step: 3
Training loss: 0.060878591001231046
Validation loss: 2.4299685560938658

Epoch: 6| Step: 4
Training loss: 0.0633780668934874
Validation loss: 2.424195259518199

Epoch: 6| Step: 5
Training loss: 0.0918682206662917
Validation loss: 2.429849257932514

Epoch: 6| Step: 6
Training loss: 0.06827793037978337
Validation loss: 2.4322452978596236

Epoch: 6| Step: 7
Training loss: 0.05719818495509369
Validation loss: 2.444131527687162

Epoch: 6| Step: 8
Training loss: 0.09583476802367064
Validation loss: 2.436366133301898

Epoch: 6| Step: 9
Training loss: 0.10465570383308122
Validation loss: 2.4121424731462757

Epoch: 6| Step: 10
Training loss: 0.08308928082119277
Validation loss: 2.4220356720214915

Epoch: 6| Step: 11
Training loss: 0.08259817190904592
Validation loss: 2.393654829513241

Epoch: 6| Step: 12
Training loss: 0.08437212435802315
Validation loss: 2.39769889636894

Epoch: 6| Step: 13
Training loss: 0.0318669589999602
Validation loss: 2.390264913072492

Epoch: 667| Step: 0
Training loss: 0.0895670797976614
Validation loss: 2.4039656413090666

Epoch: 6| Step: 1
Training loss: 0.06619041442690818
Validation loss: 2.374176366698801

Epoch: 6| Step: 2
Training loss: 0.08402303426903836
Validation loss: 2.405063020760408

Epoch: 6| Step: 3
Training loss: 0.08100479957664496
Validation loss: 2.388032558887999

Epoch: 6| Step: 4
Training loss: 0.062308711636493756
Validation loss: 2.4262188368189124

Epoch: 6| Step: 5
Training loss: 0.06543328858899278
Validation loss: 2.394373174765761

Epoch: 6| Step: 6
Training loss: 0.07210788393597162
Validation loss: 2.391213257480115

Epoch: 6| Step: 7
Training loss: 0.07710993989295006
Validation loss: 2.3998798782955726

Epoch: 6| Step: 8
Training loss: 0.0902190094205128
Validation loss: 2.3804076805027052

Epoch: 6| Step: 9
Training loss: 0.08850582767213676
Validation loss: 2.4162343274618787

Epoch: 6| Step: 10
Training loss: 0.08264545843007544
Validation loss: 2.442362723741665

Epoch: 6| Step: 11
Training loss: 0.11807781413634176
Validation loss: 2.414024158649462

Epoch: 6| Step: 12
Training loss: 0.052309532510912395
Validation loss: 2.4365593005032604

Epoch: 6| Step: 13
Training loss: 0.04375538180875231
Validation loss: 2.425036441597671

Epoch: 668| Step: 0
Training loss: 0.07850276096729271
Validation loss: 2.4093431957604676

Epoch: 6| Step: 1
Training loss: 0.08082292928649283
Validation loss: 2.414316743478932

Epoch: 6| Step: 2
Training loss: 0.06316341036505335
Validation loss: 2.396419663841827

Epoch: 6| Step: 3
Training loss: 0.07409387045850097
Validation loss: 2.406268276490916

Epoch: 6| Step: 4
Training loss: 0.03158135315197187
Validation loss: 2.4123930327011576

Epoch: 6| Step: 5
Training loss: 0.06869759675723407
Validation loss: 2.409995382887728

Epoch: 6| Step: 6
Training loss: 0.08432734951926513
Validation loss: 2.414529629576151

Epoch: 6| Step: 7
Training loss: 0.11454391523956971
Validation loss: 2.3967432722220208

Epoch: 6| Step: 8
Training loss: 0.10214511946181618
Validation loss: 2.4014233760070622

Epoch: 6| Step: 9
Training loss: 0.05112047325586115
Validation loss: 2.4193297540738357

Epoch: 6| Step: 10
Training loss: 0.04317173776309663
Validation loss: 2.4334276460957005

Epoch: 6| Step: 11
Training loss: 0.08906182259586445
Validation loss: 2.4257964809994346

Epoch: 6| Step: 12
Training loss: 0.05171370201095266
Validation loss: 2.3889745776166382

Epoch: 6| Step: 13
Training loss: 0.07798574971829542
Validation loss: 2.4114652598263473

Epoch: 669| Step: 0
Training loss: 0.08708827368293494
Validation loss: 2.430266976303765

Epoch: 6| Step: 1
Training loss: 0.06566938931237545
Validation loss: 2.4351178274953185

Epoch: 6| Step: 2
Training loss: 0.08414254431186942
Validation loss: 2.4206845303344617

Epoch: 6| Step: 3
Training loss: 0.0841375274141154
Validation loss: 2.4559191608974555

Epoch: 6| Step: 4
Training loss: 0.05373835297469039
Validation loss: 2.437124719330113

Epoch: 6| Step: 5
Training loss: 0.09204389431041285
Validation loss: 2.4245488914023654

Epoch: 6| Step: 6
Training loss: 0.09702498012593878
Validation loss: 2.4385301507683685

Epoch: 6| Step: 7
Training loss: 0.05354937616800999
Validation loss: 2.42469107945065

Epoch: 6| Step: 8
Training loss: 0.06663072037294468
Validation loss: 2.4436711803673026

Epoch: 6| Step: 9
Training loss: 0.07144303220694169
Validation loss: 2.4189970360763846

Epoch: 6| Step: 10
Training loss: 0.06777844863966294
Validation loss: 2.4306466291702864

Epoch: 6| Step: 11
Training loss: 0.08523350599372169
Validation loss: 2.4439891033423455

Epoch: 6| Step: 12
Training loss: 0.08681791591726266
Validation loss: 2.4175772629233454

Epoch: 6| Step: 13
Training loss: 0.04151163309762765
Validation loss: 2.4281178029915638

Epoch: 670| Step: 0
Training loss: 0.0682437532001847
Validation loss: 2.4527690068214554

Epoch: 6| Step: 1
Training loss: 0.0851969674083921
Validation loss: 2.432069827393898

Epoch: 6| Step: 2
Training loss: 0.061516488909014545
Validation loss: 2.4453362165586072

Epoch: 6| Step: 3
Training loss: 0.07917232938902972
Validation loss: 2.4498568674065413

Epoch: 6| Step: 4
Training loss: 0.05992687132084964
Validation loss: 2.4494497308654877

Epoch: 6| Step: 5
Training loss: 0.1054360065142441
Validation loss: 2.4411568568017117

Epoch: 6| Step: 6
Training loss: 0.071658652646709
Validation loss: 2.4451300849065656

Epoch: 6| Step: 7
Training loss: 0.07615568221201065
Validation loss: 2.4306110069485056

Epoch: 6| Step: 8
Training loss: 0.0560699771006294
Validation loss: 2.4283223393239566

Epoch: 6| Step: 9
Training loss: 0.04632241158370536
Validation loss: 2.405798034454478

Epoch: 6| Step: 10
Training loss: 0.06588256733026691
Validation loss: 2.3951144416364802

Epoch: 6| Step: 11
Training loss: 0.08873937659081496
Validation loss: 2.3822546047769575

Epoch: 6| Step: 12
Training loss: 0.07453762119180364
Validation loss: 2.379422427469623

Epoch: 6| Step: 13
Training loss: 0.10543022070117743
Validation loss: 2.4062914163567406

Epoch: 671| Step: 0
Training loss: 0.08666822404944632
Validation loss: 2.384703096913776

Epoch: 6| Step: 1
Training loss: 0.06850782692028498
Validation loss: 2.388758059127705

Epoch: 6| Step: 2
Training loss: 0.11951950286661427
Validation loss: 2.3908789015496468

Epoch: 6| Step: 3
Training loss: 0.09191134599982988
Validation loss: 2.367554208866647

Epoch: 6| Step: 4
Training loss: 0.056442477310148814
Validation loss: 2.4251083167999177

Epoch: 6| Step: 5
Training loss: 0.04733543708182297
Validation loss: 2.403490474645318

Epoch: 6| Step: 6
Training loss: 0.11454954967828615
Validation loss: 2.442859081858365

Epoch: 6| Step: 7
Training loss: 0.09662298022931415
Validation loss: 2.4120074281126618

Epoch: 6| Step: 8
Training loss: 0.07231445531439408
Validation loss: 2.4097585606110377

Epoch: 6| Step: 9
Training loss: 0.04320747266091625
Validation loss: 2.414583430262394

Epoch: 6| Step: 10
Training loss: 0.07937677801949257
Validation loss: 2.4105738011566373

Epoch: 6| Step: 11
Training loss: 0.09850406269557697
Validation loss: 2.422744416030546

Epoch: 6| Step: 12
Training loss: 0.07195386136534536
Validation loss: 2.4251857044548433

Epoch: 6| Step: 13
Training loss: 0.10999354798728504
Validation loss: 2.4023503534623267

Epoch: 672| Step: 0
Training loss: 0.07731403011019827
Validation loss: 2.409868046121502

Epoch: 6| Step: 1
Training loss: 0.0522917409939225
Validation loss: 2.398726623024872

Epoch: 6| Step: 2
Training loss: 0.0866357709197357
Validation loss: 2.392378312440436

Epoch: 6| Step: 3
Training loss: 0.062473537386140865
Validation loss: 2.416611268409617

Epoch: 6| Step: 4
Training loss: 0.07226770629978667
Validation loss: 2.3980112827772517

Epoch: 6| Step: 5
Training loss: 0.06808184417177118
Validation loss: 2.4118898839628184

Epoch: 6| Step: 6
Training loss: 0.103326597905927
Validation loss: 2.404802660326865

Epoch: 6| Step: 7
Training loss: 0.10044901519048642
Validation loss: 2.4360469502715185

Epoch: 6| Step: 8
Training loss: 0.08259910493826432
Validation loss: 2.3908699816811816

Epoch: 6| Step: 9
Training loss: 0.08025068786770445
Validation loss: 2.4108208056080516

Epoch: 6| Step: 10
Training loss: 0.09684218612336322
Validation loss: 2.4143316950676996

Epoch: 6| Step: 11
Training loss: 0.06717379258296605
Validation loss: 2.427097571025481

Epoch: 6| Step: 12
Training loss: 0.059718112821887645
Validation loss: 2.4196266558960677

Epoch: 6| Step: 13
Training loss: 0.09879117470953566
Validation loss: 2.425818319118195

Epoch: 673| Step: 0
Training loss: 0.05480361005494792
Validation loss: 2.4087716867327287

Epoch: 6| Step: 1
Training loss: 0.09934991348210759
Validation loss: 2.429584090658845

Epoch: 6| Step: 2
Training loss: 0.06464228543169966
Validation loss: 2.452201641791485

Epoch: 6| Step: 3
Training loss: 0.08523689320932604
Validation loss: 2.428735714441858

Epoch: 6| Step: 4
Training loss: 0.047164820729913036
Validation loss: 2.4383072611462953

Epoch: 6| Step: 5
Training loss: 0.08393670270477938
Validation loss: 2.429644884961643

Epoch: 6| Step: 6
Training loss: 0.08962244787366624
Validation loss: 2.4190012421335956

Epoch: 6| Step: 7
Training loss: 0.05820191017265581
Validation loss: 2.4440335829303037

Epoch: 6| Step: 8
Training loss: 0.06415867375558292
Validation loss: 2.4220585568586173

Epoch: 6| Step: 9
Training loss: 0.08424245470226258
Validation loss: 2.4226495637488017

Epoch: 6| Step: 10
Training loss: 0.08762658512263949
Validation loss: 2.430687361940972

Epoch: 6| Step: 11
Training loss: 0.10430101929335248
Validation loss: 2.4191648903663814

Epoch: 6| Step: 12
Training loss: 0.06623699553179341
Validation loss: 2.3834111460070733

Epoch: 6| Step: 13
Training loss: 0.04693471065879734
Validation loss: 2.393682237705554

Epoch: 674| Step: 0
Training loss: 0.061865610047775174
Validation loss: 2.414452216787683

Epoch: 6| Step: 1
Training loss: 0.08516769354162151
Validation loss: 2.418661921889763

Epoch: 6| Step: 2
Training loss: 0.061760679621197544
Validation loss: 2.416876701744028

Epoch: 6| Step: 3
Training loss: 0.05940363775273615
Validation loss: 2.4110594438388735

Epoch: 6| Step: 4
Training loss: 0.06755395592140855
Validation loss: 2.4091067882374677

Epoch: 6| Step: 5
Training loss: 0.0812010105014466
Validation loss: 2.4305521691255274

Epoch: 6| Step: 6
Training loss: 0.11650791209289596
Validation loss: 2.404415697702792

Epoch: 6| Step: 7
Training loss: 0.09248301574035564
Validation loss: 2.444419971847277

Epoch: 6| Step: 8
Training loss: 0.05266996485571565
Validation loss: 2.415768923010877

Epoch: 6| Step: 9
Training loss: 0.08364279725268199
Validation loss: 2.421772510425441

Epoch: 6| Step: 10
Training loss: 0.08138465646667198
Validation loss: 2.4307508491738328

Epoch: 6| Step: 11
Training loss: 0.08311751633582731
Validation loss: 2.4142717418845896

Epoch: 6| Step: 12
Training loss: 0.09914347203392544
Validation loss: 2.422138613916541

Epoch: 6| Step: 13
Training loss: 0.08244311445482284
Validation loss: 2.41027621442693

Epoch: 675| Step: 0
Training loss: 0.07655695024150334
Validation loss: 2.4317604077280803

Epoch: 6| Step: 1
Training loss: 0.0447224877512824
Validation loss: 2.43417838907045

Epoch: 6| Step: 2
Training loss: 0.11115783081292617
Validation loss: 2.4303373415996115

Epoch: 6| Step: 3
Training loss: 0.14032388609075871
Validation loss: 2.4130780396728335

Epoch: 6| Step: 4
Training loss: 0.11230496116273128
Validation loss: 2.4478260692901097

Epoch: 6| Step: 5
Training loss: 0.07699388100083963
Validation loss: 2.452238916830612

Epoch: 6| Step: 6
Training loss: 0.0602269140031132
Validation loss: 2.4393276496715637

Epoch: 6| Step: 7
Training loss: 0.08193814011555808
Validation loss: 2.4286505378291463

Epoch: 6| Step: 8
Training loss: 0.09443976057680767
Validation loss: 2.4155681223952694

Epoch: 6| Step: 9
Training loss: 0.04809282265184886
Validation loss: 2.4252576833178123

Epoch: 6| Step: 10
Training loss: 0.09753700605553622
Validation loss: 2.41694898374279

Epoch: 6| Step: 11
Training loss: 0.07621338825694407
Validation loss: 2.413685164202016

Epoch: 6| Step: 12
Training loss: 0.08176515483830372
Validation loss: 2.421185708507407

Epoch: 6| Step: 13
Training loss: 0.12007642845290577
Validation loss: 2.4426835205768582

Epoch: 676| Step: 0
Training loss: 0.1088069957491872
Validation loss: 2.4239883564899833

Epoch: 6| Step: 1
Training loss: 0.07361823185513214
Validation loss: 2.427549384421547

Epoch: 6| Step: 2
Training loss: 0.09973057217723523
Validation loss: 2.4068616908078915

Epoch: 6| Step: 3
Training loss: 0.09027379194757064
Validation loss: 2.421351740608444

Epoch: 6| Step: 4
Training loss: 0.07290181863130966
Validation loss: 2.439213359081796

Epoch: 6| Step: 5
Training loss: 0.054825693320627526
Validation loss: 2.4113305484417897

Epoch: 6| Step: 6
Training loss: 0.10297347192545052
Validation loss: 2.405331043420261

Epoch: 6| Step: 7
Training loss: 0.09267299635856227
Validation loss: 2.413044234045709

Epoch: 6| Step: 8
Training loss: 0.047096474290279224
Validation loss: 2.451252602293464

Epoch: 6| Step: 9
Training loss: 0.07481993141427787
Validation loss: 2.4624864242127025

Epoch: 6| Step: 10
Training loss: 0.0473483445515866
Validation loss: 2.433425765052666

Epoch: 6| Step: 11
Training loss: 0.1152327828378115
Validation loss: 2.4635825603953236

Epoch: 6| Step: 12
Training loss: 0.08305014484531832
Validation loss: 2.4563544289507835

Epoch: 6| Step: 13
Training loss: 0.07014787130088035
Validation loss: 2.4445190798955188

Epoch: 677| Step: 0
Training loss: 0.1007934439105755
Validation loss: 2.4462454581231223

Epoch: 6| Step: 1
Training loss: 0.07995002374398945
Validation loss: 2.4539475471140695

Epoch: 6| Step: 2
Training loss: 0.06504220954910592
Validation loss: 2.4512632884960945

Epoch: 6| Step: 3
Training loss: 0.07503809532602645
Validation loss: 2.4252846117481677

Epoch: 6| Step: 4
Training loss: 0.08498715949717606
Validation loss: 2.4376385683313635

Epoch: 6| Step: 5
Training loss: 0.09029337081473096
Validation loss: 2.4486693416173333

Epoch: 6| Step: 6
Training loss: 0.08385725714139927
Validation loss: 2.446998233992479

Epoch: 6| Step: 7
Training loss: 0.08313660167368062
Validation loss: 2.4418582368908064

Epoch: 6| Step: 8
Training loss: 0.05274544926322873
Validation loss: 2.4332722320617

Epoch: 6| Step: 9
Training loss: 0.09649933262764718
Validation loss: 2.4307760435338244

Epoch: 6| Step: 10
Training loss: 0.07787805510348234
Validation loss: 2.4387363046780126

Epoch: 6| Step: 11
Training loss: 0.0980672484579961
Validation loss: 2.438424941183913

Epoch: 6| Step: 12
Training loss: 0.07906940772107396
Validation loss: 2.431928842932333

Epoch: 6| Step: 13
Training loss: 0.04488821686444079
Validation loss: 2.421817111177913

Epoch: 678| Step: 0
Training loss: 0.08227652823456903
Validation loss: 2.4103235199437485

Epoch: 6| Step: 1
Training loss: 0.07782849132667599
Validation loss: 2.4244976285979614

Epoch: 6| Step: 2
Training loss: 0.04621551441024888
Validation loss: 2.392064336240564

Epoch: 6| Step: 3
Training loss: 0.047952173981041075
Validation loss: 2.4184563268589656

Epoch: 6| Step: 4
Training loss: 0.07779156938616413
Validation loss: 2.393657698761163

Epoch: 6| Step: 5
Training loss: 0.0793549341554166
Validation loss: 2.38945515638221

Epoch: 6| Step: 6
Training loss: 0.06154326845905396
Validation loss: 2.4137584591587293

Epoch: 6| Step: 7
Training loss: 0.07228695065060223
Validation loss: 2.3819437316276715

Epoch: 6| Step: 8
Training loss: 0.08122789593488443
Validation loss: 2.3947203445627836

Epoch: 6| Step: 9
Training loss: 0.08000958812707437
Validation loss: 2.399020622586451

Epoch: 6| Step: 10
Training loss: 0.107124619585094
Validation loss: 2.387726905570625

Epoch: 6| Step: 11
Training loss: 0.06947322806079315
Validation loss: 2.429231353232267

Epoch: 6| Step: 12
Training loss: 0.08759150733332546
Validation loss: 2.402995688178089

Epoch: 6| Step: 13
Training loss: 0.0633043888550594
Validation loss: 2.4108220752943366

Epoch: 679| Step: 0
Training loss: 0.0597172648208013
Validation loss: 2.4277379431561505

Epoch: 6| Step: 1
Training loss: 0.06832138436372506
Validation loss: 2.415182834203404

Epoch: 6| Step: 2
Training loss: 0.056368498856325194
Validation loss: 2.4287728619644886

Epoch: 6| Step: 3
Training loss: 0.09872550197223995
Validation loss: 2.4365415873915923

Epoch: 6| Step: 4
Training loss: 0.09794629892274095
Validation loss: 2.428754054472681

Epoch: 6| Step: 5
Training loss: 0.07751400564332704
Validation loss: 2.4099367385163823

Epoch: 6| Step: 6
Training loss: 0.0730394354515008
Validation loss: 2.4350442434560327

Epoch: 6| Step: 7
Training loss: 0.04858032768712072
Validation loss: 2.397876265124622

Epoch: 6| Step: 8
Training loss: 0.041840932367134494
Validation loss: 2.3973048458634443

Epoch: 6| Step: 9
Training loss: 0.11369099177691455
Validation loss: 2.4135353868759264

Epoch: 6| Step: 10
Training loss: 0.06000116750703823
Validation loss: 2.4382265647230565

Epoch: 6| Step: 11
Training loss: 0.061816367756498625
Validation loss: 2.416665925509205

Epoch: 6| Step: 12
Training loss: 0.08515532224044772
Validation loss: 2.3995329432319146

Epoch: 6| Step: 13
Training loss: 0.04594452552854403
Validation loss: 2.4115492585372786

Epoch: 680| Step: 0
Training loss: 0.12481921130877259
Validation loss: 2.417677750215338

Epoch: 6| Step: 1
Training loss: 0.05737660173806592
Validation loss: 2.4120967539669294

Epoch: 6| Step: 2
Training loss: 0.08533976492976571
Validation loss: 2.424102841408317

Epoch: 6| Step: 3
Training loss: 0.11312300217956135
Validation loss: 2.422612214924923

Epoch: 6| Step: 4
Training loss: 0.10807798892684473
Validation loss: 2.409804106862094

Epoch: 6| Step: 5
Training loss: 0.06452017966259474
Validation loss: 2.4147648808854854

Epoch: 6| Step: 6
Training loss: 0.07008115804396257
Validation loss: 2.4591033616666387

Epoch: 6| Step: 7
Training loss: 0.057577183947384564
Validation loss: 2.429006625096348

Epoch: 6| Step: 8
Training loss: 0.08050411879900925
Validation loss: 2.4309575172640634

Epoch: 6| Step: 9
Training loss: 0.09530520919368078
Validation loss: 2.44719071359483

Epoch: 6| Step: 10
Training loss: 0.07234667408555946
Validation loss: 2.4497841724052547

Epoch: 6| Step: 11
Training loss: 0.07062156620370838
Validation loss: 2.4294582343581896

Epoch: 6| Step: 12
Training loss: 0.08896880052060621
Validation loss: 2.4335705616077226

Epoch: 6| Step: 13
Training loss: 0.05230247939821268
Validation loss: 2.44263578120403

Epoch: 681| Step: 0
Training loss: 0.04976339591976231
Validation loss: 2.4328893845945214

Epoch: 6| Step: 1
Training loss: 0.05917487061918117
Validation loss: 2.414666737631228

Epoch: 6| Step: 2
Training loss: 0.07820564220714055
Validation loss: 2.4282085949584724

Epoch: 6| Step: 3
Training loss: 0.07045732259608176
Validation loss: 2.3914679410384596

Epoch: 6| Step: 4
Training loss: 0.08076184582959732
Validation loss: 2.3783806906409577

Epoch: 6| Step: 5
Training loss: 0.11392899008917215
Validation loss: 2.406384271892822

Epoch: 6| Step: 6
Training loss: 0.11938514787421631
Validation loss: 2.4099068908140575

Epoch: 6| Step: 7
Training loss: 0.07995298248678645
Validation loss: 2.4211758602458873

Epoch: 6| Step: 8
Training loss: 0.1049161092731947
Validation loss: 2.4530607896611096

Epoch: 6| Step: 9
Training loss: 0.10676099181370023
Validation loss: 2.444143165164447

Epoch: 6| Step: 10
Training loss: 0.08451035380556061
Validation loss: 2.43307973690991

Epoch: 6| Step: 11
Training loss: 0.09072246715743579
Validation loss: 2.4492944704819117

Epoch: 6| Step: 12
Training loss: 0.1116861809426894
Validation loss: 2.4500157419167343

Epoch: 6| Step: 13
Training loss: 0.08407589173359455
Validation loss: 2.457982579155435

Epoch: 682| Step: 0
Training loss: 0.07548835243626405
Validation loss: 2.4501152953609697

Epoch: 6| Step: 1
Training loss: 0.09619087374002448
Validation loss: 2.4412119877139995

Epoch: 6| Step: 2
Training loss: 0.08298138029332931
Validation loss: 2.434126335362327

Epoch: 6| Step: 3
Training loss: 0.07646569413531949
Validation loss: 2.3816825512809765

Epoch: 6| Step: 4
Training loss: 0.07416373020468577
Validation loss: 2.381701839195947

Epoch: 6| Step: 5
Training loss: 0.0644869643302249
Validation loss: 2.390817399486043

Epoch: 6| Step: 6
Training loss: 0.10711492118555258
Validation loss: 2.3964155697921745

Epoch: 6| Step: 7
Training loss: 0.09750825635327477
Validation loss: 2.3692202941550726

Epoch: 6| Step: 8
Training loss: 0.0883467494568758
Validation loss: 2.394723472674616

Epoch: 6| Step: 9
Training loss: 0.035363194227559264
Validation loss: 2.3870831430868296

Epoch: 6| Step: 10
Training loss: 0.0654387111988941
Validation loss: 2.453654280023945

Epoch: 6| Step: 11
Training loss: 0.09026172582601799
Validation loss: 2.4236648852446367

Epoch: 6| Step: 12
Training loss: 0.08673914978719469
Validation loss: 2.42874374818406

Epoch: 6| Step: 13
Training loss: 0.1090580187248522
Validation loss: 2.41722604100271

Epoch: 683| Step: 0
Training loss: 0.1012330120899879
Validation loss: 2.443298168577615

Epoch: 6| Step: 1
Training loss: 0.058415939824471144
Validation loss: 2.413819233855558

Epoch: 6| Step: 2
Training loss: 0.063318091429457
Validation loss: 2.4461820321635965

Epoch: 6| Step: 3
Training loss: 0.08714626935794989
Validation loss: 2.4056165991134977

Epoch: 6| Step: 4
Training loss: 0.08403762526460963
Validation loss: 2.4459383893253928

Epoch: 6| Step: 5
Training loss: 0.09423854313947429
Validation loss: 2.433700096477069

Epoch: 6| Step: 6
Training loss: 0.07373225292042862
Validation loss: 2.409466800138145

Epoch: 6| Step: 7
Training loss: 0.12499946355704594
Validation loss: 2.4203915273887313

Epoch: 6| Step: 8
Training loss: 0.060414924199090614
Validation loss: 2.4203974063838873

Epoch: 6| Step: 9
Training loss: 0.10488623892303671
Validation loss: 2.399778584851231

Epoch: 6| Step: 10
Training loss: 0.07411028440159988
Validation loss: 2.3940212139700545

Epoch: 6| Step: 11
Training loss: 0.04718623548038626
Validation loss: 2.3773321306484414

Epoch: 6| Step: 12
Training loss: 0.059591320898501846
Validation loss: 2.3889164967939682

Epoch: 6| Step: 13
Training loss: 0.05488379195890322
Validation loss: 2.3883324239548327

Epoch: 684| Step: 0
Training loss: 0.08466566230069948
Validation loss: 2.3833813662528875

Epoch: 6| Step: 1
Training loss: 0.052445143916306475
Validation loss: 2.363280169558704

Epoch: 6| Step: 2
Training loss: 0.07001332371221554
Validation loss: 2.397452632117003

Epoch: 6| Step: 3
Training loss: 0.07079892978220502
Validation loss: 2.4045871374042114

Epoch: 6| Step: 4
Training loss: 0.06606104123707335
Validation loss: 2.4031866684249943

Epoch: 6| Step: 5
Training loss: 0.056302837136448396
Validation loss: 2.409818330597107

Epoch: 6| Step: 6
Training loss: 0.06890561322482411
Validation loss: 2.403964470777887

Epoch: 6| Step: 7
Training loss: 0.09711806774745485
Validation loss: 2.4198510368024824

Epoch: 6| Step: 8
Training loss: 0.07359358099089895
Validation loss: 2.420489172146649

Epoch: 6| Step: 9
Training loss: 0.08985977444587323
Validation loss: 2.428014514739762

Epoch: 6| Step: 10
Training loss: 0.0411784411732795
Validation loss: 2.443982387907373

Epoch: 6| Step: 11
Training loss: 0.059658567527698395
Validation loss: 2.4052125963568285

Epoch: 6| Step: 12
Training loss: 0.10127746492096784
Validation loss: 2.3981504694438844

Epoch: 6| Step: 13
Training loss: 0.05800594694496454
Validation loss: 2.4133593633762103

Epoch: 685| Step: 0
Training loss: 0.08638791154404087
Validation loss: 2.4267232065173627

Epoch: 6| Step: 1
Training loss: 0.046764083607485435
Validation loss: 2.435114780751314

Epoch: 6| Step: 2
Training loss: 0.08259757713265373
Validation loss: 2.4119385991184332

Epoch: 6| Step: 3
Training loss: 0.07397826031529205
Validation loss: 2.413158061080637

Epoch: 6| Step: 4
Training loss: 0.050913398074412176
Validation loss: 2.4209410762491346

Epoch: 6| Step: 5
Training loss: 0.04984010344129031
Validation loss: 2.408261344263217

Epoch: 6| Step: 6
Training loss: 0.08164331691812221
Validation loss: 2.3982157571140816

Epoch: 6| Step: 7
Training loss: 0.06871816957613744
Validation loss: 2.401858703911164

Epoch: 6| Step: 8
Training loss: 0.09924909473073598
Validation loss: 2.3838536315097327

Epoch: 6| Step: 9
Training loss: 0.08232774964495161
Validation loss: 2.4076958579234513

Epoch: 6| Step: 10
Training loss: 0.07870010059998868
Validation loss: 2.3920862315289506

Epoch: 6| Step: 11
Training loss: 0.05605738738001114
Validation loss: 2.4249687729222407

Epoch: 6| Step: 12
Training loss: 0.07729693498719006
Validation loss: 2.412147599056451

Epoch: 6| Step: 13
Training loss: 0.055721815582924245
Validation loss: 2.4124011835663732

Epoch: 686| Step: 0
Training loss: 0.04531773267737719
Validation loss: 2.4278757561386897

Epoch: 6| Step: 1
Training loss: 0.0824794615571812
Validation loss: 2.446967142165181

Epoch: 6| Step: 2
Training loss: 0.04381015444019389
Validation loss: 2.4396818060343715

Epoch: 6| Step: 3
Training loss: 0.053520439185491875
Validation loss: 2.43602697869848

Epoch: 6| Step: 4
Training loss: 0.10614415534617669
Validation loss: 2.429732604357118

Epoch: 6| Step: 5
Training loss: 0.05829342327619402
Validation loss: 2.4155090619619703

Epoch: 6| Step: 6
Training loss: 0.07721705342948867
Validation loss: 2.4155014893948064

Epoch: 6| Step: 7
Training loss: 0.061983913285286164
Validation loss: 2.4223054723603794

Epoch: 6| Step: 8
Training loss: 0.05579129743980626
Validation loss: 2.436635985691005

Epoch: 6| Step: 9
Training loss: 0.06408082478976634
Validation loss: 2.4199684389728104

Epoch: 6| Step: 10
Training loss: 0.08699294057827577
Validation loss: 2.4361379250161765

Epoch: 6| Step: 11
Training loss: 0.06249981000990601
Validation loss: 2.3928550106287205

Epoch: 6| Step: 12
Training loss: 0.07679296336588032
Validation loss: 2.4149141180428266

Epoch: 6| Step: 13
Training loss: 0.09087156059900513
Validation loss: 2.418202257809818

Epoch: 687| Step: 0
Training loss: 0.06777943109179656
Validation loss: 2.431887084684823

Epoch: 6| Step: 1
Training loss: 0.0669463715546863
Validation loss: 2.42503827708323

Epoch: 6| Step: 2
Training loss: 0.08605996530861536
Validation loss: 2.4403183800440136

Epoch: 6| Step: 3
Training loss: 0.07738748166605197
Validation loss: 2.4360062865974905

Epoch: 6| Step: 4
Training loss: 0.09222774637343817
Validation loss: 2.42821987482668

Epoch: 6| Step: 5
Training loss: 0.06794033018168144
Validation loss: 2.417834972996304

Epoch: 6| Step: 6
Training loss: 0.09538137593368207
Validation loss: 2.417136757277585

Epoch: 6| Step: 7
Training loss: 0.07947179312435335
Validation loss: 2.4452164792399227

Epoch: 6| Step: 8
Training loss: 0.05086340127996261
Validation loss: 2.4374017750879933

Epoch: 6| Step: 9
Training loss: 0.0827150117406299
Validation loss: 2.4139859674932196

Epoch: 6| Step: 10
Training loss: 0.10439777119446815
Validation loss: 2.4227093178123353

Epoch: 6| Step: 11
Training loss: 0.10138628417781552
Validation loss: 2.4481174108282424

Epoch: 6| Step: 12
Training loss: 0.08628732290970934
Validation loss: 2.434245799888245

Epoch: 6| Step: 13
Training loss: 0.047879065181035484
Validation loss: 2.411861329570611

Epoch: 688| Step: 0
Training loss: 0.09300644875575623
Validation loss: 2.378631173388899

Epoch: 6| Step: 1
Training loss: 0.05964776772583337
Validation loss: 2.3947214686280804

Epoch: 6| Step: 2
Training loss: 0.06131780220127322
Validation loss: 2.3970023799837215

Epoch: 6| Step: 3
Training loss: 0.04785526757590737
Validation loss: 2.387094568422269

Epoch: 6| Step: 4
Training loss: 0.08005512011777718
Validation loss: 2.3979775501912144

Epoch: 6| Step: 5
Training loss: 0.052371220621749315
Validation loss: 2.4144511194277185

Epoch: 6| Step: 6
Training loss: 0.06023818201930479
Validation loss: 2.412508490805349

Epoch: 6| Step: 7
Training loss: 0.0786280736570705
Validation loss: 2.39098467163062

Epoch: 6| Step: 8
Training loss: 0.08242277816078758
Validation loss: 2.4013660291803665

Epoch: 6| Step: 9
Training loss: 0.06903579046009553
Validation loss: 2.382019947243004

Epoch: 6| Step: 10
Training loss: 0.07736289721756952
Validation loss: 2.4404266074690018

Epoch: 6| Step: 11
Training loss: 0.054241039705996065
Validation loss: 2.4434223645803637

Epoch: 6| Step: 12
Training loss: 0.08570202079972698
Validation loss: 2.428153380493409

Epoch: 6| Step: 13
Training loss: 0.09581475170591386
Validation loss: 2.3726059170774993

Epoch: 689| Step: 0
Training loss: 0.10313539127535376
Validation loss: 2.450115710755808

Epoch: 6| Step: 1
Training loss: 0.07886020903489253
Validation loss: 2.4260399420749477

Epoch: 6| Step: 2
Training loss: 0.047549065256144454
Validation loss: 2.434333216587808

Epoch: 6| Step: 3
Training loss: 0.0598342804257811
Validation loss: 2.412062918112812

Epoch: 6| Step: 4
Training loss: 0.07813797485374789
Validation loss: 2.4226972197135863

Epoch: 6| Step: 5
Training loss: 0.045138778722049896
Validation loss: 2.4257560560768145

Epoch: 6| Step: 6
Training loss: 0.05053644133785098
Validation loss: 2.4116903349507033

Epoch: 6| Step: 7
Training loss: 0.06475019269370529
Validation loss: 2.4192151810388145

Epoch: 6| Step: 8
Training loss: 0.10461639882837971
Validation loss: 2.442088464725455

Epoch: 6| Step: 9
Training loss: 0.07085177459668225
Validation loss: 2.408488210313814

Epoch: 6| Step: 10
Training loss: 0.07495227775627684
Validation loss: 2.4102087634249467

Epoch: 6| Step: 11
Training loss: 0.0646341123585095
Validation loss: 2.416132536585926

Epoch: 6| Step: 12
Training loss: 0.08873187232581525
Validation loss: 2.3940635989586077

Epoch: 6| Step: 13
Training loss: 0.0780206788454746
Validation loss: 2.376172214161498

Epoch: 690| Step: 0
Training loss: 0.06142570854934733
Validation loss: 2.390538509444249

Epoch: 6| Step: 1
Training loss: 0.06124255039870605
Validation loss: 2.4051126275271244

Epoch: 6| Step: 2
Training loss: 0.08037848664555337
Validation loss: 2.4056247473625203

Epoch: 6| Step: 3
Training loss: 0.07802186953901018
Validation loss: 2.395622875141977

Epoch: 6| Step: 4
Training loss: 0.0814903512099972
Validation loss: 2.4115140749849986

Epoch: 6| Step: 5
Training loss: 0.08231970615169083
Validation loss: 2.431435578081707

Epoch: 6| Step: 6
Training loss: 0.058715380153473384
Validation loss: 2.398535071747827

Epoch: 6| Step: 7
Training loss: 0.06961513104813863
Validation loss: 2.397758909235725

Epoch: 6| Step: 8
Training loss: 0.059028565829679414
Validation loss: 2.406771240756988

Epoch: 6| Step: 9
Training loss: 0.08639026170572445
Validation loss: 2.4307079390081316

Epoch: 6| Step: 10
Training loss: 0.07786965962302822
Validation loss: 2.4140544078423263

Epoch: 6| Step: 11
Training loss: 0.08453035313594098
Validation loss: 2.409937979414529

Epoch: 6| Step: 12
Training loss: 0.0435189759318579
Validation loss: 2.3980163800950365

Epoch: 6| Step: 13
Training loss: 0.03914036738335658
Validation loss: 2.396488734229794

Epoch: 691| Step: 0
Training loss: 0.059373583510091414
Validation loss: 2.416406643647858

Epoch: 6| Step: 1
Training loss: 0.06513489673473993
Validation loss: 2.377120454696493

Epoch: 6| Step: 2
Training loss: 0.059369679576516864
Validation loss: 2.3826170191741953

Epoch: 6| Step: 3
Training loss: 0.05592051832667033
Validation loss: 2.381305774305442

Epoch: 6| Step: 4
Training loss: 0.03961208384560233
Validation loss: 2.3983719511388526

Epoch: 6| Step: 5
Training loss: 0.046700425708765834
Validation loss: 2.4190585958623125

Epoch: 6| Step: 6
Training loss: 0.06438091235301426
Validation loss: 2.4072109337804206

Epoch: 6| Step: 7
Training loss: 0.04916900853631795
Validation loss: 2.4178258946544924

Epoch: 6| Step: 8
Training loss: 0.06431098639446671
Validation loss: 2.4165836264445515

Epoch: 6| Step: 9
Training loss: 0.0956833098781694
Validation loss: 2.404230992189992

Epoch: 6| Step: 10
Training loss: 0.04557399265971839
Validation loss: 2.4121145190484308

Epoch: 6| Step: 11
Training loss: 0.07952692025227062
Validation loss: 2.420977798025053

Epoch: 6| Step: 12
Training loss: 0.07006245764357608
Validation loss: 2.4129871575558623

Epoch: 6| Step: 13
Training loss: 0.08718153163177454
Validation loss: 2.4518408950980297

Epoch: 692| Step: 0
Training loss: 0.06382204087488035
Validation loss: 2.4187797834754483

Epoch: 6| Step: 1
Training loss: 0.054103001255225935
Validation loss: 2.452729313884914

Epoch: 6| Step: 2
Training loss: 0.058286932477748764
Validation loss: 2.4279810881299064

Epoch: 6| Step: 3
Training loss: 0.07638078553876601
Validation loss: 2.415969669267306

Epoch: 6| Step: 4
Training loss: 0.04928565482919685
Validation loss: 2.458250781328353

Epoch: 6| Step: 5
Training loss: 0.08197542970704105
Validation loss: 2.385617269000075

Epoch: 6| Step: 6
Training loss: 0.09663279677458851
Validation loss: 2.43812458796097

Epoch: 6| Step: 7
Training loss: 0.06503463091372606
Validation loss: 2.4083020883940462

Epoch: 6| Step: 8
Training loss: 0.0636954348804052
Validation loss: 2.4162324579674777

Epoch: 6| Step: 9
Training loss: 0.04970547668034625
Validation loss: 2.425133619992233

Epoch: 6| Step: 10
Training loss: 0.05202189586942842
Validation loss: 2.406850589910644

Epoch: 6| Step: 11
Training loss: 0.0902490698833828
Validation loss: 2.4122305728800453

Epoch: 6| Step: 12
Training loss: 0.07886558230666814
Validation loss: 2.4044706352906102

Epoch: 6| Step: 13
Training loss: 0.06846979283492338
Validation loss: 2.3996798682084095

Epoch: 693| Step: 0
Training loss: 0.04717533683883395
Validation loss: 2.393705673811941

Epoch: 6| Step: 1
Training loss: 0.09603181661338746
Validation loss: 2.431670922834658

Epoch: 6| Step: 2
Training loss: 0.0889519559651743
Validation loss: 2.4180970294185933

Epoch: 6| Step: 3
Training loss: 0.05666940262218226
Validation loss: 2.4176830457131815

Epoch: 6| Step: 4
Training loss: 0.07663132192083918
Validation loss: 2.416556321651084

Epoch: 6| Step: 5
Training loss: 0.0964869784571487
Validation loss: 2.421264285632239

Epoch: 6| Step: 6
Training loss: 0.06379022861169373
Validation loss: 2.4030048709553458

Epoch: 6| Step: 7
Training loss: 0.049994238879177325
Validation loss: 2.4123020642009765

Epoch: 6| Step: 8
Training loss: 0.046193647128665326
Validation loss: 2.429065132020796

Epoch: 6| Step: 9
Training loss: 0.05781977606105615
Validation loss: 2.4493843811964284

Epoch: 6| Step: 10
Training loss: 0.049808960151656
Validation loss: 2.4082294904420976

Epoch: 6| Step: 11
Training loss: 0.04290512777155943
Validation loss: 2.417836062193573

Epoch: 6| Step: 12
Training loss: 0.08063904926332685
Validation loss: 2.4406098331371275

Epoch: 6| Step: 13
Training loss: 0.04843724917915992
Validation loss: 2.4303742747718116

Epoch: 694| Step: 0
Training loss: 0.09191681756828304
Validation loss: 2.416545348964244

Epoch: 6| Step: 1
Training loss: 0.05231748587452019
Validation loss: 2.421753585053149

Epoch: 6| Step: 2
Training loss: 0.07664909404465287
Validation loss: 2.4083812700194436

Epoch: 6| Step: 3
Training loss: 0.06565397168018945
Validation loss: 2.3845661226989314

Epoch: 6| Step: 4
Training loss: 0.06554904413555664
Validation loss: 2.4043402634536246

Epoch: 6| Step: 5
Training loss: 0.08508344565324036
Validation loss: 2.3932867115001075

Epoch: 6| Step: 6
Training loss: 0.05205724132163925
Validation loss: 2.362371209992008

Epoch: 6| Step: 7
Training loss: 0.09308153491828583
Validation loss: 2.400613348638343

Epoch: 6| Step: 8
Training loss: 0.08432655709890477
Validation loss: 2.357482419470669

Epoch: 6| Step: 9
Training loss: 0.06513687345380584
Validation loss: 2.3794682295591523

Epoch: 6| Step: 10
Training loss: 0.07786274642542489
Validation loss: 2.3984292322029472

Epoch: 6| Step: 11
Training loss: 0.05566417125222809
Validation loss: 2.368025003538324

Epoch: 6| Step: 12
Training loss: 0.039718745169538
Validation loss: 2.3570569005449955

Epoch: 6| Step: 13
Training loss: 0.04832062435512087
Validation loss: 2.391395654280434

Epoch: 695| Step: 0
Training loss: 0.05220147036539417
Validation loss: 2.3853490461376747

Epoch: 6| Step: 1
Training loss: 0.06464024316076965
Validation loss: 2.389219192024276

Epoch: 6| Step: 2
Training loss: 0.06826718790086146
Validation loss: 2.3913566611255783

Epoch: 6| Step: 3
Training loss: 0.08399325978057076
Validation loss: 2.3677261894613175

Epoch: 6| Step: 4
Training loss: 0.06164695247052683
Validation loss: 2.383305133937013

Epoch: 6| Step: 5
Training loss: 0.09177360848543789
Validation loss: 2.4042980862876155

Epoch: 6| Step: 6
Training loss: 0.05861450860741462
Validation loss: 2.3670393574802078

Epoch: 6| Step: 7
Training loss: 0.06052188973043781
Validation loss: 2.356676972461792

Epoch: 6| Step: 8
Training loss: 0.06323492936277098
Validation loss: 2.3853354957212307

Epoch: 6| Step: 9
Training loss: 0.05897369974997934
Validation loss: 2.3789160501759916

Epoch: 6| Step: 10
Training loss: 0.05652084304757872
Validation loss: 2.386480145317509

Epoch: 6| Step: 11
Training loss: 0.06501483351379937
Validation loss: 2.3728548831871947

Epoch: 6| Step: 12
Training loss: 0.046102948301445096
Validation loss: 2.3649948677770953

Epoch: 6| Step: 13
Training loss: 0.04647134540171571
Validation loss: 2.3740695562109884

Epoch: 696| Step: 0
Training loss: 0.043041373782332346
Validation loss: 2.3753381249880876

Epoch: 6| Step: 1
Training loss: 0.09211000341180009
Validation loss: 2.3639437668981556

Epoch: 6| Step: 2
Training loss: 0.061974670201304455
Validation loss: 2.376859253437007

Epoch: 6| Step: 3
Training loss: 0.05828857022430246
Validation loss: 2.3924061863897133

Epoch: 6| Step: 4
Training loss: 0.10059594595290719
Validation loss: 2.4027073594750163

Epoch: 6| Step: 5
Training loss: 0.07913193884740218
Validation loss: 2.403681717946066

Epoch: 6| Step: 6
Training loss: 0.07864639224660135
Validation loss: 2.4337590151483415

Epoch: 6| Step: 7
Training loss: 0.07367117183628859
Validation loss: 2.443870891367858

Epoch: 6| Step: 8
Training loss: 0.03936699415696169
Validation loss: 2.4391802493757733

Epoch: 6| Step: 9
Training loss: 0.047275070259476
Validation loss: 2.4304327044713774

Epoch: 6| Step: 10
Training loss: 0.058885819948590094
Validation loss: 2.439653808107402

Epoch: 6| Step: 11
Training loss: 0.06155061689109039
Validation loss: 2.430675471248787

Epoch: 6| Step: 12
Training loss: 0.07858890842745962
Validation loss: 2.434242668853363

Epoch: 6| Step: 13
Training loss: 0.04763957185166093
Validation loss: 2.4369639271792773

Epoch: 697| Step: 0
Training loss: 0.059230692289630356
Validation loss: 2.4349248444256473

Epoch: 6| Step: 1
Training loss: 0.07926069547693816
Validation loss: 2.408378930853672

Epoch: 6| Step: 2
Training loss: 0.07085585261046978
Validation loss: 2.39759142671995

Epoch: 6| Step: 3
Training loss: 0.07079434858894018
Validation loss: 2.4089436342785326

Epoch: 6| Step: 4
Training loss: 0.07832412674765149
Validation loss: 2.3899880499769934

Epoch: 6| Step: 5
Training loss: 0.07753186973245675
Validation loss: 2.4222754204002794

Epoch: 6| Step: 6
Training loss: 0.05677599597272115
Validation loss: 2.4078333556429685

Epoch: 6| Step: 7
Training loss: 0.06208883956692328
Validation loss: 2.414156343153551

Epoch: 6| Step: 8
Training loss: 0.06071993107292467
Validation loss: 2.4249521808753447

Epoch: 6| Step: 9
Training loss: 0.05962516846360594
Validation loss: 2.3951249611358403

Epoch: 6| Step: 10
Training loss: 0.06300124692912813
Validation loss: 2.414898163934865

Epoch: 6| Step: 11
Training loss: 0.0518665027193975
Validation loss: 2.419447202201239

Epoch: 6| Step: 12
Training loss: 0.07209390781246419
Validation loss: 2.4149057962505864

Epoch: 6| Step: 13
Training loss: 0.09065181730019471
Validation loss: 2.384242914178339

Epoch: 698| Step: 0
Training loss: 0.05639591877311033
Validation loss: 2.4104882023977514

Epoch: 6| Step: 1
Training loss: 0.06566457435049868
Validation loss: 2.40958558174976

Epoch: 6| Step: 2
Training loss: 0.07290196235020219
Validation loss: 2.4150531128933337

Epoch: 6| Step: 3
Training loss: 0.06934139404854636
Validation loss: 2.4089050028635266

Epoch: 6| Step: 4
Training loss: 0.07748781175197621
Validation loss: 2.4068386120788205

Epoch: 6| Step: 5
Training loss: 0.0987713190648263
Validation loss: 2.4121164857938004

Epoch: 6| Step: 6
Training loss: 0.08587081445949538
Validation loss: 2.4064708438439624

Epoch: 6| Step: 7
Training loss: 0.08258575682529645
Validation loss: 2.3925220421820135

Epoch: 6| Step: 8
Training loss: 0.09965306614107831
Validation loss: 2.408081483820657

Epoch: 6| Step: 9
Training loss: 0.05280980481727879
Validation loss: 2.4137169640805376

Epoch: 6| Step: 10
Training loss: 0.06431592441242813
Validation loss: 2.4432913321529233

Epoch: 6| Step: 11
Training loss: 0.06828510473225505
Validation loss: 2.4175438871203996

Epoch: 6| Step: 12
Training loss: 0.06805718932831725
Validation loss: 2.4385130612087567

Epoch: 6| Step: 13
Training loss: 0.08922666114599268
Validation loss: 2.4444214537624807

Epoch: 699| Step: 0
Training loss: 0.07816232147451109
Validation loss: 2.449875270120384

Epoch: 6| Step: 1
Training loss: 0.08806151095803481
Validation loss: 2.4615205984509174

Epoch: 6| Step: 2
Training loss: 0.08178521908525672
Validation loss: 2.4173294964614027

Epoch: 6| Step: 3
Training loss: 0.11523254845674853
Validation loss: 2.4293878472931145

Epoch: 6| Step: 4
Training loss: 0.04574291532851204
Validation loss: 2.4337310933977845

Epoch: 6| Step: 5
Training loss: 0.057956307758336253
Validation loss: 2.428493789348013

Epoch: 6| Step: 6
Training loss: 0.07878756603035905
Validation loss: 2.4345690815243963

Epoch: 6| Step: 7
Training loss: 0.07780490507839871
Validation loss: 2.397338717041359

Epoch: 6| Step: 8
Training loss: 0.09578352100922172
Validation loss: 2.4268524561483784

Epoch: 6| Step: 9
Training loss: 0.09344469465350158
Validation loss: 2.4026503863368593

Epoch: 6| Step: 10
Training loss: 0.06396015892635938
Validation loss: 2.40726027836695

Epoch: 6| Step: 11
Training loss: 0.09075310486645881
Validation loss: 2.4090453436810315

Epoch: 6| Step: 12
Training loss: 0.07213695450749054
Validation loss: 2.41102707141224

Epoch: 6| Step: 13
Training loss: 0.04446941283908854
Validation loss: 2.418455956907836

Epoch: 700| Step: 0
Training loss: 0.07801852421097986
Validation loss: 2.427895351808196

Epoch: 6| Step: 1
Training loss: 0.06979869829643941
Validation loss: 2.4019928562626425

Epoch: 6| Step: 2
Training loss: 0.08468144583440479
Validation loss: 2.427766618100465

Epoch: 6| Step: 3
Training loss: 0.09389842721215542
Validation loss: 2.40970672996154

Epoch: 6| Step: 4
Training loss: 0.15320775583826834
Validation loss: 2.417925073849867

Epoch: 6| Step: 5
Training loss: 0.07012494556999474
Validation loss: 2.4222078717159667

Epoch: 6| Step: 6
Training loss: 0.07046285421697936
Validation loss: 2.4094102656054446

Epoch: 6| Step: 7
Training loss: 0.12817183720086933
Validation loss: 2.3726850756358857

Epoch: 6| Step: 8
Training loss: 0.10382502130701786
Validation loss: 2.37274974139466

Epoch: 6| Step: 9
Training loss: 0.07814776565734322
Validation loss: 2.373971672207634

Epoch: 6| Step: 10
Training loss: 0.09306216235256493
Validation loss: 2.370830176266811

Epoch: 6| Step: 11
Training loss: 0.08858749895732325
Validation loss: 2.372512898962395

Epoch: 6| Step: 12
Training loss: 0.08086548692298814
Validation loss: 2.3803848862081463

Epoch: 6| Step: 13
Training loss: 0.09762873261907566
Validation loss: 2.396378907035762

Testing loss: 2.9317300352383233
