Epoch: 1| Step: 0
Training loss: 4.908393859863281
Validation loss: 5.208071934279575

Epoch: 6| Step: 1
Training loss: 4.437942981719971
Validation loss: 5.180283351611066

Epoch: 6| Step: 2
Training loss: 5.445672988891602
Validation loss: 5.158462657723375

Epoch: 6| Step: 3
Training loss: 5.234930038452148
Validation loss: 5.137548436400711

Epoch: 6| Step: 4
Training loss: 4.74139404296875
Validation loss: 5.114520893302015

Epoch: 6| Step: 5
Training loss: 4.3833723068237305
Validation loss: 5.087042034313243

Epoch: 6| Step: 6
Training loss: 4.9501471519470215
Validation loss: 5.055275599161784

Epoch: 6| Step: 7
Training loss: 4.38460111618042
Validation loss: 5.020216306050618

Epoch: 6| Step: 8
Training loss: 5.30602502822876
Validation loss: 4.98052312994516

Epoch: 6| Step: 9
Training loss: 4.632335662841797
Validation loss: 4.9367625585166355

Epoch: 6| Step: 10
Training loss: 4.288830757141113
Validation loss: 4.886929635078676

Epoch: 6| Step: 11
Training loss: 5.047507286071777
Validation loss: 4.833695427063973

Epoch: 6| Step: 12
Training loss: 4.999856948852539
Validation loss: 4.7737606263929795

Epoch: 6| Step: 13
Training loss: 4.338951587677002
Validation loss: 4.709363598977366

Epoch: 2| Step: 0
Training loss: 3.9376935958862305
Validation loss: 4.639606632212157

Epoch: 6| Step: 1
Training loss: 3.4353904724121094
Validation loss: 4.569888135438324

Epoch: 6| Step: 2
Training loss: 4.990614891052246
Validation loss: 4.497211174298358

Epoch: 6| Step: 3
Training loss: 3.2808375358581543
Validation loss: 4.427325069263417

Epoch: 6| Step: 4
Training loss: 3.7810773849487305
Validation loss: 4.3594850263287945

Epoch: 6| Step: 5
Training loss: 3.8017845153808594
Validation loss: 4.2988805309418705

Epoch: 6| Step: 6
Training loss: 5.30975866317749
Validation loss: 4.240662190221971

Epoch: 6| Step: 7
Training loss: 3.349510669708252
Validation loss: 4.187199654117707

Epoch: 6| Step: 8
Training loss: 4.004382133483887
Validation loss: 4.134425460651356

Epoch: 6| Step: 9
Training loss: 4.060839653015137
Validation loss: 4.087058738995624

Epoch: 6| Step: 10
Training loss: 3.0116260051727295
Validation loss: 4.041353743563416

Epoch: 6| Step: 11
Training loss: 4.590615749359131
Validation loss: 4.002568560261881

Epoch: 6| Step: 12
Training loss: 5.511859893798828
Validation loss: 3.9621252193245837

Epoch: 6| Step: 13
Training loss: 3.2606074810028076
Validation loss: 3.9193899605863836

Epoch: 3| Step: 0
Training loss: 3.8211822509765625
Validation loss: 3.87975142335379

Epoch: 6| Step: 1
Training loss: 4.282955169677734
Validation loss: 3.84101245480199

Epoch: 6| Step: 2
Training loss: 3.49177885055542
Validation loss: 3.8029749983100483

Epoch: 6| Step: 3
Training loss: 3.7219653129577637
Validation loss: 3.7741529403194303

Epoch: 6| Step: 4
Training loss: 5.235712051391602
Validation loss: 3.7498556003775647

Epoch: 6| Step: 5
Training loss: 4.439474582672119
Validation loss: 3.7236541906992593

Epoch: 6| Step: 6
Training loss: 2.8733386993408203
Validation loss: 3.699572176061651

Epoch: 6| Step: 7
Training loss: 2.816235303878784
Validation loss: 3.6778609470654557

Epoch: 6| Step: 8
Training loss: 3.072706699371338
Validation loss: 3.651927412197154

Epoch: 6| Step: 9
Training loss: 3.6036767959594727
Validation loss: 3.6273443621973835

Epoch: 6| Step: 10
Training loss: 3.224754810333252
Validation loss: 3.602013188023721

Epoch: 6| Step: 11
Training loss: 3.876163959503174
Validation loss: 3.580384910747569

Epoch: 6| Step: 12
Training loss: 3.1509299278259277
Validation loss: 3.56255857406124

Epoch: 6| Step: 13
Training loss: 2.475186824798584
Validation loss: 3.543069775386523

Epoch: 4| Step: 0
Training loss: 4.948660850524902
Validation loss: 3.5239191029661443

Epoch: 6| Step: 1
Training loss: 2.7378458976745605
Validation loss: 3.503271407978509

Epoch: 6| Step: 2
Training loss: 2.847113847732544
Validation loss: 3.485241864317207

Epoch: 6| Step: 3
Training loss: 3.6835737228393555
Validation loss: 3.4693019518288235

Epoch: 6| Step: 4
Training loss: 3.3210396766662598
Validation loss: 3.452662383356402

Epoch: 6| Step: 5
Training loss: 3.1288576126098633
Validation loss: 3.4341166198894544

Epoch: 6| Step: 6
Training loss: 3.255345582962036
Validation loss: 3.420283563675419

Epoch: 6| Step: 7
Training loss: 2.899232864379883
Validation loss: 3.400249163309733

Epoch: 6| Step: 8
Training loss: 3.2313239574432373
Validation loss: 3.383519277777723

Epoch: 6| Step: 9
Training loss: 3.69936466217041
Validation loss: 3.362451845599759

Epoch: 6| Step: 10
Training loss: 3.74029541015625
Validation loss: 3.34230302738887

Epoch: 6| Step: 11
Training loss: 2.9464492797851562
Validation loss: 3.3206612422902095

Epoch: 6| Step: 12
Training loss: 2.7090377807617188
Validation loss: 3.303941762575539

Epoch: 6| Step: 13
Training loss: 4.296356201171875
Validation loss: 3.281653875945717

Epoch: 5| Step: 0
Training loss: 2.4325618743896484
Validation loss: 3.260207365917903

Epoch: 6| Step: 1
Training loss: 2.77363657951355
Validation loss: 3.2466527902951805

Epoch: 6| Step: 2
Training loss: 2.9942626953125
Validation loss: 3.235830609516431

Epoch: 6| Step: 3
Training loss: 3.290214776992798
Validation loss: 3.216974348150274

Epoch: 6| Step: 4
Training loss: 2.4532408714294434
Validation loss: 3.205238308957828

Epoch: 6| Step: 5
Training loss: 3.5722432136535645
Validation loss: 3.195211746359384

Epoch: 6| Step: 6
Training loss: 4.395278453826904
Validation loss: 3.1833601049197617

Epoch: 6| Step: 7
Training loss: 3.1372203826904297
Validation loss: 3.166783361024754

Epoch: 6| Step: 8
Training loss: 1.8395202159881592
Validation loss: 3.1517634699421544

Epoch: 6| Step: 9
Training loss: 4.586192607879639
Validation loss: 3.1434425000221498

Epoch: 6| Step: 10
Training loss: 3.264401912689209
Validation loss: 3.1352273238602506

Epoch: 6| Step: 11
Training loss: 2.4667794704437256
Validation loss: 3.1188470009834535

Epoch: 6| Step: 12
Training loss: 3.050851345062256
Validation loss: 3.1124582085558163

Epoch: 6| Step: 13
Training loss: 5.033480167388916
Validation loss: 3.1037066059727825

Epoch: 6| Step: 0
Training loss: 2.554791212081909
Validation loss: 3.0841808754910707

Epoch: 6| Step: 1
Training loss: 2.0276756286621094
Validation loss: 3.069883715721869

Epoch: 6| Step: 2
Training loss: 4.05286979675293
Validation loss: 3.093069532866119

Epoch: 6| Step: 3
Training loss: 3.3626556396484375
Validation loss: 3.0509330585438716

Epoch: 6| Step: 4
Training loss: 4.149774551391602
Validation loss: 3.0412582582043064

Epoch: 6| Step: 5
Training loss: 2.7725491523742676
Validation loss: 3.036862316951957

Epoch: 6| Step: 6
Training loss: 2.9052224159240723
Validation loss: 3.038497392849256

Epoch: 6| Step: 7
Training loss: 2.9349329471588135
Validation loss: 3.02655928878374

Epoch: 6| Step: 8
Training loss: 2.1017706394195557
Validation loss: 3.007154603158274

Epoch: 6| Step: 9
Training loss: 3.0478031635284424
Validation loss: 2.9968252566552933

Epoch: 6| Step: 10
Training loss: 3.4474687576293945
Validation loss: 2.989680900368639

Epoch: 6| Step: 11
Training loss: 3.1549599170684814
Validation loss: 2.984687523175311

Epoch: 6| Step: 12
Training loss: 3.3861308097839355
Validation loss: 2.9843940632317656

Epoch: 6| Step: 13
Training loss: 3.55277156829834
Validation loss: 2.980319315387357

Epoch: 7| Step: 0
Training loss: 2.842956781387329
Validation loss: 2.9641612550263763

Epoch: 6| Step: 1
Training loss: 2.812575340270996
Validation loss: 2.9505380353619977

Epoch: 6| Step: 2
Training loss: 4.2398529052734375
Validation loss: 2.951790045666438

Epoch: 6| Step: 3
Training loss: 3.4514739513397217
Validation loss: 2.936980257752121

Epoch: 6| Step: 4
Training loss: 2.730372428894043
Validation loss: 2.929849301615069

Epoch: 6| Step: 5
Training loss: 2.202176570892334
Validation loss: 2.9266508240853586

Epoch: 6| Step: 6
Training loss: 3.640749454498291
Validation loss: 2.9198176040444324

Epoch: 6| Step: 7
Training loss: 3.18253755569458
Validation loss: 2.911046676738288

Epoch: 6| Step: 8
Training loss: 2.553574562072754
Validation loss: 2.907153416705388

Epoch: 6| Step: 9
Training loss: 2.8755292892456055
Validation loss: 2.9016182166273876

Epoch: 6| Step: 10
Training loss: 2.7567267417907715
Validation loss: 2.9001315998774704

Epoch: 6| Step: 11
Training loss: 3.417668342590332
Validation loss: 2.891064102931689

Epoch: 6| Step: 12
Training loss: 3.0433521270751953
Validation loss: 2.8815992545056086

Epoch: 6| Step: 13
Training loss: 1.9687848091125488
Validation loss: 2.8747660165191977

Epoch: 8| Step: 0
Training loss: 3.345104932785034
Validation loss: 2.8739353431168424

Epoch: 6| Step: 1
Training loss: 3.7487258911132812
Validation loss: 2.8718202883197415

Epoch: 6| Step: 2
Training loss: 2.6313910484313965
Validation loss: 2.8619671534466486

Epoch: 6| Step: 3
Training loss: 2.696568012237549
Validation loss: 2.851851145426432

Epoch: 6| Step: 4
Training loss: 2.8738415241241455
Validation loss: 2.841406545331401

Epoch: 6| Step: 5
Training loss: 2.476952314376831
Validation loss: 2.834061391891972

Epoch: 6| Step: 6
Training loss: 3.18979549407959
Validation loss: 2.833968200991231

Epoch: 6| Step: 7
Training loss: 3.3072457313537598
Validation loss: 2.8241421663632957

Epoch: 6| Step: 8
Training loss: 3.155496835708618
Validation loss: 2.8214978351387927

Epoch: 6| Step: 9
Training loss: 2.645048141479492
Validation loss: 2.8151806118667766

Epoch: 6| Step: 10
Training loss: 2.592926263809204
Validation loss: 2.8245799849110265

Epoch: 6| Step: 11
Training loss: 2.9755189418792725
Validation loss: 2.805749880370273

Epoch: 6| Step: 12
Training loss: 2.5729334354400635
Validation loss: 2.8004409882330124

Epoch: 6| Step: 13
Training loss: 3.4786131381988525
Validation loss: 2.8157810882855485

Epoch: 9| Step: 0
Training loss: 2.62705135345459
Validation loss: 2.8001907563978627

Epoch: 6| Step: 1
Training loss: 2.3395185470581055
Validation loss: 2.8015674314191266

Epoch: 6| Step: 2
Training loss: 2.3076977729797363
Validation loss: 2.7958464289224274

Epoch: 6| Step: 3
Training loss: 3.336695671081543
Validation loss: 2.7931395448664182

Epoch: 6| Step: 4
Training loss: 3.0975117683410645
Validation loss: 2.786654149332354

Epoch: 6| Step: 5
Training loss: 2.2858219146728516
Validation loss: 2.7825044970358572

Epoch: 6| Step: 6
Training loss: 3.0353143215179443
Validation loss: 2.7796427075580885

Epoch: 6| Step: 7
Training loss: 3.3678555488586426
Validation loss: 2.7708485869951147

Epoch: 6| Step: 8
Training loss: 2.7963263988494873
Validation loss: 2.7681866063866565

Epoch: 6| Step: 9
Training loss: 3.192692279815674
Validation loss: 2.792596865725774

Epoch: 6| Step: 10
Training loss: 2.6394591331481934
Validation loss: 2.801209916350662

Epoch: 6| Step: 11
Training loss: 3.3670148849487305
Validation loss: 2.7986375029369066

Epoch: 6| Step: 12
Training loss: 3.3681981563568115
Validation loss: 2.776473142767465

Epoch: 6| Step: 13
Training loss: 3.3555052280426025
Validation loss: 2.7416818731574604

Epoch: 10| Step: 0
Training loss: 3.2889814376831055
Validation loss: 2.7611040607575448

Epoch: 6| Step: 1
Training loss: 3.3757824897766113
Validation loss: 2.8298904203599498

Epoch: 6| Step: 2
Training loss: 2.4941956996917725
Validation loss: 2.760479704026253

Epoch: 6| Step: 3
Training loss: 3.8774993419647217
Validation loss: 2.7482018778401036

Epoch: 6| Step: 4
Training loss: 2.7159132957458496
Validation loss: 2.7441447575887046

Epoch: 6| Step: 5
Training loss: 2.8442280292510986
Validation loss: 2.745688497379262

Epoch: 6| Step: 6
Training loss: 3.3171944618225098
Validation loss: 2.760675161115585

Epoch: 6| Step: 7
Training loss: 3.1362013816833496
Validation loss: 2.7612039427603445

Epoch: 6| Step: 8
Training loss: 2.111741304397583
Validation loss: 2.7508992072074645

Epoch: 6| Step: 9
Training loss: 2.977320909500122
Validation loss: 2.754758373383553

Epoch: 6| Step: 10
Training loss: 2.949309825897217
Validation loss: 2.773510335594095

Epoch: 6| Step: 11
Training loss: 2.4035212993621826
Validation loss: 2.73253381893199

Epoch: 6| Step: 12
Training loss: 2.865060329437256
Validation loss: 2.7228639407824446

Epoch: 6| Step: 13
Training loss: 1.8759217262268066
Validation loss: 2.712141872734152

Epoch: 11| Step: 0
Training loss: 2.747544527053833
Validation loss: 2.7087590232972176

Epoch: 6| Step: 1
Training loss: 2.955657482147217
Validation loss: 2.7105489905162523

Epoch: 6| Step: 2
Training loss: 2.812072992324829
Validation loss: 2.710977300520866

Epoch: 6| Step: 3
Training loss: 3.1836140155792236
Validation loss: 2.7113613261971423

Epoch: 6| Step: 4
Training loss: 1.8747799396514893
Validation loss: 2.7098754247029624

Epoch: 6| Step: 5
Training loss: 2.7730629444122314
Validation loss: 2.7093126914834462

Epoch: 6| Step: 6
Training loss: 2.719230890274048
Validation loss: 2.69912148803793

Epoch: 6| Step: 7
Training loss: 3.515894889831543
Validation loss: 2.690036425026514

Epoch: 6| Step: 8
Training loss: 3.3832900524139404
Validation loss: 2.684634259952012

Epoch: 6| Step: 9
Training loss: 2.6015257835388184
Validation loss: 2.6810696996668333

Epoch: 6| Step: 10
Training loss: 3.3280465602874756
Validation loss: 2.676295359929403

Epoch: 6| Step: 11
Training loss: 2.544593095779419
Validation loss: 2.676099267057193

Epoch: 6| Step: 12
Training loss: 2.671787738800049
Validation loss: 2.6746572371452086

Epoch: 6| Step: 13
Training loss: 3.0239453315734863
Validation loss: 2.6720382141810592

Epoch: 12| Step: 0
Training loss: 2.5808911323547363
Validation loss: 2.6799980260992564

Epoch: 6| Step: 1
Training loss: 2.3831686973571777
Validation loss: 2.6801453713447816

Epoch: 6| Step: 2
Training loss: 2.651578903198242
Validation loss: 2.6681185537768948

Epoch: 6| Step: 3
Training loss: 2.920790195465088
Validation loss: 2.6553048908069568

Epoch: 6| Step: 4
Training loss: 3.194162607192993
Validation loss: 2.6484031318336405

Epoch: 6| Step: 5
Training loss: 2.8212523460388184
Validation loss: 2.647454087452222

Epoch: 6| Step: 6
Training loss: 3.617804527282715
Validation loss: 2.6452104032680555

Epoch: 6| Step: 7
Training loss: 2.8536579608917236
Validation loss: 2.64813055017943

Epoch: 6| Step: 8
Training loss: 2.672807216644287
Validation loss: 2.639929340731713

Epoch: 6| Step: 9
Training loss: 2.5827698707580566
Validation loss: 2.6348151083915465

Epoch: 6| Step: 10
Training loss: 3.238199234008789
Validation loss: 2.639059564118744

Epoch: 6| Step: 11
Training loss: 3.179556131362915
Validation loss: 2.633576070108721

Epoch: 6| Step: 12
Training loss: 1.769840121269226
Validation loss: 2.63770805892124

Epoch: 6| Step: 13
Training loss: 3.4661080837249756
Validation loss: 2.6492363688766316

Epoch: 13| Step: 0
Training loss: 2.9482874870300293
Validation loss: 2.637119141958093

Epoch: 6| Step: 1
Training loss: 3.2717108726501465
Validation loss: 2.6252159149416032

Epoch: 6| Step: 2
Training loss: 2.3871896266937256
Validation loss: 2.622897522423857

Epoch: 6| Step: 3
Training loss: 2.5919721126556396
Validation loss: 2.640202811969224

Epoch: 6| Step: 4
Training loss: 3.6795411109924316
Validation loss: 2.7218693302523707

Epoch: 6| Step: 5
Training loss: 2.3158504962921143
Validation loss: 2.676348094017275

Epoch: 6| Step: 6
Training loss: 2.957191228866577
Validation loss: 2.657822870439099

Epoch: 6| Step: 7
Training loss: 3.2343993186950684
Validation loss: 2.6551867146645822

Epoch: 6| Step: 8
Training loss: 2.8894050121307373
Validation loss: 2.6908839748751734

Epoch: 6| Step: 9
Training loss: 2.697100877761841
Validation loss: 2.6330774907142884

Epoch: 6| Step: 10
Training loss: 2.541875123977661
Validation loss: 2.614568418072116

Epoch: 6| Step: 11
Training loss: 2.536898136138916
Validation loss: 2.6212635501738517

Epoch: 6| Step: 12
Training loss: 3.130932331085205
Validation loss: 2.6247792423412366

Epoch: 6| Step: 13
Training loss: 2.0792884826660156
Validation loss: 2.6220964385617163

Epoch: 14| Step: 0
Training loss: 3.0687332153320312
Validation loss: 2.625438949113251

Epoch: 6| Step: 1
Training loss: 3.0877676010131836
Validation loss: 2.6124065896516204

Epoch: 6| Step: 2
Training loss: 2.659170627593994
Validation loss: 2.6075935735497424

Epoch: 6| Step: 3
Training loss: 2.688352108001709
Validation loss: 2.607740271476007

Epoch: 6| Step: 4
Training loss: 2.8802006244659424
Validation loss: 2.6067643627043693

Epoch: 6| Step: 5
Training loss: 3.209679365158081
Validation loss: 2.6032333732933126

Epoch: 6| Step: 6
Training loss: 2.3868117332458496
Validation loss: 2.60422856320617

Epoch: 6| Step: 7
Training loss: 2.760622978210449
Validation loss: 2.600055202361076

Epoch: 6| Step: 8
Training loss: 2.383857488632202
Validation loss: 2.589092746857674

Epoch: 6| Step: 9
Training loss: 2.1847057342529297
Validation loss: 2.586293956284882

Epoch: 6| Step: 10
Training loss: 2.9709219932556152
Validation loss: 2.5831161237532094

Epoch: 6| Step: 11
Training loss: 3.2247748374938965
Validation loss: 2.585248501070084

Epoch: 6| Step: 12
Training loss: 2.804967164993286
Validation loss: 2.5947894178411013

Epoch: 6| Step: 13
Training loss: 3.072230815887451
Validation loss: 2.634988228480021

Epoch: 15| Step: 0
Training loss: 2.7746758460998535
Validation loss: 2.5984125111692693

Epoch: 6| Step: 1
Training loss: 2.4155831336975098
Validation loss: 2.5793307827365015

Epoch: 6| Step: 2
Training loss: 3.749955654144287
Validation loss: 2.5737226650279057

Epoch: 6| Step: 3
Training loss: 2.542529582977295
Validation loss: 2.566294485522855

Epoch: 6| Step: 4
Training loss: 2.3522825241088867
Validation loss: 2.5650140982802196

Epoch: 6| Step: 5
Training loss: 3.075322151184082
Validation loss: 2.5771803163713023

Epoch: 6| Step: 6
Training loss: 2.697378158569336
Validation loss: 2.5742695844301613

Epoch: 6| Step: 7
Training loss: 1.904862642288208
Validation loss: 2.5704690179517193

Epoch: 6| Step: 8
Training loss: 3.2104930877685547
Validation loss: 2.5579447336094354

Epoch: 6| Step: 9
Training loss: 3.6291792392730713
Validation loss: 2.551986578972109

Epoch: 6| Step: 10
Training loss: 2.8145313262939453
Validation loss: 2.5515956712025467

Epoch: 6| Step: 11
Training loss: 3.247746229171753
Validation loss: 2.554130090180264

Epoch: 6| Step: 12
Training loss: 1.9434311389923096
Validation loss: 2.5604399301672496

Epoch: 6| Step: 13
Training loss: 2.3295750617980957
Validation loss: 2.5626770527132097

Epoch: 16| Step: 0
Training loss: 2.8222265243530273
Validation loss: 2.5601535099808888

Epoch: 6| Step: 1
Training loss: 2.4154105186462402
Validation loss: 2.5595913804987425

Epoch: 6| Step: 2
Training loss: 2.8456857204437256
Validation loss: 2.5545519628832416

Epoch: 6| Step: 3
Training loss: 2.4375035762786865
Validation loss: 2.544514189484299

Epoch: 6| Step: 4
Training loss: 2.820944309234619
Validation loss: 2.5420727011977986

Epoch: 6| Step: 5
Training loss: 2.572657346725464
Validation loss: 2.5402705028492916

Epoch: 6| Step: 6
Training loss: 3.0669097900390625
Validation loss: 2.5450550330582487

Epoch: 6| Step: 7
Training loss: 2.532071590423584
Validation loss: 2.5451870861873833

Epoch: 6| Step: 8
Training loss: 2.433889389038086
Validation loss: 2.561114162527105

Epoch: 6| Step: 9
Training loss: 2.6039140224456787
Validation loss: 2.566673676172892

Epoch: 6| Step: 10
Training loss: 3.0610880851745605
Validation loss: 2.5436982852156445

Epoch: 6| Step: 11
Training loss: 3.824423313140869
Validation loss: 2.5426179183426725

Epoch: 6| Step: 12
Training loss: 2.121035099029541
Validation loss: 2.528605071447229

Epoch: 6| Step: 13
Training loss: 3.172323703765869
Validation loss: 2.530098315208189

Epoch: 17| Step: 0
Training loss: 2.251966714859009
Validation loss: 2.5283708085295973

Epoch: 6| Step: 1
Training loss: 3.1290206909179688
Validation loss: 2.5376969229790474

Epoch: 6| Step: 2
Training loss: 2.793729782104492
Validation loss: 2.546081281477405

Epoch: 6| Step: 3
Training loss: 2.672576904296875
Validation loss: 2.5393487330405944

Epoch: 6| Step: 4
Training loss: 2.677579879760742
Validation loss: 2.561300531510384

Epoch: 6| Step: 5
Training loss: 2.854184865951538
Validation loss: 2.5985241564371253

Epoch: 6| Step: 6
Training loss: 2.4028351306915283
Validation loss: 2.590210278828939

Epoch: 6| Step: 7
Training loss: 2.7650651931762695
Validation loss: 2.5870483998329408

Epoch: 6| Step: 8
Training loss: 1.7197189331054688
Validation loss: 2.5830877929605465

Epoch: 6| Step: 9
Training loss: 3.2489683628082275
Validation loss: 2.5807885918565976

Epoch: 6| Step: 10
Training loss: 2.369457721710205
Validation loss: 2.596088945224721

Epoch: 6| Step: 11
Training loss: 3.173060894012451
Validation loss: 2.5966844379260974

Epoch: 6| Step: 12
Training loss: 2.870803117752075
Validation loss: 2.5752969762330413

Epoch: 6| Step: 13
Training loss: 4.662121295928955
Validation loss: 2.5385310162780104

Epoch: 18| Step: 0
Training loss: 2.8024392127990723
Validation loss: 2.5136532604053454

Epoch: 6| Step: 1
Training loss: 2.5472049713134766
Validation loss: 2.508778795119255

Epoch: 6| Step: 2
Training loss: 2.919280767440796
Validation loss: 2.5123176420888593

Epoch: 6| Step: 3
Training loss: 2.469529628753662
Validation loss: 2.519235649416524

Epoch: 6| Step: 4
Training loss: 2.69667911529541
Validation loss: 2.5195985276211976

Epoch: 6| Step: 5
Training loss: 3.121220588684082
Validation loss: 2.531910152845485

Epoch: 6| Step: 6
Training loss: 3.060424327850342
Validation loss: 2.534532072723553

Epoch: 6| Step: 7
Training loss: 2.048290729522705
Validation loss: 2.538426632522255

Epoch: 6| Step: 8
Training loss: 2.951676845550537
Validation loss: 2.5330990488811205

Epoch: 6| Step: 9
Training loss: 2.689004421234131
Validation loss: 2.542420264213316

Epoch: 6| Step: 10
Training loss: 3.135568141937256
Validation loss: 2.549660062277189

Epoch: 6| Step: 11
Training loss: 2.2407279014587402
Validation loss: 2.5528628415958856

Epoch: 6| Step: 12
Training loss: 3.0596132278442383
Validation loss: 2.529621765177737

Epoch: 6| Step: 13
Training loss: 2.862365245819092
Validation loss: 2.5182015101114907

Epoch: 19| Step: 0
Training loss: 2.7097175121307373
Validation loss: 2.5198853118445284

Epoch: 6| Step: 1
Training loss: 2.5724570751190186
Validation loss: 2.5175989468892417

Epoch: 6| Step: 2
Training loss: 2.9505300521850586
Validation loss: 2.5157569710926344

Epoch: 6| Step: 3
Training loss: 3.4677774906158447
Validation loss: 2.5146265055543635

Epoch: 6| Step: 4
Training loss: 3.035083293914795
Validation loss: 2.508793205343267

Epoch: 6| Step: 5
Training loss: 2.0429859161376953
Validation loss: 2.518555341228362

Epoch: 6| Step: 6
Training loss: 2.018251895904541
Validation loss: 2.5442067218083206

Epoch: 6| Step: 7
Training loss: 2.7962841987609863
Validation loss: 2.5886208267622095

Epoch: 6| Step: 8
Training loss: 2.034005880355835
Validation loss: 2.664915100220711

Epoch: 6| Step: 9
Training loss: 2.9353363513946533
Validation loss: 2.7049715518951416

Epoch: 6| Step: 10
Training loss: 2.1511220932006836
Validation loss: 2.6847027732479956

Epoch: 6| Step: 11
Training loss: 3.6800174713134766
Validation loss: 2.632428853742538

Epoch: 6| Step: 12
Training loss: 3.398975372314453
Validation loss: 2.5672811436396774

Epoch: 6| Step: 13
Training loss: 2.8763961791992188
Validation loss: 2.5376095387243454

Epoch: 20| Step: 0
Training loss: 2.8398048877716064
Validation loss: 2.5345900853474936

Epoch: 6| Step: 1
Training loss: 2.8063488006591797
Validation loss: 2.6475487960282194

Epoch: 6| Step: 2
Training loss: 2.3814468383789062
Validation loss: 2.7332181187086206

Epoch: 6| Step: 3
Training loss: 2.797710418701172
Validation loss: 2.7747082351356425

Epoch: 6| Step: 4
Training loss: 2.9104104042053223
Validation loss: 2.744128114433699

Epoch: 6| Step: 5
Training loss: 3.1102733612060547
Validation loss: 2.692993658845143

Epoch: 6| Step: 6
Training loss: 2.9437320232391357
Validation loss: 2.652920348669893

Epoch: 6| Step: 7
Training loss: 2.3066678047180176
Validation loss: 2.6024832058978338

Epoch: 6| Step: 8
Training loss: 2.7572646141052246
Validation loss: 2.5768752046810683

Epoch: 6| Step: 9
Training loss: 2.410647392272949
Validation loss: 2.556442624779158

Epoch: 6| Step: 10
Training loss: 2.6207077503204346
Validation loss: 2.499365834779637

Epoch: 6| Step: 11
Training loss: 3.5716400146484375
Validation loss: 2.49918112703549

Epoch: 6| Step: 12
Training loss: 2.727057456970215
Validation loss: 2.4986790482715895

Epoch: 6| Step: 13
Training loss: 2.8385112285614014
Validation loss: 2.5137005826478362

Epoch: 21| Step: 0
Training loss: 2.8488287925720215
Validation loss: 2.515069741074757

Epoch: 6| Step: 1
Training loss: 2.4756128787994385
Validation loss: 2.5501162313645884

Epoch: 6| Step: 2
Training loss: 2.7217137813568115
Validation loss: 2.5508503324242047

Epoch: 6| Step: 3
Training loss: 3.299004554748535
Validation loss: 2.5279869135989936

Epoch: 6| Step: 4
Training loss: 2.189851760864258
Validation loss: 2.4946308802532893

Epoch: 6| Step: 5
Training loss: 3.516366958618164
Validation loss: 2.4853245160912953

Epoch: 6| Step: 6
Training loss: 2.800398111343384
Validation loss: 2.4717142094847975

Epoch: 6| Step: 7
Training loss: 2.2789509296417236
Validation loss: 2.4716564045157483

Epoch: 6| Step: 8
Training loss: 2.3003687858581543
Validation loss: 2.4703770632384927

Epoch: 6| Step: 9
Training loss: 3.055051326751709
Validation loss: 2.469985536349717

Epoch: 6| Step: 10
Training loss: 2.0557308197021484
Validation loss: 2.469818489525908

Epoch: 6| Step: 11
Training loss: 3.0652718544006348
Validation loss: 2.478880689990136

Epoch: 6| Step: 12
Training loss: 2.6642613410949707
Validation loss: 2.481268867369621

Epoch: 6| Step: 13
Training loss: 2.8903024196624756
Validation loss: 2.4801359458636214

Epoch: 22| Step: 0
Training loss: 2.5671377182006836
Validation loss: 2.4752272687932497

Epoch: 6| Step: 1
Training loss: 2.3062806129455566
Validation loss: 2.4664792168524956

Epoch: 6| Step: 2
Training loss: 2.6867847442626953
Validation loss: 2.4646655410848637

Epoch: 6| Step: 3
Training loss: 3.0883543491363525
Validation loss: 2.46396912810623

Epoch: 6| Step: 4
Training loss: 3.5343379974365234
Validation loss: 2.4597855075713126

Epoch: 6| Step: 5
Training loss: 3.1656837463378906
Validation loss: 2.4555091601546093

Epoch: 6| Step: 6
Training loss: 2.6659817695617676
Validation loss: 2.4470756207743

Epoch: 6| Step: 7
Training loss: 2.3196802139282227
Validation loss: 2.4434790508721465

Epoch: 6| Step: 8
Training loss: 2.6521053314208984
Validation loss: 2.441822172493063

Epoch: 6| Step: 9
Training loss: 2.509143590927124
Validation loss: 2.440968410943144

Epoch: 6| Step: 10
Training loss: 2.366049289703369
Validation loss: 2.446343121990081

Epoch: 6| Step: 11
Training loss: 2.4984285831451416
Validation loss: 2.454028348768911

Epoch: 6| Step: 12
Training loss: 2.5198683738708496
Validation loss: 2.4726384301339426

Epoch: 6| Step: 13
Training loss: 2.9762797355651855
Validation loss: 2.480425306545791

Epoch: 23| Step: 0
Training loss: 3.0147593021392822
Validation loss: 2.489664590486916

Epoch: 6| Step: 1
Training loss: 3.0432515144348145
Validation loss: 2.496540302871376

Epoch: 6| Step: 2
Training loss: 2.082368850708008
Validation loss: 2.4954678371388423

Epoch: 6| Step: 3
Training loss: 2.6536006927490234
Validation loss: 2.470146688081885

Epoch: 6| Step: 4
Training loss: 2.529242515563965
Validation loss: 2.449593892661474

Epoch: 6| Step: 5
Training loss: 3.1323633193969727
Validation loss: 2.4403948322419198

Epoch: 6| Step: 6
Training loss: 2.0483555793762207
Validation loss: 2.4662284633164764

Epoch: 6| Step: 7
Training loss: 2.2518091201782227
Validation loss: 2.4921459715853453

Epoch: 6| Step: 8
Training loss: 2.9775891304016113
Validation loss: 2.5303718761731218

Epoch: 6| Step: 9
Training loss: 2.97530460357666
Validation loss: 2.494330907380709

Epoch: 6| Step: 10
Training loss: 2.905488967895508
Validation loss: 2.4761898799609114

Epoch: 6| Step: 11
Training loss: 2.50783109664917
Validation loss: 2.467474381128947

Epoch: 6| Step: 12
Training loss: 2.4341511726379395
Validation loss: 2.483129470579086

Epoch: 6| Step: 13
Training loss: 3.670325756072998
Validation loss: 2.537215235412762

Epoch: 24| Step: 0
Training loss: 1.8973557949066162
Validation loss: 2.6396373869270406

Epoch: 6| Step: 1
Training loss: 1.9619636535644531
Validation loss: 2.7192056050864597

Epoch: 6| Step: 2
Training loss: 2.8886172771453857
Validation loss: 2.777327301681683

Epoch: 6| Step: 3
Training loss: 2.922496795654297
Validation loss: 2.765184592175227

Epoch: 6| Step: 4
Training loss: 3.124387264251709
Validation loss: 2.695393459771269

Epoch: 6| Step: 5
Training loss: 2.6083600521087646
Validation loss: 2.6268478055154123

Epoch: 6| Step: 6
Training loss: 3.0728867053985596
Validation loss: 2.5774722227486233

Epoch: 6| Step: 7
Training loss: 3.1812546253204346
Validation loss: 2.520110550747123

Epoch: 6| Step: 8
Training loss: 2.831967830657959
Validation loss: 2.4944454880170923

Epoch: 6| Step: 9
Training loss: 3.119070529937744
Validation loss: 2.5016659254668863

Epoch: 6| Step: 10
Training loss: 2.722583532333374
Validation loss: 2.5390475027022825

Epoch: 6| Step: 11
Training loss: 2.513986110687256
Validation loss: 2.558258177131735

Epoch: 6| Step: 12
Training loss: 3.0009994506835938
Validation loss: 2.588408067662229

Epoch: 6| Step: 13
Training loss: 3.2961161136627197
Validation loss: 2.598876368614935

Epoch: 25| Step: 0
Training loss: 3.2986788749694824
Validation loss: 2.5296056244962957

Epoch: 6| Step: 1
Training loss: 2.62985897064209
Validation loss: 2.4580867469951673

Epoch: 6| Step: 2
Training loss: 2.5224616527557373
Validation loss: 2.426278128418871

Epoch: 6| Step: 3
Training loss: 2.6031527519226074
Validation loss: 2.460880366704797

Epoch: 6| Step: 4
Training loss: 1.8562119007110596
Validation loss: 2.50856505158127

Epoch: 6| Step: 5
Training loss: 3.155271530151367
Validation loss: 2.56179428485132

Epoch: 6| Step: 6
Training loss: 2.911844253540039
Validation loss: 2.6418204794647875

Epoch: 6| Step: 7
Training loss: 2.943424701690674
Validation loss: 2.7192078380174536

Epoch: 6| Step: 8
Training loss: 2.882645606994629
Validation loss: 2.7426522649744505

Epoch: 6| Step: 9
Training loss: 2.6656856536865234
Validation loss: 2.74127104461834

Epoch: 6| Step: 10
Training loss: 3.6191658973693848
Validation loss: 2.7452431904372347

Epoch: 6| Step: 11
Training loss: 2.2994701862335205
Validation loss: 2.6652817572316816

Epoch: 6| Step: 12
Training loss: 2.564875602722168
Validation loss: 2.585043943056496

Epoch: 6| Step: 13
Training loss: 3.05185866355896
Validation loss: 2.5151625064111527

Epoch: 26| Step: 0
Training loss: 2.8922536373138428
Validation loss: 2.4542345026487946

Epoch: 6| Step: 1
Training loss: 2.983664035797119
Validation loss: 2.4272898935502574

Epoch: 6| Step: 2
Training loss: 2.364346981048584
Validation loss: 2.4468217639512915

Epoch: 6| Step: 3
Training loss: 3.713913917541504
Validation loss: 2.476968962659118

Epoch: 6| Step: 4
Training loss: 2.056706428527832
Validation loss: 2.5297084495585453

Epoch: 6| Step: 5
Training loss: 2.711738109588623
Validation loss: 2.6080840915761967

Epoch: 6| Step: 6
Training loss: 2.568862199783325
Validation loss: 2.6356697569611254

Epoch: 6| Step: 7
Training loss: 2.992746353149414
Validation loss: 2.6174182327844764

Epoch: 6| Step: 8
Training loss: 1.9864832162857056
Validation loss: 2.5531099432258197

Epoch: 6| Step: 9
Training loss: 3.337989330291748
Validation loss: 2.5038247390459945

Epoch: 6| Step: 10
Training loss: 2.241154909133911
Validation loss: 2.460167449007752

Epoch: 6| Step: 11
Training loss: 2.172497272491455
Validation loss: 2.459805065585721

Epoch: 6| Step: 12
Training loss: 3.666855573654175
Validation loss: 2.4535485441966722

Epoch: 6| Step: 13
Training loss: 2.4516117572784424
Validation loss: 2.4045457250328472

Epoch: 27| Step: 0
Training loss: 2.1518373489379883
Validation loss: 2.395054917181692

Epoch: 6| Step: 1
Training loss: 2.052450180053711
Validation loss: 2.3919350742011942

Epoch: 6| Step: 2
Training loss: 2.766449451446533
Validation loss: 2.3924938478777484

Epoch: 6| Step: 3
Training loss: 2.4994823932647705
Validation loss: 2.3986637720497708

Epoch: 6| Step: 4
Training loss: 2.76658296585083
Validation loss: 2.407084180462745

Epoch: 6| Step: 5
Training loss: 2.57523512840271
Validation loss: 2.422078706884897

Epoch: 6| Step: 6
Training loss: 3.760328531265259
Validation loss: 2.4338885481639574

Epoch: 6| Step: 7
Training loss: 2.7194159030914307
Validation loss: 2.4335061478358444

Epoch: 6| Step: 8
Training loss: 2.3194186687469482
Validation loss: 2.4193352422406598

Epoch: 6| Step: 9
Training loss: 2.418776035308838
Validation loss: 2.4016974767049155

Epoch: 6| Step: 10
Training loss: 2.615673542022705
Validation loss: 2.394583614923621

Epoch: 6| Step: 11
Training loss: 2.7593159675598145
Validation loss: 2.399043680519186

Epoch: 6| Step: 12
Training loss: 3.2460060119628906
Validation loss: 2.4004542904515422

Epoch: 6| Step: 13
Training loss: 2.893451452255249
Validation loss: 2.409481907403597

Epoch: 28| Step: 0
Training loss: 2.4422690868377686
Validation loss: 2.390290626915552

Epoch: 6| Step: 1
Training loss: 2.75709867477417
Validation loss: 2.3875219693747898

Epoch: 6| Step: 2
Training loss: 1.9075469970703125
Validation loss: 2.3851386808579966

Epoch: 6| Step: 3
Training loss: 3.696068286895752
Validation loss: 2.391299601524107

Epoch: 6| Step: 4
Training loss: 2.062230110168457
Validation loss: 2.392198444694601

Epoch: 6| Step: 5
Training loss: 2.677879571914673
Validation loss: 2.398494435894874

Epoch: 6| Step: 6
Training loss: 1.7795281410217285
Validation loss: 2.4081375932180755

Epoch: 6| Step: 7
Training loss: 3.1497397422790527
Validation loss: 2.4235105399162538

Epoch: 6| Step: 8
Training loss: 2.1887502670288086
Validation loss: 2.432624342621014

Epoch: 6| Step: 9
Training loss: 3.164586067199707
Validation loss: 2.449177336949174

Epoch: 6| Step: 10
Training loss: 3.232961416244507
Validation loss: 2.453327081536734

Epoch: 6| Step: 11
Training loss: 3.0236659049987793
Validation loss: 2.4537655358673423

Epoch: 6| Step: 12
Training loss: 2.694638729095459
Validation loss: 2.453971375701248

Epoch: 6| Step: 13
Training loss: 2.741159200668335
Validation loss: 2.469082268335486

Epoch: 29| Step: 0
Training loss: 2.5968449115753174
Validation loss: 2.459453862200501

Epoch: 6| Step: 1
Training loss: 1.8497930765151978
Validation loss: 2.467533755046065

Epoch: 6| Step: 2
Training loss: 2.6464169025421143
Validation loss: 2.4801254990280315

Epoch: 6| Step: 3
Training loss: 2.839663505554199
Validation loss: 2.465842411082278

Epoch: 6| Step: 4
Training loss: 2.808558940887451
Validation loss: 2.4635086392843597

Epoch: 6| Step: 5
Training loss: 3.0507943630218506
Validation loss: 2.4451800033610356

Epoch: 6| Step: 6
Training loss: 3.1808297634124756
Validation loss: 2.436258182730726

Epoch: 6| Step: 7
Training loss: 2.1643147468566895
Validation loss: 2.429895706074212

Epoch: 6| Step: 8
Training loss: 3.340749740600586
Validation loss: 2.428511678531606

Epoch: 6| Step: 9
Training loss: 2.020824432373047
Validation loss: 2.424916454540786

Epoch: 6| Step: 10
Training loss: 2.547879219055176
Validation loss: 2.4277210722687426

Epoch: 6| Step: 11
Training loss: 2.304595470428467
Validation loss: 2.4430531045441986

Epoch: 6| Step: 12
Training loss: 2.984124183654785
Validation loss: 2.4328769522328533

Epoch: 6| Step: 13
Training loss: 3.1928632259368896
Validation loss: 2.4245588907631497

Epoch: 30| Step: 0
Training loss: 2.192256450653076
Validation loss: 2.4153762299527406

Epoch: 6| Step: 1
Training loss: 3.0624585151672363
Validation loss: 2.416736654056016

Epoch: 6| Step: 2
Training loss: 2.9611401557922363
Validation loss: 2.4174931895348335

Epoch: 6| Step: 3
Training loss: 2.783984661102295
Validation loss: 2.4146055739413024

Epoch: 6| Step: 4
Training loss: 2.803884506225586
Validation loss: 2.410211581055836

Epoch: 6| Step: 5
Training loss: 2.7368311882019043
Validation loss: 2.4088022529437976

Epoch: 6| Step: 6
Training loss: 2.7650253772735596
Validation loss: 2.402681742945025

Epoch: 6| Step: 7
Training loss: 2.5133254528045654
Validation loss: 2.393509764825144

Epoch: 6| Step: 8
Training loss: 1.8912687301635742
Validation loss: 2.387628698861727

Epoch: 6| Step: 9
Training loss: 2.7740273475646973
Validation loss: 2.393966346658686

Epoch: 6| Step: 10
Training loss: 3.098496437072754
Validation loss: 2.3974138793124946

Epoch: 6| Step: 11
Training loss: 2.1306114196777344
Validation loss: 2.402276569797147

Epoch: 6| Step: 12
Training loss: 2.0977823734283447
Validation loss: 2.395302418739565

Epoch: 6| Step: 13
Training loss: 3.2821855545043945
Validation loss: 2.3868749141693115

Epoch: 31| Step: 0
Training loss: 2.5742597579956055
Validation loss: 2.3714485911912817

Epoch: 6| Step: 1
Training loss: 3.498697280883789
Validation loss: 2.3598159795166342

Epoch: 6| Step: 2
Training loss: 1.4362263679504395
Validation loss: 2.340751624876453

Epoch: 6| Step: 3
Training loss: 3.753887176513672
Validation loss: 2.3316913753427486

Epoch: 6| Step: 4
Training loss: 2.0933403968811035
Validation loss: 2.3280373901449223

Epoch: 6| Step: 5
Training loss: 2.2357993125915527
Validation loss: 2.3341604714752524

Epoch: 6| Step: 6
Training loss: 2.7380762100219727
Validation loss: 2.3613526590408815

Epoch: 6| Step: 7
Training loss: 2.712578296661377
Validation loss: 2.3835809846078195

Epoch: 6| Step: 8
Training loss: 2.05399227142334
Validation loss: 2.3720941953761603

Epoch: 6| Step: 9
Training loss: 2.6802597045898438
Validation loss: 2.3637264697782454

Epoch: 6| Step: 10
Training loss: 2.7248997688293457
Validation loss: 2.3495680286038305

Epoch: 6| Step: 11
Training loss: 3.7277560234069824
Validation loss: 2.3407089351325907

Epoch: 6| Step: 12
Training loss: 2.0611424446105957
Validation loss: 2.330437489735183

Epoch: 6| Step: 13
Training loss: 2.127115488052368
Validation loss: 2.3280349508408578

Epoch: 32| Step: 0
Training loss: 2.5900988578796387
Validation loss: 2.3243053549079487

Epoch: 6| Step: 1
Training loss: 1.8067759275436401
Validation loss: 2.3243264895613476

Epoch: 6| Step: 2
Training loss: 2.655479907989502
Validation loss: 2.333650358261601

Epoch: 6| Step: 3
Training loss: 2.941044569015503
Validation loss: 2.3291899465745494

Epoch: 6| Step: 4
Training loss: 2.240358829498291
Validation loss: 2.3396910429000854

Epoch: 6| Step: 5
Training loss: 3.1733155250549316
Validation loss: 2.347773309676878

Epoch: 6| Step: 6
Training loss: 2.176508903503418
Validation loss: 2.344484048504983

Epoch: 6| Step: 7
Training loss: 2.1827774047851562
Validation loss: 2.3416549800544657

Epoch: 6| Step: 8
Training loss: 2.6465139389038086
Validation loss: 2.3513813172617266

Epoch: 6| Step: 9
Training loss: 3.1389384269714355
Validation loss: 2.3605892119869107

Epoch: 6| Step: 10
Training loss: 2.316530704498291
Validation loss: 2.3612118331334924

Epoch: 6| Step: 11
Training loss: 3.039400100708008
Validation loss: 2.3527657498595533

Epoch: 6| Step: 12
Training loss: 2.3602685928344727
Validation loss: 2.347825332354474

Epoch: 6| Step: 13
Training loss: 3.7941441535949707
Validation loss: 2.340551899325463

Epoch: 33| Step: 0
Training loss: 2.1773793697357178
Validation loss: 2.3346065603276736

Epoch: 6| Step: 1
Training loss: 2.523685932159424
Validation loss: 2.331068584995885

Epoch: 6| Step: 2
Training loss: 2.654933452606201
Validation loss: 2.329980254173279

Epoch: 6| Step: 3
Training loss: 2.952082633972168
Validation loss: 2.3277904397697857

Epoch: 6| Step: 4
Training loss: 2.3043627738952637
Validation loss: 2.321286065604097

Epoch: 6| Step: 5
Training loss: 3.3668017387390137
Validation loss: 2.326480419405045

Epoch: 6| Step: 6
Training loss: 2.6918134689331055
Validation loss: 2.328936863971013

Epoch: 6| Step: 7
Training loss: 2.7840638160705566
Validation loss: 2.329032790276312

Epoch: 6| Step: 8
Training loss: 2.5974485874176025
Validation loss: 2.338538994071304

Epoch: 6| Step: 9
Training loss: 2.068390369415283
Validation loss: 2.3473236637730754

Epoch: 6| Step: 10
Training loss: 2.7862000465393066
Validation loss: 2.348776562239534

Epoch: 6| Step: 11
Training loss: 1.7141566276550293
Validation loss: 2.342751900355021

Epoch: 6| Step: 12
Training loss: 3.0925827026367188
Validation loss: 2.3475841501707673

Epoch: 6| Step: 13
Training loss: 2.6196093559265137
Validation loss: 2.3354288608797136

Epoch: 34| Step: 0
Training loss: 2.573827028274536
Validation loss: 2.3501725581384476

Epoch: 6| Step: 1
Training loss: 2.9413905143737793
Validation loss: 2.3585272014781995

Epoch: 6| Step: 2
Training loss: 2.303971767425537
Validation loss: 2.3603435485593733

Epoch: 6| Step: 3
Training loss: 2.8397178649902344
Validation loss: 2.354130680843066

Epoch: 6| Step: 4
Training loss: 2.6213464736938477
Validation loss: 2.364105465591595

Epoch: 6| Step: 5
Training loss: 2.5564470291137695
Validation loss: 2.363146233302291

Epoch: 6| Step: 6
Training loss: 2.4160499572753906
Validation loss: 2.355403164381622

Epoch: 6| Step: 7
Training loss: 3.1651289463043213
Validation loss: 2.3616184726838143

Epoch: 6| Step: 8
Training loss: 2.529057025909424
Validation loss: 2.362796457864905

Epoch: 6| Step: 9
Training loss: 1.8295152187347412
Validation loss: 2.353830801543369

Epoch: 6| Step: 10
Training loss: 2.801229476928711
Validation loss: 2.339246235867982

Epoch: 6| Step: 11
Training loss: 2.74729585647583
Validation loss: 2.337193432674613

Epoch: 6| Step: 12
Training loss: 2.4096171855926514
Validation loss: 2.3232139233619935

Epoch: 6| Step: 13
Training loss: 2.5406746864318848
Validation loss: 2.319516504964521

Epoch: 35| Step: 0
Training loss: 2.3947830200195312
Validation loss: 2.3268705747460805

Epoch: 6| Step: 1
Training loss: 1.950082540512085
Validation loss: 2.3392027578046246

Epoch: 6| Step: 2
Training loss: 2.2607970237731934
Validation loss: 2.3456567641227477

Epoch: 6| Step: 3
Training loss: 2.544365406036377
Validation loss: 2.349151481864273

Epoch: 6| Step: 4
Training loss: 2.830212116241455
Validation loss: 2.382974229833131

Epoch: 6| Step: 5
Training loss: 2.488429069519043
Validation loss: 2.4077117327720887

Epoch: 6| Step: 6
Training loss: 3.0491180419921875
Validation loss: 2.4239757086641047

Epoch: 6| Step: 7
Training loss: 2.663395404815674
Validation loss: 2.41559200902139

Epoch: 6| Step: 8
Training loss: 2.3321194648742676
Validation loss: 2.4014679770315848

Epoch: 6| Step: 9
Training loss: 3.2267088890075684
Validation loss: 2.3762700403890302

Epoch: 6| Step: 10
Training loss: 2.725588321685791
Validation loss: 2.3525566080565095

Epoch: 6| Step: 11
Training loss: 2.8268654346466064
Validation loss: 2.3499607219490954

Epoch: 6| Step: 12
Training loss: 2.8983230590820312
Validation loss: 2.3530364139105684

Epoch: 6| Step: 13
Training loss: 2.365967035293579
Validation loss: 2.3611348752052552

Epoch: 36| Step: 0
Training loss: 2.244713306427002
Validation loss: 2.353218699014315

Epoch: 6| Step: 1
Training loss: 2.8873753547668457
Validation loss: 2.337429900323191

Epoch: 6| Step: 2
Training loss: 2.253983974456787
Validation loss: 2.330002143818845

Epoch: 6| Step: 3
Training loss: 2.625413179397583
Validation loss: 2.330103225605462

Epoch: 6| Step: 4
Training loss: 2.3173837661743164
Validation loss: 2.3330454159808416

Epoch: 6| Step: 5
Training loss: 3.110255718231201
Validation loss: 2.344556575180382

Epoch: 6| Step: 6
Training loss: 1.4858877658843994
Validation loss: 2.367412737620774

Epoch: 6| Step: 7
Training loss: 2.436516046524048
Validation loss: 2.3613452167921167

Epoch: 6| Step: 8
Training loss: 2.567080497741699
Validation loss: 2.3528313662416194

Epoch: 6| Step: 9
Training loss: 3.3270821571350098
Validation loss: 2.3465211596540225

Epoch: 6| Step: 10
Training loss: 2.702800750732422
Validation loss: 2.333387877351494

Epoch: 6| Step: 11
Training loss: 2.8492565155029297
Validation loss: 2.325632031245898

Epoch: 6| Step: 12
Training loss: 3.075641632080078
Validation loss: 2.3087872869224957

Epoch: 6| Step: 13
Training loss: 2.092264413833618
Validation loss: 2.298553917997627

Epoch: 37| Step: 0
Training loss: 2.6248722076416016
Validation loss: 2.2996463980726016

Epoch: 6| Step: 1
Training loss: 1.8561744689941406
Validation loss: 2.3021635381124352

Epoch: 6| Step: 2
Training loss: 2.3654890060424805
Validation loss: 2.301686015180362

Epoch: 6| Step: 3
Training loss: 1.8347543478012085
Validation loss: 2.3107745596157607

Epoch: 6| Step: 4
Training loss: 3.180549144744873
Validation loss: 2.3072673556625203

Epoch: 6| Step: 5
Training loss: 2.3736367225646973
Validation loss: 2.3132795902990524

Epoch: 6| Step: 6
Training loss: 2.43754243850708
Validation loss: 2.3130329039789017

Epoch: 6| Step: 7
Training loss: 2.709590196609497
Validation loss: 2.3115244270652853

Epoch: 6| Step: 8
Training loss: 2.644772529602051
Validation loss: 2.3170558021914576

Epoch: 6| Step: 9
Training loss: 3.2965784072875977
Validation loss: 2.3085613789096957

Epoch: 6| Step: 10
Training loss: 3.249328374862671
Validation loss: 2.3081679228813416

Epoch: 6| Step: 11
Training loss: 2.293728828430176
Validation loss: 2.3025179152847617

Epoch: 6| Step: 12
Training loss: 2.669851303100586
Validation loss: 2.300266888833815

Epoch: 6| Step: 13
Training loss: 2.3340213298797607
Validation loss: 2.3171061931117887

Epoch: 38| Step: 0
Training loss: 2.527510166168213
Validation loss: 2.3302848287808

Epoch: 6| Step: 1
Training loss: 2.4795284271240234
Validation loss: 2.3670146490937922

Epoch: 6| Step: 2
Training loss: 2.827008008956909
Validation loss: 2.37219024473621

Epoch: 6| Step: 3
Training loss: 2.5979552268981934
Validation loss: 2.3732685042965795

Epoch: 6| Step: 4
Training loss: 2.185185194015503
Validation loss: 2.356512572175713

Epoch: 6| Step: 5
Training loss: 3.6760687828063965
Validation loss: 2.332979481707337

Epoch: 6| Step: 6
Training loss: 3.3468034267425537
Validation loss: 2.302475480623143

Epoch: 6| Step: 7
Training loss: 2.06196928024292
Validation loss: 2.29649761415297

Epoch: 6| Step: 8
Training loss: 2.4110138416290283
Validation loss: 2.288479725519816

Epoch: 6| Step: 9
Training loss: 3.040233612060547
Validation loss: 2.2842936079989196

Epoch: 6| Step: 10
Training loss: 2.064239025115967
Validation loss: 2.283535043398539

Epoch: 6| Step: 11
Training loss: 1.9133880138397217
Validation loss: 2.276742018679137

Epoch: 6| Step: 12
Training loss: 2.697206497192383
Validation loss: 2.283237588021063

Epoch: 6| Step: 13
Training loss: 2.0043208599090576
Validation loss: 2.2800415626136203

Epoch: 39| Step: 0
Training loss: 2.388185501098633
Validation loss: 2.2824451385005826

Epoch: 6| Step: 1
Training loss: 2.347618341445923
Validation loss: 2.2933042856954757

Epoch: 6| Step: 2
Training loss: 3.051217555999756
Validation loss: 2.3028754764987576

Epoch: 6| Step: 3
Training loss: 2.2481908798217773
Validation loss: 2.30107589690916

Epoch: 6| Step: 4
Training loss: 2.843006134033203
Validation loss: 2.306419341794906

Epoch: 6| Step: 5
Training loss: 2.383314847946167
Validation loss: 2.3171858326081307

Epoch: 6| Step: 6
Training loss: 1.463394284248352
Validation loss: 2.3264845468664683

Epoch: 6| Step: 7
Training loss: 2.4265451431274414
Validation loss: 2.332034754496749

Epoch: 6| Step: 8
Training loss: 2.8776631355285645
Validation loss: 2.344292051048689

Epoch: 6| Step: 9
Training loss: 2.187302827835083
Validation loss: 2.3460401591434272

Epoch: 6| Step: 10
Training loss: 3.1640658378601074
Validation loss: 2.3454431615849978

Epoch: 6| Step: 11
Training loss: 2.740288734436035
Validation loss: 2.3309889865177933

Epoch: 6| Step: 12
Training loss: 2.831683397293091
Validation loss: 2.3320556186860606

Epoch: 6| Step: 13
Training loss: 3.246901750564575
Validation loss: 2.3278710944678194

Epoch: 40| Step: 0
Training loss: 2.7431249618530273
Validation loss: 2.3322147964149393

Epoch: 6| Step: 1
Training loss: 2.389464855194092
Validation loss: 2.326931417629283

Epoch: 6| Step: 2
Training loss: 3.084754705429077
Validation loss: 2.3249443410545267

Epoch: 6| Step: 3
Training loss: 2.1054389476776123
Validation loss: 2.3309690952301025

Epoch: 6| Step: 4
Training loss: 2.6326441764831543
Validation loss: 2.3301124316389843

Epoch: 6| Step: 5
Training loss: 2.511622905731201
Validation loss: 2.329237400844533

Epoch: 6| Step: 6
Training loss: 2.9416866302490234
Validation loss: 2.3293951711347027

Epoch: 6| Step: 7
Training loss: 2.1691718101501465
Validation loss: 2.336087170467582

Epoch: 6| Step: 8
Training loss: 2.3700709342956543
Validation loss: 2.3286873525188816

Epoch: 6| Step: 9
Training loss: 2.1334874629974365
Validation loss: 2.3189622663682505

Epoch: 6| Step: 10
Training loss: 3.0603079795837402
Validation loss: 2.299926814212594

Epoch: 6| Step: 11
Training loss: 2.2754640579223633
Validation loss: 2.3037634011237853

Epoch: 6| Step: 12
Training loss: 2.8493494987487793
Validation loss: 2.3039037437849146

Epoch: 6| Step: 13
Training loss: 2.979022741317749
Validation loss: 2.314355898928899

Epoch: 41| Step: 0
Training loss: 2.416548728942871
Validation loss: 2.292281714818811

Epoch: 6| Step: 1
Training loss: 1.9838120937347412
Validation loss: 2.3032173495138846

Epoch: 6| Step: 2
Training loss: 2.65989351272583
Validation loss: 2.3161247468763784

Epoch: 6| Step: 3
Training loss: 2.2261905670166016
Validation loss: 2.316823951659664

Epoch: 6| Step: 4
Training loss: 2.435885429382324
Validation loss: 2.3090777679156234

Epoch: 6| Step: 5
Training loss: 2.1546308994293213
Validation loss: 2.3086888431220927

Epoch: 6| Step: 6
Training loss: 2.761974334716797
Validation loss: 2.3025790388866136

Epoch: 6| Step: 7
Training loss: 2.357100009918213
Validation loss: 2.2859506530146443

Epoch: 6| Step: 8
Training loss: 3.1549386978149414
Validation loss: 2.2884032213559715

Epoch: 6| Step: 9
Training loss: 2.7071733474731445
Validation loss: 2.2950737194348405

Epoch: 6| Step: 10
Training loss: 2.5877621173858643
Validation loss: 2.300198838274966

Epoch: 6| Step: 11
Training loss: 3.1879754066467285
Validation loss: 2.314641493622975

Epoch: 6| Step: 12
Training loss: 3.0630433559417725
Validation loss: 2.3352730402382473

Epoch: 6| Step: 13
Training loss: 2.017707586288452
Validation loss: 2.3272740071819675

Epoch: 42| Step: 0
Training loss: 2.8733417987823486
Validation loss: 2.321859480232321

Epoch: 6| Step: 1
Training loss: 1.9220644235610962
Validation loss: 2.34246705039855

Epoch: 6| Step: 2
Training loss: 2.469754219055176
Validation loss: 2.3392875348368

Epoch: 6| Step: 3
Training loss: 2.391019344329834
Validation loss: 2.3425962809593446

Epoch: 6| Step: 4
Training loss: 3.1113760471343994
Validation loss: 2.3549141781304472

Epoch: 6| Step: 5
Training loss: 2.280733823776245
Validation loss: 2.351658321196033

Epoch: 6| Step: 6
Training loss: 2.2142090797424316
Validation loss: 2.3189882488660913

Epoch: 6| Step: 7
Training loss: 2.6244754791259766
Validation loss: 2.287356653521138

Epoch: 6| Step: 8
Training loss: 2.870579719543457
Validation loss: 2.255898562810754

Epoch: 6| Step: 9
Training loss: 2.721869468688965
Validation loss: 2.237636007288451

Epoch: 6| Step: 10
Training loss: 2.412148952484131
Validation loss: 2.231526995217928

Epoch: 6| Step: 11
Training loss: 2.61698055267334
Validation loss: 2.2346716491124963

Epoch: 6| Step: 12
Training loss: 2.5090837478637695
Validation loss: 2.2397072725398566

Epoch: 6| Step: 13
Training loss: 2.788727283477783
Validation loss: 2.2446881724942114

Epoch: 43| Step: 0
Training loss: 2.3090782165527344
Validation loss: 2.2521656649087065

Epoch: 6| Step: 1
Training loss: 3.173429489135742
Validation loss: 2.259393681762039

Epoch: 6| Step: 2
Training loss: 2.9008913040161133
Validation loss: 2.262094977081463

Epoch: 6| Step: 3
Training loss: 2.7032814025878906
Validation loss: 2.25862011601848

Epoch: 6| Step: 4
Training loss: 1.9918930530548096
Validation loss: 2.252327003786641

Epoch: 6| Step: 5
Training loss: 3.068636894226074
Validation loss: 2.266236646201021

Epoch: 6| Step: 6
Training loss: 2.68143892288208
Validation loss: 2.2766701149684128

Epoch: 6| Step: 7
Training loss: 2.467621088027954
Validation loss: 2.280265869632844

Epoch: 6| Step: 8
Training loss: 2.1670267581939697
Validation loss: 2.2879819536721833

Epoch: 6| Step: 9
Training loss: 2.019109010696411
Validation loss: 2.3135105204838577

Epoch: 6| Step: 10
Training loss: 3.123199939727783
Validation loss: 2.3369190949265675

Epoch: 6| Step: 11
Training loss: 1.8772647380828857
Validation loss: 2.3564389597985054

Epoch: 6| Step: 12
Training loss: 3.346083641052246
Validation loss: 2.382486476693102

Epoch: 6| Step: 13
Training loss: 1.9264390468597412
Validation loss: 2.371176417155932

Epoch: 44| Step: 0
Training loss: 2.7529642581939697
Validation loss: 2.3954630859436525

Epoch: 6| Step: 1
Training loss: 3.1288013458251953
Validation loss: 2.3840577012749127

Epoch: 6| Step: 2
Training loss: 2.686677932739258
Validation loss: 2.35999132228154

Epoch: 6| Step: 3
Training loss: 2.9338791370391846
Validation loss: 2.3211976969113914

Epoch: 6| Step: 4
Training loss: 2.87981915473938
Validation loss: 2.278674325635356

Epoch: 6| Step: 5
Training loss: 2.846472978591919
Validation loss: 2.2641556442424817

Epoch: 6| Step: 6
Training loss: 2.036003589630127
Validation loss: 2.255789256864978

Epoch: 6| Step: 7
Training loss: 2.7176315784454346
Validation loss: 2.2533559068556754

Epoch: 6| Step: 8
Training loss: 2.3043911457061768
Validation loss: 2.247869066012803

Epoch: 6| Step: 9
Training loss: 2.221421957015991
Validation loss: 2.2475865220510833

Epoch: 6| Step: 10
Training loss: 2.3868308067321777
Validation loss: 2.249033122934321

Epoch: 6| Step: 11
Training loss: 1.9476745128631592
Validation loss: 2.244029305314505

Epoch: 6| Step: 12
Training loss: 2.618638753890991
Validation loss: 2.253232556004678

Epoch: 6| Step: 13
Training loss: 2.154508113861084
Validation loss: 2.2713732283602477

Epoch: 45| Step: 0
Training loss: 2.979583740234375
Validation loss: 2.275981221147763

Epoch: 6| Step: 1
Training loss: 2.561702251434326
Validation loss: 2.2792879612215105

Epoch: 6| Step: 2
Training loss: 2.0239198207855225
Validation loss: 2.282906798906224

Epoch: 6| Step: 3
Training loss: 2.414072036743164
Validation loss: 2.278758887321718

Epoch: 6| Step: 4
Training loss: 2.7997829914093018
Validation loss: 2.2831075601680304

Epoch: 6| Step: 5
Training loss: 2.1715774536132812
Validation loss: 2.2877391563948763

Epoch: 6| Step: 6
Training loss: 2.527738094329834
Validation loss: 2.3089466556426017

Epoch: 6| Step: 7
Training loss: 3.191340446472168
Validation loss: 2.309154043915451

Epoch: 6| Step: 8
Training loss: 2.607564926147461
Validation loss: 2.2876755755434752

Epoch: 6| Step: 9
Training loss: 2.6239371299743652
Validation loss: 2.258378092960645

Epoch: 6| Step: 10
Training loss: 2.0896458625793457
Validation loss: 2.247227047079353

Epoch: 6| Step: 11
Training loss: 2.2006125450134277
Validation loss: 2.2388231459484307

Epoch: 6| Step: 12
Training loss: 2.870192289352417
Validation loss: 2.2375171428085654

Epoch: 6| Step: 13
Training loss: 2.4337518215179443
Validation loss: 2.231827623100691

Epoch: 46| Step: 0
Training loss: 3.3610177040100098
Validation loss: 2.2410634102359897

Epoch: 6| Step: 1
Training loss: 2.06215238571167
Validation loss: 2.2489362762820337

Epoch: 6| Step: 2
Training loss: 2.656343460083008
Validation loss: 2.2652582865889355

Epoch: 6| Step: 3
Training loss: 2.0290732383728027
Validation loss: 2.2534190275335826

Epoch: 6| Step: 4
Training loss: 1.9792174100875854
Validation loss: 2.2657809667689826

Epoch: 6| Step: 5
Training loss: 2.09102725982666
Validation loss: 2.268400128169726

Epoch: 6| Step: 6
Training loss: 2.9468040466308594
Validation loss: 2.269280497745801

Epoch: 6| Step: 7
Training loss: 2.9191882610321045
Validation loss: 2.279567849251532

Epoch: 6| Step: 8
Training loss: 2.635669469833374
Validation loss: 2.283802027343422

Epoch: 6| Step: 9
Training loss: 2.2385921478271484
Validation loss: 2.300768013923399

Epoch: 6| Step: 10
Training loss: 2.581930637359619
Validation loss: 2.3573084185200353

Epoch: 6| Step: 11
Training loss: 2.6013872623443604
Validation loss: 2.376768409564931

Epoch: 6| Step: 12
Training loss: 2.6645870208740234
Validation loss: 2.380450100027105

Epoch: 6| Step: 13
Training loss: 3.3773107528686523
Validation loss: 2.3350608707756124

Epoch: 47| Step: 0
Training loss: 2.5411434173583984
Validation loss: 2.296624611782771

Epoch: 6| Step: 1
Training loss: 2.3596038818359375
Validation loss: 2.270119177397861

Epoch: 6| Step: 2
Training loss: 1.922520637512207
Validation loss: 2.2415969807614564

Epoch: 6| Step: 3
Training loss: 2.062150001525879
Validation loss: 2.2322200165000012

Epoch: 6| Step: 4
Training loss: 2.312680721282959
Validation loss: 2.2247723597352222

Epoch: 6| Step: 5
Training loss: 2.501491069793701
Validation loss: 2.2352286718224965

Epoch: 6| Step: 6
Training loss: 2.692077398300171
Validation loss: 2.247439794642951

Epoch: 6| Step: 7
Training loss: 2.9250290393829346
Validation loss: 2.2547013028975456

Epoch: 6| Step: 8
Training loss: 2.9957354068756104
Validation loss: 2.2669185361554547

Epoch: 6| Step: 9
Training loss: 2.717496156692505
Validation loss: 2.2632130166535736

Epoch: 6| Step: 10
Training loss: 3.076557159423828
Validation loss: 2.2560217995797434

Epoch: 6| Step: 11
Training loss: 2.328505754470825
Validation loss: 2.246364647342313

Epoch: 6| Step: 12
Training loss: 2.5384860038757324
Validation loss: 2.242201029613454

Epoch: 6| Step: 13
Training loss: 2.5575029850006104
Validation loss: 2.2483783832160373

Epoch: 48| Step: 0
Training loss: 2.1625442504882812
Validation loss: 2.266849528076828

Epoch: 6| Step: 1
Training loss: 2.845611810684204
Validation loss: 2.2826667754880843

Epoch: 6| Step: 2
Training loss: 2.129045009613037
Validation loss: 2.29424855273257

Epoch: 6| Step: 3
Training loss: 3.1359987258911133
Validation loss: 2.306937313848926

Epoch: 6| Step: 4
Training loss: 2.3077099323272705
Validation loss: 2.308097254845404

Epoch: 6| Step: 5
Training loss: 2.522671699523926
Validation loss: 2.326193453163229

Epoch: 6| Step: 6
Training loss: 2.3071653842926025
Validation loss: 2.3325379228079193

Epoch: 6| Step: 7
Training loss: 2.8274106979370117
Validation loss: 2.328148183002267

Epoch: 6| Step: 8
Training loss: 2.603426456451416
Validation loss: 2.3281272918947282

Epoch: 6| Step: 9
Training loss: 2.252523422241211
Validation loss: 2.3163799906289704

Epoch: 6| Step: 10
Training loss: 3.1871914863586426
Validation loss: 2.2966791737464165

Epoch: 6| Step: 11
Training loss: 2.4151740074157715
Validation loss: 2.24735604306703

Epoch: 6| Step: 12
Training loss: 2.551784038543701
Validation loss: 2.2211049346513647

Epoch: 6| Step: 13
Training loss: 1.9064210653305054
Validation loss: 2.217402699173138

Epoch: 49| Step: 0
Training loss: 2.979114055633545
Validation loss: 2.227239190891225

Epoch: 6| Step: 1
Training loss: 2.387855291366577
Validation loss: 2.2624702735613753

Epoch: 6| Step: 2
Training loss: 2.8593316078186035
Validation loss: 2.292906920115153

Epoch: 6| Step: 3
Training loss: 2.2357406616210938
Validation loss: 2.30044823820873

Epoch: 6| Step: 4
Training loss: 3.117504119873047
Validation loss: 2.2894387732269945

Epoch: 6| Step: 5
Training loss: 2.407310962677002
Validation loss: 2.260823160089472

Epoch: 6| Step: 6
Training loss: 2.9640426635742188
Validation loss: 2.229722476774646

Epoch: 6| Step: 7
Training loss: 2.7555253505706787
Validation loss: 2.206210154359059

Epoch: 6| Step: 8
Training loss: 2.3838798999786377
Validation loss: 2.20947374579727

Epoch: 6| Step: 9
Training loss: 1.971153974533081
Validation loss: 2.219236220082929

Epoch: 6| Step: 10
Training loss: 2.531588077545166
Validation loss: 2.2380928147223687

Epoch: 6| Step: 11
Training loss: 2.3204526901245117
Validation loss: 2.2705073100264355

Epoch: 6| Step: 12
Training loss: 2.30161452293396
Validation loss: 2.3424663876974456

Epoch: 6| Step: 13
Training loss: 2.8425722122192383
Validation loss: 2.3738518145776566

Epoch: 50| Step: 0
Training loss: 2.5357446670532227
Validation loss: 2.4090264407537316

Epoch: 6| Step: 1
Training loss: 2.0796124935150146
Validation loss: 2.4145340663130566

Epoch: 6| Step: 2
Training loss: 2.2958929538726807
Validation loss: 2.4079127926980295

Epoch: 6| Step: 3
Training loss: 2.514770030975342
Validation loss: 2.416595225693077

Epoch: 6| Step: 4
Training loss: 2.6162729263305664
Validation loss: 2.4190344759213027

Epoch: 6| Step: 5
Training loss: 3.049239158630371
Validation loss: 2.406628567685363

Epoch: 6| Step: 6
Training loss: 2.7367000579833984
Validation loss: 2.366114447193761

Epoch: 6| Step: 7
Training loss: 2.2255947589874268
Validation loss: 2.3157790271184777

Epoch: 6| Step: 8
Training loss: 2.761265754699707
Validation loss: 2.2608834902445474

Epoch: 6| Step: 9
Training loss: 2.983403444290161
Validation loss: 2.2059420231849916

Epoch: 6| Step: 10
Training loss: 2.9974544048309326
Validation loss: 2.1906491453929613

Epoch: 6| Step: 11
Training loss: 2.2123184204101562
Validation loss: 2.1857852320517264

Epoch: 6| Step: 12
Training loss: 2.7058467864990234
Validation loss: 2.187452821321385

Epoch: 6| Step: 13
Training loss: 2.0675463676452637
Validation loss: 2.2064077085064304

Epoch: 51| Step: 0
Training loss: 2.732431411743164
Validation loss: 2.2188712884021062

Epoch: 6| Step: 1
Training loss: 2.353517532348633
Validation loss: 2.220235368256928

Epoch: 6| Step: 2
Training loss: 3.0628509521484375
Validation loss: 2.2132608198350474

Epoch: 6| Step: 3
Training loss: 2.658987045288086
Validation loss: 2.2002689889682236

Epoch: 6| Step: 4
Training loss: 2.0449583530426025
Validation loss: 2.184917134623374

Epoch: 6| Step: 5
Training loss: 2.5913939476013184
Validation loss: 2.195154522054939

Epoch: 6| Step: 6
Training loss: 2.311802864074707
Validation loss: 2.194995855772367

Epoch: 6| Step: 7
Training loss: 2.4300999641418457
Validation loss: 2.2002413195948445

Epoch: 6| Step: 8
Training loss: 2.1790246963500977
Validation loss: 2.2005918205425306

Epoch: 6| Step: 9
Training loss: 3.25527286529541
Validation loss: 2.2111866089605514

Epoch: 6| Step: 10
Training loss: 2.7696757316589355
Validation loss: 2.223492782603028

Epoch: 6| Step: 11
Training loss: 1.804641604423523
Validation loss: 2.234893966746587

Epoch: 6| Step: 12
Training loss: 2.6238226890563965
Validation loss: 2.2370113172838764

Epoch: 6| Step: 13
Training loss: 2.033877372741699
Validation loss: 2.2414418599938832

Epoch: 52| Step: 0
Training loss: 3.148904323577881
Validation loss: 2.247119580545733

Epoch: 6| Step: 1
Training loss: 2.1379690170288086
Validation loss: 2.236986662751885

Epoch: 6| Step: 2
Training loss: 2.518824338912964
Validation loss: 2.2331343466235745

Epoch: 6| Step: 3
Training loss: 2.819758653640747
Validation loss: 2.246921875143564

Epoch: 6| Step: 4
Training loss: 2.5353662967681885
Validation loss: 2.2423504783261206

Epoch: 6| Step: 5
Training loss: 2.526559829711914
Validation loss: 2.2498720281867572

Epoch: 6| Step: 6
Training loss: 2.3156609535217285
Validation loss: 2.249072297926872

Epoch: 6| Step: 7
Training loss: 2.558739423751831
Validation loss: 2.235436567696192

Epoch: 6| Step: 8
Training loss: 2.4074878692626953
Validation loss: 2.201312686807366

Epoch: 6| Step: 9
Training loss: 2.6597230434417725
Validation loss: 2.192634206946178

Epoch: 6| Step: 10
Training loss: 2.467742681503296
Validation loss: 2.1763874946102018

Epoch: 6| Step: 11
Training loss: 2.8920421600341797
Validation loss: 2.1732035606138167

Epoch: 6| Step: 12
Training loss: 1.6114037036895752
Validation loss: 2.1764124362699446

Epoch: 6| Step: 13
Training loss: 2.657050132751465
Validation loss: 2.185675500541605

Epoch: 53| Step: 0
Training loss: 2.624638319015503
Validation loss: 2.19134723114711

Epoch: 6| Step: 1
Training loss: 2.6487154960632324
Validation loss: 2.1939815731458765

Epoch: 6| Step: 2
Training loss: 2.3166708946228027
Validation loss: 2.1920950207658993

Epoch: 6| Step: 3
Training loss: 3.241915702819824
Validation loss: 2.1893089458506596

Epoch: 6| Step: 4
Training loss: 2.2519307136535645
Validation loss: 2.185118812386708

Epoch: 6| Step: 5
Training loss: 2.393075466156006
Validation loss: 2.182940367729433

Epoch: 6| Step: 6
Training loss: 2.7805747985839844
Validation loss: 2.186574879512992

Epoch: 6| Step: 7
Training loss: 2.246950149536133
Validation loss: 2.1864862403561993

Epoch: 6| Step: 8
Training loss: 2.05420184135437
Validation loss: 2.1920704508340485

Epoch: 6| Step: 9
Training loss: 2.8560361862182617
Validation loss: 2.1986832003439627

Epoch: 6| Step: 10
Training loss: 2.569408416748047
Validation loss: 2.2000299512699084

Epoch: 6| Step: 11
Training loss: 2.3836848735809326
Validation loss: 2.2146042546918316

Epoch: 6| Step: 12
Training loss: 2.2688121795654297
Validation loss: 2.2325004198217906

Epoch: 6| Step: 13
Training loss: 2.6235194206237793
Validation loss: 2.248463212802846

Epoch: 54| Step: 0
Training loss: 2.3242692947387695
Validation loss: 2.2754101830144084

Epoch: 6| Step: 1
Training loss: 2.4917478561401367
Validation loss: 2.2366877422537854

Epoch: 6| Step: 2
Training loss: 2.6085352897644043
Validation loss: 2.211037125638736

Epoch: 6| Step: 3
Training loss: 2.8173205852508545
Validation loss: 2.1913207013119935

Epoch: 6| Step: 4
Training loss: 2.501650333404541
Validation loss: 2.183710931449808

Epoch: 6| Step: 5
Training loss: 3.2140932083129883
Validation loss: 2.174038653732628

Epoch: 6| Step: 6
Training loss: 2.0130655765533447
Validation loss: 2.1646804937752346

Epoch: 6| Step: 7
Training loss: 2.3709359169006348
Validation loss: 2.1707187173187092

Epoch: 6| Step: 8
Training loss: 1.9430468082427979
Validation loss: 2.17318554078379

Epoch: 6| Step: 9
Training loss: 2.209965467453003
Validation loss: 2.1644825884090957

Epoch: 6| Step: 10
Training loss: 2.9632978439331055
Validation loss: 2.1630765109933834

Epoch: 6| Step: 11
Training loss: 2.2257895469665527
Validation loss: 2.1613385882428897

Epoch: 6| Step: 12
Training loss: 3.009967803955078
Validation loss: 2.1604108964243243

Epoch: 6| Step: 13
Training loss: 2.722337484359741
Validation loss: 2.1567495061505224

Epoch: 55| Step: 0
Training loss: 1.677200198173523
Validation loss: 2.158352489112526

Epoch: 6| Step: 1
Training loss: 1.938183069229126
Validation loss: 2.1572304002700315

Epoch: 6| Step: 2
Training loss: 2.3113765716552734
Validation loss: 2.158226345175056

Epoch: 6| Step: 3
Training loss: 2.3816113471984863
Validation loss: 2.163117270315847

Epoch: 6| Step: 4
Training loss: 2.7691569328308105
Validation loss: 2.1711072050115114

Epoch: 6| Step: 5
Training loss: 2.153851270675659
Validation loss: 2.197152808148374

Epoch: 6| Step: 6
Training loss: 2.590216636657715
Validation loss: 2.199517285952004

Epoch: 6| Step: 7
Training loss: 2.997464656829834
Validation loss: 2.2105813359701507

Epoch: 6| Step: 8
Training loss: 3.1441495418548584
Validation loss: 2.2227271577363372

Epoch: 6| Step: 9
Training loss: 2.3289833068847656
Validation loss: 2.2274259213478333

Epoch: 6| Step: 10
Training loss: 2.621328353881836
Validation loss: 2.209783541258945

Epoch: 6| Step: 11
Training loss: 2.565939426422119
Validation loss: 2.19358403195617

Epoch: 6| Step: 12
Training loss: 2.450981616973877
Validation loss: 2.182585995684388

Epoch: 6| Step: 13
Training loss: 3.408513069152832
Validation loss: 2.1724481428823164

Epoch: 56| Step: 0
Training loss: 2.940965175628662
Validation loss: 2.1700477369369997

Epoch: 6| Step: 1
Training loss: 2.77494740486145
Validation loss: 2.1715735491885932

Epoch: 6| Step: 2
Training loss: 2.855947971343994
Validation loss: 2.1775258253979426

Epoch: 6| Step: 3
Training loss: 2.5823724269866943
Validation loss: 2.1900899230792956

Epoch: 6| Step: 4
Training loss: 2.367492198944092
Validation loss: 2.1822131602994856

Epoch: 6| Step: 5
Training loss: 2.198056936264038
Validation loss: 2.189514693393502

Epoch: 6| Step: 6
Training loss: 2.6127686500549316
Validation loss: 2.1803500344676356

Epoch: 6| Step: 7
Training loss: 2.721104621887207
Validation loss: 2.1792495019974245

Epoch: 6| Step: 8
Training loss: 2.5790562629699707
Validation loss: 2.180594625011567

Epoch: 6| Step: 9
Training loss: 2.215853691101074
Validation loss: 2.1736320398187123

Epoch: 6| Step: 10
Training loss: 1.9522448778152466
Validation loss: 2.160095678862705

Epoch: 6| Step: 11
Training loss: 2.386871337890625
Validation loss: 2.1495281098991312

Epoch: 6| Step: 12
Training loss: 2.4715487957000732
Validation loss: 2.156146175117903

Epoch: 6| Step: 13
Training loss: 2.077160596847534
Validation loss: 2.1565011239820913

Epoch: 57| Step: 0
Training loss: 2.8109068870544434
Validation loss: 2.157912750397959

Epoch: 6| Step: 1
Training loss: 2.644533634185791
Validation loss: 2.160347539891479

Epoch: 6| Step: 2
Training loss: 2.456634283065796
Validation loss: 2.1682246397900324

Epoch: 6| Step: 3
Training loss: 1.9152929782867432
Validation loss: 2.174685196209979

Epoch: 6| Step: 4
Training loss: 2.0370001792907715
Validation loss: 2.177054392394199

Epoch: 6| Step: 5
Training loss: 3.1204416751861572
Validation loss: 2.1706372384102113

Epoch: 6| Step: 6
Training loss: 2.712970495223999
Validation loss: 2.176966787666403

Epoch: 6| Step: 7
Training loss: 1.5734245777130127
Validation loss: 2.1631590320217993

Epoch: 6| Step: 8
Training loss: 2.199256658554077
Validation loss: 2.1601204782403927

Epoch: 6| Step: 9
Training loss: 2.8869247436523438
Validation loss: 2.1528066076258177

Epoch: 6| Step: 10
Training loss: 2.1203086376190186
Validation loss: 2.1606109001303233

Epoch: 6| Step: 11
Training loss: 3.3296878337860107
Validation loss: 2.1639327336383123

Epoch: 6| Step: 12
Training loss: 2.34702205657959
Validation loss: 2.163645916087653

Epoch: 6| Step: 13
Training loss: 2.548048973083496
Validation loss: 2.1665560122459167

Epoch: 58| Step: 0
Training loss: 2.9742908477783203
Validation loss: 2.164160438763198

Epoch: 6| Step: 1
Training loss: 2.357144594192505
Validation loss: 2.1716311106117825

Epoch: 6| Step: 2
Training loss: 2.597733736038208
Validation loss: 2.165451793260472

Epoch: 6| Step: 3
Training loss: 2.6978845596313477
Validation loss: 2.1718864979282504

Epoch: 6| Step: 4
Training loss: 2.4765772819519043
Validation loss: 2.1693020610399145

Epoch: 6| Step: 5
Training loss: 2.772390842437744
Validation loss: 2.1718784173329673

Epoch: 6| Step: 6
Training loss: 2.490635633468628
Validation loss: 2.164957022154203

Epoch: 6| Step: 7
Training loss: 1.834517240524292
Validation loss: 2.1783719344805648

Epoch: 6| Step: 8
Training loss: 2.6053314208984375
Validation loss: 2.174488857228269

Epoch: 6| Step: 9
Training loss: 1.9537012577056885
Validation loss: 2.160723727236512

Epoch: 6| Step: 10
Training loss: 2.1712048053741455
Validation loss: 2.1593123482119654

Epoch: 6| Step: 11
Training loss: 2.434142589569092
Validation loss: 2.155081231106994

Epoch: 6| Step: 12
Training loss: 2.5074315071105957
Validation loss: 2.153248422889299

Epoch: 6| Step: 13
Training loss: 2.7495639324188232
Validation loss: 2.151670995578971

Epoch: 59| Step: 0
Training loss: 2.556826591491699
Validation loss: 2.1552878323421685

Epoch: 6| Step: 1
Training loss: 2.739917039871216
Validation loss: 2.1622795943290956

Epoch: 6| Step: 2
Training loss: 2.222313642501831
Validation loss: 2.1718389052216724

Epoch: 6| Step: 3
Training loss: 2.3915958404541016
Validation loss: 2.162787183638542

Epoch: 6| Step: 4
Training loss: 2.462035655975342
Validation loss: 2.1510761976242065

Epoch: 6| Step: 5
Training loss: 1.9121320247650146
Validation loss: 2.140439138617567

Epoch: 6| Step: 6
Training loss: 2.5598037242889404
Validation loss: 2.138692009833551

Epoch: 6| Step: 7
Training loss: 2.3498635292053223
Validation loss: 2.1316636044492006

Epoch: 6| Step: 8
Training loss: 2.4853482246398926
Validation loss: 2.139233701972551

Epoch: 6| Step: 9
Training loss: 2.7285656929016113
Validation loss: 2.1329370621711976

Epoch: 6| Step: 10
Training loss: 2.590139865875244
Validation loss: 2.1384117680211223

Epoch: 6| Step: 11
Training loss: 2.4301671981811523
Validation loss: 2.1369148556904127

Epoch: 6| Step: 12
Training loss: 2.5812973976135254
Validation loss: 2.1390466895154727

Epoch: 6| Step: 13
Training loss: 2.565927028656006
Validation loss: 2.1509152279105237

Epoch: 60| Step: 0
Training loss: 2.0842010974884033
Validation loss: 2.1440206343127834

Epoch: 6| Step: 1
Training loss: 2.5827364921569824
Validation loss: 2.1446871244779198

Epoch: 6| Step: 2
Training loss: 2.3833417892456055
Validation loss: 2.147487353253108

Epoch: 6| Step: 3
Training loss: 2.261700391769409
Validation loss: 2.147962566344969

Epoch: 6| Step: 4
Training loss: 2.403855800628662
Validation loss: 2.1499412418693624

Epoch: 6| Step: 5
Training loss: 2.214608907699585
Validation loss: 2.14924039635607

Epoch: 6| Step: 6
Training loss: 2.100661039352417
Validation loss: 2.143459489268641

Epoch: 6| Step: 7
Training loss: 2.7225608825683594
Validation loss: 2.1485965674923313

Epoch: 6| Step: 8
Training loss: 2.778609037399292
Validation loss: 2.153778697854729

Epoch: 6| Step: 9
Training loss: 2.9191031455993652
Validation loss: 2.1622975282771613

Epoch: 6| Step: 10
Training loss: 2.3816304206848145
Validation loss: 2.1731751708574194

Epoch: 6| Step: 11
Training loss: 2.6833977699279785
Validation loss: 2.2074680546278596

Epoch: 6| Step: 12
Training loss: 2.4667716026306152
Validation loss: 2.230496048927307

Epoch: 6| Step: 13
Training loss: 2.4565649032592773
Validation loss: 2.228644332578105

Epoch: 61| Step: 0
Training loss: 2.3146910667419434
Validation loss: 2.2042359139329646

Epoch: 6| Step: 1
Training loss: 2.4949073791503906
Validation loss: 2.1987797111593266

Epoch: 6| Step: 2
Training loss: 1.5062536001205444
Validation loss: 2.176983589767128

Epoch: 6| Step: 3
Training loss: 2.3878414630889893
Validation loss: 2.1638707371168238

Epoch: 6| Step: 4
Training loss: 2.615084409713745
Validation loss: 2.149844974599859

Epoch: 6| Step: 5
Training loss: 2.0891480445861816
Validation loss: 2.134826444810437

Epoch: 6| Step: 6
Training loss: 2.114333152770996
Validation loss: 2.1312124575338056

Epoch: 6| Step: 7
Training loss: 2.603888988494873
Validation loss: 2.1251335451679845

Epoch: 6| Step: 8
Training loss: 2.425239086151123
Validation loss: 2.1293260179540163

Epoch: 6| Step: 9
Training loss: 2.9846909046173096
Validation loss: 2.121861339897238

Epoch: 6| Step: 10
Training loss: 2.670057773590088
Validation loss: 2.123077610487579

Epoch: 6| Step: 11
Training loss: 3.1574368476867676
Validation loss: 2.1264372974313717

Epoch: 6| Step: 12
Training loss: 2.160789966583252
Validation loss: 2.1250332452917613

Epoch: 6| Step: 13
Training loss: 3.1391191482543945
Validation loss: 2.1269696861185055

Epoch: 62| Step: 0
Training loss: 2.7611992359161377
Validation loss: 2.1324732098528134

Epoch: 6| Step: 1
Training loss: 2.4480316638946533
Validation loss: 2.1349422483034033

Epoch: 6| Step: 2
Training loss: 2.565821647644043
Validation loss: 2.1291797981467298

Epoch: 6| Step: 3
Training loss: 2.5652315616607666
Validation loss: 2.1137633938943186

Epoch: 6| Step: 4
Training loss: 2.504091262817383
Validation loss: 2.10935648282369

Epoch: 6| Step: 5
Training loss: 2.3396103382110596
Validation loss: 2.109664213272833

Epoch: 6| Step: 6
Training loss: 2.709195137023926
Validation loss: 2.1182786892819148

Epoch: 6| Step: 7
Training loss: 2.7740983963012695
Validation loss: 2.1088979039140927

Epoch: 6| Step: 8
Training loss: 2.5150089263916016
Validation loss: 2.108808047027998

Epoch: 6| Step: 9
Training loss: 2.0322937965393066
Validation loss: 2.1107079905848347

Epoch: 6| Step: 10
Training loss: 1.9376568794250488
Validation loss: 2.106789852983208

Epoch: 6| Step: 11
Training loss: 2.3140203952789307
Validation loss: 2.120144805600566

Epoch: 6| Step: 12
Training loss: 2.744753837585449
Validation loss: 2.138944920673165

Epoch: 6| Step: 13
Training loss: 2.085742235183716
Validation loss: 2.1752353842540453

Epoch: 63| Step: 0
Training loss: 3.031749725341797
Validation loss: 2.1922352185813327

Epoch: 6| Step: 1
Training loss: 2.4510045051574707
Validation loss: 2.1891258121818624

Epoch: 6| Step: 2
Training loss: 2.981423854827881
Validation loss: 2.173280723633305

Epoch: 6| Step: 3
Training loss: 2.308363437652588
Validation loss: 2.143945235078053

Epoch: 6| Step: 4
Training loss: 1.85941743850708
Validation loss: 2.133193054506856

Epoch: 6| Step: 5
Training loss: 2.3705592155456543
Validation loss: 2.1179996459714827

Epoch: 6| Step: 6
Training loss: 2.5684285163879395
Validation loss: 2.1131057303438903

Epoch: 6| Step: 7
Training loss: 2.3300089836120605
Validation loss: 2.1092696177062167

Epoch: 6| Step: 8
Training loss: 2.715419054031372
Validation loss: 2.1032090879255727

Epoch: 6| Step: 9
Training loss: 2.2180423736572266
Validation loss: 2.104200396486508

Epoch: 6| Step: 10
Training loss: 2.72564435005188
Validation loss: 2.112760346422913

Epoch: 6| Step: 11
Training loss: 2.666053295135498
Validation loss: 2.1208015898222565

Epoch: 6| Step: 12
Training loss: 2.077565908432007
Validation loss: 2.1180172222916798

Epoch: 6| Step: 13
Training loss: 1.7817376852035522
Validation loss: 2.1238292878673923

Epoch: 64| Step: 0
Training loss: 3.292140007019043
Validation loss: 2.1307537888967865

Epoch: 6| Step: 1
Training loss: 2.4880456924438477
Validation loss: 2.1273334333973546

Epoch: 6| Step: 2
Training loss: 2.891392230987549
Validation loss: 2.1378423552359305

Epoch: 6| Step: 3
Training loss: 2.4048478603363037
Validation loss: 2.149167024961082

Epoch: 6| Step: 4
Training loss: 1.5638186931610107
Validation loss: 2.1970184285153627

Epoch: 6| Step: 5
Training loss: 2.5343921184539795
Validation loss: 2.2342984496906237

Epoch: 6| Step: 6
Training loss: 2.0370655059814453
Validation loss: 2.260141364989742

Epoch: 6| Step: 7
Training loss: 2.395705223083496
Validation loss: 2.2723340449794645

Epoch: 6| Step: 8
Training loss: 1.8332006931304932
Validation loss: 2.269895527952461

Epoch: 6| Step: 9
Training loss: 2.930917263031006
Validation loss: 2.2938045788836736

Epoch: 6| Step: 10
Training loss: 2.4744069576263428
Validation loss: 2.241216508291101

Epoch: 6| Step: 11
Training loss: 2.9813151359558105
Validation loss: 2.2146005861220823

Epoch: 6| Step: 12
Training loss: 2.359652280807495
Validation loss: 2.1868105139783633

Epoch: 6| Step: 13
Training loss: 2.077205181121826
Validation loss: 2.16740749215567

Epoch: 65| Step: 0
Training loss: 2.2056479454040527
Validation loss: 2.131396575640607

Epoch: 6| Step: 1
Training loss: 2.222837448120117
Validation loss: 2.1208678009689494

Epoch: 6| Step: 2
Training loss: 1.980939269065857
Validation loss: 2.1130471280826035

Epoch: 6| Step: 3
Training loss: 1.9578018188476562
Validation loss: 2.1120206925176803

Epoch: 6| Step: 4
Training loss: 2.6419167518615723
Validation loss: 2.1128397936462076

Epoch: 6| Step: 5
Training loss: 2.636533260345459
Validation loss: 2.1276065098342074

Epoch: 6| Step: 6
Training loss: 2.502865791320801
Validation loss: 2.13605054988656

Epoch: 6| Step: 7
Training loss: 2.6199121475219727
Validation loss: 2.1361693464299685

Epoch: 6| Step: 8
Training loss: 2.8532557487487793
Validation loss: 2.1321720718055643

Epoch: 6| Step: 9
Training loss: 2.4449877738952637
Validation loss: 2.130089934154223

Epoch: 6| Step: 10
Training loss: 2.7975921630859375
Validation loss: 2.129627540547361

Epoch: 6| Step: 11
Training loss: 2.5952441692352295
Validation loss: 2.137355060987575

Epoch: 6| Step: 12
Training loss: 2.348237991333008
Validation loss: 2.136190806665728

Epoch: 6| Step: 13
Training loss: 2.2684030532836914
Validation loss: 2.1468552107452066

Epoch: 66| Step: 0
Training loss: 2.780921459197998
Validation loss: 2.1558169498238513

Epoch: 6| Step: 1
Training loss: 2.1028761863708496
Validation loss: 2.162360357981856

Epoch: 6| Step: 2
Training loss: 2.2582249641418457
Validation loss: 2.1782837375517814

Epoch: 6| Step: 3
Training loss: 2.4946696758270264
Validation loss: 2.154168064876269

Epoch: 6| Step: 4
Training loss: 3.0698018074035645
Validation loss: 2.144661772635675

Epoch: 6| Step: 5
Training loss: 2.723505973815918
Validation loss: 2.1180418293963195

Epoch: 6| Step: 6
Training loss: 2.235560178756714
Validation loss: 2.122365733628632

Epoch: 6| Step: 7
Training loss: 1.6586995124816895
Validation loss: 2.1203981048317364

Epoch: 6| Step: 8
Training loss: 2.542203187942505
Validation loss: 2.118928647810413

Epoch: 6| Step: 9
Training loss: 2.6870980262756348
Validation loss: 2.1160453211876655

Epoch: 6| Step: 10
Training loss: 2.717637062072754
Validation loss: 2.105746094898511

Epoch: 6| Step: 11
Training loss: 2.1934189796447754
Validation loss: 2.1081228768953713

Epoch: 6| Step: 12
Training loss: 2.3556554317474365
Validation loss: 2.099740687236991

Epoch: 6| Step: 13
Training loss: 1.977602243423462
Validation loss: 2.1027234203072003

Epoch: 67| Step: 0
Training loss: 2.7100114822387695
Validation loss: 2.0996662801311863

Epoch: 6| Step: 1
Training loss: 2.2111265659332275
Validation loss: 2.105026768099877

Epoch: 6| Step: 2
Training loss: 1.8255250453948975
Validation loss: 2.106102087164438

Epoch: 6| Step: 3
Training loss: 2.624119520187378
Validation loss: 2.108805057823017

Epoch: 6| Step: 4
Training loss: 3.1362009048461914
Validation loss: 2.1094395499075613

Epoch: 6| Step: 5
Training loss: 2.38796329498291
Validation loss: 2.115424674044373

Epoch: 6| Step: 6
Training loss: 3.0153727531433105
Validation loss: 2.137981061012514

Epoch: 6| Step: 7
Training loss: 1.8749154806137085
Validation loss: 2.174542546272278

Epoch: 6| Step: 8
Training loss: 2.234356641769409
Validation loss: 2.1919413766553326

Epoch: 6| Step: 9
Training loss: 2.905608892440796
Validation loss: 2.202043135960897

Epoch: 6| Step: 10
Training loss: 2.0835208892822266
Validation loss: 2.2094240124507616

Epoch: 6| Step: 11
Training loss: 2.768893241882324
Validation loss: 2.2050059098069386

Epoch: 6| Step: 12
Training loss: 2.5450804233551025
Validation loss: 2.2052573516804683

Epoch: 6| Step: 13
Training loss: 1.1425861120224
Validation loss: 2.1623769678095335

Epoch: 68| Step: 0
Training loss: 2.716301918029785
Validation loss: 2.138855081732555

Epoch: 6| Step: 1
Training loss: 1.970567226409912
Validation loss: 2.1171500221375497

Epoch: 6| Step: 2
Training loss: 2.1760666370391846
Validation loss: 2.101855477979106

Epoch: 6| Step: 3
Training loss: 2.3772268295288086
Validation loss: 2.0983474536608626

Epoch: 6| Step: 4
Training loss: 1.8888840675354004
Validation loss: 2.091421047846476

Epoch: 6| Step: 5
Training loss: 2.3410840034484863
Validation loss: 2.089167994837607

Epoch: 6| Step: 6
Training loss: 2.350750207901001
Validation loss: 2.0904086148867043

Epoch: 6| Step: 7
Training loss: 2.6464834213256836
Validation loss: 2.096693739455233

Epoch: 6| Step: 8
Training loss: 2.544743061065674
Validation loss: 2.114482864256828

Epoch: 6| Step: 9
Training loss: 2.7097904682159424
Validation loss: 2.1107861816242175

Epoch: 6| Step: 10
Training loss: 2.0926342010498047
Validation loss: 2.1169071120600544

Epoch: 6| Step: 11
Training loss: 1.9870426654815674
Validation loss: 2.126058678473196

Epoch: 6| Step: 12
Training loss: 2.963362216949463
Validation loss: 2.1571387885719218

Epoch: 6| Step: 13
Training loss: 3.2255802154541016
Validation loss: 2.1553832843739498

Epoch: 69| Step: 0
Training loss: 3.059274673461914
Validation loss: 2.155188270794448

Epoch: 6| Step: 1
Training loss: 2.624202251434326
Validation loss: 2.138230915992491

Epoch: 6| Step: 2
Training loss: 2.1815991401672363
Validation loss: 2.1399372521267144

Epoch: 6| Step: 3
Training loss: 2.5783305168151855
Validation loss: 2.14037650374956

Epoch: 6| Step: 4
Training loss: 2.0265090465545654
Validation loss: 2.1557558275038198

Epoch: 6| Step: 5
Training loss: 2.7098350524902344
Validation loss: 2.15026278649607

Epoch: 6| Step: 6
Training loss: 2.152838945388794
Validation loss: 2.1247133631860056

Epoch: 6| Step: 7
Training loss: 1.9491333961486816
Validation loss: 2.117390227574174

Epoch: 6| Step: 8
Training loss: 2.8001556396484375
Validation loss: 2.119213027338828

Epoch: 6| Step: 9
Training loss: 2.1813156604766846
Validation loss: 2.123599403647966

Epoch: 6| Step: 10
Training loss: 2.4422948360443115
Validation loss: 2.125016253481629

Epoch: 6| Step: 11
Training loss: 2.1147570610046387
Validation loss: 2.1210857770776235

Epoch: 6| Step: 12
Training loss: 2.5600039958953857
Validation loss: 2.123009381755706

Epoch: 6| Step: 13
Training loss: 2.354950189590454
Validation loss: 2.1128184423651746

Epoch: 70| Step: 0
Training loss: 3.0459909439086914
Validation loss: 2.1088495305789414

Epoch: 6| Step: 1
Training loss: 1.8003456592559814
Validation loss: 2.1108347190323697

Epoch: 6| Step: 2
Training loss: 1.9286291599273682
Validation loss: 2.109984549142981

Epoch: 6| Step: 3
Training loss: 3.463771343231201
Validation loss: 2.139556882201984

Epoch: 6| Step: 4
Training loss: 2.6477208137512207
Validation loss: 2.1547134332759406

Epoch: 6| Step: 5
Training loss: 2.4772284030914307
Validation loss: 2.1734804568752164

Epoch: 6| Step: 6
Training loss: 2.397921085357666
Validation loss: 2.1731514200087516

Epoch: 6| Step: 7
Training loss: 2.681840181350708
Validation loss: 2.168601970518789

Epoch: 6| Step: 8
Training loss: 1.4771814346313477
Validation loss: 2.183605747838174

Epoch: 6| Step: 9
Training loss: 2.948526620864868
Validation loss: 2.208102838967436

Epoch: 6| Step: 10
Training loss: 2.047110080718994
Validation loss: 2.204324459516874

Epoch: 6| Step: 11
Training loss: 2.0992801189422607
Validation loss: 2.1817148372691166

Epoch: 6| Step: 12
Training loss: 2.5047452449798584
Validation loss: 2.171971182669363

Epoch: 6| Step: 13
Training loss: 1.9223755598068237
Validation loss: 2.1528425703766527

Epoch: 71| Step: 0
Training loss: 2.5786685943603516
Validation loss: 2.130916383958632

Epoch: 6| Step: 1
Training loss: 3.1117844581604004
Validation loss: 2.1377696426965858

Epoch: 6| Step: 2
Training loss: 2.2331981658935547
Validation loss: 2.1479780109979774

Epoch: 6| Step: 3
Training loss: 1.5293775796890259
Validation loss: 2.1466057403113252

Epoch: 6| Step: 4
Training loss: 2.7179956436157227
Validation loss: 2.156716633868474

Epoch: 6| Step: 5
Training loss: 2.1195876598358154
Validation loss: 2.161590681281141

Epoch: 6| Step: 6
Training loss: 1.980863094329834
Validation loss: 2.17554295960293

Epoch: 6| Step: 7
Training loss: 2.057628631591797
Validation loss: 2.1609303938445223

Epoch: 6| Step: 8
Training loss: 2.903463363647461
Validation loss: 2.1687244625501734

Epoch: 6| Step: 9
Training loss: 3.259655237197876
Validation loss: 2.155501619462044

Epoch: 6| Step: 10
Training loss: 2.2842798233032227
Validation loss: 2.1263729500514206

Epoch: 6| Step: 11
Training loss: 2.3063831329345703
Validation loss: 2.109649855603454

Epoch: 6| Step: 12
Training loss: 1.5555040836334229
Validation loss: 2.093607405180572

Epoch: 6| Step: 13
Training loss: 2.978581428527832
Validation loss: 2.0880993925115114

Epoch: 72| Step: 0
Training loss: 1.9077168703079224
Validation loss: 2.089859720199339

Epoch: 6| Step: 1
Training loss: 1.472184658050537
Validation loss: 2.0859061697477936

Epoch: 6| Step: 2
Training loss: 2.2679781913757324
Validation loss: 2.093940137535013

Epoch: 6| Step: 3
Training loss: 1.9002455472946167
Validation loss: 2.090177095064553

Epoch: 6| Step: 4
Training loss: 3.1062021255493164
Validation loss: 2.076884295350762

Epoch: 6| Step: 5
Training loss: 2.284235954284668
Validation loss: 2.0759353458240466

Epoch: 6| Step: 6
Training loss: 2.6547513008117676
Validation loss: 2.072419863875194

Epoch: 6| Step: 7
Training loss: 2.4441919326782227
Validation loss: 2.073937023839643

Epoch: 6| Step: 8
Training loss: 2.994847536087036
Validation loss: 2.0834169028907694

Epoch: 6| Step: 9
Training loss: 1.936862587928772
Validation loss: 2.093261129112654

Epoch: 6| Step: 10
Training loss: 2.643230438232422
Validation loss: 2.1045078590352047

Epoch: 6| Step: 11
Training loss: 3.177741765975952
Validation loss: 2.1350132598671863

Epoch: 6| Step: 12
Training loss: 2.637472629547119
Validation loss: 2.1544945368202786

Epoch: 6| Step: 13
Training loss: 2.13489031791687
Validation loss: 2.1413939229903685

Epoch: 73| Step: 0
Training loss: 2.7728123664855957
Validation loss: 2.15145742893219

Epoch: 6| Step: 1
Training loss: 1.6135495901107788
Validation loss: 2.1361733687821256

Epoch: 6| Step: 2
Training loss: 2.645202159881592
Validation loss: 2.167551067567641

Epoch: 6| Step: 3
Training loss: 2.066140651702881
Validation loss: 2.1547522737133886

Epoch: 6| Step: 4
Training loss: 2.983203411102295
Validation loss: 2.1171706273991573

Epoch: 6| Step: 5
Training loss: 2.321471691131592
Validation loss: 2.0983102321624756

Epoch: 6| Step: 6
Training loss: 1.9062623977661133
Validation loss: 2.094772467049219

Epoch: 6| Step: 7
Training loss: 2.138460159301758
Validation loss: 2.0992393493652344

Epoch: 6| Step: 8
Training loss: 2.354729413986206
Validation loss: 2.0941284779579408

Epoch: 6| Step: 9
Training loss: 2.6351969242095947
Validation loss: 2.096559993682369

Epoch: 6| Step: 10
Training loss: 2.651865005493164
Validation loss: 2.0952233268368627

Epoch: 6| Step: 11
Training loss: 2.7282233238220215
Validation loss: 2.0810707153812533

Epoch: 6| Step: 12
Training loss: 2.3833181858062744
Validation loss: 2.0815043808311544

Epoch: 6| Step: 13
Training loss: 2.17513108253479
Validation loss: 2.078666765202758

Epoch: 74| Step: 0
Training loss: 2.7511653900146484
Validation loss: 2.0792602492916967

Epoch: 6| Step: 1
Training loss: 2.879106283187866
Validation loss: 2.0864428961148827

Epoch: 6| Step: 2
Training loss: 2.619222640991211
Validation loss: 2.091464997619711

Epoch: 6| Step: 3
Training loss: 2.1775074005126953
Validation loss: 2.0844357552066928

Epoch: 6| Step: 4
Training loss: 2.7438137531280518
Validation loss: 2.080234880088478

Epoch: 6| Step: 5
Training loss: 2.4737095832824707
Validation loss: 2.0691560647820912

Epoch: 6| Step: 6
Training loss: 2.2723517417907715
Validation loss: 2.0591045759057485

Epoch: 6| Step: 7
Training loss: 2.1407599449157715
Validation loss: 2.076857897543138

Epoch: 6| Step: 8
Training loss: 1.6370799541473389
Validation loss: 2.0972027804261897

Epoch: 6| Step: 9
Training loss: 2.5897765159606934
Validation loss: 2.1214713922110935

Epoch: 6| Step: 10
Training loss: 1.541182041168213
Validation loss: 2.143984984326106

Epoch: 6| Step: 11
Training loss: 2.3583621978759766
Validation loss: 2.1607707136420795

Epoch: 6| Step: 12
Training loss: 2.8487935066223145
Validation loss: 2.1566339718398226

Epoch: 6| Step: 13
Training loss: 2.060976028442383
Validation loss: 2.1281699570276404

Epoch: 75| Step: 0
Training loss: 2.8358664512634277
Validation loss: 2.1206507170072166

Epoch: 6| Step: 1
Training loss: 2.2628445625305176
Validation loss: 2.1031627962666173

Epoch: 6| Step: 2
Training loss: 2.0197324752807617
Validation loss: 2.0827158856135544

Epoch: 6| Step: 3
Training loss: 2.73291277885437
Validation loss: 2.0873507351003666

Epoch: 6| Step: 4
Training loss: 2.344709873199463
Validation loss: 2.0415510003284743

Epoch: 6| Step: 5
Training loss: 2.103538990020752
Validation loss: 2.0553578074260423

Epoch: 6| Step: 6
Training loss: 2.432976722717285
Validation loss: 2.0707962974425285

Epoch: 6| Step: 7
Training loss: 2.31001615524292
Validation loss: 2.08949536918312

Epoch: 6| Step: 8
Training loss: 2.841857433319092
Validation loss: 2.0971589229440175

Epoch: 6| Step: 9
Training loss: 2.845386505126953
Validation loss: 2.1014762129834903

Epoch: 6| Step: 10
Training loss: 1.9508635997772217
Validation loss: 2.106746760747766

Epoch: 6| Step: 11
Training loss: 2.2784552574157715
Validation loss: 2.109766152597243

Epoch: 6| Step: 12
Training loss: 2.4211373329162598
Validation loss: 2.097005887698102

Epoch: 6| Step: 13
Training loss: 1.7668366432189941
Validation loss: 2.097178969331967

Epoch: 76| Step: 0
Training loss: 2.392554759979248
Validation loss: 2.0766322100034325

Epoch: 6| Step: 1
Training loss: 2.9284393787384033
Validation loss: 2.0792998793304607

Epoch: 6| Step: 2
Training loss: 2.2395474910736084
Validation loss: 2.0771778757854173

Epoch: 6| Step: 3
Training loss: 1.7138185501098633
Validation loss: 2.0972661690045427

Epoch: 6| Step: 4
Training loss: 1.949902057647705
Validation loss: 2.1141101775630826

Epoch: 6| Step: 5
Training loss: 2.4316720962524414
Validation loss: 2.1352422955215618

Epoch: 6| Step: 6
Training loss: 3.2180228233337402
Validation loss: 2.1727001667022705

Epoch: 6| Step: 7
Training loss: 2.8079419136047363
Validation loss: 2.1982625940794587

Epoch: 6| Step: 8
Training loss: 2.5997800827026367
Validation loss: 2.206807571072732

Epoch: 6| Step: 9
Training loss: 2.469409704208374
Validation loss: 2.19909401862852

Epoch: 6| Step: 10
Training loss: 2.240450382232666
Validation loss: 2.1716773381797214

Epoch: 6| Step: 11
Training loss: 2.179105758666992
Validation loss: 2.1369784467963764

Epoch: 6| Step: 12
Training loss: 1.8852040767669678
Validation loss: 2.0924871865139214

Epoch: 6| Step: 13
Training loss: 1.723824143409729
Validation loss: 2.052975308510565

Epoch: 77| Step: 0
Training loss: 3.11489200592041
Validation loss: 2.047483762105306

Epoch: 6| Step: 1
Training loss: 2.7393155097961426
Validation loss: 2.057985423713602

Epoch: 6| Step: 2
Training loss: 2.051093101501465
Validation loss: 2.0664758361795896

Epoch: 6| Step: 3
Training loss: 1.8311535120010376
Validation loss: 2.0641648615560224

Epoch: 6| Step: 4
Training loss: 2.2293505668640137
Validation loss: 2.0598662925022904

Epoch: 6| Step: 5
Training loss: 2.870335102081299
Validation loss: 2.064738853003389

Epoch: 6| Step: 6
Training loss: 2.15519380569458
Validation loss: 2.056176531699396

Epoch: 6| Step: 7
Training loss: 2.4216437339782715
Validation loss: 2.056502949806952

Epoch: 6| Step: 8
Training loss: 2.3948888778686523
Validation loss: 2.05466535270855

Epoch: 6| Step: 9
Training loss: 2.3333168029785156
Validation loss: 2.0499890914527317

Epoch: 6| Step: 10
Training loss: 2.308476686477661
Validation loss: 2.037644076090987

Epoch: 6| Step: 11
Training loss: 2.556950569152832
Validation loss: 2.039933030323316

Epoch: 6| Step: 12
Training loss: 2.1785898208618164
Validation loss: 2.046231359563848

Epoch: 6| Step: 13
Training loss: 2.308302879333496
Validation loss: 2.078883453082013

Epoch: 78| Step: 0
Training loss: 2.5940492153167725
Validation loss: 2.1043738421573432

Epoch: 6| Step: 1
Training loss: 2.3190665245056152
Validation loss: 2.1824510059049054

Epoch: 6| Step: 2
Training loss: 2.5872411727905273
Validation loss: 2.221608228580926

Epoch: 6| Step: 3
Training loss: 2.5035197734832764
Validation loss: 2.356798456561181

Epoch: 6| Step: 4
Training loss: 2.161902666091919
Validation loss: 2.394553215272965

Epoch: 6| Step: 5
Training loss: 2.1712138652801514
Validation loss: 2.3654874165852866

Epoch: 6| Step: 6
Training loss: 2.7647786140441895
Validation loss: 2.284535966893678

Epoch: 6| Step: 7
Training loss: 1.6738202571868896
Validation loss: 2.1986740750651204

Epoch: 6| Step: 8
Training loss: 2.813584804534912
Validation loss: 2.130739076163179

Epoch: 6| Step: 9
Training loss: 2.3521149158477783
Validation loss: 2.0816048691349645

Epoch: 6| Step: 10
Training loss: 2.6321091651916504
Validation loss: 2.0943088377675703

Epoch: 6| Step: 11
Training loss: 2.408071517944336
Validation loss: 2.1172585064365017

Epoch: 6| Step: 12
Training loss: 2.198315382003784
Validation loss: 2.134107521785203

Epoch: 6| Step: 13
Training loss: 2.544084072113037
Validation loss: 2.159459796003116

Epoch: 79| Step: 0
Training loss: 2.692213296890259
Validation loss: 2.147969365119934

Epoch: 6| Step: 1
Training loss: 2.6486573219299316
Validation loss: 2.159441086553758

Epoch: 6| Step: 2
Training loss: 2.1411712169647217
Validation loss: 2.145065015362155

Epoch: 6| Step: 3
Training loss: 1.5383107662200928
Validation loss: 2.163261898102299

Epoch: 6| Step: 4
Training loss: 3.047135353088379
Validation loss: 2.2020470480765066

Epoch: 6| Step: 5
Training loss: 2.4340972900390625
Validation loss: 2.2274884972521054

Epoch: 6| Step: 6
Training loss: 2.134690523147583
Validation loss: 2.230069503989271

Epoch: 6| Step: 7
Training loss: 2.7656936645507812
Validation loss: 2.1869469304238596

Epoch: 6| Step: 8
Training loss: 2.3779568672180176
Validation loss: 2.1578052133642216

Epoch: 6| Step: 9
Training loss: 2.2398643493652344
Validation loss: 2.1466134619969193

Epoch: 6| Step: 10
Training loss: 1.7438101768493652
Validation loss: 2.1654057169473298

Epoch: 6| Step: 11
Training loss: 2.661386489868164
Validation loss: 2.1779959522267824

Epoch: 6| Step: 12
Training loss: 2.5239553451538086
Validation loss: 2.1994151864000546

Epoch: 6| Step: 13
Training loss: 2.8566088676452637
Validation loss: 2.193696912898812

Epoch: 80| Step: 0
Training loss: 2.5626230239868164
Validation loss: 2.1529430009985484

Epoch: 6| Step: 1
Training loss: 2.250032901763916
Validation loss: 2.1134056916800876

Epoch: 6| Step: 2
Training loss: 2.617854118347168
Validation loss: 2.087386400468888

Epoch: 6| Step: 3
Training loss: 1.8772125244140625
Validation loss: 2.05710341084388

Epoch: 6| Step: 4
Training loss: 2.424485445022583
Validation loss: 2.0550843797704226

Epoch: 6| Step: 5
Training loss: 2.0304787158966064
Validation loss: 2.051134419697587

Epoch: 6| Step: 6
Training loss: 2.0378360748291016
Validation loss: 2.0471411187161683

Epoch: 6| Step: 7
Training loss: 1.7727231979370117
Validation loss: 2.0508664500328804

Epoch: 6| Step: 8
Training loss: 2.788287401199341
Validation loss: 2.0661078063390588

Epoch: 6| Step: 9
Training loss: 2.725837230682373
Validation loss: 2.0799275752036803

Epoch: 6| Step: 10
Training loss: 2.1336803436279297
Validation loss: 2.1040830971092306

Epoch: 6| Step: 11
Training loss: 2.35298490524292
Validation loss: 2.1073588760950233

Epoch: 6| Step: 12
Training loss: 2.2541184425354004
Validation loss: 2.128816951987564

Epoch: 6| Step: 13
Training loss: 3.2488691806793213
Validation loss: 2.137140363775274

Epoch: 81| Step: 0
Training loss: 1.2386233806610107
Validation loss: 2.1461662041243685

Epoch: 6| Step: 1
Training loss: 3.2986297607421875
Validation loss: 2.155810538158622

Epoch: 6| Step: 2
Training loss: 3.2307560443878174
Validation loss: 2.146411539405905

Epoch: 6| Step: 3
Training loss: 2.322375535964966
Validation loss: 2.1159739340505292

Epoch: 6| Step: 4
Training loss: 1.973646640777588
Validation loss: 2.086073099925954

Epoch: 6| Step: 5
Training loss: 2.4566264152526855
Validation loss: 2.069951629125944

Epoch: 6| Step: 6
Training loss: 1.6913650035858154
Validation loss: 2.024700128903953

Epoch: 6| Step: 7
Training loss: 2.0963294506073
Validation loss: 2.0166523866755988

Epoch: 6| Step: 8
Training loss: 2.6127262115478516
Validation loss: 2.0171081160986297

Epoch: 6| Step: 9
Training loss: 1.996330976486206
Validation loss: 2.0293852231835805

Epoch: 6| Step: 10
Training loss: 2.4812726974487305
Validation loss: 2.0468400011780443

Epoch: 6| Step: 11
Training loss: 2.5467376708984375
Validation loss: 2.05352198180332

Epoch: 6| Step: 12
Training loss: 2.378579616546631
Validation loss: 2.0560967614573817

Epoch: 6| Step: 13
Training loss: 2.7955009937286377
Validation loss: 2.04774453947621

Epoch: 82| Step: 0
Training loss: 2.638096809387207
Validation loss: 2.045473478173697

Epoch: 6| Step: 1
Training loss: 2.221618175506592
Validation loss: 2.0428417882611676

Epoch: 6| Step: 2
Training loss: 1.8309661149978638
Validation loss: 2.035253201761553

Epoch: 6| Step: 3
Training loss: 2.4467740058898926
Validation loss: 2.019257358325425

Epoch: 6| Step: 4
Training loss: 2.260831356048584
Validation loss: 2.019582471539897

Epoch: 6| Step: 5
Training loss: 2.4865992069244385
Validation loss: 2.0276653176994732

Epoch: 6| Step: 6
Training loss: 2.4593286514282227
Validation loss: 2.023606550308966

Epoch: 6| Step: 7
Training loss: 2.2516698837280273
Validation loss: 2.038874887651013

Epoch: 6| Step: 8
Training loss: 2.531876802444458
Validation loss: 2.0390804403571674

Epoch: 6| Step: 9
Training loss: 2.3991706371307373
Validation loss: 2.0552658650182907

Epoch: 6| Step: 10
Training loss: 1.9776298999786377
Validation loss: 2.1042953793720534

Epoch: 6| Step: 11
Training loss: 2.2682743072509766
Validation loss: 2.148370394142725

Epoch: 6| Step: 12
Training loss: 2.217778205871582
Validation loss: 2.1499591130082325

Epoch: 6| Step: 13
Training loss: 2.633543014526367
Validation loss: 2.132102712508171

Epoch: 83| Step: 0
Training loss: 1.9857838153839111
Validation loss: 2.110456430783836

Epoch: 6| Step: 1
Training loss: 2.4708003997802734
Validation loss: 2.0587811341849704

Epoch: 6| Step: 2
Training loss: 2.6728854179382324
Validation loss: 2.032605460895005

Epoch: 6| Step: 3
Training loss: 2.427672863006592
Validation loss: 2.0282535501705703

Epoch: 6| Step: 4
Training loss: 1.7851109504699707
Validation loss: 2.025814971616191

Epoch: 6| Step: 5
Training loss: 2.7299747467041016
Validation loss: 2.043916053669427

Epoch: 6| Step: 6
Training loss: 3.3531341552734375
Validation loss: 2.044832629542197

Epoch: 6| Step: 7
Training loss: 2.207512378692627
Validation loss: 2.045929721606675

Epoch: 6| Step: 8
Training loss: 1.8796554803848267
Validation loss: 2.0321946374831663

Epoch: 6| Step: 9
Training loss: 2.1900601387023926
Validation loss: 2.0483128998869207

Epoch: 6| Step: 10
Training loss: 1.8794753551483154
Validation loss: 2.0350600391305904

Epoch: 6| Step: 11
Training loss: 2.1996021270751953
Validation loss: 2.015819134250764

Epoch: 6| Step: 12
Training loss: 2.176544666290283
Validation loss: 2.0237133067141295

Epoch: 6| Step: 13
Training loss: 2.3785390853881836
Validation loss: 2.0280532272913123

Epoch: 84| Step: 0
Training loss: 2.4274063110351562
Validation loss: 2.0153032131092523

Epoch: 6| Step: 1
Training loss: 2.165421962738037
Validation loss: 2.0258591892898723

Epoch: 6| Step: 2
Training loss: 1.7561874389648438
Validation loss: 2.017195463180542

Epoch: 6| Step: 3
Training loss: 2.5384938716888428
Validation loss: 2.0180503168413715

Epoch: 6| Step: 4
Training loss: 2.2498748302459717
Validation loss: 2.028580932207005

Epoch: 6| Step: 5
Training loss: 2.3723742961883545
Validation loss: 2.02972044867854

Epoch: 6| Step: 6
Training loss: 2.6324992179870605
Validation loss: 2.0394310566686813

Epoch: 6| Step: 7
Training loss: 2.25689697265625
Validation loss: 2.038983095076776

Epoch: 6| Step: 8
Training loss: 1.3020331859588623
Validation loss: 2.0415052367794897

Epoch: 6| Step: 9
Training loss: 2.168137788772583
Validation loss: 2.05886693539158

Epoch: 6| Step: 10
Training loss: 2.5060064792633057
Validation loss: 2.060170576136599

Epoch: 6| Step: 11
Training loss: 2.9982194900512695
Validation loss: 2.083294232686361

Epoch: 6| Step: 12
Training loss: 2.2539172172546387
Validation loss: 2.1172900789527485

Epoch: 6| Step: 13
Training loss: 1.9236937761306763
Validation loss: 2.1396017587313088

Epoch: 85| Step: 0
Training loss: 2.0890450477600098
Validation loss: 2.1156658254643923

Epoch: 6| Step: 1
Training loss: 2.313307285308838
Validation loss: 2.1199728237685336

Epoch: 6| Step: 2
Training loss: 2.061537504196167
Validation loss: 2.0936541659857637

Epoch: 6| Step: 3
Training loss: 1.8474838733673096
Validation loss: 2.08592285648469

Epoch: 6| Step: 4
Training loss: 2.823129892349243
Validation loss: 2.0605706835305817

Epoch: 6| Step: 5
Training loss: 2.646829605102539
Validation loss: 2.056224387179139

Epoch: 6| Step: 6
Training loss: 1.94627046585083
Validation loss: 2.0465477987002303

Epoch: 6| Step: 7
Training loss: 2.2110393047332764
Validation loss: 2.0505106320945163

Epoch: 6| Step: 8
Training loss: 1.870818018913269
Validation loss: 2.0456940666321786

Epoch: 6| Step: 9
Training loss: 2.5992608070373535
Validation loss: 2.036600894825433

Epoch: 6| Step: 10
Training loss: 2.473600387573242
Validation loss: 2.0327847029573176

Epoch: 6| Step: 11
Training loss: 2.0843019485473633
Validation loss: 2.027447339027159

Epoch: 6| Step: 12
Training loss: 2.415879726409912
Validation loss: 2.026753515325567

Epoch: 6| Step: 13
Training loss: 1.9112584590911865
Validation loss: 2.032093894097113

Epoch: 86| Step: 0
Training loss: 2.0060620307922363
Validation loss: 2.0370095058154036

Epoch: 6| Step: 1
Training loss: 2.735067844390869
Validation loss: 2.0607215755729267

Epoch: 6| Step: 2
Training loss: 2.5869672298431396
Validation loss: 2.0763198419283797

Epoch: 6| Step: 3
Training loss: 1.5952372550964355
Validation loss: 2.095243312979257

Epoch: 6| Step: 4
Training loss: 2.818364143371582
Validation loss: 2.1045946254525134

Epoch: 6| Step: 5
Training loss: 2.496311664581299
Validation loss: 2.103113305184149

Epoch: 6| Step: 6
Training loss: 1.6829593181610107
Validation loss: 2.0976867188689527

Epoch: 6| Step: 7
Training loss: 1.582831621170044
Validation loss: 2.068983598421979

Epoch: 6| Step: 8
Training loss: 2.484647512435913
Validation loss: 2.0675063645967873

Epoch: 6| Step: 9
Training loss: 2.3698954582214355
Validation loss: 2.044345336575662

Epoch: 6| Step: 10
Training loss: 2.2216973304748535
Validation loss: 2.02953637671727

Epoch: 6| Step: 11
Training loss: 2.357994318008423
Validation loss: 2.0236473698769846

Epoch: 6| Step: 12
Training loss: 2.12498140335083
Validation loss: 2.015273650487264

Epoch: 6| Step: 13
Training loss: 2.769351005554199
Validation loss: 2.023171728657138

Epoch: 87| Step: 0
Training loss: 2.3440568447113037
Validation loss: 2.0330577845214517

Epoch: 6| Step: 1
Training loss: 2.8127567768096924
Validation loss: 2.045360827958712

Epoch: 6| Step: 2
Training loss: 1.2434589862823486
Validation loss: 2.0533559758176088

Epoch: 6| Step: 3
Training loss: 2.3298606872558594
Validation loss: 2.0575531862115346

Epoch: 6| Step: 4
Training loss: 2.757864475250244
Validation loss: 2.0466182026811826

Epoch: 6| Step: 5
Training loss: 2.066063642501831
Validation loss: 2.0597796414488103

Epoch: 6| Step: 6
Training loss: 2.3015615940093994
Validation loss: 2.0447803697278424

Epoch: 6| Step: 7
Training loss: 2.571894645690918
Validation loss: 2.050946463820755

Epoch: 6| Step: 8
Training loss: 2.3346471786499023
Validation loss: 2.041326497190742

Epoch: 6| Step: 9
Training loss: 2.204784870147705
Validation loss: 2.03854880281674

Epoch: 6| Step: 10
Training loss: 1.5230053663253784
Validation loss: 2.0267674922943115

Epoch: 6| Step: 11
Training loss: 2.2637534141540527
Validation loss: 2.045611189257714

Epoch: 6| Step: 12
Training loss: 2.634225845336914
Validation loss: 2.0721750285035823

Epoch: 6| Step: 13
Training loss: 1.6437504291534424
Validation loss: 2.121828830370339

Epoch: 88| Step: 0
Training loss: 2.525771141052246
Validation loss: 2.1424389975045317

Epoch: 6| Step: 1
Training loss: 2.866607904434204
Validation loss: 2.134969929213165

Epoch: 6| Step: 2
Training loss: 2.403196334838867
Validation loss: 2.1158097867042787

Epoch: 6| Step: 3
Training loss: 2.043445587158203
Validation loss: 2.09798833375336

Epoch: 6| Step: 4
Training loss: 1.8158763647079468
Validation loss: 2.0966717786686395

Epoch: 6| Step: 5
Training loss: 2.559569835662842
Validation loss: 2.106683756715508

Epoch: 6| Step: 6
Training loss: 1.5098836421966553
Validation loss: 2.126290177786222

Epoch: 6| Step: 7
Training loss: 1.996745228767395
Validation loss: 2.148466299938899

Epoch: 6| Step: 8
Training loss: 1.6408425569534302
Validation loss: 2.146257230030593

Epoch: 6| Step: 9
Training loss: 2.0790319442749023
Validation loss: 2.132409326491817

Epoch: 6| Step: 10
Training loss: 2.908637762069702
Validation loss: 2.1131589515234834

Epoch: 6| Step: 11
Training loss: 2.4490060806274414
Validation loss: 2.0792602646735405

Epoch: 6| Step: 12
Training loss: 2.101686954498291
Validation loss: 2.04830962868147

Epoch: 6| Step: 13
Training loss: 2.68117356300354
Validation loss: 2.0285978291624334

Epoch: 89| Step: 0
Training loss: 1.7423808574676514
Validation loss: 2.010831614976288

Epoch: 6| Step: 1
Training loss: 1.7886157035827637
Validation loss: 2.0107924912565496

Epoch: 6| Step: 2
Training loss: 2.284083366394043
Validation loss: 1.9986588493470223

Epoch: 6| Step: 3
Training loss: 2.152081251144409
Validation loss: 2.009229304969952

Epoch: 6| Step: 4
Training loss: 2.238178014755249
Validation loss: 2.010444600095031

Epoch: 6| Step: 5
Training loss: 2.745983123779297
Validation loss: 2.0166003293888544

Epoch: 6| Step: 6
Training loss: 2.0693602561950684
Validation loss: 2.012416353789709

Epoch: 6| Step: 7
Training loss: 2.2543087005615234
Validation loss: 2.010590177710338

Epoch: 6| Step: 8
Training loss: 1.8817429542541504
Validation loss: 2.001285392750976

Epoch: 6| Step: 9
Training loss: 2.653623342514038
Validation loss: 1.9998320251382806

Epoch: 6| Step: 10
Training loss: 2.0474307537078857
Validation loss: 2.004657330051545

Epoch: 6| Step: 11
Training loss: 2.604243040084839
Validation loss: 2.0051590704148814

Epoch: 6| Step: 12
Training loss: 2.50205659866333
Validation loss: 2.0191778854657243

Epoch: 6| Step: 13
Training loss: 2.1229193210601807
Validation loss: 2.0201980785657

Epoch: 90| Step: 0
Training loss: 1.8603549003601074
Validation loss: 2.04312890191232

Epoch: 6| Step: 1
Training loss: 1.758324384689331
Validation loss: 2.0527835917729202

Epoch: 6| Step: 2
Training loss: 2.4510040283203125
Validation loss: 2.0655709005171254

Epoch: 6| Step: 3
Training loss: 2.861037015914917
Validation loss: 2.071014560678954

Epoch: 6| Step: 4
Training loss: 1.5841550827026367
Validation loss: 2.0666077060084187

Epoch: 6| Step: 5
Training loss: 1.9996830224990845
Validation loss: 2.095523677846437

Epoch: 6| Step: 6
Training loss: 2.107161521911621
Validation loss: 2.096669799538069

Epoch: 6| Step: 7
Training loss: 2.294593572616577
Validation loss: 2.1139402568981214

Epoch: 6| Step: 8
Training loss: 1.9820191860198975
Validation loss: 2.119255559418791

Epoch: 6| Step: 9
Training loss: 2.539701461791992
Validation loss: 2.1438991164648407

Epoch: 6| Step: 10
Training loss: 2.715256452560425
Validation loss: 2.1391677266807965

Epoch: 6| Step: 11
Training loss: 2.23272705078125
Validation loss: 2.131314790377053

Epoch: 6| Step: 12
Training loss: 2.3851051330566406
Validation loss: 2.1292620423019573

Epoch: 6| Step: 13
Training loss: 2.1711812019348145
Validation loss: 2.112089962087652

Epoch: 91| Step: 0
Training loss: 2.1784632205963135
Validation loss: 2.0452270405266875

Epoch: 6| Step: 1
Training loss: 2.058454990386963
Validation loss: 2.015026371966126

Epoch: 6| Step: 2
Training loss: 2.1349995136260986
Validation loss: 2.0040852139073033

Epoch: 6| Step: 3
Training loss: 2.9373226165771484
Validation loss: 2.0135788968814317

Epoch: 6| Step: 4
Training loss: 2.421417236328125
Validation loss: 2.014640203086279

Epoch: 6| Step: 5
Training loss: 1.8249045610427856
Validation loss: 2.0175431466871694

Epoch: 6| Step: 6
Training loss: 2.2738912105560303
Validation loss: 2.0091617761119718

Epoch: 6| Step: 7
Training loss: 3.0480241775512695
Validation loss: 2.006322004461801

Epoch: 6| Step: 8
Training loss: 2.4567387104034424
Validation loss: 1.9973011004027499

Epoch: 6| Step: 9
Training loss: 2.3003292083740234
Validation loss: 1.9963853525859054

Epoch: 6| Step: 10
Training loss: 2.1100854873657227
Validation loss: 1.9970212854364866

Epoch: 6| Step: 11
Training loss: 1.3997125625610352
Validation loss: 1.9952582056804369

Epoch: 6| Step: 12
Training loss: 2.1595866680145264
Validation loss: 1.9971925904673915

Epoch: 6| Step: 13
Training loss: 2.5263822078704834
Validation loss: 1.995381196339925

Epoch: 92| Step: 0
Training loss: 2.7771658897399902
Validation loss: 1.9998635348453317

Epoch: 6| Step: 1
Training loss: 1.8394925594329834
Validation loss: 2.009359400759461

Epoch: 6| Step: 2
Training loss: 1.8385319709777832
Validation loss: 2.0316687091704337

Epoch: 6| Step: 3
Training loss: 2.282623291015625
Validation loss: 2.05764433645433

Epoch: 6| Step: 4
Training loss: 2.0866012573242188
Validation loss: 2.105252060838925

Epoch: 6| Step: 5
Training loss: 2.306877374649048
Validation loss: 2.173967671650712

Epoch: 6| Step: 6
Training loss: 2.5516576766967773
Validation loss: 2.1515338369595107

Epoch: 6| Step: 7
Training loss: 2.1407852172851562
Validation loss: 2.1414867562632405

Epoch: 6| Step: 8
Training loss: 2.44685697555542
Validation loss: 2.1211980965829667

Epoch: 6| Step: 9
Training loss: 2.572280168533325
Validation loss: 2.1085413015016945

Epoch: 6| Step: 10
Training loss: 1.6124670505523682
Validation loss: 2.1123648535820747

Epoch: 6| Step: 11
Training loss: 2.3428003787994385
Validation loss: 2.1032152034903087

Epoch: 6| Step: 12
Training loss: 2.6320252418518066
Validation loss: 2.1462525526682534

Epoch: 6| Step: 13
Training loss: 2.4483957290649414
Validation loss: 2.1463609023760726

Epoch: 93| Step: 0
Training loss: 2.097236156463623
Validation loss: 2.142541600811866

Epoch: 6| Step: 1
Training loss: 1.9672820568084717
Validation loss: 2.1199161647468485

Epoch: 6| Step: 2
Training loss: 2.4040727615356445
Validation loss: 2.106085777282715

Epoch: 6| Step: 3
Training loss: 2.0525808334350586
Validation loss: 2.0969236640519995

Epoch: 6| Step: 4
Training loss: 2.861858367919922
Validation loss: 2.101677453646096

Epoch: 6| Step: 5
Training loss: 2.3670756816864014
Validation loss: 2.102672396167632

Epoch: 6| Step: 6
Training loss: 2.4592785835266113
Validation loss: 2.1048887852699525

Epoch: 6| Step: 7
Training loss: 2.0047953128814697
Validation loss: 2.094478878923642

Epoch: 6| Step: 8
Training loss: 1.6020376682281494
Validation loss: 2.0785267455603487

Epoch: 6| Step: 9
Training loss: 1.9085681438446045
Validation loss: 2.072389769297774

Epoch: 6| Step: 10
Training loss: 2.16184139251709
Validation loss: 2.0806923476598596

Epoch: 6| Step: 11
Training loss: 2.3073506355285645
Validation loss: 2.073389644263893

Epoch: 6| Step: 12
Training loss: 1.998629093170166
Validation loss: 2.067803495673723

Epoch: 6| Step: 13
Training loss: 3.2181596755981445
Validation loss: 2.050723286085231

Epoch: 94| Step: 0
Training loss: 2.749445915222168
Validation loss: 2.043359697505992

Epoch: 6| Step: 1
Training loss: 2.606564521789551
Validation loss: 2.0327282464632423

Epoch: 6| Step: 2
Training loss: 1.7594592571258545
Validation loss: 2.0289364117448048

Epoch: 6| Step: 3
Training loss: 2.668318748474121
Validation loss: 2.027761269641179

Epoch: 6| Step: 4
Training loss: 1.6550779342651367
Validation loss: 2.0360328176970124

Epoch: 6| Step: 5
Training loss: 2.9349849224090576
Validation loss: 2.0306515104027203

Epoch: 6| Step: 6
Training loss: 1.9157809019088745
Validation loss: 2.0432028039809196

Epoch: 6| Step: 7
Training loss: 2.5134997367858887
Validation loss: 2.085357109705607

Epoch: 6| Step: 8
Training loss: 2.2217648029327393
Validation loss: 2.0884440047766573

Epoch: 6| Step: 9
Training loss: 1.2325544357299805
Validation loss: 2.1040747101588915

Epoch: 6| Step: 10
Training loss: 1.8984696865081787
Validation loss: 2.0948792785726567

Epoch: 6| Step: 11
Training loss: 2.169363260269165
Validation loss: 2.0939134731087634

Epoch: 6| Step: 12
Training loss: 2.1049015522003174
Validation loss: 2.080784034985368

Epoch: 6| Step: 13
Training loss: 1.9762028455734253
Validation loss: 2.1023693828172583

Epoch: 95| Step: 0
Training loss: 2.2573952674865723
Validation loss: 2.1179314415941954

Epoch: 6| Step: 1
Training loss: 1.9132490158081055
Validation loss: 2.1205534473542245

Epoch: 6| Step: 2
Training loss: 2.3379268646240234
Validation loss: 2.108763110253119

Epoch: 6| Step: 3
Training loss: 1.7023122310638428
Validation loss: 2.0929995288131056

Epoch: 6| Step: 4
Training loss: 1.7410976886749268
Validation loss: 2.1004114022818943

Epoch: 6| Step: 5
Training loss: 1.5462594032287598
Validation loss: 2.0980553447559314

Epoch: 6| Step: 6
Training loss: 2.8234877586364746
Validation loss: 2.0846006024268364

Epoch: 6| Step: 7
Training loss: 1.761326551437378
Validation loss: 2.0755778230646604

Epoch: 6| Step: 8
Training loss: 2.5861117839813232
Validation loss: 2.086067500934806

Epoch: 6| Step: 9
Training loss: 2.390650987625122
Validation loss: 2.084728853676909

Epoch: 6| Step: 10
Training loss: 2.019033908843994
Validation loss: 2.097341319566132

Epoch: 6| Step: 11
Training loss: 2.546846389770508
Validation loss: 2.102956848759805

Epoch: 6| Step: 12
Training loss: 2.8081984519958496
Validation loss: 2.1092764459630495

Epoch: 6| Step: 13
Training loss: 2.350429058074951
Validation loss: 2.129068938634729

Epoch: 96| Step: 0
Training loss: 1.891782283782959
Validation loss: 2.127463557386911

Epoch: 6| Step: 1
Training loss: 2.175497055053711
Validation loss: 2.1016973321155836

Epoch: 6| Step: 2
Training loss: 1.6179747581481934
Validation loss: 2.1035304274610294

Epoch: 6| Step: 3
Training loss: 2.1917941570281982
Validation loss: 2.104187903865691

Epoch: 6| Step: 4
Training loss: 2.0724470615386963
Validation loss: 2.107583212596114

Epoch: 6| Step: 5
Training loss: 2.370482921600342
Validation loss: 2.084440695342197

Epoch: 6| Step: 6
Training loss: 2.5538222789764404
Validation loss: 2.089447109929977

Epoch: 6| Step: 7
Training loss: 1.7553472518920898
Validation loss: 2.093427481189851

Epoch: 6| Step: 8
Training loss: 2.7372264862060547
Validation loss: 2.1190713708118727

Epoch: 6| Step: 9
Training loss: 2.548429012298584
Validation loss: 2.127377571598176

Epoch: 6| Step: 10
Training loss: 2.443077325820923
Validation loss: 2.092404128402792

Epoch: 6| Step: 11
Training loss: 2.252960443496704
Validation loss: 2.060505629867636

Epoch: 6| Step: 12
Training loss: 2.3608479499816895
Validation loss: 2.064666291718842

Epoch: 6| Step: 13
Training loss: 0.9787158966064453
Validation loss: 2.057276101522548

Epoch: 97| Step: 0
Training loss: 1.9468727111816406
Validation loss: 2.0535386890493412

Epoch: 6| Step: 1
Training loss: 2.1649203300476074
Validation loss: 2.023176106073523

Epoch: 6| Step: 2
Training loss: 2.382459878921509
Validation loss: 2.017435517362369

Epoch: 6| Step: 3
Training loss: 2.2248153686523438
Validation loss: 2.009297301692347

Epoch: 6| Step: 4
Training loss: 2.4828991889953613
Validation loss: 2.012432357316376

Epoch: 6| Step: 5
Training loss: 1.6688323020935059
Validation loss: 2.0074759003936604

Epoch: 6| Step: 6
Training loss: 2.49265193939209
Validation loss: 2.015485144430591

Epoch: 6| Step: 7
Training loss: 2.5325589179992676
Validation loss: 2.0276479515978085

Epoch: 6| Step: 8
Training loss: 2.7746119499206543
Validation loss: 2.0224744863407587

Epoch: 6| Step: 9
Training loss: 1.9340765476226807
Validation loss: 2.00788240919831

Epoch: 6| Step: 10
Training loss: 1.8431941270828247
Validation loss: 2.006892446548708

Epoch: 6| Step: 11
Training loss: 2.123579502105713
Validation loss: 2.0109788064033753

Epoch: 6| Step: 12
Training loss: 2.0317916870117188
Validation loss: 1.997706736287763

Epoch: 6| Step: 13
Training loss: 1.9374504089355469
Validation loss: 2.0060865545785553

Epoch: 98| Step: 0
Training loss: 2.3286542892456055
Validation loss: 2.018230815087595

Epoch: 6| Step: 1
Training loss: 1.6759552955627441
Validation loss: 2.0347498386136946

Epoch: 6| Step: 2
Training loss: 2.7642738819122314
Validation loss: 2.0579299683211953

Epoch: 6| Step: 3
Training loss: 1.4999908208847046
Validation loss: 2.0768116776661207

Epoch: 6| Step: 4
Training loss: 2.04719877243042
Validation loss: 2.0728089283871394

Epoch: 6| Step: 5
Training loss: 2.4796371459960938
Validation loss: 2.0696266620389876

Epoch: 6| Step: 6
Training loss: 1.8257255554199219
Validation loss: 2.0760548781323176

Epoch: 6| Step: 7
Training loss: 1.6235120296478271
Validation loss: 2.072746712674377

Epoch: 6| Step: 8
Training loss: 2.1501123905181885
Validation loss: 2.0699169135862783

Epoch: 6| Step: 9
Training loss: 2.7036242485046387
Validation loss: 2.0731115956460275

Epoch: 6| Step: 10
Training loss: 2.533994674682617
Validation loss: 2.0886429740536596

Epoch: 6| Step: 11
Training loss: 2.263777732849121
Validation loss: 2.077463306406493

Epoch: 6| Step: 12
Training loss: 1.7912189960479736
Validation loss: 2.0622196633328675

Epoch: 6| Step: 13
Training loss: 2.0127813816070557
Validation loss: 2.039494543947199

Epoch: 99| Step: 0
Training loss: 1.8667470216751099
Validation loss: 2.0153532566562777

Epoch: 6| Step: 1
Training loss: 2.036839485168457
Validation loss: 2.0050660346143987

Epoch: 6| Step: 2
Training loss: 2.014103412628174
Validation loss: 1.9976971521172473

Epoch: 6| Step: 3
Training loss: 2.011626720428467
Validation loss: 1.9961251212704567

Epoch: 6| Step: 4
Training loss: 2.1935415267944336
Validation loss: 1.987665489155759

Epoch: 6| Step: 5
Training loss: 2.197558879852295
Validation loss: 1.9932911216571767

Epoch: 6| Step: 6
Training loss: 2.236175537109375
Validation loss: 1.9894793148963683

Epoch: 6| Step: 7
Training loss: 2.122650384902954
Validation loss: 1.986699572173498

Epoch: 6| Step: 8
Training loss: 2.641254186630249
Validation loss: 1.994490078700486

Epoch: 6| Step: 9
Training loss: 2.7104291915893555
Validation loss: 1.9974623726260277

Epoch: 6| Step: 10
Training loss: 2.011890172958374
Validation loss: 1.997808079565725

Epoch: 6| Step: 11
Training loss: 1.6846174001693726
Validation loss: 2.0207538143281014

Epoch: 6| Step: 12
Training loss: 2.146495819091797
Validation loss: 2.0279042618249052

Epoch: 6| Step: 13
Training loss: 1.7769832611083984
Validation loss: 2.0209278547635643

Epoch: 100| Step: 0
Training loss: 2.501556158065796
Validation loss: 2.0093739404473254

Epoch: 6| Step: 1
Training loss: 1.5927492380142212
Validation loss: 2.0078487806422736

Epoch: 6| Step: 2
Training loss: 2.051295757293701
Validation loss: 2.0025265678282707

Epoch: 6| Step: 3
Training loss: 1.9703927040100098
Validation loss: 2.005426437624039

Epoch: 6| Step: 4
Training loss: 2.3266024589538574
Validation loss: 2.017398029245356

Epoch: 6| Step: 5
Training loss: 2.115943670272827
Validation loss: 2.026044346952951

Epoch: 6| Step: 6
Training loss: 2.080878973007202
Validation loss: 2.0028994711496497

Epoch: 6| Step: 7
Training loss: 2.1649389266967773
Validation loss: 2.0081882169169765

Epoch: 6| Step: 8
Training loss: 2.5254030227661133
Validation loss: 1.988352737119121

Epoch: 6| Step: 9
Training loss: 2.313715934753418
Validation loss: 1.9689399734620125

Epoch: 6| Step: 10
Training loss: 1.9254783391952515
Validation loss: 1.968856446204647

Epoch: 6| Step: 11
Training loss: 1.5262985229492188
Validation loss: 1.9753100333675262

Epoch: 6| Step: 12
Training loss: 1.7178764343261719
Validation loss: 1.9792214696125319

Epoch: 6| Step: 13
Training loss: 2.5714924335479736
Validation loss: 1.9822133279615832

Epoch: 101| Step: 0
Training loss: 2.2291133403778076
Validation loss: 2.0047272443771362

Epoch: 6| Step: 1
Training loss: 2.4638752937316895
Validation loss: 2.0134552294208157

Epoch: 6| Step: 2
Training loss: 2.1523499488830566
Validation loss: 2.020581240295082

Epoch: 6| Step: 3
Training loss: 1.9761526584625244
Validation loss: 2.0155614550395677

Epoch: 6| Step: 4
Training loss: 2.1889724731445312
Validation loss: 2.0092326723119265

Epoch: 6| Step: 5
Training loss: 1.937035083770752
Validation loss: 1.9936941798015306

Epoch: 6| Step: 6
Training loss: 2.2405786514282227
Validation loss: 1.987788995107015

Epoch: 6| Step: 7
Training loss: 1.787231206893921
Validation loss: 1.9968517595721829

Epoch: 6| Step: 8
Training loss: 2.359590530395508
Validation loss: 1.9963959455490112

Epoch: 6| Step: 9
Training loss: 2.2313551902770996
Validation loss: 1.9979776413209978

Epoch: 6| Step: 10
Training loss: 1.9189112186431885
Validation loss: 1.9998380420028523

Epoch: 6| Step: 11
Training loss: 1.6801520586013794
Validation loss: 2.0071082294628186

Epoch: 6| Step: 12
Training loss: 2.051079750061035
Validation loss: 1.9991163643457557

Epoch: 6| Step: 13
Training loss: 1.719388484954834
Validation loss: 1.991730660520574

Epoch: 102| Step: 0
Training loss: 1.757699966430664
Validation loss: 1.9956522359642932

Epoch: 6| Step: 1
Training loss: 2.869234561920166
Validation loss: 1.990518541746242

Epoch: 6| Step: 2
Training loss: 2.512526035308838
Validation loss: 1.998028984633825

Epoch: 6| Step: 3
Training loss: 2.282865047454834
Validation loss: 1.994341109388618

Epoch: 6| Step: 4
Training loss: 2.2600479125976562
Validation loss: 2.000073638013614

Epoch: 6| Step: 5
Training loss: 1.8939979076385498
Validation loss: 2.0134857828899095

Epoch: 6| Step: 6
Training loss: 1.7930881977081299
Validation loss: 2.02275183123927

Epoch: 6| Step: 7
Training loss: 0.9619567394256592
Validation loss: 2.015464380223264

Epoch: 6| Step: 8
Training loss: 2.163071632385254
Validation loss: 2.0043274433382097

Epoch: 6| Step: 9
Training loss: 2.041642904281616
Validation loss: 2.007076317264188

Epoch: 6| Step: 10
Training loss: 1.95127272605896
Validation loss: 2.0140342199674217

Epoch: 6| Step: 11
Training loss: 1.999889850616455
Validation loss: 2.0173126164303032

Epoch: 6| Step: 12
Training loss: 2.012866258621216
Validation loss: 2.023137778364202

Epoch: 6| Step: 13
Training loss: 2.6401748657226562
Validation loss: 2.0318647302607054

Epoch: 103| Step: 0
Training loss: 2.1159582138061523
Validation loss: 2.0305141723284157

Epoch: 6| Step: 1
Training loss: 1.962986946105957
Validation loss: 2.037876375259892

Epoch: 6| Step: 2
Training loss: 1.6558165550231934
Validation loss: 2.0256237240247827

Epoch: 6| Step: 3
Training loss: 1.7453452348709106
Validation loss: 2.0086244319074895

Epoch: 6| Step: 4
Training loss: 1.9108948707580566
Validation loss: 2.0030166154266684

Epoch: 6| Step: 5
Training loss: 1.972611904144287
Validation loss: 1.994690591289151

Epoch: 6| Step: 6
Training loss: 2.2592551708221436
Validation loss: 1.9867924772283083

Epoch: 6| Step: 7
Training loss: 2.4986743927001953
Validation loss: 1.9953686870554441

Epoch: 6| Step: 8
Training loss: 1.9242818355560303
Validation loss: 1.9898347803341445

Epoch: 6| Step: 9
Training loss: 2.265841007232666
Validation loss: 1.9991829536294425

Epoch: 6| Step: 10
Training loss: 2.7085814476013184
Validation loss: 1.9936504364013672

Epoch: 6| Step: 11
Training loss: 2.2006900310516357
Validation loss: 2.0031038112537836

Epoch: 6| Step: 12
Training loss: 1.2574174404144287
Validation loss: 1.9851145026504353

Epoch: 6| Step: 13
Training loss: 2.505279541015625
Validation loss: 1.9918603281820975

Epoch: 104| Step: 0
Training loss: 2.7945733070373535
Validation loss: 1.9878300159208235

Epoch: 6| Step: 1
Training loss: 1.1389400959014893
Validation loss: 1.979755586193454

Epoch: 6| Step: 2
Training loss: 3.316301107406616
Validation loss: 1.9894412217601654

Epoch: 6| Step: 3
Training loss: 1.5853854417800903
Validation loss: 1.9716062045866443

Epoch: 6| Step: 4
Training loss: 1.229871153831482
Validation loss: 1.9702047173694899

Epoch: 6| Step: 5
Training loss: 2.206112861633301
Validation loss: 1.9749752001095844

Epoch: 6| Step: 6
Training loss: 1.5212392807006836
Validation loss: 1.968675321148288

Epoch: 6| Step: 7
Training loss: 1.9879180192947388
Validation loss: 1.9698243576993224

Epoch: 6| Step: 8
Training loss: 2.6675596237182617
Validation loss: 1.9817775590445406

Epoch: 6| Step: 9
Training loss: 2.2814512252807617
Validation loss: 2.008495197501234

Epoch: 6| Step: 10
Training loss: 1.9692256450653076
Validation loss: 2.0163641078497774

Epoch: 6| Step: 11
Training loss: 2.0907225608825684
Validation loss: 2.0368609556587796

Epoch: 6| Step: 12
Training loss: 2.2786145210266113
Validation loss: 2.0601164807555494

Epoch: 6| Step: 13
Training loss: 1.753494143486023
Validation loss: 2.070946021746564

Epoch: 105| Step: 0
Training loss: 2.310385227203369
Validation loss: 2.07982079316211

Epoch: 6| Step: 1
Training loss: 2.400996446609497
Validation loss: 2.0547209632012153

Epoch: 6| Step: 2
Training loss: 2.0799198150634766
Validation loss: 2.0213468356799056

Epoch: 6| Step: 3
Training loss: 1.70097815990448
Validation loss: 1.9902730744372132

Epoch: 6| Step: 4
Training loss: 2.6773200035095215
Validation loss: 1.9697352417053715

Epoch: 6| Step: 5
Training loss: 2.032139301300049
Validation loss: 1.9683526972288727

Epoch: 6| Step: 6
Training loss: 1.3866100311279297
Validation loss: 1.954299412747865

Epoch: 6| Step: 7
Training loss: 1.9005353450775146
Validation loss: 1.9733516529042234

Epoch: 6| Step: 8
Training loss: 1.545879602432251
Validation loss: 1.992371702706942

Epoch: 6| Step: 9
Training loss: 1.6338884830474854
Validation loss: 2.000231736449785

Epoch: 6| Step: 10
Training loss: 1.6340951919555664
Validation loss: 2.02655727119856

Epoch: 6| Step: 11
Training loss: 2.9836835861206055
Validation loss: 2.063628955553937

Epoch: 6| Step: 12
Training loss: 2.3568596839904785
Validation loss: 2.048193989261504

Epoch: 6| Step: 13
Training loss: 2.4619741439819336
Validation loss: 2.0264217853546143

Epoch: 106| Step: 0
Training loss: 1.8063251972198486
Validation loss: 2.008159201632264

Epoch: 6| Step: 1
Training loss: 1.6713151931762695
Validation loss: 1.965777454837676

Epoch: 6| Step: 2
Training loss: 1.7947449684143066
Validation loss: 1.9717170692259265

Epoch: 6| Step: 3
Training loss: 2.0190329551696777
Validation loss: 1.9642922057900378

Epoch: 6| Step: 4
Training loss: 1.8818751573562622
Validation loss: 1.9649296627249768

Epoch: 6| Step: 5
Training loss: 2.135632038116455
Validation loss: 1.9551253498241465

Epoch: 6| Step: 6
Training loss: 2.4257705211639404
Validation loss: 1.9568163630782918

Epoch: 6| Step: 7
Training loss: 2.209233283996582
Validation loss: 1.968949883214889

Epoch: 6| Step: 8
Training loss: 2.209486484527588
Validation loss: 1.9551638659610544

Epoch: 6| Step: 9
Training loss: 1.9207402467727661
Validation loss: 1.958934586535218

Epoch: 6| Step: 10
Training loss: 2.063688278198242
Validation loss: 1.963878495718843

Epoch: 6| Step: 11
Training loss: 2.1810550689697266
Validation loss: 1.9708059410895071

Epoch: 6| Step: 12
Training loss: 2.442373752593994
Validation loss: 1.981337470393027

Epoch: 6| Step: 13
Training loss: 2.1973633766174316
Validation loss: 1.9914201113485521

Epoch: 107| Step: 0
Training loss: 1.7828946113586426
Validation loss: 2.016633434962201

Epoch: 6| Step: 1
Training loss: 2.132624387741089
Validation loss: 2.037791262390793

Epoch: 6| Step: 2
Training loss: 2.1661176681518555
Validation loss: 2.0482760603709886

Epoch: 6| Step: 3
Training loss: 2.0364317893981934
Validation loss: 2.050037771142939

Epoch: 6| Step: 4
Training loss: 1.560471534729004
Validation loss: 2.0774165840559107

Epoch: 6| Step: 5
Training loss: 2.7009825706481934
Validation loss: 2.070033037534324

Epoch: 6| Step: 6
Training loss: 2.2171754837036133
Validation loss: 2.034551574337867

Epoch: 6| Step: 7
Training loss: 2.6370182037353516
Validation loss: 2.0207571752609743

Epoch: 6| Step: 8
Training loss: 1.9189138412475586
Validation loss: 2.0087282183349773

Epoch: 6| Step: 9
Training loss: 2.031404495239258
Validation loss: 1.9975936105174403

Epoch: 6| Step: 10
Training loss: 1.7451825141906738
Validation loss: 1.9880644403478152

Epoch: 6| Step: 11
Training loss: 2.2330322265625
Validation loss: 1.9861812027551795

Epoch: 6| Step: 12
Training loss: 1.3154830932617188
Validation loss: 1.9810359631815264

Epoch: 6| Step: 13
Training loss: 2.056424140930176
Validation loss: 1.9752056752481768

Epoch: 108| Step: 0
Training loss: 1.3124048709869385
Validation loss: 1.9852541826104606

Epoch: 6| Step: 1
Training loss: 1.234582543373108
Validation loss: 1.9797697938898557

Epoch: 6| Step: 2
Training loss: 2.260955810546875
Validation loss: 1.9819753477650304

Epoch: 6| Step: 3
Training loss: 1.9405765533447266
Validation loss: 1.992865752148372

Epoch: 6| Step: 4
Training loss: 2.267660617828369
Validation loss: 1.9928512957788282

Epoch: 6| Step: 5
Training loss: 2.843529224395752
Validation loss: 1.9832238894636913

Epoch: 6| Step: 6
Training loss: 1.7515450716018677
Validation loss: 2.0057849960942424

Epoch: 6| Step: 7
Training loss: 1.863344669342041
Validation loss: 2.031233301726721

Epoch: 6| Step: 8
Training loss: 2.2539474964141846
Validation loss: 2.032959673994331

Epoch: 6| Step: 9
Training loss: 2.255864381790161
Validation loss: 2.0457859821217035

Epoch: 6| Step: 10
Training loss: 2.004460334777832
Validation loss: 2.0507271187279814

Epoch: 6| Step: 11
Training loss: 1.9111868143081665
Validation loss: 2.042544884066428

Epoch: 6| Step: 12
Training loss: 1.7800633907318115
Validation loss: 2.027961436138358

Epoch: 6| Step: 13
Training loss: 2.8617076873779297
Validation loss: 2.025939328696138

Epoch: 109| Step: 0
Training loss: 2.332479476928711
Validation loss: 2.066124091866196

Epoch: 6| Step: 1
Training loss: 2.1008191108703613
Validation loss: 2.078888293235533

Epoch: 6| Step: 2
Training loss: 1.6817090511322021
Validation loss: 2.0684966195014214

Epoch: 6| Step: 3
Training loss: 1.7147475481033325
Validation loss: 2.057530282646097

Epoch: 6| Step: 4
Training loss: 2.7706656455993652
Validation loss: 2.0588042415598387

Epoch: 6| Step: 5
Training loss: 1.95256769657135
Validation loss: 2.0725680564039495

Epoch: 6| Step: 6
Training loss: 1.3629810810089111
Validation loss: 2.0576027542032223

Epoch: 6| Step: 7
Training loss: 1.953844428062439
Validation loss: 2.049408592203612

Epoch: 6| Step: 8
Training loss: 2.3579587936401367
Validation loss: 2.0184491988151305

Epoch: 6| Step: 9
Training loss: 2.1105387210845947
Validation loss: 2.007181397048376

Epoch: 6| Step: 10
Training loss: 2.034259080886841
Validation loss: 2.003920784560583

Epoch: 6| Step: 11
Training loss: 1.8589472770690918
Validation loss: 2.015039664442821

Epoch: 6| Step: 12
Training loss: 1.8203411102294922
Validation loss: 2.020091236278575

Epoch: 6| Step: 13
Training loss: 2.0946459770202637
Validation loss: 2.017214082902478

Epoch: 110| Step: 0
Training loss: 2.027552604675293
Validation loss: 2.0252445461929485

Epoch: 6| Step: 1
Training loss: 1.069242238998413
Validation loss: 2.02067385437668

Epoch: 6| Step: 2
Training loss: 2.4179561138153076
Validation loss: 2.0115105951986005

Epoch: 6| Step: 3
Training loss: 2.7045395374298096
Validation loss: 1.995250032794091

Epoch: 6| Step: 4
Training loss: 1.598012089729309
Validation loss: 1.9935015375896166

Epoch: 6| Step: 5
Training loss: 1.6128201484680176
Validation loss: 1.9941913620118172

Epoch: 6| Step: 6
Training loss: 1.8963309526443481
Validation loss: 1.9877173913422452

Epoch: 6| Step: 7
Training loss: 2.002894163131714
Validation loss: 1.981663598809191

Epoch: 6| Step: 8
Training loss: 1.7179278135299683
Validation loss: 1.977681790628741

Epoch: 6| Step: 9
Training loss: 1.9762320518493652
Validation loss: 1.9912635382785593

Epoch: 6| Step: 10
Training loss: 2.1732096672058105
Validation loss: 2.00706987227163

Epoch: 6| Step: 11
Training loss: 2.077516555786133
Validation loss: 2.0066585694589922

Epoch: 6| Step: 12
Training loss: 2.282223701477051
Validation loss: 2.048044830240229

Epoch: 6| Step: 13
Training loss: 2.4894583225250244
Validation loss: 2.051490283781482

Epoch: 111| Step: 0
Training loss: 2.3328990936279297
Validation loss: 2.0421416182671823

Epoch: 6| Step: 1
Training loss: 1.966151237487793
Validation loss: 2.009315913723361

Epoch: 6| Step: 2
Training loss: 1.8242688179016113
Validation loss: 1.979383454527906

Epoch: 6| Step: 3
Training loss: 1.6958897113800049
Validation loss: 1.9749170311035649

Epoch: 6| Step: 4
Training loss: 2.1141316890716553
Validation loss: 1.98821517216262

Epoch: 6| Step: 5
Training loss: 1.5774116516113281
Validation loss: 1.9877498149871826

Epoch: 6| Step: 6
Training loss: 1.7003564834594727
Validation loss: 1.9932029580557218

Epoch: 6| Step: 7
Training loss: 2.59077787399292
Validation loss: 1.9935552022790397

Epoch: 6| Step: 8
Training loss: 2.140659809112549
Validation loss: 1.9942084115038636

Epoch: 6| Step: 9
Training loss: 1.6313531398773193
Validation loss: 1.995256946932885

Epoch: 6| Step: 10
Training loss: 2.187251329421997
Validation loss: 1.9978569464016986

Epoch: 6| Step: 11
Training loss: 1.7352772951126099
Validation loss: 1.9963369856598556

Epoch: 6| Step: 12
Training loss: 2.7285234928131104
Validation loss: 2.0151754271599556

Epoch: 6| Step: 13
Training loss: 1.4659523963928223
Validation loss: 2.0424457826922016

Epoch: 112| Step: 0
Training loss: 2.5818378925323486
Validation loss: 2.0685384555529525

Epoch: 6| Step: 1
Training loss: 1.7634207010269165
Validation loss: 2.1333073390427457

Epoch: 6| Step: 2
Training loss: 2.15875244140625
Validation loss: 2.1756108704433648

Epoch: 6| Step: 3
Training loss: 2.182544708251953
Validation loss: 2.1737696586116666

Epoch: 6| Step: 4
Training loss: 1.525642991065979
Validation loss: 2.146597539224932

Epoch: 6| Step: 5
Training loss: 1.7769496440887451
Validation loss: 2.087239424387614

Epoch: 6| Step: 6
Training loss: 2.6166298389434814
Validation loss: 2.0157812000602804

Epoch: 6| Step: 7
Training loss: 2.414062738418579
Validation loss: 1.9764989255577006

Epoch: 6| Step: 8
Training loss: 1.6779423952102661
Validation loss: 1.9544996279542164

Epoch: 6| Step: 9
Training loss: 1.865892767906189
Validation loss: 1.940329554260418

Epoch: 6| Step: 10
Training loss: 1.4010025262832642
Validation loss: 1.943726085847424

Epoch: 6| Step: 11
Training loss: 2.0846807956695557
Validation loss: 1.9628571489805817

Epoch: 6| Step: 12
Training loss: 2.7016141414642334
Validation loss: 1.9567495289669241

Epoch: 6| Step: 13
Training loss: 1.7376984357833862
Validation loss: 1.9554318497257848

Epoch: 113| Step: 0
Training loss: 1.9159153699874878
Validation loss: 1.9591690878714285

Epoch: 6| Step: 1
Training loss: 1.9392483234405518
Validation loss: 1.9566746732240081

Epoch: 6| Step: 2
Training loss: 1.4284628629684448
Validation loss: 1.9664473866903653

Epoch: 6| Step: 3
Training loss: 2.380890369415283
Validation loss: 1.9984338821903351

Epoch: 6| Step: 4
Training loss: 2.298699140548706
Validation loss: 2.0130521302582114

Epoch: 6| Step: 5
Training loss: 1.7787318229675293
Validation loss: 2.0605629362085813

Epoch: 6| Step: 6
Training loss: 2.7329764366149902
Validation loss: 2.092823738692909

Epoch: 6| Step: 7
Training loss: 2.3530595302581787
Validation loss: 2.1252095225036784

Epoch: 6| Step: 8
Training loss: 2.480867385864258
Validation loss: 2.145432400447066

Epoch: 6| Step: 9
Training loss: 2.2415919303894043
Validation loss: 2.173000976603518

Epoch: 6| Step: 10
Training loss: 1.7697645425796509
Validation loss: 2.164355872779764

Epoch: 6| Step: 11
Training loss: 1.1925065517425537
Validation loss: 2.1592822792709514

Epoch: 6| Step: 12
Training loss: 1.5520868301391602
Validation loss: 2.1354674421330935

Epoch: 6| Step: 13
Training loss: 2.083483934402466
Validation loss: 2.1089368097243772

Epoch: 114| Step: 0
Training loss: 1.8849546909332275
Validation loss: 2.0902654432481333

Epoch: 6| Step: 1
Training loss: 1.912846326828003
Validation loss: 2.0394101809429865

Epoch: 6| Step: 2
Training loss: 1.1029655933380127
Validation loss: 2.0392503430766444

Epoch: 6| Step: 3
Training loss: 2.0641911029815674
Validation loss: 2.0254700017231766

Epoch: 6| Step: 4
Training loss: 1.813193917274475
Validation loss: 2.0241822273500505

Epoch: 6| Step: 5
Training loss: 2.212839126586914
Validation loss: 2.0132070895164245

Epoch: 6| Step: 6
Training loss: 2.088080883026123
Validation loss: 1.9774154796395251

Epoch: 6| Step: 7
Training loss: 1.5231326818466187
Validation loss: 1.9625015681789768

Epoch: 6| Step: 8
Training loss: 1.498364806175232
Validation loss: 1.9635772833260157

Epoch: 6| Step: 9
Training loss: 1.9445173740386963
Validation loss: 1.9637808569015995

Epoch: 6| Step: 10
Training loss: 2.4161086082458496
Validation loss: 1.9604538935486988

Epoch: 6| Step: 11
Training loss: 2.9116015434265137
Validation loss: 1.9770894460780646

Epoch: 6| Step: 12
Training loss: 2.237459659576416
Validation loss: 1.9979308766703452

Epoch: 6| Step: 13
Training loss: 1.6777693033218384
Validation loss: 1.9924239548303748

Epoch: 115| Step: 0
Training loss: 2.0179953575134277
Validation loss: 2.013223418625452

Epoch: 6| Step: 1
Training loss: 1.3075475692749023
Validation loss: 1.9879426212720974

Epoch: 6| Step: 2
Training loss: 1.9440040588378906
Validation loss: 1.9741264325316235

Epoch: 6| Step: 3
Training loss: 2.6613516807556152
Validation loss: 1.9732880412891347

Epoch: 6| Step: 4
Training loss: 2.0770890712738037
Validation loss: 1.976856682890205

Epoch: 6| Step: 5
Training loss: 1.6430268287658691
Validation loss: 1.9767199344532465

Epoch: 6| Step: 6
Training loss: 1.7716702222824097
Validation loss: 1.9821728070576985

Epoch: 6| Step: 7
Training loss: 2.488884925842285
Validation loss: 2.004062665406094

Epoch: 6| Step: 8
Training loss: 1.9746499061584473
Validation loss: 2.0139573543302474

Epoch: 6| Step: 9
Training loss: 1.7825069427490234
Validation loss: 2.018275796726186

Epoch: 6| Step: 10
Training loss: 2.1940722465515137
Validation loss: 2.003513046490249

Epoch: 6| Step: 11
Training loss: 1.8489797115325928
Validation loss: 1.9936640134421728

Epoch: 6| Step: 12
Training loss: 1.7683297395706177
Validation loss: 1.9871595085308116

Epoch: 6| Step: 13
Training loss: 2.0899529457092285
Validation loss: 1.9960142604766353

Epoch: 116| Step: 0
Training loss: 2.146254062652588
Validation loss: 2.006587971923172

Epoch: 6| Step: 1
Training loss: 2.203665256500244
Validation loss: 1.997628483721005

Epoch: 6| Step: 2
Training loss: 1.536450982093811
Validation loss: 1.9946226663486932

Epoch: 6| Step: 3
Training loss: 2.015486717224121
Validation loss: 2.0111060527063187

Epoch: 6| Step: 4
Training loss: 1.9986636638641357
Validation loss: 1.998939077059428

Epoch: 6| Step: 5
Training loss: 1.8070415258407593
Validation loss: 1.9939603344086678

Epoch: 6| Step: 6
Training loss: 1.6229428052902222
Validation loss: 1.9677218006503197

Epoch: 6| Step: 7
Training loss: 1.857107400894165
Validation loss: 1.9746304711987894

Epoch: 6| Step: 8
Training loss: 1.891800045967102
Validation loss: 1.969523827234904

Epoch: 6| Step: 9
Training loss: 1.8875081539154053
Validation loss: 1.9658755845921014

Epoch: 6| Step: 10
Training loss: 1.8546319007873535
Validation loss: 1.9756420504662298

Epoch: 6| Step: 11
Training loss: 1.9121766090393066
Validation loss: 1.9831483235923193

Epoch: 6| Step: 12
Training loss: 2.648646831512451
Validation loss: 1.9982394800391248

Epoch: 6| Step: 13
Training loss: 2.0372159481048584
Validation loss: 2.024755964996994

Epoch: 117| Step: 0
Training loss: 2.383845806121826
Validation loss: 2.0280256502089964

Epoch: 6| Step: 1
Training loss: 2.266958713531494
Validation loss: 2.0616338509385304

Epoch: 6| Step: 2
Training loss: 1.798897385597229
Validation loss: 2.0459905362898305

Epoch: 6| Step: 3
Training loss: 1.4881563186645508
Validation loss: 2.025474553467125

Epoch: 6| Step: 4
Training loss: 1.5933918952941895
Validation loss: 2.0204807455821703

Epoch: 6| Step: 5
Training loss: 1.7851121425628662
Validation loss: 1.990558660158547

Epoch: 6| Step: 6
Training loss: 2.040426254272461
Validation loss: 1.967749954551779

Epoch: 6| Step: 7
Training loss: 1.616544246673584
Validation loss: 1.9587252473318448

Epoch: 6| Step: 8
Training loss: 2.2538819313049316
Validation loss: 1.9687195477947113

Epoch: 6| Step: 9
Training loss: 2.3138012886047363
Validation loss: 1.9350955101751512

Epoch: 6| Step: 10
Training loss: 2.1587657928466797
Validation loss: 1.9239016232951995

Epoch: 6| Step: 11
Training loss: 2.666503429412842
Validation loss: 1.930306952486756

Epoch: 6| Step: 12
Training loss: 1.2653415203094482
Validation loss: 1.9270844305715253

Epoch: 6| Step: 13
Training loss: 1.3812264204025269
Validation loss: 1.9355760107758224

Epoch: 118| Step: 0
Training loss: 2.106297492980957
Validation loss: 1.9550361120572655

Epoch: 6| Step: 1
Training loss: 2.1452035903930664
Validation loss: 1.978698504868374

Epoch: 6| Step: 2
Training loss: 1.9308722019195557
Validation loss: 1.9975149490500008

Epoch: 6| Step: 3
Training loss: 1.4786332845687866
Validation loss: 2.005940923126795

Epoch: 6| Step: 4
Training loss: 2.1562952995300293
Validation loss: 2.0152237594768567

Epoch: 6| Step: 5
Training loss: 1.9132226705551147
Validation loss: 2.01817907825593

Epoch: 6| Step: 6
Training loss: 1.848697543144226
Validation loss: 2.0313868612371464

Epoch: 6| Step: 7
Training loss: 2.405756950378418
Validation loss: 2.029272647314174

Epoch: 6| Step: 8
Training loss: 1.9578670263290405
Validation loss: 2.0302499058426067

Epoch: 6| Step: 9
Training loss: 1.7104368209838867
Validation loss: 2.0131583470170216

Epoch: 6| Step: 10
Training loss: 1.3448052406311035
Validation loss: 2.0117491009414836

Epoch: 6| Step: 11
Training loss: 1.8235020637512207
Validation loss: 2.000160037830312

Epoch: 6| Step: 12
Training loss: 2.018657684326172
Validation loss: 1.9994647246535107

Epoch: 6| Step: 13
Training loss: 1.9152690172195435
Validation loss: 1.9921135787040956

Epoch: 119| Step: 0
Training loss: 1.4749755859375
Validation loss: 1.9982026956414665

Epoch: 6| Step: 1
Training loss: 1.592743992805481
Validation loss: 2.009513465307092

Epoch: 6| Step: 2
Training loss: 1.377828598022461
Validation loss: 2.0070102983905422

Epoch: 6| Step: 3
Training loss: 1.685971975326538
Validation loss: 2.0281476692486833

Epoch: 6| Step: 4
Training loss: 1.720738172531128
Validation loss: 2.0261078316678285

Epoch: 6| Step: 5
Training loss: 1.770477056503296
Validation loss: 2.034441613381909

Epoch: 6| Step: 6
Training loss: 2.18984317779541
Validation loss: 2.018963708672472

Epoch: 6| Step: 7
Training loss: 2.767390251159668
Validation loss: 1.9975620162102483

Epoch: 6| Step: 8
Training loss: 1.6483557224273682
Validation loss: 1.9674134639001661

Epoch: 6| Step: 9
Training loss: 2.5920169353485107
Validation loss: 1.9369562069574993

Epoch: 6| Step: 10
Training loss: 1.5068953037261963
Validation loss: 1.9066856830350813

Epoch: 6| Step: 11
Training loss: 2.7821712493896484
Validation loss: 1.8980608781178792

Epoch: 6| Step: 12
Training loss: 1.1978297233581543
Validation loss: 1.8851088810992498

Epoch: 6| Step: 13
Training loss: 2.550503730773926
Validation loss: 1.892873542283171

Epoch: 120| Step: 0
Training loss: 1.8412408828735352
Validation loss: 1.9092422146950998

Epoch: 6| Step: 1
Training loss: 2.203761577606201
Validation loss: 1.939251374172908

Epoch: 6| Step: 2
Training loss: 2.0246078968048096
Validation loss: 1.9474429110045075

Epoch: 6| Step: 3
Training loss: 1.930605173110962
Validation loss: 1.9517044213510328

Epoch: 6| Step: 4
Training loss: 2.111128330230713
Validation loss: 1.956690949778403

Epoch: 6| Step: 5
Training loss: 1.7456594705581665
Validation loss: 1.9599536208696262

Epoch: 6| Step: 6
Training loss: 2.2646570205688477
Validation loss: 1.9844414546925535

Epoch: 6| Step: 7
Training loss: 1.5467370748519897
Validation loss: 1.9729206844042706

Epoch: 6| Step: 8
Training loss: 1.8387022018432617
Validation loss: 1.9744851717384913

Epoch: 6| Step: 9
Training loss: 1.5907392501831055
Validation loss: 1.9597247595428138

Epoch: 6| Step: 10
Training loss: 1.7644213438034058
Validation loss: 1.9687149447779502

Epoch: 6| Step: 11
Training loss: 1.843472957611084
Validation loss: 1.9798980015580372

Epoch: 6| Step: 12
Training loss: 1.751230001449585
Validation loss: 2.0280777587685535

Epoch: 6| Step: 13
Training loss: 2.0993499755859375
Validation loss: 2.0161811818358717

Epoch: 121| Step: 0
Training loss: 1.5370872020721436
Validation loss: 2.008076403730659

Epoch: 6| Step: 1
Training loss: 1.9422317743301392
Validation loss: 1.995750868192283

Epoch: 6| Step: 2
Training loss: 1.7824608087539673
Validation loss: 1.9675120320371402

Epoch: 6| Step: 3
Training loss: 1.5594881772994995
Validation loss: 1.944192499242803

Epoch: 6| Step: 4
Training loss: 1.504363775253296
Validation loss: 1.9368123956905898

Epoch: 6| Step: 5
Training loss: 1.8913257122039795
Validation loss: 1.9484422463242725

Epoch: 6| Step: 6
Training loss: 1.689054012298584
Validation loss: 1.9662396369441864

Epoch: 6| Step: 7
Training loss: 2.2319211959838867
Validation loss: 1.9784219700803038

Epoch: 6| Step: 8
Training loss: 1.8418283462524414
Validation loss: 2.000455787104945

Epoch: 6| Step: 9
Training loss: 2.5074098110198975
Validation loss: 2.014005002155099

Epoch: 6| Step: 10
Training loss: 1.759522795677185
Validation loss: 2.012771915364009

Epoch: 6| Step: 11
Training loss: 1.9785213470458984
Validation loss: 2.0143165588378906

Epoch: 6| Step: 12
Training loss: 2.1696858406066895
Validation loss: 2.036563745108984

Epoch: 6| Step: 13
Training loss: 1.2009388208389282
Validation loss: 2.045685442545081

Epoch: 122| Step: 0
Training loss: 1.8544988632202148
Validation loss: 2.022767038755519

Epoch: 6| Step: 1
Training loss: 1.9510724544525146
Validation loss: 2.0417025319991575

Epoch: 6| Step: 2
Training loss: 1.6807990074157715
Validation loss: 2.0308487607586767

Epoch: 6| Step: 3
Training loss: 1.8266267776489258
Validation loss: 2.0194434235172887

Epoch: 6| Step: 4
Training loss: 1.5946826934814453
Validation loss: 2.006455816248412

Epoch: 6| Step: 5
Training loss: 2.0678582191467285
Validation loss: 1.9956936913151895

Epoch: 6| Step: 6
Training loss: 2.0341339111328125
Validation loss: 1.9827316550798313

Epoch: 6| Step: 7
Training loss: 1.886952519416809
Validation loss: 1.969057120302672

Epoch: 6| Step: 8
Training loss: 1.6320178508758545
Validation loss: 1.9933399218384937

Epoch: 6| Step: 9
Training loss: 1.5272036790847778
Validation loss: 2.010526757086477

Epoch: 6| Step: 10
Training loss: 2.4363162517547607
Validation loss: 2.0259761130937965

Epoch: 6| Step: 11
Training loss: 2.099449634552002
Validation loss: 2.0103233911657847

Epoch: 6| Step: 12
Training loss: 1.6601898670196533
Validation loss: 2.0147181480161604

Epoch: 6| Step: 13
Training loss: 1.8049558401107788
Validation loss: 2.0220399223348147

Epoch: 123| Step: 0
Training loss: 1.615866780281067
Validation loss: 2.008591854444114

Epoch: 6| Step: 1
Training loss: 1.5146660804748535
Validation loss: 1.975420928770496

Epoch: 6| Step: 2
Training loss: 1.8091599941253662
Validation loss: 1.9534767481588549

Epoch: 6| Step: 3
Training loss: 1.8634016513824463
Validation loss: 1.9379833949509488

Epoch: 6| Step: 4
Training loss: 2.175553321838379
Validation loss: 1.9224710374750116

Epoch: 6| Step: 5
Training loss: 1.2711784839630127
Validation loss: 1.9303055655571721

Epoch: 6| Step: 6
Training loss: 1.7429687976837158
Validation loss: 1.9366484867629183

Epoch: 6| Step: 7
Training loss: 2.0685815811157227
Validation loss: 1.9403663591672016

Epoch: 6| Step: 8
Training loss: 2.0007340908050537
Validation loss: 1.9536309985704319

Epoch: 6| Step: 9
Training loss: 1.6426975727081299
Validation loss: 1.9563554089556459

Epoch: 6| Step: 10
Training loss: 2.6666698455810547
Validation loss: 1.9718556788659864

Epoch: 6| Step: 11
Training loss: 1.9445744752883911
Validation loss: 2.005430454848915

Epoch: 6| Step: 12
Training loss: 1.6170090436935425
Validation loss: 2.0246819373100036

Epoch: 6| Step: 13
Training loss: 2.1066274642944336
Validation loss: 2.0460537325951362

Epoch: 124| Step: 0
Training loss: 1.348719835281372
Validation loss: 2.0560441042787287

Epoch: 6| Step: 1
Training loss: 1.7077749967575073
Validation loss: 2.114686537814397

Epoch: 6| Step: 2
Training loss: 2.0014123916625977
Validation loss: 2.1600546195942867

Epoch: 6| Step: 3
Training loss: 1.6818867921829224
Validation loss: 2.176060148464736

Epoch: 6| Step: 4
Training loss: 2.127473831176758
Validation loss: 2.12146173497682

Epoch: 6| Step: 5
Training loss: 1.9399961233139038
Validation loss: 2.0504226120569373

Epoch: 6| Step: 6
Training loss: 1.6836950778961182
Validation loss: 1.9648848015774962

Epoch: 6| Step: 7
Training loss: 2.315321683883667
Validation loss: 1.9482977813290012

Epoch: 6| Step: 8
Training loss: 1.5633409023284912
Validation loss: 1.9443768762773084

Epoch: 6| Step: 9
Training loss: 1.8047401905059814
Validation loss: 1.955373703792531

Epoch: 6| Step: 10
Training loss: 1.9683380126953125
Validation loss: 1.9508608118180306

Epoch: 6| Step: 11
Training loss: 2.3674211502075195
Validation loss: 1.9700510360861336

Epoch: 6| Step: 12
Training loss: 2.1077494621276855
Validation loss: 1.9692130768170921

Epoch: 6| Step: 13
Training loss: 2.0711631774902344
Validation loss: 1.9758547967480076

Epoch: 125| Step: 0
Training loss: 1.6050941944122314
Validation loss: 1.9669042992335495

Epoch: 6| Step: 1
Training loss: 1.9181277751922607
Validation loss: 1.9715606371561687

Epoch: 6| Step: 2
Training loss: 1.5730408430099487
Validation loss: 1.9831134337250904

Epoch: 6| Step: 3
Training loss: 2.3142335414886475
Validation loss: 1.9524124309580813

Epoch: 6| Step: 4
Training loss: 2.1022188663482666
Validation loss: 1.9591925426196026

Epoch: 6| Step: 5
Training loss: 1.5515813827514648
Validation loss: 1.980622842747678

Epoch: 6| Step: 6
Training loss: 1.6010372638702393
Validation loss: 2.0238372920661845

Epoch: 6| Step: 7
Training loss: 2.0470187664031982
Validation loss: 2.073083741690523

Epoch: 6| Step: 8
Training loss: 1.8474544286727905
Validation loss: 2.0746306168135775

Epoch: 6| Step: 9
Training loss: 1.8836283683776855
Validation loss: 2.065245247656299

Epoch: 6| Step: 10
Training loss: 2.103736639022827
Validation loss: 2.031936268652639

Epoch: 6| Step: 11
Training loss: 1.7635324001312256
Validation loss: 2.032959799612722

Epoch: 6| Step: 12
Training loss: 2.106004238128662
Validation loss: 2.0232986660413843

Epoch: 6| Step: 13
Training loss: 1.8070886135101318
Validation loss: 2.005421825634536

Epoch: 126| Step: 0
Training loss: 1.1656303405761719
Validation loss: 2.0048435593164093

Epoch: 6| Step: 1
Training loss: 1.9864592552185059
Validation loss: 1.9750289070990779

Epoch: 6| Step: 2
Training loss: 2.2271156311035156
Validation loss: 1.9595652844316216

Epoch: 6| Step: 3
Training loss: 1.6909759044647217
Validation loss: 1.9362447338719522

Epoch: 6| Step: 4
Training loss: 1.6969707012176514
Validation loss: 1.9120838872848018

Epoch: 6| Step: 5
Training loss: 2.0123631954193115
Validation loss: 1.900675368565385

Epoch: 6| Step: 6
Training loss: 2.1676206588745117
Validation loss: 1.8939685154986639

Epoch: 6| Step: 7
Training loss: 1.7054898738861084
Validation loss: 1.914326762640348

Epoch: 6| Step: 8
Training loss: 2.52274751663208
Validation loss: 1.9147732129660986

Epoch: 6| Step: 9
Training loss: 1.7606865167617798
Validation loss: 1.9398213355771956

Epoch: 6| Step: 10
Training loss: 1.3743187189102173
Validation loss: 1.949301089009931

Epoch: 6| Step: 11
Training loss: 1.8932018280029297
Validation loss: 1.9493432878166117

Epoch: 6| Step: 12
Training loss: 1.2259209156036377
Validation loss: 1.9609717194752028

Epoch: 6| Step: 13
Training loss: 2.801349401473999
Validation loss: 1.9836530685424805

Epoch: 127| Step: 0
Training loss: 2.0966429710388184
Validation loss: 1.9576139475709649

Epoch: 6| Step: 1
Training loss: 1.6538223028182983
Validation loss: 1.9588064583398963

Epoch: 6| Step: 2
Training loss: 1.8082163333892822
Validation loss: 1.9464002296488772

Epoch: 6| Step: 3
Training loss: 2.085911512374878
Validation loss: 1.9581947916297502

Epoch: 6| Step: 4
Training loss: 2.2596354484558105
Validation loss: 1.9672729392205515

Epoch: 6| Step: 5
Training loss: 2.2659752368927
Validation loss: 1.9685586242265598

Epoch: 6| Step: 6
Training loss: 2.007993698120117
Validation loss: 1.9651586509520007

Epoch: 6| Step: 7
Training loss: 1.5878794193267822
Validation loss: 1.967793954316006

Epoch: 6| Step: 8
Training loss: 1.8555315732955933
Validation loss: 1.9768958501918341

Epoch: 6| Step: 9
Training loss: 1.1414726972579956
Validation loss: 1.9733122946113668

Epoch: 6| Step: 10
Training loss: 1.3966035842895508
Validation loss: 1.9521436511829335

Epoch: 6| Step: 11
Training loss: 2.226405382156372
Validation loss: 1.9433947276043635

Epoch: 6| Step: 12
Training loss: 1.1771295070648193
Validation loss: 1.9394230099134548

Epoch: 6| Step: 13
Training loss: 1.822213053703308
Validation loss: 1.9598608721968949

Epoch: 128| Step: 0
Training loss: 2.253647804260254
Validation loss: 1.9861070417588758

Epoch: 6| Step: 1
Training loss: 1.4987504482269287
Validation loss: 2.0303128393747474

Epoch: 6| Step: 2
Training loss: 1.4185458421707153
Validation loss: 2.0325222156381093

Epoch: 6| Step: 3
Training loss: 1.6119186878204346
Validation loss: 2.034556934910436

Epoch: 6| Step: 4
Training loss: 1.2029571533203125
Validation loss: 2.041948431281633

Epoch: 6| Step: 5
Training loss: 2.591840982437134
Validation loss: 2.007083672349171

Epoch: 6| Step: 6
Training loss: 1.7750840187072754
Validation loss: 1.982300603261558

Epoch: 6| Step: 7
Training loss: 1.7616782188415527
Validation loss: 1.9733885859930387

Epoch: 6| Step: 8
Training loss: 1.3377933502197266
Validation loss: 1.9770048228643273

Epoch: 6| Step: 9
Training loss: 2.250244379043579
Validation loss: 1.9904573130351242

Epoch: 6| Step: 10
Training loss: 2.004791259765625
Validation loss: 2.028185116347446

Epoch: 6| Step: 11
Training loss: 1.838218092918396
Validation loss: 2.0608685157632314

Epoch: 6| Step: 12
Training loss: 1.6690192222595215
Validation loss: 2.095701902143417

Epoch: 6| Step: 13
Training loss: 1.811185598373413
Validation loss: 2.1031614221552366

Epoch: 129| Step: 0
Training loss: 2.1161036491394043
Validation loss: 2.1037255538407194

Epoch: 6| Step: 1
Training loss: 1.788527011871338
Validation loss: 2.1100963597656577

Epoch: 6| Step: 2
Training loss: 1.900067925453186
Validation loss: 2.0807193633048766

Epoch: 6| Step: 3
Training loss: 1.5784649848937988
Validation loss: 2.0133700486152404

Epoch: 6| Step: 4
Training loss: 1.7028475999832153
Validation loss: 1.9888305676880704

Epoch: 6| Step: 5
Training loss: 1.5598068237304688
Validation loss: 1.9741155806408133

Epoch: 6| Step: 6
Training loss: 1.4915575981140137
Validation loss: 1.9801766744223974

Epoch: 6| Step: 7
Training loss: 1.213895559310913
Validation loss: 1.9746388773764334

Epoch: 6| Step: 8
Training loss: 1.5085935592651367
Validation loss: 1.9720051852605676

Epoch: 6| Step: 9
Training loss: 2.332073926925659
Validation loss: 1.9831442474037089

Epoch: 6| Step: 10
Training loss: 2.40969181060791
Validation loss: 1.9734284826504287

Epoch: 6| Step: 11
Training loss: 1.459679365158081
Validation loss: 1.9574443114701139

Epoch: 6| Step: 12
Training loss: 1.7164204120635986
Validation loss: 1.9468842847372896

Epoch: 6| Step: 13
Training loss: 2.535975456237793
Validation loss: 1.923926426518348

Epoch: 130| Step: 0
Training loss: 1.3093880414962769
Validation loss: 1.9511209559696976

Epoch: 6| Step: 1
Training loss: 1.7554850578308105
Validation loss: 1.9779156587457145

Epoch: 6| Step: 2
Training loss: 2.0508925914764404
Validation loss: 2.0010781864966116

Epoch: 6| Step: 3
Training loss: 1.9754997491836548
Validation loss: 1.997351110622447

Epoch: 6| Step: 4
Training loss: 1.5938842296600342
Validation loss: 1.984988119012566

Epoch: 6| Step: 5
Training loss: 1.6293227672576904
Validation loss: 2.006197921691402

Epoch: 6| Step: 6
Training loss: 1.4454342126846313
Validation loss: 2.034492423457484

Epoch: 6| Step: 7
Training loss: 1.5695886611938477
Validation loss: 2.089161701099847

Epoch: 6| Step: 8
Training loss: 1.9555758237838745
Validation loss: 2.1784642281070834

Epoch: 6| Step: 9
Training loss: 1.6549004316329956
Validation loss: 2.1633513845423216

Epoch: 6| Step: 10
Training loss: 2.023592948913574
Validation loss: 2.104035710775724

Epoch: 6| Step: 11
Training loss: 1.5093183517456055
Validation loss: 2.108901144355856

Epoch: 6| Step: 12
Training loss: 1.693689227104187
Validation loss: 2.0635160553839897

Epoch: 6| Step: 13
Training loss: 2.2654683589935303
Validation loss: 2.0488567454840547

Epoch: 131| Step: 0
Training loss: 2.180607318878174
Validation loss: 2.03323031497258

Epoch: 6| Step: 1
Training loss: 2.7345943450927734
Validation loss: 2.0172418330305364

Epoch: 6| Step: 2
Training loss: 2.2864115238189697
Validation loss: 2.0041341653434177

Epoch: 6| Step: 3
Training loss: 1.0525338649749756
Validation loss: 1.9813567874252156

Epoch: 6| Step: 4
Training loss: 1.3811979293823242
Validation loss: 1.9721630542509017

Epoch: 6| Step: 5
Training loss: 1.7784781455993652
Validation loss: 1.9545628281049832

Epoch: 6| Step: 6
Training loss: 2.118053436279297
Validation loss: 1.9383481971679195

Epoch: 6| Step: 7
Training loss: 0.8155606985092163
Validation loss: 1.9554312767521027

Epoch: 6| Step: 8
Training loss: 1.7986464500427246
Validation loss: 1.9838067562349382

Epoch: 6| Step: 9
Training loss: 1.1545944213867188
Validation loss: 1.9879497751112907

Epoch: 6| Step: 10
Training loss: 1.912827968597412
Validation loss: 1.9902490877336072

Epoch: 6| Step: 11
Training loss: 2.0320241451263428
Validation loss: 2.01591980841852

Epoch: 6| Step: 12
Training loss: 1.4921398162841797
Validation loss: 2.005291215835079

Epoch: 6| Step: 13
Training loss: 1.0451512336730957
Validation loss: 2.0060521197575394

Epoch: 132| Step: 0
Training loss: 1.9867427349090576
Validation loss: 1.9746658571304814

Epoch: 6| Step: 1
Training loss: 1.4784570932388306
Validation loss: 1.9787131099290745

Epoch: 6| Step: 2
Training loss: 1.4550238847732544
Validation loss: 1.9845066737103205

Epoch: 6| Step: 3
Training loss: 1.5925414562225342
Validation loss: 1.981494685654999

Epoch: 6| Step: 4
Training loss: 1.4677433967590332
Validation loss: 2.0109652806353826

Epoch: 6| Step: 5
Training loss: 1.5303081274032593
Validation loss: 2.061083960276778

Epoch: 6| Step: 6
Training loss: 1.5158158540725708
Validation loss: 2.0605397967882055

Epoch: 6| Step: 7
Training loss: 1.8752801418304443
Validation loss: 2.0681036428738664

Epoch: 6| Step: 8
Training loss: 1.3551536798477173
Validation loss: 2.058227972317767

Epoch: 6| Step: 9
Training loss: 1.728210687637329
Validation loss: 2.022149001398394

Epoch: 6| Step: 10
Training loss: 2.1350114345550537
Validation loss: 2.0395141673344437

Epoch: 6| Step: 11
Training loss: 1.6247895956039429
Validation loss: 2.0411887527793966

Epoch: 6| Step: 12
Training loss: 2.1505255699157715
Validation loss: 2.0107632067895707

Epoch: 6| Step: 13
Training loss: 2.5259552001953125
Validation loss: 1.96843812798941

Epoch: 133| Step: 0
Training loss: 2.2724175453186035
Validation loss: 1.9400058061845842

Epoch: 6| Step: 1
Training loss: 1.6232225894927979
Validation loss: 1.921375923259284

Epoch: 6| Step: 2
Training loss: 0.927823543548584
Validation loss: 1.8975856073441044

Epoch: 6| Step: 3
Training loss: 1.8190593719482422
Validation loss: 1.8916436754247195

Epoch: 6| Step: 4
Training loss: 1.5161298513412476
Validation loss: 1.884292289774905

Epoch: 6| Step: 5
Training loss: 1.2635856866836548
Validation loss: 1.8947687456684728

Epoch: 6| Step: 6
Training loss: 1.9689592123031616
Validation loss: 1.901861524069181

Epoch: 6| Step: 7
Training loss: 2.055394172668457
Validation loss: 1.925536124936996

Epoch: 6| Step: 8
Training loss: 1.898810625076294
Validation loss: 1.939831784976426

Epoch: 6| Step: 9
Training loss: 1.8617379665374756
Validation loss: 1.9643202815004575

Epoch: 6| Step: 10
Training loss: 1.7430646419525146
Validation loss: 2.0252244882686163

Epoch: 6| Step: 11
Training loss: 1.1992470026016235
Validation loss: 2.0809116645525862

Epoch: 6| Step: 12
Training loss: 1.5953848361968994
Validation loss: 2.1591009375869588

Epoch: 6| Step: 13
Training loss: 2.1513524055480957
Validation loss: 2.185955755172237

Epoch: 134| Step: 0
Training loss: 1.6804990768432617
Validation loss: 2.1875121362747683

Epoch: 6| Step: 1
Training loss: 1.247908115386963
Validation loss: 2.186307863522601

Epoch: 6| Step: 2
Training loss: 1.544272780418396
Validation loss: 2.136961207594923

Epoch: 6| Step: 3
Training loss: 1.0573123693466187
Validation loss: 2.0785188213471444

Epoch: 6| Step: 4
Training loss: 2.494504928588867
Validation loss: 2.0157646312508533

Epoch: 6| Step: 5
Training loss: 1.5511049032211304
Validation loss: 1.988044656733031

Epoch: 6| Step: 6
Training loss: 1.2292792797088623
Validation loss: 1.9646834352964997

Epoch: 6| Step: 7
Training loss: 1.6685031652450562
Validation loss: 1.9464393379867717

Epoch: 6| Step: 8
Training loss: 1.6645677089691162
Validation loss: 1.9449695002648137

Epoch: 6| Step: 9
Training loss: 2.2597110271453857
Validation loss: 1.9596440651083504

Epoch: 6| Step: 10
Training loss: 1.6307075023651123
Validation loss: 1.940788572834384

Epoch: 6| Step: 11
Training loss: 2.646247386932373
Validation loss: 1.9417608373908586

Epoch: 6| Step: 12
Training loss: 1.4550635814666748
Validation loss: 1.9425613803248252

Epoch: 6| Step: 13
Training loss: 1.2650099992752075
Validation loss: 1.9405031986134027

Epoch: 135| Step: 0
Training loss: 2.1310784816741943
Validation loss: 1.9429483182968632

Epoch: 6| Step: 1
Training loss: 1.620390772819519
Validation loss: 1.937047919919414

Epoch: 6| Step: 2
Training loss: 1.9699883460998535
Validation loss: 1.91664505773975

Epoch: 6| Step: 3
Training loss: 1.7201110124588013
Validation loss: 1.91440801594847

Epoch: 6| Step: 4
Training loss: 1.3311347961425781
Validation loss: 1.9257485123090847

Epoch: 6| Step: 5
Training loss: 1.1615662574768066
Validation loss: 1.9434220380680536

Epoch: 6| Step: 6
Training loss: 1.901158094406128
Validation loss: 1.98680696692518

Epoch: 6| Step: 7
Training loss: 1.9733814001083374
Validation loss: 1.9914910690758818

Epoch: 6| Step: 8
Training loss: 1.5555720329284668
Validation loss: 2.023134808386526

Epoch: 6| Step: 9
Training loss: 1.2103055715560913
Validation loss: 2.0179360079508957

Epoch: 6| Step: 10
Training loss: 1.80513334274292
Validation loss: 2.0526325779576458

Epoch: 6| Step: 11
Training loss: 1.3182685375213623
Validation loss: 2.0578507889983473

Epoch: 6| Step: 12
Training loss: 1.6935763359069824
Validation loss: 2.0613071213486376

Epoch: 6| Step: 13
Training loss: 1.7196801900863647
Validation loss: 2.0780953412414878

Epoch: 136| Step: 0
Training loss: 1.6853721141815186
Validation loss: 2.11107716765455

Epoch: 6| Step: 1
Training loss: 1.3550317287445068
Validation loss: 2.1445336521312757

Epoch: 6| Step: 2
Training loss: 0.8182141184806824
Validation loss: 2.168993088506883

Epoch: 6| Step: 3
Training loss: 2.024496555328369
Validation loss: 2.20331907785067

Epoch: 6| Step: 4
Training loss: 1.6063246726989746
Validation loss: 2.2219102997933664

Epoch: 6| Step: 5
Training loss: 0.9409412145614624
Validation loss: 2.1805492677996234

Epoch: 6| Step: 6
Training loss: 2.527801513671875
Validation loss: 2.1206893433806715

Epoch: 6| Step: 7
Training loss: 1.8872709274291992
Validation loss: 2.0601069517033075

Epoch: 6| Step: 8
Training loss: 1.570544958114624
Validation loss: 2.0036231856192313

Epoch: 6| Step: 9
Training loss: 1.3175477981567383
Validation loss: 1.946671805074138

Epoch: 6| Step: 10
Training loss: 1.9994124174118042
Validation loss: 1.9203733474977556

Epoch: 6| Step: 11
Training loss: 1.5000274181365967
Validation loss: 1.8928970072859077

Epoch: 6| Step: 12
Training loss: 2.0552785396575928
Validation loss: 1.8868695305239769

Epoch: 6| Step: 13
Training loss: 2.1843066215515137
Validation loss: 1.9005572821504326

Epoch: 137| Step: 0
Training loss: 1.8565723896026611
Validation loss: 1.9050598605986564

Epoch: 6| Step: 1
Training loss: 1.6962826251983643
Validation loss: 1.9175375687178744

Epoch: 6| Step: 2
Training loss: 1.19682776927948
Validation loss: 1.941101312637329

Epoch: 6| Step: 3
Training loss: 1.66519033908844
Validation loss: 1.9852801228082309

Epoch: 6| Step: 4
Training loss: 2.284313678741455
Validation loss: 2.0110807495732463

Epoch: 6| Step: 5
Training loss: 1.1581047773361206
Validation loss: 1.9576483439373713

Epoch: 6| Step: 6
Training loss: 1.3790538311004639
Validation loss: 1.9515214402188537

Epoch: 6| Step: 7
Training loss: 1.6435736417770386
Validation loss: 1.9549441978495607

Epoch: 6| Step: 8
Training loss: 1.639944314956665
Validation loss: 1.9842846265403173

Epoch: 6| Step: 9
Training loss: 1.7582426071166992
Validation loss: 2.0062717981235956

Epoch: 6| Step: 10
Training loss: 1.2257623672485352
Validation loss: 2.05946506351553

Epoch: 6| Step: 11
Training loss: 1.566044569015503
Validation loss: 2.096021244602819

Epoch: 6| Step: 12
Training loss: 1.911358118057251
Validation loss: 2.185814690846269

Epoch: 6| Step: 13
Training loss: 1.9038715362548828
Validation loss: 2.2473630084786365

Epoch: 138| Step: 0
Training loss: 1.473205804824829
Validation loss: 2.2853502047959195

Epoch: 6| Step: 1
Training loss: 1.5561094284057617
Validation loss: 2.2259270709048034

Epoch: 6| Step: 2
Training loss: 1.765726089477539
Validation loss: 2.158311931035852

Epoch: 6| Step: 3
Training loss: 1.1342345476150513
Validation loss: 2.0713870973997217

Epoch: 6| Step: 4
Training loss: 1.8489019870758057
Validation loss: 1.9979030060511764

Epoch: 6| Step: 5
Training loss: 1.5882301330566406
Validation loss: 1.9838919678042013

Epoch: 6| Step: 6
Training loss: 1.5347075462341309
Validation loss: 1.9624770431108371

Epoch: 6| Step: 7
Training loss: 1.6883705854415894
Validation loss: 1.959401710059053

Epoch: 6| Step: 8
Training loss: 1.392749547958374
Validation loss: 1.9724289896667644

Epoch: 6| Step: 9
Training loss: 2.864729404449463
Validation loss: 1.9816997384512296

Epoch: 6| Step: 10
Training loss: 1.8534338474273682
Validation loss: 1.9812310100883566

Epoch: 6| Step: 11
Training loss: 1.386824131011963
Validation loss: 1.9311486674893288

Epoch: 6| Step: 12
Training loss: 1.1475226879119873
Validation loss: 1.9118983566120107

Epoch: 6| Step: 13
Training loss: 1.4674317836761475
Validation loss: 1.93038526914453

Epoch: 139| Step: 0
Training loss: 1.5105068683624268
Validation loss: 1.9445969878986318

Epoch: 6| Step: 1
Training loss: 0.8457244038581848
Validation loss: 2.017647615043066

Epoch: 6| Step: 2
Training loss: 1.1453529596328735
Validation loss: 2.02330510334302

Epoch: 6| Step: 3
Training loss: 1.4790453910827637
Validation loss: 2.0458283732014317

Epoch: 6| Step: 4
Training loss: 1.724705696105957
Validation loss: 2.0405413143096434

Epoch: 6| Step: 5
Training loss: 2.024739980697632
Validation loss: 2.0723556613409393

Epoch: 6| Step: 6
Training loss: 1.357207179069519
Validation loss: 2.093956006470547

Epoch: 6| Step: 7
Training loss: 2.1753010749816895
Validation loss: 2.1197377340767973

Epoch: 6| Step: 8
Training loss: 1.091792345046997
Validation loss: 2.076381052694013

Epoch: 6| Step: 9
Training loss: 1.3999781608581543
Validation loss: 2.0368661803583943

Epoch: 6| Step: 10
Training loss: 1.386284351348877
Validation loss: 1.9663668460743402

Epoch: 6| Step: 11
Training loss: 1.873948574066162
Validation loss: 1.9438256089405348

Epoch: 6| Step: 12
Training loss: 1.5393999814987183
Validation loss: 1.9516939193971696

Epoch: 6| Step: 13
Training loss: 2.724132776260376
Validation loss: 1.9611566964016165

Epoch: 140| Step: 0
Training loss: 1.7889504432678223
Validation loss: 1.9551120470928889

Epoch: 6| Step: 1
Training loss: 2.205414295196533
Validation loss: 1.9524617374584239

Epoch: 6| Step: 2
Training loss: 1.8745955228805542
Validation loss: 1.9804826218594787

Epoch: 6| Step: 3
Training loss: 1.4744319915771484
Validation loss: 2.0465466835165538

Epoch: 6| Step: 4
Training loss: 1.6555308103561401
Validation loss: 2.1099930450480473

Epoch: 6| Step: 5
Training loss: 1.552067518234253
Validation loss: 2.1681962936155257

Epoch: 6| Step: 6
Training loss: 1.692204236984253
Validation loss: 2.154200969203826

Epoch: 6| Step: 7
Training loss: 1.1239855289459229
Validation loss: 2.152132611120901

Epoch: 6| Step: 8
Training loss: 1.4706213474273682
Validation loss: 2.0828880007548998

Epoch: 6| Step: 9
Training loss: 1.3598241806030273
Validation loss: 1.996010875189176

Epoch: 6| Step: 10
Training loss: 1.657677173614502
Validation loss: 1.9407123340073453

Epoch: 6| Step: 11
Training loss: 0.8531713485717773
Validation loss: 1.947971555494493

Epoch: 6| Step: 12
Training loss: 1.5367937088012695
Validation loss: 1.9442749266983361

Epoch: 6| Step: 13
Training loss: 1.803884744644165
Validation loss: 1.9826531666581348

Epoch: 141| Step: 0
Training loss: 1.2781635522842407
Validation loss: 1.9708360061850598

Epoch: 6| Step: 1
Training loss: 1.6154277324676514
Validation loss: 2.0087121519991147

Epoch: 6| Step: 2
Training loss: 1.5877666473388672
Validation loss: 2.055108993284164

Epoch: 6| Step: 3
Training loss: 1.7175447940826416
Validation loss: 2.0685144368038384

Epoch: 6| Step: 4
Training loss: 2.0108981132507324
Validation loss: 2.0804109688728087

Epoch: 6| Step: 5
Training loss: 1.2872382402420044
Validation loss: 2.0523865889477473

Epoch: 6| Step: 6
Training loss: 0.9848401546478271
Validation loss: 2.0390508238987257

Epoch: 6| Step: 7
Training loss: 1.5850900411605835
Validation loss: 1.9955195547432028

Epoch: 6| Step: 8
Training loss: 1.7735347747802734
Validation loss: 1.9800102915815128

Epoch: 6| Step: 9
Training loss: 1.5725387334823608
Validation loss: 1.9718874423734603

Epoch: 6| Step: 10
Training loss: 1.3688702583312988
Validation loss: 1.963866349189512

Epoch: 6| Step: 11
Training loss: 0.9577881097793579
Validation loss: 2.0126482363670104

Epoch: 6| Step: 12
Training loss: 1.902249813079834
Validation loss: 2.0627663981529976

Epoch: 6| Step: 13
Training loss: 2.334714651107788
Validation loss: 2.0937422654962026

Epoch: 142| Step: 0
Training loss: 1.3707640171051025
Validation loss: 2.0738070600776264

Epoch: 6| Step: 1
Training loss: 1.3879823684692383
Validation loss: 2.0800312052490892

Epoch: 6| Step: 2
Training loss: 1.4200018644332886
Validation loss: 2.087576708486003

Epoch: 6| Step: 3
Training loss: 1.597664713859558
Validation loss: 2.0768228512938305

Epoch: 6| Step: 4
Training loss: 1.51216459274292
Validation loss: 2.0441073538154684

Epoch: 6| Step: 5
Training loss: 1.4883902072906494
Validation loss: 2.004569879142187

Epoch: 6| Step: 6
Training loss: 1.4772298336029053
Validation loss: 1.9657356841589815

Epoch: 6| Step: 7
Training loss: 1.4387083053588867
Validation loss: 1.9700872077736804

Epoch: 6| Step: 8
Training loss: 1.0693612098693848
Validation loss: 2.0217863744305027

Epoch: 6| Step: 9
Training loss: 2.0087389945983887
Validation loss: 2.0531328916549683

Epoch: 6| Step: 10
Training loss: 1.5231329202651978
Validation loss: 2.103344996770223

Epoch: 6| Step: 11
Training loss: 1.834840178489685
Validation loss: 2.1126579674341346

Epoch: 6| Step: 12
Training loss: 1.3153120279312134
Validation loss: 2.075106946370935

Epoch: 6| Step: 13
Training loss: 1.6679542064666748
Validation loss: 2.013305838390063

Epoch: 143| Step: 0
Training loss: 1.2980060577392578
Validation loss: 1.9632744750668925

Epoch: 6| Step: 1
Training loss: 1.6278762817382812
Validation loss: 1.927127965034977

Epoch: 6| Step: 2
Training loss: 1.998793363571167
Validation loss: 1.916514968359342

Epoch: 6| Step: 3
Training loss: 1.5153130292892456
Validation loss: 1.942132778065179

Epoch: 6| Step: 4
Training loss: 1.8073704242706299
Validation loss: 1.996116763801985

Epoch: 6| Step: 5
Training loss: 1.2170765399932861
Validation loss: 1.9769135329031176

Epoch: 6| Step: 6
Training loss: 0.961009681224823
Validation loss: 1.9751008120916222

Epoch: 6| Step: 7
Training loss: 1.6190497875213623
Validation loss: 1.9556802049759896

Epoch: 6| Step: 8
Training loss: 1.4946051836013794
Validation loss: 1.9843051202835575

Epoch: 6| Step: 9
Training loss: 1.5988023281097412
Validation loss: 2.0151294431378766

Epoch: 6| Step: 10
Training loss: 0.8987325429916382
Validation loss: 2.0458072539298766

Epoch: 6| Step: 11
Training loss: 1.9770972728729248
Validation loss: 2.0301469269619195

Epoch: 6| Step: 12
Training loss: 1.3937442302703857
Validation loss: 2.0612285906268704

Epoch: 6| Step: 13
Training loss: 1.4677151441574097
Validation loss: 2.090452946642394

Epoch: 144| Step: 0
Training loss: 1.4252139329910278
Validation loss: 2.0801557828021306

Epoch: 6| Step: 1
Training loss: 1.5237987041473389
Validation loss: 2.1017711495840423

Epoch: 6| Step: 2
Training loss: 1.6767959594726562
Validation loss: 2.101717023439305

Epoch: 6| Step: 3
Training loss: 2.037921667098999
Validation loss: 2.0556491869752125

Epoch: 6| Step: 4
Training loss: 1.7562369108200073
Validation loss: 2.0386659150482505

Epoch: 6| Step: 5
Training loss: 1.230117917060852
Validation loss: 2.025612190205564

Epoch: 6| Step: 6
Training loss: 1.0998412370681763
Validation loss: 2.0233006400446736

Epoch: 6| Step: 7
Training loss: 1.2868138551712036
Validation loss: 1.9954311540049892

Epoch: 6| Step: 8
Training loss: 1.3295319080352783
Validation loss: 1.9562360599476805

Epoch: 6| Step: 9
Training loss: 1.6065282821655273
Validation loss: 1.9194759527842205

Epoch: 6| Step: 10
Training loss: 1.3965890407562256
Validation loss: 1.91858430575299

Epoch: 6| Step: 11
Training loss: 0.8915161490440369
Validation loss: 1.9350729539830198

Epoch: 6| Step: 12
Training loss: 1.8884351253509521
Validation loss: 1.9702434232158046

Epoch: 6| Step: 13
Training loss: 1.4005608558654785
Validation loss: 2.0382758135436685

Epoch: 145| Step: 0
Training loss: 2.2707371711730957
Validation loss: 2.086463806449726

Epoch: 6| Step: 1
Training loss: 1.1777656078338623
Validation loss: 2.0934284271732455

Epoch: 6| Step: 2
Training loss: 1.7436784505844116
Validation loss: 2.108743788093649

Epoch: 6| Step: 3
Training loss: 0.6492230892181396
Validation loss: 2.0422802330345236

Epoch: 6| Step: 4
Training loss: 0.9485874176025391
Validation loss: 2.0156360826184674

Epoch: 6| Step: 5
Training loss: 1.7997376918792725
Validation loss: 2.019571735012916

Epoch: 6| Step: 6
Training loss: 1.5382452011108398
Validation loss: 2.007776506485478

Epoch: 6| Step: 7
Training loss: 2.3466663360595703
Validation loss: 2.007542108976713

Epoch: 6| Step: 8
Training loss: 1.5886473655700684
Validation loss: 2.0094945353846394

Epoch: 6| Step: 9
Training loss: 1.1688809394836426
Validation loss: 2.032990695327841

Epoch: 6| Step: 10
Training loss: 1.2407891750335693
Validation loss: 2.068561141208936

Epoch: 6| Step: 11
Training loss: 1.8833203315734863
Validation loss: 2.0767423196505477

Epoch: 6| Step: 12
Training loss: 1.1793205738067627
Validation loss: 2.1072421073913574

Epoch: 6| Step: 13
Training loss: 1.2432267665863037
Validation loss: 2.100218930552083

Epoch: 146| Step: 0
Training loss: 0.9037091732025146
Validation loss: 2.130914290746053

Epoch: 6| Step: 1
Training loss: 1.6474006175994873
Validation loss: 2.1540149411847516

Epoch: 6| Step: 2
Training loss: 1.0631752014160156
Validation loss: 2.076841369751961

Epoch: 6| Step: 3
Training loss: 1.3740795850753784
Validation loss: 2.034209143730902

Epoch: 6| Step: 4
Training loss: 1.803775668144226
Validation loss: 2.030452766726094

Epoch: 6| Step: 5
Training loss: 1.708493709564209
Validation loss: 1.9462479481133081

Epoch: 6| Step: 6
Training loss: 1.4812994003295898
Validation loss: 1.8889573261302004

Epoch: 6| Step: 7
Training loss: 0.8924875259399414
Validation loss: 1.8618205542205482

Epoch: 6| Step: 8
Training loss: 1.305108904838562
Validation loss: 1.852222470827

Epoch: 6| Step: 9
Training loss: 1.9783927202224731
Validation loss: 1.8569108234938754

Epoch: 6| Step: 10
Training loss: 1.481294870376587
Validation loss: 1.8696250223344373

Epoch: 6| Step: 11
Training loss: 1.1889421939849854
Validation loss: 1.914294917096374

Epoch: 6| Step: 12
Training loss: 1.6679842472076416
Validation loss: 1.968306964443576

Epoch: 6| Step: 13
Training loss: 1.8869976997375488
Validation loss: 2.0232930670502367

Epoch: 147| Step: 0
Training loss: 1.3871514797210693
Validation loss: 2.0988811831320486

Epoch: 6| Step: 1
Training loss: 1.5159640312194824
Validation loss: 2.158170438581897

Epoch: 6| Step: 2
Training loss: 1.5209624767303467
Validation loss: 2.226181399437689

Epoch: 6| Step: 3
Training loss: 1.1859776973724365
Validation loss: 2.239531655465403

Epoch: 6| Step: 4
Training loss: 1.585635781288147
Validation loss: 2.198269351836174

Epoch: 6| Step: 5
Training loss: 2.014047622680664
Validation loss: 2.115157097898504

Epoch: 6| Step: 6
Training loss: 1.1404223442077637
Validation loss: 1.9504825709968485

Epoch: 6| Step: 7
Training loss: 1.5522505044937134
Validation loss: 1.8760651670476443

Epoch: 6| Step: 8
Training loss: 1.4439013004302979
Validation loss: 1.8470191801747968

Epoch: 6| Step: 9
Training loss: 1.2022156715393066
Validation loss: 1.8177241304869294

Epoch: 6| Step: 10
Training loss: 1.5686821937561035
Validation loss: 1.830350575908538

Epoch: 6| Step: 11
Training loss: 1.1492478847503662
Validation loss: 1.809882366529075

Epoch: 6| Step: 12
Training loss: 1.3359973430633545
Validation loss: 1.8254607223695325

Epoch: 6| Step: 13
Training loss: 1.6323004961013794
Validation loss: 1.849801254528825

Epoch: 148| Step: 0
Training loss: 2.0611252784729004
Validation loss: 1.8924088067905878

Epoch: 6| Step: 1
Training loss: 0.777854323387146
Validation loss: 1.8998621740648824

Epoch: 6| Step: 2
Training loss: 1.31160569190979
Validation loss: 1.933270554388723

Epoch: 6| Step: 3
Training loss: 1.5264508724212646
Validation loss: 1.948196498296594

Epoch: 6| Step: 4
Training loss: 1.3633146286010742
Validation loss: 1.9299772401009836

Epoch: 6| Step: 5
Training loss: 0.9606557488441467
Validation loss: 1.9456792249474475

Epoch: 6| Step: 6
Training loss: 1.8700025081634521
Validation loss: 1.9704569719171012

Epoch: 6| Step: 7
Training loss: 1.6908133029937744
Validation loss: 1.971893427192524

Epoch: 6| Step: 8
Training loss: 0.9523668885231018
Validation loss: 1.9734354890802854

Epoch: 6| Step: 9
Training loss: 1.1771236658096313
Validation loss: 1.9649008807315622

Epoch: 6| Step: 10
Training loss: 1.3702547550201416
Validation loss: 1.9470061896949686

Epoch: 6| Step: 11
Training loss: 1.5246694087982178
Validation loss: 1.9367446027776247

Epoch: 6| Step: 12
Training loss: 1.2975839376449585
Validation loss: 1.9638404410372499

Epoch: 6| Step: 13
Training loss: 1.4348490238189697
Validation loss: 2.0027658426633446

Epoch: 149| Step: 0
Training loss: 1.6014362573623657
Validation loss: 2.043045623328096

Epoch: 6| Step: 1
Training loss: 1.1078557968139648
Validation loss: 2.036472548720657

Epoch: 6| Step: 2
Training loss: 1.3654539585113525
Validation loss: 2.0501902423879153

Epoch: 6| Step: 3
Training loss: 1.3237041234970093
Validation loss: 2.080132347281261

Epoch: 6| Step: 4
Training loss: 0.9826256036758423
Validation loss: 2.064439647941179

Epoch: 6| Step: 5
Training loss: 1.3582037687301636
Validation loss: 2.0426752426291026

Epoch: 6| Step: 6
Training loss: 2.02357816696167
Validation loss: 2.0442574767656225

Epoch: 6| Step: 7
Training loss: 0.9084203243255615
Validation loss: 2.01659050808158

Epoch: 6| Step: 8
Training loss: 2.081488609313965
Validation loss: 1.975600992479632

Epoch: 6| Step: 9
Training loss: 0.8402934670448303
Validation loss: 1.981528382147512

Epoch: 6| Step: 10
Training loss: 1.5170811414718628
Validation loss: 1.9554625083041448

Epoch: 6| Step: 11
Training loss: 1.2051020860671997
Validation loss: 1.9651977118625437

Epoch: 6| Step: 12
Training loss: 1.369708776473999
Validation loss: 1.9624472382248088

Epoch: 6| Step: 13
Training loss: 1.4684619903564453
Validation loss: 1.9624540472543368

Epoch: 150| Step: 0
Training loss: 1.4715579748153687
Validation loss: 1.9694782636498893

Epoch: 6| Step: 1
Training loss: 1.8588941097259521
Validation loss: 1.9644251254297072

Epoch: 6| Step: 2
Training loss: 1.0916166305541992
Validation loss: 1.9297168652216594

Epoch: 6| Step: 3
Training loss: 1.4107950925827026
Validation loss: 1.9801291765705231

Epoch: 6| Step: 4
Training loss: 1.50376296043396
Validation loss: 2.0095045438376804

Epoch: 6| Step: 5
Training loss: 1.1364399194717407
Validation loss: 1.9478372489252398

Epoch: 6| Step: 6
Training loss: 1.3692197799682617
Validation loss: 1.9414819145715365

Epoch: 6| Step: 7
Training loss: 1.2473773956298828
Validation loss: 1.9405656424901818

Epoch: 6| Step: 8
Training loss: 1.3624480962753296
Validation loss: 1.9376972580468783

Epoch: 6| Step: 9
Training loss: 1.5058192014694214
Validation loss: 1.9402594835527482

Epoch: 6| Step: 10
Training loss: 1.1816513538360596
Validation loss: 1.925477691875991

Epoch: 6| Step: 11
Training loss: 1.1318366527557373
Validation loss: 1.9665824495336062

Epoch: 6| Step: 12
Training loss: 1.2356934547424316
Validation loss: 2.0228827627756263

Epoch: 6| Step: 13
Training loss: 1.1446598768234253
Validation loss: 2.096369807438184

Epoch: 151| Step: 0
Training loss: 1.6369847059249878
Validation loss: 2.1879613681506087

Epoch: 6| Step: 1
Training loss: 1.2603323459625244
Validation loss: 2.18092744581161

Epoch: 6| Step: 2
Training loss: 2.0330047607421875
Validation loss: 2.1523717193193335

Epoch: 6| Step: 3
Training loss: 1.2646254301071167
Validation loss: 2.0956560296397053

Epoch: 6| Step: 4
Training loss: 1.11615788936615
Validation loss: 2.0044102873853458

Epoch: 6| Step: 5
Training loss: 0.821026623249054
Validation loss: 1.9289335255981774

Epoch: 6| Step: 6
Training loss: 1.003169059753418
Validation loss: 1.8873898495909989

Epoch: 6| Step: 7
Training loss: 1.2466483116149902
Validation loss: 1.855994532185216

Epoch: 6| Step: 8
Training loss: 1.0703990459442139
Validation loss: 1.8393763233256597

Epoch: 6| Step: 9
Training loss: 1.4595081806182861
Validation loss: 1.82850214358299

Epoch: 6| Step: 10
Training loss: 1.8376796245574951
Validation loss: 1.8381578332634383

Epoch: 6| Step: 11
Training loss: 1.5828783512115479
Validation loss: 1.840779217340613

Epoch: 6| Step: 12
Training loss: 1.2499780654907227
Validation loss: 1.859546866468204

Epoch: 6| Step: 13
Training loss: 0.6997767090797424
Validation loss: 1.877519533198367

Epoch: 152| Step: 0
Training loss: 0.6140028834342957
Validation loss: 1.9062740854037705

Epoch: 6| Step: 1
Training loss: 1.3439772129058838
Validation loss: 2.017325924288842

Epoch: 6| Step: 2
Training loss: 1.7290855646133423
Validation loss: 2.0582481968787407

Epoch: 6| Step: 3
Training loss: 1.5634804964065552
Validation loss: 2.06342649972567

Epoch: 6| Step: 4
Training loss: 1.521374225616455
Validation loss: 2.011915919601276

Epoch: 6| Step: 5
Training loss: 1.2779794931411743
Validation loss: 1.9956393126518495

Epoch: 6| Step: 6
Training loss: 1.1952160596847534
Validation loss: 1.9385626034070087

Epoch: 6| Step: 7
Training loss: 1.418152928352356
Validation loss: 1.951109355495822

Epoch: 6| Step: 8
Training loss: 1.5326411724090576
Validation loss: 1.967745493817073

Epoch: 6| Step: 9
Training loss: 1.3853377103805542
Validation loss: 1.9370042585557508

Epoch: 6| Step: 10
Training loss: 1.1781086921691895
Validation loss: 1.9501411607188563

Epoch: 6| Step: 11
Training loss: 1.3733857870101929
Validation loss: 1.9715653875822663

Epoch: 6| Step: 12
Training loss: 1.5842807292938232
Validation loss: 1.9891369086439892

Epoch: 6| Step: 13
Training loss: 0.8678311705589294
Validation loss: 2.0234608342570644

Epoch: 153| Step: 0
Training loss: 1.846215844154358
Validation loss: 1.9963062219722296

Epoch: 6| Step: 1
Training loss: 1.3392610549926758
Validation loss: 1.9935472819112963

Epoch: 6| Step: 2
Training loss: 1.6669026613235474
Validation loss: 2.0359513708340224

Epoch: 6| Step: 3
Training loss: 0.8240731954574585
Validation loss: 2.0507331535380375

Epoch: 6| Step: 4
Training loss: 1.0949854850769043
Validation loss: 2.111325628014021

Epoch: 6| Step: 5
Training loss: 0.8947239518165588
Validation loss: 2.083102649258029

Epoch: 6| Step: 6
Training loss: 1.9138340950012207
Validation loss: 2.0337750065711235

Epoch: 6| Step: 7
Training loss: 1.3277201652526855
Validation loss: 2.0358625535042054

Epoch: 6| Step: 8
Training loss: 1.6147575378417969
Validation loss: 1.9860484779521983

Epoch: 6| Step: 9
Training loss: 1.1626636981964111
Validation loss: 1.9592422746842908

Epoch: 6| Step: 10
Training loss: 0.7069555521011353
Validation loss: 1.8984262981722433

Epoch: 6| Step: 11
Training loss: 1.2468583583831787
Validation loss: 1.8805276450290476

Epoch: 6| Step: 12
Training loss: 0.7932553887367249
Validation loss: 1.8687103179193312

Epoch: 6| Step: 13
Training loss: 1.2342791557312012
Validation loss: 1.8669313858914118

Epoch: 154| Step: 0
Training loss: 1.7159944772720337
Validation loss: 1.8730142321637882

Epoch: 6| Step: 1
Training loss: 1.2404968738555908
Validation loss: 1.8972001357745099

Epoch: 6| Step: 2
Training loss: 1.2879009246826172
Validation loss: 1.9050873248807845

Epoch: 6| Step: 3
Training loss: 0.8060466051101685
Validation loss: 1.9005565604855936

Epoch: 6| Step: 4
Training loss: 1.1780476570129395
Validation loss: 1.9360921690540929

Epoch: 6| Step: 5
Training loss: 1.3375229835510254
Validation loss: 1.9656947069270636

Epoch: 6| Step: 6
Training loss: 0.5764857530593872
Validation loss: 1.9063359486159457

Epoch: 6| Step: 7
Training loss: 1.7691113948822021
Validation loss: 1.8989428961148827

Epoch: 6| Step: 8
Training loss: 1.136070728302002
Validation loss: 1.9283194541931152

Epoch: 6| Step: 9
Training loss: 1.139950156211853
Validation loss: 1.971375749957177

Epoch: 6| Step: 10
Training loss: 1.9313299655914307
Validation loss: 1.9898448016053887

Epoch: 6| Step: 11
Training loss: 1.1505801677703857
Validation loss: 2.0115090390687347

Epoch: 6| Step: 12
Training loss: 1.1281049251556396
Validation loss: 2.0204249184618712

Epoch: 6| Step: 13
Training loss: 1.2907719612121582
Validation loss: 2.00985489865785

Epoch: 155| Step: 0
Training loss: 0.9627959132194519
Validation loss: 1.99577965915844

Epoch: 6| Step: 1
Training loss: 1.3634262084960938
Validation loss: 1.9542091174792218

Epoch: 6| Step: 2
Training loss: 1.1503969430923462
Validation loss: 1.9354067387119416

Epoch: 6| Step: 3
Training loss: 1.124895691871643
Validation loss: 1.901846711353589

Epoch: 6| Step: 4
Training loss: 0.846200704574585
Validation loss: 1.891443432018321

Epoch: 6| Step: 5
Training loss: 1.27886164188385
Validation loss: 1.891786330489702

Epoch: 6| Step: 6
Training loss: 1.1879172325134277
Validation loss: 1.8998451220091952

Epoch: 6| Step: 7
Training loss: 1.7482960224151611
Validation loss: 1.9161193217000654

Epoch: 6| Step: 8
Training loss: 1.2075021266937256
Validation loss: 1.908894814470763

Epoch: 6| Step: 9
Training loss: 1.1371591091156006
Validation loss: 1.9339630821699738

Epoch: 6| Step: 10
Training loss: 1.0580439567565918
Validation loss: 1.9419096849297965

Epoch: 6| Step: 11
Training loss: 1.3062384128570557
Validation loss: 1.9865664474425777

Epoch: 6| Step: 12
Training loss: 1.5971554517745972
Validation loss: 1.996512020787885

Epoch: 6| Step: 13
Training loss: 1.677688479423523
Validation loss: 1.9504851666829919

Epoch: 156| Step: 0
Training loss: 1.681188941001892
Validation loss: 1.893249806537423

Epoch: 6| Step: 1
Training loss: 0.9055566787719727
Validation loss: 1.8733455673340829

Epoch: 6| Step: 2
Training loss: 1.1667449474334717
Validation loss: 1.866510251516937

Epoch: 6| Step: 3
Training loss: 1.1447758674621582
Validation loss: 1.886394041840748

Epoch: 6| Step: 4
Training loss: 1.8277878761291504
Validation loss: 1.8814248974605272

Epoch: 6| Step: 5
Training loss: 0.729445219039917
Validation loss: 1.8719209419783724

Epoch: 6| Step: 6
Training loss: 1.4343805313110352
Validation loss: 1.8895940485820975

Epoch: 6| Step: 7
Training loss: 0.7030482888221741
Validation loss: 1.9007108365335772

Epoch: 6| Step: 8
Training loss: 1.1485000848770142
Validation loss: 1.9401502968162618

Epoch: 6| Step: 9
Training loss: 0.9768757820129395
Validation loss: 1.941756502274544

Epoch: 6| Step: 10
Training loss: 1.2969427108764648
Validation loss: 1.9848397495926067

Epoch: 6| Step: 11
Training loss: 1.722927212715149
Validation loss: 1.999016236233455

Epoch: 6| Step: 12
Training loss: 0.7914775609970093
Validation loss: 2.0369404669730895

Epoch: 6| Step: 13
Training loss: 1.204390287399292
Validation loss: 2.0557282996434036

Epoch: 157| Step: 0
Training loss: 1.2824764251708984
Validation loss: 2.0379747498419976

Epoch: 6| Step: 1
Training loss: 0.9681806564331055
Validation loss: 1.9774282299062258

Epoch: 6| Step: 2
Training loss: 1.1060377359390259
Validation loss: 1.9652162162206506

Epoch: 6| Step: 3
Training loss: 1.1081128120422363
Validation loss: 1.939160264948363

Epoch: 6| Step: 4
Training loss: 0.8556385636329651
Validation loss: 1.9070564367437874

Epoch: 6| Step: 5
Training loss: 1.200420618057251
Validation loss: 1.8916939984085739

Epoch: 6| Step: 6
Training loss: 1.2687993049621582
Validation loss: 1.9012522082174979

Epoch: 6| Step: 7
Training loss: 0.9722946882247925
Validation loss: 1.8832481984169251

Epoch: 6| Step: 8
Training loss: 0.8661748170852661
Validation loss: 1.9218660605851041

Epoch: 6| Step: 9
Training loss: 1.4699000120162964
Validation loss: 1.9681815870346562

Epoch: 6| Step: 10
Training loss: 1.1232984066009521
Validation loss: 1.9884009309994277

Epoch: 6| Step: 11
Training loss: 1.1127357482910156
Validation loss: 2.0434246345232894

Epoch: 6| Step: 12
Training loss: 1.3305671215057373
Validation loss: 2.017322923547478

Epoch: 6| Step: 13
Training loss: 1.8962682485580444
Validation loss: 2.0177692315911733

Epoch: 158| Step: 0
Training loss: 1.486020803451538
Validation loss: 1.944588183074869

Epoch: 6| Step: 1
Training loss: 1.1762235164642334
Validation loss: 1.9149646169395858

Epoch: 6| Step: 2
Training loss: 1.556749939918518
Validation loss: 1.8661235788817048

Epoch: 6| Step: 3
Training loss: 0.9782523512840271
Validation loss: 1.827453515862906

Epoch: 6| Step: 4
Training loss: 1.0385655164718628
Validation loss: 1.8080580977983371

Epoch: 6| Step: 5
Training loss: 1.090346097946167
Validation loss: 1.8133253384661931

Epoch: 6| Step: 6
Training loss: 1.5442479848861694
Validation loss: 1.8288332646892917

Epoch: 6| Step: 7
Training loss: 1.1465864181518555
Validation loss: 1.8474783153944119

Epoch: 6| Step: 8
Training loss: 1.252944827079773
Validation loss: 1.8715357601001699

Epoch: 6| Step: 9
Training loss: 1.418181300163269
Validation loss: 1.9589454935443016

Epoch: 6| Step: 10
Training loss: 1.2600672245025635
Validation loss: 1.9995485403204476

Epoch: 6| Step: 11
Training loss: 0.7497921586036682
Validation loss: 2.021847589041597

Epoch: 6| Step: 12
Training loss: 0.6674795746803284
Validation loss: 2.058404778921476

Epoch: 6| Step: 13
Training loss: 1.6814773082733154
Validation loss: 2.039679019681869

Epoch: 159| Step: 0
Training loss: 1.1704530715942383
Validation loss: 2.027772202286669

Epoch: 6| Step: 1
Training loss: 0.6060935258865356
Validation loss: 1.9869768388809697

Epoch: 6| Step: 2
Training loss: 0.8506642580032349
Validation loss: 1.920894948385095

Epoch: 6| Step: 3
Training loss: 1.09794020652771
Validation loss: 1.8782550673330984

Epoch: 6| Step: 4
Training loss: 0.677864134311676
Validation loss: 1.853877482875701

Epoch: 6| Step: 5
Training loss: 1.1683447360992432
Validation loss: 1.8408779380142049

Epoch: 6| Step: 6
Training loss: 0.9979056715965271
Validation loss: 1.788871208826701

Epoch: 6| Step: 7
Training loss: 1.3537428379058838
Validation loss: 1.7930034270850561

Epoch: 6| Step: 8
Training loss: 1.2036255598068237
Validation loss: 1.811367606603971

Epoch: 6| Step: 9
Training loss: 1.4907945394515991
Validation loss: 1.822281583662956

Epoch: 6| Step: 10
Training loss: 1.1188710927963257
Validation loss: 1.8401307905873945

Epoch: 6| Step: 11
Training loss: 1.382494330406189
Validation loss: 1.890390690936837

Epoch: 6| Step: 12
Training loss: 1.4451428651809692
Validation loss: 1.902633649046703

Epoch: 6| Step: 13
Training loss: 1.3705687522888184
Validation loss: 1.8884393643307429

Epoch: 160| Step: 0
Training loss: 1.605360507965088
Validation loss: 1.94691070946314

Epoch: 6| Step: 1
Training loss: 0.9423941373825073
Validation loss: 1.9363308516881799

Epoch: 6| Step: 2
Training loss: 0.8875213861465454
Validation loss: 1.9354986734287714

Epoch: 6| Step: 3
Training loss: 1.6015150547027588
Validation loss: 1.9024320379380257

Epoch: 6| Step: 4
Training loss: 0.6089246869087219
Validation loss: 1.908145905822836

Epoch: 6| Step: 5
Training loss: 1.3675833940505981
Validation loss: 1.8567237725821875

Epoch: 6| Step: 6
Training loss: 0.7394495606422424
Validation loss: 1.814042209297098

Epoch: 6| Step: 7
Training loss: 1.3328149318695068
Validation loss: 1.8218537005045081

Epoch: 6| Step: 8
Training loss: 1.0440073013305664
Validation loss: 1.7826374282119095

Epoch: 6| Step: 9
Training loss: 1.1822500228881836
Validation loss: 1.8098391999480545

Epoch: 6| Step: 10
Training loss: 1.265103816986084
Validation loss: 1.866741341929282

Epoch: 6| Step: 11
Training loss: 0.8541804552078247
Validation loss: 1.8874326662350727

Epoch: 6| Step: 12
Training loss: 0.8734827041625977
Validation loss: 1.9278735678683045

Epoch: 6| Step: 13
Training loss: 1.4529979228973389
Validation loss: 1.9473926623662312

Epoch: 161| Step: 0
Training loss: 1.1634976863861084
Validation loss: 1.98262607923118

Epoch: 6| Step: 1
Training loss: 0.6927908658981323
Validation loss: 2.016570302747911

Epoch: 6| Step: 2
Training loss: 1.1179144382476807
Validation loss: 2.0173504044932704

Epoch: 6| Step: 3
Training loss: 1.1692836284637451
Validation loss: 1.9986018519247732

Epoch: 6| Step: 4
Training loss: 1.3664836883544922
Validation loss: 1.9888801523434219

Epoch: 6| Step: 5
Training loss: 0.8248616456985474
Validation loss: 1.9725072153152958

Epoch: 6| Step: 6
Training loss: 1.062195062637329
Validation loss: 2.028143326441447

Epoch: 6| Step: 7
Training loss: 1.0624773502349854
Validation loss: 2.021762627427296

Epoch: 6| Step: 8
Training loss: 1.3979921340942383
Validation loss: 2.040184836233816

Epoch: 6| Step: 9
Training loss: 1.4011940956115723
Validation loss: 2.016764974081388

Epoch: 6| Step: 10
Training loss: 1.2626646757125854
Validation loss: 1.9593708502349032

Epoch: 6| Step: 11
Training loss: 0.978090226650238
Validation loss: 1.9306145380902033

Epoch: 6| Step: 12
Training loss: 1.6080777645111084
Validation loss: 1.914921965650333

Epoch: 6| Step: 13
Training loss: 0.8393635749816895
Validation loss: 1.8809549987957042

Epoch: 162| Step: 0
Training loss: 1.093863606452942
Validation loss: 1.8325922591711885

Epoch: 6| Step: 1
Training loss: 1.0061681270599365
Validation loss: 1.8168770318390222

Epoch: 6| Step: 2
Training loss: 1.7156922817230225
Validation loss: 1.8168386361932243

Epoch: 6| Step: 3
Training loss: 1.0330132246017456
Validation loss: 1.8579906904569237

Epoch: 6| Step: 4
Training loss: 0.9992532134056091
Validation loss: 1.8388004226069297

Epoch: 6| Step: 5
Training loss: 1.0518436431884766
Validation loss: 1.912167702951739

Epoch: 6| Step: 6
Training loss: 0.9311801195144653
Validation loss: 1.9068060844175276

Epoch: 6| Step: 7
Training loss: 1.3726965188980103
Validation loss: 2.0062334652869933

Epoch: 6| Step: 8
Training loss: 1.061580777168274
Validation loss: 2.0413469960612636

Epoch: 6| Step: 9
Training loss: 1.5472650527954102
Validation loss: 2.0445597287147277

Epoch: 6| Step: 10
Training loss: 1.2771589756011963
Validation loss: 2.0420509615252094

Epoch: 6| Step: 11
Training loss: 0.8810835480690002
Validation loss: 2.0145637681407313

Epoch: 6| Step: 12
Training loss: 0.9058449268341064
Validation loss: 2.0421963635311333

Epoch: 6| Step: 13
Training loss: 0.8661153316497803
Validation loss: 2.0358537525259037

Epoch: 163| Step: 0
Training loss: 1.3866957426071167
Validation loss: 2.0229606961691253

Epoch: 6| Step: 1
Training loss: 1.2503459453582764
Validation loss: 2.0387853883927867

Epoch: 6| Step: 2
Training loss: 1.1046926975250244
Validation loss: 2.044909636179606

Epoch: 6| Step: 3
Training loss: 1.2739496231079102
Validation loss: 2.012842526999853

Epoch: 6| Step: 4
Training loss: 0.9253072738647461
Validation loss: 1.9457681281592256

Epoch: 6| Step: 5
Training loss: 1.257354736328125
Validation loss: 1.8985957830182967

Epoch: 6| Step: 6
Training loss: 1.0997512340545654
Validation loss: 1.8761026397828133

Epoch: 6| Step: 7
Training loss: 1.0540997982025146
Validation loss: 1.8265424364356584

Epoch: 6| Step: 8
Training loss: 0.9187192916870117
Validation loss: 1.8180775834668068

Epoch: 6| Step: 9
Training loss: 1.186080813407898
Validation loss: 1.8393721849687639

Epoch: 6| Step: 10
Training loss: 0.8687784671783447
Validation loss: 1.846505634246334

Epoch: 6| Step: 11
Training loss: 0.9528286457061768
Validation loss: 1.8023883527325046

Epoch: 6| Step: 12
Training loss: 1.5270195007324219
Validation loss: 1.822641844390541

Epoch: 6| Step: 13
Training loss: 0.7009286880493164
Validation loss: 1.8199087009635022

Epoch: 164| Step: 0
Training loss: 0.7712775468826294
Validation loss: 1.8231392496375627

Epoch: 6| Step: 1
Training loss: 1.2126692533493042
Validation loss: 1.8213148091429023

Epoch: 6| Step: 2
Training loss: 0.8911102414131165
Validation loss: 1.8652412737569501

Epoch: 6| Step: 3
Training loss: 1.259906530380249
Validation loss: 1.8979757703760618

Epoch: 6| Step: 4
Training loss: 0.8438742160797119
Validation loss: 1.9273149198101414

Epoch: 6| Step: 5
Training loss: 1.0259156227111816
Validation loss: 1.9122834820901193

Epoch: 6| Step: 6
Training loss: 0.9081701636314392
Validation loss: 1.8922241310919485

Epoch: 6| Step: 7
Training loss: 1.356536626815796
Validation loss: 1.9165768200351345

Epoch: 6| Step: 8
Training loss: 1.0545620918273926
Validation loss: 1.8498461182399462

Epoch: 6| Step: 9
Training loss: 1.3511955738067627
Validation loss: 1.8095344817766579

Epoch: 6| Step: 10
Training loss: 1.081471562385559
Validation loss: 1.7732390806239138

Epoch: 6| Step: 11
Training loss: 1.0674914121627808
Validation loss: 1.7566450565092024

Epoch: 6| Step: 12
Training loss: 1.3888428211212158
Validation loss: 1.7216132315256263

Epoch: 6| Step: 13
Training loss: 0.8426815867424011
Validation loss: 1.7583859735919583

Epoch: 165| Step: 0
Training loss: 0.6401674747467041
Validation loss: 1.7763285624083651

Epoch: 6| Step: 1
Training loss: 1.3384793996810913
Validation loss: 1.7768473612364901

Epoch: 6| Step: 2
Training loss: 1.1769518852233887
Validation loss: 1.8263141301370436

Epoch: 6| Step: 3
Training loss: 1.455782413482666
Validation loss: 1.8737691922854351

Epoch: 6| Step: 4
Training loss: 0.934153139591217
Validation loss: 1.8879616542529034

Epoch: 6| Step: 5
Training loss: 0.9264553189277649
Validation loss: 1.8656911106519802

Epoch: 6| Step: 6
Training loss: 1.3744096755981445
Validation loss: 1.9465787462008897

Epoch: 6| Step: 7
Training loss: 0.7781480550765991
Validation loss: 1.892056477967129

Epoch: 6| Step: 8
Training loss: 1.4558006525039673
Validation loss: 1.8831690139667963

Epoch: 6| Step: 9
Training loss: 0.8507009744644165
Validation loss: 1.8652133710922734

Epoch: 6| Step: 10
Training loss: 1.0671970844268799
Validation loss: 1.843781966035084

Epoch: 6| Step: 11
Training loss: 1.0777816772460938
Validation loss: 1.8327946303993143

Epoch: 6| Step: 12
Training loss: 1.1097465753555298
Validation loss: 1.8288254084125641

Epoch: 6| Step: 13
Training loss: 0.7660365700721741
Validation loss: 1.817639148363503

Epoch: 166| Step: 0
Training loss: 0.9803701639175415
Validation loss: 1.803858413491198

Epoch: 6| Step: 1
Training loss: 1.221325159072876
Validation loss: 1.8136784979092178

Epoch: 6| Step: 2
Training loss: 0.9049484729766846
Validation loss: 1.8368716009201542

Epoch: 6| Step: 3
Training loss: 0.732588529586792
Validation loss: 1.869106197869906

Epoch: 6| Step: 4
Training loss: 1.518932580947876
Validation loss: 1.8927105511388471

Epoch: 6| Step: 5
Training loss: 1.1928801536560059
Validation loss: 1.8733758952028008

Epoch: 6| Step: 6
Training loss: 1.3229410648345947
Validation loss: 1.842101182988895

Epoch: 6| Step: 7
Training loss: 0.7655984163284302
Validation loss: 1.7890696346118886

Epoch: 6| Step: 8
Training loss: 1.0564515590667725
Validation loss: 1.780158281326294

Epoch: 6| Step: 9
Training loss: 1.1773208379745483
Validation loss: 1.8275461735263947

Epoch: 6| Step: 10
Training loss: 1.1912866830825806
Validation loss: 1.7994312983687206

Epoch: 6| Step: 11
Training loss: 1.2669743299484253
Validation loss: 1.8111125717880905

Epoch: 6| Step: 12
Training loss: 0.8520135879516602
Validation loss: 1.782243928601665

Epoch: 6| Step: 13
Training loss: 1.1651816368103027
Validation loss: 1.824354571680869

Epoch: 167| Step: 0
Training loss: 1.228078007698059
Validation loss: 1.8182600352071947

Epoch: 6| Step: 1
Training loss: 1.0977771282196045
Validation loss: 1.839212897003338

Epoch: 6| Step: 2
Training loss: 1.2540966272354126
Validation loss: 1.8575542460205734

Epoch: 6| Step: 3
Training loss: 1.3032054901123047
Validation loss: 1.8413038330693399

Epoch: 6| Step: 4
Training loss: 1.3409329652786255
Validation loss: 1.8778834727502638

Epoch: 6| Step: 5
Training loss: 0.9917560815811157
Validation loss: 1.9109940272505566

Epoch: 6| Step: 6
Training loss: 0.7660897374153137
Validation loss: 1.9591819624747

Epoch: 6| Step: 7
Training loss: 1.099679708480835
Validation loss: 1.9649663471406507

Epoch: 6| Step: 8
Training loss: 0.7475714683532715
Validation loss: 1.9864280275119248

Epoch: 6| Step: 9
Training loss: 0.9854217767715454
Validation loss: 1.9946198719804005

Epoch: 6| Step: 10
Training loss: 1.047812581062317
Validation loss: 1.9977948370800223

Epoch: 6| Step: 11
Training loss: 0.6662050485610962
Validation loss: 1.9760339939466087

Epoch: 6| Step: 12
Training loss: 1.3693983554840088
Validation loss: 1.9037591911131335

Epoch: 6| Step: 13
Training loss: 1.3900971412658691
Validation loss: 1.8458445969448294

Epoch: 168| Step: 0
Training loss: 1.0681880712509155
Validation loss: 1.805542544652057

Epoch: 6| Step: 1
Training loss: 1.1284584999084473
Validation loss: 1.767217980918064

Epoch: 6| Step: 2
Training loss: 1.2803318500518799
Validation loss: 1.7515534970068163

Epoch: 6| Step: 3
Training loss: 0.8009091019630432
Validation loss: 1.7586553148044053

Epoch: 6| Step: 4
Training loss: 0.9679287075996399
Validation loss: 1.7849204001888153

Epoch: 6| Step: 5
Training loss: 0.7110385894775391
Validation loss: 1.8112333487438899

Epoch: 6| Step: 6
Training loss: 0.9492632150650024
Validation loss: 1.8555006006712556

Epoch: 6| Step: 7
Training loss: 1.131218671798706
Validation loss: 1.8976698678026918

Epoch: 6| Step: 8
Training loss: 0.5789649486541748
Validation loss: 1.9458862389287641

Epoch: 6| Step: 9
Training loss: 1.0477173328399658
Validation loss: 1.9570004696487098

Epoch: 6| Step: 10
Training loss: 1.3234882354736328
Validation loss: 1.9842638866875761

Epoch: 6| Step: 11
Training loss: 1.4455828666687012
Validation loss: 1.9544026428653347

Epoch: 6| Step: 12
Training loss: 0.9094635248184204
Validation loss: 1.9546602759309994

Epoch: 6| Step: 13
Training loss: 0.8936808705329895
Validation loss: 1.9455214623481996

Epoch: 169| Step: 0
Training loss: 0.9132559895515442
Validation loss: 1.9069440967293196

Epoch: 6| Step: 1
Training loss: 0.5930132269859314
Validation loss: 1.8939450915141771

Epoch: 6| Step: 2
Training loss: 1.256967306137085
Validation loss: 1.8819662960626746

Epoch: 6| Step: 3
Training loss: 1.2154624462127686
Validation loss: 1.8346585753143474

Epoch: 6| Step: 4
Training loss: 0.7435637712478638
Validation loss: 1.8015784640466013

Epoch: 6| Step: 5
Training loss: 1.238351821899414
Validation loss: 1.7708417241291334

Epoch: 6| Step: 6
Training loss: 0.9838587641716003
Validation loss: 1.782098611195882

Epoch: 6| Step: 7
Training loss: 1.0438978672027588
Validation loss: 1.774994210530353

Epoch: 6| Step: 8
Training loss: 1.0916743278503418
Validation loss: 1.786994998173047

Epoch: 6| Step: 9
Training loss: 0.9740147590637207
Validation loss: 1.7985232709556498

Epoch: 6| Step: 10
Training loss: 0.7508405447006226
Validation loss: 1.821180389773461

Epoch: 6| Step: 11
Training loss: 1.2578091621398926
Validation loss: 1.8636113341136644

Epoch: 6| Step: 12
Training loss: 0.8824527263641357
Validation loss: 1.8588475104301208

Epoch: 6| Step: 13
Training loss: 0.9472945332527161
Validation loss: 1.8238592724646292

Epoch: 170| Step: 0
Training loss: 1.380832314491272
Validation loss: 1.8004135047235796

Epoch: 6| Step: 1
Training loss: 0.7047268152236938
Validation loss: 1.7733948858835364

Epoch: 6| Step: 2
Training loss: 1.5077203512191772
Validation loss: 1.7886753210457422

Epoch: 6| Step: 3
Training loss: 0.8521069288253784
Validation loss: 1.766703183932971

Epoch: 6| Step: 4
Training loss: 1.085050344467163
Validation loss: 1.7339277908366213

Epoch: 6| Step: 5
Training loss: 1.1428585052490234
Validation loss: 1.672905493808049

Epoch: 6| Step: 6
Training loss: 1.0855294466018677
Validation loss: 1.6745220435562955

Epoch: 6| Step: 7
Training loss: 0.9432162046432495
Validation loss: 1.6412708285034343

Epoch: 6| Step: 8
Training loss: 0.5384479761123657
Validation loss: 1.6412484492025068

Epoch: 6| Step: 9
Training loss: 1.0000488758087158
Validation loss: 1.6450327493811165

Epoch: 6| Step: 10
Training loss: 0.5059041380882263
Validation loss: 1.6659756450242893

Epoch: 6| Step: 11
Training loss: 1.0294005870819092
Validation loss: 1.6949792728629163

Epoch: 6| Step: 12
Training loss: 0.9595720767974854
Validation loss: 1.7321392541290612

Epoch: 6| Step: 13
Training loss: 0.6927404999732971
Validation loss: 1.7843882499202606

Epoch: 171| Step: 0
Training loss: 1.1121883392333984
Validation loss: 1.7969239629724973

Epoch: 6| Step: 1
Training loss: 0.6229273676872253
Validation loss: 1.7964959490683772

Epoch: 6| Step: 2
Training loss: 0.9502562284469604
Validation loss: 1.805083655541943

Epoch: 6| Step: 3
Training loss: 0.9433417320251465
Validation loss: 1.8318480291674215

Epoch: 6| Step: 4
Training loss: 1.4323064088821411
Validation loss: 1.8622243724843508

Epoch: 6| Step: 5
Training loss: 1.0589734315872192
Validation loss: 1.879617747440133

Epoch: 6| Step: 6
Training loss: 0.7144744396209717
Validation loss: 1.8995314926229498

Epoch: 6| Step: 7
Training loss: 1.2720483541488647
Validation loss: 1.88648239515161

Epoch: 6| Step: 8
Training loss: 1.2253751754760742
Validation loss: 1.854781848128124

Epoch: 6| Step: 9
Training loss: 0.8431380987167358
Validation loss: 1.8583593894076604

Epoch: 6| Step: 10
Training loss: 0.608604371547699
Validation loss: 1.8043201738788235

Epoch: 6| Step: 11
Training loss: 0.7916332483291626
Validation loss: 1.807729781314891

Epoch: 6| Step: 12
Training loss: 0.6593037843704224
Validation loss: 1.7906281537907098

Epoch: 6| Step: 13
Training loss: 0.5693917870521545
Validation loss: 1.804413277615783

Epoch: 172| Step: 0
Training loss: 0.8793926239013672
Validation loss: 1.8671287054656653

Epoch: 6| Step: 1
Training loss: 1.2251594066619873
Validation loss: 1.875639448883713

Epoch: 6| Step: 2
Training loss: 0.6670017242431641
Validation loss: 1.8875718398760724

Epoch: 6| Step: 3
Training loss: 1.1270132064819336
Validation loss: 1.867529793452191

Epoch: 6| Step: 4
Training loss: 1.1986682415008545
Validation loss: 1.866313648480241

Epoch: 6| Step: 5
Training loss: 1.268967866897583
Validation loss: 1.8661726597816712

Epoch: 6| Step: 6
Training loss: 0.7596061825752258
Validation loss: 1.8350776510853921

Epoch: 6| Step: 7
Training loss: 0.6872493028640747
Validation loss: 1.8040913625430035

Epoch: 6| Step: 8
Training loss: 0.47428733110427856
Validation loss: 1.7885508550110685

Epoch: 6| Step: 9
Training loss: 0.7899131774902344
Validation loss: 1.7680853336088118

Epoch: 6| Step: 10
Training loss: 0.9532814025878906
Validation loss: 1.7948219417243876

Epoch: 6| Step: 11
Training loss: 1.1975877285003662
Validation loss: 1.753904950234198

Epoch: 6| Step: 12
Training loss: 1.0538386106491089
Validation loss: 1.743761630468471

Epoch: 6| Step: 13
Training loss: 1.0913795232772827
Validation loss: 1.7610730778786443

Epoch: 173| Step: 0
Training loss: 0.9681216478347778
Validation loss: 1.7397300915051532

Epoch: 6| Step: 1
Training loss: 0.6999489068984985
Validation loss: 1.7569500528356081

Epoch: 6| Step: 2
Training loss: 0.7945970892906189
Validation loss: 1.775436625685743

Epoch: 6| Step: 3
Training loss: 1.223254680633545
Validation loss: 1.7785917661523307

Epoch: 6| Step: 4
Training loss: 0.9260450601577759
Validation loss: 1.7788349851485221

Epoch: 6| Step: 5
Training loss: 0.8386485576629639
Validation loss: 1.7846877523647842

Epoch: 6| Step: 6
Training loss: 0.5300133228302002
Validation loss: 1.8057362379566315

Epoch: 6| Step: 7
Training loss: 1.1019943952560425
Validation loss: 1.7805209608488186

Epoch: 6| Step: 8
Training loss: 0.9512549638748169
Validation loss: 1.7936995760087044

Epoch: 6| Step: 9
Training loss: 0.7129221558570862
Validation loss: 1.7947936878409436

Epoch: 6| Step: 10
Training loss: 1.1677826642990112
Validation loss: 1.8131447658743909

Epoch: 6| Step: 11
Training loss: 0.8820266723632812
Validation loss: 1.7979675864660611

Epoch: 6| Step: 12
Training loss: 1.0143780708312988
Validation loss: 1.7880766494299776

Epoch: 6| Step: 13
Training loss: 0.3969683051109314
Validation loss: 1.7928740234785183

Epoch: 174| Step: 0
Training loss: 0.7706598043441772
Validation loss: 1.7975901865190076

Epoch: 6| Step: 1
Training loss: 0.9389446973800659
Validation loss: 1.7944143279906242

Epoch: 6| Step: 2
Training loss: 0.30312666296958923
Validation loss: 1.815896052186207

Epoch: 6| Step: 3
Training loss: 0.8587846755981445
Validation loss: 1.833176689763223

Epoch: 6| Step: 4
Training loss: 0.8574827313423157
Validation loss: 1.8388246772109822

Epoch: 6| Step: 5
Training loss: 1.0555720329284668
Validation loss: 1.825714288219329

Epoch: 6| Step: 6
Training loss: 1.2842713594436646
Validation loss: 1.7772567502913936

Epoch: 6| Step: 7
Training loss: 0.6812448501586914
Validation loss: 1.8026599858396797

Epoch: 6| Step: 8
Training loss: 1.3055611848831177
Validation loss: 1.8262077403324906

Epoch: 6| Step: 9
Training loss: 0.956840991973877
Validation loss: 1.8047728743604434

Epoch: 6| Step: 10
Training loss: 0.861708402633667
Validation loss: 1.7647173558512042

Epoch: 6| Step: 11
Training loss: 0.6811811923980713
Validation loss: 1.759179489586943

Epoch: 6| Step: 12
Training loss: 0.7282565236091614
Validation loss: 1.7578197025483655

Epoch: 6| Step: 13
Training loss: 1.296701431274414
Validation loss: 1.764129413071499

Epoch: 175| Step: 0
Training loss: 0.8096646070480347
Validation loss: 1.7800483434431014

Epoch: 6| Step: 1
Training loss: 0.9612023234367371
Validation loss: 1.7994976300065235

Epoch: 6| Step: 2
Training loss: 0.9354894757270813
Validation loss: 1.8109510009006788

Epoch: 6| Step: 3
Training loss: 0.7914025783538818
Validation loss: 1.8244891051323182

Epoch: 6| Step: 4
Training loss: 1.15834641456604
Validation loss: 1.7950246513530772

Epoch: 6| Step: 5
Training loss: 1.0975635051727295
Validation loss: 1.7813709410288001

Epoch: 6| Step: 6
Training loss: 0.8849580883979797
Validation loss: 1.7732142017733665

Epoch: 6| Step: 7
Training loss: 0.32320865988731384
Validation loss: 1.7863241562279322

Epoch: 6| Step: 8
Training loss: 0.9405063390731812
Validation loss: 1.8064122379467051

Epoch: 6| Step: 9
Training loss: 0.8130155801773071
Validation loss: 1.9237047421034945

Epoch: 6| Step: 10
Training loss: 0.6739740967750549
Validation loss: 1.9325365661292948

Epoch: 6| Step: 11
Training loss: 1.3573977947235107
Validation loss: 1.9210447957438808

Epoch: 6| Step: 12
Training loss: 1.0106115341186523
Validation loss: 1.880720567959611

Epoch: 6| Step: 13
Training loss: 0.6589118242263794
Validation loss: 1.816962601036154

Epoch: 176| Step: 0
Training loss: 0.9755544662475586
Validation loss: 1.7415992598379813

Epoch: 6| Step: 1
Training loss: 0.5215111970901489
Validation loss: 1.6968802790487967

Epoch: 6| Step: 2
Training loss: 0.5534494519233704
Validation loss: 1.6873801805639779

Epoch: 6| Step: 3
Training loss: 1.0242732763290405
Validation loss: 1.7048799735243603

Epoch: 6| Step: 4
Training loss: 0.9464547634124756
Validation loss: 1.7246255643906132

Epoch: 6| Step: 5
Training loss: 0.8985414505004883
Validation loss: 1.7242423603611607

Epoch: 6| Step: 6
Training loss: 1.1224453449249268
Validation loss: 1.7697365437784502

Epoch: 6| Step: 7
Training loss: 0.6230708360671997
Validation loss: 1.7505277279884583

Epoch: 6| Step: 8
Training loss: 0.7199011445045471
Validation loss: 1.7736470622401084

Epoch: 6| Step: 9
Training loss: 1.2154204845428467
Validation loss: 1.7913842111505487

Epoch: 6| Step: 10
Training loss: 0.6488760113716125
Validation loss: 1.7604204941821355

Epoch: 6| Step: 11
Training loss: 0.6608223915100098
Validation loss: 1.7486052807941233

Epoch: 6| Step: 12
Training loss: 1.4549624919891357
Validation loss: 1.7225945970063568

Epoch: 6| Step: 13
Training loss: 0.486638605594635
Validation loss: 1.711452389276156

Epoch: 177| Step: 0
Training loss: 0.5841149091720581
Validation loss: 1.7124999338580715

Epoch: 6| Step: 1
Training loss: 0.7024455070495605
Validation loss: 1.7697166717180641

Epoch: 6| Step: 2
Training loss: 0.4746161103248596
Validation loss: 1.8068670483045681

Epoch: 6| Step: 3
Training loss: 1.3075356483459473
Validation loss: 1.8626390554571663

Epoch: 6| Step: 4
Training loss: 1.1243176460266113
Validation loss: 1.856931641537656

Epoch: 6| Step: 5
Training loss: 0.39736127853393555
Validation loss: 1.811194748006841

Epoch: 6| Step: 6
Training loss: 1.0602818727493286
Validation loss: 1.8013805266349547

Epoch: 6| Step: 7
Training loss: 0.9009685516357422
Validation loss: 1.765428557190844

Epoch: 6| Step: 8
Training loss: 0.9543788433074951
Validation loss: 1.7734372385086552

Epoch: 6| Step: 9
Training loss: 0.8409130573272705
Validation loss: 1.782920604111046

Epoch: 6| Step: 10
Training loss: 0.8403785228729248
Validation loss: 1.759736576387959

Epoch: 6| Step: 11
Training loss: 0.6432865262031555
Validation loss: 1.7577457453614922

Epoch: 6| Step: 12
Training loss: 1.221444845199585
Validation loss: 1.7222729934159147

Epoch: 6| Step: 13
Training loss: 0.7109109163284302
Validation loss: 1.7108579386946976

Epoch: 178| Step: 0
Training loss: 0.5913078784942627
Validation loss: 1.725603057492164

Epoch: 6| Step: 1
Training loss: 0.8788884878158569
Validation loss: 1.763344487836284

Epoch: 6| Step: 2
Training loss: 1.1586565971374512
Validation loss: 1.7789936847584222

Epoch: 6| Step: 3
Training loss: 0.763056755065918
Validation loss: 1.7985383643898913

Epoch: 6| Step: 4
Training loss: 1.1878505945205688
Validation loss: 1.8075597081133115

Epoch: 6| Step: 5
Training loss: 0.9256597757339478
Validation loss: 1.7876346060024795

Epoch: 6| Step: 6
Training loss: 0.5583329200744629
Validation loss: 1.8130710522333782

Epoch: 6| Step: 7
Training loss: 1.1411560773849487
Validation loss: 1.8359328239194808

Epoch: 6| Step: 8
Training loss: 0.8789372444152832
Validation loss: 1.8137625545583747

Epoch: 6| Step: 9
Training loss: 0.6739071607589722
Validation loss: 1.8219311980790989

Epoch: 6| Step: 10
Training loss: 0.8544632196426392
Validation loss: 1.7944154399697498

Epoch: 6| Step: 11
Training loss: 0.4270094037055969
Validation loss: 1.7928859572256766

Epoch: 6| Step: 12
Training loss: 0.49802953004837036
Validation loss: 1.7182608817213325

Epoch: 6| Step: 13
Training loss: 1.2242757081985474
Validation loss: 1.6844091864042385

Epoch: 179| Step: 0
Training loss: 0.47611677646636963
Validation loss: 1.664742644115161

Epoch: 6| Step: 1
Training loss: 0.7650988101959229
Validation loss: 1.6779904519357989

Epoch: 6| Step: 2
Training loss: 1.0458587408065796
Validation loss: 1.7136719803656302

Epoch: 6| Step: 3
Training loss: 0.6845643520355225
Validation loss: 1.7668384390492593

Epoch: 6| Step: 4
Training loss: 0.9992526173591614
Validation loss: 1.772103564713591

Epoch: 6| Step: 5
Training loss: 0.7870749235153198
Validation loss: 1.818036989499164

Epoch: 6| Step: 6
Training loss: 0.7787801623344421
Validation loss: 1.855578548164778

Epoch: 6| Step: 7
Training loss: 0.8526220321655273
Validation loss: 1.8773398886444748

Epoch: 6| Step: 8
Training loss: 0.9271012544631958
Validation loss: 1.8579145221300022

Epoch: 6| Step: 9
Training loss: 1.048487663269043
Validation loss: 1.841817630234585

Epoch: 6| Step: 10
Training loss: 0.8899081945419312
Validation loss: 1.8461627626931796

Epoch: 6| Step: 11
Training loss: 1.2528774738311768
Validation loss: 1.785533316673771

Epoch: 6| Step: 12
Training loss: 0.6375105381011963
Validation loss: 1.7583713992949455

Epoch: 6| Step: 13
Training loss: 0.45240941643714905
Validation loss: 1.7462403158987723

Epoch: 180| Step: 0
Training loss: 0.6062378883361816
Validation loss: 1.711869555134927

Epoch: 6| Step: 1
Training loss: 0.765397310256958
Validation loss: 1.6498576928210515

Epoch: 6| Step: 2
Training loss: 0.7173507809638977
Validation loss: 1.6589480933322702

Epoch: 6| Step: 3
Training loss: 1.1640143394470215
Validation loss: 1.6423986317009054

Epoch: 6| Step: 4
Training loss: 0.6878418922424316
Validation loss: 1.6282916812486545

Epoch: 6| Step: 5
Training loss: 0.7656437158584595
Validation loss: 1.6789620486638879

Epoch: 6| Step: 6
Training loss: 0.6499977111816406
Validation loss: 1.699901791029079

Epoch: 6| Step: 7
Training loss: 0.5938894748687744
Validation loss: 1.7902701452214231

Epoch: 6| Step: 8
Training loss: 0.9784294962882996
Validation loss: 1.8422473963870798

Epoch: 6| Step: 9
Training loss: 1.2203130722045898
Validation loss: 1.8942674975241385

Epoch: 6| Step: 10
Training loss: 0.9648032784461975
Validation loss: 1.9132862757611018

Epoch: 6| Step: 11
Training loss: 1.1163160800933838
Validation loss: 1.9122435046780495

Epoch: 6| Step: 12
Training loss: 0.7579681873321533
Validation loss: 1.8692145873141546

Epoch: 6| Step: 13
Training loss: 0.5502682328224182
Validation loss: 1.8245918161125594

Epoch: 181| Step: 0
Training loss: 0.9766697883605957
Validation loss: 1.7869356780923822

Epoch: 6| Step: 1
Training loss: 0.9085741639137268
Validation loss: 1.7737710886104132

Epoch: 6| Step: 2
Training loss: 0.5551434755325317
Validation loss: 1.7488824193195631

Epoch: 6| Step: 3
Training loss: 0.8385763168334961
Validation loss: 1.7508213468777236

Epoch: 6| Step: 4
Training loss: 0.7798764705657959
Validation loss: 1.7543744528165428

Epoch: 6| Step: 5
Training loss: 0.6130384206771851
Validation loss: 1.7262822094783987

Epoch: 6| Step: 6
Training loss: 0.8790053129196167
Validation loss: 1.7148228127469298

Epoch: 6| Step: 7
Training loss: 1.181157112121582
Validation loss: 1.7355593853099371

Epoch: 6| Step: 8
Training loss: 0.5205288529396057
Validation loss: 1.740905757873289

Epoch: 6| Step: 9
Training loss: 1.170944333076477
Validation loss: 1.7211765358524937

Epoch: 6| Step: 10
Training loss: 0.5391057133674622
Validation loss: 1.6829007915271226

Epoch: 6| Step: 11
Training loss: 0.6164423227310181
Validation loss: 1.6754682205056632

Epoch: 6| Step: 12
Training loss: 0.6675271987915039
Validation loss: 1.6838771668813561

Epoch: 6| Step: 13
Training loss: 0.9805465340614319
Validation loss: 1.6690821263097948

Epoch: 182| Step: 0
Training loss: 0.45852500200271606
Validation loss: 1.6925781414073

Epoch: 6| Step: 1
Training loss: 0.641193687915802
Validation loss: 1.6697357700717064

Epoch: 6| Step: 2
Training loss: 0.5640460848808289
Validation loss: 1.6695518224470076

Epoch: 6| Step: 3
Training loss: 0.8050001859664917
Validation loss: 1.7056004872886084

Epoch: 6| Step: 4
Training loss: 0.907841682434082
Validation loss: 1.7609850014409711

Epoch: 6| Step: 5
Training loss: 0.8108240365982056
Validation loss: 1.734023896596765

Epoch: 6| Step: 6
Training loss: 0.5531065464019775
Validation loss: 1.7781189462190032

Epoch: 6| Step: 7
Training loss: 1.0840537548065186
Validation loss: 1.8048897622733988

Epoch: 6| Step: 8
Training loss: 1.0146288871765137
Validation loss: 1.7867781872390418

Epoch: 6| Step: 9
Training loss: 0.5824189186096191
Validation loss: 1.7914461192264353

Epoch: 6| Step: 10
Training loss: 1.2550840377807617
Validation loss: 1.7760930932978147

Epoch: 6| Step: 11
Training loss: 0.48213616013526917
Validation loss: 1.7717994207976966

Epoch: 6| Step: 12
Training loss: 0.9388134479522705
Validation loss: 1.765417759136487

Epoch: 6| Step: 13
Training loss: 1.1986660957336426
Validation loss: 1.7311095550496092

Epoch: 183| Step: 0
Training loss: 1.2071053981781006
Validation loss: 1.7499912400399484

Epoch: 6| Step: 1
Training loss: 0.4720344543457031
Validation loss: 1.750120291145899

Epoch: 6| Step: 2
Training loss: 0.7346004247665405
Validation loss: 1.7805965767111829

Epoch: 6| Step: 3
Training loss: 0.995672345161438
Validation loss: 1.7988387115540043

Epoch: 6| Step: 4
Training loss: 0.9948670864105225
Validation loss: 1.7721095418417325

Epoch: 6| Step: 5
Training loss: 0.8760467767715454
Validation loss: 1.7643697466901553

Epoch: 6| Step: 6
Training loss: 0.7915771007537842
Validation loss: 1.7308013310996435

Epoch: 6| Step: 7
Training loss: 0.9245423078536987
Validation loss: 1.6975437761634908

Epoch: 6| Step: 8
Training loss: 0.541317343711853
Validation loss: 1.6763586459621307

Epoch: 6| Step: 9
Training loss: 0.5429776310920715
Validation loss: 1.654572275377089

Epoch: 6| Step: 10
Training loss: 0.9387224316596985
Validation loss: 1.7061075728426698

Epoch: 6| Step: 11
Training loss: 0.6274865865707397
Validation loss: 1.7013915508024153

Epoch: 6| Step: 12
Training loss: 0.8004499673843384
Validation loss: 1.7061142126719158

Epoch: 6| Step: 13
Training loss: 0.7448709011077881
Validation loss: 1.7433730645846295

Epoch: 184| Step: 0
Training loss: 0.4986805021762848
Validation loss: 1.7602264727315595

Epoch: 6| Step: 1
Training loss: 0.817791759967804
Validation loss: 1.781011168674756

Epoch: 6| Step: 2
Training loss: 0.510793924331665
Validation loss: 1.803397322213778

Epoch: 6| Step: 3
Training loss: 0.8814558386802673
Validation loss: 1.8248076823449904

Epoch: 6| Step: 4
Training loss: 0.6640979051589966
Validation loss: 1.8045546495786278

Epoch: 6| Step: 5
Training loss: 0.8727013468742371
Validation loss: 1.8212173164531749

Epoch: 6| Step: 6
Training loss: 0.9500613212585449
Validation loss: 1.8106154011141868

Epoch: 6| Step: 7
Training loss: 0.6946126222610474
Validation loss: 1.7883481799915273

Epoch: 6| Step: 8
Training loss: 0.7036393880844116
Validation loss: 1.7952250831870622

Epoch: 6| Step: 9
Training loss: 0.8716135025024414
Validation loss: 1.774581286215013

Epoch: 6| Step: 10
Training loss: 0.925162672996521
Validation loss: 1.7868990949405137

Epoch: 6| Step: 11
Training loss: 0.8393446803092957
Validation loss: 1.7541362700923797

Epoch: 6| Step: 12
Training loss: 0.8286232352256775
Validation loss: 1.7652085827242943

Epoch: 6| Step: 13
Training loss: 1.0692968368530273
Validation loss: 1.7262204770118958

Epoch: 185| Step: 0
Training loss: 0.9654392004013062
Validation loss: 1.733238341987774

Epoch: 6| Step: 1
Training loss: 0.9147977828979492
Validation loss: 1.7235023949735908

Epoch: 6| Step: 2
Training loss: 0.879866361618042
Validation loss: 1.702986474960081

Epoch: 6| Step: 3
Training loss: 0.6038652062416077
Validation loss: 1.723159747738992

Epoch: 6| Step: 4
Training loss: 0.8016157150268555
Validation loss: 1.7194013352035193

Epoch: 6| Step: 5
Training loss: 0.44677603244781494
Validation loss: 1.7027454145493046

Epoch: 6| Step: 6
Training loss: 0.3294215798377991
Validation loss: 1.6825829757157194

Epoch: 6| Step: 7
Training loss: 0.8606433868408203
Validation loss: 1.687678898534467

Epoch: 6| Step: 8
Training loss: 0.54351407289505
Validation loss: 1.6844048179605955

Epoch: 6| Step: 9
Training loss: 0.6365708112716675
Validation loss: 1.7118557883847145

Epoch: 6| Step: 10
Training loss: 1.1044775247573853
Validation loss: 1.7153317800132177

Epoch: 6| Step: 11
Training loss: 0.6174412965774536
Validation loss: 1.739533849941787

Epoch: 6| Step: 12
Training loss: 0.9037356972694397
Validation loss: 1.7478564580281575

Epoch: 6| Step: 13
Training loss: 1.4398527145385742
Validation loss: 1.7681504539264146

Epoch: 186| Step: 0
Training loss: 0.7686300277709961
Validation loss: 1.8123265210018362

Epoch: 6| Step: 1
Training loss: 0.6959527730941772
Validation loss: 1.8050567385970906

Epoch: 6| Step: 2
Training loss: 0.9379507899284363
Validation loss: 1.8134455834665606

Epoch: 6| Step: 3
Training loss: 0.6942549347877502
Validation loss: 1.8130901757106985

Epoch: 6| Step: 4
Training loss: 0.9844287037849426
Validation loss: 1.788468332700832

Epoch: 6| Step: 5
Training loss: 0.869345486164093
Validation loss: 1.7495265712020218

Epoch: 6| Step: 6
Training loss: 0.8168330192565918
Validation loss: 1.7524692384145593

Epoch: 6| Step: 7
Training loss: 1.1035313606262207
Validation loss: 1.7603092026966873

Epoch: 6| Step: 8
Training loss: 0.8742561340332031
Validation loss: 1.7470804709260181

Epoch: 6| Step: 9
Training loss: 0.8264909386634827
Validation loss: 1.7582132931678527

Epoch: 6| Step: 10
Training loss: 0.6269612312316895
Validation loss: 1.749444596229061

Epoch: 6| Step: 11
Training loss: 0.9573975801467896
Validation loss: 1.7485781420943558

Epoch: 6| Step: 12
Training loss: 0.640912652015686
Validation loss: 1.802826412262455

Epoch: 6| Step: 13
Training loss: 0.39509207010269165
Validation loss: 1.7908354254179104

Epoch: 187| Step: 0
Training loss: 0.591819167137146
Validation loss: 1.7738690965919084

Epoch: 6| Step: 1
Training loss: 0.43666771054267883
Validation loss: 1.8257928663684475

Epoch: 6| Step: 2
Training loss: 1.0962942838668823
Validation loss: 1.8288403198283205

Epoch: 6| Step: 3
Training loss: 0.8045815229415894
Validation loss: 1.7806398791651572

Epoch: 6| Step: 4
Training loss: 0.8038625717163086
Validation loss: 1.7756133912712015

Epoch: 6| Step: 5
Training loss: 0.7476580142974854
Validation loss: 1.7464982578831334

Epoch: 6| Step: 6
Training loss: 0.8252629041671753
Validation loss: 1.693286136914325

Epoch: 6| Step: 7
Training loss: 1.0101977586746216
Validation loss: 1.6818006295029835

Epoch: 6| Step: 8
Training loss: 1.191795825958252
Validation loss: 1.6491257862378192

Epoch: 6| Step: 9
Training loss: 0.8143709301948547
Validation loss: 1.5933644002483738

Epoch: 6| Step: 10
Training loss: 0.6178706884384155
Validation loss: 1.6175858923183974

Epoch: 6| Step: 11
Training loss: 1.2247669696807861
Validation loss: 1.631172223757672

Epoch: 6| Step: 12
Training loss: 0.651451587677002
Validation loss: 1.6202534232088315

Epoch: 6| Step: 13
Training loss: 0.7785682678222656
Validation loss: 1.6467422734024704

Epoch: 188| Step: 0
Training loss: 0.9023905992507935
Validation loss: 1.6760082642237346

Epoch: 6| Step: 1
Training loss: 0.785820722579956
Validation loss: 1.7528599641656364

Epoch: 6| Step: 2
Training loss: 0.8715019822120667
Validation loss: 1.8491939754896267

Epoch: 6| Step: 3
Training loss: 0.7142043709754944
Validation loss: 1.911185670924443

Epoch: 6| Step: 4
Training loss: 1.1714290380477905
Validation loss: 1.994371409057289

Epoch: 6| Step: 5
Training loss: 0.9382427930831909
Validation loss: 1.9820538451594691

Epoch: 6| Step: 6
Training loss: 0.5741627216339111
Validation loss: 1.9895004828770955

Epoch: 6| Step: 7
Training loss: 0.9409231543540955
Validation loss: 1.914216322283591

Epoch: 6| Step: 8
Training loss: 0.9523008465766907
Validation loss: 1.828398839119942

Epoch: 6| Step: 9
Training loss: 0.5625731945037842
Validation loss: 1.758985936000783

Epoch: 6| Step: 10
Training loss: 0.8157419562339783
Validation loss: 1.7132663162805701

Epoch: 6| Step: 11
Training loss: 0.7609950304031372
Validation loss: 1.7067621856607416

Epoch: 6| Step: 12
Training loss: 0.6045315265655518
Validation loss: 1.7004904080462713

Epoch: 6| Step: 13
Training loss: 1.404733657836914
Validation loss: 1.6835588639782322

Epoch: 189| Step: 0
Training loss: 0.731795072555542
Validation loss: 1.6716160158957205

Epoch: 6| Step: 1
Training loss: 0.8459489345550537
Validation loss: 1.6692298548195952

Epoch: 6| Step: 2
Training loss: 0.4489976167678833
Validation loss: 1.670164469749697

Epoch: 6| Step: 3
Training loss: 0.5276778936386108
Validation loss: 1.7058980170116629

Epoch: 6| Step: 4
Training loss: 1.0318607091903687
Validation loss: 1.7051989173376432

Epoch: 6| Step: 5
Training loss: 0.8565511107444763
Validation loss: 1.6554661271392659

Epoch: 6| Step: 6
Training loss: 1.0669872760772705
Validation loss: 1.6786557615444224

Epoch: 6| Step: 7
Training loss: 0.5431883931159973
Validation loss: 1.6937572379266062

Epoch: 6| Step: 8
Training loss: 0.555631160736084
Validation loss: 1.7178427570609636

Epoch: 6| Step: 9
Training loss: 0.6719114780426025
Validation loss: 1.7496725025997366

Epoch: 6| Step: 10
Training loss: 0.9083372950553894
Validation loss: 1.7992841236052974

Epoch: 6| Step: 11
Training loss: 0.745903491973877
Validation loss: 1.830004580559269

Epoch: 6| Step: 12
Training loss: 0.5503689646720886
Validation loss: 1.8903657172315864

Epoch: 6| Step: 13
Training loss: 0.9138422012329102
Validation loss: 1.9151650551826722

Epoch: 190| Step: 0
Training loss: 0.7045559883117676
Validation loss: 1.9240687444645872

Epoch: 6| Step: 1
Training loss: 0.7003292441368103
Validation loss: 1.9052405216360604

Epoch: 6| Step: 2
Training loss: 0.7867997884750366
Validation loss: 1.893249580937047

Epoch: 6| Step: 3
Training loss: 0.6486597061157227
Validation loss: 1.8268127697770313

Epoch: 6| Step: 4
Training loss: 0.7682263851165771
Validation loss: 1.7863649091412943

Epoch: 6| Step: 5
Training loss: 0.654377818107605
Validation loss: 1.7685296868765226

Epoch: 6| Step: 6
Training loss: 0.6064881682395935
Validation loss: 1.7621891511383878

Epoch: 6| Step: 7
Training loss: 0.9250458478927612
Validation loss: 1.7633847780125116

Epoch: 6| Step: 8
Training loss: 0.8888327479362488
Validation loss: 1.7494722079205256

Epoch: 6| Step: 9
Training loss: 0.6326175928115845
Validation loss: 1.7271824344511955

Epoch: 6| Step: 10
Training loss: 0.9488266110420227
Validation loss: 1.6859872815429524

Epoch: 6| Step: 11
Training loss: 0.7846941947937012
Validation loss: 1.7022380239220076

Epoch: 6| Step: 12
Training loss: 1.1940995454788208
Validation loss: 1.7226435676697762

Epoch: 6| Step: 13
Training loss: 1.06471586227417
Validation loss: 1.742066611525833

Epoch: 191| Step: 0
Training loss: 0.4116392135620117
Validation loss: 1.74122840486547

Epoch: 6| Step: 1
Training loss: 1.1127641201019287
Validation loss: 1.8207638827703332

Epoch: 6| Step: 2
Training loss: 1.1703381538391113
Validation loss: 1.8040741259051907

Epoch: 6| Step: 3
Training loss: 1.1264302730560303
Validation loss: 1.8467437067339498

Epoch: 6| Step: 4
Training loss: 0.8553581237792969
Validation loss: 1.8401196208051456

Epoch: 6| Step: 5
Training loss: 0.8028744459152222
Validation loss: 1.826657384954473

Epoch: 6| Step: 6
Training loss: 0.6607005596160889
Validation loss: 1.8233834338444534

Epoch: 6| Step: 7
Training loss: 0.351082444190979
Validation loss: 1.804426166319078

Epoch: 6| Step: 8
Training loss: 0.9452390670776367
Validation loss: 1.8059048460375877

Epoch: 6| Step: 9
Training loss: 0.8910751938819885
Validation loss: 1.769446990823233

Epoch: 6| Step: 10
Training loss: 0.6594356298446655
Validation loss: 1.7672642507860739

Epoch: 6| Step: 11
Training loss: 0.4953148663043976
Validation loss: 1.7802479933666926

Epoch: 6| Step: 12
Training loss: 0.687046468257904
Validation loss: 1.7687641612945064

Epoch: 6| Step: 13
Training loss: 0.4793631136417389
Validation loss: 1.7811686377371512

Epoch: 192| Step: 0
Training loss: 0.5671476125717163
Validation loss: 1.7649468350154098

Epoch: 6| Step: 1
Training loss: 0.48697543144226074
Validation loss: 1.7294039700620918

Epoch: 6| Step: 2
Training loss: 0.7405217885971069
Validation loss: 1.7281983744713567

Epoch: 6| Step: 3
Training loss: 0.7119460701942444
Validation loss: 1.6879805307234488

Epoch: 6| Step: 4
Training loss: 1.0163309574127197
Validation loss: 1.7236056020182948

Epoch: 6| Step: 5
Training loss: 1.0595545768737793
Validation loss: 1.7676051944814704

Epoch: 6| Step: 6
Training loss: 0.377017080783844
Validation loss: 1.7128295847164687

Epoch: 6| Step: 7
Training loss: 1.0155212879180908
Validation loss: 1.7287603052713538

Epoch: 6| Step: 8
Training loss: 0.9720100164413452
Validation loss: 1.7234867260020266

Epoch: 6| Step: 9
Training loss: 0.848326563835144
Validation loss: 1.7020257237137004

Epoch: 6| Step: 10
Training loss: 0.5993369221687317
Validation loss: 1.6826946504654423

Epoch: 6| Step: 11
Training loss: 0.563976526260376
Validation loss: 1.723201205653529

Epoch: 6| Step: 12
Training loss: 1.0208439826965332
Validation loss: 1.7090409878761537

Epoch: 6| Step: 13
Training loss: 0.4318000078201294
Validation loss: 1.7339370712157218

Epoch: 193| Step: 0
Training loss: 0.8017621040344238
Validation loss: 1.7674205687738234

Epoch: 6| Step: 1
Training loss: 0.9912689924240112
Validation loss: 1.7703314327424573

Epoch: 6| Step: 2
Training loss: 0.9056706428527832
Validation loss: 1.7596651559234948

Epoch: 6| Step: 3
Training loss: 0.7019917964935303
Validation loss: 1.7145358118959653

Epoch: 6| Step: 4
Training loss: 0.4148293733596802
Validation loss: 1.740546388010825

Epoch: 6| Step: 5
Training loss: 0.5623875856399536
Validation loss: 1.74852285205677

Epoch: 6| Step: 6
Training loss: 0.6029699444770813
Validation loss: 1.7876570904126732

Epoch: 6| Step: 7
Training loss: 0.8629381656646729
Validation loss: 1.8195759493817565

Epoch: 6| Step: 8
Training loss: 0.960041880607605
Validation loss: 1.8231416120324084

Epoch: 6| Step: 9
Training loss: 0.5377962589263916
Validation loss: 1.811142167737407

Epoch: 6| Step: 10
Training loss: 0.9099254608154297
Validation loss: 1.8626756770636446

Epoch: 6| Step: 11
Training loss: 0.9914265871047974
Validation loss: 1.8391685216657576

Epoch: 6| Step: 12
Training loss: 0.7700469493865967
Validation loss: 1.8468310679158857

Epoch: 6| Step: 13
Training loss: 0.3485196530818939
Validation loss: 1.806240027950656

Epoch: 194| Step: 0
Training loss: 0.6105592846870422
Validation loss: 1.7973099818793676

Epoch: 6| Step: 1
Training loss: 1.167447805404663
Validation loss: 1.7846283194839314

Epoch: 6| Step: 2
Training loss: 1.0703561305999756
Validation loss: 1.7423105419323008

Epoch: 6| Step: 3
Training loss: 0.6759165525436401
Validation loss: 1.7268690306653258

Epoch: 6| Step: 4
Training loss: 0.5566563606262207
Validation loss: 1.7500464224046277

Epoch: 6| Step: 5
Training loss: 0.5673190951347351
Validation loss: 1.7323018402181647

Epoch: 6| Step: 6
Training loss: 0.5343770980834961
Validation loss: 1.7200995260669338

Epoch: 6| Step: 7
Training loss: 0.4452996850013733
Validation loss: 1.707439305961773

Epoch: 6| Step: 8
Training loss: 0.6525384187698364
Validation loss: 1.6826611641914613

Epoch: 6| Step: 9
Training loss: 0.6110763549804688
Validation loss: 1.7076057131572435

Epoch: 6| Step: 10
Training loss: 0.820669412612915
Validation loss: 1.6988495690848238

Epoch: 6| Step: 11
Training loss: 0.6408587694168091
Validation loss: 1.746816231358436

Epoch: 6| Step: 12
Training loss: 0.8342519998550415
Validation loss: 1.7367707747285084

Epoch: 6| Step: 13
Training loss: 0.6121444702148438
Validation loss: 1.7227611887839533

Epoch: 195| Step: 0
Training loss: 0.8123690485954285
Validation loss: 1.6823238416384625

Epoch: 6| Step: 1
Training loss: 0.5980787873268127
Validation loss: 1.6938837856374762

Epoch: 6| Step: 2
Training loss: 0.8957604765892029
Validation loss: 1.696568210919698

Epoch: 6| Step: 3
Training loss: 0.9003646373748779
Validation loss: 1.71368375901253

Epoch: 6| Step: 4
Training loss: 0.7035481929779053
Validation loss: 1.7037896648530038

Epoch: 6| Step: 5
Training loss: 0.7176398038864136
Validation loss: 1.7171301700735604

Epoch: 6| Step: 6
Training loss: 0.8793060779571533
Validation loss: 1.7591109532181934

Epoch: 6| Step: 7
Training loss: 1.156742811203003
Validation loss: 1.8069503332978936

Epoch: 6| Step: 8
Training loss: 0.5920883417129517
Validation loss: 1.7944839180156749

Epoch: 6| Step: 9
Training loss: 0.34245067834854126
Validation loss: 1.7464403824139667

Epoch: 6| Step: 10
Training loss: 0.62934410572052
Validation loss: 1.7339864289888771

Epoch: 6| Step: 11
Training loss: 0.715926468372345
Validation loss: 1.7287901447665306

Epoch: 6| Step: 12
Training loss: 0.6745556592941284
Validation loss: 1.683194286079817

Epoch: 6| Step: 13
Training loss: 0.6355965733528137
Validation loss: 1.6622766397332633

Epoch: 196| Step: 0
Training loss: 0.610078752040863
Validation loss: 1.6515864236380464

Epoch: 6| Step: 1
Training loss: 0.965961217880249
Validation loss: 1.6513308786576795

Epoch: 6| Step: 2
Training loss: 0.554355800151825
Validation loss: 1.629252919586756

Epoch: 6| Step: 3
Training loss: 0.8077965378761292
Validation loss: 1.6387103091004074

Epoch: 6| Step: 4
Training loss: 0.6225054860115051
Validation loss: 1.6683158451511013

Epoch: 6| Step: 5
Training loss: 0.34788811206817627
Validation loss: 1.6698200343757548

Epoch: 6| Step: 6
Training loss: 0.39239877462387085
Validation loss: 1.7049301824262064

Epoch: 6| Step: 7
Training loss: 0.5276911854743958
Validation loss: 1.716534665835801

Epoch: 6| Step: 8
Training loss: 1.0267982482910156
Validation loss: 1.750043530617991

Epoch: 6| Step: 9
Training loss: 0.709399938583374
Validation loss: 1.7625964123715636

Epoch: 6| Step: 10
Training loss: 0.5541678667068481
Validation loss: 1.762840828587932

Epoch: 6| Step: 11
Training loss: 0.8166271448135376
Validation loss: 1.7704477745999572

Epoch: 6| Step: 12
Training loss: 0.7355794906616211
Validation loss: 1.7449195948980187

Epoch: 6| Step: 13
Training loss: 0.9699013829231262
Validation loss: 1.7026200243221816

Epoch: 197| Step: 0
Training loss: 0.6044833660125732
Validation loss: 1.6932015842007053

Epoch: 6| Step: 1
Training loss: 0.3691135048866272
Validation loss: 1.654598428357032

Epoch: 6| Step: 2
Training loss: 0.7743635177612305
Validation loss: 1.6510744658849572

Epoch: 6| Step: 3
Training loss: 0.2531200647354126
Validation loss: 1.6355738460376699

Epoch: 6| Step: 4
Training loss: 0.6694185733795166
Validation loss: 1.674152894686627

Epoch: 6| Step: 5
Training loss: 0.9066756367683411
Validation loss: 1.6838290768284951

Epoch: 6| Step: 6
Training loss: 0.5994338989257812
Validation loss: 1.6935052717885664

Epoch: 6| Step: 7
Training loss: 0.7481944561004639
Validation loss: 1.7005901464851954

Epoch: 6| Step: 8
Training loss: 0.6234492063522339
Validation loss: 1.7063763859451457

Epoch: 6| Step: 9
Training loss: 0.9472424983978271
Validation loss: 1.7315316482256817

Epoch: 6| Step: 10
Training loss: 0.9165722131729126
Validation loss: 1.7198271213039276

Epoch: 6| Step: 11
Training loss: 0.7069404125213623
Validation loss: 1.699381600144089

Epoch: 6| Step: 12
Training loss: 0.6135662794113159
Validation loss: 1.7317370496770388

Epoch: 6| Step: 13
Training loss: 0.7471505999565125
Validation loss: 1.72659053597399

Epoch: 198| Step: 0
Training loss: 0.8414134979248047
Validation loss: 1.7137386016948248

Epoch: 6| Step: 1
Training loss: 0.6884719133377075
Validation loss: 1.7187267259884906

Epoch: 6| Step: 2
Training loss: 0.42879438400268555
Validation loss: 1.7188552348844466

Epoch: 6| Step: 3
Training loss: 1.173208236694336
Validation loss: 1.759210455802179

Epoch: 6| Step: 4
Training loss: 0.5135931968688965
Validation loss: 1.7554039301410798

Epoch: 6| Step: 5
Training loss: 0.5015154480934143
Validation loss: 1.7575697809137323

Epoch: 6| Step: 6
Training loss: 0.5076571106910706
Validation loss: 1.7339190744584607

Epoch: 6| Step: 7
Training loss: 0.5752447843551636
Validation loss: 1.7383861887839533

Epoch: 6| Step: 8
Training loss: 0.8266799449920654
Validation loss: 1.7058535814285278

Epoch: 6| Step: 9
Training loss: 0.8338359594345093
Validation loss: 1.7131107366213234

Epoch: 6| Step: 10
Training loss: 0.44325119256973267
Validation loss: 1.6746576306640462

Epoch: 6| Step: 11
Training loss: 0.5750445127487183
Validation loss: 1.7037529650554861

Epoch: 6| Step: 12
Training loss: 0.37975239753723145
Validation loss: 1.7238739164926673

Epoch: 6| Step: 13
Training loss: 1.2346816062927246
Validation loss: 1.7298218563038816

Epoch: 199| Step: 0
Training loss: 0.526172935962677
Validation loss: 1.7699653563960906

Epoch: 6| Step: 1
Training loss: 0.9578624367713928
Validation loss: 1.7620546766506728

Epoch: 6| Step: 2
Training loss: 0.6789475083351135
Validation loss: 1.8115812886145808

Epoch: 6| Step: 3
Training loss: 0.5713759660720825
Validation loss: 1.811856778719092

Epoch: 6| Step: 4
Training loss: 0.6572655439376831
Validation loss: 1.7838061906958138

Epoch: 6| Step: 5
Training loss: 0.5984637141227722
Validation loss: 1.8107196707879343

Epoch: 6| Step: 6
Training loss: 0.35841184854507446
Validation loss: 1.7616100516370548

Epoch: 6| Step: 7
Training loss: 0.9999690055847168
Validation loss: 1.7378675655652118

Epoch: 6| Step: 8
Training loss: 0.6725766658782959
Validation loss: 1.7179433658558836

Epoch: 6| Step: 9
Training loss: 0.3548586964607239
Validation loss: 1.7184659486175866

Epoch: 6| Step: 10
Training loss: 0.8904476165771484
Validation loss: 1.6961506848694177

Epoch: 6| Step: 11
Training loss: 0.5916615128517151
Validation loss: 1.68697399990533

Epoch: 6| Step: 12
Training loss: 0.8171204924583435
Validation loss: 1.6734888502346572

Epoch: 6| Step: 13
Training loss: 0.5871705412864685
Validation loss: 1.66941318204326

Epoch: 200| Step: 0
Training loss: 0.8034430742263794
Validation loss: 1.6493421293074084

Epoch: 6| Step: 1
Training loss: 0.5510790348052979
Validation loss: 1.612018076322412

Epoch: 6| Step: 2
Training loss: 0.8142802715301514
Validation loss: 1.617059064167802

Epoch: 6| Step: 3
Training loss: 0.5423106551170349
Validation loss: 1.615215883460096

Epoch: 6| Step: 4
Training loss: 0.6711410284042358
Validation loss: 1.6254255669091338

Epoch: 6| Step: 5
Training loss: 0.7895495295524597
Validation loss: 1.6677821893845834

Epoch: 6| Step: 6
Training loss: 0.603868842124939
Validation loss: 1.6662384835622643

Epoch: 6| Step: 7
Training loss: 0.6186175346374512
Validation loss: 1.644616416705552

Epoch: 6| Step: 8
Training loss: 0.4301959276199341
Validation loss: 1.6769134229229343

Epoch: 6| Step: 9
Training loss: 0.6227306127548218
Validation loss: 1.7057319700077016

Epoch: 6| Step: 10
Training loss: 0.5238096117973328
Validation loss: 1.7660604215437365

Epoch: 6| Step: 11
Training loss: 0.8087053298950195
Validation loss: 1.8055973399070002

Epoch: 6| Step: 12
Training loss: 0.7636297345161438
Validation loss: 1.777438170807336

Epoch: 6| Step: 13
Training loss: 0.790303647518158
Validation loss: 1.7798615476136566

Epoch: 201| Step: 0
Training loss: 0.44324684143066406
Validation loss: 1.7969885244164416

Epoch: 6| Step: 1
Training loss: 0.5991272926330566
Validation loss: 1.7497945677849553

Epoch: 6| Step: 2
Training loss: 0.4565885663032532
Validation loss: 1.7525953041609896

Epoch: 6| Step: 3
Training loss: 0.6919808387756348
Validation loss: 1.7218187342407882

Epoch: 6| Step: 4
Training loss: 0.6905131340026855
Validation loss: 1.6854668432666409

Epoch: 6| Step: 5
Training loss: 0.6708160638809204
Validation loss: 1.698270135028388

Epoch: 6| Step: 6
Training loss: 1.0335876941680908
Validation loss: 1.6282545763959166

Epoch: 6| Step: 7
Training loss: 0.6044471859931946
Validation loss: 1.6556992171913065

Epoch: 6| Step: 8
Training loss: 0.6262686252593994
Validation loss: 1.6547757758889148

Epoch: 6| Step: 9
Training loss: 0.7478846907615662
Validation loss: 1.6145472321459042

Epoch: 6| Step: 10
Training loss: 0.7221167087554932
Validation loss: 1.6232025379775672

Epoch: 6| Step: 11
Training loss: 0.6648181676864624
Validation loss: 1.6219852124491045

Epoch: 6| Step: 12
Training loss: 0.5562989115715027
Validation loss: 1.6487129554953626

Epoch: 6| Step: 13
Training loss: 0.8590569496154785
Validation loss: 1.7170347744418728

Epoch: 202| Step: 0
Training loss: 0.2063378244638443
Validation loss: 1.7472173783086962

Epoch: 6| Step: 1
Training loss: 0.9053810834884644
Validation loss: 1.8019723866575508

Epoch: 6| Step: 2
Training loss: 0.7012845277786255
Validation loss: 1.8363955110631964

Epoch: 6| Step: 3
Training loss: 0.6505379676818848
Validation loss: 1.8825614631816905

Epoch: 6| Step: 4
Training loss: 0.48041239380836487
Validation loss: 1.876684514425134

Epoch: 6| Step: 5
Training loss: 0.5956408381462097
Validation loss: 1.851176820775514

Epoch: 6| Step: 6
Training loss: 0.7750163078308105
Validation loss: 1.8226348712880125

Epoch: 6| Step: 7
Training loss: 0.7351594567298889
Validation loss: 1.8173165064986034

Epoch: 6| Step: 8
Training loss: 0.8975851535797119
Validation loss: 1.8099072312795987

Epoch: 6| Step: 9
Training loss: 0.6035516262054443
Validation loss: 1.8194917235323178

Epoch: 6| Step: 10
Training loss: 0.39108380675315857
Validation loss: 1.8311082970711492

Epoch: 6| Step: 11
Training loss: 0.6632893085479736
Validation loss: 1.807911313990111

Epoch: 6| Step: 12
Training loss: 0.6669468879699707
Validation loss: 1.7941824364405807

Epoch: 6| Step: 13
Training loss: 0.8470139503479004
Validation loss: 1.7643564542134602

Epoch: 203| Step: 0
Training loss: 0.6543746590614319
Validation loss: 1.7362360954284668

Epoch: 6| Step: 1
Training loss: 0.45192497968673706
Validation loss: 1.7249301473299663

Epoch: 6| Step: 2
Training loss: 0.6495384573936462
Validation loss: 1.7137995022599415

Epoch: 6| Step: 3
Training loss: 1.0061423778533936
Validation loss: 1.7051410610957811

Epoch: 6| Step: 4
Training loss: 0.43718358874320984
Validation loss: 1.6937119524966004

Epoch: 6| Step: 5
Training loss: 0.28821396827697754
Validation loss: 1.7061390633224158

Epoch: 6| Step: 6
Training loss: 0.3959830105304718
Validation loss: 1.6968964017847532

Epoch: 6| Step: 7
Training loss: 0.7968689799308777
Validation loss: 1.6848817768917288

Epoch: 6| Step: 8
Training loss: 0.6136157512664795
Validation loss: 1.7121110077827209

Epoch: 6| Step: 9
Training loss: 0.664222240447998
Validation loss: 1.6702811384713778

Epoch: 6| Step: 10
Training loss: 0.8695416450500488
Validation loss: 1.6506147230825117

Epoch: 6| Step: 11
Training loss: 0.6205157041549683
Validation loss: 1.6827243297330794

Epoch: 6| Step: 12
Training loss: 0.7368191480636597
Validation loss: 1.6985925295019662

Epoch: 6| Step: 13
Training loss: 0.661785364151001
Validation loss: 1.7166687929502098

Epoch: 204| Step: 0
Training loss: 0.45665162801742554
Validation loss: 1.7108898444842267

Epoch: 6| Step: 1
Training loss: 0.7675660848617554
Validation loss: 1.7598709855028378

Epoch: 6| Step: 2
Training loss: 0.45008015632629395
Validation loss: 1.7769182484637025

Epoch: 6| Step: 3
Training loss: 0.5904765129089355
Validation loss: 1.7724078227114934

Epoch: 6| Step: 4
Training loss: 1.2795109748840332
Validation loss: 1.7788170819641442

Epoch: 6| Step: 5
Training loss: 0.5752174854278564
Validation loss: 1.7570894136223743

Epoch: 6| Step: 6
Training loss: 0.5717566013336182
Validation loss: 1.7764670387391122

Epoch: 6| Step: 7
Training loss: 0.7218601703643799
Validation loss: 1.7973859130695302

Epoch: 6| Step: 8
Training loss: 0.5391673445701599
Validation loss: 1.801230263966386

Epoch: 6| Step: 9
Training loss: 0.3862888216972351
Validation loss: 1.8191036716584237

Epoch: 6| Step: 10
Training loss: 0.5403107404708862
Validation loss: 1.8223231069503292

Epoch: 6| Step: 11
Training loss: 0.4707707166671753
Validation loss: 1.788599891047324

Epoch: 6| Step: 12
Training loss: 0.7235022783279419
Validation loss: 1.7773925065994263

Epoch: 6| Step: 13
Training loss: 0.6484957337379456
Validation loss: 1.791099964931447

Epoch: 205| Step: 0
Training loss: 0.44467782974243164
Validation loss: 1.7470889001764276

Epoch: 6| Step: 1
Training loss: 0.551142692565918
Validation loss: 1.7199813294154342

Epoch: 6| Step: 2
Training loss: 0.6876835823059082
Validation loss: 1.6980828751799881

Epoch: 6| Step: 3
Training loss: 0.6887016296386719
Validation loss: 1.6815565837326871

Epoch: 6| Step: 4
Training loss: 0.811158299446106
Validation loss: 1.6704789374464302

Epoch: 6| Step: 5
Training loss: 0.8866413235664368
Validation loss: 1.642145118405742

Epoch: 6| Step: 6
Training loss: 0.6326721906661987
Validation loss: 1.6300330623503654

Epoch: 6| Step: 7
Training loss: 0.873561441898346
Validation loss: 1.6634813290770336

Epoch: 6| Step: 8
Training loss: 0.6231141090393066
Validation loss: 1.625706515004558

Epoch: 6| Step: 9
Training loss: 0.7795600295066833
Validation loss: 1.6480262471783547

Epoch: 6| Step: 10
Training loss: 0.3267151713371277
Validation loss: 1.665262968309464

Epoch: 6| Step: 11
Training loss: 0.6169158220291138
Validation loss: 1.6645769726845525

Epoch: 6| Step: 12
Training loss: 0.5017188787460327
Validation loss: 1.7031544023944485

Epoch: 6| Step: 13
Training loss: 0.25994428992271423
Validation loss: 1.7106314705264183

Epoch: 206| Step: 0
Training loss: 0.402896910905838
Validation loss: 1.7780463490434872

Epoch: 6| Step: 1
Training loss: 0.9637270569801331
Validation loss: 1.7874789776340607

Epoch: 6| Step: 2
Training loss: 0.8832804560661316
Validation loss: 1.799890072115006

Epoch: 6| Step: 3
Training loss: 0.5350023508071899
Validation loss: 1.7908775767972391

Epoch: 6| Step: 4
Training loss: 0.625501275062561
Validation loss: 1.7439895188936623

Epoch: 6| Step: 5
Training loss: 0.3815750479698181
Validation loss: 1.7611885865529378

Epoch: 6| Step: 6
Training loss: 0.6130197048187256
Validation loss: 1.739405708928262

Epoch: 6| Step: 7
Training loss: 0.7093075513839722
Validation loss: 1.7097067871401388

Epoch: 6| Step: 8
Training loss: 0.36605674028396606
Validation loss: 1.6904707070319884

Epoch: 6| Step: 9
Training loss: 0.6305762529373169
Validation loss: 1.7041205231861403

Epoch: 6| Step: 10
Training loss: 0.4163498282432556
Validation loss: 1.6793078991674608

Epoch: 6| Step: 11
Training loss: 0.9431927800178528
Validation loss: 1.6981839620938866

Epoch: 6| Step: 12
Training loss: 0.7628050446510315
Validation loss: 1.691563485771097

Epoch: 6| Step: 13
Training loss: 0.9025648832321167
Validation loss: 1.6502320253720848

Epoch: 207| Step: 0
Training loss: 0.6234285235404968
Validation loss: 1.6701159592597716

Epoch: 6| Step: 1
Training loss: 0.6362048387527466
Validation loss: 1.6722996862985755

Epoch: 6| Step: 2
Training loss: 0.6192751526832581
Validation loss: 1.6413813534603323

Epoch: 6| Step: 3
Training loss: 0.9193369150161743
Validation loss: 1.6616052812145603

Epoch: 6| Step: 4
Training loss: 0.6432067155838013
Validation loss: 1.6693526006514026

Epoch: 6| Step: 5
Training loss: 0.41134703159332275
Validation loss: 1.710483204933905

Epoch: 6| Step: 6
Training loss: 0.9983865022659302
Validation loss: 1.6929317443601546

Epoch: 6| Step: 7
Training loss: 0.39165472984313965
Validation loss: 1.7080019289447415

Epoch: 6| Step: 8
Training loss: 0.8568485975265503
Validation loss: 1.6593889344123103

Epoch: 6| Step: 9
Training loss: 0.540387749671936
Validation loss: 1.6647316948060067

Epoch: 6| Step: 10
Training loss: 0.47770678997039795
Validation loss: 1.6589491392976494

Epoch: 6| Step: 11
Training loss: 0.6683982014656067
Validation loss: 1.6435310827788485

Epoch: 6| Step: 12
Training loss: 0.2918044626712799
Validation loss: 1.6614625582131006

Epoch: 6| Step: 13
Training loss: 0.43909040093421936
Validation loss: 1.6546043811305877

Epoch: 208| Step: 0
Training loss: 0.2331007719039917
Validation loss: 1.6662366518410303

Epoch: 6| Step: 1
Training loss: 0.5325747728347778
Validation loss: 1.7051594770082863

Epoch: 6| Step: 2
Training loss: 0.3659161925315857
Validation loss: 1.6960054418092132

Epoch: 6| Step: 3
Training loss: 0.5182088017463684
Validation loss: 1.681671005423351

Epoch: 6| Step: 4
Training loss: 0.34360429644584656
Validation loss: 1.6941510195373206

Epoch: 6| Step: 5
Training loss: 0.6187124252319336
Validation loss: 1.6504557235266573

Epoch: 6| Step: 6
Training loss: 0.6472128629684448
Validation loss: 1.665920731841877

Epoch: 6| Step: 7
Training loss: 0.8496540784835815
Validation loss: 1.6836550979204075

Epoch: 6| Step: 8
Training loss: 0.652915358543396
Validation loss: 1.6892049645864835

Epoch: 6| Step: 9
Training loss: 0.7476257681846619
Validation loss: 1.7036505335120744

Epoch: 6| Step: 10
Training loss: 0.6790534853935242
Validation loss: 1.7536857512689406

Epoch: 6| Step: 11
Training loss: 0.7089232206344604
Validation loss: 1.7831137808420325

Epoch: 6| Step: 12
Training loss: 0.8146319389343262
Validation loss: 1.787071809973768

Epoch: 6| Step: 13
Training loss: 0.5469450354576111
Validation loss: 1.7869683081103909

Epoch: 209| Step: 0
Training loss: 0.7250855565071106
Validation loss: 1.8164284037005516

Epoch: 6| Step: 1
Training loss: 0.5495102405548096
Validation loss: 1.8029893482885053

Epoch: 6| Step: 2
Training loss: 0.46415412425994873
Validation loss: 1.8020461195258684

Epoch: 6| Step: 3
Training loss: 0.7344462275505066
Validation loss: 1.7951642659402662

Epoch: 6| Step: 4
Training loss: 0.56746506690979
Validation loss: 1.763362274375013

Epoch: 6| Step: 5
Training loss: 0.4301108717918396
Validation loss: 1.7693477202487249

Epoch: 6| Step: 6
Training loss: 0.5709743499755859
Validation loss: 1.7179037178716352

Epoch: 6| Step: 7
Training loss: 0.5293506979942322
Validation loss: 1.727450688680013

Epoch: 6| Step: 8
Training loss: 0.49271807074546814
Validation loss: 1.7072528100782824

Epoch: 6| Step: 9
Training loss: 0.4772823452949524
Validation loss: 1.6634069617076586

Epoch: 6| Step: 10
Training loss: 1.061719536781311
Validation loss: 1.6464999209168136

Epoch: 6| Step: 11
Training loss: 0.5459264516830444
Validation loss: 1.6507591585959158

Epoch: 6| Step: 12
Training loss: 0.8775624632835388
Validation loss: 1.6212371754389938

Epoch: 6| Step: 13
Training loss: 0.979961097240448
Validation loss: 1.6253369508251068

Epoch: 210| Step: 0
Training loss: 0.6714529395103455
Validation loss: 1.6455939700526576

Epoch: 6| Step: 1
Training loss: 0.558443546295166
Validation loss: 1.686905655809628

Epoch: 6| Step: 2
Training loss: 0.6682789921760559
Validation loss: 1.6877705166416783

Epoch: 6| Step: 3
Training loss: 0.746233344078064
Validation loss: 1.698741296286224

Epoch: 6| Step: 4
Training loss: 0.4201670289039612
Validation loss: 1.6738246653669624

Epoch: 6| Step: 5
Training loss: 0.38913825154304504
Validation loss: 1.7159015683717624

Epoch: 6| Step: 6
Training loss: 0.48003435134887695
Validation loss: 1.71847665309906

Epoch: 6| Step: 7
Training loss: 0.7474685311317444
Validation loss: 1.7200089885342507

Epoch: 6| Step: 8
Training loss: 0.3094126582145691
Validation loss: 1.7468094851381035

Epoch: 6| Step: 9
Training loss: 0.948451042175293
Validation loss: 1.7846081487594112

Epoch: 6| Step: 10
Training loss: 0.9793953895568848
Validation loss: 1.8281236335795412

Epoch: 6| Step: 11
Training loss: 0.5009971857070923
Validation loss: 1.8068916297728015

Epoch: 6| Step: 12
Training loss: 0.4487347900867462
Validation loss: 1.805238853218735

Epoch: 6| Step: 13
Training loss: 0.49555137753486633
Validation loss: 1.789493614627469

Epoch: 211| Step: 0
Training loss: 0.36042332649230957
Validation loss: 1.7757955622929398

Epoch: 6| Step: 1
Training loss: 0.22735106945037842
Validation loss: 1.7671377056388444

Epoch: 6| Step: 2
Training loss: 0.32893338799476624
Validation loss: 1.774576057669937

Epoch: 6| Step: 3
Training loss: 1.233816385269165
Validation loss: 1.7930166080433836

Epoch: 6| Step: 4
Training loss: 0.5884448289871216
Validation loss: 1.7406464366502659

Epoch: 6| Step: 5
Training loss: 0.7224974036216736
Validation loss: 1.7456114522872432

Epoch: 6| Step: 6
Training loss: 0.552316427230835
Validation loss: 1.740536287266721

Epoch: 6| Step: 7
Training loss: 0.4370798170566559
Validation loss: 1.7048830447658416

Epoch: 6| Step: 8
Training loss: 0.464470237493515
Validation loss: 1.685665847152792

Epoch: 6| Step: 9
Training loss: 0.6866531372070312
Validation loss: 1.7073349683515486

Epoch: 6| Step: 10
Training loss: 0.7416878938674927
Validation loss: 1.646661716122781

Epoch: 6| Step: 11
Training loss: 0.6431792974472046
Validation loss: 1.6494559459788825

Epoch: 6| Step: 12
Training loss: 0.5844943523406982
Validation loss: 1.65860838531166

Epoch: 6| Step: 13
Training loss: 0.4831858277320862
Validation loss: 1.6195492282990487

Epoch: 212| Step: 0
Training loss: 0.4278498589992523
Validation loss: 1.6251869893843127

Epoch: 6| Step: 1
Training loss: 0.6136165261268616
Validation loss: 1.6358756967770156

Epoch: 6| Step: 2
Training loss: 0.3993705213069916
Validation loss: 1.6141633250380074

Epoch: 6| Step: 3
Training loss: 0.8370032906532288
Validation loss: 1.6470837721260645

Epoch: 6| Step: 4
Training loss: 0.6059558987617493
Validation loss: 1.6583069627003004

Epoch: 6| Step: 5
Training loss: 0.4515794813632965
Validation loss: 1.6997574272976126

Epoch: 6| Step: 6
Training loss: 0.8263019919395447
Validation loss: 1.7305466244297643

Epoch: 6| Step: 7
Training loss: 0.7859715223312378
Validation loss: 1.7226079612649896

Epoch: 6| Step: 8
Training loss: 0.5700790882110596
Validation loss: 1.6951572997595674

Epoch: 6| Step: 9
Training loss: 0.36651527881622314
Validation loss: 1.7059435036874586

Epoch: 6| Step: 10
Training loss: 0.4426800012588501
Validation loss: 1.705522975613994

Epoch: 6| Step: 11
Training loss: 0.49116531014442444
Validation loss: 1.715616617151486

Epoch: 6| Step: 12
Training loss: 0.5245746374130249
Validation loss: 1.7650085828637565

Epoch: 6| Step: 13
Training loss: 0.6657705903053284
Validation loss: 1.7674082645805933

Epoch: 213| Step: 0
Training loss: 0.5684874057769775
Validation loss: 1.8093966566106325

Epoch: 6| Step: 1
Training loss: 0.7635838985443115
Validation loss: 1.8232154692372968

Epoch: 6| Step: 2
Training loss: 0.44637611508369446
Validation loss: 1.810234022396867

Epoch: 6| Step: 3
Training loss: 1.017578363418579
Validation loss: 1.7590723973448559

Epoch: 6| Step: 4
Training loss: 1.0136226415634155
Validation loss: 1.7066995815564228

Epoch: 6| Step: 5
Training loss: 0.3971655070781708
Validation loss: 1.643151298646004

Epoch: 6| Step: 6
Training loss: 0.7305504083633423
Validation loss: 1.6415115043681154

Epoch: 6| Step: 7
Training loss: 0.6567035913467407
Validation loss: 1.6521440590581586

Epoch: 6| Step: 8
Training loss: 0.4280954599380493
Validation loss: 1.6275985830573625

Epoch: 6| Step: 9
Training loss: 0.5053863525390625
Validation loss: 1.687871169018489

Epoch: 6| Step: 10
Training loss: 0.4844370484352112
Validation loss: 1.6802839002301615

Epoch: 6| Step: 11
Training loss: 0.4747227430343628
Validation loss: 1.6976321692107825

Epoch: 6| Step: 12
Training loss: 0.6996245980262756
Validation loss: 1.7116952250080724

Epoch: 6| Step: 13
Training loss: 0.9458762407302856
Validation loss: 1.7061045028830086

Epoch: 214| Step: 0
Training loss: 0.645901083946228
Validation loss: 1.7040083510901338

Epoch: 6| Step: 1
Training loss: 0.6913262009620667
Validation loss: 1.7208244031475437

Epoch: 6| Step: 2
Training loss: 0.8191763162612915
Validation loss: 1.7396802671494023

Epoch: 6| Step: 3
Training loss: 0.6257993578910828
Validation loss: 1.772282717048481

Epoch: 6| Step: 4
Training loss: 0.8150243163108826
Validation loss: 1.7874420970998786

Epoch: 6| Step: 5
Training loss: 0.6596662998199463
Validation loss: 1.8224489022326726

Epoch: 6| Step: 6
Training loss: 0.39739790558815
Validation loss: 1.7763920266141173

Epoch: 6| Step: 7
Training loss: 0.3351699113845825
Validation loss: 1.7093753750606249

Epoch: 6| Step: 8
Training loss: 0.5463587641716003
Validation loss: 1.687271100218578

Epoch: 6| Step: 9
Training loss: 0.47570306062698364
Validation loss: 1.6129739790834405

Epoch: 6| Step: 10
Training loss: 0.7803713083267212
Validation loss: 1.5889437724185247

Epoch: 6| Step: 11
Training loss: 0.413141131401062
Validation loss: 1.6075086183445428

Epoch: 6| Step: 12
Training loss: 0.4819453954696655
Validation loss: 1.6043533279049782

Epoch: 6| Step: 13
Training loss: 0.9398727416992188
Validation loss: 1.6454098237458097

Epoch: 215| Step: 0
Training loss: 0.4338679909706116
Validation loss: 1.6452550939334336

Epoch: 6| Step: 1
Training loss: 0.3939638137817383
Validation loss: 1.6599149947525353

Epoch: 6| Step: 2
Training loss: 0.48357439041137695
Validation loss: 1.6860234058031471

Epoch: 6| Step: 3
Training loss: 0.5324913263320923
Validation loss: 1.6764559553515526

Epoch: 6| Step: 4
Training loss: 0.6037108898162842
Validation loss: 1.6888501708225538

Epoch: 6| Step: 5
Training loss: 0.6930674314498901
Validation loss: 1.6767173659416936

Epoch: 6| Step: 6
Training loss: 0.6883235573768616
Validation loss: 1.7076661099669754

Epoch: 6| Step: 7
Training loss: 0.7426456212997437
Validation loss: 1.6951285344298168

Epoch: 6| Step: 8
Training loss: 0.2603568732738495
Validation loss: 1.7253980969869962

Epoch: 6| Step: 9
Training loss: 0.5182573795318604
Validation loss: 1.7251828665374427

Epoch: 6| Step: 10
Training loss: 0.49017035961151123
Validation loss: 1.7449565613141624

Epoch: 6| Step: 11
Training loss: 0.8547862768173218
Validation loss: 1.744485648729468

Epoch: 6| Step: 12
Training loss: 0.8530709147453308
Validation loss: 1.7663192620841406

Epoch: 6| Step: 13
Training loss: 0.29886582493782043
Validation loss: 1.784796985246802

Epoch: 216| Step: 0
Training loss: 0.8308922052383423
Validation loss: 1.8075285265522618

Epoch: 6| Step: 1
Training loss: 0.6913739442825317
Validation loss: 1.7720066642248502

Epoch: 6| Step: 2
Training loss: 0.5360036492347717
Validation loss: 1.7475819344161658

Epoch: 6| Step: 3
Training loss: 0.3264235258102417
Validation loss: 1.710527422607586

Epoch: 6| Step: 4
Training loss: 0.710092306137085
Validation loss: 1.7038924642788467

Epoch: 6| Step: 5
Training loss: 0.33884960412979126
Validation loss: 1.6978427953617548

Epoch: 6| Step: 6
Training loss: 0.4301999509334564
Validation loss: 1.6912496910300305

Epoch: 6| Step: 7
Training loss: 0.5925849676132202
Validation loss: 1.711181007405763

Epoch: 6| Step: 8
Training loss: 0.5938538312911987
Validation loss: 1.7063498522645684

Epoch: 6| Step: 9
Training loss: 0.34116247296333313
Validation loss: 1.7353297510454733

Epoch: 6| Step: 10
Training loss: 0.37537121772766113
Validation loss: 1.7729964974105998

Epoch: 6| Step: 11
Training loss: 0.9423400163650513
Validation loss: 1.7976028739765126

Epoch: 6| Step: 12
Training loss: 0.9153650999069214
Validation loss: 1.7725477737765158

Epoch: 6| Step: 13
Training loss: 0.26072049140930176
Validation loss: 1.705564679638032

Epoch: 217| Step: 0
Training loss: 0.6348673105239868
Validation loss: 1.6861586173375447

Epoch: 6| Step: 1
Training loss: 0.3978349566459656
Validation loss: 1.6686317651502547

Epoch: 6| Step: 2
Training loss: 0.4587390422821045
Validation loss: 1.6671473826131513

Epoch: 6| Step: 3
Training loss: 0.47166523337364197
Validation loss: 1.6515092311366912

Epoch: 6| Step: 4
Training loss: 0.5386192798614502
Validation loss: 1.6656196117401123

Epoch: 6| Step: 5
Training loss: 0.4136120080947876
Validation loss: 1.7005133282753728

Epoch: 6| Step: 6
Training loss: 0.8789675831794739
Validation loss: 1.6883658170700073

Epoch: 6| Step: 7
Training loss: 0.5005539655685425
Validation loss: 1.6852517102354316

Epoch: 6| Step: 8
Training loss: 0.9424606561660767
Validation loss: 1.6872899865591398

Epoch: 6| Step: 9
Training loss: 0.6086053252220154
Validation loss: 1.681324335836595

Epoch: 6| Step: 10
Training loss: 0.3928106427192688
Validation loss: 1.6801446817254508

Epoch: 6| Step: 11
Training loss: 0.5335503220558167
Validation loss: 1.663275445661237

Epoch: 6| Step: 12
Training loss: 0.49244487285614014
Validation loss: 1.6390571760874924

Epoch: 6| Step: 13
Training loss: 0.5143446326255798
Validation loss: 1.6773973331656507

Epoch: 218| Step: 0
Training loss: 0.6739242076873779
Validation loss: 1.6895354614462903

Epoch: 6| Step: 1
Training loss: 0.47603335976600647
Validation loss: 1.7234704814931399

Epoch: 6| Step: 2
Training loss: 0.8485842943191528
Validation loss: 1.6851196071153045

Epoch: 6| Step: 3
Training loss: 0.5632880926132202
Validation loss: 1.6766110222826722

Epoch: 6| Step: 4
Training loss: 0.43485012650489807
Validation loss: 1.6699575993322557

Epoch: 6| Step: 5
Training loss: 0.40023329854011536
Validation loss: 1.6624341011047363

Epoch: 6| Step: 6
Training loss: 0.5595576167106628
Validation loss: 1.6260318627921484

Epoch: 6| Step: 7
Training loss: 0.37951427698135376
Validation loss: 1.6347457042304419

Epoch: 6| Step: 8
Training loss: 0.5114910006523132
Validation loss: 1.6405016658126668

Epoch: 6| Step: 9
Training loss: 0.602888286113739
Validation loss: 1.6266920111512626

Epoch: 6| Step: 10
Training loss: 0.43632441759109497
Validation loss: 1.653207455911944

Epoch: 6| Step: 11
Training loss: 0.5611060261726379
Validation loss: 1.6654361729980798

Epoch: 6| Step: 12
Training loss: 0.4402865171432495
Validation loss: 1.6556124764104043

Epoch: 6| Step: 13
Training loss: 0.7494205832481384
Validation loss: 1.6776700942747054

Epoch: 219| Step: 0
Training loss: 0.7183761596679688
Validation loss: 1.6267929833422425

Epoch: 6| Step: 1
Training loss: 0.5245931148529053
Validation loss: 1.6156827736926336

Epoch: 6| Step: 2
Training loss: 0.44156697392463684
Validation loss: 1.6347180989480787

Epoch: 6| Step: 3
Training loss: 0.49092182517051697
Validation loss: 1.6747821909125133

Epoch: 6| Step: 4
Training loss: 0.7408052086830139
Validation loss: 1.6985237867601457

Epoch: 6| Step: 5
Training loss: 0.46667248010635376
Validation loss: 1.699691193078154

Epoch: 6| Step: 6
Training loss: 0.37079834938049316
Validation loss: 1.7061180414692048

Epoch: 6| Step: 7
Training loss: 0.44091272354125977
Validation loss: 1.728975349856961

Epoch: 6| Step: 8
Training loss: 0.774128794670105
Validation loss: 1.7422360233081284

Epoch: 6| Step: 9
Training loss: 0.7294871211051941
Validation loss: 1.7429960184199835

Epoch: 6| Step: 10
Training loss: 0.4097924828529358
Validation loss: 1.7220339954540294

Epoch: 6| Step: 11
Training loss: 0.44224387407302856
Validation loss: 1.7289131533715032

Epoch: 6| Step: 12
Training loss: 0.5376284122467041
Validation loss: 1.6615882624862015

Epoch: 6| Step: 13
Training loss: 0.22080694139003754
Validation loss: 1.6720611895284345

Epoch: 220| Step: 0
Training loss: 0.665186882019043
Validation loss: 1.6700481778831893

Epoch: 6| Step: 1
Training loss: 0.6956037878990173
Validation loss: 1.609749779906324

Epoch: 6| Step: 2
Training loss: 0.4846002459526062
Validation loss: 1.5939422717658422

Epoch: 6| Step: 3
Training loss: 0.26698291301727295
Validation loss: 1.56126146675438

Epoch: 6| Step: 4
Training loss: 0.3059138357639313
Validation loss: 1.5491831353915635

Epoch: 6| Step: 5
Training loss: 0.4901203513145447
Validation loss: 1.5433863593686012

Epoch: 6| Step: 6
Training loss: 0.3579385578632355
Validation loss: 1.552176752398091

Epoch: 6| Step: 7
Training loss: 0.323904812335968
Validation loss: 1.5721199845754972

Epoch: 6| Step: 8
Training loss: 0.4553559720516205
Validation loss: 1.624740473685726

Epoch: 6| Step: 9
Training loss: 0.44266876578330994
Validation loss: 1.6699223813190256

Epoch: 6| Step: 10
Training loss: 0.9238985776901245
Validation loss: 1.713848619050877

Epoch: 6| Step: 11
Training loss: 0.5784013271331787
Validation loss: 1.7456647170487272

Epoch: 6| Step: 12
Training loss: 0.3935037851333618
Validation loss: 1.761648428055548

Epoch: 6| Step: 13
Training loss: 1.1108258962631226
Validation loss: 1.769251686270519

Epoch: 221| Step: 0
Training loss: 0.43688133358955383
Validation loss: 1.7947649148202711

Epoch: 6| Step: 1
Training loss: 0.5401008725166321
Validation loss: 1.8164527993048392

Epoch: 6| Step: 2
Training loss: 0.5855757594108582
Validation loss: 1.8139798942432608

Epoch: 6| Step: 3
Training loss: 0.3878197968006134
Validation loss: 1.843752807186496

Epoch: 6| Step: 4
Training loss: 0.48014920949935913
Validation loss: 1.8385597608422721

Epoch: 6| Step: 5
Training loss: 0.6444785594940186
Validation loss: 1.8273019841922227

Epoch: 6| Step: 6
Training loss: 1.0403544902801514
Validation loss: 1.7640289747586815

Epoch: 6| Step: 7
Training loss: 0.491098016500473
Validation loss: 1.6864227428231189

Epoch: 6| Step: 8
Training loss: 0.2859291434288025
Validation loss: 1.650017499923706

Epoch: 6| Step: 9
Training loss: 0.4089275896549225
Validation loss: 1.6097704518225886

Epoch: 6| Step: 10
Training loss: 0.22826725244522095
Validation loss: 1.5844004654115247

Epoch: 6| Step: 11
Training loss: 0.43854549527168274
Validation loss: 1.5429081147716892

Epoch: 6| Step: 12
Training loss: 0.6360780000686646
Validation loss: 1.5770009794542867

Epoch: 6| Step: 13
Training loss: 0.46722540259361267
Validation loss: 1.5763515208357124

Epoch: 222| Step: 0
Training loss: 0.37326958775520325
Validation loss: 1.615398121136491

Epoch: 6| Step: 1
Training loss: 0.6186365485191345
Validation loss: 1.6908644437789917

Epoch: 6| Step: 2
Training loss: 0.4126160144805908
Validation loss: 1.7254470445776497

Epoch: 6| Step: 3
Training loss: 0.5448286533355713
Validation loss: 1.7435126778899983

Epoch: 6| Step: 4
Training loss: 0.6966148614883423
Validation loss: 1.6890301114769393

Epoch: 6| Step: 5
Training loss: 0.28635603189468384
Validation loss: 1.7169761298805155

Epoch: 6| Step: 6
Training loss: 0.45720231533050537
Validation loss: 1.6817840606935563

Epoch: 6| Step: 7
Training loss: 0.5520002841949463
Validation loss: 1.6546750683938303

Epoch: 6| Step: 8
Training loss: 0.7448393106460571
Validation loss: 1.6445521834076091

Epoch: 6| Step: 9
Training loss: 0.7584620118141174
Validation loss: 1.6266613634683753

Epoch: 6| Step: 10
Training loss: 0.5238924026489258
Validation loss: 1.6154629306126667

Epoch: 6| Step: 11
Training loss: 0.5413087606430054
Validation loss: 1.6078823830491753

Epoch: 6| Step: 12
Training loss: 0.6049989461898804
Validation loss: 1.6030130847807853

Epoch: 6| Step: 13
Training loss: 0.8630739450454712
Validation loss: 1.6296367875991329

Epoch: 223| Step: 0
Training loss: 0.4485723078250885
Validation loss: 1.635134131677689

Epoch: 6| Step: 1
Training loss: 0.46972352266311646
Validation loss: 1.6764576781180598

Epoch: 6| Step: 2
Training loss: 0.4045856297016144
Validation loss: 1.7050939131808538

Epoch: 6| Step: 3
Training loss: 0.40248703956604004
Validation loss: 1.671991377748469

Epoch: 6| Step: 4
Training loss: 0.38730376958847046
Validation loss: 1.6453470619775916

Epoch: 6| Step: 5
Training loss: 0.5484232902526855
Validation loss: 1.6017907255439348

Epoch: 6| Step: 6
Training loss: 0.7317593097686768
Validation loss: 1.6187078901516494

Epoch: 6| Step: 7
Training loss: 0.7262609004974365
Validation loss: 1.60951740254638

Epoch: 6| Step: 8
Training loss: 0.6553506851196289
Validation loss: 1.6002335740673927

Epoch: 6| Step: 9
Training loss: 0.3354712128639221
Validation loss: 1.592679706952905

Epoch: 6| Step: 10
Training loss: 0.4976084232330322
Validation loss: 1.586122666635821

Epoch: 6| Step: 11
Training loss: 0.8445343375205994
Validation loss: 1.6086984462635492

Epoch: 6| Step: 12
Training loss: 0.43819981813430786
Validation loss: 1.6165605437371038

Epoch: 6| Step: 13
Training loss: 0.9079635143280029
Validation loss: 1.6103289229895479

Epoch: 224| Step: 0
Training loss: 0.39599400758743286
Validation loss: 1.630214516834546

Epoch: 6| Step: 1
Training loss: 0.19194462895393372
Validation loss: 1.6716769510699856

Epoch: 6| Step: 2
Training loss: 0.6406527757644653
Validation loss: 1.6537888896080755

Epoch: 6| Step: 3
Training loss: 0.5113596320152283
Validation loss: 1.6737230208612257

Epoch: 6| Step: 4
Training loss: 0.5043215751647949
Validation loss: 1.6662028989484232

Epoch: 6| Step: 5
Training loss: 0.6007514595985413
Validation loss: 1.7171018482536398

Epoch: 6| Step: 6
Training loss: 0.5304579734802246
Validation loss: 1.6871236588365288

Epoch: 6| Step: 7
Training loss: 0.251586377620697
Validation loss: 1.6649827790516678

Epoch: 6| Step: 8
Training loss: 0.41050785779953003
Validation loss: 1.634993927453154

Epoch: 6| Step: 9
Training loss: 0.3834850788116455
Validation loss: 1.599809681215594

Epoch: 6| Step: 10
Training loss: 1.1326035261154175
Validation loss: 1.5925828429960436

Epoch: 6| Step: 11
Training loss: 0.6356528401374817
Validation loss: 1.5679420963410409

Epoch: 6| Step: 12
Training loss: 0.2735067307949066
Validation loss: 1.5745652901229037

Epoch: 6| Step: 13
Training loss: 0.35752272605895996
Validation loss: 1.586917979742891

Epoch: 225| Step: 0
Training loss: 0.4548787474632263
Validation loss: 1.6463526846260153

Epoch: 6| Step: 1
Training loss: 0.6516594290733337
Validation loss: 1.6416061616713

Epoch: 6| Step: 2
Training loss: 0.2438560128211975
Validation loss: 1.6493914217077277

Epoch: 6| Step: 3
Training loss: 0.23834478855133057
Validation loss: 1.6575610022391043

Epoch: 6| Step: 4
Training loss: 0.7713905572891235
Validation loss: 1.6827707226558397

Epoch: 6| Step: 5
Training loss: 0.3021925091743469
Validation loss: 1.638533212805307

Epoch: 6| Step: 6
Training loss: 0.5866992473602295
Validation loss: 1.6292837140380696

Epoch: 6| Step: 7
Training loss: 0.35018599033355713
Validation loss: 1.629497262739366

Epoch: 6| Step: 8
Training loss: 0.7799227833747864
Validation loss: 1.6242952731347853

Epoch: 6| Step: 9
Training loss: 0.5579659342765808
Validation loss: 1.6248693081640428

Epoch: 6| Step: 10
Training loss: 0.6572712659835815
Validation loss: 1.699647395841537

Epoch: 6| Step: 11
Training loss: 0.3508009910583496
Validation loss: 1.695091273195

Epoch: 6| Step: 12
Training loss: 0.5615406632423401
Validation loss: 1.7136912243340605

Epoch: 6| Step: 13
Training loss: 0.8198858499526978
Validation loss: 1.7111379536249305

Epoch: 226| Step: 0
Training loss: 0.4751245975494385
Validation loss: 1.6604697447951122

Epoch: 6| Step: 1
Training loss: 0.4737279415130615
Validation loss: 1.6490783870861094

Epoch: 6| Step: 2
Training loss: 0.41745999455451965
Validation loss: 1.619792543431764

Epoch: 6| Step: 3
Training loss: 0.5080995559692383
Validation loss: 1.586716369916034

Epoch: 6| Step: 4
Training loss: 0.3166813254356384
Validation loss: 1.6196642998726136

Epoch: 6| Step: 5
Training loss: 0.3124557137489319
Validation loss: 1.595803153130316

Epoch: 6| Step: 6
Training loss: 0.5671131610870361
Validation loss: 1.6292708125165714

Epoch: 6| Step: 7
Training loss: 0.5643589496612549
Validation loss: 1.6686805525133688

Epoch: 6| Step: 8
Training loss: 0.6052619814872742
Validation loss: 1.6402088262701546

Epoch: 6| Step: 9
Training loss: 0.9728506207466125
Validation loss: 1.6668300218479608

Epoch: 6| Step: 10
Training loss: 0.6724448204040527
Validation loss: 1.63323563145053

Epoch: 6| Step: 11
Training loss: 0.5183788537979126
Validation loss: 1.6175337414587698

Epoch: 6| Step: 12
Training loss: 0.3611949682235718
Validation loss: 1.6171936065919938

Epoch: 6| Step: 13
Training loss: 0.5561527609825134
Validation loss: 1.6381647240731023

Epoch: 227| Step: 0
Training loss: 0.9128514528274536
Validation loss: 1.6855102828753892

Epoch: 6| Step: 1
Training loss: 0.5368384718894958
Validation loss: 1.7078294651482695

Epoch: 6| Step: 2
Training loss: 0.6379258036613464
Validation loss: 1.731400833334974

Epoch: 6| Step: 3
Training loss: 0.4040628671646118
Validation loss: 1.7202060402080577

Epoch: 6| Step: 4
Training loss: 0.2916477918624878
Validation loss: 1.732426574153285

Epoch: 6| Step: 5
Training loss: 0.6154646873474121
Validation loss: 1.7584838213459137

Epoch: 6| Step: 6
Training loss: 0.6805304288864136
Validation loss: 1.7436885180011872

Epoch: 6| Step: 7
Training loss: 0.34571459889411926
Validation loss: 1.7375469489764142

Epoch: 6| Step: 8
Training loss: 0.4111025035381317
Validation loss: 1.76892134194733

Epoch: 6| Step: 9
Training loss: 0.4136238992214203
Validation loss: 1.7454406753663094

Epoch: 6| Step: 10
Training loss: 0.2664263844490051
Validation loss: 1.697140274509307

Epoch: 6| Step: 11
Training loss: 0.6613606214523315
Validation loss: 1.6547393747555312

Epoch: 6| Step: 12
Training loss: 0.27689462900161743
Validation loss: 1.6161630627929524

Epoch: 6| Step: 13
Training loss: 0.4654838740825653
Validation loss: 1.6436626436889812

Epoch: 228| Step: 0
Training loss: 0.6503379344940186
Validation loss: 1.6410267391512472

Epoch: 6| Step: 1
Training loss: 0.5505013465881348
Validation loss: 1.646543413080195

Epoch: 6| Step: 2
Training loss: 0.5158717632293701
Validation loss: 1.679252222020139

Epoch: 6| Step: 3
Training loss: 0.2596890926361084
Validation loss: 1.6516936620076497

Epoch: 6| Step: 4
Training loss: 0.39461418986320496
Validation loss: 1.6544550490635697

Epoch: 6| Step: 5
Training loss: 0.6087939739227295
Validation loss: 1.6723867590709398

Epoch: 6| Step: 6
Training loss: 0.5396867990493774
Validation loss: 1.658104770927019

Epoch: 6| Step: 7
Training loss: 0.6741370558738708
Validation loss: 1.6218110489588913

Epoch: 6| Step: 8
Training loss: 0.546608030796051
Validation loss: 1.6239502750417238

Epoch: 6| Step: 9
Training loss: 0.4113069176673889
Validation loss: 1.5811927331391202

Epoch: 6| Step: 10
Training loss: 0.5470221042633057
Validation loss: 1.606280816498623

Epoch: 6| Step: 11
Training loss: 0.38510268926620483
Validation loss: 1.6410532093817187

Epoch: 6| Step: 12
Training loss: 0.48189377784729004
Validation loss: 1.6328603734252274

Epoch: 6| Step: 13
Training loss: 0.39764833450317383
Validation loss: 1.6483983032165035

Epoch: 229| Step: 0
Training loss: 0.5687705278396606
Validation loss: 1.6723002387631325

Epoch: 6| Step: 1
Training loss: 0.8289268612861633
Validation loss: 1.6863965892022657

Epoch: 6| Step: 2
Training loss: 0.5630530118942261
Validation loss: 1.7126804936316706

Epoch: 6| Step: 3
Training loss: 0.450275182723999
Validation loss: 1.7084212405707246

Epoch: 6| Step: 4
Training loss: 0.3107255697250366
Validation loss: 1.7106401510136102

Epoch: 6| Step: 5
Training loss: 0.3753686249256134
Validation loss: 1.68179073128649

Epoch: 6| Step: 6
Training loss: 0.3569485545158386
Validation loss: 1.6492173966541086

Epoch: 6| Step: 7
Training loss: 0.6744855046272278
Validation loss: 1.6335744819333475

Epoch: 6| Step: 8
Training loss: 0.5911246538162231
Validation loss: 1.6108901128974011

Epoch: 6| Step: 9
Training loss: 0.2988004684448242
Validation loss: 1.57151077383308

Epoch: 6| Step: 10
Training loss: 0.5250654220581055
Validation loss: 1.604039276799848

Epoch: 6| Step: 11
Training loss: 0.5184686183929443
Validation loss: 1.6061537265777588

Epoch: 6| Step: 12
Training loss: 0.36569714546203613
Validation loss: 1.5962017274671985

Epoch: 6| Step: 13
Training loss: 0.59864741563797
Validation loss: 1.6156330377824846

Epoch: 230| Step: 0
Training loss: 0.8292404413223267
Validation loss: 1.6542181122687556

Epoch: 6| Step: 1
Training loss: 0.5709021687507629
Validation loss: 1.7073229294951244

Epoch: 6| Step: 2
Training loss: 0.4529057443141937
Validation loss: 1.7443895647602696

Epoch: 6| Step: 3
Training loss: 0.5933992266654968
Validation loss: 1.6915611067125875

Epoch: 6| Step: 4
Training loss: 0.262818843126297
Validation loss: 1.7056919028682094

Epoch: 6| Step: 5
Training loss: 0.2902868092060089
Validation loss: 1.6896808006430184

Epoch: 6| Step: 6
Training loss: 0.21689856052398682
Validation loss: 1.6727108237563924

Epoch: 6| Step: 7
Training loss: 0.5385231971740723
Validation loss: 1.6877495627249441

Epoch: 6| Step: 8
Training loss: 0.4444124698638916
Validation loss: 1.6681474831796461

Epoch: 6| Step: 9
Training loss: 0.46380239725112915
Validation loss: 1.6346285496988604

Epoch: 6| Step: 10
Training loss: 0.6437041163444519
Validation loss: 1.6195885930010068

Epoch: 6| Step: 11
Training loss: 0.5767512321472168
Validation loss: 1.6541924220259472

Epoch: 6| Step: 12
Training loss: 0.40279480814933777
Validation loss: 1.6667624788899575

Epoch: 6| Step: 13
Training loss: 0.32761988043785095
Validation loss: 1.6584358638332737

Epoch: 231| Step: 0
Training loss: 0.7175477743148804
Validation loss: 1.7046275318309825

Epoch: 6| Step: 1
Training loss: 0.2386501282453537
Validation loss: 1.6572275777016916

Epoch: 6| Step: 2
Training loss: 0.4471628963947296
Validation loss: 1.606638071357563

Epoch: 6| Step: 3
Training loss: 0.4005664587020874
Validation loss: 1.6359998974748837

Epoch: 6| Step: 4
Training loss: 0.417171835899353
Validation loss: 1.6609319320289038

Epoch: 6| Step: 5
Training loss: 0.49351853132247925
Validation loss: 1.6462506760833084

Epoch: 6| Step: 6
Training loss: 0.32043808698654175
Validation loss: 1.649966452711372

Epoch: 6| Step: 7
Training loss: 0.5553559064865112
Validation loss: 1.6639679375515188

Epoch: 6| Step: 8
Training loss: 0.5483702421188354
Validation loss: 1.6711248838773338

Epoch: 6| Step: 9
Training loss: 0.5669491291046143
Validation loss: 1.6612569068067817

Epoch: 6| Step: 10
Training loss: 0.35458728671073914
Validation loss: 1.6480053932436052

Epoch: 6| Step: 11
Training loss: 0.7650471925735474
Validation loss: 1.641388991827606

Epoch: 6| Step: 12
Training loss: 0.5842458009719849
Validation loss: 1.6744404685112737

Epoch: 6| Step: 13
Training loss: 0.11432819813489914
Validation loss: 1.6967579241721862

Epoch: 232| Step: 0
Training loss: 0.7443307638168335
Validation loss: 1.7494804141342

Epoch: 6| Step: 1
Training loss: 0.31003138422966003
Validation loss: 1.746388566109442

Epoch: 6| Step: 2
Training loss: 0.48322904109954834
Validation loss: 1.7362232900434924

Epoch: 6| Step: 3
Training loss: 0.43790963292121887
Validation loss: 1.7357749349327498

Epoch: 6| Step: 4
Training loss: 0.38786858320236206
Validation loss: 1.712805437785323

Epoch: 6| Step: 5
Training loss: 0.42954403162002563
Validation loss: 1.7096719293184177

Epoch: 6| Step: 6
Training loss: 0.6850260496139526
Validation loss: 1.7165849875378352

Epoch: 6| Step: 7
Training loss: 0.3345641493797302
Validation loss: 1.6678939198934903

Epoch: 6| Step: 8
Training loss: 0.3134438991546631
Validation loss: 1.6597784872977965

Epoch: 6| Step: 9
Training loss: 0.6224088668823242
Validation loss: 1.656114366746718

Epoch: 6| Step: 10
Training loss: 0.4259585738182068
Validation loss: 1.6319708080701931

Epoch: 6| Step: 11
Training loss: 0.31695887446403503
Validation loss: 1.6397186376715218

Epoch: 6| Step: 12
Training loss: 0.5970913171768188
Validation loss: 1.639590564594474

Epoch: 6| Step: 13
Training loss: 0.3217475414276123
Validation loss: 1.615491203082505

Epoch: 233| Step: 0
Training loss: 0.5889934301376343
Validation loss: 1.6138330005830335

Epoch: 6| Step: 1
Training loss: 0.29378610849380493
Validation loss: 1.624850788424092

Epoch: 6| Step: 2
Training loss: 0.17974238097667694
Validation loss: 1.6049881994083364

Epoch: 6| Step: 3
Training loss: 0.5282562375068665
Validation loss: 1.634097578704998

Epoch: 6| Step: 4
Training loss: 0.3634817898273468
Validation loss: 1.6275433391653082

Epoch: 6| Step: 5
Training loss: 0.4103090763092041
Validation loss: 1.6456241889666485

Epoch: 6| Step: 6
Training loss: 0.5214118957519531
Validation loss: 1.6627910290994952

Epoch: 6| Step: 7
Training loss: 0.41067880392074585
Validation loss: 1.652461859487718

Epoch: 6| Step: 8
Training loss: 0.7259666323661804
Validation loss: 1.6894561789369071

Epoch: 6| Step: 9
Training loss: 0.32365792989730835
Validation loss: 1.720181087011932

Epoch: 6| Step: 10
Training loss: 0.49207085371017456
Validation loss: 1.7268425828667098

Epoch: 6| Step: 11
Training loss: 0.4336111843585968
Validation loss: 1.7567532857259114

Epoch: 6| Step: 12
Training loss: 0.5736206769943237
Validation loss: 1.7528064379128077

Epoch: 6| Step: 13
Training loss: 0.21615654230117798
Validation loss: 1.7358652814742057

Epoch: 234| Step: 0
Training loss: 0.38976794481277466
Validation loss: 1.721617252595963

Epoch: 6| Step: 1
Training loss: 0.5602819323539734
Validation loss: 1.6812547432479037

Epoch: 6| Step: 2
Training loss: 0.2790079116821289
Validation loss: 1.658001539527729

Epoch: 6| Step: 3
Training loss: 0.48160403966903687
Validation loss: 1.6727259915362123

Epoch: 6| Step: 4
Training loss: 0.6715967059135437
Validation loss: 1.6548663800762546

Epoch: 6| Step: 5
Training loss: 0.534024178981781
Validation loss: 1.615166465441386

Epoch: 6| Step: 6
Training loss: 0.5341930389404297
Validation loss: 1.614796068078728

Epoch: 6| Step: 7
Training loss: 0.36695557832717896
Validation loss: 1.6339596881661365

Epoch: 6| Step: 8
Training loss: 0.2373548150062561
Validation loss: 1.6669128312859485

Epoch: 6| Step: 9
Training loss: 0.48278555274009705
Validation loss: 1.6277905907682193

Epoch: 6| Step: 10
Training loss: 0.49746397137641907
Validation loss: 1.661391491531044

Epoch: 6| Step: 11
Training loss: 0.35994791984558105
Validation loss: 1.6766619528493574

Epoch: 6| Step: 12
Training loss: 0.4984110891819
Validation loss: 1.6396320545545189

Epoch: 6| Step: 13
Training loss: 0.3231140971183777
Validation loss: 1.61130509068889

Epoch: 235| Step: 0
Training loss: 0.7143716812133789
Validation loss: 1.595005673746909

Epoch: 6| Step: 1
Training loss: 0.5102692246437073
Validation loss: 1.574250962144585

Epoch: 6| Step: 2
Training loss: 0.28981316089630127
Validation loss: 1.56521108201755

Epoch: 6| Step: 3
Training loss: 0.4621245563030243
Validation loss: 1.6178730713423861

Epoch: 6| Step: 4
Training loss: 0.7536345720291138
Validation loss: 1.5924342498984387

Epoch: 6| Step: 5
Training loss: 0.3539600372314453
Validation loss: 1.6020842547057776

Epoch: 6| Step: 6
Training loss: 0.2592182457447052
Validation loss: 1.5971219949824835

Epoch: 6| Step: 7
Training loss: 0.33381932973861694
Validation loss: 1.5847996306675736

Epoch: 6| Step: 8
Training loss: 0.5471841096878052
Validation loss: 1.5836920366492322

Epoch: 6| Step: 9
Training loss: 0.20013350248336792
Validation loss: 1.6000468500198857

Epoch: 6| Step: 10
Training loss: 0.5244268178939819
Validation loss: 1.6154725320877568

Epoch: 6| Step: 11
Training loss: 0.27530592679977417
Validation loss: 1.6460853238259592

Epoch: 6| Step: 12
Training loss: 0.34480202198028564
Validation loss: 1.6297171917012943

Epoch: 6| Step: 13
Training loss: 0.19572274386882782
Validation loss: 1.6198320542612383

Epoch: 236| Step: 0
Training loss: 0.5684380531311035
Validation loss: 1.645203867266255

Epoch: 6| Step: 1
Training loss: 0.402616411447525
Validation loss: 1.6725900019368818

Epoch: 6| Step: 2
Training loss: 0.36626437306404114
Validation loss: 1.6727475376539334

Epoch: 6| Step: 3
Training loss: 0.30799224972724915
Validation loss: 1.681406464627994

Epoch: 6| Step: 4
Training loss: 0.33474916219711304
Validation loss: 1.6942665089843094

Epoch: 6| Step: 5
Training loss: 0.3870764374732971
Validation loss: 1.6744759390431065

Epoch: 6| Step: 6
Training loss: 0.41935595870018005
Validation loss: 1.65700392312901

Epoch: 6| Step: 7
Training loss: 0.2427750676870346
Validation loss: 1.6509635063909716

Epoch: 6| Step: 8
Training loss: 0.5906792879104614
Validation loss: 1.6269150651911253

Epoch: 6| Step: 9
Training loss: 0.4471203684806824
Validation loss: 1.616072759833387

Epoch: 6| Step: 10
Training loss: 0.21400633454322815
Validation loss: 1.591966308573241

Epoch: 6| Step: 11
Training loss: 0.7395743131637573
Validation loss: 1.5982129343094365

Epoch: 6| Step: 12
Training loss: 0.37588241696357727
Validation loss: 1.6243400086638748

Epoch: 6| Step: 13
Training loss: 0.7470133900642395
Validation loss: 1.650111961108382

Epoch: 237| Step: 0
Training loss: 0.5530853271484375
Validation loss: 1.6440104464048981

Epoch: 6| Step: 1
Training loss: 0.470176637172699
Validation loss: 1.660016123966504

Epoch: 6| Step: 2
Training loss: 0.4314795434474945
Validation loss: 1.6679199152095343

Epoch: 6| Step: 3
Training loss: 0.6172934770584106
Validation loss: 1.644630475710797

Epoch: 6| Step: 4
Training loss: 0.37869828939437866
Validation loss: 1.641474009842001

Epoch: 6| Step: 5
Training loss: 0.33375653624534607
Validation loss: 1.6038985918926936

Epoch: 6| Step: 6
Training loss: 0.44600749015808105
Validation loss: 1.6083162651267102

Epoch: 6| Step: 7
Training loss: 0.4188051223754883
Validation loss: 1.5986979315357823

Epoch: 6| Step: 8
Training loss: 0.3107798993587494
Validation loss: 1.5980313452341224

Epoch: 6| Step: 9
Training loss: 0.41067373752593994
Validation loss: 1.6190247484432754

Epoch: 6| Step: 10
Training loss: 0.759702205657959
Validation loss: 1.6077245710998453

Epoch: 6| Step: 11
Training loss: 0.49972882866859436
Validation loss: 1.6438565972030803

Epoch: 6| Step: 12
Training loss: 0.39661890268325806
Validation loss: 1.6523106854449037

Epoch: 6| Step: 13
Training loss: 0.16122430562973022
Validation loss: 1.6548576931799612

Epoch: 238| Step: 0
Training loss: 0.4612618684768677
Validation loss: 1.7052968125189505

Epoch: 6| Step: 1
Training loss: 0.26450425386428833
Validation loss: 1.7625104714465398

Epoch: 6| Step: 2
Training loss: 0.5474277138710022
Validation loss: 1.7778985218335224

Epoch: 6| Step: 3
Training loss: 0.4148383140563965
Validation loss: 1.783469982044671

Epoch: 6| Step: 4
Training loss: 0.2962453067302704
Validation loss: 1.7929810990569413

Epoch: 6| Step: 5
Training loss: 0.8082108497619629
Validation loss: 1.7339372686160508

Epoch: 6| Step: 6
Training loss: 0.3964223861694336
Validation loss: 1.6819382508595784

Epoch: 6| Step: 7
Training loss: 0.6597890853881836
Validation loss: 1.6654088022888347

Epoch: 6| Step: 8
Training loss: 0.41127556562423706
Validation loss: 1.6608043985982095

Epoch: 6| Step: 9
Training loss: 0.4676452577114105
Validation loss: 1.619099627258957

Epoch: 6| Step: 10
Training loss: 0.3141176104545593
Validation loss: 1.6320528868705995

Epoch: 6| Step: 11
Training loss: 0.5188676118850708
Validation loss: 1.605784910981373

Epoch: 6| Step: 12
Training loss: 0.41707903146743774
Validation loss: 1.601353596615535

Epoch: 6| Step: 13
Training loss: 0.57171231508255
Validation loss: 1.6272409295523038

Epoch: 239| Step: 0
Training loss: 0.40040287375450134
Validation loss: 1.6133718567509805

Epoch: 6| Step: 1
Training loss: 0.4795612394809723
Validation loss: 1.603015236957099

Epoch: 6| Step: 2
Training loss: 0.44452914595603943
Validation loss: 1.6191688096651466

Epoch: 6| Step: 3
Training loss: 0.4099414050579071
Validation loss: 1.612508379003053

Epoch: 6| Step: 4
Training loss: 0.306735634803772
Validation loss: 1.629576458725878

Epoch: 6| Step: 5
Training loss: 0.5921236276626587
Validation loss: 1.610005533823403

Epoch: 6| Step: 6
Training loss: 0.4006584882736206
Validation loss: 1.6058886192178214

Epoch: 6| Step: 7
Training loss: 0.3092976212501526
Validation loss: 1.59430984527834

Epoch: 6| Step: 8
Training loss: 0.6723878383636475
Validation loss: 1.5999549268394389

Epoch: 6| Step: 9
Training loss: 0.17764434218406677
Validation loss: 1.6093580799718057

Epoch: 6| Step: 10
Training loss: 0.6907017827033997
Validation loss: 1.6198757668977142

Epoch: 6| Step: 11
Training loss: 0.6121107339859009
Validation loss: 1.6759829059723885

Epoch: 6| Step: 12
Training loss: 0.2601880729198456
Validation loss: 1.7120202408042005

Epoch: 6| Step: 13
Training loss: 0.17853806912899017
Validation loss: 1.7183495388236096

Epoch: 240| Step: 0
Training loss: 0.3529825210571289
Validation loss: 1.7158904844714749

Epoch: 6| Step: 1
Training loss: 0.3351063132286072
Validation loss: 1.7296490624386778

Epoch: 6| Step: 2
Training loss: 0.3629286587238312
Validation loss: 1.6921935004572715

Epoch: 6| Step: 3
Training loss: 0.200041726231575
Validation loss: 1.6596394559388519

Epoch: 6| Step: 4
Training loss: 0.45065081119537354
Validation loss: 1.611851812690817

Epoch: 6| Step: 5
Training loss: 0.4687623381614685
Validation loss: 1.5977079817043838

Epoch: 6| Step: 6
Training loss: 0.39770543575286865
Validation loss: 1.5885747696763726

Epoch: 6| Step: 7
Training loss: 0.21964524686336517
Validation loss: 1.6045467956091768

Epoch: 6| Step: 8
Training loss: 0.37110328674316406
Validation loss: 1.6069655097940916

Epoch: 6| Step: 9
Training loss: 0.39742833375930786
Validation loss: 1.632156350279367

Epoch: 6| Step: 10
Training loss: 0.30935072898864746
Validation loss: 1.662691491906361

Epoch: 6| Step: 11
Training loss: 0.4351453185081482
Validation loss: 1.687082818759385

Epoch: 6| Step: 12
Training loss: 0.8244199752807617
Validation loss: 1.7079827657309912

Epoch: 6| Step: 13
Training loss: 0.7411834597587585
Validation loss: 1.685326890278888

Epoch: 241| Step: 0
Training loss: 0.5402090549468994
Validation loss: 1.700503223685808

Epoch: 6| Step: 1
Training loss: 0.47015801072120667
Validation loss: 1.687202436949617

Epoch: 6| Step: 2
Training loss: 0.3728901743888855
Validation loss: 1.6668842454110422

Epoch: 6| Step: 3
Training loss: 0.4157755970954895
Validation loss: 1.6432505602477698

Epoch: 6| Step: 4
Training loss: 0.368073046207428
Validation loss: 1.6522057569155129

Epoch: 6| Step: 5
Training loss: 0.36212295293807983
Validation loss: 1.623827043400016

Epoch: 6| Step: 6
Training loss: 0.4199475049972534
Validation loss: 1.6166375196108254

Epoch: 6| Step: 7
Training loss: 0.5732960104942322
Validation loss: 1.6334458205007738

Epoch: 6| Step: 8
Training loss: 0.36383989453315735
Validation loss: 1.6186827664734216

Epoch: 6| Step: 9
Training loss: 0.2494019716978073
Validation loss: 1.6264307627113916

Epoch: 6| Step: 10
Training loss: 0.25711509585380554
Validation loss: 1.5926201330718173

Epoch: 6| Step: 11
Training loss: 0.7454245090484619
Validation loss: 1.5872244309353571

Epoch: 6| Step: 12
Training loss: 0.3961096405982971
Validation loss: 1.6154819752580376

Epoch: 6| Step: 13
Training loss: 0.2438226342201233
Validation loss: 1.5972837956361874

Epoch: 242| Step: 0
Training loss: 0.34340447187423706
Validation loss: 1.5963766805587276

Epoch: 6| Step: 1
Training loss: 0.23750603199005127
Validation loss: 1.6207176818642566

Epoch: 6| Step: 2
Training loss: 0.7354506850242615
Validation loss: 1.622807889856318

Epoch: 6| Step: 3
Training loss: 0.7272340655326843
Validation loss: 1.6428447666988577

Epoch: 6| Step: 4
Training loss: 0.57903653383255
Validation loss: 1.6405616806399437

Epoch: 6| Step: 5
Training loss: 0.32777804136276245
Validation loss: 1.6253780523935955

Epoch: 6| Step: 6
Training loss: 0.2461937814950943
Validation loss: 1.5854339150972263

Epoch: 6| Step: 7
Training loss: 0.3548888564109802
Validation loss: 1.6121026687724616

Epoch: 6| Step: 8
Training loss: 0.22472302615642548
Validation loss: 1.6039452809159473

Epoch: 6| Step: 9
Training loss: 0.39906150102615356
Validation loss: 1.5162008693141322

Epoch: 6| Step: 10
Training loss: 0.4102558493614197
Validation loss: 1.5393454182532527

Epoch: 6| Step: 11
Training loss: 0.2826813757419586
Validation loss: 1.5420716090868878

Epoch: 6| Step: 12
Training loss: 0.3485587239265442
Validation loss: 1.5242653226339689

Epoch: 6| Step: 13
Training loss: 0.3880825340747833
Validation loss: 1.5524972318321146

Epoch: 243| Step: 0
Training loss: 0.5619821548461914
Validation loss: 1.5965913995619743

Epoch: 6| Step: 1
Training loss: 0.3137935400009155
Validation loss: 1.5873182524916947

Epoch: 6| Step: 2
Training loss: 0.3826759457588196
Validation loss: 1.583671796706415

Epoch: 6| Step: 3
Training loss: 0.2272603064775467
Validation loss: 1.6309271768857074

Epoch: 6| Step: 4
Training loss: 0.48868101835250854
Validation loss: 1.5914559518137286

Epoch: 6| Step: 5
Training loss: 0.6013549566268921
Validation loss: 1.658678000973117

Epoch: 6| Step: 6
Training loss: 0.35372042655944824
Validation loss: 1.6356695236698273

Epoch: 6| Step: 7
Training loss: 0.5155506134033203
Validation loss: 1.612678191995108

Epoch: 6| Step: 8
Training loss: 0.511992335319519
Validation loss: 1.5997048430545355

Epoch: 6| Step: 9
Training loss: 0.4201081395149231
Validation loss: 1.5987943218600364

Epoch: 6| Step: 10
Training loss: 0.380612313747406
Validation loss: 1.6012451751257784

Epoch: 6| Step: 11
Training loss: 0.3846423327922821
Validation loss: 1.5935559170220488

Epoch: 6| Step: 12
Training loss: 0.2589375376701355
Validation loss: 1.6180214317896033

Epoch: 6| Step: 13
Training loss: 0.6015563607215881
Validation loss: 1.5821384499149937

Epoch: 244| Step: 0
Training loss: 0.35581958293914795
Validation loss: 1.6137400878373014

Epoch: 6| Step: 1
Training loss: 0.3283799886703491
Validation loss: 1.6198403399477723

Epoch: 6| Step: 2
Training loss: 0.23191744089126587
Validation loss: 1.66118485184126

Epoch: 6| Step: 3
Training loss: 0.3894793689250946
Validation loss: 1.678583183596211

Epoch: 6| Step: 4
Training loss: 0.4451265037059784
Validation loss: 1.68188355558662

Epoch: 6| Step: 5
Training loss: 0.5136520266532898
Validation loss: 1.6724733973062167

Epoch: 6| Step: 6
Training loss: 0.4043446183204651
Validation loss: 1.707901229140579

Epoch: 6| Step: 7
Training loss: 0.3669794499874115
Validation loss: 1.729126335472189

Epoch: 6| Step: 8
Training loss: 0.6039988398551941
Validation loss: 1.706161606696344

Epoch: 6| Step: 9
Training loss: 0.38639718294143677
Validation loss: 1.700684194923729

Epoch: 6| Step: 10
Training loss: 0.5300268530845642
Validation loss: 1.6384778945676741

Epoch: 6| Step: 11
Training loss: 0.3663020431995392
Validation loss: 1.6149305335937008

Epoch: 6| Step: 12
Training loss: 0.8195719718933105
Validation loss: 1.600650538680374

Epoch: 6| Step: 13
Training loss: 0.4294806718826294
Validation loss: 1.5465026837523266

Epoch: 245| Step: 0
Training loss: 0.40964218974113464
Validation loss: 1.560894553379346

Epoch: 6| Step: 1
Training loss: 0.3283498287200928
Validation loss: 1.5569613338798605

Epoch: 6| Step: 2
Training loss: 0.2727084457874298
Validation loss: 1.52249619524966

Epoch: 6| Step: 3
Training loss: 0.4280845522880554
Validation loss: 1.5389531312450286

Epoch: 6| Step: 4
Training loss: 0.26343944668769836
Validation loss: 1.5649636996689664

Epoch: 6| Step: 5
Training loss: 0.5410945415496826
Validation loss: 1.5589249300700363

Epoch: 6| Step: 6
Training loss: 0.4771016836166382
Validation loss: 1.554552150029008

Epoch: 6| Step: 7
Training loss: 0.3507550358772278
Validation loss: 1.5868820503193846

Epoch: 6| Step: 8
Training loss: 0.6448312997817993
Validation loss: 1.577757598251425

Epoch: 6| Step: 9
Training loss: 0.33857935667037964
Validation loss: 1.6131145543949579

Epoch: 6| Step: 10
Training loss: 0.544255256652832
Validation loss: 1.6305770271567888

Epoch: 6| Step: 11
Training loss: 0.6101891398429871
Validation loss: 1.6530837205148512

Epoch: 6| Step: 12
Training loss: 0.40936964750289917
Validation loss: 1.6230157780390915

Epoch: 6| Step: 13
Training loss: 0.2582254409790039
Validation loss: 1.6205893857504732

Epoch: 246| Step: 0
Training loss: 0.41684192419052124
Validation loss: 1.593585483489498

Epoch: 6| Step: 1
Training loss: 0.48589015007019043
Validation loss: 1.5644485155741374

Epoch: 6| Step: 2
Training loss: 0.2644067108631134
Validation loss: 1.5460928781058199

Epoch: 6| Step: 3
Training loss: 0.24707140028476715
Validation loss: 1.5611893079614128

Epoch: 6| Step: 4
Training loss: 0.4558808207511902
Validation loss: 1.5615420559401154

Epoch: 6| Step: 5
Training loss: 0.2845243215560913
Validation loss: 1.5984272828666113

Epoch: 6| Step: 6
Training loss: 0.43552166223526
Validation loss: 1.5828720497828659

Epoch: 6| Step: 7
Training loss: 0.5147494673728943
Validation loss: 1.605126364256746

Epoch: 6| Step: 8
Training loss: 0.9676954746246338
Validation loss: 1.6082698375948015

Epoch: 6| Step: 9
Training loss: 0.2590104043483734
Validation loss: 1.6141865330357705

Epoch: 6| Step: 10
Training loss: 0.5502508282661438
Validation loss: 1.6079520512652654

Epoch: 6| Step: 11
Training loss: 0.5993449091911316
Validation loss: 1.6187134122335782

Epoch: 6| Step: 12
Training loss: 0.2817046046257019
Validation loss: 1.6358984452421947

Epoch: 6| Step: 13
Training loss: 0.44063010811805725
Validation loss: 1.6133595371759066

Epoch: 247| Step: 0
Training loss: 0.4239725172519684
Validation loss: 1.6056541121134194

Epoch: 6| Step: 1
Training loss: 0.5818069577217102
Validation loss: 1.6101743226410241

Epoch: 6| Step: 2
Training loss: 0.32179421186447144
Validation loss: 1.5553389928674186

Epoch: 6| Step: 3
Training loss: 0.425373911857605
Validation loss: 1.5379228438100507

Epoch: 6| Step: 4
Training loss: 0.5916475057601929
Validation loss: 1.5777379466641335

Epoch: 6| Step: 5
Training loss: 0.5081708431243896
Validation loss: 1.4955361427799347

Epoch: 6| Step: 6
Training loss: 0.28419220447540283
Validation loss: 1.5541942388780656

Epoch: 6| Step: 7
Training loss: 0.3722032904624939
Validation loss: 1.5506205020412323

Epoch: 6| Step: 8
Training loss: 0.43355363607406616
Validation loss: 1.581682123163695

Epoch: 6| Step: 9
Training loss: 0.5687268972396851
Validation loss: 1.6289877994086153

Epoch: 6| Step: 10
Training loss: 0.5356703400611877
Validation loss: 1.6644433147163802

Epoch: 6| Step: 11
Training loss: 0.4933041036128998
Validation loss: 1.7351608237912577

Epoch: 6| Step: 12
Training loss: 0.5631963014602661
Validation loss: 1.7592153997831448

Epoch: 6| Step: 13
Training loss: 0.387478232383728
Validation loss: 1.7604377961927844

Epoch: 248| Step: 0
Training loss: 0.5354283452033997
Validation loss: 1.6928326224768033

Epoch: 6| Step: 1
Training loss: 0.39844760298728943
Validation loss: 1.7051352275315153

Epoch: 6| Step: 2
Training loss: 0.21563559770584106
Validation loss: 1.659731803401824

Epoch: 6| Step: 3
Training loss: 0.6180680394172668
Validation loss: 1.5955328133798414

Epoch: 6| Step: 4
Training loss: 0.4294157028198242
Validation loss: 1.5905378069928897

Epoch: 6| Step: 5
Training loss: 0.35609740018844604
Validation loss: 1.567543593786096

Epoch: 6| Step: 6
Training loss: 0.38155239820480347
Validation loss: 1.5728986737548665

Epoch: 6| Step: 7
Training loss: 0.38185834884643555
Validation loss: 1.599507361330012

Epoch: 6| Step: 8
Training loss: 0.2276812493801117
Validation loss: 1.6127513557352045

Epoch: 6| Step: 9
Training loss: 0.8492571115493774
Validation loss: 1.6534996494170158

Epoch: 6| Step: 10
Training loss: 0.535431981086731
Validation loss: 1.6788310133000857

Epoch: 6| Step: 11
Training loss: 0.38795575499534607
Validation loss: 1.7112479017626854

Epoch: 6| Step: 12
Training loss: 0.3434399962425232
Validation loss: 1.704590525678409

Epoch: 6| Step: 13
Training loss: 0.33216530084609985
Validation loss: 1.6938827614630423

Epoch: 249| Step: 0
Training loss: 0.2725071907043457
Validation loss: 1.662014618996651

Epoch: 6| Step: 1
Training loss: 0.255670964717865
Validation loss: 1.685196130506454

Epoch: 6| Step: 2
Training loss: 0.5626976490020752
Validation loss: 1.6819301318096858

Epoch: 6| Step: 3
Training loss: 0.39966729283332825
Validation loss: 1.6721760662653113

Epoch: 6| Step: 4
Training loss: 0.30307257175445557
Validation loss: 1.6814087642136442

Epoch: 6| Step: 5
Training loss: 0.4013308882713318
Validation loss: 1.6768364470492128

Epoch: 6| Step: 6
Training loss: 0.47354987263679504
Validation loss: 1.647227216792363

Epoch: 6| Step: 7
Training loss: 0.394929975271225
Validation loss: 1.6500248588541502

Epoch: 6| Step: 8
Training loss: 0.26575684547424316
Validation loss: 1.6793624419038014

Epoch: 6| Step: 9
Training loss: 0.4358614385128021
Validation loss: 1.6223556495481921

Epoch: 6| Step: 10
Training loss: 0.4511197805404663
Validation loss: 1.6014211741826867

Epoch: 6| Step: 11
Training loss: 0.38278520107269287
Validation loss: 1.6074407164768507

Epoch: 6| Step: 12
Training loss: 0.6153373718261719
Validation loss: 1.5982539692232687

Epoch: 6| Step: 13
Training loss: 0.40246662497520447
Validation loss: 1.5857468523005003

Epoch: 250| Step: 0
Training loss: 0.4340773820877075
Validation loss: 1.5790770169227355

Epoch: 6| Step: 1
Training loss: 0.44409477710723877
Validation loss: 1.5617744333000594

Epoch: 6| Step: 2
Training loss: 0.30894365906715393
Validation loss: 1.5691005901623798

Epoch: 6| Step: 3
Training loss: 0.14230117201805115
Validation loss: 1.5591079919568953

Epoch: 6| Step: 4
Training loss: 0.4980918765068054
Validation loss: 1.5796790148622246

Epoch: 6| Step: 5
Training loss: 0.4195098578929901
Validation loss: 1.6044066888029858

Epoch: 6| Step: 6
Training loss: 0.2534617483615875
Validation loss: 1.5966168847135318

Epoch: 6| Step: 7
Training loss: 0.4211582541465759
Validation loss: 1.6435597199265675

Epoch: 6| Step: 8
Training loss: 0.5081644654273987
Validation loss: 1.6482945667800082

Epoch: 6| Step: 9
Training loss: 0.45208656787872314
Validation loss: 1.6603359650540095

Epoch: 6| Step: 10
Training loss: 0.4480971097946167
Validation loss: 1.6717337408373434

Epoch: 6| Step: 11
Training loss: 0.26576992869377136
Validation loss: 1.65924665235704

Epoch: 6| Step: 12
Training loss: 0.39114677906036377
Validation loss: 1.677242249570867

Epoch: 6| Step: 13
Training loss: 0.36362355947494507
Validation loss: 1.6747985501443186

Epoch: 251| Step: 0
Training loss: 0.3599129915237427
Validation loss: 1.6041744383432532

Epoch: 6| Step: 1
Training loss: 0.6281115412712097
Validation loss: 1.6533362519356511

Epoch: 6| Step: 2
Training loss: 0.21794423460960388
Validation loss: 1.5887407820711854

Epoch: 6| Step: 3
Training loss: 0.3640419840812683
Validation loss: 1.572603899945495

Epoch: 6| Step: 4
Training loss: 0.34189921617507935
Validation loss: 1.5663971593303065

Epoch: 6| Step: 5
Training loss: 0.3839738965034485
Validation loss: 1.5749652257529638

Epoch: 6| Step: 6
Training loss: 0.41396886110305786
Validation loss: 1.5493855796834475

Epoch: 6| Step: 7
Training loss: 0.6746622323989868
Validation loss: 1.526106338347158

Epoch: 6| Step: 8
Training loss: 0.30755969882011414
Validation loss: 1.5282304517684444

Epoch: 6| Step: 9
Training loss: 0.41450852155685425
Validation loss: 1.5206536733975975

Epoch: 6| Step: 10
Training loss: 0.33419302105903625
Validation loss: 1.518559830163115

Epoch: 6| Step: 11
Training loss: 0.2591928243637085
Validation loss: 1.559432037415043

Epoch: 6| Step: 12
Training loss: 0.37165361642837524
Validation loss: 1.6025914992055585

Epoch: 6| Step: 13
Training loss: 0.2557266056537628
Validation loss: 1.63175453037344

Epoch: 252| Step: 0
Training loss: 0.475936621427536
Validation loss: 1.671814977481801

Epoch: 6| Step: 1
Training loss: 0.49434971809387207
Validation loss: 1.6825666632703555

Epoch: 6| Step: 2
Training loss: 0.38219738006591797
Validation loss: 1.689693748310048

Epoch: 6| Step: 3
Training loss: 0.509297251701355
Validation loss: 1.6908723949104227

Epoch: 6| Step: 4
Training loss: 0.27455228567123413
Validation loss: 1.670592531081169

Epoch: 6| Step: 5
Training loss: 0.657342791557312
Validation loss: 1.6692659598524853

Epoch: 6| Step: 6
Training loss: 0.25035905838012695
Validation loss: 1.6289755605882215

Epoch: 6| Step: 7
Training loss: 0.37355464696884155
Validation loss: 1.6141594840634255

Epoch: 6| Step: 8
Training loss: 0.4041517972946167
Validation loss: 1.5971026100138181

Epoch: 6| Step: 9
Training loss: 0.4605409502983093
Validation loss: 1.6131788030747445

Epoch: 6| Step: 10
Training loss: 0.2770631015300751
Validation loss: 1.610909185101909

Epoch: 6| Step: 11
Training loss: 0.2610081434249878
Validation loss: 1.576602489717545

Epoch: 6| Step: 12
Training loss: 0.2797597646713257
Validation loss: 1.632702615953261

Epoch: 6| Step: 13
Training loss: 0.25044354796409607
Validation loss: 1.6478128535773164

Epoch: 253| Step: 0
Training loss: 0.20495495200157166
Validation loss: 1.6593784683494157

Epoch: 6| Step: 1
Training loss: 0.38229355216026306
Validation loss: 1.6905376693253875

Epoch: 6| Step: 2
Training loss: 0.4363454282283783
Validation loss: 1.7254075222117926

Epoch: 6| Step: 3
Training loss: 0.5224001407623291
Validation loss: 1.7748341227090487

Epoch: 6| Step: 4
Training loss: 0.5471650958061218
Validation loss: 1.810921053732595

Epoch: 6| Step: 5
Training loss: 0.28400719165802
Validation loss: 1.8241952747427008

Epoch: 6| Step: 6
Training loss: 0.4161687195301056
Validation loss: 1.8150838831419587

Epoch: 6| Step: 7
Training loss: 0.29313650727272034
Validation loss: 1.7529731617178967

Epoch: 6| Step: 8
Training loss: 0.5373426079750061
Validation loss: 1.684507760950314

Epoch: 6| Step: 9
Training loss: 0.5367807745933533
Validation loss: 1.7037458368526992

Epoch: 6| Step: 10
Training loss: 0.27279701828956604
Validation loss: 1.6459412882404942

Epoch: 6| Step: 11
Training loss: 0.5717974901199341
Validation loss: 1.6329810471944912

Epoch: 6| Step: 12
Training loss: 0.5461050271987915
Validation loss: 1.5751470724741619

Epoch: 6| Step: 13
Training loss: 0.41244542598724365
Validation loss: 1.5982072045726161

Epoch: 254| Step: 0
Training loss: 0.3088356554508209
Validation loss: 1.5720007137585712

Epoch: 6| Step: 1
Training loss: 0.3832658529281616
Validation loss: 1.5574942737497308

Epoch: 6| Step: 2
Training loss: 0.43179285526275635
Validation loss: 1.5784306410820252

Epoch: 6| Step: 3
Training loss: 0.5934062600135803
Validation loss: 1.6110977511252127

Epoch: 6| Step: 4
Training loss: 0.24550680816173553
Validation loss: 1.652986144506803

Epoch: 6| Step: 5
Training loss: 0.40517398715019226
Validation loss: 1.6439223392035371

Epoch: 6| Step: 6
Training loss: 0.6106313467025757
Validation loss: 1.635806631016475

Epoch: 6| Step: 7
Training loss: 0.25390762090682983
Validation loss: 1.6076782275271673

Epoch: 6| Step: 8
Training loss: 0.2944565415382385
Validation loss: 1.582845559684179

Epoch: 6| Step: 9
Training loss: 0.44063618779182434
Validation loss: 1.5366393007257932

Epoch: 6| Step: 10
Training loss: 0.34250587224960327
Validation loss: 1.5371323426564534

Epoch: 6| Step: 11
Training loss: 0.2983045279979706
Validation loss: 1.5134885259853896

Epoch: 6| Step: 12
Training loss: 0.34434717893600464
Validation loss: 1.517884619774357

Epoch: 6| Step: 13
Training loss: 0.5658480525016785
Validation loss: 1.5109467019316971

Epoch: 255| Step: 0
Training loss: 0.4902246594429016
Validation loss: 1.5352776165931457

Epoch: 6| Step: 1
Training loss: 0.34092283248901367
Validation loss: 1.548849840318003

Epoch: 6| Step: 2
Training loss: 0.46684274077415466
Validation loss: 1.5641151218004123

Epoch: 6| Step: 3
Training loss: 0.35750287771224976
Validation loss: 1.5689476369529642

Epoch: 6| Step: 4
Training loss: 0.2975230813026428
Validation loss: 1.5938661739390383

Epoch: 6| Step: 5
Training loss: 0.5924274921417236
Validation loss: 1.6053487998183056

Epoch: 6| Step: 6
Training loss: 0.23253680765628815
Validation loss: 1.5838490865563835

Epoch: 6| Step: 7
Training loss: 0.18447893857955933
Validation loss: 1.600141881614603

Epoch: 6| Step: 8
Training loss: 0.3923998475074768
Validation loss: 1.621212758043761

Epoch: 6| Step: 9
Training loss: 0.1586458534002304
Validation loss: 1.6215673620982836

Epoch: 6| Step: 10
Training loss: 0.303796648979187
Validation loss: 1.6567196423007595

Epoch: 6| Step: 11
Training loss: 0.3761873245239258
Validation loss: 1.6739558827492498

Epoch: 6| Step: 12
Training loss: 0.2445182204246521
Validation loss: 1.662822095296716

Epoch: 6| Step: 13
Training loss: 0.42566144466400146
Validation loss: 1.6583413334303005

Epoch: 256| Step: 0
Training loss: 0.6621258854866028
Validation loss: 1.6527791946165022

Epoch: 6| Step: 1
Training loss: 0.38325801491737366
Validation loss: 1.6509415641907723

Epoch: 6| Step: 2
Training loss: 0.3415642976760864
Validation loss: 1.6659891233649304

Epoch: 6| Step: 3
Training loss: 0.26624441146850586
Validation loss: 1.7082005085483674

Epoch: 6| Step: 4
Training loss: 0.3203539252281189
Validation loss: 1.7033950897955126

Epoch: 6| Step: 5
Training loss: 0.2906363010406494
Validation loss: 1.6808984792360695

Epoch: 6| Step: 6
Training loss: 0.5084531307220459
Validation loss: 1.676938586337592

Epoch: 6| Step: 7
Training loss: 0.2830047011375427
Validation loss: 1.6527449277139479

Epoch: 6| Step: 8
Training loss: 0.4852842688560486
Validation loss: 1.631451460622972

Epoch: 6| Step: 9
Training loss: 0.29833829402923584
Validation loss: 1.6151218427124845

Epoch: 6| Step: 10
Training loss: 0.31277889013290405
Validation loss: 1.60616502710568

Epoch: 6| Step: 11
Training loss: 0.41788405179977417
Validation loss: 1.6267929314285197

Epoch: 6| Step: 12
Training loss: 0.3471057713031769
Validation loss: 1.6084760504384195

Epoch: 6| Step: 13
Training loss: 0.16178244352340698
Validation loss: 1.638531502857003

Epoch: 257| Step: 0
Training loss: 0.28008776903152466
Validation loss: 1.6580222934804938

Epoch: 6| Step: 1
Training loss: 0.3701598644256592
Validation loss: 1.6840015367795063

Epoch: 6| Step: 2
Training loss: 0.3472234010696411
Validation loss: 1.6967354269437893

Epoch: 6| Step: 3
Training loss: 0.3273123800754547
Validation loss: 1.695427127422825

Epoch: 6| Step: 4
Training loss: 0.46102219820022583
Validation loss: 1.701498100834508

Epoch: 6| Step: 5
Training loss: 0.2929112911224365
Validation loss: 1.6579378292124758

Epoch: 6| Step: 6
Training loss: 0.27440252900123596
Validation loss: 1.6770837588976788

Epoch: 6| Step: 7
Training loss: 0.3495030999183655
Validation loss: 1.6568994227276053

Epoch: 6| Step: 8
Training loss: 0.29680973291397095
Validation loss: 1.6537383025692356

Epoch: 6| Step: 9
Training loss: 0.29012173414230347
Validation loss: 1.6366755847007997

Epoch: 6| Step: 10
Training loss: 0.2645858824253082
Validation loss: 1.581261020834728

Epoch: 6| Step: 11
Training loss: 0.19761568307876587
Validation loss: 1.5994916064764864

Epoch: 6| Step: 12
Training loss: 0.5400890707969666
Validation loss: 1.550365953035252

Epoch: 6| Step: 13
Training loss: 0.3322373628616333
Validation loss: 1.56971392836622

Epoch: 258| Step: 0
Training loss: 0.40448251366615295
Validation loss: 1.589363613436299

Epoch: 6| Step: 1
Training loss: 0.45381563901901245
Validation loss: 1.6003256818299652

Epoch: 6| Step: 2
Training loss: 0.17443621158599854
Validation loss: 1.612507434301479

Epoch: 6| Step: 3
Training loss: 0.24650892615318298
Validation loss: 1.6127507981433664

Epoch: 6| Step: 4
Training loss: 0.2552163898944855
Validation loss: 1.6048857217193933

Epoch: 6| Step: 5
Training loss: 0.34552595019340515
Validation loss: 1.6129965474528651

Epoch: 6| Step: 6
Training loss: 0.324493408203125
Validation loss: 1.6061948114825833

Epoch: 6| Step: 7
Training loss: 0.4666721224784851
Validation loss: 1.6033942109795027

Epoch: 6| Step: 8
Training loss: 0.3052893280982971
Validation loss: 1.618558850339664

Epoch: 6| Step: 9
Training loss: 0.4674542546272278
Validation loss: 1.6165229658926688

Epoch: 6| Step: 10
Training loss: 0.2843647599220276
Validation loss: 1.6077271379450315

Epoch: 6| Step: 11
Training loss: 0.23376721143722534
Validation loss: 1.5895577592234458

Epoch: 6| Step: 12
Training loss: 0.490251749753952
Validation loss: 1.5839176998343518

Epoch: 6| Step: 13
Training loss: 0.4475669264793396
Validation loss: 1.579280887880633

Epoch: 259| Step: 0
Training loss: 0.12295707315206528
Validation loss: 1.6005399073323896

Epoch: 6| Step: 1
Training loss: 0.48059332370758057
Validation loss: 1.60796921483932

Epoch: 6| Step: 2
Training loss: 0.39376625418663025
Validation loss: 1.5698678262772099

Epoch: 6| Step: 3
Training loss: 0.23189954459667206
Validation loss: 1.5265229812232397

Epoch: 6| Step: 4
Training loss: 0.3486079275608063
Validation loss: 1.4937460768607356

Epoch: 6| Step: 5
Training loss: 0.2874617576599121
Validation loss: 1.5070716296472857

Epoch: 6| Step: 6
Training loss: 0.36305516958236694
Validation loss: 1.5091578114417292

Epoch: 6| Step: 7
Training loss: 0.38338950276374817
Validation loss: 1.537359550435056

Epoch: 6| Step: 8
Training loss: 0.3915501534938812
Validation loss: 1.5199402583542692

Epoch: 6| Step: 9
Training loss: 0.384199321269989
Validation loss: 1.5780987637017363

Epoch: 6| Step: 10
Training loss: 0.364729106426239
Validation loss: 1.5924225866153676

Epoch: 6| Step: 11
Training loss: 0.3395291566848755
Validation loss: 1.6065504371478994

Epoch: 6| Step: 12
Training loss: 0.8569008708000183
Validation loss: 1.6171510898938743

Epoch: 6| Step: 13
Training loss: 0.39797893166542053
Validation loss: 1.6223723926851827

Epoch: 260| Step: 0
Training loss: 0.3982579708099365
Validation loss: 1.6211911811623523

Epoch: 6| Step: 1
Training loss: 0.28538382053375244
Validation loss: 1.6603795725812194

Epoch: 6| Step: 2
Training loss: 0.4729624092578888
Validation loss: 1.6985458045877435

Epoch: 6| Step: 3
Training loss: 0.4809216558933258
Validation loss: 1.7308930902070896

Epoch: 6| Step: 4
Training loss: 0.368598997592926
Validation loss: 1.7451328526261032

Epoch: 6| Step: 5
Training loss: 0.36331459879875183
Validation loss: 1.770015796025594

Epoch: 6| Step: 6
Training loss: 0.3112218379974365
Validation loss: 1.746339754391742

Epoch: 6| Step: 7
Training loss: 0.4493919909000397
Validation loss: 1.7207985206316876

Epoch: 6| Step: 8
Training loss: 0.2796249985694885
Validation loss: 1.7132084305568407

Epoch: 6| Step: 9
Training loss: 0.7744376063346863
Validation loss: 1.6600505228965514

Epoch: 6| Step: 10
Training loss: 0.3017708659172058
Validation loss: 1.6386238810836629

Epoch: 6| Step: 11
Training loss: 0.4270242154598236
Validation loss: 1.6129709302738149

Epoch: 6| Step: 12
Training loss: 0.25177910923957825
Validation loss: 1.5900535198949999

Epoch: 6| Step: 13
Training loss: 0.209821879863739
Validation loss: 1.5973204976768904

Epoch: 261| Step: 0
Training loss: 0.6513270139694214
Validation loss: 1.5961438789162585

Epoch: 6| Step: 1
Training loss: 0.5468332767486572
Validation loss: 1.557321556152836

Epoch: 6| Step: 2
Training loss: 0.2890993356704712
Validation loss: 1.5820449667592202

Epoch: 6| Step: 3
Training loss: 0.3727074861526489
Validation loss: 1.5794756245869461

Epoch: 6| Step: 4
Training loss: 0.2680160701274872
Validation loss: 1.5744343073137346

Epoch: 6| Step: 5
Training loss: 0.26916828751564026
Validation loss: 1.5549992963831911

Epoch: 6| Step: 6
Training loss: 0.2628123164176941
Validation loss: 1.5696753968474686

Epoch: 6| Step: 7
Training loss: 0.23668771982192993
Validation loss: 1.6083152576159405

Epoch: 6| Step: 8
Training loss: 0.3342891335487366
Validation loss: 1.6009330082965154

Epoch: 6| Step: 9
Training loss: 0.22166281938552856
Validation loss: 1.586931336310602

Epoch: 6| Step: 10
Training loss: 0.3875581622123718
Validation loss: 1.594228083087552

Epoch: 6| Step: 11
Training loss: 0.24123936891555786
Validation loss: 1.5923633165256952

Epoch: 6| Step: 12
Training loss: 0.37779727578163147
Validation loss: 1.5818543716143536

Epoch: 6| Step: 13
Training loss: 0.4543110132217407
Validation loss: 1.5604302767784364

Epoch: 262| Step: 0
Training loss: 0.46680596470832825
Validation loss: 1.5674298668420443

Epoch: 6| Step: 1
Training loss: 0.34608668088912964
Validation loss: 1.5733438166238929

Epoch: 6| Step: 2
Training loss: 0.20032213628292084
Validation loss: 1.5539246836016256

Epoch: 6| Step: 3
Training loss: 0.1700562834739685
Validation loss: 1.5544019911878852

Epoch: 6| Step: 4
Training loss: 0.41337648034095764
Validation loss: 1.5626310366456226

Epoch: 6| Step: 5
Training loss: 0.6697750091552734
Validation loss: 1.5916792923404324

Epoch: 6| Step: 6
Training loss: 0.3689104914665222
Validation loss: 1.5791370843046455

Epoch: 6| Step: 7
Training loss: 0.22560763359069824
Validation loss: 1.5637367207516906

Epoch: 6| Step: 8
Training loss: 0.4771749973297119
Validation loss: 1.6234542849243327

Epoch: 6| Step: 9
Training loss: 0.24204137921333313
Validation loss: 1.6089723084562568

Epoch: 6| Step: 10
Training loss: 0.3421035408973694
Validation loss: 1.623136048034955

Epoch: 6| Step: 11
Training loss: 0.3730202615261078
Validation loss: 1.601319552749716

Epoch: 6| Step: 12
Training loss: 0.25163042545318604
Validation loss: 1.6100009820794547

Epoch: 6| Step: 13
Training loss: 0.18624477088451385
Validation loss: 1.583111237454158

Epoch: 263| Step: 0
Training loss: 0.21754375100135803
Validation loss: 1.5956587893988496

Epoch: 6| Step: 1
Training loss: 0.3194671869277954
Validation loss: 1.6372102870736072

Epoch: 6| Step: 2
Training loss: 0.2951715588569641
Validation loss: 1.6281114611574399

Epoch: 6| Step: 3
Training loss: 0.32203376293182373
Validation loss: 1.6234732045922229

Epoch: 6| Step: 4
Training loss: 0.4931213855743408
Validation loss: 1.621643707316409

Epoch: 6| Step: 5
Training loss: 0.1519830822944641
Validation loss: 1.62914877681322

Epoch: 6| Step: 6
Training loss: 0.24829448759555817
Validation loss: 1.6064199222031461

Epoch: 6| Step: 7
Training loss: 0.5839354991912842
Validation loss: 1.5870798159671087

Epoch: 6| Step: 8
Training loss: 0.29898351430892944
Validation loss: 1.6053231557210286

Epoch: 6| Step: 9
Training loss: 0.34693318605422974
Validation loss: 1.5991908459253208

Epoch: 6| Step: 10
Training loss: 0.2016376256942749
Validation loss: 1.5733824250518635

Epoch: 6| Step: 11
Training loss: 0.3389297127723694
Validation loss: 1.567181159091252

Epoch: 6| Step: 12
Training loss: 0.5995110273361206
Validation loss: 1.5217457381627892

Epoch: 6| Step: 13
Training loss: 0.4225483536720276
Validation loss: 1.5255532790255804

Epoch: 264| Step: 0
Training loss: 0.3035913109779358
Validation loss: 1.4834268464837024

Epoch: 6| Step: 1
Training loss: 0.35921600461006165
Validation loss: 1.4574808548855525

Epoch: 6| Step: 2
Training loss: 0.48739224672317505
Validation loss: 1.5189083417256672

Epoch: 6| Step: 3
Training loss: 0.3265993893146515
Validation loss: 1.5128983169473627

Epoch: 6| Step: 4
Training loss: 0.3308073878288269
Validation loss: 1.5189717508131457

Epoch: 6| Step: 5
Training loss: 0.1710650622844696
Validation loss: 1.5453134582888695

Epoch: 6| Step: 6
Training loss: 0.6856862306594849
Validation loss: 1.567228546706579

Epoch: 6| Step: 7
Training loss: 0.23943641781806946
Validation loss: 1.57022596943763

Epoch: 6| Step: 8
Training loss: 0.16459399461746216
Validation loss: 1.6112947156352382

Epoch: 6| Step: 9
Training loss: 0.27146807312965393
Validation loss: 1.6078939899321525

Epoch: 6| Step: 10
Training loss: 0.33904045820236206
Validation loss: 1.6173537854225404

Epoch: 6| Step: 11
Training loss: 0.3712202310562134
Validation loss: 1.6308182811224332

Epoch: 6| Step: 12
Training loss: 0.3669911324977875
Validation loss: 1.6225852120307185

Epoch: 6| Step: 13
Training loss: 0.22709840536117554
Validation loss: 1.6276709520688621

Epoch: 265| Step: 0
Training loss: 0.22004805505275726
Validation loss: 1.61460615229863

Epoch: 6| Step: 1
Training loss: 0.2851260304450989
Validation loss: 1.6066434857665852

Epoch: 6| Step: 2
Training loss: 0.3250366449356079
Validation loss: 1.5698072038671023

Epoch: 6| Step: 3
Training loss: 0.5805357098579407
Validation loss: 1.5624366062943653

Epoch: 6| Step: 4
Training loss: 0.3710509240627289
Validation loss: 1.4899940823995939

Epoch: 6| Step: 5
Training loss: 0.26330217719078064
Validation loss: 1.532209962926885

Epoch: 6| Step: 6
Training loss: 0.22980111837387085
Validation loss: 1.5068265391934303

Epoch: 6| Step: 7
Training loss: 0.4113460183143616
Validation loss: 1.530485660799088

Epoch: 6| Step: 8
Training loss: 0.2835404872894287
Validation loss: 1.5313483040819886

Epoch: 6| Step: 9
Training loss: 0.26964256167411804
Validation loss: 1.5524775123083463

Epoch: 6| Step: 10
Training loss: 0.3777010440826416
Validation loss: 1.591943625480898

Epoch: 6| Step: 11
Training loss: 0.50001060962677
Validation loss: 1.6154553089090573

Epoch: 6| Step: 12
Training loss: 0.3620753288269043
Validation loss: 1.6171264802255938

Epoch: 6| Step: 13
Training loss: 0.25082260370254517
Validation loss: 1.626312787814807

Epoch: 266| Step: 0
Training loss: 0.493123322725296
Validation loss: 1.601560608033211

Epoch: 6| Step: 1
Training loss: 0.2716735601425171
Validation loss: 1.6080584654244043

Epoch: 6| Step: 2
Training loss: 0.3998335599899292
Validation loss: 1.6022374335155691

Epoch: 6| Step: 3
Training loss: 0.23837950825691223
Validation loss: 1.5794267795419181

Epoch: 6| Step: 4
Training loss: 0.312441349029541
Validation loss: 1.5554877250425276

Epoch: 6| Step: 5
Training loss: 0.302580326795578
Validation loss: 1.5248074493100565

Epoch: 6| Step: 6
Training loss: 0.3271750807762146
Validation loss: 1.5246724159486833

Epoch: 6| Step: 7
Training loss: 0.5604211091995239
Validation loss: 1.541109828538792

Epoch: 6| Step: 8
Training loss: 0.36567026376724243
Validation loss: 1.5301006224847609

Epoch: 6| Step: 9
Training loss: 0.2252950370311737
Validation loss: 1.5325682714421263

Epoch: 6| Step: 10
Training loss: 0.3056234121322632
Validation loss: 1.5345483441506662

Epoch: 6| Step: 11
Training loss: 0.2122592031955719
Validation loss: 1.5465712021755915

Epoch: 6| Step: 12
Training loss: 0.1788351684808731
Validation loss: 1.5397225426089378

Epoch: 6| Step: 13
Training loss: 0.2965486943721771
Validation loss: 1.5448750795856598

Epoch: 267| Step: 0
Training loss: 0.15893393754959106
Validation loss: 1.5541820590214064

Epoch: 6| Step: 1
Training loss: 0.2692883610725403
Validation loss: 1.5663235225985128

Epoch: 6| Step: 2
Training loss: 0.21420225501060486
Validation loss: 1.6158545158242668

Epoch: 6| Step: 3
Training loss: 0.3434561789035797
Validation loss: 1.5807706091993599

Epoch: 6| Step: 4
Training loss: 0.28440743684768677
Validation loss: 1.5574488998741232

Epoch: 6| Step: 5
Training loss: 0.2874652147293091
Validation loss: 1.548127806314858

Epoch: 6| Step: 6
Training loss: 0.22909823060035706
Validation loss: 1.5612442134529032

Epoch: 6| Step: 7
Training loss: 0.4676811993122101
Validation loss: 1.5554374789678922

Epoch: 6| Step: 8
Training loss: 0.35962221026420593
Validation loss: 1.5606418117400138

Epoch: 6| Step: 9
Training loss: 0.1357407569885254
Validation loss: 1.5564614303650395

Epoch: 6| Step: 10
Training loss: 0.48221635818481445
Validation loss: 1.6078438156394548

Epoch: 6| Step: 11
Training loss: 0.1807764172554016
Validation loss: 1.599140917101214

Epoch: 6| Step: 12
Training loss: 0.6460100412368774
Validation loss: 1.5968812742540914

Epoch: 6| Step: 13
Training loss: 0.3010213077068329
Validation loss: 1.6147469269332064

Epoch: 268| Step: 0
Training loss: 0.2109602689743042
Validation loss: 1.6008277016301309

Epoch: 6| Step: 1
Training loss: 0.21479164063930511
Validation loss: 1.6320355887054114

Epoch: 6| Step: 2
Training loss: 0.22320044040679932
Validation loss: 1.6290140100704726

Epoch: 6| Step: 3
Training loss: 0.3689400553703308
Validation loss: 1.6165642167932244

Epoch: 6| Step: 4
Training loss: 0.5430746078491211
Validation loss: 1.6283049685980684

Epoch: 6| Step: 5
Training loss: 0.5521840453147888
Validation loss: 1.616118351618449

Epoch: 6| Step: 6
Training loss: 0.24357753992080688
Validation loss: 1.671880134972193

Epoch: 6| Step: 7
Training loss: 0.3568384647369385
Validation loss: 1.659716759958575

Epoch: 6| Step: 8
Training loss: 0.39811232686042786
Validation loss: 1.6433092291637132

Epoch: 6| Step: 9
Training loss: 0.36122989654541016
Validation loss: 1.69275971381895

Epoch: 6| Step: 10
Training loss: 0.3202412724494934
Validation loss: 1.6522576924293273

Epoch: 6| Step: 11
Training loss: 0.21042898297309875
Validation loss: 1.6718512888877624

Epoch: 6| Step: 12
Training loss: 0.17202717065811157
Validation loss: 1.6288053656137118

Epoch: 6| Step: 13
Training loss: 0.37211835384368896
Validation loss: 1.642078367612695

Epoch: 269| Step: 0
Training loss: 0.22663018107414246
Validation loss: 1.6175171252219909

Epoch: 6| Step: 1
Training loss: 0.34102383255958557
Validation loss: 1.6269163188113962

Epoch: 6| Step: 2
Training loss: 0.16448137164115906
Validation loss: 1.6062423324072233

Epoch: 6| Step: 3
Training loss: 0.20965561270713806
Validation loss: 1.6620485667259461

Epoch: 6| Step: 4
Training loss: 0.29744237661361694
Validation loss: 1.673493061014401

Epoch: 6| Step: 5
Training loss: 0.3347206711769104
Validation loss: 1.6426939528475526

Epoch: 6| Step: 6
Training loss: 0.48466822504997253
Validation loss: 1.6526810225620066

Epoch: 6| Step: 7
Training loss: 0.2652316093444824
Validation loss: 1.651100694492299

Epoch: 6| Step: 8
Training loss: 0.38491153717041016
Validation loss: 1.6503556428417083

Epoch: 6| Step: 9
Training loss: 0.21756494045257568
Validation loss: 1.6039464140451083

Epoch: 6| Step: 10
Training loss: 0.31563636660575867
Validation loss: 1.5707168335555701

Epoch: 6| Step: 11
Training loss: 0.39503878355026245
Validation loss: 1.567239265288076

Epoch: 6| Step: 12
Training loss: 0.22981491684913635
Validation loss: 1.5316492754925963

Epoch: 6| Step: 13
Training loss: 0.35054272413253784
Validation loss: 1.5223504484340709

Epoch: 270| Step: 0
Training loss: 0.29311415553092957
Validation loss: 1.5274640360186178

Epoch: 6| Step: 1
Training loss: 0.1730956733226776
Validation loss: 1.5590789792358235

Epoch: 6| Step: 2
Training loss: 0.23537319898605347
Validation loss: 1.575228520618972

Epoch: 6| Step: 3
Training loss: 0.27876782417297363
Validation loss: 1.5850035272618777

Epoch: 6| Step: 4
Training loss: 0.4996875524520874
Validation loss: 1.6200086134736256

Epoch: 6| Step: 5
Training loss: 0.5670228004455566
Validation loss: 1.628341544059015

Epoch: 6| Step: 6
Training loss: 0.309138685464859
Validation loss: 1.648978365364895

Epoch: 6| Step: 7
Training loss: 0.32412901520729065
Validation loss: 1.6663933441203127

Epoch: 6| Step: 8
Training loss: 0.19424419105052948
Validation loss: 1.6915392388579666

Epoch: 6| Step: 9
Training loss: 0.2460402101278305
Validation loss: 1.6625853494931293

Epoch: 6| Step: 10
Training loss: 0.26696062088012695
Validation loss: 1.7030994661392704

Epoch: 6| Step: 11
Training loss: 0.38985419273376465
Validation loss: 1.677175247541038

Epoch: 6| Step: 12
Training loss: 0.3028671145439148
Validation loss: 1.6505696876074678

Epoch: 6| Step: 13
Training loss: 0.14246734976768494
Validation loss: 1.6398539209878573

Epoch: 271| Step: 0
Training loss: 0.3690795600414276
Validation loss: 1.5942265570804637

Epoch: 6| Step: 1
Training loss: 0.26525968313217163
Validation loss: 1.5734937517873702

Epoch: 6| Step: 2
Training loss: 0.14258167147636414
Validation loss: 1.569229628450127

Epoch: 6| Step: 3
Training loss: 0.30653563141822815
Validation loss: 1.5496259684203773

Epoch: 6| Step: 4
Training loss: 0.22031092643737793
Validation loss: 1.523840295371189

Epoch: 6| Step: 5
Training loss: 0.2525234818458557
Validation loss: 1.4829176651534213

Epoch: 6| Step: 6
Training loss: 0.313096284866333
Validation loss: 1.51111799927168

Epoch: 6| Step: 7
Training loss: 0.3950961232185364
Validation loss: 1.5081036821488412

Epoch: 6| Step: 8
Training loss: 0.5385674238204956
Validation loss: 1.504613979529309

Epoch: 6| Step: 9
Training loss: 0.27123814821243286
Validation loss: 1.5251884934722737

Epoch: 6| Step: 10
Training loss: 0.32699280977249146
Validation loss: 1.5394757588704426

Epoch: 6| Step: 11
Training loss: 0.31480664014816284
Validation loss: 1.5578749397749543

Epoch: 6| Step: 12
Training loss: 0.2690432369709015
Validation loss: 1.5679473184770154

Epoch: 6| Step: 13
Training loss: 0.3088645339012146
Validation loss: 1.6224686894365536

Epoch: 272| Step: 0
Training loss: 0.31858593225479126
Validation loss: 1.6147831870663552

Epoch: 6| Step: 1
Training loss: 0.4432408809661865
Validation loss: 1.6551859083996023

Epoch: 6| Step: 2
Training loss: 0.3540912866592407
Validation loss: 1.6510225547257291

Epoch: 6| Step: 3
Training loss: 0.23941144347190857
Validation loss: 1.6188934528699486

Epoch: 6| Step: 4
Training loss: 0.3257535696029663
Validation loss: 1.5919252775048698

Epoch: 6| Step: 5
Training loss: 0.25052812695503235
Validation loss: 1.586728217781231

Epoch: 6| Step: 6
Training loss: 0.26584574580192566
Validation loss: 1.5911305489078644

Epoch: 6| Step: 7
Training loss: 0.28137362003326416
Validation loss: 1.5939209281757314

Epoch: 6| Step: 8
Training loss: 0.34598803520202637
Validation loss: 1.5527512873372724

Epoch: 6| Step: 9
Training loss: 0.6063273549079895
Validation loss: 1.5539427572681057

Epoch: 6| Step: 10
Training loss: 0.3335212469100952
Validation loss: 1.5313509330954602

Epoch: 6| Step: 11
Training loss: 0.23317554593086243
Validation loss: 1.5229103693398096

Epoch: 6| Step: 12
Training loss: 0.2886008024215698
Validation loss: 1.5072683044659194

Epoch: 6| Step: 13
Training loss: 0.14723077416419983
Validation loss: 1.515103187612308

Epoch: 273| Step: 0
Training loss: 0.20152343809604645
Validation loss: 1.5175380373513827

Epoch: 6| Step: 1
Training loss: 0.3689125180244446
Validation loss: 1.5245420586678289

Epoch: 6| Step: 2
Training loss: 0.25254714488983154
Validation loss: 1.5612662594805482

Epoch: 6| Step: 3
Training loss: 0.18253952264785767
Validation loss: 1.5672023078446746

Epoch: 6| Step: 4
Training loss: 0.3986434042453766
Validation loss: 1.5920094187541673

Epoch: 6| Step: 5
Training loss: 0.18067847192287445
Validation loss: 1.6058244192472069

Epoch: 6| Step: 6
Training loss: 0.22654885053634644
Validation loss: 1.5992672520299112

Epoch: 6| Step: 7
Training loss: 0.2590608298778534
Validation loss: 1.5796924842301237

Epoch: 6| Step: 8
Training loss: 0.3608531951904297
Validation loss: 1.5600680920385546

Epoch: 6| Step: 9
Training loss: 0.5199910402297974
Validation loss: 1.58630431595669

Epoch: 6| Step: 10
Training loss: 0.39433223009109497
Validation loss: 1.5639166896061232

Epoch: 6| Step: 11
Training loss: 0.2019621580839157
Validation loss: 1.5432238963342482

Epoch: 6| Step: 12
Training loss: 0.4306744933128357
Validation loss: 1.5580820011836227

Epoch: 6| Step: 13
Training loss: 0.2525591552257538
Validation loss: 1.561636758107011

Epoch: 274| Step: 0
Training loss: 0.4274922013282776
Validation loss: 1.5746348980934388

Epoch: 6| Step: 1
Training loss: 0.22004428505897522
Validation loss: 1.5806781681635047

Epoch: 6| Step: 2
Training loss: 0.3273852467536926
Validation loss: 1.608515493331417

Epoch: 6| Step: 3
Training loss: 0.2798982858657837
Validation loss: 1.616584054885372

Epoch: 6| Step: 4
Training loss: 0.2544889450073242
Validation loss: 1.6100703875223796

Epoch: 6| Step: 5
Training loss: 0.35041704773902893
Validation loss: 1.6179622988547049

Epoch: 6| Step: 6
Training loss: 0.39228808879852295
Validation loss: 1.602373473105892

Epoch: 6| Step: 7
Training loss: 0.30317291617393494
Validation loss: 1.5913943629111014

Epoch: 6| Step: 8
Training loss: 0.668586015701294
Validation loss: 1.5857555520149968

Epoch: 6| Step: 9
Training loss: 0.4613875448703766
Validation loss: 1.5416063775298416

Epoch: 6| Step: 10
Training loss: 0.15604305267333984
Validation loss: 1.5291679764306674

Epoch: 6| Step: 11
Training loss: 0.13693559169769287
Validation loss: 1.5042631856856807

Epoch: 6| Step: 12
Training loss: 0.41897857189178467
Validation loss: 1.492929849573361

Epoch: 6| Step: 13
Training loss: 0.21077457070350647
Validation loss: 1.5001901644532398

Epoch: 275| Step: 0
Training loss: 0.21393662691116333
Validation loss: 1.480872413163544

Epoch: 6| Step: 1
Training loss: 0.3356761336326599
Validation loss: 1.482695548765121

Epoch: 6| Step: 2
Training loss: 0.20621466636657715
Validation loss: 1.5318928636530393

Epoch: 6| Step: 3
Training loss: 0.37708568572998047
Validation loss: 1.5295933908031834

Epoch: 6| Step: 4
Training loss: 0.3260769248008728
Validation loss: 1.5290040277665662

Epoch: 6| Step: 5
Training loss: 0.33813542127609253
Validation loss: 1.543141193287347

Epoch: 6| Step: 6
Training loss: 0.2923430800437927
Validation loss: 1.5458989835554553

Epoch: 6| Step: 7
Training loss: 0.4128679037094116
Validation loss: 1.5374065419679046

Epoch: 6| Step: 8
Training loss: 0.3389891982078552
Validation loss: 1.5631268178263018

Epoch: 6| Step: 9
Training loss: 0.4740331172943115
Validation loss: 1.5535382750213786

Epoch: 6| Step: 10
Training loss: 0.21145395934581757
Validation loss: 1.5869288547064668

Epoch: 6| Step: 11
Training loss: 0.19359090924263
Validation loss: 1.59520730023743

Epoch: 6| Step: 12
Training loss: 0.26724183559417725
Validation loss: 1.5972649628116238

Epoch: 6| Step: 13
Training loss: 0.3726571500301361
Validation loss: 1.585781958795363

Epoch: 276| Step: 0
Training loss: 0.2969141900539398
Validation loss: 1.5955163958252117

Epoch: 6| Step: 1
Training loss: 0.21748626232147217
Validation loss: 1.598701460387117

Epoch: 6| Step: 2
Training loss: 0.2652430534362793
Validation loss: 1.6110344817561488

Epoch: 6| Step: 3
Training loss: 0.23394666612148285
Validation loss: 1.6607483317775111

Epoch: 6| Step: 4
Training loss: 0.6364055275917053
Validation loss: 1.6936139688696912

Epoch: 6| Step: 5
Training loss: 0.3334934711456299
Validation loss: 1.69590223732815

Epoch: 6| Step: 6
Training loss: 0.36772388219833374
Validation loss: 1.6620511060119958

Epoch: 6| Step: 7
Training loss: 0.37288931012153625
Validation loss: 1.5929806796453332

Epoch: 6| Step: 8
Training loss: 0.20617389678955078
Validation loss: 1.58653925952091

Epoch: 6| Step: 9
Training loss: 0.2781740725040436
Validation loss: 1.5733194171741445

Epoch: 6| Step: 10
Training loss: 0.37997180223464966
Validation loss: 1.558547605109471

Epoch: 6| Step: 11
Training loss: 0.24411962926387787
Validation loss: 1.5210386950482604

Epoch: 6| Step: 12
Training loss: 0.14654746651649475
Validation loss: 1.5083956385171542

Epoch: 6| Step: 13
Training loss: 0.4041338562965393
Validation loss: 1.491174864512618

Epoch: 277| Step: 0
Training loss: 0.2322675585746765
Validation loss: 1.4992085092811174

Epoch: 6| Step: 1
Training loss: 0.22566504776477814
Validation loss: 1.5204537504462785

Epoch: 6| Step: 2
Training loss: 0.5402588248252869
Validation loss: 1.5113632384166922

Epoch: 6| Step: 3
Training loss: 0.31952768564224243
Validation loss: 1.5497865715334493

Epoch: 6| Step: 4
Training loss: 0.15444287657737732
Validation loss: 1.5506612229090866

Epoch: 6| Step: 5
Training loss: 0.21986550092697144
Validation loss: 1.5875891370158042

Epoch: 6| Step: 6
Training loss: 0.34716641902923584
Validation loss: 1.5986266751443186

Epoch: 6| Step: 7
Training loss: 0.1854255199432373
Validation loss: 1.6348494919397498

Epoch: 6| Step: 8
Training loss: 0.2276175320148468
Validation loss: 1.6180400861206876

Epoch: 6| Step: 9
Training loss: 0.2359693944454193
Validation loss: 1.6555063724517822

Epoch: 6| Step: 10
Training loss: 0.3344395160675049
Validation loss: 1.6429976186444681

Epoch: 6| Step: 11
Training loss: 0.4943181574344635
Validation loss: 1.6130718133782829

Epoch: 6| Step: 12
Training loss: 0.23900291323661804
Validation loss: 1.6008103432193879

Epoch: 6| Step: 13
Training loss: 0.24947407841682434
Validation loss: 1.591415911592463

Epoch: 278| Step: 0
Training loss: 0.3067237138748169
Validation loss: 1.5160352671018211

Epoch: 6| Step: 1
Training loss: 0.28920063376426697
Validation loss: 1.5462355690617715

Epoch: 6| Step: 2
Training loss: 0.22878330945968628
Validation loss: 1.5302276842055782

Epoch: 6| Step: 3
Training loss: 0.3570917844772339
Validation loss: 1.563166122282705

Epoch: 6| Step: 4
Training loss: 0.37068432569503784
Validation loss: 1.589389431861139

Epoch: 6| Step: 5
Training loss: 0.20279115438461304
Validation loss: 1.6255365789577525

Epoch: 6| Step: 6
Training loss: 0.29146966338157654
Validation loss: 1.6260970920644782

Epoch: 6| Step: 7
Training loss: 0.3714030981063843
Validation loss: 1.6438893336121754

Epoch: 6| Step: 8
Training loss: 0.402459055185318
Validation loss: 1.6493946454858268

Epoch: 6| Step: 9
Training loss: 0.5837136507034302
Validation loss: 1.6430768710310741

Epoch: 6| Step: 10
Training loss: 0.25891417264938354
Validation loss: 1.6343525455844017

Epoch: 6| Step: 11
Training loss: 0.2000720351934433
Validation loss: 1.6461889256713211

Epoch: 6| Step: 12
Training loss: 0.2505474388599396
Validation loss: 1.6076890127633208

Epoch: 6| Step: 13
Training loss: 0.374174028635025
Validation loss: 1.597066246053224

Epoch: 279| Step: 0
Training loss: 0.30944162607192993
Validation loss: 1.5738869264561643

Epoch: 6| Step: 1
Training loss: 0.1992318034172058
Validation loss: 1.561031590225876

Epoch: 6| Step: 2
Training loss: 0.3541640639305115
Validation loss: 1.5286312564726798

Epoch: 6| Step: 3
Training loss: 0.3989798426628113
Validation loss: 1.5155311669072797

Epoch: 6| Step: 4
Training loss: 0.24855276942253113
Validation loss: 1.523227963396298

Epoch: 6| Step: 5
Training loss: 0.18090298771858215
Validation loss: 1.5190635112024122

Epoch: 6| Step: 6
Training loss: 0.2620421051979065
Validation loss: 1.5410941531581264

Epoch: 6| Step: 7
Training loss: 0.2074638456106186
Validation loss: 1.5288843800944667

Epoch: 6| Step: 8
Training loss: 0.25079041719436646
Validation loss: 1.5642646487041185

Epoch: 6| Step: 9
Training loss: 0.4837489426136017
Validation loss: 1.567956982120391

Epoch: 6| Step: 10
Training loss: 0.3252411484718323
Validation loss: 1.6032183631773917

Epoch: 6| Step: 11
Training loss: 0.1358758509159088
Validation loss: 1.6736790903152958

Epoch: 6| Step: 12
Training loss: 0.2907247245311737
Validation loss: 1.6621932727034374

Epoch: 6| Step: 13
Training loss: 0.5240970849990845
Validation loss: 1.6894649177469232

Epoch: 280| Step: 0
Training loss: 0.31864070892333984
Validation loss: 1.6888395253048147

Epoch: 6| Step: 1
Training loss: 0.12587839365005493
Validation loss: 1.6788446710955711

Epoch: 6| Step: 2
Training loss: 0.20378825068473816
Validation loss: 1.6707624684097946

Epoch: 6| Step: 3
Training loss: 0.3670506179332733
Validation loss: 1.6583051796882384

Epoch: 6| Step: 4
Training loss: 0.16868087649345398
Validation loss: 1.6543932550696916

Epoch: 6| Step: 5
Training loss: 0.25196003913879395
Validation loss: 1.629852512831329

Epoch: 6| Step: 6
Training loss: 0.6309524774551392
Validation loss: 1.6265889047294535

Epoch: 6| Step: 7
Training loss: 0.18361471593379974
Validation loss: 1.5931579810316845

Epoch: 6| Step: 8
Training loss: 0.20818683505058289
Validation loss: 1.5766026935269755

Epoch: 6| Step: 9
Training loss: 0.30712175369262695
Validation loss: 1.5991022612458916

Epoch: 6| Step: 10
Training loss: 0.2421303391456604
Validation loss: 1.5995807622068672

Epoch: 6| Step: 11
Training loss: 0.32050788402557373
Validation loss: 1.5922672261473954

Epoch: 6| Step: 12
Training loss: 0.3694869875907898
Validation loss: 1.5975459173161497

Epoch: 6| Step: 13
Training loss: 0.2851870357990265
Validation loss: 1.5444693539732246

Epoch: 281| Step: 0
Training loss: 0.3309435546398163
Validation loss: 1.4860495444267028

Epoch: 6| Step: 1
Training loss: 0.1583995223045349
Validation loss: 1.5021988525185535

Epoch: 6| Step: 2
Training loss: 0.2773164212703705
Validation loss: 1.5161039560071883

Epoch: 6| Step: 3
Training loss: 0.11480054259300232
Validation loss: 1.4747382581874888

Epoch: 6| Step: 4
Training loss: 0.4181680381298065
Validation loss: 1.4807440683405886

Epoch: 6| Step: 5
Training loss: 0.4342072010040283
Validation loss: 1.5418969008230394

Epoch: 6| Step: 6
Training loss: 0.20824185013771057
Validation loss: 1.5525522847329416

Epoch: 6| Step: 7
Training loss: 0.24178636074066162
Validation loss: 1.579945856525052

Epoch: 6| Step: 8
Training loss: 0.12685860693454742
Validation loss: 1.5601712426831644

Epoch: 6| Step: 9
Training loss: 0.25991490483283997
Validation loss: 1.6167595732596614

Epoch: 6| Step: 10
Training loss: 0.3052305281162262
Validation loss: 1.6104481258699972

Epoch: 6| Step: 11
Training loss: 0.39873015880584717
Validation loss: 1.5978168890040407

Epoch: 6| Step: 12
Training loss: 0.6055059432983398
Validation loss: 1.6233883903872581

Epoch: 6| Step: 13
Training loss: 0.19273681938648224
Validation loss: 1.636878772448468

Epoch: 282| Step: 0
Training loss: 0.27481701970100403
Validation loss: 1.6172060415308962

Epoch: 6| Step: 1
Training loss: 0.2314774990081787
Validation loss: 1.615427904231574

Epoch: 6| Step: 2
Training loss: 0.22380998730659485
Validation loss: 1.5987670703600811

Epoch: 6| Step: 3
Training loss: 0.34196341037750244
Validation loss: 1.5591136755481843

Epoch: 6| Step: 4
Training loss: 0.258567214012146
Validation loss: 1.5905958234622914

Epoch: 6| Step: 5
Training loss: 0.4763566255569458
Validation loss: 1.5731370506748077

Epoch: 6| Step: 6
Training loss: 0.2522885501384735
Validation loss: 1.5655776031555668

Epoch: 6| Step: 7
Training loss: 0.30703800916671753
Validation loss: 1.5345716014985116

Epoch: 6| Step: 8
Training loss: 0.3710210919380188
Validation loss: 1.5496764221499044

Epoch: 6| Step: 9
Training loss: 0.3059700131416321
Validation loss: 1.5086774108230427

Epoch: 6| Step: 10
Training loss: 0.35338711738586426
Validation loss: 1.5349769989649455

Epoch: 6| Step: 11
Training loss: 0.18601274490356445
Validation loss: 1.5200186211575744

Epoch: 6| Step: 12
Training loss: 0.42499664425849915
Validation loss: 1.5120623432179934

Epoch: 6| Step: 13
Training loss: 0.7176570892333984
Validation loss: 1.4854497768545663

Epoch: 283| Step: 0
Training loss: 0.17555662989616394
Validation loss: 1.4666688929321945

Epoch: 6| Step: 1
Training loss: 0.22785444557666779
Validation loss: 1.4656719084708922

Epoch: 6| Step: 2
Training loss: 0.2677074372768402
Validation loss: 1.4923497746067662

Epoch: 6| Step: 3
Training loss: 0.30151814222335815
Validation loss: 1.5176995518387004

Epoch: 6| Step: 4
Training loss: 0.3957020938396454
Validation loss: 1.5387276885330037

Epoch: 6| Step: 5
Training loss: 0.37189024686813354
Validation loss: 1.5436735691562775

Epoch: 6| Step: 6
Training loss: 0.12785059213638306
Validation loss: 1.5325338135483444

Epoch: 6| Step: 7
Training loss: 0.23824235796928406
Validation loss: 1.5286542587382819

Epoch: 6| Step: 8
Training loss: 0.27442729473114014
Validation loss: 1.560551002461423

Epoch: 6| Step: 9
Training loss: 0.5521567463874817
Validation loss: 1.5652081569035847

Epoch: 6| Step: 10
Training loss: 0.13797947764396667
Validation loss: 1.59753530961211

Epoch: 6| Step: 11
Training loss: 0.1849248707294464
Validation loss: 1.5868135677870883

Epoch: 6| Step: 12
Training loss: 0.25469714403152466
Validation loss: 1.6074819718637774

Epoch: 6| Step: 13
Training loss: 0.4111792743206024
Validation loss: 1.6382773871062903

Epoch: 284| Step: 0
Training loss: 0.5436121821403503
Validation loss: 1.6362064307735813

Epoch: 6| Step: 1
Training loss: 0.21139395236968994
Validation loss: 1.6670178251881753

Epoch: 6| Step: 2
Training loss: 0.15847039222717285
Validation loss: 1.649712436942644

Epoch: 6| Step: 3
Training loss: 0.15949290990829468
Validation loss: 1.6160302341625254

Epoch: 6| Step: 4
Training loss: 0.34767967462539673
Validation loss: 1.5889762063180246

Epoch: 6| Step: 5
Training loss: 0.2546922266483307
Validation loss: 1.5724833780719387

Epoch: 6| Step: 6
Training loss: 0.18749317526817322
Validation loss: 1.5635882757043327

Epoch: 6| Step: 7
Training loss: 0.2982090413570404
Validation loss: 1.5879182123368787

Epoch: 6| Step: 8
Training loss: 0.47944629192352295
Validation loss: 1.5600472086219377

Epoch: 6| Step: 9
Training loss: 0.15877749025821686
Validation loss: 1.5540831653020715

Epoch: 6| Step: 10
Training loss: 0.2768639922142029
Validation loss: 1.5535852473269227

Epoch: 6| Step: 11
Training loss: 0.27425840497016907
Validation loss: 1.5712181778364285

Epoch: 6| Step: 12
Training loss: 0.17385029792785645
Validation loss: 1.568042839727094

Epoch: 6| Step: 13
Training loss: 0.29516100883483887
Validation loss: 1.607326022399369

Epoch: 285| Step: 0
Training loss: 0.30115485191345215
Validation loss: 1.5821618976131562

Epoch: 6| Step: 1
Training loss: 0.17710936069488525
Validation loss: 1.5514786140893095

Epoch: 6| Step: 2
Training loss: 0.33872005343437195
Validation loss: 1.5658525997592556

Epoch: 6| Step: 3
Training loss: 0.2855149209499359
Validation loss: 1.5801033473783923

Epoch: 6| Step: 4
Training loss: 0.22354094684123993
Validation loss: 1.551877885736445

Epoch: 6| Step: 5
Training loss: 0.3812606930732727
Validation loss: 1.529336444793209

Epoch: 6| Step: 6
Training loss: 0.20947197079658508
Validation loss: 1.5576832755919425

Epoch: 6| Step: 7
Training loss: 0.23187164962291718
Validation loss: 1.5080778855149464

Epoch: 6| Step: 8
Training loss: 0.3311077654361725
Validation loss: 1.5288589769794094

Epoch: 6| Step: 9
Training loss: 0.5241280794143677
Validation loss: 1.506855567296346

Epoch: 6| Step: 10
Training loss: 0.2042488306760788
Validation loss: 1.5236025189840665

Epoch: 6| Step: 11
Training loss: 0.28532224893569946
Validation loss: 1.536271293958028

Epoch: 6| Step: 12
Training loss: 0.24763061106204987
Validation loss: 1.5551932498972902

Epoch: 6| Step: 13
Training loss: 0.16005657613277435
Validation loss: 1.5693521191996913

Epoch: 286| Step: 0
Training loss: 0.223695769906044
Validation loss: 1.5833622063359907

Epoch: 6| Step: 1
Training loss: 0.25465312600135803
Validation loss: 1.6119372319149714

Epoch: 6| Step: 2
Training loss: 0.3087084889411926
Validation loss: 1.615391069842923

Epoch: 6| Step: 3
Training loss: 0.27538836002349854
Validation loss: 1.6202559445493965

Epoch: 6| Step: 4
Training loss: 0.1314658671617508
Validation loss: 1.6181083584344516

Epoch: 6| Step: 5
Training loss: 0.1635984480381012
Validation loss: 1.5704995214298207

Epoch: 6| Step: 6
Training loss: 0.27400022745132446
Validation loss: 1.5622391457198768

Epoch: 6| Step: 7
Training loss: 0.2715415358543396
Validation loss: 1.5484851355193763

Epoch: 6| Step: 8
Training loss: 0.34339582920074463
Validation loss: 1.5678052235675115

Epoch: 6| Step: 9
Training loss: 0.30866846442222595
Validation loss: 1.5249011401207215

Epoch: 6| Step: 10
Training loss: 0.21468162536621094
Validation loss: 1.541677991549174

Epoch: 6| Step: 11
Training loss: 0.47754842042922974
Validation loss: 1.5487683588458645

Epoch: 6| Step: 12
Training loss: 0.25815796852111816
Validation loss: 1.6199790393152544

Epoch: 6| Step: 13
Training loss: 0.284948468208313
Validation loss: 1.6102741764437767

Epoch: 287| Step: 0
Training loss: 0.2736838161945343
Validation loss: 1.6306936061510475

Epoch: 6| Step: 1
Training loss: 0.2415328025817871
Validation loss: 1.6431484196775703

Epoch: 6| Step: 2
Training loss: 0.16183897852897644
Validation loss: 1.6598876881343063

Epoch: 6| Step: 3
Training loss: 0.461558073759079
Validation loss: 1.6355325650143366

Epoch: 6| Step: 4
Training loss: 0.28916841745376587
Validation loss: 1.6073337870259439

Epoch: 6| Step: 5
Training loss: 0.16641521453857422
Validation loss: 1.6135321573544574

Epoch: 6| Step: 6
Training loss: 0.2447223961353302
Validation loss: 1.5914945922872072

Epoch: 6| Step: 7
Training loss: 0.35005873441696167
Validation loss: 1.5991184121818953

Epoch: 6| Step: 8
Training loss: 0.20759686827659607
Validation loss: 1.6145044411382368

Epoch: 6| Step: 9
Training loss: 0.3401695489883423
Validation loss: 1.5888933379163024

Epoch: 6| Step: 10
Training loss: 0.17082855105400085
Validation loss: 1.5740265448888142

Epoch: 6| Step: 11
Training loss: 0.24518093466758728
Validation loss: 1.5379604389590602

Epoch: 6| Step: 12
Training loss: 0.2837812304496765
Validation loss: 1.5450595309657436

Epoch: 6| Step: 13
Training loss: 0.21283237636089325
Validation loss: 1.5227644763967043

Epoch: 288| Step: 0
Training loss: 0.2684876322746277
Validation loss: 1.5307385421568347

Epoch: 6| Step: 1
Training loss: 0.10723759979009628
Validation loss: 1.5034579435984294

Epoch: 6| Step: 2
Training loss: 0.1503864824771881
Validation loss: 1.4956637941380984

Epoch: 6| Step: 3
Training loss: 0.24374450743198395
Validation loss: 1.5106537393344346

Epoch: 6| Step: 4
Training loss: 0.2872422933578491
Validation loss: 1.5084080708924161

Epoch: 6| Step: 5
Training loss: 0.5175925493240356
Validation loss: 1.5078437853884954

Epoch: 6| Step: 6
Training loss: 0.27194103598594666
Validation loss: 1.5124525652136853

Epoch: 6| Step: 7
Training loss: 0.2677830457687378
Validation loss: 1.546569223045021

Epoch: 6| Step: 8
Training loss: 0.30884280800819397
Validation loss: 1.5315033633221862

Epoch: 6| Step: 9
Training loss: 0.3284999430179596
Validation loss: 1.575108233318534

Epoch: 6| Step: 10
Training loss: 0.21508267521858215
Validation loss: 1.6202445594213342

Epoch: 6| Step: 11
Training loss: 0.2309325635433197
Validation loss: 1.6524766132395754

Epoch: 6| Step: 12
Training loss: 0.20193251967430115
Validation loss: 1.6352014362171132

Epoch: 6| Step: 13
Training loss: 0.29188087582588196
Validation loss: 1.6641469617043771

Epoch: 289| Step: 0
Training loss: 0.21728083491325378
Validation loss: 1.640251657014252

Epoch: 6| Step: 1
Training loss: 0.10743613541126251
Validation loss: 1.6443602743969168

Epoch: 6| Step: 2
Training loss: 0.17301703989505768
Validation loss: 1.608554159441302

Epoch: 6| Step: 3
Training loss: 0.33214297890663147
Validation loss: 1.6085797740567116

Epoch: 6| Step: 4
Training loss: 0.3071715831756592
Validation loss: 1.5989812112623645

Epoch: 6| Step: 5
Training loss: 0.163437157869339
Validation loss: 1.5731067503652265

Epoch: 6| Step: 6
Training loss: 0.351686954498291
Validation loss: 1.6328167799980409

Epoch: 6| Step: 7
Training loss: 0.47664961218833923
Validation loss: 1.6211140155792236

Epoch: 6| Step: 8
Training loss: 0.3279692530632019
Validation loss: 1.6237320848690566

Epoch: 6| Step: 9
Training loss: 0.10646195709705353
Validation loss: 1.6281214260285901

Epoch: 6| Step: 10
Training loss: 0.18494117259979248
Validation loss: 1.604776684955884

Epoch: 6| Step: 11
Training loss: 0.48389291763305664
Validation loss: 1.5921847576736121

Epoch: 6| Step: 12
Training loss: 0.1744104027748108
Validation loss: 1.5947799759526406

Epoch: 6| Step: 13
Training loss: 0.22528256475925446
Validation loss: 1.5651169374424925

Epoch: 290| Step: 0
Training loss: 0.2534732222557068
Validation loss: 1.5700331362344886

Epoch: 6| Step: 1
Training loss: 0.3229271471500397
Validation loss: 1.58277375723726

Epoch: 6| Step: 2
Training loss: 0.16234061121940613
Validation loss: 1.6203988764875679

Epoch: 6| Step: 3
Training loss: 0.255770742893219
Validation loss: 1.6143229565312784

Epoch: 6| Step: 4
Training loss: 0.2852269411087036
Validation loss: 1.6132331407198341

Epoch: 6| Step: 5
Training loss: 0.30750375986099243
Validation loss: 1.618361077001018

Epoch: 6| Step: 6
Training loss: 0.19347581267356873
Validation loss: 1.6169297143977175

Epoch: 6| Step: 7
Training loss: 0.26102888584136963
Validation loss: 1.658437672481742

Epoch: 6| Step: 8
Training loss: 0.1639855057001114
Validation loss: 1.691162718239651

Epoch: 6| Step: 9
Training loss: 0.27955126762390137
Validation loss: 1.6653423052962109

Epoch: 6| Step: 10
Training loss: 0.4491052031517029
Validation loss: 1.6351280340584375

Epoch: 6| Step: 11
Training loss: 0.24691987037658691
Validation loss: 1.6631133351274716

Epoch: 6| Step: 12
Training loss: 0.19025149941444397
Validation loss: 1.6202932865388933

Epoch: 6| Step: 13
Training loss: 0.26749303936958313
Validation loss: 1.6219243977659492

Epoch: 291| Step: 0
Training loss: 0.25344210863113403
Validation loss: 1.5827575370829592

Epoch: 6| Step: 1
Training loss: 0.23985454440116882
Validation loss: 1.587732776518791

Epoch: 6| Step: 2
Training loss: 0.23805049061775208
Validation loss: 1.5696018613794798

Epoch: 6| Step: 3
Training loss: 0.15662673115730286
Validation loss: 1.5711944321150422

Epoch: 6| Step: 4
Training loss: 0.3517528772354126
Validation loss: 1.5380658565029022

Epoch: 6| Step: 5
Training loss: 0.29326897859573364
Validation loss: 1.5402967019747662

Epoch: 6| Step: 6
Training loss: 0.11512917280197144
Validation loss: 1.5144293551803918

Epoch: 6| Step: 7
Training loss: 0.2590618431568146
Validation loss: 1.5292494438027824

Epoch: 6| Step: 8
Training loss: 0.4983631372451782
Validation loss: 1.5710293080217095

Epoch: 6| Step: 9
Training loss: 0.13981425762176514
Validation loss: 1.5268831611961446

Epoch: 6| Step: 10
Training loss: 0.15720605850219727
Validation loss: 1.5470231938105758

Epoch: 6| Step: 11
Training loss: 0.12947377562522888
Validation loss: 1.523246063981005

Epoch: 6| Step: 12
Training loss: 0.27548331022262573
Validation loss: 1.5447929328487766

Epoch: 6| Step: 13
Training loss: 0.2148890197277069
Validation loss: 1.5708489943576116

Epoch: 292| Step: 0
Training loss: 0.3892650008201599
Validation loss: 1.5728230835289083

Epoch: 6| Step: 1
Training loss: 0.16484645009040833
Validation loss: 1.5691847711481073

Epoch: 6| Step: 2
Training loss: 0.18626683950424194
Validation loss: 1.5364580949147542

Epoch: 6| Step: 3
Training loss: 0.19301530718803406
Validation loss: 1.5424646780055056

Epoch: 6| Step: 4
Training loss: 0.2787032127380371
Validation loss: 1.5165835913791452

Epoch: 6| Step: 5
Training loss: 0.16948768496513367
Validation loss: 1.5429850496271604

Epoch: 6| Step: 6
Training loss: 0.37970229983329773
Validation loss: 1.5167244788139098

Epoch: 6| Step: 7
Training loss: 0.1701485812664032
Validation loss: 1.5555394695651146

Epoch: 6| Step: 8
Training loss: 0.25132232904434204
Validation loss: 1.484569541869625

Epoch: 6| Step: 9
Training loss: 0.13405513763427734
Validation loss: 1.5377714326304774

Epoch: 6| Step: 10
Training loss: 0.16390909254550934
Validation loss: 1.5313111133472894

Epoch: 6| Step: 11
Training loss: 0.3558221161365509
Validation loss: 1.5580616445951565

Epoch: 6| Step: 12
Training loss: 0.3467930853366852
Validation loss: 1.5507445745570685

Epoch: 6| Step: 13
Training loss: 0.3458658456802368
Validation loss: 1.5377602718209709

Epoch: 293| Step: 0
Training loss: 0.19083024561405182
Validation loss: 1.5834996623377646

Epoch: 6| Step: 1
Training loss: 0.13061778247356415
Validation loss: 1.5790364473096785

Epoch: 6| Step: 2
Training loss: 0.24230912327766418
Validation loss: 1.5723786648883615

Epoch: 6| Step: 3
Training loss: 0.219725102186203
Validation loss: 1.6177688414050686

Epoch: 6| Step: 4
Training loss: 0.2531813681125641
Validation loss: 1.596433433153296

Epoch: 6| Step: 5
Training loss: 0.32607901096343994
Validation loss: 1.612834991947297

Epoch: 6| Step: 6
Training loss: 0.5580729246139526
Validation loss: 1.640771399262131

Epoch: 6| Step: 7
Training loss: 0.2548031806945801
Validation loss: 1.6371060814908756

Epoch: 6| Step: 8
Training loss: 0.2801651358604431
Validation loss: 1.5834678385847358

Epoch: 6| Step: 9
Training loss: 0.3581715226173401
Validation loss: 1.6016101324430077

Epoch: 6| Step: 10
Training loss: 0.22414717078208923
Validation loss: 1.592543758371825

Epoch: 6| Step: 11
Training loss: 0.1642291098833084
Validation loss: 1.5578552638330767

Epoch: 6| Step: 12
Training loss: 0.24372056126594543
Validation loss: 1.5502318374572261

Epoch: 6| Step: 13
Training loss: 0.13384214043617249
Validation loss: 1.5208882260066208

Epoch: 294| Step: 0
Training loss: 0.27286791801452637
Validation loss: 1.5297871110259846

Epoch: 6| Step: 1
Training loss: 0.25065773725509644
Validation loss: 1.4963165688258346

Epoch: 6| Step: 2
Training loss: 0.17106111347675323
Validation loss: 1.470704670875303

Epoch: 6| Step: 3
Training loss: 0.16543418169021606
Validation loss: 1.458551646560751

Epoch: 6| Step: 4
Training loss: 0.3133629560470581
Validation loss: 1.4588363401351436

Epoch: 6| Step: 5
Training loss: 0.2533581852912903
Validation loss: 1.4516156360667238

Epoch: 6| Step: 6
Training loss: 0.25549033284187317
Validation loss: 1.459621484561633

Epoch: 6| Step: 7
Training loss: 0.2554541826248169
Validation loss: 1.51060531216283

Epoch: 6| Step: 8
Training loss: 0.20758280158042908
Validation loss: 1.5070632862788376

Epoch: 6| Step: 9
Training loss: 0.22304767370224
Validation loss: 1.5256280834956835

Epoch: 6| Step: 10
Training loss: 0.2304474115371704
Validation loss: 1.5265291211425618

Epoch: 6| Step: 11
Training loss: 0.18786701560020447
Validation loss: 1.5667464476759716

Epoch: 6| Step: 12
Training loss: 0.13792522251605988
Validation loss: 1.6199282497488043

Epoch: 6| Step: 13
Training loss: 0.6412711143493652
Validation loss: 1.629163686947156

Epoch: 295| Step: 0
Training loss: 0.28176528215408325
Validation loss: 1.611090785713606

Epoch: 6| Step: 1
Training loss: 0.14441946148872375
Validation loss: 1.6458605104877102

Epoch: 6| Step: 2
Training loss: 0.24985992908477783
Validation loss: 1.6208494299201555

Epoch: 6| Step: 3
Training loss: 0.3195904493331909
Validation loss: 1.6110953413030153

Epoch: 6| Step: 4
Training loss: 0.3109084367752075
Validation loss: 1.6086248749045915

Epoch: 6| Step: 5
Training loss: 0.2791571021080017
Validation loss: 1.6085874021694224

Epoch: 6| Step: 6
Training loss: 0.21525061130523682
Validation loss: 1.5915449216801634

Epoch: 6| Step: 7
Training loss: 0.23984093964099884
Validation loss: 1.5712850055386942

Epoch: 6| Step: 8
Training loss: 0.15634459257125854
Validation loss: 1.5877472200701315

Epoch: 6| Step: 9
Training loss: 0.30124008655548096
Validation loss: 1.5149428613724247

Epoch: 6| Step: 10
Training loss: 0.3391243517398834
Validation loss: 1.501235374840357

Epoch: 6| Step: 11
Training loss: 0.32268157601356506
Validation loss: 1.5279511790121756

Epoch: 6| Step: 12
Training loss: 0.2628839612007141
Validation loss: 1.5165839874616234

Epoch: 6| Step: 13
Training loss: 0.22222402691841125
Validation loss: 1.5419370153898835

Epoch: 296| Step: 0
Training loss: 0.23336535692214966
Validation loss: 1.5228202996715423

Epoch: 6| Step: 1
Training loss: 0.35054677724838257
Validation loss: 1.4935555470887052

Epoch: 6| Step: 2
Training loss: 0.27301010489463806
Validation loss: 1.5316665339213547

Epoch: 6| Step: 3
Training loss: 0.356459379196167
Validation loss: 1.5224039618686964

Epoch: 6| Step: 4
Training loss: 0.33958935737609863
Validation loss: 1.5400504937735937

Epoch: 6| Step: 5
Training loss: 0.2372562140226364
Validation loss: 1.5772161445310038

Epoch: 6| Step: 6
Training loss: 0.2030636966228485
Validation loss: 1.5941608131572764

Epoch: 6| Step: 7
Training loss: 0.25395920872688293
Validation loss: 1.6169261291462889

Epoch: 6| Step: 8
Training loss: 0.2051086127758026
Validation loss: 1.6289714472268217

Epoch: 6| Step: 9
Training loss: 0.2072308361530304
Validation loss: 1.6453327209718767

Epoch: 6| Step: 10
Training loss: 0.2758632302284241
Validation loss: 1.620463131576456

Epoch: 6| Step: 11
Training loss: 0.19547739624977112
Validation loss: 1.6379080715999808

Epoch: 6| Step: 12
Training loss: 0.1749456375837326
Validation loss: 1.6552634700652091

Epoch: 6| Step: 13
Training loss: 0.18241146206855774
Validation loss: 1.628576583759759

Epoch: 297| Step: 0
Training loss: 0.15305903553962708
Validation loss: 1.5717526135906097

Epoch: 6| Step: 1
Training loss: 0.18980816006660461
Validation loss: 1.5682707281522854

Epoch: 6| Step: 2
Training loss: 0.4032701849937439
Validation loss: 1.5279440264548025

Epoch: 6| Step: 3
Training loss: 0.1733599752187729
Validation loss: 1.5335088545276272

Epoch: 6| Step: 4
Training loss: 0.2627893388271332
Validation loss: 1.5040880018664944

Epoch: 6| Step: 5
Training loss: 0.1774287074804306
Validation loss: 1.4966533568597609

Epoch: 6| Step: 6
Training loss: 0.4653366804122925
Validation loss: 1.4879756435271232

Epoch: 6| Step: 7
Training loss: 0.21706928312778473
Validation loss: 1.5073458558769637

Epoch: 6| Step: 8
Training loss: 0.27087143063545227
Validation loss: 1.5291537802706483

Epoch: 6| Step: 9
Training loss: 0.22531387209892273
Validation loss: 1.531980569644641

Epoch: 6| Step: 10
Training loss: 0.3968663215637207
Validation loss: 1.561914413206039

Epoch: 6| Step: 11
Training loss: 0.2012573778629303
Validation loss: 1.54811857592675

Epoch: 6| Step: 12
Training loss: 0.2685767114162445
Validation loss: 1.5373836768570768

Epoch: 6| Step: 13
Training loss: 0.26288124918937683
Validation loss: 1.5518151303773284

Epoch: 298| Step: 0
Training loss: 0.18044735491275787
Validation loss: 1.5532248238081574

Epoch: 6| Step: 1
Training loss: 0.21566756069660187
Validation loss: 1.5614154800291984

Epoch: 6| Step: 2
Training loss: 0.21509777009487152
Validation loss: 1.5653017387595227

Epoch: 6| Step: 3
Training loss: 0.14597183465957642
Validation loss: 1.5767575066576722

Epoch: 6| Step: 4
Training loss: 0.19118455052375793
Validation loss: 1.5997199589206326

Epoch: 6| Step: 5
Training loss: 0.2526718080043793
Validation loss: 1.642136577636965

Epoch: 6| Step: 6
Training loss: 0.6164253354072571
Validation loss: 1.70244800659918

Epoch: 6| Step: 7
Training loss: 0.24536311626434326
Validation loss: 1.6906361041530487

Epoch: 6| Step: 8
Training loss: 0.5364775657653809
Validation loss: 1.699384061239099

Epoch: 6| Step: 9
Training loss: 0.19044609367847443
Validation loss: 1.6709031699806132

Epoch: 6| Step: 10
Training loss: 0.2504189610481262
Validation loss: 1.6186738834586194

Epoch: 6| Step: 11
Training loss: 0.25021520256996155
Validation loss: 1.60065931658591

Epoch: 6| Step: 12
Training loss: 0.3127465844154358
Validation loss: 1.5400331071628037

Epoch: 6| Step: 13
Training loss: 0.24254488945007324
Validation loss: 1.521496590747628

Epoch: 299| Step: 0
Training loss: 0.25762584805488586
Validation loss: 1.4623370555139357

Epoch: 6| Step: 1
Training loss: 0.41243642568588257
Validation loss: 1.4525826438780753

Epoch: 6| Step: 2
Training loss: 0.17951048910617828
Validation loss: 1.4842330589089343

Epoch: 6| Step: 3
Training loss: 0.19390064477920532
Validation loss: 1.4667921117556992

Epoch: 6| Step: 4
Training loss: 0.1671956181526184
Validation loss: 1.4543766231947048

Epoch: 6| Step: 5
Training loss: 0.14249065518379211
Validation loss: 1.4958738306517243

Epoch: 6| Step: 6
Training loss: 0.29136067628860474
Validation loss: 1.5076181709125478

Epoch: 6| Step: 7
Training loss: 0.3502866327762604
Validation loss: 1.536310847087573

Epoch: 6| Step: 8
Training loss: 0.1835482269525528
Validation loss: 1.5329384393589471

Epoch: 6| Step: 9
Training loss: 0.24995093047618866
Validation loss: 1.5277424320097892

Epoch: 6| Step: 10
Training loss: 0.1917598992586136
Validation loss: 1.5297365444962696

Epoch: 6| Step: 11
Training loss: 0.326093465089798
Validation loss: 1.5413110807377806

Epoch: 6| Step: 12
Training loss: 0.3184409737586975
Validation loss: 1.5314124681616341

Epoch: 6| Step: 13
Training loss: 0.2759630084037781
Validation loss: 1.5221195297856485

Epoch: 300| Step: 0
Training loss: 0.09490267932415009
Validation loss: 1.5161067067935903

Epoch: 6| Step: 1
Training loss: 0.2283833920955658
Validation loss: 1.5144129901803949

Epoch: 6| Step: 2
Training loss: 0.27420109510421753
Validation loss: 1.4953517401090233

Epoch: 6| Step: 3
Training loss: 0.21495424211025238
Validation loss: 1.504260265698997

Epoch: 6| Step: 4
Training loss: 0.4515543580055237
Validation loss: 1.4906440781008812

Epoch: 6| Step: 5
Training loss: 0.1517852544784546
Validation loss: 1.5328578333700857

Epoch: 6| Step: 6
Training loss: 0.18331095576286316
Validation loss: 1.523283145120067

Epoch: 6| Step: 7
Training loss: 0.27109628915786743
Validation loss: 1.5429730184616581

Epoch: 6| Step: 8
Training loss: 0.15319478511810303
Validation loss: 1.5455809267618323

Epoch: 6| Step: 9
Training loss: 0.14481282234191895
Validation loss: 1.5376140917501142

Epoch: 6| Step: 10
Training loss: 0.26211345195770264
Validation loss: 1.5465310965814898

Epoch: 6| Step: 11
Training loss: 0.21578846871852875
Validation loss: 1.5524599449608916

Epoch: 6| Step: 12
Training loss: 0.27868977189064026
Validation loss: 1.5231731335322063

Epoch: 6| Step: 13
Training loss: 0.31992828845977783
Validation loss: 1.555252609714385

Epoch: 301| Step: 0
Training loss: 0.2244531363248825
Validation loss: 1.585658686135405

Epoch: 6| Step: 1
Training loss: 0.20939728617668152
Validation loss: 1.626863266832085

Epoch: 6| Step: 2
Training loss: 0.4275769293308258
Validation loss: 1.6466611636582242

Epoch: 6| Step: 3
Training loss: 0.2926607131958008
Validation loss: 1.632787827522524

Epoch: 6| Step: 4
Training loss: 0.22850516438484192
Validation loss: 1.636814704505346

Epoch: 6| Step: 5
Training loss: 0.27470511198043823
Validation loss: 1.6135264801722702

Epoch: 6| Step: 6
Training loss: 0.18129950761795044
Validation loss: 1.5484582634382351

Epoch: 6| Step: 7
Training loss: 0.24185332655906677
Validation loss: 1.5093508920361918

Epoch: 6| Step: 8
Training loss: 0.4073217511177063
Validation loss: 1.4834802817272883

Epoch: 6| Step: 9
Training loss: 0.3404816687107086
Validation loss: 1.4882343264036282

Epoch: 6| Step: 10
Training loss: 0.318978488445282
Validation loss: 1.4763873072080715

Epoch: 6| Step: 11
Training loss: 0.3968546390533447
Validation loss: 1.4562014033717494

Epoch: 6| Step: 12
Training loss: 0.25146037340164185
Validation loss: 1.4833717128281951

Epoch: 6| Step: 13
Training loss: 0.3232583999633789
Validation loss: 1.4940160474469584

Epoch: 302| Step: 0
Training loss: 0.39292800426483154
Validation loss: 1.51348158877383

Epoch: 6| Step: 1
Training loss: 0.2326659858226776
Validation loss: 1.532894281930821

Epoch: 6| Step: 2
Training loss: 0.3198339343070984
Validation loss: 1.533469392407325

Epoch: 6| Step: 3
Training loss: 0.2919659912586212
Validation loss: 1.5341821383404475

Epoch: 6| Step: 4
Training loss: 0.4449203908443451
Validation loss: 1.5744542357742146

Epoch: 6| Step: 5
Training loss: 0.2726275324821472
Validation loss: 1.593890913071171

Epoch: 6| Step: 6
Training loss: 0.273825079202652
Validation loss: 1.576956142661392

Epoch: 6| Step: 7
Training loss: 0.36054450273513794
Validation loss: 1.5963774304236136

Epoch: 6| Step: 8
Training loss: 0.17006973922252655
Validation loss: 1.5748658141782206

Epoch: 6| Step: 9
Training loss: 0.1981322020292282
Validation loss: 1.5645920179223503

Epoch: 6| Step: 10
Training loss: 0.2914641499519348
Validation loss: 1.524892483988116

Epoch: 6| Step: 11
Training loss: 0.20862933993339539
Validation loss: 1.5397212556613389

Epoch: 6| Step: 12
Training loss: 0.12257711589336395
Validation loss: 1.5446220239003499

Epoch: 6| Step: 13
Training loss: 0.4743969738483429
Validation loss: 1.5450032475174114

Epoch: 303| Step: 0
Training loss: 0.26198458671569824
Validation loss: 1.547520314493487

Epoch: 6| Step: 1
Training loss: 0.33971115946769714
Validation loss: 1.5725562367387997

Epoch: 6| Step: 2
Training loss: 0.28222185373306274
Validation loss: 1.5980265563534153

Epoch: 6| Step: 3
Training loss: 0.3738707900047302
Validation loss: 1.6043592806785338

Epoch: 6| Step: 4
Training loss: 0.28630462288856506
Validation loss: 1.586072015505965

Epoch: 6| Step: 5
Training loss: 0.22164922952651978
Validation loss: 1.5442982309608049

Epoch: 6| Step: 6
Training loss: 0.5552262663841248
Validation loss: 1.4980890058702039

Epoch: 6| Step: 7
Training loss: 0.30926012992858887
Validation loss: 1.5013950806792065

Epoch: 6| Step: 8
Training loss: 0.303610622882843
Validation loss: 1.4773369219995314

Epoch: 6| Step: 9
Training loss: 0.13445578515529633
Validation loss: 1.4324152277361961

Epoch: 6| Step: 10
Training loss: 0.27884846925735474
Validation loss: 1.4284149780068347

Epoch: 6| Step: 11
Training loss: 0.3428855240345001
Validation loss: 1.39116515972281

Epoch: 6| Step: 12
Training loss: 0.300253689289093
Validation loss: 1.4201530051487747

Epoch: 6| Step: 13
Training loss: 0.16209863126277924
Validation loss: 1.4421558200672109

Epoch: 304| Step: 0
Training loss: 0.4565751850605011
Validation loss: 1.4645756143395618

Epoch: 6| Step: 1
Training loss: 0.1916658580303192
Validation loss: 1.4730629562049784

Epoch: 6| Step: 2
Training loss: 0.37369996309280396
Validation loss: 1.5505593745939192

Epoch: 6| Step: 3
Training loss: 0.22273394465446472
Validation loss: 1.5204542125425031

Epoch: 6| Step: 4
Training loss: 0.2850755751132965
Validation loss: 1.5797695011220954

Epoch: 6| Step: 5
Training loss: 0.35608357191085815
Validation loss: 1.5572147959022111

Epoch: 6| Step: 6
Training loss: 0.3027236759662628
Validation loss: 1.5387873265051073

Epoch: 6| Step: 7
Training loss: 0.18220031261444092
Validation loss: 1.6059208595624535

Epoch: 6| Step: 8
Training loss: 0.20045171678066254
Validation loss: 1.5747915032089397

Epoch: 6| Step: 9
Training loss: 0.2179172933101654
Validation loss: 1.5894859606219875

Epoch: 6| Step: 10
Training loss: 0.1726817935705185
Validation loss: 1.55715912131853

Epoch: 6| Step: 11
Training loss: 0.3213440179824829
Validation loss: 1.5748784439538115

Epoch: 6| Step: 12
Training loss: 0.2775726318359375
Validation loss: 1.571268258556243

Epoch: 6| Step: 13
Training loss: 0.19829662144184113
Validation loss: 1.5763514330310207

Epoch: 305| Step: 0
Training loss: 0.20199115574359894
Validation loss: 1.5907616564022597

Epoch: 6| Step: 1
Training loss: 0.21496494114398956
Validation loss: 1.5499480642298216

Epoch: 6| Step: 2
Training loss: 0.2601097822189331
Validation loss: 1.5575293969082575

Epoch: 6| Step: 3
Training loss: 0.28869423270225525
Validation loss: 1.5447247823079426

Epoch: 6| Step: 4
Training loss: 0.23645952343940735
Validation loss: 1.5518659955711775

Epoch: 6| Step: 5
Training loss: 0.3072693347930908
Validation loss: 1.5384998744533909

Epoch: 6| Step: 6
Training loss: 0.09371805191040039
Validation loss: 1.5334987191743747

Epoch: 6| Step: 7
Training loss: 0.21896840631961823
Validation loss: 1.559591898354151

Epoch: 6| Step: 8
Training loss: 0.25724852085113525
Validation loss: 1.5670767907173402

Epoch: 6| Step: 9
Training loss: 0.21112434566020966
Validation loss: 1.5797029272202523

Epoch: 6| Step: 10
Training loss: 0.5238814949989319
Validation loss: 1.5886243645862868

Epoch: 6| Step: 11
Training loss: 0.2500537633895874
Validation loss: 1.5565430746283582

Epoch: 6| Step: 12
Training loss: 0.18934643268585205
Validation loss: 1.553658167521159

Epoch: 6| Step: 13
Training loss: 0.2545224726200104
Validation loss: 1.5422591470902967

Epoch: 306| Step: 0
Training loss: 0.24451036751270294
Validation loss: 1.5406179979283323

Epoch: 6| Step: 1
Training loss: 0.36609917879104614
Validation loss: 1.510335155712661

Epoch: 6| Step: 2
Training loss: 0.2916153073310852
Validation loss: 1.5018318148069485

Epoch: 6| Step: 3
Training loss: 0.2102522999048233
Validation loss: 1.5104739422439246

Epoch: 6| Step: 4
Training loss: 0.16173318028450012
Validation loss: 1.5335356817450574

Epoch: 6| Step: 5
Training loss: 0.2611358165740967
Validation loss: 1.5142487390066988

Epoch: 6| Step: 6
Training loss: 0.13807982206344604
Validation loss: 1.4830880383009553

Epoch: 6| Step: 7
Training loss: 0.2534414529800415
Validation loss: 1.4941996246255853

Epoch: 6| Step: 8
Training loss: 0.2100367546081543
Validation loss: 1.4931188347519084

Epoch: 6| Step: 9
Training loss: 0.20687207579612732
Validation loss: 1.519178831449119

Epoch: 6| Step: 10
Training loss: 0.414244145154953
Validation loss: 1.5283559919685445

Epoch: 6| Step: 11
Training loss: 0.20884084701538086
Validation loss: 1.571099974775827

Epoch: 6| Step: 12
Training loss: 0.2705569863319397
Validation loss: 1.5986418153650017

Epoch: 6| Step: 13
Training loss: 0.32957908511161804
Validation loss: 1.6062189161136586

Epoch: 307| Step: 0
Training loss: 0.35575923323631287
Validation loss: 1.583799704428642

Epoch: 6| Step: 1
Training loss: 0.21131038665771484
Validation loss: 1.5831100940704346

Epoch: 6| Step: 2
Training loss: 0.19031229615211487
Validation loss: 1.5844973428274995

Epoch: 6| Step: 3
Training loss: 0.18433260917663574
Validation loss: 1.5572740416372977

Epoch: 6| Step: 4
Training loss: 0.1947418451309204
Validation loss: 1.5412420021590365

Epoch: 6| Step: 5
Training loss: 0.1169903427362442
Validation loss: 1.5380831764590355

Epoch: 6| Step: 6
Training loss: 0.260731041431427
Validation loss: 1.5180819188394854

Epoch: 6| Step: 7
Training loss: 0.32034868001937866
Validation loss: 1.535644474849906

Epoch: 6| Step: 8
Training loss: 0.16276216506958008
Validation loss: 1.5166818313701178

Epoch: 6| Step: 9
Training loss: 0.35088902711868286
Validation loss: 1.5054482721513318

Epoch: 6| Step: 10
Training loss: 0.24525441229343414
Validation loss: 1.522417474818486

Epoch: 6| Step: 11
Training loss: 0.2600480318069458
Validation loss: 1.5604981709552068

Epoch: 6| Step: 12
Training loss: 0.19687294960021973
Validation loss: 1.592118340153848

Epoch: 6| Step: 13
Training loss: 0.1568089723587036
Validation loss: 1.539529663260265

Epoch: 308| Step: 0
Training loss: 0.5231187343597412
Validation loss: 1.5618685112204602

Epoch: 6| Step: 1
Training loss: 0.16658642888069153
Validation loss: 1.577031353468536

Epoch: 6| Step: 2
Training loss: 0.20024745166301727
Validation loss: 1.6046873728434246

Epoch: 6| Step: 3
Training loss: 0.25955355167388916
Validation loss: 1.583602564309233

Epoch: 6| Step: 4
Training loss: 0.30680304765701294
Validation loss: 1.6359186762122697

Epoch: 6| Step: 5
Training loss: 0.2333698868751526
Validation loss: 1.6315124419427687

Epoch: 6| Step: 6
Training loss: 0.41325679421424866
Validation loss: 1.6223591373812767

Epoch: 6| Step: 7
Training loss: 0.1864205300807953
Validation loss: 1.6262270558264948

Epoch: 6| Step: 8
Training loss: 0.14087970554828644
Validation loss: 1.6129083607786445

Epoch: 6| Step: 9
Training loss: 0.1908068209886551
Validation loss: 1.5458894993669243

Epoch: 6| Step: 10
Training loss: 0.2065054327249527
Validation loss: 1.5566250393467564

Epoch: 6| Step: 11
Training loss: 0.20132240653038025
Validation loss: 1.5561148479420652

Epoch: 6| Step: 12
Training loss: 0.25917136669158936
Validation loss: 1.542369960456766

Epoch: 6| Step: 13
Training loss: 0.05670563876628876
Validation loss: 1.529856260104846

Epoch: 309| Step: 0
Training loss: 0.09593546390533447
Validation loss: 1.5354833013267928

Epoch: 6| Step: 1
Training loss: 0.3319076895713806
Validation loss: 1.5213652913288405

Epoch: 6| Step: 2
Training loss: 0.21028955280780792
Validation loss: 1.5365409197345856

Epoch: 6| Step: 3
Training loss: 0.1940528154373169
Validation loss: 1.5482454646018244

Epoch: 6| Step: 4
Training loss: 0.4239606261253357
Validation loss: 1.5432372221382715

Epoch: 6| Step: 5
Training loss: 0.2778848707675934
Validation loss: 1.5549749725608415

Epoch: 6| Step: 6
Training loss: 0.2464914321899414
Validation loss: 1.5689627739690966

Epoch: 6| Step: 7
Training loss: 0.084299236536026
Validation loss: 1.5687974345299505

Epoch: 6| Step: 8
Training loss: 0.19796650111675262
Validation loss: 1.5839813345222062

Epoch: 6| Step: 9
Training loss: 0.5028269290924072
Validation loss: 1.6147685896965764

Epoch: 6| Step: 10
Training loss: 0.19541119039058685
Validation loss: 1.6032325119100592

Epoch: 6| Step: 11
Training loss: 0.21771298348903656
Validation loss: 1.6356488645717662

Epoch: 6| Step: 12
Training loss: 0.22166281938552856
Validation loss: 1.6166034821541078

Epoch: 6| Step: 13
Training loss: 0.1769106090068817
Validation loss: 1.6398611427635275

Epoch: 310| Step: 0
Training loss: 0.26203373074531555
Validation loss: 1.5968399624670706

Epoch: 6| Step: 1
Training loss: 0.160084068775177
Validation loss: 1.574028076023184

Epoch: 6| Step: 2
Training loss: 0.1621449589729309
Validation loss: 1.5568663202306277

Epoch: 6| Step: 3
Training loss: 0.2197965383529663
Validation loss: 1.5324839904744139

Epoch: 6| Step: 4
Training loss: 0.26499396562576294
Validation loss: 1.5240153394719607

Epoch: 6| Step: 5
Training loss: 0.22853600978851318
Validation loss: 1.5036869395163752

Epoch: 6| Step: 6
Training loss: 0.22223031520843506
Validation loss: 1.4742401556302143

Epoch: 6| Step: 7
Training loss: 0.24097856879234314
Validation loss: 1.4769709956261419

Epoch: 6| Step: 8
Training loss: 0.24493251740932465
Validation loss: 1.4961077743960964

Epoch: 6| Step: 9
Training loss: 0.48303472995758057
Validation loss: 1.4744107236144364

Epoch: 6| Step: 10
Training loss: 0.13859379291534424
Validation loss: 1.516936094530167

Epoch: 6| Step: 11
Training loss: 0.20502644777297974
Validation loss: 1.5263931584614578

Epoch: 6| Step: 12
Training loss: 0.23829568922519684
Validation loss: 1.594594806753179

Epoch: 6| Step: 13
Training loss: 0.20340923964977264
Validation loss: 1.5876836661369569

Epoch: 311| Step: 0
Training loss: 0.19771325588226318
Validation loss: 1.6015018711807907

Epoch: 6| Step: 1
Training loss: 0.48494744300842285
Validation loss: 1.616862209894324

Epoch: 6| Step: 2
Training loss: 0.27504709362983704
Validation loss: 1.5721702332137732

Epoch: 6| Step: 3
Training loss: 0.29299861192703247
Validation loss: 1.5307097114542478

Epoch: 6| Step: 4
Training loss: 0.20234453678131104
Validation loss: 1.5342253831125074

Epoch: 6| Step: 5
Training loss: 0.21536779403686523
Validation loss: 1.5534611568656018

Epoch: 6| Step: 6
Training loss: 0.17447248101234436
Validation loss: 1.5326614226064375

Epoch: 6| Step: 7
Training loss: 0.23892325162887573
Validation loss: 1.542895902869522

Epoch: 6| Step: 8
Training loss: 0.19772692024707794
Validation loss: 1.5584328712955597

Epoch: 6| Step: 9
Training loss: 0.21911856532096863
Validation loss: 1.580533803150218

Epoch: 6| Step: 10
Training loss: 0.19585976004600525
Validation loss: 1.5431255768704157

Epoch: 6| Step: 11
Training loss: 0.16006138920783997
Validation loss: 1.5360518463196293

Epoch: 6| Step: 12
Training loss: 0.3685467839241028
Validation loss: 1.5494406248933525

Epoch: 6| Step: 13
Training loss: 0.3796807527542114
Validation loss: 1.5160264058779644

Epoch: 312| Step: 0
Training loss: 0.29108235239982605
Validation loss: 1.5107567361606065

Epoch: 6| Step: 1
Training loss: 0.1703951358795166
Validation loss: 1.4720698184864496

Epoch: 6| Step: 2
Training loss: 0.1510542929172516
Validation loss: 1.4798272181582708

Epoch: 6| Step: 3
Training loss: 0.21139857172966003
Validation loss: 1.4701017173387672

Epoch: 6| Step: 4
Training loss: 0.17570748925209045
Validation loss: 1.4683172497698056

Epoch: 6| Step: 5
Training loss: 0.2250673621892929
Validation loss: 1.5085960062601234

Epoch: 6| Step: 6
Training loss: 0.20947907865047455
Validation loss: 1.538880076459659

Epoch: 6| Step: 7
Training loss: 0.2626539468765259
Validation loss: 1.5526158963480303

Epoch: 6| Step: 8
Training loss: 0.22173850238323212
Validation loss: 1.5387284755706787

Epoch: 6| Step: 9
Training loss: 0.450792133808136
Validation loss: 1.5497190785664383

Epoch: 6| Step: 10
Training loss: 0.1833774745464325
Validation loss: 1.5643969223063479

Epoch: 6| Step: 11
Training loss: 0.21068823337554932
Validation loss: 1.516017972782094

Epoch: 6| Step: 12
Training loss: 0.21730740368366241
Validation loss: 1.5044938595064226

Epoch: 6| Step: 13
Training loss: 0.16979840397834778
Validation loss: 1.4923777246987948

Epoch: 313| Step: 0
Training loss: 0.23871688544750214
Validation loss: 1.4664064248402913

Epoch: 6| Step: 1
Training loss: 0.22663645446300507
Validation loss: 1.5071318239294074

Epoch: 6| Step: 2
Training loss: 0.15011729300022125
Validation loss: 1.5126744265197425

Epoch: 6| Step: 3
Training loss: 0.10888156294822693
Validation loss: 1.5110098328641666

Epoch: 6| Step: 4
Training loss: 0.15600764751434326
Validation loss: 1.5089126915060065

Epoch: 6| Step: 5
Training loss: 0.2051628977060318
Validation loss: 1.5536196552297121

Epoch: 6| Step: 6
Training loss: 0.25983187556266785
Validation loss: 1.5630529131940616

Epoch: 6| Step: 7
Training loss: 0.2380044162273407
Validation loss: 1.5697213078057894

Epoch: 6| Step: 8
Training loss: 0.5073426365852356
Validation loss: 1.5351890774183377

Epoch: 6| Step: 9
Training loss: 0.1901426911354065
Validation loss: 1.5808432602113294

Epoch: 6| Step: 10
Training loss: 0.30006730556488037
Validation loss: 1.5788124812546598

Epoch: 6| Step: 11
Training loss: 0.18062205612659454
Validation loss: 1.592107831790883

Epoch: 6| Step: 12
Training loss: 0.3462214171886444
Validation loss: 1.56606504994054

Epoch: 6| Step: 13
Training loss: 0.20576170086860657
Validation loss: 1.5661075999659877

Epoch: 314| Step: 0
Training loss: 0.16080886125564575
Validation loss: 1.5894188163101033

Epoch: 6| Step: 1
Training loss: 0.24390412867069244
Validation loss: 1.6017923630693907

Epoch: 6| Step: 2
Training loss: 0.27091407775878906
Validation loss: 1.602310061454773

Epoch: 6| Step: 3
Training loss: 0.20392857491970062
Validation loss: 1.5992340157108922

Epoch: 6| Step: 4
Training loss: 0.19460567831993103
Validation loss: 1.5723337563135291

Epoch: 6| Step: 5
Training loss: 0.29152795672416687
Validation loss: 1.5918331325695079

Epoch: 6| Step: 6
Training loss: 0.30981171131134033
Validation loss: 1.5809008626527683

Epoch: 6| Step: 7
Training loss: 0.23188473284244537
Validation loss: 1.5472105908137497

Epoch: 6| Step: 8
Training loss: 0.31477391719818115
Validation loss: 1.5235526215645574

Epoch: 6| Step: 9
Training loss: 0.15231940150260925
Validation loss: 1.5462333271580357

Epoch: 6| Step: 10
Training loss: 0.16017135977745056
Validation loss: 1.54897823128649

Epoch: 6| Step: 11
Training loss: 0.27785077691078186
Validation loss: 1.533972929882747

Epoch: 6| Step: 12
Training loss: 0.21867910027503967
Validation loss: 1.5202018522447156

Epoch: 6| Step: 13
Training loss: 0.2122727930545807
Validation loss: 1.4759700811037453

Epoch: 315| Step: 0
Training loss: 0.30075088143348694
Validation loss: 1.4785764576286398

Epoch: 6| Step: 1
Training loss: 0.21599680185317993
Validation loss: 1.4726166455976424

Epoch: 6| Step: 2
Training loss: 0.19055701792240143
Validation loss: 1.484864184933324

Epoch: 6| Step: 3
Training loss: 0.18215206265449524
Validation loss: 1.4713934083138742

Epoch: 6| Step: 4
Training loss: 0.46525365114212036
Validation loss: 1.4448445676475443

Epoch: 6| Step: 5
Training loss: 0.23966489732265472
Validation loss: 1.4601384311593988

Epoch: 6| Step: 6
Training loss: 0.2810840308666229
Validation loss: 1.4451153150168798

Epoch: 6| Step: 7
Training loss: 0.17582112550735474
Validation loss: 1.478118545265608

Epoch: 6| Step: 8
Training loss: 0.2785190939903259
Validation loss: 1.4917913111307288

Epoch: 6| Step: 9
Training loss: 0.11605077981948853
Validation loss: 1.484577314828032

Epoch: 6| Step: 10
Training loss: 0.2932044267654419
Validation loss: 1.4530210725722774

Epoch: 6| Step: 11
Training loss: 0.1508297622203827
Validation loss: 1.468952735265096

Epoch: 6| Step: 12
Training loss: 0.20936338603496552
Validation loss: 1.4774227796062347

Epoch: 6| Step: 13
Training loss: 0.14487557113170624
Validation loss: 1.517003454187865

Epoch: 316| Step: 0
Training loss: 0.25498348474502563
Validation loss: 1.5449610628107542

Epoch: 6| Step: 1
Training loss: 0.39320531487464905
Validation loss: 1.5715970723859725

Epoch: 6| Step: 2
Training loss: 0.1585327684879303
Validation loss: 1.5895754714165964

Epoch: 6| Step: 3
Training loss: 0.24690815806388855
Validation loss: 1.629965078446173

Epoch: 6| Step: 4
Training loss: 0.2510364055633545
Validation loss: 1.6114032447979014

Epoch: 6| Step: 5
Training loss: 0.32216888666152954
Validation loss: 1.5907725826386483

Epoch: 6| Step: 6
Training loss: 0.25752314925193787
Validation loss: 1.575217121390886

Epoch: 6| Step: 7
Training loss: 0.27416032552719116
Validation loss: 1.5281233044080837

Epoch: 6| Step: 8
Training loss: 0.18665508925914764
Validation loss: 1.564811437360702

Epoch: 6| Step: 9
Training loss: 0.3499268889427185
Validation loss: 1.5339350597832793

Epoch: 6| Step: 10
Training loss: 0.1564170867204666
Validation loss: 1.5547237268058203

Epoch: 6| Step: 11
Training loss: 0.10549330711364746
Validation loss: 1.5586830710852018

Epoch: 6| Step: 12
Training loss: 0.17055338621139526
Validation loss: 1.5457681635374665

Epoch: 6| Step: 13
Training loss: 0.1711854338645935
Validation loss: 1.526810533256941

Epoch: 317| Step: 0
Training loss: 0.17218910157680511
Validation loss: 1.5035769631785731

Epoch: 6| Step: 1
Training loss: 0.24233564734458923
Validation loss: 1.5135254193377752

Epoch: 6| Step: 2
Training loss: 0.2929920554161072
Validation loss: 1.504657781252297

Epoch: 6| Step: 3
Training loss: 0.24002806842327118
Validation loss: 1.510688425392233

Epoch: 6| Step: 4
Training loss: 0.4137147068977356
Validation loss: 1.4816692272822063

Epoch: 6| Step: 5
Training loss: 0.18136131763458252
Validation loss: 1.4838891926632132

Epoch: 6| Step: 6
Training loss: 0.19306163489818573
Validation loss: 1.490951035612373

Epoch: 6| Step: 7
Training loss: 0.15389078855514526
Validation loss: 1.5018780859567786

Epoch: 6| Step: 8
Training loss: 0.17412632703781128
Validation loss: 1.508054994767712

Epoch: 6| Step: 9
Training loss: 0.20104050636291504
Validation loss: 1.5105521525106123

Epoch: 6| Step: 10
Training loss: 0.2412663698196411
Validation loss: 1.483441839935959

Epoch: 6| Step: 11
Training loss: 0.2291610985994339
Validation loss: 1.4712575738148024

Epoch: 6| Step: 12
Training loss: 0.12520524859428406
Validation loss: 1.4795983081222863

Epoch: 6| Step: 13
Training loss: 0.08380380272865295
Validation loss: 1.488606047886674

Epoch: 318| Step: 0
Training loss: 0.18078598380088806
Validation loss: 1.4805020606645973

Epoch: 6| Step: 1
Training loss: 0.1512824296951294
Validation loss: 1.5039024122299687

Epoch: 6| Step: 2
Training loss: 0.22773632407188416
Validation loss: 1.51005708530385

Epoch: 6| Step: 3
Training loss: 0.44457361102104187
Validation loss: 1.537206562616492

Epoch: 6| Step: 4
Training loss: 0.24538904428482056
Validation loss: 1.518234052965718

Epoch: 6| Step: 5
Training loss: 0.15754690766334534
Validation loss: 1.5468452963777768

Epoch: 6| Step: 6
Training loss: 0.18492016196250916
Validation loss: 1.5671451796767533

Epoch: 6| Step: 7
Training loss: 0.3107242286205292
Validation loss: 1.5843745713592858

Epoch: 6| Step: 8
Training loss: 0.22023743391036987
Validation loss: 1.5693181945431618

Epoch: 6| Step: 9
Training loss: 0.18770146369934082
Validation loss: 1.5695874742282334

Epoch: 6| Step: 10
Training loss: 0.2337981015443802
Validation loss: 1.5578840586446947

Epoch: 6| Step: 11
Training loss: 0.1495293378829956
Validation loss: 1.5639793206286687

Epoch: 6| Step: 12
Training loss: 0.21039658784866333
Validation loss: 1.5188455286846365

Epoch: 6| Step: 13
Training loss: 0.14018987119197845
Validation loss: 1.5595973230177356

Epoch: 319| Step: 0
Training loss: 0.17822480201721191
Validation loss: 1.5375276996243386

Epoch: 6| Step: 1
Training loss: 0.15899768471717834
Validation loss: 1.541570976216306

Epoch: 6| Step: 2
Training loss: 0.23743952810764313
Validation loss: 1.5605282065688924

Epoch: 6| Step: 3
Training loss: 0.3948546350002289
Validation loss: 1.5425138922147854

Epoch: 6| Step: 4
Training loss: 0.24977000057697296
Validation loss: 1.5517265899207002

Epoch: 6| Step: 5
Training loss: 0.15470945835113525
Validation loss: 1.556233957249631

Epoch: 6| Step: 6
Training loss: 0.19224125146865845
Validation loss: 1.5497750684779177

Epoch: 6| Step: 7
Training loss: 0.20869991183280945
Validation loss: 1.5653842379969936

Epoch: 6| Step: 8
Training loss: 0.31192290782928467
Validation loss: 1.6051987845410582

Epoch: 6| Step: 9
Training loss: 0.17440912127494812
Validation loss: 1.6002017323688795

Epoch: 6| Step: 10
Training loss: 0.2153584212064743
Validation loss: 1.601480277635718

Epoch: 6| Step: 11
Training loss: 0.5056134462356567
Validation loss: 1.6013999023745138

Epoch: 6| Step: 12
Training loss: 0.18109899759292603
Validation loss: 1.629887302716573

Epoch: 6| Step: 13
Training loss: 0.2807895839214325
Validation loss: 1.6049211102147256

Epoch: 320| Step: 0
Training loss: 0.3446701169013977
Validation loss: 1.6029302291972662

Epoch: 6| Step: 1
Training loss: 0.24232739210128784
Validation loss: 1.5814700959831156

Epoch: 6| Step: 2
Training loss: 0.13646858930587769
Validation loss: 1.6109103900130077

Epoch: 6| Step: 3
Training loss: 0.14120769500732422
Validation loss: 1.6077093847336308

Epoch: 6| Step: 4
Training loss: 0.24850323796272278
Validation loss: 1.5963902422176894

Epoch: 6| Step: 5
Training loss: 0.18859514594078064
Validation loss: 1.5899900864529353

Epoch: 6| Step: 6
Training loss: 0.2217330038547516
Validation loss: 1.5696074988252373

Epoch: 6| Step: 7
Training loss: 0.17996454238891602
Validation loss: 1.5501229474621434

Epoch: 6| Step: 8
Training loss: 0.1365853101015091
Validation loss: 1.5630229570532357

Epoch: 6| Step: 9
Training loss: 0.1839771866798401
Validation loss: 1.5159809230476298

Epoch: 6| Step: 10
Training loss: 0.21219009160995483
Validation loss: 1.5173525425695604

Epoch: 6| Step: 11
Training loss: 0.452578067779541
Validation loss: 1.4428991156239663

Epoch: 6| Step: 12
Training loss: 0.26573532819747925
Validation loss: 1.4337148986836916

Epoch: 6| Step: 13
Training loss: 0.2315448671579361
Validation loss: 1.4331399586892897

Epoch: 321| Step: 0
Training loss: 0.32340213656425476
Validation loss: 1.4195671683998519

Epoch: 6| Step: 1
Training loss: 0.5418347120285034
Validation loss: 1.4640433198662215

Epoch: 6| Step: 2
Training loss: 0.3337399959564209
Validation loss: 1.4679138211793796

Epoch: 6| Step: 3
Training loss: 0.36303582787513733
Validation loss: 1.453763756059831

Epoch: 6| Step: 4
Training loss: 0.187110036611557
Validation loss: 1.4341122476003503

Epoch: 6| Step: 5
Training loss: 0.12244519591331482
Validation loss: 1.4801235839884768

Epoch: 6| Step: 6
Training loss: 0.26283010840415955
Validation loss: 1.493692216052804

Epoch: 6| Step: 7
Training loss: 0.184940367937088
Validation loss: 1.4974374540390507

Epoch: 6| Step: 8
Training loss: 0.17138725519180298
Validation loss: 1.5750284156491678

Epoch: 6| Step: 9
Training loss: 0.19572879374027252
Validation loss: 1.6312461694081624

Epoch: 6| Step: 10
Training loss: 0.17691396176815033
Validation loss: 1.598391705943692

Epoch: 6| Step: 11
Training loss: 0.23782587051391602
Validation loss: 1.588737141701483

Epoch: 6| Step: 12
Training loss: 0.1935204416513443
Validation loss: 1.6096223528667162

Epoch: 6| Step: 13
Training loss: 0.20476073026657104
Validation loss: 1.6094291261447373

Epoch: 322| Step: 0
Training loss: 0.3664558529853821
Validation loss: 1.579347228491178

Epoch: 6| Step: 1
Training loss: 0.19590730965137482
Validation loss: 1.578729373152538

Epoch: 6| Step: 2
Training loss: 0.1465131640434265
Validation loss: 1.5597612216908445

Epoch: 6| Step: 3
Training loss: 0.11203421652317047
Validation loss: 1.5446281907378987

Epoch: 6| Step: 4
Training loss: 0.1798117756843567
Validation loss: 1.5339806195228332

Epoch: 6| Step: 5
Training loss: 0.17120546102523804
Validation loss: 1.5092525943633048

Epoch: 6| Step: 6
Training loss: 0.3183756470680237
Validation loss: 1.4988259153981363

Epoch: 6| Step: 7
Training loss: 0.17699582874774933
Validation loss: 1.472826825675144

Epoch: 6| Step: 8
Training loss: 0.19603726267814636
Validation loss: 1.4630772875201317

Epoch: 6| Step: 9
Training loss: 0.18848000466823578
Validation loss: 1.4714412330299296

Epoch: 6| Step: 10
Training loss: 0.22396689653396606
Validation loss: 1.4487181184112385

Epoch: 6| Step: 11
Training loss: 0.17093470692634583
Validation loss: 1.455272973224681

Epoch: 6| Step: 12
Training loss: 0.11521433293819427
Validation loss: 1.471796989761373

Epoch: 6| Step: 13
Training loss: 0.15822771191596985
Validation loss: 1.492902140463552

Epoch: 323| Step: 0
Training loss: 0.30131930112838745
Validation loss: 1.4780311610109063

Epoch: 6| Step: 1
Training loss: 0.17425769567489624
Validation loss: 1.500571640588904

Epoch: 6| Step: 2
Training loss: 0.2128930240869522
Validation loss: 1.4589198975152866

Epoch: 6| Step: 3
Training loss: 0.1742658019065857
Validation loss: 1.452591452547299

Epoch: 6| Step: 4
Training loss: 0.41587531566619873
Validation loss: 1.4723235125182776

Epoch: 6| Step: 5
Training loss: 0.1768224537372589
Validation loss: 1.4831603944942515

Epoch: 6| Step: 6
Training loss: 0.14820154011249542
Validation loss: 1.5148643832052908

Epoch: 6| Step: 7
Training loss: 0.13570475578308105
Validation loss: 1.5213953577062136

Epoch: 6| Step: 8
Training loss: 0.23401866853237152
Validation loss: 1.5216599805380708

Epoch: 6| Step: 9
Training loss: 0.26833659410476685
Validation loss: 1.5299467297010525

Epoch: 6| Step: 10
Training loss: 0.1897299587726593
Validation loss: 1.5576031054219892

Epoch: 6| Step: 11
Training loss: 0.2409156858921051
Validation loss: 1.582308235988822

Epoch: 6| Step: 12
Training loss: 0.13105744123458862
Validation loss: 1.567122652966489

Epoch: 6| Step: 13
Training loss: 0.2938275635242462
Validation loss: 1.590029731873543

Epoch: 324| Step: 0
Training loss: 0.14006070792675018
Validation loss: 1.6064464648564656

Epoch: 6| Step: 1
Training loss: 0.3495771884918213
Validation loss: 1.6123092610348937

Epoch: 6| Step: 2
Training loss: 0.19907328486442566
Validation loss: 1.6646327844230078

Epoch: 6| Step: 3
Training loss: 0.27631354331970215
Validation loss: 1.5906361520931285

Epoch: 6| Step: 4
Training loss: 0.16327175498008728
Validation loss: 1.5699691349460232

Epoch: 6| Step: 5
Training loss: 0.1357310712337494
Validation loss: 1.568028288502847

Epoch: 6| Step: 6
Training loss: 0.18554750084877014
Validation loss: 1.5415931247895764

Epoch: 6| Step: 7
Training loss: 0.21419523656368256
Validation loss: 1.4858832814360177

Epoch: 6| Step: 8
Training loss: 0.18398338556289673
Validation loss: 1.492657164091705

Epoch: 6| Step: 9
Training loss: 0.27098560333251953
Validation loss: 1.4664244254430134

Epoch: 6| Step: 10
Training loss: 0.2021009624004364
Validation loss: 1.4575651473896478

Epoch: 6| Step: 11
Training loss: 0.287137508392334
Validation loss: 1.470254837825734

Epoch: 6| Step: 12
Training loss: 0.2124428153038025
Validation loss: 1.4966378647794005

Epoch: 6| Step: 13
Training loss: 0.22334837913513184
Validation loss: 1.5303841239662581

Epoch: 325| Step: 0
Training loss: 0.2435704916715622
Validation loss: 1.560176904483508

Epoch: 6| Step: 1
Training loss: 0.27772825956344604
Validation loss: 1.5938447944579586

Epoch: 6| Step: 2
Training loss: 0.21948830783367157
Validation loss: 1.5628402912488548

Epoch: 6| Step: 3
Training loss: 0.18175259232521057
Validation loss: 1.6058790504291494

Epoch: 6| Step: 4
Training loss: 0.19485792517662048
Validation loss: 1.6321858693194646

Epoch: 6| Step: 5
Training loss: 0.15690195560455322
Validation loss: 1.6622998701628817

Epoch: 6| Step: 6
Training loss: 0.16189375519752502
Validation loss: 1.6523608533284997

Epoch: 6| Step: 7
Training loss: 0.1547115594148636
Validation loss: 1.6629711120359358

Epoch: 6| Step: 8
Training loss: 0.3502326011657715
Validation loss: 1.6305265106180662

Epoch: 6| Step: 9
Training loss: 0.3097245693206787
Validation loss: 1.6326749517071633

Epoch: 6| Step: 10
Training loss: 0.28329986333847046
Validation loss: 1.6372009631126159

Epoch: 6| Step: 11
Training loss: 0.40865635871887207
Validation loss: 1.653032813661842

Epoch: 6| Step: 12
Training loss: 0.2617206573486328
Validation loss: 1.6282424324302263

Epoch: 6| Step: 13
Training loss: 0.23108328878879547
Validation loss: 1.6087149984093123

Epoch: 326| Step: 0
Training loss: 0.3382892310619354
Validation loss: 1.5854292966986214

Epoch: 6| Step: 1
Training loss: 0.18114422261714935
Validation loss: 1.5777602298285371

Epoch: 6| Step: 2
Training loss: 0.10433647781610489
Validation loss: 1.540993990436677

Epoch: 6| Step: 3
Training loss: 0.13841426372528076
Validation loss: 1.5188948653077567

Epoch: 6| Step: 4
Training loss: 0.27928876876831055
Validation loss: 1.540492578219342

Epoch: 6| Step: 5
Training loss: 0.261109858751297
Validation loss: 1.5139482687878352

Epoch: 6| Step: 6
Training loss: 0.24164703488349915
Validation loss: 1.5383363898082445

Epoch: 6| Step: 7
Training loss: 0.17841923236846924
Validation loss: 1.5236832070094284

Epoch: 6| Step: 8
Training loss: 0.2150239646434784
Validation loss: 1.5919132835121566

Epoch: 6| Step: 9
Training loss: 0.21002574265003204
Validation loss: 1.5919373048249112

Epoch: 6| Step: 10
Training loss: 0.18052667379379272
Validation loss: 1.60074830824329

Epoch: 6| Step: 11
Training loss: 0.15193313360214233
Validation loss: 1.6153820189096595

Epoch: 6| Step: 12
Training loss: 0.12559305131435394
Validation loss: 1.6072007674042896

Epoch: 6| Step: 13
Training loss: 0.09001757204532623
Validation loss: 1.6058297798197756

Epoch: 327| Step: 0
Training loss: 0.1513747125864029
Validation loss: 1.5826629912981423

Epoch: 6| Step: 1
Training loss: 0.20399555563926697
Validation loss: 1.584473725288145

Epoch: 6| Step: 2
Training loss: 0.2152860313653946
Validation loss: 1.56149306092211

Epoch: 6| Step: 3
Training loss: 0.15727949142456055
Validation loss: 1.5348332466617707

Epoch: 6| Step: 4
Training loss: 0.15309402346611023
Validation loss: 1.5170716470287693

Epoch: 6| Step: 5
Training loss: 0.20540376007556915
Validation loss: 1.468680433047715

Epoch: 6| Step: 6
Training loss: 0.17066311836242676
Validation loss: 1.443922660684073

Epoch: 6| Step: 7
Training loss: 0.27604347467422485
Validation loss: 1.440618247114202

Epoch: 6| Step: 8
Training loss: 0.24759161472320557
Validation loss: 1.440591045605239

Epoch: 6| Step: 9
Training loss: 0.2258608192205429
Validation loss: 1.4617255221131027

Epoch: 6| Step: 10
Training loss: 0.2385728657245636
Validation loss: 1.462140429404474

Epoch: 6| Step: 11
Training loss: 0.4050522446632385
Validation loss: 1.48566480605833

Epoch: 6| Step: 12
Training loss: 0.2186889499425888
Validation loss: 1.5139871951072448

Epoch: 6| Step: 13
Training loss: 0.306324303150177
Validation loss: 1.5510414633699643

Epoch: 328| Step: 0
Training loss: 0.2701261639595032
Validation loss: 1.563903752193656

Epoch: 6| Step: 1
Training loss: 0.16832123696804047
Validation loss: 1.6306850820459344

Epoch: 6| Step: 2
Training loss: 0.12444864958524704
Validation loss: 1.6311124114580051

Epoch: 6| Step: 3
Training loss: 0.19084855914115906
Validation loss: 1.625027564264113

Epoch: 6| Step: 4
Training loss: 0.4465380311012268
Validation loss: 1.5992289640570199

Epoch: 6| Step: 5
Training loss: 0.21753555536270142
Validation loss: 1.5894614252992856

Epoch: 6| Step: 6
Training loss: 0.20534349977970123
Validation loss: 1.5485406319300334

Epoch: 6| Step: 7
Training loss: 0.21954883635044098
Validation loss: 1.554729700088501

Epoch: 6| Step: 8
Training loss: 0.24324779212474823
Validation loss: 1.5238801817740164

Epoch: 6| Step: 9
Training loss: 0.13070909678936005
Validation loss: 1.4996240703008508

Epoch: 6| Step: 10
Training loss: 0.12751120328903198
Validation loss: 1.4919561698872557

Epoch: 6| Step: 11
Training loss: 0.17018359899520874
Validation loss: 1.4725961210907146

Epoch: 6| Step: 12
Training loss: 0.178232342004776
Validation loss: 1.4697214582914948

Epoch: 6| Step: 13
Training loss: 0.11140533536672592
Validation loss: 1.4565449017350391

Epoch: 329| Step: 0
Training loss: 0.22149580717086792
Validation loss: 1.5022610848949802

Epoch: 6| Step: 1
Training loss: 0.17108607292175293
Validation loss: 1.4963058592170797

Epoch: 6| Step: 2
Training loss: 0.15543031692504883
Validation loss: 1.5106276728773629

Epoch: 6| Step: 3
Training loss: 0.21026186645030975
Validation loss: 1.4771428608125257

Epoch: 6| Step: 4
Training loss: 0.19568085670471191
Validation loss: 1.4538592100143433

Epoch: 6| Step: 5
Training loss: 0.26419565081596375
Validation loss: 1.4422606691237418

Epoch: 6| Step: 6
Training loss: 0.25274941325187683
Validation loss: 1.4248341552672847

Epoch: 6| Step: 7
Training loss: 0.20071513950824738
Validation loss: 1.388030828327261

Epoch: 6| Step: 8
Training loss: 0.2085488736629486
Validation loss: 1.3947384331815986

Epoch: 6| Step: 9
Training loss: 0.32139307260513306
Validation loss: 1.4183411136750252

Epoch: 6| Step: 10
Training loss: 0.2244769036769867
Validation loss: 1.4629268005330076

Epoch: 6| Step: 11
Training loss: 0.5053192377090454
Validation loss: 1.4717544970973846

Epoch: 6| Step: 12
Training loss: 0.1410166472196579
Validation loss: 1.4689185580899637

Epoch: 6| Step: 13
Training loss: 0.11705534905195236
Validation loss: 1.492358620448779

Epoch: 330| Step: 0
Training loss: 0.1056261658668518
Validation loss: 1.5156594719938052

Epoch: 6| Step: 1
Training loss: 0.2555699646472931
Validation loss: 1.525592843691508

Epoch: 6| Step: 2
Training loss: 0.19588947296142578
Validation loss: 1.5125756654688107

Epoch: 6| Step: 3
Training loss: 0.24140581488609314
Validation loss: 1.5229072634891798

Epoch: 6| Step: 4
Training loss: 0.20281745493412018
Validation loss: 1.5306170114906885

Epoch: 6| Step: 5
Training loss: 0.3079931139945984
Validation loss: 1.494374954572288

Epoch: 6| Step: 6
Training loss: 0.15558813512325287
Validation loss: 1.549624478945168

Epoch: 6| Step: 7
Training loss: 0.269023060798645
Validation loss: 1.5159884140055666

Epoch: 6| Step: 8
Training loss: 0.21224601566791534
Validation loss: 1.466453170263639

Epoch: 6| Step: 9
Training loss: 0.11350525915622711
Validation loss: 1.4882938137618444

Epoch: 6| Step: 10
Training loss: 0.3225868344306946
Validation loss: 1.5054191799574002

Epoch: 6| Step: 11
Training loss: 0.20040638744831085
Validation loss: 1.4923930014333417

Epoch: 6| Step: 12
Training loss: 0.1534218192100525
Validation loss: 1.4754507195565008

Epoch: 6| Step: 13
Training loss: 0.3221680521965027
Validation loss: 1.4730513390674387

Epoch: 331| Step: 0
Training loss: 0.24469806253910065
Validation loss: 1.4908810354048205

Epoch: 6| Step: 1
Training loss: 0.31665071845054626
Validation loss: 1.484771313205842

Epoch: 6| Step: 2
Training loss: 0.2510424554347992
Validation loss: 1.4797709834191106

Epoch: 6| Step: 3
Training loss: 0.09649789333343506
Validation loss: 1.5064574339056527

Epoch: 6| Step: 4
Training loss: 0.2584170401096344
Validation loss: 1.496281728949598

Epoch: 6| Step: 5
Training loss: 0.15681979060173035
Validation loss: 1.5117780816170476

Epoch: 6| Step: 6
Training loss: 0.21719741821289062
Validation loss: 1.5314387018962572

Epoch: 6| Step: 7
Training loss: 0.18860089778900146
Validation loss: 1.5008616652539981

Epoch: 6| Step: 8
Training loss: 0.3854740262031555
Validation loss: 1.4852261094636814

Epoch: 6| Step: 9
Training loss: 0.16388481855392456
Validation loss: 1.4808142518484464

Epoch: 6| Step: 10
Training loss: 0.15050742030143738
Validation loss: 1.5088578693328365

Epoch: 6| Step: 11
Training loss: 0.13188588619232178
Validation loss: 1.4821428329713884

Epoch: 6| Step: 12
Training loss: 0.2474496066570282
Validation loss: 1.5141850556096723

Epoch: 6| Step: 13
Training loss: 0.21300680935382843
Validation loss: 1.5225319977729552

Epoch: 332| Step: 0
Training loss: 0.13799455761909485
Validation loss: 1.547017462791935

Epoch: 6| Step: 1
Training loss: 0.2462143748998642
Validation loss: 1.5509673280100669

Epoch: 6| Step: 2
Training loss: 0.35094332695007324
Validation loss: 1.559886504885971

Epoch: 6| Step: 3
Training loss: 0.15080440044403076
Validation loss: 1.5752759953980804

Epoch: 6| Step: 4
Training loss: 0.18144428730010986
Validation loss: 1.5970127723550285

Epoch: 6| Step: 5
Training loss: 0.24659213423728943
Validation loss: 1.633323497669671

Epoch: 6| Step: 6
Training loss: 0.47054293751716614
Validation loss: 1.6468105700708204

Epoch: 6| Step: 7
Training loss: 0.23727568984031677
Validation loss: 1.6627611370496853

Epoch: 6| Step: 8
Training loss: 0.1583719402551651
Validation loss: 1.6139438767586984

Epoch: 6| Step: 9
Training loss: 0.28324443101882935
Validation loss: 1.5997554025342386

Epoch: 6| Step: 10
Training loss: 0.15976497530937195
Validation loss: 1.60083830741144

Epoch: 6| Step: 11
Training loss: 0.25731369853019714
Validation loss: 1.5664688694861628

Epoch: 6| Step: 12
Training loss: 0.17110557854175568
Validation loss: 1.5705713661768104

Epoch: 6| Step: 13
Training loss: 0.38217830657958984
Validation loss: 1.5303733502664874

Epoch: 333| Step: 0
Training loss: 0.1658770740032196
Validation loss: 1.5329560656701364

Epoch: 6| Step: 1
Training loss: 0.1325569748878479
Validation loss: 1.5182947599759666

Epoch: 6| Step: 2
Training loss: 0.41280192136764526
Validation loss: 1.4956387665963942

Epoch: 6| Step: 3
Training loss: 0.1647106409072876
Validation loss: 1.4912414076507732

Epoch: 6| Step: 4
Training loss: 0.17566457390785217
Validation loss: 1.512819133779054

Epoch: 6| Step: 5
Training loss: 0.18600408732891083
Validation loss: 1.4912291047393635

Epoch: 6| Step: 6
Training loss: 0.18198475241661072
Validation loss: 1.5035560720710344

Epoch: 6| Step: 7
Training loss: 0.1754051148891449
Validation loss: 1.494066015366585

Epoch: 6| Step: 8
Training loss: 0.13148081302642822
Validation loss: 1.5110474004540393

Epoch: 6| Step: 9
Training loss: 0.18319135904312134
Validation loss: 1.4877170067961498

Epoch: 6| Step: 10
Training loss: 0.12688423693180084
Validation loss: 1.4579838706601052

Epoch: 6| Step: 11
Training loss: 0.19876116514205933
Validation loss: 1.4590414275405228

Epoch: 6| Step: 12
Training loss: 0.1842258870601654
Validation loss: 1.4987428284460498

Epoch: 6| Step: 13
Training loss: 0.25426703691482544
Validation loss: 1.4962676648170716

Epoch: 334| Step: 0
Training loss: 0.17928242683410645
Validation loss: 1.4810108420669392

Epoch: 6| Step: 1
Training loss: 0.1088198646903038
Validation loss: 1.5048764546712239

Epoch: 6| Step: 2
Training loss: 0.18996061384677887
Validation loss: 1.508059823384849

Epoch: 6| Step: 3
Training loss: 0.24473461508750916
Validation loss: 1.5501380261554514

Epoch: 6| Step: 4
Training loss: 0.40027785301208496
Validation loss: 1.5642026316735052

Epoch: 6| Step: 5
Training loss: 0.18308795988559723
Validation loss: 1.5807902159229401

Epoch: 6| Step: 6
Training loss: 0.23818159103393555
Validation loss: 1.5895884575382355

Epoch: 6| Step: 7
Training loss: 0.19737716019153595
Validation loss: 1.6023615714042418

Epoch: 6| Step: 8
Training loss: 0.2408761829137802
Validation loss: 1.5875215440668085

Epoch: 6| Step: 9
Training loss: 0.12402023375034332
Validation loss: 1.5617412790175407

Epoch: 6| Step: 10
Training loss: 0.1516229808330536
Validation loss: 1.5497267194973525

Epoch: 6| Step: 11
Training loss: 0.09379521757364273
Validation loss: 1.5435201532097274

Epoch: 6| Step: 12
Training loss: 0.1291598230600357
Validation loss: 1.5343776556753344

Epoch: 6| Step: 13
Training loss: 0.23778626322746277
Validation loss: 1.5239405926837717

Epoch: 335| Step: 0
Training loss: 0.13328847289085388
Validation loss: 1.5337030195420789

Epoch: 6| Step: 1
Training loss: 0.09946289658546448
Validation loss: 1.4994374616171724

Epoch: 6| Step: 2
Training loss: 0.19360622763633728
Validation loss: 1.4925531828275291

Epoch: 6| Step: 3
Training loss: 0.18775524199008942
Validation loss: 1.4900359005056403

Epoch: 6| Step: 4
Training loss: 0.15728265047073364
Validation loss: 1.4842159549395244

Epoch: 6| Step: 5
Training loss: 0.13886678218841553
Validation loss: 1.50631631189777

Epoch: 6| Step: 6
Training loss: 0.2946271002292633
Validation loss: 1.471850242666019

Epoch: 6| Step: 7
Training loss: 0.2982197701931
Validation loss: 1.5229900383180188

Epoch: 6| Step: 8
Training loss: 0.1865568906068802
Validation loss: 1.5237065374210317

Epoch: 6| Step: 9
Training loss: 0.14047980308532715
Validation loss: 1.5317199204557685

Epoch: 6| Step: 10
Training loss: 0.14489403367042542
Validation loss: 1.5036987367496695

Epoch: 6| Step: 11
Training loss: 0.12627916038036346
Validation loss: 1.4715425327260008

Epoch: 6| Step: 12
Training loss: 0.20134137570858002
Validation loss: 1.4728034029724777

Epoch: 6| Step: 13
Training loss: 0.19559186697006226
Validation loss: 1.4738683136560584

Epoch: 336| Step: 0
Training loss: 0.3926639258861542
Validation loss: 1.4658399794691352

Epoch: 6| Step: 1
Training loss: 0.14112117886543274
Validation loss: 1.4464934795133528

Epoch: 6| Step: 2
Training loss: 0.2482079565525055
Validation loss: 1.4374693004033898

Epoch: 6| Step: 3
Training loss: 0.2311495840549469
Validation loss: 1.44666277721364

Epoch: 6| Step: 4
Training loss: 0.14648276567459106
Validation loss: 1.4597580073982157

Epoch: 6| Step: 5
Training loss: 0.11846624314785004
Validation loss: 1.4516109843407907

Epoch: 6| Step: 6
Training loss: 0.14762617647647858
Validation loss: 1.4761396197862522

Epoch: 6| Step: 7
Training loss: 0.09718672931194305
Validation loss: 1.5207412101889168

Epoch: 6| Step: 8
Training loss: 0.2209593504667282
Validation loss: 1.480591235622283

Epoch: 6| Step: 9
Training loss: 0.2504863739013672
Validation loss: 1.5008627932558778

Epoch: 6| Step: 10
Training loss: 0.13197526335716248
Validation loss: 1.5243445827114968

Epoch: 6| Step: 11
Training loss: 0.14781220257282257
Validation loss: 1.5050789643359441

Epoch: 6| Step: 12
Training loss: 0.24635347723960876
Validation loss: 1.5049442104114

Epoch: 6| Step: 13
Training loss: 0.16505108773708344
Validation loss: 1.4984797611031482

Epoch: 337| Step: 0
Training loss: 0.205141082406044
Validation loss: 1.4731979344480781

Epoch: 6| Step: 1
Training loss: 0.1340588629245758
Validation loss: 1.432761756322717

Epoch: 6| Step: 2
Training loss: 0.2526145279407501
Validation loss: 1.4198838087820238

Epoch: 6| Step: 3
Training loss: 0.1986181139945984
Validation loss: 1.3964582412473616

Epoch: 6| Step: 4
Training loss: 0.2117840051651001
Validation loss: 1.3843692951304938

Epoch: 6| Step: 5
Training loss: 0.20020648837089539
Validation loss: 1.4249798931101316

Epoch: 6| Step: 6
Training loss: 0.1603216975927353
Validation loss: 1.400524664950627

Epoch: 6| Step: 7
Training loss: 0.1927487701177597
Validation loss: 1.3937651547052528

Epoch: 6| Step: 8
Training loss: 0.3001861572265625
Validation loss: 1.384682107997197

Epoch: 6| Step: 9
Training loss: 0.33255478739738464
Validation loss: 1.452540083598065

Epoch: 6| Step: 10
Training loss: 0.22002241015434265
Validation loss: 1.4383511094636814

Epoch: 6| Step: 11
Training loss: 0.2784162759780884
Validation loss: 1.5022280459762902

Epoch: 6| Step: 12
Training loss: 0.12046454846858978
Validation loss: 1.4892634294366325

Epoch: 6| Step: 13
Training loss: 0.2523277997970581
Validation loss: 1.5091314905433244

Epoch: 338| Step: 0
Training loss: 0.22736462950706482
Validation loss: 1.5325633031065746

Epoch: 6| Step: 1
Training loss: 0.15153875946998596
Validation loss: 1.5186953442071074

Epoch: 6| Step: 2
Training loss: 0.16791962087154388
Validation loss: 1.522378416471584

Epoch: 6| Step: 3
Training loss: 0.3209366798400879
Validation loss: 1.5631727326300837

Epoch: 6| Step: 4
Training loss: 0.27127644419670105
Validation loss: 1.5657122071071337

Epoch: 6| Step: 5
Training loss: 0.18196475505828857
Validation loss: 1.5771013729033931

Epoch: 6| Step: 6
Training loss: 0.16843697428703308
Validation loss: 1.615559377977925

Epoch: 6| Step: 7
Training loss: 0.19716876745224
Validation loss: 1.606464562877532

Epoch: 6| Step: 8
Training loss: 0.17787259817123413
Validation loss: 1.637978756299583

Epoch: 6| Step: 9
Training loss: 0.139532670378685
Validation loss: 1.619547104322782

Epoch: 6| Step: 10
Training loss: 0.13388827443122864
Validation loss: 1.6086072210342652

Epoch: 6| Step: 11
Training loss: 0.18518958985805511
Validation loss: 1.5848592032668412

Epoch: 6| Step: 12
Training loss: 0.18189199268817902
Validation loss: 1.5829208832915111

Epoch: 6| Step: 13
Training loss: 0.17721644043922424
Validation loss: 1.5573158135978125

Epoch: 339| Step: 0
Training loss: 0.1357799619436264
Validation loss: 1.5506935465720393

Epoch: 6| Step: 1
Training loss: 0.2461976855993271
Validation loss: 1.5383734305699666

Epoch: 6| Step: 2
Training loss: 0.2544460594654083
Validation loss: 1.538715321530578

Epoch: 6| Step: 3
Training loss: 0.18404702842235565
Validation loss: 1.5154941748547297

Epoch: 6| Step: 4
Training loss: 0.224689781665802
Validation loss: 1.5129315724936865

Epoch: 6| Step: 5
Training loss: 0.15860360860824585
Validation loss: 1.5018107365536433

Epoch: 6| Step: 6
Training loss: 0.24172863364219666
Validation loss: 1.5281337050981418

Epoch: 6| Step: 7
Training loss: 0.1653885543346405
Validation loss: 1.5163033117530167

Epoch: 6| Step: 8
Training loss: 0.18456581234931946
Validation loss: 1.5447279278950026

Epoch: 6| Step: 9
Training loss: 0.13507063686847687
Validation loss: 1.5593512724804621

Epoch: 6| Step: 10
Training loss: 0.16703954339027405
Validation loss: 1.5374995508501608

Epoch: 6| Step: 11
Training loss: 0.2893725037574768
Validation loss: 1.5546239806759743

Epoch: 6| Step: 12
Training loss: 0.1295572966337204
Validation loss: 1.5396290440713205

Epoch: 6| Step: 13
Training loss: 0.29192912578582764
Validation loss: 1.499697482714089

Epoch: 340| Step: 0
Training loss: 0.11938294023275375
Validation loss: 1.4918259830885037

Epoch: 6| Step: 1
Training loss: 0.1286335587501526
Validation loss: 1.5188551115733322

Epoch: 6| Step: 2
Training loss: 0.26659101247787476
Validation loss: 1.5243880287293465

Epoch: 6| Step: 3
Training loss: 0.22434772551059723
Validation loss: 1.5292171483398767

Epoch: 6| Step: 4
Training loss: 0.2640899419784546
Validation loss: 1.5324206262506463

Epoch: 6| Step: 5
Training loss: 0.16553670167922974
Validation loss: 1.5216093435082385

Epoch: 6| Step: 6
Training loss: 0.18857578933238983
Validation loss: 1.493367391247903

Epoch: 6| Step: 7
Training loss: 0.14231029152870178
Validation loss: 1.4526873160434026

Epoch: 6| Step: 8
Training loss: 0.19175586104393005
Validation loss: 1.4624105499636741

Epoch: 6| Step: 9
Training loss: 0.14216887950897217
Validation loss: 1.4847882050339893

Epoch: 6| Step: 10
Training loss: 0.15072846412658691
Validation loss: 1.4835067038894982

Epoch: 6| Step: 11
Training loss: 0.3501620888710022
Validation loss: 1.5197582142327422

Epoch: 6| Step: 12
Training loss: 0.14155927300453186
Validation loss: 1.5618125200271606

Epoch: 6| Step: 13
Training loss: 0.4325762093067169
Validation loss: 1.5771138462969052

Epoch: 341| Step: 0
Training loss: 0.14735081791877747
Validation loss: 1.57490413419662

Epoch: 6| Step: 1
Training loss: 0.19982632994651794
Validation loss: 1.5494883521910636

Epoch: 6| Step: 2
Training loss: 0.30948078632354736
Validation loss: 1.5269434964785011

Epoch: 6| Step: 3
Training loss: 0.37634947896003723
Validation loss: 1.4799658726620417

Epoch: 6| Step: 4
Training loss: 0.10636495798826218
Validation loss: 1.5234251573521604

Epoch: 6| Step: 5
Training loss: 0.23305857181549072
Validation loss: 1.452794922295437

Epoch: 6| Step: 6
Training loss: 0.12643590569496155
Validation loss: 1.4436308921024363

Epoch: 6| Step: 7
Training loss: 0.19572517275810242
Validation loss: 1.4238642108055852

Epoch: 6| Step: 8
Training loss: 0.21139922738075256
Validation loss: 1.4610035996283255

Epoch: 6| Step: 9
Training loss: 0.20516663789749146
Validation loss: 1.484117962339873

Epoch: 6| Step: 10
Training loss: 0.14858943223953247
Validation loss: 1.4772276993720763

Epoch: 6| Step: 11
Training loss: 0.17035698890686035
Validation loss: 1.5161822931740874

Epoch: 6| Step: 12
Training loss: 0.18552710115909576
Validation loss: 1.5693291348795737

Epoch: 6| Step: 13
Training loss: 0.1878768354654312
Validation loss: 1.6172350657883512

Epoch: 342| Step: 0
Training loss: 0.24203112721443176
Validation loss: 1.6182069099077614

Epoch: 6| Step: 1
Training loss: 0.21249693632125854
Validation loss: 1.6426771802286948

Epoch: 6| Step: 2
Training loss: 0.20504304766654968
Validation loss: 1.6440469641839304

Epoch: 6| Step: 3
Training loss: 0.21497800946235657
Validation loss: 1.6227633196820495

Epoch: 6| Step: 4
Training loss: 0.23985899984836578
Validation loss: 1.621207446180364

Epoch: 6| Step: 5
Training loss: 0.24712792038917542
Validation loss: 1.578341334096847

Epoch: 6| Step: 6
Training loss: 0.15389420092105865
Validation loss: 1.5429376927755212

Epoch: 6| Step: 7
Training loss: 0.19045895338058472
Validation loss: 1.5436538355324858

Epoch: 6| Step: 8
Training loss: 0.2080973982810974
Validation loss: 1.5197564901844147

Epoch: 6| Step: 9
Training loss: 0.19937844574451447
Validation loss: 1.5195621521242204

Epoch: 6| Step: 10
Training loss: 0.22410151362419128
Validation loss: 1.4513744808012439

Epoch: 6| Step: 11
Training loss: 0.16180676221847534
Validation loss: 1.4144683807126937

Epoch: 6| Step: 12
Training loss: 0.35544636845588684
Validation loss: 1.3985791898542834

Epoch: 6| Step: 13
Training loss: 0.239429771900177
Validation loss: 1.4077214528155584

Epoch: 343| Step: 0
Training loss: 0.2580128610134125
Validation loss: 1.398622376944429

Epoch: 6| Step: 1
Training loss: 0.24664302170276642
Validation loss: 1.4061941780069822

Epoch: 6| Step: 2
Training loss: 0.17434780299663544
Validation loss: 1.3794922623583066

Epoch: 6| Step: 3
Training loss: 0.21904903650283813
Validation loss: 1.369549539781386

Epoch: 6| Step: 4
Training loss: 0.21938449144363403
Validation loss: 1.426121659176324

Epoch: 6| Step: 5
Training loss: 0.2479851245880127
Validation loss: 1.4545385171008367

Epoch: 6| Step: 6
Training loss: 0.20019546151161194
Validation loss: 1.4604051407947336

Epoch: 6| Step: 7
Training loss: 0.20063799619674683
Validation loss: 1.507454591412698

Epoch: 6| Step: 8
Training loss: 0.35688138008117676
Validation loss: 1.5280181771965438

Epoch: 6| Step: 9
Training loss: 0.1955263763666153
Validation loss: 1.5403293960837907

Epoch: 6| Step: 10
Training loss: 0.10815837979316711
Validation loss: 1.5752408671122726

Epoch: 6| Step: 11
Training loss: 0.1947648972272873
Validation loss: 1.5845193824460428

Epoch: 6| Step: 12
Training loss: 0.20022305846214294
Validation loss: 1.5629385004761398

Epoch: 6| Step: 13
Training loss: 0.2064976990222931
Validation loss: 1.5854108692497335

Epoch: 344| Step: 0
Training loss: 0.1474868506193161
Validation loss: 1.5554178555806477

Epoch: 6| Step: 1
Training loss: 0.1684281975030899
Validation loss: 1.533313407692858

Epoch: 6| Step: 2
Training loss: 0.2438744306564331
Validation loss: 1.5079750553254159

Epoch: 6| Step: 3
Training loss: 0.22630375623703003
Validation loss: 1.479670081087338

Epoch: 6| Step: 4
Training loss: 0.2758426070213318
Validation loss: 1.5014767499380215

Epoch: 6| Step: 5
Training loss: 0.2790791094303131
Validation loss: 1.4941658525056736

Epoch: 6| Step: 6
Training loss: 0.14120611548423767
Validation loss: 1.4794322226637153

Epoch: 6| Step: 7
Training loss: 0.10959423333406448
Validation loss: 1.4709543246094898

Epoch: 6| Step: 8
Training loss: 0.135359525680542
Validation loss: 1.51286575102037

Epoch: 6| Step: 9
Training loss: 0.2933690547943115
Validation loss: 1.471743176060338

Epoch: 6| Step: 10
Training loss: 0.14440378546714783
Validation loss: 1.4940796975166566

Epoch: 6| Step: 11
Training loss: 0.17270323634147644
Validation loss: 1.4958909275711223

Epoch: 6| Step: 12
Training loss: 0.16366276144981384
Validation loss: 1.4917470511569773

Epoch: 6| Step: 13
Training loss: 0.1079401820898056
Validation loss: 1.4911312146853375

Epoch: 345| Step: 0
Training loss: 0.16866683959960938
Validation loss: 1.4869243098843483

Epoch: 6| Step: 1
Training loss: 0.17111697793006897
Validation loss: 1.4923894995002336

Epoch: 6| Step: 2
Training loss: 0.19042439758777618
Validation loss: 1.457644312612472

Epoch: 6| Step: 3
Training loss: 0.2792096734046936
Validation loss: 1.4680649958631045

Epoch: 6| Step: 4
Training loss: 0.16167637705802917
Validation loss: 1.4829078374370452

Epoch: 6| Step: 5
Training loss: 0.15353378653526306
Validation loss: 1.515199839427907

Epoch: 6| Step: 6
Training loss: 0.1915280669927597
Validation loss: 1.486779434706575

Epoch: 6| Step: 7
Training loss: 0.15593165159225464
Validation loss: 1.4733981932363203

Epoch: 6| Step: 8
Training loss: 0.12496732920408249
Validation loss: 1.484977360694639

Epoch: 6| Step: 9
Training loss: 0.23875029385089874
Validation loss: 1.4911122911719865

Epoch: 6| Step: 10
Training loss: 0.1903870701789856
Validation loss: 1.4860807106059084

Epoch: 6| Step: 11
Training loss: 0.4405144155025482
Validation loss: 1.523784274696022

Epoch: 6| Step: 12
Training loss: 0.2280730903148651
Validation loss: 1.5522401396946242

Epoch: 6| Step: 13
Training loss: 0.2538335621356964
Validation loss: 1.5386097879819973

Epoch: 346| Step: 0
Training loss: 0.2337227165699005
Validation loss: 1.521149835278911

Epoch: 6| Step: 1
Training loss: 0.12299562990665436
Validation loss: 1.5558081775583246

Epoch: 6| Step: 2
Training loss: 0.20390306413173676
Validation loss: 1.550836443901062

Epoch: 6| Step: 3
Training loss: 0.14839819073677063
Validation loss: 1.5247822769226567

Epoch: 6| Step: 4
Training loss: 0.2406589686870575
Validation loss: 1.5679990553086804

Epoch: 6| Step: 5
Training loss: 0.15864485502243042
Validation loss: 1.5992291383845831

Epoch: 6| Step: 6
Training loss: 0.27576619386672974
Validation loss: 1.6109452606529318

Epoch: 6| Step: 7
Training loss: 0.24954235553741455
Validation loss: 1.6045927988585604

Epoch: 6| Step: 8
Training loss: 0.18262699246406555
Validation loss: 1.627195837677166

Epoch: 6| Step: 9
Training loss: 0.21592843532562256
Validation loss: 1.597402375231507

Epoch: 6| Step: 10
Training loss: 0.17691105604171753
Validation loss: 1.5574868058645597

Epoch: 6| Step: 11
Training loss: 0.1707986295223236
Validation loss: 1.5869592620480446

Epoch: 6| Step: 12
Training loss: 0.20255400240421295
Validation loss: 1.5628298431314447

Epoch: 6| Step: 13
Training loss: 0.5341156721115112
Validation loss: 1.5238626310902257

Epoch: 347| Step: 0
Training loss: 0.25993987917900085
Validation loss: 1.4877558844063872

Epoch: 6| Step: 1
Training loss: 0.18145477771759033
Validation loss: 1.4847991184521747

Epoch: 6| Step: 2
Training loss: 0.17854256927967072
Validation loss: 1.4947626129273446

Epoch: 6| Step: 3
Training loss: 0.17087391018867493
Validation loss: 1.5021044887522215

Epoch: 6| Step: 4
Training loss: 0.20587176084518433
Validation loss: 1.5350490564941077

Epoch: 6| Step: 5
Training loss: 0.2267094850540161
Validation loss: 1.5319818514649586

Epoch: 6| Step: 6
Training loss: 0.23460273444652557
Validation loss: 1.5739403629815707

Epoch: 6| Step: 7
Training loss: 0.16370466351509094
Validation loss: 1.5794687988937541

Epoch: 6| Step: 8
Training loss: 0.33467578887939453
Validation loss: 1.574677526309926

Epoch: 6| Step: 9
Training loss: 0.15676747262477875
Validation loss: 1.5816068662110196

Epoch: 6| Step: 10
Training loss: 0.17995046079158783
Validation loss: 1.556323725690124

Epoch: 6| Step: 11
Training loss: 0.12328249961137772
Validation loss: 1.5805086179446148

Epoch: 6| Step: 12
Training loss: 0.1663815975189209
Validation loss: 1.5304307681258007

Epoch: 6| Step: 13
Training loss: 0.26131460070610046
Validation loss: 1.5459477555367254

Epoch: 348| Step: 0
Training loss: 0.1670481115579605
Validation loss: 1.5124133197210168

Epoch: 6| Step: 1
Training loss: 0.1273336112499237
Validation loss: 1.4982269457591477

Epoch: 6| Step: 2
Training loss: 0.14113079011440277
Validation loss: 1.504217819500995

Epoch: 6| Step: 3
Training loss: 0.10162284970283508
Validation loss: 1.4889541928486159

Epoch: 6| Step: 4
Training loss: 0.12582841515541077
Validation loss: 1.4879317463085215

Epoch: 6| Step: 5
Training loss: 0.15812206268310547
Validation loss: 1.4869320123426375

Epoch: 6| Step: 6
Training loss: 0.12944933772087097
Validation loss: 1.4980225639958535

Epoch: 6| Step: 7
Training loss: 0.17782288789749146
Validation loss: 1.4846146234902002

Epoch: 6| Step: 8
Training loss: 0.3470228314399719
Validation loss: 1.4960743227312643

Epoch: 6| Step: 9
Training loss: 0.22681781649589539
Validation loss: 1.5211530923843384

Epoch: 6| Step: 10
Training loss: 0.20125730335712433
Validation loss: 1.5222045631818875

Epoch: 6| Step: 11
Training loss: 0.11699647456407547
Validation loss: 1.5161379024546633

Epoch: 6| Step: 12
Training loss: 0.10300333052873611
Validation loss: 1.5002416833754508

Epoch: 6| Step: 13
Training loss: 0.09910301119089127
Validation loss: 1.5177781325514599

Epoch: 349| Step: 0
Training loss: 0.16315925121307373
Validation loss: 1.5320769010051605

Epoch: 6| Step: 1
Training loss: 0.14481893181800842
Validation loss: 1.5157454629098215

Epoch: 6| Step: 2
Training loss: 0.16023355722427368
Validation loss: 1.5650902332798127

Epoch: 6| Step: 3
Training loss: 0.1983473151922226
Validation loss: 1.5729064044132028

Epoch: 6| Step: 4
Training loss: 0.13686390221118927
Validation loss: 1.580567439397176

Epoch: 6| Step: 5
Training loss: 0.19006609916687012
Validation loss: 1.628764538354771

Epoch: 6| Step: 6
Training loss: 0.18258732557296753
Validation loss: 1.6112814449494886

Epoch: 6| Step: 7
Training loss: 0.21466270089149475
Validation loss: 1.613745040791009

Epoch: 6| Step: 8
Training loss: 0.3542937636375427
Validation loss: 1.6342850128809612

Epoch: 6| Step: 9
Training loss: 0.1516895592212677
Validation loss: 1.6049751697048065

Epoch: 6| Step: 10
Training loss: 0.17073246836662292
Validation loss: 1.5782862837596605

Epoch: 6| Step: 11
Training loss: 0.18608325719833374
Validation loss: 1.6283555992187992

Epoch: 6| Step: 12
Training loss: 0.14482486248016357
Validation loss: 1.575010040754913

Epoch: 6| Step: 13
Training loss: 0.18861831724643707
Validation loss: 1.5163820200068976

Epoch: 350| Step: 0
Training loss: 0.1236819326877594
Validation loss: 1.4864206519178165

Epoch: 6| Step: 1
Training loss: 0.30535757541656494
Validation loss: 1.4737565017515613

Epoch: 6| Step: 2
Training loss: 0.14333444833755493
Validation loss: 1.4866872461893226

Epoch: 6| Step: 3
Training loss: 0.1398227959871292
Validation loss: 1.4535781337368874

Epoch: 6| Step: 4
Training loss: 0.20306508243083954
Validation loss: 1.4761963339262112

Epoch: 6| Step: 5
Training loss: 0.16185636818408966
Validation loss: 1.4938870476138206

Epoch: 6| Step: 6
Training loss: 0.1860363781452179
Validation loss: 1.5146482362542102

Epoch: 6| Step: 7
Training loss: 0.15682604908943176
Validation loss: 1.5478877835376288

Epoch: 6| Step: 8
Training loss: 0.1512296199798584
Validation loss: 1.5662191580700617

Epoch: 6| Step: 9
Training loss: 0.18745556473731995
Validation loss: 1.5716968069794357

Epoch: 6| Step: 10
Training loss: 0.1817832887172699
Validation loss: 1.5855165502076507

Epoch: 6| Step: 11
Training loss: 0.1760523021221161
Validation loss: 1.592075353027672

Epoch: 6| Step: 12
Training loss: 0.19004304707050323
Validation loss: 1.6118953394633468

Epoch: 6| Step: 13
Training loss: 0.10191433876752853
Validation loss: 1.5532795831721316

Epoch: 351| Step: 0
Training loss: 0.1411873996257782
Validation loss: 1.5557560818169707

Epoch: 6| Step: 1
Training loss: 0.05617646127939224
Validation loss: 1.5465549204939155

Epoch: 6| Step: 2
Training loss: 0.4223616123199463
Validation loss: 1.5203234431564168

Epoch: 6| Step: 3
Training loss: 0.11682188510894775
Validation loss: 1.5212816346076228

Epoch: 6| Step: 4
Training loss: 0.15537914633750916
Validation loss: 1.5230938785819597

Epoch: 6| Step: 5
Training loss: 0.15616801381111145
Validation loss: 1.501422074533278

Epoch: 6| Step: 6
Training loss: 0.2058376669883728
Validation loss: 1.524146972164031

Epoch: 6| Step: 7
Training loss: 0.1713964343070984
Validation loss: 1.5017904549516656

Epoch: 6| Step: 8
Training loss: 0.1967795044183731
Validation loss: 1.5205381595960228

Epoch: 6| Step: 9
Training loss: 0.2711763083934784
Validation loss: 1.4898503352237005

Epoch: 6| Step: 10
Training loss: 0.14557743072509766
Validation loss: 1.497016950320172

Epoch: 6| Step: 11
Training loss: 0.1883707046508789
Validation loss: 1.5222132116235711

Epoch: 6| Step: 12
Training loss: 0.15289823710918427
Validation loss: 1.4848205415151452

Epoch: 6| Step: 13
Training loss: 0.14018715918064117
Validation loss: 1.5006033387235416

Epoch: 352| Step: 0
Training loss: 0.1409066617488861
Validation loss: 1.5271558735960273

Epoch: 6| Step: 1
Training loss: 0.20181497931480408
Validation loss: 1.5266758062506234

Epoch: 6| Step: 2
Training loss: 0.19862888753414154
Validation loss: 1.5623487605843493

Epoch: 6| Step: 3
Training loss: 0.20103470981121063
Validation loss: 1.5506782980375393

Epoch: 6| Step: 4
Training loss: 0.1610468327999115
Validation loss: 1.5654224695697907

Epoch: 6| Step: 5
Training loss: 0.3595815896987915
Validation loss: 1.5724129189727127

Epoch: 6| Step: 6
Training loss: 0.09853814542293549
Validation loss: 1.5591191245663552

Epoch: 6| Step: 7
Training loss: 0.0879383236169815
Validation loss: 1.561254128333061

Epoch: 6| Step: 8
Training loss: 0.13423307240009308
Validation loss: 1.570982402370822

Epoch: 6| Step: 9
Training loss: 0.1925712674856186
Validation loss: 1.5403358872218798

Epoch: 6| Step: 10
Training loss: 0.14791131019592285
Validation loss: 1.5465977371379893

Epoch: 6| Step: 11
Training loss: 0.1821189522743225
Validation loss: 1.5292476556634391

Epoch: 6| Step: 12
Training loss: 0.17288023233413696
Validation loss: 1.5547016307871828

Epoch: 6| Step: 13
Training loss: 0.19648504257202148
Validation loss: 1.5450580068813857

Epoch: 353| Step: 0
Training loss: 0.17071405053138733
Validation loss: 1.5641883509133452

Epoch: 6| Step: 1
Training loss: 0.11842001974582672
Validation loss: 1.5324138902848767

Epoch: 6| Step: 2
Training loss: 0.12672267854213715
Validation loss: 1.5199548787968133

Epoch: 6| Step: 3
Training loss: 0.16912537813186646
Validation loss: 1.5082412778690297

Epoch: 6| Step: 4
Training loss: 0.22952485084533691
Validation loss: 1.5003443277010353

Epoch: 6| Step: 5
Training loss: 0.14803043007850647
Validation loss: 1.4992952218619726

Epoch: 6| Step: 6
Training loss: 0.2860979735851288
Validation loss: 1.471180090340235

Epoch: 6| Step: 7
Training loss: 0.09792685508728027
Validation loss: 1.4713064829508464

Epoch: 6| Step: 8
Training loss: 0.09506285190582275
Validation loss: 1.4161468205913421

Epoch: 6| Step: 9
Training loss: 0.1361905038356781
Validation loss: 1.4188511243430517

Epoch: 6| Step: 10
Training loss: 0.12035521119832993
Validation loss: 1.4082934894869406

Epoch: 6| Step: 11
Training loss: 0.11127736419439316
Validation loss: 1.4300441318942654

Epoch: 6| Step: 12
Training loss: 0.15978547930717468
Validation loss: 1.4428820417773338

Epoch: 6| Step: 13
Training loss: 0.18724924325942993
Validation loss: 1.4175329310919649

Epoch: 354| Step: 0
Training loss: 0.22970810532569885
Validation loss: 1.4606831727489349

Epoch: 6| Step: 1
Training loss: 0.18796053528785706
Validation loss: 1.4697342059945548

Epoch: 6| Step: 2
Training loss: 0.1565280556678772
Validation loss: 1.49464717988045

Epoch: 6| Step: 3
Training loss: 0.1496572196483612
Validation loss: 1.529903563120032

Epoch: 6| Step: 4
Training loss: 0.21662624180316925
Validation loss: 1.5414887314201684

Epoch: 6| Step: 5
Training loss: 0.2240082025527954
Validation loss: 1.5598974074086835

Epoch: 6| Step: 6
Training loss: 0.23188722133636475
Validation loss: 1.5910102821165515

Epoch: 6| Step: 7
Training loss: 0.13276779651641846
Validation loss: 1.6036874017407816

Epoch: 6| Step: 8
Training loss: 0.19714191555976868
Validation loss: 1.608367020084012

Epoch: 6| Step: 9
Training loss: 0.13258278369903564
Validation loss: 1.619270952798987

Epoch: 6| Step: 10
Training loss: 0.1888393610715866
Validation loss: 1.5783334521837131

Epoch: 6| Step: 11
Training loss: 0.14729008078575134
Validation loss: 1.5651873555234683

Epoch: 6| Step: 12
Training loss: 0.3318721652030945
Validation loss: 1.5793359138632332

Epoch: 6| Step: 13
Training loss: 0.194721058011055
Validation loss: 1.572070549893123

Epoch: 355| Step: 0
Training loss: 0.28863200545310974
Validation loss: 1.5462639459999659

Epoch: 6| Step: 1
Training loss: 0.17293182015419006
Validation loss: 1.5429724800971247

Epoch: 6| Step: 2
Training loss: 0.14256617426872253
Validation loss: 1.535667275869718

Epoch: 6| Step: 3
Training loss: 0.1493234634399414
Validation loss: 1.5450215775479552

Epoch: 6| Step: 4
Training loss: 0.21803857386112213
Validation loss: 1.5403586510689027

Epoch: 6| Step: 5
Training loss: 0.21602289378643036
Validation loss: 1.4978364321493334

Epoch: 6| Step: 6
Training loss: 0.1388290673494339
Validation loss: 1.5057566794016028

Epoch: 6| Step: 7
Training loss: 0.15582343935966492
Validation loss: 1.476310190334115

Epoch: 6| Step: 8
Training loss: 0.14682966470718384
Validation loss: 1.457089868924951

Epoch: 6| Step: 9
Training loss: 0.17031137645244598
Validation loss: 1.4358368407013595

Epoch: 6| Step: 10
Training loss: 0.1667858213186264
Validation loss: 1.4609359156700872

Epoch: 6| Step: 11
Training loss: 0.18444520235061646
Validation loss: 1.46952425536289

Epoch: 6| Step: 12
Training loss: 0.20991384983062744
Validation loss: 1.5145491938437186

Epoch: 6| Step: 13
Training loss: 0.1308552473783493
Validation loss: 1.4963979836433166

Epoch: 356| Step: 0
Training loss: 0.1910669505596161
Validation loss: 1.5177176972871185

Epoch: 6| Step: 1
Training loss: 0.13779306411743164
Validation loss: 1.4803325412093953

Epoch: 6| Step: 2
Training loss: 0.14267508685588837
Validation loss: 1.5153767344772175

Epoch: 6| Step: 3
Training loss: 0.11275210976600647
Validation loss: 1.5431638142114044

Epoch: 6| Step: 4
Training loss: 0.19873526692390442
Validation loss: 1.5064967742530249

Epoch: 6| Step: 5
Training loss: 0.13834413886070251
Validation loss: 1.5320676994580094

Epoch: 6| Step: 6
Training loss: 0.1046990156173706
Validation loss: 1.5451467216655772

Epoch: 6| Step: 7
Training loss: 0.12853825092315674
Validation loss: 1.5018722575197938

Epoch: 6| Step: 8
Training loss: 0.13453227281570435
Validation loss: 1.5194606088822888

Epoch: 6| Step: 9
Training loss: 0.16646577417850494
Validation loss: 1.5009304849050378

Epoch: 6| Step: 10
Training loss: 0.21013203263282776
Validation loss: 1.5224948749747327

Epoch: 6| Step: 11
Training loss: 0.27532291412353516
Validation loss: 1.4908632052842008

Epoch: 6| Step: 12
Training loss: 0.20291684567928314
Validation loss: 1.482600236451754

Epoch: 6| Step: 13
Training loss: 0.23772189021110535
Validation loss: 1.4552763200575305

Epoch: 357| Step: 0
Training loss: 0.12411080300807953
Validation loss: 1.4411654600533106

Epoch: 6| Step: 1
Training loss: 0.15488965809345245
Validation loss: 1.4474531610806782

Epoch: 6| Step: 2
Training loss: 0.13313692808151245
Validation loss: 1.4616320030663603

Epoch: 6| Step: 3
Training loss: 0.0985448881983757
Validation loss: 1.4297121147955618

Epoch: 6| Step: 4
Training loss: 0.17018616199493408
Validation loss: 1.4164515618355042

Epoch: 6| Step: 5
Training loss: 0.18398913741111755
Validation loss: 1.3877712539447251

Epoch: 6| Step: 6
Training loss: 0.13144448399543762
Validation loss: 1.4203515437341505

Epoch: 6| Step: 7
Training loss: 0.1516035497188568
Validation loss: 1.4298668792170863

Epoch: 6| Step: 8
Training loss: 0.15278495848178864
Validation loss: 1.430027202893329

Epoch: 6| Step: 9
Training loss: 0.19045546650886536
Validation loss: 1.4284107979907785

Epoch: 6| Step: 10
Training loss: 0.1293628215789795
Validation loss: 1.4583611642160723

Epoch: 6| Step: 11
Training loss: 0.3173278272151947
Validation loss: 1.4468522097474785

Epoch: 6| Step: 12
Training loss: 0.2558213472366333
Validation loss: 1.4589883909430554

Epoch: 6| Step: 13
Training loss: 0.14806438982486725
Validation loss: 1.4500998809773435

Epoch: 358| Step: 0
Training loss: 0.17908118665218353
Validation loss: 1.527452721390673

Epoch: 6| Step: 1
Training loss: 0.17012882232666016
Validation loss: 1.50628629807503

Epoch: 6| Step: 2
Training loss: 0.1487962007522583
Validation loss: 1.5635389474130446

Epoch: 6| Step: 3
Training loss: 0.17359140515327454
Validation loss: 1.562976275720904

Epoch: 6| Step: 4
Training loss: 0.2096213698387146
Validation loss: 1.5487479189390778

Epoch: 6| Step: 5
Training loss: 0.29207736253738403
Validation loss: 1.5908025849250056

Epoch: 6| Step: 6
Training loss: 0.2241385579109192
Validation loss: 1.5588395775005381

Epoch: 6| Step: 7
Training loss: 0.15823334455490112
Validation loss: 1.592241043685585

Epoch: 6| Step: 8
Training loss: 0.3582739531993866
Validation loss: 1.5614703477069896

Epoch: 6| Step: 9
Training loss: 0.1985015571117401
Validation loss: 1.5529462598985242

Epoch: 6| Step: 10
Training loss: 0.1804037094116211
Validation loss: 1.5626262708376812

Epoch: 6| Step: 11
Training loss: 0.16093623638153076
Validation loss: 1.542001731934086

Epoch: 6| Step: 12
Training loss: 0.21069256961345673
Validation loss: 1.5405250595461937

Epoch: 6| Step: 13
Training loss: 0.1584378331899643
Validation loss: 1.5111555655797322

Epoch: 359| Step: 0
Training loss: 0.09679444134235382
Validation loss: 1.5208353355366697

Epoch: 6| Step: 1
Training loss: 0.12321309745311737
Validation loss: 1.536012573908734

Epoch: 6| Step: 2
Training loss: 0.14807815849781036
Validation loss: 1.5162529509554628

Epoch: 6| Step: 3
Training loss: 0.1576424539089203
Validation loss: 1.5369088854841007

Epoch: 6| Step: 4
Training loss: 0.1350257396697998
Validation loss: 1.5399354786001227

Epoch: 6| Step: 5
Training loss: 0.1676643341779709
Validation loss: 1.517651113130713

Epoch: 6| Step: 6
Training loss: 0.08728745579719543
Validation loss: 1.5183526879997664

Epoch: 6| Step: 7
Training loss: 0.10793498158454895
Validation loss: 1.5126111251051708

Epoch: 6| Step: 8
Training loss: 0.10600101947784424
Validation loss: 1.5339471563216178

Epoch: 6| Step: 9
Training loss: 0.1581718623638153
Validation loss: 1.4926041787670505

Epoch: 6| Step: 10
Training loss: 0.133966863155365
Validation loss: 1.4828552071766188

Epoch: 6| Step: 11
Training loss: 0.2278318852186203
Validation loss: 1.4901374399021108

Epoch: 6| Step: 12
Training loss: 0.36582282185554504
Validation loss: 1.4739163562815676

Epoch: 6| Step: 13
Training loss: 0.23189514875411987
Validation loss: 1.4769195805313766

Epoch: 360| Step: 0
Training loss: 0.18305417895317078
Validation loss: 1.457246946391239

Epoch: 6| Step: 1
Training loss: 0.2806735634803772
Validation loss: 1.476299180779406

Epoch: 6| Step: 2
Training loss: 0.11664748191833496
Validation loss: 1.5127432615526262

Epoch: 6| Step: 3
Training loss: 0.1082860678434372
Validation loss: 1.5012516065310406

Epoch: 6| Step: 4
Training loss: 0.13223440945148468
Validation loss: 1.5490893022988432

Epoch: 6| Step: 5
Training loss: 0.09308458119630814
Validation loss: 1.5414596937036003

Epoch: 6| Step: 6
Training loss: 0.16522163152694702
Validation loss: 1.570521895603467

Epoch: 6| Step: 7
Training loss: 0.10194320976734161
Validation loss: 1.5439203990403043

Epoch: 6| Step: 8
Training loss: 0.1672094464302063
Validation loss: 1.5246070604170523

Epoch: 6| Step: 9
Training loss: 0.1597546935081482
Validation loss: 1.5338212072208364

Epoch: 6| Step: 10
Training loss: 0.11110448092222214
Validation loss: 1.533272761170582

Epoch: 6| Step: 11
Training loss: 0.24205397069454193
Validation loss: 1.5309312599961475

Epoch: 6| Step: 12
Training loss: 0.0866580605506897
Validation loss: 1.5279860406793573

Epoch: 6| Step: 13
Training loss: 0.08158901333808899
Validation loss: 1.5319319950636996

Epoch: 361| Step: 0
Training loss: 0.10303573310375214
Validation loss: 1.5195745627085369

Epoch: 6| Step: 1
Training loss: 0.1409606784582138
Validation loss: 1.5216527190259708

Epoch: 6| Step: 2
Training loss: 0.12171798944473267
Validation loss: 1.5129559834798176

Epoch: 6| Step: 3
Training loss: 0.3053555488586426
Validation loss: 1.484762901900917

Epoch: 6| Step: 4
Training loss: 0.13286803662776947
Validation loss: 1.5044800152060807

Epoch: 6| Step: 5
Training loss: 0.12991851568222046
Validation loss: 1.4966897733749882

Epoch: 6| Step: 6
Training loss: 0.17828842997550964
Validation loss: 1.474979292961859

Epoch: 6| Step: 7
Training loss: 0.14929500222206116
Validation loss: 1.513613764957715

Epoch: 6| Step: 8
Training loss: 0.10691311210393906
Validation loss: 1.522049755178472

Epoch: 6| Step: 9
Training loss: 0.09825429320335388
Validation loss: 1.5348813790147022

Epoch: 6| Step: 10
Training loss: 0.10343653708696365
Validation loss: 1.5256680570622927

Epoch: 6| Step: 11
Training loss: 0.14494943618774414
Validation loss: 1.53258498766089

Epoch: 6| Step: 12
Training loss: 0.21734634041786194
Validation loss: 1.5220603917234687

Epoch: 6| Step: 13
Training loss: 0.17042869329452515
Validation loss: 1.4904623262343868

Epoch: 362| Step: 0
Training loss: 0.16097745299339294
Validation loss: 1.517738583267376

Epoch: 6| Step: 1
Training loss: 0.14857469499111176
Validation loss: 1.507639363247861

Epoch: 6| Step: 2
Training loss: 0.12703664600849152
Validation loss: 1.5048598448435466

Epoch: 6| Step: 3
Training loss: 0.21843655407428741
Validation loss: 1.52078120041919

Epoch: 6| Step: 4
Training loss: 0.12840457260608673
Validation loss: 1.554422217030679

Epoch: 6| Step: 5
Training loss: 0.25204089283943176
Validation loss: 1.5277395671413792

Epoch: 6| Step: 6
Training loss: 0.18850836157798767
Validation loss: 1.5815341331625496

Epoch: 6| Step: 7
Training loss: 0.34710824489593506
Validation loss: 1.5624070385450959

Epoch: 6| Step: 8
Training loss: 0.10773712396621704
Validation loss: 1.5366532238580848

Epoch: 6| Step: 9
Training loss: 0.1670033484697342
Validation loss: 1.5142241344656995

Epoch: 6| Step: 10
Training loss: 0.30748897790908813
Validation loss: 1.5036568026388846

Epoch: 6| Step: 11
Training loss: 0.11081712692975998
Validation loss: 1.4850740586557696

Epoch: 6| Step: 12
Training loss: 0.1433759331703186
Validation loss: 1.4967016045765211

Epoch: 6| Step: 13
Training loss: 0.09856070578098297
Validation loss: 1.506331225877167

Epoch: 363| Step: 0
Training loss: 0.34814000129699707
Validation loss: 1.4730313093431535

Epoch: 6| Step: 1
Training loss: 0.14419269561767578
Validation loss: 1.4543778678422332

Epoch: 6| Step: 2
Training loss: 0.24331994354724884
Validation loss: 1.4656765255876767

Epoch: 6| Step: 3
Training loss: 0.13074634969234467
Validation loss: 1.45723000777665

Epoch: 6| Step: 4
Training loss: 0.167441725730896
Validation loss: 1.432893596669679

Epoch: 6| Step: 5
Training loss: 0.24418842792510986
Validation loss: 1.4271602066614295

Epoch: 6| Step: 6
Training loss: 0.1785491704940796
Validation loss: 1.4512508184679094

Epoch: 6| Step: 7
Training loss: 0.1421719789505005
Validation loss: 1.4204495709429505

Epoch: 6| Step: 8
Training loss: 0.1504676640033722
Validation loss: 1.4496055687627485

Epoch: 6| Step: 9
Training loss: 0.13896507024765015
Validation loss: 1.462761079111407

Epoch: 6| Step: 10
Training loss: 0.16649554669857025
Validation loss: 1.5079756552173245

Epoch: 6| Step: 11
Training loss: 0.18007023632526398
Validation loss: 1.5731827328282018

Epoch: 6| Step: 12
Training loss: 0.17060643434524536
Validation loss: 1.5780092580344087

Epoch: 6| Step: 13
Training loss: 0.25448283553123474
Validation loss: 1.5940749273505261

Epoch: 364| Step: 0
Training loss: 0.10392346978187561
Validation loss: 1.5999235286507556

Epoch: 6| Step: 1
Training loss: 0.30668050050735474
Validation loss: 1.6120519279151835

Epoch: 6| Step: 2
Training loss: 0.15811769664287567
Validation loss: 1.609612431577457

Epoch: 6| Step: 3
Training loss: 0.23621195554733276
Validation loss: 1.568578290682967

Epoch: 6| Step: 4
Training loss: 0.21765382587909698
Validation loss: 1.5953211566453338

Epoch: 6| Step: 5
Training loss: 0.11637389659881592
Validation loss: 1.5549684160499162

Epoch: 6| Step: 6
Training loss: 0.31237083673477173
Validation loss: 1.5289114880305466

Epoch: 6| Step: 7
Training loss: 0.0936116948723793
Validation loss: 1.5485286123009139

Epoch: 6| Step: 8
Training loss: 0.15083181858062744
Validation loss: 1.538805216871282

Epoch: 6| Step: 9
Training loss: 0.20721435546875
Validation loss: 1.5214641715890618

Epoch: 6| Step: 10
Training loss: 0.1914832592010498
Validation loss: 1.5043471051800636

Epoch: 6| Step: 11
Training loss: 0.12849342823028564
Validation loss: 1.491359035174052

Epoch: 6| Step: 12
Training loss: 0.20194485783576965
Validation loss: 1.4496966049235354

Epoch: 6| Step: 13
Training loss: 0.2348732352256775
Validation loss: 1.412948332807069

Epoch: 365| Step: 0
Training loss: 0.19497725367546082
Validation loss: 1.378982888754978

Epoch: 6| Step: 1
Training loss: 0.18601441383361816
Validation loss: 1.3609464937640774

Epoch: 6| Step: 2
Training loss: 0.24016128480434418
Validation loss: 1.335523360518999

Epoch: 6| Step: 3
Training loss: 0.17432963848114014
Validation loss: 1.3172440195596347

Epoch: 6| Step: 4
Training loss: 0.21917466819286346
Validation loss: 1.3269957252728042

Epoch: 6| Step: 5
Training loss: 0.1953488290309906
Validation loss: 1.3532426664906163

Epoch: 6| Step: 6
Training loss: 0.15432298183441162
Validation loss: 1.3598773351279638

Epoch: 6| Step: 7
Training loss: 0.16090691089630127
Validation loss: 1.3865757975527035

Epoch: 6| Step: 8
Training loss: 0.26037973165512085
Validation loss: 1.4565585569668842

Epoch: 6| Step: 9
Training loss: 0.15102793276309967
Validation loss: 1.470140137339151

Epoch: 6| Step: 10
Training loss: 0.19812114536762238
Validation loss: 1.5463785586818573

Epoch: 6| Step: 11
Training loss: 0.20950829982757568
Validation loss: 1.5871316168897895

Epoch: 6| Step: 12
Training loss: 0.26782673597335815
Validation loss: 1.595233735217843

Epoch: 6| Step: 13
Training loss: 0.29401683807373047
Validation loss: 1.5664680978303314

Epoch: 366| Step: 0
Training loss: 0.34283947944641113
Validation loss: 1.5365431975292903

Epoch: 6| Step: 1
Training loss: 0.13052290678024292
Validation loss: 1.5392460297512751

Epoch: 6| Step: 2
Training loss: 0.16201063990592957
Validation loss: 1.5001066910323275

Epoch: 6| Step: 3
Training loss: 0.1168433278799057
Validation loss: 1.4750872735054261

Epoch: 6| Step: 4
Training loss: 0.12829115986824036
Validation loss: 1.4469538042622228

Epoch: 6| Step: 5
Training loss: 0.15851111710071564
Validation loss: 1.4988000687732492

Epoch: 6| Step: 6
Training loss: 0.19508135318756104
Validation loss: 1.5005611347895798

Epoch: 6| Step: 7
Training loss: 0.17296850681304932
Validation loss: 1.5300668824103572

Epoch: 6| Step: 8
Training loss: 0.262532502412796
Validation loss: 1.5504371927630516

Epoch: 6| Step: 9
Training loss: 0.1845884472131729
Validation loss: 1.5427407628746443

Epoch: 6| Step: 10
Training loss: 0.11124256998300552
Validation loss: 1.5716149281429987

Epoch: 6| Step: 11
Training loss: 0.15367618203163147
Validation loss: 1.5895609035286853

Epoch: 6| Step: 12
Training loss: 0.10461211204528809
Validation loss: 1.5977083431777133

Epoch: 6| Step: 13
Training loss: 0.14698611199855804
Validation loss: 1.5923152046818887

Epoch: 367| Step: 0
Training loss: 0.3799715042114258
Validation loss: 1.5934797333132835

Epoch: 6| Step: 1
Training loss: 0.14403416216373444
Validation loss: 1.5864214320336618

Epoch: 6| Step: 2
Training loss: 0.21856126189231873
Validation loss: 1.5388899503215667

Epoch: 6| Step: 3
Training loss: 0.1714792549610138
Validation loss: 1.5276631405276637

Epoch: 6| Step: 4
Training loss: 0.12254901230335236
Validation loss: 1.4949990728850007

Epoch: 6| Step: 5
Training loss: 0.18669506907463074
Validation loss: 1.4970902499332224

Epoch: 6| Step: 6
Training loss: 0.1475888043642044
Validation loss: 1.4930843973672518

Epoch: 6| Step: 7
Training loss: 0.12898153066635132
Validation loss: 1.481027255776108

Epoch: 6| Step: 8
Training loss: 0.13159692287445068
Validation loss: 1.5127681621941187

Epoch: 6| Step: 9
Training loss: 0.1184932291507721
Validation loss: 1.5111928703964397

Epoch: 6| Step: 10
Training loss: 0.16815009713172913
Validation loss: 1.5281151866400113

Epoch: 6| Step: 11
Training loss: 0.14984385669231415
Validation loss: 1.5278434535508514

Epoch: 6| Step: 12
Training loss: 0.18174269795417786
Validation loss: 1.5468964615175802

Epoch: 6| Step: 13
Training loss: 0.2802616059780121
Validation loss: 1.5491987402721117

Epoch: 368| Step: 0
Training loss: 0.12725946307182312
Validation loss: 1.5861556299271122

Epoch: 6| Step: 1
Training loss: 0.10707652568817139
Validation loss: 1.5313284871398762

Epoch: 6| Step: 2
Training loss: 0.16857993602752686
Validation loss: 1.5355531900159773

Epoch: 6| Step: 3
Training loss: 0.1635461002588272
Validation loss: 1.5333993204178349

Epoch: 6| Step: 4
Training loss: 0.13497456908226013
Validation loss: 1.5158919301084293

Epoch: 6| Step: 5
Training loss: 0.11391275376081467
Validation loss: 1.516592143684305

Epoch: 6| Step: 6
Training loss: 0.132007896900177
Validation loss: 1.5352261540710286

Epoch: 6| Step: 7
Training loss: 0.16557130217552185
Validation loss: 1.5348130105644144

Epoch: 6| Step: 8
Training loss: 0.17405423521995544
Validation loss: 1.534494633315712

Epoch: 6| Step: 9
Training loss: 0.1505490243434906
Validation loss: 1.5627868278052217

Epoch: 6| Step: 10
Training loss: 0.30019399523735046
Validation loss: 1.5381224886063607

Epoch: 6| Step: 11
Training loss: 0.1221233680844307
Validation loss: 1.5194304040683213

Epoch: 6| Step: 12
Training loss: 0.17121905088424683
Validation loss: 1.579261064529419

Epoch: 6| Step: 13
Training loss: 0.08253493905067444
Validation loss: 1.5343197840516285

Epoch: 369| Step: 0
Training loss: 0.1704399287700653
Validation loss: 1.5300706368620678

Epoch: 6| Step: 1
Training loss: 0.11959196627140045
Validation loss: 1.522146583885275

Epoch: 6| Step: 2
Training loss: 0.1696423590183258
Validation loss: 1.5317579059190647

Epoch: 6| Step: 3
Training loss: 0.1582145392894745
Validation loss: 1.5135072918348416

Epoch: 6| Step: 4
Training loss: 0.07577954232692719
Validation loss: 1.4848774710009176

Epoch: 6| Step: 5
Training loss: 0.12166799604892731
Validation loss: 1.514444407596383

Epoch: 6| Step: 6
Training loss: 0.07793215662240982
Validation loss: 1.4834799843449746

Epoch: 6| Step: 7
Training loss: 0.25880715250968933
Validation loss: 1.5130089457317064

Epoch: 6| Step: 8
Training loss: 0.11041054129600525
Validation loss: 1.4588005260754657

Epoch: 6| Step: 9
Training loss: 0.2208074927330017
Validation loss: 1.464969147918045

Epoch: 6| Step: 10
Training loss: 0.09467443823814392
Validation loss: 1.459430713807383

Epoch: 6| Step: 11
Training loss: 0.3012831509113312
Validation loss: 1.4513645915574924

Epoch: 6| Step: 12
Training loss: 0.1501462757587433
Validation loss: 1.4420331754992086

Epoch: 6| Step: 13
Training loss: 0.3028049170970917
Validation loss: 1.434478126546388

Epoch: 370| Step: 0
Training loss: 0.18534882366657257
Validation loss: 1.4540194234540385

Epoch: 6| Step: 1
Training loss: 0.1277686059474945
Validation loss: 1.4679818371290803

Epoch: 6| Step: 2
Training loss: 0.11202686280012131
Validation loss: 1.4568030206106042

Epoch: 6| Step: 3
Training loss: 0.1448109894990921
Validation loss: 1.5044741617735995

Epoch: 6| Step: 4
Training loss: 0.2507013976573944
Validation loss: 1.5243791931418962

Epoch: 6| Step: 5
Training loss: 0.2024868130683899
Validation loss: 1.568486390575286

Epoch: 6| Step: 6
Training loss: 0.2862319350242615
Validation loss: 1.533449206300961

Epoch: 6| Step: 7
Training loss: 0.2182294726371765
Validation loss: 1.530243246786056

Epoch: 6| Step: 8
Training loss: 0.1339508295059204
Validation loss: 1.5231309654892131

Epoch: 6| Step: 9
Training loss: 0.18727874755859375
Validation loss: 1.5052957470699022

Epoch: 6| Step: 10
Training loss: 0.08212057501077652
Validation loss: 1.4899669565180296

Epoch: 6| Step: 11
Training loss: 0.08574599772691727
Validation loss: 1.4723895057555167

Epoch: 6| Step: 12
Training loss: 0.16649074852466583
Validation loss: 1.4765507354531238

Epoch: 6| Step: 13
Training loss: 0.16434885561466217
Validation loss: 1.4253051345066359

Epoch: 371| Step: 0
Training loss: 0.16549542546272278
Validation loss: 1.4378333553191154

Epoch: 6| Step: 1
Training loss: 0.15585368871688843
Validation loss: 1.432097227342667

Epoch: 6| Step: 2
Training loss: 0.13087064027786255
Validation loss: 1.4490722405013217

Epoch: 6| Step: 3
Training loss: 0.19919919967651367
Validation loss: 1.4232722943828953

Epoch: 6| Step: 4
Training loss: 0.13227525353431702
Validation loss: 1.4754750241515457

Epoch: 6| Step: 5
Training loss: 0.18846121430397034
Validation loss: 1.4888287616032425

Epoch: 6| Step: 6
Training loss: 0.1393459141254425
Validation loss: 1.4171050222971107

Epoch: 6| Step: 7
Training loss: 0.19505442678928375
Validation loss: 1.4579988359123148

Epoch: 6| Step: 8
Training loss: 0.14610549807548523
Validation loss: 1.4671744044109056

Epoch: 6| Step: 9
Training loss: 0.16602838039398193
Validation loss: 1.4277910750399354

Epoch: 6| Step: 10
Training loss: 0.3056674003601074
Validation loss: 1.4270470911456692

Epoch: 6| Step: 11
Training loss: 0.11861703544855118
Validation loss: 1.4212485833834576

Epoch: 6| Step: 12
Training loss: 0.13734179735183716
Validation loss: 1.4443000285856185

Epoch: 6| Step: 13
Training loss: 0.19957402348518372
Validation loss: 1.4391460764792658

Epoch: 372| Step: 0
Training loss: 0.14834080636501312
Validation loss: 1.473988243969538

Epoch: 6| Step: 1
Training loss: 0.1575709581375122
Validation loss: 1.4838346909451228

Epoch: 6| Step: 2
Training loss: 0.20606106519699097
Validation loss: 1.4726019264549337

Epoch: 6| Step: 3
Training loss: 0.19381093978881836
Validation loss: 1.5369255158209032

Epoch: 6| Step: 4
Training loss: 0.10103734582662582
Validation loss: 1.5088819111547163

Epoch: 6| Step: 5
Training loss: 0.14036330580711365
Validation loss: 1.5098689743267593

Epoch: 6| Step: 6
Training loss: 0.1672835350036621
Validation loss: 1.5393558644479322

Epoch: 6| Step: 7
Training loss: 0.2163926362991333
Validation loss: 1.508565971928258

Epoch: 6| Step: 8
Training loss: 0.10941297560930252
Validation loss: 1.5279568741398473

Epoch: 6| Step: 9
Training loss: 0.1350790113210678
Validation loss: 1.5229490239133117

Epoch: 6| Step: 10
Training loss: 0.12032309174537659
Validation loss: 1.4939680509669806

Epoch: 6| Step: 11
Training loss: 0.3691103458404541
Validation loss: 1.5088965021153933

Epoch: 6| Step: 12
Training loss: 0.15626397728919983
Validation loss: 1.4804088992457236

Epoch: 6| Step: 13
Training loss: 0.09547089040279388
Validation loss: 1.4746789554113984

Epoch: 373| Step: 0
Training loss: 0.192818284034729
Validation loss: 1.4664761110018658

Epoch: 6| Step: 1
Training loss: 0.13653472065925598
Validation loss: 1.457645829005908

Epoch: 6| Step: 2
Training loss: 0.17725054919719696
Validation loss: 1.4757056108085058

Epoch: 6| Step: 3
Training loss: 0.08308057487010956
Validation loss: 1.493424456606629

Epoch: 6| Step: 4
Training loss: 0.11946411430835724
Validation loss: 1.5105207773946947

Epoch: 6| Step: 5
Training loss: 0.15897312760353088
Validation loss: 1.547700039802059

Epoch: 6| Step: 6
Training loss: 0.15218552947044373
Validation loss: 1.5376261600884058

Epoch: 6| Step: 7
Training loss: 0.1312686949968338
Validation loss: 1.5293148961118472

Epoch: 6| Step: 8
Training loss: 0.31258249282836914
Validation loss: 1.5609667249905166

Epoch: 6| Step: 9
Training loss: 0.16669568419456482
Validation loss: 1.5283871966023599

Epoch: 6| Step: 10
Training loss: 0.1373538225889206
Validation loss: 1.5440658189917122

Epoch: 6| Step: 11
Training loss: 0.1294093132019043
Validation loss: 1.4982553335928148

Epoch: 6| Step: 12
Training loss: 0.09824733436107635
Validation loss: 1.4822833999510734

Epoch: 6| Step: 13
Training loss: 0.08466905355453491
Validation loss: 1.4673195731255315

Epoch: 374| Step: 0
Training loss: 0.11026261746883392
Validation loss: 1.4990103039690243

Epoch: 6| Step: 1
Training loss: 0.1301642507314682
Validation loss: 1.4720149245313419

Epoch: 6| Step: 2
Training loss: 0.17605359852313995
Validation loss: 1.4807951860530402

Epoch: 6| Step: 3
Training loss: 0.13897879421710968
Validation loss: 1.4587007197000648

Epoch: 6| Step: 4
Training loss: 0.14681601524353027
Validation loss: 1.5006037777470005

Epoch: 6| Step: 5
Training loss: 0.12445495277643204
Validation loss: 1.4864352403148529

Epoch: 6| Step: 6
Training loss: 0.14817363023757935
Validation loss: 1.509883007695598

Epoch: 6| Step: 7
Training loss: 0.10884477943181992
Validation loss: 1.5250083438811763

Epoch: 6| Step: 8
Training loss: 0.2614735960960388
Validation loss: 1.5129417898834392

Epoch: 6| Step: 9
Training loss: 0.12785838544368744
Validation loss: 1.4980347541070753

Epoch: 6| Step: 10
Training loss: 0.07988034188747406
Validation loss: 1.5141133877538866

Epoch: 6| Step: 11
Training loss: 0.20048941671848297
Validation loss: 1.5447045321105628

Epoch: 6| Step: 12
Training loss: 0.17516487836837769
Validation loss: 1.5884155047837125

Epoch: 6| Step: 13
Training loss: 0.3043152987957001
Validation loss: 1.5272711989700154

Epoch: 375| Step: 0
Training loss: 0.1980789452791214
Validation loss: 1.5639928451148413

Epoch: 6| Step: 1
Training loss: 0.3063777983188629
Validation loss: 1.5736309315568657

Epoch: 6| Step: 2
Training loss: 0.16933110356330872
Validation loss: 1.5614037065095798

Epoch: 6| Step: 3
Training loss: 0.16335447132587433
Validation loss: 1.5361950359036844

Epoch: 6| Step: 4
Training loss: 0.15854385495185852
Validation loss: 1.5089796018856827

Epoch: 6| Step: 5
Training loss: 0.10964861512184143
Validation loss: 1.4980537032568326

Epoch: 6| Step: 6
Training loss: 0.11219625174999237
Validation loss: 1.4760120940464798

Epoch: 6| Step: 7
Training loss: 0.07833702117204666
Validation loss: 1.4501090299698614

Epoch: 6| Step: 8
Training loss: 0.14537805318832397
Validation loss: 1.5045910086683048

Epoch: 6| Step: 9
Training loss: 0.14490774273872375
Validation loss: 1.473489620352304

Epoch: 6| Step: 10
Training loss: 0.1470644772052765
Validation loss: 1.504252100503573

Epoch: 6| Step: 11
Training loss: 0.15228380262851715
Validation loss: 1.5229199676103489

Epoch: 6| Step: 12
Training loss: 0.25420942902565
Validation loss: 1.4935368696848552

Epoch: 6| Step: 13
Training loss: 0.12132927775382996
Validation loss: 1.5087796859843756

Epoch: 376| Step: 0
Training loss: 0.17729349434375763
Validation loss: 1.5026961013834963

Epoch: 6| Step: 1
Training loss: 0.11459966003894806
Validation loss: 1.4681413071129912

Epoch: 6| Step: 2
Training loss: 0.13127291202545166
Validation loss: 1.4754426581885225

Epoch: 6| Step: 3
Training loss: 0.11377682536840439
Validation loss: 1.4746831245319818

Epoch: 6| Step: 4
Training loss: 0.13229811191558838
Validation loss: 1.4716063186686525

Epoch: 6| Step: 5
Training loss: 0.16854628920555115
Validation loss: 1.4893294995830906

Epoch: 6| Step: 6
Training loss: 0.11305712163448334
Validation loss: 1.4757937974827264

Epoch: 6| Step: 7
Training loss: 0.14909431338310242
Validation loss: 1.4559965210576211

Epoch: 6| Step: 8
Training loss: 0.17353692650794983
Validation loss: 1.4591862129908737

Epoch: 6| Step: 9
Training loss: 0.1379351168870926
Validation loss: 1.4625069120878815

Epoch: 6| Step: 10
Training loss: 0.09783236682415009
Validation loss: 1.4426832365733322

Epoch: 6| Step: 11
Training loss: 0.12711675465106964
Validation loss: 1.46746067718793

Epoch: 6| Step: 12
Training loss: 0.25520914793014526
Validation loss: 1.460324683497029

Epoch: 6| Step: 13
Training loss: 0.09126513451337814
Validation loss: 1.4754043727792718

Epoch: 377| Step: 0
Training loss: 0.16310101747512817
Validation loss: 1.5092432140022196

Epoch: 6| Step: 1
Training loss: 0.18499252200126648
Validation loss: 1.493887323205189

Epoch: 6| Step: 2
Training loss: 0.10394512116909027
Validation loss: 1.4765569420271023

Epoch: 6| Step: 3
Training loss: 0.18686041235923767
Validation loss: 1.4632724049270793

Epoch: 6| Step: 4
Training loss: 0.11720622330904007
Validation loss: 1.4539101303264659

Epoch: 6| Step: 5
Training loss: 0.20626693964004517
Validation loss: 1.4468493294972244

Epoch: 6| Step: 6
Training loss: 0.10302858054637909
Validation loss: 1.4212403117969472

Epoch: 6| Step: 7
Training loss: 0.14707332849502563
Validation loss: 1.4502687697769494

Epoch: 6| Step: 8
Training loss: 0.10647124797105789
Validation loss: 1.4640517952621623

Epoch: 6| Step: 9
Training loss: 0.15174299478530884
Validation loss: 1.4536198057154173

Epoch: 6| Step: 10
Training loss: 0.14617633819580078
Validation loss: 1.461537488045231

Epoch: 6| Step: 11
Training loss: 0.11751874536275864
Validation loss: 1.4628118571414743

Epoch: 6| Step: 12
Training loss: 0.3486993908882141
Validation loss: 1.5010937580498316

Epoch: 6| Step: 13
Training loss: 0.1494738757610321
Validation loss: 1.5006108822361115

Epoch: 378| Step: 0
Training loss: 0.11133447289466858
Validation loss: 1.4990237079640871

Epoch: 6| Step: 1
Training loss: 0.1482420265674591
Validation loss: 1.5268777147416146

Epoch: 6| Step: 2
Training loss: 0.10997432470321655
Validation loss: 1.5095176812141173

Epoch: 6| Step: 3
Training loss: 0.20411141216754913
Validation loss: 1.4913686257536694

Epoch: 6| Step: 4
Training loss: 0.16983816027641296
Validation loss: 1.4730988305102113

Epoch: 6| Step: 5
Training loss: 0.09475816041231155
Validation loss: 1.4506120117761756

Epoch: 6| Step: 6
Training loss: 0.12975899875164032
Validation loss: 1.4584837318748556

Epoch: 6| Step: 7
Training loss: 0.18041668832302094
Validation loss: 1.4608365540863366

Epoch: 6| Step: 8
Training loss: 0.31967344880104065
Validation loss: 1.4474511441364084

Epoch: 6| Step: 9
Training loss: 0.14077404141426086
Validation loss: 1.4375389801558627

Epoch: 6| Step: 10
Training loss: 0.13967062532901764
Validation loss: 1.4310521669285272

Epoch: 6| Step: 11
Training loss: 0.15577158331871033
Validation loss: 1.4605546010437833

Epoch: 6| Step: 12
Training loss: 0.10545475780963898
Validation loss: 1.4577846392508476

Epoch: 6| Step: 13
Training loss: 0.1174471378326416
Validation loss: 1.5108800280478694

Epoch: 379| Step: 0
Training loss: 0.12965497374534607
Validation loss: 1.5272105252870949

Epoch: 6| Step: 1
Training loss: 0.14380569756031036
Validation loss: 1.5327819201254076

Epoch: 6| Step: 2
Training loss: 0.11896776407957077
Validation loss: 1.5297972579156198

Epoch: 6| Step: 3
Training loss: 0.11909642815589905
Validation loss: 1.5655831495920818

Epoch: 6| Step: 4
Training loss: 0.10054569691419601
Validation loss: 1.5649660748820151

Epoch: 6| Step: 5
Training loss: 0.1861410290002823
Validation loss: 1.551618592713469

Epoch: 6| Step: 6
Training loss: 0.2556299567222595
Validation loss: 1.5299723225255166

Epoch: 6| Step: 7
Training loss: 0.2708110809326172
Validation loss: 1.5036656523263583

Epoch: 6| Step: 8
Training loss: 0.12946932017803192
Validation loss: 1.5173061214467531

Epoch: 6| Step: 9
Training loss: 0.11730928719043732
Validation loss: 1.4759416016199256

Epoch: 6| Step: 10
Training loss: 0.15142688155174255
Validation loss: 1.494791562839221

Epoch: 6| Step: 11
Training loss: 0.1059618592262268
Validation loss: 1.5121541535982521

Epoch: 6| Step: 12
Training loss: 0.1023455560207367
Validation loss: 1.4846502170767835

Epoch: 6| Step: 13
Training loss: 0.12302222847938538
Validation loss: 1.4875323516066357

Epoch: 380| Step: 0
Training loss: 0.11342199146747589
Validation loss: 1.4811502233628304

Epoch: 6| Step: 1
Training loss: 0.20128804445266724
Validation loss: 1.454651972298981

Epoch: 6| Step: 2
Training loss: 0.1371643841266632
Validation loss: 1.4810658283131097

Epoch: 6| Step: 3
Training loss: 0.07521238923072815
Validation loss: 1.4359325119244155

Epoch: 6| Step: 4
Training loss: 0.07115988433361053
Validation loss: 1.443206185935646

Epoch: 6| Step: 5
Training loss: 0.19215968251228333
Validation loss: 1.4875369956416469

Epoch: 6| Step: 6
Training loss: 0.16866886615753174
Validation loss: 1.4831463265162643

Epoch: 6| Step: 7
Training loss: 0.08541366457939148
Validation loss: 1.5029687964788048

Epoch: 6| Step: 8
Training loss: 0.09581707417964935
Validation loss: 1.497020741944672

Epoch: 6| Step: 9
Training loss: 0.138506218791008
Validation loss: 1.490007899781709

Epoch: 6| Step: 10
Training loss: 0.09705491364002228
Validation loss: 1.4782686938521683

Epoch: 6| Step: 11
Training loss: 0.28009968996047974
Validation loss: 1.4820554974258586

Epoch: 6| Step: 12
Training loss: 0.057797566056251526
Validation loss: 1.4657998456749866

Epoch: 6| Step: 13
Training loss: 0.12004033476114273
Validation loss: 1.4811046155550147

Epoch: 381| Step: 0
Training loss: 0.17322038114070892
Validation loss: 1.4693528811136882

Epoch: 6| Step: 1
Training loss: 0.1398332566022873
Validation loss: 1.4900136557958459

Epoch: 6| Step: 2
Training loss: 0.14125868678092957
Validation loss: 1.490679039750048

Epoch: 6| Step: 3
Training loss: 0.10602574795484543
Validation loss: 1.5159978840940742

Epoch: 6| Step: 4
Training loss: 0.1442316472530365
Validation loss: 1.5208128216446086

Epoch: 6| Step: 5
Training loss: 0.15244682133197784
Validation loss: 1.4988855918248494

Epoch: 6| Step: 6
Training loss: 0.13247275352478027
Validation loss: 1.4894526543155793

Epoch: 6| Step: 7
Training loss: 0.09768251329660416
Validation loss: 1.5182817341178976

Epoch: 6| Step: 8
Training loss: 0.11301857978105545
Validation loss: 1.5146541723641016

Epoch: 6| Step: 9
Training loss: 0.08418262004852295
Validation loss: 1.523156742895803

Epoch: 6| Step: 10
Training loss: 0.22858819365501404
Validation loss: 1.5309632426948958

Epoch: 6| Step: 11
Training loss: 0.12956596910953522
Validation loss: 1.5400575873672322

Epoch: 6| Step: 12
Training loss: 0.15153533220291138
Validation loss: 1.5275535955223987

Epoch: 6| Step: 13
Training loss: 0.1063191369175911
Validation loss: 1.5245572008112425

Epoch: 382| Step: 0
Training loss: 0.07200811803340912
Validation loss: 1.5198532509547409

Epoch: 6| Step: 1
Training loss: 0.17502900958061218
Validation loss: 1.5198848760256203

Epoch: 6| Step: 2
Training loss: 0.08587486296892166
Validation loss: 1.5382447435009865

Epoch: 6| Step: 3
Training loss: 0.11600106209516525
Validation loss: 1.5323905701278357

Epoch: 6| Step: 4
Training loss: 0.06572870910167694
Validation loss: 1.5399652450315413

Epoch: 6| Step: 5
Training loss: 0.1023121327161789
Validation loss: 1.500653141288347

Epoch: 6| Step: 6
Training loss: 0.05428066849708557
Validation loss: 1.5107647924013035

Epoch: 6| Step: 7
Training loss: 0.2514793276786804
Validation loss: 1.543909081848719

Epoch: 6| Step: 8
Training loss: 0.16032519936561584
Validation loss: 1.5474311485085437

Epoch: 6| Step: 9
Training loss: 0.1236957460641861
Validation loss: 1.5172447478899391

Epoch: 6| Step: 10
Training loss: 0.12219788134098053
Validation loss: 1.5205560973895493

Epoch: 6| Step: 11
Training loss: 0.11091984808444977
Validation loss: 1.5024887554107174

Epoch: 6| Step: 12
Training loss: 0.1679672747850418
Validation loss: 1.4938211306448905

Epoch: 6| Step: 13
Training loss: 0.17560052871704102
Validation loss: 1.4433369790354083

Epoch: 383| Step: 0
Training loss: 0.09541207551956177
Validation loss: 1.4235269138889928

Epoch: 6| Step: 1
Training loss: 0.13640181720256805
Validation loss: 1.4134698721670336

Epoch: 6| Step: 2
Training loss: 0.07286684215068817
Validation loss: 1.4230676620237288

Epoch: 6| Step: 3
Training loss: 0.1274847537279129
Validation loss: 1.4022174304531467

Epoch: 6| Step: 4
Training loss: 0.13287317752838135
Validation loss: 1.393987585139531

Epoch: 6| Step: 5
Training loss: 0.20804820954799652
Validation loss: 1.4349590283568188

Epoch: 6| Step: 6
Training loss: 0.20536930859088898
Validation loss: 1.4503294703780965

Epoch: 6| Step: 7
Training loss: 0.3531821370124817
Validation loss: 1.4604878579416583

Epoch: 6| Step: 8
Training loss: 0.15029212832450867
Validation loss: 1.4537412120449928

Epoch: 6| Step: 9
Training loss: 0.10552927851676941
Validation loss: 1.4564304479988672

Epoch: 6| Step: 10
Training loss: 0.09133731573820114
Validation loss: 1.420079227416746

Epoch: 6| Step: 11
Training loss: 0.07225895673036575
Validation loss: 1.453215515741738

Epoch: 6| Step: 12
Training loss: 0.11172565072774887
Validation loss: 1.4492482049490816

Epoch: 6| Step: 13
Training loss: 0.07649736851453781
Validation loss: 1.4334972943029096

Epoch: 384| Step: 0
Training loss: 0.14258868992328644
Validation loss: 1.432184539815431

Epoch: 6| Step: 1
Training loss: 0.13146772980690002
Validation loss: 1.4644683330289778

Epoch: 6| Step: 2
Training loss: 0.12855568528175354
Validation loss: 1.4749226339401738

Epoch: 6| Step: 3
Training loss: 0.1823757290840149
Validation loss: 1.4467769899675924

Epoch: 6| Step: 4
Training loss: 0.11007522791624069
Validation loss: 1.4710917998385686

Epoch: 6| Step: 5
Training loss: 0.14864204823970795
Validation loss: 1.4555976467747842

Epoch: 6| Step: 6
Training loss: 0.19942396879196167
Validation loss: 1.4834504050593222

Epoch: 6| Step: 7
Training loss: 0.09750451147556305
Validation loss: 1.4705217551159602

Epoch: 6| Step: 8
Training loss: 0.11340369284152985
Validation loss: 1.4391311522453063

Epoch: 6| Step: 9
Training loss: 0.09075687825679779
Validation loss: 1.4516301142272128

Epoch: 6| Step: 10
Training loss: 0.22822290658950806
Validation loss: 1.4430479977720527

Epoch: 6| Step: 11
Training loss: 0.08182929456233978
Validation loss: 1.4521282129390265

Epoch: 6| Step: 12
Training loss: 0.21030867099761963
Validation loss: 1.4593193518218173

Epoch: 6| Step: 13
Training loss: 0.20120644569396973
Validation loss: 1.4782099710997714

Epoch: 385| Step: 0
Training loss: 0.0867549329996109
Validation loss: 1.475050502566881

Epoch: 6| Step: 1
Training loss: 0.14557404816150665
Validation loss: 1.448269969673567

Epoch: 6| Step: 2
Training loss: 0.1094973087310791
Validation loss: 1.4850676777542278

Epoch: 6| Step: 3
Training loss: 0.07568616420030594
Validation loss: 1.4719543828759143

Epoch: 6| Step: 4
Training loss: 0.2773526906967163
Validation loss: 1.4867537893274778

Epoch: 6| Step: 5
Training loss: 0.07859798520803452
Validation loss: 1.5098062753677368

Epoch: 6| Step: 6
Training loss: 0.1049392819404602
Validation loss: 1.480132447775974

Epoch: 6| Step: 7
Training loss: 0.13506251573562622
Validation loss: 1.5014835519175376

Epoch: 6| Step: 8
Training loss: 0.11313699185848236
Validation loss: 1.4599637139228083

Epoch: 6| Step: 9
Training loss: 0.113161101937294
Validation loss: 1.4602206086599698

Epoch: 6| Step: 10
Training loss: 0.11321742087602615
Validation loss: 1.4482183751239572

Epoch: 6| Step: 11
Training loss: 0.16767993569374084
Validation loss: 1.435378336137341

Epoch: 6| Step: 12
Training loss: 0.0942663848400116
Validation loss: 1.4579021776876142

Epoch: 6| Step: 13
Training loss: 0.13572150468826294
Validation loss: 1.4195680310649257

Epoch: 386| Step: 0
Training loss: 0.10077577084302902
Validation loss: 1.4363246528051232

Epoch: 6| Step: 1
Training loss: 0.09108218550682068
Validation loss: 1.4340958056911346

Epoch: 6| Step: 2
Training loss: 0.0909079760313034
Validation loss: 1.4730608033877548

Epoch: 6| Step: 3
Training loss: 0.12379869818687439
Validation loss: 1.4814204208312496

Epoch: 6| Step: 4
Training loss: 0.1383330374956131
Validation loss: 1.4495106409954768

Epoch: 6| Step: 5
Training loss: 0.10126009583473206
Validation loss: 1.4447153409322102

Epoch: 6| Step: 6
Training loss: 0.09947708249092102
Validation loss: 1.4653369265217935

Epoch: 6| Step: 7
Training loss: 0.3085354268550873
Validation loss: 1.4687811572064635

Epoch: 6| Step: 8
Training loss: 0.13894104957580566
Validation loss: 1.467703543683534

Epoch: 6| Step: 9
Training loss: 0.10538793355226517
Validation loss: 1.4962862640298822

Epoch: 6| Step: 10
Training loss: 0.1849842369556427
Validation loss: 1.516448768236304

Epoch: 6| Step: 11
Training loss: 0.10702797770500183
Validation loss: 1.526658869558765

Epoch: 6| Step: 12
Training loss: 0.14453107118606567
Validation loss: 1.5114937315705002

Epoch: 6| Step: 13
Training loss: 0.11315366625785828
Validation loss: 1.515059422421199

Epoch: 387| Step: 0
Training loss: 0.12225276231765747
Validation loss: 1.5019145909176077

Epoch: 6| Step: 1
Training loss: 0.11415000259876251
Validation loss: 1.500502981165404

Epoch: 6| Step: 2
Training loss: 0.09406720101833344
Validation loss: 1.4949082546336676

Epoch: 6| Step: 3
Training loss: 0.12550681829452515
Validation loss: 1.5359872983347984

Epoch: 6| Step: 4
Training loss: 0.0831679105758667
Validation loss: 1.5243798250793128

Epoch: 6| Step: 5
Training loss: 0.1305939257144928
Validation loss: 1.5284967396848945

Epoch: 6| Step: 6
Training loss: 0.22002625465393066
Validation loss: 1.5224058704991494

Epoch: 6| Step: 7
Training loss: 0.2928374409675598
Validation loss: 1.5549063708192559

Epoch: 6| Step: 8
Training loss: 0.12328483164310455
Validation loss: 1.5336913806135937

Epoch: 6| Step: 9
Training loss: 0.15777438879013062
Validation loss: 1.5309272491803734

Epoch: 6| Step: 10
Training loss: 0.1343935877084732
Validation loss: 1.5168486436208088

Epoch: 6| Step: 11
Training loss: 0.10423067957162857
Validation loss: 1.5000981079634799

Epoch: 6| Step: 12
Training loss: 0.09721355885267258
Validation loss: 1.470268149529734

Epoch: 6| Step: 13
Training loss: 0.06980538368225098
Validation loss: 1.4656007546250538

Epoch: 388| Step: 0
Training loss: 0.06901612132787704
Validation loss: 1.4213894310817923

Epoch: 6| Step: 1
Training loss: 0.1684260219335556
Validation loss: 1.4195897989375617

Epoch: 6| Step: 2
Training loss: 0.14671000838279724
Validation loss: 1.4147664975094538

Epoch: 6| Step: 3
Training loss: 0.1854613721370697
Validation loss: 1.4321256094081427

Epoch: 6| Step: 4
Training loss: 0.13413195312023163
Validation loss: 1.3989355884572512

Epoch: 6| Step: 5
Training loss: 0.24896547198295593
Validation loss: 1.4531100924297045

Epoch: 6| Step: 6
Training loss: 0.09630060195922852
Validation loss: 1.483410790402402

Epoch: 6| Step: 7
Training loss: 0.1519002914428711
Validation loss: 1.482403701351535

Epoch: 6| Step: 8
Training loss: 0.12355373799800873
Validation loss: 1.4769914701420774

Epoch: 6| Step: 9
Training loss: 0.11323868483304977
Validation loss: 1.480742774983888

Epoch: 6| Step: 10
Training loss: 0.09321602433919907
Validation loss: 1.503962832112466

Epoch: 6| Step: 11
Training loss: 0.0938686728477478
Validation loss: 1.5347842977892967

Epoch: 6| Step: 12
Training loss: 0.09599221497774124
Validation loss: 1.5191722646836312

Epoch: 6| Step: 13
Training loss: 0.1500583291053772
Validation loss: 1.5522194459874143

Epoch: 389| Step: 0
Training loss: 0.10613010823726654
Validation loss: 1.5180970981556883

Epoch: 6| Step: 1
Training loss: 0.1374989151954651
Validation loss: 1.4606211749456262

Epoch: 6| Step: 2
Training loss: 0.13999758660793304
Validation loss: 1.4864201853352208

Epoch: 6| Step: 3
Training loss: 0.07552558183670044
Validation loss: 1.4724997948574763

Epoch: 6| Step: 4
Training loss: 0.07685178518295288
Validation loss: 1.4579322222740418

Epoch: 6| Step: 5
Training loss: 0.11360279470682144
Validation loss: 1.4609082097648292

Epoch: 6| Step: 6
Training loss: 0.08717712759971619
Validation loss: 1.4796505916503169

Epoch: 6| Step: 7
Training loss: 0.06915538012981415
Validation loss: 1.4614362870493243

Epoch: 6| Step: 8
Training loss: 0.14166155457496643
Validation loss: 1.4537432321938135

Epoch: 6| Step: 9
Training loss: 0.2049558162689209
Validation loss: 1.4644389690891388

Epoch: 6| Step: 10
Training loss: 0.15637725591659546
Validation loss: 1.4959311293017479

Epoch: 6| Step: 11
Training loss: 0.07942929118871689
Validation loss: 1.486460333229393

Epoch: 6| Step: 12
Training loss: 0.2423219382762909
Validation loss: 1.4808915084408176

Epoch: 6| Step: 13
Training loss: 0.13347084820270538
Validation loss: 1.517092239472174

Epoch: 390| Step: 0
Training loss: 0.15722469985485077
Validation loss: 1.504180130138192

Epoch: 6| Step: 1
Training loss: 0.15581533312797546
Validation loss: 1.5002224227433563

Epoch: 6| Step: 2
Training loss: 0.0879557803273201
Validation loss: 1.46562244238392

Epoch: 6| Step: 3
Training loss: 0.10102176666259766
Validation loss: 1.4379579303085164

Epoch: 6| Step: 4
Training loss: 0.30224519968032837
Validation loss: 1.4372601393730409

Epoch: 6| Step: 5
Training loss: 0.07787314057350159
Validation loss: 1.4564555857771186

Epoch: 6| Step: 6
Training loss: 0.12715159356594086
Validation loss: 1.4577770040881248

Epoch: 6| Step: 7
Training loss: 0.12468358129262924
Validation loss: 1.454423858273414

Epoch: 6| Step: 8
Training loss: 0.10854417830705643
Validation loss: 1.4563970527341288

Epoch: 6| Step: 9
Training loss: 0.11456757038831711
Validation loss: 1.4610860117020146

Epoch: 6| Step: 10
Training loss: 0.1439388245344162
Validation loss: 1.4796075385103944

Epoch: 6| Step: 11
Training loss: 0.1308983415365219
Validation loss: 1.462101649212581

Epoch: 6| Step: 12
Training loss: 0.09671270102262497
Validation loss: 1.4277077644102034

Epoch: 6| Step: 13
Training loss: 0.09662636369466782
Validation loss: 1.4158036375558505

Epoch: 391| Step: 0
Training loss: 0.06379550695419312
Validation loss: 1.4601597093766736

Epoch: 6| Step: 1
Training loss: 0.09691602736711502
Validation loss: 1.4556332518977504

Epoch: 6| Step: 2
Training loss: 0.15019845962524414
Validation loss: 1.471516478446222

Epoch: 6| Step: 3
Training loss: 0.08474448323249817
Validation loss: 1.4553343378087527

Epoch: 6| Step: 4
Training loss: 0.1738477349281311
Validation loss: 1.473835668256206

Epoch: 6| Step: 5
Training loss: 0.17088645696640015
Validation loss: 1.4445476647346251

Epoch: 6| Step: 6
Training loss: 0.17741048336029053
Validation loss: 1.429654211126348

Epoch: 6| Step: 7
Training loss: 0.14430107176303864
Validation loss: 1.419737330047033

Epoch: 6| Step: 8
Training loss: 0.20916476845741272
Validation loss: 1.420505161567401

Epoch: 6| Step: 9
Training loss: 0.14028170704841614
Validation loss: 1.4358621181980256

Epoch: 6| Step: 10
Training loss: 0.16244757175445557
Validation loss: 1.4014026349590671

Epoch: 6| Step: 11
Training loss: 0.12589845061302185
Validation loss: 1.4281009743290562

Epoch: 6| Step: 12
Training loss: 0.3006749153137207
Validation loss: 1.4201099270133561

Epoch: 6| Step: 13
Training loss: 0.09122053533792496
Validation loss: 1.4618129807133828

Epoch: 392| Step: 0
Training loss: 0.0917552188038826
Validation loss: 1.4802592531327279

Epoch: 6| Step: 1
Training loss: 0.14011824131011963
Validation loss: 1.498783383318173

Epoch: 6| Step: 2
Training loss: 0.1339779943227768
Validation loss: 1.4946141883891115

Epoch: 6| Step: 3
Training loss: 0.2755909562110901
Validation loss: 1.5272412197564238

Epoch: 6| Step: 4
Training loss: 0.1112496480345726
Validation loss: 1.5236619928831696

Epoch: 6| Step: 5
Training loss: 0.14039337635040283
Validation loss: 1.5325608573934084

Epoch: 6| Step: 6
Training loss: 0.12945568561553955
Validation loss: 1.4935744090746808

Epoch: 6| Step: 7
Training loss: 0.13970160484313965
Validation loss: 1.4958926836649578

Epoch: 6| Step: 8
Training loss: 0.09119590371847153
Validation loss: 1.5116509852870819

Epoch: 6| Step: 9
Training loss: 0.11759151518344879
Validation loss: 1.4875623859385008

Epoch: 6| Step: 10
Training loss: 0.1931886523962021
Validation loss: 1.4941240997724636

Epoch: 6| Step: 11
Training loss: 0.1487915813922882
Validation loss: 1.4755426933688502

Epoch: 6| Step: 12
Training loss: 0.11823899298906326
Validation loss: 1.4559975542047972

Epoch: 6| Step: 13
Training loss: 0.09276048094034195
Validation loss: 1.4998352155890515

Epoch: 393| Step: 0
Training loss: 0.07032543420791626
Validation loss: 1.4937295862423476

Epoch: 6| Step: 1
Training loss: 0.13840211927890778
Validation loss: 1.4921089500509284

Epoch: 6| Step: 2
Training loss: 0.10360512137413025
Validation loss: 1.4643547919488722

Epoch: 6| Step: 3
Training loss: 0.12623237073421478
Validation loss: 1.4641036679667812

Epoch: 6| Step: 4
Training loss: 0.09163280576467514
Validation loss: 1.4675809209064772

Epoch: 6| Step: 5
Training loss: 0.16942641139030457
Validation loss: 1.4919679139250068

Epoch: 6| Step: 6
Training loss: 0.10203298181295395
Validation loss: 1.5037779397861932

Epoch: 6| Step: 7
Training loss: 0.14051169157028198
Validation loss: 1.4660394114832724

Epoch: 6| Step: 8
Training loss: 0.07702778279781342
Validation loss: 1.4300669213776946

Epoch: 6| Step: 9
Training loss: 0.12343394011259079
Validation loss: 1.458779783659084

Epoch: 6| Step: 10
Training loss: 0.11061238497495651
Validation loss: 1.433490877510399

Epoch: 6| Step: 11
Training loss: 0.3257834017276764
Validation loss: 1.422979260003695

Epoch: 6| Step: 12
Training loss: 0.08524703979492188
Validation loss: 1.4360540413087415

Epoch: 6| Step: 13
Training loss: 0.06484478712081909
Validation loss: 1.4780871714315107

Epoch: 394| Step: 0
Training loss: 0.11620397865772247
Validation loss: 1.4826172705619567

Epoch: 6| Step: 1
Training loss: 0.147026926279068
Validation loss: 1.4855422589086718

Epoch: 6| Step: 2
Training loss: 0.11410166323184967
Validation loss: 1.5158426101489733

Epoch: 6| Step: 3
Training loss: 0.23869045078754425
Validation loss: 1.5179698146799558

Epoch: 6| Step: 4
Training loss: 0.10938861221075058
Validation loss: 1.5365032085808374

Epoch: 6| Step: 5
Training loss: 0.13008368015289307
Validation loss: 1.5218970673058623

Epoch: 6| Step: 6
Training loss: 0.10200870037078857
Validation loss: 1.509818838488671

Epoch: 6| Step: 7
Training loss: 0.11737625300884247
Validation loss: 1.5714727614515571

Epoch: 6| Step: 8
Training loss: 0.14113149046897888
Validation loss: 1.5770910786044212

Epoch: 6| Step: 9
Training loss: 0.086607925593853
Validation loss: 1.5701740851966284

Epoch: 6| Step: 10
Training loss: 0.13442844152450562
Validation loss: 1.5827342335895827

Epoch: 6| Step: 11
Training loss: 0.1262599676847458
Validation loss: 1.5907374158982308

Epoch: 6| Step: 12
Training loss: 0.14378203451633453
Validation loss: 1.5937634603951567

Epoch: 6| Step: 13
Training loss: 0.17215028405189514
Validation loss: 1.5685579520399853

Epoch: 395| Step: 0
Training loss: 0.12223035097122192
Validation loss: 1.5597876964076873

Epoch: 6| Step: 1
Training loss: 0.09409204870462418
Validation loss: 1.534248839142502

Epoch: 6| Step: 2
Training loss: 0.23945724964141846
Validation loss: 1.5248699374096368

Epoch: 6| Step: 3
Training loss: 0.09668412804603577
Validation loss: 1.5416838943317372

Epoch: 6| Step: 4
Training loss: 0.13581225275993347
Validation loss: 1.5099365506120908

Epoch: 6| Step: 5
Training loss: 0.12646615505218506
Validation loss: 1.4904585935736214

Epoch: 6| Step: 6
Training loss: 0.1277741640806198
Validation loss: 1.4706157753544469

Epoch: 6| Step: 7
Training loss: 0.08640171587467194
Validation loss: 1.473662296930949

Epoch: 6| Step: 8
Training loss: 0.13005295395851135
Validation loss: 1.479288435751392

Epoch: 6| Step: 9
Training loss: 0.11891671270132065
Validation loss: 1.460272507000995

Epoch: 6| Step: 10
Training loss: 0.07347367703914642
Validation loss: 1.4477583983893036

Epoch: 6| Step: 11
Training loss: 0.1481044739484787
Validation loss: 1.444583636458202

Epoch: 6| Step: 12
Training loss: 0.10874106734991074
Validation loss: 1.4314443014001335

Epoch: 6| Step: 13
Training loss: 0.12044555693864822
Validation loss: 1.4525021737621677

Epoch: 396| Step: 0
Training loss: 0.1616504192352295
Validation loss: 1.464866574092578

Epoch: 6| Step: 1
Training loss: 0.1785292774438858
Validation loss: 1.4635831720085555

Epoch: 6| Step: 2
Training loss: 0.11571863293647766
Validation loss: 1.4836775102922994

Epoch: 6| Step: 3
Training loss: 0.14306320250034332
Validation loss: 1.4949364924943576

Epoch: 6| Step: 4
Training loss: 0.1301458179950714
Validation loss: 1.507625933616392

Epoch: 6| Step: 5
Training loss: 0.08689044415950775
Validation loss: 1.5076868252087665

Epoch: 6| Step: 6
Training loss: 0.243655264377594
Validation loss: 1.5369068166261077

Epoch: 6| Step: 7
Training loss: 0.16879889369010925
Validation loss: 1.542531151925364

Epoch: 6| Step: 8
Training loss: 0.18793950974941254
Validation loss: 1.5120278007240706

Epoch: 6| Step: 9
Training loss: 0.1423492133617401
Validation loss: 1.53353242463963

Epoch: 6| Step: 10
Training loss: 0.14522187411785126
Validation loss: 1.5010662937677035

Epoch: 6| Step: 11
Training loss: 0.20266838371753693
Validation loss: 1.5031884575402865

Epoch: 6| Step: 12
Training loss: 0.09805499762296677
Validation loss: 1.5145253442948865

Epoch: 6| Step: 13
Training loss: 0.09544806182384491
Validation loss: 1.4692159442491428

Epoch: 397| Step: 0
Training loss: 0.09003099799156189
Validation loss: 1.4532879860170427

Epoch: 6| Step: 1
Training loss: 0.11617932468652725
Validation loss: 1.4516668281247538

Epoch: 6| Step: 2
Training loss: 0.0639578178524971
Validation loss: 1.43946833379807

Epoch: 6| Step: 3
Training loss: 0.10423251986503601
Validation loss: 1.4795659793320524

Epoch: 6| Step: 4
Training loss: 0.1508246213197708
Validation loss: 1.4892650304302093

Epoch: 6| Step: 5
Training loss: 0.24031421542167664
Validation loss: 1.4956765162047518

Epoch: 6| Step: 6
Training loss: 0.14655956625938416
Validation loss: 1.4877110501771331

Epoch: 6| Step: 7
Training loss: 0.17509311437606812
Validation loss: 1.5376910881329608

Epoch: 6| Step: 8
Training loss: 0.07985981553792953
Validation loss: 1.4937948680693103

Epoch: 6| Step: 9
Training loss: 0.18791669607162476
Validation loss: 1.5046696355265956

Epoch: 6| Step: 10
Training loss: 0.08813656866550446
Validation loss: 1.4848786733483756

Epoch: 6| Step: 11
Training loss: 0.22216373682022095
Validation loss: 1.4665498528429257

Epoch: 6| Step: 12
Training loss: 0.09913142025470734
Validation loss: 1.4812545917367423

Epoch: 6| Step: 13
Training loss: 0.08444954454898834
Validation loss: 1.4793639657317952

Epoch: 398| Step: 0
Training loss: 0.12794995307922363
Validation loss: 1.480877181535126

Epoch: 6| Step: 1
Training loss: 0.12430167198181152
Validation loss: 1.4689293689625238

Epoch: 6| Step: 2
Training loss: 0.15785863995552063
Validation loss: 1.4676731722329253

Epoch: 6| Step: 3
Training loss: 0.14524322748184204
Validation loss: 1.4497179203135993

Epoch: 6| Step: 4
Training loss: 0.19362536072731018
Validation loss: 1.4539633527878792

Epoch: 6| Step: 5
Training loss: 0.32808005809783936
Validation loss: 1.4487174082827825

Epoch: 6| Step: 6
Training loss: 0.1551550030708313
Validation loss: 1.4578153689702351

Epoch: 6| Step: 7
Training loss: 0.1045755073428154
Validation loss: 1.4522412989729194

Epoch: 6| Step: 8
Training loss: 0.11966858059167862
Validation loss: 1.4640338574686358

Epoch: 6| Step: 9
Training loss: 0.11421704292297363
Validation loss: 1.4612811867908766

Epoch: 6| Step: 10
Training loss: 0.1684960424900055
Validation loss: 1.4800065473843647

Epoch: 6| Step: 11
Training loss: 0.13871029019355774
Validation loss: 1.4880766484045214

Epoch: 6| Step: 12
Training loss: 0.16287359595298767
Validation loss: 1.493388009327714

Epoch: 6| Step: 13
Training loss: 0.14244890213012695
Validation loss: 1.4760911522373077

Epoch: 399| Step: 0
Training loss: 0.09782256931066513
Validation loss: 1.4603785994232341

Epoch: 6| Step: 1
Training loss: 0.12867331504821777
Validation loss: 1.4447171649625223

Epoch: 6| Step: 2
Training loss: 0.13569435477256775
Validation loss: 1.4473862173736736

Epoch: 6| Step: 3
Training loss: 0.2461150586605072
Validation loss: 1.4397662121762511

Epoch: 6| Step: 4
Training loss: 0.1765376627445221
Validation loss: 1.4634580202000116

Epoch: 6| Step: 5
Training loss: 0.1853920817375183
Validation loss: 1.456388045382756

Epoch: 6| Step: 6
Training loss: 0.16224822402000427
Validation loss: 1.458862954570401

Epoch: 6| Step: 7
Training loss: 0.08035741001367569
Validation loss: 1.4871409029088996

Epoch: 6| Step: 8
Training loss: 0.1439656764268875
Validation loss: 1.4913058409126856

Epoch: 6| Step: 9
Training loss: 0.19815878570079803
Validation loss: 1.521816167780148

Epoch: 6| Step: 10
Training loss: 0.14801210165023804
Validation loss: 1.5344906801818519

Epoch: 6| Step: 11
Training loss: 0.09947656095027924
Validation loss: 1.5272316471222909

Epoch: 6| Step: 12
Training loss: 0.16066497564315796
Validation loss: 1.5371351780429963

Epoch: 6| Step: 13
Training loss: 0.08240222930908203
Validation loss: 1.522192015442797

Epoch: 400| Step: 0
Training loss: 0.14124304056167603
Validation loss: 1.5351584637036888

Epoch: 6| Step: 1
Training loss: 0.05735073983669281
Validation loss: 1.4954927928986088

Epoch: 6| Step: 2
Training loss: 0.12307395786046982
Validation loss: 1.4974427620569866

Epoch: 6| Step: 3
Training loss: 0.1128668263554573
Validation loss: 1.4446178123515139

Epoch: 6| Step: 4
Training loss: 0.12713491916656494
Validation loss: 1.4536291604400964

Epoch: 6| Step: 5
Training loss: 0.07686372101306915
Validation loss: 1.416478544153193

Epoch: 6| Step: 6
Training loss: 0.12637895345687866
Validation loss: 1.4042319777191326

Epoch: 6| Step: 7
Training loss: 0.16178444027900696
Validation loss: 1.4028922665503718

Epoch: 6| Step: 8
Training loss: 0.21592742204666138
Validation loss: 1.421724029766616

Epoch: 6| Step: 9
Training loss: 0.14726051688194275
Validation loss: 1.4139480827957072

Epoch: 6| Step: 10
Training loss: 0.08393064141273499
Validation loss: 1.4396685297771166

Epoch: 6| Step: 11
Training loss: 0.26646143198013306
Validation loss: 1.462054015487753

Epoch: 6| Step: 12
Training loss: 0.11968034505844116
Validation loss: 1.4498456421718802

Epoch: 6| Step: 13
Training loss: 0.11361205577850342
Validation loss: 1.4377255157757831

Epoch: 401| Step: 0
Training loss: 0.15966284275054932
Validation loss: 1.463796466909429

Epoch: 6| Step: 1
Training loss: 0.06868334114551544
Validation loss: 1.4544171229485543

Epoch: 6| Step: 2
Training loss: 0.06993332505226135
Validation loss: 1.4557159626355736

Epoch: 6| Step: 3
Training loss: 0.10009494423866272
Validation loss: 1.465696834748791

Epoch: 6| Step: 4
Training loss: 0.12309680879116058
Validation loss: 1.4750164965147614

Epoch: 6| Step: 5
Training loss: 0.1758318394422531
Validation loss: 1.4753469715836227

Epoch: 6| Step: 6
Training loss: 0.1413140743970871
Validation loss: 1.4484923578077746

Epoch: 6| Step: 7
Training loss: 0.23632566630840302
Validation loss: 1.4765393195613739

Epoch: 6| Step: 8
Training loss: 0.09544716775417328
Validation loss: 1.4755616957141506

Epoch: 6| Step: 9
Training loss: 0.13107621669769287
Validation loss: 1.475473682726583

Epoch: 6| Step: 10
Training loss: 0.09991033375263214
Validation loss: 1.4372715988466818

Epoch: 6| Step: 11
Training loss: 0.1016441211104393
Validation loss: 1.4577690151429945

Epoch: 6| Step: 12
Training loss: 0.0826779454946518
Validation loss: 1.4403047677009337

Epoch: 6| Step: 13
Training loss: 0.12944917380809784
Validation loss: 1.4299548095272434

Epoch: 402| Step: 0
Training loss: 0.06119240075349808
Validation loss: 1.451249627656834

Epoch: 6| Step: 1
Training loss: 0.17453396320343018
Validation loss: 1.4401677705908333

Epoch: 6| Step: 2
Training loss: 0.09957125037908554
Validation loss: 1.4634531057009132

Epoch: 6| Step: 3
Training loss: 0.20565688610076904
Validation loss: 1.4730530323520783

Epoch: 6| Step: 4
Training loss: 0.07670527696609497
Validation loss: 1.484222355709281

Epoch: 6| Step: 5
Training loss: 0.07525357604026794
Validation loss: 1.4831915760553012

Epoch: 6| Step: 6
Training loss: 0.10311246663331985
Validation loss: 1.491238106963455

Epoch: 6| Step: 7
Training loss: 0.1313324272632599
Validation loss: 1.4930471771506852

Epoch: 6| Step: 8
Training loss: 0.06344326585531235
Validation loss: 1.5047538703487766

Epoch: 6| Step: 9
Training loss: 0.11192505061626434
Validation loss: 1.4893109516430927

Epoch: 6| Step: 10
Training loss: 0.10946938395500183
Validation loss: 1.5326621699076828

Epoch: 6| Step: 11
Training loss: 0.19683897495269775
Validation loss: 1.504598177889342

Epoch: 6| Step: 12
Training loss: 0.1554630994796753
Validation loss: 1.4977978121849798

Epoch: 6| Step: 13
Training loss: 0.08946183323860168
Validation loss: 1.4946944264955417

Epoch: 403| Step: 0
Training loss: 0.14116117358207703
Validation loss: 1.519389724218717

Epoch: 6| Step: 1
Training loss: 0.24039416015148163
Validation loss: 1.5024228890736897

Epoch: 6| Step: 2
Training loss: 0.1234510987997055
Validation loss: 1.5269497299707064

Epoch: 6| Step: 3
Training loss: 0.1194765493273735
Validation loss: 1.529037562749719

Epoch: 6| Step: 4
Training loss: 0.06490527093410492
Validation loss: 1.5081366467219528

Epoch: 6| Step: 5
Training loss: 0.06257258355617523
Validation loss: 1.493204225776016

Epoch: 6| Step: 6
Training loss: 0.07809275388717651
Validation loss: 1.4754824100002166

Epoch: 6| Step: 7
Training loss: 0.1518080085515976
Validation loss: 1.4524937547663206

Epoch: 6| Step: 8
Training loss: 0.10023519396781921
Validation loss: 1.422930173976447

Epoch: 6| Step: 9
Training loss: 0.11213630437850952
Validation loss: 1.4175489173140576

Epoch: 6| Step: 10
Training loss: 0.15282145142555237
Validation loss: 1.3997199894279562

Epoch: 6| Step: 11
Training loss: 0.12719228863716125
Validation loss: 1.388777966140419

Epoch: 6| Step: 12
Training loss: 0.12195056676864624
Validation loss: 1.398133074083636

Epoch: 6| Step: 13
Training loss: 0.11189177632331848
Validation loss: 1.4020351504766813

Epoch: 404| Step: 0
Training loss: 0.14733470976352692
Validation loss: 1.4164654247222408

Epoch: 6| Step: 1
Training loss: 0.08838522434234619
Validation loss: 1.4305504342561126

Epoch: 6| Step: 2
Training loss: 0.12960770726203918
Validation loss: 1.4266385070739254

Epoch: 6| Step: 3
Training loss: 0.07196033746004105
Validation loss: 1.4701889073976906

Epoch: 6| Step: 4
Training loss: 0.12013307958841324
Validation loss: 1.4731910844003

Epoch: 6| Step: 5
Training loss: 0.09011596441268921
Validation loss: 1.5259906271452546

Epoch: 6| Step: 6
Training loss: 0.13763557374477386
Validation loss: 1.5360204212127193

Epoch: 6| Step: 7
Training loss: 0.10423527657985687
Validation loss: 1.5331789370506042

Epoch: 6| Step: 8
Training loss: 0.09021787345409393
Validation loss: 1.5207142599167363

Epoch: 6| Step: 9
Training loss: 0.07100324332714081
Validation loss: 1.5260485436326714

Epoch: 6| Step: 10
Training loss: 0.102805495262146
Validation loss: 1.5084456013094993

Epoch: 6| Step: 11
Training loss: 0.2651866376399994
Validation loss: 1.5169474886309715

Epoch: 6| Step: 12
Training loss: 0.15244820713996887
Validation loss: 1.4578844975399714

Epoch: 6| Step: 13
Training loss: 0.12283110618591309
Validation loss: 1.463248557941888

Epoch: 405| Step: 0
Training loss: 0.11306987702846527
Validation loss: 1.4886495567137195

Epoch: 6| Step: 1
Training loss: 0.0942082405090332
Validation loss: 1.4740544544753207

Epoch: 6| Step: 2
Training loss: 0.15051773190498352
Validation loss: 1.4778775771458943

Epoch: 6| Step: 3
Training loss: 0.2203046828508377
Validation loss: 1.450811609786044

Epoch: 6| Step: 4
Training loss: 0.07270652055740356
Validation loss: 1.4470993421411003

Epoch: 6| Step: 5
Training loss: 0.08726855367422104
Validation loss: 1.46373124020074

Epoch: 6| Step: 6
Training loss: 0.08110784739255905
Validation loss: 1.4679665296308455

Epoch: 6| Step: 7
Training loss: 0.15595757961273193
Validation loss: 1.4643687599448747

Epoch: 6| Step: 8
Training loss: 0.1108095794916153
Validation loss: 1.4837182837147866

Epoch: 6| Step: 9
Training loss: 0.1149214506149292
Validation loss: 1.512833341475456

Epoch: 6| Step: 10
Training loss: 0.12552136182785034
Validation loss: 1.4989264447201964

Epoch: 6| Step: 11
Training loss: 0.22800058126449585
Validation loss: 1.5152724750580326

Epoch: 6| Step: 12
Training loss: 0.10898454487323761
Validation loss: 1.53570516263285

Epoch: 6| Step: 13
Training loss: 0.14309269189834595
Validation loss: 1.5521097619046447

Epoch: 406| Step: 0
Training loss: 0.05832850560545921
Validation loss: 1.5427338423267487

Epoch: 6| Step: 1
Training loss: 0.12061101198196411
Validation loss: 1.5493785873536141

Epoch: 6| Step: 2
Training loss: 0.136389821767807
Validation loss: 1.5222360953207938

Epoch: 6| Step: 3
Training loss: 0.12122254818677902
Validation loss: 1.5486205252267982

Epoch: 6| Step: 4
Training loss: 0.06568080931901932
Validation loss: 1.5347293602522982

Epoch: 6| Step: 5
Training loss: 0.2754616439342499
Validation loss: 1.5223517853726622

Epoch: 6| Step: 6
Training loss: 0.09740541875362396
Validation loss: 1.512491383860188

Epoch: 6| Step: 7
Training loss: 0.11082665622234344
Validation loss: 1.4936094194330194

Epoch: 6| Step: 8
Training loss: 0.09545186161994934
Validation loss: 1.4594283757671234

Epoch: 6| Step: 9
Training loss: 0.11403252184391022
Validation loss: 1.4726708704425442

Epoch: 6| Step: 10
Training loss: 0.0871303528547287
Validation loss: 1.4408952959122197

Epoch: 6| Step: 11
Training loss: 0.08846292644739151
Validation loss: 1.4533273423871687

Epoch: 6| Step: 12
Training loss: 0.1634366512298584
Validation loss: 1.435065943707702

Epoch: 6| Step: 13
Training loss: 0.09263695776462555
Validation loss: 1.4671581445201751

Epoch: 407| Step: 0
Training loss: 0.11842432618141174
Validation loss: 1.468119845595411

Epoch: 6| Step: 1
Training loss: 0.08994527161121368
Validation loss: 1.447347653809414

Epoch: 6| Step: 2
Training loss: 0.11712352931499481
Validation loss: 1.4701582026737992

Epoch: 6| Step: 3
Training loss: 0.09368649870157242
Validation loss: 1.4720422221768288

Epoch: 6| Step: 4
Training loss: 0.07648888975381851
Validation loss: 1.468242560663531

Epoch: 6| Step: 5
Training loss: 0.28089797496795654
Validation loss: 1.4473142969992854

Epoch: 6| Step: 6
Training loss: 0.14008039236068726
Validation loss: 1.488685134918459

Epoch: 6| Step: 7
Training loss: 0.12196194380521774
Validation loss: 1.5034338101263969

Epoch: 6| Step: 8
Training loss: 0.07157127559185028
Validation loss: 1.5051080770390008

Epoch: 6| Step: 9
Training loss: 0.12426161766052246
Validation loss: 1.5225350856781006

Epoch: 6| Step: 10
Training loss: 0.15382333099842072
Validation loss: 1.5215531010781564

Epoch: 6| Step: 11
Training loss: 0.11212161928415298
Validation loss: 1.5127174085186375

Epoch: 6| Step: 12
Training loss: 0.12665021419525146
Validation loss: 1.5013576707532328

Epoch: 6| Step: 13
Training loss: 0.034384727478027344
Validation loss: 1.5052294602958105

Epoch: 408| Step: 0
Training loss: 0.08096933364868164
Validation loss: 1.5115647931252756

Epoch: 6| Step: 1
Training loss: 0.06853003799915314
Validation loss: 1.4877296724627096

Epoch: 6| Step: 2
Training loss: 0.10047207772731781
Validation loss: 1.5129660380783903

Epoch: 6| Step: 3
Training loss: 0.10492715239524841
Validation loss: 1.4821536079529793

Epoch: 6| Step: 4
Training loss: 0.07630012929439545
Validation loss: 1.4960629619577879

Epoch: 6| Step: 5
Training loss: 0.14838077127933502
Validation loss: 1.4864573940154044

Epoch: 6| Step: 6
Training loss: 0.09149391949176788
Validation loss: 1.465943790251209

Epoch: 6| Step: 7
Training loss: 0.09751685708761215
Validation loss: 1.4411826172182638

Epoch: 6| Step: 8
Training loss: 0.22216589748859406
Validation loss: 1.4642669141933482

Epoch: 6| Step: 9
Training loss: 0.09268055111169815
Validation loss: 1.470400284695369

Epoch: 6| Step: 10
Training loss: 0.1139577180147171
Validation loss: 1.4752823806578113

Epoch: 6| Step: 11
Training loss: 0.1373519003391266
Validation loss: 1.4773121123672814

Epoch: 6| Step: 12
Training loss: 0.12246285378932953
Validation loss: 1.4722104867299397

Epoch: 6| Step: 13
Training loss: 0.15884926915168762
Validation loss: 1.5306766238263858

Epoch: 409| Step: 0
Training loss: 0.091893769800663
Validation loss: 1.5125407916243359

Epoch: 6| Step: 1
Training loss: 0.10563884675502777
Validation loss: 1.5037109621109501

Epoch: 6| Step: 2
Training loss: 0.19972121715545654
Validation loss: 1.5097833859023226

Epoch: 6| Step: 3
Training loss: 0.06316262483596802
Validation loss: 1.488492597815811

Epoch: 6| Step: 4
Training loss: 0.12353073805570602
Validation loss: 1.5205082624189314

Epoch: 6| Step: 5
Training loss: 0.11037809401750565
Validation loss: 1.5319996328764065

Epoch: 6| Step: 6
Training loss: 0.11274351924657822
Validation loss: 1.4862687421101395

Epoch: 6| Step: 7
Training loss: 0.1241566389799118
Validation loss: 1.502102469885221

Epoch: 6| Step: 8
Training loss: 0.06031723693013191
Validation loss: 1.4645333072190643

Epoch: 6| Step: 9
Training loss: 0.08457691967487335
Validation loss: 1.476256202625972

Epoch: 6| Step: 10
Training loss: 0.17230890691280365
Validation loss: 1.4399860135970577

Epoch: 6| Step: 11
Training loss: 0.15178866684436798
Validation loss: 1.4464929706306868

Epoch: 6| Step: 12
Training loss: 0.22315075993537903
Validation loss: 1.467415955758864

Epoch: 6| Step: 13
Training loss: 0.0834767296910286
Validation loss: 1.4707270245398245

Epoch: 410| Step: 0
Training loss: 0.10550077259540558
Validation loss: 1.482170868945378

Epoch: 6| Step: 1
Training loss: 0.1524910032749176
Validation loss: 1.503630272803768

Epoch: 6| Step: 2
Training loss: 0.0966280996799469
Validation loss: 1.502617674489175

Epoch: 6| Step: 3
Training loss: 0.11589473485946655
Validation loss: 1.5164467032237718

Epoch: 6| Step: 4
Training loss: 0.15741540491580963
Validation loss: 1.4948616463650939

Epoch: 6| Step: 5
Training loss: 0.11034643650054932
Validation loss: 1.50734680955128

Epoch: 6| Step: 6
Training loss: 0.2751404643058777
Validation loss: 1.5340030603511359

Epoch: 6| Step: 7
Training loss: 0.10213422030210495
Validation loss: 1.5291924809896817

Epoch: 6| Step: 8
Training loss: 0.043063484132289886
Validation loss: 1.510469037999389

Epoch: 6| Step: 9
Training loss: 0.10948342829942703
Validation loss: 1.5113130436148694

Epoch: 6| Step: 10
Training loss: 0.06535111367702484
Validation loss: 1.4978723679819415

Epoch: 6| Step: 11
Training loss: 0.09528777003288269
Validation loss: 1.4923292962453698

Epoch: 6| Step: 12
Training loss: 0.0794573724269867
Validation loss: 1.4603525528343775

Epoch: 6| Step: 13
Training loss: 0.0710664615035057
Validation loss: 1.4769697881514026

Epoch: 411| Step: 0
Training loss: 0.12573875486850739
Validation loss: 1.4809455525490545

Epoch: 6| Step: 1
Training loss: 0.09561477601528168
Validation loss: 1.4845030858952513

Epoch: 6| Step: 2
Training loss: 0.06720227748155594
Validation loss: 1.491972235582208

Epoch: 6| Step: 3
Training loss: 0.1443370282649994
Validation loss: 1.5022921626285841

Epoch: 6| Step: 4
Training loss: 0.12786982953548431
Validation loss: 1.5012052469356085

Epoch: 6| Step: 5
Training loss: 0.08973190933465958
Validation loss: 1.4651079145810937

Epoch: 6| Step: 6
Training loss: 0.20791012048721313
Validation loss: 1.4178689987428728

Epoch: 6| Step: 7
Training loss: 0.10774516314268112
Validation loss: 1.4494385494980762

Epoch: 6| Step: 8
Training loss: 0.10695214569568634
Validation loss: 1.4344924970339703

Epoch: 6| Step: 9
Training loss: 0.09353770315647125
Validation loss: 1.3910872756793935

Epoch: 6| Step: 10
Training loss: 0.08387571573257446
Validation loss: 1.4119139358561525

Epoch: 6| Step: 11
Training loss: 0.1341572403907776
Validation loss: 1.4233284740037815

Epoch: 6| Step: 12
Training loss: 0.11449611932039261
Validation loss: 1.4240319472487255

Epoch: 6| Step: 13
Training loss: 0.06968805938959122
Validation loss: 1.423060836971447

Epoch: 412| Step: 0
Training loss: 0.07984450459480286
Validation loss: 1.4610532265837475

Epoch: 6| Step: 1
Training loss: 0.1212858185172081
Validation loss: 1.5016432962109965

Epoch: 6| Step: 2
Training loss: 0.2627232074737549
Validation loss: 1.4832881971072125

Epoch: 6| Step: 3
Training loss: 0.08046063035726547
Validation loss: 1.5093144370663552

Epoch: 6| Step: 4
Training loss: 0.1450231373310089
Validation loss: 1.5075516572562597

Epoch: 6| Step: 5
Training loss: 0.1629451960325241
Validation loss: 1.5166747185491747

Epoch: 6| Step: 6
Training loss: 0.09934403747320175
Validation loss: 1.477450850189373

Epoch: 6| Step: 7
Training loss: 0.11892974376678467
Validation loss: 1.4859302249006046

Epoch: 6| Step: 8
Training loss: 0.049623388797044754
Validation loss: 1.4749495060213151

Epoch: 6| Step: 9
Training loss: 0.07813400775194168
Validation loss: 1.4665675560633342

Epoch: 6| Step: 10
Training loss: 0.12191026657819748
Validation loss: 1.4407650238724166

Epoch: 6| Step: 11
Training loss: 0.12271308898925781
Validation loss: 1.4667619453963412

Epoch: 6| Step: 12
Training loss: 0.11543001979589462
Validation loss: 1.439384880886283

Epoch: 6| Step: 13
Training loss: 0.1280795782804489
Validation loss: 1.4727811992809337

Epoch: 413| Step: 0
Training loss: 0.22529280185699463
Validation loss: 1.472547637519016

Epoch: 6| Step: 1
Training loss: 0.13350804150104523
Validation loss: 1.4966750619232014

Epoch: 6| Step: 2
Training loss: 0.14396131038665771
Validation loss: 1.5078174529537078

Epoch: 6| Step: 3
Training loss: 0.11125388741493225
Validation loss: 1.4948035587546646

Epoch: 6| Step: 4
Training loss: 0.0475984588265419
Validation loss: 1.4947962337924587

Epoch: 6| Step: 5
Training loss: 0.0943627804517746
Validation loss: 1.5332772001143424

Epoch: 6| Step: 6
Training loss: 0.06626086682081223
Validation loss: 1.5548558158259238

Epoch: 6| Step: 7
Training loss: 0.07509991526603699
Validation loss: 1.493786056836446

Epoch: 6| Step: 8
Training loss: 0.14739078283309937
Validation loss: 1.4922789104523198

Epoch: 6| Step: 9
Training loss: 0.07857879251241684
Validation loss: 1.4658206175732356

Epoch: 6| Step: 10
Training loss: 0.12598463892936707
Validation loss: 1.489021651206478

Epoch: 6| Step: 11
Training loss: 0.10547643899917603
Validation loss: 1.4444525382852043

Epoch: 6| Step: 12
Training loss: 0.14407137036323547
Validation loss: 1.4927763387721071

Epoch: 6| Step: 13
Training loss: 0.06178157776594162
Validation loss: 1.472372881827816

Epoch: 414| Step: 0
Training loss: 0.08150100708007812
Validation loss: 1.4723455777732275

Epoch: 6| Step: 1
Training loss: 0.09678643196821213
Validation loss: 1.4826416636026034

Epoch: 6| Step: 2
Training loss: 0.13056637346744537
Validation loss: 1.4904768287494619

Epoch: 6| Step: 3
Training loss: 0.06845234334468842
Validation loss: 1.484509894924779

Epoch: 6| Step: 4
Training loss: 0.14325565099716187
Validation loss: 1.4926830773712487

Epoch: 6| Step: 5
Training loss: 0.06293371319770813
Validation loss: 1.4602869761887418

Epoch: 6| Step: 6
Training loss: 0.094183050096035
Validation loss: 1.4754080349399197

Epoch: 6| Step: 7
Training loss: 0.07219884544610977
Validation loss: 1.4445241317954114

Epoch: 6| Step: 8
Training loss: 0.06363290548324585
Validation loss: 1.435470691932145

Epoch: 6| Step: 9
Training loss: 0.07510212063789368
Validation loss: 1.448665371505163

Epoch: 6| Step: 10
Training loss: 0.1539096236228943
Validation loss: 1.4517920876062045

Epoch: 6| Step: 11
Training loss: 0.2108425796031952
Validation loss: 1.4684983453442972

Epoch: 6| Step: 12
Training loss: 0.11439661681652069
Validation loss: 1.478267123622279

Epoch: 6| Step: 13
Training loss: 0.10358067601919174
Validation loss: 1.4826310706394974

Epoch: 415| Step: 0
Training loss: 0.15086156129837036
Validation loss: 1.4648057260820944

Epoch: 6| Step: 1
Training loss: 0.22569598257541656
Validation loss: 1.416768882864265

Epoch: 6| Step: 2
Training loss: 0.10466074198484421
Validation loss: 1.4406111971024544

Epoch: 6| Step: 3
Training loss: 0.047303617000579834
Validation loss: 1.453822806317319

Epoch: 6| Step: 4
Training loss: 0.06043024733662605
Validation loss: 1.445463336924071

Epoch: 6| Step: 5
Training loss: 0.0975356176495552
Validation loss: 1.41503478634742

Epoch: 6| Step: 6
Training loss: 0.09956812858581543
Validation loss: 1.427176090978807

Epoch: 6| Step: 7
Training loss: 0.16084186732769012
Validation loss: 1.4578114248091174

Epoch: 6| Step: 8
Training loss: 0.08817379176616669
Validation loss: 1.4220286825651764

Epoch: 6| Step: 9
Training loss: 0.07131506502628326
Validation loss: 1.4506300931335778

Epoch: 6| Step: 10
Training loss: 0.08818551898002625
Validation loss: 1.4466283629017491

Epoch: 6| Step: 11
Training loss: 0.0782427191734314
Validation loss: 1.467605552365703

Epoch: 6| Step: 12
Training loss: 0.1245364248752594
Validation loss: 1.4574743022200882

Epoch: 6| Step: 13
Training loss: 0.10949946939945221
Validation loss: 1.4815771323378368

Epoch: 416| Step: 0
Training loss: 0.08626405894756317
Validation loss: 1.5015626517675256

Epoch: 6| Step: 1
Training loss: 0.09272760152816772
Validation loss: 1.5603533367956839

Epoch: 6| Step: 2
Training loss: 0.10408251732587814
Validation loss: 1.5375782392358268

Epoch: 6| Step: 3
Training loss: 0.13877496123313904
Validation loss: 1.534515050149733

Epoch: 6| Step: 4
Training loss: 0.08173845708370209
Validation loss: 1.5145564374103342

Epoch: 6| Step: 5
Training loss: 0.0846046656370163
Validation loss: 1.5040810838822396

Epoch: 6| Step: 6
Training loss: 0.14121198654174805
Validation loss: 1.4991403202856741

Epoch: 6| Step: 7
Training loss: 0.09261564910411835
Validation loss: 1.4737454255421956

Epoch: 6| Step: 8
Training loss: 0.1743367463350296
Validation loss: 1.4737993453138618

Epoch: 6| Step: 9
Training loss: 0.11476784944534302
Validation loss: 1.4452788163256902

Epoch: 6| Step: 10
Training loss: 0.34209123253822327
Validation loss: 1.4569414187503118

Epoch: 6| Step: 11
Training loss: 0.0817740187048912
Validation loss: 1.450348311854947

Epoch: 6| Step: 12
Training loss: 0.10465133190155029
Validation loss: 1.450308161397134

Epoch: 6| Step: 13
Training loss: 0.09454275667667389
Validation loss: 1.4398219329054638

Epoch: 417| Step: 0
Training loss: 0.09584958106279373
Validation loss: 1.4749701856285014

Epoch: 6| Step: 1
Training loss: 0.15725106000900269
Validation loss: 1.467328086976082

Epoch: 6| Step: 2
Training loss: 0.0875813439488411
Validation loss: 1.493850186306943

Epoch: 6| Step: 3
Training loss: 0.1854688823223114
Validation loss: 1.5126112943054528

Epoch: 6| Step: 4
Training loss: 0.10621930658817291
Validation loss: 1.5101648325561194

Epoch: 6| Step: 5
Training loss: 0.10939554870128632
Validation loss: 1.4828861195554015

Epoch: 6| Step: 6
Training loss: 0.10311340540647507
Validation loss: 1.5031666742858065

Epoch: 6| Step: 7
Training loss: 0.09632889181375504
Validation loss: 1.4939455780931699

Epoch: 6| Step: 8
Training loss: 0.13632459938526154
Validation loss: 1.4898984586038897

Epoch: 6| Step: 9
Training loss: 0.1265413910150528
Validation loss: 1.4966931945534163

Epoch: 6| Step: 10
Training loss: 0.15765529870986938
Validation loss: 1.502722950391872

Epoch: 6| Step: 11
Training loss: 0.09196142852306366
Validation loss: 1.4806026809959

Epoch: 6| Step: 12
Training loss: 0.06881052255630493
Validation loss: 1.5053183071074947

Epoch: 6| Step: 13
Training loss: 0.4065018594264984
Validation loss: 1.4756697429123746

Epoch: 418| Step: 0
Training loss: 0.07456421852111816
Validation loss: 1.4717018130005046

Epoch: 6| Step: 1
Training loss: 0.08000904321670532
Validation loss: 1.4990588157407698

Epoch: 6| Step: 2
Training loss: 0.09234490245580673
Validation loss: 1.521345510277697

Epoch: 6| Step: 3
Training loss: 0.26635128259658813
Validation loss: 1.5439309843124882

Epoch: 6| Step: 4
Training loss: 0.1403789222240448
Validation loss: 1.5907358097773727

Epoch: 6| Step: 5
Training loss: 0.1367778331041336
Validation loss: 1.5590031544367473

Epoch: 6| Step: 6
Training loss: 0.103643998503685
Validation loss: 1.5375313540940643

Epoch: 6| Step: 7
Training loss: 0.10311003774404526
Validation loss: 1.5317844677996892

Epoch: 6| Step: 8
Training loss: 0.1860198974609375
Validation loss: 1.527922732855684

Epoch: 6| Step: 9
Training loss: 0.09902739524841309
Validation loss: 1.524387853119963

Epoch: 6| Step: 10
Training loss: 0.0729837566614151
Validation loss: 1.471821387608846

Epoch: 6| Step: 11
Training loss: 0.1085095927119255
Validation loss: 1.452107616650161

Epoch: 6| Step: 12
Training loss: 0.13100463151931763
Validation loss: 1.4192155881594586

Epoch: 6| Step: 13
Training loss: 0.10071039199829102
Validation loss: 1.4153973364060926

Epoch: 419| Step: 0
Training loss: 0.2809731960296631
Validation loss: 1.380004685412171

Epoch: 6| Step: 1
Training loss: 0.15049830079078674
Validation loss: 1.4044608800641951

Epoch: 6| Step: 2
Training loss: 0.09468158334493637
Validation loss: 1.4127840483060448

Epoch: 6| Step: 3
Training loss: 0.10069626569747925
Validation loss: 1.4105431610538113

Epoch: 6| Step: 4
Training loss: 0.21327823400497437
Validation loss: 1.4617550488441222

Epoch: 6| Step: 5
Training loss: 0.08638457953929901
Validation loss: 1.4868276067959365

Epoch: 6| Step: 6
Training loss: 0.11748675256967545
Validation loss: 1.5158988455290436

Epoch: 6| Step: 7
Training loss: 0.13053098320960999
Validation loss: 1.5673157886792255

Epoch: 6| Step: 8
Training loss: 0.09755698591470718
Validation loss: 1.5351932061615812

Epoch: 6| Step: 9
Training loss: 0.09487894922494888
Validation loss: 1.5266836971364997

Epoch: 6| Step: 10
Training loss: 0.14444959163665771
Validation loss: 1.508847664761287

Epoch: 6| Step: 11
Training loss: 0.09108299016952515
Validation loss: 1.5027469960592126

Epoch: 6| Step: 12
Training loss: 0.11127251386642456
Validation loss: 1.483701015031466

Epoch: 6| Step: 13
Training loss: 0.15024010837078094
Validation loss: 1.4748967027151456

Epoch: 420| Step: 0
Training loss: 0.16659924387931824
Validation loss: 1.4794039290438417

Epoch: 6| Step: 1
Training loss: 0.08255767077207565
Validation loss: 1.447792589023549

Epoch: 6| Step: 2
Training loss: 0.08058518171310425
Validation loss: 1.4836220433635097

Epoch: 6| Step: 3
Training loss: 0.10026614367961884
Validation loss: 1.4760535211973294

Epoch: 6| Step: 4
Training loss: 0.11270786821842194
Validation loss: 1.4806952540592482

Epoch: 6| Step: 5
Training loss: 0.0869353786110878
Validation loss: 1.5020441509062243

Epoch: 6| Step: 6
Training loss: 0.1011139377951622
Validation loss: 1.5003465260228803

Epoch: 6| Step: 7
Training loss: 0.19774192571640015
Validation loss: 1.501425636711941

Epoch: 6| Step: 8
Training loss: 0.11268086731433868
Validation loss: 1.5131718266394831

Epoch: 6| Step: 9
Training loss: 0.09844572842121124
Validation loss: 1.51346920510774

Epoch: 6| Step: 10
Training loss: 0.20625850558280945
Validation loss: 1.4884117777629564

Epoch: 6| Step: 11
Training loss: 0.16087406873703003
Validation loss: 1.464871762901224

Epoch: 6| Step: 12
Training loss: 0.06695695221424103
Validation loss: 1.44492894218814

Epoch: 6| Step: 13
Training loss: 0.14508438110351562
Validation loss: 1.4354909844295953

Epoch: 421| Step: 0
Training loss: 0.10198747366666794
Validation loss: 1.4333302064608502

Epoch: 6| Step: 1
Training loss: 0.07219838351011276
Validation loss: 1.3882456197533557

Epoch: 6| Step: 2
Training loss: 0.08881212770938873
Validation loss: 1.386333937926959

Epoch: 6| Step: 3
Training loss: 0.18058651685714722
Validation loss: 1.3953859408696492

Epoch: 6| Step: 4
Training loss: 0.08502933382987976
Validation loss: 1.378102211542027

Epoch: 6| Step: 5
Training loss: 0.11069327592849731
Validation loss: 1.4048610374491701

Epoch: 6| Step: 6
Training loss: 0.07892461121082306
Validation loss: 1.4137919577219153

Epoch: 6| Step: 7
Training loss: 0.20375151932239532
Validation loss: 1.4370119020503054

Epoch: 6| Step: 8
Training loss: 0.1251906454563141
Validation loss: 1.4424678971690517

Epoch: 6| Step: 9
Training loss: 0.1403535008430481
Validation loss: 1.4449711820130706

Epoch: 6| Step: 10
Training loss: 0.12064941227436066
Validation loss: 1.4302244878584338

Epoch: 6| Step: 11
Training loss: 0.07502773404121399
Validation loss: 1.4659431954865814

Epoch: 6| Step: 12
Training loss: 0.08374394476413727
Validation loss: 1.4438910997042091

Epoch: 6| Step: 13
Training loss: 0.10331527143716812
Validation loss: 1.4664444981082794

Epoch: 422| Step: 0
Training loss: 0.06836284697055817
Validation loss: 1.4862722607069119

Epoch: 6| Step: 1
Training loss: 0.11218671500682831
Validation loss: 1.512216684638813

Epoch: 6| Step: 2
Training loss: 0.09609203040599823
Validation loss: 1.5171777099691413

Epoch: 6| Step: 3
Training loss: 0.09357604384422302
Validation loss: 1.5337622627135246

Epoch: 6| Step: 4
Training loss: 0.10456695407629013
Validation loss: 1.5544592744560652

Epoch: 6| Step: 5
Training loss: 0.11863924562931061
Validation loss: 1.5330258825773835

Epoch: 6| Step: 6
Training loss: 0.07668320834636688
Validation loss: 1.5070933347107263

Epoch: 6| Step: 7
Training loss: 0.11145038902759552
Validation loss: 1.4977197961140705

Epoch: 6| Step: 8
Training loss: 0.11518006026744843
Validation loss: 1.4772112010627665

Epoch: 6| Step: 9
Training loss: 0.07888185977935791
Validation loss: 1.4775103151157338

Epoch: 6| Step: 10
Training loss: 0.26740163564682007
Validation loss: 1.4761622477603216

Epoch: 6| Step: 11
Training loss: 0.08916919678449631
Validation loss: 1.482176629445886

Epoch: 6| Step: 12
Training loss: 0.10130784660577774
Validation loss: 1.4676746450444704

Epoch: 6| Step: 13
Training loss: 0.10928624868392944
Validation loss: 1.4584070251834007

Epoch: 423| Step: 0
Training loss: 0.09659961611032486
Validation loss: 1.4839523389775267

Epoch: 6| Step: 1
Training loss: 0.18751941621303558
Validation loss: 1.4805704778240574

Epoch: 6| Step: 2
Training loss: 0.13072240352630615
Validation loss: 1.4864419391078334

Epoch: 6| Step: 3
Training loss: 0.09161075949668884
Validation loss: 1.4832862448948685

Epoch: 6| Step: 4
Training loss: 0.05248580873012543
Validation loss: 1.457957745880209

Epoch: 6| Step: 5
Training loss: 0.08883275091648102
Validation loss: 1.4619838101889497

Epoch: 6| Step: 6
Training loss: 0.07203418761491776
Validation loss: 1.4188942204239547

Epoch: 6| Step: 7
Training loss: 0.08522400259971619
Validation loss: 1.4100503742053945

Epoch: 6| Step: 8
Training loss: 0.12828335165977478
Validation loss: 1.4020022564036871

Epoch: 6| Step: 9
Training loss: 0.13728435337543488
Validation loss: 1.3978670745767572

Epoch: 6| Step: 10
Training loss: 0.12110152840614319
Validation loss: 1.4104848657884905

Epoch: 6| Step: 11
Training loss: 0.09973877668380737
Validation loss: 1.4044154036429621

Epoch: 6| Step: 12
Training loss: 0.1454242318868637
Validation loss: 1.413155230142737

Epoch: 6| Step: 13
Training loss: 0.07489907741546631
Validation loss: 1.4211718882283857

Epoch: 424| Step: 0
Training loss: 0.15977948904037476
Validation loss: 1.4261718398781233

Epoch: 6| Step: 1
Training loss: 0.0742885172367096
Validation loss: 1.4412387237753919

Epoch: 6| Step: 2
Training loss: 0.04852219298481941
Validation loss: 1.4541682158747027

Epoch: 6| Step: 3
Training loss: 0.09287174046039581
Validation loss: 1.4602052614253054

Epoch: 6| Step: 4
Training loss: 0.11577317118644714
Validation loss: 1.4600203806354153

Epoch: 6| Step: 5
Training loss: 0.12318868190050125
Validation loss: 1.458268993644304

Epoch: 6| Step: 6
Training loss: 0.08382561802864075
Validation loss: 1.4347433684974589

Epoch: 6| Step: 7
Training loss: 0.0696450024843216
Validation loss: 1.4176876442406767

Epoch: 6| Step: 8
Training loss: 0.05944971367716789
Validation loss: 1.4096484658538655

Epoch: 6| Step: 9
Training loss: 0.26779407262802124
Validation loss: 1.415537175311837

Epoch: 6| Step: 10
Training loss: 0.11815048009157181
Validation loss: 1.4038687457320511

Epoch: 6| Step: 11
Training loss: 0.09552912414073944
Validation loss: 1.4262915183139104

Epoch: 6| Step: 12
Training loss: 0.05320868641138077
Validation loss: 1.4219907849065718

Epoch: 6| Step: 13
Training loss: 0.11500024795532227
Validation loss: 1.4490469207045853

Epoch: 425| Step: 0
Training loss: 0.07789333164691925
Validation loss: 1.446220087748702

Epoch: 6| Step: 1
Training loss: 0.07332520931959152
Validation loss: 1.4457175154839792

Epoch: 6| Step: 2
Training loss: 0.06853614002466202
Validation loss: 1.4810992415233324

Epoch: 6| Step: 3
Training loss: 0.05023838207125664
Validation loss: 1.4563739607411046

Epoch: 6| Step: 4
Training loss: 0.12324117869138718
Validation loss: 1.4586571583183863

Epoch: 6| Step: 5
Training loss: 0.15189382433891296
Validation loss: 1.4824177911204677

Epoch: 6| Step: 6
Training loss: 0.1375999003648758
Validation loss: 1.4889246571448542

Epoch: 6| Step: 7
Training loss: 0.28183189034461975
Validation loss: 1.4589459165450065

Epoch: 6| Step: 8
Training loss: 0.11157961189746857
Validation loss: 1.4442288670488583

Epoch: 6| Step: 9
Training loss: 0.07489132881164551
Validation loss: 1.4387259893519904

Epoch: 6| Step: 10
Training loss: 0.13531306385993958
Validation loss: 1.42544170477057

Epoch: 6| Step: 11
Training loss: 0.08490964025259018
Validation loss: 1.4106554562045681

Epoch: 6| Step: 12
Training loss: 0.09463953226804733
Validation loss: 1.4096831865208124

Epoch: 6| Step: 13
Training loss: 0.07701247185468674
Validation loss: 1.4180095439316125

Epoch: 426| Step: 0
Training loss: 0.07570779323577881
Validation loss: 1.4166214472504073

Epoch: 6| Step: 1
Training loss: 0.054651159793138504
Validation loss: 1.3977020414926673

Epoch: 6| Step: 2
Training loss: 0.09833956509828568
Validation loss: 1.43049773862285

Epoch: 6| Step: 3
Training loss: 0.06300442665815353
Validation loss: 1.4572399098386046

Epoch: 6| Step: 4
Training loss: 0.12033876776695251
Validation loss: 1.460464197461323

Epoch: 6| Step: 5
Training loss: 0.07404954731464386
Validation loss: 1.4631945125518306

Epoch: 6| Step: 6
Training loss: 0.09639760106801987
Validation loss: 1.4872984886169434

Epoch: 6| Step: 7
Training loss: 0.16275347769260406
Validation loss: 1.4816081677713702

Epoch: 6| Step: 8
Training loss: 0.2547016143798828
Validation loss: 1.4901693649189447

Epoch: 6| Step: 9
Training loss: 0.09836450219154358
Validation loss: 1.5259930510674753

Epoch: 6| Step: 10
Training loss: 0.0763917788863182
Validation loss: 1.4906141911783526

Epoch: 6| Step: 11
Training loss: 0.09772159159183502
Validation loss: 1.4733913342158

Epoch: 6| Step: 12
Training loss: 0.11739111691713333
Validation loss: 1.4640384592035764

Epoch: 6| Step: 13
Training loss: 0.07976338267326355
Validation loss: 1.4861947208322503

Epoch: 427| Step: 0
Training loss: 0.08527660369873047
Validation loss: 1.4700051161550707

Epoch: 6| Step: 1
Training loss: 0.09297934174537659
Validation loss: 1.4863663668273597

Epoch: 6| Step: 2
Training loss: 0.2827710211277008
Validation loss: 1.4795534636384697

Epoch: 6| Step: 3
Training loss: 0.1435033082962036
Validation loss: 1.4748050653806297

Epoch: 6| Step: 4
Training loss: 0.0838153213262558
Validation loss: 1.498408095811003

Epoch: 6| Step: 5
Training loss: 0.11018398404121399
Validation loss: 1.473825176556905

Epoch: 6| Step: 6
Training loss: 0.11868327111005783
Validation loss: 1.4599190360756331

Epoch: 6| Step: 7
Training loss: 0.13405519723892212
Validation loss: 1.4150744868863014

Epoch: 6| Step: 8
Training loss: 0.11919264495372772
Validation loss: 1.4375993167200396

Epoch: 6| Step: 9
Training loss: 0.07488875091075897
Validation loss: 1.4351984230420922

Epoch: 6| Step: 10
Training loss: 0.1842048168182373
Validation loss: 1.4670155714916926

Epoch: 6| Step: 11
Training loss: 0.14379781484603882
Validation loss: 1.4991553073288293

Epoch: 6| Step: 12
Training loss: 0.13419005274772644
Validation loss: 1.471200454619623

Epoch: 6| Step: 13
Training loss: 0.11813674867153168
Validation loss: 1.5104033690626903

Epoch: 428| Step: 0
Training loss: 0.11931225657463074
Validation loss: 1.5292713898484425

Epoch: 6| Step: 1
Training loss: 0.10665950924158096
Validation loss: 1.5262486011751237

Epoch: 6| Step: 2
Training loss: 0.09613589197397232
Validation loss: 1.5673266354427542

Epoch: 6| Step: 3
Training loss: 0.14442431926727295
Validation loss: 1.5694139388299757

Epoch: 6| Step: 4
Training loss: 0.20594364404678345
Validation loss: 1.5597341009365615

Epoch: 6| Step: 5
Training loss: 0.10668466240167618
Validation loss: 1.541387310592077

Epoch: 6| Step: 6
Training loss: 0.10436844825744629
Validation loss: 1.4943857974903558

Epoch: 6| Step: 7
Training loss: 0.1208638846874237
Validation loss: 1.4619071996340187

Epoch: 6| Step: 8
Training loss: 0.1340274214744568
Validation loss: 1.4399606252229342

Epoch: 6| Step: 9
Training loss: 0.13942170143127441
Validation loss: 1.3795893525564542

Epoch: 6| Step: 10
Training loss: 0.0850142166018486
Validation loss: 1.3553228243704765

Epoch: 6| Step: 11
Training loss: 0.21600982546806335
Validation loss: 1.3544068644123692

Epoch: 6| Step: 12
Training loss: 0.0983894020318985
Validation loss: 1.3381286590330062

Epoch: 6| Step: 13
Training loss: 0.16536425054073334
Validation loss: 1.3722734707658009

Epoch: 429| Step: 0
Training loss: 0.12724556028842926
Validation loss: 1.3718887695702173

Epoch: 6| Step: 1
Training loss: 0.12228512018918991
Validation loss: 1.3690394355404762

Epoch: 6| Step: 2
Training loss: 0.2212226390838623
Validation loss: 1.3582123235989643

Epoch: 6| Step: 3
Training loss: 0.10786457359790802
Validation loss: 1.3895311611954884

Epoch: 6| Step: 4
Training loss: 0.1081073135137558
Validation loss: 1.4006823006496634

Epoch: 6| Step: 5
Training loss: 0.1104530617594719
Validation loss: 1.4327332127478816

Epoch: 6| Step: 6
Training loss: 0.1365150660276413
Validation loss: 1.4271577430027786

Epoch: 6| Step: 7
Training loss: 0.15722963213920593
Validation loss: 1.4467099276922082

Epoch: 6| Step: 8
Training loss: 0.10129743814468384
Validation loss: 1.4870099482997772

Epoch: 6| Step: 9
Training loss: 0.13835731148719788
Validation loss: 1.4861804625039459

Epoch: 6| Step: 10
Training loss: 0.10109711438417435
Validation loss: 1.4754270981716853

Epoch: 6| Step: 11
Training loss: 0.12396281957626343
Validation loss: 1.478795534820967

Epoch: 6| Step: 12
Training loss: 0.09420070052146912
Validation loss: 1.4615290113674697

Epoch: 6| Step: 13
Training loss: 0.07655652612447739
Validation loss: 1.4535857387768325

Epoch: 430| Step: 0
Training loss: 0.13956895470619202
Validation loss: 1.4545372160532142

Epoch: 6| Step: 1
Training loss: 0.2330142706632614
Validation loss: 1.4636767384826497

Epoch: 6| Step: 2
Training loss: 0.17015515267848969
Validation loss: 1.4861337862988955

Epoch: 6| Step: 3
Training loss: 0.19054237008094788
Validation loss: 1.4828981135481147

Epoch: 6| Step: 4
Training loss: 0.18575027585029602
Validation loss: 1.4911490319877543

Epoch: 6| Step: 5
Training loss: 0.12431317567825317
Validation loss: 1.477700456496208

Epoch: 6| Step: 6
Training loss: 0.13006407022476196
Validation loss: 1.4939289759564143

Epoch: 6| Step: 7
Training loss: 0.1487080156803131
Validation loss: 1.4705031789759153

Epoch: 6| Step: 8
Training loss: 0.12453214824199677
Validation loss: 1.4634254555548392

Epoch: 6| Step: 9
Training loss: 0.22066238522529602
Validation loss: 1.4627582949976767

Epoch: 6| Step: 10
Training loss: 0.08885347843170166
Validation loss: 1.456631835429899

Epoch: 6| Step: 11
Training loss: 0.2150096297264099
Validation loss: 1.4574423579759495

Epoch: 6| Step: 12
Training loss: 0.15635329484939575
Validation loss: 1.4563592954348492

Epoch: 6| Step: 13
Training loss: 0.11167141795158386
Validation loss: 1.4600639035624843

Epoch: 431| Step: 0
Training loss: 0.20474086701869965
Validation loss: 1.4649458944156606

Epoch: 6| Step: 1
Training loss: 0.12849193811416626
Validation loss: 1.4583724134711809

Epoch: 6| Step: 2
Training loss: 0.051053985953330994
Validation loss: 1.4481888240383518

Epoch: 6| Step: 3
Training loss: 0.10481846332550049
Validation loss: 1.476880551666342

Epoch: 6| Step: 4
Training loss: 0.12596991658210754
Validation loss: 1.4784558344912786

Epoch: 6| Step: 5
Training loss: 0.1469092071056366
Validation loss: 1.519971521951819

Epoch: 6| Step: 6
Training loss: 0.3599218726158142
Validation loss: 1.521516271816787

Epoch: 6| Step: 7
Training loss: 0.151156485080719
Validation loss: 1.5395837932504632

Epoch: 6| Step: 8
Training loss: 0.17873603105545044
Validation loss: 1.511586098260777

Epoch: 6| Step: 9
Training loss: 0.13474993407726288
Validation loss: 1.481887835328297

Epoch: 6| Step: 10
Training loss: 0.09949935972690582
Validation loss: 1.4547371607954784

Epoch: 6| Step: 11
Training loss: 0.060062918812036514
Validation loss: 1.4450085137480049

Epoch: 6| Step: 12
Training loss: 0.07989458739757538
Validation loss: 1.4468849576929563

Epoch: 6| Step: 13
Training loss: 0.1597391664981842
Validation loss: 1.4150765301078878

Epoch: 432| Step: 0
Training loss: 0.1883753091096878
Validation loss: 1.4052971191303705

Epoch: 6| Step: 1
Training loss: 0.2467762976884842
Validation loss: 1.42951677883825

Epoch: 6| Step: 2
Training loss: 0.147808238863945
Validation loss: 1.446634369511758

Epoch: 6| Step: 3
Training loss: 0.16442696750164032
Validation loss: 1.4329018362106816

Epoch: 6| Step: 4
Training loss: 0.1858149766921997
Validation loss: 1.467373291651408

Epoch: 6| Step: 5
Training loss: 0.1784851998090744
Validation loss: 1.448290010934235

Epoch: 6| Step: 6
Training loss: 0.1357208490371704
Validation loss: 1.4639684615596649

Epoch: 6| Step: 7
Training loss: 0.1190219447016716
Validation loss: 1.4736732834128923

Epoch: 6| Step: 8
Training loss: 0.15330788493156433
Validation loss: 1.466078551866675

Epoch: 6| Step: 9
Training loss: 0.08854475617408752
Validation loss: 1.5068959613000192

Epoch: 6| Step: 10
Training loss: 0.25265711545944214
Validation loss: 1.4810344314062467

Epoch: 6| Step: 11
Training loss: 0.15751135349273682
Validation loss: 1.5571183478960426

Epoch: 6| Step: 12
Training loss: 0.23438304662704468
Validation loss: 1.5418424093595116

Epoch: 6| Step: 13
Training loss: 0.1451483815908432
Validation loss: 1.498955681759824

Epoch: 433| Step: 0
Training loss: 0.0854606106877327
Validation loss: 1.4964535082540205

Epoch: 6| Step: 1
Training loss: 0.11501854658126831
Validation loss: 1.4394743416898994

Epoch: 6| Step: 2
Training loss: 0.13127735257148743
Validation loss: 1.426075650799659

Epoch: 6| Step: 3
Training loss: 0.11843448877334595
Validation loss: 1.4090993705616202

Epoch: 6| Step: 4
Training loss: 0.07289134711027145
Validation loss: 1.4139555820854761

Epoch: 6| Step: 5
Training loss: 0.1875777244567871
Validation loss: 1.3987105149094776

Epoch: 6| Step: 6
Training loss: 0.1387273073196411
Validation loss: 1.402996575960549

Epoch: 6| Step: 7
Training loss: 0.1744350641965866
Validation loss: 1.3718034516098678

Epoch: 6| Step: 8
Training loss: 0.11872757971286774
Validation loss: 1.3994992247191809

Epoch: 6| Step: 9
Training loss: 0.1442621499300003
Validation loss: 1.4029928394543227

Epoch: 6| Step: 10
Training loss: 0.29811084270477295
Validation loss: 1.4113911633850427

Epoch: 6| Step: 11
Training loss: 0.22062666714191437
Validation loss: 1.4274782993460213

Epoch: 6| Step: 12
Training loss: 0.1868610978126526
Validation loss: 1.4523326748160905

Epoch: 6| Step: 13
Training loss: 0.05783148482441902
Validation loss: 1.460872414291546

Epoch: 434| Step: 0
Training loss: 0.06562405079603195
Validation loss: 1.432947345959243

Epoch: 6| Step: 1
Training loss: 0.22335012257099152
Validation loss: 1.4685947843777236

Epoch: 6| Step: 2
Training loss: 0.13057675957679749
Validation loss: 1.472188045901637

Epoch: 6| Step: 3
Training loss: 0.060573577880859375
Validation loss: 1.4512088696161907

Epoch: 6| Step: 4
Training loss: 0.09001638740301132
Validation loss: 1.45659847797886

Epoch: 6| Step: 5
Training loss: 0.1028624102473259
Validation loss: 1.462709681321216

Epoch: 6| Step: 6
Training loss: 0.056422531604766846
Validation loss: 1.4462524037207327

Epoch: 6| Step: 7
Training loss: 0.08696949481964111
Validation loss: 1.4598355485546974

Epoch: 6| Step: 8
Training loss: 0.0838034451007843
Validation loss: 1.4580202910207933

Epoch: 6| Step: 9
Training loss: 0.09823192656040192
Validation loss: 1.452488157056993

Epoch: 6| Step: 10
Training loss: 0.15414614975452423
Validation loss: 1.4652269296748663

Epoch: 6| Step: 11
Training loss: 0.17117953300476074
Validation loss: 1.4652136589891167

Epoch: 6| Step: 12
Training loss: 0.11860286444425583
Validation loss: 1.4788214750187372

Epoch: 6| Step: 13
Training loss: 0.21086619794368744
Validation loss: 1.4628378627120808

Epoch: 435| Step: 0
Training loss: 0.12763488292694092
Validation loss: 1.4775912338687527

Epoch: 6| Step: 1
Training loss: 0.12122774124145508
Validation loss: 1.4735317409679454

Epoch: 6| Step: 2
Training loss: 0.07298021763563156
Validation loss: 1.4836183888937837

Epoch: 6| Step: 3
Training loss: 0.12845119833946228
Validation loss: 1.4672091968597905

Epoch: 6| Step: 4
Training loss: 0.12233732640743256
Validation loss: 1.4436436455736879

Epoch: 6| Step: 5
Training loss: 0.08749498426914215
Validation loss: 1.4410617370759287

Epoch: 6| Step: 6
Training loss: 0.09346282482147217
Validation loss: 1.4470678542249946

Epoch: 6| Step: 7
Training loss: 0.15244543552398682
Validation loss: 1.483564381958336

Epoch: 6| Step: 8
Training loss: 0.11331118643283844
Validation loss: 1.4839293033845964

Epoch: 6| Step: 9
Training loss: 0.06750471889972687
Validation loss: 1.4780940740339217

Epoch: 6| Step: 10
Training loss: 0.0905027687549591
Validation loss: 1.4948970553695515

Epoch: 6| Step: 11
Training loss: 0.2274657040834427
Validation loss: 1.4963097982509161

Epoch: 6| Step: 12
Training loss: 0.06799641251564026
Validation loss: 1.4778605366265902

Epoch: 6| Step: 13
Training loss: 0.12934726476669312
Validation loss: 1.4596511279383013

Epoch: 436| Step: 0
Training loss: 0.20521779358386993
Validation loss: 1.468110022365406

Epoch: 6| Step: 1
Training loss: 0.10233666002750397
Validation loss: 1.4550109165970997

Epoch: 6| Step: 2
Training loss: 0.09407129883766174
Validation loss: 1.4390278606004612

Epoch: 6| Step: 3
Training loss: 0.11364604532718658
Validation loss: 1.4323607760090982

Epoch: 6| Step: 4
Training loss: 0.10557953268289566
Validation loss: 1.4438023695381739

Epoch: 6| Step: 5
Training loss: 0.13206082582473755
Validation loss: 1.4686361294920727

Epoch: 6| Step: 6
Training loss: 0.10493586212396622
Validation loss: 1.4249406604356663

Epoch: 6| Step: 7
Training loss: 0.06545034795999527
Validation loss: 1.4705127477645874

Epoch: 6| Step: 8
Training loss: 0.14028282463550568
Validation loss: 1.459066153213542

Epoch: 6| Step: 9
Training loss: 0.12898755073547363
Validation loss: 1.4657811413529098

Epoch: 6| Step: 10
Training loss: 0.09676265716552734
Validation loss: 1.511569716597116

Epoch: 6| Step: 11
Training loss: 0.09271453320980072
Validation loss: 1.517803302375219

Epoch: 6| Step: 12
Training loss: 0.10880283266305923
Validation loss: 1.491434701668319

Epoch: 6| Step: 13
Training loss: 0.04881393164396286
Validation loss: 1.5038037069382206

Epoch: 437| Step: 0
Training loss: 0.06917262077331543
Validation loss: 1.494133815970472

Epoch: 6| Step: 1
Training loss: 0.07920005917549133
Validation loss: 1.5019812148104432

Epoch: 6| Step: 2
Training loss: 0.039120063185691833
Validation loss: 1.4924604790185088

Epoch: 6| Step: 3
Training loss: 0.044443052262067795
Validation loss: 1.4879639667849387

Epoch: 6| Step: 4
Training loss: 0.11228806525468826
Validation loss: 1.4862098475938201

Epoch: 6| Step: 5
Training loss: 0.13876208662986755
Validation loss: 1.4884083412026847

Epoch: 6| Step: 6
Training loss: 0.08135756850242615
Validation loss: 1.4584617512200468

Epoch: 6| Step: 7
Training loss: 0.12836392223834991
Validation loss: 1.4639386118099253

Epoch: 6| Step: 8
Training loss: 0.09171426296234131
Validation loss: 1.4792584719196442

Epoch: 6| Step: 9
Training loss: 0.1469283401966095
Validation loss: 1.475764977034702

Epoch: 6| Step: 10
Training loss: 0.1703428328037262
Validation loss: 1.5040084546612156

Epoch: 6| Step: 11
Training loss: 0.06221964210271835
Validation loss: 1.5121434516804193

Epoch: 6| Step: 12
Training loss: 0.21342934668064117
Validation loss: 1.5121615368832824

Epoch: 6| Step: 13
Training loss: 0.07991482317447662
Validation loss: 1.4997070463754798

Epoch: 438| Step: 0
Training loss: 0.0935414656996727
Validation loss: 1.5408545309497463

Epoch: 6| Step: 1
Training loss: 0.05742409825325012
Validation loss: 1.528958474436114

Epoch: 6| Step: 2
Training loss: 0.10941366851329803
Validation loss: 1.4932119538707118

Epoch: 6| Step: 3
Training loss: 0.08797203004360199
Validation loss: 1.4948407591030162

Epoch: 6| Step: 4
Training loss: 0.090679831802845
Validation loss: 1.4629049442147697

Epoch: 6| Step: 5
Training loss: 0.07315205782651901
Validation loss: 1.4621246783964095

Epoch: 6| Step: 6
Training loss: 0.26541346311569214
Validation loss: 1.4463000412910216

Epoch: 6| Step: 7
Training loss: 0.20282162725925446
Validation loss: 1.4508108182619976

Epoch: 6| Step: 8
Training loss: 0.11626248061656952
Validation loss: 1.4658172694585656

Epoch: 6| Step: 9
Training loss: 0.11923140287399292
Validation loss: 1.477389850924092

Epoch: 6| Step: 10
Training loss: 0.12111818790435791
Validation loss: 1.4406389004440718

Epoch: 6| Step: 11
Training loss: 0.14068198204040527
Validation loss: 1.4409978684558664

Epoch: 6| Step: 12
Training loss: 0.13041631877422333
Validation loss: 1.4197503623142038

Epoch: 6| Step: 13
Training loss: 0.0994519367814064
Validation loss: 1.432574483656114

Epoch: 439| Step: 0
Training loss: 0.0749540627002716
Validation loss: 1.4577712871695077

Epoch: 6| Step: 1
Training loss: 0.12242184579372406
Validation loss: 1.4480901020829395

Epoch: 6| Step: 2
Training loss: 0.08506575226783752
Validation loss: 1.4342984678924724

Epoch: 6| Step: 3
Training loss: 0.12411436438560486
Validation loss: 1.4552070620239421

Epoch: 6| Step: 4
Training loss: 0.20279642939567566
Validation loss: 1.4638254770668604

Epoch: 6| Step: 5
Training loss: 0.10645095258951187
Validation loss: 1.440218178495284

Epoch: 6| Step: 6
Training loss: 0.08791960775852203
Validation loss: 1.4577151293395667

Epoch: 6| Step: 7
Training loss: 0.11350064724683762
Validation loss: 1.4545618436669792

Epoch: 6| Step: 8
Training loss: 0.11827120184898376
Validation loss: 1.4354110661373343

Epoch: 6| Step: 9
Training loss: 0.15211783349514008
Validation loss: 1.4425734166176087

Epoch: 6| Step: 10
Training loss: 0.14574380218982697
Validation loss: 1.4329739834672661

Epoch: 6| Step: 11
Training loss: 0.09924004226922989
Validation loss: 1.4617374975194213

Epoch: 6| Step: 12
Training loss: 0.10404637455940247
Validation loss: 1.4688678018508419

Epoch: 6| Step: 13
Training loss: 0.15475060045719147
Validation loss: 1.4873935759708445

Epoch: 440| Step: 0
Training loss: 0.20568601787090302
Validation loss: 1.4940839313691663

Epoch: 6| Step: 1
Training loss: 0.06299307942390442
Validation loss: 1.5040530158627419

Epoch: 6| Step: 2
Training loss: 0.08518017828464508
Validation loss: 1.477751907481942

Epoch: 6| Step: 3
Training loss: 0.12603574991226196
Validation loss: 1.4802440238255326

Epoch: 6| Step: 4
Training loss: 0.15003062784671783
Validation loss: 1.5112413757590837

Epoch: 6| Step: 5
Training loss: 0.09407948702573776
Validation loss: 1.511288692233383

Epoch: 6| Step: 6
Training loss: 0.09432274103164673
Validation loss: 1.512178413329586

Epoch: 6| Step: 7
Training loss: 0.096409872174263
Validation loss: 1.4933557254011913

Epoch: 6| Step: 8
Training loss: 0.10172459483146667
Validation loss: 1.4556762659421532

Epoch: 6| Step: 9
Training loss: 0.06970316171646118
Validation loss: 1.4484751102744893

Epoch: 6| Step: 10
Training loss: 0.06725792586803436
Validation loss: 1.4570819729117936

Epoch: 6| Step: 11
Training loss: 0.1717120110988617
Validation loss: 1.4397349203786542

Epoch: 6| Step: 12
Training loss: 0.09323158115148544
Validation loss: 1.4452118886414396

Epoch: 6| Step: 13
Training loss: 0.18745668232440948
Validation loss: 1.428525686264038

Epoch: 441| Step: 0
Training loss: 0.07062049955129623
Validation loss: 1.4166187009503763

Epoch: 6| Step: 1
Training loss: 0.12788917124271393
Validation loss: 1.4154548850110782

Epoch: 6| Step: 2
Training loss: 0.09696131944656372
Validation loss: 1.4241434553618073

Epoch: 6| Step: 3
Training loss: 0.22452399134635925
Validation loss: 1.4331736231362948

Epoch: 6| Step: 4
Training loss: 0.10526880621910095
Validation loss: 1.4375554348832817

Epoch: 6| Step: 5
Training loss: 0.05703155696392059
Validation loss: 1.4426520575759232

Epoch: 6| Step: 6
Training loss: 0.07776257395744324
Validation loss: 1.4669666380010626

Epoch: 6| Step: 7
Training loss: 0.1778590977191925
Validation loss: 1.4868352566995928

Epoch: 6| Step: 8
Training loss: 0.19805943965911865
Validation loss: 1.516521192366077

Epoch: 6| Step: 9
Training loss: 0.1192418709397316
Validation loss: 1.5151592480239047

Epoch: 6| Step: 10
Training loss: 0.07702477276325226
Validation loss: 1.528780864131066

Epoch: 6| Step: 11
Training loss: 0.11140698939561844
Validation loss: 1.5326527972375192

Epoch: 6| Step: 12
Training loss: 0.14783677458763123
Validation loss: 1.5542748230759815

Epoch: 6| Step: 13
Training loss: 0.11269407719373703
Validation loss: 1.510240743237157

Epoch: 442| Step: 0
Training loss: 0.23823300004005432
Validation loss: 1.4941510782446912

Epoch: 6| Step: 1
Training loss: 0.08622227609157562
Validation loss: 1.5071761172304872

Epoch: 6| Step: 2
Training loss: 0.12927661836147308
Validation loss: 1.4600076508778397

Epoch: 6| Step: 3
Training loss: 0.097310870885849
Validation loss: 1.4525242108170704

Epoch: 6| Step: 4
Training loss: 0.1011669859290123
Validation loss: 1.4221915929548201

Epoch: 6| Step: 5
Training loss: 0.08296425640583038
Validation loss: 1.4284785229672667

Epoch: 6| Step: 6
Training loss: 0.11176915466785431
Validation loss: 1.3981883141302294

Epoch: 6| Step: 7
Training loss: 0.09846574813127518
Validation loss: 1.3831420880492016

Epoch: 6| Step: 8
Training loss: 0.0889311134815216
Validation loss: 1.3849727094814341

Epoch: 6| Step: 9
Training loss: 0.0995999425649643
Validation loss: 1.363374339636936

Epoch: 6| Step: 10
Training loss: 0.1423424780368805
Validation loss: 1.3624580521737375

Epoch: 6| Step: 11
Training loss: 0.07531720399856567
Validation loss: 1.3458633038305468

Epoch: 6| Step: 12
Training loss: 0.18101386725902557
Validation loss: 1.3555211790146366

Epoch: 6| Step: 13
Training loss: 0.07443227618932724
Validation loss: 1.3630419046648088

Epoch: 443| Step: 0
Training loss: 0.14306044578552246
Validation loss: 1.3685619882358018

Epoch: 6| Step: 1
Training loss: 0.15826740860939026
Validation loss: 1.4003671292335755

Epoch: 6| Step: 2
Training loss: 0.12095039337873459
Validation loss: 1.4001778915364256

Epoch: 6| Step: 3
Training loss: 0.06503797322511673
Validation loss: 1.3942797421127238

Epoch: 6| Step: 4
Training loss: 0.06379979848861694
Validation loss: 1.4187424144437235

Epoch: 6| Step: 5
Training loss: 0.1721448302268982
Validation loss: 1.4288015365600586

Epoch: 6| Step: 6
Training loss: 0.07020054757595062
Validation loss: 1.427003252890802

Epoch: 6| Step: 7
Training loss: 0.12805722653865814
Validation loss: 1.413952987681153

Epoch: 6| Step: 8
Training loss: 0.09713733196258545
Validation loss: 1.4677424623120217

Epoch: 6| Step: 9
Training loss: 0.07538760453462601
Validation loss: 1.4699758714245212

Epoch: 6| Step: 10
Training loss: 0.08933378010988235
Validation loss: 1.4612099201448503

Epoch: 6| Step: 11
Training loss: 0.2550429701805115
Validation loss: 1.4628352631804764

Epoch: 6| Step: 12
Training loss: 0.05309135466814041
Validation loss: 1.479003789604351

Epoch: 6| Step: 13
Training loss: 0.10403899103403091
Validation loss: 1.510777505495215

Epoch: 444| Step: 0
Training loss: 0.11651978641748428
Validation loss: 1.4979816957186627

Epoch: 6| Step: 1
Training loss: 0.12192986905574799
Validation loss: 1.4852186223512054

Epoch: 6| Step: 2
Training loss: 0.1881544589996338
Validation loss: 1.4563270653447797

Epoch: 6| Step: 3
Training loss: 0.12065417319536209
Validation loss: 1.4753013772349204

Epoch: 6| Step: 4
Training loss: 0.09847313165664673
Validation loss: 1.4264260620199225

Epoch: 6| Step: 5
Training loss: 0.05507618561387062
Validation loss: 1.4423492147076515

Epoch: 6| Step: 6
Training loss: 0.05515990033745766
Validation loss: 1.4551837316123388

Epoch: 6| Step: 7
Training loss: 0.1300877034664154
Validation loss: 1.44269956568236

Epoch: 6| Step: 8
Training loss: 0.1086357831954956
Validation loss: 1.4545065497839322

Epoch: 6| Step: 9
Training loss: 0.0635952278971672
Validation loss: 1.445365612224866

Epoch: 6| Step: 10
Training loss: 0.06768326461315155
Validation loss: 1.4728604849948679

Epoch: 6| Step: 11
Training loss: 0.085548996925354
Validation loss: 1.4302839886757635

Epoch: 6| Step: 12
Training loss: 0.06482431292533875
Validation loss: 1.4385838611151582

Epoch: 6| Step: 13
Training loss: 0.08460269123315811
Validation loss: 1.4496010131733392

Epoch: 445| Step: 0
Training loss: 0.08062513917684555
Validation loss: 1.4213232660806308

Epoch: 6| Step: 1
Training loss: 0.10209335386753082
Validation loss: 1.407011019286289

Epoch: 6| Step: 2
Training loss: 0.05278608202934265
Validation loss: 1.3909285735058528

Epoch: 6| Step: 3
Training loss: 0.1791670173406601
Validation loss: 1.399089136431294

Epoch: 6| Step: 4
Training loss: 0.11430811136960983
Validation loss: 1.396043122455638

Epoch: 6| Step: 5
Training loss: 0.08217135816812515
Validation loss: 1.4222956498463948

Epoch: 6| Step: 6
Training loss: 0.1960146725177765
Validation loss: 1.419227989771033

Epoch: 6| Step: 7
Training loss: 0.09004009515047073
Validation loss: 1.4274025354334103

Epoch: 6| Step: 8
Training loss: 0.08564700186252594
Validation loss: 1.438725257432589

Epoch: 6| Step: 9
Training loss: 0.08537666499614716
Validation loss: 1.4325885375340779

Epoch: 6| Step: 10
Training loss: 0.08995532989501953
Validation loss: 1.4349958935091573

Epoch: 6| Step: 11
Training loss: 0.0696314126253128
Validation loss: 1.4359021853375178

Epoch: 6| Step: 12
Training loss: 0.13711443543434143
Validation loss: 1.456967467902809

Epoch: 6| Step: 13
Training loss: 0.04143451526761055
Validation loss: 1.4583018569536106

Epoch: 446| Step: 0
Training loss: 0.09069105982780457
Validation loss: 1.4581996548560359

Epoch: 6| Step: 1
Training loss: 0.07705756276845932
Validation loss: 1.44555143643451

Epoch: 6| Step: 2
Training loss: 0.12965607643127441
Validation loss: 1.4928150394911408

Epoch: 6| Step: 3
Training loss: 0.11589792370796204
Validation loss: 1.4708222971167615

Epoch: 6| Step: 4
Training loss: 0.10812695324420929
Validation loss: 1.4635719932535642

Epoch: 6| Step: 5
Training loss: 0.09509028494358063
Validation loss: 1.4256236412191903

Epoch: 6| Step: 6
Training loss: 0.07936932146549225
Validation loss: 1.4529601694435201

Epoch: 6| Step: 7
Training loss: 0.1125437468290329
Validation loss: 1.4163568750504525

Epoch: 6| Step: 8
Training loss: 0.08224798738956451
Validation loss: 1.4040378780775173

Epoch: 6| Step: 9
Training loss: 0.09221948683261871
Validation loss: 1.4257144466523202

Epoch: 6| Step: 10
Training loss: 0.18062454462051392
Validation loss: 1.4494339137948968

Epoch: 6| Step: 11
Training loss: 0.12459688633680344
Validation loss: 1.4542688605605916

Epoch: 6| Step: 12
Training loss: 0.10583163797855377
Validation loss: 1.4437125011156964

Epoch: 6| Step: 13
Training loss: 0.3350324034690857
Validation loss: 1.4506520584065428

Epoch: 447| Step: 0
Training loss: 0.10160674899816513
Validation loss: 1.4485053952022264

Epoch: 6| Step: 1
Training loss: 0.13407623767852783
Validation loss: 1.4685076667416481

Epoch: 6| Step: 2
Training loss: 0.09596423804759979
Validation loss: 1.4923986837428103

Epoch: 6| Step: 3
Training loss: 0.06789465248584747
Validation loss: 1.5221001217442174

Epoch: 6| Step: 4
Training loss: 0.1355002522468567
Validation loss: 1.528932527829242

Epoch: 6| Step: 5
Training loss: 0.08940620720386505
Validation loss: 1.5382656243539625

Epoch: 6| Step: 6
Training loss: 0.19878238439559937
Validation loss: 1.5372889503355949

Epoch: 6| Step: 7
Training loss: 0.08893522620201111
Validation loss: 1.5045933261994393

Epoch: 6| Step: 8
Training loss: 0.25067782402038574
Validation loss: 1.4841010673071748

Epoch: 6| Step: 9
Training loss: 0.0949636846780777
Validation loss: 1.465086365258822

Epoch: 6| Step: 10
Training loss: 0.11880119889974594
Validation loss: 1.4551200610335155

Epoch: 6| Step: 11
Training loss: 0.10891345888376236
Validation loss: 1.4397699256097116

Epoch: 6| Step: 12
Training loss: 0.07393313199281693
Validation loss: 1.4634761361665622

Epoch: 6| Step: 13
Training loss: 0.09076987951993942
Validation loss: 1.4328769958147438

Epoch: 448| Step: 0
Training loss: 0.09700896590948105
Validation loss: 1.4376405291659857

Epoch: 6| Step: 1
Training loss: 0.221894770860672
Validation loss: 1.4303788767066052

Epoch: 6| Step: 2
Training loss: 0.09867314994335175
Validation loss: 1.4099466031597507

Epoch: 6| Step: 3
Training loss: 0.11212774366140366
Validation loss: 1.43371719186024

Epoch: 6| Step: 4
Training loss: 0.06250236928462982
Validation loss: 1.444668254544658

Epoch: 6| Step: 5
Training loss: 0.1576484888792038
Validation loss: 1.4316869897227134

Epoch: 6| Step: 6
Training loss: 0.09466433525085449
Validation loss: 1.4292325653055662

Epoch: 6| Step: 7
Training loss: 0.1271861344575882
Validation loss: 1.4360274807099374

Epoch: 6| Step: 8
Training loss: 0.08733700215816498
Validation loss: 1.4635077509828793

Epoch: 6| Step: 9
Training loss: 0.12278751283884048
Validation loss: 1.4677998801713348

Epoch: 6| Step: 10
Training loss: 0.06926462799310684
Validation loss: 1.5177854978910057

Epoch: 6| Step: 11
Training loss: 0.14430320262908936
Validation loss: 1.5136812092155538

Epoch: 6| Step: 12
Training loss: 0.12921656668186188
Validation loss: 1.5387932767150223

Epoch: 6| Step: 13
Training loss: 0.181890070438385
Validation loss: 1.51419686630208

Epoch: 449| Step: 0
Training loss: 0.10120990872383118
Validation loss: 1.4951591055880311

Epoch: 6| Step: 1
Training loss: 0.0839691236615181
Validation loss: 1.483574551920737

Epoch: 6| Step: 2
Training loss: 0.1196649968624115
Validation loss: 1.4608047341787687

Epoch: 6| Step: 3
Training loss: 0.04162580519914627
Validation loss: 1.4492574507190334

Epoch: 6| Step: 4
Training loss: 0.07523494213819504
Validation loss: 1.4206558517230454

Epoch: 6| Step: 5
Training loss: 0.12581101059913635
Validation loss: 1.425854516285722

Epoch: 6| Step: 6
Training loss: 0.1859484314918518
Validation loss: 1.3872042176544026

Epoch: 6| Step: 7
Training loss: 0.06986461579799652
Validation loss: 1.4042171983308689

Epoch: 6| Step: 8
Training loss: 0.10700143128633499
Validation loss: 1.3890758829732095

Epoch: 6| Step: 9
Training loss: 0.1101677417755127
Validation loss: 1.4082943521520144

Epoch: 6| Step: 10
Training loss: 0.08219756186008453
Validation loss: 1.3982142492007184

Epoch: 6| Step: 11
Training loss: 0.14493323862552643
Validation loss: 1.4246186133353942

Epoch: 6| Step: 12
Training loss: 0.11337974667549133
Validation loss: 1.446449299012461

Epoch: 6| Step: 13
Training loss: 0.03317872807383537
Validation loss: 1.4377789933194396

Epoch: 450| Step: 0
Training loss: 0.1348673701286316
Validation loss: 1.4835972734676894

Epoch: 6| Step: 1
Training loss: 0.09941849857568741
Validation loss: 1.4923506039445118

Epoch: 6| Step: 2
Training loss: 0.11074890941381454
Validation loss: 1.5382025164942588

Epoch: 6| Step: 3
Training loss: 0.09237208962440491
Validation loss: 1.5234083321786696

Epoch: 6| Step: 4
Training loss: 0.16645416617393494
Validation loss: 1.5411334845327562

Epoch: 6| Step: 5
Training loss: 0.11941926181316376
Validation loss: 1.5043792686154764

Epoch: 6| Step: 6
Training loss: 0.15860044956207275
Validation loss: 1.4833342259930027

Epoch: 6| Step: 7
Training loss: 0.07174715399742126
Validation loss: 1.4762050490225516

Epoch: 6| Step: 8
Training loss: 0.2143871784210205
Validation loss: 1.456421640611464

Epoch: 6| Step: 9
Training loss: 0.16586950421333313
Validation loss: 1.4263533039759564

Epoch: 6| Step: 10
Training loss: 0.09680382907390594
Validation loss: 1.4241497055176766

Epoch: 6| Step: 11
Training loss: 0.14916636049747467
Validation loss: 1.4185927209033762

Epoch: 6| Step: 12
Training loss: 0.0989939346909523
Validation loss: 1.3732546183370775

Epoch: 6| Step: 13
Training loss: 0.2368415743112564
Validation loss: 1.3850928506543558

Epoch: 451| Step: 0
Training loss: 0.09747743606567383
Validation loss: 1.3757374222560594

Epoch: 6| Step: 1
Training loss: 0.0803745687007904
Validation loss: 1.3900266449938539

Epoch: 6| Step: 2
Training loss: 0.20874683558940887
Validation loss: 1.409677278610968

Epoch: 6| Step: 3
Training loss: 0.11898916214704514
Validation loss: 1.417618627189308

Epoch: 6| Step: 4
Training loss: 0.14070916175842285
Validation loss: 1.4273710943037463

Epoch: 6| Step: 5
Training loss: 0.08696082979440689
Validation loss: 1.439783662237147

Epoch: 6| Step: 6
Training loss: 0.10204638540744781
Validation loss: 1.427640982853469

Epoch: 6| Step: 7
Training loss: 0.11965514719486237
Validation loss: 1.4616009099509126

Epoch: 6| Step: 8
Training loss: 0.10758639127016068
Validation loss: 1.449774048661673

Epoch: 6| Step: 9
Training loss: 0.08646390587091446
Validation loss: 1.4432068486367502

Epoch: 6| Step: 10
Training loss: 0.1578388661146164
Validation loss: 1.4377835783907162

Epoch: 6| Step: 11
Training loss: 0.11775133013725281
Validation loss: 1.4422884346336446

Epoch: 6| Step: 12
Training loss: 0.07207204401493073
Validation loss: 1.4480545828419347

Epoch: 6| Step: 13
Training loss: 0.08611053228378296
Validation loss: 1.4351311281163206

Epoch: 452| Step: 0
Training loss: 0.19325974583625793
Validation loss: 1.4896149161041423

Epoch: 6| Step: 1
Training loss: 0.12076170742511749
Validation loss: 1.4903717438379924

Epoch: 6| Step: 2
Training loss: 0.1426144689321518
Validation loss: 1.4805384015524259

Epoch: 6| Step: 3
Training loss: 0.13000249862670898
Validation loss: 1.5065665911602717

Epoch: 6| Step: 4
Training loss: 0.08902829885482788
Validation loss: 1.5220209898487214

Epoch: 6| Step: 5
Training loss: 0.07707031071186066
Validation loss: 1.5022932419212915

Epoch: 6| Step: 6
Training loss: 0.13247311115264893
Validation loss: 1.4872968639096906

Epoch: 6| Step: 7
Training loss: 0.10135692358016968
Validation loss: 1.4682055442563948

Epoch: 6| Step: 8
Training loss: 0.10607051849365234
Validation loss: 1.468211926439757

Epoch: 6| Step: 9
Training loss: 0.12309915572404861
Validation loss: 1.4418475256171277

Epoch: 6| Step: 10
Training loss: 0.0816405788064003
Validation loss: 1.4535825829352103

Epoch: 6| Step: 11
Training loss: 0.08571450412273407
Validation loss: 1.429476866158106

Epoch: 6| Step: 12
Training loss: 0.034360505640506744
Validation loss: 1.4008095789981145

Epoch: 6| Step: 13
Training loss: 0.09037693589925766
Validation loss: 1.4278368347434587

Epoch: 453| Step: 0
Training loss: 0.07437990605831146
Validation loss: 1.4401579210835118

Epoch: 6| Step: 1
Training loss: 0.08962664008140564
Validation loss: 1.4055017296985914

Epoch: 6| Step: 2
Training loss: 0.0758851021528244
Validation loss: 1.39209327261935

Epoch: 6| Step: 3
Training loss: 0.07621397823095322
Validation loss: 1.3657140988175587

Epoch: 6| Step: 4
Training loss: 0.07567460089921951
Validation loss: 1.4104185495325314

Epoch: 6| Step: 5
Training loss: 0.14450538158416748
Validation loss: 1.3807467260668356

Epoch: 6| Step: 6
Training loss: 0.10337452590465546
Validation loss: 1.3635071298127532

Epoch: 6| Step: 7
Training loss: 0.07284596562385559
Validation loss: 1.3725932951896422

Epoch: 6| Step: 8
Training loss: 0.06371431052684784
Validation loss: 1.3916940663450508

Epoch: 6| Step: 9
Training loss: 0.18339265882968903
Validation loss: 1.4094342813696912

Epoch: 6| Step: 10
Training loss: 0.09828577190637589
Validation loss: 1.4264807002518767

Epoch: 6| Step: 11
Training loss: 0.1212875097990036
Validation loss: 1.4517418799861785

Epoch: 6| Step: 12
Training loss: 0.10020899027585983
Validation loss: 1.4592329097050492

Epoch: 6| Step: 13
Training loss: 0.06672525405883789
Validation loss: 1.4671805430484075

Epoch: 454| Step: 0
Training loss: 0.07523416727781296
Validation loss: 1.481774721094357

Epoch: 6| Step: 1
Training loss: 0.04360952228307724
Validation loss: 1.4842348778119652

Epoch: 6| Step: 2
Training loss: 0.14096125960350037
Validation loss: 1.5172465091110559

Epoch: 6| Step: 3
Training loss: 0.07495570182800293
Validation loss: 1.5070560260485577

Epoch: 6| Step: 4
Training loss: 0.05768132582306862
Validation loss: 1.4964232560127013

Epoch: 6| Step: 5
Training loss: 0.06237222999334335
Validation loss: 1.5068388074956915

Epoch: 6| Step: 6
Training loss: 0.09128639101982117
Validation loss: 1.5042469027221843

Epoch: 6| Step: 7
Training loss: 0.13367167115211487
Validation loss: 1.4769615011830484

Epoch: 6| Step: 8
Training loss: 0.170206218957901
Validation loss: 1.4628171119638669

Epoch: 6| Step: 9
Training loss: 0.2563815712928772
Validation loss: 1.4403579209440498

Epoch: 6| Step: 10
Training loss: 0.10039675980806351
Validation loss: 1.4558224825448887

Epoch: 6| Step: 11
Training loss: 0.14010149240493774
Validation loss: 1.4353822905530211

Epoch: 6| Step: 12
Training loss: 0.06626386940479279
Validation loss: 1.4598604350961664

Epoch: 6| Step: 13
Training loss: 0.07389005273580551
Validation loss: 1.450059506200975

Epoch: 455| Step: 0
Training loss: 0.21074458956718445
Validation loss: 1.4318619569142659

Epoch: 6| Step: 1
Training loss: 0.1287941336631775
Validation loss: 1.4397161301746164

Epoch: 6| Step: 2
Training loss: 0.1267804503440857
Validation loss: 1.4646363168634393

Epoch: 6| Step: 3
Training loss: 0.1515556275844574
Validation loss: 1.4755067030588787

Epoch: 6| Step: 4
Training loss: 0.03903822973370552
Validation loss: 1.4371251290844334

Epoch: 6| Step: 5
Training loss: 0.09997904300689697
Validation loss: 1.4507474412200272

Epoch: 6| Step: 6
Training loss: 0.11478863656520844
Validation loss: 1.4256944207734958

Epoch: 6| Step: 7
Training loss: 0.06963196396827698
Validation loss: 1.4489889849898636

Epoch: 6| Step: 8
Training loss: 0.062275826930999756
Validation loss: 1.4058513487538984

Epoch: 6| Step: 9
Training loss: 0.06437879800796509
Validation loss: 1.3973041913842643

Epoch: 6| Step: 10
Training loss: 0.10661184787750244
Validation loss: 1.3931741855477775

Epoch: 6| Step: 11
Training loss: 0.11819286644458771
Validation loss: 1.3550825401019024

Epoch: 6| Step: 12
Training loss: 0.07712019979953766
Validation loss: 1.3808697256990659

Epoch: 6| Step: 13
Training loss: 0.08889111131429672
Validation loss: 1.3709701331712867

Epoch: 456| Step: 0
Training loss: 0.11865059286355972
Validation loss: 1.393936284126774

Epoch: 6| Step: 1
Training loss: 0.07154859602451324
Validation loss: 1.3739882246140511

Epoch: 6| Step: 2
Training loss: 0.05928695946931839
Validation loss: 1.371486436295253

Epoch: 6| Step: 3
Training loss: 0.05550740286707878
Validation loss: 1.4214082994768698

Epoch: 6| Step: 4
Training loss: 0.06703570485115051
Validation loss: 1.4407593793766473

Epoch: 6| Step: 5
Training loss: 0.10492616891860962
Validation loss: 1.4640658465764855

Epoch: 6| Step: 6
Training loss: 0.07086405158042908
Validation loss: 1.465692945705947

Epoch: 6| Step: 7
Training loss: 0.1776326447725296
Validation loss: 1.4849054839021416

Epoch: 6| Step: 8
Training loss: 0.1338704526424408
Validation loss: 1.5180509064787178

Epoch: 6| Step: 9
Training loss: 0.07919986546039581
Validation loss: 1.544088916112018

Epoch: 6| Step: 10
Training loss: 0.07823766767978668
Validation loss: 1.5663612068340342

Epoch: 6| Step: 11
Training loss: 0.12726706266403198
Validation loss: 1.5819216030900196

Epoch: 6| Step: 12
Training loss: 0.10539987683296204
Validation loss: 1.5681551233414681

Epoch: 6| Step: 13
Training loss: 0.11090072989463806
Validation loss: 1.5610067934118292

Epoch: 457| Step: 0
Training loss: 0.08525410294532776
Validation loss: 1.5264975781081824

Epoch: 6| Step: 1
Training loss: 0.0964183658361435
Validation loss: 1.5279614284474363

Epoch: 6| Step: 2
Training loss: 0.07108157873153687
Validation loss: 1.496782624593345

Epoch: 6| Step: 3
Training loss: 0.1373501420021057
Validation loss: 1.459084754349083

Epoch: 6| Step: 4
Training loss: 0.1994185447692871
Validation loss: 1.4289495829612977

Epoch: 6| Step: 5
Training loss: 0.0797857716679573
Validation loss: 1.4456671822455622

Epoch: 6| Step: 6
Training loss: 0.06570450961589813
Validation loss: 1.4238563106265119

Epoch: 6| Step: 7
Training loss: 0.06810703873634338
Validation loss: 1.4652449738594793

Epoch: 6| Step: 8
Training loss: 0.09527789056301117
Validation loss: 1.4409329019567019

Epoch: 6| Step: 9
Training loss: 0.09348515421152115
Validation loss: 1.4322825977879186

Epoch: 6| Step: 10
Training loss: 0.10726872086524963
Validation loss: 1.4305875557725147

Epoch: 6| Step: 11
Training loss: 0.05467145889997482
Validation loss: 1.4641260793132167

Epoch: 6| Step: 12
Training loss: 0.07560239732265472
Validation loss: 1.4596366696460272

Epoch: 6| Step: 13
Training loss: 0.0651881992816925
Validation loss: 1.4467434716481034

Epoch: 458| Step: 0
Training loss: 0.048577554523944855
Validation loss: 1.4591223623162957

Epoch: 6| Step: 1
Training loss: 0.05805836617946625
Validation loss: 1.4405425530607983

Epoch: 6| Step: 2
Training loss: 0.07600574195384979
Validation loss: 1.442422737357437

Epoch: 6| Step: 3
Training loss: 0.06227697432041168
Validation loss: 1.4293713056912987

Epoch: 6| Step: 4
Training loss: 0.08644036948680878
Validation loss: 1.4353469456395795

Epoch: 6| Step: 5
Training loss: 0.14353683590888977
Validation loss: 1.4551062148104432

Epoch: 6| Step: 6
Training loss: 0.07760068774223328
Validation loss: 1.47483104531483

Epoch: 6| Step: 7
Training loss: 0.07677590847015381
Validation loss: 1.4585405434331586

Epoch: 6| Step: 8
Training loss: 0.21980996429920197
Validation loss: 1.4701425606204617

Epoch: 6| Step: 9
Training loss: 0.09230463951826096
Validation loss: 1.4958199704847028

Epoch: 6| Step: 10
Training loss: 0.0767010897397995
Validation loss: 1.5014119058526971

Epoch: 6| Step: 11
Training loss: 0.09778426587581635
Validation loss: 1.5373210881346016

Epoch: 6| Step: 12
Training loss: 0.1229696124792099
Validation loss: 1.552142067622113

Epoch: 6| Step: 13
Training loss: 0.08994384855031967
Validation loss: 1.5259436099759993

Epoch: 459| Step: 0
Training loss: 0.058015886694192886
Validation loss: 1.5187983512878418

Epoch: 6| Step: 1
Training loss: 0.07908738404512405
Validation loss: 1.5070740330603816

Epoch: 6| Step: 2
Training loss: 0.06774157285690308
Validation loss: 1.500485566354567

Epoch: 6| Step: 3
Training loss: 0.06488536298274994
Validation loss: 1.5049880909663376

Epoch: 6| Step: 4
Training loss: 0.07171904295682907
Validation loss: 1.4856830758433188

Epoch: 6| Step: 5
Training loss: 0.05830135941505432
Validation loss: 1.449710831847242

Epoch: 6| Step: 6
Training loss: 0.24199709296226501
Validation loss: 1.4301005371155278

Epoch: 6| Step: 7
Training loss: 0.08897215873003006
Validation loss: 1.4540870202484952

Epoch: 6| Step: 8
Training loss: 0.07473896443843842
Validation loss: 1.419886286540698

Epoch: 6| Step: 9
Training loss: 0.06004670634865761
Validation loss: 1.4227046159005934

Epoch: 6| Step: 10
Training loss: 0.06115350127220154
Validation loss: 1.4534561236699421

Epoch: 6| Step: 11
Training loss: 0.18205462396144867
Validation loss: 1.4653324786052908

Epoch: 6| Step: 12
Training loss: 0.05260509252548218
Validation loss: 1.4481741382229714

Epoch: 6| Step: 13
Training loss: 0.06422916054725647
Validation loss: 1.477785042537156

Epoch: 460| Step: 0
Training loss: 0.07671212404966354
Validation loss: 1.4870478530083933

Epoch: 6| Step: 1
Training loss: 0.07846257090568542
Validation loss: 1.494099909259427

Epoch: 6| Step: 2
Training loss: 0.22002196311950684
Validation loss: 1.50004481884741

Epoch: 6| Step: 3
Training loss: 0.08315247297286987
Validation loss: 1.4884148445180667

Epoch: 6| Step: 4
Training loss: 0.06662458926439285
Validation loss: 1.4561676902155722

Epoch: 6| Step: 5
Training loss: 0.08893248438835144
Validation loss: 1.4642484623898742

Epoch: 6| Step: 6
Training loss: 0.09332240372896194
Validation loss: 1.4745493409454182

Epoch: 6| Step: 7
Training loss: 0.08793646842241287
Validation loss: 1.4660130239302112

Epoch: 6| Step: 8
Training loss: 0.08437523990869522
Validation loss: 1.4707316352475075

Epoch: 6| Step: 9
Training loss: 0.06956751644611359
Validation loss: 1.4612709937557098

Epoch: 6| Step: 10
Training loss: 0.07361236959695816
Validation loss: 1.495031698416638

Epoch: 6| Step: 11
Training loss: 0.155164897441864
Validation loss: 1.490468370017185

Epoch: 6| Step: 12
Training loss: 0.10986527055501938
Validation loss: 1.4801468862000333

Epoch: 6| Step: 13
Training loss: 0.08996549993753433
Validation loss: 1.4834717294221282

Epoch: 461| Step: 0
Training loss: 0.0783868134021759
Validation loss: 1.4682796168070968

Epoch: 6| Step: 1
Training loss: 0.07086487859487534
Validation loss: 1.4587187677301385

Epoch: 6| Step: 2
Training loss: 0.04885848984122276
Validation loss: 1.4554108342816752

Epoch: 6| Step: 3
Training loss: 0.12294991314411163
Validation loss: 1.4727206281436387

Epoch: 6| Step: 4
Training loss: 0.10204345732927322
Validation loss: 1.4627054711823821

Epoch: 6| Step: 5
Training loss: 0.1893645077943802
Validation loss: 1.468030680892288

Epoch: 6| Step: 6
Training loss: 0.08239950984716415
Validation loss: 1.457117401143556

Epoch: 6| Step: 7
Training loss: 0.08536458015441895
Validation loss: 1.4837038491361885

Epoch: 6| Step: 8
Training loss: 0.05341491103172302
Validation loss: 1.4503692632080407

Epoch: 6| Step: 9
Training loss: 0.07977300137281418
Validation loss: 1.467725585865718

Epoch: 6| Step: 10
Training loss: 0.11354105174541473
Validation loss: 1.4616538119572464

Epoch: 6| Step: 11
Training loss: 0.09175802767276764
Validation loss: 1.4321465056429628

Epoch: 6| Step: 12
Training loss: 0.11427026987075806
Validation loss: 1.4331297464268182

Epoch: 6| Step: 13
Training loss: 0.12939588725566864
Validation loss: 1.4244544018981278

Epoch: 462| Step: 0
Training loss: 0.07304064184427261
Validation loss: 1.4351711093738515

Epoch: 6| Step: 1
Training loss: 0.10947461426258087
Validation loss: 1.4156726688467047

Epoch: 6| Step: 2
Training loss: 0.08614121377468109
Validation loss: 1.4167510629982076

Epoch: 6| Step: 3
Training loss: 0.10545557737350464
Validation loss: 1.4504578536556614

Epoch: 6| Step: 4
Training loss: 0.058021776378154755
Validation loss: 1.4251959849429388

Epoch: 6| Step: 5
Training loss: 0.07471279799938202
Validation loss: 1.4414360484769266

Epoch: 6| Step: 6
Training loss: 0.0886492058634758
Validation loss: 1.441976458795609

Epoch: 6| Step: 7
Training loss: 0.14714576303958893
Validation loss: 1.4491793314615886

Epoch: 6| Step: 8
Training loss: 0.10551640391349792
Validation loss: 1.4614309739041071

Epoch: 6| Step: 9
Training loss: 0.19499161839485168
Validation loss: 1.4646682726439608

Epoch: 6| Step: 10
Training loss: 0.09898114204406738
Validation loss: 1.4675666209190124

Epoch: 6| Step: 11
Training loss: 0.07158315181732178
Validation loss: 1.4858441147752988

Epoch: 6| Step: 12
Training loss: 0.07559292763471603
Validation loss: 1.4631056913765528

Epoch: 6| Step: 13
Training loss: 0.10206936299800873
Validation loss: 1.4947001421323387

Epoch: 463| Step: 0
Training loss: 0.05971632897853851
Validation loss: 1.4758103932103803

Epoch: 6| Step: 1
Training loss: 0.08572623133659363
Validation loss: 1.4773934714255794

Epoch: 6| Step: 2
Training loss: 0.05514031648635864
Validation loss: 1.4561991999226231

Epoch: 6| Step: 3
Training loss: 0.06514190882444382
Validation loss: 1.4635138178384433

Epoch: 6| Step: 4
Training loss: 0.0737745389342308
Validation loss: 1.495580155362365

Epoch: 6| Step: 5
Training loss: 0.10116510093212128
Validation loss: 1.4445454356490925

Epoch: 6| Step: 6
Training loss: 0.12373975664377213
Validation loss: 1.444679835791229

Epoch: 6| Step: 7
Training loss: 0.09176480770111084
Validation loss: 1.4523320210877286

Epoch: 6| Step: 8
Training loss: 0.21984750032424927
Validation loss: 1.4506584713535924

Epoch: 6| Step: 9
Training loss: 0.09798868000507355
Validation loss: 1.449255637584194

Epoch: 6| Step: 10
Training loss: 0.10869840532541275
Validation loss: 1.4863176704734884

Epoch: 6| Step: 11
Training loss: 0.13577552139759064
Validation loss: 1.4899943028726885

Epoch: 6| Step: 12
Training loss: 0.121819868683815
Validation loss: 1.4973782300949097

Epoch: 6| Step: 13
Training loss: 0.17031055688858032
Validation loss: 1.4909649561810236

Epoch: 464| Step: 0
Training loss: 0.09796513617038727
Validation loss: 1.4696690965724248

Epoch: 6| Step: 1
Training loss: 0.1154702827334404
Validation loss: 1.497445853807593

Epoch: 6| Step: 2
Training loss: 0.07206924259662628
Validation loss: 1.4728219573215773

Epoch: 6| Step: 3
Training loss: 0.0996733158826828
Validation loss: 1.4797488797095515

Epoch: 6| Step: 4
Training loss: 0.08886376768350601
Validation loss: 1.4586104757042342

Epoch: 6| Step: 5
Training loss: 0.09178407490253448
Validation loss: 1.4365522143661336

Epoch: 6| Step: 6
Training loss: 0.11924290657043457
Validation loss: 1.4726941354813115

Epoch: 6| Step: 7
Training loss: 0.08611476421356201
Validation loss: 1.447239770684191

Epoch: 6| Step: 8
Training loss: 0.20590923726558685
Validation loss: 1.4499840069842596

Epoch: 6| Step: 9
Training loss: 0.11763925850391388
Validation loss: 1.4618684091875631

Epoch: 6| Step: 10
Training loss: 0.14207294583320618
Validation loss: 1.4870331364293252

Epoch: 6| Step: 11
Training loss: 0.0829281136393547
Validation loss: 1.4607918711118801

Epoch: 6| Step: 12
Training loss: 0.17587178945541382
Validation loss: 1.467874034758537

Epoch: 6| Step: 13
Training loss: 0.08966495096683502
Validation loss: 1.4549606282223937

Epoch: 465| Step: 0
Training loss: 0.14917632937431335
Validation loss: 1.4635052014422674

Epoch: 6| Step: 1
Training loss: 0.12110403180122375
Validation loss: 1.4421949117414412

Epoch: 6| Step: 2
Training loss: 0.12256839126348495
Validation loss: 1.4503099021091257

Epoch: 6| Step: 3
Training loss: 0.19118216633796692
Validation loss: 1.3920204639434814

Epoch: 6| Step: 4
Training loss: 0.09091603010892868
Validation loss: 1.38688951153909

Epoch: 6| Step: 5
Training loss: 0.08581946790218353
Validation loss: 1.3976680847906298

Epoch: 6| Step: 6
Training loss: 0.09113477170467377
Validation loss: 1.3745512475249588

Epoch: 6| Step: 7
Training loss: 0.09571385383605957
Validation loss: 1.3837934309436428

Epoch: 6| Step: 8
Training loss: 0.0907101258635521
Validation loss: 1.3612420148746942

Epoch: 6| Step: 9
Training loss: 0.13189375400543213
Validation loss: 1.408662308928787

Epoch: 6| Step: 10
Training loss: 0.15949852764606476
Validation loss: 1.4106057023489347

Epoch: 6| Step: 11
Training loss: 0.11057206988334656
Validation loss: 1.3982922530943347

Epoch: 6| Step: 12
Training loss: 0.09810771048069
Validation loss: 1.3931530919126285

Epoch: 6| Step: 13
Training loss: 0.16771356761455536
Validation loss: 1.4046114593423822

Epoch: 466| Step: 0
Training loss: 0.08869725465774536
Validation loss: 1.403485716030162

Epoch: 6| Step: 1
Training loss: 0.08189861476421356
Validation loss: 1.4381450376202982

Epoch: 6| Step: 2
Training loss: 0.14763805270195007
Validation loss: 1.4209373394648235

Epoch: 6| Step: 3
Training loss: 0.11951582133769989
Validation loss: 1.4340131616079679

Epoch: 6| Step: 4
Training loss: 0.05366528034210205
Validation loss: 1.4392240944729056

Epoch: 6| Step: 5
Training loss: 0.218155175447464
Validation loss: 1.4589664705338017

Epoch: 6| Step: 6
Training loss: 0.13141992688179016
Validation loss: 1.46560590241545

Epoch: 6| Step: 7
Training loss: 0.09818542003631592
Validation loss: 1.4668591073764268

Epoch: 6| Step: 8
Training loss: 0.08817841112613678
Validation loss: 1.5087690686666837

Epoch: 6| Step: 9
Training loss: 0.12905403971672058
Validation loss: 1.480013177599958

Epoch: 6| Step: 10
Training loss: 0.08313476294279099
Validation loss: 1.4801169313410276

Epoch: 6| Step: 11
Training loss: 0.17225529253482819
Validation loss: 1.4624622303952453

Epoch: 6| Step: 12
Training loss: 0.06644512712955475
Validation loss: 1.4627311088705575

Epoch: 6| Step: 13
Training loss: 0.10870885103940964
Validation loss: 1.4471937725620885

Epoch: 467| Step: 0
Training loss: 0.10812760889530182
Validation loss: 1.4351017449491767

Epoch: 6| Step: 1
Training loss: 0.05479627847671509
Validation loss: 1.4271432750968522

Epoch: 6| Step: 2
Training loss: 0.07101042568683624
Validation loss: 1.4310126150808027

Epoch: 6| Step: 3
Training loss: 0.09970787167549133
Validation loss: 1.442045771947471

Epoch: 6| Step: 4
Training loss: 0.09233012050390244
Validation loss: 1.418409461616188

Epoch: 6| Step: 5
Training loss: 0.21002446115016937
Validation loss: 1.4088099393793332

Epoch: 6| Step: 6
Training loss: 0.0840596854686737
Validation loss: 1.4116832120444185

Epoch: 6| Step: 7
Training loss: 0.0754043310880661
Validation loss: 1.423744551597103

Epoch: 6| Step: 8
Training loss: 0.09043391048908234
Validation loss: 1.3858441973245272

Epoch: 6| Step: 9
Training loss: 0.10944972932338715
Validation loss: 1.3790472169076242

Epoch: 6| Step: 10
Training loss: 0.0633268877863884
Validation loss: 1.397410072306151

Epoch: 6| Step: 11
Training loss: 0.09445146471261978
Validation loss: 1.3778110800250885

Epoch: 6| Step: 12
Training loss: 0.1046627089381218
Validation loss: 1.3701928116941964

Epoch: 6| Step: 13
Training loss: 0.09090161323547363
Validation loss: 1.3299502070232103

Epoch: 468| Step: 0
Training loss: 0.11786939203739166
Validation loss: 1.3593979266382032

Epoch: 6| Step: 1
Training loss: 0.10023775696754456
Validation loss: 1.3634740729485788

Epoch: 6| Step: 2
Training loss: 0.1360710710287094
Validation loss: 1.350877486249452

Epoch: 6| Step: 3
Training loss: 0.08323347568511963
Validation loss: 1.3659868676175353

Epoch: 6| Step: 4
Training loss: 0.26218289136886597
Validation loss: 1.381557459472328

Epoch: 6| Step: 5
Training loss: 0.13757947087287903
Validation loss: 1.3944064353101997

Epoch: 6| Step: 6
Training loss: 0.10179506242275238
Validation loss: 1.4065043234056043

Epoch: 6| Step: 7
Training loss: 0.09425094723701477
Validation loss: 1.432196622253746

Epoch: 6| Step: 8
Training loss: 0.08860086649656296
Validation loss: 1.4473312939366987

Epoch: 6| Step: 9
Training loss: 0.0960477739572525
Validation loss: 1.4674432328952256

Epoch: 6| Step: 10
Training loss: 0.09840381145477295
Validation loss: 1.5216981428925709

Epoch: 6| Step: 11
Training loss: 0.14087948203086853
Validation loss: 1.538030239843553

Epoch: 6| Step: 12
Training loss: 0.09152169525623322
Validation loss: 1.49921392561287

Epoch: 6| Step: 13
Training loss: 0.13057269155979156
Validation loss: 1.477046670452241

Epoch: 469| Step: 0
Training loss: 0.11493642628192902
Validation loss: 1.4846985570846065

Epoch: 6| Step: 1
Training loss: 0.08928464353084564
Validation loss: 1.4900077760860484

Epoch: 6| Step: 2
Training loss: 0.09997047483921051
Validation loss: 1.5035099752487675

Epoch: 6| Step: 3
Training loss: 0.15285082161426544
Validation loss: 1.476321562643974

Epoch: 6| Step: 4
Training loss: 0.13572031259536743
Validation loss: 1.4482798595582285

Epoch: 6| Step: 5
Training loss: 0.25225234031677246
Validation loss: 1.41905382884446

Epoch: 6| Step: 6
Training loss: 0.1127963662147522
Validation loss: 1.4299712924547092

Epoch: 6| Step: 7
Training loss: 0.09486015141010284
Validation loss: 1.4038893817573466

Epoch: 6| Step: 8
Training loss: 0.12126193940639496
Validation loss: 1.3710728800424965

Epoch: 6| Step: 9
Training loss: 0.1123228669166565
Validation loss: 1.3334912074509488

Epoch: 6| Step: 10
Training loss: 0.08971904218196869
Validation loss: 1.316050107761096

Epoch: 6| Step: 11
Training loss: 0.15451115369796753
Validation loss: 1.3181062898328226

Epoch: 6| Step: 12
Training loss: 0.11127369850873947
Validation loss: 1.3238586430908532

Epoch: 6| Step: 13
Training loss: 0.2280673384666443
Validation loss: 1.4008889557212911

Epoch: 470| Step: 0
Training loss: 0.11655910313129425
Validation loss: 1.394949165723657

Epoch: 6| Step: 1
Training loss: 0.09537756443023682
Validation loss: 1.3994734806399192

Epoch: 6| Step: 2
Training loss: 0.08021311461925507
Validation loss: 1.4017832817569855

Epoch: 6| Step: 3
Training loss: 0.09961605817079544
Validation loss: 1.4145968870450092

Epoch: 6| Step: 4
Training loss: 0.14714184403419495
Validation loss: 1.4127321820105276

Epoch: 6| Step: 5
Training loss: 0.08687672019004822
Validation loss: 1.4013191006516899

Epoch: 6| Step: 6
Training loss: 0.14197297394275665
Validation loss: 1.4202384769275624

Epoch: 6| Step: 7
Training loss: 0.214523583650589
Validation loss: 1.422961211973621

Epoch: 6| Step: 8
Training loss: 0.0666906014084816
Validation loss: 1.4220087976865872

Epoch: 6| Step: 9
Training loss: 0.1360570192337036
Validation loss: 1.4450822478981429

Epoch: 6| Step: 10
Training loss: 0.06963163614273071
Validation loss: 1.4863823434358001

Epoch: 6| Step: 11
Training loss: 0.08774849027395248
Validation loss: 1.4981931537710211

Epoch: 6| Step: 12
Training loss: 0.06682857871055603
Validation loss: 1.5016705131018033

Epoch: 6| Step: 13
Training loss: 0.04716597497463226
Validation loss: 1.4880909240374

Epoch: 471| Step: 0
Training loss: 0.11869080364704132
Validation loss: 1.4978361129760742

Epoch: 6| Step: 1
Training loss: 0.09775634109973907
Validation loss: 1.5016560484004278

Epoch: 6| Step: 2
Training loss: 0.09543394297361374
Validation loss: 1.4946474298354118

Epoch: 6| Step: 3
Training loss: 0.22256049513816833
Validation loss: 1.5265477626554427

Epoch: 6| Step: 4
Training loss: 0.10842686891555786
Validation loss: 1.4644128994275165

Epoch: 6| Step: 5
Training loss: 0.06962744891643524
Validation loss: 1.4953574506185388

Epoch: 6| Step: 6
Training loss: 0.08682193607091904
Validation loss: 1.4649491451119865

Epoch: 6| Step: 7
Training loss: 0.05367244780063629
Validation loss: 1.428227642531036

Epoch: 6| Step: 8
Training loss: 0.09899581968784332
Validation loss: 1.4387106574991697

Epoch: 6| Step: 9
Training loss: 0.06450459361076355
Validation loss: 1.4276675742159608

Epoch: 6| Step: 10
Training loss: 0.10577063262462616
Validation loss: 1.4100757478385844

Epoch: 6| Step: 11
Training loss: 0.11464935541152954
Validation loss: 1.41794506965145

Epoch: 6| Step: 12
Training loss: 0.13934066891670227
Validation loss: 1.4242139971384438

Epoch: 6| Step: 13
Training loss: 0.07545774430036545
Validation loss: 1.399901557353235

Epoch: 472| Step: 0
Training loss: 0.07496482133865356
Validation loss: 1.4225794076919556

Epoch: 6| Step: 1
Training loss: 0.07970735430717468
Validation loss: 1.4239637826078682

Epoch: 6| Step: 2
Training loss: 0.08605916798114777
Validation loss: 1.4329749525234263

Epoch: 6| Step: 3
Training loss: 0.07207218557596207
Validation loss: 1.4468516726647653

Epoch: 6| Step: 4
Training loss: 0.11640948057174683
Validation loss: 1.4531042357926727

Epoch: 6| Step: 5
Training loss: 0.10126369446516037
Validation loss: 1.421420963861609

Epoch: 6| Step: 6
Training loss: 0.08856722712516785
Validation loss: 1.4268280639443347

Epoch: 6| Step: 7
Training loss: 0.08141299337148666
Validation loss: 1.4048313709997362

Epoch: 6| Step: 8
Training loss: 0.057406436651945114
Validation loss: 1.4473369877825502

Epoch: 6| Step: 9
Training loss: 0.07840970903635025
Validation loss: 1.4327620011503979

Epoch: 6| Step: 10
Training loss: 0.12693843245506287
Validation loss: 1.4448207860351892

Epoch: 6| Step: 11
Training loss: 0.05052927881479263
Validation loss: 1.4250330527623494

Epoch: 6| Step: 12
Training loss: 0.1792987585067749
Validation loss: 1.4435407923113914

Epoch: 6| Step: 13
Training loss: 0.07404478639364243
Validation loss: 1.4227963775716803

Epoch: 473| Step: 0
Training loss: 0.06654192507266998
Validation loss: 1.434720141913301

Epoch: 6| Step: 1
Training loss: 0.04704398661851883
Validation loss: 1.4291512799519364

Epoch: 6| Step: 2
Training loss: 0.1170954629778862
Validation loss: 1.4554628550365407

Epoch: 6| Step: 3
Training loss: 0.13876336812973022
Validation loss: 1.4578107531352709

Epoch: 6| Step: 4
Training loss: 0.06757310032844543
Validation loss: 1.41725323148953

Epoch: 6| Step: 5
Training loss: 0.08876194804906845
Validation loss: 1.4352381793401574

Epoch: 6| Step: 6
Training loss: 0.22693853080272675
Validation loss: 1.4764322798739198

Epoch: 6| Step: 7
Training loss: 0.15722621977329254
Validation loss: 1.4173714473683348

Epoch: 6| Step: 8
Training loss: 0.11672940850257874
Validation loss: 1.4266029942420222

Epoch: 6| Step: 9
Training loss: 0.08226828277111053
Validation loss: 1.4410811649855746

Epoch: 6| Step: 10
Training loss: 0.08671547472476959
Validation loss: 1.4170029611997708

Epoch: 6| Step: 11
Training loss: 0.14840610325336456
Validation loss: 1.4235303453219834

Epoch: 6| Step: 12
Training loss: 0.09478192031383514
Validation loss: 1.4119250838474562

Epoch: 6| Step: 13
Training loss: 0.07772985100746155
Validation loss: 1.383907752652322

Epoch: 474| Step: 0
Training loss: 0.09240654855966568
Validation loss: 1.4014471692423667

Epoch: 6| Step: 1
Training loss: 0.30011555552482605
Validation loss: 1.408571731659674

Epoch: 6| Step: 2
Training loss: 0.08364526927471161
Validation loss: 1.396273846267372

Epoch: 6| Step: 3
Training loss: 0.07869398593902588
Validation loss: 1.4124984074664373

Epoch: 6| Step: 4
Training loss: 0.10607829689979553
Validation loss: 1.45179997721026

Epoch: 6| Step: 5
Training loss: 0.1368533819913864
Validation loss: 1.4608087321763397

Epoch: 6| Step: 6
Training loss: 0.08049613982439041
Validation loss: 1.507573954520687

Epoch: 6| Step: 7
Training loss: 0.08995597064495087
Validation loss: 1.4901322857026131

Epoch: 6| Step: 8
Training loss: 0.056881628930568695
Validation loss: 1.5150294714076544

Epoch: 6| Step: 9
Training loss: 0.05879607051610947
Validation loss: 1.461997506439045

Epoch: 6| Step: 10
Training loss: 0.11593887209892273
Validation loss: 1.490297673850931

Epoch: 6| Step: 11
Training loss: 0.07838326692581177
Validation loss: 1.4736777095384495

Epoch: 6| Step: 12
Training loss: 0.09057553857564926
Validation loss: 1.4850614711802492

Epoch: 6| Step: 13
Training loss: 0.07718491554260254
Validation loss: 1.5072679827290196

Epoch: 475| Step: 0
Training loss: 0.06783179938793182
Validation loss: 1.4918256844243696

Epoch: 6| Step: 1
Training loss: 0.0720382034778595
Validation loss: 1.5026579556926605

Epoch: 6| Step: 2
Training loss: 0.06562449038028717
Validation loss: 1.5142412070305116

Epoch: 6| Step: 3
Training loss: 0.11063361167907715
Validation loss: 1.488591863263038

Epoch: 6| Step: 4
Training loss: 0.10602396726608276
Validation loss: 1.4586586670209003

Epoch: 6| Step: 5
Training loss: 0.08978521823883057
Validation loss: 1.455172839985099

Epoch: 6| Step: 6
Training loss: 0.2167675495147705
Validation loss: 1.4328070353436213

Epoch: 6| Step: 7
Training loss: 0.13162705302238464
Validation loss: 1.432801418406989

Epoch: 6| Step: 8
Training loss: 0.13166934251785278
Validation loss: 1.4151695748811126

Epoch: 6| Step: 9
Training loss: 0.13524173200130463
Validation loss: 1.416501050354332

Epoch: 6| Step: 10
Training loss: 0.1010914295911789
Validation loss: 1.412775510100908

Epoch: 6| Step: 11
Training loss: 0.1448695957660675
Validation loss: 1.4135555721098376

Epoch: 6| Step: 12
Training loss: 0.11529345065355301
Validation loss: 1.4015450182781424

Epoch: 6| Step: 13
Training loss: 0.08309835940599442
Validation loss: 1.4105527939334992

Epoch: 476| Step: 0
Training loss: 0.09400323033332825
Validation loss: 1.4034852654703203

Epoch: 6| Step: 1
Training loss: 0.07827775180339813
Validation loss: 1.455049785234595

Epoch: 6| Step: 2
Training loss: 0.08528374135494232
Validation loss: 1.415667510801746

Epoch: 6| Step: 3
Training loss: 0.10675857961177826
Validation loss: 1.4041169651093022

Epoch: 6| Step: 4
Training loss: 0.12390156090259552
Validation loss: 1.409587380706623

Epoch: 6| Step: 5
Training loss: 0.06771840900182724
Validation loss: 1.3960780020683043

Epoch: 6| Step: 6
Training loss: 0.21019387245178223
Validation loss: 1.4131353696187336

Epoch: 6| Step: 7
Training loss: 0.12900450825691223
Validation loss: 1.4117182275300384

Epoch: 6| Step: 8
Training loss: 0.17113333940505981
Validation loss: 1.422652639368529

Epoch: 6| Step: 9
Training loss: 0.1963273286819458
Validation loss: 1.420576451927103

Epoch: 6| Step: 10
Training loss: 0.17212265729904175
Validation loss: 1.4268096147045013

Epoch: 6| Step: 11
Training loss: 0.11329270154237747
Validation loss: 1.4226611378372356

Epoch: 6| Step: 12
Training loss: 0.12260138243436813
Validation loss: 1.3814956295874812

Epoch: 6| Step: 13
Training loss: 0.05618765577673912
Validation loss: 1.4176777806333316

Epoch: 477| Step: 0
Training loss: 0.08617039024829865
Validation loss: 1.4247454302285307

Epoch: 6| Step: 1
Training loss: 0.11179684102535248
Validation loss: 1.4251727275950934

Epoch: 6| Step: 2
Training loss: 0.22321416437625885
Validation loss: 1.4576511434329453

Epoch: 6| Step: 3
Training loss: 0.13649863004684448
Validation loss: 1.4691003343110443

Epoch: 6| Step: 4
Training loss: 0.1487409919500351
Validation loss: 1.4332539522519676

Epoch: 6| Step: 5
Training loss: 0.08326864242553711
Validation loss: 1.4384381514723583

Epoch: 6| Step: 6
Training loss: 0.08672009408473969
Validation loss: 1.4416404924085062

Epoch: 6| Step: 7
Training loss: 0.08635874092578888
Validation loss: 1.419550884154535

Epoch: 6| Step: 8
Training loss: 0.10200143605470657
Validation loss: 1.4325883824338195

Epoch: 6| Step: 9
Training loss: 0.09900246560573578
Validation loss: 1.4374474530578942

Epoch: 6| Step: 10
Training loss: 0.0603213757276535
Validation loss: 1.471765141333303

Epoch: 6| Step: 11
Training loss: 0.13871003687381744
Validation loss: 1.4687300484667543

Epoch: 6| Step: 12
Training loss: 0.0800619125366211
Validation loss: 1.446619793932925

Epoch: 6| Step: 13
Training loss: 0.06537874042987823
Validation loss: 1.4527330052468084

Epoch: 478| Step: 0
Training loss: 0.07595491409301758
Validation loss: 1.454619030798635

Epoch: 6| Step: 1
Training loss: 0.08762804418802261
Validation loss: 1.467895479612453

Epoch: 6| Step: 2
Training loss: 0.07927452027797699
Validation loss: 1.449853136975278

Epoch: 6| Step: 3
Training loss: 0.11466291546821594
Validation loss: 1.4453529664265212

Epoch: 6| Step: 4
Training loss: 0.08820557594299316
Validation loss: 1.4552957024625552

Epoch: 6| Step: 5
Training loss: 0.06348185241222382
Validation loss: 1.4356876906528269

Epoch: 6| Step: 6
Training loss: 0.13929563760757446
Validation loss: 1.4382080672889628

Epoch: 6| Step: 7
Training loss: 0.2317677140235901
Validation loss: 1.4277815639331777

Epoch: 6| Step: 8
Training loss: 0.13229817152023315
Validation loss: 1.4317037161960398

Epoch: 6| Step: 9
Training loss: 0.07916850596666336
Validation loss: 1.4466118838197441

Epoch: 6| Step: 10
Training loss: 0.10620672255754471
Validation loss: 1.4663314357880624

Epoch: 6| Step: 11
Training loss: 0.054491784423589706
Validation loss: 1.4484959456228441

Epoch: 6| Step: 12
Training loss: 0.08738179504871368
Validation loss: 1.4638036886850994

Epoch: 6| Step: 13
Training loss: 0.06081598252058029
Validation loss: 1.4945657945448352

Epoch: 479| Step: 0
Training loss: 0.10849626362323761
Validation loss: 1.4951087249222623

Epoch: 6| Step: 1
Training loss: 0.11714492738246918
Validation loss: 1.4933345023021902

Epoch: 6| Step: 2
Training loss: 0.09096178412437439
Validation loss: 1.4762858389526285

Epoch: 6| Step: 3
Training loss: 0.12452549487352371
Validation loss: 1.496666976200637

Epoch: 6| Step: 4
Training loss: 0.26029491424560547
Validation loss: 1.5029997851258965

Epoch: 6| Step: 5
Training loss: 0.0770798847079277
Validation loss: 1.494394169058851

Epoch: 6| Step: 6
Training loss: 0.07299578189849854
Validation loss: 1.4711567663377332

Epoch: 6| Step: 7
Training loss: 0.09917404502630234
Validation loss: 1.4313246011734009

Epoch: 6| Step: 8
Training loss: 0.06960486620664597
Validation loss: 1.4805222019072501

Epoch: 6| Step: 9
Training loss: 0.16554313898086548
Validation loss: 1.4702856393270596

Epoch: 6| Step: 10
Training loss: 0.08488675951957703
Validation loss: 1.479360491998734

Epoch: 6| Step: 11
Training loss: 0.09958143532276154
Validation loss: 1.4560828913924515

Epoch: 6| Step: 12
Training loss: 0.1682225465774536
Validation loss: 1.45352977578358

Epoch: 6| Step: 13
Training loss: 0.08508968353271484
Validation loss: 1.4518135395101321

Epoch: 480| Step: 0
Training loss: 0.09370793402194977
Validation loss: 1.4675791128989188

Epoch: 6| Step: 1
Training loss: 0.2203090488910675
Validation loss: 1.4712777701757287

Epoch: 6| Step: 2
Training loss: 0.14903230965137482
Validation loss: 1.4851073001020698

Epoch: 6| Step: 3
Training loss: 0.10449329018592834
Validation loss: 1.503162222523843

Epoch: 6| Step: 4
Training loss: 0.157308429479599
Validation loss: 1.5063838612648748

Epoch: 6| Step: 5
Training loss: 0.13782012462615967
Validation loss: 1.5091821327004382

Epoch: 6| Step: 6
Training loss: 0.12304094433784485
Validation loss: 1.4681282710003596

Epoch: 6| Step: 7
Training loss: 0.09316873550415039
Validation loss: 1.477492642659013

Epoch: 6| Step: 8
Training loss: 0.08243171125650406
Validation loss: 1.4100544606485674

Epoch: 6| Step: 9
Training loss: 0.06083792448043823
Validation loss: 1.410749666152462

Epoch: 6| Step: 10
Training loss: 0.07106012105941772
Validation loss: 1.384152385496324

Epoch: 6| Step: 11
Training loss: 0.1563381552696228
Validation loss: 1.368032447753414

Epoch: 6| Step: 12
Training loss: 0.12613451480865479
Validation loss: 1.3911003630648378

Epoch: 6| Step: 13
Training loss: 0.10733387619256973
Validation loss: 1.368419885635376

Epoch: 481| Step: 0
Training loss: 0.08069746941328049
Validation loss: 1.3674609084283151

Epoch: 6| Step: 1
Training loss: 0.1153671070933342
Validation loss: 1.3591704201954666

Epoch: 6| Step: 2
Training loss: 0.2850385904312134
Validation loss: 1.3652870693514425

Epoch: 6| Step: 3
Training loss: 0.11266729235649109
Validation loss: 1.337845165242431

Epoch: 6| Step: 4
Training loss: 0.13806270062923431
Validation loss: 1.4087294814407185

Epoch: 6| Step: 5
Training loss: 0.1080772802233696
Validation loss: 1.4002751804167224

Epoch: 6| Step: 6
Training loss: 0.10870092362165451
Validation loss: 1.3977922803612166

Epoch: 6| Step: 7
Training loss: 0.10587641596794128
Validation loss: 1.4016783557912356

Epoch: 6| Step: 8
Training loss: 0.1439620405435562
Validation loss: 1.4355803920376686

Epoch: 6| Step: 9
Training loss: 0.1861082911491394
Validation loss: 1.4204465881470711

Epoch: 6| Step: 10
Training loss: 0.09921450167894363
Validation loss: 1.4183900215292489

Epoch: 6| Step: 11
Training loss: 0.10937362909317017
Validation loss: 1.4369395644434038

Epoch: 6| Step: 12
Training loss: 0.10485959053039551
Validation loss: 1.4426393803729807

Epoch: 6| Step: 13
Training loss: 0.07169923186302185
Validation loss: 1.4235019824838127

Epoch: 482| Step: 0
Training loss: 0.11863098293542862
Validation loss: 1.401100104854953

Epoch: 6| Step: 1
Training loss: 0.05207980424165726
Validation loss: 1.437834539721089

Epoch: 6| Step: 2
Training loss: 0.08784471452236176
Validation loss: 1.4507797379647531

Epoch: 6| Step: 3
Training loss: 0.082422636449337
Validation loss: 1.4344830102817987

Epoch: 6| Step: 4
Training loss: 0.09305309504270554
Validation loss: 1.4074019892241365

Epoch: 6| Step: 5
Training loss: 0.10380958020687103
Validation loss: 1.4535672357005458

Epoch: 6| Step: 6
Training loss: 0.14053410291671753
Validation loss: 1.4359702467918396

Epoch: 6| Step: 7
Training loss: 0.1471225917339325
Validation loss: 1.4341681682935326

Epoch: 6| Step: 8
Training loss: 0.09088346362113953
Validation loss: 1.4430922385184997

Epoch: 6| Step: 9
Training loss: 0.21684987843036652
Validation loss: 1.453921756436748

Epoch: 6| Step: 10
Training loss: 0.12548616528511047
Validation loss: 1.4486160265502108

Epoch: 6| Step: 11
Training loss: 0.11367375403642654
Validation loss: 1.4483606699974305

Epoch: 6| Step: 12
Training loss: 0.09740271419286728
Validation loss: 1.446330899833351

Epoch: 6| Step: 13
Training loss: 0.0666436105966568
Validation loss: 1.4500415581528858

Epoch: 483| Step: 0
Training loss: 0.11921072751283646
Validation loss: 1.4496109306171376

Epoch: 6| Step: 1
Training loss: 0.08691810071468353
Validation loss: 1.4541147928084097

Epoch: 6| Step: 2
Training loss: 0.09485122561454773
Validation loss: 1.4409498976122948

Epoch: 6| Step: 3
Training loss: 0.09391312301158905
Validation loss: 1.454035880104188

Epoch: 6| Step: 4
Training loss: 0.10493066906929016
Validation loss: 1.4067938558516964

Epoch: 6| Step: 5
Training loss: 0.09000148624181747
Validation loss: 1.4033760819383847

Epoch: 6| Step: 6
Training loss: 0.08401481807231903
Validation loss: 1.3887392538850025

Epoch: 6| Step: 7
Training loss: 0.12376585602760315
Validation loss: 1.3834298567105365

Epoch: 6| Step: 8
Training loss: 0.1014355719089508
Validation loss: 1.3509372511217672

Epoch: 6| Step: 9
Training loss: 0.10824120789766312
Validation loss: 1.37339029389043

Epoch: 6| Step: 10
Training loss: 0.2509694993495941
Validation loss: 1.3724127540024378

Epoch: 6| Step: 11
Training loss: 0.11223406344652176
Validation loss: 1.407764079750225

Epoch: 6| Step: 12
Training loss: 0.12315166741609573
Validation loss: 1.4054629828340264

Epoch: 6| Step: 13
Training loss: 0.041003718972206116
Validation loss: 1.4398744240883858

Epoch: 484| Step: 0
Training loss: 0.13948450982570648
Validation loss: 1.4392954777645808

Epoch: 6| Step: 1
Training loss: 0.1210600733757019
Validation loss: 1.4460059904283094

Epoch: 6| Step: 2
Training loss: 0.12825533747673035
Validation loss: 1.4526865905331028

Epoch: 6| Step: 3
Training loss: 0.106411874294281
Validation loss: 1.474630190800595

Epoch: 6| Step: 4
Training loss: 0.11663050204515457
Validation loss: 1.4660170873006184

Epoch: 6| Step: 5
Training loss: 0.054668523371219635
Validation loss: 1.4928148113271242

Epoch: 6| Step: 6
Training loss: 0.10302844643592834
Validation loss: 1.5078961387757333

Epoch: 6| Step: 7
Training loss: 0.20841997861862183
Validation loss: 1.5262601926762571

Epoch: 6| Step: 8
Training loss: 0.11746581643819809
Validation loss: 1.52283904885733

Epoch: 6| Step: 9
Training loss: 0.0922614336013794
Validation loss: 1.506751880850843

Epoch: 6| Step: 10
Training loss: 0.1701214462518692
Validation loss: 1.5074332209043606

Epoch: 6| Step: 11
Training loss: 0.0883389338850975
Validation loss: 1.4765520281689142

Epoch: 6| Step: 12
Training loss: 0.09245401620864868
Validation loss: 1.4833036481693227

Epoch: 6| Step: 13
Training loss: 0.11190178990364075
Validation loss: 1.4405725271471086

Epoch: 485| Step: 0
Training loss: 0.06579667329788208
Validation loss: 1.4304033979292838

Epoch: 6| Step: 1
Training loss: 0.15089496970176697
Validation loss: 1.4346741079002299

Epoch: 6| Step: 2
Training loss: 0.10343047976493835
Validation loss: 1.385198567503242

Epoch: 6| Step: 3
Training loss: 0.04821749031543732
Validation loss: 1.3857125031050814

Epoch: 6| Step: 4
Training loss: 0.08551063388586044
Validation loss: 1.3382098399182802

Epoch: 6| Step: 5
Training loss: 0.18649567663669586
Validation loss: 1.3626118731755081

Epoch: 6| Step: 6
Training loss: 0.0943131372332573
Validation loss: 1.3428725786106561

Epoch: 6| Step: 7
Training loss: 0.08888234198093414
Validation loss: 1.3262739264836876

Epoch: 6| Step: 8
Training loss: 0.0788891389966011
Validation loss: 1.348313493113364

Epoch: 6| Step: 9
Training loss: 0.08859559893608093
Validation loss: 1.3760665193680794

Epoch: 6| Step: 10
Training loss: 0.09743492305278778
Validation loss: 1.3572384695852957

Epoch: 6| Step: 11
Training loss: 0.14861837029457092
Validation loss: 1.3989618362918976

Epoch: 6| Step: 12
Training loss: 0.0865836814045906
Validation loss: 1.4075924901552097

Epoch: 6| Step: 13
Training loss: 0.04758123680949211
Validation loss: 1.406199719316216

Epoch: 486| Step: 0
Training loss: 0.06491301953792572
Validation loss: 1.4245826364845358

Epoch: 6| Step: 1
Training loss: 0.08050600439310074
Validation loss: 1.4323986602085892

Epoch: 6| Step: 2
Training loss: 0.06746217608451843
Validation loss: 1.4415405181146437

Epoch: 6| Step: 3
Training loss: 0.049374938011169434
Validation loss: 1.4492839895268923

Epoch: 6| Step: 4
Training loss: 0.053407005965709686
Validation loss: 1.4628739690267911

Epoch: 6| Step: 5
Training loss: 0.06520023941993713
Validation loss: 1.4455354726442726

Epoch: 6| Step: 6
Training loss: 0.08354311436414719
Validation loss: 1.4790007895038975

Epoch: 6| Step: 7
Training loss: 0.06945298612117767
Validation loss: 1.477413978627933

Epoch: 6| Step: 8
Training loss: 0.11729434132575989
Validation loss: 1.4638238747914631

Epoch: 6| Step: 9
Training loss: 0.09255616366863251
Validation loss: 1.4665619250266784

Epoch: 6| Step: 10
Training loss: 0.1006021797657013
Validation loss: 1.4593458034658944

Epoch: 6| Step: 11
Training loss: 0.24231137335300446
Validation loss: 1.4432757554515716

Epoch: 6| Step: 12
Training loss: 0.0652930736541748
Validation loss: 1.426694453403514

Epoch: 6| Step: 13
Training loss: 0.1825045794248581
Validation loss: 1.427516500155131

Epoch: 487| Step: 0
Training loss: 0.04388337954878807
Validation loss: 1.4167239217347996

Epoch: 6| Step: 1
Training loss: 0.13225704431533813
Validation loss: 1.4070575211637764

Epoch: 6| Step: 2
Training loss: 0.07098694145679474
Validation loss: 1.4134628336916688

Epoch: 6| Step: 3
Training loss: 0.06647779792547226
Validation loss: 1.4376795035536571

Epoch: 6| Step: 4
Training loss: 0.12154997140169144
Validation loss: 1.4425420389380506

Epoch: 6| Step: 5
Training loss: 0.05352193862199783
Validation loss: 1.4422440490415018

Epoch: 6| Step: 6
Training loss: 0.09292718023061752
Validation loss: 1.4547459322919127

Epoch: 6| Step: 7
Training loss: 0.09172147512435913
Validation loss: 1.4686385085505824

Epoch: 6| Step: 8
Training loss: 0.0988125428557396
Validation loss: 1.5058353357417609

Epoch: 6| Step: 9
Training loss: 0.07895609736442566
Validation loss: 1.4777657139685847

Epoch: 6| Step: 10
Training loss: 0.05346366763114929
Validation loss: 1.4909009292561521

Epoch: 6| Step: 11
Training loss: 0.2513084411621094
Validation loss: 1.483629495866837

Epoch: 6| Step: 12
Training loss: 0.09405165910720825
Validation loss: 1.4842607417414266

Epoch: 6| Step: 13
Training loss: 0.07878666371107101
Validation loss: 1.4328067982068626

Epoch: 488| Step: 0
Training loss: 0.09433909505605698
Validation loss: 1.4467646511652137

Epoch: 6| Step: 1
Training loss: 0.09078192710876465
Validation loss: 1.4243435705861738

Epoch: 6| Step: 2
Training loss: 0.13170753419399261
Validation loss: 1.4039138965709235

Epoch: 6| Step: 3
Training loss: 0.07902434468269348
Validation loss: 1.3819267615195243

Epoch: 6| Step: 4
Training loss: 0.15956048667430878
Validation loss: 1.3946367194575648

Epoch: 6| Step: 5
Training loss: 0.07198712229728699
Validation loss: 1.3780435515988259

Epoch: 6| Step: 6
Training loss: 0.25307509303092957
Validation loss: 1.3663690090179443

Epoch: 6| Step: 7
Training loss: 0.09185667335987091
Validation loss: 1.3677814525942649

Epoch: 6| Step: 8
Training loss: 0.08332520723342896
Validation loss: 1.3705882218576246

Epoch: 6| Step: 9
Training loss: 0.069614939391613
Validation loss: 1.3810396104730585

Epoch: 6| Step: 10
Training loss: 0.09127311408519745
Validation loss: 1.3738588556166618

Epoch: 6| Step: 11
Training loss: 0.1323907971382141
Validation loss: 1.3914937921749648

Epoch: 6| Step: 12
Training loss: 0.10767574608325958
Validation loss: 1.4098800997580252

Epoch: 6| Step: 13
Training loss: 0.07213117182254791
Validation loss: 1.4433345346040622

Epoch: 489| Step: 0
Training loss: 0.04834786057472229
Validation loss: 1.4587471049319032

Epoch: 6| Step: 1
Training loss: 0.06651144474744797
Validation loss: 1.4704617877160349

Epoch: 6| Step: 2
Training loss: 0.06153130903840065
Validation loss: 1.471189183573569

Epoch: 6| Step: 3
Training loss: 0.08125072717666626
Validation loss: 1.4723579217028875

Epoch: 6| Step: 4
Training loss: 0.20457327365875244
Validation loss: 1.484390547198634

Epoch: 6| Step: 5
Training loss: 0.0740886703133583
Validation loss: 1.4903222232736566

Epoch: 6| Step: 6
Training loss: 0.0868367850780487
Validation loss: 1.4682657423839773

Epoch: 6| Step: 7
Training loss: 0.05865070968866348
Validation loss: 1.4817889633999075

Epoch: 6| Step: 8
Training loss: 0.0533650778234005
Validation loss: 1.4760234355926514

Epoch: 6| Step: 9
Training loss: 0.07559028267860413
Validation loss: 1.4471472194117885

Epoch: 6| Step: 10
Training loss: 0.09193545579910278
Validation loss: 1.456488235022432

Epoch: 6| Step: 11
Training loss: 0.13327987492084503
Validation loss: 1.4400545397112448

Epoch: 6| Step: 12
Training loss: 0.04561170935630798
Validation loss: 1.4656211048044183

Epoch: 6| Step: 13
Training loss: 0.08396906405687332
Validation loss: 1.462685759349536

Epoch: 490| Step: 0
Training loss: 0.10208985954523087
Validation loss: 1.4757633196410311

Epoch: 6| Step: 1
Training loss: 0.062128812074661255
Validation loss: 1.461888587603005

Epoch: 6| Step: 2
Training loss: 0.09715842455625534
Validation loss: 1.481412341517787

Epoch: 6| Step: 3
Training loss: 0.040401704609394073
Validation loss: 1.4550886090083788

Epoch: 6| Step: 4
Training loss: 0.10324811190366745
Validation loss: 1.4756894329542756

Epoch: 6| Step: 5
Training loss: 0.054674021899700165
Validation loss: 1.4748622743032311

Epoch: 6| Step: 6
Training loss: 0.0772910937666893
Validation loss: 1.457376508302586

Epoch: 6| Step: 7
Training loss: 0.058915067464113235
Validation loss: 1.4751693244262407

Epoch: 6| Step: 8
Training loss: 0.06797562539577484
Validation loss: 1.459997179687664

Epoch: 6| Step: 9
Training loss: 0.06090206652879715
Validation loss: 1.453690186623604

Epoch: 6| Step: 10
Training loss: 0.07073146104812622
Validation loss: 1.4317393764372794

Epoch: 6| Step: 11
Training loss: 0.17743457853794098
Validation loss: 1.4221607260806586

Epoch: 6| Step: 12
Training loss: 0.11205872148275375
Validation loss: 1.3814520092420681

Epoch: 6| Step: 13
Training loss: 0.1413179188966751
Validation loss: 1.3616284952368787

Epoch: 491| Step: 0
Training loss: 0.08927442878484726
Validation loss: 1.3551138767632105

Epoch: 6| Step: 1
Training loss: 0.09846426546573639
Validation loss: 1.3655998411998953

Epoch: 6| Step: 2
Training loss: 0.10284894704818726
Validation loss: 1.3362644808266753

Epoch: 6| Step: 3
Training loss: 0.14500227570533752
Validation loss: 1.398996469795063

Epoch: 6| Step: 4
Training loss: 0.07695552706718445
Validation loss: 1.4204365579030847

Epoch: 6| Step: 5
Training loss: 0.06811170279979706
Validation loss: 1.4301437511239001

Epoch: 6| Step: 6
Training loss: 0.07830168306827545
Validation loss: 1.4360365188249977

Epoch: 6| Step: 7
Training loss: 0.059238359332084656
Validation loss: 1.4708967131953086

Epoch: 6| Step: 8
Training loss: 0.06790154427289963
Validation loss: 1.4741580960571126

Epoch: 6| Step: 9
Training loss: 0.23800720274448395
Validation loss: 1.5154025734111827

Epoch: 6| Step: 10
Training loss: 0.11433352530002594
Validation loss: 1.5141190482724098

Epoch: 6| Step: 11
Training loss: 0.10678520798683167
Validation loss: 1.5169509046821184

Epoch: 6| Step: 12
Training loss: 0.08703812956809998
Validation loss: 1.5480026762972596

Epoch: 6| Step: 13
Training loss: 0.11730143427848816
Validation loss: 1.5432015580515708

Epoch: 492| Step: 0
Training loss: 0.10055607557296753
Validation loss: 1.5198477404091948

Epoch: 6| Step: 1
Training loss: 0.06481367349624634
Validation loss: 1.4722379099938177

Epoch: 6| Step: 2
Training loss: 0.10776064544916153
Validation loss: 1.4631661112590502

Epoch: 6| Step: 3
Training loss: 0.0811469554901123
Validation loss: 1.4371005476161998

Epoch: 6| Step: 4
Training loss: 0.1250101923942566
Validation loss: 1.438466869374757

Epoch: 6| Step: 5
Training loss: 0.13008151948451996
Validation loss: 1.425913595384167

Epoch: 6| Step: 6
Training loss: 0.10301969945430756
Validation loss: 1.4043402043722009

Epoch: 6| Step: 7
Training loss: 0.08297649025917053
Validation loss: 1.4039775684315672

Epoch: 6| Step: 8
Training loss: 0.09305384755134583
Validation loss: 1.400066614151001

Epoch: 6| Step: 9
Training loss: 0.11553084850311279
Validation loss: 1.4213854266751198

Epoch: 6| Step: 10
Training loss: 0.07688084244728088
Validation loss: 1.3929736268135808

Epoch: 6| Step: 11
Training loss: 0.1311822235584259
Validation loss: 1.4111479065751518

Epoch: 6| Step: 12
Training loss: 0.14193248748779297
Validation loss: 1.4267457480071692

Epoch: 6| Step: 13
Training loss: 0.2639239728450775
Validation loss: 1.4250130473926503

Epoch: 493| Step: 0
Training loss: 0.04411107674241066
Validation loss: 1.430836744205926

Epoch: 6| Step: 1
Training loss: 0.06973111629486084
Validation loss: 1.439483199068295

Epoch: 6| Step: 2
Training loss: 0.07112334668636322
Validation loss: 1.436189801462235

Epoch: 6| Step: 3
Training loss: 0.09001165628433228
Validation loss: 1.433678178377049

Epoch: 6| Step: 4
Training loss: 0.06604976952075958
Validation loss: 1.409943216590471

Epoch: 6| Step: 5
Training loss: 0.10717910528182983
Validation loss: 1.4186866065507293

Epoch: 6| Step: 6
Training loss: 0.10059208422899246
Validation loss: 1.4247920897699171

Epoch: 6| Step: 7
Training loss: 0.10104246437549591
Validation loss: 1.3947342723928473

Epoch: 6| Step: 8
Training loss: 0.08836377412080765
Validation loss: 1.4297574745711459

Epoch: 6| Step: 9
Training loss: 0.18600542843341827
Validation loss: 1.4080553721356135

Epoch: 6| Step: 10
Training loss: 0.0763043537735939
Validation loss: 1.430360124957177

Epoch: 6| Step: 11
Training loss: 0.08984889090061188
Validation loss: 1.413607333936999

Epoch: 6| Step: 12
Training loss: 0.12051017582416534
Validation loss: 1.4730406371496056

Epoch: 6| Step: 13
Training loss: 0.12732021510601044
Validation loss: 1.4666580000231344

Epoch: 494| Step: 0
Training loss: 0.0884648784995079
Validation loss: 1.4509427509000223

Epoch: 6| Step: 1
Training loss: 0.07096182554960251
Validation loss: 1.4760937498461815

Epoch: 6| Step: 2
Training loss: 0.1719842404127121
Validation loss: 1.4734530628368419

Epoch: 6| Step: 3
Training loss: 0.08126337826251984
Validation loss: 1.458726776543484

Epoch: 6| Step: 4
Training loss: 0.1017008051276207
Validation loss: 1.4788691625800183

Epoch: 6| Step: 5
Training loss: 0.11301859468221664
Validation loss: 1.463877667662918

Epoch: 6| Step: 6
Training loss: 0.11632286757230759
Validation loss: 1.4581277517862217

Epoch: 6| Step: 7
Training loss: 0.041664302349090576
Validation loss: 1.4631178468786261

Epoch: 6| Step: 8
Training loss: 0.17260921001434326
Validation loss: 1.4669820236903366

Epoch: 6| Step: 9
Training loss: 0.1008405014872551
Validation loss: 1.464615806456535

Epoch: 6| Step: 10
Training loss: 0.10738018155097961
Validation loss: 1.47692649210653

Epoch: 6| Step: 11
Training loss: 0.09413442015647888
Validation loss: 1.4573810536374328

Epoch: 6| Step: 12
Training loss: 0.04552607983350754
Validation loss: 1.4904239600704563

Epoch: 6| Step: 13
Training loss: 0.13656286895275116
Validation loss: 1.4618374455359675

Epoch: 495| Step: 0
Training loss: 0.05269762501120567
Validation loss: 1.4592772888880905

Epoch: 6| Step: 1
Training loss: 0.08924522995948792
Validation loss: 1.4461161116118073

Epoch: 6| Step: 2
Training loss: 0.07194335013628006
Validation loss: 1.4643266765020226

Epoch: 6| Step: 3
Training loss: 0.14079274237155914
Validation loss: 1.4690746181113745

Epoch: 6| Step: 4
Training loss: 0.11835166066884995
Validation loss: 1.4683588576573197

Epoch: 6| Step: 5
Training loss: 0.05504640191793442
Validation loss: 1.473808362919797

Epoch: 6| Step: 6
Training loss: 0.08892454206943512
Validation loss: 1.4592852848832325

Epoch: 6| Step: 7
Training loss: 0.07989379018545151
Validation loss: 1.4679258254266554

Epoch: 6| Step: 8
Training loss: 0.12284320592880249
Validation loss: 1.4486464159463042

Epoch: 6| Step: 9
Training loss: 0.13037090003490448
Validation loss: 1.4376602198487969

Epoch: 6| Step: 10
Training loss: 0.08307701349258423
Validation loss: 1.4094647181931363

Epoch: 6| Step: 11
Training loss: 0.05989229679107666
Validation loss: 1.4056356055762178

Epoch: 6| Step: 12
Training loss: 0.10957162082195282
Validation loss: 1.4195903616566812

Epoch: 6| Step: 13
Training loss: 0.3053959906101227
Validation loss: 1.4085596492213588

Epoch: 496| Step: 0
Training loss: 0.050305869430303574
Validation loss: 1.427946795699417

Epoch: 6| Step: 1
Training loss: 0.09912203997373581
Validation loss: 1.405142117572087

Epoch: 6| Step: 2
Training loss: 0.09865238517522812
Validation loss: 1.445440359013055

Epoch: 6| Step: 3
Training loss: 0.10801394283771515
Validation loss: 1.4207849425654258

Epoch: 6| Step: 4
Training loss: 0.05744694173336029
Validation loss: 1.4214238543664255

Epoch: 6| Step: 5
Training loss: 0.1981508433818817
Validation loss: 1.4378484026078255

Epoch: 6| Step: 6
Training loss: 0.07363789528608322
Validation loss: 1.4263187736593268

Epoch: 6| Step: 7
Training loss: 0.1294887512922287
Validation loss: 1.4120159931080316

Epoch: 6| Step: 8
Training loss: 0.10346084833145142
Validation loss: 1.420053271837132

Epoch: 6| Step: 9
Training loss: 0.08611120283603668
Validation loss: 1.4020177561749694

Epoch: 6| Step: 10
Training loss: 0.07612010836601257
Validation loss: 1.3641510061038438

Epoch: 6| Step: 11
Training loss: 0.10824424028396606
Validation loss: 1.3486718388013943

Epoch: 6| Step: 12
Training loss: 0.10451847314834595
Validation loss: 1.3507086846136278

Epoch: 6| Step: 13
Training loss: 0.08080606907606125
Validation loss: 1.3635076925318728

Epoch: 497| Step: 0
Training loss: 0.11315708607435226
Validation loss: 1.3943719569072928

Epoch: 6| Step: 1
Training loss: 0.09228157252073288
Validation loss: 1.4133450856772802

Epoch: 6| Step: 2
Training loss: 0.13937506079673767
Validation loss: 1.392814725957891

Epoch: 6| Step: 3
Training loss: 0.1856805384159088
Validation loss: 1.4161172438693304

Epoch: 6| Step: 4
Training loss: 0.13577917218208313
Validation loss: 1.4270263205292404

Epoch: 6| Step: 5
Training loss: 0.05724530667066574
Validation loss: 1.4792723027608727

Epoch: 6| Step: 6
Training loss: 0.09932401776313782
Validation loss: 1.4743695079639394

Epoch: 6| Step: 7
Training loss: 0.047910116612911224
Validation loss: 1.4619271460399832

Epoch: 6| Step: 8
Training loss: 0.06042129546403885
Validation loss: 1.468767055901148

Epoch: 6| Step: 9
Training loss: 0.07517944276332855
Validation loss: 1.4648982465908091

Epoch: 6| Step: 10
Training loss: 0.074858158826828
Validation loss: 1.4540197375000163

Epoch: 6| Step: 11
Training loss: 0.05992886424064636
Validation loss: 1.4560345116481985

Epoch: 6| Step: 12
Training loss: 0.04699859395623207
Validation loss: 1.4559967684489425

Epoch: 6| Step: 13
Training loss: 0.11813947558403015
Validation loss: 1.4322369688300676

Epoch: 498| Step: 0
Training loss: 0.061719201505184174
Validation loss: 1.4438879066897976

Epoch: 6| Step: 1
Training loss: 0.16718557476997375
Validation loss: 1.434029499689738

Epoch: 6| Step: 2
Training loss: 0.08413967490196228
Validation loss: 1.444675696793423

Epoch: 6| Step: 3
Training loss: 0.061098724603652954
Validation loss: 1.4249069101067

Epoch: 6| Step: 4
Training loss: 0.0662933811545372
Validation loss: 1.451960761059997

Epoch: 6| Step: 5
Training loss: 0.1405695080757141
Validation loss: 1.4572680432309386

Epoch: 6| Step: 6
Training loss: 0.12529337406158447
Validation loss: 1.4646778952690862

Epoch: 6| Step: 7
Training loss: 0.08088304102420807
Validation loss: 1.4705580665219216

Epoch: 6| Step: 8
Training loss: 0.094466432929039
Validation loss: 1.4549497647952008

Epoch: 6| Step: 9
Training loss: 0.07694120705127716
Validation loss: 1.4637666363869943

Epoch: 6| Step: 10
Training loss: 0.11122988164424896
Validation loss: 1.4659577249198832

Epoch: 6| Step: 11
Training loss: 0.0813436210155487
Validation loss: 1.4792023986898444

Epoch: 6| Step: 12
Training loss: 0.0912683829665184
Validation loss: 1.4578429140070432

Epoch: 6| Step: 13
Training loss: 0.09048224240541458
Validation loss: 1.4676310990446357

Epoch: 499| Step: 0
Training loss: 0.07455690205097198
Validation loss: 1.4823193447564238

Epoch: 6| Step: 1
Training loss: 0.08817842602729797
Validation loss: 1.4994840468129804

Epoch: 6| Step: 2
Training loss: 0.06979426741600037
Validation loss: 1.5142608278541154

Epoch: 6| Step: 3
Training loss: 0.1060369610786438
Validation loss: 1.5103996184564406

Epoch: 6| Step: 4
Training loss: 0.10601348429918289
Validation loss: 1.523338548598751

Epoch: 6| Step: 5
Training loss: 0.23313245177268982
Validation loss: 1.5169908128758913

Epoch: 6| Step: 6
Training loss: 0.06856655329465866
Validation loss: 1.5342716401623142

Epoch: 6| Step: 7
Training loss: 0.09578345715999603
Validation loss: 1.5646847012222453

Epoch: 6| Step: 8
Training loss: 0.1161520704627037
Validation loss: 1.5498055693923787

Epoch: 6| Step: 9
Training loss: 0.14900746941566467
Validation loss: 1.5218133554663709

Epoch: 6| Step: 10
Training loss: 0.13899289071559906
Validation loss: 1.5166017855367353

Epoch: 6| Step: 11
Training loss: 0.10605155676603317
Validation loss: 1.4824379080085344

Epoch: 6| Step: 12
Training loss: 0.1369122862815857
Validation loss: 1.454768923021132

Epoch: 6| Step: 13
Training loss: 0.07847915589809418
Validation loss: 1.473772289932415

Epoch: 500| Step: 0
Training loss: 0.0585218109190464
Validation loss: 1.4659807092400008

Epoch: 6| Step: 1
Training loss: 0.15491071343421936
Validation loss: 1.4596214371342813

Epoch: 6| Step: 2
Training loss: 0.10706789791584015
Validation loss: 1.4638124486451507

Epoch: 6| Step: 3
Training loss: 0.10273365676403046
Validation loss: 1.462378950529201

Epoch: 6| Step: 4
Training loss: 0.06818407773971558
Validation loss: 1.4751434935036527

Epoch: 6| Step: 5
Training loss: 0.06547030806541443
Validation loss: 1.4900114241466726

Epoch: 6| Step: 6
Training loss: 0.1121143102645874
Validation loss: 1.479047421486147

Epoch: 6| Step: 7
Training loss: 0.08297573029994965
Validation loss: 1.4930289522294076

Epoch: 6| Step: 8
Training loss: 0.11493836343288422
Validation loss: 1.4934399845779582

Epoch: 6| Step: 9
Training loss: 0.12809967994689941
Validation loss: 1.4857976885252102

Epoch: 6| Step: 10
Training loss: 0.16092437505722046
Validation loss: 1.493505274095843

Epoch: 6| Step: 11
Training loss: 0.12078436464071274
Validation loss: 1.4890286794272802

Epoch: 6| Step: 12
Training loss: 0.1683463752269745
Validation loss: 1.4615865715088383

Epoch: 6| Step: 13
Training loss: 0.275100976228714
Validation loss: 1.4805195844301613

Epoch: 501| Step: 0
Training loss: 0.061235085129737854
Validation loss: 1.4202931760459818

Epoch: 6| Step: 1
Training loss: 0.13128146529197693
Validation loss: 1.4224041431180892

Epoch: 6| Step: 2
Training loss: 0.1528143435716629
Validation loss: 1.4329289338921989

Epoch: 6| Step: 3
Training loss: 0.10030018538236618
Validation loss: 1.4021229833684943

Epoch: 6| Step: 4
Training loss: 0.1280558705329895
Validation loss: 1.4122920754135295

Epoch: 6| Step: 5
Training loss: 0.11635713279247284
Validation loss: 1.399490394899922

Epoch: 6| Step: 6
Training loss: 0.0834297388792038
Validation loss: 1.4221377565014748

Epoch: 6| Step: 7
Training loss: 0.12344986200332642
Validation loss: 1.3795253422952467

Epoch: 6| Step: 8
Training loss: 0.19351139664649963
Validation loss: 1.41787749977522

Epoch: 6| Step: 9
Training loss: 0.1347389668226242
Validation loss: 1.4452875275765695

Epoch: 6| Step: 10
Training loss: 0.1856958568096161
Validation loss: 1.4392850732290616

Epoch: 6| Step: 11
Training loss: 0.12377017736434937
Validation loss: 1.4620650096606183

Epoch: 6| Step: 12
Training loss: 0.09488143026828766
Validation loss: 1.4218350712971022

Epoch: 6| Step: 13
Training loss: 0.1187410056591034
Validation loss: 1.42306230145116

Epoch: 502| Step: 0
Training loss: 0.07813240587711334
Validation loss: 1.401368716711639

Epoch: 6| Step: 1
Training loss: 0.24076904356479645
Validation loss: 1.3961602692962976

Epoch: 6| Step: 2
Training loss: 0.10215641558170319
Validation loss: 1.3888100513847925

Epoch: 6| Step: 3
Training loss: 0.14622394740581512
Validation loss: 1.360040912064173

Epoch: 6| Step: 4
Training loss: 0.14644184708595276
Validation loss: 1.3809693577469035

Epoch: 6| Step: 5
Training loss: 0.0819750726222992
Validation loss: 1.4128657784513248

Epoch: 6| Step: 6
Training loss: 0.15284506976604462
Validation loss: 1.4167397637521066

Epoch: 6| Step: 7
Training loss: 0.07781492173671722
Validation loss: 1.4372074501488799

Epoch: 6| Step: 8
Training loss: 0.13959760963916779
Validation loss: 1.4741625388463337

Epoch: 6| Step: 9
Training loss: 0.12226028740406036
Validation loss: 1.4830065517015354

Epoch: 6| Step: 10
Training loss: 0.09206822514533997
Validation loss: 1.500943140317035

Epoch: 6| Step: 11
Training loss: 0.1267993152141571
Validation loss: 1.52655013145939

Epoch: 6| Step: 12
Training loss: 0.13099229335784912
Validation loss: 1.5179791142863612

Epoch: 6| Step: 13
Training loss: 0.14084157347679138
Validation loss: 1.5070467681013129

Epoch: 503| Step: 0
Training loss: 0.1725330352783203
Validation loss: 1.4770034019665053

Epoch: 6| Step: 1
Training loss: 0.0918848067522049
Validation loss: 1.454615948020771

Epoch: 6| Step: 2
Training loss: 0.11790213733911514
Validation loss: 1.427511151118945

Epoch: 6| Step: 3
Training loss: 0.06805962324142456
Validation loss: 1.4008231412979864

Epoch: 6| Step: 4
Training loss: 0.23224905133247375
Validation loss: 1.3550561281942552

Epoch: 6| Step: 5
Training loss: 0.12627668678760529
Validation loss: 1.3299058560402162

Epoch: 6| Step: 6
Training loss: 0.08582519739866257
Validation loss: 1.3024568878194338

Epoch: 6| Step: 7
Training loss: 0.1270933449268341
Validation loss: 1.3120495978222098

Epoch: 6| Step: 8
Training loss: 0.10841110348701477
Validation loss: 1.3006886820639334

Epoch: 6| Step: 9
Training loss: 0.09579060226678848
Validation loss: 1.310552066372287

Epoch: 6| Step: 10
Training loss: 0.0953586995601654
Validation loss: 1.310884448789781

Epoch: 6| Step: 11
Training loss: 0.1917192041873932
Validation loss: 1.3460851548820414

Epoch: 6| Step: 12
Training loss: 0.09172070026397705
Validation loss: 1.34089917777687

Epoch: 6| Step: 13
Training loss: 0.17673058807849884
Validation loss: 1.3775817091746996

Epoch: 504| Step: 0
Training loss: 0.08446428179740906
Validation loss: 1.4015798402088944

Epoch: 6| Step: 1
Training loss: 0.14233140647411346
Validation loss: 1.4096267082357918

Epoch: 6| Step: 2
Training loss: 0.19991616904735565
Validation loss: 1.4232031517131354

Epoch: 6| Step: 3
Training loss: 0.15206068754196167
Validation loss: 1.4477437952513337

Epoch: 6| Step: 4
Training loss: 0.1606852114200592
Validation loss: 1.4437497815778177

Epoch: 6| Step: 5
Training loss: 0.165286123752594
Validation loss: 1.4480654936964794

Epoch: 6| Step: 6
Training loss: 0.08600685000419617
Validation loss: 1.4203853716132462

Epoch: 6| Step: 7
Training loss: 0.07507012784481049
Validation loss: 1.4078433987914876

Epoch: 6| Step: 8
Training loss: 0.1252569556236267
Validation loss: 1.3464972178141277

Epoch: 6| Step: 9
Training loss: 0.10769934952259064
Validation loss: 1.3405746977816346

Epoch: 6| Step: 10
Training loss: 0.11669502407312393
Validation loss: 1.3609181116986018

Epoch: 6| Step: 11
Training loss: 0.17712903022766113
Validation loss: 1.3626463643966182

Epoch: 6| Step: 12
Training loss: 0.059001464396715164
Validation loss: 1.3421587822257832

Epoch: 6| Step: 13
Training loss: 0.09872328490018845
Validation loss: 1.385004001279031

Epoch: 505| Step: 0
Training loss: 0.06597625464200974
Validation loss: 1.3940140662654754

Epoch: 6| Step: 1
Training loss: 0.08231735229492188
Validation loss: 1.423647108898368

Epoch: 6| Step: 2
Training loss: 0.0705690085887909
Validation loss: 1.4421376618005897

Epoch: 6| Step: 3
Training loss: 0.10405822843313217
Validation loss: 1.4513366389018234

Epoch: 6| Step: 4
Training loss: 0.09183363616466522
Validation loss: 1.4452181336700276

Epoch: 6| Step: 5
Training loss: 0.1273246854543686
Validation loss: 1.4746016199870775

Epoch: 6| Step: 6
Training loss: 0.15392404794692993
Validation loss: 1.4724023483132804

Epoch: 6| Step: 7
Training loss: 0.09692128002643585
Validation loss: 1.459011839282128

Epoch: 6| Step: 8
Training loss: 0.07784520089626312
Validation loss: 1.4400060856214134

Epoch: 6| Step: 9
Training loss: 0.2738893926143646
Validation loss: 1.4413836015168058

Epoch: 6| Step: 10
Training loss: 0.090673066675663
Validation loss: 1.4311940426467566

Epoch: 6| Step: 11
Training loss: 0.1330220252275467
Validation loss: 1.4260599895190167

Epoch: 6| Step: 12
Training loss: 0.08923126757144928
Validation loss: 1.422676779890573

Epoch: 6| Step: 13
Training loss: 0.09233897179365158
Validation loss: 1.4071352289568992

Epoch: 506| Step: 0
Training loss: 0.10100390017032623
Validation loss: 1.4378948544943204

Epoch: 6| Step: 1
Training loss: 0.07581353187561035
Validation loss: 1.4119515816370647

Epoch: 6| Step: 2
Training loss: 0.0782223790884018
Validation loss: 1.4584084364675707

Epoch: 6| Step: 3
Training loss: 0.08267954736948013
Validation loss: 1.4162379708341373

Epoch: 6| Step: 4
Training loss: 0.08128632605075836
Validation loss: 1.4275955000231344

Epoch: 6| Step: 5
Training loss: 0.11471111327409744
Validation loss: 1.3922594965145152

Epoch: 6| Step: 6
Training loss: 0.10073426365852356
Validation loss: 1.4215564650873984

Epoch: 6| Step: 7
Training loss: 0.09577937424182892
Validation loss: 1.4116298126918014

Epoch: 6| Step: 8
Training loss: 0.0968254953622818
Validation loss: 1.4363378222270677

Epoch: 6| Step: 9
Training loss: 0.08627956360578537
Validation loss: 1.4974263445023568

Epoch: 6| Step: 10
Training loss: 0.1391707956790924
Validation loss: 1.521254099184467

Epoch: 6| Step: 11
Training loss: 0.12479528784751892
Validation loss: 1.5732310933451499

Epoch: 6| Step: 12
Training loss: 0.3211759626865387
Validation loss: 1.5516205526167346

Epoch: 6| Step: 13
Training loss: 0.09248469769954681
Validation loss: 1.575600984275982

Epoch: 507| Step: 0
Training loss: 0.28616490960121155
Validation loss: 1.540797184872371

Epoch: 6| Step: 1
Training loss: 0.11979204416275024
Validation loss: 1.5069282259992374

Epoch: 6| Step: 2
Training loss: 0.0895470678806305
Validation loss: 1.4808690394124677

Epoch: 6| Step: 3
Training loss: 0.12391401827335358
Validation loss: 1.442137384927401

Epoch: 6| Step: 4
Training loss: 0.044640667736530304
Validation loss: 1.4236648057096748

Epoch: 6| Step: 5
Training loss: 0.08549122512340546
Validation loss: 1.3693597803833664

Epoch: 6| Step: 6
Training loss: 0.21316348016262054
Validation loss: 1.363898834874553

Epoch: 6| Step: 7
Training loss: 0.1628221869468689
Validation loss: 1.3165847537338093

Epoch: 6| Step: 8
Training loss: 0.1098746657371521
Validation loss: 1.3265415481341782

Epoch: 6| Step: 9
Training loss: 0.13157173991203308
Validation loss: 1.3205536014290267

Epoch: 6| Step: 10
Training loss: 0.13729074597358704
Validation loss: 1.3224996097626225

Epoch: 6| Step: 11
Training loss: 0.1689099669456482
Validation loss: 1.3602716192122428

Epoch: 6| Step: 12
Training loss: 0.1294158697128296
Validation loss: 1.3488965649758615

Epoch: 6| Step: 13
Training loss: 0.1102532148361206
Validation loss: 1.3668422468246952

Epoch: 508| Step: 0
Training loss: 0.10110285878181458
Validation loss: 1.3893835775313839

Epoch: 6| Step: 1
Training loss: 0.07712209224700928
Validation loss: 1.418867559843166

Epoch: 6| Step: 2
Training loss: 0.08643245697021484
Validation loss: 1.4505114824541154

Epoch: 6| Step: 3
Training loss: 0.08032546192407608
Validation loss: 1.4540457289705995

Epoch: 6| Step: 4
Training loss: 0.08568277209997177
Validation loss: 1.477446686836981

Epoch: 6| Step: 5
Training loss: 0.10702353715896606
Validation loss: 1.4741533481946556

Epoch: 6| Step: 6
Training loss: 0.09317658841609955
Validation loss: 1.4587082632126347

Epoch: 6| Step: 7
Training loss: 0.1819322407245636
Validation loss: 1.4912989293375323

Epoch: 6| Step: 8
Training loss: 0.07652412354946136
Validation loss: 1.456299235743861

Epoch: 6| Step: 9
Training loss: 0.20251688361167908
Validation loss: 1.434458581350183

Epoch: 6| Step: 10
Training loss: 0.10767656564712524
Validation loss: 1.4313393690252816

Epoch: 6| Step: 11
Training loss: 0.06728747487068176
Validation loss: 1.4356816750700756

Epoch: 6| Step: 12
Training loss: 0.08355239033699036
Validation loss: 1.4056695558691537

Epoch: 6| Step: 13
Training loss: 0.08325418084859848
Validation loss: 1.4038858759787776

Epoch: 509| Step: 0
Training loss: 0.10650502890348434
Validation loss: 1.4182224414681877

Epoch: 6| Step: 1
Training loss: 0.1785934716463089
Validation loss: 1.4094416902911278

Epoch: 6| Step: 2
Training loss: 0.13390815258026123
Validation loss: 1.4109942502872919

Epoch: 6| Step: 3
Training loss: 0.1156192272901535
Validation loss: 1.417766224312526

Epoch: 6| Step: 4
Training loss: 0.11432896554470062
Validation loss: 1.4335402199017104

Epoch: 6| Step: 5
Training loss: 0.07565172016620636
Validation loss: 1.4482190737160303

Epoch: 6| Step: 6
Training loss: 0.08953844010829926
Validation loss: 1.4622236708159089

Epoch: 6| Step: 7
Training loss: 0.0926712155342102
Validation loss: 1.4844062866703156

Epoch: 6| Step: 8
Training loss: 0.08645543456077576
Validation loss: 1.456169186099883

Epoch: 6| Step: 9
Training loss: 0.08654270321130753
Validation loss: 1.452037211387388

Epoch: 6| Step: 10
Training loss: 0.10521060228347778
Validation loss: 1.4213422620168297

Epoch: 6| Step: 11
Training loss: 0.1138903796672821
Validation loss: 1.4336152326676153

Epoch: 6| Step: 12
Training loss: 0.07268396764993668
Validation loss: 1.3957194884618123

Epoch: 6| Step: 13
Training loss: 0.09889311343431473
Validation loss: 1.3852663258070588

Epoch: 510| Step: 0
Training loss: 0.08944575488567352
Validation loss: 1.408977844381845

Epoch: 6| Step: 1
Training loss: 0.04860885441303253
Validation loss: 1.41406334728323

Epoch: 6| Step: 2
Training loss: 0.14222656190395355
Validation loss: 1.4157254054982176

Epoch: 6| Step: 3
Training loss: 0.07173490524291992
Validation loss: 1.4362024991743025

Epoch: 6| Step: 4
Training loss: 0.07570395618677139
Validation loss: 1.468197077833196

Epoch: 6| Step: 5
Training loss: 0.06951047480106354
Validation loss: 1.4469932266460952

Epoch: 6| Step: 6
Training loss: 0.11828424036502838
Validation loss: 1.4431510253619122

Epoch: 6| Step: 7
Training loss: 0.07048702985048294
Validation loss: 1.4545072688851306

Epoch: 6| Step: 8
Training loss: 0.05310223996639252
Validation loss: 1.4463814073993313

Epoch: 6| Step: 9
Training loss: 0.056923434138298035
Validation loss: 1.3916990955670674

Epoch: 6| Step: 10
Training loss: 0.06105466187000275
Validation loss: 1.3922001290064987

Epoch: 6| Step: 11
Training loss: 0.21625444293022156
Validation loss: 1.3752217427376778

Epoch: 6| Step: 12
Training loss: 0.06618332117795944
Validation loss: 1.3978680872148084

Epoch: 6| Step: 13
Training loss: 0.10759762674570084
Validation loss: 1.394054643569454

Epoch: 511| Step: 0
Training loss: 0.06424130499362946
Validation loss: 1.3857283297405447

Epoch: 6| Step: 1
Training loss: 0.12695924937725067
Validation loss: 1.3739106892257609

Epoch: 6| Step: 2
Training loss: 0.13693518936634064
Validation loss: 1.3612454988623177

Epoch: 6| Step: 3
Training loss: 0.04899223893880844
Validation loss: 1.3643645919779295

Epoch: 6| Step: 4
Training loss: 0.08992653340101242
Validation loss: 1.3758621908003283

Epoch: 6| Step: 5
Training loss: 0.08316713571548462
Validation loss: 1.3766966186543947

Epoch: 6| Step: 6
Training loss: 0.10384848713874817
Validation loss: 1.3758028694378432

Epoch: 6| Step: 7
Training loss: 0.10832826793193817
Validation loss: 1.3977238478199128

Epoch: 6| Step: 8
Training loss: 0.08501197397708893
Validation loss: 1.4125198888522323

Epoch: 6| Step: 9
Training loss: 0.13198387622833252
Validation loss: 1.418688807436215

Epoch: 6| Step: 10
Training loss: 0.14110851287841797
Validation loss: 1.447501705538842

Epoch: 6| Step: 11
Training loss: 0.1776043176651001
Validation loss: 1.4514869079794934

Epoch: 6| Step: 12
Training loss: 0.08852985501289368
Validation loss: 1.433519131393843

Epoch: 6| Step: 13
Training loss: 0.09261059761047363
Validation loss: 1.452633160416798

Epoch: 512| Step: 0
Training loss: 0.11986780166625977
Validation loss: 1.4310265753858833

Epoch: 6| Step: 1
Training loss: 0.09769843518733978
Validation loss: 1.4392793627195462

Epoch: 6| Step: 2
Training loss: 0.10066334903240204
Validation loss: 1.4188872498850669

Epoch: 6| Step: 3
Training loss: 0.1629885882139206
Validation loss: 1.4182934773865568

Epoch: 6| Step: 4
Training loss: 0.05491034314036369
Validation loss: 1.401918064522487

Epoch: 6| Step: 5
Training loss: 0.11764335632324219
Validation loss: 1.3960113563845236

Epoch: 6| Step: 6
Training loss: 0.06004539132118225
Validation loss: 1.3944321101711643

Epoch: 6| Step: 7
Training loss: 0.0744117945432663
Validation loss: 1.379966934521993

Epoch: 6| Step: 8
Training loss: 0.11625102907419205
Validation loss: 1.3833564865973689

Epoch: 6| Step: 9
Training loss: 0.1022406667470932
Validation loss: 1.4117096957340036

Epoch: 6| Step: 10
Training loss: 0.0682750791311264
Validation loss: 1.3914754788080852

Epoch: 6| Step: 11
Training loss: 0.0766473263502121
Validation loss: 1.4042431724968778

Epoch: 6| Step: 12
Training loss: 0.10624320060014725
Validation loss: 1.3856256290148663

Epoch: 6| Step: 13
Training loss: 0.09657308459281921
Validation loss: 1.3921964066002959

Epoch: 513| Step: 0
Training loss: 0.10425791889429092
Validation loss: 1.4300095547911942

Epoch: 6| Step: 1
Training loss: 0.11319927871227264
Validation loss: 1.450606007088897

Epoch: 6| Step: 2
Training loss: 0.09509487450122833
Validation loss: 1.4804401551523516

Epoch: 6| Step: 3
Training loss: 0.054187972098588943
Validation loss: 1.4648026253587456

Epoch: 6| Step: 4
Training loss: 0.06763416528701782
Validation loss: 1.4981357423208093

Epoch: 6| Step: 5
Training loss: 0.17442159354686737
Validation loss: 1.4963354205572477

Epoch: 6| Step: 6
Training loss: 0.07651248574256897
Validation loss: 1.52789024255609

Epoch: 6| Step: 7
Training loss: 0.09558693319559097
Validation loss: 1.5388417154230096

Epoch: 6| Step: 8
Training loss: 0.10333992540836334
Validation loss: 1.5419003130287252

Epoch: 6| Step: 9
Training loss: 0.12080202251672745
Validation loss: 1.5160436194430116

Epoch: 6| Step: 10
Training loss: 0.062082741409540176
Validation loss: 1.5176583118336175

Epoch: 6| Step: 11
Training loss: 0.07781651616096497
Validation loss: 1.4756613572438557

Epoch: 6| Step: 12
Training loss: 0.07405519485473633
Validation loss: 1.4412673609231108

Epoch: 6| Step: 13
Training loss: 0.04835273325443268
Validation loss: 1.4328575108640937

Epoch: 514| Step: 0
Training loss: 0.06678107380867004
Validation loss: 1.433363191543087

Epoch: 6| Step: 1
Training loss: 0.08415061235427856
Validation loss: 1.4291366684821345

Epoch: 6| Step: 2
Training loss: 0.19188326597213745
Validation loss: 1.4235069444102626

Epoch: 6| Step: 3
Training loss: 0.1157737523317337
Validation loss: 1.4246991680514427

Epoch: 6| Step: 4
Training loss: 0.08102181553840637
Validation loss: 1.4220204135423065

Epoch: 6| Step: 5
Training loss: 0.07656535506248474
Validation loss: 1.4270646290112567

Epoch: 6| Step: 6
Training loss: 0.08944830298423767
Validation loss: 1.3978130106003053

Epoch: 6| Step: 7
Training loss: 0.08850600570440292
Validation loss: 1.4118297330794796

Epoch: 6| Step: 8
Training loss: 0.10813193768262863
Validation loss: 1.4183403574010378

Epoch: 6| Step: 9
Training loss: 0.06595565378665924
Validation loss: 1.3983075952017179

Epoch: 6| Step: 10
Training loss: 0.13843947649002075
Validation loss: 1.4328687806283273

Epoch: 6| Step: 11
Training loss: 0.07890331745147705
Validation loss: 1.4154206373358285

Epoch: 6| Step: 12
Training loss: 0.07433158904314041
Validation loss: 1.4091261567608002

Epoch: 6| Step: 13
Training loss: 0.060089562088251114
Validation loss: 1.4258328035313597

Epoch: 515| Step: 0
Training loss: 0.10587191581726074
Validation loss: 1.4372999155393211

Epoch: 6| Step: 1
Training loss: 0.08128917217254639
Validation loss: 1.4325763230682702

Epoch: 6| Step: 2
Training loss: 0.13387538492679596
Validation loss: 1.4463442474283197

Epoch: 6| Step: 3
Training loss: 0.06300687789916992
Validation loss: 1.4793030574757566

Epoch: 6| Step: 4
Training loss: 0.12115195393562317
Validation loss: 1.4859523427101873

Epoch: 6| Step: 5
Training loss: 0.06513485312461853
Validation loss: 1.4846710761388142

Epoch: 6| Step: 6
Training loss: 0.05637542903423309
Validation loss: 1.5135999430892288

Epoch: 6| Step: 7
Training loss: 0.1014457419514656
Validation loss: 1.536741054186257

Epoch: 6| Step: 8
Training loss: 0.19322553277015686
Validation loss: 1.4950247977369575

Epoch: 6| Step: 9
Training loss: 0.1020837128162384
Validation loss: 1.5144161940902792

Epoch: 6| Step: 10
Training loss: 0.16355587542057037
Validation loss: 1.4811902007749003

Epoch: 6| Step: 11
Training loss: 0.05925627052783966
Validation loss: 1.4550678114737234

Epoch: 6| Step: 12
Training loss: 0.04557562619447708
Validation loss: 1.4517587795052478

Epoch: 6| Step: 13
Training loss: 0.047524094581604004
Validation loss: 1.4118802598727647

Epoch: 516| Step: 0
Training loss: 0.08779259026050568
Validation loss: 1.3983824663264777

Epoch: 6| Step: 1
Training loss: 0.1296868771314621
Validation loss: 1.422791196453956

Epoch: 6| Step: 2
Training loss: 0.06420278549194336
Validation loss: 1.3827397977152178

Epoch: 6| Step: 3
Training loss: 0.05460154265165329
Validation loss: 1.4120402066938338

Epoch: 6| Step: 4
Training loss: 0.08968313038349152
Validation loss: 1.406429588153798

Epoch: 6| Step: 5
Training loss: 0.24656571447849274
Validation loss: 1.4144566110385361

Epoch: 6| Step: 6
Training loss: 0.09046457707881927
Validation loss: 1.4283239931188605

Epoch: 6| Step: 7
Training loss: 0.10777869820594788
Validation loss: 1.403696071717047

Epoch: 6| Step: 8
Training loss: 0.09898053854703903
Validation loss: 1.4116307317569692

Epoch: 6| Step: 9
Training loss: 0.060792192816734314
Validation loss: 1.4418723096129715

Epoch: 6| Step: 10
Training loss: 0.09065710008144379
Validation loss: 1.4638390694895098

Epoch: 6| Step: 11
Training loss: 0.08321289718151093
Validation loss: 1.4502389713000226

Epoch: 6| Step: 12
Training loss: 0.0727267861366272
Validation loss: 1.4692133370266165

Epoch: 6| Step: 13
Training loss: 0.08312816917896271
Validation loss: 1.4751445862554735

Epoch: 517| Step: 0
Training loss: 0.07053681463003159
Validation loss: 1.5049534061903596

Epoch: 6| Step: 1
Training loss: 0.10883428156375885
Validation loss: 1.5226082135272283

Epoch: 6| Step: 2
Training loss: 0.13836196064949036
Validation loss: 1.4863700046334216

Epoch: 6| Step: 3
Training loss: 0.07791837304830551
Validation loss: 1.4727384659551805

Epoch: 6| Step: 4
Training loss: 0.054797884076833725
Validation loss: 1.4484017536204348

Epoch: 6| Step: 5
Training loss: 0.10212972015142441
Validation loss: 1.4276347878158733

Epoch: 6| Step: 6
Training loss: 0.10212502628564835
Validation loss: 1.431972408807406

Epoch: 6| Step: 7
Training loss: 0.09234687685966492
Validation loss: 1.4146169135647435

Epoch: 6| Step: 8
Training loss: 0.09499433636665344
Validation loss: 1.421798598381781

Epoch: 6| Step: 9
Training loss: 0.07644720375537872
Validation loss: 1.4297118827860842

Epoch: 6| Step: 10
Training loss: 0.05253393203020096
Validation loss: 1.404471638382122

Epoch: 6| Step: 11
Training loss: 0.08132774382829666
Validation loss: 1.3938160327173048

Epoch: 6| Step: 12
Training loss: 0.07728681713342667
Validation loss: 1.388232296512973

Epoch: 6| Step: 13
Training loss: 0.3033909499645233
Validation loss: 1.3782362540562947

Epoch: 518| Step: 0
Training loss: 0.06510882079601288
Validation loss: 1.3923532398798133

Epoch: 6| Step: 1
Training loss: 0.053662851452827454
Validation loss: 1.413566074063701

Epoch: 6| Step: 2
Training loss: 0.08359122276306152
Validation loss: 1.4166891670996142

Epoch: 6| Step: 3
Training loss: 0.050715554505586624
Validation loss: 1.44572449755925

Epoch: 6| Step: 4
Training loss: 0.23157186806201935
Validation loss: 1.4702081321388163

Epoch: 6| Step: 5
Training loss: 0.1367216408252716
Validation loss: 1.4449649805663733

Epoch: 6| Step: 6
Training loss: 0.12828002870082855
Validation loss: 1.4677456143081828

Epoch: 6| Step: 7
Training loss: 0.10263808816671371
Validation loss: 1.4948228841186852

Epoch: 6| Step: 8
Training loss: 0.04894139617681503
Validation loss: 1.5080053421758837

Epoch: 6| Step: 9
Training loss: 0.0689534917473793
Validation loss: 1.49419564970078

Epoch: 6| Step: 10
Training loss: 0.10447751730680466
Validation loss: 1.476201677835116

Epoch: 6| Step: 11
Training loss: 0.07055972516536713
Validation loss: 1.4824062893467564

Epoch: 6| Step: 12
Training loss: 0.05239906907081604
Validation loss: 1.4782099223905993

Epoch: 6| Step: 13
Training loss: 0.11942695081233978
Validation loss: 1.4661265304011684

Epoch: 519| Step: 0
Training loss: 0.10112529247999191
Validation loss: 1.4716798156820319

Epoch: 6| Step: 1
Training loss: 0.1138080433011055
Validation loss: 1.490178096678949

Epoch: 6| Step: 2
Training loss: 0.053638845682144165
Validation loss: 1.4747103965410622

Epoch: 6| Step: 3
Training loss: 0.05954597145318985
Validation loss: 1.4735892280455558

Epoch: 6| Step: 4
Training loss: 0.19671015441417694
Validation loss: 1.478973755272486

Epoch: 6| Step: 5
Training loss: 0.06899750232696533
Validation loss: 1.484549101962838

Epoch: 6| Step: 6
Training loss: 0.0698414146900177
Validation loss: 1.468810373736966

Epoch: 6| Step: 7
Training loss: 0.07441513985395432
Validation loss: 1.472212005046106

Epoch: 6| Step: 8
Training loss: 0.07420425862073898
Validation loss: 1.43503402638179

Epoch: 6| Step: 9
Training loss: 0.056048281490802765
Validation loss: 1.4376737699713757

Epoch: 6| Step: 10
Training loss: 0.09588928520679474
Validation loss: 1.4403949386330062

Epoch: 6| Step: 11
Training loss: 0.03988104686141014
Validation loss: 1.445337559587212

Epoch: 6| Step: 12
Training loss: 0.08444741368293762
Validation loss: 1.4386461768099057

Epoch: 6| Step: 13
Training loss: 0.08071887493133545
Validation loss: 1.442489367659374

Epoch: 520| Step: 0
Training loss: 0.0629567801952362
Validation loss: 1.446143525902943

Epoch: 6| Step: 1
Training loss: 0.05203152447938919
Validation loss: 1.4442696571350098

Epoch: 6| Step: 2
Training loss: 0.06757432222366333
Validation loss: 1.4499496734270485

Epoch: 6| Step: 3
Training loss: 0.09322425723075867
Validation loss: 1.4224955702340731

Epoch: 6| Step: 4
Training loss: 0.06359351426362991
Validation loss: 1.4346152056929886

Epoch: 6| Step: 5
Training loss: 0.05161204934120178
Validation loss: 1.439277566889281

Epoch: 6| Step: 6
Training loss: 0.1129312515258789
Validation loss: 1.4430987899021437

Epoch: 6| Step: 7
Training loss: 0.06549106538295746
Validation loss: 1.4305965823511924

Epoch: 6| Step: 8
Training loss: 0.0743461325764656
Validation loss: 1.423731029674571

Epoch: 6| Step: 9
Training loss: 0.060657426714897156
Validation loss: 1.3979623266445693

Epoch: 6| Step: 10
Training loss: 0.1634020060300827
Validation loss: 1.370012661462189

Epoch: 6| Step: 11
Training loss: 0.06027546897530556
Validation loss: 1.3723161105186708

Epoch: 6| Step: 12
Training loss: 0.12518660724163055
Validation loss: 1.355753367946994

Epoch: 6| Step: 13
Training loss: 0.09540112316608429
Validation loss: 1.3517430879736458

Epoch: 521| Step: 0
Training loss: 0.1070813536643982
Validation loss: 1.35966750883287

Epoch: 6| Step: 1
Training loss: 0.15035021305084229
Validation loss: 1.35553176172318

Epoch: 6| Step: 2
Training loss: 0.0564362071454525
Validation loss: 1.3682107656232771

Epoch: 6| Step: 3
Training loss: 0.06114464998245239
Validation loss: 1.3885820469548624

Epoch: 6| Step: 4
Training loss: 0.05119963735342026
Validation loss: 1.4090860325803038

Epoch: 6| Step: 5
Training loss: 0.1353762447834015
Validation loss: 1.4168571823386735

Epoch: 6| Step: 6
Training loss: 0.10909702628850937
Validation loss: 1.4164921115803462

Epoch: 6| Step: 7
Training loss: 0.07699471712112427
Validation loss: 1.462987055060684

Epoch: 6| Step: 8
Training loss: 0.04538016766309738
Validation loss: 1.4545626922320294

Epoch: 6| Step: 9
Training loss: 0.0583178736269474
Validation loss: 1.463465367594073

Epoch: 6| Step: 10
Training loss: 0.07178892940282822
Validation loss: 1.4528760756215742

Epoch: 6| Step: 11
Training loss: 0.043125517666339874
Validation loss: 1.4736160257811188

Epoch: 6| Step: 12
Training loss: 0.06997500360012054
Validation loss: 1.4560429960168817

Epoch: 6| Step: 13
Training loss: 0.07990054041147232
Validation loss: 1.4599807441875499

Epoch: 522| Step: 0
Training loss: 0.07894064486026764
Validation loss: 1.4624982380097913

Epoch: 6| Step: 1
Training loss: 0.05058646574616432
Validation loss: 1.4461712375763924

Epoch: 6| Step: 2
Training loss: 0.06410080939531326
Validation loss: 1.461296066161125

Epoch: 6| Step: 3
Training loss: 0.055872589349746704
Validation loss: 1.4245476761171896

Epoch: 6| Step: 4
Training loss: 0.20382708311080933
Validation loss: 1.4497854863443682

Epoch: 6| Step: 5
Training loss: 0.0966377928853035
Validation loss: 1.4002816286138309

Epoch: 6| Step: 6
Training loss: 0.09600604325532913
Validation loss: 1.4054639083082958

Epoch: 6| Step: 7
Training loss: 0.04625552147626877
Validation loss: 1.4206339018319243

Epoch: 6| Step: 8
Training loss: 0.044679976999759674
Validation loss: 1.409711230185724

Epoch: 6| Step: 9
Training loss: 0.06905923783779144
Validation loss: 1.3825345475186583

Epoch: 6| Step: 10
Training loss: 0.0996706485748291
Validation loss: 1.368423338218402

Epoch: 6| Step: 11
Training loss: 0.05119304358959198
Validation loss: 1.3787193541885705

Epoch: 6| Step: 12
Training loss: 0.08206567168235779
Validation loss: 1.3818720117692025

Epoch: 6| Step: 13
Training loss: 0.05735095217823982
Validation loss: 1.3785795447646931

Epoch: 523| Step: 0
Training loss: 0.10296987742185593
Validation loss: 1.4037746601207282

Epoch: 6| Step: 1
Training loss: 0.0929412990808487
Validation loss: 1.3965977699525896

Epoch: 6| Step: 2
Training loss: 0.10219176113605499
Validation loss: 1.4520565168831938

Epoch: 6| Step: 3
Training loss: 0.07580374926328659
Validation loss: 1.439217593080254

Epoch: 6| Step: 4
Training loss: 0.06817768514156342
Validation loss: 1.434706304662971

Epoch: 6| Step: 5
Training loss: 0.06795530021190643
Validation loss: 1.4630000347732215

Epoch: 6| Step: 6
Training loss: 0.08201787620782852
Validation loss: 1.458593448003133

Epoch: 6| Step: 7
Training loss: 0.09635353088378906
Validation loss: 1.4516564440983597

Epoch: 6| Step: 8
Training loss: 0.06459100544452667
Validation loss: 1.4368628571110387

Epoch: 6| Step: 9
Training loss: 0.08495554327964783
Validation loss: 1.4428972403208415

Epoch: 6| Step: 10
Training loss: 0.17343997955322266
Validation loss: 1.4600499330028411

Epoch: 6| Step: 11
Training loss: 0.10633251816034317
Validation loss: 1.429084720150117

Epoch: 6| Step: 12
Training loss: 0.06727423518896103
Validation loss: 1.4512836035861765

Epoch: 6| Step: 13
Training loss: 0.19107641279697418
Validation loss: 1.4394749031271985

Epoch: 524| Step: 0
Training loss: 0.07842016965150833
Validation loss: 1.4497094590176818

Epoch: 6| Step: 1
Training loss: 0.18770895898342133
Validation loss: 1.4378588276524698

Epoch: 6| Step: 2
Training loss: 0.08917227387428284
Validation loss: 1.4457689151969007

Epoch: 6| Step: 3
Training loss: 0.09308560192584991
Validation loss: 1.4116293602092291

Epoch: 6| Step: 4
Training loss: 0.07319189608097076
Validation loss: 1.4013593184050692

Epoch: 6| Step: 5
Training loss: 0.07276570796966553
Validation loss: 1.406192502667827

Epoch: 6| Step: 6
Training loss: 0.0683697983622551
Validation loss: 1.393776838497449

Epoch: 6| Step: 7
Training loss: 0.1152084469795227
Validation loss: 1.3778757856738182

Epoch: 6| Step: 8
Training loss: 0.11846024543046951
Validation loss: 1.3863544643566172

Epoch: 6| Step: 9
Training loss: 0.09453921020030975
Validation loss: 1.4077226243993288

Epoch: 6| Step: 10
Training loss: 0.05482334643602371
Validation loss: 1.4209218691754084

Epoch: 6| Step: 11
Training loss: 0.09585174173116684
Validation loss: 1.4441201167721902

Epoch: 6| Step: 12
Training loss: 0.06825941056013107
Validation loss: 1.4665960445198962

Epoch: 6| Step: 13
Training loss: 0.05408402904868126
Validation loss: 1.4835599231463608

Epoch: 525| Step: 0
Training loss: 0.0668739378452301
Validation loss: 1.488575134226071

Epoch: 6| Step: 1
Training loss: 0.17754614353179932
Validation loss: 1.4907932819858674

Epoch: 6| Step: 2
Training loss: 0.10519678890705109
Validation loss: 1.509158585661201

Epoch: 6| Step: 3
Training loss: 0.06511883437633514
Validation loss: 1.5064129175678376

Epoch: 6| Step: 4
Training loss: 0.08019692450761795
Validation loss: 1.5087669254631124

Epoch: 6| Step: 5
Training loss: 0.07115282863378525
Validation loss: 1.5093568499370287

Epoch: 6| Step: 6
Training loss: 0.10047318786382675
Validation loss: 1.4862887346616356

Epoch: 6| Step: 7
Training loss: 0.09144310653209686
Validation loss: 1.4868753135845225

Epoch: 6| Step: 8
Training loss: 0.07952374219894409
Validation loss: 1.4611779964098366

Epoch: 6| Step: 9
Training loss: 0.06681989878416061
Validation loss: 1.4470007765677668

Epoch: 6| Step: 10
Training loss: 0.07139251381158829
Validation loss: 1.4600750438628658

Epoch: 6| Step: 11
Training loss: 0.06467360258102417
Validation loss: 1.425458885008289

Epoch: 6| Step: 12
Training loss: 0.08377604186534882
Validation loss: 1.417017779042644

Epoch: 6| Step: 13
Training loss: 0.14672404527664185
Validation loss: 1.4069655146650089

Epoch: 526| Step: 0
Training loss: 0.09668786823749542
Validation loss: 1.3982441784233175

Epoch: 6| Step: 1
Training loss: 0.06565924733877182
Validation loss: 1.3903788763989684

Epoch: 6| Step: 2
Training loss: 0.07148110866546631
Validation loss: 1.4132783233478505

Epoch: 6| Step: 3
Training loss: 0.06374785304069519
Validation loss: 1.427136121257659

Epoch: 6| Step: 4
Training loss: 0.03918159380555153
Validation loss: 1.431941863670144

Epoch: 6| Step: 5
Training loss: 0.09419094026088715
Validation loss: 1.4382030322987547

Epoch: 6| Step: 6
Training loss: 0.10689285397529602
Validation loss: 1.4455529720552507

Epoch: 6| Step: 7
Training loss: 0.07090043276548386
Validation loss: 1.424130279530761

Epoch: 6| Step: 8
Training loss: 0.08593150973320007
Validation loss: 1.4511964487773117

Epoch: 6| Step: 9
Training loss: 0.10478387773036957
Validation loss: 1.4384245340542128

Epoch: 6| Step: 10
Training loss: 0.05617005378007889
Validation loss: 1.418286467111239

Epoch: 6| Step: 11
Training loss: 0.0839177742600441
Validation loss: 1.4393375112164406

Epoch: 6| Step: 12
Training loss: 0.17611901462078094
Validation loss: 1.4025671135994695

Epoch: 6| Step: 13
Training loss: 0.08103325963020325
Validation loss: 1.3892625506206224

Epoch: 527| Step: 0
Training loss: 0.06515215337276459
Validation loss: 1.3835064224017564

Epoch: 6| Step: 1
Training loss: 0.1785348653793335
Validation loss: 1.3545484081391366

Epoch: 6| Step: 2
Training loss: 0.10096185654401779
Validation loss: 1.3696004165116178

Epoch: 6| Step: 3
Training loss: 0.08597588539123535
Validation loss: 1.3247973957369406

Epoch: 6| Step: 4
Training loss: 0.05874679237604141
Validation loss: 1.3646870813062113

Epoch: 6| Step: 5
Training loss: 0.08357065916061401
Validation loss: 1.3824316660563152

Epoch: 6| Step: 6
Training loss: 0.11344089359045029
Validation loss: 1.3910615591592685

Epoch: 6| Step: 7
Training loss: 0.08987927436828613
Validation loss: 1.3721164516223374

Epoch: 6| Step: 8
Training loss: 0.12267646938562393
Validation loss: 1.3634960587306688

Epoch: 6| Step: 9
Training loss: 0.10398624837398529
Validation loss: 1.3765182648935625

Epoch: 6| Step: 10
Training loss: 0.09768719971179962
Validation loss: 1.3345568641539542

Epoch: 6| Step: 11
Training loss: 0.10558603703975677
Validation loss: 1.370031455511688

Epoch: 6| Step: 12
Training loss: 0.1305561363697052
Validation loss: 1.3734051745424989

Epoch: 6| Step: 13
Training loss: 0.03504888713359833
Validation loss: 1.395661997538741

Epoch: 528| Step: 0
Training loss: 0.08396028727293015
Validation loss: 1.3937374199590375

Epoch: 6| Step: 1
Training loss: 0.08610966801643372
Validation loss: 1.4231064678520284

Epoch: 6| Step: 2
Training loss: 0.09753722697496414
Validation loss: 1.4691810172091249

Epoch: 6| Step: 3
Training loss: 0.11010652780532837
Validation loss: 1.4532747473768008

Epoch: 6| Step: 4
Training loss: 0.14063161611557007
Validation loss: 1.4565757987319783

Epoch: 6| Step: 5
Training loss: 0.08173775672912598
Validation loss: 1.4399281355642504

Epoch: 6| Step: 6
Training loss: 0.11576980352401733
Validation loss: 1.4142851611619354

Epoch: 6| Step: 7
Training loss: 0.09341473132371902
Validation loss: 1.4235087966406217

Epoch: 6| Step: 8
Training loss: 0.07348034530878067
Validation loss: 1.4171164503661535

Epoch: 6| Step: 9
Training loss: 0.11284203827381134
Validation loss: 1.4574094626211351

Epoch: 6| Step: 10
Training loss: 0.09675794839859009
Validation loss: 1.4305516199399066

Epoch: 6| Step: 11
Training loss: 0.23732289671897888
Validation loss: 1.4275835996033044

Epoch: 6| Step: 12
Training loss: 0.11835359036922455
Validation loss: 1.455688613717274

Epoch: 6| Step: 13
Training loss: 0.07622703164815903
Validation loss: 1.468095842228141

Epoch: 529| Step: 0
Training loss: 0.051184386014938354
Validation loss: 1.45786073130946

Epoch: 6| Step: 1
Training loss: 0.0906103253364563
Validation loss: 1.4211541093805784

Epoch: 6| Step: 2
Training loss: 0.11954380571842194
Validation loss: 1.4130853581172165

Epoch: 6| Step: 3
Training loss: 0.08342771232128143
Validation loss: 1.414556436641242

Epoch: 6| Step: 4
Training loss: 0.1382327824831009
Validation loss: 1.4056510117746168

Epoch: 6| Step: 5
Training loss: 0.10684511810541153
Validation loss: 1.4401065393160748

Epoch: 6| Step: 6
Training loss: 0.05688631162047386
Validation loss: 1.4365459898466706

Epoch: 6| Step: 7
Training loss: 0.08211582899093628
Validation loss: 1.4480512167817803

Epoch: 6| Step: 8
Training loss: 0.0947590321302414
Validation loss: 1.4578686311680784

Epoch: 6| Step: 9
Training loss: 0.1276179701089859
Validation loss: 1.4813482569110008

Epoch: 6| Step: 10
Training loss: 0.15020708739757538
Validation loss: 1.4821320464534145

Epoch: 6| Step: 11
Training loss: 0.2552725374698639
Validation loss: 1.4814659498071159

Epoch: 6| Step: 12
Training loss: 0.10639695078134537
Validation loss: 1.4698890204070716

Epoch: 6| Step: 13
Training loss: 0.04937746748328209
Validation loss: 1.4504842168541365

Epoch: 530| Step: 0
Training loss: 0.0890779197216034
Validation loss: 1.446727152793638

Epoch: 6| Step: 1
Training loss: 0.0895521491765976
Validation loss: 1.4717553828352241

Epoch: 6| Step: 2
Training loss: 0.11145289987325668
Validation loss: 1.470604053107641

Epoch: 6| Step: 3
Training loss: 0.20699626207351685
Validation loss: 1.5071524163728118

Epoch: 6| Step: 4
Training loss: 0.10742517560720444
Validation loss: 1.467312923041723

Epoch: 6| Step: 5
Training loss: 0.0657196119427681
Validation loss: 1.4765514648088844

Epoch: 6| Step: 6
Training loss: 0.05118900537490845
Validation loss: 1.4557009717469573

Epoch: 6| Step: 7
Training loss: 0.032106123864650726
Validation loss: 1.4450648074508996

Epoch: 6| Step: 8
Training loss: 0.05276796221733093
Validation loss: 1.4368771852985505

Epoch: 6| Step: 9
Training loss: 0.12210816890001297
Validation loss: 1.406990837025386

Epoch: 6| Step: 10
Training loss: 0.17770916223526
Validation loss: 1.437675364555851

Epoch: 6| Step: 11
Training loss: 0.08793279528617859
Validation loss: 1.4269426740625852

Epoch: 6| Step: 12
Training loss: 0.060454435646533966
Validation loss: 1.4185053481850574

Epoch: 6| Step: 13
Training loss: 0.06210744380950928
Validation loss: 1.4367263406835578

Epoch: 531| Step: 0
Training loss: 0.04016119986772537
Validation loss: 1.418314294148517

Epoch: 6| Step: 1
Training loss: 0.08719010651111603
Validation loss: 1.4311479983791229

Epoch: 6| Step: 2
Training loss: 0.05272815376520157
Validation loss: 1.4264091599372126

Epoch: 6| Step: 3
Training loss: 0.16061866283416748
Validation loss: 1.4428538084030151

Epoch: 6| Step: 4
Training loss: 0.06847313046455383
Validation loss: 1.4131044367308259

Epoch: 6| Step: 5
Training loss: 0.09423266351222992
Validation loss: 1.4436381068280948

Epoch: 6| Step: 6
Training loss: 0.05829306319355965
Validation loss: 1.4366921635084255

Epoch: 6| Step: 7
Training loss: 0.0868123322725296
Validation loss: 1.4469179735388806

Epoch: 6| Step: 8
Training loss: 0.06048908829689026
Validation loss: 1.4339954391602547

Epoch: 6| Step: 9
Training loss: 0.07981349527835846
Validation loss: 1.450137892077046

Epoch: 6| Step: 10
Training loss: 0.06228118762373924
Validation loss: 1.4617367059953752

Epoch: 6| Step: 11
Training loss: 0.0938710868358612
Validation loss: 1.4507223739418933

Epoch: 6| Step: 12
Training loss: 0.09094522148370743
Validation loss: 1.482767358902962

Epoch: 6| Step: 13
Training loss: 0.0839359238743782
Validation loss: 1.4498138876371487

Epoch: 532| Step: 0
Training loss: 0.14500553905963898
Validation loss: 1.4430018150678245

Epoch: 6| Step: 1
Training loss: 0.08370442688465118
Validation loss: 1.435209148673601

Epoch: 6| Step: 2
Training loss: 0.03840995952486992
Validation loss: 1.4238285556916268

Epoch: 6| Step: 3
Training loss: 0.046101249754428864
Validation loss: 1.4184270956182992

Epoch: 6| Step: 4
Training loss: 0.053074296563863754
Validation loss: 1.4289482229499406

Epoch: 6| Step: 5
Training loss: 0.06250564008951187
Validation loss: 1.3986722846185007

Epoch: 6| Step: 6
Training loss: 0.0481824055314064
Validation loss: 1.3754499689225228

Epoch: 6| Step: 7
Training loss: 0.11679594963788986
Validation loss: 1.392009913280446

Epoch: 6| Step: 8
Training loss: 0.09247881174087524
Validation loss: 1.364448837054673

Epoch: 6| Step: 9
Training loss: 0.1004263162612915
Validation loss: 1.3651451423604002

Epoch: 6| Step: 10
Training loss: 0.08367942273616791
Validation loss: 1.3680254182507914

Epoch: 6| Step: 11
Training loss: 0.0751974806189537
Validation loss: 1.3711836350861417

Epoch: 6| Step: 12
Training loss: 0.13385885953903198
Validation loss: 1.3468262662169754

Epoch: 6| Step: 13
Training loss: 0.04585327208042145
Validation loss: 1.344173255787101

Epoch: 533| Step: 0
Training loss: 0.05937428027391434
Validation loss: 1.3370197280760734

Epoch: 6| Step: 1
Training loss: 0.18798500299453735
Validation loss: 1.3511200720264065

Epoch: 6| Step: 2
Training loss: 0.08187428116798401
Validation loss: 1.3546538500375644

Epoch: 6| Step: 3
Training loss: 0.1054217740893364
Validation loss: 1.3276219291071738

Epoch: 6| Step: 4
Training loss: 0.06565862149000168
Validation loss: 1.3293725149605864

Epoch: 6| Step: 5
Training loss: 0.06240599602460861
Validation loss: 1.367697620904574

Epoch: 6| Step: 6
Training loss: 0.05198673531413078
Validation loss: 1.367085987521756

Epoch: 6| Step: 7
Training loss: 0.05775916203856468
Validation loss: 1.3727470264639905

Epoch: 6| Step: 8
Training loss: 0.11940237879753113
Validation loss: 1.3948323303653347

Epoch: 6| Step: 9
Training loss: 0.04278365895152092
Validation loss: 1.3755959913294802

Epoch: 6| Step: 10
Training loss: 0.11761756986379623
Validation loss: 1.3973932637963244

Epoch: 6| Step: 11
Training loss: 0.060570791363716125
Validation loss: 1.4155497371509511

Epoch: 6| Step: 12
Training loss: 0.07764829695224762
Validation loss: 1.4297148655819636

Epoch: 6| Step: 13
Training loss: 0.05563204735517502
Validation loss: 1.45837487072073

Epoch: 534| Step: 0
Training loss: 0.07377727329730988
Validation loss: 1.4349067108605498

Epoch: 6| Step: 1
Training loss: 0.03880305588245392
Validation loss: 1.4585576172797912

Epoch: 6| Step: 2
Training loss: 0.15967506170272827
Validation loss: 1.4811773556534962

Epoch: 6| Step: 3
Training loss: 0.07751695811748505
Validation loss: 1.4727369200798772

Epoch: 6| Step: 4
Training loss: 0.07417964935302734
Validation loss: 1.5180568554068123

Epoch: 6| Step: 5
Training loss: 0.053393032401800156
Validation loss: 1.4840027363069597

Epoch: 6| Step: 6
Training loss: 0.048719774931669235
Validation loss: 1.4924358693502282

Epoch: 6| Step: 7
Training loss: 0.08584922552108765
Validation loss: 1.4844318705220376

Epoch: 6| Step: 8
Training loss: 0.06368717551231384
Validation loss: 1.4638143136937132

Epoch: 6| Step: 9
Training loss: 0.07425223290920258
Validation loss: 1.4559698335586055

Epoch: 6| Step: 10
Training loss: 0.09606583416461945
Validation loss: 1.444206544788935

Epoch: 6| Step: 11
Training loss: 0.0439988374710083
Validation loss: 1.4765507585258895

Epoch: 6| Step: 12
Training loss: 0.05852510780096054
Validation loss: 1.4608872526435441

Epoch: 6| Step: 13
Training loss: 0.08805222809314728
Validation loss: 1.435983645018711

Epoch: 535| Step: 0
Training loss: 0.09528076648712158
Validation loss: 1.4576201015903103

Epoch: 6| Step: 1
Training loss: 0.1632010042667389
Validation loss: 1.4443369206561838

Epoch: 6| Step: 2
Training loss: 0.08574321866035461
Validation loss: 1.4068330000805598

Epoch: 6| Step: 3
Training loss: 0.09065324068069458
Validation loss: 1.3932835132844987

Epoch: 6| Step: 4
Training loss: 0.07068245112895966
Validation loss: 1.3864788073365406

Epoch: 6| Step: 5
Training loss: 0.058527424931526184
Validation loss: 1.3824700719566756

Epoch: 6| Step: 6
Training loss: 0.07416053861379623
Validation loss: 1.375416983840286

Epoch: 6| Step: 7
Training loss: 0.07988325506448746
Validation loss: 1.3627678437899517

Epoch: 6| Step: 8
Training loss: 0.09361737966537476
Validation loss: 1.3402796560718166

Epoch: 6| Step: 9
Training loss: 0.054387688636779785
Validation loss: 1.3652043278499315

Epoch: 6| Step: 10
Training loss: 0.05736538767814636
Validation loss: 1.371438801929515

Epoch: 6| Step: 11
Training loss: 0.06876051425933838
Validation loss: 1.358572449735416

Epoch: 6| Step: 12
Training loss: 0.10169294476509094
Validation loss: 1.4027448328592445

Epoch: 6| Step: 13
Training loss: 0.05686507746577263
Validation loss: 1.4217497533367527

Epoch: 536| Step: 0
Training loss: 0.04530606418848038
Validation loss: 1.437496082757109

Epoch: 6| Step: 1
Training loss: 0.04534061998128891
Validation loss: 1.4482401929875857

Epoch: 6| Step: 2
Training loss: 0.05368388816714287
Validation loss: 1.4375626476862098

Epoch: 6| Step: 3
Training loss: 0.06547623872756958
Validation loss: 1.4881478330140472

Epoch: 6| Step: 4
Training loss: 0.10282960534095764
Validation loss: 1.4762309956294235

Epoch: 6| Step: 5
Training loss: 0.0913001149892807
Validation loss: 1.4798119632146691

Epoch: 6| Step: 6
Training loss: 0.10981794446706772
Validation loss: 1.4807185678071872

Epoch: 6| Step: 7
Training loss: 0.04362776502966881
Validation loss: 1.4534405969804334

Epoch: 6| Step: 8
Training loss: 0.06984606385231018
Validation loss: 1.4496437426536315

Epoch: 6| Step: 9
Training loss: 0.09538647532463074
Validation loss: 1.4442613637575539

Epoch: 6| Step: 10
Training loss: 0.04184833914041519
Validation loss: 1.4275523642058014

Epoch: 6| Step: 11
Training loss: 0.06285106390714645
Validation loss: 1.4168227564903997

Epoch: 6| Step: 12
Training loss: 0.06006805598735809
Validation loss: 1.42223144859396

Epoch: 6| Step: 13
Training loss: 0.23906993865966797
Validation loss: 1.424225700798855

Epoch: 537| Step: 0
Training loss: 0.20143689215183258
Validation loss: 1.4344097805279556

Epoch: 6| Step: 1
Training loss: 0.07283684611320496
Validation loss: 1.4139779895864508

Epoch: 6| Step: 2
Training loss: 0.05617883801460266
Validation loss: 1.4101289709409077

Epoch: 6| Step: 3
Training loss: 0.08661884069442749
Validation loss: 1.4384952898948424

Epoch: 6| Step: 4
Training loss: 0.07187964767217636
Validation loss: 1.425734136694221

Epoch: 6| Step: 5
Training loss: 0.04483315721154213
Validation loss: 1.421202068687767

Epoch: 6| Step: 6
Training loss: 0.06067829951643944
Validation loss: 1.420705847842719

Epoch: 6| Step: 7
Training loss: 0.059977937489748
Validation loss: 1.4498062159425469

Epoch: 6| Step: 8
Training loss: 0.08013439178466797
Validation loss: 1.410535950814524

Epoch: 6| Step: 9
Training loss: 0.11774089187383652
Validation loss: 1.4249061333235873

Epoch: 6| Step: 10
Training loss: 0.06899464130401611
Validation loss: 1.4079891045888264

Epoch: 6| Step: 11
Training loss: 0.07501910626888275
Validation loss: 1.4072870900554042

Epoch: 6| Step: 12
Training loss: 0.09661243110895157
Validation loss: 1.385971808946261

Epoch: 6| Step: 13
Training loss: 0.0863456204533577
Validation loss: 1.3799130993504678

Epoch: 538| Step: 0
Training loss: 0.03875225409865379
Validation loss: 1.3619979113660834

Epoch: 6| Step: 1
Training loss: 0.1055225357413292
Validation loss: 1.3578485532473492

Epoch: 6| Step: 2
Training loss: 0.20058467984199524
Validation loss: 1.3737739677070289

Epoch: 6| Step: 3
Training loss: 0.058944620192050934
Validation loss: 1.3891970848524442

Epoch: 6| Step: 4
Training loss: 0.07632654905319214
Validation loss: 1.4135886430740356

Epoch: 6| Step: 5
Training loss: 0.08331140130758286
Validation loss: 1.4474870844553875

Epoch: 6| Step: 6
Training loss: 0.11169621348381042
Validation loss: 1.4695942222431142

Epoch: 6| Step: 7
Training loss: 0.083319291472435
Validation loss: 1.460299753373669

Epoch: 6| Step: 8
Training loss: 0.11003914475440979
Validation loss: 1.4429070904690733

Epoch: 6| Step: 9
Training loss: 0.06154884397983551
Validation loss: 1.4788889128674743

Epoch: 6| Step: 10
Training loss: 0.08049820363521576
Validation loss: 1.4538962507760653

Epoch: 6| Step: 11
Training loss: 0.09308186173439026
Validation loss: 1.4657895667578584

Epoch: 6| Step: 12
Training loss: 0.07257401943206787
Validation loss: 1.4492206573486328

Epoch: 6| Step: 13
Training loss: 0.09120437502861023
Validation loss: 1.4521574384422713

Epoch: 539| Step: 0
Training loss: 0.050960320979356766
Validation loss: 1.4329230400823778

Epoch: 6| Step: 1
Training loss: 0.1217690110206604
Validation loss: 1.409961538930093

Epoch: 6| Step: 2
Training loss: 0.05952395126223564
Validation loss: 1.4201539549776303

Epoch: 6| Step: 3
Training loss: 0.07226261496543884
Validation loss: 1.4423317152966735

Epoch: 6| Step: 4
Training loss: 0.08517807722091675
Validation loss: 1.4062742879313808

Epoch: 6| Step: 5
Training loss: 0.10087329149246216
Validation loss: 1.3991548002407115

Epoch: 6| Step: 6
Training loss: 0.06611543893814087
Validation loss: 1.3949634086701177

Epoch: 6| Step: 7
Training loss: 0.15111194550991058
Validation loss: 1.395326138824545

Epoch: 6| Step: 8
Training loss: 0.05235012248158455
Validation loss: 1.387856428341199

Epoch: 6| Step: 9
Training loss: 0.0898875743150711
Validation loss: 1.4106825628588278

Epoch: 6| Step: 10
Training loss: 0.07360510528087616
Validation loss: 1.3769049029196463

Epoch: 6| Step: 11
Training loss: 0.0916232019662857
Validation loss: 1.3664337473530923

Epoch: 6| Step: 12
Training loss: 0.08530597388744354
Validation loss: 1.3744161410998272

Epoch: 6| Step: 13
Training loss: 0.07160792499780655
Validation loss: 1.3806409656360585

Epoch: 540| Step: 0
Training loss: 0.13279806077480316
Validation loss: 1.3742908277819235

Epoch: 6| Step: 1
Training loss: 0.08748331665992737
Validation loss: 1.3922540487781647

Epoch: 6| Step: 2
Training loss: 0.1029263436794281
Validation loss: 1.3991200154827488

Epoch: 6| Step: 3
Training loss: 0.10528826713562012
Validation loss: 1.3884737632607902

Epoch: 6| Step: 4
Training loss: 0.09197176992893219
Validation loss: 1.423098801284708

Epoch: 6| Step: 5
Training loss: 0.04586596041917801
Validation loss: 1.390778838947255

Epoch: 6| Step: 6
Training loss: 0.16481375694274902
Validation loss: 1.4197424791192497

Epoch: 6| Step: 7
Training loss: 0.07848598808050156
Validation loss: 1.4402664605007376

Epoch: 6| Step: 8
Training loss: 0.0590163916349411
Validation loss: 1.426271318748433

Epoch: 6| Step: 9
Training loss: 0.060320667922496796
Validation loss: 1.4608877192261398

Epoch: 6| Step: 10
Training loss: 0.04443260282278061
Validation loss: 1.4738769550477304

Epoch: 6| Step: 11
Training loss: 0.12374090403318405
Validation loss: 1.505548474609211

Epoch: 6| Step: 12
Training loss: 0.06781183183193207
Validation loss: 1.5130179248830324

Epoch: 6| Step: 13
Training loss: 0.0732518807053566
Validation loss: 1.5079350240768925

Epoch: 541| Step: 0
Training loss: 0.19657057523727417
Validation loss: 1.485011072568996

Epoch: 6| Step: 1
Training loss: 0.054051533341407776
Validation loss: 1.4638089659393474

Epoch: 6| Step: 2
Training loss: 0.049134138971567154
Validation loss: 1.4517287362006404

Epoch: 6| Step: 3
Training loss: 0.14845867455005646
Validation loss: 1.4406785118964411

Epoch: 6| Step: 4
Training loss: 0.08788637816905975
Validation loss: 1.4464925783936695

Epoch: 6| Step: 5
Training loss: 0.12121320515871048
Validation loss: 1.4222664448522753

Epoch: 6| Step: 6
Training loss: 0.06366816908121109
Validation loss: 1.412716979621559

Epoch: 6| Step: 7
Training loss: 0.04565606638789177
Validation loss: 1.4221141569076046

Epoch: 6| Step: 8
Training loss: 0.07333587110042572
Validation loss: 1.3939683168165145

Epoch: 6| Step: 9
Training loss: 0.07040833681821823
Validation loss: 1.397158823987489

Epoch: 6| Step: 10
Training loss: 0.06510899215936661
Validation loss: 1.4178426829717492

Epoch: 6| Step: 11
Training loss: 0.11213631182909012
Validation loss: 1.4155112069140199

Epoch: 6| Step: 12
Training loss: 0.07747305184602737
Validation loss: 1.4100261003740373

Epoch: 6| Step: 13
Training loss: 0.03647973760962486
Validation loss: 1.3873510206899335

Epoch: 542| Step: 0
Training loss: 0.08272004127502441
Validation loss: 1.4119536453677761

Epoch: 6| Step: 1
Training loss: 0.08290958404541016
Validation loss: 1.424207079795099

Epoch: 6| Step: 2
Training loss: 0.06302373856306076
Validation loss: 1.4273436018215713

Epoch: 6| Step: 3
Training loss: 0.08378186821937561
Validation loss: 1.4202133852948424

Epoch: 6| Step: 4
Training loss: 0.0615052655339241
Validation loss: 1.4638106194875573

Epoch: 6| Step: 5
Training loss: 0.148034006357193
Validation loss: 1.438019843511684

Epoch: 6| Step: 6
Training loss: 0.042685993015766144
Validation loss: 1.4670841104240828

Epoch: 6| Step: 7
Training loss: 0.09562265127897263
Validation loss: 1.4848629043948265

Epoch: 6| Step: 8
Training loss: 0.10445335507392883
Validation loss: 1.4593866576430619

Epoch: 6| Step: 9
Training loss: 0.07013586163520813
Validation loss: 1.4250736198117655

Epoch: 6| Step: 10
Training loss: 0.11878344416618347
Validation loss: 1.4450816697971796

Epoch: 6| Step: 11
Training loss: 0.07433212548494339
Validation loss: 1.4286462683831491

Epoch: 6| Step: 12
Training loss: 0.05248692259192467
Validation loss: 1.4178599426823277

Epoch: 6| Step: 13
Training loss: 0.07551439851522446
Validation loss: 1.4397657379027335

Epoch: 543| Step: 0
Training loss: 0.05577976256608963
Validation loss: 1.4277636005032448

Epoch: 6| Step: 1
Training loss: 0.07187070697546005
Validation loss: 1.4158770820145965

Epoch: 6| Step: 2
Training loss: 0.05144575983285904
Validation loss: 1.446880595017505

Epoch: 6| Step: 3
Training loss: 0.10979267209768295
Validation loss: 1.4452296303164573

Epoch: 6| Step: 4
Training loss: 0.10072895139455795
Validation loss: 1.4684076975750666

Epoch: 6| Step: 5
Training loss: 0.06998372077941895
Validation loss: 1.4745142985415716

Epoch: 6| Step: 6
Training loss: 0.11566368490457535
Validation loss: 1.4697042716446744

Epoch: 6| Step: 7
Training loss: 0.06875529140233994
Validation loss: 1.4724742481785436

Epoch: 6| Step: 8
Training loss: 0.09554603695869446
Validation loss: 1.4885008271022508

Epoch: 6| Step: 9
Training loss: 0.07025223225355148
Validation loss: 1.4890886096544163

Epoch: 6| Step: 10
Training loss: 0.17960862815380096
Validation loss: 1.492336953839948

Epoch: 6| Step: 11
Training loss: 0.08229426294565201
Validation loss: 1.4922012846956971

Epoch: 6| Step: 12
Training loss: 0.08472999930381775
Validation loss: 1.491491070357702

Epoch: 6| Step: 13
Training loss: 0.08472214639186859
Validation loss: 1.4648318713711155

Epoch: 544| Step: 0
Training loss: 0.1542159914970398
Validation loss: 1.4507921818763978

Epoch: 6| Step: 1
Training loss: 0.08794590830802917
Validation loss: 1.4360036350065661

Epoch: 6| Step: 2
Training loss: 0.07943476736545563
Validation loss: 1.4240920018124323

Epoch: 6| Step: 3
Training loss: 0.04551294445991516
Validation loss: 1.4131254464067438

Epoch: 6| Step: 4
Training loss: 0.07179802656173706
Validation loss: 1.402695535331644

Epoch: 6| Step: 5
Training loss: 0.08117584884166718
Validation loss: 1.4188202077983527

Epoch: 6| Step: 6
Training loss: 0.13691763579845428
Validation loss: 1.396332271637455

Epoch: 6| Step: 7
Training loss: 0.03721357882022858
Validation loss: 1.4019751157811893

Epoch: 6| Step: 8
Training loss: 0.06265845894813538
Validation loss: 1.3728023780289518

Epoch: 6| Step: 9
Training loss: 0.1089489758014679
Validation loss: 1.402881767160149

Epoch: 6| Step: 10
Training loss: 0.09280204772949219
Validation loss: 1.4212479617006035

Epoch: 6| Step: 11
Training loss: 0.07049672305583954
Validation loss: 1.4412960378072595

Epoch: 6| Step: 12
Training loss: 0.07339267432689667
Validation loss: 1.4265769284258607

Epoch: 6| Step: 13
Training loss: 0.04901808872818947
Validation loss: 1.4318371793275237

Epoch: 545| Step: 0
Training loss: 0.09020746499300003
Validation loss: 1.4178648969178558

Epoch: 6| Step: 1
Training loss: 0.09021793305873871
Validation loss: 1.4280684635203371

Epoch: 6| Step: 2
Training loss: 0.08861366659402847
Validation loss: 1.4392724396080099

Epoch: 6| Step: 3
Training loss: 0.054468270391225815
Validation loss: 1.4394017573325866

Epoch: 6| Step: 4
Training loss: 0.07848641276359558
Validation loss: 1.457624000887717

Epoch: 6| Step: 5
Training loss: 0.07461751997470856
Validation loss: 1.459019745549848

Epoch: 6| Step: 6
Training loss: 0.1535632312297821
Validation loss: 1.45998425381158

Epoch: 6| Step: 7
Training loss: 0.10765140503644943
Validation loss: 1.479338696566961

Epoch: 6| Step: 8
Training loss: 0.14860357344150543
Validation loss: 1.470176621149945

Epoch: 6| Step: 9
Training loss: 0.06604339182376862
Validation loss: 1.4827791055043538

Epoch: 6| Step: 10
Training loss: 0.06857229769229889
Validation loss: 1.464480552622067

Epoch: 6| Step: 11
Training loss: 0.07591389119625092
Validation loss: 1.4442671473308275

Epoch: 6| Step: 12
Training loss: 0.0728132501244545
Validation loss: 1.4098296601285216

Epoch: 6| Step: 13
Training loss: 0.12836319208145142
Validation loss: 1.413684803952453

Epoch: 546| Step: 0
Training loss: 0.07454875111579895
Validation loss: 1.393888440183414

Epoch: 6| Step: 1
Training loss: 0.11242961138486862
Validation loss: 1.4094665037688388

Epoch: 6| Step: 2
Training loss: 0.0713905394077301
Validation loss: 1.417092833467709

Epoch: 6| Step: 3
Training loss: 0.07956185191869736
Validation loss: 1.4090568852680985

Epoch: 6| Step: 4
Training loss: 0.12549808621406555
Validation loss: 1.4092557148266864

Epoch: 6| Step: 5
Training loss: 0.04562970995903015
Validation loss: 1.4043513318543792

Epoch: 6| Step: 6
Training loss: 0.06883575022220612
Validation loss: 1.4228736982550672

Epoch: 6| Step: 7
Training loss: 0.1663261502981186
Validation loss: 1.4234487651496806

Epoch: 6| Step: 8
Training loss: 0.07604030519723892
Validation loss: 1.4304270244413806

Epoch: 6| Step: 9
Training loss: 0.07523665577173233
Validation loss: 1.4386099500040854

Epoch: 6| Step: 10
Training loss: 0.05878029763698578
Validation loss: 1.443903442992959

Epoch: 6| Step: 11
Training loss: 0.0740566998720169
Validation loss: 1.450251894612466

Epoch: 6| Step: 12
Training loss: 0.06708984076976776
Validation loss: 1.4624771238655172

Epoch: 6| Step: 13
Training loss: 0.08219709992408752
Validation loss: 1.4552547726579892

Epoch: 547| Step: 0
Training loss: 0.06251636147499084
Validation loss: 1.475416047598726

Epoch: 6| Step: 1
Training loss: 0.10351692885160446
Validation loss: 1.4908988847527453

Epoch: 6| Step: 2
Training loss: 0.10490322858095169
Validation loss: 1.4845637852145779

Epoch: 6| Step: 3
Training loss: 0.10626677423715591
Validation loss: 1.4780899388815767

Epoch: 6| Step: 4
Training loss: 0.22993920743465424
Validation loss: 1.4681121264734576

Epoch: 6| Step: 5
Training loss: 0.13284581899642944
Validation loss: 1.445344421491828

Epoch: 6| Step: 6
Training loss: 0.04737293720245361
Validation loss: 1.4337489028130808

Epoch: 6| Step: 7
Training loss: 0.07140019536018372
Validation loss: 1.4190221268643615

Epoch: 6| Step: 8
Training loss: 0.07787062972784042
Validation loss: 1.4418643597633607

Epoch: 6| Step: 9
Training loss: 0.05499443784356117
Validation loss: 1.4545452902393956

Epoch: 6| Step: 10
Training loss: 0.07535725831985474
Validation loss: 1.4440313616106588

Epoch: 6| Step: 11
Training loss: 0.10359133780002594
Validation loss: 1.4244940229641494

Epoch: 6| Step: 12
Training loss: 0.09829637408256531
Validation loss: 1.425600758803788

Epoch: 6| Step: 13
Training loss: 0.049672406166791916
Validation loss: 1.4178504277301092

Epoch: 548| Step: 0
Training loss: 0.06108018010854721
Validation loss: 1.3990843834415558

Epoch: 6| Step: 1
Training loss: 0.11108684539794922
Validation loss: 1.3790148355627572

Epoch: 6| Step: 2
Training loss: 0.08701823651790619
Validation loss: 1.4155948046715028

Epoch: 6| Step: 3
Training loss: 0.07482074201107025
Validation loss: 1.4352553185596262

Epoch: 6| Step: 4
Training loss: 0.1203058734536171
Validation loss: 1.4259821035528695

Epoch: 6| Step: 5
Training loss: 0.07337472587823868
Validation loss: 1.3988316315476612

Epoch: 6| Step: 6
Training loss: 0.07463443279266357
Validation loss: 1.4192143255664456

Epoch: 6| Step: 7
Training loss: 0.09275965392589569
Validation loss: 1.432720048453218

Epoch: 6| Step: 8
Training loss: 0.08623096346855164
Validation loss: 1.42016012566064

Epoch: 6| Step: 9
Training loss: 0.14839959144592285
Validation loss: 1.4224514140877673

Epoch: 6| Step: 10
Training loss: 0.06769946217536926
Validation loss: 1.40367635732056

Epoch: 6| Step: 11
Training loss: 0.06482401490211487
Validation loss: 1.3948061889217747

Epoch: 6| Step: 12
Training loss: 0.05275930464267731
Validation loss: 1.3918452134696386

Epoch: 6| Step: 13
Training loss: 0.084237240254879
Validation loss: 1.4104838576368106

Epoch: 549| Step: 0
Training loss: 0.10863974690437317
Validation loss: 1.3999193855511245

Epoch: 6| Step: 1
Training loss: 0.10664011538028717
Validation loss: 1.3793252475800053

Epoch: 6| Step: 2
Training loss: 0.10163383185863495
Validation loss: 1.3838160768631966

Epoch: 6| Step: 3
Training loss: 0.0856378972530365
Validation loss: 1.3882649188400598

Epoch: 6| Step: 4
Training loss: 0.06609561294317245
Validation loss: 1.4063949777233986

Epoch: 6| Step: 5
Training loss: 0.0638761967420578
Validation loss: 1.3996530848164712

Epoch: 6| Step: 6
Training loss: 0.05735577270388603
Validation loss: 1.4337891936302185

Epoch: 6| Step: 7
Training loss: 0.03903849422931671
Validation loss: 1.4522710641225178

Epoch: 6| Step: 8
Training loss: 0.10686924308538437
Validation loss: 1.4438443581263225

Epoch: 6| Step: 9
Training loss: 0.10061812400817871
Validation loss: 1.4383137386332276

Epoch: 6| Step: 10
Training loss: 0.0775880217552185
Validation loss: 1.468547764644828

Epoch: 6| Step: 11
Training loss: 0.054322075098752975
Validation loss: 1.4430287884127708

Epoch: 6| Step: 12
Training loss: 0.13071265816688538
Validation loss: 1.397852692552792

Epoch: 6| Step: 13
Training loss: 0.2366802990436554
Validation loss: 1.4113172446527789

Epoch: 550| Step: 0
Training loss: 0.05574599653482437
Validation loss: 1.42966297236822

Epoch: 6| Step: 1
Training loss: 0.1692083477973938
Validation loss: 1.3933188146160496

Epoch: 6| Step: 2
Training loss: 0.08750195801258087
Validation loss: 1.4025034468661073

Epoch: 6| Step: 3
Training loss: 0.07282939553260803
Validation loss: 1.4243598497042091

Epoch: 6| Step: 4
Training loss: 0.10507005453109741
Validation loss: 1.440820026141341

Epoch: 6| Step: 5
Training loss: 0.07633604109287262
Validation loss: 1.4432779486461351

Epoch: 6| Step: 6
Training loss: 0.0668221116065979
Validation loss: 1.4919386448398713

Epoch: 6| Step: 7
Training loss: 0.08047699183225632
Validation loss: 1.4805623574923443

Epoch: 6| Step: 8
Training loss: 0.09295882284641266
Validation loss: 1.4800885454300912

Epoch: 6| Step: 9
Training loss: 0.10029827058315277
Validation loss: 1.4872065487728323

Epoch: 6| Step: 10
Training loss: 0.06303832679986954
Validation loss: 1.5161111201009443

Epoch: 6| Step: 11
Training loss: 0.08057733625173569
Validation loss: 1.4967208575176936

Epoch: 6| Step: 12
Training loss: 0.06598043441772461
Validation loss: 1.5049534984814223

Epoch: 6| Step: 13
Training loss: 0.09973692893981934
Validation loss: 1.463593183025237

Epoch: 551| Step: 0
Training loss: 0.042740464210510254
Validation loss: 1.4948830130279704

Epoch: 6| Step: 1
Training loss: 0.06804864853620529
Validation loss: 1.4694067496125416

Epoch: 6| Step: 2
Training loss: 0.07260410487651825
Validation loss: 1.461234865650054

Epoch: 6| Step: 3
Training loss: 0.05997493118047714
Validation loss: 1.4720695685314875

Epoch: 6| Step: 4
Training loss: 0.08533927798271179
Validation loss: 1.4741337542892785

Epoch: 6| Step: 5
Training loss: 0.08449479192495346
Validation loss: 1.4633301688778786

Epoch: 6| Step: 6
Training loss: 0.08580572158098221
Validation loss: 1.47885775309737

Epoch: 6| Step: 7
Training loss: 0.06843958050012589
Validation loss: 1.4271885784723426

Epoch: 6| Step: 8
Training loss: 0.09316504001617432
Validation loss: 1.4282891872108623

Epoch: 6| Step: 9
Training loss: 0.045621346682310104
Validation loss: 1.4166578471019704

Epoch: 6| Step: 10
Training loss: 0.08332589268684387
Validation loss: 1.4294489301661009

Epoch: 6| Step: 11
Training loss: 0.13002470135688782
Validation loss: 1.4315538649917932

Epoch: 6| Step: 12
Training loss: 0.16769017279148102
Validation loss: 1.4423599179073046

Epoch: 6| Step: 13
Training loss: 0.10115636885166168
Validation loss: 1.4329960077039656

Epoch: 552| Step: 0
Training loss: 0.03942202776670456
Validation loss: 1.4528723852608794

Epoch: 6| Step: 1
Training loss: 0.09371551871299744
Validation loss: 1.4486013573984946

Epoch: 6| Step: 2
Training loss: 0.07717642188072205
Validation loss: 1.4468095969128352

Epoch: 6| Step: 3
Training loss: 0.04899650067090988
Validation loss: 1.470811757990109

Epoch: 6| Step: 4
Training loss: 0.04392526298761368
Validation loss: 1.4522670853522517

Epoch: 6| Step: 5
Training loss: 0.0789468064904213
Validation loss: 1.456021015362073

Epoch: 6| Step: 6
Training loss: 0.10539805889129639
Validation loss: 1.4438155979238532

Epoch: 6| Step: 7
Training loss: 0.19200479984283447
Validation loss: 1.440270108561362

Epoch: 6| Step: 8
Training loss: 0.06284397840499878
Validation loss: 1.4227622632057435

Epoch: 6| Step: 9
Training loss: 0.058385029435157776
Validation loss: 1.3950280021595698

Epoch: 6| Step: 10
Training loss: 0.07837696373462677
Validation loss: 1.4427857911714943

Epoch: 6| Step: 11
Training loss: 0.054549187421798706
Validation loss: 1.4291054535937566

Epoch: 6| Step: 12
Training loss: 0.07471995800733566
Validation loss: 1.4100604570040138

Epoch: 6| Step: 13
Training loss: 0.038837648928165436
Validation loss: 1.4581839602480653

Epoch: 553| Step: 0
Training loss: 0.06106889247894287
Validation loss: 1.4442326381642332

Epoch: 6| Step: 1
Training loss: 0.05283033847808838
Validation loss: 1.4291911330274356

Epoch: 6| Step: 2
Training loss: 0.0849699005484581
Validation loss: 1.425570233534741

Epoch: 6| Step: 3
Training loss: 0.07651813328266144
Validation loss: 1.4398764205235306

Epoch: 6| Step: 4
Training loss: 0.055015869438648224
Validation loss: 1.45056789664812

Epoch: 6| Step: 5
Training loss: 0.06021489202976227
Validation loss: 1.4651249903504566

Epoch: 6| Step: 6
Training loss: 0.09738114476203918
Validation loss: 1.4799091149401922

Epoch: 6| Step: 7
Training loss: 0.11852283775806427
Validation loss: 1.4764709293201406

Epoch: 6| Step: 8
Training loss: 0.0772949680685997
Validation loss: 1.5139442348992953

Epoch: 6| Step: 9
Training loss: 0.12371090054512024
Validation loss: 1.5037767175705201

Epoch: 6| Step: 10
Training loss: 0.12672437727451324
Validation loss: 1.5034020511052941

Epoch: 6| Step: 11
Training loss: 0.16105923056602478
Validation loss: 1.4955412700612059

Epoch: 6| Step: 12
Training loss: 0.04707209765911102
Validation loss: 1.4652784537243586

Epoch: 6| Step: 13
Training loss: 0.08289624750614166
Validation loss: 1.4785296609324794

Epoch: 554| Step: 0
Training loss: 0.04887685552239418
Validation loss: 1.458391224184344

Epoch: 6| Step: 1
Training loss: 0.06730677932500839
Validation loss: 1.4298051070141535

Epoch: 6| Step: 2
Training loss: 0.08002498745918274
Validation loss: 1.417383675934166

Epoch: 6| Step: 3
Training loss: 0.06692910194396973
Validation loss: 1.4347877989533127

Epoch: 6| Step: 4
Training loss: 0.1301688253879547
Validation loss: 1.391760790219871

Epoch: 6| Step: 5
Training loss: 0.11191654205322266
Validation loss: 1.419920197097204

Epoch: 6| Step: 6
Training loss: 0.059214118868112564
Validation loss: 1.4044171956277662

Epoch: 6| Step: 7
Training loss: 0.16630545258522034
Validation loss: 1.402811651588768

Epoch: 6| Step: 8
Training loss: 0.09474016726016998
Validation loss: 1.3704553381089242

Epoch: 6| Step: 9
Training loss: 0.1529676467180252
Validation loss: 1.3785144077834262

Epoch: 6| Step: 10
Training loss: 0.10071185231208801
Validation loss: 1.4091045382202312

Epoch: 6| Step: 11
Training loss: 0.04375259578227997
Validation loss: 1.4050562509926416

Epoch: 6| Step: 12
Training loss: 0.1641508936882019
Validation loss: 1.4140595697587537

Epoch: 6| Step: 13
Training loss: 0.06855881214141846
Validation loss: 1.4230423306906095

Epoch: 555| Step: 0
Training loss: 0.11224181950092316
Validation loss: 1.4468161008691276

Epoch: 6| Step: 1
Training loss: 0.18284936249256134
Validation loss: 1.4132105586349324

Epoch: 6| Step: 2
Training loss: 0.06554538011550903
Validation loss: 1.383378956907539

Epoch: 6| Step: 3
Training loss: 0.0980030819773674
Validation loss: 1.3886581492680374

Epoch: 6| Step: 4
Training loss: 0.05505138635635376
Validation loss: 1.3356035563253588

Epoch: 6| Step: 5
Training loss: 0.17362672090530396
Validation loss: 1.3266824701780915

Epoch: 6| Step: 6
Training loss: 0.09826226532459259
Validation loss: 1.3526468507705196

Epoch: 6| Step: 7
Training loss: 0.14903414249420166
Validation loss: 1.370213258650995

Epoch: 6| Step: 8
Training loss: 0.13947375118732452
Validation loss: 1.3879833029162498

Epoch: 6| Step: 9
Training loss: 0.18852917850017548
Validation loss: 1.4025725908176874

Epoch: 6| Step: 10
Training loss: 0.11906483769416809
Validation loss: 1.4024393712320635

Epoch: 6| Step: 11
Training loss: 0.1831645965576172
Validation loss: 1.4116803715305943

Epoch: 6| Step: 12
Training loss: 0.1255526840686798
Validation loss: 1.4008343463302941

Epoch: 6| Step: 13
Training loss: 0.14308375120162964
Validation loss: 1.4331764187864078

Epoch: 556| Step: 0
Training loss: 0.10622984170913696
Validation loss: 1.444548713263645

Epoch: 6| Step: 1
Training loss: 0.14093029499053955
Validation loss: 1.4783875416683894

Epoch: 6| Step: 2
Training loss: 0.08193789422512054
Validation loss: 1.5159313242922547

Epoch: 6| Step: 3
Training loss: 0.24442628026008606
Validation loss: 1.5148601467891405

Epoch: 6| Step: 4
Training loss: 0.14614659547805786
Validation loss: 1.5203679377032864

Epoch: 6| Step: 5
Training loss: 0.14359252154827118
Validation loss: 1.5339175770359654

Epoch: 6| Step: 6
Training loss: 0.16337664425373077
Validation loss: 1.506920023631024

Epoch: 6| Step: 7
Training loss: 0.08658871054649353
Validation loss: 1.508567899786016

Epoch: 6| Step: 8
Training loss: 0.12355995178222656
Validation loss: 1.455809002281517

Epoch: 6| Step: 9
Training loss: 0.12516458332538605
Validation loss: 1.4330926133740334

Epoch: 6| Step: 10
Training loss: 0.14877285063266754
Validation loss: 1.4353042866594048

Epoch: 6| Step: 11
Training loss: 0.06141570955514908
Validation loss: 1.4000094590648529

Epoch: 6| Step: 12
Training loss: 0.08888815343379974
Validation loss: 1.347744345664978

Epoch: 6| Step: 13
Training loss: 0.09206772595643997
Validation loss: 1.3578469240537254

Epoch: 557| Step: 0
Training loss: 0.10909989476203918
Validation loss: 1.3076012897235092

Epoch: 6| Step: 1
Training loss: 0.10876815021038055
Validation loss: 1.306731527851474

Epoch: 6| Step: 2
Training loss: 0.06821177154779434
Validation loss: 1.2999725546888126

Epoch: 6| Step: 3
Training loss: 0.11166387796401978
Validation loss: 1.32395980435033

Epoch: 6| Step: 4
Training loss: 0.10382494330406189
Validation loss: 1.3246379533121664

Epoch: 6| Step: 5
Training loss: 0.18935103714466095
Validation loss: 1.3214761166162388

Epoch: 6| Step: 6
Training loss: 0.06388778239488602
Validation loss: 1.3595765470176615

Epoch: 6| Step: 7
Training loss: 0.08089393377304077
Validation loss: 1.3738574494597733

Epoch: 6| Step: 8
Training loss: 0.07090206444263458
Validation loss: 1.4203987185673048

Epoch: 6| Step: 9
Training loss: 0.09192866832017899
Validation loss: 1.411652567566082

Epoch: 6| Step: 10
Training loss: 0.13599002361297607
Validation loss: 1.4559703385958107

Epoch: 6| Step: 11
Training loss: 0.09880982339382172
Validation loss: 1.4520228357725247

Epoch: 6| Step: 12
Training loss: 0.07486684620380402
Validation loss: 1.4607136569997317

Epoch: 6| Step: 13
Training loss: 0.20604464411735535
Validation loss: 1.4632837695460166

Epoch: 558| Step: 0
Training loss: 0.07996199280023575
Validation loss: 1.4561688489811395

Epoch: 6| Step: 1
Training loss: 0.13090980052947998
Validation loss: 1.4350543355429044

Epoch: 6| Step: 2
Training loss: 0.12414959818124771
Validation loss: 1.3956774909009215

Epoch: 6| Step: 3
Training loss: 0.06649111211299896
Validation loss: 1.3715753965480353

Epoch: 6| Step: 4
Training loss: 0.06330621987581253
Validation loss: 1.368914186313588

Epoch: 6| Step: 5
Training loss: 0.07361436635255814
Validation loss: 1.3910580809398363

Epoch: 6| Step: 6
Training loss: 0.10479230433702469
Validation loss: 1.3958147937251675

Epoch: 6| Step: 7
Training loss: 0.09250889718532562
Validation loss: 1.3854733949066491

Epoch: 6| Step: 8
Training loss: 0.22499743103981018
Validation loss: 1.373708628839062

Epoch: 6| Step: 9
Training loss: 0.11839210987091064
Validation loss: 1.3681889067413986

Epoch: 6| Step: 10
Training loss: 0.11348529160022736
Validation loss: 1.3497372314494143

Epoch: 6| Step: 11
Training loss: 0.13796815276145935
Validation loss: 1.3587843730885496

Epoch: 6| Step: 12
Training loss: 0.16981594264507294
Validation loss: 1.35781511440072

Epoch: 6| Step: 13
Training loss: 0.08965028822422028
Validation loss: 1.3496469951445056

Epoch: 559| Step: 0
Training loss: 0.07697044312953949
Validation loss: 1.3517956323521112

Epoch: 6| Step: 1
Training loss: 0.10217095166444778
Validation loss: 1.3381521342903056

Epoch: 6| Step: 2
Training loss: 0.07518963515758514
Validation loss: 1.3799996094037128

Epoch: 6| Step: 3
Training loss: 0.09645561873912811
Validation loss: 1.384246055797864

Epoch: 6| Step: 4
Training loss: 0.08903715014457703
Validation loss: 1.3716208242600965

Epoch: 6| Step: 5
Training loss: 0.09288305044174194
Validation loss: 1.3786913938419794

Epoch: 6| Step: 6
Training loss: 0.07578884065151215
Validation loss: 1.4001646913507932

Epoch: 6| Step: 7
Training loss: 0.18404000997543335
Validation loss: 1.3971418578137633

Epoch: 6| Step: 8
Training loss: 0.14365024864673615
Validation loss: 1.387598470974994

Epoch: 6| Step: 9
Training loss: 0.05688588321208954
Validation loss: 1.3966318586821198

Epoch: 6| Step: 10
Training loss: 0.04678156226873398
Validation loss: 1.4296366963335263

Epoch: 6| Step: 11
Training loss: 0.08433465659618378
Validation loss: 1.419726743493029

Epoch: 6| Step: 12
Training loss: 0.06424068659543991
Validation loss: 1.428792151071692

Epoch: 6| Step: 13
Training loss: 0.08343099057674408
Validation loss: 1.4209583728544173

Epoch: 560| Step: 0
Training loss: 0.08710484206676483
Validation loss: 1.4213393567710795

Epoch: 6| Step: 1
Training loss: 0.06345004588365555
Validation loss: 1.4182843905623241

Epoch: 6| Step: 2
Training loss: 0.0935681015253067
Validation loss: 1.4078436384918869

Epoch: 6| Step: 3
Training loss: 0.07640977203845978
Validation loss: 1.4033305452715965

Epoch: 6| Step: 4
Training loss: 0.08616816997528076
Validation loss: 1.391913479374301

Epoch: 6| Step: 5
Training loss: 0.055986955761909485
Validation loss: 1.359895965104462

Epoch: 6| Step: 6
Training loss: 0.05744319409132004
Validation loss: 1.4279390765774636

Epoch: 6| Step: 7
Training loss: 0.04690945893526077
Validation loss: 1.405947208404541

Epoch: 6| Step: 8
Training loss: 0.1196630448102951
Validation loss: 1.377853778100783

Epoch: 6| Step: 9
Training loss: 0.08329234272241592
Validation loss: 1.395568896365422

Epoch: 6| Step: 10
Training loss: 0.1020735651254654
Validation loss: 1.4071765606121351

Epoch: 6| Step: 11
Training loss: 0.069049172103405
Validation loss: 1.4496929581447313

Epoch: 6| Step: 12
Training loss: 0.09084182977676392
Validation loss: 1.4433769974657285

Epoch: 6| Step: 13
Training loss: 0.26854005455970764
Validation loss: 1.4410709847686112

Epoch: 561| Step: 0
Training loss: 0.058834344148635864
Validation loss: 1.4388681239979242

Epoch: 6| Step: 1
Training loss: 0.06278412789106369
Validation loss: 1.4055814416177812

Epoch: 6| Step: 2
Training loss: 0.09137486666440964
Validation loss: 1.4104468412296747

Epoch: 6| Step: 3
Training loss: 0.10431845486164093
Validation loss: 1.4045696950727893

Epoch: 6| Step: 4
Training loss: 0.06294457614421844
Validation loss: 1.4045004883120138

Epoch: 6| Step: 5
Training loss: 0.07364817708730698
Validation loss: 1.4138374636250157

Epoch: 6| Step: 6
Training loss: 0.08353723585605621
Validation loss: 1.388574149659885

Epoch: 6| Step: 7
Training loss: 0.16165632009506226
Validation loss: 1.389997317585894

Epoch: 6| Step: 8
Training loss: 0.08205293118953705
Validation loss: 1.3883675157382924

Epoch: 6| Step: 9
Training loss: 0.06530395895242691
Validation loss: 1.3546886021091091

Epoch: 6| Step: 10
Training loss: 0.08752723038196564
Validation loss: 1.3700074559898787

Epoch: 6| Step: 11
Training loss: 0.10903309285640717
Validation loss: 1.3284098018882096

Epoch: 6| Step: 12
Training loss: 0.08923742175102234
Validation loss: 1.3471409556686238

Epoch: 6| Step: 13
Training loss: 0.03645617514848709
Validation loss: 1.334848625685579

Epoch: 562| Step: 0
Training loss: 0.06625863909721375
Validation loss: 1.322800608091457

Epoch: 6| Step: 1
Training loss: 0.0726986676454544
Validation loss: 1.336219153096599

Epoch: 6| Step: 2
Training loss: 0.09826131165027618
Validation loss: 1.3318152241809393

Epoch: 6| Step: 3
Training loss: 0.14967286586761475
Validation loss: 1.361063890559699

Epoch: 6| Step: 4
Training loss: 0.08538764715194702
Validation loss: 1.3509888764350646

Epoch: 6| Step: 5
Training loss: 0.05344982445240021
Validation loss: 1.3479797993936846

Epoch: 6| Step: 6
Training loss: 0.0766545981168747
Validation loss: 1.3376356901661042

Epoch: 6| Step: 7
Training loss: 0.056284449994564056
Validation loss: 1.3634271519158476

Epoch: 6| Step: 8
Training loss: 0.0761336237192154
Validation loss: 1.3587240954881072

Epoch: 6| Step: 9
Training loss: 0.05802789330482483
Validation loss: 1.338493106185749

Epoch: 6| Step: 10
Training loss: 0.06281747668981552
Validation loss: 1.3630922776396557

Epoch: 6| Step: 11
Training loss: 0.13752543926239014
Validation loss: 1.3611278341662498

Epoch: 6| Step: 12
Training loss: 0.07498598098754883
Validation loss: 1.395982450054538

Epoch: 6| Step: 13
Training loss: 0.045204631984233856
Validation loss: 1.3876687217784185

Epoch: 563| Step: 0
Training loss: 0.07629511505365372
Validation loss: 1.3927843724527667

Epoch: 6| Step: 1
Training loss: 0.09974144399166107
Validation loss: 1.392412814401811

Epoch: 6| Step: 2
Training loss: 0.0507299080491066
Validation loss: 1.4052381271957068

Epoch: 6| Step: 3
Training loss: 0.0640704482793808
Validation loss: 1.3973401733624038

Epoch: 6| Step: 4
Training loss: 0.07559176534414291
Validation loss: 1.3968693581960534

Epoch: 6| Step: 5
Training loss: 0.07906665652990341
Validation loss: 1.3747373293804865

Epoch: 6| Step: 6
Training loss: 0.0718383863568306
Validation loss: 1.3713448803911927

Epoch: 6| Step: 7
Training loss: 0.07883180677890778
Validation loss: 1.3645372442019883

Epoch: 6| Step: 8
Training loss: 0.06474007666110992
Validation loss: 1.3593172475855837

Epoch: 6| Step: 9
Training loss: 0.09330715984106064
Validation loss: 1.3648354372670572

Epoch: 6| Step: 10
Training loss: 0.11593510210514069
Validation loss: 1.3810513160562004

Epoch: 6| Step: 11
Training loss: 0.0667928084731102
Validation loss: 1.3829996701209777

Epoch: 6| Step: 12
Training loss: 0.043008264154195786
Validation loss: 1.4094449512420162

Epoch: 6| Step: 13
Training loss: 0.06527670472860336
Validation loss: 1.4246268246763496

Epoch: 564| Step: 0
Training loss: 0.06822632253170013
Validation loss: 1.4094850632452196

Epoch: 6| Step: 1
Training loss: 0.08969127386808395
Validation loss: 1.454861431993464

Epoch: 6| Step: 2
Training loss: 0.1494554877281189
Validation loss: 1.4453299289108605

Epoch: 6| Step: 3
Training loss: 0.03685680031776428
Validation loss: 1.4551634429603495

Epoch: 6| Step: 4
Training loss: 0.05548912286758423
Validation loss: 1.4636561306574012

Epoch: 6| Step: 5
Training loss: 0.0709548145532608
Validation loss: 1.4405060160544612

Epoch: 6| Step: 6
Training loss: 0.06167997047305107
Validation loss: 1.4729638458580099

Epoch: 6| Step: 7
Training loss: 0.09383846819400787
Validation loss: 1.4607166500501736

Epoch: 6| Step: 8
Training loss: 0.057278722524642944
Validation loss: 1.4700782504132999

Epoch: 6| Step: 9
Training loss: 0.09869082272052765
Validation loss: 1.475371906834264

Epoch: 6| Step: 10
Training loss: 0.049395956099033356
Validation loss: 1.4598573318091772

Epoch: 6| Step: 11
Training loss: 0.07888292521238327
Validation loss: 1.4506605889207573

Epoch: 6| Step: 12
Training loss: 0.058648161590099335
Validation loss: 1.457930810989872

Epoch: 6| Step: 13
Training loss: 0.08796948194503784
Validation loss: 1.4403302259342645

Epoch: 565| Step: 0
Training loss: 0.07004547119140625
Validation loss: 1.419838095224032

Epoch: 6| Step: 1
Training loss: 0.12529052793979645
Validation loss: 1.397582398947849

Epoch: 6| Step: 2
Training loss: 0.10201582312583923
Validation loss: 1.3941791519041984

Epoch: 6| Step: 3
Training loss: 0.09146717190742493
Validation loss: 1.3857164626480432

Epoch: 6| Step: 4
Training loss: 0.12173418700695038
Validation loss: 1.3915516035531157

Epoch: 6| Step: 5
Training loss: 0.07003124058246613
Validation loss: 1.367121055562009

Epoch: 6| Step: 6
Training loss: 0.11448533087968826
Validation loss: 1.3609113603509881

Epoch: 6| Step: 7
Training loss: 0.07047808915376663
Validation loss: 1.360180269005478

Epoch: 6| Step: 8
Training loss: 0.14894723892211914
Validation loss: 1.3371264165447605

Epoch: 6| Step: 9
Training loss: 0.07561057060956955
Validation loss: 1.373755734453919

Epoch: 6| Step: 10
Training loss: 0.0582546703517437
Validation loss: 1.368809542348308

Epoch: 6| Step: 11
Training loss: 0.074752077460289
Validation loss: 1.3684583851086196

Epoch: 6| Step: 12
Training loss: 0.1120726689696312
Validation loss: 1.3654968956465363

Epoch: 6| Step: 13
Training loss: 0.06688962876796722
Validation loss: 1.3819540136603898

Epoch: 566| Step: 0
Training loss: 0.07812004536390305
Validation loss: 1.378127126283543

Epoch: 6| Step: 1
Training loss: 0.07002522051334381
Validation loss: 1.4047274038355837

Epoch: 6| Step: 2
Training loss: 0.09843874722719193
Validation loss: 1.4039694993726668

Epoch: 6| Step: 3
Training loss: 0.13079692423343658
Validation loss: 1.4127742564806374

Epoch: 6| Step: 4
Training loss: 0.1195671558380127
Validation loss: 1.4300297255157142

Epoch: 6| Step: 5
Training loss: 0.10335729271173477
Validation loss: 1.3928971636679865

Epoch: 6| Step: 6
Training loss: 0.12468858808279037
Validation loss: 1.404046368855302

Epoch: 6| Step: 7
Training loss: 0.11493377387523651
Validation loss: 1.4201824447160125

Epoch: 6| Step: 8
Training loss: 0.0806744247674942
Validation loss: 1.3862216991762961

Epoch: 6| Step: 9
Training loss: 0.06058785319328308
Validation loss: 1.4076728231163436

Epoch: 6| Step: 10
Training loss: 0.14449377357959747
Validation loss: 1.4022198005389142

Epoch: 6| Step: 11
Training loss: 0.04132257401943207
Validation loss: 1.3947510014298141

Epoch: 6| Step: 12
Training loss: 0.12741126120090485
Validation loss: 1.3675431557880935

Epoch: 6| Step: 13
Training loss: 0.17771543562412262
Validation loss: 1.3847601516272432

Epoch: 567| Step: 0
Training loss: 0.07805196195840836
Validation loss: 1.3737937942627938

Epoch: 6| Step: 1
Training loss: 0.19084852933883667
Validation loss: 1.3885997674798454

Epoch: 6| Step: 2
Training loss: 0.048960570245981216
Validation loss: 1.3737709432519891

Epoch: 6| Step: 3
Training loss: 0.09654774516820908
Validation loss: 1.3446724632734894

Epoch: 6| Step: 4
Training loss: 0.048396751284599304
Validation loss: 1.3591756474587224

Epoch: 6| Step: 5
Training loss: 0.09594649076461792
Validation loss: 1.34561066473684

Epoch: 6| Step: 6
Training loss: 0.07897665351629257
Validation loss: 1.3563490426668556

Epoch: 6| Step: 7
Training loss: 0.05126599222421646
Validation loss: 1.3523926324741815

Epoch: 6| Step: 8
Training loss: 0.049653299152851105
Validation loss: 1.3656532802889425

Epoch: 6| Step: 9
Training loss: 0.08140973746776581
Validation loss: 1.3656464417775471

Epoch: 6| Step: 10
Training loss: 0.047476623207330704
Validation loss: 1.378055808364704

Epoch: 6| Step: 11
Training loss: 0.03911609202623367
Validation loss: 1.3969165702019968

Epoch: 6| Step: 12
Training loss: 0.06087135896086693
Validation loss: 1.4031237350997103

Epoch: 6| Step: 13
Training loss: 0.05514322221279144
Validation loss: 1.4149144272650442

Epoch: 568| Step: 0
Training loss: 0.04473557695746422
Validation loss: 1.4303342526958835

Epoch: 6| Step: 1
Training loss: 0.06037183105945587
Validation loss: 1.4282363435273528

Epoch: 6| Step: 2
Training loss: 0.05201965570449829
Validation loss: 1.4641649876871417

Epoch: 6| Step: 3
Training loss: 0.10602838546037674
Validation loss: 1.4915316797071887

Epoch: 6| Step: 4
Training loss: 0.06815740466117859
Validation loss: 1.4814271170605895

Epoch: 6| Step: 5
Training loss: 0.12335886061191559
Validation loss: 1.4955518425151866

Epoch: 6| Step: 6
Training loss: 0.07978075742721558
Validation loss: 1.4879052023733816

Epoch: 6| Step: 7
Training loss: 0.0988805741071701
Validation loss: 1.476373739140008

Epoch: 6| Step: 8
Training loss: 0.07196146249771118
Validation loss: 1.46880010251076

Epoch: 6| Step: 9
Training loss: 0.16112543642520905
Validation loss: 1.4436256193345594

Epoch: 6| Step: 10
Training loss: 0.05182802677154541
Validation loss: 1.4468349192732124

Epoch: 6| Step: 11
Training loss: 0.08184204995632172
Validation loss: 1.4364793351901475

Epoch: 6| Step: 12
Training loss: 0.04809746518731117
Validation loss: 1.4218934184761458

Epoch: 6| Step: 13
Training loss: 0.052579574286937714
Validation loss: 1.3898271270977554

Epoch: 569| Step: 0
Training loss: 0.07982839643955231
Validation loss: 1.3857881253765476

Epoch: 6| Step: 1
Training loss: 0.07180345803499222
Validation loss: 1.3753489191814134

Epoch: 6| Step: 2
Training loss: 0.07542893290519714
Validation loss: 1.385581334431966

Epoch: 6| Step: 3
Training loss: 0.1508474051952362
Validation loss: 1.3603304509193666

Epoch: 6| Step: 4
Training loss: 0.088067427277565
Validation loss: 1.4146933735057872

Epoch: 6| Step: 5
Training loss: 0.09953747689723969
Validation loss: 1.4066174466122863

Epoch: 6| Step: 6
Training loss: 0.07334811240434647
Validation loss: 1.4321000242746005

Epoch: 6| Step: 7
Training loss: 0.0707840621471405
Validation loss: 1.4431541017306748

Epoch: 6| Step: 8
Training loss: 0.06109309196472168
Validation loss: 1.4658454900146813

Epoch: 6| Step: 9
Training loss: 0.07130574434995651
Validation loss: 1.4653617053903558

Epoch: 6| Step: 10
Training loss: 0.10301931947469711
Validation loss: 1.4526823105350617

Epoch: 6| Step: 11
Training loss: 0.05719474330544472
Validation loss: 1.4416675144626248

Epoch: 6| Step: 12
Training loss: 0.08681124448776245
Validation loss: 1.4476853647539694

Epoch: 6| Step: 13
Training loss: 0.06534989923238754
Validation loss: 1.4796277464077037

Epoch: 570| Step: 0
Training loss: 0.0766608938574791
Validation loss: 1.436877494217247

Epoch: 6| Step: 1
Training loss: 0.0631558895111084
Validation loss: 1.4566055587542954

Epoch: 6| Step: 2
Training loss: 0.05147986859083176
Validation loss: 1.4415209793275403

Epoch: 6| Step: 3
Training loss: 0.18104028701782227
Validation loss: 1.4337742290189188

Epoch: 6| Step: 4
Training loss: 0.06753818690776825
Validation loss: 1.4093144542427474

Epoch: 6| Step: 5
Training loss: 0.035490021109580994
Validation loss: 1.3986292372467697

Epoch: 6| Step: 6
Training loss: 0.0775732696056366
Validation loss: 1.3731504678726196

Epoch: 6| Step: 7
Training loss: 0.05019600689411163
Validation loss: 1.3558164501702914

Epoch: 6| Step: 8
Training loss: 0.036672502756118774
Validation loss: 1.350307882473033

Epoch: 6| Step: 9
Training loss: 0.08300668746232986
Validation loss: 1.3543147733134608

Epoch: 6| Step: 10
Training loss: 0.06358097493648529
Validation loss: 1.359531860197744

Epoch: 6| Step: 11
Training loss: 0.11631500720977783
Validation loss: 1.3576571761920888

Epoch: 6| Step: 12
Training loss: 0.056889984756708145
Validation loss: 1.3658742770071952

Epoch: 6| Step: 13
Training loss: 0.03395078331232071
Validation loss: 1.3707378038796045

Epoch: 571| Step: 0
Training loss: 0.06687886267900467
Validation loss: 1.3480888400026547

Epoch: 6| Step: 1
Training loss: 0.09574804455041885
Validation loss: 1.3791954850637784

Epoch: 6| Step: 2
Training loss: 0.048587001860141754
Validation loss: 1.3836333700405654

Epoch: 6| Step: 3
Training loss: 0.12552742660045624
Validation loss: 1.3737919952279778

Epoch: 6| Step: 4
Training loss: 0.0725862979888916
Validation loss: 1.3619162433890886

Epoch: 6| Step: 5
Training loss: 0.04273137450218201
Validation loss: 1.3707463600302254

Epoch: 6| Step: 6
Training loss: 0.07111039012670517
Validation loss: 1.3539075184893865

Epoch: 6| Step: 7
Training loss: 0.10887308418750763
Validation loss: 1.3708239492549692

Epoch: 6| Step: 8
Training loss: 0.07249275594949722
Validation loss: 1.3451410583270493

Epoch: 6| Step: 9
Training loss: 0.06910330057144165
Validation loss: 1.3882934867694814

Epoch: 6| Step: 10
Training loss: 0.07180780917406082
Validation loss: 1.356801700848405

Epoch: 6| Step: 11
Training loss: 0.0736992284655571
Validation loss: 1.392435093079844

Epoch: 6| Step: 12
Training loss: 0.0669519305229187
Validation loss: 1.4099718498927292

Epoch: 6| Step: 13
Training loss: 0.0438881553709507
Validation loss: 1.4314165602448166

Epoch: 572| Step: 0
Training loss: 0.05735740065574646
Validation loss: 1.4498900239185621

Epoch: 6| Step: 1
Training loss: 0.048001810908317566
Validation loss: 1.4599960273311985

Epoch: 6| Step: 2
Training loss: 0.13224737346172333
Validation loss: 1.449996211836415

Epoch: 6| Step: 3
Training loss: 0.052886947989463806
Validation loss: 1.4604522746096376

Epoch: 6| Step: 4
Training loss: 0.03719629347324371
Validation loss: 1.4409351079694686

Epoch: 6| Step: 5
Training loss: 0.08433577418327332
Validation loss: 1.4634514290799376

Epoch: 6| Step: 6
Training loss: 0.05817861109972
Validation loss: 1.4392504326758846

Epoch: 6| Step: 7
Training loss: 0.0754207968711853
Validation loss: 1.4584436294853047

Epoch: 6| Step: 8
Training loss: 0.027330797165632248
Validation loss: 1.4513692291834022

Epoch: 6| Step: 9
Training loss: 0.08342116326093674
Validation loss: 1.4473010711772467

Epoch: 6| Step: 10
Training loss: 0.10287149250507355
Validation loss: 1.44825146531546

Epoch: 6| Step: 11
Training loss: 0.10588841885328293
Validation loss: 1.4155702360214726

Epoch: 6| Step: 12
Training loss: 0.06382288038730621
Validation loss: 1.4085543668398293

Epoch: 6| Step: 13
Training loss: 0.053516823798418045
Validation loss: 1.4089235195549585

Epoch: 573| Step: 0
Training loss: 0.08828414976596832
Validation loss: 1.410256148666464

Epoch: 6| Step: 1
Training loss: 0.0637490451335907
Validation loss: 1.3901600581343456

Epoch: 6| Step: 2
Training loss: 0.05436820536851883
Validation loss: 1.3842032776083997

Epoch: 6| Step: 3
Training loss: 0.03588678687810898
Validation loss: 1.403135927774573

Epoch: 6| Step: 4
Training loss: 0.06146105378866196
Validation loss: 1.397426506524445

Epoch: 6| Step: 5
Training loss: 0.06304813921451569
Validation loss: 1.3802538007818244

Epoch: 6| Step: 6
Training loss: 0.09026376157999039
Validation loss: 1.3993531337348364

Epoch: 6| Step: 7
Training loss: 0.07524959743022919
Validation loss: 1.3999898754140383

Epoch: 6| Step: 8
Training loss: 0.06900864839553833
Validation loss: 1.4098834427454139

Epoch: 6| Step: 9
Training loss: 0.07129643857479095
Validation loss: 1.4211588905703636

Epoch: 6| Step: 10
Training loss: 0.05007939040660858
Validation loss: 1.4154341631038214

Epoch: 6| Step: 11
Training loss: 0.11426293849945068
Validation loss: 1.4021300282529605

Epoch: 6| Step: 12
Training loss: 0.08481714129447937
Validation loss: 1.4013356495929021

Epoch: 6| Step: 13
Training loss: 0.06022828072309494
Validation loss: 1.411592988557713

Epoch: 574| Step: 0
Training loss: 0.1483820378780365
Validation loss: 1.4050178989287345

Epoch: 6| Step: 1
Training loss: 0.07595179975032806
Validation loss: 1.435279042490067

Epoch: 6| Step: 2
Training loss: 0.08225791901350021
Validation loss: 1.4416625102361043

Epoch: 6| Step: 3
Training loss: 0.04702187329530716
Validation loss: 1.4366326960184241

Epoch: 6| Step: 4
Training loss: 0.051304176449775696
Validation loss: 1.4530735169687579

Epoch: 6| Step: 5
Training loss: 0.05000016838312149
Validation loss: 1.4398463310733918

Epoch: 6| Step: 6
Training loss: 0.046397864818573
Validation loss: 1.450915854464295

Epoch: 6| Step: 7
Training loss: 0.07161867618560791
Validation loss: 1.426646299259637

Epoch: 6| Step: 8
Training loss: 0.07107890397310257
Validation loss: 1.4174554777401749

Epoch: 6| Step: 9
Training loss: 0.055268269032239914
Validation loss: 1.3986869883793656

Epoch: 6| Step: 10
Training loss: 0.10864520817995071
Validation loss: 1.3827771768775037

Epoch: 6| Step: 11
Training loss: 0.08241263777017593
Validation loss: 1.3405003355395408

Epoch: 6| Step: 12
Training loss: 0.11401857435703278
Validation loss: 1.3424386644876132

Epoch: 6| Step: 13
Training loss: 0.06912285834550858
Validation loss: 1.3293314838922152

Epoch: 575| Step: 0
Training loss: 0.05850422382354736
Validation loss: 1.3249988196998514

Epoch: 6| Step: 1
Training loss: 0.06926283240318298
Validation loss: 1.3379644809230682

Epoch: 6| Step: 2
Training loss: 0.1405884027481079
Validation loss: 1.332423822854155

Epoch: 6| Step: 3
Training loss: 0.08087906986474991
Validation loss: 1.334078441384018

Epoch: 6| Step: 4
Training loss: 0.04529278352856636
Validation loss: 1.331839241007323

Epoch: 6| Step: 5
Training loss: 0.06488882750272751
Validation loss: 1.3459527748887257

Epoch: 6| Step: 6
Training loss: 0.08915993571281433
Validation loss: 1.3674006821006857

Epoch: 6| Step: 7
Training loss: 0.10548023879528046
Validation loss: 1.3633739948272705

Epoch: 6| Step: 8
Training loss: 0.0779961571097374
Validation loss: 1.371676516789262

Epoch: 6| Step: 9
Training loss: 0.07622122019529343
Validation loss: 1.3793928905199933

Epoch: 6| Step: 10
Training loss: 0.054310619831085205
Validation loss: 1.4000548316586403

Epoch: 6| Step: 11
Training loss: 0.06509311497211456
Validation loss: 1.409308386105363

Epoch: 6| Step: 12
Training loss: 0.06881062686443329
Validation loss: 1.3955358350148765

Epoch: 6| Step: 13
Training loss: 0.07027316093444824
Validation loss: 1.4112564145877797

Epoch: 576| Step: 0
Training loss: 0.04457458481192589
Validation loss: 1.4187356169505785

Epoch: 6| Step: 1
Training loss: 0.073185995221138
Validation loss: 1.4038225899460495

Epoch: 6| Step: 2
Training loss: 0.043978214263916016
Validation loss: 1.4102671659120949

Epoch: 6| Step: 3
Training loss: 0.0710861086845398
Validation loss: 1.3919566344189387

Epoch: 6| Step: 4
Training loss: 0.05711149796843529
Validation loss: 1.3931599265785628

Epoch: 6| Step: 5
Training loss: 0.08559465408325195
Validation loss: 1.3772639779634372

Epoch: 6| Step: 6
Training loss: 0.07798497378826141
Validation loss: 1.3898484751742373

Epoch: 6| Step: 7
Training loss: 0.07998667657375336
Validation loss: 1.3811406589323474

Epoch: 6| Step: 8
Training loss: 0.13280780613422394
Validation loss: 1.354053819051353

Epoch: 6| Step: 9
Training loss: 0.08285029977560043
Validation loss: 1.4017098308891378

Epoch: 6| Step: 10
Training loss: 0.07199013233184814
Validation loss: 1.3725704287969938

Epoch: 6| Step: 11
Training loss: 0.06751340627670288
Validation loss: 1.400933401558989

Epoch: 6| Step: 12
Training loss: 0.06844675540924072
Validation loss: 1.4108544575270785

Epoch: 6| Step: 13
Training loss: 0.04917151480913162
Validation loss: 1.4102048207354803

Epoch: 577| Step: 0
Training loss: 0.07083918899297714
Validation loss: 1.4277316895864343

Epoch: 6| Step: 1
Training loss: 0.0432937890291214
Validation loss: 1.4027511612061532

Epoch: 6| Step: 2
Training loss: 0.08148157596588135
Validation loss: 1.4402123138468752

Epoch: 6| Step: 3
Training loss: 0.09373556077480316
Validation loss: 1.4574767774151218

Epoch: 6| Step: 4
Training loss: 0.15328143537044525
Validation loss: 1.4562729789364723

Epoch: 6| Step: 5
Training loss: 0.06689933687448502
Validation loss: 1.4494094015449606

Epoch: 6| Step: 6
Training loss: 0.07727380096912384
Validation loss: 1.4308599195172709

Epoch: 6| Step: 7
Training loss: 0.09909965097904205
Validation loss: 1.438587470721173

Epoch: 6| Step: 8
Training loss: 0.0493411123752594
Validation loss: 1.426459445748278

Epoch: 6| Step: 9
Training loss: 0.0607149600982666
Validation loss: 1.4141218252079462

Epoch: 6| Step: 10
Training loss: 0.04720752686262131
Validation loss: 1.3730372728839997

Epoch: 6| Step: 11
Training loss: 0.07741374522447586
Validation loss: 1.3668372425981747

Epoch: 6| Step: 12
Training loss: 0.08856818079948425
Validation loss: 1.3641250569333312

Epoch: 6| Step: 13
Training loss: 0.04978766292333603
Validation loss: 1.3593691010628977

Epoch: 578| Step: 0
Training loss: 0.06686194241046906
Validation loss: 1.374423634621405

Epoch: 6| Step: 1
Training loss: 0.07041223347187042
Validation loss: 1.3922867108416814

Epoch: 6| Step: 2
Training loss: 0.09225467592477798
Validation loss: 1.380109731869031

Epoch: 6| Step: 3
Training loss: 0.1395709365606308
Validation loss: 1.3512709807324153

Epoch: 6| Step: 4
Training loss: 0.0838402733206749
Validation loss: 1.390645670634444

Epoch: 6| Step: 5
Training loss: 0.06633572280406952
Validation loss: 1.395629552102858

Epoch: 6| Step: 6
Training loss: 0.05816382169723511
Validation loss: 1.3963167500752274

Epoch: 6| Step: 7
Training loss: 0.07856594771146774
Validation loss: 1.4225646872674265

Epoch: 6| Step: 8
Training loss: 0.04725802689790726
Validation loss: 1.3977786892203874

Epoch: 6| Step: 9
Training loss: 0.06053741276264191
Validation loss: 1.41431805651675

Epoch: 6| Step: 10
Training loss: 0.10065285116434097
Validation loss: 1.4109083913987683

Epoch: 6| Step: 11
Training loss: 0.07121904194355011
Validation loss: 1.384112556775411

Epoch: 6| Step: 12
Training loss: 0.05891317129135132
Validation loss: 1.376285481196578

Epoch: 6| Step: 13
Training loss: 0.12432428449392319
Validation loss: 1.4043033046107138

Epoch: 579| Step: 0
Training loss: 0.07589306682348251
Validation loss: 1.3595545746946847

Epoch: 6| Step: 1
Training loss: 0.09022273123264313
Validation loss: 1.3678904989714264

Epoch: 6| Step: 2
Training loss: 0.0494103878736496
Validation loss: 1.3789748581506873

Epoch: 6| Step: 3
Training loss: 0.13597646355628967
Validation loss: 1.3539737732179704

Epoch: 6| Step: 4
Training loss: 0.03910474106669426
Validation loss: 1.3424456452810636

Epoch: 6| Step: 5
Training loss: 0.06026286631822586
Validation loss: 1.3480345036393853

Epoch: 6| Step: 6
Training loss: 0.04531149938702583
Validation loss: 1.3393419404183664

Epoch: 6| Step: 7
Training loss: 0.04970297962427139
Validation loss: 1.3741270213998773

Epoch: 6| Step: 8
Training loss: 0.044764045625925064
Validation loss: 1.3785254352836198

Epoch: 6| Step: 9
Training loss: 0.11483491212129593
Validation loss: 1.4095587397134433

Epoch: 6| Step: 10
Training loss: 0.0415271557867527
Validation loss: 1.442572852616669

Epoch: 6| Step: 11
Training loss: 0.05989854782819748
Validation loss: 1.4253678988384944

Epoch: 6| Step: 12
Training loss: 0.12122268974781036
Validation loss: 1.45188021403487

Epoch: 6| Step: 13
Training loss: 0.01971432939171791
Validation loss: 1.4421439478474278

Epoch: 580| Step: 0
Training loss: 0.05710715800523758
Validation loss: 1.4515255574257142

Epoch: 6| Step: 1
Training loss: 0.0694858729839325
Validation loss: 1.4219596078318935

Epoch: 6| Step: 2
Training loss: 0.0925663560628891
Validation loss: 1.4180514222832137

Epoch: 6| Step: 3
Training loss: 0.06358376890420914
Validation loss: 1.3945624046428229

Epoch: 6| Step: 4
Training loss: 0.09280053526163101
Validation loss: 1.4044085990998052

Epoch: 6| Step: 5
Training loss: 0.07974693924188614
Validation loss: 1.3821409953537809

Epoch: 6| Step: 6
Training loss: 0.06402803957462311
Validation loss: 1.3948784707694926

Epoch: 6| Step: 7
Training loss: 0.09928912669420242
Validation loss: 1.3813844560295023

Epoch: 6| Step: 8
Training loss: 0.12301018089056015
Validation loss: 1.4111133339584514

Epoch: 6| Step: 9
Training loss: 0.061598069965839386
Validation loss: 1.4468757490957938

Epoch: 6| Step: 10
Training loss: 0.12702691555023193
Validation loss: 1.4522706795764226

Epoch: 6| Step: 11
Training loss: 0.0721176341176033
Validation loss: 1.4419829563427997

Epoch: 6| Step: 12
Training loss: 0.09428250789642334
Validation loss: 1.4561634435448596

Epoch: 6| Step: 13
Training loss: 0.08521555364131927
Validation loss: 1.4424398073586084

Epoch: 581| Step: 0
Training loss: 0.10262565314769745
Validation loss: 1.453235149383545

Epoch: 6| Step: 1
Training loss: 0.04968855157494545
Validation loss: 1.4494635065396626

Epoch: 6| Step: 2
Training loss: 0.0649385005235672
Validation loss: 1.414221352146518

Epoch: 6| Step: 3
Training loss: 0.08402596414089203
Validation loss: 1.4023401570576493

Epoch: 6| Step: 4
Training loss: 0.09555329382419586
Validation loss: 1.4103643484013055

Epoch: 6| Step: 5
Training loss: 0.08351635932922363
Validation loss: 1.3926907893150084

Epoch: 6| Step: 6
Training loss: 0.08073937147855759
Validation loss: 1.3982110856681742

Epoch: 6| Step: 7
Training loss: 0.107622891664505
Validation loss: 1.3704737194122807

Epoch: 6| Step: 8
Training loss: 0.11622780561447144
Validation loss: 1.3841926346543014

Epoch: 6| Step: 9
Training loss: 0.0752711370587349
Validation loss: 1.4068281688997823

Epoch: 6| Step: 10
Training loss: 0.10066414624452591
Validation loss: 1.4233840434781966

Epoch: 6| Step: 11
Training loss: 0.06358233094215393
Validation loss: 1.418957673093324

Epoch: 6| Step: 12
Training loss: 0.09372491389513016
Validation loss: 1.4346434711128153

Epoch: 6| Step: 13
Training loss: 0.06065143644809723
Validation loss: 1.4360945340125792

Epoch: 582| Step: 0
Training loss: 0.05921514704823494
Validation loss: 1.4532306053305184

Epoch: 6| Step: 1
Training loss: 0.03908753767609596
Validation loss: 1.4974488507034958

Epoch: 6| Step: 2
Training loss: 0.05820395052433014
Validation loss: 1.4818666212020382

Epoch: 6| Step: 3
Training loss: 0.07898567616939545
Validation loss: 1.462510178166051

Epoch: 6| Step: 4
Training loss: 0.07917795330286026
Validation loss: 1.4653637614301456

Epoch: 6| Step: 5
Training loss: 0.08034990727901459
Validation loss: 1.4707695168833579

Epoch: 6| Step: 6
Training loss: 0.13067808747291565
Validation loss: 1.4433994889259338

Epoch: 6| Step: 7
Training loss: 0.12459412962198257
Validation loss: 1.4565371095493276

Epoch: 6| Step: 8
Training loss: 0.07616600394248962
Validation loss: 1.4026312994700607

Epoch: 6| Step: 9
Training loss: 0.11381827294826508
Validation loss: 1.416088293957454

Epoch: 6| Step: 10
Training loss: 0.08817854523658752
Validation loss: 1.386908620916387

Epoch: 6| Step: 11
Training loss: 0.08841748535633087
Validation loss: 1.3871749101146575

Epoch: 6| Step: 12
Training loss: 0.05650830641388893
Validation loss: 1.3823083177689584

Epoch: 6| Step: 13
Training loss: 0.11100554466247559
Validation loss: 1.392960528532664

Epoch: 583| Step: 0
Training loss: 0.044679634273052216
Validation loss: 1.3995093889133905

Epoch: 6| Step: 1
Training loss: 0.09668406844139099
Validation loss: 1.3629200631572354

Epoch: 6| Step: 2
Training loss: 0.11393008381128311
Validation loss: 1.3852531410032702

Epoch: 6| Step: 3
Training loss: 0.13220907747745514
Validation loss: 1.3786501653732792

Epoch: 6| Step: 4
Training loss: 0.06477174162864685
Validation loss: 1.3733421929420964

Epoch: 6| Step: 5
Training loss: 0.07551568746566772
Validation loss: 1.3699481756456438

Epoch: 6| Step: 6
Training loss: 0.045308299362659454
Validation loss: 1.3899489551462152

Epoch: 6| Step: 7
Training loss: 0.05460719019174576
Validation loss: 1.3867832588893112

Epoch: 6| Step: 8
Training loss: 0.0745444968342781
Validation loss: 1.3886983753532491

Epoch: 6| Step: 9
Training loss: 0.0737389400601387
Validation loss: 1.388903075007982

Epoch: 6| Step: 10
Training loss: 0.0954933762550354
Validation loss: 1.3895155499058385

Epoch: 6| Step: 11
Training loss: 0.056334059685468674
Validation loss: 1.3818100293477376

Epoch: 6| Step: 12
Training loss: 0.07949526607990265
Validation loss: 1.4069938416122107

Epoch: 6| Step: 13
Training loss: 0.05479861795902252
Validation loss: 1.3975622718052199

Epoch: 584| Step: 0
Training loss: 0.04257222265005112
Validation loss: 1.3944759625260548

Epoch: 6| Step: 1
Training loss: 0.03772473335266113
Validation loss: 1.3996404832409275

Epoch: 6| Step: 2
Training loss: 0.05430033057928085
Validation loss: 1.410368101571196

Epoch: 6| Step: 3
Training loss: 0.08709453046321869
Validation loss: 1.4457047959809661

Epoch: 6| Step: 4
Training loss: 0.10568712651729584
Validation loss: 1.4410125558735223

Epoch: 6| Step: 5
Training loss: 0.07836992293596268
Validation loss: 1.4458683331807454

Epoch: 6| Step: 6
Training loss: 0.12720663845539093
Validation loss: 1.4233758334190614

Epoch: 6| Step: 7
Training loss: 0.09769460558891296
Validation loss: 1.4190503640841412

Epoch: 6| Step: 8
Training loss: 0.04883892461657524
Validation loss: 1.4498983839506745

Epoch: 6| Step: 9
Training loss: 0.09876201301813126
Validation loss: 1.4228398928078272

Epoch: 6| Step: 10
Training loss: 0.03171444684267044
Validation loss: 1.4357462236958165

Epoch: 6| Step: 11
Training loss: 0.05455738306045532
Validation loss: 1.4162885732548212

Epoch: 6| Step: 12
Training loss: 0.09378594160079956
Validation loss: 1.413238957364072

Epoch: 6| Step: 13
Training loss: 0.048858460038900375
Validation loss: 1.4175957505420973

Epoch: 585| Step: 0
Training loss: 0.12390222400426865
Validation loss: 1.4083172787902176

Epoch: 6| Step: 1
Training loss: 0.03562067449092865
Validation loss: 1.4178928072734545

Epoch: 6| Step: 2
Training loss: 0.07024366408586502
Validation loss: 1.4056852556044055

Epoch: 6| Step: 3
Training loss: 0.09125583618879318
Validation loss: 1.3954370899866986

Epoch: 6| Step: 4
Training loss: 0.05748302862048149
Validation loss: 1.3812063144099327

Epoch: 6| Step: 5
Training loss: 0.05191008746623993
Validation loss: 1.3929865526896652

Epoch: 6| Step: 6
Training loss: 0.056731417775154114
Validation loss: 1.3899764642920545

Epoch: 6| Step: 7
Training loss: 0.10378487408161163
Validation loss: 1.3979174642152683

Epoch: 6| Step: 8
Training loss: 0.07339517027139664
Validation loss: 1.4096102387674394

Epoch: 6| Step: 9
Training loss: 0.0708422064781189
Validation loss: 1.4180686512301046

Epoch: 6| Step: 10
Training loss: 0.06455317884683609
Validation loss: 1.4278626672683223

Epoch: 6| Step: 11
Training loss: 0.046598970890045166
Validation loss: 1.4310449348982943

Epoch: 6| Step: 12
Training loss: 0.06907561421394348
Validation loss: 1.4250029261394213

Epoch: 6| Step: 13
Training loss: 0.03816865384578705
Validation loss: 1.4249438182000191

Epoch: 586| Step: 0
Training loss: 0.07281859219074249
Validation loss: 1.4446824519864974

Epoch: 6| Step: 1
Training loss: 0.06229890510439873
Validation loss: 1.441493913691531

Epoch: 6| Step: 2
Training loss: 0.037579525262117386
Validation loss: 1.4468879648434219

Epoch: 6| Step: 3
Training loss: 0.07261274009943008
Validation loss: 1.4347500083267049

Epoch: 6| Step: 4
Training loss: 0.03102247416973114
Validation loss: 1.4132418401779667

Epoch: 6| Step: 5
Training loss: 0.10974826663732529
Validation loss: 1.4295194354108585

Epoch: 6| Step: 6
Training loss: 0.05135997012257576
Validation loss: 1.4290839747716022

Epoch: 6| Step: 7
Training loss: 0.05708795413374901
Validation loss: 1.457105775033274

Epoch: 6| Step: 8
Training loss: 0.07155260443687439
Validation loss: 1.4375057092276953

Epoch: 6| Step: 9
Training loss: 0.06536152958869934
Validation loss: 1.4553359593114545

Epoch: 6| Step: 10
Training loss: 0.06779521703720093
Validation loss: 1.4474774406802269

Epoch: 6| Step: 11
Training loss: 0.15563085675239563
Validation loss: 1.4170089037187639

Epoch: 6| Step: 12
Training loss: 0.07476440072059631
Validation loss: 1.4408060581453386

Epoch: 6| Step: 13
Training loss: 0.047160226851701736
Validation loss: 1.4289959143566828

Epoch: 587| Step: 0
Training loss: 0.06758680939674377
Validation loss: 1.42426097777582

Epoch: 6| Step: 1
Training loss: 0.06490100920200348
Validation loss: 1.447317123413086

Epoch: 6| Step: 2
Training loss: 0.08161410689353943
Validation loss: 1.4183892562825193

Epoch: 6| Step: 3
Training loss: 0.050049345940351486
Validation loss: 1.3636975128163573

Epoch: 6| Step: 4
Training loss: 0.13901177048683167
Validation loss: 1.3881545951289516

Epoch: 6| Step: 5
Training loss: 0.0934564620256424
Validation loss: 1.3782228628794353

Epoch: 6| Step: 6
Training loss: 0.08131195604801178
Validation loss: 1.3660420108866949

Epoch: 6| Step: 7
Training loss: 0.06546620279550552
Validation loss: 1.3736486210617969

Epoch: 6| Step: 8
Training loss: 0.06311909854412079
Validation loss: 1.3638790076778782

Epoch: 6| Step: 9
Training loss: 0.054278600960969925
Validation loss: 1.3600167330875192

Epoch: 6| Step: 10
Training loss: 0.061297424137592316
Validation loss: 1.369803382504371

Epoch: 6| Step: 11
Training loss: 0.09976299852132797
Validation loss: 1.3714631577973724

Epoch: 6| Step: 12
Training loss: 0.08784924447536469
Validation loss: 1.377337964632178

Epoch: 6| Step: 13
Training loss: 0.04901844635605812
Validation loss: 1.381936393758302

Epoch: 588| Step: 0
Training loss: 0.09626990556716919
Validation loss: 1.4117718563284924

Epoch: 6| Step: 1
Training loss: 0.05847877264022827
Validation loss: 1.395740988434002

Epoch: 6| Step: 2
Training loss: 0.04864393174648285
Validation loss: 1.3970587484298214

Epoch: 6| Step: 3
Training loss: 0.07824322581291199
Validation loss: 1.412053576079748

Epoch: 6| Step: 4
Training loss: 0.10084955394268036
Validation loss: 1.4080622343606846

Epoch: 6| Step: 5
Training loss: 0.048698410391807556
Validation loss: 1.401704821535336

Epoch: 6| Step: 6
Training loss: 0.09482916444540024
Validation loss: 1.416503913940922

Epoch: 6| Step: 7
Training loss: 0.07247785478830338
Validation loss: 1.4207277189018905

Epoch: 6| Step: 8
Training loss: 0.08381128311157227
Validation loss: 1.4402373939432123

Epoch: 6| Step: 9
Training loss: 0.07052256166934967
Validation loss: 1.450739525979565

Epoch: 6| Step: 10
Training loss: 0.0523991584777832
Validation loss: 1.4447577063755324

Epoch: 6| Step: 11
Training loss: 0.12609714269638062
Validation loss: 1.4690342667282268

Epoch: 6| Step: 12
Training loss: 0.12110878527164459
Validation loss: 1.4270385490950717

Epoch: 6| Step: 13
Training loss: 0.1598910093307495
Validation loss: 1.4289285329080397

Epoch: 589| Step: 0
Training loss: 0.10477134585380554
Validation loss: 1.4132050698803318

Epoch: 6| Step: 1
Training loss: 0.09355747699737549
Validation loss: 1.406876685798809

Epoch: 6| Step: 2
Training loss: 0.07735522836446762
Validation loss: 1.4177981525339105

Epoch: 6| Step: 3
Training loss: 0.0941450372338295
Validation loss: 1.4325813657494002

Epoch: 6| Step: 4
Training loss: 0.06771111488342285
Validation loss: 1.4051550331936087

Epoch: 6| Step: 5
Training loss: 0.1343477964401245
Validation loss: 1.3896204553624636

Epoch: 6| Step: 6
Training loss: 0.09705226868391037
Validation loss: 1.4233476064538444

Epoch: 6| Step: 7
Training loss: 0.07231027632951736
Validation loss: 1.4314846249036892

Epoch: 6| Step: 8
Training loss: 0.0725422203540802
Validation loss: 1.4256342931460309

Epoch: 6| Step: 9
Training loss: 0.0402400940656662
Validation loss: 1.378748054786395

Epoch: 6| Step: 10
Training loss: 0.06856506317853928
Validation loss: 1.4036698431097052

Epoch: 6| Step: 11
Training loss: 0.09112834930419922
Validation loss: 1.3985547647681287

Epoch: 6| Step: 12
Training loss: 0.10954483598470688
Validation loss: 1.3871329548538371

Epoch: 6| Step: 13
Training loss: 0.18305929005146027
Validation loss: 1.3844336822468748

Epoch: 590| Step: 0
Training loss: 0.10837534070014954
Validation loss: 1.4012086660631242

Epoch: 6| Step: 1
Training loss: 0.06785275042057037
Validation loss: 1.3970315712754444

Epoch: 6| Step: 2
Training loss: 0.0567745640873909
Validation loss: 1.4226212847617365

Epoch: 6| Step: 3
Training loss: 0.054425813257694244
Validation loss: 1.405159895138074

Epoch: 6| Step: 4
Training loss: 0.10070276260375977
Validation loss: 1.4019841237734723

Epoch: 6| Step: 5
Training loss: 0.06252529472112656
Validation loss: 1.4215436725206272

Epoch: 6| Step: 6
Training loss: 0.07424180954694748
Validation loss: 1.3994285073331607

Epoch: 6| Step: 7
Training loss: 0.0658978819847107
Validation loss: 1.4181828191203456

Epoch: 6| Step: 8
Training loss: 0.05786702409386635
Validation loss: 1.4179592786296722

Epoch: 6| Step: 9
Training loss: 0.11178925633430481
Validation loss: 1.3859220691906509

Epoch: 6| Step: 10
Training loss: 0.07680781930685043
Validation loss: 1.39278152168438

Epoch: 6| Step: 11
Training loss: 0.13366243243217468
Validation loss: 1.3887676462050407

Epoch: 6| Step: 12
Training loss: 0.1029437929391861
Validation loss: 1.3859196145047423

Epoch: 6| Step: 13
Training loss: 0.12098094820976257
Validation loss: 1.3833871637621233

Epoch: 591| Step: 0
Training loss: 0.12241968512535095
Validation loss: 1.4120900823223976

Epoch: 6| Step: 1
Training loss: 0.12031334638595581
Validation loss: 1.4183365965402255

Epoch: 6| Step: 2
Training loss: 0.059204939752817154
Validation loss: 1.4127333676943215

Epoch: 6| Step: 3
Training loss: 0.10397806763648987
Validation loss: 1.4396144087596605

Epoch: 6| Step: 4
Training loss: 0.12557202577590942
Validation loss: 1.4267389069321335

Epoch: 6| Step: 5
Training loss: 0.09096682816743851
Validation loss: 1.4339880187024352

Epoch: 6| Step: 6
Training loss: 0.09754834324121475
Validation loss: 1.4398841050363356

Epoch: 6| Step: 7
Training loss: 0.0723303034901619
Validation loss: 1.4281207489710983

Epoch: 6| Step: 8
Training loss: 0.059356994926929474
Validation loss: 1.4447195427392119

Epoch: 6| Step: 9
Training loss: 0.09647518396377563
Validation loss: 1.4422750293567617

Epoch: 6| Step: 10
Training loss: 0.05595482513308525
Validation loss: 1.447623916851577

Epoch: 6| Step: 11
Training loss: 0.08872213214635849
Validation loss: 1.4318984682841966

Epoch: 6| Step: 12
Training loss: 0.06768359243869781
Validation loss: 1.4443046354478406

Epoch: 6| Step: 13
Training loss: 0.18823783099651337
Validation loss: 1.4299159857534594

Epoch: 592| Step: 0
Training loss: 0.1017884612083435
Validation loss: 1.3975601811562814

Epoch: 6| Step: 1
Training loss: 0.12240031361579895
Validation loss: 1.3745836327152867

Epoch: 6| Step: 2
Training loss: 0.058771781623363495
Validation loss: 1.381967713755946

Epoch: 6| Step: 3
Training loss: 0.10167284309864044
Validation loss: 1.3774111174768018

Epoch: 6| Step: 4
Training loss: 0.1027463749051094
Validation loss: 1.3803507038342056

Epoch: 6| Step: 5
Training loss: 0.11102321743965149
Validation loss: 1.3800408071087253

Epoch: 6| Step: 6
Training loss: 0.06080780178308487
Validation loss: 1.3640687132394442

Epoch: 6| Step: 7
Training loss: 0.07332748174667358
Validation loss: 1.4069038078349123

Epoch: 6| Step: 8
Training loss: 0.08142261952161789
Validation loss: 1.4116612147259455

Epoch: 6| Step: 9
Training loss: 0.10639670491218567
Validation loss: 1.444608014117005

Epoch: 6| Step: 10
Training loss: 0.062265828251838684
Validation loss: 1.440851221802414

Epoch: 6| Step: 11
Training loss: 0.07566047459840775
Validation loss: 1.464949111784658

Epoch: 6| Step: 12
Training loss: 0.0842788815498352
Validation loss: 1.487949017555483

Epoch: 6| Step: 13
Training loss: 0.06634750962257385
Validation loss: 1.489290976396171

Epoch: 593| Step: 0
Training loss: 0.07778149098157883
Validation loss: 1.5292197811988093

Epoch: 6| Step: 1
Training loss: 0.0765969306230545
Validation loss: 1.521664729682348

Epoch: 6| Step: 2
Training loss: 0.07257726043462753
Validation loss: 1.5328649654183337

Epoch: 6| Step: 3
Training loss: 0.07948602735996246
Validation loss: 1.520229374208758

Epoch: 6| Step: 4
Training loss: 0.07182688266038895
Validation loss: 1.5105805563670334

Epoch: 6| Step: 5
Training loss: 0.09629413485527039
Validation loss: 1.492013991519969

Epoch: 6| Step: 6
Training loss: 0.10312807559967041
Validation loss: 1.495196787259912

Epoch: 6| Step: 7
Training loss: 0.10451412200927734
Validation loss: 1.4743596161565473

Epoch: 6| Step: 8
Training loss: 0.06767847388982773
Validation loss: 1.4731699894833308

Epoch: 6| Step: 9
Training loss: 0.08463060855865479
Validation loss: 1.454915802965882

Epoch: 6| Step: 10
Training loss: 0.11669784784317017
Validation loss: 1.446593605062013

Epoch: 6| Step: 11
Training loss: 0.05559653043746948
Validation loss: 1.4304923024228824

Epoch: 6| Step: 12
Training loss: 0.09014298766851425
Validation loss: 1.4146502787067043

Epoch: 6| Step: 13
Training loss: 0.11517950892448425
Validation loss: 1.4021215618297618

Epoch: 594| Step: 0
Training loss: 0.10552459955215454
Validation loss: 1.4003099619701345

Epoch: 6| Step: 1
Training loss: 0.08774648606777191
Validation loss: 1.3791466438642113

Epoch: 6| Step: 2
Training loss: 0.06523120403289795
Validation loss: 1.3725592282510573

Epoch: 6| Step: 3
Training loss: 0.059565573930740356
Validation loss: 1.3629219262830672

Epoch: 6| Step: 4
Training loss: 0.06293778121471405
Validation loss: 1.3711802382622995

Epoch: 6| Step: 5
Training loss: 0.045840874314308167
Validation loss: 1.4049985690783429

Epoch: 6| Step: 6
Training loss: 0.06352764368057251
Validation loss: 1.3994926047581497

Epoch: 6| Step: 7
Training loss: 0.07041940838098526
Validation loss: 1.421105969336725

Epoch: 6| Step: 8
Training loss: 0.16650322079658508
Validation loss: 1.4412885712039085

Epoch: 6| Step: 9
Training loss: 0.0841335728764534
Validation loss: 1.43668665552652

Epoch: 6| Step: 10
Training loss: 0.09768208861351013
Validation loss: 1.4258867797031198

Epoch: 6| Step: 11
Training loss: 0.11859290301799774
Validation loss: 1.4280226999713528

Epoch: 6| Step: 12
Training loss: 0.12593874335289001
Validation loss: 1.4109407496708695

Epoch: 6| Step: 13
Training loss: 0.06364551931619644
Validation loss: 1.4119189285462903

Epoch: 595| Step: 0
Training loss: 0.04627396911382675
Validation loss: 1.4128182036902315

Epoch: 6| Step: 1
Training loss: 0.08862604200839996
Validation loss: 1.405592563331768

Epoch: 6| Step: 2
Training loss: 0.08900101482868195
Validation loss: 1.4005342683484476

Epoch: 6| Step: 3
Training loss: 0.0902562290430069
Validation loss: 1.4070022721444406

Epoch: 6| Step: 4
Training loss: 0.12056812644004822
Validation loss: 1.3898865061421548

Epoch: 6| Step: 5
Training loss: 0.08579857647418976
Validation loss: 1.3784742009255193

Epoch: 6| Step: 6
Training loss: 0.07676457613706589
Validation loss: 1.3670050585141746

Epoch: 6| Step: 7
Training loss: 0.1243354007601738
Validation loss: 1.333672454280238

Epoch: 6| Step: 8
Training loss: 0.07349094748497009
Validation loss: 1.3522922467159968

Epoch: 6| Step: 9
Training loss: 0.0629810094833374
Validation loss: 1.3181940086426274

Epoch: 6| Step: 10
Training loss: 0.08770764619112015
Validation loss: 1.3535007533206735

Epoch: 6| Step: 11
Training loss: 0.11386138200759888
Validation loss: 1.371757749588259

Epoch: 6| Step: 12
Training loss: 0.05279302969574928
Validation loss: 1.3676270797688475

Epoch: 6| Step: 13
Training loss: 0.09020360559225082
Validation loss: 1.3619303972490373

Epoch: 596| Step: 0
Training loss: 0.09494979679584503
Validation loss: 1.368038909409636

Epoch: 6| Step: 1
Training loss: 0.11892182379961014
Validation loss: 1.3785376253948416

Epoch: 6| Step: 2
Training loss: 0.08144065737724304
Validation loss: 1.3784959521344913

Epoch: 6| Step: 3
Training loss: 0.062079768627882004
Validation loss: 1.4023966071426228

Epoch: 6| Step: 4
Training loss: 0.060322586447000504
Validation loss: 1.383664164491879

Epoch: 6| Step: 5
Training loss: 0.08438562601804733
Validation loss: 1.4016079466830018

Epoch: 6| Step: 6
Training loss: 0.14249208569526672
Validation loss: 1.4057873295199486

Epoch: 6| Step: 7
Training loss: 0.11702217161655426
Validation loss: 1.3932665041697923

Epoch: 6| Step: 8
Training loss: 0.053824134171009064
Validation loss: 1.3796680973422142

Epoch: 6| Step: 9
Training loss: 0.06644732505083084
Validation loss: 1.3851332292761853

Epoch: 6| Step: 10
Training loss: 0.10623820871114731
Validation loss: 1.3741896703679075

Epoch: 6| Step: 11
Training loss: 0.09626595675945282
Validation loss: 1.4031206612945886

Epoch: 6| Step: 12
Training loss: 0.07428228110074997
Validation loss: 1.3851490969298987

Epoch: 6| Step: 13
Training loss: 0.08284321427345276
Validation loss: 1.3952641416621465

Epoch: 597| Step: 0
Training loss: 0.05807743966579437
Validation loss: 1.3577924069537912

Epoch: 6| Step: 1
Training loss: 0.12487901002168655
Validation loss: 1.3767802266664402

Epoch: 6| Step: 2
Training loss: 0.12355039268732071
Validation loss: 1.3828866122871317

Epoch: 6| Step: 3
Training loss: 0.1431269347667694
Validation loss: 1.365749568067571

Epoch: 6| Step: 4
Training loss: 0.10255195200443268
Validation loss: 1.387571479684563

Epoch: 6| Step: 5
Training loss: 0.08662983030080795
Validation loss: 1.373915236483338

Epoch: 6| Step: 6
Training loss: 0.08916033804416656
Validation loss: 1.3630033427028245

Epoch: 6| Step: 7
Training loss: 0.046981338411569595
Validation loss: 1.355007145994453

Epoch: 6| Step: 8
Training loss: 0.05849190056324005
Validation loss: 1.3880164668124209

Epoch: 6| Step: 9
Training loss: 0.06616369634866714
Validation loss: 1.35812214497597

Epoch: 6| Step: 10
Training loss: 0.06645766645669937
Validation loss: 1.3507228557781508

Epoch: 6| Step: 11
Training loss: 0.083787702023983
Validation loss: 1.3641421307799637

Epoch: 6| Step: 12
Training loss: 0.13901779055595398
Validation loss: 1.368374914251348

Epoch: 6| Step: 13
Training loss: 0.11700105667114258
Validation loss: 1.3559538036264398

Epoch: 598| Step: 0
Training loss: 0.07525020837783813
Validation loss: 1.35694295232014

Epoch: 6| Step: 1
Training loss: 0.050507426261901855
Validation loss: 1.3586728560027255

Epoch: 6| Step: 2
Training loss: 0.03328487649559975
Validation loss: 1.372978437331415

Epoch: 6| Step: 3
Training loss: 0.1640685498714447
Validation loss: 1.3817184240587297

Epoch: 6| Step: 4
Training loss: 0.06227881461381912
Validation loss: 1.363272084343818

Epoch: 6| Step: 5
Training loss: 0.13352340459823608
Validation loss: 1.3716166224530948

Epoch: 6| Step: 6
Training loss: 0.09516878426074982
Validation loss: 1.379062758978977

Epoch: 6| Step: 7
Training loss: 0.15163642168045044
Validation loss: 1.3920843139771493

Epoch: 6| Step: 8
Training loss: 0.05654776841402054
Validation loss: 1.4130516488065001

Epoch: 6| Step: 9
Training loss: 0.06447003036737442
Validation loss: 1.3935097032977688

Epoch: 6| Step: 10
Training loss: 0.06543657928705215
Validation loss: 1.4064035979650353

Epoch: 6| Step: 11
Training loss: 0.07396674156188965
Validation loss: 1.3877783013928322

Epoch: 6| Step: 12
Training loss: 0.09138356149196625
Validation loss: 1.3894747969924763

Epoch: 6| Step: 13
Training loss: 0.05492742359638214
Validation loss: 1.4146676704447756

Epoch: 599| Step: 0
Training loss: 0.09321049600839615
Validation loss: 1.3596090847446072

Epoch: 6| Step: 1
Training loss: 0.0858287364244461
Validation loss: 1.4068705317794636

Epoch: 6| Step: 2
Training loss: 0.08631813526153564
Validation loss: 1.3935727137391285

Epoch: 6| Step: 3
Training loss: 0.06414526700973511
Validation loss: 1.4074439182076404

Epoch: 6| Step: 4
Training loss: 0.06254959106445312
Validation loss: 1.4379253118268904

Epoch: 6| Step: 5
Training loss: 0.12051926553249359
Validation loss: 1.4353396302910262

Epoch: 6| Step: 6
Training loss: 0.036886878311634064
Validation loss: 1.4494963179352462

Epoch: 6| Step: 7
Training loss: 0.0884833112359047
Validation loss: 1.4640920136564521

Epoch: 6| Step: 8
Training loss: 0.1428031176328659
Validation loss: 1.4650276104609172

Epoch: 6| Step: 9
Training loss: 0.12574869394302368
Validation loss: 1.4641596976146902

Epoch: 6| Step: 10
Training loss: 0.06017543002963066
Validation loss: 1.4663417570052608

Epoch: 6| Step: 11
Training loss: 0.05459260940551758
Validation loss: 1.4166386345381379

Epoch: 6| Step: 12
Training loss: 0.07416868954896927
Validation loss: 1.4285789433346

Epoch: 6| Step: 13
Training loss: 0.07500849664211273
Validation loss: 1.4217557240557928

Epoch: 600| Step: 0
Training loss: 0.06522242724895477
Validation loss: 1.43505657616482

Epoch: 6| Step: 1
Training loss: 0.07381301373243332
Validation loss: 1.4074179510916434

Epoch: 6| Step: 2
Training loss: 0.09323004633188248
Validation loss: 1.3872100396822857

Epoch: 6| Step: 3
Training loss: 0.0894193947315216
Validation loss: 1.3793454465045725

Epoch: 6| Step: 4
Training loss: 0.07824829965829849
Validation loss: 1.4165238821378319

Epoch: 6| Step: 5
Training loss: 0.07803496718406677
Validation loss: 1.4111025141131492

Epoch: 6| Step: 6
Training loss: 0.07276236265897751
Validation loss: 1.4322197591104815

Epoch: 6| Step: 7
Training loss: 0.05394159257411957
Validation loss: 1.4411839644114177

Epoch: 6| Step: 8
Training loss: 0.058140870183706284
Validation loss: 1.428007330945743

Epoch: 6| Step: 9
Training loss: 0.0630708858370781
Validation loss: 1.4305229161375312

Epoch: 6| Step: 10
Training loss: 0.07377534359693527
Validation loss: 1.406871275235248

Epoch: 6| Step: 11
Training loss: 0.06446719169616699
Validation loss: 1.3812869748761576

Epoch: 6| Step: 12
Training loss: 0.06871329993009567
Validation loss: 1.389827077106763

Epoch: 6| Step: 13
Training loss: 0.07806852459907532
Validation loss: 1.3765480364522626

Testing loss: 2.001145961549547
