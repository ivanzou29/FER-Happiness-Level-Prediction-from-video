Epoch: 1| Step: 0
Training loss: 5.91260290145874
Validation loss: 5.237005936202182

Epoch: 6| Step: 1
Training loss: 4.701617240905762
Validation loss: 5.20931322856616

Epoch: 6| Step: 2
Training loss: 5.25264310836792
Validation loss: 5.1833011411851455

Epoch: 6| Step: 3
Training loss: 4.913150787353516
Validation loss: 5.155268807565013

Epoch: 6| Step: 4
Training loss: 3.4146313667297363
Validation loss: 5.124523788370112

Epoch: 6| Step: 5
Training loss: 4.281838417053223
Validation loss: 5.089554648245534

Epoch: 6| Step: 6
Training loss: 6.372154712677002
Validation loss: 5.050541523964174

Epoch: 6| Step: 7
Training loss: 5.614109992980957
Validation loss: 5.007239116135464

Epoch: 6| Step: 8
Training loss: 5.290889263153076
Validation loss: 4.959193870585452

Epoch: 6| Step: 9
Training loss: 4.4835381507873535
Validation loss: 4.906597762979487

Epoch: 6| Step: 10
Training loss: 4.07293701171875
Validation loss: 4.850532393301687

Epoch: 6| Step: 11
Training loss: 3.8236567974090576
Validation loss: 4.790416584219984

Epoch: 6| Step: 12
Training loss: 5.292331218719482
Validation loss: 4.727528874592115

Epoch: 6| Step: 13
Training loss: 2.9308395385742188
Validation loss: 4.66361262208672

Epoch: 2| Step: 0
Training loss: 4.98671817779541
Validation loss: 4.599287438136275

Epoch: 6| Step: 1
Training loss: 4.107492446899414
Validation loss: 4.535684436880132

Epoch: 6| Step: 2
Training loss: 4.430210113525391
Validation loss: 4.47400099744079

Epoch: 6| Step: 3
Training loss: 4.77496862411499
Validation loss: 4.415680090586345

Epoch: 6| Step: 4
Training loss: 3.3893909454345703
Validation loss: 4.362867632219868

Epoch: 6| Step: 5
Training loss: 3.875277042388916
Validation loss: 4.315155788134503

Epoch: 6| Step: 6
Training loss: 3.1795241832733154
Validation loss: 4.275755646408245

Epoch: 6| Step: 7
Training loss: 5.161169528961182
Validation loss: 4.242831983873921

Epoch: 6| Step: 8
Training loss: 4.139951705932617
Validation loss: 4.2109047161635536

Epoch: 6| Step: 9
Training loss: 3.7944514751434326
Validation loss: 4.177391741865424

Epoch: 6| Step: 10
Training loss: 3.344353675842285
Validation loss: 4.140577206047633

Epoch: 6| Step: 11
Training loss: 4.243167877197266
Validation loss: 4.096557771005938

Epoch: 6| Step: 12
Training loss: 3.5048422813415527
Validation loss: 4.043891286337248

Epoch: 6| Step: 13
Training loss: 5.023866653442383
Validation loss: 3.9927760913807857

Epoch: 3| Step: 0
Training loss: 3.948629856109619
Validation loss: 3.9448670264213317

Epoch: 6| Step: 1
Training loss: 2.9757909774780273
Validation loss: 3.906617672212662

Epoch: 6| Step: 2
Training loss: 4.244335174560547
Validation loss: 3.8684038398086384

Epoch: 6| Step: 3
Training loss: 3.093012571334839
Validation loss: 3.836343939586352

Epoch: 6| Step: 4
Training loss: 3.055205821990967
Validation loss: 3.803613890883743

Epoch: 6| Step: 5
Training loss: 4.5235185623168945
Validation loss: 3.7720434563134306

Epoch: 6| Step: 6
Training loss: 3.5732007026672363
Validation loss: 3.7389681493082354

Epoch: 6| Step: 7
Training loss: 3.612027645111084
Validation loss: 3.7041885263176373

Epoch: 6| Step: 8
Training loss: 2.712958574295044
Validation loss: 3.6707419938938592

Epoch: 6| Step: 9
Training loss: 3.3363332748413086
Validation loss: 3.642693511901363

Epoch: 6| Step: 10
Training loss: 4.732410430908203
Validation loss: 3.613937352293281

Epoch: 6| Step: 11
Training loss: 4.116178512573242
Validation loss: 3.580773979104975

Epoch: 6| Step: 12
Training loss: 3.0445618629455566
Validation loss: 3.5472885408709125

Epoch: 6| Step: 13
Training loss: 3.7101564407348633
Validation loss: 3.5239776693364626

Epoch: 4| Step: 0
Training loss: 2.9664576053619385
Validation loss: 3.511384356406427

Epoch: 6| Step: 1
Training loss: 3.354581356048584
Validation loss: 3.481267665022163

Epoch: 6| Step: 2
Training loss: 3.4997289180755615
Validation loss: 3.4544012085083993

Epoch: 6| Step: 3
Training loss: 4.205766677856445
Validation loss: 3.4340144049736763

Epoch: 6| Step: 4
Training loss: 3.5215377807617188
Validation loss: 3.4106507711513068

Epoch: 6| Step: 5
Training loss: 3.9718217849731445
Validation loss: 3.3899853075704267

Epoch: 6| Step: 6
Training loss: 3.3808727264404297
Validation loss: 3.3640650959425074

Epoch: 6| Step: 7
Training loss: 3.4974846839904785
Validation loss: 3.340497955199211

Epoch: 6| Step: 8
Training loss: 3.1295135021209717
Validation loss: 3.3217659073491252

Epoch: 6| Step: 9
Training loss: 3.1779234409332275
Validation loss: 3.297209078265775

Epoch: 6| Step: 10
Training loss: 2.5580248832702637
Validation loss: 3.2768114305311635

Epoch: 6| Step: 11
Training loss: 2.842789888381958
Validation loss: 3.2559915229838383

Epoch: 6| Step: 12
Training loss: 3.4380335807800293
Validation loss: 3.2371519970637497

Epoch: 6| Step: 13
Training loss: 2.7674927711486816
Validation loss: 3.2181289554924093

Epoch: 5| Step: 0
Training loss: 2.8456218242645264
Validation loss: 3.2001448497977307

Epoch: 6| Step: 1
Training loss: 2.665003776550293
Validation loss: 3.18420740865892

Epoch: 6| Step: 2
Training loss: 2.6002233028411865
Validation loss: 3.1693546387457077

Epoch: 6| Step: 3
Training loss: 2.950505256652832
Validation loss: 3.1573128238801034

Epoch: 6| Step: 4
Training loss: 3.7160844802856445
Validation loss: 3.147430307121687

Epoch: 6| Step: 5
Training loss: 2.502142906188965
Validation loss: 3.139231579278105

Epoch: 6| Step: 6
Training loss: 3.4926350116729736
Validation loss: 3.127645197735038

Epoch: 6| Step: 7
Training loss: 3.1998817920684814
Validation loss: 3.1095764354992936

Epoch: 6| Step: 8
Training loss: 3.2214407920837402
Validation loss: 3.091166739822716

Epoch: 6| Step: 9
Training loss: 3.919464349746704
Validation loss: 3.076148820179765

Epoch: 6| Step: 10
Training loss: 2.5915255546569824
Validation loss: 3.0680013395124868

Epoch: 6| Step: 11
Training loss: 4.473543167114258
Validation loss: 3.0427672273369244

Epoch: 6| Step: 12
Training loss: 3.2347335815429688
Validation loss: 3.02226266296961

Epoch: 6| Step: 13
Training loss: 1.9273741245269775
Validation loss: 3.0104762687478015

Epoch: 6| Step: 0
Training loss: 2.9677205085754395
Validation loss: 2.998105623388803

Epoch: 6| Step: 1
Training loss: 3.4987082481384277
Validation loss: 2.989414632961314

Epoch: 6| Step: 2
Training loss: 3.083803653717041
Validation loss: 2.9753421301482827

Epoch: 6| Step: 3
Training loss: 3.6307382583618164
Validation loss: 2.961918477089174

Epoch: 6| Step: 4
Training loss: 3.212846517562866
Validation loss: 2.9516893612441195

Epoch: 6| Step: 5
Training loss: 3.2483134269714355
Validation loss: 2.939219290210355

Epoch: 6| Step: 6
Training loss: 2.8441901206970215
Validation loss: 2.9172735726961525

Epoch: 6| Step: 7
Training loss: 2.4309098720550537
Validation loss: 2.9231287971619637

Epoch: 6| Step: 8
Training loss: 3.4719176292419434
Validation loss: 2.969978714501986

Epoch: 6| Step: 9
Training loss: 2.927711009979248
Validation loss: 2.89310008992431

Epoch: 6| Step: 10
Training loss: 2.822080612182617
Validation loss: 2.8920766743280555

Epoch: 6| Step: 11
Training loss: 2.1411619186401367
Validation loss: 2.9200931518308577

Epoch: 6| Step: 12
Training loss: 2.7669718265533447
Validation loss: 2.9274193215113815

Epoch: 6| Step: 13
Training loss: 3.5113937854766846
Validation loss: 2.9180649352330033

Epoch: 7| Step: 0
Training loss: 3.7671308517456055
Validation loss: 2.8908453013307307

Epoch: 6| Step: 1
Training loss: 2.8928134441375732
Validation loss: 2.8663434751572145

Epoch: 6| Step: 2
Training loss: 2.6799280643463135
Validation loss: 2.8576070749631493

Epoch: 6| Step: 3
Training loss: 2.941746711730957
Validation loss: 2.8581588806644564

Epoch: 6| Step: 4
Training loss: 4.148680210113525
Validation loss: 2.8740416290939494

Epoch: 6| Step: 5
Training loss: 3.2958455085754395
Validation loss: 2.8687673922507995

Epoch: 6| Step: 6
Training loss: 3.0861682891845703
Validation loss: 2.856217243338144

Epoch: 6| Step: 7
Training loss: 2.646069288253784
Validation loss: 2.815524672949186

Epoch: 6| Step: 8
Training loss: 2.6185665130615234
Validation loss: 2.8041908151359967

Epoch: 6| Step: 9
Training loss: 3.5700628757476807
Validation loss: 2.7881155578039025

Epoch: 6| Step: 10
Training loss: 2.0007286071777344
Validation loss: 2.779076730051348

Epoch: 6| Step: 11
Training loss: 2.537334680557251
Validation loss: 2.7716186713146906

Epoch: 6| Step: 12
Training loss: 2.442243814468384
Validation loss: 2.769793812946607

Epoch: 6| Step: 13
Training loss: 2.4600753784179688
Validation loss: 2.757874242721065

Epoch: 8| Step: 0
Training loss: 2.509307861328125
Validation loss: 2.76114930388748

Epoch: 6| Step: 1
Training loss: 2.765145778656006
Validation loss: 2.757200005233929

Epoch: 6| Step: 2
Training loss: 3.1226444244384766
Validation loss: 2.7437394126769035

Epoch: 6| Step: 3
Training loss: 2.8493170738220215
Validation loss: 2.724723172444169

Epoch: 6| Step: 4
Training loss: 3.009859561920166
Validation loss: 2.717509477369247

Epoch: 6| Step: 5
Training loss: 2.7668943405151367
Validation loss: 2.70959460607139

Epoch: 6| Step: 6
Training loss: 2.8634824752807617
Validation loss: 2.707740501690936

Epoch: 6| Step: 7
Training loss: 2.928530693054199
Validation loss: 2.7038597958062285

Epoch: 6| Step: 8
Training loss: 3.1092545986175537
Validation loss: 2.6996125636562223

Epoch: 6| Step: 9
Training loss: 2.9690871238708496
Validation loss: 2.7034245101354455

Epoch: 6| Step: 10
Training loss: 3.282759428024292
Validation loss: 2.722143973073652

Epoch: 6| Step: 11
Training loss: 3.0648844242095947
Validation loss: 2.6989215445774857

Epoch: 6| Step: 12
Training loss: 2.2384896278381348
Validation loss: 2.6738610216366347

Epoch: 6| Step: 13
Training loss: 2.747861862182617
Validation loss: 2.668280275919104

Epoch: 9| Step: 0
Training loss: 2.766101360321045
Validation loss: 2.6695722636356147

Epoch: 6| Step: 1
Training loss: 1.9713706970214844
Validation loss: 2.6589158170966694

Epoch: 6| Step: 2
Training loss: 3.9311914443969727
Validation loss: 2.6627315885277203

Epoch: 6| Step: 3
Training loss: 2.6009230613708496
Validation loss: 2.655393333845241

Epoch: 6| Step: 4
Training loss: 3.1811516284942627
Validation loss: 2.648412573722101

Epoch: 6| Step: 5
Training loss: 2.5989010334014893
Validation loss: 2.6463013105495

Epoch: 6| Step: 6
Training loss: 2.570537567138672
Validation loss: 2.6416413168753348

Epoch: 6| Step: 7
Training loss: 2.676255226135254
Validation loss: 2.655768773889029

Epoch: 6| Step: 8
Training loss: 3.330219268798828
Validation loss: 2.64610695069836

Epoch: 6| Step: 9
Training loss: 2.611541271209717
Validation loss: 2.6300796513916342

Epoch: 6| Step: 10
Training loss: 2.891462802886963
Validation loss: 2.636507231702087

Epoch: 6| Step: 11
Training loss: 1.9810550212860107
Validation loss: 2.6485898827993744

Epoch: 6| Step: 12
Training loss: 3.27764892578125
Validation loss: 2.6614371345889185

Epoch: 6| Step: 13
Training loss: 3.718877077102661
Validation loss: 2.639037947500906

Epoch: 10| Step: 0
Training loss: 2.89444637298584
Validation loss: 2.62334172443677

Epoch: 6| Step: 1
Training loss: 2.7248992919921875
Validation loss: 2.607520557218982

Epoch: 6| Step: 2
Training loss: 3.2204482555389404
Validation loss: 2.602803594322615

Epoch: 6| Step: 3
Training loss: 2.415034770965576
Validation loss: 2.6019164541716218

Epoch: 6| Step: 4
Training loss: 2.2378082275390625
Validation loss: 2.6016710624899915

Epoch: 6| Step: 5
Training loss: 3.2378029823303223
Validation loss: 2.6058733078741256

Epoch: 6| Step: 6
Training loss: 2.9143645763397217
Validation loss: 2.6082913362851707

Epoch: 6| Step: 7
Training loss: 2.582986831665039
Validation loss: 2.616595155449324

Epoch: 6| Step: 8
Training loss: 2.9349517822265625
Validation loss: 2.606082765004968

Epoch: 6| Step: 9
Training loss: 3.0073578357696533
Validation loss: 2.6003810257040043

Epoch: 6| Step: 10
Training loss: 2.4773640632629395
Validation loss: 2.5947550163474133

Epoch: 6| Step: 11
Training loss: 2.668560028076172
Validation loss: 2.5888567381007697

Epoch: 6| Step: 12
Training loss: 2.9166884422302246
Validation loss: 2.5822895291031047

Epoch: 6| Step: 13
Training loss: 3.2985198497772217
Validation loss: 2.579336856001167

Epoch: 11| Step: 0
Training loss: 2.7185044288635254
Validation loss: 2.578957352586972

Epoch: 6| Step: 1
Training loss: 3.169578790664673
Validation loss: 2.5789912490434546

Epoch: 6| Step: 2
Training loss: 2.206374406814575
Validation loss: 2.5811268873112176

Epoch: 6| Step: 3
Training loss: 3.159543991088867
Validation loss: 2.581737164528139

Epoch: 6| Step: 4
Training loss: 3.0217390060424805
Validation loss: 2.572261559065952

Epoch: 6| Step: 5
Training loss: 3.1184334754943848
Validation loss: 2.5749200672231694

Epoch: 6| Step: 6
Training loss: 3.3181440830230713
Validation loss: 2.5664846743306806

Epoch: 6| Step: 7
Training loss: 2.311586380004883
Validation loss: 2.5654856543387137

Epoch: 6| Step: 8
Training loss: 2.7386391162872314
Validation loss: 2.5627632397477345

Epoch: 6| Step: 9
Training loss: 2.3492188453674316
Validation loss: 2.5570091124503844

Epoch: 6| Step: 10
Training loss: 2.457528829574585
Validation loss: 2.5600230796362764

Epoch: 6| Step: 11
Training loss: 2.5562987327575684
Validation loss: 2.56572296286142

Epoch: 6| Step: 12
Training loss: 2.8379733562469482
Validation loss: 2.5698870305092103

Epoch: 6| Step: 13
Training loss: 3.2692136764526367
Validation loss: 2.5711431682750745

Epoch: 12| Step: 0
Training loss: 2.7785706520080566
Validation loss: 2.5726591156375025

Epoch: 6| Step: 1
Training loss: 2.49953293800354
Validation loss: 2.5619082168866227

Epoch: 6| Step: 2
Training loss: 2.1823971271514893
Validation loss: 2.5780344778491604

Epoch: 6| Step: 3
Training loss: 2.4980485439300537
Validation loss: 2.557582337369201

Epoch: 6| Step: 4
Training loss: 3.1286182403564453
Validation loss: 2.547914444759328

Epoch: 6| Step: 5
Training loss: 2.704355239868164
Validation loss: 2.5418986966533046

Epoch: 6| Step: 6
Training loss: 2.8968381881713867
Validation loss: 2.537783863723919

Epoch: 6| Step: 7
Training loss: 2.4272584915161133
Validation loss: 2.533733780666064

Epoch: 6| Step: 8
Training loss: 3.7280619144439697
Validation loss: 2.5386664636673464

Epoch: 6| Step: 9
Training loss: 3.303589344024658
Validation loss: 2.532378206970871

Epoch: 6| Step: 10
Training loss: 3.1305251121520996
Validation loss: 2.5314481899302494

Epoch: 6| Step: 11
Training loss: 2.397028923034668
Validation loss: 2.528946425325127

Epoch: 6| Step: 12
Training loss: 2.2806129455566406
Validation loss: 2.535142970341508

Epoch: 6| Step: 13
Training loss: 2.8808555603027344
Validation loss: 2.5327044584417857

Epoch: 13| Step: 0
Training loss: 2.8208436965942383
Validation loss: 2.532881062517884

Epoch: 6| Step: 1
Training loss: 2.910036563873291
Validation loss: 2.5355599439272316

Epoch: 6| Step: 2
Training loss: 3.0092899799346924
Validation loss: 2.5291885714377127

Epoch: 6| Step: 3
Training loss: 2.393592596054077
Validation loss: 2.521131443720992

Epoch: 6| Step: 4
Training loss: 2.7214603424072266
Validation loss: 2.5214681035728863

Epoch: 6| Step: 5
Training loss: 2.075676441192627
Validation loss: 2.524922065837409

Epoch: 6| Step: 6
Training loss: 2.8786866664886475
Validation loss: 2.519877326103949

Epoch: 6| Step: 7
Training loss: 3.185319423675537
Validation loss: 2.522546127278318

Epoch: 6| Step: 8
Training loss: 2.610074996948242
Validation loss: 2.5357826473892375

Epoch: 6| Step: 9
Training loss: 3.2578368186950684
Validation loss: 2.5214835571986374

Epoch: 6| Step: 10
Training loss: 2.5556859970092773
Validation loss: 2.5132981154226486

Epoch: 6| Step: 11
Training loss: 2.3288559913635254
Validation loss: 2.5121855915233655

Epoch: 6| Step: 12
Training loss: 2.6100568771362305
Validation loss: 2.507158798556174

Epoch: 6| Step: 13
Training loss: 3.2819035053253174
Validation loss: 2.5095240326337915

Epoch: 14| Step: 0
Training loss: 2.349396228790283
Validation loss: 2.518004689165341

Epoch: 6| Step: 1
Training loss: 2.7697126865386963
Validation loss: 2.542386293411255

Epoch: 6| Step: 2
Training loss: 3.1696786880493164
Validation loss: 2.52075861089973

Epoch: 6| Step: 3
Training loss: 3.449568271636963
Validation loss: 2.506805955722768

Epoch: 6| Step: 4
Training loss: 2.4715704917907715
Validation loss: 2.5046672154498357

Epoch: 6| Step: 5
Training loss: 1.8735175132751465
Validation loss: 2.501588726556429

Epoch: 6| Step: 6
Training loss: 2.877734661102295
Validation loss: 2.5060971321598178

Epoch: 6| Step: 7
Training loss: 2.6929991245269775
Validation loss: 2.50472399239899

Epoch: 6| Step: 8
Training loss: 1.9996384382247925
Validation loss: 2.503116118010654

Epoch: 6| Step: 9
Training loss: 2.87924861907959
Validation loss: 2.4941880344062723

Epoch: 6| Step: 10
Training loss: 3.2441654205322266
Validation loss: 2.4962106263765724

Epoch: 6| Step: 11
Training loss: 2.6837236881256104
Validation loss: 2.528492614787112

Epoch: 6| Step: 12
Training loss: 3.0054168701171875
Validation loss: 2.537057125440208

Epoch: 6| Step: 13
Training loss: 2.6709041595458984
Validation loss: 2.5026314566212315

Epoch: 15| Step: 0
Training loss: 2.262596607208252
Validation loss: 2.475566961432016

Epoch: 6| Step: 1
Training loss: 3.446265697479248
Validation loss: 2.4800135756051667

Epoch: 6| Step: 2
Training loss: 2.7422797679901123
Validation loss: 2.479912337436471

Epoch: 6| Step: 3
Training loss: 2.7341601848602295
Validation loss: 2.479376946726153

Epoch: 6| Step: 4
Training loss: 3.0393214225769043
Validation loss: 2.483730185416437

Epoch: 6| Step: 5
Training loss: 2.6867456436157227
Validation loss: 2.4895793801994732

Epoch: 6| Step: 6
Training loss: 2.1525990962982178
Validation loss: 2.4886139080088627

Epoch: 6| Step: 7
Training loss: 2.400895118713379
Validation loss: 2.4979019985404065

Epoch: 6| Step: 8
Training loss: 3.143519639968872
Validation loss: 2.515572553039879

Epoch: 6| Step: 9
Training loss: 3.0577614307403564
Validation loss: 2.4954179115192865

Epoch: 6| Step: 10
Training loss: 2.0802040100097656
Validation loss: 2.483213686173962

Epoch: 6| Step: 11
Training loss: 3.45695424079895
Validation loss: 2.4808910610855266

Epoch: 6| Step: 12
Training loss: 2.2128729820251465
Validation loss: 2.4710241338258148

Epoch: 6| Step: 13
Training loss: 2.4348671436309814
Validation loss: 2.4742900633042857

Epoch: 16| Step: 0
Training loss: 3.381221294403076
Validation loss: 2.4635641036495084

Epoch: 6| Step: 1
Training loss: 2.6925289630889893
Validation loss: 2.474583746284567

Epoch: 6| Step: 2
Training loss: 3.0275826454162598
Validation loss: 2.4623407420291694

Epoch: 6| Step: 3
Training loss: 3.5778141021728516
Validation loss: 2.458679663237705

Epoch: 6| Step: 4
Training loss: 2.2558932304382324
Validation loss: 2.480774715382566

Epoch: 6| Step: 5
Training loss: 3.337022304534912
Validation loss: 2.483458842000654

Epoch: 6| Step: 6
Training loss: 1.9728915691375732
Validation loss: 2.5199393815891717

Epoch: 6| Step: 7
Training loss: 2.6821043491363525
Validation loss: 2.5390564241716937

Epoch: 6| Step: 8
Training loss: 2.4137372970581055
Validation loss: 2.5245754218870595

Epoch: 6| Step: 9
Training loss: 2.287301540374756
Validation loss: 2.4888434820277716

Epoch: 6| Step: 10
Training loss: 2.305339813232422
Validation loss: 2.455716686864053

Epoch: 6| Step: 11
Training loss: 2.538527250289917
Validation loss: 2.4647075437730357

Epoch: 6| Step: 12
Training loss: 3.1918387413024902
Validation loss: 2.500830178619713

Epoch: 6| Step: 13
Training loss: 2.1177473068237305
Validation loss: 2.4994488172633673

Epoch: 17| Step: 0
Training loss: 3.221233367919922
Validation loss: 2.4766932174723637

Epoch: 6| Step: 1
Training loss: 2.795185089111328
Validation loss: 2.4544109682882986

Epoch: 6| Step: 2
Training loss: 1.9584953784942627
Validation loss: 2.4421843098055933

Epoch: 6| Step: 3
Training loss: 2.667170763015747
Validation loss: 2.444142851778256

Epoch: 6| Step: 4
Training loss: 1.6565959453582764
Validation loss: 2.47354515265393

Epoch: 6| Step: 5
Training loss: 3.597804546356201
Validation loss: 2.4975875269982124

Epoch: 6| Step: 6
Training loss: 2.109739303588867
Validation loss: 2.5260964849943757

Epoch: 6| Step: 7
Training loss: 2.408811092376709
Validation loss: 2.4990909484124955

Epoch: 6| Step: 8
Training loss: 3.224752902984619
Validation loss: 2.4688149985446723

Epoch: 6| Step: 9
Training loss: 2.6751797199249268
Validation loss: 2.4643214800024547

Epoch: 6| Step: 10
Training loss: 3.5495595932006836
Validation loss: 2.4695641379202566

Epoch: 6| Step: 11
Training loss: 3.0343551635742188
Validation loss: 2.4875166236713366

Epoch: 6| Step: 12
Training loss: 2.234708547592163
Validation loss: 2.485205670838715

Epoch: 6| Step: 13
Training loss: 2.9630000591278076
Validation loss: 2.469033912945819

Epoch: 18| Step: 0
Training loss: 2.588329315185547
Validation loss: 2.452186794691188

Epoch: 6| Step: 1
Training loss: 2.1725974082946777
Validation loss: 2.445715242816556

Epoch: 6| Step: 2
Training loss: 2.699568748474121
Validation loss: 2.4437077071077082

Epoch: 6| Step: 3
Training loss: 3.057260036468506
Validation loss: 2.447201475020378

Epoch: 6| Step: 4
Training loss: 2.4041922092437744
Validation loss: 2.442556901644635

Epoch: 6| Step: 5
Training loss: 2.4936232566833496
Validation loss: 2.437422194788533

Epoch: 6| Step: 6
Training loss: 3.1423420906066895
Validation loss: 2.4413569998997513

Epoch: 6| Step: 7
Training loss: 2.4016051292419434
Validation loss: 2.4318733625514533

Epoch: 6| Step: 8
Training loss: 2.2760345935821533
Validation loss: 2.4189046557231615

Epoch: 6| Step: 9
Training loss: 2.7747578620910645
Validation loss: 2.4218924609563683

Epoch: 6| Step: 10
Training loss: 3.0502748489379883
Validation loss: 2.419028607747888

Epoch: 6| Step: 11
Training loss: 2.7228684425354004
Validation loss: 2.4173058489317536

Epoch: 6| Step: 12
Training loss: 2.7515082359313965
Validation loss: 2.4245777745400705

Epoch: 6| Step: 13
Training loss: 3.093561887741089
Validation loss: 2.4526189373385523

Epoch: 19| Step: 0
Training loss: 2.7164766788482666
Validation loss: 2.520884293381886

Epoch: 6| Step: 1
Training loss: 2.0822787284851074
Validation loss: 2.586649335840697

Epoch: 6| Step: 2
Training loss: 3.284524917602539
Validation loss: 2.6398028660846014

Epoch: 6| Step: 3
Training loss: 3.5603742599487305
Validation loss: 2.665217343197074

Epoch: 6| Step: 4
Training loss: 3.1869256496429443
Validation loss: 2.61899317977249

Epoch: 6| Step: 5
Training loss: 2.1087465286254883
Validation loss: 2.592888791074035

Epoch: 6| Step: 6
Training loss: 3.269707202911377
Validation loss: 2.556993181987475

Epoch: 6| Step: 7
Training loss: 2.1101067066192627
Validation loss: 2.499303456275694

Epoch: 6| Step: 8
Training loss: 2.278918504714966
Validation loss: 2.4802921049056517

Epoch: 6| Step: 9
Training loss: 2.4808459281921387
Validation loss: 2.4705505909458285

Epoch: 6| Step: 10
Training loss: 2.3924055099487305
Validation loss: 2.4751393333558114

Epoch: 6| Step: 11
Training loss: 2.9737110137939453
Validation loss: 2.487719820391747

Epoch: 6| Step: 12
Training loss: 2.379101514816284
Validation loss: 2.4824396948660574

Epoch: 6| Step: 13
Training loss: 3.9178271293640137
Validation loss: 2.4791114432837373

Epoch: 20| Step: 0
Training loss: 3.12933087348938
Validation loss: 2.448227859312488

Epoch: 6| Step: 1
Training loss: 2.837106943130493
Validation loss: 2.430164619158673

Epoch: 6| Step: 2
Training loss: 2.7346138954162598
Validation loss: 2.416365131255119

Epoch: 6| Step: 3
Training loss: 2.5316314697265625
Validation loss: 2.4076587820565827

Epoch: 6| Step: 4
Training loss: 3.1365599632263184
Validation loss: 2.4038754355522896

Epoch: 6| Step: 5
Training loss: 2.1629743576049805
Validation loss: 2.403242670079713

Epoch: 6| Step: 6
Training loss: 2.1989195346832275
Validation loss: 2.4015926622575328

Epoch: 6| Step: 7
Training loss: 1.9171792268753052
Validation loss: 2.407415954015588

Epoch: 6| Step: 8
Training loss: 2.961348056793213
Validation loss: 2.4365852776394097

Epoch: 6| Step: 9
Training loss: 3.084965229034424
Validation loss: 2.47915393306363

Epoch: 6| Step: 10
Training loss: 2.966557502746582
Validation loss: 2.524298731998731

Epoch: 6| Step: 11
Training loss: 2.294238328933716
Validation loss: 2.534487307712596

Epoch: 6| Step: 12
Training loss: 2.883043050765991
Validation loss: 2.5565307755624094

Epoch: 6| Step: 13
Training loss: 2.7447385787963867
Validation loss: 2.4748517928584928

Epoch: 21| Step: 0
Training loss: 2.8493552207946777
Validation loss: 2.439155981104861

Epoch: 6| Step: 1
Training loss: 3.2907352447509766
Validation loss: 2.407340193307528

Epoch: 6| Step: 2
Training loss: 2.523953914642334
Validation loss: 2.390546279568826

Epoch: 6| Step: 3
Training loss: 1.9851608276367188
Validation loss: 2.3877446997550225

Epoch: 6| Step: 4
Training loss: 1.9715670347213745
Validation loss: 2.38842624233615

Epoch: 6| Step: 5
Training loss: 2.880431652069092
Validation loss: 2.3948749778091267

Epoch: 6| Step: 6
Training loss: 2.9753403663635254
Validation loss: 2.3986383638074322

Epoch: 6| Step: 7
Training loss: 2.9515562057495117
Validation loss: 2.4280957791113083

Epoch: 6| Step: 8
Training loss: 3.053908586502075
Validation loss: 2.458953642076062

Epoch: 6| Step: 9
Training loss: 2.0888044834136963
Validation loss: 2.453894063990603

Epoch: 6| Step: 10
Training loss: 3.3373584747314453
Validation loss: 2.470951816087128

Epoch: 6| Step: 11
Training loss: 2.3300445079803467
Validation loss: 2.4348718966207197

Epoch: 6| Step: 12
Training loss: 2.8898792266845703
Validation loss: 2.410409260821599

Epoch: 6| Step: 13
Training loss: 2.0415844917297363
Validation loss: 2.399603982125559

Epoch: 22| Step: 0
Training loss: 2.7135214805603027
Validation loss: 2.3905113871379564

Epoch: 6| Step: 1
Training loss: 2.397031307220459
Validation loss: 2.392818671400829

Epoch: 6| Step: 2
Training loss: 2.8461380004882812
Validation loss: 2.3933474376637447

Epoch: 6| Step: 3
Training loss: 1.2442618608474731
Validation loss: 2.393842035724271

Epoch: 6| Step: 4
Training loss: 3.097473621368408
Validation loss: 2.3957734889881586

Epoch: 6| Step: 5
Training loss: 1.8869822025299072
Validation loss: 2.392809085948493

Epoch: 6| Step: 6
Training loss: 3.384716749191284
Validation loss: 2.404609521230062

Epoch: 6| Step: 7
Training loss: 3.3954274654388428
Validation loss: 2.41000045499494

Epoch: 6| Step: 8
Training loss: 2.4800710678100586
Validation loss: 2.400256792704264

Epoch: 6| Step: 9
Training loss: 3.073941946029663
Validation loss: 2.3950193197496477

Epoch: 6| Step: 10
Training loss: 2.687772274017334
Validation loss: 2.392509639904063

Epoch: 6| Step: 11
Training loss: 3.1441268920898438
Validation loss: 2.3993418549978607

Epoch: 6| Step: 12
Training loss: 1.745473861694336
Validation loss: 2.4091798669548443

Epoch: 6| Step: 13
Training loss: 3.088852882385254
Validation loss: 2.420816324090445

Epoch: 23| Step: 0
Training loss: 2.21299147605896
Validation loss: 2.3986601521891933

Epoch: 6| Step: 1
Training loss: 2.7947890758514404
Validation loss: 2.385002084957656

Epoch: 6| Step: 2
Training loss: 2.978140354156494
Validation loss: 2.378514520583614

Epoch: 6| Step: 3
Training loss: 2.259819984436035
Validation loss: 2.3773925432594876

Epoch: 6| Step: 4
Training loss: 2.2921037673950195
Validation loss: 2.3797012913611626

Epoch: 6| Step: 5
Training loss: 3.132967948913574
Validation loss: 2.3777807758700464

Epoch: 6| Step: 6
Training loss: 2.978065013885498
Validation loss: 2.372382528038435

Epoch: 6| Step: 7
Training loss: 2.938021659851074
Validation loss: 2.3707010669092976

Epoch: 6| Step: 8
Training loss: 2.3335883617401123
Validation loss: 2.37390314122682

Epoch: 6| Step: 9
Training loss: 2.7031826972961426
Validation loss: 2.369045349859422

Epoch: 6| Step: 10
Training loss: 1.9678516387939453
Validation loss: 2.369753281275431

Epoch: 6| Step: 11
Training loss: 2.42356014251709
Validation loss: 2.3682652827232116

Epoch: 6| Step: 12
Training loss: 3.0101723670959473
Validation loss: 2.371061417364305

Epoch: 6| Step: 13
Training loss: 3.114152193069458
Validation loss: 2.3719395437548236

Epoch: 24| Step: 0
Training loss: 2.6159722805023193
Validation loss: 2.375548685750654

Epoch: 6| Step: 1
Training loss: 2.7080235481262207
Validation loss: 2.3821960521000687

Epoch: 6| Step: 2
Training loss: 2.832561492919922
Validation loss: 2.3912413479179464

Epoch: 6| Step: 3
Training loss: 1.4739515781402588
Validation loss: 2.4013668106448267

Epoch: 6| Step: 4
Training loss: 2.7507071495056152
Validation loss: 2.400732737715526

Epoch: 6| Step: 5
Training loss: 3.1975696086883545
Validation loss: 2.4066786689143025

Epoch: 6| Step: 6
Training loss: 2.6832573413848877
Validation loss: 2.393630717390327

Epoch: 6| Step: 7
Training loss: 2.910233736038208
Validation loss: 2.405610699807444

Epoch: 6| Step: 8
Training loss: 2.58644700050354
Validation loss: 2.4009118387776036

Epoch: 6| Step: 9
Training loss: 1.925286054611206
Validation loss: 2.3992111195800123

Epoch: 6| Step: 10
Training loss: 1.4180251359939575
Validation loss: 2.3910435348428707

Epoch: 6| Step: 11
Training loss: 3.151904582977295
Validation loss: 2.394038102960074

Epoch: 6| Step: 12
Training loss: 3.4231674671173096
Validation loss: 2.3836305167085383

Epoch: 6| Step: 13
Training loss: 3.39937686920166
Validation loss: 2.370443010842928

Epoch: 25| Step: 0
Training loss: 2.24252986907959
Validation loss: 2.3654164139942457

Epoch: 6| Step: 1
Training loss: 2.997540235519409
Validation loss: 2.364603675821776

Epoch: 6| Step: 2
Training loss: 2.677485942840576
Validation loss: 2.3650602192007084

Epoch: 6| Step: 3
Training loss: 2.318787097930908
Validation loss: 2.3665931224823

Epoch: 6| Step: 4
Training loss: 2.0692574977874756
Validation loss: 2.3658502306989444

Epoch: 6| Step: 5
Training loss: 2.7102584838867188
Validation loss: 2.3631805219957904

Epoch: 6| Step: 6
Training loss: 2.8791050910949707
Validation loss: 2.370099070251629

Epoch: 6| Step: 7
Training loss: 2.9435324668884277
Validation loss: 2.3736176542056504

Epoch: 6| Step: 8
Training loss: 3.266348361968994
Validation loss: 2.3719125716916976

Epoch: 6| Step: 9
Training loss: 2.7482194900512695
Validation loss: 2.385432981675671

Epoch: 6| Step: 10
Training loss: 2.218482494354248
Validation loss: 2.3871153913518435

Epoch: 6| Step: 11
Training loss: 2.4643948078155518
Validation loss: 2.396357692697997

Epoch: 6| Step: 12
Training loss: 2.411663055419922
Validation loss: 2.4099485797266804

Epoch: 6| Step: 13
Training loss: 2.9575750827789307
Validation loss: 2.4005588792985484

Epoch: 26| Step: 0
Training loss: 2.9330756664276123
Validation loss: 2.371912051272649

Epoch: 6| Step: 1
Training loss: 2.3551573753356934
Validation loss: 2.360088761134814

Epoch: 6| Step: 2
Training loss: 2.675400733947754
Validation loss: 2.3523654540379844

Epoch: 6| Step: 3
Training loss: 2.4016690254211426
Validation loss: 2.349963693208592

Epoch: 6| Step: 4
Training loss: 2.4788126945495605
Validation loss: 2.350165036416823

Epoch: 6| Step: 5
Training loss: 2.220970630645752
Validation loss: 2.3549094969226467

Epoch: 6| Step: 6
Training loss: 3.0963830947875977
Validation loss: 2.3532485167185464

Epoch: 6| Step: 7
Training loss: 2.147268295288086
Validation loss: 2.354460293246854

Epoch: 6| Step: 8
Training loss: 2.956977367401123
Validation loss: 2.3515815068316717

Epoch: 6| Step: 9
Training loss: 2.6067118644714355
Validation loss: 2.371463285979404

Epoch: 6| Step: 10
Training loss: 2.5109496116638184
Validation loss: 2.4143153390576764

Epoch: 6| Step: 11
Training loss: 2.794391632080078
Validation loss: 2.424371447614444

Epoch: 6| Step: 12
Training loss: 2.7717366218566895
Validation loss: 2.4304530594938543

Epoch: 6| Step: 13
Training loss: 2.913968324661255
Validation loss: 2.4202385846004693

Epoch: 27| Step: 0
Training loss: 2.205322504043579
Validation loss: 2.429593252879317

Epoch: 6| Step: 1
Training loss: 3.4200735092163086
Validation loss: 2.450338876375588

Epoch: 6| Step: 2
Training loss: 2.3404855728149414
Validation loss: 2.4584500353823424

Epoch: 6| Step: 3
Training loss: 2.6092782020568848
Validation loss: 2.4644373950137886

Epoch: 6| Step: 4
Training loss: 2.9265196323394775
Validation loss: 2.454472064971924

Epoch: 6| Step: 5
Training loss: 2.2708261013031006
Validation loss: 2.459238370259603

Epoch: 6| Step: 6
Training loss: 2.6246767044067383
Validation loss: 2.4285411065624607

Epoch: 6| Step: 7
Training loss: 2.2860422134399414
Validation loss: 2.416673360332366

Epoch: 6| Step: 8
Training loss: 2.7140870094299316
Validation loss: 2.3811583724073184

Epoch: 6| Step: 9
Training loss: 3.0686731338500977
Validation loss: 2.354787093336864

Epoch: 6| Step: 10
Training loss: 2.605886220932007
Validation loss: 2.338135104025564

Epoch: 6| Step: 11
Training loss: 2.2749505043029785
Validation loss: 2.3295636510336273

Epoch: 6| Step: 12
Training loss: 2.938544273376465
Validation loss: 2.3341021076325448

Epoch: 6| Step: 13
Training loss: 2.5514144897460938
Validation loss: 2.3389938954384095

Epoch: 28| Step: 0
Training loss: 2.464674234390259
Validation loss: 2.3259310081440914

Epoch: 6| Step: 1
Training loss: 2.9272494316101074
Validation loss: 2.329745497754825

Epoch: 6| Step: 2
Training loss: 2.233365297317505
Validation loss: 2.3275781933979323

Epoch: 6| Step: 3
Training loss: 2.114370346069336
Validation loss: 2.342024205833353

Epoch: 6| Step: 4
Training loss: 2.8442978858947754
Validation loss: 2.339061596060312

Epoch: 6| Step: 5
Training loss: 2.0671417713165283
Validation loss: 2.3257089584104476

Epoch: 6| Step: 6
Training loss: 2.5354232788085938
Validation loss: 2.328762346698392

Epoch: 6| Step: 7
Training loss: 2.81710147857666
Validation loss: 2.3250795128524944

Epoch: 6| Step: 8
Training loss: 2.295322895050049
Validation loss: 2.322669072817731

Epoch: 6| Step: 9
Training loss: 2.1877248287200928
Validation loss: 2.3269933141687864

Epoch: 6| Step: 10
Training loss: 3.149181365966797
Validation loss: 2.3255693271595943

Epoch: 6| Step: 11
Training loss: 2.8427743911743164
Validation loss: 2.32602531679215

Epoch: 6| Step: 12
Training loss: 2.7515029907226562
Validation loss: 2.3320888652596423

Epoch: 6| Step: 13
Training loss: 3.670724630355835
Validation loss: 2.3356221645109114

Epoch: 29| Step: 0
Training loss: 3.381863594055176
Validation loss: 2.3343091177684006

Epoch: 6| Step: 1
Training loss: 2.2725424766540527
Validation loss: 2.3283513207589426

Epoch: 6| Step: 2
Training loss: 2.265371799468994
Validation loss: 2.321874869767056

Epoch: 6| Step: 3
Training loss: 2.067073345184326
Validation loss: 2.319176443161503

Epoch: 6| Step: 4
Training loss: 2.831521987915039
Validation loss: 2.322506825129191

Epoch: 6| Step: 5
Training loss: 2.870741844177246
Validation loss: 2.3123136848531742

Epoch: 6| Step: 6
Training loss: 2.2620882987976074
Validation loss: 2.315238093817106

Epoch: 6| Step: 7
Training loss: 2.593219757080078
Validation loss: 2.313350710817563

Epoch: 6| Step: 8
Training loss: 2.8354270458221436
Validation loss: 2.3107645460354385

Epoch: 6| Step: 9
Training loss: 2.6685943603515625
Validation loss: 2.3167104515978085

Epoch: 6| Step: 10
Training loss: 2.902162551879883
Validation loss: 2.317365256688928

Epoch: 6| Step: 11
Training loss: 3.2136247158050537
Validation loss: 2.3214971852558914

Epoch: 6| Step: 12
Training loss: 2.3818960189819336
Validation loss: 2.3311141742173063

Epoch: 6| Step: 13
Training loss: 1.28688645362854
Validation loss: 2.321246885484265

Epoch: 30| Step: 0
Training loss: 2.9210801124572754
Validation loss: 2.337774263915195

Epoch: 6| Step: 1
Training loss: 3.1006197929382324
Validation loss: 2.319964292228863

Epoch: 6| Step: 2
Training loss: 2.1142468452453613
Validation loss: 2.3220132858522478

Epoch: 6| Step: 3
Training loss: 2.0237905979156494
Validation loss: 2.3310485783443657

Epoch: 6| Step: 4
Training loss: 2.809735059738159
Validation loss: 2.343164082496397

Epoch: 6| Step: 5
Training loss: 2.2681612968444824
Validation loss: 2.3591443595065864

Epoch: 6| Step: 6
Training loss: 3.1663646697998047
Validation loss: 2.3619217462437128

Epoch: 6| Step: 7
Training loss: 2.274261474609375
Validation loss: 2.377191975552549

Epoch: 6| Step: 8
Training loss: 2.1289870738983154
Validation loss: 2.4259730180104575

Epoch: 6| Step: 9
Training loss: 2.605686664581299
Validation loss: 2.4819368034280758

Epoch: 6| Step: 10
Training loss: 2.248965263366699
Validation loss: 2.4678813821525982

Epoch: 6| Step: 11
Training loss: 3.4788687229156494
Validation loss: 2.440334099595265

Epoch: 6| Step: 12
Training loss: 3.0330123901367188
Validation loss: 2.418867841843636

Epoch: 6| Step: 13
Training loss: 1.9852300882339478
Validation loss: 2.3911423247347594

Epoch: 31| Step: 0
Training loss: 2.4786782264709473
Validation loss: 2.3579373872408302

Epoch: 6| Step: 1
Training loss: 2.3775928020477295
Validation loss: 2.3441165595926265

Epoch: 6| Step: 2
Training loss: 2.615746021270752
Validation loss: 2.365794727879186

Epoch: 6| Step: 3
Training loss: 3.67452335357666
Validation loss: 2.3842944534876014

Epoch: 6| Step: 4
Training loss: 2.721250295639038
Validation loss: 2.4040030125648744

Epoch: 6| Step: 5
Training loss: 2.9947431087493896
Validation loss: 2.3807338258271575

Epoch: 6| Step: 6
Training loss: 2.504823923110962
Validation loss: 2.3504015399563696

Epoch: 6| Step: 7
Training loss: 2.0247139930725098
Validation loss: 2.3276057756075295

Epoch: 6| Step: 8
Training loss: 2.546534538269043
Validation loss: 2.316683607716714

Epoch: 6| Step: 9
Training loss: 2.235866069793701
Validation loss: 2.3145824170881704

Epoch: 6| Step: 10
Training loss: 2.674805164337158
Validation loss: 2.307987279789422

Epoch: 6| Step: 11
Training loss: 2.9270291328430176
Validation loss: 2.3061778904289327

Epoch: 6| Step: 12
Training loss: 2.619162082672119
Validation loss: 2.3036779870269117

Epoch: 6| Step: 13
Training loss: 2.3327436447143555
Validation loss: 2.309833993193924

Epoch: 32| Step: 0
Training loss: 2.5524444580078125
Validation loss: 2.3299174693322953

Epoch: 6| Step: 1
Training loss: 2.0293426513671875
Validation loss: 2.3585104096320366

Epoch: 6| Step: 2
Training loss: 2.555757522583008
Validation loss: 2.3848989240584837

Epoch: 6| Step: 3
Training loss: 2.5751757621765137
Validation loss: 2.4079164202495287

Epoch: 6| Step: 4
Training loss: 2.6773102283477783
Validation loss: 2.43318352776189

Epoch: 6| Step: 5
Training loss: 2.77518367767334
Validation loss: 2.3911621365495908

Epoch: 6| Step: 6
Training loss: 2.5028696060180664
Validation loss: 2.3392246256592455

Epoch: 6| Step: 7
Training loss: 2.235950231552124
Validation loss: 2.2990799642378286

Epoch: 6| Step: 8
Training loss: 2.910459518432617
Validation loss: 2.3014061297139814

Epoch: 6| Step: 9
Training loss: 2.3094353675842285
Validation loss: 2.2978553605336014

Epoch: 6| Step: 10
Training loss: 2.311594009399414
Validation loss: 2.297938721154326

Epoch: 6| Step: 11
Training loss: 2.785818099975586
Validation loss: 2.298219250094506

Epoch: 6| Step: 12
Training loss: 3.5490243434906006
Validation loss: 2.2960360998748452

Epoch: 6| Step: 13
Training loss: 2.463880777359009
Validation loss: 2.2961010368921424

Epoch: 33| Step: 0
Training loss: 2.164914608001709
Validation loss: 2.2893295006085466

Epoch: 6| Step: 1
Training loss: 2.8141894340515137
Validation loss: 2.291389471741133

Epoch: 6| Step: 2
Training loss: 2.8426268100738525
Validation loss: 2.289669441920455

Epoch: 6| Step: 3
Training loss: 3.4083595275878906
Validation loss: 2.290763390961514

Epoch: 6| Step: 4
Training loss: 2.058870315551758
Validation loss: 2.2871265103740077

Epoch: 6| Step: 5
Training loss: 2.4901089668273926
Validation loss: 2.286310859905776

Epoch: 6| Step: 6
Training loss: 2.833585262298584
Validation loss: 2.287650787702171

Epoch: 6| Step: 7
Training loss: 3.034907102584839
Validation loss: 2.2858072352665726

Epoch: 6| Step: 8
Training loss: 3.0599260330200195
Validation loss: 2.286632360950593

Epoch: 6| Step: 9
Training loss: 2.319575071334839
Validation loss: 2.284032763973359

Epoch: 6| Step: 10
Training loss: 2.384514570236206
Validation loss: 2.2822042972810808

Epoch: 6| Step: 11
Training loss: 1.9890484809875488
Validation loss: 2.294116166330153

Epoch: 6| Step: 12
Training loss: 2.0876057147979736
Validation loss: 2.2995094663353375

Epoch: 6| Step: 13
Training loss: 3.0006184577941895
Validation loss: 2.303717300456057

Epoch: 34| Step: 0
Training loss: 2.389559507369995
Validation loss: 2.319813436077487

Epoch: 6| Step: 1
Training loss: 2.903409004211426
Validation loss: 2.3479407166921966

Epoch: 6| Step: 2
Training loss: 2.150667428970337
Validation loss: 2.3581321393289874

Epoch: 6| Step: 3
Training loss: 2.4798216819763184
Validation loss: 2.439163693817713

Epoch: 6| Step: 4
Training loss: 2.3904871940612793
Validation loss: 2.5069325021518174

Epoch: 6| Step: 5
Training loss: 2.473837375640869
Validation loss: 2.512938186686526

Epoch: 6| Step: 6
Training loss: 2.768683910369873
Validation loss: 2.401203563136439

Epoch: 6| Step: 7
Training loss: 3.1985034942626953
Validation loss: 2.3106783948918825

Epoch: 6| Step: 8
Training loss: 3.3066182136535645
Validation loss: 2.275442869432511

Epoch: 6| Step: 9
Training loss: 2.449948310852051
Validation loss: 2.2727375773973364

Epoch: 6| Step: 10
Training loss: 2.926637649536133
Validation loss: 2.2976673649203394

Epoch: 6| Step: 11
Training loss: 2.2687792778015137
Validation loss: 2.349176417114914

Epoch: 6| Step: 12
Training loss: 2.668806552886963
Validation loss: 2.3982258919746644

Epoch: 6| Step: 13
Training loss: 2.121537446975708
Validation loss: 2.5532527149364515

Epoch: 35| Step: 0
Training loss: 2.8519885540008545
Validation loss: 2.7714653527864845

Epoch: 6| Step: 1
Training loss: 3.9651851654052734
Validation loss: 2.6669487594276347

Epoch: 6| Step: 2
Training loss: 3.1833672523498535
Validation loss: 2.5282982574996127

Epoch: 6| Step: 3
Training loss: 1.8573068380355835
Validation loss: 2.40821074926725

Epoch: 6| Step: 4
Training loss: 2.4400219917297363
Validation loss: 2.2997177313732844

Epoch: 6| Step: 5
Training loss: 2.6658802032470703
Validation loss: 2.275128479926817

Epoch: 6| Step: 6
Training loss: 2.398874044418335
Validation loss: 2.29085402078526

Epoch: 6| Step: 7
Training loss: 2.457120895385742
Validation loss: 2.3544070400217527

Epoch: 6| Step: 8
Training loss: 2.166469097137451
Validation loss: 2.431586701382873

Epoch: 6| Step: 9
Training loss: 3.0004067420959473
Validation loss: 2.5718936868893203

Epoch: 6| Step: 10
Training loss: 2.8644473552703857
Validation loss: 2.6734582660018757

Epoch: 6| Step: 11
Training loss: 3.193678855895996
Validation loss: 2.759832295038367

Epoch: 6| Step: 12
Training loss: 2.8550968170166016
Validation loss: 2.7741134499990814

Epoch: 6| Step: 13
Training loss: 2.270676374435425
Validation loss: 2.6571321231062695

Epoch: 36| Step: 0
Training loss: 2.67043399810791
Validation loss: 2.4685413709250827

Epoch: 6| Step: 1
Training loss: 1.8440194129943848
Validation loss: 2.363593575774982

Epoch: 6| Step: 2
Training loss: 2.967898368835449
Validation loss: 2.3041544652754262

Epoch: 6| Step: 3
Training loss: 2.7296130657196045
Validation loss: 2.2746350534500612

Epoch: 6| Step: 4
Training loss: 1.7048606872558594
Validation loss: 2.279445171356201

Epoch: 6| Step: 5
Training loss: 2.0327091217041016
Validation loss: 2.298802004065565

Epoch: 6| Step: 6
Training loss: 2.6092147827148438
Validation loss: 2.3284567094618276

Epoch: 6| Step: 7
Training loss: 2.7790920734405518
Validation loss: 2.3412849159650904

Epoch: 6| Step: 8
Training loss: 3.0461161136627197
Validation loss: 2.335269799796484

Epoch: 6| Step: 9
Training loss: 2.4061272144317627
Validation loss: 2.336771152352774

Epoch: 6| Step: 10
Training loss: 3.3030643463134766
Validation loss: 2.325111464787555

Epoch: 6| Step: 11
Training loss: 3.173668384552002
Validation loss: 2.314672423947242

Epoch: 6| Step: 12
Training loss: 2.5162549018859863
Validation loss: 2.3013800446705153

Epoch: 6| Step: 13
Training loss: 3.300929069519043
Validation loss: 2.292142286095568

Epoch: 37| Step: 0
Training loss: 2.1960854530334473
Validation loss: 2.282943525621968

Epoch: 6| Step: 1
Training loss: 3.445312976837158
Validation loss: 2.2723261258935414

Epoch: 6| Step: 2
Training loss: 2.677772045135498
Validation loss: 2.261541812650619

Epoch: 6| Step: 3
Training loss: 2.6613945960998535
Validation loss: 2.2696682458282798

Epoch: 6| Step: 4
Training loss: 2.8682422637939453
Validation loss: 2.281434782089726

Epoch: 6| Step: 5
Training loss: 1.7185018062591553
Validation loss: 2.2980551514574277

Epoch: 6| Step: 6
Training loss: 2.8094582557678223
Validation loss: 2.312337149855911

Epoch: 6| Step: 7
Training loss: 2.1361870765686035
Validation loss: 2.310703105823968

Epoch: 6| Step: 8
Training loss: 2.113400459289551
Validation loss: 2.3111784637615247

Epoch: 6| Step: 9
Training loss: 3.1119236946105957
Validation loss: 2.304275023039951

Epoch: 6| Step: 10
Training loss: 2.8418924808502197
Validation loss: 2.2980295740148073

Epoch: 6| Step: 11
Training loss: 2.003178834915161
Validation loss: 2.297893939479705

Epoch: 6| Step: 12
Training loss: 2.994460105895996
Validation loss: 2.3121166434339298

Epoch: 6| Step: 13
Training loss: 2.8529908657073975
Validation loss: 2.3195740253694597

Epoch: 38| Step: 0
Training loss: 2.6172046661376953
Validation loss: 2.3067786962755266

Epoch: 6| Step: 1
Training loss: 3.0879158973693848
Validation loss: 2.2996066565154702

Epoch: 6| Step: 2
Training loss: 2.3441405296325684
Validation loss: 2.3036789689012753

Epoch: 6| Step: 3
Training loss: 2.6691412925720215
Validation loss: 2.3055003509726575

Epoch: 6| Step: 4
Training loss: 2.1686062812805176
Validation loss: 2.303473746904763

Epoch: 6| Step: 5
Training loss: 2.490487575531006
Validation loss: 2.2988985610264603

Epoch: 6| Step: 6
Training loss: 3.2939910888671875
Validation loss: 2.301267300882647

Epoch: 6| Step: 7
Training loss: 2.6441855430603027
Validation loss: 2.2933449796451035

Epoch: 6| Step: 8
Training loss: 2.216067314147949
Validation loss: 2.2711966832478843

Epoch: 6| Step: 9
Training loss: 2.5144639015197754
Validation loss: 2.2532364886294127

Epoch: 6| Step: 10
Training loss: 2.1398072242736816
Validation loss: 2.242407980785575

Epoch: 6| Step: 11
Training loss: 2.5425562858581543
Validation loss: 2.239182231246784

Epoch: 6| Step: 12
Training loss: 2.839662551879883
Validation loss: 2.232699018652721

Epoch: 6| Step: 13
Training loss: 2.0554752349853516
Validation loss: 2.229115357962988

Epoch: 39| Step: 0
Training loss: 3.0291171073913574
Validation loss: 2.233414242344518

Epoch: 6| Step: 1
Training loss: 2.3802926540374756
Validation loss: 2.235309052210982

Epoch: 6| Step: 2
Training loss: 2.2843756675720215
Validation loss: 2.2391774577479207

Epoch: 6| Step: 3
Training loss: 2.6885488033294678
Validation loss: 2.2359148635659167

Epoch: 6| Step: 4
Training loss: 2.6695070266723633
Validation loss: 2.2371688299281622

Epoch: 6| Step: 5
Training loss: 2.443713665008545
Validation loss: 2.238311030531442

Epoch: 6| Step: 6
Training loss: 2.200761318206787
Validation loss: 2.2349912069177114

Epoch: 6| Step: 7
Training loss: 2.9920120239257812
Validation loss: 2.233461674823556

Epoch: 6| Step: 8
Training loss: 2.548962116241455
Validation loss: 2.231352401036088

Epoch: 6| Step: 9
Training loss: 2.420992136001587
Validation loss: 2.2305364301127772

Epoch: 6| Step: 10
Training loss: 2.775658130645752
Validation loss: 2.2277890020801174

Epoch: 6| Step: 11
Training loss: 2.763997793197632
Validation loss: 2.225839607177242

Epoch: 6| Step: 12
Training loss: 2.0385398864746094
Validation loss: 2.227538034480105

Epoch: 6| Step: 13
Training loss: 2.3701171875
Validation loss: 2.22582680948319

Epoch: 40| Step: 0
Training loss: 2.274540424346924
Validation loss: 2.2232604001158025

Epoch: 6| Step: 1
Training loss: 2.42677640914917
Validation loss: 2.2266825796455465

Epoch: 6| Step: 2
Training loss: 2.4394049644470215
Validation loss: 2.2335876123879546

Epoch: 6| Step: 3
Training loss: 2.5240817070007324
Validation loss: 2.245903807301675

Epoch: 6| Step: 4
Training loss: 2.788734197616577
Validation loss: 2.246711451520202

Epoch: 6| Step: 5
Training loss: 2.4555435180664062
Validation loss: 2.2557253081311464

Epoch: 6| Step: 6
Training loss: 3.4576990604400635
Validation loss: 2.276034111617714

Epoch: 6| Step: 7
Training loss: 2.4966726303100586
Validation loss: 2.304453819028793

Epoch: 6| Step: 8
Training loss: 2.1562392711639404
Validation loss: 2.3030130529916413

Epoch: 6| Step: 9
Training loss: 2.8918421268463135
Validation loss: 2.3142296652640066

Epoch: 6| Step: 10
Training loss: 3.0966081619262695
Validation loss: 2.3027340135266705

Epoch: 6| Step: 11
Training loss: 2.710456132888794
Validation loss: 2.3050552363036783

Epoch: 6| Step: 12
Training loss: 2.0191738605499268
Validation loss: 2.3384375187658493

Epoch: 6| Step: 13
Training loss: 1.4292793273925781
Validation loss: 2.352951617651088

Epoch: 41| Step: 0
Training loss: 2.694502353668213
Validation loss: 2.36625252744203

Epoch: 6| Step: 1
Training loss: 2.4736886024475098
Validation loss: 2.356197759669314

Epoch: 6| Step: 2
Training loss: 2.728749990463257
Validation loss: 2.356128390117358

Epoch: 6| Step: 3
Training loss: 3.3678603172302246
Validation loss: 2.309040379780595

Epoch: 6| Step: 4
Training loss: 2.660935401916504
Validation loss: 2.2651615142822266

Epoch: 6| Step: 5
Training loss: 2.7388644218444824
Validation loss: 2.2451840908296647

Epoch: 6| Step: 6
Training loss: 2.2172560691833496
Validation loss: 2.242687920088409

Epoch: 6| Step: 7
Training loss: 2.476229667663574
Validation loss: 2.2368315112206245

Epoch: 6| Step: 8
Training loss: 2.2444894313812256
Validation loss: 2.2410148984642437

Epoch: 6| Step: 9
Training loss: 2.3899788856506348
Validation loss: 2.246986654496962

Epoch: 6| Step: 10
Training loss: 2.7893970012664795
Validation loss: 2.276640768974058

Epoch: 6| Step: 11
Training loss: 2.5365710258483887
Validation loss: 2.2991902802580144

Epoch: 6| Step: 12
Training loss: 2.7144935131073
Validation loss: 2.3235619606510287

Epoch: 6| Step: 13
Training loss: 1.4153867959976196
Validation loss: 2.2896503479250017

Epoch: 42| Step: 0
Training loss: 3.586282730102539
Validation loss: 2.284033998366325

Epoch: 6| Step: 1
Training loss: 1.8413488864898682
Validation loss: 2.2603414750868276

Epoch: 6| Step: 2
Training loss: 2.3170993328094482
Validation loss: 2.2491384424189085

Epoch: 6| Step: 3
Training loss: 2.562796115875244
Validation loss: 2.236670709425403

Epoch: 6| Step: 4
Training loss: 2.717054843902588
Validation loss: 2.2348135107307026

Epoch: 6| Step: 5
Training loss: 2.2563209533691406
Validation loss: 2.22964886952472

Epoch: 6| Step: 6
Training loss: 2.721536636352539
Validation loss: 2.2311883126535723

Epoch: 6| Step: 7
Training loss: 2.23030424118042
Validation loss: 2.227802571430001

Epoch: 6| Step: 8
Training loss: 2.9342870712280273
Validation loss: 2.230470339457194

Epoch: 6| Step: 9
Training loss: 3.411825656890869
Validation loss: 2.230503389912267

Epoch: 6| Step: 10
Training loss: 2.1292686462402344
Validation loss: 2.2334197310991186

Epoch: 6| Step: 11
Training loss: 2.165060043334961
Validation loss: 2.2401066954417894

Epoch: 6| Step: 12
Training loss: 2.1848032474517822
Validation loss: 2.2353285230616087

Epoch: 6| Step: 13
Training loss: 2.62890887260437
Validation loss: 2.2453173668153825

Epoch: 43| Step: 0
Training loss: 3.0828118324279785
Validation loss: 2.2442528996416318

Epoch: 6| Step: 1
Training loss: 2.559516429901123
Validation loss: 2.2536984489810084

Epoch: 6| Step: 2
Training loss: 2.7913575172424316
Validation loss: 2.2405863167137228

Epoch: 6| Step: 3
Training loss: 2.086879253387451
Validation loss: 2.2336401401027555

Epoch: 6| Step: 4
Training loss: 2.5031490325927734
Validation loss: 2.221848682690692

Epoch: 6| Step: 5
Training loss: 2.5325498580932617
Validation loss: 2.206443376438592

Epoch: 6| Step: 6
Training loss: 2.461423397064209
Validation loss: 2.2083055127051567

Epoch: 6| Step: 7
Training loss: 2.317852020263672
Validation loss: 2.206081849272533

Epoch: 6| Step: 8
Training loss: 2.88454532623291
Validation loss: 2.2056282207530034

Epoch: 6| Step: 9
Training loss: 2.4305362701416016
Validation loss: 2.2061402759244366

Epoch: 6| Step: 10
Training loss: 2.6248087882995605
Validation loss: 2.211405902780512

Epoch: 6| Step: 11
Training loss: 2.1466588973999023
Validation loss: 2.2237143221721856

Epoch: 6| Step: 12
Training loss: 2.549164056777954
Validation loss: 2.234011368084979

Epoch: 6| Step: 13
Training loss: 2.463442087173462
Validation loss: 2.2489270856303554

Epoch: 44| Step: 0
Training loss: 3.0317978858947754
Validation loss: 2.2844575835812475

Epoch: 6| Step: 1
Training loss: 2.5893678665161133
Validation loss: 2.327064009122951

Epoch: 6| Step: 2
Training loss: 2.1403369903564453
Validation loss: 2.381646748512022

Epoch: 6| Step: 3
Training loss: 2.225250482559204
Validation loss: 2.408132194190897

Epoch: 6| Step: 4
Training loss: 2.6304874420166016
Validation loss: 2.3889045253876717

Epoch: 6| Step: 5
Training loss: 2.6343369483947754
Validation loss: 2.3611791056971394

Epoch: 6| Step: 6
Training loss: 2.9808526039123535
Validation loss: 2.3169896602630615

Epoch: 6| Step: 7
Training loss: 2.1199235916137695
Validation loss: 2.264252975422849

Epoch: 6| Step: 8
Training loss: 1.8505820035934448
Validation loss: 2.2177684140461746

Epoch: 6| Step: 9
Training loss: 3.2295641899108887
Validation loss: 2.196080166806457

Epoch: 6| Step: 10
Training loss: 2.4015560150146484
Validation loss: 2.199233014096496

Epoch: 6| Step: 11
Training loss: 2.5699667930603027
Validation loss: 2.2041104442329815

Epoch: 6| Step: 12
Training loss: 2.9143662452697754
Validation loss: 2.2160277443547405

Epoch: 6| Step: 13
Training loss: 2.4721193313598633
Validation loss: 2.2376373967816754

Epoch: 45| Step: 0
Training loss: 1.6474251747131348
Validation loss: 2.2364823818206787

Epoch: 6| Step: 1
Training loss: 2.6450695991516113
Validation loss: 2.2306765535826325

Epoch: 6| Step: 2
Training loss: 2.6744518280029297
Validation loss: 2.246394154846027

Epoch: 6| Step: 3
Training loss: 2.2132465839385986
Validation loss: 2.225904821067728

Epoch: 6| Step: 4
Training loss: 3.1670494079589844
Validation loss: 2.2078696732879965

Epoch: 6| Step: 5
Training loss: 2.766050338745117
Validation loss: 2.1987627424219602

Epoch: 6| Step: 6
Training loss: 2.708733558654785
Validation loss: 2.194317948433661

Epoch: 6| Step: 7
Training loss: 2.7538201808929443
Validation loss: 2.1918053293740876

Epoch: 6| Step: 8
Training loss: 3.1833343505859375
Validation loss: 2.18835267712993

Epoch: 6| Step: 9
Training loss: 2.79605770111084
Validation loss: 2.191295410997124

Epoch: 6| Step: 10
Training loss: 2.2172300815582275
Validation loss: 2.196159229483656

Epoch: 6| Step: 11
Training loss: 2.2240731716156006
Validation loss: 2.2082423087089293

Epoch: 6| Step: 12
Training loss: 2.425868034362793
Validation loss: 2.2266717546729633

Epoch: 6| Step: 13
Training loss: 2.0722928047180176
Validation loss: 2.23972592302548

Epoch: 46| Step: 0
Training loss: 1.9433012008666992
Validation loss: 2.23502331138939

Epoch: 6| Step: 1
Training loss: 3.2610645294189453
Validation loss: 2.2333269478172384

Epoch: 6| Step: 2
Training loss: 2.557021379470825
Validation loss: 2.2294509782586047

Epoch: 6| Step: 3
Training loss: 2.3155808448791504
Validation loss: 2.2462907555282756

Epoch: 6| Step: 4
Training loss: 2.179960012435913
Validation loss: 2.2392827003232894

Epoch: 6| Step: 5
Training loss: 2.4386978149414062
Validation loss: 2.242912812899518

Epoch: 6| Step: 6
Training loss: 2.649960994720459
Validation loss: 2.2227177235387985

Epoch: 6| Step: 7
Training loss: 2.7014012336730957
Validation loss: 2.2163663628280803

Epoch: 6| Step: 8
Training loss: 2.899527072906494
Validation loss: 2.207865632990355

Epoch: 6| Step: 9
Training loss: 2.1037635803222656
Validation loss: 2.1945597471729403

Epoch: 6| Step: 10
Training loss: 2.488779067993164
Validation loss: 2.1906773967127644

Epoch: 6| Step: 11
Training loss: 2.2954318523406982
Validation loss: 2.1775092976067656

Epoch: 6| Step: 12
Training loss: 3.0029797554016113
Validation loss: 2.1717728158479095

Epoch: 6| Step: 13
Training loss: 2.328831672668457
Validation loss: 2.1728042415393296

Epoch: 47| Step: 0
Training loss: 2.7647573947906494
Validation loss: 2.1696699473165695

Epoch: 6| Step: 1
Training loss: 2.8194384574890137
Validation loss: 2.1640971270940637

Epoch: 6| Step: 2
Training loss: 2.00881028175354
Validation loss: 2.1679299287898566

Epoch: 6| Step: 3
Training loss: 2.0952396392822266
Validation loss: 2.1660937609211093

Epoch: 6| Step: 4
Training loss: 2.6865949630737305
Validation loss: 2.1671441575532318

Epoch: 6| Step: 5
Training loss: 2.4350881576538086
Validation loss: 2.1673539633392007

Epoch: 6| Step: 6
Training loss: 2.5704479217529297
Validation loss: 2.169392878009427

Epoch: 6| Step: 7
Training loss: 1.8986129760742188
Validation loss: 2.168703467615189

Epoch: 6| Step: 8
Training loss: 3.132023572921753
Validation loss: 2.1681893858858334

Epoch: 6| Step: 9
Training loss: 2.2579610347747803
Validation loss: 2.163757621601064

Epoch: 6| Step: 10
Training loss: 2.608492136001587
Validation loss: 2.158091732250747

Epoch: 6| Step: 11
Training loss: 3.0615060329437256
Validation loss: 2.160224530004686

Epoch: 6| Step: 12
Training loss: 2.2797651290893555
Validation loss: 2.159576955661979

Epoch: 6| Step: 13
Training loss: 2.755803346633911
Validation loss: 2.1622222726063063

Epoch: 48| Step: 0
Training loss: 2.1606698036193848
Validation loss: 2.1560730370142127

Epoch: 6| Step: 1
Training loss: 3.0690248012542725
Validation loss: 2.161609847058532

Epoch: 6| Step: 2
Training loss: 2.981003522872925
Validation loss: 2.1572739334516626

Epoch: 6| Step: 3
Training loss: 2.9458212852478027
Validation loss: 2.1680877234346125

Epoch: 6| Step: 4
Training loss: 2.1425833702087402
Validation loss: 2.167749930453557

Epoch: 6| Step: 5
Training loss: 2.778477191925049
Validation loss: 2.1839756529818297

Epoch: 6| Step: 6
Training loss: 2.724745750427246
Validation loss: 2.2122367889650407

Epoch: 6| Step: 7
Training loss: 1.8443737030029297
Validation loss: 2.217938332147496

Epoch: 6| Step: 8
Training loss: 2.097477436065674
Validation loss: 2.2349008821672007

Epoch: 6| Step: 9
Training loss: 2.708829164505005
Validation loss: 2.28009977135607

Epoch: 6| Step: 10
Training loss: 2.0469565391540527
Validation loss: 2.2918373051510064

Epoch: 6| Step: 11
Training loss: 2.475517511367798
Validation loss: 2.2369149320869037

Epoch: 6| Step: 12
Training loss: 2.965331554412842
Validation loss: 2.2125487250666462

Epoch: 6| Step: 13
Training loss: 2.254625082015991
Validation loss: 2.1728105493771133

Epoch: 49| Step: 0
Training loss: 2.172344923019409
Validation loss: 2.1553557406189623

Epoch: 6| Step: 1
Training loss: 2.9124953746795654
Validation loss: 2.1546076754088044

Epoch: 6| Step: 2
Training loss: 2.5729970932006836
Validation loss: 2.156002111332391

Epoch: 6| Step: 3
Training loss: 2.154039144515991
Validation loss: 2.1584429228177635

Epoch: 6| Step: 4
Training loss: 2.912961959838867
Validation loss: 2.160368559181049

Epoch: 6| Step: 5
Training loss: 2.66331148147583
Validation loss: 2.1660013865399104

Epoch: 6| Step: 6
Training loss: 1.9166111946105957
Validation loss: 2.164906412042597

Epoch: 6| Step: 7
Training loss: 3.281400203704834
Validation loss: 2.159880776559153

Epoch: 6| Step: 8
Training loss: 2.5347647666931152
Validation loss: 2.1573085977185156

Epoch: 6| Step: 9
Training loss: 2.521454334259033
Validation loss: 2.1527810173649944

Epoch: 6| Step: 10
Training loss: 2.344353437423706
Validation loss: 2.1597414478178947

Epoch: 6| Step: 11
Training loss: 2.3961689472198486
Validation loss: 2.1620426767615863

Epoch: 6| Step: 12
Training loss: 2.429487466812134
Validation loss: 2.1580816250975414

Epoch: 6| Step: 13
Training loss: 2.5626471042633057
Validation loss: 2.1657665134758077

Epoch: 50| Step: 0
Training loss: 2.7143115997314453
Validation loss: 2.1588551152137017

Epoch: 6| Step: 1
Training loss: 1.9837431907653809
Validation loss: 2.158834890652728

Epoch: 6| Step: 2
Training loss: 1.8534817695617676
Validation loss: 2.1619420256665958

Epoch: 6| Step: 3
Training loss: 2.7274887561798096
Validation loss: 2.166093485329741

Epoch: 6| Step: 4
Training loss: 3.1834278106689453
Validation loss: 2.171777671383273

Epoch: 6| Step: 5
Training loss: 2.559168815612793
Validation loss: 2.163039081840105

Epoch: 6| Step: 6
Training loss: 2.257793426513672
Validation loss: 2.167910140047791

Epoch: 6| Step: 7
Training loss: 2.361955165863037
Validation loss: 2.1727961776077107

Epoch: 6| Step: 8
Training loss: 2.7072677612304688
Validation loss: 2.184289191358833

Epoch: 6| Step: 9
Training loss: 2.2594501972198486
Validation loss: 2.1934524531005533

Epoch: 6| Step: 10
Training loss: 2.3171546459198
Validation loss: 2.2120273984888548

Epoch: 6| Step: 11
Training loss: 3.311220407485962
Validation loss: 2.2266956785673737

Epoch: 6| Step: 12
Training loss: 2.2902491092681885
Validation loss: 2.205173343740484

Epoch: 6| Step: 13
Training loss: 2.127915382385254
Validation loss: 2.2014782351832234

Epoch: 51| Step: 0
Training loss: 2.6425609588623047
Validation loss: 2.1794497146401355

Epoch: 6| Step: 1
Training loss: 2.725584030151367
Validation loss: 2.158859678494033

Epoch: 6| Step: 2
Training loss: 2.5302579402923584
Validation loss: 2.1620372367161576

Epoch: 6| Step: 3
Training loss: 2.203106164932251
Validation loss: 2.1575469560520624

Epoch: 6| Step: 4
Training loss: 2.673271417617798
Validation loss: 2.156834153718846

Epoch: 6| Step: 5
Training loss: 2.5816078186035156
Validation loss: 2.1463484841008342

Epoch: 6| Step: 6
Training loss: 2.99212646484375
Validation loss: 2.140348880521713

Epoch: 6| Step: 7
Training loss: 1.8420226573944092
Validation loss: 2.143789096545148

Epoch: 6| Step: 8
Training loss: 2.4647915363311768
Validation loss: 2.141783086202478

Epoch: 6| Step: 9
Training loss: 2.7341673374176025
Validation loss: 2.1386589888603456

Epoch: 6| Step: 10
Training loss: 2.131284236907959
Validation loss: 2.1440601989787114

Epoch: 6| Step: 11
Training loss: 2.640570878982544
Validation loss: 2.1458001341871036

Epoch: 6| Step: 12
Training loss: 2.5873985290527344
Validation loss: 2.145513815264548

Epoch: 6| Step: 13
Training loss: 1.8276342153549194
Validation loss: 2.149905517537107

Epoch: 52| Step: 0
Training loss: 2.290144443511963
Validation loss: 2.152140120024322

Epoch: 6| Step: 1
Training loss: 2.7958600521087646
Validation loss: 2.1485620711439397

Epoch: 6| Step: 2
Training loss: 2.569624900817871
Validation loss: 2.174672024224394

Epoch: 6| Step: 3
Training loss: 2.353807210922241
Validation loss: 2.186981717745463

Epoch: 6| Step: 4
Training loss: 2.7987866401672363
Validation loss: 2.2189024289449057

Epoch: 6| Step: 5
Training loss: 2.5179271697998047
Validation loss: 2.284163967255623

Epoch: 6| Step: 6
Training loss: 2.865945339202881
Validation loss: 2.3265538215637207

Epoch: 6| Step: 7
Training loss: 2.517324686050415
Validation loss: 2.3821412440269225

Epoch: 6| Step: 8
Training loss: 2.6494178771972656
Validation loss: 2.371481764701105

Epoch: 6| Step: 9
Training loss: 1.8309123516082764
Validation loss: 2.3650597192907847

Epoch: 6| Step: 10
Training loss: 3.8427512645721436
Validation loss: 2.301143979513517

Epoch: 6| Step: 11
Training loss: 1.5863699913024902
Validation loss: 2.1938161811520978

Epoch: 6| Step: 12
Training loss: 2.066096305847168
Validation loss: 2.1591132276801654

Epoch: 6| Step: 13
Training loss: 2.6159400939941406
Validation loss: 2.1460576544525805

Epoch: 53| Step: 0
Training loss: 2.8543968200683594
Validation loss: 2.1334757804870605

Epoch: 6| Step: 1
Training loss: 3.2376794815063477
Validation loss: 2.134676246232884

Epoch: 6| Step: 2
Training loss: 2.560364246368408
Validation loss: 2.142327795746506

Epoch: 6| Step: 3
Training loss: 2.211503505706787
Validation loss: 2.147287643083962

Epoch: 6| Step: 4
Training loss: 2.232538938522339
Validation loss: 2.1559499732909666

Epoch: 6| Step: 5
Training loss: 1.9903709888458252
Validation loss: 2.1513470603573706

Epoch: 6| Step: 6
Training loss: 2.773923397064209
Validation loss: 2.1351133982340493

Epoch: 6| Step: 7
Training loss: 2.047848701477051
Validation loss: 2.1372200032716155

Epoch: 6| Step: 8
Training loss: 3.0888218879699707
Validation loss: 2.14061277527963

Epoch: 6| Step: 9
Training loss: 2.0475666522979736
Validation loss: 2.145617110754854

Epoch: 6| Step: 10
Training loss: 2.2622270584106445
Validation loss: 2.1469654139652046

Epoch: 6| Step: 11
Training loss: 2.8075761795043945
Validation loss: 2.143877995911465

Epoch: 6| Step: 12
Training loss: 2.60396409034729
Validation loss: 2.145587167432231

Epoch: 6| Step: 13
Training loss: 2.212052583694458
Validation loss: 2.1387948143866753

Epoch: 54| Step: 0
Training loss: 2.2318527698516846
Validation loss: 2.158611556535126

Epoch: 6| Step: 1
Training loss: 2.215912342071533
Validation loss: 2.1871439564612603

Epoch: 6| Step: 2
Training loss: 2.07794189453125
Validation loss: 2.2007372930485714

Epoch: 6| Step: 3
Training loss: 2.3924970626831055
Validation loss: 2.22272511195111

Epoch: 6| Step: 4
Training loss: 2.504425287246704
Validation loss: 2.225634269816901

Epoch: 6| Step: 5
Training loss: 2.7771260738372803
Validation loss: 2.239250086968945

Epoch: 6| Step: 6
Training loss: 2.8823304176330566
Validation loss: 2.227321873429001

Epoch: 6| Step: 7
Training loss: 2.5122761726379395
Validation loss: 2.2169202309782787

Epoch: 6| Step: 8
Training loss: 1.9623157978057861
Validation loss: 2.2262105480317147

Epoch: 6| Step: 9
Training loss: 2.889470338821411
Validation loss: 2.2192368481748845

Epoch: 6| Step: 10
Training loss: 2.6153414249420166
Validation loss: 2.221849713274228

Epoch: 6| Step: 11
Training loss: 3.262197494506836
Validation loss: 2.199765310492567

Epoch: 6| Step: 12
Training loss: 2.2992489337921143
Validation loss: 2.188639558771605

Epoch: 6| Step: 13
Training loss: 2.1842637062072754
Validation loss: 2.180959011918755

Epoch: 55| Step: 0
Training loss: 2.3650012016296387
Validation loss: 2.1747226292087185

Epoch: 6| Step: 1
Training loss: 3.1513631343841553
Validation loss: 2.1643251834377164

Epoch: 6| Step: 2
Training loss: 2.1224684715270996
Validation loss: 2.1663644788085774

Epoch: 6| Step: 3
Training loss: 2.7883710861206055
Validation loss: 2.1661887886703655

Epoch: 6| Step: 4
Training loss: 1.9521921873092651
Validation loss: 2.170546980314357

Epoch: 6| Step: 5
Training loss: 2.686307907104492
Validation loss: 2.180033205657877

Epoch: 6| Step: 6
Training loss: 2.1581640243530273
Validation loss: 2.175341929158857

Epoch: 6| Step: 7
Training loss: 2.4829533100128174
Validation loss: 2.1675746979251986

Epoch: 6| Step: 8
Training loss: 1.9389431476593018
Validation loss: 2.1580277309622815

Epoch: 6| Step: 9
Training loss: 2.8897974491119385
Validation loss: 2.150848703999673

Epoch: 6| Step: 10
Training loss: 2.129077434539795
Validation loss: 2.1507812315417874

Epoch: 6| Step: 11
Training loss: 2.7134087085723877
Validation loss: 2.147634426752726

Epoch: 6| Step: 12
Training loss: 2.8919849395751953
Validation loss: 2.152839263280233

Epoch: 6| Step: 13
Training loss: 2.625488042831421
Validation loss: 2.1481398408130934

Epoch: 56| Step: 0
Training loss: 2.835519313812256
Validation loss: 2.15071762505398

Epoch: 6| Step: 1
Training loss: 1.7552776336669922
Validation loss: 2.1495705163607033

Epoch: 6| Step: 2
Training loss: 2.3074963092803955
Validation loss: 2.151343313596582

Epoch: 6| Step: 3
Training loss: 2.9044041633605957
Validation loss: 2.1447742959504486

Epoch: 6| Step: 4
Training loss: 2.0594754219055176
Validation loss: 2.148786933191361

Epoch: 6| Step: 5
Training loss: 2.0756616592407227
Validation loss: 2.1501289772731003

Epoch: 6| Step: 6
Training loss: 2.1909666061401367
Validation loss: 2.147213596169667

Epoch: 6| Step: 7
Training loss: 2.1940531730651855
Validation loss: 2.143451339455061

Epoch: 6| Step: 8
Training loss: 2.203418731689453
Validation loss: 2.1384067266218123

Epoch: 6| Step: 9
Training loss: 2.9834494590759277
Validation loss: 2.1410828944175475

Epoch: 6| Step: 10
Training loss: 2.2894675731658936
Validation loss: 2.1382481974940144

Epoch: 6| Step: 11
Training loss: 2.8831305503845215
Validation loss: 2.1387615332039456

Epoch: 6| Step: 12
Training loss: 2.5704550743103027
Validation loss: 2.1390889331858647

Epoch: 6| Step: 13
Training loss: 3.964561939239502
Validation loss: 2.1466284567309963

Epoch: 57| Step: 0
Training loss: 2.311728000640869
Validation loss: 2.1443450438079013

Epoch: 6| Step: 1
Training loss: 1.8380682468414307
Validation loss: 2.160920489218927

Epoch: 6| Step: 2
Training loss: 2.1790928840637207
Validation loss: 2.184808933606712

Epoch: 6| Step: 3
Training loss: 3.257101535797119
Validation loss: 2.181500268238847

Epoch: 6| Step: 4
Training loss: 2.5102524757385254
Validation loss: 2.1818468903982513

Epoch: 6| Step: 5
Training loss: 2.533745288848877
Validation loss: 2.162132050401421

Epoch: 6| Step: 6
Training loss: 3.1706671714782715
Validation loss: 2.153896306150703

Epoch: 6| Step: 7
Training loss: 2.5960636138916016
Validation loss: 2.1457736620339016

Epoch: 6| Step: 8
Training loss: 2.595292568206787
Validation loss: 2.149686167317052

Epoch: 6| Step: 9
Training loss: 2.2644200325012207
Validation loss: 2.138049348708122

Epoch: 6| Step: 10
Training loss: 2.35113525390625
Validation loss: 2.124261979133852

Epoch: 6| Step: 11
Training loss: 2.1917033195495605
Validation loss: 2.129598820081321

Epoch: 6| Step: 12
Training loss: 2.5122008323669434
Validation loss: 2.1293757090004544

Epoch: 6| Step: 13
Training loss: 2.1043570041656494
Validation loss: 2.1398938112361456

Epoch: 58| Step: 0
Training loss: 2.064868688583374
Validation loss: 2.155202183672177

Epoch: 6| Step: 1
Training loss: 2.3464624881744385
Validation loss: 2.1653935370906705

Epoch: 6| Step: 2
Training loss: 2.6657509803771973
Validation loss: 2.1727371113274687

Epoch: 6| Step: 3
Training loss: 2.7261319160461426
Validation loss: 2.1785812941930627

Epoch: 6| Step: 4
Training loss: 2.371023654937744
Validation loss: 2.175069598741429

Epoch: 6| Step: 5
Training loss: 2.4108798503875732
Validation loss: 2.149316822328875

Epoch: 6| Step: 6
Training loss: 2.6208956241607666
Validation loss: 2.151807023632911

Epoch: 6| Step: 7
Training loss: 2.423037528991699
Validation loss: 2.146517607473558

Epoch: 6| Step: 8
Training loss: 2.5064845085144043
Validation loss: 2.1414758236177507

Epoch: 6| Step: 9
Training loss: 2.493450164794922
Validation loss: 2.142052258214643

Epoch: 6| Step: 10
Training loss: 2.362199544906616
Validation loss: 2.1301375281426216

Epoch: 6| Step: 11
Training loss: 2.1697959899902344
Validation loss: 2.1271097249882196

Epoch: 6| Step: 12
Training loss: 2.5828464031219482
Validation loss: 2.121667746574648

Epoch: 6| Step: 13
Training loss: 2.501209020614624
Validation loss: 2.116063625581803

Epoch: 59| Step: 0
Training loss: 2.9540319442749023
Validation loss: 2.1222486239607616

Epoch: 6| Step: 1
Training loss: 2.82883882522583
Validation loss: 2.1197832143434914

Epoch: 6| Step: 2
Training loss: 2.1354336738586426
Validation loss: 2.141381281678395

Epoch: 6| Step: 3
Training loss: 2.2548303604125977
Validation loss: 2.1747696886780443

Epoch: 6| Step: 4
Training loss: 1.9190698862075806
Validation loss: 2.196702459807037

Epoch: 6| Step: 5
Training loss: 2.522338390350342
Validation loss: 2.2048100553533083

Epoch: 6| Step: 6
Training loss: 2.262054443359375
Validation loss: 2.1820282602822907

Epoch: 6| Step: 7
Training loss: 2.0290920734405518
Validation loss: 2.1593175857297835

Epoch: 6| Step: 8
Training loss: 3.2956063747406006
Validation loss: 2.1521002810488463

Epoch: 6| Step: 9
Training loss: 2.298663854598999
Validation loss: 2.150279562960389

Epoch: 6| Step: 10
Training loss: 2.9366559982299805
Validation loss: 2.1411268211180166

Epoch: 6| Step: 11
Training loss: 2.0124363899230957
Validation loss: 2.13041659837128

Epoch: 6| Step: 12
Training loss: 2.426971912384033
Validation loss: 2.1309074868438063

Epoch: 6| Step: 13
Training loss: 2.528709888458252
Validation loss: 2.1401267154242403

Epoch: 60| Step: 0
Training loss: 2.8076276779174805
Validation loss: 2.1362287229107273

Epoch: 6| Step: 1
Training loss: 2.2086734771728516
Validation loss: 2.1374647848067747

Epoch: 6| Step: 2
Training loss: 2.7286205291748047
Validation loss: 2.1369078723333215

Epoch: 6| Step: 3
Training loss: 2.352851152420044
Validation loss: 2.139135476081602

Epoch: 6| Step: 4
Training loss: 2.331361770629883
Validation loss: 2.160498155060635

Epoch: 6| Step: 5
Training loss: 3.1299173831939697
Validation loss: 2.157281420564139

Epoch: 6| Step: 6
Training loss: 2.1126718521118164
Validation loss: 2.1529284920743716

Epoch: 6| Step: 7
Training loss: 2.5617270469665527
Validation loss: 2.161504363500944

Epoch: 6| Step: 8
Training loss: 2.3985021114349365
Validation loss: 2.1558891778351157

Epoch: 6| Step: 9
Training loss: 1.7243188619613647
Validation loss: 2.1428102139503724

Epoch: 6| Step: 10
Training loss: 3.105484962463379
Validation loss: 2.1399901528512277

Epoch: 6| Step: 11
Training loss: 2.049734592437744
Validation loss: 2.1380023853753203

Epoch: 6| Step: 12
Training loss: 2.0597331523895264
Validation loss: 2.1357135362522577

Epoch: 6| Step: 13
Training loss: 2.716543674468994
Validation loss: 2.126357493862029

Epoch: 61| Step: 0
Training loss: 2.546598434448242
Validation loss: 2.132007848831915

Epoch: 6| Step: 1
Training loss: 3.1404380798339844
Validation loss: 2.1225585886227187

Epoch: 6| Step: 2
Training loss: 2.2275874614715576
Validation loss: 2.1170067248805875

Epoch: 6| Step: 3
Training loss: 2.9257709980010986
Validation loss: 2.1251162636664604

Epoch: 6| Step: 4
Training loss: 2.093068838119507
Validation loss: 2.1111242899330716

Epoch: 6| Step: 5
Training loss: 2.269404411315918
Validation loss: 2.1156398352756294

Epoch: 6| Step: 6
Training loss: 2.7338924407958984
Validation loss: 2.1093404908334055

Epoch: 6| Step: 7
Training loss: 2.2020509243011475
Validation loss: 2.107170427999189

Epoch: 6| Step: 8
Training loss: 3.1946260929107666
Validation loss: 2.107907082444878

Epoch: 6| Step: 9
Training loss: 2.2888543605804443
Validation loss: 2.1263624288702525

Epoch: 6| Step: 10
Training loss: 2.0133252143859863
Validation loss: 2.141462213249617

Epoch: 6| Step: 11
Training loss: 1.5408896207809448
Validation loss: 2.1672643333353023

Epoch: 6| Step: 12
Training loss: 2.152911424636841
Validation loss: 2.1754379144278904

Epoch: 6| Step: 13
Training loss: 2.7086689472198486
Validation loss: 2.1891983170663156

Epoch: 62| Step: 0
Training loss: 3.1917734146118164
Validation loss: 2.25148912911774

Epoch: 6| Step: 1
Training loss: 2.0535597801208496
Validation loss: 2.2287532565414265

Epoch: 6| Step: 2
Training loss: 1.7050061225891113
Validation loss: 2.2232795376931467

Epoch: 6| Step: 3
Training loss: 1.7284233570098877
Validation loss: 2.1683175794539915

Epoch: 6| Step: 4
Training loss: 3.217529296875
Validation loss: 2.157059406721464

Epoch: 6| Step: 5
Training loss: 2.676455020904541
Validation loss: 2.1254167710581133

Epoch: 6| Step: 6
Training loss: 2.4352548122406006
Validation loss: 2.125507944373674

Epoch: 6| Step: 7
Training loss: 2.5194013118743896
Validation loss: 2.1014681734064573

Epoch: 6| Step: 8
Training loss: 2.7958521842956543
Validation loss: 2.103190511785528

Epoch: 6| Step: 9
Training loss: 2.4268784523010254
Validation loss: 2.106765406106108

Epoch: 6| Step: 10
Training loss: 2.7406234741210938
Validation loss: 2.101531567112092

Epoch: 6| Step: 11
Training loss: 2.026705741882324
Validation loss: 2.1137878279532156

Epoch: 6| Step: 12
Training loss: 2.4073641300201416
Validation loss: 2.1092870158533894

Epoch: 6| Step: 13
Training loss: 2.794837713241577
Validation loss: 2.1100785732269287

Epoch: 63| Step: 0
Training loss: 2.062084436416626
Validation loss: 2.1092235388294345

Epoch: 6| Step: 1
Training loss: 1.9317481517791748
Validation loss: 2.1187444515125726

Epoch: 6| Step: 2
Training loss: 2.5153841972351074
Validation loss: 2.1116938257730133

Epoch: 6| Step: 3
Training loss: 1.818039894104004
Validation loss: 2.1301962355131745

Epoch: 6| Step: 4
Training loss: 2.7344167232513428
Validation loss: 2.1480089567040883

Epoch: 6| Step: 5
Training loss: 2.1680874824523926
Validation loss: 2.162248621704758

Epoch: 6| Step: 6
Training loss: 2.696218729019165
Validation loss: 2.172321355471047

Epoch: 6| Step: 7
Training loss: 2.518482208251953
Validation loss: 2.181268294652303

Epoch: 6| Step: 8
Training loss: 2.9100277423858643
Validation loss: 2.2036928951099353

Epoch: 6| Step: 9
Training loss: 2.825566053390503
Validation loss: 2.1990907192230225

Epoch: 6| Step: 10
Training loss: 2.5107381343841553
Validation loss: 2.1866348430674565

Epoch: 6| Step: 11
Training loss: 3.1361374855041504
Validation loss: 2.1774925237060874

Epoch: 6| Step: 12
Training loss: 2.009018659591675
Validation loss: 2.1574542304520965

Epoch: 6| Step: 13
Training loss: 2.263864517211914
Validation loss: 2.1532974858437814

Epoch: 64| Step: 0
Training loss: 2.5288310050964355
Validation loss: 2.1756121650818856

Epoch: 6| Step: 1
Training loss: 2.3919403553009033
Validation loss: 2.170877892483947

Epoch: 6| Step: 2
Training loss: 3.1282660961151123
Validation loss: 2.1740402970262753

Epoch: 6| Step: 3
Training loss: 2.6261982917785645
Validation loss: 2.1614192813955326

Epoch: 6| Step: 4
Training loss: 2.6465888023376465
Validation loss: 2.1600356101989746

Epoch: 6| Step: 5
Training loss: 2.1899638175964355
Validation loss: 2.152762638625278

Epoch: 6| Step: 6
Training loss: 2.0357604026794434
Validation loss: 2.1531069560717513

Epoch: 6| Step: 7
Training loss: 3.3106956481933594
Validation loss: 2.156041870835007

Epoch: 6| Step: 8
Training loss: 2.961904525756836
Validation loss: 2.142142741910873

Epoch: 6| Step: 9
Training loss: 2.0650792121887207
Validation loss: 2.1351329306120514

Epoch: 6| Step: 10
Training loss: 1.9133269786834717
Validation loss: 2.116911054939352

Epoch: 6| Step: 11
Training loss: 1.824404239654541
Validation loss: 2.106197444341516

Epoch: 6| Step: 12
Training loss: 2.3466315269470215
Validation loss: 2.1012235533806587

Epoch: 6| Step: 13
Training loss: 1.7112406492233276
Validation loss: 2.100432070352698

Epoch: 65| Step: 0
Training loss: 2.2327394485473633
Validation loss: 2.100055777898399

Epoch: 6| Step: 1
Training loss: 3.053290843963623
Validation loss: 2.0982242668828657

Epoch: 6| Step: 2
Training loss: 2.0224251747131348
Validation loss: 2.1025934552633636

Epoch: 6| Step: 3
Training loss: 2.9745030403137207
Validation loss: 2.095659553363759

Epoch: 6| Step: 4
Training loss: 2.4937257766723633
Validation loss: 2.0968042676166823

Epoch: 6| Step: 5
Training loss: 2.6280364990234375
Validation loss: 2.0953302024513163

Epoch: 6| Step: 6
Training loss: 1.6715208292007446
Validation loss: 2.105053222307595

Epoch: 6| Step: 7
Training loss: 2.241361618041992
Validation loss: 2.1045111417770386

Epoch: 6| Step: 8
Training loss: 2.761636257171631
Validation loss: 2.0967204647679485

Epoch: 6| Step: 9
Training loss: 2.7150449752807617
Validation loss: 2.0909322307955835

Epoch: 6| Step: 10
Training loss: 2.8723950386047363
Validation loss: 2.0845339477703138

Epoch: 6| Step: 11
Training loss: 2.1178126335144043
Validation loss: 2.088308741969447

Epoch: 6| Step: 12
Training loss: 1.9471302032470703
Validation loss: 2.08880542683345

Epoch: 6| Step: 13
Training loss: 1.7178289890289307
Validation loss: 2.1111322038917133

Epoch: 66| Step: 0
Training loss: 1.9860968589782715
Validation loss: 2.145908903050166

Epoch: 6| Step: 1
Training loss: 2.274853467941284
Validation loss: 2.17755215655091

Epoch: 6| Step: 2
Training loss: 2.5322515964508057
Validation loss: 2.186456236788022

Epoch: 6| Step: 3
Training loss: 2.1169095039367676
Validation loss: 2.2080698654215825

Epoch: 6| Step: 4
Training loss: 2.514307975769043
Validation loss: 2.217967539705256

Epoch: 6| Step: 5
Training loss: 3.0046181678771973
Validation loss: 2.2254164129175167

Epoch: 6| Step: 6
Training loss: 2.6063156127929688
Validation loss: 2.2390770040532595

Epoch: 6| Step: 7
Training loss: 1.974417805671692
Validation loss: 2.217756922527026

Epoch: 6| Step: 8
Training loss: 2.3914990425109863
Validation loss: 2.1763279463655207

Epoch: 6| Step: 9
Training loss: 3.00832462310791
Validation loss: 2.1343330311518844

Epoch: 6| Step: 10
Training loss: 2.5769996643066406
Validation loss: 2.1110759371070453

Epoch: 6| Step: 11
Training loss: 2.3072052001953125
Validation loss: 2.0959886120211695

Epoch: 6| Step: 12
Training loss: 1.8498938083648682
Validation loss: 2.0880554209473314

Epoch: 6| Step: 13
Training loss: 2.8674278259277344
Validation loss: 2.083679578637564

Epoch: 67| Step: 0
Training loss: 2.3350846767425537
Validation loss: 2.0798154005440335

Epoch: 6| Step: 1
Training loss: 2.285304546356201
Validation loss: 2.0812991203800326

Epoch: 6| Step: 2
Training loss: 2.7842965126037598
Validation loss: 2.091092960808867

Epoch: 6| Step: 3
Training loss: 2.39125394821167
Validation loss: 2.096756480073416

Epoch: 6| Step: 4
Training loss: 3.1564812660217285
Validation loss: 2.1008503834406533

Epoch: 6| Step: 5
Training loss: 1.6602823734283447
Validation loss: 2.1061690545851186

Epoch: 6| Step: 6
Training loss: 2.8360652923583984
Validation loss: 2.103379305972848

Epoch: 6| Step: 7
Training loss: 2.289182424545288
Validation loss: 2.1127719212603826

Epoch: 6| Step: 8
Training loss: 2.697277069091797
Validation loss: 2.106946850335726

Epoch: 6| Step: 9
Training loss: 2.0018436908721924
Validation loss: 2.1181146611449537

Epoch: 6| Step: 10
Training loss: 2.0477113723754883
Validation loss: 2.1083863819799116

Epoch: 6| Step: 11
Training loss: 2.1388845443725586
Validation loss: 2.1038813052638883

Epoch: 6| Step: 12
Training loss: 2.732882499694824
Validation loss: 2.1129521990335114

Epoch: 6| Step: 13
Training loss: 2.744601249694824
Validation loss: 2.1186089156776347

Epoch: 68| Step: 0
Training loss: 1.9296389818191528
Validation loss: 2.1224188804626465

Epoch: 6| Step: 1
Training loss: 2.0036780834198
Validation loss: 2.1226271378096713

Epoch: 6| Step: 2
Training loss: 1.7538074254989624
Validation loss: 2.121363188630791

Epoch: 6| Step: 3
Training loss: 2.8267364501953125
Validation loss: 2.132101512724353

Epoch: 6| Step: 4
Training loss: 2.223799228668213
Validation loss: 2.1443507132991666

Epoch: 6| Step: 5
Training loss: 2.0728940963745117
Validation loss: 2.1550168221996677

Epoch: 6| Step: 6
Training loss: 2.8845810890197754
Validation loss: 2.1417765386642946

Epoch: 6| Step: 7
Training loss: 2.682783603668213
Validation loss: 2.128858376574773

Epoch: 6| Step: 8
Training loss: 2.7043256759643555
Validation loss: 2.0929618138138966

Epoch: 6| Step: 9
Training loss: 2.8077807426452637
Validation loss: 2.093017696052469

Epoch: 6| Step: 10
Training loss: 2.7954843044281006
Validation loss: 2.072272772430092

Epoch: 6| Step: 11
Training loss: 2.5960159301757812
Validation loss: 2.0617357953902213

Epoch: 6| Step: 12
Training loss: 1.9823673963546753
Validation loss: 2.055279481795526

Epoch: 6| Step: 13
Training loss: 2.325873374938965
Validation loss: 2.058067919105612

Epoch: 69| Step: 0
Training loss: 1.508797526359558
Validation loss: 2.0581881051422446

Epoch: 6| Step: 1
Training loss: 2.7087416648864746
Validation loss: 2.0574783612323064

Epoch: 6| Step: 2
Training loss: 2.802375316619873
Validation loss: 2.060434869540635

Epoch: 6| Step: 3
Training loss: 1.9218554496765137
Validation loss: 2.055956498269112

Epoch: 6| Step: 4
Training loss: 2.29233717918396
Validation loss: 2.063625979167159

Epoch: 6| Step: 5
Training loss: 2.205441474914551
Validation loss: 2.0715813867507444

Epoch: 6| Step: 6
Training loss: 2.2868988513946533
Validation loss: 2.073281200983191

Epoch: 6| Step: 7
Training loss: 2.422771692276001
Validation loss: 2.0983153696983092

Epoch: 6| Step: 8
Training loss: 2.112816572189331
Validation loss: 2.1047373792176605

Epoch: 6| Step: 9
Training loss: 3.235507011413574
Validation loss: 2.162097923217281

Epoch: 6| Step: 10
Training loss: 2.6438121795654297
Validation loss: 2.20812943802085

Epoch: 6| Step: 11
Training loss: 2.699453592300415
Validation loss: 2.2587684251928843

Epoch: 6| Step: 12
Training loss: 2.8053150177001953
Validation loss: 2.29285845961622

Epoch: 6| Step: 13
Training loss: 2.4042956829071045
Validation loss: 2.2177244335092525

Epoch: 70| Step: 0
Training loss: 2.0000343322753906
Validation loss: 2.179750729632634

Epoch: 6| Step: 1
Training loss: 2.4965152740478516
Validation loss: 2.1310855906496764

Epoch: 6| Step: 2
Training loss: 1.9935927391052246
Validation loss: 2.1144359009240263

Epoch: 6| Step: 3
Training loss: 1.9233486652374268
Validation loss: 2.091903699341641

Epoch: 6| Step: 4
Training loss: 2.1496338844299316
Validation loss: 2.0829497434759654

Epoch: 6| Step: 5
Training loss: 1.9998310804367065
Validation loss: 2.080960435252036

Epoch: 6| Step: 6
Training loss: 2.576584815979004
Validation loss: 2.0813365674787954

Epoch: 6| Step: 7
Training loss: 2.193122386932373
Validation loss: 2.070227175630549

Epoch: 6| Step: 8
Training loss: 2.4024596214294434
Validation loss: 2.0639164973330755

Epoch: 6| Step: 9
Training loss: 3.085266590118408
Validation loss: 2.057666390172897

Epoch: 6| Step: 10
Training loss: 2.517406702041626
Validation loss: 2.056569322463005

Epoch: 6| Step: 11
Training loss: 2.5655508041381836
Validation loss: 2.0587693593835317

Epoch: 6| Step: 12
Training loss: 2.7726802825927734
Validation loss: 2.070962254719068

Epoch: 6| Step: 13
Training loss: 3.0025339126586914
Validation loss: 2.0831102863434823

Epoch: 71| Step: 0
Training loss: 2.6575164794921875
Validation loss: 2.0735694157179965

Epoch: 6| Step: 1
Training loss: 1.9541527032852173
Validation loss: 2.0509774479814755

Epoch: 6| Step: 2
Training loss: 1.7948546409606934
Validation loss: 2.052166033816594

Epoch: 6| Step: 3
Training loss: 1.772995948791504
Validation loss: 2.0420604982683734

Epoch: 6| Step: 4
Training loss: 2.353287696838379
Validation loss: 2.054288484716928

Epoch: 6| Step: 5
Training loss: 2.728576183319092
Validation loss: 2.085994433331233

Epoch: 6| Step: 6
Training loss: 2.41384220123291
Validation loss: 2.121212000487953

Epoch: 6| Step: 7
Training loss: 2.725860118865967
Validation loss: 2.1399297009232225

Epoch: 6| Step: 8
Training loss: 2.1300466060638428
Validation loss: 2.1420779330756075

Epoch: 6| Step: 9
Training loss: 2.705911159515381
Validation loss: 2.157502125668269

Epoch: 6| Step: 10
Training loss: 2.2230582237243652
Validation loss: 2.1233482796658754

Epoch: 6| Step: 11
Training loss: 2.749242067337036
Validation loss: 2.1054662427594586

Epoch: 6| Step: 12
Training loss: 3.0592920780181885
Validation loss: 2.085468287109047

Epoch: 6| Step: 13
Training loss: 2.1778292655944824
Validation loss: 2.067595330617761

Epoch: 72| Step: 0
Training loss: 2.009629249572754
Validation loss: 2.0523701252475863

Epoch: 6| Step: 1
Training loss: 2.878214120864868
Validation loss: 2.056370494186237

Epoch: 6| Step: 2
Training loss: 2.6037726402282715
Validation loss: 2.0570050157526487

Epoch: 6| Step: 3
Training loss: 2.634988784790039
Validation loss: 2.055117940389982

Epoch: 6| Step: 4
Training loss: 2.2875351905822754
Validation loss: 2.0614477947194088

Epoch: 6| Step: 5
Training loss: 2.3143486976623535
Validation loss: 2.0663587175389773

Epoch: 6| Step: 6
Training loss: 2.7319483757019043
Validation loss: 2.0641473813723494

Epoch: 6| Step: 7
Training loss: 2.021501064300537
Validation loss: 2.062497893969218

Epoch: 6| Step: 8
Training loss: 1.827275037765503
Validation loss: 2.0711229257686163

Epoch: 6| Step: 9
Training loss: 2.445450782775879
Validation loss: 2.0610182208399617

Epoch: 6| Step: 10
Training loss: 2.712829828262329
Validation loss: 2.072728318552817

Epoch: 6| Step: 11
Training loss: 2.259942054748535
Validation loss: 2.0728899535312446

Epoch: 6| Step: 12
Training loss: 2.2085084915161133
Validation loss: 2.07096436203167

Epoch: 6| Step: 13
Training loss: 2.172124147415161
Validation loss: 2.0712892342639226

Epoch: 73| Step: 0
Training loss: 2.0308752059936523
Validation loss: 2.067651992203087

Epoch: 6| Step: 1
Training loss: 2.5288400650024414
Validation loss: 2.0588522418852775

Epoch: 6| Step: 2
Training loss: 2.6130897998809814
Validation loss: 2.0485450824101767

Epoch: 6| Step: 3
Training loss: 1.9555385112762451
Validation loss: 2.047585905239146

Epoch: 6| Step: 4
Training loss: 2.546156644821167
Validation loss: 2.0526654592124363

Epoch: 6| Step: 5
Training loss: 2.6237258911132812
Validation loss: 2.055216314972088

Epoch: 6| Step: 6
Training loss: 2.5342509746551514
Validation loss: 2.0665889709226546

Epoch: 6| Step: 7
Training loss: 2.4742441177368164
Validation loss: 2.074867416453618

Epoch: 6| Step: 8
Training loss: 2.9086809158325195
Validation loss: 2.072992956766518

Epoch: 6| Step: 9
Training loss: 2.1038620471954346
Validation loss: 2.082124860055985

Epoch: 6| Step: 10
Training loss: 2.1018855571746826
Validation loss: 2.0748148118295977

Epoch: 6| Step: 11
Training loss: 1.5172404050827026
Validation loss: 2.054630733305408

Epoch: 6| Step: 12
Training loss: 2.2488014698028564
Validation loss: 2.064329808758151

Epoch: 6| Step: 13
Training loss: 3.0757997035980225
Validation loss: 2.0718774423804334

Epoch: 74| Step: 0
Training loss: 2.3798410892486572
Validation loss: 2.0956771630112843

Epoch: 6| Step: 1
Training loss: 2.24727725982666
Validation loss: 2.147545688895769

Epoch: 6| Step: 2
Training loss: 2.8897433280944824
Validation loss: 2.174698661732417

Epoch: 6| Step: 3
Training loss: 1.9603261947631836
Validation loss: 2.1581582151433474

Epoch: 6| Step: 4
Training loss: 2.249634027481079
Validation loss: 2.1366880196397022

Epoch: 6| Step: 5
Training loss: 2.3590927124023438
Validation loss: 2.111512137997535

Epoch: 6| Step: 6
Training loss: 2.167609691619873
Validation loss: 2.078952517560733

Epoch: 6| Step: 7
Training loss: 1.7587878704071045
Validation loss: 2.0605281219687512

Epoch: 6| Step: 8
Training loss: 2.678447723388672
Validation loss: 2.063084666446973

Epoch: 6| Step: 9
Training loss: 2.9134700298309326
Validation loss: 2.04388097024733

Epoch: 6| Step: 10
Training loss: 2.31540584564209
Validation loss: 2.057160464666223

Epoch: 6| Step: 11
Training loss: 2.5215816497802734
Validation loss: 2.054843512914514

Epoch: 6| Step: 12
Training loss: 2.313131093978882
Validation loss: 2.0579763535530335

Epoch: 6| Step: 13
Training loss: 2.3695497512817383
Validation loss: 2.055750587935089

Epoch: 75| Step: 0
Training loss: 2.2928528785705566
Validation loss: 2.05698126105852

Epoch: 6| Step: 1
Training loss: 2.7470250129699707
Validation loss: 2.051748921794276

Epoch: 6| Step: 2
Training loss: 2.2540440559387207
Validation loss: 2.053495442995461

Epoch: 6| Step: 3
Training loss: 2.4550881385803223
Validation loss: 2.0429433417576615

Epoch: 6| Step: 4
Training loss: 2.245474338531494
Validation loss: 2.0453212248381747

Epoch: 6| Step: 5
Training loss: 2.877958297729492
Validation loss: 2.0553723945412585

Epoch: 6| Step: 6
Training loss: 2.0524725914001465
Validation loss: 2.054008876123736

Epoch: 6| Step: 7
Training loss: 2.4955403804779053
Validation loss: 2.0639111277877644

Epoch: 6| Step: 8
Training loss: 1.9782978296279907
Validation loss: 2.0532855128729217

Epoch: 6| Step: 9
Training loss: 3.155350685119629
Validation loss: 2.0544677716429516

Epoch: 6| Step: 10
Training loss: 2.1648242473602295
Validation loss: 2.056659198576404

Epoch: 6| Step: 11
Training loss: 2.621682643890381
Validation loss: 2.054026363998331

Epoch: 6| Step: 12
Training loss: 1.7250665426254272
Validation loss: 2.0719294727489515

Epoch: 6| Step: 13
Training loss: 2.1217031478881836
Validation loss: 2.073146773922828

Epoch: 76| Step: 0
Training loss: 3.0852341651916504
Validation loss: 2.129077708849343

Epoch: 6| Step: 1
Training loss: 2.7049381732940674
Validation loss: 2.1123842500871226

Epoch: 6| Step: 2
Training loss: 2.3535642623901367
Validation loss: 2.108006454283191

Epoch: 6| Step: 3
Training loss: 2.192013740539551
Validation loss: 2.0891216570331204

Epoch: 6| Step: 4
Training loss: 2.4877829551696777
Validation loss: 2.100082766625189

Epoch: 6| Step: 5
Training loss: 2.586378574371338
Validation loss: 2.089918303233321

Epoch: 6| Step: 6
Training loss: 1.948196291923523
Validation loss: 2.0700912424313125

Epoch: 6| Step: 7
Training loss: 2.493412494659424
Validation loss: 2.0893717158225273

Epoch: 6| Step: 8
Training loss: 2.468897819519043
Validation loss: 2.094926493142241

Epoch: 6| Step: 9
Training loss: 2.2908802032470703
Validation loss: 2.084639838946763

Epoch: 6| Step: 10
Training loss: 2.2001428604125977
Validation loss: 2.063153928326022

Epoch: 6| Step: 11
Training loss: 1.896655797958374
Validation loss: 2.066630490364567

Epoch: 6| Step: 12
Training loss: 1.9237786531448364
Validation loss: 2.057716477301813

Epoch: 6| Step: 13
Training loss: 2.2489757537841797
Validation loss: 2.0629516301616544

Epoch: 77| Step: 0
Training loss: 2.243351697921753
Validation loss: 2.0451904227656703

Epoch: 6| Step: 1
Training loss: 3.2212507724761963
Validation loss: 2.052442007167365

Epoch: 6| Step: 2
Training loss: 2.6798043251037598
Validation loss: 2.05022664864858

Epoch: 6| Step: 3
Training loss: 1.7425148487091064
Validation loss: 2.0407516725601687

Epoch: 6| Step: 4
Training loss: 2.217710018157959
Validation loss: 2.031478479344358

Epoch: 6| Step: 5
Training loss: 2.888054609298706
Validation loss: 2.040810728585848

Epoch: 6| Step: 6
Training loss: 1.6788567304611206
Validation loss: 2.0420758749849055

Epoch: 6| Step: 7
Training loss: 1.988858938217163
Validation loss: 2.064082098263566

Epoch: 6| Step: 8
Training loss: 2.216506004333496
Validation loss: 2.067825419928438

Epoch: 6| Step: 9
Training loss: 2.144451141357422
Validation loss: 2.089896548178888

Epoch: 6| Step: 10
Training loss: 2.524155378341675
Validation loss: 2.119172321852817

Epoch: 6| Step: 11
Training loss: 2.3028383255004883
Validation loss: 2.137251256614603

Epoch: 6| Step: 12
Training loss: 2.5253419876098633
Validation loss: 2.123563443460772

Epoch: 6| Step: 13
Training loss: 2.2370829582214355
Validation loss: 2.11874803163672

Epoch: 78| Step: 0
Training loss: 2.290943145751953
Validation loss: 2.090055875880744

Epoch: 6| Step: 1
Training loss: 1.9408575296401978
Validation loss: 2.070690965139738

Epoch: 6| Step: 2
Training loss: 1.7290042638778687
Validation loss: 2.0607446624386694

Epoch: 6| Step: 3
Training loss: 2.2852206230163574
Validation loss: 2.0751492143959127

Epoch: 6| Step: 4
Training loss: 1.8496228456497192
Validation loss: 2.096274175951558

Epoch: 6| Step: 5
Training loss: 1.797461986541748
Validation loss: 2.0870017825916247

Epoch: 6| Step: 6
Training loss: 2.5891385078430176
Validation loss: 2.0625790972863474

Epoch: 6| Step: 7
Training loss: 2.1196906566619873
Validation loss: 2.044666087755593

Epoch: 6| Step: 8
Training loss: 3.4338598251342773
Validation loss: 2.0276649716079875

Epoch: 6| Step: 9
Training loss: 2.6606762409210205
Validation loss: 2.0196705928412815

Epoch: 6| Step: 10
Training loss: 2.8298826217651367
Validation loss: 2.0171519184625275

Epoch: 6| Step: 11
Training loss: 2.17372989654541
Validation loss: 2.0147423282746346

Epoch: 6| Step: 12
Training loss: 2.466834545135498
Validation loss: 2.0221720203276603

Epoch: 6| Step: 13
Training loss: 2.418867826461792
Validation loss: 2.0071054991855415

Epoch: 79| Step: 0
Training loss: 3.01871395111084
Validation loss: 2.005552643088884

Epoch: 6| Step: 1
Training loss: 2.062922954559326
Validation loss: 2.0080095234737603

Epoch: 6| Step: 2
Training loss: 2.895754337310791
Validation loss: 2.010280737312891

Epoch: 6| Step: 3
Training loss: 1.8165702819824219
Validation loss: 2.0102688625294673

Epoch: 6| Step: 4
Training loss: 2.0585055351257324
Validation loss: 2.018435732010872

Epoch: 6| Step: 5
Training loss: 0.977546215057373
Validation loss: 2.030068343685519

Epoch: 6| Step: 6
Training loss: 2.9550940990448
Validation loss: 2.0555706690716486

Epoch: 6| Step: 7
Training loss: 3.118835210800171
Validation loss: 2.112004651818224

Epoch: 6| Step: 8
Training loss: 2.0965847969055176
Validation loss: 2.128883715598814

Epoch: 6| Step: 9
Training loss: 2.5097930431365967
Validation loss: 2.0799706353936145

Epoch: 6| Step: 10
Training loss: 1.9412428140640259
Validation loss: 2.0685267948335215

Epoch: 6| Step: 11
Training loss: 2.935959815979004
Validation loss: 2.044113423234673

Epoch: 6| Step: 12
Training loss: 2.0617761611938477
Validation loss: 2.043736619334067

Epoch: 6| Step: 13
Training loss: 2.446619749069214
Validation loss: 2.0310974659458285

Epoch: 80| Step: 0
Training loss: 2.1034650802612305
Validation loss: 2.0109334684187368

Epoch: 6| Step: 1
Training loss: 1.9778823852539062
Validation loss: 1.9941569925636373

Epoch: 6| Step: 2
Training loss: 2.412236213684082
Validation loss: 1.9943752673364454

Epoch: 6| Step: 3
Training loss: 2.1929678916931152
Validation loss: 2.004510820552867

Epoch: 6| Step: 4
Training loss: 2.585036277770996
Validation loss: 1.9984069408908967

Epoch: 6| Step: 5
Training loss: 1.9662400484085083
Validation loss: 2.0107920631285636

Epoch: 6| Step: 6
Training loss: 2.434586763381958
Validation loss: 2.01566437111106

Epoch: 6| Step: 7
Training loss: 2.9413228034973145
Validation loss: 2.059746603811941

Epoch: 6| Step: 8
Training loss: 2.454447031021118
Validation loss: 2.096995863863217

Epoch: 6| Step: 9
Training loss: 2.6453206539154053
Validation loss: 2.135875483994843

Epoch: 6| Step: 10
Training loss: 2.196457862854004
Validation loss: 2.1608985572732906

Epoch: 6| Step: 11
Training loss: 2.714657783508301
Validation loss: 2.119123787008306

Epoch: 6| Step: 12
Training loss: 2.146883249282837
Validation loss: 2.0641930757030362

Epoch: 6| Step: 13
Training loss: 1.791760802268982
Validation loss: 2.0138398549890004

Epoch: 81| Step: 0
Training loss: 2.828819751739502
Validation loss: 1.9951747361049856

Epoch: 6| Step: 1
Training loss: 2.316479206085205
Validation loss: 1.9998590048923288

Epoch: 6| Step: 2
Training loss: 2.4762580394744873
Validation loss: 1.994442295002681

Epoch: 6| Step: 3
Training loss: 0.9351931810379028
Validation loss: 2.0017362486931587

Epoch: 6| Step: 4
Training loss: 2.349902629852295
Validation loss: 1.9936940939195695

Epoch: 6| Step: 5
Training loss: 2.3877010345458984
Validation loss: 2.007217627699657

Epoch: 6| Step: 6
Training loss: 1.8183400630950928
Validation loss: 2.024967933213839

Epoch: 6| Step: 7
Training loss: 1.8330501317977905
Validation loss: 2.0483889772045996

Epoch: 6| Step: 8
Training loss: 2.5232162475585938
Validation loss: 2.0859915876901276

Epoch: 6| Step: 9
Training loss: 2.8988921642303467
Validation loss: 2.1310364994951474

Epoch: 6| Step: 10
Training loss: 2.933689594268799
Validation loss: 2.157610385648666

Epoch: 6| Step: 11
Training loss: 2.655503988265991
Validation loss: 2.1669747124436083

Epoch: 6| Step: 12
Training loss: 2.704604148864746
Validation loss: 2.1590754626899638

Epoch: 6| Step: 13
Training loss: 2.7060582637786865
Validation loss: 2.106553872426351

Epoch: 82| Step: 0
Training loss: 3.026932716369629
Validation loss: 2.087324474447517

Epoch: 6| Step: 1
Training loss: 2.5663976669311523
Validation loss: 2.0556358701439312

Epoch: 6| Step: 2
Training loss: 1.926981806755066
Validation loss: 2.045760735388725

Epoch: 6| Step: 3
Training loss: 2.4026601314544678
Validation loss: 2.032508921879594

Epoch: 6| Step: 4
Training loss: 2.747875213623047
Validation loss: 2.029920772839618

Epoch: 6| Step: 5
Training loss: 1.8729970455169678
Validation loss: 2.0225956286153486

Epoch: 6| Step: 6
Training loss: 1.7222559452056885
Validation loss: 2.0223494511778637

Epoch: 6| Step: 7
Training loss: 2.015855312347412
Validation loss: 2.016282363604474

Epoch: 6| Step: 8
Training loss: 2.6184239387512207
Validation loss: 2.0176996159297165

Epoch: 6| Step: 9
Training loss: 2.5037074089050293
Validation loss: 2.016081287014869

Epoch: 6| Step: 10
Training loss: 1.922845721244812
Validation loss: 2.0314875187412387

Epoch: 6| Step: 11
Training loss: 2.518770694732666
Validation loss: 2.0454718887165027

Epoch: 6| Step: 12
Training loss: 2.119725227355957
Validation loss: 2.0700564281914824

Epoch: 6| Step: 13
Training loss: 2.7699098587036133
Validation loss: 2.0927268215405044

Epoch: 83| Step: 0
Training loss: 2.517709970474243
Validation loss: 2.120779688640307

Epoch: 6| Step: 1
Training loss: 2.605409622192383
Validation loss: 2.159484472326053

Epoch: 6| Step: 2
Training loss: 2.808925151824951
Validation loss: 2.14777615762526

Epoch: 6| Step: 3
Training loss: 2.2777175903320312
Validation loss: 2.1005538650738296

Epoch: 6| Step: 4
Training loss: 2.180771827697754
Validation loss: 2.0371503855592463

Epoch: 6| Step: 5
Training loss: 1.4051433801651
Validation loss: 2.0135430494944253

Epoch: 6| Step: 6
Training loss: 1.785080909729004
Validation loss: 1.9987279881713211

Epoch: 6| Step: 7
Training loss: 1.8796093463897705
Validation loss: 2.008500163273145

Epoch: 6| Step: 8
Training loss: 2.4488747119903564
Validation loss: 2.0042596991344164

Epoch: 6| Step: 9
Training loss: 2.686082363128662
Validation loss: 2.0064544318824686

Epoch: 6| Step: 10
Training loss: 2.382981300354004
Validation loss: 1.9943702182462137

Epoch: 6| Step: 11
Training loss: 2.909107208251953
Validation loss: 2.003609472705472

Epoch: 6| Step: 12
Training loss: 2.7969093322753906
Validation loss: 2.008399017395512

Epoch: 6| Step: 13
Training loss: 2.2873547077178955
Validation loss: 2.0208321309858754

Epoch: 84| Step: 0
Training loss: 2.5636072158813477
Validation loss: 2.0430146084036878

Epoch: 6| Step: 1
Training loss: 1.9215067625045776
Validation loss: 2.0973636129850983

Epoch: 6| Step: 2
Training loss: 2.6069557666778564
Validation loss: 2.1356482454525527

Epoch: 6| Step: 3
Training loss: 2.3959414958953857
Validation loss: 2.145426191309447

Epoch: 6| Step: 4
Training loss: 2.1318840980529785
Validation loss: 2.135852298428935

Epoch: 6| Step: 5
Training loss: 2.5425426959991455
Validation loss: 2.1198351255027195

Epoch: 6| Step: 6
Training loss: 2.6019113063812256
Validation loss: 2.1160142242267566

Epoch: 6| Step: 7
Training loss: 1.6643614768981934
Validation loss: 2.1258511286909862

Epoch: 6| Step: 8
Training loss: 2.3736727237701416
Validation loss: 2.1107924727983374

Epoch: 6| Step: 9
Training loss: 2.2838685512542725
Validation loss: 2.0798828499291533

Epoch: 6| Step: 10
Training loss: 2.013631820678711
Validation loss: 2.051459165029628

Epoch: 6| Step: 11
Training loss: 2.9124794006347656
Validation loss: 2.0177367733370875

Epoch: 6| Step: 12
Training loss: 1.6428611278533936
Validation loss: 2.0184283871804514

Epoch: 6| Step: 13
Training loss: 3.3300743103027344
Validation loss: 2.0340569660227787

Epoch: 85| Step: 0
Training loss: 2.2090275287628174
Validation loss: 2.0252815651637253

Epoch: 6| Step: 1
Training loss: 2.469491481781006
Validation loss: 2.0296021994724067

Epoch: 6| Step: 2
Training loss: 2.1051554679870605
Validation loss: 2.038988085203273

Epoch: 6| Step: 3
Training loss: 2.549348831176758
Validation loss: 2.034860236670381

Epoch: 6| Step: 4
Training loss: 2.3626868724823
Validation loss: 2.004996911171944

Epoch: 6| Step: 5
Training loss: 1.6356227397918701
Validation loss: 2.00838464818975

Epoch: 6| Step: 6
Training loss: 2.904270648956299
Validation loss: 2.003390622395341

Epoch: 6| Step: 7
Training loss: 2.5593576431274414
Validation loss: 2.004351706915004

Epoch: 6| Step: 8
Training loss: 2.373169422149658
Validation loss: 2.0029801476386284

Epoch: 6| Step: 9
Training loss: 1.917877197265625
Validation loss: 2.022393226623535

Epoch: 6| Step: 10
Training loss: 2.3741745948791504
Validation loss: 2.03739381477397

Epoch: 6| Step: 11
Training loss: 1.98131263256073
Validation loss: 2.064282267324386

Epoch: 6| Step: 12
Training loss: 2.7150380611419678
Validation loss: 2.071801818827147

Epoch: 6| Step: 13
Training loss: 1.7040104866027832
Validation loss: 2.0944988394296296

Epoch: 86| Step: 0
Training loss: 3.0176751613616943
Validation loss: 2.0908211187649797

Epoch: 6| Step: 1
Training loss: 2.4130828380584717
Validation loss: 2.085452905265234

Epoch: 6| Step: 2
Training loss: 1.939557433128357
Validation loss: 2.0482492421263006

Epoch: 6| Step: 3
Training loss: 1.8538234233856201
Validation loss: 2.0464699832342004

Epoch: 6| Step: 4
Training loss: 2.3112261295318604
Validation loss: 2.0155666130845264

Epoch: 6| Step: 5
Training loss: 2.218536853790283
Validation loss: 2.008011605149956

Epoch: 6| Step: 6
Training loss: 1.924440622329712
Validation loss: 2.0051634747494935

Epoch: 6| Step: 7
Training loss: 1.9530105590820312
Validation loss: 1.9892785651709444

Epoch: 6| Step: 8
Training loss: 2.774721384048462
Validation loss: 1.9928300790889288

Epoch: 6| Step: 9
Training loss: 2.590031147003174
Validation loss: 1.9973565314405708

Epoch: 6| Step: 10
Training loss: 2.6565704345703125
Validation loss: 1.9932865583768455

Epoch: 6| Step: 11
Training loss: 1.4763026237487793
Validation loss: 1.9851411760494273

Epoch: 6| Step: 12
Training loss: 2.9584739208221436
Validation loss: 1.9837618463782853

Epoch: 6| Step: 13
Training loss: 2.002178192138672
Validation loss: 2.0023965707389255

Epoch: 87| Step: 0
Training loss: 1.4133410453796387
Validation loss: 2.0077227161776636

Epoch: 6| Step: 1
Training loss: 3.0978565216064453
Validation loss: 2.0365581179177887

Epoch: 6| Step: 2
Training loss: 2.0474507808685303
Validation loss: 2.047620898933821

Epoch: 6| Step: 3
Training loss: 2.366373300552368
Validation loss: 2.074794202722529

Epoch: 6| Step: 4
Training loss: 2.0380635261535645
Validation loss: 2.0979006110980944

Epoch: 6| Step: 5
Training loss: 2.565074920654297
Validation loss: 2.109041790808401

Epoch: 6| Step: 6
Training loss: 2.4650440216064453
Validation loss: 2.099925761581749

Epoch: 6| Step: 7
Training loss: 2.488527536392212
Validation loss: 2.061670773772783

Epoch: 6| Step: 8
Training loss: 1.9201792478561401
Validation loss: 2.0234612675123316

Epoch: 6| Step: 9
Training loss: 2.406399726867676
Validation loss: 2.0093940060625792

Epoch: 6| Step: 10
Training loss: 2.732219934463501
Validation loss: 1.999355423835016

Epoch: 6| Step: 11
Training loss: 1.9644426107406616
Validation loss: 2.0057493332893617

Epoch: 6| Step: 12
Training loss: 2.10833740234375
Validation loss: 2.01411194955149

Epoch: 6| Step: 13
Training loss: 3.0282652378082275
Validation loss: 2.009871013702885

Epoch: 88| Step: 0
Training loss: 2.290294885635376
Validation loss: 2.0097575097955684

Epoch: 6| Step: 1
Training loss: 2.547147750854492
Validation loss: 2.023219129090668

Epoch: 6| Step: 2
Training loss: 2.028315305709839
Validation loss: 2.020934404865388

Epoch: 6| Step: 3
Training loss: 2.231792449951172
Validation loss: 2.018262629867882

Epoch: 6| Step: 4
Training loss: 2.2388789653778076
Validation loss: 2.033778626431701

Epoch: 6| Step: 5
Training loss: 2.1812214851379395
Validation loss: 2.0488213621160036

Epoch: 6| Step: 6
Training loss: 2.0826008319854736
Validation loss: 2.0743992841371925

Epoch: 6| Step: 7
Training loss: 2.7136595249176025
Validation loss: 2.0996635626721125

Epoch: 6| Step: 8
Training loss: 1.9509499073028564
Validation loss: 2.1139810751843195

Epoch: 6| Step: 9
Training loss: 2.308086395263672
Validation loss: 2.0724977075412707

Epoch: 6| Step: 10
Training loss: 2.3222546577453613
Validation loss: 2.0421729344193653

Epoch: 6| Step: 11
Training loss: 1.6968246698379517
Validation loss: 2.003236662956976

Epoch: 6| Step: 12
Training loss: 2.4065980911254883
Validation loss: 2.0136815629979616

Epoch: 6| Step: 13
Training loss: 3.4495458602905273
Validation loss: 2.0264598118361605

Epoch: 89| Step: 0
Training loss: 3.0434694290161133
Validation loss: 2.038555020927101

Epoch: 6| Step: 1
Training loss: 1.6603870391845703
Validation loss: 2.0574663121213197

Epoch: 6| Step: 2
Training loss: 2.871964693069458
Validation loss: 2.0587577742914998

Epoch: 6| Step: 3
Training loss: 1.8952583074569702
Validation loss: 2.026631893650178

Epoch: 6| Step: 4
Training loss: 2.324465274810791
Validation loss: 2.0305689457924134

Epoch: 6| Step: 5
Training loss: 2.166792631149292
Validation loss: 2.0211647825856365

Epoch: 6| Step: 6
Training loss: 2.2781333923339844
Validation loss: 2.0146761325097855

Epoch: 6| Step: 7
Training loss: 2.452843189239502
Validation loss: 2.010357624741011

Epoch: 6| Step: 8
Training loss: 2.294386863708496
Validation loss: 2.0152079828323854

Epoch: 6| Step: 9
Training loss: 1.964974284172058
Validation loss: 2.0135697677571285

Epoch: 6| Step: 10
Training loss: 2.0650124549865723
Validation loss: 2.0279118630193893

Epoch: 6| Step: 11
Training loss: 2.5090456008911133
Validation loss: 2.0307392484398297

Epoch: 6| Step: 12
Training loss: 1.647106409072876
Validation loss: 2.0389904745163454

Epoch: 6| Step: 13
Training loss: 2.89845609664917
Validation loss: 2.0408151239477177

Epoch: 90| Step: 0
Training loss: 2.768618583679199
Validation loss: 2.062881892727267

Epoch: 6| Step: 1
Training loss: 2.64620041847229
Validation loss: 2.0747860964908393

Epoch: 6| Step: 2
Training loss: 2.246460437774658
Validation loss: 2.078282433171426

Epoch: 6| Step: 3
Training loss: 2.635530471801758
Validation loss: 2.0530452369361796

Epoch: 6| Step: 4
Training loss: 2.1186435222625732
Validation loss: 2.0331377470365135

Epoch: 6| Step: 5
Training loss: 2.29895281791687
Validation loss: 2.0236344234917754

Epoch: 6| Step: 6
Training loss: 1.7646279335021973
Validation loss: 2.0013707901841853

Epoch: 6| Step: 7
Training loss: 2.098304510116577
Validation loss: 1.9998864794290194

Epoch: 6| Step: 8
Training loss: 2.2339134216308594
Validation loss: 2.002595563088694

Epoch: 6| Step: 9
Training loss: 2.3864378929138184
Validation loss: 1.996056887411302

Epoch: 6| Step: 10
Training loss: 2.4995908737182617
Validation loss: 2.009762663995066

Epoch: 6| Step: 11
Training loss: 2.125520944595337
Validation loss: 2.003519981138168

Epoch: 6| Step: 12
Training loss: 1.967682957649231
Validation loss: 2.029135539967527

Epoch: 6| Step: 13
Training loss: 2.0483179092407227
Validation loss: 2.039827467292868

Epoch: 91| Step: 0
Training loss: 1.6294137239456177
Validation loss: 2.0548171394614765

Epoch: 6| Step: 1
Training loss: 2.409705638885498
Validation loss: 2.0477965160082747

Epoch: 6| Step: 2
Training loss: 2.2229230403900146
Validation loss: 2.0228896653780373

Epoch: 6| Step: 3
Training loss: 2.022050380706787
Validation loss: 2.0230875194713636

Epoch: 6| Step: 4
Training loss: 2.5059280395507812
Validation loss: 2.02253476009574

Epoch: 6| Step: 5
Training loss: 2.004936695098877
Validation loss: 2.0122456524961736

Epoch: 6| Step: 6
Training loss: 2.6522648334503174
Validation loss: 2.0029556161613873

Epoch: 6| Step: 7
Training loss: 1.9607954025268555
Validation loss: 2.0145577423034178

Epoch: 6| Step: 8
Training loss: 2.873391628265381
Validation loss: 2.015867725495369

Epoch: 6| Step: 9
Training loss: 2.442521572113037
Validation loss: 2.0157902727844896

Epoch: 6| Step: 10
Training loss: 1.9837998151779175
Validation loss: 2.018363546299678

Epoch: 6| Step: 11
Training loss: 2.1575920581817627
Validation loss: 2.0162174547872236

Epoch: 6| Step: 12
Training loss: 2.4040870666503906
Validation loss: 2.0156978971214703

Epoch: 6| Step: 13
Training loss: 2.213723659515381
Validation loss: 2.03218847961836

Epoch: 92| Step: 0
Training loss: 1.4087659120559692
Validation loss: 2.05505899460085

Epoch: 6| Step: 1
Training loss: 2.968513011932373
Validation loss: 2.058233461072368

Epoch: 6| Step: 2
Training loss: 1.8667773008346558
Validation loss: 2.0909630919015534

Epoch: 6| Step: 3
Training loss: 2.514770030975342
Validation loss: 2.114113280850072

Epoch: 6| Step: 4
Training loss: 2.9962401390075684
Validation loss: 2.1063999565698768

Epoch: 6| Step: 5
Training loss: 1.9861395359039307
Validation loss: 2.0823162986386206

Epoch: 6| Step: 6
Training loss: 2.4581944942474365
Validation loss: 2.059772747819142

Epoch: 6| Step: 7
Training loss: 2.5275919437408447
Validation loss: 2.0212311180689

Epoch: 6| Step: 8
Training loss: 1.6671934127807617
Validation loss: 2.0195616932325464

Epoch: 6| Step: 9
Training loss: 2.819741725921631
Validation loss: 2.018584111685394

Epoch: 6| Step: 10
Training loss: 2.071645498275757
Validation loss: 2.012394970463168

Epoch: 6| Step: 11
Training loss: 1.5362868309020996
Validation loss: 2.015467110500541

Epoch: 6| Step: 12
Training loss: 2.0508222579956055
Validation loss: 2.0060872236887612

Epoch: 6| Step: 13
Training loss: 3.0108726024627686
Validation loss: 2.005528452575848

Epoch: 93| Step: 0
Training loss: 2.127812147140503
Validation loss: 2.0025790122247513

Epoch: 6| Step: 1
Training loss: 2.105639696121216
Validation loss: 2.0022368136272637

Epoch: 6| Step: 2
Training loss: 2.5564932823181152
Validation loss: 1.994809728796764

Epoch: 6| Step: 3
Training loss: 2.088412284851074
Validation loss: 2.007361488957559

Epoch: 6| Step: 4
Training loss: 1.9574213027954102
Validation loss: 2.0061221840561076

Epoch: 6| Step: 5
Training loss: 2.8491291999816895
Validation loss: 2.014275421378433

Epoch: 6| Step: 6
Training loss: 2.1023316383361816
Validation loss: 2.030579892537927

Epoch: 6| Step: 7
Training loss: 2.1340720653533936
Validation loss: 2.047639298182662

Epoch: 6| Step: 8
Training loss: 2.8016955852508545
Validation loss: 2.0329695401653165

Epoch: 6| Step: 9
Training loss: 2.1668405532836914
Validation loss: 2.045784463164627

Epoch: 6| Step: 10
Training loss: 1.6637002229690552
Validation loss: 2.0188390042192195

Epoch: 6| Step: 11
Training loss: 2.0527448654174805
Validation loss: 2.001224112767045

Epoch: 6| Step: 12
Training loss: 2.4749035835266113
Validation loss: 1.9981322121876541

Epoch: 6| Step: 13
Training loss: 2.318458318710327
Validation loss: 2.0108734946097098

Epoch: 94| Step: 0
Training loss: 2.2662363052368164
Validation loss: 2.0461977733078824

Epoch: 6| Step: 1
Training loss: 2.678410530090332
Validation loss: 2.0902035172267626

Epoch: 6| Step: 2
Training loss: 2.13385272026062
Validation loss: 2.1019089452682005

Epoch: 6| Step: 3
Training loss: 2.49697208404541
Validation loss: 2.1273476718574442

Epoch: 6| Step: 4
Training loss: 2.016948699951172
Validation loss: 2.119347454399191

Epoch: 6| Step: 5
Training loss: 2.634816884994507
Validation loss: 2.0973609019351263

Epoch: 6| Step: 6
Training loss: 1.5625735521316528
Validation loss: 2.0562616368775726

Epoch: 6| Step: 7
Training loss: 2.409364700317383
Validation loss: 2.0198520409163607

Epoch: 6| Step: 8
Training loss: 1.8828787803649902
Validation loss: 2.0109482260160547

Epoch: 6| Step: 9
Training loss: 2.4492437839508057
Validation loss: 2.0110024034336047

Epoch: 6| Step: 10
Training loss: 1.9623680114746094
Validation loss: 2.0136075250564085

Epoch: 6| Step: 11
Training loss: 1.6416212320327759
Validation loss: 2.014774645528486

Epoch: 6| Step: 12
Training loss: 3.0387208461761475
Validation loss: 2.0182085473050355

Epoch: 6| Step: 13
Training loss: 2.7542836666107178
Validation loss: 2.0232336059693368

Epoch: 95| Step: 0
Training loss: 2.0262932777404785
Validation loss: 2.0230627790574105

Epoch: 6| Step: 1
Training loss: 2.8494811058044434
Validation loss: 2.0157934568261586

Epoch: 6| Step: 2
Training loss: 2.750608444213867
Validation loss: 2.012416765254031

Epoch: 6| Step: 3
Training loss: 2.499904155731201
Validation loss: 2.010186428664833

Epoch: 6| Step: 4
Training loss: 2.4296765327453613
Validation loss: 2.0078896040557535

Epoch: 6| Step: 5
Training loss: 1.9250200986862183
Validation loss: 2.0043837049955964

Epoch: 6| Step: 6
Training loss: 1.9777766466140747
Validation loss: 2.0140947295773413

Epoch: 6| Step: 7
Training loss: 1.9751672744750977
Validation loss: 2.025289776504681

Epoch: 6| Step: 8
Training loss: 2.1351752281188965
Validation loss: 2.0313074947685323

Epoch: 6| Step: 9
Training loss: 1.931736707687378
Validation loss: 2.0372371750493206

Epoch: 6| Step: 10
Training loss: 1.9127154350280762
Validation loss: 2.0457356924651773

Epoch: 6| Step: 11
Training loss: 2.0301899909973145
Validation loss: 2.0300931827996367

Epoch: 6| Step: 12
Training loss: 2.403669834136963
Validation loss: 2.022683861435101

Epoch: 6| Step: 13
Training loss: 2.4205870628356934
Validation loss: 2.0276576421594106

Epoch: 96| Step: 0
Training loss: 1.3924074172973633
Validation loss: 2.0010233258688324

Epoch: 6| Step: 1
Training loss: 2.3038806915283203
Validation loss: 2.0011259048215804

Epoch: 6| Step: 2
Training loss: 2.707677125930786
Validation loss: 2.0071889943973993

Epoch: 6| Step: 3
Training loss: 2.390669345855713
Validation loss: 2.006773384668494

Epoch: 6| Step: 4
Training loss: 2.3088178634643555
Validation loss: 2.0088027151682044

Epoch: 6| Step: 5
Training loss: 2.484668254852295
Validation loss: 2.0080979588211223

Epoch: 6| Step: 6
Training loss: 2.2930350303649902
Validation loss: 2.0002975002411874

Epoch: 6| Step: 7
Training loss: 1.4082856178283691
Validation loss: 1.995780808951265

Epoch: 6| Step: 8
Training loss: 2.836143970489502
Validation loss: 2.011403032528457

Epoch: 6| Step: 9
Training loss: 2.3765721321105957
Validation loss: 2.04054267175736

Epoch: 6| Step: 10
Training loss: 2.2886481285095215
Validation loss: 2.036622057678879

Epoch: 6| Step: 11
Training loss: 2.4457058906555176
Validation loss: 2.0351980886151715

Epoch: 6| Step: 12
Training loss: 2.2218387126922607
Validation loss: 2.022744758154756

Epoch: 6| Step: 13
Training loss: 1.8016717433929443
Validation loss: 2.0093174083258516

Epoch: 97| Step: 0
Training loss: 1.9574240446090698
Validation loss: 2.00692109523281

Epoch: 6| Step: 1
Training loss: 1.996884822845459
Validation loss: 1.9999618607182656

Epoch: 6| Step: 2
Training loss: 2.5957090854644775
Validation loss: 2.003215032239114

Epoch: 6| Step: 3
Training loss: 2.392693042755127
Validation loss: 2.001717491816449

Epoch: 6| Step: 4
Training loss: 1.9924479722976685
Validation loss: 2.0030366643782584

Epoch: 6| Step: 5
Training loss: 2.236768960952759
Validation loss: 2.011249365345124

Epoch: 6| Step: 6
Training loss: 2.8920114040374756
Validation loss: 2.0062579775369294

Epoch: 6| Step: 7
Training loss: 2.139939546585083
Validation loss: 1.9931059627122776

Epoch: 6| Step: 8
Training loss: 1.8335025310516357
Validation loss: 2.019270496983682

Epoch: 6| Step: 9
Training loss: 2.3606743812561035
Validation loss: 2.022296408171295

Epoch: 6| Step: 10
Training loss: 2.2846524715423584
Validation loss: 2.037738569321171

Epoch: 6| Step: 11
Training loss: 2.6315102577209473
Validation loss: 2.04225827288884

Epoch: 6| Step: 12
Training loss: 1.9201364517211914
Validation loss: 2.066258259998855

Epoch: 6| Step: 13
Training loss: 1.0619219541549683
Validation loss: 2.074448302227964

Epoch: 98| Step: 0
Training loss: 2.703113555908203
Validation loss: 2.0839571952819824

Epoch: 6| Step: 1
Training loss: 2.4610328674316406
Validation loss: 2.0695211707904773

Epoch: 6| Step: 2
Training loss: 2.525546073913574
Validation loss: 2.0428602003282115

Epoch: 6| Step: 3
Training loss: 1.8738170862197876
Validation loss: 2.0398259919176818

Epoch: 6| Step: 4
Training loss: 2.9500694274902344
Validation loss: 2.017630825760544

Epoch: 6| Step: 5
Training loss: 1.8777003288269043
Validation loss: 2.0052371127631075

Epoch: 6| Step: 6
Training loss: 1.540955662727356
Validation loss: 2.005611135113624

Epoch: 6| Step: 7
Training loss: 1.5671874284744263
Validation loss: 2.0197195609410605

Epoch: 6| Step: 8
Training loss: 2.215329170227051
Validation loss: 2.032736482158784

Epoch: 6| Step: 9
Training loss: 2.0988943576812744
Validation loss: 2.029490029940041

Epoch: 6| Step: 10
Training loss: 3.3114304542541504
Validation loss: 2.031721866259011

Epoch: 6| Step: 11
Training loss: 1.9825494289398193
Validation loss: 2.02729300016998

Epoch: 6| Step: 12
Training loss: 2.1944165229797363
Validation loss: 2.0231349429776593

Epoch: 6| Step: 13
Training loss: 1.2454026937484741
Validation loss: 2.0251713439982426

Epoch: 99| Step: 0
Training loss: 2.9284181594848633
Validation loss: 2.0194006466096446

Epoch: 6| Step: 1
Training loss: 2.2098617553710938
Validation loss: 2.015800106909967

Epoch: 6| Step: 2
Training loss: 2.680408000946045
Validation loss: 2.012899991004698

Epoch: 6| Step: 3
Training loss: 1.7147027254104614
Validation loss: 2.0030136646762973

Epoch: 6| Step: 4
Training loss: 3.0690550804138184
Validation loss: 2.006771129946555

Epoch: 6| Step: 5
Training loss: 1.9791351556777954
Validation loss: 1.9991482765443864

Epoch: 6| Step: 6
Training loss: 2.714308500289917
Validation loss: 2.0023412473740114

Epoch: 6| Step: 7
Training loss: 1.8627440929412842
Validation loss: 1.986447234307566

Epoch: 6| Step: 8
Training loss: 1.7546441555023193
Validation loss: 1.9901371886653285

Epoch: 6| Step: 9
Training loss: 1.4797762632369995
Validation loss: 2.0092592675198793

Epoch: 6| Step: 10
Training loss: 2.5801455974578857
Validation loss: 2.0141736640725085

Epoch: 6| Step: 11
Training loss: 1.8354674577713013
Validation loss: 2.024448897248955

Epoch: 6| Step: 12
Training loss: 1.2083110809326172
Validation loss: 2.02784485970774

Epoch: 6| Step: 13
Training loss: 3.330307960510254
Validation loss: 2.035742385413057

Epoch: 100| Step: 0
Training loss: 2.582324504852295
Validation loss: 2.0401117058210474

Epoch: 6| Step: 1
Training loss: 1.6459248065948486
Validation loss: 2.0426125654610257

Epoch: 6| Step: 2
Training loss: 1.8590002059936523
Validation loss: 2.0352821273188435

Epoch: 6| Step: 3
Training loss: 1.5704150199890137
Validation loss: 2.036279175871162

Epoch: 6| Step: 4
Training loss: 2.3210062980651855
Validation loss: 2.0243917844628774

Epoch: 6| Step: 5
Training loss: 2.2299036979675293
Validation loss: 2.0462910167632566

Epoch: 6| Step: 6
Training loss: 2.036520481109619
Validation loss: 2.0746784197386874

Epoch: 6| Step: 7
Training loss: 2.4688222408294678
Validation loss: 2.069595739405642

Epoch: 6| Step: 8
Training loss: 2.7013745307922363
Validation loss: 2.084782426075269

Epoch: 6| Step: 9
Training loss: 2.1918411254882812
Validation loss: 2.077760506701726

Epoch: 6| Step: 10
Training loss: 2.5810651779174805
Validation loss: 2.0721923933234265

Epoch: 6| Step: 11
Training loss: 2.3371195793151855
Validation loss: 2.0573841910208426

Epoch: 6| Step: 12
Training loss: 1.9172637462615967
Validation loss: 2.0454322522686375

Epoch: 6| Step: 13
Training loss: 2.781747341156006
Validation loss: 2.0262423228192072

Epoch: 101| Step: 0
Training loss: 2.970306873321533
Validation loss: 2.012892976883919

Epoch: 6| Step: 1
Training loss: 1.9126803874969482
Validation loss: 2.0084849403750513

Epoch: 6| Step: 2
Training loss: 1.9818873405456543
Validation loss: 2.006844057831713

Epoch: 6| Step: 3
Training loss: 2.3879079818725586
Validation loss: 2.008059372184097

Epoch: 6| Step: 4
Training loss: 2.3679590225219727
Validation loss: 2.007820362685829

Epoch: 6| Step: 5
Training loss: 1.6514337062835693
Validation loss: 2.0063595182152203

Epoch: 6| Step: 6
Training loss: 2.2132925987243652
Validation loss: 2.018316966231151

Epoch: 6| Step: 7
Training loss: 2.247680187225342
Validation loss: 2.0136656889351467

Epoch: 6| Step: 8
Training loss: 2.4966135025024414
Validation loss: 2.0095600158937517

Epoch: 6| Step: 9
Training loss: 2.446690082550049
Validation loss: 2.005281768819337

Epoch: 6| Step: 10
Training loss: 2.28556489944458
Validation loss: 2.008527919810305

Epoch: 6| Step: 11
Training loss: 1.5796129703521729
Validation loss: 2.0104976264379357

Epoch: 6| Step: 12
Training loss: 2.0826101303100586
Validation loss: 2.0130868624615412

Epoch: 6| Step: 13
Training loss: 1.7494664192199707
Validation loss: 2.0053638130105953

Epoch: 102| Step: 0
Training loss: 2.247661590576172
Validation loss: 2.012321505495297

Epoch: 6| Step: 1
Training loss: 2.332960844039917
Validation loss: 2.0132770371693436

Epoch: 6| Step: 2
Training loss: 2.0894393920898438
Validation loss: 2.0102834791265507

Epoch: 6| Step: 3
Training loss: 2.305323600769043
Validation loss: 2.0170377659541305

Epoch: 6| Step: 4
Training loss: 2.7643790245056152
Validation loss: 2.020628703537808

Epoch: 6| Step: 5
Training loss: 1.877660870552063
Validation loss: 2.003507585935695

Epoch: 6| Step: 6
Training loss: 2.0088653564453125
Validation loss: 2.012335333772885

Epoch: 6| Step: 7
Training loss: 2.609578847885132
Validation loss: 2.017212665209206

Epoch: 6| Step: 8
Training loss: 2.345304489135742
Validation loss: 2.016792671654814

Epoch: 6| Step: 9
Training loss: 1.5956473350524902
Validation loss: 2.0134331231476157

Epoch: 6| Step: 10
Training loss: 2.236672878265381
Validation loss: 2.0113821503936604

Epoch: 6| Step: 11
Training loss: 2.0273208618164062
Validation loss: 2.016057232374786

Epoch: 6| Step: 12
Training loss: 1.7926113605499268
Validation loss: 2.036490692887255

Epoch: 6| Step: 13
Training loss: 2.0972745418548584
Validation loss: 2.040011618726997

Epoch: 103| Step: 0
Training loss: 2.3176169395446777
Validation loss: 2.051101848643313

Epoch: 6| Step: 1
Training loss: 2.336531639099121
Validation loss: 2.0547698979736655

Epoch: 6| Step: 2
Training loss: 2.6501214504241943
Validation loss: 2.0680839938502156

Epoch: 6| Step: 3
Training loss: 2.171984910964966
Validation loss: 2.094934509646508

Epoch: 6| Step: 4
Training loss: 1.4434208869934082
Validation loss: 2.1013855523960565

Epoch: 6| Step: 5
Training loss: 2.004514217376709
Validation loss: 2.118962126393472

Epoch: 6| Step: 6
Training loss: 2.1082472801208496
Validation loss: 2.1326199449518675

Epoch: 6| Step: 7
Training loss: 2.9834144115448
Validation loss: 2.1390086130429338

Epoch: 6| Step: 8
Training loss: 2.2317519187927246
Validation loss: 2.14145799093349

Epoch: 6| Step: 9
Training loss: 2.0701019763946533
Validation loss: 2.1299714067930817

Epoch: 6| Step: 10
Training loss: 2.142942190170288
Validation loss: 2.090423608338961

Epoch: 6| Step: 11
Training loss: 2.081389904022217
Validation loss: 2.0506750319593694

Epoch: 6| Step: 12
Training loss: 2.1837897300720215
Validation loss: 2.0330844489477014

Epoch: 6| Step: 13
Training loss: 2.3870561122894287
Validation loss: 2.0785892804463706

Epoch: 104| Step: 0
Training loss: 1.9585416316986084
Validation loss: 2.0765489121919036

Epoch: 6| Step: 1
Training loss: 2.2505807876586914
Validation loss: 2.078283066390663

Epoch: 6| Step: 2
Training loss: 2.105412006378174
Validation loss: 2.0545969983582855

Epoch: 6| Step: 3
Training loss: 2.8051090240478516
Validation loss: 2.0305810513034945

Epoch: 6| Step: 4
Training loss: 2.000972270965576
Validation loss: 2.0243895976774153

Epoch: 6| Step: 5
Training loss: 2.8016562461853027
Validation loss: 2.015256012639692

Epoch: 6| Step: 6
Training loss: 2.123635768890381
Validation loss: 2.0194316628158733

Epoch: 6| Step: 7
Training loss: 1.9449787139892578
Validation loss: 2.033133381156511

Epoch: 6| Step: 8
Training loss: 1.342116117477417
Validation loss: 2.038433397969892

Epoch: 6| Step: 9
Training loss: 2.3262391090393066
Validation loss: 2.0421097586231847

Epoch: 6| Step: 10
Training loss: 2.275298833847046
Validation loss: 2.0486304542069793

Epoch: 6| Step: 11
Training loss: 2.8693838119506836
Validation loss: 2.036754976036728

Epoch: 6| Step: 12
Training loss: 1.9922256469726562
Validation loss: 2.044525058038773

Epoch: 6| Step: 13
Training loss: 1.5156407356262207
Validation loss: 2.0370088469597603

Epoch: 105| Step: 0
Training loss: 2.1052157878875732
Validation loss: 2.0415947642377628

Epoch: 6| Step: 1
Training loss: 2.3721680641174316
Validation loss: 2.0446234544118247

Epoch: 6| Step: 2
Training loss: 2.921844959259033
Validation loss: 2.034598345397621

Epoch: 6| Step: 3
Training loss: 1.79562509059906
Validation loss: 2.0396232733162503

Epoch: 6| Step: 4
Training loss: 1.7542022466659546
Validation loss: 2.0544947321696947

Epoch: 6| Step: 5
Training loss: 2.216104030609131
Validation loss: 2.056510735583562

Epoch: 6| Step: 6
Training loss: 1.8489404916763306
Validation loss: 2.0382087358864407

Epoch: 6| Step: 7
Training loss: 2.6915738582611084
Validation loss: 2.0353354125894527

Epoch: 6| Step: 8
Training loss: 2.5895183086395264
Validation loss: 2.0208327590778308

Epoch: 6| Step: 9
Training loss: 2.1149988174438477
Validation loss: 2.0215149194963518

Epoch: 6| Step: 10
Training loss: 2.2959799766540527
Validation loss: 2.0318582801408667

Epoch: 6| Step: 11
Training loss: 1.8463103771209717
Validation loss: 2.0344499054775445

Epoch: 6| Step: 12
Training loss: 1.7769256830215454
Validation loss: 2.0479212601979575

Epoch: 6| Step: 13
Training loss: 1.843436360359192
Validation loss: 2.0529177317055325

Epoch: 106| Step: 0
Training loss: 2.0254998207092285
Validation loss: 2.0854358237276793

Epoch: 6| Step: 1
Training loss: 2.0479729175567627
Validation loss: 2.1056564161854405

Epoch: 6| Step: 2
Training loss: 1.8781824111938477
Validation loss: 2.0931492928535707

Epoch: 6| Step: 3
Training loss: 2.4686756134033203
Validation loss: 2.1071002867914017

Epoch: 6| Step: 4
Training loss: 2.2726171016693115
Validation loss: 2.1037461450023036

Epoch: 6| Step: 5
Training loss: 2.0015792846679688
Validation loss: 2.1184143814989316

Epoch: 6| Step: 6
Training loss: 1.9129871129989624
Validation loss: 2.1408657027829077

Epoch: 6| Step: 7
Training loss: 2.235408067703247
Validation loss: 2.1441536693162817

Epoch: 6| Step: 8
Training loss: 2.2997376918792725
Validation loss: 2.111006147118025

Epoch: 6| Step: 9
Training loss: 1.9539124965667725
Validation loss: 2.079957035280043

Epoch: 6| Step: 10
Training loss: 2.3830971717834473
Validation loss: 2.039132754007975

Epoch: 6| Step: 11
Training loss: 1.8889129161834717
Validation loss: 2.0295611607131137

Epoch: 6| Step: 12
Training loss: 2.3468923568725586
Validation loss: 2.050168014341785

Epoch: 6| Step: 13
Training loss: 2.488736152648926
Validation loss: 2.07981764629323

Epoch: 107| Step: 0
Training loss: 2.338019371032715
Validation loss: 2.1224925466763076

Epoch: 6| Step: 1
Training loss: 2.6240296363830566
Validation loss: 2.1476673464621268

Epoch: 6| Step: 2
Training loss: 3.0587196350097656
Validation loss: 2.156768883428266

Epoch: 6| Step: 3
Training loss: 2.1461753845214844
Validation loss: 2.111699470909693

Epoch: 6| Step: 4
Training loss: 2.559438705444336
Validation loss: 2.089626236628461

Epoch: 6| Step: 5
Training loss: 1.6583166122436523
Validation loss: 2.0486276739387104

Epoch: 6| Step: 6
Training loss: 1.4399359226226807
Validation loss: 2.027164947602057

Epoch: 6| Step: 7
Training loss: 2.1545135974884033
Validation loss: 2.0300608527275825

Epoch: 6| Step: 8
Training loss: 2.3080496788024902
Validation loss: 2.020520458939255

Epoch: 6| Step: 9
Training loss: 2.123019218444824
Validation loss: 2.0129388096512004

Epoch: 6| Step: 10
Training loss: 2.79608154296875
Validation loss: 2.0317836448710453

Epoch: 6| Step: 11
Training loss: 1.659070611000061
Validation loss: 2.040334615656125

Epoch: 6| Step: 12
Training loss: 2.2339327335357666
Validation loss: 2.0513027791054017

Epoch: 6| Step: 13
Training loss: 2.4943575859069824
Validation loss: 2.0687409703449537

Epoch: 108| Step: 0
Training loss: 2.4074161052703857
Validation loss: 2.0841155975095687

Epoch: 6| Step: 1
Training loss: 2.1988656520843506
Validation loss: 2.1068478104888753

Epoch: 6| Step: 2
Training loss: 2.634969472885132
Validation loss: 2.088682319528313

Epoch: 6| Step: 3
Training loss: 1.9180105924606323
Validation loss: 2.086865109782065

Epoch: 6| Step: 4
Training loss: 1.7053840160369873
Validation loss: 2.0662063501214467

Epoch: 6| Step: 5
Training loss: 2.209831953048706
Validation loss: 2.076367634598927

Epoch: 6| Step: 6
Training loss: 1.6586754322052002
Validation loss: 2.0840921953160274

Epoch: 6| Step: 7
Training loss: 1.731210470199585
Validation loss: 2.114171343465005

Epoch: 6| Step: 8
Training loss: 2.227430582046509
Validation loss: 2.1208556147031885

Epoch: 6| Step: 9
Training loss: 2.165165424346924
Validation loss: 2.1363565716692197

Epoch: 6| Step: 10
Training loss: 2.6625735759735107
Validation loss: 2.1051142164455947

Epoch: 6| Step: 11
Training loss: 2.131101608276367
Validation loss: 2.07705948686087

Epoch: 6| Step: 12
Training loss: 2.624053478240967
Validation loss: 2.052636178590918

Epoch: 6| Step: 13
Training loss: 2.6946771144866943
Validation loss: 2.0465466745438112

Epoch: 109| Step: 0
Training loss: 2.3110861778259277
Validation loss: 2.052656550561228

Epoch: 6| Step: 1
Training loss: 2.8371410369873047
Validation loss: 2.029051375645463

Epoch: 6| Step: 2
Training loss: 2.7663187980651855
Validation loss: 2.015873330895619

Epoch: 6| Step: 3
Training loss: 2.2146382331848145
Validation loss: 2.0327454126009377

Epoch: 6| Step: 4
Training loss: 2.255441665649414
Validation loss: 2.0150939354332547

Epoch: 6| Step: 5
Training loss: 2.4174602031707764
Validation loss: 2.018772940481863

Epoch: 6| Step: 6
Training loss: 1.6885968446731567
Validation loss: 2.019714199086671

Epoch: 6| Step: 7
Training loss: 1.9753570556640625
Validation loss: 2.0313564039045766

Epoch: 6| Step: 8
Training loss: 1.8320116996765137
Validation loss: 2.0273435295269056

Epoch: 6| Step: 9
Training loss: 2.0158495903015137
Validation loss: 2.037607603175666

Epoch: 6| Step: 10
Training loss: 1.9519026279449463
Validation loss: 2.0362551917311964

Epoch: 6| Step: 11
Training loss: 2.3353400230407715
Validation loss: 2.0510375986817064

Epoch: 6| Step: 12
Training loss: 1.6240671873092651
Validation loss: 2.0451471139025945

Epoch: 6| Step: 13
Training loss: 1.5689702033996582
Validation loss: 2.0553712332120506

Epoch: 110| Step: 0
Training loss: 2.3810534477233887
Validation loss: 2.0656821573934248

Epoch: 6| Step: 1
Training loss: 1.3695182800292969
Validation loss: 2.0988386279793194

Epoch: 6| Step: 2
Training loss: 1.8327131271362305
Validation loss: 2.106607434570148

Epoch: 6| Step: 3
Training loss: 2.77242374420166
Validation loss: 2.1279077683725665

Epoch: 6| Step: 4
Training loss: 2.684016466140747
Validation loss: 2.11241029923962

Epoch: 6| Step: 5
Training loss: 2.3070855140686035
Validation loss: 2.101230998193064

Epoch: 6| Step: 6
Training loss: 2.4431777000427246
Validation loss: 2.101881436122361

Epoch: 6| Step: 7
Training loss: 1.8661584854125977
Validation loss: 2.0878431104844615

Epoch: 6| Step: 8
Training loss: 1.347714900970459
Validation loss: 2.0838501376490437

Epoch: 6| Step: 9
Training loss: 1.8709425926208496
Validation loss: 2.0647377865288847

Epoch: 6| Step: 10
Training loss: 2.4384799003601074
Validation loss: 2.0683148368712394

Epoch: 6| Step: 11
Training loss: 2.426823616027832
Validation loss: 2.079813298358712

Epoch: 6| Step: 12
Training loss: 2.0099434852600098
Validation loss: 2.089413289100893

Epoch: 6| Step: 13
Training loss: 2.1351988315582275
Validation loss: 2.0929439426750265

Epoch: 111| Step: 0
Training loss: 2.34334659576416
Validation loss: 2.1010355129036853

Epoch: 6| Step: 1
Training loss: 1.6534724235534668
Validation loss: 2.096547818952991

Epoch: 6| Step: 2
Training loss: 2.1034722328186035
Validation loss: 2.075923050603559

Epoch: 6| Step: 3
Training loss: 2.4713892936706543
Validation loss: 2.0770237048467

Epoch: 6| Step: 4
Training loss: 2.5392680168151855
Validation loss: 2.0547636939633276

Epoch: 6| Step: 5
Training loss: 2.0777652263641357
Validation loss: 2.069686963994016

Epoch: 6| Step: 6
Training loss: 2.307497024536133
Validation loss: 2.049431916206114

Epoch: 6| Step: 7
Training loss: 2.2726056575775146
Validation loss: 2.035976545785063

Epoch: 6| Step: 8
Training loss: 1.9673631191253662
Validation loss: 2.01681334998018

Epoch: 6| Step: 9
Training loss: 1.3009635210037231
Validation loss: 2.0098355764983804

Epoch: 6| Step: 10
Training loss: 2.1002492904663086
Validation loss: 2.0039448661188923

Epoch: 6| Step: 11
Training loss: 2.6446123123168945
Validation loss: 1.9907419399548603

Epoch: 6| Step: 12
Training loss: 1.945633053779602
Validation loss: 1.9997095087523102

Epoch: 6| Step: 13
Training loss: 1.9953901767730713
Validation loss: 1.997491576338327

Epoch: 112| Step: 0
Training loss: 2.0159945487976074
Validation loss: 1.9970432891640613

Epoch: 6| Step: 1
Training loss: 2.6120405197143555
Validation loss: 2.0046282493939964

Epoch: 6| Step: 2
Training loss: 1.4886889457702637
Validation loss: 1.9991358287872807

Epoch: 6| Step: 3
Training loss: 2.3090171813964844
Validation loss: 2.010735119542768

Epoch: 6| Step: 4
Training loss: 2.09060001373291
Validation loss: 2.0155645288446897

Epoch: 6| Step: 5
Training loss: 2.9619269371032715
Validation loss: 2.0126578987285657

Epoch: 6| Step: 6
Training loss: 2.000621795654297
Validation loss: 2.0134368981084516

Epoch: 6| Step: 7
Training loss: 2.402845859527588
Validation loss: 2.02920542224761

Epoch: 6| Step: 8
Training loss: 1.968790054321289
Validation loss: 2.031192156576341

Epoch: 6| Step: 9
Training loss: 1.6642301082611084
Validation loss: 2.0339002737434964

Epoch: 6| Step: 10
Training loss: 1.778287649154663
Validation loss: 2.0417337238147693

Epoch: 6| Step: 11
Training loss: 1.7926121950149536
Validation loss: 2.0535142319176787

Epoch: 6| Step: 12
Training loss: 1.8488212823867798
Validation loss: 2.067609597277898

Epoch: 6| Step: 13
Training loss: 2.8888444900512695
Validation loss: 2.068861751146214

Epoch: 113| Step: 0
Training loss: 2.472789764404297
Validation loss: 2.075388054693899

Epoch: 6| Step: 1
Training loss: 1.670028567314148
Validation loss: 2.1063649808206866

Epoch: 6| Step: 2
Training loss: 1.8787938356399536
Validation loss: 2.145691156387329

Epoch: 6| Step: 3
Training loss: 2.631899118423462
Validation loss: 2.1647774698913738

Epoch: 6| Step: 4
Training loss: 1.5545897483825684
Validation loss: 2.2097559052128948

Epoch: 6| Step: 5
Training loss: 2.8251991271972656
Validation loss: 2.2128283336598384

Epoch: 6| Step: 6
Training loss: 2.7755000591278076
Validation loss: 2.1793486072171118

Epoch: 6| Step: 7
Training loss: 2.0403103828430176
Validation loss: 2.1514829589474584

Epoch: 6| Step: 8
Training loss: 1.2797942161560059
Validation loss: 2.144084648419452

Epoch: 6| Step: 9
Training loss: 1.9733967781066895
Validation loss: 2.1059401548036965

Epoch: 6| Step: 10
Training loss: 2.301252603530884
Validation loss: 2.10919701796706

Epoch: 6| Step: 11
Training loss: 2.284928321838379
Validation loss: 2.0955253903583815

Epoch: 6| Step: 12
Training loss: 1.691097617149353
Validation loss: 2.0559050806107058

Epoch: 6| Step: 13
Training loss: 2.3834357261657715
Validation loss: 2.0444035735181583

Epoch: 114| Step: 0
Training loss: 2.4366977214813232
Validation loss: 2.0202573371189896

Epoch: 6| Step: 1
Training loss: 1.1665737628936768
Validation loss: 2.028508027394613

Epoch: 6| Step: 2
Training loss: 1.9923746585845947
Validation loss: 2.0284135880008822

Epoch: 6| Step: 3
Training loss: 2.7273714542388916
Validation loss: 2.0334739492785547

Epoch: 6| Step: 4
Training loss: 2.3482794761657715
Validation loss: 2.032712403164115

Epoch: 6| Step: 5
Training loss: 2.3345305919647217
Validation loss: 2.042297799100158

Epoch: 6| Step: 6
Training loss: 2.2170631885528564
Validation loss: 2.028815564288888

Epoch: 6| Step: 7
Training loss: 1.6076470613479614
Validation loss: 2.0367058784730974

Epoch: 6| Step: 8
Training loss: 2.235464334487915
Validation loss: 2.0343178677302536

Epoch: 6| Step: 9
Training loss: 1.7000579833984375
Validation loss: 2.0482646880611295

Epoch: 6| Step: 10
Training loss: 2.0147063732147217
Validation loss: 2.069545915049891

Epoch: 6| Step: 11
Training loss: 2.4799771308898926
Validation loss: 2.0621556312807146

Epoch: 6| Step: 12
Training loss: 2.026827096939087
Validation loss: 2.0716106148176294

Epoch: 6| Step: 13
Training loss: 2.5386106967926025
Validation loss: 2.0797690755577496

Epoch: 115| Step: 0
Training loss: 1.4262139797210693
Validation loss: 2.0800943643816057

Epoch: 6| Step: 1
Training loss: 2.753356456756592
Validation loss: 2.100577680013513

Epoch: 6| Step: 2
Training loss: 2.1212291717529297
Validation loss: 2.113156013591315

Epoch: 6| Step: 3
Training loss: 2.0914950370788574
Validation loss: 2.1110935749546176

Epoch: 6| Step: 4
Training loss: 3.188107967376709
Validation loss: 2.086197304469283

Epoch: 6| Step: 5
Training loss: 1.7569477558135986
Validation loss: 2.0654903560556392

Epoch: 6| Step: 6
Training loss: 2.2140583992004395
Validation loss: 2.060004472732544

Epoch: 6| Step: 7
Training loss: 1.5300209522247314
Validation loss: 2.0388974476886053

Epoch: 6| Step: 8
Training loss: 2.235720634460449
Validation loss: 2.0555166967453493

Epoch: 6| Step: 9
Training loss: 1.6316442489624023
Validation loss: 2.0707852891696397

Epoch: 6| Step: 10
Training loss: 2.2410449981689453
Validation loss: 2.103470520306659

Epoch: 6| Step: 11
Training loss: 1.8221135139465332
Validation loss: 2.1287623169601604

Epoch: 6| Step: 12
Training loss: 2.577664613723755
Validation loss: 2.1626115588731665

Epoch: 6| Step: 13
Training loss: 1.5281050205230713
Validation loss: 2.1819739328917636

Epoch: 116| Step: 0
Training loss: 1.764869213104248
Validation loss: 2.1982982056115263

Epoch: 6| Step: 1
Training loss: 1.7238940000534058
Validation loss: 2.210304797336619

Epoch: 6| Step: 2
Training loss: 2.223811626434326
Validation loss: 2.210454120430895

Epoch: 6| Step: 3
Training loss: 2.1584548950195312
Validation loss: 2.19601152020116

Epoch: 6| Step: 4
Training loss: 1.919244647026062
Validation loss: 2.2059391672893236

Epoch: 6| Step: 5
Training loss: 2.3217263221740723
Validation loss: 2.2058860371189732

Epoch: 6| Step: 6
Training loss: 2.427797317504883
Validation loss: 2.203605303200342

Epoch: 6| Step: 7
Training loss: 1.9158083200454712
Validation loss: 2.1674166058981292

Epoch: 6| Step: 8
Training loss: 2.4623045921325684
Validation loss: 2.1221400255798013

Epoch: 6| Step: 9
Training loss: 2.193636894226074
Validation loss: 2.0856683869515695

Epoch: 6| Step: 10
Training loss: 2.319875478744507
Validation loss: 2.0490698058118104

Epoch: 6| Step: 11
Training loss: 2.444113254547119
Validation loss: 2.047921208925145

Epoch: 6| Step: 12
Training loss: 1.978261947631836
Validation loss: 2.0609819889068604

Epoch: 6| Step: 13
Training loss: 2.0019900798797607
Validation loss: 2.0758255220228627

Epoch: 117| Step: 0
Training loss: 2.29870343208313
Validation loss: 2.0815134407371603

Epoch: 6| Step: 1
Training loss: 1.7431817054748535
Validation loss: 2.1098261340971916

Epoch: 6| Step: 2
Training loss: 1.9430146217346191
Validation loss: 2.1116003605627243

Epoch: 6| Step: 3
Training loss: 2.099759578704834
Validation loss: 2.0921926049775976

Epoch: 6| Step: 4
Training loss: 2.4553427696228027
Validation loss: 2.0868476436984156

Epoch: 6| Step: 5
Training loss: 1.4235074520111084
Validation loss: 2.0512945805826495

Epoch: 6| Step: 6
Training loss: 1.5979456901550293
Validation loss: 2.0650211944374988

Epoch: 6| Step: 7
Training loss: 2.3531641960144043
Validation loss: 2.108361665920545

Epoch: 6| Step: 8
Training loss: 1.5808706283569336
Validation loss: 2.1187233886411114

Epoch: 6| Step: 9
Training loss: 2.5309596061706543
Validation loss: 2.122281127078559

Epoch: 6| Step: 10
Training loss: 2.562366485595703
Validation loss: 2.1372494364297516

Epoch: 6| Step: 11
Training loss: 2.0886855125427246
Validation loss: 2.135040403694235

Epoch: 6| Step: 12
Training loss: 2.457472562789917
Validation loss: 2.150287566646453

Epoch: 6| Step: 13
Training loss: 2.6976704597473145
Validation loss: 2.15901534018978

Epoch: 118| Step: 0
Training loss: 1.4294153451919556
Validation loss: 2.1391364707741687

Epoch: 6| Step: 1
Training loss: 2.4345498085021973
Validation loss: 2.1343925691420034

Epoch: 6| Step: 2
Training loss: 1.352694034576416
Validation loss: 2.136154379895938

Epoch: 6| Step: 3
Training loss: 1.576284646987915
Validation loss: 2.141181489472748

Epoch: 6| Step: 4
Training loss: 2.55570125579834
Validation loss: 2.1468777861646426

Epoch: 6| Step: 5
Training loss: 3.1712164878845215
Validation loss: 2.135491519845942

Epoch: 6| Step: 6
Training loss: 1.5820262432098389
Validation loss: 2.117049506915513

Epoch: 6| Step: 7
Training loss: 3.028191089630127
Validation loss: 2.106350221941548

Epoch: 6| Step: 8
Training loss: 1.0609593391418457
Validation loss: 2.097532859412573

Epoch: 6| Step: 9
Training loss: 2.384492874145508
Validation loss: 2.0821146644571775

Epoch: 6| Step: 10
Training loss: 2.7904913425445557
Validation loss: 2.0695968161347094

Epoch: 6| Step: 11
Training loss: 1.4338631629943848
Validation loss: 2.0754840758539017

Epoch: 6| Step: 12
Training loss: 1.9294590950012207
Validation loss: 2.0717137013712237

Epoch: 6| Step: 13
Training loss: 2.02506685256958
Validation loss: 2.0522647416719826

Epoch: 119| Step: 0
Training loss: 1.8187482357025146
Validation loss: 2.0493122980158818

Epoch: 6| Step: 1
Training loss: 1.4708247184753418
Validation loss: 2.0425767026921755

Epoch: 6| Step: 2
Training loss: 2.1792047023773193
Validation loss: 2.0440740816054808

Epoch: 6| Step: 3
Training loss: 1.9385327100753784
Validation loss: 2.0382195800863285

Epoch: 6| Step: 4
Training loss: 1.6577892303466797
Validation loss: 2.0651734426457393

Epoch: 6| Step: 5
Training loss: 1.672461748123169
Validation loss: 2.0688879130988993

Epoch: 6| Step: 6
Training loss: 2.310720920562744
Validation loss: 2.0850209754000426

Epoch: 6| Step: 7
Training loss: 1.6102056503295898
Validation loss: 2.1212807099024453

Epoch: 6| Step: 8
Training loss: 2.508903980255127
Validation loss: 2.1384786739144275

Epoch: 6| Step: 9
Training loss: 2.61665678024292
Validation loss: 2.1481222170655445

Epoch: 6| Step: 10
Training loss: 2.5474965572357178
Validation loss: 2.1357879074670936

Epoch: 6| Step: 11
Training loss: 2.3553590774536133
Validation loss: 2.1036854251738517

Epoch: 6| Step: 12
Training loss: 1.8096424341201782
Validation loss: 2.0798834805847495

Epoch: 6| Step: 13
Training loss: 2.5659961700439453
Validation loss: 2.0698620029675063

Epoch: 120| Step: 0
Training loss: 2.187044143676758
Validation loss: 2.0694330584618355

Epoch: 6| Step: 1
Training loss: 2.302917003631592
Validation loss: 2.086436892068514

Epoch: 6| Step: 2
Training loss: 2.5303988456726074
Validation loss: 2.087128313638831

Epoch: 6| Step: 3
Training loss: 1.770843505859375
Validation loss: 2.1100761659683718

Epoch: 6| Step: 4
Training loss: 2.857527256011963
Validation loss: 2.126746468646552

Epoch: 6| Step: 5
Training loss: 1.5162365436553955
Validation loss: 2.139889596610941

Epoch: 6| Step: 6
Training loss: 1.6093192100524902
Validation loss: 2.19079077628351

Epoch: 6| Step: 7
Training loss: 2.6274023056030273
Validation loss: 2.2017766993532897

Epoch: 6| Step: 8
Training loss: 1.7202427387237549
Validation loss: 2.1884284173288653

Epoch: 6| Step: 9
Training loss: 2.356142044067383
Validation loss: 2.158284310371645

Epoch: 6| Step: 10
Training loss: 1.9832333326339722
Validation loss: 2.132123854852492

Epoch: 6| Step: 11
Training loss: 2.1986446380615234
Validation loss: 2.098587130987516

Epoch: 6| Step: 12
Training loss: 2.4657931327819824
Validation loss: 2.0817089644811486

Epoch: 6| Step: 13
Training loss: 2.1265907287597656
Validation loss: 2.079704442331868

Epoch: 121| Step: 0
Training loss: 2.1304514408111572
Validation loss: 2.084726092635944

Epoch: 6| Step: 1
Training loss: 1.6917462348937988
Validation loss: 2.0901801201605026

Epoch: 6| Step: 2
Training loss: 2.009091854095459
Validation loss: 2.0828898901580484

Epoch: 6| Step: 3
Training loss: 2.6318020820617676
Validation loss: 2.056316029640936

Epoch: 6| Step: 4
Training loss: 2.395554542541504
Validation loss: 2.0789521945420133

Epoch: 6| Step: 5
Training loss: 1.6209430694580078
Validation loss: 2.0867806903777586

Epoch: 6| Step: 6
Training loss: 1.8307368755340576
Validation loss: 2.096090180899507

Epoch: 6| Step: 7
Training loss: 2.150477886199951
Validation loss: 2.0793360228179605

Epoch: 6| Step: 8
Training loss: 1.8516316413879395
Validation loss: 2.0598708839826685

Epoch: 6| Step: 9
Training loss: 1.9208648204803467
Validation loss: 2.0676876268079205

Epoch: 6| Step: 10
Training loss: 2.486724376678467
Validation loss: 2.0593996163337462

Epoch: 6| Step: 11
Training loss: 2.657519578933716
Validation loss: 2.055131680221968

Epoch: 6| Step: 12
Training loss: 1.7127807140350342
Validation loss: 2.0563067338799916

Epoch: 6| Step: 13
Training loss: 1.3890448808670044
Validation loss: 2.0558094504059

Epoch: 122| Step: 0
Training loss: 1.7216036319732666
Validation loss: 2.06308659174109

Epoch: 6| Step: 1
Training loss: 2.531527042388916
Validation loss: 2.0686223353109052

Epoch: 6| Step: 2
Training loss: 1.7840876579284668
Validation loss: 2.054686878317146

Epoch: 6| Step: 3
Training loss: 2.004542350769043
Validation loss: 2.081286317558699

Epoch: 6| Step: 4
Training loss: 1.8524885177612305
Validation loss: 2.0811119361590316

Epoch: 6| Step: 5
Training loss: 2.191260814666748
Validation loss: 2.081691450970147

Epoch: 6| Step: 6
Training loss: 1.6214098930358887
Validation loss: 2.0796844574712936

Epoch: 6| Step: 7
Training loss: 1.745806097984314
Validation loss: 2.096778387664467

Epoch: 6| Step: 8
Training loss: 2.4619526863098145
Validation loss: 2.0969416736274638

Epoch: 6| Step: 9
Training loss: 1.6238749027252197
Validation loss: 2.080082719044019

Epoch: 6| Step: 10
Training loss: 2.1583218574523926
Validation loss: 2.102730199854861

Epoch: 6| Step: 11
Training loss: 1.941556453704834
Validation loss: 2.107645350117837

Epoch: 6| Step: 12
Training loss: 2.6146886348724365
Validation loss: 2.089585345278504

Epoch: 6| Step: 13
Training loss: 1.4333670139312744
Validation loss: 2.085681851192187

Epoch: 123| Step: 0
Training loss: 2.2208333015441895
Validation loss: 2.0840725104014077

Epoch: 6| Step: 1
Training loss: 2.005053997039795
Validation loss: 2.0687123562700007

Epoch: 6| Step: 2
Training loss: 1.9581409692764282
Validation loss: 2.065201228664767

Epoch: 6| Step: 3
Training loss: 1.9631049633026123
Validation loss: 2.060475746790568

Epoch: 6| Step: 4
Training loss: 1.582270622253418
Validation loss: 2.060073673084218

Epoch: 6| Step: 5
Training loss: 2.704387664794922
Validation loss: 2.0754908848834295

Epoch: 6| Step: 6
Training loss: 1.6239910125732422
Validation loss: 2.0678270734766477

Epoch: 6| Step: 7
Training loss: 1.410094976425171
Validation loss: 2.0746540869435957

Epoch: 6| Step: 8
Training loss: 1.8691480159759521
Validation loss: 2.074257102063907

Epoch: 6| Step: 9
Training loss: 2.3536458015441895
Validation loss: 2.0804089756422144

Epoch: 6| Step: 10
Training loss: 2.418067216873169
Validation loss: 2.083860360166078

Epoch: 6| Step: 11
Training loss: 1.6517189741134644
Validation loss: 2.1163711112032653

Epoch: 6| Step: 12
Training loss: 1.6732885837554932
Validation loss: 2.0918707322048884

Epoch: 6| Step: 13
Training loss: 2.402665376663208
Validation loss: 2.082439136761491

Epoch: 124| Step: 0
Training loss: 1.6437664031982422
Validation loss: 2.0742165132235457

Epoch: 6| Step: 1
Training loss: 1.9185309410095215
Validation loss: 2.0650539462284376

Epoch: 6| Step: 2
Training loss: 2.743743419647217
Validation loss: 2.06226751881261

Epoch: 6| Step: 3
Training loss: 2.6958963871002197
Validation loss: 2.0853380054555912

Epoch: 6| Step: 4
Training loss: 2.4301586151123047
Validation loss: 2.0682697603779454

Epoch: 6| Step: 5
Training loss: 0.84630286693573
Validation loss: 2.08415731563363

Epoch: 6| Step: 6
Training loss: 1.618598461151123
Validation loss: 2.105902669250324

Epoch: 6| Step: 7
Training loss: 1.2807104587554932
Validation loss: 2.1176012536530853

Epoch: 6| Step: 8
Training loss: 1.6143146753311157
Validation loss: 2.1399907014703237

Epoch: 6| Step: 9
Training loss: 1.9171156883239746
Validation loss: 2.176076635237663

Epoch: 6| Step: 10
Training loss: 2.186824321746826
Validation loss: 2.1737424724845478

Epoch: 6| Step: 11
Training loss: 2.48455548286438
Validation loss: 2.1256760269083004

Epoch: 6| Step: 12
Training loss: 2.2230777740478516
Validation loss: 2.1150309193518853

Epoch: 6| Step: 13
Training loss: 1.9504305124282837
Validation loss: 2.07775741879658

Epoch: 125| Step: 0
Training loss: 1.9140456914901733
Validation loss: 2.0862211155635055

Epoch: 6| Step: 1
Training loss: 1.538414478302002
Validation loss: 2.040089552120496

Epoch: 6| Step: 2
Training loss: 2.4258577823638916
Validation loss: 2.0194786722942064

Epoch: 6| Step: 3
Training loss: 1.915298581123352
Validation loss: 2.027284494010351

Epoch: 6| Step: 4
Training loss: 1.8981420993804932
Validation loss: 2.0389806660272742

Epoch: 6| Step: 5
Training loss: 1.4236384630203247
Validation loss: 2.0317547718683877

Epoch: 6| Step: 6
Training loss: 1.4836745262145996
Validation loss: 2.0500884248364355

Epoch: 6| Step: 7
Training loss: 2.6404809951782227
Validation loss: 2.0468171168399114

Epoch: 6| Step: 8
Training loss: 2.39892578125
Validation loss: 2.0365425566191315

Epoch: 6| Step: 9
Training loss: 2.632812023162842
Validation loss: 2.0423579164730605

Epoch: 6| Step: 10
Training loss: 2.1924428939819336
Validation loss: 2.0485028784762145

Epoch: 6| Step: 11
Training loss: 2.1743359565734863
Validation loss: 2.057920768696775

Epoch: 6| Step: 12
Training loss: 1.6669554710388184
Validation loss: 2.058540246819937

Epoch: 6| Step: 13
Training loss: 2.4857895374298096
Validation loss: 2.087807979635013

Epoch: 126| Step: 0
Training loss: 2.026157855987549
Validation loss: 2.118269774221605

Epoch: 6| Step: 1
Training loss: 1.47869873046875
Validation loss: 2.1167812167957263

Epoch: 6| Step: 2
Training loss: 1.5627672672271729
Validation loss: 2.1034430329517653

Epoch: 6| Step: 3
Training loss: 1.8315802812576294
Validation loss: 2.0929665732127365

Epoch: 6| Step: 4
Training loss: 1.417925477027893
Validation loss: 2.100905486332473

Epoch: 6| Step: 5
Training loss: 1.9870736598968506
Validation loss: 2.107326490904695

Epoch: 6| Step: 6
Training loss: 2.8777453899383545
Validation loss: 2.0943193025486444

Epoch: 6| Step: 7
Training loss: 2.314944267272949
Validation loss: 2.093155325099986

Epoch: 6| Step: 8
Training loss: 1.8168480396270752
Validation loss: 2.086091004392152

Epoch: 6| Step: 9
Training loss: 2.1526880264282227
Validation loss: 2.099536047186903

Epoch: 6| Step: 10
Training loss: 1.8501696586608887
Validation loss: 2.1182990638158654

Epoch: 6| Step: 11
Training loss: 1.9109044075012207
Validation loss: 2.1460985496479976

Epoch: 6| Step: 12
Training loss: 2.254345417022705
Validation loss: 2.1451873817751483

Epoch: 6| Step: 13
Training loss: 2.451247215270996
Validation loss: 2.100101888820689

Epoch: 127| Step: 0
Training loss: 1.761186122894287
Validation loss: 2.110352808429349

Epoch: 6| Step: 1
Training loss: 1.474540114402771
Validation loss: 2.0962161043638825

Epoch: 6| Step: 2
Training loss: 2.332779884338379
Validation loss: 2.0801630891779417

Epoch: 6| Step: 3
Training loss: 1.740551233291626
Validation loss: 2.073158989670456

Epoch: 6| Step: 4
Training loss: 1.8442168235778809
Validation loss: 2.0405306290554743

Epoch: 6| Step: 5
Training loss: 1.2968661785125732
Validation loss: 2.0542073736908617

Epoch: 6| Step: 6
Training loss: 2.1712186336517334
Validation loss: 2.04454198960335

Epoch: 6| Step: 7
Training loss: 1.8451268672943115
Validation loss: 2.0925902448674685

Epoch: 6| Step: 8
Training loss: 2.0664753913879395
Validation loss: 2.148300829754081

Epoch: 6| Step: 9
Training loss: 1.9655177593231201
Validation loss: 2.1644816834439515

Epoch: 6| Step: 10
Training loss: 2.078688144683838
Validation loss: 2.2188946303500923

Epoch: 6| Step: 11
Training loss: 2.545959949493408
Validation loss: 2.2344563776446926

Epoch: 6| Step: 12
Training loss: 2.3118338584899902
Validation loss: 2.1682387141771216

Epoch: 6| Step: 13
Training loss: 2.693260669708252
Validation loss: 2.1090018441600185

Epoch: 128| Step: 0
Training loss: 1.850785255432129
Validation loss: 2.0939461902905534

Epoch: 6| Step: 1
Training loss: 2.247774600982666
Validation loss: 2.097088547163112

Epoch: 6| Step: 2
Training loss: 1.9464044570922852
Validation loss: 2.07886504614225

Epoch: 6| Step: 3
Training loss: 2.2104790210723877
Validation loss: 2.0637605062095066

Epoch: 6| Step: 4
Training loss: 1.887835144996643
Validation loss: 2.0645712767877886

Epoch: 6| Step: 5
Training loss: 1.8416013717651367
Validation loss: 2.031307625514205

Epoch: 6| Step: 6
Training loss: 1.6469275951385498
Validation loss: 2.0621022806372693

Epoch: 6| Step: 7
Training loss: 3.0362656116485596
Validation loss: 2.0593306620915732

Epoch: 6| Step: 8
Training loss: 1.6433100700378418
Validation loss: 2.0569638718840895

Epoch: 6| Step: 9
Training loss: 1.464012622833252
Validation loss: 2.047757779398272

Epoch: 6| Step: 10
Training loss: 2.0426769256591797
Validation loss: 2.047432780265808

Epoch: 6| Step: 11
Training loss: 1.7526135444641113
Validation loss: 2.045351976989418

Epoch: 6| Step: 12
Training loss: 2.174818515777588
Validation loss: 2.0486114883935578

Epoch: 6| Step: 13
Training loss: 1.285912036895752
Validation loss: 2.0543316794979956

Epoch: 129| Step: 0
Training loss: 2.143812894821167
Validation loss: 2.0841758276826594

Epoch: 6| Step: 1
Training loss: 1.6555553674697876
Validation loss: 2.1270998165171635

Epoch: 6| Step: 2
Training loss: 2.5620694160461426
Validation loss: 2.1641219482626965

Epoch: 6| Step: 3
Training loss: 1.3291480541229248
Validation loss: 2.19511233093918

Epoch: 6| Step: 4
Training loss: 1.8085551261901855
Validation loss: 2.195160171037079

Epoch: 6| Step: 5
Training loss: 2.1499533653259277
Validation loss: 2.2003673020229546

Epoch: 6| Step: 6
Training loss: 2.8132734298706055
Validation loss: 2.15877870334092

Epoch: 6| Step: 7
Training loss: 2.0989766120910645
Validation loss: 2.107227084457233

Epoch: 6| Step: 8
Training loss: 1.4305626153945923
Validation loss: 2.0591225034447125

Epoch: 6| Step: 9
Training loss: 1.5406378507614136
Validation loss: 2.0443112516915924

Epoch: 6| Step: 10
Training loss: 1.8557039499282837
Validation loss: 2.037631762925015

Epoch: 6| Step: 11
Training loss: 2.2024171352386475
Validation loss: 2.038837548225157

Epoch: 6| Step: 12
Training loss: 1.8346573114395142
Validation loss: 2.052217150247225

Epoch: 6| Step: 13
Training loss: 1.992798924446106
Validation loss: 2.0764906124402116

Epoch: 130| Step: 0
Training loss: 2.1915335655212402
Validation loss: 2.0858246459755847

Epoch: 6| Step: 1
Training loss: 1.7300001382827759
Validation loss: 2.0926139252160185

Epoch: 6| Step: 2
Training loss: 1.565246343612671
Validation loss: 2.08186597465187

Epoch: 6| Step: 3
Training loss: 1.781062126159668
Validation loss: 2.052877817102658

Epoch: 6| Step: 4
Training loss: 1.8932424783706665
Validation loss: 2.073706549982871

Epoch: 6| Step: 5
Training loss: 1.982658863067627
Validation loss: 2.101261301707196

Epoch: 6| Step: 6
Training loss: 2.3675622940063477
Validation loss: 2.1168741205687165

Epoch: 6| Step: 7
Training loss: 2.851569652557373
Validation loss: 2.1475394246398762

Epoch: 6| Step: 8
Training loss: 1.413743495941162
Validation loss: 2.1545716934306647

Epoch: 6| Step: 9
Training loss: 2.8490021228790283
Validation loss: 2.130664949776024

Epoch: 6| Step: 10
Training loss: 1.2894365787506104
Validation loss: 2.133687401330599

Epoch: 6| Step: 11
Training loss: 2.405090808868408
Validation loss: 2.1118749674930366

Epoch: 6| Step: 12
Training loss: 2.001319646835327
Validation loss: 2.141822034312833

Epoch: 6| Step: 13
Training loss: 2.034348726272583
Validation loss: 2.2005509561108005

Epoch: 131| Step: 0
Training loss: 1.7429835796356201
Validation loss: 2.243348672825803

Epoch: 6| Step: 1
Training loss: 2.1228983402252197
Validation loss: 2.284144829678279

Epoch: 6| Step: 2
Training loss: 2.7605910301208496
Validation loss: 2.3074892182503977

Epoch: 6| Step: 3
Training loss: 2.2992992401123047
Validation loss: 2.240808028046803

Epoch: 6| Step: 4
Training loss: 2.7073121070861816
Validation loss: 2.152867978618991

Epoch: 6| Step: 5
Training loss: 2.042997360229492
Validation loss: 2.09602774471365

Epoch: 6| Step: 6
Training loss: 1.8311326503753662
Validation loss: 2.045121987660726

Epoch: 6| Step: 7
Training loss: 0.8038051724433899
Validation loss: 2.0376992866557133

Epoch: 6| Step: 8
Training loss: 2.3856239318847656
Validation loss: 2.0389919152823825

Epoch: 6| Step: 9
Training loss: 1.7836205959320068
Validation loss: 2.059489737274826

Epoch: 6| Step: 10
Training loss: 2.0227537155151367
Validation loss: 2.054315003015662

Epoch: 6| Step: 11
Training loss: 2.3065176010131836
Validation loss: 2.063368835756856

Epoch: 6| Step: 12
Training loss: 2.2188875675201416
Validation loss: 2.0230082901575233

Epoch: 6| Step: 13
Training loss: 1.9313864707946777
Validation loss: 2.014086300326932

Epoch: 132| Step: 0
Training loss: 1.7910194396972656
Validation loss: 2.0007872786573184

Epoch: 6| Step: 1
Training loss: 1.8616559505462646
Validation loss: 1.992071556788619

Epoch: 6| Step: 2
Training loss: 1.7690258026123047
Validation loss: 2.0107734177702214

Epoch: 6| Step: 3
Training loss: 2.224323272705078
Validation loss: 2.011109398257348

Epoch: 6| Step: 4
Training loss: 1.6543923616409302
Validation loss: 2.028822757864511

Epoch: 6| Step: 5
Training loss: 1.8562792539596558
Validation loss: 2.0422790717053156

Epoch: 6| Step: 6
Training loss: 1.8819961547851562
Validation loss: 2.072961261195521

Epoch: 6| Step: 7
Training loss: 1.5268468856811523
Validation loss: 2.0820668076956146

Epoch: 6| Step: 8
Training loss: 1.6731793880462646
Validation loss: 2.115101122087048

Epoch: 6| Step: 9
Training loss: 2.2375457286834717
Validation loss: 2.1430741997175318

Epoch: 6| Step: 10
Training loss: 2.2863712310791016
Validation loss: 2.1568764537893315

Epoch: 6| Step: 11
Training loss: 2.7621264457702637
Validation loss: 2.1545927806567122

Epoch: 6| Step: 12
Training loss: 2.1233649253845215
Validation loss: 2.1404964334221295

Epoch: 6| Step: 13
Training loss: 2.1277825832366943
Validation loss: 2.133602708898565

Epoch: 133| Step: 0
Training loss: 2.327293872833252
Validation loss: 2.1249134156011764

Epoch: 6| Step: 1
Training loss: 1.7700796127319336
Validation loss: 2.0996071010507564

Epoch: 6| Step: 2
Training loss: 1.6504186391830444
Validation loss: 2.10646346692116

Epoch: 6| Step: 3
Training loss: 2.6675195693969727
Validation loss: 2.1040740910396782

Epoch: 6| Step: 4
Training loss: 1.34824538230896
Validation loss: 2.0982230324898996

Epoch: 6| Step: 5
Training loss: 1.5791873931884766
Validation loss: 2.095419886291668

Epoch: 6| Step: 6
Training loss: 2.141573667526245
Validation loss: 2.09891729329222

Epoch: 6| Step: 7
Training loss: 2.328686475753784
Validation loss: 2.1121515945721696

Epoch: 6| Step: 8
Training loss: 1.5933958292007446
Validation loss: 2.1105736019790813

Epoch: 6| Step: 9
Training loss: 1.8015697002410889
Validation loss: 2.1078834328600156

Epoch: 6| Step: 10
Training loss: 2.2321290969848633
Validation loss: 2.100795525376515

Epoch: 6| Step: 11
Training loss: 1.23732590675354
Validation loss: 2.0797429289869083

Epoch: 6| Step: 12
Training loss: 2.349771499633789
Validation loss: 2.060743829255463

Epoch: 6| Step: 13
Training loss: 1.218963384628296
Validation loss: 2.0444459351160194

Epoch: 134| Step: 0
Training loss: 1.426520824432373
Validation loss: 2.0435405546619045

Epoch: 6| Step: 1
Training loss: 1.8078962564468384
Validation loss: 2.052000254713079

Epoch: 6| Step: 2
Training loss: 2.002359628677368
Validation loss: 2.074136677608695

Epoch: 6| Step: 3
Training loss: 1.5083503723144531
Validation loss: 2.103916734777471

Epoch: 6| Step: 4
Training loss: 1.9027765989303589
Validation loss: 2.1182164966419177

Epoch: 6| Step: 5
Training loss: 2.3764100074768066
Validation loss: 2.1360210526374077

Epoch: 6| Step: 6
Training loss: 1.5392789840698242
Validation loss: 2.141397714614868

Epoch: 6| Step: 7
Training loss: 1.4297643899917603
Validation loss: 2.1141395966211953

Epoch: 6| Step: 8
Training loss: 1.7133249044418335
Validation loss: 2.084793467675486

Epoch: 6| Step: 9
Training loss: 1.5825098752975464
Validation loss: 2.0780540640636156

Epoch: 6| Step: 10
Training loss: 2.3374195098876953
Validation loss: 2.0789594855359805

Epoch: 6| Step: 11
Training loss: 2.1728148460388184
Validation loss: 2.078316028400134

Epoch: 6| Step: 12
Training loss: 2.0345547199249268
Validation loss: 2.063822784731465

Epoch: 6| Step: 13
Training loss: 2.972729206085205
Validation loss: 2.05948503427608

Epoch: 135| Step: 0
Training loss: 1.5953315496444702
Validation loss: 2.052207072575887

Epoch: 6| Step: 1
Training loss: 1.947108507156372
Validation loss: 2.0315892401561944

Epoch: 6| Step: 2
Training loss: 2.3178415298461914
Validation loss: 2.0400400418107227

Epoch: 6| Step: 3
Training loss: 1.9562593698501587
Validation loss: 2.047954951563189

Epoch: 6| Step: 4
Training loss: 1.8184748888015747
Validation loss: 2.050154637264949

Epoch: 6| Step: 5
Training loss: 2.4797468185424805
Validation loss: 2.0673842789024435

Epoch: 6| Step: 6
Training loss: 0.9542865753173828
Validation loss: 2.086507663931898

Epoch: 6| Step: 7
Training loss: 2.2509284019470215
Validation loss: 2.0808402081971527

Epoch: 6| Step: 8
Training loss: 1.4580167531967163
Validation loss: 2.107005501306185

Epoch: 6| Step: 9
Training loss: 1.8396943807601929
Validation loss: 2.136769066574753

Epoch: 6| Step: 10
Training loss: 1.574910283088684
Validation loss: 2.137901859898721

Epoch: 6| Step: 11
Training loss: 2.079662561416626
Validation loss: 2.1544349911392375

Epoch: 6| Step: 12
Training loss: 2.300264358520508
Validation loss: 2.1793353019222135

Epoch: 6| Step: 13
Training loss: 1.4369242191314697
Validation loss: 2.1894896953336653

Epoch: 136| Step: 0
Training loss: 1.6570245027542114
Validation loss: 2.165823418606994

Epoch: 6| Step: 1
Training loss: 1.180482268333435
Validation loss: 2.1421313144827403

Epoch: 6| Step: 2
Training loss: 2.0304088592529297
Validation loss: 2.0951657423409085

Epoch: 6| Step: 3
Training loss: 2.471407651901245
Validation loss: 2.0757308954833658

Epoch: 6| Step: 4
Training loss: 1.7693098783493042
Validation loss: 2.0336131357377574

Epoch: 6| Step: 5
Training loss: 2.5396511554718018
Validation loss: 2.003737611155356

Epoch: 6| Step: 6
Training loss: 1.4360260963439941
Validation loss: 1.9903155578080045

Epoch: 6| Step: 7
Training loss: 2.075955629348755
Validation loss: 1.9982494077374857

Epoch: 6| Step: 8
Training loss: 2.0436294078826904
Validation loss: 1.99553806038313

Epoch: 6| Step: 9
Training loss: 2.186455488204956
Validation loss: 2.00852176579096

Epoch: 6| Step: 10
Training loss: 1.465526819229126
Validation loss: 2.0298079136879212

Epoch: 6| Step: 11
Training loss: 2.4297709465026855
Validation loss: 2.040785335725354

Epoch: 6| Step: 12
Training loss: 1.65128493309021
Validation loss: 2.062691301427862

Epoch: 6| Step: 13
Training loss: 1.9296616315841675
Validation loss: 2.0830011342161443

Epoch: 137| Step: 0
Training loss: 2.691798448562622
Validation loss: 2.1435916936525734

Epoch: 6| Step: 1
Training loss: 2.6897215843200684
Validation loss: 2.1933563524676907

Epoch: 6| Step: 2
Training loss: 1.4958665370941162
Validation loss: 2.191040533845143

Epoch: 6| Step: 3
Training loss: 1.738124132156372
Validation loss: 2.167496637631488

Epoch: 6| Step: 4
Training loss: 1.8846099376678467
Validation loss: 2.127383283389512

Epoch: 6| Step: 5
Training loss: 1.678837537765503
Validation loss: 2.145920240750877

Epoch: 6| Step: 6
Training loss: 2.4462461471557617
Validation loss: 2.1715052486747823

Epoch: 6| Step: 7
Training loss: 1.6256518363952637
Validation loss: 2.1717770791822866

Epoch: 6| Step: 8
Training loss: 1.5109179019927979
Validation loss: 2.1222443952355334

Epoch: 6| Step: 9
Training loss: 2.00141978263855
Validation loss: 2.090154100489873

Epoch: 6| Step: 10
Training loss: 1.5337586402893066
Validation loss: 2.0726015465233916

Epoch: 6| Step: 11
Training loss: 1.479383111000061
Validation loss: 2.0342908687489007

Epoch: 6| Step: 12
Training loss: 1.5311793088912964
Validation loss: 1.996235106581001

Epoch: 6| Step: 13
Training loss: 1.4996585845947266
Validation loss: 1.9803284752753474

Epoch: 138| Step: 0
Training loss: 2.3216114044189453
Validation loss: 1.9613305445640319

Epoch: 6| Step: 1
Training loss: 2.1446499824523926
Validation loss: 1.9665705696229012

Epoch: 6| Step: 2
Training loss: 1.7234251499176025
Validation loss: 1.9630682750414776

Epoch: 6| Step: 3
Training loss: 1.4487638473510742
Validation loss: 1.9608084309485652

Epoch: 6| Step: 4
Training loss: 2.601367950439453
Validation loss: 1.9710526415096816

Epoch: 6| Step: 5
Training loss: 1.520561695098877
Validation loss: 1.9876097876538512

Epoch: 6| Step: 6
Training loss: 2.4072086811065674
Validation loss: 2.003870000121414

Epoch: 6| Step: 7
Training loss: 2.3066110610961914
Validation loss: 2.0061130267317577

Epoch: 6| Step: 8
Training loss: 1.8562372922897339
Validation loss: 2.0213123008769047

Epoch: 6| Step: 9
Training loss: 1.9606304168701172
Validation loss: 2.0195955589253414

Epoch: 6| Step: 10
Training loss: 1.8640854358673096
Validation loss: 2.0237434243643158

Epoch: 6| Step: 11
Training loss: 1.59043550491333
Validation loss: 2.048705034358527

Epoch: 6| Step: 12
Training loss: 1.3978190422058105
Validation loss: 2.0504258063531693

Epoch: 6| Step: 13
Training loss: 1.6332242488861084
Validation loss: 2.0794677221646873

Epoch: 139| Step: 0
Training loss: 1.4090776443481445
Validation loss: 2.0790252839365313

Epoch: 6| Step: 1
Training loss: 2.1583170890808105
Validation loss: 2.099973460679413

Epoch: 6| Step: 2
Training loss: 2.1971311569213867
Validation loss: 2.1006278030333982

Epoch: 6| Step: 3
Training loss: 2.3886337280273438
Validation loss: 2.1260371797828266

Epoch: 6| Step: 4
Training loss: 2.0768866539001465
Validation loss: 2.1396853308523855

Epoch: 6| Step: 5
Training loss: 1.5506114959716797
Validation loss: 2.11689059324162

Epoch: 6| Step: 6
Training loss: 1.8470203876495361
Validation loss: 2.0903996523990425

Epoch: 6| Step: 7
Training loss: 1.626288652420044
Validation loss: 2.0829476797452537

Epoch: 6| Step: 8
Training loss: 1.952431559562683
Validation loss: 2.104556578461842

Epoch: 6| Step: 9
Training loss: 1.491349220275879
Validation loss: 2.1224568966896302

Epoch: 6| Step: 10
Training loss: 2.105006694793701
Validation loss: 2.1355329867332213

Epoch: 6| Step: 11
Training loss: 1.5396537780761719
Validation loss: 2.1353904278047624

Epoch: 6| Step: 12
Training loss: 2.042379140853882
Validation loss: 2.1265895699941986

Epoch: 6| Step: 13
Training loss: 1.9977599382400513
Validation loss: 2.1172479275734193

Epoch: 140| Step: 0
Training loss: 1.8837085962295532
Validation loss: 2.117648381058888

Epoch: 6| Step: 1
Training loss: 2.3324012756347656
Validation loss: 2.11763419130797

Epoch: 6| Step: 2
Training loss: 1.7595586776733398
Validation loss: 2.0988835762905818

Epoch: 6| Step: 3
Training loss: 1.732545018196106
Validation loss: 2.0979083353473293

Epoch: 6| Step: 4
Training loss: 1.6598142385482788
Validation loss: 2.092157671528478

Epoch: 6| Step: 5
Training loss: 2.279404878616333
Validation loss: 2.108855060351792

Epoch: 6| Step: 6
Training loss: 2.04864501953125
Validation loss: 2.1109920701672955

Epoch: 6| Step: 7
Training loss: 1.601186990737915
Validation loss: 2.0982915034858127

Epoch: 6| Step: 8
Training loss: 1.1542848348617554
Validation loss: 2.09967109721194

Epoch: 6| Step: 9
Training loss: 2.2458410263061523
Validation loss: 2.1047837375312723

Epoch: 6| Step: 10
Training loss: 1.0845093727111816
Validation loss: 2.144052026092365

Epoch: 6| Step: 11
Training loss: 1.6013729572296143
Validation loss: 2.156930661970569

Epoch: 6| Step: 12
Training loss: 2.089527130126953
Validation loss: 2.1868790990562847

Epoch: 6| Step: 13
Training loss: 2.4686591625213623
Validation loss: 2.1462623457754813

Epoch: 141| Step: 0
Training loss: 3.170053005218506
Validation loss: 2.1019986470540366

Epoch: 6| Step: 1
Training loss: 1.8664629459381104
Validation loss: 2.0484366698931624

Epoch: 6| Step: 2
Training loss: 2.1198313236236572
Validation loss: 2.025469800477387

Epoch: 6| Step: 3
Training loss: 1.4716763496398926
Validation loss: 2.040038711281233

Epoch: 6| Step: 4
Training loss: 1.7376048564910889
Validation loss: 2.029130886959773

Epoch: 6| Step: 5
Training loss: 1.6688041687011719
Validation loss: 2.0192087619535384

Epoch: 6| Step: 6
Training loss: 1.7626020908355713
Validation loss: 1.9988556908022972

Epoch: 6| Step: 7
Training loss: 1.0363000631332397
Validation loss: 1.9697437145376717

Epoch: 6| Step: 8
Training loss: 1.5326732397079468
Validation loss: 1.99247452264191

Epoch: 6| Step: 9
Training loss: 2.032864570617676
Validation loss: 2.0050697890661096

Epoch: 6| Step: 10
Training loss: 2.442108154296875
Validation loss: 2.022687722277898

Epoch: 6| Step: 11
Training loss: 2.1078262329101562
Validation loss: 2.0576568880388812

Epoch: 6| Step: 12
Training loss: 2.170135021209717
Validation loss: 2.100509969137048

Epoch: 6| Step: 13
Training loss: 2.2615580558776855
Validation loss: 2.127524414370137

Epoch: 142| Step: 0
Training loss: 1.6566102504730225
Validation loss: 2.1068136435683056

Epoch: 6| Step: 1
Training loss: 2.0531816482543945
Validation loss: 2.1161924305782525

Epoch: 6| Step: 2
Training loss: 2.3481292724609375
Validation loss: 2.1523146834424747

Epoch: 6| Step: 3
Training loss: 1.1552132368087769
Validation loss: 2.1447163986903366

Epoch: 6| Step: 4
Training loss: 1.9313900470733643
Validation loss: 2.136758276211318

Epoch: 6| Step: 5
Training loss: 1.910241723060608
Validation loss: 2.1479636597377

Epoch: 6| Step: 6
Training loss: 2.71348237991333
Validation loss: 2.1335872052818217

Epoch: 6| Step: 7
Training loss: 1.7134801149368286
Validation loss: 2.097145398457845

Epoch: 6| Step: 8
Training loss: 1.6134109497070312
Validation loss: 2.0556306877443866

Epoch: 6| Step: 9
Training loss: 1.2333511114120483
Validation loss: 2.040867079970657

Epoch: 6| Step: 10
Training loss: 2.2462563514709473
Validation loss: 2.028962581388412

Epoch: 6| Step: 11
Training loss: 1.6400288343429565
Validation loss: 2.0277343411599436

Epoch: 6| Step: 12
Training loss: 2.089958667755127
Validation loss: 2.0579906381586546

Epoch: 6| Step: 13
Training loss: 1.2171640396118164
Validation loss: 2.078570371033043

Epoch: 143| Step: 0
Training loss: 1.8518805503845215
Validation loss: 2.07351823647817

Epoch: 6| Step: 1
Training loss: 1.4059699773788452
Validation loss: 2.067861710825274

Epoch: 6| Step: 2
Training loss: 1.626299262046814
Validation loss: 2.0426273384401874

Epoch: 6| Step: 3
Training loss: 1.4220097064971924
Validation loss: 2.0310208079635457

Epoch: 6| Step: 4
Training loss: 2.6757640838623047
Validation loss: 2.045800260318223

Epoch: 6| Step: 5
Training loss: 1.6638329029083252
Validation loss: 2.071104936702277

Epoch: 6| Step: 6
Training loss: 1.4281284809112549
Validation loss: 2.077624918312155

Epoch: 6| Step: 7
Training loss: 2.0421743392944336
Validation loss: 2.071251179582329

Epoch: 6| Step: 8
Training loss: 1.7873601913452148
Validation loss: 2.0833089249108427

Epoch: 6| Step: 9
Training loss: 2.269362688064575
Validation loss: 2.059786517132995

Epoch: 6| Step: 10
Training loss: 1.7634443044662476
Validation loss: 2.0337002149192234

Epoch: 6| Step: 11
Training loss: 1.4339220523834229
Validation loss: 2.0508853466280046

Epoch: 6| Step: 12
Training loss: 1.4718420505523682
Validation loss: 2.02337372174827

Epoch: 6| Step: 13
Training loss: 2.057781457901001
Validation loss: 2.021735542563982

Epoch: 144| Step: 0
Training loss: 1.510859727859497
Validation loss: 2.0490812755400136

Epoch: 6| Step: 1
Training loss: 1.7103722095489502
Validation loss: 2.0277183671151437

Epoch: 6| Step: 2
Training loss: 2.045640468597412
Validation loss: 1.9901817767850813

Epoch: 6| Step: 3
Training loss: 1.5403715372085571
Validation loss: 1.9817348795552407

Epoch: 6| Step: 4
Training loss: 1.886103868484497
Validation loss: 1.9596371035422049

Epoch: 6| Step: 5
Training loss: 1.8627591133117676
Validation loss: 1.9540324813576155

Epoch: 6| Step: 6
Training loss: 1.0494532585144043
Validation loss: 1.9589963856563772

Epoch: 6| Step: 7
Training loss: 1.6955244541168213
Validation loss: 1.9578331119270735

Epoch: 6| Step: 8
Training loss: 2.3485703468322754
Validation loss: 1.9788607384568901

Epoch: 6| Step: 9
Training loss: 1.8769303560256958
Validation loss: 1.9601926342133553

Epoch: 6| Step: 10
Training loss: 2.137308359146118
Validation loss: 1.9511220890988585

Epoch: 6| Step: 11
Training loss: 1.9620416164398193
Validation loss: 1.9601380940406554

Epoch: 6| Step: 12
Training loss: 1.8706905841827393
Validation loss: 1.9772110959535003

Epoch: 6| Step: 13
Training loss: 1.7961535453796387
Validation loss: 2.0261690770426104

Epoch: 145| Step: 0
Training loss: 1.8623454570770264
Validation loss: 2.09808079401652

Epoch: 6| Step: 1
Training loss: 1.9967149496078491
Validation loss: 2.1523519895410024

Epoch: 6| Step: 2
Training loss: 1.528813362121582
Validation loss: 2.1653913733779744

Epoch: 6| Step: 3
Training loss: 1.8237485885620117
Validation loss: 2.1873855206274215

Epoch: 6| Step: 4
Training loss: 1.0615241527557373
Validation loss: 2.1562898915301085

Epoch: 6| Step: 5
Training loss: 1.796895146369934
Validation loss: 2.1164410665471065

Epoch: 6| Step: 6
Training loss: 1.5487593412399292
Validation loss: 2.085146213090548

Epoch: 6| Step: 7
Training loss: 1.7353742122650146
Validation loss: 2.0543648491623583

Epoch: 6| Step: 8
Training loss: 2.747619152069092
Validation loss: 2.0392413754617014

Epoch: 6| Step: 9
Training loss: 2.27260684967041
Validation loss: 2.0335920010843584

Epoch: 6| Step: 10
Training loss: 1.7228977680206299
Validation loss: 2.0211010568885395

Epoch: 6| Step: 11
Training loss: 1.5045361518859863
Validation loss: 1.991078071696784

Epoch: 6| Step: 12
Training loss: 1.6827573776245117
Validation loss: 1.9864190906606696

Epoch: 6| Step: 13
Training loss: 1.6008425951004028
Validation loss: 1.981373679253363

Epoch: 146| Step: 0
Training loss: 1.7925597429275513
Validation loss: 1.9973290761311848

Epoch: 6| Step: 1
Training loss: 1.6046262979507446
Validation loss: 2.0075065833266064

Epoch: 6| Step: 2
Training loss: 2.1067161560058594
Validation loss: 2.0361075170578493

Epoch: 6| Step: 3
Training loss: 1.687545657157898
Validation loss: 2.070483681976154

Epoch: 6| Step: 4
Training loss: 1.2593021392822266
Validation loss: 2.0747126968958045

Epoch: 6| Step: 5
Training loss: 2.151517629623413
Validation loss: 2.1195251967317317

Epoch: 6| Step: 6
Training loss: 1.391899824142456
Validation loss: 2.1318876563861804

Epoch: 6| Step: 7
Training loss: 1.988634467124939
Validation loss: 2.1344360536144626

Epoch: 6| Step: 8
Training loss: 1.5205789804458618
Validation loss: 2.126515546152669

Epoch: 6| Step: 9
Training loss: 1.4829378128051758
Validation loss: 2.1059584361250683

Epoch: 6| Step: 10
Training loss: 2.1098501682281494
Validation loss: 2.100545888305992

Epoch: 6| Step: 11
Training loss: 1.7650055885314941
Validation loss: 2.0733581563477874

Epoch: 6| Step: 12
Training loss: 2.0429022312164307
Validation loss: 2.070711397355603

Epoch: 6| Step: 13
Training loss: 1.2450417280197144
Validation loss: 2.0556249708257694

Epoch: 147| Step: 0
Training loss: 1.2897210121154785
Validation loss: 2.0892931645916355

Epoch: 6| Step: 1
Training loss: 2.2783455848693848
Validation loss: 2.0936095483841433

Epoch: 6| Step: 2
Training loss: 1.676974892616272
Validation loss: 2.0941661583480013

Epoch: 6| Step: 3
Training loss: 2.0733180046081543
Validation loss: 2.1001463526038715

Epoch: 6| Step: 4
Training loss: 1.301053762435913
Validation loss: 2.1184215097017187

Epoch: 6| Step: 5
Training loss: 1.6822937726974487
Validation loss: 2.147501737840714

Epoch: 6| Step: 6
Training loss: 2.2761855125427246
Validation loss: 2.1464759419041295

Epoch: 6| Step: 7
Training loss: 1.4062656164169312
Validation loss: 2.1430431078839045

Epoch: 6| Step: 8
Training loss: 1.2641916275024414
Validation loss: 2.1215204577292166

Epoch: 6| Step: 9
Training loss: 1.9730513095855713
Validation loss: 2.119366043357439

Epoch: 6| Step: 10
Training loss: 1.454443335533142
Validation loss: 2.1111306733982538

Epoch: 6| Step: 11
Training loss: 1.6410791873931885
Validation loss: 2.0977774461110434

Epoch: 6| Step: 12
Training loss: 1.7919318675994873
Validation loss: 2.0536862804043676

Epoch: 6| Step: 13
Training loss: 2.270138740539551
Validation loss: 2.0139010029454387

Epoch: 148| Step: 0
Training loss: 1.9131183624267578
Validation loss: 2.026411541046635

Epoch: 6| Step: 1
Training loss: 1.6745405197143555
Validation loss: 2.0209612923283733

Epoch: 6| Step: 2
Training loss: 1.5846242904663086
Validation loss: 2.00592787291414

Epoch: 6| Step: 3
Training loss: 1.4230258464813232
Validation loss: 2.02132490886155

Epoch: 6| Step: 4
Training loss: 1.7252589464187622
Validation loss: 2.0169413115388606

Epoch: 6| Step: 5
Training loss: 1.550095558166504
Validation loss: 2.022875044935493

Epoch: 6| Step: 6
Training loss: 2.2501747608184814
Validation loss: 2.0366283334711546

Epoch: 6| Step: 7
Training loss: 1.3020788431167603
Validation loss: 2.0417806371565788

Epoch: 6| Step: 8
Training loss: 2.4385364055633545
Validation loss: 2.056370596731863

Epoch: 6| Step: 9
Training loss: 1.3185138702392578
Validation loss: 2.0648433393047703

Epoch: 6| Step: 10
Training loss: 1.6259760856628418
Validation loss: 2.1024623045357327

Epoch: 6| Step: 11
Training loss: 1.8392908573150635
Validation loss: 2.1279905226922806

Epoch: 6| Step: 12
Training loss: 1.8104231357574463
Validation loss: 2.1159118631834626

Epoch: 6| Step: 13
Training loss: 1.6556140184402466
Validation loss: 2.1127699267479683

Epoch: 149| Step: 0
Training loss: 1.506052851676941
Validation loss: 2.10009531692792

Epoch: 6| Step: 1
Training loss: 1.857191801071167
Validation loss: 2.1009846092552267

Epoch: 6| Step: 2
Training loss: 1.8391292095184326
Validation loss: 2.0781555752600394

Epoch: 6| Step: 3
Training loss: 1.499446153640747
Validation loss: 2.0594498470265377

Epoch: 6| Step: 4
Training loss: 2.178781509399414
Validation loss: 2.0257493706159693

Epoch: 6| Step: 5
Training loss: 1.307718276977539
Validation loss: 1.995830092378842

Epoch: 6| Step: 6
Training loss: 1.9960229396820068
Validation loss: 1.9918291363664853

Epoch: 6| Step: 7
Training loss: 2.232685089111328
Validation loss: 1.9997942575844385

Epoch: 6| Step: 8
Training loss: 2.1484203338623047
Validation loss: 2.022377578161096

Epoch: 6| Step: 9
Training loss: 0.9575493335723877
Validation loss: 2.046863507199031

Epoch: 6| Step: 10
Training loss: 1.3881562948226929
Validation loss: 2.0526776980328303

Epoch: 6| Step: 11
Training loss: 1.6148091554641724
Validation loss: 2.0924272306503786

Epoch: 6| Step: 12
Training loss: 1.5748474597930908
Validation loss: 2.089924987926278

Epoch: 6| Step: 13
Training loss: 2.21954083442688
Validation loss: 2.1060283594234015

Epoch: 150| Step: 0
Training loss: 1.850780963897705
Validation loss: 2.094806532705984

Epoch: 6| Step: 1
Training loss: 1.089559555053711
Validation loss: 2.087206659778472

Epoch: 6| Step: 2
Training loss: 1.8836424350738525
Validation loss: 2.088417460841517

Epoch: 6| Step: 3
Training loss: 1.9739359617233276
Validation loss: 2.083544815740278

Epoch: 6| Step: 4
Training loss: 1.3707501888275146
Validation loss: 2.112111679969295

Epoch: 6| Step: 5
Training loss: 1.7989698648452759
Validation loss: 2.1029433050463275

Epoch: 6| Step: 6
Training loss: 1.260265827178955
Validation loss: 2.075934576731856

Epoch: 6| Step: 7
Training loss: 1.9620592594146729
Validation loss: 2.0722709522452405

Epoch: 6| Step: 8
Training loss: 1.956313133239746
Validation loss: 2.0612509942823842

Epoch: 6| Step: 9
Training loss: 1.8627970218658447
Validation loss: 2.0482967912509875

Epoch: 6| Step: 10
Training loss: 2.090230703353882
Validation loss: 2.027117492050253

Epoch: 6| Step: 11
Training loss: 1.2303407192230225
Validation loss: 2.0118421944238807

Epoch: 6| Step: 12
Training loss: 1.4694398641586304
Validation loss: 2.026172153411373

Epoch: 6| Step: 13
Training loss: 2.0678646564483643
Validation loss: 2.0354765269064132

Epoch: 151| Step: 0
Training loss: 1.2892765998840332
Validation loss: 2.054330584823444

Epoch: 6| Step: 1
Training loss: 1.8945989608764648
Validation loss: 2.0593447839060137

Epoch: 6| Step: 2
Training loss: 1.2141053676605225
Validation loss: 2.073477739928871

Epoch: 6| Step: 3
Training loss: 1.4701666831970215
Validation loss: 2.0951962368462675

Epoch: 6| Step: 4
Training loss: 1.5706496238708496
Validation loss: 2.0950322407548145

Epoch: 6| Step: 5
Training loss: 1.5679457187652588
Validation loss: 2.0884846974444646

Epoch: 6| Step: 6
Training loss: 1.6545023918151855
Validation loss: 2.0854189036994852

Epoch: 6| Step: 7
Training loss: 1.517091989517212
Validation loss: 2.0249676806952364

Epoch: 6| Step: 8
Training loss: 1.841780185699463
Validation loss: 2.005423504819152

Epoch: 6| Step: 9
Training loss: 2.3443593978881836
Validation loss: 1.9948126641652917

Epoch: 6| Step: 10
Training loss: 1.260756254196167
Validation loss: 2.0103712428000664

Epoch: 6| Step: 11
Training loss: 1.9997897148132324
Validation loss: 1.9854345488291916

Epoch: 6| Step: 12
Training loss: 1.9908976554870605
Validation loss: 1.9877480717115505

Epoch: 6| Step: 13
Training loss: 1.8381603956222534
Validation loss: 1.9931037413176669

Epoch: 152| Step: 0
Training loss: 1.962571620941162
Validation loss: 1.9832038238484373

Epoch: 6| Step: 1
Training loss: 2.3827972412109375
Validation loss: 1.9916168489763815

Epoch: 6| Step: 2
Training loss: 1.539632797241211
Validation loss: 2.024346399050887

Epoch: 6| Step: 3
Training loss: 1.7731091976165771
Validation loss: 2.0292289410868

Epoch: 6| Step: 4
Training loss: 1.2370645999908447
Validation loss: 2.02703486334893

Epoch: 6| Step: 5
Training loss: 1.50778329372406
Validation loss: 2.0380690482354935

Epoch: 6| Step: 6
Training loss: 1.4236068725585938
Validation loss: 2.01889290348176

Epoch: 6| Step: 7
Training loss: 1.8382089138031006
Validation loss: 2.042265353664275

Epoch: 6| Step: 8
Training loss: 1.5986357927322388
Validation loss: 2.05247559085969

Epoch: 6| Step: 9
Training loss: 1.2374334335327148
Validation loss: 2.073271894967684

Epoch: 6| Step: 10
Training loss: 1.7122149467468262
Validation loss: 2.090141757842033

Epoch: 6| Step: 11
Training loss: 1.5450270175933838
Validation loss: 2.108292820633099

Epoch: 6| Step: 12
Training loss: 1.5380825996398926
Validation loss: 2.1614443794373543

Epoch: 6| Step: 13
Training loss: 2.305967330932617
Validation loss: 2.1799933884733464

Epoch: 153| Step: 0
Training loss: 1.8245618343353271
Validation loss: 2.1411056185281403

Epoch: 6| Step: 1
Training loss: 1.4942433834075928
Validation loss: 2.0934838351383003

Epoch: 6| Step: 2
Training loss: 1.6340466737747192
Validation loss: 2.0141256470834055

Epoch: 6| Step: 3
Training loss: 1.9644368886947632
Validation loss: 1.9742430192168041

Epoch: 6| Step: 4
Training loss: 1.6154757738113403
Validation loss: 1.9752197393807032

Epoch: 6| Step: 5
Training loss: 1.3980679512023926
Validation loss: 1.9564444172766902

Epoch: 6| Step: 6
Training loss: 1.3924368619918823
Validation loss: 1.96836648320639

Epoch: 6| Step: 7
Training loss: 1.4450476169586182
Validation loss: 1.9517163448436285

Epoch: 6| Step: 8
Training loss: 1.6123759746551514
Validation loss: 1.9505686336948025

Epoch: 6| Step: 9
Training loss: 1.0943129062652588
Validation loss: 1.9491030926345496

Epoch: 6| Step: 10
Training loss: 1.6845208406448364
Validation loss: 1.9540257005281345

Epoch: 6| Step: 11
Training loss: 2.1527295112609863
Validation loss: 1.970402095907478

Epoch: 6| Step: 12
Training loss: 1.6001639366149902
Validation loss: 2.0178478123039327

Epoch: 6| Step: 13
Training loss: 2.214707851409912
Validation loss: 2.0563071568806968

Epoch: 154| Step: 0
Training loss: 1.3304967880249023
Validation loss: 2.10229911855472

Epoch: 6| Step: 1
Training loss: 1.9269349575042725
Validation loss: 2.111361180582354

Epoch: 6| Step: 2
Training loss: 1.6045935153961182
Validation loss: 2.0903744825752835

Epoch: 6| Step: 3
Training loss: 1.549325704574585
Validation loss: 2.116761105034941

Epoch: 6| Step: 4
Training loss: 1.3661384582519531
Validation loss: 2.133597086834651

Epoch: 6| Step: 5
Training loss: 1.7599890232086182
Validation loss: 2.1320340992302023

Epoch: 6| Step: 6
Training loss: 1.7301652431488037
Validation loss: 2.113445069200249

Epoch: 6| Step: 7
Training loss: 1.4513285160064697
Validation loss: 2.103071299932336

Epoch: 6| Step: 8
Training loss: 1.969111442565918
Validation loss: 2.0741538488736717

Epoch: 6| Step: 9
Training loss: 1.2793172597885132
Validation loss: 2.0636843609553512

Epoch: 6| Step: 10
Training loss: 1.2904109954833984
Validation loss: 2.064763817735898

Epoch: 6| Step: 11
Training loss: 1.1628503799438477
Validation loss: 2.0535387095584663

Epoch: 6| Step: 12
Training loss: 2.4376397132873535
Validation loss: 2.0023522710287445

Epoch: 6| Step: 13
Training loss: 1.466101884841919
Validation loss: 1.9931116052853164

Epoch: 155| Step: 0
Training loss: 2.4233176708221436
Validation loss: 1.9953567763810516

Epoch: 6| Step: 1
Training loss: 1.39579176902771
Validation loss: 2.012613114490304

Epoch: 6| Step: 2
Training loss: 1.2963019609451294
Validation loss: 2.004366833676574

Epoch: 6| Step: 3
Training loss: 1.3999223709106445
Validation loss: 1.9929337732253536

Epoch: 6| Step: 4
Training loss: 1.8003132343292236
Validation loss: 2.0194774827649518

Epoch: 6| Step: 5
Training loss: 2.012995719909668
Validation loss: 2.0771689517523653

Epoch: 6| Step: 6
Training loss: 0.7164807319641113
Validation loss: 2.136706588088825

Epoch: 6| Step: 7
Training loss: 1.323157548904419
Validation loss: 2.169082518546812

Epoch: 6| Step: 8
Training loss: 2.4546260833740234
Validation loss: 2.1464112907327633

Epoch: 6| Step: 9
Training loss: 1.3890271186828613
Validation loss: 2.061296837304228

Epoch: 6| Step: 10
Training loss: 2.0684375762939453
Validation loss: 2.052630001498807

Epoch: 6| Step: 11
Training loss: 1.4712224006652832
Validation loss: 2.0705827307957474

Epoch: 6| Step: 12
Training loss: 2.088247776031494
Validation loss: 2.054170089383279

Epoch: 6| Step: 13
Training loss: 1.547243595123291
Validation loss: 2.0287762880325317

Epoch: 156| Step: 0
Training loss: 1.4596381187438965
Validation loss: 2.0212419033050537

Epoch: 6| Step: 1
Training loss: 1.7066607475280762
Validation loss: 2.0640963764600855

Epoch: 6| Step: 2
Training loss: 1.4230477809906006
Validation loss: 2.1319653808429675

Epoch: 6| Step: 3
Training loss: 2.599436044692993
Validation loss: 2.1705193955411195

Epoch: 6| Step: 4
Training loss: 2.1919398307800293
Validation loss: 2.184664680111793

Epoch: 6| Step: 5
Training loss: 1.189136028289795
Validation loss: 2.2045136062047814

Epoch: 6| Step: 6
Training loss: 1.7555902004241943
Validation loss: 2.161492557935817

Epoch: 6| Step: 7
Training loss: 1.372033953666687
Validation loss: 2.1186889986838064

Epoch: 6| Step: 8
Training loss: 1.4793740510940552
Validation loss: 2.091840946546165

Epoch: 6| Step: 9
Training loss: 1.1171164512634277
Validation loss: 2.0772718691056773

Epoch: 6| Step: 10
Training loss: 1.712801456451416
Validation loss: 2.064967945057859

Epoch: 6| Step: 11
Training loss: 1.8177268505096436
Validation loss: 2.082501793420443

Epoch: 6| Step: 12
Training loss: 1.6895556449890137
Validation loss: 2.08895811470606

Epoch: 6| Step: 13
Training loss: 0.9809063673019409
Validation loss: 2.0618073632640224

Epoch: 157| Step: 0
Training loss: 1.3882427215576172
Validation loss: 2.017030272432553

Epoch: 6| Step: 1
Training loss: 1.3150064945220947
Validation loss: 1.975595551152383

Epoch: 6| Step: 2
Training loss: 1.8926737308502197
Validation loss: 1.9681839225112752

Epoch: 6| Step: 3
Training loss: 1.9992215633392334
Validation loss: 1.9622849059361283

Epoch: 6| Step: 4
Training loss: 1.8819334506988525
Validation loss: 1.9425879627145746

Epoch: 6| Step: 5
Training loss: 1.5425786972045898
Validation loss: 1.9417726916651572

Epoch: 6| Step: 6
Training loss: 1.679795742034912
Validation loss: 1.9614825863992014

Epoch: 6| Step: 7
Training loss: 1.417361855506897
Validation loss: 1.9458906445451962

Epoch: 6| Step: 8
Training loss: 1.63924241065979
Validation loss: 2.001225131814198

Epoch: 6| Step: 9
Training loss: 1.6470106840133667
Validation loss: 2.0570750339056856

Epoch: 6| Step: 10
Training loss: 1.4851512908935547
Validation loss: 2.100361809935621

Epoch: 6| Step: 11
Training loss: 1.321239709854126
Validation loss: 2.0916544596354165

Epoch: 6| Step: 12
Training loss: 1.581020474433899
Validation loss: 2.0668927623379614

Epoch: 6| Step: 13
Training loss: 1.7370363473892212
Validation loss: 2.067462896787992

Epoch: 158| Step: 0
Training loss: 1.412484884262085
Validation loss: 2.0574097838453067

Epoch: 6| Step: 1
Training loss: 2.5131914615631104
Validation loss: 2.077337758515471

Epoch: 6| Step: 2
Training loss: 1.7860602140426636
Validation loss: 2.089310217929143

Epoch: 6| Step: 3
Training loss: 1.447502613067627
Validation loss: 2.102822098680722

Epoch: 6| Step: 4
Training loss: 1.7281006574630737
Validation loss: 2.102906478348599

Epoch: 6| Step: 5
Training loss: 1.3260140419006348
Validation loss: 2.1051243646170503

Epoch: 6| Step: 6
Training loss: 1.3548777103424072
Validation loss: 2.086125212330972

Epoch: 6| Step: 7
Training loss: 1.3576509952545166
Validation loss: 2.056169976470291

Epoch: 6| Step: 8
Training loss: 1.6560543775558472
Validation loss: 2.021652017870257

Epoch: 6| Step: 9
Training loss: 1.691222906112671
Validation loss: 1.9917120164440525

Epoch: 6| Step: 10
Training loss: 2.094756841659546
Validation loss: 1.9957793066578526

Epoch: 6| Step: 11
Training loss: 1.5674656629562378
Validation loss: 2.0189920817652056

Epoch: 6| Step: 12
Training loss: 0.876578688621521
Validation loss: 2.004949003137568

Epoch: 6| Step: 13
Training loss: 1.279976725578308
Validation loss: 2.033973293919717

Epoch: 159| Step: 0
Training loss: 1.4558279514312744
Validation loss: 2.104598255567653

Epoch: 6| Step: 1
Training loss: 1.1762173175811768
Validation loss: 2.183067698632517

Epoch: 6| Step: 2
Training loss: 1.684156894683838
Validation loss: 2.199724171751289

Epoch: 6| Step: 3
Training loss: 2.4228498935699463
Validation loss: 2.190499513379989

Epoch: 6| Step: 4
Training loss: 1.801449179649353
Validation loss: 2.1579637373647382

Epoch: 6| Step: 5
Training loss: 1.6601746082305908
Validation loss: 2.0876343122092624

Epoch: 6| Step: 6
Training loss: 1.527616262435913
Validation loss: 2.11978905944414

Epoch: 6| Step: 7
Training loss: 1.7102599143981934
Validation loss: 2.0553342296231176

Epoch: 6| Step: 8
Training loss: 1.8401901721954346
Validation loss: 2.058091284126364

Epoch: 6| Step: 9
Training loss: 1.237466812133789
Validation loss: 2.0305131866085913

Epoch: 6| Step: 10
Training loss: 1.8296054601669312
Validation loss: 1.9630379817819084

Epoch: 6| Step: 11
Training loss: 2.0694189071655273
Validation loss: 1.9186554403715237

Epoch: 6| Step: 12
Training loss: 1.2102222442626953
Validation loss: 1.899437633893823

Epoch: 6| Step: 13
Training loss: 1.325725793838501
Validation loss: 1.8915331645678448

Epoch: 160| Step: 0
Training loss: 1.6727867126464844
Validation loss: 1.9227350373421945

Epoch: 6| Step: 1
Training loss: 1.5593641996383667
Validation loss: 1.9362700536686888

Epoch: 6| Step: 2
Training loss: 1.4495900869369507
Validation loss: 1.9241899803120603

Epoch: 6| Step: 3
Training loss: 1.3823351860046387
Validation loss: 1.963271915271718

Epoch: 6| Step: 4
Training loss: 1.5624613761901855
Validation loss: 1.9624087913061983

Epoch: 6| Step: 5
Training loss: 1.5444172620773315
Validation loss: 2.0205989191609044

Epoch: 6| Step: 6
Training loss: 1.8634613752365112
Validation loss: 2.1052564805553806

Epoch: 6| Step: 7
Training loss: 1.5384750366210938
Validation loss: 2.13451386010775

Epoch: 6| Step: 8
Training loss: 2.2219247817993164
Validation loss: 2.172914702405212

Epoch: 6| Step: 9
Training loss: 1.5495030879974365
Validation loss: 2.150102018028177

Epoch: 6| Step: 10
Training loss: 0.998778760433197
Validation loss: 2.1424393602596816

Epoch: 6| Step: 11
Training loss: 2.0265650749206543
Validation loss: 2.1585899270990843

Epoch: 6| Step: 12
Training loss: 1.765981674194336
Validation loss: 2.130087278222525

Epoch: 6| Step: 13
Training loss: 1.6355786323547363
Validation loss: 2.0703363905670824

Epoch: 161| Step: 0
Training loss: 1.516603708267212
Validation loss: 2.034333398265223

Epoch: 6| Step: 1
Training loss: 2.0671229362487793
Validation loss: 1.9949846716337307

Epoch: 6| Step: 2
Training loss: 1.2534501552581787
Validation loss: 1.9828061467857772

Epoch: 6| Step: 3
Training loss: 1.4393024444580078
Validation loss: 1.9617997266912972

Epoch: 6| Step: 4
Training loss: 1.3158458471298218
Validation loss: 1.9460929927005564

Epoch: 6| Step: 5
Training loss: 1.8854033946990967
Validation loss: 1.930595048012272

Epoch: 6| Step: 6
Training loss: 1.617614507675171
Validation loss: 1.9102903130233928

Epoch: 6| Step: 7
Training loss: 1.642155408859253
Validation loss: 1.9295054148602229

Epoch: 6| Step: 8
Training loss: 1.3235667943954468
Validation loss: 1.9507851882647442

Epoch: 6| Step: 9
Training loss: 2.1940736770629883
Validation loss: 1.9728888106602493

Epoch: 6| Step: 10
Training loss: 1.7163113355636597
Validation loss: 2.0408885427700576

Epoch: 6| Step: 11
Training loss: 0.9541851282119751
Validation loss: 2.0949948372379428

Epoch: 6| Step: 12
Training loss: 1.6405256986618042
Validation loss: 2.161066396262056

Epoch: 6| Step: 13
Training loss: 0.9988282322883606
Validation loss: 2.204526141125669

Epoch: 162| Step: 0
Training loss: 0.9939917325973511
Validation loss: 2.2394896348317466

Epoch: 6| Step: 1
Training loss: 1.6695036888122559
Validation loss: 2.234030718444496

Epoch: 6| Step: 2
Training loss: 1.373343586921692
Validation loss: 2.224217850674865

Epoch: 6| Step: 3
Training loss: 1.7599644660949707
Validation loss: 2.2073247496799757

Epoch: 6| Step: 4
Training loss: 1.7816202640533447
Validation loss: 2.107428926293568

Epoch: 6| Step: 5
Training loss: 1.620931625366211
Validation loss: 2.048828419818673

Epoch: 6| Step: 6
Training loss: 1.5722949504852295
Validation loss: 2.043686653978081

Epoch: 6| Step: 7
Training loss: 2.2785019874572754
Validation loss: 2.020605871754308

Epoch: 6| Step: 8
Training loss: 1.6396167278289795
Validation loss: 1.9653030967199674

Epoch: 6| Step: 9
Training loss: 1.612706184387207
Validation loss: 1.8900926215674287

Epoch: 6| Step: 10
Training loss: 1.280778169631958
Validation loss: 1.8786977529525757

Epoch: 6| Step: 11
Training loss: 1.495382308959961
Validation loss: 1.8983381076525616

Epoch: 6| Step: 12
Training loss: 1.768495798110962
Validation loss: 1.8939776523138887

Epoch: 6| Step: 13
Training loss: 2.309406042098999
Validation loss: 1.89744952160825

Epoch: 163| Step: 0
Training loss: 1.6995043754577637
Validation loss: 1.8872471893987348

Epoch: 6| Step: 1
Training loss: 1.7969383001327515
Validation loss: 1.9089244924565798

Epoch: 6| Step: 2
Training loss: 1.5248892307281494
Validation loss: 1.893629482997361

Epoch: 6| Step: 3
Training loss: 2.1712427139282227
Validation loss: 1.928722845610752

Epoch: 6| Step: 4
Training loss: 1.6772515773773193
Validation loss: 1.9469099172981836

Epoch: 6| Step: 5
Training loss: 1.6145260334014893
Validation loss: 2.0033189788941415

Epoch: 6| Step: 6
Training loss: 1.3222556114196777
Validation loss: 2.053945469599898

Epoch: 6| Step: 7
Training loss: 1.2655670642852783
Validation loss: 2.1320616686215965

Epoch: 6| Step: 8
Training loss: 1.8408899307250977
Validation loss: 2.2269136175032584

Epoch: 6| Step: 9
Training loss: 1.706918478012085
Validation loss: 2.2781760410595964

Epoch: 6| Step: 10
Training loss: 0.9724205732345581
Validation loss: 2.3139013218623337

Epoch: 6| Step: 11
Training loss: 1.4836288690567017
Validation loss: 2.3291532454952115

Epoch: 6| Step: 12
Training loss: 1.3776705265045166
Validation loss: 2.3292651560998734

Epoch: 6| Step: 13
Training loss: 1.3073203563690186
Validation loss: 2.3086254801801456

Epoch: 164| Step: 0
Training loss: 1.565485954284668
Validation loss: 2.2895128765413837

Epoch: 6| Step: 1
Training loss: 0.7086789608001709
Validation loss: 2.2291699455630396

Epoch: 6| Step: 2
Training loss: 2.2343616485595703
Validation loss: 2.1571692535954137

Epoch: 6| Step: 3
Training loss: 2.0351834297180176
Validation loss: 2.085979175823991

Epoch: 6| Step: 4
Training loss: 0.8744133114814758
Validation loss: 2.0263633804936565

Epoch: 6| Step: 5
Training loss: 1.7243341207504272
Validation loss: 2.0067187111864806

Epoch: 6| Step: 6
Training loss: 1.0595496892929077
Validation loss: 1.9823508647180372

Epoch: 6| Step: 7
Training loss: 2.3989548683166504
Validation loss: 1.9620703907423123

Epoch: 6| Step: 8
Training loss: 1.4038742780685425
Validation loss: 1.9611311804863714

Epoch: 6| Step: 9
Training loss: 2.0406994819641113
Validation loss: 1.9593942229465773

Epoch: 6| Step: 10
Training loss: 1.511330008506775
Validation loss: 1.9647565554547053

Epoch: 6| Step: 11
Training loss: 1.3632094860076904
Validation loss: 1.966920816770164

Epoch: 6| Step: 12
Training loss: 1.1487445831298828
Validation loss: 1.973801407762753

Epoch: 6| Step: 13
Training loss: 1.6496896743774414
Validation loss: 2.0150586584562897

Epoch: 165| Step: 0
Training loss: 1.0799874067306519
Validation loss: 2.0137594566550305

Epoch: 6| Step: 1
Training loss: 1.7712501287460327
Validation loss: 2.032917103459758

Epoch: 6| Step: 2
Training loss: 1.4771647453308105
Validation loss: 2.04226666368464

Epoch: 6| Step: 3
Training loss: 1.3356834650039673
Validation loss: 2.121696295276765

Epoch: 6| Step: 4
Training loss: 1.774765968322754
Validation loss: 2.186425380809333

Epoch: 6| Step: 5
Training loss: 2.245415210723877
Validation loss: 2.2363544894802954

Epoch: 6| Step: 6
Training loss: 1.5400874614715576
Validation loss: 2.2274953370453208

Epoch: 6| Step: 7
Training loss: 1.7516379356384277
Validation loss: 2.2254706531442623

Epoch: 6| Step: 8
Training loss: 1.5334221124649048
Validation loss: 2.195525715428014

Epoch: 6| Step: 9
Training loss: 1.0992474555969238
Validation loss: 2.1523486439899733

Epoch: 6| Step: 10
Training loss: 1.196174144744873
Validation loss: 2.128099931183682

Epoch: 6| Step: 11
Training loss: 0.9837371110916138
Validation loss: 2.1029947675684446

Epoch: 6| Step: 12
Training loss: 2.008899211883545
Validation loss: 2.0939048451762043

Epoch: 6| Step: 13
Training loss: 1.279618740081787
Validation loss: 2.0873884026722243

Epoch: 166| Step: 0
Training loss: 1.2265021800994873
Validation loss: 2.0777783150314004

Epoch: 6| Step: 1
Training loss: 1.5668889284133911
Validation loss: 2.0463445724979525

Epoch: 6| Step: 2
Training loss: 2.245595932006836
Validation loss: 2.014379212933202

Epoch: 6| Step: 3
Training loss: 1.548316478729248
Validation loss: 2.0055683646150815

Epoch: 6| Step: 4
Training loss: 1.106465220451355
Validation loss: 2.0044038808473976

Epoch: 6| Step: 5
Training loss: 1.751969337463379
Validation loss: 2.042761371981713

Epoch: 6| Step: 6
Training loss: 1.9390064477920532
Validation loss: 2.0717004934946694

Epoch: 6| Step: 7
Training loss: 1.5705993175506592
Validation loss: 2.108820455048674

Epoch: 6| Step: 8
Training loss: 1.7641551494598389
Validation loss: 2.0850862482542634

Epoch: 6| Step: 9
Training loss: 0.7624393105506897
Validation loss: 2.10340589989898

Epoch: 6| Step: 10
Training loss: 1.0253547430038452
Validation loss: 2.0990172316951137

Epoch: 6| Step: 11
Training loss: 1.6069879531860352
Validation loss: 2.0966874476402038

Epoch: 6| Step: 12
Training loss: 0.9897794127464294
Validation loss: 2.085045806823238

Epoch: 6| Step: 13
Training loss: 1.667397379875183
Validation loss: 2.093844739339685

Epoch: 167| Step: 0
Training loss: 1.0995872020721436
Validation loss: 2.083942428711922

Epoch: 6| Step: 1
Training loss: 0.890242338180542
Validation loss: 2.070116457118783

Epoch: 6| Step: 2
Training loss: 1.368749976158142
Validation loss: 2.1135285144211142

Epoch: 6| Step: 3
Training loss: 1.4541834592819214
Validation loss: 2.1482945231981176

Epoch: 6| Step: 4
Training loss: 2.189910411834717
Validation loss: 2.2117036927130913

Epoch: 6| Step: 5
Training loss: 1.1858521699905396
Validation loss: 2.2139282829018048

Epoch: 6| Step: 6
Training loss: 1.848558783531189
Validation loss: 2.2384082348115983

Epoch: 6| Step: 7
Training loss: 1.8290785551071167
Validation loss: 2.1861147829281387

Epoch: 6| Step: 8
Training loss: 1.5411953926086426
Validation loss: 2.13132752654373

Epoch: 6| Step: 9
Training loss: 1.4117827415466309
Validation loss: 2.055007742297265

Epoch: 6| Step: 10
Training loss: 1.1924424171447754
Validation loss: 2.024405651195075

Epoch: 6| Step: 11
Training loss: 1.616189956665039
Validation loss: 2.007296580140309

Epoch: 6| Step: 12
Training loss: 1.4770170450210571
Validation loss: 2.000316554500211

Epoch: 6| Step: 13
Training loss: 1.1787970066070557
Validation loss: 1.9765513455995949

Epoch: 168| Step: 0
Training loss: 1.1240816116333008
Validation loss: 1.987645588895326

Epoch: 6| Step: 1
Training loss: 0.7384375333786011
Validation loss: 2.0224879223813295

Epoch: 6| Step: 2
Training loss: 1.526187539100647
Validation loss: 2.0435362503092778

Epoch: 6| Step: 3
Training loss: 1.4488883018493652
Validation loss: 2.023274620374044

Epoch: 6| Step: 4
Training loss: 1.3554532527923584
Validation loss: 2.067489740669086

Epoch: 6| Step: 5
Training loss: 0.7045390605926514
Validation loss: 2.053222028158044

Epoch: 6| Step: 6
Training loss: 1.3610060214996338
Validation loss: 2.0473738088402698

Epoch: 6| Step: 7
Training loss: 1.5244942903518677
Validation loss: 2.0018610531283962

Epoch: 6| Step: 8
Training loss: 0.8070496320724487
Validation loss: 2.0463972322402464

Epoch: 6| Step: 9
Training loss: 1.9978883266448975
Validation loss: 2.07155841653065

Epoch: 6| Step: 10
Training loss: 1.9684863090515137
Validation loss: 2.11145725429699

Epoch: 6| Step: 11
Training loss: 1.9705371856689453
Validation loss: 2.112635665042426

Epoch: 6| Step: 12
Training loss: 1.3361754417419434
Validation loss: 2.1393969187172512

Epoch: 6| Step: 13
Training loss: 2.071425676345825
Validation loss: 2.1156342606390677

Epoch: 169| Step: 0
Training loss: 1.0119311809539795
Validation loss: 2.0822896265214488

Epoch: 6| Step: 1
Training loss: 1.668964147567749
Validation loss: 2.046306194797639

Epoch: 6| Step: 2
Training loss: 1.2730870246887207
Validation loss: 2.0144803806017806

Epoch: 6| Step: 3
Training loss: 1.2650161981582642
Validation loss: 2.010515074576101

Epoch: 6| Step: 4
Training loss: 1.1454493999481201
Validation loss: 1.9882091796526344

Epoch: 6| Step: 5
Training loss: 1.404447317123413
Validation loss: 1.9904837928792483

Epoch: 6| Step: 6
Training loss: 1.2272231578826904
Validation loss: 1.9740934256584413

Epoch: 6| Step: 7
Training loss: 1.6472673416137695
Validation loss: 1.9508062562634867

Epoch: 6| Step: 8
Training loss: 2.329155445098877
Validation loss: 1.9650174674167429

Epoch: 6| Step: 9
Training loss: 1.1385455131530762
Validation loss: 2.0136490842347503

Epoch: 6| Step: 10
Training loss: 1.2303134202957153
Validation loss: 2.0268236744788384

Epoch: 6| Step: 11
Training loss: 1.2189404964447021
Validation loss: 2.0366811303682226

Epoch: 6| Step: 12
Training loss: 1.4613595008850098
Validation loss: 2.1142165507039716

Epoch: 6| Step: 13
Training loss: 0.9403160810470581
Validation loss: 2.129990108551518

Epoch: 170| Step: 0
Training loss: 1.2278640270233154
Validation loss: 2.200045152377057

Epoch: 6| Step: 1
Training loss: 1.435962200164795
Validation loss: 2.241083166932547

Epoch: 6| Step: 2
Training loss: 1.5677995681762695
Validation loss: 2.229689062282603

Epoch: 6| Step: 3
Training loss: 1.0687655210494995
Validation loss: 2.228478334283316

Epoch: 6| Step: 4
Training loss: 0.9785230755805969
Validation loss: 2.217843060852379

Epoch: 6| Step: 5
Training loss: 1.327324628829956
Validation loss: 2.195032424824212

Epoch: 6| Step: 6
Training loss: 1.4229825735092163
Validation loss: 2.1360785973969327

Epoch: 6| Step: 7
Training loss: 1.2625441551208496
Validation loss: 2.0844656882747525

Epoch: 6| Step: 8
Training loss: 1.5018867254257202
Validation loss: 2.026086199668146

Epoch: 6| Step: 9
Training loss: 1.640687108039856
Validation loss: 2.006917130562567

Epoch: 6| Step: 10
Training loss: 1.861574411392212
Validation loss: 1.9853013151435441

Epoch: 6| Step: 11
Training loss: 0.9352148771286011
Validation loss: 1.9725725971242434

Epoch: 6| Step: 12
Training loss: 1.4696986675262451
Validation loss: 1.9626510976463236

Epoch: 6| Step: 13
Training loss: 1.87704598903656
Validation loss: 1.9562301212741482

Epoch: 171| Step: 0
Training loss: 1.456156611442566
Validation loss: 2.002432079725368

Epoch: 6| Step: 1
Training loss: 0.9468876123428345
Validation loss: 2.0428416203427058

Epoch: 6| Step: 2
Training loss: 1.3345251083374023
Validation loss: 2.0658160627529187

Epoch: 6| Step: 3
Training loss: 1.1717031002044678
Validation loss: 2.0957886403606785

Epoch: 6| Step: 4
Training loss: 1.1957536935806274
Validation loss: 2.1396953239235827

Epoch: 6| Step: 5
Training loss: 1.7845821380615234
Validation loss: 2.1388447682062783

Epoch: 6| Step: 6
Training loss: 1.245598316192627
Validation loss: 2.138957836294687

Epoch: 6| Step: 7
Training loss: 1.760937213897705
Validation loss: 2.15563509028445

Epoch: 6| Step: 8
Training loss: 0.7099205255508423
Validation loss: 2.161436434715025

Epoch: 6| Step: 9
Training loss: 1.7384324073791504
Validation loss: 2.120380828457494

Epoch: 6| Step: 10
Training loss: 1.6259956359863281
Validation loss: 2.106101525727139

Epoch: 6| Step: 11
Training loss: 1.3640069961547852
Validation loss: 2.1000844304279616

Epoch: 6| Step: 12
Training loss: 1.8909646272659302
Validation loss: 2.055910628329041

Epoch: 6| Step: 13
Training loss: 1.008324146270752
Validation loss: 2.0049134582601567

Epoch: 172| Step: 0
Training loss: 1.9400827884674072
Validation loss: 1.9758856988722278

Epoch: 6| Step: 1
Training loss: 1.344323754310608
Validation loss: 1.9997894161490983

Epoch: 6| Step: 2
Training loss: 0.7995545864105225
Validation loss: 2.0057148164318455

Epoch: 6| Step: 3
Training loss: 1.5605714321136475
Validation loss: 2.006547592019522

Epoch: 6| Step: 4
Training loss: 1.5655415058135986
Validation loss: 2.0360857696943384

Epoch: 6| Step: 5
Training loss: 1.1552820205688477
Validation loss: 2.0437913953617053

Epoch: 6| Step: 6
Training loss: 1.1163172721862793
Validation loss: 2.057988219363715

Epoch: 6| Step: 7
Training loss: 1.6520214080810547
Validation loss: 2.0826719114857335

Epoch: 6| Step: 8
Training loss: 1.7953627109527588
Validation loss: 2.1049349538741575

Epoch: 6| Step: 9
Training loss: 1.4382045269012451
Validation loss: 2.1022884615005983

Epoch: 6| Step: 10
Training loss: 0.9757521152496338
Validation loss: 2.0933772158879105

Epoch: 6| Step: 11
Training loss: 0.6962895393371582
Validation loss: 2.097654523388032

Epoch: 6| Step: 12
Training loss: 1.2563303709030151
Validation loss: 2.0736645216582925

Epoch: 6| Step: 13
Training loss: 1.4100526571273804
Validation loss: 2.0395046100821546

Epoch: 173| Step: 0
Training loss: 1.0349137783050537
Validation loss: 2.039243026446271

Epoch: 6| Step: 1
Training loss: 0.984675407409668
Validation loss: 2.0640937589829966

Epoch: 6| Step: 2
Training loss: 1.6401035785675049
Validation loss: 2.064233692743445

Epoch: 6| Step: 3
Training loss: 1.1948637962341309
Validation loss: 2.083532940956854

Epoch: 6| Step: 4
Training loss: 1.7305915355682373
Validation loss: 2.107962667301137

Epoch: 6| Step: 5
Training loss: 1.4462140798568726
Validation loss: 2.169717332368256

Epoch: 6| Step: 6
Training loss: 1.2491791248321533
Validation loss: 2.2303208074262066

Epoch: 6| Step: 7
Training loss: 2.3343982696533203
Validation loss: 2.2041859524224394

Epoch: 6| Step: 8
Training loss: 1.1341495513916016
Validation loss: 2.14500343671409

Epoch: 6| Step: 9
Training loss: 1.5575532913208008
Validation loss: 2.1247783835216234

Epoch: 6| Step: 10
Training loss: 1.0385644435882568
Validation loss: 2.059684940563735

Epoch: 6| Step: 11
Training loss: 0.9719123244285583
Validation loss: 2.0176011208565003

Epoch: 6| Step: 12
Training loss: 1.225691795349121
Validation loss: 1.9987068894088909

Epoch: 6| Step: 13
Training loss: 1.1831988096237183
Validation loss: 1.9864172192030056

Epoch: 174| Step: 0
Training loss: 1.437184453010559
Validation loss: 2.0392576545797367

Epoch: 6| Step: 1
Training loss: 1.2490925788879395
Validation loss: 2.080453439425397

Epoch: 6| Step: 2
Training loss: 1.3503400087356567
Validation loss: 2.1007960457955637

Epoch: 6| Step: 3
Training loss: 1.4328269958496094
Validation loss: 2.1168637173150175

Epoch: 6| Step: 4
Training loss: 0.9018830060958862
Validation loss: 2.1024931092416086

Epoch: 6| Step: 5
Training loss: 1.7202622890472412
Validation loss: 2.1077764521362963

Epoch: 6| Step: 6
Training loss: 1.1590723991394043
Validation loss: 2.1083601879817184

Epoch: 6| Step: 7
Training loss: 1.0289125442504883
Validation loss: 2.1157498795499086

Epoch: 6| Step: 8
Training loss: 1.567744255065918
Validation loss: 2.1450005474910943

Epoch: 6| Step: 9
Training loss: 1.4428720474243164
Validation loss: 2.1643214559042327

Epoch: 6| Step: 10
Training loss: 1.318927526473999
Validation loss: 2.158840133297828

Epoch: 6| Step: 11
Training loss: 1.67165207862854
Validation loss: 2.1233503946693997

Epoch: 6| Step: 12
Training loss: 1.3423343896865845
Validation loss: 2.0879557491630636

Epoch: 6| Step: 13
Training loss: 1.0848230123519897
Validation loss: 2.0837392319915113

Epoch: 175| Step: 0
Training loss: 1.6599106788635254
Validation loss: 2.0666876633961997

Epoch: 6| Step: 1
Training loss: 1.6414210796356201
Validation loss: 2.0248746538674958

Epoch: 6| Step: 2
Training loss: 1.297018051147461
Validation loss: 1.9992134994076145

Epoch: 6| Step: 3
Training loss: 1.5295863151550293
Validation loss: 1.9748079238399383

Epoch: 6| Step: 4
Training loss: 1.396803855895996
Validation loss: 1.944309171809945

Epoch: 6| Step: 5
Training loss: 1.602553129196167
Validation loss: 1.9393717371007448

Epoch: 6| Step: 6
Training loss: 1.033644437789917
Validation loss: 1.941755658836775

Epoch: 6| Step: 7
Training loss: 1.3184099197387695
Validation loss: 1.961647641274237

Epoch: 6| Step: 8
Training loss: 1.5114331245422363
Validation loss: 2.0170196974149315

Epoch: 6| Step: 9
Training loss: 1.1647262573242188
Validation loss: 2.0604764428190006

Epoch: 6| Step: 10
Training loss: 0.9389864206314087
Validation loss: 2.094219917892128

Epoch: 6| Step: 11
Training loss: 1.5656545162200928
Validation loss: 2.109559246288833

Epoch: 6| Step: 12
Training loss: 1.5239803791046143
Validation loss: 2.1198231968828427

Epoch: 6| Step: 13
Training loss: 0.5863560438156128
Validation loss: 2.171915244030696

Epoch: 176| Step: 0
Training loss: 0.9801259636878967
Validation loss: 2.183869731041693

Epoch: 6| Step: 1
Training loss: 1.1650753021240234
Validation loss: 2.210951194968275

Epoch: 6| Step: 2
Training loss: 1.67762291431427
Validation loss: 2.2236512309761456

Epoch: 6| Step: 3
Training loss: 1.5075509548187256
Validation loss: 2.1704642029218775

Epoch: 6| Step: 4
Training loss: 1.132346272468567
Validation loss: 2.144111338482108

Epoch: 6| Step: 5
Training loss: 1.5538318157196045
Validation loss: 2.0739525159200034

Epoch: 6| Step: 6
Training loss: 1.313472032546997
Validation loss: 2.020491023217478

Epoch: 6| Step: 7
Training loss: 0.639971137046814
Validation loss: 2.0110613748591435

Epoch: 6| Step: 8
Training loss: 1.3740622997283936
Validation loss: 2.0060806735869376

Epoch: 6| Step: 9
Training loss: 1.5536653995513916
Validation loss: 2.051931717062509

Epoch: 6| Step: 10
Training loss: 1.2411209344863892
Validation loss: 2.0712682047197895

Epoch: 6| Step: 11
Training loss: 1.5433357954025269
Validation loss: 2.129630893789312

Epoch: 6| Step: 12
Training loss: 1.3199267387390137
Validation loss: 2.125560809207219

Epoch: 6| Step: 13
Training loss: 1.3180028200149536
Validation loss: 2.1494396642972062

Epoch: 177| Step: 0
Training loss: 1.425461769104004
Validation loss: 2.1033367854292675

Epoch: 6| Step: 1
Training loss: 1.1287857294082642
Validation loss: 2.0251430606329315

Epoch: 6| Step: 2
Training loss: 1.5517548322677612
Validation loss: 2.002944582252092

Epoch: 6| Step: 3
Training loss: 1.105870246887207
Validation loss: 1.9663998901203115

Epoch: 6| Step: 4
Training loss: 1.0189446210861206
Validation loss: 1.9639594336991668

Epoch: 6| Step: 5
Training loss: 1.2493891716003418
Validation loss: 1.972087311488326

Epoch: 6| Step: 6
Training loss: 1.582632303237915
Validation loss: 1.9991908291334748

Epoch: 6| Step: 7
Training loss: 0.6765005588531494
Validation loss: 2.056346921510594

Epoch: 6| Step: 8
Training loss: 1.8839856386184692
Validation loss: 2.1374658820449666

Epoch: 6| Step: 9
Training loss: 1.5065412521362305
Validation loss: 2.158880969529511

Epoch: 6| Step: 10
Training loss: 1.4551260471343994
Validation loss: 2.1946171047866985

Epoch: 6| Step: 11
Training loss: 1.6261471509933472
Validation loss: 2.2095988360784387

Epoch: 6| Step: 12
Training loss: 1.0204148292541504
Validation loss: 2.1809690588264057

Epoch: 6| Step: 13
Training loss: 1.0975159406661987
Validation loss: 2.1635345938385173

Epoch: 178| Step: 0
Training loss: 1.3591158390045166
Validation loss: 2.0886965079974105

Epoch: 6| Step: 1
Training loss: 1.3041094541549683
Validation loss: 2.0513605584380445

Epoch: 6| Step: 2
Training loss: 0.9876620769500732
Validation loss: 2.015348152447772

Epoch: 6| Step: 3
Training loss: 2.176065683364868
Validation loss: 1.9883825381596882

Epoch: 6| Step: 4
Training loss: 1.7002708911895752
Validation loss: 1.9561421691730458

Epoch: 6| Step: 5
Training loss: 1.6661958694458008
Validation loss: 1.9459270892604705

Epoch: 6| Step: 6
Training loss: 0.9011293649673462
Validation loss: 1.9284235418483775

Epoch: 6| Step: 7
Training loss: 1.477005958557129
Validation loss: 1.9615866727726434

Epoch: 6| Step: 8
Training loss: 1.3088750839233398
Validation loss: 1.9883709697313205

Epoch: 6| Step: 9
Training loss: 1.0294734239578247
Validation loss: 2.0450062213405484

Epoch: 6| Step: 10
Training loss: 1.5446017980575562
Validation loss: 2.0743218570627193

Epoch: 6| Step: 11
Training loss: 1.031488299369812
Validation loss: 2.1066896402707664

Epoch: 6| Step: 12
Training loss: 0.7219157814979553
Validation loss: 2.0959623475228586

Epoch: 6| Step: 13
Training loss: 0.8731857538223267
Validation loss: 2.0784061519048547

Epoch: 179| Step: 0
Training loss: 1.6027050018310547
Validation loss: 2.0577662580756733

Epoch: 6| Step: 1
Training loss: 1.562875747680664
Validation loss: 2.0568973095186296

Epoch: 6| Step: 2
Training loss: 2.103034257888794
Validation loss: 2.0481066088522635

Epoch: 6| Step: 3
Training loss: 1.3280987739562988
Validation loss: 2.0284043076217815

Epoch: 6| Step: 4
Training loss: 0.9510716199874878
Validation loss: 2.0095854215724493

Epoch: 6| Step: 5
Training loss: 1.2280616760253906
Validation loss: 2.021201883592913

Epoch: 6| Step: 6
Training loss: 0.7151139974594116
Validation loss: 2.0538562831058296

Epoch: 6| Step: 7
Training loss: 1.8702280521392822
Validation loss: 2.083975645803636

Epoch: 6| Step: 8
Training loss: 1.3092461824417114
Validation loss: 2.08908212184906

Epoch: 6| Step: 9
Training loss: 1.2154514789581299
Validation loss: 2.085289233474321

Epoch: 6| Step: 10
Training loss: 0.9773719310760498
Validation loss: 2.0374511826422905

Epoch: 6| Step: 11
Training loss: 1.3805264234542847
Validation loss: 2.0394303708948116

Epoch: 6| Step: 12
Training loss: 0.8812954425811768
Validation loss: 2.0451213441869265

Epoch: 6| Step: 13
Training loss: 1.2121704816818237
Validation loss: 2.033986278759536

Epoch: 180| Step: 0
Training loss: 1.5479421615600586
Validation loss: 2.063371709598008

Epoch: 6| Step: 1
Training loss: 1.1289546489715576
Validation loss: 2.0552591021342943

Epoch: 6| Step: 2
Training loss: 1.3002687692642212
Validation loss: 2.121968961531116

Epoch: 6| Step: 3
Training loss: 0.9998859763145447
Validation loss: 2.143072914051753

Epoch: 6| Step: 4
Training loss: 1.2514623403549194
Validation loss: 2.125748324137862

Epoch: 6| Step: 5
Training loss: 1.7431949377059937
Validation loss: 2.174750679282732

Epoch: 6| Step: 6
Training loss: 1.2645184993743896
Validation loss: 2.1878970489707044

Epoch: 6| Step: 7
Training loss: 1.6972204446792603
Validation loss: 2.1751058793837026

Epoch: 6| Step: 8
Training loss: 1.6579551696777344
Validation loss: 2.134300370370188

Epoch: 6| Step: 9
Training loss: 0.9007382392883301
Validation loss: 2.042260957020585

Epoch: 6| Step: 10
Training loss: 1.0563288927078247
Validation loss: 2.0407452096221266

Epoch: 6| Step: 11
Training loss: 1.3972668647766113
Validation loss: 2.02435278636153

Epoch: 6| Step: 12
Training loss: 1.0112648010253906
Validation loss: 2.0269682035651257

Epoch: 6| Step: 13
Training loss: 0.7798025608062744
Validation loss: 2.031671724011821

Epoch: 181| Step: 0
Training loss: 0.8400149941444397
Validation loss: 2.023082451153827

Epoch: 6| Step: 1
Training loss: 1.653984785079956
Validation loss: 2.005639031369199

Epoch: 6| Step: 2
Training loss: 1.7442888021469116
Validation loss: 2.012996918411665

Epoch: 6| Step: 3
Training loss: 1.6515477895736694
Validation loss: 2.043355631571944

Epoch: 6| Step: 4
Training loss: 0.7889046669006348
Validation loss: 2.049755140017438

Epoch: 6| Step: 5
Training loss: 1.216286540031433
Validation loss: 2.113018576816846

Epoch: 6| Step: 6
Training loss: 1.4846913814544678
Validation loss: 2.1349988983523462

Epoch: 6| Step: 7
Training loss: 1.534794569015503
Validation loss: 2.147315605994194

Epoch: 6| Step: 8
Training loss: 1.015894889831543
Validation loss: 2.152410912257369

Epoch: 6| Step: 9
Training loss: 1.0853815078735352
Validation loss: 2.0932921824916715

Epoch: 6| Step: 10
Training loss: 0.8060491681098938
Validation loss: 2.069491442813668

Epoch: 6| Step: 11
Training loss: 1.154503345489502
Validation loss: 2.0340537460901404

Epoch: 6| Step: 12
Training loss: 1.2304373979568481
Validation loss: 1.9754397202563543

Epoch: 6| Step: 13
Training loss: 1.3406745195388794
Validation loss: 1.9410963135380899

Epoch: 182| Step: 0
Training loss: 1.3693066835403442
Validation loss: 1.9398000958145305

Epoch: 6| Step: 1
Training loss: 1.026742696762085
Validation loss: 1.9518899968875352

Epoch: 6| Step: 2
Training loss: 1.3949158191680908
Validation loss: 1.9773877487387708

Epoch: 6| Step: 3
Training loss: 0.8597942590713501
Validation loss: 2.0333081381295317

Epoch: 6| Step: 4
Training loss: 1.9285438060760498
Validation loss: 2.062690316989858

Epoch: 6| Step: 5
Training loss: 1.5893464088439941
Validation loss: 2.1224125149429485

Epoch: 6| Step: 6
Training loss: 1.196377158164978
Validation loss: 2.1476740080823182

Epoch: 6| Step: 7
Training loss: 0.8940004110336304
Validation loss: 2.1712992729679232

Epoch: 6| Step: 8
Training loss: 1.3481237888336182
Validation loss: 2.2173163249928463

Epoch: 6| Step: 9
Training loss: 1.0691685676574707
Validation loss: 2.215933358797463

Epoch: 6| Step: 10
Training loss: 1.1845029592514038
Validation loss: 2.2245791240405013

Epoch: 6| Step: 11
Training loss: 1.3520028591156006
Validation loss: 2.1678101221720376

Epoch: 6| Step: 12
Training loss: 1.6366748809814453
Validation loss: 2.142715400265109

Epoch: 6| Step: 13
Training loss: 1.1311533451080322
Validation loss: 2.073519222197994

Epoch: 183| Step: 0
Training loss: 1.178043246269226
Validation loss: 2.043032641051918

Epoch: 6| Step: 1
Training loss: 0.93199622631073
Validation loss: 2.0042781752924763

Epoch: 6| Step: 2
Training loss: 1.1556391716003418
Validation loss: 1.9424139761155652

Epoch: 6| Step: 3
Training loss: 1.6558992862701416
Validation loss: 1.9407334994244319

Epoch: 6| Step: 4
Training loss: 1.6174161434173584
Validation loss: 1.919053534025787

Epoch: 6| Step: 5
Training loss: 0.9767158031463623
Validation loss: 1.934369937066109

Epoch: 6| Step: 6
Training loss: 0.8752933740615845
Validation loss: 1.9330259112901584

Epoch: 6| Step: 7
Training loss: 1.862046480178833
Validation loss: 1.9332567184202132

Epoch: 6| Step: 8
Training loss: 0.9349754452705383
Validation loss: 1.9696098437873266

Epoch: 6| Step: 9
Training loss: 1.6149682998657227
Validation loss: 2.085280772178404

Epoch: 6| Step: 10
Training loss: 1.3940072059631348
Validation loss: 2.130355609360562

Epoch: 6| Step: 11
Training loss: 0.842856228351593
Validation loss: 2.1540058928151287

Epoch: 6| Step: 12
Training loss: 0.7671453356742859
Validation loss: 2.192203474301164

Epoch: 6| Step: 13
Training loss: 1.4402257204055786
Validation loss: 2.2128231012693016

Epoch: 184| Step: 0
Training loss: 1.4424618482589722
Validation loss: 2.15614745437458

Epoch: 6| Step: 1
Training loss: 1.194945216178894
Validation loss: 2.129232179734015

Epoch: 6| Step: 2
Training loss: 0.8985819816589355
Validation loss: 2.0635211211378857

Epoch: 6| Step: 3
Training loss: 0.9418435096740723
Validation loss: 2.020816892705938

Epoch: 6| Step: 4
Training loss: 1.1321470737457275
Validation loss: 2.0458765388816915

Epoch: 6| Step: 5
Training loss: 1.992310881614685
Validation loss: 2.0109183455026276

Epoch: 6| Step: 6
Training loss: 1.127512812614441
Validation loss: 2.0309819623988163

Epoch: 6| Step: 7
Training loss: 1.9246439933776855
Validation loss: 2.0191368749064784

Epoch: 6| Step: 8
Training loss: 1.3947479724884033
Validation loss: 2.0020073357448784

Epoch: 6| Step: 9
Training loss: 1.1813020706176758
Validation loss: 1.990691456743466

Epoch: 6| Step: 10
Training loss: 1.5720685720443726
Validation loss: 2.0295966620086343

Epoch: 6| Step: 11
Training loss: 0.9229570627212524
Validation loss: 2.0505698624477593

Epoch: 6| Step: 12
Training loss: 0.9658086895942688
Validation loss: 2.039794509128858

Epoch: 6| Step: 13
Training loss: 0.789732813835144
Validation loss: 2.0270655770455637

Epoch: 185| Step: 0
Training loss: 1.552018404006958
Validation loss: 1.9943395083950413

Epoch: 6| Step: 1
Training loss: 0.8519024848937988
Validation loss: 2.004982820121191

Epoch: 6| Step: 2
Training loss: 0.7529902458190918
Validation loss: 2.031062806806257

Epoch: 6| Step: 3
Training loss: 0.9499276876449585
Validation loss: 2.0474240908058743

Epoch: 6| Step: 4
Training loss: 1.067732572555542
Validation loss: 2.067572360397667

Epoch: 6| Step: 5
Training loss: 1.090841293334961
Validation loss: 2.0980883759836995

Epoch: 6| Step: 6
Training loss: 1.3911511898040771
Validation loss: 2.0698018663672992

Epoch: 6| Step: 7
Training loss: 1.3696551322937012
Validation loss: 2.0676593088334605

Epoch: 6| Step: 8
Training loss: 1.1163029670715332
Validation loss: 2.046215613683065

Epoch: 6| Step: 9
Training loss: 0.9254463911056519
Validation loss: 2.076110445043092

Epoch: 6| Step: 10
Training loss: 1.335719108581543
Validation loss: 2.0768550724111576

Epoch: 6| Step: 11
Training loss: 1.1563992500305176
Validation loss: 2.0755337233184488

Epoch: 6| Step: 12
Training loss: 1.64851975440979
Validation loss: 2.0522833870303248

Epoch: 6| Step: 13
Training loss: 1.5873881578445435
Validation loss: 2.042217667384814

Epoch: 186| Step: 0
Training loss: 0.9454915523529053
Validation loss: 2.0660085357645506

Epoch: 6| Step: 1
Training loss: 1.0480504035949707
Validation loss: 2.0715055542607463

Epoch: 6| Step: 2
Training loss: 1.2323212623596191
Validation loss: 2.0731802050785353

Epoch: 6| Step: 3
Training loss: 0.9344016313552856
Validation loss: 2.0374240567607265

Epoch: 6| Step: 4
Training loss: 1.3482286930084229
Validation loss: 2.056113848122217

Epoch: 6| Step: 5
Training loss: 1.4909577369689941
Validation loss: 2.0455853028963973

Epoch: 6| Step: 6
Training loss: 0.4752332270145416
Validation loss: 2.0453476393094627

Epoch: 6| Step: 7
Training loss: 1.173478603363037
Validation loss: 2.0186314326460644

Epoch: 6| Step: 8
Training loss: 1.330651044845581
Validation loss: 2.023649446425899

Epoch: 6| Step: 9
Training loss: 1.3352935314178467
Validation loss: 2.097455656656655

Epoch: 6| Step: 10
Training loss: 1.0113203525543213
Validation loss: 2.120130649176977

Epoch: 6| Step: 11
Training loss: 1.3369801044464111
Validation loss: 2.112911901166362

Epoch: 6| Step: 12
Training loss: 1.2780444622039795
Validation loss: 2.146930351052233

Epoch: 6| Step: 13
Training loss: 1.2817864418029785
Validation loss: 2.120363430310321

Epoch: 187| Step: 0
Training loss: 1.326033353805542
Validation loss: 2.1253640946521553

Epoch: 6| Step: 1
Training loss: 0.5636203289031982
Validation loss: 2.083757185166882

Epoch: 6| Step: 2
Training loss: 1.2656490802764893
Validation loss: 2.050167623386588

Epoch: 6| Step: 3
Training loss: 1.017756462097168
Validation loss: 1.9862836278894895

Epoch: 6| Step: 4
Training loss: 1.3865423202514648
Validation loss: 1.9732610333350398

Epoch: 6| Step: 5
Training loss: 0.7169655561447144
Validation loss: 1.932162182305449

Epoch: 6| Step: 6
Training loss: 1.2169405221939087
Validation loss: 1.9262884278451242

Epoch: 6| Step: 7
Training loss: 1.0008008480072021
Validation loss: 1.9209005666035477

Epoch: 6| Step: 8
Training loss: 0.8121200799942017
Validation loss: 1.9703087755428847

Epoch: 6| Step: 9
Training loss: 1.4085423946380615
Validation loss: 1.9790539613334082

Epoch: 6| Step: 10
Training loss: 1.7281074523925781
Validation loss: 2.038960249193253

Epoch: 6| Step: 11
Training loss: 1.0718638896942139
Validation loss: 2.1296109922470583

Epoch: 6| Step: 12
Training loss: 1.2111692428588867
Validation loss: 2.1617670725750666

Epoch: 6| Step: 13
Training loss: 1.7570616006851196
Validation loss: 2.2088542343467794

Epoch: 188| Step: 0
Training loss: 1.5571482181549072
Validation loss: 2.26844419458861

Epoch: 6| Step: 1
Training loss: 1.2446684837341309
Validation loss: 2.2943661828194895

Epoch: 6| Step: 2
Training loss: 1.0986814498901367
Validation loss: 2.285076229803024

Epoch: 6| Step: 3
Training loss: 1.7973436117172241
Validation loss: 2.2445004268359114

Epoch: 6| Step: 4
Training loss: 1.1025910377502441
Validation loss: 2.155006206163796

Epoch: 6| Step: 5
Training loss: 1.1303799152374268
Validation loss: 2.111814155373522

Epoch: 6| Step: 6
Training loss: 1.1625157594680786
Validation loss: 2.038269390342056

Epoch: 6| Step: 7
Training loss: 0.6548606157302856
Validation loss: 2.0164217551549277

Epoch: 6| Step: 8
Training loss: 0.9741018414497375
Validation loss: 2.0061501021026285

Epoch: 6| Step: 9
Training loss: 1.3055603504180908
Validation loss: 2.0094980321904665

Epoch: 6| Step: 10
Training loss: 1.6109627485275269
Validation loss: 1.987953834636237

Epoch: 6| Step: 11
Training loss: 0.6770529747009277
Validation loss: 1.959548763049546

Epoch: 6| Step: 12
Training loss: 0.896550714969635
Validation loss: 1.9544849036842264

Epoch: 6| Step: 13
Training loss: 1.4936206340789795
Validation loss: 1.9875244555934783

Epoch: 189| Step: 0
Training loss: 1.1128365993499756
Validation loss: 1.9823085595202703

Epoch: 6| Step: 1
Training loss: 1.0554566383361816
Validation loss: 2.014659625227733

Epoch: 6| Step: 2
Training loss: 1.7498672008514404
Validation loss: 2.0552947675028155

Epoch: 6| Step: 3
Training loss: 0.7665635943412781
Validation loss: 2.10677646821545

Epoch: 6| Step: 4
Training loss: 0.995343029499054
Validation loss: 2.1364860867941253

Epoch: 6| Step: 5
Training loss: 1.2138431072235107
Validation loss: 2.1664321063667216

Epoch: 6| Step: 6
Training loss: 0.9883478879928589
Validation loss: 2.185647021057785

Epoch: 6| Step: 7
Training loss: 0.8547208905220032
Validation loss: 2.182563163900888

Epoch: 6| Step: 8
Training loss: 0.7804822325706482
Validation loss: 2.1876596712297007

Epoch: 6| Step: 9
Training loss: 1.1921933889389038
Validation loss: 2.1938576159938687

Epoch: 6| Step: 10
Training loss: 1.579533338546753
Validation loss: 2.159920584770941

Epoch: 6| Step: 11
Training loss: 0.8178017139434814
Validation loss: 2.1176605788610314

Epoch: 6| Step: 12
Training loss: 1.3839747905731201
Validation loss: 2.0651461539729947

Epoch: 6| Step: 13
Training loss: 1.155790090560913
Validation loss: 1.9915547447819864

Epoch: 190| Step: 0
Training loss: 1.3714876174926758
Validation loss: 1.921530597953386

Epoch: 6| Step: 1
Training loss: 1.6057460308074951
Validation loss: 1.9213126756811654

Epoch: 6| Step: 2
Training loss: 0.931564450263977
Validation loss: 1.8908183292676044

Epoch: 6| Step: 3
Training loss: 1.2104624509811401
Validation loss: 1.9039087910805979

Epoch: 6| Step: 4
Training loss: 1.2402100563049316
Validation loss: 1.8915754146473382

Epoch: 6| Step: 5
Training loss: 1.4265896081924438
Validation loss: 1.9166827906844437

Epoch: 6| Step: 6
Training loss: 1.1507048606872559
Validation loss: 1.878262560854676

Epoch: 6| Step: 7
Training loss: 1.3169472217559814
Validation loss: 1.903122527624971

Epoch: 6| Step: 8
Training loss: 0.9725260734558105
Validation loss: 1.955265418175728

Epoch: 6| Step: 9
Training loss: 1.0652978420257568
Validation loss: 2.065094132577219

Epoch: 6| Step: 10
Training loss: 1.1328707933425903
Validation loss: 2.168845135678527

Epoch: 6| Step: 11
Training loss: 1.4840672016143799
Validation loss: 2.261209011077881

Epoch: 6| Step: 12
Training loss: 1.1650819778442383
Validation loss: 2.2918520794119885

Epoch: 6| Step: 13
Training loss: 0.508396565914154
Validation loss: 2.3113657582190728

Epoch: 191| Step: 0
Training loss: 1.0607120990753174
Validation loss: 2.2985230210006877

Epoch: 6| Step: 1
Training loss: 0.6564150452613831
Validation loss: 2.272755435718003

Epoch: 6| Step: 2
Training loss: 1.2660632133483887
Validation loss: 2.1980281978525142

Epoch: 6| Step: 3
Training loss: 1.3425217866897583
Validation loss: 2.152561818399737

Epoch: 6| Step: 4
Training loss: 1.005168080329895
Validation loss: 2.07500454174575

Epoch: 6| Step: 5
Training loss: 0.9389948844909668
Validation loss: 2.0228874273197626

Epoch: 6| Step: 6
Training loss: 1.229954481124878
Validation loss: 1.981706565426242

Epoch: 6| Step: 7
Training loss: 1.7318038940429688
Validation loss: 1.9483371601309827

Epoch: 6| Step: 8
Training loss: 1.1722495555877686
Validation loss: 1.8834552764892578

Epoch: 6| Step: 9
Training loss: 1.5018075704574585
Validation loss: 1.8525881254544823

Epoch: 6| Step: 10
Training loss: 1.5257704257965088
Validation loss: 1.8598884882465485

Epoch: 6| Step: 11
Training loss: 1.7385690212249756
Validation loss: 1.8500828819890176

Epoch: 6| Step: 12
Training loss: 0.9877676367759705
Validation loss: 1.8556154979172574

Epoch: 6| Step: 13
Training loss: 1.0329511165618896
Validation loss: 1.9005134849138157

Epoch: 192| Step: 0
Training loss: 1.2722556591033936
Validation loss: 1.9472902820956322

Epoch: 6| Step: 1
Training loss: 1.4892776012420654
Validation loss: 2.070118857968238

Epoch: 6| Step: 2
Training loss: 0.9872447848320007
Validation loss: 2.12848787794831

Epoch: 6| Step: 3
Training loss: 1.1454250812530518
Validation loss: 2.194656123397171

Epoch: 6| Step: 4
Training loss: 0.7997665405273438
Validation loss: 2.2678965855670232

Epoch: 6| Step: 5
Training loss: 1.787994384765625
Validation loss: 2.3198995769664807

Epoch: 6| Step: 6
Training loss: 0.7445894479751587
Validation loss: 2.335681474337014

Epoch: 6| Step: 7
Training loss: 1.3858352899551392
Validation loss: 2.2980628833975842

Epoch: 6| Step: 8
Training loss: 1.7054598331451416
Validation loss: 2.257574116030047

Epoch: 6| Step: 9
Training loss: 1.5562244653701782
Validation loss: 2.1577531765866023

Epoch: 6| Step: 10
Training loss: 0.9649720191955566
Validation loss: 2.080356469718359

Epoch: 6| Step: 11
Training loss: 0.9943983554840088
Validation loss: 2.0100409805133777

Epoch: 6| Step: 12
Training loss: 0.9221075773239136
Validation loss: 1.964398495612606

Epoch: 6| Step: 13
Training loss: 1.2460179328918457
Validation loss: 1.9412956955612346

Epoch: 193| Step: 0
Training loss: 0.9073300361633301
Validation loss: 1.9672168211270404

Epoch: 6| Step: 1
Training loss: 1.048391580581665
Validation loss: 1.9650650588415002

Epoch: 6| Step: 2
Training loss: 1.0906093120574951
Validation loss: 1.966232943278487

Epoch: 6| Step: 3
Training loss: 1.0555182695388794
Validation loss: 1.9725343911878523

Epoch: 6| Step: 4
Training loss: 1.0015512704849243
Validation loss: 2.001442269612384

Epoch: 6| Step: 5
Training loss: 0.8041173219680786
Validation loss: 2.0105627185554913

Epoch: 6| Step: 6
Training loss: 1.338942527770996
Validation loss: 2.049679717709941

Epoch: 6| Step: 7
Training loss: 0.8747093677520752
Validation loss: 2.048177954971149

Epoch: 6| Step: 8
Training loss: 1.2863149642944336
Validation loss: 2.0685090352130193

Epoch: 6| Step: 9
Training loss: 1.5473389625549316
Validation loss: 2.052691641674247

Epoch: 6| Step: 10
Training loss: 0.9652391076087952
Validation loss: 2.0751105149586997

Epoch: 6| Step: 11
Training loss: 1.2591136693954468
Validation loss: 2.0824193749376523

Epoch: 6| Step: 12
Training loss: 1.3433444499969482
Validation loss: 2.0609026185927855

Epoch: 6| Step: 13
Training loss: 1.054758071899414
Validation loss: 2.073158553851548

Epoch: 194| Step: 0
Training loss: 1.2188142538070679
Validation loss: 2.0438814599026918

Epoch: 6| Step: 1
Training loss: 0.8542298078536987
Validation loss: 2.0388004574724423

Epoch: 6| Step: 2
Training loss: 1.1416724920272827
Validation loss: 2.001499145261703

Epoch: 6| Step: 3
Training loss: 1.1353590488433838
Validation loss: 1.9925014370231218

Epoch: 6| Step: 4
Training loss: 1.0175279378890991
Validation loss: 1.953652899752381

Epoch: 6| Step: 5
Training loss: 0.9854526519775391
Validation loss: 1.9633591713443879

Epoch: 6| Step: 6
Training loss: 1.3893216848373413
Validation loss: 1.9354996617122362

Epoch: 6| Step: 7
Training loss: 0.7717077732086182
Validation loss: 1.9412497320482809

Epoch: 6| Step: 8
Training loss: 1.1599363088607788
Validation loss: 1.943086262672178

Epoch: 6| Step: 9
Training loss: 1.424725890159607
Validation loss: 1.9640911548368392

Epoch: 6| Step: 10
Training loss: 0.8450995683670044
Validation loss: 1.9676350111602454

Epoch: 6| Step: 11
Training loss: 1.0159430503845215
Validation loss: 1.9803064433477258

Epoch: 6| Step: 12
Training loss: 0.9298710227012634
Validation loss: 2.0519026684504684

Epoch: 6| Step: 13
Training loss: 1.145159125328064
Validation loss: 2.058793217905106

Epoch: 195| Step: 0
Training loss: 0.8882865309715271
Validation loss: 2.0495956636244252

Epoch: 6| Step: 1
Training loss: 1.1220414638519287
Validation loss: 2.0641731805698846

Epoch: 6| Step: 2
Training loss: 1.0103486776351929
Validation loss: 1.9924058170728787

Epoch: 6| Step: 3
Training loss: 0.7535309791564941
Validation loss: 1.978360645232662

Epoch: 6| Step: 4
Training loss: 1.3704102039337158
Validation loss: 1.9433509419041295

Epoch: 6| Step: 5
Training loss: 1.3719203472137451
Validation loss: 1.9308110770358835

Epoch: 6| Step: 6
Training loss: 0.6497080326080322
Validation loss: 1.9253530938138244

Epoch: 6| Step: 7
Training loss: 1.4362339973449707
Validation loss: 1.9629212502510316

Epoch: 6| Step: 8
Training loss: 0.652063250541687
Validation loss: 1.9497313755814747

Epoch: 6| Step: 9
Training loss: 1.3722038269042969
Validation loss: 1.9672470579865158

Epoch: 6| Step: 10
Training loss: 1.347771167755127
Validation loss: 2.0087072746728056

Epoch: 6| Step: 11
Training loss: 0.9347807765007019
Validation loss: 2.023998366889133

Epoch: 6| Step: 12
Training loss: 0.9719257354736328
Validation loss: 2.0945339023426013

Epoch: 6| Step: 13
Training loss: 1.3887560367584229
Validation loss: 2.118057313785758

Epoch: 196| Step: 0
Training loss: 1.031865119934082
Validation loss: 2.1042130724076302

Epoch: 6| Step: 1
Training loss: 1.112213373184204
Validation loss: 2.063801616750738

Epoch: 6| Step: 2
Training loss: 1.206935167312622
Validation loss: 2.061881414023779

Epoch: 6| Step: 3
Training loss: 0.4168989658355713
Validation loss: 2.0494266427973264

Epoch: 6| Step: 4
Training loss: 0.9263826608657837
Validation loss: 1.982947685385263

Epoch: 6| Step: 5
Training loss: 1.0120793581008911
Validation loss: 1.981174369012156

Epoch: 6| Step: 6
Training loss: 1.591517686843872
Validation loss: 1.9898789057167627

Epoch: 6| Step: 7
Training loss: 1.6470119953155518
Validation loss: 2.004708085008847

Epoch: 6| Step: 8
Training loss: 1.2888002395629883
Validation loss: 1.9989353226077171

Epoch: 6| Step: 9
Training loss: 0.7830604314804077
Validation loss: 1.9912774947381788

Epoch: 6| Step: 10
Training loss: 1.29437255859375
Validation loss: 2.001484699146722

Epoch: 6| Step: 11
Training loss: 1.1754980087280273
Validation loss: 2.0183151845009095

Epoch: 6| Step: 12
Training loss: 0.8212527632713318
Validation loss: 2.06994221415571

Epoch: 6| Step: 13
Training loss: 0.7196153998374939
Validation loss: 2.1068500677744546

Epoch: 197| Step: 0
Training loss: 0.6547727584838867
Validation loss: 2.1772746245066323

Epoch: 6| Step: 1
Training loss: 1.5905272960662842
Validation loss: 2.1852636311643865

Epoch: 6| Step: 2
Training loss: 1.1131818294525146
Validation loss: 2.2187246609759588

Epoch: 6| Step: 3
Training loss: 0.663196861743927
Validation loss: 2.18554163107308

Epoch: 6| Step: 4
Training loss: 0.755850076675415
Validation loss: 2.18501276611

Epoch: 6| Step: 5
Training loss: 1.340069055557251
Validation loss: 2.130146672648768

Epoch: 6| Step: 6
Training loss: 1.3378832340240479
Validation loss: 2.1312222762774398

Epoch: 6| Step: 7
Training loss: 0.8533511161804199
Validation loss: 2.099411609352276

Epoch: 6| Step: 8
Training loss: 1.129607915878296
Validation loss: 2.097705271936232

Epoch: 6| Step: 9
Training loss: 1.8108891248703003
Validation loss: 2.081429786579583

Epoch: 6| Step: 10
Training loss: 0.9186297655105591
Validation loss: 2.056318113880773

Epoch: 6| Step: 11
Training loss: 0.9820607900619507
Validation loss: 2.0188093031606367

Epoch: 6| Step: 12
Training loss: 1.137994647026062
Validation loss: 2.033358291913104

Epoch: 6| Step: 13
Training loss: 0.8839754462242126
Validation loss: 1.9874390350875033

Epoch: 198| Step: 0
Training loss: 1.0701584815979004
Validation loss: 1.9883877103046705

Epoch: 6| Step: 1
Training loss: 1.1675444841384888
Validation loss: 1.959708088187761

Epoch: 6| Step: 2
Training loss: 1.0036845207214355
Validation loss: 1.9253465462756414

Epoch: 6| Step: 3
Training loss: 1.0529215335845947
Validation loss: 1.9376777833507908

Epoch: 6| Step: 4
Training loss: 1.122023582458496
Validation loss: 1.9429603007531935

Epoch: 6| Step: 5
Training loss: 0.5853351354598999
Validation loss: 1.9496000018171085

Epoch: 6| Step: 6
Training loss: 1.1583046913146973
Validation loss: 1.9917225504434237

Epoch: 6| Step: 7
Training loss: 1.1182575225830078
Validation loss: 2.0210686832345943

Epoch: 6| Step: 8
Training loss: 1.3121337890625
Validation loss: 2.068894519600817

Epoch: 6| Step: 9
Training loss: 0.7387768030166626
Validation loss: 2.123791165249322

Epoch: 6| Step: 10
Training loss: 1.3478388786315918
Validation loss: 2.1523138348774244

Epoch: 6| Step: 11
Training loss: 1.2849549055099487
Validation loss: 2.162253209339675

Epoch: 6| Step: 12
Training loss: 1.128585696220398
Validation loss: 2.14912066664747

Epoch: 6| Step: 13
Training loss: 0.9859605431556702
Validation loss: 2.1412557530146774

Epoch: 199| Step: 0
Training loss: 0.4629942774772644
Validation loss: 2.1376540635221746

Epoch: 6| Step: 1
Training loss: 1.3017483949661255
Validation loss: 2.0949401099194764

Epoch: 6| Step: 2
Training loss: 0.9957259297370911
Validation loss: 2.064690430959066

Epoch: 6| Step: 3
Training loss: 1.0963733196258545
Validation loss: 2.053454665727513

Epoch: 6| Step: 4
Training loss: 1.1657752990722656
Validation loss: 2.022957983837333

Epoch: 6| Step: 5
Training loss: 1.150895595550537
Validation loss: 1.9584109360171902

Epoch: 6| Step: 6
Training loss: 0.8985810279846191
Validation loss: 1.9365774098262991

Epoch: 6| Step: 7
Training loss: 0.9735379219055176
Validation loss: 1.9405802616509058

Epoch: 6| Step: 8
Training loss: 1.4776207208633423
Validation loss: 1.9171916169504966

Epoch: 6| Step: 9
Training loss: 0.6675666570663452
Validation loss: 1.9180835447003763

Epoch: 6| Step: 10
Training loss: 1.5982942581176758
Validation loss: 1.9453694551221785

Epoch: 6| Step: 11
Training loss: 0.9807183742523193
Validation loss: 1.9563105772900324

Epoch: 6| Step: 12
Training loss: 1.010632038116455
Validation loss: 1.9752555483130998

Epoch: 6| Step: 13
Training loss: 0.46084731817245483
Validation loss: 2.020550395852776

Epoch: 200| Step: 0
Training loss: 1.1664098501205444
Validation loss: 2.043030123556814

Epoch: 6| Step: 1
Training loss: 0.614734411239624
Validation loss: 2.0107017191507484

Epoch: 6| Step: 2
Training loss: 1.314164400100708
Validation loss: 1.9909459967767038

Epoch: 6| Step: 3
Training loss: 1.0298705101013184
Validation loss: 1.9583001072688768

Epoch: 6| Step: 4
Training loss: 1.1559271812438965
Validation loss: 1.9847169435152443

Epoch: 6| Step: 5
Training loss: 0.6403592824935913
Validation loss: 1.998642526647096

Epoch: 6| Step: 6
Training loss: 0.5972927808761597
Validation loss: 2.0020528685662056

Epoch: 6| Step: 7
Training loss: 1.2213809490203857
Validation loss: 2.0095234788874143

Epoch: 6| Step: 8
Training loss: 0.7247045040130615
Validation loss: 2.060191382643997

Epoch: 6| Step: 9
Training loss: 0.9580622315406799
Validation loss: 2.0653430518283638

Epoch: 6| Step: 10
Training loss: 1.3302192687988281
Validation loss: 2.1162068779750536

Epoch: 6| Step: 11
Training loss: 1.4258134365081787
Validation loss: 2.1509824529770882

Epoch: 6| Step: 12
Training loss: 1.364508867263794
Validation loss: 2.154071443824358

Epoch: 6| Step: 13
Training loss: 1.6917510032653809
Validation loss: 2.1466228449216453

Epoch: 201| Step: 0
Training loss: 0.8491730690002441
Validation loss: 2.088576470651934

Epoch: 6| Step: 1
Training loss: 0.9722604751586914
Validation loss: 2.0477958494617092

Epoch: 6| Step: 2
Training loss: 1.3715578317642212
Validation loss: 2.012332849605109

Epoch: 6| Step: 3
Training loss: 1.3350200653076172
Validation loss: 2.0315468426673644

Epoch: 6| Step: 4
Training loss: 1.3323214054107666
Validation loss: 2.028595124521563

Epoch: 6| Step: 5
Training loss: 0.7827646732330322
Validation loss: 2.017163856055147

Epoch: 6| Step: 6
Training loss: 0.9544407725334167
Validation loss: 1.9780494397686375

Epoch: 6| Step: 7
Training loss: 0.981430172920227
Validation loss: 1.9531772316143077

Epoch: 6| Step: 8
Training loss: 0.7987613677978516
Validation loss: 1.9843230632043654

Epoch: 6| Step: 9
Training loss: 1.3718498945236206
Validation loss: 2.0046269432190926

Epoch: 6| Step: 10
Training loss: 0.8963528871536255
Validation loss: 2.0357156774049163

Epoch: 6| Step: 11
Training loss: 0.8300766944885254
Validation loss: 2.1051866700572353

Epoch: 6| Step: 12
Training loss: 0.9557867050170898
Validation loss: 2.1211609840393066

Epoch: 6| Step: 13
Training loss: 0.8059911131858826
Validation loss: 2.108390003122309

Epoch: 202| Step: 0
Training loss: 0.7800880670547485
Validation loss: 2.090230272662255

Epoch: 6| Step: 1
Training loss: 1.24345064163208
Validation loss: 2.0891989507982807

Epoch: 6| Step: 2
Training loss: 1.2790837287902832
Validation loss: 2.0730983441875828

Epoch: 6| Step: 3
Training loss: 1.2957043647766113
Validation loss: 2.0981933429676998

Epoch: 6| Step: 4
Training loss: 1.302572250366211
Validation loss: 2.069815920245263

Epoch: 6| Step: 5
Training loss: 1.414243221282959
Validation loss: 2.0674896188961562

Epoch: 6| Step: 6
Training loss: 0.8925408720970154
Validation loss: 2.031402818618282

Epoch: 6| Step: 7
Training loss: 0.8420222401618958
Validation loss: 2.063621885033064

Epoch: 6| Step: 8
Training loss: 0.6046180129051208
Validation loss: 2.0918095342574583

Epoch: 6| Step: 9
Training loss: 1.409444808959961
Validation loss: 2.1056945734126593

Epoch: 6| Step: 10
Training loss: 0.9506216049194336
Validation loss: 2.101793622457853

Epoch: 6| Step: 11
Training loss: 0.8019352555274963
Validation loss: 2.1189067850830736

Epoch: 6| Step: 12
Training loss: 0.8105143308639526
Validation loss: 2.0987718566771476

Epoch: 6| Step: 13
Training loss: 1.3938099145889282
Validation loss: 2.079199456399487

Epoch: 203| Step: 0
Training loss: 0.8301029205322266
Validation loss: 2.0416275403832875

Epoch: 6| Step: 1
Training loss: 1.0204777717590332
Validation loss: 1.9899806540499452

Epoch: 6| Step: 2
Training loss: 1.1305235624313354
Validation loss: 1.944490860867244

Epoch: 6| Step: 3
Training loss: 1.268833875656128
Validation loss: 1.9401747693297684

Epoch: 6| Step: 4
Training loss: 1.3086254596710205
Validation loss: 1.9696224658719954

Epoch: 6| Step: 5
Training loss: 0.7858957648277283
Validation loss: 1.9449776731511599

Epoch: 6| Step: 6
Training loss: 0.5207626819610596
Validation loss: 1.945183902658442

Epoch: 6| Step: 7
Training loss: 0.6063315272331238
Validation loss: 1.9978454523189093

Epoch: 6| Step: 8
Training loss: 0.6170028448104858
Validation loss: 2.0201794152618735

Epoch: 6| Step: 9
Training loss: 1.0597484111785889
Validation loss: 2.0286098500733734

Epoch: 6| Step: 10
Training loss: 1.3351178169250488
Validation loss: 2.064897432122179

Epoch: 6| Step: 11
Training loss: 1.460721492767334
Validation loss: 2.073533745222194

Epoch: 6| Step: 12
Training loss: 1.5860651731491089
Validation loss: 2.0716734496496056

Epoch: 6| Step: 13
Training loss: 0.8108639121055603
Validation loss: 1.9964691246709516

Epoch: 204| Step: 0
Training loss: 1.0983781814575195
Validation loss: 2.0176167206097673

Epoch: 6| Step: 1
Training loss: 0.875200629234314
Validation loss: 1.9810853645365725

Epoch: 6| Step: 2
Training loss: 0.6196700930595398
Validation loss: 1.9630244393502512

Epoch: 6| Step: 3
Training loss: 0.8151307106018066
Validation loss: 1.9736712260912823

Epoch: 6| Step: 4
Training loss: 0.9317044019699097
Validation loss: 1.9762727188807663

Epoch: 6| Step: 5
Training loss: 1.6666028499603271
Validation loss: 1.9960655666166736

Epoch: 6| Step: 6
Training loss: 1.1736886501312256
Validation loss: 1.9783793059728478

Epoch: 6| Step: 7
Training loss: 0.6561036109924316
Validation loss: 2.002132431153328

Epoch: 6| Step: 8
Training loss: 1.0506662130355835
Validation loss: 2.0295775987768687

Epoch: 6| Step: 9
Training loss: 1.375002384185791
Validation loss: 2.060110825364308

Epoch: 6| Step: 10
Training loss: 0.86937016248703
Validation loss: 2.07164397803686

Epoch: 6| Step: 11
Training loss: 1.2851126194000244
Validation loss: 2.1000113589789278

Epoch: 6| Step: 12
Training loss: 0.9724894165992737
Validation loss: 2.1079513975369033

Epoch: 6| Step: 13
Training loss: 0.3900710344314575
Validation loss: 2.054905351772103

Epoch: 205| Step: 0
Training loss: 1.292051076889038
Validation loss: 2.0394262152333416

Epoch: 6| Step: 1
Training loss: 0.9238545894622803
Validation loss: 1.9738918645407564

Epoch: 6| Step: 2
Training loss: 1.0568394660949707
Validation loss: 1.9690646509970389

Epoch: 6| Step: 3
Training loss: 0.8266151547431946
Validation loss: 1.9749168285759546

Epoch: 6| Step: 4
Training loss: 1.0402638912200928
Validation loss: 1.9405570927486624

Epoch: 6| Step: 5
Training loss: 0.581411600112915
Validation loss: 1.9634158367751746

Epoch: 6| Step: 6
Training loss: 0.6356641054153442
Validation loss: 1.9933237670570292

Epoch: 6| Step: 7
Training loss: 0.846031904220581
Validation loss: 2.0201997551866757

Epoch: 6| Step: 8
Training loss: 0.6091794371604919
Validation loss: 2.069622270522579

Epoch: 6| Step: 9
Training loss: 0.9106051921844482
Validation loss: 2.058540185292562

Epoch: 6| Step: 10
Training loss: 1.6809039115905762
Validation loss: 2.0732356579073015

Epoch: 6| Step: 11
Training loss: 0.5470519661903381
Validation loss: 2.050865839886409

Epoch: 6| Step: 12
Training loss: 1.1560111045837402
Validation loss: 2.0302300376276814

Epoch: 6| Step: 13
Training loss: 1.2671760320663452
Validation loss: 2.0101279007491244

Epoch: 206| Step: 0
Training loss: 0.8526363968849182
Validation loss: 1.9803707010002547

Epoch: 6| Step: 1
Training loss: 0.8330382704734802
Validation loss: 1.961794989083403

Epoch: 6| Step: 2
Training loss: 1.0796294212341309
Validation loss: 1.9569769905459495

Epoch: 6| Step: 3
Training loss: 0.626831591129303
Validation loss: 1.9670769732485536

Epoch: 6| Step: 4
Training loss: 1.4821275472640991
Validation loss: 1.9670612965860674

Epoch: 6| Step: 5
Training loss: 0.6954503059387207
Validation loss: 1.993134598578176

Epoch: 6| Step: 6
Training loss: 0.7901390194892883
Validation loss: 2.024009040606919

Epoch: 6| Step: 7
Training loss: 1.1926391124725342
Validation loss: 2.0326432886944024

Epoch: 6| Step: 8
Training loss: 0.8009140491485596
Validation loss: 2.09005634502698

Epoch: 6| Step: 9
Training loss: 1.2036174535751343
Validation loss: 2.1140775654905584

Epoch: 6| Step: 10
Training loss: 0.6848120093345642
Validation loss: 2.103756848201957

Epoch: 6| Step: 11
Training loss: 0.6708382964134216
Validation loss: 2.0987345864695888

Epoch: 6| Step: 12
Training loss: 1.2303882837295532
Validation loss: 2.0810557796109106

Epoch: 6| Step: 13
Training loss: 1.4170535802841187
Validation loss: 2.0778948927438385

Epoch: 207| Step: 0
Training loss: 0.5382493734359741
Validation loss: 2.0300179758379535

Epoch: 6| Step: 1
Training loss: 1.100743293762207
Validation loss: 2.002156816503053

Epoch: 6| Step: 2
Training loss: 1.2431249618530273
Validation loss: 1.986289434535529

Epoch: 6| Step: 3
Training loss: 0.58763188123703
Validation loss: 1.9933836229385868

Epoch: 6| Step: 4
Training loss: 1.012842059135437
Validation loss: 2.0111780346080823

Epoch: 6| Step: 5
Training loss: 0.738243043422699
Validation loss: 2.0355488087541316

Epoch: 6| Step: 6
Training loss: 1.259139060974121
Validation loss: 2.040559148275724

Epoch: 6| Step: 7
Training loss: 0.3114122152328491
Validation loss: 2.0718355101923787

Epoch: 6| Step: 8
Training loss: 0.8741964101791382
Validation loss: 2.0667862264058923

Epoch: 6| Step: 9
Training loss: 0.8992397785186768
Validation loss: 2.058906352648171

Epoch: 6| Step: 10
Training loss: 1.0144343376159668
Validation loss: 2.0602511898163827

Epoch: 6| Step: 11
Training loss: 0.7064903974533081
Validation loss: 2.0581932516508203

Epoch: 6| Step: 12
Training loss: 1.5214004516601562
Validation loss: 2.0286906214170557

Epoch: 6| Step: 13
Training loss: 1.9285916090011597
Validation loss: 2.034624186895227

Epoch: 208| Step: 0
Training loss: 0.7362526655197144
Validation loss: 2.0187100697589178

Epoch: 6| Step: 1
Training loss: 0.8013108372688293
Validation loss: 2.005220628553821

Epoch: 6| Step: 2
Training loss: 1.0130541324615479
Validation loss: 1.958003149237684

Epoch: 6| Step: 3
Training loss: 1.386199712753296
Validation loss: 1.9625372450838807

Epoch: 6| Step: 4
Training loss: 0.8591887950897217
Validation loss: 1.9756585321118754

Epoch: 6| Step: 5
Training loss: 0.7553491592407227
Validation loss: 1.9545323515451083

Epoch: 6| Step: 6
Training loss: 1.278261661529541
Validation loss: 1.9796196542760378

Epoch: 6| Step: 7
Training loss: 1.1041595935821533
Validation loss: 2.0212958307676416

Epoch: 6| Step: 8
Training loss: 1.2525089979171753
Validation loss: 2.016340337773805

Epoch: 6| Step: 9
Training loss: 0.7434709668159485
Validation loss: 2.057578408589927

Epoch: 6| Step: 10
Training loss: 0.6767982840538025
Validation loss: 2.0732652474475164

Epoch: 6| Step: 11
Training loss: 0.8604552745819092
Validation loss: 2.087116769565049

Epoch: 6| Step: 12
Training loss: 0.609024703502655
Validation loss: 2.084731040462371

Epoch: 6| Step: 13
Training loss: 0.75069260597229
Validation loss: 2.0608982911673923

Epoch: 209| Step: 0
Training loss: 1.3577141761779785
Validation loss: 2.020191108026812

Epoch: 6| Step: 1
Training loss: 0.9691044688224792
Validation loss: 2.0093535454042497

Epoch: 6| Step: 2
Training loss: 0.9608383774757385
Validation loss: 1.980632310272545

Epoch: 6| Step: 3
Training loss: 0.973003625869751
Validation loss: 1.9634704448843514

Epoch: 6| Step: 4
Training loss: 0.9736149311065674
Validation loss: 1.9745325196173884

Epoch: 6| Step: 5
Training loss: 0.8625519275665283
Validation loss: 1.971888316574917

Epoch: 6| Step: 6
Training loss: 0.8218722939491272
Validation loss: 1.9788256511893323

Epoch: 6| Step: 7
Training loss: 1.0413659811019897
Validation loss: 1.986460143519986

Epoch: 6| Step: 8
Training loss: 0.5163702964782715
Validation loss: 2.0241454801251813

Epoch: 6| Step: 9
Training loss: 0.6628559827804565
Validation loss: 2.0441590380925003

Epoch: 6| Step: 10
Training loss: 1.1201703548431396
Validation loss: 2.0665286523039623

Epoch: 6| Step: 11
Training loss: 0.3858070373535156
Validation loss: 2.0892651465631302

Epoch: 6| Step: 12
Training loss: 0.7629685401916504
Validation loss: 2.1175629272255847

Epoch: 6| Step: 13
Training loss: 1.2690144777297974
Validation loss: 2.0784988941684848

Epoch: 210| Step: 0
Training loss: 1.3692901134490967
Validation loss: 2.022067489162568

Epoch: 6| Step: 1
Training loss: 0.6706022024154663
Validation loss: 1.9769498943000712

Epoch: 6| Step: 2
Training loss: 0.5596534013748169
Validation loss: 1.9439410163510231

Epoch: 6| Step: 3
Training loss: 0.8391127586364746
Validation loss: 1.9505839399112168

Epoch: 6| Step: 4
Training loss: 0.872724711894989
Validation loss: 1.9729710701973207

Epoch: 6| Step: 5
Training loss: 0.7515887022018433
Validation loss: 1.9699019719195623

Epoch: 6| Step: 6
Training loss: 1.0938360691070557
Validation loss: 2.003313297866493

Epoch: 6| Step: 7
Training loss: 0.8305320739746094
Validation loss: 2.065538731954431

Epoch: 6| Step: 8
Training loss: 1.1858967542648315
Validation loss: 2.086943011130056

Epoch: 6| Step: 9
Training loss: 1.365401268005371
Validation loss: 2.1206210723487278

Epoch: 6| Step: 10
Training loss: 0.6761321425437927
Validation loss: 2.099202803386155

Epoch: 6| Step: 11
Training loss: 0.9776293635368347
Validation loss: 2.09771801066655

Epoch: 6| Step: 12
Training loss: 0.8281693458557129
Validation loss: 2.070322923762824

Epoch: 6| Step: 13
Training loss: 0.5467023849487305
Validation loss: 2.0333391363902757

Epoch: 211| Step: 0
Training loss: 0.9096060395240784
Validation loss: 2.025981838985156

Epoch: 6| Step: 1
Training loss: 0.6825344562530518
Validation loss: 2.015479596712256

Epoch: 6| Step: 2
Training loss: 1.1742339134216309
Validation loss: 2.0105105741049654

Epoch: 6| Step: 3
Training loss: 0.9857909679412842
Validation loss: 2.0202171623065905

Epoch: 6| Step: 4
Training loss: 0.6762456893920898
Validation loss: 2.028225580851237

Epoch: 6| Step: 5
Training loss: 0.8516919612884521
Validation loss: 2.061152494081887

Epoch: 6| Step: 6
Training loss: 1.3733062744140625
Validation loss: 2.0559207265095045

Epoch: 6| Step: 7
Training loss: 0.7760379314422607
Validation loss: 2.0465346741419967

Epoch: 6| Step: 8
Training loss: 0.525259256362915
Validation loss: 2.040676716835268

Epoch: 6| Step: 9
Training loss: 1.2878737449645996
Validation loss: 2.0267533281798005

Epoch: 6| Step: 10
Training loss: 0.6012480854988098
Validation loss: 2.000189550461308

Epoch: 6| Step: 11
Training loss: 1.335998773574829
Validation loss: 2.0127006717907485

Epoch: 6| Step: 12
Training loss: 0.7295411229133606
Validation loss: 2.0073626951504777

Epoch: 6| Step: 13
Training loss: 0.8033078908920288
Validation loss: 2.023981628879424

Epoch: 212| Step: 0
Training loss: 0.9469805955886841
Validation loss: 2.011477936980545

Epoch: 6| Step: 1
Training loss: 1.2188756465911865
Validation loss: 1.9640237682609147

Epoch: 6| Step: 2
Training loss: 0.8202127814292908
Validation loss: 1.9551751536707724

Epoch: 6| Step: 3
Training loss: 0.8961191177368164
Validation loss: 1.967032455628918

Epoch: 6| Step: 4
Training loss: 0.7438362836837769
Validation loss: 1.9451180581123597

Epoch: 6| Step: 5
Training loss: 0.6188293695449829
Validation loss: 1.9452628115172028

Epoch: 6| Step: 6
Training loss: 0.8135295510292053
Validation loss: 1.959824651800176

Epoch: 6| Step: 7
Training loss: 0.9234915971755981
Validation loss: 2.002863037970758

Epoch: 6| Step: 8
Training loss: 1.3689547777175903
Validation loss: 2.040765194482701

Epoch: 6| Step: 9
Training loss: 0.6470156908035278
Validation loss: 2.062823712184865

Epoch: 6| Step: 10
Training loss: 0.7362989783287048
Validation loss: 2.1000496008062877

Epoch: 6| Step: 11
Training loss: 0.9265103340148926
Validation loss: 2.1006264968584945

Epoch: 6| Step: 12
Training loss: 1.4706121683120728
Validation loss: 2.115773129206832

Epoch: 6| Step: 13
Training loss: 0.6418454647064209
Validation loss: 2.0975576562266194

Epoch: 213| Step: 0
Training loss: 1.0112720727920532
Validation loss: 2.048967907505651

Epoch: 6| Step: 1
Training loss: 0.9482588768005371
Validation loss: 2.0047287992251817

Epoch: 6| Step: 2
Training loss: 0.9867172241210938
Validation loss: 2.0138958756641676

Epoch: 6| Step: 3
Training loss: 0.8492300510406494
Validation loss: 2.0009855519058886

Epoch: 6| Step: 4
Training loss: 0.9260344505310059
Validation loss: 1.9684630324763637

Epoch: 6| Step: 5
Training loss: 1.082007646560669
Validation loss: 1.9661182408691735

Epoch: 6| Step: 6
Training loss: 0.6055063009262085
Validation loss: 1.941503006924865

Epoch: 6| Step: 7
Training loss: 1.1261489391326904
Validation loss: 1.962328246844712

Epoch: 6| Step: 8
Training loss: 0.8564229011535645
Validation loss: 1.9434270858764648

Epoch: 6| Step: 9
Training loss: 1.141789436340332
Validation loss: 1.968671452614569

Epoch: 6| Step: 10
Training loss: 0.8029360175132751
Validation loss: 1.9726001857429423

Epoch: 6| Step: 11
Training loss: 0.5664113759994507
Validation loss: 1.9838652239050916

Epoch: 6| Step: 12
Training loss: 0.5116652250289917
Validation loss: 2.001850767802167

Epoch: 6| Step: 13
Training loss: 0.6730197668075562
Validation loss: 2.0100611691833823

Epoch: 214| Step: 0
Training loss: 0.481856107711792
Validation loss: 2.0054056311166413

Epoch: 6| Step: 1
Training loss: 0.5635384321212769
Validation loss: 1.9995061479588991

Epoch: 6| Step: 2
Training loss: 1.1157996654510498
Validation loss: 2.04015794620719

Epoch: 6| Step: 3
Training loss: 0.40960848331451416
Validation loss: 2.065791071102183

Epoch: 6| Step: 4
Training loss: 1.0179038047790527
Validation loss: 2.0621196403298327

Epoch: 6| Step: 5
Training loss: 0.4622254967689514
Validation loss: 2.0737977335529942

Epoch: 6| Step: 6
Training loss: 0.8610467910766602
Validation loss: 2.03256574497428

Epoch: 6| Step: 7
Training loss: 1.6726570129394531
Validation loss: 2.03409013184168

Epoch: 6| Step: 8
Training loss: 0.9069795608520508
Validation loss: 1.9800598018912858

Epoch: 6| Step: 9
Training loss: 0.7976793050765991
Validation loss: 1.9889150306742678

Epoch: 6| Step: 10
Training loss: 1.2574715614318848
Validation loss: 1.9695851905371553

Epoch: 6| Step: 11
Training loss: 0.954127311706543
Validation loss: 1.95802769994223

Epoch: 6| Step: 12
Training loss: 0.8654993772506714
Validation loss: 1.9295085976200719

Epoch: 6| Step: 13
Training loss: 0.35590922832489014
Validation loss: 1.9404663770429549

Epoch: 215| Step: 0
Training loss: 0.842764675617218
Validation loss: 1.945107957368256

Epoch: 6| Step: 1
Training loss: 0.8436353802680969
Validation loss: 1.9343852932735155

Epoch: 6| Step: 2
Training loss: 0.9079815745353699
Validation loss: 1.9910743185268935

Epoch: 6| Step: 3
Training loss: 1.0103627443313599
Validation loss: 2.0467950785031883

Epoch: 6| Step: 4
Training loss: 0.7632573843002319
Validation loss: 2.087004448777886

Epoch: 6| Step: 5
Training loss: 0.43309029936790466
Validation loss: 2.0722832525930097

Epoch: 6| Step: 6
Training loss: 1.417356252670288
Validation loss: 2.0146291050859677

Epoch: 6| Step: 7
Training loss: 1.2828187942504883
Validation loss: 1.986084525303174

Epoch: 6| Step: 8
Training loss: 0.7674316167831421
Validation loss: 1.9717022488194127

Epoch: 6| Step: 9
Training loss: 1.1211700439453125
Validation loss: 1.9553598050148255

Epoch: 6| Step: 10
Training loss: 0.8799165487289429
Validation loss: 1.8946461036641111

Epoch: 6| Step: 11
Training loss: 0.3133496046066284
Validation loss: 1.91630797232351

Epoch: 6| Step: 12
Training loss: 0.7383961081504822
Validation loss: 1.9425350619900612

Epoch: 6| Step: 13
Training loss: 0.6210813522338867
Validation loss: 1.9201120304804977

Epoch: 216| Step: 0
Training loss: 1.4485833644866943
Validation loss: 1.9317395456375615

Epoch: 6| Step: 1
Training loss: 0.563448429107666
Validation loss: 1.9974576068180863

Epoch: 6| Step: 2
Training loss: 0.5511798858642578
Validation loss: 2.025071550441045

Epoch: 6| Step: 3
Training loss: 1.1247034072875977
Validation loss: 2.0403591586697485

Epoch: 6| Step: 4
Training loss: 0.8045233488082886
Validation loss: 2.0499177517429477

Epoch: 6| Step: 5
Training loss: 0.6429746150970459
Validation loss: 2.040353657096945

Epoch: 6| Step: 6
Training loss: 0.6663766503334045
Validation loss: 2.031175862076462

Epoch: 6| Step: 7
Training loss: 0.7150713205337524
Validation loss: 2.0055791126784457

Epoch: 6| Step: 8
Training loss: 1.0137183666229248
Validation loss: 1.9692378646583968

Epoch: 6| Step: 9
Training loss: 0.4564809203147888
Validation loss: 1.9595267054855183

Epoch: 6| Step: 10
Training loss: 0.637341320514679
Validation loss: 1.9621758512271348

Epoch: 6| Step: 11
Training loss: 0.9624217748641968
Validation loss: 1.9886035765371015

Epoch: 6| Step: 12
Training loss: 1.542189359664917
Validation loss: 1.961906874051658

Epoch: 6| Step: 13
Training loss: 0.35536736249923706
Validation loss: 1.9968868301760765

Epoch: 217| Step: 0
Training loss: 0.664995014667511
Validation loss: 1.9981205335227392

Epoch: 6| Step: 1
Training loss: 1.036816120147705
Validation loss: 1.9867814343462709

Epoch: 6| Step: 2
Training loss: 0.6571217179298401
Validation loss: 1.9727310134518532

Epoch: 6| Step: 3
Training loss: 0.6376331448554993
Validation loss: 2.012093056914627

Epoch: 6| Step: 4
Training loss: 0.8557957410812378
Validation loss: 1.9978306921579505

Epoch: 6| Step: 5
Training loss: 0.9793137311935425
Validation loss: 2.0082066238567395

Epoch: 6| Step: 6
Training loss: 0.8226246237754822
Validation loss: 2.0386173853310208

Epoch: 6| Step: 7
Training loss: 1.0583999156951904
Validation loss: 2.047432609783706

Epoch: 6| Step: 8
Training loss: 0.5951530337333679
Validation loss: 2.0710029499505156

Epoch: 6| Step: 9
Training loss: 1.3643276691436768
Validation loss: 2.0959390747931694

Epoch: 6| Step: 10
Training loss: 0.6383051872253418
Validation loss: 2.0676895110837874

Epoch: 6| Step: 11
Training loss: 0.8292962312698364
Validation loss: 2.0794487512239845

Epoch: 6| Step: 12
Training loss: 0.37970179319381714
Validation loss: 2.0695971353079683

Epoch: 6| Step: 13
Training loss: 1.1379570960998535
Validation loss: 2.070326938424059

Epoch: 218| Step: 0
Training loss: 0.6954008340835571
Validation loss: 2.052285635343162

Epoch: 6| Step: 1
Training loss: 0.5292045474052429
Validation loss: 2.0243897309867283

Epoch: 6| Step: 2
Training loss: 0.6649187803268433
Validation loss: 2.029516540547853

Epoch: 6| Step: 3
Training loss: 0.5375728607177734
Validation loss: 1.987085965371901

Epoch: 6| Step: 4
Training loss: 0.5873095393180847
Validation loss: 2.0000862370255175

Epoch: 6| Step: 5
Training loss: 0.8075350522994995
Validation loss: 2.0129897081723778

Epoch: 6| Step: 6
Training loss: 0.8754794597625732
Validation loss: 2.018589950376941

Epoch: 6| Step: 7
Training loss: 0.7131447792053223
Validation loss: 1.982037708323489

Epoch: 6| Step: 8
Training loss: 0.6723775267601013
Validation loss: 1.9762501844795801

Epoch: 6| Step: 9
Training loss: 1.2631504535675049
Validation loss: 1.959821016557755

Epoch: 6| Step: 10
Training loss: 1.0393513441085815
Validation loss: 1.9609611957303938

Epoch: 6| Step: 11
Training loss: 0.538731575012207
Validation loss: 1.996123940713944

Epoch: 6| Step: 12
Training loss: 1.3024308681488037
Validation loss: 1.9787205444869174

Epoch: 6| Step: 13
Training loss: 0.9072954654693604
Validation loss: 2.0177684458353187

Epoch: 219| Step: 0
Training loss: 0.8871030807495117
Validation loss: 2.033047869641294

Epoch: 6| Step: 1
Training loss: 1.1444718837738037
Validation loss: 2.016631685277467

Epoch: 6| Step: 2
Training loss: 0.4544678330421448
Validation loss: 2.007984212649766

Epoch: 6| Step: 3
Training loss: 0.4814344644546509
Validation loss: 2.018889137493667

Epoch: 6| Step: 4
Training loss: 0.666737973690033
Validation loss: 2.022858870926724

Epoch: 6| Step: 5
Training loss: 0.6259033679962158
Validation loss: 2.0262141766086703

Epoch: 6| Step: 6
Training loss: 0.9617000818252563
Validation loss: 1.9911217830514396

Epoch: 6| Step: 7
Training loss: 0.5635547041893005
Validation loss: 1.9739542276628557

Epoch: 6| Step: 8
Training loss: 1.187530279159546
Validation loss: 2.018756297326857

Epoch: 6| Step: 9
Training loss: 0.9589847326278687
Validation loss: 2.0071962700095227

Epoch: 6| Step: 10
Training loss: 1.1021488904953003
Validation loss: 1.994386185881912

Epoch: 6| Step: 11
Training loss: 0.4674379825592041
Validation loss: 2.082414775766352

Epoch: 6| Step: 12
Training loss: 0.696418285369873
Validation loss: 2.0650949478149414

Epoch: 6| Step: 13
Training loss: 1.3863844871520996
Validation loss: 2.0682493307257213

Epoch: 220| Step: 0
Training loss: 0.7910791039466858
Validation loss: 2.027351410158219

Epoch: 6| Step: 1
Training loss: 1.0847556591033936
Validation loss: 2.0232339956427134

Epoch: 6| Step: 2
Training loss: 0.5751306414604187
Validation loss: 2.0086170652861237

Epoch: 6| Step: 3
Training loss: 0.7090335488319397
Validation loss: 2.0002485513687134

Epoch: 6| Step: 4
Training loss: 1.2294957637786865
Validation loss: 1.9821512391490321

Epoch: 6| Step: 5
Training loss: 1.5262489318847656
Validation loss: 2.0134181989136564

Epoch: 6| Step: 6
Training loss: 0.5056052803993225
Validation loss: 2.0186568601157076

Epoch: 6| Step: 7
Training loss: 0.3907965123653412
Validation loss: 1.9950072329531434

Epoch: 6| Step: 8
Training loss: 0.6524537801742554
Validation loss: 2.0249091553431686

Epoch: 6| Step: 9
Training loss: 0.947162389755249
Validation loss: 2.0286136750252015

Epoch: 6| Step: 10
Training loss: 1.0046977996826172
Validation loss: 2.0399128185805453

Epoch: 6| Step: 11
Training loss: 0.5062295198440552
Validation loss: 2.0453099076465895

Epoch: 6| Step: 12
Training loss: 0.5601398348808289
Validation loss: 2.039085357419906

Epoch: 6| Step: 13
Training loss: 0.5896799564361572
Validation loss: 2.033614025321058

Epoch: 221| Step: 0
Training loss: 0.5893932580947876
Validation loss: 1.9963066475365752

Epoch: 6| Step: 1
Training loss: 1.2959420680999756
Validation loss: 1.977764311657157

Epoch: 6| Step: 2
Training loss: 0.8338794112205505
Validation loss: 1.948004291903588

Epoch: 6| Step: 3
Training loss: 0.4585719704627991
Validation loss: 1.9446723025332215

Epoch: 6| Step: 4
Training loss: 0.984134316444397
Validation loss: 1.9589921274492819

Epoch: 6| Step: 5
Training loss: 0.6504040956497192
Validation loss: 1.9849385433299567

Epoch: 6| Step: 6
Training loss: 0.6592690944671631
Validation loss: 1.9557524496509182

Epoch: 6| Step: 7
Training loss: 0.5453832149505615
Validation loss: 1.9826608665527836

Epoch: 6| Step: 8
Training loss: 1.073042392730713
Validation loss: 2.0272323854507937

Epoch: 6| Step: 9
Training loss: 1.4177427291870117
Validation loss: 2.083978783699774

Epoch: 6| Step: 10
Training loss: 0.9191091656684875
Validation loss: 2.1021311924021733

Epoch: 6| Step: 11
Training loss: 0.437638521194458
Validation loss: 2.0643980785082747

Epoch: 6| Step: 12
Training loss: 0.5822393894195557
Validation loss: 2.136778764827277

Epoch: 6| Step: 13
Training loss: 0.9390403032302856
Validation loss: 2.0778776573878464

Epoch: 222| Step: 0
Training loss: 1.1192212104797363
Validation loss: 2.011657581534437

Epoch: 6| Step: 1
Training loss: 0.5324752926826477
Validation loss: 1.9769734387756677

Epoch: 6| Step: 2
Training loss: 0.7063430547714233
Validation loss: 1.9549705495116532

Epoch: 6| Step: 3
Training loss: 0.6743453741073608
Validation loss: 1.9303331964759416

Epoch: 6| Step: 4
Training loss: 0.8430172204971313
Validation loss: 1.9402021220935288

Epoch: 6| Step: 5
Training loss: 0.8393747210502625
Validation loss: 1.924003093473373

Epoch: 6| Step: 6
Training loss: 0.5697383880615234
Validation loss: 1.9518845978603567

Epoch: 6| Step: 7
Training loss: 0.5674058198928833
Validation loss: 2.0100262588070286

Epoch: 6| Step: 8
Training loss: 1.2737116813659668
Validation loss: 2.0533663393348776

Epoch: 6| Step: 9
Training loss: 1.0181562900543213
Validation loss: 2.049051042525999

Epoch: 6| Step: 10
Training loss: 0.5206746459007263
Validation loss: 2.021880690769483

Epoch: 6| Step: 11
Training loss: 1.0775690078735352
Validation loss: 1.9711393938269666

Epoch: 6| Step: 12
Training loss: 0.7591678500175476
Validation loss: 1.9544424895317323

Epoch: 6| Step: 13
Training loss: 0.9709934592247009
Validation loss: 1.930011285248623

Epoch: 223| Step: 0
Training loss: 0.4309737980365753
Validation loss: 1.9150737280486732

Epoch: 6| Step: 1
Training loss: 0.6340655088424683
Validation loss: 1.9369455101669475

Epoch: 6| Step: 2
Training loss: 1.0788767337799072
Validation loss: 1.9444707785883257

Epoch: 6| Step: 3
Training loss: 0.5041237473487854
Validation loss: 1.943208896985618

Epoch: 6| Step: 4
Training loss: 1.3333852291107178
Validation loss: 1.9887934474534885

Epoch: 6| Step: 5
Training loss: 0.9977591037750244
Validation loss: 2.0171385260038477

Epoch: 6| Step: 6
Training loss: 1.1273932456970215
Validation loss: 2.025180700004742

Epoch: 6| Step: 7
Training loss: 1.2789299488067627
Validation loss: 2.035821727527085

Epoch: 6| Step: 8
Training loss: 0.6013575792312622
Validation loss: 2.048579433912872

Epoch: 6| Step: 9
Training loss: 0.8055052757263184
Validation loss: 2.036993649698073

Epoch: 6| Step: 10
Training loss: 0.4892778992652893
Validation loss: 1.9891249723331903

Epoch: 6| Step: 11
Training loss: 0.6712042093276978
Validation loss: 1.9838462170734201

Epoch: 6| Step: 12
Training loss: 0.9133065342903137
Validation loss: 1.9532989994172127

Epoch: 6| Step: 13
Training loss: 0.7365748882293701
Validation loss: 1.9481344248658867

Epoch: 224| Step: 0
Training loss: 0.6722570061683655
Validation loss: 1.93671174715924

Epoch: 6| Step: 1
Training loss: 1.0901503562927246
Validation loss: 1.922094516856696

Epoch: 6| Step: 2
Training loss: 0.5919506549835205
Validation loss: 1.9310889859353342

Epoch: 6| Step: 3
Training loss: 0.43816298246383667
Validation loss: 1.9308998636020127

Epoch: 6| Step: 4
Training loss: 1.215832233428955
Validation loss: 1.9605850711945565

Epoch: 6| Step: 5
Training loss: 1.2522225379943848
Validation loss: 1.9845679254942044

Epoch: 6| Step: 6
Training loss: 0.6071610450744629
Validation loss: 1.9903529459430325

Epoch: 6| Step: 7
Training loss: 0.7984729409217834
Validation loss: 1.9908097585042317

Epoch: 6| Step: 8
Training loss: 0.743777871131897
Validation loss: 1.972474136660176

Epoch: 6| Step: 9
Training loss: 0.5030855536460876
Validation loss: 1.9678962717774093

Epoch: 6| Step: 10
Training loss: 1.177676796913147
Validation loss: 2.010479311789236

Epoch: 6| Step: 11
Training loss: 0.836276650428772
Validation loss: 2.0091984477094424

Epoch: 6| Step: 12
Training loss: 0.9133111834526062
Validation loss: 1.9760227190550936

Epoch: 6| Step: 13
Training loss: 0.46087169647216797
Validation loss: 1.9971309592646938

Epoch: 225| Step: 0
Training loss: 0.8137040138244629
Validation loss: 1.9736831136929092

Epoch: 6| Step: 1
Training loss: 1.0303242206573486
Validation loss: 1.9850290821444603

Epoch: 6| Step: 2
Training loss: 0.6417626738548279
Validation loss: 1.9837013508683892

Epoch: 6| Step: 3
Training loss: 0.6371766328811646
Validation loss: 1.9707941393698416

Epoch: 6| Step: 4
Training loss: 0.30627182126045227
Validation loss: 1.9349757035573323

Epoch: 6| Step: 5
Training loss: 0.6758917570114136
Validation loss: 1.9399590171793455

Epoch: 6| Step: 6
Training loss: 0.9762510657310486
Validation loss: 1.9329439952809324

Epoch: 6| Step: 7
Training loss: 0.6633570194244385
Validation loss: 1.9003618327520226

Epoch: 6| Step: 8
Training loss: 1.039340853691101
Validation loss: 1.9310687793198453

Epoch: 6| Step: 9
Training loss: 0.9060249328613281
Validation loss: 1.9239986385068586

Epoch: 6| Step: 10
Training loss: 0.5813252329826355
Validation loss: 1.9105268575811898

Epoch: 6| Step: 11
Training loss: 1.128708004951477
Validation loss: 1.9705198093127179

Epoch: 6| Step: 12
Training loss: 0.7660648822784424
Validation loss: 1.9688892902866486

Epoch: 6| Step: 13
Training loss: 0.5357593894004822
Validation loss: 2.030561865016978

Epoch: 226| Step: 0
Training loss: 0.57942795753479
Validation loss: 2.0035267440221642

Epoch: 6| Step: 1
Training loss: 1.1906195878982544
Validation loss: 2.0066043356413483

Epoch: 6| Step: 2
Training loss: 1.101100206375122
Validation loss: 1.9773988839118712

Epoch: 6| Step: 3
Training loss: 1.1020509004592896
Validation loss: 1.9350994120361984

Epoch: 6| Step: 4
Training loss: 0.8689131140708923
Validation loss: 1.9344239375924552

Epoch: 6| Step: 5
Training loss: 0.2983520030975342
Validation loss: 1.9331470971466393

Epoch: 6| Step: 6
Training loss: 0.8744680881500244
Validation loss: 1.928573727607727

Epoch: 6| Step: 7
Training loss: 0.5488672256469727
Validation loss: 1.9282341311054845

Epoch: 6| Step: 8
Training loss: 1.167755126953125
Validation loss: 1.9275067390934113

Epoch: 6| Step: 9
Training loss: 0.48099565505981445
Validation loss: 1.9529531489136398

Epoch: 6| Step: 10
Training loss: 0.7850171327590942
Validation loss: 1.929522233624612

Epoch: 6| Step: 11
Training loss: 0.5132720470428467
Validation loss: 1.9670596738015451

Epoch: 6| Step: 12
Training loss: 0.6353480219841003
Validation loss: 1.9586359070193382

Epoch: 6| Step: 13
Training loss: 0.542555570602417
Validation loss: 1.999908862575408

Epoch: 227| Step: 0
Training loss: 0.6584058403968811
Validation loss: 2.000973291294549

Epoch: 6| Step: 1
Training loss: 0.91290283203125
Validation loss: 2.0255001873098393

Epoch: 6| Step: 2
Training loss: 0.6305380463600159
Validation loss: 2.0566312241297897

Epoch: 6| Step: 3
Training loss: 0.44555002450942993
Validation loss: 2.053857967417727

Epoch: 6| Step: 4
Training loss: 0.7923171520233154
Validation loss: 2.042375082610756

Epoch: 6| Step: 5
Training loss: 0.7747880220413208
Validation loss: 1.9968151918021582

Epoch: 6| Step: 6
Training loss: 0.9290931224822998
Validation loss: 1.9724257299976964

Epoch: 6| Step: 7
Training loss: 0.6459870338439941
Validation loss: 1.935690369657291

Epoch: 6| Step: 8
Training loss: 1.0249075889587402
Validation loss: 1.9264419937646517

Epoch: 6| Step: 9
Training loss: 0.6275777220726013
Validation loss: 1.9240101281032767

Epoch: 6| Step: 10
Training loss: 0.7051255702972412
Validation loss: 1.9229831926284298

Epoch: 6| Step: 11
Training loss: 1.116520881652832
Validation loss: 1.9321555758035311

Epoch: 6| Step: 12
Training loss: 0.7270581126213074
Validation loss: 1.985743732862575

Epoch: 6| Step: 13
Training loss: 0.6003137826919556
Validation loss: 1.9622934582412883

Epoch: 228| Step: 0
Training loss: 0.6691868305206299
Validation loss: 1.9572190084765035

Epoch: 6| Step: 1
Training loss: 0.49627485871315
Validation loss: 1.955545335687617

Epoch: 6| Step: 2
Training loss: 0.7101553678512573
Validation loss: 1.9496046676430652

Epoch: 6| Step: 3
Training loss: 1.2661638259887695
Validation loss: 1.9404508811171337

Epoch: 6| Step: 4
Training loss: 0.292231023311615
Validation loss: 2.0230947438106743

Epoch: 6| Step: 5
Training loss: 1.0185328722000122
Validation loss: 2.000122421531267

Epoch: 6| Step: 6
Training loss: 0.4466073513031006
Validation loss: 2.00340788338774

Epoch: 6| Step: 7
Training loss: 0.9000989198684692
Validation loss: 2.001189266481707

Epoch: 6| Step: 8
Training loss: 1.028749704360962
Validation loss: 1.9623233964366298

Epoch: 6| Step: 9
Training loss: 0.8565912246704102
Validation loss: 1.963196539109753

Epoch: 6| Step: 10
Training loss: 0.5774545669555664
Validation loss: 1.9219176205255653

Epoch: 6| Step: 11
Training loss: 0.49461498856544495
Validation loss: 1.920280566779516

Epoch: 6| Step: 12
Training loss: 0.7784742116928101
Validation loss: 1.888080576414703

Epoch: 6| Step: 13
Training loss: 0.3906244933605194
Validation loss: 1.9067215868221816

Epoch: 229| Step: 0
Training loss: 0.3802361488342285
Validation loss: 1.906538373680525

Epoch: 6| Step: 1
Training loss: 0.624894380569458
Validation loss: 1.8755729583001906

Epoch: 6| Step: 2
Training loss: 0.9757253527641296
Validation loss: 1.8863634704261698

Epoch: 6| Step: 3
Training loss: 0.8419538736343384
Validation loss: 1.905369935497161

Epoch: 6| Step: 4
Training loss: 0.6570497751235962
Validation loss: 1.8903001085404427

Epoch: 6| Step: 5
Training loss: 0.33532091975212097
Validation loss: 1.9257517809508948

Epoch: 6| Step: 6
Training loss: 0.3307369351387024
Validation loss: 1.922076504717591

Epoch: 6| Step: 7
Training loss: 0.5906454920768738
Validation loss: 1.9169963277796263

Epoch: 6| Step: 8
Training loss: 1.076589584350586
Validation loss: 1.9436487177366852

Epoch: 6| Step: 9
Training loss: 0.5568464994430542
Validation loss: 2.003804458084927

Epoch: 6| Step: 10
Training loss: 0.5477306246757507
Validation loss: 2.005088908697969

Epoch: 6| Step: 11
Training loss: 1.1450612545013428
Validation loss: 2.053929223809191

Epoch: 6| Step: 12
Training loss: 1.1937627792358398
Validation loss: 1.9985739825874247

Epoch: 6| Step: 13
Training loss: 1.0824236869812012
Validation loss: 1.963045476585306

Epoch: 230| Step: 0
Training loss: 0.7984827160835266
Validation loss: 1.9362253348032634

Epoch: 6| Step: 1
Training loss: 0.6472465991973877
Validation loss: 1.936212557618336

Epoch: 6| Step: 2
Training loss: 0.7205933928489685
Validation loss: 1.9217819231812672

Epoch: 6| Step: 3
Training loss: 0.4315611720085144
Validation loss: 1.9032955502951017

Epoch: 6| Step: 4
Training loss: 0.5223708748817444
Validation loss: 1.9278858553978704

Epoch: 6| Step: 5
Training loss: 0.9739787578582764
Validation loss: 1.9194394080869612

Epoch: 6| Step: 6
Training loss: 1.00734543800354
Validation loss: 1.928414499887856

Epoch: 6| Step: 7
Training loss: 0.5571246147155762
Validation loss: 1.915699928037582

Epoch: 6| Step: 8
Training loss: 0.4707142114639282
Validation loss: 1.9037355710101385

Epoch: 6| Step: 9
Training loss: 0.5800289511680603
Validation loss: 1.9439175346846223

Epoch: 6| Step: 10
Training loss: 0.9947304725646973
Validation loss: 1.9268796802848898

Epoch: 6| Step: 11
Training loss: 0.8131904602050781
Validation loss: 1.933878565347323

Epoch: 6| Step: 12
Training loss: 0.981841504573822
Validation loss: 1.9181894961223807

Epoch: 6| Step: 13
Training loss: 0.2033953070640564
Validation loss: 1.9114920528986121

Epoch: 231| Step: 0
Training loss: 0.5636699199676514
Validation loss: 1.9122250182654268

Epoch: 6| Step: 1
Training loss: 0.903652548789978
Validation loss: 1.9153007435542282

Epoch: 6| Step: 2
Training loss: 0.4125533998012543
Validation loss: 1.9418687487161288

Epoch: 6| Step: 3
Training loss: 0.833577036857605
Validation loss: 1.9423582887136808

Epoch: 6| Step: 4
Training loss: 1.3238770961761475
Validation loss: 1.9205547827546314

Epoch: 6| Step: 5
Training loss: 0.6444671154022217
Validation loss: 1.930744037833265

Epoch: 6| Step: 6
Training loss: 0.5557959675788879
Validation loss: 1.9322038696658226

Epoch: 6| Step: 7
Training loss: 0.6997072100639343
Validation loss: 1.932935002029583

Epoch: 6| Step: 8
Training loss: 0.32874196767807007
Validation loss: 1.9401585619936708

Epoch: 6| Step: 9
Training loss: 0.5548014640808105
Validation loss: 1.9842343356019707

Epoch: 6| Step: 10
Training loss: 0.9906021952629089
Validation loss: 1.9886171176869383

Epoch: 6| Step: 11
Training loss: 0.7175297737121582
Validation loss: 2.017011096400599

Epoch: 6| Step: 12
Training loss: 0.6234365701675415
Validation loss: 2.018110966169706

Epoch: 6| Step: 13
Training loss: 0.6446132659912109
Validation loss: 2.0019973452373216

Epoch: 232| Step: 0
Training loss: 0.37525105476379395
Validation loss: 1.9826682242014075

Epoch: 6| Step: 1
Training loss: 1.045412302017212
Validation loss: 1.9321658149842293

Epoch: 6| Step: 2
Training loss: 0.26215660572052
Validation loss: 1.8933833029962355

Epoch: 6| Step: 3
Training loss: 0.8898823261260986
Validation loss: 1.883348814902767

Epoch: 6| Step: 4
Training loss: 0.7104995250701904
Validation loss: 1.876764928140948

Epoch: 6| Step: 5
Training loss: 0.7031548023223877
Validation loss: 1.8698004753358903

Epoch: 6| Step: 6
Training loss: 0.650518536567688
Validation loss: 1.8839871011754519

Epoch: 6| Step: 7
Training loss: 0.9093611240386963
Validation loss: 1.9120663442919332

Epoch: 6| Step: 8
Training loss: 1.143568754196167
Validation loss: 1.9368181946457073

Epoch: 6| Step: 9
Training loss: 0.511760950088501
Validation loss: 1.9783917780845397

Epoch: 6| Step: 10
Training loss: 0.812854528427124
Validation loss: 1.9805591516597296

Epoch: 6| Step: 11
Training loss: 0.83424973487854
Validation loss: 1.9682557377763974

Epoch: 6| Step: 12
Training loss: 0.4769095182418823
Validation loss: 1.980638119482225

Epoch: 6| Step: 13
Training loss: 0.979171633720398
Validation loss: 1.9783676567898

Epoch: 233| Step: 0
Training loss: 0.7452049255371094
Validation loss: 1.9749104822835615

Epoch: 6| Step: 1
Training loss: 0.754492998123169
Validation loss: 1.954207287039808

Epoch: 6| Step: 2
Training loss: 0.5880351662635803
Validation loss: 1.94586173565157

Epoch: 6| Step: 3
Training loss: 1.0234242677688599
Validation loss: 1.9333461664056266

Epoch: 6| Step: 4
Training loss: 0.5415449142456055
Validation loss: 1.9033942863505373

Epoch: 6| Step: 5
Training loss: 0.8784610033035278
Validation loss: 1.8786167201175485

Epoch: 6| Step: 6
Training loss: 0.4658997058868408
Validation loss: 1.8777853660686041

Epoch: 6| Step: 7
Training loss: 0.7039113640785217
Validation loss: 1.8910022756104827

Epoch: 6| Step: 8
Training loss: 0.3713907301425934
Validation loss: 1.8894347952258201

Epoch: 6| Step: 9
Training loss: 0.645107626914978
Validation loss: 1.9659146801117928

Epoch: 6| Step: 10
Training loss: 0.7450150847434998
Validation loss: 1.9834900979072816

Epoch: 6| Step: 11
Training loss: 1.0984888076782227
Validation loss: 2.0085154194985666

Epoch: 6| Step: 12
Training loss: 0.4412190914154053
Validation loss: 1.9764357753979263

Epoch: 6| Step: 13
Training loss: 1.293626308441162
Validation loss: 1.9972122189819173

Epoch: 234| Step: 0
Training loss: 0.8730957508087158
Validation loss: 1.9671967362844816

Epoch: 6| Step: 1
Training loss: 0.3793058693408966
Validation loss: 1.969287383940912

Epoch: 6| Step: 2
Training loss: 0.48681479692459106
Validation loss: 1.9812179534666

Epoch: 6| Step: 3
Training loss: 0.5065931081771851
Validation loss: 1.9259206056594849

Epoch: 6| Step: 4
Training loss: 0.8582128882408142
Validation loss: 1.9585804836724394

Epoch: 6| Step: 5
Training loss: 0.7729378938674927
Validation loss: 1.9284703603354834

Epoch: 6| Step: 6
Training loss: 1.1137827634811401
Validation loss: 1.9261061978596512

Epoch: 6| Step: 7
Training loss: 1.0534584522247314
Validation loss: 1.9673351613424157

Epoch: 6| Step: 8
Training loss: 0.6644545197486877
Validation loss: 1.9793392996634207

Epoch: 6| Step: 9
Training loss: 0.41408801078796387
Validation loss: 1.985731779888112

Epoch: 6| Step: 10
Training loss: 0.46691954135894775
Validation loss: 1.974042925783383

Epoch: 6| Step: 11
Training loss: 1.008292317390442
Validation loss: 1.9661946873511038

Epoch: 6| Step: 12
Training loss: 0.5201308131217957
Validation loss: 1.934731137367987

Epoch: 6| Step: 13
Training loss: 0.9595661163330078
Validation loss: 1.9237023502267816

Epoch: 235| Step: 0
Training loss: 0.9282742738723755
Validation loss: 1.9122274998695619

Epoch: 6| Step: 1
Training loss: 0.6289771795272827
Validation loss: 1.9042241983516242

Epoch: 6| Step: 2
Training loss: 0.5911492109298706
Validation loss: 1.9378223573007891

Epoch: 6| Step: 3
Training loss: 0.6497600078582764
Validation loss: 1.92985628497216

Epoch: 6| Step: 4
Training loss: 0.8241310119628906
Validation loss: 1.93537478293142

Epoch: 6| Step: 5
Training loss: 0.6895281076431274
Validation loss: 1.9766553653183805

Epoch: 6| Step: 6
Training loss: 0.565214991569519
Validation loss: 1.978605757477463

Epoch: 6| Step: 7
Training loss: 1.1692171096801758
Validation loss: 1.9985058282011299

Epoch: 6| Step: 8
Training loss: 0.5451034307479858
Validation loss: 1.9405670883835002

Epoch: 6| Step: 9
Training loss: 0.5269852876663208
Validation loss: 1.9651085099866312

Epoch: 6| Step: 10
Training loss: 0.7519000768661499
Validation loss: 1.939949934200574

Epoch: 6| Step: 11
Training loss: 0.4703085422515869
Validation loss: 1.9222569452819003

Epoch: 6| Step: 12
Training loss: 0.8613758683204651
Validation loss: 1.914899879886258

Epoch: 6| Step: 13
Training loss: 0.8603665232658386
Validation loss: 1.9053242232209893

Epoch: 236| Step: 0
Training loss: 0.859594464302063
Validation loss: 1.9286299187649962

Epoch: 6| Step: 1
Training loss: 0.6125097274780273
Validation loss: 1.9189216193332468

Epoch: 6| Step: 2
Training loss: 0.9062871932983398
Validation loss: 1.9543146100095523

Epoch: 6| Step: 3
Training loss: 0.6049376726150513
Validation loss: 1.9840693448179512

Epoch: 6| Step: 4
Training loss: 0.532368004322052
Validation loss: 1.983043339944655

Epoch: 6| Step: 5
Training loss: 0.739129364490509
Validation loss: 2.0107286463501635

Epoch: 6| Step: 6
Training loss: 0.4019612669944763
Validation loss: 2.005377205469275

Epoch: 6| Step: 7
Training loss: 0.31036874651908875
Validation loss: 2.0199394572165703

Epoch: 6| Step: 8
Training loss: 0.8873928189277649
Validation loss: 1.9403334663760277

Epoch: 6| Step: 9
Training loss: 0.37549689412117004
Validation loss: 1.927536041505875

Epoch: 6| Step: 10
Training loss: 0.6164075136184692
Validation loss: 1.8970746019835114

Epoch: 6| Step: 11
Training loss: 0.6519736051559448
Validation loss: 1.9020755278166903

Epoch: 6| Step: 12
Training loss: 0.6703646183013916
Validation loss: 1.8721141481912265

Epoch: 6| Step: 13
Training loss: 1.735768437385559
Validation loss: 1.8516786880390619

Epoch: 237| Step: 0
Training loss: 1.0939735174179077
Validation loss: 1.8629061739931825

Epoch: 6| Step: 1
Training loss: 1.2619136571884155
Validation loss: 1.8913458906194216

Epoch: 6| Step: 2
Training loss: 0.5614824295043945
Validation loss: 1.9105701933624923

Epoch: 6| Step: 3
Training loss: 0.4402855634689331
Validation loss: 1.9269914473256757

Epoch: 6| Step: 4
Training loss: 0.8275929689407349
Validation loss: 1.9471654789422148

Epoch: 6| Step: 5
Training loss: 0.8052713871002197
Validation loss: 1.9720276107070267

Epoch: 6| Step: 6
Training loss: 0.5532388687133789
Validation loss: 1.9289616077176985

Epoch: 6| Step: 7
Training loss: 0.37813302874565125
Validation loss: 1.9362906871303436

Epoch: 6| Step: 8
Training loss: 0.43636608123779297
Validation loss: 1.913270422207412

Epoch: 6| Step: 9
Training loss: 0.8612830638885498
Validation loss: 1.8691175048069288

Epoch: 6| Step: 10
Training loss: 0.46568432450294495
Validation loss: 1.9101056770611835

Epoch: 6| Step: 11
Training loss: 0.41736310720443726
Validation loss: 1.909478989980554

Epoch: 6| Step: 12
Training loss: 0.6297386884689331
Validation loss: 1.9460807410619592

Epoch: 6| Step: 13
Training loss: 0.5750048160552979
Validation loss: 1.9953996430161178

Epoch: 238| Step: 0
Training loss: 0.6992183327674866
Validation loss: 1.9801453454520113

Epoch: 6| Step: 1
Training loss: 0.5445048213005066
Validation loss: 1.99645233667025

Epoch: 6| Step: 2
Training loss: 0.6084201335906982
Validation loss: 1.9906093676884968

Epoch: 6| Step: 3
Training loss: 0.5626454949378967
Validation loss: 1.9821082545864968

Epoch: 6| Step: 4
Training loss: 0.4947679042816162
Validation loss: 1.9270814029119347

Epoch: 6| Step: 5
Training loss: 0.30481958389282227
Validation loss: 1.9230718023033553

Epoch: 6| Step: 6
Training loss: 0.5422872304916382
Validation loss: 1.9014651531814246

Epoch: 6| Step: 7
Training loss: 0.6806083917617798
Validation loss: 1.8943093156301847

Epoch: 6| Step: 8
Training loss: 0.7975673079490662
Validation loss: 1.8791152482391686

Epoch: 6| Step: 9
Training loss: 1.2386194467544556
Validation loss: 1.8856019832754647

Epoch: 6| Step: 10
Training loss: 1.1845200061798096
Validation loss: 1.8750034929603658

Epoch: 6| Step: 11
Training loss: 1.0976738929748535
Validation loss: 1.8914960097241145

Epoch: 6| Step: 12
Training loss: 0.40181151032447815
Validation loss: 1.9222090423748057

Epoch: 6| Step: 13
Training loss: 0.22083821892738342
Validation loss: 1.9009158021660262

Epoch: 239| Step: 0
Training loss: 0.4973805844783783
Validation loss: 1.9119318518587338

Epoch: 6| Step: 1
Training loss: 0.5791783928871155
Validation loss: 1.9130275070026357

Epoch: 6| Step: 2
Training loss: 0.6008039712905884
Validation loss: 1.9443651412122993

Epoch: 6| Step: 3
Training loss: 0.7172244787216187
Validation loss: 1.8835725579210507

Epoch: 6| Step: 4
Training loss: 0.6914854645729065
Validation loss: 1.9182642493196713

Epoch: 6| Step: 5
Training loss: 0.45966774225234985
Validation loss: 1.947948310964851

Epoch: 6| Step: 6
Training loss: 0.5459068417549133
Validation loss: 1.9374133258737543

Epoch: 6| Step: 7
Training loss: 0.4440382122993469
Validation loss: 1.9356183569918397

Epoch: 6| Step: 8
Training loss: 0.5686706304550171
Validation loss: 1.9596263503515592

Epoch: 6| Step: 9
Training loss: 0.32121002674102783
Validation loss: 1.943318377258957

Epoch: 6| Step: 10
Training loss: 0.9828283190727234
Validation loss: 1.957260734291487

Epoch: 6| Step: 11
Training loss: 1.179250717163086
Validation loss: 1.873782104061496

Epoch: 6| Step: 12
Training loss: 0.9572550654411316
Validation loss: 1.8647570430591542

Epoch: 6| Step: 13
Training loss: 0.3553915023803711
Validation loss: 1.8547669559396722

Epoch: 240| Step: 0
Training loss: 0.5437403917312622
Validation loss: 1.8275066883333269

Epoch: 6| Step: 1
Training loss: 0.8179013729095459
Validation loss: 1.8104823558561263

Epoch: 6| Step: 2
Training loss: 0.4368523955345154
Validation loss: 1.8262146301166986

Epoch: 6| Step: 3
Training loss: 0.6634653806686401
Validation loss: 1.8565156549535773

Epoch: 6| Step: 4
Training loss: 0.5072191953659058
Validation loss: 1.9016068391902472

Epoch: 6| Step: 5
Training loss: 1.082370638847351
Validation loss: 1.8407261486976378

Epoch: 6| Step: 6
Training loss: 0.5935449600219727
Validation loss: 1.850614268292663

Epoch: 6| Step: 7
Training loss: 0.5370873808860779
Validation loss: 1.8798285299731838

Epoch: 6| Step: 8
Training loss: 0.7803311347961426
Validation loss: 1.9039885869590185

Epoch: 6| Step: 9
Training loss: 0.5745575428009033
Validation loss: 1.8992530735590125

Epoch: 6| Step: 10
Training loss: 0.6378333568572998
Validation loss: 1.93360355207997

Epoch: 6| Step: 11
Training loss: 0.746533989906311
Validation loss: 1.9277864720231743

Epoch: 6| Step: 12
Training loss: 0.4645345211029053
Validation loss: 1.9490105516167098

Epoch: 6| Step: 13
Training loss: 0.2066929042339325
Validation loss: 1.9217176616832774

Epoch: 241| Step: 0
Training loss: 0.4734402894973755
Validation loss: 1.928063977149225

Epoch: 6| Step: 1
Training loss: 0.524330735206604
Validation loss: 1.9439805681987474

Epoch: 6| Step: 2
Training loss: 0.7656108736991882
Validation loss: 1.8928785349733086

Epoch: 6| Step: 3
Training loss: 0.8423510789871216
Validation loss: 1.9156827977908555

Epoch: 6| Step: 4
Training loss: 0.7469443082809448
Validation loss: 1.8921915767013386

Epoch: 6| Step: 5
Training loss: 1.0183093547821045
Validation loss: 1.859693827167634

Epoch: 6| Step: 6
Training loss: 0.4226735830307007
Validation loss: 1.8419216102169407

Epoch: 6| Step: 7
Training loss: 0.7302712202072144
Validation loss: 1.850587111647411

Epoch: 6| Step: 8
Training loss: 0.7971402406692505
Validation loss: 1.839694384605654

Epoch: 6| Step: 9
Training loss: 0.4064955413341522
Validation loss: 1.8616664704456125

Epoch: 6| Step: 10
Training loss: 0.37624144554138184
Validation loss: 1.82839003685982

Epoch: 6| Step: 11
Training loss: 0.5072277784347534
Validation loss: 1.8628262422418083

Epoch: 6| Step: 12
Training loss: 0.4426252245903015
Validation loss: 1.8728531688772223

Epoch: 6| Step: 13
Training loss: 0.6928144693374634
Validation loss: 1.9037788888459564

Epoch: 242| Step: 0
Training loss: 0.5545125007629395
Validation loss: 1.935075371496139

Epoch: 6| Step: 1
Training loss: 0.5194066166877747
Validation loss: 1.9534253484459334

Epoch: 6| Step: 2
Training loss: 0.9404836893081665
Validation loss: 1.96070231417174

Epoch: 6| Step: 3
Training loss: 0.43860602378845215
Validation loss: 1.9106319578745032

Epoch: 6| Step: 4
Training loss: 0.5695062279701233
Validation loss: 1.8838679841769639

Epoch: 6| Step: 5
Training loss: 0.41251224279403687
Validation loss: 1.8359856400438535

Epoch: 6| Step: 6
Training loss: 0.5083843469619751
Validation loss: 1.8400476735125306

Epoch: 6| Step: 7
Training loss: 0.789337158203125
Validation loss: 1.870597767573531

Epoch: 6| Step: 8
Training loss: 0.7979761362075806
Validation loss: 1.8871337290733092

Epoch: 6| Step: 9
Training loss: 0.28915566205978394
Validation loss: 1.872020862435782

Epoch: 6| Step: 10
Training loss: 0.5533947944641113
Validation loss: 1.8911131658861715

Epoch: 6| Step: 11
Training loss: 0.8686734437942505
Validation loss: 1.8897602942682081

Epoch: 6| Step: 12
Training loss: 1.0168594121932983
Validation loss: 1.887073851400806

Epoch: 6| Step: 13
Training loss: 0.815573513507843
Validation loss: 1.8959965039325017

Epoch: 243| Step: 0
Training loss: 0.9806106090545654
Validation loss: 1.926639296675241

Epoch: 6| Step: 1
Training loss: 0.9164088368415833
Validation loss: 1.937977583177628

Epoch: 6| Step: 2
Training loss: 0.7844443321228027
Validation loss: 1.9308308644961285

Epoch: 6| Step: 3
Training loss: 0.49381405115127563
Validation loss: 1.929084949595954

Epoch: 6| Step: 4
Training loss: 0.7464482188224792
Validation loss: 1.910899785257155

Epoch: 6| Step: 5
Training loss: 0.3121969699859619
Validation loss: 1.8889415443584483

Epoch: 6| Step: 6
Training loss: 0.7755279541015625
Validation loss: 1.8931581743301884

Epoch: 6| Step: 7
Training loss: 0.45614850521087646
Validation loss: 1.9000683061538204

Epoch: 6| Step: 8
Training loss: 0.45269206166267395
Validation loss: 1.9246401979077248

Epoch: 6| Step: 9
Training loss: 0.5759584903717041
Validation loss: 1.9363171131380144

Epoch: 6| Step: 10
Training loss: 0.6143431663513184
Validation loss: 1.9455421368281047

Epoch: 6| Step: 11
Training loss: 0.49453848600387573
Validation loss: 1.8844064845833728

Epoch: 6| Step: 12
Training loss: 0.21611309051513672
Validation loss: 1.887430493549634

Epoch: 6| Step: 13
Training loss: 0.8517342805862427
Validation loss: 1.87004683351004

Epoch: 244| Step: 0
Training loss: 0.4812746047973633
Validation loss: 1.8653658115735618

Epoch: 6| Step: 1
Training loss: 0.41045135259628296
Validation loss: 1.8717982820285264

Epoch: 6| Step: 2
Training loss: 1.1415611505508423
Validation loss: 1.8807166532803608

Epoch: 6| Step: 3
Training loss: 0.3389725685119629
Validation loss: 1.884935127791538

Epoch: 6| Step: 4
Training loss: 1.1015009880065918
Validation loss: 1.895521338267993

Epoch: 6| Step: 5
Training loss: 0.4571056067943573
Validation loss: 1.9010042810952792

Epoch: 6| Step: 6
Training loss: 0.9046328663825989
Validation loss: 1.931232649792907

Epoch: 6| Step: 7
Training loss: 0.4332674443721771
Validation loss: 1.934602939954368

Epoch: 6| Step: 8
Training loss: 0.52974933385849
Validation loss: 1.9589049226494246

Epoch: 6| Step: 9
Training loss: 0.4254986047744751
Validation loss: 1.9579963812264063

Epoch: 6| Step: 10
Training loss: 0.35849928855895996
Validation loss: 1.9466462058405722

Epoch: 6| Step: 11
Training loss: 0.8437802791595459
Validation loss: 1.9677147506385722

Epoch: 6| Step: 12
Training loss: 0.3894190192222595
Validation loss: 1.9191452944150535

Epoch: 6| Step: 13
Training loss: 0.514873206615448
Validation loss: 1.8905427148265224

Epoch: 245| Step: 0
Training loss: 0.14762796461582184
Validation loss: 1.8849334768069688

Epoch: 6| Step: 1
Training loss: 0.5828104019165039
Validation loss: 1.8578842545068392

Epoch: 6| Step: 2
Training loss: 0.8447566032409668
Validation loss: 1.8893093319349392

Epoch: 6| Step: 3
Training loss: 1.1687684059143066
Validation loss: 1.8817393561845184

Epoch: 6| Step: 4
Training loss: 0.7827207446098328
Validation loss: 1.9300140155259

Epoch: 6| Step: 5
Training loss: 0.8953965902328491
Validation loss: 1.928544431604365

Epoch: 6| Step: 6
Training loss: 0.3887520432472229
Validation loss: 1.9617827682084934

Epoch: 6| Step: 7
Training loss: 0.6247984170913696
Validation loss: 2.004476406240976

Epoch: 6| Step: 8
Training loss: 0.5744690895080566
Validation loss: 1.9563059409459431

Epoch: 6| Step: 9
Training loss: 0.7027756571769714
Validation loss: 1.9266567589134298

Epoch: 6| Step: 10
Training loss: 0.35562863945961
Validation loss: 1.8628343779553649

Epoch: 6| Step: 11
Training loss: 0.3490467369556427
Validation loss: 1.858627825654963

Epoch: 6| Step: 12
Training loss: 0.8494782447814941
Validation loss: 1.8050308304448281

Epoch: 6| Step: 13
Training loss: 0.7219698429107666
Validation loss: 1.8176215617887435

Epoch: 246| Step: 0
Training loss: 0.9550470113754272
Validation loss: 1.7913783493862356

Epoch: 6| Step: 1
Training loss: 0.37295934557914734
Validation loss: 1.7810056196746005

Epoch: 6| Step: 2
Training loss: 1.126892328262329
Validation loss: 1.8049889597841489

Epoch: 6| Step: 3
Training loss: 0.2049746811389923
Validation loss: 1.867077576216831

Epoch: 6| Step: 4
Training loss: 0.6343508362770081
Validation loss: 1.9325178746254212

Epoch: 6| Step: 5
Training loss: 0.48879197239875793
Validation loss: 1.9251100581179383

Epoch: 6| Step: 6
Training loss: 0.6148906946182251
Validation loss: 1.9128638211116995

Epoch: 6| Step: 7
Training loss: 0.34321820735931396
Validation loss: 1.8845172518043107

Epoch: 6| Step: 8
Training loss: 0.43852919340133667
Validation loss: 1.8374458807770924

Epoch: 6| Step: 9
Training loss: 0.4676777422428131
Validation loss: 1.8126651804934266

Epoch: 6| Step: 10
Training loss: 0.9846601486206055
Validation loss: 1.818627021645987

Epoch: 6| Step: 11
Training loss: 0.7386472821235657
Validation loss: 1.8429907803894372

Epoch: 6| Step: 12
Training loss: 0.6983388066291809
Validation loss: 1.8037399284301265

Epoch: 6| Step: 13
Training loss: 0.3826770782470703
Validation loss: 1.7818570829206897

Epoch: 247| Step: 0
Training loss: 0.4452010989189148
Validation loss: 1.8227592629771079

Epoch: 6| Step: 1
Training loss: 0.35967785120010376
Validation loss: 1.8277728019222137

Epoch: 6| Step: 2
Training loss: 0.917221188545227
Validation loss: 1.8465010966024091

Epoch: 6| Step: 3
Training loss: 0.44029855728149414
Validation loss: 1.8849435544783069

Epoch: 6| Step: 4
Training loss: 0.3437085449695587
Validation loss: 1.8375875616586337

Epoch: 6| Step: 5
Training loss: 0.33437249064445496
Validation loss: 1.8546289705461072

Epoch: 6| Step: 6
Training loss: 0.7020559310913086
Validation loss: 1.8500482805313603

Epoch: 6| Step: 7
Training loss: 0.46954408288002014
Validation loss: 1.8844126668027652

Epoch: 6| Step: 8
Training loss: 0.7805328965187073
Validation loss: 1.895475382445961

Epoch: 6| Step: 9
Training loss: 0.5894018411636353
Validation loss: 1.8810429316695019

Epoch: 6| Step: 10
Training loss: 0.3369593024253845
Validation loss: 1.8375255766735281

Epoch: 6| Step: 11
Training loss: 0.9414555430412292
Validation loss: 1.8503519796556043

Epoch: 6| Step: 12
Training loss: 0.8822003602981567
Validation loss: 1.8032034225361322

Epoch: 6| Step: 13
Training loss: 0.535320520401001
Validation loss: 1.7998781768224572

Epoch: 248| Step: 0
Training loss: 0.4206668734550476
Validation loss: 1.7582647954263995

Epoch: 6| Step: 1
Training loss: 0.9916917681694031
Validation loss: 1.7586862515377741

Epoch: 6| Step: 2
Training loss: 0.8437725305557251
Validation loss: 1.7660897367744035

Epoch: 6| Step: 3
Training loss: 0.701539158821106
Validation loss: 1.7733477738595778

Epoch: 6| Step: 4
Training loss: 0.5667855739593506
Validation loss: 1.798491306202386

Epoch: 6| Step: 5
Training loss: 0.7166410088539124
Validation loss: 1.816760088807793

Epoch: 6| Step: 6
Training loss: 0.36131155490875244
Validation loss: 1.8339215158134379

Epoch: 6| Step: 7
Training loss: 0.3922170400619507
Validation loss: 1.8595410290584768

Epoch: 6| Step: 8
Training loss: 1.1417932510375977
Validation loss: 1.880060088249945

Epoch: 6| Step: 9
Training loss: 0.4490853250026703
Validation loss: 1.9074262790782477

Epoch: 6| Step: 10
Training loss: 0.5606028437614441
Validation loss: 1.9297140900806715

Epoch: 6| Step: 11
Training loss: 0.3996855318546295
Validation loss: 1.934700745408253

Epoch: 6| Step: 12
Training loss: 0.3802933692932129
Validation loss: 1.8872716093576083

Epoch: 6| Step: 13
Training loss: 0.2761632204055786
Validation loss: 1.9025400377088977

Epoch: 249| Step: 0
Training loss: 0.23365387320518494
Validation loss: 1.892016310845652

Epoch: 6| Step: 1
Training loss: 0.389338880777359
Validation loss: 1.8676084369741461

Epoch: 6| Step: 2
Training loss: 0.6666284799575806
Validation loss: 1.8931310740850305

Epoch: 6| Step: 3
Training loss: 0.2901493012905121
Validation loss: 1.8884601362289921

Epoch: 6| Step: 4
Training loss: 0.5644873976707458
Validation loss: 1.861266912952546

Epoch: 6| Step: 5
Training loss: 0.4392254054546356
Validation loss: 1.873700193179551

Epoch: 6| Step: 6
Training loss: 0.8497118353843689
Validation loss: 1.8449448475273706

Epoch: 6| Step: 7
Training loss: 0.7406777143478394
Validation loss: 1.8447979829644645

Epoch: 6| Step: 8
Training loss: 0.8153607845306396
Validation loss: 1.8468700608899515

Epoch: 6| Step: 9
Training loss: 0.5327340364456177
Validation loss: 1.865597786441926

Epoch: 6| Step: 10
Training loss: 0.7772024869918823
Validation loss: 1.857990244383453

Epoch: 6| Step: 11
Training loss: 0.5105720162391663
Validation loss: 1.8886064944728729

Epoch: 6| Step: 12
Training loss: 0.5367873907089233
Validation loss: 1.884208269016717

Epoch: 6| Step: 13
Training loss: 0.19894316792488098
Validation loss: 1.9051822065025248

Epoch: 250| Step: 0
Training loss: 0.8345280885696411
Validation loss: 1.9222929528964463

Epoch: 6| Step: 1
Training loss: 0.5420677661895752
Validation loss: 1.8697660366694133

Epoch: 6| Step: 2
Training loss: 0.29467591643333435
Validation loss: 1.8067626337851248

Epoch: 6| Step: 3
Training loss: 0.4579154849052429
Validation loss: 1.7941071243696316

Epoch: 6| Step: 4
Training loss: 0.49576616287231445
Validation loss: 1.8019654340641473

Epoch: 6| Step: 5
Training loss: 0.32118067145347595
Validation loss: 1.803374203302527

Epoch: 6| Step: 6
Training loss: 1.1038161516189575
Validation loss: 1.8270745854223929

Epoch: 6| Step: 7
Training loss: 0.8539155721664429
Validation loss: 1.810383378818471

Epoch: 6| Step: 8
Training loss: 0.24538764357566833
Validation loss: 1.8439616900618359

Epoch: 6| Step: 9
Training loss: 0.8095909953117371
Validation loss: 1.8544018191675986

Epoch: 6| Step: 10
Training loss: 0.31616708636283875
Validation loss: 1.8734340052450857

Epoch: 6| Step: 11
Training loss: 0.5936206579208374
Validation loss: 1.9104673939366494

Epoch: 6| Step: 12
Training loss: 0.6621419191360474
Validation loss: 1.9511808733786307

Epoch: 6| Step: 13
Training loss: 0.3851493299007416
Validation loss: 1.9535721322541595

Epoch: 251| Step: 0
Training loss: 0.8817167282104492
Validation loss: 1.9283034493846278

Epoch: 6| Step: 1
Training loss: 0.6387654542922974
Validation loss: 1.9034914432033416

Epoch: 6| Step: 2
Training loss: 0.7082444429397583
Validation loss: 1.8940839088091286

Epoch: 6| Step: 3
Training loss: 0.4831061065196991
Validation loss: 1.8750948547035136

Epoch: 6| Step: 4
Training loss: 0.41228628158569336
Validation loss: 1.8682742413654123

Epoch: 6| Step: 5
Training loss: 0.4415813088417053
Validation loss: 1.8149433097531718

Epoch: 6| Step: 6
Training loss: 0.695496678352356
Validation loss: 1.7974237088234193

Epoch: 6| Step: 7
Training loss: 0.48284465074539185
Validation loss: 1.7723379186404649

Epoch: 6| Step: 8
Training loss: 0.7023489475250244
Validation loss: 1.749818746761609

Epoch: 6| Step: 9
Training loss: 0.48350989818573
Validation loss: 1.7677936220681796

Epoch: 6| Step: 10
Training loss: 0.23506590723991394
Validation loss: 1.7836549551256242

Epoch: 6| Step: 11
Training loss: 0.7786868810653687
Validation loss: 1.776974671630449

Epoch: 6| Step: 12
Training loss: 0.3555563688278198
Validation loss: 1.8288180597366825

Epoch: 6| Step: 13
Training loss: 0.7774491906166077
Validation loss: 1.847391087521789

Epoch: 252| Step: 0
Training loss: 0.6268144845962524
Validation loss: 1.8774924688441779

Epoch: 6| Step: 1
Training loss: 0.5813800096511841
Validation loss: 1.9086452030366468

Epoch: 6| Step: 2
Training loss: 0.7655419707298279
Validation loss: 1.902249469551989

Epoch: 6| Step: 3
Training loss: 0.8688318133354187
Validation loss: 1.9140584866205852

Epoch: 6| Step: 4
Training loss: 0.4497954249382019
Validation loss: 1.9191516278892435

Epoch: 6| Step: 5
Training loss: 0.29641300439834595
Validation loss: 1.894624420391616

Epoch: 6| Step: 6
Training loss: 0.5879637598991394
Validation loss: 1.8391336343621696

Epoch: 6| Step: 7
Training loss: 0.4648936688899994
Validation loss: 1.8367460056017804

Epoch: 6| Step: 8
Training loss: 0.47009390592575073
Validation loss: 1.8527187570448844

Epoch: 6| Step: 9
Training loss: 0.34088626503944397
Validation loss: 1.8436144282740932

Epoch: 6| Step: 10
Training loss: 0.48463159799575806
Validation loss: 1.8353216084100867

Epoch: 6| Step: 11
Training loss: 0.5904173254966736
Validation loss: 1.8541251587611374

Epoch: 6| Step: 12
Training loss: 0.589337944984436
Validation loss: 1.8392688830693562

Epoch: 6| Step: 13
Training loss: 0.3279377222061157
Validation loss: 1.835295005511212

Epoch: 253| Step: 0
Training loss: 0.6895996928215027
Validation loss: 1.7966367993303525

Epoch: 6| Step: 1
Training loss: 0.6780045032501221
Validation loss: 1.7814314237204931

Epoch: 6| Step: 2
Training loss: 0.5023934841156006
Validation loss: 1.8112135189835743

Epoch: 6| Step: 3
Training loss: 0.5529376864433289
Validation loss: 1.8018617565913866

Epoch: 6| Step: 4
Training loss: 0.3530363440513611
Validation loss: 1.7971503952498078

Epoch: 6| Step: 5
Training loss: 0.540947437286377
Validation loss: 1.8129143150903846

Epoch: 6| Step: 6
Training loss: 0.5913974046707153
Validation loss: 1.8214814214296238

Epoch: 6| Step: 7
Training loss: 0.39555609226226807
Validation loss: 1.7949427379074918

Epoch: 6| Step: 8
Training loss: 0.4724602997303009
Validation loss: 1.8190764547676168

Epoch: 6| Step: 9
Training loss: 0.6450521945953369
Validation loss: 1.8226111550484934

Epoch: 6| Step: 10
Training loss: 0.5734306573867798
Validation loss: 1.8197271670064619

Epoch: 6| Step: 11
Training loss: 0.4645460247993469
Validation loss: 1.8505955152614142

Epoch: 6| Step: 12
Training loss: 0.4096658527851105
Validation loss: 1.8839663561954294

Epoch: 6| Step: 13
Training loss: 0.756249189376831
Validation loss: 1.8694709257412983

Epoch: 254| Step: 0
Training loss: 0.4281657040119171
Validation loss: 1.8796313283263997

Epoch: 6| Step: 1
Training loss: 0.38707253336906433
Validation loss: 1.8480112655188448

Epoch: 6| Step: 2
Training loss: 0.6186755299568176
Validation loss: 1.8681535208097069

Epoch: 6| Step: 3
Training loss: 0.42881619930267334
Validation loss: 1.8415694544392247

Epoch: 6| Step: 4
Training loss: 0.6064037680625916
Validation loss: 1.8793620191594607

Epoch: 6| Step: 5
Training loss: 0.5565078258514404
Validation loss: 1.8307173470015168

Epoch: 6| Step: 6
Training loss: 0.5035666227340698
Validation loss: 1.8628403397016629

Epoch: 6| Step: 7
Training loss: 0.38918018341064453
Validation loss: 1.8204626126955914

Epoch: 6| Step: 8
Training loss: 0.6022788286209106
Validation loss: 1.8017583111281037

Epoch: 6| Step: 9
Training loss: 0.7806971073150635
Validation loss: 1.805252117495383

Epoch: 6| Step: 10
Training loss: 0.7466422319412231
Validation loss: 1.77335238200362

Epoch: 6| Step: 11
Training loss: 0.6525653004646301
Validation loss: 1.7354798316955566

Epoch: 6| Step: 12
Training loss: 0.4230886399745941
Validation loss: 1.7406345964759908

Epoch: 6| Step: 13
Training loss: 0.43081605434417725
Validation loss: 1.7843713798830587

Epoch: 255| Step: 0
Training loss: 0.5099332332611084
Validation loss: 1.8187477601471769

Epoch: 6| Step: 1
Training loss: 0.5892022848129272
Validation loss: 1.8676231420168312

Epoch: 6| Step: 2
Training loss: 0.6459968090057373
Validation loss: 1.8527584845019924

Epoch: 6| Step: 3
Training loss: 0.48936691880226135
Validation loss: 1.8823844719958562

Epoch: 6| Step: 4
Training loss: 0.3803798258304596
Validation loss: 1.850591778755188

Epoch: 6| Step: 5
Training loss: 0.4094812870025635
Validation loss: 1.8951596534380348

Epoch: 6| Step: 6
Training loss: 0.5755259394645691
Validation loss: 1.8956289573382306

Epoch: 6| Step: 7
Training loss: 0.646399736404419
Validation loss: 1.9305251772685716

Epoch: 6| Step: 8
Training loss: 0.28558284044265747
Validation loss: 1.877605381832328

Epoch: 6| Step: 9
Training loss: 0.49609655141830444
Validation loss: 1.8696025315151419

Epoch: 6| Step: 10
Training loss: 0.8510818481445312
Validation loss: 1.8341165319565804

Epoch: 6| Step: 11
Training loss: 0.4442442059516907
Validation loss: 1.8073538554612028

Epoch: 6| Step: 12
Training loss: 0.6974775791168213
Validation loss: 1.8361030086394279

Epoch: 6| Step: 13
Training loss: 0.3763211667537689
Validation loss: 1.847751316203866

Epoch: 256| Step: 0
Training loss: 0.31695789098739624
Validation loss: 1.825720473002362

Epoch: 6| Step: 1
Training loss: 0.446338951587677
Validation loss: 1.852379116960751

Epoch: 6| Step: 2
Training loss: 0.46841755509376526
Validation loss: 1.87305631432482

Epoch: 6| Step: 3
Training loss: 0.45619654655456543
Validation loss: 1.9023825276282527

Epoch: 6| Step: 4
Training loss: 0.3712562918663025
Validation loss: 1.9001973546961302

Epoch: 6| Step: 5
Training loss: 0.4363333284854889
Validation loss: 1.8712647627758723

Epoch: 6| Step: 6
Training loss: 0.3845110833644867
Validation loss: 1.845946959269944

Epoch: 6| Step: 7
Training loss: 0.29338017106056213
Validation loss: 1.78382364267944

Epoch: 6| Step: 8
Training loss: 0.6389507055282593
Validation loss: 1.7655330140103576

Epoch: 6| Step: 9
Training loss: 0.8004245162010193
Validation loss: 1.7631788484511837

Epoch: 6| Step: 10
Training loss: 0.5865187644958496
Validation loss: 1.748441360330069

Epoch: 6| Step: 11
Training loss: 0.4730491042137146
Validation loss: 1.7685360344507361

Epoch: 6| Step: 12
Training loss: 1.0337278842926025
Validation loss: 1.7560066971727597

Epoch: 6| Step: 13
Training loss: 0.7127668857574463
Validation loss: 1.765150180426977

Epoch: 257| Step: 0
Training loss: 0.6203041672706604
Validation loss: 1.7876059650092997

Epoch: 6| Step: 1
Training loss: 0.5924602150917053
Validation loss: 1.8303363336029874

Epoch: 6| Step: 2
Training loss: 0.6843585968017578
Validation loss: 1.8765590447251514

Epoch: 6| Step: 3
Training loss: 0.3444651961326599
Validation loss: 1.8731032968849264

Epoch: 6| Step: 4
Training loss: 0.3918178379535675
Validation loss: 1.8876883881066435

Epoch: 6| Step: 5
Training loss: 0.5665838122367859
Validation loss: 1.8307143936875045

Epoch: 6| Step: 6
Training loss: 0.8237809538841248
Validation loss: 1.8177656025014899

Epoch: 6| Step: 7
Training loss: 0.9823523163795471
Validation loss: 1.8101620161405174

Epoch: 6| Step: 8
Training loss: 0.4710816442966461
Validation loss: 1.7693288621082102

Epoch: 6| Step: 9
Training loss: 0.15096226334571838
Validation loss: 1.7442410799764818

Epoch: 6| Step: 10
Training loss: 0.42053279280662537
Validation loss: 1.7730810321787351

Epoch: 6| Step: 11
Training loss: 0.35589802265167236
Validation loss: 1.72040395967422

Epoch: 6| Step: 12
Training loss: 0.8792482614517212
Validation loss: 1.774772314615147

Epoch: 6| Step: 13
Training loss: 0.35994842648506165
Validation loss: 1.7774810765379219

Epoch: 258| Step: 0
Training loss: 0.5592094659805298
Validation loss: 1.839253766562349

Epoch: 6| Step: 1
Training loss: 0.44648122787475586
Validation loss: 1.869001200122218

Epoch: 6| Step: 2
Training loss: 0.28498080372810364
Validation loss: 1.9484454047295354

Epoch: 6| Step: 3
Training loss: 0.9910053610801697
Validation loss: 1.9771744564015379

Epoch: 6| Step: 4
Training loss: 0.5461467504501343
Validation loss: 1.9464168779311641

Epoch: 6| Step: 5
Training loss: 0.40985026955604553
Validation loss: 1.8907719709539925

Epoch: 6| Step: 6
Training loss: 0.38959449529647827
Validation loss: 1.84881624098747

Epoch: 6| Step: 7
Training loss: 0.501331090927124
Validation loss: 1.8309909759029266

Epoch: 6| Step: 8
Training loss: 0.4607664942741394
Validation loss: 1.7777005549400084

Epoch: 6| Step: 9
Training loss: 0.5447549223899841
Validation loss: 1.7778341180534774

Epoch: 6| Step: 10
Training loss: 0.36865392327308655
Validation loss: 1.7668651303937357

Epoch: 6| Step: 11
Training loss: 0.5559533834457397
Validation loss: 1.7663157293873448

Epoch: 6| Step: 12
Training loss: 0.652896523475647
Validation loss: 1.8091670774644422

Epoch: 6| Step: 13
Training loss: 1.0196298360824585
Validation loss: 1.8123560643965198

Epoch: 259| Step: 0
Training loss: 0.3604990243911743
Validation loss: 1.828175703684489

Epoch: 6| Step: 1
Training loss: 0.6751540899276733
Validation loss: 1.8534782099467453

Epoch: 6| Step: 2
Training loss: 0.5089079737663269
Validation loss: 1.7916804359805198

Epoch: 6| Step: 3
Training loss: 0.33456939458847046
Validation loss: 1.767978488758046

Epoch: 6| Step: 4
Training loss: 0.3212645947933197
Validation loss: 1.7594251337871756

Epoch: 6| Step: 5
Training loss: 0.7719683051109314
Validation loss: 1.7349820931752522

Epoch: 6| Step: 6
Training loss: 0.41689643263816833
Validation loss: 1.7546242372964018

Epoch: 6| Step: 7
Training loss: 0.9070851802825928
Validation loss: 1.7555485207547423

Epoch: 6| Step: 8
Training loss: 0.5943167805671692
Validation loss: 1.7254645196340417

Epoch: 6| Step: 9
Training loss: 0.7843353748321533
Validation loss: 1.7608849720288349

Epoch: 6| Step: 10
Training loss: 0.43644729256629944
Validation loss: 1.7777885865139704

Epoch: 6| Step: 11
Training loss: 0.5501872301101685
Validation loss: 1.801282831417617

Epoch: 6| Step: 12
Training loss: 0.4149588346481323
Validation loss: 1.807164159513289

Epoch: 6| Step: 13
Training loss: 0.5057840347290039
Validation loss: 1.8087157844215311

Epoch: 260| Step: 0
Training loss: 0.3457406461238861
Validation loss: 1.8109804391860962

Epoch: 6| Step: 1
Training loss: 0.39401447772979736
Validation loss: 1.825027919584705

Epoch: 6| Step: 2
Training loss: 0.49849599599838257
Validation loss: 1.8505308294808993

Epoch: 6| Step: 3
Training loss: 0.483275443315506
Validation loss: 1.843148974962132

Epoch: 6| Step: 4
Training loss: 0.6180135011672974
Validation loss: 1.8205079186347224

Epoch: 6| Step: 5
Training loss: 0.27136749029159546
Validation loss: 1.8190566173163794

Epoch: 6| Step: 6
Training loss: 0.28817373514175415
Validation loss: 1.8128721765292588

Epoch: 6| Step: 7
Training loss: 0.4722980260848999
Validation loss: 1.8631406445657053

Epoch: 6| Step: 8
Training loss: 0.6313304305076599
Validation loss: 1.8460105132031184

Epoch: 6| Step: 9
Training loss: 0.4735468924045563
Validation loss: 1.839293300464589

Epoch: 6| Step: 10
Training loss: 1.1387451887130737
Validation loss: 1.8755830282806067

Epoch: 6| Step: 11
Training loss: 0.5262424349784851
Validation loss: 1.8664179668631604

Epoch: 6| Step: 12
Training loss: 0.4000544846057892
Validation loss: 1.86882286302505

Epoch: 6| Step: 13
Training loss: 0.4471462070941925
Validation loss: 1.8570631216931086

Epoch: 261| Step: 0
Training loss: 0.5085279941558838
Validation loss: 1.8108548912950742

Epoch: 6| Step: 1
Training loss: 0.32486215233802795
Validation loss: 1.7595493947305987

Epoch: 6| Step: 2
Training loss: 0.7883339524269104
Validation loss: 1.770105492684149

Epoch: 6| Step: 3
Training loss: 0.40751025080680847
Validation loss: 1.753457441124865

Epoch: 6| Step: 4
Training loss: 0.7847326993942261
Validation loss: 1.745421201952042

Epoch: 6| Step: 5
Training loss: 0.48465752601623535
Validation loss: 1.7380614370428107

Epoch: 6| Step: 6
Training loss: 0.2850154638290405
Validation loss: 1.7669363585851525

Epoch: 6| Step: 7
Training loss: 0.43838798999786377
Validation loss: 1.7728399743315995

Epoch: 6| Step: 8
Training loss: 0.5420987606048584
Validation loss: 1.8307451355841853

Epoch: 6| Step: 9
Training loss: 0.2318534553050995
Validation loss: 1.8756037540333246

Epoch: 6| Step: 10
Training loss: 0.34056562185287476
Validation loss: 1.8923042589618313

Epoch: 6| Step: 11
Training loss: 0.5042651295661926
Validation loss: 1.8887381412649666

Epoch: 6| Step: 12
Training loss: 0.6418719291687012
Validation loss: 1.9030373993740286

Epoch: 6| Step: 13
Training loss: 0.9816165566444397
Validation loss: 1.8719059280169907

Epoch: 262| Step: 0
Training loss: 0.5142684578895569
Validation loss: 1.8831304491207164

Epoch: 6| Step: 1
Training loss: 0.3434301018714905
Validation loss: 1.906350653658631

Epoch: 6| Step: 2
Training loss: 0.42339104413986206
Validation loss: 1.853281992737965

Epoch: 6| Step: 3
Training loss: 0.7380675077438354
Validation loss: 1.8481913817826139

Epoch: 6| Step: 4
Training loss: 0.5923243761062622
Validation loss: 1.827455674448321

Epoch: 6| Step: 5
Training loss: 0.2355024814605713
Validation loss: 1.8105023137984737

Epoch: 6| Step: 6
Training loss: 0.835538923740387
Validation loss: 1.7986811758369528

Epoch: 6| Step: 7
Training loss: 0.3174331784248352
Validation loss: 1.7719421514900782

Epoch: 6| Step: 8
Training loss: 0.898749589920044
Validation loss: 1.790125403352963

Epoch: 6| Step: 9
Training loss: 0.22566580772399902
Validation loss: 1.784795662408234

Epoch: 6| Step: 10
Training loss: 0.5567547678947449
Validation loss: 1.7716382267654582

Epoch: 6| Step: 11
Training loss: 0.27554747462272644
Validation loss: 1.7972833110440163

Epoch: 6| Step: 12
Training loss: 0.498592734336853
Validation loss: 1.779485361550444

Epoch: 6| Step: 13
Training loss: 0.38592270016670227
Validation loss: 1.7505950953370781

Epoch: 263| Step: 0
Training loss: 0.4714623689651489
Validation loss: 1.7621741756316154

Epoch: 6| Step: 1
Training loss: 0.33341044187545776
Validation loss: 1.7424287937020744

Epoch: 6| Step: 2
Training loss: 0.32989221811294556
Validation loss: 1.6614080859768776

Epoch: 6| Step: 3
Training loss: 0.3931604027748108
Validation loss: 1.7219829495235155

Epoch: 6| Step: 4
Training loss: 0.4526779055595398
Validation loss: 1.7194981523739394

Epoch: 6| Step: 5
Training loss: 0.6162506341934204
Validation loss: 1.7090388280089184

Epoch: 6| Step: 6
Training loss: 0.581304669380188
Validation loss: 1.7292255445193219

Epoch: 6| Step: 7
Training loss: 0.7463071346282959
Validation loss: 1.7177880425607004

Epoch: 6| Step: 8
Training loss: 0.3928532302379608
Validation loss: 1.7501526071179299

Epoch: 6| Step: 9
Training loss: 0.41625189781188965
Validation loss: 1.7585984199277815

Epoch: 6| Step: 10
Training loss: 0.728222131729126
Validation loss: 1.7834596736456758

Epoch: 6| Step: 11
Training loss: 0.7751481533050537
Validation loss: 1.796256011532199

Epoch: 6| Step: 12
Training loss: 0.2273220419883728
Validation loss: 1.7736100471147926

Epoch: 6| Step: 13
Training loss: 0.3551080822944641
Validation loss: 1.7830078114745438

Epoch: 264| Step: 0
Training loss: 0.5883532762527466
Validation loss: 1.7518045697160947

Epoch: 6| Step: 1
Training loss: 0.46882495284080505
Validation loss: 1.7088406931969427

Epoch: 6| Step: 2
Training loss: 0.2655428647994995
Validation loss: 1.7261093765176752

Epoch: 6| Step: 3
Training loss: 0.6386342644691467
Validation loss: 1.7198321844941826

Epoch: 6| Step: 4
Training loss: 0.34982508420944214
Validation loss: 1.7221049288267731

Epoch: 6| Step: 5
Training loss: 0.2685473561286926
Validation loss: 1.7312121904024513

Epoch: 6| Step: 6
Training loss: 0.3838379383087158
Validation loss: 1.7365174075608611

Epoch: 6| Step: 7
Training loss: 0.525624692440033
Validation loss: 1.712972084681193

Epoch: 6| Step: 8
Training loss: 0.5238324999809265
Validation loss: 1.7539484449612197

Epoch: 6| Step: 9
Training loss: 0.45595642924308777
Validation loss: 1.7410120579504198

Epoch: 6| Step: 10
Training loss: 0.8836861252784729
Validation loss: 1.7514671484629314

Epoch: 6| Step: 11
Training loss: 0.543491780757904
Validation loss: 1.7688111054000033

Epoch: 6| Step: 12
Training loss: 0.4907948672771454
Validation loss: 1.7820956040454168

Epoch: 6| Step: 13
Training loss: 0.14190424978733063
Validation loss: 1.7992018089499524

Epoch: 265| Step: 0
Training loss: 0.3794025778770447
Validation loss: 1.7766908778939197

Epoch: 6| Step: 1
Training loss: 0.34176766872406006
Validation loss: 1.7868208372464744

Epoch: 6| Step: 2
Training loss: 0.5000593066215515
Validation loss: 1.7520612016800912

Epoch: 6| Step: 3
Training loss: 0.35741880536079407
Validation loss: 1.7465170378326087

Epoch: 6| Step: 4
Training loss: 0.7755419015884399
Validation loss: 1.7410228874093743

Epoch: 6| Step: 5
Training loss: 0.6682519912719727
Validation loss: 1.7352640667269308

Epoch: 6| Step: 6
Training loss: 0.4301072955131531
Validation loss: 1.7474105819579093

Epoch: 6| Step: 7
Training loss: 0.5198674201965332
Validation loss: 1.7418070800842778

Epoch: 6| Step: 8
Training loss: 0.5026328563690186
Validation loss: 1.781079364079301

Epoch: 6| Step: 9
Training loss: 0.5752461552619934
Validation loss: 1.7567877859197638

Epoch: 6| Step: 10
Training loss: 0.3564199209213257
Validation loss: 1.7882330904724777

Epoch: 6| Step: 11
Training loss: 0.21759173274040222
Validation loss: 1.7768092078547324

Epoch: 6| Step: 12
Training loss: 0.4675253927707672
Validation loss: 1.7756038622189594

Epoch: 6| Step: 13
Training loss: 0.3603709936141968
Validation loss: 1.800099447209348

Epoch: 266| Step: 0
Training loss: 0.46097075939178467
Validation loss: 1.8062927440930439

Epoch: 6| Step: 1
Training loss: 0.44252610206604004
Validation loss: 1.7905949546444802

Epoch: 6| Step: 2
Training loss: 0.42544591426849365
Validation loss: 1.7634186398598455

Epoch: 6| Step: 3
Training loss: 0.362291544675827
Validation loss: 1.773256504407493

Epoch: 6| Step: 4
Training loss: 0.8460776805877686
Validation loss: 1.7497212322809363

Epoch: 6| Step: 5
Training loss: 0.3683624863624573
Validation loss: 1.7616945517960416

Epoch: 6| Step: 6
Training loss: 0.4775909185409546
Validation loss: 1.78313357855684

Epoch: 6| Step: 7
Training loss: 0.32115060091018677
Validation loss: 1.7633874403533114

Epoch: 6| Step: 8
Training loss: 0.16471225023269653
Validation loss: 1.7613614964228805

Epoch: 6| Step: 9
Training loss: 0.5873304009437561
Validation loss: 1.7877595296470068

Epoch: 6| Step: 10
Training loss: 0.44739830493927
Validation loss: 1.7995100918636526

Epoch: 6| Step: 11
Training loss: 0.65202397108078
Validation loss: 1.8273762400432298

Epoch: 6| Step: 12
Training loss: 0.40903332829475403
Validation loss: 1.775470051714169

Epoch: 6| Step: 13
Training loss: 0.47720861434936523
Validation loss: 1.8135408944981073

Epoch: 267| Step: 0
Training loss: 0.31487295031547546
Validation loss: 1.7977436845020582

Epoch: 6| Step: 1
Training loss: 0.36591285467147827
Validation loss: 1.8063597397137714

Epoch: 6| Step: 2
Training loss: 0.7227727174758911
Validation loss: 1.8060529347388976

Epoch: 6| Step: 3
Training loss: 0.23369339108467102
Validation loss: 1.8153571492882186

Epoch: 6| Step: 4
Training loss: 0.5851333141326904
Validation loss: 1.785158718785932

Epoch: 6| Step: 5
Training loss: 0.5835974812507629
Validation loss: 1.818594273700509

Epoch: 6| Step: 6
Training loss: 0.24188348650932312
Validation loss: 1.8438141884342316

Epoch: 6| Step: 7
Training loss: 0.4782083332538605
Validation loss: 1.87418128982667

Epoch: 6| Step: 8
Training loss: 0.5257103443145752
Validation loss: 1.8518831755525322

Epoch: 6| Step: 9
Training loss: 0.48158976435661316
Validation loss: 1.8879953840727448

Epoch: 6| Step: 10
Training loss: 0.3743484616279602
Validation loss: 1.854526259565866

Epoch: 6| Step: 11
Training loss: 0.9418057203292847
Validation loss: 1.8487296181340371

Epoch: 6| Step: 12
Training loss: 0.31988152861595154
Validation loss: 1.8486694905065721

Epoch: 6| Step: 13
Training loss: 0.3409525454044342
Validation loss: 1.8199361614001694

Epoch: 268| Step: 0
Training loss: 0.3967052102088928
Validation loss: 1.8289245149140716

Epoch: 6| Step: 1
Training loss: 0.43354007601737976
Validation loss: 1.801622836820541

Epoch: 6| Step: 2
Training loss: 0.23374104499816895
Validation loss: 1.8300753280680666

Epoch: 6| Step: 3
Training loss: 0.2976933717727661
Validation loss: 1.8071645908458258

Epoch: 6| Step: 4
Training loss: 0.5850914716720581
Validation loss: 1.807148459137127

Epoch: 6| Step: 5
Training loss: 0.504210352897644
Validation loss: 1.8068730651691396

Epoch: 6| Step: 6
Training loss: 0.5858078002929688
Validation loss: 1.7685391454286472

Epoch: 6| Step: 7
Training loss: 0.4998217821121216
Validation loss: 1.7512449295290056

Epoch: 6| Step: 8
Training loss: 0.32836025953292847
Validation loss: 1.7451228249457575

Epoch: 6| Step: 9
Training loss: 0.7087472677230835
Validation loss: 1.7632127474713069

Epoch: 6| Step: 10
Training loss: 0.4121354818344116
Validation loss: 1.7303695114709998

Epoch: 6| Step: 11
Training loss: 0.37260228395462036
Validation loss: 1.7671370954923733

Epoch: 6| Step: 12
Training loss: 0.9242734909057617
Validation loss: 1.7550843928449897

Epoch: 6| Step: 13
Training loss: 0.29381200671195984
Validation loss: 1.7810257045171594

Epoch: 269| Step: 0
Training loss: 0.29560256004333496
Validation loss: 1.778432023140692

Epoch: 6| Step: 1
Training loss: 0.30615776777267456
Validation loss: 1.7726785726444696

Epoch: 6| Step: 2
Training loss: 0.6996579170227051
Validation loss: 1.7871626948797574

Epoch: 6| Step: 3
Training loss: 0.21487994492053986
Validation loss: 1.7834634396337694

Epoch: 6| Step: 4
Training loss: 0.23108826577663422
Validation loss: 1.749872826760815

Epoch: 6| Step: 5
Training loss: 0.311861127614975
Validation loss: 1.7849898748500372

Epoch: 6| Step: 6
Training loss: 0.40923118591308594
Validation loss: 1.8051635629387313

Epoch: 6| Step: 7
Training loss: 0.39473018050193787
Validation loss: 1.76406616292974

Epoch: 6| Step: 8
Training loss: 0.4048951268196106
Validation loss: 1.7583864299199914

Epoch: 6| Step: 9
Training loss: 0.4302036166191101
Validation loss: 1.7695311820635231

Epoch: 6| Step: 10
Training loss: 0.39679986238479614
Validation loss: 1.7703844372944166

Epoch: 6| Step: 11
Training loss: 0.6889066696166992
Validation loss: 1.7708294929996613

Epoch: 6| Step: 12
Training loss: 0.6388806104660034
Validation loss: 1.8056019160055345

Epoch: 6| Step: 13
Training loss: 1.151613712310791
Validation loss: 1.841280407803033

Epoch: 270| Step: 0
Training loss: 0.5689497590065002
Validation loss: 1.8765862680250598

Epoch: 6| Step: 1
Training loss: 0.5624643564224243
Validation loss: 1.8835199622697727

Epoch: 6| Step: 2
Training loss: 0.49324896931648254
Validation loss: 1.8804131323291409

Epoch: 6| Step: 3
Training loss: 0.6041203737258911
Validation loss: 1.9071354750664002

Epoch: 6| Step: 4
Training loss: 0.5566905736923218
Validation loss: 1.925161502694571

Epoch: 6| Step: 5
Training loss: 0.7228657007217407
Validation loss: 1.8312794623836395

Epoch: 6| Step: 6
Training loss: 0.3225679397583008
Validation loss: 1.7893491611685803

Epoch: 6| Step: 7
Training loss: 0.47103068232536316
Validation loss: 1.729177366020859

Epoch: 6| Step: 8
Training loss: 0.3845275640487671
Validation loss: 1.6918646776547996

Epoch: 6| Step: 9
Training loss: 0.4216049909591675
Validation loss: 1.6778754162532028

Epoch: 6| Step: 10
Training loss: 0.6524889469146729
Validation loss: 1.6773123587331464

Epoch: 6| Step: 11
Training loss: 0.5726878046989441
Validation loss: 1.6653987694812078

Epoch: 6| Step: 12
Training loss: 0.29239746928215027
Validation loss: 1.6539727103325628

Epoch: 6| Step: 13
Training loss: 0.3518609404563904
Validation loss: 1.7153436419784382

Epoch: 271| Step: 0
Training loss: 0.257534384727478
Validation loss: 1.7543834229951263

Epoch: 6| Step: 1
Training loss: 0.7335010766983032
Validation loss: 1.7910698716358473

Epoch: 6| Step: 2
Training loss: 0.6691376566886902
Validation loss: 1.7597676374578988

Epoch: 6| Step: 3
Training loss: 0.6771174073219299
Validation loss: 1.761084266888198

Epoch: 6| Step: 4
Training loss: 0.6608502864837646
Validation loss: 1.7494468240327732

Epoch: 6| Step: 5
Training loss: 0.27094030380249023
Validation loss: 1.7110794077637375

Epoch: 6| Step: 6
Training loss: 0.23437471687793732
Validation loss: 1.7103159773734309

Epoch: 6| Step: 7
Training loss: 0.4070286154747009
Validation loss: 1.6618014074140979

Epoch: 6| Step: 8
Training loss: 0.3748009204864502
Validation loss: 1.6615282963680964

Epoch: 6| Step: 9
Training loss: 0.3039688169956207
Validation loss: 1.6843730320212662

Epoch: 6| Step: 10
Training loss: 0.4776753783226013
Validation loss: 1.6574555007360314

Epoch: 6| Step: 11
Training loss: 0.7599546313285828
Validation loss: 1.6696161698269587

Epoch: 6| Step: 12
Training loss: 0.6870209574699402
Validation loss: 1.7086807540667954

Epoch: 6| Step: 13
Training loss: 0.4434020221233368
Validation loss: 1.6885625470069148

Epoch: 272| Step: 0
Training loss: 0.4830877184867859
Validation loss: 1.7273181164136497

Epoch: 6| Step: 1
Training loss: 0.5837421417236328
Validation loss: 1.776827440466932

Epoch: 6| Step: 2
Training loss: 0.37252238392829895
Validation loss: 1.824179180206791

Epoch: 6| Step: 3
Training loss: 0.4493834376335144
Validation loss: 1.8601222897088656

Epoch: 6| Step: 4
Training loss: 0.4081055819988251
Validation loss: 1.855020699962493

Epoch: 6| Step: 5
Training loss: 0.2822217047214508
Validation loss: 1.8532067998763053

Epoch: 6| Step: 6
Training loss: 0.6464216709136963
Validation loss: 1.8377208017533826

Epoch: 6| Step: 7
Training loss: 0.6396801471710205
Validation loss: 1.7835987434592298

Epoch: 6| Step: 8
Training loss: 0.7318239212036133
Validation loss: 1.7341774509799095

Epoch: 6| Step: 9
Training loss: 0.37256160378456116
Validation loss: 1.7176866787736134

Epoch: 6| Step: 10
Training loss: 0.32185202836990356
Validation loss: 1.73147536605917

Epoch: 6| Step: 11
Training loss: 0.3184916377067566
Validation loss: 1.7129637131126978

Epoch: 6| Step: 12
Training loss: 0.5832390785217285
Validation loss: 1.7101517941362114

Epoch: 6| Step: 13
Training loss: 0.16907699406147003
Validation loss: 1.6967052900662987

Epoch: 273| Step: 0
Training loss: 0.6256436109542847
Validation loss: 1.6935581981494863

Epoch: 6| Step: 1
Training loss: 0.5676711797714233
Validation loss: 1.704239869630465

Epoch: 6| Step: 2
Training loss: 0.5761317014694214
Validation loss: 1.734876060998568

Epoch: 6| Step: 3
Training loss: 1.0550616979599
Validation loss: 1.756202966936173

Epoch: 6| Step: 4
Training loss: 0.2905327081680298
Validation loss: 1.7438889857261413

Epoch: 6| Step: 5
Training loss: 0.5549866557121277
Validation loss: 1.7342844419581915

Epoch: 6| Step: 6
Training loss: 0.3250882029533386
Validation loss: 1.755511574847724

Epoch: 6| Step: 7
Training loss: 0.33167940378189087
Validation loss: 1.7744302570178945

Epoch: 6| Step: 8
Training loss: 0.34570789337158203
Validation loss: 1.7485297905501498

Epoch: 6| Step: 9
Training loss: 0.36123397946357727
Validation loss: 1.763592380349354

Epoch: 6| Step: 10
Training loss: 0.24066531658172607
Validation loss: 1.7008179439011442

Epoch: 6| Step: 11
Training loss: 0.3956403434276581
Validation loss: 1.6975583286695584

Epoch: 6| Step: 12
Training loss: 0.21831832826137543
Validation loss: 1.6853168715712845

Epoch: 6| Step: 13
Training loss: 0.32050031423568726
Validation loss: 1.6832603895536034

Epoch: 274| Step: 0
Training loss: 0.3776509165763855
Validation loss: 1.6662025938751877

Epoch: 6| Step: 1
Training loss: 0.5417309999465942
Validation loss: 1.6830304207340363

Epoch: 6| Step: 2
Training loss: 0.26176008582115173
Validation loss: 1.720725138982137

Epoch: 6| Step: 3
Training loss: 0.6170084476470947
Validation loss: 1.7642585000684183

Epoch: 6| Step: 4
Training loss: 0.2662712633609772
Validation loss: 1.7808834404073737

Epoch: 6| Step: 5
Training loss: 0.3133362829685211
Validation loss: 1.7760294073371476

Epoch: 6| Step: 6
Training loss: 0.9998734593391418
Validation loss: 1.8108790971899544

Epoch: 6| Step: 7
Training loss: 0.25976529717445374
Validation loss: 1.824108769816737

Epoch: 6| Step: 8
Training loss: 0.4944007396697998
Validation loss: 1.7956598138296476

Epoch: 6| Step: 9
Training loss: 0.47093474864959717
Validation loss: 1.8295364136336951

Epoch: 6| Step: 10
Training loss: 0.3994632959365845
Validation loss: 1.8198130579404934

Epoch: 6| Step: 11
Training loss: 0.5007263422012329
Validation loss: 1.828665469282417

Epoch: 6| Step: 12
Training loss: 0.2397148311138153
Validation loss: 1.7984098567757556

Epoch: 6| Step: 13
Training loss: 0.30270305275917053
Validation loss: 1.809814738970931

Epoch: 275| Step: 0
Training loss: 0.24334193766117096
Validation loss: 1.769561283050045

Epoch: 6| Step: 1
Training loss: 0.47534364461898804
Validation loss: 1.7517128631632815

Epoch: 6| Step: 2
Training loss: 0.806235671043396
Validation loss: 1.7306717454746205

Epoch: 6| Step: 3
Training loss: 0.27587294578552246
Validation loss: 1.7408276091339767

Epoch: 6| Step: 4
Training loss: 0.369475781917572
Validation loss: 1.7196575646759362

Epoch: 6| Step: 5
Training loss: 0.373460978269577
Validation loss: 1.7263582137323195

Epoch: 6| Step: 6
Training loss: 0.4729957580566406
Validation loss: 1.7301952890170518

Epoch: 6| Step: 7
Training loss: 0.36221641302108765
Validation loss: 1.7761519057776338

Epoch: 6| Step: 8
Training loss: 0.7060750722885132
Validation loss: 1.777302021621376

Epoch: 6| Step: 9
Training loss: 0.38619983196258545
Validation loss: 1.7812553304497913

Epoch: 6| Step: 10
Training loss: 0.32229864597320557
Validation loss: 1.7614966771935905

Epoch: 6| Step: 11
Training loss: 0.6096293926239014
Validation loss: 1.7825692738256147

Epoch: 6| Step: 12
Training loss: 0.5125818252563477
Validation loss: 1.8175673677075295

Epoch: 6| Step: 13
Training loss: 0.5246522426605225
Validation loss: 1.7970374771343764

Epoch: 276| Step: 0
Training loss: 0.5145368576049805
Validation loss: 1.7624842095118698

Epoch: 6| Step: 1
Training loss: 0.3861082196235657
Validation loss: 1.7328340238140476

Epoch: 6| Step: 2
Training loss: 0.9098191261291504
Validation loss: 1.6914055757625128

Epoch: 6| Step: 3
Training loss: 0.26759594678878784
Validation loss: 1.6996030986949962

Epoch: 6| Step: 4
Training loss: 0.3406657576560974
Validation loss: 1.7081418857779553

Epoch: 6| Step: 5
Training loss: 0.3450978398323059
Validation loss: 1.692031200214099

Epoch: 6| Step: 6
Training loss: 0.3581867516040802
Validation loss: 1.6757894459591116

Epoch: 6| Step: 7
Training loss: 0.5477098822593689
Validation loss: 1.6884212904078986

Epoch: 6| Step: 8
Training loss: 0.4689992666244507
Validation loss: 1.662769857273307

Epoch: 6| Step: 9
Training loss: 0.3436332941055298
Validation loss: 1.670474426720732

Epoch: 6| Step: 10
Training loss: 0.5011769533157349
Validation loss: 1.722552905800522

Epoch: 6| Step: 11
Training loss: 0.27446937561035156
Validation loss: 1.7203048865000408

Epoch: 6| Step: 12
Training loss: 0.52772456407547
Validation loss: 1.7119061793050458

Epoch: 6| Step: 13
Training loss: 0.18378959596157074
Validation loss: 1.7819212918640466

Epoch: 277| Step: 0
Training loss: 0.5088969469070435
Validation loss: 1.7759531460782534

Epoch: 6| Step: 1
Training loss: 0.6398335099220276
Validation loss: 1.730391756180794

Epoch: 6| Step: 2
Training loss: 0.4561644494533539
Validation loss: 1.6796760905173518

Epoch: 6| Step: 3
Training loss: 0.14602239429950714
Validation loss: 1.6982734023883779

Epoch: 6| Step: 4
Training loss: 0.2322331666946411
Validation loss: 1.6784507651482858

Epoch: 6| Step: 5
Training loss: 0.40303707122802734
Validation loss: 1.6540854912932201

Epoch: 6| Step: 6
Training loss: 0.3522579073905945
Validation loss: 1.6699962936421877

Epoch: 6| Step: 7
Training loss: 0.442227840423584
Validation loss: 1.6689524983847013

Epoch: 6| Step: 8
Training loss: 0.7861760258674622
Validation loss: 1.6844391540814472

Epoch: 6| Step: 9
Training loss: 0.5338371992111206
Validation loss: 1.711492541015789

Epoch: 6| Step: 10
Training loss: 0.19880296289920807
Validation loss: 1.720749255149595

Epoch: 6| Step: 11
Training loss: 0.2340320199728012
Validation loss: 1.7240709002299974

Epoch: 6| Step: 12
Training loss: 0.5297533273696899
Validation loss: 1.7537946624140586

Epoch: 6| Step: 13
Training loss: 0.8019999861717224
Validation loss: 1.746920020349564

Epoch: 278| Step: 0
Training loss: 0.4000204801559448
Validation loss: 1.7594161841177172

Epoch: 6| Step: 1
Training loss: 0.593725323677063
Validation loss: 1.7940434230271207

Epoch: 6| Step: 2
Training loss: 0.6591024994850159
Validation loss: 1.7730345136375838

Epoch: 6| Step: 3
Training loss: 0.5201023817062378
Validation loss: 1.7674866273838987

Epoch: 6| Step: 4
Training loss: 0.267970472574234
Validation loss: 1.7099225303178192

Epoch: 6| Step: 5
Training loss: 0.3255329132080078
Validation loss: 1.7451969333874282

Epoch: 6| Step: 6
Training loss: 0.5024718642234802
Validation loss: 1.7246427677010978

Epoch: 6| Step: 7
Training loss: 0.3536798059940338
Validation loss: 1.6842289099129297

Epoch: 6| Step: 8
Training loss: 0.40989214181900024
Validation loss: 1.7128134004531368

Epoch: 6| Step: 9
Training loss: 0.32446494698524475
Validation loss: 1.7269074570748113

Epoch: 6| Step: 10
Training loss: 0.5787290334701538
Validation loss: 1.7336270693809754

Epoch: 6| Step: 11
Training loss: 0.4103480279445648
Validation loss: 1.7436606422547372

Epoch: 6| Step: 12
Training loss: 0.2267998605966568
Validation loss: 1.763208100872655

Epoch: 6| Step: 13
Training loss: 0.4629286527633667
Validation loss: 1.7383261521657307

Epoch: 279| Step: 0
Training loss: 0.5019841194152832
Validation loss: 1.7303820066554572

Epoch: 6| Step: 1
Training loss: 0.15811198949813843
Validation loss: 1.716559325495074

Epoch: 6| Step: 2
Training loss: 0.28886663913726807
Validation loss: 1.6773258178464827

Epoch: 6| Step: 3
Training loss: 0.3008202910423279
Validation loss: 1.6997138197704027

Epoch: 6| Step: 4
Training loss: 0.6678148508071899
Validation loss: 1.6943539188754173

Epoch: 6| Step: 5
Training loss: 0.36260467767715454
Validation loss: 1.710733554696524

Epoch: 6| Step: 6
Training loss: 0.3165991008281708
Validation loss: 1.7321727634758077

Epoch: 6| Step: 7
Training loss: 0.360320121049881
Validation loss: 1.7263375482251566

Epoch: 6| Step: 8
Training loss: 0.7563124895095825
Validation loss: 1.7363364927230343

Epoch: 6| Step: 9
Training loss: 0.2972593605518341
Validation loss: 1.7553788705538678

Epoch: 6| Step: 10
Training loss: 0.25132256746292114
Validation loss: 1.7512378410626483

Epoch: 6| Step: 11
Training loss: 0.7205462455749512
Validation loss: 1.755053113865596

Epoch: 6| Step: 12
Training loss: 0.35422375798225403
Validation loss: 1.7856965936640257

Epoch: 6| Step: 13
Training loss: 0.6599864959716797
Validation loss: 1.755796476077008

Epoch: 280| Step: 0
Training loss: 0.2265554666519165
Validation loss: 1.758050008486676

Epoch: 6| Step: 1
Training loss: 0.34247422218322754
Validation loss: 1.7047826038893832

Epoch: 6| Step: 2
Training loss: 0.2169586569070816
Validation loss: 1.702465985410957

Epoch: 6| Step: 3
Training loss: 0.820675790309906
Validation loss: 1.680876398599276

Epoch: 6| Step: 4
Training loss: 0.5632480382919312
Validation loss: 1.6586121718088787

Epoch: 6| Step: 5
Training loss: 0.44046086072921753
Validation loss: 1.653378096959924

Epoch: 6| Step: 6
Training loss: 0.34360605478286743
Validation loss: 1.6710061770613476

Epoch: 6| Step: 7
Training loss: 0.2581217288970947
Validation loss: 1.6647731514387234

Epoch: 6| Step: 8
Training loss: 0.28115034103393555
Validation loss: 1.6940002082496561

Epoch: 6| Step: 9
Training loss: 0.21580630540847778
Validation loss: 1.6976422174002535

Epoch: 6| Step: 10
Training loss: 0.24489647150039673
Validation loss: 1.696245402418157

Epoch: 6| Step: 11
Training loss: 0.6574693322181702
Validation loss: 1.6861065856872066

Epoch: 6| Step: 12
Training loss: 0.3861178457736969
Validation loss: 1.739810929503492

Epoch: 6| Step: 13
Training loss: 0.5637839436531067
Validation loss: 1.7348311767783215

Epoch: 281| Step: 0
Training loss: 0.16135480999946594
Validation loss: 1.7163876743726834

Epoch: 6| Step: 1
Training loss: 0.3695402145385742
Validation loss: 1.7715806589331677

Epoch: 6| Step: 2
Training loss: 0.35712143778800964
Validation loss: 1.7475730885741532

Epoch: 6| Step: 3
Training loss: 0.48557037115097046
Validation loss: 1.7804293901689592

Epoch: 6| Step: 4
Training loss: 0.266269713640213
Validation loss: 1.760600750164319

Epoch: 6| Step: 5
Training loss: 0.4129745364189148
Validation loss: 1.7660397419365503

Epoch: 6| Step: 6
Training loss: 0.6518497467041016
Validation loss: 1.7526849187830442

Epoch: 6| Step: 7
Training loss: 0.34549206495285034
Validation loss: 1.7634210996730353

Epoch: 6| Step: 8
Training loss: 0.378568172454834
Validation loss: 1.7740589457173501

Epoch: 6| Step: 9
Training loss: 0.48109185695648193
Validation loss: 1.7476526665431198

Epoch: 6| Step: 10
Training loss: 0.28595179319381714
Validation loss: 1.6965697157767512

Epoch: 6| Step: 11
Training loss: 0.39124831557273865
Validation loss: 1.7127006207742999

Epoch: 6| Step: 12
Training loss: 0.3358229398727417
Validation loss: 1.713430509772352

Epoch: 6| Step: 13
Training loss: 0.5262991189956665
Validation loss: 1.698267367578322

Epoch: 282| Step: 0
Training loss: 0.29291826486587524
Validation loss: 1.7068762240871307

Epoch: 6| Step: 1
Training loss: 0.2606821656227112
Validation loss: 1.7338853433567991

Epoch: 6| Step: 2
Training loss: 0.3250415325164795
Validation loss: 1.7297054580462876

Epoch: 6| Step: 3
Training loss: 0.2907651662826538
Validation loss: 1.7806655117260513

Epoch: 6| Step: 4
Training loss: 0.4446418881416321
Validation loss: 1.805165442087317

Epoch: 6| Step: 5
Training loss: 0.35668569803237915
Validation loss: 1.7720695964751705

Epoch: 6| Step: 6
Training loss: 0.5131208300590515
Validation loss: 1.784805082505749

Epoch: 6| Step: 7
Training loss: 0.7428471446037292
Validation loss: 1.7442727576019943

Epoch: 6| Step: 8
Training loss: 0.14281755685806274
Validation loss: 1.701181971898643

Epoch: 6| Step: 9
Training loss: 0.416217565536499
Validation loss: 1.6976443849584109

Epoch: 6| Step: 10
Training loss: 0.36593449115753174
Validation loss: 1.6803672057326122

Epoch: 6| Step: 11
Training loss: 0.6462783813476562
Validation loss: 1.6392899905481646

Epoch: 6| Step: 12
Training loss: 0.4275744557380676
Validation loss: 1.6239495713223693

Epoch: 6| Step: 13
Training loss: 0.337089478969574
Validation loss: 1.6458762999503844

Epoch: 283| Step: 0
Training loss: 0.4147666096687317
Validation loss: 1.6686730538645098

Epoch: 6| Step: 1
Training loss: 0.5026645660400391
Validation loss: 1.613280915444897

Epoch: 6| Step: 2
Training loss: 0.28754761815071106
Validation loss: 1.6498458206012685

Epoch: 6| Step: 3
Training loss: 0.7441592216491699
Validation loss: 1.6567182822894024

Epoch: 6| Step: 4
Training loss: 0.4482179284095764
Validation loss: 1.658707857131958

Epoch: 6| Step: 5
Training loss: 0.3369779586791992
Validation loss: 1.7107002427501063

Epoch: 6| Step: 6
Training loss: 0.6251384615898132
Validation loss: 1.7181875398082118

Epoch: 6| Step: 7
Training loss: 0.3215196132659912
Validation loss: 1.7962674863876835

Epoch: 6| Step: 8
Training loss: 0.5158863067626953
Validation loss: 1.772218688841789

Epoch: 6| Step: 9
Training loss: 0.26567232608795166
Validation loss: 1.7857315873587003

Epoch: 6| Step: 10
Training loss: 0.2572588324546814
Validation loss: 1.7904351834327943

Epoch: 6| Step: 11
Training loss: 0.7310926914215088
Validation loss: 1.8049545762359456

Epoch: 6| Step: 12
Training loss: 0.3870098292827606
Validation loss: 1.786659650905158

Epoch: 6| Step: 13
Training loss: 0.29817235469818115
Validation loss: 1.7993077321719098

Epoch: 284| Step: 0
Training loss: 0.2661297917366028
Validation loss: 1.717124609537022

Epoch: 6| Step: 1
Training loss: 0.3366001546382904
Validation loss: 1.7076818481568368

Epoch: 6| Step: 2
Training loss: 0.3473645746707916
Validation loss: 1.6765609454083186

Epoch: 6| Step: 3
Training loss: 0.31661564111709595
Validation loss: 1.6651924861374723

Epoch: 6| Step: 4
Training loss: 0.2570209205150604
Validation loss: 1.672463140180034

Epoch: 6| Step: 5
Training loss: 0.7689861059188843
Validation loss: 1.6644027566397062

Epoch: 6| Step: 6
Training loss: 0.7235150933265686
Validation loss: 1.6705180265570199

Epoch: 6| Step: 7
Training loss: 0.289111465215683
Validation loss: 1.697846512640676

Epoch: 6| Step: 8
Training loss: 0.48784205317497253
Validation loss: 1.6672901517601424

Epoch: 6| Step: 9
Training loss: 0.17777611315250397
Validation loss: 1.701251970824375

Epoch: 6| Step: 10
Training loss: 0.3003489375114441
Validation loss: 1.7002875997174172

Epoch: 6| Step: 11
Training loss: 0.43521982431411743
Validation loss: 1.7214143417214836

Epoch: 6| Step: 12
Training loss: 0.21672824025154114
Validation loss: 1.715490016885983

Epoch: 6| Step: 13
Training loss: 0.19582797586917877
Validation loss: 1.7074822943697694

Epoch: 285| Step: 0
Training loss: 0.28039467334747314
Validation loss: 1.69976346723495

Epoch: 6| Step: 1
Training loss: 0.256954550743103
Validation loss: 1.6890537956709504

Epoch: 6| Step: 2
Training loss: 0.61611008644104
Validation loss: 1.671487028880786

Epoch: 6| Step: 3
Training loss: 0.2001945823431015
Validation loss: 1.6501028896659933

Epoch: 6| Step: 4
Training loss: 0.21360743045806885
Validation loss: 1.6376291231442524

Epoch: 6| Step: 5
Training loss: 0.4903140068054199
Validation loss: 1.6542619223235755

Epoch: 6| Step: 6
Training loss: 0.24259337782859802
Validation loss: 1.6479434992677422

Epoch: 6| Step: 7
Training loss: 0.37284573912620544
Validation loss: 1.6955173477049796

Epoch: 6| Step: 8
Training loss: 0.7451048493385315
Validation loss: 1.6901901332280969

Epoch: 6| Step: 9
Training loss: 0.19991789758205414
Validation loss: 1.7031862940839542

Epoch: 6| Step: 10
Training loss: 0.2577630281448364
Validation loss: 1.724496897830758

Epoch: 6| Step: 11
Training loss: 0.26065513491630554
Validation loss: 1.7261888839865243

Epoch: 6| Step: 12
Training loss: 0.6352726221084595
Validation loss: 1.7052339738415134

Epoch: 6| Step: 13
Training loss: 0.23320335149765015
Validation loss: 1.7278942677282518

Epoch: 286| Step: 0
Training loss: 0.2962646782398224
Validation loss: 1.7134371649834417

Epoch: 6| Step: 1
Training loss: 0.2642218768596649
Validation loss: 1.6987998959838704

Epoch: 6| Step: 2
Training loss: 0.22274866700172424
Validation loss: 1.7026885350545247

Epoch: 6| Step: 3
Training loss: 0.13078193366527557
Validation loss: 1.706149866504054

Epoch: 6| Step: 4
Training loss: 0.4023206830024719
Validation loss: 1.6880570150190783

Epoch: 6| Step: 5
Training loss: 0.4409724771976471
Validation loss: 1.6635260787061465

Epoch: 6| Step: 6
Training loss: 0.7939895391464233
Validation loss: 1.6563050862281554

Epoch: 6| Step: 7
Training loss: 0.3751733899116516
Validation loss: 1.6481314397627307

Epoch: 6| Step: 8
Training loss: 0.2340349555015564
Validation loss: 1.6833820009744296

Epoch: 6| Step: 9
Training loss: 0.18735727667808533
Validation loss: 1.6750792867393904

Epoch: 6| Step: 10
Training loss: 0.3526499569416046
Validation loss: 1.6626853635234218

Epoch: 6| Step: 11
Training loss: 0.3792608678340912
Validation loss: 1.6721599563475578

Epoch: 6| Step: 12
Training loss: 0.20998713374137878
Validation loss: 1.6821715370301278

Epoch: 6| Step: 13
Training loss: 0.6770904064178467
Validation loss: 1.7094540416553456

Epoch: 287| Step: 0
Training loss: 0.8585551381111145
Validation loss: 1.741275369480092

Epoch: 6| Step: 1
Training loss: 0.239411398768425
Validation loss: 1.7547083977730042

Epoch: 6| Step: 2
Training loss: 0.24599647521972656
Validation loss: 1.7210123141606648

Epoch: 6| Step: 3
Training loss: 0.23293811082839966
Validation loss: 1.6836411645335536

Epoch: 6| Step: 4
Training loss: 0.10122349113225937
Validation loss: 1.7018698043720697

Epoch: 6| Step: 5
Training loss: 0.317158579826355
Validation loss: 1.646595106329969

Epoch: 6| Step: 6
Training loss: 0.2294015735387802
Validation loss: 1.6605424509253552

Epoch: 6| Step: 7
Training loss: 0.340384304523468
Validation loss: 1.6403569675260974

Epoch: 6| Step: 8
Training loss: 0.42306771874427795
Validation loss: 1.6531624947824786

Epoch: 6| Step: 9
Training loss: 0.31103938817977905
Validation loss: 1.6690463660865702

Epoch: 6| Step: 10
Training loss: 0.3212122619152069
Validation loss: 1.660016135502887

Epoch: 6| Step: 11
Training loss: 0.8586364984512329
Validation loss: 1.6690551939830984

Epoch: 6| Step: 12
Training loss: 0.26467740535736084
Validation loss: 1.6692451610360095

Epoch: 6| Step: 13
Training loss: 0.21813856065273285
Validation loss: 1.672677719464866

Epoch: 288| Step: 0
Training loss: 0.5400461554527283
Validation loss: 1.6991342652228572

Epoch: 6| Step: 1
Training loss: 0.19748160243034363
Validation loss: 1.7299703936423025

Epoch: 6| Step: 2
Training loss: 0.5068597793579102
Validation loss: 1.721032742531069

Epoch: 6| Step: 3
Training loss: 0.4101579785346985
Validation loss: 1.7112105802823139

Epoch: 6| Step: 4
Training loss: 0.39591628313064575
Validation loss: 1.7308221029978927

Epoch: 6| Step: 5
Training loss: 0.33497923612594604
Validation loss: 1.7262389672699796

Epoch: 6| Step: 6
Training loss: 0.19992826879024506
Validation loss: 1.7124404548316874

Epoch: 6| Step: 7
Training loss: 0.2032046914100647
Validation loss: 1.6782321468476327

Epoch: 6| Step: 8
Training loss: 0.30256760120391846
Validation loss: 1.6622261129399782

Epoch: 6| Step: 9
Training loss: 0.45442476868629456
Validation loss: 1.6376841927087435

Epoch: 6| Step: 10
Training loss: 0.2111145555973053
Validation loss: 1.6440993175711682

Epoch: 6| Step: 11
Training loss: 0.4194614887237549
Validation loss: 1.6676243428261048

Epoch: 6| Step: 12
Training loss: 0.4135037958621979
Validation loss: 1.6624345548691288

Epoch: 6| Step: 13
Training loss: 0.33217954635620117
Validation loss: 1.6701602371790076

Epoch: 289| Step: 0
Training loss: 0.1975633203983307
Validation loss: 1.6969235366390598

Epoch: 6| Step: 1
Training loss: 0.351667582988739
Validation loss: 1.692942193759385

Epoch: 6| Step: 2
Training loss: 0.2619931101799011
Validation loss: 1.6870139183536652

Epoch: 6| Step: 3
Training loss: 0.701208233833313
Validation loss: 1.7188657727292789

Epoch: 6| Step: 4
Training loss: 0.19891676306724548
Validation loss: 1.6982751725822367

Epoch: 6| Step: 5
Training loss: 0.27694055438041687
Validation loss: 1.692615229596374

Epoch: 6| Step: 6
Training loss: 0.47379612922668457
Validation loss: 1.6973816874206706

Epoch: 6| Step: 7
Training loss: 0.3090464472770691
Validation loss: 1.7144303821748303

Epoch: 6| Step: 8
Training loss: 0.3896736800670624
Validation loss: 1.6893225767279183

Epoch: 6| Step: 9
Training loss: 0.25952184200286865
Validation loss: 1.6478472114891134

Epoch: 6| Step: 10
Training loss: 0.29498812556266785
Validation loss: 1.6870070606149652

Epoch: 6| Step: 11
Training loss: 0.22342774271965027
Validation loss: 1.6487279861204085

Epoch: 6| Step: 12
Training loss: 0.42052721977233887
Validation loss: 1.635507224708475

Epoch: 6| Step: 13
Training loss: 0.2038719654083252
Validation loss: 1.6617567769942745

Epoch: 290| Step: 0
Training loss: 0.5479348301887512
Validation loss: 1.6734451632345877

Epoch: 6| Step: 1
Training loss: 0.2063702791929245
Validation loss: 1.6744184981110275

Epoch: 6| Step: 2
Training loss: 0.7632555961608887
Validation loss: 1.6802477131607712

Epoch: 6| Step: 3
Training loss: 0.33258336782455444
Validation loss: 1.6962924324056154

Epoch: 6| Step: 4
Training loss: 0.3327544033527374
Validation loss: 1.6967945086058749

Epoch: 6| Step: 5
Training loss: 0.4344150125980377
Validation loss: 1.7118906051881853

Epoch: 6| Step: 6
Training loss: 0.21428892016410828
Validation loss: 1.6938568033197874

Epoch: 6| Step: 7
Training loss: 0.3316490054130554
Validation loss: 1.681316617996462

Epoch: 6| Step: 8
Training loss: 0.16253355145454407
Validation loss: 1.6828415816830051

Epoch: 6| Step: 9
Training loss: 0.1869789958000183
Validation loss: 1.7000442397209905

Epoch: 6| Step: 10
Training loss: 0.38165950775146484
Validation loss: 1.7028635714643745

Epoch: 6| Step: 11
Training loss: 0.25740933418273926
Validation loss: 1.6893227869464504

Epoch: 6| Step: 12
Training loss: 0.3315175473690033
Validation loss: 1.715798157517628

Epoch: 6| Step: 13
Training loss: 0.5326741337776184
Validation loss: 1.6729679505030315

Epoch: 291| Step: 0
Training loss: 0.3043399453163147
Validation loss: 1.7190939636640652

Epoch: 6| Step: 1
Training loss: 0.39057546854019165
Validation loss: 1.7212074033675655

Epoch: 6| Step: 2
Training loss: 0.3084602355957031
Validation loss: 1.7378168247079337

Epoch: 6| Step: 3
Training loss: 0.1925785392522812
Validation loss: 1.6695141151387205

Epoch: 6| Step: 4
Training loss: 0.20411479473114014
Validation loss: 1.665884021789797

Epoch: 6| Step: 5
Training loss: 0.20203638076782227
Validation loss: 1.6018264562852922

Epoch: 6| Step: 6
Training loss: 0.45603257417678833
Validation loss: 1.614025080075828

Epoch: 6| Step: 7
Training loss: 0.29762938618659973
Validation loss: 1.6364871007139965

Epoch: 6| Step: 8
Training loss: 0.3980492353439331
Validation loss: 1.6276236272627307

Epoch: 6| Step: 9
Training loss: 0.30183279514312744
Validation loss: 1.6364180823808074

Epoch: 6| Step: 10
Training loss: 0.26878732442855835
Validation loss: 1.6326636498974216

Epoch: 6| Step: 11
Training loss: 0.6643970012664795
Validation loss: 1.6649389754059494

Epoch: 6| Step: 12
Training loss: 0.4044305682182312
Validation loss: 1.6959166616521857

Epoch: 6| Step: 13
Training loss: 0.4800688922405243
Validation loss: 1.7116244351992043

Epoch: 292| Step: 0
Training loss: 0.21372513473033905
Validation loss: 1.7027212086544241

Epoch: 6| Step: 1
Training loss: 0.5534529685974121
Validation loss: 1.730912567466818

Epoch: 6| Step: 2
Training loss: 0.21138997375965118
Validation loss: 1.6786649803961478

Epoch: 6| Step: 3
Training loss: 0.5494955778121948
Validation loss: 1.7311467611661522

Epoch: 6| Step: 4
Training loss: 0.276583194732666
Validation loss: 1.7088495941572293

Epoch: 6| Step: 5
Training loss: 0.3215045630931854
Validation loss: 1.7258606469759377

Epoch: 6| Step: 6
Training loss: 0.18606290221214294
Validation loss: 1.7119675490163988

Epoch: 6| Step: 7
Training loss: 0.1780007928609848
Validation loss: 1.7160492097177813

Epoch: 6| Step: 8
Training loss: 0.18664081394672394
Validation loss: 1.695967073081642

Epoch: 6| Step: 9
Training loss: 0.24208009243011475
Validation loss: 1.7142438568094724

Epoch: 6| Step: 10
Training loss: 0.663503885269165
Validation loss: 1.6944555313356462

Epoch: 6| Step: 11
Training loss: 0.25214630365371704
Validation loss: 1.7210854817462224

Epoch: 6| Step: 12
Training loss: 0.5506502985954285
Validation loss: 1.7126435900247226

Epoch: 6| Step: 13
Training loss: 0.19540318846702576
Validation loss: 1.6695341320448025

Epoch: 293| Step: 0
Training loss: 0.2337832748889923
Validation loss: 1.6917123518964297

Epoch: 6| Step: 1
Training loss: 0.38790199160575867
Validation loss: 1.677785086375411

Epoch: 6| Step: 2
Training loss: 0.5378031730651855
Validation loss: 1.6702665026469896

Epoch: 6| Step: 3
Training loss: 0.21974125504493713
Validation loss: 1.6423166874916322

Epoch: 6| Step: 4
Training loss: 0.22438395023345947
Validation loss: 1.6246177586176063

Epoch: 6| Step: 5
Training loss: 0.30358585715293884
Validation loss: 1.6436671454419371

Epoch: 6| Step: 6
Training loss: 0.652179479598999
Validation loss: 1.6367275714874268

Epoch: 6| Step: 7
Training loss: 0.1564723700284958
Validation loss: 1.6567587480750134

Epoch: 6| Step: 8
Training loss: 0.23294085264205933
Validation loss: 1.6477851816402969

Epoch: 6| Step: 9
Training loss: 0.26451271772384644
Validation loss: 1.6575279287112656

Epoch: 6| Step: 10
Training loss: 0.18388110399246216
Validation loss: 1.6638708473533712

Epoch: 6| Step: 11
Training loss: 0.5640287399291992
Validation loss: 1.670130850166403

Epoch: 6| Step: 12
Training loss: 0.3176382780075073
Validation loss: 1.657943764040547

Epoch: 6| Step: 13
Training loss: 0.5111054182052612
Validation loss: 1.6725721205434492

Epoch: 294| Step: 0
Training loss: 0.25670668482780457
Validation loss: 1.694690022417294

Epoch: 6| Step: 1
Training loss: 0.5081863403320312
Validation loss: 1.6846946567617438

Epoch: 6| Step: 2
Training loss: 0.262923002243042
Validation loss: 1.6801353334098734

Epoch: 6| Step: 3
Training loss: 0.2641703486442566
Validation loss: 1.6866901664323704

Epoch: 6| Step: 4
Training loss: 0.2067098170518875
Validation loss: 1.639982505511212

Epoch: 6| Step: 5
Training loss: 0.48831722140312195
Validation loss: 1.6456843601760043

Epoch: 6| Step: 6
Training loss: 0.15122875571250916
Validation loss: 1.6475813952825402

Epoch: 6| Step: 7
Training loss: 0.23116564750671387
Validation loss: 1.6468560375193113

Epoch: 6| Step: 8
Training loss: 0.469003826379776
Validation loss: 1.664732526707393

Epoch: 6| Step: 9
Training loss: 0.5050414800643921
Validation loss: 1.687457771711452

Epoch: 6| Step: 10
Training loss: 0.3131346106529236
Validation loss: 1.7008232147462907

Epoch: 6| Step: 11
Training loss: 0.26483482122421265
Validation loss: 1.7051978739359046

Epoch: 6| Step: 12
Training loss: 0.23676598072052002
Validation loss: 1.6716276138059554

Epoch: 6| Step: 13
Training loss: 0.3423668444156647
Validation loss: 1.6756079709658058

Epoch: 295| Step: 0
Training loss: 0.38012805581092834
Validation loss: 1.6792577159020208

Epoch: 6| Step: 1
Training loss: 0.2992485761642456
Validation loss: 1.6815272685020202

Epoch: 6| Step: 2
Training loss: 0.20794883370399475
Validation loss: 1.686420456055672

Epoch: 6| Step: 3
Training loss: 0.36230990290641785
Validation loss: 1.6966501461562289

Epoch: 6| Step: 4
Training loss: 0.23990944027900696
Validation loss: 1.67268116499788

Epoch: 6| Step: 5
Training loss: 0.39433684945106506
Validation loss: 1.6769318439627205

Epoch: 6| Step: 6
Training loss: 0.40895241498947144
Validation loss: 1.653532870354191

Epoch: 6| Step: 7
Training loss: 0.32554954290390015
Validation loss: 1.6721940117497598

Epoch: 6| Step: 8
Training loss: 0.20607341825962067
Validation loss: 1.6239222320177222

Epoch: 6| Step: 9
Training loss: 0.14445528388023376
Validation loss: 1.6411655936189877

Epoch: 6| Step: 10
Training loss: 0.554599940776825
Validation loss: 1.6102468121436335

Epoch: 6| Step: 11
Training loss: 0.441669225692749
Validation loss: 1.6214201783621183

Epoch: 6| Step: 12
Training loss: 0.1725708544254303
Validation loss: 1.6035993893941243

Epoch: 6| Step: 13
Training loss: 0.19473469257354736
Validation loss: 1.597579421535615

Epoch: 296| Step: 0
Training loss: 0.17887571454048157
Validation loss: 1.6075795517172864

Epoch: 6| Step: 1
Training loss: 0.2262570559978485
Validation loss: 1.6199090801259524

Epoch: 6| Step: 2
Training loss: 0.7053702473640442
Validation loss: 1.6155538469232538

Epoch: 6| Step: 3
Training loss: 0.25603923201560974
Validation loss: 1.6548066164857598

Epoch: 6| Step: 4
Training loss: 0.36346572637557983
Validation loss: 1.6426136955138175

Epoch: 6| Step: 5
Training loss: 0.16756507754325867
Validation loss: 1.6338139234050628

Epoch: 6| Step: 6
Training loss: 0.24940137565135956
Validation loss: 1.6116059287901847

Epoch: 6| Step: 7
Training loss: 0.20249664783477783
Validation loss: 1.6143362599034463

Epoch: 6| Step: 8
Training loss: 0.20747902989387512
Validation loss: 1.6514515633224158

Epoch: 6| Step: 9
Training loss: 0.5968420505523682
Validation loss: 1.6591794099859012

Epoch: 6| Step: 10
Training loss: 0.3460376262664795
Validation loss: 1.6620514405670987

Epoch: 6| Step: 11
Training loss: 0.21198636293411255
Validation loss: 1.6627487931200253

Epoch: 6| Step: 12
Training loss: 0.31308943033218384
Validation loss: 1.6512363341546827

Epoch: 6| Step: 13
Training loss: 0.1887754648923874
Validation loss: 1.6423693831248949

Epoch: 297| Step: 0
Training loss: 0.21330556273460388
Validation loss: 1.6410079386926466

Epoch: 6| Step: 1
Training loss: 0.4949907064437866
Validation loss: 1.6253656392456384

Epoch: 6| Step: 2
Training loss: 0.20886348187923431
Validation loss: 1.6263736653071579

Epoch: 6| Step: 3
Training loss: 0.30252110958099365
Validation loss: 1.6098822316815775

Epoch: 6| Step: 4
Training loss: 0.16616922616958618
Validation loss: 1.6269468697168494

Epoch: 6| Step: 5
Training loss: 0.23467135429382324
Validation loss: 1.6380250325766943

Epoch: 6| Step: 6
Training loss: 0.5856526494026184
Validation loss: 1.6390594551640172

Epoch: 6| Step: 7
Training loss: 0.35901129245758057
Validation loss: 1.6507565424006472

Epoch: 6| Step: 8
Training loss: 0.4988447427749634
Validation loss: 1.666723596152439

Epoch: 6| Step: 9
Training loss: 0.21963384747505188
Validation loss: 1.7027826206658476

Epoch: 6| Step: 10
Training loss: 0.215223491191864
Validation loss: 1.684925195991352

Epoch: 6| Step: 11
Training loss: 0.29867032170295715
Validation loss: 1.7203289180673578

Epoch: 6| Step: 12
Training loss: 0.24095991253852844
Validation loss: 1.6887439822637906

Epoch: 6| Step: 13
Training loss: 0.21659114956855774
Validation loss: 1.678986196876854

Epoch: 298| Step: 0
Training loss: 0.1941666603088379
Validation loss: 1.667552842888781

Epoch: 6| Step: 1
Training loss: 0.24628016352653503
Validation loss: 1.6470419822200653

Epoch: 6| Step: 2
Training loss: 0.3302394151687622
Validation loss: 1.6401214343245312

Epoch: 6| Step: 3
Training loss: 0.28956514596939087
Validation loss: 1.5967975431872952

Epoch: 6| Step: 4
Training loss: 0.30347007513046265
Validation loss: 1.591953682643111

Epoch: 6| Step: 5
Training loss: 0.20811554789543152
Validation loss: 1.5958713780167282

Epoch: 6| Step: 6
Training loss: 0.15737095475196838
Validation loss: 1.597985222775449

Epoch: 6| Step: 7
Training loss: 0.234798401594162
Validation loss: 1.598067411812403

Epoch: 6| Step: 8
Training loss: 0.30593249201774597
Validation loss: 1.579063525763891

Epoch: 6| Step: 9
Training loss: 0.1823963224887848
Validation loss: 1.6174189095856042

Epoch: 6| Step: 10
Training loss: 0.19997438788414001
Validation loss: 1.6219709252798429

Epoch: 6| Step: 11
Training loss: 0.7502816319465637
Validation loss: 1.6194203149887823

Epoch: 6| Step: 12
Training loss: 0.5454511642456055
Validation loss: 1.661460643173546

Epoch: 6| Step: 13
Training loss: 0.20014642179012299
Validation loss: 1.6748226611844954

Epoch: 299| Step: 0
Training loss: 0.3496587872505188
Validation loss: 1.6520688649146789

Epoch: 6| Step: 1
Training loss: 0.5996081233024597
Validation loss: 1.6938873196160922

Epoch: 6| Step: 2
Training loss: 0.18809832632541656
Validation loss: 1.6947951137378652

Epoch: 6| Step: 3
Training loss: 0.1589963734149933
Validation loss: 1.6756856774771085

Epoch: 6| Step: 4
Training loss: 0.45817509293556213
Validation loss: 1.64031094889487

Epoch: 6| Step: 5
Training loss: 0.2035171389579773
Validation loss: 1.6638424934879426

Epoch: 6| Step: 6
Training loss: 0.36941614747047424
Validation loss: 1.6368108744262366

Epoch: 6| Step: 7
Training loss: 0.20812535285949707
Validation loss: 1.631225162936795

Epoch: 6| Step: 8
Training loss: 0.2129734754562378
Validation loss: 1.627307140698997

Epoch: 6| Step: 9
Training loss: 0.08963777124881744
Validation loss: 1.6139526213369062

Epoch: 6| Step: 10
Training loss: 0.3751460015773773
Validation loss: 1.6118451831161336

Epoch: 6| Step: 11
Training loss: 0.19320005178451538
Validation loss: 1.643755147534032

Epoch: 6| Step: 12
Training loss: 0.4516724646091461
Validation loss: 1.6719664348069059

Epoch: 6| Step: 13
Training loss: 0.26338624954223633
Validation loss: 1.6872959829145862

Epoch: 300| Step: 0
Training loss: 0.2850530743598938
Validation loss: 1.7213058458861483

Epoch: 6| Step: 1
Training loss: 0.19824612140655518
Validation loss: 1.694030846318891

Epoch: 6| Step: 2
Training loss: 0.23953476548194885
Validation loss: 1.6999852606045303

Epoch: 6| Step: 3
Training loss: 0.19579783082008362
Validation loss: 1.6544040095421575

Epoch: 6| Step: 4
Training loss: 0.5833476781845093
Validation loss: 1.64924152692159

Epoch: 6| Step: 5
Training loss: 0.5533974766731262
Validation loss: 1.668562904480965

Epoch: 6| Step: 6
Training loss: 0.20914047956466675
Validation loss: 1.6237683629476896

Epoch: 6| Step: 7
Training loss: 0.1784217357635498
Validation loss: 1.6380684170671689

Epoch: 6| Step: 8
Training loss: 0.29416024684906006
Validation loss: 1.6424437735670356

Epoch: 6| Step: 9
Training loss: 0.25092238187789917
Validation loss: 1.6582613965516448

Epoch: 6| Step: 10
Training loss: 0.20398180186748505
Validation loss: 1.6361034454837922

Epoch: 6| Step: 11
Training loss: 0.5259427428245544
Validation loss: 1.6324232944878199

Epoch: 6| Step: 12
Training loss: 0.3897477090358734
Validation loss: 1.6474068498098722

Epoch: 6| Step: 13
Training loss: 0.23991616070270538
Validation loss: 1.65745573659097

Epoch: 301| Step: 0
Training loss: 0.32948732376098633
Validation loss: 1.6838046440514185

Epoch: 6| Step: 1
Training loss: 0.21239373087882996
Validation loss: 1.660688820705619

Epoch: 6| Step: 2
Training loss: 0.20957732200622559
Validation loss: 1.6658765154500161

Epoch: 6| Step: 3
Training loss: 0.2929409146308899
Validation loss: 1.6366523401711577

Epoch: 6| Step: 4
Training loss: 0.10750646889209747
Validation loss: 1.6123953660329182

Epoch: 6| Step: 5
Training loss: 0.2206106185913086
Validation loss: 1.6145613090966338

Epoch: 6| Step: 6
Training loss: 0.21823875606060028
Validation loss: 1.6311064343298636

Epoch: 6| Step: 7
Training loss: 0.24339285492897034
Validation loss: 1.6154923131389003

Epoch: 6| Step: 8
Training loss: 0.206049382686615
Validation loss: 1.6091802312481789

Epoch: 6| Step: 9
Training loss: 0.17938408255577087
Validation loss: 1.5853653979557816

Epoch: 6| Step: 10
Training loss: 0.49080783128738403
Validation loss: 1.6011464672703897

Epoch: 6| Step: 11
Training loss: 0.18749180436134338
Validation loss: 1.6135041277895692

Epoch: 6| Step: 12
Training loss: 0.6828674077987671
Validation loss: 1.6364229302252493

Epoch: 6| Step: 13
Training loss: 0.3062736988067627
Validation loss: 1.652177640186843

Epoch: 302| Step: 0
Training loss: 0.20089614391326904
Validation loss: 1.6584850998334988

Epoch: 6| Step: 1
Training loss: 0.21800273656845093
Validation loss: 1.6466726564591931

Epoch: 6| Step: 2
Training loss: 0.25940972566604614
Validation loss: 1.6502335994474349

Epoch: 6| Step: 3
Training loss: 0.5671505928039551
Validation loss: 1.6381911308534685

Epoch: 6| Step: 4
Training loss: 0.34728431701660156
Validation loss: 1.600000745506697

Epoch: 6| Step: 5
Training loss: 0.29103952646255493
Validation loss: 1.5650885951134466

Epoch: 6| Step: 6
Training loss: 0.29533708095550537
Validation loss: 1.596217478475263

Epoch: 6| Step: 7
Training loss: 0.2424934208393097
Validation loss: 1.5657487505225725

Epoch: 6| Step: 8
Training loss: 0.21923354268074036
Validation loss: 1.538923034103968

Epoch: 6| Step: 9
Training loss: 0.24639379978179932
Validation loss: 1.539838340333713

Epoch: 6| Step: 10
Training loss: 0.6072590947151184
Validation loss: 1.5675695006565382

Epoch: 6| Step: 11
Training loss: 0.4341801404953003
Validation loss: 1.573481136752713

Epoch: 6| Step: 12
Training loss: 0.18836861848831177
Validation loss: 1.5913950320213073

Epoch: 6| Step: 13
Training loss: 0.10886020213365555
Validation loss: 1.5869064484873125

Epoch: 303| Step: 0
Training loss: 0.17909491062164307
Validation loss: 1.627130892968947

Epoch: 6| Step: 1
Training loss: 0.4125853478908539
Validation loss: 1.5932843877423195

Epoch: 6| Step: 2
Training loss: 0.19008922576904297
Validation loss: 1.6197219343595608

Epoch: 6| Step: 3
Training loss: 0.4876140058040619
Validation loss: 1.6280823407634613

Epoch: 6| Step: 4
Training loss: 0.20285995304584503
Validation loss: 1.6388348763988865

Epoch: 6| Step: 5
Training loss: 0.2823735475540161
Validation loss: 1.61168106396993

Epoch: 6| Step: 6
Training loss: 0.23211929202079773
Validation loss: 1.6185689126291583

Epoch: 6| Step: 7
Training loss: 0.22980855405330658
Validation loss: 1.6079098857859129

Epoch: 6| Step: 8
Training loss: 0.19706177711486816
Validation loss: 1.6035229403485534

Epoch: 6| Step: 9
Training loss: 0.20433461666107178
Validation loss: 1.6286292793930217

Epoch: 6| Step: 10
Training loss: 0.5594511032104492
Validation loss: 1.6122240251110447

Epoch: 6| Step: 11
Training loss: 0.35226064920425415
Validation loss: 1.6434237931364326

Epoch: 6| Step: 12
Training loss: 0.48744335770606995
Validation loss: 1.6634836863445979

Epoch: 6| Step: 13
Training loss: 0.2259088158607483
Validation loss: 1.690755066051278

Epoch: 304| Step: 0
Training loss: 0.35620248317718506
Validation loss: 1.6991905896894393

Epoch: 6| Step: 1
Training loss: 0.19409798085689545
Validation loss: 1.6849291324615479

Epoch: 6| Step: 2
Training loss: 0.3333061933517456
Validation loss: 1.6603561319330686

Epoch: 6| Step: 3
Training loss: 0.38050171732902527
Validation loss: 1.6539977314651653

Epoch: 6| Step: 4
Training loss: 0.3302365839481354
Validation loss: 1.6438401309392785

Epoch: 6| Step: 5
Training loss: 0.18768106400966644
Validation loss: 1.6050041580712924

Epoch: 6| Step: 6
Training loss: 0.3321731388568878
Validation loss: 1.6062540854177167

Epoch: 6| Step: 7
Training loss: 0.1626991331577301
Validation loss: 1.6051301994631368

Epoch: 6| Step: 8
Training loss: 0.21002936363220215
Validation loss: 1.6336628672897175

Epoch: 6| Step: 9
Training loss: 0.7723382711410522
Validation loss: 1.6693294522582844

Epoch: 6| Step: 10
Training loss: 0.2339545339345932
Validation loss: 1.6526891672483055

Epoch: 6| Step: 11
Training loss: 0.15719562768936157
Validation loss: 1.636749388069235

Epoch: 6| Step: 12
Training loss: 0.5491037368774414
Validation loss: 1.6613363591573571

Epoch: 6| Step: 13
Training loss: 0.45245614647865295
Validation loss: 1.6414948394221645

Epoch: 305| Step: 0
Training loss: 0.17154139280319214
Validation loss: 1.7152784806425854

Epoch: 6| Step: 1
Training loss: 0.2644253373146057
Validation loss: 1.6592523641483758

Epoch: 6| Step: 2
Training loss: 0.2393602430820465
Validation loss: 1.6501443321986864

Epoch: 6| Step: 3
Training loss: 0.18081411719322205
Validation loss: 1.6414185826496412

Epoch: 6| Step: 4
Training loss: 0.2032753825187683
Validation loss: 1.605944215610463

Epoch: 6| Step: 5
Training loss: 0.31855422258377075
Validation loss: 1.6058477342769664

Epoch: 6| Step: 6
Training loss: 0.598812997341156
Validation loss: 1.6058878975529824

Epoch: 6| Step: 7
Training loss: 0.27237367630004883
Validation loss: 1.5997332155063588

Epoch: 6| Step: 8
Training loss: 0.22426649928092957
Validation loss: 1.6135418722706456

Epoch: 6| Step: 9
Training loss: 0.5534760355949402
Validation loss: 1.6303373434210335

Epoch: 6| Step: 10
Training loss: 0.3045225739479065
Validation loss: 1.6339380048936414

Epoch: 6| Step: 11
Training loss: 0.1939142644405365
Validation loss: 1.640240821787106

Epoch: 6| Step: 12
Training loss: 0.20776905119419098
Validation loss: 1.687187583215775

Epoch: 6| Step: 13
Training loss: 0.9184112548828125
Validation loss: 1.6412958028495952

Epoch: 306| Step: 0
Training loss: 0.5564049482345581
Validation loss: 1.6925533945842455

Epoch: 6| Step: 1
Training loss: 0.5336576104164124
Validation loss: 1.6571065379727272

Epoch: 6| Step: 2
Training loss: 0.26446181535720825
Validation loss: 1.6275538949556247

Epoch: 6| Step: 3
Training loss: 0.19158199429512024
Validation loss: 1.5713802255609983

Epoch: 6| Step: 4
Training loss: 0.2328622043132782
Validation loss: 1.6079061569706086

Epoch: 6| Step: 5
Training loss: 0.23570825159549713
Validation loss: 1.5917231190589167

Epoch: 6| Step: 6
Training loss: 0.2580127716064453
Validation loss: 1.608470159192239

Epoch: 6| Step: 7
Training loss: 0.20014898478984833
Validation loss: 1.5990201555272585

Epoch: 6| Step: 8
Training loss: 0.24309810996055603
Validation loss: 1.6124057795411797

Epoch: 6| Step: 9
Training loss: 0.30999085307121277
Validation loss: 1.599650295831824

Epoch: 6| Step: 10
Training loss: 0.27652034163475037
Validation loss: 1.6041536202994726

Epoch: 6| Step: 11
Training loss: 0.1557428240776062
Validation loss: 1.6413351951106903

Epoch: 6| Step: 12
Training loss: 0.5029591917991638
Validation loss: 1.6257105360748947

Epoch: 6| Step: 13
Training loss: 0.23292361199855804
Validation loss: 1.6308453723948488

Epoch: 307| Step: 0
Training loss: 0.16936224699020386
Validation loss: 1.611479809207301

Epoch: 6| Step: 1
Training loss: 0.12947748601436615
Validation loss: 1.6235309275247718

Epoch: 6| Step: 2
Training loss: 0.303080677986145
Validation loss: 1.5767689122948596

Epoch: 6| Step: 3
Training loss: 0.21206870675086975
Validation loss: 1.5802230040232341

Epoch: 6| Step: 4
Training loss: 0.1900395154953003
Validation loss: 1.552063600991362

Epoch: 6| Step: 5
Training loss: 0.2597612738609314
Validation loss: 1.58978545793923

Epoch: 6| Step: 6
Training loss: 0.47305235266685486
Validation loss: 1.605331459353047

Epoch: 6| Step: 7
Training loss: 0.775036096572876
Validation loss: 1.6147639789888937

Epoch: 6| Step: 8
Training loss: 0.1230563074350357
Validation loss: 1.6080758763897804

Epoch: 6| Step: 9
Training loss: 0.17453241348266602
Validation loss: 1.59121669748778

Epoch: 6| Step: 10
Training loss: 0.266368567943573
Validation loss: 1.5860980031310872

Epoch: 6| Step: 11
Training loss: 0.298786997795105
Validation loss: 1.622820879823418

Epoch: 6| Step: 12
Training loss: 0.21310968697071075
Validation loss: 1.6212131348989343

Epoch: 6| Step: 13
Training loss: 0.21180790662765503
Validation loss: 1.6128906357672907

Epoch: 308| Step: 0
Training loss: 0.16514864563941956
Validation loss: 1.6307080227841613

Epoch: 6| Step: 1
Training loss: 0.1542988121509552
Validation loss: 1.648746234114452

Epoch: 6| Step: 2
Training loss: 0.3233380913734436
Validation loss: 1.6553207321833538

Epoch: 6| Step: 3
Training loss: 0.684669017791748
Validation loss: 1.6693164802366687

Epoch: 6| Step: 4
Training loss: 0.1847626119852066
Validation loss: 1.6605918561258624

Epoch: 6| Step: 5
Training loss: 0.3668631911277771
Validation loss: 1.6755507197431339

Epoch: 6| Step: 6
Training loss: 0.15574181079864502
Validation loss: 1.6668931412440475

Epoch: 6| Step: 7
Training loss: 0.24630114436149597
Validation loss: 1.647963208536948

Epoch: 6| Step: 8
Training loss: 0.22164613008499146
Validation loss: 1.6341051952813261

Epoch: 6| Step: 9
Training loss: 0.21920819580554962
Validation loss: 1.6441074263664983

Epoch: 6| Step: 10
Training loss: 0.15553194284439087
Validation loss: 1.63581342850962

Epoch: 6| Step: 11
Training loss: 0.2305549681186676
Validation loss: 1.5961082776387532

Epoch: 6| Step: 12
Training loss: 0.48524948954582214
Validation loss: 1.6029872432831795

Epoch: 6| Step: 13
Training loss: 0.333138108253479
Validation loss: 1.5921523365923154

Epoch: 309| Step: 0
Training loss: 0.22885575890541077
Validation loss: 1.5663671967803792

Epoch: 6| Step: 1
Training loss: 0.2103065550327301
Validation loss: 1.5837316897607618

Epoch: 6| Step: 2
Training loss: 0.20661866664886475
Validation loss: 1.5961036425764843

Epoch: 6| Step: 3
Training loss: 0.48999977111816406
Validation loss: 1.583983875090076

Epoch: 6| Step: 4
Training loss: 0.17468024790287018
Validation loss: 1.63709258520475

Epoch: 6| Step: 5
Training loss: 0.20369145274162292
Validation loss: 1.6329396117118098

Epoch: 6| Step: 6
Training loss: 0.473373144865036
Validation loss: 1.653435557119308

Epoch: 6| Step: 7
Training loss: 0.17016872763633728
Validation loss: 1.635005145944575

Epoch: 6| Step: 8
Training loss: 0.31362253427505493
Validation loss: 1.6159561487936205

Epoch: 6| Step: 9
Training loss: 0.18204225599765778
Validation loss: 1.635470563365567

Epoch: 6| Step: 10
Training loss: 0.48907482624053955
Validation loss: 1.6327287804695867

Epoch: 6| Step: 11
Training loss: 0.2622653841972351
Validation loss: 1.6200518467093026

Epoch: 6| Step: 12
Training loss: 0.19102637469768524
Validation loss: 1.6265094651970813

Epoch: 6| Step: 13
Training loss: 0.2072470337152481
Validation loss: 1.6630371232186594

Epoch: 310| Step: 0
Training loss: 0.26431113481521606
Validation loss: 1.6419639830948205

Epoch: 6| Step: 1
Training loss: 0.2235816866159439
Validation loss: 1.654135645717703

Epoch: 6| Step: 2
Training loss: 0.5987070798873901
Validation loss: 1.6547267078071513

Epoch: 6| Step: 3
Training loss: 0.23972082138061523
Validation loss: 1.662445943842652

Epoch: 6| Step: 4
Training loss: 0.15683817863464355
Validation loss: 1.689760583703236

Epoch: 6| Step: 5
Training loss: 0.2669028043746948
Validation loss: 1.707246470194991

Epoch: 6| Step: 6
Training loss: 0.19138911366462708
Validation loss: 1.6706057440850042

Epoch: 6| Step: 7
Training loss: 0.21735382080078125
Validation loss: 1.68585112274334

Epoch: 6| Step: 8
Training loss: 0.4588107466697693
Validation loss: 1.6667645131388018

Epoch: 6| Step: 9
Training loss: 0.3020990788936615
Validation loss: 1.632449306467528

Epoch: 6| Step: 10
Training loss: 0.44821739196777344
Validation loss: 1.582237571798345

Epoch: 6| Step: 11
Training loss: 0.31826144456863403
Validation loss: 1.5630022479641823

Epoch: 6| Step: 12
Training loss: 0.18048129975795746
Validation loss: 1.543778815577107

Epoch: 6| Step: 13
Training loss: 0.18427875638008118
Validation loss: 1.5333098756369723

Epoch: 311| Step: 0
Training loss: 0.4880504608154297
Validation loss: 1.54006500141595

Epoch: 6| Step: 1
Training loss: 0.18595071136951447
Validation loss: 1.5582006041721632

Epoch: 6| Step: 2
Training loss: 0.2911792993545532
Validation loss: 1.5473588461517005

Epoch: 6| Step: 3
Training loss: 0.5265328884124756
Validation loss: 1.5603004578621156

Epoch: 6| Step: 4
Training loss: 0.3187464475631714
Validation loss: 1.5829213473104662

Epoch: 6| Step: 5
Training loss: 0.26066434383392334
Validation loss: 1.5970768915709628

Epoch: 6| Step: 6
Training loss: 0.12156210839748383
Validation loss: 1.5886395913298412

Epoch: 6| Step: 7
Training loss: 0.12583261728286743
Validation loss: 1.601656820184441

Epoch: 6| Step: 8
Training loss: 0.12169457226991653
Validation loss: 1.6228404506560294

Epoch: 6| Step: 9
Training loss: 0.24097377061843872
Validation loss: 1.6243661436983334

Epoch: 6| Step: 10
Training loss: 0.5031023025512695
Validation loss: 1.6436104364292596

Epoch: 6| Step: 11
Training loss: 0.19733195006847382
Validation loss: 1.6051756130751742

Epoch: 6| Step: 12
Training loss: 0.2299308329820633
Validation loss: 1.6427875520080648

Epoch: 6| Step: 13
Training loss: 0.16159194707870483
Validation loss: 1.6144850407877276

Epoch: 312| Step: 0
Training loss: 0.218840092420578
Validation loss: 1.621743550864599

Epoch: 6| Step: 1
Training loss: 0.18153980374336243
Validation loss: 1.5938002909383466

Epoch: 6| Step: 2
Training loss: 0.313728928565979
Validation loss: 1.5878698268244344

Epoch: 6| Step: 3
Training loss: 0.21053728461265564
Validation loss: 1.611724143387169

Epoch: 6| Step: 4
Training loss: 0.29286813735961914
Validation loss: 1.6205768944114767

Epoch: 6| Step: 5
Training loss: 0.5188448429107666
Validation loss: 1.6361617759991718

Epoch: 6| Step: 6
Training loss: 0.3280901312828064
Validation loss: 1.6629036946963238

Epoch: 6| Step: 7
Training loss: 0.609748363494873
Validation loss: 1.6753362353130052

Epoch: 6| Step: 8
Training loss: 0.18251454830169678
Validation loss: 1.7163856708875267

Epoch: 6| Step: 9
Training loss: 0.21257972717285156
Validation loss: 1.7014166924261278

Epoch: 6| Step: 10
Training loss: 0.19349393248558044
Validation loss: 1.6844238914469236

Epoch: 6| Step: 11
Training loss: 0.5561853647232056
Validation loss: 1.690536686169204

Epoch: 6| Step: 12
Training loss: 0.2653486728668213
Validation loss: 1.6460433429287327

Epoch: 6| Step: 13
Training loss: 0.23696643114089966
Validation loss: 1.606463170820667

Epoch: 313| Step: 0
Training loss: 0.2597433030605316
Validation loss: 1.6210889713738554

Epoch: 6| Step: 1
Training loss: 0.22611141204833984
Validation loss: 1.5570136885489188

Epoch: 6| Step: 2
Training loss: 0.42153728008270264
Validation loss: 1.5689003262468564

Epoch: 6| Step: 3
Training loss: 0.18770503997802734
Validation loss: 1.5477892557779949

Epoch: 6| Step: 4
Training loss: 0.23195528984069824
Validation loss: 1.5136622716021795

Epoch: 6| Step: 5
Training loss: 0.5264618992805481
Validation loss: 1.5363489991875106

Epoch: 6| Step: 6
Training loss: 0.3100253641605377
Validation loss: 1.5319426713451263

Epoch: 6| Step: 7
Training loss: 0.553331732749939
Validation loss: 1.5519859906165832

Epoch: 6| Step: 8
Training loss: 0.16922219097614288
Validation loss: 1.5853433673099806

Epoch: 6| Step: 9
Training loss: 0.28557461500167847
Validation loss: 1.6155727012183076

Epoch: 6| Step: 10
Training loss: 0.2654998004436493
Validation loss: 1.631282929451235

Epoch: 6| Step: 11
Training loss: 0.19844956696033478
Validation loss: 1.625517960517637

Epoch: 6| Step: 12
Training loss: 0.2988167107105255
Validation loss: 1.594067826065966

Epoch: 6| Step: 13
Training loss: 0.21760882437229156
Validation loss: 1.618259406858875

Epoch: 314| Step: 0
Training loss: 0.38614609837532043
Validation loss: 1.5613833217210666

Epoch: 6| Step: 1
Training loss: 0.2757566571235657
Validation loss: 1.5967823113164594

Epoch: 6| Step: 2
Training loss: 0.21294596791267395
Validation loss: 1.5664351319753995

Epoch: 6| Step: 3
Training loss: 0.19829510152339935
Validation loss: 1.5923470374076598

Epoch: 6| Step: 4
Training loss: 0.603293776512146
Validation loss: 1.6259619330847135

Epoch: 6| Step: 5
Training loss: 0.2554444968700409
Validation loss: 1.6009819622962707

Epoch: 6| Step: 6
Training loss: 0.16886399686336517
Validation loss: 1.5952427374419345

Epoch: 6| Step: 7
Training loss: 0.3485085368156433
Validation loss: 1.6501924837789228

Epoch: 6| Step: 8
Training loss: 0.613183319568634
Validation loss: 1.6474863047240882

Epoch: 6| Step: 9
Training loss: 0.23082005977630615
Validation loss: 1.6490099442902433

Epoch: 6| Step: 10
Training loss: 0.2565869987010956
Validation loss: 1.6463832278405466

Epoch: 6| Step: 11
Training loss: 0.2537505328655243
Validation loss: 1.674430799740617

Epoch: 6| Step: 12
Training loss: 0.18297079205513
Validation loss: 1.6318973341295797

Epoch: 6| Step: 13
Training loss: 0.25360366702079773
Validation loss: 1.592347373244583

Epoch: 315| Step: 0
Training loss: 0.3341842591762543
Validation loss: 1.5794108208789621

Epoch: 6| Step: 1
Training loss: 0.2787034213542938
Validation loss: 1.5573792367853143

Epoch: 6| Step: 2
Training loss: 0.17700128257274628
Validation loss: 1.5436776325266848

Epoch: 6| Step: 3
Training loss: 0.16020050644874573
Validation loss: 1.5554809877949376

Epoch: 6| Step: 4
Training loss: 0.31941354274749756
Validation loss: 1.556642997649408

Epoch: 6| Step: 5
Training loss: 0.22491022944450378
Validation loss: 1.5783191496326077

Epoch: 6| Step: 6
Training loss: 0.4504276514053345
Validation loss: 1.610077751580105

Epoch: 6| Step: 7
Training loss: 0.19644096493721008
Validation loss: 1.6192315355423959

Epoch: 6| Step: 8
Training loss: 0.24624419212341309
Validation loss: 1.6311793660604825

Epoch: 6| Step: 9
Training loss: 0.18223100900650024
Validation loss: 1.6523377562081942

Epoch: 6| Step: 10
Training loss: 0.3748939335346222
Validation loss: 1.6592816204153082

Epoch: 6| Step: 11
Training loss: 0.3040383756160736
Validation loss: 1.628631830215454

Epoch: 6| Step: 12
Training loss: 0.3433566093444824
Validation loss: 1.614461434784756

Epoch: 6| Step: 13
Training loss: 0.289249449968338
Validation loss: 1.6438522326048983

Epoch: 316| Step: 0
Training loss: 0.14945507049560547
Validation loss: 1.641945165972556

Epoch: 6| Step: 1
Training loss: 0.2584480941295624
Validation loss: 1.6342783153698008

Epoch: 6| Step: 2
Training loss: 0.24227088689804077
Validation loss: 1.6493604913834603

Epoch: 6| Step: 3
Training loss: 0.3379957675933838
Validation loss: 1.659702713771533

Epoch: 6| Step: 4
Training loss: 0.4199725091457367
Validation loss: 1.6714587455154748

Epoch: 6| Step: 5
Training loss: 0.19569724798202515
Validation loss: 1.6587085121421403

Epoch: 6| Step: 6
Training loss: 0.24573427438735962
Validation loss: 1.6426069864662745

Epoch: 6| Step: 7
Training loss: 0.18929603695869446
Validation loss: 1.6623323316215186

Epoch: 6| Step: 8
Training loss: 0.16506844758987427
Validation loss: 1.6651356220245361

Epoch: 6| Step: 9
Training loss: 0.32142749428749084
Validation loss: 1.6470808880303496

Epoch: 6| Step: 10
Training loss: 0.3940539062023163
Validation loss: 1.6247650064447874

Epoch: 6| Step: 11
Training loss: 0.5022638440132141
Validation loss: 1.5773370650506788

Epoch: 6| Step: 12
Training loss: 0.2348523885011673
Validation loss: 1.5931824586724723

Epoch: 6| Step: 13
Training loss: 0.24764864146709442
Validation loss: 1.6114199334575283

Epoch: 317| Step: 0
Training loss: 0.24535831809043884
Validation loss: 1.5984929876942788

Epoch: 6| Step: 1
Training loss: 0.1933746635913849
Validation loss: 1.597671280625046

Epoch: 6| Step: 2
Training loss: 0.13789495825767517
Validation loss: 1.5925517492396857

Epoch: 6| Step: 3
Training loss: 0.2769988775253296
Validation loss: 1.596580195170577

Epoch: 6| Step: 4
Training loss: 0.189560666680336
Validation loss: 1.6513133638648576

Epoch: 6| Step: 5
Training loss: 0.1134428009390831
Validation loss: 1.6679753565019177

Epoch: 6| Step: 6
Training loss: 0.21917356550693512
Validation loss: 1.6393517358328706

Epoch: 6| Step: 7
Training loss: 0.44409000873565674
Validation loss: 1.6662217276070708

Epoch: 6| Step: 8
Training loss: 0.14965000748634338
Validation loss: 1.6950465863750828

Epoch: 6| Step: 9
Training loss: 0.2704532742500305
Validation loss: 1.6778612047113397

Epoch: 6| Step: 10
Training loss: 0.22932451963424683
Validation loss: 1.6965802997671149

Epoch: 6| Step: 11
Training loss: 0.1988649070262909
Validation loss: 1.6817724986742901

Epoch: 6| Step: 12
Training loss: 0.7993934154510498
Validation loss: 1.6689838799097205

Epoch: 6| Step: 13
Training loss: 0.2909061312675476
Validation loss: 1.6662473922134728

Epoch: 318| Step: 0
Training loss: 0.141535222530365
Validation loss: 1.6475003752657162

Epoch: 6| Step: 1
Training loss: 0.21233394742012024
Validation loss: 1.6374654052078084

Epoch: 6| Step: 2
Training loss: 0.5490068197250366
Validation loss: 1.6250877239370858

Epoch: 6| Step: 3
Training loss: 0.21778884530067444
Validation loss: 1.6194625695546467

Epoch: 6| Step: 4
Training loss: 0.33185598254203796
Validation loss: 1.6216264065875803

Epoch: 6| Step: 5
Training loss: 0.2536640167236328
Validation loss: 1.6388627162543676

Epoch: 6| Step: 6
Training loss: 0.398547887802124
Validation loss: 1.6413008333534322

Epoch: 6| Step: 7
Training loss: 0.3688685894012451
Validation loss: 1.645558170093003

Epoch: 6| Step: 8
Training loss: 0.4250657558441162
Validation loss: 1.625575783432171

Epoch: 6| Step: 9
Training loss: 0.44503456354141235
Validation loss: 1.640528058493009

Epoch: 6| Step: 10
Training loss: 0.1712746024131775
Validation loss: 1.630442286050448

Epoch: 6| Step: 11
Training loss: 0.2827151417732239
Validation loss: 1.6292645572334208

Epoch: 6| Step: 12
Training loss: 0.24323920905590057
Validation loss: 1.5997462195734824

Epoch: 6| Step: 13
Training loss: 0.2608337104320526
Validation loss: 1.6270193310194119

Epoch: 319| Step: 0
Training loss: 0.6420416831970215
Validation loss: 1.5986276275368148

Epoch: 6| Step: 1
Training loss: 0.16010260581970215
Validation loss: 1.5781173770145704

Epoch: 6| Step: 2
Training loss: 0.2748618721961975
Validation loss: 1.5605386918590916

Epoch: 6| Step: 3
Training loss: 0.16026216745376587
Validation loss: 1.5782575882891172

Epoch: 6| Step: 4
Training loss: 0.13112489879131317
Validation loss: 1.5337335230201803

Epoch: 6| Step: 5
Training loss: 0.19955304265022278
Validation loss: 1.574253595644428

Epoch: 6| Step: 6
Training loss: 0.16119258105754852
Validation loss: 1.5728494723637898

Epoch: 6| Step: 7
Training loss: 0.2935083508491516
Validation loss: 1.5665725995135564

Epoch: 6| Step: 8
Training loss: 0.22083842754364014
Validation loss: 1.5673287087871182

Epoch: 6| Step: 9
Training loss: 0.27222102880477905
Validation loss: 1.5546289618297289

Epoch: 6| Step: 10
Training loss: 0.23280496895313263
Validation loss: 1.5803408686832716

Epoch: 6| Step: 11
Training loss: 0.24993634223937988
Validation loss: 1.5871974729722547

Epoch: 6| Step: 12
Training loss: 0.2058124840259552
Validation loss: 1.5650040808544363

Epoch: 6| Step: 13
Training loss: 1.0424115657806396
Validation loss: 1.6091350099091888

Epoch: 320| Step: 0
Training loss: 0.24763575196266174
Validation loss: 1.6575298309326172

Epoch: 6| Step: 1
Training loss: 0.5583759546279907
Validation loss: 1.6836406056598952

Epoch: 6| Step: 2
Training loss: 0.2978532612323761
Validation loss: 1.6861824143317439

Epoch: 6| Step: 3
Training loss: 0.20442113280296326
Validation loss: 1.6602343026027884

Epoch: 6| Step: 4
Training loss: 0.2515355944633484
Validation loss: 1.6357578808261501

Epoch: 6| Step: 5
Training loss: 0.15453672409057617
Validation loss: 1.6239376042478828

Epoch: 6| Step: 6
Training loss: 0.20533445477485657
Validation loss: 1.6318788656624414

Epoch: 6| Step: 7
Training loss: 0.13952338695526123
Validation loss: 1.5705598900395055

Epoch: 6| Step: 8
Training loss: 0.4014430046081543
Validation loss: 1.610521803620041

Epoch: 6| Step: 9
Training loss: 0.1590849757194519
Validation loss: 1.5984454270332091

Epoch: 6| Step: 10
Training loss: 0.4104287624359131
Validation loss: 1.6287346245140157

Epoch: 6| Step: 11
Training loss: 0.1579570174217224
Validation loss: 1.6003606088699833

Epoch: 6| Step: 12
Training loss: 0.31134623289108276
Validation loss: 1.6178150151365547

Epoch: 6| Step: 13
Training loss: 0.1740570366382599
Validation loss: 1.6153541329086467

Epoch: 321| Step: 0
Training loss: 0.2100045382976532
Validation loss: 1.6247785937401555

Epoch: 6| Step: 1
Training loss: 0.4229806661605835
Validation loss: 1.6560654858107209

Epoch: 6| Step: 2
Training loss: 0.2686460614204407
Validation loss: 1.6782821968037596

Epoch: 6| Step: 3
Training loss: 0.2579606771469116
Validation loss: 1.6669100407631166

Epoch: 6| Step: 4
Training loss: 0.2816516160964966
Validation loss: 1.653897104724761

Epoch: 6| Step: 5
Training loss: 0.34596318006515503
Validation loss: 1.6353375988621865

Epoch: 6| Step: 6
Training loss: 0.4203437268733978
Validation loss: 1.6185892346084758

Epoch: 6| Step: 7
Training loss: 0.16537174582481384
Validation loss: 1.6101652755532214

Epoch: 6| Step: 8
Training loss: 0.3177946209907532
Validation loss: 1.5817290781646647

Epoch: 6| Step: 9
Training loss: 0.15848268568515778
Validation loss: 1.5731599356538506

Epoch: 6| Step: 10
Training loss: 0.38699790835380554
Validation loss: 1.5878289912336616

Epoch: 6| Step: 11
Training loss: 0.180284783244133
Validation loss: 1.5604363974704538

Epoch: 6| Step: 12
Training loss: 0.18493367731571198
Validation loss: 1.5765202686350832

Epoch: 6| Step: 13
Training loss: 0.2651626169681549
Validation loss: 1.6090947812603367

Epoch: 322| Step: 0
Training loss: 0.38286370038986206
Validation loss: 1.6282052647682927

Epoch: 6| Step: 1
Training loss: 0.2658120095729828
Validation loss: 1.6192030547767557

Epoch: 6| Step: 2
Training loss: 0.3359067738056183
Validation loss: 1.6311849035242552

Epoch: 6| Step: 3
Training loss: 0.17639997601509094
Validation loss: 1.6507731368464809

Epoch: 6| Step: 4
Training loss: 0.17595119774341583
Validation loss: 1.621772595631179

Epoch: 6| Step: 5
Training loss: 0.3657885789871216
Validation loss: 1.5811099365193357

Epoch: 6| Step: 6
Training loss: 0.2152177095413208
Validation loss: 1.5399131287810623

Epoch: 6| Step: 7
Training loss: 0.1324910819530487
Validation loss: 1.5476897711394935

Epoch: 6| Step: 8
Training loss: 0.2729411721229553
Validation loss: 1.538878212692917

Epoch: 6| Step: 9
Training loss: 0.23531413078308105
Validation loss: 1.509581878621091

Epoch: 6| Step: 10
Training loss: 0.4420088529586792
Validation loss: 1.5217497169330556

Epoch: 6| Step: 11
Training loss: 0.1857602596282959
Validation loss: 1.5492940884764477

Epoch: 6| Step: 12
Training loss: 0.2701978087425232
Validation loss: 1.5654726412988478

Epoch: 6| Step: 13
Training loss: 0.23867326974868774
Validation loss: 1.605540216609996

Epoch: 323| Step: 0
Training loss: 0.1643034815788269
Validation loss: 1.5878403340616534

Epoch: 6| Step: 1
Training loss: 0.5749461650848389
Validation loss: 1.5951345159161476

Epoch: 6| Step: 2
Training loss: 0.20146282017230988
Validation loss: 1.6435332067551152

Epoch: 6| Step: 3
Training loss: 0.28147459030151367
Validation loss: 1.604257316999538

Epoch: 6| Step: 4
Training loss: 0.1285754293203354
Validation loss: 1.5952601202072636

Epoch: 6| Step: 5
Training loss: 0.269777774810791
Validation loss: 1.6244822932827858

Epoch: 6| Step: 6
Training loss: 0.4187406301498413
Validation loss: 1.609472531144337

Epoch: 6| Step: 7
Training loss: 0.2655000686645508
Validation loss: 1.6067904426205544

Epoch: 6| Step: 8
Training loss: 0.11928413808345795
Validation loss: 1.591920345060287

Epoch: 6| Step: 9
Training loss: 0.13093921542167664
Validation loss: 1.5874217652505445

Epoch: 6| Step: 10
Training loss: 0.20209211111068726
Validation loss: 1.5768331776383102

Epoch: 6| Step: 11
Training loss: 0.394018292427063
Validation loss: 1.5935764851108674

Epoch: 6| Step: 12
Training loss: 0.13483086228370667
Validation loss: 1.5968008528473556

Epoch: 6| Step: 13
Training loss: 0.18080991506576538
Validation loss: 1.6215661725690287

Epoch: 324| Step: 0
Training loss: 0.15269145369529724
Validation loss: 1.623213146322517

Epoch: 6| Step: 1
Training loss: 0.4578236937522888
Validation loss: 1.6352520200514025

Epoch: 6| Step: 2
Training loss: 0.4519059360027313
Validation loss: 1.6490651920277586

Epoch: 6| Step: 3
Training loss: 0.14418303966522217
Validation loss: 1.6445315755823606

Epoch: 6| Step: 4
Training loss: 0.20340822637081146
Validation loss: 1.6106218804595291

Epoch: 6| Step: 5
Training loss: 0.38670116662979126
Validation loss: 1.6136822155726853

Epoch: 6| Step: 6
Training loss: 0.468118280172348
Validation loss: 1.6075151697281869

Epoch: 6| Step: 7
Training loss: 0.1867099553346634
Validation loss: 1.614411465583309

Epoch: 6| Step: 8
Training loss: 0.10650017112493515
Validation loss: 1.6264846017283778

Epoch: 6| Step: 9
Training loss: 0.18666164577007294
Validation loss: 1.5965388436471262

Epoch: 6| Step: 10
Training loss: 0.2565760612487793
Validation loss: 1.5988399482542468

Epoch: 6| Step: 11
Training loss: 0.32099753618240356
Validation loss: 1.6314875900104482

Epoch: 6| Step: 12
Training loss: 0.29981744289398193
Validation loss: 1.624589084297098

Epoch: 6| Step: 13
Training loss: 0.18004222214221954
Validation loss: 1.6302290129405197

Epoch: 325| Step: 0
Training loss: 0.23105376958847046
Validation loss: 1.6689141809299428

Epoch: 6| Step: 1
Training loss: 0.4043933153152466
Validation loss: 1.6402950248410624

Epoch: 6| Step: 2
Training loss: 0.4608422517776489
Validation loss: 1.6549610034112008

Epoch: 6| Step: 3
Training loss: 0.28665903210639954
Validation loss: 1.650506204174411

Epoch: 6| Step: 4
Training loss: 0.25280749797821045
Validation loss: 1.6074356007319626

Epoch: 6| Step: 5
Training loss: 0.1591256856918335
Validation loss: 1.613316656440817

Epoch: 6| Step: 6
Training loss: 0.49267256259918213
Validation loss: 1.6311180027582313

Epoch: 6| Step: 7
Training loss: 0.2525218725204468
Validation loss: 1.6580923000971477

Epoch: 6| Step: 8
Training loss: 0.18433129787445068
Validation loss: 1.6686650424875238

Epoch: 6| Step: 9
Training loss: 0.20323246717453003
Validation loss: 1.6658540515489475

Epoch: 6| Step: 10
Training loss: 0.28358468413352966
Validation loss: 1.6704265571409656

Epoch: 6| Step: 11
Training loss: 0.18997202813625336
Validation loss: 1.6679341587969052

Epoch: 6| Step: 12
Training loss: 0.220916286110878
Validation loss: 1.6483368527504705

Epoch: 6| Step: 13
Training loss: 0.15873882174491882
Validation loss: 1.6578135477599276

Epoch: 326| Step: 0
Training loss: 0.16619054973125458
Validation loss: 1.6227610623964699

Epoch: 6| Step: 1
Training loss: 0.17435985803604126
Validation loss: 1.6903859428180161

Epoch: 6| Step: 2
Training loss: 0.21468043327331543
Validation loss: 1.650454987761795

Epoch: 6| Step: 3
Training loss: 0.23630280792713165
Validation loss: 1.6402815926459529

Epoch: 6| Step: 4
Training loss: 0.3265487849712372
Validation loss: 1.6211179853767477

Epoch: 6| Step: 5
Training loss: 0.17666372656822205
Validation loss: 1.6347580032963906

Epoch: 6| Step: 6
Training loss: 0.13439148664474487
Validation loss: 1.6301491901438723

Epoch: 6| Step: 7
Training loss: 0.4609540104866028
Validation loss: 1.6148323705119472

Epoch: 6| Step: 8
Training loss: 0.15043430030345917
Validation loss: 1.6138795857788415

Epoch: 6| Step: 9
Training loss: 0.269229531288147
Validation loss: 1.6171281414647256

Epoch: 6| Step: 10
Training loss: 0.5455626249313354
Validation loss: 1.6077600986726823

Epoch: 6| Step: 11
Training loss: 0.15441656112670898
Validation loss: 1.5858945526102537

Epoch: 6| Step: 12
Training loss: 0.13890066742897034
Validation loss: 1.5818075710727322

Epoch: 6| Step: 13
Training loss: 0.2778944969177246
Validation loss: 1.6041862503174813

Epoch: 327| Step: 0
Training loss: 0.27949780225753784
Validation loss: 1.5299025979093326

Epoch: 6| Step: 1
Training loss: 0.22810326516628265
Validation loss: 1.5222986769932572

Epoch: 6| Step: 2
Training loss: 0.12759453058242798
Validation loss: 1.5469070698625298

Epoch: 6| Step: 3
Training loss: 0.23810526728630066
Validation loss: 1.552327884140835

Epoch: 6| Step: 4
Training loss: 0.14089737832546234
Validation loss: 1.5609698385320685

Epoch: 6| Step: 5
Training loss: 0.19027230143547058
Validation loss: 1.5595910626073037

Epoch: 6| Step: 6
Training loss: 0.16126631200313568
Validation loss: 1.5746462127213836

Epoch: 6| Step: 7
Training loss: 0.18435025215148926
Validation loss: 1.5801422967705676

Epoch: 6| Step: 8
Training loss: 0.1381397843360901
Validation loss: 1.6270504356712423

Epoch: 6| Step: 9
Training loss: 0.1533791720867157
Validation loss: 1.5921633089742353

Epoch: 6| Step: 10
Training loss: 0.6233615875244141
Validation loss: 1.6106279280877882

Epoch: 6| Step: 11
Training loss: 0.3561092019081116
Validation loss: 1.6052679823290916

Epoch: 6| Step: 12
Training loss: 0.11289267241954803
Validation loss: 1.60703488831879

Epoch: 6| Step: 13
Training loss: 0.28969383239746094
Validation loss: 1.6048119683419504

Epoch: 328| Step: 0
Training loss: 0.4149392545223236
Validation loss: 1.5930284684704197

Epoch: 6| Step: 1
Training loss: 0.14685668051242828
Validation loss: 1.5932287131586382

Epoch: 6| Step: 2
Training loss: 0.4349110722541809
Validation loss: 1.6008599701748099

Epoch: 6| Step: 3
Training loss: 0.2281205952167511
Validation loss: 1.5901100750892394

Epoch: 6| Step: 4
Training loss: 0.24607878923416138
Validation loss: 1.5893106845117384

Epoch: 6| Step: 5
Training loss: 0.13843457400798798
Validation loss: 1.5878402802252

Epoch: 6| Step: 6
Training loss: 0.23700064420700073
Validation loss: 1.5925840075298021

Epoch: 6| Step: 7
Training loss: 0.190756157040596
Validation loss: 1.6238637560157365

Epoch: 6| Step: 8
Training loss: 0.33411359786987305
Validation loss: 1.61331388514529

Epoch: 6| Step: 9
Training loss: 0.20065197348594666
Validation loss: 1.597645249418033

Epoch: 6| Step: 10
Training loss: 0.22262415289878845
Validation loss: 1.6180734608763008

Epoch: 6| Step: 11
Training loss: 0.16642555594444275
Validation loss: 1.6188386614604662

Epoch: 6| Step: 12
Training loss: 0.44766679406166077
Validation loss: 1.6326953993048718

Epoch: 6| Step: 13
Training loss: 0.22217139601707458
Validation loss: 1.6284561195681173

Epoch: 329| Step: 0
Training loss: 0.15759283304214478
Validation loss: 1.5779448337452386

Epoch: 6| Step: 1
Training loss: 0.4181537628173828
Validation loss: 1.5959763283370643

Epoch: 6| Step: 2
Training loss: 0.18960651755332947
Validation loss: 1.6173250829019854

Epoch: 6| Step: 3
Training loss: 0.3345246911048889
Validation loss: 1.6153237255670692

Epoch: 6| Step: 4
Training loss: 0.3242360055446625
Validation loss: 1.6150562455577235

Epoch: 6| Step: 5
Training loss: 0.23174238204956055
Validation loss: 1.5930889960258239

Epoch: 6| Step: 6
Training loss: 0.1398247480392456
Validation loss: 1.5978519019260202

Epoch: 6| Step: 7
Training loss: 0.22086980938911438
Validation loss: 1.6108301570338588

Epoch: 6| Step: 8
Training loss: 0.19381117820739746
Validation loss: 1.639412392852127

Epoch: 6| Step: 9
Training loss: 0.1760459840297699
Validation loss: 1.6779168075130833

Epoch: 6| Step: 10
Training loss: 0.22511285543441772
Validation loss: 1.6256529643971434

Epoch: 6| Step: 11
Training loss: 0.240839421749115
Validation loss: 1.6344875404911656

Epoch: 6| Step: 12
Training loss: 0.21599619090557098
Validation loss: 1.6002704904925438

Epoch: 6| Step: 13
Training loss: 0.5478605628013611
Validation loss: 1.5888526901122062

Epoch: 330| Step: 0
Training loss: 0.3372139632701874
Validation loss: 1.5787582359006327

Epoch: 6| Step: 1
Training loss: 0.21376371383666992
Validation loss: 1.5909499442705544

Epoch: 6| Step: 2
Training loss: 0.19089193642139435
Validation loss: 1.5464669978746803

Epoch: 6| Step: 3
Training loss: 0.3968283534049988
Validation loss: 1.551545181582051

Epoch: 6| Step: 4
Training loss: 0.22451290488243103
Validation loss: 1.5194342649111183

Epoch: 6| Step: 5
Training loss: 0.14984697103500366
Validation loss: 1.5328886175668368

Epoch: 6| Step: 6
Training loss: 0.47264933586120605
Validation loss: 1.5615187960286294

Epoch: 6| Step: 7
Training loss: 0.2754516005516052
Validation loss: 1.5560208751309303

Epoch: 6| Step: 8
Training loss: 0.14521855115890503
Validation loss: 1.5589825158478112

Epoch: 6| Step: 9
Training loss: 0.20811718702316284
Validation loss: 1.569993935605531

Epoch: 6| Step: 10
Training loss: 0.14446547627449036
Validation loss: 1.5604222871923958

Epoch: 6| Step: 11
Training loss: 0.12020686268806458
Validation loss: 1.5729442168307561

Epoch: 6| Step: 12
Training loss: 0.178756445646286
Validation loss: 1.5536388504889704

Epoch: 6| Step: 13
Training loss: 0.16491787135601044
Validation loss: 1.5418942545049934

Epoch: 331| Step: 0
Training loss: 0.3057200312614441
Validation loss: 1.5438865987203454

Epoch: 6| Step: 1
Training loss: 0.23266258835792542
Validation loss: 1.5638105946202432

Epoch: 6| Step: 2
Training loss: 0.21232441067695618
Validation loss: 1.5665024916330974

Epoch: 6| Step: 3
Training loss: 0.1683942675590515
Validation loss: 1.5574064741852462

Epoch: 6| Step: 4
Training loss: 0.12067869305610657
Validation loss: 1.5584128466985558

Epoch: 6| Step: 5
Training loss: 0.18515220284461975
Validation loss: 1.5700401362552439

Epoch: 6| Step: 6
Training loss: 0.19703680276870728
Validation loss: 1.5626117606316843

Epoch: 6| Step: 7
Training loss: 0.21503332257270813
Validation loss: 1.5504241733140842

Epoch: 6| Step: 8
Training loss: 0.21448051929473877
Validation loss: 1.5434392812431499

Epoch: 6| Step: 9
Training loss: 0.21855008602142334
Validation loss: 1.5710440028098323

Epoch: 6| Step: 10
Training loss: 0.5040985941886902
Validation loss: 1.5805518588712137

Epoch: 6| Step: 11
Training loss: 0.16770222783088684
Validation loss: 1.5730055724420855

Epoch: 6| Step: 12
Training loss: 0.12177671492099762
Validation loss: 1.5969070093606108

Epoch: 6| Step: 13
Training loss: 0.20288994908332825
Validation loss: 1.5861563374919276

Epoch: 332| Step: 0
Training loss: 0.294161856174469
Validation loss: 1.609971187447989

Epoch: 6| Step: 1
Training loss: 0.31913286447525024
Validation loss: 1.6046750455774286

Epoch: 6| Step: 2
Training loss: 0.1256733238697052
Validation loss: 1.5827371202489382

Epoch: 6| Step: 3
Training loss: 0.19191616773605347
Validation loss: 1.5672851224099436

Epoch: 6| Step: 4
Training loss: 0.1455794870853424
Validation loss: 1.6063502309142903

Epoch: 6| Step: 5
Training loss: 0.31672853231430054
Validation loss: 1.5987732115612234

Epoch: 6| Step: 6
Training loss: 0.19808325171470642
Validation loss: 1.6240721479538949

Epoch: 6| Step: 7
Training loss: 0.49197545647621155
Validation loss: 1.5748658180236816

Epoch: 6| Step: 8
Training loss: 0.14249981939792633
Validation loss: 1.5854893269077424

Epoch: 6| Step: 9
Training loss: 0.17041455209255219
Validation loss: 1.5921965491387151

Epoch: 6| Step: 10
Training loss: 0.12332216650247574
Validation loss: 1.565340486905908

Epoch: 6| Step: 11
Training loss: 0.14966349303722382
Validation loss: 1.5631160056719215

Epoch: 6| Step: 12
Training loss: 0.14649465680122375
Validation loss: 1.542234137494077

Epoch: 6| Step: 13
Training loss: 0.1867847442626953
Validation loss: 1.521110930750447

Epoch: 333| Step: 0
Training loss: 0.1141350194811821
Validation loss: 1.5108581243022796

Epoch: 6| Step: 1
Training loss: 0.18681424856185913
Validation loss: 1.5042776920462166

Epoch: 6| Step: 2
Training loss: 0.19418756663799286
Validation loss: 1.4873871034191501

Epoch: 6| Step: 3
Training loss: 0.378934770822525
Validation loss: 1.533897865203119

Epoch: 6| Step: 4
Training loss: 0.2041807621717453
Validation loss: 1.5457639104576522

Epoch: 6| Step: 5
Training loss: 0.17497247457504272
Validation loss: 1.545473660192182

Epoch: 6| Step: 6
Training loss: 0.2948615849018097
Validation loss: 1.5653750691362607

Epoch: 6| Step: 7
Training loss: 0.21598786115646362
Validation loss: 1.5604428475902927

Epoch: 6| Step: 8
Training loss: 0.2591758370399475
Validation loss: 1.542425371626372

Epoch: 6| Step: 9
Training loss: 0.16479231417179108
Validation loss: 1.5700610273627824

Epoch: 6| Step: 10
Training loss: 0.3101204037666321
Validation loss: 1.5495088818252727

Epoch: 6| Step: 11
Training loss: 0.161587193608284
Validation loss: 1.5197064838101786

Epoch: 6| Step: 12
Training loss: 0.08810734748840332
Validation loss: 1.5612275997797649

Epoch: 6| Step: 13
Training loss: 0.17219363152980804
Validation loss: 1.5142341429187405

Epoch: 334| Step: 0
Training loss: 0.1290210485458374
Validation loss: 1.5427082020749328

Epoch: 6| Step: 1
Training loss: 0.18788427114486694
Validation loss: 1.5454157962593982

Epoch: 6| Step: 2
Training loss: 0.27412012219429016
Validation loss: 1.570752591215154

Epoch: 6| Step: 3
Training loss: 0.15222172439098358
Validation loss: 1.5314517290361467

Epoch: 6| Step: 4
Training loss: 0.17721091210842133
Validation loss: 1.5530699606864684

Epoch: 6| Step: 5
Training loss: 0.3178848624229431
Validation loss: 1.5815779342446277

Epoch: 6| Step: 6
Training loss: 0.15614178776741028
Validation loss: 1.539472596619719

Epoch: 6| Step: 7
Training loss: 0.42738908529281616
Validation loss: 1.5330087869398055

Epoch: 6| Step: 8
Training loss: 0.35051339864730835
Validation loss: 1.5150067165333738

Epoch: 6| Step: 9
Training loss: 0.16425129771232605
Validation loss: 1.5091290179119314

Epoch: 6| Step: 10
Training loss: 0.14303813874721527
Validation loss: 1.5091719563289354

Epoch: 6| Step: 11
Training loss: 0.11945019662380219
Validation loss: 1.4832274926606046

Epoch: 6| Step: 12
Training loss: 0.21196648478507996
Validation loss: 1.4674505777256464

Epoch: 6| Step: 13
Training loss: 0.16664353013038635
Validation loss: 1.4722617428789857

Epoch: 335| Step: 0
Training loss: 0.3869168162345886
Validation loss: 1.4892078413758227

Epoch: 6| Step: 1
Training loss: 0.18016499280929565
Validation loss: 1.5401736408151605

Epoch: 6| Step: 2
Training loss: 0.24360230565071106
Validation loss: 1.527557776820275

Epoch: 6| Step: 3
Training loss: 0.21697752177715302
Validation loss: 1.5718212807050316

Epoch: 6| Step: 4
Training loss: 0.17968475818634033
Validation loss: 1.6295802413776357

Epoch: 6| Step: 5
Training loss: 0.1595063954591751
Validation loss: 1.6758847403269943

Epoch: 6| Step: 6
Training loss: 0.22457270324230194
Validation loss: 1.7053991735622447

Epoch: 6| Step: 7
Training loss: 0.3944094181060791
Validation loss: 1.6888466496621408

Epoch: 6| Step: 8
Training loss: 0.19693554937839508
Validation loss: 1.6819543364227458

Epoch: 6| Step: 9
Training loss: 0.22583888471126556
Validation loss: 1.6390141146157378

Epoch: 6| Step: 10
Training loss: 0.477520227432251
Validation loss: 1.6139497500593945

Epoch: 6| Step: 11
Training loss: 0.17246225476264954
Validation loss: 1.6227805063288698

Epoch: 6| Step: 12
Training loss: 0.1358705312013626
Validation loss: 1.5849942468827771

Epoch: 6| Step: 13
Training loss: 0.21777532994747162
Validation loss: 1.5467632906411284

Epoch: 336| Step: 0
Training loss: 0.19855543971061707
Validation loss: 1.51325249479663

Epoch: 6| Step: 1
Training loss: 0.1780489981174469
Validation loss: 1.5175701469503424

Epoch: 6| Step: 2
Training loss: 0.13949650526046753
Validation loss: 1.4995129646793488

Epoch: 6| Step: 3
Training loss: 0.14858877658843994
Validation loss: 1.5423754415204447

Epoch: 6| Step: 4
Training loss: 0.46213215589523315
Validation loss: 1.5344952178257767

Epoch: 6| Step: 5
Training loss: 0.12495496869087219
Validation loss: 1.5030167512996222

Epoch: 6| Step: 6
Training loss: 0.3816205561161041
Validation loss: 1.5189072880693661

Epoch: 6| Step: 7
Training loss: 0.1472807377576828
Validation loss: 1.5170494779463737

Epoch: 6| Step: 8
Training loss: 0.25412240624427795
Validation loss: 1.5297224201181883

Epoch: 6| Step: 9
Training loss: 0.1876591145992279
Validation loss: 1.5797971961318806

Epoch: 6| Step: 10
Training loss: 0.26615333557128906
Validation loss: 1.600806354194559

Epoch: 6| Step: 11
Training loss: 0.4494393765926361
Validation loss: 1.5874224785835511

Epoch: 6| Step: 12
Training loss: 0.23518703877925873
Validation loss: 1.6151101743021319

Epoch: 6| Step: 13
Training loss: 0.22367241978645325
Validation loss: 1.6079619456362981

Epoch: 337| Step: 0
Training loss: 0.2038346827030182
Validation loss: 1.5770076346653763

Epoch: 6| Step: 1
Training loss: 0.38666605949401855
Validation loss: 1.5906357111469391

Epoch: 6| Step: 2
Training loss: 0.21405129134655
Validation loss: 1.584425430144033

Epoch: 6| Step: 3
Training loss: 0.22992335259914398
Validation loss: 1.5684412243545696

Epoch: 6| Step: 4
Training loss: 0.3161054253578186
Validation loss: 1.580369730149546

Epoch: 6| Step: 5
Training loss: 0.2579362392425537
Validation loss: 1.5688489342248568

Epoch: 6| Step: 6
Training loss: 0.18201139569282532
Validation loss: 1.5604899352596653

Epoch: 6| Step: 7
Training loss: 0.1805690973997116
Validation loss: 1.5433756869326356

Epoch: 6| Step: 8
Training loss: 0.17540638148784637
Validation loss: 1.5394176706191032

Epoch: 6| Step: 9
Training loss: 0.46280863881111145
Validation loss: 1.52983594453463

Epoch: 6| Step: 10
Training loss: 0.1201765164732933
Validation loss: 1.5454947845910185

Epoch: 6| Step: 11
Training loss: 0.1559636890888214
Validation loss: 1.5731521370590373

Epoch: 6| Step: 12
Training loss: 0.2778405249118805
Validation loss: 1.557332973326406

Epoch: 6| Step: 13
Training loss: 0.10023969411849976
Validation loss: 1.5902184658153082

Epoch: 338| Step: 0
Training loss: 0.23152577877044678
Validation loss: 1.6106512149175007

Epoch: 6| Step: 1
Training loss: 0.4074706733226776
Validation loss: 1.6055545537702498

Epoch: 6| Step: 2
Training loss: 0.2199905663728714
Validation loss: 1.5889855251517346

Epoch: 6| Step: 3
Training loss: 0.17883208394050598
Validation loss: 1.5608820985722285

Epoch: 6| Step: 4
Training loss: 0.10258860141038895
Validation loss: 1.543409965371573

Epoch: 6| Step: 5
Training loss: 0.30786949396133423
Validation loss: 1.509731682397986

Epoch: 6| Step: 6
Training loss: 0.3021402060985565
Validation loss: 1.5075318697960145

Epoch: 6| Step: 7
Training loss: 0.11292195320129395
Validation loss: 1.5053508666253859

Epoch: 6| Step: 8
Training loss: 0.1828032284975052
Validation loss: 1.5400220296716178

Epoch: 6| Step: 9
Training loss: 0.3089953362941742
Validation loss: 1.5213659219844367

Epoch: 6| Step: 10
Training loss: 0.22780784964561462
Validation loss: 1.5269032793660318

Epoch: 6| Step: 11
Training loss: 0.1782950758934021
Validation loss: 1.543656720269111

Epoch: 6| Step: 12
Training loss: 0.5227338075637817
Validation loss: 1.5496134437540525

Epoch: 6| Step: 13
Training loss: 0.11802869290113449
Validation loss: 1.575242587315139

Epoch: 339| Step: 0
Training loss: 0.22555756568908691
Validation loss: 1.5953614570761239

Epoch: 6| Step: 1
Training loss: 0.129917711019516
Validation loss: 1.6105709434837423

Epoch: 6| Step: 2
Training loss: 0.42191261053085327
Validation loss: 1.6582073870525564

Epoch: 6| Step: 3
Training loss: 0.239169180393219
Validation loss: 1.658922363353032

Epoch: 6| Step: 4
Training loss: 0.23488633334636688
Validation loss: 1.602779511482485

Epoch: 6| Step: 5
Training loss: 0.09356480836868286
Validation loss: 1.586576597664946

Epoch: 6| Step: 6
Training loss: 0.3501695692539215
Validation loss: 1.5712866603687246

Epoch: 6| Step: 7
Training loss: 0.20421230792999268
Validation loss: 1.5584147412289855

Epoch: 6| Step: 8
Training loss: 0.20296187698841095
Validation loss: 1.536807999815992

Epoch: 6| Step: 9
Training loss: 0.1877257525920868
Validation loss: 1.5430877849619875

Epoch: 6| Step: 10
Training loss: 0.16083839535713196
Validation loss: 1.5683857881894676

Epoch: 6| Step: 11
Training loss: 0.2192418873310089
Validation loss: 1.5618320511233421

Epoch: 6| Step: 12
Training loss: 0.15412411093711853
Validation loss: 1.5580353634331816

Epoch: 6| Step: 13
Training loss: 0.5086660385131836
Validation loss: 1.5805118929955266

Epoch: 340| Step: 0
Training loss: 0.3575740158557892
Validation loss: 1.6532511736757012

Epoch: 6| Step: 1
Training loss: 0.4817366600036621
Validation loss: 1.6616204707853255

Epoch: 6| Step: 2
Training loss: 0.4675259590148926
Validation loss: 1.650990843131978

Epoch: 6| Step: 3
Training loss: 0.3139748275279999
Validation loss: 1.5936176738431376

Epoch: 6| Step: 4
Training loss: 0.1677323579788208
Validation loss: 1.601405393692755

Epoch: 6| Step: 5
Training loss: 0.2555480897426605
Validation loss: 1.5816541423079788

Epoch: 6| Step: 6
Training loss: 0.21818608045578003
Validation loss: 1.5789339568025322

Epoch: 6| Step: 7
Training loss: 0.19825038313865662
Validation loss: 1.5991343875085153

Epoch: 6| Step: 8
Training loss: 0.27640360593795776
Validation loss: 1.575418536381055

Epoch: 6| Step: 9
Training loss: 0.23317788541316986
Validation loss: 1.5459714961308304

Epoch: 6| Step: 10
Training loss: 0.2267850935459137
Validation loss: 1.5464957657680716

Epoch: 6| Step: 11
Training loss: 0.3309284448623657
Validation loss: 1.5696329025812046

Epoch: 6| Step: 12
Training loss: 0.16209430992603302
Validation loss: 1.5335483768934846

Epoch: 6| Step: 13
Training loss: 0.12756772339344025
Validation loss: 1.55825767337635

Epoch: 341| Step: 0
Training loss: 0.1820462942123413
Validation loss: 1.603425225903911

Epoch: 6| Step: 1
Training loss: 0.15530851483345032
Validation loss: 1.5964192216114332

Epoch: 6| Step: 2
Training loss: 0.2345883548259735
Validation loss: 1.6248472762364212

Epoch: 6| Step: 3
Training loss: 0.3967440724372864
Validation loss: 1.630935530508718

Epoch: 6| Step: 4
Training loss: 0.2847707271575928
Validation loss: 1.604274857428766

Epoch: 6| Step: 5
Training loss: 0.18907132744789124
Validation loss: 1.5854576736368158

Epoch: 6| Step: 6
Training loss: 0.3009052872657776
Validation loss: 1.5526517847532868

Epoch: 6| Step: 7
Training loss: 0.37605994939804077
Validation loss: 1.5207762013199508

Epoch: 6| Step: 8
Training loss: 0.2855212092399597
Validation loss: 1.5113121399315455

Epoch: 6| Step: 9
Training loss: 0.17402833700180054
Validation loss: 1.5302656401870072

Epoch: 6| Step: 10
Training loss: 0.20432764291763306
Validation loss: 1.5160786092922252

Epoch: 6| Step: 11
Training loss: 0.13556483387947083
Validation loss: 1.4866073323834328

Epoch: 6| Step: 12
Training loss: 0.3843901455402374
Validation loss: 1.4880747961741623

Epoch: 6| Step: 13
Training loss: 0.3487529754638672
Validation loss: 1.4726693822491554

Epoch: 342| Step: 0
Training loss: 0.15423712134361267
Validation loss: 1.475768998745949

Epoch: 6| Step: 1
Training loss: 0.15754085779190063
Validation loss: 1.4712344638762935

Epoch: 6| Step: 2
Training loss: 0.19618991017341614
Validation loss: 1.47897966190051

Epoch: 6| Step: 3
Training loss: 0.2913518249988556
Validation loss: 1.491082719577256

Epoch: 6| Step: 4
Training loss: 0.13975191116333008
Validation loss: 1.5196034254566315

Epoch: 6| Step: 5
Training loss: 0.23736685514450073
Validation loss: 1.533108885570239

Epoch: 6| Step: 6
Training loss: 0.45539599657058716
Validation loss: 1.5360288850722774

Epoch: 6| Step: 7
Training loss: 0.13546547293663025
Validation loss: 1.537041465441386

Epoch: 6| Step: 8
Training loss: 0.18787814676761627
Validation loss: 1.544478029333135

Epoch: 6| Step: 9
Training loss: 0.17840386927127838
Validation loss: 1.5457212591683993

Epoch: 6| Step: 10
Training loss: 0.16248023509979248
Validation loss: 1.575649929943905

Epoch: 6| Step: 11
Training loss: 0.366868257522583
Validation loss: 1.6229151679623512

Epoch: 6| Step: 12
Training loss: 0.17644807696342468
Validation loss: 1.6044143233247983

Epoch: 6| Step: 13
Training loss: 0.5183010101318359
Validation loss: 1.6338309728971092

Epoch: 343| Step: 0
Training loss: 0.21444012224674225
Validation loss: 1.631686883587991

Epoch: 6| Step: 1
Training loss: 0.3455634117126465
Validation loss: 1.625227084723852

Epoch: 6| Step: 2
Training loss: 0.18736737966537476
Validation loss: 1.610349884597204

Epoch: 6| Step: 3
Training loss: 0.1725538969039917
Validation loss: 1.601238755769627

Epoch: 6| Step: 4
Training loss: 0.2509394884109497
Validation loss: 1.5690291799524778

Epoch: 6| Step: 5
Training loss: 0.20043420791625977
Validation loss: 1.5352604312281455

Epoch: 6| Step: 6
Training loss: 0.16579023003578186
Validation loss: 1.5313523148977628

Epoch: 6| Step: 7
Training loss: 0.1953854113817215
Validation loss: 1.5505359236912062

Epoch: 6| Step: 8
Training loss: 0.3118422031402588
Validation loss: 1.5803541291144587

Epoch: 6| Step: 9
Training loss: 0.3539075553417206
Validation loss: 1.5632234773328226

Epoch: 6| Step: 10
Training loss: 0.17150208353996277
Validation loss: 1.5864941766185146

Epoch: 6| Step: 11
Training loss: 0.25324535369873047
Validation loss: 1.608113847753053

Epoch: 6| Step: 12
Training loss: 0.4135858416557312
Validation loss: 1.6120076512777677

Epoch: 6| Step: 13
Training loss: 0.579544723033905
Validation loss: 1.613148521351558

Epoch: 344| Step: 0
Training loss: 0.3183651566505432
Validation loss: 1.6070397771814817

Epoch: 6| Step: 1
Training loss: 0.21716183423995972
Validation loss: 1.6186343098199496

Epoch: 6| Step: 2
Training loss: 0.21746693551540375
Validation loss: 1.6191093678115516

Epoch: 6| Step: 3
Training loss: 0.34503716230392456
Validation loss: 1.5626268309931601

Epoch: 6| Step: 4
Training loss: 0.16814404726028442
Validation loss: 1.5696063016050605

Epoch: 6| Step: 5
Training loss: 0.21119064092636108
Validation loss: 1.5847460710874168

Epoch: 6| Step: 6
Training loss: 0.18137049674987793
Validation loss: 1.5481828290929076

Epoch: 6| Step: 7
Training loss: 0.15480734407901764
Validation loss: 1.5625383289911414

Epoch: 6| Step: 8
Training loss: 0.170017272233963
Validation loss: 1.5493131593991352

Epoch: 6| Step: 9
Training loss: 0.09051644802093506
Validation loss: 1.5409763448981828

Epoch: 6| Step: 10
Training loss: 0.3688516616821289
Validation loss: 1.5509190379932363

Epoch: 6| Step: 11
Training loss: 0.4300681948661804
Validation loss: 1.5158003350739837

Epoch: 6| Step: 12
Training loss: 0.14016078412532806
Validation loss: 1.5193542818869314

Epoch: 6| Step: 13
Training loss: 0.36287224292755127
Validation loss: 1.5229273944772699

Epoch: 345| Step: 0
Training loss: 0.19832399487495422
Validation loss: 1.5345599407790809

Epoch: 6| Step: 1
Training loss: 0.15661513805389404
Validation loss: 1.4873933202476912

Epoch: 6| Step: 2
Training loss: 0.11728804558515549
Validation loss: 1.4881183255103327

Epoch: 6| Step: 3
Training loss: 0.15176008641719818
Validation loss: 1.497718798216953

Epoch: 6| Step: 4
Training loss: 0.13138258457183838
Validation loss: 1.5226898667632893

Epoch: 6| Step: 5
Training loss: 0.14867274463176727
Validation loss: 1.5196169153336556

Epoch: 6| Step: 6
Training loss: 0.18567553162574768
Validation loss: 1.5382731627392512

Epoch: 6| Step: 7
Training loss: 0.22182482481002808
Validation loss: 1.5738728636054582

Epoch: 6| Step: 8
Training loss: 0.20325732231140137
Validation loss: 1.5747826227577784

Epoch: 6| Step: 9
Training loss: 0.5359145402908325
Validation loss: 1.5821370014580347

Epoch: 6| Step: 10
Training loss: 0.2021423876285553
Validation loss: 1.5553594007286975

Epoch: 6| Step: 11
Training loss: 0.28271064162254333
Validation loss: 1.5337005123015373

Epoch: 6| Step: 12
Training loss: 0.3984636068344116
Validation loss: 1.5416038113255655

Epoch: 6| Step: 13
Training loss: 0.2592943608760834
Validation loss: 1.5002166660883094

Epoch: 346| Step: 0
Training loss: 0.3235967457294464
Validation loss: 1.5031119085127307

Epoch: 6| Step: 1
Training loss: 0.21264706552028656
Validation loss: 1.5081161132422827

Epoch: 6| Step: 2
Training loss: 0.1580522507429123
Validation loss: 1.5563508579807896

Epoch: 6| Step: 3
Training loss: 0.3790353238582611
Validation loss: 1.5612849022752495

Epoch: 6| Step: 4
Training loss: 0.2808332145214081
Validation loss: 1.5294626271852882

Epoch: 6| Step: 5
Training loss: 0.25892019271850586
Validation loss: 1.5315606324903426

Epoch: 6| Step: 6
Training loss: 0.197544127702713
Validation loss: 1.5481180606349823

Epoch: 6| Step: 7
Training loss: 0.1966131627559662
Validation loss: 1.576064194402387

Epoch: 6| Step: 8
Training loss: 0.19736520946025848
Validation loss: 1.601103445535065

Epoch: 6| Step: 9
Training loss: 0.12213751673698425
Validation loss: 1.6310801352224042

Epoch: 6| Step: 10
Training loss: 0.23092888295650482
Validation loss: 1.6490996960670716

Epoch: 6| Step: 11
Training loss: 0.47585999965667725
Validation loss: 1.6851748817710466

Epoch: 6| Step: 12
Training loss: 0.4033692181110382
Validation loss: 1.6615865358742334

Epoch: 6| Step: 13
Training loss: 0.6027347445487976
Validation loss: 1.6538481340613416

Epoch: 347| Step: 0
Training loss: 0.1795460730791092
Validation loss: 1.5906724019717144

Epoch: 6| Step: 1
Training loss: 0.2255626767873764
Validation loss: 1.5810492269454464

Epoch: 6| Step: 2
Training loss: 0.4455007314682007
Validation loss: 1.5361318261392656

Epoch: 6| Step: 3
Training loss: 0.3153080344200134
Validation loss: 1.5474880741488548

Epoch: 6| Step: 4
Training loss: 0.3616463243961334
Validation loss: 1.5348869100693734

Epoch: 6| Step: 5
Training loss: 0.15842783451080322
Validation loss: 1.5458512857396116

Epoch: 6| Step: 6
Training loss: 0.23334619402885437
Validation loss: 1.555867115656535

Epoch: 6| Step: 7
Training loss: 0.2722846269607544
Validation loss: 1.4999636821849371

Epoch: 6| Step: 8
Training loss: 0.18693536520004272
Validation loss: 1.5256749032646097

Epoch: 6| Step: 9
Training loss: 0.37852978706359863
Validation loss: 1.5307851068435177

Epoch: 6| Step: 10
Training loss: 0.17263802886009216
Validation loss: 1.5773460377929032

Epoch: 6| Step: 11
Training loss: 0.23308157920837402
Validation loss: 1.5671193394609677

Epoch: 6| Step: 12
Training loss: 0.15671326220035553
Validation loss: 1.5970391368353238

Epoch: 6| Step: 13
Training loss: 0.19167381525039673
Validation loss: 1.6015906346741544

Epoch: 348| Step: 0
Training loss: 0.19632653892040253
Validation loss: 1.6290292252776444

Epoch: 6| Step: 1
Training loss: 0.2360471934080124
Validation loss: 1.6079821253335604

Epoch: 6| Step: 2
Training loss: 0.16534803807735443
Validation loss: 1.5875412392359909

Epoch: 6| Step: 3
Training loss: 0.21000072360038757
Validation loss: 1.584640710584579

Epoch: 6| Step: 4
Training loss: 0.1920926868915558
Validation loss: 1.5868492587920158

Epoch: 6| Step: 5
Training loss: 0.17642700672149658
Validation loss: 1.5591550014352287

Epoch: 6| Step: 6
Training loss: 0.2416365146636963
Validation loss: 1.5412094118774577

Epoch: 6| Step: 7
Training loss: 0.3716069161891937
Validation loss: 1.5327312523318875

Epoch: 6| Step: 8
Training loss: 0.22472341358661652
Validation loss: 1.5410620012590963

Epoch: 6| Step: 9
Training loss: 0.25691312551498413
Validation loss: 1.5386420219175276

Epoch: 6| Step: 10
Training loss: 0.48995763063430786
Validation loss: 1.563559345019761

Epoch: 6| Step: 11
Training loss: 0.19226881861686707
Validation loss: 1.5518549360254759

Epoch: 6| Step: 12
Training loss: 0.17418301105499268
Validation loss: 1.55280908589722

Epoch: 6| Step: 13
Training loss: 0.14032207429409027
Validation loss: 1.6027738791640087

Epoch: 349| Step: 0
Training loss: 0.3407074511051178
Validation loss: 1.6287637769535024

Epoch: 6| Step: 1
Training loss: 0.20007044076919556
Validation loss: 1.635813408000495

Epoch: 6| Step: 2
Training loss: 0.20145897567272186
Validation loss: 1.6276964808023104

Epoch: 6| Step: 3
Training loss: 0.23317554593086243
Validation loss: 1.6558247074004142

Epoch: 6| Step: 4
Training loss: 0.218154639005661
Validation loss: 1.6568145828862344

Epoch: 6| Step: 5
Training loss: 0.31579697132110596
Validation loss: 1.6205515246237479

Epoch: 6| Step: 6
Training loss: 0.40041857957839966
Validation loss: 1.6075737694258332

Epoch: 6| Step: 7
Training loss: 0.10977356880903244
Validation loss: 1.5607412348511398

Epoch: 6| Step: 8
Training loss: 0.13660013675689697
Validation loss: 1.5131608388757194

Epoch: 6| Step: 9
Training loss: 0.19008061289787292
Validation loss: 1.5467370492155834

Epoch: 6| Step: 10
Training loss: 0.16219791769981384
Validation loss: 1.4966446930362332

Epoch: 6| Step: 11
Training loss: 0.23866868019104004
Validation loss: 1.5105327149873138

Epoch: 6| Step: 12
Training loss: 0.20123222470283508
Validation loss: 1.5098902948441044

Epoch: 6| Step: 13
Training loss: 0.1407126933336258
Validation loss: 1.48166662005968

Epoch: 350| Step: 0
Training loss: 0.14307276904582977
Validation loss: 1.500120061700062

Epoch: 6| Step: 1
Training loss: 0.13369475305080414
Validation loss: 1.470799228196503

Epoch: 6| Step: 2
Training loss: 0.16441881656646729
Validation loss: 1.450638081437798

Epoch: 6| Step: 3
Training loss: 0.21621976792812347
Validation loss: 1.465519893553949

Epoch: 6| Step: 4
Training loss: 0.1753915548324585
Validation loss: 1.4653194335199171

Epoch: 6| Step: 5
Training loss: 0.18294575810432434
Validation loss: 1.5024087416228427

Epoch: 6| Step: 6
Training loss: 0.17173457145690918
Validation loss: 1.5033202991690686

Epoch: 6| Step: 7
Training loss: 0.41371506452560425
Validation loss: 1.5345292873280023

Epoch: 6| Step: 8
Training loss: 0.17613519728183746
Validation loss: 1.5456223410944785

Epoch: 6| Step: 9
Training loss: 0.2773492932319641
Validation loss: 1.5571676851600729

Epoch: 6| Step: 10
Training loss: 0.6073548793792725
Validation loss: 1.5373791956132459

Epoch: 6| Step: 11
Training loss: 0.3010931611061096
Validation loss: 1.5324758316880913

Epoch: 6| Step: 12
Training loss: 0.19031375646591187
Validation loss: 1.5135500136242117

Epoch: 6| Step: 13
Training loss: 0.15431807935237885
Validation loss: 1.5217604201327088

Epoch: 351| Step: 0
Training loss: 0.3227427005767822
Validation loss: 1.5362810165651384

Epoch: 6| Step: 1
Training loss: 0.15634608268737793
Validation loss: 1.5598235687901896

Epoch: 6| Step: 2
Training loss: 0.2899903655052185
Validation loss: 1.5978744042816984

Epoch: 6| Step: 3
Training loss: 0.1986059844493866
Validation loss: 1.6047884007935882

Epoch: 6| Step: 4
Training loss: 0.24627920985221863
Validation loss: 1.620306449551736

Epoch: 6| Step: 5
Training loss: 0.19095134735107422
Validation loss: 1.6314513209045574

Epoch: 6| Step: 6
Training loss: 0.23403212428092957
Validation loss: 1.6338973942623343

Epoch: 6| Step: 7
Training loss: 0.12123756110668182
Validation loss: 1.5853618139861732

Epoch: 6| Step: 8
Training loss: 0.2720470428466797
Validation loss: 1.5932169960391136

Epoch: 6| Step: 9
Training loss: 0.10233922302722931
Validation loss: 1.5597176007045213

Epoch: 6| Step: 10
Training loss: 0.20035651326179504
Validation loss: 1.559459520924476

Epoch: 6| Step: 11
Training loss: 0.35578539967536926
Validation loss: 1.5573137114124913

Epoch: 6| Step: 12
Training loss: 0.19786210358142853
Validation loss: 1.5528964573337185

Epoch: 6| Step: 13
Training loss: 0.11827794462442398
Validation loss: 1.5513933268926476

Epoch: 352| Step: 0
Training loss: 0.1680644452571869
Validation loss: 1.541310053999706

Epoch: 6| Step: 1
Training loss: 0.11635254323482513
Validation loss: 1.5376823935457455

Epoch: 6| Step: 2
Training loss: 0.15512672066688538
Validation loss: 1.5573521070582892

Epoch: 6| Step: 3
Training loss: 0.12795253098011017
Validation loss: 1.5647345499325824

Epoch: 6| Step: 4
Training loss: 0.3103220462799072
Validation loss: 1.598313077803581

Epoch: 6| Step: 5
Training loss: 0.1306082010269165
Validation loss: 1.5954100085842995

Epoch: 6| Step: 6
Training loss: 0.5208834409713745
Validation loss: 1.592866741200929

Epoch: 6| Step: 7
Training loss: 0.17252600193023682
Validation loss: 1.6024260277389197

Epoch: 6| Step: 8
Training loss: 0.15844708681106567
Validation loss: 1.5637822728003226

Epoch: 6| Step: 9
Training loss: 0.16094937920570374
Validation loss: 1.5663431588039602

Epoch: 6| Step: 10
Training loss: 0.11494961380958557
Validation loss: 1.5686557395483858

Epoch: 6| Step: 11
Training loss: 0.1982652246952057
Validation loss: 1.553902925983552

Epoch: 6| Step: 12
Training loss: 0.14077842235565186
Validation loss: 1.5560075057450162

Epoch: 6| Step: 13
Training loss: 0.22186507284641266
Validation loss: 1.5625307226693759

Epoch: 353| Step: 0
Training loss: 0.3049318492412567
Validation loss: 1.5548301550649828

Epoch: 6| Step: 1
Training loss: 0.14343120157718658
Validation loss: 1.5470195329317482

Epoch: 6| Step: 2
Training loss: 0.2686189115047455
Validation loss: 1.550665481116182

Epoch: 6| Step: 3
Training loss: 0.130161315202713
Validation loss: 1.5423249108816988

Epoch: 6| Step: 4
Training loss: 0.22729170322418213
Validation loss: 1.5288447609511755

Epoch: 6| Step: 5
Training loss: 0.17203199863433838
Validation loss: 1.5189156968106505

Epoch: 6| Step: 6
Training loss: 0.14043402671813965
Validation loss: 1.5487222953509259

Epoch: 6| Step: 7
Training loss: 0.13554927706718445
Validation loss: 1.5298536733914447

Epoch: 6| Step: 8
Training loss: 0.26503098011016846
Validation loss: 1.5352070985301849

Epoch: 6| Step: 9
Training loss: 0.09391595423221588
Validation loss: 1.5193995480896325

Epoch: 6| Step: 10
Training loss: 0.2523733675479889
Validation loss: 1.5306871539802962

Epoch: 6| Step: 11
Training loss: 0.09345108270645142
Validation loss: 1.490588172789543

Epoch: 6| Step: 12
Training loss: 0.24454817175865173
Validation loss: 1.5262309235911216

Epoch: 6| Step: 13
Training loss: 0.15595592558383942
Validation loss: 1.5570465659582486

Epoch: 354| Step: 0
Training loss: 0.3665510416030884
Validation loss: 1.5627137935289772

Epoch: 6| Step: 1
Training loss: 0.19922375679016113
Validation loss: 1.6059204621981549

Epoch: 6| Step: 2
Training loss: 0.09071503579616547
Validation loss: 1.560474217578929

Epoch: 6| Step: 3
Training loss: 0.2944108247756958
Validation loss: 1.6016363661776307

Epoch: 6| Step: 4
Training loss: 0.15171849727630615
Validation loss: 1.5751010769157

Epoch: 6| Step: 5
Training loss: 0.16849279403686523
Validation loss: 1.5559391795947988

Epoch: 6| Step: 6
Training loss: 0.15624424815177917
Validation loss: 1.5425247851238455

Epoch: 6| Step: 7
Training loss: 0.3569547235965729
Validation loss: 1.5418452524369763

Epoch: 6| Step: 8
Training loss: 0.19105027616024017
Validation loss: 1.5122343186409242

Epoch: 6| Step: 9
Training loss: 0.1824234575033188
Validation loss: 1.547882149296422

Epoch: 6| Step: 10
Training loss: 0.20134183764457703
Validation loss: 1.5225024454055294

Epoch: 6| Step: 11
Training loss: 0.10488811880350113
Validation loss: 1.496380857242051

Epoch: 6| Step: 12
Training loss: 0.20282548666000366
Validation loss: 1.4903677791677497

Epoch: 6| Step: 13
Training loss: 0.13349583745002747
Validation loss: 1.4867311113624162

Epoch: 355| Step: 0
Training loss: 0.31889021396636963
Validation loss: 1.483434736087758

Epoch: 6| Step: 1
Training loss: 0.3744284212589264
Validation loss: 1.5181214719690301

Epoch: 6| Step: 2
Training loss: 0.12024092674255371
Validation loss: 1.494210663662162

Epoch: 6| Step: 3
Training loss: 0.10234717279672623
Validation loss: 1.5003109734545472

Epoch: 6| Step: 4
Training loss: 0.16597571969032288
Validation loss: 1.5131049310007403

Epoch: 6| Step: 5
Training loss: 0.1606840193271637
Validation loss: 1.4966066486092025

Epoch: 6| Step: 6
Training loss: 0.1436462700366974
Validation loss: 1.5144805549293436

Epoch: 6| Step: 7
Training loss: 0.1416008025407791
Validation loss: 1.5395653760561379

Epoch: 6| Step: 8
Training loss: 0.12241249531507492
Validation loss: 1.5411699818026634

Epoch: 6| Step: 9
Training loss: 0.3596338629722595
Validation loss: 1.556961682534987

Epoch: 6| Step: 10
Training loss: 0.13554760813713074
Validation loss: 1.5443088982694892

Epoch: 6| Step: 11
Training loss: 0.15512782335281372
Validation loss: 1.5630911755305466

Epoch: 6| Step: 12
Training loss: 0.10918020457029343
Validation loss: 1.5798220326823573

Epoch: 6| Step: 13
Training loss: 0.17164114117622375
Validation loss: 1.5715973582319034

Epoch: 356| Step: 0
Training loss: 0.14311081171035767
Validation loss: 1.5781232028879144

Epoch: 6| Step: 1
Training loss: 0.13923531770706177
Validation loss: 1.552861786657764

Epoch: 6| Step: 2
Training loss: 0.12039149552583694
Validation loss: 1.5794462632107478

Epoch: 6| Step: 3
Training loss: 0.171673983335495
Validation loss: 1.5519226904838317

Epoch: 6| Step: 4
Training loss: 0.1237402930855751
Validation loss: 1.5563901778190368

Epoch: 6| Step: 5
Training loss: 0.2792331576347351
Validation loss: 1.537693122381805

Epoch: 6| Step: 6
Training loss: 0.15007776021957397
Validation loss: 1.5173178475390199

Epoch: 6| Step: 7
Training loss: 0.17354315519332886
Validation loss: 1.5404327838651595

Epoch: 6| Step: 8
Training loss: 0.22885973751544952
Validation loss: 1.541513737811837

Epoch: 6| Step: 9
Training loss: 0.1383381485939026
Validation loss: 1.5170672375668761

Epoch: 6| Step: 10
Training loss: 0.29171356558799744
Validation loss: 1.5248208943233694

Epoch: 6| Step: 11
Training loss: 0.20545846223831177
Validation loss: 1.5065397690701228

Epoch: 6| Step: 12
Training loss: 0.29989129304885864
Validation loss: 1.54111994466474

Epoch: 6| Step: 13
Training loss: 0.18362712860107422
Validation loss: 1.5601082501872894

Epoch: 357| Step: 0
Training loss: 0.18043744564056396
Validation loss: 1.546866964268428

Epoch: 6| Step: 1
Training loss: 0.18878169357776642
Validation loss: 1.561582278179866

Epoch: 6| Step: 2
Training loss: 0.27073249220848083
Validation loss: 1.5601377641001055

Epoch: 6| Step: 3
Training loss: 0.11747249215841293
Validation loss: 1.5578060842329455

Epoch: 6| Step: 4
Training loss: 0.17987249791622162
Validation loss: 1.5516077036498694

Epoch: 6| Step: 5
Training loss: 0.15164943039417267
Validation loss: 1.5473463817309308

Epoch: 6| Step: 6
Training loss: 0.11983562260866165
Validation loss: 1.5668822808932232

Epoch: 6| Step: 7
Training loss: 0.31251421570777893
Validation loss: 1.5589818685285506

Epoch: 6| Step: 8
Training loss: 0.10631735622882843
Validation loss: 1.5481994600706204

Epoch: 6| Step: 9
Training loss: 0.2777731418609619
Validation loss: 1.5397504209190287

Epoch: 6| Step: 10
Training loss: 0.12397194653749466
Validation loss: 1.5539283585804764

Epoch: 6| Step: 11
Training loss: 0.2020626664161682
Validation loss: 1.5395024348330755

Epoch: 6| Step: 12
Training loss: 0.14821158349514008
Validation loss: 1.5487843892907585

Epoch: 6| Step: 13
Training loss: 0.16275092959403992
Validation loss: 1.536267884315983

Epoch: 358| Step: 0
Training loss: 0.1328672617673874
Validation loss: 1.5245945799735285

Epoch: 6| Step: 1
Training loss: 0.2680776119232178
Validation loss: 1.5382259276605421

Epoch: 6| Step: 2
Training loss: 0.3215785622596741
Validation loss: 1.533682523235198

Epoch: 6| Step: 3
Training loss: 0.1815151870250702
Validation loss: 1.553781819599931

Epoch: 6| Step: 4
Training loss: 0.3011535108089447
Validation loss: 1.5797909741760583

Epoch: 6| Step: 5
Training loss: 0.17002782225608826
Validation loss: 1.5994761079870246

Epoch: 6| Step: 6
Training loss: 0.18986031413078308
Validation loss: 1.5794983140883907

Epoch: 6| Step: 7
Training loss: 0.19271662831306458
Validation loss: 1.58351158454854

Epoch: 6| Step: 8
Training loss: 0.13429398834705353
Validation loss: 1.5510725391808378

Epoch: 6| Step: 9
Training loss: 0.15421205759048462
Validation loss: 1.5667059870176419

Epoch: 6| Step: 10
Training loss: 0.13532550632953644
Validation loss: 1.5646779203927645

Epoch: 6| Step: 11
Training loss: 0.18287143111228943
Validation loss: 1.5859722418169822

Epoch: 6| Step: 12
Training loss: 0.12906669080257416
Validation loss: 1.5625077037401096

Epoch: 6| Step: 13
Training loss: 0.20011723041534424
Validation loss: 1.5761977562340357

Epoch: 359| Step: 0
Training loss: 0.11228957772254944
Validation loss: 1.5706602565703853

Epoch: 6| Step: 1
Training loss: 0.13095000386238098
Validation loss: 1.5405463903181014

Epoch: 6| Step: 2
Training loss: 0.09348288178443909
Validation loss: 1.5603856719950193

Epoch: 6| Step: 3
Training loss: 0.2975609302520752
Validation loss: 1.5704617833578458

Epoch: 6| Step: 4
Training loss: 0.10728902369737625
Validation loss: 1.5544448578229515

Epoch: 6| Step: 5
Training loss: 0.1559932678937912
Validation loss: 1.537863637170484

Epoch: 6| Step: 6
Training loss: 0.13869673013687134
Validation loss: 1.5674477302899925

Epoch: 6| Step: 7
Training loss: 0.15197110176086426
Validation loss: 1.5928147121142315

Epoch: 6| Step: 8
Training loss: 0.344753623008728
Validation loss: 1.5801206301617365

Epoch: 6| Step: 9
Training loss: 0.173694908618927
Validation loss: 1.5756826810939337

Epoch: 6| Step: 10
Training loss: 0.14239062368869781
Validation loss: 1.5494678738296672

Epoch: 6| Step: 11
Training loss: 0.26189345121383667
Validation loss: 1.5767596408885012

Epoch: 6| Step: 12
Training loss: 0.12663599848747253
Validation loss: 1.5478050080678796

Epoch: 6| Step: 13
Training loss: 0.19864307343959808
Validation loss: 1.535664153355424

Epoch: 360| Step: 0
Training loss: 0.3618890941143036
Validation loss: 1.5478053913321546

Epoch: 6| Step: 1
Training loss: 0.2039211541414261
Validation loss: 1.5355517248953543

Epoch: 6| Step: 2
Training loss: 0.09194919466972351
Validation loss: 1.5599601114949873

Epoch: 6| Step: 3
Training loss: 0.17762324213981628
Validation loss: 1.5244067458696262

Epoch: 6| Step: 4
Training loss: 0.2683030962944031
Validation loss: 1.5672854608105076

Epoch: 6| Step: 5
Training loss: 0.13608382642269135
Validation loss: 1.5953689736704673

Epoch: 6| Step: 6
Training loss: 0.2013348937034607
Validation loss: 1.5926372415275984

Epoch: 6| Step: 7
Training loss: 0.2659306526184082
Validation loss: 1.5989643886525144

Epoch: 6| Step: 8
Training loss: 0.16154389083385468
Validation loss: 1.5952610559360956

Epoch: 6| Step: 9
Training loss: 0.12211644649505615
Validation loss: 1.6115363874743063

Epoch: 6| Step: 10
Training loss: 0.20577242970466614
Validation loss: 1.6102312213631087

Epoch: 6| Step: 11
Training loss: 0.17847707867622375
Validation loss: 1.6125055564347135

Epoch: 6| Step: 12
Training loss: 0.14292103052139282
Validation loss: 1.5937456238654353

Epoch: 6| Step: 13
Training loss: 0.16552229225635529
Validation loss: 1.578949624492276

Epoch: 361| Step: 0
Training loss: 0.09764661639928818
Validation loss: 1.5751508320531538

Epoch: 6| Step: 1
Training loss: 0.3271722197532654
Validation loss: 1.5973080922198553

Epoch: 6| Step: 2
Training loss: 0.17013122141361237
Validation loss: 1.600747214850559

Epoch: 6| Step: 3
Training loss: 0.09724348783493042
Validation loss: 1.597393242261743

Epoch: 6| Step: 4
Training loss: 0.29872220754623413
Validation loss: 1.6082790269646594

Epoch: 6| Step: 5
Training loss: 0.132053941488266
Validation loss: 1.617164537470828

Epoch: 6| Step: 6
Training loss: 0.20052163302898407
Validation loss: 1.5743879143909743

Epoch: 6| Step: 7
Training loss: 0.15748795866966248
Validation loss: 1.551261519873014

Epoch: 6| Step: 8
Training loss: 0.27822408080101013
Validation loss: 1.5639150450306554

Epoch: 6| Step: 9
Training loss: 0.153593972325325
Validation loss: 1.5188274723227306

Epoch: 6| Step: 10
Training loss: 0.1432264894247055
Validation loss: 1.516746763260134

Epoch: 6| Step: 11
Training loss: 0.15373241901397705
Validation loss: 1.551710637666846

Epoch: 6| Step: 12
Training loss: 0.11888553202152252
Validation loss: 1.5159377372393044

Epoch: 6| Step: 13
Training loss: 0.09535995125770569
Validation loss: 1.4972117190719934

Epoch: 362| Step: 0
Training loss: 0.1858181655406952
Validation loss: 1.5072561733184322

Epoch: 6| Step: 1
Training loss: 0.3488597869873047
Validation loss: 1.484469573984864

Epoch: 6| Step: 2
Training loss: 0.13542142510414124
Validation loss: 1.5134156173275364

Epoch: 6| Step: 3
Training loss: 0.14672520756721497
Validation loss: 1.523911940154209

Epoch: 6| Step: 4
Training loss: 0.08990882337093353
Validation loss: 1.5291021889255894

Epoch: 6| Step: 5
Training loss: 0.1482618898153305
Validation loss: 1.511801682492738

Epoch: 6| Step: 6
Training loss: 0.3043418824672699
Validation loss: 1.5237992732755599

Epoch: 6| Step: 7
Training loss: 0.12700863182544708
Validation loss: 1.568471295859224

Epoch: 6| Step: 8
Training loss: 0.1517573893070221
Validation loss: 1.5875990134413525

Epoch: 6| Step: 9
Training loss: 0.19668689370155334
Validation loss: 1.584444474148494

Epoch: 6| Step: 10
Training loss: 0.17845162749290466
Validation loss: 1.5751191954458914

Epoch: 6| Step: 11
Training loss: 0.10347433388233185
Validation loss: 1.585435358426904

Epoch: 6| Step: 12
Training loss: 0.11465173959732056
Validation loss: 1.5815702945955339

Epoch: 6| Step: 13
Training loss: 0.38813579082489014
Validation loss: 1.5601894047952467

Epoch: 363| Step: 0
Training loss: 0.11869879066944122
Validation loss: 1.547428395158501

Epoch: 6| Step: 1
Training loss: 0.3628782629966736
Validation loss: 1.5475584678752448

Epoch: 6| Step: 2
Training loss: 0.09022664278745651
Validation loss: 1.5130885672825638

Epoch: 6| Step: 3
Training loss: 0.17776283621788025
Validation loss: 1.5181266095048638

Epoch: 6| Step: 4
Training loss: 0.18247447907924652
Validation loss: 1.5025128106917105

Epoch: 6| Step: 5
Training loss: 0.21970021724700928
Validation loss: 1.5155318276856535

Epoch: 6| Step: 6
Training loss: 0.14215317368507385
Validation loss: 1.5007318476194977

Epoch: 6| Step: 7
Training loss: 0.13239015638828278
Validation loss: 1.4793556031360422

Epoch: 6| Step: 8
Training loss: 0.16468121111392975
Validation loss: 1.5202993846708728

Epoch: 6| Step: 9
Training loss: 0.1012887954711914
Validation loss: 1.5376382848267913

Epoch: 6| Step: 10
Training loss: 0.25242185592651367
Validation loss: 1.5636212928320772

Epoch: 6| Step: 11
Training loss: 0.22326406836509705
Validation loss: 1.5707010056382866

Epoch: 6| Step: 12
Training loss: 0.31531059741973877
Validation loss: 1.5768086423156082

Epoch: 6| Step: 13
Training loss: 0.2845989763736725
Validation loss: 1.5334514482046968

Epoch: 364| Step: 0
Training loss: 0.14054429531097412
Validation loss: 1.5453736628255537

Epoch: 6| Step: 1
Training loss: 0.15989086031913757
Validation loss: 1.4866775325549546

Epoch: 6| Step: 2
Training loss: 0.09960336238145828
Validation loss: 1.502434028092251

Epoch: 6| Step: 3
Training loss: 0.3238927721977234
Validation loss: 1.4726169442617765

Epoch: 6| Step: 4
Training loss: 0.1776627004146576
Validation loss: 1.4948919127064366

Epoch: 6| Step: 5
Training loss: 0.13476651906967163
Validation loss: 1.5054271272433701

Epoch: 6| Step: 6
Training loss: 0.19381645321846008
Validation loss: 1.5040014610495618

Epoch: 6| Step: 7
Training loss: 0.17152559757232666
Validation loss: 1.5055494398199103

Epoch: 6| Step: 8
Training loss: 0.18719182908535004
Validation loss: 1.5401078859965007

Epoch: 6| Step: 9
Training loss: 0.14105486869812012
Validation loss: 1.5275413605474657

Epoch: 6| Step: 10
Training loss: 0.3041503131389618
Validation loss: 1.5710680792408604

Epoch: 6| Step: 11
Training loss: 0.1437045931816101
Validation loss: 1.5759432341462822

Epoch: 6| Step: 12
Training loss: 0.29852673411369324
Validation loss: 1.5928398511743034

Epoch: 6| Step: 13
Training loss: 0.13725057244300842
Validation loss: 1.5877917761443763

Epoch: 365| Step: 0
Training loss: 0.25485119223594666
Validation loss: 1.5777826411749727

Epoch: 6| Step: 1
Training loss: 0.11225670576095581
Validation loss: 1.590322103551639

Epoch: 6| Step: 2
Training loss: 0.12719812989234924
Validation loss: 1.571156414606238

Epoch: 6| Step: 3
Training loss: 0.2582237720489502
Validation loss: 1.593235110723844

Epoch: 6| Step: 4
Training loss: 0.26541876792907715
Validation loss: 1.5648218316416587

Epoch: 6| Step: 5
Training loss: 0.15819159150123596
Validation loss: 1.5693616726065194

Epoch: 6| Step: 6
Training loss: 0.11288773268461227
Validation loss: 1.5448660901797715

Epoch: 6| Step: 7
Training loss: 0.228465735912323
Validation loss: 1.5653438516842422

Epoch: 6| Step: 8
Training loss: 0.172789067029953
Validation loss: 1.5949699019873014

Epoch: 6| Step: 9
Training loss: 0.17749714851379395
Validation loss: 1.5840196865861134

Epoch: 6| Step: 10
Training loss: 0.16937637329101562
Validation loss: 1.5563407149366153

Epoch: 6| Step: 11
Training loss: 0.1657770276069641
Validation loss: 1.5459121927138297

Epoch: 6| Step: 12
Training loss: 0.3276587426662445
Validation loss: 1.5303326511895785

Epoch: 6| Step: 13
Training loss: 0.07357513159513474
Validation loss: 1.5132148958021594

Epoch: 366| Step: 0
Training loss: 0.1489953100681305
Validation loss: 1.500593868635034

Epoch: 6| Step: 1
Training loss: 0.22762814164161682
Validation loss: 1.4819585091324263

Epoch: 6| Step: 2
Training loss: 0.3516833782196045
Validation loss: 1.4559810802500734

Epoch: 6| Step: 3
Training loss: 0.19850999116897583
Validation loss: 1.5035445485063779

Epoch: 6| Step: 4
Training loss: 0.17810167372226715
Validation loss: 1.4957440232717862

Epoch: 6| Step: 5
Training loss: 0.11228372156620026
Validation loss: 1.522093819033715

Epoch: 6| Step: 6
Training loss: 0.2463034987449646
Validation loss: 1.5403889289466284

Epoch: 6| Step: 7
Training loss: 0.3071402907371521
Validation loss: 1.5417971944296232

Epoch: 6| Step: 8
Training loss: 0.16940470039844513
Validation loss: 1.5513501410843225

Epoch: 6| Step: 9
Training loss: 0.12776462733745575
Validation loss: 1.5923636164716495

Epoch: 6| Step: 10
Training loss: 0.1889074742794037
Validation loss: 1.563054451378443

Epoch: 6| Step: 11
Training loss: 0.13788065314292908
Validation loss: 1.6031189349389845

Epoch: 6| Step: 12
Training loss: 0.3139410614967346
Validation loss: 1.5885656161974835

Epoch: 6| Step: 13
Training loss: 0.07148877531290054
Validation loss: 1.5848414231372137

Epoch: 367| Step: 0
Training loss: 0.11217136681079865
Validation loss: 1.5878954933535667

Epoch: 6| Step: 1
Training loss: 0.16700276732444763
Validation loss: 1.6052413307210451

Epoch: 6| Step: 2
Training loss: 0.16170412302017212
Validation loss: 1.5694731973832654

Epoch: 6| Step: 3
Training loss: 0.17017295956611633
Validation loss: 1.5748825457788282

Epoch: 6| Step: 4
Training loss: 0.19641467928886414
Validation loss: 1.6172289450963337

Epoch: 6| Step: 5
Training loss: 0.1197730302810669
Validation loss: 1.5744514631968674

Epoch: 6| Step: 6
Training loss: 0.15869924426078796
Validation loss: 1.587143869810207

Epoch: 6| Step: 7
Training loss: 0.1666576862335205
Validation loss: 1.5906531016031902

Epoch: 6| Step: 8
Training loss: 0.08321750909090042
Validation loss: 1.576221957001635

Epoch: 6| Step: 9
Training loss: 0.25296342372894287
Validation loss: 1.595016155191647

Epoch: 6| Step: 10
Training loss: 0.13385486602783203
Validation loss: 1.6058550316800353

Epoch: 6| Step: 11
Training loss: 0.11339900642633438
Validation loss: 1.5660949125084827

Epoch: 6| Step: 12
Training loss: 0.5528299808502197
Validation loss: 1.5301344894593762

Epoch: 6| Step: 13
Training loss: 0.12261870503425598
Validation loss: 1.54834093265636

Epoch: 368| Step: 0
Training loss: 0.1687689870595932
Validation loss: 1.4803209650901057

Epoch: 6| Step: 1
Training loss: 0.17435169219970703
Validation loss: 1.520819196137049

Epoch: 6| Step: 2
Training loss: 0.21479302644729614
Validation loss: 1.5207167043480823

Epoch: 6| Step: 3
Training loss: 0.29229599237442017
Validation loss: 1.53653787156587

Epoch: 6| Step: 4
Training loss: 0.2429681122303009
Validation loss: 1.5112335528096845

Epoch: 6| Step: 5
Training loss: 0.16639983654022217
Validation loss: 1.5359270188116259

Epoch: 6| Step: 6
Training loss: 0.19739976525306702
Validation loss: 1.507829689210461

Epoch: 6| Step: 7
Training loss: 0.12571053206920624
Validation loss: 1.5435297630166496

Epoch: 6| Step: 8
Training loss: 0.19186270236968994
Validation loss: 1.5690466985907605

Epoch: 6| Step: 9
Training loss: 0.2771361470222473
Validation loss: 1.5482640753510177

Epoch: 6| Step: 10
Training loss: 0.18191182613372803
Validation loss: 1.5766902149364512

Epoch: 6| Step: 11
Training loss: 0.21020342409610748
Validation loss: 1.6472002203746507

Epoch: 6| Step: 12
Training loss: 0.2774108946323395
Validation loss: 1.6311156326724636

Epoch: 6| Step: 13
Training loss: 0.12112041562795639
Validation loss: 1.6458270677956202

Epoch: 369| Step: 0
Training loss: 0.2867302894592285
Validation loss: 1.6361875405875586

Epoch: 6| Step: 1
Training loss: 0.31817352771759033
Validation loss: 1.596195980425804

Epoch: 6| Step: 2
Training loss: 0.09396576881408691
Validation loss: 1.5675791219998432

Epoch: 6| Step: 3
Training loss: 0.1726226955652237
Validation loss: 1.593613152862877

Epoch: 6| Step: 4
Training loss: 0.11597864329814911
Validation loss: 1.5761735464936943

Epoch: 6| Step: 5
Training loss: 0.3316989541053772
Validation loss: 1.5617383564672163

Epoch: 6| Step: 6
Training loss: 0.16179277002811432
Validation loss: 1.5537230865929716

Epoch: 6| Step: 7
Training loss: 0.17193299531936646
Validation loss: 1.5576240965115127

Epoch: 6| Step: 8
Training loss: 0.15504366159439087
Validation loss: 1.55901518688407

Epoch: 6| Step: 9
Training loss: 0.1457808017730713
Validation loss: 1.5542781827270344

Epoch: 6| Step: 10
Training loss: 0.19922062754631042
Validation loss: 1.5542509119997743

Epoch: 6| Step: 11
Training loss: 0.08737140893936157
Validation loss: 1.5243288663125807

Epoch: 6| Step: 12
Training loss: 0.07278049737215042
Validation loss: 1.534220951859669

Epoch: 6| Step: 13
Training loss: 0.1815846860408783
Validation loss: 1.548570038169943

Epoch: 370| Step: 0
Training loss: 0.169450581073761
Validation loss: 1.5414473459284792

Epoch: 6| Step: 1
Training loss: 0.15977716445922852
Validation loss: 1.5747622302783433

Epoch: 6| Step: 2
Training loss: 0.11035040766000748
Validation loss: 1.5835990111033122

Epoch: 6| Step: 3
Training loss: 0.31919559836387634
Validation loss: 1.5786563542581373

Epoch: 6| Step: 4
Training loss: 0.12687253952026367
Validation loss: 1.6215853139918337

Epoch: 6| Step: 5
Training loss: 0.14970168471336365
Validation loss: 1.597573963544702

Epoch: 6| Step: 6
Training loss: 0.13128796219825745
Validation loss: 1.6015362406289706

Epoch: 6| Step: 7
Training loss: 0.12147165089845657
Validation loss: 1.5965274098098918

Epoch: 6| Step: 8
Training loss: 0.14273518323898315
Validation loss: 1.596184984330208

Epoch: 6| Step: 9
Training loss: 0.13820765912532806
Validation loss: 1.6052597850881598

Epoch: 6| Step: 10
Training loss: 0.09043087810277939
Validation loss: 1.6120866601185133

Epoch: 6| Step: 11
Training loss: 0.13650071620941162
Validation loss: 1.590524326088608

Epoch: 6| Step: 12
Training loss: 0.3517502546310425
Validation loss: 1.5643722998198641

Epoch: 6| Step: 13
Training loss: 0.3482550382614136
Validation loss: 1.577743807146626

Epoch: 371| Step: 0
Training loss: 0.19215542078018188
Validation loss: 1.5714807612921602

Epoch: 6| Step: 1
Training loss: 0.16500107944011688
Validation loss: 1.5604236318219094

Epoch: 6| Step: 2
Training loss: 0.14965571463108063
Validation loss: 1.5794290355456773

Epoch: 6| Step: 3
Training loss: 0.3082473874092102
Validation loss: 1.5584716130328435

Epoch: 6| Step: 4
Training loss: 0.12208520621061325
Validation loss: 1.5771173482300134

Epoch: 6| Step: 5
Training loss: 0.07342620193958282
Validation loss: 1.5260084867477417

Epoch: 6| Step: 6
Training loss: 0.3244898319244385
Validation loss: 1.559303081163796

Epoch: 6| Step: 7
Training loss: 0.14297866821289062
Validation loss: 1.5302008505790465

Epoch: 6| Step: 8
Training loss: 0.2544461786746979
Validation loss: 1.5043038616898239

Epoch: 6| Step: 9
Training loss: 0.12289615720510483
Validation loss: 1.5429296352530038

Epoch: 6| Step: 10
Training loss: 0.3365018963813782
Validation loss: 1.556742541251644

Epoch: 6| Step: 11
Training loss: 0.12801045179367065
Validation loss: 1.5471301706888343

Epoch: 6| Step: 12
Training loss: 0.11464942991733551
Validation loss: 1.5506344085098596

Epoch: 6| Step: 13
Training loss: 0.10656954348087311
Validation loss: 1.5420621274619974

Epoch: 372| Step: 0
Training loss: 0.4998668432235718
Validation loss: 1.5326095768200454

Epoch: 6| Step: 1
Training loss: 0.13869905471801758
Validation loss: 1.5339353879292805

Epoch: 6| Step: 2
Training loss: 0.1602322906255722
Validation loss: 1.548391694022763

Epoch: 6| Step: 3
Training loss: 0.09060995280742645
Validation loss: 1.5309230858279812

Epoch: 6| Step: 4
Training loss: 0.1981077641248703
Validation loss: 1.5302197990878936

Epoch: 6| Step: 5
Training loss: 0.09854276478290558
Validation loss: 1.5497235803193943

Epoch: 6| Step: 6
Training loss: 0.2374354749917984
Validation loss: 1.5450849417717225

Epoch: 6| Step: 7
Training loss: 0.0897737592458725
Validation loss: 1.5383157666011522

Epoch: 6| Step: 8
Training loss: 0.17464116215705872
Validation loss: 1.5492827648757606

Epoch: 6| Step: 9
Training loss: 0.13461127877235413
Validation loss: 1.5799747449095531

Epoch: 6| Step: 10
Training loss: 0.15108045935630798
Validation loss: 1.5705015095331336

Epoch: 6| Step: 11
Training loss: 0.10438892990350723
Validation loss: 1.5650570328517626

Epoch: 6| Step: 12
Training loss: 0.10093267261981964
Validation loss: 1.5416050047002814

Epoch: 6| Step: 13
Training loss: 0.06188954785466194
Validation loss: 1.5415986994261384

Epoch: 373| Step: 0
Training loss: 0.11319620162248611
Validation loss: 1.5314323120219733

Epoch: 6| Step: 1
Training loss: 0.16519689559936523
Validation loss: 1.5355890489393664

Epoch: 6| Step: 2
Training loss: 0.12075486034154892
Validation loss: 1.5480979629742202

Epoch: 6| Step: 3
Training loss: 0.22416582703590393
Validation loss: 1.5676445691816268

Epoch: 6| Step: 4
Training loss: 0.13158458471298218
Validation loss: 1.581722132621273

Epoch: 6| Step: 5
Training loss: 0.27952951192855835
Validation loss: 1.5889002507732761

Epoch: 6| Step: 6
Training loss: 0.15675929188728333
Validation loss: 1.5490104793220438

Epoch: 6| Step: 7
Training loss: 0.10152000188827515
Validation loss: 1.5555081918675413

Epoch: 6| Step: 8
Training loss: 0.22264273464679718
Validation loss: 1.5539747380441236

Epoch: 6| Step: 9
Training loss: 0.1973419189453125
Validation loss: 1.5939940137247885

Epoch: 6| Step: 10
Training loss: 0.3654572367668152
Validation loss: 1.5982555650895642

Epoch: 6| Step: 11
Training loss: 0.15711379051208496
Validation loss: 1.5624510857366747

Epoch: 6| Step: 12
Training loss: 0.19316664338111877
Validation loss: 1.5302771868244294

Epoch: 6| Step: 13
Training loss: 0.15399689972400665
Validation loss: 1.5327707516249789

Epoch: 374| Step: 0
Training loss: 0.11625015735626221
Validation loss: 1.4880540537577804

Epoch: 6| Step: 1
Training loss: 0.21245801448822021
Validation loss: 1.5238101802846438

Epoch: 6| Step: 2
Training loss: 0.2145056426525116
Validation loss: 1.5043268921554729

Epoch: 6| Step: 3
Training loss: 0.16797345876693726
Validation loss: 1.5217185622902327

Epoch: 6| Step: 4
Training loss: 0.3273397982120514
Validation loss: 1.511329162505365

Epoch: 6| Step: 5
Training loss: 0.2537219226360321
Validation loss: 1.48812400269252

Epoch: 6| Step: 6
Training loss: 0.08675174415111542
Validation loss: 1.5279515327945832

Epoch: 6| Step: 7
Training loss: 0.24642179906368256
Validation loss: 1.542321466630505

Epoch: 6| Step: 8
Training loss: 0.11268782615661621
Validation loss: 1.5399509719623032

Epoch: 6| Step: 9
Training loss: 0.11891420930624008
Validation loss: 1.53252705835527

Epoch: 6| Step: 10
Training loss: 0.15650196373462677
Validation loss: 1.6192901288309405

Epoch: 6| Step: 11
Training loss: 0.40500909090042114
Validation loss: 1.606138434461368

Epoch: 6| Step: 12
Training loss: 0.23264619708061218
Validation loss: 1.5713940640931487

Epoch: 6| Step: 13
Training loss: 0.18747127056121826
Validation loss: 1.5795989780015842

Epoch: 375| Step: 0
Training loss: 0.2801722288131714
Validation loss: 1.5205800020566551

Epoch: 6| Step: 1
Training loss: 0.1611855924129486
Validation loss: 1.4904856528005292

Epoch: 6| Step: 2
Training loss: 0.27139031887054443
Validation loss: 1.5121294708662136

Epoch: 6| Step: 3
Training loss: 0.1756582111120224
Validation loss: 1.5196693123027842

Epoch: 6| Step: 4
Training loss: 0.22160391509532928
Validation loss: 1.5214760175315283

Epoch: 6| Step: 5
Training loss: 0.27289247512817383
Validation loss: 1.5174853442817606

Epoch: 6| Step: 6
Training loss: 0.13118106126785278
Validation loss: 1.5341803079010339

Epoch: 6| Step: 7
Training loss: 0.12384041398763657
Validation loss: 1.535176161796816

Epoch: 6| Step: 8
Training loss: 0.28268370032310486
Validation loss: 1.5514579729367328

Epoch: 6| Step: 9
Training loss: 0.10212351381778717
Validation loss: 1.5636885627623527

Epoch: 6| Step: 10
Training loss: 0.13945278525352478
Validation loss: 1.5709277211978872

Epoch: 6| Step: 11
Training loss: 0.1103152334690094
Validation loss: 1.563763496696308

Epoch: 6| Step: 12
Training loss: 0.1616571992635727
Validation loss: 1.5757188566269413

Epoch: 6| Step: 13
Training loss: 0.05259217321872711
Validation loss: 1.5524553342532086

Epoch: 376| Step: 0
Training loss: 0.15444119274616241
Validation loss: 1.5839680881910427

Epoch: 6| Step: 1
Training loss: 0.23227356374263763
Validation loss: 1.5749470777409051

Epoch: 6| Step: 2
Training loss: 0.07950830459594727
Validation loss: 1.5698297305773663

Epoch: 6| Step: 3
Training loss: 0.1273488849401474
Validation loss: 1.5626909925091652

Epoch: 6| Step: 4
Training loss: 0.14898079633712769
Validation loss: 1.5406853716860536

Epoch: 6| Step: 5
Training loss: 0.1998666524887085
Validation loss: 1.5435439091856762

Epoch: 6| Step: 6
Training loss: 0.15638890862464905
Validation loss: 1.5270444141921176

Epoch: 6| Step: 7
Training loss: 0.134942889213562
Validation loss: 1.5517521494178361

Epoch: 6| Step: 8
Training loss: 0.11229363828897476
Validation loss: 1.534118216524842

Epoch: 6| Step: 9
Training loss: 0.16497915983200073
Validation loss: 1.5331530635074904

Epoch: 6| Step: 10
Training loss: 0.36249417066574097
Validation loss: 1.5393639264568206

Epoch: 6| Step: 11
Training loss: 0.205407053232193
Validation loss: 1.5471505042045348

Epoch: 6| Step: 12
Training loss: 0.0859871432185173
Validation loss: 1.5542070263175554

Epoch: 6| Step: 13
Training loss: 0.1485162377357483
Validation loss: 1.5442156573777557

Epoch: 377| Step: 0
Training loss: 0.10491633415222168
Validation loss: 1.5236636592495827

Epoch: 6| Step: 1
Training loss: 0.08782273530960083
Validation loss: 1.5323290465980448

Epoch: 6| Step: 2
Training loss: 0.10889360308647156
Validation loss: 1.509174769924533

Epoch: 6| Step: 3
Training loss: 0.3407781422138214
Validation loss: 1.508545652512581

Epoch: 6| Step: 4
Training loss: 0.2087082862854004
Validation loss: 1.4730535296983616

Epoch: 6| Step: 5
Training loss: 0.09952861070632935
Validation loss: 1.4668066642617668

Epoch: 6| Step: 6
Training loss: 0.23428688943386078
Validation loss: 1.4854198040500763

Epoch: 6| Step: 7
Training loss: 0.12116554379463196
Validation loss: 1.4688075947505173

Epoch: 6| Step: 8
Training loss: 0.13200582563877106
Validation loss: 1.4707375905847038

Epoch: 6| Step: 9
Training loss: 0.14108164608478546
Validation loss: 1.4509691506303766

Epoch: 6| Step: 10
Training loss: 0.14980818331241608
Validation loss: 1.4768229107702933

Epoch: 6| Step: 11
Training loss: 0.09266561269760132
Validation loss: 1.4935964128022552

Epoch: 6| Step: 12
Training loss: 0.1506134420633316
Validation loss: 1.4842695151605914

Epoch: 6| Step: 13
Training loss: 0.18055182695388794
Validation loss: 1.5250066108601068

Epoch: 378| Step: 0
Training loss: 0.16211211681365967
Validation loss: 1.5190127523996497

Epoch: 6| Step: 1
Training loss: 0.18356627225875854
Validation loss: 1.5308247804641724

Epoch: 6| Step: 2
Training loss: 0.17179226875305176
Validation loss: 1.5333982026705177

Epoch: 6| Step: 3
Training loss: 0.12830084562301636
Validation loss: 1.5138812148442833

Epoch: 6| Step: 4
Training loss: 0.09618444740772247
Validation loss: 1.517510724324052

Epoch: 6| Step: 5
Training loss: 0.14178183674812317
Validation loss: 1.5454798616388792

Epoch: 6| Step: 6
Training loss: 0.15560123324394226
Validation loss: 1.5606602468798239

Epoch: 6| Step: 7
Training loss: 0.14049333333969116
Validation loss: 1.554346478113564

Epoch: 6| Step: 8
Training loss: 0.5448441505432129
Validation loss: 1.5856485020729802

Epoch: 6| Step: 9
Training loss: 0.1215033084154129
Validation loss: 1.6094422289120254

Epoch: 6| Step: 10
Training loss: 0.14752045273780823
Validation loss: 1.605080493034855

Epoch: 6| Step: 11
Training loss: 0.18536347150802612
Validation loss: 1.5603018781190277

Epoch: 6| Step: 12
Training loss: 0.17565974593162537
Validation loss: 1.5966426864747079

Epoch: 6| Step: 13
Training loss: 0.16452890634536743
Validation loss: 1.5930011246794014

Epoch: 379| Step: 0
Training loss: 0.16388031840324402
Validation loss: 1.5866303661818146

Epoch: 6| Step: 1
Training loss: 0.15028296411037445
Validation loss: 1.5825774861920265

Epoch: 6| Step: 2
Training loss: 0.10231658071279526
Validation loss: 1.5897908300481818

Epoch: 6| Step: 3
Training loss: 0.14008662104606628
Validation loss: 1.5788437807431785

Epoch: 6| Step: 4
Training loss: 0.11662300676107407
Validation loss: 1.5645323876411683

Epoch: 6| Step: 5
Training loss: 0.2888451814651489
Validation loss: 1.5645976156316779

Epoch: 6| Step: 6
Training loss: 0.20363959670066833
Validation loss: 1.5348824980438396

Epoch: 6| Step: 7
Training loss: 0.07941585034132004
Validation loss: 1.5397876603629

Epoch: 6| Step: 8
Training loss: 0.11424841731786728
Validation loss: 1.533308421411822

Epoch: 6| Step: 9
Training loss: 0.08100509643554688
Validation loss: 1.5133006957269484

Epoch: 6| Step: 10
Training loss: 0.2614954710006714
Validation loss: 1.518274732815322

Epoch: 6| Step: 11
Training loss: 0.12269718945026398
Validation loss: 1.491216367290866

Epoch: 6| Step: 12
Training loss: 0.16753453016281128
Validation loss: 1.5029433850319154

Epoch: 6| Step: 13
Training loss: 0.14514249563217163
Validation loss: 1.52027670157853

Epoch: 380| Step: 0
Training loss: 0.43886831402778625
Validation loss: 1.506517517951227

Epoch: 6| Step: 1
Training loss: 0.1368538737297058
Validation loss: 1.5186183253924053

Epoch: 6| Step: 2
Training loss: 0.15421807765960693
Validation loss: 1.5066907226398427

Epoch: 6| Step: 3
Training loss: 0.1355634182691574
Validation loss: 1.4980821519769647

Epoch: 6| Step: 4
Training loss: 0.08997438102960587
Validation loss: 1.4660925416536228

Epoch: 6| Step: 5
Training loss: 0.16886796057224274
Validation loss: 1.5001752889284523

Epoch: 6| Step: 6
Training loss: 0.10553209483623505
Validation loss: 1.468345445330425

Epoch: 6| Step: 7
Training loss: 0.19593128561973572
Validation loss: 1.4812897174589095

Epoch: 6| Step: 8
Training loss: 0.11360921710729599
Validation loss: 1.4903377461177048

Epoch: 6| Step: 9
Training loss: 0.1680566370487213
Validation loss: 1.4813386778677664

Epoch: 6| Step: 10
Training loss: 0.36651235818862915
Validation loss: 1.466372190624155

Epoch: 6| Step: 11
Training loss: 0.16107839345932007
Validation loss: 1.5053380766222555

Epoch: 6| Step: 12
Training loss: 0.12928453087806702
Validation loss: 1.5129124156890377

Epoch: 6| Step: 13
Training loss: 0.12911221385002136
Validation loss: 1.4832826429797756

Epoch: 381| Step: 0
Training loss: 0.09392961859703064
Validation loss: 1.5174700290926042

Epoch: 6| Step: 1
Training loss: 0.11421974003314972
Validation loss: 1.5397550925131767

Epoch: 6| Step: 2
Training loss: 0.11960852891206741
Validation loss: 1.5294699271519978

Epoch: 6| Step: 3
Training loss: 0.14387235045433044
Validation loss: 1.5478500730247908

Epoch: 6| Step: 4
Training loss: 0.21498343348503113
Validation loss: 1.5864655958708895

Epoch: 6| Step: 5
Training loss: 0.2103734016418457
Validation loss: 1.6005306577169767

Epoch: 6| Step: 6
Training loss: 0.30710598826408386
Validation loss: 1.5776964131221975

Epoch: 6| Step: 7
Training loss: 0.12030628323554993
Validation loss: 1.5613198562334942

Epoch: 6| Step: 8
Training loss: 0.23479585349559784
Validation loss: 1.5622231370659285

Epoch: 6| Step: 9
Training loss: 0.13517451286315918
Validation loss: 1.589580580752383

Epoch: 6| Step: 10
Training loss: 0.11986330896615982
Validation loss: 1.565984559315507

Epoch: 6| Step: 11
Training loss: 0.15730559825897217
Validation loss: 1.5677275997336193

Epoch: 6| Step: 12
Training loss: 0.1679176390171051
Validation loss: 1.5420564566889117

Epoch: 6| Step: 13
Training loss: 0.11880630999803543
Validation loss: 1.5400663780909714

Epoch: 382| Step: 0
Training loss: 0.17933475971221924
Validation loss: 1.5426801250826927

Epoch: 6| Step: 1
Training loss: 0.3412618041038513
Validation loss: 1.5034802113809893

Epoch: 6| Step: 2
Training loss: 0.10090219974517822
Validation loss: 1.5223347653624832

Epoch: 6| Step: 3
Training loss: 0.17814448475837708
Validation loss: 1.5151157199695546

Epoch: 6| Step: 4
Training loss: 0.15832805633544922
Validation loss: 1.5133062998453777

Epoch: 6| Step: 5
Training loss: 0.10042136907577515
Validation loss: 1.5390877915966896

Epoch: 6| Step: 6
Training loss: 0.12691043317317963
Validation loss: 1.5539534373949933

Epoch: 6| Step: 7
Training loss: 0.15210357308387756
Validation loss: 1.539267486141574

Epoch: 6| Step: 8
Training loss: 0.23318560421466827
Validation loss: 1.541017573366883

Epoch: 6| Step: 9
Training loss: 0.08409582078456879
Validation loss: 1.5407464555514756

Epoch: 6| Step: 10
Training loss: 0.0642499253153801
Validation loss: 1.562941292280792

Epoch: 6| Step: 11
Training loss: 0.1261136531829834
Validation loss: 1.5360679677737656

Epoch: 6| Step: 12
Training loss: 0.1624583899974823
Validation loss: 1.5895833097478396

Epoch: 6| Step: 13
Training loss: 0.12093673646450043
Validation loss: 1.5959571228232434

Epoch: 383| Step: 0
Training loss: 0.15279152989387512
Validation loss: 1.5772460429899153

Epoch: 6| Step: 1
Training loss: 0.0880734845995903
Validation loss: 1.5706519913929764

Epoch: 6| Step: 2
Training loss: 0.09407675266265869
Validation loss: 1.5769319431756132

Epoch: 6| Step: 3
Training loss: 0.1390293836593628
Validation loss: 1.5541904626354095

Epoch: 6| Step: 4
Training loss: 0.11931963264942169
Validation loss: 1.5473785746482112

Epoch: 6| Step: 5
Training loss: 0.1265684962272644
Validation loss: 1.5682188195566977

Epoch: 6| Step: 6
Training loss: 0.222237691283226
Validation loss: 1.5560706764139154

Epoch: 6| Step: 7
Training loss: 0.252535343170166
Validation loss: 1.5673019680925595

Epoch: 6| Step: 8
Training loss: 0.1401081532239914
Validation loss: 1.5728768212820894

Epoch: 6| Step: 9
Training loss: 0.2535353899002075
Validation loss: 1.6062285861661356

Epoch: 6| Step: 10
Training loss: 0.1835961937904358
Validation loss: 1.5914480122186805

Epoch: 6| Step: 11
Training loss: 0.2212885469198227
Validation loss: 1.567158220916666

Epoch: 6| Step: 12
Training loss: 0.08388274908065796
Validation loss: 1.5997712586515693

Epoch: 6| Step: 13
Training loss: 0.09576287120580673
Validation loss: 1.56591195829453

Epoch: 384| Step: 0
Training loss: 0.1701098531484604
Validation loss: 1.5911141749351256

Epoch: 6| Step: 1
Training loss: 0.24316070973873138
Validation loss: 1.5692159463000555

Epoch: 6| Step: 2
Training loss: 0.09067036211490631
Validation loss: 1.5544310795363558

Epoch: 6| Step: 3
Training loss: 0.155953049659729
Validation loss: 1.5602911108283586

Epoch: 6| Step: 4
Training loss: 0.18109609186649323
Validation loss: 1.5113444161671463

Epoch: 6| Step: 5
Training loss: 0.07391238212585449
Validation loss: 1.5015503950016473

Epoch: 6| Step: 6
Training loss: 0.1327839493751526
Validation loss: 1.5128047543187295

Epoch: 6| Step: 7
Training loss: 0.09747587144374847
Validation loss: 1.5248749717589347

Epoch: 6| Step: 8
Training loss: 0.24478362500667572
Validation loss: 1.5042917222105048

Epoch: 6| Step: 9
Training loss: 0.1561019867658615
Validation loss: 1.512883037649175

Epoch: 6| Step: 10
Training loss: 0.10229282081127167
Validation loss: 1.5346791744232178

Epoch: 6| Step: 11
Training loss: 0.1323769986629486
Validation loss: 1.5117437442143757

Epoch: 6| Step: 12
Training loss: 0.22904863953590393
Validation loss: 1.5307635363712107

Epoch: 6| Step: 13
Training loss: 0.08607937395572662
Validation loss: 1.523078845393273

Epoch: 385| Step: 0
Training loss: 0.13062086701393127
Validation loss: 1.549533272302279

Epoch: 6| Step: 1
Training loss: 0.08052875846624374
Validation loss: 1.5613019633036789

Epoch: 6| Step: 2
Training loss: 0.2910192012786865
Validation loss: 1.5830267872861636

Epoch: 6| Step: 3
Training loss: 0.1204623207449913
Validation loss: 1.5742569751636957

Epoch: 6| Step: 4
Training loss: 0.13073958456516266
Validation loss: 1.5883764041367399

Epoch: 6| Step: 5
Training loss: 0.05535954609513283
Validation loss: 1.5415396728823263

Epoch: 6| Step: 6
Training loss: 0.13496683537960052
Validation loss: 1.5243238787497244

Epoch: 6| Step: 7
Training loss: 0.06286223232746124
Validation loss: 1.532227534760711

Epoch: 6| Step: 8
Training loss: 0.12297569215297699
Validation loss: 1.5171556652233165

Epoch: 6| Step: 9
Training loss: 0.10632786154747009
Validation loss: 1.498370228275176

Epoch: 6| Step: 10
Training loss: 0.2718084454536438
Validation loss: 1.5301593760008454

Epoch: 6| Step: 11
Training loss: 0.10015428066253662
Validation loss: 1.5081132881103023

Epoch: 6| Step: 12
Training loss: 0.12136084586381912
Validation loss: 1.4899929902886833

Epoch: 6| Step: 13
Training loss: 0.35670292377471924
Validation loss: 1.5107833775140906

Epoch: 386| Step: 0
Training loss: 0.07011663913726807
Validation loss: 1.519221790375248

Epoch: 6| Step: 1
Training loss: 0.13635626435279846
Validation loss: 1.5348548068795154

Epoch: 6| Step: 2
Training loss: 0.10248441249132156
Validation loss: 1.534798950277349

Epoch: 6| Step: 3
Training loss: 0.122951440513134
Validation loss: 1.5459385379668205

Epoch: 6| Step: 4
Training loss: 0.1239636018872261
Validation loss: 1.545216255290534

Epoch: 6| Step: 5
Training loss: 0.11348479986190796
Validation loss: 1.5518138972661828

Epoch: 6| Step: 6
Training loss: 0.1467350721359253
Validation loss: 1.5397149888418054

Epoch: 6| Step: 7
Training loss: 0.1257520318031311
Validation loss: 1.5188457286486061

Epoch: 6| Step: 8
Training loss: 0.3432914614677429
Validation loss: 1.5139703173791208

Epoch: 6| Step: 9
Training loss: 0.14808319509029388
Validation loss: 1.5241155893571916

Epoch: 6| Step: 10
Training loss: 0.16781365871429443
Validation loss: 1.5190882170072166

Epoch: 6| Step: 11
Training loss: 0.1250189244747162
Validation loss: 1.525459845860799

Epoch: 6| Step: 12
Training loss: 0.24764105677604675
Validation loss: 1.56604080559105

Epoch: 6| Step: 13
Training loss: 0.12634500861167908
Validation loss: 1.5449181269573908

Epoch: 387| Step: 0
Training loss: 0.13364718854427338
Validation loss: 1.5390832911255539

Epoch: 6| Step: 1
Training loss: 0.1914057582616806
Validation loss: 1.551370128508537

Epoch: 6| Step: 2
Training loss: 0.13767576217651367
Validation loss: 1.567670928534641

Epoch: 6| Step: 3
Training loss: 0.07357526570558548
Validation loss: 1.5811355049892137

Epoch: 6| Step: 4
Training loss: 0.16430369019508362
Validation loss: 1.5637238512757003

Epoch: 6| Step: 5
Training loss: 0.1033472791314125
Validation loss: 1.5544432978476248

Epoch: 6| Step: 6
Training loss: 0.12681829929351807
Validation loss: 1.5355799057150399

Epoch: 6| Step: 7
Training loss: 0.1179075688123703
Validation loss: 1.5091889571118098

Epoch: 6| Step: 8
Training loss: 0.22260481119155884
Validation loss: 1.5807206861434444

Epoch: 6| Step: 9
Training loss: 0.13997066020965576
Validation loss: 1.5433496634165447

Epoch: 6| Step: 10
Training loss: 0.29652881622314453
Validation loss: 1.5718636743484005

Epoch: 6| Step: 11
Training loss: 0.11366359144449234
Validation loss: 1.5687794146999237

Epoch: 6| Step: 12
Training loss: 0.14848418533802032
Validation loss: 1.5764133314932547

Epoch: 6| Step: 13
Training loss: 0.0973285660147667
Validation loss: 1.5779829307269024

Epoch: 388| Step: 0
Training loss: 0.21278075873851776
Validation loss: 1.5789407876230055

Epoch: 6| Step: 1
Training loss: 0.09237433224916458
Validation loss: 1.5937010677911903

Epoch: 6| Step: 2
Training loss: 0.09945788234472275
Validation loss: 1.5618584912310365

Epoch: 6| Step: 3
Training loss: 0.1501888632774353
Validation loss: 1.5382148886239657

Epoch: 6| Step: 4
Training loss: 0.1870400756597519
Validation loss: 1.5488100833790277

Epoch: 6| Step: 5
Training loss: 0.10822893679141998
Validation loss: 1.5223897028994817

Epoch: 6| Step: 6
Training loss: 0.36126068234443665
Validation loss: 1.5341371515745759

Epoch: 6| Step: 7
Training loss: 0.1394844353199005
Validation loss: 1.505459270169658

Epoch: 6| Step: 8
Training loss: 0.1336795538663864
Validation loss: 1.5414849724820865

Epoch: 6| Step: 9
Training loss: 0.12938770651817322
Validation loss: 1.5221673788562897

Epoch: 6| Step: 10
Training loss: 0.24469560384750366
Validation loss: 1.538221215689054

Epoch: 6| Step: 11
Training loss: 0.1280699372291565
Validation loss: 1.536092500532827

Epoch: 6| Step: 12
Training loss: 0.20628389716148376
Validation loss: 1.5115843831851918

Epoch: 6| Step: 13
Training loss: 0.09501411020755768
Validation loss: 1.5234913851625176

Epoch: 389| Step: 0
Training loss: 0.1294846385717392
Validation loss: 1.5302735451729066

Epoch: 6| Step: 1
Training loss: 0.12663902342319489
Validation loss: 1.5347269940119919

Epoch: 6| Step: 2
Training loss: 0.06326383352279663
Validation loss: 1.4869979844298413

Epoch: 6| Step: 3
Training loss: 0.15957137942314148
Validation loss: 1.482413814913842

Epoch: 6| Step: 4
Training loss: 0.35303395986557007
Validation loss: 1.5158176319573515

Epoch: 6| Step: 5
Training loss: 0.12708622217178345
Validation loss: 1.5212892934840212

Epoch: 6| Step: 6
Training loss: 0.17804349958896637
Validation loss: 1.5292810752827635

Epoch: 6| Step: 7
Training loss: 0.1330881416797638
Validation loss: 1.5587671764435307

Epoch: 6| Step: 8
Training loss: 0.08890276402235031
Validation loss: 1.6050770667291456

Epoch: 6| Step: 9
Training loss: 0.09995647519826889
Validation loss: 1.5816022375578522

Epoch: 6| Step: 10
Training loss: 0.130591481924057
Validation loss: 1.6348703522836008

Epoch: 6| Step: 11
Training loss: 0.22990202903747559
Validation loss: 1.6101715577545987

Epoch: 6| Step: 12
Training loss: 0.14258304238319397
Validation loss: 1.6165356687320176

Epoch: 6| Step: 13
Training loss: 0.2362482249736786
Validation loss: 1.616889270403052

Epoch: 390| Step: 0
Training loss: 0.1499561071395874
Validation loss: 1.6020431941555393

Epoch: 6| Step: 1
Training loss: 0.11622984707355499
Validation loss: 1.5687072328341904

Epoch: 6| Step: 2
Training loss: 0.13766591250896454
Validation loss: 1.5605071212655754

Epoch: 6| Step: 3
Training loss: 0.10901091247797012
Validation loss: 1.5367435357903922

Epoch: 6| Step: 4
Training loss: 0.07222121953964233
Validation loss: 1.5488779673012354

Epoch: 6| Step: 5
Training loss: 0.12724988162517548
Validation loss: 1.518761464344558

Epoch: 6| Step: 6
Training loss: 0.168400377035141
Validation loss: 1.5145634105128627

Epoch: 6| Step: 7
Training loss: 0.20912052690982819
Validation loss: 1.5006063945831791

Epoch: 6| Step: 8
Training loss: 0.0807761400938034
Validation loss: 1.4901594128659976

Epoch: 6| Step: 9
Training loss: 0.20270970463752747
Validation loss: 1.508546349822834

Epoch: 6| Step: 10
Training loss: 0.12964248657226562
Validation loss: 1.510366145000663

Epoch: 6| Step: 11
Training loss: 0.25807005167007446
Validation loss: 1.5313617490953015

Epoch: 6| Step: 12
Training loss: 0.1319977343082428
Validation loss: 1.5157443220897386

Epoch: 6| Step: 13
Training loss: 0.13342195749282837
Validation loss: 1.5384097637668732

Epoch: 391| Step: 0
Training loss: 0.20687967538833618
Validation loss: 1.545738975207011

Epoch: 6| Step: 1
Training loss: 0.14575380086898804
Validation loss: 1.5570922936162641

Epoch: 6| Step: 2
Training loss: 0.2679503560066223
Validation loss: 1.588558179076

Epoch: 6| Step: 3
Training loss: 0.10825729370117188
Validation loss: 1.567186378663586

Epoch: 6| Step: 4
Training loss: 0.07716106623411179
Validation loss: 1.553464069161364

Epoch: 6| Step: 5
Training loss: 0.12523972988128662
Validation loss: 1.5621106393875615

Epoch: 6| Step: 6
Training loss: 0.15064437687397003
Validation loss: 1.5820177742229995

Epoch: 6| Step: 7
Training loss: 0.17170462012290955
Validation loss: 1.5861067624502285

Epoch: 6| Step: 8
Training loss: 0.07919135689735413
Validation loss: 1.5690294568256666

Epoch: 6| Step: 9
Training loss: 0.14771327376365662
Validation loss: 1.5826150627546414

Epoch: 6| Step: 10
Training loss: 0.1420791745185852
Validation loss: 1.6011632860347789

Epoch: 6| Step: 11
Training loss: 0.23342375457286835
Validation loss: 1.5885177555904593

Epoch: 6| Step: 12
Training loss: 0.15342572331428528
Validation loss: 1.6358827442251227

Epoch: 6| Step: 13
Training loss: 0.11117594689130783
Validation loss: 1.6133836110432942

Epoch: 392| Step: 0
Training loss: 0.0962575152516365
Validation loss: 1.6091971179490447

Epoch: 6| Step: 1
Training loss: 0.10351285338401794
Validation loss: 1.6029126644134521

Epoch: 6| Step: 2
Training loss: 0.4047600030899048
Validation loss: 1.6180236275478075

Epoch: 6| Step: 3
Training loss: 0.1820918172597885
Validation loss: 1.5565253790988718

Epoch: 6| Step: 4
Training loss: 0.12374086678028107
Validation loss: 1.5824940332802393

Epoch: 6| Step: 5
Training loss: 0.15780267119407654
Validation loss: 1.5788701118961457

Epoch: 6| Step: 6
Training loss: 0.1666722595691681
Validation loss: 1.5618344455636957

Epoch: 6| Step: 7
Training loss: 0.2839873433113098
Validation loss: 1.5487144442014797

Epoch: 6| Step: 8
Training loss: 0.1495341658592224
Validation loss: 1.5383511691965082

Epoch: 6| Step: 9
Training loss: 0.12522591650485992
Validation loss: 1.5563911340569938

Epoch: 6| Step: 10
Training loss: 0.08757339417934418
Validation loss: 1.5917543352291148

Epoch: 6| Step: 11
Training loss: 0.15840856730937958
Validation loss: 1.573383081343866

Epoch: 6| Step: 12
Training loss: 0.25931012630462646
Validation loss: 1.5765278954659738

Epoch: 6| Step: 13
Training loss: 0.1318720430135727
Validation loss: 1.589281899954683

Epoch: 393| Step: 0
Training loss: 0.11321915686130524
Validation loss: 1.5684772486327796

Epoch: 6| Step: 1
Training loss: 0.16339285671710968
Validation loss: 1.5691571466384395

Epoch: 6| Step: 2
Training loss: 0.10412896424531937
Validation loss: 1.562397559483846

Epoch: 6| Step: 3
Training loss: 0.1725015640258789
Validation loss: 1.5362098896375267

Epoch: 6| Step: 4
Training loss: 0.1709553301334381
Validation loss: 1.5442289511362712

Epoch: 6| Step: 5
Training loss: 0.18991199135780334
Validation loss: 1.5353068331236481

Epoch: 6| Step: 6
Training loss: 0.15182539820671082
Validation loss: 1.496966067821749

Epoch: 6| Step: 7
Training loss: 0.14679959416389465
Validation loss: 1.508180090176162

Epoch: 6| Step: 8
Training loss: 0.19150716066360474
Validation loss: 1.5118521169949604

Epoch: 6| Step: 9
Training loss: 0.1453685462474823
Validation loss: 1.5257514676740092

Epoch: 6| Step: 10
Training loss: 0.37715286016464233
Validation loss: 1.5196170524884296

Epoch: 6| Step: 11
Training loss: 0.2619273066520691
Validation loss: 1.5195840507425287

Epoch: 6| Step: 12
Training loss: 0.20139345526695251
Validation loss: 1.4812300243685323

Epoch: 6| Step: 13
Training loss: 0.07906288653612137
Validation loss: 1.4873253068616312

Epoch: 394| Step: 0
Training loss: 0.28719383478164673
Validation loss: 1.503488217630694

Epoch: 6| Step: 1
Training loss: 0.23780575394630432
Validation loss: 1.505036514292481

Epoch: 6| Step: 2
Training loss: 0.21151329576969147
Validation loss: 1.5278280909343431

Epoch: 6| Step: 3
Training loss: 0.216127410531044
Validation loss: 1.5032141618831183

Epoch: 6| Step: 4
Training loss: 0.2503356337547302
Validation loss: 1.5166746647127214

Epoch: 6| Step: 5
Training loss: 0.14126741886138916
Validation loss: 1.4939701736614268

Epoch: 6| Step: 6
Training loss: 0.14509126543998718
Validation loss: 1.492265808966852

Epoch: 6| Step: 7
Training loss: 0.09690503776073456
Validation loss: 1.4765100235580115

Epoch: 6| Step: 8
Training loss: 0.1358550488948822
Validation loss: 1.4810569773438156

Epoch: 6| Step: 9
Training loss: 0.18038836121559143
Validation loss: 1.5089183520245295

Epoch: 6| Step: 10
Training loss: 0.13235415518283844
Validation loss: 1.477719853001256

Epoch: 6| Step: 11
Training loss: 0.13760820031166077
Validation loss: 1.483883378326252

Epoch: 6| Step: 12
Training loss: 0.13116851449012756
Validation loss: 1.4993892997823737

Epoch: 6| Step: 13
Training loss: 0.14189091324806213
Validation loss: 1.5205813556589105

Epoch: 395| Step: 0
Training loss: 0.18179190158843994
Validation loss: 1.5011828868619856

Epoch: 6| Step: 1
Training loss: 0.29035109281539917
Validation loss: 1.5143058107745262

Epoch: 6| Step: 2
Training loss: 0.139089435338974
Validation loss: 1.52095236444986

Epoch: 6| Step: 3
Training loss: 0.2694183886051178
Validation loss: 1.5451295504006006

Epoch: 6| Step: 4
Training loss: 0.18140500783920288
Validation loss: 1.541497798376186

Epoch: 6| Step: 5
Training loss: 0.11400693655014038
Validation loss: 1.5575717418424544

Epoch: 6| Step: 6
Training loss: 0.11571905761957169
Validation loss: 1.535565963996354

Epoch: 6| Step: 7
Training loss: 0.11653245985507965
Validation loss: 1.564136125708139

Epoch: 6| Step: 8
Training loss: 0.12476149946451187
Validation loss: 1.5347357308992775

Epoch: 6| Step: 9
Training loss: 0.064488485455513
Validation loss: 1.54366692291793

Epoch: 6| Step: 10
Training loss: 0.11368478834629059
Validation loss: 1.5176678306312972

Epoch: 6| Step: 11
Training loss: 0.0770934447646141
Validation loss: 1.5197177183243535

Epoch: 6| Step: 12
Training loss: 0.2019626498222351
Validation loss: 1.5127525803863362

Epoch: 6| Step: 13
Training loss: 0.3806973993778229
Validation loss: 1.5078356278839933

Epoch: 396| Step: 0
Training loss: 0.11656241863965988
Validation loss: 1.4832645398314281

Epoch: 6| Step: 1
Training loss: 0.11334198713302612
Validation loss: 1.4886332699047622

Epoch: 6| Step: 2
Training loss: 0.12065806984901428
Validation loss: 1.4813531662828179

Epoch: 6| Step: 3
Training loss: 0.3138423562049866
Validation loss: 1.484185649502662

Epoch: 6| Step: 4
Training loss: 0.1635846346616745
Validation loss: 1.5166144242850683

Epoch: 6| Step: 5
Training loss: 0.12936627864837646
Validation loss: 1.5121822011086248

Epoch: 6| Step: 6
Training loss: 0.103130042552948
Validation loss: 1.4698561109522337

Epoch: 6| Step: 7
Training loss: 0.1062614768743515
Validation loss: 1.5165537134293587

Epoch: 6| Step: 8
Training loss: 0.25778093934059143
Validation loss: 1.5138354532180294

Epoch: 6| Step: 9
Training loss: 0.08132418990135193
Validation loss: 1.517386624889989

Epoch: 6| Step: 10
Training loss: 0.10617510229349136
Validation loss: 1.5328389175476567

Epoch: 6| Step: 11
Training loss: 0.15620383620262146
Validation loss: 1.5347384688674763

Epoch: 6| Step: 12
Training loss: 0.1768507957458496
Validation loss: 1.5410121128123293

Epoch: 6| Step: 13
Training loss: 0.24524293839931488
Validation loss: 1.5394645788336312

Epoch: 397| Step: 0
Training loss: 0.21643498539924622
Validation loss: 1.566157579421997

Epoch: 6| Step: 1
Training loss: 0.10030950605869293
Validation loss: 1.5307605599844327

Epoch: 6| Step: 2
Training loss: 0.13047510385513306
Validation loss: 1.5717378559932913

Epoch: 6| Step: 3
Training loss: 0.21094176173210144
Validation loss: 1.5593968681109849

Epoch: 6| Step: 4
Training loss: 0.117707259953022
Validation loss: 1.5627378289417555

Epoch: 6| Step: 5
Training loss: 0.1691513955593109
Validation loss: 1.5355858770749902

Epoch: 6| Step: 6
Training loss: 0.3660329580307007
Validation loss: 1.520819075645939

Epoch: 6| Step: 7
Training loss: 0.09849323332309723
Validation loss: 1.5180184892428819

Epoch: 6| Step: 8
Training loss: 0.15655334293842316
Validation loss: 1.5158070351487847

Epoch: 6| Step: 9
Training loss: 0.14832821488380432
Validation loss: 1.5206364521416285

Epoch: 6| Step: 10
Training loss: 0.1032923012971878
Validation loss: 1.5280350356973627

Epoch: 6| Step: 11
Training loss: 0.10624358803033829
Validation loss: 1.5168456377521637

Epoch: 6| Step: 12
Training loss: 0.12259619683027267
Validation loss: 1.5409428201695925

Epoch: 6| Step: 13
Training loss: 0.06396743655204773
Validation loss: 1.5267919507077945

Epoch: 398| Step: 0
Training loss: 0.16734960675239563
Validation loss: 1.5329598252491285

Epoch: 6| Step: 1
Training loss: 0.2222321331501007
Validation loss: 1.5323811051666096

Epoch: 6| Step: 2
Training loss: 0.06118806451559067
Validation loss: 1.5083650696662165

Epoch: 6| Step: 3
Training loss: 0.10521481931209564
Validation loss: 1.4893104068694576

Epoch: 6| Step: 4
Training loss: 0.09899469465017319
Validation loss: 1.4895198011911044

Epoch: 6| Step: 5
Training loss: 0.23278722167015076
Validation loss: 1.4728534157558153

Epoch: 6| Step: 6
Training loss: 0.12186922132968903
Validation loss: 1.4902275236704017

Epoch: 6| Step: 7
Training loss: 0.23926138877868652
Validation loss: 1.4862607140694895

Epoch: 6| Step: 8
Training loss: 0.12418511509895325
Validation loss: 1.492535969262482

Epoch: 6| Step: 9
Training loss: 0.13183358311653137
Validation loss: 1.5129032186282578

Epoch: 6| Step: 10
Training loss: 0.12251409888267517
Validation loss: 1.49038476456878

Epoch: 6| Step: 11
Training loss: 0.12906429171562195
Validation loss: 1.5008880874162078

Epoch: 6| Step: 12
Training loss: 0.10821607708930969
Validation loss: 1.5134287316312072

Epoch: 6| Step: 13
Training loss: 0.29162368178367615
Validation loss: 1.48636681161901

Epoch: 399| Step: 0
Training loss: 0.1277330070734024
Validation loss: 1.4967931573108961

Epoch: 6| Step: 1
Training loss: 0.1232447624206543
Validation loss: 1.5004603632034794

Epoch: 6| Step: 2
Training loss: 0.08356119692325592
Validation loss: 1.498276263154963

Epoch: 6| Step: 3
Training loss: 0.22630196809768677
Validation loss: 1.5022681054248606

Epoch: 6| Step: 4
Training loss: 0.23624488711357117
Validation loss: 1.5263481076045702

Epoch: 6| Step: 5
Training loss: 0.18254341185092926
Validation loss: 1.5251043663229993

Epoch: 6| Step: 6
Training loss: 0.16099703311920166
Validation loss: 1.5344657474948513

Epoch: 6| Step: 7
Training loss: 0.2258593589067459
Validation loss: 1.5489166834021126

Epoch: 6| Step: 8
Training loss: 0.1324254274368286
Validation loss: 1.5228692088075864

Epoch: 6| Step: 9
Training loss: 0.17156629264354706
Validation loss: 1.5336705292424848

Epoch: 6| Step: 10
Training loss: 0.2035113424062729
Validation loss: 1.5324424069414857

Epoch: 6| Step: 11
Training loss: 0.26728200912475586
Validation loss: 1.5817492469664542

Epoch: 6| Step: 12
Training loss: 0.14467960596084595
Validation loss: 1.578869600449839

Epoch: 6| Step: 13
Training loss: 0.17686785757541656
Validation loss: 1.5379044150793424

Epoch: 400| Step: 0
Training loss: 0.19470113515853882
Validation loss: 1.538148449313256

Epoch: 6| Step: 1
Training loss: 0.10910270363092422
Validation loss: 1.5226322104853969

Epoch: 6| Step: 2
Training loss: 0.13130596280097961
Validation loss: 1.5064549061559862

Epoch: 6| Step: 3
Training loss: 0.15580131113529205
Validation loss: 1.5201263158552107

Epoch: 6| Step: 4
Training loss: 0.23717446625232697
Validation loss: 1.526615959341808

Epoch: 6| Step: 5
Training loss: 0.24358634650707245
Validation loss: 1.546127378299672

Epoch: 6| Step: 6
Training loss: 0.1278758943080902
Validation loss: 1.5579045382879113

Epoch: 6| Step: 7
Training loss: 0.10643956810235977
Validation loss: 1.5477733035241403

Epoch: 6| Step: 8
Training loss: 0.21242383122444153
Validation loss: 1.5438872434759652

Epoch: 6| Step: 9
Training loss: 0.15362022817134857
Validation loss: 1.5244481909659602

Epoch: 6| Step: 10
Training loss: 0.11623828113079071
Validation loss: 1.5270124109842445

Epoch: 6| Step: 11
Training loss: 0.1336132287979126
Validation loss: 1.5296448225616126

Epoch: 6| Step: 12
Training loss: 0.08952009677886963
Validation loss: 1.5350045388744724

Epoch: 6| Step: 13
Training loss: 0.10167448967695236
Validation loss: 1.5133616321830339

Epoch: 401| Step: 0
Training loss: 0.07702003419399261
Validation loss: 1.4837586315729285

Epoch: 6| Step: 1
Training loss: 0.1003590077161789
Validation loss: 1.504495442554515

Epoch: 6| Step: 2
Training loss: 0.16135616600513458
Validation loss: 1.4757053646990048

Epoch: 6| Step: 3
Training loss: 0.25773072242736816
Validation loss: 1.4944497513514694

Epoch: 6| Step: 4
Training loss: 0.08742056787014008
Validation loss: 1.4994575387688094

Epoch: 6| Step: 5
Training loss: 0.11610473692417145
Validation loss: 1.4889472492279545

Epoch: 6| Step: 6
Training loss: 0.12831303477287292
Validation loss: 1.4829033062022219

Epoch: 6| Step: 7
Training loss: 0.1971704363822937
Validation loss: 1.4889172648870816

Epoch: 6| Step: 8
Training loss: 0.08435092866420746
Validation loss: 1.495182301408501

Epoch: 6| Step: 9
Training loss: 0.22441577911376953
Validation loss: 1.4806079172318982

Epoch: 6| Step: 10
Training loss: 0.13470140099525452
Validation loss: 1.4717863951959917

Epoch: 6| Step: 11
Training loss: 0.11148384213447571
Validation loss: 1.4777691056651454

Epoch: 6| Step: 12
Training loss: 0.12198574841022491
Validation loss: 1.516835694671959

Epoch: 6| Step: 13
Training loss: 0.15818412601947784
Validation loss: 1.5255671816487466

Epoch: 402| Step: 0
Training loss: 0.14513850212097168
Validation loss: 1.5158483828267744

Epoch: 6| Step: 1
Training loss: 0.14948178827762604
Validation loss: 1.5099174758439422

Epoch: 6| Step: 2
Training loss: 0.11250185966491699
Validation loss: 1.521921084773156

Epoch: 6| Step: 3
Training loss: 0.14222362637519836
Validation loss: 1.5142458036381712

Epoch: 6| Step: 4
Training loss: 0.22383353114128113
Validation loss: 1.5154333729897775

Epoch: 6| Step: 5
Training loss: 0.22577521204948425
Validation loss: 1.505081187012375

Epoch: 6| Step: 6
Training loss: 0.1131887137889862
Validation loss: 1.4752326037294121

Epoch: 6| Step: 7
Training loss: 0.12678208947181702
Validation loss: 1.4892646971569266

Epoch: 6| Step: 8
Training loss: 0.1570741981267929
Validation loss: 1.4540842592075307

Epoch: 6| Step: 9
Training loss: 0.1012628972530365
Validation loss: 1.5080875286491968

Epoch: 6| Step: 10
Training loss: 0.11011835187673569
Validation loss: 1.4866395804189867

Epoch: 6| Step: 11
Training loss: 0.07778900861740112
Validation loss: 1.5095196872629144

Epoch: 6| Step: 12
Training loss: 0.17326313257217407
Validation loss: 1.511177029660953

Epoch: 6| Step: 13
Training loss: 0.11645258963108063
Validation loss: 1.5258390736836258

Epoch: 403| Step: 0
Training loss: 0.14117947220802307
Validation loss: 1.5355586877433203

Epoch: 6| Step: 1
Training loss: 0.1336551457643509
Validation loss: 1.5304180037590764

Epoch: 6| Step: 2
Training loss: 0.12166154384613037
Validation loss: 1.540217743125013

Epoch: 6| Step: 3
Training loss: 0.2264021933078766
Validation loss: 1.5475274132144066

Epoch: 6| Step: 4
Training loss: 0.17903970181941986
Validation loss: 1.4908476119400353

Epoch: 6| Step: 5
Training loss: 0.1223524734377861
Validation loss: 1.47192580469193

Epoch: 6| Step: 6
Training loss: 0.10734846442937851
Validation loss: 1.4596508638833159

Epoch: 6| Step: 7
Training loss: 0.10016971826553345
Validation loss: 1.4823626318285543

Epoch: 6| Step: 8
Training loss: 0.1380416452884674
Validation loss: 1.47098175684611

Epoch: 6| Step: 9
Training loss: 0.2011387050151825
Validation loss: 1.4865501003880655

Epoch: 6| Step: 10
Training loss: 0.29561933875083923
Validation loss: 1.456511752579802

Epoch: 6| Step: 11
Training loss: 0.1272568553686142
Validation loss: 1.4593872844531972

Epoch: 6| Step: 12
Training loss: 0.08970233798027039
Validation loss: 1.4950237415170158

Epoch: 6| Step: 13
Training loss: 0.07034484297037125
Validation loss: 1.5008767932973883

Epoch: 404| Step: 0
Training loss: 0.14979183673858643
Validation loss: 1.5232633993189821

Epoch: 6| Step: 1
Training loss: 0.12199059128761292
Validation loss: 1.5238752685567385

Epoch: 6| Step: 2
Training loss: 0.2325945496559143
Validation loss: 1.497641312178745

Epoch: 6| Step: 3
Training loss: 0.0895995944738388
Validation loss: 1.474099301522778

Epoch: 6| Step: 4
Training loss: 0.11400210857391357
Validation loss: 1.4879813655730216

Epoch: 6| Step: 5
Training loss: 0.24976766109466553
Validation loss: 1.4663450948653682

Epoch: 6| Step: 6
Training loss: 0.22207173705101013
Validation loss: 1.486527019931424

Epoch: 6| Step: 7
Training loss: 0.0739082396030426
Validation loss: 1.5034239010144306

Epoch: 6| Step: 8
Training loss: 0.15770946443080902
Validation loss: 1.4951484575066516

Epoch: 6| Step: 9
Training loss: 0.1608964204788208
Validation loss: 1.5098809657558319

Epoch: 6| Step: 10
Training loss: 0.165179044008255
Validation loss: 1.499393061604551

Epoch: 6| Step: 11
Training loss: 0.14958058297634125
Validation loss: 1.5220169521147204

Epoch: 6| Step: 12
Training loss: 0.1749982386827469
Validation loss: 1.5052602951244642

Epoch: 6| Step: 13
Training loss: 0.1411800980567932
Validation loss: 1.524389156090316

Epoch: 405| Step: 0
Training loss: 0.11439397186040878
Validation loss: 1.515569394634616

Epoch: 6| Step: 1
Training loss: 0.08138902485370636
Validation loss: 1.4999910753260377

Epoch: 6| Step: 2
Training loss: 0.16130375862121582
Validation loss: 1.5055982899922196

Epoch: 6| Step: 3
Training loss: 0.14279823005199432
Validation loss: 1.5102879956204405

Epoch: 6| Step: 4
Training loss: 0.1550913006067276
Validation loss: 1.4995434450846847

Epoch: 6| Step: 5
Training loss: 0.1331387460231781
Validation loss: 1.5079566842766219

Epoch: 6| Step: 6
Training loss: 0.14843353629112244
Validation loss: 1.5071622812619774

Epoch: 6| Step: 7
Training loss: 0.10201486945152283
Validation loss: 1.5209129330932454

Epoch: 6| Step: 8
Training loss: 0.2103913575410843
Validation loss: 1.559697219120559

Epoch: 6| Step: 9
Training loss: 0.3096888065338135
Validation loss: 1.5956105288638864

Epoch: 6| Step: 10
Training loss: 0.13956201076507568
Validation loss: 1.5898554786559074

Epoch: 6| Step: 11
Training loss: 0.18130381405353546
Validation loss: 1.5713223180463236

Epoch: 6| Step: 12
Training loss: 0.3073030710220337
Validation loss: 1.586974686191928

Epoch: 6| Step: 13
Training loss: 0.1166304349899292
Validation loss: 1.5197527895691574

Epoch: 406| Step: 0
Training loss: 0.14328087866306305
Validation loss: 1.5185177249293174

Epoch: 6| Step: 1
Training loss: 0.18135567009449005
Validation loss: 1.5214560595891808

Epoch: 6| Step: 2
Training loss: 0.07620564103126526
Validation loss: 1.5128991603851318

Epoch: 6| Step: 3
Training loss: 0.1186147928237915
Validation loss: 1.5059557294332853

Epoch: 6| Step: 4
Training loss: 0.10218992829322815
Validation loss: 1.502069660412368

Epoch: 6| Step: 5
Training loss: 0.2595251202583313
Validation loss: 1.4964429306727585

Epoch: 6| Step: 6
Training loss: 0.28501641750335693
Validation loss: 1.496124376532852

Epoch: 6| Step: 7
Training loss: 0.14769595861434937
Validation loss: 1.5089552146132275

Epoch: 6| Step: 8
Training loss: 0.11784628033638
Validation loss: 1.512900096754874

Epoch: 6| Step: 9
Training loss: 0.1036662682890892
Validation loss: 1.5194861324884559

Epoch: 6| Step: 10
Training loss: 0.19288457930088043
Validation loss: 1.5291888278017762

Epoch: 6| Step: 11
Training loss: 0.10194907337427139
Validation loss: 1.5327291424556444

Epoch: 6| Step: 12
Training loss: 0.15235558152198792
Validation loss: 1.5528183624308596

Epoch: 6| Step: 13
Training loss: 0.1733367145061493
Validation loss: 1.5402604328688754

Epoch: 407| Step: 0
Training loss: 0.11008346825838089
Validation loss: 1.5503711815803283

Epoch: 6| Step: 1
Training loss: 0.15570098161697388
Validation loss: 1.5379294990211405

Epoch: 6| Step: 2
Training loss: 0.1262286901473999
Validation loss: 1.5560062123883156

Epoch: 6| Step: 3
Training loss: 0.07316360622644424
Validation loss: 1.5355624191222652

Epoch: 6| Step: 4
Training loss: 0.13627411425113678
Validation loss: 1.5448566175276233

Epoch: 6| Step: 5
Training loss: 0.13213908672332764
Validation loss: 1.5048094705868793

Epoch: 6| Step: 6
Training loss: 0.288453608751297
Validation loss: 1.5259265412566483

Epoch: 6| Step: 7
Training loss: 0.08782131969928741
Validation loss: 1.4653833514900618

Epoch: 6| Step: 8
Training loss: 0.1447264552116394
Validation loss: 1.4875037144589167

Epoch: 6| Step: 9
Training loss: 0.08012417703866959
Validation loss: 1.4999130387460031

Epoch: 6| Step: 10
Training loss: 0.07214690744876862
Validation loss: 1.4763346666930823

Epoch: 6| Step: 11
Training loss: 0.21592846512794495
Validation loss: 1.4623162073473777

Epoch: 6| Step: 12
Training loss: 0.06479573249816895
Validation loss: 1.486119988144085

Epoch: 6| Step: 13
Training loss: 0.1034139022231102
Validation loss: 1.506908905121588

Epoch: 408| Step: 0
Training loss: 0.16411948204040527
Validation loss: 1.4911824554525397

Epoch: 6| Step: 1
Training loss: 0.08631083369255066
Validation loss: 1.4740640597958719

Epoch: 6| Step: 2
Training loss: 0.13200470805168152
Validation loss: 1.4897387591741418

Epoch: 6| Step: 3
Training loss: 0.16282342374324799
Validation loss: 1.475336746502948

Epoch: 6| Step: 4
Training loss: 0.08387184888124466
Validation loss: 1.469570359876079

Epoch: 6| Step: 5
Training loss: 0.19161784648895264
Validation loss: 1.4763068127375778

Epoch: 6| Step: 6
Training loss: 0.12861350178718567
Validation loss: 1.4828031550171554

Epoch: 6| Step: 7
Training loss: 0.09731300175189972
Validation loss: 1.4739600766089656

Epoch: 6| Step: 8
Training loss: 0.12149754166603088
Validation loss: 1.4747091672753776

Epoch: 6| Step: 9
Training loss: 0.08423985540866852
Validation loss: 1.5230271136888893

Epoch: 6| Step: 10
Training loss: 0.19891045987606049
Validation loss: 1.4984730084737141

Epoch: 6| Step: 11
Training loss: 0.20288649201393127
Validation loss: 1.4856039298477994

Epoch: 6| Step: 12
Training loss: 0.08801347017288208
Validation loss: 1.490148744275493

Epoch: 6| Step: 13
Training loss: 0.45303085446357727
Validation loss: 1.5138629649275093

Epoch: 409| Step: 0
Training loss: 0.12702003121376038
Validation loss: 1.5174804836191156

Epoch: 6| Step: 1
Training loss: 0.07355450093746185
Validation loss: 1.5027468614680792

Epoch: 6| Step: 2
Training loss: 0.2666780650615692
Validation loss: 1.51781310830065

Epoch: 6| Step: 3
Training loss: 0.15545690059661865
Validation loss: 1.4805060419985043

Epoch: 6| Step: 4
Training loss: 0.2223360240459442
Validation loss: 1.4903021217674337

Epoch: 6| Step: 5
Training loss: 0.0991172194480896
Validation loss: 1.509989542345847

Epoch: 6| Step: 6
Training loss: 0.1502922624349594
Validation loss: 1.518316420175696

Epoch: 6| Step: 7
Training loss: 0.1324557065963745
Validation loss: 1.5364505321748796

Epoch: 6| Step: 8
Training loss: 0.1399621218442917
Validation loss: 1.5648909063749417

Epoch: 6| Step: 9
Training loss: 0.19048596918582916
Validation loss: 1.5595806029535109

Epoch: 6| Step: 10
Training loss: 0.10662434995174408
Validation loss: 1.5628236545029508

Epoch: 6| Step: 11
Training loss: 0.2475324124097824
Validation loss: 1.5765126071950442

Epoch: 6| Step: 12
Training loss: 0.07927139103412628
Validation loss: 1.5556984075935938

Epoch: 6| Step: 13
Training loss: 0.09542099386453629
Validation loss: 1.5624317597317439

Epoch: 410| Step: 0
Training loss: 0.23821143805980682
Validation loss: 1.5146967005986038

Epoch: 6| Step: 1
Training loss: 0.1213178038597107
Validation loss: 1.512313864564383

Epoch: 6| Step: 2
Training loss: 0.09363710135221481
Validation loss: 1.5190963975844844

Epoch: 6| Step: 3
Training loss: 0.06238366290926933
Validation loss: 1.4956019745078137

Epoch: 6| Step: 4
Training loss: 0.2075478434562683
Validation loss: 1.4885455177676292

Epoch: 6| Step: 5
Training loss: 0.11525923013687134
Validation loss: 1.4903114547011673

Epoch: 6| Step: 6
Training loss: 0.10974067449569702
Validation loss: 1.4835292062451761

Epoch: 6| Step: 7
Training loss: 0.11194030940532684
Validation loss: 1.446029237521592

Epoch: 6| Step: 8
Training loss: 0.13413262367248535
Validation loss: 1.4653713933883175

Epoch: 6| Step: 9
Training loss: 0.1640295386314392
Validation loss: 1.473554830397329

Epoch: 6| Step: 10
Training loss: 0.11831958591938019
Validation loss: 1.437820069251522

Epoch: 6| Step: 11
Training loss: 0.18484839797019958
Validation loss: 1.4238371708059823

Epoch: 6| Step: 12
Training loss: 0.1330445408821106
Validation loss: 1.4210040223213933

Epoch: 6| Step: 13
Training loss: 0.10479915142059326
Validation loss: 1.4184745139973138

Epoch: 411| Step: 0
Training loss: 0.10604814440011978
Validation loss: 1.4131952101184475

Epoch: 6| Step: 1
Training loss: 0.09572754800319672
Validation loss: 1.402484163161247

Epoch: 6| Step: 2
Training loss: 0.11311647295951843
Validation loss: 1.4373466853172547

Epoch: 6| Step: 3
Training loss: 0.17106148600578308
Validation loss: 1.435376404434122

Epoch: 6| Step: 4
Training loss: 0.21357181668281555
Validation loss: 1.4448081934323875

Epoch: 6| Step: 5
Training loss: 0.1261904537677765
Validation loss: 1.4291747385455715

Epoch: 6| Step: 6
Training loss: 0.12287396937608719
Validation loss: 1.4876152943539362

Epoch: 6| Step: 7
Training loss: 0.19534453749656677
Validation loss: 1.4461362669544835

Epoch: 6| Step: 8
Training loss: 0.11738960444927216
Validation loss: 1.4506249530341035

Epoch: 6| Step: 9
Training loss: 0.22268331050872803
Validation loss: 1.4645842044584212

Epoch: 6| Step: 10
Training loss: 0.05895049870014191
Validation loss: 1.4545998291302753

Epoch: 6| Step: 11
Training loss: 0.1086236834526062
Validation loss: 1.449186885228721

Epoch: 6| Step: 12
Training loss: 0.09110772609710693
Validation loss: 1.4519767113911208

Epoch: 6| Step: 13
Training loss: 0.10424208641052246
Validation loss: 1.4257859388987224

Epoch: 412| Step: 0
Training loss: 0.08183930814266205
Validation loss: 1.4553473059849074

Epoch: 6| Step: 1
Training loss: 0.16320979595184326
Validation loss: 1.4454878248194212

Epoch: 6| Step: 2
Training loss: 0.11464357376098633
Validation loss: 1.4424920453820178

Epoch: 6| Step: 3
Training loss: 0.07861950993537903
Validation loss: 1.50503045833239

Epoch: 6| Step: 4
Training loss: 0.2100898176431656
Validation loss: 1.487787377449774

Epoch: 6| Step: 5
Training loss: 0.09213411808013916
Validation loss: 1.4883489672855665

Epoch: 6| Step: 6
Training loss: 0.09916342794895172
Validation loss: 1.523698176107099

Epoch: 6| Step: 7
Training loss: 0.1512315273284912
Validation loss: 1.5125581551623601

Epoch: 6| Step: 8
Training loss: 0.0849282443523407
Validation loss: 1.5237814893004715

Epoch: 6| Step: 9
Training loss: 0.07626336067914963
Validation loss: 1.5213320601371028

Epoch: 6| Step: 10
Training loss: 0.13269147276878357
Validation loss: 1.5389110529294578

Epoch: 6| Step: 11
Training loss: 0.10302777588367462
Validation loss: 1.5465459938972228

Epoch: 6| Step: 12
Training loss: 0.214474156498909
Validation loss: 1.5108622530455231

Epoch: 6| Step: 13
Training loss: 0.12352310121059418
Validation loss: 1.4990770214347429

Epoch: 413| Step: 0
Training loss: 0.09151104092597961
Validation loss: 1.488005990623146

Epoch: 6| Step: 1
Training loss: 0.14810751378536224
Validation loss: 1.5077251958590683

Epoch: 6| Step: 2
Training loss: 0.07147505134344101
Validation loss: 1.481535929505543

Epoch: 6| Step: 3
Training loss: 0.06852921843528748
Validation loss: 1.5047433222493818

Epoch: 6| Step: 4
Training loss: 0.12946780025959015
Validation loss: 1.5317724776524368

Epoch: 6| Step: 5
Training loss: 0.19695110619068146
Validation loss: 1.5357064329167849

Epoch: 6| Step: 6
Training loss: 0.17900845408439636
Validation loss: 1.5282857136059833

Epoch: 6| Step: 7
Training loss: 0.16528835892677307
Validation loss: 1.5401733177964405

Epoch: 6| Step: 8
Training loss: 0.16708199679851532
Validation loss: 1.534706405414048

Epoch: 6| Step: 9
Training loss: 0.150174081325531
Validation loss: 1.5431351123317596

Epoch: 6| Step: 10
Training loss: 0.13379043340682983
Validation loss: 1.5249835188670824

Epoch: 6| Step: 11
Training loss: 0.3197516202926636
Validation loss: 1.5185054707270798

Epoch: 6| Step: 12
Training loss: 0.14769744873046875
Validation loss: 1.5046991955849431

Epoch: 6| Step: 13
Training loss: 0.1349734216928482
Validation loss: 1.4662922043954172

Epoch: 414| Step: 0
Training loss: 0.1790202558040619
Validation loss: 1.4790334855356524

Epoch: 6| Step: 1
Training loss: 0.14429742097854614
Validation loss: 1.479907161446028

Epoch: 6| Step: 2
Training loss: 0.09507175534963608
Validation loss: 1.4627261379713654

Epoch: 6| Step: 3
Training loss: 0.1294548511505127
Validation loss: 1.4641893935459915

Epoch: 6| Step: 4
Training loss: 0.13921841979026794
Validation loss: 1.4781256837229575

Epoch: 6| Step: 5
Training loss: 0.12045928835868835
Validation loss: 1.493859287231199

Epoch: 6| Step: 6
Training loss: 0.11756379902362823
Validation loss: 1.4673501881220008

Epoch: 6| Step: 7
Training loss: 0.09741605818271637
Validation loss: 1.4877479191749328

Epoch: 6| Step: 8
Training loss: 0.21992488205432892
Validation loss: 1.495114814850592

Epoch: 6| Step: 9
Training loss: 0.2522229254245758
Validation loss: 1.4916321052018033

Epoch: 6| Step: 10
Training loss: 0.1343926340341568
Validation loss: 1.503951520048162

Epoch: 6| Step: 11
Training loss: 0.0911138653755188
Validation loss: 1.5240554668570077

Epoch: 6| Step: 12
Training loss: 0.1049613505601883
Validation loss: 1.5304596219011533

Epoch: 6| Step: 13
Training loss: 0.08790302276611328
Validation loss: 1.5368840015062721

Epoch: 415| Step: 0
Training loss: 0.13156551122665405
Validation loss: 1.5357434788057882

Epoch: 6| Step: 1
Training loss: 0.11996589601039886
Validation loss: 1.5119124433045745

Epoch: 6| Step: 2
Training loss: 0.16690173745155334
Validation loss: 1.4880850571458057

Epoch: 6| Step: 3
Training loss: 0.08173789083957672
Validation loss: 1.4769029155854256

Epoch: 6| Step: 4
Training loss: 0.10623699426651001
Validation loss: 1.5123773826065885

Epoch: 6| Step: 5
Training loss: 0.15333911776542664
Validation loss: 1.4920014360899567

Epoch: 6| Step: 6
Training loss: 0.06608395278453827
Validation loss: 1.514988624921409

Epoch: 6| Step: 7
Training loss: 0.10242876410484314
Validation loss: 1.509233154276366

Epoch: 6| Step: 8
Training loss: 0.08083099126815796
Validation loss: 1.4828166782215078

Epoch: 6| Step: 9
Training loss: 0.08253799378871918
Validation loss: 1.4964371188994376

Epoch: 6| Step: 10
Training loss: 0.09560181945562363
Validation loss: 1.5028379950472104

Epoch: 6| Step: 11
Training loss: 0.20136258006095886
Validation loss: 1.541875680287679

Epoch: 6| Step: 12
Training loss: 0.13988222181797028
Validation loss: 1.544707457224528

Epoch: 6| Step: 13
Training loss: 0.2675231695175171
Validation loss: 1.5523204713739374

Epoch: 416| Step: 0
Training loss: 0.19232064485549927
Validation loss: 1.5082814437086864

Epoch: 6| Step: 1
Training loss: 0.11805223673582077
Validation loss: 1.5097994086562947

Epoch: 6| Step: 2
Training loss: 0.11417463421821594
Validation loss: 1.5229179487433484

Epoch: 6| Step: 3
Training loss: 0.13373549282550812
Validation loss: 1.477846662203471

Epoch: 6| Step: 4
Training loss: 0.11146658658981323
Validation loss: 1.480593971026841

Epoch: 6| Step: 5
Training loss: 0.13557586073875427
Validation loss: 1.4523713563078193

Epoch: 6| Step: 6
Training loss: 0.164638489484787
Validation loss: 1.4666060145183275

Epoch: 6| Step: 7
Training loss: 0.12263177335262299
Validation loss: 1.4531133085168817

Epoch: 6| Step: 8
Training loss: 0.34722286462783813
Validation loss: 1.4569213633896203

Epoch: 6| Step: 9
Training loss: 0.12852536141872406
Validation loss: 1.4687559168825868

Epoch: 6| Step: 10
Training loss: 0.10720936208963394
Validation loss: 1.468913443626896

Epoch: 6| Step: 11
Training loss: 0.06585343182086945
Validation loss: 1.496838810623333

Epoch: 6| Step: 12
Training loss: 0.09182462096214294
Validation loss: 1.5031266379100021

Epoch: 6| Step: 13
Training loss: 0.1781664490699768
Validation loss: 1.5152408666508173

Epoch: 417| Step: 0
Training loss: 0.11961981654167175
Validation loss: 1.5476570898486721

Epoch: 6| Step: 1
Training loss: 0.10121690481901169
Validation loss: 1.5102994557349914

Epoch: 6| Step: 2
Training loss: 0.10679417103528976
Validation loss: 1.5032314318482594

Epoch: 6| Step: 3
Training loss: 0.18003159761428833
Validation loss: 1.5151210420875139

Epoch: 6| Step: 4
Training loss: 0.1709669530391693
Validation loss: 1.4847171691156202

Epoch: 6| Step: 5
Training loss: 0.3640652894973755
Validation loss: 1.49380527516847

Epoch: 6| Step: 6
Training loss: 0.11215932667255402
Validation loss: 1.4831341799869333

Epoch: 6| Step: 7
Training loss: 0.12164109200239182
Validation loss: 1.5300328372627177

Epoch: 6| Step: 8
Training loss: 0.11923178285360336
Validation loss: 1.5338738272267003

Epoch: 6| Step: 9
Training loss: 0.09997361898422241
Validation loss: 1.548662148496156

Epoch: 6| Step: 10
Training loss: 0.12162797152996063
Validation loss: 1.5593678823081396

Epoch: 6| Step: 11
Training loss: 0.08602100610733032
Validation loss: 1.5460589611402122

Epoch: 6| Step: 12
Training loss: 0.15187765657901764
Validation loss: 1.5358689997785835

Epoch: 6| Step: 13
Training loss: 0.06713298708200455
Validation loss: 1.5069773966266262

Epoch: 418| Step: 0
Training loss: 0.10772737860679626
Validation loss: 1.5051322688338578

Epoch: 6| Step: 1
Training loss: 0.11144503951072693
Validation loss: 1.4976348479588826

Epoch: 6| Step: 2
Training loss: 0.2683733105659485
Validation loss: 1.475923107516381

Epoch: 6| Step: 3
Training loss: 0.1376054286956787
Validation loss: 1.4960234113918838

Epoch: 6| Step: 4
Training loss: 0.10273263603448868
Validation loss: 1.4819202500004922

Epoch: 6| Step: 5
Training loss: 0.12127190828323364
Validation loss: 1.4756035163838377

Epoch: 6| Step: 6
Training loss: 0.10658397525548935
Validation loss: 1.4692534990208124

Epoch: 6| Step: 7
Training loss: 0.20497840642929077
Validation loss: 1.4971791569904616

Epoch: 6| Step: 8
Training loss: 0.10556773841381073
Validation loss: 1.484702544827615

Epoch: 6| Step: 9
Training loss: 0.10542082786560059
Validation loss: 1.4907481016651276

Epoch: 6| Step: 10
Training loss: 0.16724804043769836
Validation loss: 1.4995196506541262

Epoch: 6| Step: 11
Training loss: 0.09720826894044876
Validation loss: 1.479770068840314

Epoch: 6| Step: 12
Training loss: 0.1682572066783905
Validation loss: 1.5055846937241093

Epoch: 6| Step: 13
Training loss: 0.10085243731737137
Validation loss: 1.4566496661914292

Epoch: 419| Step: 0
Training loss: 0.1106390506029129
Validation loss: 1.4468654080103802

Epoch: 6| Step: 1
Training loss: 0.11243002116680145
Validation loss: 1.4751737002403504

Epoch: 6| Step: 2
Training loss: 0.0840655118227005
Validation loss: 1.4279240228796517

Epoch: 6| Step: 3
Training loss: 0.1969134509563446
Validation loss: 1.4381731043579757

Epoch: 6| Step: 4
Training loss: 0.09180925786495209
Validation loss: 1.429901337110868

Epoch: 6| Step: 5
Training loss: 0.3006126284599304
Validation loss: 1.4183310103672806

Epoch: 6| Step: 6
Training loss: 0.10894368588924408
Validation loss: 1.4289442172614477

Epoch: 6| Step: 7
Training loss: 0.13643401861190796
Validation loss: 1.442642190123117

Epoch: 6| Step: 8
Training loss: 0.1042083203792572
Validation loss: 1.4545263872351697

Epoch: 6| Step: 9
Training loss: 0.0924239307641983
Validation loss: 1.4367590553017073

Epoch: 6| Step: 10
Training loss: 0.06296417117118835
Validation loss: 1.4616643433929772

Epoch: 6| Step: 11
Training loss: 0.17601144313812256
Validation loss: 1.4554363707060456

Epoch: 6| Step: 12
Training loss: 0.1388334333896637
Validation loss: 1.4490541488893571

Epoch: 6| Step: 13
Training loss: 0.07333937287330627
Validation loss: 1.458573902806928

Epoch: 420| Step: 0
Training loss: 0.10299097001552582
Validation loss: 1.4869343196192095

Epoch: 6| Step: 1
Training loss: 0.1483294665813446
Validation loss: 1.4997305152236775

Epoch: 6| Step: 2
Training loss: 0.10820605605840683
Validation loss: 1.4868543968405774

Epoch: 6| Step: 3
Training loss: 0.26172351837158203
Validation loss: 1.4997916554891935

Epoch: 6| Step: 4
Training loss: 0.07975950837135315
Validation loss: 1.5125555088443141

Epoch: 6| Step: 5
Training loss: 0.11463510990142822
Validation loss: 1.4928525070990286

Epoch: 6| Step: 6
Training loss: 0.08910307288169861
Validation loss: 1.4994911827066892

Epoch: 6| Step: 7
Training loss: 0.21313683688640594
Validation loss: 1.4678656849809872

Epoch: 6| Step: 8
Training loss: 0.09908921271562576
Validation loss: 1.4744785626729329

Epoch: 6| Step: 9
Training loss: 0.16739000380039215
Validation loss: 1.4551222273098525

Epoch: 6| Step: 10
Training loss: 0.09725789725780487
Validation loss: 1.4436918420176352

Epoch: 6| Step: 11
Training loss: 0.10227009654045105
Validation loss: 1.452386438205678

Epoch: 6| Step: 12
Training loss: 0.0998406708240509
Validation loss: 1.451437548924518

Epoch: 6| Step: 13
Training loss: 0.10724673420190811
Validation loss: 1.4264291870978572

Epoch: 421| Step: 0
Training loss: 0.08127902448177338
Validation loss: 1.4289042642039638

Epoch: 6| Step: 1
Training loss: 0.11386285722255707
Validation loss: 1.4408774260551698

Epoch: 6| Step: 2
Training loss: 0.0959150418639183
Validation loss: 1.4332403213747087

Epoch: 6| Step: 3
Training loss: 0.10277248919010162
Validation loss: 1.480113721662952

Epoch: 6| Step: 4
Training loss: 0.09995107352733612
Validation loss: 1.4802280446534515

Epoch: 6| Step: 5
Training loss: 0.1384093314409256
Validation loss: 1.483434764287805

Epoch: 6| Step: 6
Training loss: 0.15837904810905457
Validation loss: 1.4812626864320488

Epoch: 6| Step: 7
Training loss: 0.12032986432313919
Validation loss: 1.5101192151346514

Epoch: 6| Step: 8
Training loss: 0.14937733113765717
Validation loss: 1.497541175093702

Epoch: 6| Step: 9
Training loss: 0.21320365369319916
Validation loss: 1.4968213983761367

Epoch: 6| Step: 10
Training loss: 0.10902847349643707
Validation loss: 1.5399864232668312

Epoch: 6| Step: 11
Training loss: 0.29580914974212646
Validation loss: 1.5160873884795814

Epoch: 6| Step: 12
Training loss: 0.09028302878141403
Validation loss: 1.4963829568637315

Epoch: 6| Step: 13
Training loss: 0.12033621221780777
Validation loss: 1.5150865867573728

Epoch: 422| Step: 0
Training loss: 0.1435708850622177
Validation loss: 1.5149102608362834

Epoch: 6| Step: 1
Training loss: 0.19812552630901337
Validation loss: 1.5233631223760626

Epoch: 6| Step: 2
Training loss: 0.2239549160003662
Validation loss: 1.509889280924233

Epoch: 6| Step: 3
Training loss: 0.10673097521066666
Validation loss: 1.5336018441825785

Epoch: 6| Step: 4
Training loss: 0.15954715013504028
Validation loss: 1.4814556055171515

Epoch: 6| Step: 5
Training loss: 0.10931938141584396
Validation loss: 1.4821476936340332

Epoch: 6| Step: 6
Training loss: 0.11716225743293762
Validation loss: 1.4884960241215204

Epoch: 6| Step: 7
Training loss: 0.20357376337051392
Validation loss: 1.513887935428209

Epoch: 6| Step: 8
Training loss: 0.14223289489746094
Validation loss: 1.498326269529199

Epoch: 6| Step: 9
Training loss: 0.1390964537858963
Validation loss: 1.501731118848247

Epoch: 6| Step: 10
Training loss: 0.1309342384338379
Validation loss: 1.5056445560147684

Epoch: 6| Step: 11
Training loss: 0.08509720116853714
Validation loss: 1.5013322394381288

Epoch: 6| Step: 12
Training loss: 0.10077330470085144
Validation loss: 1.5028957654071111

Epoch: 6| Step: 13
Training loss: 0.12826339900493622
Validation loss: 1.5150021660712458

Epoch: 423| Step: 0
Training loss: 0.10058967769145966
Validation loss: 1.50592331476109

Epoch: 6| Step: 1
Training loss: 0.130080908536911
Validation loss: 1.5201395301408664

Epoch: 6| Step: 2
Training loss: 0.09827598184347153
Validation loss: 1.522463293485744

Epoch: 6| Step: 3
Training loss: 0.17628416419029236
Validation loss: 1.5210999647776287

Epoch: 6| Step: 4
Training loss: 0.1849091351032257
Validation loss: 1.5359001428850236

Epoch: 6| Step: 5
Training loss: 0.15316016972064972
Validation loss: 1.5451609562802058

Epoch: 6| Step: 6
Training loss: 0.13566990196704865
Validation loss: 1.5527632236480713

Epoch: 6| Step: 7
Training loss: 0.09699743986129761
Validation loss: 1.534671603992421

Epoch: 6| Step: 8
Training loss: 0.15130995213985443
Validation loss: 1.5020309084205217

Epoch: 6| Step: 9
Training loss: 0.14103227853775024
Validation loss: 1.4919923390111616

Epoch: 6| Step: 10
Training loss: 0.13895681500434875
Validation loss: 1.51168901945955

Epoch: 6| Step: 11
Training loss: 0.11924246698617935
Validation loss: 1.4829718707710184

Epoch: 6| Step: 12
Training loss: 0.19103558361530304
Validation loss: 1.5144448818699006

Epoch: 6| Step: 13
Training loss: 0.35082539916038513
Validation loss: 1.499358646331295

Epoch: 424| Step: 0
Training loss: 0.14113247394561768
Validation loss: 1.4993872937335764

Epoch: 6| Step: 1
Training loss: 0.17304730415344238
Validation loss: 1.5023030388739802

Epoch: 6| Step: 2
Training loss: 0.09992125630378723
Validation loss: 1.5132255836199688

Epoch: 6| Step: 3
Training loss: 0.10014685988426208
Validation loss: 1.4950591710305983

Epoch: 6| Step: 4
Training loss: 0.10703263431787491
Validation loss: 1.5125089024984708

Epoch: 6| Step: 5
Training loss: 0.2216801941394806
Validation loss: 1.5267063712561002

Epoch: 6| Step: 6
Training loss: 0.1355835646390915
Validation loss: 1.523448569800264

Epoch: 6| Step: 7
Training loss: 0.16671137511730194
Validation loss: 1.5338113692498976

Epoch: 6| Step: 8
Training loss: 0.19989962875843048
Validation loss: 1.5166143409667476

Epoch: 6| Step: 9
Training loss: 0.08911295980215073
Validation loss: 1.494838902386286

Epoch: 6| Step: 10
Training loss: 0.13995859026908875
Validation loss: 1.5065492122404036

Epoch: 6| Step: 11
Training loss: 0.08589096367359161
Validation loss: 1.5041343371073406

Epoch: 6| Step: 12
Training loss: 0.10322929918766022
Validation loss: 1.4760179494016914

Epoch: 6| Step: 13
Training loss: 0.12324505299329758
Validation loss: 1.4867552211207729

Epoch: 425| Step: 0
Training loss: 0.1506911665201187
Validation loss: 1.4978311356677805

Epoch: 6| Step: 1
Training loss: 0.0928337574005127
Validation loss: 1.5184219037332842

Epoch: 6| Step: 2
Training loss: 0.2254396229982376
Validation loss: 1.5095810582560878

Epoch: 6| Step: 3
Training loss: 0.08112534880638123
Validation loss: 1.5116651968289447

Epoch: 6| Step: 4
Training loss: 0.15534532070159912
Validation loss: 1.4974062455597745

Epoch: 6| Step: 5
Training loss: 0.06369662284851074
Validation loss: 1.5609398465002737

Epoch: 6| Step: 6
Training loss: 0.19524867832660675
Validation loss: 1.5058176158576884

Epoch: 6| Step: 7
Training loss: 0.15199272334575653
Validation loss: 1.527921434371702

Epoch: 6| Step: 8
Training loss: 0.08393647521734238
Validation loss: 1.4880016247431438

Epoch: 6| Step: 9
Training loss: 0.12353566288948059
Validation loss: 1.448624425036933

Epoch: 6| Step: 10
Training loss: 0.11418745666742325
Validation loss: 1.4663960267138738

Epoch: 6| Step: 11
Training loss: 0.11448103934526443
Validation loss: 1.4743717139767063

Epoch: 6| Step: 12
Training loss: 0.21624058485031128
Validation loss: 1.4433399656767487

Epoch: 6| Step: 13
Training loss: 0.09569276869297028
Validation loss: 1.4629211130962576

Epoch: 426| Step: 0
Training loss: 0.10158248990774155
Validation loss: 1.4789111293772215

Epoch: 6| Step: 1
Training loss: 0.10707738995552063
Validation loss: 1.4473553043539806

Epoch: 6| Step: 2
Training loss: 0.1809317171573639
Validation loss: 1.4375104852901992

Epoch: 6| Step: 3
Training loss: 0.131639301776886
Validation loss: 1.4550476907401957

Epoch: 6| Step: 4
Training loss: 0.11596749722957611
Validation loss: 1.4782308916891775

Epoch: 6| Step: 5
Training loss: 0.19754113256931305
Validation loss: 1.4572051212351809

Epoch: 6| Step: 6
Training loss: 0.1276058703660965
Validation loss: 1.5004198499905166

Epoch: 6| Step: 7
Training loss: 0.10517995059490204
Validation loss: 1.5030319113885202

Epoch: 6| Step: 8
Training loss: 0.10129068791866302
Validation loss: 1.5339034244578371

Epoch: 6| Step: 9
Training loss: 0.1744307577610016
Validation loss: 1.5176806475526543

Epoch: 6| Step: 10
Training loss: 0.14868766069412231
Validation loss: 1.525606434832337

Epoch: 6| Step: 11
Training loss: 0.13602206110954285
Validation loss: 1.519275503773843

Epoch: 6| Step: 12
Training loss: 0.2098645120859146
Validation loss: 1.479441112087619

Epoch: 6| Step: 13
Training loss: 0.09901528805494308
Validation loss: 1.500485671463833

Epoch: 427| Step: 0
Training loss: 0.0665343776345253
Validation loss: 1.5067779043669343

Epoch: 6| Step: 1
Training loss: 0.10220733284950256
Validation loss: 1.5457687839385001

Epoch: 6| Step: 2
Training loss: 0.0720355212688446
Validation loss: 1.5467148057876094

Epoch: 6| Step: 3
Training loss: 0.07686875760555267
Validation loss: 1.5400230371823875

Epoch: 6| Step: 4
Training loss: 0.16045698523521423
Validation loss: 1.5370024820809722

Epoch: 6| Step: 5
Training loss: 0.10020390152931213
Validation loss: 1.532401942437695

Epoch: 6| Step: 6
Training loss: 0.11638680100440979
Validation loss: 1.505525105102088

Epoch: 6| Step: 7
Training loss: 0.2143235057592392
Validation loss: 1.4993743550392888

Epoch: 6| Step: 8
Training loss: 0.24080778658390045
Validation loss: 1.477727101695153

Epoch: 6| Step: 9
Training loss: 0.10020260512828827
Validation loss: 1.4730913049431258

Epoch: 6| Step: 10
Training loss: 0.2214323878288269
Validation loss: 1.475549772221555

Epoch: 6| Step: 11
Training loss: 0.17132249474525452
Validation loss: 1.4836878366367792

Epoch: 6| Step: 12
Training loss: 0.13721618056297302
Validation loss: 1.4828786157792615

Epoch: 6| Step: 13
Training loss: 0.14871735870838165
Validation loss: 1.4899111883614653

Epoch: 428| Step: 0
Training loss: 0.1373651772737503
Validation loss: 1.4640742014813166

Epoch: 6| Step: 1
Training loss: 0.0831403136253357
Validation loss: 1.459444462612111

Epoch: 6| Step: 2
Training loss: 0.1805882453918457
Validation loss: 1.4551683959140573

Epoch: 6| Step: 3
Training loss: 0.10515470802783966
Validation loss: 1.4758810061280445

Epoch: 6| Step: 4
Training loss: 0.15471553802490234
Validation loss: 1.4654509239299323

Epoch: 6| Step: 5
Training loss: 0.20163902640342712
Validation loss: 1.4831383882030365

Epoch: 6| Step: 6
Training loss: 0.23958683013916016
Validation loss: 1.4853888762894498

Epoch: 6| Step: 7
Training loss: 0.15733084082603455
Validation loss: 1.4847646720947758

Epoch: 6| Step: 8
Training loss: 0.10351057350635529
Validation loss: 1.483476633666664

Epoch: 6| Step: 9
Training loss: 0.11358505487442017
Validation loss: 1.460390774152612

Epoch: 6| Step: 10
Training loss: 0.0869300365447998
Validation loss: 1.4389300948830062

Epoch: 6| Step: 11
Training loss: 0.1252112239599228
Validation loss: 1.4363985138554727

Epoch: 6| Step: 12
Training loss: 0.10919476300477982
Validation loss: 1.4322863221168518

Epoch: 6| Step: 13
Training loss: 0.10594974458217621
Validation loss: 1.4295486083594702

Epoch: 429| Step: 0
Training loss: 0.2062908113002777
Validation loss: 1.4120019751210366

Epoch: 6| Step: 1
Training loss: 0.15668122470378876
Validation loss: 1.4349218017311507

Epoch: 6| Step: 2
Training loss: 0.12259364873170853
Validation loss: 1.4098448727720527

Epoch: 6| Step: 3
Training loss: 0.10355211049318314
Validation loss: 1.4349210454571633

Epoch: 6| Step: 4
Training loss: 0.05410267785191536
Validation loss: 1.4389215169414398

Epoch: 6| Step: 5
Training loss: 0.10654579102993011
Validation loss: 1.4634395696783578

Epoch: 6| Step: 6
Training loss: 0.09120297431945801
Validation loss: 1.453445041051475

Epoch: 6| Step: 7
Training loss: 0.09127477556467056
Validation loss: 1.4899321691964262

Epoch: 6| Step: 8
Training loss: 0.0908278077840805
Validation loss: 1.494293092399515

Epoch: 6| Step: 9
Training loss: 0.11842136830091476
Validation loss: 1.5020902028647802

Epoch: 6| Step: 10
Training loss: 0.12471521645784378
Validation loss: 1.5072517805202033

Epoch: 6| Step: 11
Training loss: 0.1869034618139267
Validation loss: 1.4932579763474003

Epoch: 6| Step: 12
Training loss: 0.20275667309761047
Validation loss: 1.4956954345908215

Epoch: 6| Step: 13
Training loss: 0.08938011527061462
Validation loss: 1.4923618660178235

Epoch: 430| Step: 0
Training loss: 0.07612857222557068
Validation loss: 1.4651125028569212

Epoch: 6| Step: 1
Training loss: 0.05086743086576462
Validation loss: 1.4698850083094772

Epoch: 6| Step: 2
Training loss: 0.2293488085269928
Validation loss: 1.4646110598758986

Epoch: 6| Step: 3
Training loss: 0.07793653011322021
Validation loss: 1.4956792336638256

Epoch: 6| Step: 4
Training loss: 0.1410691738128662
Validation loss: 1.470802495556493

Epoch: 6| Step: 5
Training loss: 0.11780643463134766
Validation loss: 1.484744785934366

Epoch: 6| Step: 6
Training loss: 0.21992704272270203
Validation loss: 1.4945262580789545

Epoch: 6| Step: 7
Training loss: 0.0879908874630928
Validation loss: 1.5154645955690773

Epoch: 6| Step: 8
Training loss: 0.22526615858078003
Validation loss: 1.515580701571639

Epoch: 6| Step: 9
Training loss: 0.1032666563987732
Validation loss: 1.53709715156145

Epoch: 6| Step: 10
Training loss: 0.07371021062135696
Validation loss: 1.5421765811981694

Epoch: 6| Step: 11
Training loss: 0.13487574458122253
Validation loss: 1.52483437010037

Epoch: 6| Step: 12
Training loss: 0.14429306983947754
Validation loss: 1.5526780902698476

Epoch: 6| Step: 13
Training loss: 0.13183872401714325
Validation loss: 1.5468785044967488

Epoch: 431| Step: 0
Training loss: 0.20831076800823212
Validation loss: 1.5473219592084166

Epoch: 6| Step: 1
Training loss: 0.24172531068325043
Validation loss: 1.5561537140159196

Epoch: 6| Step: 2
Training loss: 0.10876163095235825
Validation loss: 1.5189196691718152

Epoch: 6| Step: 3
Training loss: 0.14778777956962585
Validation loss: 1.499111484455806

Epoch: 6| Step: 4
Training loss: 0.08263896405696869
Validation loss: 1.4768274086777882

Epoch: 6| Step: 5
Training loss: 0.04309173673391342
Validation loss: 1.4569725093021189

Epoch: 6| Step: 6
Training loss: 0.12927497923374176
Validation loss: 1.4215968373001262

Epoch: 6| Step: 7
Training loss: 0.12122491747140884
Validation loss: 1.443791022864721

Epoch: 6| Step: 8
Training loss: 0.18286120891571045
Validation loss: 1.4094207479107765

Epoch: 6| Step: 9
Training loss: 0.09029799699783325
Validation loss: 1.4102998933484476

Epoch: 6| Step: 10
Training loss: 0.12228542566299438
Validation loss: 1.4267701295114332

Epoch: 6| Step: 11
Training loss: 0.17801418900489807
Validation loss: 1.427841523642181

Epoch: 6| Step: 12
Training loss: 0.11763676255941391
Validation loss: 1.451873593432929

Epoch: 6| Step: 13
Training loss: 0.12995702028274536
Validation loss: 1.4662073940359137

Epoch: 432| Step: 0
Training loss: 0.07586851716041565
Validation loss: 1.4599398695012575

Epoch: 6| Step: 1
Training loss: 0.12001713365316391
Validation loss: 1.468483942811207

Epoch: 6| Step: 2
Training loss: 0.152572900056839
Validation loss: 1.5068503887422624

Epoch: 6| Step: 3
Training loss: 0.14164142310619354
Validation loss: 1.4783456171712568

Epoch: 6| Step: 4
Training loss: 0.1031918078660965
Validation loss: 1.4931623410153132

Epoch: 6| Step: 5
Training loss: 0.16424165666103363
Validation loss: 1.472429544694962

Epoch: 6| Step: 6
Training loss: 0.1528831273317337
Validation loss: 1.450992343246296

Epoch: 6| Step: 7
Training loss: 0.24097177386283875
Validation loss: 1.4370021038157965

Epoch: 6| Step: 8
Training loss: 0.09303566068410873
Validation loss: 1.4291282699954124

Epoch: 6| Step: 9
Training loss: 0.2217104434967041
Validation loss: 1.428317166143848

Epoch: 6| Step: 10
Training loss: 0.068266861140728
Validation loss: 1.428626157904184

Epoch: 6| Step: 11
Training loss: 0.10894361138343811
Validation loss: 1.453420207064639

Epoch: 6| Step: 12
Training loss: 0.2175389975309372
Validation loss: 1.4244821917626165

Epoch: 6| Step: 13
Training loss: 0.07338106632232666
Validation loss: 1.4157389363934916

Epoch: 433| Step: 0
Training loss: 0.10298144072294235
Validation loss: 1.4189872318698513

Epoch: 6| Step: 1
Training loss: 0.08664526790380478
Validation loss: 1.4361753130471835

Epoch: 6| Step: 2
Training loss: 0.11413892358541489
Validation loss: 1.4629301307021931

Epoch: 6| Step: 3
Training loss: 0.12141339480876923
Validation loss: 1.450632910574636

Epoch: 6| Step: 4
Training loss: 0.14056448638439178
Validation loss: 1.469784959670036

Epoch: 6| Step: 5
Training loss: 0.13518992066383362
Validation loss: 1.500614530296736

Epoch: 6| Step: 6
Training loss: 0.2133529782295227
Validation loss: 1.5160527331854707

Epoch: 6| Step: 7
Training loss: 0.07274266332387924
Validation loss: 1.4838229148618636

Epoch: 6| Step: 8
Training loss: 0.15214946866035461
Validation loss: 1.5136445722272318

Epoch: 6| Step: 9
Training loss: 0.12231655418872833
Validation loss: 1.5102639095757597

Epoch: 6| Step: 10
Training loss: 0.21288546919822693
Validation loss: 1.5226514550947374

Epoch: 6| Step: 11
Training loss: 0.18327085673809052
Validation loss: 1.5194164322268577

Epoch: 6| Step: 12
Training loss: 0.08857253938913345
Validation loss: 1.5094455224211498

Epoch: 6| Step: 13
Training loss: 0.11311875283718109
Validation loss: 1.5053836889164423

Epoch: 434| Step: 0
Training loss: 0.06443826109170914
Validation loss: 1.529045412617345

Epoch: 6| Step: 1
Training loss: 0.14787015318870544
Validation loss: 1.501055254731127

Epoch: 6| Step: 2
Training loss: 0.16355681419372559
Validation loss: 1.5450965018682583

Epoch: 6| Step: 3
Training loss: 0.13430406153202057
Validation loss: 1.5268246025167487

Epoch: 6| Step: 4
Training loss: 0.1744384616613388
Validation loss: 1.497607893841241

Epoch: 6| Step: 5
Training loss: 0.20101407170295715
Validation loss: 1.4942382843263688

Epoch: 6| Step: 6
Training loss: 0.07720571756362915
Validation loss: 1.5065665834693498

Epoch: 6| Step: 7
Training loss: 0.13979773223400116
Validation loss: 1.484239366746718

Epoch: 6| Step: 8
Training loss: 0.10297251492738724
Validation loss: 1.4987558523813884

Epoch: 6| Step: 9
Training loss: 0.24736317992210388
Validation loss: 1.4892161866670013

Epoch: 6| Step: 10
Training loss: 0.14776059985160828
Validation loss: 1.466917246900579

Epoch: 6| Step: 11
Training loss: 0.07720257341861725
Validation loss: 1.4552719823775753

Epoch: 6| Step: 12
Training loss: 0.0653965100646019
Validation loss: 1.436555326625865

Epoch: 6| Step: 13
Training loss: 0.08605825901031494
Validation loss: 1.4160265230363416

Epoch: 435| Step: 0
Training loss: 0.1205122247338295
Validation loss: 1.4387959562322146

Epoch: 6| Step: 1
Training loss: 0.10474962741136551
Validation loss: 1.4149449948341615

Epoch: 6| Step: 2
Training loss: 0.10419654101133347
Validation loss: 1.4338487617431148

Epoch: 6| Step: 3
Training loss: 0.17471595108509064
Validation loss: 1.4183226528988089

Epoch: 6| Step: 4
Training loss: 0.13672874867916107
Validation loss: 1.461479180602617

Epoch: 6| Step: 5
Training loss: 0.10470986366271973
Validation loss: 1.437840679640411

Epoch: 6| Step: 6
Training loss: 0.06992210447788239
Validation loss: 1.4609788912598805

Epoch: 6| Step: 7
Training loss: 0.11777514219284058
Validation loss: 1.469278089461788

Epoch: 6| Step: 8
Training loss: 0.06785057485103607
Validation loss: 1.4728199282000143

Epoch: 6| Step: 9
Training loss: 0.17352046072483063
Validation loss: 1.488624313826202

Epoch: 6| Step: 10
Training loss: 0.06906650960445404
Validation loss: 1.476917984665081

Epoch: 6| Step: 11
Training loss: 0.07719075679779053
Validation loss: 1.4795096382018058

Epoch: 6| Step: 12
Training loss: 0.13578766584396362
Validation loss: 1.4983600326763686

Epoch: 6| Step: 13
Training loss: 0.24744544923305511
Validation loss: 1.4690291163741902

Epoch: 436| Step: 0
Training loss: 0.20159481465816498
Validation loss: 1.4741875010152017

Epoch: 6| Step: 1
Training loss: 0.061828430742025375
Validation loss: 1.4981468146847141

Epoch: 6| Step: 2
Training loss: 0.12007260322570801
Validation loss: 1.4874430292396135

Epoch: 6| Step: 3
Training loss: 0.16590291261672974
Validation loss: 1.4875268859248008

Epoch: 6| Step: 4
Training loss: 0.08144305646419525
Validation loss: 1.4871796267006987

Epoch: 6| Step: 5
Training loss: 0.06833886355161667
Validation loss: 1.4983588777562624

Epoch: 6| Step: 6
Training loss: 0.10199099034070969
Validation loss: 1.485582395266461

Epoch: 6| Step: 7
Training loss: 0.07964970171451569
Validation loss: 1.4962866819033058

Epoch: 6| Step: 8
Training loss: 0.08428818732500076
Validation loss: 1.5096934123705792

Epoch: 6| Step: 9
Training loss: 0.10754813253879547
Validation loss: 1.5015698094521799

Epoch: 6| Step: 10
Training loss: 0.07549664378166199
Validation loss: 1.4813534341832644

Epoch: 6| Step: 11
Training loss: 0.12343447655439377
Validation loss: 1.4980815328577513

Epoch: 6| Step: 12
Training loss: 0.19521482288837433
Validation loss: 1.491190755239097

Epoch: 6| Step: 13
Training loss: 0.14172904193401337
Validation loss: 1.4740324392113635

Epoch: 437| Step: 0
Training loss: 0.08241100609302521
Validation loss: 1.46989873532326

Epoch: 6| Step: 1
Training loss: 0.13770709931850433
Validation loss: 1.4460845878047328

Epoch: 6| Step: 2
Training loss: 0.15602967143058777
Validation loss: 1.456444045548798

Epoch: 6| Step: 3
Training loss: 0.14493684470653534
Validation loss: 1.4100864600109797

Epoch: 6| Step: 4
Training loss: 0.2174031138420105
Validation loss: 1.4197805722554524

Epoch: 6| Step: 5
Training loss: 0.06836877763271332
Validation loss: 1.4060707502467658

Epoch: 6| Step: 6
Training loss: 0.09481851756572723
Validation loss: 1.4026834259751022

Epoch: 6| Step: 7
Training loss: 0.09165343642234802
Validation loss: 1.3900989819598455

Epoch: 6| Step: 8
Training loss: 0.10401849448680878
Validation loss: 1.3837584180216635

Epoch: 6| Step: 9
Training loss: 0.09994421899318695
Validation loss: 1.36045164703041

Epoch: 6| Step: 10
Training loss: 0.13199104368686676
Validation loss: 1.3704530526232976

Epoch: 6| Step: 11
Training loss: 0.1501697301864624
Validation loss: 1.4174229778269285

Epoch: 6| Step: 12
Training loss: 0.18694448471069336
Validation loss: 1.4058959061099636

Epoch: 6| Step: 13
Training loss: 0.0556163527071476
Validation loss: 1.421889526869661

Epoch: 438| Step: 0
Training loss: 0.10555209219455719
Validation loss: 1.443032419809731

Epoch: 6| Step: 1
Training loss: 0.12954531610012054
Validation loss: 1.4323857048506379

Epoch: 6| Step: 2
Training loss: 0.10524894297122955
Validation loss: 1.4404467382738668

Epoch: 6| Step: 3
Training loss: 0.12459711730480194
Validation loss: 1.4526052756976056

Epoch: 6| Step: 4
Training loss: 0.18991556763648987
Validation loss: 1.4552701519381614

Epoch: 6| Step: 5
Training loss: 0.19601580500602722
Validation loss: 1.4583965680932487

Epoch: 6| Step: 6
Training loss: 0.05918421968817711
Validation loss: 1.4517525831858318

Epoch: 6| Step: 7
Training loss: 0.10126020759344101
Validation loss: 1.4582314862999866

Epoch: 6| Step: 8
Training loss: 0.13829305768013
Validation loss: 1.4545818259639125

Epoch: 6| Step: 9
Training loss: 0.10031035542488098
Validation loss: 1.446806453889416

Epoch: 6| Step: 10
Training loss: 0.10192567855119705
Validation loss: 1.4506918243182603

Epoch: 6| Step: 11
Training loss: 0.10142860561609268
Validation loss: 1.4358690925823745

Epoch: 6| Step: 12
Training loss: 0.12365520000457764
Validation loss: 1.434438709289797

Epoch: 6| Step: 13
Training loss: 0.09114348888397217
Validation loss: 1.4215323136698814

Epoch: 439| Step: 0
Training loss: 0.048113059252500534
Validation loss: 1.4565341882808234

Epoch: 6| Step: 1
Training loss: 0.08071976900100708
Validation loss: 1.4748132664670226

Epoch: 6| Step: 2
Training loss: 0.08268273621797562
Validation loss: 1.4417027132485503

Epoch: 6| Step: 3
Training loss: 0.3094428777694702
Validation loss: 1.4228193695827196

Epoch: 6| Step: 4
Training loss: 0.1265399307012558
Validation loss: 1.4271444082260132

Epoch: 6| Step: 5
Training loss: 0.10203096270561218
Validation loss: 1.4276017296698786

Epoch: 6| Step: 6
Training loss: 0.0826062560081482
Validation loss: 1.4287585801975702

Epoch: 6| Step: 7
Training loss: 0.06863358616828918
Validation loss: 1.4136892313598304

Epoch: 6| Step: 8
Training loss: 0.07622288167476654
Validation loss: 1.4625896856349

Epoch: 6| Step: 9
Training loss: 0.12822780013084412
Validation loss: 1.4190603366462133

Epoch: 6| Step: 10
Training loss: 0.07077498733997345
Validation loss: 1.4246374727577291

Epoch: 6| Step: 11
Training loss: 0.14294058084487915
Validation loss: 1.44018215774208

Epoch: 6| Step: 12
Training loss: 0.2034108191728592
Validation loss: 1.4508351677207536

Epoch: 6| Step: 13
Training loss: 0.10355377197265625
Validation loss: 1.4588977906011766

Epoch: 440| Step: 0
Training loss: 0.12762750685214996
Validation loss: 1.4457493264188048

Epoch: 6| Step: 1
Training loss: 0.18233850598335266
Validation loss: 1.4799873053386647

Epoch: 6| Step: 2
Training loss: 0.07031716406345367
Validation loss: 1.45837027154943

Epoch: 6| Step: 3
Training loss: 0.19274957478046417
Validation loss: 1.4565207419856903

Epoch: 6| Step: 4
Training loss: 0.10546164214611053
Validation loss: 1.4599751849328317

Epoch: 6| Step: 5
Training loss: 0.2261194884777069
Validation loss: 1.4507296969813686

Epoch: 6| Step: 6
Training loss: 0.06673771142959595
Validation loss: 1.455761900512121

Epoch: 6| Step: 7
Training loss: 0.09568528831005096
Validation loss: 1.4661577414440852

Epoch: 6| Step: 8
Training loss: 0.20722098648548126
Validation loss: 1.4240238140988093

Epoch: 6| Step: 9
Training loss: 0.20314526557922363
Validation loss: 1.4262028176297423

Epoch: 6| Step: 10
Training loss: 0.17468813061714172
Validation loss: 1.435564430811072

Epoch: 6| Step: 11
Training loss: 0.2014218121767044
Validation loss: 1.4554082655137586

Epoch: 6| Step: 12
Training loss: 0.12484653294086456
Validation loss: 1.4583835460806405

Epoch: 6| Step: 13
Training loss: 0.10970643907785416
Validation loss: 1.4593015434921428

Epoch: 441| Step: 0
Training loss: 0.10108834505081177
Validation loss: 1.478502954206159

Epoch: 6| Step: 1
Training loss: 0.16607573628425598
Validation loss: 1.4726218472244919

Epoch: 6| Step: 2
Training loss: 0.10670284181833267
Validation loss: 1.5036863050153177

Epoch: 6| Step: 3
Training loss: 0.15859146416187286
Validation loss: 1.4910845871894591

Epoch: 6| Step: 4
Training loss: 0.08601009100675583
Validation loss: 1.5023276062421902

Epoch: 6| Step: 5
Training loss: 0.09225843846797943
Validation loss: 1.468801502258547

Epoch: 6| Step: 6
Training loss: 0.11998973041772842
Validation loss: 1.457338986858245

Epoch: 6| Step: 7
Training loss: 0.2187161147594452
Validation loss: 1.4544893323734243

Epoch: 6| Step: 8
Training loss: 0.09869188815355301
Validation loss: 1.4189578794663953

Epoch: 6| Step: 9
Training loss: 0.18736650049686432
Validation loss: 1.4384592707439134

Epoch: 6| Step: 10
Training loss: 0.2434064894914627
Validation loss: 1.4326688666497507

Epoch: 6| Step: 11
Training loss: 0.11014287918806076
Validation loss: 1.387868571025069

Epoch: 6| Step: 12
Training loss: 0.1709906905889511
Validation loss: 1.4062518586394608

Epoch: 6| Step: 13
Training loss: 0.10803025215864182
Validation loss: 1.3988929717771468

Epoch: 442| Step: 0
Training loss: 0.1267760992050171
Validation loss: 1.4256200078994996

Epoch: 6| Step: 1
Training loss: 0.2052786648273468
Validation loss: 1.419134674533721

Epoch: 6| Step: 2
Training loss: 0.1123165488243103
Validation loss: 1.4144035859774517

Epoch: 6| Step: 3
Training loss: 0.07001382112503052
Validation loss: 1.4213965605663996

Epoch: 6| Step: 4
Training loss: 0.10488443076610565
Validation loss: 1.4738293822093675

Epoch: 6| Step: 5
Training loss: 0.06882956624031067
Validation loss: 1.5008114819885583

Epoch: 6| Step: 6
Training loss: 0.10257752239704132
Validation loss: 1.5039184683112687

Epoch: 6| Step: 7
Training loss: 0.2002168893814087
Validation loss: 1.4624421788800148

Epoch: 6| Step: 8
Training loss: 0.07550249993801117
Validation loss: 1.4380502072713708

Epoch: 6| Step: 9
Training loss: 0.15097680687904358
Validation loss: 1.420175108858334

Epoch: 6| Step: 10
Training loss: 0.04640393704175949
Validation loss: 1.4216411934104016

Epoch: 6| Step: 11
Training loss: 0.0856844037771225
Validation loss: 1.4029193975592171

Epoch: 6| Step: 12
Training loss: 0.11273471266031265
Validation loss: 1.4117872202268211

Epoch: 6| Step: 13
Training loss: 0.17041581869125366
Validation loss: 1.4154813007641864

Epoch: 443| Step: 0
Training loss: 0.13824531435966492
Validation loss: 1.4162446568089146

Epoch: 6| Step: 1
Training loss: 0.10973509401082993
Validation loss: 1.4066136421695832

Epoch: 6| Step: 2
Training loss: 0.11524678766727448
Validation loss: 1.4472658121457664

Epoch: 6| Step: 3
Training loss: 0.1230224221944809
Validation loss: 1.4523309360268295

Epoch: 6| Step: 4
Training loss: 0.12299682199954987
Validation loss: 1.466109627036638

Epoch: 6| Step: 5
Training loss: 0.07822452485561371
Validation loss: 1.4716320076296407

Epoch: 6| Step: 6
Training loss: 0.06753300130367279
Validation loss: 1.4574207426399313

Epoch: 6| Step: 7
Training loss: 0.1313742697238922
Validation loss: 1.4922804819640292

Epoch: 6| Step: 8
Training loss: 0.27910202741622925
Validation loss: 1.4562884133349183

Epoch: 6| Step: 9
Training loss: 0.0885557308793068
Validation loss: 1.4320930947539627

Epoch: 6| Step: 10
Training loss: 0.1550319790840149
Validation loss: 1.4402442914183422

Epoch: 6| Step: 11
Training loss: 0.2332332879304886
Validation loss: 1.4291845162709553

Epoch: 6| Step: 12
Training loss: 0.100046806037426
Validation loss: 1.4238572761576662

Epoch: 6| Step: 13
Training loss: 0.05255063250660896
Validation loss: 1.4305732070758779

Epoch: 444| Step: 0
Training loss: 0.08622244745492935
Validation loss: 1.4466150960614603

Epoch: 6| Step: 1
Training loss: 0.1594596803188324
Validation loss: 1.4437340767152849

Epoch: 6| Step: 2
Training loss: 0.07727574557065964
Validation loss: 1.4387484186439103

Epoch: 6| Step: 3
Training loss: 0.10283481329679489
Validation loss: 1.453571968181159

Epoch: 6| Step: 4
Training loss: 0.06348711997270584
Validation loss: 1.477621223977817

Epoch: 6| Step: 5
Training loss: 0.1640097051858902
Validation loss: 1.4825430993110902

Epoch: 6| Step: 6
Training loss: 0.08139368146657944
Validation loss: 1.4779377842462191

Epoch: 6| Step: 7
Training loss: 0.21130242943763733
Validation loss: 1.4604367543292303

Epoch: 6| Step: 8
Training loss: 0.08945350348949432
Validation loss: 1.4874613323519308

Epoch: 6| Step: 9
Training loss: 0.11488670110702515
Validation loss: 1.4551965382791334

Epoch: 6| Step: 10
Training loss: 0.1411777138710022
Validation loss: 1.4451746671430525

Epoch: 6| Step: 11
Training loss: 0.1859080195426941
Validation loss: 1.451835310587319

Epoch: 6| Step: 12
Training loss: 0.09035605937242508
Validation loss: 1.4804560048605806

Epoch: 6| Step: 13
Training loss: 0.1564105898141861
Validation loss: 1.4668695016573834

Epoch: 445| Step: 0
Training loss: 0.0849466323852539
Validation loss: 1.4265017765824513

Epoch: 6| Step: 1
Training loss: 0.13270485401153564
Validation loss: 1.4064372861257164

Epoch: 6| Step: 2
Training loss: 0.14186428487300873
Validation loss: 1.4219317359309043

Epoch: 6| Step: 3
Training loss: 0.11477397382259369
Validation loss: 1.4038330021724905

Epoch: 6| Step: 4
Training loss: 0.2080494463443756
Validation loss: 1.4078806664354058

Epoch: 6| Step: 5
Training loss: 0.252255380153656
Validation loss: 1.4334236537256548

Epoch: 6| Step: 6
Training loss: 0.10190160572528839
Validation loss: 1.4268159494605115

Epoch: 6| Step: 7
Training loss: 0.08897875249385834
Validation loss: 1.4157095788627543

Epoch: 6| Step: 8
Training loss: 0.13684457540512085
Validation loss: 1.4494737386703491

Epoch: 6| Step: 9
Training loss: 0.0782734677195549
Validation loss: 1.453789593071066

Epoch: 6| Step: 10
Training loss: 0.052548572421073914
Validation loss: 1.4416545232137044

Epoch: 6| Step: 11
Training loss: 0.09104640781879425
Validation loss: 1.4921203838881625

Epoch: 6| Step: 12
Training loss: 0.06896800547838211
Validation loss: 1.4627788868001712

Epoch: 6| Step: 13
Training loss: 0.05156315863132477
Validation loss: 1.4457285199114072

Epoch: 446| Step: 0
Training loss: 0.0796608179807663
Validation loss: 1.4683853817242447

Epoch: 6| Step: 1
Training loss: 0.045795783400535583
Validation loss: 1.449001730129283

Epoch: 6| Step: 2
Training loss: 0.16189563274383545
Validation loss: 1.4614143410036642

Epoch: 6| Step: 3
Training loss: 0.07889649271965027
Validation loss: 1.444943602367114

Epoch: 6| Step: 4
Training loss: 0.07489722967147827
Validation loss: 1.446536797349171

Epoch: 6| Step: 5
Training loss: 0.11127905547618866
Validation loss: 1.4604364556650962

Epoch: 6| Step: 6
Training loss: 0.19759401679039001
Validation loss: 1.442841188881987

Epoch: 6| Step: 7
Training loss: 0.1005304604768753
Validation loss: 1.4554869256993777

Epoch: 6| Step: 8
Training loss: 0.10095323622226715
Validation loss: 1.4678382309534217

Epoch: 6| Step: 9
Training loss: 0.12040767818689346
Validation loss: 1.4562143023296068

Epoch: 6| Step: 10
Training loss: 0.12604202330112457
Validation loss: 1.453248123968801

Epoch: 6| Step: 11
Training loss: 0.19247673451900482
Validation loss: 1.4585471742896623

Epoch: 6| Step: 12
Training loss: 0.10622748732566833
Validation loss: 1.470322992212029

Epoch: 6| Step: 13
Training loss: 0.12451781332492828
Validation loss: 1.4611799973313526

Epoch: 447| Step: 0
Training loss: 0.08216209709644318
Validation loss: 1.4499725757106658

Epoch: 6| Step: 1
Training loss: 0.1769505888223648
Validation loss: 1.4504925102315924

Epoch: 6| Step: 2
Training loss: 0.0721828043460846
Validation loss: 1.4192425640680457

Epoch: 6| Step: 3
Training loss: 0.07140006124973297
Validation loss: 1.4247393665775177

Epoch: 6| Step: 4
Training loss: 0.08423317968845367
Validation loss: 1.4302636320872972

Epoch: 6| Step: 5
Training loss: 0.14084893465042114
Validation loss: 1.3896139270515853

Epoch: 6| Step: 6
Training loss: 0.08485698699951172
Validation loss: 1.4111390882922756

Epoch: 6| Step: 7
Training loss: 0.08581255376338959
Validation loss: 1.388263903638368

Epoch: 6| Step: 8
Training loss: 0.202310711145401
Validation loss: 1.4195282702804894

Epoch: 6| Step: 9
Training loss: 0.07763050496578217
Validation loss: 1.4301232753261444

Epoch: 6| Step: 10
Training loss: 0.12687088549137115
Validation loss: 1.4452873993945379

Epoch: 6| Step: 11
Training loss: 0.08080627024173737
Validation loss: 1.4429609262815086

Epoch: 6| Step: 12
Training loss: 0.13893133401870728
Validation loss: 1.4456775278173468

Epoch: 6| Step: 13
Training loss: 0.111869677901268
Validation loss: 1.4459812346325125

Epoch: 448| Step: 0
Training loss: 0.16501402854919434
Validation loss: 1.42773534277434

Epoch: 6| Step: 1
Training loss: 0.07489504665136337
Validation loss: 1.4428711322046095

Epoch: 6| Step: 2
Training loss: 0.1963488757610321
Validation loss: 1.446491249146

Epoch: 6| Step: 3
Training loss: 0.09550442546606064
Validation loss: 1.449544196487755

Epoch: 6| Step: 4
Training loss: 0.0896308645606041
Validation loss: 1.4576139693619103

Epoch: 6| Step: 5
Training loss: 0.18026326596736908
Validation loss: 1.4405156643159929

Epoch: 6| Step: 6
Training loss: 0.06326242536306381
Validation loss: 1.4368962869849256

Epoch: 6| Step: 7
Training loss: 0.0798976719379425
Validation loss: 1.4142532233268983

Epoch: 6| Step: 8
Training loss: 0.09483940154314041
Validation loss: 1.4689621675399043

Epoch: 6| Step: 9
Training loss: 0.08737128227949142
Validation loss: 1.4221617752505886

Epoch: 6| Step: 10
Training loss: 0.0846894234418869
Validation loss: 1.4498524563286894

Epoch: 6| Step: 11
Training loss: 0.10754989087581635
Validation loss: 1.4346832280517907

Epoch: 6| Step: 12
Training loss: 0.1484040766954422
Validation loss: 1.4341654457071775

Epoch: 6| Step: 13
Training loss: 0.14952246844768524
Validation loss: 1.465109561079292

Epoch: 449| Step: 0
Training loss: 0.09487614035606384
Validation loss: 1.4494153261184692

Epoch: 6| Step: 1
Training loss: 0.17973020672798157
Validation loss: 1.4168870987430695

Epoch: 6| Step: 2
Training loss: 0.10214633494615555
Validation loss: 1.434832008936072

Epoch: 6| Step: 3
Training loss: 0.22337885200977325
Validation loss: 1.4305176414469236

Epoch: 6| Step: 4
Training loss: 0.08255890011787415
Validation loss: 1.4559933075340845

Epoch: 6| Step: 5
Training loss: 0.20219109952449799
Validation loss: 1.4619983543631851

Epoch: 6| Step: 6
Training loss: 0.09136896580457687
Validation loss: 1.4573907339444725

Epoch: 6| Step: 7
Training loss: 0.08529456704854965
Validation loss: 1.477928888413214

Epoch: 6| Step: 8
Training loss: 0.09228917956352234
Validation loss: 1.4883439848499913

Epoch: 6| Step: 9
Training loss: 0.11733447760343552
Validation loss: 1.510458416836236

Epoch: 6| Step: 10
Training loss: 0.15458092093467712
Validation loss: 1.503371327154098

Epoch: 6| Step: 11
Training loss: 0.18179965019226074
Validation loss: 1.4893534670593918

Epoch: 6| Step: 12
Training loss: 0.11723856627941132
Validation loss: 1.49630493246099

Epoch: 6| Step: 13
Training loss: 0.04282217472791672
Validation loss: 1.4699262345349917

Epoch: 450| Step: 0
Training loss: 0.12147916853427887
Validation loss: 1.4541707731062365

Epoch: 6| Step: 1
Training loss: 0.08257564157247543
Validation loss: 1.4621595554454352

Epoch: 6| Step: 2
Training loss: 0.325260728597641
Validation loss: 1.457799203934208

Epoch: 6| Step: 3
Training loss: 0.08199919760227203
Validation loss: 1.4500243958606516

Epoch: 6| Step: 4
Training loss: 0.09101969003677368
Validation loss: 1.4460514155767297

Epoch: 6| Step: 5
Training loss: 0.0751347541809082
Validation loss: 1.4363300197867936

Epoch: 6| Step: 6
Training loss: 0.09581650793552399
Validation loss: 1.467055623249341

Epoch: 6| Step: 7
Training loss: 0.1644866168498993
Validation loss: 1.4557078935766732

Epoch: 6| Step: 8
Training loss: 0.05634152144193649
Validation loss: 1.4570113728123326

Epoch: 6| Step: 9
Training loss: 0.15310515463352203
Validation loss: 1.4675555190732401

Epoch: 6| Step: 10
Training loss: 0.11437451839447021
Validation loss: 1.4362665145627913

Epoch: 6| Step: 11
Training loss: 0.13245166838169098
Validation loss: 1.4640439582127396

Epoch: 6| Step: 12
Training loss: 0.08673108369112015
Validation loss: 1.4587807257970173

Epoch: 6| Step: 13
Training loss: 0.09944799542427063
Validation loss: 1.47638358992915

Epoch: 451| Step: 0
Training loss: 0.13336674869060516
Validation loss: 1.4593034700680805

Epoch: 6| Step: 1
Training loss: 0.0848938524723053
Validation loss: 1.4650561463448308

Epoch: 6| Step: 2
Training loss: 0.07548607140779495
Validation loss: 1.457435134918459

Epoch: 6| Step: 3
Training loss: 0.1512313187122345
Validation loss: 1.47161449668228

Epoch: 6| Step: 4
Training loss: 0.10602351278066635
Validation loss: 1.4836923127533288

Epoch: 6| Step: 5
Training loss: 0.07801920920610428
Validation loss: 1.449241836865743

Epoch: 6| Step: 6
Training loss: 0.09653471410274506
Validation loss: 1.4564773780043407

Epoch: 6| Step: 7
Training loss: 0.14464789628982544
Validation loss: 1.460416277249654

Epoch: 6| Step: 8
Training loss: 0.1827123761177063
Validation loss: 1.4554457100488807

Epoch: 6| Step: 9
Training loss: 0.08868758380413055
Validation loss: 1.4455425918743174

Epoch: 6| Step: 10
Training loss: 0.09391389042139053
Validation loss: 1.4589554673881941

Epoch: 6| Step: 11
Training loss: 0.16855689883232117
Validation loss: 1.4475034090780443

Epoch: 6| Step: 12
Training loss: 0.19385944306850433
Validation loss: 1.4514689240404355

Epoch: 6| Step: 13
Training loss: 0.08038454502820969
Validation loss: 1.4537733908622497

Epoch: 452| Step: 0
Training loss: 0.09224730730056763
Validation loss: 1.4614335298538208

Epoch: 6| Step: 1
Training loss: 0.0807425007224083
Validation loss: 1.463326217025839

Epoch: 6| Step: 2
Training loss: 0.10738620162010193
Validation loss: 1.4625878641682286

Epoch: 6| Step: 3
Training loss: 0.0808255672454834
Validation loss: 1.4655400501784457

Epoch: 6| Step: 4
Training loss: 0.15329761803150177
Validation loss: 1.4842322116257043

Epoch: 6| Step: 5
Training loss: 0.14177951216697693
Validation loss: 1.4888880522020402

Epoch: 6| Step: 6
Training loss: 0.18237951397895813
Validation loss: 1.489073392524514

Epoch: 6| Step: 7
Training loss: 0.12843744456768036
Validation loss: 1.4987180732911634

Epoch: 6| Step: 8
Training loss: 0.052499398589134216
Validation loss: 1.49340473451922

Epoch: 6| Step: 9
Training loss: 0.07379895448684692
Validation loss: 1.4863670756739955

Epoch: 6| Step: 10
Training loss: 0.09681689739227295
Validation loss: 1.5060715342080722

Epoch: 6| Step: 11
Training loss: 0.2013525813817978
Validation loss: 1.5009181473844795

Epoch: 6| Step: 12
Training loss: 0.10439261794090271
Validation loss: 1.4836788241581251

Epoch: 6| Step: 13
Training loss: 0.09248023480176926
Validation loss: 1.4842315014972483

Epoch: 453| Step: 0
Training loss: 0.08759135752916336
Validation loss: 1.464295353299828

Epoch: 6| Step: 1
Training loss: 0.054566774517297745
Validation loss: 1.4648897750403291

Epoch: 6| Step: 2
Training loss: 0.09154458343982697
Validation loss: 1.4603763331649124

Epoch: 6| Step: 3
Training loss: 0.17807891964912415
Validation loss: 1.4614866728423743

Epoch: 6| Step: 4
Training loss: 0.1305554211139679
Validation loss: 1.4681649913070023

Epoch: 6| Step: 5
Training loss: 0.24806776642799377
Validation loss: 1.4380975025956348

Epoch: 6| Step: 6
Training loss: 0.10791444033384323
Validation loss: 1.4279255585003925

Epoch: 6| Step: 7
Training loss: 0.0880662053823471
Validation loss: 1.4532542151789511

Epoch: 6| Step: 8
Training loss: 0.140554279088974
Validation loss: 1.45423464621267

Epoch: 6| Step: 9
Training loss: 0.14287561178207397
Validation loss: 1.4359229021174933

Epoch: 6| Step: 10
Training loss: 0.09441995620727539
Validation loss: 1.4171454598826747

Epoch: 6| Step: 11
Training loss: 0.11354947090148926
Validation loss: 1.405408206806388

Epoch: 6| Step: 12
Training loss: 0.11636388301849365
Validation loss: 1.3939573277709305

Epoch: 6| Step: 13
Training loss: 0.12752792239189148
Validation loss: 1.3820368807802919

Epoch: 454| Step: 0
Training loss: 0.11582960188388824
Validation loss: 1.4079835581523117

Epoch: 6| Step: 1
Training loss: 0.07897865027189255
Validation loss: 1.4198549812839878

Epoch: 6| Step: 2
Training loss: 0.2395854890346527
Validation loss: 1.419827417660785

Epoch: 6| Step: 3
Training loss: 0.10557672381401062
Validation loss: 1.4216905261880608

Epoch: 6| Step: 4
Training loss: 0.08408951759338379
Validation loss: 1.42998121887125

Epoch: 6| Step: 5
Training loss: 0.11323869973421097
Validation loss: 1.42765474319458

Epoch: 6| Step: 6
Training loss: 0.07490526139736176
Validation loss: 1.459911370790133

Epoch: 6| Step: 7
Training loss: 0.1709057092666626
Validation loss: 1.438289160369545

Epoch: 6| Step: 8
Training loss: 0.11147422343492508
Validation loss: 1.4878784507833502

Epoch: 6| Step: 9
Training loss: 0.09228399395942688
Validation loss: 1.4607802719198248

Epoch: 6| Step: 10
Training loss: 0.16724538803100586
Validation loss: 1.4938548277783137

Epoch: 6| Step: 11
Training loss: 0.09588378667831421
Validation loss: 1.49652039107456

Epoch: 6| Step: 12
Training loss: 0.08840497583150864
Validation loss: 1.5082093848977038

Epoch: 6| Step: 13
Training loss: 0.06991651654243469
Validation loss: 1.5146387994930308

Epoch: 455| Step: 0
Training loss: 0.1626206636428833
Validation loss: 1.4991127521761003

Epoch: 6| Step: 1
Training loss: 0.09275390952825546
Validation loss: 1.5380755650099887

Epoch: 6| Step: 2
Training loss: 0.11922911554574966
Validation loss: 1.5239062578447404

Epoch: 6| Step: 3
Training loss: 0.10055959224700928
Validation loss: 1.5083979637392106

Epoch: 6| Step: 4
Training loss: 0.13797971606254578
Validation loss: 1.4998929154488347

Epoch: 6| Step: 5
Training loss: 0.08571512997150421
Validation loss: 1.4984105671605756

Epoch: 6| Step: 6
Training loss: 0.15434980392456055
Validation loss: 1.4868265813396824

Epoch: 6| Step: 7
Training loss: 0.08937636017799377
Validation loss: 1.4792933842187286

Epoch: 6| Step: 8
Training loss: 0.08402153104543686
Validation loss: 1.447572442793077

Epoch: 6| Step: 9
Training loss: 0.13605546951293945
Validation loss: 1.4167252035551174

Epoch: 6| Step: 10
Training loss: 0.11182059347629547
Validation loss: 1.4166238320771085

Epoch: 6| Step: 11
Training loss: 0.1743733137845993
Validation loss: 1.432435514465455

Epoch: 6| Step: 12
Training loss: 0.20421302318572998
Validation loss: 1.3990567525227864

Epoch: 6| Step: 13
Training loss: 0.17468637228012085
Validation loss: 1.4278360810331119

Epoch: 456| Step: 0
Training loss: 0.08796514570713043
Validation loss: 1.413777502634192

Epoch: 6| Step: 1
Training loss: 0.08499325811862946
Validation loss: 1.3972383852927917

Epoch: 6| Step: 2
Training loss: 0.10201550275087357
Validation loss: 1.4116570962372648

Epoch: 6| Step: 3
Training loss: 0.08734872937202454
Validation loss: 1.4106987740403862

Epoch: 6| Step: 4
Training loss: 0.1062752902507782
Validation loss: 1.4028804282988272

Epoch: 6| Step: 5
Training loss: 0.10127697885036469
Validation loss: 1.4113634235115462

Epoch: 6| Step: 6
Training loss: 0.16977539658546448
Validation loss: 1.4145400460048387

Epoch: 6| Step: 7
Training loss: 0.07768835127353668
Validation loss: 1.4111393767018472

Epoch: 6| Step: 8
Training loss: 0.1485932171344757
Validation loss: 1.4145455110457636

Epoch: 6| Step: 9
Training loss: 0.20835477113723755
Validation loss: 1.4373077461796422

Epoch: 6| Step: 10
Training loss: 0.08644814789295197
Validation loss: 1.4346445254100266

Epoch: 6| Step: 11
Training loss: 0.07587359845638275
Validation loss: 1.4616922492622046

Epoch: 6| Step: 12
Training loss: 0.11019660532474518
Validation loss: 1.4464486465659192

Epoch: 6| Step: 13
Training loss: 0.0860094353556633
Validation loss: 1.4585489021834506

Epoch: 457| Step: 0
Training loss: 0.08015735447406769
Validation loss: 1.4726378456238778

Epoch: 6| Step: 1
Training loss: 0.08889101445674896
Validation loss: 1.45758484255883

Epoch: 6| Step: 2
Training loss: 0.13513173162937164
Validation loss: 1.4637185629977976

Epoch: 6| Step: 3
Training loss: 0.12373007088899612
Validation loss: 1.4054769719800642

Epoch: 6| Step: 4
Training loss: 0.15733599662780762
Validation loss: 1.4534565723070534

Epoch: 6| Step: 5
Training loss: 0.14941850304603577
Validation loss: 1.4319789871092765

Epoch: 6| Step: 6
Training loss: 0.06610437482595444
Validation loss: 1.4479761533839728

Epoch: 6| Step: 7
Training loss: 0.11076314747333527
Validation loss: 1.421324650446574

Epoch: 6| Step: 8
Training loss: 0.19596649706363678
Validation loss: 1.4363952823864516

Epoch: 6| Step: 9
Training loss: 0.097286656498909
Validation loss: 1.4485694195634575

Epoch: 6| Step: 10
Training loss: 0.08299097418785095
Validation loss: 1.4485508216324674

Epoch: 6| Step: 11
Training loss: 0.08633360266685486
Validation loss: 1.4435253579129455

Epoch: 6| Step: 12
Training loss: 0.061428703367710114
Validation loss: 1.4435984639711277

Epoch: 6| Step: 13
Training loss: 0.1314961314201355
Validation loss: 1.4462726705817766

Epoch: 458| Step: 0
Training loss: 0.0524551197886467
Validation loss: 1.4446726742611136

Epoch: 6| Step: 1
Training loss: 0.08270810544490814
Validation loss: 1.4698200379648516

Epoch: 6| Step: 2
Training loss: 0.10166475176811218
Validation loss: 1.4694985561473395

Epoch: 6| Step: 3
Training loss: 0.08813723921775818
Validation loss: 1.4818810429624332

Epoch: 6| Step: 4
Training loss: 0.16918785870075226
Validation loss: 1.4586791569186794

Epoch: 6| Step: 5
Training loss: 0.10773128271102905
Validation loss: 1.4849556684494019

Epoch: 6| Step: 6
Training loss: 0.11320823431015015
Validation loss: 1.4701121340515793

Epoch: 6| Step: 7
Training loss: 0.14615324139595032
Validation loss: 1.480634230439381

Epoch: 6| Step: 8
Training loss: 0.1022663563489914
Validation loss: 1.4616540349939817

Epoch: 6| Step: 9
Training loss: 0.17279095947742462
Validation loss: 1.4474782546361287

Epoch: 6| Step: 10
Training loss: 0.06956849992275238
Validation loss: 1.464569426351978

Epoch: 6| Step: 11
Training loss: 0.054551925510168076
Validation loss: 1.4253703637789654

Epoch: 6| Step: 12
Training loss: 0.08355161547660828
Validation loss: 1.4366980098908948

Epoch: 6| Step: 13
Training loss: 0.10297193378210068
Validation loss: 1.4158806198386735

Epoch: 459| Step: 0
Training loss: 0.08750562369823456
Validation loss: 1.4369998337120138

Epoch: 6| Step: 1
Training loss: 0.08248718082904816
Validation loss: 1.4293764919363043

Epoch: 6| Step: 2
Training loss: 0.05917339399456978
Validation loss: 1.4367246198397812

Epoch: 6| Step: 3
Training loss: 0.16406428813934326
Validation loss: 1.446804299790372

Epoch: 6| Step: 4
Training loss: 0.18170413374900818
Validation loss: 1.45920935369307

Epoch: 6| Step: 5
Training loss: 0.05930668115615845
Validation loss: 1.467453892512988

Epoch: 6| Step: 6
Training loss: 0.08620648831129074
Validation loss: 1.469259185175742

Epoch: 6| Step: 7
Training loss: 0.17642371356487274
Validation loss: 1.4462541610963884

Epoch: 6| Step: 8
Training loss: 0.07292816787958145
Validation loss: 1.479564203370002

Epoch: 6| Step: 9
Training loss: 0.04802573099732399
Validation loss: 1.468054380468143

Epoch: 6| Step: 10
Training loss: 0.1247936263680458
Validation loss: 1.461967772053134

Epoch: 6| Step: 11
Training loss: 0.0851164162158966
Validation loss: 1.4649900191573686

Epoch: 6| Step: 12
Training loss: 0.06837353110313416
Validation loss: 1.4625372066292712

Epoch: 6| Step: 13
Training loss: 0.14779633283615112
Validation loss: 1.4715128803765902

Epoch: 460| Step: 0
Training loss: 0.11576040834188461
Validation loss: 1.4883345083523822

Epoch: 6| Step: 1
Training loss: 0.0772646963596344
Validation loss: 1.5161435950186946

Epoch: 6| Step: 2
Training loss: 0.20178042352199554
Validation loss: 1.499668986566605

Epoch: 6| Step: 3
Training loss: 0.14834459125995636
Validation loss: 1.501321920784571

Epoch: 6| Step: 4
Training loss: 0.10458499938249588
Validation loss: 1.4971867171666955

Epoch: 6| Step: 5
Training loss: 0.1223975270986557
Validation loss: 1.468570206754951

Epoch: 6| Step: 6
Training loss: 0.05880278721451759
Validation loss: 1.468322387305639

Epoch: 6| Step: 7
Training loss: 0.11187826842069626
Validation loss: 1.4677222762056576

Epoch: 6| Step: 8
Training loss: 0.08279775828123093
Validation loss: 1.465643927615176

Epoch: 6| Step: 9
Training loss: 0.07283549755811691
Validation loss: 1.4482910453632314

Epoch: 6| Step: 10
Training loss: 0.12934929132461548
Validation loss: 1.4531044319111814

Epoch: 6| Step: 11
Training loss: 0.10017593204975128
Validation loss: 1.428470826918079

Epoch: 6| Step: 12
Training loss: 0.22004325687885284
Validation loss: 1.4285051976480792

Epoch: 6| Step: 13
Training loss: 0.06547366827726364
Validation loss: 1.4258686413047135

Epoch: 461| Step: 0
Training loss: 0.11842793971300125
Validation loss: 1.4376033224085325

Epoch: 6| Step: 1
Training loss: 0.0659734308719635
Validation loss: 1.4384984239455192

Epoch: 6| Step: 2
Training loss: 0.06052654981613159
Validation loss: 1.4528269588306386

Epoch: 6| Step: 3
Training loss: 0.1716121882200241
Validation loss: 1.4507594070126932

Epoch: 6| Step: 4
Training loss: 0.20982211828231812
Validation loss: 1.4594371511090187

Epoch: 6| Step: 5
Training loss: 0.12351268529891968
Validation loss: 1.4831029830440399

Epoch: 6| Step: 6
Training loss: 0.08264270424842834
Validation loss: 1.4795540571212769

Epoch: 6| Step: 7
Training loss: 0.10761532187461853
Validation loss: 1.4467640730642504

Epoch: 6| Step: 8
Training loss: 0.07874538004398346
Validation loss: 1.427031829792966

Epoch: 6| Step: 9
Training loss: 0.10402907431125641
Validation loss: 1.4308922277983798

Epoch: 6| Step: 10
Training loss: 0.13406717777252197
Validation loss: 1.4276940489328036

Epoch: 6| Step: 11
Training loss: 0.132966548204422
Validation loss: 1.4458313885555472

Epoch: 6| Step: 12
Training loss: 0.16545239090919495
Validation loss: 1.4409657985933366

Epoch: 6| Step: 13
Training loss: 0.07274823635816574
Validation loss: 1.4160072854770127

Epoch: 462| Step: 0
Training loss: 0.11317715793848038
Validation loss: 1.4346539474302722

Epoch: 6| Step: 1
Training loss: 0.09785589575767517
Validation loss: 1.4334767326231925

Epoch: 6| Step: 2
Training loss: 0.09779070317745209
Validation loss: 1.4542124066301572

Epoch: 6| Step: 3
Training loss: 0.23200838267803192
Validation loss: 1.4598412847006192

Epoch: 6| Step: 4
Training loss: 0.11052393168210983
Validation loss: 1.4522604378320838

Epoch: 6| Step: 5
Training loss: 0.1544070839881897
Validation loss: 1.4417559651918308

Epoch: 6| Step: 6
Training loss: 0.05484159290790558
Validation loss: 1.4821933866829

Epoch: 6| Step: 7
Training loss: 0.08118298649787903
Validation loss: 1.4209060322853826

Epoch: 6| Step: 8
Training loss: 0.07970055192708969
Validation loss: 1.4460299707228137

Epoch: 6| Step: 9
Training loss: 0.178787499666214
Validation loss: 1.4418785379778953

Epoch: 6| Step: 10
Training loss: 0.05064082890748978
Validation loss: 1.4219231349165722

Epoch: 6| Step: 11
Training loss: 0.07962802797555923
Validation loss: 1.4317689223956036

Epoch: 6| Step: 12
Training loss: 0.07897409796714783
Validation loss: 1.4493714711999381

Epoch: 6| Step: 13
Training loss: 0.07484527677297592
Validation loss: 1.4468323094870454

Epoch: 463| Step: 0
Training loss: 0.15109622478485107
Validation loss: 1.4528751116926952

Epoch: 6| Step: 1
Training loss: 0.05800279602408409
Validation loss: 1.426472633115707

Epoch: 6| Step: 2
Training loss: 0.13594359159469604
Validation loss: 1.4644628494016585

Epoch: 6| Step: 3
Training loss: 0.13506698608398438
Validation loss: 1.44657987676641

Epoch: 6| Step: 4
Training loss: 0.07452113181352615
Validation loss: 1.4603456822774743

Epoch: 6| Step: 5
Training loss: 0.057892512530088425
Validation loss: 1.4593082128032562

Epoch: 6| Step: 6
Training loss: 0.10939579457044601
Validation loss: 1.4552420275185698

Epoch: 6| Step: 7
Training loss: 0.08293746411800385
Validation loss: 1.4532113049619941

Epoch: 6| Step: 8
Training loss: 0.06343277543783188
Validation loss: 1.4585282700036162

Epoch: 6| Step: 9
Training loss: 0.057209860533475876
Validation loss: 1.4278519980369075

Epoch: 6| Step: 10
Training loss: 0.13123629987239838
Validation loss: 1.418613346674109

Epoch: 6| Step: 11
Training loss: 0.1379866898059845
Validation loss: 1.428247522282344

Epoch: 6| Step: 12
Training loss: 0.07136371731758118
Validation loss: 1.4187024357498332

Epoch: 6| Step: 13
Training loss: 0.2750432789325714
Validation loss: 1.4183222324617448

Epoch: 464| Step: 0
Training loss: 0.11835935711860657
Validation loss: 1.46370985943784

Epoch: 6| Step: 1
Training loss: 0.13741746544837952
Validation loss: 1.4617578265487507

Epoch: 6| Step: 2
Training loss: 0.07588134706020355
Validation loss: 1.4469339757837274

Epoch: 6| Step: 3
Training loss: 0.07375667244195938
Validation loss: 1.4773795450887373

Epoch: 6| Step: 4
Training loss: 0.09131640195846558
Validation loss: 1.487827108752343

Epoch: 6| Step: 5
Training loss: 0.07699023187160492
Validation loss: 1.4794402019951933

Epoch: 6| Step: 6
Training loss: 0.10680785775184631
Validation loss: 1.5115465733312792

Epoch: 6| Step: 7
Training loss: 0.08441981673240662
Validation loss: 1.4815168303828086

Epoch: 6| Step: 8
Training loss: 0.06226319074630737
Validation loss: 1.4903554339562692

Epoch: 6| Step: 9
Training loss: 0.190557599067688
Validation loss: 1.4821327770909956

Epoch: 6| Step: 10
Training loss: 0.1355101764202118
Validation loss: 1.4602500559181295

Epoch: 6| Step: 11
Training loss: 0.16165781021118164
Validation loss: 1.4652724971053421

Epoch: 6| Step: 12
Training loss: 0.09176911413669586
Validation loss: 1.4700675087590371

Epoch: 6| Step: 13
Training loss: 0.09943816065788269
Validation loss: 1.46513460528466

Epoch: 465| Step: 0
Training loss: 0.054074112325906754
Validation loss: 1.439865663487424

Epoch: 6| Step: 1
Training loss: 0.06115321069955826
Validation loss: 1.4547875132612003

Epoch: 6| Step: 2
Training loss: 0.1764567494392395
Validation loss: 1.4316254059473674

Epoch: 6| Step: 3
Training loss: 0.06299687176942825
Validation loss: 1.4226748007600025

Epoch: 6| Step: 4
Training loss: 0.07458926737308502
Validation loss: 1.4315697839183192

Epoch: 6| Step: 5
Training loss: 0.09473763406276703
Validation loss: 1.4276502683598509

Epoch: 6| Step: 6
Training loss: 0.10787546634674072
Validation loss: 1.4302369445882819

Epoch: 6| Step: 7
Training loss: 0.05293099582195282
Validation loss: 1.4497788542060441

Epoch: 6| Step: 8
Training loss: 0.06493081152439117
Validation loss: 1.4462193801838865

Epoch: 6| Step: 9
Training loss: 0.17845779657363892
Validation loss: 1.4307248182194208

Epoch: 6| Step: 10
Training loss: 0.08308123052120209
Validation loss: 1.473585299266282

Epoch: 6| Step: 11
Training loss: 0.13897712528705597
Validation loss: 1.4622926224944413

Epoch: 6| Step: 12
Training loss: 0.10264354944229126
Validation loss: 1.4360520660236318

Epoch: 6| Step: 13
Training loss: 0.09150001406669617
Validation loss: 1.45838285774313

Epoch: 466| Step: 0
Training loss: 0.03768431395292282
Validation loss: 1.4566433782218604

Epoch: 6| Step: 1
Training loss: 0.08728717267513275
Validation loss: 1.4434529196831487

Epoch: 6| Step: 2
Training loss: 0.22677363455295563
Validation loss: 1.428799181856135

Epoch: 6| Step: 3
Training loss: 0.10674193501472473
Validation loss: 1.4525642433474142

Epoch: 6| Step: 4
Training loss: 0.0764327198266983
Validation loss: 1.4346543204399846

Epoch: 6| Step: 5
Training loss: 0.12042487412691116
Validation loss: 1.4726984270157353

Epoch: 6| Step: 6
Training loss: 0.07235930114984512
Validation loss: 1.480986109343908

Epoch: 6| Step: 7
Training loss: 0.11497804522514343
Validation loss: 1.471547866380343

Epoch: 6| Step: 8
Training loss: 0.14624139666557312
Validation loss: 1.5018305560593963

Epoch: 6| Step: 9
Training loss: 0.08614414930343628
Validation loss: 1.5000917514165242

Epoch: 6| Step: 10
Training loss: 0.09542068839073181
Validation loss: 1.502390787165652

Epoch: 6| Step: 11
Training loss: 0.06638529151678085
Validation loss: 1.4813398635515602

Epoch: 6| Step: 12
Training loss: 0.2138707935810089
Validation loss: 1.4972885013908468

Epoch: 6| Step: 13
Training loss: 0.0896834284067154
Validation loss: 1.4687227356818415

Epoch: 467| Step: 0
Training loss: 0.07801737636327744
Validation loss: 1.4468255876212992

Epoch: 6| Step: 1
Training loss: 0.06648706644773483
Validation loss: 1.452591976811809

Epoch: 6| Step: 2
Training loss: 0.0982702374458313
Validation loss: 1.4549304605812154

Epoch: 6| Step: 3
Training loss: 0.11823069304227829
Validation loss: 1.45692188765413

Epoch: 6| Step: 4
Training loss: 0.11204010248184204
Validation loss: 1.4347902036482287

Epoch: 6| Step: 5
Training loss: 0.07578384876251221
Validation loss: 1.4528651666897598

Epoch: 6| Step: 6
Training loss: 0.10900990664958954
Validation loss: 1.450003985435732

Epoch: 6| Step: 7
Training loss: 0.06527578830718994
Validation loss: 1.4545805390163133

Epoch: 6| Step: 8
Training loss: 0.10117389261722565
Validation loss: 1.4601694332656039

Epoch: 6| Step: 9
Training loss: 0.15531998872756958
Validation loss: 1.4364672232699651

Epoch: 6| Step: 10
Training loss: 0.1092982217669487
Validation loss: 1.4279737523806992

Epoch: 6| Step: 11
Training loss: 0.07852493226528168
Validation loss: 1.4189820481884865

Epoch: 6| Step: 12
Training loss: 0.2077597677707672
Validation loss: 1.427771472161816

Epoch: 6| Step: 13
Training loss: 0.10562287271022797
Validation loss: 1.41064545928791

Epoch: 468| Step: 0
Training loss: 0.09018769860267639
Validation loss: 1.4162492675165976

Epoch: 6| Step: 1
Training loss: 0.16272972524166107
Validation loss: 1.4168709529343473

Epoch: 6| Step: 2
Training loss: 0.10313740372657776
Validation loss: 1.4266721074299147

Epoch: 6| Step: 3
Training loss: 0.05044154077768326
Validation loss: 1.4225885944981729

Epoch: 6| Step: 4
Training loss: 0.0855524092912674
Validation loss: 1.4222831136436873

Epoch: 6| Step: 5
Training loss: 0.12323081493377686
Validation loss: 1.455224173043364

Epoch: 6| Step: 6
Training loss: 0.07166028022766113
Validation loss: 1.4511223352083595

Epoch: 6| Step: 7
Training loss: 0.10437488555908203
Validation loss: 1.47062333168522

Epoch: 6| Step: 8
Training loss: 0.0954940915107727
Validation loss: 1.47860917481043

Epoch: 6| Step: 9
Training loss: 0.1629943549633026
Validation loss: 1.4513646325757426

Epoch: 6| Step: 10
Training loss: 0.05923551321029663
Validation loss: 1.4432000402481324

Epoch: 6| Step: 11
Training loss: 0.1806502640247345
Validation loss: 1.4530070661216654

Epoch: 6| Step: 12
Training loss: 0.09515334665775299
Validation loss: 1.4500254020896008

Epoch: 6| Step: 13
Training loss: 0.11647387593984604
Validation loss: 1.4194665878049788

Epoch: 469| Step: 0
Training loss: 0.0804796814918518
Validation loss: 1.431102551439757

Epoch: 6| Step: 1
Training loss: 0.11034797132015228
Validation loss: 1.460619341942572

Epoch: 6| Step: 2
Training loss: 0.19961021840572357
Validation loss: 1.4197164594486196

Epoch: 6| Step: 3
Training loss: 0.11077357828617096
Validation loss: 1.4276114907315982

Epoch: 6| Step: 4
Training loss: 0.06990700960159302
Validation loss: 1.4608021872017973

Epoch: 6| Step: 5
Training loss: 0.08460269868373871
Validation loss: 1.445499611157243

Epoch: 6| Step: 6
Training loss: 0.1349373608827591
Validation loss: 1.4639224102420192

Epoch: 6| Step: 7
Training loss: 0.08261457085609436
Validation loss: 1.4643021040065314

Epoch: 6| Step: 8
Training loss: 0.14010915160179138
Validation loss: 1.5107128145874187

Epoch: 6| Step: 9
Training loss: 0.10737532377243042
Validation loss: 1.4738720296531596

Epoch: 6| Step: 10
Training loss: 0.08245382457971573
Validation loss: 1.477124753818717

Epoch: 6| Step: 11
Training loss: 0.1571975201368332
Validation loss: 1.4384880860646565

Epoch: 6| Step: 12
Training loss: 0.07118210196495056
Validation loss: 1.4213088686748216

Epoch: 6| Step: 13
Training loss: 0.19286459684371948
Validation loss: 1.4215868814017183

Epoch: 470| Step: 0
Training loss: 0.0705638974905014
Validation loss: 1.4099610005655596

Epoch: 6| Step: 1
Training loss: 0.051707684993743896
Validation loss: 1.4243193787913169

Epoch: 6| Step: 2
Training loss: 0.06332805752754211
Validation loss: 1.4148450833494945

Epoch: 6| Step: 3
Training loss: 0.16256728768348694
Validation loss: 1.4213831629804385

Epoch: 6| Step: 4
Training loss: 0.0760633796453476
Validation loss: 1.4325352971271803

Epoch: 6| Step: 5
Training loss: 0.07143533229827881
Validation loss: 1.456154634875636

Epoch: 6| Step: 6
Training loss: 0.0737638771533966
Validation loss: 1.4520226165812502

Epoch: 6| Step: 7
Training loss: 0.07153952121734619
Validation loss: 1.4697075684865315

Epoch: 6| Step: 8
Training loss: 0.06815479695796967
Validation loss: 1.4638871377514255

Epoch: 6| Step: 9
Training loss: 0.11731145530939102
Validation loss: 1.4548153236348143

Epoch: 6| Step: 10
Training loss: 0.05372451990842819
Validation loss: 1.4741557708350561

Epoch: 6| Step: 11
Training loss: 0.22151237726211548
Validation loss: 1.4629349734193535

Epoch: 6| Step: 12
Training loss: 0.12462035566568375
Validation loss: 1.460187860714492

Epoch: 6| Step: 13
Training loss: 0.11229673027992249
Validation loss: 1.4489369700031896

Epoch: 471| Step: 0
Training loss: 0.08789429068565369
Validation loss: 1.4497565454052341

Epoch: 6| Step: 1
Training loss: 0.09921829402446747
Validation loss: 1.4342133242596862

Epoch: 6| Step: 2
Training loss: 0.1519220471382141
Validation loss: 1.4439761805278

Epoch: 6| Step: 3
Training loss: 0.18921561539173126
Validation loss: 1.4516286734611756

Epoch: 6| Step: 4
Training loss: 0.09980122745037079
Validation loss: 1.3909902098358318

Epoch: 6| Step: 5
Training loss: 0.11980611085891724
Validation loss: 1.3888811949760682

Epoch: 6| Step: 6
Training loss: 0.1150730773806572
Validation loss: 1.3793659082023046

Epoch: 6| Step: 7
Training loss: 0.10099766403436661
Validation loss: 1.378350213009824

Epoch: 6| Step: 8
Training loss: 0.08836725354194641
Validation loss: 1.389857812594342

Epoch: 6| Step: 9
Training loss: 0.11815549433231354
Validation loss: 1.3724284710422638

Epoch: 6| Step: 10
Training loss: 0.10670696198940277
Validation loss: 1.3864832212848048

Epoch: 6| Step: 11
Training loss: 0.17825904488563538
Validation loss: 1.393747861667346

Epoch: 6| Step: 12
Training loss: 0.06658181548118591
Validation loss: 1.4101330798159364

Epoch: 6| Step: 13
Training loss: 0.08870901167392731
Validation loss: 1.4082031557636876

Epoch: 472| Step: 0
Training loss: 0.08124510943889618
Validation loss: 1.4384297529856365

Epoch: 6| Step: 1
Training loss: 0.06851623952388763
Validation loss: 1.4438861364959388

Epoch: 6| Step: 2
Training loss: 0.1017068475484848
Validation loss: 1.4583623986090384

Epoch: 6| Step: 3
Training loss: 0.1706627458333969
Validation loss: 1.4937867195375505

Epoch: 6| Step: 4
Training loss: 0.0585949644446373
Validation loss: 1.4655661204809785

Epoch: 6| Step: 5
Training loss: 0.10974621772766113
Validation loss: 1.4846800540083198

Epoch: 6| Step: 6
Training loss: 0.08033021539449692
Validation loss: 1.4807769752317859

Epoch: 6| Step: 7
Training loss: 0.06495930254459381
Validation loss: 1.4962225498691681

Epoch: 6| Step: 8
Training loss: 0.07619680464267731
Validation loss: 1.4938667025617374

Epoch: 6| Step: 9
Training loss: 0.09185972064733505
Validation loss: 1.4801500176870694

Epoch: 6| Step: 10
Training loss: 0.0841614156961441
Validation loss: 1.4929256900664298

Epoch: 6| Step: 11
Training loss: 0.141818106174469
Validation loss: 1.4740389111221477

Epoch: 6| Step: 12
Training loss: 0.22191625833511353
Validation loss: 1.4582462144154373

Epoch: 6| Step: 13
Training loss: 0.12480076402425766
Validation loss: 1.4504368253933486

Epoch: 473| Step: 0
Training loss: 0.07445888221263885
Validation loss: 1.4371325046785417

Epoch: 6| Step: 1
Training loss: 0.06848013401031494
Validation loss: 1.4145688190255115

Epoch: 6| Step: 2
Training loss: 0.087500661611557
Validation loss: 1.424114877177823

Epoch: 6| Step: 3
Training loss: 0.11328141391277313
Validation loss: 1.4100699270925214

Epoch: 6| Step: 4
Training loss: 0.14246979355812073
Validation loss: 1.414948849267857

Epoch: 6| Step: 5
Training loss: 0.1243559792637825
Validation loss: 1.438720682615875

Epoch: 6| Step: 6
Training loss: 0.07667525112628937
Validation loss: 1.4174525519852996

Epoch: 6| Step: 7
Training loss: 0.07303370535373688
Validation loss: 1.403432664691761

Epoch: 6| Step: 8
Training loss: 0.07848067581653595
Validation loss: 1.4095426080047444

Epoch: 6| Step: 9
Training loss: 0.15288659930229187
Validation loss: 1.3916666520539152

Epoch: 6| Step: 10
Training loss: 0.15239658951759338
Validation loss: 1.4131671690171765

Epoch: 6| Step: 11
Training loss: 0.10242754220962524
Validation loss: 1.4031054230146511

Epoch: 6| Step: 12
Training loss: 0.11239250004291534
Validation loss: 1.4092085669117589

Epoch: 6| Step: 13
Training loss: 0.17139479517936707
Validation loss: 1.3880390608182518

Epoch: 474| Step: 0
Training loss: 0.08788327872753143
Validation loss: 1.4174547451798634

Epoch: 6| Step: 1
Training loss: 0.09618327021598816
Validation loss: 1.4296480058341898

Epoch: 6| Step: 2
Training loss: 0.10817898064851761
Validation loss: 1.4277423774042437

Epoch: 6| Step: 3
Training loss: 0.09427600353956223
Validation loss: 1.4384309104693833

Epoch: 6| Step: 4
Training loss: 0.13379095494747162
Validation loss: 1.4438544370794808

Epoch: 6| Step: 5
Training loss: 0.07736460864543915
Validation loss: 1.4386429581590878

Epoch: 6| Step: 6
Training loss: 0.1063423827290535
Validation loss: 1.441576401392619

Epoch: 6| Step: 7
Training loss: 0.09588373452425003
Validation loss: 1.4488032812713294

Epoch: 6| Step: 8
Training loss: 0.18049924075603485
Validation loss: 1.4519611879061627

Epoch: 6| Step: 9
Training loss: 0.11422360688447952
Validation loss: 1.4518080924146919

Epoch: 6| Step: 10
Training loss: 0.1414240151643753
Validation loss: 1.4555344171421503

Epoch: 6| Step: 11
Training loss: 0.06466038525104523
Validation loss: 1.4585451733681463

Epoch: 6| Step: 12
Training loss: 0.08008001744747162
Validation loss: 1.4363127331579886

Epoch: 6| Step: 13
Training loss: 0.13825853168964386
Validation loss: 1.4383462936647478

Epoch: 475| Step: 0
Training loss: 0.07026215642690659
Validation loss: 1.4528480998931392

Epoch: 6| Step: 1
Training loss: 0.1160193383693695
Validation loss: 1.4588846506610993

Epoch: 6| Step: 2
Training loss: 0.07499505579471588
Validation loss: 1.4819824734041769

Epoch: 6| Step: 3
Training loss: 0.09202487021684647
Validation loss: 1.4875831962913595

Epoch: 6| Step: 4
Training loss: 0.20710402727127075
Validation loss: 1.5195725605052004

Epoch: 6| Step: 5
Training loss: 0.2482050359249115
Validation loss: 1.4643661399041452

Epoch: 6| Step: 6
Training loss: 0.10756652802228928
Validation loss: 1.4899367094039917

Epoch: 6| Step: 7
Training loss: 0.10294546186923981
Validation loss: 1.4572295604213592

Epoch: 6| Step: 8
Training loss: 0.1138136088848114
Validation loss: 1.4574597574049426

Epoch: 6| Step: 9
Training loss: 0.0721365362405777
Validation loss: 1.4512347893048358

Epoch: 6| Step: 10
Training loss: 0.10632167756557465
Validation loss: 1.447763301992929

Epoch: 6| Step: 11
Training loss: 0.07170861214399338
Validation loss: 1.4436194518561005

Epoch: 6| Step: 12
Training loss: 0.1274961233139038
Validation loss: 1.451125814068702

Epoch: 6| Step: 13
Training loss: 0.08850577473640442
Validation loss: 1.4434153661932996

Epoch: 476| Step: 0
Training loss: 0.056939203292131424
Validation loss: 1.4593857770325036

Epoch: 6| Step: 1
Training loss: 0.0567055270075798
Validation loss: 1.4674947107991865

Epoch: 6| Step: 2
Training loss: 0.0851912572979927
Validation loss: 1.4834631258441555

Epoch: 6| Step: 3
Training loss: 0.08378636091947556
Validation loss: 1.4915891763984517

Epoch: 6| Step: 4
Training loss: 0.06526358425617218
Validation loss: 1.5030080477396648

Epoch: 6| Step: 5
Training loss: 0.10336685925722122
Validation loss: 1.5079265473991312

Epoch: 6| Step: 6
Training loss: 0.12036889791488647
Validation loss: 1.4975808102597472

Epoch: 6| Step: 7
Training loss: 0.21505948901176453
Validation loss: 1.488631776584092

Epoch: 6| Step: 8
Training loss: 0.08783777058124542
Validation loss: 1.4755639337724256

Epoch: 6| Step: 9
Training loss: 0.124596506357193
Validation loss: 1.5092266695473784

Epoch: 6| Step: 10
Training loss: 0.13991998136043549
Validation loss: 1.4736918518620152

Epoch: 6| Step: 11
Training loss: 0.2145231068134308
Validation loss: 1.4717168378573593

Epoch: 6| Step: 12
Training loss: 0.0960395485162735
Validation loss: 1.4736194995141798

Epoch: 6| Step: 13
Training loss: 0.09244957566261292
Validation loss: 1.4770985047022502

Epoch: 477| Step: 0
Training loss: 0.09023801982402802
Validation loss: 1.4694316464085733

Epoch: 6| Step: 1
Training loss: 0.10589221119880676
Validation loss: 1.483945991403313

Epoch: 6| Step: 2
Training loss: 0.16968035697937012
Validation loss: 1.4641292582276046

Epoch: 6| Step: 3
Training loss: 0.11093772202730179
Validation loss: 1.4814857308582594

Epoch: 6| Step: 4
Training loss: 0.09531205892562866
Validation loss: 1.422227313441615

Epoch: 6| Step: 5
Training loss: 0.07522481679916382
Validation loss: 1.4049745823747368

Epoch: 6| Step: 6
Training loss: 0.10601691156625748
Validation loss: 1.408307493373912

Epoch: 6| Step: 7
Training loss: 0.07260135561227798
Validation loss: 1.4140595787314958

Epoch: 6| Step: 8
Training loss: 0.05684209614992142
Validation loss: 1.418884709317197

Epoch: 6| Step: 9
Training loss: 0.09989775717258453
Validation loss: 1.4078741509427306

Epoch: 6| Step: 10
Training loss: 0.19166071712970734
Validation loss: 1.4498602010870492

Epoch: 6| Step: 11
Training loss: 0.08995430171489716
Validation loss: 1.4512464705333914

Epoch: 6| Step: 12
Training loss: 0.10150177031755447
Validation loss: 1.455035855693202

Epoch: 6| Step: 13
Training loss: 0.08299443125724792
Validation loss: 1.5197239383574455

Epoch: 478| Step: 0
Training loss: 0.09400814026594162
Validation loss: 1.5149596711640716

Epoch: 6| Step: 1
Training loss: 0.15551915764808655
Validation loss: 1.5608904297633837

Epoch: 6| Step: 2
Training loss: 0.12410791218280792
Validation loss: 1.5705027785352481

Epoch: 6| Step: 3
Training loss: 0.08254170417785645
Validation loss: 1.557048475870522

Epoch: 6| Step: 4
Training loss: 0.08035635948181152
Validation loss: 1.5312535685877646

Epoch: 6| Step: 5
Training loss: 0.20493130385875702
Validation loss: 1.5240127963404502

Epoch: 6| Step: 6
Training loss: 0.2112572342157364
Validation loss: 1.510399862002301

Epoch: 6| Step: 7
Training loss: 0.0951068103313446
Validation loss: 1.4982740981604463

Epoch: 6| Step: 8
Training loss: 0.11034607142210007
Validation loss: 1.5122310115445046

Epoch: 6| Step: 9
Training loss: 0.12965616583824158
Validation loss: 1.4782828387393747

Epoch: 6| Step: 10
Training loss: 0.0943228006362915
Validation loss: 1.4647949331550187

Epoch: 6| Step: 11
Training loss: 0.07245242595672607
Validation loss: 1.459579425473367

Epoch: 6| Step: 12
Training loss: 0.09747340530157089
Validation loss: 1.4623767214436685

Epoch: 6| Step: 13
Training loss: 0.0762336254119873
Validation loss: 1.436653273079985

Epoch: 479| Step: 0
Training loss: 0.07543890178203583
Validation loss: 1.433156164743567

Epoch: 6| Step: 1
Training loss: 0.058749549090862274
Validation loss: 1.4373850322538806

Epoch: 6| Step: 2
Training loss: 0.05434765666723251
Validation loss: 1.4572274210632488

Epoch: 6| Step: 3
Training loss: 0.08672313392162323
Validation loss: 1.4564468296625281

Epoch: 6| Step: 4
Training loss: 0.1363532841205597
Validation loss: 1.450916273619539

Epoch: 6| Step: 5
Training loss: 0.08471570909023285
Validation loss: 1.4544968156404392

Epoch: 6| Step: 6
Training loss: 0.08694641292095184
Validation loss: 1.446809084184708

Epoch: 6| Step: 7
Training loss: 0.10171297192573547
Validation loss: 1.4327469045116055

Epoch: 6| Step: 8
Training loss: 0.1795710027217865
Validation loss: 1.4123378005079044

Epoch: 6| Step: 9
Training loss: 0.18291087448596954
Validation loss: 1.4363466501235962

Epoch: 6| Step: 10
Training loss: 0.07462452352046967
Validation loss: 1.4368444899077057

Epoch: 6| Step: 11
Training loss: 0.11081043630838394
Validation loss: 1.425129102122399

Epoch: 6| Step: 12
Training loss: 0.09426867961883545
Validation loss: 1.4346682012722056

Epoch: 6| Step: 13
Training loss: 0.078203946352005
Validation loss: 1.4590975674249793

Epoch: 480| Step: 0
Training loss: 0.08162419497966766
Validation loss: 1.4611209682239

Epoch: 6| Step: 1
Training loss: 0.17110538482666016
Validation loss: 1.4536237780765822

Epoch: 6| Step: 2
Training loss: 0.09974540770053864
Validation loss: 1.4787071558736986

Epoch: 6| Step: 3
Training loss: 0.09450007975101471
Validation loss: 1.5092460327250983

Epoch: 6| Step: 4
Training loss: 0.0987342968583107
Validation loss: 1.5136652274798321

Epoch: 6| Step: 5
Training loss: 0.06540475785732269
Validation loss: 1.5042381824985627

Epoch: 6| Step: 6
Training loss: 0.08706751465797424
Validation loss: 1.4696573980392948

Epoch: 6| Step: 7
Training loss: 0.09845265001058578
Validation loss: 1.5093519277470087

Epoch: 6| Step: 8
Training loss: 0.20209035277366638
Validation loss: 1.4805771420078893

Epoch: 6| Step: 9
Training loss: 0.04743313789367676
Validation loss: 1.4944663432336622

Epoch: 6| Step: 10
Training loss: 0.15664708614349365
Validation loss: 1.4966684374757993

Epoch: 6| Step: 11
Training loss: 0.10185028612613678
Validation loss: 1.4825418495362805

Epoch: 6| Step: 12
Training loss: 0.09362618625164032
Validation loss: 1.4714630547390188

Epoch: 6| Step: 13
Training loss: 0.2408270537853241
Validation loss: 1.5004712368852349

Epoch: 481| Step: 0
Training loss: 0.13580086827278137
Validation loss: 1.4704598867765037

Epoch: 6| Step: 1
Training loss: 0.13746744394302368
Validation loss: 1.4700311473620835

Epoch: 6| Step: 2
Training loss: 0.05309448391199112
Validation loss: 1.4541447611265286

Epoch: 6| Step: 3
Training loss: 0.09530221670866013
Validation loss: 1.4458960269087104

Epoch: 6| Step: 4
Training loss: 0.17007000744342804
Validation loss: 1.439777607558876

Epoch: 6| Step: 5
Training loss: 0.09361383318901062
Validation loss: 1.4164210160573323

Epoch: 6| Step: 6
Training loss: 0.08261960744857788
Validation loss: 1.4323247466036069

Epoch: 6| Step: 7
Training loss: 0.13106179237365723
Validation loss: 1.4141085032493836

Epoch: 6| Step: 8
Training loss: 0.12817621231079102
Validation loss: 1.4244949061383483

Epoch: 6| Step: 9
Training loss: 0.14265938103199005
Validation loss: 1.4451418256246915

Epoch: 6| Step: 10
Training loss: 0.1032341867685318
Validation loss: 1.4308441249273156

Epoch: 6| Step: 11
Training loss: 0.08471861481666565
Validation loss: 1.4382766972305954

Epoch: 6| Step: 12
Training loss: 0.1265108585357666
Validation loss: 1.4476809899012248

Epoch: 6| Step: 13
Training loss: 0.05820821225643158
Validation loss: 1.4470887773780412

Epoch: 482| Step: 0
Training loss: 0.07036317884922028
Validation loss: 1.4552616034784625

Epoch: 6| Step: 1
Training loss: 0.08733278512954712
Validation loss: 1.4617937572540776

Epoch: 6| Step: 2
Training loss: 0.11564850807189941
Validation loss: 1.4499360758771178

Epoch: 6| Step: 3
Training loss: 0.16826051473617554
Validation loss: 1.4401502865616993

Epoch: 6| Step: 4
Training loss: 0.07865481823682785
Validation loss: 1.442952835431663

Epoch: 6| Step: 5
Training loss: 0.14169099926948547
Validation loss: 1.45304835227228

Epoch: 6| Step: 6
Training loss: 0.06616073846817017
Validation loss: 1.4380478166764783

Epoch: 6| Step: 7
Training loss: 0.102918840944767
Validation loss: 1.447783693190544

Epoch: 6| Step: 8
Training loss: 0.12282586097717285
Validation loss: 1.4231825990061606

Epoch: 6| Step: 9
Training loss: 0.08054260909557343
Validation loss: 1.4244578294856574

Epoch: 6| Step: 10
Training loss: 0.07547692209482193
Validation loss: 1.436277365171781

Epoch: 6| Step: 11
Training loss: 0.08056505024433136
Validation loss: 1.4173418834645262

Epoch: 6| Step: 12
Training loss: 0.11004643887281418
Validation loss: 1.4226890930565455

Epoch: 6| Step: 13
Training loss: 0.17544753849506378
Validation loss: 1.459026909643604

Epoch: 483| Step: 0
Training loss: 0.1768825352191925
Validation loss: 1.4371682995109147

Epoch: 6| Step: 1
Training loss: 0.08438228070735931
Validation loss: 1.4225328583871164

Epoch: 6| Step: 2
Training loss: 0.0854436457157135
Validation loss: 1.406982551338852

Epoch: 6| Step: 3
Training loss: 0.059433192014694214
Validation loss: 1.4251936610027025

Epoch: 6| Step: 4
Training loss: 0.06808638572692871
Validation loss: 1.4187332366102485

Epoch: 6| Step: 5
Training loss: 0.06845182925462723
Validation loss: 1.4242385202838528

Epoch: 6| Step: 6
Training loss: 0.06448838114738464
Validation loss: 1.438956646509068

Epoch: 6| Step: 7
Training loss: 0.08209821581840515
Validation loss: 1.4413913539660874

Epoch: 6| Step: 8
Training loss: 0.12046635150909424
Validation loss: 1.4684283066821355

Epoch: 6| Step: 9
Training loss: 0.11340496689081192
Validation loss: 1.4419765100684216

Epoch: 6| Step: 10
Training loss: 0.08002243936061859
Validation loss: 1.4667735689429826

Epoch: 6| Step: 11
Training loss: 0.05333748459815979
Validation loss: 1.4569042728793236

Epoch: 6| Step: 12
Training loss: 0.09159459173679352
Validation loss: 1.4787687140126382

Epoch: 6| Step: 13
Training loss: 0.2725478410720825
Validation loss: 1.4588589476000877

Epoch: 484| Step: 0
Training loss: 0.07184769213199615
Validation loss: 1.44591676035235

Epoch: 6| Step: 1
Training loss: 0.13461069762706757
Validation loss: 1.4419895359264907

Epoch: 6| Step: 2
Training loss: 0.06464888155460358
Validation loss: 1.4340662033327165

Epoch: 6| Step: 3
Training loss: 0.06678427755832672
Validation loss: 1.426797136183708

Epoch: 6| Step: 4
Training loss: 0.08183948695659637
Validation loss: 1.438428553842729

Epoch: 6| Step: 5
Training loss: 0.059024713933467865
Validation loss: 1.440951447333059

Epoch: 6| Step: 6
Training loss: 0.07089168578386307
Validation loss: 1.4350448154634046

Epoch: 6| Step: 7
Training loss: 0.10324446856975555
Validation loss: 1.4293922378170876

Epoch: 6| Step: 8
Training loss: 0.1780851185321808
Validation loss: 1.4379130166064027

Epoch: 6| Step: 9
Training loss: 0.09238862991333008
Validation loss: 1.4385128739059612

Epoch: 6| Step: 10
Training loss: 0.05073537677526474
Validation loss: 1.437677550059493

Epoch: 6| Step: 11
Training loss: 0.034675419330596924
Validation loss: 1.4114030279139036

Epoch: 6| Step: 12
Training loss: 0.08284398168325424
Validation loss: 1.433170259639781

Epoch: 6| Step: 13
Training loss: 0.06337549537420273
Validation loss: 1.4505538248246717

Epoch: 485| Step: 0
Training loss: 0.07468430697917938
Validation loss: 1.4631566834706131

Epoch: 6| Step: 1
Training loss: 0.092837855219841
Validation loss: 1.435159448654421

Epoch: 6| Step: 2
Training loss: 0.08872092515230179
Validation loss: 1.4383056830334406

Epoch: 6| Step: 3
Training loss: 0.09257900714874268
Validation loss: 1.3976404218263523

Epoch: 6| Step: 4
Training loss: 0.07257197797298431
Validation loss: 1.4495768431694276

Epoch: 6| Step: 5
Training loss: 0.09510742872953415
Validation loss: 1.4269666505116287

Epoch: 6| Step: 6
Training loss: 0.16880527138710022
Validation loss: 1.4321894350872244

Epoch: 6| Step: 7
Training loss: 0.0829186961054802
Validation loss: 1.4602558535914267

Epoch: 6| Step: 8
Training loss: 0.08540415018796921
Validation loss: 1.4341631634261018

Epoch: 6| Step: 9
Training loss: 0.12557798624038696
Validation loss: 1.461866625534591

Epoch: 6| Step: 10
Training loss: 0.10714758187532425
Validation loss: 1.459075984134469

Epoch: 6| Step: 11
Training loss: 0.05922122299671173
Validation loss: 1.43940689486842

Epoch: 6| Step: 12
Training loss: 0.07590216398239136
Validation loss: 1.4661257997635873

Epoch: 6| Step: 13
Training loss: 0.2877001464366913
Validation loss: 1.4345453477674914

Epoch: 486| Step: 0
Training loss: 0.07272504270076752
Validation loss: 1.4697948296864827

Epoch: 6| Step: 1
Training loss: 0.15528227388858795
Validation loss: 1.4207342337536555

Epoch: 6| Step: 2
Training loss: 0.05529526248574257
Validation loss: 1.438324459137455

Epoch: 6| Step: 3
Training loss: 0.12253928184509277
Validation loss: 1.450413405254323

Epoch: 6| Step: 4
Training loss: 0.19106006622314453
Validation loss: 1.4700656411468342

Epoch: 6| Step: 5
Training loss: 0.08730877190828323
Validation loss: 1.4664866898649482

Epoch: 6| Step: 6
Training loss: 0.09388542175292969
Validation loss: 1.455897008219073

Epoch: 6| Step: 7
Training loss: 0.0950537770986557
Validation loss: 1.4807150940741263

Epoch: 6| Step: 8
Training loss: 0.04695775359869003
Validation loss: 1.464511416291678

Epoch: 6| Step: 9
Training loss: 0.0671195313334465
Validation loss: 1.483008098858659

Epoch: 6| Step: 10
Training loss: 0.08765629678964615
Validation loss: 1.4702465534210205

Epoch: 6| Step: 11
Training loss: 0.06481710076332092
Validation loss: 1.483226454386147

Epoch: 6| Step: 12
Training loss: 0.0985383540391922
Validation loss: 1.4582585057904642

Epoch: 6| Step: 13
Training loss: 0.06144407019019127
Validation loss: 1.487275094114324

Epoch: 487| Step: 0
Training loss: 0.07448971271514893
Validation loss: 1.4819063512227868

Epoch: 6| Step: 1
Training loss: 0.09344212710857391
Validation loss: 1.4835127579268588

Epoch: 6| Step: 2
Training loss: 0.09656094759702682
Validation loss: 1.5062149045287923

Epoch: 6| Step: 3
Training loss: 0.07200399041175842
Validation loss: 1.503552116373534

Epoch: 6| Step: 4
Training loss: 0.0837593674659729
Validation loss: 1.495192967435365

Epoch: 6| Step: 5
Training loss: 0.13575580716133118
Validation loss: 1.4986491254580918

Epoch: 6| Step: 6
Training loss: 0.08589129149913788
Validation loss: 1.4601855867652482

Epoch: 6| Step: 7
Training loss: 0.05455022305250168
Validation loss: 1.4881908496220906

Epoch: 6| Step: 8
Training loss: 0.06805495172739029
Validation loss: 1.4672006855728805

Epoch: 6| Step: 9
Training loss: 0.16267472505569458
Validation loss: 1.4670482579097952

Epoch: 6| Step: 10
Training loss: 0.19475048780441284
Validation loss: 1.441110816053165

Epoch: 6| Step: 11
Training loss: 0.06255035102367401
Validation loss: 1.4826125329540623

Epoch: 6| Step: 12
Training loss: 0.07304525375366211
Validation loss: 1.4589009336245957

Epoch: 6| Step: 13
Training loss: 0.06489177793264389
Validation loss: 1.4848079085350037

Epoch: 488| Step: 0
Training loss: 0.10980506241321564
Validation loss: 1.4928077472153531

Epoch: 6| Step: 1
Training loss: 0.08305928111076355
Validation loss: 1.4970044833357616

Epoch: 6| Step: 2
Training loss: 0.09955272823572159
Validation loss: 1.4757095777219342

Epoch: 6| Step: 3
Training loss: 0.06686398386955261
Validation loss: 1.5076507291486185

Epoch: 6| Step: 4
Training loss: 0.09667190164327621
Validation loss: 1.499848061992276

Epoch: 6| Step: 5
Training loss: 0.05607948079705238
Validation loss: 1.4650068834263792

Epoch: 6| Step: 6
Training loss: 0.060710348188877106
Validation loss: 1.4679164181473434

Epoch: 6| Step: 7
Training loss: 0.05899873375892639
Validation loss: 1.4842201432874125

Epoch: 6| Step: 8
Training loss: 0.20262214541435242
Validation loss: 1.4374989796710271

Epoch: 6| Step: 9
Training loss: 0.06335114687681198
Validation loss: 1.422608506294989

Epoch: 6| Step: 10
Training loss: 0.07443540543317795
Validation loss: 1.460745757625949

Epoch: 6| Step: 11
Training loss: 0.08639179170131683
Validation loss: 1.4444341108363161

Epoch: 6| Step: 12
Training loss: 0.15935373306274414
Validation loss: 1.4800398875308294

Epoch: 6| Step: 13
Training loss: 0.0939597561955452
Validation loss: 1.4785520107515397

Epoch: 489| Step: 0
Training loss: 0.07517063617706299
Validation loss: 1.4712327987917009

Epoch: 6| Step: 1
Training loss: 0.12737011909484863
Validation loss: 1.4844394665892406

Epoch: 6| Step: 2
Training loss: 0.10444039106369019
Validation loss: 1.4929983180056337

Epoch: 6| Step: 3
Training loss: 0.09648597240447998
Validation loss: 1.4991138596688547

Epoch: 6| Step: 4
Training loss: 0.11457474529743195
Validation loss: 1.4811256521491594

Epoch: 6| Step: 5
Training loss: 0.07693710178136826
Validation loss: 1.465291270645716

Epoch: 6| Step: 6
Training loss: 0.06275251507759094
Validation loss: 1.468362364717709

Epoch: 6| Step: 7
Training loss: 0.0515872947871685
Validation loss: 1.4577195182923348

Epoch: 6| Step: 8
Training loss: 0.18133720755577087
Validation loss: 1.4203936130769792

Epoch: 6| Step: 9
Training loss: 0.13678212463855743
Validation loss: 1.4455330999948646

Epoch: 6| Step: 10
Training loss: 0.17861679196357727
Validation loss: 1.4452060755862985

Epoch: 6| Step: 11
Training loss: 0.08418416976928711
Validation loss: 1.4073556610333022

Epoch: 6| Step: 12
Training loss: 0.07781277596950531
Validation loss: 1.4358321043752855

Epoch: 6| Step: 13
Training loss: 0.06950826942920685
Validation loss: 1.4433130705228416

Epoch: 490| Step: 0
Training loss: 0.19558316469192505
Validation loss: 1.433907203776862

Epoch: 6| Step: 1
Training loss: 0.12509211897850037
Validation loss: 1.4370064241911775

Epoch: 6| Step: 2
Training loss: 0.21542438864707947
Validation loss: 1.457882099254157

Epoch: 6| Step: 3
Training loss: 0.07353289425373077
Validation loss: 1.4358627501354422

Epoch: 6| Step: 4
Training loss: 0.09238095581531525
Validation loss: 1.4441520078207857

Epoch: 6| Step: 5
Training loss: 0.07583469152450562
Validation loss: 1.4826424903767084

Epoch: 6| Step: 6
Training loss: 0.11945165693759918
Validation loss: 1.491678717315838

Epoch: 6| Step: 7
Training loss: 0.14717963337898254
Validation loss: 1.4875651674885904

Epoch: 6| Step: 8
Training loss: 0.08401760458946228
Validation loss: 1.4766338051006358

Epoch: 6| Step: 9
Training loss: 0.07666902244091034
Validation loss: 1.4871498718056628

Epoch: 6| Step: 10
Training loss: 0.08609160035848618
Validation loss: 1.4741085972837222

Epoch: 6| Step: 11
Training loss: 0.08957964181900024
Validation loss: 1.4562835244722263

Epoch: 6| Step: 12
Training loss: 0.07306456565856934
Validation loss: 1.4509297160692112

Epoch: 6| Step: 13
Training loss: 0.09736791998147964
Validation loss: 1.4627589487260388

Epoch: 491| Step: 0
Training loss: 0.08423154056072235
Validation loss: 1.4524869149731052

Epoch: 6| Step: 1
Training loss: 0.2698425352573395
Validation loss: 1.4596612773915774

Epoch: 6| Step: 2
Training loss: 0.12745241820812225
Validation loss: 1.4561621489063385

Epoch: 6| Step: 3
Training loss: 0.10985732078552246
Validation loss: 1.4616482930798684

Epoch: 6| Step: 4
Training loss: 0.07984819263219833
Validation loss: 1.4918972753709363

Epoch: 6| Step: 5
Training loss: 0.07141244411468506
Validation loss: 1.4901114920134186

Epoch: 6| Step: 6
Training loss: 0.04440116882324219
Validation loss: 1.4963584593547288

Epoch: 6| Step: 7
Training loss: 0.11099337786436081
Validation loss: 1.5112568447666783

Epoch: 6| Step: 8
Training loss: 0.1553908884525299
Validation loss: 1.5268295349613312

Epoch: 6| Step: 9
Training loss: 0.16150754690170288
Validation loss: 1.5251829502403096

Epoch: 6| Step: 10
Training loss: 0.144606813788414
Validation loss: 1.5097760615810272

Epoch: 6| Step: 11
Training loss: 0.080647774040699
Validation loss: 1.5050171690602456

Epoch: 6| Step: 12
Training loss: 0.12955546379089355
Validation loss: 1.4969491304889802

Epoch: 6| Step: 13
Training loss: 0.07074984163045883
Validation loss: 1.4857857804144583

Epoch: 492| Step: 0
Training loss: 0.15201188623905182
Validation loss: 1.4905651115602063

Epoch: 6| Step: 1
Training loss: 0.23530928790569305
Validation loss: 1.4896410626749839

Epoch: 6| Step: 2
Training loss: 0.12519295513629913
Validation loss: 1.4935611819708219

Epoch: 6| Step: 3
Training loss: 0.05692904815077782
Validation loss: 1.4823496623705792

Epoch: 6| Step: 4
Training loss: 0.13141824305057526
Validation loss: 1.4770408150970296

Epoch: 6| Step: 5
Training loss: 0.08206599950790405
Validation loss: 1.467167797908988

Epoch: 6| Step: 6
Training loss: 0.10348616540431976
Validation loss: 1.4602749988596926

Epoch: 6| Step: 7
Training loss: 0.1960301697254181
Validation loss: 1.446870728205609

Epoch: 6| Step: 8
Training loss: 0.10631982982158661
Validation loss: 1.4352931271317184

Epoch: 6| Step: 9
Training loss: 0.13099268078804016
Validation loss: 1.4501803254568448

Epoch: 6| Step: 10
Training loss: 0.07779774814844131
Validation loss: 1.4567770996401388

Epoch: 6| Step: 11
Training loss: 0.08929737657308578
Validation loss: 1.4736105741993073

Epoch: 6| Step: 12
Training loss: 0.07080374658107758
Validation loss: 1.4854900176807115

Epoch: 6| Step: 13
Training loss: 0.13603509962558746
Validation loss: 1.5081048524507912

Epoch: 493| Step: 0
Training loss: 0.12480080127716064
Validation loss: 1.5254183482098322

Epoch: 6| Step: 1
Training loss: 0.1462976038455963
Validation loss: 1.5147280987872873

Epoch: 6| Step: 2
Training loss: 0.1321028172969818
Validation loss: 1.547001741265738

Epoch: 6| Step: 3
Training loss: 0.15947824716567993
Validation loss: 1.557234711544488

Epoch: 6| Step: 4
Training loss: 0.14563947916030884
Validation loss: 1.515014099818404

Epoch: 6| Step: 5
Training loss: 0.1301114857196808
Validation loss: 1.4969193294484129

Epoch: 6| Step: 6
Training loss: 0.08530372381210327
Validation loss: 1.4902520205384941

Epoch: 6| Step: 7
Training loss: 0.09761413931846619
Validation loss: 1.4530701457813222

Epoch: 6| Step: 8
Training loss: 0.1790926456451416
Validation loss: 1.4623279994533909

Epoch: 6| Step: 9
Training loss: 0.15660810470581055
Validation loss: 1.425087994144809

Epoch: 6| Step: 10
Training loss: 0.13758182525634766
Validation loss: 1.4393618324751496

Epoch: 6| Step: 11
Training loss: 0.16890530288219452
Validation loss: 1.4466320801806707

Epoch: 6| Step: 12
Training loss: 0.12234735488891602
Validation loss: 1.4552104197522646

Epoch: 6| Step: 13
Training loss: 0.08402567356824875
Validation loss: 1.4607676036896244

Epoch: 494| Step: 0
Training loss: 0.11128890514373779
Validation loss: 1.4838114182154338

Epoch: 6| Step: 1
Training loss: 0.11041072010993958
Validation loss: 1.490527573452201

Epoch: 6| Step: 2
Training loss: 0.1499054729938507
Validation loss: 1.4904097908286638

Epoch: 6| Step: 3
Training loss: 0.09112036228179932
Validation loss: 1.4827651285356092

Epoch: 6| Step: 4
Training loss: 0.09021039307117462
Validation loss: 1.5095458466519591

Epoch: 6| Step: 5
Training loss: 0.11687381565570831
Validation loss: 1.4710557845331007

Epoch: 6| Step: 6
Training loss: 0.05733335763216019
Validation loss: 1.4676519337520804

Epoch: 6| Step: 7
Training loss: 0.16510766744613647
Validation loss: 1.4823805965403074

Epoch: 6| Step: 8
Training loss: 0.14652782678604126
Validation loss: 1.4691542540827105

Epoch: 6| Step: 9
Training loss: 0.161036878824234
Validation loss: 1.479073570620629

Epoch: 6| Step: 10
Training loss: 0.12105639278888702
Validation loss: 1.4782763219648791

Epoch: 6| Step: 11
Training loss: 0.07222651690244675
Validation loss: 1.4663979366261473

Epoch: 6| Step: 12
Training loss: 0.1262769103050232
Validation loss: 1.4789142429187734

Epoch: 6| Step: 13
Training loss: 0.06280627846717834
Validation loss: 1.4702780810735558

Epoch: 495| Step: 0
Training loss: 0.04879263788461685
Validation loss: 1.4588908200622888

Epoch: 6| Step: 1
Training loss: 0.052253350615501404
Validation loss: 1.4570057097301687

Epoch: 6| Step: 2
Training loss: 0.11133641004562378
Validation loss: 1.4597353396877166

Epoch: 6| Step: 3
Training loss: 0.05637633055448532
Validation loss: 1.4336894109684934

Epoch: 6| Step: 4
Training loss: 0.09955218434333801
Validation loss: 1.440935157960461

Epoch: 6| Step: 5
Training loss: 0.10108623653650284
Validation loss: 1.4201331241156465

Epoch: 6| Step: 6
Training loss: 0.1851767897605896
Validation loss: 1.414129190547492

Epoch: 6| Step: 7
Training loss: 0.18743759393692017
Validation loss: 1.4213766628696072

Epoch: 6| Step: 8
Training loss: 0.09586341679096222
Validation loss: 1.4040086602651944

Epoch: 6| Step: 9
Training loss: 0.10440634936094284
Validation loss: 1.4065134166389384

Epoch: 6| Step: 10
Training loss: 0.1291552186012268
Validation loss: 1.3976723160794986

Epoch: 6| Step: 11
Training loss: 0.07157282531261444
Validation loss: 1.4177094826134302

Epoch: 6| Step: 12
Training loss: 0.07305611670017242
Validation loss: 1.4355466545269053

Epoch: 6| Step: 13
Training loss: 0.10571037232875824
Validation loss: 1.4475752115249634

Epoch: 496| Step: 0
Training loss: 0.09200230985879898
Validation loss: 1.466211522779157

Epoch: 6| Step: 1
Training loss: 0.05935260280966759
Validation loss: 1.4473283611318117

Epoch: 6| Step: 2
Training loss: 0.07607067376375198
Validation loss: 1.484094105741029

Epoch: 6| Step: 3
Training loss: 0.053777117282152176
Validation loss: 1.4893979154607302

Epoch: 6| Step: 4
Training loss: 0.14594526588916779
Validation loss: 1.46422545115153

Epoch: 6| Step: 5
Training loss: 0.0791299119591713
Validation loss: 1.4599048219701296

Epoch: 6| Step: 6
Training loss: 0.0797102078795433
Validation loss: 1.46669223103472

Epoch: 6| Step: 7
Training loss: 0.15016117691993713
Validation loss: 1.4876578123338762

Epoch: 6| Step: 8
Training loss: 0.10361446440219879
Validation loss: 1.4799050913062146

Epoch: 6| Step: 9
Training loss: 0.10667218267917633
Validation loss: 1.5024943595291467

Epoch: 6| Step: 10
Training loss: 0.07015539705753326
Validation loss: 1.522314190864563

Epoch: 6| Step: 11
Training loss: 0.15852618217468262
Validation loss: 1.529004914786226

Epoch: 6| Step: 12
Training loss: 0.1010194793343544
Validation loss: 1.515366526060207

Epoch: 6| Step: 13
Training loss: 0.10771026462316513
Validation loss: 1.5137365146349835

Epoch: 497| Step: 0
Training loss: 0.08409842103719711
Validation loss: 1.4894456132765739

Epoch: 6| Step: 1
Training loss: 0.05396544188261032
Validation loss: 1.4675878017179427

Epoch: 6| Step: 2
Training loss: 0.0870940238237381
Validation loss: 1.41348022542974

Epoch: 6| Step: 3
Training loss: 0.0778716430068016
Validation loss: 1.4147176460553241

Epoch: 6| Step: 4
Training loss: 0.08237634599208832
Validation loss: 1.404999743225754

Epoch: 6| Step: 5
Training loss: 0.11597058922052383
Validation loss: 1.3826163584186184

Epoch: 6| Step: 6
Training loss: 0.14525927603244781
Validation loss: 1.3811093722620318

Epoch: 6| Step: 7
Training loss: 0.17810767889022827
Validation loss: 1.4042206015638126

Epoch: 6| Step: 8
Training loss: 0.10027340054512024
Validation loss: 1.42370262581815

Epoch: 6| Step: 9
Training loss: 0.08666706830263138
Validation loss: 1.4164797131733229

Epoch: 6| Step: 10
Training loss: 0.059017449617385864
Validation loss: 1.4434313620290449

Epoch: 6| Step: 11
Training loss: 0.07124931365251541
Validation loss: 1.4230143998258857

Epoch: 6| Step: 12
Training loss: 0.07341431081295013
Validation loss: 1.439144242194391

Epoch: 6| Step: 13
Training loss: 0.05391274392604828
Validation loss: 1.4679549676115795

Epoch: 498| Step: 0
Training loss: 0.09899773448705673
Validation loss: 1.479253743284492

Epoch: 6| Step: 1
Training loss: 0.17655938863754272
Validation loss: 1.4754860253744229

Epoch: 6| Step: 2
Training loss: 0.08843433856964111
Validation loss: 1.483001680784328

Epoch: 6| Step: 3
Training loss: 0.09430298954248428
Validation loss: 1.455591167173078

Epoch: 6| Step: 4
Training loss: 0.06458745896816254
Validation loss: 1.4521708283373105

Epoch: 6| Step: 5
Training loss: 0.16649627685546875
Validation loss: 1.4531228042417956

Epoch: 6| Step: 6
Training loss: 0.088593028485775
Validation loss: 1.4305095467516171

Epoch: 6| Step: 7
Training loss: 0.08825555443763733
Validation loss: 1.4239180581544035

Epoch: 6| Step: 8
Training loss: 0.13365890085697174
Validation loss: 1.3857910421586805

Epoch: 6| Step: 9
Training loss: 0.07024811208248138
Validation loss: 1.395402499424514

Epoch: 6| Step: 10
Training loss: 0.09440601617097855
Validation loss: 1.412854456132458

Epoch: 6| Step: 11
Training loss: 0.10274435579776764
Validation loss: 1.4035160554352628

Epoch: 6| Step: 12
Training loss: 0.10860829800367355
Validation loss: 1.4179350765802528

Epoch: 6| Step: 13
Training loss: 0.09497306495904922
Validation loss: 1.4389015833536785

Epoch: 499| Step: 0
Training loss: 0.15353238582611084
Validation loss: 1.4298108277782318

Epoch: 6| Step: 1
Training loss: 0.1561719924211502
Validation loss: 1.432760484756962

Epoch: 6| Step: 2
Training loss: 0.10091137886047363
Validation loss: 1.446508583202157

Epoch: 6| Step: 3
Training loss: 0.10910295695066452
Validation loss: 1.456444158348986

Epoch: 6| Step: 4
Training loss: 0.05247163772583008
Validation loss: 1.4670766950935445

Epoch: 6| Step: 5
Training loss: 0.11575431376695633
Validation loss: 1.4790648830834257

Epoch: 6| Step: 6
Training loss: 0.11276865005493164
Validation loss: 1.4990551215346142

Epoch: 6| Step: 7
Training loss: 0.08645349740982056
Validation loss: 1.4660588541338522

Epoch: 6| Step: 8
Training loss: 0.07571455836296082
Validation loss: 1.4619460234078028

Epoch: 6| Step: 9
Training loss: 0.06220996752381325
Validation loss: 1.4849920067735898

Epoch: 6| Step: 10
Training loss: 0.10024995356798172
Validation loss: 1.4462058351885887

Epoch: 6| Step: 11
Training loss: 0.056228332221508026
Validation loss: 1.448811549012379

Epoch: 6| Step: 12
Training loss: 0.07710506021976471
Validation loss: 1.442867418771149

Epoch: 6| Step: 13
Training loss: 0.04551707208156586
Validation loss: 1.4426801717409523

Epoch: 500| Step: 0
Training loss: 0.1708124577999115
Validation loss: 1.4236845752244354

Epoch: 6| Step: 1
Training loss: 0.08223658055067062
Validation loss: 1.4343956619180658

Epoch: 6| Step: 2
Training loss: 0.10584348440170288
Validation loss: 1.4396892504025531

Epoch: 6| Step: 3
Training loss: 0.09983552992343903
Validation loss: 1.444333307204708

Epoch: 6| Step: 4
Training loss: 0.06536024808883667
Validation loss: 1.4591999598728713

Epoch: 6| Step: 5
Training loss: 0.07308328151702881
Validation loss: 1.4625327779400734

Epoch: 6| Step: 6
Training loss: 0.1320270448923111
Validation loss: 1.4645876064095447

Epoch: 6| Step: 7
Training loss: 0.09668727219104767
Validation loss: 1.474831231178776

Epoch: 6| Step: 8
Training loss: 0.07864052057266235
Validation loss: 1.4454588159438102

Epoch: 6| Step: 9
Training loss: 0.07452921569347382
Validation loss: 1.4468609107437955

Epoch: 6| Step: 10
Training loss: 0.08018894493579865
Validation loss: 1.4373206477011404

Epoch: 6| Step: 11
Training loss: 0.06472711265087128
Validation loss: 1.4409774529036654

Epoch: 6| Step: 12
Training loss: 0.16315999627113342
Validation loss: 1.4694592491272958

Epoch: 6| Step: 13
Training loss: 0.06264444440603256
Validation loss: 1.431184483471737

Epoch: 501| Step: 0
Training loss: 0.15772560238838196
Validation loss: 1.4464361706087667

Epoch: 6| Step: 1
Training loss: 0.05956237018108368
Validation loss: 1.439075558416305

Epoch: 6| Step: 2
Training loss: 0.095826655626297
Validation loss: 1.4304404931683694

Epoch: 6| Step: 3
Training loss: 0.0887710303068161
Validation loss: 1.4485217890431803

Epoch: 6| Step: 4
Training loss: 0.06637740135192871
Validation loss: 1.4386027500193606

Epoch: 6| Step: 5
Training loss: 0.0430624783039093
Validation loss: 1.4622285135330693

Epoch: 6| Step: 6
Training loss: 0.16119739413261414
Validation loss: 1.465006632189597

Epoch: 6| Step: 7
Training loss: 0.09738055616617203
Validation loss: 1.4805766433797858

Epoch: 6| Step: 8
Training loss: 0.09564592689275742
Validation loss: 1.4884051007609214

Epoch: 6| Step: 9
Training loss: 0.06695400923490524
Validation loss: 1.4691591519181446

Epoch: 6| Step: 10
Training loss: 0.12213627994060516
Validation loss: 1.4756456267449163

Epoch: 6| Step: 11
Training loss: 0.09962919354438782
Validation loss: 1.4228677582997147

Epoch: 6| Step: 12
Training loss: 0.03951078653335571
Validation loss: 1.4191154177470873

Epoch: 6| Step: 13
Training loss: 0.05013180524110794
Validation loss: 1.4126933095275716

Epoch: 502| Step: 0
Training loss: 0.05522589758038521
Validation loss: 1.4044224805729364

Epoch: 6| Step: 1
Training loss: 0.09837814420461655
Validation loss: 1.3912416632457445

Epoch: 6| Step: 2
Training loss: 0.11726728081703186
Validation loss: 1.3877017100652058

Epoch: 6| Step: 3
Training loss: 0.06065400689840317
Validation loss: 1.3736703062570224

Epoch: 6| Step: 4
Training loss: 0.11205251514911652
Validation loss: 1.391206947065169

Epoch: 6| Step: 5
Training loss: 0.17573431134223938
Validation loss: 1.4051788160877843

Epoch: 6| Step: 6
Training loss: 0.10922183096408844
Validation loss: 1.3961055753051594

Epoch: 6| Step: 7
Training loss: 0.08368575572967529
Validation loss: 1.4001996222362723

Epoch: 6| Step: 8
Training loss: 0.17202168703079224
Validation loss: 1.4145975766643402

Epoch: 6| Step: 9
Training loss: 0.05552185699343681
Validation loss: 1.4187686135691981

Epoch: 6| Step: 10
Training loss: 0.04178667068481445
Validation loss: 1.4343479948659097

Epoch: 6| Step: 11
Training loss: 0.07187622785568237
Validation loss: 1.4490396861107118

Epoch: 6| Step: 12
Training loss: 0.10570351779460907
Validation loss: 1.4633671570849676

Epoch: 6| Step: 13
Training loss: 0.05359691381454468
Validation loss: 1.4842414868775236

Epoch: 503| Step: 0
Training loss: 0.08204106986522675
Validation loss: 1.4765803596024871

Epoch: 6| Step: 1
Training loss: 0.10552601516246796
Validation loss: 1.4714477228861984

Epoch: 6| Step: 2
Training loss: 0.089580237865448
Validation loss: 1.4666710745903753

Epoch: 6| Step: 3
Training loss: 0.05828694626688957
Validation loss: 1.487629053413227

Epoch: 6| Step: 4
Training loss: 0.11186546087265015
Validation loss: 1.485717446573319

Epoch: 6| Step: 5
Training loss: 0.09143407642841339
Validation loss: 1.469455167811404

Epoch: 6| Step: 6
Training loss: 0.15027520060539246
Validation loss: 1.4595847347731232

Epoch: 6| Step: 7
Training loss: 0.06732303649187088
Validation loss: 1.4595359807373376

Epoch: 6| Step: 8
Training loss: 0.08465056866407394
Validation loss: 1.4565768696928536

Epoch: 6| Step: 9
Training loss: 0.09320642799139023
Validation loss: 1.4622037000553583

Epoch: 6| Step: 10
Training loss: 0.10123425722122192
Validation loss: 1.4690215087706042

Epoch: 6| Step: 11
Training loss: 0.21828830242156982
Validation loss: 1.5034438128112464

Epoch: 6| Step: 12
Training loss: 0.11881018429994583
Validation loss: 1.4787910087134248

Epoch: 6| Step: 13
Training loss: 0.12698674201965332
Validation loss: 1.4892712395678285

Epoch: 504| Step: 0
Training loss: 0.09846267104148865
Validation loss: 1.4857481628335931

Epoch: 6| Step: 1
Training loss: 0.11775707453489304
Validation loss: 1.483275621168075

Epoch: 6| Step: 2
Training loss: 0.09106887876987457
Validation loss: 1.4736173024741552

Epoch: 6| Step: 3
Training loss: 0.15524207055568695
Validation loss: 1.4556860539220995

Epoch: 6| Step: 4
Training loss: 0.15539127588272095
Validation loss: 1.450568764440475

Epoch: 6| Step: 5
Training loss: 0.09003519266843796
Validation loss: 1.4184687573422667

Epoch: 6| Step: 6
Training loss: 0.06642971187829971
Validation loss: 1.4682563838138376

Epoch: 6| Step: 7
Training loss: 0.10556918382644653
Validation loss: 1.4466938882745721

Epoch: 6| Step: 8
Training loss: 0.10807337611913681
Validation loss: 1.4319201707839966

Epoch: 6| Step: 9
Training loss: 0.08416330814361572
Validation loss: 1.4555629799442906

Epoch: 6| Step: 10
Training loss: 0.14494222402572632
Validation loss: 1.4280953112468924

Epoch: 6| Step: 11
Training loss: 0.08428315818309784
Validation loss: 1.4439091656797676

Epoch: 6| Step: 12
Training loss: 0.0776873379945755
Validation loss: 1.4279114264313892

Epoch: 6| Step: 13
Training loss: 0.10296458750963211
Validation loss: 1.4228087599559496

Epoch: 505| Step: 0
Training loss: 0.16691821813583374
Validation loss: 1.43874664204095

Epoch: 6| Step: 1
Training loss: 0.1364256888628006
Validation loss: 1.438889398369738

Epoch: 6| Step: 2
Training loss: 0.08733651787042618
Validation loss: 1.4413919269397695

Epoch: 6| Step: 3
Training loss: 0.07071572542190552
Validation loss: 1.4199213250990836

Epoch: 6| Step: 4
Training loss: 0.08515025675296783
Validation loss: 1.4120615695112495

Epoch: 6| Step: 5
Training loss: 0.04787648469209671
Validation loss: 1.4308917868521907

Epoch: 6| Step: 6
Training loss: 0.08703364431858063
Validation loss: 1.4432033223490561

Epoch: 6| Step: 7
Training loss: 0.07565100491046906
Validation loss: 1.4033749488092238

Epoch: 6| Step: 8
Training loss: 0.11047884076833725
Validation loss: 1.4429465724575905

Epoch: 6| Step: 9
Training loss: 0.17049440741539001
Validation loss: 1.4205882216012606

Epoch: 6| Step: 10
Training loss: 0.06289267539978027
Validation loss: 1.4186654718973304

Epoch: 6| Step: 11
Training loss: 0.08389987051486969
Validation loss: 1.4244431910976287

Epoch: 6| Step: 12
Training loss: 0.08003277331590652
Validation loss: 1.4231188322908135

Epoch: 6| Step: 13
Training loss: 0.08680825680494308
Validation loss: 1.4469019123302993

Epoch: 506| Step: 0
Training loss: 0.07946734130382538
Validation loss: 1.4338055400438205

Epoch: 6| Step: 1
Training loss: 0.1656431406736374
Validation loss: 1.4362944659366403

Epoch: 6| Step: 2
Training loss: 0.09324834495782852
Validation loss: 1.4453966271492742

Epoch: 6| Step: 3
Training loss: 0.16988474130630493
Validation loss: 1.4626541676059845

Epoch: 6| Step: 4
Training loss: 0.10692662000656128
Validation loss: 1.4643695867189797

Epoch: 6| Step: 5
Training loss: 0.08464209735393524
Validation loss: 1.4757027638855802

Epoch: 6| Step: 6
Training loss: 0.11630284786224365
Validation loss: 1.469071166489714

Epoch: 6| Step: 7
Training loss: 0.09501641988754272
Validation loss: 1.448980644185056

Epoch: 6| Step: 8
Training loss: 0.08400055766105652
Validation loss: 1.4723163727791078

Epoch: 6| Step: 9
Training loss: 0.08189009130001068
Validation loss: 1.4179387874500726

Epoch: 6| Step: 10
Training loss: 0.08153721690177917
Validation loss: 1.445943271921527

Epoch: 6| Step: 11
Training loss: 0.09263564646244049
Validation loss: 1.430014141144291

Epoch: 6| Step: 12
Training loss: 0.0878128707408905
Validation loss: 1.4397680182610788

Epoch: 6| Step: 13
Training loss: 0.11887432634830475
Validation loss: 1.3968701054972987

Epoch: 507| Step: 0
Training loss: 0.09103462100028992
Validation loss: 1.4431814506489744

Epoch: 6| Step: 1
Training loss: 0.06803901493549347
Validation loss: 1.4324091083259993

Epoch: 6| Step: 2
Training loss: 0.06544886529445648
Validation loss: 1.441314903638696

Epoch: 6| Step: 3
Training loss: 0.154474675655365
Validation loss: 1.4473289494873376

Epoch: 6| Step: 4
Training loss: 0.06779946386814117
Validation loss: 1.4187892918945642

Epoch: 6| Step: 5
Training loss: 0.06684046983718872
Validation loss: 1.4692670401706491

Epoch: 6| Step: 6
Training loss: 0.09367979317903519
Validation loss: 1.4315832712317025

Epoch: 6| Step: 7
Training loss: 0.05090438947081566
Validation loss: 1.436596760185816

Epoch: 6| Step: 8
Training loss: 0.10458377003669739
Validation loss: 1.4344843452976597

Epoch: 6| Step: 9
Training loss: 0.08329359441995621
Validation loss: 1.4046345359535628

Epoch: 6| Step: 10
Training loss: 0.0806175246834755
Validation loss: 1.4249456262075773

Epoch: 6| Step: 11
Training loss: 0.061932940036058426
Validation loss: 1.4303544516204505

Epoch: 6| Step: 12
Training loss: 0.16343805193901062
Validation loss: 1.4025672712633688

Epoch: 6| Step: 13
Training loss: 0.05935472249984741
Validation loss: 1.411865786839557

Epoch: 508| Step: 0
Training loss: 0.06394306570291519
Validation loss: 1.4109439157670545

Epoch: 6| Step: 1
Training loss: 0.09493769705295563
Validation loss: 1.4166647862362605

Epoch: 6| Step: 2
Training loss: 0.16381344199180603
Validation loss: 1.4333206735631472

Epoch: 6| Step: 3
Training loss: 0.08887725323438644
Validation loss: 1.4082120733876382

Epoch: 6| Step: 4
Training loss: 0.05791771411895752
Validation loss: 1.3967467277280745

Epoch: 6| Step: 5
Training loss: 0.06607945263385773
Validation loss: 1.408667319564409

Epoch: 6| Step: 6
Training loss: 0.044885337352752686
Validation loss: 1.3835511733126897

Epoch: 6| Step: 7
Training loss: 0.08825640380382538
Validation loss: 1.4020504977113457

Epoch: 6| Step: 8
Training loss: 0.1139916256070137
Validation loss: 1.4214395041106849

Epoch: 6| Step: 9
Training loss: 0.0672922134399414
Validation loss: 1.41376498822243

Epoch: 6| Step: 10
Training loss: 0.08345189690589905
Validation loss: 1.4255513965442617

Epoch: 6| Step: 11
Training loss: 0.037408776581287384
Validation loss: 1.4221012207769579

Epoch: 6| Step: 12
Training loss: 0.11919514834880829
Validation loss: 1.4306621487422655

Epoch: 6| Step: 13
Training loss: 0.035366613417863846
Validation loss: 1.4559278359977148

Epoch: 509| Step: 0
Training loss: 0.08878965675830841
Validation loss: 1.507680598125663

Epoch: 6| Step: 1
Training loss: 0.12968213856220245
Validation loss: 1.5013406968885852

Epoch: 6| Step: 2
Training loss: 0.11067304760217667
Validation loss: 1.5296694258207917

Epoch: 6| Step: 3
Training loss: 0.17610971629619598
Validation loss: 1.5366858077305618

Epoch: 6| Step: 4
Training loss: 0.07879144698381424
Validation loss: 1.509216821321877

Epoch: 6| Step: 5
Training loss: 0.13070876896381378
Validation loss: 1.4849561273410756

Epoch: 6| Step: 6
Training loss: 0.07020734250545502
Validation loss: 1.4554048456171507

Epoch: 6| Step: 7
Training loss: 0.08119349926710129
Validation loss: 1.4333406020236272

Epoch: 6| Step: 8
Training loss: 0.08932837843894958
Validation loss: 1.4099091419609644

Epoch: 6| Step: 9
Training loss: 0.09884306788444519
Validation loss: 1.4162442543173348

Epoch: 6| Step: 10
Training loss: 0.1654931753873825
Validation loss: 1.4283719972897602

Epoch: 6| Step: 11
Training loss: 0.0420425608754158
Validation loss: 1.4190378522360196

Epoch: 6| Step: 12
Training loss: 0.07818439602851868
Validation loss: 1.4253744547085097

Epoch: 6| Step: 13
Training loss: 0.04950264096260071
Validation loss: 1.4197933981495519

Epoch: 510| Step: 0
Training loss: 0.08399244397878647
Validation loss: 1.4370840569978118

Epoch: 6| Step: 1
Training loss: 0.17886701226234436
Validation loss: 1.4598143568602941

Epoch: 6| Step: 2
Training loss: 0.0805569663643837
Validation loss: 1.441584264078448

Epoch: 6| Step: 3
Training loss: 0.11979693919420242
Validation loss: 1.4360101684447257

Epoch: 6| Step: 4
Training loss: 0.11175823211669922
Validation loss: 1.443990433087913

Epoch: 6| Step: 5
Training loss: 0.0689140260219574
Validation loss: 1.4200124086872223

Epoch: 6| Step: 6
Training loss: 0.07300841808319092
Validation loss: 1.4287254938515284

Epoch: 6| Step: 7
Training loss: 0.1651650369167328
Validation loss: 1.4471925766237321

Epoch: 6| Step: 8
Training loss: 0.07970471680164337
Validation loss: 1.436443116075249

Epoch: 6| Step: 9
Training loss: 0.06563836336135864
Validation loss: 1.4415610387761106

Epoch: 6| Step: 10
Training loss: 0.09088844060897827
Validation loss: 1.4561780127145911

Epoch: 6| Step: 11
Training loss: 0.12002808600664139
Validation loss: 1.4498280440607378

Epoch: 6| Step: 12
Training loss: 0.09131664782762527
Validation loss: 1.4338531853050314

Epoch: 6| Step: 13
Training loss: 0.10204580426216125
Validation loss: 1.4390890059932586

Epoch: 511| Step: 0
Training loss: 0.15377850830554962
Validation loss: 1.4029941405019453

Epoch: 6| Step: 1
Training loss: 0.08431360125541687
Validation loss: 1.4037087457154387

Epoch: 6| Step: 2
Training loss: 0.09806910157203674
Validation loss: 1.4233556024489864

Epoch: 6| Step: 3
Training loss: 0.10503387451171875
Validation loss: 1.4355770464866393

Epoch: 6| Step: 4
Training loss: 0.07148200273513794
Validation loss: 1.4336731997869347

Epoch: 6| Step: 5
Training loss: 0.09225421398878098
Validation loss: 1.4189442652528004

Epoch: 6| Step: 6
Training loss: 0.15555869042873383
Validation loss: 1.4201019130727297

Epoch: 6| Step: 7
Training loss: 0.12534576654434204
Validation loss: 1.4566278944733322

Epoch: 6| Step: 8
Training loss: 0.09643366187810898
Validation loss: 1.4465611352715442

Epoch: 6| Step: 9
Training loss: 0.04309269040822983
Validation loss: 1.4396184881528218

Epoch: 6| Step: 10
Training loss: 0.07531866431236267
Validation loss: 1.448235886071318

Epoch: 6| Step: 11
Training loss: 0.09032801538705826
Validation loss: 1.468091675030288

Epoch: 6| Step: 12
Training loss: 0.0739559680223465
Validation loss: 1.4414638588505406

Epoch: 6| Step: 13
Training loss: 0.06559916585683823
Validation loss: 1.4256849763213948

Epoch: 512| Step: 0
Training loss: 0.07026825845241547
Validation loss: 1.4235418560684368

Epoch: 6| Step: 1
Training loss: 0.1422642171382904
Validation loss: 1.4208136521359926

Epoch: 6| Step: 2
Training loss: 0.0717766061425209
Validation loss: 1.4069535078540925

Epoch: 6| Step: 3
Training loss: 0.09519128501415253
Validation loss: 1.4075354030055385

Epoch: 6| Step: 4
Training loss: 0.0739642083644867
Validation loss: 1.369191219729762

Epoch: 6| Step: 5
Training loss: 0.07428809255361557
Validation loss: 1.385702710638764

Epoch: 6| Step: 6
Training loss: 0.10638412088155746
Validation loss: 1.3885989137875137

Epoch: 6| Step: 7
Training loss: 0.10786648839712143
Validation loss: 1.3836207838468655

Epoch: 6| Step: 8
Training loss: 0.09362972527742386
Validation loss: 1.3725527704402964

Epoch: 6| Step: 9
Training loss: 0.09880458563566208
Validation loss: 1.3862000088537894

Epoch: 6| Step: 10
Training loss: 0.11514091491699219
Validation loss: 1.4065002151714858

Epoch: 6| Step: 11
Training loss: 0.14333558082580566
Validation loss: 1.4009355537353023

Epoch: 6| Step: 12
Training loss: 0.0951634868979454
Validation loss: 1.3927723092417563

Epoch: 6| Step: 13
Training loss: 0.10080194473266602
Validation loss: 1.4084434701550392

Epoch: 513| Step: 0
Training loss: 0.1822872757911682
Validation loss: 1.4190307906878892

Epoch: 6| Step: 1
Training loss: 0.05816097930073738
Validation loss: 1.4186616148999942

Epoch: 6| Step: 2
Training loss: 0.0801599770784378
Validation loss: 1.420131419294624

Epoch: 6| Step: 3
Training loss: 0.08102624118328094
Validation loss: 1.4312149337542954

Epoch: 6| Step: 4
Training loss: 0.09059973061084747
Validation loss: 1.4289542244326683

Epoch: 6| Step: 5
Training loss: 0.06528303772211075
Validation loss: 1.424889983669404

Epoch: 6| Step: 6
Training loss: 0.08256709575653076
Validation loss: 1.4371230768901047

Epoch: 6| Step: 7
Training loss: 0.1760384440422058
Validation loss: 1.426490855473344

Epoch: 6| Step: 8
Training loss: 0.09477458894252777
Validation loss: 1.4460988621557913

Epoch: 6| Step: 9
Training loss: 0.05355098098516464
Validation loss: 1.4630130401221655

Epoch: 6| Step: 10
Training loss: 0.05025045946240425
Validation loss: 1.4838415627838464

Epoch: 6| Step: 11
Training loss: 0.1402532160282135
Validation loss: 1.4929421768393567

Epoch: 6| Step: 12
Training loss: 0.08336736261844635
Validation loss: 1.4879854391979914

Epoch: 6| Step: 13
Training loss: 0.04575272276997566
Validation loss: 1.4879196190064954

Epoch: 514| Step: 0
Training loss: 0.0515039898455143
Validation loss: 1.4878353047114548

Epoch: 6| Step: 1
Training loss: 0.15906819701194763
Validation loss: 1.4737300013983121

Epoch: 6| Step: 2
Training loss: 0.08050471544265747
Validation loss: 1.4902019834005704

Epoch: 6| Step: 3
Training loss: 0.08688235282897949
Validation loss: 1.5020414296016897

Epoch: 6| Step: 4
Training loss: 0.08876090496778488
Validation loss: 1.4974758458393875

Epoch: 6| Step: 5
Training loss: 0.09214110672473907
Validation loss: 1.4900466113962152

Epoch: 6| Step: 6
Training loss: 0.1560244858264923
Validation loss: 1.4788043165719638

Epoch: 6| Step: 7
Training loss: 0.12149578332901001
Validation loss: 1.459750497212974

Epoch: 6| Step: 8
Training loss: 0.07665681838989258
Validation loss: 1.4652187721703642

Epoch: 6| Step: 9
Training loss: 0.07176108658313751
Validation loss: 1.4659821333423737

Epoch: 6| Step: 10
Training loss: 0.09263364970684052
Validation loss: 1.4660197265686528

Epoch: 6| Step: 11
Training loss: 0.09761074185371399
Validation loss: 1.4597878238206268

Epoch: 6| Step: 12
Training loss: 0.05843697860836983
Validation loss: 1.4456784507279754

Epoch: 6| Step: 13
Training loss: 0.03130808845162392
Validation loss: 1.4435882850359845

Epoch: 515| Step: 0
Training loss: 0.10017214715480804
Validation loss: 1.4308003796044217

Epoch: 6| Step: 1
Training loss: 0.22227509319782257
Validation loss: 1.4350850287304129

Epoch: 6| Step: 2
Training loss: 0.06191304698586464
Validation loss: 1.4454500470110165

Epoch: 6| Step: 3
Training loss: 0.05693090707063675
Validation loss: 1.4326574581284677

Epoch: 6| Step: 4
Training loss: 0.09564389288425446
Validation loss: 1.442311684290568

Epoch: 6| Step: 5
Training loss: 0.07468090951442719
Validation loss: 1.4590086654950214

Epoch: 6| Step: 6
Training loss: 0.10668863356113434
Validation loss: 1.4916201817092074

Epoch: 6| Step: 7
Training loss: 0.15393538773059845
Validation loss: 1.4891155330083703

Epoch: 6| Step: 8
Training loss: 0.05488823726773262
Validation loss: 1.4959598228495607

Epoch: 6| Step: 9
Training loss: 0.07478328794240952
Validation loss: 1.4685152884452575

Epoch: 6| Step: 10
Training loss: 0.10544970631599426
Validation loss: 1.4865622828083653

Epoch: 6| Step: 11
Training loss: 0.03752059116959572
Validation loss: 1.453567192118655

Epoch: 6| Step: 12
Training loss: 0.07315467298030853
Validation loss: 1.4633440881647088

Epoch: 6| Step: 13
Training loss: 0.06694234162569046
Validation loss: 1.4474029464106406

Epoch: 516| Step: 0
Training loss: 0.09946900606155396
Validation loss: 1.4306106887837893

Epoch: 6| Step: 1
Training loss: 0.23084524273872375
Validation loss: 1.423603783371628

Epoch: 6| Step: 2
Training loss: 0.06926621496677399
Validation loss: 1.4162397269279725

Epoch: 6| Step: 3
Training loss: 0.05979333817958832
Validation loss: 1.395989211656714

Epoch: 6| Step: 4
Training loss: 0.09588051587343216
Validation loss: 1.4142848605750709

Epoch: 6| Step: 5
Training loss: 0.08104557543992996
Validation loss: 1.4242055121288504

Epoch: 6| Step: 6
Training loss: 0.10104361921548843
Validation loss: 1.420235687686551

Epoch: 6| Step: 7
Training loss: 0.09809912741184235
Validation loss: 1.405938143371254

Epoch: 6| Step: 8
Training loss: 0.17991109192371368
Validation loss: 1.4206892854423934

Epoch: 6| Step: 9
Training loss: 0.08493946492671967
Validation loss: 1.4373607776498283

Epoch: 6| Step: 10
Training loss: 0.05400140583515167
Validation loss: 1.4296222258639593

Epoch: 6| Step: 11
Training loss: 0.055997803807258606
Validation loss: 1.4438286378819456

Epoch: 6| Step: 12
Training loss: 0.09478648751974106
Validation loss: 1.419252731466806

Epoch: 6| Step: 13
Training loss: 0.047682907432317734
Validation loss: 1.4083690841992695

Epoch: 517| Step: 0
Training loss: 0.04145212471485138
Validation loss: 1.4116581268208002

Epoch: 6| Step: 1
Training loss: 0.13569024205207825
Validation loss: 1.4039833878958097

Epoch: 6| Step: 2
Training loss: 0.15346266329288483
Validation loss: 1.412439187367757

Epoch: 6| Step: 3
Training loss: 0.14773479104042053
Validation loss: 1.4106278983495568

Epoch: 6| Step: 4
Training loss: 0.09754878282546997
Validation loss: 1.4129017373566986

Epoch: 6| Step: 5
Training loss: 0.06494352966547012
Validation loss: 1.4224389394124348

Epoch: 6| Step: 6
Training loss: 0.07743039727210999
Validation loss: 1.4175366156844682

Epoch: 6| Step: 7
Training loss: 0.04768339917063713
Validation loss: 1.4208761825356433

Epoch: 6| Step: 8
Training loss: 0.0901595950126648
Validation loss: 1.4380126858270297

Epoch: 6| Step: 9
Training loss: 0.10702264308929443
Validation loss: 1.4589061961379102

Epoch: 6| Step: 10
Training loss: 0.13050511479377747
Validation loss: 1.4750191665464831

Epoch: 6| Step: 11
Training loss: 0.06689028441905975
Validation loss: 1.4547300287472305

Epoch: 6| Step: 12
Training loss: 0.09628336876630783
Validation loss: 1.4963336503633888

Epoch: 6| Step: 13
Training loss: 0.08485833555459976
Validation loss: 1.4694051358007616

Epoch: 518| Step: 0
Training loss: 0.07793348282575607
Validation loss: 1.4120989166280276

Epoch: 6| Step: 1
Training loss: 0.10171918570995331
Validation loss: 1.432569396111273

Epoch: 6| Step: 2
Training loss: 0.05472712218761444
Validation loss: 1.3988208668206328

Epoch: 6| Step: 3
Training loss: 0.08422845602035522
Validation loss: 1.4379695359096731

Epoch: 6| Step: 4
Training loss: 0.1633439064025879
Validation loss: 1.4299483478710215

Epoch: 6| Step: 5
Training loss: 0.0666370540857315
Validation loss: 1.4240203506203108

Epoch: 6| Step: 6
Training loss: 0.08861656486988068
Validation loss: 1.4268099851505731

Epoch: 6| Step: 7
Training loss: 0.09261950850486755
Validation loss: 1.4304971925673946

Epoch: 6| Step: 8
Training loss: 0.0749281495809555
Validation loss: 1.444895512314253

Epoch: 6| Step: 9
Training loss: 0.06439635902643204
Validation loss: 1.4625989865231257

Epoch: 6| Step: 10
Training loss: 0.07071731239557266
Validation loss: 1.4582867699284707

Epoch: 6| Step: 11
Training loss: 0.17646485567092896
Validation loss: 1.4563722456655195

Epoch: 6| Step: 12
Training loss: 0.09096910059452057
Validation loss: 1.4602165311895392

Epoch: 6| Step: 13
Training loss: 0.10476204007863998
Validation loss: 1.4764834911592546

Epoch: 519| Step: 0
Training loss: 0.13513460755348206
Validation loss: 1.4618565113313737

Epoch: 6| Step: 1
Training loss: 0.15611660480499268
Validation loss: 1.4700172421752766

Epoch: 6| Step: 2
Training loss: 0.09407274425029755
Validation loss: 1.4683936834335327

Epoch: 6| Step: 3
Training loss: 0.07421275228261948
Validation loss: 1.4834462615751451

Epoch: 6| Step: 4
Training loss: 0.054149508476257324
Validation loss: 1.4362098696411296

Epoch: 6| Step: 5
Training loss: 0.06986621767282486
Validation loss: 1.4364686204541115

Epoch: 6| Step: 6
Training loss: 0.042649153620004654
Validation loss: 1.453385583816036

Epoch: 6| Step: 7
Training loss: 0.13135546445846558
Validation loss: 1.4537954356080742

Epoch: 6| Step: 8
Training loss: 0.10824466496706009
Validation loss: 1.4403229291721056

Epoch: 6| Step: 9
Training loss: 0.07840193063020706
Validation loss: 1.4390567259121967

Epoch: 6| Step: 10
Training loss: 0.08513594418764114
Validation loss: 1.4649439389987657

Epoch: 6| Step: 11
Training loss: 0.07376249134540558
Validation loss: 1.4763629872311828

Epoch: 6| Step: 12
Training loss: 0.16152460873126984
Validation loss: 1.4529240099332665

Epoch: 6| Step: 13
Training loss: 0.06169995293021202
Validation loss: 1.4398894489452403

Epoch: 520| Step: 0
Training loss: 0.05813562124967575
Validation loss: 1.4365063418624222

Epoch: 6| Step: 1
Training loss: 0.1337425708770752
Validation loss: 1.4742118068920669

Epoch: 6| Step: 2
Training loss: 0.17886683344841003
Validation loss: 1.4525913166743454

Epoch: 6| Step: 3
Training loss: 0.07511006295681
Validation loss: 1.4610881568283163

Epoch: 6| Step: 4
Training loss: 0.0406663604080677
Validation loss: 1.4759932903833286

Epoch: 6| Step: 5
Training loss: 0.06276968866586685
Validation loss: 1.46447330264635

Epoch: 6| Step: 6
Training loss: 0.04895820468664169
Validation loss: 1.4567232055048789

Epoch: 6| Step: 7
Training loss: 0.0534481406211853
Validation loss: 1.4758079744154406

Epoch: 6| Step: 8
Training loss: 0.08582460880279541
Validation loss: 1.4654829540560323

Epoch: 6| Step: 9
Training loss: 0.08628124743700027
Validation loss: 1.4618257104709584

Epoch: 6| Step: 10
Training loss: 0.0883011519908905
Validation loss: 1.4659876438879198

Epoch: 6| Step: 11
Training loss: 0.06872652471065521
Validation loss: 1.4816643973832488

Epoch: 6| Step: 12
Training loss: 0.06870245933532715
Validation loss: 1.4831110835075378

Epoch: 6| Step: 13
Training loss: 0.11805910617113113
Validation loss: 1.4648313419793242

Epoch: 521| Step: 0
Training loss: 0.09553585946559906
Validation loss: 1.4643989647588422

Epoch: 6| Step: 1
Training loss: 0.07162731140851974
Validation loss: 1.4796986451712988

Epoch: 6| Step: 2
Training loss: 0.14661841094493866
Validation loss: 1.4528565816981818

Epoch: 6| Step: 3
Training loss: 0.19322127103805542
Validation loss: 1.4575870806171047

Epoch: 6| Step: 4
Training loss: 0.0540710911154747
Validation loss: 1.4510813848946684

Epoch: 6| Step: 5
Training loss: 0.08216806501150131
Validation loss: 1.4539590817625805

Epoch: 6| Step: 6
Training loss: 0.07144984602928162
Validation loss: 1.4594120517853768

Epoch: 6| Step: 7
Training loss: 0.06743350625038147
Validation loss: 1.4507970092117146

Epoch: 6| Step: 8
Training loss: 0.058402977883815765
Validation loss: 1.4220570313033236

Epoch: 6| Step: 9
Training loss: 0.09276720136404037
Validation loss: 1.4221919941645798

Epoch: 6| Step: 10
Training loss: 0.08566266298294067
Validation loss: 1.4141182156019314

Epoch: 6| Step: 11
Training loss: 0.051678016781806946
Validation loss: 1.4019143209662488

Epoch: 6| Step: 12
Training loss: 0.0862874984741211
Validation loss: 1.3985719360331053

Epoch: 6| Step: 13
Training loss: 0.1011626198887825
Validation loss: 1.4225338159068939

Epoch: 522| Step: 0
Training loss: 0.13616377115249634
Validation loss: 1.4179975672434735

Epoch: 6| Step: 1
Training loss: 0.0412488728761673
Validation loss: 1.443823718255566

Epoch: 6| Step: 2
Training loss: 0.17027266323566437
Validation loss: 1.4663296258577736

Epoch: 6| Step: 3
Training loss: 0.14891363680362701
Validation loss: 1.4417939327096427

Epoch: 6| Step: 4
Training loss: 0.061484936624765396
Validation loss: 1.4511612781914331

Epoch: 6| Step: 5
Training loss: 0.07572054862976074
Validation loss: 1.4396963196416055

Epoch: 6| Step: 6
Training loss: 0.07655611634254456
Validation loss: 1.41223689112612

Epoch: 6| Step: 7
Training loss: 0.07945075631141663
Validation loss: 1.4125186929138758

Epoch: 6| Step: 8
Training loss: 0.08661200106143951
Validation loss: 1.4516542483401556

Epoch: 6| Step: 9
Training loss: 0.09169621020555496
Validation loss: 1.4451938803477953

Epoch: 6| Step: 10
Training loss: 0.10533034801483154
Validation loss: 1.4482145306243692

Epoch: 6| Step: 11
Training loss: 0.062085628509521484
Validation loss: 1.4227328877295218

Epoch: 6| Step: 12
Training loss: 0.06274015456438065
Validation loss: 1.4373997680602535

Epoch: 6| Step: 13
Training loss: 0.10634876787662506
Validation loss: 1.4227299485155331

Epoch: 523| Step: 0
Training loss: 0.046827204525470734
Validation loss: 1.424429702502425

Epoch: 6| Step: 1
Training loss: 0.07399186491966248
Validation loss: 1.436214764912923

Epoch: 6| Step: 2
Training loss: 0.13350006937980652
Validation loss: 1.450707894499584

Epoch: 6| Step: 3
Training loss: 0.04502330720424652
Validation loss: 1.4413084676188808

Epoch: 6| Step: 4
Training loss: 0.05718952789902687
Validation loss: 1.4563229417288175

Epoch: 6| Step: 5
Training loss: 0.05383838713169098
Validation loss: 1.4508590018877419

Epoch: 6| Step: 6
Training loss: 0.05841229110956192
Validation loss: 1.4770265612550961

Epoch: 6| Step: 7
Training loss: 0.07206743210554123
Validation loss: 1.4744574228922527

Epoch: 6| Step: 8
Training loss: 0.11036819219589233
Validation loss: 1.473197546697432

Epoch: 6| Step: 9
Training loss: 0.06741681694984436
Validation loss: 1.4751376362257107

Epoch: 6| Step: 10
Training loss: 0.07011932134628296
Validation loss: 1.465663726611804

Epoch: 6| Step: 11
Training loss: 0.19989334046840668
Validation loss: 1.4753222542424356

Epoch: 6| Step: 12
Training loss: 0.11171560734510422
Validation loss: 1.4748319887345838

Epoch: 6| Step: 13
Training loss: 0.07269484549760818
Validation loss: 1.450839283645794

Epoch: 524| Step: 0
Training loss: 0.09378720819950104
Validation loss: 1.4376914770372453

Epoch: 6| Step: 1
Training loss: 0.14923107624053955
Validation loss: 1.454754399996932

Epoch: 6| Step: 2
Training loss: 0.06079547107219696
Validation loss: 1.4488452442230717

Epoch: 6| Step: 3
Training loss: 0.13062641024589539
Validation loss: 1.4503434153013333

Epoch: 6| Step: 4
Training loss: 0.06128271669149399
Validation loss: 1.46468053197348

Epoch: 6| Step: 5
Training loss: 0.06515978276729584
Validation loss: 1.4418475858626827

Epoch: 6| Step: 6
Training loss: 0.07849584519863129
Validation loss: 1.4266453968581332

Epoch: 6| Step: 7
Training loss: 0.028209568932652473
Validation loss: 1.4291799267133076

Epoch: 6| Step: 8
Training loss: 0.04517117887735367
Validation loss: 1.4515211787275089

Epoch: 6| Step: 9
Training loss: 0.06831496953964233
Validation loss: 1.445684899565994

Epoch: 6| Step: 10
Training loss: 0.07213422656059265
Validation loss: 1.4352267865211732

Epoch: 6| Step: 11
Training loss: 0.09723949432373047
Validation loss: 1.4630892340854933

Epoch: 6| Step: 12
Training loss: 0.07815216481685638
Validation loss: 1.4708025699020715

Epoch: 6| Step: 13
Training loss: 0.0441608689725399
Validation loss: 1.456254852715359

Epoch: 525| Step: 0
Training loss: 0.07152417302131653
Validation loss: 1.4453270281514814

Epoch: 6| Step: 1
Training loss: 0.046163346618413925
Validation loss: 1.4767184911235687

Epoch: 6| Step: 2
Training loss: 0.05541490390896797
Validation loss: 1.4781208307512346

Epoch: 6| Step: 3
Training loss: 0.08018648624420166
Validation loss: 1.4947830092522405

Epoch: 6| Step: 4
Training loss: 0.09821134805679321
Validation loss: 1.4817801162760744

Epoch: 6| Step: 5
Training loss: 0.07990895211696625
Validation loss: 1.4882649298637145

Epoch: 6| Step: 6
Training loss: 0.07274334132671356
Validation loss: 1.4752212621832406

Epoch: 6| Step: 7
Training loss: 0.09008768945932388
Validation loss: 1.4791464203147477

Epoch: 6| Step: 8
Training loss: 0.07200079411268234
Validation loss: 1.491465469842316

Epoch: 6| Step: 9
Training loss: 0.22454631328582764
Validation loss: 1.469027296189339

Epoch: 6| Step: 10
Training loss: 0.08689957112073898
Validation loss: 1.4933915292063067

Epoch: 6| Step: 11
Training loss: 0.04990262910723686
Validation loss: 1.4674141765922628

Epoch: 6| Step: 12
Training loss: 0.10394173860549927
Validation loss: 1.4943375241371892

Epoch: 6| Step: 13
Training loss: 0.07823005318641663
Validation loss: 1.481978206224339

Epoch: 526| Step: 0
Training loss: 0.10785147547721863
Validation loss: 1.4658497148944485

Epoch: 6| Step: 1
Training loss: 0.1497209370136261
Validation loss: 1.4629807523501817

Epoch: 6| Step: 2
Training loss: 0.08148889243602753
Validation loss: 1.4612299652509793

Epoch: 6| Step: 3
Training loss: 0.09289346635341644
Validation loss: 1.442959088151173

Epoch: 6| Step: 4
Training loss: 0.07606150954961777
Validation loss: 1.4584157338706396

Epoch: 6| Step: 5
Training loss: 0.08027118444442749
Validation loss: 1.4317637041050901

Epoch: 6| Step: 6
Training loss: 0.07565914839506149
Validation loss: 1.4447486080149168

Epoch: 6| Step: 7
Training loss: 0.08178677409887314
Validation loss: 1.4357328543099024

Epoch: 6| Step: 8
Training loss: 0.08743482828140259
Validation loss: 1.452544484087216

Epoch: 6| Step: 9
Training loss: 0.06778150796890259
Validation loss: 1.4223406750668761

Epoch: 6| Step: 10
Training loss: 0.06837420910596848
Validation loss: 1.4327408908515848

Epoch: 6| Step: 11
Training loss: 0.045117247849702835
Validation loss: 1.4380093748851488

Epoch: 6| Step: 12
Training loss: 0.16624942421913147
Validation loss: 1.4312493698571318

Epoch: 6| Step: 13
Training loss: 0.09574207663536072
Validation loss: 1.4186930086023064

Epoch: 527| Step: 0
Training loss: 0.07351301610469818
Validation loss: 1.3981284262031637

Epoch: 6| Step: 1
Training loss: 0.1518370509147644
Validation loss: 1.3810841652654833

Epoch: 6| Step: 2
Training loss: 0.07507076114416122
Validation loss: 1.405657752867668

Epoch: 6| Step: 3
Training loss: 0.06989528238773346
Validation loss: 1.3934491347241145

Epoch: 6| Step: 4
Training loss: 0.07367198169231415
Validation loss: 1.3708378191917174

Epoch: 6| Step: 5
Training loss: 0.06402339786291122
Validation loss: 1.3851077351518857

Epoch: 6| Step: 6
Training loss: 0.08123505115509033
Validation loss: 1.4012757161612153

Epoch: 6| Step: 7
Training loss: 0.1061374694108963
Validation loss: 1.3905754691811019

Epoch: 6| Step: 8
Training loss: 0.10840187966823578
Validation loss: 1.4064999921347505

Epoch: 6| Step: 9
Training loss: 0.06204335018992424
Validation loss: 1.4012984665491248

Epoch: 6| Step: 10
Training loss: 0.06283790618181229
Validation loss: 1.4245374343728507

Epoch: 6| Step: 11
Training loss: 0.13051512837409973
Validation loss: 1.4405717478003552

Epoch: 6| Step: 12
Training loss: 0.10251295566558838
Validation loss: 1.4460853902242516

Epoch: 6| Step: 13
Training loss: 0.09526146948337555
Validation loss: 1.434319100072307

Epoch: 528| Step: 0
Training loss: 0.07849999517202377
Validation loss: 1.423779535037215

Epoch: 6| Step: 1
Training loss: 0.06259211152791977
Validation loss: 1.4284126245847313

Epoch: 6| Step: 2
Training loss: 0.1039862185716629
Validation loss: 1.4514699071966193

Epoch: 6| Step: 3
Training loss: 0.17702428996562958
Validation loss: 1.4420566712656329

Epoch: 6| Step: 4
Training loss: 0.0708664208650589
Validation loss: 1.4577907516110329

Epoch: 6| Step: 5
Training loss: 0.11076461523771286
Validation loss: 1.4381752014160156

Epoch: 6| Step: 6
Training loss: 0.0932077169418335
Validation loss: 1.4408545788898264

Epoch: 6| Step: 7
Training loss: 0.05397045984864235
Validation loss: 1.4509323630281674

Epoch: 6| Step: 8
Training loss: 0.07349753379821777
Validation loss: 1.4259758674970238

Epoch: 6| Step: 9
Training loss: 0.09218361973762512
Validation loss: 1.4594813290462698

Epoch: 6| Step: 10
Training loss: 0.10792697966098785
Validation loss: 1.4691854215437365

Epoch: 6| Step: 11
Training loss: 0.19910717010498047
Validation loss: 1.441248925783301

Epoch: 6| Step: 12
Training loss: 0.06142818182706833
Validation loss: 1.4343389618781306

Epoch: 6| Step: 13
Training loss: 0.10604986548423767
Validation loss: 1.4620984843982163

Epoch: 529| Step: 0
Training loss: 0.0874592512845993
Validation loss: 1.422888543016167

Epoch: 6| Step: 1
Training loss: 0.10661198198795319
Validation loss: 1.4728006714133806

Epoch: 6| Step: 2
Training loss: 0.10570019483566284
Validation loss: 1.4597165379472958

Epoch: 6| Step: 3
Training loss: 0.14868462085723877
Validation loss: 1.4208638450150848

Epoch: 6| Step: 4
Training loss: 0.06453776359558105
Validation loss: 1.4594652281012586

Epoch: 6| Step: 5
Training loss: 0.1576153188943863
Validation loss: 1.4387708863904398

Epoch: 6| Step: 6
Training loss: 0.09875594079494476
Validation loss: 1.4381377299626668

Epoch: 6| Step: 7
Training loss: 0.07390043139457703
Validation loss: 1.4059994259188253

Epoch: 6| Step: 8
Training loss: 0.08453354239463806
Validation loss: 1.4103223751950007

Epoch: 6| Step: 9
Training loss: 0.08570901304483414
Validation loss: 1.4186064940626903

Epoch: 6| Step: 10
Training loss: 0.07051984965801239
Validation loss: 1.3891158642307404

Epoch: 6| Step: 11
Training loss: 0.07372839003801346
Validation loss: 1.4155470145645963

Epoch: 6| Step: 12
Training loss: 0.08040471374988556
Validation loss: 1.4064036518014886

Epoch: 6| Step: 13
Training loss: 0.05028560385107994
Validation loss: 1.4141464009079883

Epoch: 530| Step: 0
Training loss: 0.11642260104417801
Validation loss: 1.410681422038745

Epoch: 6| Step: 1
Training loss: 0.08844397962093353
Validation loss: 1.4432320787060646

Epoch: 6| Step: 2
Training loss: 0.13990992307662964
Validation loss: 1.4174858863635729

Epoch: 6| Step: 3
Training loss: 0.08913066983222961
Validation loss: 1.405741205779455

Epoch: 6| Step: 4
Training loss: 0.07306976616382599
Validation loss: 1.4333993145214614

Epoch: 6| Step: 5
Training loss: 0.17928016185760498
Validation loss: 1.4319459270405512

Epoch: 6| Step: 6
Training loss: 0.1652815341949463
Validation loss: 1.4339462057236703

Epoch: 6| Step: 7
Training loss: 0.0576888844370842
Validation loss: 1.419852707334744

Epoch: 6| Step: 8
Training loss: 0.07145702093839645
Validation loss: 1.4227271387653966

Epoch: 6| Step: 9
Training loss: 0.11828334629535675
Validation loss: 1.4114966469426309

Epoch: 6| Step: 10
Training loss: 0.10137949883937836
Validation loss: 1.4658331435213807

Epoch: 6| Step: 11
Training loss: 0.08699330687522888
Validation loss: 1.4350668666183308

Epoch: 6| Step: 12
Training loss: 0.08718391507863998
Validation loss: 1.4504545504047024

Epoch: 6| Step: 13
Training loss: 0.10639593005180359
Validation loss: 1.431583123822366

Epoch: 531| Step: 0
Training loss: 0.0647178441286087
Validation loss: 1.425426007598959

Epoch: 6| Step: 1
Training loss: 0.16001766920089722
Validation loss: 1.4158536330346139

Epoch: 6| Step: 2
Training loss: 0.06404902040958405
Validation loss: 1.4112717272132955

Epoch: 6| Step: 3
Training loss: 0.09191573411226273
Validation loss: 1.411802839207393

Epoch: 6| Step: 4
Training loss: 0.0702059417963028
Validation loss: 1.3978868248642131

Epoch: 6| Step: 5
Training loss: 0.07865922152996063
Validation loss: 1.3883503239641908

Epoch: 6| Step: 6
Training loss: 0.07130366563796997
Validation loss: 1.4273319577658048

Epoch: 6| Step: 7
Training loss: 0.07094283401966095
Validation loss: 1.4093369213483666

Epoch: 6| Step: 8
Training loss: 0.1384708732366562
Validation loss: 1.428568277307736

Epoch: 6| Step: 9
Training loss: 0.08142223954200745
Validation loss: 1.4437315092291882

Epoch: 6| Step: 10
Training loss: 0.09859782457351685
Validation loss: 1.462762281458865

Epoch: 6| Step: 11
Training loss: 0.07334501296281815
Validation loss: 1.440780048729271

Epoch: 6| Step: 12
Training loss: 0.07459291070699692
Validation loss: 1.4265281923355595

Epoch: 6| Step: 13
Training loss: 0.06940256059169769
Validation loss: 1.41855614800607

Epoch: 532| Step: 0
Training loss: 0.06742487847805023
Validation loss: 1.4006611621508034

Epoch: 6| Step: 1
Training loss: 0.06640316545963287
Validation loss: 1.400988317305042

Epoch: 6| Step: 2
Training loss: 0.10071985423564911
Validation loss: 1.3851568384837079

Epoch: 6| Step: 3
Training loss: 0.093544602394104
Validation loss: 1.387366150015144

Epoch: 6| Step: 4
Training loss: 0.08311241865158081
Validation loss: 1.4000681407989994

Epoch: 6| Step: 5
Training loss: 0.11355330049991608
Validation loss: 1.4109417661543815

Epoch: 6| Step: 6
Training loss: 0.08832612633705139
Validation loss: 1.4121414064079203

Epoch: 6| Step: 7
Training loss: 0.05381125211715698
Validation loss: 1.4116041673127042

Epoch: 6| Step: 8
Training loss: 0.2078549563884735
Validation loss: 1.3860623118697957

Epoch: 6| Step: 9
Training loss: 0.06649184226989746
Validation loss: 1.4602955079847766

Epoch: 6| Step: 10
Training loss: 0.09666410088539124
Validation loss: 1.4558064732500302

Epoch: 6| Step: 11
Training loss: 0.11331252753734589
Validation loss: 1.4511216968618414

Epoch: 6| Step: 12
Training loss: 0.1055852621793747
Validation loss: 1.4445797730517644

Epoch: 6| Step: 13
Training loss: 0.05645787715911865
Validation loss: 1.4236973729184879

Epoch: 533| Step: 0
Training loss: 0.07961389422416687
Validation loss: 1.4159687142218313

Epoch: 6| Step: 1
Training loss: 0.06004860997200012
Validation loss: 1.4123851009594497

Epoch: 6| Step: 2
Training loss: 0.05013677850365639
Validation loss: 1.375277183389151

Epoch: 6| Step: 3
Training loss: 0.19605612754821777
Validation loss: 1.3515900469595385

Epoch: 6| Step: 4
Training loss: 0.14705362915992737
Validation loss: 1.3698251837043351

Epoch: 6| Step: 5
Training loss: 0.11579024791717529
Validation loss: 1.3729735061686525

Epoch: 6| Step: 6
Training loss: 0.06666649878025055
Validation loss: 1.363739428981658

Epoch: 6| Step: 7
Training loss: 0.060334462672472
Validation loss: 1.3827218560762302

Epoch: 6| Step: 8
Training loss: 0.06119685620069504
Validation loss: 1.3722747641225015

Epoch: 6| Step: 9
Training loss: 0.07386385649442673
Validation loss: 1.3922037360488728

Epoch: 6| Step: 10
Training loss: 0.09522636979818344
Validation loss: 1.4247229842729465

Epoch: 6| Step: 11
Training loss: 0.054648660123348236
Validation loss: 1.4147640633326706

Epoch: 6| Step: 12
Training loss: 0.1084141880273819
Validation loss: 1.4222504861893193

Epoch: 6| Step: 13
Training loss: 0.08463137596845627
Validation loss: 1.4278936668108868

Epoch: 534| Step: 0
Training loss: 0.0892070010304451
Validation loss: 1.4123373326434885

Epoch: 6| Step: 1
Training loss: 0.11826792359352112
Validation loss: 1.4289977614597609

Epoch: 6| Step: 2
Training loss: 0.20014281570911407
Validation loss: 1.3969360743799517

Epoch: 6| Step: 3
Training loss: 0.11353114247322083
Validation loss: 1.3919213843602005

Epoch: 6| Step: 4
Training loss: 0.13498656451702118
Validation loss: 1.3826024596409132

Epoch: 6| Step: 5
Training loss: 0.0906287282705307
Validation loss: 1.3806872867768811

Epoch: 6| Step: 6
Training loss: 0.11371377110481262
Validation loss: 1.4163746128800094

Epoch: 6| Step: 7
Training loss: 0.08676785975694656
Validation loss: 1.4142997892954017

Epoch: 6| Step: 8
Training loss: 0.11752273142337799
Validation loss: 1.446218982819588

Epoch: 6| Step: 9
Training loss: 0.15259584784507751
Validation loss: 1.4543799905366794

Epoch: 6| Step: 10
Training loss: 0.07123906910419464
Validation loss: 1.421420548551826

Epoch: 6| Step: 11
Training loss: 0.091025710105896
Validation loss: 1.473304731871492

Epoch: 6| Step: 12
Training loss: 0.10476440191268921
Validation loss: 1.5017337593981015

Epoch: 6| Step: 13
Training loss: 0.11428940296173096
Validation loss: 1.5006073726120817

Epoch: 535| Step: 0
Training loss: 0.10284323990345001
Validation loss: 1.5244087749911892

Epoch: 6| Step: 1
Training loss: 0.11795860528945923
Validation loss: 1.4832313445306593

Epoch: 6| Step: 2
Training loss: 0.10074060410261154
Validation loss: 1.4977772043597313

Epoch: 6| Step: 3
Training loss: 0.09512747079133987
Validation loss: 1.4761903747435539

Epoch: 6| Step: 4
Training loss: 0.1883365511894226
Validation loss: 1.4663773352100002

Epoch: 6| Step: 5
Training loss: 0.0830230563879013
Validation loss: 1.4364162516850296

Epoch: 6| Step: 6
Training loss: 0.08209066092967987
Validation loss: 1.4213149983395812

Epoch: 6| Step: 7
Training loss: 0.18129703402519226
Validation loss: 1.4397317504370084

Epoch: 6| Step: 8
Training loss: 0.10542089492082596
Validation loss: 1.4377719945805048

Epoch: 6| Step: 9
Training loss: 0.09667426347732544
Validation loss: 1.440957816698218

Epoch: 6| Step: 10
Training loss: 0.12335938215255737
Validation loss: 1.426376481210032

Epoch: 6| Step: 11
Training loss: 0.10806046426296234
Validation loss: 1.4178040873619817

Epoch: 6| Step: 12
Training loss: 0.07406400889158249
Validation loss: 1.3967395059524044

Epoch: 6| Step: 13
Training loss: 0.13893252611160278
Validation loss: 1.3687583208084106

Epoch: 536| Step: 0
Training loss: 0.06578860431909561
Validation loss: 1.3691658845511816

Epoch: 6| Step: 1
Training loss: 0.09576252102851868
Validation loss: 1.3663006828677269

Epoch: 6| Step: 2
Training loss: 0.11414168030023575
Validation loss: 1.3388008648349392

Epoch: 6| Step: 3
Training loss: 0.08654456585645676
Validation loss: 1.3719646494875672

Epoch: 6| Step: 4
Training loss: 0.17046622931957245
Validation loss: 1.3800737934727823

Epoch: 6| Step: 5
Training loss: 0.10499162971973419
Validation loss: 1.3936908424541514

Epoch: 6| Step: 6
Training loss: 0.09358437359333038
Validation loss: 1.4106046486926336

Epoch: 6| Step: 7
Training loss: 0.045457035303115845
Validation loss: 1.3898484219786942

Epoch: 6| Step: 8
Training loss: 0.07891703397035599
Validation loss: 1.42164086398258

Epoch: 6| Step: 9
Training loss: 0.13478566706180573
Validation loss: 1.4078635579796248

Epoch: 6| Step: 10
Training loss: 0.15508529543876648
Validation loss: 1.4219911162571242

Epoch: 6| Step: 11
Training loss: 0.07515846937894821
Validation loss: 1.4103046335199827

Epoch: 6| Step: 12
Training loss: 0.11134905368089676
Validation loss: 1.3869517798064857

Epoch: 6| Step: 13
Training loss: 0.04077419638633728
Validation loss: 1.3789251581315072

Epoch: 537| Step: 0
Training loss: 0.09441390633583069
Validation loss: 1.4105313413886613

Epoch: 6| Step: 1
Training loss: 0.0686722919344902
Validation loss: 1.4075908724979689

Epoch: 6| Step: 2
Training loss: 0.11213614046573639
Validation loss: 1.4118027007707985

Epoch: 6| Step: 3
Training loss: 0.07642163336277008
Validation loss: 1.4060090549530522

Epoch: 6| Step: 4
Training loss: 0.09777480363845825
Validation loss: 1.4189238612369826

Epoch: 6| Step: 5
Training loss: 0.07198920845985413
Validation loss: 1.400944076558595

Epoch: 6| Step: 6
Training loss: 0.12966333329677582
Validation loss: 1.442325508722695

Epoch: 6| Step: 7
Training loss: 0.06610152125358582
Validation loss: 1.4511103630065918

Epoch: 6| Step: 8
Training loss: 0.12450284510850906
Validation loss: 1.4606612779760872

Epoch: 6| Step: 9
Training loss: 0.08533874154090881
Validation loss: 1.4858914459905317

Epoch: 6| Step: 10
Training loss: 0.06300804764032364
Validation loss: 1.4858512442599061

Epoch: 6| Step: 11
Training loss: 0.05204208567738533
Validation loss: 1.4780468235733688

Epoch: 6| Step: 12
Training loss: 0.1552487015724182
Validation loss: 1.4603009211119784

Epoch: 6| Step: 13
Training loss: 0.0855269804596901
Validation loss: 1.4501414798921155

Epoch: 538| Step: 0
Training loss: 0.05297254025936127
Validation loss: 1.4452823733770719

Epoch: 6| Step: 1
Training loss: 0.10239695757627487
Validation loss: 1.42320881735894

Epoch: 6| Step: 2
Training loss: 0.09344944357872009
Validation loss: 1.403107455981675

Epoch: 6| Step: 3
Training loss: 0.05203267186880112
Validation loss: 1.3901469784398233

Epoch: 6| Step: 4
Training loss: 0.18938663601875305
Validation loss: 1.3816335803718978

Epoch: 6| Step: 5
Training loss: 0.11521293222904205
Validation loss: 1.378186595055365

Epoch: 6| Step: 6
Training loss: 0.12827950716018677
Validation loss: 1.3723236412130377

Epoch: 6| Step: 7
Training loss: 0.17169272899627686
Validation loss: 1.3758637014255728

Epoch: 6| Step: 8
Training loss: 0.06559033691883087
Validation loss: 1.3845421960276942

Epoch: 6| Step: 9
Training loss: 0.06968304514884949
Validation loss: 1.4029349537305935

Epoch: 6| Step: 10
Training loss: 0.07698319852352142
Validation loss: 1.4196054063817507

Epoch: 6| Step: 11
Training loss: 0.09423676878213882
Validation loss: 1.4532015797912434

Epoch: 6| Step: 12
Training loss: 0.10781201720237732
Validation loss: 1.4601191666818434

Epoch: 6| Step: 13
Training loss: 0.0775860846042633
Validation loss: 1.4624641236438547

Epoch: 539| Step: 0
Training loss: 0.06441286951303482
Validation loss: 1.462097906297253

Epoch: 6| Step: 1
Training loss: 0.1787392795085907
Validation loss: 1.4578498973641345

Epoch: 6| Step: 2
Training loss: 0.04020024836063385
Validation loss: 1.4804423727015013

Epoch: 6| Step: 3
Training loss: 0.13850393891334534
Validation loss: 1.4620897282836258

Epoch: 6| Step: 4
Training loss: 0.10030094534158707
Validation loss: 1.4656914613580192

Epoch: 6| Step: 5
Training loss: 0.09528063237667084
Validation loss: 1.494376729893428

Epoch: 6| Step: 6
Training loss: 0.12773318588733673
Validation loss: 1.509150226910909

Epoch: 6| Step: 7
Training loss: 0.08724512904882431
Validation loss: 1.504494329934479

Epoch: 6| Step: 8
Training loss: 0.12262671440839767
Validation loss: 1.5156112460679905

Epoch: 6| Step: 9
Training loss: 0.09236353635787964
Validation loss: 1.4927693361877112

Epoch: 6| Step: 10
Training loss: 0.08872481435537338
Validation loss: 1.4618578623699885

Epoch: 6| Step: 11
Training loss: 0.09268778562545776
Validation loss: 1.4870359730976883

Epoch: 6| Step: 12
Training loss: 0.09128990024328232
Validation loss: 1.4700868334821475

Epoch: 6| Step: 13
Training loss: 0.11033608019351959
Validation loss: 1.4681780658742434

Epoch: 540| Step: 0
Training loss: 0.07313874363899231
Validation loss: 1.462619799439625

Epoch: 6| Step: 1
Training loss: 0.13878808915615082
Validation loss: 1.4825498032313522

Epoch: 6| Step: 2
Training loss: 0.06165529042482376
Validation loss: 1.4486814718092642

Epoch: 6| Step: 3
Training loss: 0.06761033087968826
Validation loss: 1.4573607739581858

Epoch: 6| Step: 4
Training loss: 0.1056029200553894
Validation loss: 1.4316497720697874

Epoch: 6| Step: 5
Training loss: 0.05106198042631149
Validation loss: 1.4261522728909728

Epoch: 6| Step: 6
Training loss: 0.0838390439748764
Validation loss: 1.4357094572436424

Epoch: 6| Step: 7
Training loss: 0.07341037690639496
Validation loss: 1.4035183024662796

Epoch: 6| Step: 8
Training loss: 0.14325043559074402
Validation loss: 1.4552998491512832

Epoch: 6| Step: 9
Training loss: 0.13368558883666992
Validation loss: 1.4325448389976256

Epoch: 6| Step: 10
Training loss: 0.08249662816524506
Validation loss: 1.4208415400597356

Epoch: 6| Step: 11
Training loss: 0.0894947201013565
Validation loss: 1.4400548204298942

Epoch: 6| Step: 12
Training loss: 0.1355549842119217
Validation loss: 1.426768809236506

Epoch: 6| Step: 13
Training loss: 0.14687012135982513
Validation loss: 1.4303817351659138

Epoch: 541| Step: 0
Training loss: 0.12267088890075684
Validation loss: 1.4548493328914847

Epoch: 6| Step: 1
Training loss: 0.05163697898387909
Validation loss: 1.4728359714631112

Epoch: 6| Step: 2
Training loss: 0.07867591083049774
Validation loss: 1.4838873545328777

Epoch: 6| Step: 3
Training loss: 0.07006888836622238
Validation loss: 1.4661881462220223

Epoch: 6| Step: 4
Training loss: 0.08642707020044327
Validation loss: 1.475408774550243

Epoch: 6| Step: 5
Training loss: 0.079013392329216
Validation loss: 1.4327453310771654

Epoch: 6| Step: 6
Training loss: 0.08383070677518845
Validation loss: 1.4474148916941818

Epoch: 6| Step: 7
Training loss: 0.08045703172683716
Validation loss: 1.4105243913588985

Epoch: 6| Step: 8
Training loss: 0.12383507192134857
Validation loss: 1.416847973741511

Epoch: 6| Step: 9
Training loss: 0.08819285780191422
Validation loss: 1.4274573749111545

Epoch: 6| Step: 10
Training loss: 0.0775105282664299
Validation loss: 1.4215878068759877

Epoch: 6| Step: 11
Training loss: 0.15763193368911743
Validation loss: 1.4159346767651138

Epoch: 6| Step: 12
Training loss: 0.054589610546827316
Validation loss: 1.43278411639634

Epoch: 6| Step: 13
Training loss: 0.05061252787709236
Validation loss: 1.4364846726899505

Epoch: 542| Step: 0
Training loss: 0.13302063941955566
Validation loss: 1.4358249518179125

Epoch: 6| Step: 1
Training loss: 0.04684622585773468
Validation loss: 1.4640406408617574

Epoch: 6| Step: 2
Training loss: 0.04984913766384125
Validation loss: 1.4459719439988494

Epoch: 6| Step: 3
Training loss: 0.07677700370550156
Validation loss: 1.4616464671268259

Epoch: 6| Step: 4
Training loss: 0.09809167683124542
Validation loss: 1.4665923580046623

Epoch: 6| Step: 5
Training loss: 0.11896975338459015
Validation loss: 1.4649319616697167

Epoch: 6| Step: 6
Training loss: 0.07659973949193954
Validation loss: 1.4777053722771265

Epoch: 6| Step: 7
Training loss: 0.05807119607925415
Validation loss: 1.4578107621080132

Epoch: 6| Step: 8
Training loss: 0.07626352459192276
Validation loss: 1.449855730097781

Epoch: 6| Step: 9
Training loss: 0.056427083909511566
Validation loss: 1.4402446516098515

Epoch: 6| Step: 10
Training loss: 0.05986517667770386
Validation loss: 1.4143307837106849

Epoch: 6| Step: 11
Training loss: 0.040228188037872314
Validation loss: 1.4248801777439732

Epoch: 6| Step: 12
Training loss: 0.08161494135856628
Validation loss: 1.3940799723389328

Epoch: 6| Step: 13
Training loss: 0.08978255838155746
Validation loss: 1.4023663126012331

Epoch: 543| Step: 0
Training loss: 0.08572884649038315
Validation loss: 1.4134345451990764

Epoch: 6| Step: 1
Training loss: 0.12919852137565613
Validation loss: 1.3869413034890288

Epoch: 6| Step: 2
Training loss: 0.09209268540143967
Validation loss: 1.3954407604791785

Epoch: 6| Step: 3
Training loss: 0.05098366737365723
Validation loss: 1.4049206754212737

Epoch: 6| Step: 4
Training loss: 0.08094422519207001
Validation loss: 1.4245041326809955

Epoch: 6| Step: 5
Training loss: 0.04578946530818939
Validation loss: 1.4704954021720475

Epoch: 6| Step: 6
Training loss: 0.11040861159563065
Validation loss: 1.4622368069105252

Epoch: 6| Step: 7
Training loss: 0.09091384708881378
Validation loss: 1.4630937935203634

Epoch: 6| Step: 8
Training loss: 0.1158757135272026
Validation loss: 1.471187004479029

Epoch: 6| Step: 9
Training loss: 0.06952045857906342
Validation loss: 1.4664996567592825

Epoch: 6| Step: 10
Training loss: 0.07674382627010345
Validation loss: 1.4750275611877441

Epoch: 6| Step: 11
Training loss: 0.06043720245361328
Validation loss: 1.4523968363320956

Epoch: 6| Step: 12
Training loss: 0.052607953548431396
Validation loss: 1.4503506832225348

Epoch: 6| Step: 13
Training loss: 0.19751054048538208
Validation loss: 1.4461504220962524

Epoch: 544| Step: 0
Training loss: 0.06500677019357681
Validation loss: 1.4397014430774155

Epoch: 6| Step: 1
Training loss: 0.06933823227882385
Validation loss: 1.456153069773028

Epoch: 6| Step: 2
Training loss: 0.08709127455949783
Validation loss: 1.4265006626805952

Epoch: 6| Step: 3
Training loss: 0.05596257001161575
Validation loss: 1.4593005077813261

Epoch: 6| Step: 4
Training loss: 0.04420808330178261
Validation loss: 1.4588574831203749

Epoch: 6| Step: 5
Training loss: 0.13295216858386993
Validation loss: 1.4411260825331493

Epoch: 6| Step: 6
Training loss: 0.06630353629589081
Validation loss: 1.4530706662003712

Epoch: 6| Step: 7
Training loss: 0.06525014340877533
Validation loss: 1.4357195631150277

Epoch: 6| Step: 8
Training loss: 0.07055443525314331
Validation loss: 1.445518724380001

Epoch: 6| Step: 9
Training loss: 0.029597021639347076
Validation loss: 1.4524399067765923

Epoch: 6| Step: 10
Training loss: 0.08240211009979248
Validation loss: 1.4510169054872246

Epoch: 6| Step: 11
Training loss: 0.1342012733221054
Validation loss: 1.4394891454327492

Epoch: 6| Step: 12
Training loss: 0.09726503491401672
Validation loss: 1.4546599772668654

Epoch: 6| Step: 13
Training loss: 0.06413182616233826
Validation loss: 1.4384185524397

Epoch: 545| Step: 0
Training loss: 0.04987706243991852
Validation loss: 1.4337756967031827

Epoch: 6| Step: 1
Training loss: 0.05172888934612274
Validation loss: 1.443159382830384

Epoch: 6| Step: 2
Training loss: 0.07422464340925217
Validation loss: 1.4360248645146687

Epoch: 6| Step: 3
Training loss: 0.19990427792072296
Validation loss: 1.4240522218006912

Epoch: 6| Step: 4
Training loss: 0.0717228353023529
Validation loss: 1.4184081157048543

Epoch: 6| Step: 5
Training loss: 0.11683880537748337
Validation loss: 1.4396588584428192

Epoch: 6| Step: 6
Training loss: 0.07313939929008484
Validation loss: 1.4433298072507303

Epoch: 6| Step: 7
Training loss: 0.0910293236374855
Validation loss: 1.443216141834054

Epoch: 6| Step: 8
Training loss: 0.09836035966873169
Validation loss: 1.4633748249341083

Epoch: 6| Step: 9
Training loss: 0.0857388898730278
Validation loss: 1.4719488005484305

Epoch: 6| Step: 10
Training loss: 0.09428701549768448
Validation loss: 1.4588222157570623

Epoch: 6| Step: 11
Training loss: 0.17471431195735931
Validation loss: 1.4988019530491163

Epoch: 6| Step: 12
Training loss: 0.09297646582126617
Validation loss: 1.491713834065263

Epoch: 6| Step: 13
Training loss: 0.04333299770951271
Validation loss: 1.4816946598791307

Epoch: 546| Step: 0
Training loss: 0.06780371814966202
Validation loss: 1.4962691363467966

Epoch: 6| Step: 1
Training loss: 0.1434992104768753
Validation loss: 1.4919523885173183

Epoch: 6| Step: 2
Training loss: 0.06390144675970078
Validation loss: 1.4709502458572388

Epoch: 6| Step: 3
Training loss: 0.08276067674160004
Validation loss: 1.4558004627945602

Epoch: 6| Step: 4
Training loss: 0.06433835625648499
Validation loss: 1.458355011478547

Epoch: 6| Step: 5
Training loss: 0.082032710313797
Validation loss: 1.4427768767520945

Epoch: 6| Step: 6
Training loss: 0.14673466980457306
Validation loss: 1.4523329786075059

Epoch: 6| Step: 7
Training loss: 0.08955328166484833
Validation loss: 1.432544764652047

Epoch: 6| Step: 8
Training loss: 0.07221522927284241
Validation loss: 1.4651666264380179

Epoch: 6| Step: 9
Training loss: 0.10213619470596313
Validation loss: 1.4368480559318297

Epoch: 6| Step: 10
Training loss: 0.09618912637233734
Validation loss: 1.474009052399666

Epoch: 6| Step: 11
Training loss: 0.07275885343551636
Validation loss: 1.4671638934843

Epoch: 6| Step: 12
Training loss: 0.07210010290145874
Validation loss: 1.4819838693065028

Epoch: 6| Step: 13
Training loss: 0.0737774446606636
Validation loss: 1.5070003207011888

Epoch: 547| Step: 0
Training loss: 0.059777259826660156
Validation loss: 1.4919506785690144

Epoch: 6| Step: 1
Training loss: 0.07139841467142105
Validation loss: 1.4717053610791442

Epoch: 6| Step: 2
Training loss: 0.10666012018918991
Validation loss: 1.4874842570674034

Epoch: 6| Step: 3
Training loss: 0.05885276943445206
Validation loss: 1.4816583651368336

Epoch: 6| Step: 4
Training loss: 0.1272297501564026
Validation loss: 1.4600996419947634

Epoch: 6| Step: 5
Training loss: 0.10328216850757599
Validation loss: 1.4758751879456222

Epoch: 6| Step: 6
Training loss: 0.09137514233589172
Validation loss: 1.4486745480568177

Epoch: 6| Step: 7
Training loss: 0.06812497973442078
Validation loss: 1.4521401082315752

Epoch: 6| Step: 8
Training loss: 0.04164895415306091
Validation loss: 1.4456262614137383

Epoch: 6| Step: 9
Training loss: 0.06786930561065674
Validation loss: 1.4334955343636133

Epoch: 6| Step: 10
Training loss: 0.1232428327202797
Validation loss: 1.4108234118389826

Epoch: 6| Step: 11
Training loss: 0.1667441725730896
Validation loss: 1.4091644889564925

Epoch: 6| Step: 12
Training loss: 0.10171554237604141
Validation loss: 1.4146829958884948

Epoch: 6| Step: 13
Training loss: 0.09713733196258545
Validation loss: 1.4319125862531765

Epoch: 548| Step: 0
Training loss: 0.0923568457365036
Validation loss: 1.4337982631498767

Epoch: 6| Step: 1
Training loss: 0.11203362047672272
Validation loss: 1.4124455067419237

Epoch: 6| Step: 2
Training loss: 0.08361062407493591
Validation loss: 1.4017093848156672

Epoch: 6| Step: 3
Training loss: 0.1035446971654892
Validation loss: 1.4265298670338047

Epoch: 6| Step: 4
Training loss: 0.05716780200600624
Validation loss: 1.4436212239726898

Epoch: 6| Step: 5
Training loss: 0.06665361672639847
Validation loss: 1.4551347737671227

Epoch: 6| Step: 6
Training loss: 0.06997012346982956
Validation loss: 1.444853203271025

Epoch: 6| Step: 7
Training loss: 0.08402600139379501
Validation loss: 1.4666499719824841

Epoch: 6| Step: 8
Training loss: 0.05212292820215225
Validation loss: 1.4533910161705428

Epoch: 6| Step: 9
Training loss: 0.10225575417280197
Validation loss: 1.439802400527462

Epoch: 6| Step: 10
Training loss: 0.07363813370466232
Validation loss: 1.4348350923548463

Epoch: 6| Step: 11
Training loss: 0.048517800867557526
Validation loss: 1.4294143363993654

Epoch: 6| Step: 12
Training loss: 0.1599760800600052
Validation loss: 1.4442642786169564

Epoch: 6| Step: 13
Training loss: 0.12901519238948822
Validation loss: 1.4369590756713704

Epoch: 549| Step: 0
Training loss: 0.1067962571978569
Validation loss: 1.4545592313171716

Epoch: 6| Step: 1
Training loss: 0.13723325729370117
Validation loss: 1.4450947161643737

Epoch: 6| Step: 2
Training loss: 0.0769321620464325
Validation loss: 1.443853311641242

Epoch: 6| Step: 3
Training loss: 0.11209316551685333
Validation loss: 1.4178792763781805

Epoch: 6| Step: 4
Training loss: 0.07537190616130829
Validation loss: 1.4201779455266974

Epoch: 6| Step: 5
Training loss: 0.08084434270858765
Validation loss: 1.4274947066460886

Epoch: 6| Step: 6
Training loss: 0.06578881293535233
Validation loss: 1.4226898429214314

Epoch: 6| Step: 7
Training loss: 0.0866507887840271
Validation loss: 1.432589300217167

Epoch: 6| Step: 8
Training loss: 0.10572165250778198
Validation loss: 1.441666781261403

Epoch: 6| Step: 9
Training loss: 0.07826966047286987
Validation loss: 1.4308923514940406

Epoch: 6| Step: 10
Training loss: 0.04928690195083618
Validation loss: 1.4263598765096357

Epoch: 6| Step: 11
Training loss: 0.11768827587366104
Validation loss: 1.4128226278930582

Epoch: 6| Step: 12
Training loss: 0.08663991093635559
Validation loss: 1.4177415409395773

Epoch: 6| Step: 13
Training loss: 0.040248528122901917
Validation loss: 1.4063483169001918

Epoch: 550| Step: 0
Training loss: 0.08097027242183685
Validation loss: 1.449853543312319

Epoch: 6| Step: 1
Training loss: 0.0685938224196434
Validation loss: 1.4704043346066629

Epoch: 6| Step: 2
Training loss: 0.09129968285560608
Validation loss: 1.4524259003259803

Epoch: 6| Step: 3
Training loss: 0.07215172052383423
Validation loss: 1.4468743916480773

Epoch: 6| Step: 4
Training loss: 0.1425338238477707
Validation loss: 1.4589539586856801

Epoch: 6| Step: 5
Training loss: 0.07754425704479218
Validation loss: 1.4834851295717302

Epoch: 6| Step: 6
Training loss: 0.05758899822831154
Validation loss: 1.4911135588922808

Epoch: 6| Step: 7
Training loss: 0.06774367392063141
Validation loss: 1.478601142924319

Epoch: 6| Step: 8
Training loss: 0.1011752337217331
Validation loss: 1.4868760826767131

Epoch: 6| Step: 9
Training loss: 0.14888343214988708
Validation loss: 1.4678178500103694

Epoch: 6| Step: 10
Training loss: 0.0858154445886612
Validation loss: 1.4633033224331435

Epoch: 6| Step: 11
Training loss: 0.09187226742506027
Validation loss: 1.463358723989097

Epoch: 6| Step: 12
Training loss: 0.05113767087459564
Validation loss: 1.4570428850830242

Epoch: 6| Step: 13
Training loss: 0.0674896091222763
Validation loss: 1.41838502371183

Epoch: 551| Step: 0
Training loss: 0.07621100544929504
Validation loss: 1.3993294982499973

Epoch: 6| Step: 1
Training loss: 0.08935516327619553
Validation loss: 1.3901814132608392

Epoch: 6| Step: 2
Training loss: 0.1364370882511139
Validation loss: 1.3701687423131799

Epoch: 6| Step: 3
Training loss: 0.10286061465740204
Validation loss: 1.3931256968487975

Epoch: 6| Step: 4
Training loss: 0.09249711781740189
Validation loss: 1.392981089571471

Epoch: 6| Step: 5
Training loss: 0.16933463513851166
Validation loss: 1.4413017226803688

Epoch: 6| Step: 6
Training loss: 0.09110745787620544
Validation loss: 1.4339574895879275

Epoch: 6| Step: 7
Training loss: 0.107301265001297
Validation loss: 1.4695738041272728

Epoch: 6| Step: 8
Training loss: 0.06777128577232361
Validation loss: 1.503776587465758

Epoch: 6| Step: 9
Training loss: 0.10674616694450378
Validation loss: 1.5501751386991112

Epoch: 6| Step: 10
Training loss: 0.08698825538158417
Validation loss: 1.5649433610259846

Epoch: 6| Step: 11
Training loss: 0.15950363874435425
Validation loss: 1.5775984205225462

Epoch: 6| Step: 12
Training loss: 0.1894661784172058
Validation loss: 1.5613495995921474

Epoch: 6| Step: 13
Training loss: 0.23824173212051392
Validation loss: 1.5018164906450497

Epoch: 552| Step: 0
Training loss: 0.08003877848386765
Validation loss: 1.4488650701379264

Epoch: 6| Step: 1
Training loss: 0.13694480061531067
Validation loss: 1.4243851502736409

Epoch: 6| Step: 2
Training loss: 0.15044891834259033
Validation loss: 1.4201440170247068

Epoch: 6| Step: 3
Training loss: 0.11870259791612625
Validation loss: 1.4235911279596307

Epoch: 6| Step: 4
Training loss: 0.10184095799922943
Validation loss: 1.3843229278441398

Epoch: 6| Step: 5
Training loss: 0.06790594756603241
Validation loss: 1.4079556067784627

Epoch: 6| Step: 6
Training loss: 0.1546926647424698
Validation loss: 1.404135920668161

Epoch: 6| Step: 7
Training loss: 0.059871647506952286
Validation loss: 1.4057790028151644

Epoch: 6| Step: 8
Training loss: 0.0625639334321022
Validation loss: 1.4467798227904944

Epoch: 6| Step: 9
Training loss: 0.07592155784368515
Validation loss: 1.4243845144907634

Epoch: 6| Step: 10
Training loss: 0.09209975600242615
Validation loss: 1.4492091799295077

Epoch: 6| Step: 11
Training loss: 0.10425303876399994
Validation loss: 1.4770582004259991

Epoch: 6| Step: 12
Training loss: 0.07509766519069672
Validation loss: 1.4742759370034741

Epoch: 6| Step: 13
Training loss: 0.11235842108726501
Validation loss: 1.47641509579074

Epoch: 553| Step: 0
Training loss: 0.11460886895656586
Validation loss: 1.4735572607286516

Epoch: 6| Step: 1
Training loss: 0.0614180862903595
Validation loss: 1.4465778694357923

Epoch: 6| Step: 2
Training loss: 0.07577215135097504
Validation loss: 1.4246650767582718

Epoch: 6| Step: 3
Training loss: 0.09343835711479187
Validation loss: 1.4354590318536247

Epoch: 6| Step: 4
Training loss: 0.1507418155670166
Validation loss: 1.4346993264331613

Epoch: 6| Step: 5
Training loss: 0.1392095386981964
Validation loss: 1.4446901736720916

Epoch: 6| Step: 6
Training loss: 0.16185542941093445
Validation loss: 1.4182741090815554

Epoch: 6| Step: 7
Training loss: 0.09816528111696243
Validation loss: 1.439766357021947

Epoch: 6| Step: 8
Training loss: 0.08925765752792358
Validation loss: 1.4432905309943742

Epoch: 6| Step: 9
Training loss: 0.04338574409484863
Validation loss: 1.4671577356194938

Epoch: 6| Step: 10
Training loss: 0.06748056411743164
Validation loss: 1.481763844848961

Epoch: 6| Step: 11
Training loss: 0.07808095216751099
Validation loss: 1.4759676379542197

Epoch: 6| Step: 12
Training loss: 0.06138061732053757
Validation loss: 1.4650423603673135

Epoch: 6| Step: 13
Training loss: 0.07073965668678284
Validation loss: 1.4736980494632517

Epoch: 554| Step: 0
Training loss: 0.058323703706264496
Validation loss: 1.513433034702014

Epoch: 6| Step: 1
Training loss: 0.09082350134849548
Validation loss: 1.4875496536172845

Epoch: 6| Step: 2
Training loss: 0.1282605230808258
Validation loss: 1.4548678885224045

Epoch: 6| Step: 3
Training loss: 0.12856616079807281
Validation loss: 1.4602966718776251

Epoch: 6| Step: 4
Training loss: 0.04508394002914429
Validation loss: 1.4481926310446955

Epoch: 6| Step: 5
Training loss: 0.09062299132347107
Validation loss: 1.453821566797072

Epoch: 6| Step: 6
Training loss: 0.07953677326440811
Validation loss: 1.4410886943981212

Epoch: 6| Step: 7
Training loss: 0.07363368570804596
Validation loss: 1.4131306691836285

Epoch: 6| Step: 8
Training loss: 0.05395705997943878
Validation loss: 1.4583984357054516

Epoch: 6| Step: 9
Training loss: 0.05262789875268936
Validation loss: 1.4497874603476575

Epoch: 6| Step: 10
Training loss: 0.05243127793073654
Validation loss: 1.4596008510999783

Epoch: 6| Step: 11
Training loss: 0.03512446582317352
Validation loss: 1.4480320304952643

Epoch: 6| Step: 12
Training loss: 0.05345723778009415
Validation loss: 1.4815115928649902

Epoch: 6| Step: 13
Training loss: 0.08981214463710785
Validation loss: 1.490116362930626

Epoch: 555| Step: 0
Training loss: 0.07718492299318314
Validation loss: 1.493704700982699

Epoch: 6| Step: 1
Training loss: 0.12924258410930634
Validation loss: 1.4602897500479093

Epoch: 6| Step: 2
Training loss: 0.05818288400769234
Validation loss: 1.5049983339924966

Epoch: 6| Step: 3
Training loss: 0.042643286287784576
Validation loss: 1.4886786796713387

Epoch: 6| Step: 4
Training loss: 0.05902297794818878
Validation loss: 1.4847431285406953

Epoch: 6| Step: 5
Training loss: 0.04891488701105118
Validation loss: 1.5014588281672487

Epoch: 6| Step: 6
Training loss: 0.054156593978405
Validation loss: 1.49520404108109

Epoch: 6| Step: 7
Training loss: 0.09853541851043701
Validation loss: 1.4561529351818947

Epoch: 6| Step: 8
Training loss: 0.0552869588136673
Validation loss: 1.458573990932075

Epoch: 6| Step: 9
Training loss: 0.07573947310447693
Validation loss: 1.46447632902412

Epoch: 6| Step: 10
Training loss: 0.13649016618728638
Validation loss: 1.4680172281880532

Epoch: 6| Step: 11
Training loss: 0.055231913924217224
Validation loss: 1.4532394357906875

Epoch: 6| Step: 12
Training loss: 0.0658072829246521
Validation loss: 1.4401520657283005

Epoch: 6| Step: 13
Training loss: 0.07940909266471863
Validation loss: 1.3908984776466125

Epoch: 556| Step: 0
Training loss: 0.05297037586569786
Validation loss: 1.4103789983257171

Epoch: 6| Step: 1
Training loss: 0.049408480525016785
Validation loss: 1.409007103212418

Epoch: 6| Step: 2
Training loss: 0.09847226738929749
Validation loss: 1.4196393919247452

Epoch: 6| Step: 3
Training loss: 0.06447122991085052
Validation loss: 1.4156747607774631

Epoch: 6| Step: 4
Training loss: 0.1340698003768921
Validation loss: 1.4176996260560968

Epoch: 6| Step: 5
Training loss: 0.1216646283864975
Validation loss: 1.4258033203822311

Epoch: 6| Step: 6
Training loss: 0.05403518304228783
Validation loss: 1.4586585939571421

Epoch: 6| Step: 7
Training loss: 0.08970371633768082
Validation loss: 1.4594153473454137

Epoch: 6| Step: 8
Training loss: 0.06601671874523163
Validation loss: 1.4576423347637217

Epoch: 6| Step: 9
Training loss: 0.11113975197076797
Validation loss: 1.4759244816277617

Epoch: 6| Step: 10
Training loss: 0.10333184897899628
Validation loss: 1.4620035438127414

Epoch: 6| Step: 11
Training loss: 0.1108541414141655
Validation loss: 1.4778083537214546

Epoch: 6| Step: 12
Training loss: 0.04965794086456299
Validation loss: 1.4493419021688483

Epoch: 6| Step: 13
Training loss: 0.06902355700731277
Validation loss: 1.446774939055084

Epoch: 557| Step: 0
Training loss: 0.07853905111551285
Validation loss: 1.4322868021585609

Epoch: 6| Step: 1
Training loss: 0.11347110569477081
Validation loss: 1.4479209325646842

Epoch: 6| Step: 2
Training loss: 0.052878208458423615
Validation loss: 1.4332705736160278

Epoch: 6| Step: 3
Training loss: 0.0554627850651741
Validation loss: 1.4459267623962895

Epoch: 6| Step: 4
Training loss: 0.15497377514839172
Validation loss: 1.4732549113612021

Epoch: 6| Step: 5
Training loss: 0.0685356855392456
Validation loss: 1.4348281122023059

Epoch: 6| Step: 6
Training loss: 0.0784962922334671
Validation loss: 1.430941451621312

Epoch: 6| Step: 7
Training loss: 0.052707891911268234
Validation loss: 1.4350484353239819

Epoch: 6| Step: 8
Training loss: 0.08562451601028442
Validation loss: 1.4217088799322806

Epoch: 6| Step: 9
Training loss: 0.074656642973423
Validation loss: 1.4380267191958684

Epoch: 6| Step: 10
Training loss: 0.054444819688797
Validation loss: 1.437090245626306

Epoch: 6| Step: 11
Training loss: 0.04928005486726761
Validation loss: 1.4296305743596887

Epoch: 6| Step: 12
Training loss: 0.05858137086033821
Validation loss: 1.4179983690220823

Epoch: 6| Step: 13
Training loss: 0.04639865458011627
Validation loss: 1.4179903089359243

Epoch: 558| Step: 0
Training loss: 0.07379971444606781
Validation loss: 1.4105902461595432

Epoch: 6| Step: 1
Training loss: 0.12003810703754425
Validation loss: 1.3861172840159426

Epoch: 6| Step: 2
Training loss: 0.052109494805336
Validation loss: 1.410632356520622

Epoch: 6| Step: 3
Training loss: 0.08972979336977005
Validation loss: 1.410553942444504

Epoch: 6| Step: 4
Training loss: 0.08447545766830444
Validation loss: 1.4098819840338923

Epoch: 6| Step: 5
Training loss: 0.07191638648509979
Validation loss: 1.4190622350221038

Epoch: 6| Step: 6
Training loss: 0.05649937316775322
Validation loss: 1.412205893506286

Epoch: 6| Step: 7
Training loss: 0.06164149194955826
Validation loss: 1.449281637386609

Epoch: 6| Step: 8
Training loss: 0.16817861795425415
Validation loss: 1.432619156376008

Epoch: 6| Step: 9
Training loss: 0.0766361802816391
Validation loss: 1.435346854630337

Epoch: 6| Step: 10
Training loss: 0.11397581547498703
Validation loss: 1.4468672608816495

Epoch: 6| Step: 11
Training loss: 0.1045793816447258
Validation loss: 1.470881426206199

Epoch: 6| Step: 12
Training loss: 0.0650845393538475
Validation loss: 1.4812769902649747

Epoch: 6| Step: 13
Training loss: 0.08119390904903412
Validation loss: 1.4916908894815752

Epoch: 559| Step: 0
Training loss: 0.048194073140621185
Validation loss: 1.4782778357946744

Epoch: 6| Step: 1
Training loss: 0.1182011142373085
Validation loss: 1.4852553631669732

Epoch: 6| Step: 2
Training loss: 0.06816694140434265
Validation loss: 1.499619262192839

Epoch: 6| Step: 3
Training loss: 0.07019159197807312
Validation loss: 1.4850162383048766

Epoch: 6| Step: 4
Training loss: 0.08579286932945251
Validation loss: 1.497265879825879

Epoch: 6| Step: 5
Training loss: 0.050796203315258026
Validation loss: 1.4699509509148136

Epoch: 6| Step: 6
Training loss: 0.0711565762758255
Validation loss: 1.4595081293454735

Epoch: 6| Step: 7
Training loss: 0.06434056162834167
Validation loss: 1.462685949058943

Epoch: 6| Step: 8
Training loss: 0.09698519110679626
Validation loss: 1.4459847993748163

Epoch: 6| Step: 9
Training loss: 0.17564231157302856
Validation loss: 1.4506805148175967

Epoch: 6| Step: 10
Training loss: 0.09578036516904831
Validation loss: 1.4343597017308718

Epoch: 6| Step: 11
Training loss: 0.10753902047872543
Validation loss: 1.4345505570852628

Epoch: 6| Step: 12
Training loss: 0.0900489017367363
Validation loss: 1.4358010984236194

Epoch: 6| Step: 13
Training loss: 0.13018587231636047
Validation loss: 1.4438166278664784

Epoch: 560| Step: 0
Training loss: 0.08255025744438171
Validation loss: 1.4507509348213032

Epoch: 6| Step: 1
Training loss: 0.10404625535011292
Validation loss: 1.4471993369440879

Epoch: 6| Step: 2
Training loss: 0.11673208326101303
Validation loss: 1.4491989253669657

Epoch: 6| Step: 3
Training loss: 0.059904083609580994
Validation loss: 1.4302909540873703

Epoch: 6| Step: 4
Training loss: 0.0999111533164978
Validation loss: 1.4159308043859338

Epoch: 6| Step: 5
Training loss: 0.15400123596191406
Validation loss: 1.4086764653523762

Epoch: 6| Step: 6
Training loss: 0.08418391644954681
Validation loss: 1.4283758350597915

Epoch: 6| Step: 7
Training loss: 0.09431035816669464
Validation loss: 1.4063805469902613

Epoch: 6| Step: 8
Training loss: 0.07286456972360611
Validation loss: 1.3816069338911323

Epoch: 6| Step: 9
Training loss: 0.06328262388706207
Validation loss: 1.3978876522792283

Epoch: 6| Step: 10
Training loss: 0.10829752683639526
Validation loss: 1.4115898647615988

Epoch: 6| Step: 11
Training loss: 0.07311990112066269
Validation loss: 1.383350323605281

Epoch: 6| Step: 12
Training loss: 0.06141301244497299
Validation loss: 1.4186534394500077

Epoch: 6| Step: 13
Training loss: 0.08190417289733887
Validation loss: 1.3945682510252921

Epoch: 561| Step: 0
Training loss: 0.08559739589691162
Validation loss: 1.4197252129995694

Epoch: 6| Step: 1
Training loss: 0.08672330528497696
Validation loss: 1.4334332930144442

Epoch: 6| Step: 2
Training loss: 0.06109445542097092
Validation loss: 1.430181234754542

Epoch: 6| Step: 3
Training loss: 0.10673640668392181
Validation loss: 1.4352730422891595

Epoch: 6| Step: 4
Training loss: 0.18212270736694336
Validation loss: 1.4527744298340173

Epoch: 6| Step: 5
Training loss: 0.05700729787349701
Validation loss: 1.4414434227892148

Epoch: 6| Step: 6
Training loss: 0.07038606703281403
Validation loss: 1.403411551188397

Epoch: 6| Step: 7
Training loss: 0.10245220363140106
Validation loss: 1.4047833758015786

Epoch: 6| Step: 8
Training loss: 0.1261572539806366
Validation loss: 1.4205430784533102

Epoch: 6| Step: 9
Training loss: 0.0647842213511467
Validation loss: 1.3767178199624504

Epoch: 6| Step: 10
Training loss: 0.11208674311637878
Validation loss: 1.4012133267617994

Epoch: 6| Step: 11
Training loss: 0.0796581506729126
Validation loss: 1.3953529839874597

Epoch: 6| Step: 12
Training loss: 0.06207362562417984
Validation loss: 1.4043192850646151

Epoch: 6| Step: 13
Training loss: 0.0411195233464241
Validation loss: 1.392025234878704

Epoch: 562| Step: 0
Training loss: 0.07337170839309692
Validation loss: 1.3871378539710917

Epoch: 6| Step: 1
Training loss: 0.04513922333717346
Validation loss: 1.3943939439712032

Epoch: 6| Step: 2
Training loss: 0.04595126584172249
Validation loss: 1.4195441353705622

Epoch: 6| Step: 3
Training loss: 0.0889778733253479
Validation loss: 1.4338919167877526

Epoch: 6| Step: 4
Training loss: 0.12294778227806091
Validation loss: 1.4425973687120663

Epoch: 6| Step: 5
Training loss: 0.14407987892627716
Validation loss: 1.4568040704214444

Epoch: 6| Step: 6
Training loss: 0.07185091078281403
Validation loss: 1.445864189055658

Epoch: 6| Step: 7
Training loss: 0.08001004159450531
Validation loss: 1.4484526694461863

Epoch: 6| Step: 8
Training loss: 0.08241267502307892
Validation loss: 1.4499989940274147

Epoch: 6| Step: 9
Training loss: 0.09000254422426224
Validation loss: 1.4174127322371288

Epoch: 6| Step: 10
Training loss: 0.10462821274995804
Validation loss: 1.4355536994113718

Epoch: 6| Step: 11
Training loss: 0.08963793516159058
Validation loss: 1.425416628519694

Epoch: 6| Step: 12
Training loss: 0.1341460645198822
Validation loss: 1.461145249746179

Epoch: 6| Step: 13
Training loss: 0.08273119479417801
Validation loss: 1.453699751566815

Epoch: 563| Step: 0
Training loss: 0.05544771999120712
Validation loss: 1.4539832543301325

Epoch: 6| Step: 1
Training loss: 0.07034213095903397
Validation loss: 1.4551940041203653

Epoch: 6| Step: 2
Training loss: 0.08881157636642456
Validation loss: 1.462586747702732

Epoch: 6| Step: 3
Training loss: 0.12215914577245712
Validation loss: 1.4805840125647924

Epoch: 6| Step: 4
Training loss: 0.14338737726211548
Validation loss: 1.468956438443994

Epoch: 6| Step: 5
Training loss: 0.08018708229064941
Validation loss: 1.4798847988087644

Epoch: 6| Step: 6
Training loss: 0.15294158458709717
Validation loss: 1.4657108399175829

Epoch: 6| Step: 7
Training loss: 0.0713638961315155
Validation loss: 1.45957342655428

Epoch: 6| Step: 8
Training loss: 0.07534399628639221
Validation loss: 1.4372190352409118

Epoch: 6| Step: 9
Training loss: 0.07371601462364197
Validation loss: 1.4485505678320443

Epoch: 6| Step: 10
Training loss: 0.09165152907371521
Validation loss: 1.406338946793669

Epoch: 6| Step: 11
Training loss: 0.11051235347986221
Validation loss: 1.3899292907407206

Epoch: 6| Step: 12
Training loss: 0.12073096632957458
Validation loss: 1.406185184755633

Epoch: 6| Step: 13
Training loss: 0.04868079721927643
Validation loss: 1.3680917716795398

Epoch: 564| Step: 0
Training loss: 0.06785671412944794
Validation loss: 1.361325248595207

Epoch: 6| Step: 1
Training loss: 0.1377720981836319
Validation loss: 1.3664955727515682

Epoch: 6| Step: 2
Training loss: 0.08786698430776596
Validation loss: 1.374651284628017

Epoch: 6| Step: 3
Training loss: 0.0924571305513382
Validation loss: 1.4041840568665536

Epoch: 6| Step: 4
Training loss: 0.04946240037679672
Validation loss: 1.4020058147368892

Epoch: 6| Step: 5
Training loss: 0.050866737961769104
Validation loss: 1.4277973899277308

Epoch: 6| Step: 6
Training loss: 0.15700024366378784
Validation loss: 1.4658146545451174

Epoch: 6| Step: 7
Training loss: 0.05912497267127037
Validation loss: 1.4417019044199297

Epoch: 6| Step: 8
Training loss: 0.07324621081352234
Validation loss: 1.443580997887478

Epoch: 6| Step: 9
Training loss: 0.0774436667561531
Validation loss: 1.4518946460498277

Epoch: 6| Step: 10
Training loss: 0.07715645432472229
Validation loss: 1.4334574245637464

Epoch: 6| Step: 11
Training loss: 0.04918844625353813
Validation loss: 1.420207764512749

Epoch: 6| Step: 12
Training loss: 0.07334360480308533
Validation loss: 1.4306200345357258

Epoch: 6| Step: 13
Training loss: 0.08536549657583237
Validation loss: 1.4335392809683276

Epoch: 565| Step: 0
Training loss: 0.045299068093299866
Validation loss: 1.4509379056192213

Epoch: 6| Step: 1
Training loss: 0.057564202696084976
Validation loss: 1.4507557615157096

Epoch: 6| Step: 2
Training loss: 0.08298376202583313
Validation loss: 1.4297869692566574

Epoch: 6| Step: 3
Training loss: 0.0765748918056488
Validation loss: 1.4391469455534411

Epoch: 6| Step: 4
Training loss: 0.04342425987124443
Validation loss: 1.46982697004913

Epoch: 6| Step: 5
Training loss: 0.07567664235830307
Validation loss: 1.4600559460219515

Epoch: 6| Step: 6
Training loss: 0.058012187480926514
Validation loss: 1.433780054251353

Epoch: 6| Step: 7
Training loss: 0.05824654549360275
Validation loss: 1.4530728017130206

Epoch: 6| Step: 8
Training loss: 0.0888378918170929
Validation loss: 1.4637708087121286

Epoch: 6| Step: 9
Training loss: 0.075258769094944
Validation loss: 1.4557641379294857

Epoch: 6| Step: 10
Training loss: 0.0706065446138382
Validation loss: 1.4698016348705496

Epoch: 6| Step: 11
Training loss: 0.1414276510477066
Validation loss: 1.486758501298966

Epoch: 6| Step: 12
Training loss: 0.1298830658197403
Validation loss: 1.4827575939957813

Epoch: 6| Step: 13
Training loss: 0.04118984192609787
Validation loss: 1.4823324308600476

Epoch: 566| Step: 0
Training loss: 0.05147615820169449
Validation loss: 1.487154769641097

Epoch: 6| Step: 1
Training loss: 0.12548741698265076
Validation loss: 1.5040506765406618

Epoch: 6| Step: 2
Training loss: 0.05378652364015579
Validation loss: 1.493755546949243

Epoch: 6| Step: 3
Training loss: 0.0653756707906723
Validation loss: 1.4891627180960871

Epoch: 6| Step: 4
Training loss: 0.06403600424528122
Validation loss: 1.462065428815862

Epoch: 6| Step: 5
Training loss: 0.12078060209751129
Validation loss: 1.455564454037656

Epoch: 6| Step: 6
Training loss: 0.07263615727424622
Validation loss: 1.4398951530456543

Epoch: 6| Step: 7
Training loss: 0.09717777371406555
Validation loss: 1.4315936462853545

Epoch: 6| Step: 8
Training loss: 0.06615567952394485
Validation loss: 1.4297317676646735

Epoch: 6| Step: 9
Training loss: 0.09282568097114563
Validation loss: 1.4179550165771155

Epoch: 6| Step: 10
Training loss: 0.05630461499094963
Validation loss: 1.4235759781252952

Epoch: 6| Step: 11
Training loss: 0.09218244254589081
Validation loss: 1.417110840479533

Epoch: 6| Step: 12
Training loss: 0.06504574418067932
Validation loss: 1.407371554323422

Epoch: 6| Step: 13
Training loss: 0.07815913110971451
Validation loss: 1.394738845927741

Epoch: 567| Step: 0
Training loss: 0.06019796431064606
Validation loss: 1.4047054449717205

Epoch: 6| Step: 1
Training loss: 0.04859388619661331
Validation loss: 1.4114630542775637

Epoch: 6| Step: 2
Training loss: 0.1705431044101715
Validation loss: 1.4041673316750476

Epoch: 6| Step: 3
Training loss: 0.08706249296665192
Validation loss: 1.419249411552183

Epoch: 6| Step: 4
Training loss: 0.06677405536174774
Validation loss: 1.4600607105480727

Epoch: 6| Step: 5
Training loss: 0.05555219203233719
Validation loss: 1.4558311623911704

Epoch: 6| Step: 6
Training loss: 0.08350914716720581
Validation loss: 1.4620903871392692

Epoch: 6| Step: 7
Training loss: 0.05707969889044762
Validation loss: 1.4350073401645949

Epoch: 6| Step: 8
Training loss: 0.09215229749679565
Validation loss: 1.4556939858262257

Epoch: 6| Step: 9
Training loss: 0.06115442514419556
Validation loss: 1.4190584651885494

Epoch: 6| Step: 10
Training loss: 0.10738316178321838
Validation loss: 1.4355405498576421

Epoch: 6| Step: 11
Training loss: 0.09862853586673737
Validation loss: 1.4002903917784333

Epoch: 6| Step: 12
Training loss: 0.0656217709183693
Validation loss: 1.4032480332159227

Epoch: 6| Step: 13
Training loss: 0.034955091774463654
Validation loss: 1.4165220081165273

Epoch: 568| Step: 0
Training loss: 0.07494038343429565
Validation loss: 1.3876987708512174

Epoch: 6| Step: 1
Training loss: 0.07016566395759583
Validation loss: 1.4211652080217998

Epoch: 6| Step: 2
Training loss: 0.04396016150712967
Validation loss: 1.4026858191336355

Epoch: 6| Step: 3
Training loss: 0.12340214103460312
Validation loss: 1.4145733989695066

Epoch: 6| Step: 4
Training loss: 0.053356632590293884
Validation loss: 1.437162640274212

Epoch: 6| Step: 5
Training loss: 0.06332950294017792
Validation loss: 1.4239693175080002

Epoch: 6| Step: 6
Training loss: 0.05007167160511017
Validation loss: 1.4174779858640445

Epoch: 6| Step: 7
Training loss: 0.06039608269929886
Validation loss: 1.4067216022040254

Epoch: 6| Step: 8
Training loss: 0.1059802919626236
Validation loss: 1.4185406674620926

Epoch: 6| Step: 9
Training loss: 0.17556284368038177
Validation loss: 1.3950932602728567

Epoch: 6| Step: 10
Training loss: 0.051424674689769745
Validation loss: 1.395998699690706

Epoch: 6| Step: 11
Training loss: 0.06800027191638947
Validation loss: 1.4092778505817536

Epoch: 6| Step: 12
Training loss: 0.0793052688241005
Validation loss: 1.4193573446683987

Epoch: 6| Step: 13
Training loss: 0.02064461261034012
Validation loss: 1.44041875485451

Epoch: 569| Step: 0
Training loss: 0.05848003923892975
Validation loss: 1.4396874802086943

Epoch: 6| Step: 1
Training loss: 0.06040231138467789
Validation loss: 1.4294912122911023

Epoch: 6| Step: 2
Training loss: 0.07271258533000946
Validation loss: 1.4454265935446626

Epoch: 6| Step: 3
Training loss: 0.08183488994836807
Validation loss: 1.4413938073701755

Epoch: 6| Step: 4
Training loss: 0.07382111996412277
Validation loss: 1.4288767806945308

Epoch: 6| Step: 5
Training loss: 0.0472920723259449
Validation loss: 1.4348691169933607

Epoch: 6| Step: 6
Training loss: 0.09951403737068176
Validation loss: 1.441188213325316

Epoch: 6| Step: 7
Training loss: 0.05914527550339699
Validation loss: 1.459803831192755

Epoch: 6| Step: 8
Training loss: 0.06973441690206528
Validation loss: 1.4394677672334897

Epoch: 6| Step: 9
Training loss: 0.03913230076432228
Validation loss: 1.4233235928320116

Epoch: 6| Step: 10
Training loss: 0.11589555442333221
Validation loss: 1.436703029499259

Epoch: 6| Step: 11
Training loss: 0.06743654608726501
Validation loss: 1.4287691802106879

Epoch: 6| Step: 12
Training loss: 0.06294441223144531
Validation loss: 1.4463137535638706

Epoch: 6| Step: 13
Training loss: 0.02882206439971924
Validation loss: 1.4267126449974634

Epoch: 570| Step: 0
Training loss: 0.13143137097358704
Validation loss: 1.4387185913260265

Epoch: 6| Step: 1
Training loss: 0.07061676681041718
Validation loss: 1.4257051406368133

Epoch: 6| Step: 2
Training loss: 0.06257732212543488
Validation loss: 1.445878590306928

Epoch: 6| Step: 3
Training loss: 0.0798363983631134
Validation loss: 1.4602301441213137

Epoch: 6| Step: 4
Training loss: 0.04569975659251213
Validation loss: 1.450596647877847

Epoch: 6| Step: 5
Training loss: 0.05988244339823723
Validation loss: 1.4529063214537918

Epoch: 6| Step: 6
Training loss: 0.05670715495944023
Validation loss: 1.4282073231153591

Epoch: 6| Step: 7
Training loss: 0.05235834792256355
Validation loss: 1.4333840236868909

Epoch: 6| Step: 8
Training loss: 0.08374524116516113
Validation loss: 1.4281345631486626

Epoch: 6| Step: 9
Training loss: 0.044114354997873306
Validation loss: 1.4026613940474808

Epoch: 6| Step: 10
Training loss: 0.06468194723129272
Validation loss: 1.4139024480696647

Epoch: 6| Step: 11
Training loss: 0.10563013702630997
Validation loss: 1.413148618513538

Epoch: 6| Step: 12
Training loss: 0.06601166725158691
Validation loss: 1.4241835096830964

Epoch: 6| Step: 13
Training loss: 0.045226044952869415
Validation loss: 1.4344841664837253

Epoch: 571| Step: 0
Training loss: 0.125457301735878
Validation loss: 1.4290652339176466

Epoch: 6| Step: 1
Training loss: 0.10949406027793884
Validation loss: 1.4376052066843996

Epoch: 6| Step: 2
Training loss: 0.07130847871303558
Validation loss: 1.4344723224639893

Epoch: 6| Step: 3
Training loss: 0.07802946865558624
Validation loss: 1.4484491329039297

Epoch: 6| Step: 4
Training loss: 0.056032076478004456
Validation loss: 1.464574715142609

Epoch: 6| Step: 5
Training loss: 0.07291629165410995
Validation loss: 1.4362905467710188

Epoch: 6| Step: 6
Training loss: 0.06447875499725342
Validation loss: 1.446471191221668

Epoch: 6| Step: 7
Training loss: 0.040974535048007965
Validation loss: 1.4594527341986214

Epoch: 6| Step: 8
Training loss: 0.08084326982498169
Validation loss: 1.448915466185539

Epoch: 6| Step: 9
Training loss: 0.0624704547226429
Validation loss: 1.4537282829643579

Epoch: 6| Step: 10
Training loss: 0.05331241339445114
Validation loss: 1.435973128964824

Epoch: 6| Step: 11
Training loss: 0.1562730371952057
Validation loss: 1.4363236658034786

Epoch: 6| Step: 12
Training loss: 0.0781552717089653
Validation loss: 1.4379628371166926

Epoch: 6| Step: 13
Training loss: 0.04744632914662361
Validation loss: 1.4511871145617576

Epoch: 572| Step: 0
Training loss: 0.07164889574050903
Validation loss: 1.446370497826607

Epoch: 6| Step: 1
Training loss: 0.04855785146355629
Validation loss: 1.4336830723670222

Epoch: 6| Step: 2
Training loss: 0.05909600108861923
Validation loss: 1.4150786194750058

Epoch: 6| Step: 3
Training loss: 0.09814133495092392
Validation loss: 1.4314205620878486

Epoch: 6| Step: 4
Training loss: 0.12315970659255981
Validation loss: 1.4203262457283594

Epoch: 6| Step: 5
Training loss: 0.12851662933826447
Validation loss: 1.4279421785826325

Epoch: 6| Step: 6
Training loss: 0.058817289769649506
Validation loss: 1.4492729402357531

Epoch: 6| Step: 7
Training loss: 0.13995178043842316
Validation loss: 1.4636803955160163

Epoch: 6| Step: 8
Training loss: 0.06580989807844162
Validation loss: 1.4546474077368294

Epoch: 6| Step: 9
Training loss: 0.12691861391067505
Validation loss: 1.4705084882756716

Epoch: 6| Step: 10
Training loss: 0.058429352939128876
Validation loss: 1.485906506097445

Epoch: 6| Step: 11
Training loss: 0.093648761510849
Validation loss: 1.485361482507439

Epoch: 6| Step: 12
Training loss: 0.0736265629529953
Validation loss: 1.477514039444667

Epoch: 6| Step: 13
Training loss: 0.12854427099227905
Validation loss: 1.4359768539346673

Epoch: 573| Step: 0
Training loss: 0.0769152045249939
Validation loss: 1.4018224836677633

Epoch: 6| Step: 1
Training loss: 0.11286839097738266
Validation loss: 1.402464965338348

Epoch: 6| Step: 2
Training loss: 0.047672614455223083
Validation loss: 1.4110972515998348

Epoch: 6| Step: 3
Training loss: 0.06255335360765457
Validation loss: 1.3952286794621458

Epoch: 6| Step: 4
Training loss: 0.05658063292503357
Validation loss: 1.401915498959121

Epoch: 6| Step: 5
Training loss: 0.05293913930654526
Validation loss: 1.4081412438423402

Epoch: 6| Step: 6
Training loss: 0.0936768501996994
Validation loss: 1.450417890343615

Epoch: 6| Step: 7
Training loss: 0.08137601613998413
Validation loss: 1.4346323256851525

Epoch: 6| Step: 8
Training loss: 0.04737582802772522
Validation loss: 1.4563608284919494

Epoch: 6| Step: 9
Training loss: 0.08102397620677948
Validation loss: 1.4645545456999092

Epoch: 6| Step: 10
Training loss: 0.08706291019916534
Validation loss: 1.458386560922028

Epoch: 6| Step: 11
Training loss: 0.0568850003182888
Validation loss: 1.4654524608324933

Epoch: 6| Step: 12
Training loss: 0.06289777904748917
Validation loss: 1.4462837596093454

Epoch: 6| Step: 13
Training loss: 0.20564550161361694
Validation loss: 1.4499146425595848

Epoch: 574| Step: 0
Training loss: 0.08554273843765259
Validation loss: 1.4122244183735182

Epoch: 6| Step: 1
Training loss: 0.08038698881864548
Validation loss: 1.4328073211895522

Epoch: 6| Step: 2
Training loss: 0.07759363204240799
Validation loss: 1.4402500198733421

Epoch: 6| Step: 3
Training loss: 0.10469184815883636
Validation loss: 1.437924183825011

Epoch: 6| Step: 4
Training loss: 0.06805004924535751
Validation loss: 1.4513054329861876

Epoch: 6| Step: 5
Training loss: 0.04692253842949867
Validation loss: 1.4580080522003995

Epoch: 6| Step: 6
Training loss: 0.04597485810518265
Validation loss: 1.4517669511097733

Epoch: 6| Step: 7
Training loss: 0.05218524485826492
Validation loss: 1.4599204576143654

Epoch: 6| Step: 8
Training loss: 0.065730020403862
Validation loss: 1.4743762452115294

Epoch: 6| Step: 9
Training loss: 0.07857795059680939
Validation loss: 1.4733849058869064

Epoch: 6| Step: 10
Training loss: 0.10762808471918106
Validation loss: 1.4390584281695786

Epoch: 6| Step: 11
Training loss: 0.07014824450016022
Validation loss: 1.423215284783353

Epoch: 6| Step: 12
Training loss: 0.055470578372478485
Validation loss: 1.4413199085061268

Epoch: 6| Step: 13
Training loss: 0.10298935323953629
Validation loss: 1.4349810666935419

Epoch: 575| Step: 0
Training loss: 0.07698940485715866
Validation loss: 1.426503772376686

Epoch: 6| Step: 1
Training loss: 0.07197088748216629
Validation loss: 1.425567901262673

Epoch: 6| Step: 2
Training loss: 0.08250442147254944
Validation loss: 1.4285733597252959

Epoch: 6| Step: 3
Training loss: 0.14177124202251434
Validation loss: 1.4402151389788556

Epoch: 6| Step: 4
Training loss: 0.041808538138866425
Validation loss: 1.4707404862168014

Epoch: 6| Step: 5
Training loss: 0.07020740956068039
Validation loss: 1.4819200628547258

Epoch: 6| Step: 6
Training loss: 0.12188553810119629
Validation loss: 1.4673296373377565

Epoch: 6| Step: 7
Training loss: 0.0617462694644928
Validation loss: 1.4849776247496247

Epoch: 6| Step: 8
Training loss: 0.08742056041955948
Validation loss: 1.4741274240196391

Epoch: 6| Step: 9
Training loss: 0.1036156639456749
Validation loss: 1.464891185683589

Epoch: 6| Step: 10
Training loss: 0.07993709295988083
Validation loss: 1.416334976432144

Epoch: 6| Step: 11
Training loss: 0.07535853981971741
Validation loss: 1.4357567794861332

Epoch: 6| Step: 12
Training loss: 0.05760382115840912
Validation loss: 1.4147486814888575

Epoch: 6| Step: 13
Training loss: 0.16845166683197021
Validation loss: 1.4071976619382058

Epoch: 576| Step: 0
Training loss: 0.0907629132270813
Validation loss: 1.4296803564153693

Epoch: 6| Step: 1
Training loss: 0.05023844540119171
Validation loss: 1.4153834581375122

Epoch: 6| Step: 2
Training loss: 0.09568466991186142
Validation loss: 1.4272742258605136

Epoch: 6| Step: 3
Training loss: 0.07374675571918488
Validation loss: 1.456987819363994

Epoch: 6| Step: 4
Training loss: 0.0612795352935791
Validation loss: 1.4767194031387247

Epoch: 6| Step: 5
Training loss: 0.1719113290309906
Validation loss: 1.4785340383488645

Epoch: 6| Step: 6
Training loss: 0.08193770051002502
Validation loss: 1.4913491087575113

Epoch: 6| Step: 7
Training loss: 0.06434817612171173
Validation loss: 1.4947079637999177

Epoch: 6| Step: 8
Training loss: 0.05840378627181053
Validation loss: 1.4462177907266924

Epoch: 6| Step: 9
Training loss: 0.09750581532716751
Validation loss: 1.450280060050308

Epoch: 6| Step: 10
Training loss: 0.049927182495594025
Validation loss: 1.4365208495047785

Epoch: 6| Step: 11
Training loss: 0.09077700972557068
Validation loss: 1.447692367338365

Epoch: 6| Step: 12
Training loss: 0.12414848804473877
Validation loss: 1.4512846008423836

Epoch: 6| Step: 13
Training loss: 0.08413992822170258
Validation loss: 1.4392102764498802

Epoch: 577| Step: 0
Training loss: 0.0634278804063797
Validation loss: 1.4334410980183592

Epoch: 6| Step: 1
Training loss: 0.05944674834609032
Validation loss: 1.4417210137972267

Epoch: 6| Step: 2
Training loss: 0.07969702035188675
Validation loss: 1.414388156706287

Epoch: 6| Step: 3
Training loss: 0.0712052509188652
Validation loss: 1.456928970993206

Epoch: 6| Step: 4
Training loss: 0.05361771583557129
Validation loss: 1.4544695551677416

Epoch: 6| Step: 5
Training loss: 0.07538509368896484
Validation loss: 1.4729073880821146

Epoch: 6| Step: 6
Training loss: 0.08828692883253098
Validation loss: 1.4472937955651233

Epoch: 6| Step: 7
Training loss: 0.08279199153184891
Validation loss: 1.466475167582112

Epoch: 6| Step: 8
Training loss: 0.11357852816581726
Validation loss: 1.4352812741392402

Epoch: 6| Step: 9
Training loss: 0.07943098992109299
Validation loss: 1.4479641273457518

Epoch: 6| Step: 10
Training loss: 0.050923511385917664
Validation loss: 1.4101655919064757

Epoch: 6| Step: 11
Training loss: 0.17013110220432281
Validation loss: 1.4039009277538588

Epoch: 6| Step: 12
Training loss: 0.07966037094593048
Validation loss: 1.3958341075528053

Epoch: 6| Step: 13
Training loss: 0.06765846908092499
Validation loss: 1.4216808593401344

Epoch: 578| Step: 0
Training loss: 0.08257350325584412
Validation loss: 1.3977111308805403

Epoch: 6| Step: 1
Training loss: 0.06688668578863144
Validation loss: 1.407746366275254

Epoch: 6| Step: 2
Training loss: 0.05798003450036049
Validation loss: 1.40169846370656

Epoch: 6| Step: 3
Training loss: 0.12553507089614868
Validation loss: 1.4280004744888635

Epoch: 6| Step: 4
Training loss: 0.16580641269683838
Validation loss: 1.417479456111949

Epoch: 6| Step: 5
Training loss: 0.12139381468296051
Validation loss: 1.4456186018964297

Epoch: 6| Step: 6
Training loss: 0.11064980179071426
Validation loss: 1.448018281690536

Epoch: 6| Step: 7
Training loss: 0.14383798837661743
Validation loss: 1.4089914380863149

Epoch: 6| Step: 8
Training loss: 0.08586227893829346
Validation loss: 1.4231918434942923

Epoch: 6| Step: 9
Training loss: 0.10536473989486694
Validation loss: 1.402403220053642

Epoch: 6| Step: 10
Training loss: 0.14382047951221466
Validation loss: 1.3849565495726883

Epoch: 6| Step: 11
Training loss: 0.07695754617452621
Validation loss: 1.387932732541074

Epoch: 6| Step: 12
Training loss: 0.07011087238788605
Validation loss: 1.3996715161108202

Epoch: 6| Step: 13
Training loss: 0.08223965764045715
Validation loss: 1.4007164457792878

Epoch: 579| Step: 0
Training loss: 0.08300462365150452
Validation loss: 1.4189345990457842

Epoch: 6| Step: 1
Training loss: 0.0774393305182457
Validation loss: 1.4350445142356298

Epoch: 6| Step: 2
Training loss: 0.06880120933055878
Validation loss: 1.4281105751632361

Epoch: 6| Step: 3
Training loss: 0.08689659833908081
Validation loss: 1.4522464057450652

Epoch: 6| Step: 4
Training loss: 0.09733067452907562
Validation loss: 1.4686795716644616

Epoch: 6| Step: 5
Training loss: 0.12529805302619934
Validation loss: 1.4475907830781833

Epoch: 6| Step: 6
Training loss: 0.15136048197746277
Validation loss: 1.482177843329727

Epoch: 6| Step: 7
Training loss: 0.08224347233772278
Validation loss: 1.4370132543707406

Epoch: 6| Step: 8
Training loss: 0.0477769672870636
Validation loss: 1.4049424932849022

Epoch: 6| Step: 9
Training loss: 0.07179857790470123
Validation loss: 1.4193468234872306

Epoch: 6| Step: 10
Training loss: 0.07277829945087433
Validation loss: 1.397829048095211

Epoch: 6| Step: 11
Training loss: 0.07610897719860077
Validation loss: 1.4057462484605852

Epoch: 6| Step: 12
Training loss: 0.11177010834217072
Validation loss: 1.4233911338672842

Epoch: 6| Step: 13
Training loss: 0.08293583989143372
Validation loss: 1.3996359763606903

Epoch: 580| Step: 0
Training loss: 0.04305701702833176
Validation loss: 1.4073773686603834

Epoch: 6| Step: 1
Training loss: 0.057915154844522476
Validation loss: 1.4204416351933633

Epoch: 6| Step: 2
Training loss: 0.051836807280778885
Validation loss: 1.4129106319078835

Epoch: 6| Step: 3
Training loss: 0.06583458185195923
Validation loss: 1.408788110620232

Epoch: 6| Step: 4
Training loss: 0.15349481999874115
Validation loss: 1.4149993670884

Epoch: 6| Step: 5
Training loss: 0.05037207156419754
Validation loss: 1.4390843068399737

Epoch: 6| Step: 6
Training loss: 0.06229189783334732
Validation loss: 1.4216037796389671

Epoch: 6| Step: 7
Training loss: 0.11203208565711975
Validation loss: 1.4012667132962136

Epoch: 6| Step: 8
Training loss: 0.041188593953847885
Validation loss: 1.439371257699946

Epoch: 6| Step: 9
Training loss: 0.10018660128116608
Validation loss: 1.3937430176683652

Epoch: 6| Step: 10
Training loss: 0.05023790895938873
Validation loss: 1.4319101431036507

Epoch: 6| Step: 11
Training loss: 0.10090214014053345
Validation loss: 1.414646540918658

Epoch: 6| Step: 12
Training loss: 0.06396698951721191
Validation loss: 1.4432978630065918

Epoch: 6| Step: 13
Training loss: 0.07628169655799866
Validation loss: 1.4351254765705397

Epoch: 581| Step: 0
Training loss: 0.05622674524784088
Validation loss: 1.5015675611393426

Epoch: 6| Step: 1
Training loss: 0.07860450446605682
Validation loss: 1.4920577515837967

Epoch: 6| Step: 2
Training loss: 0.06380528211593628
Validation loss: 1.514235019683838

Epoch: 6| Step: 3
Training loss: 0.09325392544269562
Validation loss: 1.5137141545613606

Epoch: 6| Step: 4
Training loss: 0.07711711525917053
Validation loss: 1.493835062109014

Epoch: 6| Step: 5
Training loss: 0.10043837875127792
Validation loss: 1.512980168865573

Epoch: 6| Step: 6
Training loss: 0.08971744775772095
Validation loss: 1.493400631412383

Epoch: 6| Step: 7
Training loss: 0.10170524567365646
Validation loss: 1.4784929419076571

Epoch: 6| Step: 8
Training loss: 0.0738275870680809
Validation loss: 1.4477974650680379

Epoch: 6| Step: 9
Training loss: 0.04627963900566101
Validation loss: 1.4477148517485587

Epoch: 6| Step: 10
Training loss: 0.12586930394172668
Validation loss: 1.4359434958427184

Epoch: 6| Step: 11
Training loss: 0.07157044112682343
Validation loss: 1.4248307584434428

Epoch: 6| Step: 12
Training loss: 0.06886487454175949
Validation loss: 1.4190387597648046

Epoch: 6| Step: 13
Training loss: 0.050977952778339386
Validation loss: 1.4158834558661266

Epoch: 582| Step: 0
Training loss: 0.04401096701622009
Validation loss: 1.3809542168853104

Epoch: 6| Step: 1
Training loss: 0.1227646917104721
Validation loss: 1.4263179635488858

Epoch: 6| Step: 2
Training loss: 0.06875254958868027
Validation loss: 1.4116633963841263

Epoch: 6| Step: 3
Training loss: 0.081128790974617
Validation loss: 1.4114593216167983

Epoch: 6| Step: 4
Training loss: 0.07446315884590149
Validation loss: 1.4568542190777358

Epoch: 6| Step: 5
Training loss: 0.07660361379384995
Validation loss: 1.4262162408521097

Epoch: 6| Step: 6
Training loss: 0.05168267339468002
Validation loss: 1.4391180340961744

Epoch: 6| Step: 7
Training loss: 0.05745745822787285
Validation loss: 1.4313320370130642

Epoch: 6| Step: 8
Training loss: 0.08406049758195877
Validation loss: 1.4499981826351536

Epoch: 6| Step: 9
Training loss: 0.08665021508932114
Validation loss: 1.4429695260140203

Epoch: 6| Step: 10
Training loss: 0.06248399615287781
Validation loss: 1.4430313135987969

Epoch: 6| Step: 11
Training loss: 0.0629420354962349
Validation loss: 1.420831262424428

Epoch: 6| Step: 12
Training loss: 0.1063116192817688
Validation loss: 1.432382402240589

Epoch: 6| Step: 13
Training loss: 0.04262771084904671
Validation loss: 1.4339703616275583

Epoch: 583| Step: 0
Training loss: 0.12395620346069336
Validation loss: 1.4285675812793035

Epoch: 6| Step: 1
Training loss: 0.03910810500383377
Validation loss: 1.4298670817446966

Epoch: 6| Step: 2
Training loss: 0.05976682901382446
Validation loss: 1.4316445531383637

Epoch: 6| Step: 3
Training loss: 0.04581363871693611
Validation loss: 1.4103481141469811

Epoch: 6| Step: 4
Training loss: 0.14199048280715942
Validation loss: 1.4497569376422512

Epoch: 6| Step: 5
Training loss: 0.049674637615680695
Validation loss: 1.4266619502857167

Epoch: 6| Step: 6
Training loss: 0.06387642025947571
Validation loss: 1.4502911939415881

Epoch: 6| Step: 7
Training loss: 0.0624273307621479
Validation loss: 1.4345873299465384

Epoch: 6| Step: 8
Training loss: 0.07061103731393814
Validation loss: 1.4561441380490538

Epoch: 6| Step: 9
Training loss: 0.06544329226016998
Validation loss: 1.4496442182089693

Epoch: 6| Step: 10
Training loss: 0.07448232173919678
Validation loss: 1.4190412516235023

Epoch: 6| Step: 11
Training loss: 0.0626867488026619
Validation loss: 1.427786207968189

Epoch: 6| Step: 12
Training loss: 0.055556878447532654
Validation loss: 1.4115747687637166

Epoch: 6| Step: 13
Training loss: 0.04049510136246681
Validation loss: 1.4347494661167104

Epoch: 584| Step: 0
Training loss: 0.07495616376399994
Validation loss: 1.4255651299671461

Epoch: 6| Step: 1
Training loss: 0.0703626424074173
Validation loss: 1.4065207909512263

Epoch: 6| Step: 2
Training loss: 0.07179882377386093
Validation loss: 1.4429666175637195

Epoch: 6| Step: 3
Training loss: 0.07674914598464966
Validation loss: 1.4267389928140948

Epoch: 6| Step: 4
Training loss: 0.09133424609899521
Validation loss: 1.4223372602975497

Epoch: 6| Step: 5
Training loss: 0.062280137091875076
Validation loss: 1.4434453941160632

Epoch: 6| Step: 6
Training loss: 0.04303060472011566
Validation loss: 1.4376470055631412

Epoch: 6| Step: 7
Training loss: 0.09752865880727768
Validation loss: 1.4473591684013285

Epoch: 6| Step: 8
Training loss: 0.1098422035574913
Validation loss: 1.4520368197912812

Epoch: 6| Step: 9
Training loss: 0.07714203745126724
Validation loss: 1.4480526607523683

Epoch: 6| Step: 10
Training loss: 0.07675784081220627
Validation loss: 1.452590665509624

Epoch: 6| Step: 11
Training loss: 0.05777064710855484
Validation loss: 1.4576230459315802

Epoch: 6| Step: 12
Training loss: 0.07652352750301361
Validation loss: 1.4412166098112702

Epoch: 6| Step: 13
Training loss: 0.06846145540475845
Validation loss: 1.4277599293698546

Epoch: 585| Step: 0
Training loss: 0.04392628371715546
Validation loss: 1.4100070493195647

Epoch: 6| Step: 1
Training loss: 0.07079803943634033
Validation loss: 1.3884883452487249

Epoch: 6| Step: 2
Training loss: 0.07026921212673187
Validation loss: 1.4025331389519475

Epoch: 6| Step: 3
Training loss: 0.10274548828601837
Validation loss: 1.3978924969191193

Epoch: 6| Step: 4
Training loss: 0.0628565177321434
Validation loss: 1.392742613310455

Epoch: 6| Step: 5
Training loss: 0.06774462759494781
Validation loss: 1.4008880789561937

Epoch: 6| Step: 6
Training loss: 0.09755541384220123
Validation loss: 1.4076515692536549

Epoch: 6| Step: 7
Training loss: 0.11986443400382996
Validation loss: 1.379590969572785

Epoch: 6| Step: 8
Training loss: 0.11389944702386856
Validation loss: 1.406833214144553

Epoch: 6| Step: 9
Training loss: 0.06344524770975113
Validation loss: 1.4208066617288897

Epoch: 6| Step: 10
Training loss: 0.0495847687125206
Validation loss: 1.4052505191936289

Epoch: 6| Step: 11
Training loss: 0.055236950516700745
Validation loss: 1.409171501795451

Epoch: 6| Step: 12
Training loss: 0.07970976829528809
Validation loss: 1.4169606701020272

Epoch: 6| Step: 13
Training loss: 0.08630883693695068
Validation loss: 1.4165568069745136

Epoch: 586| Step: 0
Training loss: 0.07646187394857407
Validation loss: 1.4182395447966873

Epoch: 6| Step: 1
Training loss: 0.09151913225650787
Validation loss: 1.413955928176962

Epoch: 6| Step: 2
Training loss: 0.0504467636346817
Validation loss: 1.4163931082653742

Epoch: 6| Step: 3
Training loss: 0.05336710810661316
Validation loss: 1.4227036891445037

Epoch: 6| Step: 4
Training loss: 0.08531168848276138
Validation loss: 1.4386640107759865

Epoch: 6| Step: 5
Training loss: 0.04445316642522812
Validation loss: 1.443029716450681

Epoch: 6| Step: 6
Training loss: 0.1065448522567749
Validation loss: 1.4657917086796095

Epoch: 6| Step: 7
Training loss: 0.08047981560230255
Validation loss: 1.4540724113423338

Epoch: 6| Step: 8
Training loss: 0.08819358050823212
Validation loss: 1.4553904635931856

Epoch: 6| Step: 9
Training loss: 0.04975559562444687
Validation loss: 1.4435318964783863

Epoch: 6| Step: 10
Training loss: 0.09628524631261826
Validation loss: 1.4450220010613883

Epoch: 6| Step: 11
Training loss: 0.05201517790555954
Validation loss: 1.4420864197515673

Epoch: 6| Step: 12
Training loss: 0.0336420014500618
Validation loss: 1.4492163318459705

Epoch: 6| Step: 13
Training loss: 0.15364466607570648
Validation loss: 1.4179581390914096

Epoch: 587| Step: 0
Training loss: 0.09614928066730499
Validation loss: 1.4596064180456183

Epoch: 6| Step: 1
Training loss: 0.062218353152275085
Validation loss: 1.4421498397345185

Epoch: 6| Step: 2
Training loss: 0.0758146196603775
Validation loss: 1.4447303318208264

Epoch: 6| Step: 3
Training loss: 0.07566460967063904
Validation loss: 1.473896162484282

Epoch: 6| Step: 4
Training loss: 0.06233222782611847
Validation loss: 1.4563351036399923

Epoch: 6| Step: 5
Training loss: 0.0708022490143776
Validation loss: 1.4686072193166262

Epoch: 6| Step: 6
Training loss: 0.08885237574577332
Validation loss: 1.4586054503276784

Epoch: 6| Step: 7
Training loss: 0.0566328689455986
Validation loss: 1.4708259349228234

Epoch: 6| Step: 8
Training loss: 0.051932524889707565
Validation loss: 1.4425249356095509

Epoch: 6| Step: 9
Training loss: 0.06885996460914612
Validation loss: 1.4563324387355516

Epoch: 6| Step: 10
Training loss: 0.13777071237564087
Validation loss: 1.4456226236076766

Epoch: 6| Step: 11
Training loss: 0.06476624310016632
Validation loss: 1.4522628681634062

Epoch: 6| Step: 12
Training loss: 0.12488289177417755
Validation loss: 1.4536405660772835

Epoch: 6| Step: 13
Training loss: 0.02869570255279541
Validation loss: 1.4491087326439478

Epoch: 588| Step: 0
Training loss: 0.05541074275970459
Validation loss: 1.4447256134402366

Epoch: 6| Step: 1
Training loss: 0.05636058375239372
Validation loss: 1.4244460072568668

Epoch: 6| Step: 2
Training loss: 0.09482567757368088
Validation loss: 1.4412903247341033

Epoch: 6| Step: 3
Training loss: 0.043382368981838226
Validation loss: 1.4543599403032692

Epoch: 6| Step: 4
Training loss: 0.04033264145255089
Validation loss: 1.422587966406217

Epoch: 6| Step: 5
Training loss: 0.11353926360607147
Validation loss: 1.4212095827184699

Epoch: 6| Step: 6
Training loss: 0.0625324696302414
Validation loss: 1.4114102932714647

Epoch: 6| Step: 7
Training loss: 0.10907793045043945
Validation loss: 1.391222006531172

Epoch: 6| Step: 8
Training loss: 0.0640716478228569
Validation loss: 1.386530622359245

Epoch: 6| Step: 9
Training loss: 0.09652449935674667
Validation loss: 1.3759988328462005

Epoch: 6| Step: 10
Training loss: 0.0653812438249588
Validation loss: 1.3996397846488542

Epoch: 6| Step: 11
Training loss: 0.07393845915794373
Validation loss: 1.3814635686976935

Epoch: 6| Step: 12
Training loss: 0.042261481285095215
Validation loss: 1.3888219453955208

Epoch: 6| Step: 13
Training loss: 0.04348589479923248
Validation loss: 1.3943366453211794

Epoch: 589| Step: 0
Training loss: 0.0954720675945282
Validation loss: 1.3971955865942023

Epoch: 6| Step: 1
Training loss: 0.10794693231582642
Validation loss: 1.3889603319988455

Epoch: 6| Step: 2
Training loss: 0.05698946863412857
Validation loss: 1.4057551058389808

Epoch: 6| Step: 3
Training loss: 0.07737062871456146
Validation loss: 1.4080377714608305

Epoch: 6| Step: 4
Training loss: 0.11546473205089569
Validation loss: 1.3986810625240367

Epoch: 6| Step: 5
Training loss: 0.06352034211158752
Validation loss: 1.4086642079455878

Epoch: 6| Step: 6
Training loss: 0.06549859046936035
Validation loss: 1.3961509261080014

Epoch: 6| Step: 7
Training loss: 0.0577438622713089
Validation loss: 1.4285756362381803

Epoch: 6| Step: 8
Training loss: 0.05701630935072899
Validation loss: 1.3830470500453826

Epoch: 6| Step: 9
Training loss: 0.061978019773960114
Validation loss: 1.4062391570819321

Epoch: 6| Step: 10
Training loss: 0.06348200142383575
Validation loss: 1.4097794204629877

Epoch: 6| Step: 11
Training loss: 0.05717815086245537
Validation loss: 1.389376922320294

Epoch: 6| Step: 12
Training loss: 0.07236655801534653
Validation loss: 1.4012845562350364

Epoch: 6| Step: 13
Training loss: 0.10942081362009048
Validation loss: 1.3834477368221487

Epoch: 590| Step: 0
Training loss: 0.05867461860179901
Validation loss: 1.3791734595452585

Epoch: 6| Step: 1
Training loss: 0.05438901111483574
Validation loss: 1.413115575108477

Epoch: 6| Step: 2
Training loss: 0.044775623828172684
Validation loss: 1.4305958055680799

Epoch: 6| Step: 3
Training loss: 0.06650924682617188
Validation loss: 1.4039119840950094

Epoch: 6| Step: 4
Training loss: 0.07201087474822998
Validation loss: 1.4220002722996536

Epoch: 6| Step: 5
Training loss: 0.049902524799108505
Validation loss: 1.416324455250976

Epoch: 6| Step: 6
Training loss: 0.07186369597911835
Validation loss: 1.4218516477974512

Epoch: 6| Step: 7
Training loss: 0.05808074027299881
Validation loss: 1.4026373740165465

Epoch: 6| Step: 8
Training loss: 0.05123262107372284
Validation loss: 1.4205359053868118

Epoch: 6| Step: 9
Training loss: 0.05806475877761841
Validation loss: 1.4312328484750563

Epoch: 6| Step: 10
Training loss: 0.04122058302164078
Validation loss: 1.4301773630162722

Epoch: 6| Step: 11
Training loss: 0.1197267472743988
Validation loss: 1.4449460000120184

Epoch: 6| Step: 12
Training loss: 0.10091687738895416
Validation loss: 1.4478759945079844

Epoch: 6| Step: 13
Training loss: 0.0683700442314148
Validation loss: 1.4573957048436648

Epoch: 591| Step: 0
Training loss: 0.060181111097335815
Validation loss: 1.4365254538033598

Epoch: 6| Step: 1
Training loss: 0.0984242856502533
Validation loss: 1.4306310684450212

Epoch: 6| Step: 2
Training loss: 0.0821438580751419
Validation loss: 1.4157069844584311

Epoch: 6| Step: 3
Training loss: 0.05406216159462929
Validation loss: 1.4301916001945414

Epoch: 6| Step: 4
Training loss: 0.07633548974990845
Validation loss: 1.4377348346094931

Epoch: 6| Step: 5
Training loss: 0.05923141911625862
Validation loss: 1.4238288056465886

Epoch: 6| Step: 6
Training loss: 0.06977952271699905
Validation loss: 1.4078316765446817

Epoch: 6| Step: 7
Training loss: 0.09043732285499573
Validation loss: 1.3900808326659664

Epoch: 6| Step: 8
Training loss: 0.06421522796154022
Validation loss: 1.3979846123726136

Epoch: 6| Step: 9
Training loss: 0.08390575647354126
Validation loss: 1.4068503302912558

Epoch: 6| Step: 10
Training loss: 0.06265411525964737
Validation loss: 1.3948024498519076

Epoch: 6| Step: 11
Training loss: 0.06349273025989532
Validation loss: 1.3940861122582549

Epoch: 6| Step: 12
Training loss: 0.07275345176458359
Validation loss: 1.3913319059597549

Epoch: 6| Step: 13
Training loss: 0.04397761821746826
Validation loss: 1.4208200054783975

Epoch: 592| Step: 0
Training loss: 0.042741499841213226
Validation loss: 1.4217036795872513

Epoch: 6| Step: 1
Training loss: 0.06193278729915619
Validation loss: 1.4205659858642086

Epoch: 6| Step: 2
Training loss: 0.0687018409371376
Validation loss: 1.423199192811084

Epoch: 6| Step: 3
Training loss: 0.04576697200536728
Validation loss: 1.4115495566398866

Epoch: 6| Step: 4
Training loss: 0.07686454802751541
Validation loss: 1.4261890816432174

Epoch: 6| Step: 5
Training loss: 0.0656922310590744
Validation loss: 1.456123383455379

Epoch: 6| Step: 6
Training loss: 0.06416381895542145
Validation loss: 1.4337990745421378

Epoch: 6| Step: 7
Training loss: 0.08583281934261322
Validation loss: 1.4506416064436718

Epoch: 6| Step: 8
Training loss: 0.07433664798736572
Validation loss: 1.4543810467566214

Epoch: 6| Step: 9
Training loss: 0.03981718420982361
Validation loss: 1.4125052421323714

Epoch: 6| Step: 10
Training loss: 0.0432727113366127
Validation loss: 1.417981114438785

Epoch: 6| Step: 11
Training loss: 0.133090078830719
Validation loss: 1.4278698146984141

Epoch: 6| Step: 12
Training loss: 0.033518142998218536
Validation loss: 1.411794065788228

Epoch: 6| Step: 13
Training loss: 0.030028529465198517
Validation loss: 1.4044182108294578

Epoch: 593| Step: 0
Training loss: 0.051097068935632706
Validation loss: 1.4032425752250097

Epoch: 6| Step: 1
Training loss: 0.058745309710502625
Validation loss: 1.3940256872484762

Epoch: 6| Step: 2
Training loss: 0.06890182197093964
Validation loss: 1.381887230821835

Epoch: 6| Step: 3
Training loss: 0.044884584844112396
Validation loss: 1.3973937938290257

Epoch: 6| Step: 4
Training loss: 0.039741598069667816
Validation loss: 1.3823380483094083

Epoch: 6| Step: 5
Training loss: 0.08078964054584503
Validation loss: 1.350820246563163

Epoch: 6| Step: 6
Training loss: 0.03779536858201027
Validation loss: 1.3656610859337674

Epoch: 6| Step: 7
Training loss: 0.09553930908441544
Validation loss: 1.386652572180635

Epoch: 6| Step: 8
Training loss: 0.06475690007209778
Validation loss: 1.3996660081289147

Epoch: 6| Step: 9
Training loss: 0.03481736034154892
Validation loss: 1.4086018159825315

Epoch: 6| Step: 10
Training loss: 0.1218557134270668
Validation loss: 1.4107901588562997

Epoch: 6| Step: 11
Training loss: 0.07184350490570068
Validation loss: 1.4180393039539296

Epoch: 6| Step: 12
Training loss: 0.11907503753900528
Validation loss: 1.4406565876417263

Epoch: 6| Step: 13
Training loss: 0.04529860243201256
Validation loss: 1.4233814093374437

Epoch: 594| Step: 0
Training loss: 0.06672289967536926
Validation loss: 1.4257291132403958

Epoch: 6| Step: 1
Training loss: 0.0828627347946167
Validation loss: 1.4077982056525447

Epoch: 6| Step: 2
Training loss: 0.06341676414012909
Validation loss: 1.4277799937032885

Epoch: 6| Step: 3
Training loss: 0.05969548970460892
Validation loss: 1.4330743999891384

Epoch: 6| Step: 4
Training loss: 0.08801504224538803
Validation loss: 1.4462567631916334

Epoch: 6| Step: 5
Training loss: 0.08056037127971649
Validation loss: 1.4365944586774355

Epoch: 6| Step: 6
Training loss: 0.055419668555259705
Validation loss: 1.4330632840433428

Epoch: 6| Step: 7
Training loss: 0.1347925364971161
Validation loss: 1.4117899274313321

Epoch: 6| Step: 8
Training loss: 0.042869340628385544
Validation loss: 1.4381358200503933

Epoch: 6| Step: 9
Training loss: 0.0705309808254242
Validation loss: 1.4248485783095002

Epoch: 6| Step: 10
Training loss: 0.0751819759607315
Validation loss: 1.4211523532867432

Epoch: 6| Step: 11
Training loss: 0.059741146862506866
Validation loss: 1.420885000177609

Epoch: 6| Step: 12
Training loss: 0.09200401604175568
Validation loss: 1.4227106955743605

Epoch: 6| Step: 13
Training loss: 0.04462822899222374
Validation loss: 1.4039329136571577

Epoch: 595| Step: 0
Training loss: 0.05984355881810188
Validation loss: 1.3986094279955792

Epoch: 6| Step: 1
Training loss: 0.12545162439346313
Validation loss: 1.422515651231171

Epoch: 6| Step: 2
Training loss: 0.07366392016410828
Validation loss: 1.4291268587112427

Epoch: 6| Step: 3
Training loss: 0.06137450784444809
Validation loss: 1.4032844074310795

Epoch: 6| Step: 4
Training loss: 0.07919852435588837
Validation loss: 1.4001505554363292

Epoch: 6| Step: 5
Training loss: 0.09286722540855408
Validation loss: 1.4046449789436914

Epoch: 6| Step: 6
Training loss: 0.04310505837202072
Validation loss: 1.4176648662936302

Epoch: 6| Step: 7
Training loss: 0.06095873564481735
Validation loss: 1.3860134373429

Epoch: 6| Step: 8
Training loss: 0.11108429729938507
Validation loss: 1.3873726373077722

Epoch: 6| Step: 9
Training loss: 0.09441956877708435
Validation loss: 1.38429815923014

Epoch: 6| Step: 10
Training loss: 0.07889866083860397
Validation loss: 1.3877237176382413

Epoch: 6| Step: 11
Training loss: 0.05102447792887688
Validation loss: 1.4036158361742574

Epoch: 6| Step: 12
Training loss: 0.059387072920799255
Validation loss: 1.4080064783814132

Epoch: 6| Step: 13
Training loss: 0.06608273088932037
Validation loss: 1.4142141137071835

Epoch: 596| Step: 0
Training loss: 0.07081256061792374
Validation loss: 1.4357404708862305

Epoch: 6| Step: 1
Training loss: 0.11416532099246979
Validation loss: 1.4196322964083763

Epoch: 6| Step: 2
Training loss: 0.06828557699918747
Validation loss: 1.4362162082426009

Epoch: 6| Step: 3
Training loss: 0.052592359483242035
Validation loss: 1.430527138453658

Epoch: 6| Step: 4
Training loss: 0.06420014798641205
Validation loss: 1.4482117032492032

Epoch: 6| Step: 5
Training loss: 0.08261729776859283
Validation loss: 1.450667005713268

Epoch: 6| Step: 6
Training loss: 0.08089818805456161
Validation loss: 1.465680310803075

Epoch: 6| Step: 7
Training loss: 0.10165740549564362
Validation loss: 1.4562180683177004

Epoch: 6| Step: 8
Training loss: 0.07746701687574387
Validation loss: 1.466589823845894

Epoch: 6| Step: 9
Training loss: 0.12821754813194275
Validation loss: 1.4964103929458126

Epoch: 6| Step: 10
Training loss: 0.052277255803346634
Validation loss: 1.4626217016609766

Epoch: 6| Step: 11
Training loss: 0.07442360371351242
Validation loss: 1.4732219711426766

Epoch: 6| Step: 12
Training loss: 0.0606968030333519
Validation loss: 1.4878198780039305

Epoch: 6| Step: 13
Training loss: 0.07517775893211365
Validation loss: 1.4848729397660942

Epoch: 597| Step: 0
Training loss: 0.07208943367004395
Validation loss: 1.469888481401628

Epoch: 6| Step: 1
Training loss: 0.17177481949329376
Validation loss: 1.4559670545721566

Epoch: 6| Step: 2
Training loss: 0.060187533497810364
Validation loss: 1.438312832706718

Epoch: 6| Step: 3
Training loss: 0.049114711582660675
Validation loss: 1.4202260054567808

Epoch: 6| Step: 4
Training loss: 0.03315897285938263
Validation loss: 1.390032696467574

Epoch: 6| Step: 5
Training loss: 0.12320113927125931
Validation loss: 1.4129156367753142

Epoch: 6| Step: 6
Training loss: 0.07102704048156738
Validation loss: 1.3974103786612069

Epoch: 6| Step: 7
Training loss: 0.048801034688949585
Validation loss: 1.3724509073841957

Epoch: 6| Step: 8
Training loss: 0.040318068116903305
Validation loss: 1.3929943025753062

Epoch: 6| Step: 9
Training loss: 0.09192253649234772
Validation loss: 1.3927259983554963

Epoch: 6| Step: 10
Training loss: 0.05115007609128952
Validation loss: 1.4213169185064172

Epoch: 6| Step: 11
Training loss: 0.06294667720794678
Validation loss: 1.4117973837801205

Epoch: 6| Step: 12
Training loss: 0.058265481144189835
Validation loss: 1.404598428357032

Epoch: 6| Step: 13
Training loss: 0.07538725435733795
Validation loss: 1.4156687375037902

Epoch: 598| Step: 0
Training loss: 0.06720466911792755
Validation loss: 1.4327281495576263

Epoch: 6| Step: 1
Training loss: 0.0821470320224762
Validation loss: 1.4521180070856565

Epoch: 6| Step: 2
Training loss: 0.06681662797927856
Validation loss: 1.4300059144214918

Epoch: 6| Step: 3
Training loss: 0.05220753699541092
Validation loss: 1.4463986248098395

Epoch: 6| Step: 4
Training loss: 0.06700197607278824
Validation loss: 1.4418875555838309

Epoch: 6| Step: 5
Training loss: 0.1296471357345581
Validation loss: 1.450091132553675

Epoch: 6| Step: 6
Training loss: 0.06084008887410164
Validation loss: 1.434187545571276

Epoch: 6| Step: 7
Training loss: 0.058201201260089874
Validation loss: 1.4245005743477934

Epoch: 6| Step: 8
Training loss: 0.06609226018190384
Validation loss: 1.4205682687861945

Epoch: 6| Step: 9
Training loss: 0.06433521211147308
Validation loss: 1.4565997623628186

Epoch: 6| Step: 10
Training loss: 0.0774133950471878
Validation loss: 1.4369136018137778

Epoch: 6| Step: 11
Training loss: 0.11073864996433258
Validation loss: 1.4147913789236417

Epoch: 6| Step: 12
Training loss: 0.05109097808599472
Validation loss: 1.421411363027429

Epoch: 6| Step: 13
Training loss: 0.05845433473587036
Validation loss: 1.4133839620056974

Epoch: 599| Step: 0
Training loss: 0.060625962913036346
Validation loss: 1.4324089173347718

Epoch: 6| Step: 1
Training loss: 0.07665061950683594
Validation loss: 1.4000238949252712

Epoch: 6| Step: 2
Training loss: 0.07823541760444641
Validation loss: 1.422066528310058

Epoch: 6| Step: 3
Training loss: 0.05037281662225723
Validation loss: 1.4064895747810282

Epoch: 6| Step: 4
Training loss: 0.05772886797785759
Validation loss: 1.4089399371095883

Epoch: 6| Step: 5
Training loss: 0.07425503432750702
Validation loss: 1.4461083758261897

Epoch: 6| Step: 6
Training loss: 0.09567941725254059
Validation loss: 1.4484149320151216

Epoch: 6| Step: 7
Training loss: 0.05293451249599457
Validation loss: 1.4268258681861303

Epoch: 6| Step: 8
Training loss: 0.06835624575614929
Validation loss: 1.4352326739218928

Epoch: 6| Step: 9
Training loss: 0.058521416038274765
Validation loss: 1.4463305050326931

Epoch: 6| Step: 10
Training loss: 0.07365895807743073
Validation loss: 1.4188322418479509

Epoch: 6| Step: 11
Training loss: 0.04652227461338043
Validation loss: 1.446531408576555

Epoch: 6| Step: 12
Training loss: 0.057190559804439545
Validation loss: 1.4367005209768973

Epoch: 6| Step: 13
Training loss: 0.14064496755599976
Validation loss: 1.4285001472760273

Epoch: 600| Step: 0
Training loss: 0.06456547230482101
Validation loss: 1.4261854720372025

Epoch: 6| Step: 1
Training loss: 0.11915294080972672
Validation loss: 1.4323950467571136

Epoch: 6| Step: 2
Training loss: 0.10505668818950653
Validation loss: 1.450304941464496

Epoch: 6| Step: 3
Training loss: 0.07819361239671707
Validation loss: 1.426155335159712

Epoch: 6| Step: 4
Training loss: 0.06089356541633606
Validation loss: 1.4354277426196682

Epoch: 6| Step: 5
Training loss: 0.06115754321217537
Validation loss: 1.4442676677498767

Epoch: 6| Step: 6
Training loss: 0.06157510727643967
Validation loss: 1.423799213542733

Epoch: 6| Step: 7
Training loss: 0.05817980319261551
Validation loss: 1.4347158619152602

Epoch: 6| Step: 8
Training loss: 0.05192039906978607
Validation loss: 1.432785213634532

Epoch: 6| Step: 9
Training loss: 0.07147710025310516
Validation loss: 1.4289256186895474

Epoch: 6| Step: 10
Training loss: 0.051959313452243805
Validation loss: 1.4311559892469836

Epoch: 6| Step: 11
Training loss: 0.03521985560655594
Validation loss: 1.41376632003374

Epoch: 6| Step: 12
Training loss: 0.04545975849032402
Validation loss: 1.4166382378147495

Epoch: 6| Step: 13
Training loss: 0.0800415575504303
Validation loss: 1.425874319127811

Epoch: 601| Step: 0
Training loss: 0.07113572955131531
Validation loss: 1.4232508546562606

Epoch: 6| Step: 1
Training loss: 0.05985158681869507
Validation loss: 1.4136025315971785

Epoch: 6| Step: 2
Training loss: 0.08683938533067703
Validation loss: 1.409912641330432

Epoch: 6| Step: 3
Training loss: 0.06602734327316284
Validation loss: 1.4260323714184504

Epoch: 6| Step: 4
Training loss: 0.07186426967382431
Validation loss: 1.434611274350074

Epoch: 6| Step: 5
Training loss: 0.055644698441028595
Validation loss: 1.392563896794473

Epoch: 6| Step: 6
Training loss: 0.073732390999794
Validation loss: 1.4236667656129407

Epoch: 6| Step: 7
Training loss: 0.057937346398830414
Validation loss: 1.4306013622591573

Epoch: 6| Step: 8
Training loss: 0.07311258465051651
Validation loss: 1.4238764919260496

Epoch: 6| Step: 9
Training loss: 0.07237865030765533
Validation loss: 1.4339221754381735

Epoch: 6| Step: 10
Training loss: 0.06433403491973877
Validation loss: 1.423407999418115

Epoch: 6| Step: 11
Training loss: 0.07225112617015839
Validation loss: 1.4429404171564246

Epoch: 6| Step: 12
Training loss: 0.05090344697237015
Validation loss: 1.428703368991934

Epoch: 6| Step: 13
Training loss: 0.029499106109142303
Validation loss: 1.4188242599528322

Epoch: 602| Step: 0
Training loss: 0.09618030488491058
Validation loss: 1.4313314537848196

Epoch: 6| Step: 1
Training loss: 0.05727392062544823
Validation loss: 1.4725691580003308

Epoch: 6| Step: 2
Training loss: 0.04171033576130867
Validation loss: 1.4468008523346276

Epoch: 6| Step: 3
Training loss: 0.034203432500362396
Validation loss: 1.416119981837529

Epoch: 6| Step: 4
Training loss: 0.09284619241952896
Validation loss: 1.4315833603182146

Epoch: 6| Step: 5
Training loss: 0.04719315096735954
Validation loss: 1.4267096199015135

Epoch: 6| Step: 6
Training loss: 0.07566364854574203
Validation loss: 1.406720588284154

Epoch: 6| Step: 7
Training loss: 0.046691328287124634
Validation loss: 1.3963862465273948

Epoch: 6| Step: 8
Training loss: 0.049813248217105865
Validation loss: 1.3871719657733876

Epoch: 6| Step: 9
Training loss: 0.060144126415252686
Validation loss: 1.3796651965828353

Epoch: 6| Step: 10
Training loss: 0.09578939527273178
Validation loss: 1.422787720157254

Epoch: 6| Step: 11
Training loss: 0.0630178451538086
Validation loss: 1.3926360735329248

Epoch: 6| Step: 12
Training loss: 0.06199197098612785
Validation loss: 1.4158454018254434

Epoch: 6| Step: 13
Training loss: 0.0497799851000309
Validation loss: 1.3955727930991881

Epoch: 603| Step: 0
Training loss: 0.05595128610730171
Validation loss: 1.3949107252141482

Epoch: 6| Step: 1
Training loss: 0.08742552995681763
Validation loss: 1.372867679083219

Epoch: 6| Step: 2
Training loss: 0.07674964517354965
Validation loss: 1.396484701864181

Epoch: 6| Step: 3
Training loss: 0.09314890205860138
Validation loss: 1.4103882146138016

Epoch: 6| Step: 4
Training loss: 0.06908048689365387
Validation loss: 1.3857092216450682

Epoch: 6| Step: 5
Training loss: 0.09194076806306839
Validation loss: 1.396290236903775

Epoch: 6| Step: 6
Training loss: 0.05608821287751198
Validation loss: 1.4013657095611736

Epoch: 6| Step: 7
Training loss: 0.08607208728790283
Validation loss: 1.372852768949283

Epoch: 6| Step: 8
Training loss: 0.05680547654628754
Validation loss: 1.3999969754167783

Epoch: 6| Step: 9
Training loss: 0.08005872368812561
Validation loss: 1.3874348055931829

Epoch: 6| Step: 10
Training loss: 0.15120837092399597
Validation loss: 1.3835989185558852

Epoch: 6| Step: 11
Training loss: 0.09368904680013657
Validation loss: 1.4087908434611496

Epoch: 6| Step: 12
Training loss: 0.04597432166337967
Validation loss: 1.3909185265982023

Epoch: 6| Step: 13
Training loss: 0.16174858808517456
Validation loss: 1.4000993492782756

Epoch: 604| Step: 0
Training loss: 0.0451781302690506
Validation loss: 1.401175420771363

Epoch: 6| Step: 1
Training loss: 0.156015083193779
Validation loss: 1.4082916487929642

Epoch: 6| Step: 2
Training loss: 0.07904943823814392
Validation loss: 1.4175260759169055

Epoch: 6| Step: 3
Training loss: 0.10349874198436737
Validation loss: 1.4225235292988438

Epoch: 6| Step: 4
Training loss: 0.041352249681949615
Validation loss: 1.4591968469722296

Epoch: 6| Step: 5
Training loss: 0.05497971549630165
Validation loss: 1.4580153342216247

Epoch: 6| Step: 6
Training loss: 0.07122042775154114
Validation loss: 1.4543053732123425

Epoch: 6| Step: 7
Training loss: 0.0660146027803421
Validation loss: 1.464411577870769

Epoch: 6| Step: 8
Training loss: 0.05692461133003235
Validation loss: 1.443707340507097

Epoch: 6| Step: 9
Training loss: 0.08033660054206848
Validation loss: 1.4468634641298683

Epoch: 6| Step: 10
Training loss: 0.07344026118516922
Validation loss: 1.4522443779053227

Epoch: 6| Step: 11
Training loss: 0.049284353852272034
Validation loss: 1.437957202234576

Epoch: 6| Step: 12
Training loss: 0.034813977777957916
Validation loss: 1.439195575252656

Epoch: 6| Step: 13
Training loss: 0.026287555694580078
Validation loss: 1.4257546368465628

Epoch: 605| Step: 0
Training loss: 0.05983658507466316
Validation loss: 1.415361439028094

Epoch: 6| Step: 1
Training loss: 0.05486248433589935
Validation loss: 1.4182923045209659

Epoch: 6| Step: 2
Training loss: 0.05944246053695679
Validation loss: 1.4118146332361365

Epoch: 6| Step: 3
Training loss: 0.05270255357027054
Validation loss: 1.3846058819883613

Epoch: 6| Step: 4
Training loss: 0.04891074448823929
Validation loss: 1.3857391367676437

Epoch: 6| Step: 5
Training loss: 0.0851428359746933
Validation loss: 1.392933440464799

Epoch: 6| Step: 6
Training loss: 0.05097246170043945
Validation loss: 1.37266243016848

Epoch: 6| Step: 7
Training loss: 0.05470169708132744
Validation loss: 1.3776672065898936

Epoch: 6| Step: 8
Training loss: 0.06966769695281982
Validation loss: 1.3922492752793014

Epoch: 6| Step: 9
Training loss: 0.1281333565711975
Validation loss: 1.4035340996198757

Epoch: 6| Step: 10
Training loss: 0.08045656979084015
Validation loss: 1.412098870482496

Epoch: 6| Step: 11
Training loss: 0.07056920230388641
Validation loss: 1.4007550080617268

Epoch: 6| Step: 12
Training loss: 0.07932193577289581
Validation loss: 1.4202793413592922

Epoch: 6| Step: 13
Training loss: 0.04532575234770775
Validation loss: 1.4175097980806906

Epoch: 606| Step: 0
Training loss: 0.05537019670009613
Validation loss: 1.4200510183970134

Epoch: 6| Step: 1
Training loss: 0.03406792879104614
Validation loss: 1.3910665127538866

Epoch: 6| Step: 2
Training loss: 0.049352023750543594
Validation loss: 1.412905671904164

Epoch: 6| Step: 3
Training loss: 0.09471316635608673
Validation loss: 1.4078600150282665

Epoch: 6| Step: 4
Training loss: 0.0804160088300705
Validation loss: 1.4146685100370837

Epoch: 6| Step: 5
Training loss: 0.032577648758888245
Validation loss: 1.4079580589007306

Epoch: 6| Step: 6
Training loss: 0.06987269222736359
Validation loss: 1.4034293928454

Epoch: 6| Step: 7
Training loss: 0.05878910422325134
Validation loss: 1.416530260475733

Epoch: 6| Step: 8
Training loss: 0.0702192634344101
Validation loss: 1.4258056186860608

Epoch: 6| Step: 9
Training loss: 0.0888788104057312
Validation loss: 1.4222364605114024

Epoch: 6| Step: 10
Training loss: 0.04410170018672943
Validation loss: 1.3854450910322127

Epoch: 6| Step: 11
Training loss: 0.05885041505098343
Validation loss: 1.4072953039600002

Epoch: 6| Step: 12
Training loss: 0.05229125916957855
Validation loss: 1.366489710346345

Epoch: 6| Step: 13
Training loss: 0.11584790796041489
Validation loss: 1.4114785681488693

Epoch: 607| Step: 0
Training loss: 0.06663727760314941
Validation loss: 1.4285748274095598

Epoch: 6| Step: 1
Training loss: 0.0693761482834816
Validation loss: 1.4012223584677583

Epoch: 6| Step: 2
Training loss: 0.13251657783985138
Validation loss: 1.4098592650505803

Epoch: 6| Step: 3
Training loss: 0.045676425099372864
Validation loss: 1.443372618767523

Epoch: 6| Step: 4
Training loss: 0.0569109171628952
Validation loss: 1.4285984411034534

Epoch: 6| Step: 5
Training loss: 0.05887402966618538
Validation loss: 1.4252671439160582

Epoch: 6| Step: 6
Training loss: 0.10799027234315872
Validation loss: 1.4417362828408518

Epoch: 6| Step: 7
Training loss: 0.04737289249897003
Validation loss: 1.4415330092112224

Epoch: 6| Step: 8
Training loss: 0.036286611109972
Validation loss: 1.4414880557726788

Epoch: 6| Step: 9
Training loss: 0.069058358669281
Validation loss: 1.42206121196029

Epoch: 6| Step: 10
Training loss: 0.07558397948741913
Validation loss: 1.4127012093861897

Epoch: 6| Step: 11
Training loss: 0.06523530185222626
Validation loss: 1.4554158692718835

Epoch: 6| Step: 12
Training loss: 0.08509890735149384
Validation loss: 1.410194407868129

Epoch: 6| Step: 13
Training loss: 0.10866835713386536
Validation loss: 1.416492969759049

Epoch: 608| Step: 0
Training loss: 0.0888635516166687
Validation loss: 1.4234023709450998

Epoch: 6| Step: 1
Training loss: 0.05928106978535652
Validation loss: 1.3924648351566766

Epoch: 6| Step: 2
Training loss: 0.058158889412879944
Validation loss: 1.4051342202771095

Epoch: 6| Step: 3
Training loss: 0.06703521311283112
Validation loss: 1.416663881271116

Epoch: 6| Step: 4
Training loss: 0.06728145480155945
Validation loss: 1.424558457507882

Epoch: 6| Step: 5
Training loss: 0.053697988390922546
Validation loss: 1.4337258838838147

Epoch: 6| Step: 6
Training loss: 0.037236325442790985
Validation loss: 1.4535116521261071

Epoch: 6| Step: 7
Training loss: 0.06147446855902672
Validation loss: 1.4470596774931876

Epoch: 6| Step: 8
Training loss: 0.05060809105634689
Validation loss: 1.447193330334079

Epoch: 6| Step: 9
Training loss: 0.08930513262748718
Validation loss: 1.4295172537526777

Epoch: 6| Step: 10
Training loss: 0.10178781300783157
Validation loss: 1.4451224951333896

Epoch: 6| Step: 11
Training loss: 0.05686448514461517
Validation loss: 1.4421184357776438

Epoch: 6| Step: 12
Training loss: 0.06935562193393707
Validation loss: 1.4186894432190926

Epoch: 6| Step: 13
Training loss: 0.06730568408966064
Validation loss: 1.4109566544973722

Epoch: 609| Step: 0
Training loss: 0.09526784718036652
Validation loss: 1.430375833665171

Epoch: 6| Step: 1
Training loss: 0.0916861891746521
Validation loss: 1.4204674049090313

Epoch: 6| Step: 2
Training loss: 0.057997480034828186
Validation loss: 1.4449906977274085

Epoch: 6| Step: 3
Training loss: 0.04656188189983368
Validation loss: 1.4344014454913396

Epoch: 6| Step: 4
Training loss: 0.04346121847629547
Validation loss: 1.4412631732161327

Epoch: 6| Step: 5
Training loss: 0.06376388669013977
Validation loss: 1.4195613694447342

Epoch: 6| Step: 6
Training loss: 0.05816769599914551
Validation loss: 1.422347903251648

Epoch: 6| Step: 7
Training loss: 0.03842034935951233
Validation loss: 1.448987563451131

Epoch: 6| Step: 8
Training loss: 0.03349229693412781
Validation loss: 1.436115220028867

Epoch: 6| Step: 9
Training loss: 0.06276964396238327
Validation loss: 1.44180404755377

Epoch: 6| Step: 10
Training loss: 0.06474010646343231
Validation loss: 1.4352777709243119

Epoch: 6| Step: 11
Training loss: 0.06549227982759476
Validation loss: 1.4414100993064143

Epoch: 6| Step: 12
Training loss: 0.060026537626981735
Validation loss: 1.4265456276555215

Epoch: 6| Step: 13
Training loss: 0.06611596047878265
Validation loss: 1.4165115958900862

Epoch: 610| Step: 0
Training loss: 0.05651969835162163
Validation loss: 1.3944985969092256

Epoch: 6| Step: 1
Training loss: 0.07266490161418915
Validation loss: 1.3934963057118077

Epoch: 6| Step: 2
Training loss: 0.05144234746694565
Validation loss: 1.3920835474485993

Epoch: 6| Step: 3
Training loss: 0.09177108108997345
Validation loss: 1.4000838225887668

Epoch: 6| Step: 4
Training loss: 0.06572049111127853
Validation loss: 1.3709104650764055

Epoch: 6| Step: 5
Training loss: 0.0732429176568985
Validation loss: 1.4119428075769895

Epoch: 6| Step: 6
Training loss: 0.08826006948947906
Validation loss: 1.3958071047259915

Epoch: 6| Step: 7
Training loss: 0.05616914480924606
Validation loss: 1.393108957557268

Epoch: 6| Step: 8
Training loss: 0.10263559967279434
Validation loss: 1.419611596292065

Epoch: 6| Step: 9
Training loss: 0.05540287494659424
Validation loss: 1.4590589372060632

Epoch: 6| Step: 10
Training loss: 0.07644117623567581
Validation loss: 1.45366963648027

Epoch: 6| Step: 11
Training loss: 0.0767115131020546
Validation loss: 1.4480698884174388

Epoch: 6| Step: 12
Training loss: 0.05059923231601715
Validation loss: 1.461495671221005

Epoch: 6| Step: 13
Training loss: 0.0431002676486969
Validation loss: 1.4705145474403136

Epoch: 611| Step: 0
Training loss: 0.0745515376329422
Validation loss: 1.4514393088638142

Epoch: 6| Step: 1
Training loss: 0.059880033135414124
Validation loss: 1.4521580216705159

Epoch: 6| Step: 2
Training loss: 0.03759819641709328
Validation loss: 1.4507355831002677

Epoch: 6| Step: 3
Training loss: 0.0905776172876358
Validation loss: 1.4384741244777557

Epoch: 6| Step: 4
Training loss: 0.05643342807888985
Validation loss: 1.4064608312422229

Epoch: 6| Step: 5
Training loss: 0.07849348336458206
Validation loss: 1.3914479747895272

Epoch: 6| Step: 6
Training loss: 0.08051000535488129
Validation loss: 1.3925719671351935

Epoch: 6| Step: 7
Training loss: 0.06505518406629562
Validation loss: 1.3579996631991478

Epoch: 6| Step: 8
Training loss: 0.051945120096206665
Validation loss: 1.353588346512087

Epoch: 6| Step: 9
Training loss: 0.11657156050205231
Validation loss: 1.36549323989499

Epoch: 6| Step: 10
Training loss: 0.05134839192032814
Validation loss: 1.3615495940690399

Epoch: 6| Step: 11
Training loss: 0.03921034187078476
Validation loss: 1.3919467733752342

Epoch: 6| Step: 12
Training loss: 0.05679233372211456
Validation loss: 1.3876254738018077

Epoch: 6| Step: 13
Training loss: 0.08736458420753479
Validation loss: 1.410169142548756

Epoch: 612| Step: 0
Training loss: 0.08231646567583084
Validation loss: 1.4118684889167867

Epoch: 6| Step: 1
Training loss: 0.0995989441871643
Validation loss: 1.420207090275262

Epoch: 6| Step: 2
Training loss: 0.08466777205467224
Validation loss: 1.4121757630378968

Epoch: 6| Step: 3
Training loss: 0.08426051586866379
Validation loss: 1.4156599685709963

Epoch: 6| Step: 4
Training loss: 0.10984594374895096
Validation loss: 1.408640048837149

Epoch: 6| Step: 5
Training loss: 0.08761375397443771
Validation loss: 1.418090469093733

Epoch: 6| Step: 6
Training loss: 0.04636036604642868
Validation loss: 1.424011456069126

Epoch: 6| Step: 7
Training loss: 0.12267131358385086
Validation loss: 1.4023513640126875

Epoch: 6| Step: 8
Training loss: 0.07944130897521973
Validation loss: 1.413954351537971

Epoch: 6| Step: 9
Training loss: 0.0583021380007267
Validation loss: 1.4200696086370816

Epoch: 6| Step: 10
Training loss: 0.05608264356851578
Validation loss: 1.4266705397636659

Epoch: 6| Step: 11
Training loss: 0.04097891226410866
Validation loss: 1.421652127337712

Epoch: 6| Step: 12
Training loss: 0.08399344235658646
Validation loss: 1.419185225681592

Epoch: 6| Step: 13
Training loss: 0.03579400107264519
Validation loss: 1.3987200260162354

Epoch: 613| Step: 0
Training loss: 0.08111529797315598
Validation loss: 1.3788419359473771

Epoch: 6| Step: 1
Training loss: 0.06891652196645737
Validation loss: 1.3916249570026193

Epoch: 6| Step: 2
Training loss: 0.0731126144528389
Validation loss: 1.3869698611638879

Epoch: 6| Step: 3
Training loss: 0.09067609161138535
Validation loss: 1.422747177462424

Epoch: 6| Step: 4
Training loss: 0.09668882936239243
Validation loss: 1.4072391012663483

Epoch: 6| Step: 5
Training loss: 0.1164865493774414
Validation loss: 1.419388464702073

Epoch: 6| Step: 6
Training loss: 0.07148584723472595
Validation loss: 1.40260608478259

Epoch: 6| Step: 7
Training loss: 0.045454930514097214
Validation loss: 1.402874122383774

Epoch: 6| Step: 8
Training loss: 0.12299909442663193
Validation loss: 1.4167606587051063

Epoch: 6| Step: 9
Training loss: 0.1014249250292778
Validation loss: 1.3884933712661907

Epoch: 6| Step: 10
Training loss: 0.07531362026929855
Validation loss: 1.4178595824908184

Epoch: 6| Step: 11
Training loss: 0.1056935042142868
Validation loss: 1.4175983308463969

Epoch: 6| Step: 12
Training loss: 0.08267339318990707
Validation loss: 1.3959285084919264

Epoch: 6| Step: 13
Training loss: 0.06891192495822906
Validation loss: 1.4205451293658184

Epoch: 614| Step: 0
Training loss: 0.08188295364379883
Validation loss: 1.4587474561506701

Epoch: 6| Step: 1
Training loss: 0.030748413875699043
Validation loss: 1.418297367711221

Epoch: 6| Step: 2
Training loss: 0.0736691802740097
Validation loss: 1.4297578738581749

Epoch: 6| Step: 3
Training loss: 0.0818660706281662
Validation loss: 1.460754229176429

Epoch: 6| Step: 4
Training loss: 0.08587102591991425
Validation loss: 1.4570166859575497

Epoch: 6| Step: 5
Training loss: 0.14343509078025818
Validation loss: 1.4265583881767847

Epoch: 6| Step: 6
Training loss: 0.08582282066345215
Validation loss: 1.4105442031737296

Epoch: 6| Step: 7
Training loss: 0.09977243840694427
Validation loss: 1.3816208121597127

Epoch: 6| Step: 8
Training loss: 0.06376252323389053
Validation loss: 1.4059156653701619

Epoch: 6| Step: 9
Training loss: 0.047608740627765656
Validation loss: 1.396918407050512

Epoch: 6| Step: 10
Training loss: 0.04271862655878067
Validation loss: 1.4046467683648551

Epoch: 6| Step: 11
Training loss: 0.07679663598537445
Validation loss: 1.3937535914041663

Epoch: 6| Step: 12
Training loss: 0.1357879936695099
Validation loss: 1.4010970374589324

Epoch: 6| Step: 13
Training loss: 0.07034627348184586
Validation loss: 1.4254076916684386

Epoch: 615| Step: 0
Training loss: 0.07577856630086899
Validation loss: 1.4203134557252288

Epoch: 6| Step: 1
Training loss: 0.05589177459478378
Validation loss: 1.4539328480279574

Epoch: 6| Step: 2
Training loss: 0.06774479895830154
Validation loss: 1.438204740965238

Epoch: 6| Step: 3
Training loss: 0.10806432366371155
Validation loss: 1.4551638095609603

Epoch: 6| Step: 4
Training loss: 0.053178511559963226
Validation loss: 1.4271403551101685

Epoch: 6| Step: 5
Training loss: 0.09581802785396576
Validation loss: 1.4267959005089217

Epoch: 6| Step: 6
Training loss: 0.056675560772418976
Validation loss: 1.4257866579999205

Epoch: 6| Step: 7
Training loss: 0.050280697643756866
Validation loss: 1.4238694765234505

Epoch: 6| Step: 8
Training loss: 0.05193180590867996
Validation loss: 1.3886076634930027

Epoch: 6| Step: 9
Training loss: 0.03298645466566086
Validation loss: 1.3840095330310125

Epoch: 6| Step: 10
Training loss: 0.057019446045160294
Validation loss: 1.4039667050043743

Epoch: 6| Step: 11
Training loss: 0.08082796633243561
Validation loss: 1.3951285654498684

Epoch: 6| Step: 12
Training loss: 0.0358881950378418
Validation loss: 1.393563876869858

Epoch: 6| Step: 13
Training loss: 0.06683216989040375
Validation loss: 1.382383914404018

Epoch: 616| Step: 0
Training loss: 0.06746236979961395
Validation loss: 1.3812702202027844

Epoch: 6| Step: 1
Training loss: 0.06239809840917587
Validation loss: 1.4109375736405771

Epoch: 6| Step: 2
Training loss: 0.09297918528318405
Validation loss: 1.4166363131615423

Epoch: 6| Step: 3
Training loss: 0.03757564350962639
Validation loss: 1.4076865539755872

Epoch: 6| Step: 4
Training loss: 0.055813394486904144
Validation loss: 1.411042824868233

Epoch: 6| Step: 5
Training loss: 0.08255556225776672
Validation loss: 1.4179176643330564

Epoch: 6| Step: 6
Training loss: 0.04940462112426758
Validation loss: 1.4503378201556463

Epoch: 6| Step: 7
Training loss: 0.09749846905469894
Validation loss: 1.4552858337279289

Epoch: 6| Step: 8
Training loss: 0.07549326121807098
Validation loss: 1.4478181587752474

Epoch: 6| Step: 9
Training loss: 0.06935276091098785
Validation loss: 1.4492729504903157

Epoch: 6| Step: 10
Training loss: 0.04504293203353882
Validation loss: 1.4456523541481263

Epoch: 6| Step: 11
Training loss: 0.05917389690876007
Validation loss: 1.4564812907608606

Epoch: 6| Step: 12
Training loss: 0.04911968484520912
Validation loss: 1.4337507608116313

Epoch: 6| Step: 13
Training loss: 0.03761178255081177
Validation loss: 1.4283239700460946

Epoch: 617| Step: 0
Training loss: 0.05243362858891487
Validation loss: 1.4558479760282783

Epoch: 6| Step: 1
Training loss: 0.0416317880153656
Validation loss: 1.4290823628825526

Epoch: 6| Step: 2
Training loss: 0.0706300213932991
Validation loss: 1.4597188093328988

Epoch: 6| Step: 3
Training loss: 0.05334015190601349
Validation loss: 1.4489643855761456

Epoch: 6| Step: 4
Training loss: 0.12406079471111298
Validation loss: 1.4578126700975562

Epoch: 6| Step: 5
Training loss: 0.08069807291030884
Validation loss: 1.435747472188806

Epoch: 6| Step: 6
Training loss: 0.0897480696439743
Validation loss: 1.4340075017303548

Epoch: 6| Step: 7
Training loss: 0.0650072768330574
Validation loss: 1.4099570230771137

Epoch: 6| Step: 8
Training loss: 0.06228084862232208
Validation loss: 1.4025586048762004

Epoch: 6| Step: 9
Training loss: 0.0517539419233799
Validation loss: 1.386923486186612

Epoch: 6| Step: 10
Training loss: 0.09409799426794052
Validation loss: 1.3987930256833312

Epoch: 6| Step: 11
Training loss: 0.12917841970920563
Validation loss: 1.3922741387480049

Epoch: 6| Step: 12
Training loss: 0.05374571681022644
Validation loss: 1.3737529490583686

Epoch: 6| Step: 13
Training loss: 0.019694605842232704
Validation loss: 1.367045876800373

Epoch: 618| Step: 0
Training loss: 0.09522503614425659
Validation loss: 1.3730292153614823

Epoch: 6| Step: 1
Training loss: 0.08997839689254761
Validation loss: 1.3728394636543848

Epoch: 6| Step: 2
Training loss: 0.0835326761007309
Validation loss: 1.3801600119119048

Epoch: 6| Step: 3
Training loss: 0.08440396189689636
Validation loss: 1.3784538981735066

Epoch: 6| Step: 4
Training loss: 0.06276696175336838
Validation loss: 1.4081982784373785

Epoch: 6| Step: 5
Training loss: 0.06907941401004791
Validation loss: 1.3974964836592316

Epoch: 6| Step: 6
Training loss: 0.054483041167259216
Validation loss: 1.4098268401238225

Epoch: 6| Step: 7
Training loss: 0.11808282136917114
Validation loss: 1.3915606839682466

Epoch: 6| Step: 8
Training loss: 0.04768507182598114
Validation loss: 1.3934975824048441

Epoch: 6| Step: 9
Training loss: 0.05400686711072922
Validation loss: 1.3997416611640685

Epoch: 6| Step: 10
Training loss: 0.060847945511341095
Validation loss: 1.4234343728711527

Epoch: 6| Step: 11
Training loss: 0.05975273251533508
Validation loss: 1.4283611030988796

Epoch: 6| Step: 12
Training loss: 0.03703759238123894
Validation loss: 1.4071118780361709

Epoch: 6| Step: 13
Training loss: 0.024805797263979912
Validation loss: 1.4212680990977953

Epoch: 619| Step: 0
Training loss: 0.052501507103443146
Validation loss: 1.4469484847079042

Epoch: 6| Step: 1
Training loss: 0.0880654975771904
Validation loss: 1.4252573238906039

Epoch: 6| Step: 2
Training loss: 0.08141610026359558
Validation loss: 1.438437044620514

Epoch: 6| Step: 3
Training loss: 0.09010455757379532
Validation loss: 1.4595269169858707

Epoch: 6| Step: 4
Training loss: 0.07677896320819855
Validation loss: 1.4504349859811927

Epoch: 6| Step: 5
Training loss: 0.08073030412197113
Validation loss: 1.456404133509564

Epoch: 6| Step: 6
Training loss: 0.03721300885081291
Validation loss: 1.455048712350989

Epoch: 6| Step: 7
Training loss: 0.09361825883388519
Validation loss: 1.4238205109873125

Epoch: 6| Step: 8
Training loss: 0.07236463576555252
Validation loss: 1.437131763786398

Epoch: 6| Step: 9
Training loss: 0.04597965627908707
Validation loss: 1.4103041438646213

Epoch: 6| Step: 10
Training loss: 0.0697689950466156
Validation loss: 1.4245272028830744

Epoch: 6| Step: 11
Training loss: 0.04858259856700897
Validation loss: 1.3917375661993538

Epoch: 6| Step: 12
Training loss: 0.04098010063171387
Validation loss: 1.4328177898160872

Epoch: 6| Step: 13
Training loss: 0.05460614711046219
Validation loss: 1.4274986841345345

Epoch: 620| Step: 0
Training loss: 0.07000942528247833
Validation loss: 1.4115881381496307

Epoch: 6| Step: 1
Training loss: 0.06677517294883728
Validation loss: 1.431025464688578

Epoch: 6| Step: 2
Training loss: 0.06566708534955978
Validation loss: 1.4227451432135798

Epoch: 6| Step: 3
Training loss: 0.0583968311548233
Validation loss: 1.4068414293309695

Epoch: 6| Step: 4
Training loss: 0.060703344643116
Validation loss: 1.4107594079868768

Epoch: 6| Step: 5
Training loss: 0.06854887306690216
Validation loss: 1.4047663301549933

Epoch: 6| Step: 6
Training loss: 0.09447921812534332
Validation loss: 1.3886235221739738

Epoch: 6| Step: 7
Training loss: 0.06174498796463013
Validation loss: 1.4198921688141362

Epoch: 6| Step: 8
Training loss: 0.08547134697437286
Validation loss: 1.380224706024252

Epoch: 6| Step: 9
Training loss: 0.08977168798446655
Validation loss: 1.3889574869986503

Epoch: 6| Step: 10
Training loss: 0.10068614035844803
Validation loss: 1.416990077623757

Epoch: 6| Step: 11
Training loss: 0.11174166202545166
Validation loss: 1.4124419996815343

Epoch: 6| Step: 12
Training loss: 0.08261281996965408
Validation loss: 1.4199762869906682

Epoch: 6| Step: 13
Training loss: 0.1314895898103714
Validation loss: 1.4247167482171008

Epoch: 621| Step: 0
Training loss: 0.05508662760257721
Validation loss: 1.4542768360466085

Epoch: 6| Step: 1
Training loss: 0.055089354515075684
Validation loss: 1.4355657023768271

Epoch: 6| Step: 2
Training loss: 0.10017544776201248
Validation loss: 1.44206985094214

Epoch: 6| Step: 3
Training loss: 0.07377461344003677
Validation loss: 1.4146223106691915

Epoch: 6| Step: 4
Training loss: 0.04934041202068329
Validation loss: 1.4219202674845213

Epoch: 6| Step: 5
Training loss: 0.07210429757833481
Validation loss: 1.3816322562515095

Epoch: 6| Step: 6
Training loss: 0.1374475210905075
Validation loss: 1.3964158386312506

Epoch: 6| Step: 7
Training loss: 0.06699936091899872
Validation loss: 1.3771561050927767

Epoch: 6| Step: 8
Training loss: 0.04893080145120621
Validation loss: 1.3857170106262289

Epoch: 6| Step: 9
Training loss: 0.13064110279083252
Validation loss: 1.3785309919746973

Epoch: 6| Step: 10
Training loss: 0.09113838523626328
Validation loss: 1.4128710992874638

Epoch: 6| Step: 11
Training loss: 0.09017252922058105
Validation loss: 1.3812528259010726

Epoch: 6| Step: 12
Training loss: 0.10273849964141846
Validation loss: 1.3833952757620043

Epoch: 6| Step: 13
Training loss: 0.05931456387042999
Validation loss: 1.3731203822679416

Epoch: 622| Step: 0
Training loss: 0.09601190686225891
Validation loss: 1.4045710191931775

Epoch: 6| Step: 1
Training loss: 0.06382973492145538
Validation loss: 1.420288715311276

Epoch: 6| Step: 2
Training loss: 0.05267908424139023
Validation loss: 1.403237445380098

Epoch: 6| Step: 3
Training loss: 0.08702273666858673
Validation loss: 1.4129215889079596

Epoch: 6| Step: 4
Training loss: 0.05490819737315178
Validation loss: 1.4198989547708982

Epoch: 6| Step: 5
Training loss: 0.04649908095598221
Validation loss: 1.445769420875016

Epoch: 6| Step: 6
Training loss: 0.05262080207467079
Validation loss: 1.4492490445413897

Epoch: 6| Step: 7
Training loss: 0.07104524970054626
Validation loss: 1.426595244356381

Epoch: 6| Step: 8
Training loss: 0.06881173700094223
Validation loss: 1.4423155361606228

Epoch: 6| Step: 9
Training loss: 0.0371088981628418
Validation loss: 1.4379507751875027

Epoch: 6| Step: 10
Training loss: 0.08319669961929321
Validation loss: 1.418109131115739

Epoch: 6| Step: 11
Training loss: 0.06341592967510223
Validation loss: 1.4441304437575802

Epoch: 6| Step: 12
Training loss: 0.08098873496055603
Validation loss: 1.4593451100011026

Epoch: 6| Step: 13
Training loss: 0.059769708663225174
Validation loss: 1.444379328399576

Epoch: 623| Step: 0
Training loss: 0.04685219004750252
Validation loss: 1.4523055764936632

Epoch: 6| Step: 1
Training loss: 0.0497245267033577
Validation loss: 1.4661939772226478

Epoch: 6| Step: 2
Training loss: 0.037462446838617325
Validation loss: 1.4547703599417081

Epoch: 6| Step: 3
Training loss: 0.06031613424420357
Validation loss: 1.453567229291444

Epoch: 6| Step: 4
Training loss: 0.11064551770687103
Validation loss: 1.4306934238761984

Epoch: 6| Step: 5
Training loss: 0.13725785911083221
Validation loss: 1.428767087639019

Epoch: 6| Step: 6
Training loss: 0.08027203381061554
Validation loss: 1.4246010921334709

Epoch: 6| Step: 7
Training loss: 0.0761701762676239
Validation loss: 1.404949676605963

Epoch: 6| Step: 8
Training loss: 0.039241909980773926
Validation loss: 1.3843599878331667

Epoch: 6| Step: 9
Training loss: 0.06433476507663727
Validation loss: 1.4055437721231931

Epoch: 6| Step: 10
Training loss: 0.050262451171875
Validation loss: 1.4030715829582625

Epoch: 6| Step: 11
Training loss: 0.07460719347000122
Validation loss: 1.4094791207262265

Epoch: 6| Step: 12
Training loss: 0.06454938650131226
Validation loss: 1.4108758056035606

Epoch: 6| Step: 13
Training loss: 0.05028540641069412
Validation loss: 1.4333562517678866

Epoch: 624| Step: 0
Training loss: 0.08526281267404556
Validation loss: 1.4263002577648367

Epoch: 6| Step: 1
Training loss: 0.06444753706455231
Validation loss: 1.434790786235563

Epoch: 6| Step: 2
Training loss: 0.04399415850639343
Validation loss: 1.4482692915906188

Epoch: 6| Step: 3
Training loss: 0.07193340361118317
Validation loss: 1.44420636341136

Epoch: 6| Step: 4
Training loss: 0.04345722496509552
Validation loss: 1.4159989139085174

Epoch: 6| Step: 5
Training loss: 0.08547158539295197
Validation loss: 1.4359136781384867

Epoch: 6| Step: 6
Training loss: 0.041476257145404816
Validation loss: 1.4166225284658454

Epoch: 6| Step: 7
Training loss: 0.06409597396850586
Validation loss: 1.4070552356781498

Epoch: 6| Step: 8
Training loss: 0.0800943523645401
Validation loss: 1.3864820772601711

Epoch: 6| Step: 9
Training loss: 0.04800117388367653
Validation loss: 1.408887679217964

Epoch: 6| Step: 10
Training loss: 0.08450453728437424
Validation loss: 1.392237860669372

Epoch: 6| Step: 11
Training loss: 0.08946305513381958
Validation loss: 1.3818221258860763

Epoch: 6| Step: 12
Training loss: 0.09876418858766556
Validation loss: 1.377300363714977

Epoch: 6| Step: 13
Training loss: 0.05491021275520325
Validation loss: 1.3658646819412068

Epoch: 625| Step: 0
Training loss: 0.04950318858027458
Validation loss: 1.3744989069559241

Epoch: 6| Step: 1
Training loss: 0.057033970952034
Validation loss: 1.3790639536355132

Epoch: 6| Step: 2
Training loss: 0.04639503359794617
Validation loss: 1.4033611436044016

Epoch: 6| Step: 3
Training loss: 0.07870928943157196
Validation loss: 1.3584046389466973

Epoch: 6| Step: 4
Training loss: 0.13040730357170105
Validation loss: 1.4143627394912064

Epoch: 6| Step: 5
Training loss: 0.0587853267788887
Validation loss: 1.373333356713736

Epoch: 6| Step: 6
Training loss: 0.05138673633337021
Validation loss: 1.3852628751467633

Epoch: 6| Step: 7
Training loss: 0.03410288318991661
Validation loss: 1.369776648859824

Epoch: 6| Step: 8
Training loss: 0.07262295484542847
Validation loss: 1.3871963524049329

Epoch: 6| Step: 9
Training loss: 0.09152708202600479
Validation loss: 1.3424228013202708

Epoch: 6| Step: 10
Training loss: 0.03594967722892761
Validation loss: 1.4002108291913105

Epoch: 6| Step: 11
Training loss: 0.039030950516462326
Validation loss: 1.3829847035869476

Epoch: 6| Step: 12
Training loss: 0.061992526054382324
Validation loss: 1.369044206475699

Epoch: 6| Step: 13
Training loss: 0.10641516745090485
Validation loss: 1.3658739187384163

Epoch: 626| Step: 0
Training loss: 0.0769658163189888
Validation loss: 1.3788232521344257

Epoch: 6| Step: 1
Training loss: 0.06400556862354279
Validation loss: 1.3941781341388662

Epoch: 6| Step: 2
Training loss: 0.0794319212436676
Validation loss: 1.3914643359440628

Epoch: 6| Step: 3
Training loss: 0.07546989619731903
Validation loss: 1.406973942633598

Epoch: 6| Step: 4
Training loss: 0.06309907138347626
Validation loss: 1.3880278371995496

Epoch: 6| Step: 5
Training loss: 0.05070666968822479
Validation loss: 1.3877161946347965

Epoch: 6| Step: 6
Training loss: 0.03520539030432701
Validation loss: 1.3750593880171418

Epoch: 6| Step: 7
Training loss: 0.15290582180023193
Validation loss: 1.387933463178655

Epoch: 6| Step: 8
Training loss: 0.04419398307800293
Validation loss: 1.4081000935646795

Epoch: 6| Step: 9
Training loss: 0.08951156586408615
Validation loss: 1.4064057129685597

Epoch: 6| Step: 10
Training loss: 0.11802887171506882
Validation loss: 1.4169852836157686

Epoch: 6| Step: 11
Training loss: 0.11251088976860046
Validation loss: 1.4177005919077064

Epoch: 6| Step: 12
Training loss: 0.07227736711502075
Validation loss: 1.4180795825937742

Epoch: 6| Step: 13
Training loss: 0.07009927183389664
Validation loss: 1.42491179127847

Epoch: 627| Step: 0
Training loss: 0.045421913266181946
Validation loss: 1.410697970339047

Epoch: 6| Step: 1
Training loss: 0.08334356546401978
Validation loss: 1.4221588527002642

Epoch: 6| Step: 2
Training loss: 0.07294782251119614
Validation loss: 1.4117715512552569

Epoch: 6| Step: 3
Training loss: 0.13911426067352295
Validation loss: 1.4237934863695534

Epoch: 6| Step: 4
Training loss: 0.09162896871566772
Validation loss: 1.397034267584483

Epoch: 6| Step: 5
Training loss: 0.16064047813415527
Validation loss: 1.3981532845445859

Epoch: 6| Step: 6
Training loss: 0.10854188352823257
Validation loss: 1.3689269878531014

Epoch: 6| Step: 7
Training loss: 0.1042572632431984
Validation loss: 1.3653722591297601

Epoch: 6| Step: 8
Training loss: 0.07715601474046707
Validation loss: 1.3721671194158576

Epoch: 6| Step: 9
Training loss: 0.08556307852268219
Validation loss: 1.3867758499678744

Epoch: 6| Step: 10
Training loss: 0.058479275554418564
Validation loss: 1.401123296829962

Epoch: 6| Step: 11
Training loss: 0.07393361628055573
Validation loss: 1.4253775432545652

Epoch: 6| Step: 12
Training loss: 0.06266002357006073
Validation loss: 1.4601730415897984

Epoch: 6| Step: 13
Training loss: 0.2169097512960434
Validation loss: 1.4792763238312097

Epoch: 628| Step: 0
Training loss: 0.1281416118144989
Validation loss: 1.4657465052861038

Epoch: 6| Step: 1
Training loss: 0.1318184733390808
Validation loss: 1.4429003551442137

Epoch: 6| Step: 2
Training loss: 0.1079123467206955
Validation loss: 1.40191315579158

Epoch: 6| Step: 3
Training loss: 0.056244418025016785
Validation loss: 1.4134392283296073

Epoch: 6| Step: 4
Training loss: 0.06195664405822754
Validation loss: 1.3767204566668438

Epoch: 6| Step: 5
Training loss: 0.10170221328735352
Validation loss: 1.3909046790933097

Epoch: 6| Step: 6
Training loss: 0.11422671377658844
Validation loss: 1.3976170625737918

Epoch: 6| Step: 7
Training loss: 0.11224811524152756
Validation loss: 1.400665287048586

Epoch: 6| Step: 8
Training loss: 0.06955815851688385
Validation loss: 1.3756304069231915

Epoch: 6| Step: 9
Training loss: 0.12079821527004242
Validation loss: 1.3578240358701317

Epoch: 6| Step: 10
Training loss: 0.04823318496346474
Validation loss: 1.368581457804608

Epoch: 6| Step: 11
Training loss: 0.07942820340394974
Validation loss: 1.3581266364743632

Epoch: 6| Step: 12
Training loss: 0.10245154798030853
Validation loss: 1.3842897902252853

Epoch: 6| Step: 13
Training loss: 0.06824369728565216
Validation loss: 1.3943478330489127

Epoch: 629| Step: 0
Training loss: 0.046303242444992065
Validation loss: 1.4168061646082069

Epoch: 6| Step: 1
Training loss: 0.12980899214744568
Validation loss: 1.433882099325939

Epoch: 6| Step: 2
Training loss: 0.09700514376163483
Validation loss: 1.460339710276614

Epoch: 6| Step: 3
Training loss: 0.052694037556648254
Validation loss: 1.44552598204664

Epoch: 6| Step: 4
Training loss: 0.08198948204517365
Validation loss: 1.481641661736273

Epoch: 6| Step: 5
Training loss: 0.09902631491422653
Validation loss: 1.4886344825067828

Epoch: 6| Step: 6
Training loss: 0.04369419068098068
Validation loss: 1.471749400579801

Epoch: 6| Step: 7
Training loss: 0.036110542714595795
Validation loss: 1.4774337071244434

Epoch: 6| Step: 8
Training loss: 0.03940917178988457
Validation loss: 1.453727411967452

Epoch: 6| Step: 9
Training loss: 0.16485615074634552
Validation loss: 1.445448798518027

Epoch: 6| Step: 10
Training loss: 0.07757744193077087
Validation loss: 1.4628645066292054

Epoch: 6| Step: 11
Training loss: 0.0851333886384964
Validation loss: 1.4569808859978952

Epoch: 6| Step: 12
Training loss: 0.07488954067230225
Validation loss: 1.4477178935081727

Epoch: 6| Step: 13
Training loss: 0.0560528039932251
Validation loss: 1.4477344879540064

Epoch: 630| Step: 0
Training loss: 0.10386047512292862
Validation loss: 1.4452098954108454

Epoch: 6| Step: 1
Training loss: 0.04642266035079956
Validation loss: 1.4776813907008017

Epoch: 6| Step: 2
Training loss: 0.06772354245185852
Validation loss: 1.494984765206614

Epoch: 6| Step: 3
Training loss: 0.08597582578659058
Validation loss: 1.4909954237681564

Epoch: 6| Step: 4
Training loss: 0.14049819111824036
Validation loss: 1.4980783436888008

Epoch: 6| Step: 5
Training loss: 0.10497504472732544
Validation loss: 1.4876065613121114

Epoch: 6| Step: 6
Training loss: 0.10225655138492584
Validation loss: 1.5257023983104254

Epoch: 6| Step: 7
Training loss: 0.09066714346408844
Validation loss: 1.4951435212166078

Epoch: 6| Step: 8
Training loss: 0.08386221528053284
Validation loss: 1.479235214571799

Epoch: 6| Step: 9
Training loss: 0.06976664066314697
Validation loss: 1.4449506575061428

Epoch: 6| Step: 10
Training loss: 0.05671635642647743
Validation loss: 1.4402997416834677

Epoch: 6| Step: 11
Training loss: 0.0777551457285881
Validation loss: 1.4285830502868981

Epoch: 6| Step: 12
Training loss: 0.03940631449222565
Validation loss: 1.4265085586937525

Epoch: 6| Step: 13
Training loss: 0.06501788645982742
Validation loss: 1.4079583293648177

Epoch: 631| Step: 0
Training loss: 0.06951186060905457
Validation loss: 1.4294658322488107

Epoch: 6| Step: 1
Training loss: 0.08282706141471863
Validation loss: 1.408645869583212

Epoch: 6| Step: 2
Training loss: 0.09839276969432831
Validation loss: 1.4194183182972733

Epoch: 6| Step: 3
Training loss: 0.061586424708366394
Validation loss: 1.4127523642714306

Epoch: 6| Step: 4
Training loss: 0.09379371255636215
Validation loss: 1.4313784171176214

Epoch: 6| Step: 5
Training loss: 0.12220504879951477
Validation loss: 1.440658228371733

Epoch: 6| Step: 6
Training loss: 0.06528007984161377
Validation loss: 1.4538124415182299

Epoch: 6| Step: 7
Training loss: 0.08896002918481827
Validation loss: 1.467726125512072

Epoch: 6| Step: 8
Training loss: 0.05870233103632927
Validation loss: 1.4745229085286458

Epoch: 6| Step: 9
Training loss: 0.0882369875907898
Validation loss: 1.5039292971293132

Epoch: 6| Step: 10
Training loss: 0.11178907006978989
Validation loss: 1.467770758495536

Epoch: 6| Step: 11
Training loss: 0.07823915779590607
Validation loss: 1.4560627424588768

Epoch: 6| Step: 12
Training loss: 0.07529818266630173
Validation loss: 1.4419023631721415

Epoch: 6| Step: 13
Training loss: 0.06596427410840988
Validation loss: 1.429633367446161

Epoch: 632| Step: 0
Training loss: 0.06120114028453827
Validation loss: 1.4218028822252828

Epoch: 6| Step: 1
Training loss: 0.07238689064979553
Validation loss: 1.3922152685862716

Epoch: 6| Step: 2
Training loss: 0.08532815426588058
Validation loss: 1.3945596166836318

Epoch: 6| Step: 3
Training loss: 0.09142820537090302
Validation loss: 1.3884409114878664

Epoch: 6| Step: 4
Training loss: 0.08565646409988403
Validation loss: 1.3969495988661242

Epoch: 6| Step: 5
Training loss: 0.06653662770986557
Validation loss: 1.3899668762760777

Epoch: 6| Step: 6
Training loss: 0.058367177844047546
Validation loss: 1.4019999555362168

Epoch: 6| Step: 7
Training loss: 0.06350430101156235
Validation loss: 1.3975524761343514

Epoch: 6| Step: 8
Training loss: 0.04618013650178909
Validation loss: 1.390305228771702

Epoch: 6| Step: 9
Training loss: 0.07092396914958954
Validation loss: 1.39771734129998

Epoch: 6| Step: 10
Training loss: 0.08784233033657074
Validation loss: 1.42279141436341

Epoch: 6| Step: 11
Training loss: 0.1234898790717125
Validation loss: 1.4253988112172773

Epoch: 6| Step: 12
Training loss: 0.09690072387456894
Validation loss: 1.4218216019292031

Epoch: 6| Step: 13
Training loss: 0.061437204480171204
Validation loss: 1.4278081591411302

Epoch: 633| Step: 0
Training loss: 0.058875828981399536
Validation loss: 1.430791562603366

Epoch: 6| Step: 1
Training loss: 0.08485840260982513
Validation loss: 1.447385343172217

Epoch: 6| Step: 2
Training loss: 0.06862881779670715
Validation loss: 1.4454643431530203

Epoch: 6| Step: 3
Training loss: 0.0620022788643837
Validation loss: 1.4200326755482664

Epoch: 6| Step: 4
Training loss: 0.06645487248897552
Validation loss: 1.4081683069147088

Epoch: 6| Step: 5
Training loss: 0.12914827466011047
Validation loss: 1.4201231976991058

Epoch: 6| Step: 6
Training loss: 0.03747134655714035
Validation loss: 1.4045190926521056

Epoch: 6| Step: 7
Training loss: 0.054698195308446884
Validation loss: 1.4025501961349158

Epoch: 6| Step: 8
Training loss: 0.10334384441375732
Validation loss: 1.419733783250214

Epoch: 6| Step: 9
Training loss: 0.06355956196784973
Validation loss: 1.4243646924213698

Epoch: 6| Step: 10
Training loss: 0.07856810837984085
Validation loss: 1.4186542905786985

Epoch: 6| Step: 11
Training loss: 0.040013767778873444
Validation loss: 1.416892570834006

Epoch: 6| Step: 12
Training loss: 0.04584968835115433
Validation loss: 1.3931782630182081

Epoch: 6| Step: 13
Training loss: 0.09480256587266922
Validation loss: 1.4109828561864874

Epoch: 634| Step: 0
Training loss: 0.044870756566524506
Validation loss: 1.4138816184895013

Epoch: 6| Step: 1
Training loss: 0.08914052695035934
Validation loss: 1.407498716026224

Epoch: 6| Step: 2
Training loss: 0.0598086416721344
Validation loss: 1.4196741465599305

Epoch: 6| Step: 3
Training loss: 0.05004233866930008
Validation loss: 1.4030590198373283

Epoch: 6| Step: 4
Training loss: 0.06049192324280739
Validation loss: 1.417503636370423

Epoch: 6| Step: 5
Training loss: 0.06457123905420303
Validation loss: 1.4136447182265661

Epoch: 6| Step: 6
Training loss: 0.0681624785065651
Validation loss: 1.401915559845586

Epoch: 6| Step: 7
Training loss: 0.11584234982728958
Validation loss: 1.4081432204092703

Epoch: 6| Step: 8
Training loss: 0.132173091173172
Validation loss: 1.4357802931980421

Epoch: 6| Step: 9
Training loss: 0.08266378939151764
Validation loss: 1.4213065011526949

Epoch: 6| Step: 10
Training loss: 0.07233798503875732
Validation loss: 1.4110617547906854

Epoch: 6| Step: 11
Training loss: 0.09006516635417938
Validation loss: 1.3925658746432232

Epoch: 6| Step: 12
Training loss: 0.044434238225221634
Validation loss: 1.3984734114780222

Epoch: 6| Step: 13
Training loss: 0.06474757194519043
Validation loss: 1.3682055870691936

Epoch: 635| Step: 0
Training loss: 0.07177877426147461
Validation loss: 1.3831086850935412

Epoch: 6| Step: 1
Training loss: 0.0762622281908989
Validation loss: 1.373746830929992

Epoch: 6| Step: 2
Training loss: 0.0487409383058548
Validation loss: 1.380611253041093

Epoch: 6| Step: 3
Training loss: 0.08894553780555725
Validation loss: 1.3521276795735924

Epoch: 6| Step: 4
Training loss: 0.08883719146251678
Validation loss: 1.3734518879203386

Epoch: 6| Step: 5
Training loss: 0.11857414990663528
Validation loss: 1.3964268584405222

Epoch: 6| Step: 6
Training loss: 0.0444214791059494
Validation loss: 1.4157760976463236

Epoch: 6| Step: 7
Training loss: 0.06938676536083221
Validation loss: 1.3903559542471362

Epoch: 6| Step: 8
Training loss: 0.050711747258901596
Validation loss: 1.434080712256893

Epoch: 6| Step: 9
Training loss: 0.11379910260438919
Validation loss: 1.453449394113274

Epoch: 6| Step: 10
Training loss: 0.09658007323741913
Validation loss: 1.4464026471619964

Epoch: 6| Step: 11
Training loss: 0.08034491539001465
Validation loss: 1.4478955550860333

Epoch: 6| Step: 12
Training loss: 0.05094505846500397
Validation loss: 1.4249711395591818

Epoch: 6| Step: 13
Training loss: 0.218326598405838
Validation loss: 1.398718266076939

Epoch: 636| Step: 0
Training loss: 0.04982057586312294
Validation loss: 1.3741469985695296

Epoch: 6| Step: 1
Training loss: 0.12390800565481186
Validation loss: 1.3635768191788786

Epoch: 6| Step: 2
Training loss: 0.11718495190143585
Validation loss: 1.3815888153609408

Epoch: 6| Step: 3
Training loss: 0.08964632451534271
Validation loss: 1.3857419125495418

Epoch: 6| Step: 4
Training loss: 0.04392486438155174
Validation loss: 1.3792478628056024

Epoch: 6| Step: 5
Training loss: 0.06283874809741974
Validation loss: 1.3959498097819667

Epoch: 6| Step: 6
Training loss: 0.055047936737537384
Validation loss: 1.4157779780767297

Epoch: 6| Step: 7
Training loss: 0.04350605607032776
Validation loss: 1.4031059940656025

Epoch: 6| Step: 8
Training loss: 0.047822751104831696
Validation loss: 1.4281927180546585

Epoch: 6| Step: 9
Training loss: 0.03277040272951126
Validation loss: 1.4287734486723458

Epoch: 6| Step: 10
Training loss: 0.0626334473490715
Validation loss: 1.437334386251306

Epoch: 6| Step: 11
Training loss: 0.062255799770355225
Validation loss: 1.413782795270284

Epoch: 6| Step: 12
Training loss: 0.08382367342710495
Validation loss: 1.3971519060032342

Epoch: 6| Step: 13
Training loss: 0.0418291874229908
Validation loss: 1.4001774672539002

Epoch: 637| Step: 0
Training loss: 0.0709085464477539
Validation loss: 1.3991349294621458

Epoch: 6| Step: 1
Training loss: 0.124565988779068
Validation loss: 1.4150518550667712

Epoch: 6| Step: 2
Training loss: 0.07409773766994476
Validation loss: 1.402355747838174

Epoch: 6| Step: 3
Training loss: 0.06496530771255493
Validation loss: 1.4149778889071556

Epoch: 6| Step: 4
Training loss: 0.059236228466033936
Validation loss: 1.4146232399889218

Epoch: 6| Step: 5
Training loss: 0.06551213562488556
Validation loss: 1.4142167516933974

Epoch: 6| Step: 6
Training loss: 0.0854928195476532
Validation loss: 1.4119949276729296

Epoch: 6| Step: 7
Training loss: 0.08042462915182114
Validation loss: 1.4067318683029504

Epoch: 6| Step: 8
Training loss: 0.06622572243213654
Validation loss: 1.3867031156375844

Epoch: 6| Step: 9
Training loss: 0.06436575949192047
Validation loss: 1.3912003911951536

Epoch: 6| Step: 10
Training loss: 0.039322637021541595
Validation loss: 1.4026597392174505

Epoch: 6| Step: 11
Training loss: 0.10604561865329742
Validation loss: 1.3867421124571113

Epoch: 6| Step: 12
Training loss: 0.053431227803230286
Validation loss: 1.4028163443329513

Epoch: 6| Step: 13
Training loss: 0.0520431213080883
Validation loss: 1.4111946782758158

Epoch: 638| Step: 0
Training loss: 0.10364453494548798
Validation loss: 1.4317652871531825

Epoch: 6| Step: 1
Training loss: 0.06001337617635727
Validation loss: 1.404472493356274

Epoch: 6| Step: 2
Training loss: 0.09667906910181046
Validation loss: 1.4633985719373148

Epoch: 6| Step: 3
Training loss: 0.11586141586303711
Validation loss: 1.4470304532717633

Epoch: 6| Step: 4
Training loss: 0.09161091595888138
Validation loss: 1.462006667608856

Epoch: 6| Step: 5
Training loss: 0.05979836732149124
Validation loss: 1.4643551444494596

Epoch: 6| Step: 6
Training loss: 0.09089825302362442
Validation loss: 1.4727804609524306

Epoch: 6| Step: 7
Training loss: 0.06770118325948715
Validation loss: 1.459974818332221

Epoch: 6| Step: 8
Training loss: 0.04857190325856209
Validation loss: 1.4799212871059295

Epoch: 6| Step: 9
Training loss: 0.05257514491677284
Validation loss: 1.4818937483654226

Epoch: 6| Step: 10
Training loss: 0.07662854343652725
Validation loss: 1.4865037241289694

Epoch: 6| Step: 11
Training loss: 0.07681876420974731
Validation loss: 1.4530919456994662

Epoch: 6| Step: 12
Training loss: 0.08083926886320114
Validation loss: 1.4707783140161985

Epoch: 6| Step: 13
Training loss: 0.04735095798969269
Validation loss: 1.4596717652454172

Epoch: 639| Step: 0
Training loss: 0.05224251002073288
Validation loss: 1.4564211291651572

Epoch: 6| Step: 1
Training loss: 0.08023157715797424
Validation loss: 1.4311554765188566

Epoch: 6| Step: 2
Training loss: 0.045154690742492676
Validation loss: 1.4398501701252435

Epoch: 6| Step: 3
Training loss: 0.13145652413368225
Validation loss: 1.4343305787732523

Epoch: 6| Step: 4
Training loss: 0.06598269939422607
Validation loss: 1.3927971419467722

Epoch: 6| Step: 5
Training loss: 0.08568282425403595
Validation loss: 1.3656556542201708

Epoch: 6| Step: 6
Training loss: 0.05058213323354721
Validation loss: 1.3683544102535452

Epoch: 6| Step: 7
Training loss: 0.14767339825630188
Validation loss: 1.3513437688991587

Epoch: 6| Step: 8
Training loss: 0.18783913552761078
Validation loss: 1.3390995232007836

Epoch: 6| Step: 9
Training loss: 0.09366875886917114
Validation loss: 1.3573259269037554

Epoch: 6| Step: 10
Training loss: 0.09181283414363861
Validation loss: 1.3840533994859265

Epoch: 6| Step: 11
Training loss: 0.08089659363031387
Validation loss: 1.3872628192747793

Epoch: 6| Step: 12
Training loss: 0.07821454107761383
Validation loss: 1.4463277593735726

Epoch: 6| Step: 13
Training loss: 0.0772673562169075
Validation loss: 1.4596890967379335

Epoch: 640| Step: 0
Training loss: 0.1115562841296196
Validation loss: 1.46643695780026

Epoch: 6| Step: 1
Training loss: 0.09505996108055115
Validation loss: 1.465635480419282

Epoch: 6| Step: 2
Training loss: 0.09346131235361099
Validation loss: 1.4799526910628042

Epoch: 6| Step: 3
Training loss: 0.07084134966135025
Validation loss: 1.4582002137296943

Epoch: 6| Step: 4
Training loss: 0.10725261270999908
Validation loss: 1.4568981611600487

Epoch: 6| Step: 5
Training loss: 0.06336531043052673
Validation loss: 1.4351295117408998

Epoch: 6| Step: 6
Training loss: 0.046861059963703156
Validation loss: 1.4291110128484747

Epoch: 6| Step: 7
Training loss: 0.08755265176296234
Validation loss: 1.4071806425689368

Epoch: 6| Step: 8
Training loss: 0.14731544256210327
Validation loss: 1.3997708828218522

Epoch: 6| Step: 9
Training loss: 0.07410207390785217
Validation loss: 1.4111299732679963

Epoch: 6| Step: 10
Training loss: 0.07637061178684235
Validation loss: 1.398567957903749

Epoch: 6| Step: 11
Training loss: 0.09286230802536011
Validation loss: 1.3832047934173255

Epoch: 6| Step: 12
Training loss: 0.047077033668756485
Validation loss: 1.4025215641144784

Epoch: 6| Step: 13
Training loss: 0.04120596870779991
Validation loss: 1.3977630702398156

Epoch: 641| Step: 0
Training loss: 0.08407026529312134
Validation loss: 1.4208188672219553

Epoch: 6| Step: 1
Training loss: 0.062479157000780106
Validation loss: 1.420034896942877

Epoch: 6| Step: 2
Training loss: 0.05679614469408989
Validation loss: 1.4154690375892065

Epoch: 6| Step: 3
Training loss: 0.1005605012178421
Validation loss: 1.4271810939235072

Epoch: 6| Step: 4
Training loss: 0.055269964039325714
Validation loss: 1.4124813009333868

Epoch: 6| Step: 5
Training loss: 0.0768091157078743
Validation loss: 1.4608313934777373

Epoch: 6| Step: 6
Training loss: 0.0658612996339798
Validation loss: 1.4353259481409544

Epoch: 6| Step: 7
Training loss: 0.04609152302145958
Validation loss: 1.438535483934546

Epoch: 6| Step: 8
Training loss: 0.06454545259475708
Validation loss: 1.4291423341279388

Epoch: 6| Step: 9
Training loss: 0.06427999585866928
Validation loss: 1.3854024230792958

Epoch: 6| Step: 10
Training loss: 0.10683564841747284
Validation loss: 1.3932514870038597

Epoch: 6| Step: 11
Training loss: 0.07421056181192398
Validation loss: 1.382886912233086

Epoch: 6| Step: 12
Training loss: 0.06809151917695999
Validation loss: 1.3710461611388831

Epoch: 6| Step: 13
Training loss: 0.07049065083265305
Validation loss: 1.3673202183938795

Epoch: 642| Step: 0
Training loss: 0.05980853736400604
Validation loss: 1.3633744139825144

Epoch: 6| Step: 1
Training loss: 0.049198396503925323
Validation loss: 1.3598226808732556

Epoch: 6| Step: 2
Training loss: 0.06203027069568634
Validation loss: 1.348158637682597

Epoch: 6| Step: 3
Training loss: 0.055701062083244324
Validation loss: 1.3537747026771627

Epoch: 6| Step: 4
Training loss: 0.0773797333240509
Validation loss: 1.4021402751245806

Epoch: 6| Step: 5
Training loss: 0.06289790570735931
Validation loss: 1.410981030874355

Epoch: 6| Step: 6
Training loss: 0.0468185693025589
Validation loss: 1.4188122941601662

Epoch: 6| Step: 7
Training loss: 0.06918247044086456
Validation loss: 1.4161626876041453

Epoch: 6| Step: 8
Training loss: 0.06715835630893707
Validation loss: 1.4524536517358595

Epoch: 6| Step: 9
Training loss: 0.06985586881637573
Validation loss: 1.446919991124061

Epoch: 6| Step: 10
Training loss: 0.07066994905471802
Validation loss: 1.4522226766873432

Epoch: 6| Step: 11
Training loss: 0.05129268765449524
Validation loss: 1.4675618935656805

Epoch: 6| Step: 12
Training loss: 0.11151675879955292
Validation loss: 1.4406212991283787

Epoch: 6| Step: 13
Training loss: 0.12428024411201477
Validation loss: 1.4394479990005493

Epoch: 643| Step: 0
Training loss: 0.092385433614254
Validation loss: 1.4421662015299643

Epoch: 6| Step: 1
Training loss: 0.07891439646482468
Validation loss: 1.4216509711357854

Epoch: 6| Step: 2
Training loss: 0.05987309664487839
Validation loss: 1.4167321946031304

Epoch: 6| Step: 3
Training loss: 0.11718670278787613
Validation loss: 1.4275321140084216

Epoch: 6| Step: 4
Training loss: 0.10684680938720703
Validation loss: 1.429366639865342

Epoch: 6| Step: 5
Training loss: 0.0455973818898201
Validation loss: 1.4246737123817526

Epoch: 6| Step: 6
Training loss: 0.07183021306991577
Validation loss: 1.4495844866639824

Epoch: 6| Step: 7
Training loss: 0.05660540610551834
Validation loss: 1.4362168433845683

Epoch: 6| Step: 8
Training loss: 0.0644683837890625
Validation loss: 1.447957924617234

Epoch: 6| Step: 9
Training loss: 0.06650581955909729
Validation loss: 1.4420173706546906

Epoch: 6| Step: 10
Training loss: 0.07773199677467346
Validation loss: 1.4473409627073555

Epoch: 6| Step: 11
Training loss: 0.051504798233509064
Validation loss: 1.462767658695098

Epoch: 6| Step: 12
Training loss: 0.03861308842897415
Validation loss: 1.4567889558371676

Epoch: 6| Step: 13
Training loss: 0.07891110330820084
Validation loss: 1.4236906946346324

Epoch: 644| Step: 0
Training loss: 0.04128352552652359
Validation loss: 1.4309841663606706

Epoch: 6| Step: 1
Training loss: 0.08271540701389313
Validation loss: 1.4264542402759675

Epoch: 6| Step: 2
Training loss: 0.061792727559804916
Validation loss: 1.4381466008001758

Epoch: 6| Step: 3
Training loss: 0.10270152986049652
Validation loss: 1.364850450587529

Epoch: 6| Step: 4
Training loss: 0.059355854988098145
Validation loss: 1.3750294921218709

Epoch: 6| Step: 5
Training loss: 0.055827513337135315
Validation loss: 1.3612273893048685

Epoch: 6| Step: 6
Training loss: 0.07219427824020386
Validation loss: 1.3486631711324055

Epoch: 6| Step: 7
Training loss: 0.1026800200343132
Validation loss: 1.3549681818613442

Epoch: 6| Step: 8
Training loss: 0.09164705127477646
Validation loss: 1.352967986496546

Epoch: 6| Step: 9
Training loss: 0.0649242177605629
Validation loss: 1.3732502768116612

Epoch: 6| Step: 10
Training loss: 0.04003433883190155
Validation loss: 1.3943756241952219

Epoch: 6| Step: 11
Training loss: 0.056638311594724655
Validation loss: 1.3840852924572524

Epoch: 6| Step: 12
Training loss: 0.0364670604467392
Validation loss: 1.394013609296532

Epoch: 6| Step: 13
Training loss: 0.06642601639032364
Validation loss: 1.4225142053378526

Epoch: 645| Step: 0
Training loss: 0.04040265083312988
Validation loss: 1.4241525607724344

Epoch: 6| Step: 1
Training loss: 0.1257946491241455
Validation loss: 1.44264502550966

Epoch: 6| Step: 2
Training loss: 0.07621189206838608
Validation loss: 1.4317810971249816

Epoch: 6| Step: 3
Training loss: 0.04361329227685928
Validation loss: 1.42315931986737

Epoch: 6| Step: 4
Training loss: 0.08216524124145508
Validation loss: 1.4397449262680546

Epoch: 6| Step: 5
Training loss: 0.07434628903865814
Validation loss: 1.434487133897761

Epoch: 6| Step: 6
Training loss: 0.07756523787975311
Validation loss: 1.4355240547528831

Epoch: 6| Step: 7
Training loss: 0.06758580356836319
Validation loss: 1.4078414811882922

Epoch: 6| Step: 8
Training loss: 0.11179196089506149
Validation loss: 1.4204275684971963

Epoch: 6| Step: 9
Training loss: 0.07460007816553116
Validation loss: 1.404417174477731

Epoch: 6| Step: 10
Training loss: 0.039883509278297424
Validation loss: 1.445277580650904

Epoch: 6| Step: 11
Training loss: 0.06238909810781479
Validation loss: 1.401108984024294

Epoch: 6| Step: 12
Training loss: 0.04673454910516739
Validation loss: 1.3862439637543054

Epoch: 6| Step: 13
Training loss: 0.050843290984630585
Validation loss: 1.3962082978217834

Epoch: 646| Step: 0
Training loss: 0.06443691998720169
Validation loss: 1.396980227962617

Epoch: 6| Step: 1
Training loss: 0.058576591312885284
Validation loss: 1.4024993078683012

Epoch: 6| Step: 2
Training loss: 0.04992595314979553
Validation loss: 1.407346237090326

Epoch: 6| Step: 3
Training loss: 0.04822613298892975
Validation loss: 1.4152273125545953

Epoch: 6| Step: 4
Training loss: 0.04813947528600693
Validation loss: 1.4185328355399511

Epoch: 6| Step: 5
Training loss: 0.04689064621925354
Validation loss: 1.434451248056145

Epoch: 6| Step: 6
Training loss: 0.047334782779216766
Validation loss: 1.4405752712039537

Epoch: 6| Step: 7
Training loss: 0.06258944422006607
Validation loss: 1.4230212319281794

Epoch: 6| Step: 8
Training loss: 0.12003043293952942
Validation loss: 1.4391958431531024

Epoch: 6| Step: 9
Training loss: 0.06888772547245026
Validation loss: 1.399573617084052

Epoch: 6| Step: 10
Training loss: 0.0955839678645134
Validation loss: 1.406850976328696

Epoch: 6| Step: 11
Training loss: 0.07299531996250153
Validation loss: 1.396978441105094

Epoch: 6| Step: 12
Training loss: 0.05882059782743454
Validation loss: 1.424345911190074

Epoch: 6| Step: 13
Training loss: 0.04750050604343414
Validation loss: 1.3954991704674178

Epoch: 647| Step: 0
Training loss: 0.05724753439426422
Validation loss: 1.4445178540804053

Epoch: 6| Step: 1
Training loss: 0.09315852075815201
Validation loss: 1.4175347320495113

Epoch: 6| Step: 2
Training loss: 0.04763530194759369
Validation loss: 1.4294520757531608

Epoch: 6| Step: 3
Training loss: 0.04656760394573212
Validation loss: 1.3951144513263498

Epoch: 6| Step: 4
Training loss: 0.054274171590805054
Validation loss: 1.3880518803032496

Epoch: 6| Step: 5
Training loss: 0.07517106086015701
Validation loss: 1.37679696659888

Epoch: 6| Step: 6
Training loss: 0.0867384672164917
Validation loss: 1.383673874280786

Epoch: 6| Step: 7
Training loss: 0.06656037271022797
Validation loss: 1.3849220109242264

Epoch: 6| Step: 8
Training loss: 0.04828408360481262
Validation loss: 1.4103647265382993

Epoch: 6| Step: 9
Training loss: 0.07640980184078217
Validation loss: 1.404629046558052

Epoch: 6| Step: 10
Training loss: 0.0618603490293026
Validation loss: 1.4182579728864855

Epoch: 6| Step: 11
Training loss: 0.06128604710102081
Validation loss: 1.419292611460532

Epoch: 6| Step: 12
Training loss: 0.0895557850599289
Validation loss: 1.4180601232795305

Epoch: 6| Step: 13
Training loss: 0.030489154160022736
Validation loss: 1.4120461069127566

Epoch: 648| Step: 0
Training loss: 0.036184750497341156
Validation loss: 1.412660780773368

Epoch: 6| Step: 1
Training loss: 0.07741478085517883
Validation loss: 1.4331787901539956

Epoch: 6| Step: 2
Training loss: 0.06237640231847763
Validation loss: 1.4389833045262161

Epoch: 6| Step: 3
Training loss: 0.10722017288208008
Validation loss: 1.4619179771792503

Epoch: 6| Step: 4
Training loss: 0.07000938057899475
Validation loss: 1.452791230652922

Epoch: 6| Step: 5
Training loss: 0.05335448309779167
Validation loss: 1.4225076295996224

Epoch: 6| Step: 6
Training loss: 0.061728864908218384
Validation loss: 1.428667486354869

Epoch: 6| Step: 7
Training loss: 0.05150973051786423
Validation loss: 1.423364313699866

Epoch: 6| Step: 8
Training loss: 0.09991560131311417
Validation loss: 1.438430441323147

Epoch: 6| Step: 9
Training loss: 0.07085096091032028
Validation loss: 1.424851913605967

Epoch: 6| Step: 10
Training loss: 0.04116766154766083
Validation loss: 1.4167648220574984

Epoch: 6| Step: 11
Training loss: 0.04861866682767868
Validation loss: 1.424705232343366

Epoch: 6| Step: 12
Training loss: 0.056560516357421875
Validation loss: 1.4168326316341278

Epoch: 6| Step: 13
Training loss: 0.024672428146004677
Validation loss: 1.4083832194728236

Epoch: 649| Step: 0
Training loss: 0.04395896568894386
Validation loss: 1.433217446009318

Epoch: 6| Step: 1
Training loss: 0.0797414481639862
Validation loss: 1.4209847411801737

Epoch: 6| Step: 2
Training loss: 0.07174232602119446
Validation loss: 1.4504503152703727

Epoch: 6| Step: 3
Training loss: 0.046839773654937744
Validation loss: 1.428540974534968

Epoch: 6| Step: 4
Training loss: 0.10132281482219696
Validation loss: 1.4288590287649503

Epoch: 6| Step: 5
Training loss: 0.05873822420835495
Validation loss: 1.3851962320266231

Epoch: 6| Step: 6
Training loss: 0.062487583607435226
Validation loss: 1.3852309783299763

Epoch: 6| Step: 7
Training loss: 0.05227475240826607
Validation loss: 1.350897309600666

Epoch: 6| Step: 8
Training loss: 0.07253938913345337
Validation loss: 1.3593911137632144

Epoch: 6| Step: 9
Training loss: 0.08939971774816513
Validation loss: 1.3630564879345637

Epoch: 6| Step: 10
Training loss: 0.06580886244773865
Validation loss: 1.3587533222731722

Epoch: 6| Step: 11
Training loss: 0.0485420860350132
Validation loss: 1.3469508617155013

Epoch: 6| Step: 12
Training loss: 0.03760839253664017
Validation loss: 1.360598309706616

Epoch: 6| Step: 13
Training loss: 0.05794082581996918
Validation loss: 1.3658400498410708

Epoch: 650| Step: 0
Training loss: 0.0532853826880455
Validation loss: 1.369718006862107

Epoch: 6| Step: 1
Training loss: 0.05233907327055931
Validation loss: 1.4068139330033334

Epoch: 6| Step: 2
Training loss: 0.08783124387264252
Validation loss: 1.39847941424257

Epoch: 6| Step: 3
Training loss: 0.08086301386356354
Validation loss: 1.3922425636681177

Epoch: 6| Step: 4
Training loss: 0.046867936849594116
Validation loss: 1.405522334319289

Epoch: 6| Step: 5
Training loss: 0.0517846941947937
Validation loss: 1.3885011749882852

Epoch: 6| Step: 6
Training loss: 0.08087335526943207
Validation loss: 1.3976568329718806

Epoch: 6| Step: 7
Training loss: 0.034712765365839005
Validation loss: 1.387434087773805

Epoch: 6| Step: 8
Training loss: 0.07365801930427551
Validation loss: 1.3811532169260003

Epoch: 6| Step: 9
Training loss: 0.08879905194044113
Validation loss: 1.3831588529771375

Epoch: 6| Step: 10
Training loss: 0.069949209690094
Validation loss: 1.3755905615386141

Epoch: 6| Step: 11
Training loss: 0.04904147982597351
Validation loss: 1.3841297280403875

Epoch: 6| Step: 12
Training loss: 0.0808292031288147
Validation loss: 1.4092559442725232

Epoch: 6| Step: 13
Training loss: 0.07680018991231918
Validation loss: 1.363758925468691

Epoch: 651| Step: 0
Training loss: 0.04842725396156311
Validation loss: 1.3604514906483312

Epoch: 6| Step: 1
Training loss: 0.08282864093780518
Validation loss: 1.3244024989425496

Epoch: 6| Step: 2
Training loss: 0.05184559524059296
Validation loss: 1.3665236465392574

Epoch: 6| Step: 3
Training loss: 0.06535869091749191
Validation loss: 1.3583387572278258

Epoch: 6| Step: 4
Training loss: 0.04422329366207123
Validation loss: 1.3697732058904504

Epoch: 6| Step: 5
Training loss: 0.05865167826414108
Validation loss: 1.3769686068257978

Epoch: 6| Step: 6
Training loss: 0.07380835711956024
Validation loss: 1.3844770872464744

Epoch: 6| Step: 7
Training loss: 0.09628012776374817
Validation loss: 1.3651306808635753

Epoch: 6| Step: 8
Training loss: 0.057222094386816025
Validation loss: 1.3826271199410962

Epoch: 6| Step: 9
Training loss: 0.04682309553027153
Validation loss: 1.3514774319946126

Epoch: 6| Step: 10
Training loss: 0.06603924185037613
Validation loss: 1.376042148118378

Epoch: 6| Step: 11
Training loss: 0.04895835369825363
Validation loss: 1.37501762887483

Epoch: 6| Step: 12
Training loss: 0.06516072154045105
Validation loss: 1.3731656702615882

Epoch: 6| Step: 13
Training loss: 0.06806722283363342
Validation loss: 1.3930946024515296

Epoch: 652| Step: 0
Training loss: 0.052013248205184937
Validation loss: 1.3951829312950053

Epoch: 6| Step: 1
Training loss: 0.0461827889084816
Validation loss: 1.4132097639063352

Epoch: 6| Step: 2
Training loss: 0.0567585714161396
Validation loss: 1.4182399575428297

Epoch: 6| Step: 3
Training loss: 0.0419263131916523
Validation loss: 1.3915825313137424

Epoch: 6| Step: 4
Training loss: 0.04631287604570389
Validation loss: 1.4169696646351968

Epoch: 6| Step: 5
Training loss: 0.04620540887117386
Validation loss: 1.4163394884396625

Epoch: 6| Step: 6
Training loss: 0.05093136429786682
Validation loss: 1.4160303390154274

Epoch: 6| Step: 7
Training loss: 0.08219467103481293
Validation loss: 1.4288658262580953

Epoch: 6| Step: 8
Training loss: 0.06174643337726593
Validation loss: 1.4376062475224978

Epoch: 6| Step: 9
Training loss: 0.045381106436252594
Validation loss: 1.4392115198155886

Epoch: 6| Step: 10
Training loss: 0.0778343677520752
Validation loss: 1.4410049889677314

Epoch: 6| Step: 11
Training loss: 0.0765620693564415
Validation loss: 1.415277809866013

Epoch: 6| Step: 12
Training loss: 0.08372843265533447
Validation loss: 1.3986140348578011

Epoch: 6| Step: 13
Training loss: 0.11685165017843246
Validation loss: 1.3933341721052765

Epoch: 653| Step: 0
Training loss: 0.07776427268981934
Validation loss: 1.3862137704767206

Epoch: 6| Step: 1
Training loss: 0.04860297590494156
Validation loss: 1.3619102213972358

Epoch: 6| Step: 2
Training loss: 0.10163130611181259
Validation loss: 1.3693770503485074

Epoch: 6| Step: 3
Training loss: 0.05029556155204773
Validation loss: 1.3731825915716027

Epoch: 6| Step: 4
Training loss: 0.08610968291759491
Validation loss: 1.3735322875361289

Epoch: 6| Step: 5
Training loss: 0.05260051041841507
Validation loss: 1.3799860708175167

Epoch: 6| Step: 6
Training loss: 0.05626639351248741
Validation loss: 1.3695519175580753

Epoch: 6| Step: 7
Training loss: 0.07157593965530396
Validation loss: 1.3439055258227932

Epoch: 6| Step: 8
Training loss: 0.057303257286548615
Validation loss: 1.3830973935383621

Epoch: 6| Step: 9
Training loss: 0.035563431680202484
Validation loss: 1.3774663620097662

Epoch: 6| Step: 10
Training loss: 0.03734812140464783
Validation loss: 1.3734800841218682

Epoch: 6| Step: 11
Training loss: 0.06654269993305206
Validation loss: 1.4148750241084764

Epoch: 6| Step: 12
Training loss: 0.05901116132736206
Validation loss: 1.3818009937963178

Epoch: 6| Step: 13
Training loss: 0.03824761137366295
Validation loss: 1.3914046274718417

Epoch: 654| Step: 0
Training loss: 0.05035451427102089
Validation loss: 1.4052823064147786

Epoch: 6| Step: 1
Training loss: 0.040303826332092285
Validation loss: 1.4015191524259505

Epoch: 6| Step: 2
Training loss: 0.039879169315099716
Validation loss: 1.4155668609885759

Epoch: 6| Step: 3
Training loss: 0.04125714674592018
Validation loss: 1.4184410277233328

Epoch: 6| Step: 4
Training loss: 0.047088924795389175
Validation loss: 1.4125683025647235

Epoch: 6| Step: 5
Training loss: 0.059655994176864624
Validation loss: 1.4219741859743673

Epoch: 6| Step: 6
Training loss: 0.05838370695710182
Validation loss: 1.4435937917360695

Epoch: 6| Step: 7
Training loss: 0.05878375098109245
Validation loss: 1.4253344740918887

Epoch: 6| Step: 8
Training loss: 0.08313822746276855
Validation loss: 1.434695372017481

Epoch: 6| Step: 9
Training loss: 0.09809024631977081
Validation loss: 1.4301721780530867

Epoch: 6| Step: 10
Training loss: 0.06402547657489777
Validation loss: 1.4030101638968273

Epoch: 6| Step: 11
Training loss: 0.043554700911045074
Validation loss: 1.412764012172658

Epoch: 6| Step: 12
Training loss: 0.049875207245349884
Validation loss: 1.398000512071835

Epoch: 6| Step: 13
Training loss: 0.12446701526641846
Validation loss: 1.3898431319062428

Epoch: 655| Step: 0
Training loss: 0.05593869835138321
Validation loss: 1.3999437273189586

Epoch: 6| Step: 1
Training loss: 0.054581306874752045
Validation loss: 1.3882144330650248

Epoch: 6| Step: 2
Training loss: 0.05729089677333832
Validation loss: 1.393629227915118

Epoch: 6| Step: 3
Training loss: 0.0615009143948555
Validation loss: 1.4138036645868772

Epoch: 6| Step: 4
Training loss: 0.06776528060436249
Validation loss: 1.400339739937936

Epoch: 6| Step: 5
Training loss: 0.06880196183919907
Validation loss: 1.4194048784112419

Epoch: 6| Step: 6
Training loss: 0.037720322608947754
Validation loss: 1.4035882629374021

Epoch: 6| Step: 7
Training loss: 0.06913924217224121
Validation loss: 1.4198003981703071

Epoch: 6| Step: 8
Training loss: 0.06544077396392822
Validation loss: 1.4014973845533145

Epoch: 6| Step: 9
Training loss: 0.09139534831047058
Validation loss: 1.429857446301368

Epoch: 6| Step: 10
Training loss: 0.029133889824151993
Validation loss: 1.4304278101972354

Epoch: 6| Step: 11
Training loss: 0.08026239275932312
Validation loss: 1.414121682925891

Epoch: 6| Step: 12
Training loss: 0.04877698794007301
Validation loss: 1.41574280236357

Epoch: 6| Step: 13
Training loss: 0.06250565499067307
Validation loss: 1.4138806904515913

Epoch: 656| Step: 0
Training loss: 0.04989426210522652
Validation loss: 1.3808023839868524

Epoch: 6| Step: 1
Training loss: 0.054127972573041916
Validation loss: 1.3923236106031684

Epoch: 6| Step: 2
Training loss: 0.07414036989212036
Validation loss: 1.4107419893305788

Epoch: 6| Step: 3
Training loss: 0.0815940573811531
Validation loss: 1.397019968237928

Epoch: 6| Step: 4
Training loss: 0.032763686031103134
Validation loss: 1.4203792259257326

Epoch: 6| Step: 5
Training loss: 0.05986645445227623
Validation loss: 1.4234286046797229

Epoch: 6| Step: 6
Training loss: 0.04718228429555893
Validation loss: 1.4104967668492308

Epoch: 6| Step: 7
Training loss: 0.022084325551986694
Validation loss: 1.4192713229886946

Epoch: 6| Step: 8
Training loss: 0.039593882858753204
Validation loss: 1.4157559871673584

Epoch: 6| Step: 9
Training loss: 0.057502809911966324
Validation loss: 1.409903843556681

Epoch: 6| Step: 10
Training loss: 0.05752909183502197
Validation loss: 1.4226274515992852

Epoch: 6| Step: 11
Training loss: 0.04545913264155388
Validation loss: 1.4022834070267216

Epoch: 6| Step: 12
Training loss: 0.04673447832465172
Validation loss: 1.3938658968094857

Epoch: 6| Step: 13
Training loss: 0.04660783335566521
Validation loss: 1.385052236177588

Epoch: 657| Step: 0
Training loss: 0.05399021506309509
Validation loss: 1.3809316671022804

Epoch: 6| Step: 1
Training loss: 0.07556141167879105
Validation loss: 1.3802174573303552

Epoch: 6| Step: 2
Training loss: 0.12059177458286285
Validation loss: 1.3577621172192276

Epoch: 6| Step: 3
Training loss: 0.03219827264547348
Validation loss: 1.389674707125592

Epoch: 6| Step: 4
Training loss: 0.05103538930416107
Validation loss: 1.3949802338436086

Epoch: 6| Step: 5
Training loss: 0.04976285994052887
Validation loss: 1.393494797970659

Epoch: 6| Step: 6
Training loss: 0.042336102575063705
Validation loss: 1.4038413596409622

Epoch: 6| Step: 7
Training loss: 0.04532864689826965
Validation loss: 1.420398787785602

Epoch: 6| Step: 8
Training loss: 0.05513345077633858
Validation loss: 1.4060108097650672

Epoch: 6| Step: 9
Training loss: 0.08794474601745605
Validation loss: 1.4540569923257316

Epoch: 6| Step: 10
Training loss: 0.060858435928821564
Validation loss: 1.4287444071103168

Epoch: 6| Step: 11
Training loss: 0.04668349772691727
Validation loss: 1.42971222887757

Epoch: 6| Step: 12
Training loss: 0.04788004234433174
Validation loss: 1.3845881018587338

Epoch: 6| Step: 13
Training loss: 0.039965543895959854
Validation loss: 1.382387912401589

Epoch: 658| Step: 0
Training loss: 0.14561207592487335
Validation loss: 1.3809379608400407

Epoch: 6| Step: 1
Training loss: 0.05319664254784584
Validation loss: 1.3766193466801797

Epoch: 6| Step: 2
Training loss: 0.0761101171374321
Validation loss: 1.3741549625191638

Epoch: 6| Step: 3
Training loss: 0.05818503350019455
Validation loss: 1.3804347515106201

Epoch: 6| Step: 4
Training loss: 0.06940583884716034
Validation loss: 1.383161917168607

Epoch: 6| Step: 5
Training loss: 0.056479960680007935
Validation loss: 1.419508417447408

Epoch: 6| Step: 6
Training loss: 0.04370339214801788
Validation loss: 1.4003429451296407

Epoch: 6| Step: 7
Training loss: 0.04041207954287529
Validation loss: 1.4228477862573439

Epoch: 6| Step: 8
Training loss: 0.04661394655704498
Validation loss: 1.4266347564676756

Epoch: 6| Step: 9
Training loss: 0.05331554263830185
Validation loss: 1.4429816251159997

Epoch: 6| Step: 10
Training loss: 0.0786527544260025
Validation loss: 1.4422742448827273

Epoch: 6| Step: 11
Training loss: 0.06553326547145844
Validation loss: 1.4558498846587313

Epoch: 6| Step: 12
Training loss: 0.0389576219022274
Validation loss: 1.440589310020529

Epoch: 6| Step: 13
Training loss: 0.05129590630531311
Validation loss: 1.4226775156554354

Epoch: 659| Step: 0
Training loss: 0.11252276599407196
Validation loss: 1.420389352306243

Epoch: 6| Step: 1
Training loss: 0.08088688552379608
Validation loss: 1.3975648316003944

Epoch: 6| Step: 2
Training loss: 0.08115822076797485
Validation loss: 1.3839313099461217

Epoch: 6| Step: 3
Training loss: 0.05684155225753784
Validation loss: 1.4027509612421836

Epoch: 6| Step: 4
Training loss: 0.039853207767009735
Validation loss: 1.3915992859871156

Epoch: 6| Step: 5
Training loss: 0.048203252255916595
Validation loss: 1.3832773136836227

Epoch: 6| Step: 6
Training loss: 0.043741706758737564
Validation loss: 1.3758452194993214

Epoch: 6| Step: 7
Training loss: 0.06638151407241821
Validation loss: 1.3826350672270662

Epoch: 6| Step: 8
Training loss: 0.02649134024977684
Validation loss: 1.4031883132073186

Epoch: 6| Step: 9
Training loss: 0.04926419258117676
Validation loss: 1.4192939483991234

Epoch: 6| Step: 10
Training loss: 0.057199813425540924
Validation loss: 1.4130379179472565

Epoch: 6| Step: 11
Training loss: 0.06040641665458679
Validation loss: 1.4303011983953497

Epoch: 6| Step: 12
Training loss: 0.10678477585315704
Validation loss: 1.4246657843230872

Epoch: 6| Step: 13
Training loss: 0.06451157480478287
Validation loss: 1.408263280827512

Epoch: 660| Step: 0
Training loss: 0.02018691785633564
Validation loss: 1.3943656131785402

Epoch: 6| Step: 1
Training loss: 0.06055324897170067
Validation loss: 1.4087527067430559

Epoch: 6| Step: 2
Training loss: 0.08575573563575745
Validation loss: 1.3886949554566415

Epoch: 6| Step: 3
Training loss: 0.04881872609257698
Validation loss: 1.403963635044713

Epoch: 6| Step: 4
Training loss: 0.04727626591920853
Validation loss: 1.3845833360507924

Epoch: 6| Step: 5
Training loss: 0.0707928016781807
Validation loss: 1.3803137874090543

Epoch: 6| Step: 6
Training loss: 0.05953926593065262
Validation loss: 1.3466987238135388

Epoch: 6| Step: 7
Training loss: 0.04823502153158188
Validation loss: 1.390496011703245

Epoch: 6| Step: 8
Training loss: 0.03581509739160538
Validation loss: 1.3641942688213882

Epoch: 6| Step: 9
Training loss: 0.06895922124385834
Validation loss: 1.3899904630517448

Epoch: 6| Step: 10
Training loss: 0.07926929742097855
Validation loss: 1.3640521636573217

Epoch: 6| Step: 11
Training loss: 0.03976690024137497
Validation loss: 1.3923625561498827

Epoch: 6| Step: 12
Training loss: 0.05023832619190216
Validation loss: 1.3888034025828044

Epoch: 6| Step: 13
Training loss: 0.11804363131523132
Validation loss: 1.3840094932945826

Epoch: 661| Step: 0
Training loss: 0.05240488052368164
Validation loss: 1.3769882097039172

Epoch: 6| Step: 1
Training loss: 0.046081602573394775
Validation loss: 1.3933543966662498

Epoch: 6| Step: 2
Training loss: 0.09308251738548279
Validation loss: 1.4177656327524493

Epoch: 6| Step: 3
Training loss: 0.05849456414580345
Validation loss: 1.4309566815694172

Epoch: 6| Step: 4
Training loss: 0.0460590124130249
Validation loss: 1.4128428056675901

Epoch: 6| Step: 5
Training loss: 0.07210636883974075
Validation loss: 1.4434976141939881

Epoch: 6| Step: 6
Training loss: 0.05867863446474075
Validation loss: 1.4523517700933641

Epoch: 6| Step: 7
Training loss: 0.03771214932203293
Validation loss: 1.447041033416666

Epoch: 6| Step: 8
Training loss: 0.03356946259737015
Validation loss: 1.4473587928279754

Epoch: 6| Step: 9
Training loss: 0.09163013100624084
Validation loss: 1.4530069462714656

Epoch: 6| Step: 10
Training loss: 0.06387143582105637
Validation loss: 1.42586338391868

Epoch: 6| Step: 11
Training loss: 0.04799807444214821
Validation loss: 1.4334614340977003

Epoch: 6| Step: 12
Training loss: 0.05643599480390549
Validation loss: 1.4100147588278658

Epoch: 6| Step: 13
Training loss: 0.06800764054059982
Validation loss: 1.3996736503416491

Epoch: 662| Step: 0
Training loss: 0.06988710910081863
Validation loss: 1.3924281174136746

Epoch: 6| Step: 1
Training loss: 0.07375223934650421
Validation loss: 1.384165467754487

Epoch: 6| Step: 2
Training loss: 0.05963991954922676
Validation loss: 1.3776676526633642

Epoch: 6| Step: 3
Training loss: 0.056260205805301666
Validation loss: 1.373825559052088

Epoch: 6| Step: 4
Training loss: 0.07343559712171555
Validation loss: 1.3508640476452407

Epoch: 6| Step: 5
Training loss: 0.057255327701568604
Validation loss: 1.3698571311530245

Epoch: 6| Step: 6
Training loss: 0.09146222472190857
Validation loss: 1.3618620339260306

Epoch: 6| Step: 7
Training loss: 0.052012499421834946
Validation loss: 1.352521082406403

Epoch: 6| Step: 8
Training loss: 0.07283920049667358
Validation loss: 1.3723674269132717

Epoch: 6| Step: 9
Training loss: 0.08954527974128723
Validation loss: 1.4104468848115654

Epoch: 6| Step: 10
Training loss: 0.09212668985128403
Validation loss: 1.4072244462146555

Epoch: 6| Step: 11
Training loss: 0.09672890603542328
Validation loss: 1.4224045417642082

Epoch: 6| Step: 12
Training loss: 0.07897636294364929
Validation loss: 1.4267042939380934

Epoch: 6| Step: 13
Training loss: 0.08386162668466568
Validation loss: 1.4441588655594857

Epoch: 663| Step: 0
Training loss: 0.06268325448036194
Validation loss: 1.4102115374739452

Epoch: 6| Step: 1
Training loss: 0.05950597673654556
Validation loss: 1.4168648854378731

Epoch: 6| Step: 2
Training loss: 0.07384011149406433
Validation loss: 1.410076509239853

Epoch: 6| Step: 3
Training loss: 0.04079165309667587
Validation loss: 1.4045279301622862

Epoch: 6| Step: 4
Training loss: 0.05909492075443268
Validation loss: 1.4103109323850243

Epoch: 6| Step: 5
Training loss: 0.05913970619440079
Validation loss: 1.398278567098802

Epoch: 6| Step: 6
Training loss: 0.04832681268453598
Validation loss: 1.404678838227385

Epoch: 6| Step: 7
Training loss: 0.046860381960868835
Validation loss: 1.4043541774954846

Epoch: 6| Step: 8
Training loss: 0.0842662900686264
Validation loss: 1.3964825278969222

Epoch: 6| Step: 9
Training loss: 0.09833121299743652
Validation loss: 1.4070847245954698

Epoch: 6| Step: 10
Training loss: 0.07332216203212738
Validation loss: 1.4028385493063158

Epoch: 6| Step: 11
Training loss: 0.09067767858505249
Validation loss: 1.4193311583611272

Epoch: 6| Step: 12
Training loss: 0.0816795825958252
Validation loss: 1.4025389507252684

Epoch: 6| Step: 13
Training loss: 0.04530620574951172
Validation loss: 1.432218518308414

Epoch: 664| Step: 0
Training loss: 0.06738367676734924
Validation loss: 1.4468816993057088

Epoch: 6| Step: 1
Training loss: 0.06769081205129623
Validation loss: 1.4047368918695757

Epoch: 6| Step: 2
Training loss: 0.047670356929302216
Validation loss: 1.4573688737807735

Epoch: 6| Step: 3
Training loss: 0.07640613615512848
Validation loss: 1.404068841729113

Epoch: 6| Step: 4
Training loss: 0.049908898770809174
Validation loss: 1.4177516480927825

Epoch: 6| Step: 5
Training loss: 0.06706152856349945
Validation loss: 1.3890369188401006

Epoch: 6| Step: 6
Training loss: 0.08391723036766052
Validation loss: 1.3947440270454652

Epoch: 6| Step: 7
Training loss: 0.06656593829393387
Validation loss: 1.3877094381599016

Epoch: 6| Step: 8
Training loss: 0.03623272478580475
Validation loss: 1.3892789585615999

Epoch: 6| Step: 9
Training loss: 0.045681893825531006
Validation loss: 1.3843773770075973

Epoch: 6| Step: 10
Training loss: 0.05332016199827194
Validation loss: 1.384442078169956

Epoch: 6| Step: 11
Training loss: 0.12341906130313873
Validation loss: 1.3848263884103427

Epoch: 6| Step: 12
Training loss: 0.0726872980594635
Validation loss: 1.3919573753110823

Epoch: 6| Step: 13
Training loss: 0.07090872526168823
Validation loss: 1.4152770311601701

Epoch: 665| Step: 0
Training loss: 0.04592614248394966
Validation loss: 1.4078150564624416

Epoch: 6| Step: 1
Training loss: 0.057926252484321594
Validation loss: 1.452593368868674

Epoch: 6| Step: 2
Training loss: 0.05530727654695511
Validation loss: 1.4371762224422988

Epoch: 6| Step: 3
Training loss: 0.06872349977493286
Validation loss: 1.4360093942252539

Epoch: 6| Step: 4
Training loss: 0.10267377644777298
Validation loss: 1.453797730066443

Epoch: 6| Step: 5
Training loss: 0.031849514693021774
Validation loss: 1.4434568023168912

Epoch: 6| Step: 6
Training loss: 0.06299170851707458
Validation loss: 1.4285777422689623

Epoch: 6| Step: 7
Training loss: 0.08224814385175705
Validation loss: 1.4384343316478114

Epoch: 6| Step: 8
Training loss: 0.04578739032149315
Validation loss: 1.4330451539767686

Epoch: 6| Step: 9
Training loss: 0.0661931186914444
Validation loss: 1.4407934142697243

Epoch: 6| Step: 10
Training loss: 0.06450047343969345
Validation loss: 1.445330487784519

Epoch: 6| Step: 11
Training loss: 0.052278947085142136
Validation loss: 1.4149806082889598

Epoch: 6| Step: 12
Training loss: 0.0564851388335228
Validation loss: 1.4256236694192375

Epoch: 6| Step: 13
Training loss: 0.09598848223686218
Validation loss: 1.4337122376247118

Epoch: 666| Step: 0
Training loss: 0.06892863661050797
Validation loss: 1.4320669238285353

Epoch: 6| Step: 1
Training loss: 0.05020379275083542
Validation loss: 1.4288495772628373

Epoch: 6| Step: 2
Training loss: 0.08016879856586456
Validation loss: 1.4093318241898731

Epoch: 6| Step: 3
Training loss: 0.08532734215259552
Validation loss: 1.4162965538681194

Epoch: 6| Step: 4
Training loss: 0.0791635513305664
Validation loss: 1.3837720642807663

Epoch: 6| Step: 5
Training loss: 0.043405696749687195
Validation loss: 1.3730839452435892

Epoch: 6| Step: 6
Training loss: 0.07133293896913528
Validation loss: 1.3557783583159089

Epoch: 6| Step: 7
Training loss: 0.09549181163311005
Validation loss: 1.3689850966135662

Epoch: 6| Step: 8
Training loss: 0.06232631579041481
Validation loss: 1.3783805011421122

Epoch: 6| Step: 9
Training loss: 0.14607194066047668
Validation loss: 1.3919529389309626

Epoch: 6| Step: 10
Training loss: 0.10242172330617905
Validation loss: 1.4010202128400084

Epoch: 6| Step: 11
Training loss: 0.04993375390768051
Validation loss: 1.4104496753343971

Epoch: 6| Step: 12
Training loss: 0.053576670587062836
Validation loss: 1.4161235068434028

Epoch: 6| Step: 13
Training loss: 0.09149420261383057
Validation loss: 1.4141029222037202

Epoch: 667| Step: 0
Training loss: 0.054778091609478
Validation loss: 1.4313562480352258

Epoch: 6| Step: 1
Training loss: 0.03821182623505592
Validation loss: 1.4185030280902822

Epoch: 6| Step: 2
Training loss: 0.04330490529537201
Validation loss: 1.4423599730255783

Epoch: 6| Step: 3
Training loss: 0.08993010222911835
Validation loss: 1.4467068590143675

Epoch: 6| Step: 4
Training loss: 0.07407747954130173
Validation loss: 1.422232917560044

Epoch: 6| Step: 5
Training loss: 0.06264825165271759
Validation loss: 1.4075398727129864

Epoch: 6| Step: 6
Training loss: 0.03634391352534294
Validation loss: 1.4244623889205277

Epoch: 6| Step: 7
Training loss: 0.04415188729763031
Validation loss: 1.3846834897994995

Epoch: 6| Step: 8
Training loss: 0.09553929418325424
Validation loss: 1.4086135215656732

Epoch: 6| Step: 9
Training loss: 0.0816693976521492
Validation loss: 1.4024199683179137

Epoch: 6| Step: 10
Training loss: 0.06637540459632874
Validation loss: 1.3711688108341669

Epoch: 6| Step: 11
Training loss: 0.0681341215968132
Validation loss: 1.4019319267683132

Epoch: 6| Step: 12
Training loss: 0.04590802267193794
Validation loss: 1.4153479350510465

Epoch: 6| Step: 13
Training loss: 0.08363274484872818
Validation loss: 1.4287067074929514

Epoch: 668| Step: 0
Training loss: 0.05590827018022537
Validation loss: 1.4263174405661962

Epoch: 6| Step: 1
Training loss: 0.05751854181289673
Validation loss: 1.4284997883663382

Epoch: 6| Step: 2
Training loss: 0.0538841113448143
Validation loss: 1.4076408340084938

Epoch: 6| Step: 3
Training loss: 0.04562617093324661
Validation loss: 1.4034557611711564

Epoch: 6| Step: 4
Training loss: 0.05308292433619499
Validation loss: 1.4260913120803012

Epoch: 6| Step: 5
Training loss: 0.049659110605716705
Validation loss: 1.4007263657867268

Epoch: 6| Step: 6
Training loss: 0.0623779259622097
Validation loss: 1.4125489868143553

Epoch: 6| Step: 7
Training loss: 0.09845445305109024
Validation loss: 1.410680486309913

Epoch: 6| Step: 8
Training loss: 0.06539922952651978
Validation loss: 1.4269074566902653

Epoch: 6| Step: 9
Training loss: 0.08346299827098846
Validation loss: 1.40708331395221

Epoch: 6| Step: 10
Training loss: 0.09651482105255127
Validation loss: 1.4022788796373593

Epoch: 6| Step: 11
Training loss: 0.08125408738851547
Validation loss: 1.3922828679443688

Epoch: 6| Step: 12
Training loss: 0.058246735483407974
Validation loss: 1.358070263298609

Epoch: 6| Step: 13
Training loss: 0.05212048813700676
Validation loss: 1.3874649514434159

Epoch: 669| Step: 0
Training loss: 0.04210302606225014
Validation loss: 1.38707999901105

Epoch: 6| Step: 1
Training loss: 0.11560530960559845
Validation loss: 1.3895913862412976

Epoch: 6| Step: 2
Training loss: 0.036686092615127563
Validation loss: 1.3993039631074475

Epoch: 6| Step: 3
Training loss: 0.05582013353705406
Validation loss: 1.4150895021295036

Epoch: 6| Step: 4
Training loss: 0.06254395842552185
Validation loss: 1.3937488730235765

Epoch: 6| Step: 5
Training loss: 0.051238641142845154
Validation loss: 1.4281618883532863

Epoch: 6| Step: 6
Training loss: 0.05551394075155258
Validation loss: 1.4233806312725108

Epoch: 6| Step: 7
Training loss: 0.05844970792531967
Validation loss: 1.4084298764505694

Epoch: 6| Step: 8
Training loss: 0.031939797103405
Validation loss: 1.4153780655194355

Epoch: 6| Step: 9
Training loss: 0.0483604371547699
Validation loss: 1.401028606199449

Epoch: 6| Step: 10
Training loss: 0.04456869512796402
Validation loss: 1.4270964437915432

Epoch: 6| Step: 11
Training loss: 0.06250225007534027
Validation loss: 1.4102991793745308

Epoch: 6| Step: 12
Training loss: 0.038802340626716614
Validation loss: 1.4137329093871578

Epoch: 6| Step: 13
Training loss: 0.08581128716468811
Validation loss: 1.4087357572329942

Epoch: 670| Step: 0
Training loss: 0.043728262186050415
Validation loss: 1.426678660095379

Epoch: 6| Step: 1
Training loss: 0.06435557454824448
Validation loss: 1.426821179287408

Epoch: 6| Step: 2
Training loss: 0.048697326332330704
Validation loss: 1.4319803125114852

Epoch: 6| Step: 3
Training loss: 0.061794571578502655
Validation loss: 1.4250752464417489

Epoch: 6| Step: 4
Training loss: 0.06690026074647903
Validation loss: 1.4343557062969412

Epoch: 6| Step: 5
Training loss: 0.056070245802402496
Validation loss: 1.428074215048103

Epoch: 6| Step: 6
Training loss: 0.028340809047222137
Validation loss: 1.4359505009907547

Epoch: 6| Step: 7
Training loss: 0.035930193960666656
Validation loss: 1.4282252314270183

Epoch: 6| Step: 8
Training loss: 0.06309036165475845
Validation loss: 1.439517092961137

Epoch: 6| Step: 9
Training loss: 0.06220554932951927
Validation loss: 1.4120631038501699

Epoch: 6| Step: 10
Training loss: 0.047136224806308746
Validation loss: 1.4167720463968092

Epoch: 6| Step: 11
Training loss: 0.06847639381885529
Validation loss: 1.423356928492105

Epoch: 6| Step: 12
Training loss: 0.04851939156651497
Validation loss: 1.4234595356449005

Epoch: 6| Step: 13
Training loss: 0.09570521861314774
Validation loss: 1.4187827635836858

Epoch: 671| Step: 0
Training loss: 0.050296101719141006
Validation loss: 1.4295181484632595

Epoch: 6| Step: 1
Training loss: 0.04541570693254471
Validation loss: 1.4230540978011263

Epoch: 6| Step: 2
Training loss: 0.063269704580307
Validation loss: 1.4326396155100998

Epoch: 6| Step: 3
Training loss: 0.05384507402777672
Validation loss: 1.4237610934883036

Epoch: 6| Step: 4
Training loss: 0.04233846813440323
Validation loss: 1.4380634677025579

Epoch: 6| Step: 5
Training loss: 0.03203015774488449
Validation loss: 1.4405337764370827

Epoch: 6| Step: 6
Training loss: 0.04181194305419922
Validation loss: 1.4214861110974384

Epoch: 6| Step: 7
Training loss: 0.034430935978889465
Validation loss: 1.4345224467656945

Epoch: 6| Step: 8
Training loss: 0.032669007778167725
Validation loss: 1.4322453147621566

Epoch: 6| Step: 9
Training loss: 0.03886202722787857
Validation loss: 1.444054941977224

Epoch: 6| Step: 10
Training loss: 0.06820863485336304
Validation loss: 1.451907705235225

Epoch: 6| Step: 11
Training loss: 0.07987101376056671
Validation loss: 1.4397609861948157

Epoch: 6| Step: 12
Training loss: 0.05957335978746414
Validation loss: 1.4240365028381348

Epoch: 6| Step: 13
Training loss: 0.09156714379787445
Validation loss: 1.4349313089924474

Epoch: 672| Step: 0
Training loss: 0.05515033379197121
Validation loss: 1.4360170242606953

Epoch: 6| Step: 1
Training loss: 0.03654918819665909
Validation loss: 1.420569383969871

Epoch: 6| Step: 2
Training loss: 0.04326392710208893
Validation loss: 1.4380614090991277

Epoch: 6| Step: 3
Training loss: 0.05281409993767738
Validation loss: 1.4152194787097234

Epoch: 6| Step: 4
Training loss: 0.031184446066617966
Validation loss: 1.4187560491664435

Epoch: 6| Step: 5
Training loss: 0.06700173020362854
Validation loss: 1.4395625014458933

Epoch: 6| Step: 6
Training loss: 0.06424849480390549
Validation loss: 1.4122881120251072

Epoch: 6| Step: 7
Training loss: 0.06614306569099426
Validation loss: 1.4167309999465942

Epoch: 6| Step: 8
Training loss: 0.08220314979553223
Validation loss: 1.4274226939806374

Epoch: 6| Step: 9
Training loss: 0.07380664348602295
Validation loss: 1.4307720520163094

Epoch: 6| Step: 10
Training loss: 0.060519054532051086
Validation loss: 1.411526318519346

Epoch: 6| Step: 11
Training loss: 0.07183833420276642
Validation loss: 1.4182094720102125

Epoch: 6| Step: 12
Training loss: 0.05108116567134857
Validation loss: 1.420097908666057

Epoch: 6| Step: 13
Training loss: 0.025767246261239052
Validation loss: 1.400973912208311

Epoch: 673| Step: 0
Training loss: 0.0400397926568985
Validation loss: 1.4084123526850054

Epoch: 6| Step: 1
Training loss: 0.060472384095191956
Validation loss: 1.4054157041734265

Epoch: 6| Step: 2
Training loss: 0.046894706785678864
Validation loss: 1.3932751301796205

Epoch: 6| Step: 3
Training loss: 0.08011840283870697
Validation loss: 1.380908566136514

Epoch: 6| Step: 4
Training loss: 0.06992760300636292
Validation loss: 1.3561929297703568

Epoch: 6| Step: 5
Training loss: 0.08208057284355164
Validation loss: 1.389014236388668

Epoch: 6| Step: 6
Training loss: 0.06973583251237869
Validation loss: 1.3978732798689155

Epoch: 6| Step: 7
Training loss: 0.027032138779759407
Validation loss: 1.3997444677096542

Epoch: 6| Step: 8
Training loss: 0.052324533462524414
Validation loss: 1.417617312041662

Epoch: 6| Step: 9
Training loss: 0.032121073454618454
Validation loss: 1.3901097518141552

Epoch: 6| Step: 10
Training loss: 0.06834189593791962
Validation loss: 1.4062153767513972

Epoch: 6| Step: 11
Training loss: 0.056460097432136536
Validation loss: 1.4084777293666717

Epoch: 6| Step: 12
Training loss: 0.0720086395740509
Validation loss: 1.4165009055086362

Epoch: 6| Step: 13
Training loss: 0.06278017163276672
Validation loss: 1.427172359599862

Epoch: 674| Step: 0
Training loss: 0.08198492974042892
Validation loss: 1.4280710181882303

Epoch: 6| Step: 1
Training loss: 0.05501532554626465
Validation loss: 1.4206827186769055

Epoch: 6| Step: 2
Training loss: 0.0529763326048851
Validation loss: 1.4431110915317331

Epoch: 6| Step: 3
Training loss: 0.03898084908723831
Validation loss: 1.4297230064228017

Epoch: 6| Step: 4
Training loss: 0.02623666822910309
Validation loss: 1.4256793632302234

Epoch: 6| Step: 5
Training loss: 0.053274527192115784
Validation loss: 1.3988624054898497

Epoch: 6| Step: 6
Training loss: 0.0681951716542244
Validation loss: 1.3996903729695145

Epoch: 6| Step: 7
Training loss: 0.05347824841737747
Validation loss: 1.3646184007326763

Epoch: 6| Step: 8
Training loss: 0.04374495521187782
Validation loss: 1.3806915129384687

Epoch: 6| Step: 9
Training loss: 0.047318361699581146
Validation loss: 1.381736465679702

Epoch: 6| Step: 10
Training loss: 0.07129718363285065
Validation loss: 1.390551281872616

Epoch: 6| Step: 11
Training loss: 0.06101781129837036
Validation loss: 1.379792272403676

Epoch: 6| Step: 12
Training loss: 0.05656407028436661
Validation loss: 1.4101331092978036

Epoch: 6| Step: 13
Training loss: 0.03511334955692291
Validation loss: 1.4399932366545483

Epoch: 675| Step: 0
Training loss: 0.04839733988046646
Validation loss: 1.431401232237457

Epoch: 6| Step: 1
Training loss: 0.0703447088599205
Validation loss: 1.4176529479283158

Epoch: 6| Step: 2
Training loss: 0.039217837154865265
Validation loss: 1.448056883709405

Epoch: 6| Step: 3
Training loss: 0.042441628873348236
Validation loss: 1.4249813607943955

Epoch: 6| Step: 4
Training loss: 0.049299903213977814
Validation loss: 1.4240521596324058

Epoch: 6| Step: 5
Training loss: 0.04475906491279602
Validation loss: 1.440002631115657

Epoch: 6| Step: 6
Training loss: 0.05719439685344696
Validation loss: 1.4173836079976891

Epoch: 6| Step: 7
Training loss: 0.05507998913526535
Validation loss: 1.3947626583037838

Epoch: 6| Step: 8
Training loss: 0.10350526869297028
Validation loss: 1.417539288920741

Epoch: 6| Step: 9
Training loss: 0.044027652591466904
Validation loss: 1.423440501254092

Epoch: 6| Step: 10
Training loss: 0.06044884771108627
Validation loss: 1.4264532481470416

Epoch: 6| Step: 11
Training loss: 0.06321152299642563
Validation loss: 1.4439120497754825

Epoch: 6| Step: 12
Training loss: 0.0610990896821022
Validation loss: 1.449892819568675

Epoch: 6| Step: 13
Training loss: 0.0777750015258789
Validation loss: 1.4372168753736763

Epoch: 676| Step: 0
Training loss: 0.060150519013404846
Validation loss: 1.4083845653841573

Epoch: 6| Step: 1
Training loss: 0.06486896425485611
Validation loss: 1.3843305508295696

Epoch: 6| Step: 2
Training loss: 0.04185496270656586
Validation loss: 1.3725493595164309

Epoch: 6| Step: 3
Training loss: 0.04998602718114853
Validation loss: 1.3551099966931086

Epoch: 6| Step: 4
Training loss: 0.04520741105079651
Validation loss: 1.3272019740073913

Epoch: 6| Step: 5
Training loss: 0.07496185600757599
Validation loss: 1.3401220114000383

Epoch: 6| Step: 6
Training loss: 0.04135708510875702
Validation loss: 1.3117205084011119

Epoch: 6| Step: 7
Training loss: 0.03366893529891968
Validation loss: 1.345749701863976

Epoch: 6| Step: 8
Training loss: 0.05128701776266098
Validation loss: 1.3649301452021445

Epoch: 6| Step: 9
Training loss: 0.06736787408590317
Validation loss: 1.370595843561234

Epoch: 6| Step: 10
Training loss: 0.029618650674819946
Validation loss: 1.3946966573756228

Epoch: 6| Step: 11
Training loss: 0.071872279047966
Validation loss: 1.415486950387237

Epoch: 6| Step: 12
Training loss: 0.12896201014518738
Validation loss: 1.402430284407831

Epoch: 6| Step: 13
Training loss: 0.0787942036986351
Validation loss: 1.3786687235678396

Epoch: 677| Step: 0
Training loss: 0.07263486832380295
Validation loss: 1.342602655451785

Epoch: 6| Step: 1
Training loss: 0.10078326612710953
Validation loss: 1.3217579126358032

Epoch: 6| Step: 2
Training loss: 0.10659392178058624
Validation loss: 1.3212722616810952

Epoch: 6| Step: 3
Training loss: 0.10188056528568268
Validation loss: 1.3400266401229366

Epoch: 6| Step: 4
Training loss: 0.09403486549854279
Validation loss: 1.355662881046213

Epoch: 6| Step: 5
Training loss: 0.06423178315162659
Validation loss: 1.383998570903655

Epoch: 6| Step: 6
Training loss: 0.07086293399333954
Validation loss: 1.3968724704557849

Epoch: 6| Step: 7
Training loss: 0.09131885319948196
Validation loss: 1.417182210953005

Epoch: 6| Step: 8
Training loss: 0.07567156851291656
Validation loss: 1.4280940448084185

Epoch: 6| Step: 9
Training loss: 0.061965011060237885
Validation loss: 1.4354294192406438

Epoch: 6| Step: 10
Training loss: 0.07427900284528732
Validation loss: 1.4662026564280193

Epoch: 6| Step: 11
Training loss: 0.07331521809101105
Validation loss: 1.459822782906153

Epoch: 6| Step: 12
Training loss: 0.05770139396190643
Validation loss: 1.4508211343519148

Epoch: 6| Step: 13
Training loss: 0.08529366552829742
Validation loss: 1.4325750489388742

Epoch: 678| Step: 0
Training loss: 0.07305729389190674
Validation loss: 1.4211220920726817

Epoch: 6| Step: 1
Training loss: 0.051175251603126526
Validation loss: 1.4100307751727361

Epoch: 6| Step: 2
Training loss: 0.04633855074644089
Validation loss: 1.4096163883004138

Epoch: 6| Step: 3
Training loss: 0.06396903097629547
Validation loss: 1.3853174512104323

Epoch: 6| Step: 4
Training loss: 0.0661737471818924
Validation loss: 1.3776892808175856

Epoch: 6| Step: 5
Training loss: 0.08523982763290405
Validation loss: 1.3737327770520282

Epoch: 6| Step: 6
Training loss: 0.0797080248594284
Validation loss: 1.4019424902495516

Epoch: 6| Step: 7
Training loss: 0.04624339938163757
Validation loss: 1.3823482631355204

Epoch: 6| Step: 8
Training loss: 0.04404127970337868
Validation loss: 1.4107041692221036

Epoch: 6| Step: 9
Training loss: 0.0521993562579155
Validation loss: 1.405016109507571

Epoch: 6| Step: 10
Training loss: 0.05354118347167969
Validation loss: 1.4300709757753598

Epoch: 6| Step: 11
Training loss: 0.06686791032552719
Validation loss: 1.4343303454819547

Epoch: 6| Step: 12
Training loss: 0.04112676903605461
Validation loss: 1.4185936258685203

Epoch: 6| Step: 13
Training loss: 0.07164300978183746
Validation loss: 1.4634029442264187

Epoch: 679| Step: 0
Training loss: 0.07665423303842545
Validation loss: 1.476406458885439

Epoch: 6| Step: 1
Training loss: 0.08862300962209702
Validation loss: 1.464651353897587

Epoch: 6| Step: 2
Training loss: 0.05476699024438858
Validation loss: 1.4456810605141424

Epoch: 6| Step: 3
Training loss: 0.04298366978764534
Validation loss: 1.4389172959071335

Epoch: 6| Step: 4
Training loss: 0.053171075880527496
Validation loss: 1.4192959441933581

Epoch: 6| Step: 5
Training loss: 0.06357526034116745
Validation loss: 1.412803243565303

Epoch: 6| Step: 6
Training loss: 0.0626540556550026
Validation loss: 1.417216859838014

Epoch: 6| Step: 7
Training loss: 0.04611407220363617
Validation loss: 1.39752778186593

Epoch: 6| Step: 8
Training loss: 0.0450163260102272
Validation loss: 1.3987419605255127

Epoch: 6| Step: 9
Training loss: 0.06344696879386902
Validation loss: 1.4090122240845875

Epoch: 6| Step: 10
Training loss: 0.06318129599094391
Validation loss: 1.3727962983551847

Epoch: 6| Step: 11
Training loss: 0.07555042952299118
Validation loss: 1.391973466001531

Epoch: 6| Step: 12
Training loss: 0.06957095116376877
Validation loss: 1.3715268668308054

Epoch: 6| Step: 13
Training loss: 0.08722657710313797
Validation loss: 1.39284546080456

Epoch: 680| Step: 0
Training loss: 0.07014288008213043
Validation loss: 1.375202150114121

Epoch: 6| Step: 1
Training loss: 0.0678996741771698
Validation loss: 1.3766591292555614

Epoch: 6| Step: 2
Training loss: 0.06609316170215607
Validation loss: 1.4054381494881005

Epoch: 6| Step: 3
Training loss: 0.07763321697711945
Validation loss: 1.3986505654550367

Epoch: 6| Step: 4
Training loss: 0.10163432359695435
Validation loss: 1.4209867767108384

Epoch: 6| Step: 5
Training loss: 0.05245524272322655
Validation loss: 1.4194936733092032

Epoch: 6| Step: 6
Training loss: 0.034866273403167725
Validation loss: 1.4230062243758992

Epoch: 6| Step: 7
Training loss: 0.08032189309597015
Validation loss: 1.4015169118040351

Epoch: 6| Step: 8
Training loss: 0.06556250154972076
Validation loss: 1.4314771595821585

Epoch: 6| Step: 9
Training loss: 0.05372098833322525
Validation loss: 1.4271123075997958

Epoch: 6| Step: 10
Training loss: 0.055526524782180786
Validation loss: 1.4237372362485496

Epoch: 6| Step: 11
Training loss: 0.05360948666930199
Validation loss: 1.3937836334269533

Epoch: 6| Step: 12
Training loss: 0.06866101920604706
Validation loss: 1.3998080017746135

Epoch: 6| Step: 13
Training loss: 0.05981424078345299
Validation loss: 1.4041117775824763

Epoch: 681| Step: 0
Training loss: 0.06706150621175766
Validation loss: 1.3900898925719722

Epoch: 6| Step: 1
Training loss: 0.06135675311088562
Validation loss: 1.3840199901211647

Epoch: 6| Step: 2
Training loss: 0.08151379227638245
Validation loss: 1.4000045035475044

Epoch: 6| Step: 3
Training loss: 0.07001585513353348
Validation loss: 1.4105447184654973

Epoch: 6| Step: 4
Training loss: 0.05355702340602875
Validation loss: 1.414722418272367

Epoch: 6| Step: 5
Training loss: 0.03659491986036301
Validation loss: 1.3932182455575595

Epoch: 6| Step: 6
Training loss: 0.05766904354095459
Validation loss: 1.4090035705156223

Epoch: 6| Step: 7
Training loss: 0.047923341393470764
Validation loss: 1.422264926536109

Epoch: 6| Step: 8
Training loss: 0.06853777915239334
Validation loss: 1.421953164121156

Epoch: 6| Step: 9
Training loss: 0.0532069206237793
Validation loss: 1.406374018679383

Epoch: 6| Step: 10
Training loss: 0.040955059230327606
Validation loss: 1.4051685858798284

Epoch: 6| Step: 11
Training loss: 0.034947190433740616
Validation loss: 1.393166224161784

Epoch: 6| Step: 12
Training loss: 0.046585679054260254
Validation loss: 1.3859706617170764

Epoch: 6| Step: 13
Training loss: 0.020987801253795624
Validation loss: 1.3712748609563357

Epoch: 682| Step: 0
Training loss: 0.06393122673034668
Validation loss: 1.3774326828218275

Epoch: 6| Step: 1
Training loss: 0.05868735909461975
Validation loss: 1.3620908003981396

Epoch: 6| Step: 2
Training loss: 0.03123493492603302
Validation loss: 1.3725754791690457

Epoch: 6| Step: 3
Training loss: 0.07511381804943085
Validation loss: 1.385029972240489

Epoch: 6| Step: 4
Training loss: 0.03700143098831177
Validation loss: 1.3899938983301963

Epoch: 6| Step: 5
Training loss: 0.05883999913930893
Validation loss: 1.3963391716762255

Epoch: 6| Step: 6
Training loss: 0.04677702486515045
Validation loss: 1.3919863816230529

Epoch: 6| Step: 7
Training loss: 0.060540229082107544
Validation loss: 1.3726268564501116

Epoch: 6| Step: 8
Training loss: 0.054096519947052
Validation loss: 1.4004950882286153

Epoch: 6| Step: 9
Training loss: 0.0792241171002388
Validation loss: 1.420475189403821

Epoch: 6| Step: 10
Training loss: 0.06342577934265137
Validation loss: 1.4092215799516248

Epoch: 6| Step: 11
Training loss: 0.08076406270265579
Validation loss: 1.4151950574690295

Epoch: 6| Step: 12
Training loss: 0.07544757425785065
Validation loss: 1.3899482885996501

Epoch: 6| Step: 13
Training loss: 0.026690270751714706
Validation loss: 1.4170045506569646

Epoch: 683| Step: 0
Training loss: 0.051642030477523804
Validation loss: 1.405207464771886

Epoch: 6| Step: 1
Training loss: 0.03136797249317169
Validation loss: 1.3910683675478863

Epoch: 6| Step: 2
Training loss: 0.04254595935344696
Validation loss: 1.3955800392294442

Epoch: 6| Step: 3
Training loss: 0.06230390444397926
Validation loss: 1.3963346891505743

Epoch: 6| Step: 4
Training loss: 0.05117042362689972
Validation loss: 1.409850138489918

Epoch: 6| Step: 5
Training loss: 0.03536757826805115
Validation loss: 1.4079103392939414

Epoch: 6| Step: 6
Training loss: 0.05590716749429703
Validation loss: 1.381678258219073

Epoch: 6| Step: 7
Training loss: 0.07441550493240356
Validation loss: 1.401186107307352

Epoch: 6| Step: 8
Training loss: 0.08670436590909958
Validation loss: 1.3865446826463104

Epoch: 6| Step: 9
Training loss: 0.05543474107980728
Validation loss: 1.381977121035258

Epoch: 6| Step: 10
Training loss: 0.07525237649679184
Validation loss: 1.3610743207316245

Epoch: 6| Step: 11
Training loss: 0.06350477784872055
Validation loss: 1.3869063918308546

Epoch: 6| Step: 12
Training loss: 0.08141481131315231
Validation loss: 1.3705451655131515

Epoch: 6| Step: 13
Training loss: 0.12077805399894714
Validation loss: 1.3800489928132744

Epoch: 684| Step: 0
Training loss: 0.05887453258037567
Validation loss: 1.3687122906408002

Epoch: 6| Step: 1
Training loss: 0.0474637970328331
Validation loss: 1.3799673793136433

Epoch: 6| Step: 2
Training loss: 0.030994927510619164
Validation loss: 1.412458255726804

Epoch: 6| Step: 3
Training loss: 0.03842095285654068
Validation loss: 1.4328465692458614

Epoch: 6| Step: 4
Training loss: 0.07055293023586273
Validation loss: 1.4067999278345416

Epoch: 6| Step: 5
Training loss: 0.07465200126171112
Validation loss: 1.4325606271784792

Epoch: 6| Step: 6
Training loss: 0.040647752583026886
Validation loss: 1.4228305855105001

Epoch: 6| Step: 7
Training loss: 0.06487755477428436
Validation loss: 1.409164555611149

Epoch: 6| Step: 8
Training loss: 0.07659640163183212
Validation loss: 1.4359052386335147

Epoch: 6| Step: 9
Training loss: 0.055162213742733
Validation loss: 1.4237680165998396

Epoch: 6| Step: 10
Training loss: 0.05453215539455414
Validation loss: 1.4119395748261483

Epoch: 6| Step: 11
Training loss: 0.062356457114219666
Validation loss: 1.3914594611813944

Epoch: 6| Step: 12
Training loss: 0.060153186321258545
Validation loss: 1.409096792180051

Epoch: 6| Step: 13
Training loss: 0.08008548617362976
Validation loss: 1.4070779251795944

Epoch: 685| Step: 0
Training loss: 0.05764526128768921
Validation loss: 1.4190894352492465

Epoch: 6| Step: 1
Training loss: 0.08004625141620636
Validation loss: 1.3989969235594555

Epoch: 6| Step: 2
Training loss: 0.06855423748493195
Validation loss: 1.3968713578357492

Epoch: 6| Step: 3
Training loss: 0.043253302574157715
Validation loss: 1.405011300117739

Epoch: 6| Step: 4
Training loss: 0.06125077232718468
Validation loss: 1.4110763867696126

Epoch: 6| Step: 5
Training loss: 0.07225526124238968
Validation loss: 1.4309702278465353

Epoch: 6| Step: 6
Training loss: 0.053715288639068604
Validation loss: 1.439830304473959

Epoch: 6| Step: 7
Training loss: 0.07192288339138031
Validation loss: 1.421902250218135

Epoch: 6| Step: 8
Training loss: 0.06015904247760773
Validation loss: 1.4418986907569311

Epoch: 6| Step: 9
Training loss: 0.07324554026126862
Validation loss: 1.4257279903657976

Epoch: 6| Step: 10
Training loss: 0.057627856731414795
Validation loss: 1.45147551772415

Epoch: 6| Step: 11
Training loss: 0.05392960458993912
Validation loss: 1.4195129358640282

Epoch: 6| Step: 12
Training loss: 0.051166512072086334
Validation loss: 1.4367459858617475

Epoch: 6| Step: 13
Training loss: 0.05736041069030762
Validation loss: 1.44227744302442

Epoch: 686| Step: 0
Training loss: 0.03702016547322273
Validation loss: 1.4389211823863368

Epoch: 6| Step: 1
Training loss: 0.020461276173591614
Validation loss: 1.4205985376911778

Epoch: 6| Step: 2
Training loss: 0.029755182564258575
Validation loss: 1.4240626071089058

Epoch: 6| Step: 3
Training loss: 0.07873807847499847
Validation loss: 1.4026900260679183

Epoch: 6| Step: 4
Training loss: 0.04130754619836807
Validation loss: 1.4086085737392466

Epoch: 6| Step: 5
Training loss: 0.05200552940368652
Validation loss: 1.4022535681724548

Epoch: 6| Step: 6
Training loss: 0.037570927292108536
Validation loss: 1.410155245052871

Epoch: 6| Step: 7
Training loss: 0.07772059738636017
Validation loss: 1.4126990136279856

Epoch: 6| Step: 8
Training loss: 0.03832510858774185
Validation loss: 1.4158462888451033

Epoch: 6| Step: 9
Training loss: 0.03922652453184128
Validation loss: 1.4316014692347536

Epoch: 6| Step: 10
Training loss: 0.04284563288092613
Validation loss: 1.4469098506435272

Epoch: 6| Step: 11
Training loss: 0.06544037908315659
Validation loss: 1.427371363486013

Epoch: 6| Step: 12
Training loss: 0.04876542091369629
Validation loss: 1.4216488689504645

Epoch: 6| Step: 13
Training loss: 0.03616049513220787
Validation loss: 1.414201210903865

Epoch: 687| Step: 0
Training loss: 0.03332814201712608
Validation loss: 1.4295065261984383

Epoch: 6| Step: 1
Training loss: 0.054787375032901764
Validation loss: 1.423566783628156

Epoch: 6| Step: 2
Training loss: 0.056403160095214844
Validation loss: 1.403559664244293

Epoch: 6| Step: 3
Training loss: 0.05508427321910858
Validation loss: 1.4080688209943875

Epoch: 6| Step: 4
Training loss: 0.06933464109897614
Validation loss: 1.3995719660994828

Epoch: 6| Step: 5
Training loss: 0.06874684989452362
Validation loss: 1.401720553316096

Epoch: 6| Step: 6
Training loss: 0.05873126536607742
Validation loss: 1.3858309939343443

Epoch: 6| Step: 7
Training loss: 0.05338776111602783
Validation loss: 1.3927312204914708

Epoch: 6| Step: 8
Training loss: 0.07335282117128372
Validation loss: 1.3864897707457184

Epoch: 6| Step: 9
Training loss: 0.06351646780967712
Validation loss: 1.4076086744185416

Epoch: 6| Step: 10
Training loss: 0.03586958348751068
Validation loss: 1.4055119291428597

Epoch: 6| Step: 11
Training loss: 0.10070930421352386
Validation loss: 1.4181752704804944

Epoch: 6| Step: 12
Training loss: 0.025668255984783173
Validation loss: 1.4477895318820913

Epoch: 6| Step: 13
Training loss: 0.039743926376104355
Validation loss: 1.436647653579712

Epoch: 688| Step: 0
Training loss: 0.06902793049812317
Validation loss: 1.4551939554111932

Epoch: 6| Step: 1
Training loss: 0.04707718640565872
Validation loss: 1.4807471665002967

Epoch: 6| Step: 2
Training loss: 0.035425446927547455
Validation loss: 1.43600756378584

Epoch: 6| Step: 3
Training loss: 0.028199240565299988
Validation loss: 1.4222519282371766

Epoch: 6| Step: 4
Training loss: 0.06395889818668365
Validation loss: 1.415817447887954

Epoch: 6| Step: 5
Training loss: 0.057348646223545074
Validation loss: 1.398994876492408

Epoch: 6| Step: 6
Training loss: 0.08207505941390991
Validation loss: 1.4169430630181425

Epoch: 6| Step: 7
Training loss: 0.08300904184579849
Validation loss: 1.3847064843741796

Epoch: 6| Step: 8
Training loss: 0.08288741111755371
Validation loss: 1.4030157109742523

Epoch: 6| Step: 9
Training loss: 0.03371988981962204
Validation loss: 1.4178768332286547

Epoch: 6| Step: 10
Training loss: 0.04247157275676727
Validation loss: 1.42350455317446

Epoch: 6| Step: 11
Training loss: 0.05375160276889801
Validation loss: 1.4129526730506652

Epoch: 6| Step: 12
Training loss: 0.021269818767905235
Validation loss: 1.4385197444628643

Epoch: 6| Step: 13
Training loss: 0.08670602738857269
Validation loss: 1.4529383310707666

Epoch: 689| Step: 0
Training loss: 0.06656897068023682
Validation loss: 1.4820642009858163

Epoch: 6| Step: 1
Training loss: 0.06503579020500183
Validation loss: 1.4835879007975261

Epoch: 6| Step: 2
Training loss: 0.04921411722898483
Validation loss: 1.4740055684120423

Epoch: 6| Step: 3
Training loss: 0.051510944962501526
Validation loss: 1.4705914662730308

Epoch: 6| Step: 4
Training loss: 0.0434078723192215
Validation loss: 1.4659324012776858

Epoch: 6| Step: 5
Training loss: 0.06909340620040894
Validation loss: 1.4501331583146126

Epoch: 6| Step: 6
Training loss: 0.08738976716995239
Validation loss: 1.405971315599257

Epoch: 6| Step: 7
Training loss: 0.07229889184236526
Validation loss: 1.376785518020712

Epoch: 6| Step: 8
Training loss: 0.030109867453575134
Validation loss: 1.3878747519626413

Epoch: 6| Step: 9
Training loss: 0.06475172936916351
Validation loss: 1.3795872965166647

Epoch: 6| Step: 10
Training loss: 0.053279727697372437
Validation loss: 1.3627185706169374

Epoch: 6| Step: 11
Training loss: 0.04218372702598572
Validation loss: 1.3602457431054884

Epoch: 6| Step: 12
Training loss: 0.02673857845366001
Validation loss: 1.3466014451878046

Epoch: 6| Step: 13
Training loss: 0.08009142428636551
Validation loss: 1.3619746251772809

Epoch: 690| Step: 0
Training loss: 0.04029073938727379
Validation loss: 1.3670793374379475

Epoch: 6| Step: 1
Training loss: 0.06846121698617935
Validation loss: 1.3375854556278517

Epoch: 6| Step: 2
Training loss: 0.07250338047742844
Validation loss: 1.3548298798581606

Epoch: 6| Step: 3
Training loss: 0.06422232836484909
Validation loss: 1.3421316390396447

Epoch: 6| Step: 4
Training loss: 0.03630169481039047
Validation loss: 1.345641545070115

Epoch: 6| Step: 5
Training loss: 0.06251917779445648
Validation loss: 1.3619863064058366

Epoch: 6| Step: 6
Training loss: 0.04044070094823837
Validation loss: 1.366093857313997

Epoch: 6| Step: 7
Training loss: 0.06618374586105347
Validation loss: 1.3724968010379421

Epoch: 6| Step: 8
Training loss: 0.05608123540878296
Validation loss: 1.385732671265961

Epoch: 6| Step: 9
Training loss: 0.038537897169589996
Validation loss: 1.4097657344674552

Epoch: 6| Step: 10
Training loss: 0.049520011991262436
Validation loss: 1.4066601876289613

Epoch: 6| Step: 11
Training loss: 0.03517237305641174
Validation loss: 1.419011164737004

Epoch: 6| Step: 12
Training loss: 0.035271406173706055
Validation loss: 1.4261808356931132

Epoch: 6| Step: 13
Training loss: 0.05885024741292
Validation loss: 1.4341176171456613

Epoch: 691| Step: 0
Training loss: 0.03231078386306763
Validation loss: 1.4415430356097478

Epoch: 6| Step: 1
Training loss: 0.05855942144989967
Validation loss: 1.4580392273523475

Epoch: 6| Step: 2
Training loss: 0.042565908282995224
Validation loss: 1.441247586281069

Epoch: 6| Step: 3
Training loss: 0.07444508373737335
Validation loss: 1.463702501789216

Epoch: 6| Step: 4
Training loss: 0.09931161999702454
Validation loss: 1.4308695562424198

Epoch: 6| Step: 5
Training loss: 0.1413571685552597
Validation loss: 1.4352451832063737

Epoch: 6| Step: 6
Training loss: 0.05787472426891327
Validation loss: 1.432137277177585

Epoch: 6| Step: 7
Training loss: 0.048582032322883606
Validation loss: 1.4196701600987425

Epoch: 6| Step: 8
Training loss: 0.049685560166835785
Validation loss: 1.4340262207933652

Epoch: 6| Step: 9
Training loss: 0.0816749781370163
Validation loss: 1.4350596640699653

Epoch: 6| Step: 10
Training loss: 0.06311159580945969
Validation loss: 1.4135244648943666

Epoch: 6| Step: 11
Training loss: 0.06686626374721527
Validation loss: 1.4161023632172616

Epoch: 6| Step: 12
Training loss: 0.04507407546043396
Validation loss: 1.4314014809105986

Epoch: 6| Step: 13
Training loss: 0.06774748861789703
Validation loss: 1.4376494000034947

Epoch: 692| Step: 0
Training loss: 0.06138414517045021
Validation loss: 1.4126433505806872

Epoch: 6| Step: 1
Training loss: 0.03910507261753082
Validation loss: 1.4128564147539036

Epoch: 6| Step: 2
Training loss: 0.06281185895204544
Validation loss: 1.4153142949586273

Epoch: 6| Step: 3
Training loss: 0.06422008574008942
Validation loss: 1.395463466644287

Epoch: 6| Step: 4
Training loss: 0.0480898842215538
Validation loss: 1.4094947691886657

Epoch: 6| Step: 5
Training loss: 0.05377312749624252
Validation loss: 1.3768817840083953

Epoch: 6| Step: 6
Training loss: 0.06968185305595398
Validation loss: 1.384758746752175

Epoch: 6| Step: 7
Training loss: 0.05489101633429527
Validation loss: 1.3919070484817668

Epoch: 6| Step: 8
Training loss: 0.05148191750049591
Validation loss: 1.3731631386664607

Epoch: 6| Step: 9
Training loss: 0.04192778468132019
Validation loss: 1.3962958910131966

Epoch: 6| Step: 10
Training loss: 0.04523704573512077
Validation loss: 1.3819491619704871

Epoch: 6| Step: 11
Training loss: 0.03283292055130005
Validation loss: 1.3950243528171251

Epoch: 6| Step: 12
Training loss: 0.04550362378358841
Validation loss: 1.4286677029825026

Epoch: 6| Step: 13
Training loss: 0.03532347083091736
Validation loss: 1.4445687852880007

Epoch: 693| Step: 0
Training loss: 0.023511480540037155
Validation loss: 1.4326806734966975

Epoch: 6| Step: 1
Training loss: 0.059500157833099365
Validation loss: 1.4169446883663055

Epoch: 6| Step: 2
Training loss: 0.058536939322948456
Validation loss: 1.409258242576353

Epoch: 6| Step: 3
Training loss: 0.06261035799980164
Validation loss: 1.4053335356455978

Epoch: 6| Step: 4
Training loss: 0.05413571000099182
Validation loss: 1.4092786055739208

Epoch: 6| Step: 5
Training loss: 0.0634220615029335
Validation loss: 1.3961215019226074

Epoch: 6| Step: 6
Training loss: 0.07630904763936996
Validation loss: 1.3863105373356932

Epoch: 6| Step: 7
Training loss: 0.055092837661504745
Validation loss: 1.398053370496278

Epoch: 6| Step: 8
Training loss: 0.05602516978979111
Validation loss: 1.4092098397593344

Epoch: 6| Step: 9
Training loss: 0.0649389699101448
Validation loss: 1.4076782811072566

Epoch: 6| Step: 10
Training loss: 0.046325646340847015
Validation loss: 1.4165888204369494

Epoch: 6| Step: 11
Training loss: 0.02959807962179184
Validation loss: 1.4457600309002785

Epoch: 6| Step: 12
Training loss: 0.06936444342136383
Validation loss: 1.4539651922000352

Epoch: 6| Step: 13
Training loss: 0.06693974137306213
Validation loss: 1.458678618554146

Epoch: 694| Step: 0
Training loss: 0.04001765698194504
Validation loss: 1.4957642427054785

Epoch: 6| Step: 1
Training loss: 0.04965189844369888
Validation loss: 1.4714990969627135

Epoch: 6| Step: 2
Training loss: 0.05915207788348198
Validation loss: 1.521527591572013

Epoch: 6| Step: 3
Training loss: 0.08002856373786926
Validation loss: 1.5228792634061588

Epoch: 6| Step: 4
Training loss: 0.05863720178604126
Validation loss: 1.501303449753792

Epoch: 6| Step: 5
Training loss: 0.0613417811691761
Validation loss: 1.5015063939556

Epoch: 6| Step: 6
Training loss: 0.06453922390937805
Validation loss: 1.5131196975708008

Epoch: 6| Step: 7
Training loss: 0.05129033327102661
Validation loss: 1.4705018920283164

Epoch: 6| Step: 8
Training loss: 0.04892289638519287
Validation loss: 1.4817198066301243

Epoch: 6| Step: 9
Training loss: 0.07024239748716354
Validation loss: 1.469255470460461

Epoch: 6| Step: 10
Training loss: 0.05767492949962616
Validation loss: 1.4523319967331425

Epoch: 6| Step: 11
Training loss: 0.0698695108294487
Validation loss: 1.4446209143566828

Epoch: 6| Step: 12
Training loss: 0.03588742017745972
Validation loss: 1.4373029149988645

Epoch: 6| Step: 13
Training loss: 0.036149583756923676
Validation loss: 1.4160558869761806

Epoch: 695| Step: 0
Training loss: 0.03597602993249893
Validation loss: 1.4019127250999532

Epoch: 6| Step: 1
Training loss: 0.027355821803212166
Validation loss: 1.409212145754086

Epoch: 6| Step: 2
Training loss: 0.06463758647441864
Validation loss: 1.399930086187137

Epoch: 6| Step: 3
Training loss: 0.06949105858802795
Validation loss: 1.4064492525592927

Epoch: 6| Step: 4
Training loss: 0.05824830010533333
Validation loss: 1.3980127573013306

Epoch: 6| Step: 5
Training loss: 0.07647979259490967
Validation loss: 1.3849963513753747

Epoch: 6| Step: 6
Training loss: 0.055610865354537964
Validation loss: 1.3873405738543438

Epoch: 6| Step: 7
Training loss: 0.05822579562664032
Validation loss: 1.3672485325926094

Epoch: 6| Step: 8
Training loss: 0.06762544810771942
Validation loss: 1.369079541134578

Epoch: 6| Step: 9
Training loss: 0.0547686330974102
Validation loss: 1.3819280433398422

Epoch: 6| Step: 10
Training loss: 0.0552440881729126
Validation loss: 1.4101324594149025

Epoch: 6| Step: 11
Training loss: 0.04671085625886917
Validation loss: 1.3929069554933937

Epoch: 6| Step: 12
Training loss: 0.03844865784049034
Validation loss: 1.4265954212475849

Epoch: 6| Step: 13
Training loss: 0.056364696472883224
Validation loss: 1.4202158258807274

Epoch: 696| Step: 0
Training loss: 0.04892078414559364
Validation loss: 1.4282140526720273

Epoch: 6| Step: 1
Training loss: 0.06775817275047302
Validation loss: 1.444423097436146

Epoch: 6| Step: 2
Training loss: 0.08872741460800171
Validation loss: 1.4593774291776842

Epoch: 6| Step: 3
Training loss: 0.033416446298360825
Validation loss: 1.45334945378765

Epoch: 6| Step: 4
Training loss: 0.05846710503101349
Validation loss: 1.459226546748992

Epoch: 6| Step: 5
Training loss: 0.04224449396133423
Validation loss: 1.4601446338879165

Epoch: 6| Step: 6
Training loss: 0.07287809252738953
Validation loss: 1.4542340924662929

Epoch: 6| Step: 7
Training loss: 0.05678243190050125
Validation loss: 1.4485411676027442

Epoch: 6| Step: 8
Training loss: 0.07423394173383713
Validation loss: 1.4163649428275324

Epoch: 6| Step: 9
Training loss: 0.04208320379257202
Validation loss: 1.4314414788317937

Epoch: 6| Step: 10
Training loss: 0.08529850840568542
Validation loss: 1.4043167880786362

Epoch: 6| Step: 11
Training loss: 0.07972145080566406
Validation loss: 1.3905336356932116

Epoch: 6| Step: 12
Training loss: 0.04392731934785843
Validation loss: 1.4169588409444338

Epoch: 6| Step: 13
Training loss: 0.05399274826049805
Validation loss: 1.4095072348912556

Epoch: 697| Step: 0
Training loss: 0.052876852452754974
Validation loss: 1.3889106242887435

Epoch: 6| Step: 1
Training loss: 0.04328889399766922
Validation loss: 1.411837645756301

Epoch: 6| Step: 2
Training loss: 0.061857543885707855
Validation loss: 1.4229001716900898

Epoch: 6| Step: 3
Training loss: 0.05203085392713547
Validation loss: 1.4139621052690732

Epoch: 6| Step: 4
Training loss: 0.10007771849632263
Validation loss: 1.4550521732658468

Epoch: 6| Step: 5
Training loss: 0.04647652804851532
Validation loss: 1.4471580751480595

Epoch: 6| Step: 6
Training loss: 0.0728578045964241
Validation loss: 1.4404964677749141

Epoch: 6| Step: 7
Training loss: 0.051537301391363144
Validation loss: 1.4423896369113718

Epoch: 6| Step: 8
Training loss: 0.06536173820495605
Validation loss: 1.439731159517842

Epoch: 6| Step: 9
Training loss: 0.051777184009552
Validation loss: 1.437864730435033

Epoch: 6| Step: 10
Training loss: 0.0380287729203701
Validation loss: 1.4090437696826073

Epoch: 6| Step: 11
Training loss: 0.0664186179637909
Validation loss: 1.4006478658286474

Epoch: 6| Step: 12
Training loss: 0.08126887679100037
Validation loss: 1.392026408385205

Epoch: 6| Step: 13
Training loss: 0.08535182476043701
Validation loss: 1.391931027494451

Epoch: 698| Step: 0
Training loss: 0.0483500137925148
Validation loss: 1.3799238768956994

Epoch: 6| Step: 1
Training loss: 0.053498271852731705
Validation loss: 1.3934799381481704

Epoch: 6| Step: 2
Training loss: 0.08069376647472382
Validation loss: 1.3836490992576844

Epoch: 6| Step: 3
Training loss: 0.07407110929489136
Validation loss: 1.3764001771967898

Epoch: 6| Step: 4
Training loss: 0.07424724102020264
Validation loss: 1.3916921141327068

Epoch: 6| Step: 5
Training loss: 0.07776522636413574
Validation loss: 1.3944849237318961

Epoch: 6| Step: 6
Training loss: 0.05509151145815849
Validation loss: 1.3959065130961839

Epoch: 6| Step: 7
Training loss: 0.06248738616704941
Validation loss: 1.4149971597938127

Epoch: 6| Step: 8
Training loss: 0.03888527303934097
Validation loss: 1.410595456759135

Epoch: 6| Step: 9
Training loss: 0.06210419163107872
Validation loss: 1.4032309619329308

Epoch: 6| Step: 10
Training loss: 0.04735244810581207
Validation loss: 1.4097265607567244

Epoch: 6| Step: 11
Training loss: 0.039415039122104645
Validation loss: 1.4056836905017975

Epoch: 6| Step: 12
Training loss: 0.047391653060913086
Validation loss: 1.3928146593032344

Epoch: 6| Step: 13
Training loss: 0.0565187931060791
Validation loss: 1.4095679854833951

Epoch: 699| Step: 0
Training loss: 0.05176359415054321
Validation loss: 1.3975366315534037

Epoch: 6| Step: 1
Training loss: 0.05337017774581909
Validation loss: 1.4106734016890168

Epoch: 6| Step: 2
Training loss: 0.04484957456588745
Validation loss: 1.3911138183327132

Epoch: 6| Step: 3
Training loss: 0.052145883440971375
Validation loss: 1.390259733443619

Epoch: 6| Step: 4
Training loss: 0.03351322561502457
Validation loss: 1.402280044812028

Epoch: 6| Step: 5
Training loss: 0.06634007394313812
Validation loss: 1.4079767388682212

Epoch: 6| Step: 6
Training loss: 0.0953017845749855
Validation loss: 1.4193198962878155

Epoch: 6| Step: 7
Training loss: 0.04439987987279892
Validation loss: 1.4244639553049558

Epoch: 6| Step: 8
Training loss: 0.0781625509262085
Validation loss: 1.4414557564643122

Epoch: 6| Step: 9
Training loss: 0.0574127659201622
Validation loss: 1.4365352148650794

Epoch: 6| Step: 10
Training loss: 0.04484599083662033
Validation loss: 1.4228067513435119

Epoch: 6| Step: 11
Training loss: 0.07209494709968567
Validation loss: 1.4294462255252305

Epoch: 6| Step: 12
Training loss: 0.0581938736140728
Validation loss: 1.4263550325106549

Epoch: 6| Step: 13
Training loss: 0.03379255160689354
Validation loss: 1.4405486481164091

Epoch: 700| Step: 0
Training loss: 0.05017876625061035
Validation loss: 1.458914372228807

Epoch: 6| Step: 1
Training loss: 0.0866076648235321
Validation loss: 1.4371043456498014

Epoch: 6| Step: 2
Training loss: 0.07674026489257812
Validation loss: 1.4312655041294713

Epoch: 6| Step: 3
Training loss: 0.04419314116239548
Validation loss: 1.4520496251762554

Epoch: 6| Step: 4
Training loss: 0.07530313730239868
Validation loss: 1.4590897239664549

Epoch: 6| Step: 5
Training loss: 0.052991922944784164
Validation loss: 1.4632599071789814

Epoch: 6| Step: 6
Training loss: 0.04921329766511917
Validation loss: 1.4646388074403167

Epoch: 6| Step: 7
Training loss: 0.03831300884485245
Validation loss: 1.4768393578067902

Epoch: 6| Step: 8
Training loss: 0.0525256022810936
Validation loss: 1.4651749146881925

Epoch: 6| Step: 9
Training loss: 0.05887584388256073
Validation loss: 1.460276497307644

Epoch: 6| Step: 10
Training loss: 0.06847508251667023
Validation loss: 1.4377848935383621

Epoch: 6| Step: 11
Training loss: 0.07611995935440063
Validation loss: 1.4095828738263858

Epoch: 6| Step: 12
Training loss: 0.0490599051117897
Validation loss: 1.4219810763994853

Epoch: 6| Step: 13
Training loss: 0.038143888115882874
Validation loss: 1.4028320158681562

Testing loss: 2.239103142420451
