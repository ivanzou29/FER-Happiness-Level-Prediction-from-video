Epoch: 1| Step: 0
Training loss: 4.251826286315918
Validation loss: 5.244680245717366

Epoch: 6| Step: 1
Training loss: 4.779815673828125
Validation loss: 5.215384093664026

Epoch: 6| Step: 2
Training loss: 3.2810051441192627
Validation loss: 5.185959005868563

Epoch: 6| Step: 3
Training loss: 5.71184778213501
Validation loss: 5.153724516591718

Epoch: 6| Step: 4
Training loss: 2.906090497970581
Validation loss: 5.116424078582435

Epoch: 6| Step: 5
Training loss: 6.1687517166137695
Validation loss: 5.074593497860816

Epoch: 6| Step: 6
Training loss: 4.094968795776367
Validation loss: 5.027426355628557

Epoch: 6| Step: 7
Training loss: 5.22755241394043
Validation loss: 4.97449283189671

Epoch: 6| Step: 8
Training loss: 4.78861141204834
Validation loss: 4.916654925192556

Epoch: 6| Step: 9
Training loss: 4.868261337280273
Validation loss: 4.854594440870388

Epoch: 6| Step: 10
Training loss: 6.263637542724609
Validation loss: 4.787518675609301

Epoch: 6| Step: 11
Training loss: 4.68840217590332
Validation loss: 4.71867872053577

Epoch: 6| Step: 12
Training loss: 4.381153106689453
Validation loss: 4.64892259208105

Epoch: 6| Step: 13
Training loss: 5.536253929138184
Validation loss: 4.578370145572129

Epoch: 2| Step: 0
Training loss: 4.934932231903076
Validation loss: 4.507227072151759

Epoch: 6| Step: 1
Training loss: 5.201673984527588
Validation loss: 4.436956744040212

Epoch: 6| Step: 2
Training loss: 5.044412136077881
Validation loss: 4.364162962923768

Epoch: 6| Step: 3
Training loss: 4.847778797149658
Validation loss: 4.291927783719955

Epoch: 6| Step: 4
Training loss: 2.8973817825317383
Validation loss: 4.218259729364867

Epoch: 6| Step: 5
Training loss: 4.025667190551758
Validation loss: 4.143747468148509

Epoch: 6| Step: 6
Training loss: 4.341677665710449
Validation loss: 4.073524636607016

Epoch: 6| Step: 7
Training loss: 3.275923252105713
Validation loss: 4.003459551001108

Epoch: 6| Step: 8
Training loss: 3.3681869506835938
Validation loss: 3.9417475526050856

Epoch: 6| Step: 9
Training loss: 3.4970695972442627
Validation loss: 3.887727916881602

Epoch: 6| Step: 10
Training loss: 3.7611379623413086
Validation loss: 3.836297132635629

Epoch: 6| Step: 11
Training loss: 4.275054931640625
Validation loss: 3.786308119373937

Epoch: 6| Step: 12
Training loss: 2.495147705078125
Validation loss: 3.740055919975363

Epoch: 6| Step: 13
Training loss: 2.222564220428467
Validation loss: 3.7007356946186354

Epoch: 3| Step: 0
Training loss: 2.4502367973327637
Validation loss: 3.6644049357342463

Epoch: 6| Step: 1
Training loss: 3.6487677097320557
Validation loss: 3.633938599658269

Epoch: 6| Step: 2
Training loss: 4.351271629333496
Validation loss: 3.6042621648439797

Epoch: 6| Step: 3
Training loss: 3.270998477935791
Validation loss: 3.5788479722956175

Epoch: 6| Step: 4
Training loss: 3.9485740661621094
Validation loss: 3.554154888276131

Epoch: 6| Step: 5
Training loss: 3.242650032043457
Validation loss: 3.5272350260006484

Epoch: 6| Step: 6
Training loss: 2.877821207046509
Validation loss: 3.5097399219389884

Epoch: 6| Step: 7
Training loss: 4.371118545532227
Validation loss: 3.49223187405576

Epoch: 6| Step: 8
Training loss: 2.9308221340179443
Validation loss: 3.4756080437732

Epoch: 6| Step: 9
Training loss: 3.708218812942505
Validation loss: 3.4577245712280273

Epoch: 6| Step: 10
Training loss: 4.479101181030273
Validation loss: 3.441993313450967

Epoch: 6| Step: 11
Training loss: 2.2257041931152344
Validation loss: 3.4166000555920344

Epoch: 6| Step: 12
Training loss: 3.3544082641601562
Validation loss: 3.4003623967529624

Epoch: 6| Step: 13
Training loss: 3.6609103679656982
Validation loss: 3.3818766301678074

Epoch: 4| Step: 0
Training loss: 2.20392107963562
Validation loss: 3.366479476292928

Epoch: 6| Step: 1
Training loss: 3.8376104831695557
Validation loss: 3.3530431357763146

Epoch: 6| Step: 2
Training loss: 4.23189640045166
Validation loss: 3.3356456525864138

Epoch: 6| Step: 3
Training loss: 3.78220534324646
Validation loss: 3.3177409966786704

Epoch: 6| Step: 4
Training loss: 2.572495460510254
Validation loss: 3.299383158324867

Epoch: 6| Step: 5
Training loss: 2.3092756271362305
Validation loss: 3.2805541971678376

Epoch: 6| Step: 6
Training loss: 2.277876377105713
Validation loss: 3.2673450439207015

Epoch: 6| Step: 7
Training loss: 4.2089362144470215
Validation loss: 3.251989382569508

Epoch: 6| Step: 8
Training loss: 2.8488192558288574
Validation loss: 3.2409007728740735

Epoch: 6| Step: 9
Training loss: 3.156810998916626
Validation loss: 3.225009749012609

Epoch: 6| Step: 10
Training loss: 5.002630233764648
Validation loss: 3.211363705255652

Epoch: 6| Step: 11
Training loss: 2.943936824798584
Validation loss: 3.20137010851214

Epoch: 6| Step: 12
Training loss: 3.5686697959899902
Validation loss: 3.1892780078354703

Epoch: 6| Step: 13
Training loss: 1.959758996963501
Validation loss: 3.179662163539599

Epoch: 5| Step: 0
Training loss: 2.2823939323425293
Validation loss: 3.1664274866862963

Epoch: 6| Step: 1
Training loss: 3.4014410972595215
Validation loss: 3.1573995646610054

Epoch: 6| Step: 2
Training loss: 2.143840789794922
Validation loss: 3.1476017480255454

Epoch: 6| Step: 3
Training loss: 2.6517319679260254
Validation loss: 3.139977006502049

Epoch: 6| Step: 4
Training loss: 2.386969566345215
Validation loss: 3.1267681993463987

Epoch: 6| Step: 5
Training loss: 3.416463851928711
Validation loss: 3.1192449318465365

Epoch: 6| Step: 6
Training loss: 3.2789669036865234
Validation loss: 3.112144139505202

Epoch: 6| Step: 7
Training loss: 3.2414188385009766
Validation loss: 3.09682209004638

Epoch: 6| Step: 8
Training loss: 4.375278472900391
Validation loss: 3.0841709311290453

Epoch: 6| Step: 9
Training loss: 3.2527337074279785
Validation loss: 3.0714734395345054

Epoch: 6| Step: 10
Training loss: 3.2897000312805176
Validation loss: 3.0557671695627193

Epoch: 6| Step: 11
Training loss: 3.7576262950897217
Validation loss: 3.0476933448545394

Epoch: 6| Step: 12
Training loss: 3.622023344039917
Validation loss: 3.0376559636926137

Epoch: 6| Step: 13
Training loss: 2.370465040206909
Validation loss: 3.0355330308278403

Epoch: 6| Step: 0
Training loss: 2.8624930381774902
Validation loss: 3.037093677828389

Epoch: 6| Step: 1
Training loss: 2.5465664863586426
Validation loss: 3.017479519690237

Epoch: 6| Step: 2
Training loss: 2.9610557556152344
Validation loss: 3.009415139434158

Epoch: 6| Step: 3
Training loss: 2.7747764587402344
Validation loss: 3.0036372548790387

Epoch: 6| Step: 4
Training loss: 3.3442587852478027
Validation loss: 2.9951228454548824

Epoch: 6| Step: 5
Training loss: 3.2477874755859375
Validation loss: 2.987062300405195

Epoch: 6| Step: 6
Training loss: 2.335620880126953
Validation loss: 2.9832454060995452

Epoch: 6| Step: 7
Training loss: 3.5833582878112793
Validation loss: 2.9764815171559653

Epoch: 6| Step: 8
Training loss: 3.289318561553955
Validation loss: 2.9680773365882134

Epoch: 6| Step: 9
Training loss: 3.4499082565307617
Validation loss: 2.9623128701281805

Epoch: 6| Step: 10
Training loss: 3.974551200866699
Validation loss: 2.954617525941582

Epoch: 6| Step: 11
Training loss: 3.7182180881500244
Validation loss: 2.949146545061501

Epoch: 6| Step: 12
Training loss: 2.080744981765747
Validation loss: 2.9385321524835404

Epoch: 6| Step: 13
Training loss: 2.214293956756592
Validation loss: 2.933212254637031

Epoch: 7| Step: 0
Training loss: 3.531733512878418
Validation loss: 2.92593095379491

Epoch: 6| Step: 1
Training loss: 2.693807601928711
Validation loss: 2.9228530853025374

Epoch: 6| Step: 2
Training loss: 3.01926851272583
Validation loss: 2.9228860229574223

Epoch: 6| Step: 3
Training loss: 2.9960803985595703
Validation loss: 2.9209711372211413

Epoch: 6| Step: 4
Training loss: 3.991976022720337
Validation loss: 2.9465957533928657

Epoch: 6| Step: 5
Training loss: 3.457944393157959
Validation loss: 2.9068939301275436

Epoch: 6| Step: 6
Training loss: 2.119083881378174
Validation loss: 2.9330492737472698

Epoch: 6| Step: 7
Training loss: 3.178018808364868
Validation loss: 2.9632916347954863

Epoch: 6| Step: 8
Training loss: 3.6729774475097656
Validation loss: 2.963929445512833

Epoch: 6| Step: 9
Training loss: 2.38344407081604
Validation loss: 2.9207819405422417

Epoch: 6| Step: 10
Training loss: 3.1672284603118896
Validation loss: 2.9061355667729534

Epoch: 6| Step: 11
Training loss: 1.8272478580474854
Validation loss: 2.906032964747439

Epoch: 6| Step: 12
Training loss: 3.3254776000976562
Validation loss: 2.917039725088304

Epoch: 6| Step: 13
Training loss: 2.830416679382324
Validation loss: 2.9254679961871077

Epoch: 8| Step: 0
Training loss: 1.9661540985107422
Validation loss: 2.9345332422564105

Epoch: 6| Step: 1
Training loss: 2.1426842212677
Validation loss: 2.9383161144871868

Epoch: 6| Step: 2
Training loss: 4.171844482421875
Validation loss: 2.9137746236657582

Epoch: 6| Step: 3
Training loss: 3.104618549346924
Validation loss: 2.8928049969416794

Epoch: 6| Step: 4
Training loss: 3.2347617149353027
Validation loss: 2.880655224605273

Epoch: 6| Step: 5
Training loss: 2.439533233642578
Validation loss: 2.8743719003533803

Epoch: 6| Step: 6
Training loss: 3.4081220626831055
Validation loss: 2.8720799594797115

Epoch: 6| Step: 7
Training loss: 2.546607732772827
Validation loss: 2.86916511289535

Epoch: 6| Step: 8
Training loss: 1.8532871007919312
Validation loss: 2.8724965844103085

Epoch: 6| Step: 9
Training loss: 3.742035150527954
Validation loss: 2.880191039013606

Epoch: 6| Step: 10
Training loss: 2.9348678588867188
Validation loss: 2.870446697358162

Epoch: 6| Step: 11
Training loss: 3.111926794052124
Validation loss: 2.851850212261241

Epoch: 6| Step: 12
Training loss: 4.01963472366333
Validation loss: 2.8360642105020504

Epoch: 6| Step: 13
Training loss: 3.2199227809906006
Validation loss: 2.8252453445106425

Epoch: 9| Step: 0
Training loss: 2.2057290077209473
Validation loss: 2.8249934104181107

Epoch: 6| Step: 1
Training loss: 2.6119375228881836
Validation loss: 2.8213243381951445

Epoch: 6| Step: 2
Training loss: 2.0863633155822754
Validation loss: 2.825041914498934

Epoch: 6| Step: 3
Training loss: 3.1693408489227295
Validation loss: 2.82225122246691

Epoch: 6| Step: 4
Training loss: 3.1465511322021484
Validation loss: 2.828665074481759

Epoch: 6| Step: 5
Training loss: 2.584718704223633
Validation loss: 2.829289613231536

Epoch: 6| Step: 6
Training loss: 3.5189554691314697
Validation loss: 2.8163376213401876

Epoch: 6| Step: 7
Training loss: 2.848557233810425
Validation loss: 2.7970615561290453

Epoch: 6| Step: 8
Training loss: 3.636608600616455
Validation loss: 2.7857170899709067

Epoch: 6| Step: 9
Training loss: 3.1199188232421875
Validation loss: 2.773806425832933

Epoch: 6| Step: 10
Training loss: 3.3660497665405273
Validation loss: 2.7683717743042977

Epoch: 6| Step: 11
Training loss: 2.987994432449341
Validation loss: 2.767927369763774

Epoch: 6| Step: 12
Training loss: 2.7754812240600586
Validation loss: 2.770311901646276

Epoch: 6| Step: 13
Training loss: 2.9585814476013184
Validation loss: 2.769359293804374

Epoch: 10| Step: 0
Training loss: 2.2886431217193604
Validation loss: 2.7608395314985708

Epoch: 6| Step: 1
Training loss: 3.6745760440826416
Validation loss: 2.7566471740763676

Epoch: 6| Step: 2
Training loss: 2.8850765228271484
Validation loss: 2.742760101954142

Epoch: 6| Step: 3
Training loss: 4.256418228149414
Validation loss: 2.7325543767662457

Epoch: 6| Step: 4
Training loss: 1.7793687582015991
Validation loss: 2.7252764240387948

Epoch: 6| Step: 5
Training loss: 2.3931198120117188
Validation loss: 2.7229384863248436

Epoch: 6| Step: 6
Training loss: 2.70745849609375
Validation loss: 2.7229359201205674

Epoch: 6| Step: 7
Training loss: 2.8531484603881836
Validation loss: 2.727798064549764

Epoch: 6| Step: 8
Training loss: 2.3529701232910156
Validation loss: 2.7298455674161195

Epoch: 6| Step: 9
Training loss: 2.973916530609131
Validation loss: 2.728266475021198

Epoch: 6| Step: 10
Training loss: 3.8029837608337402
Validation loss: 2.728292801046884

Epoch: 6| Step: 11
Training loss: 2.5823211669921875
Validation loss: 2.714198991816531

Epoch: 6| Step: 12
Training loss: 3.103473663330078
Validation loss: 2.7043865983204176

Epoch: 6| Step: 13
Training loss: 2.6701500415802
Validation loss: 2.696181745939357

Epoch: 11| Step: 0
Training loss: 2.979389190673828
Validation loss: 2.6909594100008727

Epoch: 6| Step: 1
Training loss: 2.1113133430480957
Validation loss: 2.6870040432099374

Epoch: 6| Step: 2
Training loss: 1.9208768606185913
Validation loss: 2.69205399738845

Epoch: 6| Step: 3
Training loss: 2.8168981075286865
Validation loss: 2.694464275913854

Epoch: 6| Step: 4
Training loss: 3.158360004425049
Validation loss: 2.6882681462072555

Epoch: 6| Step: 5
Training loss: 3.0470190048217773
Validation loss: 2.679993857619583

Epoch: 6| Step: 6
Training loss: 3.6123206615448
Validation loss: 2.6741330162171395

Epoch: 6| Step: 7
Training loss: 2.7889575958251953
Validation loss: 2.6678762384640273

Epoch: 6| Step: 8
Training loss: 2.7064425945281982
Validation loss: 2.662294569835868

Epoch: 6| Step: 9
Training loss: 3.052028179168701
Validation loss: 2.6615392443954304

Epoch: 6| Step: 10
Training loss: 2.4857285022735596
Validation loss: 2.6583183324465187

Epoch: 6| Step: 11
Training loss: 2.7052478790283203
Validation loss: 2.6766091341613443

Epoch: 6| Step: 12
Training loss: 2.9913032054901123
Validation loss: 2.657575417590398

Epoch: 6| Step: 13
Training loss: 4.043811321258545
Validation loss: 2.6576638837014475

Epoch: 12| Step: 0
Training loss: 3.3198318481445312
Validation loss: 2.652105180166101

Epoch: 6| Step: 1
Training loss: 2.7444190979003906
Validation loss: 2.6541544750172603

Epoch: 6| Step: 2
Training loss: 3.1629536151885986
Validation loss: 2.6527785383244997

Epoch: 6| Step: 3
Training loss: 2.959177017211914
Validation loss: 2.652963835705993

Epoch: 6| Step: 4
Training loss: 3.012678623199463
Validation loss: 2.6523910824970534

Epoch: 6| Step: 5
Training loss: 2.250319480895996
Validation loss: 2.64888031764697

Epoch: 6| Step: 6
Training loss: 2.6161608695983887
Validation loss: 2.646023235013408

Epoch: 6| Step: 7
Training loss: 3.2753701210021973
Validation loss: 2.647127354016868

Epoch: 6| Step: 8
Training loss: 2.442200183868408
Validation loss: 2.6549162582684587

Epoch: 6| Step: 9
Training loss: 2.671333074569702
Validation loss: 2.654065680760209

Epoch: 6| Step: 10
Training loss: 2.7722997665405273
Validation loss: 2.6434084471835884

Epoch: 6| Step: 11
Training loss: 2.5602965354919434
Validation loss: 2.63343378548981

Epoch: 6| Step: 12
Training loss: 2.8940248489379883
Validation loss: 2.628457377033849

Epoch: 6| Step: 13
Training loss: 3.1196675300598145
Validation loss: 2.6281421748540734

Epoch: 13| Step: 0
Training loss: 3.061363697052002
Validation loss: 2.6245062658863683

Epoch: 6| Step: 1
Training loss: 3.373859167098999
Validation loss: 2.619497101794007

Epoch: 6| Step: 2
Training loss: 2.114269733428955
Validation loss: 2.6146487933333202

Epoch: 6| Step: 3
Training loss: 3.253828525543213
Validation loss: 2.6122251838766117

Epoch: 6| Step: 4
Training loss: 3.0569281578063965
Validation loss: 2.6204349225567234

Epoch: 6| Step: 5
Training loss: 2.6413626670837402
Validation loss: 2.626853427579326

Epoch: 6| Step: 6
Training loss: 3.27494740486145
Validation loss: 2.613400464416832

Epoch: 6| Step: 7
Training loss: 3.253528118133545
Validation loss: 2.6033944314525974

Epoch: 6| Step: 8
Training loss: 2.076749801635742
Validation loss: 2.5958256336950485

Epoch: 6| Step: 9
Training loss: 3.046215534210205
Validation loss: 2.59633832593118

Epoch: 6| Step: 10
Training loss: 2.1024129390716553
Validation loss: 2.6011729855691232

Epoch: 6| Step: 11
Training loss: 3.0274786949157715
Validation loss: 2.605926323962468

Epoch: 6| Step: 12
Training loss: 2.368929624557495
Validation loss: 2.6051665262509416

Epoch: 6| Step: 13
Training loss: 2.6084177494049072
Validation loss: 2.5966692688644573

Epoch: 14| Step: 0
Training loss: 2.6695733070373535
Validation loss: 2.588480741746964

Epoch: 6| Step: 1
Training loss: 2.6497840881347656
Validation loss: 2.583485008567892

Epoch: 6| Step: 2
Training loss: 2.5911388397216797
Validation loss: 2.5818309553207888

Epoch: 6| Step: 3
Training loss: 2.866298198699951
Validation loss: 2.597941352475074

Epoch: 6| Step: 4
Training loss: 3.27640962600708
Validation loss: 2.599851264748522

Epoch: 6| Step: 5
Training loss: 2.206045627593994
Validation loss: 2.5801803373521373

Epoch: 6| Step: 6
Training loss: 3.2031302452087402
Validation loss: 2.582137164249215

Epoch: 6| Step: 7
Training loss: 1.7776449918746948
Validation loss: 2.578923407421317

Epoch: 6| Step: 8
Training loss: 3.2902679443359375
Validation loss: 2.593161831619919

Epoch: 6| Step: 9
Training loss: 2.4449949264526367
Validation loss: 2.5977256862066125

Epoch: 6| Step: 10
Training loss: 2.6212432384490967
Validation loss: 2.58878344105136

Epoch: 6| Step: 11
Training loss: 2.5716605186462402
Validation loss: 2.5867957786847184

Epoch: 6| Step: 12
Training loss: 3.569876194000244
Validation loss: 2.5790428525658062

Epoch: 6| Step: 13
Training loss: 3.865461587905884
Validation loss: 2.5800236476364957

Epoch: 15| Step: 0
Training loss: 2.6763358116149902
Validation loss: 2.5747084540705525

Epoch: 6| Step: 1
Training loss: 2.587174654006958
Validation loss: 2.5695944780944497

Epoch: 6| Step: 2
Training loss: 2.847076177597046
Validation loss: 2.571400498831144

Epoch: 6| Step: 3
Training loss: 2.6956892013549805
Validation loss: 2.5797079711832027

Epoch: 6| Step: 4
Training loss: 3.2241621017456055
Validation loss: 2.5889156428716515

Epoch: 6| Step: 5
Training loss: 3.0026254653930664
Validation loss: 2.5837098885607976

Epoch: 6| Step: 6
Training loss: 2.6909165382385254
Validation loss: 2.577275150565691

Epoch: 6| Step: 7
Training loss: 3.437711715698242
Validation loss: 2.572701184980331

Epoch: 6| Step: 8
Training loss: 2.5692923069000244
Validation loss: 2.583649384078159

Epoch: 6| Step: 9
Training loss: 2.0072309970855713
Validation loss: 2.5695127594855522

Epoch: 6| Step: 10
Training loss: 3.3808305263519287
Validation loss: 2.5639390407070035

Epoch: 6| Step: 11
Training loss: 1.9480520486831665
Validation loss: 2.55463763975328

Epoch: 6| Step: 12
Training loss: 2.7070369720458984
Validation loss: 2.5560294466633953

Epoch: 6| Step: 13
Training loss: 3.2472825050354004
Validation loss: 2.558635929579376

Epoch: 16| Step: 0
Training loss: 3.2319540977478027
Validation loss: 2.5653534820002895

Epoch: 6| Step: 1
Training loss: 2.271716833114624
Validation loss: 2.5640548121544624

Epoch: 6| Step: 2
Training loss: 2.3709211349487305
Validation loss: 2.5647499612582627

Epoch: 6| Step: 3
Training loss: 3.2448554039001465
Validation loss: 2.567151020931941

Epoch: 6| Step: 4
Training loss: 3.37641978263855
Validation loss: 2.569294270648751

Epoch: 6| Step: 5
Training loss: 2.5043301582336426
Validation loss: 2.55345501694628

Epoch: 6| Step: 6
Training loss: 2.868328094482422
Validation loss: 2.55031394702132

Epoch: 6| Step: 7
Training loss: 2.519768476486206
Validation loss: 2.5403070860011603

Epoch: 6| Step: 8
Training loss: 3.2027394771575928
Validation loss: 2.537206842053321

Epoch: 6| Step: 9
Training loss: 2.6493382453918457
Validation loss: 2.5379966535875873

Epoch: 6| Step: 10
Training loss: 2.213693618774414
Validation loss: 2.59205122147837

Epoch: 6| Step: 11
Training loss: 1.9667913913726807
Validation loss: 2.6420702242082164

Epoch: 6| Step: 12
Training loss: 3.5754244327545166
Validation loss: 2.710699091675461

Epoch: 6| Step: 13
Training loss: 3.1744296550750732
Validation loss: 2.642160059303366

Epoch: 17| Step: 0
Training loss: 2.375006675720215
Validation loss: 2.6170112548335904

Epoch: 6| Step: 1
Training loss: 3.2329061031341553
Validation loss: 2.608801946845106

Epoch: 6| Step: 2
Training loss: 3.5309879779815674
Validation loss: 2.601183122204196

Epoch: 6| Step: 3
Training loss: 4.079687118530273
Validation loss: 2.5929776109674925

Epoch: 6| Step: 4
Training loss: 2.5879645347595215
Validation loss: 2.59053793004764

Epoch: 6| Step: 5
Training loss: 2.2735180854797363
Validation loss: 2.5823908877629105

Epoch: 6| Step: 6
Training loss: 3.072450637817383
Validation loss: 2.586168989058464

Epoch: 6| Step: 7
Training loss: 1.6546415090560913
Validation loss: 2.581970517353345

Epoch: 6| Step: 8
Training loss: 2.6466856002807617
Validation loss: 2.571167856134394

Epoch: 6| Step: 9
Training loss: 3.134976863861084
Validation loss: 2.5885679157831336

Epoch: 6| Step: 10
Training loss: 2.3698997497558594
Validation loss: 2.568725862810689

Epoch: 6| Step: 11
Training loss: 2.941748857498169
Validation loss: 2.5391834282105967

Epoch: 6| Step: 12
Training loss: 2.2548460960388184
Validation loss: 2.5400567695658696

Epoch: 6| Step: 13
Training loss: 3.06581974029541
Validation loss: 2.5531965250610025

Epoch: 18| Step: 0
Training loss: 2.7840847969055176
Validation loss: 2.5757171338604343

Epoch: 6| Step: 1
Training loss: 2.818678379058838
Validation loss: 2.6043732858473256

Epoch: 6| Step: 2
Training loss: 2.7905468940734863
Validation loss: 2.5383420605813303

Epoch: 6| Step: 3
Training loss: 2.8685531616210938
Validation loss: 2.5148802688044887

Epoch: 6| Step: 4
Training loss: 3.343522310256958
Validation loss: 2.511374476135418

Epoch: 6| Step: 5
Training loss: 2.3349833488464355
Validation loss: 2.5243481000264487

Epoch: 6| Step: 6
Training loss: 2.549543857574463
Validation loss: 2.557469896090928

Epoch: 6| Step: 7
Training loss: 2.1006922721862793
Validation loss: 2.560616490661457

Epoch: 6| Step: 8
Training loss: 2.7840423583984375
Validation loss: 2.551085102942682

Epoch: 6| Step: 9
Training loss: 4.023418426513672
Validation loss: 2.547651647239603

Epoch: 6| Step: 10
Training loss: 2.996666193008423
Validation loss: 2.53085756814608

Epoch: 6| Step: 11
Training loss: 1.8752460479736328
Validation loss: 2.522198059225595

Epoch: 6| Step: 12
Training loss: 2.768547773361206
Validation loss: 2.5157205802138134

Epoch: 6| Step: 13
Training loss: 2.364436149597168
Validation loss: 2.5132618975895706

Epoch: 19| Step: 0
Training loss: 2.452313184738159
Validation loss: 2.5157592194054716

Epoch: 6| Step: 1
Training loss: 3.004491090774536
Validation loss: 2.5104884486044607

Epoch: 6| Step: 2
Training loss: 3.0722317695617676
Validation loss: 2.520378981867144

Epoch: 6| Step: 3
Training loss: 2.5630359649658203
Validation loss: 2.5233401636923514

Epoch: 6| Step: 4
Training loss: 2.3996388912200928
Validation loss: 2.5291107059806905

Epoch: 6| Step: 5
Training loss: 2.803068161010742
Validation loss: 2.532915061519992

Epoch: 6| Step: 6
Training loss: 2.6862950325012207
Validation loss: 2.524860164170624

Epoch: 6| Step: 7
Training loss: 2.4599695205688477
Validation loss: 2.5065475689467562

Epoch: 6| Step: 8
Training loss: 2.6311068534851074
Validation loss: 2.499319589266213

Epoch: 6| Step: 9
Training loss: 2.710226058959961
Validation loss: 2.497457763200165

Epoch: 6| Step: 10
Training loss: 2.939490795135498
Validation loss: 2.498393431786568

Epoch: 6| Step: 11
Training loss: 1.7034307718276978
Validation loss: 2.500660965519567

Epoch: 6| Step: 12
Training loss: 3.962702989578247
Validation loss: 2.5055885186759372

Epoch: 6| Step: 13
Training loss: 2.8611574172973633
Validation loss: 2.5048230181458178

Epoch: 20| Step: 0
Training loss: 2.358053684234619
Validation loss: 2.510008176167806

Epoch: 6| Step: 1
Training loss: 2.1992979049682617
Validation loss: 2.5132589852938088

Epoch: 6| Step: 2
Training loss: 2.849050283432007
Validation loss: 2.50993606352037

Epoch: 6| Step: 3
Training loss: 3.303452491760254
Validation loss: 2.506586910575949

Epoch: 6| Step: 4
Training loss: 2.1819188594818115
Validation loss: 2.5085559096387637

Epoch: 6| Step: 5
Training loss: 2.2836544513702393
Validation loss: 2.507204435204947

Epoch: 6| Step: 6
Training loss: 3.092944622039795
Validation loss: 2.5134582263167187

Epoch: 6| Step: 7
Training loss: 3.3631200790405273
Validation loss: 2.534685227178758

Epoch: 6| Step: 8
Training loss: 2.909973621368408
Validation loss: 2.53576946514909

Epoch: 6| Step: 9
Training loss: 3.1394243240356445
Validation loss: 2.5168817607305383

Epoch: 6| Step: 10
Training loss: 2.471825122833252
Validation loss: 2.4990154671412643

Epoch: 6| Step: 11
Training loss: 2.829249858856201
Validation loss: 2.4802859444772043

Epoch: 6| Step: 12
Training loss: 2.4018821716308594
Validation loss: 2.480742205855667

Epoch: 6| Step: 13
Training loss: 2.550839424133301
Validation loss: 2.491685414826998

Epoch: 21| Step: 0
Training loss: 2.7834739685058594
Validation loss: 2.4965722150700067

Epoch: 6| Step: 1
Training loss: 2.6364030838012695
Validation loss: 2.5001319710926344

Epoch: 6| Step: 2
Training loss: 3.122042179107666
Validation loss: 2.494717832534544

Epoch: 6| Step: 3
Training loss: 3.3072214126586914
Validation loss: 2.499457026040682

Epoch: 6| Step: 4
Training loss: 2.5267932415008545
Validation loss: 2.48648714762862

Epoch: 6| Step: 5
Training loss: 2.6320085525512695
Validation loss: 2.487558816068916

Epoch: 6| Step: 6
Training loss: 2.877568483352661
Validation loss: 2.481673126579613

Epoch: 6| Step: 7
Training loss: 2.702608346939087
Validation loss: 2.4747956414376535

Epoch: 6| Step: 8
Training loss: 2.901618480682373
Validation loss: 2.473970515753633

Epoch: 6| Step: 9
Training loss: 1.8691164255142212
Validation loss: 2.4683354336728334

Epoch: 6| Step: 10
Training loss: 2.05265474319458
Validation loss: 2.474207329493697

Epoch: 6| Step: 11
Training loss: 2.906440496444702
Validation loss: 2.48782657295145

Epoch: 6| Step: 12
Training loss: 2.575010061264038
Validation loss: 2.4946611158309446

Epoch: 6| Step: 13
Training loss: 3.447389841079712
Validation loss: 2.4909745800879692

Epoch: 22| Step: 0
Training loss: 2.270280122756958
Validation loss: 2.496490245224327

Epoch: 6| Step: 1
Training loss: 2.8630738258361816
Validation loss: 2.483373498403898

Epoch: 6| Step: 2
Training loss: 2.26411771774292
Validation loss: 2.491528098301221

Epoch: 6| Step: 3
Training loss: 2.9641199111938477
Validation loss: 2.490907848522227

Epoch: 6| Step: 4
Training loss: 2.7894725799560547
Validation loss: 2.4866746523047007

Epoch: 6| Step: 5
Training loss: 2.630807399749756
Validation loss: 2.485296997972714

Epoch: 6| Step: 6
Training loss: 3.0997090339660645
Validation loss: 2.5244445134234685

Epoch: 6| Step: 7
Training loss: 2.887472152709961
Validation loss: 2.5021822375635945

Epoch: 6| Step: 8
Training loss: 2.3149609565734863
Validation loss: 2.4875697192325386

Epoch: 6| Step: 9
Training loss: 3.0887107849121094
Validation loss: 2.478781718079762

Epoch: 6| Step: 10
Training loss: 2.2527413368225098
Validation loss: 2.4729027055924937

Epoch: 6| Step: 11
Training loss: 2.187239646911621
Validation loss: 2.4803871954641035

Epoch: 6| Step: 12
Training loss: 2.410937786102295
Validation loss: 2.475986808858892

Epoch: 6| Step: 13
Training loss: 4.371733665466309
Validation loss: 2.4734848442898003

Epoch: 23| Step: 0
Training loss: 3.5276217460632324
Validation loss: 2.4623421058859876

Epoch: 6| Step: 1
Training loss: 2.654252052307129
Validation loss: 2.4630642065437893

Epoch: 6| Step: 2
Training loss: 2.281704902648926
Validation loss: 2.46044078693595

Epoch: 6| Step: 3
Training loss: 3.4350976943969727
Validation loss: 2.4567483317467476

Epoch: 6| Step: 4
Training loss: 2.9242987632751465
Validation loss: 2.4611394892456713

Epoch: 6| Step: 5
Training loss: 1.9805195331573486
Validation loss: 2.4605665155636367

Epoch: 6| Step: 6
Training loss: 2.655670166015625
Validation loss: 2.4628050711847123

Epoch: 6| Step: 7
Training loss: 2.769221782684326
Validation loss: 2.4780566205260572

Epoch: 6| Step: 8
Training loss: 3.0343143939971924
Validation loss: 2.4889509677886963

Epoch: 6| Step: 9
Training loss: 2.471686363220215
Validation loss: 2.4915156466986543

Epoch: 6| Step: 10
Training loss: 2.5309252738952637
Validation loss: 2.4915164414272515

Epoch: 6| Step: 11
Training loss: 1.9192801713943481
Validation loss: 2.4798888262882026

Epoch: 6| Step: 12
Training loss: 3.178866386413574
Validation loss: 2.4804750206649944

Epoch: 6| Step: 13
Training loss: 1.7986125946044922
Validation loss: 2.484650058131064

Epoch: 24| Step: 0
Training loss: 3.854288101196289
Validation loss: 2.4882908687796643

Epoch: 6| Step: 1
Training loss: 3.4106032848358154
Validation loss: 2.498468127301944

Epoch: 6| Step: 2
Training loss: 3.0707950592041016
Validation loss: 2.5083470216361423

Epoch: 6| Step: 3
Training loss: 2.5724034309387207
Validation loss: 2.488255598211801

Epoch: 6| Step: 4
Training loss: 1.6500003337860107
Validation loss: 2.4814546159518662

Epoch: 6| Step: 5
Training loss: 2.138131618499756
Validation loss: 2.4622689908550632

Epoch: 6| Step: 6
Training loss: 2.314620018005371
Validation loss: 2.4604580761283956

Epoch: 6| Step: 7
Training loss: 2.663926601409912
Validation loss: 2.4695824871781054

Epoch: 6| Step: 8
Training loss: 2.7726223468780518
Validation loss: 2.4750187755912862

Epoch: 6| Step: 9
Training loss: 2.003432273864746
Validation loss: 2.459961611737487

Epoch: 6| Step: 10
Training loss: 2.5708627700805664
Validation loss: 2.4575191492675454

Epoch: 6| Step: 11
Training loss: 2.543992042541504
Validation loss: 2.452280185555899

Epoch: 6| Step: 12
Training loss: 3.473013401031494
Validation loss: 2.454368988672892

Epoch: 6| Step: 13
Training loss: 2.562643527984619
Validation loss: 2.455641044083462

Epoch: 25| Step: 0
Training loss: 2.702897310256958
Validation loss: 2.462644833390431

Epoch: 6| Step: 1
Training loss: 3.6039929389953613
Validation loss: 2.4896109924521497

Epoch: 6| Step: 2
Training loss: 3.1220812797546387
Validation loss: 2.502096470966134

Epoch: 6| Step: 3
Training loss: 1.9876384735107422
Validation loss: 2.4897761498728106

Epoch: 6| Step: 4
Training loss: 2.816708564758301
Validation loss: 2.5004182707878853

Epoch: 6| Step: 5
Training loss: 2.829204797744751
Validation loss: 2.4800997523851294

Epoch: 6| Step: 6
Training loss: 2.391845703125
Validation loss: 2.4838887773534304

Epoch: 6| Step: 7
Training loss: 2.722520589828491
Validation loss: 2.482517309086297

Epoch: 6| Step: 8
Training loss: 2.8793630599975586
Validation loss: 2.465781227234871

Epoch: 6| Step: 9
Training loss: 2.3422765731811523
Validation loss: 2.449004183533371

Epoch: 6| Step: 10
Training loss: 2.3412415981292725
Validation loss: 2.452187991911365

Epoch: 6| Step: 11
Training loss: 2.1981759071350098
Validation loss: 2.468238312710998

Epoch: 6| Step: 12
Training loss: 3.252699613571167
Validation loss: 2.4829444423798592

Epoch: 6| Step: 13
Training loss: 2.3675992488861084
Validation loss: 2.4417304095401557

Epoch: 26| Step: 0
Training loss: 2.185209274291992
Validation loss: 2.445207765025477

Epoch: 6| Step: 1
Training loss: 2.3307580947875977
Validation loss: 2.4655822118123374

Epoch: 6| Step: 2
Training loss: 2.968881368637085
Validation loss: 2.5030460101301952

Epoch: 6| Step: 3
Training loss: 2.3787548542022705
Validation loss: 2.5243757155633744

Epoch: 6| Step: 4
Training loss: 2.8481030464172363
Validation loss: 2.542400478034891

Epoch: 6| Step: 5
Training loss: 2.8036048412323
Validation loss: 2.523181735828359

Epoch: 6| Step: 6
Training loss: 2.7497236728668213
Validation loss: 2.4862163092500422

Epoch: 6| Step: 7
Training loss: 3.027855157852173
Validation loss: 2.4455430558932725

Epoch: 6| Step: 8
Training loss: 2.8412158489227295
Validation loss: 2.4333613636673137

Epoch: 6| Step: 9
Training loss: 2.330714225769043
Validation loss: 2.4321777333495436

Epoch: 6| Step: 10
Training loss: 3.0206451416015625
Validation loss: 2.43534343729737

Epoch: 6| Step: 11
Training loss: 2.041231155395508
Validation loss: 2.4353391842175554

Epoch: 6| Step: 12
Training loss: 2.924351692199707
Validation loss: 2.435436079579015

Epoch: 6| Step: 13
Training loss: 3.349125862121582
Validation loss: 2.442960049516411

Epoch: 27| Step: 0
Training loss: 3.2507572174072266
Validation loss: 2.4313069466621644

Epoch: 6| Step: 1
Training loss: 1.4414842128753662
Validation loss: 2.4274764548065844

Epoch: 6| Step: 2
Training loss: 2.8931384086608887
Validation loss: 2.4286770179707515

Epoch: 6| Step: 3
Training loss: 2.090458869934082
Validation loss: 2.4408143669046383

Epoch: 6| Step: 4
Training loss: 2.5070788860321045
Validation loss: 2.456419498689713

Epoch: 6| Step: 5
Training loss: 3.5035693645477295
Validation loss: 2.477978624323363

Epoch: 6| Step: 6
Training loss: 2.865138530731201
Validation loss: 2.4765306724015104

Epoch: 6| Step: 7
Training loss: 2.0148563385009766
Validation loss: 2.450434592462355

Epoch: 6| Step: 8
Training loss: 2.5636982917785645
Validation loss: 2.4383994174259964

Epoch: 6| Step: 9
Training loss: 2.79443359375
Validation loss: 2.432950488982662

Epoch: 6| Step: 10
Training loss: 3.6031835079193115
Validation loss: 2.4407105317679783

Epoch: 6| Step: 11
Training loss: 2.7238550186157227
Validation loss: 2.4416929547504713

Epoch: 6| Step: 12
Training loss: 2.41398024559021
Validation loss: 2.4537854886824086

Epoch: 6| Step: 13
Training loss: 2.4909634590148926
Validation loss: 2.487216103461481

Epoch: 28| Step: 0
Training loss: 2.2873854637145996
Validation loss: 2.5313593110730572

Epoch: 6| Step: 1
Training loss: 3.195255756378174
Validation loss: 2.5951186867170435

Epoch: 6| Step: 2
Training loss: 3.5142300128936768
Validation loss: 2.570285084427044

Epoch: 6| Step: 3
Training loss: 2.524376392364502
Validation loss: 2.50024430213436

Epoch: 6| Step: 4
Training loss: 3.5005106925964355
Validation loss: 2.4460320677808536

Epoch: 6| Step: 5
Training loss: 2.593759298324585
Validation loss: 2.4229174121733634

Epoch: 6| Step: 6
Training loss: 2.532834768295288
Validation loss: 2.4116065450893935

Epoch: 6| Step: 7
Training loss: 3.3715660572052
Validation loss: 2.410832287162863

Epoch: 6| Step: 8
Training loss: 2.2781758308410645
Validation loss: 2.415417848094817

Epoch: 6| Step: 9
Training loss: 2.604544162750244
Validation loss: 2.4153236394287436

Epoch: 6| Step: 10
Training loss: 2.2569758892059326
Validation loss: 2.416558991196335

Epoch: 6| Step: 11
Training loss: 1.6200281381607056
Validation loss: 2.4204467958019626

Epoch: 6| Step: 12
Training loss: 3.077003240585327
Validation loss: 2.4226844233851277

Epoch: 6| Step: 13
Training loss: 2.106818437576294
Validation loss: 2.427964743747506

Epoch: 29| Step: 0
Training loss: 2.488882064819336
Validation loss: 2.416686427208685

Epoch: 6| Step: 1
Training loss: 2.518491268157959
Validation loss: 2.4126519592859412

Epoch: 6| Step: 2
Training loss: 3.2176971435546875
Validation loss: 2.4137472465474117

Epoch: 6| Step: 3
Training loss: 2.3100967407226562
Validation loss: 2.416914596352526

Epoch: 6| Step: 4
Training loss: 2.499490737915039
Validation loss: 2.4240633159555416

Epoch: 6| Step: 5
Training loss: 3.365309953689575
Validation loss: 2.433197154793688

Epoch: 6| Step: 6
Training loss: 2.9885711669921875
Validation loss: 2.4486902759921167

Epoch: 6| Step: 7
Training loss: 2.7512731552124023
Validation loss: 2.4446330019222793

Epoch: 6| Step: 8
Training loss: 2.6134305000305176
Validation loss: 2.449099730419856

Epoch: 6| Step: 9
Training loss: 2.476013660430908
Validation loss: 2.4499153475607596

Epoch: 6| Step: 10
Training loss: 2.8534345626831055
Validation loss: 2.4396261117791616

Epoch: 6| Step: 11
Training loss: 2.8501038551330566
Validation loss: 2.434858973308276

Epoch: 6| Step: 12
Training loss: 2.2046351432800293
Validation loss: 2.432532084885464

Epoch: 6| Step: 13
Training loss: 1.7503864765167236
Validation loss: 2.4312819306568434

Epoch: 30| Step: 0
Training loss: 2.4778289794921875
Validation loss: 2.4316944165896346

Epoch: 6| Step: 1
Training loss: 2.57778000831604
Validation loss: 2.425949050534156

Epoch: 6| Step: 2
Training loss: 2.355222702026367
Validation loss: 2.4293404932945006

Epoch: 6| Step: 3
Training loss: 2.4677910804748535
Validation loss: 2.4267928049128544

Epoch: 6| Step: 4
Training loss: 2.7747888565063477
Validation loss: 2.4239906880163375

Epoch: 6| Step: 5
Training loss: 2.775810480117798
Validation loss: 2.4171746853859193

Epoch: 6| Step: 6
Training loss: 3.5419182777404785
Validation loss: 2.415535721727597

Epoch: 6| Step: 7
Training loss: 3.278468132019043
Validation loss: 2.4100910873823267

Epoch: 6| Step: 8
Training loss: 1.8911418914794922
Validation loss: 2.409488913833454

Epoch: 6| Step: 9
Training loss: 2.8211874961853027
Validation loss: 2.407551734678207

Epoch: 6| Step: 10
Training loss: 2.397174835205078
Validation loss: 2.4059264967518468

Epoch: 6| Step: 11
Training loss: 2.753331184387207
Validation loss: 2.4111500478559926

Epoch: 6| Step: 12
Training loss: 2.6054279804229736
Validation loss: 2.4053942875195573

Epoch: 6| Step: 13
Training loss: 2.0910563468933105
Validation loss: 2.4124874030390093

Epoch: 31| Step: 0
Training loss: 2.4774794578552246
Validation loss: 2.408260335204422

Epoch: 6| Step: 1
Training loss: 1.8934065103530884
Validation loss: 2.410988953805739

Epoch: 6| Step: 2
Training loss: 2.446168899536133
Validation loss: 2.4230259003177768

Epoch: 6| Step: 3
Training loss: 2.9009315967559814
Validation loss: 2.4449189965442946

Epoch: 6| Step: 4
Training loss: 2.476351737976074
Validation loss: 2.4512953681330525

Epoch: 6| Step: 5
Training loss: 3.10916805267334
Validation loss: 2.4505014150373396

Epoch: 6| Step: 6
Training loss: 3.1064019203186035
Validation loss: 2.4422431556127404

Epoch: 6| Step: 7
Training loss: 3.032212257385254
Validation loss: 2.432726667773339

Epoch: 6| Step: 8
Training loss: 2.907076120376587
Validation loss: 2.419172707424369

Epoch: 6| Step: 9
Training loss: 1.8755264282226562
Validation loss: 2.401805231648107

Epoch: 6| Step: 10
Training loss: 2.7980856895446777
Validation loss: 2.3965004208267375

Epoch: 6| Step: 11
Training loss: 2.551572799682617
Validation loss: 2.3976423202022428

Epoch: 6| Step: 12
Training loss: 3.1119370460510254
Validation loss: 2.3896771015659457

Epoch: 6| Step: 13
Training loss: 1.964274525642395
Validation loss: 2.388424745170019

Epoch: 32| Step: 0
Training loss: 2.2787046432495117
Validation loss: 2.383727360797185

Epoch: 6| Step: 1
Training loss: 2.1698789596557617
Validation loss: 2.3898858844593005

Epoch: 6| Step: 2
Training loss: 2.809617519378662
Validation loss: 2.3930002566306823

Epoch: 6| Step: 3
Training loss: 3.3001487255096436
Validation loss: 2.407678078579646

Epoch: 6| Step: 4
Training loss: 2.4424068927764893
Validation loss: 2.416617444766465

Epoch: 6| Step: 5
Training loss: 2.113771438598633
Validation loss: 2.446960336418562

Epoch: 6| Step: 6
Training loss: 3.4357388019561768
Validation loss: 2.4673736813247844

Epoch: 6| Step: 7
Training loss: 3.532985210418701
Validation loss: 2.473784387752574

Epoch: 6| Step: 8
Training loss: 2.7307488918304443
Validation loss: 2.449172589086717

Epoch: 6| Step: 9
Training loss: 2.43221378326416
Validation loss: 2.4242575758246967

Epoch: 6| Step: 10
Training loss: 2.602161169052124
Validation loss: 2.4050741503315587

Epoch: 6| Step: 11
Training loss: 2.198394536972046
Validation loss: 2.3960783148324616

Epoch: 6| Step: 12
Training loss: 2.1822831630706787
Validation loss: 2.3887118626666326

Epoch: 6| Step: 13
Training loss: 3.143787384033203
Validation loss: 2.3911152039804766

Epoch: 33| Step: 0
Training loss: 2.965117931365967
Validation loss: 2.3796656695745324

Epoch: 6| Step: 1
Training loss: 2.6296772956848145
Validation loss: 2.3814164028372815

Epoch: 6| Step: 2
Training loss: 3.188011646270752
Validation loss: 2.378622060180992

Epoch: 6| Step: 3
Training loss: 2.8858096599578857
Validation loss: 2.3774725416655182

Epoch: 6| Step: 4
Training loss: 2.6364593505859375
Validation loss: 2.3801159679248767

Epoch: 6| Step: 5
Training loss: 2.6108622550964355
Validation loss: 2.375953387188655

Epoch: 6| Step: 6
Training loss: 2.559835433959961
Validation loss: 2.3782129364628948

Epoch: 6| Step: 7
Training loss: 1.8842811584472656
Validation loss: 2.3735457671585904

Epoch: 6| Step: 8
Training loss: 2.291400671005249
Validation loss: 2.377827852003036

Epoch: 6| Step: 9
Training loss: 2.9452996253967285
Validation loss: 2.376993553612822

Epoch: 6| Step: 10
Training loss: 2.6234216690063477
Validation loss: 2.3743730052824943

Epoch: 6| Step: 11
Training loss: 2.809898853302002
Validation loss: 2.381732268999982

Epoch: 6| Step: 12
Training loss: 2.2367568016052246
Validation loss: 2.376495376709969

Epoch: 6| Step: 13
Training loss: 2.417339324951172
Validation loss: 2.3791419665018716

Epoch: 34| Step: 0
Training loss: 3.332435369491577
Validation loss: 2.3853174537740727

Epoch: 6| Step: 1
Training loss: 2.2639071941375732
Validation loss: 2.383340968880602

Epoch: 6| Step: 2
Training loss: 2.0306549072265625
Validation loss: 2.3934978362052672

Epoch: 6| Step: 3
Training loss: 2.246225595474243
Validation loss: 2.4031399885813394

Epoch: 6| Step: 4
Training loss: 2.0206680297851562
Validation loss: 2.40160640593498

Epoch: 6| Step: 5
Training loss: 2.123626470565796
Validation loss: 2.4104624230374574

Epoch: 6| Step: 6
Training loss: 2.521958351135254
Validation loss: 2.4382947260333645

Epoch: 6| Step: 7
Training loss: 3.6986942291259766
Validation loss: 2.4263592099630706

Epoch: 6| Step: 8
Training loss: 2.716144323348999
Validation loss: 2.4113082885742188

Epoch: 6| Step: 9
Training loss: 2.8659870624542236
Validation loss: 2.4101002946976693

Epoch: 6| Step: 10
Training loss: 2.8538057804107666
Validation loss: 2.3936931369125203

Epoch: 6| Step: 11
Training loss: 2.8768646717071533
Validation loss: 2.3895564874013266

Epoch: 6| Step: 12
Training loss: 2.375645160675049
Validation loss: 2.3768472184417067

Epoch: 6| Step: 13
Training loss: 2.9470126628875732
Validation loss: 2.368612176628523

Epoch: 35| Step: 0
Training loss: 2.373035430908203
Validation loss: 2.367380275521227

Epoch: 6| Step: 1
Training loss: 2.401648998260498
Validation loss: 2.36447085103681

Epoch: 6| Step: 2
Training loss: 2.407637357711792
Validation loss: 2.3662247042502127

Epoch: 6| Step: 3
Training loss: 3.2815518379211426
Validation loss: 2.366538792528132

Epoch: 6| Step: 4
Training loss: 2.1954965591430664
Validation loss: 2.363245238539993

Epoch: 6| Step: 5
Training loss: 2.18328857421875
Validation loss: 2.3711074193318686

Epoch: 6| Step: 6
Training loss: 3.0860743522644043
Validation loss: 2.3748683826897734

Epoch: 6| Step: 7
Training loss: 2.036930799484253
Validation loss: 2.3736793071992937

Epoch: 6| Step: 8
Training loss: 2.615140199661255
Validation loss: 2.380079371954805

Epoch: 6| Step: 9
Training loss: 3.129448890686035
Validation loss: 2.3791373622032905

Epoch: 6| Step: 10
Training loss: 3.080388069152832
Validation loss: 2.3677778295291367

Epoch: 6| Step: 11
Training loss: 2.9616518020629883
Validation loss: 2.362288301990878

Epoch: 6| Step: 12
Training loss: 2.3202881813049316
Validation loss: 2.351258498366161

Epoch: 6| Step: 13
Training loss: 2.587207317352295
Validation loss: 2.35222630346975

Epoch: 36| Step: 0
Training loss: 2.9077532291412354
Validation loss: 2.351061587692589

Epoch: 6| Step: 1
Training loss: 2.4412248134613037
Validation loss: 2.3507872627627466

Epoch: 6| Step: 2
Training loss: 2.8512606620788574
Validation loss: 2.347699906236382

Epoch: 6| Step: 3
Training loss: 2.8042678833007812
Validation loss: 2.347083371172669

Epoch: 6| Step: 4
Training loss: 2.3718347549438477
Validation loss: 2.349319727190079

Epoch: 6| Step: 5
Training loss: 2.2933788299560547
Validation loss: 2.348674166587091

Epoch: 6| Step: 6
Training loss: 2.987238883972168
Validation loss: 2.35704513519041

Epoch: 6| Step: 7
Training loss: 2.7650489807128906
Validation loss: 2.370998123640655

Epoch: 6| Step: 8
Training loss: 2.4410619735717773
Validation loss: 2.3809533221747285

Epoch: 6| Step: 9
Training loss: 2.632089614868164
Validation loss: 2.390482082161852

Epoch: 6| Step: 10
Training loss: 2.5607221126556396
Validation loss: 2.4035422366152526

Epoch: 6| Step: 11
Training loss: 2.9574387073516846
Validation loss: 2.3959998392289683

Epoch: 6| Step: 12
Training loss: 2.7642436027526855
Validation loss: 2.374645674100486

Epoch: 6| Step: 13
Training loss: 1.6031756401062012
Validation loss: 2.358797557892338

Epoch: 37| Step: 0
Training loss: 2.3555965423583984
Validation loss: 2.34556475762398

Epoch: 6| Step: 1
Training loss: 2.366668224334717
Validation loss: 2.344621624997867

Epoch: 6| Step: 2
Training loss: 3.245687484741211
Validation loss: 2.3397358720020582

Epoch: 6| Step: 3
Training loss: 2.626277446746826
Validation loss: 2.341669485133181

Epoch: 6| Step: 4
Training loss: 2.8771355152130127
Validation loss: 2.3416685263315835

Epoch: 6| Step: 5
Training loss: 2.761737823486328
Validation loss: 2.343409340868714

Epoch: 6| Step: 6
Training loss: 2.8391990661621094
Validation loss: 2.338818662910051

Epoch: 6| Step: 7
Training loss: 3.0768392086029053
Validation loss: 2.340427649918423

Epoch: 6| Step: 8
Training loss: 2.2977051734924316
Validation loss: 2.3409687396018737

Epoch: 6| Step: 9
Training loss: 3.1558077335357666
Validation loss: 2.3385614502814507

Epoch: 6| Step: 10
Training loss: 1.892012119293213
Validation loss: 2.337994683173395

Epoch: 6| Step: 11
Training loss: 2.3265953063964844
Validation loss: 2.3415869769229682

Epoch: 6| Step: 12
Training loss: 2.705629587173462
Validation loss: 2.343136892523817

Epoch: 6| Step: 13
Training loss: 1.724663496017456
Validation loss: 2.3436277297235306

Epoch: 38| Step: 0
Training loss: 1.8858994245529175
Validation loss: 2.3465111896555912

Epoch: 6| Step: 1
Training loss: 2.9311935901641846
Validation loss: 2.3508900980795584

Epoch: 6| Step: 2
Training loss: 2.6932544708251953
Validation loss: 2.3604184658296647

Epoch: 6| Step: 3
Training loss: 2.784634590148926
Validation loss: 2.3718284868424937

Epoch: 6| Step: 4
Training loss: 2.1781044006347656
Validation loss: 2.3615043945209955

Epoch: 6| Step: 5
Training loss: 2.8216962814331055
Validation loss: 2.3611575147157073

Epoch: 6| Step: 6
Training loss: 2.0461814403533936
Validation loss: 2.3723542305731002

Epoch: 6| Step: 7
Training loss: 2.6720433235168457
Validation loss: 2.381383672837288

Epoch: 6| Step: 8
Training loss: 3.755690097808838
Validation loss: 2.4022434296146518

Epoch: 6| Step: 9
Training loss: 2.3871140480041504
Validation loss: 2.397843098127714

Epoch: 6| Step: 10
Training loss: 2.0987730026245117
Validation loss: 2.3801255508135726

Epoch: 6| Step: 11
Training loss: 2.981006145477295
Validation loss: 2.3659709371546263

Epoch: 6| Step: 12
Training loss: 2.206122398376465
Validation loss: 2.357748580235307

Epoch: 6| Step: 13
Training loss: 3.3407931327819824
Validation loss: 2.3508153935914398

Epoch: 39| Step: 0
Training loss: 2.4183712005615234
Validation loss: 2.340569967864662

Epoch: 6| Step: 1
Training loss: 2.4075372219085693
Validation loss: 2.334637341960784

Epoch: 6| Step: 2
Training loss: 3.140745162963867
Validation loss: 2.3354824371235345

Epoch: 6| Step: 3
Training loss: 3.2598934173583984
Validation loss: 2.3380058298828783

Epoch: 6| Step: 4
Training loss: 2.944366455078125
Validation loss: 2.3318032167291127

Epoch: 6| Step: 5
Training loss: 2.5234744548797607
Validation loss: 2.3318404613002652

Epoch: 6| Step: 6
Training loss: 2.2783617973327637
Validation loss: 2.326300205722932

Epoch: 6| Step: 7
Training loss: 2.900676965713501
Validation loss: 2.333805743084159

Epoch: 6| Step: 8
Training loss: 2.8297154903411865
Validation loss: 2.3349135280937277

Epoch: 6| Step: 9
Training loss: 2.3886513710021973
Validation loss: 2.3381704002298336

Epoch: 6| Step: 10
Training loss: 2.065452814102173
Validation loss: 2.3412818549781718

Epoch: 6| Step: 11
Training loss: 2.1260733604431152
Validation loss: 2.3515131781178136

Epoch: 6| Step: 12
Training loss: 2.148137092590332
Validation loss: 2.3430694175022904

Epoch: 6| Step: 13
Training loss: 3.0954551696777344
Validation loss: 2.3506858733392533

Epoch: 40| Step: 0
Training loss: 2.411391258239746
Validation loss: 2.351635540685346

Epoch: 6| Step: 1
Training loss: 3.104424476623535
Validation loss: 2.3445844060631207

Epoch: 6| Step: 2
Training loss: 3.0919086933135986
Validation loss: 2.346198703653069

Epoch: 6| Step: 3
Training loss: 2.536327362060547
Validation loss: 2.3503330984423236

Epoch: 6| Step: 4
Training loss: 1.8169949054718018
Validation loss: 2.355072159920969

Epoch: 6| Step: 5
Training loss: 2.3465418815612793
Validation loss: 2.3671264699710313

Epoch: 6| Step: 6
Training loss: 2.489834785461426
Validation loss: 2.40180193736989

Epoch: 6| Step: 7
Training loss: 2.19352650642395
Validation loss: 2.4180000725612847

Epoch: 6| Step: 8
Training loss: 1.9140822887420654
Validation loss: 2.4459394101173646

Epoch: 6| Step: 9
Training loss: 3.5041074752807617
Validation loss: 2.460760265268305

Epoch: 6| Step: 10
Training loss: 2.655508518218994
Validation loss: 2.40670637161501

Epoch: 6| Step: 11
Training loss: 3.0736920833587646
Validation loss: 2.3317401742422454

Epoch: 6| Step: 12
Training loss: 2.5915563106536865
Validation loss: 2.339250967066775

Epoch: 6| Step: 13
Training loss: 2.5153470039367676
Validation loss: 2.3571528337335073

Epoch: 41| Step: 0
Training loss: 3.4949512481689453
Validation loss: 2.4197339396322928

Epoch: 6| Step: 1
Training loss: 2.9813966751098633
Validation loss: 2.4713270587305867

Epoch: 6| Step: 2
Training loss: 2.7202441692352295
Validation loss: 2.4659642942490114

Epoch: 6| Step: 3
Training loss: 2.441932201385498
Validation loss: 2.41119062003269

Epoch: 6| Step: 4
Training loss: 2.24609637260437
Validation loss: 2.4065638665230042

Epoch: 6| Step: 5
Training loss: 2.0212206840515137
Validation loss: 2.3932608891558904

Epoch: 6| Step: 6
Training loss: 2.4022319316864014
Validation loss: 2.4037194508378223

Epoch: 6| Step: 7
Training loss: 2.5260086059570312
Validation loss: 2.3916508331093738

Epoch: 6| Step: 8
Training loss: 2.5072882175445557
Validation loss: 2.372525824013577

Epoch: 6| Step: 9
Training loss: 2.8086905479431152
Validation loss: 2.3491105802597536

Epoch: 6| Step: 10
Training loss: 2.7736425399780273
Validation loss: 2.3355365055863575

Epoch: 6| Step: 11
Training loss: 2.0634658336639404
Validation loss: 2.3175609419422765

Epoch: 6| Step: 12
Training loss: 2.9252171516418457
Validation loss: 2.317586124584239

Epoch: 6| Step: 13
Training loss: 2.9270429611206055
Validation loss: 2.317544748706202

Epoch: 42| Step: 0
Training loss: 2.942234992980957
Validation loss: 2.320005222033429

Epoch: 6| Step: 1
Training loss: 2.2108685970306396
Validation loss: 2.315656308204897

Epoch: 6| Step: 2
Training loss: 3.1522793769836426
Validation loss: 2.3157741613285516

Epoch: 6| Step: 3
Training loss: 2.7100110054016113
Validation loss: 2.3219448571564048

Epoch: 6| Step: 4
Training loss: 2.585686683654785
Validation loss: 2.3097165733255367

Epoch: 6| Step: 5
Training loss: 2.5816121101379395
Validation loss: 2.3093864712663876

Epoch: 6| Step: 6
Training loss: 2.3155691623687744
Validation loss: 2.304804250758181

Epoch: 6| Step: 7
Training loss: 2.774563789367676
Validation loss: 2.299850179303077

Epoch: 6| Step: 8
Training loss: 3.2371327877044678
Validation loss: 2.3047083821347965

Epoch: 6| Step: 9
Training loss: 2.4213709831237793
Validation loss: 2.312847806561378

Epoch: 6| Step: 10
Training loss: 2.45135498046875
Validation loss: 2.314926652498143

Epoch: 6| Step: 11
Training loss: 2.388774871826172
Validation loss: 2.31968831246899

Epoch: 6| Step: 12
Training loss: 2.325882911682129
Validation loss: 2.3374736719234015

Epoch: 6| Step: 13
Training loss: 1.7727543115615845
Validation loss: 2.358850940581291

Epoch: 43| Step: 0
Training loss: 2.558624029159546
Validation loss: 2.38055133563216

Epoch: 6| Step: 1
Training loss: 2.670103073120117
Validation loss: 2.3886316412238666

Epoch: 6| Step: 2
Training loss: 2.2418465614318848
Validation loss: 2.381173813214866

Epoch: 6| Step: 3
Training loss: 3.2048020362854004
Validation loss: 2.3692238484659502

Epoch: 6| Step: 4
Training loss: 2.2388036251068115
Validation loss: 2.344683054954775

Epoch: 6| Step: 5
Training loss: 2.0943875312805176
Validation loss: 2.3174748036169235

Epoch: 6| Step: 6
Training loss: 2.071572780609131
Validation loss: 2.2992904340067217

Epoch: 6| Step: 7
Training loss: 2.772275447845459
Validation loss: 2.2909569637749785

Epoch: 6| Step: 8
Training loss: 2.748042583465576
Validation loss: 2.2907909577892673

Epoch: 6| Step: 9
Training loss: 2.72857928276062
Validation loss: 2.2879889242110716

Epoch: 6| Step: 10
Training loss: 3.0993170738220215
Validation loss: 2.2872328681330525

Epoch: 6| Step: 11
Training loss: 3.1573543548583984
Validation loss: 2.2862678548341155

Epoch: 6| Step: 12
Training loss: 2.3478832244873047
Validation loss: 2.2861059481097805

Epoch: 6| Step: 13
Training loss: 1.8116790056228638
Validation loss: 2.283455136001751

Epoch: 44| Step: 0
Training loss: 2.8392605781555176
Validation loss: 2.282950749961279

Epoch: 6| Step: 1
Training loss: 2.099820375442505
Validation loss: 2.2836082596932687

Epoch: 6| Step: 2
Training loss: 2.022930145263672
Validation loss: 2.2782759153714744

Epoch: 6| Step: 3
Training loss: 2.7279748916625977
Validation loss: 2.2757348373372066

Epoch: 6| Step: 4
Training loss: 3.4395744800567627
Validation loss: 2.276964633695541

Epoch: 6| Step: 5
Training loss: 2.7148780822753906
Validation loss: 2.277549059160294

Epoch: 6| Step: 6
Training loss: 2.9724361896514893
Validation loss: 2.276564023827994

Epoch: 6| Step: 7
Training loss: 2.128467559814453
Validation loss: 2.2830430846060477

Epoch: 6| Step: 8
Training loss: 2.2855753898620605
Validation loss: 2.305359617356331

Epoch: 6| Step: 9
Training loss: 2.7420272827148438
Validation loss: 2.3491069373264106

Epoch: 6| Step: 10
Training loss: 2.703303337097168
Validation loss: 2.385049919928274

Epoch: 6| Step: 11
Training loss: 2.1911768913269043
Validation loss: 2.3964728565626245

Epoch: 6| Step: 12
Training loss: 2.6360867023468018
Validation loss: 2.386225800360403

Epoch: 6| Step: 13
Training loss: 2.459110736846924
Validation loss: 2.377676002440914

Epoch: 45| Step: 0
Training loss: 2.0738000869750977
Validation loss: 2.3537828383907193

Epoch: 6| Step: 1
Training loss: 2.213590145111084
Validation loss: 2.326537634736748

Epoch: 6| Step: 2
Training loss: 2.8586654663085938
Validation loss: 2.296777996965634

Epoch: 6| Step: 3
Training loss: 2.9042608737945557
Validation loss: 2.279498605317967

Epoch: 6| Step: 4
Training loss: 2.8807060718536377
Validation loss: 2.265396541164767

Epoch: 6| Step: 5
Training loss: 2.299246311187744
Validation loss: 2.2621650977801253

Epoch: 6| Step: 6
Training loss: 2.9121384620666504
Validation loss: 2.2691977447079075

Epoch: 6| Step: 7
Training loss: 3.1147913932800293
Validation loss: 2.270866401733891

Epoch: 6| Step: 8
Training loss: 2.5483269691467285
Validation loss: 2.2725124897495395

Epoch: 6| Step: 9
Training loss: 2.552891731262207
Validation loss: 2.271430625710436

Epoch: 6| Step: 10
Training loss: 2.6663451194763184
Validation loss: 2.265791618695823

Epoch: 6| Step: 11
Training loss: 2.7579526901245117
Validation loss: 2.2621506362833004

Epoch: 6| Step: 12
Training loss: 2.5817770957946777
Validation loss: 2.259613125554977

Epoch: 6| Step: 13
Training loss: 0.989410400390625
Validation loss: 2.2562240605713217

Epoch: 46| Step: 0
Training loss: 1.9233670234680176
Validation loss: 2.2546082286424536

Epoch: 6| Step: 1
Training loss: 2.6771068572998047
Validation loss: 2.254673860406363

Epoch: 6| Step: 2
Training loss: 2.0347113609313965
Validation loss: 2.2571844413716304

Epoch: 6| Step: 3
Training loss: 2.8299317359924316
Validation loss: 2.269173178621518

Epoch: 6| Step: 4
Training loss: 2.5955934524536133
Validation loss: 2.2996689914375223

Epoch: 6| Step: 5
Training loss: 2.2242660522460938
Validation loss: 2.3266538035485054

Epoch: 6| Step: 6
Training loss: 2.886475086212158
Validation loss: 2.3557683934447584

Epoch: 6| Step: 7
Training loss: 2.485029697418213
Validation loss: 2.354086688769761

Epoch: 6| Step: 8
Training loss: 2.9681472778320312
Validation loss: 2.3685151838487193

Epoch: 6| Step: 9
Training loss: 3.0799098014831543
Validation loss: 2.3596421005905315

Epoch: 6| Step: 10
Training loss: 2.5860774517059326
Validation loss: 2.3457411155905774

Epoch: 6| Step: 11
Training loss: 2.359851837158203
Validation loss: 2.3216733471039803

Epoch: 6| Step: 12
Training loss: 2.035066843032837
Validation loss: 2.2961718754101823

Epoch: 6| Step: 13
Training loss: 3.4041173458099365
Validation loss: 2.2761544207090973

Epoch: 47| Step: 0
Training loss: 2.2003836631774902
Validation loss: 2.261466885125765

Epoch: 6| Step: 1
Training loss: 2.3025062084198
Validation loss: 2.252634443262572

Epoch: 6| Step: 2
Training loss: 2.8844847679138184
Validation loss: 2.2481420117039836

Epoch: 6| Step: 3
Training loss: 2.0751824378967285
Validation loss: 2.2476874295101372

Epoch: 6| Step: 4
Training loss: 2.475111961364746
Validation loss: 2.2442748392781904

Epoch: 6| Step: 5
Training loss: 2.663914203643799
Validation loss: 2.2463735970117713

Epoch: 6| Step: 6
Training loss: 2.0173187255859375
Validation loss: 2.2453230914249214

Epoch: 6| Step: 7
Training loss: 2.2426600456237793
Validation loss: 2.2445643383969545

Epoch: 6| Step: 8
Training loss: 3.030717372894287
Validation loss: 2.243782768967331

Epoch: 6| Step: 9
Training loss: 3.4924473762512207
Validation loss: 2.242102248694307

Epoch: 6| Step: 10
Training loss: 3.045994281768799
Validation loss: 2.2418449104473157

Epoch: 6| Step: 11
Training loss: 2.5777995586395264
Validation loss: 2.2411407527103218

Epoch: 6| Step: 12
Training loss: 1.9956231117248535
Validation loss: 2.248042163028512

Epoch: 6| Step: 13
Training loss: 2.7874040603637695
Validation loss: 2.25420186596532

Epoch: 48| Step: 0
Training loss: 2.07951021194458
Validation loss: 2.258624267834489

Epoch: 6| Step: 1
Training loss: 1.7396330833435059
Validation loss: 2.2720469941375074

Epoch: 6| Step: 2
Training loss: 2.9036855697631836
Validation loss: 2.2851049156599146

Epoch: 6| Step: 3
Training loss: 2.185624361038208
Validation loss: 2.3088212884882444

Epoch: 6| Step: 4
Training loss: 2.5752787590026855
Validation loss: 2.329950132677632

Epoch: 6| Step: 5
Training loss: 2.4214155673980713
Validation loss: 2.3801531560959353

Epoch: 6| Step: 6
Training loss: 3.3252620697021484
Validation loss: 2.381338237434305

Epoch: 6| Step: 7
Training loss: 2.925103187561035
Validation loss: 2.3704178000009186

Epoch: 6| Step: 8
Training loss: 2.3643293380737305
Validation loss: 2.318836135248984

Epoch: 6| Step: 9
Training loss: 2.197848320007324
Validation loss: 2.298812481664842

Epoch: 6| Step: 10
Training loss: 2.096306800842285
Validation loss: 2.2610838643966185

Epoch: 6| Step: 11
Training loss: 2.815670967102051
Validation loss: 2.241759720668998

Epoch: 6| Step: 12
Training loss: 3.602504014968872
Validation loss: 2.2356449891162176

Epoch: 6| Step: 13
Training loss: 2.3197598457336426
Validation loss: 2.236945729101858

Epoch: 49| Step: 0
Training loss: 1.5431387424468994
Validation loss: 2.235549444793373

Epoch: 6| Step: 1
Training loss: 2.9818384647369385
Validation loss: 2.231199146598898

Epoch: 6| Step: 2
Training loss: 3.5826127529144287
Validation loss: 2.2322660940949635

Epoch: 6| Step: 3
Training loss: 2.5516929626464844
Validation loss: 2.2343688831534436

Epoch: 6| Step: 4
Training loss: 2.600505828857422
Validation loss: 2.2360394052279893

Epoch: 6| Step: 5
Training loss: 2.5101847648620605
Validation loss: 2.2369336094907535

Epoch: 6| Step: 6
Training loss: 2.3858296871185303
Validation loss: 2.2395749143374863

Epoch: 6| Step: 7
Training loss: 1.5700137615203857
Validation loss: 2.2491062559107298

Epoch: 6| Step: 8
Training loss: 2.053706169128418
Validation loss: 2.2742279985899567

Epoch: 6| Step: 9
Training loss: 2.7005205154418945
Validation loss: 2.308921116654591

Epoch: 6| Step: 10
Training loss: 3.1797971725463867
Validation loss: 2.3171748345898044

Epoch: 6| Step: 11
Training loss: 2.6262450218200684
Validation loss: 2.324540115171863

Epoch: 6| Step: 12
Training loss: 3.10042667388916
Validation loss: 2.3316524503051594

Epoch: 6| Step: 13
Training loss: 2.280338764190674
Validation loss: 2.2974945883597098

Epoch: 50| Step: 0
Training loss: 3.3316030502319336
Validation loss: 2.268934629296744

Epoch: 6| Step: 1
Training loss: 2.363373279571533
Validation loss: 2.249468748287488

Epoch: 6| Step: 2
Training loss: 2.0428366661071777
Validation loss: 2.228723636237524

Epoch: 6| Step: 3
Training loss: 2.461364984512329
Validation loss: 2.221441973922073

Epoch: 6| Step: 4
Training loss: 2.694312334060669
Validation loss: 2.233100812922242

Epoch: 6| Step: 5
Training loss: 2.822148323059082
Validation loss: 2.241683103704965

Epoch: 6| Step: 6
Training loss: 3.2922089099884033
Validation loss: 2.234538719218264

Epoch: 6| Step: 7
Training loss: 2.2515475749969482
Validation loss: 2.2335245404192197

Epoch: 6| Step: 8
Training loss: 2.7841930389404297
Validation loss: 2.2282632768795056

Epoch: 6| Step: 9
Training loss: 2.23368763923645
Validation loss: 2.2297980785369873

Epoch: 6| Step: 10
Training loss: 2.340632915496826
Validation loss: 2.2171550322604436

Epoch: 6| Step: 11
Training loss: 1.8307557106018066
Validation loss: 2.2154739185046126

Epoch: 6| Step: 12
Training loss: 2.7325243949890137
Validation loss: 2.221478804465263

Epoch: 6| Step: 13
Training loss: 2.7007269859313965
Validation loss: 2.220965885346936

Epoch: 51| Step: 0
Training loss: 2.353722095489502
Validation loss: 2.2202926297341623

Epoch: 6| Step: 1
Training loss: 2.4978182315826416
Validation loss: 2.2219295270981325

Epoch: 6| Step: 2
Training loss: 1.8570630550384521
Validation loss: 2.2304998879791587

Epoch: 6| Step: 3
Training loss: 2.07792592048645
Validation loss: 2.237102175271639

Epoch: 6| Step: 4
Training loss: 2.9787445068359375
Validation loss: 2.239450890530822

Epoch: 6| Step: 5
Training loss: 2.853306293487549
Validation loss: 2.236136644117294

Epoch: 6| Step: 6
Training loss: 3.1313071250915527
Validation loss: 2.231859907027214

Epoch: 6| Step: 7
Training loss: 2.409599542617798
Validation loss: 2.224747080956736

Epoch: 6| Step: 8
Training loss: 2.77797794342041
Validation loss: 2.222271465486096

Epoch: 6| Step: 9
Training loss: 2.7725677490234375
Validation loss: 2.219472887695477

Epoch: 6| Step: 10
Training loss: 2.485962152481079
Validation loss: 2.2183191340456725

Epoch: 6| Step: 11
Training loss: 2.4505529403686523
Validation loss: 2.225619432746723

Epoch: 6| Step: 12
Training loss: 2.7782516479492188
Validation loss: 2.230814406948705

Epoch: 6| Step: 13
Training loss: 1.3477308750152588
Validation loss: 2.2367863270544235

Epoch: 52| Step: 0
Training loss: 2.5059053897857666
Validation loss: 2.2501237776971634

Epoch: 6| Step: 1
Training loss: 2.590372085571289
Validation loss: 2.2487167914708457

Epoch: 6| Step: 2
Training loss: 1.9767913818359375
Validation loss: 2.2569770274623746

Epoch: 6| Step: 3
Training loss: 2.9558238983154297
Validation loss: 2.2598912869730303

Epoch: 6| Step: 4
Training loss: 2.419188976287842
Validation loss: 2.244932451555806

Epoch: 6| Step: 5
Training loss: 2.5574452877044678
Validation loss: 2.240514402748436

Epoch: 6| Step: 6
Training loss: 2.5083324909210205
Validation loss: 2.2264675119871735

Epoch: 6| Step: 7
Training loss: 3.215104341506958
Validation loss: 2.223811500815935

Epoch: 6| Step: 8
Training loss: 2.276944637298584
Validation loss: 2.216091427751767

Epoch: 6| Step: 9
Training loss: 1.6137120723724365
Validation loss: 2.2093066976916407

Epoch: 6| Step: 10
Training loss: 3.1139426231384277
Validation loss: 2.209597394030581

Epoch: 6| Step: 11
Training loss: 2.6151185035705566
Validation loss: 2.20516384801557

Epoch: 6| Step: 12
Training loss: 1.8537664413452148
Validation loss: 2.2111790692934425

Epoch: 6| Step: 13
Training loss: 3.2147035598754883
Validation loss: 2.210717588342646

Epoch: 53| Step: 0
Training loss: 2.9367904663085938
Validation loss: 2.2099187245932956

Epoch: 6| Step: 1
Training loss: 2.554055690765381
Validation loss: 2.205877375859086

Epoch: 6| Step: 2
Training loss: 2.0352444648742676
Validation loss: 2.206921213416643

Epoch: 6| Step: 3
Training loss: 2.8953847885131836
Validation loss: 2.2109501002937235

Epoch: 6| Step: 4
Training loss: 1.6249092817306519
Validation loss: 2.2108753573509956

Epoch: 6| Step: 5
Training loss: 2.3331515789031982
Validation loss: 2.2156773305708364

Epoch: 6| Step: 6
Training loss: 2.8204667568206787
Validation loss: 2.211736899550243

Epoch: 6| Step: 7
Training loss: 2.356745719909668
Validation loss: 2.214715273149552

Epoch: 6| Step: 8
Training loss: 2.965763568878174
Validation loss: 2.2131234522788756

Epoch: 6| Step: 9
Training loss: 2.3663840293884277
Validation loss: 2.216736470499346

Epoch: 6| Step: 10
Training loss: 2.4330668449401855
Validation loss: 2.2323445812348397

Epoch: 6| Step: 11
Training loss: 2.3544206619262695
Validation loss: 2.25854516285722

Epoch: 6| Step: 12
Training loss: 2.3321096897125244
Validation loss: 2.2735944717161116

Epoch: 6| Step: 13
Training loss: 3.2897093296051025
Validation loss: 2.326028903325399

Epoch: 54| Step: 0
Training loss: 3.2078919410705566
Validation loss: 2.2842134019379974

Epoch: 6| Step: 1
Training loss: 2.4580435752868652
Validation loss: 2.240196370309399

Epoch: 6| Step: 2
Training loss: 2.0921854972839355
Validation loss: 2.2195665849152433

Epoch: 6| Step: 3
Training loss: 2.2768287658691406
Validation loss: 2.2257025921216576

Epoch: 6| Step: 4
Training loss: 2.785755157470703
Validation loss: 2.2448913384509344

Epoch: 6| Step: 5
Training loss: 2.572288990020752
Validation loss: 2.2699490285688833

Epoch: 6| Step: 6
Training loss: 2.8943076133728027
Validation loss: 2.266963143502512

Epoch: 6| Step: 7
Training loss: 2.7827906608581543
Validation loss: 2.2473460794777

Epoch: 6| Step: 8
Training loss: 1.6694910526275635
Validation loss: 2.2390006357623684

Epoch: 6| Step: 9
Training loss: 2.1968488693237305
Validation loss: 2.245250425031108

Epoch: 6| Step: 10
Training loss: 1.8178553581237793
Validation loss: 2.261101597098894

Epoch: 6| Step: 11
Training loss: 2.5652639865875244
Validation loss: 2.24235535693425

Epoch: 6| Step: 12
Training loss: 3.3472213745117188
Validation loss: 2.208123763402303

Epoch: 6| Step: 13
Training loss: 2.632359027862549
Validation loss: 2.1952914768649685

Epoch: 55| Step: 0
Training loss: 2.2332265377044678
Validation loss: 2.1932291625648417

Epoch: 6| Step: 1
Training loss: 2.4915823936462402
Validation loss: 2.196238954861959

Epoch: 6| Step: 2
Training loss: 2.092503070831299
Validation loss: 2.203418513779999

Epoch: 6| Step: 3
Training loss: 2.397063732147217
Validation loss: 2.2141272034696353

Epoch: 6| Step: 4
Training loss: 2.9323134422302246
Validation loss: 2.2186264581577753

Epoch: 6| Step: 5
Training loss: 2.1626405715942383
Validation loss: 2.2076396339683124

Epoch: 6| Step: 6
Training loss: 2.2167930603027344
Validation loss: 2.203607687386133

Epoch: 6| Step: 7
Training loss: 2.750439167022705
Validation loss: 2.2154683041316208

Epoch: 6| Step: 8
Training loss: 2.475930690765381
Validation loss: 2.237993037828835

Epoch: 6| Step: 9
Training loss: 2.603569507598877
Validation loss: 2.2292178907702045

Epoch: 6| Step: 10
Training loss: 2.8607614040374756
Validation loss: 2.218675869767384

Epoch: 6| Step: 11
Training loss: 2.732302188873291
Validation loss: 2.2188599058376846

Epoch: 6| Step: 12
Training loss: 2.6001014709472656
Validation loss: 2.206811446015553

Epoch: 6| Step: 13
Training loss: 2.3701701164245605
Validation loss: 2.2019742291460753

Epoch: 56| Step: 0
Training loss: 2.3371965885162354
Validation loss: 2.2058689901905675

Epoch: 6| Step: 1
Training loss: 2.775024175643921
Validation loss: 2.196734020786901

Epoch: 6| Step: 2
Training loss: 2.544584274291992
Validation loss: 2.1981477070880193

Epoch: 6| Step: 3
Training loss: 2.8773012161254883
Validation loss: 2.2035031331482755

Epoch: 6| Step: 4
Training loss: 2.318281650543213
Validation loss: 2.2096192759852253

Epoch: 6| Step: 5
Training loss: 2.2635018825531006
Validation loss: 2.2223680865380073

Epoch: 6| Step: 6
Training loss: 2.183523178100586
Validation loss: 2.220781763394674

Epoch: 6| Step: 7
Training loss: 2.6710400581359863
Validation loss: 2.2383740755819503

Epoch: 6| Step: 8
Training loss: 2.1478073596954346
Validation loss: 2.2663060542075866

Epoch: 6| Step: 9
Training loss: 2.1044039726257324
Validation loss: 2.3175492466136975

Epoch: 6| Step: 10
Training loss: 2.7165298461914062
Validation loss: 2.3384534697378836

Epoch: 6| Step: 11
Training loss: 3.6864583492279053
Validation loss: 2.270755967786235

Epoch: 6| Step: 12
Training loss: 2.159916400909424
Validation loss: 2.220424787972563

Epoch: 6| Step: 13
Training loss: 2.235584259033203
Validation loss: 2.1934587186382664

Epoch: 57| Step: 0
Training loss: 2.180190086364746
Validation loss: 2.174658698420371

Epoch: 6| Step: 1
Training loss: 2.979428768157959
Validation loss: 2.1823624795483005

Epoch: 6| Step: 2
Training loss: 2.8537685871124268
Validation loss: 2.1922715351145756

Epoch: 6| Step: 3
Training loss: 1.8295791149139404
Validation loss: 2.2004817557591263

Epoch: 6| Step: 4
Training loss: 2.0460164546966553
Validation loss: 2.2017492709621305

Epoch: 6| Step: 5
Training loss: 2.7620725631713867
Validation loss: 2.2022617632342922

Epoch: 6| Step: 6
Training loss: 2.791646957397461
Validation loss: 2.1987374341616066

Epoch: 6| Step: 7
Training loss: 2.666961908340454
Validation loss: 2.1791066072320424

Epoch: 6| Step: 8
Training loss: 2.2913999557495117
Validation loss: 2.184858722071494

Epoch: 6| Step: 9
Training loss: 2.402456760406494
Validation loss: 2.183373917815506

Epoch: 6| Step: 10
Training loss: 2.317214012145996
Validation loss: 2.20705763242578

Epoch: 6| Step: 11
Training loss: 2.3135862350463867
Validation loss: 2.211198934944727

Epoch: 6| Step: 12
Training loss: 2.5248241424560547
Validation loss: 2.228028446115473

Epoch: 6| Step: 13
Training loss: 3.0678253173828125
Validation loss: 2.2171195886468373

Epoch: 58| Step: 0
Training loss: 2.328148365020752
Validation loss: 2.196191692865023

Epoch: 6| Step: 1
Training loss: 2.6109468936920166
Validation loss: 2.1727773194671958

Epoch: 6| Step: 2
Training loss: 1.681492805480957
Validation loss: 2.165901061027281

Epoch: 6| Step: 3
Training loss: 3.0227434635162354
Validation loss: 2.1565423088689006

Epoch: 6| Step: 4
Training loss: 2.2859010696411133
Validation loss: 2.152814660021054

Epoch: 6| Step: 5
Training loss: 2.685336112976074
Validation loss: 2.157050427570138

Epoch: 6| Step: 6
Training loss: 2.069399118423462
Validation loss: 2.155101954296071

Epoch: 6| Step: 7
Training loss: 2.0127687454223633
Validation loss: 2.158342174304429

Epoch: 6| Step: 8
Training loss: 2.8809704780578613
Validation loss: 2.1617457764123076

Epoch: 6| Step: 9
Training loss: 2.33944034576416
Validation loss: 2.1663970588355936

Epoch: 6| Step: 10
Training loss: 2.2312393188476562
Validation loss: 2.186310150290048

Epoch: 6| Step: 11
Training loss: 2.789806365966797
Validation loss: 2.1971062819163003

Epoch: 6| Step: 12
Training loss: 2.72184681892395
Validation loss: 2.205090848348474

Epoch: 6| Step: 13
Training loss: 3.341674566268921
Validation loss: 2.2101564535530667

Epoch: 59| Step: 0
Training loss: 2.6237287521362305
Validation loss: 2.2090096589057677

Epoch: 6| Step: 1
Training loss: 1.5965814590454102
Validation loss: 2.197665875957858

Epoch: 6| Step: 2
Training loss: 2.4358487129211426
Validation loss: 2.1849874809224117

Epoch: 6| Step: 3
Training loss: 2.7746782302856445
Validation loss: 2.1761616506884174

Epoch: 6| Step: 4
Training loss: 2.3502373695373535
Validation loss: 2.158390737348987

Epoch: 6| Step: 5
Training loss: 2.9719364643096924
Validation loss: 2.1546124001984954

Epoch: 6| Step: 6
Training loss: 2.6794939041137695
Validation loss: 2.158781636145807

Epoch: 6| Step: 7
Training loss: 2.939323902130127
Validation loss: 2.1613864949954453

Epoch: 6| Step: 8
Training loss: 2.996273994445801
Validation loss: 2.1673156933117936

Epoch: 6| Step: 9
Training loss: 1.9404752254486084
Validation loss: 2.1561154857758553

Epoch: 6| Step: 10
Training loss: 2.6096296310424805
Validation loss: 2.1595830635357927

Epoch: 6| Step: 11
Training loss: 2.3392772674560547
Validation loss: 2.150412864582513

Epoch: 6| Step: 12
Training loss: 2.0326602458953857
Validation loss: 2.1499996877485708

Epoch: 6| Step: 13
Training loss: 1.902921438217163
Validation loss: 2.156953396335725

Epoch: 60| Step: 0
Training loss: 2.4522345066070557
Validation loss: 2.164400457054056

Epoch: 6| Step: 1
Training loss: 1.3082845211029053
Validation loss: 2.1719166591603267

Epoch: 6| Step: 2
Training loss: 2.9160265922546387
Validation loss: 2.197928359431605

Epoch: 6| Step: 3
Training loss: 2.4232845306396484
Validation loss: 2.2028608809235277

Epoch: 6| Step: 4
Training loss: 3.0180721282958984
Validation loss: 2.2037200004823747

Epoch: 6| Step: 5
Training loss: 2.3686540126800537
Validation loss: 2.2007774383791032

Epoch: 6| Step: 6
Training loss: 2.0408146381378174
Validation loss: 2.18870436504323

Epoch: 6| Step: 7
Training loss: 2.654109001159668
Validation loss: 2.1721847275251984

Epoch: 6| Step: 8
Training loss: 2.2788643836975098
Validation loss: 2.1638315903243197

Epoch: 6| Step: 9
Training loss: 2.4243521690368652
Validation loss: 2.1533654223206224

Epoch: 6| Step: 10
Training loss: 2.895728826522827
Validation loss: 2.145835450900498

Epoch: 6| Step: 11
Training loss: 2.527998685836792
Validation loss: 2.1442149018728607

Epoch: 6| Step: 12
Training loss: 2.7534332275390625
Validation loss: 2.133054925549415

Epoch: 6| Step: 13
Training loss: 2.1971302032470703
Validation loss: 2.134903787284769

Epoch: 61| Step: 0
Training loss: 2.209906578063965
Validation loss: 2.169647906416206

Epoch: 6| Step: 1
Training loss: 2.7290687561035156
Validation loss: 2.2002056978082143

Epoch: 6| Step: 2
Training loss: 2.851790428161621
Validation loss: 2.217804355006064

Epoch: 6| Step: 3
Training loss: 2.9213075637817383
Validation loss: 2.2164648963559057

Epoch: 6| Step: 4
Training loss: 2.31850004196167
Validation loss: 2.229072152927358

Epoch: 6| Step: 5
Training loss: 0.8833479285240173
Validation loss: 2.2243638243726505

Epoch: 6| Step: 6
Training loss: 1.9768729209899902
Validation loss: 2.236832449513097

Epoch: 6| Step: 7
Training loss: 2.8152718544006348
Validation loss: 2.2584199008121284

Epoch: 6| Step: 8
Training loss: 1.8769643306732178
Validation loss: 2.256988981718658

Epoch: 6| Step: 9
Training loss: 3.098879814147949
Validation loss: 2.25091201771972

Epoch: 6| Step: 10
Training loss: 3.0082874298095703
Validation loss: 2.236554184267598

Epoch: 6| Step: 11
Training loss: 2.6688852310180664
Validation loss: 2.207226789125832

Epoch: 6| Step: 12
Training loss: 2.4674413204193115
Validation loss: 2.1844004738715386

Epoch: 6| Step: 13
Training loss: 3.2572617530822754
Validation loss: 2.1761336224053496

Epoch: 62| Step: 0
Training loss: 2.4288158416748047
Validation loss: 2.1702068339111986

Epoch: 6| Step: 1
Training loss: 2.807569980621338
Validation loss: 2.1682881027139644

Epoch: 6| Step: 2
Training loss: 2.7174153327941895
Validation loss: 2.161947670803275

Epoch: 6| Step: 3
Training loss: 2.2675955295562744
Validation loss: 2.1545114876121603

Epoch: 6| Step: 4
Training loss: 2.2577619552612305
Validation loss: 2.147992298167239

Epoch: 6| Step: 5
Training loss: 1.8214945793151855
Validation loss: 2.1340773977259153

Epoch: 6| Step: 6
Training loss: 2.4498348236083984
Validation loss: 2.1375829455673054

Epoch: 6| Step: 7
Training loss: 2.2573156356811523
Validation loss: 2.1364227494885846

Epoch: 6| Step: 8
Training loss: 3.2130284309387207
Validation loss: 2.136229766312466

Epoch: 6| Step: 9
Training loss: 2.7032039165496826
Validation loss: 2.15297193168312

Epoch: 6| Step: 10
Training loss: 2.549550771713257
Validation loss: 2.1653919040515857

Epoch: 6| Step: 11
Training loss: 2.2284765243530273
Validation loss: 2.1974190063374017

Epoch: 6| Step: 12
Training loss: 2.489797830581665
Validation loss: 2.2203381215372393

Epoch: 6| Step: 13
Training loss: 2.532449960708618
Validation loss: 2.2269602180809103

Epoch: 63| Step: 0
Training loss: 2.385148048400879
Validation loss: 2.179617081919024

Epoch: 6| Step: 1
Training loss: 2.6441144943237305
Validation loss: 2.156985516189247

Epoch: 6| Step: 2
Training loss: 2.4028048515319824
Validation loss: 2.145029185920633

Epoch: 6| Step: 3
Training loss: 2.3966784477233887
Validation loss: 2.131319502348541

Epoch: 6| Step: 4
Training loss: 2.0107421875
Validation loss: 2.120452360440326

Epoch: 6| Step: 5
Training loss: 2.510237693786621
Validation loss: 2.116043602266619

Epoch: 6| Step: 6
Training loss: 2.1710901260375977
Validation loss: 2.1137645821417532

Epoch: 6| Step: 7
Training loss: 2.1924586296081543
Validation loss: 2.1197042003754647

Epoch: 6| Step: 8
Training loss: 2.890501022338867
Validation loss: 2.1179839564907934

Epoch: 6| Step: 9
Training loss: 2.75142502784729
Validation loss: 2.1213400825377433

Epoch: 6| Step: 10
Training loss: 2.4916067123413086
Validation loss: 2.123558972471504

Epoch: 6| Step: 11
Training loss: 2.418393850326538
Validation loss: 2.1290642894724363

Epoch: 6| Step: 12
Training loss: 2.4118785858154297
Validation loss: 2.132004658381144

Epoch: 6| Step: 13
Training loss: 2.1557583808898926
Validation loss: 2.13914853783064

Epoch: 64| Step: 0
Training loss: 2.018170118331909
Validation loss: 2.138542398329704

Epoch: 6| Step: 1
Training loss: 3.204564094543457
Validation loss: 2.1429973776622484

Epoch: 6| Step: 2
Training loss: 2.3751659393310547
Validation loss: 2.156406335933234

Epoch: 6| Step: 3
Training loss: 1.8207534551620483
Validation loss: 2.170218224166542

Epoch: 6| Step: 4
Training loss: 2.6816444396972656
Validation loss: 2.185463099069493

Epoch: 6| Step: 5
Training loss: 1.9233899116516113
Validation loss: 2.1879106196024085

Epoch: 6| Step: 6
Training loss: 2.294886589050293
Validation loss: 2.1758741486457085

Epoch: 6| Step: 7
Training loss: 3.2747788429260254
Validation loss: 2.151962867347143

Epoch: 6| Step: 8
Training loss: 1.8060706853866577
Validation loss: 2.1458139983556603

Epoch: 6| Step: 9
Training loss: 2.7955474853515625
Validation loss: 2.127845407814108

Epoch: 6| Step: 10
Training loss: 2.2286744117736816
Validation loss: 2.1082871575509348

Epoch: 6| Step: 11
Training loss: 2.4419326782226562
Validation loss: 2.107852018007668

Epoch: 6| Step: 12
Training loss: 2.444014310836792
Validation loss: 2.1004578785229753

Epoch: 6| Step: 13
Training loss: 2.7973978519439697
Validation loss: 2.100822238511937

Epoch: 65| Step: 0
Training loss: 2.7828803062438965
Validation loss: 2.0957898145080893

Epoch: 6| Step: 1
Training loss: 2.4896109104156494
Validation loss: 2.093805252864797

Epoch: 6| Step: 2
Training loss: 2.9133036136627197
Validation loss: 2.098433197185557

Epoch: 6| Step: 3
Training loss: 2.065178394317627
Validation loss: 2.1063670881332888

Epoch: 6| Step: 4
Training loss: 2.1218299865722656
Validation loss: 2.106870884536415

Epoch: 6| Step: 5
Training loss: 2.4922103881835938
Validation loss: 2.10889986894464

Epoch: 6| Step: 6
Training loss: 2.2007253170013428
Validation loss: 2.1252577163839854

Epoch: 6| Step: 7
Training loss: 1.9991955757141113
Validation loss: 2.141928090844103

Epoch: 6| Step: 8
Training loss: 2.7030203342437744
Validation loss: 2.1745600085104666

Epoch: 6| Step: 9
Training loss: 2.2961249351501465
Validation loss: 2.172799551358787

Epoch: 6| Step: 10
Training loss: 3.1907618045806885
Validation loss: 2.162295215873308

Epoch: 6| Step: 11
Training loss: 2.755455493927002
Validation loss: 2.17149491207574

Epoch: 6| Step: 12
Training loss: 1.8292042016983032
Validation loss: 2.1736219339473273

Epoch: 6| Step: 13
Training loss: 1.985769271850586
Validation loss: 2.1664185472714004

Epoch: 66| Step: 0
Training loss: 2.0343406200408936
Validation loss: 2.1420091967428885

Epoch: 6| Step: 1
Training loss: 2.365403413772583
Validation loss: 2.1298356774032756

Epoch: 6| Step: 2
Training loss: 2.468228340148926
Validation loss: 2.113545366512832

Epoch: 6| Step: 3
Training loss: 1.7265987396240234
Validation loss: 2.1033691590832126

Epoch: 6| Step: 4
Training loss: 2.627192497253418
Validation loss: 2.1097067389436948

Epoch: 6| Step: 5
Training loss: 1.9991636276245117
Validation loss: 2.0983201021789224

Epoch: 6| Step: 6
Training loss: 3.380992889404297
Validation loss: 2.092978431332496

Epoch: 6| Step: 7
Training loss: 2.2390246391296387
Validation loss: 2.088551016264064

Epoch: 6| Step: 8
Training loss: 2.1617608070373535
Validation loss: 2.088534252617949

Epoch: 6| Step: 9
Training loss: 2.3175952434539795
Validation loss: 2.0877981775550434

Epoch: 6| Step: 10
Training loss: 2.670403480529785
Validation loss: 2.099611766876713

Epoch: 6| Step: 11
Training loss: 2.36411452293396
Validation loss: 2.1146926315881873

Epoch: 6| Step: 12
Training loss: 2.805881977081299
Validation loss: 2.1201753731696837

Epoch: 6| Step: 13
Training loss: 2.4922075271606445
Validation loss: 2.1404726607825166

Epoch: 67| Step: 0
Training loss: 2.505918025970459
Validation loss: 2.143375148055374

Epoch: 6| Step: 1
Training loss: 1.665045142173767
Validation loss: 2.1404828179267144

Epoch: 6| Step: 2
Training loss: 2.8121862411499023
Validation loss: 2.124338734534479

Epoch: 6| Step: 3
Training loss: 2.232553243637085
Validation loss: 2.108790300225699

Epoch: 6| Step: 4
Training loss: 2.544731616973877
Validation loss: 2.0991653691055956

Epoch: 6| Step: 5
Training loss: 2.5985770225524902
Validation loss: 2.0922386377088484

Epoch: 6| Step: 6
Training loss: 1.749772071838379
Validation loss: 2.095682167237805

Epoch: 6| Step: 7
Training loss: 1.9911243915557861
Validation loss: 2.1005650835652507

Epoch: 6| Step: 8
Training loss: 2.805288314819336
Validation loss: 2.10243438008011

Epoch: 6| Step: 9
Training loss: 2.7222795486450195
Validation loss: 2.1055558061087005

Epoch: 6| Step: 10
Training loss: 2.0964765548706055
Validation loss: 2.1135399008309967

Epoch: 6| Step: 11
Training loss: 2.6419830322265625
Validation loss: 2.1134820471527758

Epoch: 6| Step: 12
Training loss: 2.7077407836914062
Validation loss: 2.1165653915815454

Epoch: 6| Step: 13
Training loss: 2.3413045406341553
Validation loss: 2.1078624468977734

Epoch: 68| Step: 0
Training loss: 1.856978416442871
Validation loss: 2.0959486871637325

Epoch: 6| Step: 1
Training loss: 2.0659539699554443
Validation loss: 2.089807043793381

Epoch: 6| Step: 2
Training loss: 1.5907000303268433
Validation loss: 2.0870794891029276

Epoch: 6| Step: 3
Training loss: 2.6879405975341797
Validation loss: 2.0807477863886024

Epoch: 6| Step: 4
Training loss: 2.743269681930542
Validation loss: 2.079802087558213

Epoch: 6| Step: 5
Training loss: 2.876725673675537
Validation loss: 2.0774394363485356

Epoch: 6| Step: 6
Training loss: 2.39928936958313
Validation loss: 2.074949754181729

Epoch: 6| Step: 7
Training loss: 2.5063281059265137
Validation loss: 2.064815095675889

Epoch: 6| Step: 8
Training loss: 1.8679298162460327
Validation loss: 2.072636628663668

Epoch: 6| Step: 9
Training loss: 2.816101312637329
Validation loss: 2.0806208887407855

Epoch: 6| Step: 10
Training loss: 2.009176254272461
Validation loss: 2.1050688758973153

Epoch: 6| Step: 11
Training loss: 2.3609535694122314
Validation loss: 2.1323537775265273

Epoch: 6| Step: 12
Training loss: 3.098336696624756
Validation loss: 2.1790691421877955

Epoch: 6| Step: 13
Training loss: 2.8158016204833984
Validation loss: 2.2150940407988844

Epoch: 69| Step: 0
Training loss: 2.006930351257324
Validation loss: 2.2023232829186226

Epoch: 6| Step: 1
Training loss: 2.434661865234375
Validation loss: 2.13670104037049

Epoch: 6| Step: 2
Training loss: 2.2905354499816895
Validation loss: 2.082162143081747

Epoch: 6| Step: 3
Training loss: 2.3270423412323
Validation loss: 2.067868371163645

Epoch: 6| Step: 4
Training loss: 3.1207292079925537
Validation loss: 2.0695275145192302

Epoch: 6| Step: 5
Training loss: 2.831725835800171
Validation loss: 2.0835056843296176

Epoch: 6| Step: 6
Training loss: 1.8147141933441162
Validation loss: 2.0949160642521356

Epoch: 6| Step: 7
Training loss: 2.031907081604004
Validation loss: 2.1039921083757953

Epoch: 6| Step: 8
Training loss: 2.670942783355713
Validation loss: 2.1114007196118756

Epoch: 6| Step: 9
Training loss: 2.099486827850342
Validation loss: 2.1269790536613873

Epoch: 6| Step: 10
Training loss: 2.845604419708252
Validation loss: 2.1196047849552606

Epoch: 6| Step: 11
Training loss: 2.558664321899414
Validation loss: 2.1012616388259397

Epoch: 6| Step: 12
Training loss: 2.955808162689209
Validation loss: 2.1020687600617767

Epoch: 6| Step: 13
Training loss: 1.848968505859375
Validation loss: 2.1204637378774662

Epoch: 70| Step: 0
Training loss: 2.1521780490875244
Validation loss: 2.143956063896097

Epoch: 6| Step: 1
Training loss: 2.839716672897339
Validation loss: 2.208381542595484

Epoch: 6| Step: 2
Training loss: 2.031330108642578
Validation loss: 2.30232512053623

Epoch: 6| Step: 3
Training loss: 2.5259718894958496
Validation loss: 2.3597191379916285

Epoch: 6| Step: 4
Training loss: 2.7066707611083984
Validation loss: 2.396318963778916

Epoch: 6| Step: 5
Training loss: 1.8921501636505127
Validation loss: 2.4009937855505172

Epoch: 6| Step: 6
Training loss: 2.516638994216919
Validation loss: 2.362147746547576

Epoch: 6| Step: 7
Training loss: 2.3382761478424072
Validation loss: 2.2997113940536336

Epoch: 6| Step: 8
Training loss: 2.748642683029175
Validation loss: 2.21773874375128

Epoch: 6| Step: 9
Training loss: 2.5528252124786377
Validation loss: 2.1318444590414725

Epoch: 6| Step: 10
Training loss: 2.6698923110961914
Validation loss: 2.1007995656741563

Epoch: 6| Step: 11
Training loss: 2.746204137802124
Validation loss: 2.081726763838081

Epoch: 6| Step: 12
Training loss: 2.203444242477417
Validation loss: 2.085103614355928

Epoch: 6| Step: 13
Training loss: 2.6341018676757812
Validation loss: 2.0956292434405257

Epoch: 71| Step: 0
Training loss: 2.5554215908050537
Validation loss: 2.117177019837082

Epoch: 6| Step: 1
Training loss: 2.3688979148864746
Validation loss: 2.1333476215280514

Epoch: 6| Step: 2
Training loss: 2.852206230163574
Validation loss: 2.1501530780587146

Epoch: 6| Step: 3
Training loss: 2.595459222793579
Validation loss: 2.130094374379804

Epoch: 6| Step: 4
Training loss: 2.01824951171875
Validation loss: 2.1168568659854192

Epoch: 6| Step: 5
Training loss: 2.7920727729797363
Validation loss: 2.101507762426971

Epoch: 6| Step: 6
Training loss: 2.2282276153564453
Validation loss: 2.084047894324026

Epoch: 6| Step: 7
Training loss: 2.63725209236145
Validation loss: 2.089531276815681

Epoch: 6| Step: 8
Training loss: 1.5857857465744019
Validation loss: 2.097790677060363

Epoch: 6| Step: 9
Training loss: 2.5194921493530273
Validation loss: 2.1288002050051125

Epoch: 6| Step: 10
Training loss: 3.021557331085205
Validation loss: 2.1342997192054667

Epoch: 6| Step: 11
Training loss: 1.8629781007766724
Validation loss: 2.0987689687359716

Epoch: 6| Step: 12
Training loss: 2.275881290435791
Validation loss: 2.082248754398797

Epoch: 6| Step: 13
Training loss: 2.7820992469787598
Validation loss: 2.0749901674127065

Epoch: 72| Step: 0
Training loss: 2.743859052658081
Validation loss: 2.070460964274663

Epoch: 6| Step: 1
Training loss: 1.9881324768066406
Validation loss: 2.0686421625075804

Epoch: 6| Step: 2
Training loss: 2.252930164337158
Validation loss: 2.069031346228815

Epoch: 6| Step: 3
Training loss: 2.2107157707214355
Validation loss: 2.0814634305174633

Epoch: 6| Step: 4
Training loss: 1.939300537109375
Validation loss: 2.0807050415264663

Epoch: 6| Step: 5
Training loss: 2.7566213607788086
Validation loss: 2.0884308071546656

Epoch: 6| Step: 6
Training loss: 2.8899483680725098
Validation loss: 2.083997672603976

Epoch: 6| Step: 7
Training loss: 2.408327579498291
Validation loss: 2.0824267018225884

Epoch: 6| Step: 8
Training loss: 2.492990493774414
Validation loss: 2.079807186639437

Epoch: 6| Step: 9
Training loss: 2.171261787414551
Validation loss: 2.090997730532

Epoch: 6| Step: 10
Training loss: 2.3113226890563965
Validation loss: 2.084500869115194

Epoch: 6| Step: 11
Training loss: 2.4955291748046875
Validation loss: 2.07484600364521

Epoch: 6| Step: 12
Training loss: 2.57716703414917
Validation loss: 2.0634554124647573

Epoch: 6| Step: 13
Training loss: 1.751463770866394
Validation loss: 2.065409750066778

Epoch: 73| Step: 0
Training loss: 1.7921990156173706
Validation loss: 2.0779392642359578

Epoch: 6| Step: 1
Training loss: 2.70749568939209
Validation loss: 2.0832132600968882

Epoch: 6| Step: 2
Training loss: 2.0225250720977783
Validation loss: 2.0954672264796432

Epoch: 6| Step: 3
Training loss: 2.2363250255584717
Validation loss: 2.1104636141048965

Epoch: 6| Step: 4
Training loss: 2.876199722290039
Validation loss: 2.0888272023970083

Epoch: 6| Step: 5
Training loss: 1.9967011213302612
Validation loss: 2.0950690918071295

Epoch: 6| Step: 6
Training loss: 2.636765241622925
Validation loss: 2.1086598442446802

Epoch: 6| Step: 7
Training loss: 1.8726203441619873
Validation loss: 2.122673590977987

Epoch: 6| Step: 8
Training loss: 2.6635336875915527
Validation loss: 2.12376933328567

Epoch: 6| Step: 9
Training loss: 2.803410530090332
Validation loss: 2.1018986983965804

Epoch: 6| Step: 10
Training loss: 2.066237449645996
Validation loss: 2.093862292587116

Epoch: 6| Step: 11
Training loss: 2.0676894187927246
Validation loss: 2.0717534608738397

Epoch: 6| Step: 12
Training loss: 2.6835217475891113
Validation loss: 2.069743411515349

Epoch: 6| Step: 13
Training loss: 3.039421558380127
Validation loss: 2.0526372886473134

Epoch: 74| Step: 0
Training loss: 1.755983591079712
Validation loss: 2.0440431769176195

Epoch: 6| Step: 1
Training loss: 2.7858924865722656
Validation loss: 2.0429457413252963

Epoch: 6| Step: 2
Training loss: 2.118772029876709
Validation loss: 2.0377633956170853

Epoch: 6| Step: 3
Training loss: 2.3780622482299805
Validation loss: 2.036887397048294

Epoch: 6| Step: 4
Training loss: 2.5801305770874023
Validation loss: 2.0386450021497664

Epoch: 6| Step: 5
Training loss: 2.274138927459717
Validation loss: 2.0450911009183494

Epoch: 6| Step: 6
Training loss: 2.058953285217285
Validation loss: 2.061784836553758

Epoch: 6| Step: 7
Training loss: 2.4001736640930176
Validation loss: 2.077177099002305

Epoch: 6| Step: 8
Training loss: 2.7656657695770264
Validation loss: 2.1052415332486554

Epoch: 6| Step: 9
Training loss: 1.8861373662948608
Validation loss: 2.11958896985618

Epoch: 6| Step: 10
Training loss: 2.6415863037109375
Validation loss: 2.1177046632253997

Epoch: 6| Step: 11
Training loss: 3.0011374950408936
Validation loss: 2.1023437669200282

Epoch: 6| Step: 12
Training loss: 2.118525505065918
Validation loss: 2.0768428515362483

Epoch: 6| Step: 13
Training loss: 2.363602876663208
Validation loss: 2.050459870728113

Epoch: 75| Step: 0
Training loss: 2.749497890472412
Validation loss: 2.030212935581002

Epoch: 6| Step: 1
Training loss: 2.5903592109680176
Validation loss: 2.0231993429122435

Epoch: 6| Step: 2
Training loss: 1.6429030895233154
Validation loss: 2.0229819974591656

Epoch: 6| Step: 3
Training loss: 2.380903720855713
Validation loss: 2.0284212020135697

Epoch: 6| Step: 4
Training loss: 2.1864161491394043
Validation loss: 2.0279174914924045

Epoch: 6| Step: 5
Training loss: 2.285050868988037
Validation loss: 2.0352533273799445

Epoch: 6| Step: 6
Training loss: 2.544741153717041
Validation loss: 2.0552708307902017

Epoch: 6| Step: 7
Training loss: 2.053997755050659
Validation loss: 2.058637870255337

Epoch: 6| Step: 8
Training loss: 2.4722142219543457
Validation loss: 2.069210701091315

Epoch: 6| Step: 9
Training loss: 2.2870538234710693
Validation loss: 2.0770818571890555

Epoch: 6| Step: 10
Training loss: 2.0420732498168945
Validation loss: 2.085084658797069

Epoch: 6| Step: 11
Training loss: 2.741466522216797
Validation loss: 2.071973118730771

Epoch: 6| Step: 12
Training loss: 2.470808982849121
Validation loss: 2.0647090070991108

Epoch: 6| Step: 13
Training loss: 2.827493190765381
Validation loss: 2.053978778982675

Epoch: 76| Step: 0
Training loss: 2.493300437927246
Validation loss: 2.034379246414349

Epoch: 6| Step: 1
Training loss: 2.7152881622314453
Validation loss: 2.0381430605406403

Epoch: 6| Step: 2
Training loss: 2.5054359436035156
Validation loss: 2.0348981465062788

Epoch: 6| Step: 3
Training loss: 2.0344080924987793
Validation loss: 2.0383926873566

Epoch: 6| Step: 4
Training loss: 2.3576865196228027
Validation loss: 2.0353841320160897

Epoch: 6| Step: 5
Training loss: 2.543633460998535
Validation loss: 2.035128558835676

Epoch: 6| Step: 6
Training loss: 1.5451381206512451
Validation loss: 2.035479017483291

Epoch: 6| Step: 7
Training loss: 1.8871406316757202
Validation loss: 2.0323831983791885

Epoch: 6| Step: 8
Training loss: 2.2990262508392334
Validation loss: 2.055300251130135

Epoch: 6| Step: 9
Training loss: 2.1738409996032715
Validation loss: 2.08010236806767

Epoch: 6| Step: 10
Training loss: 2.5201046466827393
Validation loss: 2.1289624462845507

Epoch: 6| Step: 11
Training loss: 2.5759594440460205
Validation loss: 2.1617746878695745

Epoch: 6| Step: 12
Training loss: 2.801438331604004
Validation loss: 2.2155513763427734

Epoch: 6| Step: 13
Training loss: 2.8766391277313232
Validation loss: 2.2434853520444644

Epoch: 77| Step: 0
Training loss: 2.762449264526367
Validation loss: 2.258405080405615

Epoch: 6| Step: 1
Training loss: 2.4958105087280273
Validation loss: 2.2306361326607327

Epoch: 6| Step: 2
Training loss: 2.4285621643066406
Validation loss: 2.176037288481189

Epoch: 6| Step: 3
Training loss: 2.6888298988342285
Validation loss: 2.136962248433021

Epoch: 6| Step: 4
Training loss: 1.6693425178527832
Validation loss: 2.0962943159123903

Epoch: 6| Step: 5
Training loss: 2.01017427444458
Validation loss: 2.0694251163031465

Epoch: 6| Step: 6
Training loss: 2.3596880435943604
Validation loss: 2.0534085355779177

Epoch: 6| Step: 7
Training loss: 2.2618050575256348
Validation loss: 2.040103250934232

Epoch: 6| Step: 8
Training loss: 2.5843467712402344
Validation loss: 2.0390226469245007

Epoch: 6| Step: 9
Training loss: 1.4350146055221558
Validation loss: 2.04038913788334

Epoch: 6| Step: 10
Training loss: 2.4226841926574707
Validation loss: 2.0383312061268795

Epoch: 6| Step: 11
Training loss: 2.855287551879883
Validation loss: 2.0392970346635386

Epoch: 6| Step: 12
Training loss: 2.320173740386963
Validation loss: 2.0289069170592935

Epoch: 6| Step: 13
Training loss: 2.938342571258545
Validation loss: 2.0280403885790097

Epoch: 78| Step: 0
Training loss: 2.889984130859375
Validation loss: 2.0205836962628108

Epoch: 6| Step: 1
Training loss: 3.3035902976989746
Validation loss: 2.0143579629159745

Epoch: 6| Step: 2
Training loss: 1.7718846797943115
Validation loss: 2.0112814531531384

Epoch: 6| Step: 3
Training loss: 1.7409783601760864
Validation loss: 2.011491105120669

Epoch: 6| Step: 4
Training loss: 2.076361656188965
Validation loss: 2.0167244570229643

Epoch: 6| Step: 5
Training loss: 2.815518856048584
Validation loss: 2.015598071518765

Epoch: 6| Step: 6
Training loss: 2.47056245803833
Validation loss: 2.0249988904563327

Epoch: 6| Step: 7
Training loss: 2.169833183288574
Validation loss: 2.0354727237455306

Epoch: 6| Step: 8
Training loss: 2.5811522006988525
Validation loss: 2.0373060575095554

Epoch: 6| Step: 9
Training loss: 1.9718520641326904
Validation loss: 2.0593066600061234

Epoch: 6| Step: 10
Training loss: 2.585505962371826
Validation loss: 2.0556536515553794

Epoch: 6| Step: 11
Training loss: 1.708613634109497
Validation loss: 2.0357246732199066

Epoch: 6| Step: 12
Training loss: 2.2013659477233887
Validation loss: 2.022420838315

Epoch: 6| Step: 13
Training loss: 2.6044836044311523
Validation loss: 2.0139658463898527

Epoch: 79| Step: 0
Training loss: 2.9178225994110107
Validation loss: 2.01531716315977

Epoch: 6| Step: 1
Training loss: 2.9219412803649902
Validation loss: 2.011915344063954

Epoch: 6| Step: 2
Training loss: 2.4361634254455566
Validation loss: 2.012200552930114

Epoch: 6| Step: 3
Training loss: 1.983386516571045
Validation loss: 2.008715396286339

Epoch: 6| Step: 4
Training loss: 2.7304844856262207
Validation loss: 2.006672320827361

Epoch: 6| Step: 5
Training loss: 2.00997257232666
Validation loss: 2.0031561620773806

Epoch: 6| Step: 6
Training loss: 1.9694697856903076
Validation loss: 2.0158588450442076

Epoch: 6| Step: 7
Training loss: 2.314000129699707
Validation loss: 2.0208864583764026

Epoch: 6| Step: 8
Training loss: 2.556002140045166
Validation loss: 2.0310602713656682

Epoch: 6| Step: 9
Training loss: 2.1593503952026367
Validation loss: 2.019330724593132

Epoch: 6| Step: 10
Training loss: 2.520918369293213
Validation loss: 2.0077769294861825

Epoch: 6| Step: 11
Training loss: 2.2894420623779297
Validation loss: 1.9987079917743642

Epoch: 6| Step: 12
Training loss: 1.6536980867385864
Validation loss: 2.0005773344347553

Epoch: 6| Step: 13
Training loss: 2.5140764713287354
Validation loss: 2.0024287944198935

Epoch: 80| Step: 0
Training loss: 2.2011094093322754
Validation loss: 2.0025075238238097

Epoch: 6| Step: 1
Training loss: 2.7856221199035645
Validation loss: 2.012087486123526

Epoch: 6| Step: 2
Training loss: 2.2255091667175293
Validation loss: 2.020096130268548

Epoch: 6| Step: 3
Training loss: 2.45806884765625
Validation loss: 2.028413026563583

Epoch: 6| Step: 4
Training loss: 2.5277328491210938
Validation loss: 2.0267429479988675

Epoch: 6| Step: 5
Training loss: 2.2991433143615723
Validation loss: 2.050535957018534

Epoch: 6| Step: 6
Training loss: 1.7385649681091309
Validation loss: 2.0622084474050872

Epoch: 6| Step: 7
Training loss: 2.6551246643066406
Validation loss: 2.0683869764369023

Epoch: 6| Step: 8
Training loss: 2.584991455078125
Validation loss: 2.058720919393724

Epoch: 6| Step: 9
Training loss: 1.9169526100158691
Validation loss: 2.053009489531158

Epoch: 6| Step: 10
Training loss: 2.624971866607666
Validation loss: 2.013301646837624

Epoch: 6| Step: 11
Training loss: 1.9656805992126465
Validation loss: 2.010805312023368

Epoch: 6| Step: 12
Training loss: 2.259035110473633
Validation loss: 2.0139803860777166

Epoch: 6| Step: 13
Training loss: 2.556908369064331
Validation loss: 2.0062470307914158

Epoch: 81| Step: 0
Training loss: 2.811253070831299
Validation loss: 2.007419806654735

Epoch: 6| Step: 1
Training loss: 2.071848154067993
Validation loss: 2.0124011629371235

Epoch: 6| Step: 2
Training loss: 2.1394028663635254
Validation loss: 2.0222143229617866

Epoch: 6| Step: 3
Training loss: 2.471386671066284
Validation loss: 2.030362957267351

Epoch: 6| Step: 4
Training loss: 2.413992404937744
Validation loss: 2.0385003500087286

Epoch: 6| Step: 5
Training loss: 2.365116596221924
Validation loss: 2.0512824737897484

Epoch: 6| Step: 6
Training loss: 2.726547956466675
Validation loss: 2.0554665288617535

Epoch: 6| Step: 7
Training loss: 1.9679133892059326
Validation loss: 2.0405080715815225

Epoch: 6| Step: 8
Training loss: 2.844571113586426
Validation loss: 2.036169167487852

Epoch: 6| Step: 9
Training loss: 2.7117738723754883
Validation loss: 2.0206164954811014

Epoch: 6| Step: 10
Training loss: 1.9633256196975708
Validation loss: 2.0088421862612487

Epoch: 6| Step: 11
Training loss: 1.832352638244629
Validation loss: 2.009315453549867

Epoch: 6| Step: 12
Training loss: 1.8232946395874023
Validation loss: 2.008667379297236

Epoch: 6| Step: 13
Training loss: 2.3832340240478516
Validation loss: 2.0247391295689408

Epoch: 82| Step: 0
Training loss: 2.3448452949523926
Validation loss: 2.035388603005358

Epoch: 6| Step: 1
Training loss: 2.822826623916626
Validation loss: 2.053205032502451

Epoch: 6| Step: 2
Training loss: 2.5397305488586426
Validation loss: 2.0568570936879804

Epoch: 6| Step: 3
Training loss: 1.80253267288208
Validation loss: 2.0719906181417485

Epoch: 6| Step: 4
Training loss: 3.0825705528259277
Validation loss: 2.055931609164002

Epoch: 6| Step: 5
Training loss: 2.323821783065796
Validation loss: 2.047290794311031

Epoch: 6| Step: 6
Training loss: 2.2701778411865234
Validation loss: 2.03213543404815

Epoch: 6| Step: 7
Training loss: 2.792435646057129
Validation loss: 2.0140475765351327

Epoch: 6| Step: 8
Training loss: 2.0766453742980957
Validation loss: 2.006817615160378

Epoch: 6| Step: 9
Training loss: 1.9437695741653442
Validation loss: 2.015976114939618

Epoch: 6| Step: 10
Training loss: 2.1941235065460205
Validation loss: 2.0318032721037507

Epoch: 6| Step: 11
Training loss: 1.8909265995025635
Validation loss: 2.0323030448728994

Epoch: 6| Step: 12
Training loss: 2.4257190227508545
Validation loss: 2.028748295640433

Epoch: 6| Step: 13
Training loss: 1.5094579458236694
Validation loss: 2.030842013256524

Epoch: 83| Step: 0
Training loss: 2.450361728668213
Validation loss: 2.0292142450168567

Epoch: 6| Step: 1
Training loss: 2.721770763397217
Validation loss: 2.0203229624737977

Epoch: 6| Step: 2
Training loss: 2.0903830528259277
Validation loss: 2.02397749757254

Epoch: 6| Step: 3
Training loss: 1.6193288564682007
Validation loss: 2.0130580266316733

Epoch: 6| Step: 4
Training loss: 2.1010022163391113
Validation loss: 2.0108371396218576

Epoch: 6| Step: 5
Training loss: 2.176586151123047
Validation loss: 2.004960754866241

Epoch: 6| Step: 6
Training loss: 2.436448574066162
Validation loss: 1.9940125711502568

Epoch: 6| Step: 7
Training loss: 2.4822371006011963
Validation loss: 1.9987213534693564

Epoch: 6| Step: 8
Training loss: 2.0990076065063477
Validation loss: 2.0047817384043047

Epoch: 6| Step: 9
Training loss: 2.853224754333496
Validation loss: 2.012994771362633

Epoch: 6| Step: 10
Training loss: 2.48480224609375
Validation loss: 2.0345300295019664

Epoch: 6| Step: 11
Training loss: 1.6726276874542236
Validation loss: 2.0500754540966404

Epoch: 6| Step: 12
Training loss: 2.8320112228393555
Validation loss: 2.052364671102134

Epoch: 6| Step: 13
Training loss: 2.7174785137176514
Validation loss: 2.043467637031309

Epoch: 84| Step: 0
Training loss: 1.8655766248703003
Validation loss: 2.03224164952514

Epoch: 6| Step: 1
Training loss: 2.1187970638275146
Validation loss: 2.032573643551078

Epoch: 6| Step: 2
Training loss: 2.653958797454834
Validation loss: 2.017225116811773

Epoch: 6| Step: 3
Training loss: 2.4129292964935303
Validation loss: 2.003390412176809

Epoch: 6| Step: 4
Training loss: 2.6804065704345703
Validation loss: 1.9953694215384863

Epoch: 6| Step: 5
Training loss: 2.446564197540283
Validation loss: 1.9969930687258322

Epoch: 6| Step: 6
Training loss: 2.69329833984375
Validation loss: 1.9951952106209212

Epoch: 6| Step: 7
Training loss: 2.5822553634643555
Validation loss: 1.982488944966306

Epoch: 6| Step: 8
Training loss: 2.3454480171203613
Validation loss: 1.9786924264764274

Epoch: 6| Step: 9
Training loss: 2.029874801635742
Validation loss: 1.9936262971611434

Epoch: 6| Step: 10
Training loss: 1.5408058166503906
Validation loss: 1.9929182734540714

Epoch: 6| Step: 11
Training loss: 2.4645838737487793
Validation loss: 2.0055047568454536

Epoch: 6| Step: 12
Training loss: 2.0354743003845215
Validation loss: 2.0045536128423547

Epoch: 6| Step: 13
Training loss: 2.600203514099121
Validation loss: 1.9975151041502595

Epoch: 85| Step: 0
Training loss: 1.9295086860656738
Validation loss: 2.006015805787938

Epoch: 6| Step: 1
Training loss: 1.841054916381836
Validation loss: 2.0190237311906714

Epoch: 6| Step: 2
Training loss: 2.1596150398254395
Validation loss: 2.0289726282960627

Epoch: 6| Step: 3
Training loss: 2.1082005500793457
Validation loss: 2.0266714813888713

Epoch: 6| Step: 4
Training loss: 2.231557607650757
Validation loss: 2.019899361877031

Epoch: 6| Step: 5
Training loss: 2.8249287605285645
Validation loss: 2.013014547286495

Epoch: 6| Step: 6
Training loss: 2.2597994804382324
Validation loss: 1.9983680337987921

Epoch: 6| Step: 7
Training loss: 2.2492165565490723
Validation loss: 1.9986541476300967

Epoch: 6| Step: 8
Training loss: 1.9188003540039062
Validation loss: 1.9946552399666078

Epoch: 6| Step: 9
Training loss: 2.4586997032165527
Validation loss: 1.9986239223070041

Epoch: 6| Step: 10
Training loss: 2.5176589488983154
Validation loss: 2.010612705702423

Epoch: 6| Step: 11
Training loss: 2.656144142150879
Validation loss: 2.010256956982356

Epoch: 6| Step: 12
Training loss: 1.9004673957824707
Validation loss: 2.027383473611647

Epoch: 6| Step: 13
Training loss: 3.470855712890625
Validation loss: 2.031422027977564

Epoch: 86| Step: 0
Training loss: 1.5019993782043457
Validation loss: 2.0219734637968

Epoch: 6| Step: 1
Training loss: 2.413764476776123
Validation loss: 2.034373064194956

Epoch: 6| Step: 2
Training loss: 2.740961790084839
Validation loss: 2.042829158485577

Epoch: 6| Step: 3
Training loss: 1.9480106830596924
Validation loss: 2.0431930570192236

Epoch: 6| Step: 4
Training loss: 2.6901097297668457
Validation loss: 2.033855599741782

Epoch: 6| Step: 5
Training loss: 2.5891470909118652
Validation loss: 2.032564583645072

Epoch: 6| Step: 6
Training loss: 2.479764699935913
Validation loss: 1.9950925906499226

Epoch: 6| Step: 7
Training loss: 1.8911991119384766
Validation loss: 1.9842040769515499

Epoch: 6| Step: 8
Training loss: 2.6662020683288574
Validation loss: 1.9764565549870974

Epoch: 6| Step: 9
Training loss: 2.0347142219543457
Validation loss: 1.9749399026234944

Epoch: 6| Step: 10
Training loss: 2.3870956897735596
Validation loss: 1.979660734053581

Epoch: 6| Step: 11
Training loss: 2.566987991333008
Validation loss: 1.9914054844969062

Epoch: 6| Step: 12
Training loss: 1.3404135704040527
Validation loss: 1.9979612545300556

Epoch: 6| Step: 13
Training loss: 3.387838125228882
Validation loss: 1.9842960667866532

Epoch: 87| Step: 0
Training loss: 2.399542808532715
Validation loss: 1.979909848141414

Epoch: 6| Step: 1
Training loss: 2.316720962524414
Validation loss: 1.9848035996960056

Epoch: 6| Step: 2
Training loss: 2.4008748531341553
Validation loss: 1.9852304291981522

Epoch: 6| Step: 3
Training loss: 2.1780002117156982
Validation loss: 1.9792990889600528

Epoch: 6| Step: 4
Training loss: 2.184296131134033
Validation loss: 1.9755426619642524

Epoch: 6| Step: 5
Training loss: 2.1057889461517334
Validation loss: 1.9776683853518577

Epoch: 6| Step: 6
Training loss: 2.3413825035095215
Validation loss: 2.0069766352253575

Epoch: 6| Step: 7
Training loss: 2.3360610008239746
Validation loss: 2.0137002955200853

Epoch: 6| Step: 8
Training loss: 2.0872678756713867
Validation loss: 2.0220696362116004

Epoch: 6| Step: 9
Training loss: 2.5459036827087402
Validation loss: 2.005907045897617

Epoch: 6| Step: 10
Training loss: 2.364501953125
Validation loss: 1.990832612078677

Epoch: 6| Step: 11
Training loss: 1.8849416971206665
Validation loss: 1.9663145567781182

Epoch: 6| Step: 12
Training loss: 2.028794765472412
Validation loss: 1.9651116363463863

Epoch: 6| Step: 13
Training loss: 3.118483781814575
Validation loss: 1.9771345661532493

Epoch: 88| Step: 0
Training loss: 2.409119129180908
Validation loss: 1.978429421301811

Epoch: 6| Step: 1
Training loss: 2.3777999877929688
Validation loss: 1.9796095150773243

Epoch: 6| Step: 2
Training loss: 2.3798916339874268
Validation loss: 1.9864305501343102

Epoch: 6| Step: 3
Training loss: 2.7903666496276855
Validation loss: 1.9935596258409563

Epoch: 6| Step: 4
Training loss: 2.287877082824707
Validation loss: 2.0148254415040374

Epoch: 6| Step: 5
Training loss: 2.5508553981781006
Validation loss: 2.0516658342012795

Epoch: 6| Step: 6
Training loss: 2.1502981185913086
Validation loss: 2.0739983717600503

Epoch: 6| Step: 7
Training loss: 2.8031368255615234
Validation loss: 2.102499715743526

Epoch: 6| Step: 8
Training loss: 2.106820583343506
Validation loss: 2.11046003782621

Epoch: 6| Step: 9
Training loss: 2.34360671043396
Validation loss: 2.0947132802778676

Epoch: 6| Step: 10
Training loss: 2.3942224979400635
Validation loss: 2.044834554836314

Epoch: 6| Step: 11
Training loss: 1.4893348217010498
Validation loss: 2.0008732400914675

Epoch: 6| Step: 12
Training loss: 2.672287940979004
Validation loss: 1.978629312207622

Epoch: 6| Step: 13
Training loss: 0.9894521236419678
Validation loss: 1.9752213467833817

Epoch: 89| Step: 0
Training loss: 2.593148946762085
Validation loss: 1.9772312154052079

Epoch: 6| Step: 1
Training loss: 2.128218650817871
Validation loss: 1.9784442481174265

Epoch: 6| Step: 2
Training loss: 2.7549514770507812
Validation loss: 1.9903890599486649

Epoch: 6| Step: 3
Training loss: 3.247802495956421
Validation loss: 1.9851936550550564

Epoch: 6| Step: 4
Training loss: 2.238969326019287
Validation loss: 2.004429542890159

Epoch: 6| Step: 5
Training loss: 1.976601481437683
Validation loss: 2.0021285139104372

Epoch: 6| Step: 6
Training loss: 2.3348045349121094
Validation loss: 2.041674106351791

Epoch: 6| Step: 7
Training loss: 2.1604599952697754
Validation loss: 2.068736304518997

Epoch: 6| Step: 8
Training loss: 2.0621397495269775
Validation loss: 2.0820324472201768

Epoch: 6| Step: 9
Training loss: 2.5718374252319336
Validation loss: 2.1011999243049213

Epoch: 6| Step: 10
Training loss: 2.7042324542999268
Validation loss: 2.1203770663148616

Epoch: 6| Step: 11
Training loss: 1.5918961763381958
Validation loss: 2.1262206044248355

Epoch: 6| Step: 12
Training loss: 1.910462737083435
Validation loss: 2.13670011233258

Epoch: 6| Step: 13
Training loss: 2.1949214935302734
Validation loss: 2.1093283571222776

Epoch: 90| Step: 0
Training loss: 2.0043962001800537
Validation loss: 2.0859973225542294

Epoch: 6| Step: 1
Training loss: 1.8775408267974854
Validation loss: 2.0471884768496276

Epoch: 6| Step: 2
Training loss: 2.47451114654541
Validation loss: 2.0199597740686066

Epoch: 6| Step: 3
Training loss: 2.479541540145874
Validation loss: 2.0013830431046022

Epoch: 6| Step: 4
Training loss: 2.2795510292053223
Validation loss: 2.0040970515179377

Epoch: 6| Step: 5
Training loss: 2.562398910522461
Validation loss: 1.9891774756934053

Epoch: 6| Step: 6
Training loss: 1.8834986686706543
Validation loss: 1.9788983201467862

Epoch: 6| Step: 7
Training loss: 2.7123141288757324
Validation loss: 1.97311492120066

Epoch: 6| Step: 8
Training loss: 2.252237319946289
Validation loss: 1.9784039553775583

Epoch: 6| Step: 9
Training loss: 2.44099497795105
Validation loss: 1.988259243708785

Epoch: 6| Step: 10
Training loss: 2.0710463523864746
Validation loss: 1.9963015510189919

Epoch: 6| Step: 11
Training loss: 1.8375595808029175
Validation loss: 2.014151046353002

Epoch: 6| Step: 12
Training loss: 2.1275908946990967
Validation loss: 2.028523152874362

Epoch: 6| Step: 13
Training loss: 3.3865597248077393
Validation loss: 2.0233329957531345

Epoch: 91| Step: 0
Training loss: 2.3735718727111816
Validation loss: 2.022146309575727

Epoch: 6| Step: 1
Training loss: 2.664724111557007
Validation loss: 2.032207909450736

Epoch: 6| Step: 2
Training loss: 1.804565191268921
Validation loss: 2.0097860828522713

Epoch: 6| Step: 3
Training loss: 3.148922920227051
Validation loss: 2.0213681472245084

Epoch: 6| Step: 4
Training loss: 1.9808974266052246
Validation loss: 2.014500293680417

Epoch: 6| Step: 5
Training loss: 2.2772083282470703
Validation loss: 2.039668124209168

Epoch: 6| Step: 6
Training loss: 1.9967694282531738
Validation loss: 2.041694256567186

Epoch: 6| Step: 7
Training loss: 2.2506747245788574
Validation loss: 2.0300539360251477

Epoch: 6| Step: 8
Training loss: 1.2484982013702393
Validation loss: 2.0096993638623144

Epoch: 6| Step: 9
Training loss: 2.52455472946167
Validation loss: 1.994778048607611

Epoch: 6| Step: 10
Training loss: 2.055872917175293
Validation loss: 1.984886077142531

Epoch: 6| Step: 11
Training loss: 2.4894888401031494
Validation loss: 1.9796456598466443

Epoch: 6| Step: 12
Training loss: 2.674126148223877
Validation loss: 1.965520151199833

Epoch: 6| Step: 13
Training loss: 2.0591280460357666
Validation loss: 1.9604409228089035

Epoch: 92| Step: 0
Training loss: 2.1594173908233643
Validation loss: 1.9592142284557383

Epoch: 6| Step: 1
Training loss: 2.107619047164917
Validation loss: 1.9606871374191777

Epoch: 6| Step: 2
Training loss: 2.268148422241211
Validation loss: 1.9514909816044632

Epoch: 6| Step: 3
Training loss: 2.5477476119995117
Validation loss: 1.9542053156001593

Epoch: 6| Step: 4
Training loss: 1.9494973421096802
Validation loss: 1.9608872167525753

Epoch: 6| Step: 5
Training loss: 2.554870128631592
Validation loss: 1.9762629924281951

Epoch: 6| Step: 6
Training loss: 1.884812831878662
Validation loss: 1.9735936144346833

Epoch: 6| Step: 7
Training loss: 2.7764594554901123
Validation loss: 1.9733700495894237

Epoch: 6| Step: 8
Training loss: 2.298945426940918
Validation loss: 1.9968781240524784

Epoch: 6| Step: 9
Training loss: 2.617936849594116
Validation loss: 2.0022987716941425

Epoch: 6| Step: 10
Training loss: 1.4676403999328613
Validation loss: 2.0364642040703886

Epoch: 6| Step: 11
Training loss: 2.6370577812194824
Validation loss: 2.056960239205309

Epoch: 6| Step: 12
Training loss: 1.9857988357543945
Validation loss: 2.0745121355979674

Epoch: 6| Step: 13
Training loss: 2.4135050773620605
Validation loss: 2.0756366765627297

Epoch: 93| Step: 0
Training loss: 2.4519033432006836
Validation loss: 2.0814410050710044

Epoch: 6| Step: 1
Training loss: 1.712338924407959
Validation loss: 2.0383143040441696

Epoch: 6| Step: 2
Training loss: 1.8757290840148926
Validation loss: 2.0319303774064585

Epoch: 6| Step: 3
Training loss: 2.3468804359436035
Validation loss: 2.0196501362708306

Epoch: 6| Step: 4
Training loss: 2.866443634033203
Validation loss: 1.9960638438501666

Epoch: 6| Step: 5
Training loss: 2.5682668685913086
Validation loss: 1.9955478445176156

Epoch: 6| Step: 6
Training loss: 1.917109727859497
Validation loss: 1.993336490405503

Epoch: 6| Step: 7
Training loss: 2.4893293380737305
Validation loss: 1.9931230814226213

Epoch: 6| Step: 8
Training loss: 2.2329158782958984
Validation loss: 1.991071933059282

Epoch: 6| Step: 9
Training loss: 2.1238090991973877
Validation loss: 1.9795084717453166

Epoch: 6| Step: 10
Training loss: 2.055731773376465
Validation loss: 1.9996893687914776

Epoch: 6| Step: 11
Training loss: 2.5447702407836914
Validation loss: 2.00844766119475

Epoch: 6| Step: 12
Training loss: 2.564817428588867
Validation loss: 2.019470217407391

Epoch: 6| Step: 13
Training loss: 1.4079680442810059
Validation loss: 2.0512221013346026

Epoch: 94| Step: 0
Training loss: 1.6852303743362427
Validation loss: 2.036292637548139

Epoch: 6| Step: 1
Training loss: 2.3022804260253906
Validation loss: 2.0532806124738467

Epoch: 6| Step: 2
Training loss: 1.9754002094268799
Validation loss: 2.0530680892288045

Epoch: 6| Step: 3
Training loss: 2.384176015853882
Validation loss: 2.0461128988573627

Epoch: 6| Step: 4
Training loss: 2.2627038955688477
Validation loss: 2.038019412307329

Epoch: 6| Step: 5
Training loss: 2.197821617126465
Validation loss: 2.0240322377092097

Epoch: 6| Step: 6
Training loss: 2.441312313079834
Validation loss: 2.0066464767661145

Epoch: 6| Step: 7
Training loss: 2.559915065765381
Validation loss: 1.9943140014525382

Epoch: 6| Step: 8
Training loss: 2.489776134490967
Validation loss: 1.9834631950624528

Epoch: 6| Step: 9
Training loss: 1.967850923538208
Validation loss: 1.981748983424197

Epoch: 6| Step: 10
Training loss: 2.4607858657836914
Validation loss: 1.9711586275408346

Epoch: 6| Step: 11
Training loss: 1.9104145765304565
Validation loss: 1.962659074414161

Epoch: 6| Step: 12
Training loss: 1.921354055404663
Validation loss: 1.9659932287790443

Epoch: 6| Step: 13
Training loss: 3.0884315967559814
Validation loss: 1.9671398067987094

Epoch: 95| Step: 0
Training loss: 1.4943311214447021
Validation loss: 1.962712364812051

Epoch: 6| Step: 1
Training loss: 2.4841818809509277
Validation loss: 1.9665981159415296

Epoch: 6| Step: 2
Training loss: 2.6596994400024414
Validation loss: 1.9735863234407158

Epoch: 6| Step: 3
Training loss: 2.1349146366119385
Validation loss: 1.9892967926558627

Epoch: 6| Step: 4
Training loss: 2.1484804153442383
Validation loss: 1.996837499321148

Epoch: 6| Step: 5
Training loss: 2.784609317779541
Validation loss: 1.9926946060631865

Epoch: 6| Step: 6
Training loss: 2.258530616760254
Validation loss: 2.0098536873376496

Epoch: 6| Step: 7
Training loss: 2.1946730613708496
Validation loss: 2.0024104913075766

Epoch: 6| Step: 8
Training loss: 1.6496567726135254
Validation loss: 2.0008507633721955

Epoch: 6| Step: 9
Training loss: 1.9742629528045654
Validation loss: 2.0028964242627545

Epoch: 6| Step: 10
Training loss: 2.4566233158111572
Validation loss: 2.0350511125338975

Epoch: 6| Step: 11
Training loss: 2.2745909690856934
Validation loss: 2.0507957345695904

Epoch: 6| Step: 12
Training loss: 2.4200611114501953
Validation loss: 2.049234149276569

Epoch: 6| Step: 13
Training loss: 1.9541857242584229
Validation loss: 2.0538437802304506

Epoch: 96| Step: 0
Training loss: 2.6341679096221924
Validation loss: 2.0476939152645808

Epoch: 6| Step: 1
Training loss: 1.9103829860687256
Validation loss: 2.049180761460335

Epoch: 6| Step: 2
Training loss: 2.5593719482421875
Validation loss: 2.036299476059534

Epoch: 6| Step: 3
Training loss: 2.0245299339294434
Validation loss: 2.0085063365197953

Epoch: 6| Step: 4
Training loss: 2.847201347351074
Validation loss: 2.0019631142257364

Epoch: 6| Step: 5
Training loss: 1.6783214807510376
Validation loss: 1.9916898614616805

Epoch: 6| Step: 6
Training loss: 1.7230629920959473
Validation loss: 1.990851274100683

Epoch: 6| Step: 7
Training loss: 2.687166690826416
Validation loss: 1.9948989960455126

Epoch: 6| Step: 8
Training loss: 1.895672082901001
Validation loss: 1.9962233702341716

Epoch: 6| Step: 9
Training loss: 2.9553966522216797
Validation loss: 1.9773727501592329

Epoch: 6| Step: 10
Training loss: 2.2698113918304443
Validation loss: 1.9702189084022277

Epoch: 6| Step: 11
Training loss: 1.466265320777893
Validation loss: 1.9651601288908271

Epoch: 6| Step: 12
Training loss: 1.6558940410614014
Validation loss: 1.973912787693803

Epoch: 6| Step: 13
Training loss: 2.5617117881774902
Validation loss: 1.9796635489309988

Epoch: 97| Step: 0
Training loss: 1.6284708976745605
Validation loss: 1.9875415127764466

Epoch: 6| Step: 1
Training loss: 2.7643027305603027
Validation loss: 1.9844746743479083

Epoch: 6| Step: 2
Training loss: 2.2996315956115723
Validation loss: 1.9902422902404622

Epoch: 6| Step: 3
Training loss: 2.7019176483154297
Validation loss: 2.015031906866258

Epoch: 6| Step: 4
Training loss: 2.198147773742676
Validation loss: 2.0180297154252247

Epoch: 6| Step: 5
Training loss: 2.5885379314422607
Validation loss: 2.024071526783769

Epoch: 6| Step: 6
Training loss: 1.8236284255981445
Validation loss: 2.036491145369827

Epoch: 6| Step: 7
Training loss: 2.247460126876831
Validation loss: 2.0302236233988116

Epoch: 6| Step: 8
Training loss: 1.9327821731567383
Validation loss: 2.031189595499346

Epoch: 6| Step: 9
Training loss: 2.221508264541626
Validation loss: 2.0326077579170145

Epoch: 6| Step: 10
Training loss: 1.9119640588760376
Validation loss: 2.0120204853755173

Epoch: 6| Step: 11
Training loss: 1.4238996505737305
Validation loss: 2.0239025995295536

Epoch: 6| Step: 12
Training loss: 2.6852993965148926
Validation loss: 2.012997132475658

Epoch: 6| Step: 13
Training loss: 2.0119848251342773
Validation loss: 2.024700580104705

Epoch: 98| Step: 0
Training loss: 2.0530638694763184
Validation loss: 2.0410616167130007

Epoch: 6| Step: 1
Training loss: 2.4861879348754883
Validation loss: 2.0044589491300684

Epoch: 6| Step: 2
Training loss: 2.205803394317627
Validation loss: 2.0060399040099113

Epoch: 6| Step: 3
Training loss: 2.2416136264801025
Validation loss: 2.009033603052939

Epoch: 6| Step: 4
Training loss: 1.6768804788589478
Validation loss: 2.035818028193648

Epoch: 6| Step: 5
Training loss: 2.776763916015625
Validation loss: 2.053569778319328

Epoch: 6| Step: 6
Training loss: 2.2742772102355957
Validation loss: 2.044938700173491

Epoch: 6| Step: 7
Training loss: 1.3151111602783203
Validation loss: 2.043002223455778

Epoch: 6| Step: 8
Training loss: 1.9436922073364258
Validation loss: 2.0354949787098873

Epoch: 6| Step: 9
Training loss: 2.2106194496154785
Validation loss: 2.022226543836696

Epoch: 6| Step: 10
Training loss: 2.5243189334869385
Validation loss: 2.0203717062550206

Epoch: 6| Step: 11
Training loss: 2.1747846603393555
Validation loss: 2.010306474983051

Epoch: 6| Step: 12
Training loss: 2.3998751640319824
Validation loss: 2.0429484126388386

Epoch: 6| Step: 13
Training loss: 2.833686351776123
Validation loss: 2.060022231071226

Epoch: 99| Step: 0
Training loss: 2.1563305854797363
Validation loss: 2.0648594389679613

Epoch: 6| Step: 1
Training loss: 2.4505984783172607
Validation loss: 2.0569421963025163

Epoch: 6| Step: 2
Training loss: 2.734645366668701
Validation loss: 2.0395663938214703

Epoch: 6| Step: 3
Training loss: 1.7514764070510864
Validation loss: 2.0128877316751788

Epoch: 6| Step: 4
Training loss: 1.8830105066299438
Validation loss: 2.009677263998216

Epoch: 6| Step: 5
Training loss: 2.974236011505127
Validation loss: 2.0134825911573184

Epoch: 6| Step: 6
Training loss: 1.9856164455413818
Validation loss: 2.0187628653741654

Epoch: 6| Step: 7
Training loss: 1.482548475265503
Validation loss: 2.0192073340057046

Epoch: 6| Step: 8
Training loss: 2.337740898132324
Validation loss: 2.0109205989427466

Epoch: 6| Step: 9
Training loss: 2.2280867099761963
Validation loss: 2.016589521079935

Epoch: 6| Step: 10
Training loss: 2.268744468688965
Validation loss: 2.0397779800558604

Epoch: 6| Step: 11
Training loss: 2.4312117099761963
Validation loss: 2.088640293767375

Epoch: 6| Step: 12
Training loss: 1.7720710039138794
Validation loss: 2.1147430122539563

Epoch: 6| Step: 13
Training loss: 2.469269037246704
Validation loss: 2.159777945087802

Epoch: 100| Step: 0
Training loss: 1.7587367296218872
Validation loss: 2.1241091092427573

Epoch: 6| Step: 1
Training loss: 1.9509708881378174
Validation loss: 2.0866780165703065

Epoch: 6| Step: 2
Training loss: 2.675255537033081
Validation loss: 2.083446137366756

Epoch: 6| Step: 3
Training loss: 1.458630919456482
Validation loss: 2.035106635862781

Epoch: 6| Step: 4
Training loss: 2.685235023498535
Validation loss: 2.0187670799993698

Epoch: 6| Step: 5
Training loss: 1.9465179443359375
Validation loss: 2.000681036262102

Epoch: 6| Step: 6
Training loss: 2.140817642211914
Validation loss: 1.995880598663002

Epoch: 6| Step: 7
Training loss: 2.702242851257324
Validation loss: 2.0027615344652565

Epoch: 6| Step: 8
Training loss: 1.8904221057891846
Validation loss: 2.0007190230072185

Epoch: 6| Step: 9
Training loss: 2.5538082122802734
Validation loss: 1.9925050709837226

Epoch: 6| Step: 10
Training loss: 1.6794307231903076
Validation loss: 1.9795259288562241

Epoch: 6| Step: 11
Training loss: 2.136235237121582
Validation loss: 1.9947469234466553

Epoch: 6| Step: 12
Training loss: 2.5839500427246094
Validation loss: 1.9994976225719656

Epoch: 6| Step: 13
Training loss: 2.291550874710083
Validation loss: 2.004922115674583

Epoch: 101| Step: 0
Training loss: 1.9197148084640503
Validation loss: 1.993581489850116

Epoch: 6| Step: 1
Training loss: 1.7835336923599243
Validation loss: 1.988550550194197

Epoch: 6| Step: 2
Training loss: 2.3950412273406982
Validation loss: 1.9864949667325584

Epoch: 6| Step: 3
Training loss: 2.1219847202301025
Validation loss: 1.9837424268004715

Epoch: 6| Step: 4
Training loss: 1.8520150184631348
Validation loss: 1.9865782606986262

Epoch: 6| Step: 5
Training loss: 1.77278733253479
Validation loss: 1.9887064400539602

Epoch: 6| Step: 6
Training loss: 2.5767085552215576
Validation loss: 2.0012147336877804

Epoch: 6| Step: 7
Training loss: 2.644451379776001
Validation loss: 2.009420000096803

Epoch: 6| Step: 8
Training loss: 1.532543420791626
Validation loss: 2.007600707392539

Epoch: 6| Step: 9
Training loss: 2.0986921787261963
Validation loss: 2.020774472144342

Epoch: 6| Step: 10
Training loss: 2.5470972061157227
Validation loss: 2.036751124166673

Epoch: 6| Step: 11
Training loss: 2.386652708053589
Validation loss: 2.075146805855536

Epoch: 6| Step: 12
Training loss: 1.608579158782959
Validation loss: 2.0791491334156325

Epoch: 6| Step: 13
Training loss: 3.260010242462158
Validation loss: 2.1008979300017

Epoch: 102| Step: 0
Training loss: 2.727053642272949
Validation loss: 2.089008310789703

Epoch: 6| Step: 1
Training loss: 1.982100009918213
Validation loss: 2.0819938003375964

Epoch: 6| Step: 2
Training loss: 2.262979745864868
Validation loss: 2.065751426963396

Epoch: 6| Step: 3
Training loss: 2.1982715129852295
Validation loss: 2.0210865338643393

Epoch: 6| Step: 4
Training loss: 2.2476565837860107
Validation loss: 2.0093639166124406

Epoch: 6| Step: 5
Training loss: 1.7980293035507202
Validation loss: 2.0041177118978193

Epoch: 6| Step: 6
Training loss: 2.1580429077148438
Validation loss: 1.9944164688869188

Epoch: 6| Step: 7
Training loss: 2.3660097122192383
Validation loss: 2.010602786976804

Epoch: 6| Step: 8
Training loss: 2.2194437980651855
Validation loss: 2.0345693544674943

Epoch: 6| Step: 9
Training loss: 1.5102720260620117
Validation loss: 2.0380990095036005

Epoch: 6| Step: 10
Training loss: 1.9167231321334839
Validation loss: 2.049818987487465

Epoch: 6| Step: 11
Training loss: 2.1600069999694824
Validation loss: 2.0473739408677623

Epoch: 6| Step: 12
Training loss: 2.0381624698638916
Validation loss: 2.068823583664433

Epoch: 6| Step: 13
Training loss: 2.618805408477783
Validation loss: 2.085779772009901

Epoch: 103| Step: 0
Training loss: 3.492784261703491
Validation loss: 2.079969676592017

Epoch: 6| Step: 1
Training loss: 1.9432783126831055
Validation loss: 2.0808173097589964

Epoch: 6| Step: 2
Training loss: 1.9789791107177734
Validation loss: 2.0742392860433108

Epoch: 6| Step: 3
Training loss: 1.8555511236190796
Validation loss: 2.0338220839859336

Epoch: 6| Step: 4
Training loss: 2.5979652404785156
Validation loss: 2.037904759889008

Epoch: 6| Step: 5
Training loss: 2.2535738945007324
Validation loss: 2.029843170155761

Epoch: 6| Step: 6
Training loss: 1.6674840450286865
Validation loss: 2.0216517448425293

Epoch: 6| Step: 7
Training loss: 1.7734107971191406
Validation loss: 2.043946022628456

Epoch: 6| Step: 8
Training loss: 2.585007667541504
Validation loss: 2.049531284198966

Epoch: 6| Step: 9
Training loss: 2.0453786849975586
Validation loss: 2.0589883994030695

Epoch: 6| Step: 10
Training loss: 2.0115675926208496
Validation loss: 2.0561295324756252

Epoch: 6| Step: 11
Training loss: 1.8816379308700562
Validation loss: 2.031996518053034

Epoch: 6| Step: 12
Training loss: 1.7662391662597656
Validation loss: 2.0017904338016304

Epoch: 6| Step: 13
Training loss: 1.7974802255630493
Validation loss: 1.9965239340259182

Epoch: 104| Step: 0
Training loss: 1.5309629440307617
Validation loss: 1.9940070644501717

Epoch: 6| Step: 1
Training loss: 2.223212242126465
Validation loss: 2.012527479920336

Epoch: 6| Step: 2
Training loss: 2.0968241691589355
Validation loss: 2.059907715807679

Epoch: 6| Step: 3
Training loss: 2.9305477142333984
Validation loss: 2.0809705718871085

Epoch: 6| Step: 4
Training loss: 1.5651063919067383
Validation loss: 2.060779925315611

Epoch: 6| Step: 5
Training loss: 1.8142181634902954
Validation loss: 2.0343288055030246

Epoch: 6| Step: 6
Training loss: 1.8667713403701782
Validation loss: 2.048952209052219

Epoch: 6| Step: 7
Training loss: 1.8695361614227295
Validation loss: 2.0749820175991265

Epoch: 6| Step: 8
Training loss: 2.3887600898742676
Validation loss: 2.1057884103508404

Epoch: 6| Step: 9
Training loss: 1.8361307382583618
Validation loss: 2.1114659668296896

Epoch: 6| Step: 10
Training loss: 2.527304172515869
Validation loss: 2.119135247763767

Epoch: 6| Step: 11
Training loss: 2.380692958831787
Validation loss: 2.112554298934116

Epoch: 6| Step: 12
Training loss: 2.6762924194335938
Validation loss: 2.106785325593846

Epoch: 6| Step: 13
Training loss: 2.9786298274993896
Validation loss: 2.067180420762749

Epoch: 105| Step: 0
Training loss: 2.2714967727661133
Validation loss: 2.007680008488317

Epoch: 6| Step: 1
Training loss: 1.6409430503845215
Validation loss: 1.983860840079605

Epoch: 6| Step: 2
Training loss: 1.7638018131256104
Validation loss: 1.9887879266533801

Epoch: 6| Step: 3
Training loss: 2.593388557434082
Validation loss: 1.9845663885916434

Epoch: 6| Step: 4
Training loss: 2.362748622894287
Validation loss: 1.9699810768968316

Epoch: 6| Step: 5
Training loss: 2.3583483695983887
Validation loss: 1.9593241945389779

Epoch: 6| Step: 6
Training loss: 1.66102933883667
Validation loss: 1.9697808578450193

Epoch: 6| Step: 7
Training loss: 2.0333168506622314
Validation loss: 1.9872539748427689

Epoch: 6| Step: 8
Training loss: 2.286494731903076
Validation loss: 2.0164683685507825

Epoch: 6| Step: 9
Training loss: 2.4647011756896973
Validation loss: 2.056643775714341

Epoch: 6| Step: 10
Training loss: 2.309457778930664
Validation loss: 2.0709309295941423

Epoch: 6| Step: 11
Training loss: 1.7124121189117432
Validation loss: 2.069081288512035

Epoch: 6| Step: 12
Training loss: 2.4416027069091797
Validation loss: 2.058481549703947

Epoch: 6| Step: 13
Training loss: 1.9501749277114868
Validation loss: 2.035842062324606

Epoch: 106| Step: 0
Training loss: 2.5682668685913086
Validation loss: 2.0686707009551344

Epoch: 6| Step: 1
Training loss: 2.1797919273376465
Validation loss: 2.089953743001466

Epoch: 6| Step: 2
Training loss: 1.8227893114089966
Validation loss: 2.143103663639356

Epoch: 6| Step: 3
Training loss: 1.7112219333648682
Validation loss: 2.1735486612525037

Epoch: 6| Step: 4
Training loss: 1.9710819721221924
Validation loss: 2.179505568678661

Epoch: 6| Step: 5
Training loss: 1.8215219974517822
Validation loss: 2.1941765739071752

Epoch: 6| Step: 6
Training loss: 1.8195745944976807
Validation loss: 2.190994014022171

Epoch: 6| Step: 7
Training loss: 3.395629405975342
Validation loss: 2.1544445214733

Epoch: 6| Step: 8
Training loss: 2.174755811691284
Validation loss: 2.131142836745067

Epoch: 6| Step: 9
Training loss: 2.0167880058288574
Validation loss: 2.1219291071737967

Epoch: 6| Step: 10
Training loss: 2.0909366607666016
Validation loss: 2.0748119379884455

Epoch: 6| Step: 11
Training loss: 1.5818216800689697
Validation loss: 2.0533082100652877

Epoch: 6| Step: 12
Training loss: 2.031240224838257
Validation loss: 2.0263955490563506

Epoch: 6| Step: 13
Training loss: 2.8500962257385254
Validation loss: 2.004526469015306

Epoch: 107| Step: 0
Training loss: 2.447209596633911
Validation loss: 2.0084041087858138

Epoch: 6| Step: 1
Training loss: 1.653691291809082
Validation loss: 1.9912924651176698

Epoch: 6| Step: 2
Training loss: 2.2329978942871094
Validation loss: 1.9889748429739347

Epoch: 6| Step: 3
Training loss: 2.4315292835235596
Validation loss: 1.9871195939279371

Epoch: 6| Step: 4
Training loss: 1.7870078086853027
Validation loss: 1.9954562520468107

Epoch: 6| Step: 5
Training loss: 1.543097734451294
Validation loss: 1.993236780166626

Epoch: 6| Step: 6
Training loss: 2.206130027770996
Validation loss: 1.998865637727963

Epoch: 6| Step: 7
Training loss: 1.770289421081543
Validation loss: 1.9938469958561722

Epoch: 6| Step: 8
Training loss: 1.9666759967803955
Validation loss: 2.0141283465969946

Epoch: 6| Step: 9
Training loss: 2.267425537109375
Validation loss: 1.9965072652345062

Epoch: 6| Step: 10
Training loss: 2.1580395698547363
Validation loss: 1.9995495888494677

Epoch: 6| Step: 11
Training loss: 1.84307062625885
Validation loss: 2.015518808877596

Epoch: 6| Step: 12
Training loss: 2.5913944244384766
Validation loss: 2.0140482520544403

Epoch: 6| Step: 13
Training loss: 2.339179039001465
Validation loss: 2.057053586488129

Epoch: 108| Step: 0
Training loss: 2.0827560424804688
Validation loss: 2.0817252948719966

Epoch: 6| Step: 1
Training loss: 1.6479109525680542
Validation loss: 2.037119186052712

Epoch: 6| Step: 2
Training loss: 2.230316162109375
Validation loss: 2.0054445317996445

Epoch: 6| Step: 3
Training loss: 2.166585922241211
Validation loss: 2.013062213056831

Epoch: 6| Step: 4
Training loss: 2.4790828227996826
Validation loss: 2.0160926772702124

Epoch: 6| Step: 5
Training loss: 1.9844636917114258
Validation loss: 2.032163038048693

Epoch: 6| Step: 6
Training loss: 1.989933729171753
Validation loss: 2.028151112218057

Epoch: 6| Step: 7
Training loss: 1.6811422109603882
Validation loss: 2.032832086727183

Epoch: 6| Step: 8
Training loss: 2.2210135459899902
Validation loss: 2.0431344227124284

Epoch: 6| Step: 9
Training loss: 2.2488818168640137
Validation loss: 2.058554362225276

Epoch: 6| Step: 10
Training loss: 1.7170257568359375
Validation loss: 2.0738260451183526

Epoch: 6| Step: 11
Training loss: 2.198549747467041
Validation loss: 2.0780727017310356

Epoch: 6| Step: 12
Training loss: 2.2234625816345215
Validation loss: 2.102513993940046

Epoch: 6| Step: 13
Training loss: 2.0738894939422607
Validation loss: 2.1025926656620477

Epoch: 109| Step: 0
Training loss: 2.102038621902466
Validation loss: 2.087571818341491

Epoch: 6| Step: 1
Training loss: 2.096215009689331
Validation loss: 2.1046722858182845

Epoch: 6| Step: 2
Training loss: 2.189577102661133
Validation loss: 2.0900255390392837

Epoch: 6| Step: 3
Training loss: 2.7026243209838867
Validation loss: 2.0790524380181425

Epoch: 6| Step: 4
Training loss: 2.387125015258789
Validation loss: 2.087346648657194

Epoch: 6| Step: 5
Training loss: 1.9326708316802979
Validation loss: 2.061863524939424

Epoch: 6| Step: 6
Training loss: 2.5840988159179688
Validation loss: 2.054665709054598

Epoch: 6| Step: 7
Training loss: 1.5702712535858154
Validation loss: 2.0264005558465117

Epoch: 6| Step: 8
Training loss: 2.0850000381469727
Validation loss: 2.0217892380170923

Epoch: 6| Step: 9
Training loss: 1.8442093133926392
Validation loss: 2.0198259738183792

Epoch: 6| Step: 10
Training loss: 1.861931562423706
Validation loss: 2.0140648529093754

Epoch: 6| Step: 11
Training loss: 1.3634660243988037
Validation loss: 2.008921851393997

Epoch: 6| Step: 12
Training loss: 1.8382723331451416
Validation loss: 2.0118332793635707

Epoch: 6| Step: 13
Training loss: 2.2263834476470947
Validation loss: 2.019709651188184

Epoch: 110| Step: 0
Training loss: 1.4345026016235352
Validation loss: 2.050461274321361

Epoch: 6| Step: 1
Training loss: 1.9512913227081299
Validation loss: 2.0526652951394357

Epoch: 6| Step: 2
Training loss: 2.287944793701172
Validation loss: 2.062571960110818

Epoch: 6| Step: 3
Training loss: 2.2292914390563965
Validation loss: 2.0799391654229935

Epoch: 6| Step: 4
Training loss: 2.0667171478271484
Validation loss: 2.111396917732813

Epoch: 6| Step: 5
Training loss: 2.47896671295166
Validation loss: 2.1135512859590593

Epoch: 6| Step: 6
Training loss: 1.9285064935684204
Validation loss: 2.112399667821905

Epoch: 6| Step: 7
Training loss: 1.322118878364563
Validation loss: 2.0814320131014754

Epoch: 6| Step: 8
Training loss: 2.124235153198242
Validation loss: 2.0949152733689997

Epoch: 6| Step: 9
Training loss: 2.5639960765838623
Validation loss: 2.10671103513369

Epoch: 6| Step: 10
Training loss: 1.8907291889190674
Validation loss: 2.087142759753812

Epoch: 6| Step: 11
Training loss: 1.9893699884414673
Validation loss: 2.067048534270256

Epoch: 6| Step: 12
Training loss: 2.2455787658691406
Validation loss: 2.0516827324385285

Epoch: 6| Step: 13
Training loss: 2.3555667400360107
Validation loss: 2.009879535244357

Epoch: 111| Step: 0
Training loss: 1.8038288354873657
Validation loss: 2.0207992317856

Epoch: 6| Step: 1
Training loss: 2.529536485671997
Validation loss: 2.01565110042531

Epoch: 6| Step: 2
Training loss: 1.9341027736663818
Validation loss: 1.997552228230302

Epoch: 6| Step: 3
Training loss: 2.4650678634643555
Validation loss: 2.0131089456619753

Epoch: 6| Step: 4
Training loss: 2.607753276824951
Validation loss: 2.0280985806577947

Epoch: 6| Step: 5
Training loss: 1.6138734817504883
Validation loss: 2.0501390144389164

Epoch: 6| Step: 6
Training loss: 1.7802059650421143
Validation loss: 2.0702195872542677

Epoch: 6| Step: 7
Training loss: 1.7331948280334473
Validation loss: 2.0908281213493756

Epoch: 6| Step: 8
Training loss: 1.8692978620529175
Validation loss: 2.124954794042854

Epoch: 6| Step: 9
Training loss: 1.889858365058899
Validation loss: 2.1965111301791285

Epoch: 6| Step: 10
Training loss: 1.8193395137786865
Validation loss: 2.2182016013770975

Epoch: 6| Step: 11
Training loss: 2.0393102169036865
Validation loss: 2.160732482069282

Epoch: 6| Step: 12
Training loss: 2.7427914142608643
Validation loss: 2.110058387120565

Epoch: 6| Step: 13
Training loss: 1.3491339683532715
Validation loss: 2.086397050529398

Epoch: 112| Step: 0
Training loss: 2.1809334754943848
Validation loss: 2.126060021820889

Epoch: 6| Step: 1
Training loss: 2.6137938499450684
Validation loss: 2.1351640583366476

Epoch: 6| Step: 2
Training loss: 1.9746100902557373
Validation loss: 2.13082189970119

Epoch: 6| Step: 3
Training loss: 1.8337905406951904
Validation loss: 2.115929106230377

Epoch: 6| Step: 4
Training loss: 1.6394531726837158
Validation loss: 2.060308846094275

Epoch: 6| Step: 5
Training loss: 1.9686225652694702
Validation loss: 2.020934893238929

Epoch: 6| Step: 6
Training loss: 2.4467806816101074
Validation loss: 2.003503163655599

Epoch: 6| Step: 7
Training loss: 2.1508231163024902
Validation loss: 2.010242718522267

Epoch: 6| Step: 8
Training loss: 2.312558174133301
Validation loss: 2.0139874771077144

Epoch: 6| Step: 9
Training loss: 2.6028003692626953
Validation loss: 2.029499687174315

Epoch: 6| Step: 10
Training loss: 1.9126648902893066
Validation loss: 2.0380593115283596

Epoch: 6| Step: 11
Training loss: 1.8025658130645752
Validation loss: 2.0501174452484294

Epoch: 6| Step: 12
Training loss: 1.8259717226028442
Validation loss: 2.0390395682345153

Epoch: 6| Step: 13
Training loss: 1.6444478034973145
Validation loss: 2.007066762575539

Epoch: 113| Step: 0
Training loss: 1.630159854888916
Validation loss: 1.9977647027661722

Epoch: 6| Step: 1
Training loss: 2.3600575923919678
Validation loss: 2.0197610355192617

Epoch: 6| Step: 2
Training loss: 2.584681987762451
Validation loss: 2.0381200800659838

Epoch: 6| Step: 3
Training loss: 1.5311663150787354
Validation loss: 2.05367192914409

Epoch: 6| Step: 4
Training loss: 2.017235517501831
Validation loss: 2.0591781088100967

Epoch: 6| Step: 5
Training loss: 2.3042144775390625
Validation loss: 2.061096691316174

Epoch: 6| Step: 6
Training loss: 2.14003849029541
Validation loss: 2.0572902899916454

Epoch: 6| Step: 7
Training loss: 2.261058807373047
Validation loss: 2.08154434029774

Epoch: 6| Step: 8
Training loss: 2.0434117317199707
Validation loss: 2.103037436803182

Epoch: 6| Step: 9
Training loss: 2.3654685020446777
Validation loss: 2.118100543175974

Epoch: 6| Step: 10
Training loss: 2.8975279331207275
Validation loss: 2.146388271803497

Epoch: 6| Step: 11
Training loss: 1.469813346862793
Validation loss: 2.1569037488711778

Epoch: 6| Step: 12
Training loss: 1.5429837703704834
Validation loss: 2.1522245163558633

Epoch: 6| Step: 13
Training loss: 1.081368088722229
Validation loss: 2.111595533227408

Epoch: 114| Step: 0
Training loss: 1.927712082862854
Validation loss: 2.10033001694628

Epoch: 6| Step: 1
Training loss: 2.3795175552368164
Validation loss: 2.080500619385832

Epoch: 6| Step: 2
Training loss: 1.9000250101089478
Validation loss: 2.062795067346224

Epoch: 6| Step: 3
Training loss: 2.1151702404022217
Validation loss: 2.0685485178424465

Epoch: 6| Step: 4
Training loss: 2.0959970951080322
Validation loss: 2.0871673437856857

Epoch: 6| Step: 5
Training loss: 2.290343761444092
Validation loss: 2.124448360935334

Epoch: 6| Step: 6
Training loss: 1.7102817296981812
Validation loss: 2.1120220756018036

Epoch: 6| Step: 7
Training loss: 1.5951390266418457
Validation loss: 2.111315519578995

Epoch: 6| Step: 8
Training loss: 2.2287983894348145
Validation loss: 2.1133915480747016

Epoch: 6| Step: 9
Training loss: 0.8900161385536194
Validation loss: 2.0983545985273135

Epoch: 6| Step: 10
Training loss: 2.7333664894104004
Validation loss: 2.081892389123158

Epoch: 6| Step: 11
Training loss: 2.0150108337402344
Validation loss: 2.043222810632439

Epoch: 6| Step: 12
Training loss: 1.9332220554351807
Validation loss: 2.0302057548235823

Epoch: 6| Step: 13
Training loss: 1.9703059196472168
Validation loss: 2.0305326305409914

Epoch: 115| Step: 0
Training loss: 1.9778006076812744
Validation loss: 2.0351179850998746

Epoch: 6| Step: 1
Training loss: 2.2138357162475586
Validation loss: 2.028069343618167

Epoch: 6| Step: 2
Training loss: 2.5950465202331543
Validation loss: 2.0140052546737013

Epoch: 6| Step: 3
Training loss: 1.3344067335128784
Validation loss: 2.0206493587904077

Epoch: 6| Step: 4
Training loss: 2.339162588119507
Validation loss: 2.0184354679558867

Epoch: 6| Step: 5
Training loss: 2.0798182487487793
Validation loss: 2.0281836730177685

Epoch: 6| Step: 6
Training loss: 1.5348420143127441
Validation loss: 2.014585497558758

Epoch: 6| Step: 7
Training loss: 1.7871711254119873
Validation loss: 2.041179564691359

Epoch: 6| Step: 8
Training loss: 1.6114177703857422
Validation loss: 2.074786247745637

Epoch: 6| Step: 9
Training loss: 2.407841444015503
Validation loss: 2.104972667591546

Epoch: 6| Step: 10
Training loss: 1.6853183507919312
Validation loss: 2.11499979419093

Epoch: 6| Step: 11
Training loss: 2.5127880573272705
Validation loss: 2.11979038869181

Epoch: 6| Step: 12
Training loss: 2.1778628826141357
Validation loss: 2.1066618016971055

Epoch: 6| Step: 13
Training loss: 1.609239101409912
Validation loss: 2.089890783832919

Epoch: 116| Step: 0
Training loss: 1.8725210428237915
Validation loss: 2.0763923583492154

Epoch: 6| Step: 1
Training loss: 2.2366113662719727
Validation loss: 2.0948808065024753

Epoch: 6| Step: 2
Training loss: 1.5782381296157837
Validation loss: 2.0921771218699794

Epoch: 6| Step: 3
Training loss: 1.1395843029022217
Validation loss: 2.085337536309355

Epoch: 6| Step: 4
Training loss: 2.157029151916504
Validation loss: 2.104452602324947

Epoch: 6| Step: 5
Training loss: 2.684732437133789
Validation loss: 2.062262360767652

Epoch: 6| Step: 6
Training loss: 2.8609962463378906
Validation loss: 2.0449563431483444

Epoch: 6| Step: 7
Training loss: 1.9459342956542969
Validation loss: 2.014945669840741

Epoch: 6| Step: 8
Training loss: 1.9101316928863525
Validation loss: 2.0111223164425103

Epoch: 6| Step: 9
Training loss: 1.9477550983428955
Validation loss: 2.0059427651025916

Epoch: 6| Step: 10
Training loss: 1.9160192012786865
Validation loss: 2.0067391933933383

Epoch: 6| Step: 11
Training loss: 1.9053101539611816
Validation loss: 2.0478027930823703

Epoch: 6| Step: 12
Training loss: 1.954944133758545
Validation loss: 2.0592451595490977

Epoch: 6| Step: 13
Training loss: 1.9254297018051147
Validation loss: 2.0684885260879353

Epoch: 117| Step: 0
Training loss: 1.3878471851348877
Validation loss: 2.0825290500476794

Epoch: 6| Step: 1
Training loss: 1.756067156791687
Validation loss: 2.09065499613362

Epoch: 6| Step: 2
Training loss: 1.9546542167663574
Validation loss: 2.1130212455667476

Epoch: 6| Step: 3
Training loss: 2.2767746448516846
Validation loss: 2.118361952484295

Epoch: 6| Step: 4
Training loss: 1.663161039352417
Validation loss: 2.081860940943482

Epoch: 6| Step: 5
Training loss: 2.4178826808929443
Validation loss: 2.0816357084499892

Epoch: 6| Step: 6
Training loss: 2.1323201656341553
Validation loss: 2.0586264235998994

Epoch: 6| Step: 7
Training loss: 2.4354701042175293
Validation loss: 2.033536643110296

Epoch: 6| Step: 8
Training loss: 1.5817632675170898
Validation loss: 2.0467998032928794

Epoch: 6| Step: 9
Training loss: 2.888683557510376
Validation loss: 2.0475067759072907

Epoch: 6| Step: 10
Training loss: 1.5541601181030273
Validation loss: 2.0460768656064103

Epoch: 6| Step: 11
Training loss: 1.5693795680999756
Validation loss: 2.074043894326815

Epoch: 6| Step: 12
Training loss: 1.6167488098144531
Validation loss: 2.0638476994729813

Epoch: 6| Step: 13
Training loss: 2.173335075378418
Validation loss: 2.077555694887715

Epoch: 118| Step: 0
Training loss: 1.8817708492279053
Validation loss: 2.0740268768802768

Epoch: 6| Step: 1
Training loss: 2.6269407272338867
Validation loss: 2.0760481844666185

Epoch: 6| Step: 2
Training loss: 1.681643009185791
Validation loss: 2.0980839216580955

Epoch: 6| Step: 3
Training loss: 2.414480209350586
Validation loss: 2.107946329219367

Epoch: 6| Step: 4
Training loss: 2.1218066215515137
Validation loss: 2.1194777129798807

Epoch: 6| Step: 5
Training loss: 2.3655991554260254
Validation loss: 2.1098272633808914

Epoch: 6| Step: 6
Training loss: 1.7985541820526123
Validation loss: 2.137789093038087

Epoch: 6| Step: 7
Training loss: 1.8934626579284668
Validation loss: 2.1599369074708674

Epoch: 6| Step: 8
Training loss: 1.4838768243789673
Validation loss: 2.1700298401617233

Epoch: 6| Step: 9
Training loss: 2.3260128498077393
Validation loss: 2.0858041701778287

Epoch: 6| Step: 10
Training loss: 2.02009916305542
Validation loss: 2.0434846185868785

Epoch: 6| Step: 11
Training loss: 1.3178801536560059
Validation loss: 2.0217939858795493

Epoch: 6| Step: 12
Training loss: 1.4889307022094727
Validation loss: 2.0105960240928074

Epoch: 6| Step: 13
Training loss: 1.5793565511703491
Validation loss: 2.007516671252507

Epoch: 119| Step: 0
Training loss: 2.8956573009490967
Validation loss: 1.973018036093763

Epoch: 6| Step: 1
Training loss: 2.0207245349884033
Validation loss: 1.9331502209427536

Epoch: 6| Step: 2
Training loss: 1.53868567943573
Validation loss: 1.9505985372809953

Epoch: 6| Step: 3
Training loss: 1.3295917510986328
Validation loss: 1.957367439423838

Epoch: 6| Step: 4
Training loss: 2.09161376953125
Validation loss: 1.9750828948072208

Epoch: 6| Step: 5
Training loss: 1.7630863189697266
Validation loss: 1.9636372609805035

Epoch: 6| Step: 6
Training loss: 1.810465693473816
Validation loss: 1.980146884918213

Epoch: 6| Step: 7
Training loss: 1.4114257097244263
Validation loss: 1.9832704951686244

Epoch: 6| Step: 8
Training loss: 2.1201186180114746
Validation loss: 2.0040876480840866

Epoch: 6| Step: 9
Training loss: 2.067307472229004
Validation loss: 2.0219483606276976

Epoch: 6| Step: 10
Training loss: 1.9692543745040894
Validation loss: 2.0694758456240416

Epoch: 6| Step: 11
Training loss: 2.526611328125
Validation loss: 2.1089641714608796

Epoch: 6| Step: 12
Training loss: 1.8302488327026367
Validation loss: 2.1455469003287693

Epoch: 6| Step: 13
Training loss: 2.608449697494507
Validation loss: 2.1876609069044872

Epoch: 120| Step: 0
Training loss: 1.3868968486785889
Validation loss: 2.1433974299379575

Epoch: 6| Step: 1
Training loss: 2.1668403148651123
Validation loss: 2.1256976537807013

Epoch: 6| Step: 2
Training loss: 1.3330118656158447
Validation loss: 2.1044805229351087

Epoch: 6| Step: 3
Training loss: 2.1235616207122803
Validation loss: 2.0855146556772213

Epoch: 6| Step: 4
Training loss: 1.973984956741333
Validation loss: 2.0703122359450146

Epoch: 6| Step: 5
Training loss: 1.7571104764938354
Validation loss: 2.0557156570496096

Epoch: 6| Step: 6
Training loss: 1.8226827383041382
Validation loss: 2.070023436700144

Epoch: 6| Step: 7
Training loss: 1.9711642265319824
Validation loss: 2.0715669867812947

Epoch: 6| Step: 8
Training loss: 1.6592565774917603
Validation loss: 2.063363654639131

Epoch: 6| Step: 9
Training loss: 2.065377712249756
Validation loss: 2.0680190209419496

Epoch: 6| Step: 10
Training loss: 1.5762403011322021
Validation loss: 2.0893290068513606

Epoch: 6| Step: 11
Training loss: 1.6637451648712158
Validation loss: 2.0716560143296436

Epoch: 6| Step: 12
Training loss: 2.328524351119995
Validation loss: 2.078465989840928

Epoch: 6| Step: 13
Training loss: 3.2512624263763428
Validation loss: 2.0763528654652257

Epoch: 121| Step: 0
Training loss: 1.7032361030578613
Validation loss: 2.0786176035481114

Epoch: 6| Step: 1
Training loss: 1.8576183319091797
Validation loss: 2.087161059020668

Epoch: 6| Step: 2
Training loss: 1.3801121711730957
Validation loss: 2.1048436164855957

Epoch: 6| Step: 3
Training loss: 1.882541298866272
Validation loss: 2.1415350180800243

Epoch: 6| Step: 4
Training loss: 1.7457195520401
Validation loss: 2.152503191783864

Epoch: 6| Step: 5
Training loss: 2.0255448818206787
Validation loss: 2.165539349279096

Epoch: 6| Step: 6
Training loss: 1.9355465173721313
Validation loss: 2.1493831270484516

Epoch: 6| Step: 7
Training loss: 1.6912461519241333
Validation loss: 2.1454030941891413

Epoch: 6| Step: 8
Training loss: 1.7141437530517578
Validation loss: 2.129576713808121

Epoch: 6| Step: 9
Training loss: 2.924041748046875
Validation loss: 2.1341026034406436

Epoch: 6| Step: 10
Training loss: 2.5607709884643555
Validation loss: 2.1058724182908253

Epoch: 6| Step: 11
Training loss: 1.789560079574585
Validation loss: 2.0814155429922123

Epoch: 6| Step: 12
Training loss: 2.0107197761535645
Validation loss: 2.07589304062628

Epoch: 6| Step: 13
Training loss: 0.639270544052124
Validation loss: 2.0553192374526814

Epoch: 122| Step: 0
Training loss: 1.725987434387207
Validation loss: 2.046624190063887

Epoch: 6| Step: 1
Training loss: 1.7307672500610352
Validation loss: 2.0273328519636586

Epoch: 6| Step: 2
Training loss: 2.5973150730133057
Validation loss: 2.039879168233564

Epoch: 6| Step: 3
Training loss: 1.8726457357406616
Validation loss: 1.9924971044704478

Epoch: 6| Step: 4
Training loss: 1.6434937715530396
Validation loss: 1.989736988980283

Epoch: 6| Step: 5
Training loss: 1.9203715324401855
Validation loss: 1.9778009806909869

Epoch: 6| Step: 6
Training loss: 1.3136451244354248
Validation loss: 1.99481535983342

Epoch: 6| Step: 7
Training loss: 1.6288191080093384
Validation loss: 1.996666689072886

Epoch: 6| Step: 8
Training loss: 1.963173747062683
Validation loss: 2.0058504945488385

Epoch: 6| Step: 9
Training loss: 1.2808767557144165
Validation loss: 2.0383098381821827

Epoch: 6| Step: 10
Training loss: 2.229360818862915
Validation loss: 2.062367746906896

Epoch: 6| Step: 11
Training loss: 2.164917469024658
Validation loss: 2.082962130987516

Epoch: 6| Step: 12
Training loss: 2.670252561569214
Validation loss: 2.1255147739123275

Epoch: 6| Step: 13
Training loss: 1.4602694511413574
Validation loss: 2.153253957789431

Epoch: 123| Step: 0
Training loss: 2.8354907035827637
Validation loss: 2.1355890176629506

Epoch: 6| Step: 1
Training loss: 2.066734790802002
Validation loss: 2.168667786864824

Epoch: 6| Step: 2
Training loss: 1.577881097793579
Validation loss: 2.172569021101921

Epoch: 6| Step: 3
Training loss: 1.8437175750732422
Validation loss: 2.166569830268942

Epoch: 6| Step: 4
Training loss: 1.698162317276001
Validation loss: 2.1491297611626248

Epoch: 6| Step: 5
Training loss: 1.1445003747940063
Validation loss: 2.1321910081371183

Epoch: 6| Step: 6
Training loss: 2.305068016052246
Validation loss: 2.1270095353485434

Epoch: 6| Step: 7
Training loss: 1.6160862445831299
Validation loss: 2.1196700834458873

Epoch: 6| Step: 8
Training loss: 1.6013362407684326
Validation loss: 2.1261423839035856

Epoch: 6| Step: 9
Training loss: 1.767114520072937
Validation loss: 2.118821187685895

Epoch: 6| Step: 10
Training loss: 2.200859546661377
Validation loss: 2.078403216536327

Epoch: 6| Step: 11
Training loss: 2.3271124362945557
Validation loss: 2.0515049811332458

Epoch: 6| Step: 12
Training loss: 1.8621258735656738
Validation loss: 2.021910846874278

Epoch: 6| Step: 13
Training loss: 0.8718456625938416
Validation loss: 1.9985664634294407

Epoch: 124| Step: 0
Training loss: 1.3157434463500977
Validation loss: 1.9946335143940424

Epoch: 6| Step: 1
Training loss: 2.008481979370117
Validation loss: 1.9718760021271244

Epoch: 6| Step: 2
Training loss: 2.343386650085449
Validation loss: 1.9625638274736301

Epoch: 6| Step: 3
Training loss: 1.891946792602539
Validation loss: 2.0061647379270164

Epoch: 6| Step: 4
Training loss: 1.9938772916793823
Validation loss: 1.9980707553125197

Epoch: 6| Step: 5
Training loss: 1.5597710609436035
Validation loss: 2.0528603523008284

Epoch: 6| Step: 6
Training loss: 2.3884172439575195
Validation loss: 2.1551680975062872

Epoch: 6| Step: 7
Training loss: 2.0566391944885254
Validation loss: 2.185418716040991

Epoch: 6| Step: 8
Training loss: 1.5386414527893066
Validation loss: 2.1743339607792516

Epoch: 6| Step: 9
Training loss: 2.535072088241577
Validation loss: 2.1814720963919036

Epoch: 6| Step: 10
Training loss: 1.2487324476242065
Validation loss: 2.1899288059562765

Epoch: 6| Step: 11
Training loss: 2.072492837905884
Validation loss: 2.179030579905356

Epoch: 6| Step: 12
Training loss: 1.6818654537200928
Validation loss: 2.167322430559384

Epoch: 6| Step: 13
Training loss: 2.094618558883667
Validation loss: 2.158404411808137

Epoch: 125| Step: 0
Training loss: 1.7238857746124268
Validation loss: 2.127747151159471

Epoch: 6| Step: 1
Training loss: 2.2405447959899902
Validation loss: 2.116906504477224

Epoch: 6| Step: 2
Training loss: 1.3473209142684937
Validation loss: 2.1164373582409275

Epoch: 6| Step: 3
Training loss: 1.8466651439666748
Validation loss: 2.1149664796808714

Epoch: 6| Step: 4
Training loss: 2.583498001098633
Validation loss: 2.1155269774057532

Epoch: 6| Step: 5
Training loss: 1.2780117988586426
Validation loss: 2.1279503324980378

Epoch: 6| Step: 6
Training loss: 1.3588382005691528
Validation loss: 2.1475626089239634

Epoch: 6| Step: 7
Training loss: 1.6928397417068481
Validation loss: 2.1525764478150236

Epoch: 6| Step: 8
Training loss: 1.96258544921875
Validation loss: 2.1662769445808987

Epoch: 6| Step: 9
Training loss: 2.4621143341064453
Validation loss: 2.1824702806370233

Epoch: 6| Step: 10
Training loss: 1.7405215501785278
Validation loss: 2.1773946580066474

Epoch: 6| Step: 11
Training loss: 1.6631300449371338
Validation loss: 2.1440887604990313

Epoch: 6| Step: 12
Training loss: 2.0711753368377686
Validation loss: 2.099613866498393

Epoch: 6| Step: 13
Training loss: 2.8706371784210205
Validation loss: 2.057678314947313

Epoch: 126| Step: 0
Training loss: 1.211844563484192
Validation loss: 2.0109961725050405

Epoch: 6| Step: 1
Training loss: 1.3887193202972412
Validation loss: 2.013105662920142

Epoch: 6| Step: 2
Training loss: 1.7997697591781616
Validation loss: 2.0042830333914807

Epoch: 6| Step: 3
Training loss: 1.392442226409912
Validation loss: 2.0254437949067805

Epoch: 6| Step: 4
Training loss: 2.3081777095794678
Validation loss: 2.0374445299948416

Epoch: 6| Step: 5
Training loss: 1.6748995780944824
Validation loss: 2.062440445346217

Epoch: 6| Step: 6
Training loss: 2.662949800491333
Validation loss: 2.089624562571126

Epoch: 6| Step: 7
Training loss: 1.8090548515319824
Validation loss: 2.1183921906255905

Epoch: 6| Step: 8
Training loss: 1.9045894145965576
Validation loss: 2.1256765883455992

Epoch: 6| Step: 9
Training loss: 2.173212766647339
Validation loss: 2.144715275815738

Epoch: 6| Step: 10
Training loss: 1.4698076248168945
Validation loss: 2.1456638587418424

Epoch: 6| Step: 11
Training loss: 2.6226868629455566
Validation loss: 2.136829459539024

Epoch: 6| Step: 12
Training loss: 1.2925058603286743
Validation loss: 2.1302048442184285

Epoch: 6| Step: 13
Training loss: 2.279428005218506
Validation loss: 2.134318882419217

Epoch: 127| Step: 0
Training loss: 1.7314149141311646
Validation loss: 2.1287748480355866

Epoch: 6| Step: 1
Training loss: 2.231788158416748
Validation loss: 2.1146141739301783

Epoch: 6| Step: 2
Training loss: 1.451178789138794
Validation loss: 2.105401844106695

Epoch: 6| Step: 3
Training loss: 2.110227584838867
Validation loss: 2.13402227176133

Epoch: 6| Step: 4
Training loss: 2.1217689514160156
Validation loss: 2.115772097341476

Epoch: 6| Step: 5
Training loss: 1.9967896938323975
Validation loss: 2.105411091158467

Epoch: 6| Step: 6
Training loss: 1.146206259727478
Validation loss: 2.0898358911596318

Epoch: 6| Step: 7
Training loss: 2.5252163410186768
Validation loss: 2.10738480219277

Epoch: 6| Step: 8
Training loss: 1.1065548658370972
Validation loss: 2.1102039416631064

Epoch: 6| Step: 9
Training loss: 1.0787988901138306
Validation loss: 2.108051215448687

Epoch: 6| Step: 10
Training loss: 1.939488410949707
Validation loss: 2.086523778976933

Epoch: 6| Step: 11
Training loss: 2.233450174331665
Validation loss: 2.0768542712734592

Epoch: 6| Step: 12
Training loss: 1.8532676696777344
Validation loss: 2.082491550394284

Epoch: 6| Step: 13
Training loss: 1.3643872737884521
Validation loss: 2.065995685515865

Epoch: 128| Step: 0
Training loss: 2.426302194595337
Validation loss: 2.0843023048934115

Epoch: 6| Step: 1
Training loss: 1.6331809759140015
Validation loss: 2.0827764464962866

Epoch: 6| Step: 2
Training loss: 1.5435786247253418
Validation loss: 2.1073528105212795

Epoch: 6| Step: 3
Training loss: 1.5197820663452148
Validation loss: 2.1657105210006877

Epoch: 6| Step: 4
Training loss: 1.658857822418213
Validation loss: 2.1964007218678794

Epoch: 6| Step: 5
Training loss: 1.8799707889556885
Validation loss: 2.1341267503717893

Epoch: 6| Step: 6
Training loss: 1.568174123764038
Validation loss: 2.124843810194282

Epoch: 6| Step: 7
Training loss: 2.536672592163086
Validation loss: 2.133348577766008

Epoch: 6| Step: 8
Training loss: 1.513333797454834
Validation loss: 2.0968677869407077

Epoch: 6| Step: 9
Training loss: 1.139848232269287
Validation loss: 2.09149238627444

Epoch: 6| Step: 10
Training loss: 1.848036289215088
Validation loss: 2.0571097635453746

Epoch: 6| Step: 11
Training loss: 1.453096628189087
Validation loss: 2.0470528961509786

Epoch: 6| Step: 12
Training loss: 2.4676613807678223
Validation loss: 2.012531272826656

Epoch: 6| Step: 13
Training loss: 2.4853596687316895
Validation loss: 1.994619474616102

Epoch: 129| Step: 0
Training loss: 2.2735648155212402
Validation loss: 1.9916206841827722

Epoch: 6| Step: 1
Training loss: 1.9653935432434082
Validation loss: 1.9956060801782916

Epoch: 6| Step: 2
Training loss: 0.8258181810379028
Validation loss: 2.021194875881236

Epoch: 6| Step: 3
Training loss: 1.6437231302261353
Validation loss: 2.065431830703571

Epoch: 6| Step: 4
Training loss: 1.8183869123458862
Validation loss: 2.160458546812816

Epoch: 6| Step: 5
Training loss: 1.791225552558899
Validation loss: 2.210272805665129

Epoch: 6| Step: 6
Training loss: 1.945377230644226
Validation loss: 2.258360537149573

Epoch: 6| Step: 7
Training loss: 2.227731227874756
Validation loss: 2.238069734265727

Epoch: 6| Step: 8
Training loss: 1.3196433782577515
Validation loss: 2.221249113800705

Epoch: 6| Step: 9
Training loss: 2.0380446910858154
Validation loss: 2.2081173055915424

Epoch: 6| Step: 10
Training loss: 1.4103630781173706
Validation loss: 2.1734786982177408

Epoch: 6| Step: 11
Training loss: 3.1040518283843994
Validation loss: 2.176682177410331

Epoch: 6| Step: 12
Training loss: 1.8236345052719116
Validation loss: 2.142746530553346

Epoch: 6| Step: 13
Training loss: 2.426640510559082
Validation loss: 2.084750085748652

Epoch: 130| Step: 0
Training loss: 0.7298306226730347
Validation loss: 2.074191950982617

Epoch: 6| Step: 1
Training loss: 1.1756095886230469
Validation loss: 2.0465626178249234

Epoch: 6| Step: 2
Training loss: 1.941046953201294
Validation loss: 2.0596795364092757

Epoch: 6| Step: 3
Training loss: 2.2193973064422607
Validation loss: 2.0622389265286025

Epoch: 6| Step: 4
Training loss: 1.8300600051879883
Validation loss: 2.080512521087482

Epoch: 6| Step: 5
Training loss: 2.626380443572998
Validation loss: 2.0763665758153445

Epoch: 6| Step: 6
Training loss: 1.983633041381836
Validation loss: 2.0880134592774096

Epoch: 6| Step: 7
Training loss: 2.545631170272827
Validation loss: 2.081348652480751

Epoch: 6| Step: 8
Training loss: 1.6000373363494873
Validation loss: 2.109755395561136

Epoch: 6| Step: 9
Training loss: 2.147731304168701
Validation loss: 2.141567304570188

Epoch: 6| Step: 10
Training loss: 1.3518587350845337
Validation loss: 2.135865121759394

Epoch: 6| Step: 11
Training loss: 1.7324233055114746
Validation loss: 2.1522870627782678

Epoch: 6| Step: 12
Training loss: 1.021277666091919
Validation loss: 2.166570989034509

Epoch: 6| Step: 13
Training loss: 1.9938311576843262
Validation loss: 2.173797494621687

Epoch: 131| Step: 0
Training loss: 2.127746820449829
Validation loss: 2.169239200571532

Epoch: 6| Step: 1
Training loss: 1.9706860780715942
Validation loss: 2.171632138631677

Epoch: 6| Step: 2
Training loss: 1.9068777561187744
Validation loss: 2.1552179910803355

Epoch: 6| Step: 3
Training loss: 2.361440896987915
Validation loss: 2.1644258601691133

Epoch: 6| Step: 4
Training loss: 1.610224723815918
Validation loss: 2.1571769457991405

Epoch: 6| Step: 5
Training loss: 1.6394197940826416
Validation loss: 2.153383147331976

Epoch: 6| Step: 6
Training loss: 2.66685152053833
Validation loss: 2.1609720132684194

Epoch: 6| Step: 7
Training loss: 1.8097506761550903
Validation loss: 2.1859624437106553

Epoch: 6| Step: 8
Training loss: 1.5695112943649292
Validation loss: 2.2733019987742105

Epoch: 6| Step: 9
Training loss: 1.685197114944458
Validation loss: 2.3624147471561225

Epoch: 6| Step: 10
Training loss: 1.5907708406448364
Validation loss: 2.3304012411384174

Epoch: 6| Step: 11
Training loss: 1.1905016899108887
Validation loss: 2.2395749784285024

Epoch: 6| Step: 12
Training loss: 1.871329426765442
Validation loss: 2.1842915896446473

Epoch: 6| Step: 13
Training loss: 1.591676950454712
Validation loss: 2.132725925855739

Epoch: 132| Step: 0
Training loss: 2.3815689086914062
Validation loss: 2.1156427168077037

Epoch: 6| Step: 1
Training loss: 1.5289275646209717
Validation loss: 2.1142970977290982

Epoch: 6| Step: 2
Training loss: 1.9477005004882812
Validation loss: 2.094805073994462

Epoch: 6| Step: 3
Training loss: 1.718649983406067
Validation loss: 2.073624890337708

Epoch: 6| Step: 4
Training loss: 1.6416609287261963
Validation loss: 2.055428727980583

Epoch: 6| Step: 5
Training loss: 1.6126810312271118
Validation loss: 2.0474084846435057

Epoch: 6| Step: 6
Training loss: 1.5733299255371094
Validation loss: 2.0644472286265385

Epoch: 6| Step: 7
Training loss: 1.0521376132965088
Validation loss: 2.04649035392269

Epoch: 6| Step: 8
Training loss: 1.5758745670318604
Validation loss: 2.083048197530931

Epoch: 6| Step: 9
Training loss: 1.719395399093628
Validation loss: 2.09959025408632

Epoch: 6| Step: 10
Training loss: 2.269951581954956
Validation loss: 2.114223513551938

Epoch: 6| Step: 11
Training loss: 2.3879427909851074
Validation loss: 2.1242432901936192

Epoch: 6| Step: 12
Training loss: 2.1856791973114014
Validation loss: 2.124840456952331

Epoch: 6| Step: 13
Training loss: 0.9636305570602417
Validation loss: 2.090187639318487

Epoch: 133| Step: 0
Training loss: 1.935110092163086
Validation loss: 2.085047257843838

Epoch: 6| Step: 1
Training loss: 2.1731531620025635
Validation loss: 2.0805977211203626

Epoch: 6| Step: 2
Training loss: 1.052940845489502
Validation loss: 2.0557841588092107

Epoch: 6| Step: 3
Training loss: 2.105811595916748
Validation loss: 2.077734890804496

Epoch: 6| Step: 4
Training loss: 2.1103909015655518
Validation loss: 2.0795305980149137

Epoch: 6| Step: 5
Training loss: 1.797283411026001
Validation loss: 2.0746382897899998

Epoch: 6| Step: 6
Training loss: 1.3354315757751465
Validation loss: 2.082993858604021

Epoch: 6| Step: 7
Training loss: 1.605973720550537
Validation loss: 2.1039001928862704

Epoch: 6| Step: 8
Training loss: 1.5711873769760132
Validation loss: 2.114826435683876

Epoch: 6| Step: 9
Training loss: 1.3939241170883179
Validation loss: 2.124757288604654

Epoch: 6| Step: 10
Training loss: 2.003028392791748
Validation loss: 2.1469492758474042

Epoch: 6| Step: 11
Training loss: 1.8653180599212646
Validation loss: 2.1564079946087253

Epoch: 6| Step: 12
Training loss: 1.2975592613220215
Validation loss: 2.151651659319478

Epoch: 6| Step: 13
Training loss: 1.9612541198730469
Validation loss: 2.1553808668608307

Epoch: 134| Step: 0
Training loss: 1.7693347930908203
Validation loss: 2.164850837440901

Epoch: 6| Step: 1
Training loss: 1.7430099248886108
Validation loss: 2.1504032201664423

Epoch: 6| Step: 2
Training loss: 1.9097979068756104
Validation loss: 2.1627764189115135

Epoch: 6| Step: 3
Training loss: 1.2902493476867676
Validation loss: 2.1326504471481487

Epoch: 6| Step: 4
Training loss: 1.7191827297210693
Validation loss: 2.097025550821776

Epoch: 6| Step: 5
Training loss: 1.5885930061340332
Validation loss: 2.0856707326827513

Epoch: 6| Step: 6
Training loss: 1.6777712106704712
Validation loss: 2.059058702120217

Epoch: 6| Step: 7
Training loss: 1.5956348180770874
Validation loss: 2.0533721959719093

Epoch: 6| Step: 8
Training loss: 2.3057849407196045
Validation loss: 2.047575258439587

Epoch: 6| Step: 9
Training loss: 1.4878814220428467
Validation loss: 2.0283215122838176

Epoch: 6| Step: 10
Training loss: 1.29789137840271
Validation loss: 2.0281440724608717

Epoch: 6| Step: 11
Training loss: 1.9097734689712524
Validation loss: 2.0138013337248113

Epoch: 6| Step: 12
Training loss: 2.0933449268341064
Validation loss: 2.033847194845958

Epoch: 6| Step: 13
Training loss: 1.6961225271224976
Validation loss: 2.043499605630034

Epoch: 135| Step: 0
Training loss: 1.8185861110687256
Validation loss: 2.036041575093423

Epoch: 6| Step: 1
Training loss: 1.3886455297470093
Validation loss: 2.053702933813936

Epoch: 6| Step: 2
Training loss: 1.7072681188583374
Validation loss: 2.1078251613083707

Epoch: 6| Step: 3
Training loss: 1.6117744445800781
Validation loss: 2.126690090343516

Epoch: 6| Step: 4
Training loss: 1.5657281875610352
Validation loss: 2.1449335300794212

Epoch: 6| Step: 5
Training loss: 1.6047427654266357
Validation loss: 2.1958389615499847

Epoch: 6| Step: 6
Training loss: 2.173020839691162
Validation loss: 2.188040307773057

Epoch: 6| Step: 7
Training loss: 1.4556684494018555
Validation loss: 2.1822406348361763

Epoch: 6| Step: 8
Training loss: 1.7029521465301514
Validation loss: 2.192685414386052

Epoch: 6| Step: 9
Training loss: 1.3429687023162842
Validation loss: 2.1536636403811875

Epoch: 6| Step: 10
Training loss: 2.260467529296875
Validation loss: 2.122988981585349

Epoch: 6| Step: 11
Training loss: 1.895117163658142
Validation loss: 2.090234471905616

Epoch: 6| Step: 12
Training loss: 1.5564618110656738
Validation loss: 2.0795562651849564

Epoch: 6| Step: 13
Training loss: 2.172022819519043
Validation loss: 2.0442293395278273

Epoch: 136| Step: 0
Training loss: 1.7714786529541016
Validation loss: 2.058897873406769

Epoch: 6| Step: 1
Training loss: 1.8353099822998047
Validation loss: 2.040837591694247

Epoch: 6| Step: 2
Training loss: 2.30556583404541
Validation loss: 2.05335376339574

Epoch: 6| Step: 3
Training loss: 1.1835609674453735
Validation loss: 2.072352618299505

Epoch: 6| Step: 4
Training loss: 1.4482128620147705
Validation loss: 2.0935462802969

Epoch: 6| Step: 5
Training loss: 1.8772913217544556
Validation loss: 2.109956923351493

Epoch: 6| Step: 6
Training loss: 2.498993158340454
Validation loss: 2.123371744668612

Epoch: 6| Step: 7
Training loss: 2.1836483478546143
Validation loss: 2.1103521213736585

Epoch: 6| Step: 8
Training loss: 1.7405400276184082
Validation loss: 2.0659611353310208

Epoch: 6| Step: 9
Training loss: 1.6590697765350342
Validation loss: 2.043638744661885

Epoch: 6| Step: 10
Training loss: 2.1435799598693848
Validation loss: 2.0425192386873308

Epoch: 6| Step: 11
Training loss: 0.981852114200592
Validation loss: 2.0540620485941568

Epoch: 6| Step: 12
Training loss: 1.146619200706482
Validation loss: 2.0552316955340806

Epoch: 6| Step: 13
Training loss: 1.9213011264801025
Validation loss: 2.0636757727592223

Epoch: 137| Step: 0
Training loss: 1.5759031772613525
Validation loss: 2.0576327821259857

Epoch: 6| Step: 1
Training loss: 1.9289419651031494
Validation loss: 2.095257436075518

Epoch: 6| Step: 2
Training loss: 0.9557456374168396
Validation loss: 2.125880456739856

Epoch: 6| Step: 3
Training loss: 1.085325002670288
Validation loss: 2.137090262546334

Epoch: 6| Step: 4
Training loss: 2.551839828491211
Validation loss: 2.172185438935475

Epoch: 6| Step: 5
Training loss: 1.6721155643463135
Validation loss: 2.205313577446886

Epoch: 6| Step: 6
Training loss: 1.709869384765625
Validation loss: 2.1807316554489957

Epoch: 6| Step: 7
Training loss: 2.196157455444336
Validation loss: 2.144388935899222

Epoch: 6| Step: 8
Training loss: 1.2427538633346558
Validation loss: 2.158430025141726

Epoch: 6| Step: 9
Training loss: 2.1033525466918945
Validation loss: 2.119492211649495

Epoch: 6| Step: 10
Training loss: 2.0588510036468506
Validation loss: 2.0982792813290834

Epoch: 6| Step: 11
Training loss: 2.1609771251678467
Validation loss: 2.0707419072428057

Epoch: 6| Step: 12
Training loss: 1.4865167140960693
Validation loss: 2.043105443318685

Epoch: 6| Step: 13
Training loss: 1.2003778219223022
Validation loss: 2.0254167972072477

Epoch: 138| Step: 0
Training loss: 1.8163408041000366
Validation loss: 2.051537077914002

Epoch: 6| Step: 1
Training loss: 1.6002753973007202
Validation loss: 2.064636440687282

Epoch: 6| Step: 2
Training loss: 1.5802768468856812
Validation loss: 2.083028139606599

Epoch: 6| Step: 3
Training loss: 2.678278684616089
Validation loss: 2.1300717092329458

Epoch: 6| Step: 4
Training loss: 1.1961846351623535
Validation loss: 2.141737727708714

Epoch: 6| Step: 5
Training loss: 1.7589271068572998
Validation loss: 2.1525239688093945

Epoch: 6| Step: 6
Training loss: 1.1386984586715698
Validation loss: 2.210976513483191

Epoch: 6| Step: 7
Training loss: 1.1562012434005737
Validation loss: 2.2362937517063592

Epoch: 6| Step: 8
Training loss: 1.939953088760376
Validation loss: 2.228193542008759

Epoch: 6| Step: 9
Training loss: 2.1397080421447754
Validation loss: 2.208451571003083

Epoch: 6| Step: 10
Training loss: 2.026109218597412
Validation loss: 2.1815363104625414

Epoch: 6| Step: 11
Training loss: 1.8868497610092163
Validation loss: 2.154480558569713

Epoch: 6| Step: 12
Training loss: 1.4188992977142334
Validation loss: 2.136210867153701

Epoch: 6| Step: 13
Training loss: 1.358620524406433
Validation loss: 2.103613071544196

Epoch: 139| Step: 0
Training loss: 1.808175802230835
Validation loss: 2.069939454396566

Epoch: 6| Step: 1
Training loss: 1.610788345336914
Validation loss: 2.07614012815619

Epoch: 6| Step: 2
Training loss: 2.0380263328552246
Validation loss: 2.053694607109152

Epoch: 6| Step: 3
Training loss: 1.5840840339660645
Validation loss: 2.076503630607359

Epoch: 6| Step: 4
Training loss: 1.9520201683044434
Validation loss: 2.072255870347382

Epoch: 6| Step: 5
Training loss: 1.5785932540893555
Validation loss: 2.0757122680705082

Epoch: 6| Step: 6
Training loss: 2.1465275287628174
Validation loss: 2.076995268944771

Epoch: 6| Step: 7
Training loss: 1.3135013580322266
Validation loss: 2.0785999144277265

Epoch: 6| Step: 8
Training loss: 1.6577131748199463
Validation loss: 2.0630419279939387

Epoch: 6| Step: 9
Training loss: 1.4215505123138428
Validation loss: 2.0812401386999313

Epoch: 6| Step: 10
Training loss: 1.824960708618164
Validation loss: 2.0884463171805105

Epoch: 6| Step: 11
Training loss: 1.7235609292984009
Validation loss: 2.1276936684885333

Epoch: 6| Step: 12
Training loss: 1.1383180618286133
Validation loss: 2.1110683551398655

Epoch: 6| Step: 13
Training loss: 1.4183839559555054
Validation loss: 2.1225539715059343

Epoch: 140| Step: 0
Training loss: 2.612734794616699
Validation loss: 2.130643903568227

Epoch: 6| Step: 1
Training loss: 1.2720460891723633
Validation loss: 2.088545083999634

Epoch: 6| Step: 2
Training loss: 1.650956392288208
Validation loss: 2.0765540497277373

Epoch: 6| Step: 3
Training loss: 1.7251880168914795
Validation loss: 2.0561822998908257

Epoch: 6| Step: 4
Training loss: 1.9269827604293823
Validation loss: 2.041784671045119

Epoch: 6| Step: 5
Training loss: 1.5961754322052002
Validation loss: 2.056347195820142

Epoch: 6| Step: 6
Training loss: 1.5137546062469482
Validation loss: 2.0788710066067275

Epoch: 6| Step: 7
Training loss: 2.1203246116638184
Validation loss: 2.1436703205108643

Epoch: 6| Step: 8
Training loss: 1.7992640733718872
Validation loss: 2.1571438261257705

Epoch: 6| Step: 9
Training loss: 1.021244764328003
Validation loss: 2.162861982981364

Epoch: 6| Step: 10
Training loss: 1.9792299270629883
Validation loss: 2.182151481669436

Epoch: 6| Step: 11
Training loss: 1.462226152420044
Validation loss: 2.1815604317572808

Epoch: 6| Step: 12
Training loss: 1.2349092960357666
Validation loss: 2.1486416555220083

Epoch: 6| Step: 13
Training loss: 1.7230066061019897
Validation loss: 2.109057778953224

Epoch: 141| Step: 0
Training loss: 2.00313138961792
Validation loss: 2.1243250421298447

Epoch: 6| Step: 1
Training loss: 1.041996955871582
Validation loss: 2.112482140141149

Epoch: 6| Step: 2
Training loss: 1.6285459995269775
Validation loss: 2.0676746214589765

Epoch: 6| Step: 3
Training loss: 1.4306507110595703
Validation loss: 2.0853232158127653

Epoch: 6| Step: 4
Training loss: 1.4137283563613892
Validation loss: 2.0823865141919864

Epoch: 6| Step: 5
Training loss: 1.8923826217651367
Validation loss: 2.080994898273099

Epoch: 6| Step: 6
Training loss: 1.5713452100753784
Validation loss: 2.076526564936484

Epoch: 6| Step: 7
Training loss: 1.3607795238494873
Validation loss: 2.10475294820724

Epoch: 6| Step: 8
Training loss: 2.2396159172058105
Validation loss: 2.1461211148128716

Epoch: 6| Step: 9
Training loss: 1.875452995300293
Validation loss: 2.14173153908022

Epoch: 6| Step: 10
Training loss: 1.9818449020385742
Validation loss: 2.125147978464762

Epoch: 6| Step: 11
Training loss: 1.1928061246871948
Validation loss: 2.0832263795278405

Epoch: 6| Step: 12
Training loss: 2.2792372703552246
Validation loss: 2.079033097913188

Epoch: 6| Step: 13
Training loss: 1.6279919147491455
Validation loss: 2.086498004133983

Epoch: 142| Step: 0
Training loss: 1.416152000427246
Validation loss: 2.0924750784392

Epoch: 6| Step: 1
Training loss: 1.5841240882873535
Validation loss: 2.083073754464426

Epoch: 6| Step: 2
Training loss: 1.5168706178665161
Validation loss: 2.1031313762869885

Epoch: 6| Step: 3
Training loss: 1.3521137237548828
Validation loss: 2.0798692113609722

Epoch: 6| Step: 4
Training loss: 1.5649874210357666
Validation loss: 2.0571913283358336

Epoch: 6| Step: 5
Training loss: 1.9238084554672241
Validation loss: 2.07713851492892

Epoch: 6| Step: 6
Training loss: 2.0753395557403564
Validation loss: 2.092827676444925

Epoch: 6| Step: 7
Training loss: 1.5555164813995361
Validation loss: 2.107518275578817

Epoch: 6| Step: 8
Training loss: 1.9809259176254272
Validation loss: 2.1013056257719636

Epoch: 6| Step: 9
Training loss: 1.2208222150802612
Validation loss: 2.081494688987732

Epoch: 6| Step: 10
Training loss: 1.7434649467468262
Validation loss: 2.0782800054037445

Epoch: 6| Step: 11
Training loss: 1.8510534763336182
Validation loss: 2.0453355158528974

Epoch: 6| Step: 12
Training loss: 1.216475248336792
Validation loss: 2.076294950259629

Epoch: 6| Step: 13
Training loss: 2.0521602630615234
Validation loss: 2.091202835882864

Epoch: 143| Step: 0
Training loss: 0.9587144255638123
Validation loss: 2.114404466844374

Epoch: 6| Step: 1
Training loss: 1.497896432876587
Validation loss: 2.1564767540142102

Epoch: 6| Step: 2
Training loss: 1.9877734184265137
Validation loss: 2.1724999207322315

Epoch: 6| Step: 3
Training loss: 1.6240620613098145
Validation loss: 2.2310102370477494

Epoch: 6| Step: 4
Training loss: 1.6166658401489258
Validation loss: 2.1920918495424333

Epoch: 6| Step: 5
Training loss: 1.7463197708129883
Validation loss: 2.1719361043745473

Epoch: 6| Step: 6
Training loss: 2.0754454135894775
Validation loss: 2.138167811978248

Epoch: 6| Step: 7
Training loss: 1.2583059072494507
Validation loss: 2.114858255591444

Epoch: 6| Step: 8
Training loss: 1.3655978441238403
Validation loss: 2.0993017932420135

Epoch: 6| Step: 9
Training loss: 1.6574535369873047
Validation loss: 2.099312982251567

Epoch: 6| Step: 10
Training loss: 1.6508820056915283
Validation loss: 2.0996028492527623

Epoch: 6| Step: 11
Training loss: 1.1928465366363525
Validation loss: 2.1102143218440395

Epoch: 6| Step: 12
Training loss: 2.0691628456115723
Validation loss: 2.137972104933954

Epoch: 6| Step: 13
Training loss: 1.6579785346984863
Validation loss: 2.1324304021814817

Epoch: 144| Step: 0
Training loss: 1.3153220415115356
Validation loss: 2.14340708076313

Epoch: 6| Step: 1
Training loss: 1.6798672676086426
Validation loss: 2.172204235548614

Epoch: 6| Step: 2
Training loss: 1.5595053434371948
Validation loss: 2.1649261315663657

Epoch: 6| Step: 3
Training loss: 1.458030343055725
Validation loss: 2.1679474282008346

Epoch: 6| Step: 4
Training loss: 2.17506742477417
Validation loss: 2.16584183836496

Epoch: 6| Step: 5
Training loss: 1.104628562927246
Validation loss: 2.136746969274295

Epoch: 6| Step: 6
Training loss: 1.899053931236267
Validation loss: 2.1157905004357778

Epoch: 6| Step: 7
Training loss: 1.2738531827926636
Validation loss: 2.0998610296557025

Epoch: 6| Step: 8
Training loss: 1.1843702793121338
Validation loss: 2.122764100310623

Epoch: 6| Step: 9
Training loss: 1.6678215265274048
Validation loss: 2.0976818556426675

Epoch: 6| Step: 10
Training loss: 2.130824565887451
Validation loss: 2.066808751834336

Epoch: 6| Step: 11
Training loss: 1.7914798259735107
Validation loss: 2.0520483704023462

Epoch: 6| Step: 12
Training loss: 1.3550121784210205
Validation loss: 2.039566630958229

Epoch: 6| Step: 13
Training loss: 1.2934199571609497
Validation loss: 2.055971345593852

Epoch: 145| Step: 0
Training loss: 1.5680160522460938
Validation loss: 2.0701895644587855

Epoch: 6| Step: 1
Training loss: 2.0284483432769775
Validation loss: 2.076389986981628

Epoch: 6| Step: 2
Training loss: 1.213611364364624
Validation loss: 2.08443045872514

Epoch: 6| Step: 3
Training loss: 1.5337820053100586
Validation loss: 2.1087261169187483

Epoch: 6| Step: 4
Training loss: 1.1383947134017944
Validation loss: 2.1270659021151963

Epoch: 6| Step: 5
Training loss: 1.9396836757659912
Validation loss: 2.1518393101230746

Epoch: 6| Step: 6
Training loss: 1.2731614112854004
Validation loss: 2.1842424869537354

Epoch: 6| Step: 7
Training loss: 1.303115725517273
Validation loss: 2.2057333172008557

Epoch: 6| Step: 8
Training loss: 1.3602099418640137
Validation loss: 2.2062193245016117

Epoch: 6| Step: 9
Training loss: 1.6356964111328125
Validation loss: 2.2306597155909382

Epoch: 6| Step: 10
Training loss: 1.899675965309143
Validation loss: 2.221307780153008

Epoch: 6| Step: 11
Training loss: 1.5896117687225342
Validation loss: 2.1597674828703686

Epoch: 6| Step: 12
Training loss: 1.7695379257202148
Validation loss: 2.1268934383187243

Epoch: 6| Step: 13
Training loss: 2.164308547973633
Validation loss: 2.134919669038506

Epoch: 146| Step: 0
Training loss: 1.9782919883728027
Validation loss: 2.1213511523380073

Epoch: 6| Step: 1
Training loss: 1.385225534439087
Validation loss: 2.1088920665043656

Epoch: 6| Step: 2
Training loss: 1.7197099924087524
Validation loss: 2.1086588085338636

Epoch: 6| Step: 3
Training loss: 0.8956854343414307
Validation loss: 2.1141700988174765

Epoch: 6| Step: 4
Training loss: 1.491445541381836
Validation loss: 2.088547788640504

Epoch: 6| Step: 5
Training loss: 1.4073383808135986
Validation loss: 2.121053034259427

Epoch: 6| Step: 6
Training loss: 1.4788155555725098
Validation loss: 2.141731422434571

Epoch: 6| Step: 7
Training loss: 1.822700023651123
Validation loss: 2.1375881471941547

Epoch: 6| Step: 8
Training loss: 1.3242475986480713
Validation loss: 2.168080124803769

Epoch: 6| Step: 9
Training loss: 1.9015939235687256
Validation loss: 2.1644708443713445

Epoch: 6| Step: 10
Training loss: 1.6455609798431396
Validation loss: 2.158123339376142

Epoch: 6| Step: 11
Training loss: 2.152731418609619
Validation loss: 2.1738404356023318

Epoch: 6| Step: 12
Training loss: 1.4924830198287964
Validation loss: 2.182190623334659

Epoch: 6| Step: 13
Training loss: 1.4666699171066284
Validation loss: 2.1421923175934823

Epoch: 147| Step: 0
Training loss: 1.5453975200653076
Validation loss: 2.12234043177738

Epoch: 6| Step: 1
Training loss: 1.6995773315429688
Validation loss: 2.0926130023053897

Epoch: 6| Step: 2
Training loss: 1.7177162170410156
Validation loss: 2.083712726510981

Epoch: 6| Step: 3
Training loss: 0.9980655908584595
Validation loss: 2.0741360495167394

Epoch: 6| Step: 4
Training loss: 1.3014295101165771
Validation loss: 2.0969897752167075

Epoch: 6| Step: 5
Training loss: 1.439729928970337
Validation loss: 2.0788038853676087

Epoch: 6| Step: 6
Training loss: 1.6789239645004272
Validation loss: 2.1289844359121015

Epoch: 6| Step: 7
Training loss: 1.585200309753418
Validation loss: 2.1616745559118127

Epoch: 6| Step: 8
Training loss: 1.9925124645233154
Validation loss: 2.183308142487721

Epoch: 6| Step: 9
Training loss: 1.599365472793579
Validation loss: 2.1675062756384573

Epoch: 6| Step: 10
Training loss: 1.3359079360961914
Validation loss: 2.1612024025250505

Epoch: 6| Step: 11
Training loss: 1.4193953275680542
Validation loss: 2.134249617976527

Epoch: 6| Step: 12
Training loss: 2.1921424865722656
Validation loss: 2.1124909770104194

Epoch: 6| Step: 13
Training loss: 1.3705196380615234
Validation loss: 2.087711267573859

Epoch: 148| Step: 0
Training loss: 1.3406238555908203
Validation loss: 2.0821819997602895

Epoch: 6| Step: 1
Training loss: 1.5474895238876343
Validation loss: 2.09479243909159

Epoch: 6| Step: 2
Training loss: 1.565744400024414
Validation loss: 2.1240943016544467

Epoch: 6| Step: 3
Training loss: 1.2768733501434326
Validation loss: 2.140305124303346

Epoch: 6| Step: 4
Training loss: 1.5122358798980713
Validation loss: 2.1603713548311623

Epoch: 6| Step: 5
Training loss: 1.640495777130127
Validation loss: 2.1483511386379117

Epoch: 6| Step: 6
Training loss: 1.6734888553619385
Validation loss: 2.1217032042882775

Epoch: 6| Step: 7
Training loss: 1.6594270467758179
Validation loss: 2.117730843123569

Epoch: 6| Step: 8
Training loss: 1.4209814071655273
Validation loss: 2.0873928736614924

Epoch: 6| Step: 9
Training loss: 1.6756629943847656
Validation loss: 2.0879803280676565

Epoch: 6| Step: 10
Training loss: 1.593526005744934
Validation loss: 2.08199676006071

Epoch: 6| Step: 11
Training loss: 1.4487072229385376
Validation loss: 2.088976867737309

Epoch: 6| Step: 12
Training loss: 1.598680853843689
Validation loss: 2.0999180834780455

Epoch: 6| Step: 13
Training loss: 2.253950357437134
Validation loss: 2.1184553433490056

Epoch: 149| Step: 0
Training loss: 1.6230145692825317
Validation loss: 2.131519471445391

Epoch: 6| Step: 1
Training loss: 1.7948181629180908
Validation loss: 2.1235977782998035

Epoch: 6| Step: 2
Training loss: 0.7686920762062073
Validation loss: 2.144382248642624

Epoch: 6| Step: 3
Training loss: 1.3819456100463867
Validation loss: 2.115477567077965

Epoch: 6| Step: 4
Training loss: 1.3625013828277588
Validation loss: 2.116906553186396

Epoch: 6| Step: 5
Training loss: 1.3695762157440186
Validation loss: 2.103580761981267

Epoch: 6| Step: 6
Training loss: 1.14786696434021
Validation loss: 2.072810713962842

Epoch: 6| Step: 7
Training loss: 1.927695631980896
Validation loss: 2.0887352484528736

Epoch: 6| Step: 8
Training loss: 2.328972101211548
Validation loss: 2.084490422279604

Epoch: 6| Step: 9
Training loss: 1.8084380626678467
Validation loss: 2.121429802269064

Epoch: 6| Step: 10
Training loss: 1.422467827796936
Validation loss: 2.1074323384992537

Epoch: 6| Step: 11
Training loss: 1.555306315422058
Validation loss: 2.1248690210362917

Epoch: 6| Step: 12
Training loss: 1.685104489326477
Validation loss: 2.1303668893793577

Epoch: 6| Step: 13
Training loss: 1.102315068244934
Validation loss: 2.146835360475766

Epoch: 150| Step: 0
Training loss: 1.4320815801620483
Validation loss: 2.118863187810426

Epoch: 6| Step: 1
Training loss: 1.4715791940689087
Validation loss: 2.0912624994913735

Epoch: 6| Step: 2
Training loss: 1.470781683921814
Validation loss: 2.0850044424815843

Epoch: 6| Step: 3
Training loss: 1.372319221496582
Validation loss: 2.0663820325687365

Epoch: 6| Step: 4
Training loss: 1.1071972846984863
Validation loss: 2.0620623070706605

Epoch: 6| Step: 5
Training loss: 1.7487493753433228
Validation loss: 2.0428080853595527

Epoch: 6| Step: 6
Training loss: 1.8733739852905273
Validation loss: 2.0615118088260775

Epoch: 6| Step: 7
Training loss: 1.9426785707473755
Validation loss: 2.0692283953389814

Epoch: 6| Step: 8
Training loss: 1.766374945640564
Validation loss: 2.0803083591563727

Epoch: 6| Step: 9
Training loss: 1.1048953533172607
Validation loss: 2.0756064845669653

Epoch: 6| Step: 10
Training loss: 1.5355812311172485
Validation loss: 2.088728993169723

Epoch: 6| Step: 11
Training loss: 1.4843777418136597
Validation loss: 2.1264226539160616

Epoch: 6| Step: 12
Training loss: 0.9959364533424377
Validation loss: 2.1702180575299006

Epoch: 6| Step: 13
Training loss: 1.4299882650375366
Validation loss: 2.199143276419691

Epoch: 151| Step: 0
Training loss: 2.089339017868042
Validation loss: 2.21491946840799

Epoch: 6| Step: 1
Training loss: 1.8545925617218018
Validation loss: 2.253534227289179

Epoch: 6| Step: 2
Training loss: 1.4986791610717773
Validation loss: 2.212775622644732

Epoch: 6| Step: 3
Training loss: 2.016261100769043
Validation loss: 2.1753477665685836

Epoch: 6| Step: 4
Training loss: 1.1318888664245605
Validation loss: 2.1094212044951735

Epoch: 6| Step: 5
Training loss: 1.9270654916763306
Validation loss: 2.065550369601096

Epoch: 6| Step: 6
Training loss: 1.2915266752243042
Validation loss: 2.05694418696947

Epoch: 6| Step: 7
Training loss: 1.2154942750930786
Validation loss: 2.05230680588753

Epoch: 6| Step: 8
Training loss: 1.5586411952972412
Validation loss: 2.0659516639606927

Epoch: 6| Step: 9
Training loss: 1.921298861503601
Validation loss: 2.062986336728578

Epoch: 6| Step: 10
Training loss: 1.480708122253418
Validation loss: 2.089013832871632

Epoch: 6| Step: 11
Training loss: 0.8272674679756165
Validation loss: 2.0869417754552697

Epoch: 6| Step: 12
Training loss: 1.102597713470459
Validation loss: 2.1006762378959247

Epoch: 6| Step: 13
Training loss: 1.3144503831863403
Validation loss: 2.1466048302189

Epoch: 152| Step: 0
Training loss: 1.848806619644165
Validation loss: 2.155938543299193

Epoch: 6| Step: 1
Training loss: 1.8688013553619385
Validation loss: 2.1887046290982153

Epoch: 6| Step: 2
Training loss: 0.99851393699646
Validation loss: 2.1891287539594915

Epoch: 6| Step: 3
Training loss: 2.2557806968688965
Validation loss: 2.162275037457866

Epoch: 6| Step: 4
Training loss: 1.1307231187820435
Validation loss: 2.156838470889676

Epoch: 6| Step: 5
Training loss: 1.3142285346984863
Validation loss: 2.0984774199865197

Epoch: 6| Step: 6
Training loss: 1.3222692012786865
Validation loss: 2.0902330337032193

Epoch: 6| Step: 7
Training loss: 0.9879814982414246
Validation loss: 2.09107215686511

Epoch: 6| Step: 8
Training loss: 1.2415916919708252
Validation loss: 2.102855186308584

Epoch: 6| Step: 9
Training loss: 1.2406319379806519
Validation loss: 2.119065764129803

Epoch: 6| Step: 10
Training loss: 1.782719373703003
Validation loss: 2.135348058515979

Epoch: 6| Step: 11
Training loss: 1.3760714530944824
Validation loss: 2.1378935767758276

Epoch: 6| Step: 12
Training loss: 1.6957985162734985
Validation loss: 2.125529989119499

Epoch: 6| Step: 13
Training loss: 2.1016385555267334
Validation loss: 2.1288232239343787

Epoch: 153| Step: 0
Training loss: 1.779956579208374
Validation loss: 2.102666534403319

Epoch: 6| Step: 1
Training loss: 1.6196768283843994
Validation loss: 2.0751394866615214

Epoch: 6| Step: 2
Training loss: 1.3151774406433105
Validation loss: 2.1242561596696095

Epoch: 6| Step: 3
Training loss: 1.2387481927871704
Validation loss: 2.0947973164178992

Epoch: 6| Step: 4
Training loss: 0.8762475252151489
Validation loss: 2.119736079246767

Epoch: 6| Step: 5
Training loss: 1.3920152187347412
Validation loss: 2.1185058227149387

Epoch: 6| Step: 6
Training loss: 2.1027376651763916
Validation loss: 2.11725974852039

Epoch: 6| Step: 7
Training loss: 1.9760618209838867
Validation loss: 2.1201404422842045

Epoch: 6| Step: 8
Training loss: 1.7883026599884033
Validation loss: 2.1398933587535733

Epoch: 6| Step: 9
Training loss: 1.6052541732788086
Validation loss: 2.114326379632437

Epoch: 6| Step: 10
Training loss: 1.3221737146377563
Validation loss: 2.1193647423098163

Epoch: 6| Step: 11
Training loss: 1.1463825702667236
Validation loss: 2.0874344610398814

Epoch: 6| Step: 12
Training loss: 1.126950979232788
Validation loss: 2.0930473753201064

Epoch: 6| Step: 13
Training loss: 1.0918415784835815
Validation loss: 2.0871053229096117

Epoch: 154| Step: 0
Training loss: 1.884913682937622
Validation loss: 2.081140646370508

Epoch: 6| Step: 1
Training loss: 1.2815974950790405
Validation loss: 2.127473815794914

Epoch: 6| Step: 2
Training loss: 1.0355185270309448
Validation loss: 2.150176481534076

Epoch: 6| Step: 3
Training loss: 0.9179826974868774
Validation loss: 2.2025300815541256

Epoch: 6| Step: 4
Training loss: 1.0333257913589478
Validation loss: 2.2058530879277054

Epoch: 6| Step: 5
Training loss: 1.685744047164917
Validation loss: 2.21422710598156

Epoch: 6| Step: 6
Training loss: 1.3445394039154053
Validation loss: 2.202996782077256

Epoch: 6| Step: 7
Training loss: 1.4673908948898315
Validation loss: 2.188747908479424

Epoch: 6| Step: 8
Training loss: 1.6399526596069336
Validation loss: 2.1395528137042956

Epoch: 6| Step: 9
Training loss: 2.406312942504883
Validation loss: 2.1320109957007953

Epoch: 6| Step: 10
Training loss: 1.0677300691604614
Validation loss: 2.1176858230303695

Epoch: 6| Step: 11
Training loss: 1.536635398864746
Validation loss: 2.089992510375156

Epoch: 6| Step: 12
Training loss: 1.3027048110961914
Validation loss: 2.075743506031652

Epoch: 6| Step: 13
Training loss: 2.183666706085205
Validation loss: 2.085151844127204

Epoch: 155| Step: 0
Training loss: 1.7943967580795288
Validation loss: 2.082339989241733

Epoch: 6| Step: 1
Training loss: 1.06425940990448
Validation loss: 2.0829354639976256

Epoch: 6| Step: 2
Training loss: 1.058631420135498
Validation loss: 2.1279560801803425

Epoch: 6| Step: 3
Training loss: 1.0273489952087402
Validation loss: 2.1168485738897838

Epoch: 6| Step: 4
Training loss: 1.412693738937378
Validation loss: 2.164914233710176

Epoch: 6| Step: 5
Training loss: 1.3489413261413574
Validation loss: 2.1561936050333004

Epoch: 6| Step: 6
Training loss: 1.7712371349334717
Validation loss: 2.145454091410483

Epoch: 6| Step: 7
Training loss: 1.0463643074035645
Validation loss: 2.1144298263775405

Epoch: 6| Step: 8
Training loss: 2.22515606880188
Validation loss: 2.1189889613018242

Epoch: 6| Step: 9
Training loss: 1.1101539134979248
Validation loss: 2.101559269812799

Epoch: 6| Step: 10
Training loss: 1.793687105178833
Validation loss: 2.082684466915746

Epoch: 6| Step: 11
Training loss: 1.2802951335906982
Validation loss: 2.0771045889905704

Epoch: 6| Step: 12
Training loss: 1.607008457183838
Validation loss: 2.081260094078638

Epoch: 6| Step: 13
Training loss: 1.5387687683105469
Validation loss: 2.0590332297868628

Epoch: 156| Step: 0
Training loss: 1.272748351097107
Validation loss: 2.028455707334703

Epoch: 6| Step: 1
Training loss: 2.6156435012817383
Validation loss: 1.9991109371185303

Epoch: 6| Step: 2
Training loss: 1.7727241516113281
Validation loss: 2.0173515504406345

Epoch: 6| Step: 3
Training loss: 1.205657720565796
Validation loss: 2.026176611582438

Epoch: 6| Step: 4
Training loss: 1.4885720014572144
Validation loss: 2.067515419375512

Epoch: 6| Step: 5
Training loss: 1.6997805833816528
Validation loss: 2.0668540385461625

Epoch: 6| Step: 6
Training loss: 0.7680284976959229
Validation loss: 2.105696396161151

Epoch: 6| Step: 7
Training loss: 1.2926722764968872
Validation loss: 2.1252560359175487

Epoch: 6| Step: 8
Training loss: 1.147005558013916
Validation loss: 2.113793924290647

Epoch: 6| Step: 9
Training loss: 1.4722869396209717
Validation loss: 2.1109954157183246

Epoch: 6| Step: 10
Training loss: 1.4594905376434326
Validation loss: 2.1151131378707064

Epoch: 6| Step: 11
Training loss: 1.3909438848495483
Validation loss: 2.113255859703146

Epoch: 6| Step: 12
Training loss: 1.3565685749053955
Validation loss: 2.127780650251655

Epoch: 6| Step: 13
Training loss: 1.4939309358596802
Validation loss: 2.1241094220069145

Epoch: 157| Step: 0
Training loss: 1.5001072883605957
Validation loss: 2.141254009739045

Epoch: 6| Step: 1
Training loss: 1.988755226135254
Validation loss: 2.1347606284644014

Epoch: 6| Step: 2
Training loss: 1.0194957256317139
Validation loss: 2.1496788404321157

Epoch: 6| Step: 3
Training loss: 1.9640114307403564
Validation loss: 2.152385921888454

Epoch: 6| Step: 4
Training loss: 1.4038326740264893
Validation loss: 2.1768408667656685

Epoch: 6| Step: 5
Training loss: 0.7263894081115723
Validation loss: 2.146805178734564

Epoch: 6| Step: 6
Training loss: 1.3072032928466797
Validation loss: 2.147368459291356

Epoch: 6| Step: 7
Training loss: 1.3908789157867432
Validation loss: 2.136999322522071

Epoch: 6| Step: 8
Training loss: 1.4158281087875366
Validation loss: 2.116100335633883

Epoch: 6| Step: 9
Training loss: 2.0032119750976562
Validation loss: 2.119736522756597

Epoch: 6| Step: 10
Training loss: 1.3173155784606934
Validation loss: 2.082769665666806

Epoch: 6| Step: 11
Training loss: 1.3024108409881592
Validation loss: 2.0526751831013668

Epoch: 6| Step: 12
Training loss: 1.4734315872192383
Validation loss: 2.0410140611792125

Epoch: 6| Step: 13
Training loss: 1.0695332288742065
Validation loss: 2.008526855899442

Epoch: 158| Step: 0
Training loss: 1.6118547916412354
Validation loss: 2.021129849136517

Epoch: 6| Step: 1
Training loss: 1.5495922565460205
Validation loss: 2.037452656735656

Epoch: 6| Step: 2
Training loss: 1.2184807062149048
Validation loss: 2.0374024427065285

Epoch: 6| Step: 3
Training loss: 0.8581315279006958
Validation loss: 2.0351218613245154

Epoch: 6| Step: 4
Training loss: 1.1154632568359375
Validation loss: 2.0687477845017628

Epoch: 6| Step: 5
Training loss: 1.6176279783248901
Validation loss: 2.0777923086638093

Epoch: 6| Step: 6
Training loss: 0.8674373030662537
Validation loss: 2.1040211621151177

Epoch: 6| Step: 7
Training loss: 1.413285255432129
Validation loss: 2.11418491794217

Epoch: 6| Step: 8
Training loss: 1.6540484428405762
Validation loss: 2.1308902258514077

Epoch: 6| Step: 9
Training loss: 1.3859655857086182
Validation loss: 2.107392757169662

Epoch: 6| Step: 10
Training loss: 1.1779985427856445
Validation loss: 2.1068441252554617

Epoch: 6| Step: 11
Training loss: 1.5583183765411377
Validation loss: 2.069154694516172

Epoch: 6| Step: 12
Training loss: 2.0341763496398926
Validation loss: 2.060649150161333

Epoch: 6| Step: 13
Training loss: 2.551140069961548
Validation loss: 2.048295504303389

Epoch: 159| Step: 0
Training loss: 1.597687005996704
Validation loss: 2.069867394303763

Epoch: 6| Step: 1
Training loss: 1.350656509399414
Validation loss: 2.0417848351181194

Epoch: 6| Step: 2
Training loss: 1.699404001235962
Validation loss: 2.0659512076326596

Epoch: 6| Step: 3
Training loss: 1.473914623260498
Validation loss: 2.038053772782767

Epoch: 6| Step: 4
Training loss: 0.9595487117767334
Validation loss: 2.0530879728255735

Epoch: 6| Step: 5
Training loss: 1.2360193729400635
Validation loss: 2.0429582006187847

Epoch: 6| Step: 6
Training loss: 1.612792730331421
Validation loss: 2.0553377264289447

Epoch: 6| Step: 7
Training loss: 1.2894117832183838
Validation loss: 2.0527073516640613

Epoch: 6| Step: 8
Training loss: 1.2836788892745972
Validation loss: 2.061232428396902

Epoch: 6| Step: 9
Training loss: 1.6647992134094238
Validation loss: 2.0757298136270173

Epoch: 6| Step: 10
Training loss: 1.5533219575881958
Validation loss: 2.085657440206056

Epoch: 6| Step: 11
Training loss: 1.0252151489257812
Validation loss: 2.109807748948374

Epoch: 6| Step: 12
Training loss: 1.4445641040802002
Validation loss: 2.135665391081123

Epoch: 6| Step: 13
Training loss: 1.6872845888137817
Validation loss: 2.1600324953756025

Epoch: 160| Step: 0
Training loss: 1.3800767660140991
Validation loss: 2.163898624399657

Epoch: 6| Step: 1
Training loss: 0.9271226525306702
Validation loss: 2.146020230426583

Epoch: 6| Step: 2
Training loss: 1.5082823038101196
Validation loss: 2.1271017033566713

Epoch: 6| Step: 3
Training loss: 1.9670600891113281
Validation loss: 2.088337121471282

Epoch: 6| Step: 4
Training loss: 0.6889628171920776
Validation loss: 2.0747544406562723

Epoch: 6| Step: 5
Training loss: 1.7414777278900146
Validation loss: 2.0572666801432127

Epoch: 6| Step: 6
Training loss: 1.7370964288711548
Validation loss: 2.0664339744916527

Epoch: 6| Step: 7
Training loss: 1.8934028148651123
Validation loss: 2.071050395247757

Epoch: 6| Step: 8
Training loss: 1.3269598484039307
Validation loss: 2.07733440655534

Epoch: 6| Step: 9
Training loss: 1.6621417999267578
Validation loss: 2.099533866810542

Epoch: 6| Step: 10
Training loss: 0.880028486251831
Validation loss: 2.1259389077463458

Epoch: 6| Step: 11
Training loss: 0.8273559212684631
Validation loss: 2.1581424346534153

Epoch: 6| Step: 12
Training loss: 1.5161306858062744
Validation loss: 2.167229021749189

Epoch: 6| Step: 13
Training loss: 2.1955502033233643
Validation loss: 2.180215217733896

Epoch: 161| Step: 0
Training loss: 1.4148826599121094
Validation loss: 2.1440579032385223

Epoch: 6| Step: 1
Training loss: 1.5086266994476318
Validation loss: 2.103649100949687

Epoch: 6| Step: 2
Training loss: 1.1786003112792969
Validation loss: 2.0818520540832193

Epoch: 6| Step: 3
Training loss: 1.0619608163833618
Validation loss: 2.05723556651864

Epoch: 6| Step: 4
Training loss: 1.0163123607635498
Validation loss: 2.0300694780965007

Epoch: 6| Step: 5
Training loss: 1.608337640762329
Validation loss: 2.03039804838037

Epoch: 6| Step: 6
Training loss: 1.17075514793396
Validation loss: 2.01745036596893

Epoch: 6| Step: 7
Training loss: 1.6627987623214722
Validation loss: 2.032950940952506

Epoch: 6| Step: 8
Training loss: 1.7291444540023804
Validation loss: 2.0623730651793943

Epoch: 6| Step: 9
Training loss: 1.1792386770248413
Validation loss: 2.104046239647814

Epoch: 6| Step: 10
Training loss: 1.4499614238739014
Validation loss: 2.0949300694209274

Epoch: 6| Step: 11
Training loss: 1.094869613647461
Validation loss: 2.1135288310307327

Epoch: 6| Step: 12
Training loss: 1.682999849319458
Validation loss: 2.111859920204327

Epoch: 6| Step: 13
Training loss: 2.265669584274292
Validation loss: 2.110831974655069

Epoch: 162| Step: 0
Training loss: 1.7954031229019165
Validation loss: 2.120449568635674

Epoch: 6| Step: 1
Training loss: 0.8831305503845215
Validation loss: 2.1325116183168147

Epoch: 6| Step: 2
Training loss: 1.7243809700012207
Validation loss: 2.1399621732773317

Epoch: 6| Step: 3
Training loss: 1.2797832489013672
Validation loss: 2.147296567117014

Epoch: 6| Step: 4
Training loss: 1.773298740386963
Validation loss: 2.1716400961722098

Epoch: 6| Step: 5
Training loss: 1.288785696029663
Validation loss: 2.1945780605398197

Epoch: 6| Step: 6
Training loss: 1.098686695098877
Validation loss: 2.180389964452354

Epoch: 6| Step: 7
Training loss: 0.9292384386062622
Validation loss: 2.2020677315291537

Epoch: 6| Step: 8
Training loss: 1.2625491619110107
Validation loss: 2.222855544859363

Epoch: 6| Step: 9
Training loss: 1.8519431352615356
Validation loss: 2.211514106360815

Epoch: 6| Step: 10
Training loss: 1.2948884963989258
Validation loss: 2.186090688551626

Epoch: 6| Step: 11
Training loss: 1.6950538158416748
Validation loss: 2.1336097255829842

Epoch: 6| Step: 12
Training loss: 1.328336477279663
Validation loss: 2.0830391171158

Epoch: 6| Step: 13
Training loss: 1.5443222522735596
Validation loss: 2.0345908518760436

Epoch: 163| Step: 0
Training loss: 0.7502092719078064
Validation loss: 2.0159352928079586

Epoch: 6| Step: 1
Training loss: 2.0429046154022217
Validation loss: 1.9892643677291049

Epoch: 6| Step: 2
Training loss: 1.6864748001098633
Validation loss: 1.9842834729020313

Epoch: 6| Step: 3
Training loss: 1.6688506603240967
Validation loss: 1.9772864977518718

Epoch: 6| Step: 4
Training loss: 1.8533514738082886
Validation loss: 1.9724092714248165

Epoch: 6| Step: 5
Training loss: 1.1201331615447998
Validation loss: 1.9753452475352953

Epoch: 6| Step: 6
Training loss: 1.1512306928634644
Validation loss: 1.995569816199682

Epoch: 6| Step: 7
Training loss: 1.616833209991455
Validation loss: 2.0173791634139193

Epoch: 6| Step: 8
Training loss: 1.2299319505691528
Validation loss: 2.074015901934716

Epoch: 6| Step: 9
Training loss: 2.3219971656799316
Validation loss: 2.113874045751428

Epoch: 6| Step: 10
Training loss: 1.3947973251342773
Validation loss: 2.133096400127616

Epoch: 6| Step: 11
Training loss: 1.255989670753479
Validation loss: 2.13650131353768

Epoch: 6| Step: 12
Training loss: 0.6392091512680054
Validation loss: 2.1531792789377193

Epoch: 6| Step: 13
Training loss: 1.6900662183761597
Validation loss: 2.1734369980391635

Epoch: 164| Step: 0
Training loss: 1.6505054235458374
Validation loss: 2.1522596984781246

Epoch: 6| Step: 1
Training loss: 1.4658324718475342
Validation loss: 2.136942373808994

Epoch: 6| Step: 2
Training loss: 1.2831789255142212
Validation loss: 2.095951244395266

Epoch: 6| Step: 3
Training loss: 1.5677337646484375
Validation loss: 2.112613893324329

Epoch: 6| Step: 4
Training loss: 0.8621377944946289
Validation loss: 2.1391511450531664

Epoch: 6| Step: 5
Training loss: 1.5394651889801025
Validation loss: 2.0966642108014835

Epoch: 6| Step: 6
Training loss: 1.0180144309997559
Validation loss: 2.1003383821056736

Epoch: 6| Step: 7
Training loss: 1.8537726402282715
Validation loss: 2.091542092702722

Epoch: 6| Step: 8
Training loss: 1.4489920139312744
Validation loss: 2.1012413514557706

Epoch: 6| Step: 9
Training loss: 1.3225438594818115
Validation loss: 2.105085834380119

Epoch: 6| Step: 10
Training loss: 1.5847539901733398
Validation loss: 2.0926390258214806

Epoch: 6| Step: 11
Training loss: 1.0583810806274414
Validation loss: 2.078593454053325

Epoch: 6| Step: 12
Training loss: 1.3365797996520996
Validation loss: 2.0712994683173394

Epoch: 6| Step: 13
Training loss: 1.6788978576660156
Validation loss: 2.037229960964572

Epoch: 165| Step: 0
Training loss: 1.0255608558654785
Validation loss: 2.0381540624044274

Epoch: 6| Step: 1
Training loss: 1.5011924505233765
Validation loss: 2.040561999044111

Epoch: 6| Step: 2
Training loss: 0.8601964712142944
Validation loss: 2.038830887886786

Epoch: 6| Step: 3
Training loss: 0.8555866479873657
Validation loss: 2.0243437572192122

Epoch: 6| Step: 4
Training loss: 2.0503249168395996
Validation loss: 2.055851823540144

Epoch: 6| Step: 5
Training loss: 1.2538565397262573
Validation loss: 2.1021659194782214

Epoch: 6| Step: 6
Training loss: 1.3738479614257812
Validation loss: 2.1432224294190765

Epoch: 6| Step: 7
Training loss: 1.5679945945739746
Validation loss: 2.1636889724321264

Epoch: 6| Step: 8
Training loss: 2.0027830600738525
Validation loss: 2.147431265923285

Epoch: 6| Step: 9
Training loss: 1.6293375492095947
Validation loss: 2.1488938767422914

Epoch: 6| Step: 10
Training loss: 1.3507108688354492
Validation loss: 2.1578288462854203

Epoch: 6| Step: 11
Training loss: 1.092021107673645
Validation loss: 2.1289055065442155

Epoch: 6| Step: 12
Training loss: 1.6467018127441406
Validation loss: 2.147570113981924

Epoch: 6| Step: 13
Training loss: 0.8079468607902527
Validation loss: 2.1259391256558

Epoch: 166| Step: 0
Training loss: 1.4328460693359375
Validation loss: 2.1568387708356305

Epoch: 6| Step: 1
Training loss: 0.972833514213562
Validation loss: 2.1376686480737503

Epoch: 6| Step: 2
Training loss: 1.5815942287445068
Validation loss: 2.1296070121949717

Epoch: 6| Step: 3
Training loss: 1.0723793506622314
Validation loss: 2.1247888713754635

Epoch: 6| Step: 4
Training loss: 1.3202967643737793
Validation loss: 2.1172679649886263

Epoch: 6| Step: 5
Training loss: 1.03855562210083
Validation loss: 2.1107772575911654

Epoch: 6| Step: 6
Training loss: 1.2494266033172607
Validation loss: 2.123803682224725

Epoch: 6| Step: 7
Training loss: 1.8569817543029785
Validation loss: 2.11245342352057

Epoch: 6| Step: 8
Training loss: 0.8108962774276733
Validation loss: 2.1111921930825837

Epoch: 6| Step: 9
Training loss: 1.21342134475708
Validation loss: 2.0480664263489428

Epoch: 6| Step: 10
Training loss: 1.7463099956512451
Validation loss: 2.02166126876749

Epoch: 6| Step: 11
Training loss: 0.9713508486747742
Validation loss: 2.0080845958443096

Epoch: 6| Step: 12
Training loss: 1.937369704246521
Validation loss: 1.9847809717219362

Epoch: 6| Step: 13
Training loss: 1.9147521257400513
Validation loss: 1.9986491408399356

Epoch: 167| Step: 0
Training loss: 1.699177622795105
Validation loss: 2.0154549601257488

Epoch: 6| Step: 1
Training loss: 0.9802748560905457
Validation loss: 2.0066045740599274

Epoch: 6| Step: 2
Training loss: 1.7125544548034668
Validation loss: 2.0078655814611786

Epoch: 6| Step: 3
Training loss: 1.0021347999572754
Validation loss: 2.0167948789494012

Epoch: 6| Step: 4
Training loss: 1.5633981227874756
Validation loss: 2.0175065225170505

Epoch: 6| Step: 5
Training loss: 1.462374210357666
Validation loss: 2.0492235973317134

Epoch: 6| Step: 6
Training loss: 1.6113160848617554
Validation loss: 2.0824255225478963

Epoch: 6| Step: 7
Training loss: 0.9496067762374878
Validation loss: 2.1337969226221882

Epoch: 6| Step: 8
Training loss: 1.5202155113220215
Validation loss: 2.1184948772512455

Epoch: 6| Step: 9
Training loss: 0.9803580045700073
Validation loss: 2.130320497738418

Epoch: 6| Step: 10
Training loss: 1.5476903915405273
Validation loss: 2.1325320992418515

Epoch: 6| Step: 11
Training loss: 0.9708406329154968
Validation loss: 2.131006343390352

Epoch: 6| Step: 12
Training loss: 1.7200003862380981
Validation loss: 2.1176394211348666

Epoch: 6| Step: 13
Training loss: 1.481209635734558
Validation loss: 2.121440727223632

Epoch: 168| Step: 0
Training loss: 1.2696589231491089
Validation loss: 2.103892723719279

Epoch: 6| Step: 1
Training loss: 2.086162567138672
Validation loss: 2.117688271307176

Epoch: 6| Step: 2
Training loss: 1.6181896924972534
Validation loss: 2.0793001164672194

Epoch: 6| Step: 3
Training loss: 1.4531219005584717
Validation loss: 2.0845818442683064

Epoch: 6| Step: 4
Training loss: 1.75290048122406
Validation loss: 2.0828951430577103

Epoch: 6| Step: 5
Training loss: 1.6601672172546387
Validation loss: 2.1313418726767264

Epoch: 6| Step: 6
Training loss: 1.333409309387207
Validation loss: 2.1902156670888266

Epoch: 6| Step: 7
Training loss: 1.5815362930297852
Validation loss: 2.2272732693661927

Epoch: 6| Step: 8
Training loss: 1.5696072578430176
Validation loss: 2.2051680498225714

Epoch: 6| Step: 9
Training loss: 1.1805484294891357
Validation loss: 2.1569896257051857

Epoch: 6| Step: 10
Training loss: 1.3472065925598145
Validation loss: 2.093075680476363

Epoch: 6| Step: 11
Training loss: 1.6420929431915283
Validation loss: 2.053675987387216

Epoch: 6| Step: 12
Training loss: 0.7579846382141113
Validation loss: 2.0292188429063365

Epoch: 6| Step: 13
Training loss: 0.8532760739326477
Validation loss: 2.006824703626735

Epoch: 169| Step: 0
Training loss: 1.4033775329589844
Validation loss: 1.984955072402954

Epoch: 6| Step: 1
Training loss: 1.59221613407135
Validation loss: 1.998949154730766

Epoch: 6| Step: 2
Training loss: 1.2936865091323853
Validation loss: 2.01261491416603

Epoch: 6| Step: 3
Training loss: 1.890568733215332
Validation loss: 2.042158353713251

Epoch: 6| Step: 4
Training loss: 1.0377310514450073
Validation loss: 2.0648252143654773

Epoch: 6| Step: 5
Training loss: 1.5251383781433105
Validation loss: 2.092468350164352

Epoch: 6| Step: 6
Training loss: 1.4012653827667236
Validation loss: 2.126116834661012

Epoch: 6| Step: 7
Training loss: 1.4123902320861816
Validation loss: 2.14179737593538

Epoch: 6| Step: 8
Training loss: 1.1544252634048462
Validation loss: 2.1657387133567565

Epoch: 6| Step: 9
Training loss: 0.8119754791259766
Validation loss: 2.139044556566464

Epoch: 6| Step: 10
Training loss: 1.696325659751892
Validation loss: 2.1625195062288673

Epoch: 6| Step: 11
Training loss: 0.9919983148574829
Validation loss: 2.1228744727309032

Epoch: 6| Step: 12
Training loss: 1.3468761444091797
Validation loss: 2.102601517913162

Epoch: 6| Step: 13
Training loss: 1.6055452823638916
Validation loss: 2.0847489192921627

Epoch: 170| Step: 0
Training loss: 1.6403870582580566
Validation loss: 2.047035509540189

Epoch: 6| Step: 1
Training loss: 1.312246322631836
Validation loss: 2.039348761240641

Epoch: 6| Step: 2
Training loss: 1.1993381977081299
Validation loss: 2.0520713252405964

Epoch: 6| Step: 3
Training loss: 0.9062938094139099
Validation loss: 2.0449925007358676

Epoch: 6| Step: 4
Training loss: 1.8662796020507812
Validation loss: 2.079464961123723

Epoch: 6| Step: 5
Training loss: 1.4242843389511108
Validation loss: 2.1034707279615503

Epoch: 6| Step: 6
Training loss: 1.0957043170928955
Validation loss: 2.104394380764295

Epoch: 6| Step: 7
Training loss: 1.5938055515289307
Validation loss: 2.081836918348907

Epoch: 6| Step: 8
Training loss: 0.976658284664154
Validation loss: 2.0727353595918223

Epoch: 6| Step: 9
Training loss: 1.17023766040802
Validation loss: 2.063246665462371

Epoch: 6| Step: 10
Training loss: 1.299522876739502
Validation loss: 2.0775832206972185

Epoch: 6| Step: 11
Training loss: 1.2359893321990967
Validation loss: 2.0468552343307005

Epoch: 6| Step: 12
Training loss: 1.1727094650268555
Validation loss: 2.0892548817460255

Epoch: 6| Step: 13
Training loss: 0.6777601838111877
Validation loss: 2.0887824258496686

Epoch: 171| Step: 0
Training loss: 1.4078643321990967
Validation loss: 2.064372798447968

Epoch: 6| Step: 1
Training loss: 1.7142581939697266
Validation loss: 2.0482775037006666

Epoch: 6| Step: 2
Training loss: 1.0575281381607056
Validation loss: 2.050718386967977

Epoch: 6| Step: 3
Training loss: 1.379192590713501
Validation loss: 2.048322731448758

Epoch: 6| Step: 4
Training loss: 1.36683988571167
Validation loss: 2.0594627498298563

Epoch: 6| Step: 5
Training loss: 1.2411561012268066
Validation loss: 2.078416814086258

Epoch: 6| Step: 6
Training loss: 1.3448349237442017
Validation loss: 2.0473644964156614

Epoch: 6| Step: 7
Training loss: 0.9632095098495483
Validation loss: 2.088402719907863

Epoch: 6| Step: 8
Training loss: 1.648910641670227
Validation loss: 2.100068789656444

Epoch: 6| Step: 9
Training loss: 1.1835182905197144
Validation loss: 2.0901885365927093

Epoch: 6| Step: 10
Training loss: 0.7418816089630127
Validation loss: 2.0960006457503124

Epoch: 6| Step: 11
Training loss: 0.9149866104125977
Validation loss: 2.099182818525581

Epoch: 6| Step: 12
Training loss: 1.4314262866973877
Validation loss: 2.1010537429522445

Epoch: 6| Step: 13
Training loss: 1.8859286308288574
Validation loss: 2.0920088060440554

Epoch: 172| Step: 0
Training loss: 1.2428197860717773
Validation loss: 2.0601334443656345

Epoch: 6| Step: 1
Training loss: 1.580200433731079
Validation loss: 2.060780753371536

Epoch: 6| Step: 2
Training loss: 1.61716628074646
Validation loss: 2.0523924519938808

Epoch: 6| Step: 3
Training loss: 1.430382490158081
Validation loss: 2.0279178388657106

Epoch: 6| Step: 4
Training loss: 1.198799729347229
Validation loss: 2.0165475081372004

Epoch: 6| Step: 5
Training loss: 1.403626799583435
Validation loss: 2.018057502726073

Epoch: 6| Step: 6
Training loss: 1.0609347820281982
Validation loss: 2.0120597013863186

Epoch: 6| Step: 7
Training loss: 1.2204933166503906
Validation loss: 2.0388267335071357

Epoch: 6| Step: 8
Training loss: 1.380086898803711
Validation loss: 2.0527698634773173

Epoch: 6| Step: 9
Training loss: 1.3822152614593506
Validation loss: 2.0501117603753203

Epoch: 6| Step: 10
Training loss: 0.9212964773178101
Validation loss: 2.0594418894860054

Epoch: 6| Step: 11
Training loss: 1.0122478008270264
Validation loss: 2.066496968269348

Epoch: 6| Step: 12
Training loss: 0.8420864343643188
Validation loss: 2.0839107228863623

Epoch: 6| Step: 13
Training loss: 0.7743848562240601
Validation loss: 2.0839113727692635

Epoch: 173| Step: 0
Training loss: 0.9033956527709961
Validation loss: 2.0695037598251016

Epoch: 6| Step: 1
Training loss: 1.3322012424468994
Validation loss: 2.0528458664494176

Epoch: 6| Step: 2
Training loss: 1.2275025844573975
Validation loss: 2.0687745155826693

Epoch: 6| Step: 3
Training loss: 1.022456169128418
Validation loss: 2.0596081056902484

Epoch: 6| Step: 4
Training loss: 1.0997636318206787
Validation loss: 2.0696086293907574

Epoch: 6| Step: 5
Training loss: 1.9243457317352295
Validation loss: 2.0400309485773884

Epoch: 6| Step: 6
Training loss: 0.7831799983978271
Validation loss: 2.0508041407472346

Epoch: 6| Step: 7
Training loss: 1.054314374923706
Validation loss: 2.0521965616492817

Epoch: 6| Step: 8
Training loss: 1.5535838603973389
Validation loss: 2.054445243650867

Epoch: 6| Step: 9
Training loss: 0.9786994457244873
Validation loss: 2.0622879202647875

Epoch: 6| Step: 10
Training loss: 0.9109256267547607
Validation loss: 2.0526613407237555

Epoch: 6| Step: 11
Training loss: 1.288042664527893
Validation loss: 2.0710929439913843

Epoch: 6| Step: 12
Training loss: 1.7512266635894775
Validation loss: 2.081787156802352

Epoch: 6| Step: 13
Training loss: 1.4407269954681396
Validation loss: 2.1060040394465127

Epoch: 174| Step: 0
Training loss: 0.9787849187850952
Validation loss: 2.12050953988106

Epoch: 6| Step: 1
Training loss: 1.418245792388916
Validation loss: 2.127146174830775

Epoch: 6| Step: 2
Training loss: 1.4858758449554443
Validation loss: 2.1176513856457126

Epoch: 6| Step: 3
Training loss: 1.4437254667282104
Validation loss: 2.106933443777023

Epoch: 6| Step: 4
Training loss: 0.937819242477417
Validation loss: 2.0835396948681084

Epoch: 6| Step: 5
Training loss: 0.8167614936828613
Validation loss: 2.048219726931664

Epoch: 6| Step: 6
Training loss: 1.2562592029571533
Validation loss: 2.062075348310573

Epoch: 6| Step: 7
Training loss: 1.1815283298492432
Validation loss: 2.045265431045204

Epoch: 6| Step: 8
Training loss: 1.3382267951965332
Validation loss: 2.066846666797515

Epoch: 6| Step: 9
Training loss: 1.2585057020187378
Validation loss: 2.0679782436740015

Epoch: 6| Step: 10
Training loss: 1.0431780815124512
Validation loss: 2.0688703419059835

Epoch: 6| Step: 11
Training loss: 1.282554268836975
Validation loss: 2.0488716171633814

Epoch: 6| Step: 12
Training loss: 0.8966001272201538
Validation loss: 2.0429783123795704

Epoch: 6| Step: 13
Training loss: 1.4316450357437134
Validation loss: 2.019513075069715

Epoch: 175| Step: 0
Training loss: 1.0194035768508911
Validation loss: 2.0052971429722284

Epoch: 6| Step: 1
Training loss: 1.397456407546997
Validation loss: 2.0174401216609503

Epoch: 6| Step: 2
Training loss: 0.8638778328895569
Validation loss: 2.033824625835624

Epoch: 6| Step: 3
Training loss: 1.0449457168579102
Validation loss: 2.0787457266161518

Epoch: 6| Step: 4
Training loss: 1.2343488931655884
Validation loss: 2.0796347279702463

Epoch: 6| Step: 5
Training loss: 1.1318702697753906
Validation loss: 2.1015710625597226

Epoch: 6| Step: 6
Training loss: 1.1931387186050415
Validation loss: 2.1032532568900817

Epoch: 6| Step: 7
Training loss: 1.1064060926437378
Validation loss: 2.0979173644896476

Epoch: 6| Step: 8
Training loss: 0.9244242906570435
Validation loss: 2.079905289475636

Epoch: 6| Step: 9
Training loss: 1.0152387619018555
Validation loss: 2.0514017176884476

Epoch: 6| Step: 10
Training loss: 1.034576416015625
Validation loss: 2.033650577709239

Epoch: 6| Step: 11
Training loss: 1.720287799835205
Validation loss: 2.0152414524427025

Epoch: 6| Step: 12
Training loss: 1.0388922691345215
Validation loss: 2.0096498279161352

Epoch: 6| Step: 13
Training loss: 2.3078408241271973
Validation loss: 2.0103897099853842

Epoch: 176| Step: 0
Training loss: 1.450249433517456
Validation loss: 1.989709017097309

Epoch: 6| Step: 1
Training loss: 1.3769457340240479
Validation loss: 1.9874935752602034

Epoch: 6| Step: 2
Training loss: 1.1774702072143555
Validation loss: 1.9489301596918414

Epoch: 6| Step: 3
Training loss: 0.9427089691162109
Validation loss: 1.976330021376251

Epoch: 6| Step: 4
Training loss: 0.7172565460205078
Validation loss: 1.9841957912650159

Epoch: 6| Step: 5
Training loss: 1.6660972833633423
Validation loss: 2.0401761621557255

Epoch: 6| Step: 6
Training loss: 1.3212326765060425
Validation loss: 2.0142150745596936

Epoch: 6| Step: 7
Training loss: 1.1880967617034912
Validation loss: 2.0300037796779344

Epoch: 6| Step: 8
Training loss: 1.0700898170471191
Validation loss: 2.055649889412747

Epoch: 6| Step: 9
Training loss: 1.4977080821990967
Validation loss: 2.0521166247706257

Epoch: 6| Step: 10
Training loss: 1.694187879562378
Validation loss: 2.0372602990878526

Epoch: 6| Step: 11
Training loss: 1.1785142421722412
Validation loss: 2.041592497979441

Epoch: 6| Step: 12
Training loss: 1.1924335956573486
Validation loss: 2.037155992241316

Epoch: 6| Step: 13
Training loss: 1.5670946836471558
Validation loss: 2.010838790606427

Epoch: 177| Step: 0
Training loss: 1.57420015335083
Validation loss: 2.0759127909137356

Epoch: 6| Step: 1
Training loss: 1.5352485179901123
Validation loss: 2.0551433332504763

Epoch: 6| Step: 2
Training loss: 0.8898391127586365
Validation loss: 2.068066191929643

Epoch: 6| Step: 3
Training loss: 1.3410944938659668
Validation loss: 2.101793186638945

Epoch: 6| Step: 4
Training loss: 0.7738890647888184
Validation loss: 2.126445770263672

Epoch: 6| Step: 5
Training loss: 0.7254205346107483
Validation loss: 2.1707853604388494

Epoch: 6| Step: 6
Training loss: 1.2513024806976318
Validation loss: 2.1652907761194373

Epoch: 6| Step: 7
Training loss: 1.431563377380371
Validation loss: 2.153082783504199

Epoch: 6| Step: 8
Training loss: 1.4250245094299316
Validation loss: 2.153877583883142

Epoch: 6| Step: 9
Training loss: 1.0705060958862305
Validation loss: 2.1346166210789836

Epoch: 6| Step: 10
Training loss: 1.1918894052505493
Validation loss: 2.104563610528105

Epoch: 6| Step: 11
Training loss: 1.330478310585022
Validation loss: 2.088910630954209

Epoch: 6| Step: 12
Training loss: 1.2572007179260254
Validation loss: 2.07787404265455

Epoch: 6| Step: 13
Training loss: 1.6362448930740356
Validation loss: 2.0305433850134573

Epoch: 178| Step: 0
Training loss: 0.918220579624176
Validation loss: 2.0065113972592097

Epoch: 6| Step: 1
Training loss: 1.395999789237976
Validation loss: 1.9730447261564192

Epoch: 6| Step: 2
Training loss: 1.5409468412399292
Validation loss: 1.9935190472551572

Epoch: 6| Step: 3
Training loss: 1.0561603307724
Validation loss: 1.9584200048959384

Epoch: 6| Step: 4
Training loss: 0.6215270161628723
Validation loss: 1.9910029954807733

Epoch: 6| Step: 5
Training loss: 1.5670597553253174
Validation loss: 1.9949224097754366

Epoch: 6| Step: 6
Training loss: 1.132312536239624
Validation loss: 2.027062626295192

Epoch: 6| Step: 7
Training loss: 1.399526834487915
Validation loss: 2.031800035507448

Epoch: 6| Step: 8
Training loss: 0.8762054443359375
Validation loss: 2.0774881557751725

Epoch: 6| Step: 9
Training loss: 1.231757402420044
Validation loss: 2.0976014162904475

Epoch: 6| Step: 10
Training loss: 1.2218208312988281
Validation loss: 2.111510461376559

Epoch: 6| Step: 11
Training loss: 2.0913002490997314
Validation loss: 2.1201380862984607

Epoch: 6| Step: 12
Training loss: 0.970867931842804
Validation loss: 2.0765766828290877

Epoch: 6| Step: 13
Training loss: 0.7467639446258545
Validation loss: 2.0806571540012153

Epoch: 179| Step: 0
Training loss: 1.5319945812225342
Validation loss: 2.0585186789112706

Epoch: 6| Step: 1
Training loss: 1.921039342880249
Validation loss: 2.039398839396815

Epoch: 6| Step: 2
Training loss: 1.6219947338104248
Validation loss: 2.034335599150709

Epoch: 6| Step: 3
Training loss: 0.6530252695083618
Validation loss: 2.025987599485664

Epoch: 6| Step: 4
Training loss: 1.2405176162719727
Validation loss: 2.0199557453073482

Epoch: 6| Step: 5
Training loss: 0.8916088938713074
Validation loss: 2.019795330621863

Epoch: 6| Step: 6
Training loss: 1.1927649974822998
Validation loss: 2.0477479862910446

Epoch: 6| Step: 7
Training loss: 1.5350980758666992
Validation loss: 2.029917219633697

Epoch: 6| Step: 8
Training loss: 1.047279715538025
Validation loss: 2.002761176837388

Epoch: 6| Step: 9
Training loss: 0.9773363471031189
Validation loss: 1.9928280230491393

Epoch: 6| Step: 10
Training loss: 1.0022294521331787
Validation loss: 2.003282299605749

Epoch: 6| Step: 11
Training loss: 1.0694316625595093
Validation loss: 1.9955972984272947

Epoch: 6| Step: 12
Training loss: 0.8218300938606262
Validation loss: 2.011275957989436

Epoch: 6| Step: 13
Training loss: 1.3748332262039185
Validation loss: 2.019367221863039

Epoch: 180| Step: 0
Training loss: 1.1288292407989502
Validation loss: 2.0658634747228315

Epoch: 6| Step: 1
Training loss: 1.0621535778045654
Validation loss: 2.088235749993273

Epoch: 6| Step: 2
Training loss: 0.8376088738441467
Validation loss: 2.1089668145743747

Epoch: 6| Step: 3
Training loss: 1.6338441371917725
Validation loss: 2.157213123895789

Epoch: 6| Step: 4
Training loss: 1.4019638299942017
Validation loss: 2.1343277705613004

Epoch: 6| Step: 5
Training loss: 1.0844478607177734
Validation loss: 2.127436891678841

Epoch: 6| Step: 6
Training loss: 1.6957330703735352
Validation loss: 2.1230452393972747

Epoch: 6| Step: 7
Training loss: 1.402551531791687
Validation loss: 2.0926192422066965

Epoch: 6| Step: 8
Training loss: 1.1708194017410278
Validation loss: 2.0504621305773334

Epoch: 6| Step: 9
Training loss: 1.215508222579956
Validation loss: 2.0109287154289985

Epoch: 6| Step: 10
Training loss: 0.9889078736305237
Validation loss: 2.0172412010931198

Epoch: 6| Step: 11
Training loss: 1.0038402080535889
Validation loss: 1.9826178268719745

Epoch: 6| Step: 12
Training loss: 0.6479735374450684
Validation loss: 1.991075942593236

Epoch: 6| Step: 13
Training loss: 0.8091546297073364
Validation loss: 1.9858800198442192

Epoch: 181| Step: 0
Training loss: 1.3438570499420166
Validation loss: 2.000776198602492

Epoch: 6| Step: 1
Training loss: 0.8959057331085205
Validation loss: 1.9781794548034668

Epoch: 6| Step: 2
Training loss: 1.3969998359680176
Validation loss: 1.99886865128753

Epoch: 6| Step: 3
Training loss: 0.7822805047035217
Validation loss: 2.0058024109050794

Epoch: 6| Step: 4
Training loss: 0.9239976406097412
Validation loss: 2.025925141508861

Epoch: 6| Step: 5
Training loss: 1.6347651481628418
Validation loss: 2.0354253515120475

Epoch: 6| Step: 6
Training loss: 1.0249907970428467
Validation loss: 2.0477493988570346

Epoch: 6| Step: 7
Training loss: 0.8385173678398132
Validation loss: 2.0612599234427176

Epoch: 6| Step: 8
Training loss: 1.2340819835662842
Validation loss: 2.0967563967550955

Epoch: 6| Step: 9
Training loss: 0.8451895713806152
Validation loss: 2.079184350147042

Epoch: 6| Step: 10
Training loss: 1.4849154949188232
Validation loss: 2.069623031923848

Epoch: 6| Step: 11
Training loss: 0.9212335348129272
Validation loss: 2.066926916440328

Epoch: 6| Step: 12
Training loss: 1.1761057376861572
Validation loss: 2.0398836315319104

Epoch: 6| Step: 13
Training loss: 1.4161815643310547
Validation loss: 2.0055890954950804

Epoch: 182| Step: 0
Training loss: 0.9857521653175354
Validation loss: 1.9931553884219098

Epoch: 6| Step: 1
Training loss: 1.18521249294281
Validation loss: 2.0111107134049937

Epoch: 6| Step: 2
Training loss: 0.9571348428726196
Validation loss: 1.9976333072108607

Epoch: 6| Step: 3
Training loss: 1.1550352573394775
Validation loss: 2.005302720172431

Epoch: 6| Step: 4
Training loss: 1.3660722970962524
Validation loss: 2.037114671481553

Epoch: 6| Step: 5
Training loss: 1.0747642517089844
Validation loss: 2.07278956649124

Epoch: 6| Step: 6
Training loss: 1.2568821907043457
Validation loss: 2.060407543695101

Epoch: 6| Step: 7
Training loss: 1.104836106300354
Validation loss: 2.034545806146437

Epoch: 6| Step: 8
Training loss: 1.2920135259628296
Validation loss: 2.0339335382625623

Epoch: 6| Step: 9
Training loss: 0.8696075677871704
Validation loss: 2.023054071651992

Epoch: 6| Step: 10
Training loss: 0.9754226207733154
Validation loss: 2.011855968865015

Epoch: 6| Step: 11
Training loss: 0.7840232849121094
Validation loss: 1.9815269580451391

Epoch: 6| Step: 12
Training loss: 1.4127544164657593
Validation loss: 2.0120343315985894

Epoch: 6| Step: 13
Training loss: 1.6223326921463013
Validation loss: 1.9836732110669535

Epoch: 183| Step: 0
Training loss: 1.2672828435897827
Validation loss: 1.955530305062571

Epoch: 6| Step: 1
Training loss: 1.0769381523132324
Validation loss: 1.9790615843188377

Epoch: 6| Step: 2
Training loss: 1.1079869270324707
Validation loss: 1.992959839041515

Epoch: 6| Step: 3
Training loss: 1.390855073928833
Validation loss: 1.999897531283799

Epoch: 6| Step: 4
Training loss: 1.3228633403778076
Validation loss: 2.0325088231794295

Epoch: 6| Step: 5
Training loss: 0.8644511699676514
Validation loss: 2.0322606076476393

Epoch: 6| Step: 6
Training loss: 1.2718005180358887
Validation loss: 2.059617709088069

Epoch: 6| Step: 7
Training loss: 1.006685495376587
Validation loss: 2.067034729065434

Epoch: 6| Step: 8
Training loss: 1.1558749675750732
Validation loss: 2.0519735684958835

Epoch: 6| Step: 9
Training loss: 1.1627683639526367
Validation loss: 2.0503194383395615

Epoch: 6| Step: 10
Training loss: 0.6562497019767761
Validation loss: 2.022005747723323

Epoch: 6| Step: 11
Training loss: 1.1639355421066284
Validation loss: 2.015819998197658

Epoch: 6| Step: 12
Training loss: 1.183185338973999
Validation loss: 2.0035769285694247

Epoch: 6| Step: 13
Training loss: 0.47310870885849
Validation loss: 1.9874537401301886

Epoch: 184| Step: 0
Training loss: 1.2726677656173706
Validation loss: 1.9658359507078766

Epoch: 6| Step: 1
Training loss: 1.357460856437683
Validation loss: 1.955852908472861

Epoch: 6| Step: 2
Training loss: 0.9306043386459351
Validation loss: 1.9272833921576058

Epoch: 6| Step: 3
Training loss: 1.1190699338912964
Validation loss: 1.9328344803984447

Epoch: 6| Step: 4
Training loss: 1.116959810256958
Validation loss: 1.919493289404018

Epoch: 6| Step: 5
Training loss: 0.9814616441726685
Validation loss: 1.9582576597890546

Epoch: 6| Step: 6
Training loss: 0.7980964183807373
Validation loss: 1.950927557483796

Epoch: 6| Step: 7
Training loss: 1.2154890298843384
Validation loss: 1.9781823747901506

Epoch: 6| Step: 8
Training loss: 1.157345175743103
Validation loss: 1.9706573319691483

Epoch: 6| Step: 9
Training loss: 1.0561773777008057
Validation loss: 2.009204372282951

Epoch: 6| Step: 10
Training loss: 0.892041027545929
Validation loss: 2.0341022552982455

Epoch: 6| Step: 11
Training loss: 1.3940908908843994
Validation loss: 2.082179584810811

Epoch: 6| Step: 12
Training loss: 1.0685358047485352
Validation loss: 2.077031657259951

Epoch: 6| Step: 13
Training loss: 0.6135613918304443
Validation loss: 2.0874609434476463

Epoch: 185| Step: 0
Training loss: 1.1405675411224365
Validation loss: 2.0847963799712477

Epoch: 6| Step: 1
Training loss: 0.9297179579734802
Validation loss: 2.077835429099298

Epoch: 6| Step: 2
Training loss: 1.1739287376403809
Validation loss: 2.058985928053497

Epoch: 6| Step: 3
Training loss: 1.5624442100524902
Validation loss: 2.03294369482225

Epoch: 6| Step: 4
Training loss: 0.8491456508636475
Validation loss: 2.0121678665120113

Epoch: 6| Step: 5
Training loss: 0.8733206391334534
Validation loss: 1.991768943366184

Epoch: 6| Step: 6
Training loss: 0.7417601943016052
Validation loss: 1.957283240492626

Epoch: 6| Step: 7
Training loss: 1.00380277633667
Validation loss: 1.9839795199773644

Epoch: 6| Step: 8
Training loss: 0.861111044883728
Validation loss: 1.9791347801044423

Epoch: 6| Step: 9
Training loss: 0.9976208806037903
Validation loss: 1.9932620217723231

Epoch: 6| Step: 10
Training loss: 1.4099557399749756
Validation loss: 1.9854393082280313

Epoch: 6| Step: 11
Training loss: 1.4433602094650269
Validation loss: 2.0132909051833616

Epoch: 6| Step: 12
Training loss: 0.9788514971733093
Validation loss: 1.997641199378557

Epoch: 6| Step: 13
Training loss: 1.1572165489196777
Validation loss: 1.986190826662125

Epoch: 186| Step: 0
Training loss: 1.3144185543060303
Validation loss: 1.9374814136053926

Epoch: 6| Step: 1
Training loss: 1.209615707397461
Validation loss: 1.9399816195170085

Epoch: 6| Step: 2
Training loss: 1.072277307510376
Validation loss: 1.9185211837932628

Epoch: 6| Step: 3
Training loss: 1.4240059852600098
Validation loss: 1.9366298670409827

Epoch: 6| Step: 4
Training loss: 1.4717342853546143
Validation loss: 1.9322775256249212

Epoch: 6| Step: 5
Training loss: 0.9049393534660339
Validation loss: 1.9687975991156794

Epoch: 6| Step: 6
Training loss: 0.937199592590332
Validation loss: 1.962973653629262

Epoch: 6| Step: 7
Training loss: 0.6904232501983643
Validation loss: 2.003890552828389

Epoch: 6| Step: 8
Training loss: 0.885566234588623
Validation loss: 2.0189489600478963

Epoch: 6| Step: 9
Training loss: 1.1493446826934814
Validation loss: 2.075197417248962

Epoch: 6| Step: 10
Training loss: 1.477971076965332
Validation loss: 2.0782182088462253

Epoch: 6| Step: 11
Training loss: 0.9887704849243164
Validation loss: 2.0907232940837903

Epoch: 6| Step: 12
Training loss: 0.8328052163124084
Validation loss: 2.0340571711140294

Epoch: 6| Step: 13
Training loss: 1.0645787715911865
Validation loss: 1.9973904855789677

Epoch: 187| Step: 0
Training loss: 1.0029560327529907
Validation loss: 1.958732758798907

Epoch: 6| Step: 1
Training loss: 0.9792537093162537
Validation loss: 1.941731632396739

Epoch: 6| Step: 2
Training loss: 0.944488525390625
Validation loss: 1.8753035670967513

Epoch: 6| Step: 3
Training loss: 1.4602736234664917
Validation loss: 1.8566084959173714

Epoch: 6| Step: 4
Training loss: 1.3503981828689575
Validation loss: 1.8460261988383468

Epoch: 6| Step: 5
Training loss: 1.247755527496338
Validation loss: 1.8507859694060458

Epoch: 6| Step: 6
Training loss: 0.872328519821167
Validation loss: 1.8576117548891293

Epoch: 6| Step: 7
Training loss: 1.1454007625579834
Validation loss: 1.8593706982110136

Epoch: 6| Step: 8
Training loss: 1.1571154594421387
Validation loss: 1.8741177871663084

Epoch: 6| Step: 9
Training loss: 0.898057222366333
Validation loss: 1.9090484572995094

Epoch: 6| Step: 10
Training loss: 1.513014316558838
Validation loss: 1.9381064394468903

Epoch: 6| Step: 11
Training loss: 1.0699167251586914
Validation loss: 1.955191009788103

Epoch: 6| Step: 12
Training loss: 0.7908914089202881
Validation loss: 1.999978566682467

Epoch: 6| Step: 13
Training loss: 0.5742688179016113
Validation loss: 2.0226686821188977

Epoch: 188| Step: 0
Training loss: 1.2877001762390137
Validation loss: 2.024113699954043

Epoch: 6| Step: 1
Training loss: 1.1184659004211426
Validation loss: 2.0186188297887004

Epoch: 6| Step: 2
Training loss: 1.27015221118927
Validation loss: 2.0322762586737193

Epoch: 6| Step: 3
Training loss: 0.6339830160140991
Validation loss: 2.0314782845076693

Epoch: 6| Step: 4
Training loss: 1.0043891668319702
Validation loss: 2.0301212597918767

Epoch: 6| Step: 5
Training loss: 1.27803373336792
Validation loss: 2.0071127440339778

Epoch: 6| Step: 6
Training loss: 1.1759092807769775
Validation loss: 1.9983879032955374

Epoch: 6| Step: 7
Training loss: 0.680456280708313
Validation loss: 1.9875637356952955

Epoch: 6| Step: 8
Training loss: 0.7897034883499146
Validation loss: 1.9893715330349502

Epoch: 6| Step: 9
Training loss: 1.3602113723754883
Validation loss: 1.9700587859717749

Epoch: 6| Step: 10
Training loss: 0.7475888729095459
Validation loss: 1.9573391227311985

Epoch: 6| Step: 11
Training loss: 1.015902042388916
Validation loss: 1.9955164258198073

Epoch: 6| Step: 12
Training loss: 1.0921196937561035
Validation loss: 2.007199231014457

Epoch: 6| Step: 13
Training loss: 0.964544951915741
Validation loss: 1.9660601949179044

Epoch: 189| Step: 0
Training loss: 0.9954713582992554
Validation loss: 1.9957552020267775

Epoch: 6| Step: 1
Training loss: 0.7352970838546753
Validation loss: 1.9941874575871292

Epoch: 6| Step: 2
Training loss: 0.8316481113433838
Validation loss: 1.9985389376199374

Epoch: 6| Step: 3
Training loss: 0.9130369424819946
Validation loss: 1.9850493015781525

Epoch: 6| Step: 4
Training loss: 1.847919225692749
Validation loss: 1.9635723098631828

Epoch: 6| Step: 5
Training loss: 0.6614125967025757
Validation loss: 2.009324117373395

Epoch: 6| Step: 6
Training loss: 1.4264485836029053
Validation loss: 1.9857660173087992

Epoch: 6| Step: 7
Training loss: 0.7125471234321594
Validation loss: 1.9681142325042396

Epoch: 6| Step: 8
Training loss: 1.435563087463379
Validation loss: 1.963927504836872

Epoch: 6| Step: 9
Training loss: 1.0279101133346558
Validation loss: 1.9692942378341511

Epoch: 6| Step: 10
Training loss: 0.9321098327636719
Validation loss: 1.9335258109595186

Epoch: 6| Step: 11
Training loss: 1.1949970722198486
Validation loss: 1.9321224048573484

Epoch: 6| Step: 12
Training loss: 0.6963164210319519
Validation loss: 1.9355351668532177

Epoch: 6| Step: 13
Training loss: 1.0859794616699219
Validation loss: 1.9375282974653347

Epoch: 190| Step: 0
Training loss: 1.2546350955963135
Validation loss: 1.954199476908612

Epoch: 6| Step: 1
Training loss: 0.8015239238739014
Validation loss: 1.9613677404260124

Epoch: 6| Step: 2
Training loss: 0.9988930821418762
Validation loss: 1.9592555543427825

Epoch: 6| Step: 3
Training loss: 0.9711679816246033
Validation loss: 1.9639563868122716

Epoch: 6| Step: 4
Training loss: 1.1710751056671143
Validation loss: 1.9407297795818699

Epoch: 6| Step: 5
Training loss: 1.4494000673294067
Validation loss: 1.9569846609587311

Epoch: 6| Step: 6
Training loss: 1.3163928985595703
Validation loss: 1.997173083725796

Epoch: 6| Step: 7
Training loss: 1.0278100967407227
Validation loss: 2.0067897458230295

Epoch: 6| Step: 8
Training loss: 0.9291675090789795
Validation loss: 2.009305518160584

Epoch: 6| Step: 9
Training loss: 0.9067257642745972
Validation loss: 2.02120784021193

Epoch: 6| Step: 10
Training loss: 0.7476826906204224
Validation loss: 2.0282367121788765

Epoch: 6| Step: 11
Training loss: 1.1854302883148193
Validation loss: 2.0287888332079818

Epoch: 6| Step: 12
Training loss: 0.7089893817901611
Validation loss: 1.9971293134074057

Epoch: 6| Step: 13
Training loss: 1.3990328311920166
Validation loss: 1.9930000971722346

Epoch: 191| Step: 0
Training loss: 0.9855584502220154
Validation loss: 1.9721688147514098

Epoch: 6| Step: 1
Training loss: 1.1749244928359985
Validation loss: 1.9726231034084032

Epoch: 6| Step: 2
Training loss: 0.8696088790893555
Validation loss: 1.9544946711550477

Epoch: 6| Step: 3
Training loss: 1.0122427940368652
Validation loss: 1.9360858778799734

Epoch: 6| Step: 4
Training loss: 0.9857119917869568
Validation loss: 1.961610964549485

Epoch: 6| Step: 5
Training loss: 0.8854115009307861
Validation loss: 1.9615246813784364

Epoch: 6| Step: 6
Training loss: 1.376646637916565
Validation loss: 1.9934464270068752

Epoch: 6| Step: 7
Training loss: 0.9636086225509644
Validation loss: 1.9595899402454335

Epoch: 6| Step: 8
Training loss: 0.8035168051719666
Validation loss: 1.9194857317914245

Epoch: 6| Step: 9
Training loss: 0.734230637550354
Validation loss: 1.9191184402793966

Epoch: 6| Step: 10
Training loss: 1.0775461196899414
Validation loss: 1.9621132009772844

Epoch: 6| Step: 11
Training loss: 1.2053344249725342
Validation loss: 1.9450657752252394

Epoch: 6| Step: 12
Training loss: 0.855980634689331
Validation loss: 1.937152180620419

Epoch: 6| Step: 13
Training loss: 1.7703560590744019
Validation loss: 1.9550349507280576

Epoch: 192| Step: 0
Training loss: 0.9154911041259766
Validation loss: 1.9803094838255195

Epoch: 6| Step: 1
Training loss: 1.7351242303848267
Validation loss: 1.9610485799850956

Epoch: 6| Step: 2
Training loss: 0.8404589295387268
Validation loss: 1.9555911851185623

Epoch: 6| Step: 3
Training loss: 0.9511396884918213
Validation loss: 1.9429787858839958

Epoch: 6| Step: 4
Training loss: 0.5349226593971252
Validation loss: 1.9304207473672845

Epoch: 6| Step: 5
Training loss: 1.166750192642212
Validation loss: 1.905333613836637

Epoch: 6| Step: 6
Training loss: 1.0742542743682861
Validation loss: 1.9140827732701455

Epoch: 6| Step: 7
Training loss: 1.1090481281280518
Validation loss: 1.8940654134237638

Epoch: 6| Step: 8
Training loss: 0.8286454677581787
Validation loss: 1.9068229711183937

Epoch: 6| Step: 9
Training loss: 0.9177632331848145
Validation loss: 1.8972905810161302

Epoch: 6| Step: 10
Training loss: 1.0266671180725098
Validation loss: 1.9257284902757215

Epoch: 6| Step: 11
Training loss: 0.965995728969574
Validation loss: 1.940051790206663

Epoch: 6| Step: 12
Training loss: 0.9538434147834778
Validation loss: 1.9259122110182239

Epoch: 6| Step: 13
Training loss: 1.181301474571228
Validation loss: 1.976040610703089

Epoch: 193| Step: 0
Training loss: 1.3010015487670898
Validation loss: 2.0164231023480816

Epoch: 6| Step: 1
Training loss: 1.1536682844161987
Validation loss: 2.0206133127212524

Epoch: 6| Step: 2
Training loss: 0.6683837175369263
Validation loss: 2.0417374769846597

Epoch: 6| Step: 3
Training loss: 1.1824144124984741
Validation loss: 2.0384399070534656

Epoch: 6| Step: 4
Training loss: 1.1428864002227783
Validation loss: 1.9733967499066425

Epoch: 6| Step: 5
Training loss: 1.0222619771957397
Validation loss: 1.956668843505203

Epoch: 6| Step: 6
Training loss: 1.1917381286621094
Validation loss: 1.9500745804079118

Epoch: 6| Step: 7
Training loss: 1.3394291400909424
Validation loss: 1.9312899189610635

Epoch: 6| Step: 8
Training loss: 0.9929274320602417
Validation loss: 1.9019201340213898

Epoch: 6| Step: 9
Training loss: 1.2065398693084717
Validation loss: 1.8869494225389214

Epoch: 6| Step: 10
Training loss: 1.1772719621658325
Validation loss: 1.8796078722964051

Epoch: 6| Step: 11
Training loss: 1.0775527954101562
Validation loss: 1.9222678138363747

Epoch: 6| Step: 12
Training loss: 1.2522454261779785
Validation loss: 1.9104890336272538

Epoch: 6| Step: 13
Training loss: 1.0536983013153076
Validation loss: 1.9565234402174592

Epoch: 194| Step: 0
Training loss: 1.48575758934021
Validation loss: 1.9624965934343235

Epoch: 6| Step: 1
Training loss: 1.1932227611541748
Validation loss: 1.9737576746171521

Epoch: 6| Step: 2
Training loss: 1.0546749830245972
Validation loss: 1.978787455507504

Epoch: 6| Step: 3
Training loss: 1.1268291473388672
Validation loss: 1.9907679967982794

Epoch: 6| Step: 4
Training loss: 0.839736819267273
Validation loss: 1.9890850615757767

Epoch: 6| Step: 5
Training loss: 1.1815696954727173
Validation loss: 2.0043339165308143

Epoch: 6| Step: 6
Training loss: 0.7299806475639343
Validation loss: 1.9732861300950408

Epoch: 6| Step: 7
Training loss: 1.2534745931625366
Validation loss: 1.9941233640076013

Epoch: 6| Step: 8
Training loss: 0.794001579284668
Validation loss: 1.9906402275126467

Epoch: 6| Step: 9
Training loss: 0.766461968421936
Validation loss: 1.9551083528867332

Epoch: 6| Step: 10
Training loss: 1.5748634338378906
Validation loss: 1.95663119387883

Epoch: 6| Step: 11
Training loss: 0.7357724905014038
Validation loss: 1.9915889898935955

Epoch: 6| Step: 12
Training loss: 0.8411910533905029
Validation loss: 1.95723924585568

Epoch: 6| Step: 13
Training loss: 0.9330178499221802
Validation loss: 1.9823907793209117

Epoch: 195| Step: 0
Training loss: 0.8885353803634644
Validation loss: 1.9710591967387865

Epoch: 6| Step: 1
Training loss: 1.408452033996582
Validation loss: 2.0104004208759596

Epoch: 6| Step: 2
Training loss: 0.8693543672561646
Validation loss: 2.041083258967246

Epoch: 6| Step: 3
Training loss: 1.0372300148010254
Validation loss: 2.0570219409081245

Epoch: 6| Step: 4
Training loss: 0.9432775974273682
Validation loss: 2.0454629467379664

Epoch: 6| Step: 5
Training loss: 0.9129582643508911
Validation loss: 2.0428496637651996

Epoch: 6| Step: 6
Training loss: 0.7285505533218384
Validation loss: 2.0608129783343245

Epoch: 6| Step: 7
Training loss: 0.9702726602554321
Validation loss: 2.054069088351342

Epoch: 6| Step: 8
Training loss: 1.0915776491165161
Validation loss: 2.0227298249480543

Epoch: 6| Step: 9
Training loss: 1.243058204650879
Validation loss: 1.996265794641228

Epoch: 6| Step: 10
Training loss: 0.7118856906890869
Validation loss: 1.9868290193619267

Epoch: 6| Step: 11
Training loss: 1.4220120906829834
Validation loss: 1.9710542271214146

Epoch: 6| Step: 12
Training loss: 0.5951021909713745
Validation loss: 1.9450391877082087

Epoch: 6| Step: 13
Training loss: 0.8275001049041748
Validation loss: 1.9262491426160258

Epoch: 196| Step: 0
Training loss: 0.7218488454818726
Validation loss: 1.9152906543465071

Epoch: 6| Step: 1
Training loss: 1.6262083053588867
Validation loss: 1.9413246749549784

Epoch: 6| Step: 2
Training loss: 0.5470353364944458
Validation loss: 1.9480428926406368

Epoch: 6| Step: 3
Training loss: 0.6514579057693481
Validation loss: 1.9565459976914108

Epoch: 6| Step: 4
Training loss: 1.1006176471710205
Validation loss: 1.9785819656105452

Epoch: 6| Step: 5
Training loss: 0.5964202284812927
Validation loss: 1.9534561582790908

Epoch: 6| Step: 6
Training loss: 1.1681922674179077
Validation loss: 1.975646121527559

Epoch: 6| Step: 7
Training loss: 0.8296144008636475
Validation loss: 1.9624762535095215

Epoch: 6| Step: 8
Training loss: 0.7785472869873047
Validation loss: 1.9587137122308054

Epoch: 6| Step: 9
Training loss: 1.0943561792373657
Validation loss: 1.930591029505576

Epoch: 6| Step: 10
Training loss: 0.9452610015869141
Validation loss: 1.897841324088394

Epoch: 6| Step: 11
Training loss: 0.8944987058639526
Validation loss: 1.9181996058392268

Epoch: 6| Step: 12
Training loss: 1.475146770477295
Validation loss: 1.9132509616113478

Epoch: 6| Step: 13
Training loss: 1.0606439113616943
Validation loss: 1.9421392102395334

Epoch: 197| Step: 0
Training loss: 1.0419769287109375
Validation loss: 1.9157517558784896

Epoch: 6| Step: 1
Training loss: 1.4101967811584473
Validation loss: 1.9083429203238538

Epoch: 6| Step: 2
Training loss: 1.1464316844940186
Validation loss: 1.8795334344269128

Epoch: 6| Step: 3
Training loss: 0.8754875659942627
Validation loss: 1.914894538540994

Epoch: 6| Step: 4
Training loss: 0.26168712973594666
Validation loss: 1.9381549666004796

Epoch: 6| Step: 5
Training loss: 0.8974765539169312
Validation loss: 1.9752736527432677

Epoch: 6| Step: 6
Training loss: 0.9501030445098877
Validation loss: 1.978006842315838

Epoch: 6| Step: 7
Training loss: 0.8696956634521484
Validation loss: 1.9670344834686608

Epoch: 6| Step: 8
Training loss: 0.8558142185211182
Validation loss: 1.984801851293092

Epoch: 6| Step: 9
Training loss: 0.9953323602676392
Validation loss: 1.9510466103912683

Epoch: 6| Step: 10
Training loss: 1.257842779159546
Validation loss: 1.9294004389034805

Epoch: 6| Step: 11
Training loss: 0.8223296403884888
Validation loss: 1.8816336893266248

Epoch: 6| Step: 12
Training loss: 1.2040525674819946
Validation loss: 1.88186982370192

Epoch: 6| Step: 13
Training loss: 0.9108494520187378
Validation loss: 1.875635572659072

Epoch: 198| Step: 0
Training loss: 1.4749596118927002
Validation loss: 1.8672511577606201

Epoch: 6| Step: 1
Training loss: 0.6655993461608887
Validation loss: 1.8684839042284156

Epoch: 6| Step: 2
Training loss: 1.1095257997512817
Validation loss: 1.877258978864198

Epoch: 6| Step: 3
Training loss: 0.9155261516571045
Validation loss: 1.9071259062777284

Epoch: 6| Step: 4
Training loss: 0.8641834855079651
Validation loss: 1.9360914807165823

Epoch: 6| Step: 5
Training loss: 0.9879008531570435
Validation loss: 1.970312741494948

Epoch: 6| Step: 6
Training loss: 1.173166036605835
Validation loss: 1.9818609478653118

Epoch: 6| Step: 7
Training loss: 1.2111139297485352
Validation loss: 2.0397911533232658

Epoch: 6| Step: 8
Training loss: 0.8537518382072449
Validation loss: 1.9903002041642384

Epoch: 6| Step: 9
Training loss: 0.6730601787567139
Validation loss: 1.940947332689839

Epoch: 6| Step: 10
Training loss: 0.8537875413894653
Validation loss: 1.9666625402306999

Epoch: 6| Step: 11
Training loss: 1.1968460083007812
Validation loss: 1.949281607904742

Epoch: 6| Step: 12
Training loss: 0.7594199180603027
Validation loss: 1.965691542112699

Epoch: 6| Step: 13
Training loss: 0.25779014825820923
Validation loss: 1.953519336638912

Epoch: 199| Step: 0
Training loss: 0.8441905975341797
Validation loss: 1.9586320077219317

Epoch: 6| Step: 1
Training loss: 1.075829267501831
Validation loss: 1.907206419975527

Epoch: 6| Step: 2
Training loss: 0.887236475944519
Validation loss: 1.8988990758055

Epoch: 6| Step: 3
Training loss: 1.3423569202423096
Validation loss: 1.9206821546759656

Epoch: 6| Step: 4
Training loss: 0.6730068922042847
Validation loss: 1.9408302730129612

Epoch: 6| Step: 5
Training loss: 0.8572773933410645
Validation loss: 1.9001517001018728

Epoch: 6| Step: 6
Training loss: 0.8381005525588989
Validation loss: 1.8873241780906596

Epoch: 6| Step: 7
Training loss: 0.7635926604270935
Validation loss: 1.8981893062591553

Epoch: 6| Step: 8
Training loss: 1.2531392574310303
Validation loss: 1.9026987475733603

Epoch: 6| Step: 9
Training loss: 1.0089055299758911
Validation loss: 1.875945730875897

Epoch: 6| Step: 10
Training loss: 0.9297481775283813
Validation loss: 1.9074949051744194

Epoch: 6| Step: 11
Training loss: 0.6802036762237549
Validation loss: 1.8876982030048166

Epoch: 6| Step: 12
Training loss: 0.9621696472167969
Validation loss: 1.9262959316212644

Epoch: 6| Step: 13
Training loss: 0.9922209978103638
Validation loss: 1.9169127684767528

Epoch: 200| Step: 0
Training loss: 1.3382213115692139
Validation loss: 1.9339152766812233

Epoch: 6| Step: 1
Training loss: 0.7528742551803589
Validation loss: 1.920511394418696

Epoch: 6| Step: 2
Training loss: 0.9147237539291382
Validation loss: 1.9092740012753395

Epoch: 6| Step: 3
Training loss: 0.7829222679138184
Validation loss: 1.9181371773442915

Epoch: 6| Step: 4
Training loss: 0.745998740196228
Validation loss: 1.9050141880589146

Epoch: 6| Step: 5
Training loss: 0.4190458059310913
Validation loss: 1.9032990176190612

Epoch: 6| Step: 6
Training loss: 1.3753759860992432
Validation loss: 1.9317920207977295

Epoch: 6| Step: 7
Training loss: 0.6871278285980225
Validation loss: 1.9331762918861963

Epoch: 6| Step: 8
Training loss: 1.159127950668335
Validation loss: 1.9649658613307501

Epoch: 6| Step: 9
Training loss: 0.9666183590888977
Validation loss: 1.9439618459311865

Epoch: 6| Step: 10
Training loss: 0.9626173973083496
Validation loss: 1.98573326423604

Epoch: 6| Step: 11
Training loss: 1.3184024095535278
Validation loss: 1.954945424551605

Epoch: 6| Step: 12
Training loss: 0.619350790977478
Validation loss: 1.9321508305047148

Epoch: 6| Step: 13
Training loss: 1.2289196252822876
Validation loss: 1.9516536561391686

Epoch: 201| Step: 0
Training loss: 0.5777960419654846
Validation loss: 1.9650993526622813

Epoch: 6| Step: 1
Training loss: 0.7316493988037109
Validation loss: 1.940806504218809

Epoch: 6| Step: 2
Training loss: 1.2617228031158447
Validation loss: 1.9194052578300558

Epoch: 6| Step: 3
Training loss: 0.9280558228492737
Validation loss: 1.9233438097020632

Epoch: 6| Step: 4
Training loss: 0.7120423316955566
Validation loss: 1.8918564678520284

Epoch: 6| Step: 5
Training loss: 1.0093443393707275
Validation loss: 1.9003017192245812

Epoch: 6| Step: 6
Training loss: 0.8322347402572632
Validation loss: 1.8744892868944394

Epoch: 6| Step: 7
Training loss: 0.964384913444519
Validation loss: 1.8750085343596756

Epoch: 6| Step: 8
Training loss: 0.9712647199630737
Validation loss: 1.8670168294701526

Epoch: 6| Step: 9
Training loss: 0.816684901714325
Validation loss: 1.8576255357393654

Epoch: 6| Step: 10
Training loss: 0.994331955909729
Validation loss: 1.8512334772335586

Epoch: 6| Step: 11
Training loss: 1.39179265499115
Validation loss: 1.897888655303627

Epoch: 6| Step: 12
Training loss: 0.7561753988265991
Validation loss: 1.9027877853762718

Epoch: 6| Step: 13
Training loss: 1.2261852025985718
Validation loss: 1.900895821150913

Epoch: 202| Step: 0
Training loss: 0.9020821452140808
Validation loss: 1.897349681905521

Epoch: 6| Step: 1
Training loss: 1.292301058769226
Validation loss: 1.8823892660038446

Epoch: 6| Step: 2
Training loss: 1.382632851600647
Validation loss: 1.9095077181375155

Epoch: 6| Step: 3
Training loss: 0.5099226832389832
Validation loss: 1.8897700732754124

Epoch: 6| Step: 4
Training loss: 0.5281602144241333
Validation loss: 1.907433218853448

Epoch: 6| Step: 5
Training loss: 0.8175522089004517
Validation loss: 1.941194765029415

Epoch: 6| Step: 6
Training loss: 1.2477810382843018
Validation loss: 1.923574291249757

Epoch: 6| Step: 7
Training loss: 0.8547167778015137
Validation loss: 1.893954897439608

Epoch: 6| Step: 8
Training loss: 0.6581528186798096
Validation loss: 1.9137350231088617

Epoch: 6| Step: 9
Training loss: 1.2772316932678223
Validation loss: 1.9072833727764826

Epoch: 6| Step: 10
Training loss: 0.8585876226425171
Validation loss: 1.940322288902857

Epoch: 6| Step: 11
Training loss: 0.6722756624221802
Validation loss: 1.9280640258583972

Epoch: 6| Step: 12
Training loss: 0.8939743041992188
Validation loss: 1.8950454727295907

Epoch: 6| Step: 13
Training loss: 0.9354483485221863
Validation loss: 1.8998680960747503

Epoch: 203| Step: 0
Training loss: 1.089927315711975
Validation loss: 1.8896876740199264

Epoch: 6| Step: 1
Training loss: 0.5035918951034546
Validation loss: 1.8672954036343483

Epoch: 6| Step: 2
Training loss: 1.2520027160644531
Validation loss: 1.8970005025145829

Epoch: 6| Step: 3
Training loss: 0.8978217840194702
Validation loss: 1.8932222922643025

Epoch: 6| Step: 4
Training loss: 0.7188974618911743
Validation loss: 1.9117879495825818

Epoch: 6| Step: 5
Training loss: 0.931178092956543
Validation loss: 1.9566826102554158

Epoch: 6| Step: 6
Training loss: 0.8992167711257935
Validation loss: 2.0047399190164383

Epoch: 6| Step: 7
Training loss: 0.9140534996986389
Validation loss: 1.9999389750983125

Epoch: 6| Step: 8
Training loss: 0.7690383195877075
Validation loss: 1.9574486440227878

Epoch: 6| Step: 9
Training loss: 0.9800546169281006
Validation loss: 1.962277276541597

Epoch: 6| Step: 10
Training loss: 0.8315435647964478
Validation loss: 1.9828862208192066

Epoch: 6| Step: 11
Training loss: 0.626854419708252
Validation loss: 1.9647787706826323

Epoch: 6| Step: 12
Training loss: 1.2210144996643066
Validation loss: 1.98368675093497

Epoch: 6| Step: 13
Training loss: 0.7028446197509766
Validation loss: 1.9821540232627624

Epoch: 204| Step: 0
Training loss: 0.6387204527854919
Validation loss: 1.9598989281603085

Epoch: 6| Step: 1
Training loss: 1.1662870645523071
Validation loss: 1.9561287433870378

Epoch: 6| Step: 2
Training loss: 0.9372265934944153
Validation loss: 1.9520956008665022

Epoch: 6| Step: 3
Training loss: 0.8567496538162231
Validation loss: 1.972938693979735

Epoch: 6| Step: 4
Training loss: 0.7657986879348755
Validation loss: 1.9675197370590702

Epoch: 6| Step: 5
Training loss: 0.975242018699646
Validation loss: 1.978741443285378

Epoch: 6| Step: 6
Training loss: 0.7996982336044312
Validation loss: 1.9886767530954013

Epoch: 6| Step: 7
Training loss: 1.0720394849777222
Validation loss: 1.9966386313079505

Epoch: 6| Step: 8
Training loss: 0.9847080707550049
Validation loss: 1.9449889198426278

Epoch: 6| Step: 9
Training loss: 0.44275233149528503
Validation loss: 1.9338409285391531

Epoch: 6| Step: 10
Training loss: 0.8757688999176025
Validation loss: 1.9162051421339794

Epoch: 6| Step: 11
Training loss: 1.313143014907837
Validation loss: 1.8997759729303338

Epoch: 6| Step: 12
Training loss: 0.8688230514526367
Validation loss: 1.9020332700462752

Epoch: 6| Step: 13
Training loss: 0.7749059200286865
Validation loss: 1.8964199327653455

Epoch: 205| Step: 0
Training loss: 0.8360804915428162
Validation loss: 1.8926562211846794

Epoch: 6| Step: 1
Training loss: 0.6865661144256592
Validation loss: 1.911064624786377

Epoch: 6| Step: 2
Training loss: 0.8090890645980835
Validation loss: 1.9306863328462005

Epoch: 6| Step: 3
Training loss: 0.891211986541748
Validation loss: 1.9370376345931843

Epoch: 6| Step: 4
Training loss: 0.869479775428772
Validation loss: 1.9215047667103429

Epoch: 6| Step: 5
Training loss: 0.5055795907974243
Validation loss: 1.902514729448544

Epoch: 6| Step: 6
Training loss: 0.830245852470398
Validation loss: 1.9040676752726238

Epoch: 6| Step: 7
Training loss: 1.5234601497650146
Validation loss: 1.9324780407772268

Epoch: 6| Step: 8
Training loss: 0.905427873134613
Validation loss: 1.9317995117556663

Epoch: 6| Step: 9
Training loss: 0.7241963148117065
Validation loss: 1.94168851196125

Epoch: 6| Step: 10
Training loss: 0.5198088884353638
Validation loss: 1.9022851938842444

Epoch: 6| Step: 11
Training loss: 1.1779003143310547
Validation loss: 1.923668521706776

Epoch: 6| Step: 12
Training loss: 0.7187843322753906
Validation loss: 1.9065678247841455

Epoch: 6| Step: 13
Training loss: 1.3061237335205078
Validation loss: 1.9054636198987243

Epoch: 206| Step: 0
Training loss: 0.6538852453231812
Validation loss: 1.8868107846988145

Epoch: 6| Step: 1
Training loss: 0.9258070588111877
Validation loss: 1.905131083662792

Epoch: 6| Step: 2
Training loss: 0.9444437026977539
Validation loss: 1.8718337371785154

Epoch: 6| Step: 3
Training loss: 0.9660703539848328
Validation loss: 1.8926923685176398

Epoch: 6| Step: 4
Training loss: 1.2865008115768433
Validation loss: 1.8956052898078837

Epoch: 6| Step: 5
Training loss: 0.8551624417304993
Validation loss: 1.8762240281669043

Epoch: 6| Step: 6
Training loss: 0.8514268398284912
Validation loss: 1.9007297818378737

Epoch: 6| Step: 7
Training loss: 1.0374674797058105
Validation loss: 1.9331590052573913

Epoch: 6| Step: 8
Training loss: 1.074345350265503
Validation loss: 1.9121533440005394

Epoch: 6| Step: 9
Training loss: 0.9827765822410583
Validation loss: 1.923259150597357

Epoch: 6| Step: 10
Training loss: 0.3947370946407318
Validation loss: 1.9452183464522004

Epoch: 6| Step: 11
Training loss: 0.8299320936203003
Validation loss: 1.9651538402803483

Epoch: 6| Step: 12
Training loss: 1.0620061159133911
Validation loss: 2.000962972640991

Epoch: 6| Step: 13
Training loss: 0.5027710795402527
Validation loss: 1.970155454451038

Epoch: 207| Step: 0
Training loss: 0.8781083226203918
Validation loss: 2.0025674719964304

Epoch: 6| Step: 1
Training loss: 0.8354092240333557
Validation loss: 2.0154366083042596

Epoch: 6| Step: 2
Training loss: 1.1504077911376953
Validation loss: 1.9818603005460513

Epoch: 6| Step: 3
Training loss: 0.5981042385101318
Validation loss: 1.9535478597046227

Epoch: 6| Step: 4
Training loss: 0.8813808560371399
Validation loss: 1.941808182706115

Epoch: 6| Step: 5
Training loss: 0.9926005601882935
Validation loss: 1.9323422447327645

Epoch: 6| Step: 6
Training loss: 0.8979426622390747
Validation loss: 1.918727582500827

Epoch: 6| Step: 7
Training loss: 0.6322610378265381
Validation loss: 1.9528291891979914

Epoch: 6| Step: 8
Training loss: 1.1613095998764038
Validation loss: 1.9481677739850936

Epoch: 6| Step: 9
Training loss: 1.3479515314102173
Validation loss: 1.9568071929357385

Epoch: 6| Step: 10
Training loss: 0.5901222825050354
Validation loss: 1.957475204621592

Epoch: 6| Step: 11
Training loss: 0.7956181168556213
Validation loss: 1.9517338737364738

Epoch: 6| Step: 12
Training loss: 0.8080926537513733
Validation loss: 1.9183426351957424

Epoch: 6| Step: 13
Training loss: 0.6118847727775574
Validation loss: 1.8833545895032986

Epoch: 208| Step: 0
Training loss: 0.7934390306472778
Validation loss: 1.8571406641314108

Epoch: 6| Step: 1
Training loss: 1.07314133644104
Validation loss: 1.8562833532210319

Epoch: 6| Step: 2
Training loss: 1.1044673919677734
Validation loss: 1.81523879625464

Epoch: 6| Step: 3
Training loss: 1.2347733974456787
Validation loss: 1.8216288166661416

Epoch: 6| Step: 4
Training loss: 0.9638441801071167
Validation loss: 1.8537649685336697

Epoch: 6| Step: 5
Training loss: 0.7664049863815308
Validation loss: 1.857722706692193

Epoch: 6| Step: 6
Training loss: 0.9952387809753418
Validation loss: 1.902334156856742

Epoch: 6| Step: 7
Training loss: 0.8642938137054443
Validation loss: 1.9241740870219406

Epoch: 6| Step: 8
Training loss: 0.5248082280158997
Validation loss: 1.9499383254717755

Epoch: 6| Step: 9
Training loss: 0.8423563241958618
Validation loss: 1.9717656284250238

Epoch: 6| Step: 10
Training loss: 0.9580257534980774
Validation loss: 1.9870479414539952

Epoch: 6| Step: 11
Training loss: 0.9264488816261292
Validation loss: 1.9887295217924221

Epoch: 6| Step: 12
Training loss: 1.0324472188949585
Validation loss: 1.9590761725620558

Epoch: 6| Step: 13
Training loss: 0.8217287659645081
Validation loss: 1.9344058498259513

Epoch: 209| Step: 0
Training loss: 1.0575406551361084
Validation loss: 1.9347211801877586

Epoch: 6| Step: 1
Training loss: 0.5327295064926147
Validation loss: 1.9193706256087109

Epoch: 6| Step: 2
Training loss: 1.0168952941894531
Validation loss: 1.9093804564527286

Epoch: 6| Step: 3
Training loss: 0.9044824242591858
Validation loss: 1.9022151013856292

Epoch: 6| Step: 4
Training loss: 0.8120802640914917
Validation loss: 1.8746419234942364

Epoch: 6| Step: 5
Training loss: 0.9508939981460571
Validation loss: 1.9142398462500623

Epoch: 6| Step: 6
Training loss: 0.7644275426864624
Validation loss: 1.9186997977636193

Epoch: 6| Step: 7
Training loss: 0.7902989387512207
Validation loss: 1.899498216567501

Epoch: 6| Step: 8
Training loss: 0.7906396985054016
Validation loss: 1.9492184500540457

Epoch: 6| Step: 9
Training loss: 1.0167229175567627
Validation loss: 1.9303865689103321

Epoch: 6| Step: 10
Training loss: 0.9007744193077087
Validation loss: 1.871422016492454

Epoch: 6| Step: 11
Training loss: 0.5860724449157715
Validation loss: 1.902287979279795

Epoch: 6| Step: 12
Training loss: 0.7405625581741333
Validation loss: 1.8923188050587971

Epoch: 6| Step: 13
Training loss: 1.6340755224227905
Validation loss: 1.922664378278999

Epoch: 210| Step: 0
Training loss: 1.1360735893249512
Validation loss: 1.9074549469896542

Epoch: 6| Step: 1
Training loss: 0.8916621208190918
Validation loss: 1.919911612746536

Epoch: 6| Step: 2
Training loss: 0.6302087306976318
Validation loss: 1.8754367995005783

Epoch: 6| Step: 3
Training loss: 0.6679319143295288
Validation loss: 1.8842685222625732

Epoch: 6| Step: 4
Training loss: 0.9237415790557861
Validation loss: 1.8856951728943856

Epoch: 6| Step: 5
Training loss: 0.6865980625152588
Validation loss: 1.8792156788610643

Epoch: 6| Step: 6
Training loss: 0.9296627640724182
Validation loss: 1.8932139283867293

Epoch: 6| Step: 7
Training loss: 1.2704375982284546
Validation loss: 1.8817065274843605

Epoch: 6| Step: 8
Training loss: 0.8423199653625488
Validation loss: 1.8877555221639655

Epoch: 6| Step: 9
Training loss: 0.5522856116294861
Validation loss: 1.8885505096886748

Epoch: 6| Step: 10
Training loss: 1.0530983209609985
Validation loss: 1.8895184045196862

Epoch: 6| Step: 11
Training loss: 0.563185453414917
Validation loss: 1.9034099271220546

Epoch: 6| Step: 12
Training loss: 0.4608159065246582
Validation loss: 1.9038139530407485

Epoch: 6| Step: 13
Training loss: 1.0501761436462402
Validation loss: 1.898212694352673

Epoch: 211| Step: 0
Training loss: 0.7389962673187256
Validation loss: 1.9302230419651154

Epoch: 6| Step: 1
Training loss: 0.943966805934906
Validation loss: 1.940055803586078

Epoch: 6| Step: 2
Training loss: 1.346537470817566
Validation loss: 1.9548259024978967

Epoch: 6| Step: 3
Training loss: 1.2490161657333374
Validation loss: 1.9453471053031184

Epoch: 6| Step: 4
Training loss: 0.43978291749954224
Validation loss: 1.9429824480446436

Epoch: 6| Step: 5
Training loss: 0.6272791028022766
Validation loss: 1.9222041150575042

Epoch: 6| Step: 6
Training loss: 0.5983767509460449
Validation loss: 1.894919741538263

Epoch: 6| Step: 7
Training loss: 0.9613717198371887
Validation loss: 1.8728706657245595

Epoch: 6| Step: 8
Training loss: 0.4050653576850891
Validation loss: 1.8776492303417576

Epoch: 6| Step: 9
Training loss: 1.0916348695755005
Validation loss: 1.8764302089650144

Epoch: 6| Step: 10
Training loss: 0.6799273490905762
Validation loss: 1.903385764809065

Epoch: 6| Step: 11
Training loss: 0.9107704162597656
Validation loss: 1.9038623225304387

Epoch: 6| Step: 12
Training loss: 0.7679461240768433
Validation loss: 1.9305499856190016

Epoch: 6| Step: 13
Training loss: 0.7392313480377197
Validation loss: 1.980413152325538

Epoch: 212| Step: 0
Training loss: 0.8780255913734436
Validation loss: 2.009168396713913

Epoch: 6| Step: 1
Training loss: 0.9712498188018799
Validation loss: 1.98922251501391

Epoch: 6| Step: 2
Training loss: 0.7267821431159973
Validation loss: 1.9988830833024875

Epoch: 6| Step: 3
Training loss: 0.949766993522644
Validation loss: 1.9637922881751932

Epoch: 6| Step: 4
Training loss: 1.1186338663101196
Validation loss: 1.9144746167685396

Epoch: 6| Step: 5
Training loss: 0.8879860639572144
Validation loss: 1.8894101355665474

Epoch: 6| Step: 6
Training loss: 0.9243851900100708
Validation loss: 1.876671048902696

Epoch: 6| Step: 7
Training loss: 1.0020042657852173
Validation loss: 1.8360420798742643

Epoch: 6| Step: 8
Training loss: 0.7782087326049805
Validation loss: 1.8559841878952519

Epoch: 6| Step: 9
Training loss: 0.903167724609375
Validation loss: 1.8378130364161667

Epoch: 6| Step: 10
Training loss: 0.7603314518928528
Validation loss: 1.8284340596968127

Epoch: 6| Step: 11
Training loss: 0.7599456310272217
Validation loss: 1.812281467581308

Epoch: 6| Step: 12
Training loss: 0.5985183715820312
Validation loss: 1.7954841993188346

Epoch: 6| Step: 13
Training loss: 0.30218684673309326
Validation loss: 1.856442956514256

Epoch: 213| Step: 0
Training loss: 1.083146572113037
Validation loss: 1.848392132789858

Epoch: 6| Step: 1
Training loss: 0.46784311532974243
Validation loss: 1.8595015489926903

Epoch: 6| Step: 2
Training loss: 0.7148931622505188
Validation loss: 1.8839700683470695

Epoch: 6| Step: 3
Training loss: 0.9652096629142761
Validation loss: 1.8689177549013527

Epoch: 6| Step: 4
Training loss: 0.5822844505310059
Validation loss: 1.8818275281178054

Epoch: 6| Step: 5
Training loss: 0.6482032537460327
Validation loss: 1.8953502191010343

Epoch: 6| Step: 6
Training loss: 1.2399998903274536
Validation loss: 1.890182582280969

Epoch: 6| Step: 7
Training loss: 0.8571668267250061
Validation loss: 1.8864078034636795

Epoch: 6| Step: 8
Training loss: 1.1883270740509033
Validation loss: 1.8766824314671178

Epoch: 6| Step: 9
Training loss: 0.6529074907302856
Validation loss: 1.944511704547431

Epoch: 6| Step: 10
Training loss: 0.7828656435012817
Validation loss: 1.9419564316349645

Epoch: 6| Step: 11
Training loss: 0.998955488204956
Validation loss: 1.952973231192558

Epoch: 6| Step: 12
Training loss: 0.613837480545044
Validation loss: 1.9870170982935096

Epoch: 6| Step: 13
Training loss: 0.4020761549472809
Validation loss: 1.9971417124553392

Epoch: 214| Step: 0
Training loss: 0.5327712893486023
Validation loss: 1.9776139079883535

Epoch: 6| Step: 1
Training loss: 0.5163953304290771
Validation loss: 1.9501348554447133

Epoch: 6| Step: 2
Training loss: 0.779575526714325
Validation loss: 1.9195356651019024

Epoch: 6| Step: 3
Training loss: 1.091893196105957
Validation loss: 1.8931465174562188

Epoch: 6| Step: 4
Training loss: 0.8976690769195557
Validation loss: 1.8828492882431194

Epoch: 6| Step: 5
Training loss: 1.2658071517944336
Validation loss: 1.853798822690082

Epoch: 6| Step: 6
Training loss: 0.7001935839653015
Validation loss: 1.8479750438403058

Epoch: 6| Step: 7
Training loss: 0.5901575684547424
Validation loss: 1.8332007726033528

Epoch: 6| Step: 8
Training loss: 0.7084317803382874
Validation loss: 1.8320329394391788

Epoch: 6| Step: 9
Training loss: 0.882689356803894
Validation loss: 1.8287853630640174

Epoch: 6| Step: 10
Training loss: 0.6327300667762756
Validation loss: 1.8135679357795305

Epoch: 6| Step: 11
Training loss: 0.9619253873825073
Validation loss: 1.8480061023466048

Epoch: 6| Step: 12
Training loss: 0.7342061400413513
Validation loss: 1.8609307478832942

Epoch: 6| Step: 13
Training loss: 0.7236239314079285
Validation loss: 1.876335326061454

Epoch: 215| Step: 0
Training loss: 1.1041975021362305
Validation loss: 1.8594018592629382

Epoch: 6| Step: 1
Training loss: 0.7963705658912659
Validation loss: 1.8634696250320764

Epoch: 6| Step: 2
Training loss: 0.8514906764030457
Validation loss: 1.8775653839111328

Epoch: 6| Step: 3
Training loss: 0.6335279941558838
Validation loss: 1.8818800359643915

Epoch: 6| Step: 4
Training loss: 0.6751618981361389
Validation loss: 1.8836531344280447

Epoch: 6| Step: 5
Training loss: 0.7085496187210083
Validation loss: 1.8795583965957805

Epoch: 6| Step: 6
Training loss: 0.5255329608917236
Validation loss: 1.908149783329297

Epoch: 6| Step: 7
Training loss: 0.8796228766441345
Validation loss: 1.8789200321320565

Epoch: 6| Step: 8
Training loss: 0.6367135047912598
Validation loss: 1.8411847981073524

Epoch: 6| Step: 9
Training loss: 0.4921463131904602
Validation loss: 1.8836895573523738

Epoch: 6| Step: 10
Training loss: 1.0316803455352783
Validation loss: 1.859636260617164

Epoch: 6| Step: 11
Training loss: 1.2698040008544922
Validation loss: 1.8033414399752052

Epoch: 6| Step: 12
Training loss: 0.4926866888999939
Validation loss: 1.8232926040567377

Epoch: 6| Step: 13
Training loss: 0.703223466873169
Validation loss: 1.8440333950904109

Epoch: 216| Step: 0
Training loss: 1.1731823682785034
Validation loss: 1.8474886161024853

Epoch: 6| Step: 1
Training loss: 0.24685333669185638
Validation loss: 1.8422537580613167

Epoch: 6| Step: 2
Training loss: 0.7178670763969421
Validation loss: 1.8329437522478

Epoch: 6| Step: 3
Training loss: 0.8602356910705566
Validation loss: 1.8604235867018342

Epoch: 6| Step: 4
Training loss: 0.8691166639328003
Validation loss: 1.8882769064236713

Epoch: 6| Step: 5
Training loss: 0.8162730932235718
Validation loss: 1.9039498964945476

Epoch: 6| Step: 6
Training loss: 0.8122664093971252
Validation loss: 1.9356997756547825

Epoch: 6| Step: 7
Training loss: 0.5222334861755371
Validation loss: 1.947281664417636

Epoch: 6| Step: 8
Training loss: 0.7433128952980042
Validation loss: 1.9513958449004798

Epoch: 6| Step: 9
Training loss: 0.38924652338027954
Validation loss: 1.9479873898208782

Epoch: 6| Step: 10
Training loss: 1.1559540033340454
Validation loss: 1.9399291981932938

Epoch: 6| Step: 11
Training loss: 0.6362635493278503
Validation loss: 1.914851083550402

Epoch: 6| Step: 12
Training loss: 1.1778435707092285
Validation loss: 1.909400196485622

Epoch: 6| Step: 13
Training loss: 0.7430546283721924
Validation loss: 1.8549933433532715

Epoch: 217| Step: 0
Training loss: 0.9173449277877808
Validation loss: 1.8194913902590353

Epoch: 6| Step: 1
Training loss: 0.9250643253326416
Validation loss: 1.8188140007757372

Epoch: 6| Step: 2
Training loss: 0.9999947547912598
Validation loss: 1.841084586676731

Epoch: 6| Step: 3
Training loss: 0.8410528898239136
Validation loss: 1.8246127559292702

Epoch: 6| Step: 4
Training loss: 0.5770825743675232
Validation loss: 1.83216231612749

Epoch: 6| Step: 5
Training loss: 0.9801876544952393
Validation loss: 1.8358949307472474

Epoch: 6| Step: 6
Training loss: 0.6961297988891602
Validation loss: 1.8655794064203899

Epoch: 6| Step: 7
Training loss: 0.7196177244186401
Validation loss: 1.857806928696171

Epoch: 6| Step: 8
Training loss: 0.9598595499992371
Validation loss: 1.8892490056253248

Epoch: 6| Step: 9
Training loss: 1.0142549276351929
Validation loss: 1.8463328833221107

Epoch: 6| Step: 10
Training loss: 0.5916377305984497
Validation loss: 1.87355246210611

Epoch: 6| Step: 11
Training loss: 0.7035855054855347
Validation loss: 1.8853765713271273

Epoch: 6| Step: 12
Training loss: 0.6548795700073242
Validation loss: 1.8660080804619739

Epoch: 6| Step: 13
Training loss: 0.40247175097465515
Validation loss: 1.8665548588639946

Epoch: 218| Step: 0
Training loss: 0.423664927482605
Validation loss: 1.8460961041911956

Epoch: 6| Step: 1
Training loss: 0.7549995183944702
Validation loss: 1.8520792838065856

Epoch: 6| Step: 2
Training loss: 0.4893876910209656
Validation loss: 1.8675196375898135

Epoch: 6| Step: 3
Training loss: 0.9597965478897095
Validation loss: 1.8569965580458283

Epoch: 6| Step: 4
Training loss: 0.992655873298645
Validation loss: 1.8816186817743445

Epoch: 6| Step: 5
Training loss: 0.8218761682510376
Validation loss: 1.9242072784772484

Epoch: 6| Step: 6
Training loss: 0.8537290096282959
Validation loss: 1.9298687545202111

Epoch: 6| Step: 7
Training loss: 0.493513822555542
Validation loss: 1.9150904788765857

Epoch: 6| Step: 8
Training loss: 0.8816579580307007
Validation loss: 1.9229601852355465

Epoch: 6| Step: 9
Training loss: 0.5242265462875366
Validation loss: 1.9014037629609466

Epoch: 6| Step: 10
Training loss: 0.8268640637397766
Validation loss: 1.8829564343216598

Epoch: 6| Step: 11
Training loss: 1.2190170288085938
Validation loss: 1.8918401066974928

Epoch: 6| Step: 12
Training loss: 0.9827136993408203
Validation loss: 1.865302337113247

Epoch: 6| Step: 13
Training loss: 0.6164913177490234
Validation loss: 1.8472657434401973

Epoch: 219| Step: 0
Training loss: 0.6127517223358154
Validation loss: 1.8990530942075996

Epoch: 6| Step: 1
Training loss: 0.7789433002471924
Validation loss: 1.9174585380861837

Epoch: 6| Step: 2
Training loss: 0.8835996389389038
Validation loss: 1.8972864945729573

Epoch: 6| Step: 3
Training loss: 0.4963546395301819
Validation loss: 1.8673535277766566

Epoch: 6| Step: 4
Training loss: 0.750038743019104
Validation loss: 1.8953777718287643

Epoch: 6| Step: 5
Training loss: 0.8206310272216797
Validation loss: 1.8795384591625584

Epoch: 6| Step: 6
Training loss: 0.6342481374740601
Validation loss: 1.8662593672352452

Epoch: 6| Step: 7
Training loss: 0.8524317741394043
Validation loss: 1.893226135161615

Epoch: 6| Step: 8
Training loss: 0.40448126196861267
Validation loss: 1.8718470168370072

Epoch: 6| Step: 9
Training loss: 0.5656546354293823
Validation loss: 1.8557956962175266

Epoch: 6| Step: 10
Training loss: 0.6137266159057617
Validation loss: 1.8853091552693357

Epoch: 6| Step: 11
Training loss: 0.5810037851333618
Validation loss: 1.867266470386136

Epoch: 6| Step: 12
Training loss: 1.1419847011566162
Validation loss: 1.8754241645977061

Epoch: 6| Step: 13
Training loss: 1.6918257474899292
Validation loss: 1.881952424203196

Epoch: 220| Step: 0
Training loss: 0.6574902534484863
Validation loss: 1.8823403158495504

Epoch: 6| Step: 1
Training loss: 1.0877107381820679
Validation loss: 1.9187841569223711

Epoch: 6| Step: 2
Training loss: 0.4096881151199341
Validation loss: 1.8719255052587038

Epoch: 6| Step: 3
Training loss: 1.0814547538757324
Validation loss: 1.8891749984474593

Epoch: 6| Step: 4
Training loss: 1.049027919769287
Validation loss: 1.9149450127796461

Epoch: 6| Step: 5
Training loss: 0.9161521196365356
Validation loss: 1.9082475426376506

Epoch: 6| Step: 6
Training loss: 0.8180826902389526
Validation loss: 1.8861076703635595

Epoch: 6| Step: 7
Training loss: 0.8075038194656372
Validation loss: 1.8672745676450833

Epoch: 6| Step: 8
Training loss: 0.5792655348777771
Validation loss: 1.8702143135891165

Epoch: 6| Step: 9
Training loss: 0.4616219997406006
Validation loss: 1.8847380594540668

Epoch: 6| Step: 10
Training loss: 0.39316198229789734
Validation loss: 1.8567417821576517

Epoch: 6| Step: 11
Training loss: 0.9438341856002808
Validation loss: 1.8620281463028283

Epoch: 6| Step: 12
Training loss: 0.7465254068374634
Validation loss: 1.8647818270549978

Epoch: 6| Step: 13
Training loss: 0.38164636492729187
Validation loss: 1.8907377053332586

Epoch: 221| Step: 0
Training loss: 0.747596263885498
Validation loss: 1.8531803930959394

Epoch: 6| Step: 1
Training loss: 0.6422730684280396
Validation loss: 1.8606550834512199

Epoch: 6| Step: 2
Training loss: 0.41329896450042725
Validation loss: 1.8492457841032295

Epoch: 6| Step: 3
Training loss: 0.6442296504974365
Validation loss: 1.8600125274350565

Epoch: 6| Step: 4
Training loss: 0.6834055185317993
Validation loss: 1.8495543003082275

Epoch: 6| Step: 5
Training loss: 0.3732861876487732
Validation loss: 1.8698935188272947

Epoch: 6| Step: 6
Training loss: 0.5913591384887695
Validation loss: 1.8366670967430196

Epoch: 6| Step: 7
Training loss: 0.5550048351287842
Validation loss: 1.8582353527827928

Epoch: 6| Step: 8
Training loss: 0.7725579738616943
Validation loss: 1.8229315768006027

Epoch: 6| Step: 9
Training loss: 0.8619699478149414
Validation loss: 1.8714369561082573

Epoch: 6| Step: 10
Training loss: 1.0241717100143433
Validation loss: 1.8976043129480014

Epoch: 6| Step: 11
Training loss: 0.9840152263641357
Validation loss: 1.883012197350943

Epoch: 6| Step: 12
Training loss: 0.8168516159057617
Validation loss: 1.9016129970550537

Epoch: 6| Step: 13
Training loss: 0.735012412071228
Validation loss: 1.8957566753510506

Epoch: 222| Step: 0
Training loss: 0.7083607912063599
Validation loss: 1.9030759065381941

Epoch: 6| Step: 1
Training loss: 0.881130576133728
Validation loss: 1.8946040830304545

Epoch: 6| Step: 2
Training loss: 0.686550498008728
Validation loss: 1.9220908354687434

Epoch: 6| Step: 3
Training loss: 0.6886148452758789
Validation loss: 1.8918642946468887

Epoch: 6| Step: 4
Training loss: 0.8199508786201477
Validation loss: 1.9210931383153445

Epoch: 6| Step: 5
Training loss: 0.9933105707168579
Validation loss: 1.8915013151784097

Epoch: 6| Step: 6
Training loss: 0.6616917252540588
Validation loss: 1.888735245632869

Epoch: 6| Step: 7
Training loss: 0.4341981112957001
Validation loss: 1.8472702644204582

Epoch: 6| Step: 8
Training loss: 0.8507222533226013
Validation loss: 1.8461490831067484

Epoch: 6| Step: 9
Training loss: 0.8047852516174316
Validation loss: 1.8668093835153887

Epoch: 6| Step: 10
Training loss: 1.061745524406433
Validation loss: 1.850931385511993

Epoch: 6| Step: 11
Training loss: 0.2710035741329193
Validation loss: 1.891127783765075

Epoch: 6| Step: 12
Training loss: 0.7810112833976746
Validation loss: 1.8791382684502551

Epoch: 6| Step: 13
Training loss: 0.5385729670524597
Validation loss: 1.8930489286299674

Epoch: 223| Step: 0
Training loss: 0.6434534788131714
Validation loss: 1.8762606318278978

Epoch: 6| Step: 1
Training loss: 0.48827841877937317
Validation loss: 1.9037709774509552

Epoch: 6| Step: 2
Training loss: 0.9132559299468994
Validation loss: 1.9118770476310485

Epoch: 6| Step: 3
Training loss: 0.734397828578949
Validation loss: 1.9843575185345066

Epoch: 6| Step: 4
Training loss: 0.6389044523239136
Validation loss: 1.9494784006508448

Epoch: 6| Step: 5
Training loss: 0.9248533248901367
Validation loss: 1.9313165705691102

Epoch: 6| Step: 6
Training loss: 0.5397657155990601
Validation loss: 1.9352674048434022

Epoch: 6| Step: 7
Training loss: 0.5782684087753296
Validation loss: 1.936517515490132

Epoch: 6| Step: 8
Training loss: 0.6938050985336304
Validation loss: 1.8948960701624553

Epoch: 6| Step: 9
Training loss: 0.7237530946731567
Validation loss: 1.8549539965967978

Epoch: 6| Step: 10
Training loss: 1.0330326557159424
Validation loss: 1.8390638661640946

Epoch: 6| Step: 11
Training loss: 1.1332687139511108
Validation loss: 1.8360920952212425

Epoch: 6| Step: 12
Training loss: 1.2355625629425049
Validation loss: 1.8302630762900076

Epoch: 6| Step: 13
Training loss: 0.8797104358673096
Validation loss: 1.8266966830017746

Epoch: 224| Step: 0
Training loss: 1.237769603729248
Validation loss: 1.8509568270816599

Epoch: 6| Step: 1
Training loss: 0.7565504312515259
Validation loss: 1.8606799161562355

Epoch: 6| Step: 2
Training loss: 0.8513174653053284
Validation loss: 1.871239391706323

Epoch: 6| Step: 3
Training loss: 0.7395738363265991
Validation loss: 1.9006202656735656

Epoch: 6| Step: 4
Training loss: 0.7070414423942566
Validation loss: 1.8866099939551404

Epoch: 6| Step: 5
Training loss: 0.7887732982635498
Validation loss: 1.935180881971954

Epoch: 6| Step: 6
Training loss: 0.6487982273101807
Validation loss: 1.9172588125351937

Epoch: 6| Step: 7
Training loss: 0.7140188813209534
Validation loss: 1.90609831963816

Epoch: 6| Step: 8
Training loss: 0.8251945972442627
Validation loss: 1.9081312917893933

Epoch: 6| Step: 9
Training loss: 0.49300289154052734
Validation loss: 1.8901631075848815

Epoch: 6| Step: 10
Training loss: 0.6310811638832092
Validation loss: 1.8459717894113192

Epoch: 6| Step: 11
Training loss: 0.5629935264587402
Validation loss: 1.8391293825641755

Epoch: 6| Step: 12
Training loss: 0.8621642589569092
Validation loss: 1.805497871932163

Epoch: 6| Step: 13
Training loss: 1.0895957946777344
Validation loss: 1.8288780873821628

Epoch: 225| Step: 0
Training loss: 0.7708668112754822
Validation loss: 1.8301065660292102

Epoch: 6| Step: 1
Training loss: 0.5872225761413574
Validation loss: 1.8169855289561774

Epoch: 6| Step: 2
Training loss: 0.6737707853317261
Validation loss: 1.8488474456212853

Epoch: 6| Step: 3
Training loss: 0.5799130201339722
Validation loss: 1.864019090129483

Epoch: 6| Step: 4
Training loss: 0.6186881065368652
Validation loss: 1.8713257979321223

Epoch: 6| Step: 5
Training loss: 0.6819218397140503
Validation loss: 1.912587458087552

Epoch: 6| Step: 6
Training loss: 0.6744775176048279
Validation loss: 1.9060377356826619

Epoch: 6| Step: 7
Training loss: 0.7526361346244812
Validation loss: 1.9268922767331522

Epoch: 6| Step: 8
Training loss: 0.6504387855529785
Validation loss: 1.8914444472200127

Epoch: 6| Step: 9
Training loss: 1.2767043113708496
Validation loss: 1.8982938899788806

Epoch: 6| Step: 10
Training loss: 0.7205321788787842
Validation loss: 1.901996212620889

Epoch: 6| Step: 11
Training loss: 0.4422876536846161
Validation loss: 1.8913051594970047

Epoch: 6| Step: 12
Training loss: 0.8746702075004578
Validation loss: 1.872345216812626

Epoch: 6| Step: 13
Training loss: 0.4438498020172119
Validation loss: 1.862237516269889

Epoch: 226| Step: 0
Training loss: 0.5899165868759155
Validation loss: 1.8713096444324782

Epoch: 6| Step: 1
Training loss: 0.665448009967804
Validation loss: 1.8347008792302941

Epoch: 6| Step: 2
Training loss: 0.6258856058120728
Validation loss: 1.835104412929986

Epoch: 6| Step: 3
Training loss: 0.7127261161804199
Validation loss: 1.8020985100858955

Epoch: 6| Step: 4
Training loss: 0.6224691271781921
Validation loss: 1.8221582443483415

Epoch: 6| Step: 5
Training loss: 0.5127029418945312
Validation loss: 1.8329336681673605

Epoch: 6| Step: 6
Training loss: 0.7869204878807068
Validation loss: 1.8787925961197063

Epoch: 6| Step: 7
Training loss: 0.6995258331298828
Validation loss: 1.854129591295796

Epoch: 6| Step: 8
Training loss: 0.7587270736694336
Validation loss: 1.8449646247330533

Epoch: 6| Step: 9
Training loss: 0.5435837507247925
Validation loss: 1.8840057849884033

Epoch: 6| Step: 10
Training loss: 0.9590371251106262
Validation loss: 1.8940496624156993

Epoch: 6| Step: 11
Training loss: 0.5169589519500732
Validation loss: 1.89253750155049

Epoch: 6| Step: 12
Training loss: 0.8410570621490479
Validation loss: 1.8814319564450173

Epoch: 6| Step: 13
Training loss: 0.9521433711051941
Validation loss: 1.92090868437162

Epoch: 227| Step: 0
Training loss: 0.8030329942703247
Validation loss: 1.8845108529572845

Epoch: 6| Step: 1
Training loss: 0.6120908856391907
Validation loss: 1.8816204122317735

Epoch: 6| Step: 2
Training loss: 0.7305096387863159
Validation loss: 1.8529088907344367

Epoch: 6| Step: 3
Training loss: 0.5635173916816711
Validation loss: 1.8399822353034891

Epoch: 6| Step: 4
Training loss: 0.48979562520980835
Validation loss: 1.8582194338562668

Epoch: 6| Step: 5
Training loss: 0.7414978742599487
Validation loss: 1.8411805309275144

Epoch: 6| Step: 6
Training loss: 0.5564548373222351
Validation loss: 1.8025420942614157

Epoch: 6| Step: 7
Training loss: 0.6941282749176025
Validation loss: 1.8085870153160506

Epoch: 6| Step: 8
Training loss: 0.7699979543685913
Validation loss: 1.7889227251852713

Epoch: 6| Step: 9
Training loss: 0.6034267544746399
Validation loss: 1.811683677857922

Epoch: 6| Step: 10
Training loss: 0.4581705331802368
Validation loss: 1.8351893027623494

Epoch: 6| Step: 11
Training loss: 0.8900982141494751
Validation loss: 1.856479493520593

Epoch: 6| Step: 12
Training loss: 0.9637389183044434
Validation loss: 1.847359408614456

Epoch: 6| Step: 13
Training loss: 0.7062297463417053
Validation loss: 1.8684134790974278

Epoch: 228| Step: 0
Training loss: 0.5496101975440979
Validation loss: 1.8521088220739876

Epoch: 6| Step: 1
Training loss: 0.6638644933700562
Validation loss: 1.9065049412429973

Epoch: 6| Step: 2
Training loss: 0.8107538223266602
Validation loss: 1.9165091078768495

Epoch: 6| Step: 3
Training loss: 0.5811776518821716
Validation loss: 1.8521501018155007

Epoch: 6| Step: 4
Training loss: 0.5094500780105591
Validation loss: 1.8566176904145109

Epoch: 6| Step: 5
Training loss: 0.6303379535675049
Validation loss: 1.8441342717857772

Epoch: 6| Step: 6
Training loss: 0.8085411787033081
Validation loss: 1.8590930559301888

Epoch: 6| Step: 7
Training loss: 1.035604476928711
Validation loss: 1.8557578235544183

Epoch: 6| Step: 8
Training loss: 0.5602275133132935
Validation loss: 1.837474726861523

Epoch: 6| Step: 9
Training loss: 0.8619875907897949
Validation loss: 1.8591051409321446

Epoch: 6| Step: 10
Training loss: 0.35920456051826477
Validation loss: 1.8824618452338762

Epoch: 6| Step: 11
Training loss: 0.9189927577972412
Validation loss: 1.8749489104875954

Epoch: 6| Step: 12
Training loss: 0.9854209423065186
Validation loss: 1.8786890301653134

Epoch: 6| Step: 13
Training loss: 0.6897658109664917
Validation loss: 1.8927071632877472

Epoch: 229| Step: 0
Training loss: 0.45324620604515076
Validation loss: 1.896609628072349

Epoch: 6| Step: 1
Training loss: 1.138002634048462
Validation loss: 1.902018093293713

Epoch: 6| Step: 2
Training loss: 0.7609292268753052
Validation loss: 1.9154427705272552

Epoch: 6| Step: 3
Training loss: 0.37200212478637695
Validation loss: 1.8860085446347472

Epoch: 6| Step: 4
Training loss: 0.5043196678161621
Validation loss: 1.893183518481511

Epoch: 6| Step: 5
Training loss: 0.563967764377594
Validation loss: 1.8686038601783015

Epoch: 6| Step: 6
Training loss: 0.6110365390777588
Validation loss: 1.8366803033377535

Epoch: 6| Step: 7
Training loss: 0.9695684313774109
Validation loss: 1.8428868068161832

Epoch: 6| Step: 8
Training loss: 0.5675891637802124
Validation loss: 1.7933615189726635

Epoch: 6| Step: 9
Training loss: 0.8308708667755127
Validation loss: 1.829948627820579

Epoch: 6| Step: 10
Training loss: 0.5977982878684998
Validation loss: 1.8180153703176847

Epoch: 6| Step: 11
Training loss: 0.8015022277832031
Validation loss: 1.833934143025388

Epoch: 6| Step: 12
Training loss: 0.45339319109916687
Validation loss: 1.8674887649474605

Epoch: 6| Step: 13
Training loss: 0.5160754323005676
Validation loss: 1.8769775744407409

Epoch: 230| Step: 0
Training loss: 0.4365890622138977
Validation loss: 1.8859672418204687

Epoch: 6| Step: 1
Training loss: 0.9091695547103882
Validation loss: 1.9092005170801634

Epoch: 6| Step: 2
Training loss: 0.9687674045562744
Validation loss: 1.904327561778407

Epoch: 6| Step: 3
Training loss: 0.603412389755249
Validation loss: 1.8839020421428065

Epoch: 6| Step: 4
Training loss: 0.5083216428756714
Validation loss: 1.8420887736863987

Epoch: 6| Step: 5
Training loss: 0.3119584023952484
Validation loss: 1.819439229144845

Epoch: 6| Step: 6
Training loss: 0.47928088903427124
Validation loss: 1.8442134241903982

Epoch: 6| Step: 7
Training loss: 0.621249258518219
Validation loss: 1.8221503893534343

Epoch: 6| Step: 8
Training loss: 0.5767008066177368
Validation loss: 1.8126518162347938

Epoch: 6| Step: 9
Training loss: 1.0656774044036865
Validation loss: 1.8218076600823352

Epoch: 6| Step: 10
Training loss: 0.5809605121612549
Validation loss: 1.8384831592600832

Epoch: 6| Step: 11
Training loss: 0.6733592748641968
Validation loss: 1.837542736402122

Epoch: 6| Step: 12
Training loss: 0.5075052976608276
Validation loss: 1.7991121276732414

Epoch: 6| Step: 13
Training loss: 1.0173486471176147
Validation loss: 1.8000723597823933

Epoch: 231| Step: 0
Training loss: 0.5237506628036499
Validation loss: 1.8132908780087706

Epoch: 6| Step: 1
Training loss: 0.5727404356002808
Validation loss: 1.8343974313428324

Epoch: 6| Step: 2
Training loss: 0.4230962097644806
Validation loss: 1.8476786177645448

Epoch: 6| Step: 3
Training loss: 0.6541121602058411
Validation loss: 1.8654356182262462

Epoch: 6| Step: 4
Training loss: 0.6703001856803894
Validation loss: 1.845598566916681

Epoch: 6| Step: 5
Training loss: 0.5463979244232178
Validation loss: 1.8334190076397312

Epoch: 6| Step: 6
Training loss: 0.844329833984375
Validation loss: 1.810959949288317

Epoch: 6| Step: 7
Training loss: 0.9269223213195801
Validation loss: 1.8142595547501759

Epoch: 6| Step: 8
Training loss: 0.6031429767608643
Validation loss: 1.821333360928361

Epoch: 6| Step: 9
Training loss: 0.6715477705001831
Validation loss: 1.812562047794301

Epoch: 6| Step: 10
Training loss: 0.9513723254203796
Validation loss: 1.8121844337832542

Epoch: 6| Step: 11
Training loss: 0.4754581153392792
Validation loss: 1.814541703911238

Epoch: 6| Step: 12
Training loss: 0.4521360993385315
Validation loss: 1.8212058210885653

Epoch: 6| Step: 13
Training loss: 0.4546569585800171
Validation loss: 1.8539406176536315

Epoch: 232| Step: 0
Training loss: 0.5918124914169312
Validation loss: 1.869322064102337

Epoch: 6| Step: 1
Training loss: 0.6383465528488159
Validation loss: 1.9091192804357058

Epoch: 6| Step: 2
Training loss: 0.5125359296798706
Validation loss: 1.91404116025535

Epoch: 6| Step: 3
Training loss: 0.6389594078063965
Validation loss: 1.9064833323160808

Epoch: 6| Step: 4
Training loss: 0.7128576636314392
Validation loss: 1.903512877802695

Epoch: 6| Step: 5
Training loss: 0.41405364871025085
Validation loss: 1.869652577625808

Epoch: 6| Step: 6
Training loss: 0.4996798634529114
Validation loss: 1.8410118869555894

Epoch: 6| Step: 7
Training loss: 0.44916215538978577
Validation loss: 1.8471562183031471

Epoch: 6| Step: 8
Training loss: 0.8720478415489197
Validation loss: 1.8348304828008015

Epoch: 6| Step: 9
Training loss: 0.5544978976249695
Validation loss: 1.8169741463917557

Epoch: 6| Step: 10
Training loss: 1.1243846416473389
Validation loss: 1.822240347503334

Epoch: 6| Step: 11
Training loss: 0.8723241090774536
Validation loss: 1.8115843624197028

Epoch: 6| Step: 12
Training loss: 0.6579017043113708
Validation loss: 1.8078498558331562

Epoch: 6| Step: 13
Training loss: 0.5305712223052979
Validation loss: 1.8186467539879583

Epoch: 233| Step: 0
Training loss: 0.6746664643287659
Validation loss: 1.8433499874607209

Epoch: 6| Step: 1
Training loss: 0.5453507304191589
Validation loss: 1.8503788235366985

Epoch: 6| Step: 2
Training loss: 0.8867184519767761
Validation loss: 1.8744225309741112

Epoch: 6| Step: 3
Training loss: 0.8921357989311218
Validation loss: 1.8599192583432762

Epoch: 6| Step: 4
Training loss: 0.9210338592529297
Validation loss: 1.868517957707887

Epoch: 6| Step: 5
Training loss: 0.41858136653900146
Validation loss: 1.8844191976772842

Epoch: 6| Step: 6
Training loss: 0.4609871506690979
Validation loss: 1.8505220554208244

Epoch: 6| Step: 7
Training loss: 0.6097916960716248
Validation loss: 1.847419684933078

Epoch: 6| Step: 8
Training loss: 0.36236369609832764
Validation loss: 1.8849587543036348

Epoch: 6| Step: 9
Training loss: 0.6060912609100342
Validation loss: 1.8540125059825119

Epoch: 6| Step: 10
Training loss: 0.7117907404899597
Validation loss: 1.8279762601339689

Epoch: 6| Step: 11
Training loss: 0.7335407733917236
Validation loss: 1.8239390157884168

Epoch: 6| Step: 12
Training loss: 0.5383281707763672
Validation loss: 1.8442164428772465

Epoch: 6| Step: 13
Training loss: 0.511729896068573
Validation loss: 1.8242256743933565

Epoch: 234| Step: 0
Training loss: 0.9889811277389526
Validation loss: 1.824647540687233

Epoch: 6| Step: 1
Training loss: 0.5490744113922119
Validation loss: 1.8226114549944479

Epoch: 6| Step: 2
Training loss: 0.5732325315475464
Validation loss: 1.8599446268491848

Epoch: 6| Step: 3
Training loss: 0.49325138330459595
Validation loss: 1.844149871539044

Epoch: 6| Step: 4
Training loss: 0.487653911113739
Validation loss: 1.84139173517945

Epoch: 6| Step: 5
Training loss: 0.6453396677970886
Validation loss: 1.8711834812677035

Epoch: 6| Step: 6
Training loss: 0.6043713092803955
Validation loss: 1.8474810982263217

Epoch: 6| Step: 7
Training loss: 0.5536267757415771
Validation loss: 1.8648450015693583

Epoch: 6| Step: 8
Training loss: 0.8536516427993774
Validation loss: 1.842131119902416

Epoch: 6| Step: 9
Training loss: 0.5938235521316528
Validation loss: 1.8605342911135765

Epoch: 6| Step: 10
Training loss: 0.7428948283195496
Validation loss: 1.8783672830109954

Epoch: 6| Step: 11
Training loss: 0.7066013813018799
Validation loss: 1.8663325207207793

Epoch: 6| Step: 12
Training loss: 0.7342487573623657
Validation loss: 1.8689612163010465

Epoch: 6| Step: 13
Training loss: 0.7095906734466553
Validation loss: 1.8529112492838213

Epoch: 235| Step: 0
Training loss: 0.5355879068374634
Validation loss: 1.8890310871985652

Epoch: 6| Step: 1
Training loss: 0.5257254242897034
Validation loss: 1.8547128490222398

Epoch: 6| Step: 2
Training loss: 0.48751553893089294
Validation loss: 1.8347816134011874

Epoch: 6| Step: 3
Training loss: 0.6203888058662415
Validation loss: 1.902877825562672

Epoch: 6| Step: 4
Training loss: 0.4031594395637512
Validation loss: 1.892905109672136

Epoch: 6| Step: 5
Training loss: 0.7502090930938721
Validation loss: 1.8683566983028124

Epoch: 6| Step: 6
Training loss: 0.6516510248184204
Validation loss: 1.8645356957630446

Epoch: 6| Step: 7
Training loss: 0.7437978982925415
Validation loss: 1.825783452680034

Epoch: 6| Step: 8
Training loss: 0.49153411388397217
Validation loss: 1.8265781787133986

Epoch: 6| Step: 9
Training loss: 0.3486454486846924
Validation loss: 1.832299925947702

Epoch: 6| Step: 10
Training loss: 1.0970194339752197
Validation loss: 1.8447979150279876

Epoch: 6| Step: 11
Training loss: 0.7272278070449829
Validation loss: 1.8362505525671027

Epoch: 6| Step: 12
Training loss: 0.5793538093566895
Validation loss: 1.8812357943545106

Epoch: 6| Step: 13
Training loss: 0.46804046630859375
Validation loss: 1.855281300442193

Epoch: 236| Step: 0
Training loss: 0.5361397862434387
Validation loss: 1.840292461456791

Epoch: 6| Step: 1
Training loss: 0.319116473197937
Validation loss: 1.8406299429555093

Epoch: 6| Step: 2
Training loss: 0.39366036653518677
Validation loss: 1.8254967786932503

Epoch: 6| Step: 3
Training loss: 0.9819167852401733
Validation loss: 1.8643851408394434

Epoch: 6| Step: 4
Training loss: 0.5582494735717773
Validation loss: 1.8564066758719824

Epoch: 6| Step: 5
Training loss: 0.659709095954895
Validation loss: 1.85063551574625

Epoch: 6| Step: 6
Training loss: 0.6566463708877563
Validation loss: 1.8350203857626965

Epoch: 6| Step: 7
Training loss: 0.5894215106964111
Validation loss: 1.871204697957603

Epoch: 6| Step: 8
Training loss: 0.4970155358314514
Validation loss: 1.876830235604317

Epoch: 6| Step: 9
Training loss: 0.886722981929779
Validation loss: 1.8801699376875354

Epoch: 6| Step: 10
Training loss: 0.6660700440406799
Validation loss: 1.8843831221262615

Epoch: 6| Step: 11
Training loss: 0.6130849123001099
Validation loss: 1.8939455888604606

Epoch: 6| Step: 12
Training loss: 0.4743768274784088
Validation loss: 1.8922357328476445

Epoch: 6| Step: 13
Training loss: 0.7306807637214661
Validation loss: 1.8763215708476242

Epoch: 237| Step: 0
Training loss: 0.6256178021430969
Validation loss: 1.883644151431258

Epoch: 6| Step: 1
Training loss: 0.4790637493133545
Validation loss: 1.8824875982858802

Epoch: 6| Step: 2
Training loss: 0.6224455833435059
Validation loss: 1.8543763852888537

Epoch: 6| Step: 3
Training loss: 0.4357009530067444
Validation loss: 1.8615171012058054

Epoch: 6| Step: 4
Training loss: 0.42878007888793945
Validation loss: 1.8834942656178628

Epoch: 6| Step: 5
Training loss: 0.5314106345176697
Validation loss: 1.8420243968245804

Epoch: 6| Step: 6
Training loss: 0.6878931522369385
Validation loss: 1.876446557301347

Epoch: 6| Step: 7
Training loss: 0.7935099005699158
Validation loss: 1.8826569280316752

Epoch: 6| Step: 8
Training loss: 0.812552809715271
Validation loss: 1.8744129724400018

Epoch: 6| Step: 9
Training loss: 0.5704199075698853
Validation loss: 1.8445205765385781

Epoch: 6| Step: 10
Training loss: 0.5780306458473206
Validation loss: 1.8921889412787654

Epoch: 6| Step: 11
Training loss: 0.6874643564224243
Validation loss: 1.8795442478631132

Epoch: 6| Step: 12
Training loss: 0.5335178971290588
Validation loss: 1.8299573211259739

Epoch: 6| Step: 13
Training loss: 0.8217107057571411
Validation loss: 1.8567465402746712

Epoch: 238| Step: 0
Training loss: 0.36592626571655273
Validation loss: 1.8523557903946086

Epoch: 6| Step: 1
Training loss: 0.8436141610145569
Validation loss: 1.8496092955271404

Epoch: 6| Step: 2
Training loss: 0.48027315735816956
Validation loss: 1.8567841822101223

Epoch: 6| Step: 3
Training loss: 0.7549989223480225
Validation loss: 1.8914240355132728

Epoch: 6| Step: 4
Training loss: 0.9396065473556519
Validation loss: 1.8907611216268232

Epoch: 6| Step: 5
Training loss: 0.7860405445098877
Validation loss: 1.8863473233356272

Epoch: 6| Step: 6
Training loss: 0.47393739223480225
Validation loss: 1.8804906055491457

Epoch: 6| Step: 7
Training loss: 0.46621161699295044
Validation loss: 1.855858532331323

Epoch: 6| Step: 8
Training loss: 0.4697614014148712
Validation loss: 1.8570953017921858

Epoch: 6| Step: 9
Training loss: 0.6082265973091125
Validation loss: 1.8575030129442933

Epoch: 6| Step: 10
Training loss: 0.40420863032341003
Validation loss: 1.8361148641955467

Epoch: 6| Step: 11
Training loss: 0.9936191439628601
Validation loss: 1.8578534151918145

Epoch: 6| Step: 12
Training loss: 0.3369782269001007
Validation loss: 1.859135712346723

Epoch: 6| Step: 13
Training loss: 0.3150329291820526
Validation loss: 1.8509366563571397

Epoch: 239| Step: 0
Training loss: 0.297176331281662
Validation loss: 1.8367595595698203

Epoch: 6| Step: 1
Training loss: 0.625027060508728
Validation loss: 1.8294035106576898

Epoch: 6| Step: 2
Training loss: 0.6575369834899902
Validation loss: 1.8565561848302041

Epoch: 6| Step: 3
Training loss: 0.32900312542915344
Validation loss: 1.8500920316224456

Epoch: 6| Step: 4
Training loss: 0.8248029947280884
Validation loss: 1.8717624788643212

Epoch: 6| Step: 5
Training loss: 0.538706362247467
Validation loss: 1.8383770373559767

Epoch: 6| Step: 6
Training loss: 0.6267296075820923
Validation loss: 1.873941795800322

Epoch: 6| Step: 7
Training loss: 0.715565025806427
Validation loss: 1.8567083984292962

Epoch: 6| Step: 8
Training loss: 0.7775249481201172
Validation loss: 1.799727004061463

Epoch: 6| Step: 9
Training loss: 0.49113816022872925
Validation loss: 1.8117457282158635

Epoch: 6| Step: 10
Training loss: 0.6282384991645813
Validation loss: 1.8055742017684444

Epoch: 6| Step: 11
Training loss: 0.7434186935424805
Validation loss: 1.8364211026058401

Epoch: 6| Step: 12
Training loss: 0.4881001114845276
Validation loss: 1.8269591626300608

Epoch: 6| Step: 13
Training loss: 0.3969787359237671
Validation loss: 1.8004825820205033

Epoch: 240| Step: 0
Training loss: 0.804194450378418
Validation loss: 1.841854767132831

Epoch: 6| Step: 1
Training loss: 0.7641891837120056
Validation loss: 1.8452230115090646

Epoch: 6| Step: 2
Training loss: 0.5271217823028564
Validation loss: 1.832919846298874

Epoch: 6| Step: 3
Training loss: 0.4161897301673889
Validation loss: 1.8782129159537695

Epoch: 6| Step: 4
Training loss: 0.5708139538764954
Validation loss: 1.871062018538034

Epoch: 6| Step: 5
Training loss: 0.9341899752616882
Validation loss: 1.8725704928880096

Epoch: 6| Step: 6
Training loss: 0.645282506942749
Validation loss: 1.8543937642087218

Epoch: 6| Step: 7
Training loss: 0.48079732060432434
Validation loss: 1.8647222518920898

Epoch: 6| Step: 8
Training loss: 0.6769516468048096
Validation loss: 1.85054366050228

Epoch: 6| Step: 9
Training loss: 0.33527079224586487
Validation loss: 1.8560528787233497

Epoch: 6| Step: 10
Training loss: 0.706058144569397
Validation loss: 1.8664032105476625

Epoch: 6| Step: 11
Training loss: 0.33363857865333557
Validation loss: 1.8255426063332507

Epoch: 6| Step: 12
Training loss: 0.6059218049049377
Validation loss: 1.848703037026108

Epoch: 6| Step: 13
Training loss: 0.5390004515647888
Validation loss: 1.8412377283137331

Epoch: 241| Step: 0
Training loss: 0.3282705545425415
Validation loss: 1.8309117055708362

Epoch: 6| Step: 1
Training loss: 0.7230890989303589
Validation loss: 1.843059637213266

Epoch: 6| Step: 2
Training loss: 0.4244120121002197
Validation loss: 1.8682808260763846

Epoch: 6| Step: 3
Training loss: 0.3616776466369629
Validation loss: 1.869439555752662

Epoch: 6| Step: 4
Training loss: 0.7246792316436768
Validation loss: 1.895723207022554

Epoch: 6| Step: 5
Training loss: 0.7259435653686523
Validation loss: 1.9252882465239494

Epoch: 6| Step: 6
Training loss: 0.8129171133041382
Validation loss: 1.90247130650346

Epoch: 6| Step: 7
Training loss: 0.39066481590270996
Validation loss: 1.9078392315936346

Epoch: 6| Step: 8
Training loss: 0.36560168862342834
Validation loss: 1.8856442564277238

Epoch: 6| Step: 9
Training loss: 0.5246474742889404
Validation loss: 1.849917250294839

Epoch: 6| Step: 10
Training loss: 0.6431630253791809
Validation loss: 1.8469599382851714

Epoch: 6| Step: 11
Training loss: 0.8187539577484131
Validation loss: 1.8395645554347704

Epoch: 6| Step: 12
Training loss: 0.8181217312812805
Validation loss: 1.8108302367630826

Epoch: 6| Step: 13
Training loss: 0.1886563003063202
Validation loss: 1.844096270940637

Epoch: 242| Step: 0
Training loss: 0.49672624468803406
Validation loss: 1.845019817352295

Epoch: 6| Step: 1
Training loss: 0.6022839546203613
Validation loss: 1.8679859484395673

Epoch: 6| Step: 2
Training loss: 0.571343719959259
Validation loss: 1.8525887253463909

Epoch: 6| Step: 3
Training loss: 0.6002751588821411
Validation loss: 1.8204672131487118

Epoch: 6| Step: 4
Training loss: 0.4937504529953003
Validation loss: 1.8196470019637898

Epoch: 6| Step: 5
Training loss: 0.5098148584365845
Validation loss: 1.8358115816629061

Epoch: 6| Step: 6
Training loss: 0.4012017250061035
Validation loss: 1.8289492335370792

Epoch: 6| Step: 7
Training loss: 0.8682863116264343
Validation loss: 1.860464947198027

Epoch: 6| Step: 8
Training loss: 0.7007502913475037
Validation loss: 1.8460569535532305

Epoch: 6| Step: 9
Training loss: 0.7613757848739624
Validation loss: 1.8507573245674052

Epoch: 6| Step: 10
Training loss: 0.525702953338623
Validation loss: 1.8424013276253977

Epoch: 6| Step: 11
Training loss: 0.46076688170433044
Validation loss: 1.8489143220327233

Epoch: 6| Step: 12
Training loss: 0.8355106711387634
Validation loss: 1.7843014783756708

Epoch: 6| Step: 13
Training loss: 0.37132394313812256
Validation loss: 1.7656300016628799

Epoch: 243| Step: 0
Training loss: 0.6892852187156677
Validation loss: 1.7986868978828512

Epoch: 6| Step: 1
Training loss: 0.9179800152778625
Validation loss: 1.801535383347542

Epoch: 6| Step: 2
Training loss: 0.6120343208312988
Validation loss: 1.8152343842291063

Epoch: 6| Step: 3
Training loss: 0.8984130024909973
Validation loss: 1.7928304723514024

Epoch: 6| Step: 4
Training loss: 0.6348052024841309
Validation loss: 1.8049296461125857

Epoch: 6| Step: 5
Training loss: 0.530300498008728
Validation loss: 1.7825018526405416

Epoch: 6| Step: 6
Training loss: 0.643578052520752
Validation loss: 1.836062010898385

Epoch: 6| Step: 7
Training loss: 0.21461623907089233
Validation loss: 1.8024452194090812

Epoch: 6| Step: 8
Training loss: 0.5365884304046631
Validation loss: 1.831746023188355

Epoch: 6| Step: 9
Training loss: 0.5182921886444092
Validation loss: 1.8459577406606367

Epoch: 6| Step: 10
Training loss: 0.5398042798042297
Validation loss: 1.9006966608826832

Epoch: 6| Step: 11
Training loss: 0.5376070737838745
Validation loss: 1.9614931729532057

Epoch: 6| Step: 12
Training loss: 0.790922999382019
Validation loss: 1.947491443285378

Epoch: 6| Step: 13
Training loss: 0.6275651454925537
Validation loss: 1.9500943063407816

Epoch: 244| Step: 0
Training loss: 0.5336896181106567
Validation loss: 1.9243198389648108

Epoch: 6| Step: 1
Training loss: 0.3247501850128174
Validation loss: 1.8636395059606081

Epoch: 6| Step: 2
Training loss: 0.5916894674301147
Validation loss: 1.827127730974587

Epoch: 6| Step: 3
Training loss: 0.7616044282913208
Validation loss: 1.8475803623917282

Epoch: 6| Step: 4
Training loss: 0.5002152919769287
Validation loss: 1.839544516737743

Epoch: 6| Step: 5
Training loss: 0.8611193895339966
Validation loss: 1.8364695554138513

Epoch: 6| Step: 6
Training loss: 0.6015218496322632
Validation loss: 1.8545282412600774

Epoch: 6| Step: 7
Training loss: 0.48910433053970337
Validation loss: 1.8100862259505897

Epoch: 6| Step: 8
Training loss: 0.7600597143173218
Validation loss: 1.8181789818630423

Epoch: 6| Step: 9
Training loss: 0.9109320044517517
Validation loss: 1.7915208160236318

Epoch: 6| Step: 10
Training loss: 0.49807241559028625
Validation loss: 1.78274017764676

Epoch: 6| Step: 11
Training loss: 0.652731716632843
Validation loss: 1.8438265477457354

Epoch: 6| Step: 12
Training loss: 0.4463404417037964
Validation loss: 1.8447057739380868

Epoch: 6| Step: 13
Training loss: 0.629382312297821
Validation loss: 1.9131423593849264

Epoch: 245| Step: 0
Training loss: 0.9852646589279175
Validation loss: 1.9130835866415372

Epoch: 6| Step: 1
Training loss: 0.5400255918502808
Validation loss: 1.9220509721386818

Epoch: 6| Step: 2
Training loss: 0.5377237796783447
Validation loss: 1.9613994231788061

Epoch: 6| Step: 3
Training loss: 0.5903220176696777
Validation loss: 1.9377421743126326

Epoch: 6| Step: 4
Training loss: 0.4551957845687866
Validation loss: 1.9390126248841644

Epoch: 6| Step: 5
Training loss: 0.6586285829544067
Validation loss: 1.920398610894398

Epoch: 6| Step: 6
Training loss: 0.6067472696304321
Validation loss: 1.8690224309121408

Epoch: 6| Step: 7
Training loss: 0.2655213475227356
Validation loss: 1.8416736202855264

Epoch: 6| Step: 8
Training loss: 0.7961101531982422
Validation loss: 1.8379051851969894

Epoch: 6| Step: 9
Training loss: 0.6462794542312622
Validation loss: 1.8253395788131221

Epoch: 6| Step: 10
Training loss: 0.34040918946266174
Validation loss: 1.8154116202426214

Epoch: 6| Step: 11
Training loss: 0.5101834535598755
Validation loss: 1.8463865146842053

Epoch: 6| Step: 12
Training loss: 0.6313726902008057
Validation loss: 1.8340047636339742

Epoch: 6| Step: 13
Training loss: 0.44641706347465515
Validation loss: 1.8103817842339958

Epoch: 246| Step: 0
Training loss: 0.8191449642181396
Validation loss: 1.8491859833399455

Epoch: 6| Step: 1
Training loss: 0.44669660925865173
Validation loss: 1.8138855093268937

Epoch: 6| Step: 2
Training loss: 0.7048295736312866
Validation loss: 1.8377490633277482

Epoch: 6| Step: 3
Training loss: 0.2984558939933777
Validation loss: 1.8443041604052308

Epoch: 6| Step: 4
Training loss: 0.7411440014839172
Validation loss: 1.8855349735547138

Epoch: 6| Step: 5
Training loss: 0.4142071306705475
Validation loss: 1.9112975879382061

Epoch: 6| Step: 6
Training loss: 0.4952125549316406
Validation loss: 1.9043457328632314

Epoch: 6| Step: 7
Training loss: 0.45942187309265137
Validation loss: 1.8951241790607412

Epoch: 6| Step: 8
Training loss: 0.6825242042541504
Validation loss: 1.8591321924681306

Epoch: 6| Step: 9
Training loss: 0.75694739818573
Validation loss: 1.8466660335499754

Epoch: 6| Step: 10
Training loss: 0.5986918807029724
Validation loss: 1.8433507527074506

Epoch: 6| Step: 11
Training loss: 0.8505945205688477
Validation loss: 1.8277813952456239

Epoch: 6| Step: 12
Training loss: 0.6538825035095215
Validation loss: 1.839473480819374

Epoch: 6| Step: 13
Training loss: 0.3992246687412262
Validation loss: 1.831595117045987

Epoch: 247| Step: 0
Training loss: 0.5481728315353394
Validation loss: 1.8435156999095794

Epoch: 6| Step: 1
Training loss: 0.46237027645111084
Validation loss: 1.7965075200603855

Epoch: 6| Step: 2
Training loss: 0.537594199180603
Validation loss: 1.8203323246330343

Epoch: 6| Step: 3
Training loss: 0.593224048614502
Validation loss: 1.8205558843510126

Epoch: 6| Step: 4
Training loss: 0.6814814209938049
Validation loss: 1.8132226082586473

Epoch: 6| Step: 5
Training loss: 0.5519071221351624
Validation loss: 1.826349389168524

Epoch: 6| Step: 6
Training loss: 0.5758730173110962
Validation loss: 1.8273660188080163

Epoch: 6| Step: 7
Training loss: 0.45920422673225403
Validation loss: 1.820886532465617

Epoch: 6| Step: 8
Training loss: 0.4741053879261017
Validation loss: 1.8453942011761408

Epoch: 6| Step: 9
Training loss: 0.6653952598571777
Validation loss: 1.8251072078622796

Epoch: 6| Step: 10
Training loss: 0.7961839437484741
Validation loss: 1.8333038822297127

Epoch: 6| Step: 11
Training loss: 0.7352115511894226
Validation loss: 1.8179606955538514

Epoch: 6| Step: 12
Training loss: 0.3089379072189331
Validation loss: 1.857183276966054

Epoch: 6| Step: 13
Training loss: 0.3489185571670532
Validation loss: 1.8251465443641908

Epoch: 248| Step: 0
Training loss: 0.5982680320739746
Validation loss: 1.8523098602089831

Epoch: 6| Step: 1
Training loss: 0.5452953577041626
Validation loss: 1.8307575141229937

Epoch: 6| Step: 2
Training loss: 0.5807504653930664
Validation loss: 1.8462645251263854

Epoch: 6| Step: 3
Training loss: 0.41379696130752563
Validation loss: 1.881272969707366

Epoch: 6| Step: 4
Training loss: 0.4670029282569885
Validation loss: 1.8659516995952976

Epoch: 6| Step: 5
Training loss: 0.39673060178756714
Validation loss: 1.8573545435423493

Epoch: 6| Step: 6
Training loss: 0.4430224597454071
Validation loss: 1.8428873118533884

Epoch: 6| Step: 7
Training loss: 0.38905730843544006
Validation loss: 1.8537000020345051

Epoch: 6| Step: 8
Training loss: 0.4060192108154297
Validation loss: 1.8367325593066472

Epoch: 6| Step: 9
Training loss: 0.3400917649269104
Validation loss: 1.8315410537104453

Epoch: 6| Step: 10
Training loss: 0.6644893884658813
Validation loss: 1.8263958884823708

Epoch: 6| Step: 11
Training loss: 0.4283338785171509
Validation loss: 1.8392305284418085

Epoch: 6| Step: 12
Training loss: 0.9963790774345398
Validation loss: 1.8149819194629628

Epoch: 6| Step: 13
Training loss: 0.8752948641777039
Validation loss: 1.8400918309406569

Epoch: 249| Step: 0
Training loss: 0.33084824681282043
Validation loss: 1.8170181756378503

Epoch: 6| Step: 1
Training loss: 0.34220969676971436
Validation loss: 1.8284575131631666

Epoch: 6| Step: 2
Training loss: 0.5201939344406128
Validation loss: 1.8001827398935955

Epoch: 6| Step: 3
Training loss: 0.24911737442016602
Validation loss: 1.8397311600305701

Epoch: 6| Step: 4
Training loss: 0.5800317525863647
Validation loss: 1.8315248335561445

Epoch: 6| Step: 5
Training loss: 0.5098273754119873
Validation loss: 1.8159199722351567

Epoch: 6| Step: 6
Training loss: 0.4771353006362915
Validation loss: 1.8350176388217556

Epoch: 6| Step: 7
Training loss: 0.6911174058914185
Validation loss: 1.808157205581665

Epoch: 6| Step: 8
Training loss: 0.5302547216415405
Validation loss: 1.8143060412458194

Epoch: 6| Step: 9
Training loss: 0.6773977279663086
Validation loss: 1.8281490495128017

Epoch: 6| Step: 10
Training loss: 0.5589261054992676
Validation loss: 1.8441735877785632

Epoch: 6| Step: 11
Training loss: 0.5423954725265503
Validation loss: 1.8293092725097493

Epoch: 6| Step: 12
Training loss: 0.3964006304740906
Validation loss: 1.8296425470741846

Epoch: 6| Step: 13
Training loss: 0.48365041613578796
Validation loss: 1.8197548312525595

Epoch: 250| Step: 0
Training loss: 0.8509306907653809
Validation loss: 1.8327473055931829

Epoch: 6| Step: 1
Training loss: 0.5435004234313965
Validation loss: 1.8473553965168614

Epoch: 6| Step: 2
Training loss: 0.5056620836257935
Validation loss: 1.8514302020431848

Epoch: 6| Step: 3
Training loss: 0.591193437576294
Validation loss: 1.8523773070304625

Epoch: 6| Step: 4
Training loss: 0.4440857172012329
Validation loss: 1.8148854163385206

Epoch: 6| Step: 5
Training loss: 0.5128349661827087
Validation loss: 1.842285333141204

Epoch: 6| Step: 6
Training loss: 0.6727292537689209
Validation loss: 1.8342142899831135

Epoch: 6| Step: 7
Training loss: 0.31580132246017456
Validation loss: 1.8119335084833124

Epoch: 6| Step: 8
Training loss: 0.4374099373817444
Validation loss: 1.8140766338635517

Epoch: 6| Step: 9
Training loss: 0.3285853862762451
Validation loss: 1.8422374956069454

Epoch: 6| Step: 10
Training loss: 0.7740378975868225
Validation loss: 1.830736542260775

Epoch: 6| Step: 11
Training loss: 0.3261352479457855
Validation loss: 1.8304303628142162

Epoch: 6| Step: 12
Training loss: 0.4392436146736145
Validation loss: 1.836672366306346

Epoch: 6| Step: 13
Training loss: 0.1693146526813507
Validation loss: 1.8285190956566924

Epoch: 251| Step: 0
Training loss: 0.36145710945129395
Validation loss: 1.8370350201924641

Epoch: 6| Step: 1
Training loss: 0.629005491733551
Validation loss: 1.8494345744450886

Epoch: 6| Step: 2
Training loss: 0.2908620536327362
Validation loss: 1.8153016310866161

Epoch: 6| Step: 3
Training loss: 0.7828229665756226
Validation loss: 1.8028916851166756

Epoch: 6| Step: 4
Training loss: 0.4377736449241638
Validation loss: 1.82473365593982

Epoch: 6| Step: 5
Training loss: 0.2533985376358032
Validation loss: 1.8014731881439046

Epoch: 6| Step: 6
Training loss: 0.5901713967323303
Validation loss: 1.8020263243747014

Epoch: 6| Step: 7
Training loss: 0.4794473946094513
Validation loss: 1.7900385574627948

Epoch: 6| Step: 8
Training loss: 0.7199198007583618
Validation loss: 1.8599610174855878

Epoch: 6| Step: 9
Training loss: 0.5364352464675903
Validation loss: 1.8731739264662548

Epoch: 6| Step: 10
Training loss: 1.041324257850647
Validation loss: 1.8590843164792625

Epoch: 6| Step: 11
Training loss: 0.3736157715320587
Validation loss: 1.8164212652432021

Epoch: 6| Step: 12
Training loss: 0.25293296575546265
Validation loss: 1.8190168180773336

Epoch: 6| Step: 13
Training loss: 0.5630563497543335
Validation loss: 1.7858552932739258

Epoch: 252| Step: 0
Training loss: 0.48161908984184265
Validation loss: 1.7980325965471164

Epoch: 6| Step: 1
Training loss: 0.34845882654190063
Validation loss: 1.774407717489427

Epoch: 6| Step: 2
Training loss: 0.4634351134300232
Validation loss: 1.7882085666861585

Epoch: 6| Step: 3
Training loss: 0.566149115562439
Validation loss: 1.7815653021617601

Epoch: 6| Step: 4
Training loss: 0.5822147130966187
Validation loss: 1.785407838001046

Epoch: 6| Step: 5
Training loss: 0.4409293830394745
Validation loss: 1.7335574088558074

Epoch: 6| Step: 6
Training loss: 0.2746838331222534
Validation loss: 1.7513867014197892

Epoch: 6| Step: 7
Training loss: 0.588318943977356
Validation loss: 1.7590589369496992

Epoch: 6| Step: 8
Training loss: 0.1924205720424652
Validation loss: 1.7826367655108053

Epoch: 6| Step: 9
Training loss: 0.30232930183410645
Validation loss: 1.7820100245937225

Epoch: 6| Step: 10
Training loss: 0.8791694641113281
Validation loss: 1.8135480976873828

Epoch: 6| Step: 11
Training loss: 0.8700953722000122
Validation loss: 1.8326711039389334

Epoch: 6| Step: 12
Training loss: 0.4224965572357178
Validation loss: 1.8179647973788682

Epoch: 6| Step: 13
Training loss: 0.6504519581794739
Validation loss: 1.7981146099746868

Epoch: 253| Step: 0
Training loss: 0.506791353225708
Validation loss: 1.8126656342578191

Epoch: 6| Step: 1
Training loss: 0.3995317220687866
Validation loss: 1.758508123377318

Epoch: 6| Step: 2
Training loss: 0.2767258286476135
Validation loss: 1.7499720652898152

Epoch: 6| Step: 3
Training loss: 0.4435679018497467
Validation loss: 1.732586137710079

Epoch: 6| Step: 4
Training loss: 0.6366583108901978
Validation loss: 1.7579152494348504

Epoch: 6| Step: 5
Training loss: 0.5799766182899475
Validation loss: 1.751188293580086

Epoch: 6| Step: 6
Training loss: 0.43536606431007385
Validation loss: 1.755608348436253

Epoch: 6| Step: 7
Training loss: 0.33834540843963623
Validation loss: 1.78730131477438

Epoch: 6| Step: 8
Training loss: 0.42777037620544434
Validation loss: 1.8157577155738749

Epoch: 6| Step: 9
Training loss: 0.6075654029846191
Validation loss: 1.7755320597720403

Epoch: 6| Step: 10
Training loss: 0.5377563238143921
Validation loss: 1.7742309019129763

Epoch: 6| Step: 11
Training loss: 0.5453893542289734
Validation loss: 1.7789133389790852

Epoch: 6| Step: 12
Training loss: 0.555772602558136
Validation loss: 1.7850052810484363

Epoch: 6| Step: 13
Training loss: 0.5110306739807129
Validation loss: 1.7703845090763544

Epoch: 254| Step: 0
Training loss: 0.5668014287948608
Validation loss: 1.7851836027637604

Epoch: 6| Step: 1
Training loss: 0.8584096431732178
Validation loss: 1.7837052332457675

Epoch: 6| Step: 2
Training loss: 0.2706359028816223
Validation loss: 1.7314770798529349

Epoch: 6| Step: 3
Training loss: 0.43899932503700256
Validation loss: 1.7680896469341811

Epoch: 6| Step: 4
Training loss: 0.2828676104545593
Validation loss: 1.7880649733287033

Epoch: 6| Step: 5
Training loss: 0.4280306100845337
Validation loss: 1.7939546236427881

Epoch: 6| Step: 6
Training loss: 0.3027845025062561
Validation loss: 1.8065197954895675

Epoch: 6| Step: 7
Training loss: 0.35307425260543823
Validation loss: 1.8113979639545563

Epoch: 6| Step: 8
Training loss: 0.4442659616470337
Validation loss: 1.8006701918058499

Epoch: 6| Step: 9
Training loss: 0.6159982085227966
Validation loss: 1.8111682822627406

Epoch: 6| Step: 10
Training loss: 0.5475868582725525
Validation loss: 1.784459578093662

Epoch: 6| Step: 11
Training loss: 0.588683009147644
Validation loss: 1.816272871468657

Epoch: 6| Step: 12
Training loss: 0.4368135333061218
Validation loss: 1.7625294436690628

Epoch: 6| Step: 13
Training loss: 0.16709429025650024
Validation loss: 1.7739870035520164

Epoch: 255| Step: 0
Training loss: 0.4428238272666931
Validation loss: 1.769900168142011

Epoch: 6| Step: 1
Training loss: 0.22538653016090393
Validation loss: 1.778437291422198

Epoch: 6| Step: 2
Training loss: 0.36522552371025085
Validation loss: 1.7705629602555306

Epoch: 6| Step: 3
Training loss: 0.5591559410095215
Validation loss: 1.789667615326502

Epoch: 6| Step: 4
Training loss: 0.5131946802139282
Validation loss: 1.797075907389323

Epoch: 6| Step: 5
Training loss: 0.2375282347202301
Validation loss: 1.7875618934631348

Epoch: 6| Step: 6
Training loss: 0.5635128021240234
Validation loss: 1.787791282899918

Epoch: 6| Step: 7
Training loss: 0.5015679001808167
Validation loss: 1.8181591110844766

Epoch: 6| Step: 8
Training loss: 0.15954375267028809
Validation loss: 1.8061083029675227

Epoch: 6| Step: 9
Training loss: 0.8098917007446289
Validation loss: 1.768154678806182

Epoch: 6| Step: 10
Training loss: 0.4281178116798401
Validation loss: 1.8034699219529347

Epoch: 6| Step: 11
Training loss: 0.590782105922699
Validation loss: 1.8010410019146499

Epoch: 6| Step: 12
Training loss: 0.7563827037811279
Validation loss: 1.8063568197270876

Epoch: 6| Step: 13
Training loss: 0.45203420519828796
Validation loss: 1.813924999647243

Epoch: 256| Step: 0
Training loss: 0.7126528024673462
Validation loss: 1.8099979841580955

Epoch: 6| Step: 1
Training loss: 0.37973302602767944
Validation loss: 1.8372261216563563

Epoch: 6| Step: 2
Training loss: 0.5364770293235779
Validation loss: 1.8517153122091805

Epoch: 6| Step: 3
Training loss: 0.5249776244163513
Validation loss: 1.8213034829785746

Epoch: 6| Step: 4
Training loss: 0.30447328090667725
Validation loss: 1.813170313835144

Epoch: 6| Step: 5
Training loss: 0.3928964138031006
Validation loss: 1.7879771340277888

Epoch: 6| Step: 6
Training loss: 0.3107915222644806
Validation loss: 1.764216528143934

Epoch: 6| Step: 7
Training loss: 0.5716478824615479
Validation loss: 1.7895870849650393

Epoch: 6| Step: 8
Training loss: 0.35085177421569824
Validation loss: 1.7634748258898336

Epoch: 6| Step: 9
Training loss: 0.5527470111846924
Validation loss: 1.799807938196326

Epoch: 6| Step: 10
Training loss: 0.5984592437744141
Validation loss: 1.8274484283180648

Epoch: 6| Step: 11
Training loss: 0.4672076106071472
Validation loss: 1.7869209999679236

Epoch: 6| Step: 12
Training loss: 0.5648481845855713
Validation loss: 1.7934430568448958

Epoch: 6| Step: 13
Training loss: 0.13093198835849762
Validation loss: 1.7989427223000476

Epoch: 257| Step: 0
Training loss: 0.5429999828338623
Validation loss: 1.7761825476923296

Epoch: 6| Step: 1
Training loss: 0.36444687843322754
Validation loss: 1.8043824511189615

Epoch: 6| Step: 2
Training loss: 0.3459278345108032
Validation loss: 1.7487521972707523

Epoch: 6| Step: 3
Training loss: 0.22020143270492554
Validation loss: 1.7880561121048466

Epoch: 6| Step: 4
Training loss: 0.4802533686161041
Validation loss: 1.803465292017947

Epoch: 6| Step: 5
Training loss: 0.4406459331512451
Validation loss: 1.775080733401801

Epoch: 6| Step: 6
Training loss: 0.4600505828857422
Validation loss: 1.7380918405389274

Epoch: 6| Step: 7
Training loss: 0.6293461322784424
Validation loss: 1.7801482895369172

Epoch: 6| Step: 8
Training loss: 0.6137923002243042
Validation loss: 1.7576289010304276

Epoch: 6| Step: 9
Training loss: 0.6133589744567871
Validation loss: 1.7792906953442482

Epoch: 6| Step: 10
Training loss: 0.4604616165161133
Validation loss: 1.7836929380252797

Epoch: 6| Step: 11
Training loss: 0.49144595861434937
Validation loss: 1.7849966018430647

Epoch: 6| Step: 12
Training loss: 0.3992392122745514
Validation loss: 1.7940726972395373

Epoch: 6| Step: 13
Training loss: 0.7937530279159546
Validation loss: 1.77797269821167

Epoch: 258| Step: 0
Training loss: 0.7424928545951843
Validation loss: 1.786190350850423

Epoch: 6| Step: 1
Training loss: 0.5473886728286743
Validation loss: 1.8104798383610223

Epoch: 6| Step: 2
Training loss: 0.4822038412094116
Validation loss: 1.8070023598209504

Epoch: 6| Step: 3
Training loss: 0.35953226685523987
Validation loss: 1.8314754655284267

Epoch: 6| Step: 4
Training loss: 0.5549112558364868
Validation loss: 1.8272112018318587

Epoch: 6| Step: 5
Training loss: 0.4430283308029175
Validation loss: 1.7949536449165755

Epoch: 6| Step: 6
Training loss: 0.5324718952178955
Validation loss: 1.7753350670619676

Epoch: 6| Step: 7
Training loss: 0.6124488711357117
Validation loss: 1.7463341156641643

Epoch: 6| Step: 8
Training loss: 0.26789426803588867
Validation loss: 1.7548085156307425

Epoch: 6| Step: 9
Training loss: 0.5527665019035339
Validation loss: 1.7150858845762027

Epoch: 6| Step: 10
Training loss: 0.3230026960372925
Validation loss: 1.7156655608966787

Epoch: 6| Step: 11
Training loss: 0.3285941779613495
Validation loss: 1.7564877797198553

Epoch: 6| Step: 12
Training loss: 0.5318652391433716
Validation loss: 1.722695524974536

Epoch: 6| Step: 13
Training loss: 0.4834226965904236
Validation loss: 1.8036224483161845

Epoch: 259| Step: 0
Training loss: 0.5858402252197266
Validation loss: 1.8078190434363581

Epoch: 6| Step: 1
Training loss: 0.37288033962249756
Validation loss: 1.8395976827990623

Epoch: 6| Step: 2
Training loss: 0.2827317714691162
Validation loss: 1.8167485242248864

Epoch: 6| Step: 3
Training loss: 0.5602983832359314
Validation loss: 1.8067679456485215

Epoch: 6| Step: 4
Training loss: 0.38779765367507935
Validation loss: 1.7745454849735383

Epoch: 6| Step: 5
Training loss: 0.8394211530685425
Validation loss: 1.7439291938658683

Epoch: 6| Step: 6
Training loss: 0.41030529141426086
Validation loss: 1.764139618924869

Epoch: 6| Step: 7
Training loss: 0.5122738480567932
Validation loss: 1.755180480659649

Epoch: 6| Step: 8
Training loss: 0.3317873775959015
Validation loss: 1.7556713691321753

Epoch: 6| Step: 9
Training loss: 0.4989681541919708
Validation loss: 1.7891906538317282

Epoch: 6| Step: 10
Training loss: 0.49133872985839844
Validation loss: 1.7883300435158513

Epoch: 6| Step: 11
Training loss: 0.46638011932373047
Validation loss: 1.7669819990793865

Epoch: 6| Step: 12
Training loss: 0.639946699142456
Validation loss: 1.7738931089319208

Epoch: 6| Step: 13
Training loss: 0.6538657546043396
Validation loss: 1.7932486136754353

Epoch: 260| Step: 0
Training loss: 0.3950536549091339
Validation loss: 1.7959480721463439

Epoch: 6| Step: 1
Training loss: 0.9678118824958801
Validation loss: 1.7993619800895773

Epoch: 6| Step: 2
Training loss: 0.4189426302909851
Validation loss: 1.77846783720037

Epoch: 6| Step: 3
Training loss: 0.3690146803855896
Validation loss: 1.834776989234391

Epoch: 6| Step: 4
Training loss: 0.3212771415710449
Validation loss: 1.8213111175003873

Epoch: 6| Step: 5
Training loss: 0.4781222343444824
Validation loss: 1.8309179505994242

Epoch: 6| Step: 6
Training loss: 0.669426679611206
Validation loss: 1.8701390950910506

Epoch: 6| Step: 7
Training loss: 0.45359006524086
Validation loss: 1.8676874022330008

Epoch: 6| Step: 8
Training loss: 0.4777533710002899
Validation loss: 1.8779032025285947

Epoch: 6| Step: 9
Training loss: 0.3570239543914795
Validation loss: 1.8202047489022697

Epoch: 6| Step: 10
Training loss: 0.6131566762924194
Validation loss: 1.8347194803658353

Epoch: 6| Step: 11
Training loss: 0.2741926312446594
Validation loss: 1.8045076285639117

Epoch: 6| Step: 12
Training loss: 0.5379757881164551
Validation loss: 1.79244234741375

Epoch: 6| Step: 13
Training loss: 0.29804521799087524
Validation loss: 1.7727416997314782

Epoch: 261| Step: 0
Training loss: 0.39113691449165344
Validation loss: 1.7851173621352001

Epoch: 6| Step: 1
Training loss: 0.409542441368103
Validation loss: 1.778663669863055

Epoch: 6| Step: 2
Training loss: 0.3273950219154358
Validation loss: 1.7646443805386942

Epoch: 6| Step: 3
Training loss: 0.3433716297149658
Validation loss: 1.7818745028588079

Epoch: 6| Step: 4
Training loss: 0.528403639793396
Validation loss: 1.8244873310929985

Epoch: 6| Step: 5
Training loss: 0.5626977682113647
Validation loss: 1.824595018099713

Epoch: 6| Step: 6
Training loss: 0.4869726896286011
Validation loss: 1.8505783465600782

Epoch: 6| Step: 7
Training loss: 0.6078415513038635
Validation loss: 1.862053801936488

Epoch: 6| Step: 8
Training loss: 0.5983026027679443
Validation loss: 1.802407803074006

Epoch: 6| Step: 9
Training loss: 0.441008061170578
Validation loss: 1.7933608267896919

Epoch: 6| Step: 10
Training loss: 0.5073397159576416
Validation loss: 1.7713148183720087

Epoch: 6| Step: 11
Training loss: 0.5176365971565247
Validation loss: 1.751441251847052

Epoch: 6| Step: 12
Training loss: 0.37094932794570923
Validation loss: 1.776392057377805

Epoch: 6| Step: 13
Training loss: 0.6098389029502869
Validation loss: 1.7673526143514982

Epoch: 262| Step: 0
Training loss: 0.21481700241565704
Validation loss: 1.7846599637821157

Epoch: 6| Step: 1
Training loss: 0.5522345304489136
Validation loss: 1.7889085854253461

Epoch: 6| Step: 2
Training loss: 0.7247732877731323
Validation loss: 1.7400577106783468

Epoch: 6| Step: 3
Training loss: 0.5134487152099609
Validation loss: 1.7947472885090818

Epoch: 6| Step: 4
Training loss: 0.36743539571762085
Validation loss: 1.802327707249631

Epoch: 6| Step: 5
Training loss: 0.34284740686416626
Validation loss: 1.782127167588921

Epoch: 6| Step: 6
Training loss: 0.49915745854377747
Validation loss: 1.765744911727085

Epoch: 6| Step: 7
Training loss: 0.610593855381012
Validation loss: 1.7974937820947299

Epoch: 6| Step: 8
Training loss: 0.3446826636791229
Validation loss: 1.7798208607140409

Epoch: 6| Step: 9
Training loss: 0.4560547471046448
Validation loss: 1.803480811016534

Epoch: 6| Step: 10
Training loss: 0.5758326053619385
Validation loss: 1.8072279396877493

Epoch: 6| Step: 11
Training loss: 0.369797021150589
Validation loss: 1.768890557750579

Epoch: 6| Step: 12
Training loss: 0.5129550099372864
Validation loss: 1.775234660794658

Epoch: 6| Step: 13
Training loss: 0.24447840452194214
Validation loss: 1.755802527550728

Epoch: 263| Step: 0
Training loss: 0.34277480840682983
Validation loss: 1.7896556995248283

Epoch: 6| Step: 1
Training loss: 0.5196474194526672
Validation loss: 1.7861261547252696

Epoch: 6| Step: 2
Training loss: 0.29713472723960876
Validation loss: 1.798421690540929

Epoch: 6| Step: 3
Training loss: 0.3122699558734894
Validation loss: 1.7744759590395036

Epoch: 6| Step: 4
Training loss: 0.3408278524875641
Validation loss: 1.781981070836385

Epoch: 6| Step: 5
Training loss: 0.424878865480423
Validation loss: 1.7467869430459955

Epoch: 6| Step: 6
Training loss: 0.700533390045166
Validation loss: 1.7538047118853497

Epoch: 6| Step: 7
Training loss: 0.7521086931228638
Validation loss: 1.740475385419784

Epoch: 6| Step: 8
Training loss: 0.3876693546772003
Validation loss: 1.755853590144906

Epoch: 6| Step: 9
Training loss: 0.42586231231689453
Validation loss: 1.7626078205723916

Epoch: 6| Step: 10
Training loss: 0.24065622687339783
Validation loss: 1.7618061727093113

Epoch: 6| Step: 11
Training loss: 0.26232457160949707
Validation loss: 1.7915451962460753

Epoch: 6| Step: 12
Training loss: 0.6140571236610413
Validation loss: 1.7697811690709924

Epoch: 6| Step: 13
Training loss: 0.49268272519111633
Validation loss: 1.7735408813722673

Epoch: 264| Step: 0
Training loss: 0.4396756887435913
Validation loss: 1.7671833602331017

Epoch: 6| Step: 1
Training loss: 0.3274115324020386
Validation loss: 1.7451697139329807

Epoch: 6| Step: 2
Training loss: 0.2836163341999054
Validation loss: 1.706542779040593

Epoch: 6| Step: 3
Training loss: 0.6835932731628418
Validation loss: 1.7296916528414654

Epoch: 6| Step: 4
Training loss: 0.34526652097702026
Validation loss: 1.7207279538595548

Epoch: 6| Step: 5
Training loss: 0.23429735004901886
Validation loss: 1.7534961879894297

Epoch: 6| Step: 6
Training loss: 0.34486472606658936
Validation loss: 1.740279983448726

Epoch: 6| Step: 7
Training loss: 0.6156704425811768
Validation loss: 1.7804107396833357

Epoch: 6| Step: 8
Training loss: 0.1985645890235901
Validation loss: 1.8083082796424947

Epoch: 6| Step: 9
Training loss: 0.4443930387496948
Validation loss: 1.8120692904277513

Epoch: 6| Step: 10
Training loss: 0.48258987069129944
Validation loss: 1.8272835593069754

Epoch: 6| Step: 11
Training loss: 0.4101482629776001
Validation loss: 1.8017529851646834

Epoch: 6| Step: 12
Training loss: 0.5849239230155945
Validation loss: 1.7806129724748674

Epoch: 6| Step: 13
Training loss: 0.6316804885864258
Validation loss: 1.7714525115105413

Epoch: 265| Step: 0
Training loss: 0.8882887959480286
Validation loss: 1.7536723229192919

Epoch: 6| Step: 1
Training loss: 0.4858379364013672
Validation loss: 1.772384351299655

Epoch: 6| Step: 2
Training loss: 0.6884311437606812
Validation loss: 1.7574687862908969

Epoch: 6| Step: 3
Training loss: 0.5419228076934814
Validation loss: 1.7737275887561101

Epoch: 6| Step: 4
Training loss: 0.40758293867111206
Validation loss: 1.7701247212707356

Epoch: 6| Step: 5
Training loss: 0.4763786792755127
Validation loss: 1.7632406526996243

Epoch: 6| Step: 6
Training loss: 0.5660233497619629
Validation loss: 1.7848542877422866

Epoch: 6| Step: 7
Training loss: 0.25010499358177185
Validation loss: 1.8033775603899391

Epoch: 6| Step: 8
Training loss: 0.24166221916675568
Validation loss: 1.7933978085876794

Epoch: 6| Step: 9
Training loss: 0.4325634241104126
Validation loss: 1.8332807235820319

Epoch: 6| Step: 10
Training loss: 0.3915092945098877
Validation loss: 1.8051239777636785

Epoch: 6| Step: 11
Training loss: 0.34823912382125854
Validation loss: 1.8223319310013966

Epoch: 6| Step: 12
Training loss: 0.23821154236793518
Validation loss: 1.819352420427466

Epoch: 6| Step: 13
Training loss: 0.23293542861938477
Validation loss: 1.8127058911067184

Epoch: 266| Step: 0
Training loss: 0.2765793204307556
Validation loss: 1.7953147580546718

Epoch: 6| Step: 1
Training loss: 0.528660237789154
Validation loss: 1.805511482300297

Epoch: 6| Step: 2
Training loss: 0.3480733633041382
Validation loss: 1.8136101538135159

Epoch: 6| Step: 3
Training loss: 0.440241277217865
Validation loss: 1.8329708358292938

Epoch: 6| Step: 4
Training loss: 0.48365455865859985
Validation loss: 1.8254638897475375

Epoch: 6| Step: 5
Training loss: 0.33528047800064087
Validation loss: 1.7983470142528575

Epoch: 6| Step: 6
Training loss: 0.6623563766479492
Validation loss: 1.8257173927881385

Epoch: 6| Step: 7
Training loss: 0.5579591989517212
Validation loss: 1.8217757594200872

Epoch: 6| Step: 8
Training loss: 0.32073140144348145
Validation loss: 1.8156448641131002

Epoch: 6| Step: 9
Training loss: 0.35083675384521484
Validation loss: 1.824087755654448

Epoch: 6| Step: 10
Training loss: 0.4389132261276245
Validation loss: 1.819517045892695

Epoch: 6| Step: 11
Training loss: 0.5568478107452393
Validation loss: 1.8103148398860809

Epoch: 6| Step: 12
Training loss: 0.5041801929473877
Validation loss: 1.798623764386741

Epoch: 6| Step: 13
Training loss: 0.270709365606308
Validation loss: 1.820637692687332

Epoch: 267| Step: 0
Training loss: 0.4637954831123352
Validation loss: 1.8046216810903242

Epoch: 6| Step: 1
Training loss: 0.5479574203491211
Validation loss: 1.7738252262915335

Epoch: 6| Step: 2
Training loss: 0.4044414758682251
Validation loss: 1.7789836724599202

Epoch: 6| Step: 3
Training loss: 0.4184798002243042
Validation loss: 1.7548293798200545

Epoch: 6| Step: 4
Training loss: 0.5775401592254639
Validation loss: 1.7495459536070466

Epoch: 6| Step: 5
Training loss: 0.5951980352401733
Validation loss: 1.753475163572578

Epoch: 6| Step: 6
Training loss: 0.3119220733642578
Validation loss: 1.7452539154278335

Epoch: 6| Step: 7
Training loss: 0.2856343686580658
Validation loss: 1.7550258251928514

Epoch: 6| Step: 8
Training loss: 0.5189058780670166
Validation loss: 1.7553479351023191

Epoch: 6| Step: 9
Training loss: 0.26987141370773315
Validation loss: 1.7637071558224258

Epoch: 6| Step: 10
Training loss: 0.2983558177947998
Validation loss: 1.795369525109568

Epoch: 6| Step: 11
Training loss: 0.3371065557003021
Validation loss: 1.7964810030434721

Epoch: 6| Step: 12
Training loss: 0.340378999710083
Validation loss: 1.8339793964098858

Epoch: 6| Step: 13
Training loss: 0.398708701133728
Validation loss: 1.847665225305865

Epoch: 268| Step: 0
Training loss: 0.3241904377937317
Validation loss: 1.8344443792937903

Epoch: 6| Step: 1
Training loss: 0.4282544255256653
Validation loss: 1.8470604586344894

Epoch: 6| Step: 2
Training loss: 0.163987398147583
Validation loss: 1.8213368564523675

Epoch: 6| Step: 3
Training loss: 0.28508177399635315
Validation loss: 1.8286368000891902

Epoch: 6| Step: 4
Training loss: 0.5231981873512268
Validation loss: 1.8511695592634139

Epoch: 6| Step: 5
Training loss: 0.24441762268543243
Validation loss: 1.7906234341282998

Epoch: 6| Step: 6
Training loss: 0.2834409773349762
Validation loss: 1.7945990075347245

Epoch: 6| Step: 7
Training loss: 0.7484841346740723
Validation loss: 1.798511569217969

Epoch: 6| Step: 8
Training loss: 0.28448447585105896
Validation loss: 1.7697961330413818

Epoch: 6| Step: 9
Training loss: 0.3690733313560486
Validation loss: 1.7904148691443986

Epoch: 6| Step: 10
Training loss: 0.5157475471496582
Validation loss: 1.7782511967484669

Epoch: 6| Step: 11
Training loss: 0.6786093711853027
Validation loss: 1.8157942948802825

Epoch: 6| Step: 12
Training loss: 0.5895687937736511
Validation loss: 1.8067329673356907

Epoch: 6| Step: 13
Training loss: 0.4466603994369507
Validation loss: 1.800164012498753

Epoch: 269| Step: 0
Training loss: 0.36821845173835754
Validation loss: 1.754747800929572

Epoch: 6| Step: 1
Training loss: 0.724634051322937
Validation loss: 1.7603131212213987

Epoch: 6| Step: 2
Training loss: 0.14885078370571136
Validation loss: 1.7613736910204734

Epoch: 6| Step: 3
Training loss: 0.31796637177467346
Validation loss: 1.7473036102069321

Epoch: 6| Step: 4
Training loss: 0.47954702377319336
Validation loss: 1.7947830218140797

Epoch: 6| Step: 5
Training loss: 0.334975928068161
Validation loss: 1.8449306936674221

Epoch: 6| Step: 6
Training loss: 0.6361324787139893
Validation loss: 1.8203580379486084

Epoch: 6| Step: 7
Training loss: 0.43813517689704895
Validation loss: 1.8149753937157251

Epoch: 6| Step: 8
Training loss: 0.32155174016952515
Validation loss: 1.762240376523746

Epoch: 6| Step: 9
Training loss: 0.30732375383377075
Validation loss: 1.777404212182568

Epoch: 6| Step: 10
Training loss: 0.2998032569885254
Validation loss: 1.761384080815059

Epoch: 6| Step: 11
Training loss: 0.6455664038658142
Validation loss: 1.737904607608754

Epoch: 6| Step: 12
Training loss: 0.570143461227417
Validation loss: 1.772507147122455

Epoch: 6| Step: 13
Training loss: 0.15731656551361084
Validation loss: 1.7510499479950115

Epoch: 270| Step: 0
Training loss: 0.3662671446800232
Validation loss: 1.7776219075725925

Epoch: 6| Step: 1
Training loss: 0.6364766359329224
Validation loss: 1.759416663518516

Epoch: 6| Step: 2
Training loss: 0.6242612600326538
Validation loss: 1.7772599215148597

Epoch: 6| Step: 3
Training loss: 0.5091438293457031
Validation loss: 1.819438583107405

Epoch: 6| Step: 4
Training loss: 0.2830005884170532
Validation loss: 1.7873301929043186

Epoch: 6| Step: 5
Training loss: 0.21842527389526367
Validation loss: 1.814523409771663

Epoch: 6| Step: 6
Training loss: 0.2862108647823334
Validation loss: 1.8094992906816545

Epoch: 6| Step: 7
Training loss: 0.4564046263694763
Validation loss: 1.7894097720423052

Epoch: 6| Step: 8
Training loss: 0.4228649437427521
Validation loss: 1.8194242356925883

Epoch: 6| Step: 9
Training loss: 0.33816683292388916
Validation loss: 1.8191646786146267

Epoch: 6| Step: 10
Training loss: 0.46323609352111816
Validation loss: 1.801278414264802

Epoch: 6| Step: 11
Training loss: 0.6160508394241333
Validation loss: 1.7951300349286807

Epoch: 6| Step: 12
Training loss: 0.44494813680648804
Validation loss: 1.8238004779302945

Epoch: 6| Step: 13
Training loss: 0.3280421495437622
Validation loss: 1.773253272938472

Epoch: 271| Step: 0
Training loss: 0.612153172492981
Validation loss: 1.849339028840424

Epoch: 6| Step: 1
Training loss: 0.2523300349712372
Validation loss: 1.8599731178693875

Epoch: 6| Step: 2
Training loss: 0.3219456970691681
Validation loss: 1.832956047468288

Epoch: 6| Step: 3
Training loss: 0.6556574106216431
Validation loss: 1.8006519527845486

Epoch: 6| Step: 4
Training loss: 0.2836794853210449
Validation loss: 1.7937286515389719

Epoch: 6| Step: 5
Training loss: 0.3371991515159607
Validation loss: 1.79183627072201

Epoch: 6| Step: 6
Training loss: 0.29826080799102783
Validation loss: 1.7935675408250542

Epoch: 6| Step: 7
Training loss: 0.5155836343765259
Validation loss: 1.782388662779203

Epoch: 6| Step: 8
Training loss: 0.4075831472873688
Validation loss: 1.7760134820015199

Epoch: 6| Step: 9
Training loss: 0.1495719850063324
Validation loss: 1.772950332651856

Epoch: 6| Step: 10
Training loss: 0.3895198702812195
Validation loss: 1.7756487041391351

Epoch: 6| Step: 11
Training loss: 0.6549186706542969
Validation loss: 1.7893266741947462

Epoch: 6| Step: 12
Training loss: 0.3586861789226532
Validation loss: 1.7716680726697367

Epoch: 6| Step: 13
Training loss: 0.22293107211589813
Validation loss: 1.7662340030875257

Epoch: 272| Step: 0
Training loss: 0.4081791639328003
Validation loss: 1.7360862326878372

Epoch: 6| Step: 1
Training loss: 0.4296415448188782
Validation loss: 1.7968642891094249

Epoch: 6| Step: 2
Training loss: 0.27721065282821655
Validation loss: 1.7862222976582025

Epoch: 6| Step: 3
Training loss: 0.3992367088794708
Validation loss: 1.7595553269950293

Epoch: 6| Step: 4
Training loss: 0.5694250464439392
Validation loss: 1.772607002207028

Epoch: 6| Step: 5
Training loss: 0.44479355216026306
Validation loss: 1.7781578827929754

Epoch: 6| Step: 6
Training loss: 0.49524933099746704
Validation loss: 1.7837097721715127

Epoch: 6| Step: 7
Training loss: 0.4703178107738495
Validation loss: 1.7483207320654264

Epoch: 6| Step: 8
Training loss: 0.34760603308677673
Validation loss: 1.76012239661268

Epoch: 6| Step: 9
Training loss: 0.3988141417503357
Validation loss: 1.7482803278071906

Epoch: 6| Step: 10
Training loss: 0.171357199549675
Validation loss: 1.772622549405662

Epoch: 6| Step: 11
Training loss: 0.6401175260543823
Validation loss: 1.7903222332718551

Epoch: 6| Step: 12
Training loss: 0.2694864273071289
Validation loss: 1.783988719345421

Epoch: 6| Step: 13
Training loss: 0.38792645931243896
Validation loss: 1.8052438164270053

Epoch: 273| Step: 0
Training loss: 0.39077842235565186
Validation loss: 1.838440901489668

Epoch: 6| Step: 1
Training loss: 0.5618048310279846
Validation loss: 1.8362749148440618

Epoch: 6| Step: 2
Training loss: 0.28446879982948303
Validation loss: 1.871550489497441

Epoch: 6| Step: 3
Training loss: 0.13617286086082458
Validation loss: 1.8230831033440047

Epoch: 6| Step: 4
Training loss: 0.28589117527008057
Validation loss: 1.7928729262403262

Epoch: 6| Step: 5
Training loss: 0.1724504828453064
Validation loss: 1.7863133748372395

Epoch: 6| Step: 6
Training loss: 0.28430312871932983
Validation loss: 1.7682228883107503

Epoch: 6| Step: 7
Training loss: 0.5089259147644043
Validation loss: 1.7512778261656403

Epoch: 6| Step: 8
Training loss: 0.6442734003067017
Validation loss: 1.7404669023329211

Epoch: 6| Step: 9
Training loss: 0.5205737352371216
Validation loss: 1.749925999231236

Epoch: 6| Step: 10
Training loss: 0.5414309501647949
Validation loss: 1.751970806429463

Epoch: 6| Step: 11
Training loss: 0.3016726076602936
Validation loss: 1.730343549482284

Epoch: 6| Step: 12
Training loss: 0.27895456552505493
Validation loss: 1.7307510427249375

Epoch: 6| Step: 13
Training loss: 0.35910385847091675
Validation loss: 1.7565432504941059

Epoch: 274| Step: 0
Training loss: 0.3502870202064514
Validation loss: 1.766431882817258

Epoch: 6| Step: 1
Training loss: 0.392196387052536
Validation loss: 1.796467436257229

Epoch: 6| Step: 2
Training loss: 0.287155419588089
Validation loss: 1.820082523489511

Epoch: 6| Step: 3
Training loss: 0.3130200505256653
Validation loss: 1.8049302639499787

Epoch: 6| Step: 4
Training loss: 0.3126799166202545
Validation loss: 1.77983057883478

Epoch: 6| Step: 5
Training loss: 0.4986826777458191
Validation loss: 1.8236060219426309

Epoch: 6| Step: 6
Training loss: 0.340576171875
Validation loss: 1.7887978092316659

Epoch: 6| Step: 7
Training loss: 0.29890474677085876
Validation loss: 1.7968309822902884

Epoch: 6| Step: 8
Training loss: 0.45074957609176636
Validation loss: 1.795156705764032

Epoch: 6| Step: 9
Training loss: 0.38701725006103516
Validation loss: 1.7805761829499276

Epoch: 6| Step: 10
Training loss: 0.28209954500198364
Validation loss: 1.7926716484049314

Epoch: 6| Step: 11
Training loss: 0.738194465637207
Validation loss: 1.8026223887679398

Epoch: 6| Step: 12
Training loss: 0.34109535813331604
Validation loss: 1.8123770067768712

Epoch: 6| Step: 13
Training loss: 0.28033554553985596
Validation loss: 1.8275157302938483

Epoch: 275| Step: 0
Training loss: 0.5197336673736572
Validation loss: 1.8596089962990052

Epoch: 6| Step: 1
Training loss: 0.8440374135971069
Validation loss: 1.845550734509704

Epoch: 6| Step: 2
Training loss: 0.35161930322647095
Validation loss: 1.8305257930550525

Epoch: 6| Step: 3
Training loss: 0.4236568808555603
Validation loss: 1.8093623922717186

Epoch: 6| Step: 4
Training loss: 0.21234750747680664
Validation loss: 1.7764185141491633

Epoch: 6| Step: 5
Training loss: 0.5458304286003113
Validation loss: 1.771052469489395

Epoch: 6| Step: 6
Training loss: 0.3571293354034424
Validation loss: 1.7696274429239252

Epoch: 6| Step: 7
Training loss: 0.33154162764549255
Validation loss: 1.7681641732492754

Epoch: 6| Step: 8
Training loss: 0.21626977622509003
Validation loss: 1.7564827472932878

Epoch: 6| Step: 9
Training loss: 0.4034062623977661
Validation loss: 1.7520785562453731

Epoch: 6| Step: 10
Training loss: 0.28200438618659973
Validation loss: 1.7999862304297827

Epoch: 6| Step: 11
Training loss: 0.616901159286499
Validation loss: 1.7421406469037455

Epoch: 6| Step: 12
Training loss: 0.19632980227470398
Validation loss: 1.75428815298183

Epoch: 6| Step: 13
Training loss: 0.17337757349014282
Validation loss: 1.7579840985677575

Epoch: 276| Step: 0
Training loss: 0.2362290322780609
Validation loss: 1.7464702526728313

Epoch: 6| Step: 1
Training loss: 0.2608160674571991
Validation loss: 1.7470988355657107

Epoch: 6| Step: 2
Training loss: 0.2198447287082672
Validation loss: 1.7664698657169138

Epoch: 6| Step: 3
Training loss: 0.30523568391799927
Validation loss: 1.7499999384726248

Epoch: 6| Step: 4
Training loss: 0.4784567952156067
Validation loss: 1.742778967785579

Epoch: 6| Step: 5
Training loss: 0.6940990686416626
Validation loss: 1.7165213836136686

Epoch: 6| Step: 6
Training loss: 0.2742517590522766
Validation loss: 1.7432885067437285

Epoch: 6| Step: 7
Training loss: 0.2980119585990906
Validation loss: 1.7541773806336105

Epoch: 6| Step: 8
Training loss: 0.32490259408950806
Validation loss: 1.7476549174195977

Epoch: 6| Step: 9
Training loss: 0.3517458736896515
Validation loss: 1.7622887460134362

Epoch: 6| Step: 10
Training loss: 0.6166703701019287
Validation loss: 1.7305454502823532

Epoch: 6| Step: 11
Training loss: 0.6092841625213623
Validation loss: 1.758330709190779

Epoch: 6| Step: 12
Training loss: 0.23456206917762756
Validation loss: 1.7857877874887118

Epoch: 6| Step: 13
Training loss: 0.4558066725730896
Validation loss: 1.7747831036967616

Epoch: 277| Step: 0
Training loss: 0.378994882106781
Validation loss: 1.7852674722671509

Epoch: 6| Step: 1
Training loss: 0.42454642057418823
Validation loss: 1.8051727689722532

Epoch: 6| Step: 2
Training loss: 0.24080890417099
Validation loss: 1.7566646529782204

Epoch: 6| Step: 3
Training loss: 0.456216037273407
Validation loss: 1.7766756011593727

Epoch: 6| Step: 4
Training loss: 0.3867694139480591
Validation loss: 1.7549414493704354

Epoch: 6| Step: 5
Training loss: 0.4628291130065918
Validation loss: 1.7685143742510068

Epoch: 6| Step: 6
Training loss: 0.38514700531959534
Validation loss: 1.7574088240182528

Epoch: 6| Step: 7
Training loss: 0.3710145354270935
Validation loss: 1.7736471365856867

Epoch: 6| Step: 8
Training loss: 0.33994260430336
Validation loss: 1.7565225721687399

Epoch: 6| Step: 9
Training loss: 0.3183208107948303
Validation loss: 1.776686063376806

Epoch: 6| Step: 10
Training loss: 0.25696808099746704
Validation loss: 1.7632161615997233

Epoch: 6| Step: 11
Training loss: 0.5458303093910217
Validation loss: 1.7385664242570118

Epoch: 6| Step: 12
Training loss: 0.32740291953086853
Validation loss: 1.7765383143578806

Epoch: 6| Step: 13
Training loss: 0.2804677486419678
Validation loss: 1.7453302952551073

Epoch: 278| Step: 0
Training loss: 0.12055978178977966
Validation loss: 1.7845367923859627

Epoch: 6| Step: 1
Training loss: 0.4788978695869446
Validation loss: 1.8393660053130119

Epoch: 6| Step: 2
Training loss: 0.3642408847808838
Validation loss: 1.8415061760974187

Epoch: 6| Step: 3
Training loss: 0.433420866727829
Validation loss: 1.8638450907122703

Epoch: 6| Step: 4
Training loss: 0.45062804222106934
Validation loss: 1.8416964725781513

Epoch: 6| Step: 5
Training loss: 0.24973352253437042
Validation loss: 1.7946598234997

Epoch: 6| Step: 6
Training loss: 0.5133031010627747
Validation loss: 1.7729797350463046

Epoch: 6| Step: 7
Training loss: 0.2562200129032135
Validation loss: 1.7440484877555602

Epoch: 6| Step: 8
Training loss: 0.506821870803833
Validation loss: 1.7739053349341116

Epoch: 6| Step: 9
Training loss: 0.27794161438941956
Validation loss: 1.7705432830318328

Epoch: 6| Step: 10
Training loss: 0.3308505415916443
Validation loss: 1.7644476070198962

Epoch: 6| Step: 11
Training loss: 0.2791516184806824
Validation loss: 1.7653988689504645

Epoch: 6| Step: 12
Training loss: 0.5921216607093811
Validation loss: 1.7638580927284815

Epoch: 6| Step: 13
Training loss: 0.5111294984817505
Validation loss: 1.771738306168587

Epoch: 279| Step: 0
Training loss: 0.3310655951499939
Validation loss: 1.7721314225145566

Epoch: 6| Step: 1
Training loss: 0.5886656045913696
Validation loss: 1.8113038386068037

Epoch: 6| Step: 2
Training loss: 0.7716449499130249
Validation loss: 1.7707984460297452

Epoch: 6| Step: 3
Training loss: 0.31080156564712524
Validation loss: 1.805628635550058

Epoch: 6| Step: 4
Training loss: 0.30122172832489014
Validation loss: 1.791504700978597

Epoch: 6| Step: 5
Training loss: 0.2262616604566574
Validation loss: 1.819112661064312

Epoch: 6| Step: 6
Training loss: 0.35951513051986694
Validation loss: 1.8131558741292646

Epoch: 6| Step: 7
Training loss: 0.3619263172149658
Validation loss: 1.8053010535496536

Epoch: 6| Step: 8
Training loss: 0.26411715149879456
Validation loss: 1.828815180768249

Epoch: 6| Step: 9
Training loss: 0.33842670917510986
Validation loss: 1.8230835853084442

Epoch: 6| Step: 10
Training loss: 0.4299297332763672
Validation loss: 1.8406724417081444

Epoch: 6| Step: 11
Training loss: 0.19504697620868683
Validation loss: 1.8188283187086864

Epoch: 6| Step: 12
Training loss: 0.378060907125473
Validation loss: 1.8013120107753302

Epoch: 6| Step: 13
Training loss: 0.18411679565906525
Validation loss: 1.7956040943822553

Epoch: 280| Step: 0
Training loss: 0.3576843738555908
Validation loss: 1.764042797908988

Epoch: 6| Step: 1
Training loss: 0.3319850564002991
Validation loss: 1.7952875552638885

Epoch: 6| Step: 2
Training loss: 0.23867657780647278
Validation loss: 1.769483197119928

Epoch: 6| Step: 3
Training loss: 0.3972143530845642
Validation loss: 1.7719354488516366

Epoch: 6| Step: 4
Training loss: 0.6222221851348877
Validation loss: 1.7824890844283565

Epoch: 6| Step: 5
Training loss: 0.2652091681957245
Validation loss: 1.7735761160491614

Epoch: 6| Step: 6
Training loss: 0.4407215118408203
Validation loss: 1.7745969410865539

Epoch: 6| Step: 7
Training loss: 0.22491121292114258
Validation loss: 1.7630416757317

Epoch: 6| Step: 8
Training loss: 0.6411409378051758
Validation loss: 1.7601939337227934

Epoch: 6| Step: 9
Training loss: 0.5933719873428345
Validation loss: 1.7959508229327459

Epoch: 6| Step: 10
Training loss: 0.2648220956325531
Validation loss: 1.8107401401765886

Epoch: 6| Step: 11
Training loss: 0.3447093963623047
Validation loss: 1.7587483057411768

Epoch: 6| Step: 12
Training loss: 0.17878279089927673
Validation loss: 1.7923578511002243

Epoch: 6| Step: 13
Training loss: 0.2596094608306885
Validation loss: 1.7643376294002737

Epoch: 281| Step: 0
Training loss: 0.33710622787475586
Validation loss: 1.7444805035027124

Epoch: 6| Step: 1
Training loss: 0.26258158683776855
Validation loss: 1.7260913848876953

Epoch: 6| Step: 2
Training loss: 0.3593115210533142
Validation loss: 1.7569442654168734

Epoch: 6| Step: 3
Training loss: 0.27337244153022766
Validation loss: 1.7564064302752096

Epoch: 6| Step: 4
Training loss: 0.6231128573417664
Validation loss: 1.754458906829998

Epoch: 6| Step: 5
Training loss: 0.16304165124893188
Validation loss: 1.7700598855172434

Epoch: 6| Step: 6
Training loss: 0.32042989134788513
Validation loss: 1.77408278629344

Epoch: 6| Step: 7
Training loss: 0.4001438617706299
Validation loss: 1.7368261224480086

Epoch: 6| Step: 8
Training loss: 0.4715993106365204
Validation loss: 1.743403548194516

Epoch: 6| Step: 9
Training loss: 0.302366703748703
Validation loss: 1.7281351063841133

Epoch: 6| Step: 10
Training loss: 0.506842851638794
Validation loss: 1.7165547981057117

Epoch: 6| Step: 11
Training loss: 0.19184820353984833
Validation loss: 1.7026762013794274

Epoch: 6| Step: 12
Training loss: 0.22735321521759033
Validation loss: 1.7204182135161532

Epoch: 6| Step: 13
Training loss: 0.2530035078525543
Validation loss: 1.7111915901143064

Epoch: 282| Step: 0
Training loss: 0.1989985704421997
Validation loss: 1.7671392156231789

Epoch: 6| Step: 1
Training loss: 0.4601294994354248
Validation loss: 1.766843358675639

Epoch: 6| Step: 2
Training loss: 0.32325172424316406
Validation loss: 1.8132366057365172

Epoch: 6| Step: 3
Training loss: 0.35611361265182495
Validation loss: 1.8403564140360842

Epoch: 6| Step: 4
Training loss: 0.374021977186203
Validation loss: 1.8005558906062957

Epoch: 6| Step: 5
Training loss: 0.4287681579589844
Validation loss: 1.7955740805595153

Epoch: 6| Step: 6
Training loss: 0.42204388976097107
Validation loss: 1.7572702233509352

Epoch: 6| Step: 7
Training loss: 0.2723029851913452
Validation loss: 1.71363486654015

Epoch: 6| Step: 8
Training loss: 0.30354270339012146
Validation loss: 1.6795836655042504

Epoch: 6| Step: 9
Training loss: 0.32987546920776367
Validation loss: 1.6896109568175448

Epoch: 6| Step: 10
Training loss: 0.2144596427679062
Validation loss: 1.6849714081774476

Epoch: 6| Step: 11
Training loss: 0.4479901194572449
Validation loss: 1.7263130193115563

Epoch: 6| Step: 12
Training loss: 0.4460930824279785
Validation loss: 1.7296503538726478

Epoch: 6| Step: 13
Training loss: 0.6487501859664917
Validation loss: 1.71441376081077

Epoch: 283| Step: 0
Training loss: 0.36173754930496216
Validation loss: 1.7187091522319342

Epoch: 6| Step: 1
Training loss: 0.3621603846549988
Validation loss: 1.7464316160448137

Epoch: 6| Step: 2
Training loss: 0.31089162826538086
Validation loss: 1.78305987645221

Epoch: 6| Step: 3
Training loss: 0.16632720828056335
Validation loss: 1.7561832192123576

Epoch: 6| Step: 4
Training loss: 0.5395216941833496
Validation loss: 1.794955712492748

Epoch: 6| Step: 5
Training loss: 0.4396195411682129
Validation loss: 1.8314257591001448

Epoch: 6| Step: 6
Training loss: 0.5664001703262329
Validation loss: 1.8158387496907225

Epoch: 6| Step: 7
Training loss: 0.41229385137557983
Validation loss: 1.8154128892447359

Epoch: 6| Step: 8
Training loss: 0.4848253130912781
Validation loss: 1.7723095045294812

Epoch: 6| Step: 9
Training loss: 0.2056117206811905
Validation loss: 1.7509243283220517

Epoch: 6| Step: 10
Training loss: 0.26151371002197266
Validation loss: 1.7268215533225768

Epoch: 6| Step: 11
Training loss: 0.3562299609184265
Validation loss: 1.7659808538293327

Epoch: 6| Step: 12
Training loss: 0.3125549256801605
Validation loss: 1.7735875409136537

Epoch: 6| Step: 13
Training loss: 0.21657238900661469
Validation loss: 1.7608347374905822

Epoch: 284| Step: 0
Training loss: 0.5300235748291016
Validation loss: 1.7310655604126632

Epoch: 6| Step: 1
Training loss: 0.4258618950843811
Validation loss: 1.7709676732299149

Epoch: 6| Step: 2
Training loss: 0.3929387927055359
Validation loss: 1.8045349313366799

Epoch: 6| Step: 3
Training loss: 0.48055553436279297
Validation loss: 1.824211097532703

Epoch: 6| Step: 4
Training loss: 0.26526594161987305
Validation loss: 1.7926893580344416

Epoch: 6| Step: 5
Training loss: 0.30401700735092163
Validation loss: 1.7969785274997834

Epoch: 6| Step: 6
Training loss: 0.31288179755210876
Validation loss: 1.7865654653118503

Epoch: 6| Step: 7
Training loss: 0.27078455686569214
Validation loss: 1.790676571989572

Epoch: 6| Step: 8
Training loss: 0.3458072543144226
Validation loss: 1.7966347830269926

Epoch: 6| Step: 9
Training loss: 0.4114333987236023
Validation loss: 1.789408104394072

Epoch: 6| Step: 10
Training loss: 0.2219323217868805
Validation loss: 1.7648517624024422

Epoch: 6| Step: 11
Training loss: 0.23903220891952515
Validation loss: 1.7469301544209963

Epoch: 6| Step: 12
Training loss: 0.16871100664138794
Validation loss: 1.747676754510531

Epoch: 6| Step: 13
Training loss: 0.4670044481754303
Validation loss: 1.7380413355365876

Epoch: 285| Step: 0
Training loss: 0.2133921980857849
Validation loss: 1.7244300983285392

Epoch: 6| Step: 1
Training loss: 0.2332426905632019
Validation loss: 1.7454347584837226

Epoch: 6| Step: 2
Training loss: 0.38900965452194214
Validation loss: 1.747108168499444

Epoch: 6| Step: 3
Training loss: 0.17846475541591644
Validation loss: 1.7368254456468808

Epoch: 6| Step: 4
Training loss: 0.4450913667678833
Validation loss: 1.7208013239727225

Epoch: 6| Step: 5
Training loss: 0.4745737612247467
Validation loss: 1.746670401224526

Epoch: 6| Step: 6
Training loss: 0.3970670700073242
Validation loss: 1.7645474069861955

Epoch: 6| Step: 7
Training loss: 0.36895692348480225
Validation loss: 1.7660775684541272

Epoch: 6| Step: 8
Training loss: 0.27619263529777527
Validation loss: 1.760142699364693

Epoch: 6| Step: 9
Training loss: 0.27590441703796387
Validation loss: 1.7693777955988401

Epoch: 6| Step: 10
Training loss: 0.253949373960495
Validation loss: 1.7767480573346537

Epoch: 6| Step: 11
Training loss: 0.4619114398956299
Validation loss: 1.7846866371811076

Epoch: 6| Step: 12
Training loss: 0.41330212354660034
Validation loss: 1.7824780171917332

Epoch: 6| Step: 13
Training loss: 0.3210630714893341
Validation loss: 1.7828057863379037

Epoch: 286| Step: 0
Training loss: 0.2568223774433136
Validation loss: 1.7465087854734032

Epoch: 6| Step: 1
Training loss: 0.2554696500301361
Validation loss: 1.7685224343371648

Epoch: 6| Step: 2
Training loss: 0.46288514137268066
Validation loss: 1.7654724915822346

Epoch: 6| Step: 3
Training loss: 0.3009669780731201
Validation loss: 1.755608267681573

Epoch: 6| Step: 4
Training loss: 0.40050479769706726
Validation loss: 1.7768024552252986

Epoch: 6| Step: 5
Training loss: 0.29472553730010986
Validation loss: 1.7798156571644608

Epoch: 6| Step: 6
Training loss: 0.2019265741109848
Validation loss: 1.7835728635070145

Epoch: 6| Step: 7
Training loss: 0.3536858856678009
Validation loss: 1.7825842224141604

Epoch: 6| Step: 8
Training loss: 0.42469659447669983
Validation loss: 1.7643017486859394

Epoch: 6| Step: 9
Training loss: 0.4916263520717621
Validation loss: 1.7527349777119134

Epoch: 6| Step: 10
Training loss: 0.487185537815094
Validation loss: 1.751012045850036

Epoch: 6| Step: 11
Training loss: 0.399445503950119
Validation loss: 1.774064105044129

Epoch: 6| Step: 12
Training loss: 0.26127952337265015
Validation loss: 1.8046034356599212

Epoch: 6| Step: 13
Training loss: 0.1818711757659912
Validation loss: 1.803729377767091

Epoch: 287| Step: 0
Training loss: 0.2504824995994568
Validation loss: 1.8614062468210857

Epoch: 6| Step: 1
Training loss: 0.4941695034503937
Validation loss: 1.8865473360143683

Epoch: 6| Step: 2
Training loss: 0.31598374247550964
Validation loss: 1.8126068281871017

Epoch: 6| Step: 3
Training loss: 0.31199419498443604
Validation loss: 1.7748750076499036

Epoch: 6| Step: 4
Training loss: 0.33389976620674133
Validation loss: 1.7440775363676009

Epoch: 6| Step: 5
Training loss: 0.497356653213501
Validation loss: 1.7469554075630762

Epoch: 6| Step: 6
Training loss: 0.5328303575515747
Validation loss: 1.7537223690299577

Epoch: 6| Step: 7
Training loss: 0.3404201865196228
Validation loss: 1.7359684680097847

Epoch: 6| Step: 8
Training loss: 0.2412312626838684
Validation loss: 1.7577005483770882

Epoch: 6| Step: 9
Training loss: 0.3510136604309082
Validation loss: 1.7423420029301797

Epoch: 6| Step: 10
Training loss: 0.45815083384513855
Validation loss: 1.773183734186234

Epoch: 6| Step: 11
Training loss: 0.2715810239315033
Validation loss: 1.7668430356569187

Epoch: 6| Step: 12
Training loss: 0.4390413463115692
Validation loss: 1.7830684223482687

Epoch: 6| Step: 13
Training loss: 0.2406574934720993
Validation loss: 1.7922005268835253

Epoch: 288| Step: 0
Training loss: 0.359136164188385
Validation loss: 1.7927630627027122

Epoch: 6| Step: 1
Training loss: 0.2754642069339752
Validation loss: 1.784469791637954

Epoch: 6| Step: 2
Training loss: 0.5460508465766907
Validation loss: 1.7985397769558815

Epoch: 6| Step: 3
Training loss: 0.36018937826156616
Validation loss: 1.7789806012184388

Epoch: 6| Step: 4
Training loss: 0.27192115783691406
Validation loss: 1.7729773944424045

Epoch: 6| Step: 5
Training loss: 0.3173612356185913
Validation loss: 1.757464273001558

Epoch: 6| Step: 6
Training loss: 0.2918376922607422
Validation loss: 1.7588967764249412

Epoch: 6| Step: 7
Training loss: 0.2785748243331909
Validation loss: 1.7580530117916804

Epoch: 6| Step: 8
Training loss: 0.19137585163116455
Validation loss: 1.7380994930062243

Epoch: 6| Step: 9
Training loss: 0.4442368447780609
Validation loss: 1.7477182918979275

Epoch: 6| Step: 10
Training loss: 0.33697712421417236
Validation loss: 1.7775779821539437

Epoch: 6| Step: 11
Training loss: 0.4372403025627136
Validation loss: 1.7250886271076817

Epoch: 6| Step: 12
Training loss: 0.19077788293361664
Validation loss: 1.7619450092315674

Epoch: 6| Step: 13
Training loss: 0.2250026911497116
Validation loss: 1.7520920025405062

Epoch: 289| Step: 0
Training loss: 0.1950404942035675
Validation loss: 1.75475319867493

Epoch: 6| Step: 1
Training loss: 0.24766729772090912
Validation loss: 1.774320976708525

Epoch: 6| Step: 2
Training loss: 0.39802616834640503
Validation loss: 1.771854003270467

Epoch: 6| Step: 3
Training loss: 0.24560844898223877
Validation loss: 1.771386928455804

Epoch: 6| Step: 4
Training loss: 0.4382511079311371
Validation loss: 1.7509330344456497

Epoch: 6| Step: 5
Training loss: 0.17982986569404602
Validation loss: 1.7381052586340136

Epoch: 6| Step: 6
Training loss: 0.42462408542633057
Validation loss: 1.7379412945880686

Epoch: 6| Step: 7
Training loss: 0.24480819702148438
Validation loss: 1.7626180789803947

Epoch: 6| Step: 8
Training loss: 0.37698328495025635
Validation loss: 1.7638499813695108

Epoch: 6| Step: 9
Training loss: 0.3862532675266266
Validation loss: 1.7521508188657864

Epoch: 6| Step: 10
Training loss: 0.208184614777565
Validation loss: 1.7422656807848202

Epoch: 6| Step: 11
Training loss: 0.27327674627304077
Validation loss: 1.7070125610597673

Epoch: 6| Step: 12
Training loss: 0.36981093883514404
Validation loss: 1.7352298741699548

Epoch: 6| Step: 13
Training loss: 0.4254867434501648
Validation loss: 1.7466325195886756

Epoch: 290| Step: 0
Training loss: 0.3774890601634979
Validation loss: 1.7156495727518553

Epoch: 6| Step: 1
Training loss: 0.41685399413108826
Validation loss: 1.6726069719560686

Epoch: 6| Step: 2
Training loss: 0.2673928439617157
Validation loss: 1.6960309192698488

Epoch: 6| Step: 3
Training loss: 0.17959526181221008
Validation loss: 1.6573448437516407

Epoch: 6| Step: 4
Training loss: 0.22716742753982544
Validation loss: 1.707733969534597

Epoch: 6| Step: 5
Training loss: 0.3435306251049042
Validation loss: 1.6870410801261984

Epoch: 6| Step: 6
Training loss: 0.3837738633155823
Validation loss: 1.7086362422153514

Epoch: 6| Step: 7
Training loss: 0.2733115553855896
Validation loss: 1.730933811074944

Epoch: 6| Step: 8
Training loss: 0.36146995425224304
Validation loss: 1.7394417537155973

Epoch: 6| Step: 9
Training loss: 0.5439079999923706
Validation loss: 1.7470131247274336

Epoch: 6| Step: 10
Training loss: 0.21528509259223938
Validation loss: 1.7240838209788005

Epoch: 6| Step: 11
Training loss: 0.3426458239555359
Validation loss: 1.710430024772562

Epoch: 6| Step: 12
Training loss: 0.5378916263580322
Validation loss: 1.6928831479882682

Epoch: 6| Step: 13
Training loss: 0.13210488855838776
Validation loss: 1.713495175043742

Epoch: 291| Step: 0
Training loss: 0.5802538394927979
Validation loss: 1.7000803306538572

Epoch: 6| Step: 1
Training loss: 0.3780291676521301
Validation loss: 1.7096360037403722

Epoch: 6| Step: 2
Training loss: 0.3487723469734192
Validation loss: 1.7165573143189954

Epoch: 6| Step: 3
Training loss: 0.3294423222541809
Validation loss: 1.7277879356056132

Epoch: 6| Step: 4
Training loss: 0.30205288529396057
Validation loss: 1.7495596357571181

Epoch: 6| Step: 5
Training loss: 0.27268239855766296
Validation loss: 1.7821811206879155

Epoch: 6| Step: 6
Training loss: 0.16826364398002625
Validation loss: 1.742982954107305

Epoch: 6| Step: 7
Training loss: 0.1619432270526886
Validation loss: 1.7758396581936908

Epoch: 6| Step: 8
Training loss: 0.32528650760650635
Validation loss: 1.7547309321741904

Epoch: 6| Step: 9
Training loss: 0.2002076953649521
Validation loss: 1.7381050291881766

Epoch: 6| Step: 10
Training loss: 0.361181378364563
Validation loss: 1.7552600958014046

Epoch: 6| Step: 11
Training loss: 0.39251837134361267
Validation loss: 1.7446126425138084

Epoch: 6| Step: 12
Training loss: 0.27760517597198486
Validation loss: 1.7539804494509132

Epoch: 6| Step: 13
Training loss: 0.2930706739425659
Validation loss: 1.7486979884486045

Epoch: 292| Step: 0
Training loss: 0.43328484892845154
Validation loss: 1.7690108732510639

Epoch: 6| Step: 1
Training loss: 0.20679277181625366
Validation loss: 1.785035410235005

Epoch: 6| Step: 2
Training loss: 0.340237021446228
Validation loss: 1.8028856490247993

Epoch: 6| Step: 3
Training loss: 0.5910767912864685
Validation loss: 1.7964323246350853

Epoch: 6| Step: 4
Training loss: 0.34581100940704346
Validation loss: 1.7581618434639388

Epoch: 6| Step: 5
Training loss: 0.22310329973697662
Validation loss: 1.7100909089529386

Epoch: 6| Step: 6
Training loss: 0.2641473114490509
Validation loss: 1.7209222957652102

Epoch: 6| Step: 7
Training loss: 0.12082644551992416
Validation loss: 1.691752040258018

Epoch: 6| Step: 8
Training loss: 0.28716805577278137
Validation loss: 1.6965549774067377

Epoch: 6| Step: 9
Training loss: 0.29477715492248535
Validation loss: 1.747695961306172

Epoch: 6| Step: 10
Training loss: 0.36416345834732056
Validation loss: 1.7315647909718175

Epoch: 6| Step: 11
Training loss: 0.5331432223320007
Validation loss: 1.754509597696284

Epoch: 6| Step: 12
Training loss: 0.29197779297828674
Validation loss: 1.7277591920668078

Epoch: 6| Step: 13
Training loss: 0.1484045386314392
Validation loss: 1.7110439756865143

Epoch: 293| Step: 0
Training loss: 0.189801424741745
Validation loss: 1.6999197698408557

Epoch: 6| Step: 1
Training loss: 0.2147633284330368
Validation loss: 1.6836064720666537

Epoch: 6| Step: 2
Training loss: 0.2830202579498291
Validation loss: 1.6833722463218115

Epoch: 6| Step: 3
Training loss: 0.2185252457857132
Validation loss: 1.6663321179728354

Epoch: 6| Step: 4
Training loss: 0.3738880157470703
Validation loss: 1.6728309944111814

Epoch: 6| Step: 5
Training loss: 0.2622902989387512
Validation loss: 1.7001810548126057

Epoch: 6| Step: 6
Training loss: 0.292969673871994
Validation loss: 1.7224542569088679

Epoch: 6| Step: 7
Training loss: 0.09497503936290741
Validation loss: 1.7177590131759644

Epoch: 6| Step: 8
Training loss: 0.39545875787734985
Validation loss: 1.7417967242579306

Epoch: 6| Step: 9
Training loss: 0.3182833790779114
Validation loss: 1.70652191100582

Epoch: 6| Step: 10
Training loss: 0.5497902631759644
Validation loss: 1.696098300718492

Epoch: 6| Step: 11
Training loss: 0.4048956036567688
Validation loss: 1.731280985698905

Epoch: 6| Step: 12
Training loss: 0.4001789093017578
Validation loss: 1.7587843736012776

Epoch: 6| Step: 13
Training loss: 0.30286940932273865
Validation loss: 1.7137762551666589

Epoch: 294| Step: 0
Training loss: 0.2170642614364624
Validation loss: 1.7878838508359847

Epoch: 6| Step: 1
Training loss: 0.22948554158210754
Validation loss: 1.7354173327005038

Epoch: 6| Step: 2
Training loss: 0.2622740864753723
Validation loss: 1.727487503841359

Epoch: 6| Step: 3
Training loss: 0.1507388949394226
Validation loss: 1.7383678946443784

Epoch: 6| Step: 4
Training loss: 0.4181332588195801
Validation loss: 1.6895456583269182

Epoch: 6| Step: 5
Training loss: 0.5325978994369507
Validation loss: 1.7317926550424227

Epoch: 6| Step: 6
Training loss: 0.463664174079895
Validation loss: 1.7390684286753337

Epoch: 6| Step: 7
Training loss: 0.21811625361442566
Validation loss: 1.7152229188590922

Epoch: 6| Step: 8
Training loss: 0.3615451455116272
Validation loss: 1.7405123153040487

Epoch: 6| Step: 9
Training loss: 0.16659164428710938
Validation loss: 1.7034739037995696

Epoch: 6| Step: 10
Training loss: 0.23284421861171722
Validation loss: 1.7516113788850847

Epoch: 6| Step: 11
Training loss: 0.3581593632698059
Validation loss: 1.7505748835943078

Epoch: 6| Step: 12
Training loss: 0.2626093029975891
Validation loss: 1.7552888829221007

Epoch: 6| Step: 13
Training loss: 0.11359771341085434
Validation loss: 1.7135440008614653

Epoch: 295| Step: 0
Training loss: 0.19992810487747192
Validation loss: 1.7403838390945106

Epoch: 6| Step: 1
Training loss: 0.30642274022102356
Validation loss: 1.7049420110640987

Epoch: 6| Step: 2
Training loss: 0.30739060044288635
Validation loss: 1.7286675527531614

Epoch: 6| Step: 3
Training loss: 0.2816489040851593
Validation loss: 1.7414171106071883

Epoch: 6| Step: 4
Training loss: 0.26691734790802
Validation loss: 1.7462352527085172

Epoch: 6| Step: 5
Training loss: 0.4300413727760315
Validation loss: 1.8026637005549606

Epoch: 6| Step: 6
Training loss: 0.37526485323905945
Validation loss: 1.8200599531973563

Epoch: 6| Step: 7
Training loss: 0.7397476434707642
Validation loss: 1.8198796292786956

Epoch: 6| Step: 8
Training loss: 0.4767758548259735
Validation loss: 1.795204072870234

Epoch: 6| Step: 9
Training loss: 0.3081478476524353
Validation loss: 1.7956254982179212

Epoch: 6| Step: 10
Training loss: 0.31588393449783325
Validation loss: 1.7488989253197946

Epoch: 6| Step: 11
Training loss: 0.15293151140213013
Validation loss: 1.7252014048637883

Epoch: 6| Step: 12
Training loss: 0.2563491463661194
Validation loss: 1.6931130732259443

Epoch: 6| Step: 13
Training loss: 0.2778365910053253
Validation loss: 1.7025921485757316

Epoch: 296| Step: 0
Training loss: 0.3837987184524536
Validation loss: 1.7021509011586506

Epoch: 6| Step: 1
Training loss: 0.2362441122531891
Validation loss: 1.7191685143337454

Epoch: 6| Step: 2
Training loss: 0.17985406517982483
Validation loss: 1.6953987024163688

Epoch: 6| Step: 3
Training loss: 0.44588595628738403
Validation loss: 1.7098718074060255

Epoch: 6| Step: 4
Training loss: 0.21725362539291382
Validation loss: 1.720017425475582

Epoch: 6| Step: 5
Training loss: 0.32574355602264404
Validation loss: 1.6919371043482134

Epoch: 6| Step: 6
Training loss: 0.366644948720932
Validation loss: 1.723262317718998

Epoch: 6| Step: 7
Training loss: 0.384784072637558
Validation loss: 1.7188143781436387

Epoch: 6| Step: 8
Training loss: 0.5497080683708191
Validation loss: 1.6955251437361523

Epoch: 6| Step: 9
Training loss: 0.14558422565460205
Validation loss: 1.6988138229616228

Epoch: 6| Step: 10
Training loss: 0.19490233063697815
Validation loss: 1.669431951738173

Epoch: 6| Step: 11
Training loss: 0.41789788007736206
Validation loss: 1.6918875222565026

Epoch: 6| Step: 12
Training loss: 0.2087479531764984
Validation loss: 1.7005942790738997

Epoch: 6| Step: 13
Training loss: 0.24905450642108917
Validation loss: 1.71501592282326

Epoch: 297| Step: 0
Training loss: 0.2380884885787964
Validation loss: 1.6972520312955302

Epoch: 6| Step: 1
Training loss: 0.4822167158126831
Validation loss: 1.7067230260500343

Epoch: 6| Step: 2
Training loss: 0.24542105197906494
Validation loss: 1.7270928941747195

Epoch: 6| Step: 3
Training loss: 0.37741222977638245
Validation loss: 1.7187439626263035

Epoch: 6| Step: 4
Training loss: 0.22688736021518707
Validation loss: 1.7190951134568901

Epoch: 6| Step: 5
Training loss: 0.20818541944026947
Validation loss: 1.7255546444205827

Epoch: 6| Step: 6
Training loss: 0.36911702156066895
Validation loss: 1.6858817672216764

Epoch: 6| Step: 7
Training loss: 0.1626138985157013
Validation loss: 1.7030674654950377

Epoch: 6| Step: 8
Training loss: 0.28645196557044983
Validation loss: 1.6922567505990305

Epoch: 6| Step: 9
Training loss: 0.43654170632362366
Validation loss: 1.719822229877595

Epoch: 6| Step: 10
Training loss: 0.18017512559890747
Validation loss: 1.71668230846364

Epoch: 6| Step: 11
Training loss: 0.3377969264984131
Validation loss: 1.7048724992300874

Epoch: 6| Step: 12
Training loss: 0.39989084005355835
Validation loss: 1.717593749364217

Epoch: 6| Step: 13
Training loss: 0.1756235510110855
Validation loss: 1.736357242830338

Epoch: 298| Step: 0
Training loss: 0.24344545602798462
Validation loss: 1.7428931151666949

Epoch: 6| Step: 1
Training loss: 0.30498236417770386
Validation loss: 1.74102585546432

Epoch: 6| Step: 2
Training loss: 0.34516942501068115
Validation loss: 1.774003336506505

Epoch: 6| Step: 3
Training loss: 0.3296637237071991
Validation loss: 1.7240102201379754

Epoch: 6| Step: 4
Training loss: 0.3483172059059143
Validation loss: 1.7396283777811195

Epoch: 6| Step: 5
Training loss: 0.26589858531951904
Validation loss: 1.7043349999253468

Epoch: 6| Step: 6
Training loss: 0.40366870164871216
Validation loss: 1.6594261366833922

Epoch: 6| Step: 7
Training loss: 0.24532201886177063
Validation loss: 1.6871798487119778

Epoch: 6| Step: 8
Training loss: 0.179500013589859
Validation loss: 1.6953653456062399

Epoch: 6| Step: 9
Training loss: 0.22033126652240753
Validation loss: 1.6545844372882639

Epoch: 6| Step: 10
Training loss: 0.22888199985027313
Validation loss: 1.6616063335890412

Epoch: 6| Step: 11
Training loss: 0.27370327711105347
Validation loss: 1.664921417031237

Epoch: 6| Step: 12
Training loss: 0.5851226449012756
Validation loss: 1.6745554208755493

Epoch: 6| Step: 13
Training loss: 0.23560017347335815
Validation loss: 1.6892443356975433

Epoch: 299| Step: 0
Training loss: 0.3539845943450928
Validation loss: 1.6721844762884162

Epoch: 6| Step: 1
Training loss: 0.4240017235279083
Validation loss: 1.655984168411583

Epoch: 6| Step: 2
Training loss: 0.3903964161872864
Validation loss: 1.6757063955389044

Epoch: 6| Step: 3
Training loss: 0.19602571427822113
Validation loss: 1.7160025732491606

Epoch: 6| Step: 4
Training loss: 0.3770431876182556
Validation loss: 1.6730367842540945

Epoch: 6| Step: 5
Training loss: 0.2988373339176178
Validation loss: 1.6910892596808813

Epoch: 6| Step: 6
Training loss: 0.18693149089813232
Validation loss: 1.666435823645643

Epoch: 6| Step: 7
Training loss: 0.1855289191007614
Validation loss: 1.6716101669496106

Epoch: 6| Step: 8
Training loss: 0.38915586471557617
Validation loss: 1.7541314555752663

Epoch: 6| Step: 9
Training loss: 0.24484741687774658
Validation loss: 1.7200678266504759

Epoch: 6| Step: 10
Training loss: 0.3256877660751343
Validation loss: 1.7604206595369565

Epoch: 6| Step: 11
Training loss: 0.2908855080604553
Validation loss: 1.7908898809904694

Epoch: 6| Step: 12
Training loss: 0.22854602336883545
Validation loss: 1.7302722866817186

Epoch: 6| Step: 13
Training loss: 0.3028048872947693
Validation loss: 1.7140571904438797

Epoch: 300| Step: 0
Training loss: 0.2063043862581253
Validation loss: 1.6986893838451755

Epoch: 6| Step: 1
Training loss: 0.2439003735780716
Validation loss: 1.6997020603508077

Epoch: 6| Step: 2
Training loss: 0.22543765604496002
Validation loss: 1.7054763250453497

Epoch: 6| Step: 3
Training loss: 0.37678810954093933
Validation loss: 1.6989441674242738

Epoch: 6| Step: 4
Training loss: 0.2940315306186676
Validation loss: 1.709351945948857

Epoch: 6| Step: 5
Training loss: 0.30072250962257385
Validation loss: 1.7175322450617307

Epoch: 6| Step: 6
Training loss: 0.285668283700943
Validation loss: 1.7174425778850433

Epoch: 6| Step: 7
Training loss: 0.36530131101608276
Validation loss: 1.7467401232770694

Epoch: 6| Step: 8
Training loss: 0.23953841626644135
Validation loss: 1.7570088242971769

Epoch: 6| Step: 9
Training loss: 0.44767987728118896
Validation loss: 1.7518762106536536

Epoch: 6| Step: 10
Training loss: 0.2899165153503418
Validation loss: 1.7901941768584713

Epoch: 6| Step: 11
Training loss: 0.44464296102523804
Validation loss: 1.7503616386844265

Epoch: 6| Step: 12
Training loss: 0.272229939699173
Validation loss: 1.7493299681653258

Epoch: 6| Step: 13
Training loss: 0.22878974676132202
Validation loss: 1.763760611575137

Testing loss: 2.117988692389594
