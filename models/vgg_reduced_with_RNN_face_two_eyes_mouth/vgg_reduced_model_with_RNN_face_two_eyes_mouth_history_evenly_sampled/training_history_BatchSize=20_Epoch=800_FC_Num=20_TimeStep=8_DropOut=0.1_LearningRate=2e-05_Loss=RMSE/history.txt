Epoch: 1| Step: 0
Training loss: 5.422834064188183
Validation loss: 5.770646657294065

Epoch: 5| Step: 1
Training loss: 5.839811088955489
Validation loss: 5.74636495861206

Epoch: 5| Step: 2
Training loss: 5.4177937826605715
Validation loss: 5.721934199024571

Epoch: 5| Step: 3
Training loss: 5.853311315566053
Validation loss: 5.6951613833855665

Epoch: 5| Step: 4
Training loss: 5.333395758899289
Validation loss: 5.664844809407795

Epoch: 5| Step: 5
Training loss: 5.2867967719624165
Validation loss: 5.6303322861612

Epoch: 5| Step: 6
Training loss: 5.71993255895591
Validation loss: 5.592088438015287

Epoch: 5| Step: 7
Training loss: 5.803699024181151
Validation loss: 5.54557622170228

Epoch: 5| Step: 8
Training loss: 5.867966032630679
Validation loss: 5.4947193036205855

Epoch: 5| Step: 9
Training loss: 5.774570544900057
Validation loss: 5.43520331897938

Epoch: 5| Step: 10
Training loss: 5.743731191311696
Validation loss: 5.370388719153884

Epoch: 2| Step: 0
Training loss: 4.486358735474588
Validation loss: 5.297326861969852

Epoch: 5| Step: 1
Training loss: 4.8627458760286855
Validation loss: 5.2205194680404565

Epoch: 5| Step: 2
Training loss: 5.938650883012297
Validation loss: 5.135427633919995

Epoch: 5| Step: 3
Training loss: 4.844706976092992
Validation loss: 5.049970710528939

Epoch: 5| Step: 4
Training loss: 4.998192651254325
Validation loss: 4.959488745554791

Epoch: 5| Step: 5
Training loss: 4.759961774977102
Validation loss: 4.870697988266262

Epoch: 5| Step: 6
Training loss: 4.93941296568293
Validation loss: 4.780625121995321

Epoch: 5| Step: 7
Training loss: 5.743035120263337
Validation loss: 4.6952120196364415

Epoch: 5| Step: 8
Training loss: 4.627244147137343
Validation loss: 4.611132619779372

Epoch: 5| Step: 9
Training loss: 3.7571782391740283
Validation loss: 4.528778760138617

Epoch: 5| Step: 10
Training loss: 5.105581385939524
Validation loss: 4.4544111120618455

Epoch: 3| Step: 0
Training loss: 4.770829157709462
Validation loss: 4.390470467372824

Epoch: 5| Step: 1
Training loss: 3.199701182003371
Validation loss: 4.331009813764287

Epoch: 5| Step: 2
Training loss: 4.880522509883796
Validation loss: 4.278683783060353

Epoch: 5| Step: 3
Training loss: 4.6430016799059395
Validation loss: 4.23131247315722

Epoch: 5| Step: 4
Training loss: 4.576566984383472
Validation loss: 4.188797143901771

Epoch: 5| Step: 5
Training loss: 4.298964557623172
Validation loss: 4.147601885672805

Epoch: 5| Step: 6
Training loss: 4.952152192767508
Validation loss: 4.109141695294989

Epoch: 5| Step: 7
Training loss: 3.531089846599877
Validation loss: 4.06851350712498

Epoch: 5| Step: 8
Training loss: 4.397305981648336
Validation loss: 4.037344434362213

Epoch: 5| Step: 9
Training loss: 3.0562632367368168
Validation loss: 4.006269759511027

Epoch: 5| Step: 10
Training loss: 4.484785851987093
Validation loss: 3.976502885288419

Epoch: 4| Step: 0
Training loss: 4.648987912200686
Validation loss: 3.9268654618459444

Epoch: 5| Step: 1
Training loss: 4.325258703708243
Validation loss: 3.8901277967271883

Epoch: 5| Step: 2
Training loss: 4.257452321348377
Validation loss: 3.8641946182118074

Epoch: 5| Step: 3
Training loss: 4.935055477676925
Validation loss: 3.8310507527572444

Epoch: 5| Step: 4
Training loss: 4.032895720730591
Validation loss: 3.7967200322515873

Epoch: 5| Step: 5
Training loss: 3.988936980290244
Validation loss: 3.767120376218719

Epoch: 5| Step: 6
Training loss: 3.345276813771081
Validation loss: 3.7452335528528597

Epoch: 5| Step: 7
Training loss: 3.9844714583146437
Validation loss: 3.729042024099684

Epoch: 5| Step: 8
Training loss: 3.6014307622751023
Validation loss: 3.7057231544182567

Epoch: 5| Step: 9
Training loss: 2.9816261933850927
Validation loss: 3.686693944304037

Epoch: 5| Step: 10
Training loss: 3.040681148061606
Validation loss: 3.6642624690953673

Epoch: 5| Step: 0
Training loss: 3.6570574529076225
Validation loss: 3.63805130450986

Epoch: 5| Step: 1
Training loss: 3.8161987123313574
Validation loss: 3.5993852017467205

Epoch: 5| Step: 2
Training loss: 3.71565078970234
Validation loss: 3.573585148990692

Epoch: 5| Step: 3
Training loss: 2.9758399226502856
Validation loss: 3.5628890116768885

Epoch: 5| Step: 4
Training loss: 4.208220955635552
Validation loss: 3.5364452922845855

Epoch: 5| Step: 5
Training loss: 3.442750423633864
Validation loss: 3.510360412546151

Epoch: 5| Step: 6
Training loss: 3.936845755340533
Validation loss: 3.4957542420948964

Epoch: 5| Step: 7
Training loss: 4.298250623195418
Validation loss: 3.4736391226394727

Epoch: 5| Step: 8
Training loss: 3.452894522453722
Validation loss: 3.4429489219720772

Epoch: 5| Step: 9
Training loss: 3.7828537243468308
Validation loss: 3.428936202563662

Epoch: 5| Step: 10
Training loss: 3.4640692669944757
Validation loss: 3.4118803841436898

Epoch: 6| Step: 0
Training loss: 3.4958108627694426
Validation loss: 3.389096031726009

Epoch: 5| Step: 1
Training loss: 3.625765620968322
Validation loss: 3.374314279903508

Epoch: 5| Step: 2
Training loss: 4.331194618828837
Validation loss: 3.359694452495482

Epoch: 5| Step: 3
Training loss: 3.415421344238394
Validation loss: 3.3411065763034435

Epoch: 5| Step: 4
Training loss: 3.162779446645782
Validation loss: 3.3213371719639047

Epoch: 5| Step: 5
Training loss: 3.9387017490018628
Validation loss: 3.301874059353173

Epoch: 5| Step: 6
Training loss: 2.7181564209245357
Validation loss: 3.287497048743374

Epoch: 5| Step: 7
Training loss: 3.658600141546974
Validation loss: 3.2888707979108056

Epoch: 5| Step: 8
Training loss: 3.499766478241324
Validation loss: 3.2785112646471455

Epoch: 5| Step: 9
Training loss: 3.5818506026814125
Validation loss: 3.261155047850378

Epoch: 5| Step: 10
Training loss: 3.4456025777827946
Validation loss: 3.2614617830881847

Epoch: 7| Step: 0
Training loss: 3.9918492242934462
Validation loss: 3.265975748828118

Epoch: 5| Step: 1
Training loss: 3.6154245649087877
Validation loss: 3.2490274458694826

Epoch: 5| Step: 2
Training loss: 3.470590601413487
Validation loss: 3.2285617723604867

Epoch: 5| Step: 3
Training loss: 3.344992433547969
Validation loss: 3.211577284236821

Epoch: 5| Step: 4
Training loss: 3.651047093944715
Validation loss: 3.201974545620367

Epoch: 5| Step: 5
Training loss: 2.933116970608067
Validation loss: 3.19350753058663

Epoch: 5| Step: 6
Training loss: 3.7791988389658617
Validation loss: 3.184744139603306

Epoch: 5| Step: 7
Training loss: 3.0943100547562814
Validation loss: 3.1743894412908342

Epoch: 5| Step: 8
Training loss: 3.493836288887876
Validation loss: 3.1603947248604416

Epoch: 5| Step: 9
Training loss: 3.545340319440696
Validation loss: 3.151875174732698

Epoch: 5| Step: 10
Training loss: 2.931619154859755
Validation loss: 3.1442992744236493

Epoch: 8| Step: 0
Training loss: 3.544731265321416
Validation loss: 3.139467980796177

Epoch: 5| Step: 1
Training loss: 3.6925258977003788
Validation loss: 3.132905896651994

Epoch: 5| Step: 2
Training loss: 3.5920720702844586
Validation loss: 3.1241908726132355

Epoch: 5| Step: 3
Training loss: 2.789324237926575
Validation loss: 3.121301418851107

Epoch: 5| Step: 4
Training loss: 4.245715955335292
Validation loss: 3.113643241929327

Epoch: 5| Step: 5
Training loss: 3.0961108206991383
Validation loss: 3.1069534245763513

Epoch: 5| Step: 6
Training loss: 2.6703240427266617
Validation loss: 3.101103685717907

Epoch: 5| Step: 7
Training loss: 3.769000934198901
Validation loss: 3.0994439122154844

Epoch: 5| Step: 8
Training loss: 2.6996756358812712
Validation loss: 3.0951241534062075

Epoch: 5| Step: 9
Training loss: 3.7897574819710775
Validation loss: 3.089590263202654

Epoch: 5| Step: 10
Training loss: 2.889482757057484
Validation loss: 3.0851779985993804

Epoch: 9| Step: 0
Training loss: 3.539218385475857
Validation loss: 3.0780716516596014

Epoch: 5| Step: 1
Training loss: 3.470882138523151
Validation loss: 3.069751178750559

Epoch: 5| Step: 2
Training loss: 3.672188733272493
Validation loss: 3.0656870686059405

Epoch: 5| Step: 3
Training loss: 3.9734586882391962
Validation loss: 3.0615343668881074

Epoch: 5| Step: 4
Training loss: 2.716079013742572
Validation loss: 3.0570356377776693

Epoch: 5| Step: 5
Training loss: 2.791352771553171
Validation loss: 3.0491571630575818

Epoch: 5| Step: 6
Training loss: 2.971597851526806
Validation loss: 3.0444637529285683

Epoch: 5| Step: 7
Training loss: 3.091270609230481
Validation loss: 3.0396332618555255

Epoch: 5| Step: 8
Training loss: 3.7663657065367375
Validation loss: 3.0344656001977337

Epoch: 5| Step: 9
Training loss: 3.3006440083339763
Validation loss: 3.0303473186239662

Epoch: 5| Step: 10
Training loss: 3.1735071953126517
Validation loss: 3.0276803769022074

Epoch: 10| Step: 0
Training loss: 3.7977231181272297
Validation loss: 3.0288730440495315

Epoch: 5| Step: 1
Training loss: 3.4402795824390027
Validation loss: 3.0267571688196444

Epoch: 5| Step: 2
Training loss: 3.186414646041659
Validation loss: 3.0227360086626924

Epoch: 5| Step: 3
Training loss: 3.496483671298876
Validation loss: 3.0146455002357544

Epoch: 5| Step: 4
Training loss: 3.147113834170841
Validation loss: 3.0102013883796688

Epoch: 5| Step: 5
Training loss: 3.417824913268137
Validation loss: 3.005276159265864

Epoch: 5| Step: 6
Training loss: 3.349739485902312
Validation loss: 3.0038857085874873

Epoch: 5| Step: 7
Training loss: 2.9011010940646997
Validation loss: 2.996224572579918

Epoch: 5| Step: 8
Training loss: 3.3917832044470706
Validation loss: 2.9906662928259458

Epoch: 5| Step: 9
Training loss: 3.042625554800267
Validation loss: 2.9914915627673313

Epoch: 5| Step: 10
Training loss: 3.053622086821009
Validation loss: 2.9859730829718987

Epoch: 11| Step: 0
Training loss: 3.597320905499474
Validation loss: 2.9846854357420822

Epoch: 5| Step: 1
Training loss: 3.424284622216762
Validation loss: 2.9770743947514324

Epoch: 5| Step: 2
Training loss: 3.397529568462812
Validation loss: 2.9725421927134037

Epoch: 5| Step: 3
Training loss: 3.03776730589638
Validation loss: 2.97243559488694

Epoch: 5| Step: 4
Training loss: 3.6604286507743415
Validation loss: 2.9738204427271

Epoch: 5| Step: 5
Training loss: 2.7261810473118193
Validation loss: 2.968002511064846

Epoch: 5| Step: 6
Training loss: 3.15956213875125
Validation loss: 2.963665057375127

Epoch: 5| Step: 7
Training loss: 3.5315872976527682
Validation loss: 2.9578437787183964

Epoch: 5| Step: 8
Training loss: 3.024137351877798
Validation loss: 2.955456086850774

Epoch: 5| Step: 9
Training loss: 2.708462775633926
Validation loss: 2.9552924423297804

Epoch: 5| Step: 10
Training loss: 3.645859389439071
Validation loss: 2.9779766137431336

Epoch: 12| Step: 0
Training loss: 3.4040109817471182
Validation loss: 2.9686317631870303

Epoch: 5| Step: 1
Training loss: 2.9305404031933318
Validation loss: 2.9498165479584606

Epoch: 5| Step: 2
Training loss: 3.1538850592240792
Validation loss: 2.955470548548343

Epoch: 5| Step: 3
Training loss: 3.372840897147131
Validation loss: 2.989556020484944

Epoch: 5| Step: 4
Training loss: 3.0036047894591937
Validation loss: 2.976837799180233

Epoch: 5| Step: 5
Training loss: 3.5478339558381595
Validation loss: 2.953671420185632

Epoch: 5| Step: 6
Training loss: 2.8409347852065148
Validation loss: 2.940830157465064

Epoch: 5| Step: 7
Training loss: 3.6457895476118853
Validation loss: 2.9373696987111173

Epoch: 5| Step: 8
Training loss: 3.788282428158329
Validation loss: 2.9408900794220925

Epoch: 5| Step: 9
Training loss: 3.1653149045275444
Validation loss: 2.951158125411625

Epoch: 5| Step: 10
Training loss: 2.8119834425535064
Validation loss: 2.9568725279782413

Epoch: 13| Step: 0
Training loss: 3.4259697091299532
Validation loss: 2.9610861663202734

Epoch: 5| Step: 1
Training loss: 2.9047944720733327
Validation loss: 2.9288660065071217

Epoch: 5| Step: 2
Training loss: 3.9708922604287697
Validation loss: 2.939261194532233

Epoch: 5| Step: 3
Training loss: 2.7456021255453815
Validation loss: 2.946345120658864

Epoch: 5| Step: 4
Training loss: 3.598606841408998
Validation loss: 2.9410637554525123

Epoch: 5| Step: 5
Training loss: 2.569705879955673
Validation loss: 2.928861833066878

Epoch: 5| Step: 6
Training loss: 3.1497963370227096
Validation loss: 2.9190865692936874

Epoch: 5| Step: 7
Training loss: 3.5930833281089343
Validation loss: 2.914999622271845

Epoch: 5| Step: 8
Training loss: 2.956788389444881
Validation loss: 2.91349815915644

Epoch: 5| Step: 9
Training loss: 3.43785773063139
Validation loss: 2.9164588016207755

Epoch: 5| Step: 10
Training loss: 3.0223882071721886
Validation loss: 2.9121658173259264

Epoch: 14| Step: 0
Training loss: 3.1039453380628546
Validation loss: 2.9107643885543832

Epoch: 5| Step: 1
Training loss: 3.2102712417991803
Validation loss: 2.903938006749336

Epoch: 5| Step: 2
Training loss: 2.915346900621666
Validation loss: 2.9001923128519627

Epoch: 5| Step: 3
Training loss: 3.421782749273767
Validation loss: 2.899824968995836

Epoch: 5| Step: 4
Training loss: 3.617436773226116
Validation loss: 2.9030726619718084

Epoch: 5| Step: 5
Training loss: 3.5635328970523092
Validation loss: 2.903560200385025

Epoch: 5| Step: 6
Training loss: 3.2356544212402234
Validation loss: 2.9064491178179934

Epoch: 5| Step: 7
Training loss: 3.113563821525959
Validation loss: 2.9031411491889845

Epoch: 5| Step: 8
Training loss: 3.4821827924625195
Validation loss: 2.908401791775596

Epoch: 5| Step: 9
Training loss: 2.399244340507349
Validation loss: 2.899551135648102

Epoch: 5| Step: 10
Training loss: 3.1765039801660477
Validation loss: 2.8897520015829463

Epoch: 15| Step: 0
Training loss: 3.102293144664464
Validation loss: 2.886555469878472

Epoch: 5| Step: 1
Training loss: 3.137470084119936
Validation loss: 2.8960609945588653

Epoch: 5| Step: 2
Training loss: 3.503207644220215
Validation loss: 2.8841753372589354

Epoch: 5| Step: 3
Training loss: 3.057284682794985
Validation loss: 2.881534932167754

Epoch: 5| Step: 4
Training loss: 3.0129221133734743
Validation loss: 2.882495937334766

Epoch: 5| Step: 5
Training loss: 3.7012703029458347
Validation loss: 2.8806269928743324

Epoch: 5| Step: 6
Training loss: 2.7247485053522706
Validation loss: 2.883353898067948

Epoch: 5| Step: 7
Training loss: 3.404259056104476
Validation loss: 2.8787550994014426

Epoch: 5| Step: 8
Training loss: 3.167290743183434
Validation loss: 2.8794713696981917

Epoch: 5| Step: 9
Training loss: 3.2107494883938985
Validation loss: 2.877021392815841

Epoch: 5| Step: 10
Training loss: 3.126288949265457
Validation loss: 2.873529164080305

Epoch: 16| Step: 0
Training loss: 3.2158062260073352
Validation loss: 2.873534399255828

Epoch: 5| Step: 1
Training loss: 3.2545798384156415
Validation loss: 2.882027539039047

Epoch: 5| Step: 2
Training loss: 3.1864272163586866
Validation loss: 2.875230979647076

Epoch: 5| Step: 3
Training loss: 3.133017060029757
Validation loss: 2.891789063102212

Epoch: 5| Step: 4
Training loss: 3.473207513674418
Validation loss: 2.8847310186084365

Epoch: 5| Step: 5
Training loss: 2.9830375190853693
Validation loss: 2.8673392049466457

Epoch: 5| Step: 6
Training loss: 3.305130732687627
Validation loss: 2.8640177512771117

Epoch: 5| Step: 7
Training loss: 2.664264570610335
Validation loss: 2.8641290868703413

Epoch: 5| Step: 8
Training loss: 2.907290856800812
Validation loss: 2.864956677999146

Epoch: 5| Step: 9
Training loss: 2.961764982441764
Validation loss: 2.8701173054047873

Epoch: 5| Step: 10
Training loss: 3.9725038092218647
Validation loss: 2.8625777662860044

Epoch: 17| Step: 0
Training loss: 3.1531219089216918
Validation loss: 2.8598113990869285

Epoch: 5| Step: 1
Training loss: 3.1491887637437586
Validation loss: 2.8607935684607395

Epoch: 5| Step: 2
Training loss: 3.3535490395375906
Validation loss: 2.8612824700073864

Epoch: 5| Step: 3
Training loss: 2.608549889866702
Validation loss: 2.8666059233842147

Epoch: 5| Step: 4
Training loss: 3.493629516271073
Validation loss: 2.865100573307621

Epoch: 5| Step: 5
Training loss: 3.0957065137008266
Validation loss: 2.8579294347765716

Epoch: 5| Step: 6
Training loss: 3.2342608887818716
Validation loss: 2.8555922738728086

Epoch: 5| Step: 7
Training loss: 2.897694783020115
Validation loss: 2.8549372081497375

Epoch: 5| Step: 8
Training loss: 3.377102797254276
Validation loss: 2.853440174230173

Epoch: 5| Step: 9
Training loss: 3.5527723581927093
Validation loss: 2.8506720388325344

Epoch: 5| Step: 10
Training loss: 2.9650065059493995
Validation loss: 2.8509545910341734

Epoch: 18| Step: 0
Training loss: 3.8056110616257364
Validation loss: 2.848776911410112

Epoch: 5| Step: 1
Training loss: 3.298721302712794
Validation loss: 2.8470836447276877

Epoch: 5| Step: 2
Training loss: 3.8921899061222365
Validation loss: 2.842959787659399

Epoch: 5| Step: 3
Training loss: 2.397684283448449
Validation loss: 2.8436157652842815

Epoch: 5| Step: 4
Training loss: 2.9103191150945236
Validation loss: 2.843221258956181

Epoch: 5| Step: 5
Training loss: 3.425396226671067
Validation loss: 2.842840432152531

Epoch: 5| Step: 6
Training loss: 3.345336252597687
Validation loss: 2.842514541399311

Epoch: 5| Step: 7
Training loss: 2.67187455383654
Validation loss: 2.838299959986931

Epoch: 5| Step: 8
Training loss: 3.641729621139368
Validation loss: 2.8359201859516547

Epoch: 5| Step: 9
Training loss: 2.355099372306035
Validation loss: 2.8357368745628744

Epoch: 5| Step: 10
Training loss: 2.455150375577679
Validation loss: 2.838598785472962

Epoch: 19| Step: 0
Training loss: 3.073772470734173
Validation loss: 2.872405734221913

Epoch: 5| Step: 1
Training loss: 3.494607313195218
Validation loss: 2.8987054829471166

Epoch: 5| Step: 2
Training loss: 3.5436230510598796
Validation loss: 2.8447384744114714

Epoch: 5| Step: 3
Training loss: 3.1029409425053163
Validation loss: 2.8268494155034842

Epoch: 5| Step: 4
Training loss: 3.1496667473729403
Validation loss: 2.8324391156144406

Epoch: 5| Step: 5
Training loss: 2.842764882920399
Validation loss: 2.831068064143753

Epoch: 5| Step: 6
Training loss: 3.160833071738756
Validation loss: 2.830205583185892

Epoch: 5| Step: 7
Training loss: 3.5469240697751747
Validation loss: 2.825907145158316

Epoch: 5| Step: 8
Training loss: 2.909379975901609
Validation loss: 2.828081116930466

Epoch: 5| Step: 9
Training loss: 3.0018061922706787
Validation loss: 2.833085202771384

Epoch: 5| Step: 10
Training loss: 2.882428234096946
Validation loss: 2.833362113823353

Epoch: 20| Step: 0
Training loss: 3.0477594119059543
Validation loss: 2.834359694896326

Epoch: 5| Step: 1
Training loss: 3.7573238062966796
Validation loss: 2.8341246416190984

Epoch: 5| Step: 2
Training loss: 2.8641900549754915
Validation loss: 2.8295556764950742

Epoch: 5| Step: 3
Training loss: 3.2955328211561454
Validation loss: 2.820525217850111

Epoch: 5| Step: 4
Training loss: 3.10252138780573
Validation loss: 2.8129915881121863

Epoch: 5| Step: 5
Training loss: 2.741970477523304
Validation loss: 2.8152859816074254

Epoch: 5| Step: 6
Training loss: 3.0520249883046238
Validation loss: 2.8164811809833368

Epoch: 5| Step: 7
Training loss: 3.4898791439259016
Validation loss: 2.8151730503782075

Epoch: 5| Step: 8
Training loss: 2.9453665730903396
Validation loss: 2.8109679010760282

Epoch: 5| Step: 9
Training loss: 2.8391058591513936
Validation loss: 2.8089640969915552

Epoch: 5| Step: 10
Training loss: 3.3878525328806592
Validation loss: 2.804371405378015

Epoch: 21| Step: 0
Training loss: 3.402271992641691
Validation loss: 2.8057465398085997

Epoch: 5| Step: 1
Training loss: 3.1075302095548323
Validation loss: 2.8062819752704415

Epoch: 5| Step: 2
Training loss: 2.9237765891834195
Validation loss: 2.817900808348132

Epoch: 5| Step: 3
Training loss: 2.2681917580907807
Validation loss: 2.826719973079021

Epoch: 5| Step: 4
Training loss: 2.9655696497938333
Validation loss: 2.8414303923485194

Epoch: 5| Step: 5
Training loss: 2.91459671319195
Validation loss: 2.8463973693267977

Epoch: 5| Step: 6
Training loss: 3.705515415928082
Validation loss: 2.8175328480035837

Epoch: 5| Step: 7
Training loss: 2.8341294086553073
Validation loss: 2.8062214418709353

Epoch: 5| Step: 8
Training loss: 3.0188998293765184
Validation loss: 2.8069745403914323

Epoch: 5| Step: 9
Training loss: 3.908764571506433
Validation loss: 2.8049676715042993

Epoch: 5| Step: 10
Training loss: 3.163076741698967
Validation loss: 2.802720532006694

Epoch: 22| Step: 0
Training loss: 3.4349078028048337
Validation loss: 2.800603791075438

Epoch: 5| Step: 1
Training loss: 3.1312225949730914
Validation loss: 2.8019805357482004

Epoch: 5| Step: 2
Training loss: 3.0410606268246196
Validation loss: 2.805304327458746

Epoch: 5| Step: 3
Training loss: 3.0166889744841803
Validation loss: 2.8026558804626105

Epoch: 5| Step: 4
Training loss: 3.2547801150633986
Validation loss: 2.8348394446893606

Epoch: 5| Step: 5
Training loss: 3.3816950760712317
Validation loss: 2.832349607051231

Epoch: 5| Step: 6
Training loss: 3.074717693240705
Validation loss: 2.837734301244074

Epoch: 5| Step: 7
Training loss: 3.359156827717438
Validation loss: 2.8341830214306585

Epoch: 5| Step: 8
Training loss: 2.325409502452301
Validation loss: 2.8363924239310476

Epoch: 5| Step: 9
Training loss: 3.2840179394453863
Validation loss: 2.846634411772344

Epoch: 5| Step: 10
Training loss: 3.1024128783455964
Validation loss: 2.874490278088566

Epoch: 23| Step: 0
Training loss: 2.8605029273495752
Validation loss: 2.914067386116256

Epoch: 5| Step: 1
Training loss: 2.601139893444752
Validation loss: 2.9194785444117692

Epoch: 5| Step: 2
Training loss: 2.794697515944694
Validation loss: 2.889552387047854

Epoch: 5| Step: 3
Training loss: 3.5750971480821465
Validation loss: 2.845177502325868

Epoch: 5| Step: 4
Training loss: 3.423370034733954
Validation loss: 2.8349316580894652

Epoch: 5| Step: 5
Training loss: 2.7788849107782556
Validation loss: 2.824917404879628

Epoch: 5| Step: 6
Training loss: 3.3201019579387014
Validation loss: 2.816182153320556

Epoch: 5| Step: 7
Training loss: 3.598319954387134
Validation loss: 2.827130653404332

Epoch: 5| Step: 8
Training loss: 3.6981654696871695
Validation loss: 2.8238965240153844

Epoch: 5| Step: 9
Training loss: 2.6506426697699514
Validation loss: 2.827801592717744

Epoch: 5| Step: 10
Training loss: 3.227747517143159
Validation loss: 2.824805735388899

Epoch: 24| Step: 0
Training loss: 3.36761429420679
Validation loss: 2.8196224608928193

Epoch: 5| Step: 1
Training loss: 3.7480233387011785
Validation loss: 2.816437263950065

Epoch: 5| Step: 2
Training loss: 3.1193861318338802
Validation loss: 2.8129378001969023

Epoch: 5| Step: 3
Training loss: 3.1310046680455845
Validation loss: 2.8141471278180954

Epoch: 5| Step: 4
Training loss: 2.3377135806501723
Validation loss: 2.814838912633796

Epoch: 5| Step: 5
Training loss: 3.0967508269974315
Validation loss: 2.824359176658187

Epoch: 5| Step: 6
Training loss: 2.2632308411835984
Validation loss: 2.848008161015885

Epoch: 5| Step: 7
Training loss: 2.8333625978940677
Validation loss: 2.879405501555588

Epoch: 5| Step: 8
Training loss: 3.3388944648728556
Validation loss: 2.8928739827892436

Epoch: 5| Step: 9
Training loss: 3.6862891844034436
Validation loss: 2.831012861989217

Epoch: 5| Step: 10
Training loss: 3.211928759895303
Validation loss: 2.7969294849963506

Epoch: 25| Step: 0
Training loss: 3.4640159951384746
Validation loss: 2.808074157820898

Epoch: 5| Step: 1
Training loss: 2.9903093225217274
Validation loss: 2.8189739247763015

Epoch: 5| Step: 2
Training loss: 3.007294845623419
Validation loss: 2.8399788941889303

Epoch: 5| Step: 3
Training loss: 3.0938125758152286
Validation loss: 2.8594473346571614

Epoch: 5| Step: 4
Training loss: 3.472255001337247
Validation loss: 2.8226151912526425

Epoch: 5| Step: 5
Training loss: 3.41016268210662
Validation loss: 2.801568777555913

Epoch: 5| Step: 6
Training loss: 2.996914866702376
Validation loss: 2.796395007704563

Epoch: 5| Step: 7
Training loss: 3.2080983327696995
Validation loss: 2.7946758413500428

Epoch: 5| Step: 8
Training loss: 3.0307626234114364
Validation loss: 2.7954958610545626

Epoch: 5| Step: 9
Training loss: 2.537721438212127
Validation loss: 2.7970919914167394

Epoch: 5| Step: 10
Training loss: 3.1445200286096364
Validation loss: 2.812709469668606

Epoch: 26| Step: 0
Training loss: 3.179078739761876
Validation loss: 2.839772122091647

Epoch: 5| Step: 1
Training loss: 2.9901052057135633
Validation loss: 2.8435608788435554

Epoch: 5| Step: 2
Training loss: 3.2414760314535402
Validation loss: 2.8701372937691185

Epoch: 5| Step: 3
Training loss: 3.185003013190217
Validation loss: 2.8526105675495605

Epoch: 5| Step: 4
Training loss: 3.2599022472680317
Validation loss: 2.842365514298435

Epoch: 5| Step: 5
Training loss: 3.11105316728795
Validation loss: 2.816911184567681

Epoch: 5| Step: 6
Training loss: 2.68147685196143
Validation loss: 2.7944775162316033

Epoch: 5| Step: 7
Training loss: 3.178747989655405
Validation loss: 2.785970884707917

Epoch: 5| Step: 8
Training loss: 3.208568135046206
Validation loss: 2.7786928915932787

Epoch: 5| Step: 9
Training loss: 3.035750989932471
Validation loss: 2.7765533253402648

Epoch: 5| Step: 10
Training loss: 3.2490266662893483
Validation loss: 2.772825866392518

Epoch: 27| Step: 0
Training loss: 2.916671280630186
Validation loss: 2.768594656436186

Epoch: 5| Step: 1
Training loss: 3.256622755860251
Validation loss: 2.7691249948929326

Epoch: 5| Step: 2
Training loss: 3.0023522691806828
Validation loss: 2.7704529730580685

Epoch: 5| Step: 3
Training loss: 3.002856166528852
Validation loss: 2.7648690077246427

Epoch: 5| Step: 4
Training loss: 3.3629282058280268
Validation loss: 2.760127664499305

Epoch: 5| Step: 5
Training loss: 2.8646896250107172
Validation loss: 2.7570628736086396

Epoch: 5| Step: 6
Training loss: 3.014197451436305
Validation loss: 2.7578955773217233

Epoch: 5| Step: 7
Training loss: 3.407935609128611
Validation loss: 2.7532259793626355

Epoch: 5| Step: 8
Training loss: 2.962010171691203
Validation loss: 2.7518164200327235

Epoch: 5| Step: 9
Training loss: 2.6926997250407663
Validation loss: 2.7476496800184256

Epoch: 5| Step: 10
Training loss: 3.470210274913008
Validation loss: 2.7484238807319192

Epoch: 28| Step: 0
Training loss: 3.3685510976527517
Validation loss: 2.7496911376051023

Epoch: 5| Step: 1
Training loss: 3.1862212963465035
Validation loss: 2.74831440428695

Epoch: 5| Step: 2
Training loss: 2.816253023040138
Validation loss: 2.7501473969962857

Epoch: 5| Step: 3
Training loss: 3.3751679837842454
Validation loss: 2.7500899757887405

Epoch: 5| Step: 4
Training loss: 2.940043383167954
Validation loss: 2.7429226429590146

Epoch: 5| Step: 5
Training loss: 3.0297012305182194
Validation loss: 2.740913235511964

Epoch: 5| Step: 6
Training loss: 3.2582812806741686
Validation loss: 2.740861781946449

Epoch: 5| Step: 7
Training loss: 3.26395296795937
Validation loss: 2.7406473241642266

Epoch: 5| Step: 8
Training loss: 2.8519504231000075
Validation loss: 2.7398093960141257

Epoch: 5| Step: 9
Training loss: 3.0886629454981898
Validation loss: 2.736792153899053

Epoch: 5| Step: 10
Training loss: 2.380777859876602
Validation loss: 2.7356490572409493

Epoch: 29| Step: 0
Training loss: 3.42200919110275
Validation loss: 2.7367540979624936

Epoch: 5| Step: 1
Training loss: 2.6613407494735335
Validation loss: 2.74642711676696

Epoch: 5| Step: 2
Training loss: 2.7131916974878303
Validation loss: 2.768457994438042

Epoch: 5| Step: 3
Training loss: 3.262655998388178
Validation loss: 2.8025922501055835

Epoch: 5| Step: 4
Training loss: 2.3837982640133757
Validation loss: 2.7372787185367864

Epoch: 5| Step: 5
Training loss: 2.9719866325519337
Validation loss: 2.7324557955629563

Epoch: 5| Step: 6
Training loss: 3.3800743950325396
Validation loss: 2.73452506923661

Epoch: 5| Step: 7
Training loss: 2.9497724606968
Validation loss: 2.740696657469186

Epoch: 5| Step: 8
Training loss: 3.235173223654081
Validation loss: 2.7499085203227103

Epoch: 5| Step: 9
Training loss: 3.601777506800787
Validation loss: 2.750886926975107

Epoch: 5| Step: 10
Training loss: 2.943761118485173
Validation loss: 2.7466310456162693

Epoch: 30| Step: 0
Training loss: 2.8203770004040165
Validation loss: 2.745075540308432

Epoch: 5| Step: 1
Training loss: 2.981570059112316
Validation loss: 2.744657578856832

Epoch: 5| Step: 2
Training loss: 3.1280344154435418
Validation loss: 2.7383219547811875

Epoch: 5| Step: 3
Training loss: 3.222922870126157
Validation loss: 2.736734885255719

Epoch: 5| Step: 4
Training loss: 3.2672233502953745
Validation loss: 2.7387922562462457

Epoch: 5| Step: 5
Training loss: 3.6848649777399993
Validation loss: 2.7315901293346223

Epoch: 5| Step: 6
Training loss: 2.8976401494438444
Validation loss: 2.7291878501622935

Epoch: 5| Step: 7
Training loss: 2.8107543614235007
Validation loss: 2.727108422937799

Epoch: 5| Step: 8
Training loss: 2.2625890977714014
Validation loss: 2.7255480712341775

Epoch: 5| Step: 9
Training loss: 3.383233940531205
Validation loss: 2.7265729085080266

Epoch: 5| Step: 10
Training loss: 2.9296210929973787
Validation loss: 2.7273795664261815

Epoch: 31| Step: 0
Training loss: 2.749557286086292
Validation loss: 2.7317935995012768

Epoch: 5| Step: 1
Training loss: 3.657130078416876
Validation loss: 2.7347198953233267

Epoch: 5| Step: 2
Training loss: 3.4723456365057253
Validation loss: 2.7336850919413678

Epoch: 5| Step: 3
Training loss: 2.3927395513145187
Validation loss: 2.7325688926504603

Epoch: 5| Step: 4
Training loss: 2.9200415749398916
Validation loss: 2.7248951768239844

Epoch: 5| Step: 5
Training loss: 3.31075600832796
Validation loss: 2.727027919865627

Epoch: 5| Step: 6
Training loss: 3.120670065452237
Validation loss: 2.7252191521121807

Epoch: 5| Step: 7
Training loss: 2.511043000868259
Validation loss: 2.7225351713200237

Epoch: 5| Step: 8
Training loss: 3.4993146497833654
Validation loss: 2.725739353606729

Epoch: 5| Step: 9
Training loss: 2.830677208632707
Validation loss: 2.7230460877884086

Epoch: 5| Step: 10
Training loss: 2.705653160479146
Validation loss: 2.7200293213098137

Epoch: 32| Step: 0
Training loss: 3.2691463485450702
Validation loss: 2.7257786082400086

Epoch: 5| Step: 1
Training loss: 3.2780481611324905
Validation loss: 2.716537433356016

Epoch: 5| Step: 2
Training loss: 3.125589849117639
Validation loss: 2.7109522183011547

Epoch: 5| Step: 3
Training loss: 3.2081237493319725
Validation loss: 2.712581142752228

Epoch: 5| Step: 4
Training loss: 2.6405975520947726
Validation loss: 2.7103385172545233

Epoch: 5| Step: 5
Training loss: 2.8124421855494393
Validation loss: 2.7066008558561605

Epoch: 5| Step: 6
Training loss: 1.9913154039579368
Validation loss: 2.7097444485115103

Epoch: 5| Step: 7
Training loss: 3.3445366620361052
Validation loss: 2.7063617001093396

Epoch: 5| Step: 8
Training loss: 3.2280710309992804
Validation loss: 2.7078174588817836

Epoch: 5| Step: 9
Training loss: 3.0446296439105858
Validation loss: 2.7044178231858327

Epoch: 5| Step: 10
Training loss: 3.2998054100232266
Validation loss: 2.704608703281763

Epoch: 33| Step: 0
Training loss: 2.679257995172097
Validation loss: 2.7042697045452337

Epoch: 5| Step: 1
Training loss: 3.343998409562896
Validation loss: 2.703478589281124

Epoch: 5| Step: 2
Training loss: 3.2764095388935637
Validation loss: 2.7043223273686365

Epoch: 5| Step: 3
Training loss: 3.09057068502221
Validation loss: 2.6981968248235306

Epoch: 5| Step: 4
Training loss: 3.0318168817948634
Validation loss: 2.6996489127567496

Epoch: 5| Step: 5
Training loss: 2.7221069657542505
Validation loss: 2.7007324909179

Epoch: 5| Step: 6
Training loss: 3.4184995402589258
Validation loss: 2.7002368629408267

Epoch: 5| Step: 7
Training loss: 3.219974322009325
Validation loss: 2.7033825358713544

Epoch: 5| Step: 8
Training loss: 2.7897572226500507
Validation loss: 2.7001744411468662

Epoch: 5| Step: 9
Training loss: 2.7988344286936164
Validation loss: 2.6980282957626716

Epoch: 5| Step: 10
Training loss: 2.908531687912278
Validation loss: 2.696177751557433

Epoch: 34| Step: 0
Training loss: 2.7282019989928075
Validation loss: 2.69519660680336

Epoch: 5| Step: 1
Training loss: 3.052790294093571
Validation loss: 2.6939819837520265

Epoch: 5| Step: 2
Training loss: 2.9334282758548844
Validation loss: 2.697265586981636

Epoch: 5| Step: 3
Training loss: 2.744944694253733
Validation loss: 2.7091225268585273

Epoch: 5| Step: 4
Training loss: 3.2035260205332183
Validation loss: 2.72804625833241

Epoch: 5| Step: 5
Training loss: 3.3759800936035194
Validation loss: 2.716453077021726

Epoch: 5| Step: 6
Training loss: 3.4183921333759906
Validation loss: 2.6944294818685015

Epoch: 5| Step: 7
Training loss: 2.6359145004634845
Validation loss: 2.6894886255399264

Epoch: 5| Step: 8
Training loss: 2.8370476853750266
Validation loss: 2.691585326984129

Epoch: 5| Step: 9
Training loss: 3.3741128956574054
Validation loss: 2.6978816080295998

Epoch: 5| Step: 10
Training loss: 2.86904722182462
Validation loss: 2.6992392364902704

Epoch: 35| Step: 0
Training loss: 2.953017621384029
Validation loss: 2.7053465772817575

Epoch: 5| Step: 1
Training loss: 2.9075319477664756
Validation loss: 2.705738592557284

Epoch: 5| Step: 2
Training loss: 3.044300889562161
Validation loss: 2.7006686870641827

Epoch: 5| Step: 3
Training loss: 3.4144229654975224
Validation loss: 2.696659522324014

Epoch: 5| Step: 4
Training loss: 2.8742996689691442
Validation loss: 2.694355106201202

Epoch: 5| Step: 5
Training loss: 3.043660507609792
Validation loss: 2.692170979674081

Epoch: 5| Step: 6
Training loss: 2.851875016318845
Validation loss: 2.6900717489501016

Epoch: 5| Step: 7
Training loss: 3.0077879273042516
Validation loss: 2.6890590340056786

Epoch: 5| Step: 8
Training loss: 2.8162716477565723
Validation loss: 2.689344510054895

Epoch: 5| Step: 9
Training loss: 3.2352029966078257
Validation loss: 2.689700627682266

Epoch: 5| Step: 10
Training loss: 3.2321153201501063
Validation loss: 2.6864517105779817

Epoch: 36| Step: 0
Training loss: 2.995153326781074
Validation loss: 2.686175392681602

Epoch: 5| Step: 1
Training loss: 2.8739539192131702
Validation loss: 2.6883168373079624

Epoch: 5| Step: 2
Training loss: 3.0029793885622795
Validation loss: 2.687917619191273

Epoch: 5| Step: 3
Training loss: 3.1145972482291766
Validation loss: 2.690605220231517

Epoch: 5| Step: 4
Training loss: 2.951024514438071
Validation loss: 2.696705118103405

Epoch: 5| Step: 5
Training loss: 3.398337877939979
Validation loss: 2.6935812820281324

Epoch: 5| Step: 6
Training loss: 3.130416296187931
Validation loss: 2.687955821006534

Epoch: 5| Step: 7
Training loss: 2.9158622358978743
Validation loss: 2.6837189488697284

Epoch: 5| Step: 8
Training loss: 2.7210447777397193
Validation loss: 2.6836358039449344

Epoch: 5| Step: 9
Training loss: 3.1312026456195023
Validation loss: 2.680111654931376

Epoch: 5| Step: 10
Training loss: 3.0020500172432625
Validation loss: 2.68233128410987

Epoch: 37| Step: 0
Training loss: 3.12786337323359
Validation loss: 2.6823482830421534

Epoch: 5| Step: 1
Training loss: 2.8297463506248244
Validation loss: 2.6811907715167824

Epoch: 5| Step: 2
Training loss: 2.8903250873764654
Validation loss: 2.6812897272100047

Epoch: 5| Step: 3
Training loss: 3.146713655762129
Validation loss: 2.6831309511515933

Epoch: 5| Step: 4
Training loss: 3.0856052654424184
Validation loss: 2.6824839112805354

Epoch: 5| Step: 5
Training loss: 2.785827555816377
Validation loss: 2.6839054027783567

Epoch: 5| Step: 6
Training loss: 3.292285925322208
Validation loss: 2.6833445834310825

Epoch: 5| Step: 7
Training loss: 2.860785798113943
Validation loss: 2.6836570876402766

Epoch: 5| Step: 8
Training loss: 3.0243885210416495
Validation loss: 2.6815755571366107

Epoch: 5| Step: 9
Training loss: 3.059915035539261
Validation loss: 2.681314918999413

Epoch: 5| Step: 10
Training loss: 3.0874246997376784
Validation loss: 2.6791002743549903

Epoch: 38| Step: 0
Training loss: 2.8713129699471494
Validation loss: 2.6807512692584563

Epoch: 5| Step: 1
Training loss: 3.447154134617078
Validation loss: 2.6809240457675156

Epoch: 5| Step: 2
Training loss: 3.281342859316622
Validation loss: 2.67692231286603

Epoch: 5| Step: 3
Training loss: 3.030840187292257
Validation loss: 2.678371870280514

Epoch: 5| Step: 4
Training loss: 2.964453710499926
Validation loss: 2.6775014352998077

Epoch: 5| Step: 5
Training loss: 3.0851689794127584
Validation loss: 2.6758268087323143

Epoch: 5| Step: 6
Training loss: 3.0991610591626055
Validation loss: 2.6785164000312602

Epoch: 5| Step: 7
Training loss: 3.0529066587561493
Validation loss: 2.671862308779333

Epoch: 5| Step: 8
Training loss: 2.624703345111845
Validation loss: 2.672506244756918

Epoch: 5| Step: 9
Training loss: 2.479325735508081
Validation loss: 2.6742056757417187

Epoch: 5| Step: 10
Training loss: 3.0530278607223957
Validation loss: 2.686090626846904

Epoch: 39| Step: 0
Training loss: 2.988399647879168
Validation loss: 2.673583052705084

Epoch: 5| Step: 1
Training loss: 2.9173959274492653
Validation loss: 2.668161035666692

Epoch: 5| Step: 2
Training loss: 3.036550704746278
Validation loss: 2.6582919124472952

Epoch: 5| Step: 3
Training loss: 2.9842666686203625
Validation loss: 2.650504936317429

Epoch: 5| Step: 4
Training loss: 3.1475262328880995
Validation loss: 2.6491019936024336

Epoch: 5| Step: 5
Training loss: 3.2381501947809586
Validation loss: 2.646206266943653

Epoch: 5| Step: 6
Training loss: 2.7241702365083627
Validation loss: 2.6476544327153952

Epoch: 5| Step: 7
Training loss: 3.529384018751551
Validation loss: 2.651008976289689

Epoch: 5| Step: 8
Training loss: 2.945581560468173
Validation loss: 2.64916029539472

Epoch: 5| Step: 9
Training loss: 2.8634744243328933
Validation loss: 2.647997569711183

Epoch: 5| Step: 10
Training loss: 2.381067356103766
Validation loss: 2.6518161779448866

Epoch: 40| Step: 0
Training loss: 3.0617435065940612
Validation loss: 2.6513448178800614

Epoch: 5| Step: 1
Training loss: 2.948281489107455
Validation loss: 2.652733939572303

Epoch: 5| Step: 2
Training loss: 2.67701129346367
Validation loss: 2.6475391742910905

Epoch: 5| Step: 3
Training loss: 3.1892017982633813
Validation loss: 2.6456969002088635

Epoch: 5| Step: 4
Training loss: 3.42359093966849
Validation loss: 2.6444236120433655

Epoch: 5| Step: 5
Training loss: 2.9805357839262956
Validation loss: 2.6448367580921923

Epoch: 5| Step: 6
Training loss: 3.298783170440066
Validation loss: 2.6461433834240964

Epoch: 5| Step: 7
Training loss: 2.7799247413163566
Validation loss: 2.641608787767694

Epoch: 5| Step: 8
Training loss: 2.1192032905841076
Validation loss: 2.6423292636526448

Epoch: 5| Step: 9
Training loss: 3.153969271155176
Validation loss: 2.6415182118580525

Epoch: 5| Step: 10
Training loss: 3.0592324088263347
Validation loss: 2.6470094863116214

Epoch: 41| Step: 0
Training loss: 3.0383868017913396
Validation loss: 2.6535432742940688

Epoch: 5| Step: 1
Training loss: 3.1458141671580018
Validation loss: 2.6631762814086373

Epoch: 5| Step: 2
Training loss: 2.8133303793971507
Validation loss: 2.650552150128539

Epoch: 5| Step: 3
Training loss: 3.313564921088327
Validation loss: 2.649008363151279

Epoch: 5| Step: 4
Training loss: 3.4847744426224474
Validation loss: 2.6497165636704088

Epoch: 5| Step: 5
Training loss: 2.8411487797279826
Validation loss: 2.64291265655601

Epoch: 5| Step: 6
Training loss: 2.73722525136701
Validation loss: 2.6416119661028317

Epoch: 5| Step: 7
Training loss: 2.9356219192628408
Validation loss: 2.6411667057178834

Epoch: 5| Step: 8
Training loss: 2.6798104572168695
Validation loss: 2.648557883287311

Epoch: 5| Step: 9
Training loss: 3.137158050748476
Validation loss: 2.6461501971370223

Epoch: 5| Step: 10
Training loss: 2.543607335694376
Validation loss: 2.646523707667828

Epoch: 42| Step: 0
Training loss: 3.0854278529906907
Validation loss: 2.647947507525232

Epoch: 5| Step: 1
Training loss: 2.6290027436321535
Validation loss: 2.6485635708867004

Epoch: 5| Step: 2
Training loss: 2.7312828673037157
Validation loss: 2.655747884334358

Epoch: 5| Step: 3
Training loss: 2.5397357693602154
Validation loss: 2.6586561342682793

Epoch: 5| Step: 4
Training loss: 2.993557369907701
Validation loss: 2.6517919259686007

Epoch: 5| Step: 5
Training loss: 3.4433181076476367
Validation loss: 2.6410487869422807

Epoch: 5| Step: 6
Training loss: 3.268529157308047
Validation loss: 2.63324959508743

Epoch: 5| Step: 7
Training loss: 2.9658441074736928
Validation loss: 2.6361460608807334

Epoch: 5| Step: 8
Training loss: 2.9825061319037154
Validation loss: 2.634262404822915

Epoch: 5| Step: 9
Training loss: 3.0407098458381636
Validation loss: 2.6378043621158946

Epoch: 5| Step: 10
Training loss: 3.0278411259766047
Validation loss: 2.6325806249406147

Epoch: 43| Step: 0
Training loss: 3.001466551582095
Validation loss: 2.6359915160908525

Epoch: 5| Step: 1
Training loss: 2.808522187702048
Validation loss: 2.637415448522714

Epoch: 5| Step: 2
Training loss: 2.919096416035003
Validation loss: 2.6464695645549727

Epoch: 5| Step: 3
Training loss: 3.440989162704044
Validation loss: 2.659464349223352

Epoch: 5| Step: 4
Training loss: 2.6578364403132544
Validation loss: 2.655800759089062

Epoch: 5| Step: 5
Training loss: 3.1290866833118716
Validation loss: 2.6520870868131183

Epoch: 5| Step: 6
Training loss: 3.132984946206531
Validation loss: 2.6423143833469696

Epoch: 5| Step: 7
Training loss: 2.709548726391481
Validation loss: 2.6347748305860494

Epoch: 5| Step: 8
Training loss: 3.1000225558537085
Validation loss: 2.6331516759554514

Epoch: 5| Step: 9
Training loss: 3.273536553170196
Validation loss: 2.625973869968544

Epoch: 5| Step: 10
Training loss: 2.436861394710674
Validation loss: 2.622605954364078

Epoch: 44| Step: 0
Training loss: 2.8488209544271648
Validation loss: 2.6260665635103333

Epoch: 5| Step: 1
Training loss: 2.808196186901335
Validation loss: 2.6271976621690274

Epoch: 5| Step: 2
Training loss: 2.54563405515548
Validation loss: 2.621699772940821

Epoch: 5| Step: 3
Training loss: 3.2478187283636335
Validation loss: 2.6233049986080537

Epoch: 5| Step: 4
Training loss: 3.235806208387224
Validation loss: 2.6239253851054833

Epoch: 5| Step: 5
Training loss: 2.736635243990087
Validation loss: 2.6326064474072424

Epoch: 5| Step: 6
Training loss: 3.3784619695271125
Validation loss: 2.641399773024738

Epoch: 5| Step: 7
Training loss: 3.268823253036898
Validation loss: 2.6633963322917626

Epoch: 5| Step: 8
Training loss: 2.973424985040416
Validation loss: 2.6360787263654255

Epoch: 5| Step: 9
Training loss: 2.9639780341195454
Validation loss: 2.6230882303550076

Epoch: 5| Step: 10
Training loss: 2.5803836061230383
Validation loss: 2.6161026135152055

Epoch: 45| Step: 0
Training loss: 2.8171168262928283
Validation loss: 2.6225586294299967

Epoch: 5| Step: 1
Training loss: 2.7127000866763553
Validation loss: 2.6216581145459994

Epoch: 5| Step: 2
Training loss: 3.299907139714284
Validation loss: 2.6265203728602335

Epoch: 5| Step: 3
Training loss: 3.445984928312901
Validation loss: 2.6208505399828335

Epoch: 5| Step: 4
Training loss: 2.400376620147052
Validation loss: 2.6219404235958756

Epoch: 5| Step: 5
Training loss: 2.8525337132995037
Validation loss: 2.6238165813483647

Epoch: 5| Step: 6
Training loss: 2.761904525443632
Validation loss: 2.6211016088648824

Epoch: 5| Step: 7
Training loss: 2.8015429366833415
Validation loss: 2.61817657142996

Epoch: 5| Step: 8
Training loss: 3.2810131169143864
Validation loss: 2.6199943114920874

Epoch: 5| Step: 9
Training loss: 3.281211344173343
Validation loss: 2.6184837886373145

Epoch: 5| Step: 10
Training loss: 2.936353906292715
Validation loss: 2.6238204866762245

Epoch: 46| Step: 0
Training loss: 2.9285482811096077
Validation loss: 2.6288668780360536

Epoch: 5| Step: 1
Training loss: 3.4598760419481756
Validation loss: 2.6423741010182087

Epoch: 5| Step: 2
Training loss: 2.4480922121993594
Validation loss: 2.640746638396908

Epoch: 5| Step: 3
Training loss: 2.9339360470448934
Validation loss: 2.6392191473171516

Epoch: 5| Step: 4
Training loss: 3.118040651674247
Validation loss: 2.658230886826506

Epoch: 5| Step: 5
Training loss: 2.978932155813628
Validation loss: 2.646095822579796

Epoch: 5| Step: 6
Training loss: 3.03308899143366
Validation loss: 2.6350105540509086

Epoch: 5| Step: 7
Training loss: 3.016491068863005
Validation loss: 2.6254114677201086

Epoch: 5| Step: 8
Training loss: 3.0781841756486674
Validation loss: 2.6179433119122146

Epoch: 5| Step: 9
Training loss: 3.123975967471087
Validation loss: 2.612175410233242

Epoch: 5| Step: 10
Training loss: 2.2687664483264913
Validation loss: 2.6067074620300597

Epoch: 47| Step: 0
Training loss: 3.245170820116161
Validation loss: 2.607587019384704

Epoch: 5| Step: 1
Training loss: 2.65776234377048
Validation loss: 2.607625377555157

Epoch: 5| Step: 2
Training loss: 2.4101384438918827
Validation loss: 2.6042511353278375

Epoch: 5| Step: 3
Training loss: 2.937680178047163
Validation loss: 2.603361783246073

Epoch: 5| Step: 4
Training loss: 3.0121500025628625
Validation loss: 2.6086821662672546

Epoch: 5| Step: 5
Training loss: 2.9892160187783996
Validation loss: 2.6110436567455992

Epoch: 5| Step: 6
Training loss: 2.9476833363493444
Validation loss: 2.611689736981429

Epoch: 5| Step: 7
Training loss: 2.820288407072256
Validation loss: 2.6078922843044636

Epoch: 5| Step: 8
Training loss: 3.1393253806869392
Validation loss: 2.605422075118001

Epoch: 5| Step: 9
Training loss: 3.333033707185888
Validation loss: 2.6023264802225294

Epoch: 5| Step: 10
Training loss: 2.958908956340844
Validation loss: 2.603959847061813

Epoch: 48| Step: 0
Training loss: 2.829028243516191
Validation loss: 2.6081945273934988

Epoch: 5| Step: 1
Training loss: 2.9177084197689336
Validation loss: 2.620776153894883

Epoch: 5| Step: 2
Training loss: 2.772148585015743
Validation loss: 2.6286399974774595

Epoch: 5| Step: 3
Training loss: 3.5380756947650522
Validation loss: 2.6572072243673

Epoch: 5| Step: 4
Training loss: 2.099653319852617
Validation loss: 2.63834056421542

Epoch: 5| Step: 5
Training loss: 3.1490072108816407
Validation loss: 2.6150488554033915

Epoch: 5| Step: 6
Training loss: 3.2687915981701963
Validation loss: 2.619935323481623

Epoch: 5| Step: 7
Training loss: 3.154438518733443
Validation loss: 2.597809061864476

Epoch: 5| Step: 8
Training loss: 3.128553125311755
Validation loss: 2.5962955295725054

Epoch: 5| Step: 9
Training loss: 2.8531481371105434
Validation loss: 2.596141182947736

Epoch: 5| Step: 10
Training loss: 2.4930632675840294
Validation loss: 2.5962690161554463

Epoch: 49| Step: 0
Training loss: 2.282789781941736
Validation loss: 2.5968273956483396

Epoch: 5| Step: 1
Training loss: 3.280637556776223
Validation loss: 2.5947875245676766

Epoch: 5| Step: 2
Training loss: 3.0460327549336066
Validation loss: 2.5961598423256156

Epoch: 5| Step: 3
Training loss: 3.018833331424967
Validation loss: 2.6011678040349664

Epoch: 5| Step: 4
Training loss: 2.7784377034733962
Validation loss: 2.604063723262479

Epoch: 5| Step: 5
Training loss: 2.904769520373639
Validation loss: 2.6220281882366496

Epoch: 5| Step: 6
Training loss: 3.065134589023478
Validation loss: 2.635120304332479

Epoch: 5| Step: 7
Training loss: 2.8700616966820123
Validation loss: 2.6171749334472896

Epoch: 5| Step: 8
Training loss: 2.5974893846193963
Validation loss: 2.607927450058314

Epoch: 5| Step: 9
Training loss: 3.357030289800523
Validation loss: 2.6039254045195293

Epoch: 5| Step: 10
Training loss: 3.188428855644247
Validation loss: 2.594948917646203

Epoch: 50| Step: 0
Training loss: 3.047233677806512
Validation loss: 2.593694008001576

Epoch: 5| Step: 1
Training loss: 2.170167320234765
Validation loss: 2.595309823702262

Epoch: 5| Step: 2
Training loss: 2.9956460192981766
Validation loss: 2.604929525230504

Epoch: 5| Step: 3
Training loss: 2.7665441677443137
Validation loss: 2.607242405652509

Epoch: 5| Step: 4
Training loss: 3.356149375728403
Validation loss: 2.6108720265305654

Epoch: 5| Step: 5
Training loss: 3.3583542803417923
Validation loss: 2.6073018735474327

Epoch: 5| Step: 6
Training loss: 3.0361574698962563
Validation loss: 2.603009115240432

Epoch: 5| Step: 7
Training loss: 2.9529887173001446
Validation loss: 2.6037887404018645

Epoch: 5| Step: 8
Training loss: 2.74549036464831
Validation loss: 2.605027555522648

Epoch: 5| Step: 9
Training loss: 3.161952089635591
Validation loss: 2.618810571057211

Epoch: 5| Step: 10
Training loss: 2.8584743394538994
Validation loss: 2.6084319501932995

Epoch: 51| Step: 0
Training loss: 3.157319142771526
Validation loss: 2.612263135912127

Epoch: 5| Step: 1
Training loss: 2.9945510015674754
Validation loss: 2.6313926714802287

Epoch: 5| Step: 2
Training loss: 3.191038075458116
Validation loss: 2.6803263805498627

Epoch: 5| Step: 3
Training loss: 3.057060861188208
Validation loss: 2.6867145421707015

Epoch: 5| Step: 4
Training loss: 2.7386443894541013
Validation loss: 2.6825931155474314

Epoch: 5| Step: 5
Training loss: 2.8854878734703315
Validation loss: 2.682253095853478

Epoch: 5| Step: 6
Training loss: 3.0020549411917967
Validation loss: 2.686220964092278

Epoch: 5| Step: 7
Training loss: 3.014202513737795
Validation loss: 2.676359844414336

Epoch: 5| Step: 8
Training loss: 3.268421928324171
Validation loss: 2.687591412862357

Epoch: 5| Step: 9
Training loss: 2.8701919488816934
Validation loss: 2.6551603781148128

Epoch: 5| Step: 10
Training loss: 2.5213466993784883
Validation loss: 2.647666097421454

Epoch: 52| Step: 0
Training loss: 3.110313848868689
Validation loss: 2.648009839928689

Epoch: 5| Step: 1
Training loss: 3.115053292395707
Validation loss: 2.6404143043861987

Epoch: 5| Step: 2
Training loss: 2.873009863640344
Validation loss: 2.645876258099471

Epoch: 5| Step: 3
Training loss: 2.6950610057316844
Validation loss: 2.644132398930747

Epoch: 5| Step: 4
Training loss: 2.9232350820155677
Validation loss: 2.6378445259005403

Epoch: 5| Step: 5
Training loss: 3.6182904467214816
Validation loss: 2.640092026913365

Epoch: 5| Step: 6
Training loss: 2.8372176042428756
Validation loss: 2.6362643584349614

Epoch: 5| Step: 7
Training loss: 2.936855488947978
Validation loss: 2.639560760482594

Epoch: 5| Step: 8
Training loss: 2.8800412636026085
Validation loss: 2.630823024844533

Epoch: 5| Step: 9
Training loss: 2.7621230027848918
Validation loss: 2.631454785670506

Epoch: 5| Step: 10
Training loss: 2.790255251457496
Validation loss: 2.621939962090925

Epoch: 53| Step: 0
Training loss: 2.8069690997927217
Validation loss: 2.6130657379716022

Epoch: 5| Step: 1
Training loss: 3.5264449384342575
Validation loss: 2.59247204278457

Epoch: 5| Step: 2
Training loss: 2.723352767317809
Validation loss: 2.5783178551299826

Epoch: 5| Step: 3
Training loss: 3.286887566556408
Validation loss: 2.5808303475590066

Epoch: 5| Step: 4
Training loss: 2.6471568924682733
Validation loss: 2.581154376404544

Epoch: 5| Step: 5
Training loss: 2.9656326792288947
Validation loss: 2.5882181757071354

Epoch: 5| Step: 6
Training loss: 2.7026016522538763
Validation loss: 2.589830060385763

Epoch: 5| Step: 7
Training loss: 2.8719280250477532
Validation loss: 2.5975869633916844

Epoch: 5| Step: 8
Training loss: 3.0724857006562787
Validation loss: 2.5904274564526104

Epoch: 5| Step: 9
Training loss: 3.133397834871459
Validation loss: 2.5803101229835086

Epoch: 5| Step: 10
Training loss: 2.560383457582012
Validation loss: 2.5866402555719388

Epoch: 54| Step: 0
Training loss: 3.422358648531338
Validation loss: 2.598709764989142

Epoch: 5| Step: 1
Training loss: 3.0366088062165972
Validation loss: 2.6360587565535685

Epoch: 5| Step: 2
Training loss: 2.6150070900757116
Validation loss: 2.6571679398545696

Epoch: 5| Step: 3
Training loss: 3.021969461000189
Validation loss: 2.649434326435953

Epoch: 5| Step: 4
Training loss: 2.9180004521579406
Validation loss: 2.607092321847795

Epoch: 5| Step: 5
Training loss: 2.8978831951330055
Validation loss: 2.585449327326352

Epoch: 5| Step: 6
Training loss: 2.961683516517955
Validation loss: 2.5810790757220228

Epoch: 5| Step: 7
Training loss: 2.7532405833339006
Validation loss: 2.5727686582668503

Epoch: 5| Step: 8
Training loss: 2.8086057193166805
Validation loss: 2.57143331009011

Epoch: 5| Step: 9
Training loss: 2.616423811444964
Validation loss: 2.5759967410836957

Epoch: 5| Step: 10
Training loss: 3.254106714638275
Validation loss: 2.5763723213690524

Epoch: 55| Step: 0
Training loss: 3.0192916794818903
Validation loss: 2.5808169334680167

Epoch: 5| Step: 1
Training loss: 3.1796477594165053
Validation loss: 2.5786440578182863

Epoch: 5| Step: 2
Training loss: 3.131107617946265
Validation loss: 2.5819904453925018

Epoch: 5| Step: 3
Training loss: 2.9581267772792534
Validation loss: 2.57895391071351

Epoch: 5| Step: 4
Training loss: 2.9928087829522148
Validation loss: 2.5721407072239537

Epoch: 5| Step: 5
Training loss: 2.5138439247039575
Validation loss: 2.572455209162162

Epoch: 5| Step: 6
Training loss: 2.796329210614906
Validation loss: 2.571619398684476

Epoch: 5| Step: 7
Training loss: 3.0837601718495153
Validation loss: 2.569000573598316

Epoch: 5| Step: 8
Training loss: 2.955722211697948
Validation loss: 2.5724292273638016

Epoch: 5| Step: 9
Training loss: 2.5547902497793107
Validation loss: 2.603896997743129

Epoch: 5| Step: 10
Training loss: 3.1840944235808726
Validation loss: 2.619659050247173

Epoch: 56| Step: 0
Training loss: 2.7538406256032943
Validation loss: 2.635574349397514

Epoch: 5| Step: 1
Training loss: 3.280563137280041
Validation loss: 2.658213376830324

Epoch: 5| Step: 2
Training loss: 2.347545856032017
Validation loss: 2.6762890444008893

Epoch: 5| Step: 3
Training loss: 2.9549561328504206
Validation loss: 2.666083778490748

Epoch: 5| Step: 4
Training loss: 2.7414074954021643
Validation loss: 2.654707963020795

Epoch: 5| Step: 5
Training loss: 2.9455208540258995
Validation loss: 2.644269214617117

Epoch: 5| Step: 6
Training loss: 3.0685940269719882
Validation loss: 2.6149028446720792

Epoch: 5| Step: 7
Training loss: 2.562864231182441
Validation loss: 2.604169444092941

Epoch: 5| Step: 8
Training loss: 3.2732564288840793
Validation loss: 2.603778880790164

Epoch: 5| Step: 9
Training loss: 3.2734230787737975
Validation loss: 2.610453841873891

Epoch: 5| Step: 10
Training loss: 3.384734631818576
Validation loss: 2.614944229806522

Epoch: 57| Step: 0
Training loss: 1.8254064577617248
Validation loss: 2.605596335158033

Epoch: 5| Step: 1
Training loss: 2.74851811102649
Validation loss: 2.6016798622683974

Epoch: 5| Step: 2
Training loss: 3.2077139384517284
Validation loss: 2.5964681025802876

Epoch: 5| Step: 3
Training loss: 3.119787217244758
Validation loss: 2.599205026260836

Epoch: 5| Step: 4
Training loss: 2.814542579685255
Validation loss: 2.60118457843255

Epoch: 5| Step: 5
Training loss: 2.978219279571179
Validation loss: 2.58696371327595

Epoch: 5| Step: 6
Training loss: 3.217367819891994
Validation loss: 2.5679912321854474

Epoch: 5| Step: 7
Training loss: 3.2605475418750065
Validation loss: 2.6242917487798474

Epoch: 5| Step: 8
Training loss: 3.0846924406840435
Validation loss: 2.6240490872298494

Epoch: 5| Step: 9
Training loss: 3.0891915077820813
Validation loss: 2.566945928998281

Epoch: 5| Step: 10
Training loss: 2.7856390963876647
Validation loss: 2.563261880771542

Epoch: 58| Step: 0
Training loss: 3.0525095949014367
Validation loss: 2.5615302901501438

Epoch: 5| Step: 1
Training loss: 2.723344975714698
Validation loss: 2.5624568894564357

Epoch: 5| Step: 2
Training loss: 3.430209665368674
Validation loss: 2.571320587254463

Epoch: 5| Step: 3
Training loss: 3.072980114987628
Validation loss: 2.584139994361186

Epoch: 5| Step: 4
Training loss: 3.009882068795088
Validation loss: 2.596667826333955

Epoch: 5| Step: 5
Training loss: 2.677832492447013
Validation loss: 2.59560217851232

Epoch: 5| Step: 6
Training loss: 2.7942973784755747
Validation loss: 2.5998960498273824

Epoch: 5| Step: 7
Training loss: 3.2943604629245073
Validation loss: 2.5876700816770173

Epoch: 5| Step: 8
Training loss: 2.746088627556789
Validation loss: 2.5835640897178616

Epoch: 5| Step: 9
Training loss: 2.7655410322815515
Validation loss: 2.5662020321729995

Epoch: 5| Step: 10
Training loss: 2.542017792592181
Validation loss: 2.5755203737961723

Epoch: 59| Step: 0
Training loss: 2.730189755311177
Validation loss: 2.59909042156562

Epoch: 5| Step: 1
Training loss: 3.026395705889752
Validation loss: 2.5932498197075393

Epoch: 5| Step: 2
Training loss: 2.975161084854896
Validation loss: 2.583647935733466

Epoch: 5| Step: 3
Training loss: 2.5600084426859877
Validation loss: 2.566979042091826

Epoch: 5| Step: 4
Training loss: 2.8116623372796656
Validation loss: 2.5636161586334874

Epoch: 5| Step: 5
Training loss: 2.879047861330129
Validation loss: 2.5589475380695776

Epoch: 5| Step: 6
Training loss: 2.868349427158291
Validation loss: 2.5631730101013175

Epoch: 5| Step: 7
Training loss: 2.6618920935148913
Validation loss: 2.5608922365140163

Epoch: 5| Step: 8
Training loss: 2.8691688780305666
Validation loss: 2.5680967818907052

Epoch: 5| Step: 9
Training loss: 3.3077260290347956
Validation loss: 2.570391997874495

Epoch: 5| Step: 10
Training loss: 3.488551899319838
Validation loss: 2.5729732476484206

Epoch: 60| Step: 0
Training loss: 3.0790083339041914
Validation loss: 2.573067922249258

Epoch: 5| Step: 1
Training loss: 2.5974200836899692
Validation loss: 2.5644689689296554

Epoch: 5| Step: 2
Training loss: 2.729811866342177
Validation loss: 2.5667467680397684

Epoch: 5| Step: 3
Training loss: 2.6572105914739628
Validation loss: 2.566951628643411

Epoch: 5| Step: 4
Training loss: 2.774000857451402
Validation loss: 2.567366236642391

Epoch: 5| Step: 5
Training loss: 2.953991152378849
Validation loss: 2.566563797199611

Epoch: 5| Step: 6
Training loss: 3.3021800671837926
Validation loss: 2.570958840424543

Epoch: 5| Step: 7
Training loss: 3.4053475120545986
Validation loss: 2.5700811895492603

Epoch: 5| Step: 8
Training loss: 2.5807953847530505
Validation loss: 2.5720709136831394

Epoch: 5| Step: 9
Training loss: 3.2318581634124244
Validation loss: 2.57855242147208

Epoch: 5| Step: 10
Training loss: 2.721529274497973
Validation loss: 2.605085756280194

Epoch: 61| Step: 0
Training loss: 2.9641553157417113
Validation loss: 2.631008377811379

Epoch: 5| Step: 1
Training loss: 2.8080725683687118
Validation loss: 2.598568347597247

Epoch: 5| Step: 2
Training loss: 2.674188337451227
Validation loss: 2.5739797380712184

Epoch: 5| Step: 3
Training loss: 3.3410225555836863
Validation loss: 2.5665051354168775

Epoch: 5| Step: 4
Training loss: 3.3113019684126037
Validation loss: 2.5610511159204545

Epoch: 5| Step: 5
Training loss: 2.842431066477388
Validation loss: 2.564940095414772

Epoch: 5| Step: 6
Training loss: 3.249883796375096
Validation loss: 2.561862713242798

Epoch: 5| Step: 7
Training loss: 2.396790376882754
Validation loss: 2.5608705952217194

Epoch: 5| Step: 8
Training loss: 2.905567376149407
Validation loss: 2.558614089961373

Epoch: 5| Step: 9
Training loss: 2.8553184542782257
Validation loss: 2.554411719042397

Epoch: 5| Step: 10
Training loss: 2.7672629812964664
Validation loss: 2.553579201866311

Epoch: 62| Step: 0
Training loss: 2.524595012857086
Validation loss: 2.5564448078435404

Epoch: 5| Step: 1
Training loss: 3.347801677166841
Validation loss: 2.560434531964692

Epoch: 5| Step: 2
Training loss: 2.8344349309101236
Validation loss: 2.565019668845588

Epoch: 5| Step: 3
Training loss: 2.5442710623973688
Validation loss: 2.569788787466547

Epoch: 5| Step: 4
Training loss: 2.60566301207839
Validation loss: 2.5801418784345382

Epoch: 5| Step: 5
Training loss: 2.5076042873188316
Validation loss: 2.583882107502695

Epoch: 5| Step: 6
Training loss: 2.918342127268417
Validation loss: 2.601450366251569

Epoch: 5| Step: 7
Training loss: 3.384846487691762
Validation loss: 2.5628421674054316

Epoch: 5| Step: 8
Training loss: 2.9704217319781554
Validation loss: 2.5525032081458097

Epoch: 5| Step: 9
Training loss: 3.07456787918852
Validation loss: 2.5522368762647307

Epoch: 5| Step: 10
Training loss: 3.2200064567832896
Validation loss: 2.5517821130210487

Epoch: 63| Step: 0
Training loss: 2.713672061259575
Validation loss: 2.5491991147054978

Epoch: 5| Step: 1
Training loss: 2.552668622431683
Validation loss: 2.5491886778915096

Epoch: 5| Step: 2
Training loss: 2.6472319163033426
Validation loss: 2.5546966258544535

Epoch: 5| Step: 3
Training loss: 3.1425429224255805
Validation loss: 2.5574384678564837

Epoch: 5| Step: 4
Training loss: 2.928236619904279
Validation loss: 2.565066379293568

Epoch: 5| Step: 5
Training loss: 2.800691866545738
Validation loss: 2.5670211988481277

Epoch: 5| Step: 6
Training loss: 3.0376032682218894
Validation loss: 2.5609590212419397

Epoch: 5| Step: 7
Training loss: 3.403104116832878
Validation loss: 2.5464365692712954

Epoch: 5| Step: 8
Training loss: 2.528173955907814
Validation loss: 2.5420413027793654

Epoch: 5| Step: 9
Training loss: 3.0638597544851507
Validation loss: 2.5457532707337287

Epoch: 5| Step: 10
Training loss: 3.1603940442825667
Validation loss: 2.555433927121753

Epoch: 64| Step: 0
Training loss: 2.6678111977924246
Validation loss: 2.573315430139544

Epoch: 5| Step: 1
Training loss: 2.950014605728458
Validation loss: 2.598432939851849

Epoch: 5| Step: 2
Training loss: 2.8092437543752915
Validation loss: 2.6256566122503524

Epoch: 5| Step: 3
Training loss: 2.8389244638077384
Validation loss: 2.6055251708224207

Epoch: 5| Step: 4
Training loss: 3.2896287299308007
Validation loss: 2.574013422999392

Epoch: 5| Step: 5
Training loss: 2.417636139753446
Validation loss: 2.544868438267726

Epoch: 5| Step: 6
Training loss: 2.6075255641250994
Validation loss: 2.5432838847160837

Epoch: 5| Step: 7
Training loss: 3.663129935919445
Validation loss: 2.5330365529168057

Epoch: 5| Step: 8
Training loss: 2.662351982049793
Validation loss: 2.5331181810731938

Epoch: 5| Step: 9
Training loss: 2.7403097217122454
Validation loss: 2.5363673998858713

Epoch: 5| Step: 10
Training loss: 3.2159109094150793
Validation loss: 2.5363599314218996

Epoch: 65| Step: 0
Training loss: 3.3474568293140234
Validation loss: 2.5421113671321556

Epoch: 5| Step: 1
Training loss: 2.8486286277073307
Validation loss: 2.5373994586803303

Epoch: 5| Step: 2
Training loss: 2.528907539713816
Validation loss: 2.54633559617306

Epoch: 5| Step: 3
Training loss: 2.395398329897245
Validation loss: 2.5530920838118525

Epoch: 5| Step: 4
Training loss: 3.0386055649420634
Validation loss: 2.5604032676747557

Epoch: 5| Step: 5
Training loss: 2.6169542806536095
Validation loss: 2.5771172953983337

Epoch: 5| Step: 6
Training loss: 2.620001984806619
Validation loss: 2.598062132426941

Epoch: 5| Step: 7
Training loss: 3.4037289870752128
Validation loss: 2.6052816174075546

Epoch: 5| Step: 8
Training loss: 3.047622823641913
Validation loss: 2.627748936856754

Epoch: 5| Step: 9
Training loss: 3.070241369146624
Validation loss: 2.6704055409616045

Epoch: 5| Step: 10
Training loss: 2.976031238473993
Validation loss: 2.6601952590938414

Epoch: 66| Step: 0
Training loss: 2.961248295961842
Validation loss: 2.636746029243655

Epoch: 5| Step: 1
Training loss: 3.536990470720245
Validation loss: 2.6255967789547787

Epoch: 5| Step: 2
Training loss: 2.570377615709666
Validation loss: 2.6055711305248708

Epoch: 5| Step: 3
Training loss: 2.6988108170738796
Validation loss: 2.599429236080669

Epoch: 5| Step: 4
Training loss: 3.0378829902983657
Validation loss: 2.588067460181767

Epoch: 5| Step: 5
Training loss: 2.8211514818046504
Validation loss: 2.591857001926161

Epoch: 5| Step: 6
Training loss: 2.4526861490732386
Validation loss: 2.5760881488913694

Epoch: 5| Step: 7
Training loss: 3.1480848999983557
Validation loss: 2.5778049840907022

Epoch: 5| Step: 8
Training loss: 2.512136753830549
Validation loss: 2.60404845299619

Epoch: 5| Step: 9
Training loss: 2.904521140782242
Validation loss: 2.6005557700732544

Epoch: 5| Step: 10
Training loss: 3.4991806978684954
Validation loss: 2.607476082681126

Epoch: 67| Step: 0
Training loss: 3.2393392162197614
Validation loss: 2.6029861054858596

Epoch: 5| Step: 1
Training loss: 2.6177741005394406
Validation loss: 2.5900687860174485

Epoch: 5| Step: 2
Training loss: 3.244096235491764
Validation loss: 2.601731973513591

Epoch: 5| Step: 3
Training loss: 2.470435231276787
Validation loss: 2.591125161371969

Epoch: 5| Step: 4
Training loss: 3.1939294335411406
Validation loss: 2.592452526199166

Epoch: 5| Step: 5
Training loss: 2.8109123835308285
Validation loss: 2.5953607481165526

Epoch: 5| Step: 6
Training loss: 2.850371647745858
Validation loss: 2.5872316506764674

Epoch: 5| Step: 7
Training loss: 2.9136689357535617
Validation loss: 2.580766767090066

Epoch: 5| Step: 8
Training loss: 3.2801229812082635
Validation loss: 2.5697374410918035

Epoch: 5| Step: 9
Training loss: 2.520063950166195
Validation loss: 2.561862655202545

Epoch: 5| Step: 10
Training loss: 2.7986689946257477
Validation loss: 2.5618572054171236

Epoch: 68| Step: 0
Training loss: 2.7136935864545486
Validation loss: 2.5635741288876703

Epoch: 5| Step: 1
Training loss: 3.457363099803351
Validation loss: 2.5547482113063795

Epoch: 5| Step: 2
Training loss: 2.4222902987865553
Validation loss: 2.5507147169023714

Epoch: 5| Step: 3
Training loss: 3.0581977363760164
Validation loss: 2.551826820432376

Epoch: 5| Step: 4
Training loss: 2.9769463078914202
Validation loss: 2.5475346219196013

Epoch: 5| Step: 5
Training loss: 3.0700736304782037
Validation loss: 2.5496193907584597

Epoch: 5| Step: 6
Training loss: 3.184787568534117
Validation loss: 2.5469166782274812

Epoch: 5| Step: 7
Training loss: 2.4941235140674314
Validation loss: 2.54140678830868

Epoch: 5| Step: 8
Training loss: 2.6534929215858116
Validation loss: 2.5456365567248618

Epoch: 5| Step: 9
Training loss: 3.0398465986196817
Validation loss: 2.5438115322345087

Epoch: 5| Step: 10
Training loss: 2.7594637587583715
Validation loss: 2.5443670921511012

Epoch: 69| Step: 0
Training loss: 3.1203505451173372
Validation loss: 2.546046956050891

Epoch: 5| Step: 1
Training loss: 2.8478749299822295
Validation loss: 2.547882128569558

Epoch: 5| Step: 2
Training loss: 2.690272121350192
Validation loss: 2.5312597856189396

Epoch: 5| Step: 3
Training loss: 2.8661851508103218
Validation loss: 2.5219378772354633

Epoch: 5| Step: 4
Training loss: 2.925163662236132
Validation loss: 2.516894174810564

Epoch: 5| Step: 5
Training loss: 2.7541184363900943
Validation loss: 2.5154997144056024

Epoch: 5| Step: 6
Training loss: 2.8040032787439872
Validation loss: 2.511911545472709

Epoch: 5| Step: 7
Training loss: 2.8337397190440914
Validation loss: 2.5159591873712546

Epoch: 5| Step: 8
Training loss: 2.8843149957997163
Validation loss: 2.5178683563365722

Epoch: 5| Step: 9
Training loss: 2.753004340343331
Validation loss: 2.5247455024777836

Epoch: 5| Step: 10
Training loss: 3.370614204467258
Validation loss: 2.533527619106744

Epoch: 70| Step: 0
Training loss: 2.842140664610758
Validation loss: 2.5319888992302104

Epoch: 5| Step: 1
Training loss: 3.148629232394761
Validation loss: 2.540830861742691

Epoch: 5| Step: 2
Training loss: 3.4365506335063407
Validation loss: 2.5496953862721097

Epoch: 5| Step: 3
Training loss: 2.568235630782056
Validation loss: 2.588393368156669

Epoch: 5| Step: 4
Training loss: 3.0227378015862825
Validation loss: 2.596657961404129

Epoch: 5| Step: 5
Training loss: 2.682533287844359
Validation loss: 2.6066430974877277

Epoch: 5| Step: 6
Training loss: 2.233632851438852
Validation loss: 2.5842774217818607

Epoch: 5| Step: 7
Training loss: 2.6717826425752262
Validation loss: 2.540262226293428

Epoch: 5| Step: 8
Training loss: 2.6770386351974076
Validation loss: 2.5176964126175663

Epoch: 5| Step: 9
Training loss: 2.864885700335839
Validation loss: 2.5080890259634723

Epoch: 5| Step: 10
Training loss: 3.47361826149609
Validation loss: 2.511149456790003

Epoch: 71| Step: 0
Training loss: 2.6129489567673123
Validation loss: 2.516271967219227

Epoch: 5| Step: 1
Training loss: 2.561208446011073
Validation loss: 2.5182448660454506

Epoch: 5| Step: 2
Training loss: 3.183228266981027
Validation loss: 2.5171203133381495

Epoch: 5| Step: 3
Training loss: 2.7776898518527835
Validation loss: 2.5172350813723

Epoch: 5| Step: 4
Training loss: 3.0941114118227824
Validation loss: 2.515094495032246

Epoch: 5| Step: 5
Training loss: 2.913595944606969
Validation loss: 2.5123712435358576

Epoch: 5| Step: 6
Training loss: 3.0273779294945524
Validation loss: 2.512948993155665

Epoch: 5| Step: 7
Training loss: 2.954303486125751
Validation loss: 2.516180066003177

Epoch: 5| Step: 8
Training loss: 2.7705007559061525
Validation loss: 2.512834535392594

Epoch: 5| Step: 9
Training loss: 2.852577509583421
Validation loss: 2.5110209197396474

Epoch: 5| Step: 10
Training loss: 3.0922047773112733
Validation loss: 2.5148563799296784

Epoch: 72| Step: 0
Training loss: 2.848841709537147
Validation loss: 2.5258234097002346

Epoch: 5| Step: 1
Training loss: 2.701517674618631
Validation loss: 2.5570698360292146

Epoch: 5| Step: 2
Training loss: 2.8332941015182738
Validation loss: 2.5810677845024843

Epoch: 5| Step: 3
Training loss: 2.973774402673822
Validation loss: 2.58356129741684

Epoch: 5| Step: 4
Training loss: 2.8386488214734897
Validation loss: 2.557951417007705

Epoch: 5| Step: 5
Training loss: 2.9402564893154177
Validation loss: 2.555886080177488

Epoch: 5| Step: 6
Training loss: 2.819306677681991
Validation loss: 2.5316981956044184

Epoch: 5| Step: 7
Training loss: 2.9765886120389267
Validation loss: 2.513064546421145

Epoch: 5| Step: 8
Training loss: 2.8957824885526713
Validation loss: 2.5096863436738612

Epoch: 5| Step: 9
Training loss: 2.924508443104424
Validation loss: 2.5139154041394955

Epoch: 5| Step: 10
Training loss: 2.764142086075783
Validation loss: 2.511626122321198

Epoch: 73| Step: 0
Training loss: 3.165855671950337
Validation loss: 2.5119651393282663

Epoch: 5| Step: 1
Training loss: 2.83663956960548
Validation loss: 2.5063963561467575

Epoch: 5| Step: 2
Training loss: 2.5720741241239127
Validation loss: 2.503966417738839

Epoch: 5| Step: 3
Training loss: 2.3592197796623355
Validation loss: 2.5058590864974972

Epoch: 5| Step: 4
Training loss: 3.174061589970918
Validation loss: 2.5098038581868534

Epoch: 5| Step: 5
Training loss: 3.024856589204504
Validation loss: 2.507027074555954

Epoch: 5| Step: 6
Training loss: 3.470843671315441
Validation loss: 2.5121024871799658

Epoch: 5| Step: 7
Training loss: 2.8448427217852195
Validation loss: 2.5144381726314973

Epoch: 5| Step: 8
Training loss: 3.021890564871529
Validation loss: 2.5212597799422864

Epoch: 5| Step: 9
Training loss: 2.6129282440657406
Validation loss: 2.5239620016047994

Epoch: 5| Step: 10
Training loss: 2.2941930774295956
Validation loss: 2.517689791957011

Epoch: 74| Step: 0
Training loss: 2.6920820697103856
Validation loss: 2.519923355486891

Epoch: 5| Step: 1
Training loss: 3.073978787936586
Validation loss: 2.5169143333095354

Epoch: 5| Step: 2
Training loss: 2.3308082837079525
Validation loss: 2.5254596123766833

Epoch: 5| Step: 3
Training loss: 3.4111642647687535
Validation loss: 2.5322784902813353

Epoch: 5| Step: 4
Training loss: 3.1287506483917844
Validation loss: 2.507943793809609

Epoch: 5| Step: 5
Training loss: 2.6812371313679932
Validation loss: 2.4993116046281556

Epoch: 5| Step: 6
Training loss: 2.5864628837218695
Validation loss: 2.4989251553911553

Epoch: 5| Step: 7
Training loss: 2.9327895361235523
Validation loss: 2.4997290228554925

Epoch: 5| Step: 8
Training loss: 2.859045958217309
Validation loss: 2.5031195640364117

Epoch: 5| Step: 9
Training loss: 3.0221726879411284
Validation loss: 2.504307304441978

Epoch: 5| Step: 10
Training loss: 2.7504407356117135
Validation loss: 2.503934931127266

Epoch: 75| Step: 0
Training loss: 2.494640422741449
Validation loss: 2.5056248892603397

Epoch: 5| Step: 1
Training loss: 2.4952586035022604
Validation loss: 2.502591434842599

Epoch: 5| Step: 2
Training loss: 3.399362582874712
Validation loss: 2.507023841149742

Epoch: 5| Step: 3
Training loss: 2.4012730639341466
Validation loss: 2.5090122879051053

Epoch: 5| Step: 4
Training loss: 3.0140677270601706
Validation loss: 2.515101974658577

Epoch: 5| Step: 5
Training loss: 2.922298951424892
Validation loss: 2.519611051299983

Epoch: 5| Step: 6
Training loss: 2.9302309066349586
Validation loss: 2.5213200099274813

Epoch: 5| Step: 7
Training loss: 3.1370577314303842
Validation loss: 2.5233278856795596

Epoch: 5| Step: 8
Training loss: 3.01120287562607
Validation loss: 2.5190204951965254

Epoch: 5| Step: 9
Training loss: 2.7175874526508204
Validation loss: 2.5212414956094173

Epoch: 5| Step: 10
Training loss: 2.8852325454156182
Validation loss: 2.537305290049846

Epoch: 76| Step: 0
Training loss: 3.2146590818296947
Validation loss: 2.5232538565165314

Epoch: 5| Step: 1
Training loss: 2.529217221688577
Validation loss: 2.514138247804459

Epoch: 5| Step: 2
Training loss: 2.7487200445925595
Validation loss: 2.512331990731643

Epoch: 5| Step: 3
Training loss: 2.9405185530203237
Validation loss: 2.5005838132926184

Epoch: 5| Step: 4
Training loss: 2.3893634733799636
Validation loss: 2.4989544333034375

Epoch: 5| Step: 5
Training loss: 2.8723553642864452
Validation loss: 2.497492089634762

Epoch: 5| Step: 6
Training loss: 2.7835249437023437
Validation loss: 2.495941384953107

Epoch: 5| Step: 7
Training loss: 3.1494317768397164
Validation loss: 2.4981001054100114

Epoch: 5| Step: 8
Training loss: 2.2765971770882247
Validation loss: 2.5025134275303444

Epoch: 5| Step: 9
Training loss: 3.068728749498803
Validation loss: 2.5134611653294177

Epoch: 5| Step: 10
Training loss: 3.49385798906683
Validation loss: 2.5305825177178276

Epoch: 77| Step: 0
Training loss: 2.965286000756787
Validation loss: 2.551812917326131

Epoch: 5| Step: 1
Training loss: 2.8907313971656174
Validation loss: 2.5897311751620244

Epoch: 5| Step: 2
Training loss: 2.495759323712564
Validation loss: 2.609469972959679

Epoch: 5| Step: 3
Training loss: 3.170497350817074
Validation loss: 2.623877871950741

Epoch: 5| Step: 4
Training loss: 2.993767622416003
Validation loss: 2.5782707165717835

Epoch: 5| Step: 5
Training loss: 2.576063777110387
Validation loss: 2.529635029781765

Epoch: 5| Step: 6
Training loss: 2.7103288390472997
Validation loss: 2.5154961270382814

Epoch: 5| Step: 7
Training loss: 2.9632911687997225
Validation loss: 2.5078215367770262

Epoch: 5| Step: 8
Training loss: 2.8756272005015964
Validation loss: 2.498946337003481

Epoch: 5| Step: 9
Training loss: 3.0450073778285454
Validation loss: 2.4985563344992414

Epoch: 5| Step: 10
Training loss: 2.835590772214111
Validation loss: 2.5027413340824993

Epoch: 78| Step: 0
Training loss: 2.4322890309572065
Validation loss: 2.495078977912724

Epoch: 5| Step: 1
Training loss: 2.6653893709854857
Validation loss: 2.4962698149182336

Epoch: 5| Step: 2
Training loss: 3.0392157900868737
Validation loss: 2.498528737739316

Epoch: 5| Step: 3
Training loss: 2.696512944571507
Validation loss: 2.500926708412244

Epoch: 5| Step: 4
Training loss: 2.713369108974912
Validation loss: 2.5136085111717796

Epoch: 5| Step: 5
Training loss: 3.1131945589600525
Validation loss: 2.5318298536562063

Epoch: 5| Step: 6
Training loss: 2.35617748118546
Validation loss: 2.539479012352031

Epoch: 5| Step: 7
Training loss: 3.6225261797330828
Validation loss: 2.558189551414339

Epoch: 5| Step: 8
Training loss: 2.838779675132488
Validation loss: 2.531810589546269

Epoch: 5| Step: 9
Training loss: 2.6682301249450555
Validation loss: 2.5021169795068094

Epoch: 5| Step: 10
Training loss: 3.24209278381981
Validation loss: 2.49347133937705

Epoch: 79| Step: 0
Training loss: 2.5041893190532543
Validation loss: 2.4922688850515002

Epoch: 5| Step: 1
Training loss: 2.668604226341123
Validation loss: 2.4875450483078874

Epoch: 5| Step: 2
Training loss: 2.9288613744082337
Validation loss: 2.4903951659822825

Epoch: 5| Step: 3
Training loss: 2.8836615741270126
Validation loss: 2.487684864610292

Epoch: 5| Step: 4
Training loss: 3.313749545517138
Validation loss: 2.488006849177363

Epoch: 5| Step: 5
Training loss: 2.7361868822565043
Validation loss: 2.491797723621733

Epoch: 5| Step: 6
Training loss: 3.1388143757515836
Validation loss: 2.4895375373229944

Epoch: 5| Step: 7
Training loss: 2.834494988405242
Validation loss: 2.4930084364903595

Epoch: 5| Step: 8
Training loss: 2.909782969453442
Validation loss: 2.499981218698157

Epoch: 5| Step: 9
Training loss: 2.4770266702607597
Validation loss: 2.50326670032983

Epoch: 5| Step: 10
Training loss: 2.9615283064615716
Validation loss: 2.5120086234726324

Epoch: 80| Step: 0
Training loss: 2.786504518120219
Validation loss: 2.5328750488354053

Epoch: 5| Step: 1
Training loss: 3.102529379853871
Validation loss: 2.5306882631227596

Epoch: 5| Step: 2
Training loss: 2.9350026654778874
Validation loss: 2.56094973250893

Epoch: 5| Step: 3
Training loss: 2.606573371128215
Validation loss: 2.569659540170838

Epoch: 5| Step: 4
Training loss: 3.0771083024100307
Validation loss: 2.588663250157953

Epoch: 5| Step: 5
Training loss: 2.853014098369583
Validation loss: 2.5711534036386077

Epoch: 5| Step: 6
Training loss: 2.6255581580255116
Validation loss: 2.5391411942497

Epoch: 5| Step: 7
Training loss: 2.951181084790808
Validation loss: 2.516518676319353

Epoch: 5| Step: 8
Training loss: 2.7051505729806538
Validation loss: 2.505955992824532

Epoch: 5| Step: 9
Training loss: 2.4923094716613665
Validation loss: 2.4901192870339277

Epoch: 5| Step: 10
Training loss: 3.209829171647181
Validation loss: 2.489681290539059

Epoch: 81| Step: 0
Training loss: 2.79385067547145
Validation loss: 2.4913494552545123

Epoch: 5| Step: 1
Training loss: 2.2463788456972247
Validation loss: 2.4950121662398037

Epoch: 5| Step: 2
Training loss: 2.621331512537208
Validation loss: 2.4920169971173927

Epoch: 5| Step: 3
Training loss: 2.9770203085640077
Validation loss: 2.488779741932569

Epoch: 5| Step: 4
Training loss: 2.9571376766267394
Validation loss: 2.4888450923992074

Epoch: 5| Step: 5
Training loss: 2.8253601216025443
Validation loss: 2.4863869771470415

Epoch: 5| Step: 6
Training loss: 2.8929963154088596
Validation loss: 2.4995476733955635

Epoch: 5| Step: 7
Training loss: 3.2033682381921076
Validation loss: 2.510580773789907

Epoch: 5| Step: 8
Training loss: 2.728463021537932
Validation loss: 2.5231146700386473

Epoch: 5| Step: 9
Training loss: 3.1544912744855806
Validation loss: 2.5607123683731214

Epoch: 5| Step: 10
Training loss: 3.3354816348634317
Validation loss: 2.5650716903343826

Epoch: 82| Step: 0
Training loss: 2.6458963902285944
Validation loss: 2.534281894003414

Epoch: 5| Step: 1
Training loss: 3.518862035129799
Validation loss: 2.496448918385357

Epoch: 5| Step: 2
Training loss: 3.3237531001896796
Validation loss: 2.483086878749358

Epoch: 5| Step: 3
Training loss: 2.7912784610156565
Validation loss: 2.489220621140486

Epoch: 5| Step: 4
Training loss: 3.0096458495391842
Validation loss: 2.4993524297207133

Epoch: 5| Step: 5
Training loss: 2.9482907079271725
Validation loss: 2.5100488963077296

Epoch: 5| Step: 6
Training loss: 2.73049546912222
Validation loss: 2.5167964805524834

Epoch: 5| Step: 7
Training loss: 3.005951382404397
Validation loss: 2.5396278073871272

Epoch: 5| Step: 8
Training loss: 2.7854258017626754
Validation loss: 2.549163182037486

Epoch: 5| Step: 9
Training loss: 2.652035410154138
Validation loss: 2.547387944224286

Epoch: 5| Step: 10
Training loss: 2.6522019900387632
Validation loss: 2.543555761151763

Epoch: 83| Step: 0
Training loss: 3.384772950619597
Validation loss: 2.5416841306310003

Epoch: 5| Step: 1
Training loss: 3.3219030542346353
Validation loss: 2.5372246463582147

Epoch: 5| Step: 2
Training loss: 3.027328944016213
Validation loss: 2.5333167970821435

Epoch: 5| Step: 3
Training loss: 3.1849058478076575
Validation loss: 2.5318718514391843

Epoch: 5| Step: 4
Training loss: 2.5588446807116103
Validation loss: 2.52579133434395

Epoch: 5| Step: 5
Training loss: 2.43894377767116
Validation loss: 2.5243008365152457

Epoch: 5| Step: 6
Training loss: 2.885003639893244
Validation loss: 2.523947362994567

Epoch: 5| Step: 7
Training loss: 2.9987536066438296
Validation loss: 2.5199808543595066

Epoch: 5| Step: 8
Training loss: 2.594265438478338
Validation loss: 2.5206337472376323

Epoch: 5| Step: 9
Training loss: 2.4835988877763193
Validation loss: 2.526393956562711

Epoch: 5| Step: 10
Training loss: 2.721101993150736
Validation loss: 2.5532571898531295

Epoch: 84| Step: 0
Training loss: 3.0901514568061184
Validation loss: 2.5889932271553313

Epoch: 5| Step: 1
Training loss: 3.453923335935883
Validation loss: 2.5627060023795245

Epoch: 5| Step: 2
Training loss: 3.0197671696929342
Validation loss: 2.5299608134640814

Epoch: 5| Step: 3
Training loss: 2.880898768268801
Validation loss: 2.5194307427257727

Epoch: 5| Step: 4
Training loss: 2.951899521479705
Validation loss: 2.510729334252429

Epoch: 5| Step: 5
Training loss: 2.959808214779114
Validation loss: 2.5054843407645517

Epoch: 5| Step: 6
Training loss: 2.6573237324605183
Validation loss: 2.514151617939002

Epoch: 5| Step: 7
Training loss: 2.3116543228747624
Validation loss: 2.5107199515852114

Epoch: 5| Step: 8
Training loss: 2.9579088327365266
Validation loss: 2.5143410263182124

Epoch: 5| Step: 9
Training loss: 2.9553687235770365
Validation loss: 2.510765968080874

Epoch: 5| Step: 10
Training loss: 2.269389215381238
Validation loss: 2.5165240246202263

Epoch: 85| Step: 0
Training loss: 3.1714505818362966
Validation loss: 2.523830056027506

Epoch: 5| Step: 1
Training loss: 2.7807500154083176
Validation loss: 2.5340366841398043

Epoch: 5| Step: 2
Training loss: 3.047313482571094
Validation loss: 2.580613077192416

Epoch: 5| Step: 3
Training loss: 3.348145065318701
Validation loss: 2.597596981714949

Epoch: 5| Step: 4
Training loss: 2.262494785871873
Validation loss: 2.5695350554132736

Epoch: 5| Step: 5
Training loss: 3.1567892992421225
Validation loss: 2.5497488465185083

Epoch: 5| Step: 6
Training loss: 2.990988548448195
Validation loss: 2.549835240210676

Epoch: 5| Step: 7
Training loss: 2.3605455943016858
Validation loss: 2.571391785974289

Epoch: 5| Step: 8
Training loss: 2.8712347502048123
Validation loss: 2.5601169771613033

Epoch: 5| Step: 9
Training loss: 2.841370310017239
Validation loss: 2.6247821694041056

Epoch: 5| Step: 10
Training loss: 2.72481430540916
Validation loss: 2.5567411856080575

Epoch: 86| Step: 0
Training loss: 2.974833469378114
Validation loss: 2.5499991878385173

Epoch: 5| Step: 1
Training loss: 2.9980223813128113
Validation loss: 2.5327708350749014

Epoch: 5| Step: 2
Training loss: 2.4938922659847154
Validation loss: 2.5212503581688135

Epoch: 5| Step: 3
Training loss: 2.929659179550617
Validation loss: 2.526003746574378

Epoch: 5| Step: 4
Training loss: 2.8394222655110464
Validation loss: 2.5457560581811514

Epoch: 5| Step: 5
Training loss: 2.728987437956327
Validation loss: 2.585274421272035

Epoch: 5| Step: 6
Training loss: 3.308175629156827
Validation loss: 2.5928212853185295

Epoch: 5| Step: 7
Training loss: 2.778453835763384
Validation loss: 2.53055198076225

Epoch: 5| Step: 8
Training loss: 2.766203135607555
Validation loss: 2.51120908295718

Epoch: 5| Step: 9
Training loss: 2.692895662640074
Validation loss: 2.5060175297318814

Epoch: 5| Step: 10
Training loss: 3.131293558819017
Validation loss: 2.513299087777886

Epoch: 87| Step: 0
Training loss: 2.565371974125995
Validation loss: 2.5136182410418924

Epoch: 5| Step: 1
Training loss: 3.1521625301264224
Validation loss: 2.518044178507685

Epoch: 5| Step: 2
Training loss: 2.9434355160813532
Validation loss: 2.5164767401529042

Epoch: 5| Step: 3
Training loss: 3.0414416260404895
Validation loss: 2.509115627882972

Epoch: 5| Step: 4
Training loss: 2.9491550463939493
Validation loss: 2.503802998600371

Epoch: 5| Step: 5
Training loss: 2.2976241155230137
Validation loss: 2.5019973979335837

Epoch: 5| Step: 6
Training loss: 3.124315415737758
Validation loss: 2.5120565992615336

Epoch: 5| Step: 7
Training loss: 3.12912417068443
Validation loss: 2.512027366898835

Epoch: 5| Step: 8
Training loss: 2.7944957480283077
Validation loss: 2.512836129993824

Epoch: 5| Step: 9
Training loss: 2.484754137583246
Validation loss: 2.5279632776229386

Epoch: 5| Step: 10
Training loss: 2.8453870819053817
Validation loss: 2.5463197426096116

Epoch: 88| Step: 0
Training loss: 3.0246677310777215
Validation loss: 2.570968328322697

Epoch: 5| Step: 1
Training loss: 2.7138887989986027
Validation loss: 2.5646532952457517

Epoch: 5| Step: 2
Training loss: 2.355211436829061
Validation loss: 2.5460898742292866

Epoch: 5| Step: 3
Training loss: 3.416957718772634
Validation loss: 2.5366526041609547

Epoch: 5| Step: 4
Training loss: 2.1872525756416152
Validation loss: 2.5369010909961216

Epoch: 5| Step: 5
Training loss: 2.8117930901428188
Validation loss: 2.526872729868223

Epoch: 5| Step: 6
Training loss: 3.1939276420026537
Validation loss: 2.5026235442788787

Epoch: 5| Step: 7
Training loss: 2.776218792749823
Validation loss: 2.5093131359926892

Epoch: 5| Step: 8
Training loss: 2.4615300509648423
Validation loss: 2.5060940976092763

Epoch: 5| Step: 9
Training loss: 3.325015912699088
Validation loss: 2.4949021004233276

Epoch: 5| Step: 10
Training loss: 2.759381936432878
Validation loss: 2.4874893308622923

Epoch: 89| Step: 0
Training loss: 3.0457021167494642
Validation loss: 2.492599578220041

Epoch: 5| Step: 1
Training loss: 2.878126683270918
Validation loss: 2.4898405202669633

Epoch: 5| Step: 2
Training loss: 2.3936064834002035
Validation loss: 2.49677945733433

Epoch: 5| Step: 3
Training loss: 2.381767368932813
Validation loss: 2.504333655172298

Epoch: 5| Step: 4
Training loss: 3.218378730768504
Validation loss: 2.5160683177775187

Epoch: 5| Step: 5
Training loss: 3.0692991181075877
Validation loss: 2.522522825864293

Epoch: 5| Step: 6
Training loss: 3.0423127276445605
Validation loss: 2.5275352765427854

Epoch: 5| Step: 7
Training loss: 2.3100158132697173
Validation loss: 2.5445408128033313

Epoch: 5| Step: 8
Training loss: 2.9702249175939843
Validation loss: 2.5315521760723234

Epoch: 5| Step: 9
Training loss: 2.801809124960368
Validation loss: 2.4991454694409114

Epoch: 5| Step: 10
Training loss: 2.969748881092145
Validation loss: 2.500412899703577

Epoch: 90| Step: 0
Training loss: 2.493791596106377
Validation loss: 2.4887227984942966

Epoch: 5| Step: 1
Training loss: 3.198998747586586
Validation loss: 2.4881283849032445

Epoch: 5| Step: 2
Training loss: 2.2035454964265604
Validation loss: 2.4882037610045464

Epoch: 5| Step: 3
Training loss: 2.3721342364791385
Validation loss: 2.486677188038915

Epoch: 5| Step: 4
Training loss: 2.7537023590579817
Validation loss: 2.4857615500136805

Epoch: 5| Step: 5
Training loss: 3.32015308670625
Validation loss: 2.4859823912876675

Epoch: 5| Step: 6
Training loss: 3.088908867881924
Validation loss: 2.4892603820530823

Epoch: 5| Step: 7
Training loss: 2.5762712692278593
Validation loss: 2.491977453019431

Epoch: 5| Step: 8
Training loss: 2.6418363061421744
Validation loss: 2.495748910978015

Epoch: 5| Step: 9
Training loss: 3.307003283005046
Validation loss: 2.503328410875214

Epoch: 5| Step: 10
Training loss: 2.9489317495391347
Validation loss: 2.5155220925320485

Epoch: 91| Step: 0
Training loss: 2.8691336447966487
Validation loss: 2.5160050010559063

Epoch: 5| Step: 1
Training loss: 2.906500200556078
Validation loss: 2.525405630846189

Epoch: 5| Step: 2
Training loss: 2.897426377448085
Validation loss: 2.548111761823485

Epoch: 5| Step: 3
Training loss: 2.6897415748887585
Validation loss: 2.5545652391065925

Epoch: 5| Step: 4
Training loss: 3.2214060074816806
Validation loss: 2.553930135142875

Epoch: 5| Step: 5
Training loss: 2.602723558481576
Validation loss: 2.5552890512525432

Epoch: 5| Step: 6
Training loss: 2.873343280618654
Validation loss: 2.543400994962541

Epoch: 5| Step: 7
Training loss: 2.4440058425483855
Validation loss: 2.5502880627018283

Epoch: 5| Step: 8
Training loss: 2.9651927315405087
Validation loss: 2.525340761542715

Epoch: 5| Step: 9
Training loss: 3.0488315658012293
Validation loss: 2.518273977370114

Epoch: 5| Step: 10
Training loss: 2.4258056246259296
Validation loss: 2.507503929726863

Epoch: 92| Step: 0
Training loss: 3.0733459862416175
Validation loss: 2.492962753960148

Epoch: 5| Step: 1
Training loss: 3.3178329723826354
Validation loss: 2.494878106978186

Epoch: 5| Step: 2
Training loss: 2.241743622017895
Validation loss: 2.4934997868538646

Epoch: 5| Step: 3
Training loss: 2.5811990617432037
Validation loss: 2.4876304838351166

Epoch: 5| Step: 4
Training loss: 2.9091108454216226
Validation loss: 2.483826571381934

Epoch: 5| Step: 5
Training loss: 2.5062379261211176
Validation loss: 2.491172497169763

Epoch: 5| Step: 6
Training loss: 2.9506324865904348
Validation loss: 2.4974964219151174

Epoch: 5| Step: 7
Training loss: 2.7492327920393027
Validation loss: 2.5039685693206026

Epoch: 5| Step: 8
Training loss: 3.2790216054341284
Validation loss: 2.5113936230269043

Epoch: 5| Step: 9
Training loss: 2.6110805031716215
Validation loss: 2.5151698264314324

Epoch: 5| Step: 10
Training loss: 2.746125960398531
Validation loss: 2.5132335846735483

Epoch: 93| Step: 0
Training loss: 3.1242065948379603
Validation loss: 2.512802751300029

Epoch: 5| Step: 1
Training loss: 2.614293653593731
Validation loss: 2.5099648040175317

Epoch: 5| Step: 2
Training loss: 2.7171591127129138
Validation loss: 2.51223611406542

Epoch: 5| Step: 3
Training loss: 2.8434988057627213
Validation loss: 2.504801667395968

Epoch: 5| Step: 4
Training loss: 2.931360850241091
Validation loss: 2.4929885772614764

Epoch: 5| Step: 5
Training loss: 2.676526933334638
Validation loss: 2.4912399520750834

Epoch: 5| Step: 6
Training loss: 2.453542200074245
Validation loss: 2.491581263450231

Epoch: 5| Step: 7
Training loss: 2.6900709408052683
Validation loss: 2.500194074419519

Epoch: 5| Step: 8
Training loss: 2.9850316149189156
Validation loss: 2.498689372544136

Epoch: 5| Step: 9
Training loss: 2.9927938061166484
Validation loss: 2.5105516263576275

Epoch: 5| Step: 10
Training loss: 2.8280164160353163
Validation loss: 2.5270962387036913

Epoch: 94| Step: 0
Training loss: 2.681974630538805
Validation loss: 2.554246309243128

Epoch: 5| Step: 1
Training loss: 2.728306166323884
Validation loss: 2.5746059909168344

Epoch: 5| Step: 2
Training loss: 3.167647226671038
Validation loss: 2.6097385191841935

Epoch: 5| Step: 3
Training loss: 2.6555137062588132
Validation loss: 2.602094218575502

Epoch: 5| Step: 4
Training loss: 3.334939776195674
Validation loss: 2.5562296679447587

Epoch: 5| Step: 5
Training loss: 2.926594395827756
Validation loss: 2.5012962979811073

Epoch: 5| Step: 6
Training loss: 2.6379496548167207
Validation loss: 2.4827180334979784

Epoch: 5| Step: 7
Training loss: 3.0488575280853154
Validation loss: 2.4859064414778973

Epoch: 5| Step: 8
Training loss: 3.014202988328124
Validation loss: 2.4901788011173154

Epoch: 5| Step: 9
Training loss: 2.4451881840217413
Validation loss: 2.4969519399755025

Epoch: 5| Step: 10
Training loss: 2.668395336446574
Validation loss: 2.4997284423842676

Epoch: 95| Step: 0
Training loss: 3.089384447531326
Validation loss: 2.49880871025387

Epoch: 5| Step: 1
Training loss: 3.0432492323999574
Validation loss: 2.4878231695918

Epoch: 5| Step: 2
Training loss: 2.825356071110038
Validation loss: 2.485335857859827

Epoch: 5| Step: 3
Training loss: 2.386929916305463
Validation loss: 2.481277536793364

Epoch: 5| Step: 4
Training loss: 2.632389657224895
Validation loss: 2.4859035477327063

Epoch: 5| Step: 5
Training loss: 2.5503273248960276
Validation loss: 2.4914060546558816

Epoch: 5| Step: 6
Training loss: 3.1791271868879605
Validation loss: 2.520021229648185

Epoch: 5| Step: 7
Training loss: 2.8195592661644513
Validation loss: 2.563805301461982

Epoch: 5| Step: 8
Training loss: 2.8806059541608553
Validation loss: 2.568677310081291

Epoch: 5| Step: 9
Training loss: 2.9819564206311697
Validation loss: 2.5674762703749088

Epoch: 5| Step: 10
Training loss: 2.6570508759336553
Validation loss: 2.5531866170425705

Epoch: 96| Step: 0
Training loss: 2.739163113893395
Validation loss: 2.545161278860605

Epoch: 5| Step: 1
Training loss: 2.7897385918446975
Validation loss: 2.519063226579705

Epoch: 5| Step: 2
Training loss: 2.9950046275617357
Validation loss: 2.5108805997779706

Epoch: 5| Step: 3
Training loss: 3.2330264906123896
Validation loss: 2.49314832069665

Epoch: 5| Step: 4
Training loss: 2.6481871359987545
Validation loss: 2.49021982534985

Epoch: 5| Step: 5
Training loss: 3.30774664365056
Validation loss: 2.4852478079181215

Epoch: 5| Step: 6
Training loss: 2.7115284388347054
Validation loss: 2.4806741991291377

Epoch: 5| Step: 7
Training loss: 2.733164492098699
Validation loss: 2.4817101014769305

Epoch: 5| Step: 8
Training loss: 2.697910637769014
Validation loss: 2.48067556430976

Epoch: 5| Step: 9
Training loss: 2.3497648243205655
Validation loss: 2.4785467048084393

Epoch: 5| Step: 10
Training loss: 2.5212030586256806
Validation loss: 2.4781472900755364

Epoch: 97| Step: 0
Training loss: 2.717839669596978
Validation loss: 2.485994023630203

Epoch: 5| Step: 1
Training loss: 2.921309798954449
Validation loss: 2.53073621908777

Epoch: 5| Step: 2
Training loss: 3.075528981679555
Validation loss: 2.5881375919940908

Epoch: 5| Step: 3
Training loss: 2.6361009114100162
Validation loss: 2.6098498115739512

Epoch: 5| Step: 4
Training loss: 2.6616261548148312
Validation loss: 2.6021488810771016

Epoch: 5| Step: 5
Training loss: 2.7281260557052476
Validation loss: 2.5629933500348123

Epoch: 5| Step: 6
Training loss: 3.2435992373084668
Validation loss: 2.4938478491618574

Epoch: 5| Step: 7
Training loss: 2.4108076652727792
Validation loss: 2.4790579938419017

Epoch: 5| Step: 8
Training loss: 3.069945179949953
Validation loss: 2.487015841951921

Epoch: 5| Step: 9
Training loss: 2.8345484839259765
Validation loss: 2.503238905611388

Epoch: 5| Step: 10
Training loss: 2.927601145129886
Validation loss: 2.5132541943236646

Epoch: 98| Step: 0
Training loss: 3.1627387397727893
Validation loss: 2.527320338424144

Epoch: 5| Step: 1
Training loss: 2.7715076018120275
Validation loss: 2.5205219411736275

Epoch: 5| Step: 2
Training loss: 2.9148481603633547
Validation loss: 2.522674459405275

Epoch: 5| Step: 3
Training loss: 2.7144019776017516
Validation loss: 2.527707390757637

Epoch: 5| Step: 4
Training loss: 2.911192925672959
Validation loss: 2.5171261533046674

Epoch: 5| Step: 5
Training loss: 2.4132611077216133
Validation loss: 2.5099127383723876

Epoch: 5| Step: 6
Training loss: 2.817962343585688
Validation loss: 2.5007942148191056

Epoch: 5| Step: 7
Training loss: 2.7499015096887165
Validation loss: 2.498833799616151

Epoch: 5| Step: 8
Training loss: 3.0095067392512402
Validation loss: 2.4933993098480594

Epoch: 5| Step: 9
Training loss: 3.135114247553802
Validation loss: 2.491261595215315

Epoch: 5| Step: 10
Training loss: 3.156253625848784
Validation loss: 2.501665547035976

Epoch: 99| Step: 0
Training loss: 2.7982799049019342
Validation loss: 2.5048495110245472

Epoch: 5| Step: 1
Training loss: 2.3886546074281325
Validation loss: 2.5199992953503116

Epoch: 5| Step: 2
Training loss: 2.3416866120634996
Validation loss: 2.539281330633431

Epoch: 5| Step: 3
Training loss: 2.937659563641272
Validation loss: 2.555304669083252

Epoch: 5| Step: 4
Training loss: 2.662487828759684
Validation loss: 2.549553820297304

Epoch: 5| Step: 5
Training loss: 2.701144071423474
Validation loss: 2.5646423920294286

Epoch: 5| Step: 6
Training loss: 2.5568771078081935
Validation loss: 2.5966326542124953

Epoch: 5| Step: 7
Training loss: 3.002573657756203
Validation loss: 2.614103530049758

Epoch: 5| Step: 8
Training loss: 3.506790793969389
Validation loss: 2.615799483797401

Epoch: 5| Step: 9
Training loss: 3.1265056797490276
Validation loss: 2.6029975498184417

Epoch: 5| Step: 10
Training loss: 3.110443851652794
Validation loss: 2.5740173162439164

Epoch: 100| Step: 0
Training loss: 3.053197941450527
Validation loss: 2.5050657662123132

Epoch: 5| Step: 1
Training loss: 2.626458897950023
Validation loss: 2.4762666540509373

Epoch: 5| Step: 2
Training loss: 2.538385764682791
Validation loss: 2.4730533815601277

Epoch: 5| Step: 3
Training loss: 2.854871695286044
Validation loss: 2.474514985252926

Epoch: 5| Step: 4
Training loss: 2.8486468733583385
Validation loss: 2.4830518384879063

Epoch: 5| Step: 5
Training loss: 2.563405225941945
Validation loss: 2.486884025184571

Epoch: 5| Step: 6
Training loss: 2.969731058345002
Validation loss: 2.492599084539613

Epoch: 5| Step: 7
Training loss: 2.676741512656729
Validation loss: 2.494834428040079

Epoch: 5| Step: 8
Training loss: 3.332813095185718
Validation loss: 2.491357245929106

Epoch: 5| Step: 9
Training loss: 2.7796443633516583
Validation loss: 2.4893487329002366

Epoch: 5| Step: 10
Training loss: 3.337804624678385
Validation loss: 2.4842522455970784

Epoch: 101| Step: 0
Training loss: 3.0097691104579103
Validation loss: 2.4723203736435173

Epoch: 5| Step: 1
Training loss: 2.97616214012099
Validation loss: 2.466851084227709

Epoch: 5| Step: 2
Training loss: 2.131796123082173
Validation loss: 2.462666756277728

Epoch: 5| Step: 3
Training loss: 3.126574768011835
Validation loss: 2.466406192873283

Epoch: 5| Step: 4
Training loss: 3.1034515547095625
Validation loss: 2.47833996938385

Epoch: 5| Step: 5
Training loss: 2.5323250453877453
Validation loss: 2.5019438395524363

Epoch: 5| Step: 6
Training loss: 2.8287866988016073
Validation loss: 2.5356976634265815

Epoch: 5| Step: 7
Training loss: 3.1547557957565235
Validation loss: 2.555471050692678

Epoch: 5| Step: 8
Training loss: 3.23644393133555
Validation loss: 2.5684639114547014

Epoch: 5| Step: 9
Training loss: 2.0432080918222786
Validation loss: 2.607077754707937

Epoch: 5| Step: 10
Training loss: 2.8121508063660743
Validation loss: 2.641100531997843

Epoch: 102| Step: 0
Training loss: 2.627762022591751
Validation loss: 2.598523543626774

Epoch: 5| Step: 1
Training loss: 3.205566964073162
Validation loss: 2.570476461547523

Epoch: 5| Step: 2
Training loss: 2.780816548035509
Validation loss: 2.531277909473787

Epoch: 5| Step: 3
Training loss: 2.5385932371348328
Validation loss: 2.4891354369091894

Epoch: 5| Step: 4
Training loss: 2.8996918218567926
Validation loss: 2.479834192596865

Epoch: 5| Step: 5
Training loss: 2.8841701711747083
Validation loss: 2.4702489146568456

Epoch: 5| Step: 6
Training loss: 3.121871297564903
Validation loss: 2.466304609998455

Epoch: 5| Step: 7
Training loss: 2.255544189629108
Validation loss: 2.4657245060419375

Epoch: 5| Step: 8
Training loss: 2.8132497000203
Validation loss: 2.4600464014395405

Epoch: 5| Step: 9
Training loss: 2.9126028542100517
Validation loss: 2.4604000121170992

Epoch: 5| Step: 10
Training loss: 2.8879018792895814
Validation loss: 2.4599507067227266

Epoch: 103| Step: 0
Training loss: 2.1848767491546477
Validation loss: 2.460458318516789

Epoch: 5| Step: 1
Training loss: 2.612093942287716
Validation loss: 2.465815743143922

Epoch: 5| Step: 2
Training loss: 2.998734525169143
Validation loss: 2.4814380274156234

Epoch: 5| Step: 3
Training loss: 1.9277751265124956
Validation loss: 2.482176251633601

Epoch: 5| Step: 4
Training loss: 2.6473910534625618
Validation loss: 2.4885338910502717

Epoch: 5| Step: 5
Training loss: 2.710260576058457
Validation loss: 2.4905267181687716

Epoch: 5| Step: 6
Training loss: 2.7505231706440423
Validation loss: 2.521395007898315

Epoch: 5| Step: 7
Training loss: 2.7126961316339484
Validation loss: 2.514876824901406

Epoch: 5| Step: 8
Training loss: 3.5452082410590697
Validation loss: 2.511769654472255

Epoch: 5| Step: 9
Training loss: 3.392721907709826
Validation loss: 2.5030687745213087

Epoch: 5| Step: 10
Training loss: 2.8011402873624274
Validation loss: 2.4863215713511915

Epoch: 104| Step: 0
Training loss: 2.392181089506025
Validation loss: 2.4938359717835126

Epoch: 5| Step: 1
Training loss: 3.5101530766594826
Validation loss: 2.490681702571849

Epoch: 5| Step: 2
Training loss: 2.457894614776519
Validation loss: 2.50021610966672

Epoch: 5| Step: 3
Training loss: 2.365538069666034
Validation loss: 2.5030676028373327

Epoch: 5| Step: 4
Training loss: 2.643708184094168
Validation loss: 2.501617045059362

Epoch: 5| Step: 5
Training loss: 3.0844829752998395
Validation loss: 2.4898909443405244

Epoch: 5| Step: 6
Training loss: 2.9938345178448422
Validation loss: 2.4867555039774536

Epoch: 5| Step: 7
Training loss: 2.8184818656247317
Validation loss: 2.478514145885983

Epoch: 5| Step: 8
Training loss: 2.6372154841705164
Validation loss: 2.4836632133359013

Epoch: 5| Step: 9
Training loss: 2.935275757554677
Validation loss: 2.470202730793463

Epoch: 5| Step: 10
Training loss: 2.467538560529293
Validation loss: 2.4765579784131155

Epoch: 105| Step: 0
Training loss: 2.480115297621433
Validation loss: 2.4743098349391937

Epoch: 5| Step: 1
Training loss: 2.914486278983955
Validation loss: 2.482776902037034

Epoch: 5| Step: 2
Training loss: 3.149885351123073
Validation loss: 2.484717578348192

Epoch: 5| Step: 3
Training loss: 2.3187339884984057
Validation loss: 2.506955924850685

Epoch: 5| Step: 4
Training loss: 2.8007446456922014
Validation loss: 2.5325852385158867

Epoch: 5| Step: 5
Training loss: 2.5810070228288975
Validation loss: 2.5328678554999597

Epoch: 5| Step: 6
Training loss: 3.062299760772792
Validation loss: 2.519014793960223

Epoch: 5| Step: 7
Training loss: 2.730083301936088
Validation loss: 2.5066126195332155

Epoch: 5| Step: 8
Training loss: 2.795023726360907
Validation loss: 2.483934702559601

Epoch: 5| Step: 9
Training loss: 2.8802955618831394
Validation loss: 2.4730434755066795

Epoch: 5| Step: 10
Training loss: 2.8005724287728198
Validation loss: 2.4621397395476317

Epoch: 106| Step: 0
Training loss: 2.673057339168516
Validation loss: 2.461663668510133

Epoch: 5| Step: 1
Training loss: 3.0283437738429306
Validation loss: 2.4654598926981666

Epoch: 5| Step: 2
Training loss: 2.91843656699001
Validation loss: 2.4677019408913496

Epoch: 5| Step: 3
Training loss: 2.137668544972888
Validation loss: 2.4730372536223486

Epoch: 5| Step: 4
Training loss: 3.0605467191987037
Validation loss: 2.476253583548861

Epoch: 5| Step: 5
Training loss: 2.8094888462511243
Validation loss: 2.4759910211136735

Epoch: 5| Step: 6
Training loss: 2.784478360536388
Validation loss: 2.468075869072871

Epoch: 5| Step: 7
Training loss: 3.135773208640547
Validation loss: 2.474241525776573

Epoch: 5| Step: 8
Training loss: 2.494542554763425
Validation loss: 2.480550536071108

Epoch: 5| Step: 9
Training loss: 2.6054697565765954
Validation loss: 2.4940523729785675

Epoch: 5| Step: 10
Training loss: 2.930798454724302
Validation loss: 2.5009866695301772

Epoch: 107| Step: 0
Training loss: 2.613575917325257
Validation loss: 2.5142883508106024

Epoch: 5| Step: 1
Training loss: 2.4611587667144894
Validation loss: 2.514122204976727

Epoch: 5| Step: 2
Training loss: 2.9861436965307893
Validation loss: 2.51645803292338

Epoch: 5| Step: 3
Training loss: 3.280224594474859
Validation loss: 2.5084699959061094

Epoch: 5| Step: 4
Training loss: 2.8200642907139133
Validation loss: 2.5146900677323822

Epoch: 5| Step: 5
Training loss: 2.131586637786714
Validation loss: 2.5122589539344724

Epoch: 5| Step: 6
Training loss: 2.8114660269787564
Validation loss: 2.5100615252795238

Epoch: 5| Step: 7
Training loss: 3.048078719807137
Validation loss: 2.5068425520556263

Epoch: 5| Step: 8
Training loss: 2.792071517132218
Validation loss: 2.483361175938765

Epoch: 5| Step: 9
Training loss: 2.5386712814590973
Validation loss: 2.4807981784415816

Epoch: 5| Step: 10
Training loss: 2.7938698762098553
Validation loss: 2.4797091943051206

Epoch: 108| Step: 0
Training loss: 2.4810979570749154
Validation loss: 2.475254447198649

Epoch: 5| Step: 1
Training loss: 2.864796486062348
Validation loss: 2.4716369521750496

Epoch: 5| Step: 2
Training loss: 2.6064304938811613
Validation loss: 2.4712284970384215

Epoch: 5| Step: 3
Training loss: 2.3720454862134854
Validation loss: 2.4633228602267137

Epoch: 5| Step: 4
Training loss: 2.792106783510857
Validation loss: 2.464459007008754

Epoch: 5| Step: 5
Training loss: 3.220027040640506
Validation loss: 2.4700477764349333

Epoch: 5| Step: 6
Training loss: 2.5967918850925313
Validation loss: 2.4675697879476757

Epoch: 5| Step: 7
Training loss: 2.606605110400999
Validation loss: 2.4708432697181495

Epoch: 5| Step: 8
Training loss: 3.0805578541572722
Validation loss: 2.475751895369584

Epoch: 5| Step: 9
Training loss: 2.7539801837925717
Validation loss: 2.4885351952592303

Epoch: 5| Step: 10
Training loss: 2.8113707924653144
Validation loss: 2.4970919225595845

Epoch: 109| Step: 0
Training loss: 2.757367235932041
Validation loss: 2.5156617398548202

Epoch: 5| Step: 1
Training loss: 2.8085504563009684
Validation loss: 2.5367815134778

Epoch: 5| Step: 2
Training loss: 2.3577084750313944
Validation loss: 2.5288523068041395

Epoch: 5| Step: 3
Training loss: 2.5465377865213688
Validation loss: 2.5079056825328396

Epoch: 5| Step: 4
Training loss: 2.232238815424854
Validation loss: 2.482584361592335

Epoch: 5| Step: 5
Training loss: 2.7498790540975264
Validation loss: 2.465401438384144

Epoch: 5| Step: 6
Training loss: 2.8050742560092905
Validation loss: 2.459491172031786

Epoch: 5| Step: 7
Training loss: 3.3504525861050896
Validation loss: 2.4682260759296275

Epoch: 5| Step: 8
Training loss: 2.9419236658956724
Validation loss: 2.470196147854332

Epoch: 5| Step: 9
Training loss: 3.085652398568653
Validation loss: 2.479582069183488

Epoch: 5| Step: 10
Training loss: 2.8022186549149968
Validation loss: 2.47950061718035

Epoch: 110| Step: 0
Training loss: 2.866534499145273
Validation loss: 2.476479042887886

Epoch: 5| Step: 1
Training loss: 2.9446504288924458
Validation loss: 2.4715294374423915

Epoch: 5| Step: 2
Training loss: 2.9738239496247614
Validation loss: 2.462926820200821

Epoch: 5| Step: 3
Training loss: 2.8724802004245484
Validation loss: 2.461079736242927

Epoch: 5| Step: 4
Training loss: 1.731290462861106
Validation loss: 2.4655981571366623

Epoch: 5| Step: 5
Training loss: 2.9125663455069963
Validation loss: 2.498165613309527

Epoch: 5| Step: 6
Training loss: 2.719802652660922
Validation loss: 2.496512236129298

Epoch: 5| Step: 7
Training loss: 2.82452669482954
Validation loss: 2.4967569861754857

Epoch: 5| Step: 8
Training loss: 2.65337260857784
Validation loss: 2.493597119000075

Epoch: 5| Step: 9
Training loss: 2.6303006196906598
Validation loss: 2.4821258784380142

Epoch: 5| Step: 10
Training loss: 3.0022447453101133
Validation loss: 2.4874258658903483

Epoch: 111| Step: 0
Training loss: 2.559107791426705
Validation loss: 2.4786463027909975

Epoch: 5| Step: 1
Training loss: 2.141796932884882
Validation loss: 2.4837126656124515

Epoch: 5| Step: 2
Training loss: 2.589152570411298
Validation loss: 2.4632169876423844

Epoch: 5| Step: 3
Training loss: 2.872564860143705
Validation loss: 2.465577810947323

Epoch: 5| Step: 4
Training loss: 2.8506590365648825
Validation loss: 2.4657434068738744

Epoch: 5| Step: 5
Training loss: 2.5812494014711587
Validation loss: 2.455323214073456

Epoch: 5| Step: 6
Training loss: 3.092583792930498
Validation loss: 2.473981077200849

Epoch: 5| Step: 7
Training loss: 2.730938828678945
Validation loss: 2.474062413528947

Epoch: 5| Step: 8
Training loss: 2.979065811121773
Validation loss: 2.484306631181359

Epoch: 5| Step: 9
Training loss: 3.063186879882451
Validation loss: 2.4726720123625827

Epoch: 5| Step: 10
Training loss: 2.657962650854715
Validation loss: 2.489077925862951

Epoch: 112| Step: 0
Training loss: 3.309602729951518
Validation loss: 2.485675084890722

Epoch: 5| Step: 1
Training loss: 2.8975415760180936
Validation loss: 2.489267056699416

Epoch: 5| Step: 2
Training loss: 2.410125880614225
Validation loss: 2.5001001584078315

Epoch: 5| Step: 3
Training loss: 2.717641143923531
Validation loss: 2.4931281839174244

Epoch: 5| Step: 4
Training loss: 2.6550149177951146
Validation loss: 2.493497620584112

Epoch: 5| Step: 5
Training loss: 2.910584857279681
Validation loss: 2.473145483359123

Epoch: 5| Step: 6
Training loss: 2.584831623666245
Validation loss: 2.4718000896459493

Epoch: 5| Step: 7
Training loss: 2.542266045443118
Validation loss: 2.465080312673427

Epoch: 5| Step: 8
Training loss: 2.8946819806718103
Validation loss: 2.458927298305844

Epoch: 5| Step: 9
Training loss: 1.7833634938455565
Validation loss: 2.4584029410136226

Epoch: 5| Step: 10
Training loss: 3.18198186403833
Validation loss: 2.459114212090124

Epoch: 113| Step: 0
Training loss: 1.9407053244363959
Validation loss: 2.47526741629925

Epoch: 5| Step: 1
Training loss: 3.0694714042051134
Validation loss: 2.4816163836678

Epoch: 5| Step: 2
Training loss: 2.8128371990243823
Validation loss: 2.480874689714169

Epoch: 5| Step: 3
Training loss: 2.86234400294988
Validation loss: 2.4841546195473843

Epoch: 5| Step: 4
Training loss: 3.1855854941903377
Validation loss: 2.4765604172554183

Epoch: 5| Step: 5
Training loss: 2.022023889168454
Validation loss: 2.4796102024848445

Epoch: 5| Step: 6
Training loss: 3.523046366091686
Validation loss: 2.481015822743581

Epoch: 5| Step: 7
Training loss: 2.794507351144707
Validation loss: 2.4897125934153266

Epoch: 5| Step: 8
Training loss: 2.939431387481917
Validation loss: 2.4983170125544603

Epoch: 5| Step: 9
Training loss: 2.055598763994067
Validation loss: 2.4935277949998174

Epoch: 5| Step: 10
Training loss: 2.474834428894073
Validation loss: 2.4915563737235216

Epoch: 114| Step: 0
Training loss: 2.3855048306315694
Validation loss: 2.4768568553492165

Epoch: 5| Step: 1
Training loss: 2.9797818453514733
Validation loss: 2.4737833845695794

Epoch: 5| Step: 2
Training loss: 2.37079871163009
Validation loss: 2.456792998191364

Epoch: 5| Step: 3
Training loss: 2.4417793660199023
Validation loss: 2.4607510414200386

Epoch: 5| Step: 4
Training loss: 2.8751761341044872
Validation loss: 2.454366108870914

Epoch: 5| Step: 5
Training loss: 2.5648071323631148
Validation loss: 2.453116357413339

Epoch: 5| Step: 6
Training loss: 2.3668511784404633
Validation loss: 2.458744436699488

Epoch: 5| Step: 7
Training loss: 3.2297817177725814
Validation loss: 2.4633447548930087

Epoch: 5| Step: 8
Training loss: 3.152593780018143
Validation loss: 2.462025685320602

Epoch: 5| Step: 9
Training loss: 2.4150557465368405
Validation loss: 2.470536682704196

Epoch: 5| Step: 10
Training loss: 3.10377389014487
Validation loss: 2.47853295125518

Epoch: 115| Step: 0
Training loss: 2.7249724115497527
Validation loss: 2.4774579820780227

Epoch: 5| Step: 1
Training loss: 2.8103324166789108
Validation loss: 2.4704570047967285

Epoch: 5| Step: 2
Training loss: 2.6419222201695374
Validation loss: 2.469916955098936

Epoch: 5| Step: 3
Training loss: 2.519420248735806
Validation loss: 2.4732593585642206

Epoch: 5| Step: 4
Training loss: 2.689539202252475
Validation loss: 2.467452251653359

Epoch: 5| Step: 5
Training loss: 2.192450344345489
Validation loss: 2.4641679709423627

Epoch: 5| Step: 6
Training loss: 2.724065648451589
Validation loss: 2.453151798095387

Epoch: 5| Step: 7
Training loss: 2.583403945285956
Validation loss: 2.465698932140405

Epoch: 5| Step: 8
Training loss: 3.3927968184765858
Validation loss: 2.465712160483852

Epoch: 5| Step: 9
Training loss: 2.712992304413142
Validation loss: 2.457317622864376

Epoch: 5| Step: 10
Training loss: 2.94604839167632
Validation loss: 2.463934892597356

Epoch: 116| Step: 0
Training loss: 2.760159021025799
Validation loss: 2.4744696456071202

Epoch: 5| Step: 1
Training loss: 3.025122830758169
Validation loss: 2.4680452120900003

Epoch: 5| Step: 2
Training loss: 2.7604515697263974
Validation loss: 2.470166214615519

Epoch: 5| Step: 3
Training loss: 2.463671035004366
Validation loss: 2.4712570594760086

Epoch: 5| Step: 4
Training loss: 3.298845759740461
Validation loss: 2.4758195167261707

Epoch: 5| Step: 5
Training loss: 2.473799743923236
Validation loss: 2.470808348416716

Epoch: 5| Step: 6
Training loss: 2.4786269190745873
Validation loss: 2.4830465977380367

Epoch: 5| Step: 7
Training loss: 2.9175178557358645
Validation loss: 2.4772962375632206

Epoch: 5| Step: 8
Training loss: 2.5756836400325827
Validation loss: 2.5088764385052027

Epoch: 5| Step: 9
Training loss: 2.4187099325326162
Validation loss: 2.5036353802605738

Epoch: 5| Step: 10
Training loss: 2.7198463947736697
Validation loss: 2.506516264306822

Epoch: 117| Step: 0
Training loss: 2.8602727095758773
Validation loss: 2.5067148107329174

Epoch: 5| Step: 1
Training loss: 2.55912875340446
Validation loss: 2.5092343277123526

Epoch: 5| Step: 2
Training loss: 3.1380984643643512
Validation loss: 2.521745995716692

Epoch: 5| Step: 3
Training loss: 2.666136798270769
Validation loss: 2.5143169777438295

Epoch: 5| Step: 4
Training loss: 2.549002759073709
Validation loss: 2.5095975202606406

Epoch: 5| Step: 5
Training loss: 2.598638959588511
Validation loss: 2.4831274512832837

Epoch: 5| Step: 6
Training loss: 2.4966192274420815
Validation loss: 2.4624712140149967

Epoch: 5| Step: 7
Training loss: 2.7098309899868687
Validation loss: 2.4591530836937303

Epoch: 5| Step: 8
Training loss: 2.6623539521900432
Validation loss: 2.4667498106719554

Epoch: 5| Step: 9
Training loss: 2.684947820259431
Validation loss: 2.4700016656160644

Epoch: 5| Step: 10
Training loss: 3.2882471954257175
Validation loss: 2.476875276884662

Epoch: 118| Step: 0
Training loss: 2.7085817858858388
Validation loss: 2.4641560805518297

Epoch: 5| Step: 1
Training loss: 2.331587297108055
Validation loss: 2.4670746345626515

Epoch: 5| Step: 2
Training loss: 2.8171333295085677
Validation loss: 2.4548389797604826

Epoch: 5| Step: 3
Training loss: 3.1727161513598423
Validation loss: 2.454671774048595

Epoch: 5| Step: 4
Training loss: 2.6050919885190695
Validation loss: 2.4678238055142816

Epoch: 5| Step: 5
Training loss: 2.4850876463817073
Validation loss: 2.4803481975984814

Epoch: 5| Step: 6
Training loss: 2.9236242596553867
Validation loss: 2.484870016713207

Epoch: 5| Step: 7
Training loss: 2.7729601811969653
Validation loss: 2.4926222215905858

Epoch: 5| Step: 8
Training loss: 2.5897341974024672
Validation loss: 2.4928119453299433

Epoch: 5| Step: 9
Training loss: 2.9748026934678333
Validation loss: 2.4905903521937693

Epoch: 5| Step: 10
Training loss: 2.613078065280531
Validation loss: 2.488084263936799

Epoch: 119| Step: 0
Training loss: 1.9786643813039497
Validation loss: 2.4841872438609434

Epoch: 5| Step: 1
Training loss: 2.727005449838652
Validation loss: 2.487177332154993

Epoch: 5| Step: 2
Training loss: 2.9010133222545598
Validation loss: 2.4843149733223173

Epoch: 5| Step: 3
Training loss: 3.1531485247608715
Validation loss: 2.477274338914831

Epoch: 5| Step: 4
Training loss: 2.795435444413456
Validation loss: 2.4780026049742743

Epoch: 5| Step: 5
Training loss: 2.3933215920772177
Validation loss: 2.479801041665244

Epoch: 5| Step: 6
Training loss: 3.0526347177631283
Validation loss: 2.4802321563016356

Epoch: 5| Step: 7
Training loss: 2.711647314539128
Validation loss: 2.488982424454661

Epoch: 5| Step: 8
Training loss: 2.9997521933887676
Validation loss: 2.496789233791137

Epoch: 5| Step: 9
Training loss: 2.047076848684525
Validation loss: 2.493833218822416

Epoch: 5| Step: 10
Training loss: 2.8035184926388688
Validation loss: 2.507578070126406

Epoch: 120| Step: 0
Training loss: 2.8465525472787157
Validation loss: 2.5005709016783997

Epoch: 5| Step: 1
Training loss: 2.6406190409395593
Validation loss: 2.498182138815365

Epoch: 5| Step: 2
Training loss: 2.800649812771903
Validation loss: 2.5062478421322423

Epoch: 5| Step: 3
Training loss: 2.5671324377487608
Validation loss: 2.534158010297409

Epoch: 5| Step: 4
Training loss: 2.591407545409685
Validation loss: 2.509590227003947

Epoch: 5| Step: 5
Training loss: 2.5106593815351244
Validation loss: 2.4958238401993724

Epoch: 5| Step: 6
Training loss: 2.8852851002211386
Validation loss: 2.4970348945538507

Epoch: 5| Step: 7
Training loss: 2.7993821143545174
Validation loss: 2.5184146030512036

Epoch: 5| Step: 8
Training loss: 2.8743761463830713
Validation loss: 2.5114789868203413

Epoch: 5| Step: 9
Training loss: 2.8082930572368525
Validation loss: 2.5209792500096917

Epoch: 5| Step: 10
Training loss: 2.70909720187943
Validation loss: 2.504589285143009

Epoch: 121| Step: 0
Training loss: 2.7179470411169993
Validation loss: 2.4869578010059232

Epoch: 5| Step: 1
Training loss: 2.3280494216837937
Validation loss: 2.4701508067748037

Epoch: 5| Step: 2
Training loss: 2.554781850769884
Validation loss: 2.4602518772849113

Epoch: 5| Step: 3
Training loss: 2.804726688036854
Validation loss: 2.4530732490531344

Epoch: 5| Step: 4
Training loss: 2.579315835298705
Validation loss: 2.4572578804442005

Epoch: 5| Step: 5
Training loss: 2.5289773039547936
Validation loss: 2.4676964888549042

Epoch: 5| Step: 6
Training loss: 2.858843311009594
Validation loss: 2.4748734296079276

Epoch: 5| Step: 7
Training loss: 3.0945541415659554
Validation loss: 2.4863969908850247

Epoch: 5| Step: 8
Training loss: 2.46358703399457
Validation loss: 2.506030700743677

Epoch: 5| Step: 9
Training loss: 3.153065349517456
Validation loss: 2.505450673807154

Epoch: 5| Step: 10
Training loss: 2.66419199519745
Validation loss: 2.5185832394756926

Epoch: 122| Step: 0
Training loss: 2.8305336827098664
Validation loss: 2.5185407971776037

Epoch: 5| Step: 1
Training loss: 2.401911800597924
Validation loss: 2.4768036207095787

Epoch: 5| Step: 2
Training loss: 2.6401727955072785
Validation loss: 2.463784455340609

Epoch: 5| Step: 3
Training loss: 2.7085926127424513
Validation loss: 2.464473059635521

Epoch: 5| Step: 4
Training loss: 2.738896930606257
Validation loss: 2.4622987648206554

Epoch: 5| Step: 5
Training loss: 3.185616479016172
Validation loss: 2.466296605055151

Epoch: 5| Step: 6
Training loss: 2.7328134492029514
Validation loss: 2.4780005570632975

Epoch: 5| Step: 7
Training loss: 2.8095272035709105
Validation loss: 2.4727710849555407

Epoch: 5| Step: 8
Training loss: 2.456644145995201
Validation loss: 2.4697670483001994

Epoch: 5| Step: 9
Training loss: 2.5776482343551965
Validation loss: 2.478268509691406

Epoch: 5| Step: 10
Training loss: 2.763117369973676
Validation loss: 2.468570691813249

Epoch: 123| Step: 0
Training loss: 2.9103663016685193
Validation loss: 2.4651090181060478

Epoch: 5| Step: 1
Training loss: 2.3963143460146816
Validation loss: 2.4629544734213122

Epoch: 5| Step: 2
Training loss: 2.2388280496884474
Validation loss: 2.4611497648478937

Epoch: 5| Step: 3
Training loss: 2.64493944181694
Validation loss: 2.4736829928081976

Epoch: 5| Step: 4
Training loss: 3.0479975270939605
Validation loss: 2.4907867399401598

Epoch: 5| Step: 5
Training loss: 2.3751220671755746
Validation loss: 2.4905604756965434

Epoch: 5| Step: 6
Training loss: 2.941352752563801
Validation loss: 2.4980876602132156

Epoch: 5| Step: 7
Training loss: 2.7781212170535445
Validation loss: 2.5099985222664425

Epoch: 5| Step: 8
Training loss: 3.0162417714986476
Validation loss: 2.5004136645675006

Epoch: 5| Step: 9
Training loss: 2.4749811460759448
Validation loss: 2.4881621347867466

Epoch: 5| Step: 10
Training loss: 2.719844115642883
Validation loss: 2.4831281270047683

Epoch: 124| Step: 0
Training loss: 2.4401799654646337
Validation loss: 2.476654929861142

Epoch: 5| Step: 1
Training loss: 2.9318444208499277
Validation loss: 2.4779370492572146

Epoch: 5| Step: 2
Training loss: 2.6908245371555353
Validation loss: 2.479238715037897

Epoch: 5| Step: 3
Training loss: 2.589174670389273
Validation loss: 2.4698792815204933

Epoch: 5| Step: 4
Training loss: 2.6092241437785306
Validation loss: 2.474494689070387

Epoch: 5| Step: 5
Training loss: 2.785041367995771
Validation loss: 2.480104765453867

Epoch: 5| Step: 6
Training loss: 2.5722075088644085
Validation loss: 2.4886203248358894

Epoch: 5| Step: 7
Training loss: 2.5675098479174
Validation loss: 2.4810182360211335

Epoch: 5| Step: 8
Training loss: 3.0422710358250336
Validation loss: 2.4794736354850984

Epoch: 5| Step: 9
Training loss: 2.767203015499893
Validation loss: 2.472127518639887

Epoch: 5| Step: 10
Training loss: 2.416531580953244
Validation loss: 2.48026616970789

Epoch: 125| Step: 0
Training loss: 2.768566657684661
Validation loss: 2.4740723776747884

Epoch: 5| Step: 1
Training loss: 2.7208463106727048
Validation loss: 2.4739288894809617

Epoch: 5| Step: 2
Training loss: 2.888010853416781
Validation loss: 2.4807596832027974

Epoch: 5| Step: 3
Training loss: 3.066922012009204
Validation loss: 2.48485382619085

Epoch: 5| Step: 4
Training loss: 2.3669375045255396
Validation loss: 2.4712553052603408

Epoch: 5| Step: 5
Training loss: 2.4113608245140288
Validation loss: 2.4825863897160225

Epoch: 5| Step: 6
Training loss: 2.869976298536731
Validation loss: 2.4914466553215817

Epoch: 5| Step: 7
Training loss: 2.1464701574824865
Validation loss: 2.506244904362044

Epoch: 5| Step: 8
Training loss: 2.871257502239226
Validation loss: 2.507892934348629

Epoch: 5| Step: 9
Training loss: 2.2833496255595036
Validation loss: 2.510609111133408

Epoch: 5| Step: 10
Training loss: 2.7826713616179686
Validation loss: 2.4994836540643353

Epoch: 126| Step: 0
Training loss: 2.7528995486555248
Validation loss: 2.503389040531933

Epoch: 5| Step: 1
Training loss: 2.1977849863630787
Validation loss: 2.514045571606641

Epoch: 5| Step: 2
Training loss: 2.704403789764624
Validation loss: 2.5400980004210427

Epoch: 5| Step: 3
Training loss: 2.643595813195989
Validation loss: 2.540452262229972

Epoch: 5| Step: 4
Training loss: 3.1533222783266557
Validation loss: 2.548991976484601

Epoch: 5| Step: 5
Training loss: 2.791938474337951
Validation loss: 2.510428500659248

Epoch: 5| Step: 6
Training loss: 2.5799246315704147
Validation loss: 2.4951881394910886

Epoch: 5| Step: 7
Training loss: 2.274252414486968
Validation loss: 2.4695863938578952

Epoch: 5| Step: 8
Training loss: 2.5430983174917166
Validation loss: 2.465324040306735

Epoch: 5| Step: 9
Training loss: 3.166988724510518
Validation loss: 2.4825466881707365

Epoch: 5| Step: 10
Training loss: 2.816660198979222
Validation loss: 2.498267730330103

Epoch: 127| Step: 0
Training loss: 2.6801321478190117
Validation loss: 2.503758853330698

Epoch: 5| Step: 1
Training loss: 2.5790002435371253
Validation loss: 2.4977121990774522

Epoch: 5| Step: 2
Training loss: 2.825376492283928
Validation loss: 2.496298693670542

Epoch: 5| Step: 3
Training loss: 3.0558942279586025
Validation loss: 2.476021220435795

Epoch: 5| Step: 4
Training loss: 2.247607760789748
Validation loss: 2.4671589137664416

Epoch: 5| Step: 5
Training loss: 1.9772073651216158
Validation loss: 2.4656987335535563

Epoch: 5| Step: 6
Training loss: 2.7614970462195494
Validation loss: 2.4697279472264313

Epoch: 5| Step: 7
Training loss: 2.719033938960355
Validation loss: 2.4596162607869587

Epoch: 5| Step: 8
Training loss: 3.1705361533204
Validation loss: 2.46706714025985

Epoch: 5| Step: 9
Training loss: 2.931478293827641
Validation loss: 2.4689242840276093

Epoch: 5| Step: 10
Training loss: 2.1439419407456177
Validation loss: 2.4742636222273426

Epoch: 128| Step: 0
Training loss: 2.4753884020363914
Validation loss: 2.481683409291337

Epoch: 5| Step: 1
Training loss: 3.119000588786665
Validation loss: 2.4841137634738812

Epoch: 5| Step: 2
Training loss: 2.610968006442067
Validation loss: 2.4827896748935325

Epoch: 5| Step: 3
Training loss: 2.3729948312837337
Validation loss: 2.5069268983815056

Epoch: 5| Step: 4
Training loss: 2.795904150879379
Validation loss: 2.505647232802193

Epoch: 5| Step: 5
Training loss: 3.1240084791764424
Validation loss: 2.5052661907405476

Epoch: 5| Step: 6
Training loss: 2.720621100926163
Validation loss: 2.5116639413647426

Epoch: 5| Step: 7
Training loss: 2.438458180998
Validation loss: 2.536154262569162

Epoch: 5| Step: 8
Training loss: 2.8932667800468144
Validation loss: 2.5544149868040145

Epoch: 5| Step: 9
Training loss: 2.0757627900565847
Validation loss: 2.5838286167857665

Epoch: 5| Step: 10
Training loss: 2.5695173430769622
Validation loss: 2.5874142904909756

Epoch: 129| Step: 0
Training loss: 2.7339313256122697
Validation loss: 2.5717903997783824

Epoch: 5| Step: 1
Training loss: 2.7410567253503046
Validation loss: 2.55868586167995

Epoch: 5| Step: 2
Training loss: 2.9243921871051195
Validation loss: 2.5225756139807096

Epoch: 5| Step: 3
Training loss: 2.3241467376580385
Validation loss: 2.5063428360216164

Epoch: 5| Step: 4
Training loss: 2.5958564202112195
Validation loss: 2.503540663546231

Epoch: 5| Step: 5
Training loss: 2.4020672398668004
Validation loss: 2.5095666559359757

Epoch: 5| Step: 6
Training loss: 2.620550380729803
Validation loss: 2.4976296570378627

Epoch: 5| Step: 7
Training loss: 2.915118396899916
Validation loss: 2.4986658022697577

Epoch: 5| Step: 8
Training loss: 2.8931527297907222
Validation loss: 2.515289408584817

Epoch: 5| Step: 9
Training loss: 2.464557516221307
Validation loss: 2.5273317784751774

Epoch: 5| Step: 10
Training loss: 2.2692606201595775
Validation loss: 2.5398208563484284

Epoch: 130| Step: 0
Training loss: 2.2163721156592864
Validation loss: 2.5343852596602057

Epoch: 5| Step: 1
Training loss: 2.654307384343847
Validation loss: 2.5316634737419523

Epoch: 5| Step: 2
Training loss: 3.0408175776972417
Validation loss: 2.520093446372118

Epoch: 5| Step: 3
Training loss: 2.365236995831021
Validation loss: 2.521508245411627

Epoch: 5| Step: 4
Training loss: 1.9230716360459643
Validation loss: 2.5209680628199487

Epoch: 5| Step: 5
Training loss: 2.6966069305964613
Validation loss: 2.525139209504412

Epoch: 5| Step: 6
Training loss: 2.6985104372629523
Validation loss: 2.528207157013432

Epoch: 5| Step: 7
Training loss: 2.8807567513501064
Validation loss: 2.537874353674063

Epoch: 5| Step: 8
Training loss: 2.7100256889786705
Validation loss: 2.5274440196910914

Epoch: 5| Step: 9
Training loss: 2.953010839445616
Validation loss: 2.5400592422003885

Epoch: 5| Step: 10
Training loss: 2.5830966984647294
Validation loss: 2.542649560347491

Epoch: 131| Step: 0
Training loss: 2.1719966278049996
Validation loss: 2.54940824726254

Epoch: 5| Step: 1
Training loss: 2.928940334411738
Validation loss: 2.554800522222

Epoch: 5| Step: 2
Training loss: 2.123122114797748
Validation loss: 2.5366619232481797

Epoch: 5| Step: 3
Training loss: 2.2951096997606775
Validation loss: 2.530317105491098

Epoch: 5| Step: 4
Training loss: 3.2225170128538227
Validation loss: 2.520980953354379

Epoch: 5| Step: 5
Training loss: 2.7932536800138017
Validation loss: 2.516125900670478

Epoch: 5| Step: 6
Training loss: 2.8913297876546364
Validation loss: 2.5112583123230015

Epoch: 5| Step: 7
Training loss: 2.727237912880607
Validation loss: 2.5058705344968435

Epoch: 5| Step: 8
Training loss: 2.658723733948891
Validation loss: 2.5379981297170184

Epoch: 5| Step: 9
Training loss: 2.239569115408781
Validation loss: 2.557834362568758

Epoch: 5| Step: 10
Training loss: 2.598035282791102
Validation loss: 2.5528457564201577

Epoch: 132| Step: 0
Training loss: 2.2686414960656296
Validation loss: 2.546065746939597

Epoch: 5| Step: 1
Training loss: 2.347170254234247
Validation loss: 2.534073027562275

Epoch: 5| Step: 2
Training loss: 2.9877447307375182
Validation loss: 2.552130485301661

Epoch: 5| Step: 3
Training loss: 2.3436582420189382
Validation loss: 2.5619897121727435

Epoch: 5| Step: 4
Training loss: 2.821194244090723
Validation loss: 2.557747295896933

Epoch: 5| Step: 5
Training loss: 2.850490086228937
Validation loss: 2.547276858568739

Epoch: 5| Step: 6
Training loss: 2.459366748219162
Validation loss: 2.5407876771477205

Epoch: 5| Step: 7
Training loss: 2.432251194052884
Validation loss: 2.5284538123053313

Epoch: 5| Step: 8
Training loss: 2.521703732712503
Validation loss: 2.5210812940879967

Epoch: 5| Step: 9
Training loss: 2.872777660419625
Validation loss: 2.5280561189850497

Epoch: 5| Step: 10
Training loss: 2.9392058918037813
Validation loss: 2.5241559094718133

Epoch: 133| Step: 0
Training loss: 1.5850935320528676
Validation loss: 2.519119361049369

Epoch: 5| Step: 1
Training loss: 3.3070559119754295
Validation loss: 2.541459235635418

Epoch: 5| Step: 2
Training loss: 2.2204438312300776
Validation loss: 2.537879198361797

Epoch: 5| Step: 3
Training loss: 2.7065325300995027
Validation loss: 2.5480430406339787

Epoch: 5| Step: 4
Training loss: 2.8481066521595
Validation loss: 2.563167102016835

Epoch: 5| Step: 5
Training loss: 2.6447969244030416
Validation loss: 2.547351055093162

Epoch: 5| Step: 6
Training loss: 2.55918232212311
Validation loss: 2.54982564753546

Epoch: 5| Step: 7
Training loss: 2.423423419766378
Validation loss: 2.5301010145214233

Epoch: 5| Step: 8
Training loss: 2.923830245124899
Validation loss: 2.538142131533442

Epoch: 5| Step: 9
Training loss: 2.8112087252492874
Validation loss: 2.534379888359158

Epoch: 5| Step: 10
Training loss: 2.2869659300661223
Validation loss: 2.5398106373796603

Epoch: 134| Step: 0
Training loss: 1.9849599141414143
Validation loss: 2.527651172153691

Epoch: 5| Step: 1
Training loss: 2.917569665542864
Validation loss: 2.511696200195486

Epoch: 5| Step: 2
Training loss: 2.821181905632022
Validation loss: 2.529361481688124

Epoch: 5| Step: 3
Training loss: 2.900903357194231
Validation loss: 2.5217432417096326

Epoch: 5| Step: 4
Training loss: 2.6537569800782372
Validation loss: 2.5289583891351834

Epoch: 5| Step: 5
Training loss: 1.9929735016925052
Validation loss: 2.512244086919719

Epoch: 5| Step: 6
Training loss: 2.943721756526284
Validation loss: 2.518915591197104

Epoch: 5| Step: 7
Training loss: 2.650317669667655
Validation loss: 2.5324227044606316

Epoch: 5| Step: 8
Training loss: 2.3913479378839817
Validation loss: 2.533640385198865

Epoch: 5| Step: 9
Training loss: 2.5039814716055795
Validation loss: 2.5076209147082773

Epoch: 5| Step: 10
Training loss: 2.4319669083301463
Validation loss: 2.516145203355423

Epoch: 135| Step: 0
Training loss: 2.608922039623221
Validation loss: 2.514339317455683

Epoch: 5| Step: 1
Training loss: 2.1994985399078772
Validation loss: 2.518939858446502

Epoch: 5| Step: 2
Training loss: 2.5279592150826597
Validation loss: 2.5318257608678185

Epoch: 5| Step: 3
Training loss: 2.281178512498263
Validation loss: 2.515765901131744

Epoch: 5| Step: 4
Training loss: 2.622210700967051
Validation loss: 2.524904107906962

Epoch: 5| Step: 5
Training loss: 2.5036071503483024
Validation loss: 2.517597584568194

Epoch: 5| Step: 6
Training loss: 2.5670377050289948
Validation loss: 2.5303221237156706

Epoch: 5| Step: 7
Training loss: 2.852221603515674
Validation loss: 2.5383171558875257

Epoch: 5| Step: 8
Training loss: 2.7866034259038868
Validation loss: 2.563501425970693

Epoch: 5| Step: 9
Training loss: 2.7021727896896888
Validation loss: 2.5445594228859805

Epoch: 5| Step: 10
Training loss: 2.6365338295976857
Validation loss: 2.5416908299995233

Epoch: 136| Step: 0
Training loss: 1.9296380781879716
Validation loss: 2.5418366806187884

Epoch: 5| Step: 1
Training loss: 2.3479253579773998
Validation loss: 2.551321799442561

Epoch: 5| Step: 2
Training loss: 2.844656998752531
Validation loss: 2.553534980932519

Epoch: 5| Step: 3
Training loss: 2.219653738012937
Validation loss: 2.552020852230463

Epoch: 5| Step: 4
Training loss: 3.000531785244525
Validation loss: 2.5187711400456587

Epoch: 5| Step: 5
Training loss: 2.5433287475597925
Validation loss: 2.508564559204567

Epoch: 5| Step: 6
Training loss: 2.3468735289791285
Validation loss: 2.5222029952025546

Epoch: 5| Step: 7
Training loss: 2.5616304736619897
Validation loss: 2.5603021039290716

Epoch: 5| Step: 8
Training loss: 3.365788498841409
Validation loss: 2.570024392609271

Epoch: 5| Step: 9
Training loss: 2.68137886786941
Validation loss: 2.553204742892115

Epoch: 5| Step: 10
Training loss: 2.1985938910605656
Validation loss: 2.541824929648982

Epoch: 137| Step: 0
Training loss: 2.4354746302311407
Validation loss: 2.551061488376832

Epoch: 5| Step: 1
Training loss: 2.30772887164273
Validation loss: 2.5645784742088513

Epoch: 5| Step: 2
Training loss: 2.726799634879559
Validation loss: 2.5353003065522492

Epoch: 5| Step: 3
Training loss: 2.8952991532637258
Validation loss: 2.540774440115201

Epoch: 5| Step: 4
Training loss: 2.7177723847913877
Validation loss: 2.5206636059650607

Epoch: 5| Step: 5
Training loss: 2.781693241075491
Validation loss: 2.5106536041303866

Epoch: 5| Step: 6
Training loss: 2.322775718164746
Validation loss: 2.4995423472318956

Epoch: 5| Step: 7
Training loss: 2.657714888604055
Validation loss: 2.514489364618399

Epoch: 5| Step: 8
Training loss: 2.453788521804846
Validation loss: 2.5182820237476697

Epoch: 5| Step: 9
Training loss: 2.77949571467874
Validation loss: 2.5173034571597968

Epoch: 5| Step: 10
Training loss: 1.9830855738402258
Validation loss: 2.528005980550115

Epoch: 138| Step: 0
Training loss: 2.319099494526946
Validation loss: 2.5325827453125394

Epoch: 5| Step: 1
Training loss: 2.6845440244029377
Validation loss: 2.5571502037578866

Epoch: 5| Step: 2
Training loss: 2.3556101489288443
Validation loss: 2.553651599982473

Epoch: 5| Step: 3
Training loss: 2.4283584934136435
Validation loss: 2.558349887323635

Epoch: 5| Step: 4
Training loss: 2.3354025135637984
Validation loss: 2.546816014569918

Epoch: 5| Step: 5
Training loss: 2.5873574222222118
Validation loss: 2.551551587323646

Epoch: 5| Step: 6
Training loss: 2.5132030888748678
Validation loss: 2.549466563348695

Epoch: 5| Step: 7
Training loss: 2.4439307260638197
Validation loss: 2.5575116192867062

Epoch: 5| Step: 8
Training loss: 2.6792158150997496
Validation loss: 2.58641926168634

Epoch: 5| Step: 9
Training loss: 2.6345192106150703
Validation loss: 2.610322721830461

Epoch: 5| Step: 10
Training loss: 3.1179155536836376
Validation loss: 2.631299264347421

Epoch: 139| Step: 0
Training loss: 2.603748033571348
Validation loss: 2.631355660345376

Epoch: 5| Step: 1
Training loss: 2.4666457080809834
Validation loss: 2.5975017749944898

Epoch: 5| Step: 2
Training loss: 2.6566109804693445
Validation loss: 2.5521063643909065

Epoch: 5| Step: 3
Training loss: 2.83095851180851
Validation loss: 2.543808456442198

Epoch: 5| Step: 4
Training loss: 2.494893103165329
Validation loss: 2.5339117342204642

Epoch: 5| Step: 5
Training loss: 1.9104255221240334
Validation loss: 2.508597918666866

Epoch: 5| Step: 6
Training loss: 2.0453160296847526
Validation loss: 2.500549643607095

Epoch: 5| Step: 7
Training loss: 2.29027673590072
Validation loss: 2.5003108610674714

Epoch: 5| Step: 8
Training loss: 2.735588458424839
Validation loss: 2.508846305633159

Epoch: 5| Step: 9
Training loss: 2.8576725128243363
Validation loss: 2.510275752597848

Epoch: 5| Step: 10
Training loss: 2.9193987629763885
Validation loss: 2.528182846894732

Epoch: 140| Step: 0
Training loss: 2.5947922600299203
Validation loss: 2.537903748947451

Epoch: 5| Step: 1
Training loss: 2.8876441226017424
Validation loss: 2.5511047904837985

Epoch: 5| Step: 2
Training loss: 2.917862038659119
Validation loss: 2.563230308912678

Epoch: 5| Step: 3
Training loss: 2.4136446001617333
Validation loss: 2.5613407280975395

Epoch: 5| Step: 4
Training loss: 2.553364168915504
Validation loss: 2.585827873118755

Epoch: 5| Step: 5
Training loss: 2.4648466518282244
Validation loss: 2.618878042180529

Epoch: 5| Step: 6
Training loss: 3.019966755361921
Validation loss: 2.617369552008382

Epoch: 5| Step: 7
Training loss: 2.0614676926528737
Validation loss: 2.6114487670417983

Epoch: 5| Step: 8
Training loss: 2.005024677800163
Validation loss: 2.5888767919727673

Epoch: 5| Step: 9
Training loss: 2.314108418093439
Validation loss: 2.5863433074348188

Epoch: 5| Step: 10
Training loss: 2.267470561785902
Validation loss: 2.564956460067615

Epoch: 141| Step: 0
Training loss: 2.2058048047664953
Validation loss: 2.559382418292546

Epoch: 5| Step: 1
Training loss: 2.5629589321137036
Validation loss: 2.5352318963842544

Epoch: 5| Step: 2
Training loss: 2.555920131450369
Validation loss: 2.528131731405316

Epoch: 5| Step: 3
Training loss: 2.470386397374213
Validation loss: 2.511860476495232

Epoch: 5| Step: 4
Training loss: 1.9487231891737937
Validation loss: 2.4963986966061453

Epoch: 5| Step: 5
Training loss: 2.733629223074711
Validation loss: 2.4891507086963998

Epoch: 5| Step: 6
Training loss: 2.784454728172061
Validation loss: 2.4940912273595908

Epoch: 5| Step: 7
Training loss: 2.643601224424148
Validation loss: 2.513380420599289

Epoch: 5| Step: 8
Training loss: 2.400279974501652
Validation loss: 2.5515766604352565

Epoch: 5| Step: 9
Training loss: 2.386496475782975
Validation loss: 2.5652754824751245

Epoch: 5| Step: 10
Training loss: 2.8204616179631516
Validation loss: 2.5826956021010763

Epoch: 142| Step: 0
Training loss: 2.5962183593820236
Validation loss: 2.5914285221241045

Epoch: 5| Step: 1
Training loss: 2.5072374486720315
Validation loss: 2.591135161145925

Epoch: 5| Step: 2
Training loss: 2.676767877380977
Validation loss: 2.5861361822928086

Epoch: 5| Step: 3
Training loss: 2.5133974626523625
Validation loss: 2.5629769568433343

Epoch: 5| Step: 4
Training loss: 2.0889506205214152
Validation loss: 2.557422621971861

Epoch: 5| Step: 5
Training loss: 1.987864992227953
Validation loss: 2.5587664201103197

Epoch: 5| Step: 6
Training loss: 2.40178762062066
Validation loss: 2.55393882253406

Epoch: 5| Step: 7
Training loss: 2.06531471311197
Validation loss: 2.5477459699972274

Epoch: 5| Step: 8
Training loss: 3.2350323142747515
Validation loss: 2.5477321200898846

Epoch: 5| Step: 9
Training loss: 2.9962435091829236
Validation loss: 2.552354471663439

Epoch: 5| Step: 10
Training loss: 1.758447828979419
Validation loss: 2.5667960908053455

Epoch: 143| Step: 0
Training loss: 2.3964895483083932
Validation loss: 2.5883470291550705

Epoch: 5| Step: 1
Training loss: 2.2167392269486657
Validation loss: 2.5904084470069364

Epoch: 5| Step: 2
Training loss: 2.262381711786643
Validation loss: 2.6086898129092284

Epoch: 5| Step: 3
Training loss: 2.6125138642887764
Validation loss: 2.61420235290849

Epoch: 5| Step: 4
Training loss: 2.2701893047767414
Validation loss: 2.6161035944414817

Epoch: 5| Step: 5
Training loss: 2.448624777676107
Validation loss: 2.60682029308814

Epoch: 5| Step: 6
Training loss: 2.8048158579067426
Validation loss: 2.5808555315715767

Epoch: 5| Step: 7
Training loss: 2.489226396795678
Validation loss: 2.57120353723154

Epoch: 5| Step: 8
Training loss: 1.7608381891552247
Validation loss: 2.5779611037616057

Epoch: 5| Step: 9
Training loss: 2.6394548701514413
Validation loss: 2.589451670484644

Epoch: 5| Step: 10
Training loss: 3.0569816228521973
Validation loss: 2.610694887934563

Epoch: 144| Step: 0
Training loss: 2.6465332026745645
Validation loss: 2.6069565416198235

Epoch: 5| Step: 1
Training loss: 2.4600326570033473
Validation loss: 2.578290173462151

Epoch: 5| Step: 2
Training loss: 2.2171501516754484
Validation loss: 2.569298099280939

Epoch: 5| Step: 3
Training loss: 1.933692760051891
Validation loss: 2.5575780231816174

Epoch: 5| Step: 4
Training loss: 2.5218786379044587
Validation loss: 2.5728390456812322

Epoch: 5| Step: 5
Training loss: 2.324195361620768
Validation loss: 2.569944641458247

Epoch: 5| Step: 6
Training loss: 3.1001259193688218
Validation loss: 2.545367073015867

Epoch: 5| Step: 7
Training loss: 2.3469134534588454
Validation loss: 2.5386994627847557

Epoch: 5| Step: 8
Training loss: 2.2898639408654353
Validation loss: 2.5177588783343596

Epoch: 5| Step: 9
Training loss: 2.422442560449927
Validation loss: 2.502481092841118

Epoch: 5| Step: 10
Training loss: 2.607481857924288
Validation loss: 2.492672088528071

Epoch: 145| Step: 0
Training loss: 2.073863313325736
Validation loss: 2.4773466489421145

Epoch: 5| Step: 1
Training loss: 2.90800078785294
Validation loss: 2.4801136923189704

Epoch: 5| Step: 2
Training loss: 2.497042814304009
Validation loss: 2.4827738673123165

Epoch: 5| Step: 3
Training loss: 2.242998886836027
Validation loss: 2.493569221639573

Epoch: 5| Step: 4
Training loss: 2.5496776115224793
Validation loss: 2.5028319838660704

Epoch: 5| Step: 5
Training loss: 2.7265714191629726
Validation loss: 2.5093644407053213

Epoch: 5| Step: 6
Training loss: 2.485785605671185
Validation loss: 2.5205896104314944

Epoch: 5| Step: 7
Training loss: 1.8537225798664398
Validation loss: 2.535070395642187

Epoch: 5| Step: 8
Training loss: 2.713446958991731
Validation loss: 2.5803593126669195

Epoch: 5| Step: 9
Training loss: 2.0385332261035685
Validation loss: 2.5592549338706534

Epoch: 5| Step: 10
Training loss: 2.5599388721737784
Validation loss: 2.546611060306568

Epoch: 146| Step: 0
Training loss: 2.50678001374123
Validation loss: 2.548260846547231

Epoch: 5| Step: 1
Training loss: 2.449546001176022
Validation loss: 2.5386301697091196

Epoch: 5| Step: 2
Training loss: 1.977588854504322
Validation loss: 2.523830935687528

Epoch: 5| Step: 3
Training loss: 2.6176635309269636
Validation loss: 2.5117331455145884

Epoch: 5| Step: 4
Training loss: 2.47522119246536
Validation loss: 2.512717843135552

Epoch: 5| Step: 5
Training loss: 2.2193394267551554
Validation loss: 2.5145361634392813

Epoch: 5| Step: 6
Training loss: 1.9860253267353989
Validation loss: 2.5349192871754167

Epoch: 5| Step: 7
Training loss: 2.4617263740559503
Validation loss: 2.5476856754598582

Epoch: 5| Step: 8
Training loss: 2.613489527592131
Validation loss: 2.541060710498586

Epoch: 5| Step: 9
Training loss: 2.3797661991844414
Validation loss: 2.552308473749705

Epoch: 5| Step: 10
Training loss: 2.841770866773168
Validation loss: 2.5477021730806353

Epoch: 147| Step: 0
Training loss: 2.4927444074937384
Validation loss: 2.544620931960985

Epoch: 5| Step: 1
Training loss: 2.4388478782795517
Validation loss: 2.5595292089098236

Epoch: 5| Step: 2
Training loss: 2.4196694452557357
Validation loss: 2.5732345281748756

Epoch: 5| Step: 3
Training loss: 2.5573865532347697
Validation loss: 2.5910209326782176

Epoch: 5| Step: 4
Training loss: 2.183106069409026
Validation loss: 2.56314448773998

Epoch: 5| Step: 5
Training loss: 2.5689988881216763
Validation loss: 2.565527975025336

Epoch: 5| Step: 6
Training loss: 2.185617127026632
Validation loss: 2.5866361008425938

Epoch: 5| Step: 7
Training loss: 2.3049326620795654
Validation loss: 2.585906203009654

Epoch: 5| Step: 8
Training loss: 2.927570035570693
Validation loss: 2.5716284225837085

Epoch: 5| Step: 9
Training loss: 2.2670247982437357
Validation loss: 2.5518918985003

Epoch: 5| Step: 10
Training loss: 2.144908322951633
Validation loss: 2.5392271704397986

Epoch: 148| Step: 0
Training loss: 2.124769871536333
Validation loss: 2.5138597510698646

Epoch: 5| Step: 1
Training loss: 2.2038921346283398
Validation loss: 2.5235961835723204

Epoch: 5| Step: 2
Training loss: 2.442784474263216
Validation loss: 2.5160397586598364

Epoch: 5| Step: 3
Training loss: 2.3304878891386926
Validation loss: 2.5178332278985245

Epoch: 5| Step: 4
Training loss: 2.6064821757357133
Validation loss: 2.5207511785414094

Epoch: 5| Step: 5
Training loss: 2.3528288919640628
Validation loss: 2.517710143661359

Epoch: 5| Step: 6
Training loss: 2.139907048247746
Validation loss: 2.5327419440236496

Epoch: 5| Step: 7
Training loss: 2.1416924035966356
Validation loss: 2.5616191647696946

Epoch: 5| Step: 8
Training loss: 2.9538660482048447
Validation loss: 2.58498663763814

Epoch: 5| Step: 9
Training loss: 2.537502337675474
Validation loss: 2.5990693991751015

Epoch: 5| Step: 10
Training loss: 2.1956974655862953
Validation loss: 2.6094242951200504

Epoch: 149| Step: 0
Training loss: 2.483129224987262
Validation loss: 2.59367366045365

Epoch: 5| Step: 1
Training loss: 2.391796747407313
Validation loss: 2.579348133609505

Epoch: 5| Step: 2
Training loss: 1.4220374716691888
Validation loss: 2.5615225507675334

Epoch: 5| Step: 3
Training loss: 1.9413562668443094
Validation loss: 2.569672075709306

Epoch: 5| Step: 4
Training loss: 1.8965189466065575
Validation loss: 2.5779007312906903

Epoch: 5| Step: 5
Training loss: 2.950210343959969
Validation loss: 2.578379677442727

Epoch: 5| Step: 6
Training loss: 2.8591992266883937
Validation loss: 2.5781131837337274

Epoch: 5| Step: 7
Training loss: 2.4483409324547107
Validation loss: 2.563736140971363

Epoch: 5| Step: 8
Training loss: 2.6505544298416095
Validation loss: 2.5590434849180506

Epoch: 5| Step: 9
Training loss: 2.164043660546662
Validation loss: 2.538563707452516

Epoch: 5| Step: 10
Training loss: 2.278423491756545
Validation loss: 2.5230455047424005

Epoch: 150| Step: 0
Training loss: 2.1278041961906786
Validation loss: 2.528798301387588

Epoch: 5| Step: 1
Training loss: 2.2872325886830764
Validation loss: 2.5310399150476086

Epoch: 5| Step: 2
Training loss: 2.6994649109613325
Validation loss: 2.5450774663492335

Epoch: 5| Step: 3
Training loss: 2.5510381829168027
Validation loss: 2.5575963895494374

Epoch: 5| Step: 4
Training loss: 2.2106586186055814
Validation loss: 2.6024736186520427

Epoch: 5| Step: 5
Training loss: 3.0814377052439057
Validation loss: 2.6488012611606475

Epoch: 5| Step: 6
Training loss: 1.9771754705293147
Validation loss: 2.637730507594333

Epoch: 5| Step: 7
Training loss: 2.4590198614273215
Validation loss: 2.639957631744732

Epoch: 5| Step: 8
Training loss: 2.0486217936724
Validation loss: 2.618288184668911

Epoch: 5| Step: 9
Training loss: 2.0371964491817165
Validation loss: 2.615349761234113

Epoch: 5| Step: 10
Training loss: 2.1369723600136146
Validation loss: 2.6397285626661717

Epoch: 151| Step: 0
Training loss: 2.210902453033565
Validation loss: 2.657630520163753

Epoch: 5| Step: 1
Training loss: 2.4972738661168377
Validation loss: 2.6013004617285196

Epoch: 5| Step: 2
Training loss: 2.9456254302117
Validation loss: 2.5880708211556063

Epoch: 5| Step: 3
Training loss: 2.296352923998486
Validation loss: 2.6160697194437814

Epoch: 5| Step: 4
Training loss: 1.653735789658209
Validation loss: 2.661464317335439

Epoch: 5| Step: 5
Training loss: 2.1692736298602986
Validation loss: 2.6828154792658974

Epoch: 5| Step: 6
Training loss: 2.870258900199563
Validation loss: 2.658673040617231

Epoch: 5| Step: 7
Training loss: 3.137932225581641
Validation loss: 2.585048202284529

Epoch: 5| Step: 8
Training loss: 2.3378966418247034
Validation loss: 2.5161104074713845

Epoch: 5| Step: 9
Training loss: 2.167099787141044
Validation loss: 2.4897524854775974

Epoch: 5| Step: 10
Training loss: 2.132591711221067
Validation loss: 2.4619570321995674

Epoch: 152| Step: 0
Training loss: 2.3366668481141954
Validation loss: 2.449141512529208

Epoch: 5| Step: 1
Training loss: 1.7843690968965336
Validation loss: 2.444050271483007

Epoch: 5| Step: 2
Training loss: 2.4438765822307857
Validation loss: 2.4502159810333457

Epoch: 5| Step: 3
Training loss: 2.229597626380492
Validation loss: 2.4744741238704275

Epoch: 5| Step: 4
Training loss: 2.7545375668492595
Validation loss: 2.487101083833982

Epoch: 5| Step: 5
Training loss: 2.098585438005012
Validation loss: 2.4663183184424984

Epoch: 5| Step: 6
Training loss: 2.5360323151957354
Validation loss: 2.443688075966856

Epoch: 5| Step: 7
Training loss: 2.378803219623353
Validation loss: 2.4387129297086663

Epoch: 5| Step: 8
Training loss: 2.466987173633918
Validation loss: 2.4686728003692657

Epoch: 5| Step: 9
Training loss: 2.401110225424112
Validation loss: 2.5052833442713816

Epoch: 5| Step: 10
Training loss: 2.559466264189789
Validation loss: 2.5292953678084964

Epoch: 153| Step: 0
Training loss: 2.6578931326411555
Validation loss: 2.583547229690916

Epoch: 5| Step: 1
Training loss: 2.4868870157208955
Validation loss: 2.5770814933541155

Epoch: 5| Step: 2
Training loss: 2.558344192564674
Validation loss: 2.5535142240265207

Epoch: 5| Step: 3
Training loss: 2.034058258197562
Validation loss: 2.5502860944495453

Epoch: 5| Step: 4
Training loss: 2.628371480480698
Validation loss: 2.532879279604275

Epoch: 5| Step: 5
Training loss: 1.4880349263276131
Validation loss: 2.5282647377212215

Epoch: 5| Step: 6
Training loss: 1.7925123244624037
Validation loss: 2.5241666519022634

Epoch: 5| Step: 7
Training loss: 2.094094660844605
Validation loss: 2.531041561990548

Epoch: 5| Step: 8
Training loss: 2.8412511557204536
Validation loss: 2.548154639691248

Epoch: 5| Step: 9
Training loss: 2.2563405238032423
Validation loss: 2.563777730084665

Epoch: 5| Step: 10
Training loss: 2.580900235990769
Validation loss: 2.569343556562413

Epoch: 154| Step: 0
Training loss: 2.4632777152624397
Validation loss: 2.578325004190591

Epoch: 5| Step: 1
Training loss: 2.068134933267984
Validation loss: 2.5727072013518795

Epoch: 5| Step: 2
Training loss: 1.9671812316455308
Validation loss: 2.5825676658304446

Epoch: 5| Step: 3
Training loss: 2.201936983161353
Validation loss: 2.5853365482485344

Epoch: 5| Step: 4
Training loss: 2.216834087311566
Validation loss: 2.5800069046595855

Epoch: 5| Step: 5
Training loss: 2.1261429798209925
Validation loss: 2.5695672162660905

Epoch: 5| Step: 6
Training loss: 1.9896414250652537
Validation loss: 2.5489246770518554

Epoch: 5| Step: 7
Training loss: 1.9211227681627725
Validation loss: 2.542779265088041

Epoch: 5| Step: 8
Training loss: 2.7012559018474396
Validation loss: 2.524351811230044

Epoch: 5| Step: 9
Training loss: 2.7991550464924586
Validation loss: 2.528256421450801

Epoch: 5| Step: 10
Training loss: 2.377285409864031
Validation loss: 2.532035595333768

Epoch: 155| Step: 0
Training loss: 2.551079865482855
Validation loss: 2.5392534939828844

Epoch: 5| Step: 1
Training loss: 2.2421932419759885
Validation loss: 2.578337462798215

Epoch: 5| Step: 2
Training loss: 2.5058728854736136
Validation loss: 2.5915116418232182

Epoch: 5| Step: 3
Training loss: 1.6380764012293958
Validation loss: 2.5790392296620848

Epoch: 5| Step: 4
Training loss: 1.4521822588739615
Validation loss: 2.542312221020398

Epoch: 5| Step: 5
Training loss: 2.0064467003913236
Validation loss: 2.54893653810995

Epoch: 5| Step: 6
Training loss: 2.4286822726494988
Validation loss: 2.546645407233883

Epoch: 5| Step: 7
Training loss: 3.03153943125307
Validation loss: 2.5436030461707566

Epoch: 5| Step: 8
Training loss: 2.23191805116211
Validation loss: 2.558220921925705

Epoch: 5| Step: 9
Training loss: 2.071885227736233
Validation loss: 2.551241129034939

Epoch: 5| Step: 10
Training loss: 2.0026889844244313
Validation loss: 2.5607824304427482

Epoch: 156| Step: 0
Training loss: 2.2432725786292735
Validation loss: 2.5349830264763726

Epoch: 5| Step: 1
Training loss: 2.2023256623877563
Validation loss: 2.5362208354739613

Epoch: 5| Step: 2
Training loss: 2.155183721973086
Validation loss: 2.5245458160919036

Epoch: 5| Step: 3
Training loss: 2.609747488880676
Validation loss: 2.524524231847205

Epoch: 5| Step: 4
Training loss: 1.9703547885358867
Validation loss: 2.524429709874604

Epoch: 5| Step: 5
Training loss: 2.160770487589235
Validation loss: 2.530557346005294

Epoch: 5| Step: 6
Training loss: 2.409917043627338
Validation loss: 2.519436343301385

Epoch: 5| Step: 7
Training loss: 2.190646714825283
Validation loss: 2.505324387221762

Epoch: 5| Step: 8
Training loss: 2.5137961237624786
Validation loss: 2.5368854942701247

Epoch: 5| Step: 9
Training loss: 1.8729550336133598
Validation loss: 2.527100953914127

Epoch: 5| Step: 10
Training loss: 1.9428246457323268
Validation loss: 2.5338186308698263

Epoch: 157| Step: 0
Training loss: 2.1717826768751407
Validation loss: 2.5394172182141648

Epoch: 5| Step: 1
Training loss: 2.226479404973575
Validation loss: 2.5388044086349497

Epoch: 5| Step: 2
Training loss: 2.4236036468750406
Validation loss: 2.539892369810287

Epoch: 5| Step: 3
Training loss: 2.1342135009432965
Validation loss: 2.5585556998105

Epoch: 5| Step: 4
Training loss: 1.9723913033709313
Validation loss: 2.5539852332501587

Epoch: 5| Step: 5
Training loss: 2.3703307380552983
Validation loss: 2.539309506198329

Epoch: 5| Step: 6
Training loss: 2.165470808080357
Validation loss: 2.5660782049013733

Epoch: 5| Step: 7
Training loss: 2.2403504824627865
Validation loss: 2.5830483360421908

Epoch: 5| Step: 8
Training loss: 2.6470914137460895
Validation loss: 2.591888143976218

Epoch: 5| Step: 9
Training loss: 1.825661588966246
Validation loss: 2.5834160707808747

Epoch: 5| Step: 10
Training loss: 1.7345383713217544
Validation loss: 2.5610892221281225

Epoch: 158| Step: 0
Training loss: 1.533497542765825
Validation loss: 2.5802776697975225

Epoch: 5| Step: 1
Training loss: 2.3706151740114154
Validation loss: 2.5792487038900167

Epoch: 5| Step: 2
Training loss: 2.5552429155408833
Validation loss: 2.5764111333252955

Epoch: 5| Step: 3
Training loss: 2.391839211472543
Validation loss: 2.5974783680517732

Epoch: 5| Step: 4
Training loss: 2.0096046375861993
Validation loss: 2.573977516031689

Epoch: 5| Step: 5
Training loss: 1.6178949992244938
Validation loss: 2.5954212656148408

Epoch: 5| Step: 6
Training loss: 2.4408778725108684
Validation loss: 2.5687330739179948

Epoch: 5| Step: 7
Training loss: 1.845468528411002
Validation loss: 2.5298615829023876

Epoch: 5| Step: 8
Training loss: 2.3470754809535754
Validation loss: 2.507496502070786

Epoch: 5| Step: 9
Training loss: 2.0935468432805044
Validation loss: 2.4910733840574553

Epoch: 5| Step: 10
Training loss: 2.1843241935355198
Validation loss: 2.4905584324501344

Epoch: 159| Step: 0
Training loss: 2.0045473140424046
Validation loss: 2.489234757465385

Epoch: 5| Step: 1
Training loss: 2.0778089010431517
Validation loss: 2.4770249698095452

Epoch: 5| Step: 2
Training loss: 2.2244991981880458
Validation loss: 2.472349320609202

Epoch: 5| Step: 3
Training loss: 2.0792368732389828
Validation loss: 2.4892349356365324

Epoch: 5| Step: 4
Training loss: 2.196240320678294
Validation loss: 2.505062719600557

Epoch: 5| Step: 5
Training loss: 2.3437790932439104
Validation loss: 2.521141719506338

Epoch: 5| Step: 6
Training loss: 2.048201851635411
Validation loss: 2.5451008415007466

Epoch: 5| Step: 7
Training loss: 1.6703086717381512
Validation loss: 2.583218915021734

Epoch: 5| Step: 8
Training loss: 2.080044884931005
Validation loss: 2.6369752018589065

Epoch: 5| Step: 9
Training loss: 2.599389253922583
Validation loss: 2.6826096149260366

Epoch: 5| Step: 10
Training loss: 1.8996699849680023
Validation loss: 2.625223694238907

Epoch: 160| Step: 0
Training loss: 1.8231713108043466
Validation loss: 2.613816938323615

Epoch: 5| Step: 1
Training loss: 2.087260423263931
Validation loss: 2.592739716478517

Epoch: 5| Step: 2
Training loss: 2.2119041459490734
Validation loss: 2.571117542479185

Epoch: 5| Step: 3
Training loss: 1.4869924657152342
Validation loss: 2.5852611373367194

Epoch: 5| Step: 4
Training loss: 2.766945389032583
Validation loss: 2.5856291145858847

Epoch: 5| Step: 5
Training loss: 2.2618476685988482
Validation loss: 2.5692900300754307

Epoch: 5| Step: 6
Training loss: 2.529488032713656
Validation loss: 2.5777480559915764

Epoch: 5| Step: 7
Training loss: 1.2034575758185428
Validation loss: 2.567525454315711

Epoch: 5| Step: 8
Training loss: 2.055214353830678
Validation loss: 2.5696764204837366

Epoch: 5| Step: 9
Training loss: 1.978061514704998
Validation loss: 2.5392441450320833

Epoch: 5| Step: 10
Training loss: 2.4110052508404203
Validation loss: 2.4996473207176453

Epoch: 161| Step: 0
Training loss: 2.1189701697359293
Validation loss: 2.463707087629063

Epoch: 5| Step: 1
Training loss: 2.3041243560199067
Validation loss: 2.4390095742056017

Epoch: 5| Step: 2
Training loss: 2.0508464693870465
Validation loss: 2.4461877100517304

Epoch: 5| Step: 3
Training loss: 2.1031562972892996
Validation loss: 2.4529573785498076

Epoch: 5| Step: 4
Training loss: 1.8235095849126515
Validation loss: 2.464936790376395

Epoch: 5| Step: 5
Training loss: 2.41437170523691
Validation loss: 2.5045698729250625

Epoch: 5| Step: 6
Training loss: 1.506444518006119
Validation loss: 2.5278888740933807

Epoch: 5| Step: 7
Training loss: 1.7916195515788187
Validation loss: 2.5352159344539547

Epoch: 5| Step: 8
Training loss: 2.0608312618472984
Validation loss: 2.536353175520808

Epoch: 5| Step: 9
Training loss: 2.3567303114862086
Validation loss: 2.55549039225571

Epoch: 5| Step: 10
Training loss: 2.422048747075341
Validation loss: 2.5322751048637957

Epoch: 162| Step: 0
Training loss: 2.507921448239468
Validation loss: 2.5251253249448635

Epoch: 5| Step: 1
Training loss: 1.5294902576935614
Validation loss: 2.512342943925208

Epoch: 5| Step: 2
Training loss: 2.133765374582475
Validation loss: 2.518352072160467

Epoch: 5| Step: 3
Training loss: 1.929188899440099
Validation loss: 2.5236008900844262

Epoch: 5| Step: 4
Training loss: 2.1797863790856353
Validation loss: 2.5508258855059807

Epoch: 5| Step: 5
Training loss: 2.224128115126815
Validation loss: 2.5476684044143694

Epoch: 5| Step: 6
Training loss: 2.201553325214315
Validation loss: 2.5503489430707993

Epoch: 5| Step: 7
Training loss: 2.0182974198808403
Validation loss: 2.5368333849071436

Epoch: 5| Step: 8
Training loss: 1.919771237056805
Validation loss: 2.552460275269615

Epoch: 5| Step: 9
Training loss: 1.8852838149782114
Validation loss: 2.5306455497401803

Epoch: 5| Step: 10
Training loss: 1.9515626685918974
Validation loss: 2.5230942826746547

Epoch: 163| Step: 0
Training loss: 1.963062001808174
Validation loss: 2.514706863376094

Epoch: 5| Step: 1
Training loss: 2.3106334473360324
Validation loss: 2.52501094803152

Epoch: 5| Step: 2
Training loss: 2.0279902197396966
Validation loss: 2.515973994732309

Epoch: 5| Step: 3
Training loss: 2.121804920775275
Validation loss: 2.5066855007347493

Epoch: 5| Step: 4
Training loss: 1.373584365370057
Validation loss: 2.4994035624623474

Epoch: 5| Step: 5
Training loss: 2.2164924849527576
Validation loss: 2.517344860684046

Epoch: 5| Step: 6
Training loss: 2.017393770316474
Validation loss: 2.5338234499237973

Epoch: 5| Step: 7
Training loss: 1.9167313633932335
Validation loss: 2.554133846161287

Epoch: 5| Step: 8
Training loss: 2.0923936920324713
Validation loss: 2.543497426464238

Epoch: 5| Step: 9
Training loss: 2.0139092528384226
Validation loss: 2.5727372548884495

Epoch: 5| Step: 10
Training loss: 1.999936162406636
Validation loss: 2.562928516845487

Epoch: 164| Step: 0
Training loss: 1.9535160741288726
Validation loss: 2.5281366839987447

Epoch: 5| Step: 1
Training loss: 1.8389464050830362
Validation loss: 2.5115492290563433

Epoch: 5| Step: 2
Training loss: 2.0213441367040983
Validation loss: 2.542705971622044

Epoch: 5| Step: 3
Training loss: 2.1505236675465196
Validation loss: 2.537137723220588

Epoch: 5| Step: 4
Training loss: 1.742583225621598
Validation loss: 2.5500233030450814

Epoch: 5| Step: 5
Training loss: 1.9068102404195206
Validation loss: 2.5767981014799854

Epoch: 5| Step: 6
Training loss: 1.890560306671766
Validation loss: 2.57496833745962

Epoch: 5| Step: 7
Training loss: 2.2700192686767164
Validation loss: 2.5544629840801645

Epoch: 5| Step: 8
Training loss: 1.7161202860557758
Validation loss: 2.5545122469644745

Epoch: 5| Step: 9
Training loss: 2.27285087856208
Validation loss: 2.562992541830624

Epoch: 5| Step: 10
Training loss: 2.206415195062001
Validation loss: 2.5506378745603757

Epoch: 165| Step: 0
Training loss: 1.7855961964934184
Validation loss: 2.5101010234723944

Epoch: 5| Step: 1
Training loss: 2.019789894999028
Validation loss: 2.4990213037165714

Epoch: 5| Step: 2
Training loss: 2.638686151134123
Validation loss: 2.5044108969105343

Epoch: 5| Step: 3
Training loss: 2.1607250271905127
Validation loss: 2.5093284264760176

Epoch: 5| Step: 4
Training loss: 1.9122119287687525
Validation loss: 2.5170786122835302

Epoch: 5| Step: 5
Training loss: 1.6523521910106869
Validation loss: 2.5122264421111873

Epoch: 5| Step: 6
Training loss: 1.9270152380657053
Validation loss: 2.5226452515057853

Epoch: 5| Step: 7
Training loss: 1.7338501419596677
Validation loss: 2.5327626889715398

Epoch: 5| Step: 8
Training loss: 1.8939079596482877
Validation loss: 2.538605340357721

Epoch: 5| Step: 9
Training loss: 2.0428628985260056
Validation loss: 2.5136542381741758

Epoch: 5| Step: 10
Training loss: 1.4638335546659638
Validation loss: 2.5112214886482325

Epoch: 166| Step: 0
Training loss: 1.8648086141816926
Validation loss: 2.5056366503902954

Epoch: 5| Step: 1
Training loss: 2.1205343559088696
Validation loss: 2.4999488548461564

Epoch: 5| Step: 2
Training loss: 2.062468788604396
Validation loss: 2.494406693274121

Epoch: 5| Step: 3
Training loss: 2.118225631417022
Validation loss: 2.5082486979278413

Epoch: 5| Step: 4
Training loss: 1.9705090611522211
Validation loss: 2.5112671866345604

Epoch: 5| Step: 5
Training loss: 2.1820658079061133
Validation loss: 2.5208666589158395

Epoch: 5| Step: 6
Training loss: 2.1346764995261918
Validation loss: 2.5487840700756403

Epoch: 5| Step: 7
Training loss: 2.1073199398641336
Validation loss: 2.5619990101435532

Epoch: 5| Step: 8
Training loss: 1.470140326672472
Validation loss: 2.5786474897311003

Epoch: 5| Step: 9
Training loss: 1.2951626791088622
Validation loss: 2.566483836127292

Epoch: 5| Step: 10
Training loss: 1.6634133375621316
Validation loss: 2.5366681810955853

Epoch: 167| Step: 0
Training loss: 2.2408008075517905
Validation loss: 2.536975800146497

Epoch: 5| Step: 1
Training loss: 2.004029030412566
Validation loss: 2.498159694127618

Epoch: 5| Step: 2
Training loss: 1.5112144555643938
Validation loss: 2.4969667902364523

Epoch: 5| Step: 3
Training loss: 1.5976804997252332
Validation loss: 2.5016464451844347

Epoch: 5| Step: 4
Training loss: 1.5864910043052034
Validation loss: 2.493008525955252

Epoch: 5| Step: 5
Training loss: 1.7376425952167345
Validation loss: 2.4939513518387955

Epoch: 5| Step: 6
Training loss: 1.917216415622471
Validation loss: 2.5005747718889597

Epoch: 5| Step: 7
Training loss: 1.824254429731706
Validation loss: 2.5030795828704404

Epoch: 5| Step: 8
Training loss: 2.3540599652530783
Validation loss: 2.493766865167082

Epoch: 5| Step: 9
Training loss: 2.2362008270947227
Validation loss: 2.482759713819397

Epoch: 5| Step: 10
Training loss: 1.9521574752010655
Validation loss: 2.4637795393536446

Epoch: 168| Step: 0
Training loss: 1.7918430359846504
Validation loss: 2.4907734829159276

Epoch: 5| Step: 1
Training loss: 2.0240389250453847
Validation loss: 2.5050848522244884

Epoch: 5| Step: 2
Training loss: 1.7604703349523367
Validation loss: 2.5239032749936476

Epoch: 5| Step: 3
Training loss: 2.071288717180841
Validation loss: 2.5393598555621746

Epoch: 5| Step: 4
Training loss: 1.8709716119901245
Validation loss: 2.546673522464952

Epoch: 5| Step: 5
Training loss: 2.149151936431652
Validation loss: 2.5574220846685956

Epoch: 5| Step: 6
Training loss: 1.9076194846751744
Validation loss: 2.5653112034468126

Epoch: 5| Step: 7
Training loss: 1.729622386337393
Validation loss: 2.574193139546137

Epoch: 5| Step: 8
Training loss: 1.9586320676277416
Validation loss: 2.5537585595110714

Epoch: 5| Step: 9
Training loss: 1.8750949835560804
Validation loss: 2.545568029552525

Epoch: 5| Step: 10
Training loss: 1.6372485339020848
Validation loss: 2.5252860373995154

Epoch: 169| Step: 0
Training loss: 1.9575459608623624
Validation loss: 2.4901917460245446

Epoch: 5| Step: 1
Training loss: 1.9224761394910033
Validation loss: 2.4705259364075114

Epoch: 5| Step: 2
Training loss: 2.1586469513242377
Validation loss: 2.48572606478665

Epoch: 5| Step: 3
Training loss: 2.1067040381356072
Validation loss: 2.4979641613393793

Epoch: 5| Step: 4
Training loss: 1.4720083577188317
Validation loss: 2.5012450512155824

Epoch: 5| Step: 5
Training loss: 2.123275618175494
Validation loss: 2.52419825329395

Epoch: 5| Step: 6
Training loss: 1.4130932768846634
Validation loss: 2.5205151580775853

Epoch: 5| Step: 7
Training loss: 1.4976717045185106
Validation loss: 2.550278599395282

Epoch: 5| Step: 8
Training loss: 2.3551588977572835
Validation loss: 2.550786558622896

Epoch: 5| Step: 9
Training loss: 1.9566546475606155
Validation loss: 2.538198190999645

Epoch: 5| Step: 10
Training loss: 1.4892286754321824
Validation loss: 2.5204602091394914

Epoch: 170| Step: 0
Training loss: 1.8199660335766716
Validation loss: 2.522188848502032

Epoch: 5| Step: 1
Training loss: 2.263244957282313
Validation loss: 2.5198846257433307

Epoch: 5| Step: 2
Training loss: 1.5539283624286877
Validation loss: 2.5035550589810502

Epoch: 5| Step: 3
Training loss: 1.395503114194549
Validation loss: 2.4925460575498355

Epoch: 5| Step: 4
Training loss: 1.7051213314704032
Validation loss: 2.5093611714889237

Epoch: 5| Step: 5
Training loss: 1.5962377093983826
Validation loss: 2.492626724322074

Epoch: 5| Step: 6
Training loss: 2.2892842364407406
Validation loss: 2.5069251425375216

Epoch: 5| Step: 7
Training loss: 2.237877934253923
Validation loss: 2.5342668577647305

Epoch: 5| Step: 8
Training loss: 1.8139299474057589
Validation loss: 2.5168762091545727

Epoch: 5| Step: 9
Training loss: 1.9677350288977975
Validation loss: 2.520955266794302

Epoch: 5| Step: 10
Training loss: 1.4715622296255093
Validation loss: 2.510686222092642

Epoch: 171| Step: 0
Training loss: 2.238904297078607
Validation loss: 2.5104994962951186

Epoch: 5| Step: 1
Training loss: 2.3236614681162577
Validation loss: 2.478087786019151

Epoch: 5| Step: 2
Training loss: 1.7837590398739829
Validation loss: 2.486713791145055

Epoch: 5| Step: 3
Training loss: 2.0485312480410056
Validation loss: 2.498706353715323

Epoch: 5| Step: 4
Training loss: 1.700720253000853
Validation loss: 2.5020249277454476

Epoch: 5| Step: 5
Training loss: 1.3340770862360085
Validation loss: 2.5229539798156506

Epoch: 5| Step: 6
Training loss: 1.4487351590071953
Validation loss: 2.520366284915604

Epoch: 5| Step: 7
Training loss: 1.7282209759458478
Validation loss: 2.5341909276453105

Epoch: 5| Step: 8
Training loss: 1.6151362139062562
Validation loss: 2.585278108156881

Epoch: 5| Step: 9
Training loss: 1.9675998658521605
Validation loss: 2.6361952677299985

Epoch: 5| Step: 10
Training loss: 1.8073219128220552
Validation loss: 2.6552453724808713

Epoch: 172| Step: 0
Training loss: 1.7365633244192442
Validation loss: 2.6363381956838174

Epoch: 5| Step: 1
Training loss: 1.2775706984932136
Validation loss: 2.5969174078450683

Epoch: 5| Step: 2
Training loss: 2.0803569767973533
Validation loss: 2.5770290577314965

Epoch: 5| Step: 3
Training loss: 2.01414506386391
Validation loss: 2.5904733237863327

Epoch: 5| Step: 4
Training loss: 1.890638493261186
Validation loss: 2.5452344381671224

Epoch: 5| Step: 5
Training loss: 1.4568248121862455
Validation loss: 2.549048980572565

Epoch: 5| Step: 6
Training loss: 1.7510835835078415
Validation loss: 2.4849337120290924

Epoch: 5| Step: 7
Training loss: 2.2195661950910295
Validation loss: 2.4580982612760502

Epoch: 5| Step: 8
Training loss: 2.124409088552603
Validation loss: 2.39280141887172

Epoch: 5| Step: 9
Training loss: 1.8653991945953936
Validation loss: 2.3914067207892313

Epoch: 5| Step: 10
Training loss: 1.4671317580484184
Validation loss: 2.394032803765197

Epoch: 173| Step: 0
Training loss: 2.0489335519377754
Validation loss: 2.417526182084717

Epoch: 5| Step: 1
Training loss: 1.8830230088694515
Validation loss: 2.469355743433865

Epoch: 5| Step: 2
Training loss: 1.9570820510575262
Validation loss: 2.4643422107576445

Epoch: 5| Step: 3
Training loss: 2.2099091527571764
Validation loss: 2.4542659898690617

Epoch: 5| Step: 4
Training loss: 1.804749128602242
Validation loss: 2.437143346515881

Epoch: 5| Step: 5
Training loss: 1.326506672146118
Validation loss: 2.489243977033125

Epoch: 5| Step: 6
Training loss: 2.00913560073022
Validation loss: 2.5255191676585382

Epoch: 5| Step: 7
Training loss: 1.8942679625363466
Validation loss: 2.574022384723552

Epoch: 5| Step: 8
Training loss: 1.5523850917830626
Validation loss: 2.570248443905465

Epoch: 5| Step: 9
Training loss: 1.7657270823988065
Validation loss: 2.547374441586164

Epoch: 5| Step: 10
Training loss: 1.5835435209132531
Validation loss: 2.536174925020786

Epoch: 174| Step: 0
Training loss: 1.806916680767365
Validation loss: 2.481973999730293

Epoch: 5| Step: 1
Training loss: 1.9578605919949377
Validation loss: 2.4625492170774987

Epoch: 5| Step: 2
Training loss: 1.2087190056410044
Validation loss: 2.4467195160270574

Epoch: 5| Step: 3
Training loss: 1.588646665344494
Validation loss: 2.4170929091203948

Epoch: 5| Step: 4
Training loss: 2.3090571988811965
Validation loss: 2.4140423646012743

Epoch: 5| Step: 5
Training loss: 1.5691445025585335
Validation loss: 2.409335947500316

Epoch: 5| Step: 6
Training loss: 1.9290873099937331
Validation loss: 2.421586969656357

Epoch: 5| Step: 7
Training loss: 2.056581038058329
Validation loss: 2.437065716874166

Epoch: 5| Step: 8
Training loss: 1.8460918360315606
Validation loss: 2.4447968307592904

Epoch: 5| Step: 9
Training loss: 1.4120070550974664
Validation loss: 2.50067319112465

Epoch: 5| Step: 10
Training loss: 1.8320285821500764
Validation loss: 2.5645103432274112

Epoch: 175| Step: 0
Training loss: 1.559289227345585
Validation loss: 2.6403509994067806

Epoch: 5| Step: 1
Training loss: 2.193929759428647
Validation loss: 2.6475667061274075

Epoch: 5| Step: 2
Training loss: 1.7717634189464109
Validation loss: 2.5956914657908325

Epoch: 5| Step: 3
Training loss: 1.4803099534518351
Validation loss: 2.5167271721774704

Epoch: 5| Step: 4
Training loss: 1.6300947578362266
Validation loss: 2.457369150369778

Epoch: 5| Step: 5
Training loss: 1.5566237004794734
Validation loss: 2.4438621782901127

Epoch: 5| Step: 6
Training loss: 1.8793135933062033
Validation loss: 2.443317912312355

Epoch: 5| Step: 7
Training loss: 1.8626954379366176
Validation loss: 2.4495957350980837

Epoch: 5| Step: 8
Training loss: 1.8623812439200191
Validation loss: 2.464919493878026

Epoch: 5| Step: 9
Training loss: 2.2643302638040903
Validation loss: 2.475296821789785

Epoch: 5| Step: 10
Training loss: 1.6449301047969662
Validation loss: 2.4703178593386075

Epoch: 176| Step: 0
Training loss: 1.5225870742076828
Validation loss: 2.480524030874764

Epoch: 5| Step: 1
Training loss: 1.4784267706230738
Validation loss: 2.4911909270738994

Epoch: 5| Step: 2
Training loss: 1.7099780872123298
Validation loss: 2.5129481351907206

Epoch: 5| Step: 3
Training loss: 1.751476890792657
Validation loss: 2.503844008991095

Epoch: 5| Step: 4
Training loss: 1.8645011699055987
Validation loss: 2.4892561955854786

Epoch: 5| Step: 5
Training loss: 1.811669850152151
Validation loss: 2.4995199850155196

Epoch: 5| Step: 6
Training loss: 2.190050327820119
Validation loss: 2.5008630124365796

Epoch: 5| Step: 7
Training loss: 1.6347923139902487
Validation loss: 2.4602805702807573

Epoch: 5| Step: 8
Training loss: 1.7959643502764717
Validation loss: 2.4667085301749867

Epoch: 5| Step: 9
Training loss: 1.3931721708339064
Validation loss: 2.4406678077200157

Epoch: 5| Step: 10
Training loss: 2.2524528908328234
Validation loss: 2.4492308123451596

Epoch: 177| Step: 0
Training loss: 1.901855280708431
Validation loss: 2.472338957559776

Epoch: 5| Step: 1
Training loss: 1.5890529455987348
Validation loss: 2.475999458572358

Epoch: 5| Step: 2
Training loss: 2.0815045404432793
Validation loss: 2.4824809540025616

Epoch: 5| Step: 3
Training loss: 1.2566749689011747
Validation loss: 2.4880938483948523

Epoch: 5| Step: 4
Training loss: 1.5706816282131846
Validation loss: 2.503031249635609

Epoch: 5| Step: 5
Training loss: 1.856429130567954
Validation loss: 2.5028639324767723

Epoch: 5| Step: 6
Training loss: 1.6097673845177383
Validation loss: 2.4875800994790898

Epoch: 5| Step: 7
Training loss: 1.7666151932949121
Validation loss: 2.4777772387433434

Epoch: 5| Step: 8
Training loss: 1.9877426527154043
Validation loss: 2.487983468275895

Epoch: 5| Step: 9
Training loss: 1.7126434739426946
Validation loss: 2.505820160862362

Epoch: 5| Step: 10
Training loss: 1.6849334413870172
Validation loss: 2.4973075663161115

Epoch: 178| Step: 0
Training loss: 1.6480201807638262
Validation loss: 2.5030325401454134

Epoch: 5| Step: 1
Training loss: 1.3365211773331622
Validation loss: 2.4824666511636897

Epoch: 5| Step: 2
Training loss: 1.3200595319934996
Validation loss: 2.4982195364313906

Epoch: 5| Step: 3
Training loss: 1.4429678379421522
Validation loss: 2.535615617839558

Epoch: 5| Step: 4
Training loss: 2.189078170426212
Validation loss: 2.5598860583693894

Epoch: 5| Step: 5
Training loss: 2.0385383721586363
Validation loss: 2.5577020925842855

Epoch: 5| Step: 6
Training loss: 1.9969193455125571
Validation loss: 2.5433938898587383

Epoch: 5| Step: 7
Training loss: 1.8203519890558113
Validation loss: 2.5385034240658717

Epoch: 5| Step: 8
Training loss: 1.6133799672808766
Validation loss: 2.5314646632015627

Epoch: 5| Step: 9
Training loss: 1.567824409048811
Validation loss: 2.5485765852833326

Epoch: 5| Step: 10
Training loss: 1.7424654204386842
Validation loss: 2.560341571021767

Epoch: 179| Step: 0
Training loss: 1.6602185046921214
Validation loss: 2.558215627727938

Epoch: 5| Step: 1
Training loss: 1.480235944575857
Validation loss: 2.536860446742113

Epoch: 5| Step: 2
Training loss: 1.841560615604614
Validation loss: 2.518536677704078

Epoch: 5| Step: 3
Training loss: 1.5647364061078675
Validation loss: 2.5034316577835245

Epoch: 5| Step: 4
Training loss: 1.6789931170542298
Validation loss: 2.5073390172921917

Epoch: 5| Step: 5
Training loss: 1.7564545536042067
Validation loss: 2.5061299143442652

Epoch: 5| Step: 6
Training loss: 1.7859463268472404
Validation loss: 2.50050016957779

Epoch: 5| Step: 7
Training loss: 1.68111008129241
Validation loss: 2.5193263910611896

Epoch: 5| Step: 8
Training loss: 1.7878683844348402
Validation loss: 2.5162170942378927

Epoch: 5| Step: 9
Training loss: 1.7552725518889638
Validation loss: 2.522779238602876

Epoch: 5| Step: 10
Training loss: 1.4849529546613163
Validation loss: 2.489366528539415

Epoch: 180| Step: 0
Training loss: 1.1023442625913773
Validation loss: 2.496562415576646

Epoch: 5| Step: 1
Training loss: 1.3666717864537676
Validation loss: 2.4838779463281764

Epoch: 5| Step: 2
Training loss: 1.4812162017185475
Validation loss: 2.4922228777967916

Epoch: 5| Step: 3
Training loss: 1.5656495204688097
Validation loss: 2.486395927855239

Epoch: 5| Step: 4
Training loss: 1.7838152433358052
Validation loss: 2.518986796448664

Epoch: 5| Step: 5
Training loss: 2.40758952718074
Validation loss: 2.5166754715582176

Epoch: 5| Step: 6
Training loss: 1.6809994564066864
Validation loss: 2.4843763574715307

Epoch: 5| Step: 7
Training loss: 1.9217120465922308
Validation loss: 2.5125197537402286

Epoch: 5| Step: 8
Training loss: 1.5965569405226532
Validation loss: 2.5170990300389104

Epoch: 5| Step: 9
Training loss: 1.5132517373078043
Validation loss: 2.499725635404021

Epoch: 5| Step: 10
Training loss: 1.565246609401275
Validation loss: 2.499915090780237

Epoch: 181| Step: 0
Training loss: 1.3064336912231667
Validation loss: 2.487876034480326

Epoch: 5| Step: 1
Training loss: 1.6318322848833298
Validation loss: 2.4951994160652955

Epoch: 5| Step: 2
Training loss: 1.6580386310489816
Validation loss: 2.504039824896434

Epoch: 5| Step: 3
Training loss: 1.745266780408125
Validation loss: 2.513947295516959

Epoch: 5| Step: 4
Training loss: 1.4389142253090108
Validation loss: 2.499719919902531

Epoch: 5| Step: 5
Training loss: 1.2344059517758337
Validation loss: 2.510164669887497

Epoch: 5| Step: 6
Training loss: 1.9363235470500464
Validation loss: 2.524413955868415

Epoch: 5| Step: 7
Training loss: 1.570202420300183
Validation loss: 2.533481707407981

Epoch: 5| Step: 8
Training loss: 2.176923304856152
Validation loss: 2.504841177910449

Epoch: 5| Step: 9
Training loss: 1.6054782542297754
Validation loss: 2.46299135569547

Epoch: 5| Step: 10
Training loss: 1.6807405231644994
Validation loss: 2.4316874611308203

Epoch: 182| Step: 0
Training loss: 1.7468383703332375
Validation loss: 2.4147141567302177

Epoch: 5| Step: 1
Training loss: 1.7965654189410727
Validation loss: 2.411568480854658

Epoch: 5| Step: 2
Training loss: 1.664182989925176
Validation loss: 2.4306622747694195

Epoch: 5| Step: 3
Training loss: 1.301953632252775
Validation loss: 2.4273610402226615

Epoch: 5| Step: 4
Training loss: 1.5537347222311313
Validation loss: 2.4479381496627424

Epoch: 5| Step: 5
Training loss: 2.0024187244394813
Validation loss: 2.44523284309543

Epoch: 5| Step: 6
Training loss: 1.634366404873656
Validation loss: 2.5136402799763378

Epoch: 5| Step: 7
Training loss: 1.0926105558555472
Validation loss: 2.5473762309389087

Epoch: 5| Step: 8
Training loss: 1.5135963470320142
Validation loss: 2.557693641994998

Epoch: 5| Step: 9
Training loss: 1.7047842500051296
Validation loss: 2.5631129264375647

Epoch: 5| Step: 10
Training loss: 1.706996262669732
Validation loss: 2.5185648837988497

Epoch: 183| Step: 0
Training loss: 1.85299060971083
Validation loss: 2.4739033579047804

Epoch: 5| Step: 1
Training loss: 1.327940894437423
Validation loss: 2.422500401519956

Epoch: 5| Step: 2
Training loss: 1.7669458765442128
Validation loss: 2.3897158348148344

Epoch: 5| Step: 3
Training loss: 1.4604004061342843
Validation loss: 2.344456285821226

Epoch: 5| Step: 4
Training loss: 1.9615414361945565
Validation loss: 2.3627879956273548

Epoch: 5| Step: 5
Training loss: 1.512736842630158
Validation loss: 2.393541996476653

Epoch: 5| Step: 6
Training loss: 1.554957227455961
Validation loss: 2.4377883546524104

Epoch: 5| Step: 7
Training loss: 1.3593386064239745
Validation loss: 2.506842289232707

Epoch: 5| Step: 8
Training loss: 1.6050300091466299
Validation loss: 2.570914670133167

Epoch: 5| Step: 9
Training loss: 1.669889179824304
Validation loss: 2.6084255097117595

Epoch: 5| Step: 10
Training loss: 1.7424882706147495
Validation loss: 2.6183549838809586

Epoch: 184| Step: 0
Training loss: 1.6726524470578703
Validation loss: 2.589759074078927

Epoch: 5| Step: 1
Training loss: 1.914706312622273
Validation loss: 2.5639290520265154

Epoch: 5| Step: 2
Training loss: 1.9361495572284524
Validation loss: 2.513521093636867

Epoch: 5| Step: 3
Training loss: 1.50577363835147
Validation loss: 2.442372289762695

Epoch: 5| Step: 4
Training loss: 1.4270113720350508
Validation loss: 2.3850702293115233

Epoch: 5| Step: 5
Training loss: 1.630042541978481
Validation loss: 2.3588870453337023

Epoch: 5| Step: 6
Training loss: 1.886857748341296
Validation loss: 2.353304920237073

Epoch: 5| Step: 7
Training loss: 1.7787958605946954
Validation loss: 2.34585868782259

Epoch: 5| Step: 8
Training loss: 1.4652845202748357
Validation loss: 2.3890603210580497

Epoch: 5| Step: 9
Training loss: 1.2286139177503121
Validation loss: 2.423997650242916

Epoch: 5| Step: 10
Training loss: 1.4244513174771636
Validation loss: 2.4745055098194437

Epoch: 185| Step: 0
Training loss: 1.742153081853303
Validation loss: 2.4943231600051647

Epoch: 5| Step: 1
Training loss: 1.984695228509957
Validation loss: 2.5168159716293297

Epoch: 5| Step: 2
Training loss: 1.4234340629996753
Validation loss: 2.5197587776900843

Epoch: 5| Step: 3
Training loss: 2.1005514329162853
Validation loss: 2.502009812412074

Epoch: 5| Step: 4
Training loss: 1.395431399005171
Validation loss: 2.467794420055625

Epoch: 5| Step: 5
Training loss: 1.4386061683169342
Validation loss: 2.4740178458671664

Epoch: 5| Step: 6
Training loss: 1.4613763486669809
Validation loss: 2.4469825912183465

Epoch: 5| Step: 7
Training loss: 1.4798184780975323
Validation loss: 2.464579022328807

Epoch: 5| Step: 8
Training loss: 1.6308947530780997
Validation loss: 2.4263435773978768

Epoch: 5| Step: 9
Training loss: 1.6866912316555165
Validation loss: 2.4120601308092966

Epoch: 5| Step: 10
Training loss: 1.1554876855997085
Validation loss: 2.4360261304752338

Epoch: 186| Step: 0
Training loss: 1.2476329325943663
Validation loss: 2.4361003267921606

Epoch: 5| Step: 1
Training loss: 1.730150318340564
Validation loss: 2.4429521997581682

Epoch: 5| Step: 2
Training loss: 1.5577362684692464
Validation loss: 2.493249169755206

Epoch: 5| Step: 3
Training loss: 1.5400467257408814
Validation loss: 2.5035680962604014

Epoch: 5| Step: 4
Training loss: 1.6998552905929696
Validation loss: 2.499909729507103

Epoch: 5| Step: 5
Training loss: 1.8114147225633175
Validation loss: 2.464460715610225

Epoch: 5| Step: 6
Training loss: 1.4004156943063142
Validation loss: 2.457963140432931

Epoch: 5| Step: 7
Training loss: 1.179581441595909
Validation loss: 2.4573963121735685

Epoch: 5| Step: 8
Training loss: 1.810934903765867
Validation loss: 2.454108846729754

Epoch: 5| Step: 9
Training loss: 1.3540289099634186
Validation loss: 2.4330347841658027

Epoch: 5| Step: 10
Training loss: 1.9403616783384179
Validation loss: 2.440840615129275

Epoch: 187| Step: 0
Training loss: 1.4914483441606554
Validation loss: 2.4276328593412755

Epoch: 5| Step: 1
Training loss: 1.540851927597445
Validation loss: 2.446875030425798

Epoch: 5| Step: 2
Training loss: 1.2527274416763479
Validation loss: 2.44643883501584

Epoch: 5| Step: 3
Training loss: 1.5481104685378984
Validation loss: 2.465872698860645

Epoch: 5| Step: 4
Training loss: 1.4618325984786122
Validation loss: 2.4895265661738937

Epoch: 5| Step: 5
Training loss: 1.5267548267168898
Validation loss: 2.5176772358702344

Epoch: 5| Step: 6
Training loss: 1.6226460940943614
Validation loss: 2.5110681231738234

Epoch: 5| Step: 7
Training loss: 1.7296815205292353
Validation loss: 2.490820162787403

Epoch: 5| Step: 8
Training loss: 1.761943726648804
Validation loss: 2.45949320095732

Epoch: 5| Step: 9
Training loss: 1.3978882888589372
Validation loss: 2.4384872650036855

Epoch: 5| Step: 10
Training loss: 1.6411649996034714
Validation loss: 2.407611121558994

Epoch: 188| Step: 0
Training loss: 1.2747189679555353
Validation loss: 2.409426240623668

Epoch: 5| Step: 1
Training loss: 1.3267752127515098
Validation loss: 2.411814380542511

Epoch: 5| Step: 2
Training loss: 1.065507503083912
Validation loss: 2.403445324208191

Epoch: 5| Step: 3
Training loss: 2.106856474454056
Validation loss: 2.386956513501534

Epoch: 5| Step: 4
Training loss: 1.4183439068487913
Validation loss: 2.4162028864479184

Epoch: 5| Step: 5
Training loss: 1.440004323449532
Validation loss: 2.428395896905941

Epoch: 5| Step: 6
Training loss: 1.748969455825249
Validation loss: 2.435117473761587

Epoch: 5| Step: 7
Training loss: 1.787236376976336
Validation loss: 2.483607374741503

Epoch: 5| Step: 8
Training loss: 1.6202792775823158
Validation loss: 2.499102125646627

Epoch: 5| Step: 9
Training loss: 1.47464753158415
Validation loss: 2.516771258559231

Epoch: 5| Step: 10
Training loss: 1.2216881767728127
Validation loss: 2.5419758484744035

Epoch: 189| Step: 0
Training loss: 1.604378880257218
Validation loss: 2.5346055945772292

Epoch: 5| Step: 1
Training loss: 1.1403189470605979
Validation loss: 2.5038205092547083

Epoch: 5| Step: 2
Training loss: 1.611115782646919
Validation loss: 2.516087445653488

Epoch: 5| Step: 3
Training loss: 1.4860634286109662
Validation loss: 2.522894680002956

Epoch: 5| Step: 4
Training loss: 1.6523839345965035
Validation loss: 2.52005723094426

Epoch: 5| Step: 5
Training loss: 1.5227639298704516
Validation loss: 2.5062138754884105

Epoch: 5| Step: 6
Training loss: 1.4770907309938313
Validation loss: 2.489620285868633

Epoch: 5| Step: 7
Training loss: 1.2123261395893803
Validation loss: 2.4466288760670203

Epoch: 5| Step: 8
Training loss: 1.7953560421330588
Validation loss: 2.4189973352034664

Epoch: 5| Step: 9
Training loss: 1.0164096442245822
Validation loss: 2.3899746071165953

Epoch: 5| Step: 10
Training loss: 1.8598037353661894
Validation loss: 2.3770708631342434

Epoch: 190| Step: 0
Training loss: 0.9737007324036563
Validation loss: 2.41443955172623

Epoch: 5| Step: 1
Training loss: 1.8185646277274716
Validation loss: 2.400973943779766

Epoch: 5| Step: 2
Training loss: 1.6278170596443537
Validation loss: 2.4394830399617304

Epoch: 5| Step: 3
Training loss: 1.0927737102218438
Validation loss: 2.429756087876985

Epoch: 5| Step: 4
Training loss: 1.641094758128692
Validation loss: 2.457614558617002

Epoch: 5| Step: 5
Training loss: 1.3299106038674835
Validation loss: 2.5022990781425354

Epoch: 5| Step: 6
Training loss: 1.9120382387295856
Validation loss: 2.549584593205057

Epoch: 5| Step: 7
Training loss: 1.3462688878964955
Validation loss: 2.5738657273386756

Epoch: 5| Step: 8
Training loss: 1.3898453830925974
Validation loss: 2.53281596105736

Epoch: 5| Step: 9
Training loss: 1.7180581521038862
Validation loss: 2.4592064450116426

Epoch: 5| Step: 10
Training loss: 1.121702607066983
Validation loss: 2.4494610877019625

Epoch: 191| Step: 0
Training loss: 1.8678691050884417
Validation loss: 2.4186720633907117

Epoch: 5| Step: 1
Training loss: 1.641904059865551
Validation loss: 2.35903781892906

Epoch: 5| Step: 2
Training loss: 1.29188722860291
Validation loss: 2.355597825930976

Epoch: 5| Step: 3
Training loss: 1.622385268893883
Validation loss: 2.378506317944196

Epoch: 5| Step: 4
Training loss: 1.6708918737999368
Validation loss: 2.401310867964723

Epoch: 5| Step: 5
Training loss: 1.2335778088593576
Validation loss: 2.3944926258870436

Epoch: 5| Step: 6
Training loss: 1.3656942005213937
Validation loss: 2.396693571648429

Epoch: 5| Step: 7
Training loss: 1.157682716828064
Validation loss: 2.424268786344938

Epoch: 5| Step: 8
Training loss: 1.297139795685643
Validation loss: 2.4251839274851545

Epoch: 5| Step: 9
Training loss: 1.3099460276194126
Validation loss: 2.458574591537635

Epoch: 5| Step: 10
Training loss: 1.4513626897334342
Validation loss: 2.4749487018375604

Epoch: 192| Step: 0
Training loss: 1.1911807988212144
Validation loss: 2.4494691089396787

Epoch: 5| Step: 1
Training loss: 1.6941010677899246
Validation loss: 2.482564835653826

Epoch: 5| Step: 2
Training loss: 1.5045019778146418
Validation loss: 2.465811526228957

Epoch: 5| Step: 3
Training loss: 1.0412761655636251
Validation loss: 2.4768951752597252

Epoch: 5| Step: 4
Training loss: 1.8139954678606072
Validation loss: 2.4595634482795723

Epoch: 5| Step: 5
Training loss: 1.482640427472728
Validation loss: 2.4738642491497025

Epoch: 5| Step: 6
Training loss: 1.5852784539764129
Validation loss: 2.452417910146783

Epoch: 5| Step: 7
Training loss: 1.1045399460724756
Validation loss: 2.4459441424575896

Epoch: 5| Step: 8
Training loss: 1.5154571440252598
Validation loss: 2.4534960423638386

Epoch: 5| Step: 9
Training loss: 1.4910222641774835
Validation loss: 2.4178810947298555

Epoch: 5| Step: 10
Training loss: 1.09147298031337
Validation loss: 2.430091436308154

Epoch: 193| Step: 0
Training loss: 1.405887938620268
Validation loss: 2.4175666152502795

Epoch: 5| Step: 1
Training loss: 1.6345976056128892
Validation loss: 2.427030214646225

Epoch: 5| Step: 2
Training loss: 1.8361477345969144
Validation loss: 2.4153242004289535

Epoch: 5| Step: 3
Training loss: 1.4315973251893348
Validation loss: 2.3878969512471464

Epoch: 5| Step: 4
Training loss: 1.1939634801305172
Validation loss: 2.3773572845444133

Epoch: 5| Step: 5
Training loss: 1.5625512686901368
Validation loss: 2.381727659505277

Epoch: 5| Step: 6
Training loss: 1.0869141721768252
Validation loss: 2.3885521703494983

Epoch: 5| Step: 7
Training loss: 1.3862513654476833
Validation loss: 2.384157425446601

Epoch: 5| Step: 8
Training loss: 1.7935268223386347
Validation loss: 2.410282199993927

Epoch: 5| Step: 9
Training loss: 0.9090734106243763
Validation loss: 2.4340093285454336

Epoch: 5| Step: 10
Training loss: 1.0309498668066515
Validation loss: 2.462395438554186

Epoch: 194| Step: 0
Training loss: 1.8322968442958294
Validation loss: 2.4497086936290993

Epoch: 5| Step: 1
Training loss: 1.6173414074181784
Validation loss: 2.469337362353494

Epoch: 5| Step: 2
Training loss: 1.2378839282561591
Validation loss: 2.486022512327167

Epoch: 5| Step: 3
Training loss: 1.2411993642968269
Validation loss: 2.485435179657161

Epoch: 5| Step: 4
Training loss: 1.3212891527219575
Validation loss: 2.485450061596813

Epoch: 5| Step: 5
Training loss: 1.1015169932387505
Validation loss: 2.4770807715301224

Epoch: 5| Step: 6
Training loss: 1.561423579417306
Validation loss: 2.466168585839507

Epoch: 5| Step: 7
Training loss: 1.4289589781962944
Validation loss: 2.4674451221425673

Epoch: 5| Step: 8
Training loss: 1.309199816289971
Validation loss: 2.460674573294704

Epoch: 5| Step: 9
Training loss: 1.465115127856977
Validation loss: 2.448314309970615

Epoch: 5| Step: 10
Training loss: 1.0353224135136387
Validation loss: 2.4274813520078693

Epoch: 195| Step: 0
Training loss: 1.1806283697723392
Validation loss: 2.439953277528213

Epoch: 5| Step: 1
Training loss: 1.163209487412891
Validation loss: 2.423446128722323

Epoch: 5| Step: 2
Training loss: 1.4885399460921633
Validation loss: 2.427442499173827

Epoch: 5| Step: 3
Training loss: 1.236438908969385
Validation loss: 2.4329343547772746

Epoch: 5| Step: 4
Training loss: 1.2560723629898456
Validation loss: 2.4350038278234662

Epoch: 5| Step: 5
Training loss: 1.4425267772073436
Validation loss: 2.457160934676877

Epoch: 5| Step: 6
Training loss: 1.491438992492085
Validation loss: 2.4380557065986714

Epoch: 5| Step: 7
Training loss: 1.2622183646130454
Validation loss: 2.4353654000793936

Epoch: 5| Step: 8
Training loss: 1.7188342680647277
Validation loss: 2.4360300832351385

Epoch: 5| Step: 9
Training loss: 1.632171505041335
Validation loss: 2.4336430651565326

Epoch: 5| Step: 10
Training loss: 1.0947430053891694
Validation loss: 2.4407000070570306

Epoch: 196| Step: 0
Training loss: 1.5641391548632644
Validation loss: 2.472830174742197

Epoch: 5| Step: 1
Training loss: 1.2779486387615029
Validation loss: 2.447706036395711

Epoch: 5| Step: 2
Training loss: 1.3098218933633627
Validation loss: 2.4330284367878554

Epoch: 5| Step: 3
Training loss: 0.9253256276187268
Validation loss: 2.4243555740748

Epoch: 5| Step: 4
Training loss: 1.5046547352361859
Validation loss: 2.4279607476996166

Epoch: 5| Step: 5
Training loss: 1.4939343677847474
Validation loss: 2.426088380498369

Epoch: 5| Step: 6
Training loss: 1.2073860511167398
Validation loss: 2.4453502097654494

Epoch: 5| Step: 7
Training loss: 1.4446176869272565
Validation loss: 2.4231140190579747

Epoch: 5| Step: 8
Training loss: 1.5052976834750142
Validation loss: 2.4124206190711446

Epoch: 5| Step: 9
Training loss: 1.508861196824396
Validation loss: 2.4194475693518065

Epoch: 5| Step: 10
Training loss: 1.096172538204127
Validation loss: 2.4024515966309905

Epoch: 197| Step: 0
Training loss: 1.3052855166147896
Validation loss: 2.386610528110154

Epoch: 5| Step: 1
Training loss: 1.4091568890139698
Validation loss: 2.419538165362472

Epoch: 5| Step: 2
Training loss: 1.1566287786359584
Validation loss: 2.415978155051883

Epoch: 5| Step: 3
Training loss: 1.321635198823844
Validation loss: 2.421848967296826

Epoch: 5| Step: 4
Training loss: 1.5154149804653505
Validation loss: 2.4426363689455974

Epoch: 5| Step: 5
Training loss: 1.1982763607309903
Validation loss: 2.4402751643154166

Epoch: 5| Step: 6
Training loss: 1.2814343017514398
Validation loss: 2.4436398699579676

Epoch: 5| Step: 7
Training loss: 1.4334824854110442
Validation loss: 2.439840498315782

Epoch: 5| Step: 8
Training loss: 1.5115228570389116
Validation loss: 2.4302510797338472

Epoch: 5| Step: 9
Training loss: 1.2746526619016814
Validation loss: 2.449846432234102

Epoch: 5| Step: 10
Training loss: 1.4837680579663752
Validation loss: 2.406744037013191

Epoch: 198| Step: 0
Training loss: 1.2571064169667983
Validation loss: 2.4244595944938867

Epoch: 5| Step: 1
Training loss: 1.3423351557450625
Validation loss: 2.434387603217019

Epoch: 5| Step: 2
Training loss: 1.40506516451422
Validation loss: 2.4246362004145015

Epoch: 5| Step: 3
Training loss: 1.618514985805613
Validation loss: 2.419902130011705

Epoch: 5| Step: 4
Training loss: 1.5214680779775458
Validation loss: 2.4187963823566303

Epoch: 5| Step: 5
Training loss: 1.134447167993461
Validation loss: 2.4316137482443154

Epoch: 5| Step: 6
Training loss: 1.3329488776177454
Validation loss: 2.43322968401992

Epoch: 5| Step: 7
Training loss: 1.0214014548495067
Validation loss: 2.4262027372653403

Epoch: 5| Step: 8
Training loss: 1.7202122796824844
Validation loss: 2.3946447761896836

Epoch: 5| Step: 9
Training loss: 1.3170172747649969
Validation loss: 2.3835729328688418

Epoch: 5| Step: 10
Training loss: 0.8348195809619995
Validation loss: 2.3848960348790365

Epoch: 199| Step: 0
Training loss: 1.404266187308667
Validation loss: 2.3538755744548885

Epoch: 5| Step: 1
Training loss: 1.4455595063160351
Validation loss: 2.39726663297533

Epoch: 5| Step: 2
Training loss: 1.4740273647071542
Validation loss: 2.4125323279453426

Epoch: 5| Step: 3
Training loss: 1.472038159570329
Validation loss: 2.450022269209073

Epoch: 5| Step: 4
Training loss: 1.199972506049221
Validation loss: 2.4433790164658826

Epoch: 5| Step: 5
Training loss: 1.0962401789156788
Validation loss: 2.4413674854113343

Epoch: 5| Step: 6
Training loss: 1.1259766683719052
Validation loss: 2.457069859282132

Epoch: 5| Step: 7
Training loss: 1.5363822099179594
Validation loss: 2.444388106782347

Epoch: 5| Step: 8
Training loss: 1.267282319196177
Validation loss: 2.418737826303864

Epoch: 5| Step: 9
Training loss: 1.2717396000953751
Validation loss: 2.4026533035275097

Epoch: 5| Step: 10
Training loss: 1.3428161836235828
Validation loss: 2.419551611114118

Epoch: 200| Step: 0
Training loss: 1.0459068148408373
Validation loss: 2.4320719672124764

Epoch: 5| Step: 1
Training loss: 1.2479003915802789
Validation loss: 2.4345004881371106

Epoch: 5| Step: 2
Training loss: 1.4767965302867776
Validation loss: 2.4640891170955705

Epoch: 5| Step: 3
Training loss: 1.3664233878943748
Validation loss: 2.4481774150466475

Epoch: 5| Step: 4
Training loss: 1.328716191375766
Validation loss: 2.417220660718369

Epoch: 5| Step: 5
Training loss: 1.3416096696929396
Validation loss: 2.40871923670172

Epoch: 5| Step: 6
Training loss: 1.3689662152922
Validation loss: 2.3871877432481448

Epoch: 5| Step: 7
Training loss: 1.4215752421889993
Validation loss: 2.3744096977681797

Epoch: 5| Step: 8
Training loss: 0.9595237815378683
Validation loss: 2.3686862509804176

Epoch: 5| Step: 9
Training loss: 1.055239497656888
Validation loss: 2.3844969547724744

Epoch: 5| Step: 10
Training loss: 1.7872603222411103
Validation loss: 2.3980186433092117

Epoch: 201| Step: 0
Training loss: 1.611820843819626
Validation loss: 2.4500358134421516

Epoch: 5| Step: 1
Training loss: 1.7602848552887778
Validation loss: 2.4805668228911335

Epoch: 5| Step: 2
Training loss: 1.1812816736728107
Validation loss: 2.4898314202876044

Epoch: 5| Step: 3
Training loss: 1.1044755119866008
Validation loss: 2.485165439886629

Epoch: 5| Step: 4
Training loss: 1.1750315560506637
Validation loss: 2.46931622264417

Epoch: 5| Step: 5
Training loss: 1.0851296363241993
Validation loss: 2.436746226743875

Epoch: 5| Step: 6
Training loss: 1.3947574635025815
Validation loss: 2.415683085431433

Epoch: 5| Step: 7
Training loss: 0.9098874460556899
Validation loss: 2.3945574330170754

Epoch: 5| Step: 8
Training loss: 1.2909656693897196
Validation loss: 2.406126709831775

Epoch: 5| Step: 9
Training loss: 1.1316730951530185
Validation loss: 2.4059280746958125

Epoch: 5| Step: 10
Training loss: 1.521315128182942
Validation loss: 2.3850788261069544

Epoch: 202| Step: 0
Training loss: 1.4053021521481037
Validation loss: 2.374825265541316

Epoch: 5| Step: 1
Training loss: 1.4490642619497625
Validation loss: 2.354648499034819

Epoch: 5| Step: 2
Training loss: 1.2426779396622956
Validation loss: 2.3268824001274337

Epoch: 5| Step: 3
Training loss: 1.1570834171916495
Validation loss: 2.3471329762610984

Epoch: 5| Step: 4
Training loss: 1.1623113376566288
Validation loss: 2.3486346659442923

Epoch: 5| Step: 5
Training loss: 1.4481613537897313
Validation loss: 2.3505730123019815

Epoch: 5| Step: 6
Training loss: 1.3347712551553046
Validation loss: 2.377071500520127

Epoch: 5| Step: 7
Training loss: 0.6995501026154852
Validation loss: 2.3924171539260413

Epoch: 5| Step: 8
Training loss: 1.2006056032296912
Validation loss: 2.419988319018262

Epoch: 5| Step: 9
Training loss: 1.3889510119637964
Validation loss: 2.438964475858559

Epoch: 5| Step: 10
Training loss: 1.6260005364927412
Validation loss: 2.4682300435967113

Epoch: 203| Step: 0
Training loss: 1.7133020235359961
Validation loss: 2.4856631148287303

Epoch: 5| Step: 1
Training loss: 1.4750298513204325
Validation loss: 2.469086804357648

Epoch: 5| Step: 2
Training loss: 1.0859692246447918
Validation loss: 2.43266958965207

Epoch: 5| Step: 3
Training loss: 1.0451468252315097
Validation loss: 2.3957207851716364

Epoch: 5| Step: 4
Training loss: 1.3765668178321764
Validation loss: 2.4013885314409475

Epoch: 5| Step: 5
Training loss: 1.246644714429086
Validation loss: 2.380260990849507

Epoch: 5| Step: 6
Training loss: 1.3137787084954358
Validation loss: 2.3723383357659142

Epoch: 5| Step: 7
Training loss: 0.8538761730428955
Validation loss: 2.359877259834454

Epoch: 5| Step: 8
Training loss: 1.491962995167432
Validation loss: 2.3580199307297276

Epoch: 5| Step: 9
Training loss: 1.179450863984288
Validation loss: 2.369064072955064

Epoch: 5| Step: 10
Training loss: 1.0976772645723873
Validation loss: 2.4333593392285353

Epoch: 204| Step: 0
Training loss: 1.3873688369477983
Validation loss: 2.476591815582827

Epoch: 5| Step: 1
Training loss: 1.1219303850619124
Validation loss: 2.4954944947654534

Epoch: 5| Step: 2
Training loss: 1.551209666844387
Validation loss: 2.512487424875012

Epoch: 5| Step: 3
Training loss: 1.1838614283869182
Validation loss: 2.472069633693723

Epoch: 5| Step: 4
Training loss: 1.1746034521188904
Validation loss: 2.425188206586636

Epoch: 5| Step: 5
Training loss: 1.0513513996512802
Validation loss: 2.394816673973352

Epoch: 5| Step: 6
Training loss: 1.1132645455161243
Validation loss: 2.380893879880773

Epoch: 5| Step: 7
Training loss: 1.3031594928228993
Validation loss: 2.3731949557831884

Epoch: 5| Step: 8
Training loss: 1.105710383989555
Validation loss: 2.3969337286870074

Epoch: 5| Step: 9
Training loss: 1.375261325278473
Validation loss: 2.4061072357404294

Epoch: 5| Step: 10
Training loss: 1.6199396276409619
Validation loss: 2.429643831921372

Epoch: 205| Step: 0
Training loss: 1.2800629862546986
Validation loss: 2.429232713552209

Epoch: 5| Step: 1
Training loss: 1.1196050029986304
Validation loss: 2.4317165618068604

Epoch: 5| Step: 2
Training loss: 1.165995484246855
Validation loss: 2.4308238244052025

Epoch: 5| Step: 3
Training loss: 1.1765475896571924
Validation loss: 2.3969438498179443

Epoch: 5| Step: 4
Training loss: 1.4710396309498923
Validation loss: 2.367639896463471

Epoch: 5| Step: 5
Training loss: 1.0258998224158802
Validation loss: 2.3818518143857172

Epoch: 5| Step: 6
Training loss: 1.7619511013368667
Validation loss: 2.3582773462068745

Epoch: 5| Step: 7
Training loss: 1.196143665430796
Validation loss: 2.3791159244381275

Epoch: 5| Step: 8
Training loss: 1.2123069648850346
Validation loss: 2.379034631907657

Epoch: 5| Step: 9
Training loss: 0.9624580200750572
Validation loss: 2.3654423838630882

Epoch: 5| Step: 10
Training loss: 1.4268420310102725
Validation loss: 2.379760520909863

Epoch: 206| Step: 0
Training loss: 1.2347684788391866
Validation loss: 2.4221143971394214

Epoch: 5| Step: 1
Training loss: 1.149438019975208
Validation loss: 2.4298452360343825

Epoch: 5| Step: 2
Training loss: 1.1207466252667795
Validation loss: 2.4457920011504544

Epoch: 5| Step: 3
Training loss: 1.2944500784326134
Validation loss: 2.4768991673357976

Epoch: 5| Step: 4
Training loss: 1.387248193384597
Validation loss: 2.481561021753271

Epoch: 5| Step: 5
Training loss: 1.138230095776239
Validation loss: 2.450812648297854

Epoch: 5| Step: 6
Training loss: 1.3867254122721784
Validation loss: 2.421723676565935

Epoch: 5| Step: 7
Training loss: 0.882877718786671
Validation loss: 2.3991063334364546

Epoch: 5| Step: 8
Training loss: 1.4810611073252824
Validation loss: 2.4012699817210588

Epoch: 5| Step: 9
Training loss: 1.1646451068160752
Validation loss: 2.3891226830642953

Epoch: 5| Step: 10
Training loss: 1.4501698295846082
Validation loss: 2.394144042812972

Epoch: 207| Step: 0
Training loss: 1.1622147199823396
Validation loss: 2.377711522796182

Epoch: 5| Step: 1
Training loss: 1.34104669692158
Validation loss: 2.3581434573984685

Epoch: 5| Step: 2
Training loss: 1.4560188273690269
Validation loss: 2.3728689219082773

Epoch: 5| Step: 3
Training loss: 1.099754201996778
Validation loss: 2.3488228385963503

Epoch: 5| Step: 4
Training loss: 1.0464542169557678
Validation loss: 2.3692472097259554

Epoch: 5| Step: 5
Training loss: 1.179834925048059
Validation loss: 2.3737840815986466

Epoch: 5| Step: 6
Training loss: 0.9865382206816843
Validation loss: 2.386579549736747

Epoch: 5| Step: 7
Training loss: 1.4271555508720442
Validation loss: 2.3682704135165165

Epoch: 5| Step: 8
Training loss: 1.5105688961092036
Validation loss: 2.3966196497054155

Epoch: 5| Step: 9
Training loss: 1.201570423035611
Validation loss: 2.4101874965298196

Epoch: 5| Step: 10
Training loss: 1.1160652018782078
Validation loss: 2.424459722440135

Epoch: 208| Step: 0
Training loss: 0.900119898015213
Validation loss: 2.415660016957382

Epoch: 5| Step: 1
Training loss: 1.342283069196836
Validation loss: 2.418109927117319

Epoch: 5| Step: 2
Training loss: 1.232913153616406
Validation loss: 2.424367128829708

Epoch: 5| Step: 3
Training loss: 1.5502003847846413
Validation loss: 2.4370295299580733

Epoch: 5| Step: 4
Training loss: 1.0403123953106759
Validation loss: 2.409636395777818

Epoch: 5| Step: 5
Training loss: 1.467355512560296
Validation loss: 2.4104400662842496

Epoch: 5| Step: 6
Training loss: 0.8056086480705941
Validation loss: 2.410526819075385

Epoch: 5| Step: 7
Training loss: 1.1471128544517268
Validation loss: 2.406394852922257

Epoch: 5| Step: 8
Training loss: 1.0199756457656315
Validation loss: 2.3709673428446183

Epoch: 5| Step: 9
Training loss: 1.41987712637427
Validation loss: 2.390462835684254

Epoch: 5| Step: 10
Training loss: 1.264185286736622
Validation loss: 2.373250186093239

Epoch: 209| Step: 0
Training loss: 1.1237745498334861
Validation loss: 2.396006155178799

Epoch: 5| Step: 1
Training loss: 1.1111818026201299
Validation loss: 2.392008684010041

Epoch: 5| Step: 2
Training loss: 1.3524707983534672
Validation loss: 2.412395821745425

Epoch: 5| Step: 3
Training loss: 1.241662256288483
Validation loss: 2.415481881270701

Epoch: 5| Step: 4
Training loss: 1.4588629532912252
Validation loss: 2.4326392478744676

Epoch: 5| Step: 5
Training loss: 1.2285349348579315
Validation loss: 2.3908129237590257

Epoch: 5| Step: 6
Training loss: 1.1646396818956217
Validation loss: 2.372000700755475

Epoch: 5| Step: 7
Training loss: 0.9743531220862987
Validation loss: 2.371779994814757

Epoch: 5| Step: 8
Training loss: 1.2742100344043494
Validation loss: 2.3520418664524705

Epoch: 5| Step: 9
Training loss: 1.2280986909256602
Validation loss: 2.3619019362245455

Epoch: 5| Step: 10
Training loss: 1.2084920493934852
Validation loss: 2.373308681635615

Epoch: 210| Step: 0
Training loss: 1.1032162960841994
Validation loss: 2.3736350320436297

Epoch: 5| Step: 1
Training loss: 1.2602655409490546
Validation loss: 2.3690930068304747

Epoch: 5| Step: 2
Training loss: 1.601940724441839
Validation loss: 2.4044968294220395

Epoch: 5| Step: 3
Training loss: 0.998241636977308
Validation loss: 2.4073632228440203

Epoch: 5| Step: 4
Training loss: 1.0532441612315422
Validation loss: 2.4245902452444597

Epoch: 5| Step: 5
Training loss: 1.1580359095373576
Validation loss: 2.4064013930660972

Epoch: 5| Step: 6
Training loss: 1.0446304057384126
Validation loss: 2.4030160062875767

Epoch: 5| Step: 7
Training loss: 1.1604023168328348
Validation loss: 2.3867939570858634

Epoch: 5| Step: 8
Training loss: 1.1200364606746789
Validation loss: 2.3888351965089254

Epoch: 5| Step: 9
Training loss: 1.4107165715990637
Validation loss: 2.3692488268470417

Epoch: 5| Step: 10
Training loss: 1.3752035510511635
Validation loss: 2.381735920696549

Epoch: 211| Step: 0
Training loss: 1.4063507891669673
Validation loss: 2.4010369551688058

Epoch: 5| Step: 1
Training loss: 1.467506694096077
Validation loss: 2.387882105492229

Epoch: 5| Step: 2
Training loss: 1.0505700448644846
Validation loss: 2.367913679683326

Epoch: 5| Step: 3
Training loss: 0.8815317907329349
Validation loss: 2.3373912579139478

Epoch: 5| Step: 4
Training loss: 1.1966562633983109
Validation loss: 2.334658086998024

Epoch: 5| Step: 5
Training loss: 0.9191400724928946
Validation loss: 2.316492777662299

Epoch: 5| Step: 6
Training loss: 1.1871492972255842
Validation loss: 2.311832434723112

Epoch: 5| Step: 7
Training loss: 1.3331584915124763
Validation loss: 2.345543323109929

Epoch: 5| Step: 8
Training loss: 1.3116654967448644
Validation loss: 2.3943138629452614

Epoch: 5| Step: 9
Training loss: 1.4117201905910823
Validation loss: 2.4611587490066147

Epoch: 5| Step: 10
Training loss: 0.7860109602040242
Validation loss: 2.447773655414532

Epoch: 212| Step: 0
Training loss: 1.276067907361994
Validation loss: 2.4709787761293858

Epoch: 5| Step: 1
Training loss: 0.9768663162655772
Validation loss: 2.496370127094919

Epoch: 5| Step: 2
Training loss: 1.0655470520328163
Validation loss: 2.45806353072055

Epoch: 5| Step: 3
Training loss: 1.2877756805081022
Validation loss: 2.432694268841528

Epoch: 5| Step: 4
Training loss: 1.0582496675075816
Validation loss: 2.379785084655487

Epoch: 5| Step: 5
Training loss: 1.0320269230095644
Validation loss: 2.355021355808662

Epoch: 5| Step: 6
Training loss: 1.2812766560828746
Validation loss: 2.3412776242273736

Epoch: 5| Step: 7
Training loss: 1.2235065952243307
Validation loss: 2.327788874946854

Epoch: 5| Step: 8
Training loss: 1.138548122898421
Validation loss: 2.328881744663023

Epoch: 5| Step: 9
Training loss: 1.4500820334018938
Validation loss: 2.3081541024322942

Epoch: 5| Step: 10
Training loss: 1.318966828730982
Validation loss: 2.328690355545802

Epoch: 213| Step: 0
Training loss: 1.1487722622579037
Validation loss: 2.338055785986753

Epoch: 5| Step: 1
Training loss: 1.395718622001497
Validation loss: 2.3862370270950377

Epoch: 5| Step: 2
Training loss: 1.3782670481994206
Validation loss: 2.394164848295108

Epoch: 5| Step: 3
Training loss: 1.014099324972825
Validation loss: 2.412713984888872

Epoch: 5| Step: 4
Training loss: 1.2425590295412654
Validation loss: 2.4147931652598147

Epoch: 5| Step: 5
Training loss: 0.702694019051577
Validation loss: 2.4326823890127227

Epoch: 5| Step: 6
Training loss: 1.1906941771748296
Validation loss: 2.4046838695383017

Epoch: 5| Step: 7
Training loss: 1.044320534199601
Validation loss: 2.376135173245108

Epoch: 5| Step: 8
Training loss: 1.0996134403892155
Validation loss: 2.3365561785117435

Epoch: 5| Step: 9
Training loss: 1.36406731009318
Validation loss: 2.342526055699976

Epoch: 5| Step: 10
Training loss: 1.2200494343482227
Validation loss: 2.3283651524967315

Epoch: 214| Step: 0
Training loss: 0.9204665594248105
Validation loss: 2.300477035759204

Epoch: 5| Step: 1
Training loss: 0.9661855903664359
Validation loss: 2.2950448591503236

Epoch: 5| Step: 2
Training loss: 0.9615730416975617
Validation loss: 2.3004305962124416

Epoch: 5| Step: 3
Training loss: 1.1885014878529698
Validation loss: 2.3167429863265645

Epoch: 5| Step: 4
Training loss: 1.1362839224339563
Validation loss: 2.331634556451597

Epoch: 5| Step: 5
Training loss: 1.312514895400038
Validation loss: 2.3348163961723496

Epoch: 5| Step: 6
Training loss: 1.3232953838621007
Validation loss: 2.340202095793026

Epoch: 5| Step: 7
Training loss: 1.3081302562157842
Validation loss: 2.3777532890726856

Epoch: 5| Step: 8
Training loss: 1.2782208059354208
Validation loss: 2.3837870713076192

Epoch: 5| Step: 9
Training loss: 1.0709190042466405
Validation loss: 2.4359325888975847

Epoch: 5| Step: 10
Training loss: 1.24827427948913
Validation loss: 2.4386963859691972

Epoch: 215| Step: 0
Training loss: 1.0009248152592165
Validation loss: 2.4581447752867174

Epoch: 5| Step: 1
Training loss: 1.136793415986336
Validation loss: 2.4525245551895343

Epoch: 5| Step: 2
Training loss: 0.9782443403377149
Validation loss: 2.4873373745951115

Epoch: 5| Step: 3
Training loss: 0.9978587053438658
Validation loss: 2.487778048785714

Epoch: 5| Step: 4
Training loss: 1.0153858783631817
Validation loss: 2.4414672371414863

Epoch: 5| Step: 5
Training loss: 1.3310892124414375
Validation loss: 2.4316070284159337

Epoch: 5| Step: 6
Training loss: 1.1866461042880052
Validation loss: 2.4070586779501513

Epoch: 5| Step: 7
Training loss: 1.3591289516824114
Validation loss: 2.394832398163503

Epoch: 5| Step: 8
Training loss: 1.0626346278448306
Validation loss: 2.389234893233391

Epoch: 5| Step: 9
Training loss: 1.2349356331827799
Validation loss: 2.3686370629608375

Epoch: 5| Step: 10
Training loss: 1.2920940471468643
Validation loss: 2.345887532525426

Epoch: 216| Step: 0
Training loss: 1.166783525654275
Validation loss: 2.338293990472255

Epoch: 5| Step: 1
Training loss: 1.1372568226876072
Validation loss: 2.326354617868036

Epoch: 5| Step: 2
Training loss: 1.1012992814952143
Validation loss: 2.374845857049174

Epoch: 5| Step: 3
Training loss: 0.7953431234103594
Validation loss: 2.3888902583892984

Epoch: 5| Step: 4
Training loss: 1.2971730177072514
Validation loss: 2.400455879509879

Epoch: 5| Step: 5
Training loss: 1.0321758622319845
Validation loss: 2.3646682665097023

Epoch: 5| Step: 6
Training loss: 1.1591392195080457
Validation loss: 2.3873465594968275

Epoch: 5| Step: 7
Training loss: 1.0935978919936082
Validation loss: 2.3979176881954998

Epoch: 5| Step: 8
Training loss: 1.1243625530340662
Validation loss: 2.4043916137622543

Epoch: 5| Step: 9
Training loss: 1.454816346654548
Validation loss: 2.3686484565932706

Epoch: 5| Step: 10
Training loss: 1.0573417325999082
Validation loss: 2.3920742807774436

Epoch: 217| Step: 0
Training loss: 0.7031533553445897
Validation loss: 2.3875016896506516

Epoch: 5| Step: 1
Training loss: 0.9118706923887022
Validation loss: 2.414091782339689

Epoch: 5| Step: 2
Training loss: 0.9471177133131613
Validation loss: 2.4473282500643156

Epoch: 5| Step: 3
Training loss: 0.9185245535740136
Validation loss: 2.4524354077133754

Epoch: 5| Step: 4
Training loss: 1.0425160314850417
Validation loss: 2.4552701003956843

Epoch: 5| Step: 5
Training loss: 1.3931479124338824
Validation loss: 2.4388046265073173

Epoch: 5| Step: 6
Training loss: 1.2266023471458392
Validation loss: 2.440908213230178

Epoch: 5| Step: 7
Training loss: 1.2220780830691051
Validation loss: 2.417668908807627

Epoch: 5| Step: 8
Training loss: 0.9986118277887759
Validation loss: 2.404699771477749

Epoch: 5| Step: 9
Training loss: 1.6953530021083552
Validation loss: 2.388200909276103

Epoch: 5| Step: 10
Training loss: 0.9533420378169792
Validation loss: 2.389218261730031

Epoch: 218| Step: 0
Training loss: 0.6155656437409635
Validation loss: 2.377378354474765

Epoch: 5| Step: 1
Training loss: 1.3824913384716364
Validation loss: 2.34307051294444

Epoch: 5| Step: 2
Training loss: 0.8096859323654988
Validation loss: 2.3863627682859043

Epoch: 5| Step: 3
Training loss: 1.2242434987851178
Validation loss: 2.3592124110930963

Epoch: 5| Step: 4
Training loss: 1.0789312582135417
Validation loss: 2.3383536756674377

Epoch: 5| Step: 5
Training loss: 1.065677995007246
Validation loss: 2.3530643747246485

Epoch: 5| Step: 6
Training loss: 1.0758948549388887
Validation loss: 2.350861284810479

Epoch: 5| Step: 7
Training loss: 1.662896262534122
Validation loss: 2.3686679550872936

Epoch: 5| Step: 8
Training loss: 0.8214173279164556
Validation loss: 2.37654581372804

Epoch: 5| Step: 9
Training loss: 1.0573902115521918
Validation loss: 2.3952265102477943

Epoch: 5| Step: 10
Training loss: 1.2085843264034228
Validation loss: 2.4227626014248926

Epoch: 219| Step: 0
Training loss: 1.2482294895252666
Validation loss: 2.4062042828614243

Epoch: 5| Step: 1
Training loss: 1.0652179175386594
Validation loss: 2.4035943287911983

Epoch: 5| Step: 2
Training loss: 1.08147947930185
Validation loss: 2.4199402733533217

Epoch: 5| Step: 3
Training loss: 1.1871398580440145
Validation loss: 2.442857680327234

Epoch: 5| Step: 4
Training loss: 1.0479756163643321
Validation loss: 2.425113861409892

Epoch: 5| Step: 5
Training loss: 1.1547981632459863
Validation loss: 2.435074313649591

Epoch: 5| Step: 6
Training loss: 0.8375010618516254
Validation loss: 2.4113566707795533

Epoch: 5| Step: 7
Training loss: 1.211074624450095
Validation loss: 2.4161723670634045

Epoch: 5| Step: 8
Training loss: 1.0104997279578762
Validation loss: 2.4087024917454376

Epoch: 5| Step: 9
Training loss: 1.2771283355965037
Validation loss: 2.395933731957322

Epoch: 5| Step: 10
Training loss: 1.048522336344454
Validation loss: 2.3653013017468965

Epoch: 220| Step: 0
Training loss: 0.720217781707461
Validation loss: 2.3657158481419467

Epoch: 5| Step: 1
Training loss: 1.1253452830795054
Validation loss: 2.3701928748500296

Epoch: 5| Step: 2
Training loss: 1.1217902807693716
Validation loss: 2.366882032679131

Epoch: 5| Step: 3
Training loss: 0.9845614181083508
Validation loss: 2.361034891376972

Epoch: 5| Step: 4
Training loss: 1.0699730216395356
Validation loss: 2.3895205121169054

Epoch: 5| Step: 5
Training loss: 1.1596985501724288
Validation loss: 2.4232803855834266

Epoch: 5| Step: 6
Training loss: 1.069749391655906
Validation loss: 2.436761629078298

Epoch: 5| Step: 7
Training loss: 1.2112977015153923
Validation loss: 2.4646861953607186

Epoch: 5| Step: 8
Training loss: 1.1353157535236507
Validation loss: 2.4644206289589943

Epoch: 5| Step: 9
Training loss: 1.2261780057220948
Validation loss: 2.4358408276589407

Epoch: 5| Step: 10
Training loss: 1.226857726898095
Validation loss: 2.3950268849203553

Epoch: 221| Step: 0
Training loss: 1.2605101758250346
Validation loss: 2.3634663127597317

Epoch: 5| Step: 1
Training loss: 0.7595560525196613
Validation loss: 2.3561429266169007

Epoch: 5| Step: 2
Training loss: 1.332205349907515
Validation loss: 2.3742619853633045

Epoch: 5| Step: 3
Training loss: 1.1215744317228662
Validation loss: 2.3927903341710675

Epoch: 5| Step: 4
Training loss: 1.1988494503228877
Validation loss: 2.3787668081099094

Epoch: 5| Step: 5
Training loss: 0.9268359522140849
Validation loss: 2.398505394263808

Epoch: 5| Step: 6
Training loss: 1.0934943854140298
Validation loss: 2.388872315769112

Epoch: 5| Step: 7
Training loss: 0.99664467928203
Validation loss: 2.383710549217904

Epoch: 5| Step: 8
Training loss: 0.7924159711820743
Validation loss: 2.4167345944095264

Epoch: 5| Step: 9
Training loss: 1.2706668411173372
Validation loss: 2.431061719194379

Epoch: 5| Step: 10
Training loss: 1.1488014734335776
Validation loss: 2.4308920859847896

Epoch: 222| Step: 0
Training loss: 1.2309319971392065
Validation loss: 2.441208224495834

Epoch: 5| Step: 1
Training loss: 1.2221011525695475
Validation loss: 2.4654302960530923

Epoch: 5| Step: 2
Training loss: 1.177192930447514
Validation loss: 2.4841905255668033

Epoch: 5| Step: 3
Training loss: 1.2923653568993179
Validation loss: 2.496196711772484

Epoch: 5| Step: 4
Training loss: 0.868316808593358
Validation loss: 2.4604845397439368

Epoch: 5| Step: 5
Training loss: 0.9432781492532694
Validation loss: 2.4692484782183137

Epoch: 5| Step: 6
Training loss: 0.9896890316112099
Validation loss: 2.4414435953544915

Epoch: 5| Step: 7
Training loss: 0.9127552433202886
Validation loss: 2.4372552581081064

Epoch: 5| Step: 8
Training loss: 0.9654396471809815
Validation loss: 2.4168040749591246

Epoch: 5| Step: 9
Training loss: 0.9806971189044071
Validation loss: 2.4029989468751607

Epoch: 5| Step: 10
Training loss: 1.23893220079281
Validation loss: 2.395274068036855

Epoch: 223| Step: 0
Training loss: 0.7788354946740227
Validation loss: 2.3787539853824406

Epoch: 5| Step: 1
Training loss: 1.0432352589914833
Validation loss: 2.357677140825367

Epoch: 5| Step: 2
Training loss: 1.2201549550441728
Validation loss: 2.370087760990283

Epoch: 5| Step: 3
Training loss: 0.9477678678212371
Validation loss: 2.3615833735089455

Epoch: 5| Step: 4
Training loss: 1.0618749911985796
Validation loss: 2.3923519909130198

Epoch: 5| Step: 5
Training loss: 1.0897922298600342
Validation loss: 2.3906415691709033

Epoch: 5| Step: 6
Training loss: 1.0647420228657962
Validation loss: 2.4442822851055044

Epoch: 5| Step: 7
Training loss: 1.0554514061147275
Validation loss: 2.4088430061292425

Epoch: 5| Step: 8
Training loss: 0.852153817753722
Validation loss: 2.4285556866251174

Epoch: 5| Step: 9
Training loss: 1.4279028588280323
Validation loss: 2.418545403931563

Epoch: 5| Step: 10
Training loss: 1.1423815957615817
Validation loss: 2.418433494991062

Epoch: 224| Step: 0
Training loss: 1.33379964820101
Validation loss: 2.376198585448881

Epoch: 5| Step: 1
Training loss: 1.1951410507211164
Validation loss: 2.4031065432740677

Epoch: 5| Step: 2
Training loss: 0.8238297760441796
Validation loss: 2.393813527280435

Epoch: 5| Step: 3
Training loss: 1.2032081278036924
Validation loss: 2.401848165338972

Epoch: 5| Step: 4
Training loss: 0.85655655350512
Validation loss: 2.389913593724064

Epoch: 5| Step: 5
Training loss: 0.7325041457700096
Validation loss: 2.407920916210133

Epoch: 5| Step: 6
Training loss: 1.217328979339905
Validation loss: 2.4145464509133636

Epoch: 5| Step: 7
Training loss: 1.0723522825261531
Validation loss: 2.3934585504387123

Epoch: 5| Step: 8
Training loss: 1.0232276410144512
Validation loss: 2.4367280668036173

Epoch: 5| Step: 9
Training loss: 1.2431282943290685
Validation loss: 2.396325687218773

Epoch: 5| Step: 10
Training loss: 0.7873550296739319
Validation loss: 2.414609436187385

Epoch: 225| Step: 0
Training loss: 1.2156051261473684
Validation loss: 2.4165382421851893

Epoch: 5| Step: 1
Training loss: 1.1134595226301522
Validation loss: 2.390333914630611

Epoch: 5| Step: 2
Training loss: 1.1005381698193708
Validation loss: 2.4099813881081666

Epoch: 5| Step: 3
Training loss: 0.5523568471518528
Validation loss: 2.3936705830235447

Epoch: 5| Step: 4
Training loss: 0.7294590545442714
Validation loss: 2.39769747966693

Epoch: 5| Step: 5
Training loss: 0.9981099984051461
Validation loss: 2.3900063990684366

Epoch: 5| Step: 6
Training loss: 1.2527764480134533
Validation loss: 2.395506778699411

Epoch: 5| Step: 7
Training loss: 1.572998785776299
Validation loss: 2.4110481549275127

Epoch: 5| Step: 8
Training loss: 1.0277742709423643
Validation loss: 2.3929067166815496

Epoch: 5| Step: 9
Training loss: 0.8490268156986148
Validation loss: 2.3473277719827554

Epoch: 5| Step: 10
Training loss: 0.8338540754888049
Validation loss: 2.383590814817716

Epoch: 226| Step: 0
Training loss: 1.1967113014404775
Validation loss: 2.372247376121716

Epoch: 5| Step: 1
Training loss: 1.0212277150144802
Validation loss: 2.390850440686387

Epoch: 5| Step: 2
Training loss: 1.0364009643217464
Validation loss: 2.366977405217036

Epoch: 5| Step: 3
Training loss: 0.8447255040862227
Validation loss: 2.366796158418711

Epoch: 5| Step: 4
Training loss: 1.1967137917897657
Validation loss: 2.343507308153335

Epoch: 5| Step: 5
Training loss: 1.057995053292376
Validation loss: 2.3347250996437845

Epoch: 5| Step: 6
Training loss: 0.8525387129285867
Validation loss: 2.3686601846068034

Epoch: 5| Step: 7
Training loss: 1.0287505406393342
Validation loss: 2.382797000699443

Epoch: 5| Step: 8
Training loss: 1.1068390350271529
Validation loss: 2.40829880280863

Epoch: 5| Step: 9
Training loss: 0.9041094657864017
Validation loss: 2.442864383112422

Epoch: 5| Step: 10
Training loss: 1.2900715895312642
Validation loss: 2.478051359136139

Epoch: 227| Step: 0
Training loss: 0.7739548157260755
Validation loss: 2.469598866417887

Epoch: 5| Step: 1
Training loss: 0.7450289492775
Validation loss: 2.458802399710294

Epoch: 5| Step: 2
Training loss: 1.073022516208123
Validation loss: 2.4604822079144255

Epoch: 5| Step: 3
Training loss: 1.2803648240261267
Validation loss: 2.4407628278908478

Epoch: 5| Step: 4
Training loss: 0.9873177275659623
Validation loss: 2.4310518202504525

Epoch: 5| Step: 5
Training loss: 0.8490383991952929
Validation loss: 2.3999380639289765

Epoch: 5| Step: 6
Training loss: 0.8024774590413364
Validation loss: 2.3556729393862774

Epoch: 5| Step: 7
Training loss: 1.3037811603278668
Validation loss: 2.3295748877825404

Epoch: 5| Step: 8
Training loss: 1.3262886366757685
Validation loss: 2.3210793753271646

Epoch: 5| Step: 9
Training loss: 1.321261544515507
Validation loss: 2.3296176491259297

Epoch: 5| Step: 10
Training loss: 0.5960468488768181
Validation loss: 2.3367886039657293

Epoch: 228| Step: 0
Training loss: 1.0830599305362745
Validation loss: 2.3307144510136077

Epoch: 5| Step: 1
Training loss: 1.0796043087918887
Validation loss: 2.3885570238215386

Epoch: 5| Step: 2
Training loss: 1.0956424689545932
Validation loss: 2.418908392414927

Epoch: 5| Step: 3
Training loss: 0.7544762625755349
Validation loss: 2.4285398173840695

Epoch: 5| Step: 4
Training loss: 0.8836099179624355
Validation loss: 2.437883618765216

Epoch: 5| Step: 5
Training loss: 1.0175543432696643
Validation loss: 2.380342503210055

Epoch: 5| Step: 6
Training loss: 1.020005214621734
Validation loss: 2.3911817281623335

Epoch: 5| Step: 7
Training loss: 0.9450276473708846
Validation loss: 2.36395438931818

Epoch: 5| Step: 8
Training loss: 0.9747637242351178
Validation loss: 2.3747495984476457

Epoch: 5| Step: 9
Training loss: 1.3323925344993812
Validation loss: 2.381711007870439

Epoch: 5| Step: 10
Training loss: 1.2002011229930798
Validation loss: 2.353655776477461

Epoch: 229| Step: 0
Training loss: 0.8906505647972208
Validation loss: 2.3753093621623376

Epoch: 5| Step: 1
Training loss: 1.1718626911788466
Validation loss: 2.3931029724559605

Epoch: 5| Step: 2
Training loss: 1.2219676068034808
Validation loss: 2.415730951520466

Epoch: 5| Step: 3
Training loss: 0.9417228641170133
Validation loss: 2.4328579470168967

Epoch: 5| Step: 4
Training loss: 0.7920088572223613
Validation loss: 2.420262488295572

Epoch: 5| Step: 5
Training loss: 1.002431654847846
Validation loss: 2.407041136493641

Epoch: 5| Step: 6
Training loss: 1.0878616959237088
Validation loss: 2.400081638431168

Epoch: 5| Step: 7
Training loss: 1.07960464005012
Validation loss: 2.406919552686875

Epoch: 5| Step: 8
Training loss: 1.1318983928047213
Validation loss: 2.364281303353884

Epoch: 5| Step: 9
Training loss: 0.822245654228327
Validation loss: 2.3843004970495656

Epoch: 5| Step: 10
Training loss: 1.0704502657473622
Validation loss: 2.3972843967385407

Epoch: 230| Step: 0
Training loss: 0.9104586905085247
Validation loss: 2.372286967589084

Epoch: 5| Step: 1
Training loss: 1.10159350412444
Validation loss: 2.370849943907508

Epoch: 5| Step: 2
Training loss: 0.9632526204726739
Validation loss: 2.3394432439326533

Epoch: 5| Step: 3
Training loss: 0.9798984160615148
Validation loss: 2.365102659868309

Epoch: 5| Step: 4
Training loss: 1.1069627782392806
Validation loss: 2.3801002078470535

Epoch: 5| Step: 5
Training loss: 1.1912424443936982
Validation loss: 2.3554798557840932

Epoch: 5| Step: 6
Training loss: 0.9930062407732542
Validation loss: 2.342770298020188

Epoch: 5| Step: 7
Training loss: 0.8087037237450265
Validation loss: 2.388700786017138

Epoch: 5| Step: 8
Training loss: 1.103993054302453
Validation loss: 2.3918001558789657

Epoch: 5| Step: 9
Training loss: 0.7327907193003294
Validation loss: 2.379057550130739

Epoch: 5| Step: 10
Training loss: 1.240544317970641
Validation loss: 2.4003195318769723

Epoch: 231| Step: 0
Training loss: 1.0903241045775178
Validation loss: 2.4114590969991228

Epoch: 5| Step: 1
Training loss: 1.1803127425569502
Validation loss: 2.417661251812793

Epoch: 5| Step: 2
Training loss: 0.900863225536803
Validation loss: 2.402611097280902

Epoch: 5| Step: 3
Training loss: 0.9776526203182638
Validation loss: 2.3790407655820016

Epoch: 5| Step: 4
Training loss: 1.5491966011283893
Validation loss: 2.3868177255896272

Epoch: 5| Step: 5
Training loss: 0.8059678123545283
Validation loss: 2.387114961197201

Epoch: 5| Step: 6
Training loss: 1.03039341811009
Validation loss: 2.381888894482612

Epoch: 5| Step: 7
Training loss: 0.7329624469968298
Validation loss: 2.4315647195598156

Epoch: 5| Step: 8
Training loss: 1.0770215455169647
Validation loss: 2.421400332635047

Epoch: 5| Step: 9
Training loss: 0.8352276649309038
Validation loss: 2.415935780479536

Epoch: 5| Step: 10
Training loss: 0.6206749997930011
Validation loss: 2.399813441576484

Epoch: 232| Step: 0
Training loss: 0.5486242927169499
Validation loss: 2.38242150939615

Epoch: 5| Step: 1
Training loss: 1.093696974422654
Validation loss: 2.3572990478665714

Epoch: 5| Step: 2
Training loss: 1.2037896141276023
Validation loss: 2.3459157703640243

Epoch: 5| Step: 3
Training loss: 0.7891651124613307
Validation loss: 2.345989648086564

Epoch: 5| Step: 4
Training loss: 0.844506489746291
Validation loss: 2.335261097550382

Epoch: 5| Step: 5
Training loss: 1.0943446041746436
Validation loss: 2.342773787121141

Epoch: 5| Step: 6
Training loss: 1.0699437195245993
Validation loss: 2.36494498400755

Epoch: 5| Step: 7
Training loss: 1.1725422294836487
Validation loss: 2.359444107405047

Epoch: 5| Step: 8
Training loss: 0.9411245850678541
Validation loss: 2.3892829576273518

Epoch: 5| Step: 9
Training loss: 1.1531384847209194
Validation loss: 2.4305029895526284

Epoch: 5| Step: 10
Training loss: 0.8918354776309498
Validation loss: 2.4420629587616554

Epoch: 233| Step: 0
Training loss: 1.0698064456997263
Validation loss: 2.435417896259459

Epoch: 5| Step: 1
Training loss: 1.250808930909784
Validation loss: 2.4552895860203767

Epoch: 5| Step: 2
Training loss: 0.9151648045212166
Validation loss: 2.4431652942447215

Epoch: 5| Step: 3
Training loss: 1.0596919820516932
Validation loss: 2.4019159482518497

Epoch: 5| Step: 4
Training loss: 0.9645199251583799
Validation loss: 2.371607863908376

Epoch: 5| Step: 5
Training loss: 0.8440814603436458
Validation loss: 2.326910084714617

Epoch: 5| Step: 6
Training loss: 1.0175328455129558
Validation loss: 2.338217562758475

Epoch: 5| Step: 7
Training loss: 1.0300037483036022
Validation loss: 2.315100666686085

Epoch: 5| Step: 8
Training loss: 0.8006870865702036
Validation loss: 2.321166708996534

Epoch: 5| Step: 9
Training loss: 0.9493856714991191
Validation loss: 2.3238642083580046

Epoch: 5| Step: 10
Training loss: 0.9841584164152241
Validation loss: 2.361507639281165

Epoch: 234| Step: 0
Training loss: 0.7977134930641462
Validation loss: 2.369979411390078

Epoch: 5| Step: 1
Training loss: 1.1806937972016915
Validation loss: 2.4038706749989815

Epoch: 5| Step: 2
Training loss: 0.9451914307801952
Validation loss: 2.4339581754631663

Epoch: 5| Step: 3
Training loss: 1.1117165260533963
Validation loss: 2.435606324751283

Epoch: 5| Step: 4
Training loss: 1.013651470941833
Validation loss: 2.4731099052229455

Epoch: 5| Step: 5
Training loss: 0.5316236528298364
Validation loss: 2.4454515911583448

Epoch: 5| Step: 6
Training loss: 1.4241030496964695
Validation loss: 2.4553040868500187

Epoch: 5| Step: 7
Training loss: 0.8624089870255324
Validation loss: 2.4083955976928655

Epoch: 5| Step: 8
Training loss: 0.5368378108758777
Validation loss: 2.378591038686029

Epoch: 5| Step: 9
Training loss: 0.8791754077338232
Validation loss: 2.3473353121936844

Epoch: 5| Step: 10
Training loss: 1.2625833861507714
Validation loss: 2.322479922877651

Epoch: 235| Step: 0
Training loss: 0.9491640867969081
Validation loss: 2.3057036720645616

Epoch: 5| Step: 1
Training loss: 0.8585754489770547
Validation loss: 2.3179048169869736

Epoch: 5| Step: 2
Training loss: 0.8106975001823494
Validation loss: 2.317607747395899

Epoch: 5| Step: 3
Training loss: 1.1016342464376252
Validation loss: 2.303715631415807

Epoch: 5| Step: 4
Training loss: 0.9749820585311827
Validation loss: 2.3969696257271806

Epoch: 5| Step: 5
Training loss: 1.060110546861398
Validation loss: 2.3795313188811393

Epoch: 5| Step: 6
Training loss: 1.221665148263554
Validation loss: 2.4223463908992913

Epoch: 5| Step: 7
Training loss: 0.9227369449222154
Validation loss: 2.4109844630837483

Epoch: 5| Step: 8
Training loss: 0.8416727421481481
Validation loss: 2.4348362007535815

Epoch: 5| Step: 9
Training loss: 0.9495250694295969
Validation loss: 2.4517602049506033

Epoch: 5| Step: 10
Training loss: 0.9378201891575311
Validation loss: 2.458487571715143

Epoch: 236| Step: 0
Training loss: 0.9507758473452032
Validation loss: 2.4276345088515368

Epoch: 5| Step: 1
Training loss: 0.656519811659616
Validation loss: 2.4254366753962118

Epoch: 5| Step: 2
Training loss: 0.8846949871235547
Validation loss: 2.3673084495768015

Epoch: 5| Step: 3
Training loss: 1.3108642466724159
Validation loss: 2.352229455376957

Epoch: 5| Step: 4
Training loss: 0.7669054728875914
Validation loss: 2.343925879657541

Epoch: 5| Step: 5
Training loss: 0.5353239311872799
Validation loss: 2.321520465545176

Epoch: 5| Step: 6
Training loss: 1.2281973082244104
Validation loss: 2.3538557633740034

Epoch: 5| Step: 7
Training loss: 1.1098031305879072
Validation loss: 2.3478567522948417

Epoch: 5| Step: 8
Training loss: 1.0831671306078692
Validation loss: 2.3603179270915584

Epoch: 5| Step: 9
Training loss: 0.9533561676354064
Validation loss: 2.3663633797687176

Epoch: 5| Step: 10
Training loss: 0.8005141021968379
Validation loss: 2.3684874069973363

Epoch: 237| Step: 0
Training loss: 1.3813107628208803
Validation loss: 2.37044921608778

Epoch: 5| Step: 1
Training loss: 0.8479227446979499
Validation loss: 2.3735826026768114

Epoch: 5| Step: 2
Training loss: 0.7025341306316565
Validation loss: 2.369060458630592

Epoch: 5| Step: 3
Training loss: 1.1153283288398403
Validation loss: 2.3818758044165067

Epoch: 5| Step: 4
Training loss: 0.7444253211704608
Validation loss: 2.3929468662577085

Epoch: 5| Step: 5
Training loss: 0.8377400865460607
Validation loss: 2.411614281272592

Epoch: 5| Step: 6
Training loss: 0.8854268279147041
Validation loss: 2.4092519673895074

Epoch: 5| Step: 7
Training loss: 1.0039770197879068
Validation loss: 2.4003963484575253

Epoch: 5| Step: 8
Training loss: 0.9860678149883609
Validation loss: 2.4396090721250157

Epoch: 5| Step: 9
Training loss: 1.0200566951104355
Validation loss: 2.4133350521294097

Epoch: 5| Step: 10
Training loss: 0.836570678203566
Validation loss: 2.4236009558799987

Epoch: 238| Step: 0
Training loss: 0.7595438498695947
Validation loss: 2.4092840811575065

Epoch: 5| Step: 1
Training loss: 0.9233937441920697
Validation loss: 2.389188303271884

Epoch: 5| Step: 2
Training loss: 1.084786992588942
Validation loss: 2.3772781059178465

Epoch: 5| Step: 3
Training loss: 0.7406402924322983
Validation loss: 2.355796515120572

Epoch: 5| Step: 4
Training loss: 1.0935017440251735
Validation loss: 2.3286786618231323

Epoch: 5| Step: 5
Training loss: 0.6630134149592366
Validation loss: 2.3557100675270433

Epoch: 5| Step: 6
Training loss: 0.9618753957964484
Validation loss: 2.352342323049433

Epoch: 5| Step: 7
Training loss: 1.1710119502616698
Validation loss: 2.351133776869701

Epoch: 5| Step: 8
Training loss: 0.9745931375561367
Validation loss: 2.364612617291467

Epoch: 5| Step: 9
Training loss: 1.0634292017511773
Validation loss: 2.4212744554087227

Epoch: 5| Step: 10
Training loss: 0.8916887656411627
Validation loss: 2.422351637032923

Epoch: 239| Step: 0
Training loss: 0.9065813248161477
Validation loss: 2.441282499593834

Epoch: 5| Step: 1
Training loss: 1.0106647553937482
Validation loss: 2.4642955208763317

Epoch: 5| Step: 2
Training loss: 1.0351451945164354
Validation loss: 2.4525464427712995

Epoch: 5| Step: 3
Training loss: 1.0087967435649614
Validation loss: 2.4133633511366495

Epoch: 5| Step: 4
Training loss: 0.6817610451209606
Validation loss: 2.4336857271120027

Epoch: 5| Step: 5
Training loss: 1.1181343707677642
Validation loss: 2.395962097930824

Epoch: 5| Step: 6
Training loss: 1.1139321014148484
Validation loss: 2.3847130651601964

Epoch: 5| Step: 7
Training loss: 0.848740793608004
Validation loss: 2.351193654590915

Epoch: 5| Step: 8
Training loss: 1.032069256506476
Validation loss: 2.347951486942981

Epoch: 5| Step: 9
Training loss: 0.7672597987026896
Validation loss: 2.307101127082683

Epoch: 5| Step: 10
Training loss: 0.7596910925544457
Validation loss: 2.298293904802706

Epoch: 240| Step: 0
Training loss: 0.7233313628871583
Validation loss: 2.307273367084188

Epoch: 5| Step: 1
Training loss: 0.6722213828087742
Validation loss: 2.3491575789913046

Epoch: 5| Step: 2
Training loss: 1.1825338723329588
Validation loss: 2.3218543236624685

Epoch: 5| Step: 3
Training loss: 1.042372515268197
Validation loss: 2.3690654158808053

Epoch: 5| Step: 4
Training loss: 0.7891689266533668
Validation loss: 2.39102295114177

Epoch: 5| Step: 5
Training loss: 0.8586363652546588
Validation loss: 2.370908164550392

Epoch: 5| Step: 6
Training loss: 1.1412332036765975
Validation loss: 2.3836072564984723

Epoch: 5| Step: 7
Training loss: 0.8371559247608614
Validation loss: 2.402015506874079

Epoch: 5| Step: 8
Training loss: 0.869599433412341
Validation loss: 2.38907330093663

Epoch: 5| Step: 9
Training loss: 1.1227617250083826
Validation loss: 2.3863490259555804

Epoch: 5| Step: 10
Training loss: 0.8439385591963765
Validation loss: 2.397980887870707

Epoch: 241| Step: 0
Training loss: 1.0027507262016868
Validation loss: 2.3797974709266287

Epoch: 5| Step: 1
Training loss: 0.7494834074457546
Validation loss: 2.3460061964780157

Epoch: 5| Step: 2
Training loss: 0.8969370046309477
Validation loss: 2.364716746216814

Epoch: 5| Step: 3
Training loss: 1.2474110495555764
Validation loss: 2.347754032196038

Epoch: 5| Step: 4
Training loss: 0.9628781517103013
Validation loss: 2.3224366961954437

Epoch: 5| Step: 5
Training loss: 0.8994450765723628
Validation loss: 2.3444017036084097

Epoch: 5| Step: 6
Training loss: 0.7795513378192266
Validation loss: 2.3544393187883226

Epoch: 5| Step: 7
Training loss: 0.6304533038321202
Validation loss: 2.3494332770188566

Epoch: 5| Step: 8
Training loss: 0.6192527212237928
Validation loss: 2.357065756132164

Epoch: 5| Step: 9
Training loss: 1.1836400290528195
Validation loss: 2.398435980052893

Epoch: 5| Step: 10
Training loss: 0.9738614379228353
Validation loss: 2.3904685169564854

Epoch: 242| Step: 0
Training loss: 0.75646227072242
Validation loss: 2.4086702254733146

Epoch: 5| Step: 1
Training loss: 1.3051061815056553
Validation loss: 2.404936146376581

Epoch: 5| Step: 2
Training loss: 0.6232724872469453
Validation loss: 2.3616888246318815

Epoch: 5| Step: 3
Training loss: 0.7890339836784247
Validation loss: 2.3562944905200593

Epoch: 5| Step: 4
Training loss: 1.2365630832041228
Validation loss: 2.3274498187786117

Epoch: 5| Step: 5
Training loss: 1.0023093975124022
Validation loss: 2.3016815621907765

Epoch: 5| Step: 6
Training loss: 0.6171125294022446
Validation loss: 2.3025233265358307

Epoch: 5| Step: 7
Training loss: 0.9685110597348253
Validation loss: 2.3363456000561467

Epoch: 5| Step: 8
Training loss: 0.8476999157324917
Validation loss: 2.3290016482235583

Epoch: 5| Step: 9
Training loss: 0.7863603156105362
Validation loss: 2.3457580332108217

Epoch: 5| Step: 10
Training loss: 0.9569072409492295
Validation loss: 2.391791228995662

Epoch: 243| Step: 0
Training loss: 0.5387195380730825
Validation loss: 2.373682089824453

Epoch: 5| Step: 1
Training loss: 1.1122777331052836
Validation loss: 2.377145352003508

Epoch: 5| Step: 2
Training loss: 0.821292618642903
Validation loss: 2.3800150281018553

Epoch: 5| Step: 3
Training loss: 0.8732352170962507
Validation loss: 2.407469402254201

Epoch: 5| Step: 4
Training loss: 1.28350988985954
Validation loss: 2.4051425869551086

Epoch: 5| Step: 5
Training loss: 0.7039981506848971
Validation loss: 2.350355618165328

Epoch: 5| Step: 6
Training loss: 0.8611489453430043
Validation loss: 2.37842032444774

Epoch: 5| Step: 7
Training loss: 0.9308528488513099
Validation loss: 2.3855783941743347

Epoch: 5| Step: 8
Training loss: 1.1086637339099197
Validation loss: 2.365391559027952

Epoch: 5| Step: 9
Training loss: 0.5541559278073872
Validation loss: 2.356354750622865

Epoch: 5| Step: 10
Training loss: 0.8846530463740016
Validation loss: 2.3673982123382356

Epoch: 244| Step: 0
Training loss: 0.9986197363513828
Validation loss: 2.370527867946058

Epoch: 5| Step: 1
Training loss: 0.6365763030992522
Validation loss: 2.4052561153789527

Epoch: 5| Step: 2
Training loss: 0.9895327036437479
Validation loss: 2.381332831567361

Epoch: 5| Step: 3
Training loss: 0.7794723504394752
Validation loss: 2.4073047729984665

Epoch: 5| Step: 4
Training loss: 0.4378321783039428
Validation loss: 2.3914890292225666

Epoch: 5| Step: 5
Training loss: 0.6958819211530339
Validation loss: 2.413425431452474

Epoch: 5| Step: 6
Training loss: 1.1707536545834307
Validation loss: 2.400397046934147

Epoch: 5| Step: 7
Training loss: 0.9500132246100849
Validation loss: 2.3660207194760847

Epoch: 5| Step: 8
Training loss: 1.0468557555294482
Validation loss: 2.348635194252056

Epoch: 5| Step: 9
Training loss: 0.8886198594517056
Validation loss: 2.334442048490171

Epoch: 5| Step: 10
Training loss: 1.0134595233266337
Validation loss: 2.343484082740787

Epoch: 245| Step: 0
Training loss: 0.8152108818291879
Validation loss: 2.3591974500340496

Epoch: 5| Step: 1
Training loss: 0.8856638208144235
Validation loss: 2.3741290595574194

Epoch: 5| Step: 2
Training loss: 0.9244092923832564
Validation loss: 2.388634397910512

Epoch: 5| Step: 3
Training loss: 1.1970520326846565
Validation loss: 2.3737777788237957

Epoch: 5| Step: 4
Training loss: 0.8136577427333163
Validation loss: 2.4143453686436867

Epoch: 5| Step: 5
Training loss: 0.9712184405507855
Validation loss: 2.424049498418679

Epoch: 5| Step: 6
Training loss: 0.8024169591322834
Validation loss: 2.4083041556546285

Epoch: 5| Step: 7
Training loss: 0.7673640061712721
Validation loss: 2.363316794724518

Epoch: 5| Step: 8
Training loss: 0.9333591246163548
Validation loss: 2.3723669800832328

Epoch: 5| Step: 9
Training loss: 0.8362697760919297
Validation loss: 2.344262732749871

Epoch: 5| Step: 10
Training loss: 0.7421640894359858
Validation loss: 2.3241789463764655

Epoch: 246| Step: 0
Training loss: 0.8752024961218029
Validation loss: 2.313427042813034

Epoch: 5| Step: 1
Training loss: 0.6973816590771554
Validation loss: 2.309125519588022

Epoch: 5| Step: 2
Training loss: 0.6883251050645107
Validation loss: 2.302869975742133

Epoch: 5| Step: 3
Training loss: 0.81774748366274
Validation loss: 2.3188831949704185

Epoch: 5| Step: 4
Training loss: 0.6573553993493136
Validation loss: 2.3552533207335546

Epoch: 5| Step: 5
Training loss: 0.7604076350124274
Validation loss: 2.337331872254218

Epoch: 5| Step: 6
Training loss: 1.048441497749632
Validation loss: 2.3892638913238446

Epoch: 5| Step: 7
Training loss: 0.8126332833936313
Validation loss: 2.4112774656570823

Epoch: 5| Step: 8
Training loss: 1.1270762992728707
Validation loss: 2.391840614495201

Epoch: 5| Step: 9
Training loss: 1.1230426290680606
Validation loss: 2.402800311371882

Epoch: 5| Step: 10
Training loss: 0.9932043616896964
Validation loss: 2.3912706140738273

Epoch: 247| Step: 0
Training loss: 1.0281861771119456
Validation loss: 2.3698716031268083

Epoch: 5| Step: 1
Training loss: 0.48697264219867037
Validation loss: 2.381685709433449

Epoch: 5| Step: 2
Training loss: 0.8368553043067687
Validation loss: 2.3711812320020043

Epoch: 5| Step: 3
Training loss: 1.0998701257329975
Validation loss: 2.4044345974776307

Epoch: 5| Step: 4
Training loss: 0.8380896769795572
Validation loss: 2.3925092599587803

Epoch: 5| Step: 5
Training loss: 1.0315288397917348
Validation loss: 2.3772823914487136

Epoch: 5| Step: 6
Training loss: 0.813480445880024
Validation loss: 2.3845459951796064

Epoch: 5| Step: 7
Training loss: 0.688990624240815
Validation loss: 2.3894144932182364

Epoch: 5| Step: 8
Training loss: 0.5708708968878548
Validation loss: 2.398648374238569

Epoch: 5| Step: 9
Training loss: 1.0191662014273712
Validation loss: 2.3961973009255475

Epoch: 5| Step: 10
Training loss: 1.0025750027993408
Validation loss: 2.3654016915681124

Epoch: 248| Step: 0
Training loss: 1.1928603007468135
Validation loss: 2.3775037322808648

Epoch: 5| Step: 1
Training loss: 0.7514737273069775
Validation loss: 2.3402322256344883

Epoch: 5| Step: 2
Training loss: 1.075760944648544
Validation loss: 2.344442520922622

Epoch: 5| Step: 3
Training loss: 0.9680701916167607
Validation loss: 2.3275865107000615

Epoch: 5| Step: 4
Training loss: 0.8494165662148373
Validation loss: 2.352673732270791

Epoch: 5| Step: 5
Training loss: 0.6842132377184684
Validation loss: 2.35434335830876

Epoch: 5| Step: 6
Training loss: 0.6684492513400326
Validation loss: 2.3634132109082113

Epoch: 5| Step: 7
Training loss: 1.0505833208938355
Validation loss: 2.369459738885571

Epoch: 5| Step: 8
Training loss: 0.6562873511811177
Validation loss: 2.4339837510854108

Epoch: 5| Step: 9
Training loss: 0.3803310936400197
Validation loss: 2.411964746225918

Epoch: 5| Step: 10
Training loss: 0.9858894505709557
Validation loss: 2.390194442252935

Epoch: 249| Step: 0
Training loss: 0.8207096773201038
Validation loss: 2.408690855459568

Epoch: 5| Step: 1
Training loss: 1.0931423679234913
Validation loss: 2.413480774130886

Epoch: 5| Step: 2
Training loss: 0.8565635469048222
Validation loss: 2.3768357445197057

Epoch: 5| Step: 3
Training loss: 0.49060608347488976
Validation loss: 2.3740278034171154

Epoch: 5| Step: 4
Training loss: 0.9115692761430572
Validation loss: 2.3860620679759164

Epoch: 5| Step: 5
Training loss: 0.9063761721945272
Validation loss: 2.3724431294707835

Epoch: 5| Step: 6
Training loss: 0.9373044763760767
Validation loss: 2.3650977821118584

Epoch: 5| Step: 7
Training loss: 0.997586048736161
Validation loss: 2.3585447309126746

Epoch: 5| Step: 8
Training loss: 1.0682482897037069
Validation loss: 2.3828826694925676

Epoch: 5| Step: 9
Training loss: 0.7046925978042704
Validation loss: 2.3970363669314354

Epoch: 5| Step: 10
Training loss: 0.3551898323155689
Validation loss: 2.3751005794771034

Epoch: 250| Step: 0
Training loss: 0.9478840804874317
Validation loss: 2.3948942761512386

Epoch: 5| Step: 1
Training loss: 0.8321996527374284
Validation loss: 2.407783327665053

Epoch: 5| Step: 2
Training loss: 0.9063416138743405
Validation loss: 2.4139222108531895

Epoch: 5| Step: 3
Training loss: 1.0123173772688863
Validation loss: 2.4089652165183373

Epoch: 5| Step: 4
Training loss: 1.12438990686447
Validation loss: 2.4166135842247

Epoch: 5| Step: 5
Training loss: 0.9544356667972695
Validation loss: 2.406519751789755

Epoch: 5| Step: 6
Training loss: 0.7067375416084353
Validation loss: 2.3981939156497205

Epoch: 5| Step: 7
Training loss: 0.5694920373298001
Validation loss: 2.404999486203297

Epoch: 5| Step: 8
Training loss: 0.9190405250057166
Validation loss: 2.404808157409035

Epoch: 5| Step: 9
Training loss: 0.7089216556602963
Validation loss: 2.414204843202494

Epoch: 5| Step: 10
Training loss: 0.5050737031181055
Validation loss: 2.4237875784015173

Epoch: 251| Step: 0
Training loss: 1.009670644163112
Validation loss: 2.4138685743844217

Epoch: 5| Step: 1
Training loss: 0.8310026876495638
Validation loss: 2.4149563889924583

Epoch: 5| Step: 2
Training loss: 0.8734063212881162
Validation loss: 2.4021041546547375

Epoch: 5| Step: 3
Training loss: 0.5550786640505553
Validation loss: 2.4132831835642166

Epoch: 5| Step: 4
Training loss: 0.7972803020107578
Validation loss: 2.390029799888755

Epoch: 5| Step: 5
Training loss: 0.8490088785176804
Validation loss: 2.4275700313856157

Epoch: 5| Step: 6
Training loss: 0.563609988383443
Validation loss: 2.394961235754623

Epoch: 5| Step: 7
Training loss: 0.8717008450945029
Validation loss: 2.3473944622549188

Epoch: 5| Step: 8
Training loss: 0.9545709242250758
Validation loss: 2.341251522066101

Epoch: 5| Step: 9
Training loss: 0.9639076603177148
Validation loss: 2.3875311903743492

Epoch: 5| Step: 10
Training loss: 0.9545213757714684
Validation loss: 2.378529515025612

Epoch: 252| Step: 0
Training loss: 0.6806452569320327
Validation loss: 2.3851101894218503

Epoch: 5| Step: 1
Training loss: 0.907731949192059
Validation loss: 2.3813515926530746

Epoch: 5| Step: 2
Training loss: 0.9304866721783784
Validation loss: 2.368887520828331

Epoch: 5| Step: 3
Training loss: 0.5268230269151146
Validation loss: 2.399811613771571

Epoch: 5| Step: 4
Training loss: 0.810044318976471
Validation loss: 2.424743880741682

Epoch: 5| Step: 5
Training loss: 0.7999112497215115
Validation loss: 2.410487633406001

Epoch: 5| Step: 6
Training loss: 0.631680995804638
Validation loss: 2.41201404657003

Epoch: 5| Step: 7
Training loss: 0.9566788627985745
Validation loss: 2.379956504575649

Epoch: 5| Step: 8
Training loss: 0.7187831705151564
Validation loss: 2.3800420537204308

Epoch: 5| Step: 9
Training loss: 1.1365731791722737
Validation loss: 2.373636224416725

Epoch: 5| Step: 10
Training loss: 1.011770534294747
Validation loss: 2.3502174973229812

Epoch: 253| Step: 0
Training loss: 0.9070217201067413
Validation loss: 2.360350996084906

Epoch: 5| Step: 1
Training loss: 0.5020308378748028
Validation loss: 2.346962897962568

Epoch: 5| Step: 2
Training loss: 0.9357009792629742
Validation loss: 2.355967484564217

Epoch: 5| Step: 3
Training loss: 0.7151435681902844
Validation loss: 2.37345809246563

Epoch: 5| Step: 4
Training loss: 0.5976895092455009
Validation loss: 2.369254901996993

Epoch: 5| Step: 5
Training loss: 0.7182431714576126
Validation loss: 2.3659188096661365

Epoch: 5| Step: 6
Training loss: 1.023698263945416
Validation loss: 2.3775441877937427

Epoch: 5| Step: 7
Training loss: 0.6561324604676416
Validation loss: 2.361802012557016

Epoch: 5| Step: 8
Training loss: 1.077635667849652
Validation loss: 2.37413034832656

Epoch: 5| Step: 9
Training loss: 0.9886736185155693
Validation loss: 2.3593176965369906

Epoch: 5| Step: 10
Training loss: 0.8328226471760495
Validation loss: 2.344979401420635

Epoch: 254| Step: 0
Training loss: 1.0294879540530248
Validation loss: 2.3405207613348664

Epoch: 5| Step: 1
Training loss: 0.8732055246825811
Validation loss: 2.3550554222817355

Epoch: 5| Step: 2
Training loss: 0.7503126605318494
Validation loss: 2.351159156530338

Epoch: 5| Step: 3
Training loss: 0.7174821119703731
Validation loss: 2.3426993363376827

Epoch: 5| Step: 4
Training loss: 0.6512942065942575
Validation loss: 2.3592699474777614

Epoch: 5| Step: 5
Training loss: 0.6164702339953138
Validation loss: 2.340669531880299

Epoch: 5| Step: 6
Training loss: 0.8390742835668369
Validation loss: 2.3476189011187554

Epoch: 5| Step: 7
Training loss: 0.8935001210712677
Validation loss: 2.3477286670473894

Epoch: 5| Step: 8
Training loss: 0.803267475953181
Validation loss: 2.3720436694348512

Epoch: 5| Step: 9
Training loss: 0.8432202618894322
Validation loss: 2.380072844670973

Epoch: 5| Step: 10
Training loss: 1.0019985731499235
Validation loss: 2.382864263124612

Epoch: 255| Step: 0
Training loss: 0.89716341651367
Validation loss: 2.384159005572404

Epoch: 5| Step: 1
Training loss: 0.46140726042216057
Validation loss: 2.391262918649486

Epoch: 5| Step: 2
Training loss: 0.8739223315189728
Validation loss: 2.3916290939116385

Epoch: 5| Step: 3
Training loss: 0.8773068604564894
Validation loss: 2.397824254610003

Epoch: 5| Step: 4
Training loss: 1.2119866533079606
Validation loss: 2.38344225483641

Epoch: 5| Step: 5
Training loss: 0.6505747583139412
Validation loss: 2.373079517605373

Epoch: 5| Step: 6
Training loss: 1.0310630050817957
Validation loss: 2.373037059228034

Epoch: 5| Step: 7
Training loss: 0.6396079480118126
Validation loss: 2.355478863187724

Epoch: 5| Step: 8
Training loss: 0.6867232052394874
Validation loss: 2.3367740939598787

Epoch: 5| Step: 9
Training loss: 0.6069930301451497
Validation loss: 2.336844091345468

Epoch: 5| Step: 10
Training loss: 0.7422440356756622
Validation loss: 2.344970522601987

Epoch: 256| Step: 0
Training loss: 0.6766427122497254
Validation loss: 2.340876263941657

Epoch: 5| Step: 1
Training loss: 0.758046969292171
Validation loss: 2.337332352662883

Epoch: 5| Step: 2
Training loss: 0.9476364511055375
Validation loss: 2.369008785091144

Epoch: 5| Step: 3
Training loss: 0.7091136635839629
Validation loss: 2.3726502978108863

Epoch: 5| Step: 4
Training loss: 0.5920587596004004
Validation loss: 2.389885770083052

Epoch: 5| Step: 5
Training loss: 0.7479706966963713
Validation loss: 2.383305526555122

Epoch: 5| Step: 6
Training loss: 0.8608682317266912
Validation loss: 2.3716230417813824

Epoch: 5| Step: 7
Training loss: 0.7440014806701939
Validation loss: 2.3966047745468493

Epoch: 5| Step: 8
Training loss: 0.8936965579614241
Validation loss: 2.4089205454311378

Epoch: 5| Step: 9
Training loss: 1.196947761893621
Validation loss: 2.397547370801686

Epoch: 5| Step: 10
Training loss: 0.5166171383447619
Validation loss: 2.3980404190194045

Epoch: 257| Step: 0
Training loss: 0.35719752957604706
Validation loss: 2.408381563812117

Epoch: 5| Step: 1
Training loss: 0.801319443881704
Validation loss: 2.409170563773553

Epoch: 5| Step: 2
Training loss: 1.0740439532856547
Validation loss: 2.397071573684026

Epoch: 5| Step: 3
Training loss: 0.9019969257145867
Validation loss: 2.3846386557238746

Epoch: 5| Step: 4
Training loss: 0.8895706159470299
Validation loss: 2.3529672506588435

Epoch: 5| Step: 5
Training loss: 1.0445729466335145
Validation loss: 2.3580028659676815

Epoch: 5| Step: 6
Training loss: 0.3703455560151059
Validation loss: 2.3371038699069437

Epoch: 5| Step: 7
Training loss: 0.921593671642123
Validation loss: 2.3396808294252516

Epoch: 5| Step: 8
Training loss: 0.646427140482709
Validation loss: 2.3541561888398888

Epoch: 5| Step: 9
Training loss: 0.9070682449090552
Validation loss: 2.333626829387244

Epoch: 5| Step: 10
Training loss: 0.5754803144135574
Validation loss: 2.3304929130370002

Epoch: 258| Step: 0
Training loss: 0.5404538153696601
Validation loss: 2.352156260827715

Epoch: 5| Step: 1
Training loss: 0.9313117832452187
Validation loss: 2.3549131142381476

Epoch: 5| Step: 2
Training loss: 0.6436406311164062
Validation loss: 2.350489989849942

Epoch: 5| Step: 3
Training loss: 0.810932040333974
Validation loss: 2.3520296680902804

Epoch: 5| Step: 4
Training loss: 0.6803638556971325
Validation loss: 2.3474647397859862

Epoch: 5| Step: 5
Training loss: 0.6441992164553757
Validation loss: 2.3153062503820987

Epoch: 5| Step: 6
Training loss: 0.5758887678404613
Validation loss: 2.3585517292856655

Epoch: 5| Step: 7
Training loss: 0.9586497420270288
Validation loss: 2.37774742701316

Epoch: 5| Step: 8
Training loss: 1.1276663865094612
Validation loss: 2.4141259502840593

Epoch: 5| Step: 9
Training loss: 0.8924629921813734
Validation loss: 2.398782754755332

Epoch: 5| Step: 10
Training loss: 0.803509377551236
Validation loss: 2.4181667883392612

Epoch: 259| Step: 0
Training loss: 0.8567413549173498
Validation loss: 2.4017524456404007

Epoch: 5| Step: 1
Training loss: 0.6309482996008312
Validation loss: 2.3764627385444763

Epoch: 5| Step: 2
Training loss: 0.9442679253498516
Validation loss: 2.3815771070569007

Epoch: 5| Step: 3
Training loss: 0.6243679188278101
Validation loss: 2.3681197752309124

Epoch: 5| Step: 4
Training loss: 0.6277797157990053
Validation loss: 2.331873753289366

Epoch: 5| Step: 5
Training loss: 0.931770779457041
Validation loss: 2.3651003012033347

Epoch: 5| Step: 6
Training loss: 0.6913915298532892
Validation loss: 2.350380244896101

Epoch: 5| Step: 7
Training loss: 0.754415982135864
Validation loss: 2.3967902720605756

Epoch: 5| Step: 8
Training loss: 0.9299984259745906
Validation loss: 2.382668282461368

Epoch: 5| Step: 9
Training loss: 0.8279442499944897
Validation loss: 2.411445409449167

Epoch: 5| Step: 10
Training loss: 0.8021743194365099
Validation loss: 2.416399655285477

Epoch: 260| Step: 0
Training loss: 0.9755153993264112
Validation loss: 2.389739955090691

Epoch: 5| Step: 1
Training loss: 0.6960695838372523
Validation loss: 2.385751861810144

Epoch: 5| Step: 2
Training loss: 0.8674251471334669
Validation loss: 2.3644362196035345

Epoch: 5| Step: 3
Training loss: 0.6312061455100496
Validation loss: 2.361371680619446

Epoch: 5| Step: 4
Training loss: 0.8283988571795506
Validation loss: 2.336740062124366

Epoch: 5| Step: 5
Training loss: 0.5484971375386355
Validation loss: 2.3341040114945053

Epoch: 5| Step: 6
Training loss: 0.5150715140345608
Validation loss: 2.3786344185816697

Epoch: 5| Step: 7
Training loss: 1.00996754027602
Validation loss: 2.3727650707887413

Epoch: 5| Step: 8
Training loss: 0.5891086722170628
Validation loss: 2.38257606391727

Epoch: 5| Step: 9
Training loss: 0.8066596890244948
Validation loss: 2.3987945956718395

Epoch: 5| Step: 10
Training loss: 1.0286538361185762
Validation loss: 2.3677422399996524

Epoch: 261| Step: 0
Training loss: 0.4083612674124121
Validation loss: 2.402857702919443

Epoch: 5| Step: 1
Training loss: 0.7713689017492907
Validation loss: 2.406105632736805

Epoch: 5| Step: 2
Training loss: 1.1249736676843123
Validation loss: 2.422188731715241

Epoch: 5| Step: 3
Training loss: 0.8254605019522152
Validation loss: 2.452863209648778

Epoch: 5| Step: 4
Training loss: 0.6001958557186033
Validation loss: 2.4662489896061555

Epoch: 5| Step: 5
Training loss: 0.5773618919815502
Validation loss: 2.4531890879580045

Epoch: 5| Step: 6
Training loss: 0.742517618747352
Validation loss: 2.437669615080555

Epoch: 5| Step: 7
Training loss: 0.8085242347505832
Validation loss: 2.4095061944557545

Epoch: 5| Step: 8
Training loss: 0.6556364097366073
Validation loss: 2.380250543520902

Epoch: 5| Step: 9
Training loss: 0.9857112352845279
Validation loss: 2.3464247521407358

Epoch: 5| Step: 10
Training loss: 0.9455175886651495
Validation loss: 2.3389737263389048

Epoch: 262| Step: 0
Training loss: 0.7203367796010349
Validation loss: 2.2985861730363375

Epoch: 5| Step: 1
Training loss: 0.9424227849359365
Validation loss: 2.3126213376694933

Epoch: 5| Step: 2
Training loss: 0.6017414916641081
Validation loss: 2.3390404092910044

Epoch: 5| Step: 3
Training loss: 0.5107602468182534
Validation loss: 2.341561694444127

Epoch: 5| Step: 4
Training loss: 0.8892810452361105
Validation loss: 2.3575525115505958

Epoch: 5| Step: 5
Training loss: 0.6361937435438523
Validation loss: 2.357300922772813

Epoch: 5| Step: 6
Training loss: 1.0891070319858245
Validation loss: 2.369672972203688

Epoch: 5| Step: 7
Training loss: 0.7716136582611818
Validation loss: 2.339316416378682

Epoch: 5| Step: 8
Training loss: 0.9897711157399938
Validation loss: 2.372722060069882

Epoch: 5| Step: 9
Training loss: 0.49582158530232784
Validation loss: 2.3470225778879965

Epoch: 5| Step: 10
Training loss: 0.6685783549205879
Validation loss: 2.315476118517254

Epoch: 263| Step: 0
Training loss: 0.7111905245057466
Validation loss: 2.325717625885876

Epoch: 5| Step: 1
Training loss: 0.3981234116574976
Validation loss: 2.3355551665470506

Epoch: 5| Step: 2
Training loss: 1.1024467220105587
Validation loss: 2.331757830638212

Epoch: 5| Step: 3
Training loss: 0.7374676050733091
Validation loss: 2.361164369853093

Epoch: 5| Step: 4
Training loss: 0.8151179100234875
Validation loss: 2.379866201279406

Epoch: 5| Step: 5
Training loss: 0.8927482259257905
Validation loss: 2.425272902278047

Epoch: 5| Step: 6
Training loss: 0.8117946350636517
Validation loss: 2.3727097395075383

Epoch: 5| Step: 7
Training loss: 0.5355732260912158
Validation loss: 2.3895312300464573

Epoch: 5| Step: 8
Training loss: 0.8724133200340007
Validation loss: 2.362206658936052

Epoch: 5| Step: 9
Training loss: 0.7636288681993846
Validation loss: 2.3609988595079354

Epoch: 5| Step: 10
Training loss: 0.6365861345041328
Validation loss: 2.3407524065120495

Epoch: 264| Step: 0
Training loss: 0.9620041858260834
Validation loss: 2.340174471501196

Epoch: 5| Step: 1
Training loss: 0.40617977048812853
Validation loss: 2.3610435376841803

Epoch: 5| Step: 2
Training loss: 0.46138387822817867
Validation loss: 2.4139921801550246

Epoch: 5| Step: 3
Training loss: 0.5277946240123494
Validation loss: 2.4194551814883893

Epoch: 5| Step: 4
Training loss: 0.6703626111557551
Validation loss: 2.4538385589086262

Epoch: 5| Step: 5
Training loss: 0.782493441008845
Validation loss: 2.4545576020675934

Epoch: 5| Step: 6
Training loss: 0.6776003746339062
Validation loss: 2.420094894718879

Epoch: 5| Step: 7
Training loss: 1.1085908294273654
Validation loss: 2.4308578257158753

Epoch: 5| Step: 8
Training loss: 0.8927707589459175
Validation loss: 2.3751112092065143

Epoch: 5| Step: 9
Training loss: 0.781815171853435
Validation loss: 2.356629008352719

Epoch: 5| Step: 10
Training loss: 0.8523142934546609
Validation loss: 2.316947182836026

Epoch: 265| Step: 0
Training loss: 1.028898737596851
Validation loss: 2.321274482114252

Epoch: 5| Step: 1
Training loss: 0.6660974178262441
Validation loss: 2.3010483887923043

Epoch: 5| Step: 2
Training loss: 0.31990595348270257
Validation loss: 2.310685947023191

Epoch: 5| Step: 3
Training loss: 0.8917519984606569
Validation loss: 2.3259846561771447

Epoch: 5| Step: 4
Training loss: 0.6034647355336512
Validation loss: 2.3452282636054558

Epoch: 5| Step: 5
Training loss: 0.9295619270724597
Validation loss: 2.364420610684968

Epoch: 5| Step: 6
Training loss: 0.843279495449478
Validation loss: 2.348793088547012

Epoch: 5| Step: 7
Training loss: 0.9011567801148446
Validation loss: 2.352719300786315

Epoch: 5| Step: 8
Training loss: 0.6340752706280395
Validation loss: 2.331056582415226

Epoch: 5| Step: 9
Training loss: 0.44708399853770936
Validation loss: 2.3439250735725494

Epoch: 5| Step: 10
Training loss: 0.7693778335308389
Validation loss: 2.3558264030769203

Epoch: 266| Step: 0
Training loss: 0.8836064777081566
Validation loss: 2.3462659188627164

Epoch: 5| Step: 1
Training loss: 0.68707786951925
Validation loss: 2.34157113251258

Epoch: 5| Step: 2
Training loss: 0.677187718390063
Validation loss: 2.3390461918979315

Epoch: 5| Step: 3
Training loss: 0.5148919124969767
Validation loss: 2.3512746187518467

Epoch: 5| Step: 4
Training loss: 0.8086270680220514
Validation loss: 2.3520531066779355

Epoch: 5| Step: 5
Training loss: 0.5318365225226596
Validation loss: 2.3296862774742544

Epoch: 5| Step: 6
Training loss: 0.9562183586819687
Validation loss: 2.3626838489708977

Epoch: 5| Step: 7
Training loss: 0.7999318898532773
Validation loss: 2.369163162815027

Epoch: 5| Step: 8
Training loss: 0.7133736006417394
Validation loss: 2.387372776209507

Epoch: 5| Step: 9
Training loss: 0.6587447928814599
Validation loss: 2.3496267582178025

Epoch: 5| Step: 10
Training loss: 0.8378315795865918
Validation loss: 2.3721634409117454

Epoch: 267| Step: 0
Training loss: 0.8051419132436085
Validation loss: 2.3751203795766034

Epoch: 5| Step: 1
Training loss: 0.46581247511054563
Validation loss: 2.367579618239792

Epoch: 5| Step: 2
Training loss: 0.6409611634080777
Validation loss: 2.3562869093468413

Epoch: 5| Step: 3
Training loss: 0.5127285901123582
Validation loss: 2.3453861795783735

Epoch: 5| Step: 4
Training loss: 0.7160236647467215
Validation loss: 2.33767565179736

Epoch: 5| Step: 5
Training loss: 0.44797659258701744
Validation loss: 2.327383076914031

Epoch: 5| Step: 6
Training loss: 0.9348792638700578
Validation loss: 2.3593198974494376

Epoch: 5| Step: 7
Training loss: 0.8244509256955869
Validation loss: 2.3842433173944504

Epoch: 5| Step: 8
Training loss: 0.8695808581573057
Validation loss: 2.371493448957379

Epoch: 5| Step: 9
Training loss: 0.7670089513910363
Validation loss: 2.36032714841985

Epoch: 5| Step: 10
Training loss: 0.8473307604306723
Validation loss: 2.350885098183637

Epoch: 268| Step: 0
Training loss: 0.7389719320859404
Validation loss: 2.3574918829719307

Epoch: 5| Step: 1
Training loss: 0.888091918844631
Validation loss: 2.3793334685090475

Epoch: 5| Step: 2
Training loss: 0.7457879523282417
Validation loss: 2.354073795886498

Epoch: 5| Step: 3
Training loss: 0.5070761991305656
Validation loss: 2.343990490788267

Epoch: 5| Step: 4
Training loss: 0.7139738031972297
Validation loss: 2.3564219379990705

Epoch: 5| Step: 5
Training loss: 0.6347082963144328
Validation loss: 2.3530039350229384

Epoch: 5| Step: 6
Training loss: 0.6688148538391027
Validation loss: 2.3689310632642178

Epoch: 5| Step: 7
Training loss: 0.8104833371181013
Validation loss: 2.3703348533646067

Epoch: 5| Step: 8
Training loss: 0.810569707709751
Validation loss: 2.3619728376371567

Epoch: 5| Step: 9
Training loss: 0.5074313567393802
Validation loss: 2.3473389272051084

Epoch: 5| Step: 10
Training loss: 0.7874310311891113
Validation loss: 2.3346489410743465

Epoch: 269| Step: 0
Training loss: 0.7563463559518157
Validation loss: 2.3549942781927373

Epoch: 5| Step: 1
Training loss: 0.4980756863507041
Validation loss: 2.3415896461469377

Epoch: 5| Step: 2
Training loss: 0.7052005650943779
Validation loss: 2.350867126671889

Epoch: 5| Step: 3
Training loss: 0.8405497223002498
Validation loss: 2.371428127200351

Epoch: 5| Step: 4
Training loss: 0.7499120183838016
Validation loss: 2.3709635540940095

Epoch: 5| Step: 5
Training loss: 0.4883012386045385
Validation loss: 2.3325300077186135

Epoch: 5| Step: 6
Training loss: 0.9660158644019177
Validation loss: 2.337772031068897

Epoch: 5| Step: 7
Training loss: 0.8382268200043453
Validation loss: 2.3574260378559537

Epoch: 5| Step: 8
Training loss: 0.6144417879934566
Validation loss: 2.40157802866403

Epoch: 5| Step: 9
Training loss: 0.4591584545111914
Validation loss: 2.36929289391859

Epoch: 5| Step: 10
Training loss: 0.6684993621820275
Validation loss: 2.3693172372536275

Epoch: 270| Step: 0
Training loss: 0.8165638967648811
Validation loss: 2.4174377970653755

Epoch: 5| Step: 1
Training loss: 0.7480743642193339
Validation loss: 2.4134733863993985

Epoch: 5| Step: 2
Training loss: 0.5388621358714178
Validation loss: 2.4198830109718297

Epoch: 5| Step: 3
Training loss: 0.8908318061982052
Validation loss: 2.419468667965558

Epoch: 5| Step: 4
Training loss: 0.833157310174106
Validation loss: 2.4143256247704588

Epoch: 5| Step: 5
Training loss: 0.9405843225345889
Validation loss: 2.3668305320011958

Epoch: 5| Step: 6
Training loss: 0.5856999742357802
Validation loss: 2.35393754209093

Epoch: 5| Step: 7
Training loss: 0.7625773359383924
Validation loss: 2.3530299907066694

Epoch: 5| Step: 8
Training loss: 0.6265455686036697
Validation loss: 2.3415096417812555

Epoch: 5| Step: 9
Training loss: 0.3666204375507615
Validation loss: 2.3928252562683126

Epoch: 5| Step: 10
Training loss: 0.4420483906167666
Validation loss: 2.4065157132732224

Epoch: 271| Step: 0
Training loss: 0.688952731776952
Validation loss: 2.409102699254136

Epoch: 5| Step: 1
Training loss: 0.7726213021084198
Validation loss: 2.417871403184542

Epoch: 5| Step: 2
Training loss: 0.6095299157052494
Validation loss: 2.3946052749535744

Epoch: 5| Step: 3
Training loss: 0.39025907543316246
Validation loss: 2.363290363220635

Epoch: 5| Step: 4
Training loss: 0.8878056255156331
Validation loss: 2.349260311926105

Epoch: 5| Step: 5
Training loss: 0.9521132868611847
Validation loss: 2.3024892705698745

Epoch: 5| Step: 6
Training loss: 0.9540069439453346
Validation loss: 2.268744884984539

Epoch: 5| Step: 7
Training loss: 0.7419006596460636
Validation loss: 2.255509774685502

Epoch: 5| Step: 8
Training loss: 0.7872786801281527
Validation loss: 2.2819694927384706

Epoch: 5| Step: 9
Training loss: 0.5412510659117037
Validation loss: 2.305133056953676

Epoch: 5| Step: 10
Training loss: 0.28645867289898713
Validation loss: 2.3547433757855663

Epoch: 272| Step: 0
Training loss: 0.6912540332890367
Validation loss: 2.416061744326354

Epoch: 5| Step: 1
Training loss: 0.6080589020534691
Validation loss: 2.3935656872607183

Epoch: 5| Step: 2
Training loss: 0.7289647004302877
Validation loss: 2.4112500405734067

Epoch: 5| Step: 3
Training loss: 0.43528483081741204
Validation loss: 2.4076468098907857

Epoch: 5| Step: 4
Training loss: 0.8015463546703352
Validation loss: 2.380706766336035

Epoch: 5| Step: 5
Training loss: 0.6830097210458996
Validation loss: 2.4105305222450677

Epoch: 5| Step: 6
Training loss: 0.9457126117468397
Validation loss: 2.423771021105846

Epoch: 5| Step: 7
Training loss: 0.571454668087759
Validation loss: 2.431019698231975

Epoch: 5| Step: 8
Training loss: 1.071934438675606
Validation loss: 2.4161665769948226

Epoch: 5| Step: 9
Training loss: 0.5234719450136168
Validation loss: 2.4349148632703392

Epoch: 5| Step: 10
Training loss: 0.4394510565815037
Validation loss: 2.3909885763527083

Epoch: 273| Step: 0
Training loss: 0.8129336593653346
Validation loss: 2.3952994198891484

Epoch: 5| Step: 1
Training loss: 0.787827762635982
Validation loss: 2.3930139489154536

Epoch: 5| Step: 2
Training loss: 0.7935379315728452
Validation loss: 2.353507175429538

Epoch: 5| Step: 3
Training loss: 0.5709459627606895
Validation loss: 2.3459886400007024

Epoch: 5| Step: 4
Training loss: 0.6932284164329117
Validation loss: 2.321355376587852

Epoch: 5| Step: 5
Training loss: 0.6199132629065541
Validation loss: 2.330745494347887

Epoch: 5| Step: 6
Training loss: 0.7779932040699784
Validation loss: 2.302242581088788

Epoch: 5| Step: 7
Training loss: 0.5048500803034325
Validation loss: 2.315326613868607

Epoch: 5| Step: 8
Training loss: 0.8026614562094668
Validation loss: 2.3271049361977347

Epoch: 5| Step: 9
Training loss: 0.545494680932928
Validation loss: 2.3521043298170126

Epoch: 5| Step: 10
Training loss: 0.6029679365664153
Validation loss: 2.380144351901623

Epoch: 274| Step: 0
Training loss: 0.8725890937175195
Validation loss: 2.4112767852168338

Epoch: 5| Step: 1
Training loss: 0.7878584787584473
Validation loss: 2.421001141181142

Epoch: 5| Step: 2
Training loss: 0.7790710963491435
Validation loss: 2.4329125362761226

Epoch: 5| Step: 3
Training loss: 0.6633819234086722
Validation loss: 2.4001729910555247

Epoch: 5| Step: 4
Training loss: 0.6968888191597801
Validation loss: 2.391251404413013

Epoch: 5| Step: 5
Training loss: 0.48081415058240934
Validation loss: 2.376115553150277

Epoch: 5| Step: 6
Training loss: 0.4557948873452431
Validation loss: 2.3467871967557734

Epoch: 5| Step: 7
Training loss: 0.6505157991758671
Validation loss: 2.3053471125536915

Epoch: 5| Step: 8
Training loss: 0.49473545022805526
Validation loss: 2.2935115230991068

Epoch: 5| Step: 9
Training loss: 1.0325943247495624
Validation loss: 2.317544404597692

Epoch: 5| Step: 10
Training loss: 0.3391842636648478
Validation loss: 2.3077896311541366

Epoch: 275| Step: 0
Training loss: 0.8182177364166944
Validation loss: 2.3197792014613876

Epoch: 5| Step: 1
Training loss: 0.6977419895572012
Validation loss: 2.3036664861550684

Epoch: 5| Step: 2
Training loss: 0.5310510094400576
Validation loss: 2.347799960446012

Epoch: 5| Step: 3
Training loss: 0.6036604920374627
Validation loss: 2.3521854762516345

Epoch: 5| Step: 4
Training loss: 0.36915196799960526
Validation loss: 2.3823627824196016

Epoch: 5| Step: 5
Training loss: 0.7489475176953889
Validation loss: 2.3616488774668314

Epoch: 5| Step: 6
Training loss: 0.80688454401472
Validation loss: 2.38544557558103

Epoch: 5| Step: 7
Training loss: 0.7263562719884534
Validation loss: 2.390642778798454

Epoch: 5| Step: 8
Training loss: 0.6592943784049677
Validation loss: 2.364352801336651

Epoch: 5| Step: 9
Training loss: 0.6284593451452867
Validation loss: 2.3499967331995584

Epoch: 5| Step: 10
Training loss: 0.7734134554737913
Validation loss: 2.3310836994401662

Epoch: 276| Step: 0
Training loss: 0.5153265580665035
Validation loss: 2.3401773526413856

Epoch: 5| Step: 1
Training loss: 0.6508526693036912
Validation loss: 2.363918448040128

Epoch: 5| Step: 2
Training loss: 0.825960677908156
Validation loss: 2.3652746778140634

Epoch: 5| Step: 3
Training loss: 0.5888417303298384
Validation loss: 2.398715653343126

Epoch: 5| Step: 4
Training loss: 0.9037277375113388
Validation loss: 2.4015786168463835

Epoch: 5| Step: 5
Training loss: 0.5856654234851083
Validation loss: 2.4039304799354775

Epoch: 5| Step: 6
Training loss: 0.5077645499259165
Validation loss: 2.4072370152253892

Epoch: 5| Step: 7
Training loss: 0.5652013657006019
Validation loss: 2.339504099167223

Epoch: 5| Step: 8
Training loss: 0.559523149403489
Validation loss: 2.318386644961063

Epoch: 5| Step: 9
Training loss: 0.9166323734862393
Validation loss: 2.2973549270072597

Epoch: 5| Step: 10
Training loss: 0.6786777845011014
Validation loss: 2.2659814686413116

Epoch: 277| Step: 0
Training loss: 0.7400853150392069
Validation loss: 2.2481699739912697

Epoch: 5| Step: 1
Training loss: 0.6588214720402878
Validation loss: 2.2670749272282893

Epoch: 5| Step: 2
Training loss: 0.7030997801602263
Validation loss: 2.2740530253387403

Epoch: 5| Step: 3
Training loss: 0.8395322355019305
Validation loss: 2.3112819915042673

Epoch: 5| Step: 4
Training loss: 0.2571487117779199
Validation loss: 2.3174912726557015

Epoch: 5| Step: 5
Training loss: 0.7511728176640682
Validation loss: 2.343013753889163

Epoch: 5| Step: 6
Training loss: 0.5727530737152944
Validation loss: 2.37106839558526

Epoch: 5| Step: 7
Training loss: 0.5221215973227881
Validation loss: 2.3500867295695476

Epoch: 5| Step: 8
Training loss: 0.9120778113056132
Validation loss: 2.3899149903683363

Epoch: 5| Step: 9
Training loss: 0.5042270851451122
Validation loss: 2.3461970772616585

Epoch: 5| Step: 10
Training loss: 0.768216748325819
Validation loss: 2.332313782532419

Epoch: 278| Step: 0
Training loss: 0.5927084521096305
Validation loss: 2.3227611382813693

Epoch: 5| Step: 1
Training loss: 0.8424174771516477
Validation loss: 2.3389616642376407

Epoch: 5| Step: 2
Training loss: 0.567541261172875
Validation loss: 2.323792536954416

Epoch: 5| Step: 3
Training loss: 0.7042684158947982
Validation loss: 2.33386901853233

Epoch: 5| Step: 4
Training loss: 0.798774997278242
Validation loss: 2.369295923594325

Epoch: 5| Step: 5
Training loss: 0.8632603293253018
Validation loss: 2.377541117410672

Epoch: 5| Step: 6
Training loss: 0.5918350710990586
Validation loss: 2.371101960663656

Epoch: 5| Step: 7
Training loss: 0.43676542875423136
Validation loss: 2.349090197758437

Epoch: 5| Step: 8
Training loss: 0.5638952435238239
Validation loss: 2.321713113750903

Epoch: 5| Step: 9
Training loss: 0.5736339991202987
Validation loss: 2.2769214088854226

Epoch: 5| Step: 10
Training loss: 0.7726837878435436
Validation loss: 2.2575307582924347

Epoch: 279| Step: 0
Training loss: 0.3346605538848338
Validation loss: 2.2896400660135807

Epoch: 5| Step: 1
Training loss: 0.9424156380900558
Validation loss: 2.2779562317936937

Epoch: 5| Step: 2
Training loss: 0.5224321303937645
Validation loss: 2.2834163128234803

Epoch: 5| Step: 3
Training loss: 0.3475344691059286
Validation loss: 2.3351747707547434

Epoch: 5| Step: 4
Training loss: 0.39364674061918553
Validation loss: 2.3722166149023214

Epoch: 5| Step: 5
Training loss: 0.7419834057116786
Validation loss: 2.401783463138611

Epoch: 5| Step: 6
Training loss: 0.6330238742785668
Validation loss: 2.4408044274615177

Epoch: 5| Step: 7
Training loss: 0.7671107453837995
Validation loss: 2.438412931045554

Epoch: 5| Step: 8
Training loss: 0.8182264415777337
Validation loss: 2.4556655102151095

Epoch: 5| Step: 9
Training loss: 0.7852081737145349
Validation loss: 2.4253671757816173

Epoch: 5| Step: 10
Training loss: 0.7411647375130457
Validation loss: 2.412354978316843

Epoch: 280| Step: 0
Training loss: 0.6257178475672974
Validation loss: 2.3796916813908235

Epoch: 5| Step: 1
Training loss: 0.6355461369130937
Validation loss: 2.3330621569106498

Epoch: 5| Step: 2
Training loss: 0.42070615407832607
Validation loss: 2.3529802531359514

Epoch: 5| Step: 3
Training loss: 0.7791831332691973
Validation loss: 2.359794000892273

Epoch: 5| Step: 4
Training loss: 0.7303064747448778
Validation loss: 2.319457712254844

Epoch: 5| Step: 5
Training loss: 0.7332374202977104
Validation loss: 2.3293261757937724

Epoch: 5| Step: 6
Training loss: 0.31835032959239923
Validation loss: 2.345383588485471

Epoch: 5| Step: 7
Training loss: 0.7650872502405538
Validation loss: 2.334570089076295

Epoch: 5| Step: 8
Training loss: 0.5423260184785127
Validation loss: 2.313003426485736

Epoch: 5| Step: 9
Training loss: 0.6619902422018715
Validation loss: 2.288509481986588

Epoch: 5| Step: 10
Training loss: 0.7600218823695822
Validation loss: 2.3257044125674353

Epoch: 281| Step: 0
Training loss: 0.8921886905054277
Validation loss: 2.3019604594217444

Epoch: 5| Step: 1
Training loss: 0.7368782477594427
Validation loss: 2.315080273527998

Epoch: 5| Step: 2
Training loss: 0.7227866390234688
Validation loss: 2.323905960038323

Epoch: 5| Step: 3
Training loss: 0.542084062367134
Validation loss: 2.3201670140637405

Epoch: 5| Step: 4
Training loss: 0.32538426268220366
Validation loss: 2.296664923377276

Epoch: 5| Step: 5
Training loss: 0.431944968522065
Validation loss: 2.350656717813122

Epoch: 5| Step: 6
Training loss: 0.6466227726155944
Validation loss: 2.354709671155325

Epoch: 5| Step: 7
Training loss: 0.2524023708363269
Validation loss: 2.3631724722498344

Epoch: 5| Step: 8
Training loss: 0.7099055251544218
Validation loss: 2.339558602784589

Epoch: 5| Step: 9
Training loss: 0.617876320351516
Validation loss: 2.3600538820428705

Epoch: 5| Step: 10
Training loss: 0.8909713004934952
Validation loss: 2.3639055924872

Epoch: 282| Step: 0
Training loss: 0.4645606228561998
Validation loss: 2.384885874443299

Epoch: 5| Step: 1
Training loss: 0.5795239199753082
Validation loss: 2.371821399144517

Epoch: 5| Step: 2
Training loss: 0.8424552944671971
Validation loss: 2.3507757926279433

Epoch: 5| Step: 3
Training loss: 0.36354637725897
Validation loss: 2.359839185311106

Epoch: 5| Step: 4
Training loss: 0.6519655513322015
Validation loss: 2.319908586170516

Epoch: 5| Step: 5
Training loss: 0.7348273081545084
Validation loss: 2.322087352911108

Epoch: 5| Step: 6
Training loss: 0.7600863841177913
Validation loss: 2.339300651903837

Epoch: 5| Step: 7
Training loss: 0.6444245914871561
Validation loss: 2.3226581957405137

Epoch: 5| Step: 8
Training loss: 0.7514866162096259
Validation loss: 2.3113198404881965

Epoch: 5| Step: 9
Training loss: 0.3960662854847318
Validation loss: 2.2957537008708226

Epoch: 5| Step: 10
Training loss: 0.5860105341853058
Validation loss: 2.2878108304121683

Epoch: 283| Step: 0
Training loss: 0.6842894147894599
Validation loss: 2.3160714416246204

Epoch: 5| Step: 1
Training loss: 0.47239539143949266
Validation loss: 2.3121396188310728

Epoch: 5| Step: 2
Training loss: 0.7515550228389344
Validation loss: 2.3160565815536724

Epoch: 5| Step: 3
Training loss: 0.18535930790209013
Validation loss: 2.326049481311691

Epoch: 5| Step: 4
Training loss: 0.3950700385737279
Validation loss: 2.2694573487358713

Epoch: 5| Step: 5
Training loss: 0.6479220352277526
Validation loss: 2.292865549952872

Epoch: 5| Step: 6
Training loss: 0.7212204149283941
Validation loss: 2.3185313735202144

Epoch: 5| Step: 7
Training loss: 0.5586968173461959
Validation loss: 2.321348390870196

Epoch: 5| Step: 8
Training loss: 0.7753101374364526
Validation loss: 2.3250113472081098

Epoch: 5| Step: 9
Training loss: 0.6721299818711676
Validation loss: 2.3309276883760757

Epoch: 5| Step: 10
Training loss: 0.7711942489357154
Validation loss: 2.3673910738921307

Epoch: 284| Step: 0
Training loss: 0.5496763957139797
Validation loss: 2.35477032346512

Epoch: 5| Step: 1
Training loss: 0.7029562429725973
Validation loss: 2.3582098396283935

Epoch: 5| Step: 2
Training loss: 0.5321412464320456
Validation loss: 2.364612618917721

Epoch: 5| Step: 3
Training loss: 0.45134870358449214
Validation loss: 2.327707532226982

Epoch: 5| Step: 4
Training loss: 0.9961309987003757
Validation loss: 2.302236261737086

Epoch: 5| Step: 5
Training loss: 0.6679233067095793
Validation loss: 2.291609661776734

Epoch: 5| Step: 6
Training loss: 0.905164594804414
Validation loss: 2.2733408538739193

Epoch: 5| Step: 7
Training loss: 0.37231827530696887
Validation loss: 2.2624326252291906

Epoch: 5| Step: 8
Training loss: 0.39406168726596014
Validation loss: 2.2395351117592948

Epoch: 5| Step: 9
Training loss: 0.6184930152128607
Validation loss: 2.2897405396101305

Epoch: 5| Step: 10
Training loss: 0.260829196656933
Validation loss: 2.318035164538392

Epoch: 285| Step: 0
Training loss: 0.7607640078430532
Validation loss: 2.3705089952420395

Epoch: 5| Step: 1
Training loss: 0.6398625838007906
Validation loss: 2.362504658995839

Epoch: 5| Step: 2
Training loss: 1.0479405801722912
Validation loss: 2.4035584688277503

Epoch: 5| Step: 3
Training loss: 0.4564546713891805
Validation loss: 2.372316272262802

Epoch: 5| Step: 4
Training loss: 0.6555035978563329
Validation loss: 2.377466849593745

Epoch: 5| Step: 5
Training loss: 0.5375525570834617
Validation loss: 2.344541927525094

Epoch: 5| Step: 6
Training loss: 0.3223610823312743
Validation loss: 2.3735875612832023

Epoch: 5| Step: 7
Training loss: 0.6215813120607829
Validation loss: 2.3685847502561677

Epoch: 5| Step: 8
Training loss: 0.49085858488406353
Validation loss: 2.382698594034791

Epoch: 5| Step: 9
Training loss: 0.3271701179266651
Validation loss: 2.3566560546758026

Epoch: 5| Step: 10
Training loss: 0.6815469016100907
Validation loss: 2.38880428776657

Epoch: 286| Step: 0
Training loss: 0.6069085260985647
Validation loss: 2.367985668848581

Epoch: 5| Step: 1
Training loss: 0.5940358327210915
Validation loss: 2.349174544312731

Epoch: 5| Step: 2
Training loss: 0.7722920885505962
Validation loss: 2.3551691668448815

Epoch: 5| Step: 3
Training loss: 0.7084555847659683
Validation loss: 2.332202246823245

Epoch: 5| Step: 4
Training loss: 0.694385682374931
Validation loss: 2.3016494446396227

Epoch: 5| Step: 5
Training loss: 0.7017927900558739
Validation loss: 2.264195560357905

Epoch: 5| Step: 6
Training loss: 0.51324645436879
Validation loss: 2.256130296526158

Epoch: 5| Step: 7
Training loss: 0.5864530456964094
Validation loss: 2.260514227508934

Epoch: 5| Step: 8
Training loss: 0.3472465608596771
Validation loss: 2.2938276205950254

Epoch: 5| Step: 9
Training loss: 0.7159878273254189
Validation loss: 2.3694107573507086

Epoch: 5| Step: 10
Training loss: 0.6142259356016055
Validation loss: 2.375325537382289

Epoch: 287| Step: 0
Training loss: 0.5682109625884354
Validation loss: 2.418329984727716

Epoch: 5| Step: 1
Training loss: 0.6606541398189142
Validation loss: 2.4134814353609624

Epoch: 5| Step: 2
Training loss: 0.6048412886431277
Validation loss: 2.399996065492037

Epoch: 5| Step: 3
Training loss: 0.4777735814922466
Validation loss: 2.418437914036348

Epoch: 5| Step: 4
Training loss: 0.5014117694763731
Validation loss: 2.4060953540966237

Epoch: 5| Step: 5
Training loss: 0.39786746817748625
Validation loss: 2.4011206321729817

Epoch: 5| Step: 6
Training loss: 0.532002757201543
Validation loss: 2.3820649662087576

Epoch: 5| Step: 7
Training loss: 0.5138958344835005
Validation loss: 2.3937434886491573

Epoch: 5| Step: 8
Training loss: 0.6666941835764527
Validation loss: 2.366699807476485

Epoch: 5| Step: 9
Training loss: 0.9181146059428192
Validation loss: 2.3393180533683737

Epoch: 5| Step: 10
Training loss: 0.7967633561857281
Validation loss: 2.3556182105919854

Epoch: 288| Step: 0
Training loss: 0.8428662935203581
Validation loss: 2.376238939651887

Epoch: 5| Step: 1
Training loss: 0.4696099340739815
Validation loss: 2.3514125946399727

Epoch: 5| Step: 2
Training loss: 0.600264349956962
Validation loss: 2.346348365285848

Epoch: 5| Step: 3
Training loss: 0.3842456033823697
Validation loss: 2.392132267782167

Epoch: 5| Step: 4
Training loss: 0.6442825531156985
Validation loss: 2.3944298105885795

Epoch: 5| Step: 5
Training loss: 0.6646695223638215
Validation loss: 2.408033053670069

Epoch: 5| Step: 6
Training loss: 0.7024354732649485
Validation loss: 2.3875429383771807

Epoch: 5| Step: 7
Training loss: 0.7833335178118008
Validation loss: 2.3875367503083127

Epoch: 5| Step: 8
Training loss: 0.5331867480994313
Validation loss: 2.3576910035200545

Epoch: 5| Step: 9
Training loss: 0.5734474035753919
Validation loss: 2.376743285648661

Epoch: 5| Step: 10
Training loss: 0.2139985974151112
Validation loss: 2.3350983370128335

Epoch: 289| Step: 0
Training loss: 0.5716635756181981
Validation loss: 2.3275897609759153

Epoch: 5| Step: 1
Training loss: 0.6344594363690284
Validation loss: 2.372856712309554

Epoch: 5| Step: 2
Training loss: 0.5004654744231914
Validation loss: 2.3599698765245063

Epoch: 5| Step: 3
Training loss: 0.400133636622127
Validation loss: 2.3488992241087843

Epoch: 5| Step: 4
Training loss: 0.6504848973223867
Validation loss: 2.3538155906951017

Epoch: 5| Step: 5
Training loss: 0.474722232665455
Validation loss: 2.3668288753174274

Epoch: 5| Step: 6
Training loss: 0.608681749046632
Validation loss: 2.3489268478409064

Epoch: 5| Step: 7
Training loss: 0.5493648253400258
Validation loss: 2.3705344946076767

Epoch: 5| Step: 8
Training loss: 0.6886948043459427
Validation loss: 2.3678554308850375

Epoch: 5| Step: 9
Training loss: 0.5578891605304022
Validation loss: 2.3345973503220834

Epoch: 5| Step: 10
Training loss: 0.8908553243931552
Validation loss: 2.370931126725696

Epoch: 290| Step: 0
Training loss: 0.6233630917537891
Validation loss: 2.3376224131739645

Epoch: 5| Step: 1
Training loss: 0.7489368532909068
Validation loss: 2.3364180681260747

Epoch: 5| Step: 2
Training loss: 0.3879265467979754
Validation loss: 2.322091060221417

Epoch: 5| Step: 3
Training loss: 0.4068246225440047
Validation loss: 2.304876557735646

Epoch: 5| Step: 4
Training loss: 0.7447195129300983
Validation loss: 2.3419659902521723

Epoch: 5| Step: 5
Training loss: 0.4818875059837837
Validation loss: 2.3216635864431487

Epoch: 5| Step: 6
Training loss: 0.6326349503843185
Validation loss: 2.332178205309087

Epoch: 5| Step: 7
Training loss: 0.45660923767557715
Validation loss: 2.341181606084347

Epoch: 5| Step: 8
Training loss: 0.6307148723625796
Validation loss: 2.3703899686187886

Epoch: 5| Step: 9
Training loss: 0.5809065173066049
Validation loss: 2.354340916997358

Epoch: 5| Step: 10
Training loss: 0.7513165045576677
Validation loss: 2.3452066632465347

Epoch: 291| Step: 0
Training loss: 0.489023940787478
Validation loss: 2.344720844197027

Epoch: 5| Step: 1
Training loss: 0.39106220573839773
Validation loss: 2.321272062348902

Epoch: 5| Step: 2
Training loss: 0.6361275953501137
Validation loss: 2.377805745074995

Epoch: 5| Step: 3
Training loss: 0.6077780461291377
Validation loss: 2.3531278873344124

Epoch: 5| Step: 4
Training loss: 0.58249650831363
Validation loss: 2.3731215323074673

Epoch: 5| Step: 5
Training loss: 0.7040697320735144
Validation loss: 2.3634083058010846

Epoch: 5| Step: 6
Training loss: 0.3415662914145968
Validation loss: 2.383639682425851

Epoch: 5| Step: 7
Training loss: 0.57832673135923
Validation loss: 2.3805806030930086

Epoch: 5| Step: 8
Training loss: 0.6986467589878472
Validation loss: 2.3391075939499877

Epoch: 5| Step: 9
Training loss: 0.6634388631913586
Validation loss: 2.3034539015183735

Epoch: 5| Step: 10
Training loss: 0.6845461069744335
Validation loss: 2.316186765816775

Epoch: 292| Step: 0
Training loss: 0.6290740506001933
Validation loss: 2.3019324925926674

Epoch: 5| Step: 1
Training loss: 0.7144643892179237
Validation loss: 2.306104722832892

Epoch: 5| Step: 2
Training loss: 0.6692415347285323
Validation loss: 2.3037391386871686

Epoch: 5| Step: 3
Training loss: 0.6917845343119657
Validation loss: 2.3009824637836624

Epoch: 5| Step: 4
Training loss: 0.5816635404009091
Validation loss: 2.321436212473684

Epoch: 5| Step: 5
Training loss: 0.34076796296324424
Validation loss: 2.3165054398274694

Epoch: 5| Step: 6
Training loss: 0.7590801608534825
Validation loss: 2.3185108634762175

Epoch: 5| Step: 7
Training loss: 0.47675377493605553
Validation loss: 2.3400284900014228

Epoch: 5| Step: 8
Training loss: 0.49699275342889127
Validation loss: 2.3293157845195482

Epoch: 5| Step: 9
Training loss: 0.6190833657920638
Validation loss: 2.3524745210581606

Epoch: 5| Step: 10
Training loss: 0.1508512625940467
Validation loss: 2.338493201594534

Epoch: 293| Step: 0
Training loss: 0.6961254981750361
Validation loss: 2.3354513378737907

Epoch: 5| Step: 1
Training loss: 0.4759825632924715
Validation loss: 2.325548639223001

Epoch: 5| Step: 2
Training loss: 0.8078798100007955
Validation loss: 2.3308281751951165

Epoch: 5| Step: 3
Training loss: 0.4451036130635522
Validation loss: 2.334887214240263

Epoch: 5| Step: 4
Training loss: 0.4874744310765121
Validation loss: 2.356758960582247

Epoch: 5| Step: 5
Training loss: 0.483992733394441
Validation loss: 2.391272387298495

Epoch: 5| Step: 6
Training loss: 0.6281933742525979
Validation loss: 2.366537415237573

Epoch: 5| Step: 7
Training loss: 0.7075585775085527
Validation loss: 2.3652766255203357

Epoch: 5| Step: 8
Training loss: 0.6022414549810836
Validation loss: 2.3794914460833128

Epoch: 5| Step: 9
Training loss: 0.48794551751307624
Validation loss: 2.4228788467407

Epoch: 5| Step: 10
Training loss: 0.40893166611381543
Validation loss: 2.391363830412088

Epoch: 294| Step: 0
Training loss: 0.7691727398570274
Validation loss: 2.361694598461071

Epoch: 5| Step: 1
Training loss: 0.7355850882386292
Validation loss: 2.3639269216700964

Epoch: 5| Step: 2
Training loss: 0.30416628688414044
Validation loss: 2.3757154048928375

Epoch: 5| Step: 3
Training loss: 0.6591344069010926
Validation loss: 2.33554352036744

Epoch: 5| Step: 4
Training loss: 0.4155920675323826
Validation loss: 2.3290875318427986

Epoch: 5| Step: 5
Training loss: 0.37282835467025216
Validation loss: 2.309339956671844

Epoch: 5| Step: 6
Training loss: 0.48055855756837507
Validation loss: 2.3408399814640437

Epoch: 5| Step: 7
Training loss: 0.477282542973065
Validation loss: 2.3520336562853528

Epoch: 5| Step: 8
Training loss: 0.736479159379488
Validation loss: 2.3498067376656415

Epoch: 5| Step: 9
Training loss: 0.6957105290288258
Validation loss: 2.3449698344005787

Epoch: 5| Step: 10
Training loss: 0.4508525825006007
Validation loss: 2.371231002958559

Epoch: 295| Step: 0
Training loss: 0.5453534621891521
Validation loss: 2.381524373505888

Epoch: 5| Step: 1
Training loss: 0.7349310048475921
Validation loss: 2.3474000823069083

Epoch: 5| Step: 2
Training loss: 0.4537354993473579
Validation loss: 2.3574934679211714

Epoch: 5| Step: 3
Training loss: 0.19962256774304402
Validation loss: 2.3395908765591162

Epoch: 5| Step: 4
Training loss: 0.7284025457334574
Validation loss: 2.3605886085903234

Epoch: 5| Step: 5
Training loss: 0.4961984629017579
Validation loss: 2.360023077035413

Epoch: 5| Step: 6
Training loss: 0.5201149436567082
Validation loss: 2.3201875591894305

Epoch: 5| Step: 7
Training loss: 0.42852928814452484
Validation loss: 2.338236653338082

Epoch: 5| Step: 8
Training loss: 0.7237323893247607
Validation loss: 2.3401894501049956

Epoch: 5| Step: 9
Training loss: 0.6725108442531215
Validation loss: 2.329434351691725

Epoch: 5| Step: 10
Training loss: 0.529363620955527
Validation loss: 2.3288699610846284

Epoch: 296| Step: 0
Training loss: 0.43221083042285563
Validation loss: 2.3206195613620744

Epoch: 5| Step: 1
Training loss: 0.7660620862535341
Validation loss: 2.3374864830655895

Epoch: 5| Step: 2
Training loss: 0.33849845634922693
Validation loss: 2.3464828225034435

Epoch: 5| Step: 3
Training loss: 0.353963368166537
Validation loss: 2.363871501725326

Epoch: 5| Step: 4
Training loss: 0.5112498807090863
Validation loss: 2.3850549714818903

Epoch: 5| Step: 5
Training loss: 0.16974939712893494
Validation loss: 2.398890110652845

Epoch: 5| Step: 6
Training loss: 0.48384471291407616
Validation loss: 2.4099990257082844

Epoch: 5| Step: 7
Training loss: 0.5366797376111093
Validation loss: 2.4120682753595806

Epoch: 5| Step: 8
Training loss: 0.7829335954699264
Validation loss: 2.415210890777313

Epoch: 5| Step: 9
Training loss: 0.9442391410063861
Validation loss: 2.387020909838271

Epoch: 5| Step: 10
Training loss: 0.5187331070504853
Validation loss: 2.36156178596253

Epoch: 297| Step: 0
Training loss: 0.34867087191181656
Validation loss: 2.3512956683664563

Epoch: 5| Step: 1
Training loss: 0.7789934375447347
Validation loss: 2.362155697191695

Epoch: 5| Step: 2
Training loss: 0.7289995319825437
Validation loss: 2.3483378953804324

Epoch: 5| Step: 3
Training loss: 0.44075230457095044
Validation loss: 2.3324921566924384

Epoch: 5| Step: 4
Training loss: 0.3679255919851735
Validation loss: 2.3358177269313165

Epoch: 5| Step: 5
Training loss: 0.6285036113152734
Validation loss: 2.340091769215086

Epoch: 5| Step: 6
Training loss: 0.4965194017493706
Validation loss: 2.3522566411101913

Epoch: 5| Step: 7
Training loss: 0.7406519615319906
Validation loss: 2.3327040699089996

Epoch: 5| Step: 8
Training loss: 0.6042964784883507
Validation loss: 2.3236921709896716

Epoch: 5| Step: 9
Training loss: 0.5304690118039009
Validation loss: 2.3452744883610035

Epoch: 5| Step: 10
Training loss: 0.17501135814796395
Validation loss: 2.331665436356033

Epoch: 298| Step: 0
Training loss: 0.6200014982666863
Validation loss: 2.309720781063353

Epoch: 5| Step: 1
Training loss: 0.7569090973964421
Validation loss: 2.336308559757279

Epoch: 5| Step: 2
Training loss: 0.7271740298464151
Validation loss: 2.3472343113292555

Epoch: 5| Step: 3
Training loss: 0.45650632986650175
Validation loss: 2.3510540869236625

Epoch: 5| Step: 4
Training loss: 0.4889452729785523
Validation loss: 2.3303795575279995

Epoch: 5| Step: 5
Training loss: 0.6776982058677099
Validation loss: 2.336372460379541

Epoch: 5| Step: 6
Training loss: 0.5511920560282337
Validation loss: 2.3157444936081855

Epoch: 5| Step: 7
Training loss: 0.2845793728508628
Validation loss: 2.3222285831202907

Epoch: 5| Step: 8
Training loss: 0.33584865237944317
Validation loss: 2.342096154039867

Epoch: 5| Step: 9
Training loss: 0.5934504958221809
Validation loss: 2.333381548689548

Epoch: 5| Step: 10
Training loss: 0.4028110568048091
Validation loss: 2.3553514852230495

Epoch: 299| Step: 0
Training loss: 0.44117016513142515
Validation loss: 2.354174405309481

Epoch: 5| Step: 1
Training loss: 0.5738756621050978
Validation loss: 2.3499299056814733

Epoch: 5| Step: 2
Training loss: 0.7262421999198948
Validation loss: 2.3351361551263006

Epoch: 5| Step: 3
Training loss: 0.5750651447047516
Validation loss: 2.3350103189023823

Epoch: 5| Step: 4
Training loss: 0.4177682342133931
Validation loss: 2.329132430859084

Epoch: 5| Step: 5
Training loss: 0.5196854785505975
Validation loss: 2.3468725851762664

Epoch: 5| Step: 6
Training loss: 0.5461721808741382
Validation loss: 2.351912886402288

Epoch: 5| Step: 7
Training loss: 0.36993127748489635
Validation loss: 2.3441622266954143

Epoch: 5| Step: 8
Training loss: 0.876161145481736
Validation loss: 2.328288064132345

Epoch: 5| Step: 9
Training loss: 0.3052206754087661
Validation loss: 2.3409302816766036

Epoch: 5| Step: 10
Training loss: 0.503148092604764
Validation loss: 2.33844172032125

Epoch: 300| Step: 0
Training loss: 0.5840535202683153
Validation loss: 2.3574561941457843

Epoch: 5| Step: 1
Training loss: 0.341181151427968
Validation loss: 2.353189017276409

Epoch: 5| Step: 2
Training loss: 0.5494556301433547
Validation loss: 2.3675816317255047

Epoch: 5| Step: 3
Training loss: 0.3690960367713441
Validation loss: 2.3550070256337277

Epoch: 5| Step: 4
Training loss: 0.6961272962644999
Validation loss: 2.342796012851274

Epoch: 5| Step: 5
Training loss: 0.5478686977705476
Validation loss: 2.3697853157709305

Epoch: 5| Step: 6
Training loss: 0.6202101510119197
Validation loss: 2.391971093077036

Epoch: 5| Step: 7
Training loss: 0.5246227566623601
Validation loss: 2.380608028276558

Epoch: 5| Step: 8
Training loss: 0.7267543580430111
Validation loss: 2.363038677450609

Epoch: 5| Step: 9
Training loss: 0.39810282545153086
Validation loss: 2.365065859657401

Epoch: 5| Step: 10
Training loss: 0.6046463333823731
Validation loss: 2.3767402277139142

Epoch: 301| Step: 0
Training loss: 0.17044203714151632
Validation loss: 2.3679791016358385

Epoch: 5| Step: 1
Training loss: 0.642176772350545
Validation loss: 2.3524495974922637

Epoch: 5| Step: 2
Training loss: 0.38097587173134884
Validation loss: 2.3468133083526355

Epoch: 5| Step: 3
Training loss: 0.6466935847847697
Validation loss: 2.357205189720317

Epoch: 5| Step: 4
Training loss: 0.45382560630778435
Validation loss: 2.3370408443638606

Epoch: 5| Step: 5
Training loss: 0.36758557513771406
Validation loss: 2.3283598900342475

Epoch: 5| Step: 6
Training loss: 0.5327534159009771
Validation loss: 2.31151464145137

Epoch: 5| Step: 7
Training loss: 0.6595109121534773
Validation loss: 2.306601365511695

Epoch: 5| Step: 8
Training loss: 0.7875305260690926
Validation loss: 2.321293197936626

Epoch: 5| Step: 9
Training loss: 0.741467578469804
Validation loss: 2.325106033022652

Epoch: 5| Step: 10
Training loss: 0.28434351495267096
Validation loss: 2.342225171186372

Epoch: 302| Step: 0
Training loss: 0.4157546930960037
Validation loss: 2.3800931893581025

Epoch: 5| Step: 1
Training loss: 0.42785862202437563
Validation loss: 2.3798808056513883

Epoch: 5| Step: 2
Training loss: 0.6478994044205039
Validation loss: 2.3784275168295954

Epoch: 5| Step: 3
Training loss: 0.6824236637784227
Validation loss: 2.341609852226813

Epoch: 5| Step: 4
Training loss: 0.7854190215894234
Validation loss: 2.2988078094108046

Epoch: 5| Step: 5
Training loss: 0.44707144974163526
Validation loss: 2.307367960276525

Epoch: 5| Step: 6
Training loss: 0.6056698864973885
Validation loss: 2.2853504082648683

Epoch: 5| Step: 7
Training loss: 0.4592644506547238
Validation loss: 2.2976274204579026

Epoch: 5| Step: 8
Training loss: 0.6248720514937979
Validation loss: 2.306129122874257

Epoch: 5| Step: 9
Training loss: 0.4250602917820677
Validation loss: 2.2897114460844765

Epoch: 5| Step: 10
Training loss: 0.3851134572427394
Validation loss: 2.287111151919715

Epoch: 303| Step: 0
Training loss: 0.4613516288797198
Validation loss: 2.270946761391067

Epoch: 5| Step: 1
Training loss: 0.3584348987461676
Validation loss: 2.309391306844916

Epoch: 5| Step: 2
Training loss: 0.5695308659137535
Validation loss: 2.324665208490166

Epoch: 5| Step: 3
Training loss: 0.5754507433528608
Validation loss: 2.348684153894159

Epoch: 5| Step: 4
Training loss: 0.7139778521091952
Validation loss: 2.3719486459737293

Epoch: 5| Step: 5
Training loss: 0.4093188684142531
Validation loss: 2.3929586048140226

Epoch: 5| Step: 6
Training loss: 0.6272465147147384
Validation loss: 2.377226014640137

Epoch: 5| Step: 7
Training loss: 0.7398370164445963
Validation loss: 2.3864744336028747

Epoch: 5| Step: 8
Training loss: 0.5748574733314374
Validation loss: 2.3904785496373795

Epoch: 5| Step: 9
Training loss: 0.28259548902751647
Validation loss: 2.39337099580692

Epoch: 5| Step: 10
Training loss: 0.5076327666078577
Validation loss: 2.357056863565073

Epoch: 304| Step: 0
Training loss: 0.5789979581483933
Validation loss: 2.3547498830164875

Epoch: 5| Step: 1
Training loss: 0.42960845913870044
Validation loss: 2.33463925156107

Epoch: 5| Step: 2
Training loss: 0.4941809566156755
Validation loss: 2.321690688400929

Epoch: 5| Step: 3
Training loss: 0.43219703956165567
Validation loss: 2.343522030808133

Epoch: 5| Step: 4
Training loss: 0.5927907573551493
Validation loss: 2.342806195515902

Epoch: 5| Step: 5
Training loss: 0.4255507834114785
Validation loss: 2.372870320481875

Epoch: 5| Step: 6
Training loss: 0.5754617744165961
Validation loss: 2.338117450882477

Epoch: 5| Step: 7
Training loss: 0.8123539646663572
Validation loss: 2.3542496507505644

Epoch: 5| Step: 8
Training loss: 0.36209205083957846
Validation loss: 2.3601406577018325

Epoch: 5| Step: 9
Training loss: 0.6077206726137963
Validation loss: 2.354061304758924

Epoch: 5| Step: 10
Training loss: 0.5526931531652168
Validation loss: 2.3754404174527446

Epoch: 305| Step: 0
Training loss: 0.4516624821783438
Validation loss: 2.393114102308187

Epoch: 5| Step: 1
Training loss: 0.5863213362735996
Validation loss: 2.3872919441792573

Epoch: 5| Step: 2
Training loss: 0.39928003128222844
Validation loss: 2.3702747237130026

Epoch: 5| Step: 3
Training loss: 0.625942163816647
Validation loss: 2.396590267273936

Epoch: 5| Step: 4
Training loss: 0.5058485935785497
Validation loss: 2.40264258758265

Epoch: 5| Step: 5
Training loss: 0.3091324317661968
Validation loss: 2.4089504399415924

Epoch: 5| Step: 6
Training loss: 0.46127413725306843
Validation loss: 2.4330584602452303

Epoch: 5| Step: 7
Training loss: 0.7580406396132313
Validation loss: 2.4098159662304512

Epoch: 5| Step: 8
Training loss: 0.7280788390626445
Validation loss: 2.408627734041757

Epoch: 5| Step: 9
Training loss: 0.46410140699671837
Validation loss: 2.411196368585399

Epoch: 5| Step: 10
Training loss: 0.5860222818708266
Validation loss: 2.38298813286751

Epoch: 306| Step: 0
Training loss: 0.526082374080414
Validation loss: 2.3421868638914076

Epoch: 5| Step: 1
Training loss: 0.5289234660064036
Validation loss: 2.321673288150017

Epoch: 5| Step: 2
Training loss: 0.6808849397763311
Validation loss: 2.329498027088348

Epoch: 5| Step: 3
Training loss: 0.4593672758218559
Validation loss: 2.326531274836221

Epoch: 5| Step: 4
Training loss: 0.5185696874485713
Validation loss: 2.329412309929728

Epoch: 5| Step: 5
Training loss: 0.42978838689899124
Validation loss: 2.3334148807676005

Epoch: 5| Step: 6
Training loss: 0.46116521027570206
Validation loss: 2.3485478543047438

Epoch: 5| Step: 7
Training loss: 0.5225118166668755
Validation loss: 2.357381595617799

Epoch: 5| Step: 8
Training loss: 0.3920998387945185
Validation loss: 2.3498374000383446

Epoch: 5| Step: 9
Training loss: 0.7032982506823416
Validation loss: 2.3489544570600196

Epoch: 5| Step: 10
Training loss: 0.7701087372655091
Validation loss: 2.35241203755398

Epoch: 307| Step: 0
Training loss: 0.4768184068578696
Validation loss: 2.344560986290533

Epoch: 5| Step: 1
Training loss: 0.2934294448047543
Validation loss: 2.389476554557908

Epoch: 5| Step: 2
Training loss: 0.3356687446586425
Validation loss: 2.337059832118148

Epoch: 5| Step: 3
Training loss: 0.4295307220200409
Validation loss: 2.325618812707199

Epoch: 5| Step: 4
Training loss: 0.785951922911915
Validation loss: 2.359080449932676

Epoch: 5| Step: 5
Training loss: 0.6017153161881307
Validation loss: 2.382383786559419

Epoch: 5| Step: 6
Training loss: 0.6302606440079976
Validation loss: 2.395771814085259

Epoch: 5| Step: 7
Training loss: 0.49710132374734
Validation loss: 2.393179211897498

Epoch: 5| Step: 8
Training loss: 0.4611378089023364
Validation loss: 2.385801305164303

Epoch: 5| Step: 9
Training loss: 0.6069862790921505
Validation loss: 2.3626267353543082

Epoch: 5| Step: 10
Training loss: 0.7100107629390046
Validation loss: 2.382702061786766

Epoch: 308| Step: 0
Training loss: 0.49352370641558263
Validation loss: 2.336069926753619

Epoch: 5| Step: 1
Training loss: 0.3592157840481869
Validation loss: 2.351059163922094

Epoch: 5| Step: 2
Training loss: 0.38096865528935664
Validation loss: 2.3832996232930035

Epoch: 5| Step: 3
Training loss: 0.4900306034992479
Validation loss: 2.404549186043408

Epoch: 5| Step: 4
Training loss: 0.5194513072984492
Validation loss: 2.4175382742478853

Epoch: 5| Step: 5
Training loss: 0.42737501542614903
Validation loss: 2.425209476188265

Epoch: 5| Step: 6
Training loss: 0.4487170195613575
Validation loss: 2.4414102266012643

Epoch: 5| Step: 7
Training loss: 0.6843931483122523
Validation loss: 2.420617879576726

Epoch: 5| Step: 8
Training loss: 0.6950293832509193
Validation loss: 2.4126207439104075

Epoch: 5| Step: 9
Training loss: 0.6021422775304875
Validation loss: 2.386185483249252

Epoch: 5| Step: 10
Training loss: 0.7402160561743225
Validation loss: 2.3758172532676545

Epoch: 309| Step: 0
Training loss: 0.6007518508126986
Validation loss: 2.3890302114600415

Epoch: 5| Step: 1
Training loss: 0.3031033390210499
Validation loss: 2.3474619817133653

Epoch: 5| Step: 2
Training loss: 0.6464442906241097
Validation loss: 2.300183853123809

Epoch: 5| Step: 3
Training loss: 0.35211043573308193
Validation loss: 2.317238528309808

Epoch: 5| Step: 4
Training loss: 0.4131073822154639
Validation loss: 2.3206570442936694

Epoch: 5| Step: 5
Training loss: 0.7430733864765087
Validation loss: 2.3545625487909274

Epoch: 5| Step: 6
Training loss: 0.5506076945119527
Validation loss: 2.3460412281748657

Epoch: 5| Step: 7
Training loss: 0.6950121241479398
Validation loss: 2.3917275361606833

Epoch: 5| Step: 8
Training loss: 0.5725310819842255
Validation loss: 2.383393185265093

Epoch: 5| Step: 9
Training loss: 0.3152441654315803
Validation loss: 2.390634968754472

Epoch: 5| Step: 10
Training loss: 0.38271826927246444
Validation loss: 2.4258640164153604

Epoch: 310| Step: 0
Training loss: 0.7441940488686543
Validation loss: 2.3852602705945802

Epoch: 5| Step: 1
Training loss: 0.2885563904601118
Validation loss: 2.4023210176449

Epoch: 5| Step: 2
Training loss: 0.3582699828740692
Validation loss: 2.405008436545559

Epoch: 5| Step: 3
Training loss: 0.47697883930293644
Validation loss: 2.382330971862729

Epoch: 5| Step: 4
Training loss: 0.4007940353525551
Validation loss: 2.3435303309600495

Epoch: 5| Step: 5
Training loss: 0.41308388134600194
Validation loss: 2.325639194200786

Epoch: 5| Step: 6
Training loss: 0.6837222605209372
Validation loss: 2.333254877286196

Epoch: 5| Step: 7
Training loss: 0.553411601325973
Validation loss: 2.3348728812706154

Epoch: 5| Step: 8
Training loss: 0.7418273453483291
Validation loss: 2.3295156258602243

Epoch: 5| Step: 9
Training loss: 0.4943104026345751
Validation loss: 2.3230132194136797

Epoch: 5| Step: 10
Training loss: 0.40434167217543615
Validation loss: 2.3156891671094013

Epoch: 311| Step: 0
Training loss: 0.6571962709517275
Validation loss: 2.312215847183126

Epoch: 5| Step: 1
Training loss: 0.45097533399729306
Validation loss: 2.313980604121539

Epoch: 5| Step: 2
Training loss: 0.4818581441857801
Validation loss: 2.333944418831988

Epoch: 5| Step: 3
Training loss: 0.3017016114672044
Validation loss: 2.3433593632285348

Epoch: 5| Step: 4
Training loss: 0.5014395257042843
Validation loss: 2.368707834746703

Epoch: 5| Step: 5
Training loss: 0.5070007291521476
Validation loss: 2.414994057380704

Epoch: 5| Step: 6
Training loss: 0.503894598774428
Validation loss: 2.4158799944980185

Epoch: 5| Step: 7
Training loss: 0.4898884225093247
Validation loss: 2.3955006310012874

Epoch: 5| Step: 8
Training loss: 0.6478819938001026
Validation loss: 2.3824235291694835

Epoch: 5| Step: 9
Training loss: 0.6098513086638797
Validation loss: 2.3905678558007746

Epoch: 5| Step: 10
Training loss: 0.469419414638632
Validation loss: 2.395896266272995

Epoch: 312| Step: 0
Training loss: 0.6137754308011888
Validation loss: 2.367364279620618

Epoch: 5| Step: 1
Training loss: 0.3772089984143087
Validation loss: 2.3379118450117846

Epoch: 5| Step: 2
Training loss: 0.7287509323428227
Validation loss: 2.333787488431242

Epoch: 5| Step: 3
Training loss: 0.5512154943777812
Validation loss: 2.3291781457020875

Epoch: 5| Step: 4
Training loss: 0.45169697379499796
Validation loss: 2.327070555845258

Epoch: 5| Step: 5
Training loss: 0.6666729723115576
Validation loss: 2.331966103039408

Epoch: 5| Step: 6
Training loss: 0.21879617169705817
Validation loss: 2.3776701261530415

Epoch: 5| Step: 7
Training loss: 0.44568396016406797
Validation loss: 2.333076766919673

Epoch: 5| Step: 8
Training loss: 0.5550843820346757
Validation loss: 2.3660299489169607

Epoch: 5| Step: 9
Training loss: 0.3779925705593379
Validation loss: 2.368768392165644

Epoch: 5| Step: 10
Training loss: 0.48835363233036994
Validation loss: 2.3647262409352185

Epoch: 313| Step: 0
Training loss: 0.4704488645295614
Validation loss: 2.3337766787220358

Epoch: 5| Step: 1
Training loss: 0.40792744284602833
Validation loss: 2.343268757023283

Epoch: 5| Step: 2
Training loss: 0.3956601073370281
Validation loss: 2.350267802212572

Epoch: 5| Step: 3
Training loss: 0.5225082803827538
Validation loss: 2.3439388251039106

Epoch: 5| Step: 4
Training loss: 0.5863488851248271
Validation loss: 2.3394052784676926

Epoch: 5| Step: 5
Training loss: 0.7791473321674751
Validation loss: 2.350333755699212

Epoch: 5| Step: 6
Training loss: 0.5498741742904232
Validation loss: 2.3656934703785537

Epoch: 5| Step: 7
Training loss: 0.5811298738448776
Validation loss: 2.3854226961627023

Epoch: 5| Step: 8
Training loss: 0.500588487967648
Validation loss: 2.3826778584296107

Epoch: 5| Step: 9
Training loss: 0.2598702356324706
Validation loss: 2.4299258679124596

Epoch: 5| Step: 10
Training loss: 0.25552557508659385
Validation loss: 2.4191025758301548

Epoch: 314| Step: 0
Training loss: 0.6547136715776731
Validation loss: 2.399427198988538

Epoch: 5| Step: 1
Training loss: 0.1900981168350414
Validation loss: 2.4473621105930174

Epoch: 5| Step: 2
Training loss: 0.46074095269426224
Validation loss: 2.4323735858472544

Epoch: 5| Step: 3
Training loss: 0.4747034301495663
Validation loss: 2.4048041741178365

Epoch: 5| Step: 4
Training loss: 0.5069618730147394
Validation loss: 2.3770549068617184

Epoch: 5| Step: 5
Training loss: 0.5015153571579548
Validation loss: 2.364449258219338

Epoch: 5| Step: 6
Training loss: 0.6483809894618277
Validation loss: 2.3650313612430742

Epoch: 5| Step: 7
Training loss: 0.4691282653451006
Validation loss: 2.365602984573658

Epoch: 5| Step: 8
Training loss: 0.4568844257796625
Validation loss: 2.3574831393614417

Epoch: 5| Step: 9
Training loss: 0.4396581383494512
Validation loss: 2.3606337761707348

Epoch: 5| Step: 10
Training loss: 0.5902094938637307
Validation loss: 2.3745510236083347

Epoch: 315| Step: 0
Training loss: 0.32442592987273566
Validation loss: 2.3701217823508034

Epoch: 5| Step: 1
Training loss: 0.3380867934367663
Validation loss: 2.3728834953396287

Epoch: 5| Step: 2
Training loss: 0.4955775962471002
Validation loss: 2.360179781796192

Epoch: 5| Step: 3
Training loss: 0.4512223714998475
Validation loss: 2.36578493503533

Epoch: 5| Step: 4
Training loss: 0.6319878467797664
Validation loss: 2.4000854538501626

Epoch: 5| Step: 5
Training loss: 0.4105472698990132
Validation loss: 2.399697944217946

Epoch: 5| Step: 6
Training loss: 0.5351409909933961
Validation loss: 2.36672101019804

Epoch: 5| Step: 7
Training loss: 0.7205567663598098
Validation loss: 2.4296378819187194

Epoch: 5| Step: 8
Training loss: 0.7109842389850668
Validation loss: 2.384984088742385

Epoch: 5| Step: 9
Training loss: 0.4353022551306602
Validation loss: 2.4208345547449683

Epoch: 5| Step: 10
Training loss: 0.3238770166170152
Validation loss: 2.3989183663277966

Epoch: 316| Step: 0
Training loss: 0.5933559013300179
Validation loss: 2.4324300672641637

Epoch: 5| Step: 1
Training loss: 0.567592641142052
Validation loss: 2.3718389595027367

Epoch: 5| Step: 2
Training loss: 0.3735689434652917
Validation loss: 2.405103865706922

Epoch: 5| Step: 3
Training loss: 0.31565656268114994
Validation loss: 2.391919711915937

Epoch: 5| Step: 4
Training loss: 0.5060710979408286
Validation loss: 2.369422954411269

Epoch: 5| Step: 5
Training loss: 0.5572025608117546
Validation loss: 2.376252975641958

Epoch: 5| Step: 6
Training loss: 0.523853620553037
Validation loss: 2.3505826377694676

Epoch: 5| Step: 7
Training loss: 0.3837889460206765
Validation loss: 2.3591932500973822

Epoch: 5| Step: 8
Training loss: 0.5870377700601973
Validation loss: 2.373268560623937

Epoch: 5| Step: 9
Training loss: 0.5183675252220513
Validation loss: 2.3349811120101664

Epoch: 5| Step: 10
Training loss: 0.4692429017346576
Validation loss: 2.3853651822961863

Epoch: 317| Step: 0
Training loss: 0.5843098731647511
Validation loss: 2.3570380853028388

Epoch: 5| Step: 1
Training loss: 0.6155235216571923
Validation loss: 2.375367154042985

Epoch: 5| Step: 2
Training loss: 0.6274527582113882
Validation loss: 2.366007458186608

Epoch: 5| Step: 3
Training loss: 0.47683742285148906
Validation loss: 2.3592761374263675

Epoch: 5| Step: 4
Training loss: 0.21286824309959237
Validation loss: 2.3752493066337874

Epoch: 5| Step: 5
Training loss: 0.6248600326213737
Validation loss: 2.3640947992358123

Epoch: 5| Step: 6
Training loss: 0.3228343453636777
Validation loss: 2.365886176079828

Epoch: 5| Step: 7
Training loss: 0.42132330955556024
Validation loss: 2.371206413306658

Epoch: 5| Step: 8
Training loss: 0.27107930323558926
Validation loss: 2.3900452925087676

Epoch: 5| Step: 9
Training loss: 0.5623190641801276
Validation loss: 2.40143993632651

Epoch: 5| Step: 10
Training loss: 0.5352384685091995
Validation loss: 2.3712720373994407

Epoch: 318| Step: 0
Training loss: 0.586298208470985
Validation loss: 2.3803691077759153

Epoch: 5| Step: 1
Training loss: 0.3736714432363151
Validation loss: 2.39613412375097

Epoch: 5| Step: 2
Training loss: 0.5381146265817791
Validation loss: 2.3896402894881352

Epoch: 5| Step: 3
Training loss: 0.3079080931851192
Validation loss: 2.3899564291405113

Epoch: 5| Step: 4
Training loss: 0.443271880402102
Validation loss: 2.402225297578232

Epoch: 5| Step: 5
Training loss: 0.5188299335803778
Validation loss: 2.3916960291649882

Epoch: 5| Step: 6
Training loss: 0.6600075503480962
Validation loss: 2.3820044772255518

Epoch: 5| Step: 7
Training loss: 0.47626628424871453
Validation loss: 2.3191769430329257

Epoch: 5| Step: 8
Training loss: 0.3560388834632288
Validation loss: 2.3240672618388065

Epoch: 5| Step: 9
Training loss: 0.4253388827883921
Validation loss: 2.315154438162084

Epoch: 5| Step: 10
Training loss: 0.6043336873101687
Validation loss: 2.3286077538858625

Epoch: 319| Step: 0
Training loss: 0.15898739720501753
Validation loss: 2.3183383392806953

Epoch: 5| Step: 1
Training loss: 0.16875788043306744
Validation loss: 2.3366925286285825

Epoch: 5| Step: 2
Training loss: 0.5371447742240981
Validation loss: 2.340792409108585

Epoch: 5| Step: 3
Training loss: 0.47952226905703393
Validation loss: 2.373401488176668

Epoch: 5| Step: 4
Training loss: 0.4966684451914099
Validation loss: 2.360900887482957

Epoch: 5| Step: 5
Training loss: 0.376389868329515
Validation loss: 2.3718134266027757

Epoch: 5| Step: 6
Training loss: 0.7079447119645127
Validation loss: 2.3794622453990244

Epoch: 5| Step: 7
Training loss: 0.3466693393076215
Validation loss: 2.394697111620748

Epoch: 5| Step: 8
Training loss: 0.49402344109541324
Validation loss: 2.3990081939731387

Epoch: 5| Step: 9
Training loss: 0.47340577966665565
Validation loss: 2.388227386045926

Epoch: 5| Step: 10
Training loss: 0.7696761174043711
Validation loss: 2.3523946651100296

Epoch: 320| Step: 0
Training loss: 0.36115669101398684
Validation loss: 2.3646042751353264

Epoch: 5| Step: 1
Training loss: 0.18895560742262257
Validation loss: 2.371749436689018

Epoch: 5| Step: 2
Training loss: 0.6750979855731264
Validation loss: 2.380580742012746

Epoch: 5| Step: 3
Training loss: 0.667272617708544
Validation loss: 2.355170351694857

Epoch: 5| Step: 4
Training loss: 0.41550213281196535
Validation loss: 2.3384354439782453

Epoch: 5| Step: 5
Training loss: 0.3514868972867574
Validation loss: 2.3561862791472614

Epoch: 5| Step: 6
Training loss: 0.3703822895070415
Validation loss: 2.3667490720448328

Epoch: 5| Step: 7
Training loss: 0.4582824859446401
Validation loss: 2.364865800658048

Epoch: 5| Step: 8
Training loss: 0.5034153639451282
Validation loss: 2.3347762900885245

Epoch: 5| Step: 9
Training loss: 0.4032073890417695
Validation loss: 2.335271962413576

Epoch: 5| Step: 10
Training loss: 0.6891112520094463
Validation loss: 2.3239996865025407

Epoch: 321| Step: 0
Training loss: 0.5367279640528492
Validation loss: 2.3062378843998426

Epoch: 5| Step: 1
Training loss: 0.4344600580489203
Validation loss: 2.325974423567936

Epoch: 5| Step: 2
Training loss: 0.5986112307567826
Validation loss: 2.33324030739796

Epoch: 5| Step: 3
Training loss: 0.5135021436956692
Validation loss: 2.3557920795044223

Epoch: 5| Step: 4
Training loss: 0.6954570577131829
Validation loss: 2.3685058179358025

Epoch: 5| Step: 5
Training loss: 0.2806895154907398
Validation loss: 2.394256866750626

Epoch: 5| Step: 6
Training loss: 0.36235590981382726
Validation loss: 2.3711139981976963

Epoch: 5| Step: 7
Training loss: 0.39043316899207714
Validation loss: 2.3939248086442126

Epoch: 5| Step: 8
Training loss: 0.49102153122049924
Validation loss: 2.4149792550608113

Epoch: 5| Step: 9
Training loss: 0.37028483516835375
Validation loss: 2.4284811700693827

Epoch: 5| Step: 10
Training loss: 0.5092943724494561
Validation loss: 2.3941130858911612

Epoch: 322| Step: 0
Training loss: 0.6682659402680781
Validation loss: 2.3766038074622293

Epoch: 5| Step: 1
Training loss: 0.5748037614986674
Validation loss: 2.334160890553589

Epoch: 5| Step: 2
Training loss: 0.5239639766027714
Validation loss: 2.3420790099237534

Epoch: 5| Step: 3
Training loss: 0.30682107754667004
Validation loss: 2.314089090242254

Epoch: 5| Step: 4
Training loss: 0.4009207031168648
Validation loss: 2.3015816728026293

Epoch: 5| Step: 5
Training loss: 0.2143820917719265
Validation loss: 2.305838154268017

Epoch: 5| Step: 6
Training loss: 0.3272406149291437
Validation loss: 2.3434033351461823

Epoch: 5| Step: 7
Training loss: 0.5070251817149084
Validation loss: 2.3262044590360227

Epoch: 5| Step: 8
Training loss: 0.6449850161238806
Validation loss: 2.346897185099116

Epoch: 5| Step: 9
Training loss: 0.3675414874864162
Validation loss: 2.368725260173184

Epoch: 5| Step: 10
Training loss: 0.5142234480720606
Validation loss: 2.3774400610464594

Epoch: 323| Step: 0
Training loss: 0.4206146203810876
Validation loss: 2.357014809403809

Epoch: 5| Step: 1
Training loss: 0.4887597295519518
Validation loss: 2.365003890927307

Epoch: 5| Step: 2
Training loss: 0.6071170643128191
Validation loss: 2.386001345097105

Epoch: 5| Step: 3
Training loss: 0.5275060615824048
Validation loss: 2.3740748366749633

Epoch: 5| Step: 4
Training loss: 0.48500802606155274
Validation loss: 2.3675548921274574

Epoch: 5| Step: 5
Training loss: 0.67114690763285
Validation loss: 2.3440540786429302

Epoch: 5| Step: 6
Training loss: 0.2845215199884406
Validation loss: 2.325042149133812

Epoch: 5| Step: 7
Training loss: 0.566310611411426
Validation loss: 2.3133881993637706

Epoch: 5| Step: 8
Training loss: 0.4376029166016328
Validation loss: 2.2838999547353454

Epoch: 5| Step: 9
Training loss: 0.3270324729244078
Validation loss: 2.2780703620902893

Epoch: 5| Step: 10
Training loss: 0.5255461678826963
Validation loss: 2.289435091220646

Epoch: 324| Step: 0
Training loss: 0.43660269408170244
Validation loss: 2.3126878825598007

Epoch: 5| Step: 1
Training loss: 0.41616191888626036
Validation loss: 2.3536356879723836

Epoch: 5| Step: 2
Training loss: 0.28169630984251365
Validation loss: 2.3712143727531982

Epoch: 5| Step: 3
Training loss: 0.6831916280294926
Validation loss: 2.3637985706031546

Epoch: 5| Step: 4
Training loss: 0.3699952178723366
Validation loss: 2.4008547115503505

Epoch: 5| Step: 5
Training loss: 0.5174452701136796
Validation loss: 2.393348523138396

Epoch: 5| Step: 6
Training loss: 0.5604424462421871
Validation loss: 2.402304025330422

Epoch: 5| Step: 7
Training loss: 0.6790129723636976
Validation loss: 2.373667877707228

Epoch: 5| Step: 8
Training loss: 0.22016396114417017
Validation loss: 2.3772070937408736

Epoch: 5| Step: 9
Training loss: 0.5266732368280742
Validation loss: 2.396388303050513

Epoch: 5| Step: 10
Training loss: 0.3664208992833692
Validation loss: 2.3725598034124156

Epoch: 325| Step: 0
Training loss: 0.35512511442881495
Validation loss: 2.355969536809914

Epoch: 5| Step: 1
Training loss: 0.6713519832988913
Validation loss: 2.3744666132602874

Epoch: 5| Step: 2
Training loss: 0.4882198752931315
Validation loss: 2.3724115295384394

Epoch: 5| Step: 3
Training loss: 0.4123473361756673
Validation loss: 2.36701881773987

Epoch: 5| Step: 4
Training loss: 0.5472466976751001
Validation loss: 2.3346177300243403

Epoch: 5| Step: 5
Training loss: 0.48234024592771246
Validation loss: 2.330518370075391

Epoch: 5| Step: 6
Training loss: 0.46474741089680904
Validation loss: 2.3307478723802544

Epoch: 5| Step: 7
Training loss: 0.41101815625157956
Validation loss: 2.338167260110951

Epoch: 5| Step: 8
Training loss: 0.5181855290377375
Validation loss: 2.3631487414721892

Epoch: 5| Step: 9
Training loss: 0.28341183042526646
Validation loss: 2.3717788285308132

Epoch: 5| Step: 10
Training loss: 0.5361752797246144
Validation loss: 2.4127474105037523

Epoch: 326| Step: 0
Training loss: 0.4880062244254786
Validation loss: 2.383224374781892

Epoch: 5| Step: 1
Training loss: 0.6076631710710843
Validation loss: 2.4759108363831164

Epoch: 5| Step: 2
Training loss: 0.34944546442741325
Validation loss: 2.4570699338833086

Epoch: 5| Step: 3
Training loss: 0.271694417700882
Validation loss: 2.465674943565118

Epoch: 5| Step: 4
Training loss: 0.6095799566041981
Validation loss: 2.4632142863241686

Epoch: 5| Step: 5
Training loss: 0.33720748949944995
Validation loss: 2.458732681694298

Epoch: 5| Step: 6
Training loss: 0.4765303554012435
Validation loss: 2.3703709358310934

Epoch: 5| Step: 7
Training loss: 0.5685458319867751
Validation loss: 2.3479546768176744

Epoch: 5| Step: 8
Training loss: 0.5495380954570958
Validation loss: 2.3269239511227395

Epoch: 5| Step: 9
Training loss: 0.2657201119847516
Validation loss: 2.2902794201207293

Epoch: 5| Step: 10
Training loss: 0.567214967256994
Validation loss: 2.3224715828177827

Epoch: 327| Step: 0
Training loss: 0.5204392722630942
Validation loss: 2.27438731020116

Epoch: 5| Step: 1
Training loss: 0.306021642696375
Validation loss: 2.3142875645747436

Epoch: 5| Step: 2
Training loss: 0.42841980940051866
Validation loss: 2.360172147115817

Epoch: 5| Step: 3
Training loss: 0.46882221937154905
Validation loss: 2.366700178206197

Epoch: 5| Step: 4
Training loss: 0.481912985441271
Validation loss: 2.422457966950086

Epoch: 5| Step: 5
Training loss: 0.5597836818298321
Validation loss: 2.4325138689787003

Epoch: 5| Step: 6
Training loss: 0.5694939997543658
Validation loss: 2.4420535978124307

Epoch: 5| Step: 7
Training loss: 0.6129215424752377
Validation loss: 2.40078260304393

Epoch: 5| Step: 8
Training loss: 0.43704671879418117
Validation loss: 2.353171936001971

Epoch: 5| Step: 9
Training loss: 0.3593315429949585
Validation loss: 2.339993939631583

Epoch: 5| Step: 10
Training loss: 0.5341906223886503
Validation loss: 2.2694129799366114

Epoch: 328| Step: 0
Training loss: 0.2356174360143867
Validation loss: 2.2242489919465784

Epoch: 5| Step: 1
Training loss: 0.34401313507292025
Validation loss: 2.2646806694434476

Epoch: 5| Step: 2
Training loss: 0.5021069361519304
Validation loss: 2.2558967304905715

Epoch: 5| Step: 3
Training loss: 0.4897013346185116
Validation loss: 2.280147420613112

Epoch: 5| Step: 4
Training loss: 0.5178411427266999
Validation loss: 2.317574383214441

Epoch: 5| Step: 5
Training loss: 0.7000315539877625
Validation loss: 2.3197986802721733

Epoch: 5| Step: 6
Training loss: 0.39175277035749384
Validation loss: 2.3411452347131876

Epoch: 5| Step: 7
Training loss: 0.4669717756315152
Validation loss: 2.3995111426040263

Epoch: 5| Step: 8
Training loss: 0.6565048540347012
Validation loss: 2.394381237612231

Epoch: 5| Step: 9
Training loss: 0.5159535950449785
Validation loss: 2.359703580298262

Epoch: 5| Step: 10
Training loss: 0.5387257616117987
Validation loss: 2.3809922340825516

Epoch: 329| Step: 0
Training loss: 0.3709654536074687
Validation loss: 2.3780413262133577

Epoch: 5| Step: 1
Training loss: 0.44096859190373494
Validation loss: 2.3595545542250465

Epoch: 5| Step: 2
Training loss: 0.3698211935728981
Validation loss: 2.3322966698325946

Epoch: 5| Step: 3
Training loss: 0.6150047721522575
Validation loss: 2.3165462584184793

Epoch: 5| Step: 4
Training loss: 0.4548648776641799
Validation loss: 2.3268094549292293

Epoch: 5| Step: 5
Training loss: 0.7080994014035504
Validation loss: 2.333605734647778

Epoch: 5| Step: 6
Training loss: 0.42706408302218063
Validation loss: 2.354199417878138

Epoch: 5| Step: 7
Training loss: 0.478813110056395
Validation loss: 2.3187226851561293

Epoch: 5| Step: 8
Training loss: 0.4865624502888815
Validation loss: 2.353025945366874

Epoch: 5| Step: 9
Training loss: 0.5036621981318844
Validation loss: 2.3824775383709142

Epoch: 5| Step: 10
Training loss: 0.3646793738524633
Validation loss: 2.3819675829701383

Epoch: 330| Step: 0
Training loss: 0.39679367704054774
Validation loss: 2.3936621723819873

Epoch: 5| Step: 1
Training loss: 0.35910849433515085
Validation loss: 2.3862290108600557

Epoch: 5| Step: 2
Training loss: 0.5029364428020225
Validation loss: 2.3832886417666823

Epoch: 5| Step: 3
Training loss: 0.587082139003379
Validation loss: 2.4033461010905413

Epoch: 5| Step: 4
Training loss: 0.6041460664021401
Validation loss: 2.428084769515977

Epoch: 5| Step: 5
Training loss: 0.45972655332061113
Validation loss: 2.431954408798656

Epoch: 5| Step: 6
Training loss: 0.3265455241559365
Validation loss: 2.413196629722701

Epoch: 5| Step: 7
Training loss: 0.3726858019357496
Validation loss: 2.3855119320685008

Epoch: 5| Step: 8
Training loss: 0.4940024623790175
Validation loss: 2.3749690655613467

Epoch: 5| Step: 9
Training loss: 0.4442787888214508
Validation loss: 2.372402244418639

Epoch: 5| Step: 10
Training loss: 0.4820294502261797
Validation loss: 2.3550892672856887

Epoch: 331| Step: 0
Training loss: 0.43773683881227954
Validation loss: 2.3721883027078374

Epoch: 5| Step: 1
Training loss: 0.4277286964631803
Validation loss: 2.357743088205236

Epoch: 5| Step: 2
Training loss: 0.49388266603954734
Validation loss: 2.3928120546076523

Epoch: 5| Step: 3
Training loss: 0.5228248255907643
Validation loss: 2.3647127121966904

Epoch: 5| Step: 4
Training loss: 0.3177996436475385
Validation loss: 2.3640657532194345

Epoch: 5| Step: 5
Training loss: 0.5709900423958754
Validation loss: 2.3462361620694137

Epoch: 5| Step: 6
Training loss: 0.23831574393574925
Validation loss: 2.3700952385276333

Epoch: 5| Step: 7
Training loss: 0.5313860494648902
Validation loss: 2.3682305232436422

Epoch: 5| Step: 8
Training loss: 0.4593607232087553
Validation loss: 2.374689980562242

Epoch: 5| Step: 9
Training loss: 0.5349811908053717
Validation loss: 2.366509100096907

Epoch: 5| Step: 10
Training loss: 0.40928592076708886
Validation loss: 2.3659084312018535

Epoch: 332| Step: 0
Training loss: 0.39659252476940665
Validation loss: 2.410220859326594

Epoch: 5| Step: 1
Training loss: 0.48378702593710865
Validation loss: 2.4166900526138

Epoch: 5| Step: 2
Training loss: 0.3648137000572147
Validation loss: 2.3653204902154767

Epoch: 5| Step: 3
Training loss: 0.4065530270375233
Validation loss: 2.378448114067621

Epoch: 5| Step: 4
Training loss: 0.48888698389965807
Validation loss: 2.387984438193321

Epoch: 5| Step: 5
Training loss: 0.38001462713750267
Validation loss: 2.382396400091814

Epoch: 5| Step: 6
Training loss: 0.5888225987698783
Validation loss: 2.343519750517428

Epoch: 5| Step: 7
Training loss: 0.4909521979955167
Validation loss: 2.3235601090148537

Epoch: 5| Step: 8
Training loss: 0.5347768176337652
Validation loss: 2.336851279222346

Epoch: 5| Step: 9
Training loss: 0.5137769062301083
Validation loss: 2.309248625430131

Epoch: 5| Step: 10
Training loss: 0.38267399754145276
Validation loss: 2.3400345966425675

Epoch: 333| Step: 0
Training loss: 0.4354405979108166
Validation loss: 2.3350652589730094

Epoch: 5| Step: 1
Training loss: 0.5274043578181584
Validation loss: 2.367630618076296

Epoch: 5| Step: 2
Training loss: 0.20667187070511286
Validation loss: 2.381003202512699

Epoch: 5| Step: 3
Training loss: 0.403734783913372
Validation loss: 2.428318403050052

Epoch: 5| Step: 4
Training loss: 0.3628858239520484
Validation loss: 2.4343849357267318

Epoch: 5| Step: 5
Training loss: 0.3184080145252818
Validation loss: 2.4340973309022607

Epoch: 5| Step: 6
Training loss: 0.5097092345168516
Validation loss: 2.4369591343474712

Epoch: 5| Step: 7
Training loss: 0.3626505596629923
Validation loss: 2.423649190243588

Epoch: 5| Step: 8
Training loss: 0.6277608214280812
Validation loss: 2.414816026503966

Epoch: 5| Step: 9
Training loss: 0.4318510034797937
Validation loss: 2.4068858245911167

Epoch: 5| Step: 10
Training loss: 0.6492987738361117
Validation loss: 2.3841435650263563

Epoch: 334| Step: 0
Training loss: 0.45695160717972155
Validation loss: 2.370556992675096

Epoch: 5| Step: 1
Training loss: 0.6596769364747709
Validation loss: 2.363475532651203

Epoch: 5| Step: 2
Training loss: 0.2579955982490721
Validation loss: 2.3727066644891934

Epoch: 5| Step: 3
Training loss: 0.3512684758170219
Validation loss: 2.354081996215815

Epoch: 5| Step: 4
Training loss: 0.4416997996833957
Validation loss: 2.347005298266272

Epoch: 5| Step: 5
Training loss: 0.6010193540198842
Validation loss: 2.3658765207689654

Epoch: 5| Step: 6
Training loss: 0.279985831894217
Validation loss: 2.4127040776083106

Epoch: 5| Step: 7
Training loss: 0.414040492930474
Validation loss: 2.3975374767674595

Epoch: 5| Step: 8
Training loss: 0.47118195044956745
Validation loss: 2.4146766756108313

Epoch: 5| Step: 9
Training loss: 0.458913432381014
Validation loss: 2.384384894183515

Epoch: 5| Step: 10
Training loss: 0.36460252665906556
Validation loss: 2.3825346936909866

Epoch: 335| Step: 0
Training loss: 0.28068419339821554
Validation loss: 2.380272941271679

Epoch: 5| Step: 1
Training loss: 0.6782780206546742
Validation loss: 2.366600901539062

Epoch: 5| Step: 2
Training loss: 0.37623803100685344
Validation loss: 2.387803136291473

Epoch: 5| Step: 3
Training loss: 0.37760221108116543
Validation loss: 2.370768956197158

Epoch: 5| Step: 4
Training loss: 0.5342783723436738
Validation loss: 2.4040386254218435

Epoch: 5| Step: 5
Training loss: 0.37460453320696696
Validation loss: 2.3614311372554178

Epoch: 5| Step: 6
Training loss: 0.5241493395178848
Validation loss: 2.3730941469990445

Epoch: 5| Step: 7
Training loss: 0.43683519261175646
Validation loss: 2.35282334099405

Epoch: 5| Step: 8
Training loss: 0.542803704954236
Validation loss: 2.3551976814520237

Epoch: 5| Step: 9
Training loss: 0.17110593460626067
Validation loss: 2.3646189531689346

Epoch: 5| Step: 10
Training loss: 0.2990802748249947
Validation loss: 2.358673867306124

Epoch: 336| Step: 0
Training loss: 0.4358658926613759
Validation loss: 2.339908585054244

Epoch: 5| Step: 1
Training loss: 0.16415549662533524
Validation loss: 2.313206134997117

Epoch: 5| Step: 2
Training loss: 0.4495994447461616
Validation loss: 2.3070697255923474

Epoch: 5| Step: 3
Training loss: 0.4957322583306208
Validation loss: 2.3234597837650877

Epoch: 5| Step: 4
Training loss: 0.44728757979301653
Validation loss: 2.3180906899609566

Epoch: 5| Step: 5
Training loss: 0.5830181894065781
Validation loss: 2.31203084331093

Epoch: 5| Step: 6
Training loss: 0.5151638222746177
Validation loss: 2.3394696939200075

Epoch: 5| Step: 7
Training loss: 0.30265199094029566
Validation loss: 2.359182171573974

Epoch: 5| Step: 8
Training loss: 0.26347230493542784
Validation loss: 2.3544321399630532

Epoch: 5| Step: 9
Training loss: 0.5093348352710105
Validation loss: 2.3352718438521407

Epoch: 5| Step: 10
Training loss: 0.5238672741079283
Validation loss: 2.3607242309089487

Epoch: 337| Step: 0
Training loss: 0.41043170580281924
Validation loss: 2.3461611098126216

Epoch: 5| Step: 1
Training loss: 0.08779162818555633
Validation loss: 2.3497566258357794

Epoch: 5| Step: 2
Training loss: 0.37887681276472346
Validation loss: 2.3572705853233864

Epoch: 5| Step: 3
Training loss: 0.41459069660810877
Validation loss: 2.377851164032298

Epoch: 5| Step: 4
Training loss: 0.582512650045471
Validation loss: 2.349192821237468

Epoch: 5| Step: 5
Training loss: 0.4269406867418624
Validation loss: 2.369461062111946

Epoch: 5| Step: 6
Training loss: 0.49345694428123615
Validation loss: 2.333149198072677

Epoch: 5| Step: 7
Training loss: 0.37783889271295246
Validation loss: 2.3659208121042044

Epoch: 5| Step: 8
Training loss: 0.31561908999660254
Validation loss: 2.373384716556279

Epoch: 5| Step: 9
Training loss: 0.5891953245213771
Validation loss: 2.345517459693885

Epoch: 5| Step: 10
Training loss: 0.4843907507519756
Validation loss: 2.3610871531143456

Epoch: 338| Step: 0
Training loss: 0.45245258820563133
Validation loss: 2.338829119513783

Epoch: 5| Step: 1
Training loss: 0.33847918545190375
Validation loss: 2.3516315568214257

Epoch: 5| Step: 2
Training loss: 0.2610121625883564
Validation loss: 2.356766124025593

Epoch: 5| Step: 3
Training loss: 0.46432841610250325
Validation loss: 2.3878499443834924

Epoch: 5| Step: 4
Training loss: 0.38964472795216903
Validation loss: 2.4057091173100074

Epoch: 5| Step: 5
Training loss: 0.3204266995871168
Validation loss: 2.405326355956333

Epoch: 5| Step: 6
Training loss: 0.4452403160618541
Validation loss: 2.3681703802154948

Epoch: 5| Step: 7
Training loss: 0.3373472000306096
Validation loss: 2.3903283140126383

Epoch: 5| Step: 8
Training loss: 0.6802850924338725
Validation loss: 2.408275119103323

Epoch: 5| Step: 9
Training loss: 0.5380691830333804
Validation loss: 2.3800944194262623

Epoch: 5| Step: 10
Training loss: 0.34107788758521057
Validation loss: 2.3936438151678856

Epoch: 339| Step: 0
Training loss: 0.31169453768284033
Validation loss: 2.3837236114632496

Epoch: 5| Step: 1
Training loss: 0.4151449449900136
Validation loss: 2.377603017616262

Epoch: 5| Step: 2
Training loss: 0.2565630489255211
Validation loss: 2.3750679462991804

Epoch: 5| Step: 3
Training loss: 0.354370033088067
Validation loss: 2.389234417895902

Epoch: 5| Step: 4
Training loss: 0.2704796896958369
Validation loss: 2.370964890537552

Epoch: 5| Step: 5
Training loss: 0.4680589986907814
Validation loss: 2.3924651801058388

Epoch: 5| Step: 6
Training loss: 0.7281961840104486
Validation loss: 2.390468774342732

Epoch: 5| Step: 7
Training loss: 0.5519458011646147
Validation loss: 2.3653388157946664

Epoch: 5| Step: 8
Training loss: 0.36333789178776815
Validation loss: 2.3513909104473223

Epoch: 5| Step: 9
Training loss: 0.3815208950057603
Validation loss: 2.334032117420809

Epoch: 5| Step: 10
Training loss: 0.31797615342577706
Validation loss: 2.3568267561816185

Epoch: 340| Step: 0
Training loss: 0.36727806759976744
Validation loss: 2.351117273837175

Epoch: 5| Step: 1
Training loss: 0.3351065205313594
Validation loss: 2.356411390689918

Epoch: 5| Step: 2
Training loss: 0.25046838157088896
Validation loss: 2.3512763392754343

Epoch: 5| Step: 3
Training loss: 0.6406365835491672
Validation loss: 2.3524561001703854

Epoch: 5| Step: 4
Training loss: 0.49026376704524016
Validation loss: 2.375564768187245

Epoch: 5| Step: 5
Training loss: 0.31024775704595914
Validation loss: 2.410115941420723

Epoch: 5| Step: 6
Training loss: 0.502844586625878
Validation loss: 2.4077738675149094

Epoch: 5| Step: 7
Training loss: 0.35331819616962873
Validation loss: 2.4091392199877415

Epoch: 5| Step: 8
Training loss: 0.4793764895449577
Validation loss: 2.353030885191045

Epoch: 5| Step: 9
Training loss: 0.2760716532968203
Validation loss: 2.386893636818279

Epoch: 5| Step: 10
Training loss: 0.5570973446704838
Validation loss: 2.335567870256485

Epoch: 341| Step: 0
Training loss: 0.327164652408327
Validation loss: 2.359635040289221

Epoch: 5| Step: 1
Training loss: 0.33057875729903496
Validation loss: 2.3435377034393636

Epoch: 5| Step: 2
Training loss: 0.3676413105767728
Validation loss: 2.3392865454307206

Epoch: 5| Step: 3
Training loss: 0.43640990348950165
Validation loss: 2.379781875504101

Epoch: 5| Step: 4
Training loss: 0.6384703291912265
Validation loss: 2.3878801735404047

Epoch: 5| Step: 5
Training loss: 0.21274320065069843
Validation loss: 2.3581464649794

Epoch: 5| Step: 6
Training loss: 0.5048632737885471
Validation loss: 2.3687442910319354

Epoch: 5| Step: 7
Training loss: 0.441353820117595
Validation loss: 2.387971715419412

Epoch: 5| Step: 8
Training loss: 0.338541121360144
Validation loss: 2.366575417744721

Epoch: 5| Step: 9
Training loss: 0.5591866607710883
Validation loss: 2.346535853818305

Epoch: 5| Step: 10
Training loss: 0.22942396732657833
Validation loss: 2.3800220285097478

Epoch: 342| Step: 0
Training loss: 0.3928307247258678
Validation loss: 2.3661027830900148

Epoch: 5| Step: 1
Training loss: 0.5707200044594046
Validation loss: 2.361465743631377

Epoch: 5| Step: 2
Training loss: 0.26173267042802717
Validation loss: 2.3434245812707126

Epoch: 5| Step: 3
Training loss: 0.256571513934122
Validation loss: 2.359985721276235

Epoch: 5| Step: 4
Training loss: 0.6641124706540357
Validation loss: 2.359972189260907

Epoch: 5| Step: 5
Training loss: 0.2839893870586982
Validation loss: 2.324428557635079

Epoch: 5| Step: 6
Training loss: 0.44222802492062835
Validation loss: 2.3326807545178245

Epoch: 5| Step: 7
Training loss: 0.16028751251055845
Validation loss: 2.3787260247425617

Epoch: 5| Step: 8
Training loss: 0.4895965865214882
Validation loss: 2.3798013867329764

Epoch: 5| Step: 9
Training loss: 0.29879842872417145
Validation loss: 2.3712354237496056

Epoch: 5| Step: 10
Training loss: 0.4322286027462844
Validation loss: 2.3671977797197417

Epoch: 343| Step: 0
Training loss: 0.30083720194600166
Validation loss: 2.3739990041980383

Epoch: 5| Step: 1
Training loss: 0.2940889685512372
Validation loss: 2.3522667114351514

Epoch: 5| Step: 2
Training loss: 0.3741383189371045
Validation loss: 2.360500464675058

Epoch: 5| Step: 3
Training loss: 0.5156437263556177
Validation loss: 2.3545189170245493

Epoch: 5| Step: 4
Training loss: 0.390439428119225
Validation loss: 2.333848877248841

Epoch: 5| Step: 5
Training loss: 0.4914021811748952
Validation loss: 2.320299051499315

Epoch: 5| Step: 6
Training loss: 0.41999984727016576
Validation loss: 2.35963049183504

Epoch: 5| Step: 7
Training loss: 0.4099830806834886
Validation loss: 2.3444198274715644

Epoch: 5| Step: 8
Training loss: 0.2244106823672455
Validation loss: 2.3446354375504477

Epoch: 5| Step: 9
Training loss: 0.48011441074245276
Validation loss: 2.3617257216973737

Epoch: 5| Step: 10
Training loss: 0.5196538794785355
Validation loss: 2.3729094569797975

Epoch: 344| Step: 0
Training loss: 0.33445925720552655
Validation loss: 2.3989769359477893

Epoch: 5| Step: 1
Training loss: 0.33831009158199155
Validation loss: 2.3723472461556523

Epoch: 5| Step: 2
Training loss: 0.536542558693841
Validation loss: 2.409558289553744

Epoch: 5| Step: 3
Training loss: 0.4539464706223613
Validation loss: 2.403382002623146

Epoch: 5| Step: 4
Training loss: 0.3638670105864606
Validation loss: 2.398701928345258

Epoch: 5| Step: 5
Training loss: 0.3618256726024319
Validation loss: 2.3938775196228956

Epoch: 5| Step: 6
Training loss: 0.5632969191404824
Validation loss: 2.384748694648747

Epoch: 5| Step: 7
Training loss: 0.45541749014726174
Validation loss: 2.3955081667317764

Epoch: 5| Step: 8
Training loss: 0.45956436198767964
Validation loss: 2.373628591706492

Epoch: 5| Step: 9
Training loss: 0.19855577818672107
Validation loss: 2.3646679927633563

Epoch: 5| Step: 10
Training loss: 0.15170923778757098
Validation loss: 2.3845296965110396

Epoch: 345| Step: 0
Training loss: 0.38602599314770697
Validation loss: 2.403666211095861

Epoch: 5| Step: 1
Training loss: 0.2636928691276703
Validation loss: 2.382636401741429

Epoch: 5| Step: 2
Training loss: 0.4656295225704657
Validation loss: 2.3959978843418175

Epoch: 5| Step: 3
Training loss: 0.22246843079229112
Validation loss: 2.3790390177234957

Epoch: 5| Step: 4
Training loss: 0.4404069848140757
Validation loss: 2.3955792549593564

Epoch: 5| Step: 5
Training loss: 0.4455294164413971
Validation loss: 2.398170387107339

Epoch: 5| Step: 6
Training loss: 0.4111838048631775
Validation loss: 2.4114499563821465

Epoch: 5| Step: 7
Training loss: 0.3753374885797158
Validation loss: 2.4002716046426853

Epoch: 5| Step: 8
Training loss: 0.15211137753634477
Validation loss: 2.4351318209920736

Epoch: 5| Step: 9
Training loss: 0.5033627617624519
Validation loss: 2.4086972925155354

Epoch: 5| Step: 10
Training loss: 0.5749487615644143
Validation loss: 2.3843128915823226

Epoch: 346| Step: 0
Training loss: 0.3640552806547754
Validation loss: 2.333963118731096

Epoch: 5| Step: 1
Training loss: 0.509535755931837
Validation loss: 2.3540918153375023

Epoch: 5| Step: 2
Training loss: 0.3228691576289926
Validation loss: 2.3518506457741335

Epoch: 5| Step: 3
Training loss: 0.2943974815984614
Validation loss: 2.366688555571905

Epoch: 5| Step: 4
Training loss: 0.5401226068755768
Validation loss: 2.33971718795046

Epoch: 5| Step: 5
Training loss: 0.3388308085061996
Validation loss: 2.328695895236514

Epoch: 5| Step: 6
Training loss: 0.3764134234627271
Validation loss: 2.3720245904732264

Epoch: 5| Step: 7
Training loss: 0.45217892109418373
Validation loss: 2.360707704785636

Epoch: 5| Step: 8
Training loss: 0.3951396594443217
Validation loss: 2.394333746140054

Epoch: 5| Step: 9
Training loss: 0.3692660648412897
Validation loss: 2.4094878808144635

Epoch: 5| Step: 10
Training loss: 0.41849477591039824
Validation loss: 2.400448890633773

Epoch: 347| Step: 0
Training loss: 0.44531813835456147
Validation loss: 2.3738416427840323

Epoch: 5| Step: 1
Training loss: 0.3740164654034613
Validation loss: 2.358965396945533

Epoch: 5| Step: 2
Training loss: 0.2608648290346752
Validation loss: 2.291207538452048

Epoch: 5| Step: 3
Training loss: 0.3543624220067437
Validation loss: 2.3242830480786916

Epoch: 5| Step: 4
Training loss: 0.7089215715823903
Validation loss: 2.283305974700165

Epoch: 5| Step: 5
Training loss: 0.4126085088081324
Validation loss: 2.310888645266656

Epoch: 5| Step: 6
Training loss: 0.3662707470690757
Validation loss: 2.301518768348868

Epoch: 5| Step: 7
Training loss: 0.2194558574143814
Validation loss: 2.343471513289125

Epoch: 5| Step: 8
Training loss: 0.3019323245603651
Validation loss: 2.361315475195614

Epoch: 5| Step: 9
Training loss: 0.3370101681068139
Validation loss: 2.343943904389293

Epoch: 5| Step: 10
Training loss: 0.44504572590557484
Validation loss: 2.399008526849869

Epoch: 348| Step: 0
Training loss: 0.3479853797299622
Validation loss: 2.3866105930978234

Epoch: 5| Step: 1
Training loss: 0.42502886239388027
Validation loss: 2.4154233870885573

Epoch: 5| Step: 2
Training loss: 0.3106920035148459
Validation loss: 2.3925473664051773

Epoch: 5| Step: 3
Training loss: 0.15510809390201014
Validation loss: 2.3916630950463156

Epoch: 5| Step: 4
Training loss: 0.6190738822510683
Validation loss: 2.3603886672801226

Epoch: 5| Step: 5
Training loss: 0.5098750263783643
Validation loss: 2.3329779948402316

Epoch: 5| Step: 6
Training loss: 0.488417019088224
Validation loss: 2.3390388682830308

Epoch: 5| Step: 7
Training loss: 0.33019452046085335
Validation loss: 2.3481774365096753

Epoch: 5| Step: 8
Training loss: 0.3862096730262951
Validation loss: 2.3491295781947485

Epoch: 5| Step: 9
Training loss: 0.4258583244068635
Validation loss: 2.357622403642826

Epoch: 5| Step: 10
Training loss: 0.17341157208200408
Validation loss: 2.3175709109315052

Epoch: 349| Step: 0
Training loss: 0.544617078850039
Validation loss: 2.363457984455083

Epoch: 5| Step: 1
Training loss: 0.4893771423887321
Validation loss: 2.3503680515443803

Epoch: 5| Step: 2
Training loss: 0.13540197179609126
Validation loss: 2.3643267815214988

Epoch: 5| Step: 3
Training loss: 0.1982006724818222
Validation loss: 2.3640207081443974

Epoch: 5| Step: 4
Training loss: 0.40626296609580853
Validation loss: 2.3336371701561847

Epoch: 5| Step: 5
Training loss: 0.2625055726913027
Validation loss: 2.319984868386236

Epoch: 5| Step: 6
Training loss: 0.4326326526779529
Validation loss: 2.3462994836486817

Epoch: 5| Step: 7
Training loss: 0.37076405385261757
Validation loss: 2.3372319626556104

Epoch: 5| Step: 8
Training loss: 0.368938168506511
Validation loss: 2.313493384457831

Epoch: 5| Step: 9
Training loss: 0.5779377917733193
Validation loss: 2.338582669940617

Epoch: 5| Step: 10
Training loss: 0.324738774863274
Validation loss: 2.283591470871644

Epoch: 350| Step: 0
Training loss: 0.3493013356844802
Validation loss: 2.2996351700852933

Epoch: 5| Step: 1
Training loss: 0.29846973994005727
Validation loss: 2.29828912117417

Epoch: 5| Step: 2
Training loss: 0.4360114386965379
Validation loss: 2.3202736105058976

Epoch: 5| Step: 3
Training loss: 0.5507004861258389
Validation loss: 2.329217256339326

Epoch: 5| Step: 4
Training loss: 0.45824663649956754
Validation loss: 2.357157366327574

Epoch: 5| Step: 5
Training loss: 0.44831654715163755
Validation loss: 2.374477639905544

Epoch: 5| Step: 6
Training loss: 0.3593297598185753
Validation loss: 2.392147477255625

Epoch: 5| Step: 7
Training loss: 0.4698341072039384
Validation loss: 2.375120309687205

Epoch: 5| Step: 8
Training loss: 0.2859705702621927
Validation loss: 2.3461076829307577

Epoch: 5| Step: 9
Training loss: 0.18957206099572615
Validation loss: 2.321144684261267

Epoch: 5| Step: 10
Training loss: 0.37923356302735606
Validation loss: 2.3399317484472033

Epoch: 351| Step: 0
Training loss: 0.642177050800192
Validation loss: 2.3105692065727887

Epoch: 5| Step: 1
Training loss: 0.11870055141624192
Validation loss: 2.304215933204752

Epoch: 5| Step: 2
Training loss: 0.35476289611586764
Validation loss: 2.3308875813731142

Epoch: 5| Step: 3
Training loss: 0.36497194378292663
Validation loss: 2.3164437762071324

Epoch: 5| Step: 4
Training loss: 0.4351062170608547
Validation loss: 2.305288080210509

Epoch: 5| Step: 5
Training loss: 0.421802885461735
Validation loss: 2.3626098926718875

Epoch: 5| Step: 6
Training loss: 0.2342351019090172
Validation loss: 2.376255933870025

Epoch: 5| Step: 7
Training loss: 0.43312583626009976
Validation loss: 2.3689174762920255

Epoch: 5| Step: 8
Training loss: 0.34640102738713724
Validation loss: 2.3705320499637965

Epoch: 5| Step: 9
Training loss: 0.3358837350803342
Validation loss: 2.367944274317465

Epoch: 5| Step: 10
Training loss: 0.37693450565505543
Validation loss: 2.3781937615046065

Epoch: 352| Step: 0
Training loss: 0.3200800680409273
Validation loss: 2.3509511662994993

Epoch: 5| Step: 1
Training loss: 0.24738118814320298
Validation loss: 2.382408656839949

Epoch: 5| Step: 2
Training loss: 0.49397519324060607
Validation loss: 2.341901863493366

Epoch: 5| Step: 3
Training loss: 0.335891432153978
Validation loss: 2.352532217873905

Epoch: 5| Step: 4
Training loss: 0.3440437145804367
Validation loss: 2.3948496535737234

Epoch: 5| Step: 5
Training loss: 0.5180072085457076
Validation loss: 2.379939377358115

Epoch: 5| Step: 6
Training loss: 0.3239556819443383
Validation loss: 2.3564195031928867

Epoch: 5| Step: 7
Training loss: 0.5085942340151217
Validation loss: 2.406363548622249

Epoch: 5| Step: 8
Training loss: 0.4188382561043068
Validation loss: 2.375684470057618

Epoch: 5| Step: 9
Training loss: 0.19502190906983358
Validation loss: 2.420549935393395

Epoch: 5| Step: 10
Training loss: 0.38267736579949735
Validation loss: 2.4010228910898346

Epoch: 353| Step: 0
Training loss: 0.31795370549032703
Validation loss: 2.3683265737683463

Epoch: 5| Step: 1
Training loss: 0.5579081509429079
Validation loss: 2.3522980152663244

Epoch: 5| Step: 2
Training loss: 0.31036312737112465
Validation loss: 2.3257142859117463

Epoch: 5| Step: 3
Training loss: 0.36956484200380485
Validation loss: 2.319372168404231

Epoch: 5| Step: 4
Training loss: 0.30063732221097805
Validation loss: 2.313432420693258

Epoch: 5| Step: 5
Training loss: 0.5047700265309607
Validation loss: 2.3234845797133477

Epoch: 5| Step: 6
Training loss: 0.1916131730601064
Validation loss: 2.332959105180307

Epoch: 5| Step: 7
Training loss: 0.3308016279644098
Validation loss: 2.3018023441407482

Epoch: 5| Step: 8
Training loss: 0.4214641194960708
Validation loss: 2.3395171129129646

Epoch: 5| Step: 9
Training loss: 0.2742470066477491
Validation loss: 2.3357805180189626

Epoch: 5| Step: 10
Training loss: 0.5729468135415895
Validation loss: 2.3283410785191627

Epoch: 354| Step: 0
Training loss: 0.4751584679634289
Validation loss: 2.3361708714855713

Epoch: 5| Step: 1
Training loss: 0.21952902497490995
Validation loss: 2.304187930333013

Epoch: 5| Step: 2
Training loss: 0.49060851330603866
Validation loss: 2.324187466169662

Epoch: 5| Step: 3
Training loss: 0.45520060450483585
Validation loss: 2.3389929970743837

Epoch: 5| Step: 4
Training loss: 0.39761134120766667
Validation loss: 2.3466135624862323

Epoch: 5| Step: 5
Training loss: 0.5807229513568454
Validation loss: 2.3791419904766156

Epoch: 5| Step: 6
Training loss: 0.42242762786577037
Validation loss: 2.4171458594197963

Epoch: 5| Step: 7
Training loss: 0.3209543078514823
Validation loss: 2.4534848290698803

Epoch: 5| Step: 8
Training loss: 0.1704046800493164
Validation loss: 2.452422630430427

Epoch: 5| Step: 9
Training loss: 0.2611534789530527
Validation loss: 2.444892593275366

Epoch: 5| Step: 10
Training loss: 0.359015409271724
Validation loss: 2.4271294011442595

Epoch: 355| Step: 0
Training loss: 0.21824666425771005
Validation loss: 2.4188576597632787

Epoch: 5| Step: 1
Training loss: 0.36131117497458376
Validation loss: 2.4274873854469057

Epoch: 5| Step: 2
Training loss: 0.5692937976036273
Validation loss: 2.3980782558366993

Epoch: 5| Step: 3
Training loss: 0.3759873425808452
Validation loss: 2.3887090128966055

Epoch: 5| Step: 4
Training loss: 0.34265990156601567
Validation loss: 2.368461303257073

Epoch: 5| Step: 5
Training loss: 0.1456850240064141
Validation loss: 2.3565730980363404

Epoch: 5| Step: 6
Training loss: 0.37385069042569086
Validation loss: 2.3483757306261897

Epoch: 5| Step: 7
Training loss: 0.42671891303602333
Validation loss: 2.3204961119678607

Epoch: 5| Step: 8
Training loss: 0.4998640084103937
Validation loss: 2.3074411345511723

Epoch: 5| Step: 9
Training loss: 0.2649953475804663
Validation loss: 2.3110306785399044

Epoch: 5| Step: 10
Training loss: 0.42803052987634604
Validation loss: 2.3347867399605025

Epoch: 356| Step: 0
Training loss: 0.48879523119207857
Validation loss: 2.343005197513281

Epoch: 5| Step: 1
Training loss: 0.38646013108663907
Validation loss: 2.3546830586583556

Epoch: 5| Step: 2
Training loss: 0.30822245074311777
Validation loss: 2.3562393191933744

Epoch: 5| Step: 3
Training loss: 0.3652941812926412
Validation loss: 2.3407269764430283

Epoch: 5| Step: 4
Training loss: 0.17947524429731884
Validation loss: 2.3555762662433075

Epoch: 5| Step: 5
Training loss: 0.2922877471227808
Validation loss: 2.341308647403068

Epoch: 5| Step: 6
Training loss: 0.2888303417257979
Validation loss: 2.3417530863940814

Epoch: 5| Step: 7
Training loss: 0.34586360676332717
Validation loss: 2.350095997588305

Epoch: 5| Step: 8
Training loss: 0.4265188250697117
Validation loss: 2.3639386915443246

Epoch: 5| Step: 9
Training loss: 0.4583210311307892
Validation loss: 2.3340883117646283

Epoch: 5| Step: 10
Training loss: 0.4662260292017316
Validation loss: 2.344745648191917

Epoch: 357| Step: 0
Training loss: 0.36176537528379726
Validation loss: 2.3732122812878402

Epoch: 5| Step: 1
Training loss: 0.27036740346334415
Validation loss: 2.3435216408233366

Epoch: 5| Step: 2
Training loss: 0.5346493234388066
Validation loss: 2.3367542009750117

Epoch: 5| Step: 3
Training loss: 0.24806868089360326
Validation loss: 2.3468305953960877

Epoch: 5| Step: 4
Training loss: 0.465555671676643
Validation loss: 2.382913508729526

Epoch: 5| Step: 5
Training loss: 0.4276947630215804
Validation loss: 2.3405539963977176

Epoch: 5| Step: 6
Training loss: 0.3129715937362882
Validation loss: 2.382593590740169

Epoch: 5| Step: 7
Training loss: 0.1796017836251985
Validation loss: 2.3682699935084597

Epoch: 5| Step: 8
Training loss: 0.303974625904905
Validation loss: 2.347043322659792

Epoch: 5| Step: 9
Training loss: 0.35520275350235864
Validation loss: 2.3436168848881866

Epoch: 5| Step: 10
Training loss: 0.4688386197561128
Validation loss: 2.3216228302184727

Epoch: 358| Step: 0
Training loss: 0.1426527076461046
Validation loss: 2.352501379213629

Epoch: 5| Step: 1
Training loss: 0.516840340537396
Validation loss: 2.3536427957043884

Epoch: 5| Step: 2
Training loss: 0.26422920664303473
Validation loss: 2.339027990228451

Epoch: 5| Step: 3
Training loss: 0.4475755409063584
Validation loss: 2.354883934287128

Epoch: 5| Step: 4
Training loss: 0.3088183973591192
Validation loss: 2.3822665593226207

Epoch: 5| Step: 5
Training loss: 0.5813083896227104
Validation loss: 2.3788952287949767

Epoch: 5| Step: 6
Training loss: 0.3837944399236128
Validation loss: 2.3619613374539

Epoch: 5| Step: 7
Training loss: 0.24992122750229712
Validation loss: 2.3559518217139392

Epoch: 5| Step: 8
Training loss: 0.20963490922443903
Validation loss: 2.3803389227044383

Epoch: 5| Step: 9
Training loss: 0.3801645445320562
Validation loss: 2.352386331391646

Epoch: 5| Step: 10
Training loss: 0.3114940545745452
Validation loss: 2.3253296717952368

Epoch: 359| Step: 0
Training loss: 0.10499667552669166
Validation loss: 2.3246361826147277

Epoch: 5| Step: 1
Training loss: 0.5067028833869999
Validation loss: 2.349744501528667

Epoch: 5| Step: 2
Training loss: 0.33490064206188525
Validation loss: 2.311627737608058

Epoch: 5| Step: 3
Training loss: 0.33298973414775196
Validation loss: 2.2925377056443703

Epoch: 5| Step: 4
Training loss: 0.17827814361915062
Validation loss: 2.3081339452884233

Epoch: 5| Step: 5
Training loss: 0.4195996489788838
Validation loss: 2.3307939971488647

Epoch: 5| Step: 6
Training loss: 0.4389411826540746
Validation loss: 2.325137295122129

Epoch: 5| Step: 7
Training loss: 0.5260867077520682
Validation loss: 2.37219000157872

Epoch: 5| Step: 8
Training loss: 0.3565014520618245
Validation loss: 2.343768104838787

Epoch: 5| Step: 9
Training loss: 0.4161494223480084
Validation loss: 2.374622127089676

Epoch: 5| Step: 10
Training loss: 0.10087419149897302
Validation loss: 2.3394777164137213

Epoch: 360| Step: 0
Training loss: 0.2730449720106268
Validation loss: 2.341556649953102

Epoch: 5| Step: 1
Training loss: 0.3867713430072369
Validation loss: 2.343491405591293

Epoch: 5| Step: 2
Training loss: 0.17616662062022106
Validation loss: 2.3351513625626517

Epoch: 5| Step: 3
Training loss: 0.6691158996040149
Validation loss: 2.3282360318285344

Epoch: 5| Step: 4
Training loss: 0.3876419991607217
Validation loss: 2.339852432431262

Epoch: 5| Step: 5
Training loss: 0.15334802122058325
Validation loss: 2.3506619123643993

Epoch: 5| Step: 6
Training loss: 0.28697890606480075
Validation loss: 2.3202751385644054

Epoch: 5| Step: 7
Training loss: 0.38380255444910555
Validation loss: 2.3277796221877924

Epoch: 5| Step: 8
Training loss: 0.24944446351557004
Validation loss: 2.356782315695967

Epoch: 5| Step: 9
Training loss: 0.5180979870977803
Validation loss: 2.364482117640947

Epoch: 5| Step: 10
Training loss: 0.24741985639417804
Validation loss: 2.346880840161361

Epoch: 361| Step: 0
Training loss: 0.2910887991033204
Validation loss: 2.3589797313301273

Epoch: 5| Step: 1
Training loss: 0.2778364559954254
Validation loss: 2.3621541810312143

Epoch: 5| Step: 2
Training loss: 0.5654423898380263
Validation loss: 2.327197443792278

Epoch: 5| Step: 3
Training loss: 0.24368263010528812
Validation loss: 2.340442903495652

Epoch: 5| Step: 4
Training loss: 0.5454838633786075
Validation loss: 2.3442651812759276

Epoch: 5| Step: 5
Training loss: 0.29114795722709924
Validation loss: 2.3353336950534

Epoch: 5| Step: 6
Training loss: 0.38395431105931516
Validation loss: 2.331820991826851

Epoch: 5| Step: 7
Training loss: 0.20822692577599589
Validation loss: 2.3798597691871684

Epoch: 5| Step: 8
Training loss: 0.2665423512642076
Validation loss: 2.3792226473782674

Epoch: 5| Step: 9
Training loss: 0.22824226233151274
Validation loss: 2.428005058449405

Epoch: 5| Step: 10
Training loss: 0.4886549625778633
Validation loss: 2.3970165425182643

Epoch: 362| Step: 0
Training loss: 0.24953618088342852
Validation loss: 2.3915309102421967

Epoch: 5| Step: 1
Training loss: 0.3797268191728057
Validation loss: 2.4165243574369804

Epoch: 5| Step: 2
Training loss: 0.26324797570028996
Validation loss: 2.367456318618782

Epoch: 5| Step: 3
Training loss: 0.5245486749113248
Validation loss: 2.338720271578405

Epoch: 5| Step: 4
Training loss: 0.3819033082811751
Validation loss: 2.327765033447617

Epoch: 5| Step: 5
Training loss: 0.24436298162756398
Validation loss: 2.3325124075102286

Epoch: 5| Step: 6
Training loss: 0.4231537758693114
Validation loss: 2.3152808353569982

Epoch: 5| Step: 7
Training loss: 0.40034036088246966
Validation loss: 2.304864828838845

Epoch: 5| Step: 8
Training loss: 0.3572839773182944
Validation loss: 2.2990141642665396

Epoch: 5| Step: 9
Training loss: 0.3057218746808211
Validation loss: 2.270498211703962

Epoch: 5| Step: 10
Training loss: 0.3628863577699609
Validation loss: 2.3011879992058133

Epoch: 363| Step: 0
Training loss: 0.490576833438057
Validation loss: 2.2930126618873614

Epoch: 5| Step: 1
Training loss: 0.5118392918839345
Validation loss: 2.293197317174432

Epoch: 5| Step: 2
Training loss: 0.21033293128850522
Validation loss: 2.2950438203094827

Epoch: 5| Step: 3
Training loss: 0.38064745362298336
Validation loss: 2.3246408982413365

Epoch: 5| Step: 4
Training loss: 0.23697294586875758
Validation loss: 2.3197311612805445

Epoch: 5| Step: 5
Training loss: 0.29822837882560216
Validation loss: 2.317264404773157

Epoch: 5| Step: 6
Training loss: 0.48747780883850805
Validation loss: 2.3206802904772594

Epoch: 5| Step: 7
Training loss: 0.37191973665562883
Validation loss: 2.3073721323297254

Epoch: 5| Step: 8
Training loss: 0.3140767492791096
Validation loss: 2.275541345775858

Epoch: 5| Step: 9
Training loss: 0.28886833629160485
Validation loss: 2.3017283050660153

Epoch: 5| Step: 10
Training loss: 0.17602344887518273
Validation loss: 2.3198808517348435

Epoch: 364| Step: 0
Training loss: 0.4584299188050748
Validation loss: 2.298625641356907

Epoch: 5| Step: 1
Training loss: 0.1393534739725138
Validation loss: 2.3406259954563127

Epoch: 5| Step: 2
Training loss: 0.3096022002827653
Validation loss: 2.2905236309614083

Epoch: 5| Step: 3
Training loss: 0.2892379872433092
Validation loss: 2.3345308117000383

Epoch: 5| Step: 4
Training loss: 0.31727389300670783
Validation loss: 2.317559171059017

Epoch: 5| Step: 5
Training loss: 0.5997220905738267
Validation loss: 2.3385613617386394

Epoch: 5| Step: 6
Training loss: 0.3886209004008935
Validation loss: 2.3208679957345764

Epoch: 5| Step: 7
Training loss: 0.4470936307079721
Validation loss: 2.3121572934550145

Epoch: 5| Step: 8
Training loss: 0.23327802001750853
Validation loss: 2.2890221757650333

Epoch: 5| Step: 9
Training loss: 0.25734328429151593
Validation loss: 2.313485737826309

Epoch: 5| Step: 10
Training loss: 0.16496387439329255
Validation loss: 2.328128034797954

Epoch: 365| Step: 0
Training loss: 0.22560394512484672
Validation loss: 2.303211147667231

Epoch: 5| Step: 1
Training loss: 0.20136201076716911
Validation loss: 2.3301374523816167

Epoch: 5| Step: 2
Training loss: 0.40217121832316866
Validation loss: 2.333761382137248

Epoch: 5| Step: 3
Training loss: 0.31119500907699477
Validation loss: 2.3674712583480395

Epoch: 5| Step: 4
Training loss: 0.27295945477613165
Validation loss: 2.3648623652905645

Epoch: 5| Step: 5
Training loss: 0.4772747064782674
Validation loss: 2.3695477734838217

Epoch: 5| Step: 6
Training loss: 0.4398736255859514
Validation loss: 2.368015442474592

Epoch: 5| Step: 7
Training loss: 0.48877709199009817
Validation loss: 2.377689680048704

Epoch: 5| Step: 8
Training loss: 0.18566604601962056
Validation loss: 2.380632527280033

Epoch: 5| Step: 9
Training loss: 0.26924607490823843
Validation loss: 2.4220320953324035

Epoch: 5| Step: 10
Training loss: 0.40238267284376444
Validation loss: 2.3883857617745936

Epoch: 366| Step: 0
Training loss: 0.2755978122804981
Validation loss: 2.3532094222589963

Epoch: 5| Step: 1
Training loss: 0.34922713156590385
Validation loss: 2.3202527341205954

Epoch: 5| Step: 2
Training loss: 0.25037857538470976
Validation loss: 2.330716834577332

Epoch: 5| Step: 3
Training loss: 0.3715553223964983
Validation loss: 2.3266992783619638

Epoch: 5| Step: 4
Training loss: 0.3769134737813319
Validation loss: 2.2784962245972684

Epoch: 5| Step: 5
Training loss: 0.30997155837748086
Validation loss: 2.264103222167557

Epoch: 5| Step: 6
Training loss: 0.31329012166159065
Validation loss: 2.2840858293617843

Epoch: 5| Step: 7
Training loss: 0.25177085552654765
Validation loss: 2.294916876562955

Epoch: 5| Step: 8
Training loss: 0.41099236053249094
Validation loss: 2.2930899880774915

Epoch: 5| Step: 9
Training loss: 0.36970015409841467
Validation loss: 2.3241244008703075

Epoch: 5| Step: 10
Training loss: 0.5048117375473757
Validation loss: 2.308976035646452

Epoch: 367| Step: 0
Training loss: 0.23705681464953143
Validation loss: 2.2963774924074065

Epoch: 5| Step: 1
Training loss: 0.3468950703974705
Validation loss: 2.3193406992735497

Epoch: 5| Step: 2
Training loss: 0.21045710467014717
Validation loss: 2.318444839562189

Epoch: 5| Step: 3
Training loss: 0.5184147245383706
Validation loss: 2.3285490460422977

Epoch: 5| Step: 4
Training loss: 0.3711130036830391
Validation loss: 2.3199727766216984

Epoch: 5| Step: 5
Training loss: 0.4080530830859061
Validation loss: 2.321021178300399

Epoch: 5| Step: 6
Training loss: 0.3496047504481476
Validation loss: 2.3467194656138037

Epoch: 5| Step: 7
Training loss: 0.18633833283427434
Validation loss: 2.3416659731078022

Epoch: 5| Step: 8
Training loss: 0.3173830355129926
Validation loss: 2.3219874972951864

Epoch: 5| Step: 9
Training loss: 0.3241666843938128
Validation loss: 2.33267284822291

Epoch: 5| Step: 10
Training loss: 0.3751658231950856
Validation loss: 2.3374821344438335

Epoch: 368| Step: 0
Training loss: 0.29273720810402165
Validation loss: 2.3406046590325493

Epoch: 5| Step: 1
Training loss: 0.26741393126252394
Validation loss: 2.3724685005306365

Epoch: 5| Step: 2
Training loss: 0.4646163833163994
Validation loss: 2.3259890615638654

Epoch: 5| Step: 3
Training loss: 0.35053286775030507
Validation loss: 2.3393455220215067

Epoch: 5| Step: 4
Training loss: 0.2698166621472357
Validation loss: 2.347229313433655

Epoch: 5| Step: 5
Training loss: 0.41594521728166034
Validation loss: 2.3543216139968792

Epoch: 5| Step: 6
Training loss: 0.0841591507937273
Validation loss: 2.350397999803945

Epoch: 5| Step: 7
Training loss: 0.5877801785057467
Validation loss: 2.3416919567920536

Epoch: 5| Step: 8
Training loss: 0.2135644712521811
Validation loss: 2.3416722429816583

Epoch: 5| Step: 9
Training loss: 0.1632478447102962
Validation loss: 2.3275328898554304

Epoch: 5| Step: 10
Training loss: 0.2747656040012676
Validation loss: 2.3392325264522267

Epoch: 369| Step: 0
Training loss: 0.35028605266855073
Validation loss: 2.3070943737815024

Epoch: 5| Step: 1
Training loss: 0.16943536367233994
Validation loss: 2.353898169121294

Epoch: 5| Step: 2
Training loss: 0.3897887816119333
Validation loss: 2.337786467987598

Epoch: 5| Step: 3
Training loss: 0.460033273374623
Validation loss: 2.2919115608749956

Epoch: 5| Step: 4
Training loss: 0.27473102875659905
Validation loss: 2.331522568768774

Epoch: 5| Step: 5
Training loss: 0.2946189941923802
Validation loss: 2.3271256381952194

Epoch: 5| Step: 6
Training loss: 0.4715094091158207
Validation loss: 2.336395477781784

Epoch: 5| Step: 7
Training loss: 0.3141194699935724
Validation loss: 2.32150601029445

Epoch: 5| Step: 8
Training loss: 0.319840094485356
Validation loss: 2.3125095428207816

Epoch: 5| Step: 9
Training loss: 0.3134247567694588
Validation loss: 2.3306319102288735

Epoch: 5| Step: 10
Training loss: 0.2301924067090039
Validation loss: 2.3217815219316256

Epoch: 370| Step: 0
Training loss: 0.16009697165999592
Validation loss: 2.281035431308987

Epoch: 5| Step: 1
Training loss: 0.24609746627423665
Validation loss: 2.3272919913709456

Epoch: 5| Step: 2
Training loss: 0.26999364801281883
Validation loss: 2.3017054800662455

Epoch: 5| Step: 3
Training loss: 0.29202013934508525
Validation loss: 2.280102373561916

Epoch: 5| Step: 4
Training loss: 0.3223678542318083
Validation loss: 2.29674626382303

Epoch: 5| Step: 5
Training loss: 0.31871300931477586
Validation loss: 2.2721119145216475

Epoch: 5| Step: 6
Training loss: 0.38429155529455855
Validation loss: 2.303355094589373

Epoch: 5| Step: 7
Training loss: 0.3621070919355827
Validation loss: 2.2887470610814846

Epoch: 5| Step: 8
Training loss: 0.3823604249923049
Validation loss: 2.3070433653007996

Epoch: 5| Step: 9
Training loss: 0.4601922233263503
Validation loss: 2.3173035588381157

Epoch: 5| Step: 10
Training loss: 0.40661556961893097
Validation loss: 2.301244831255304

Epoch: 371| Step: 0
Training loss: 0.1276927967821449
Validation loss: 2.3105842139962953

Epoch: 5| Step: 1
Training loss: 0.2591546409480624
Validation loss: 2.3359069833200183

Epoch: 5| Step: 2
Training loss: 0.24747840440340876
Validation loss: 2.3177460948877

Epoch: 5| Step: 3
Training loss: 0.3224094185665604
Validation loss: 2.3466703360713916

Epoch: 5| Step: 4
Training loss: 0.1801083859982163
Validation loss: 2.342356174806163

Epoch: 5| Step: 5
Training loss: 0.393981285892489
Validation loss: 2.3811394073201417

Epoch: 5| Step: 6
Training loss: 0.471238761459229
Validation loss: 2.399949086240573

Epoch: 5| Step: 7
Training loss: 0.3700033128435444
Validation loss: 2.407999492348952

Epoch: 5| Step: 8
Training loss: 0.3487957592309646
Validation loss: 2.3689908915492275

Epoch: 5| Step: 9
Training loss: 0.39061099981014835
Validation loss: 2.354469909942306

Epoch: 5| Step: 10
Training loss: 0.5464558766414419
Validation loss: 2.2999994800936205

Epoch: 372| Step: 0
Training loss: 0.2112766647439392
Validation loss: 2.3364390809661524

Epoch: 5| Step: 1
Training loss: 0.4057208980587766
Validation loss: 2.3027997572321404

Epoch: 5| Step: 2
Training loss: 0.3107457753567154
Validation loss: 2.298971850128458

Epoch: 5| Step: 3
Training loss: 0.4280740269019472
Validation loss: 2.3273356684516306

Epoch: 5| Step: 4
Training loss: 0.18756182962454787
Validation loss: 2.2999101577553573

Epoch: 5| Step: 5
Training loss: 0.2491356540733083
Validation loss: 2.328058664010414

Epoch: 5| Step: 6
Training loss: 0.26380402820669824
Validation loss: 2.342845119685342

Epoch: 5| Step: 7
Training loss: 0.5237578080990521
Validation loss: 2.3550803835839207

Epoch: 5| Step: 8
Training loss: 0.529358976317539
Validation loss: 2.3193293032764486

Epoch: 5| Step: 9
Training loss: 0.17997303335196554
Validation loss: 2.3416736891995242

Epoch: 5| Step: 10
Training loss: 0.2431938965048597
Validation loss: 2.3528003497381467

Epoch: 373| Step: 0
Training loss: 0.21293894193220983
Validation loss: 2.338326317332673

Epoch: 5| Step: 1
Training loss: 0.4405026259154598
Validation loss: 2.3373568873750017

Epoch: 5| Step: 2
Training loss: 0.3592818595600357
Validation loss: 2.332623172251132

Epoch: 5| Step: 3
Training loss: 0.32610724716877765
Validation loss: 2.332580164314238

Epoch: 5| Step: 4
Training loss: 0.3945438836218364
Validation loss: 2.34800083807216

Epoch: 5| Step: 5
Training loss: 0.36888573944580655
Validation loss: 2.3246118632397508

Epoch: 5| Step: 6
Training loss: 0.3445246918588258
Validation loss: 2.338492111344965

Epoch: 5| Step: 7
Training loss: 0.24456948569450032
Validation loss: 2.3425521469427464

Epoch: 5| Step: 8
Training loss: 0.3737778218225916
Validation loss: 2.3598981403774784

Epoch: 5| Step: 9
Training loss: 0.29478576500357845
Validation loss: 2.311434963097657

Epoch: 5| Step: 10
Training loss: 0.3261182021335066
Validation loss: 2.303844229637727

Epoch: 374| Step: 0
Training loss: 0.38250887760755714
Validation loss: 2.287719199140538

Epoch: 5| Step: 1
Training loss: 0.29490492310972793
Validation loss: 2.3165042423945446

Epoch: 5| Step: 2
Training loss: 0.21063033450924268
Validation loss: 2.328033496120815

Epoch: 5| Step: 3
Training loss: 0.28129407749226887
Validation loss: 2.334461272074916

Epoch: 5| Step: 4
Training loss: 0.5336091448460646
Validation loss: 2.332932282479531

Epoch: 5| Step: 5
Training loss: 0.30901181597092514
Validation loss: 2.34540511124813

Epoch: 5| Step: 6
Training loss: 0.26825700387050444
Validation loss: 2.3692493830195795

Epoch: 5| Step: 7
Training loss: 0.34161996895442065
Validation loss: 2.395620543315995

Epoch: 5| Step: 8
Training loss: 0.23324715727375017
Validation loss: 2.3779786412585375

Epoch: 5| Step: 9
Training loss: 0.5093341331236403
Validation loss: 2.3506781274046413

Epoch: 5| Step: 10
Training loss: 0.16460164922391204
Validation loss: 2.3167213937057447

Epoch: 375| Step: 0
Training loss: 0.29077897914961126
Validation loss: 2.309831348229429

Epoch: 5| Step: 1
Training loss: 0.2972552599710231
Validation loss: 2.2744180797136226

Epoch: 5| Step: 2
Training loss: 0.33858062324375077
Validation loss: 2.237000934597536

Epoch: 5| Step: 3
Training loss: 0.3600802343418068
Validation loss: 2.235946278335463

Epoch: 5| Step: 4
Training loss: 0.2928482570820377
Validation loss: 2.249528476570374

Epoch: 5| Step: 5
Training loss: 0.3351726919200428
Validation loss: 2.281949780891747

Epoch: 5| Step: 6
Training loss: 0.5430965684795332
Validation loss: 2.305354917956644

Epoch: 5| Step: 7
Training loss: 0.28795860191922934
Validation loss: 2.3015741859779113

Epoch: 5| Step: 8
Training loss: 0.35624036775918666
Validation loss: 2.314648459164115

Epoch: 5| Step: 9
Training loss: 0.3575855568231638
Validation loss: 2.332933282471042

Epoch: 5| Step: 10
Training loss: 0.1908876341308888
Validation loss: 2.3500081921157356

Epoch: 376| Step: 0
Training loss: 0.3351585094669181
Validation loss: 2.354050949160974

Epoch: 5| Step: 1
Training loss: 0.2601255347188195
Validation loss: 2.3133971168366094

Epoch: 5| Step: 2
Training loss: 0.27623776751832885
Validation loss: 2.3113289794549834

Epoch: 5| Step: 3
Training loss: 0.37354303488806145
Validation loss: 2.2737035059735313

Epoch: 5| Step: 4
Training loss: 0.4350423413804162
Validation loss: 2.3104198798396003

Epoch: 5| Step: 5
Training loss: 0.3341725471844055
Validation loss: 2.3134853743599684

Epoch: 5| Step: 6
Training loss: 0.33406000229175653
Validation loss: 2.3354998593000387

Epoch: 5| Step: 7
Training loss: 0.24606403292507165
Validation loss: 2.332425748163776

Epoch: 5| Step: 8
Training loss: 0.2982160870336131
Validation loss: 2.3092936359645653

Epoch: 5| Step: 9
Training loss: 0.3561867808414876
Validation loss: 2.3545801307553123

Epoch: 5| Step: 10
Training loss: 0.3654050988998297
Validation loss: 2.2930311824206964

Epoch: 377| Step: 0
Training loss: 0.36292259395779597
Validation loss: 2.304129334204653

Epoch: 5| Step: 1
Training loss: 0.278737982845859
Validation loss: 2.3290916737958174

Epoch: 5| Step: 2
Training loss: 0.11016478809788367
Validation loss: 2.303783340476804

Epoch: 5| Step: 3
Training loss: 0.3093359990053035
Validation loss: 2.313467356109443

Epoch: 5| Step: 4
Training loss: 0.3116418260774493
Validation loss: 2.3196962447720795

Epoch: 5| Step: 5
Training loss: 0.43559745529090943
Validation loss: 2.3276073240620003

Epoch: 5| Step: 6
Training loss: 0.34193145282371673
Validation loss: 2.3348971892939963

Epoch: 5| Step: 7
Training loss: 0.3856600323843887
Validation loss: 2.36027724528916

Epoch: 5| Step: 8
Training loss: 0.17372356977911568
Validation loss: 2.383244794756701

Epoch: 5| Step: 9
Training loss: 0.38156395320631226
Validation loss: 2.413614143226143

Epoch: 5| Step: 10
Training loss: 0.37730470380300235
Validation loss: 2.4113194367541553

Epoch: 378| Step: 0
Training loss: 0.22131264334520223
Validation loss: 2.422670843998132

Epoch: 5| Step: 1
Training loss: 0.28815469729447124
Validation loss: 2.427980419761955

Epoch: 5| Step: 2
Training loss: 0.2392109494149018
Validation loss: 2.416663200268436

Epoch: 5| Step: 3
Training loss: 0.24682808110284485
Validation loss: 2.4394184416390066

Epoch: 5| Step: 4
Training loss: 0.4104808068220015
Validation loss: 2.410670988565763

Epoch: 5| Step: 5
Training loss: 0.3596380763562094
Validation loss: 2.375809961533345

Epoch: 5| Step: 6
Training loss: 0.335115602780566
Validation loss: 2.3808921872204887

Epoch: 5| Step: 7
Training loss: 0.3655146782872218
Validation loss: 2.3385600752925524

Epoch: 5| Step: 8
Training loss: 0.1697455785127053
Validation loss: 2.3332400788585863

Epoch: 5| Step: 9
Training loss: 0.4127131012794077
Validation loss: 2.317130966326098

Epoch: 5| Step: 10
Training loss: 0.4233246902868843
Validation loss: 2.3238381257256893

Epoch: 379| Step: 0
Training loss: 0.341589695946295
Validation loss: 2.323059528654977

Epoch: 5| Step: 1
Training loss: 0.3886450370072211
Validation loss: 2.3389693640414024

Epoch: 5| Step: 2
Training loss: 0.30430686846129273
Validation loss: 2.3193332979611467

Epoch: 5| Step: 3
Training loss: 0.41132381107281607
Validation loss: 2.3258536348171748

Epoch: 5| Step: 4
Training loss: 0.46796598035600967
Validation loss: 2.359916415725333

Epoch: 5| Step: 5
Training loss: 0.2005470535342912
Validation loss: 2.390271881316405

Epoch: 5| Step: 6
Training loss: 0.20181706122651394
Validation loss: 2.3619265657602946

Epoch: 5| Step: 7
Training loss: 0.3224850572221845
Validation loss: 2.3391452250428104

Epoch: 5| Step: 8
Training loss: 0.27125914582422267
Validation loss: 2.3687028036930733

Epoch: 5| Step: 9
Training loss: 0.30013308106521197
Validation loss: 2.357831059029751

Epoch: 5| Step: 10
Training loss: 0.2571441048992061
Validation loss: 2.352880151058399

Epoch: 380| Step: 0
Training loss: 0.2698300543591365
Validation loss: 2.3462070932837364

Epoch: 5| Step: 1
Training loss: 0.28537428371825785
Validation loss: 2.3423862936304243

Epoch: 5| Step: 2
Training loss: 0.43172307327430814
Validation loss: 2.3473729069482365

Epoch: 5| Step: 3
Training loss: 0.23886301593771708
Validation loss: 2.312692999996524

Epoch: 5| Step: 4
Training loss: 0.40817707836518946
Validation loss: 2.341929720278524

Epoch: 5| Step: 5
Training loss: 0.3446453095983445
Validation loss: 2.349595721031613

Epoch: 5| Step: 6
Training loss: 0.2502178196904637
Validation loss: 2.356993294220001

Epoch: 5| Step: 7
Training loss: 0.35508602624543645
Validation loss: 2.3346404495753728

Epoch: 5| Step: 8
Training loss: 0.23311222355887717
Validation loss: 2.321820819548143

Epoch: 5| Step: 9
Training loss: 0.2440746981299207
Validation loss: 2.336570367848236

Epoch: 5| Step: 10
Training loss: 0.300221603721476
Validation loss: 2.327728436469424

Epoch: 381| Step: 0
Training loss: 0.3441077559813725
Validation loss: 2.3617096728758193

Epoch: 5| Step: 1
Training loss: 0.222021931030549
Validation loss: 2.330647829036305

Epoch: 5| Step: 2
Training loss: 0.20499223999711297
Validation loss: 2.31679081349197

Epoch: 5| Step: 3
Training loss: 0.2975416353286501
Validation loss: 2.326657764673884

Epoch: 5| Step: 4
Training loss: 0.4014078569806972
Validation loss: 2.3103654186695555

Epoch: 5| Step: 5
Training loss: 0.13389589402070942
Validation loss: 2.3235214515151834

Epoch: 5| Step: 6
Training loss: 0.2900106114263006
Validation loss: 2.331063487899987

Epoch: 5| Step: 7
Training loss: 0.2980191119101092
Validation loss: 2.336466566733151

Epoch: 5| Step: 8
Training loss: 0.27604972479712736
Validation loss: 2.30242674220653

Epoch: 5| Step: 9
Training loss: 0.392620748606791
Validation loss: 2.306481126636174

Epoch: 5| Step: 10
Training loss: 0.4196145108252594
Validation loss: 2.3531884627551922

Epoch: 382| Step: 0
Training loss: 0.10542303436759008
Validation loss: 2.318641090162678

Epoch: 5| Step: 1
Training loss: 0.42037779432054856
Validation loss: 2.339500496157122

Epoch: 5| Step: 2
Training loss: 0.1762471858520261
Validation loss: 2.315177744579052

Epoch: 5| Step: 3
Training loss: 0.17574192772901423
Validation loss: 2.318662143037112

Epoch: 5| Step: 4
Training loss: 0.34370638830792477
Validation loss: 2.3155035331511113

Epoch: 5| Step: 5
Training loss: 0.33395468150422986
Validation loss: 2.310252526763026

Epoch: 5| Step: 6
Training loss: 0.20145311418523087
Validation loss: 2.3148098013583165

Epoch: 5| Step: 7
Training loss: 0.4282847134416358
Validation loss: 2.3097773312972922

Epoch: 5| Step: 8
Training loss: 0.4166052673718784
Validation loss: 2.3034287741953214

Epoch: 5| Step: 9
Training loss: 0.23398509176714463
Validation loss: 2.3255916482200267

Epoch: 5| Step: 10
Training loss: 0.33109805292895217
Validation loss: 2.347893055729792

Epoch: 383| Step: 0
Training loss: 0.3814977919363415
Validation loss: 2.3143690206209384

Epoch: 5| Step: 1
Training loss: 0.13161459107871334
Validation loss: 2.3634669771354666

Epoch: 5| Step: 2
Training loss: 0.27289963000511147
Validation loss: 2.361385510497131

Epoch: 5| Step: 3
Training loss: 0.3389186325378907
Validation loss: 2.3413719916572067

Epoch: 5| Step: 4
Training loss: 0.18891202203153393
Validation loss: 2.3413719500498305

Epoch: 5| Step: 5
Training loss: 0.3375100876042361
Validation loss: 2.3781152262741587

Epoch: 5| Step: 6
Training loss: 0.2305027807294509
Validation loss: 2.3835162746207916

Epoch: 5| Step: 7
Training loss: 0.3665956841202276
Validation loss: 2.369915050678357

Epoch: 5| Step: 8
Training loss: 0.32789703806417425
Validation loss: 2.3324906300429284

Epoch: 5| Step: 9
Training loss: 0.3820826131230801
Validation loss: 2.3304339340762223

Epoch: 5| Step: 10
Training loss: 0.2522961846274434
Validation loss: 2.3672331004835767

Epoch: 384| Step: 0
Training loss: 0.340858238755159
Validation loss: 2.3962807101653993

Epoch: 5| Step: 1
Training loss: 0.24404567397970173
Validation loss: 2.350074873957432

Epoch: 5| Step: 2
Training loss: 0.392001283366185
Validation loss: 2.3193453167918374

Epoch: 5| Step: 3
Training loss: 0.3921057102893253
Validation loss: 2.35802396315323

Epoch: 5| Step: 4
Training loss: 0.3565658992434795
Validation loss: 2.323066852985613

Epoch: 5| Step: 5
Training loss: 0.2534611542054714
Validation loss: 2.3362950409333734

Epoch: 5| Step: 6
Training loss: 0.3200526811962994
Validation loss: 2.3284566736200736

Epoch: 5| Step: 7
Training loss: 0.23229682186775527
Validation loss: 2.2983610318311953

Epoch: 5| Step: 8
Training loss: 0.17241727831494488
Validation loss: 2.3068974920565752

Epoch: 5| Step: 9
Training loss: 0.23292690192909105
Validation loss: 2.2834000198306414

Epoch: 5| Step: 10
Training loss: 0.2863009743093314
Validation loss: 2.2994403611235326

Epoch: 385| Step: 0
Training loss: 0.21516307162051185
Validation loss: 2.3193357186438774

Epoch: 5| Step: 1
Training loss: 0.17618003750180566
Validation loss: 2.2884717990596886

Epoch: 5| Step: 2
Training loss: 0.3626363629333062
Validation loss: 2.3371151221934467

Epoch: 5| Step: 3
Training loss: 0.15547635955973652
Validation loss: 2.349928422543387

Epoch: 5| Step: 4
Training loss: 0.42143921066563816
Validation loss: 2.3676408623058625

Epoch: 5| Step: 5
Training loss: 0.15330906844973793
Validation loss: 2.329379128034299

Epoch: 5| Step: 6
Training loss: 0.45730013966223515
Validation loss: 2.3443556223937643

Epoch: 5| Step: 7
Training loss: 0.240509139691288
Validation loss: 2.3339806865811106

Epoch: 5| Step: 8
Training loss: 0.34064995298067546
Validation loss: 2.3441296637058624

Epoch: 5| Step: 9
Training loss: 0.2934891973502536
Validation loss: 2.377352418991196

Epoch: 5| Step: 10
Training loss: 0.29938682984729476
Validation loss: 2.365098044427017

Epoch: 386| Step: 0
Training loss: 0.4191335330871544
Validation loss: 2.329492855776513

Epoch: 5| Step: 1
Training loss: 0.19288070268476382
Validation loss: 2.3471584243034416

Epoch: 5| Step: 2
Training loss: 0.1767856512750786
Validation loss: 2.332309294562205

Epoch: 5| Step: 3
Training loss: 0.07097842522666283
Validation loss: 2.356058092338056

Epoch: 5| Step: 4
Training loss: 0.35643937615454835
Validation loss: 2.3530770939439063

Epoch: 5| Step: 5
Training loss: 0.4699735091484819
Validation loss: 2.3334333915469214

Epoch: 5| Step: 6
Training loss: 0.23230092724415122
Validation loss: 2.3415149513306783

Epoch: 5| Step: 7
Training loss: 0.2746118667511196
Validation loss: 2.288468505547881

Epoch: 5| Step: 8
Training loss: 0.35213616508980233
Validation loss: 2.31146953719259

Epoch: 5| Step: 9
Training loss: 0.25672756563027055
Validation loss: 2.320843821344817

Epoch: 5| Step: 10
Training loss: 0.22479525628345304
Validation loss: 2.3294981602503015

Epoch: 387| Step: 0
Training loss: 0.38113264403867775
Validation loss: 2.299125643003436

Epoch: 5| Step: 1
Training loss: 0.2792751997426474
Validation loss: 2.344224271745609

Epoch: 5| Step: 2
Training loss: 0.25699381454238
Validation loss: 2.3531960615365244

Epoch: 5| Step: 3
Training loss: 0.15118007785513515
Validation loss: 2.353058604232595

Epoch: 5| Step: 4
Training loss: 0.22614455313359003
Validation loss: 2.3489105519519384

Epoch: 5| Step: 5
Training loss: 0.20382417876055806
Validation loss: 2.347010960211396

Epoch: 5| Step: 6
Training loss: 0.23644119111632866
Validation loss: 2.3403872182800916

Epoch: 5| Step: 7
Training loss: 0.4549298843132068
Validation loss: 2.309265119606762

Epoch: 5| Step: 8
Training loss: 0.33651092293484797
Validation loss: 2.329900445182194

Epoch: 5| Step: 9
Training loss: 0.39196247012893753
Validation loss: 2.3282537243737296

Epoch: 5| Step: 10
Training loss: 0.1790770028184586
Validation loss: 2.3424440066368972

Epoch: 388| Step: 0
Training loss: 0.3721466186453364
Validation loss: 2.303343419160566

Epoch: 5| Step: 1
Training loss: 0.29508004147263517
Validation loss: 2.270759619330845

Epoch: 5| Step: 2
Training loss: 0.3760604566633019
Validation loss: 2.289891932499383

Epoch: 5| Step: 3
Training loss: 0.13185231142441084
Validation loss: 2.279516825123089

Epoch: 5| Step: 4
Training loss: 0.3999086596091511
Validation loss: 2.2745808858653747

Epoch: 5| Step: 5
Training loss: 0.28114482449556316
Validation loss: 2.296240823319787

Epoch: 5| Step: 6
Training loss: 0.19118239488797303
Validation loss: 2.309856143419026

Epoch: 5| Step: 7
Training loss: 0.31312669856358866
Validation loss: 2.2627828919389774

Epoch: 5| Step: 8
Training loss: 0.17417859525609702
Validation loss: 2.310675115225724

Epoch: 5| Step: 9
Training loss: 0.3171851261407126
Validation loss: 2.3272591083384553

Epoch: 5| Step: 10
Training loss: 0.33258498523707825
Validation loss: 2.3392979735216053

Epoch: 389| Step: 0
Training loss: 0.16789581134608395
Validation loss: 2.3314000678170244

Epoch: 5| Step: 1
Training loss: 0.23708300184607728
Validation loss: 2.348397427922495

Epoch: 5| Step: 2
Training loss: 0.32989639154902306
Validation loss: 2.33816984220611

Epoch: 5| Step: 3
Training loss: 0.4043172932504476
Validation loss: 2.3916784211248245

Epoch: 5| Step: 4
Training loss: 0.2048222898798222
Validation loss: 2.3564682480667924

Epoch: 5| Step: 5
Training loss: 0.36335878672743893
Validation loss: 2.376976068685115

Epoch: 5| Step: 6
Training loss: 0.29394119361196835
Validation loss: 2.3423212313735746

Epoch: 5| Step: 7
Training loss: 0.17916048551217503
Validation loss: 2.345870925376841

Epoch: 5| Step: 8
Training loss: 0.3310510190687352
Validation loss: 2.3119510297241255

Epoch: 5| Step: 9
Training loss: 0.2882919738553057
Validation loss: 2.285085505114501

Epoch: 5| Step: 10
Training loss: 0.38627448717290286
Validation loss: 2.3145294505013903

Epoch: 390| Step: 0
Training loss: 0.25798517282337297
Validation loss: 2.2909195760787426

Epoch: 5| Step: 1
Training loss: 0.2429177365612092
Validation loss: 2.2812360964565053

Epoch: 5| Step: 2
Training loss: 0.2695383540889669
Validation loss: 2.3098934464121443

Epoch: 5| Step: 3
Training loss: 0.2190192047711612
Validation loss: 2.310995071755536

Epoch: 5| Step: 4
Training loss: 0.24183348192173815
Validation loss: 2.3323300954564776

Epoch: 5| Step: 5
Training loss: 0.35919052033011606
Validation loss: 2.317261963119174

Epoch: 5| Step: 6
Training loss: 0.2643678169762683
Validation loss: 2.349106430741281

Epoch: 5| Step: 7
Training loss: 0.44919075256673224
Validation loss: 2.3303432463848504

Epoch: 5| Step: 8
Training loss: 0.27066631699926674
Validation loss: 2.295650481402445

Epoch: 5| Step: 9
Training loss: 0.3029505050461685
Validation loss: 2.3026101148081284

Epoch: 5| Step: 10
Training loss: 0.2788179065331504
Validation loss: 2.296986654543824

Epoch: 391| Step: 0
Training loss: 0.2385003146028543
Validation loss: 2.3006189161847033

Epoch: 5| Step: 1
Training loss: 0.40151620219473777
Validation loss: 2.311508348557306

Epoch: 5| Step: 2
Training loss: 0.34676278421340756
Validation loss: 2.298041385656915

Epoch: 5| Step: 3
Training loss: 0.31570712900018044
Validation loss: 2.292465559200983

Epoch: 5| Step: 4
Training loss: 0.23195420023076946
Validation loss: 2.3337974258937346

Epoch: 5| Step: 5
Training loss: 0.20777529046354254
Validation loss: 2.370293347357866

Epoch: 5| Step: 6
Training loss: 0.33426254244149656
Validation loss: 2.355531047939406

Epoch: 5| Step: 7
Training loss: 0.3700102397429677
Validation loss: 2.3890026715603043

Epoch: 5| Step: 8
Training loss: 0.34726576359920935
Validation loss: 2.3909378356447424

Epoch: 5| Step: 9
Training loss: 0.22682335240745224
Validation loss: 2.3809253403157973

Epoch: 5| Step: 10
Training loss: 0.18004938669992757
Validation loss: 2.366424159142138

Epoch: 392| Step: 0
Training loss: 0.32201611656822615
Validation loss: 2.3773489720124616

Epoch: 5| Step: 1
Training loss: 0.34031318163562674
Validation loss: 2.376268811073729

Epoch: 5| Step: 2
Training loss: 0.1798864486442805
Validation loss: 2.3273153808507323

Epoch: 5| Step: 3
Training loss: 0.2608319817275432
Validation loss: 2.329530418234146

Epoch: 5| Step: 4
Training loss: 0.41496944067939406
Validation loss: 2.318221280857337

Epoch: 5| Step: 5
Training loss: 0.33054462175135474
Validation loss: 2.290396612136574

Epoch: 5| Step: 6
Training loss: 0.46290963371295324
Validation loss: 2.295118937901759

Epoch: 5| Step: 7
Training loss: 0.23625316692177387
Validation loss: 2.303026500207435

Epoch: 5| Step: 8
Training loss: 0.2366774318377927
Validation loss: 2.2815236329117865

Epoch: 5| Step: 9
Training loss: 0.20026945276464755
Validation loss: 2.294822227602936

Epoch: 5| Step: 10
Training loss: 0.3077183632753789
Validation loss: 2.3098827085658433

Epoch: 393| Step: 0
Training loss: 0.3006650279038155
Validation loss: 2.3159022232232362

Epoch: 5| Step: 1
Training loss: 0.2625708586559355
Validation loss: 2.3382511400149277

Epoch: 5| Step: 2
Training loss: 0.3049773524818652
Validation loss: 2.329875764829807

Epoch: 5| Step: 3
Training loss: 0.14877222618375524
Validation loss: 2.3511121800631063

Epoch: 5| Step: 4
Training loss: 0.2438335929484842
Validation loss: 2.377945575373402

Epoch: 5| Step: 5
Training loss: 0.2914136302719087
Validation loss: 2.3707265310537307

Epoch: 5| Step: 6
Training loss: 0.37146764290369394
Validation loss: 2.3936499670994276

Epoch: 5| Step: 7
Training loss: 0.4279214806860101
Validation loss: 2.3662443569637337

Epoch: 5| Step: 8
Training loss: 0.3833483623930887
Validation loss: 2.385380142590738

Epoch: 5| Step: 9
Training loss: 0.19499901409083334
Validation loss: 2.37501077050453

Epoch: 5| Step: 10
Training loss: 0.3585986583764403
Validation loss: 2.3288067644429997

Epoch: 394| Step: 0
Training loss: 0.13918814795873838
Validation loss: 2.322259500335858

Epoch: 5| Step: 1
Training loss: 0.2126772449900913
Validation loss: 2.3006913161814864

Epoch: 5| Step: 2
Training loss: 0.2256572247447024
Validation loss: 2.2876787867914037

Epoch: 5| Step: 3
Training loss: 0.40842045013635686
Validation loss: 2.3007941195270476

Epoch: 5| Step: 4
Training loss: 0.26385683707175933
Validation loss: 2.316649625262106

Epoch: 5| Step: 5
Training loss: 0.17741961431973743
Validation loss: 2.3271396994086215

Epoch: 5| Step: 6
Training loss: 0.33465021251618715
Validation loss: 2.3473097382861896

Epoch: 5| Step: 7
Training loss: 0.4168385886114361
Validation loss: 2.356073341548393

Epoch: 5| Step: 8
Training loss: 0.23226235629597153
Validation loss: 2.358426866322024

Epoch: 5| Step: 9
Training loss: 0.4807789119332596
Validation loss: 2.3655948203888055

Epoch: 5| Step: 10
Training loss: 0.17388351500892393
Validation loss: 2.388779714811035

Epoch: 395| Step: 0
Training loss: 0.3550356017985041
Validation loss: 2.3550174608487473

Epoch: 5| Step: 1
Training loss: 0.20979861705054215
Validation loss: 2.342871493516079

Epoch: 5| Step: 2
Training loss: 0.38025351042572353
Validation loss: 2.317514842631517

Epoch: 5| Step: 3
Training loss: 0.2993800607424755
Validation loss: 2.321079885607794

Epoch: 5| Step: 4
Training loss: 0.1358425194965599
Validation loss: 2.3249643446788015

Epoch: 5| Step: 5
Training loss: 0.22799943838970552
Validation loss: 2.290592606030366

Epoch: 5| Step: 6
Training loss: 0.33331108267350623
Validation loss: 2.282293586986443

Epoch: 5| Step: 7
Training loss: 0.26771532147312654
Validation loss: 2.2515981756777577

Epoch: 5| Step: 8
Training loss: 0.2531287687515571
Validation loss: 2.264764374358711

Epoch: 5| Step: 9
Training loss: 0.260755288584321
Validation loss: 2.3009765069705987

Epoch: 5| Step: 10
Training loss: 0.4806081988172278
Validation loss: 2.2902451373128287

Epoch: 396| Step: 0
Training loss: 0.3379505964210418
Validation loss: 2.2887741456583055

Epoch: 5| Step: 1
Training loss: 0.39268150676432384
Validation loss: 2.3326280184525134

Epoch: 5| Step: 2
Training loss: 0.2961034285037985
Validation loss: 2.341977820687074

Epoch: 5| Step: 3
Training loss: 0.3149194044367817
Validation loss: 2.337988163199127

Epoch: 5| Step: 4
Training loss: 0.24138070128714242
Validation loss: 2.3334284014459574

Epoch: 5| Step: 5
Training loss: 0.15629294520529505
Validation loss: 2.3668880746406336

Epoch: 5| Step: 6
Training loss: 0.38927793934071087
Validation loss: 2.3645185702310374

Epoch: 5| Step: 7
Training loss: 0.38097524592065424
Validation loss: 2.370957725526207

Epoch: 5| Step: 8
Training loss: 0.1773580192505363
Validation loss: 2.3719001751930304

Epoch: 5| Step: 9
Training loss: 0.25725896250383096
Validation loss: 2.378234944220841

Epoch: 5| Step: 10
Training loss: 0.2528441884818852
Validation loss: 2.357847366657456

Epoch: 397| Step: 0
Training loss: 0.20476244289773954
Validation loss: 2.3738088767425722

Epoch: 5| Step: 1
Training loss: 0.46390762955899556
Validation loss: 2.3926725370368653

Epoch: 5| Step: 2
Training loss: 0.3298330243461637
Validation loss: 2.372848130655936

Epoch: 5| Step: 3
Training loss: 0.3543010648334575
Validation loss: 2.3904174070058573

Epoch: 5| Step: 4
Training loss: 0.1819368940577217
Validation loss: 2.3667069328426433

Epoch: 5| Step: 5
Training loss: 0.10807716598736025
Validation loss: 2.3446306342088845

Epoch: 5| Step: 6
Training loss: 0.20215781738338798
Validation loss: 2.3088447991341594

Epoch: 5| Step: 7
Training loss: 0.20917354471428304
Validation loss: 2.3303537711410693

Epoch: 5| Step: 8
Training loss: 0.2239349439886594
Validation loss: 2.3368679329171447

Epoch: 5| Step: 9
Training loss: 0.4505298058676596
Validation loss: 2.340295412800013

Epoch: 5| Step: 10
Training loss: 0.28952140723439185
Validation loss: 2.3340577467434356

Epoch: 398| Step: 0
Training loss: 0.25720282917991755
Validation loss: 2.3437395813413002

Epoch: 5| Step: 1
Training loss: 0.3894080469793956
Validation loss: 2.345001429141869

Epoch: 5| Step: 2
Training loss: 0.36830055681456364
Validation loss: 2.3771833650272174

Epoch: 5| Step: 3
Training loss: 0.20050213260063468
Validation loss: 2.3819478570089374

Epoch: 5| Step: 4
Training loss: 0.3060148255778689
Validation loss: 2.4044731045361685

Epoch: 5| Step: 5
Training loss: 0.31664396704494335
Validation loss: 2.390667621603379

Epoch: 5| Step: 6
Training loss: 0.26130079231959624
Validation loss: 2.360755155451196

Epoch: 5| Step: 7
Training loss: 0.24892095065003625
Validation loss: 2.3615254386279685

Epoch: 5| Step: 8
Training loss: 0.3569088573729648
Validation loss: 2.3442242695584117

Epoch: 5| Step: 9
Training loss: 0.2743831087621702
Validation loss: 2.317698585533078

Epoch: 5| Step: 10
Training loss: 0.320205403078546
Validation loss: 2.3223619891870064

Epoch: 399| Step: 0
Training loss: 0.2714842789464547
Validation loss: 2.2929178605310376

Epoch: 5| Step: 1
Training loss: 0.3939189692149458
Validation loss: 2.3216251325683657

Epoch: 5| Step: 2
Training loss: 0.39116804522937954
Validation loss: 2.309640025476172

Epoch: 5| Step: 3
Training loss: 0.3079020558703338
Validation loss: 2.3339228573860957

Epoch: 5| Step: 4
Training loss: 0.3380647111616923
Validation loss: 2.3451561760041577

Epoch: 5| Step: 5
Training loss: 0.2266995903137638
Validation loss: 2.34832808112946

Epoch: 5| Step: 6
Training loss: 0.21136047200335414
Validation loss: 2.367636831102329

Epoch: 5| Step: 7
Training loss: 0.28977616594096633
Validation loss: 2.3582905074708007

Epoch: 5| Step: 8
Training loss: 0.2567077142592102
Validation loss: 2.347281660837971

Epoch: 5| Step: 9
Training loss: 0.38498977483448077
Validation loss: 2.359692836346741

Epoch: 5| Step: 10
Training loss: 0.15514526235123546
Validation loss: 2.3131935866559266

Epoch: 400| Step: 0
Training loss: 0.22195823746794854
Validation loss: 2.3029511039823625

Epoch: 5| Step: 1
Training loss: 0.37586111302629094
Validation loss: 2.3103299100997803

Epoch: 5| Step: 2
Training loss: 0.19508438140039547
Validation loss: 2.319664193465021

Epoch: 5| Step: 3
Training loss: 0.4140964889971239
Validation loss: 2.3439324650443556

Epoch: 5| Step: 4
Training loss: 0.20398071580904498
Validation loss: 2.310869687367624

Epoch: 5| Step: 5
Training loss: 0.37160260297697173
Validation loss: 2.325288289108513

Epoch: 5| Step: 6
Training loss: 0.28667601492983136
Validation loss: 2.33432673111309

Epoch: 5| Step: 7
Training loss: 0.19068201416261615
Validation loss: 2.3301950190610046

Epoch: 5| Step: 8
Training loss: 0.20388405448867683
Validation loss: 2.31021786676316

Epoch: 5| Step: 9
Training loss: 0.25545854693928416
Validation loss: 2.3213940237756723

Epoch: 5| Step: 10
Training loss: 0.29765141751028573
Validation loss: 2.314902423754908

Epoch: 401| Step: 0
Training loss: 0.23143399689773977
Validation loss: 2.2787398641612877

Epoch: 5| Step: 1
Training loss: 0.23506137955603185
Validation loss: 2.291745781208743

Epoch: 5| Step: 2
Training loss: 0.3602836979175622
Validation loss: 2.2966763269074315

Epoch: 5| Step: 3
Training loss: 0.38952256083982284
Validation loss: 2.3112254578426814

Epoch: 5| Step: 4
Training loss: 0.17487040941172372
Validation loss: 2.3108719236062742

Epoch: 5| Step: 5
Training loss: 0.27912824381742724
Validation loss: 2.31284282341539

Epoch: 5| Step: 6
Training loss: 0.37663908215317343
Validation loss: 2.319883983513207

Epoch: 5| Step: 7
Training loss: 0.2975233301864153
Validation loss: 2.3186920121173897

Epoch: 5| Step: 8
Training loss: 0.1685973536660429
Validation loss: 2.3107409118157727

Epoch: 5| Step: 9
Training loss: 0.24994710273210052
Validation loss: 2.321307354669308

Epoch: 5| Step: 10
Training loss: 0.29537180501878335
Validation loss: 2.318856776673242

Epoch: 402| Step: 0
Training loss: 0.30917648631864725
Validation loss: 2.288488394254215

Epoch: 5| Step: 1
Training loss: 0.27141906446688646
Validation loss: 2.307547000127311

Epoch: 5| Step: 2
Training loss: 0.31508059715627257
Validation loss: 2.3031736318148064

Epoch: 5| Step: 3
Training loss: 0.3322434364442661
Validation loss: 2.274986428147412

Epoch: 5| Step: 4
Training loss: 0.17375394224078722
Validation loss: 2.2493463532989666

Epoch: 5| Step: 5
Training loss: 0.40041087029608663
Validation loss: 2.257432922392237

Epoch: 5| Step: 6
Training loss: 0.1281077405306763
Validation loss: 2.285386465638128

Epoch: 5| Step: 7
Training loss: 0.2801145974091228
Validation loss: 2.285477622009706

Epoch: 5| Step: 8
Training loss: 0.2260354093192416
Validation loss: 2.277070790465798

Epoch: 5| Step: 9
Training loss: 0.1752350958708563
Validation loss: 2.289729078025547

Epoch: 5| Step: 10
Training loss: 0.3243166879011182
Validation loss: 2.2847761546417704

Epoch: 403| Step: 0
Training loss: 0.2897563931209946
Validation loss: 2.3243172419005753

Epoch: 5| Step: 1
Training loss: 0.13130002062033647
Validation loss: 2.316022214299591

Epoch: 5| Step: 2
Training loss: 0.21217334723992456
Validation loss: 2.3018531530189814

Epoch: 5| Step: 3
Training loss: 0.12669068867745395
Validation loss: 2.3487892803999806

Epoch: 5| Step: 4
Training loss: 0.1878246437374023
Validation loss: 2.3087961522415643

Epoch: 5| Step: 5
Training loss: 0.31599346361386665
Validation loss: 2.283561393587119

Epoch: 5| Step: 6
Training loss: 0.4576263954320543
Validation loss: 2.3051093498073767

Epoch: 5| Step: 7
Training loss: 0.28904328411257024
Validation loss: 2.3263885514780442

Epoch: 5| Step: 8
Training loss: 0.32049136866404543
Validation loss: 2.314008269127684

Epoch: 5| Step: 9
Training loss: 0.30976422370891943
Validation loss: 2.338675331914445

Epoch: 5| Step: 10
Training loss: 0.23415174977778788
Validation loss: 2.326974869746299

Epoch: 404| Step: 0
Training loss: 0.17786819534394893
Validation loss: 2.295384256791576

Epoch: 5| Step: 1
Training loss: 0.2595477086451621
Validation loss: 2.2915999295612357

Epoch: 5| Step: 2
Training loss: 0.3528661504994556
Validation loss: 2.3292303242572276

Epoch: 5| Step: 3
Training loss: 0.3163092900286481
Validation loss: 2.3127243389918686

Epoch: 5| Step: 4
Training loss: 0.46447768342947
Validation loss: 2.311272466908144

Epoch: 5| Step: 5
Training loss: 0.1842274382453837
Validation loss: 2.364092271482053

Epoch: 5| Step: 6
Training loss: 0.3145744374051066
Validation loss: 2.343728528214957

Epoch: 5| Step: 7
Training loss: 0.13314537799034915
Validation loss: 2.3547095274430965

Epoch: 5| Step: 8
Training loss: 0.12449765593455384
Validation loss: 2.3616832117160604

Epoch: 5| Step: 9
Training loss: 0.20713434711308376
Validation loss: 2.359908724518494

Epoch: 5| Step: 10
Training loss: 0.24004001818995113
Validation loss: 2.362917673145961

Epoch: 405| Step: 0
Training loss: 0.2918438231503544
Validation loss: 2.3494779318015095

Epoch: 5| Step: 1
Training loss: 0.25481179954501776
Validation loss: 2.3397835949699366

Epoch: 5| Step: 2
Training loss: 0.2725431666831319
Validation loss: 2.30939813502089

Epoch: 5| Step: 3
Training loss: 0.286207456259097
Validation loss: 2.3440542016817147

Epoch: 5| Step: 4
Training loss: 0.2703700213888813
Validation loss: 2.3484856964242473

Epoch: 5| Step: 5
Training loss: 0.29710652709366386
Validation loss: 2.3412540547703093

Epoch: 5| Step: 6
Training loss: 0.26013076187692535
Validation loss: 2.3511693613097853

Epoch: 5| Step: 7
Training loss: 0.294588936840559
Validation loss: 2.337667233802787

Epoch: 5| Step: 8
Training loss: 0.20049403164249613
Validation loss: 2.3409290885239473

Epoch: 5| Step: 9
Training loss: 0.29611607218319647
Validation loss: 2.338151107423784

Epoch: 5| Step: 10
Training loss: 0.2626528226956723
Validation loss: 2.328440254286174

Epoch: 406| Step: 0
Training loss: 0.38840275941324254
Validation loss: 2.2876403718454217

Epoch: 5| Step: 1
Training loss: 0.3313654226165939
Validation loss: 2.257500131087601

Epoch: 5| Step: 2
Training loss: 0.40852514825263453
Validation loss: 2.2927079960630294

Epoch: 5| Step: 3
Training loss: 0.2578391292575472
Validation loss: 2.2689380454710224

Epoch: 5| Step: 4
Training loss: 0.1509564765113512
Validation loss: 2.232578016507996

Epoch: 5| Step: 5
Training loss: 0.3307473210235654
Validation loss: 2.276885748901776

Epoch: 5| Step: 6
Training loss: 0.18085694198125357
Validation loss: 2.313498502329038

Epoch: 5| Step: 7
Training loss: 0.25213001754223874
Validation loss: 2.2893286114988713

Epoch: 5| Step: 8
Training loss: 0.21588606717357176
Validation loss: 2.3209104977551664

Epoch: 5| Step: 9
Training loss: 0.1950028826427135
Validation loss: 2.3359516684014374

Epoch: 5| Step: 10
Training loss: 0.20903715019892544
Validation loss: 2.3195810942341724

Epoch: 407| Step: 0
Training loss: 0.22898625547794593
Validation loss: 2.322186638997017

Epoch: 5| Step: 1
Training loss: 0.2863567634613718
Validation loss: 2.3538690119847434

Epoch: 5| Step: 2
Training loss: 0.323815830765797
Validation loss: 2.3212622915957

Epoch: 5| Step: 3
Training loss: 0.17512898757868356
Validation loss: 2.319118053795536

Epoch: 5| Step: 4
Training loss: 0.23588270188904095
Validation loss: 2.3388627910245146

Epoch: 5| Step: 5
Training loss: 0.31332297439690493
Validation loss: 2.3193206683672543

Epoch: 5| Step: 6
Training loss: 0.3477037590225755
Validation loss: 2.301842756335185

Epoch: 5| Step: 7
Training loss: 0.3991681113479104
Validation loss: 2.3351256987212676

Epoch: 5| Step: 8
Training loss: 0.2963697752280872
Validation loss: 2.327848832242613

Epoch: 5| Step: 9
Training loss: 0.16037216402662333
Validation loss: 2.361992599630546

Epoch: 5| Step: 10
Training loss: 0.24087128297049093
Validation loss: 2.346626342343543

Epoch: 408| Step: 0
Training loss: 0.27599286451739097
Validation loss: 2.349398590521949

Epoch: 5| Step: 1
Training loss: 0.2607758746727402
Validation loss: 2.368684083122796

Epoch: 5| Step: 2
Training loss: 0.40513978155983194
Validation loss: 2.3289624959891824

Epoch: 5| Step: 3
Training loss: 0.312279933690374
Validation loss: 2.2890409340984044

Epoch: 5| Step: 4
Training loss: 0.21044950197559248
Validation loss: 2.3016924574743616

Epoch: 5| Step: 5
Training loss: 0.25165643892810474
Validation loss: 2.2625232118594183

Epoch: 5| Step: 6
Training loss: 0.3204794309185537
Validation loss: 2.261087218243842

Epoch: 5| Step: 7
Training loss: 0.23647819042152732
Validation loss: 2.2803969300415488

Epoch: 5| Step: 8
Training loss: 0.24240871294134322
Validation loss: 2.322138865004964

Epoch: 5| Step: 9
Training loss: 0.1736590280899268
Validation loss: 2.29706358022099

Epoch: 5| Step: 10
Training loss: 0.428992663296295
Validation loss: 2.334387851515035

Epoch: 409| Step: 0
Training loss: 0.310084052054459
Validation loss: 2.3581459360846395

Epoch: 5| Step: 1
Training loss: 0.3015807413108567
Validation loss: 2.3471666848366066

Epoch: 5| Step: 2
Training loss: 0.19281980581059732
Validation loss: 2.3735285574076808

Epoch: 5| Step: 3
Training loss: 0.4242969328490969
Validation loss: 2.3842993788235325

Epoch: 5| Step: 4
Training loss: 0.33771456282437795
Validation loss: 2.3475007839097386

Epoch: 5| Step: 5
Training loss: 0.15408822329459654
Validation loss: 2.31719297067197

Epoch: 5| Step: 6
Training loss: 0.2890429361269773
Validation loss: 2.2783556400335927

Epoch: 5| Step: 7
Training loss: 0.5485582332908027
Validation loss: 2.2656150605489707

Epoch: 5| Step: 8
Training loss: 0.5377248670698173
Validation loss: 2.259371062063005

Epoch: 5| Step: 9
Training loss: 0.212558504774262
Validation loss: 2.2975718016311304

Epoch: 5| Step: 10
Training loss: 0.5562992856340143
Validation loss: 2.336020959261823

Epoch: 410| Step: 0
Training loss: 0.3363693699374426
Validation loss: 2.347133628330351

Epoch: 5| Step: 1
Training loss: 0.37071726925780973
Validation loss: 2.3211304216109103

Epoch: 5| Step: 2
Training loss: 0.5723968199240386
Validation loss: 2.2542702306381774

Epoch: 5| Step: 3
Training loss: 0.38490382002552576
Validation loss: 2.2116927654132494

Epoch: 5| Step: 4
Training loss: 0.4111443742227319
Validation loss: 2.1908247566285395

Epoch: 5| Step: 5
Training loss: 0.4412432513112647
Validation loss: 2.239493233503584

Epoch: 5| Step: 6
Training loss: 0.44476637898670524
Validation loss: 2.255390456483285

Epoch: 5| Step: 7
Training loss: 0.4341444007169785
Validation loss: 2.3145579643037344

Epoch: 5| Step: 8
Training loss: 0.39783132480092476
Validation loss: 2.3704265228663512

Epoch: 5| Step: 9
Training loss: 0.3264821113312606
Validation loss: 2.430841612929385

Epoch: 5| Step: 10
Training loss: 0.5059752460463494
Validation loss: 2.4786760229539486

Epoch: 411| Step: 0
Training loss: 0.4506681197827705
Validation loss: 2.432944551640331

Epoch: 5| Step: 1
Training loss: 0.3119034318061861
Validation loss: 2.361712221633202

Epoch: 5| Step: 2
Training loss: 0.4464798567469038
Validation loss: 2.3225030017992645

Epoch: 5| Step: 3
Training loss: 0.4187809904217405
Validation loss: 2.244615098520489

Epoch: 5| Step: 4
Training loss: 0.39228458722628595
Validation loss: 2.20138188773962

Epoch: 5| Step: 5
Training loss: 0.5625872014588497
Validation loss: 2.2057762405872356

Epoch: 5| Step: 6
Training loss: 0.39587283773888693
Validation loss: 2.2066268290460544

Epoch: 5| Step: 7
Training loss: 0.25593050484884994
Validation loss: 2.2660952619255785

Epoch: 5| Step: 8
Training loss: 0.26558857555849386
Validation loss: 2.291009256776678

Epoch: 5| Step: 9
Training loss: 0.49262455805342703
Validation loss: 2.355090482111067

Epoch: 5| Step: 10
Training loss: 0.42081466513795845
Validation loss: 2.395833728535224

Epoch: 412| Step: 0
Training loss: 0.47360710782173593
Validation loss: 2.4133060357419533

Epoch: 5| Step: 1
Training loss: 0.3514720906461531
Validation loss: 2.4286601879437932

Epoch: 5| Step: 2
Training loss: 0.42933059087920417
Validation loss: 2.3809615734614336

Epoch: 5| Step: 3
Training loss: 0.331308689406393
Validation loss: 2.3308818731136096

Epoch: 5| Step: 4
Training loss: 0.4201784990973101
Validation loss: 2.3310455994739656

Epoch: 5| Step: 5
Training loss: 0.3999563513723018
Validation loss: 2.2905073960797373

Epoch: 5| Step: 6
Training loss: 0.37838329525497505
Validation loss: 2.2793937173476726

Epoch: 5| Step: 7
Training loss: 0.2578547327534145
Validation loss: 2.2868407082463063

Epoch: 5| Step: 8
Training loss: 0.4356230596447151
Validation loss: 2.3522326181977036

Epoch: 5| Step: 9
Training loss: 0.2851462297116072
Validation loss: 2.3668505881269137

Epoch: 5| Step: 10
Training loss: 0.39177403255063503
Validation loss: 2.385654495820626

Epoch: 413| Step: 0
Training loss: 0.271851613694138
Validation loss: 2.3612726994313573

Epoch: 5| Step: 1
Training loss: 0.3705782471963927
Validation loss: 2.3481645853954336

Epoch: 5| Step: 2
Training loss: 0.40972679907007925
Validation loss: 2.332573053398846

Epoch: 5| Step: 3
Training loss: 0.4288204635405518
Validation loss: 2.3345747044746465

Epoch: 5| Step: 4
Training loss: 0.35019565418437365
Validation loss: 2.32856897114106

Epoch: 5| Step: 5
Training loss: 0.39316613490036506
Validation loss: 2.299538748735513

Epoch: 5| Step: 6
Training loss: 0.41127779979720924
Validation loss: 2.349127581087224

Epoch: 5| Step: 7
Training loss: 0.2848830547407578
Validation loss: 2.391453632012196

Epoch: 5| Step: 8
Training loss: 0.5479506132780831
Validation loss: 2.3791813917849955

Epoch: 5| Step: 9
Training loss: 0.34612910647658185
Validation loss: 2.3619651688646686

Epoch: 5| Step: 10
Training loss: 0.3539570323560193
Validation loss: 2.332419276473513

Epoch: 414| Step: 0
Training loss: 0.35077041830148686
Validation loss: 2.3526396819810333

Epoch: 5| Step: 1
Training loss: 0.43139290929585583
Validation loss: 2.2882725890802167

Epoch: 5| Step: 2
Training loss: 0.3032285287383609
Validation loss: 2.319432370903953

Epoch: 5| Step: 3
Training loss: 0.3850028376660489
Validation loss: 2.3246391635182544

Epoch: 5| Step: 4
Training loss: 0.49062495990923094
Validation loss: 2.372837377885497

Epoch: 5| Step: 5
Training loss: 0.3384831915997034
Validation loss: 2.313354263449761

Epoch: 5| Step: 6
Training loss: 0.3544775799560607
Validation loss: 2.2447558638251417

Epoch: 5| Step: 7
Training loss: 0.3089601538577282
Validation loss: 2.2299209766024486

Epoch: 5| Step: 8
Training loss: 0.542593984461354
Validation loss: 2.2052336740883067

Epoch: 5| Step: 9
Training loss: 0.4035034872114716
Validation loss: 2.192315451934236

Epoch: 5| Step: 10
Training loss: 0.48978917549480894
Validation loss: 2.2017965693541535

Epoch: 415| Step: 0
Training loss: 0.33167357533813774
Validation loss: 2.260224519943002

Epoch: 5| Step: 1
Training loss: 0.2710894449645229
Validation loss: 2.267356673011665

Epoch: 5| Step: 2
Training loss: 0.4614839385989431
Validation loss: 2.307414768503261

Epoch: 5| Step: 3
Training loss: 0.4564717772764664
Validation loss: 2.333660969240395

Epoch: 5| Step: 4
Training loss: 0.48111786452661515
Validation loss: 2.3736161916051786

Epoch: 5| Step: 5
Training loss: 0.27397329424969236
Validation loss: 2.358596617944309

Epoch: 5| Step: 6
Training loss: 0.2279716194892576
Validation loss: 2.2920917146637856

Epoch: 5| Step: 7
Training loss: 0.4453306027129303
Validation loss: 2.300162600471666

Epoch: 5| Step: 8
Training loss: 0.7211930591974964
Validation loss: 2.3055344310393515

Epoch: 5| Step: 9
Training loss: 0.39164794494983884
Validation loss: 2.3972707095305448

Epoch: 5| Step: 10
Training loss: 0.31528715332354595
Validation loss: 2.398114140020698

Epoch: 416| Step: 0
Training loss: 0.3188106404384695
Validation loss: 2.39607800861235

Epoch: 5| Step: 1
Training loss: 0.4654116167217419
Validation loss: 2.3971833529530397

Epoch: 5| Step: 2
Training loss: 0.3139951818826974
Validation loss: 2.407535438163048

Epoch: 5| Step: 3
Training loss: 0.5492022179493499
Validation loss: 2.4404619162406003

Epoch: 5| Step: 4
Training loss: 0.2882490956845618
Validation loss: 2.344505060456844

Epoch: 5| Step: 5
Training loss: 0.2525222619317922
Validation loss: 2.2972937843855346

Epoch: 5| Step: 6
Training loss: 0.2552566125837053
Validation loss: 2.2761942408079774

Epoch: 5| Step: 7
Training loss: 0.42580683220120824
Validation loss: 2.259437365249801

Epoch: 5| Step: 8
Training loss: 0.3117394371147517
Validation loss: 2.2666920503821264

Epoch: 5| Step: 9
Training loss: 0.27144380993659833
Validation loss: 2.28350658121767

Epoch: 5| Step: 10
Training loss: 0.3324341853514962
Validation loss: 2.309554715730331

Epoch: 417| Step: 0
Training loss: 0.32291201875274456
Validation loss: 2.3390720117868105

Epoch: 5| Step: 1
Training loss: 0.2796623266601912
Validation loss: 2.371906467825468

Epoch: 5| Step: 2
Training loss: 0.28050250485180694
Validation loss: 2.3855026689233187

Epoch: 5| Step: 3
Training loss: 0.28436984749202865
Validation loss: 2.3814150575748245

Epoch: 5| Step: 4
Training loss: 0.39508731293512883
Validation loss: 2.350591729876455

Epoch: 5| Step: 5
Training loss: 0.4033173752647756
Validation loss: 2.312392781351481

Epoch: 5| Step: 6
Training loss: 0.40731925732689783
Validation loss: 2.3024699364842447

Epoch: 5| Step: 7
Training loss: 0.3319049707267207
Validation loss: 2.318835589511401

Epoch: 5| Step: 8
Training loss: 0.3534121915287621
Validation loss: 2.3119998769111114

Epoch: 5| Step: 9
Training loss: 0.253704842133751
Validation loss: 2.2891225432110516

Epoch: 5| Step: 10
Training loss: 0.21908252850340323
Validation loss: 2.3428946429348527

Epoch: 418| Step: 0
Training loss: 0.42545232404198957
Validation loss: 2.4189365075199727

Epoch: 5| Step: 1
Training loss: 0.2913691018897399
Validation loss: 2.3967808765520315

Epoch: 5| Step: 2
Training loss: 0.3078625502777647
Validation loss: 2.4296844327298133

Epoch: 5| Step: 3
Training loss: 0.33481321052275065
Validation loss: 2.489206926048601

Epoch: 5| Step: 4
Training loss: 0.24792196477844033
Validation loss: 2.4042528012026336

Epoch: 5| Step: 5
Training loss: 0.33671630362841193
Validation loss: 2.3948403596411576

Epoch: 5| Step: 6
Training loss: 0.2641227258475124
Validation loss: 2.370199935634542

Epoch: 5| Step: 7
Training loss: 0.16579187124565978
Validation loss: 2.3578800207160477

Epoch: 5| Step: 8
Training loss: 0.2867729265755771
Validation loss: 2.3275583159360953

Epoch: 5| Step: 9
Training loss: 0.18552135492801614
Validation loss: 2.3037486877521354

Epoch: 5| Step: 10
Training loss: 0.30120592976165783
Validation loss: 2.2803322045295644

Epoch: 419| Step: 0
Training loss: 0.1867581433674463
Validation loss: 2.289662224169982

Epoch: 5| Step: 1
Training loss: 0.16385534241414756
Validation loss: 2.2649169901882966

Epoch: 5| Step: 2
Training loss: 0.3085556972558131
Validation loss: 2.253644114346637

Epoch: 5| Step: 3
Training loss: 0.42078378624900703
Validation loss: 2.245884189040947

Epoch: 5| Step: 4
Training loss: 0.2353335409268764
Validation loss: 2.2652651290600105

Epoch: 5| Step: 5
Training loss: 0.3120256877512291
Validation loss: 2.2240686514384738

Epoch: 5| Step: 6
Training loss: 0.23236435891791551
Validation loss: 2.305546643005625

Epoch: 5| Step: 7
Training loss: 0.3573326458058457
Validation loss: 2.3211523653030484

Epoch: 5| Step: 8
Training loss: 0.3328695709474811
Validation loss: 2.3160478021678834

Epoch: 5| Step: 9
Training loss: 0.28599690930157035
Validation loss: 2.326221464468232

Epoch: 5| Step: 10
Training loss: 0.19634279303322824
Validation loss: 2.286859499607436

Epoch: 420| Step: 0
Training loss: 0.24714642886410784
Validation loss: 2.3160796735647846

Epoch: 5| Step: 1
Training loss: 0.17911723077726688
Validation loss: 2.268312840469936

Epoch: 5| Step: 2
Training loss: 0.2390474991050017
Validation loss: 2.29202351033879

Epoch: 5| Step: 3
Training loss: 0.40308925854645367
Validation loss: 2.272351830777333

Epoch: 5| Step: 4
Training loss: 0.19096485157431559
Validation loss: 2.2555495873131197

Epoch: 5| Step: 5
Training loss: 0.19731654086066944
Validation loss: 2.2856685574958453

Epoch: 5| Step: 6
Training loss: 0.24999333909221097
Validation loss: 2.2797036587604813

Epoch: 5| Step: 7
Training loss: 0.32137668423561855
Validation loss: 2.2453118577060613

Epoch: 5| Step: 8
Training loss: 0.32408702426471897
Validation loss: 2.2475474378989015

Epoch: 5| Step: 9
Training loss: 0.3101472022132562
Validation loss: 2.26087234559327

Epoch: 5| Step: 10
Training loss: 0.17457466868652247
Validation loss: 2.3040638113979806

Epoch: 421| Step: 0
Training loss: 0.2369417153971865
Validation loss: 2.3173737720807717

Epoch: 5| Step: 1
Training loss: 0.2747662141135774
Validation loss: 2.3104356921325

Epoch: 5| Step: 2
Training loss: 0.26939665156395476
Validation loss: 2.33933496648703

Epoch: 5| Step: 3
Training loss: 0.18949617309719632
Validation loss: 2.3557428660222772

Epoch: 5| Step: 4
Training loss: 0.3121249093592966
Validation loss: 2.352784956732219

Epoch: 5| Step: 5
Training loss: 0.2024718935616916
Validation loss: 2.3353925357286287

Epoch: 5| Step: 6
Training loss: 0.17639834909172045
Validation loss: 2.3398679395491455

Epoch: 5| Step: 7
Training loss: 0.19716784442748428
Validation loss: 2.308593723348548

Epoch: 5| Step: 8
Training loss: 0.2555670050561906
Validation loss: 2.336057629076975

Epoch: 5| Step: 9
Training loss: 0.35065442534678165
Validation loss: 2.3538580979099857

Epoch: 5| Step: 10
Training loss: 0.441241343253917
Validation loss: 2.3428331584903463

Epoch: 422| Step: 0
Training loss: 0.3443186781047308
Validation loss: 2.3104484734857746

Epoch: 5| Step: 1
Training loss: 0.276737921517541
Validation loss: 2.3151857322119094

Epoch: 5| Step: 2
Training loss: 0.36402075368540904
Validation loss: 2.3070609403435838

Epoch: 5| Step: 3
Training loss: 0.2543577288404407
Validation loss: 2.2969550667868748

Epoch: 5| Step: 4
Training loss: 0.21452911920454779
Validation loss: 2.340127511702501

Epoch: 5| Step: 5
Training loss: 0.27268647187638284
Validation loss: 2.3212022834478563

Epoch: 5| Step: 6
Training loss: 0.1672088489092798
Validation loss: 2.3193576461561864

Epoch: 5| Step: 7
Training loss: 0.15974685633316787
Validation loss: 2.3199550424722277

Epoch: 5| Step: 8
Training loss: 0.23589375671452606
Validation loss: 2.32718104091091

Epoch: 5| Step: 9
Training loss: 0.3302595892495113
Validation loss: 2.3107043930258304

Epoch: 5| Step: 10
Training loss: 0.1413796560560443
Validation loss: 2.306093607160547

Epoch: 423| Step: 0
Training loss: 0.17252461174906156
Validation loss: 2.3200470666315463

Epoch: 5| Step: 1
Training loss: 0.34378006110095427
Validation loss: 2.346648963110297

Epoch: 5| Step: 2
Training loss: 0.23986716233837826
Validation loss: 2.311247907089535

Epoch: 5| Step: 3
Training loss: 0.33037242522663446
Validation loss: 2.3311976376471675

Epoch: 5| Step: 4
Training loss: 0.3220511213869123
Validation loss: 2.3190398261740253

Epoch: 5| Step: 5
Training loss: 0.23284202554873362
Validation loss: 2.288767908970193

Epoch: 5| Step: 6
Training loss: 0.15246756119722998
Validation loss: 2.3302439717335415

Epoch: 5| Step: 7
Training loss: 0.2572211940613579
Validation loss: 2.325758867006145

Epoch: 5| Step: 8
Training loss: 0.25253129019286696
Validation loss: 2.329001715919473

Epoch: 5| Step: 9
Training loss: 0.2990411983624695
Validation loss: 2.3479934468513752

Epoch: 5| Step: 10
Training loss: 0.2183127887553553
Validation loss: 2.322132029028692

Epoch: 424| Step: 0
Training loss: 0.2996329396516417
Validation loss: 2.334849578203891

Epoch: 5| Step: 1
Training loss: 0.2651072252143341
Validation loss: 2.3041565269700017

Epoch: 5| Step: 2
Training loss: 0.20433512925805103
Validation loss: 2.3709253899872085

Epoch: 5| Step: 3
Training loss: 0.3004719766650868
Validation loss: 2.3547442598206705

Epoch: 5| Step: 4
Training loss: 0.33838061267593156
Validation loss: 2.355748152197859

Epoch: 5| Step: 5
Training loss: 0.22554455827633774
Validation loss: 2.331437983306168

Epoch: 5| Step: 6
Training loss: 0.2973737417301081
Validation loss: 2.3384908714526795

Epoch: 5| Step: 7
Training loss: 0.1710813415504383
Validation loss: 2.3094109787307824

Epoch: 5| Step: 8
Training loss: 0.27330064073345145
Validation loss: 2.3152393561036724

Epoch: 5| Step: 9
Training loss: 0.21904059250214897
Validation loss: 2.292925338165064

Epoch: 5| Step: 10
Training loss: 0.1917104930545302
Validation loss: 2.3006051007232164

Epoch: 425| Step: 0
Training loss: 0.2152487838269921
Validation loss: 2.2900350396643785

Epoch: 5| Step: 1
Training loss: 0.2370874721585409
Validation loss: 2.261479225590643

Epoch: 5| Step: 2
Training loss: 0.32092020491491385
Validation loss: 2.3266929003765076

Epoch: 5| Step: 3
Training loss: 0.2253940476235356
Validation loss: 2.328766920345862

Epoch: 5| Step: 4
Training loss: 0.13180617243699247
Validation loss: 2.3041859226445425

Epoch: 5| Step: 5
Training loss: 0.219690964252295
Validation loss: 2.325230180335308

Epoch: 5| Step: 6
Training loss: 0.29523106971136165
Validation loss: 2.3308128603598743

Epoch: 5| Step: 7
Training loss: 0.2997119896939397
Validation loss: 2.3231228038414584

Epoch: 5| Step: 8
Training loss: 0.2651934483994033
Validation loss: 2.3672508952257876

Epoch: 5| Step: 9
Training loss: 0.25910216769788
Validation loss: 2.335452714946469

Epoch: 5| Step: 10
Training loss: 0.2078126071987019
Validation loss: 2.3770435977415234

Epoch: 426| Step: 0
Training loss: 0.2711267517186265
Validation loss: 2.3698123974700755

Epoch: 5| Step: 1
Training loss: 0.17375172854325274
Validation loss: 2.3245845295554823

Epoch: 5| Step: 2
Training loss: 0.3087261254041348
Validation loss: 2.337698480903906

Epoch: 5| Step: 3
Training loss: 0.4100737715853605
Validation loss: 2.3370994503695757

Epoch: 5| Step: 4
Training loss: 0.19959880069262947
Validation loss: 2.361401172589921

Epoch: 5| Step: 5
Training loss: 0.15307457784647144
Validation loss: 2.2830671725061698

Epoch: 5| Step: 6
Training loss: 0.1847993751331598
Validation loss: 2.292336182850804

Epoch: 5| Step: 7
Training loss: 0.19318608504634588
Validation loss: 2.296562335942175

Epoch: 5| Step: 8
Training loss: 0.1863166601624496
Validation loss: 2.2913139414872425

Epoch: 5| Step: 9
Training loss: 0.19136266796087995
Validation loss: 2.2824044154767775

Epoch: 5| Step: 10
Training loss: 0.2851551134269743
Validation loss: 2.289343908776738

Epoch: 427| Step: 0
Training loss: 0.40842630591372
Validation loss: 2.2739958186618248

Epoch: 5| Step: 1
Training loss: 0.20856085314284806
Validation loss: 2.280684482088103

Epoch: 5| Step: 2
Training loss: 0.2633996759414128
Validation loss: 2.29481481368287

Epoch: 5| Step: 3
Training loss: 0.1852776230193119
Validation loss: 2.294461588853565

Epoch: 5| Step: 4
Training loss: 0.11321919073171222
Validation loss: 2.3335737263506124

Epoch: 5| Step: 5
Training loss: 0.32018746284858446
Validation loss: 2.3340539771615654

Epoch: 5| Step: 6
Training loss: 0.26292728264853255
Validation loss: 2.3084193329787204

Epoch: 5| Step: 7
Training loss: 0.21387978956465717
Validation loss: 2.3249235106875457

Epoch: 5| Step: 8
Training loss: 0.11937911755515761
Validation loss: 2.2766254506405366

Epoch: 5| Step: 9
Training loss: 0.21803258009126658
Validation loss: 2.3143767069806636

Epoch: 5| Step: 10
Training loss: 0.11152174909953724
Validation loss: 2.315246103363479

Epoch: 428| Step: 0
Training loss: 0.13716081268446362
Validation loss: 2.31528874789374

Epoch: 5| Step: 1
Training loss: 0.3961310856244254
Validation loss: 2.308708362834268

Epoch: 5| Step: 2
Training loss: 0.13561360011335372
Validation loss: 2.3054791858865697

Epoch: 5| Step: 3
Training loss: 0.24684188294709722
Validation loss: 2.300137037623842

Epoch: 5| Step: 4
Training loss: 0.35598660569897905
Validation loss: 2.3106197882793853

Epoch: 5| Step: 5
Training loss: 0.15527643044904102
Validation loss: 2.3161050344421863

Epoch: 5| Step: 6
Training loss: 0.17208068093313944
Validation loss: 2.310800503792004

Epoch: 5| Step: 7
Training loss: 0.18694053071861194
Validation loss: 2.3194756563391454

Epoch: 5| Step: 8
Training loss: 0.2235403077818093
Validation loss: 2.350270717337964

Epoch: 5| Step: 9
Training loss: 0.197647075289364
Validation loss: 2.2886607412406463

Epoch: 5| Step: 10
Training loss: 0.23136000529832193
Validation loss: 2.3020870019581605

Epoch: 429| Step: 0
Training loss: 0.3939374666657298
Validation loss: 2.2936977119316886

Epoch: 5| Step: 1
Training loss: 0.24864548817916798
Validation loss: 2.280791237227237

Epoch: 5| Step: 2
Training loss: 0.3581221344385459
Validation loss: 2.300428396350797

Epoch: 5| Step: 3
Training loss: 0.29157198777048043
Validation loss: 2.2911209023369414

Epoch: 5| Step: 4
Training loss: 0.1537375210237446
Validation loss: 2.2822615880608157

Epoch: 5| Step: 5
Training loss: 0.22362863128618019
Validation loss: 2.2516236258020603

Epoch: 5| Step: 6
Training loss: 0.1549172123906139
Validation loss: 2.26189613174484

Epoch: 5| Step: 7
Training loss: 0.1566282759766808
Validation loss: 2.281268776167218

Epoch: 5| Step: 8
Training loss: 0.1699443396703236
Validation loss: 2.239345749894659

Epoch: 5| Step: 9
Training loss: 0.211125034397206
Validation loss: 2.2588387494720363

Epoch: 5| Step: 10
Training loss: 0.0913625649452631
Validation loss: 2.2455094000445053

Epoch: 430| Step: 0
Training loss: 0.1675254828014171
Validation loss: 2.256621203080989

Epoch: 5| Step: 1
Training loss: 0.3320817123662299
Validation loss: 2.284165406720955

Epoch: 5| Step: 2
Training loss: 0.1257606104390041
Validation loss: 2.2780635424214313

Epoch: 5| Step: 3
Training loss: 0.13411784322412468
Validation loss: 2.3046061428275877

Epoch: 5| Step: 4
Training loss: 0.21819505804319472
Validation loss: 2.3022980592412114

Epoch: 5| Step: 5
Training loss: 0.10815400840428031
Validation loss: 2.31700182870433

Epoch: 5| Step: 6
Training loss: 0.3555183795196382
Validation loss: 2.2882699417180294

Epoch: 5| Step: 7
Training loss: 0.23153095029146575
Validation loss: 2.322639988713785

Epoch: 5| Step: 8
Training loss: 0.2705876890059448
Validation loss: 2.2763026678168097

Epoch: 5| Step: 9
Training loss: 0.2913547945998927
Validation loss: 2.27430263440716

Epoch: 5| Step: 10
Training loss: 0.22188597168457602
Validation loss: 2.2476522372396017

Epoch: 431| Step: 0
Training loss: 0.09663602054762677
Validation loss: 2.2430524837987136

Epoch: 5| Step: 1
Training loss: 0.1493276395994406
Validation loss: 2.2434693703627566

Epoch: 5| Step: 2
Training loss: 0.2561265555055745
Validation loss: 2.2798706258226678

Epoch: 5| Step: 3
Training loss: 0.1849116041057202
Validation loss: 2.269328850009772

Epoch: 5| Step: 4
Training loss: 0.23713368663551948
Validation loss: 2.259503973968499

Epoch: 5| Step: 5
Training loss: 0.17416004573197777
Validation loss: 2.2488366871718575

Epoch: 5| Step: 6
Training loss: 0.41237420345829595
Validation loss: 2.272953312429362

Epoch: 5| Step: 7
Training loss: 0.1739545212592575
Validation loss: 2.276109232952908

Epoch: 5| Step: 8
Training loss: 0.2919918047542041
Validation loss: 2.306361543421442

Epoch: 5| Step: 9
Training loss: 0.27576481983638534
Validation loss: 2.324466037598512

Epoch: 5| Step: 10
Training loss: 0.15892770047603566
Validation loss: 2.291667559186327

Epoch: 432| Step: 0
Training loss: 0.1238711992189784
Validation loss: 2.3439666177601333

Epoch: 5| Step: 1
Training loss: 0.28251671313328447
Validation loss: 2.3351162910044474

Epoch: 5| Step: 2
Training loss: 0.30467206964790305
Validation loss: 2.332528932267094

Epoch: 5| Step: 3
Training loss: 0.218826731779872
Validation loss: 2.3545745380485505

Epoch: 5| Step: 4
Training loss: 0.22860808824900963
Validation loss: 2.3057323714508082

Epoch: 5| Step: 5
Training loss: 0.23223880161280167
Validation loss: 2.3703617254557314

Epoch: 5| Step: 6
Training loss: 0.14091025666449636
Validation loss: 2.351432864583822

Epoch: 5| Step: 7
Training loss: 0.2992183406418672
Validation loss: 2.3374253998173358

Epoch: 5| Step: 8
Training loss: 0.2438150905851896
Validation loss: 2.3423399328019188

Epoch: 5| Step: 9
Training loss: 0.27344096045348
Validation loss: 2.319083736332222

Epoch: 5| Step: 10
Training loss: 0.09474337320505108
Validation loss: 2.3348633919706225

Epoch: 433| Step: 0
Training loss: 0.2822404613834362
Validation loss: 2.276866678184183

Epoch: 5| Step: 1
Training loss: 0.11346415026699018
Validation loss: 2.285737031639986

Epoch: 5| Step: 2
Training loss: 0.13888011662940186
Validation loss: 2.3338353485710046

Epoch: 5| Step: 3
Training loss: 0.17873308430174067
Validation loss: 2.2954103031164466

Epoch: 5| Step: 4
Training loss: 0.258498896463647
Validation loss: 2.321450670919846

Epoch: 5| Step: 5
Training loss: 0.3457656415889077
Validation loss: 2.3036690880023656

Epoch: 5| Step: 6
Training loss: 0.39905787770724205
Validation loss: 2.3277207462895793

Epoch: 5| Step: 7
Training loss: 0.14096343852721263
Validation loss: 2.3112612318938903

Epoch: 5| Step: 8
Training loss: 0.15965170004553592
Validation loss: 2.3608040646378443

Epoch: 5| Step: 9
Training loss: 0.25348143618891206
Validation loss: 2.350437487577553

Epoch: 5| Step: 10
Training loss: 0.13532842380529012
Validation loss: 2.33828599187485

Epoch: 434| Step: 0
Training loss: 0.16704073417793744
Validation loss: 2.356269968034779

Epoch: 5| Step: 1
Training loss: 0.3282287637947602
Validation loss: 2.346301997792329

Epoch: 5| Step: 2
Training loss: 0.15815821940453312
Validation loss: 2.306253591417349

Epoch: 5| Step: 3
Training loss: 0.2705401046703334
Validation loss: 2.3053467722691035

Epoch: 5| Step: 4
Training loss: 0.2525071550998455
Validation loss: 2.3427940965181944

Epoch: 5| Step: 5
Training loss: 0.19448723007721333
Validation loss: 2.2970698049882947

Epoch: 5| Step: 6
Training loss: 0.16839715197485514
Validation loss: 2.301041334182994

Epoch: 5| Step: 7
Training loss: 0.36544591723906894
Validation loss: 2.313314442444709

Epoch: 5| Step: 8
Training loss: 0.15711908635760855
Validation loss: 2.301495389889533

Epoch: 5| Step: 9
Training loss: 0.20778796617631998
Validation loss: 2.2888363570360943

Epoch: 5| Step: 10
Training loss: 0.11473061883345169
Validation loss: 2.274772910100493

Epoch: 435| Step: 0
Training loss: 0.30760754766951837
Validation loss: 2.2695454031583613

Epoch: 5| Step: 1
Training loss: 0.2050981602645768
Validation loss: 2.2964610176732245

Epoch: 5| Step: 2
Training loss: 0.10901423971425857
Validation loss: 2.2905861068029387

Epoch: 5| Step: 3
Training loss: 0.12165457311739103
Validation loss: 2.266651343440729

Epoch: 5| Step: 4
Training loss: 0.18724692670263446
Validation loss: 2.2963838479765535

Epoch: 5| Step: 5
Training loss: 0.27511917425519095
Validation loss: 2.255003091215978

Epoch: 5| Step: 6
Training loss: 0.13148193869370725
Validation loss: 2.2961693620793007

Epoch: 5| Step: 7
Training loss: 0.2139257585979482
Validation loss: 2.268358427642805

Epoch: 5| Step: 8
Training loss: 0.3043986565289256
Validation loss: 2.2932123013385675

Epoch: 5| Step: 9
Training loss: 0.2419219714891793
Validation loss: 2.301833531257635

Epoch: 5| Step: 10
Training loss: 0.28510956839360846
Validation loss: 2.3029884177997864

Epoch: 436| Step: 0
Training loss: 0.16411250919006715
Validation loss: 2.327494482283653

Epoch: 5| Step: 1
Training loss: 0.28061617852260096
Validation loss: 2.2955337770583766

Epoch: 5| Step: 2
Training loss: 0.18325815574014415
Validation loss: 2.2837082051305684

Epoch: 5| Step: 3
Training loss: 0.18607213811671117
Validation loss: 2.3056255152380887

Epoch: 5| Step: 4
Training loss: 0.3078728718298811
Validation loss: 2.3464948724364785

Epoch: 5| Step: 5
Training loss: 0.21657822726611728
Validation loss: 2.3254310110930096

Epoch: 5| Step: 6
Training loss: 0.2723503572031294
Validation loss: 2.3243165784670152

Epoch: 5| Step: 7
Training loss: 0.1269608128494065
Validation loss: 2.3225829527927773

Epoch: 5| Step: 8
Training loss: 0.28032238629193507
Validation loss: 2.3401617341898753

Epoch: 5| Step: 9
Training loss: 0.18254430611913905
Validation loss: 2.2953201476878253

Epoch: 5| Step: 10
Training loss: 0.22783290733695463
Validation loss: 2.325711364808328

Epoch: 437| Step: 0
Training loss: 0.1833133280651172
Validation loss: 2.3262453344609666

Epoch: 5| Step: 1
Training loss: 0.23472939559234898
Validation loss: 2.3313161899357273

Epoch: 5| Step: 2
Training loss: 0.18208324688430003
Validation loss: 2.3025050877787714

Epoch: 5| Step: 3
Training loss: 0.16889760551069502
Validation loss: 2.2869182801180754

Epoch: 5| Step: 4
Training loss: 0.24991065902560408
Validation loss: 2.307873237714785

Epoch: 5| Step: 5
Training loss: 0.2693640840137473
Validation loss: 2.290754415963096

Epoch: 5| Step: 6
Training loss: 0.1466774113627063
Validation loss: 2.297145599593731

Epoch: 5| Step: 7
Training loss: 0.14249381747344372
Validation loss: 2.2815525058329724

Epoch: 5| Step: 8
Training loss: 0.255540984554387
Validation loss: 2.262946748157479

Epoch: 5| Step: 9
Training loss: 0.38765116711704917
Validation loss: 2.274457723392859

Epoch: 5| Step: 10
Training loss: 0.10525911300955461
Validation loss: 2.3432829437307614

Epoch: 438| Step: 0
Training loss: 0.2001147782766924
Validation loss: 2.2792560551839887

Epoch: 5| Step: 1
Training loss: 0.20501662649208488
Validation loss: 2.3341342538257557

Epoch: 5| Step: 2
Training loss: 0.2103206923562743
Validation loss: 2.3357224348436763

Epoch: 5| Step: 3
Training loss: 0.2991551124888246
Validation loss: 2.346764269260444

Epoch: 5| Step: 4
Training loss: 0.18242943643913132
Validation loss: 2.3077325386987337

Epoch: 5| Step: 5
Training loss: 0.23906963499803507
Validation loss: 2.3065090005219124

Epoch: 5| Step: 6
Training loss: 0.19464942911972222
Validation loss: 2.3465233116391175

Epoch: 5| Step: 7
Training loss: 0.25800029099710453
Validation loss: 2.347804558572056

Epoch: 5| Step: 8
Training loss: 0.26721038051145996
Validation loss: 2.3056325246877556

Epoch: 5| Step: 9
Training loss: 0.16655938351347593
Validation loss: 2.347023800711744

Epoch: 5| Step: 10
Training loss: 0.38109250880590984
Validation loss: 2.365993956277728

Epoch: 439| Step: 0
Training loss: 0.21020945545561168
Validation loss: 2.3549602298858936

Epoch: 5| Step: 1
Training loss: 0.174535031888144
Validation loss: 2.3703326102244926

Epoch: 5| Step: 2
Training loss: 0.23119678916120553
Validation loss: 2.3671797262842733

Epoch: 5| Step: 3
Training loss: 0.18646468989940387
Validation loss: 2.3340621753353377

Epoch: 5| Step: 4
Training loss: 0.2933529432787916
Validation loss: 2.3707095820869863

Epoch: 5| Step: 5
Training loss: 0.22143704414912932
Validation loss: 2.317860996757808

Epoch: 5| Step: 6
Training loss: 0.40825787774805666
Validation loss: 2.311893605349205

Epoch: 5| Step: 7
Training loss: 0.15237471070273884
Validation loss: 2.2967755316589504

Epoch: 5| Step: 8
Training loss: 0.19415773435301847
Validation loss: 2.266677455843245

Epoch: 5| Step: 9
Training loss: 0.18405089380624481
Validation loss: 2.250592156107312

Epoch: 5| Step: 10
Training loss: 0.21278786585283965
Validation loss: 2.265488145405648

Epoch: 440| Step: 0
Training loss: 0.2740274060615183
Validation loss: 2.2376582391014375

Epoch: 5| Step: 1
Training loss: 0.236200952598018
Validation loss: 2.2687427515777254

Epoch: 5| Step: 2
Training loss: 0.1956465153852025
Validation loss: 2.2630047518564482

Epoch: 5| Step: 3
Training loss: 0.1451321238638851
Validation loss: 2.2597587217278545

Epoch: 5| Step: 4
Training loss: 0.13797561036590256
Validation loss: 2.3014453110893234

Epoch: 5| Step: 5
Training loss: 0.2320617562607514
Validation loss: 2.2867154526628317

Epoch: 5| Step: 6
Training loss: 0.2100375368425759
Validation loss: 2.3202699124454593

Epoch: 5| Step: 7
Training loss: 0.2780804855641739
Validation loss: 2.3305399327680125

Epoch: 5| Step: 8
Training loss: 0.32372341464773413
Validation loss: 2.3334945144738786

Epoch: 5| Step: 9
Training loss: 0.22825686158043754
Validation loss: 2.3215235189155

Epoch: 5| Step: 10
Training loss: 0.24506345669132318
Validation loss: 2.3287405370444794

Epoch: 441| Step: 0
Training loss: 0.35655210802479237
Validation loss: 2.352835294440643

Epoch: 5| Step: 1
Training loss: 0.22665026214581505
Validation loss: 2.2930856866254565

Epoch: 5| Step: 2
Training loss: 0.11177649472834203
Validation loss: 2.2767271010024723

Epoch: 5| Step: 3
Training loss: 0.19735504238895862
Validation loss: 2.311926148886527

Epoch: 5| Step: 4
Training loss: 0.24295836484737995
Validation loss: 2.2769399758607114

Epoch: 5| Step: 5
Training loss: 0.22310848487512408
Validation loss: 2.3040408927044176

Epoch: 5| Step: 6
Training loss: 0.2338483217453414
Validation loss: 2.271401781153156

Epoch: 5| Step: 7
Training loss: 0.14613145912765316
Validation loss: 2.278055464576031

Epoch: 5| Step: 8
Training loss: 0.25390110010646466
Validation loss: 2.2762625162325483

Epoch: 5| Step: 9
Training loss: 0.16095889560363597
Validation loss: 2.318422254329997

Epoch: 5| Step: 10
Training loss: 0.2583990649203456
Validation loss: 2.3042814630894957

Epoch: 442| Step: 0
Training loss: 0.1590710017324856
Validation loss: 2.31423882826344

Epoch: 5| Step: 1
Training loss: 0.25750074900360803
Validation loss: 2.305194170698209

Epoch: 5| Step: 2
Training loss: 0.14215994609842073
Validation loss: 2.289733770374086

Epoch: 5| Step: 3
Training loss: 0.31469539526360646
Validation loss: 2.279440435901048

Epoch: 5| Step: 4
Training loss: 0.2945526793194716
Validation loss: 2.2818163793639865

Epoch: 5| Step: 5
Training loss: 0.19337721462991284
Validation loss: 2.2979570047010927

Epoch: 5| Step: 6
Training loss: 0.11259283335034939
Validation loss: 2.2771080389154537

Epoch: 5| Step: 7
Training loss: 0.1411294498882399
Validation loss: 2.292835128632642

Epoch: 5| Step: 8
Training loss: 0.3500926125135179
Validation loss: 2.3109756696099044

Epoch: 5| Step: 9
Training loss: 0.19706907016751976
Validation loss: 2.241257062199604

Epoch: 5| Step: 10
Training loss: 0.22612689333555885
Validation loss: 2.297117674029182

Epoch: 443| Step: 0
Training loss: 0.27409857809337457
Validation loss: 2.2745072264407535

Epoch: 5| Step: 1
Training loss: 0.1516791175244095
Validation loss: 2.2830305451200554

Epoch: 5| Step: 2
Training loss: 0.2557329928596827
Validation loss: 2.29866133937176

Epoch: 5| Step: 3
Training loss: 0.277178379239932
Validation loss: 2.271662825241394

Epoch: 5| Step: 4
Training loss: 0.20372311856506647
Validation loss: 2.2702981597260274

Epoch: 5| Step: 5
Training loss: 0.16889418120411576
Validation loss: 2.2891823261518165

Epoch: 5| Step: 6
Training loss: 0.25990905243937207
Validation loss: 2.2775738300759274

Epoch: 5| Step: 7
Training loss: 0.0999721810642561
Validation loss: 2.2875903433103053

Epoch: 5| Step: 8
Training loss: 0.1294420335054935
Validation loss: 2.302333594532523

Epoch: 5| Step: 9
Training loss: 0.17396865479083135
Validation loss: 2.294641259779005

Epoch: 5| Step: 10
Training loss: 0.30679919765322733
Validation loss: 2.3052173292612115

Epoch: 444| Step: 0
Training loss: 0.23573135660822817
Validation loss: 2.2954670967278816

Epoch: 5| Step: 1
Training loss: 0.27731282773706734
Validation loss: 2.2849767588676606

Epoch: 5| Step: 2
Training loss: 0.1952924336615785
Validation loss: 2.310203826840629

Epoch: 5| Step: 3
Training loss: 0.11890492027481596
Validation loss: 2.300025255411013

Epoch: 5| Step: 4
Training loss: 0.22172603038746708
Validation loss: 2.2920114237377467

Epoch: 5| Step: 5
Training loss: 0.2950989905048272
Validation loss: 2.26618339834058

Epoch: 5| Step: 6
Training loss: 0.14819500590734155
Validation loss: 2.2898230485623463

Epoch: 5| Step: 7
Training loss: 0.3119683153412527
Validation loss: 2.301373896718304

Epoch: 5| Step: 8
Training loss: 0.20673336334938197
Validation loss: 2.2989529631813217

Epoch: 5| Step: 9
Training loss: 0.12646877621461197
Validation loss: 2.3075940730187545

Epoch: 5| Step: 10
Training loss: 0.20358069362625839
Validation loss: 2.325500859334846

Epoch: 445| Step: 0
Training loss: 0.2537750932425556
Validation loss: 2.3010600279590925

Epoch: 5| Step: 1
Training loss: 0.16026202058676522
Validation loss: 2.3238182400454073

Epoch: 5| Step: 2
Training loss: 0.19799476366813476
Validation loss: 2.306232104012615

Epoch: 5| Step: 3
Training loss: 0.17061781049784347
Validation loss: 2.2839556618030725

Epoch: 5| Step: 4
Training loss: 0.23798236706522602
Validation loss: 2.31775722823095

Epoch: 5| Step: 5
Training loss: 0.22562748249833345
Validation loss: 2.295292720395185

Epoch: 5| Step: 6
Training loss: 0.1790541183547187
Validation loss: 2.285191816823226

Epoch: 5| Step: 7
Training loss: 0.18386293521824149
Validation loss: 2.2712155107337515

Epoch: 5| Step: 8
Training loss: 0.2104550159479
Validation loss: 2.28048962304791

Epoch: 5| Step: 9
Training loss: 0.34827909504021387
Validation loss: 2.286849660856764

Epoch: 5| Step: 10
Training loss: 0.09213203766130744
Validation loss: 2.284313018349848

Epoch: 446| Step: 0
Training loss: 0.1974161253810073
Validation loss: 2.3001663871439155

Epoch: 5| Step: 1
Training loss: 0.24132907152221833
Validation loss: 2.3000626373143804

Epoch: 5| Step: 2
Training loss: 0.3082257382179756
Validation loss: 2.3077374677193903

Epoch: 5| Step: 3
Training loss: 0.14627990439337402
Validation loss: 2.3031056337834532

Epoch: 5| Step: 4
Training loss: 0.2317258366113982
Validation loss: 2.3068539750520114

Epoch: 5| Step: 5
Training loss: 0.16197669677956958
Validation loss: 2.3125804719722645

Epoch: 5| Step: 6
Training loss: 0.22999819709496216
Validation loss: 2.333058678009636

Epoch: 5| Step: 7
Training loss: 0.3022291952163712
Validation loss: 2.3182416109971618

Epoch: 5| Step: 8
Training loss: 0.1142310331213455
Validation loss: 2.3282852640741574

Epoch: 5| Step: 9
Training loss: 0.1595627907856056
Validation loss: 2.3137099186371057

Epoch: 5| Step: 10
Training loss: 0.2312803928275345
Validation loss: 2.3009961917474167

Epoch: 447| Step: 0
Training loss: 0.4149920089078702
Validation loss: 2.277366460066632

Epoch: 5| Step: 1
Training loss: 0.19436831180681718
Validation loss: 2.2790763682168262

Epoch: 5| Step: 2
Training loss: 0.10322263928776856
Validation loss: 2.283101355926935

Epoch: 5| Step: 3
Training loss: 0.11177944422002599
Validation loss: 2.2752871853957783

Epoch: 5| Step: 4
Training loss: 0.30302529661647004
Validation loss: 2.2718423650815573

Epoch: 5| Step: 5
Training loss: 0.19544610222384237
Validation loss: 2.2459767009809526

Epoch: 5| Step: 6
Training loss: 0.1317827329301157
Validation loss: 2.27304520989669

Epoch: 5| Step: 7
Training loss: 0.12921367457707422
Validation loss: 2.2429009759800227

Epoch: 5| Step: 8
Training loss: 0.17448629654128336
Validation loss: 2.2726632593411926

Epoch: 5| Step: 9
Training loss: 0.25800914200953523
Validation loss: 2.2899451220984717

Epoch: 5| Step: 10
Training loss: 0.11010859757364531
Validation loss: 2.3015168190391018

Epoch: 448| Step: 0
Training loss: 0.22218579231281982
Validation loss: 2.280956468564606

Epoch: 5| Step: 1
Training loss: 0.18323731825195183
Validation loss: 2.270711094152502

Epoch: 5| Step: 2
Training loss: 0.3554571380395407
Validation loss: 2.3019328818275078

Epoch: 5| Step: 3
Training loss: 0.07018140983676298
Validation loss: 2.2701046660713082

Epoch: 5| Step: 4
Training loss: 0.20659261697467993
Validation loss: 2.290543188159469

Epoch: 5| Step: 5
Training loss: 0.15982754050892037
Validation loss: 2.2947023513028086

Epoch: 5| Step: 6
Training loss: 0.24517432530947156
Validation loss: 2.2730608733416227

Epoch: 5| Step: 7
Training loss: 0.09665049969668062
Validation loss: 2.29277649422311

Epoch: 5| Step: 8
Training loss: 0.14880247170336758
Validation loss: 2.275656007249831

Epoch: 5| Step: 9
Training loss: 0.0681212125226253
Validation loss: 2.2956928358214355

Epoch: 5| Step: 10
Training loss: 0.32183647480746297
Validation loss: 2.2800488166120263

Epoch: 449| Step: 0
Training loss: 0.2924539493517175
Validation loss: 2.264234952205081

Epoch: 5| Step: 1
Training loss: 0.19015763240741143
Validation loss: 2.278381067507155

Epoch: 5| Step: 2
Training loss: 0.09608679858705133
Validation loss: 2.290720581205783

Epoch: 5| Step: 3
Training loss: 0.2879224151491988
Validation loss: 2.2790677619007718

Epoch: 5| Step: 4
Training loss: 0.10919012896676024
Validation loss: 2.272113329418658

Epoch: 5| Step: 5
Training loss: 0.1729399460515123
Validation loss: 2.2820736202766994

Epoch: 5| Step: 6
Training loss: 0.3157433288017467
Validation loss: 2.3029217985794266

Epoch: 5| Step: 7
Training loss: 0.17228008347989426
Validation loss: 2.3009312228770855

Epoch: 5| Step: 8
Training loss: 0.17260136789283215
Validation loss: 2.310696069820689

Epoch: 5| Step: 9
Training loss: 0.21349917935050639
Validation loss: 2.328448248720502

Epoch: 5| Step: 10
Training loss: 0.08120540027539369
Validation loss: 2.346958561983967

Epoch: 450| Step: 0
Training loss: 0.18847013867751677
Validation loss: 2.309785177779481

Epoch: 5| Step: 1
Training loss: 0.2026971198453695
Validation loss: 2.300982035671314

Epoch: 5| Step: 2
Training loss: 0.2662693510948237
Validation loss: 2.309348214827398

Epoch: 5| Step: 3
Training loss: 0.26202374806410306
Validation loss: 2.3122083063692673

Epoch: 5| Step: 4
Training loss: 0.13690082143188123
Validation loss: 2.318648153693693

Epoch: 5| Step: 5
Training loss: 0.23417593131341896
Validation loss: 2.2845834299311236

Epoch: 5| Step: 6
Training loss: 0.11831877566070262
Validation loss: 2.2956252105941415

Epoch: 5| Step: 7
Training loss: 0.20657558499269224
Validation loss: 2.297195956823369

Epoch: 5| Step: 8
Training loss: 0.15289856678097322
Validation loss: 2.3101806339268194

Epoch: 5| Step: 9
Training loss: 0.16768329228067436
Validation loss: 2.2876392198185256

Epoch: 5| Step: 10
Training loss: 0.19336978807249922
Validation loss: 2.2312900505264173

Epoch: 451| Step: 0
Training loss: 0.09060808221164796
Validation loss: 2.239670383529196

Epoch: 5| Step: 1
Training loss: 0.2069604320683391
Validation loss: 2.2539974636433358

Epoch: 5| Step: 2
Training loss: 0.3301470983548455
Validation loss: 2.2682989774297218

Epoch: 5| Step: 3
Training loss: 0.16617390996801593
Validation loss: 2.2476474193992475

Epoch: 5| Step: 4
Training loss: 0.1821436530885215
Validation loss: 2.2763592342743983

Epoch: 5| Step: 5
Training loss: 0.34556281480586837
Validation loss: 2.2512441428978223

Epoch: 5| Step: 6
Training loss: 0.20082777649432146
Validation loss: 2.234247428739625

Epoch: 5| Step: 7
Training loss: 0.11637611431111786
Validation loss: 2.213443704038301

Epoch: 5| Step: 8
Training loss: 0.09756585706033995
Validation loss: 2.218676460280247

Epoch: 5| Step: 9
Training loss: 0.2314288137486575
Validation loss: 2.2437873967239987

Epoch: 5| Step: 10
Training loss: 0.13587574597481178
Validation loss: 2.2649153823356327

Epoch: 452| Step: 0
Training loss: 0.22345880960337494
Validation loss: 2.2802819549456985

Epoch: 5| Step: 1
Training loss: 0.19680534144684314
Validation loss: 2.2542929076084337

Epoch: 5| Step: 2
Training loss: 0.16556088493152715
Validation loss: 2.2728056070899085

Epoch: 5| Step: 3
Training loss: 0.1704114350978664
Validation loss: 2.2915855954578994

Epoch: 5| Step: 4
Training loss: 0.09858500388961168
Validation loss: 2.3028192538680288

Epoch: 5| Step: 5
Training loss: 0.12600965582704174
Validation loss: 2.3108694463540522

Epoch: 5| Step: 6
Training loss: 0.3298712765092147
Validation loss: 2.284848225232966

Epoch: 5| Step: 7
Training loss: 0.15537176078111328
Validation loss: 2.3075939969181145

Epoch: 5| Step: 8
Training loss: 0.2622926170997479
Validation loss: 2.3093639351034665

Epoch: 5| Step: 9
Training loss: 0.14984820130571444
Validation loss: 2.2783077582435953

Epoch: 5| Step: 10
Training loss: 0.2218762924935748
Validation loss: 2.2953218654777494

Epoch: 453| Step: 0
Training loss: 0.18270374225631916
Validation loss: 2.2934089365723107

Epoch: 5| Step: 1
Training loss: 0.21358909119085703
Validation loss: 2.2839705859345236

Epoch: 5| Step: 2
Training loss: 0.0876661055552627
Validation loss: 2.2797984023741154

Epoch: 5| Step: 3
Training loss: 0.11494418961647954
Validation loss: 2.295399433857168

Epoch: 5| Step: 4
Training loss: 0.3030913186778627
Validation loss: 2.283162199858346

Epoch: 5| Step: 5
Training loss: 0.21875874467809628
Validation loss: 2.3077754764804546

Epoch: 5| Step: 6
Training loss: 0.25215550360319183
Validation loss: 2.2656921580442027

Epoch: 5| Step: 7
Training loss: 0.27041508706977996
Validation loss: 2.2544054725507245

Epoch: 5| Step: 8
Training loss: 0.14576834198329888
Validation loss: 2.245990168754307

Epoch: 5| Step: 9
Training loss: 0.14685731461759202
Validation loss: 2.250363875376926

Epoch: 5| Step: 10
Training loss: 0.1127484056038631
Validation loss: 2.2763320709614248

Epoch: 454| Step: 0
Training loss: 0.14310375416164428
Validation loss: 2.2627489425626597

Epoch: 5| Step: 1
Training loss: 0.18110372296997937
Validation loss: 2.2676104204415943

Epoch: 5| Step: 2
Training loss: 0.22702355990739168
Validation loss: 2.268365030112068

Epoch: 5| Step: 3
Training loss: 0.07886522213176601
Validation loss: 2.294503607404265

Epoch: 5| Step: 4
Training loss: 0.19543013844656285
Validation loss: 2.271849164494127

Epoch: 5| Step: 5
Training loss: 0.12528149380544804
Validation loss: 2.3073443633127284

Epoch: 5| Step: 6
Training loss: 0.18314144544024677
Validation loss: 2.2878307049459883

Epoch: 5| Step: 7
Training loss: 0.1878929490958833
Validation loss: 2.2739644617034345

Epoch: 5| Step: 8
Training loss: 0.13697119294976928
Validation loss: 2.287337796925708

Epoch: 5| Step: 9
Training loss: 0.25232248069010443
Validation loss: 2.3078175869905775

Epoch: 5| Step: 10
Training loss: 0.33496942314765743
Validation loss: 2.315999496410139

Epoch: 455| Step: 0
Training loss: 0.09375437090539118
Validation loss: 2.3298652830281603

Epoch: 5| Step: 1
Training loss: 0.11519151229902673
Validation loss: 2.3279295522220202

Epoch: 5| Step: 2
Training loss: 0.3300596378724576
Validation loss: 2.3173172044963186

Epoch: 5| Step: 3
Training loss: 0.14185624075270764
Validation loss: 2.343094060300097

Epoch: 5| Step: 4
Training loss: 0.18373108860583248
Validation loss: 2.2980414235865103

Epoch: 5| Step: 5
Training loss: 0.1855854696991745
Validation loss: 2.2935198460716943

Epoch: 5| Step: 6
Training loss: 0.12957019038822837
Validation loss: 2.2767247464930813

Epoch: 5| Step: 7
Training loss: 0.3239157536276814
Validation loss: 2.282439284429636

Epoch: 5| Step: 8
Training loss: 0.2312264755887629
Validation loss: 2.2782208678852394

Epoch: 5| Step: 9
Training loss: 0.14821879688626535
Validation loss: 2.2665526904157782

Epoch: 5| Step: 10
Training loss: 0.06543467630753942
Validation loss: 2.290397268605855

Epoch: 456| Step: 0
Training loss: 0.12971767884448368
Validation loss: 2.26943971066902

Epoch: 5| Step: 1
Training loss: 0.23903769663624255
Validation loss: 2.265100189630219

Epoch: 5| Step: 2
Training loss: 0.10640010836321692
Validation loss: 2.2965664344149435

Epoch: 5| Step: 3
Training loss: 0.265659484307803
Validation loss: 2.2824473198034347

Epoch: 5| Step: 4
Training loss: 0.12985603515402327
Validation loss: 2.2939285690301516

Epoch: 5| Step: 5
Training loss: 0.2928314650265564
Validation loss: 2.2623116202174542

Epoch: 5| Step: 6
Training loss: 0.2328780130082913
Validation loss: 2.3027493533272048

Epoch: 5| Step: 7
Training loss: 0.2638564699877898
Validation loss: 2.285636196985327

Epoch: 5| Step: 8
Training loss: 0.12017815291062206
Validation loss: 2.303187367866872

Epoch: 5| Step: 9
Training loss: 0.10041773259403759
Validation loss: 2.3014885482924323

Epoch: 5| Step: 10
Training loss: 0.19136586055073637
Validation loss: 2.2860153441471085

Epoch: 457| Step: 0
Training loss: 0.26581591869481574
Validation loss: 2.2847976598142066

Epoch: 5| Step: 1
Training loss: 0.2930382328289684
Validation loss: 2.280426923153555

Epoch: 5| Step: 2
Training loss: 0.22591770430989921
Validation loss: 2.2757430158145033

Epoch: 5| Step: 3
Training loss: 0.19400856584694476
Validation loss: 2.2766262388897123

Epoch: 5| Step: 4
Training loss: 0.0791965844013744
Validation loss: 2.2803242763754326

Epoch: 5| Step: 5
Training loss: 0.18794502652418424
Validation loss: 2.2610356520306065

Epoch: 5| Step: 6
Training loss: 0.2507718063667952
Validation loss: 2.3113204205826783

Epoch: 5| Step: 7
Training loss: 0.20400856491182098
Validation loss: 2.2879983260222962

Epoch: 5| Step: 8
Training loss: 0.13467907545113403
Validation loss: 2.297876009456242

Epoch: 5| Step: 9
Training loss: 0.10169409516089396
Validation loss: 2.307564805749447

Epoch: 5| Step: 10
Training loss: 0.07507643964207576
Validation loss: 2.3113170858692986

Epoch: 458| Step: 0
Training loss: 0.22815463089221483
Validation loss: 2.2982566717692183

Epoch: 5| Step: 1
Training loss: 0.23975450769021428
Validation loss: 2.279583227525289

Epoch: 5| Step: 2
Training loss: 0.23024814360022441
Validation loss: 2.2712111571304225

Epoch: 5| Step: 3
Training loss: 0.14233304214819992
Validation loss: 2.2859297594645875

Epoch: 5| Step: 4
Training loss: 0.12303971088080416
Validation loss: 2.2989206285281893

Epoch: 5| Step: 5
Training loss: 0.20172395228171638
Validation loss: 2.3073358885461657

Epoch: 5| Step: 6
Training loss: 0.26694078487803596
Validation loss: 2.274276901507566

Epoch: 5| Step: 7
Training loss: 0.07840537781304405
Validation loss: 2.332799002302685

Epoch: 5| Step: 8
Training loss: 0.26582505602391604
Validation loss: 2.31336974428579

Epoch: 5| Step: 9
Training loss: 0.13584568002916783
Validation loss: 2.301721485880186

Epoch: 5| Step: 10
Training loss: 0.15511005731053867
Validation loss: 2.3106662038901775

Epoch: 459| Step: 0
Training loss: 0.1356639499372767
Validation loss: 2.297312785407031

Epoch: 5| Step: 1
Training loss: 0.2754513017621235
Validation loss: 2.2918753091766897

Epoch: 5| Step: 2
Training loss: 0.10319500429169652
Validation loss: 2.2972470349767367

Epoch: 5| Step: 3
Training loss: 0.19871933364602487
Validation loss: 2.2702313152277123

Epoch: 5| Step: 4
Training loss: 0.3364789613456982
Validation loss: 2.2521897869428913

Epoch: 5| Step: 5
Training loss: 0.1309047876386995
Validation loss: 2.2922261443573713

Epoch: 5| Step: 6
Training loss: 0.170392071002
Validation loss: 2.3070665764189875

Epoch: 5| Step: 7
Training loss: 0.3242377424996806
Validation loss: 2.254728098503604

Epoch: 5| Step: 8
Training loss: 0.13469376928913368
Validation loss: 2.2979726283107413

Epoch: 5| Step: 9
Training loss: 0.12013232128050076
Validation loss: 2.293199916366859

Epoch: 5| Step: 10
Training loss: 0.1731815743879829
Validation loss: 2.312376853282444

Epoch: 460| Step: 0
Training loss: 0.17317882634961237
Validation loss: 2.310923606935464

Epoch: 5| Step: 1
Training loss: 0.17204305712228157
Validation loss: 2.305432351148831

Epoch: 5| Step: 2
Training loss: 0.2101196930865881
Validation loss: 2.291075963904758

Epoch: 5| Step: 3
Training loss: 0.1136231155624805
Validation loss: 2.3189715598748095

Epoch: 5| Step: 4
Training loss: 0.26525648583905725
Validation loss: 2.345222454702578

Epoch: 5| Step: 5
Training loss: 0.2777741008091328
Validation loss: 2.2871305455033073

Epoch: 5| Step: 6
Training loss: 0.2360587121322771
Validation loss: 2.279983769193345

Epoch: 5| Step: 7
Training loss: 0.21124603524522306
Validation loss: 2.2639054929884055

Epoch: 5| Step: 8
Training loss: 0.13230028675059805
Validation loss: 2.2885750896984702

Epoch: 5| Step: 9
Training loss: 0.1143220655616703
Validation loss: 2.2584172289978706

Epoch: 5| Step: 10
Training loss: 0.2198617138060792
Validation loss: 2.233433972832201

Epoch: 461| Step: 0
Training loss: 0.28712909656702845
Validation loss: 2.282217856293977

Epoch: 5| Step: 1
Training loss: 0.2335463179080623
Validation loss: 2.293010690253153

Epoch: 5| Step: 2
Training loss: 0.19029808387588495
Validation loss: 2.2802529262449283

Epoch: 5| Step: 3
Training loss: 0.23501281577785474
Validation loss: 2.300085926680075

Epoch: 5| Step: 4
Training loss: 0.13710502144838307
Validation loss: 2.303735813586849

Epoch: 5| Step: 5
Training loss: 0.13218289390952953
Validation loss: 2.3232509347331427

Epoch: 5| Step: 6
Training loss: 0.2057336231344557
Validation loss: 2.311967313343316

Epoch: 5| Step: 7
Training loss: 0.22760992624835805
Validation loss: 2.287094206814125

Epoch: 5| Step: 8
Training loss: 0.16981238093036777
Validation loss: 2.291337141879876

Epoch: 5| Step: 9
Training loss: 0.19445420505136377
Validation loss: 2.2936869697978337

Epoch: 5| Step: 10
Training loss: 0.10692568100868922
Validation loss: 2.2963936520186876

Epoch: 462| Step: 0
Training loss: 0.1030668526416254
Validation loss: 2.302244082141057

Epoch: 5| Step: 1
Training loss: 0.14378262932150415
Validation loss: 2.3004509409324974

Epoch: 5| Step: 2
Training loss: 0.1560968781254231
Validation loss: 2.2925508864724233

Epoch: 5| Step: 3
Training loss: 0.11712887807708651
Validation loss: 2.3001100138444004

Epoch: 5| Step: 4
Training loss: 0.2144426676801002
Validation loss: 2.291428257314129

Epoch: 5| Step: 5
Training loss: 0.10460388149939173
Validation loss: 2.28489859991586

Epoch: 5| Step: 6
Training loss: 0.28815604181285254
Validation loss: 2.2713265490661203

Epoch: 5| Step: 7
Training loss: 0.1306609742123242
Validation loss: 2.2734776896363837

Epoch: 5| Step: 8
Training loss: 0.28687455831755504
Validation loss: 2.311145242624902

Epoch: 5| Step: 9
Training loss: 0.07488321584792897
Validation loss: 2.3087613993126777

Epoch: 5| Step: 10
Training loss: 0.28525416117248326
Validation loss: 2.286192558121034

Epoch: 463| Step: 0
Training loss: 0.2362182456327954
Validation loss: 2.2866461949944994

Epoch: 5| Step: 1
Training loss: 0.20153728186887698
Validation loss: 2.282738109077648

Epoch: 5| Step: 2
Training loss: 0.13021431114462056
Validation loss: 2.294973457296072

Epoch: 5| Step: 3
Training loss: 0.23198795685360615
Validation loss: 2.3175380650235518

Epoch: 5| Step: 4
Training loss: 0.1541167970869853
Validation loss: 2.280148554781817

Epoch: 5| Step: 5
Training loss: 0.21059566633125548
Validation loss: 2.314471358215363

Epoch: 5| Step: 6
Training loss: 0.2141040030849963
Validation loss: 2.3098856413624107

Epoch: 5| Step: 7
Training loss: 0.1710727184468095
Validation loss: 2.2812267262385117

Epoch: 5| Step: 8
Training loss: 0.22012812055025452
Validation loss: 2.285361991085693

Epoch: 5| Step: 9
Training loss: 0.12360846564486788
Validation loss: 2.2766878138197995

Epoch: 5| Step: 10
Training loss: 0.11928413299957133
Validation loss: 2.2767888038195836

Epoch: 464| Step: 0
Training loss: 0.08732389147122731
Validation loss: 2.287113013466518

Epoch: 5| Step: 1
Training loss: 0.11317080013191842
Validation loss: 2.2524737610853114

Epoch: 5| Step: 2
Training loss: 0.23499560841555728
Validation loss: 2.282394914706756

Epoch: 5| Step: 3
Training loss: 0.27233640497822414
Validation loss: 2.290029149530683

Epoch: 5| Step: 4
Training loss: 0.13504905198070608
Validation loss: 2.2689748099587836

Epoch: 5| Step: 5
Training loss: 0.17823779943224202
Validation loss: 2.308447950849443

Epoch: 5| Step: 6
Training loss: 0.14617470752289807
Validation loss: 2.306683673130293

Epoch: 5| Step: 7
Training loss: 0.23611928050705763
Validation loss: 2.2897427139122684

Epoch: 5| Step: 8
Training loss: 0.22697697742282297
Validation loss: 2.3120856796659393

Epoch: 5| Step: 9
Training loss: 0.14974862085242283
Validation loss: 2.281760192000336

Epoch: 5| Step: 10
Training loss: 0.16878803186647118
Validation loss: 2.287135811477243

Epoch: 465| Step: 0
Training loss: 0.17737083144259577
Validation loss: 2.312872517698648

Epoch: 5| Step: 1
Training loss: 0.1308049686690649
Validation loss: 2.318975202519422

Epoch: 5| Step: 2
Training loss: 0.31192667343835445
Validation loss: 2.324553258367776

Epoch: 5| Step: 3
Training loss: 0.2007719063718465
Validation loss: 2.314112554730038

Epoch: 5| Step: 4
Training loss: 0.22520032349409952
Validation loss: 2.3134639602186504

Epoch: 5| Step: 5
Training loss: 0.16828767307317646
Validation loss: 2.31816251663848

Epoch: 5| Step: 6
Training loss: 0.12010084211584687
Validation loss: 2.3075564678870903

Epoch: 5| Step: 7
Training loss: 0.14322288600560384
Validation loss: 2.350949656543937

Epoch: 5| Step: 8
Training loss: 0.10658587353229176
Validation loss: 2.336179449600426

Epoch: 5| Step: 9
Training loss: 0.16173442888963813
Validation loss: 2.3114151564877585

Epoch: 5| Step: 10
Training loss: 0.2667756263459233
Validation loss: 2.3166323893832272

Epoch: 466| Step: 0
Training loss: 0.24269750179357533
Validation loss: 2.3259134039225247

Epoch: 5| Step: 1
Training loss: 0.25886658281192637
Validation loss: 2.2995508788282892

Epoch: 5| Step: 2
Training loss: 0.2097247547420605
Validation loss: 2.2821396146501702

Epoch: 5| Step: 3
Training loss: 0.18010979247770809
Validation loss: 2.2668887270575055

Epoch: 5| Step: 4
Training loss: 0.14958533898242454
Validation loss: 2.259404165109519

Epoch: 5| Step: 5
Training loss: 0.22738264708061603
Validation loss: 2.2696481135632895

Epoch: 5| Step: 6
Training loss: 0.13399837298437456
Validation loss: 2.2451176956338115

Epoch: 5| Step: 7
Training loss: 0.16447830301939448
Validation loss: 2.2655510652364543

Epoch: 5| Step: 8
Training loss: 0.22577510680186744
Validation loss: 2.3005855803086344

Epoch: 5| Step: 9
Training loss: 0.2861074755390333
Validation loss: 2.3170045854163726

Epoch: 5| Step: 10
Training loss: 0.0982761212589077
Validation loss: 2.316632990279895

Epoch: 467| Step: 0
Training loss: 0.16942913588230335
Validation loss: 2.346787549602365

Epoch: 5| Step: 1
Training loss: 0.10703969942976305
Validation loss: 2.3662690935201547

Epoch: 5| Step: 2
Training loss: 0.24497463442906248
Validation loss: 2.3611502713119403

Epoch: 5| Step: 3
Training loss: 0.09260906414734771
Validation loss: 2.350239910088196

Epoch: 5| Step: 4
Training loss: 0.16340668482603143
Validation loss: 2.331523435219081

Epoch: 5| Step: 5
Training loss: 0.1331045082152785
Validation loss: 2.2925963735575863

Epoch: 5| Step: 6
Training loss: 0.26583420705253097
Validation loss: 2.333377667048372

Epoch: 5| Step: 7
Training loss: 0.19176817755040418
Validation loss: 2.288053971962688

Epoch: 5| Step: 8
Training loss: 0.24222035339005893
Validation loss: 2.266977758235184

Epoch: 5| Step: 9
Training loss: 0.08198477075425646
Validation loss: 2.255460402823214

Epoch: 5| Step: 10
Training loss: 0.3262708822049417
Validation loss: 2.2417844357390657

Epoch: 468| Step: 0
Training loss: 0.26955246496327717
Validation loss: 2.216327255556473

Epoch: 5| Step: 1
Training loss: 0.14074100901512368
Validation loss: 2.234369065540527

Epoch: 5| Step: 2
Training loss: 0.2602556382456219
Validation loss: 2.229462760816724

Epoch: 5| Step: 3
Training loss: 0.19858020472159751
Validation loss: 2.24971963646536

Epoch: 5| Step: 4
Training loss: 0.15201214622291395
Validation loss: 2.2621215890020485

Epoch: 5| Step: 5
Training loss: 0.10190948487744628
Validation loss: 2.259557764302753

Epoch: 5| Step: 6
Training loss: 0.06578399677952533
Validation loss: 2.305676620130993

Epoch: 5| Step: 7
Training loss: 0.11115364154385812
Validation loss: 2.3155214137700835

Epoch: 5| Step: 8
Training loss: 0.2517940255482336
Validation loss: 2.3316719722595813

Epoch: 5| Step: 9
Training loss: 0.28074440280756285
Validation loss: 2.32359731833336

Epoch: 5| Step: 10
Training loss: 0.2110359174228341
Validation loss: 2.300862479465207

Epoch: 469| Step: 0
Training loss: 0.14537842649667726
Validation loss: 2.313073370707018

Epoch: 5| Step: 1
Training loss: 0.34278224053449724
Validation loss: 2.303547372820599

Epoch: 5| Step: 2
Training loss: 0.15439393214110134
Validation loss: 2.288942852377068

Epoch: 5| Step: 3
Training loss: 0.21669407718536154
Validation loss: 2.269201801955608

Epoch: 5| Step: 4
Training loss: 0.2284636886786369
Validation loss: 2.2689720327430516

Epoch: 5| Step: 5
Training loss: 0.16800630504479108
Validation loss: 2.212889081873341

Epoch: 5| Step: 6
Training loss: 0.25935537884504756
Validation loss: 2.2410162090620553

Epoch: 5| Step: 7
Training loss: 0.12609668298120416
Validation loss: 2.2572414389784843

Epoch: 5| Step: 8
Training loss: 0.19073634765047404
Validation loss: 2.2473081417331215

Epoch: 5| Step: 9
Training loss: 0.12335343622017574
Validation loss: 2.280601807197153

Epoch: 5| Step: 10
Training loss: 0.14043318063691593
Validation loss: 2.301088732898635

Epoch: 470| Step: 0
Training loss: 0.1341635134859047
Validation loss: 2.2908449625808514

Epoch: 5| Step: 1
Training loss: 0.26393118928523196
Validation loss: 2.2932629131826885

Epoch: 5| Step: 2
Training loss: 0.25343283019837715
Validation loss: 2.310780840407011

Epoch: 5| Step: 3
Training loss: 0.11915628142747882
Validation loss: 2.282020690392275

Epoch: 5| Step: 4
Training loss: 0.09923660425557183
Validation loss: 2.311458736240098

Epoch: 5| Step: 5
Training loss: 0.18841646649590305
Validation loss: 2.315522362601548

Epoch: 5| Step: 6
Training loss: 0.17986812013812534
Validation loss: 2.3139448820835518

Epoch: 5| Step: 7
Training loss: 0.24015153061219943
Validation loss: 2.299850147603484

Epoch: 5| Step: 8
Training loss: 0.14485972683637213
Validation loss: 2.3022429763956747

Epoch: 5| Step: 9
Training loss: 0.2725434810613219
Validation loss: 2.3328439606593583

Epoch: 5| Step: 10
Training loss: 0.12438022177244244
Validation loss: 2.312758984706686

Epoch: 471| Step: 0
Training loss: 0.16738767249619999
Validation loss: 2.2871290636753354

Epoch: 5| Step: 1
Training loss: 0.07777004370093513
Validation loss: 2.2712048812447208

Epoch: 5| Step: 2
Training loss: 0.10079476058946761
Validation loss: 2.2680547588384927

Epoch: 5| Step: 3
Training loss: 0.14954657070554225
Validation loss: 2.2837894188385226

Epoch: 5| Step: 4
Training loss: 0.1477870114914097
Validation loss: 2.278881893370696

Epoch: 5| Step: 5
Training loss: 0.3163848328111774
Validation loss: 2.299665366282491

Epoch: 5| Step: 6
Training loss: 0.18540665196758233
Validation loss: 2.2677954303369487

Epoch: 5| Step: 7
Training loss: 0.21286938062588043
Validation loss: 2.2745229992913494

Epoch: 5| Step: 8
Training loss: 0.1176651676820831
Validation loss: 2.284119312327223

Epoch: 5| Step: 9
Training loss: 0.16044717045577678
Validation loss: 2.2604469195974946

Epoch: 5| Step: 10
Training loss: 0.30774225992374915
Validation loss: 2.298981193740574

Epoch: 472| Step: 0
Training loss: 0.11185184067227064
Validation loss: 2.2592670268785713

Epoch: 5| Step: 1
Training loss: 0.10243311358434841
Validation loss: 2.286996688400313

Epoch: 5| Step: 2
Training loss: 0.2502071744085741
Validation loss: 2.2752393483263695

Epoch: 5| Step: 3
Training loss: 0.23639990764664928
Validation loss: 2.2563328215307585

Epoch: 5| Step: 4
Training loss: 0.11570483283714943
Validation loss: 2.2612601259815537

Epoch: 5| Step: 5
Training loss: 0.187749230126099
Validation loss: 2.2362105762872715

Epoch: 5| Step: 6
Training loss: 0.23817111424859724
Validation loss: 2.2358018975961516

Epoch: 5| Step: 7
Training loss: 0.26890546604642906
Validation loss: 2.245005076666867

Epoch: 5| Step: 8
Training loss: 0.2603661043036587
Validation loss: 2.2898873182835877

Epoch: 5| Step: 9
Training loss: 0.20464281475267135
Validation loss: 2.257230558557783

Epoch: 5| Step: 10
Training loss: 0.21682844705345392
Validation loss: 2.2408171734622475

Epoch: 473| Step: 0
Training loss: 0.09804033090401836
Validation loss: 2.271390877705775

Epoch: 5| Step: 1
Training loss: 0.22538313894550024
Validation loss: 2.2793116508013602

Epoch: 5| Step: 2
Training loss: 0.16692648258686327
Validation loss: 2.2691265799687406

Epoch: 5| Step: 3
Training loss: 0.2663903989578909
Validation loss: 2.2692479050681804

Epoch: 5| Step: 4
Training loss: 0.15559859987374572
Validation loss: 2.253496653587674

Epoch: 5| Step: 5
Training loss: 0.11134232045737986
Validation loss: 2.251427818385649

Epoch: 5| Step: 6
Training loss: 0.1940491635505304
Validation loss: 2.252160139467334

Epoch: 5| Step: 7
Training loss: 0.300641621964848
Validation loss: 2.271157001648396

Epoch: 5| Step: 8
Training loss: 0.14012250263266923
Validation loss: 2.2190320065236304

Epoch: 5| Step: 9
Training loss: 0.14803733342003592
Validation loss: 2.2218643716440503

Epoch: 5| Step: 10
Training loss: 0.32188587355533704
Validation loss: 2.2355385482983436

Epoch: 474| Step: 0
Training loss: 0.11591033364067918
Validation loss: 2.248084458949386

Epoch: 5| Step: 1
Training loss: 0.30356232420107465
Validation loss: 2.2437785282287184

Epoch: 5| Step: 2
Training loss: 0.23539410598363744
Validation loss: 2.234083197766631

Epoch: 5| Step: 3
Training loss: 0.15456132921013765
Validation loss: 2.2571895657042558

Epoch: 5| Step: 4
Training loss: 0.22663738394375493
Validation loss: 2.2665866823519103

Epoch: 5| Step: 5
Training loss: 0.09393702666765556
Validation loss: 2.2726853309044617

Epoch: 5| Step: 6
Training loss: 0.17379360177612732
Validation loss: 2.2825038120407

Epoch: 5| Step: 7
Training loss: 0.16736608886856752
Validation loss: 2.263877303761972

Epoch: 5| Step: 8
Training loss: 0.28261163702142983
Validation loss: 2.2674436337222676

Epoch: 5| Step: 9
Training loss: 0.12926784287399867
Validation loss: 2.2414786331725796

Epoch: 5| Step: 10
Training loss: 0.10552534156917781
Validation loss: 2.2442175920525855

Epoch: 475| Step: 0
Training loss: 0.1532410702359566
Validation loss: 2.2336779252204044

Epoch: 5| Step: 1
Training loss: 0.18908705197274467
Validation loss: 2.2174437168563212

Epoch: 5| Step: 2
Training loss: 0.25143102029524744
Validation loss: 2.256047162725501

Epoch: 5| Step: 3
Training loss: 0.2455194447750165
Validation loss: 2.2603652567938672

Epoch: 5| Step: 4
Training loss: 0.21755215816909007
Validation loss: 2.2767750920392933

Epoch: 5| Step: 5
Training loss: 0.11610989224787502
Validation loss: 2.3408321383208497

Epoch: 5| Step: 6
Training loss: 0.28132597903656986
Validation loss: 2.324377245181092

Epoch: 5| Step: 7
Training loss: 0.1520847417382995
Validation loss: 2.3300544807641304

Epoch: 5| Step: 8
Training loss: 0.08754557323202859
Validation loss: 2.2858946667437623

Epoch: 5| Step: 9
Training loss: 0.1685976519588301
Validation loss: 2.3042368861818443

Epoch: 5| Step: 10
Training loss: 0.13959065822578803
Validation loss: 2.2684816065273683

Epoch: 476| Step: 0
Training loss: 0.25925842043684816
Validation loss: 2.282324271251113

Epoch: 5| Step: 1
Training loss: 0.12320401738677557
Validation loss: 2.2479023435650816

Epoch: 5| Step: 2
Training loss: 0.1526342824984329
Validation loss: 2.220936932735362

Epoch: 5| Step: 3
Training loss: 0.2380357712928136
Validation loss: 2.223675352035678

Epoch: 5| Step: 4
Training loss: 0.21524689736605754
Validation loss: 2.2415615052736455

Epoch: 5| Step: 5
Training loss: 0.22064101771599393
Validation loss: 2.2469984563612493

Epoch: 5| Step: 6
Training loss: 0.1494992082121942
Validation loss: 2.265903594667847

Epoch: 5| Step: 7
Training loss: 0.11883651113794881
Validation loss: 2.266260328311223

Epoch: 5| Step: 8
Training loss: 0.28201050721708854
Validation loss: 2.285222095893741

Epoch: 5| Step: 9
Training loss: 0.10331155797577359
Validation loss: 2.279268410757636

Epoch: 5| Step: 10
Training loss: 0.07138555019585956
Validation loss: 2.2935054529883816

Epoch: 477| Step: 0
Training loss: 0.3412501403787345
Validation loss: 2.307750286234299

Epoch: 5| Step: 1
Training loss: 0.19749822217406696
Validation loss: 2.2728319753280486

Epoch: 5| Step: 2
Training loss: 0.12339718845504506
Validation loss: 2.303396462305415

Epoch: 5| Step: 3
Training loss: 0.16835596674148878
Validation loss: 2.260555477047255

Epoch: 5| Step: 4
Training loss: 0.24464880887082094
Validation loss: 2.235638521736623

Epoch: 5| Step: 5
Training loss: 0.19662771854776648
Validation loss: 2.2474406850827937

Epoch: 5| Step: 6
Training loss: 0.14714061606906306
Validation loss: 2.2739703342608344

Epoch: 5| Step: 7
Training loss: 0.09939982306646472
Validation loss: 2.2361989630039125

Epoch: 5| Step: 8
Training loss: 0.12707670505883745
Validation loss: 2.2687768912133444

Epoch: 5| Step: 9
Training loss: 0.11847943395247186
Validation loss: 2.270267422454718

Epoch: 5| Step: 10
Training loss: 0.08148360518551791
Validation loss: 2.2994198012042086

Epoch: 478| Step: 0
Training loss: 0.2231421689632593
Validation loss: 2.295029934983617

Epoch: 5| Step: 1
Training loss: 0.21959459368379597
Validation loss: 2.2963591032454467

Epoch: 5| Step: 2
Training loss: 0.06798447599668722
Validation loss: 2.302430982226146

Epoch: 5| Step: 3
Training loss: 0.10575051111803468
Validation loss: 2.3106662704590466

Epoch: 5| Step: 4
Training loss: 0.1200065646139284
Validation loss: 2.3095791037435833

Epoch: 5| Step: 5
Training loss: 0.17389183270003059
Validation loss: 2.3018231161084444

Epoch: 5| Step: 6
Training loss: 0.231194750848728
Validation loss: 2.3106417801974377

Epoch: 5| Step: 7
Training loss: 0.2243509796562213
Validation loss: 2.2875347594976736

Epoch: 5| Step: 8
Training loss: 0.11576534642713643
Validation loss: 2.296253411829867

Epoch: 5| Step: 9
Training loss: 0.25021694128574545
Validation loss: 2.2771786032704

Epoch: 5| Step: 10
Training loss: 0.15583946416349423
Validation loss: 2.3201247779777945

Epoch: 479| Step: 0
Training loss: 0.13956448892764048
Validation loss: 2.3102008483952545

Epoch: 5| Step: 1
Training loss: 0.22612364786818212
Validation loss: 2.280920336103043

Epoch: 5| Step: 2
Training loss: 0.22713700164846057
Validation loss: 2.2761053482517832

Epoch: 5| Step: 3
Training loss: 0.22886674754954534
Validation loss: 2.2894283166023777

Epoch: 5| Step: 4
Training loss: 0.1440200205481129
Validation loss: 2.3329982205625064

Epoch: 5| Step: 5
Training loss: 0.17548863108944504
Validation loss: 2.315717401767618

Epoch: 5| Step: 6
Training loss: 0.09301612632599704
Validation loss: 2.3168911204654483

Epoch: 5| Step: 7
Training loss: 0.20329425252662972
Validation loss: 2.3361509069727258

Epoch: 5| Step: 8
Training loss: 0.15463239068637877
Validation loss: 2.3560378072370876

Epoch: 5| Step: 9
Training loss: 0.2500961536033142
Validation loss: 2.341192804826899

Epoch: 5| Step: 10
Training loss: 0.11770169380403583
Validation loss: 2.354334968876353

Epoch: 480| Step: 0
Training loss: 0.163746228092737
Validation loss: 2.343780705514029

Epoch: 5| Step: 1
Training loss: 0.23974342111624486
Validation loss: 2.299936936429242

Epoch: 5| Step: 2
Training loss: 0.2801483353594116
Validation loss: 2.3212408641579056

Epoch: 5| Step: 3
Training loss: 0.11976401815064358
Validation loss: 2.3147394167562783

Epoch: 5| Step: 4
Training loss: 0.11496115071714061
Validation loss: 2.3013937106562965

Epoch: 5| Step: 5
Training loss: 0.23364313617827
Validation loss: 2.300162260255995

Epoch: 5| Step: 6
Training loss: 0.15242221230020356
Validation loss: 2.282299667259531

Epoch: 5| Step: 7
Training loss: 0.1433687563017254
Validation loss: 2.3117154405470632

Epoch: 5| Step: 8
Training loss: 0.23376349306941555
Validation loss: 2.301304977150729

Epoch: 5| Step: 9
Training loss: 0.10673446491395706
Validation loss: 2.283549030368419

Epoch: 5| Step: 10
Training loss: 0.09960843534587384
Validation loss: 2.285060887099393

Epoch: 481| Step: 0
Training loss: 0.21443678718966536
Validation loss: 2.333191625808419

Epoch: 5| Step: 1
Training loss: 0.102630202343326
Validation loss: 2.312391463717302

Epoch: 5| Step: 2
Training loss: 0.1067760779286754
Validation loss: 2.3376160869251517

Epoch: 5| Step: 3
Training loss: 0.1169164463364806
Validation loss: 2.3315850727660856

Epoch: 5| Step: 4
Training loss: 0.1304275304816453
Validation loss: 2.3104368028336846

Epoch: 5| Step: 5
Training loss: 0.2623181951003209
Validation loss: 2.302603237555331

Epoch: 5| Step: 6
Training loss: 0.09738590012179854
Validation loss: 2.322046519664985

Epoch: 5| Step: 7
Training loss: 0.21889736116647676
Validation loss: 2.3143854216744346

Epoch: 5| Step: 8
Training loss: 0.12374614896224861
Validation loss: 2.3053369373555817

Epoch: 5| Step: 9
Training loss: 0.2265483999797574
Validation loss: 2.30313770932226

Epoch: 5| Step: 10
Training loss: 0.23736607577787358
Validation loss: 2.3051595664293214

Epoch: 482| Step: 0
Training loss: 0.21311331834409425
Validation loss: 2.3184063146077443

Epoch: 5| Step: 1
Training loss: 0.1965643721796098
Validation loss: 2.3007625617586194

Epoch: 5| Step: 2
Training loss: 0.11595627184839741
Validation loss: 2.279742255237137

Epoch: 5| Step: 3
Training loss: 0.24662133083088913
Validation loss: 2.3356518034490934

Epoch: 5| Step: 4
Training loss: 0.09333633014733346
Validation loss: 2.278749324481746

Epoch: 5| Step: 5
Training loss: 0.12568103517952864
Validation loss: 2.3094871792034524

Epoch: 5| Step: 6
Training loss: 0.11178171877486784
Validation loss: 2.315849027590635

Epoch: 5| Step: 7
Training loss: 0.17662417381171683
Validation loss: 2.3108603848911473

Epoch: 5| Step: 8
Training loss: 0.2750971292064792
Validation loss: 2.281804275772276

Epoch: 5| Step: 9
Training loss: 0.12836135950951663
Validation loss: 2.2997986847194536

Epoch: 5| Step: 10
Training loss: 0.15795896668706733
Validation loss: 2.3003583250876165

Epoch: 483| Step: 0
Training loss: 0.23779336823541505
Validation loss: 2.2945160060089904

Epoch: 5| Step: 1
Training loss: 0.13193097397852507
Validation loss: 2.3010380564339115

Epoch: 5| Step: 2
Training loss: 0.1639507458040772
Validation loss: 2.2835362730282665

Epoch: 5| Step: 3
Training loss: 0.19901300539597438
Validation loss: 2.2796676335181862

Epoch: 5| Step: 4
Training loss: 0.10463702333605145
Validation loss: 2.2633195263612453

Epoch: 5| Step: 5
Training loss: 0.0864207244729907
Validation loss: 2.2666291893690436

Epoch: 5| Step: 6
Training loss: 0.23105387038588643
Validation loss: 2.2737914957415772

Epoch: 5| Step: 7
Training loss: 0.21799391973780838
Validation loss: 2.2597394661951835

Epoch: 5| Step: 8
Training loss: 0.10964441326708119
Validation loss: 2.27367347208985

Epoch: 5| Step: 9
Training loss: 0.18198765654285656
Validation loss: 2.245388559118512

Epoch: 5| Step: 10
Training loss: 0.21516135754752622
Validation loss: 2.2761758417619147

Epoch: 484| Step: 0
Training loss: 0.30281865577227823
Validation loss: 2.276476801110569

Epoch: 5| Step: 1
Training loss: 0.12270626730898604
Validation loss: 2.2640065954149193

Epoch: 5| Step: 2
Training loss: 0.11461403735194108
Validation loss: 2.2906824528542007

Epoch: 5| Step: 3
Training loss: 0.267871083736941
Validation loss: 2.309534364623611

Epoch: 5| Step: 4
Training loss: 0.11171968099566328
Validation loss: 2.335002994706269

Epoch: 5| Step: 5
Training loss: 0.13467986377302016
Validation loss: 2.3265368196678957

Epoch: 5| Step: 6
Training loss: 0.13261343258245661
Validation loss: 2.3325069955856903

Epoch: 5| Step: 7
Training loss: 0.15049947168528385
Validation loss: 2.334721700084159

Epoch: 5| Step: 8
Training loss: 0.13406886475799856
Validation loss: 2.326834754498962

Epoch: 5| Step: 9
Training loss: 0.21289617198752037
Validation loss: 2.3034522788293494

Epoch: 5| Step: 10
Training loss: 0.16048889969679542
Validation loss: 2.2953091294533556

Epoch: 485| Step: 0
Training loss: 0.13837514615115792
Validation loss: 2.323031312605826

Epoch: 5| Step: 1
Training loss: 0.19374383408979542
Validation loss: 2.3013982811941553

Epoch: 5| Step: 2
Training loss: 0.20464401620427497
Validation loss: 2.3208351666642884

Epoch: 5| Step: 3
Training loss: 0.25353420583289554
Validation loss: 2.2816328546961984

Epoch: 5| Step: 4
Training loss: 0.1781946656704021
Validation loss: 2.3053500394438906

Epoch: 5| Step: 5
Training loss: 0.17813135185962886
Validation loss: 2.317193834735942

Epoch: 5| Step: 6
Training loss: 0.09183594704079913
Validation loss: 2.3570658931748873

Epoch: 5| Step: 7
Training loss: 0.24896750476468774
Validation loss: 2.3620277545680604

Epoch: 5| Step: 8
Training loss: 0.24055899420721102
Validation loss: 2.384839170226784

Epoch: 5| Step: 9
Training loss: 0.2433946274747078
Validation loss: 2.3688748123681487

Epoch: 5| Step: 10
Training loss: 0.14999642045001796
Validation loss: 2.3438603047765145

Epoch: 486| Step: 0
Training loss: 0.1625907999603592
Validation loss: 2.305990573700358

Epoch: 5| Step: 1
Training loss: 0.2636370883176075
Validation loss: 2.2746111162751235

Epoch: 5| Step: 2
Training loss: 0.2600691606621636
Validation loss: 2.281577428564489

Epoch: 5| Step: 3
Training loss: 0.10289908285288343
Validation loss: 2.2468246111217933

Epoch: 5| Step: 4
Training loss: 0.147180011765312
Validation loss: 2.2313498979532427

Epoch: 5| Step: 5
Training loss: 0.24729496840517337
Validation loss: 2.2668366436619873

Epoch: 5| Step: 6
Training loss: 0.13005507668790814
Validation loss: 2.257986956226094

Epoch: 5| Step: 7
Training loss: 0.15338789914124076
Validation loss: 2.2703786765309473

Epoch: 5| Step: 8
Training loss: 0.11811153962757896
Validation loss: 2.284772544993437

Epoch: 5| Step: 9
Training loss: 0.14742303828602746
Validation loss: 2.2795704508025394

Epoch: 5| Step: 10
Training loss: 0.2771130260294765
Validation loss: 2.283872827508931

Epoch: 487| Step: 0
Training loss: 0.23973057030418016
Validation loss: 2.2701456301126477

Epoch: 5| Step: 1
Training loss: 0.1364295625811133
Validation loss: 2.2714760917672177

Epoch: 5| Step: 2
Training loss: 0.15361561249008637
Validation loss: 2.2799421565820075

Epoch: 5| Step: 3
Training loss: 0.24006362987968477
Validation loss: 2.2648324276725527

Epoch: 5| Step: 4
Training loss: 0.15203887437126948
Validation loss: 2.3006605905041995

Epoch: 5| Step: 5
Training loss: 0.23087031730628563
Validation loss: 2.295614064838572

Epoch: 5| Step: 6
Training loss: 0.21568007249625415
Validation loss: 2.271236604766216

Epoch: 5| Step: 7
Training loss: 0.14968166198575014
Validation loss: 2.299797757268954

Epoch: 5| Step: 8
Training loss: 0.12464739942820736
Validation loss: 2.308161432965948

Epoch: 5| Step: 9
Training loss: 0.17885052591912526
Validation loss: 2.3035707360192794

Epoch: 5| Step: 10
Training loss: 0.2283043985555904
Validation loss: 2.336267053591955

Epoch: 488| Step: 0
Training loss: 0.09573961068479045
Validation loss: 2.358999057072555

Epoch: 5| Step: 1
Training loss: 0.13289193274400043
Validation loss: 2.3156016966011

Epoch: 5| Step: 2
Training loss: 0.2595015739777226
Validation loss: 2.36288702427706

Epoch: 5| Step: 3
Training loss: 0.21914322455457186
Validation loss: 2.363704070334062

Epoch: 5| Step: 4
Training loss: 0.07873373399595826
Validation loss: 2.3628926107354444

Epoch: 5| Step: 5
Training loss: 0.17580817334302434
Validation loss: 2.387003559439364

Epoch: 5| Step: 6
Training loss: 0.24374194590393553
Validation loss: 2.3327638151533963

Epoch: 5| Step: 7
Training loss: 0.27389817260217547
Validation loss: 2.3392858319951175

Epoch: 5| Step: 8
Training loss: 0.0635395068084274
Validation loss: 2.3068424940317134

Epoch: 5| Step: 9
Training loss: 0.09964386492488493
Validation loss: 2.279270881864328

Epoch: 5| Step: 10
Training loss: 0.21541133812844643
Validation loss: 2.3348496605531124

Epoch: 489| Step: 0
Training loss: 0.14038722811640234
Validation loss: 2.3155870748685192

Epoch: 5| Step: 1
Training loss: 0.1504089975900657
Validation loss: 2.3067901280300656

Epoch: 5| Step: 2
Training loss: 0.14390866759068108
Validation loss: 2.2844189558337873

Epoch: 5| Step: 3
Training loss: 0.2766418170876338
Validation loss: 2.2839420895812625

Epoch: 5| Step: 4
Training loss: 0.16593555314597622
Validation loss: 2.2835394058159393

Epoch: 5| Step: 5
Training loss: 0.12382078133958298
Validation loss: 2.3013065133483606

Epoch: 5| Step: 6
Training loss: 0.27993734324988073
Validation loss: 2.282744399862025

Epoch: 5| Step: 7
Training loss: 0.25451619173378276
Validation loss: 2.3127465298231753

Epoch: 5| Step: 8
Training loss: 0.21720656784662662
Validation loss: 2.3277491621072466

Epoch: 5| Step: 9
Training loss: 0.2292840947581329
Validation loss: 2.3290144575764664

Epoch: 5| Step: 10
Training loss: 0.12126892632192096
Validation loss: 2.2982916381994967

Epoch: 490| Step: 0
Training loss: 0.15515750179573326
Validation loss: 2.310183806598011

Epoch: 5| Step: 1
Training loss: 0.10717007863849679
Validation loss: 2.315402926353862

Epoch: 5| Step: 2
Training loss: 0.10934746344524852
Validation loss: 2.296015532528234

Epoch: 5| Step: 3
Training loss: 0.2842966343773067
Validation loss: 2.32461619292761

Epoch: 5| Step: 4
Training loss: 0.2747715694857167
Validation loss: 2.3362325537621245

Epoch: 5| Step: 5
Training loss: 0.1798981799790079
Validation loss: 2.315154751536535

Epoch: 5| Step: 6
Training loss: 0.14289908666151996
Validation loss: 2.352271328076208

Epoch: 5| Step: 7
Training loss: 0.21562513959576055
Validation loss: 2.3456155288741285

Epoch: 5| Step: 8
Training loss: 0.20671289186257708
Validation loss: 2.3458704581915115

Epoch: 5| Step: 9
Training loss: 0.14855928193740628
Validation loss: 2.333322077458857

Epoch: 5| Step: 10
Training loss: 0.1036354262392277
Validation loss: 2.3519110938577357

Epoch: 491| Step: 0
Training loss: 0.11064266529849841
Validation loss: 2.332185260267698

Epoch: 5| Step: 1
Training loss: 0.13078786547255292
Validation loss: 2.3214720296099336

Epoch: 5| Step: 2
Training loss: 0.14078360461383943
Validation loss: 2.298517304558609

Epoch: 5| Step: 3
Training loss: 0.26735474666985465
Validation loss: 2.2889496189121044

Epoch: 5| Step: 4
Training loss: 0.08682434401895915
Validation loss: 2.2966162556978067

Epoch: 5| Step: 5
Training loss: 0.1348420216835272
Validation loss: 2.2685593739229426

Epoch: 5| Step: 6
Training loss: 0.19210803552310293
Validation loss: 2.2350029510803773

Epoch: 5| Step: 7
Training loss: 0.08993044070850602
Validation loss: 2.256090897255627

Epoch: 5| Step: 8
Training loss: 0.11836384207727775
Validation loss: 2.242342100601448

Epoch: 5| Step: 9
Training loss: 0.2714014132414056
Validation loss: 2.2428054452549717

Epoch: 5| Step: 10
Training loss: 0.2843722317110239
Validation loss: 2.260247232449447

Epoch: 492| Step: 0
Training loss: 0.2341679850908295
Validation loss: 2.2630083577090807

Epoch: 5| Step: 1
Training loss: 0.11355071246863453
Validation loss: 2.289870850780844

Epoch: 5| Step: 2
Training loss: 0.16005595486079066
Validation loss: 2.2772527971441936

Epoch: 5| Step: 3
Training loss: 0.20753597418772127
Validation loss: 2.2897807963338916

Epoch: 5| Step: 4
Training loss: 0.22252707331406923
Validation loss: 2.3236461248020466

Epoch: 5| Step: 5
Training loss: 0.17127159795167787
Validation loss: 2.3158300812394543

Epoch: 5| Step: 6
Training loss: 0.10387246686954499
Validation loss: 2.334830100335522

Epoch: 5| Step: 7
Training loss: 0.12942569285463917
Validation loss: 2.335585178517181

Epoch: 5| Step: 8
Training loss: 0.08800696514380354
Validation loss: 2.3525501505122715

Epoch: 5| Step: 9
Training loss: 0.2258774743733621
Validation loss: 2.3691608693305417

Epoch: 5| Step: 10
Training loss: 0.1993319059155249
Validation loss: 2.3086389459780827

Epoch: 493| Step: 0
Training loss: 0.11003962457396173
Validation loss: 2.2741834502569414

Epoch: 5| Step: 1
Training loss: 0.24404433831253827
Validation loss: 2.309838267224531

Epoch: 5| Step: 2
Training loss: 0.16703936819397636
Validation loss: 2.2870699007410447

Epoch: 5| Step: 3
Training loss: 0.1801045594910691
Validation loss: 2.2596580472744985

Epoch: 5| Step: 4
Training loss: 0.15871118275583307
Validation loss: 2.2805586596249294

Epoch: 5| Step: 5
Training loss: 0.06467138528511712
Validation loss: 2.296090997948708

Epoch: 5| Step: 6
Training loss: 0.2186521754193904
Validation loss: 2.2980182150191832

Epoch: 5| Step: 7
Training loss: 0.1348586728733292
Validation loss: 2.291115040730671

Epoch: 5| Step: 8
Training loss: 0.2227486034064818
Validation loss: 2.3041196918652167

Epoch: 5| Step: 9
Training loss: 0.20350425417539905
Validation loss: 2.322672091395628

Epoch: 5| Step: 10
Training loss: 0.09860090646146961
Validation loss: 2.322838977905348

Epoch: 494| Step: 0
Training loss: 0.1357603884233765
Validation loss: 2.3248189866489186

Epoch: 5| Step: 1
Training loss: 0.22252053591972595
Validation loss: 2.3602064922568604

Epoch: 5| Step: 2
Training loss: 0.19013750206424
Validation loss: 2.3739367848566584

Epoch: 5| Step: 3
Training loss: 0.08936417125577696
Validation loss: 2.3580081095681944

Epoch: 5| Step: 4
Training loss: 0.16926224699006406
Validation loss: 2.3677035102029786

Epoch: 5| Step: 5
Training loss: 0.07678471911437358
Validation loss: 2.3104895427718497

Epoch: 5| Step: 6
Training loss: 0.2206232635359469
Validation loss: 2.32325929240943

Epoch: 5| Step: 7
Training loss: 0.13195653979872604
Validation loss: 2.3267173280156364

Epoch: 5| Step: 8
Training loss: 0.1363398751821488
Validation loss: 2.299515965549279

Epoch: 5| Step: 9
Training loss: 0.253153933531557
Validation loss: 2.3085255518139727

Epoch: 5| Step: 10
Training loss: 0.14968797720472687
Validation loss: 2.2939664422671298

Epoch: 495| Step: 0
Training loss: 0.1438530785599792
Validation loss: 2.2809724457681697

Epoch: 5| Step: 1
Training loss: 0.10643979154495509
Validation loss: 2.2878185502512456

Epoch: 5| Step: 2
Training loss: 0.11212343433492662
Validation loss: 2.27152646984489

Epoch: 5| Step: 3
Training loss: 0.10232278630986429
Validation loss: 2.303266563533462

Epoch: 5| Step: 4
Training loss: 0.2849787852271749
Validation loss: 2.3374614770090565

Epoch: 5| Step: 5
Training loss: 0.2232265029697274
Validation loss: 2.3441100669112114

Epoch: 5| Step: 6
Training loss: 0.08287318475851192
Validation loss: 2.3666443842206206

Epoch: 5| Step: 7
Training loss: 0.2863230154458485
Validation loss: 2.3698450332432905

Epoch: 5| Step: 8
Training loss: 0.1350961239981416
Validation loss: 2.3443339098340488

Epoch: 5| Step: 9
Training loss: 0.11357755385509914
Validation loss: 2.335248599656701

Epoch: 5| Step: 10
Training loss: 0.09447631520489953
Validation loss: 2.344655104031712

Epoch: 496| Step: 0
Training loss: 0.10818075540995829
Validation loss: 2.333971428162693

Epoch: 5| Step: 1
Training loss: 0.1276152364314884
Validation loss: 2.314718811090701

Epoch: 5| Step: 2
Training loss: 0.17381360496998274
Validation loss: 2.3264223121352607

Epoch: 5| Step: 3
Training loss: 0.22122134917578337
Validation loss: 2.310313907332683

Epoch: 5| Step: 4
Training loss: 0.12895510932433774
Validation loss: 2.318775033203443

Epoch: 5| Step: 5
Training loss: 0.23786675250408637
Validation loss: 2.3274824532146514

Epoch: 5| Step: 6
Training loss: 0.2460412241874956
Validation loss: 2.310825539862718

Epoch: 5| Step: 7
Training loss: 0.11644337753280144
Validation loss: 2.3068914093825224

Epoch: 5| Step: 8
Training loss: 0.0544248279970469
Validation loss: 2.353383689180861

Epoch: 5| Step: 9
Training loss: 0.12796988838397438
Validation loss: 2.3384209880436186

Epoch: 5| Step: 10
Training loss: 0.1783973360372193
Validation loss: 2.3443783602073966

Epoch: 497| Step: 0
Training loss: 0.22052827170837866
Validation loss: 2.3577823947933596

Epoch: 5| Step: 1
Training loss: 0.1282067247590888
Validation loss: 2.32469643075219

Epoch: 5| Step: 2
Training loss: 0.21295389932475856
Validation loss: 2.3041734403348855

Epoch: 5| Step: 3
Training loss: 0.15019571381156893
Validation loss: 2.3102527686732164

Epoch: 5| Step: 4
Training loss: 0.2081501522989378
Validation loss: 2.29317701262897

Epoch: 5| Step: 5
Training loss: 0.1257845946275986
Validation loss: 2.2979439703491655

Epoch: 5| Step: 6
Training loss: 0.21004479086699715
Validation loss: 2.2826272720807403

Epoch: 5| Step: 7
Training loss: 0.18781859430844441
Validation loss: 2.2908281248291105

Epoch: 5| Step: 8
Training loss: 0.17065045484766683
Validation loss: 2.3039400869120144

Epoch: 5| Step: 9
Training loss: 0.10377260914019402
Validation loss: 2.336231189768529

Epoch: 5| Step: 10
Training loss: 0.10065359784327028
Validation loss: 2.362192754911805

Epoch: 498| Step: 0
Training loss: 0.22156207287724355
Validation loss: 2.3205221885259877

Epoch: 5| Step: 1
Training loss: 0.10611690378842738
Validation loss: 2.3186886653400847

Epoch: 5| Step: 2
Training loss: 0.08766469527171643
Validation loss: 2.3237049963718435

Epoch: 5| Step: 3
Training loss: 0.15796932558054821
Validation loss: 2.3493160509023774

Epoch: 5| Step: 4
Training loss: 0.1694132218220201
Validation loss: 2.3216630078288016

Epoch: 5| Step: 5
Training loss: 0.24020703478051647
Validation loss: 2.334134114612915

Epoch: 5| Step: 6
Training loss: 0.1989875929639278
Validation loss: 2.301027692833524

Epoch: 5| Step: 7
Training loss: 0.19901527036132266
Validation loss: 2.2939832670416864

Epoch: 5| Step: 8
Training loss: 0.1722137840273521
Validation loss: 2.323001593125265

Epoch: 5| Step: 9
Training loss: 0.09340667444185656
Validation loss: 2.2717739579431573

Epoch: 5| Step: 10
Training loss: 0.08818785423725391
Validation loss: 2.3068937908899585

Epoch: 499| Step: 0
Training loss: 0.2323029558506261
Validation loss: 2.2954819158633146

Epoch: 5| Step: 1
Training loss: 0.17991765458345363
Validation loss: 2.294947226163312

Epoch: 5| Step: 2
Training loss: 0.12432355313310631
Validation loss: 2.300455317208044

Epoch: 5| Step: 3
Training loss: 0.12392375349184952
Validation loss: 2.292987534744321

Epoch: 5| Step: 4
Training loss: 0.1667797510884921
Validation loss: 2.2893407111440363

Epoch: 5| Step: 5
Training loss: 0.15620474159905337
Validation loss: 2.287082161418385

Epoch: 5| Step: 6
Training loss: 0.13919962273158135
Validation loss: 2.3053482713001796

Epoch: 5| Step: 7
Training loss: 0.2554264045174164
Validation loss: 2.2970879780873736

Epoch: 5| Step: 8
Training loss: 0.09851867379137975
Validation loss: 2.3356980256496955

Epoch: 5| Step: 9
Training loss: 0.10130708930518482
Validation loss: 2.334922133878601

Epoch: 5| Step: 10
Training loss: 0.22336882622954815
Validation loss: 2.3552841222731162

Epoch: 500| Step: 0
Training loss: 0.30499026343563623
Validation loss: 2.3592278871265413

Epoch: 5| Step: 1
Training loss: 0.140564653905918
Validation loss: 2.3698435214613465

Epoch: 5| Step: 2
Training loss: 0.0803191958365483
Validation loss: 2.3461300060175296

Epoch: 5| Step: 3
Training loss: 0.1246243210800832
Validation loss: 2.3428353324866684

Epoch: 5| Step: 4
Training loss: 0.13240592798630985
Validation loss: 2.3488831943370068

Epoch: 5| Step: 5
Training loss: 0.20554125126765066
Validation loss: 2.339174133899036

Epoch: 5| Step: 6
Training loss: 0.14235300424477018
Validation loss: 2.3500944703749234

Epoch: 5| Step: 7
Training loss: 0.07013213349016088
Validation loss: 2.3186099621629226

Epoch: 5| Step: 8
Training loss: 0.22758969574470017
Validation loss: 2.328927860157753

Epoch: 5| Step: 9
Training loss: 0.14307147072430668
Validation loss: 2.3165507315540395

Epoch: 5| Step: 10
Training loss: 0.10633031950738396
Validation loss: 2.3299530498811496

Epoch: 501| Step: 0
Training loss: 0.10439509042816707
Validation loss: 2.302480984473525

Epoch: 5| Step: 1
Training loss: 0.1784386358208257
Validation loss: 2.3007652148028472

Epoch: 5| Step: 2
Training loss: 0.08994674480387592
Validation loss: 2.353190138302203

Epoch: 5| Step: 3
Training loss: 0.0726531245984797
Validation loss: 2.334629762958609

Epoch: 5| Step: 4
Training loss: 0.1393690381998837
Validation loss: 2.3452418172918414

Epoch: 5| Step: 5
Training loss: 0.11243689674610016
Validation loss: 2.3424588727775486

Epoch: 5| Step: 6
Training loss: 0.3098322364987957
Validation loss: 2.3717712676677962

Epoch: 5| Step: 7
Training loss: 0.1670748522759115
Validation loss: 2.36768199686443

Epoch: 5| Step: 8
Training loss: 0.14242398408509366
Validation loss: 2.340089729337417

Epoch: 5| Step: 9
Training loss: 0.22773778202917352
Validation loss: 2.300114103209289

Epoch: 5| Step: 10
Training loss: 0.09562618705224658
Validation loss: 2.313584860058086

Epoch: 502| Step: 0
Training loss: 0.07992518171105417
Validation loss: 2.312149466942081

Epoch: 5| Step: 1
Training loss: 0.21251584232404194
Validation loss: 2.311665640262654

Epoch: 5| Step: 2
Training loss: 0.1741539975932244
Validation loss: 2.284262792365159

Epoch: 5| Step: 3
Training loss: 0.1478014292815313
Validation loss: 2.2938352933618362

Epoch: 5| Step: 4
Training loss: 0.15292685738742526
Validation loss: 2.299116564246331

Epoch: 5| Step: 5
Training loss: 0.11674232963497708
Validation loss: 2.320914848155231

Epoch: 5| Step: 6
Training loss: 0.18302024383826318
Validation loss: 2.3287394747046704

Epoch: 5| Step: 7
Training loss: 0.1801513924154731
Validation loss: 2.3558546246207173

Epoch: 5| Step: 8
Training loss: 0.22363005557297383
Validation loss: 2.3489827578917577

Epoch: 5| Step: 9
Training loss: 0.15524295291709062
Validation loss: 2.3461267721388994

Epoch: 5| Step: 10
Training loss: 0.24667211718809248
Validation loss: 2.3550830832052063

Epoch: 503| Step: 0
Training loss: 0.10624173584522331
Validation loss: 2.3588657232898838

Epoch: 5| Step: 1
Training loss: 0.12855463044760224
Validation loss: 2.2980635342031577

Epoch: 5| Step: 2
Training loss: 0.11973120927738788
Validation loss: 2.32320392803714

Epoch: 5| Step: 3
Training loss: 0.11531328473689909
Validation loss: 2.2821237517752624

Epoch: 5| Step: 4
Training loss: 0.23515957801466283
Validation loss: 2.2811843563698218

Epoch: 5| Step: 5
Training loss: 0.22028037743375986
Validation loss: 2.29220217789904

Epoch: 5| Step: 6
Training loss: 0.14006220601053973
Validation loss: 2.284270876317182

Epoch: 5| Step: 7
Training loss: 0.22212575155044095
Validation loss: 2.2776435712802567

Epoch: 5| Step: 8
Training loss: 0.27830785087661813
Validation loss: 2.322897088554963

Epoch: 5| Step: 9
Training loss: 0.1463331013641369
Validation loss: 2.309881870623283

Epoch: 5| Step: 10
Training loss: 0.19591803143712958
Validation loss: 2.291377793467489

Epoch: 504| Step: 0
Training loss: 0.1411831824540464
Validation loss: 2.3073420531016713

Epoch: 5| Step: 1
Training loss: 0.21689164607616532
Validation loss: 2.2816702039483823

Epoch: 5| Step: 2
Training loss: 0.1375118480801289
Validation loss: 2.2580912093300243

Epoch: 5| Step: 3
Training loss: 0.11107780523196459
Validation loss: 2.300712638885065

Epoch: 5| Step: 4
Training loss: 0.16302864987298127
Validation loss: 2.2664209169363425

Epoch: 5| Step: 5
Training loss: 0.09000344182095756
Validation loss: 2.315553621786216

Epoch: 5| Step: 6
Training loss: 0.12639924045267387
Validation loss: 2.2559111356734425

Epoch: 5| Step: 7
Training loss: 0.31890171171152426
Validation loss: 2.2771709168790233

Epoch: 5| Step: 8
Training loss: 0.22158654394551985
Validation loss: 2.2711342424717893

Epoch: 5| Step: 9
Training loss: 0.07477642401870087
Validation loss: 2.2736400889913346

Epoch: 5| Step: 10
Training loss: 0.13356112115163424
Validation loss: 2.2828064779626533

Epoch: 505| Step: 0
Training loss: 0.17853255828078926
Validation loss: 2.3135962788100026

Epoch: 5| Step: 1
Training loss: 0.10445981995005686
Validation loss: 2.2997715566378147

Epoch: 5| Step: 2
Training loss: 0.18861713997609952
Validation loss: 2.320933184143076

Epoch: 5| Step: 3
Training loss: 0.0965443588780317
Validation loss: 2.300793822024508

Epoch: 5| Step: 4
Training loss: 0.1264997308986425
Validation loss: 2.2720837732330748

Epoch: 5| Step: 5
Training loss: 0.08526039513956837
Validation loss: 2.3016837452613386

Epoch: 5| Step: 6
Training loss: 0.12220252316039795
Validation loss: 2.311046268121855

Epoch: 5| Step: 7
Training loss: 0.2144904092087302
Validation loss: 2.3176362581696104

Epoch: 5| Step: 8
Training loss: 0.19565259886562458
Validation loss: 2.3224695180812427

Epoch: 5| Step: 9
Training loss: 0.21314199288995236
Validation loss: 2.324501859333438

Epoch: 5| Step: 10
Training loss: 0.22040500592597692
Validation loss: 2.3206989384586127

Epoch: 506| Step: 0
Training loss: 0.11941650374403197
Validation loss: 2.3332132978444817

Epoch: 5| Step: 1
Training loss: 0.12361286568899547
Validation loss: 2.3428020526414097

Epoch: 5| Step: 2
Training loss: 0.2012557160560882
Validation loss: 2.319456492306284

Epoch: 5| Step: 3
Training loss: 0.08413728942918419
Validation loss: 2.3571274267280327

Epoch: 5| Step: 4
Training loss: 0.14236495660870763
Validation loss: 2.3595940392406716

Epoch: 5| Step: 5
Training loss: 0.1507784314460394
Validation loss: 2.340639450383726

Epoch: 5| Step: 6
Training loss: 0.24007036456628575
Validation loss: 2.3147918709423427

Epoch: 5| Step: 7
Training loss: 0.0930834659499627
Validation loss: 2.336253742197529

Epoch: 5| Step: 8
Training loss: 0.12038211759032111
Validation loss: 2.3542868699394637

Epoch: 5| Step: 9
Training loss: 0.2234056977000942
Validation loss: 2.3368134789922026

Epoch: 5| Step: 10
Training loss: 0.18440551060856578
Validation loss: 2.3263471881784126

Epoch: 507| Step: 0
Training loss: 0.23448777664410647
Validation loss: 2.3397765015640903

Epoch: 5| Step: 1
Training loss: 0.20306562509594714
Validation loss: 2.361823050841016

Epoch: 5| Step: 2
Training loss: 0.14322802947777796
Validation loss: 2.3287117419598427

Epoch: 5| Step: 3
Training loss: 0.16326390338544547
Validation loss: 2.3297587260049415

Epoch: 5| Step: 4
Training loss: 0.22766029010033792
Validation loss: 2.322644706737594

Epoch: 5| Step: 5
Training loss: 0.049220686261374096
Validation loss: 2.3078965193544283

Epoch: 5| Step: 6
Training loss: 0.12637775323907965
Validation loss: 2.3116713083623117

Epoch: 5| Step: 7
Training loss: 0.1487472902880622
Validation loss: 2.3025983031110093

Epoch: 5| Step: 8
Training loss: 0.12633770918716997
Validation loss: 2.284842921167634

Epoch: 5| Step: 9
Training loss: 0.19733897818793852
Validation loss: 2.2799500781938997

Epoch: 5| Step: 10
Training loss: 0.08028582352079902
Validation loss: 2.2737940675081587

Epoch: 508| Step: 0
Training loss: 0.25757433265159724
Validation loss: 2.2453183795145986

Epoch: 5| Step: 1
Training loss: 0.24043327719319627
Validation loss: 2.259279617154566

Epoch: 5| Step: 2
Training loss: 0.12439323098186957
Validation loss: 2.2422763354806303

Epoch: 5| Step: 3
Training loss: 0.192173335476065
Validation loss: 2.262064087383915

Epoch: 5| Step: 4
Training loss: 0.1504701367034077
Validation loss: 2.2629512717313696

Epoch: 5| Step: 5
Training loss: 0.12114415350323642
Validation loss: 2.263121756180657

Epoch: 5| Step: 6
Training loss: 0.1972112769619754
Validation loss: 2.2668339000165805

Epoch: 5| Step: 7
Training loss: 0.1199125702568969
Validation loss: 2.307346269367049

Epoch: 5| Step: 8
Training loss: 0.15436761779547567
Validation loss: 2.2943881637594243

Epoch: 5| Step: 9
Training loss: 0.13078238941366244
Validation loss: 2.27871595836736

Epoch: 5| Step: 10
Training loss: 0.1430535424604199
Validation loss: 2.2615994433953035

Epoch: 509| Step: 0
Training loss: 0.21249510394795193
Validation loss: 2.3000412814163838

Epoch: 5| Step: 1
Training loss: 0.10802096723084105
Validation loss: 2.325876999356803

Epoch: 5| Step: 2
Training loss: 0.1720381038714072
Validation loss: 2.34002123464684

Epoch: 5| Step: 3
Training loss: 0.1241572701762466
Validation loss: 2.3337153632540866

Epoch: 5| Step: 4
Training loss: 0.14304390036981357
Validation loss: 2.323981766869805

Epoch: 5| Step: 5
Training loss: 0.11549081797324201
Validation loss: 2.30311853150748

Epoch: 5| Step: 6
Training loss: 0.15930986639557007
Validation loss: 2.2824100192108676

Epoch: 5| Step: 7
Training loss: 0.22589784997121234
Validation loss: 2.2697073745438514

Epoch: 5| Step: 8
Training loss: 0.2033918718362949
Validation loss: 2.2668971867925434

Epoch: 5| Step: 9
Training loss: 0.11894431904595579
Validation loss: 2.2909993289822217

Epoch: 5| Step: 10
Training loss: 0.16693350669971935
Validation loss: 2.2637304886482132

Epoch: 510| Step: 0
Training loss: 0.12065271849701738
Validation loss: 2.266595935517206

Epoch: 5| Step: 1
Training loss: 0.21840361008909198
Validation loss: 2.249730407920924

Epoch: 5| Step: 2
Training loss: 0.23398068955309975
Validation loss: 2.3007413072094485

Epoch: 5| Step: 3
Training loss: 0.13440131966524496
Validation loss: 2.283397474601374

Epoch: 5| Step: 4
Training loss: 0.11148501517627298
Validation loss: 2.2953009268935234

Epoch: 5| Step: 5
Training loss: 0.15559580465869036
Validation loss: 2.283917881853306

Epoch: 5| Step: 6
Training loss: 0.1343480981467859
Validation loss: 2.3221886371945244

Epoch: 5| Step: 7
Training loss: 0.2205721035836887
Validation loss: 2.306460571402536

Epoch: 5| Step: 8
Training loss: 0.15608284473032968
Validation loss: 2.285166872930819

Epoch: 5| Step: 9
Training loss: 0.0926644588664922
Validation loss: 2.2985645938793637

Epoch: 5| Step: 10
Training loss: 0.1433917502764082
Validation loss: 2.2776992332691726

Epoch: 511| Step: 0
Training loss: 0.13535416670766914
Validation loss: 2.281969408480968

Epoch: 5| Step: 1
Training loss: 0.11971583808423501
Validation loss: 2.2643837340033532

Epoch: 5| Step: 2
Training loss: 0.20764764757902066
Validation loss: 2.253817797846202

Epoch: 5| Step: 3
Training loss: 0.19213968007696888
Validation loss: 2.224008401163673

Epoch: 5| Step: 4
Training loss: 0.12042690293677716
Validation loss: 2.229129202888919

Epoch: 5| Step: 5
Training loss: 0.19687649143501784
Validation loss: 2.237856190700922

Epoch: 5| Step: 6
Training loss: 0.2322390582650554
Validation loss: 2.2385552643451745

Epoch: 5| Step: 7
Training loss: 0.14192202249889108
Validation loss: 2.235515774547141

Epoch: 5| Step: 8
Training loss: 0.13894077207811015
Validation loss: 2.254201052556996

Epoch: 5| Step: 9
Training loss: 0.11254796753924644
Validation loss: 2.2088627487318315

Epoch: 5| Step: 10
Training loss: 0.11794839440234724
Validation loss: 2.2610355942050373

Epoch: 512| Step: 0
Training loss: 0.10969352322530483
Validation loss: 2.2617493841203613

Epoch: 5| Step: 1
Training loss: 0.14188574851068003
Validation loss: 2.2630995477329106

Epoch: 5| Step: 2
Training loss: 0.11354333059013288
Validation loss: 2.2652292032456187

Epoch: 5| Step: 3
Training loss: 0.0772998266055604
Validation loss: 2.267047578603377

Epoch: 5| Step: 4
Training loss: 0.21392588049549263
Validation loss: 2.2362219361523943

Epoch: 5| Step: 5
Training loss: 0.2071498854829498
Validation loss: 2.273229757738691

Epoch: 5| Step: 6
Training loss: 0.3050141906173025
Validation loss: 2.251877686015953

Epoch: 5| Step: 7
Training loss: 0.09777926326682781
Validation loss: 2.2451892345881728

Epoch: 5| Step: 8
Training loss: 0.11777035881560736
Validation loss: 2.2364961202718066

Epoch: 5| Step: 9
Training loss: 0.14304264379021853
Validation loss: 2.2506133614194823

Epoch: 5| Step: 10
Training loss: 0.10296122522022301
Validation loss: 2.2817602324476463

Epoch: 513| Step: 0
Training loss: 0.22070202784982929
Validation loss: 2.2805441251611556

Epoch: 5| Step: 1
Training loss: 0.12655495044184759
Validation loss: 2.287492844926634

Epoch: 5| Step: 2
Training loss: 0.19446941564974113
Validation loss: 2.307129777972292

Epoch: 5| Step: 3
Training loss: 0.09257664136059926
Validation loss: 2.3003088924480313

Epoch: 5| Step: 4
Training loss: 0.09265963953453936
Validation loss: 2.2665484828136093

Epoch: 5| Step: 5
Training loss: 0.13895833957916123
Validation loss: 2.277381371093594

Epoch: 5| Step: 6
Training loss: 0.207814928628598
Validation loss: 2.3046258911552338

Epoch: 5| Step: 7
Training loss: 0.13584057926332627
Validation loss: 2.301503374326209

Epoch: 5| Step: 8
Training loss: 0.1520580767753739
Validation loss: 2.287225699378956

Epoch: 5| Step: 9
Training loss: 0.16483730760071197
Validation loss: 2.262646609840794

Epoch: 5| Step: 10
Training loss: 0.15199447598740615
Validation loss: 2.30392164016297

Epoch: 514| Step: 0
Training loss: 0.1079920203613233
Validation loss: 2.2903412911915897

Epoch: 5| Step: 1
Training loss: 0.07942206303046838
Validation loss: 2.272939688608815

Epoch: 5| Step: 2
Training loss: 0.11904926392931692
Validation loss: 2.2651022302648913

Epoch: 5| Step: 3
Training loss: 0.2393684831907471
Validation loss: 2.3192835971386208

Epoch: 5| Step: 4
Training loss: 0.05676423757775433
Validation loss: 2.3188955063392678

Epoch: 5| Step: 5
Training loss: 0.26945878865435696
Validation loss: 2.2847063001454058

Epoch: 5| Step: 6
Training loss: 0.104507498644363
Validation loss: 2.2991237580102064

Epoch: 5| Step: 7
Training loss: 0.11158844561296362
Validation loss: 2.292517238140654

Epoch: 5| Step: 8
Training loss: 0.23157376937625707
Validation loss: 2.2578954319853444

Epoch: 5| Step: 9
Training loss: 0.15134064841651607
Validation loss: 2.281403140149169

Epoch: 5| Step: 10
Training loss: 0.0972247700508755
Validation loss: 2.268436992616338

Epoch: 515| Step: 0
Training loss: 0.07427095785482775
Validation loss: 2.27094164075714

Epoch: 5| Step: 1
Training loss: 0.1634735252982404
Validation loss: 2.265948402143378

Epoch: 5| Step: 2
Training loss: 0.15586508785858655
Validation loss: 2.267241315350754

Epoch: 5| Step: 3
Training loss: 0.10049941220930071
Validation loss: 2.2827906079299023

Epoch: 5| Step: 4
Training loss: 0.24261799360297048
Validation loss: 2.275093356568474

Epoch: 5| Step: 5
Training loss: 0.2498575490179058
Validation loss: 2.264280365033289

Epoch: 5| Step: 6
Training loss: 0.07861045275510263
Validation loss: 2.279119100665045

Epoch: 5| Step: 7
Training loss: 0.10231640119082552
Validation loss: 2.2785402511301265

Epoch: 5| Step: 8
Training loss: 0.10553440946526625
Validation loss: 2.2890398824531175

Epoch: 5| Step: 9
Training loss: 0.09101074005082743
Validation loss: 2.2768816938190937

Epoch: 5| Step: 10
Training loss: 0.16323488822988513
Validation loss: 2.3120443504392068

Epoch: 516| Step: 0
Training loss: 0.0973746531282008
Validation loss: 2.2924388347169704

Epoch: 5| Step: 1
Training loss: 0.06790734770471764
Validation loss: 2.328965130393769

Epoch: 5| Step: 2
Training loss: 0.168333207108156
Validation loss: 2.3064832591759483

Epoch: 5| Step: 3
Training loss: 0.08757178170034104
Validation loss: 2.329444694013402

Epoch: 5| Step: 4
Training loss: 0.10393718137193335
Validation loss: 2.321135484538761

Epoch: 5| Step: 5
Training loss: 0.13729247558463498
Validation loss: 2.298820204316942

Epoch: 5| Step: 6
Training loss: 0.21612797897011157
Validation loss: 2.2858667559769104

Epoch: 5| Step: 7
Training loss: 0.13970999928013117
Validation loss: 2.3023133833669776

Epoch: 5| Step: 8
Training loss: 0.24192680664101426
Validation loss: 2.2895535822112976

Epoch: 5| Step: 9
Training loss: 0.14893604305745717
Validation loss: 2.269155749876101

Epoch: 5| Step: 10
Training loss: 0.19413413299820068
Validation loss: 2.281701441525545

Epoch: 517| Step: 0
Training loss: 0.13303590665485157
Validation loss: 2.2900923141695966

Epoch: 5| Step: 1
Training loss: 0.1197520459173055
Validation loss: 2.3226992196646683

Epoch: 5| Step: 2
Training loss: 0.0887162635208893
Validation loss: 2.339663323551234

Epoch: 5| Step: 3
Training loss: 0.2154857320504217
Validation loss: 2.3548293814837487

Epoch: 5| Step: 4
Training loss: 0.2077111828996587
Validation loss: 2.3426007631453665

Epoch: 5| Step: 5
Training loss: 0.08884346823592293
Validation loss: 2.3826733598812324

Epoch: 5| Step: 6
Training loss: 0.14056817204568303
Validation loss: 2.334741189288257

Epoch: 5| Step: 7
Training loss: 0.09843185461598475
Validation loss: 2.3642077505256527

Epoch: 5| Step: 8
Training loss: 0.12307475546185494
Validation loss: 2.339487001257021

Epoch: 5| Step: 9
Training loss: 0.2515685228847011
Validation loss: 2.335238352750143

Epoch: 5| Step: 10
Training loss: 0.11978368283355663
Validation loss: 2.301445717115452

Epoch: 518| Step: 0
Training loss: 0.10631464891711953
Validation loss: 2.2916176672327464

Epoch: 5| Step: 1
Training loss: 0.13859694430982633
Validation loss: 2.2821533717096476

Epoch: 5| Step: 2
Training loss: 0.08375824103536215
Validation loss: 2.2843346838778964

Epoch: 5| Step: 3
Training loss: 0.09772302252124478
Validation loss: 2.238418894425092

Epoch: 5| Step: 4
Training loss: 0.08487564771602409
Validation loss: 2.2431094167393644

Epoch: 5| Step: 5
Training loss: 0.12183669814997258
Validation loss: 2.2451350052290535

Epoch: 5| Step: 6
Training loss: 0.2487399188950977
Validation loss: 2.233043245374164

Epoch: 5| Step: 7
Training loss: 0.21444063515068232
Validation loss: 2.2395570811177974

Epoch: 5| Step: 8
Training loss: 0.14800262746137896
Validation loss: 2.271586549410083

Epoch: 5| Step: 9
Training loss: 0.1285283444727978
Validation loss: 2.2574819680617355

Epoch: 5| Step: 10
Training loss: 0.22419462472937968
Validation loss: 2.256399597166205

Epoch: 519| Step: 0
Training loss: 0.17628477881256624
Validation loss: 2.271428269523358

Epoch: 5| Step: 1
Training loss: 0.08604556030514562
Validation loss: 2.24846779417091

Epoch: 5| Step: 2
Training loss: 0.20153460161696457
Validation loss: 2.28488003870737

Epoch: 5| Step: 3
Training loss: 0.09008920353292016
Validation loss: 2.281679949866676

Epoch: 5| Step: 4
Training loss: 0.12126264023274791
Validation loss: 2.2789475771673904

Epoch: 5| Step: 5
Training loss: 0.086105174974199
Validation loss: 2.2627423582620554

Epoch: 5| Step: 6
Training loss: 0.08471989694689254
Validation loss: 2.2634083892873966

Epoch: 5| Step: 7
Training loss: 0.15946922999367155
Validation loss: 2.247620996372425

Epoch: 5| Step: 8
Training loss: 0.22352242556442864
Validation loss: 2.3130856553659083

Epoch: 5| Step: 9
Training loss: 0.23364972110619808
Validation loss: 2.2923698562069044

Epoch: 5| Step: 10
Training loss: 0.056850914440206866
Validation loss: 2.293966755183359

Epoch: 520| Step: 0
Training loss: 0.19398611778493452
Validation loss: 2.3121452342109254

Epoch: 5| Step: 1
Training loss: 0.24063898919052787
Validation loss: 2.3010279011755523

Epoch: 5| Step: 2
Training loss: 0.19381119699910476
Validation loss: 2.3195531110742214

Epoch: 5| Step: 3
Training loss: 0.23031994493167326
Validation loss: 2.343508388959166

Epoch: 5| Step: 4
Training loss: 0.09668173932296854
Validation loss: 2.3188028742876345

Epoch: 5| Step: 5
Training loss: 0.07928682930741014
Validation loss: 2.3267603187154573

Epoch: 5| Step: 6
Training loss: 0.07951454977469302
Validation loss: 2.3400945266623636

Epoch: 5| Step: 7
Training loss: 0.0845188995530246
Validation loss: 2.322683118346469

Epoch: 5| Step: 8
Training loss: 0.11169681233646923
Validation loss: 2.3143203109488955

Epoch: 5| Step: 9
Training loss: 0.10239994057166063
Validation loss: 2.3098581403522256

Epoch: 5| Step: 10
Training loss: 0.05480313422597845
Validation loss: 2.3051249672016993

Epoch: 521| Step: 0
Training loss: 0.18125450975463914
Validation loss: 2.3070700356201206

Epoch: 5| Step: 1
Training loss: 0.05527522611588507
Validation loss: 2.305494423956824

Epoch: 5| Step: 2
Training loss: 0.2513551046673035
Validation loss: 2.3139079474224835

Epoch: 5| Step: 3
Training loss: 0.14131013543817672
Validation loss: 2.2984555105272184

Epoch: 5| Step: 4
Training loss: 0.18215885887627173
Validation loss: 2.297558010247839

Epoch: 5| Step: 5
Training loss: 0.11916978666777249
Validation loss: 2.29164063409989

Epoch: 5| Step: 6
Training loss: 0.08154063021567329
Validation loss: 2.276669451981014

Epoch: 5| Step: 7
Training loss: 0.12692942764951556
Validation loss: 2.281676396555081

Epoch: 5| Step: 8
Training loss: 0.125095963894715
Validation loss: 2.284710366587291

Epoch: 5| Step: 9
Training loss: 0.18438842934661373
Validation loss: 2.2760178275232756

Epoch: 5| Step: 10
Training loss: 0.0926061276043005
Validation loss: 2.2889880163655993

Epoch: 522| Step: 0
Training loss: 0.27250956713216906
Validation loss: 2.27806915570811

Epoch: 5| Step: 1
Training loss: 0.14188161319914547
Validation loss: 2.263697569337276

Epoch: 5| Step: 2
Training loss: 0.08878797626963753
Validation loss: 2.2704289251131065

Epoch: 5| Step: 3
Training loss: 0.10589648859530647
Validation loss: 2.27946572081229

Epoch: 5| Step: 4
Training loss: 0.1316911255274495
Validation loss: 2.261500406186818

Epoch: 5| Step: 5
Training loss: 0.1425075486969502
Validation loss: 2.2515893037896015

Epoch: 5| Step: 6
Training loss: 0.15524376879655527
Validation loss: 2.2316662120392055

Epoch: 5| Step: 7
Training loss: 0.209773063882952
Validation loss: 2.2679632147365174

Epoch: 5| Step: 8
Training loss: 0.13130120516065608
Validation loss: 2.2713528582885125

Epoch: 5| Step: 9
Training loss: 0.09200031989692448
Validation loss: 2.269972233123833

Epoch: 5| Step: 10
Training loss: 0.07052089683352832
Validation loss: 2.26667957422875

Epoch: 523| Step: 0
Training loss: 0.11340677771415296
Validation loss: 2.2757045861088896

Epoch: 5| Step: 1
Training loss: 0.13012591535143686
Validation loss: 2.2686185167203083

Epoch: 5| Step: 2
Training loss: 0.27317805924921595
Validation loss: 2.2785389381098793

Epoch: 5| Step: 3
Training loss: 0.2061572610547836
Validation loss: 2.2941779650179646

Epoch: 5| Step: 4
Training loss: 0.1735266900774688
Validation loss: 2.2904005414354054

Epoch: 5| Step: 5
Training loss: 0.10710186543144601
Validation loss: 2.279488663910444

Epoch: 5| Step: 6
Training loss: 0.11904697176780027
Validation loss: 2.2752808182199797

Epoch: 5| Step: 7
Training loss: 0.11098168661714068
Validation loss: 2.295064261929937

Epoch: 5| Step: 8
Training loss: 0.06987144633658607
Validation loss: 2.27801557796575

Epoch: 5| Step: 9
Training loss: 0.09945765328417841
Validation loss: 2.2797541808562576

Epoch: 5| Step: 10
Training loss: 0.07044391470926162
Validation loss: 2.291741044598484

Epoch: 524| Step: 0
Training loss: 0.12958299838673928
Validation loss: 2.277149120147155

Epoch: 5| Step: 1
Training loss: 0.20928118475710344
Validation loss: 2.2936426460881574

Epoch: 5| Step: 2
Training loss: 0.07165145863868784
Validation loss: 2.3064288791431338

Epoch: 5| Step: 3
Training loss: 0.09571170768399886
Validation loss: 2.306970252308099

Epoch: 5| Step: 4
Training loss: 0.2484636035137195
Validation loss: 2.302677736136618

Epoch: 5| Step: 5
Training loss: 0.11693616777259568
Validation loss: 2.29939360462832

Epoch: 5| Step: 6
Training loss: 0.18439802575595732
Validation loss: 2.280452246590904

Epoch: 5| Step: 7
Training loss: 0.08815555908408368
Validation loss: 2.278440875748968

Epoch: 5| Step: 8
Training loss: 0.1456486832920958
Validation loss: 2.284516807596398

Epoch: 5| Step: 9
Training loss: 0.16209309277861814
Validation loss: 2.28460955506948

Epoch: 5| Step: 10
Training loss: 0.13367667663886104
Validation loss: 2.272016022731523

Epoch: 525| Step: 0
Training loss: 0.2794928763305791
Validation loss: 2.2576301206680482

Epoch: 5| Step: 1
Training loss: 0.08585430040887512
Validation loss: 2.247036863891321

Epoch: 5| Step: 2
Training loss: 0.09695112771183263
Validation loss: 2.277418760238862

Epoch: 5| Step: 3
Training loss: 0.14041335683420436
Validation loss: 2.2983815175657805

Epoch: 5| Step: 4
Training loss: 0.19871691533390698
Validation loss: 2.284102572589434

Epoch: 5| Step: 5
Training loss: 0.11443130656253526
Validation loss: 2.3004962155355546

Epoch: 5| Step: 6
Training loss: 0.1894571362886798
Validation loss: 2.3233237748325997

Epoch: 5| Step: 7
Training loss: 0.08158156914702273
Validation loss: 2.309893252187978

Epoch: 5| Step: 8
Training loss: 0.13408131943060184
Validation loss: 2.305066456341111

Epoch: 5| Step: 9
Training loss: 0.1364352625048727
Validation loss: 2.296877648605484

Epoch: 5| Step: 10
Training loss: 0.14429364133143302
Validation loss: 2.266869402034012

Epoch: 526| Step: 0
Training loss: 0.19355892711811704
Validation loss: 2.270464307686021

Epoch: 5| Step: 1
Training loss: 0.11176282940097004
Validation loss: 2.2534912970604037

Epoch: 5| Step: 2
Training loss: 0.18669404221505762
Validation loss: 2.2592955479430943

Epoch: 5| Step: 3
Training loss: 0.20875398467880765
Validation loss: 2.2380442461722367

Epoch: 5| Step: 4
Training loss: 0.14950770516617715
Validation loss: 2.259479946346938

Epoch: 5| Step: 5
Training loss: 0.13896989364187756
Validation loss: 2.250084951749948

Epoch: 5| Step: 6
Training loss: 0.10308226256127938
Validation loss: 2.2969241650087944

Epoch: 5| Step: 7
Training loss: 0.19180168448825738
Validation loss: 2.279643620497166

Epoch: 5| Step: 8
Training loss: 0.09859798779727894
Validation loss: 2.3170277299398303

Epoch: 5| Step: 9
Training loss: 0.22557099197883068
Validation loss: 2.304081649500973

Epoch: 5| Step: 10
Training loss: 0.11904616206879787
Validation loss: 2.3291739114469676

Epoch: 527| Step: 0
Training loss: 0.11543492468298719
Validation loss: 2.3237014791902117

Epoch: 5| Step: 1
Training loss: 0.07697073473561032
Validation loss: 2.3611391183670722

Epoch: 5| Step: 2
Training loss: 0.19711104086505732
Validation loss: 2.3489471130415978

Epoch: 5| Step: 3
Training loss: 0.22055852423457492
Validation loss: 2.3572149751682874

Epoch: 5| Step: 4
Training loss: 0.0737913114357482
Validation loss: 2.360939535590188

Epoch: 5| Step: 5
Training loss: 0.11317574998009021
Validation loss: 2.3290320836680616

Epoch: 5| Step: 6
Training loss: 0.2298333655292907
Validation loss: 2.3068696073066777

Epoch: 5| Step: 7
Training loss: 0.12187176770423402
Validation loss: 2.2849518199203387

Epoch: 5| Step: 8
Training loss: 0.09765870091223747
Validation loss: 2.275593837730122

Epoch: 5| Step: 9
Training loss: 0.13187775125390694
Validation loss: 2.269131234141346

Epoch: 5| Step: 10
Training loss: 0.14479541479263386
Validation loss: 2.273457957724987

Epoch: 528| Step: 0
Training loss: 0.18912203852244078
Validation loss: 2.2448122727705266

Epoch: 5| Step: 1
Training loss: 0.11127768595300704
Validation loss: 2.2657548136680052

Epoch: 5| Step: 2
Training loss: 0.09418273929538866
Validation loss: 2.2693389578984995

Epoch: 5| Step: 3
Training loss: 0.11154705405498111
Validation loss: 2.296162486749053

Epoch: 5| Step: 4
Training loss: 0.08512140335384523
Validation loss: 2.2809102784134154

Epoch: 5| Step: 5
Training loss: 0.10285440728599389
Validation loss: 2.304859434304867

Epoch: 5| Step: 6
Training loss: 0.2149370944376206
Validation loss: 2.2860116590756414

Epoch: 5| Step: 7
Training loss: 0.10172011451421246
Validation loss: 2.3357416676468707

Epoch: 5| Step: 8
Training loss: 0.17547114887788753
Validation loss: 2.330118424171164

Epoch: 5| Step: 9
Training loss: 0.20423755039690983
Validation loss: 2.308942558950309

Epoch: 5| Step: 10
Training loss: 0.24386263470216554
Validation loss: 2.315119749119872

Epoch: 529| Step: 0
Training loss: 0.12146806546109871
Validation loss: 2.2843218607831357

Epoch: 5| Step: 1
Training loss: 0.11271609952600897
Validation loss: 2.2769509416824327

Epoch: 5| Step: 2
Training loss: 0.19201047078777567
Validation loss: 2.2629134130021655

Epoch: 5| Step: 3
Training loss: 0.18551549144153065
Validation loss: 2.2466445237577175

Epoch: 5| Step: 4
Training loss: 0.08597145168499318
Validation loss: 2.2295612066176935

Epoch: 5| Step: 5
Training loss: 0.1377308711678951
Validation loss: 2.2364345208724314

Epoch: 5| Step: 6
Training loss: 0.21859603811106756
Validation loss: 2.224902401892464

Epoch: 5| Step: 7
Training loss: 0.13744951860372004
Validation loss: 2.232814004602873

Epoch: 5| Step: 8
Training loss: 0.12197966452409287
Validation loss: 2.267216235592632

Epoch: 5| Step: 9
Training loss: 0.2057174526372451
Validation loss: 2.2910049419064653

Epoch: 5| Step: 10
Training loss: 0.10881879424208787
Validation loss: 2.2761742322888256

Epoch: 530| Step: 0
Training loss: 0.08083737783641029
Validation loss: 2.315872536791445

Epoch: 5| Step: 1
Training loss: 0.08655683365929494
Validation loss: 2.3357856216302992

Epoch: 5| Step: 2
Training loss: 0.09851092654072695
Validation loss: 2.3167219359305316

Epoch: 5| Step: 3
Training loss: 0.17918217133554576
Validation loss: 2.3488820630699583

Epoch: 5| Step: 4
Training loss: 0.09436041078158515
Validation loss: 2.3234517341001935

Epoch: 5| Step: 5
Training loss: 0.1846103322072504
Validation loss: 2.3513524014056584

Epoch: 5| Step: 6
Training loss: 0.18627474718049836
Validation loss: 2.3480462548907752

Epoch: 5| Step: 7
Training loss: 0.17754669550737479
Validation loss: 2.3054892092286132

Epoch: 5| Step: 8
Training loss: 0.11284035352033892
Validation loss: 2.327465240556273

Epoch: 5| Step: 9
Training loss: 0.11418566096651371
Validation loss: 2.302357600280628

Epoch: 5| Step: 10
Training loss: 0.1590016252592831
Validation loss: 2.2839598075920002

Epoch: 531| Step: 0
Training loss: 0.12604903568710776
Validation loss: 2.312898524476624

Epoch: 5| Step: 1
Training loss: 0.1286531767377328
Validation loss: 2.3272563125501313

Epoch: 5| Step: 2
Training loss: 0.19530602444404357
Validation loss: 2.302919499795092

Epoch: 5| Step: 3
Training loss: 0.15001600845664567
Validation loss: 2.3276012365831655

Epoch: 5| Step: 4
Training loss: 0.11963862165587469
Validation loss: 2.3327658163793945

Epoch: 5| Step: 5
Training loss: 0.08155850587945444
Validation loss: 2.3530580496806452

Epoch: 5| Step: 6
Training loss: 0.1757204904451425
Validation loss: 2.357124333556799

Epoch: 5| Step: 7
Training loss: 0.20207985345721688
Validation loss: 2.3596377211189115

Epoch: 5| Step: 8
Training loss: 0.19507071788445818
Validation loss: 2.354999340165182

Epoch: 5| Step: 9
Training loss: 0.12261742627380981
Validation loss: 2.3466550327222073

Epoch: 5| Step: 10
Training loss: 0.13899197370568372
Validation loss: 2.321286024282952

Epoch: 532| Step: 0
Training loss: 0.06522840169867027
Validation loss: 2.3256597543685333

Epoch: 5| Step: 1
Training loss: 0.17911285273285396
Validation loss: 2.3007417247810538

Epoch: 5| Step: 2
Training loss: 0.12817370460140998
Validation loss: 2.24783497079073

Epoch: 5| Step: 3
Training loss: 0.22617435915147688
Validation loss: 2.2773151386409562

Epoch: 5| Step: 4
Training loss: 0.11186694373261354
Validation loss: 2.258860895397464

Epoch: 5| Step: 5
Training loss: 0.16083171918924585
Validation loss: 2.280506814798341

Epoch: 5| Step: 6
Training loss: 0.10187238404653992
Validation loss: 2.313335913934226

Epoch: 5| Step: 7
Training loss: 0.12712477304125155
Validation loss: 2.2931629382454197

Epoch: 5| Step: 8
Training loss: 0.205533983296807
Validation loss: 2.307697981935766

Epoch: 5| Step: 9
Training loss: 0.09689739068519342
Validation loss: 2.3307951498439228

Epoch: 5| Step: 10
Training loss: 0.2169289315607867
Validation loss: 2.332469596469882

Epoch: 533| Step: 0
Training loss: 0.09579346246790074
Validation loss: 2.336270512901587

Epoch: 5| Step: 1
Training loss: 0.13558701352390626
Validation loss: 2.351870232845632

Epoch: 5| Step: 2
Training loss: 0.20105288977418675
Validation loss: 2.32997466181699

Epoch: 5| Step: 3
Training loss: 0.18089569295647598
Validation loss: 2.305917365624113

Epoch: 5| Step: 4
Training loss: 0.15547203463051074
Validation loss: 2.3258262490404236

Epoch: 5| Step: 5
Training loss: 0.11645866084635659
Validation loss: 2.308620483472409

Epoch: 5| Step: 6
Training loss: 0.12422232562742927
Validation loss: 2.306417003638404

Epoch: 5| Step: 7
Training loss: 0.09839995440214543
Validation loss: 2.3059598580427

Epoch: 5| Step: 8
Training loss: 0.1255953291352131
Validation loss: 2.2991379743111415

Epoch: 5| Step: 9
Training loss: 0.19426676223484604
Validation loss: 2.3084340778509045

Epoch: 5| Step: 10
Training loss: 0.1649407313927621
Validation loss: 2.326602868897011

Epoch: 534| Step: 0
Training loss: 0.10933548349693054
Validation loss: 2.3090731442980954

Epoch: 5| Step: 1
Training loss: 0.0685740709751398
Validation loss: 2.287105801540497

Epoch: 5| Step: 2
Training loss: 0.07625639334633051
Validation loss: 2.291835295624832

Epoch: 5| Step: 3
Training loss: 0.15538091358775816
Validation loss: 2.276648957239732

Epoch: 5| Step: 4
Training loss: 0.20089807673894186
Validation loss: 2.282080670611812

Epoch: 5| Step: 5
Training loss: 0.13403186901658448
Validation loss: 2.27516904777795

Epoch: 5| Step: 6
Training loss: 0.22951166597855427
Validation loss: 2.268321552012595

Epoch: 5| Step: 7
Training loss: 0.062484744937137404
Validation loss: 2.2725526495658728

Epoch: 5| Step: 8
Training loss: 0.18802238254137832
Validation loss: 2.251183256803256

Epoch: 5| Step: 9
Training loss: 0.12258268400725764
Validation loss: 2.254289045585435

Epoch: 5| Step: 10
Training loss: 0.07533100814856471
Validation loss: 2.254527651255477

Epoch: 535| Step: 0
Training loss: 0.07054962796535409
Validation loss: 2.2455336850405496

Epoch: 5| Step: 1
Training loss: 0.2562199737821093
Validation loss: 2.2552954769588576

Epoch: 5| Step: 2
Training loss: 0.1265460751319002
Validation loss: 2.2500514619335994

Epoch: 5| Step: 3
Training loss: 0.07847873653877202
Validation loss: 2.264053629215617

Epoch: 5| Step: 4
Training loss: 0.19108108225870515
Validation loss: 2.270456372173531

Epoch: 5| Step: 5
Training loss: 0.06186176740450469
Validation loss: 2.2930030848833143

Epoch: 5| Step: 6
Training loss: 0.07458424606854726
Validation loss: 2.292195863301181

Epoch: 5| Step: 7
Training loss: 0.13471339084236536
Validation loss: 2.2654811939375428

Epoch: 5| Step: 8
Training loss: 0.16807332775486133
Validation loss: 2.2849842882938973

Epoch: 5| Step: 9
Training loss: 0.15658193140263446
Validation loss: 2.264580640587381

Epoch: 5| Step: 10
Training loss: 0.11647351037110898
Validation loss: 2.3042043372378234

Epoch: 536| Step: 0
Training loss: 0.08141225056855309
Validation loss: 2.2999064397708864

Epoch: 5| Step: 1
Training loss: 0.0893777704809847
Validation loss: 2.2767102387879947

Epoch: 5| Step: 2
Training loss: 0.07134162258592998
Validation loss: 2.288186237895761

Epoch: 5| Step: 3
Training loss: 0.1938351643954991
Validation loss: 2.262454997727659

Epoch: 5| Step: 4
Training loss: 0.21699513142371632
Validation loss: 2.2731634718479476

Epoch: 5| Step: 5
Training loss: 0.1885244081477026
Validation loss: 2.258354164049109

Epoch: 5| Step: 6
Training loss: 0.09406509693654372
Validation loss: 2.290121932349133

Epoch: 5| Step: 7
Training loss: 0.08693707086572379
Validation loss: 2.2993923486702452

Epoch: 5| Step: 8
Training loss: 0.13860604913277888
Validation loss: 2.3065643616082814

Epoch: 5| Step: 9
Training loss: 0.15311379707966402
Validation loss: 2.290707061935682

Epoch: 5| Step: 10
Training loss: 0.1237085053446032
Validation loss: 2.3114070310481316

Epoch: 537| Step: 0
Training loss: 0.16660123089380569
Validation loss: 2.292164156956978

Epoch: 5| Step: 1
Training loss: 0.11624380256043106
Validation loss: 2.3053928303322313

Epoch: 5| Step: 2
Training loss: 0.08758959610854725
Validation loss: 2.313686312669867

Epoch: 5| Step: 3
Training loss: 0.07065785879503646
Validation loss: 2.301756079465226

Epoch: 5| Step: 4
Training loss: 0.10310984196667718
Validation loss: 2.3024387730191456

Epoch: 5| Step: 5
Training loss: 0.22409158815791536
Validation loss: 2.2804859605239445

Epoch: 5| Step: 6
Training loss: 0.11606894561841885
Validation loss: 2.29647893660013

Epoch: 5| Step: 7
Training loss: 0.06558059257098546
Validation loss: 2.3088336566806418

Epoch: 5| Step: 8
Training loss: 0.09170834858450243
Validation loss: 2.2917726594757672

Epoch: 5| Step: 9
Training loss: 0.1778086622323466
Validation loss: 2.2727954486324107

Epoch: 5| Step: 10
Training loss: 0.16481377387829327
Validation loss: 2.281167831660483

Epoch: 538| Step: 0
Training loss: 0.12939872734895513
Validation loss: 2.251021781561329

Epoch: 5| Step: 1
Training loss: 0.22244730565183612
Validation loss: 2.2357531186481063

Epoch: 5| Step: 2
Training loss: 0.10702945819106706
Validation loss: 2.2603938966975337

Epoch: 5| Step: 3
Training loss: 0.0853956817759543
Validation loss: 2.2478102148225667

Epoch: 5| Step: 4
Training loss: 0.0987152001019488
Validation loss: 2.2671371092857626

Epoch: 5| Step: 5
Training loss: 0.17344430274337827
Validation loss: 2.266393077133781

Epoch: 5| Step: 6
Training loss: 0.0744867067866302
Validation loss: 2.245487863965864

Epoch: 5| Step: 7
Training loss: 0.07580774338184795
Validation loss: 2.255754873846154

Epoch: 5| Step: 8
Training loss: 0.13824468953718663
Validation loss: 2.2360716227774997

Epoch: 5| Step: 9
Training loss: 0.08202107684314312
Validation loss: 2.2499016919188315

Epoch: 5| Step: 10
Training loss: 0.1904698060642472
Validation loss: 2.242024532428505

Epoch: 539| Step: 0
Training loss: 0.11789719735817203
Validation loss: 2.2811213833699555

Epoch: 5| Step: 1
Training loss: 0.10028774076985862
Validation loss: 2.2679485540553457

Epoch: 5| Step: 2
Training loss: 0.06013825800834647
Validation loss: 2.2945185176763654

Epoch: 5| Step: 3
Training loss: 0.12394310384514322
Validation loss: 2.2799320625307775

Epoch: 5| Step: 4
Training loss: 0.23777734912746282
Validation loss: 2.2630584805047853

Epoch: 5| Step: 5
Training loss: 0.07734552692048308
Validation loss: 2.2537691467719276

Epoch: 5| Step: 6
Training loss: 0.13459330059301536
Validation loss: 2.288671559052338

Epoch: 5| Step: 7
Training loss: 0.10368456190825878
Validation loss: 2.268277688241689

Epoch: 5| Step: 8
Training loss: 0.19638379975458603
Validation loss: 2.255651080462429

Epoch: 5| Step: 9
Training loss: 0.08574034552018524
Validation loss: 2.2662567298952627

Epoch: 5| Step: 10
Training loss: 0.0898345030296789
Validation loss: 2.2802897843120173

Epoch: 540| Step: 0
Training loss: 0.25838402774967806
Validation loss: 2.2388738353050175

Epoch: 5| Step: 1
Training loss: 0.11797956376059719
Validation loss: 2.257988867613213

Epoch: 5| Step: 2
Training loss: 0.0935929393414781
Validation loss: 2.2690671933795934

Epoch: 5| Step: 3
Training loss: 0.12811154259975224
Validation loss: 2.2633238945781295

Epoch: 5| Step: 4
Training loss: 0.12451065287414301
Validation loss: 2.2871130162687847

Epoch: 5| Step: 5
Training loss: 0.06881723002154934
Validation loss: 2.2606188488662586

Epoch: 5| Step: 6
Training loss: 0.09847707066599656
Validation loss: 2.2660198723287004

Epoch: 5| Step: 7
Training loss: 0.11149340624407444
Validation loss: 2.257748539010103

Epoch: 5| Step: 8
Training loss: 0.08785095114132667
Validation loss: 2.277996627557931

Epoch: 5| Step: 9
Training loss: 0.1936519316930037
Validation loss: 2.269274264373212

Epoch: 5| Step: 10
Training loss: 0.10844974764027963
Validation loss: 2.297534853704246

Epoch: 541| Step: 0
Training loss: 0.09613665363429998
Validation loss: 2.297830858946138

Epoch: 5| Step: 1
Training loss: 0.11959820956883278
Validation loss: 2.295985134521116

Epoch: 5| Step: 2
Training loss: 0.08647708124626714
Validation loss: 2.3088786553185794

Epoch: 5| Step: 3
Training loss: 0.10543949993161124
Validation loss: 2.315476346042004

Epoch: 5| Step: 4
Training loss: 0.14144398043641843
Validation loss: 2.313143379310926

Epoch: 5| Step: 5
Training loss: 0.1726129145200212
Validation loss: 2.3037308570863653

Epoch: 5| Step: 6
Training loss: 0.1160741489839609
Validation loss: 2.277448771184599

Epoch: 5| Step: 7
Training loss: 0.06032856106310293
Validation loss: 2.306989590349981

Epoch: 5| Step: 8
Training loss: 0.11547889064219836
Validation loss: 2.2984352306830114

Epoch: 5| Step: 9
Training loss: 0.2388898004416206
Validation loss: 2.3013331170317914

Epoch: 5| Step: 10
Training loss: 0.11628355033683381
Validation loss: 2.2632021301355043

Epoch: 542| Step: 0
Training loss: 0.0787405500248351
Validation loss: 2.3120599398391217

Epoch: 5| Step: 1
Training loss: 0.08463985786034003
Validation loss: 2.3113211343316156

Epoch: 5| Step: 2
Training loss: 0.1626598708806029
Validation loss: 2.301549162608592

Epoch: 5| Step: 3
Training loss: 0.11743061358662964
Validation loss: 2.2644989188313214

Epoch: 5| Step: 4
Training loss: 0.2376664782849279
Validation loss: 2.2867411201427412

Epoch: 5| Step: 5
Training loss: 0.07506818366647372
Validation loss: 2.2680555093746486

Epoch: 5| Step: 6
Training loss: 0.1320087077856648
Validation loss: 2.2624259176291197

Epoch: 5| Step: 7
Training loss: 0.08777184937809795
Validation loss: 2.2801289368161513

Epoch: 5| Step: 8
Training loss: 0.20838873643113023
Validation loss: 2.2815061131294914

Epoch: 5| Step: 9
Training loss: 0.11656442143336955
Validation loss: 2.2825630354840385

Epoch: 5| Step: 10
Training loss: 0.08201844535527027
Validation loss: 2.262580102136977

Epoch: 543| Step: 0
Training loss: 0.10560109523989568
Validation loss: 2.2628701031896195

Epoch: 5| Step: 1
Training loss: 0.15800620409473431
Validation loss: 2.260045028726713

Epoch: 5| Step: 2
Training loss: 0.15223542054295058
Validation loss: 2.268787010318353

Epoch: 5| Step: 3
Training loss: 0.22373433702938628
Validation loss: 2.296461737156864

Epoch: 5| Step: 4
Training loss: 0.1026610829175177
Validation loss: 2.278547871583169

Epoch: 5| Step: 5
Training loss: 0.1452148611944787
Validation loss: 2.2833563980034635

Epoch: 5| Step: 6
Training loss: 0.11802545409936377
Validation loss: 2.3306806276846643

Epoch: 5| Step: 7
Training loss: 0.08346074454708304
Validation loss: 2.3013079147518325

Epoch: 5| Step: 8
Training loss: 0.1755420912246571
Validation loss: 2.305478078356863

Epoch: 5| Step: 9
Training loss: 0.07324597348918464
Validation loss: 2.3031695974148407

Epoch: 5| Step: 10
Training loss: 0.0972612690237452
Validation loss: 2.331041281178227

Epoch: 544| Step: 0
Training loss: 0.14371112811031075
Validation loss: 2.3252816365872775

Epoch: 5| Step: 1
Training loss: 0.2331985431649152
Validation loss: 2.3273063288941027

Epoch: 5| Step: 2
Training loss: 0.14364602303878543
Validation loss: 2.3181923299505622

Epoch: 5| Step: 3
Training loss: 0.10542996452806788
Validation loss: 2.357186751966209

Epoch: 5| Step: 4
Training loss: 0.09770107670968427
Validation loss: 2.3275425494747712

Epoch: 5| Step: 5
Training loss: 0.1096735906136599
Validation loss: 2.3147564421805877

Epoch: 5| Step: 6
Training loss: 0.12943036285047357
Validation loss: 2.317974188612672

Epoch: 5| Step: 7
Training loss: 0.10267327471585783
Validation loss: 2.34368318414645

Epoch: 5| Step: 8
Training loss: 0.08495911782607052
Validation loss: 2.331359215691723

Epoch: 5| Step: 9
Training loss: 0.19628638650009517
Validation loss: 2.3425752918567357

Epoch: 5| Step: 10
Training loss: 0.07385567587503997
Validation loss: 2.351280678739981

Epoch: 545| Step: 0
Training loss: 0.17489486904135948
Validation loss: 2.329533154617688

Epoch: 5| Step: 1
Training loss: 0.12684126107028834
Validation loss: 2.324417720394449

Epoch: 5| Step: 2
Training loss: 0.1382820466120991
Validation loss: 2.3334730252261373

Epoch: 5| Step: 3
Training loss: 0.06813477676782986
Validation loss: 2.2958740392754935

Epoch: 5| Step: 4
Training loss: 0.1514574212641935
Validation loss: 2.3085893575034073

Epoch: 5| Step: 5
Training loss: 0.12805349605169639
Validation loss: 2.3051466812374026

Epoch: 5| Step: 6
Training loss: 0.08471532375143244
Validation loss: 2.302519742482834

Epoch: 5| Step: 7
Training loss: 0.08890755752983064
Validation loss: 2.300013145375327

Epoch: 5| Step: 8
Training loss: 0.17072662436186936
Validation loss: 2.328897923112459

Epoch: 5| Step: 9
Training loss: 0.18844561742819047
Validation loss: 2.3101579878747738

Epoch: 5| Step: 10
Training loss: 0.08744431931545023
Validation loss: 2.342419729868233

Epoch: 546| Step: 0
Training loss: 0.06672194416297514
Validation loss: 2.2742523259982006

Epoch: 5| Step: 1
Training loss: 0.10058004862018607
Validation loss: 2.3130515554126045

Epoch: 5| Step: 2
Training loss: 0.133225989406997
Validation loss: 2.3240924528239653

Epoch: 5| Step: 3
Training loss: 0.08277781824164332
Validation loss: 2.3246391954998105

Epoch: 5| Step: 4
Training loss: 0.21950810062628354
Validation loss: 2.3163482720183506

Epoch: 5| Step: 5
Training loss: 0.12177023817193763
Validation loss: 2.2893513796073663

Epoch: 5| Step: 6
Training loss: 0.10758005979871657
Validation loss: 2.2957957979478647

Epoch: 5| Step: 7
Training loss: 0.12973505952018866
Validation loss: 2.272737178184275

Epoch: 5| Step: 8
Training loss: 0.21710592871830875
Validation loss: 2.2856175727858945

Epoch: 5| Step: 9
Training loss: 0.08708564826473787
Validation loss: 2.26743573964728

Epoch: 5| Step: 10
Training loss: 0.08855052218844606
Validation loss: 2.284894353167745

Epoch: 547| Step: 0
Training loss: 0.12218796972638157
Validation loss: 2.2775949023650814

Epoch: 5| Step: 1
Training loss: 0.06060929887454097
Validation loss: 2.280400640487271

Epoch: 5| Step: 2
Training loss: 0.10871699495535485
Validation loss: 2.319337502652273

Epoch: 5| Step: 3
Training loss: 0.1933037070856276
Validation loss: 2.317233511631161

Epoch: 5| Step: 4
Training loss: 0.089368516980305
Validation loss: 2.3087070314378657

Epoch: 5| Step: 5
Training loss: 0.15021544942806886
Validation loss: 2.3166835682340134

Epoch: 5| Step: 6
Training loss: 0.11194737023618684
Validation loss: 2.3318938511666327

Epoch: 5| Step: 7
Training loss: 0.1337148920221652
Validation loss: 2.2966540890781815

Epoch: 5| Step: 8
Training loss: 0.15151140049649606
Validation loss: 2.300685430486581

Epoch: 5| Step: 9
Training loss: 0.06587945378062143
Validation loss: 2.318990619852655

Epoch: 5| Step: 10
Training loss: 0.18253278566813957
Validation loss: 2.283994937337048

Epoch: 548| Step: 0
Training loss: 0.12525179209397896
Validation loss: 2.309384308803915

Epoch: 5| Step: 1
Training loss: 0.16793013838614082
Validation loss: 2.333769464898097

Epoch: 5| Step: 2
Training loss: 0.1505023863047189
Validation loss: 2.2924504208632537

Epoch: 5| Step: 3
Training loss: 0.06823627764589178
Validation loss: 2.2790053547321385

Epoch: 5| Step: 4
Training loss: 0.15268086766904013
Validation loss: 2.2856893022359546

Epoch: 5| Step: 5
Training loss: 0.13089331855657285
Validation loss: 2.29497059089866

Epoch: 5| Step: 6
Training loss: 0.06879932655170169
Validation loss: 2.299625835261792

Epoch: 5| Step: 7
Training loss: 0.1728986578970062
Validation loss: 2.28873013452836

Epoch: 5| Step: 8
Training loss: 0.09302537740214618
Validation loss: 2.292955816427089

Epoch: 5| Step: 9
Training loss: 0.09943214712924545
Validation loss: 2.2887194273253626

Epoch: 5| Step: 10
Training loss: 0.1366970726266574
Validation loss: 2.2693913752921646

Epoch: 549| Step: 0
Training loss: 0.21118264611506476
Validation loss: 2.2896080656295634

Epoch: 5| Step: 1
Training loss: 0.09083028964132978
Validation loss: 2.2841351271111208

Epoch: 5| Step: 2
Training loss: 0.17175458895079043
Validation loss: 2.278774445497657

Epoch: 5| Step: 3
Training loss: 0.12278221823557407
Validation loss: 2.305955931354036

Epoch: 5| Step: 4
Training loss: 0.06912871072240022
Validation loss: 2.3291920145672558

Epoch: 5| Step: 5
Training loss: 0.092087953776669
Validation loss: 2.2907708648039304

Epoch: 5| Step: 6
Training loss: 0.10446220930507977
Validation loss: 2.3177323234471485

Epoch: 5| Step: 7
Training loss: 0.08606287631996284
Validation loss: 2.3467377376258467

Epoch: 5| Step: 8
Training loss: 0.14314021397192148
Validation loss: 2.2875989029943398

Epoch: 5| Step: 9
Training loss: 0.08814977481087609
Validation loss: 2.308112014722385

Epoch: 5| Step: 10
Training loss: 0.16813482901051363
Validation loss: 2.280513961595578

Epoch: 550| Step: 0
Training loss: 0.13174180803039007
Validation loss: 2.2465144451374397

Epoch: 5| Step: 1
Training loss: 0.19051156851229975
Validation loss: 2.257496200736572

Epoch: 5| Step: 2
Training loss: 0.15251061275559807
Validation loss: 2.23860378912605

Epoch: 5| Step: 3
Training loss: 0.17100036851037345
Validation loss: 2.244916986390089

Epoch: 5| Step: 4
Training loss: 0.08478847351737827
Validation loss: 2.226503059876163

Epoch: 5| Step: 5
Training loss: 0.10299522116081622
Validation loss: 2.2510612763873707

Epoch: 5| Step: 6
Training loss: 0.19388677937320403
Validation loss: 2.265601405048103

Epoch: 5| Step: 7
Training loss: 0.10362064234753575
Validation loss: 2.291048957453472

Epoch: 5| Step: 8
Training loss: 0.13262464055732606
Validation loss: 2.2976654960444978

Epoch: 5| Step: 9
Training loss: 0.1094168004132945
Validation loss: 2.2855744054929232

Epoch: 5| Step: 10
Training loss: 0.06842519112182402
Validation loss: 2.310209293232244

Epoch: 551| Step: 0
Training loss: 0.0921963461171552
Validation loss: 2.314212815499762

Epoch: 5| Step: 1
Training loss: 0.10530015928312085
Validation loss: 2.3245614492428985

Epoch: 5| Step: 2
Training loss: 0.16811832709878805
Validation loss: 2.3207490955735395

Epoch: 5| Step: 3
Training loss: 0.16990054753072448
Validation loss: 2.314798061879925

Epoch: 5| Step: 4
Training loss: 0.1465898388454908
Validation loss: 2.3108655579613084

Epoch: 5| Step: 5
Training loss: 0.10478990691580024
Validation loss: 2.3041185703304294

Epoch: 5| Step: 6
Training loss: 0.1612585790702889
Validation loss: 2.31286137026367

Epoch: 5| Step: 7
Training loss: 0.0862538680733043
Validation loss: 2.259229851368687

Epoch: 5| Step: 8
Training loss: 0.1644243722639184
Validation loss: 2.264961393579602

Epoch: 5| Step: 9
Training loss: 0.19065788485681612
Validation loss: 2.2560906506742286

Epoch: 5| Step: 10
Training loss: 0.1243532780867277
Validation loss: 2.26049773655568

Epoch: 552| Step: 0
Training loss: 0.15546552304891753
Validation loss: 2.2607176213504574

Epoch: 5| Step: 1
Training loss: 0.09093093800055639
Validation loss: 2.2667095333940375

Epoch: 5| Step: 2
Training loss: 0.0871159213219283
Validation loss: 2.2771623889226746

Epoch: 5| Step: 3
Training loss: 0.26486286049370517
Validation loss: 2.2963262430807387

Epoch: 5| Step: 4
Training loss: 0.07494521661018816
Validation loss: 2.320406155619104

Epoch: 5| Step: 5
Training loss: 0.1054496836206032
Validation loss: 2.293358245229537

Epoch: 5| Step: 6
Training loss: 0.06689843980828607
Validation loss: 2.31192353942137

Epoch: 5| Step: 7
Training loss: 0.09292458218360518
Validation loss: 2.3375802023982897

Epoch: 5| Step: 8
Training loss: 0.11151792008201737
Validation loss: 2.3240710001863443

Epoch: 5| Step: 9
Training loss: 0.13027712117581852
Validation loss: 2.347461993726359

Epoch: 5| Step: 10
Training loss: 0.11693578150015035
Validation loss: 2.3435488094266246

Epoch: 553| Step: 0
Training loss: 0.1722238371026261
Validation loss: 2.3009105091516555

Epoch: 5| Step: 1
Training loss: 0.06993824977511204
Validation loss: 2.3485297715765756

Epoch: 5| Step: 2
Training loss: 0.13242016372025037
Validation loss: 2.3105704614483247

Epoch: 5| Step: 3
Training loss: 0.10846033992216654
Validation loss: 2.2905581471557475

Epoch: 5| Step: 4
Training loss: 0.12232629258043781
Validation loss: 2.301130488392921

Epoch: 5| Step: 5
Training loss: 0.06196848045248177
Validation loss: 2.281208293610531

Epoch: 5| Step: 6
Training loss: 0.22991266081140746
Validation loss: 2.278578823434457

Epoch: 5| Step: 7
Training loss: 0.15352758137780373
Validation loss: 2.2625414103320076

Epoch: 5| Step: 8
Training loss: 0.09108186816070728
Validation loss: 2.271667288574878

Epoch: 5| Step: 9
Training loss: 0.1250091340780863
Validation loss: 2.302983467483028

Epoch: 5| Step: 10
Training loss: 0.073106344132682
Validation loss: 2.332030100114566

Epoch: 554| Step: 0
Training loss: 0.1380071558263225
Validation loss: 2.314598779580747

Epoch: 5| Step: 1
Training loss: 0.1330013755327454
Validation loss: 2.3117515568928457

Epoch: 5| Step: 2
Training loss: 0.17392032299869195
Validation loss: 2.3275557479525575

Epoch: 5| Step: 3
Training loss: 0.1844641364953861
Validation loss: 2.3312602707712675

Epoch: 5| Step: 4
Training loss: 0.1635123804976166
Validation loss: 2.317898010552335

Epoch: 5| Step: 5
Training loss: 0.12080491135243508
Validation loss: 2.3283106555128374

Epoch: 5| Step: 6
Training loss: 0.0910680734359641
Validation loss: 2.311262490830478

Epoch: 5| Step: 7
Training loss: 0.0815375548981127
Validation loss: 2.327277693966473

Epoch: 5| Step: 8
Training loss: 0.10640788076358264
Validation loss: 2.296904340418079

Epoch: 5| Step: 9
Training loss: 0.11584579579831648
Validation loss: 2.2927237566355148

Epoch: 5| Step: 10
Training loss: 0.0908820598669179
Validation loss: 2.2875046382404034

Epoch: 555| Step: 0
Training loss: 0.18982937409086298
Validation loss: 2.302732975021299

Epoch: 5| Step: 1
Training loss: 0.12377012470880229
Validation loss: 2.2770056861206465

Epoch: 5| Step: 2
Training loss: 0.10741941275809155
Validation loss: 2.3045384468168253

Epoch: 5| Step: 3
Training loss: 0.20198005076197353
Validation loss: 2.300326870558467

Epoch: 5| Step: 4
Training loss: 0.16126689534056116
Validation loss: 2.3039788398482757

Epoch: 5| Step: 5
Training loss: 0.14168644695706778
Validation loss: 2.282964236529768

Epoch: 5| Step: 6
Training loss: 0.14462118314925693
Validation loss: 2.2887898756348157

Epoch: 5| Step: 7
Training loss: 0.07432607996334357
Validation loss: 2.2706506374715056

Epoch: 5| Step: 8
Training loss: 0.07285300488616508
Validation loss: 2.2664117761710076

Epoch: 5| Step: 9
Training loss: 0.12212013753661774
Validation loss: 2.294004917232592

Epoch: 5| Step: 10
Training loss: 0.1669606798129043
Validation loss: 2.299665935103282

Epoch: 556| Step: 0
Training loss: 0.208662703543559
Validation loss: 2.292391429932738

Epoch: 5| Step: 1
Training loss: 0.15449518425081005
Validation loss: 2.3407861949239286

Epoch: 5| Step: 2
Training loss: 0.13814623701805273
Validation loss: 2.33321513442052

Epoch: 5| Step: 3
Training loss: 0.16954184929723115
Validation loss: 2.3281712433508015

Epoch: 5| Step: 4
Training loss: 0.08097578137578133
Validation loss: 2.3071708935551496

Epoch: 5| Step: 5
Training loss: 0.11872388307831623
Validation loss: 2.2932216052551277

Epoch: 5| Step: 6
Training loss: 0.16527450290698079
Validation loss: 2.280104098319231

Epoch: 5| Step: 7
Training loss: 0.12393317354608187
Validation loss: 2.266605266687079

Epoch: 5| Step: 8
Training loss: 0.12099563561599859
Validation loss: 2.2464277064664184

Epoch: 5| Step: 9
Training loss: 0.21492217973183453
Validation loss: 2.2445373375854927

Epoch: 5| Step: 10
Training loss: 0.11408579748461571
Validation loss: 2.216620708818466

Epoch: 557| Step: 0
Training loss: 0.2526527272900672
Validation loss: 2.245980228018139

Epoch: 5| Step: 1
Training loss: 0.1317910082517011
Validation loss: 2.2248326517357837

Epoch: 5| Step: 2
Training loss: 0.1347411520477957
Validation loss: 2.25938935854319

Epoch: 5| Step: 3
Training loss: 0.13747866475866855
Validation loss: 2.2802068292129043

Epoch: 5| Step: 4
Training loss: 0.17582695154971242
Validation loss: 2.2676353567843086

Epoch: 5| Step: 5
Training loss: 0.1160412037712923
Validation loss: 2.318831253452381

Epoch: 5| Step: 6
Training loss: 0.15119280460776907
Validation loss: 2.3250881902777722

Epoch: 5| Step: 7
Training loss: 0.21981124941351077
Validation loss: 2.319326643833955

Epoch: 5| Step: 8
Training loss: 0.19846270656439194
Validation loss: 2.297769192333019

Epoch: 5| Step: 9
Training loss: 0.16525307159519628
Validation loss: 2.2656462948781035

Epoch: 5| Step: 10
Training loss: 0.15764035098433654
Validation loss: 2.23624691756419

Epoch: 558| Step: 0
Training loss: 0.15689036160179012
Validation loss: 2.226364005422856

Epoch: 5| Step: 1
Training loss: 0.17235749967134278
Validation loss: 2.2096198678671346

Epoch: 5| Step: 2
Training loss: 0.1946988766195024
Validation loss: 2.213374397766925

Epoch: 5| Step: 3
Training loss: 0.1220257715980997
Validation loss: 2.2476419274592603

Epoch: 5| Step: 4
Training loss: 0.2200405251366173
Validation loss: 2.2311056094329276

Epoch: 5| Step: 5
Training loss: 0.21355867996516906
Validation loss: 2.242143449110855

Epoch: 5| Step: 6
Training loss: 0.16028811097293774
Validation loss: 2.267116845559626

Epoch: 5| Step: 7
Training loss: 0.08837794203258602
Validation loss: 2.2921606305231856

Epoch: 5| Step: 8
Training loss: 0.13567604539246
Validation loss: 2.310441690578305

Epoch: 5| Step: 9
Training loss: 0.15152001203228468
Validation loss: 2.3377821073128167

Epoch: 5| Step: 10
Training loss: 0.21721265633434697
Validation loss: 2.335133048194909

Epoch: 559| Step: 0
Training loss: 0.17367634415292388
Validation loss: 2.3109593557071864

Epoch: 5| Step: 1
Training loss: 0.2267214529900348
Validation loss: 2.2793657570630574

Epoch: 5| Step: 2
Training loss: 0.19905367725408954
Validation loss: 2.226835903673568

Epoch: 5| Step: 3
Training loss: 0.19822198548759284
Validation loss: 2.1736041014783694

Epoch: 5| Step: 4
Training loss: 0.13400259172144824
Validation loss: 2.1776305700866727

Epoch: 5| Step: 5
Training loss: 0.16961054946935572
Validation loss: 2.1794904129525134

Epoch: 5| Step: 6
Training loss: 0.20748457670342033
Validation loss: 2.1876457259571915

Epoch: 5| Step: 7
Training loss: 0.13841048979278298
Validation loss: 2.1702494870678595

Epoch: 5| Step: 8
Training loss: 0.14826688246666617
Validation loss: 2.136604718921319

Epoch: 5| Step: 9
Training loss: 0.22262227485173278
Validation loss: 2.1577811075810667

Epoch: 5| Step: 10
Training loss: 0.20663867473583364
Validation loss: 2.1753093979380833

Epoch: 560| Step: 0
Training loss: 0.1895124991278104
Validation loss: 2.2245006145577797

Epoch: 5| Step: 1
Training loss: 0.15230735319573094
Validation loss: 2.2238507345768594

Epoch: 5| Step: 2
Training loss: 0.13667596420009384
Validation loss: 2.2674533774738648

Epoch: 5| Step: 3
Training loss: 0.125477608549711
Validation loss: 2.3211717873076707

Epoch: 5| Step: 4
Training loss: 0.1274287118837561
Validation loss: 2.3135449953737637

Epoch: 5| Step: 5
Training loss: 0.26104157650776794
Validation loss: 2.339891684025068

Epoch: 5| Step: 6
Training loss: 0.19119253683735032
Validation loss: 2.3443423927405393

Epoch: 5| Step: 7
Training loss: 0.19048231326935233
Validation loss: 2.3464058226886184

Epoch: 5| Step: 8
Training loss: 0.16122609530547263
Validation loss: 2.3368089124469185

Epoch: 5| Step: 9
Training loss: 0.1994342199705568
Validation loss: 2.3012346362473997

Epoch: 5| Step: 10
Training loss: 0.2062635673771129
Validation loss: 2.288915352587557

Epoch: 561| Step: 0
Training loss: 0.1708369716735623
Validation loss: 2.2730652775382283

Epoch: 5| Step: 1
Training loss: 0.21126426888417085
Validation loss: 2.2605764352328084

Epoch: 5| Step: 2
Training loss: 0.22887922361790478
Validation loss: 2.2276607410655873

Epoch: 5| Step: 3
Training loss: 0.12195417983498837
Validation loss: 2.2646022648068183

Epoch: 5| Step: 4
Training loss: 0.09987389279648205
Validation loss: 2.239123529927854

Epoch: 5| Step: 5
Training loss: 0.11826214384700312
Validation loss: 2.236976619427106

Epoch: 5| Step: 6
Training loss: 0.16367128822749527
Validation loss: 2.231862033084251

Epoch: 5| Step: 7
Training loss: 0.1361677442417654
Validation loss: 2.26968628663025

Epoch: 5| Step: 8
Training loss: 0.09527153870339324
Validation loss: 2.2801930418582854

Epoch: 5| Step: 9
Training loss: 0.09821847246430013
Validation loss: 2.259480026337319

Epoch: 5| Step: 10
Training loss: 0.15608970048785625
Validation loss: 2.296153622924125

Epoch: 562| Step: 0
Training loss: 0.14114684395469348
Validation loss: 2.2720378997370823

Epoch: 5| Step: 1
Training loss: 0.1639762947123589
Validation loss: 2.2845492170668646

Epoch: 5| Step: 2
Training loss: 0.17927801078674788
Validation loss: 2.260130616400236

Epoch: 5| Step: 3
Training loss: 0.10860630672913478
Validation loss: 2.227490594189698

Epoch: 5| Step: 4
Training loss: 0.11606157545631501
Validation loss: 2.219865258970694

Epoch: 5| Step: 5
Training loss: 0.1837537555245923
Validation loss: 2.2015780811041856

Epoch: 5| Step: 6
Training loss: 0.1065964544434636
Validation loss: 2.2037971676728323

Epoch: 5| Step: 7
Training loss: 0.15245106780711032
Validation loss: 2.194594706327785

Epoch: 5| Step: 8
Training loss: 0.1050313471439279
Validation loss: 2.211365036381261

Epoch: 5| Step: 9
Training loss: 0.18060125341701252
Validation loss: 2.2295915104683286

Epoch: 5| Step: 10
Training loss: 0.18044186924479483
Validation loss: 2.239586475901439

Epoch: 563| Step: 0
Training loss: 0.12428584086404072
Validation loss: 2.2701187145825075

Epoch: 5| Step: 1
Training loss: 0.14713829946366377
Validation loss: 2.256509150852106

Epoch: 5| Step: 2
Training loss: 0.1756418470111624
Validation loss: 2.2971473137865743

Epoch: 5| Step: 3
Training loss: 0.08479161490336079
Validation loss: 2.3002386988490646

Epoch: 5| Step: 4
Training loss: 0.18336333364432025
Validation loss: 2.3063202055460876

Epoch: 5| Step: 5
Training loss: 0.12148718217384652
Validation loss: 2.30088910443855

Epoch: 5| Step: 6
Training loss: 0.1575170522685133
Validation loss: 2.307705127286314

Epoch: 5| Step: 7
Training loss: 0.15611753212887344
Validation loss: 2.2721885707138387

Epoch: 5| Step: 8
Training loss: 0.13920254647291763
Validation loss: 2.313193431498268

Epoch: 5| Step: 9
Training loss: 0.19995430185851484
Validation loss: 2.2547890184920134

Epoch: 5| Step: 10
Training loss: 0.14112094343562143
Validation loss: 2.26563321495052

Epoch: 564| Step: 0
Training loss: 0.12733708785480827
Validation loss: 2.240901518071475

Epoch: 5| Step: 1
Training loss: 0.07942787903506998
Validation loss: 2.2576317013461598

Epoch: 5| Step: 2
Training loss: 0.1247414955783666
Validation loss: 2.291804569230581

Epoch: 5| Step: 3
Training loss: 0.17599723051002714
Validation loss: 2.285527131461773

Epoch: 5| Step: 4
Training loss: 0.17860176837706201
Validation loss: 2.312355013123854

Epoch: 5| Step: 5
Training loss: 0.13073584433772023
Validation loss: 2.3364632865624997

Epoch: 5| Step: 6
Training loss: 0.12103945914833643
Validation loss: 2.332489058329286

Epoch: 5| Step: 7
Training loss: 0.21081663130266987
Validation loss: 2.3385737377852314

Epoch: 5| Step: 8
Training loss: 0.17394533920202215
Validation loss: 2.344226927001769

Epoch: 5| Step: 9
Training loss: 0.16484607609016158
Validation loss: 2.336457736760023

Epoch: 5| Step: 10
Training loss: 0.07427473215612101
Validation loss: 2.298701988573147

Epoch: 565| Step: 0
Training loss: 0.13871532081976795
Validation loss: 2.277074890808583

Epoch: 5| Step: 1
Training loss: 0.111605457735964
Validation loss: 2.275954923335238

Epoch: 5| Step: 2
Training loss: 0.16474266071281465
Validation loss: 2.286744818612823

Epoch: 5| Step: 3
Training loss: 0.1608177283345586
Validation loss: 2.3078970492119986

Epoch: 5| Step: 4
Training loss: 0.09956741384160797
Validation loss: 2.2954520317931424

Epoch: 5| Step: 5
Training loss: 0.18467610470880452
Validation loss: 2.3209433191325073

Epoch: 5| Step: 6
Training loss: 0.11614551626113696
Validation loss: 2.3164965525806447

Epoch: 5| Step: 7
Training loss: 0.11460834513762559
Validation loss: 2.3200477981381855

Epoch: 5| Step: 8
Training loss: 0.19164727080897678
Validation loss: 2.326857481734174

Epoch: 5| Step: 9
Training loss: 0.16492189954886713
Validation loss: 2.3259767601866717

Epoch: 5| Step: 10
Training loss: 0.13125710751952857
Validation loss: 2.3187307036965437

Epoch: 566| Step: 0
Training loss: 0.15961556930957765
Validation loss: 2.3066870428826434

Epoch: 5| Step: 1
Training loss: 0.09502281975225844
Validation loss: 2.3071726647467052

Epoch: 5| Step: 2
Training loss: 0.12146604513140674
Validation loss: 2.2983419848197473

Epoch: 5| Step: 3
Training loss: 0.13221408159637754
Validation loss: 2.2995355981674246

Epoch: 5| Step: 4
Training loss: 0.1591769376177891
Validation loss: 2.322305461417293

Epoch: 5| Step: 5
Training loss: 0.09705316768267848
Validation loss: 2.3214733597591755

Epoch: 5| Step: 6
Training loss: 0.12217756518782996
Validation loss: 2.3334632583195996

Epoch: 5| Step: 7
Training loss: 0.12160413227129283
Validation loss: 2.2987718053116772

Epoch: 5| Step: 8
Training loss: 0.18662538787995672
Validation loss: 2.320697995333849

Epoch: 5| Step: 9
Training loss: 0.19777381702547164
Validation loss: 2.3281426603543918

Epoch: 5| Step: 10
Training loss: 0.13217047878230975
Validation loss: 2.3259093742461547

Epoch: 567| Step: 0
Training loss: 0.14534738516706028
Validation loss: 2.3092006897921604

Epoch: 5| Step: 1
Training loss: 0.13919942870538388
Validation loss: 2.3492432691988054

Epoch: 5| Step: 2
Training loss: 0.22372709394130014
Validation loss: 2.317017430666505

Epoch: 5| Step: 3
Training loss: 0.10046103972932553
Validation loss: 2.319385575303581

Epoch: 5| Step: 4
Training loss: 0.14807946543435532
Validation loss: 2.3310743910237988

Epoch: 5| Step: 5
Training loss: 0.10321544813325594
Validation loss: 2.295469781579471

Epoch: 5| Step: 6
Training loss: 0.12022705016154082
Validation loss: 2.310294800184298

Epoch: 5| Step: 7
Training loss: 0.08812894828385863
Validation loss: 2.3385785206802385

Epoch: 5| Step: 8
Training loss: 0.09644877186160637
Validation loss: 2.2969391438346043

Epoch: 5| Step: 9
Training loss: 0.16653216729043027
Validation loss: 2.281399672370557

Epoch: 5| Step: 10
Training loss: 0.11831672910501234
Validation loss: 2.2577192092301965

Epoch: 568| Step: 0
Training loss: 0.1003686864237231
Validation loss: 2.2650440165626127

Epoch: 5| Step: 1
Training loss: 0.1624075778064982
Validation loss: 2.281329149240521

Epoch: 5| Step: 2
Training loss: 0.11908399690091578
Validation loss: 2.2720452632989656

Epoch: 5| Step: 3
Training loss: 0.14553625993622168
Validation loss: 2.300463845182247

Epoch: 5| Step: 4
Training loss: 0.18384555025595561
Validation loss: 2.279467704162271

Epoch: 5| Step: 5
Training loss: 0.12116415914789563
Validation loss: 2.2894748539065506

Epoch: 5| Step: 6
Training loss: 0.18375782027114196
Validation loss: 2.3145961191333297

Epoch: 5| Step: 7
Training loss: 0.09474501479239693
Validation loss: 2.312157358040614

Epoch: 5| Step: 8
Training loss: 0.1695659626084497
Validation loss: 2.327071328659646

Epoch: 5| Step: 9
Training loss: 0.08697901666746322
Validation loss: 2.317390826826493

Epoch: 5| Step: 10
Training loss: 0.13718637467055309
Validation loss: 2.3246286084778798

Epoch: 569| Step: 0
Training loss: 0.09522352423590956
Validation loss: 2.3144856004265506

Epoch: 5| Step: 1
Training loss: 0.11720761285480864
Validation loss: 2.309107085952938

Epoch: 5| Step: 2
Training loss: 0.11421236536339123
Validation loss: 2.289084149974028

Epoch: 5| Step: 3
Training loss: 0.12741709802538745
Validation loss: 2.3037229782984934

Epoch: 5| Step: 4
Training loss: 0.13133815461574064
Validation loss: 2.282467248059834

Epoch: 5| Step: 5
Training loss: 0.14163467414714442
Validation loss: 2.2565080749565083

Epoch: 5| Step: 6
Training loss: 0.15468408190678792
Validation loss: 2.252053983950419

Epoch: 5| Step: 7
Training loss: 0.11703587498076044
Validation loss: 2.2734443493326797

Epoch: 5| Step: 8
Training loss: 0.18899408749952326
Validation loss: 2.3197873318347835

Epoch: 5| Step: 9
Training loss: 0.16988799426047807
Validation loss: 2.293393723977399

Epoch: 5| Step: 10
Training loss: 0.1779150306703124
Validation loss: 2.30355166030193

Epoch: 570| Step: 0
Training loss: 0.09002947270096587
Validation loss: 2.32991429269297

Epoch: 5| Step: 1
Training loss: 0.14550531628406901
Validation loss: 2.334094729401684

Epoch: 5| Step: 2
Training loss: 0.20299948886104652
Validation loss: 2.3523176988776253

Epoch: 5| Step: 3
Training loss: 0.16189953424779638
Validation loss: 2.3324897507627

Epoch: 5| Step: 4
Training loss: 0.14364093343618012
Validation loss: 2.3082597853729134

Epoch: 5| Step: 5
Training loss: 0.11471835673687479
Validation loss: 2.289346541459248

Epoch: 5| Step: 6
Training loss: 0.1043307358356659
Validation loss: 2.2965012492447

Epoch: 5| Step: 7
Training loss: 0.10861053422850601
Validation loss: 2.2688811086866885

Epoch: 5| Step: 8
Training loss: 0.10740600381994461
Validation loss: 2.2732342659250038

Epoch: 5| Step: 9
Training loss: 0.1655049998188667
Validation loss: 2.2429147136807797

Epoch: 5| Step: 10
Training loss: 0.12420441721753753
Validation loss: 2.2569681939284054

Epoch: 571| Step: 0
Training loss: 0.18372993288299608
Validation loss: 2.290217113615746

Epoch: 5| Step: 1
Training loss: 0.15688166492103797
Validation loss: 2.2579713125374705

Epoch: 5| Step: 2
Training loss: 0.10178693402247882
Validation loss: 2.2706738446364945

Epoch: 5| Step: 3
Training loss: 0.12980641003733423
Validation loss: 2.296887605682889

Epoch: 5| Step: 4
Training loss: 0.11388789719815996
Validation loss: 2.2787608705420794

Epoch: 5| Step: 5
Training loss: 0.11319359726099604
Validation loss: 2.272341612189282

Epoch: 5| Step: 6
Training loss: 0.0976117127903242
Validation loss: 2.2695515057240523

Epoch: 5| Step: 7
Training loss: 0.1394701132591268
Validation loss: 2.298185340141201

Epoch: 5| Step: 8
Training loss: 0.174803637922322
Validation loss: 2.2634673614361804

Epoch: 5| Step: 9
Training loss: 0.13869398236350017
Validation loss: 2.296277102670511

Epoch: 5| Step: 10
Training loss: 0.11188281473511796
Validation loss: 2.3005193991038135

Epoch: 572| Step: 0
Training loss: 0.09324878582982112
Validation loss: 2.293668104159753

Epoch: 5| Step: 1
Training loss: 0.17336538422163134
Validation loss: 2.281316875624348

Epoch: 5| Step: 2
Training loss: 0.1234537995115663
Validation loss: 2.2735663799176478

Epoch: 5| Step: 3
Training loss: 0.18082269457280004
Validation loss: 2.2727786142109996

Epoch: 5| Step: 4
Training loss: 0.15318877658249822
Validation loss: 2.264012010290867

Epoch: 5| Step: 5
Training loss: 0.08840768040079346
Validation loss: 2.24261837604129

Epoch: 5| Step: 6
Training loss: 0.07834985085642361
Validation loss: 2.275920246075295

Epoch: 5| Step: 7
Training loss: 0.08958166186950564
Validation loss: 2.275650969311946

Epoch: 5| Step: 8
Training loss: 0.12500899252731829
Validation loss: 2.2399266687850488

Epoch: 5| Step: 9
Training loss: 0.12992410792062314
Validation loss: 2.2684155052528294

Epoch: 5| Step: 10
Training loss: 0.1299664937681335
Validation loss: 2.2958906613617667

Epoch: 573| Step: 0
Training loss: 0.09180075556080791
Validation loss: 2.2969730644506985

Epoch: 5| Step: 1
Training loss: 0.14700623062246865
Validation loss: 2.338821583667057

Epoch: 5| Step: 2
Training loss: 0.24430467815764506
Validation loss: 2.319259164158039

Epoch: 5| Step: 3
Training loss: 0.11029475783999089
Validation loss: 2.3221253321370754

Epoch: 5| Step: 4
Training loss: 0.09246233930600879
Validation loss: 2.358172733451091

Epoch: 5| Step: 5
Training loss: 0.11525858608584318
Validation loss: 2.315563111058525

Epoch: 5| Step: 6
Training loss: 0.157838513099967
Validation loss: 2.333108790825176

Epoch: 5| Step: 7
Training loss: 0.0843189224237089
Validation loss: 2.331873649671777

Epoch: 5| Step: 8
Training loss: 0.12502227525123752
Validation loss: 2.3368311532210786

Epoch: 5| Step: 9
Training loss: 0.11969730212558147
Validation loss: 2.328347199297468

Epoch: 5| Step: 10
Training loss: 0.10646011966993899
Validation loss: 2.328148901129098

Epoch: 574| Step: 0
Training loss: 0.10858532114730213
Validation loss: 2.3284995077954616

Epoch: 5| Step: 1
Training loss: 0.09732907803090754
Validation loss: 2.3035775986982427

Epoch: 5| Step: 2
Training loss: 0.07922056747642726
Validation loss: 2.322308381285213

Epoch: 5| Step: 3
Training loss: 0.0747434832583329
Validation loss: 2.3126359404628345

Epoch: 5| Step: 4
Training loss: 0.07302929455033114
Validation loss: 2.2987332434033663

Epoch: 5| Step: 5
Training loss: 0.09471767423164222
Validation loss: 2.314955009353361

Epoch: 5| Step: 6
Training loss: 0.19386024338143484
Validation loss: 2.3011896769659055

Epoch: 5| Step: 7
Training loss: 0.17728846020008518
Validation loss: 2.3081421241791333

Epoch: 5| Step: 8
Training loss: 0.20811241277944567
Validation loss: 2.292867824715248

Epoch: 5| Step: 9
Training loss: 0.10909297464745915
Validation loss: 2.297662273172769

Epoch: 5| Step: 10
Training loss: 0.12219223037694975
Validation loss: 2.270334076750471

Epoch: 575| Step: 0
Training loss: 0.13702272954134012
Validation loss: 2.3024681165811014

Epoch: 5| Step: 1
Training loss: 0.17261415546669534
Validation loss: 2.3068067503635703

Epoch: 5| Step: 2
Training loss: 0.09697747367425294
Validation loss: 2.3006360522338736

Epoch: 5| Step: 3
Training loss: 0.1186354432805048
Validation loss: 2.336086079564639

Epoch: 5| Step: 4
Training loss: 0.14675121798204835
Validation loss: 2.330847519324838

Epoch: 5| Step: 5
Training loss: 0.09434130082768935
Validation loss: 2.349854903758885

Epoch: 5| Step: 6
Training loss: 0.17809094304210318
Validation loss: 2.3201696128763953

Epoch: 5| Step: 7
Training loss: 0.08959450044540536
Validation loss: 2.3263538211225687

Epoch: 5| Step: 8
Training loss: 0.15025693351128716
Validation loss: 2.3052897483142027

Epoch: 5| Step: 9
Training loss: 0.1419460775340158
Validation loss: 2.3199826434178905

Epoch: 5| Step: 10
Training loss: 0.17566330979762582
Validation loss: 2.2912268685511545

Epoch: 576| Step: 0
Training loss: 0.144362409019937
Validation loss: 2.299083442424172

Epoch: 5| Step: 1
Training loss: 0.0734382548191968
Validation loss: 2.2590310178481836

Epoch: 5| Step: 2
Training loss: 0.17214112919164612
Validation loss: 2.269110558334461

Epoch: 5| Step: 3
Training loss: 0.1340089508517125
Validation loss: 2.294730978806354

Epoch: 5| Step: 4
Training loss: 0.13052202981363406
Validation loss: 2.278271417236548

Epoch: 5| Step: 5
Training loss: 0.09886206055561715
Validation loss: 2.258682462614374

Epoch: 5| Step: 6
Training loss: 0.09942974461523642
Validation loss: 2.2501205835879183

Epoch: 5| Step: 7
Training loss: 0.1349158348317428
Validation loss: 2.2785769962630558

Epoch: 5| Step: 8
Training loss: 0.06356657322090614
Validation loss: 2.2671765026044803

Epoch: 5| Step: 9
Training loss: 0.15989013404401758
Validation loss: 2.291703154719961

Epoch: 5| Step: 10
Training loss: 0.10923288683613547
Validation loss: 2.3081322695216335

Epoch: 577| Step: 0
Training loss: 0.10759591828786455
Validation loss: 2.307841756752162

Epoch: 5| Step: 1
Training loss: 0.09362714386651264
Validation loss: 2.297750925880733

Epoch: 5| Step: 2
Training loss: 0.17254994904518203
Validation loss: 2.293464239412365

Epoch: 5| Step: 3
Training loss: 0.08672956107168497
Validation loss: 2.305201318249175

Epoch: 5| Step: 4
Training loss: 0.12252939111899487
Validation loss: 2.318618395721695

Epoch: 5| Step: 5
Training loss: 0.07230996047751939
Validation loss: 2.269361565628598

Epoch: 5| Step: 6
Training loss: 0.08352392970760697
Validation loss: 2.2641527302449824

Epoch: 5| Step: 7
Training loss: 0.08463734905775665
Validation loss: 2.2827039348172073

Epoch: 5| Step: 8
Training loss: 0.119003130573579
Validation loss: 2.278714657823776

Epoch: 5| Step: 9
Training loss: 0.14035853332781859
Validation loss: 2.2804520130423303

Epoch: 5| Step: 10
Training loss: 0.2119434178144034
Validation loss: 2.262358650728375

Epoch: 578| Step: 0
Training loss: 0.11999093763459387
Validation loss: 2.259460605610865

Epoch: 5| Step: 1
Training loss: 0.15742238212674148
Validation loss: 2.2955293087572484

Epoch: 5| Step: 2
Training loss: 0.1310685677717795
Validation loss: 2.2837877630942245

Epoch: 5| Step: 3
Training loss: 0.10920846982799069
Validation loss: 2.294268090463188

Epoch: 5| Step: 4
Training loss: 0.08676375829889299
Validation loss: 2.289452862460789

Epoch: 5| Step: 5
Training loss: 0.1665400468639994
Validation loss: 2.3061027279299444

Epoch: 5| Step: 6
Training loss: 0.06365493508115233
Validation loss: 2.3011991441443502

Epoch: 5| Step: 7
Training loss: 0.09472380958568243
Validation loss: 2.3137570096311717

Epoch: 5| Step: 8
Training loss: 0.1519159337696306
Validation loss: 2.3288726178852435

Epoch: 5| Step: 9
Training loss: 0.10687010112488171
Validation loss: 2.328723770733758

Epoch: 5| Step: 10
Training loss: 0.17409057306908154
Validation loss: 2.3258011600549167

Epoch: 579| Step: 0
Training loss: 0.11032010364262818
Validation loss: 2.3345598606050566

Epoch: 5| Step: 1
Training loss: 0.12056726167104394
Validation loss: 2.3337388550560094

Epoch: 5| Step: 2
Training loss: 0.09980045018467248
Validation loss: 2.3073582611958634

Epoch: 5| Step: 3
Training loss: 0.1310140350554684
Validation loss: 2.29062165478858

Epoch: 5| Step: 4
Training loss: 0.08478181690932746
Validation loss: 2.278507357888533

Epoch: 5| Step: 5
Training loss: 0.16755518900805605
Validation loss: 2.265951128758957

Epoch: 5| Step: 6
Training loss: 0.09072747151024471
Validation loss: 2.2680453036441093

Epoch: 5| Step: 7
Training loss: 0.08640353676259345
Validation loss: 2.28510755766303

Epoch: 5| Step: 8
Training loss: 0.16405126555896993
Validation loss: 2.2728977812293962

Epoch: 5| Step: 9
Training loss: 0.17056121798187623
Validation loss: 2.282865632350972

Epoch: 5| Step: 10
Training loss: 0.12167290657951363
Validation loss: 2.286924840214084

Epoch: 580| Step: 0
Training loss: 0.09789671379662042
Validation loss: 2.2780213947831345

Epoch: 5| Step: 1
Training loss: 0.13704218753369887
Validation loss: 2.251867877715025

Epoch: 5| Step: 2
Training loss: 0.06838356679916352
Validation loss: 2.272659470272998

Epoch: 5| Step: 3
Training loss: 0.18809329976124453
Validation loss: 2.277583290174516

Epoch: 5| Step: 4
Training loss: 0.08450840044923541
Validation loss: 2.2891275313419768

Epoch: 5| Step: 5
Training loss: 0.10515632537992137
Validation loss: 2.28582794523783

Epoch: 5| Step: 6
Training loss: 0.08117974067886692
Validation loss: 2.3038959025953045

Epoch: 5| Step: 7
Training loss: 0.08239522295137802
Validation loss: 2.306858230271911

Epoch: 5| Step: 8
Training loss: 0.1299456895918986
Validation loss: 2.3201925200354587

Epoch: 5| Step: 9
Training loss: 0.05566066179428093
Validation loss: 2.2847775908695493

Epoch: 5| Step: 10
Training loss: 0.20258916273841662
Validation loss: 2.311488457176572

Epoch: 581| Step: 0
Training loss: 0.054429279097537045
Validation loss: 2.3133526737478234

Epoch: 5| Step: 1
Training loss: 0.09076904059655597
Validation loss: 2.3155221411706695

Epoch: 5| Step: 2
Training loss: 0.20516813210377965
Validation loss: 2.3209100183656544

Epoch: 5| Step: 3
Training loss: 0.0779992671339516
Validation loss: 2.3161315223822885

Epoch: 5| Step: 4
Training loss: 0.11841554520643845
Validation loss: 2.3041853048724956

Epoch: 5| Step: 5
Training loss: 0.12890959504151192
Validation loss: 2.319613744327255

Epoch: 5| Step: 6
Training loss: 0.09747158710952965
Validation loss: 2.274456399562228

Epoch: 5| Step: 7
Training loss: 0.11062130831630923
Validation loss: 2.311970693413531

Epoch: 5| Step: 8
Training loss: 0.09109449530242628
Validation loss: 2.2711067928799826

Epoch: 5| Step: 9
Training loss: 0.0707943880549004
Validation loss: 2.270917704801286

Epoch: 5| Step: 10
Training loss: 0.14427760136448206
Validation loss: 2.256574526736573

Epoch: 582| Step: 0
Training loss: 0.06866029175159397
Validation loss: 2.274158553586811

Epoch: 5| Step: 1
Training loss: 0.07203853211447073
Validation loss: 2.271660588492971

Epoch: 5| Step: 2
Training loss: 0.14834976740699293
Validation loss: 2.298850651262289

Epoch: 5| Step: 3
Training loss: 0.1629212170056484
Validation loss: 2.2784046842652077

Epoch: 5| Step: 4
Training loss: 0.1353110320163589
Validation loss: 2.2908583971065783

Epoch: 5| Step: 5
Training loss: 0.09291266985851677
Validation loss: 2.2954570745757854

Epoch: 5| Step: 6
Training loss: 0.07407139593429832
Validation loss: 2.285129595414305

Epoch: 5| Step: 7
Training loss: 0.0875761206573634
Validation loss: 2.2730545822618624

Epoch: 5| Step: 8
Training loss: 0.07476791070415867
Validation loss: 2.3007523462283794

Epoch: 5| Step: 9
Training loss: 0.17533492539872683
Validation loss: 2.31042371405733

Epoch: 5| Step: 10
Training loss: 0.09552856017129698
Validation loss: 2.327685830956588

Epoch: 583| Step: 0
Training loss: 0.06303373441518656
Validation loss: 2.3176971730240874

Epoch: 5| Step: 1
Training loss: 0.12147128565148407
Validation loss: 2.3259130082297768

Epoch: 5| Step: 2
Training loss: 0.08994710719858534
Validation loss: 2.335150091803552

Epoch: 5| Step: 3
Training loss: 0.07183417840310832
Validation loss: 2.3220532438328907

Epoch: 5| Step: 4
Training loss: 0.22958764059355627
Validation loss: 2.342240948266192

Epoch: 5| Step: 5
Training loss: 0.10773243228773503
Validation loss: 2.317767691235254

Epoch: 5| Step: 6
Training loss: 0.10982452132705561
Validation loss: 2.295503043771147

Epoch: 5| Step: 7
Training loss: 0.1497698829236636
Validation loss: 2.2964235662570314

Epoch: 5| Step: 8
Training loss: 0.09180727351927835
Validation loss: 2.287816505226193

Epoch: 5| Step: 9
Training loss: 0.1284492730107306
Validation loss: 2.2710344572282724

Epoch: 5| Step: 10
Training loss: 0.07563582420224005
Validation loss: 2.265461103248738

Epoch: 584| Step: 0
Training loss: 0.1526956650638877
Validation loss: 2.271388172292839

Epoch: 5| Step: 1
Training loss: 0.12181360336633879
Validation loss: 2.252556800854066

Epoch: 5| Step: 2
Training loss: 0.08053404129066201
Validation loss: 2.259789922988839

Epoch: 5| Step: 3
Training loss: 0.13706190097032586
Validation loss: 2.271978123791926

Epoch: 5| Step: 4
Training loss: 0.10510437772163823
Validation loss: 2.2709752215646692

Epoch: 5| Step: 5
Training loss: 0.11673016716372697
Validation loss: 2.311317443021602

Epoch: 5| Step: 6
Training loss: 0.11115066287751033
Validation loss: 2.2930635514884137

Epoch: 5| Step: 7
Training loss: 0.07396792705808973
Validation loss: 2.2987059521887043

Epoch: 5| Step: 8
Training loss: 0.16904132518266815
Validation loss: 2.3254446614249398

Epoch: 5| Step: 9
Training loss: 0.0920504759927727
Validation loss: 2.323165376065319

Epoch: 5| Step: 10
Training loss: 0.14991950890491368
Validation loss: 2.2864791144485914

Epoch: 585| Step: 0
Training loss: 0.09943703627673048
Validation loss: 2.274829060432698

Epoch: 5| Step: 1
Training loss: 0.14444605146205958
Validation loss: 2.2640329200604046

Epoch: 5| Step: 2
Training loss: 0.08946385610755077
Validation loss: 2.2715153260391436

Epoch: 5| Step: 3
Training loss: 0.0941302218565499
Validation loss: 2.2538424539884714

Epoch: 5| Step: 4
Training loss: 0.07111499385138792
Validation loss: 2.263535030300464

Epoch: 5| Step: 5
Training loss: 0.08480873396087339
Validation loss: 2.2470881329961894

Epoch: 5| Step: 6
Training loss: 0.11207879609753034
Validation loss: 2.2485575969064766

Epoch: 5| Step: 7
Training loss: 0.1009870282104531
Validation loss: 2.246481470971629

Epoch: 5| Step: 8
Training loss: 0.15796628932187207
Validation loss: 2.263097932358609

Epoch: 5| Step: 9
Training loss: 0.15082181078629245
Validation loss: 2.2560480325949612

Epoch: 5| Step: 10
Training loss: 0.07371991441986721
Validation loss: 2.257927453771261

Epoch: 586| Step: 0
Training loss: 0.08382769318795598
Validation loss: 2.2582043489655215

Epoch: 5| Step: 1
Training loss: 0.0909609884392834
Validation loss: 2.280977688869568

Epoch: 5| Step: 2
Training loss: 0.057455942450937554
Validation loss: 2.2652858357211483

Epoch: 5| Step: 3
Training loss: 0.1052087917963117
Validation loss: 2.2848987985086437

Epoch: 5| Step: 4
Training loss: 0.14684646359664258
Validation loss: 2.269315259220134

Epoch: 5| Step: 5
Training loss: 0.19698159382429406
Validation loss: 2.3080163340502122

Epoch: 5| Step: 6
Training loss: 0.11279362104483243
Validation loss: 2.272795072455037

Epoch: 5| Step: 7
Training loss: 0.10692349477659017
Validation loss: 2.291802405833494

Epoch: 5| Step: 8
Training loss: 0.11229660170927772
Validation loss: 2.2740485745792283

Epoch: 5| Step: 9
Training loss: 0.08430742630845979
Validation loss: 2.284886134537679

Epoch: 5| Step: 10
Training loss: 0.06549759799387692
Validation loss: 2.267768526479318

Epoch: 587| Step: 0
Training loss: 0.11173834012074513
Validation loss: 2.256280225180294

Epoch: 5| Step: 1
Training loss: 0.12758828245935663
Validation loss: 2.251010444565313

Epoch: 5| Step: 2
Training loss: 0.08477096310081231
Validation loss: 2.2497048554715944

Epoch: 5| Step: 3
Training loss: 0.09611372061747028
Validation loss: 2.267815585129207

Epoch: 5| Step: 4
Training loss: 0.07564034610697663
Validation loss: 2.265499403162854

Epoch: 5| Step: 5
Training loss: 0.1283375230624939
Validation loss: 2.2401861779303056

Epoch: 5| Step: 6
Training loss: 0.07877591588927177
Validation loss: 2.284783851353452

Epoch: 5| Step: 7
Training loss: 0.16631457395883953
Validation loss: 2.2770717913464176

Epoch: 5| Step: 8
Training loss: 0.20522817844116412
Validation loss: 2.285409202910861

Epoch: 5| Step: 9
Training loss: 0.10313335496840567
Validation loss: 2.2919159081543805

Epoch: 5| Step: 10
Training loss: 0.11885689736315497
Validation loss: 2.276926191805878

Epoch: 588| Step: 0
Training loss: 0.07940341317958018
Validation loss: 2.2910637660023743

Epoch: 5| Step: 1
Training loss: 0.18448587534822558
Validation loss: 2.257871503059352

Epoch: 5| Step: 2
Training loss: 0.08056621262498188
Validation loss: 2.279463119455262

Epoch: 5| Step: 3
Training loss: 0.08857940355832636
Validation loss: 2.2832414647067107

Epoch: 5| Step: 4
Training loss: 0.1594865917837709
Validation loss: 2.288756385389689

Epoch: 5| Step: 5
Training loss: 0.11020095219154231
Validation loss: 2.278572055917282

Epoch: 5| Step: 6
Training loss: 0.07851063204779599
Validation loss: 2.303640042406035

Epoch: 5| Step: 7
Training loss: 0.12248909640199866
Validation loss: 2.282578497716862

Epoch: 5| Step: 8
Training loss: 0.09004749126246615
Validation loss: 2.3192936713572436

Epoch: 5| Step: 9
Training loss: 0.154288786664053
Validation loss: 2.3077490087184582

Epoch: 5| Step: 10
Training loss: 0.12448307156589655
Validation loss: 2.3278597768539595

Epoch: 589| Step: 0
Training loss: 0.16285332634643854
Validation loss: 2.31514211686516

Epoch: 5| Step: 1
Training loss: 0.06596408573003573
Validation loss: 2.3142936499642737

Epoch: 5| Step: 2
Training loss: 0.1717728668982766
Validation loss: 2.3004833808382945

Epoch: 5| Step: 3
Training loss: 0.19129121009161731
Validation loss: 2.2641871997914707

Epoch: 5| Step: 4
Training loss: 0.20079719502408172
Validation loss: 2.252210910623615

Epoch: 5| Step: 5
Training loss: 0.11759045384172141
Validation loss: 2.2464348315855034

Epoch: 5| Step: 6
Training loss: 0.1090725138993827
Validation loss: 2.2332747504378427

Epoch: 5| Step: 7
Training loss: 0.09214586513885863
Validation loss: 2.224400575609477

Epoch: 5| Step: 8
Training loss: 0.13811894444530018
Validation loss: 2.2194806504417595

Epoch: 5| Step: 9
Training loss: 0.0918294159047326
Validation loss: 2.2208509352798234

Epoch: 5| Step: 10
Training loss: 0.11496482454987828
Validation loss: 2.2265980350499093

Epoch: 590| Step: 0
Training loss: 0.12816830577761268
Validation loss: 2.246649920001706

Epoch: 5| Step: 1
Training loss: 0.14398417808655858
Validation loss: 2.260175666495848

Epoch: 5| Step: 2
Training loss: 0.1646271480312994
Validation loss: 2.2644477843821513

Epoch: 5| Step: 3
Training loss: 0.12159342884736013
Validation loss: 2.3046815344092106

Epoch: 5| Step: 4
Training loss: 0.08114092616843122
Validation loss: 2.308829274633741

Epoch: 5| Step: 5
Training loss: 0.14438230340204375
Validation loss: 2.324833855772056

Epoch: 5| Step: 6
Training loss: 0.13242927828773862
Validation loss: 2.3384185410723837

Epoch: 5| Step: 7
Training loss: 0.11036298490164576
Validation loss: 2.349528625692079

Epoch: 5| Step: 8
Training loss: 0.15278161530539772
Validation loss: 2.3207650009780787

Epoch: 5| Step: 9
Training loss: 0.16090884393359642
Validation loss: 2.335252024247599

Epoch: 5| Step: 10
Training loss: 0.1115268097148868
Validation loss: 2.339450934480588

Epoch: 591| Step: 0
Training loss: 0.11402689185273006
Validation loss: 2.3103565269450312

Epoch: 5| Step: 1
Training loss: 0.20192453635827162
Validation loss: 2.3003014962116017

Epoch: 5| Step: 2
Training loss: 0.07391349231768984
Validation loss: 2.3362851486599867

Epoch: 5| Step: 3
Training loss: 0.13711081555688404
Validation loss: 2.3194400979590952

Epoch: 5| Step: 4
Training loss: 0.0668972390733635
Validation loss: 2.3427030422174817

Epoch: 5| Step: 5
Training loss: 0.15382680633739174
Validation loss: 2.354200890158281

Epoch: 5| Step: 6
Training loss: 0.127092468377661
Validation loss: 2.322885424161375

Epoch: 5| Step: 7
Training loss: 0.15730467923024385
Validation loss: 2.332547684729321

Epoch: 5| Step: 8
Training loss: 0.07992900361667207
Validation loss: 2.299039090058372

Epoch: 5| Step: 9
Training loss: 0.10007190838399777
Validation loss: 2.2960092390254063

Epoch: 5| Step: 10
Training loss: 0.1358735526059572
Validation loss: 2.287409072880796

Epoch: 592| Step: 0
Training loss: 0.08526432196579344
Validation loss: 2.2857461007309476

Epoch: 5| Step: 1
Training loss: 0.09511225626889576
Validation loss: 2.274123219473364

Epoch: 5| Step: 2
Training loss: 0.15540091961399233
Validation loss: 2.282188555097664

Epoch: 5| Step: 3
Training loss: 0.078521728515625
Validation loss: 2.2606914094899224

Epoch: 5| Step: 4
Training loss: 0.09245152085849764
Validation loss: 2.2887082294573218

Epoch: 5| Step: 5
Training loss: 0.1618120903125614
Validation loss: 2.282330621023814

Epoch: 5| Step: 6
Training loss: 0.12078378599448192
Validation loss: 2.2981450443474136

Epoch: 5| Step: 7
Training loss: 0.16891026546811475
Validation loss: 2.293028084402207

Epoch: 5| Step: 8
Training loss: 0.12229957033172133
Validation loss: 2.3276823919298555

Epoch: 5| Step: 9
Training loss: 0.1194392588933549
Validation loss: 2.3124558256941548

Epoch: 5| Step: 10
Training loss: 0.13072401846542545
Validation loss: 2.3121000460658956

Epoch: 593| Step: 0
Training loss: 0.07703843906313966
Validation loss: 2.2877928080149026

Epoch: 5| Step: 1
Training loss: 0.13538798080345227
Validation loss: 2.303899513438717

Epoch: 5| Step: 2
Training loss: 0.10271564447062198
Validation loss: 2.283084607602533

Epoch: 5| Step: 3
Training loss: 0.08376114586956807
Validation loss: 2.3073613827498995

Epoch: 5| Step: 4
Training loss: 0.10608752955767446
Validation loss: 2.2867299877004843

Epoch: 5| Step: 5
Training loss: 0.08970637288216378
Validation loss: 2.3194954853026877

Epoch: 5| Step: 6
Training loss: 0.0750786197876281
Validation loss: 2.2801267561572813

Epoch: 5| Step: 7
Training loss: 0.08473305999583809
Validation loss: 2.3113882457120547

Epoch: 5| Step: 8
Training loss: 0.15645034581920628
Validation loss: 2.303380356275061

Epoch: 5| Step: 9
Training loss: 0.09692972775431781
Validation loss: 2.282316427522005

Epoch: 5| Step: 10
Training loss: 0.2063172642522621
Validation loss: 2.3082085999504365

Epoch: 594| Step: 0
Training loss: 0.17415569815213702
Validation loss: 2.307701574610122

Epoch: 5| Step: 1
Training loss: 0.1477355610312185
Validation loss: 2.3263126748541607

Epoch: 5| Step: 2
Training loss: 0.1031199712321915
Validation loss: 2.328475276663648

Epoch: 5| Step: 3
Training loss: 0.08148291083617806
Validation loss: 2.328081001592199

Epoch: 5| Step: 4
Training loss: 0.10022775987217203
Validation loss: 2.325444404007453

Epoch: 5| Step: 5
Training loss: 0.09764389913657814
Validation loss: 2.321278388412007

Epoch: 5| Step: 6
Training loss: 0.08430072619185063
Validation loss: 2.3316763394137907

Epoch: 5| Step: 7
Training loss: 0.08844911305302
Validation loss: 2.329172254945274

Epoch: 5| Step: 8
Training loss: 0.08393265551102465
Validation loss: 2.342773821590828

Epoch: 5| Step: 9
Training loss: 0.06167332050143452
Validation loss: 2.3168045219234203

Epoch: 5| Step: 10
Training loss: 0.17896553831247738
Validation loss: 2.2778767641801254

Epoch: 595| Step: 0
Training loss: 0.07638915567941508
Validation loss: 2.305063195437444

Epoch: 5| Step: 1
Training loss: 0.09976747532012153
Validation loss: 2.2823982759519565

Epoch: 5| Step: 2
Training loss: 0.15192093005539237
Validation loss: 2.2931629673121097

Epoch: 5| Step: 3
Training loss: 0.16943361024004502
Validation loss: 2.2905302235423877

Epoch: 5| Step: 4
Training loss: 0.13157816517277418
Validation loss: 2.2856905606764606

Epoch: 5| Step: 5
Training loss: 0.11581274943883295
Validation loss: 2.2830600803016132

Epoch: 5| Step: 6
Training loss: 0.07377689680819573
Validation loss: 2.3374582108473585

Epoch: 5| Step: 7
Training loss: 0.06664021033485619
Validation loss: 2.3117313953527017

Epoch: 5| Step: 8
Training loss: 0.1062441158067788
Validation loss: 2.302760628757052

Epoch: 5| Step: 9
Training loss: 0.13482426321334803
Validation loss: 2.3240244606953544

Epoch: 5| Step: 10
Training loss: 0.17074038144816592
Validation loss: 2.31093440872504

Epoch: 596| Step: 0
Training loss: 0.11532630324775751
Validation loss: 2.314059900133887

Epoch: 5| Step: 1
Training loss: 0.07861378474103918
Validation loss: 2.269608214464171

Epoch: 5| Step: 2
Training loss: 0.11361717697476108
Validation loss: 2.295458568617727

Epoch: 5| Step: 3
Training loss: 0.0829385047363403
Validation loss: 2.295959105883256

Epoch: 5| Step: 4
Training loss: 0.15155955365846735
Validation loss: 2.292417751817574

Epoch: 5| Step: 5
Training loss: 0.16642746051415222
Validation loss: 2.2881087459843528

Epoch: 5| Step: 6
Training loss: 0.10791312079866922
Validation loss: 2.2775710886717007

Epoch: 5| Step: 7
Training loss: 0.14343775963188393
Validation loss: 2.3067840589647624

Epoch: 5| Step: 8
Training loss: 0.16004769204923747
Validation loss: 2.30187861049594

Epoch: 5| Step: 9
Training loss: 0.09766534286128468
Validation loss: 2.2992086190859293

Epoch: 5| Step: 10
Training loss: 0.10189058881535829
Validation loss: 2.279274767918819

Epoch: 597| Step: 0
Training loss: 0.11802913512909911
Validation loss: 2.2892006710553665

Epoch: 5| Step: 1
Training loss: 0.13283927731689493
Validation loss: 2.3112955443257275

Epoch: 5| Step: 2
Training loss: 0.22039355450846448
Validation loss: 2.295427008973796

Epoch: 5| Step: 3
Training loss: 0.13220679080381662
Validation loss: 2.298482678679597

Epoch: 5| Step: 4
Training loss: 0.11060027982492514
Validation loss: 2.2931281608049274

Epoch: 5| Step: 5
Training loss: 0.1579000725767429
Validation loss: 2.262665284321556

Epoch: 5| Step: 6
Training loss: 0.1414464627303178
Validation loss: 2.279702009607383

Epoch: 5| Step: 7
Training loss: 0.15208628490492776
Validation loss: 2.2955410780940526

Epoch: 5| Step: 8
Training loss: 0.17253586663155165
Validation loss: 2.2765710157444214

Epoch: 5| Step: 9
Training loss: 0.12911376722302814
Validation loss: 2.300204488688826

Epoch: 5| Step: 10
Training loss: 0.10978160789305447
Validation loss: 2.3077630557994246

Epoch: 598| Step: 0
Training loss: 0.11137439786730048
Validation loss: 2.320257945362156

Epoch: 5| Step: 1
Training loss: 0.18560599338955508
Validation loss: 2.3439381010532894

Epoch: 5| Step: 2
Training loss: 0.1231903760732514
Validation loss: 2.3360504607065904

Epoch: 5| Step: 3
Training loss: 0.1723057269867351
Validation loss: 2.3568802919578937

Epoch: 5| Step: 4
Training loss: 0.11806169126575919
Validation loss: 2.3571144079735933

Epoch: 5| Step: 5
Training loss: 0.15620820559387635
Validation loss: 2.3424825718383793

Epoch: 5| Step: 6
Training loss: 0.22536762622665318
Validation loss: 2.339477313152844

Epoch: 5| Step: 7
Training loss: 0.22678116407914498
Validation loss: 2.34630676930396

Epoch: 5| Step: 8
Training loss: 0.11688434808238825
Validation loss: 2.308330224281149

Epoch: 5| Step: 9
Training loss: 0.1475245988870109
Validation loss: 2.2518548680316957

Epoch: 5| Step: 10
Training loss: 0.1508360619807499
Validation loss: 2.2520850432283397

Epoch: 599| Step: 0
Training loss: 0.18308323025762024
Validation loss: 2.2191806550316113

Epoch: 5| Step: 1
Training loss: 0.17166401093899333
Validation loss: 2.2228449991781574

Epoch: 5| Step: 2
Training loss: 0.2199169097394083
Validation loss: 2.2733067227273254

Epoch: 5| Step: 3
Training loss: 0.1986790714768122
Validation loss: 2.275293025244237

Epoch: 5| Step: 4
Training loss: 0.18029860571908224
Validation loss: 2.2915160520249747

Epoch: 5| Step: 5
Training loss: 0.09613402828949758
Validation loss: 2.2910907577326136

Epoch: 5| Step: 6
Training loss: 0.1279558781029406
Validation loss: 2.2749340185283544

Epoch: 5| Step: 7
Training loss: 0.1584193494565156
Validation loss: 2.246739334984748

Epoch: 5| Step: 8
Training loss: 0.2161119484289331
Validation loss: 2.231337179381968

Epoch: 5| Step: 9
Training loss: 0.1922182841573623
Validation loss: 2.22261483747349

Epoch: 5| Step: 10
Training loss: 0.161709234169634
Validation loss: 2.2509079198585873

Epoch: 600| Step: 0
Training loss: 0.18897401062960875
Validation loss: 2.2134242922929825

Epoch: 5| Step: 1
Training loss: 0.1063656421301154
Validation loss: 2.244393385428853

Epoch: 5| Step: 2
Training loss: 0.14426574290644767
Validation loss: 2.205305433301997

Epoch: 5| Step: 3
Training loss: 0.12034900904010942
Validation loss: 2.22586449946377

Epoch: 5| Step: 4
Training loss: 0.16961217478194465
Validation loss: 2.24120445292528

Epoch: 5| Step: 5
Training loss: 0.17151354039897462
Validation loss: 2.308401158158865

Epoch: 5| Step: 6
Training loss: 0.08224299327846606
Validation loss: 2.2980226015054575

Epoch: 5| Step: 7
Training loss: 0.12264213146665233
Validation loss: 2.347795133004538

Epoch: 5| Step: 8
Training loss: 0.09264718047522168
Validation loss: 2.3638546234467817

Epoch: 5| Step: 9
Training loss: 0.17205105239685706
Validation loss: 2.3922369745604124

Epoch: 5| Step: 10
Training loss: 0.18029177687115347
Validation loss: 2.402868592877945

Epoch: 601| Step: 0
Training loss: 0.1250575722791643
Validation loss: 2.361979151833165

Epoch: 5| Step: 1
Training loss: 0.20215324727846248
Validation loss: 2.3135444269180776

Epoch: 5| Step: 2
Training loss: 0.16033739220179968
Validation loss: 2.304145557109787

Epoch: 5| Step: 3
Training loss: 0.18868395409311628
Validation loss: 2.275946444890078

Epoch: 5| Step: 4
Training loss: 0.12054040057039012
Validation loss: 2.256213990279403

Epoch: 5| Step: 5
Training loss: 0.1526311584162782
Validation loss: 2.2457926127698054

Epoch: 5| Step: 6
Training loss: 0.16587277605790907
Validation loss: 2.251611196522175

Epoch: 5| Step: 7
Training loss: 0.21817310078885863
Validation loss: 2.2258097969756476

Epoch: 5| Step: 8
Training loss: 0.15501946846152176
Validation loss: 2.242270696616538

Epoch: 5| Step: 9
Training loss: 0.10748016336582394
Validation loss: 2.2966389962093445

Epoch: 5| Step: 10
Training loss: 0.09719031762212213
Validation loss: 2.330618051582102

Epoch: 602| Step: 0
Training loss: 0.20909914091928933
Validation loss: 2.344336156253055

Epoch: 5| Step: 1
Training loss: 0.18906452201518628
Validation loss: 2.3464099111266914

Epoch: 5| Step: 2
Training loss: 0.148760012311724
Validation loss: 2.3425432441500265

Epoch: 5| Step: 3
Training loss: 0.13412810615460674
Validation loss: 2.325184607280564

Epoch: 5| Step: 4
Training loss: 0.09472149904226893
Validation loss: 2.2925476793346764

Epoch: 5| Step: 5
Training loss: 0.14429346060934312
Validation loss: 2.240788781019763

Epoch: 5| Step: 6
Training loss: 0.16186587878713166
Validation loss: 2.2567030292021317

Epoch: 5| Step: 7
Training loss: 0.14430590408735108
Validation loss: 2.230855229979511

Epoch: 5| Step: 8
Training loss: 0.13292774641809607
Validation loss: 2.2144429021952274

Epoch: 5| Step: 9
Training loss: 0.16609768802714917
Validation loss: 2.255923146077759

Epoch: 5| Step: 10
Training loss: 0.1136258941739531
Validation loss: 2.238427087534379

Epoch: 603| Step: 0
Training loss: 0.16738703265039065
Validation loss: 2.292949975443782

Epoch: 5| Step: 1
Training loss: 0.1338949202370432
Validation loss: 2.2926205422056105

Epoch: 5| Step: 2
Training loss: 0.13233236871937515
Validation loss: 2.3124367046479595

Epoch: 5| Step: 3
Training loss: 0.1438766618582117
Validation loss: 2.3304229294992327

Epoch: 5| Step: 4
Training loss: 0.14051806172035772
Validation loss: 2.3417659858302287

Epoch: 5| Step: 5
Training loss: 0.16368173510365114
Validation loss: 2.3069376555279884

Epoch: 5| Step: 6
Training loss: 0.20471575374562245
Validation loss: 2.326099397412499

Epoch: 5| Step: 7
Training loss: 0.13062769037195707
Validation loss: 2.269747087511785

Epoch: 5| Step: 8
Training loss: 0.12654979901103772
Validation loss: 2.2519197307027756

Epoch: 5| Step: 9
Training loss: 0.17098189359794014
Validation loss: 2.201550312730908

Epoch: 5| Step: 10
Training loss: 0.18769455789499695
Validation loss: 2.182744652716218

Epoch: 604| Step: 0
Training loss: 0.2861038557900131
Validation loss: 2.175059770029942

Epoch: 5| Step: 1
Training loss: 0.14108691249641273
Validation loss: 2.2301033550715927

Epoch: 5| Step: 2
Training loss: 0.13625711433402818
Validation loss: 2.245593073516105

Epoch: 5| Step: 3
Training loss: 0.13969609307734043
Validation loss: 2.2566855277408098

Epoch: 5| Step: 4
Training loss: 0.16508827942805523
Validation loss: 2.2782074702399164

Epoch: 5| Step: 5
Training loss: 0.23632928359323035
Validation loss: 2.2955212611027354

Epoch: 5| Step: 6
Training loss: 0.1186505227282777
Validation loss: 2.262040638888375

Epoch: 5| Step: 7
Training loss: 0.12304011205222785
Validation loss: 2.2256385554276807

Epoch: 5| Step: 8
Training loss: 0.21068464241251333
Validation loss: 2.180551701121175

Epoch: 5| Step: 9
Training loss: 0.17741823900697268
Validation loss: 2.19072124549528

Epoch: 5| Step: 10
Training loss: 0.19485401700095423
Validation loss: 2.1858455771244287

Epoch: 605| Step: 0
Training loss: 0.29079784975221074
Validation loss: 2.145961421541005

Epoch: 5| Step: 1
Training loss: 0.16731228739247941
Validation loss: 2.177045235877268

Epoch: 5| Step: 2
Training loss: 0.1883392921193617
Validation loss: 2.1985204027166305

Epoch: 5| Step: 3
Training loss: 0.21684128933533087
Validation loss: 2.225590784955573

Epoch: 5| Step: 4
Training loss: 0.19795044916012386
Validation loss: 2.2353119650049718

Epoch: 5| Step: 5
Training loss: 0.1977334565315031
Validation loss: 2.2494405771104864

Epoch: 5| Step: 6
Training loss: 0.19884824894538647
Validation loss: 2.215219539626414

Epoch: 5| Step: 7
Training loss: 0.1249612323427195
Validation loss: 2.2252417120739683

Epoch: 5| Step: 8
Training loss: 0.14920137264266514
Validation loss: 2.206691068218758

Epoch: 5| Step: 9
Training loss: 0.22121927788902224
Validation loss: 2.199443455000382

Epoch: 5| Step: 10
Training loss: 0.19327019070044935
Validation loss: 2.2083863766460885

Epoch: 606| Step: 0
Training loss: 0.16484963533101113
Validation loss: 2.215106211895665

Epoch: 5| Step: 1
Training loss: 0.15149378865833765
Validation loss: 2.21655365834489

Epoch: 5| Step: 2
Training loss: 0.23408719511865245
Validation loss: 2.208954384979196

Epoch: 5| Step: 3
Training loss: 0.22766096917931453
Validation loss: 2.2246398085328276

Epoch: 5| Step: 4
Training loss: 0.2162407882883864
Validation loss: 2.2387795332036617

Epoch: 5| Step: 5
Training loss: 0.17853638718150133
Validation loss: 2.2648247861152964

Epoch: 5| Step: 6
Training loss: 0.1579282397577248
Validation loss: 2.2558922683426483

Epoch: 5| Step: 7
Training loss: 0.1260000399218602
Validation loss: 2.249764789059273

Epoch: 5| Step: 8
Training loss: 0.17756482305688873
Validation loss: 2.2356759072057715

Epoch: 5| Step: 9
Training loss: 0.1985731228366423
Validation loss: 2.2684519340854323

Epoch: 5| Step: 10
Training loss: 0.14188569599954307
Validation loss: 2.207938714117318

Epoch: 607| Step: 0
Training loss: 0.17738514429713254
Validation loss: 2.225178554542221

Epoch: 5| Step: 1
Training loss: 0.13598275993227016
Validation loss: 2.2118433477172967

Epoch: 5| Step: 2
Training loss: 0.19356278595981777
Validation loss: 2.2233602971358484

Epoch: 5| Step: 3
Training loss: 0.17115643781192344
Validation loss: 2.21960827895628

Epoch: 5| Step: 4
Training loss: 0.1249621527714974
Validation loss: 2.242555041419009

Epoch: 5| Step: 5
Training loss: 0.12734002066926173
Validation loss: 2.2147374194620877

Epoch: 5| Step: 6
Training loss: 0.20330204034174076
Validation loss: 2.273843651523709

Epoch: 5| Step: 7
Training loss: 0.19811473940203947
Validation loss: 2.248810029598955

Epoch: 5| Step: 8
Training loss: 0.15259154048369197
Validation loss: 2.2434370793587477

Epoch: 5| Step: 9
Training loss: 0.15017399729664954
Validation loss: 2.253626422477175

Epoch: 5| Step: 10
Training loss: 0.19562353164073026
Validation loss: 2.2397577950896426

Epoch: 608| Step: 0
Training loss: 0.16050153820765423
Validation loss: 2.2488254765290425

Epoch: 5| Step: 1
Training loss: 0.1378575309613657
Validation loss: 2.2652981724294037

Epoch: 5| Step: 2
Training loss: 0.16980547590403983
Validation loss: 2.219688515428004

Epoch: 5| Step: 3
Training loss: 0.1283585370988947
Validation loss: 2.203671620226904

Epoch: 5| Step: 4
Training loss: 0.20714556938601403
Validation loss: 2.2077375365949883

Epoch: 5| Step: 5
Training loss: 0.11588160547854463
Validation loss: 2.210856506749534

Epoch: 5| Step: 6
Training loss: 0.14516139557200763
Validation loss: 2.2434945658905905

Epoch: 5| Step: 7
Training loss: 0.1770380443740509
Validation loss: 2.2331829389188154

Epoch: 5| Step: 8
Training loss: 0.11404427111640356
Validation loss: 2.2354844684313258

Epoch: 5| Step: 9
Training loss: 0.15343282301081396
Validation loss: 2.246688998736888

Epoch: 5| Step: 10
Training loss: 0.1102248662947473
Validation loss: 2.2759921787831234

Epoch: 609| Step: 0
Training loss: 0.13641068628313652
Validation loss: 2.2499114444127835

Epoch: 5| Step: 1
Training loss: 0.10323967680546615
Validation loss: 2.243575646970201

Epoch: 5| Step: 2
Training loss: 0.18456657849929717
Validation loss: 2.238138189806611

Epoch: 5| Step: 3
Training loss: 0.08958628292920336
Validation loss: 2.246158356738324

Epoch: 5| Step: 4
Training loss: 0.13702980487674787
Validation loss: 2.261926214902999

Epoch: 5| Step: 5
Training loss: 0.12756795920932934
Validation loss: 2.274960038678068

Epoch: 5| Step: 6
Training loss: 0.12486700343922957
Validation loss: 2.254173398471751

Epoch: 5| Step: 7
Training loss: 0.0911959703242461
Validation loss: 2.262427042268242

Epoch: 5| Step: 8
Training loss: 0.17528313951907182
Validation loss: 2.2868318951708617

Epoch: 5| Step: 9
Training loss: 0.17590510984909566
Validation loss: 2.288195925250516

Epoch: 5| Step: 10
Training loss: 0.12681518543524717
Validation loss: 2.2569279868948633

Epoch: 610| Step: 0
Training loss: 0.1576976176205164
Validation loss: 2.2721573713145555

Epoch: 5| Step: 1
Training loss: 0.10466465576219003
Validation loss: 2.2592355131515798

Epoch: 5| Step: 2
Training loss: 0.15804123542668813
Validation loss: 2.2785210440550165

Epoch: 5| Step: 3
Training loss: 0.12965780142184394
Validation loss: 2.299040541908002

Epoch: 5| Step: 4
Training loss: 0.1359453533359543
Validation loss: 2.270366085135382

Epoch: 5| Step: 5
Training loss: 0.16228974889871683
Validation loss: 2.2770113639385303

Epoch: 5| Step: 6
Training loss: 0.11432618760691862
Validation loss: 2.2771463151861093

Epoch: 5| Step: 7
Training loss: 0.10371694691088662
Validation loss: 2.262342891089067

Epoch: 5| Step: 8
Training loss: 0.12147832377042184
Validation loss: 2.323041489757561

Epoch: 5| Step: 9
Training loss: 0.1288430463571369
Validation loss: 2.2888290855763453

Epoch: 5| Step: 10
Training loss: 0.08521821541053726
Validation loss: 2.293134463891813

Epoch: 611| Step: 0
Training loss: 0.1060232184283238
Validation loss: 2.300258683053562

Epoch: 5| Step: 1
Training loss: 0.10270886666576633
Validation loss: 2.2796320058098107

Epoch: 5| Step: 2
Training loss: 0.10852884919212921
Validation loss: 2.2562255437186396

Epoch: 5| Step: 3
Training loss: 0.14934898654723516
Validation loss: 2.250088910997515

Epoch: 5| Step: 4
Training loss: 0.16255594125105505
Validation loss: 2.270421961672908

Epoch: 5| Step: 5
Training loss: 0.13495153237017327
Validation loss: 2.2343932430074185

Epoch: 5| Step: 6
Training loss: 0.19319841640610233
Validation loss: 2.269995450612527

Epoch: 5| Step: 7
Training loss: 0.17003902693821935
Validation loss: 2.2923850082170283

Epoch: 5| Step: 8
Training loss: 0.12626468622599551
Validation loss: 2.3050545993974496

Epoch: 5| Step: 9
Training loss: 0.08852196280170428
Validation loss: 2.326208046822823

Epoch: 5| Step: 10
Training loss: 0.12125118081756646
Validation loss: 2.3298539495133164

Epoch: 612| Step: 0
Training loss: 0.14220569908085
Validation loss: 2.309561388021528

Epoch: 5| Step: 1
Training loss: 0.11374932629521999
Validation loss: 2.3048740039667073

Epoch: 5| Step: 2
Training loss: 0.170280024293243
Validation loss: 2.2695908057410468

Epoch: 5| Step: 3
Training loss: 0.19244652869343898
Validation loss: 2.269497768694583

Epoch: 5| Step: 4
Training loss: 0.11455889508064045
Validation loss: 2.2743101321021997

Epoch: 5| Step: 5
Training loss: 0.10274260165270517
Validation loss: 2.2519599713731213

Epoch: 5| Step: 6
Training loss: 0.12054947854603291
Validation loss: 2.2281795482432947

Epoch: 5| Step: 7
Training loss: 0.21594384054378754
Validation loss: 2.253442969425884

Epoch: 5| Step: 8
Training loss: 0.1729996795534187
Validation loss: 2.248200692951158

Epoch: 5| Step: 9
Training loss: 0.18724312670612972
Validation loss: 2.286225796056057

Epoch: 5| Step: 10
Training loss: 0.14287925300584225
Validation loss: 2.314017395814995

Epoch: 613| Step: 0
Training loss: 0.1139984651671893
Validation loss: 2.3338467539238685

Epoch: 5| Step: 1
Training loss: 0.16943639153800755
Validation loss: 2.341437580386633

Epoch: 5| Step: 2
Training loss: 0.12091829294029702
Validation loss: 2.377687720407455

Epoch: 5| Step: 3
Training loss: 0.14281506642512654
Validation loss: 2.365022376137024

Epoch: 5| Step: 4
Training loss: 0.10232438366507682
Validation loss: 2.33054182150166

Epoch: 5| Step: 5
Training loss: 0.12328683827187908
Validation loss: 2.3170615135806067

Epoch: 5| Step: 6
Training loss: 0.19898844477756733
Validation loss: 2.319901750805275

Epoch: 5| Step: 7
Training loss: 0.11879427783936301
Validation loss: 2.3013383298984897

Epoch: 5| Step: 8
Training loss: 0.16129843551810602
Validation loss: 2.2395717213227813

Epoch: 5| Step: 9
Training loss: 0.12967950641171988
Validation loss: 2.24276164311927

Epoch: 5| Step: 10
Training loss: 0.1466193276874836
Validation loss: 2.2433618876724633

Epoch: 614| Step: 0
Training loss: 0.142894315885718
Validation loss: 2.253902805886131

Epoch: 5| Step: 1
Training loss: 0.2131546378293524
Validation loss: 2.228690363803911

Epoch: 5| Step: 2
Training loss: 0.15981861905112027
Validation loss: 2.254013930784513

Epoch: 5| Step: 3
Training loss: 0.1459505016367617
Validation loss: 2.2587421562872687

Epoch: 5| Step: 4
Training loss: 0.18083052312371095
Validation loss: 2.26182161774825

Epoch: 5| Step: 5
Training loss: 0.15257804533667763
Validation loss: 2.2734175016121765

Epoch: 5| Step: 6
Training loss: 0.18886586241074815
Validation loss: 2.264703809868867

Epoch: 5| Step: 7
Training loss: 0.11034216038983088
Validation loss: 2.2578446876004823

Epoch: 5| Step: 8
Training loss: 0.10903662041153336
Validation loss: 2.2442225611894724

Epoch: 5| Step: 9
Training loss: 0.10422042909667914
Validation loss: 2.229851035646071

Epoch: 5| Step: 10
Training loss: 0.12999695946273823
Validation loss: 2.2247678537902167

Epoch: 615| Step: 0
Training loss: 0.08881524422893694
Validation loss: 2.227288371318707

Epoch: 5| Step: 1
Training loss: 0.21127218609616188
Validation loss: 2.211030323366181

Epoch: 5| Step: 2
Training loss: 0.13084448544642008
Validation loss: 2.202585864625675

Epoch: 5| Step: 3
Training loss: 0.1528724093007137
Validation loss: 2.2011191097571343

Epoch: 5| Step: 4
Training loss: 0.11726008392600346
Validation loss: 2.2079801998790316

Epoch: 5| Step: 5
Training loss: 0.1958973425304964
Validation loss: 2.2218460534572935

Epoch: 5| Step: 6
Training loss: 0.12376840908462243
Validation loss: 2.2123106811349427

Epoch: 5| Step: 7
Training loss: 0.17634521719284849
Validation loss: 2.2340252825832274

Epoch: 5| Step: 8
Training loss: 0.15535808750959218
Validation loss: 2.234326420669018

Epoch: 5| Step: 9
Training loss: 0.1249339517799903
Validation loss: 2.2140090833002715

Epoch: 5| Step: 10
Training loss: 0.1072318477057661
Validation loss: 2.2216840983548396

Epoch: 616| Step: 0
Training loss: 0.11332324499249888
Validation loss: 2.256103124307042

Epoch: 5| Step: 1
Training loss: 0.11081482272959958
Validation loss: 2.2229413957747735

Epoch: 5| Step: 2
Training loss: 0.11151447510657599
Validation loss: 2.220322745521239

Epoch: 5| Step: 3
Training loss: 0.16253741755131032
Validation loss: 2.2244635783247553

Epoch: 5| Step: 4
Training loss: 0.1712188605116536
Validation loss: 2.224985722883948

Epoch: 5| Step: 5
Training loss: 0.09169171783026393
Validation loss: 2.229627982627227

Epoch: 5| Step: 6
Training loss: 0.16136185522048901
Validation loss: 2.2350453005900803

Epoch: 5| Step: 7
Training loss: 0.10349801651521434
Validation loss: 2.2479815915290824

Epoch: 5| Step: 8
Training loss: 0.1183370474727235
Validation loss: 2.2566497007833037

Epoch: 5| Step: 9
Training loss: 0.1568890022206824
Validation loss: 2.28609279543876

Epoch: 5| Step: 10
Training loss: 0.1294886912223427
Validation loss: 2.2912087133006516

Epoch: 617| Step: 0
Training loss: 0.11070331281378192
Validation loss: 2.2691210394629193

Epoch: 5| Step: 1
Training loss: 0.11679716668363657
Validation loss: 2.2630948907846524

Epoch: 5| Step: 2
Training loss: 0.11761075910334327
Validation loss: 2.263004738262271

Epoch: 5| Step: 3
Training loss: 0.16758419528272714
Validation loss: 2.2407541483198643

Epoch: 5| Step: 4
Training loss: 0.10537078952833775
Validation loss: 2.229431365103664

Epoch: 5| Step: 5
Training loss: 0.18253002024352075
Validation loss: 2.1977616499279105

Epoch: 5| Step: 6
Training loss: 0.08865606990563298
Validation loss: 2.192011164788511

Epoch: 5| Step: 7
Training loss: 0.13273781191017497
Validation loss: 2.2127748492816965

Epoch: 5| Step: 8
Training loss: 0.09511423419699201
Validation loss: 2.2090750592309663

Epoch: 5| Step: 9
Training loss: 0.08601152418064262
Validation loss: 2.196976178245488

Epoch: 5| Step: 10
Training loss: 0.14318778061433401
Validation loss: 2.2268929645552955

Epoch: 618| Step: 0
Training loss: 0.10637920409125057
Validation loss: 2.1913687187839854

Epoch: 5| Step: 1
Training loss: 0.09830651272429354
Validation loss: 2.2106195546826966

Epoch: 5| Step: 2
Training loss: 0.09517397859472186
Validation loss: 2.2498445388793487

Epoch: 5| Step: 3
Training loss: 0.13528103332607924
Validation loss: 2.2491264248260463

Epoch: 5| Step: 4
Training loss: 0.15021686920121818
Validation loss: 2.263316284032228

Epoch: 5| Step: 5
Training loss: 0.14593785377802637
Validation loss: 2.26682573691675

Epoch: 5| Step: 6
Training loss: 0.13863123714683778
Validation loss: 2.2991950203835785

Epoch: 5| Step: 7
Training loss: 0.13232983510390595
Validation loss: 2.294616759366484

Epoch: 5| Step: 8
Training loss: 0.12048802468366386
Validation loss: 2.3221070872598526

Epoch: 5| Step: 9
Training loss: 0.06091665972238541
Validation loss: 2.329156421811504

Epoch: 5| Step: 10
Training loss: 0.11009453065775703
Validation loss: 2.3270095379516262

Epoch: 619| Step: 0
Training loss: 0.1337570514112536
Validation loss: 2.2964977238891864

Epoch: 5| Step: 1
Training loss: 0.16102130962222744
Validation loss: 2.2909325804563645

Epoch: 5| Step: 2
Training loss: 0.11349034742711149
Validation loss: 2.3029952271117495

Epoch: 5| Step: 3
Training loss: 0.14614817503138175
Validation loss: 2.2827493177013816

Epoch: 5| Step: 4
Training loss: 0.11611590787517045
Validation loss: 2.2753093300938985

Epoch: 5| Step: 5
Training loss: 0.07912931132152883
Validation loss: 2.2621077367513194

Epoch: 5| Step: 6
Training loss: 0.1420329527338441
Validation loss: 2.257621326990305

Epoch: 5| Step: 7
Training loss: 0.14905744267127724
Validation loss: 2.235474462629488

Epoch: 5| Step: 8
Training loss: 0.07750717187102825
Validation loss: 2.2849550119143447

Epoch: 5| Step: 9
Training loss: 0.17799340749638196
Validation loss: 2.284813212395747

Epoch: 5| Step: 10
Training loss: 0.12933305683574461
Validation loss: 2.285164038546092

Epoch: 620| Step: 0
Training loss: 0.10985698258040189
Validation loss: 2.3078529811975694

Epoch: 5| Step: 1
Training loss: 0.09645541505522054
Validation loss: 2.2861867853620392

Epoch: 5| Step: 2
Training loss: 0.11461422018069138
Validation loss: 2.2799781831087196

Epoch: 5| Step: 3
Training loss: 0.14533433237446955
Validation loss: 2.2827171002703075

Epoch: 5| Step: 4
Training loss: 0.12409027431301782
Validation loss: 2.280774851858426

Epoch: 5| Step: 5
Training loss: 0.13636665646819257
Validation loss: 2.279984072784509

Epoch: 5| Step: 6
Training loss: 0.16812252058803145
Validation loss: 2.290814370064488

Epoch: 5| Step: 7
Training loss: 0.10793760649615647
Validation loss: 2.2529125914125103

Epoch: 5| Step: 8
Training loss: 0.09932001945652216
Validation loss: 2.2575772422594893

Epoch: 5| Step: 9
Training loss: 0.1431835723323283
Validation loss: 2.278126979183164

Epoch: 5| Step: 10
Training loss: 0.1058798082274914
Validation loss: 2.259945061836548

Epoch: 621| Step: 0
Training loss: 0.09490778881310159
Validation loss: 2.2262950889914697

Epoch: 5| Step: 1
Training loss: 0.11058334045702392
Validation loss: 2.2176604032771396

Epoch: 5| Step: 2
Training loss: 0.1363495815301278
Validation loss: 2.21456051353226

Epoch: 5| Step: 3
Training loss: 0.08978969564988824
Validation loss: 2.2217566982094334

Epoch: 5| Step: 4
Training loss: 0.15443008442986586
Validation loss: 2.2331216654279897

Epoch: 5| Step: 5
Training loss: 0.1147680626799231
Validation loss: 2.1918264895700976

Epoch: 5| Step: 6
Training loss: 0.06953059662286899
Validation loss: 2.2246520664139497

Epoch: 5| Step: 7
Training loss: 0.07184348659458797
Validation loss: 2.1930509650361896

Epoch: 5| Step: 8
Training loss: 0.12259173230196199
Validation loss: 2.2283326299318973

Epoch: 5| Step: 9
Training loss: 0.1703837191123688
Validation loss: 2.2482589892878813

Epoch: 5| Step: 10
Training loss: 0.09016003085097489
Validation loss: 2.245879665906452

Epoch: 622| Step: 0
Training loss: 0.06053695866688631
Validation loss: 2.2827848591359077

Epoch: 5| Step: 1
Training loss: 0.08940495230883982
Validation loss: 2.285525562224449

Epoch: 5| Step: 2
Training loss: 0.08304304889700388
Validation loss: 2.2917473559749735

Epoch: 5| Step: 3
Training loss: 0.1846127536963332
Validation loss: 2.298073156215243

Epoch: 5| Step: 4
Training loss: 0.07430154173040522
Validation loss: 2.3098870647524015

Epoch: 5| Step: 5
Training loss: 0.09321020611054091
Validation loss: 2.3108331026619484

Epoch: 5| Step: 6
Training loss: 0.09047129952753445
Validation loss: 2.3139981663591245

Epoch: 5| Step: 7
Training loss: 0.07483681768116188
Validation loss: 2.301001826522774

Epoch: 5| Step: 8
Training loss: 0.13710263716615448
Validation loss: 2.297160993803154

Epoch: 5| Step: 9
Training loss: 0.07361617608677622
Validation loss: 2.268203314943778

Epoch: 5| Step: 10
Training loss: 0.08995070000428337
Validation loss: 2.247375354914284

Epoch: 623| Step: 0
Training loss: 0.158017455750992
Validation loss: 2.2519069074524873

Epoch: 5| Step: 1
Training loss: 0.11117021336925499
Validation loss: 2.23588851231023

Epoch: 5| Step: 2
Training loss: 0.09698462321189903
Validation loss: 2.231746849828806

Epoch: 5| Step: 3
Training loss: 0.06704202458121833
Validation loss: 2.2255350853758213

Epoch: 5| Step: 4
Training loss: 0.15210917337146596
Validation loss: 2.2278025523272715

Epoch: 5| Step: 5
Training loss: 0.1052172895040683
Validation loss: 2.2325185855416647

Epoch: 5| Step: 6
Training loss: 0.11379367343008302
Validation loss: 2.2368598692348085

Epoch: 5| Step: 7
Training loss: 0.09517080315515705
Validation loss: 2.235751575248051

Epoch: 5| Step: 8
Training loss: 0.17253316228795207
Validation loss: 2.224681321647998

Epoch: 5| Step: 9
Training loss: 0.0643932107402996
Validation loss: 2.2211867058727583

Epoch: 5| Step: 10
Training loss: 0.11901420780949236
Validation loss: 2.23092660747693

Epoch: 624| Step: 0
Training loss: 0.1231852049062185
Validation loss: 2.2184420875604833

Epoch: 5| Step: 1
Training loss: 0.1289232416224999
Validation loss: 2.222482209310618

Epoch: 5| Step: 2
Training loss: 0.15608742123547836
Validation loss: 2.261447318430739

Epoch: 5| Step: 3
Training loss: 0.08408129998574727
Validation loss: 2.225441750170303

Epoch: 5| Step: 4
Training loss: 0.06861307545909864
Validation loss: 2.2603657019559256

Epoch: 5| Step: 5
Training loss: 0.09002409332693308
Validation loss: 2.2758410102459217

Epoch: 5| Step: 6
Training loss: 0.11229452833582253
Validation loss: 2.271152586978577

Epoch: 5| Step: 7
Training loss: 0.14373709968027137
Validation loss: 2.266773312501784

Epoch: 5| Step: 8
Training loss: 0.16115021467160537
Validation loss: 2.295841670750256

Epoch: 5| Step: 9
Training loss: 0.09117811743867012
Validation loss: 2.289846079331618

Epoch: 5| Step: 10
Training loss: 0.10361545625178134
Validation loss: 2.2812481423782156

Epoch: 625| Step: 0
Training loss: 0.15028259186989418
Validation loss: 2.28043998624212

Epoch: 5| Step: 1
Training loss: 0.08302426455649278
Validation loss: 2.2744816542178863

Epoch: 5| Step: 2
Training loss: 0.10414304067982187
Validation loss: 2.282121152324727

Epoch: 5| Step: 3
Training loss: 0.08640783198979597
Validation loss: 2.2861627645624685

Epoch: 5| Step: 4
Training loss: 0.13528919792399816
Validation loss: 2.2614602547928637

Epoch: 5| Step: 5
Training loss: 0.11719233185025688
Validation loss: 2.2517509165107574

Epoch: 5| Step: 6
Training loss: 0.11579252298845373
Validation loss: 2.253038838135616

Epoch: 5| Step: 7
Training loss: 0.1038587120847635
Validation loss: 2.2550814672324724

Epoch: 5| Step: 8
Training loss: 0.17279510330290876
Validation loss: 2.252429478861746

Epoch: 5| Step: 9
Training loss: 0.10813203500727651
Validation loss: 2.2416475090339363

Epoch: 5| Step: 10
Training loss: 0.15013604476735745
Validation loss: 2.2638013539151998

Epoch: 626| Step: 0
Training loss: 0.14305923235616633
Validation loss: 2.2734624840647997

Epoch: 5| Step: 1
Training loss: 0.2023391376985959
Validation loss: 2.260433264064139

Epoch: 5| Step: 2
Training loss: 0.11676248327939577
Validation loss: 2.2830576874074864

Epoch: 5| Step: 3
Training loss: 0.06289160502600169
Validation loss: 2.2570794186384022

Epoch: 5| Step: 4
Training loss: 0.13438524245992617
Validation loss: 2.2565452532709998

Epoch: 5| Step: 5
Training loss: 0.08082998969605658
Validation loss: 2.2571596425977054

Epoch: 5| Step: 6
Training loss: 0.06728668197319372
Validation loss: 2.2439680118512717

Epoch: 5| Step: 7
Training loss: 0.08034024138896359
Validation loss: 2.269554830076395

Epoch: 5| Step: 8
Training loss: 0.09803874924412322
Validation loss: 2.2866201828170793

Epoch: 5| Step: 9
Training loss: 0.14053292704101764
Validation loss: 2.2569375764118087

Epoch: 5| Step: 10
Training loss: 0.08113485703351027
Validation loss: 2.2734529369052727

Epoch: 627| Step: 0
Training loss: 0.13338720573179774
Validation loss: 2.281679326281959

Epoch: 5| Step: 1
Training loss: 0.14145456115817806
Validation loss: 2.284633799792411

Epoch: 5| Step: 2
Training loss: 0.14498075615475256
Validation loss: 2.2507076347022537

Epoch: 5| Step: 3
Training loss: 0.17910741382554474
Validation loss: 2.248221703022966

Epoch: 5| Step: 4
Training loss: 0.11711908171076627
Validation loss: 2.2140840282645944

Epoch: 5| Step: 5
Training loss: 0.10898230936970987
Validation loss: 2.215050027902183

Epoch: 5| Step: 6
Training loss: 0.09972138278208882
Validation loss: 2.2225533147326018

Epoch: 5| Step: 7
Training loss: 0.1453795860133802
Validation loss: 2.1909729128801723

Epoch: 5| Step: 8
Training loss: 0.12093763902197839
Validation loss: 2.1820235192753743

Epoch: 5| Step: 9
Training loss: 0.06477399630449884
Validation loss: 2.227342230652419

Epoch: 5| Step: 10
Training loss: 0.11966253314056145
Validation loss: 2.2379074060795867

Epoch: 628| Step: 0
Training loss: 0.14577055258103952
Validation loss: 2.22694930045248

Epoch: 5| Step: 1
Training loss: 0.09377347632358633
Validation loss: 2.222676376965896

Epoch: 5| Step: 2
Training loss: 0.11750131550519165
Validation loss: 2.2515873767225183

Epoch: 5| Step: 3
Training loss: 0.08547716773578685
Validation loss: 2.271426577680919

Epoch: 5| Step: 4
Training loss: 0.09780356739620728
Validation loss: 2.2769097577932653

Epoch: 5| Step: 5
Training loss: 0.09822410470164197
Validation loss: 2.2872149167609344

Epoch: 5| Step: 6
Training loss: 0.0582135321606254
Validation loss: 2.282435054446545

Epoch: 5| Step: 7
Training loss: 0.16411683340920147
Validation loss: 2.292201960925899

Epoch: 5| Step: 8
Training loss: 0.09146333525817033
Validation loss: 2.305212261399249

Epoch: 5| Step: 9
Training loss: 0.13803734470667176
Validation loss: 2.2703368325392503

Epoch: 5| Step: 10
Training loss: 0.08861916378541272
Validation loss: 2.2401829753601277

Epoch: 629| Step: 0
Training loss: 0.08983655050705341
Validation loss: 2.268681038979348

Epoch: 5| Step: 1
Training loss: 0.14038348651583854
Validation loss: 2.24238106405648

Epoch: 5| Step: 2
Training loss: 0.15606693630344756
Validation loss: 2.2573304860956873

Epoch: 5| Step: 3
Training loss: 0.12054538388420918
Validation loss: 2.255427268463145

Epoch: 5| Step: 4
Training loss: 0.09839980769973326
Validation loss: 2.2529471680698

Epoch: 5| Step: 5
Training loss: 0.05884910017686257
Validation loss: 2.257388750510571

Epoch: 5| Step: 6
Training loss: 0.08672294606547455
Validation loss: 2.271710298635136

Epoch: 5| Step: 7
Training loss: 0.10278964532157951
Validation loss: 2.291379194230429

Epoch: 5| Step: 8
Training loss: 0.13843875417291937
Validation loss: 2.316336632198626

Epoch: 5| Step: 9
Training loss: 0.09785894339434459
Validation loss: 2.3110280483734327

Epoch: 5| Step: 10
Training loss: 0.12104770338671941
Validation loss: 2.3503533325062884

Epoch: 630| Step: 0
Training loss: 0.09512032928604507
Validation loss: 2.3315380026415404

Epoch: 5| Step: 1
Training loss: 0.0872447601841549
Validation loss: 2.315837429541766

Epoch: 5| Step: 2
Training loss: 0.078503027897042
Validation loss: 2.317333908411678

Epoch: 5| Step: 3
Training loss: 0.07479600656800943
Validation loss: 2.303786491356216

Epoch: 5| Step: 4
Training loss: 0.07462151001811784
Validation loss: 2.3165704181724984

Epoch: 5| Step: 5
Training loss: 0.10988242512379374
Validation loss: 2.309489439259203

Epoch: 5| Step: 6
Training loss: 0.11459588303621017
Validation loss: 2.275155300882847

Epoch: 5| Step: 7
Training loss: 0.1260720637674339
Validation loss: 2.294756028765992

Epoch: 5| Step: 8
Training loss: 0.08058413108284028
Validation loss: 2.275554016125352

Epoch: 5| Step: 9
Training loss: 0.16348306763716972
Validation loss: 2.272006363428027

Epoch: 5| Step: 10
Training loss: 0.12684057822283124
Validation loss: 2.2818874087277594

Epoch: 631| Step: 0
Training loss: 0.16746812891751547
Validation loss: 2.269526099062085

Epoch: 5| Step: 1
Training loss: 0.08494501129047168
Validation loss: 2.2609038058898654

Epoch: 5| Step: 2
Training loss: 0.09673961554534585
Validation loss: 2.240723786061618

Epoch: 5| Step: 3
Training loss: 0.097147474571766
Validation loss: 2.228597576590912

Epoch: 5| Step: 4
Training loss: 0.09685093230793056
Validation loss: 2.235053951394719

Epoch: 5| Step: 5
Training loss: 0.06453479303373569
Validation loss: 2.2254705215702333

Epoch: 5| Step: 6
Training loss: 0.09058792367051534
Validation loss: 2.254259434816764

Epoch: 5| Step: 7
Training loss: 0.11629272435951186
Validation loss: 2.2543810562570132

Epoch: 5| Step: 8
Training loss: 0.0942769045569616
Validation loss: 2.26727357431882

Epoch: 5| Step: 9
Training loss: 0.13411048231675518
Validation loss: 2.264786674017101

Epoch: 5| Step: 10
Training loss: 0.1077922332069501
Validation loss: 2.2694761631628695

Epoch: 632| Step: 0
Training loss: 0.10516786926319234
Validation loss: 2.2853748980850974

Epoch: 5| Step: 1
Training loss: 0.06113187565253257
Validation loss: 2.2809964605348565

Epoch: 5| Step: 2
Training loss: 0.07213111550743562
Validation loss: 2.302895009528692

Epoch: 5| Step: 3
Training loss: 0.15175227740588332
Validation loss: 2.27736683830316

Epoch: 5| Step: 4
Training loss: 0.09912115482272066
Validation loss: 2.2814333801688735

Epoch: 5| Step: 5
Training loss: 0.08870369680494856
Validation loss: 2.2650061005673154

Epoch: 5| Step: 6
Training loss: 0.06528228910344136
Validation loss: 2.284665900145846

Epoch: 5| Step: 7
Training loss: 0.10864490120793599
Validation loss: 2.2744391778588047

Epoch: 5| Step: 8
Training loss: 0.14254827709526618
Validation loss: 2.2751854639408324

Epoch: 5| Step: 9
Training loss: 0.08546176818247263
Validation loss: 2.249761794411963

Epoch: 5| Step: 10
Training loss: 0.04772557732802778
Validation loss: 2.2446726199827176

Epoch: 633| Step: 0
Training loss: 0.10080632814469005
Validation loss: 2.26962042093569

Epoch: 5| Step: 1
Training loss: 0.05799495581839332
Validation loss: 2.2708121292450416

Epoch: 5| Step: 2
Training loss: 0.09297837660340072
Validation loss: 2.2744343254605446

Epoch: 5| Step: 3
Training loss: 0.08467175608329355
Validation loss: 2.2986175688534214

Epoch: 5| Step: 4
Training loss: 0.12845525454115655
Validation loss: 2.3083750583713925

Epoch: 5| Step: 5
Training loss: 0.06983066075625327
Validation loss: 2.2539657602262824

Epoch: 5| Step: 6
Training loss: 0.0714225857671565
Validation loss: 2.2876045477959406

Epoch: 5| Step: 7
Training loss: 0.1301025167283726
Validation loss: 2.291523808326935

Epoch: 5| Step: 8
Training loss: 0.13691475306185763
Validation loss: 2.284782546970507

Epoch: 5| Step: 9
Training loss: 0.11472598366336446
Validation loss: 2.3047267548263295

Epoch: 5| Step: 10
Training loss: 0.08905487885409841
Validation loss: 2.2748793729913364

Epoch: 634| Step: 0
Training loss: 0.06634528503133505
Validation loss: 2.284898109043793

Epoch: 5| Step: 1
Training loss: 0.1385374492228008
Validation loss: 2.287412748416059

Epoch: 5| Step: 2
Training loss: 0.09384358721752956
Validation loss: 2.2888680030738535

Epoch: 5| Step: 3
Training loss: 0.07913634924621347
Validation loss: 2.261044611291041

Epoch: 5| Step: 4
Training loss: 0.05577587934960432
Validation loss: 2.2659553691487826

Epoch: 5| Step: 5
Training loss: 0.0747989668538673
Validation loss: 2.292822876356501

Epoch: 5| Step: 6
Training loss: 0.11030099773686325
Validation loss: 2.2619514519187778

Epoch: 5| Step: 7
Training loss: 0.165917822134437
Validation loss: 2.279333367804991

Epoch: 5| Step: 8
Training loss: 0.07161006443620707
Validation loss: 2.282955650765728

Epoch: 5| Step: 9
Training loss: 0.07141464746417385
Validation loss: 2.290777891728844

Epoch: 5| Step: 10
Training loss: 0.0951476226616393
Validation loss: 2.286482383916789

Epoch: 635| Step: 0
Training loss: 0.06419053193298192
Validation loss: 2.295433718980416

Epoch: 5| Step: 1
Training loss: 0.08592765112273602
Validation loss: 2.29660745390295

Epoch: 5| Step: 2
Training loss: 0.07927832456942029
Validation loss: 2.3101945585807075

Epoch: 5| Step: 3
Training loss: 0.14041870270530166
Validation loss: 2.3168414671171838

Epoch: 5| Step: 4
Training loss: 0.09469985093715048
Validation loss: 2.325039587743482

Epoch: 5| Step: 5
Training loss: 0.1308544357278616
Validation loss: 2.3117034352789076

Epoch: 5| Step: 6
Training loss: 0.07852325556575249
Validation loss: 2.2701711597074

Epoch: 5| Step: 7
Training loss: 0.09459145733033807
Validation loss: 2.296053248521245

Epoch: 5| Step: 8
Training loss: 0.12663833030113705
Validation loss: 2.2712801297777117

Epoch: 5| Step: 9
Training loss: 0.0708320877313954
Validation loss: 2.267219475171221

Epoch: 5| Step: 10
Training loss: 0.052912376360047
Validation loss: 2.254919658916171

Epoch: 636| Step: 0
Training loss: 0.08652896701977275
Validation loss: 2.2463526371390596

Epoch: 5| Step: 1
Training loss: 0.10079453883422708
Validation loss: 2.2685094133532493

Epoch: 5| Step: 2
Training loss: 0.1474532763278351
Validation loss: 2.2543011746580994

Epoch: 5| Step: 3
Training loss: 0.09781632655096198
Validation loss: 2.259286725004147

Epoch: 5| Step: 4
Training loss: 0.1246706004987784
Validation loss: 2.2747366478616575

Epoch: 5| Step: 5
Training loss: 0.055872549740805966
Validation loss: 2.2784334237146067

Epoch: 5| Step: 6
Training loss: 0.08829890102130412
Validation loss: 2.2735615696325304

Epoch: 5| Step: 7
Training loss: 0.07283809450444392
Validation loss: 2.266524171316299

Epoch: 5| Step: 8
Training loss: 0.11014814955775665
Validation loss: 2.289075087388414

Epoch: 5| Step: 9
Training loss: 0.08629925944328548
Validation loss: 2.2753896098596975

Epoch: 5| Step: 10
Training loss: 0.07881489365744584
Validation loss: 2.286822956503966

Epoch: 637| Step: 0
Training loss: 0.09047777944513391
Validation loss: 2.293709285571784

Epoch: 5| Step: 1
Training loss: 0.0868593322224039
Validation loss: 2.2677415917794987

Epoch: 5| Step: 2
Training loss: 0.12883423469773247
Validation loss: 2.279779458914234

Epoch: 5| Step: 3
Training loss: 0.060340294356993306
Validation loss: 2.2434683259232306

Epoch: 5| Step: 4
Training loss: 0.0775874119258299
Validation loss: 2.258914606280916

Epoch: 5| Step: 5
Training loss: 0.09801218969514656
Validation loss: 2.2667937424390887

Epoch: 5| Step: 6
Training loss: 0.05762003228874851
Validation loss: 2.240735931929571

Epoch: 5| Step: 7
Training loss: 0.06635753162815654
Validation loss: 2.245312915560221

Epoch: 5| Step: 8
Training loss: 0.14312647837495843
Validation loss: 2.233937361826981

Epoch: 5| Step: 9
Training loss: 0.06693465359185159
Validation loss: 2.2136771884573614

Epoch: 5| Step: 10
Training loss: 0.12284010210542898
Validation loss: 2.2208994529718242

Epoch: 638| Step: 0
Training loss: 0.06996626510441463
Validation loss: 2.227875986137966

Epoch: 5| Step: 1
Training loss: 0.06643380967627337
Validation loss: 2.2445215356237926

Epoch: 5| Step: 2
Training loss: 0.08175325974256133
Validation loss: 2.227994903732234

Epoch: 5| Step: 3
Training loss: 0.09331653142608738
Validation loss: 2.244732761592829

Epoch: 5| Step: 4
Training loss: 0.08150890346905956
Validation loss: 2.276678681620327

Epoch: 5| Step: 5
Training loss: 0.06095810031533982
Validation loss: 2.270732497698835

Epoch: 5| Step: 6
Training loss: 0.11696306831070544
Validation loss: 2.258269300015787

Epoch: 5| Step: 7
Training loss: 0.11481059270457158
Validation loss: 2.2634329398243183

Epoch: 5| Step: 8
Training loss: 0.05817301414538877
Validation loss: 2.246914155783119

Epoch: 5| Step: 9
Training loss: 0.15665042351876413
Validation loss: 2.2589029508348983

Epoch: 5| Step: 10
Training loss: 0.14282100709539985
Validation loss: 2.265491699778217

Epoch: 639| Step: 0
Training loss: 0.04896458868425154
Validation loss: 2.2429957528587545

Epoch: 5| Step: 1
Training loss: 0.08706045680274091
Validation loss: 2.2480558087642626

Epoch: 5| Step: 2
Training loss: 0.04330420678835575
Validation loss: 2.268481465263234

Epoch: 5| Step: 3
Training loss: 0.09715741066624356
Validation loss: 2.24445571500193

Epoch: 5| Step: 4
Training loss: 0.07265569471331641
Validation loss: 2.2440165829545435

Epoch: 5| Step: 5
Training loss: 0.0881753495207955
Validation loss: 2.243701447851547

Epoch: 5| Step: 6
Training loss: 0.14170795258645952
Validation loss: 2.2772088977008433

Epoch: 5| Step: 7
Training loss: 0.06653375865861688
Validation loss: 2.239590783379868

Epoch: 5| Step: 8
Training loss: 0.07323861749213668
Validation loss: 2.246344981648821

Epoch: 5| Step: 9
Training loss: 0.1256101291309756
Validation loss: 2.250829837590416

Epoch: 5| Step: 10
Training loss: 0.10889673828418336
Validation loss: 2.262502927772025

Epoch: 640| Step: 0
Training loss: 0.08525967693134177
Validation loss: 2.2608420346660134

Epoch: 5| Step: 1
Training loss: 0.0793442623301053
Validation loss: 2.2657009503820476

Epoch: 5| Step: 2
Training loss: 0.08565816672858616
Validation loss: 2.253870654124075

Epoch: 5| Step: 3
Training loss: 0.0694034710930644
Validation loss: 2.2439579342010085

Epoch: 5| Step: 4
Training loss: 0.09269057639136072
Validation loss: 2.242337209614209

Epoch: 5| Step: 5
Training loss: 0.12043751671058012
Validation loss: 2.26689322240891

Epoch: 5| Step: 6
Training loss: 0.07951425695900959
Validation loss: 2.252175882142756

Epoch: 5| Step: 7
Training loss: 0.12657642964837137
Validation loss: 2.261535273238177

Epoch: 5| Step: 8
Training loss: 0.057392457965480335
Validation loss: 2.2548696843478724

Epoch: 5| Step: 9
Training loss: 0.11208483696600212
Validation loss: 2.262186995344122

Epoch: 5| Step: 10
Training loss: 0.07606027448418451
Validation loss: 2.2465236337683994

Epoch: 641| Step: 0
Training loss: 0.07163467956112615
Validation loss: 2.254178902930962

Epoch: 5| Step: 1
Training loss: 0.12888394509591497
Validation loss: 2.242634581223024

Epoch: 5| Step: 2
Training loss: 0.07158063025879492
Validation loss: 2.2345039048814304

Epoch: 5| Step: 3
Training loss: 0.08511144089086753
Validation loss: 2.2485759933461837

Epoch: 5| Step: 4
Training loss: 0.10194987459957283
Validation loss: 2.2698028222931237

Epoch: 5| Step: 5
Training loss: 0.053585150118369757
Validation loss: 2.269740695758773

Epoch: 5| Step: 6
Training loss: 0.0599274521623281
Validation loss: 2.2460553971092954

Epoch: 5| Step: 7
Training loss: 0.10355041027409163
Validation loss: 2.2506372034879774

Epoch: 5| Step: 8
Training loss: 0.06207565330853122
Validation loss: 2.227449367070139

Epoch: 5| Step: 9
Training loss: 0.08938378265883967
Validation loss: 2.2315891995235395

Epoch: 5| Step: 10
Training loss: 0.13868773732330522
Validation loss: 2.236436132579549

Epoch: 642| Step: 0
Training loss: 0.03843920050712905
Validation loss: 2.2324155291124033

Epoch: 5| Step: 1
Training loss: 0.05503712380976707
Validation loss: 2.2578164354776797

Epoch: 5| Step: 2
Training loss: 0.11464157213909311
Validation loss: 2.2518714609858557

Epoch: 5| Step: 3
Training loss: 0.11412094346662814
Validation loss: 2.2172827137613513

Epoch: 5| Step: 4
Training loss: 0.10853491602746294
Validation loss: 2.248371246300587

Epoch: 5| Step: 5
Training loss: 0.05761026890482534
Validation loss: 2.229966266816

Epoch: 5| Step: 6
Training loss: 0.10055780017217943
Validation loss: 2.2253046397092398

Epoch: 5| Step: 7
Training loss: 0.05649185992082492
Validation loss: 2.2367894673139292

Epoch: 5| Step: 8
Training loss: 0.13020143649591367
Validation loss: 2.255942509470658

Epoch: 5| Step: 9
Training loss: 0.13840043002165844
Validation loss: 2.2479675996863726

Epoch: 5| Step: 10
Training loss: 0.07631678125039704
Validation loss: 2.247546529807362

Epoch: 643| Step: 0
Training loss: 0.06765524069449493
Validation loss: 2.2527733338042455

Epoch: 5| Step: 1
Training loss: 0.06740339282779946
Validation loss: 2.2533115493776994

Epoch: 5| Step: 2
Training loss: 0.10327994760595312
Validation loss: 2.2418011245295735

Epoch: 5| Step: 3
Training loss: 0.0640019534840139
Validation loss: 2.241419911148779

Epoch: 5| Step: 4
Training loss: 0.07848101500739299
Validation loss: 2.275774616090285

Epoch: 5| Step: 5
Training loss: 0.07358987932696896
Validation loss: 2.2768223327296

Epoch: 5| Step: 6
Training loss: 0.13064125728739323
Validation loss: 2.273722803354728

Epoch: 5| Step: 7
Training loss: 0.11191553194768972
Validation loss: 2.271115996587018

Epoch: 5| Step: 8
Training loss: 0.06453531255934593
Validation loss: 2.274009639080838

Epoch: 5| Step: 9
Training loss: 0.1313413739031458
Validation loss: 2.2809582887722293

Epoch: 5| Step: 10
Training loss: 0.1145129208710678
Validation loss: 2.267272067640349

Epoch: 644| Step: 0
Training loss: 0.09108769117755126
Validation loss: 2.2764985119367496

Epoch: 5| Step: 1
Training loss: 0.07052657202755587
Validation loss: 2.25471215420426

Epoch: 5| Step: 2
Training loss: 0.08030623128097195
Validation loss: 2.236546601673665

Epoch: 5| Step: 3
Training loss: 0.07220399006637186
Validation loss: 2.2367729894121346

Epoch: 5| Step: 4
Training loss: 0.09963997202661218
Validation loss: 2.2437745555610653

Epoch: 5| Step: 5
Training loss: 0.03955313887456871
Validation loss: 2.231981289057085

Epoch: 5| Step: 6
Training loss: 0.0667727782470305
Validation loss: 2.211745374245497

Epoch: 5| Step: 7
Training loss: 0.08320075499602259
Validation loss: 2.211821583083604

Epoch: 5| Step: 8
Training loss: 0.07980263820823429
Validation loss: 2.1996173524007236

Epoch: 5| Step: 9
Training loss: 0.09046883919897607
Validation loss: 2.2139912860314004

Epoch: 5| Step: 10
Training loss: 0.1986316369546109
Validation loss: 2.207466785124028

Epoch: 645| Step: 0
Training loss: 0.06643799065308245
Validation loss: 2.2224030222031095

Epoch: 5| Step: 1
Training loss: 0.16410265726270495
Validation loss: 2.243007608687727

Epoch: 5| Step: 2
Training loss: 0.12272985810042607
Validation loss: 2.239682712815859

Epoch: 5| Step: 3
Training loss: 0.0673412768569217
Validation loss: 2.245265852271136

Epoch: 5| Step: 4
Training loss: 0.06838448267744623
Validation loss: 2.225414942242634

Epoch: 5| Step: 5
Training loss: 0.11045636626978751
Validation loss: 2.2514660860217455

Epoch: 5| Step: 6
Training loss: 0.07614346120982016
Validation loss: 2.2707859712485785

Epoch: 5| Step: 7
Training loss: 0.08839290992692579
Validation loss: 2.2652385626800746

Epoch: 5| Step: 8
Training loss: 0.11381812551794325
Validation loss: 2.2750182882513923

Epoch: 5| Step: 9
Training loss: 0.0621196340988989
Validation loss: 2.2867117877783603

Epoch: 5| Step: 10
Training loss: 0.09521410526087061
Validation loss: 2.2644161825573224

Epoch: 646| Step: 0
Training loss: 0.1331858576212831
Validation loss: 2.2551497264917106

Epoch: 5| Step: 1
Training loss: 0.08843468123247175
Validation loss: 2.263665847751185

Epoch: 5| Step: 2
Training loss: 0.0876910964784984
Validation loss: 2.2535419830525387

Epoch: 5| Step: 3
Training loss: 0.07242150506189503
Validation loss: 2.2860474475296804

Epoch: 5| Step: 4
Training loss: 0.07637914554213339
Validation loss: 2.2686563988969994

Epoch: 5| Step: 5
Training loss: 0.08347977093879796
Validation loss: 2.254467838599762

Epoch: 5| Step: 6
Training loss: 0.12894830595677215
Validation loss: 2.238156500647176

Epoch: 5| Step: 7
Training loss: 0.06925831734849268
Validation loss: 2.2369307365295326

Epoch: 5| Step: 8
Training loss: 0.13451382706962997
Validation loss: 2.2303482936027375

Epoch: 5| Step: 9
Training loss: 0.07002098196380963
Validation loss: 2.23485390415543

Epoch: 5| Step: 10
Training loss: 0.10737143112431048
Validation loss: 2.2696179206842735

Epoch: 647| Step: 0
Training loss: 0.04985698590730783
Validation loss: 2.2234316119967845

Epoch: 5| Step: 1
Training loss: 0.08279620012428336
Validation loss: 2.2359489372003725

Epoch: 5| Step: 2
Training loss: 0.0838713495299386
Validation loss: 2.261099363571325

Epoch: 5| Step: 3
Training loss: 0.064222095151777
Validation loss: 2.2589209571685456

Epoch: 5| Step: 4
Training loss: 0.059063118279843896
Validation loss: 2.2738255725401793

Epoch: 5| Step: 5
Training loss: 0.09136225403688532
Validation loss: 2.293816952833182

Epoch: 5| Step: 6
Training loss: 0.17474904586670678
Validation loss: 2.280558472457552

Epoch: 5| Step: 7
Training loss: 0.0956147428072727
Validation loss: 2.2879562849241464

Epoch: 5| Step: 8
Training loss: 0.10899525523139178
Validation loss: 2.2991078456174248

Epoch: 5| Step: 9
Training loss: 0.08780741726514679
Validation loss: 2.325388018969164

Epoch: 5| Step: 10
Training loss: 0.11011275048060168
Validation loss: 2.286019458725364

Epoch: 648| Step: 0
Training loss: 0.0999884032439352
Validation loss: 2.275753162241217

Epoch: 5| Step: 1
Training loss: 0.055218913933915946
Validation loss: 2.2863776403218403

Epoch: 5| Step: 2
Training loss: 0.1250087988260076
Validation loss: 2.254815508736471

Epoch: 5| Step: 3
Training loss: 0.08047868982052499
Validation loss: 2.2383606690862345

Epoch: 5| Step: 4
Training loss: 0.15413334788232802
Validation loss: 2.2493405865581915

Epoch: 5| Step: 5
Training loss: 0.07550894366866065
Validation loss: 2.228196406095045

Epoch: 5| Step: 6
Training loss: 0.08503329823924524
Validation loss: 2.2383245430916237

Epoch: 5| Step: 7
Training loss: 0.1003595693771378
Validation loss: 2.2525165708459363

Epoch: 5| Step: 8
Training loss: 0.0670169455097315
Validation loss: 2.2428801961046942

Epoch: 5| Step: 9
Training loss: 0.06706207414195894
Validation loss: 2.2691334886351675

Epoch: 5| Step: 10
Training loss: 0.10487943267349159
Validation loss: 2.2738015911207423

Epoch: 649| Step: 0
Training loss: 0.10688267109344812
Validation loss: 2.2602072601229457

Epoch: 5| Step: 1
Training loss: 0.09508450708464421
Validation loss: 2.282019841095558

Epoch: 5| Step: 2
Training loss: 0.1201771958415278
Validation loss: 2.315002080003524

Epoch: 5| Step: 3
Training loss: 0.08963607025443866
Validation loss: 2.314010650511875

Epoch: 5| Step: 4
Training loss: 0.1147838854950631
Validation loss: 2.3032751484379124

Epoch: 5| Step: 5
Training loss: 0.08830631815884557
Validation loss: 2.2791892360709527

Epoch: 5| Step: 6
Training loss: 0.1521380454004667
Validation loss: 2.2593960700521114

Epoch: 5| Step: 7
Training loss: 0.14255488219305104
Validation loss: 2.2709251036045623

Epoch: 5| Step: 8
Training loss: 0.06797334460919509
Validation loss: 2.258371521750583

Epoch: 5| Step: 9
Training loss: 0.07666077583208394
Validation loss: 2.2639569867578695

Epoch: 5| Step: 10
Training loss: 0.08360189571979043
Validation loss: 2.2792724160411906

Epoch: 650| Step: 0
Training loss: 0.0785823725718423
Validation loss: 2.259365715491488

Epoch: 5| Step: 1
Training loss: 0.08396339154368575
Validation loss: 2.2499308900234665

Epoch: 5| Step: 2
Training loss: 0.075681240291305
Validation loss: 2.264455340745778

Epoch: 5| Step: 3
Training loss: 0.09102846718098866
Validation loss: 2.240907857088409

Epoch: 5| Step: 4
Training loss: 0.07686242977255602
Validation loss: 2.265073774393512

Epoch: 5| Step: 5
Training loss: 0.14723641943278817
Validation loss: 2.262273185309868

Epoch: 5| Step: 6
Training loss: 0.1466106252209411
Validation loss: 2.284216053475533

Epoch: 5| Step: 7
Training loss: 0.1291458475218854
Validation loss: 2.251487660563113

Epoch: 5| Step: 8
Training loss: 0.1125217082351524
Validation loss: 2.258566696532715

Epoch: 5| Step: 9
Training loss: 0.10376815761961597
Validation loss: 2.270624387290906

Epoch: 5| Step: 10
Training loss: 0.15168719766018493
Validation loss: 2.289911649308738

Epoch: 651| Step: 0
Training loss: 0.08745146015999379
Validation loss: 2.2406832509246284

Epoch: 5| Step: 1
Training loss: 0.06665144559703004
Validation loss: 2.2802895802586556

Epoch: 5| Step: 2
Training loss: 0.10044395277211611
Validation loss: 2.285265913201382

Epoch: 5| Step: 3
Training loss: 0.07648793087565338
Validation loss: 2.2746341951225806

Epoch: 5| Step: 4
Training loss: 0.10371946113028865
Validation loss: 2.2821246538310875

Epoch: 5| Step: 5
Training loss: 0.12555126732036967
Validation loss: 2.294967153674595

Epoch: 5| Step: 6
Training loss: 0.10448198179513675
Validation loss: 2.2872853172601793

Epoch: 5| Step: 7
Training loss: 0.09581155376159926
Validation loss: 2.2834025033070158

Epoch: 5| Step: 8
Training loss: 0.16340060343664506
Validation loss: 2.2965683109024178

Epoch: 5| Step: 9
Training loss: 0.12366948721262008
Validation loss: 2.287296758586698

Epoch: 5| Step: 10
Training loss: 0.08544540669248644
Validation loss: 2.279960471261982

Epoch: 652| Step: 0
Training loss: 0.10075379688956704
Validation loss: 2.2697182098375066

Epoch: 5| Step: 1
Training loss: 0.12023011768282002
Validation loss: 2.2771719627476426

Epoch: 5| Step: 2
Training loss: 0.09135634657666859
Validation loss: 2.222994242364577

Epoch: 5| Step: 3
Training loss: 0.15579697978152293
Validation loss: 2.223365267919234

Epoch: 5| Step: 4
Training loss: 0.11437244859309424
Validation loss: 2.2401177888729147

Epoch: 5| Step: 5
Training loss: 0.07596701804767723
Validation loss: 2.2224820593551797

Epoch: 5| Step: 6
Training loss: 0.12775069374579165
Validation loss: 2.2001199864829935

Epoch: 5| Step: 7
Training loss: 0.13807869019435315
Validation loss: 2.224282781508851

Epoch: 5| Step: 8
Training loss: 0.1497204077232151
Validation loss: 2.208437764102956

Epoch: 5| Step: 9
Training loss: 0.11062326151079875
Validation loss: 2.202076540483313

Epoch: 5| Step: 10
Training loss: 0.1189205489978735
Validation loss: 2.2251713337087646

Epoch: 653| Step: 0
Training loss: 0.08929208685919515
Validation loss: 2.256509528608358

Epoch: 5| Step: 1
Training loss: 0.07562117309778964
Validation loss: 2.226260169501412

Epoch: 5| Step: 2
Training loss: 0.1334126530524968
Validation loss: 2.2646136546057605

Epoch: 5| Step: 3
Training loss: 0.08596058015403259
Validation loss: 2.24776818507935

Epoch: 5| Step: 4
Training loss: 0.06584930375724247
Validation loss: 2.239280336396944

Epoch: 5| Step: 5
Training loss: 0.11231086962726007
Validation loss: 2.232522635080406

Epoch: 5| Step: 6
Training loss: 0.10269873312661604
Validation loss: 2.2365575173819163

Epoch: 5| Step: 7
Training loss: 0.13234251677063516
Validation loss: 2.27516597557946

Epoch: 5| Step: 8
Training loss: 0.1122431835436508
Validation loss: 2.2773142290514086

Epoch: 5| Step: 9
Training loss: 0.15300671280754716
Validation loss: 2.262081479233321

Epoch: 5| Step: 10
Training loss: 0.15742286132806413
Validation loss: 2.285543031285978

Epoch: 654| Step: 0
Training loss: 0.14795346143827096
Validation loss: 2.323202228104648

Epoch: 5| Step: 1
Training loss: 0.11286287494657982
Validation loss: 2.281712385025626

Epoch: 5| Step: 2
Training loss: 0.08480331993493904
Validation loss: 2.2818506371351934

Epoch: 5| Step: 3
Training loss: 0.10217721763406527
Validation loss: 2.2722750303207437

Epoch: 5| Step: 4
Training loss: 0.10524341123196682
Validation loss: 2.251874407289736

Epoch: 5| Step: 5
Training loss: 0.09990133245856822
Validation loss: 2.2646662758935276

Epoch: 5| Step: 6
Training loss: 0.10828625398415705
Validation loss: 2.241754284846687

Epoch: 5| Step: 7
Training loss: 0.15617528559599256
Validation loss: 2.260367214655641

Epoch: 5| Step: 8
Training loss: 0.06598686573712283
Validation loss: 2.255001334185949

Epoch: 5| Step: 9
Training loss: 0.12302801956545871
Validation loss: 2.2908985161265716

Epoch: 5| Step: 10
Training loss: 0.10243989145124459
Validation loss: 2.2559098094822403

Epoch: 655| Step: 0
Training loss: 0.08694422391401443
Validation loss: 2.2314382595757607

Epoch: 5| Step: 1
Training loss: 0.09117067089446107
Validation loss: 2.2238142938998795

Epoch: 5| Step: 2
Training loss: 0.13684145325812933
Validation loss: 2.258203645674156

Epoch: 5| Step: 3
Training loss: 0.08538698382349351
Validation loss: 2.2476706268321696

Epoch: 5| Step: 4
Training loss: 0.08290121863800183
Validation loss: 2.27496841825236

Epoch: 5| Step: 5
Training loss: 0.12515663972000995
Validation loss: 2.2333164095371294

Epoch: 5| Step: 6
Training loss: 0.06905777636185126
Validation loss: 2.2537964941487907

Epoch: 5| Step: 7
Training loss: 0.14520951872491833
Validation loss: 2.2528484383935945

Epoch: 5| Step: 8
Training loss: 0.12807697087924722
Validation loss: 2.2749472652896614

Epoch: 5| Step: 9
Training loss: 0.09091768377404874
Validation loss: 2.290560453029522

Epoch: 5| Step: 10
Training loss: 0.09866984304871482
Validation loss: 2.2577462413541083

Epoch: 656| Step: 0
Training loss: 0.15076220421750597
Validation loss: 2.2452613159020807

Epoch: 5| Step: 1
Training loss: 0.10472544811442719
Validation loss: 2.230031408613616

Epoch: 5| Step: 2
Training loss: 0.0883061573245758
Validation loss: 2.245034247101828

Epoch: 5| Step: 3
Training loss: 0.08056485145686962
Validation loss: 2.1874767331528187

Epoch: 5| Step: 4
Training loss: 0.09248010540642101
Validation loss: 2.2417449417229642

Epoch: 5| Step: 5
Training loss: 0.1488722595595999
Validation loss: 2.199515033641314

Epoch: 5| Step: 6
Training loss: 0.08028182719120795
Validation loss: 2.215090658290482

Epoch: 5| Step: 7
Training loss: 0.1537824699378273
Validation loss: 2.2142870471894196

Epoch: 5| Step: 8
Training loss: 0.08525448544404922
Validation loss: 2.216205853547575

Epoch: 5| Step: 9
Training loss: 0.12156832667559425
Validation loss: 2.221519015638248

Epoch: 5| Step: 10
Training loss: 0.07353398371517755
Validation loss: 2.252647296398495

Epoch: 657| Step: 0
Training loss: 0.1409958215265147
Validation loss: 2.255253704934896

Epoch: 5| Step: 1
Training loss: 0.11613341157786276
Validation loss: 2.2660684866508505

Epoch: 5| Step: 2
Training loss: 0.07110596358008621
Validation loss: 2.259438760001577

Epoch: 5| Step: 3
Training loss: 0.10664315604954579
Validation loss: 2.296506684622315

Epoch: 5| Step: 4
Training loss: 0.1150601897082861
Validation loss: 2.2842764187964257

Epoch: 5| Step: 5
Training loss: 0.15150048324221474
Validation loss: 2.249615341266446

Epoch: 5| Step: 6
Training loss: 0.10482546874357063
Validation loss: 2.2664400845977264

Epoch: 5| Step: 7
Training loss: 0.0608300041887854
Validation loss: 2.275878421317604

Epoch: 5| Step: 8
Training loss: 0.08269934278171372
Validation loss: 2.2729148217394672

Epoch: 5| Step: 9
Training loss: 0.09526204626435573
Validation loss: 2.247565548752033

Epoch: 5| Step: 10
Training loss: 0.09966250012716056
Validation loss: 2.25739846725168

Epoch: 658| Step: 0
Training loss: 0.20731199770255043
Validation loss: 2.2795481816167005

Epoch: 5| Step: 1
Training loss: 0.12397892220662718
Validation loss: 2.2525068438577835

Epoch: 5| Step: 2
Training loss: 0.0733201597341207
Validation loss: 2.2946438305223715

Epoch: 5| Step: 3
Training loss: 0.0792276296209887
Validation loss: 2.3307794234264945

Epoch: 5| Step: 4
Training loss: 0.21769612055994225
Validation loss: 2.3053628756817566

Epoch: 5| Step: 5
Training loss: 0.20284329650774147
Validation loss: 2.32185504355838

Epoch: 5| Step: 6
Training loss: 0.08610482074604645
Validation loss: 2.315690631768621

Epoch: 5| Step: 7
Training loss: 0.08059256446890145
Validation loss: 2.286456273450075

Epoch: 5| Step: 8
Training loss: 0.08053910341889914
Validation loss: 2.282554398792492

Epoch: 5| Step: 9
Training loss: 0.10273093482519953
Validation loss: 2.271804153482638

Epoch: 5| Step: 10
Training loss: 0.12791685229261063
Validation loss: 2.2892833349663473

Epoch: 659| Step: 0
Training loss: 0.0815592852274984
Validation loss: 2.2968850251733053

Epoch: 5| Step: 1
Training loss: 0.0993871875477959
Validation loss: 2.3043160666382634

Epoch: 5| Step: 2
Training loss: 0.1044614960704965
Validation loss: 2.276734030520048

Epoch: 5| Step: 3
Training loss: 0.08258243003259214
Validation loss: 2.3120100926421894

Epoch: 5| Step: 4
Training loss: 0.07427565375869799
Validation loss: 2.287313633542202

Epoch: 5| Step: 5
Training loss: 0.09901159561799124
Validation loss: 2.289137114480836

Epoch: 5| Step: 6
Training loss: 0.12203496039607367
Validation loss: 2.278900382782441

Epoch: 5| Step: 7
Training loss: 0.12955081067256746
Validation loss: 2.2799676869558687

Epoch: 5| Step: 8
Training loss: 0.10361519109779661
Validation loss: 2.2769923218572936

Epoch: 5| Step: 9
Training loss: 0.09336962623657431
Validation loss: 2.2732101330681402

Epoch: 5| Step: 10
Training loss: 0.18368756149786783
Validation loss: 2.252056762108117

Epoch: 660| Step: 0
Training loss: 0.10057450664714782
Validation loss: 2.303893951958589

Epoch: 5| Step: 1
Training loss: 0.0707799880965799
Validation loss: 2.2650200975114974

Epoch: 5| Step: 2
Training loss: 0.11678088694325381
Validation loss: 2.2555584743119925

Epoch: 5| Step: 3
Training loss: 0.09168097098142479
Validation loss: 2.263275743483653

Epoch: 5| Step: 4
Training loss: 0.07542845574869204
Validation loss: 2.267184134680468

Epoch: 5| Step: 5
Training loss: 0.14406168541295253
Validation loss: 2.256805377543024

Epoch: 5| Step: 6
Training loss: 0.15009699059998358
Validation loss: 2.288265566785654

Epoch: 5| Step: 7
Training loss: 0.1231492237525045
Validation loss: 2.288815980901542

Epoch: 5| Step: 8
Training loss: 0.08797221635151478
Validation loss: 2.2750936405293047

Epoch: 5| Step: 9
Training loss: 0.08283752477158234
Validation loss: 2.2880648710739817

Epoch: 5| Step: 10
Training loss: 0.1435242575228061
Validation loss: 2.2960386329356752

Epoch: 661| Step: 0
Training loss: 0.08043270576931347
Validation loss: 2.2787515362717783

Epoch: 5| Step: 1
Training loss: 0.12947519055606793
Validation loss: 2.3110494445965175

Epoch: 5| Step: 2
Training loss: 0.06735008592185046
Validation loss: 2.3071208023837877

Epoch: 5| Step: 3
Training loss: 0.08521905964685662
Validation loss: 2.2790380270592845

Epoch: 5| Step: 4
Training loss: 0.18200231248439708
Validation loss: 2.2645855559855605

Epoch: 5| Step: 5
Training loss: 0.12920439083389476
Validation loss: 2.277956385975214

Epoch: 5| Step: 6
Training loss: 0.13134708900754605
Validation loss: 2.251680151318041

Epoch: 5| Step: 7
Training loss: 0.10950901132240255
Validation loss: 2.2362068297775712

Epoch: 5| Step: 8
Training loss: 0.07522899319264192
Validation loss: 2.2295256739514593

Epoch: 5| Step: 9
Training loss: 0.11177135376158776
Validation loss: 2.218099653343951

Epoch: 5| Step: 10
Training loss: 0.08817481612985885
Validation loss: 2.2074011649937577

Epoch: 662| Step: 0
Training loss: 0.12252938731859
Validation loss: 2.2188716510178006

Epoch: 5| Step: 1
Training loss: 0.1022996787556189
Validation loss: 2.2224297612022244

Epoch: 5| Step: 2
Training loss: 0.10883756990928854
Validation loss: 2.2136945218338258

Epoch: 5| Step: 3
Training loss: 0.14270640181071964
Validation loss: 2.2404111148456543

Epoch: 5| Step: 4
Training loss: 0.09567860853730427
Validation loss: 2.2251955370897596

Epoch: 5| Step: 5
Training loss: 0.08074121583982347
Validation loss: 2.2295300146657606

Epoch: 5| Step: 6
Training loss: 0.08358692225977786
Validation loss: 2.25307209978589

Epoch: 5| Step: 7
Training loss: 0.13102482542194832
Validation loss: 2.2598676310088797

Epoch: 5| Step: 8
Training loss: 0.07650478070372638
Validation loss: 2.2599671050369423

Epoch: 5| Step: 9
Training loss: 0.06406140864419582
Validation loss: 2.2342727463335916

Epoch: 5| Step: 10
Training loss: 0.10271796559596291
Validation loss: 2.242711705126221

Epoch: 663| Step: 0
Training loss: 0.09363320645379561
Validation loss: 2.242444113782443

Epoch: 5| Step: 1
Training loss: 0.08580260635439019
Validation loss: 2.278885450195855

Epoch: 5| Step: 2
Training loss: 0.11806485054373171
Validation loss: 2.250085684068854

Epoch: 5| Step: 3
Training loss: 0.1323930202543436
Validation loss: 2.255387775070922

Epoch: 5| Step: 4
Training loss: 0.09132141390470869
Validation loss: 2.2787231259692464

Epoch: 5| Step: 5
Training loss: 0.10083608170709829
Validation loss: 2.2947996824640646

Epoch: 5| Step: 6
Training loss: 0.1336850088858474
Validation loss: 2.292621054347615

Epoch: 5| Step: 7
Training loss: 0.07529225850048601
Validation loss: 2.264528241462721

Epoch: 5| Step: 8
Training loss: 0.1010088732396188
Validation loss: 2.247206985074951

Epoch: 5| Step: 9
Training loss: 0.11481447008786114
Validation loss: 2.2282792840757715

Epoch: 5| Step: 10
Training loss: 0.06325646168087572
Validation loss: 2.2116924199923207

Epoch: 664| Step: 0
Training loss: 0.07150554447751267
Validation loss: 2.191895035932498

Epoch: 5| Step: 1
Training loss: 0.10993918869511835
Validation loss: 2.1817939895274754

Epoch: 5| Step: 2
Training loss: 0.0910926090106861
Validation loss: 2.2083031572387988

Epoch: 5| Step: 3
Training loss: 0.08678221882278304
Validation loss: 2.19475830355839

Epoch: 5| Step: 4
Training loss: 0.10140468183283588
Validation loss: 2.1645819919808673

Epoch: 5| Step: 5
Training loss: 0.09223473902434527
Validation loss: 2.198036972817833

Epoch: 5| Step: 6
Training loss: 0.0811294704753573
Validation loss: 2.201719178946934

Epoch: 5| Step: 7
Training loss: 0.07209354610232394
Validation loss: 2.2255945755415576

Epoch: 5| Step: 8
Training loss: 0.12731578086797982
Validation loss: 2.2372449793136835

Epoch: 5| Step: 9
Training loss: 0.11570649496936639
Validation loss: 2.2722236221041325

Epoch: 5| Step: 10
Training loss: 0.14056901347095918
Validation loss: 2.2442563293245907

Epoch: 665| Step: 0
Training loss: 0.08192158646289915
Validation loss: 2.2783296159054

Epoch: 5| Step: 1
Training loss: 0.1030173364633374
Validation loss: 2.2902061491879695

Epoch: 5| Step: 2
Training loss: 0.11073663923032569
Validation loss: 2.2953657881922696

Epoch: 5| Step: 3
Training loss: 0.07807660093780056
Validation loss: 2.248280270198564

Epoch: 5| Step: 4
Training loss: 0.08805508062548892
Validation loss: 2.25842997271503

Epoch: 5| Step: 5
Training loss: 0.15075096705823987
Validation loss: 2.243093088125701

Epoch: 5| Step: 6
Training loss: 0.069500650278701
Validation loss: 2.299771503130434

Epoch: 5| Step: 7
Training loss: 0.13695488700668942
Validation loss: 2.3142862557735757

Epoch: 5| Step: 8
Training loss: 0.16000399679541485
Validation loss: 2.2981488276508566

Epoch: 5| Step: 9
Training loss: 0.14603118729870637
Validation loss: 2.2958591590228163

Epoch: 5| Step: 10
Training loss: 0.06807937498523248
Validation loss: 2.2814078147873023

Epoch: 666| Step: 0
Training loss: 0.07529026390293564
Validation loss: 2.29548680194661

Epoch: 5| Step: 1
Training loss: 0.11225076292995743
Validation loss: 2.311830338860573

Epoch: 5| Step: 2
Training loss: 0.07473415617837997
Validation loss: 2.316119730939123

Epoch: 5| Step: 3
Training loss: 0.13126567849111723
Validation loss: 2.3228169066686046

Epoch: 5| Step: 4
Training loss: 0.14215024339493715
Validation loss: 2.322777074056138

Epoch: 5| Step: 5
Training loss: 0.11155572013128588
Validation loss: 2.308589134852302

Epoch: 5| Step: 6
Training loss: 0.1103533558995177
Validation loss: 2.326639784526495

Epoch: 5| Step: 7
Training loss: 0.08216381714463133
Validation loss: 2.3370079896284564

Epoch: 5| Step: 8
Training loss: 0.10450490089866855
Validation loss: 2.3331068701064797

Epoch: 5| Step: 9
Training loss: 0.13213595408880546
Validation loss: 2.3395855697656067

Epoch: 5| Step: 10
Training loss: 0.11463170132501119
Validation loss: 2.3386198901761652

Epoch: 667| Step: 0
Training loss: 0.09538369490235386
Validation loss: 2.3369006689487715

Epoch: 5| Step: 1
Training loss: 0.07246980304413521
Validation loss: 2.3266833914877796

Epoch: 5| Step: 2
Training loss: 0.07051053240065831
Validation loss: 2.24596601938924

Epoch: 5| Step: 3
Training loss: 0.1411715060695267
Validation loss: 2.281554669960035

Epoch: 5| Step: 4
Training loss: 0.12389648503047726
Validation loss: 2.233871645931213

Epoch: 5| Step: 5
Training loss: 0.1142510224631528
Validation loss: 2.2308597807035677

Epoch: 5| Step: 6
Training loss: 0.08931062959550438
Validation loss: 2.2813855410620234

Epoch: 5| Step: 7
Training loss: 0.1512763581480854
Validation loss: 2.248718512056647

Epoch: 5| Step: 8
Training loss: 0.10692076410120357
Validation loss: 2.280798644465602

Epoch: 5| Step: 9
Training loss: 0.07020892355715126
Validation loss: 2.307931682416219

Epoch: 5| Step: 10
Training loss: 0.1399961557456556
Validation loss: 2.3159869333166005

Epoch: 668| Step: 0
Training loss: 0.1230489034334139
Validation loss: 2.3216104041151024

Epoch: 5| Step: 1
Training loss: 0.15651383179373024
Validation loss: 2.3330434514383778

Epoch: 5| Step: 2
Training loss: 0.1027246385391706
Validation loss: 2.2887284661166674

Epoch: 5| Step: 3
Training loss: 0.06902978358431613
Validation loss: 2.2778281455478404

Epoch: 5| Step: 4
Training loss: 0.15922236894232683
Validation loss: 2.267378654333174

Epoch: 5| Step: 5
Training loss: 0.12975281110696962
Validation loss: 2.2493092263875054

Epoch: 5| Step: 6
Training loss: 0.09672096122808481
Validation loss: 2.2330521048423266

Epoch: 5| Step: 7
Training loss: 0.14458620470046732
Validation loss: 2.232965657226273

Epoch: 5| Step: 8
Training loss: 0.0792559394737314
Validation loss: 2.230246497306359

Epoch: 5| Step: 9
Training loss: 0.13407038605443855
Validation loss: 2.2551017055290847

Epoch: 5| Step: 10
Training loss: 0.08831593867931567
Validation loss: 2.286556220404367

Epoch: 669| Step: 0
Training loss: 0.11739777931348226
Validation loss: 2.279375655672867

Epoch: 5| Step: 1
Training loss: 0.11312017416671653
Validation loss: 2.2919240518006725

Epoch: 5| Step: 2
Training loss: 0.12715630045543166
Validation loss: 2.356700835307121

Epoch: 5| Step: 3
Training loss: 0.10936787701300903
Validation loss: 2.3286399302134146

Epoch: 5| Step: 4
Training loss: 0.1145268638858665
Validation loss: 2.3521140214983203

Epoch: 5| Step: 5
Training loss: 0.06726949257536924
Validation loss: 2.2923921976633177

Epoch: 5| Step: 6
Training loss: 0.10248818724879084
Validation loss: 2.298014002556528

Epoch: 5| Step: 7
Training loss: 0.08974826963690542
Validation loss: 2.2858785843159186

Epoch: 5| Step: 8
Training loss: 0.10473907129212194
Validation loss: 2.2886266397358943

Epoch: 5| Step: 9
Training loss: 0.07945635196392989
Validation loss: 2.2352440725318186

Epoch: 5| Step: 10
Training loss: 0.0970559984625429
Validation loss: 2.277374390356394

Epoch: 670| Step: 0
Training loss: 0.10814826035714131
Validation loss: 2.246835326569981

Epoch: 5| Step: 1
Training loss: 0.1288484602771958
Validation loss: 2.2539340233784877

Epoch: 5| Step: 2
Training loss: 0.06562383869256232
Validation loss: 2.290810344673523

Epoch: 5| Step: 3
Training loss: 0.07205873592824036
Validation loss: 2.3206963714460964

Epoch: 5| Step: 4
Training loss: 0.11038280989891047
Validation loss: 2.301175683339802

Epoch: 5| Step: 5
Training loss: 0.1547307421228812
Validation loss: 2.2831219712831605

Epoch: 5| Step: 6
Training loss: 0.08518854981053332
Validation loss: 2.2847270059342764

Epoch: 5| Step: 7
Training loss: 0.12486422884035707
Validation loss: 2.310469140536982

Epoch: 5| Step: 8
Training loss: 0.0994841124601691
Validation loss: 2.286205746376084

Epoch: 5| Step: 9
Training loss: 0.058464420162615466
Validation loss: 2.291558959719421

Epoch: 5| Step: 10
Training loss: 0.09823981921183475
Validation loss: 2.2973877791537824

Epoch: 671| Step: 0
Training loss: 0.10080688708638146
Validation loss: 2.297614515340825

Epoch: 5| Step: 1
Training loss: 0.10750840343437401
Validation loss: 2.343336752279009

Epoch: 5| Step: 2
Training loss: 0.12452104196985189
Validation loss: 2.34222590507003

Epoch: 5| Step: 3
Training loss: 0.12656293474523028
Validation loss: 2.316788676193193

Epoch: 5| Step: 4
Training loss: 0.14720129687444808
Validation loss: 2.3390186619138484

Epoch: 5| Step: 5
Training loss: 0.09981947134302005
Validation loss: 2.339549251382627

Epoch: 5| Step: 6
Training loss: 0.07558193762987003
Validation loss: 2.2940901710448425

Epoch: 5| Step: 7
Training loss: 0.1461196555154733
Validation loss: 2.3128718437774864

Epoch: 5| Step: 8
Training loss: 0.0866655536679103
Validation loss: 2.27935247074646

Epoch: 5| Step: 9
Training loss: 0.08505173468279854
Validation loss: 2.2609063072736477

Epoch: 5| Step: 10
Training loss: 0.09564843853569825
Validation loss: 2.2885741375361386

Epoch: 672| Step: 0
Training loss: 0.08821244924150438
Validation loss: 2.2944011289239663

Epoch: 5| Step: 1
Training loss: 0.0855143190080661
Validation loss: 2.2629761863448707

Epoch: 5| Step: 2
Training loss: 0.1182534612644054
Validation loss: 2.2365386552842335

Epoch: 5| Step: 3
Training loss: 0.09963064340656004
Validation loss: 2.2502188752703876

Epoch: 5| Step: 4
Training loss: 0.13441320308730945
Validation loss: 2.2521369930952595

Epoch: 5| Step: 5
Training loss: 0.10724041958680929
Validation loss: 2.2630403111125355

Epoch: 5| Step: 6
Training loss: 0.08808158157472722
Validation loss: 2.2211630234954156

Epoch: 5| Step: 7
Training loss: 0.14722305967759516
Validation loss: 2.236284472271472

Epoch: 5| Step: 8
Training loss: 0.08487935918075933
Validation loss: 2.245712562662368

Epoch: 5| Step: 9
Training loss: 0.09597753091120954
Validation loss: 2.22851606904678

Epoch: 5| Step: 10
Training loss: 0.07180673944494223
Validation loss: 2.2678794193256877

Epoch: 673| Step: 0
Training loss: 0.10821053827278358
Validation loss: 2.2484225060721386

Epoch: 5| Step: 1
Training loss: 0.09204192629092964
Validation loss: 2.220247063166796

Epoch: 5| Step: 2
Training loss: 0.08879965532270598
Validation loss: 2.2382755208956393

Epoch: 5| Step: 3
Training loss: 0.09464738919240019
Validation loss: 2.252849492708857

Epoch: 5| Step: 4
Training loss: 0.12529364754425304
Validation loss: 2.215162975436178

Epoch: 5| Step: 5
Training loss: 0.1672917573498266
Validation loss: 2.206862799549988

Epoch: 5| Step: 6
Training loss: 0.13348713798034484
Validation loss: 2.242788662348303

Epoch: 5| Step: 7
Training loss: 0.08560203511416703
Validation loss: 2.2442605433091085

Epoch: 5| Step: 8
Training loss: 0.13467683493215862
Validation loss: 2.2528011097699583

Epoch: 5| Step: 9
Training loss: 0.09675504656624138
Validation loss: 2.25398495703182

Epoch: 5| Step: 10
Training loss: 0.07436932798603912
Validation loss: 2.2730224871079745

Epoch: 674| Step: 0
Training loss: 0.15678118775054567
Validation loss: 2.2874560552919707

Epoch: 5| Step: 1
Training loss: 0.11323087081735148
Validation loss: 2.2747701219317085

Epoch: 5| Step: 2
Training loss: 0.060439362361764
Validation loss: 2.2931656302665244

Epoch: 5| Step: 3
Training loss: 0.1288935481662684
Validation loss: 2.284003993422161

Epoch: 5| Step: 4
Training loss: 0.08731392698446232
Validation loss: 2.2578983562359927

Epoch: 5| Step: 5
Training loss: 0.11018324987790809
Validation loss: 2.247514916757771

Epoch: 5| Step: 6
Training loss: 0.12167199571279454
Validation loss: 2.242291864006706

Epoch: 5| Step: 7
Training loss: 0.104799696063748
Validation loss: 2.2467610108256673

Epoch: 5| Step: 8
Training loss: 0.08384968247576721
Validation loss: 2.26113302904177

Epoch: 5| Step: 9
Training loss: 0.07965552363975541
Validation loss: 2.2672444881804568

Epoch: 5| Step: 10
Training loss: 0.11758042266729829
Validation loss: 2.269714527673256

Epoch: 675| Step: 0
Training loss: 0.10742692935496959
Validation loss: 2.2696029496159102

Epoch: 5| Step: 1
Training loss: 0.08247101503068158
Validation loss: 2.2715711776931524

Epoch: 5| Step: 2
Training loss: 0.10684333109682878
Validation loss: 2.2745671004757995

Epoch: 5| Step: 3
Training loss: 0.12313826134350205
Validation loss: 2.285463634817525

Epoch: 5| Step: 4
Training loss: 0.10860999400956192
Validation loss: 2.3009335275474494

Epoch: 5| Step: 5
Training loss: 0.10831850988578144
Validation loss: 2.284336474459224

Epoch: 5| Step: 6
Training loss: 0.13752887352231755
Validation loss: 2.2827608794674066

Epoch: 5| Step: 7
Training loss: 0.10807955292545282
Validation loss: 2.2864025295187376

Epoch: 5| Step: 8
Training loss: 0.10486464209836131
Validation loss: 2.3040868967609707

Epoch: 5| Step: 9
Training loss: 0.08421976348076057
Validation loss: 2.2847080169388065

Epoch: 5| Step: 10
Training loss: 0.0845218278292813
Validation loss: 2.296170040902606

Epoch: 676| Step: 0
Training loss: 0.07971991108946393
Validation loss: 2.254649773309381

Epoch: 5| Step: 1
Training loss: 0.0998983492383614
Validation loss: 2.2851298941147706

Epoch: 5| Step: 2
Training loss: 0.1015233734764728
Validation loss: 2.2878334525457342

Epoch: 5| Step: 3
Training loss: 0.07666310529442692
Validation loss: 2.2753025460917966

Epoch: 5| Step: 4
Training loss: 0.16818529409254082
Validation loss: 2.274244680442939

Epoch: 5| Step: 5
Training loss: 0.1047377864140356
Validation loss: 2.261999968942112

Epoch: 5| Step: 6
Training loss: 0.06119793357578342
Validation loss: 2.292831485829145

Epoch: 5| Step: 7
Training loss: 0.08955663955146384
Validation loss: 2.2771446788165104

Epoch: 5| Step: 8
Training loss: 0.08915466404489364
Validation loss: 2.2563809992163755

Epoch: 5| Step: 9
Training loss: 0.10493521047477855
Validation loss: 2.23864059543053

Epoch: 5| Step: 10
Training loss: 0.06401927830334644
Validation loss: 2.2679856050216487

Epoch: 677| Step: 0
Training loss: 0.12494928478561576
Validation loss: 2.2695349460166683

Epoch: 5| Step: 1
Training loss: 0.08864805430952005
Validation loss: 2.248247400325949

Epoch: 5| Step: 2
Training loss: 0.08060128006289878
Validation loss: 2.269962087679819

Epoch: 5| Step: 3
Training loss: 0.09057889661777785
Validation loss: 2.273858257002819

Epoch: 5| Step: 4
Training loss: 0.0697619086789024
Validation loss: 2.2621009006915562

Epoch: 5| Step: 5
Training loss: 0.13486744310060578
Validation loss: 2.2722482968393707

Epoch: 5| Step: 6
Training loss: 0.09343163255781245
Validation loss: 2.2677668545159526

Epoch: 5| Step: 7
Training loss: 0.058337497651237226
Validation loss: 2.241869172351806

Epoch: 5| Step: 8
Training loss: 0.13609560234920226
Validation loss: 2.255055426891004

Epoch: 5| Step: 9
Training loss: 0.11135899801660142
Validation loss: 2.2565085220156176

Epoch: 5| Step: 10
Training loss: 0.11173523117754157
Validation loss: 2.2444924670336146

Epoch: 678| Step: 0
Training loss: 0.11622922016230203
Validation loss: 2.2581489576429687

Epoch: 5| Step: 1
Training loss: 0.10642444336026259
Validation loss: 2.231268814957555

Epoch: 5| Step: 2
Training loss: 0.078551016014682
Validation loss: 2.248851304585119

Epoch: 5| Step: 3
Training loss: 0.10498713982256087
Validation loss: 2.2196005445062017

Epoch: 5| Step: 4
Training loss: 0.0874989417982827
Validation loss: 2.2287770945708956

Epoch: 5| Step: 5
Training loss: 0.08549580530248772
Validation loss: 2.2367714490080717

Epoch: 5| Step: 6
Training loss: 0.07533907152983575
Validation loss: 2.213873099041598

Epoch: 5| Step: 7
Training loss: 0.11644521307597096
Validation loss: 2.2422761794173685

Epoch: 5| Step: 8
Training loss: 0.07162884837463042
Validation loss: 2.2566869205013034

Epoch: 5| Step: 9
Training loss: 0.08504610615981459
Validation loss: 2.2650708809109488

Epoch: 5| Step: 10
Training loss: 0.13555721331480142
Validation loss: 2.2747928143031473

Epoch: 679| Step: 0
Training loss: 0.1110552740198964
Validation loss: 2.2400235053785233

Epoch: 5| Step: 1
Training loss: 0.10305612623060499
Validation loss: 2.265653178513978

Epoch: 5| Step: 2
Training loss: 0.0723665730889813
Validation loss: 2.2367159868782998

Epoch: 5| Step: 3
Training loss: 0.10845453082554209
Validation loss: 2.2314796818310323

Epoch: 5| Step: 4
Training loss: 0.09855619608555691
Validation loss: 2.214897443757824

Epoch: 5| Step: 5
Training loss: 0.061452497349003966
Validation loss: 2.235299904927342

Epoch: 5| Step: 6
Training loss: 0.09543312678656732
Validation loss: 2.2390206624366065

Epoch: 5| Step: 7
Training loss: 0.08777741717716223
Validation loss: 2.2210490759179997

Epoch: 5| Step: 8
Training loss: 0.08785114196211938
Validation loss: 2.2332380606068103

Epoch: 5| Step: 9
Training loss: 0.0664689315157637
Validation loss: 2.218044418391177

Epoch: 5| Step: 10
Training loss: 0.06427468176991638
Validation loss: 2.2436993946085306

Epoch: 680| Step: 0
Training loss: 0.08647051693296989
Validation loss: 2.230646330259726

Epoch: 5| Step: 1
Training loss: 0.04795791038315772
Validation loss: 2.2435775483530294

Epoch: 5| Step: 2
Training loss: 0.05561384437103382
Validation loss: 2.2535105587704307

Epoch: 5| Step: 3
Training loss: 0.10888666315462207
Validation loss: 2.250692406856988

Epoch: 5| Step: 4
Training loss: 0.06398007524573018
Validation loss: 2.30732558767688

Epoch: 5| Step: 5
Training loss: 0.08723519501632923
Validation loss: 2.2867482889360096

Epoch: 5| Step: 6
Training loss: 0.10364412932536717
Validation loss: 2.2396632160001904

Epoch: 5| Step: 7
Training loss: 0.10964314764979731
Validation loss: 2.2809475181122245

Epoch: 5| Step: 8
Training loss: 0.07159256668936187
Validation loss: 2.298468531939938

Epoch: 5| Step: 9
Training loss: 0.1480081522684232
Validation loss: 2.316428041448145

Epoch: 5| Step: 10
Training loss: 0.12138657005957706
Validation loss: 2.310569354139974

Epoch: 681| Step: 0
Training loss: 0.12014611213835401
Validation loss: 2.3140617023347634

Epoch: 5| Step: 1
Training loss: 0.14503123175175622
Validation loss: 2.3310257345874543

Epoch: 5| Step: 2
Training loss: 0.06974986258723112
Validation loss: 2.3183261200531575

Epoch: 5| Step: 3
Training loss: 0.054372557545483306
Validation loss: 2.2964179956025252

Epoch: 5| Step: 4
Training loss: 0.10913373529455186
Validation loss: 2.2879042301157484

Epoch: 5| Step: 5
Training loss: 0.12181677619617355
Validation loss: 2.2829717456429033

Epoch: 5| Step: 6
Training loss: 0.10083007350672234
Validation loss: 2.2859611429429227

Epoch: 5| Step: 7
Training loss: 0.07447258933019545
Validation loss: 2.283552192327613

Epoch: 5| Step: 8
Training loss: 0.09148764776277082
Validation loss: 2.26315695960715

Epoch: 5| Step: 9
Training loss: 0.10094214762330583
Validation loss: 2.264108928944701

Epoch: 5| Step: 10
Training loss: 0.06627702059644243
Validation loss: 2.2534031397727414

Epoch: 682| Step: 0
Training loss: 0.07563882241842478
Validation loss: 2.2531927943080468

Epoch: 5| Step: 1
Training loss: 0.07849629802444733
Validation loss: 2.28120503681198

Epoch: 5| Step: 2
Training loss: 0.0793287288409114
Validation loss: 2.2630476252195506

Epoch: 5| Step: 3
Training loss: 0.11691245544736191
Validation loss: 2.259088833844104

Epoch: 5| Step: 4
Training loss: 0.07143537647803239
Validation loss: 2.2708496242938705

Epoch: 5| Step: 5
Training loss: 0.13912587329131146
Validation loss: 2.2722722289329114

Epoch: 5| Step: 6
Training loss: 0.11429965646844212
Validation loss: 2.2638108800600687

Epoch: 5| Step: 7
Training loss: 0.07944657296384885
Validation loss: 2.2562696486107168

Epoch: 5| Step: 8
Training loss: 0.13075851710005976
Validation loss: 2.2236744597029694

Epoch: 5| Step: 9
Training loss: 0.055311790713649465
Validation loss: 2.2504277910753876

Epoch: 5| Step: 10
Training loss: 0.06365932416960211
Validation loss: 2.225728150483027

Epoch: 683| Step: 0
Training loss: 0.04177698448654436
Validation loss: 2.223528204674564

Epoch: 5| Step: 1
Training loss: 0.06612835265757179
Validation loss: 2.2287894090642952

Epoch: 5| Step: 2
Training loss: 0.06359970911912782
Validation loss: 2.239360606132993

Epoch: 5| Step: 3
Training loss: 0.14332710443405955
Validation loss: 2.2160989237682887

Epoch: 5| Step: 4
Training loss: 0.07098486744669766
Validation loss: 2.2474642494024044

Epoch: 5| Step: 5
Training loss: 0.11232694322402437
Validation loss: 2.2328211186267195

Epoch: 5| Step: 6
Training loss: 0.07455414355448443
Validation loss: 2.251020137304686

Epoch: 5| Step: 7
Training loss: 0.05891663873002486
Validation loss: 2.2554876461520688

Epoch: 5| Step: 8
Training loss: 0.08209071955552875
Validation loss: 2.2605471829707002

Epoch: 5| Step: 9
Training loss: 0.12749381467597937
Validation loss: 2.2733879494138085

Epoch: 5| Step: 10
Training loss: 0.1029697184741447
Validation loss: 2.265056769966584

Epoch: 684| Step: 0
Training loss: 0.09300908227604096
Validation loss: 2.295357275342048

Epoch: 5| Step: 1
Training loss: 0.0910391069171679
Validation loss: 2.291735656087645

Epoch: 5| Step: 2
Training loss: 0.05313669051539978
Validation loss: 2.28232515076252

Epoch: 5| Step: 3
Training loss: 0.08875989200643061
Validation loss: 2.2447664483906067

Epoch: 5| Step: 4
Training loss: 0.08114953983021286
Validation loss: 2.254003533806177

Epoch: 5| Step: 5
Training loss: 0.08124969188925205
Validation loss: 2.254754525792167

Epoch: 5| Step: 6
Training loss: 0.09293941407615208
Validation loss: 2.2479118333050434

Epoch: 5| Step: 7
Training loss: 0.12055583272225237
Validation loss: 2.27096818077828

Epoch: 5| Step: 8
Training loss: 0.07182613971846928
Validation loss: 2.259025620538748

Epoch: 5| Step: 9
Training loss: 0.13411607942086207
Validation loss: 2.2779827767459224

Epoch: 5| Step: 10
Training loss: 0.08799503535471863
Validation loss: 2.257331600780789

Epoch: 685| Step: 0
Training loss: 0.09745677602747445
Validation loss: 2.2703633751137526

Epoch: 5| Step: 1
Training loss: 0.11464412703851132
Validation loss: 2.2609178956973097

Epoch: 5| Step: 2
Training loss: 0.10373928541129904
Validation loss: 2.2671026076959433

Epoch: 5| Step: 3
Training loss: 0.08861020418121203
Validation loss: 2.3105230087043336

Epoch: 5| Step: 4
Training loss: 0.06106795002185249
Validation loss: 2.276489165011704

Epoch: 5| Step: 5
Training loss: 0.07458772357625394
Validation loss: 2.320609324980844

Epoch: 5| Step: 6
Training loss: 0.05436281909788671
Validation loss: 2.300163523874142

Epoch: 5| Step: 7
Training loss: 0.06953293056278712
Validation loss: 2.3328464478195254

Epoch: 5| Step: 8
Training loss: 0.100061498484761
Validation loss: 2.3179014259383504

Epoch: 5| Step: 9
Training loss: 0.07976019070670809
Validation loss: 2.303098919413679

Epoch: 5| Step: 10
Training loss: 0.12468271668181624
Validation loss: 2.345650332517669

Epoch: 686| Step: 0
Training loss: 0.05584081394757708
Validation loss: 2.3199700427746754

Epoch: 5| Step: 1
Training loss: 0.07424081925989232
Validation loss: 2.31820754707462

Epoch: 5| Step: 2
Training loss: 0.1019388844786625
Validation loss: 2.3069052427614234

Epoch: 5| Step: 3
Training loss: 0.107001740153481
Validation loss: 2.2906187795879056

Epoch: 5| Step: 4
Training loss: 0.08258646163705542
Validation loss: 2.271648698253487

Epoch: 5| Step: 5
Training loss: 0.13579872381066443
Validation loss: 2.269715670726111

Epoch: 5| Step: 6
Training loss: 0.07638471163300296
Validation loss: 2.243445057878517

Epoch: 5| Step: 7
Training loss: 0.10372305725603988
Validation loss: 2.264202878658832

Epoch: 5| Step: 8
Training loss: 0.06288427074981823
Validation loss: 2.2530412663255235

Epoch: 5| Step: 9
Training loss: 0.09091365283592835
Validation loss: 2.269699149490198

Epoch: 5| Step: 10
Training loss: 0.09462699868530368
Validation loss: 2.2659733183097193

Epoch: 687| Step: 0
Training loss: 0.06470612519260567
Validation loss: 2.260263493281995

Epoch: 5| Step: 1
Training loss: 0.08457598127611395
Validation loss: 2.287042177782311

Epoch: 5| Step: 2
Training loss: 0.0674640193825011
Validation loss: 2.2711661080771233

Epoch: 5| Step: 3
Training loss: 0.11442797778403187
Validation loss: 2.28760306459401

Epoch: 5| Step: 4
Training loss: 0.08480647175272332
Validation loss: 2.2885039396772804

Epoch: 5| Step: 5
Training loss: 0.07363466961185755
Validation loss: 2.271501157503918

Epoch: 5| Step: 6
Training loss: 0.07881003393868623
Validation loss: 2.2634419946470636

Epoch: 5| Step: 7
Training loss: 0.06695694343868698
Validation loss: 2.2601643504617868

Epoch: 5| Step: 8
Training loss: 0.12721650605927276
Validation loss: 2.273004828207732

Epoch: 5| Step: 9
Training loss: 0.06379647700661864
Validation loss: 2.2541252304683543

Epoch: 5| Step: 10
Training loss: 0.15285687960611893
Validation loss: 2.250401757261481

Epoch: 688| Step: 0
Training loss: 0.09597261593831909
Validation loss: 2.2532921158756887

Epoch: 5| Step: 1
Training loss: 0.11039967458662331
Validation loss: 2.2585271604195403

Epoch: 5| Step: 2
Training loss: 0.06728723215518971
Validation loss: 2.2740250861941997

Epoch: 5| Step: 3
Training loss: 0.13178033009208717
Validation loss: 2.2950771791529414

Epoch: 5| Step: 4
Training loss: 0.08347109928024152
Validation loss: 2.255479825599381

Epoch: 5| Step: 5
Training loss: 0.08129548303635765
Validation loss: 2.229426442630186

Epoch: 5| Step: 6
Training loss: 0.06897601883803935
Validation loss: 2.245088669019147

Epoch: 5| Step: 7
Training loss: 0.0733865142423875
Validation loss: 2.248034333002467

Epoch: 5| Step: 8
Training loss: 0.0897420950778111
Validation loss: 2.237294072216654

Epoch: 5| Step: 9
Training loss: 0.07722109680727662
Validation loss: 2.2428666079280957

Epoch: 5| Step: 10
Training loss: 0.11356005395806876
Validation loss: 2.237300298847297

Epoch: 689| Step: 0
Training loss: 0.11404015929767514
Validation loss: 2.2031028634155376

Epoch: 5| Step: 1
Training loss: 0.07478010119680806
Validation loss: 2.211563782878468

Epoch: 5| Step: 2
Training loss: 0.10570280278023542
Validation loss: 2.1935722656770493

Epoch: 5| Step: 3
Training loss: 0.07383275988829624
Validation loss: 2.210991777349293

Epoch: 5| Step: 4
Training loss: 0.07151335548311094
Validation loss: 2.2304498226192475

Epoch: 5| Step: 5
Training loss: 0.07931711415451882
Validation loss: 2.2133507980101985

Epoch: 5| Step: 6
Training loss: 0.06797707468332445
Validation loss: 2.2495225379262873

Epoch: 5| Step: 7
Training loss: 0.08536380040667202
Validation loss: 2.23741533599658

Epoch: 5| Step: 8
Training loss: 0.10597381370992522
Validation loss: 2.2552541681570375

Epoch: 5| Step: 9
Training loss: 0.08547720859416942
Validation loss: 2.2548522976998373

Epoch: 5| Step: 10
Training loss: 0.06251232577020072
Validation loss: 2.2493031925654017

Epoch: 690| Step: 0
Training loss: 0.07182608461147794
Validation loss: 2.2660472664481817

Epoch: 5| Step: 1
Training loss: 0.06687049016051161
Validation loss: 2.2680639935808506

Epoch: 5| Step: 2
Training loss: 0.07933355091643064
Validation loss: 2.2772482333076427

Epoch: 5| Step: 3
Training loss: 0.11412605611734478
Validation loss: 2.275649218648451

Epoch: 5| Step: 4
Training loss: 0.10649659732466854
Validation loss: 2.2784552160364098

Epoch: 5| Step: 5
Training loss: 0.08828388026631792
Validation loss: 2.295179035455222

Epoch: 5| Step: 6
Training loss: 0.04756938197071106
Validation loss: 2.306482265917555

Epoch: 5| Step: 7
Training loss: 0.055619527334588977
Validation loss: 2.256308498811008

Epoch: 5| Step: 8
Training loss: 0.0952462706908988
Validation loss: 2.284985865756599

Epoch: 5| Step: 9
Training loss: 0.0648201944182995
Validation loss: 2.275199152061318

Epoch: 5| Step: 10
Training loss: 0.13473590578423753
Validation loss: 2.295860513502755

Epoch: 691| Step: 0
Training loss: 0.11666452618392284
Validation loss: 2.2946054718497613

Epoch: 5| Step: 1
Training loss: 0.06584305214794972
Validation loss: 2.2858693245319897

Epoch: 5| Step: 2
Training loss: 0.0868107900100933
Validation loss: 2.2824195597920354

Epoch: 5| Step: 3
Training loss: 0.07536719234755596
Validation loss: 2.2821853019446516

Epoch: 5| Step: 4
Training loss: 0.12078295709580579
Validation loss: 2.2979891403911092

Epoch: 5| Step: 5
Training loss: 0.06445337786769392
Validation loss: 2.2944013537899

Epoch: 5| Step: 6
Training loss: 0.09457722917085554
Validation loss: 2.2711081536560895

Epoch: 5| Step: 7
Training loss: 0.12156507458081105
Validation loss: 2.279917506643561

Epoch: 5| Step: 8
Training loss: 0.08826792055117226
Validation loss: 2.2770791073875984

Epoch: 5| Step: 9
Training loss: 0.08756800088971789
Validation loss: 2.2775179882984187

Epoch: 5| Step: 10
Training loss: 0.06513467510969424
Validation loss: 2.260877655718373

Epoch: 692| Step: 0
Training loss: 0.08746306744750977
Validation loss: 2.2666819855439573

Epoch: 5| Step: 1
Training loss: 0.07954096316996813
Validation loss: 2.2387195070697583

Epoch: 5| Step: 2
Training loss: 0.06716134122123629
Validation loss: 2.244343049681358

Epoch: 5| Step: 3
Training loss: 0.07058964851495518
Validation loss: 2.248940364159781

Epoch: 5| Step: 4
Training loss: 0.13056671810184234
Validation loss: 2.2431033365247464

Epoch: 5| Step: 5
Training loss: 0.1315225408334873
Validation loss: 2.2493868286274767

Epoch: 5| Step: 6
Training loss: 0.07342145597432079
Validation loss: 2.2737567089585515

Epoch: 5| Step: 7
Training loss: 0.06427697835057412
Validation loss: 2.2622925892574677

Epoch: 5| Step: 8
Training loss: 0.11719514901311459
Validation loss: 2.2698407739299906

Epoch: 5| Step: 9
Training loss: 0.08922206843262566
Validation loss: 2.264563029065082

Epoch: 5| Step: 10
Training loss: 0.13396144815366415
Validation loss: 2.2690581610045664

Epoch: 693| Step: 0
Training loss: 0.10240616587727654
Validation loss: 2.2820958558317916

Epoch: 5| Step: 1
Training loss: 0.09277576644383503
Validation loss: 2.2811892983629805

Epoch: 5| Step: 2
Training loss: 0.12101822081946968
Validation loss: 2.3017637912372

Epoch: 5| Step: 3
Training loss: 0.12781672550015935
Validation loss: 2.286086231833726

Epoch: 5| Step: 4
Training loss: 0.057392885957975995
Validation loss: 2.269020474219514

Epoch: 5| Step: 5
Training loss: 0.07112200314458998
Validation loss: 2.2497515814723505

Epoch: 5| Step: 6
Training loss: 0.09053677732990838
Validation loss: 2.2615672321514895

Epoch: 5| Step: 7
Training loss: 0.09973456892633865
Validation loss: 2.2891843195615555

Epoch: 5| Step: 8
Training loss: 0.05088557704825752
Validation loss: 2.2925767575549876

Epoch: 5| Step: 9
Training loss: 0.10763499619724143
Validation loss: 2.3072494813718176

Epoch: 5| Step: 10
Training loss: 0.08289798314713576
Validation loss: 2.318676142799789

Epoch: 694| Step: 0
Training loss: 0.08448926398571585
Validation loss: 2.3267048343625136

Epoch: 5| Step: 1
Training loss: 0.08856054471757553
Validation loss: 2.3340941132302113

Epoch: 5| Step: 2
Training loss: 0.09906605192940626
Validation loss: 2.3119412672596455

Epoch: 5| Step: 3
Training loss: 0.07498447784095638
Validation loss: 2.3169761899634613

Epoch: 5| Step: 4
Training loss: 0.08118804050137894
Validation loss: 2.325297814176012

Epoch: 5| Step: 5
Training loss: 0.08404313294228223
Validation loss: 2.2946209618658258

Epoch: 5| Step: 6
Training loss: 0.1450835192760603
Validation loss: 2.2753006103771405

Epoch: 5| Step: 7
Training loss: 0.0704653092715824
Validation loss: 2.306428923603913

Epoch: 5| Step: 8
Training loss: 0.05851872130695993
Validation loss: 2.257734897814335

Epoch: 5| Step: 9
Training loss: 0.06405236539110656
Validation loss: 2.282637173112851

Epoch: 5| Step: 10
Training loss: 0.08921604535701541
Validation loss: 2.275669008728069

Epoch: 695| Step: 0
Training loss: 0.1398317427781541
Validation loss: 2.2811350257569165

Epoch: 5| Step: 1
Training loss: 0.08476570322762672
Validation loss: 2.2392628458790615

Epoch: 5| Step: 2
Training loss: 0.08565117267621046
Validation loss: 2.2435470026257205

Epoch: 5| Step: 3
Training loss: 0.08061304187623589
Validation loss: 2.240955730330234

Epoch: 5| Step: 4
Training loss: 0.1020729962495035
Validation loss: 2.241598031706859

Epoch: 5| Step: 5
Training loss: 0.05087776823473453
Validation loss: 2.236735587322288

Epoch: 5| Step: 6
Training loss: 0.09045495613301933
Validation loss: 2.251917736182136

Epoch: 5| Step: 7
Training loss: 0.06156741568623259
Validation loss: 2.2429344988395306

Epoch: 5| Step: 8
Training loss: 0.12777570382525022
Validation loss: 2.233409982699653

Epoch: 5| Step: 9
Training loss: 0.1075305129288963
Validation loss: 2.2646211634362885

Epoch: 5| Step: 10
Training loss: 0.08014474981473127
Validation loss: 2.2445469700458425

Epoch: 696| Step: 0
Training loss: 0.08681079805623478
Validation loss: 2.2872380175051137

Epoch: 5| Step: 1
Training loss: 0.0854699028048973
Validation loss: 2.2743252452115033

Epoch: 5| Step: 2
Training loss: 0.10320355049958109
Validation loss: 2.268857500704727

Epoch: 5| Step: 3
Training loss: 0.08333376391369127
Validation loss: 2.2833616075620715

Epoch: 5| Step: 4
Training loss: 0.07781439967977175
Validation loss: 2.272785029003724

Epoch: 5| Step: 5
Training loss: 0.11481052781001327
Validation loss: 2.249964843666759

Epoch: 5| Step: 6
Training loss: 0.07694355401678893
Validation loss: 2.2613154288374173

Epoch: 5| Step: 7
Training loss: 0.11043226616206402
Validation loss: 2.2472958796637337

Epoch: 5| Step: 8
Training loss: 0.08854010407621037
Validation loss: 2.2441523319850316

Epoch: 5| Step: 9
Training loss: 0.08432155943307038
Validation loss: 2.2565518323640874

Epoch: 5| Step: 10
Training loss: 0.08002766903704875
Validation loss: 2.2565817374007566

Epoch: 697| Step: 0
Training loss: 0.06763189345950794
Validation loss: 2.2411607830753733

Epoch: 5| Step: 1
Training loss: 0.09038586430059409
Validation loss: 2.24582108920769

Epoch: 5| Step: 2
Training loss: 0.06499976569028035
Validation loss: 2.2379974343926836

Epoch: 5| Step: 3
Training loss: 0.06761636547842893
Validation loss: 2.216505845035833

Epoch: 5| Step: 4
Training loss: 0.0491190706105647
Validation loss: 2.2191900117117473

Epoch: 5| Step: 5
Training loss: 0.06176057029444331
Validation loss: 2.243133495713144

Epoch: 5| Step: 6
Training loss: 0.08554774734627109
Validation loss: 2.222775794583421

Epoch: 5| Step: 7
Training loss: 0.10469155143613004
Validation loss: 2.2239219218934743

Epoch: 5| Step: 8
Training loss: 0.10022892601918873
Validation loss: 2.202261018823184

Epoch: 5| Step: 9
Training loss: 0.11210747693943936
Validation loss: 2.223006244076307

Epoch: 5| Step: 10
Training loss: 0.06379097319554515
Validation loss: 2.2304787397533583

Epoch: 698| Step: 0
Training loss: 0.05943684204268381
Validation loss: 2.2399888156393373

Epoch: 5| Step: 1
Training loss: 0.1439530754842852
Validation loss: 2.236527425981992

Epoch: 5| Step: 2
Training loss: 0.050325364724953865
Validation loss: 2.2447143833365426

Epoch: 5| Step: 3
Training loss: 0.07298939631311879
Validation loss: 2.2643532668548705

Epoch: 5| Step: 4
Training loss: 0.07052286454996266
Validation loss: 2.271296427315759

Epoch: 5| Step: 5
Training loss: 0.0740308138913811
Validation loss: 2.2468051223674625

Epoch: 5| Step: 6
Training loss: 0.07443332397804431
Validation loss: 2.2839202558866147

Epoch: 5| Step: 7
Training loss: 0.10493527260126653
Validation loss: 2.2686852900868724

Epoch: 5| Step: 8
Training loss: 0.05453696351123527
Validation loss: 2.284327822307875

Epoch: 5| Step: 9
Training loss: 0.1239564895158834
Validation loss: 2.285241574781391

Epoch: 5| Step: 10
Training loss: 0.09518239373107253
Validation loss: 2.2597217256156164

Epoch: 699| Step: 0
Training loss: 0.07339321777213631
Validation loss: 2.2508152187890027

Epoch: 5| Step: 1
Training loss: 0.06975468594652107
Validation loss: 2.269965430347886

Epoch: 5| Step: 2
Training loss: 0.06380559666685205
Validation loss: 2.282238695304585

Epoch: 5| Step: 3
Training loss: 0.09111565589876787
Validation loss: 2.2704445738624384

Epoch: 5| Step: 4
Training loss: 0.08428259509402568
Validation loss: 2.252001676993122

Epoch: 5| Step: 5
Training loss: 0.09522871747787585
Validation loss: 2.272549195920136

Epoch: 5| Step: 6
Training loss: 0.1175078345093885
Validation loss: 2.3039038063847848

Epoch: 5| Step: 7
Training loss: 0.09445802240477583
Validation loss: 2.2968908112253583

Epoch: 5| Step: 8
Training loss: 0.11546749441447555
Validation loss: 2.2914759424182964

Epoch: 5| Step: 9
Training loss: 0.10526811094379417
Validation loss: 2.2693136660631406

Epoch: 5| Step: 10
Training loss: 0.13469327145356455
Validation loss: 2.2909893854786008

Epoch: 700| Step: 0
Training loss: 0.11730377071783271
Validation loss: 2.296493884840089

Epoch: 5| Step: 1
Training loss: 0.04818658423604992
Validation loss: 2.256496837099763

Epoch: 5| Step: 2
Training loss: 0.07285762920124651
Validation loss: 2.2371948219222597

Epoch: 5| Step: 3
Training loss: 0.0715773547103411
Validation loss: 2.229399537726912

Epoch: 5| Step: 4
Training loss: 0.13781572041890017
Validation loss: 2.1989951680430306

Epoch: 5| Step: 5
Training loss: 0.1184712979247239
Validation loss: 2.2266810772935286

Epoch: 5| Step: 6
Training loss: 0.1298410664061894
Validation loss: 2.273008949419563

Epoch: 5| Step: 7
Training loss: 0.09877197909815397
Validation loss: 2.256951421490769

Epoch: 5| Step: 8
Training loss: 0.10044345207951105
Validation loss: 2.243317379872428

Epoch: 5| Step: 9
Training loss: 0.10070180238043124
Validation loss: 2.2924939512825033

Epoch: 5| Step: 10
Training loss: 0.13554369183411263
Validation loss: 2.268586213028687

Epoch: 701| Step: 0
Training loss: 0.13463903092698717
Validation loss: 2.277641167630478

Epoch: 5| Step: 1
Training loss: 0.08483782705863213
Validation loss: 2.285594202731264

Epoch: 5| Step: 2
Training loss: 0.12489508905287099
Validation loss: 2.288626811121212

Epoch: 5| Step: 3
Training loss: 0.09823706520635744
Validation loss: 2.313718193881851

Epoch: 5| Step: 4
Training loss: 0.0771664163910777
Validation loss: 2.293314000683996

Epoch: 5| Step: 5
Training loss: 0.1328168615859177
Validation loss: 2.280189134601492

Epoch: 5| Step: 6
Training loss: 0.09287873366065875
Validation loss: 2.2842710065041523

Epoch: 5| Step: 7
Training loss: 0.11615678984306449
Validation loss: 2.28034444522163

Epoch: 5| Step: 8
Training loss: 0.10669113786357971
Validation loss: 2.2745225242138756

Epoch: 5| Step: 9
Training loss: 0.06377091749475063
Validation loss: 2.2677648841072395

Epoch: 5| Step: 10
Training loss: 0.14892368627856972
Validation loss: 2.286611084679443

Epoch: 702| Step: 0
Training loss: 0.0753743375222034
Validation loss: 2.2708150289595017

Epoch: 5| Step: 1
Training loss: 0.09529832945684934
Validation loss: 2.258372119418683

Epoch: 5| Step: 2
Training loss: 0.09635640530520219
Validation loss: 2.268071216321313

Epoch: 5| Step: 3
Training loss: 0.09321391293428187
Validation loss: 2.2680811811786907

Epoch: 5| Step: 4
Training loss: 0.1314230635066223
Validation loss: 2.2698945610038166

Epoch: 5| Step: 5
Training loss: 0.1112766732563164
Validation loss: 2.253415418666609

Epoch: 5| Step: 6
Training loss: 0.12449749510061574
Validation loss: 2.289140781081961

Epoch: 5| Step: 7
Training loss: 0.13295683310929626
Validation loss: 2.263864718105861

Epoch: 5| Step: 8
Training loss: 0.08628407677199669
Validation loss: 2.2623260191162533

Epoch: 5| Step: 9
Training loss: 0.12932013046094207
Validation loss: 2.252961100539824

Epoch: 5| Step: 10
Training loss: 0.05853105409432074
Validation loss: 2.264449199539443

Epoch: 703| Step: 0
Training loss: 0.08622295480826037
Validation loss: 2.2572851850091196

Epoch: 5| Step: 1
Training loss: 0.13540494314822468
Validation loss: 2.236405563822831

Epoch: 5| Step: 2
Training loss: 0.12207977258265475
Validation loss: 2.252571488588619

Epoch: 5| Step: 3
Training loss: 0.0675374447478242
Validation loss: 2.262421301787027

Epoch: 5| Step: 4
Training loss: 0.10762649900857889
Validation loss: 2.24735323212591

Epoch: 5| Step: 5
Training loss: 0.09691333473728773
Validation loss: 2.2637114933989975

Epoch: 5| Step: 6
Training loss: 0.11584971892489884
Validation loss: 2.252856788693508

Epoch: 5| Step: 7
Training loss: 0.11323425534940672
Validation loss: 2.26185662719307

Epoch: 5| Step: 8
Training loss: 0.13096493406295792
Validation loss: 2.2593214038180065

Epoch: 5| Step: 9
Training loss: 0.11009080850319039
Validation loss: 2.259192165172562

Epoch: 5| Step: 10
Training loss: 0.0999603725684221
Validation loss: 2.2578602069853555

Epoch: 704| Step: 0
Training loss: 0.09981821644082521
Validation loss: 2.244758321531887

Epoch: 5| Step: 1
Training loss: 0.09345176566346687
Validation loss: 2.262834237632656

Epoch: 5| Step: 2
Training loss: 0.11281460806285067
Validation loss: 2.295083589705577

Epoch: 5| Step: 3
Training loss: 0.09893819537132283
Validation loss: 2.297242373598297

Epoch: 5| Step: 4
Training loss: 0.06443628177777017
Validation loss: 2.261902055469651

Epoch: 5| Step: 5
Training loss: 0.06292843748161786
Validation loss: 2.2936366364018324

Epoch: 5| Step: 6
Training loss: 0.06659304418932697
Validation loss: 2.270434911260817

Epoch: 5| Step: 7
Training loss: 0.0886412042349737
Validation loss: 2.2923009947275865

Epoch: 5| Step: 8
Training loss: 0.11798619052983955
Validation loss: 2.302186804276921

Epoch: 5| Step: 9
Training loss: 0.07359216678742769
Validation loss: 2.2643987503339833

Epoch: 5| Step: 10
Training loss: 0.13738911313557303
Validation loss: 2.289382817522704

Epoch: 705| Step: 0
Training loss: 0.0947513056422286
Validation loss: 2.297150156263685

Epoch: 5| Step: 1
Training loss: 0.07058275129033406
Validation loss: 2.2951691781949206

Epoch: 5| Step: 2
Training loss: 0.06946986320163959
Validation loss: 2.302260994522876

Epoch: 5| Step: 3
Training loss: 0.1024596406256116
Validation loss: 2.3197773360135336

Epoch: 5| Step: 4
Training loss: 0.0936386569764907
Validation loss: 2.3028204239058505

Epoch: 5| Step: 5
Training loss: 0.06646954801436408
Validation loss: 2.285887370786073

Epoch: 5| Step: 6
Training loss: 0.11314605175848996
Validation loss: 2.280395139739492

Epoch: 5| Step: 7
Training loss: 0.11773615985724875
Validation loss: 2.3018427630175893

Epoch: 5| Step: 8
Training loss: 0.06448344760040255
Validation loss: 2.2659857282074443

Epoch: 5| Step: 9
Training loss: 0.10606450901253052
Validation loss: 2.2560705184052616

Epoch: 5| Step: 10
Training loss: 0.06697738000025323
Validation loss: 2.2639180339714886

Epoch: 706| Step: 0
Training loss: 0.08034421742554423
Validation loss: 2.274928427932444

Epoch: 5| Step: 1
Training loss: 0.02666346556521762
Validation loss: 2.25764885026988

Epoch: 5| Step: 2
Training loss: 0.03217438244763293
Validation loss: 2.2629365205195646

Epoch: 5| Step: 3
Training loss: 0.09137970914004064
Validation loss: 2.264907768648228

Epoch: 5| Step: 4
Training loss: 0.12124997106409219
Validation loss: 2.260990259637371

Epoch: 5| Step: 5
Training loss: 0.08942224790071106
Validation loss: 2.281443335543794

Epoch: 5| Step: 6
Training loss: 0.08164716390952914
Validation loss: 2.23671710438674

Epoch: 5| Step: 7
Training loss: 0.09739194388791732
Validation loss: 2.2632429987949814

Epoch: 5| Step: 8
Training loss: 0.04782529275282236
Validation loss: 2.2654999344493048

Epoch: 5| Step: 9
Training loss: 0.10779846677117762
Validation loss: 2.2536311911336244

Epoch: 5| Step: 10
Training loss: 0.07977997705838917
Validation loss: 2.293210242677733

Epoch: 707| Step: 0
Training loss: 0.11879516373269426
Validation loss: 2.2751879282142387

Epoch: 5| Step: 1
Training loss: 0.08656427095853265
Validation loss: 2.2837962957772047

Epoch: 5| Step: 2
Training loss: 0.08311767880656427
Validation loss: 2.296963642355608

Epoch: 5| Step: 3
Training loss: 0.12387146612457058
Validation loss: 2.2944314099264975

Epoch: 5| Step: 4
Training loss: 0.10238888506034596
Validation loss: 2.287871383540167

Epoch: 5| Step: 5
Training loss: 0.07608236653641419
Validation loss: 2.3135837730298565

Epoch: 5| Step: 6
Training loss: 0.10848930777162061
Validation loss: 2.3041856369840983

Epoch: 5| Step: 7
Training loss: 0.05562580408428635
Validation loss: 2.283483173560018

Epoch: 5| Step: 8
Training loss: 0.059520409349805306
Validation loss: 2.2812520565305197

Epoch: 5| Step: 9
Training loss: 0.1346250090705316
Validation loss: 2.2469135453690883

Epoch: 5| Step: 10
Training loss: 0.06191409679616466
Validation loss: 2.2291257633331787

Epoch: 708| Step: 0
Training loss: 0.14454428510909517
Validation loss: 2.2519340782212787

Epoch: 5| Step: 1
Training loss: 0.07752895974036568
Validation loss: 2.222926457482297

Epoch: 5| Step: 2
Training loss: 0.1320513484261639
Validation loss: 2.2605468291378106

Epoch: 5| Step: 3
Training loss: 0.06194235835017536
Validation loss: 2.2431356506192635

Epoch: 5| Step: 4
Training loss: 0.13046611937423488
Validation loss: 2.2488773067591623

Epoch: 5| Step: 5
Training loss: 0.09456325493641687
Validation loss: 2.2742259917006518

Epoch: 5| Step: 6
Training loss: 0.08657125847882012
Validation loss: 2.2474396630213227

Epoch: 5| Step: 7
Training loss: 0.05113721986271144
Validation loss: 2.22832779045421

Epoch: 5| Step: 8
Training loss: 0.07878610320767851
Validation loss: 2.2255558428957176

Epoch: 5| Step: 9
Training loss: 0.11918200493418975
Validation loss: 2.2333218150269616

Epoch: 5| Step: 10
Training loss: 0.08150409582825842
Validation loss: 2.2410176842024394

Epoch: 709| Step: 0
Training loss: 0.07508214882220791
Validation loss: 2.265339777909849

Epoch: 5| Step: 1
Training loss: 0.08541184289131815
Validation loss: 2.242158142746032

Epoch: 5| Step: 2
Training loss: 0.10406094093128573
Validation loss: 2.245732278080086

Epoch: 5| Step: 3
Training loss: 0.10511449641706526
Validation loss: 2.2810874237103436

Epoch: 5| Step: 4
Training loss: 0.13083980186178149
Validation loss: 2.274008989436218

Epoch: 5| Step: 5
Training loss: 0.07942100472980038
Validation loss: 2.2662962725644853

Epoch: 5| Step: 6
Training loss: 0.09106197302665166
Validation loss: 2.269078277465203

Epoch: 5| Step: 7
Training loss: 0.0738826910842619
Validation loss: 2.2705631085914573

Epoch: 5| Step: 8
Training loss: 0.10060842503399697
Validation loss: 2.261203839945548

Epoch: 5| Step: 9
Training loss: 0.1313306591849194
Validation loss: 2.253048643045729

Epoch: 5| Step: 10
Training loss: 0.06840861114118882
Validation loss: 2.2634070907082955

Epoch: 710| Step: 0
Training loss: 0.08371897280173221
Validation loss: 2.2693282637000083

Epoch: 5| Step: 1
Training loss: 0.14646973854693363
Validation loss: 2.290326347568955

Epoch: 5| Step: 2
Training loss: 0.05638639970919734
Validation loss: 2.2690021073906053

Epoch: 5| Step: 3
Training loss: 0.06658745333772159
Validation loss: 2.2438192576638127

Epoch: 5| Step: 4
Training loss: 0.09987053108273176
Validation loss: 2.2490866178978

Epoch: 5| Step: 5
Training loss: 0.06903897075597339
Validation loss: 2.248367613552803

Epoch: 5| Step: 6
Training loss: 0.07776418454601126
Validation loss: 2.248785657433487

Epoch: 5| Step: 7
Training loss: 0.12944501216010249
Validation loss: 2.255363808740711

Epoch: 5| Step: 8
Training loss: 0.12661589067376014
Validation loss: 2.2265449228188428

Epoch: 5| Step: 9
Training loss: 0.09450745066248455
Validation loss: 2.266290596181845

Epoch: 5| Step: 10
Training loss: 0.08304838423196399
Validation loss: 2.2718253943902313

Epoch: 711| Step: 0
Training loss: 0.06914642789164034
Validation loss: 2.2800344706061275

Epoch: 5| Step: 1
Training loss: 0.1179113918086159
Validation loss: 2.246936527628168

Epoch: 5| Step: 2
Training loss: 0.11381350637438223
Validation loss: 2.2619204436825746

Epoch: 5| Step: 3
Training loss: 0.11070046925774801
Validation loss: 2.2443665140223614

Epoch: 5| Step: 4
Training loss: 0.12180749830342977
Validation loss: 2.245261147486491

Epoch: 5| Step: 5
Training loss: 0.10876043549158651
Validation loss: 2.2501501764748433

Epoch: 5| Step: 6
Training loss: 0.07254100216648468
Validation loss: 2.266586868410917

Epoch: 5| Step: 7
Training loss: 0.11756073404884006
Validation loss: 2.2479664581196848

Epoch: 5| Step: 8
Training loss: 0.08888406907593491
Validation loss: 2.2394936072616223

Epoch: 5| Step: 9
Training loss: 0.10239940851556906
Validation loss: 2.221547975166376

Epoch: 5| Step: 10
Training loss: 0.11534080197466623
Validation loss: 2.242414853062884

Epoch: 712| Step: 0
Training loss: 0.10083035983953768
Validation loss: 2.2251028829608597

Epoch: 5| Step: 1
Training loss: 0.05586467947816183
Validation loss: 2.228039982836664

Epoch: 5| Step: 2
Training loss: 0.07834017744257181
Validation loss: 2.2208541374461115

Epoch: 5| Step: 3
Training loss: 0.08151955753885154
Validation loss: 2.204902267771719

Epoch: 5| Step: 4
Training loss: 0.13197870647974433
Validation loss: 2.2350232283840596

Epoch: 5| Step: 5
Training loss: 0.0903949569926863
Validation loss: 2.216705639860714

Epoch: 5| Step: 6
Training loss: 0.10509152415615564
Validation loss: 2.239107606179001

Epoch: 5| Step: 7
Training loss: 0.07428534556682322
Validation loss: 2.269258914274066

Epoch: 5| Step: 8
Training loss: 0.13758433042586998
Validation loss: 2.2707336978178616

Epoch: 5| Step: 9
Training loss: 0.06994188837451407
Validation loss: 2.2426693403484554

Epoch: 5| Step: 10
Training loss: 0.05078806739674908
Validation loss: 2.257080488582546

Epoch: 713| Step: 0
Training loss: 0.11316750011285831
Validation loss: 2.2695187013459313

Epoch: 5| Step: 1
Training loss: 0.0594446662908317
Validation loss: 2.2791407728230593

Epoch: 5| Step: 2
Training loss: 0.09645975026479629
Validation loss: 2.2888696887445565

Epoch: 5| Step: 3
Training loss: 0.07673165152172733
Validation loss: 2.279416746647122

Epoch: 5| Step: 4
Training loss: 0.05821516997238194
Validation loss: 2.270393027091144

Epoch: 5| Step: 5
Training loss: 0.13079129768386172
Validation loss: 2.2550959870421425

Epoch: 5| Step: 6
Training loss: 0.16927703088027457
Validation loss: 2.2770484304078495

Epoch: 5| Step: 7
Training loss: 0.09093058464786961
Validation loss: 2.286521826834293

Epoch: 5| Step: 8
Training loss: 0.07734678219140069
Validation loss: 2.2920466112733133

Epoch: 5| Step: 9
Training loss: 0.043861152275376056
Validation loss: 2.3138900044783344

Epoch: 5| Step: 10
Training loss: 0.08694662062934028
Validation loss: 2.299040512915622

Epoch: 714| Step: 0
Training loss: 0.09268644671475082
Validation loss: 2.281326097137046

Epoch: 5| Step: 1
Training loss: 0.07688096313105176
Validation loss: 2.3217186457971346

Epoch: 5| Step: 2
Training loss: 0.07303607230961863
Validation loss: 2.2783539201413507

Epoch: 5| Step: 3
Training loss: 0.09515949498987326
Validation loss: 2.28138570456341

Epoch: 5| Step: 4
Training loss: 0.09953481089930777
Validation loss: 2.2499759984986563

Epoch: 5| Step: 5
Training loss: 0.08265023348423955
Validation loss: 2.2201674239452935

Epoch: 5| Step: 6
Training loss: 0.10635209157502896
Validation loss: 2.2405125345634116

Epoch: 5| Step: 7
Training loss: 0.08299199682919622
Validation loss: 2.206876812699699

Epoch: 5| Step: 8
Training loss: 0.12638093676050266
Validation loss: 2.1984251911787123

Epoch: 5| Step: 9
Training loss: 0.13039262286667552
Validation loss: 2.226015909774463

Epoch: 5| Step: 10
Training loss: 0.07859211986360386
Validation loss: 2.2023091670045827

Epoch: 715| Step: 0
Training loss: 0.10343455793051712
Validation loss: 2.2403660529448075

Epoch: 5| Step: 1
Training loss: 0.1018888246994076
Validation loss: 2.2419754642094896

Epoch: 5| Step: 2
Training loss: 0.09614839899470404
Validation loss: 2.2861890165889442

Epoch: 5| Step: 3
Training loss: 0.09795377707405058
Validation loss: 2.2998520058059486

Epoch: 5| Step: 4
Training loss: 0.08713104188136389
Validation loss: 2.315273181895228

Epoch: 5| Step: 5
Training loss: 0.140318828643944
Validation loss: 2.332804684990978

Epoch: 5| Step: 6
Training loss: 0.07560674087825935
Validation loss: 2.3597065649770754

Epoch: 5| Step: 7
Training loss: 0.07560891189165338
Validation loss: 2.328024543312156

Epoch: 5| Step: 8
Training loss: 0.13843734815472958
Validation loss: 2.3338341397079834

Epoch: 5| Step: 9
Training loss: 0.06883170910378812
Validation loss: 2.3257001488394162

Epoch: 5| Step: 10
Training loss: 0.09014192113607376
Validation loss: 2.2887179963714868

Epoch: 716| Step: 0
Training loss: 0.10635557241550705
Validation loss: 2.2382091758368574

Epoch: 5| Step: 1
Training loss: 0.0470474320118673
Validation loss: 2.2442924649272458

Epoch: 5| Step: 2
Training loss: 0.07859820464195862
Validation loss: 2.2215105844729535

Epoch: 5| Step: 3
Training loss: 0.0837060675136759
Validation loss: 2.1954435022515053

Epoch: 5| Step: 4
Training loss: 0.08607992107475788
Validation loss: 2.213352170840083

Epoch: 5| Step: 5
Training loss: 0.11555033541250635
Validation loss: 2.2145440982847564

Epoch: 5| Step: 6
Training loss: 0.09943358018013707
Validation loss: 2.212047401948747

Epoch: 5| Step: 7
Training loss: 0.08490567767027925
Validation loss: 2.2133160165699146

Epoch: 5| Step: 8
Training loss: 0.07043799816761863
Validation loss: 2.2284035831878195

Epoch: 5| Step: 9
Training loss: 0.09758133398877146
Validation loss: 2.2843450917875865

Epoch: 5| Step: 10
Training loss: 0.12950912295797612
Validation loss: 2.2832337891817556

Epoch: 717| Step: 0
Training loss: 0.11163202851302029
Validation loss: 2.271005440141666

Epoch: 5| Step: 1
Training loss: 0.0809917262868112
Validation loss: 2.2848706531389387

Epoch: 5| Step: 2
Training loss: 0.09466443039672366
Validation loss: 2.2552048438427277

Epoch: 5| Step: 3
Training loss: 0.09253313665550475
Validation loss: 2.2765701193707377

Epoch: 5| Step: 4
Training loss: 0.10193126469685168
Validation loss: 2.265138321918429

Epoch: 5| Step: 5
Training loss: 0.09357495655779349
Validation loss: 2.270315749343193

Epoch: 5| Step: 6
Training loss: 0.10623641032375883
Validation loss: 2.2739466393176904

Epoch: 5| Step: 7
Training loss: 0.10652518993820467
Validation loss: 2.267646036921209

Epoch: 5| Step: 8
Training loss: 0.11115568592688777
Validation loss: 2.239016466069913

Epoch: 5| Step: 9
Training loss: 0.0919680419950359
Validation loss: 2.2308874468375515

Epoch: 5| Step: 10
Training loss: 0.0868218259331937
Validation loss: 2.24693545399463

Epoch: 718| Step: 0
Training loss: 0.06073713595920964
Validation loss: 2.236814762152687

Epoch: 5| Step: 1
Training loss: 0.04854252498344364
Validation loss: 2.2547666955663823

Epoch: 5| Step: 2
Training loss: 0.11532312547762266
Validation loss: 2.2645262003108093

Epoch: 5| Step: 3
Training loss: 0.09060846251837229
Validation loss: 2.255780868609624

Epoch: 5| Step: 4
Training loss: 0.10794031576151691
Validation loss: 2.2713792552425325

Epoch: 5| Step: 5
Training loss: 0.09082341957930165
Validation loss: 2.2698760832233713

Epoch: 5| Step: 6
Training loss: 0.08066175482915017
Validation loss: 2.2221563864854743

Epoch: 5| Step: 7
Training loss: 0.0803959198636206
Validation loss: 2.2343670085979492

Epoch: 5| Step: 8
Training loss: 0.07991157051397955
Validation loss: 2.2420989491391623

Epoch: 5| Step: 9
Training loss: 0.06282369787243018
Validation loss: 2.2597742617181824

Epoch: 5| Step: 10
Training loss: 0.0602539266527534
Validation loss: 2.2281453592723084

Epoch: 719| Step: 0
Training loss: 0.10960614949413354
Validation loss: 2.2442082249140527

Epoch: 5| Step: 1
Training loss: 0.08682337058232233
Validation loss: 2.2564740044745766

Epoch: 5| Step: 2
Training loss: 0.09944493614399473
Validation loss: 2.2637830336398252

Epoch: 5| Step: 3
Training loss: 0.06780400837192128
Validation loss: 2.2773517571986424

Epoch: 5| Step: 4
Training loss: 0.1093770478261248
Validation loss: 2.2946387426598274

Epoch: 5| Step: 5
Training loss: 0.08002394785760662
Validation loss: 2.3238375708198293

Epoch: 5| Step: 6
Training loss: 0.0993034442481361
Validation loss: 2.308355953499171

Epoch: 5| Step: 7
Training loss: 0.08411109036711303
Validation loss: 2.3327963378852776

Epoch: 5| Step: 8
Training loss: 0.07667729617416083
Validation loss: 2.32965063339639

Epoch: 5| Step: 9
Training loss: 0.08491299087479257
Validation loss: 2.3462846041462493

Epoch: 5| Step: 10
Training loss: 0.13247299979750302
Validation loss: 2.3402904055629707

Epoch: 720| Step: 0
Training loss: 0.08528826950664119
Validation loss: 2.3285959982334545

Epoch: 5| Step: 1
Training loss: 0.12823587278307355
Validation loss: 2.299173207210179

Epoch: 5| Step: 2
Training loss: 0.07512537688924027
Validation loss: 2.3182151377670643

Epoch: 5| Step: 3
Training loss: 0.13238173638855047
Validation loss: 2.2819489635867773

Epoch: 5| Step: 4
Training loss: 0.11577620253326586
Validation loss: 2.2936053196651423

Epoch: 5| Step: 5
Training loss: 0.05267197396108678
Validation loss: 2.2970638017571487

Epoch: 5| Step: 6
Training loss: 0.0900590741970572
Validation loss: 2.263010297141108

Epoch: 5| Step: 7
Training loss: 0.09338805743666245
Validation loss: 2.2850586847821504

Epoch: 5| Step: 8
Training loss: 0.12094110435467134
Validation loss: 2.2932287118680392

Epoch: 5| Step: 9
Training loss: 0.08535376257865171
Validation loss: 2.2987991331040245

Epoch: 5| Step: 10
Training loss: 0.08636771422768598
Validation loss: 2.29934542116981

Epoch: 721| Step: 0
Training loss: 0.14513391421455815
Validation loss: 2.2956833132713768

Epoch: 5| Step: 1
Training loss: 0.05707691753307524
Validation loss: 2.2773858108369502

Epoch: 5| Step: 2
Training loss: 0.0839537464891295
Validation loss: 2.2842554356409313

Epoch: 5| Step: 3
Training loss: 0.11400952219303595
Validation loss: 2.2791986568454226

Epoch: 5| Step: 4
Training loss: 0.07524918818392352
Validation loss: 2.259042165362153

Epoch: 5| Step: 5
Training loss: 0.07849000659926379
Validation loss: 2.273380525923303

Epoch: 5| Step: 6
Training loss: 0.0783492624616782
Validation loss: 2.284056959001342

Epoch: 5| Step: 7
Training loss: 0.05472675260147307
Validation loss: 2.273389716478385

Epoch: 5| Step: 8
Training loss: 0.09279602177438522
Validation loss: 2.2742934125972556

Epoch: 5| Step: 9
Training loss: 0.09023312489357858
Validation loss: 2.2933568920663707

Epoch: 5| Step: 10
Training loss: 0.05222023787610279
Validation loss: 2.2702505500904695

Epoch: 722| Step: 0
Training loss: 0.05303527718239628
Validation loss: 2.2467186530833922

Epoch: 5| Step: 1
Training loss: 0.06180289167467279
Validation loss: 2.281709341018822

Epoch: 5| Step: 2
Training loss: 0.11501000268857793
Validation loss: 2.2384319664501438

Epoch: 5| Step: 3
Training loss: 0.09594281018810534
Validation loss: 2.2542904449440613

Epoch: 5| Step: 4
Training loss: 0.1165391790260673
Validation loss: 2.2586247922848974

Epoch: 5| Step: 5
Training loss: 0.06931296491853975
Validation loss: 2.264040539520641

Epoch: 5| Step: 6
Training loss: 0.060694618089287715
Validation loss: 2.2779423692005136

Epoch: 5| Step: 7
Training loss: 0.06736215675656412
Validation loss: 2.2399082227680807

Epoch: 5| Step: 8
Training loss: 0.1266553173449682
Validation loss: 2.2607293904784673

Epoch: 5| Step: 9
Training loss: 0.0836601040767805
Validation loss: 2.235780868134248

Epoch: 5| Step: 10
Training loss: 0.10208780356354208
Validation loss: 2.291364411774848

Epoch: 723| Step: 0
Training loss: 0.09089237348643037
Validation loss: 2.273764555156138

Epoch: 5| Step: 1
Training loss: 0.11198726659873513
Validation loss: 2.224636822702349

Epoch: 5| Step: 2
Training loss: 0.11642124076299837
Validation loss: 2.2209146718342527

Epoch: 5| Step: 3
Training loss: 0.09617361397956732
Validation loss: 2.2304401384735444

Epoch: 5| Step: 4
Training loss: 0.06634279332659353
Validation loss: 2.1963622321490788

Epoch: 5| Step: 5
Training loss: 0.16067629792831925
Validation loss: 2.1572671945842736

Epoch: 5| Step: 6
Training loss: 0.08063087484945755
Validation loss: 2.1922066127957325

Epoch: 5| Step: 7
Training loss: 0.09065363571318745
Validation loss: 2.209880364659983

Epoch: 5| Step: 8
Training loss: 0.1045294454587036
Validation loss: 2.221716582631875

Epoch: 5| Step: 9
Training loss: 0.1573958995487807
Validation loss: 2.2707082603521007

Epoch: 5| Step: 10
Training loss: 0.10996192741964807
Validation loss: 2.2652571286505516

Epoch: 724| Step: 0
Training loss: 0.11126605612504294
Validation loss: 2.2936773995212327

Epoch: 5| Step: 1
Training loss: 0.14729648539939885
Validation loss: 2.299897298887394

Epoch: 5| Step: 2
Training loss: 0.19240745154286448
Validation loss: 2.311206009934551

Epoch: 5| Step: 3
Training loss: 0.14413210163916076
Validation loss: 2.2899753248846055

Epoch: 5| Step: 4
Training loss: 0.11095857352924217
Validation loss: 2.241384552181385

Epoch: 5| Step: 5
Training loss: 0.10711905539331272
Validation loss: 2.2244501674986705

Epoch: 5| Step: 6
Training loss: 0.319779545816268
Validation loss: 2.232288975645803

Epoch: 5| Step: 7
Training loss: 0.11331155799047031
Validation loss: 2.231980772189661

Epoch: 5| Step: 8
Training loss: 0.20527701950940497
Validation loss: 2.321854350161708

Epoch: 5| Step: 9
Training loss: 0.433696184859978
Validation loss: 2.3580350231998746

Epoch: 5| Step: 10
Training loss: 0.2603886382596288
Validation loss: 2.257154839371749

Epoch: 725| Step: 0
Training loss: 0.2752597849732474
Validation loss: 2.2399396993922798

Epoch: 5| Step: 1
Training loss: 0.47176775692592066
Validation loss: 2.2662985474121267

Epoch: 5| Step: 2
Training loss: 0.7848251555645858
Validation loss: 2.299751367545896

Epoch: 5| Step: 3
Training loss: 0.3785005344024272
Validation loss: 2.359982181038249

Epoch: 5| Step: 4
Training loss: 0.8328610790749027
Validation loss: 2.5285334105825266

Epoch: 5| Step: 5
Training loss: 0.5578489606892921
Validation loss: 2.4178061643589017

Epoch: 5| Step: 6
Training loss: 0.6607644028048294
Validation loss: 2.2818886872405444

Epoch: 5| Step: 7
Training loss: 0.8489192220341656
Validation loss: 2.211798883586894

Epoch: 5| Step: 8
Training loss: 0.762377410164329
Validation loss: 2.1741781781828076

Epoch: 5| Step: 9
Training loss: 0.4062833955683323
Validation loss: 2.210986462783633

Epoch: 5| Step: 10
Training loss: 0.5675841875271028
Validation loss: 2.3318377380668402

Epoch: 726| Step: 0
Training loss: 0.5845743471688911
Validation loss: 2.4119601077922477

Epoch: 5| Step: 1
Training loss: 0.6729810615017444
Validation loss: 2.403604173362025

Epoch: 5| Step: 2
Training loss: 0.42891564836610335
Validation loss: 2.349314939485885

Epoch: 5| Step: 3
Training loss: 0.916431096903557
Validation loss: 2.2479655115654475

Epoch: 5| Step: 4
Training loss: 0.3606125214928413
Validation loss: 2.187317540283881

Epoch: 5| Step: 5
Training loss: 0.7198878693686339
Validation loss: 2.133274226569949

Epoch: 5| Step: 6
Training loss: 0.6751218897651291
Validation loss: 2.0873511250191013

Epoch: 5| Step: 7
Training loss: 0.6851167552182564
Validation loss: 2.1080122483068817

Epoch: 5| Step: 8
Training loss: 0.44193172403692726
Validation loss: 2.119663058558001

Epoch: 5| Step: 9
Training loss: 0.6277826828282047
Validation loss: 2.1409231190449156

Epoch: 5| Step: 10
Training loss: 0.5759453538347771
Validation loss: 2.197526005237541

Epoch: 727| Step: 0
Training loss: 0.6680817536363185
Validation loss: 2.222169603783177

Epoch: 5| Step: 1
Training loss: 0.5312699706867875
Validation loss: 2.2089976760433196

Epoch: 5| Step: 2
Training loss: 0.6399310237625
Validation loss: 2.255722122267947

Epoch: 5| Step: 3
Training loss: 0.595440641013524
Validation loss: 2.3616499532267867

Epoch: 5| Step: 4
Training loss: 0.7247959523971119
Validation loss: 2.3158333214473394

Epoch: 5| Step: 5
Training loss: 0.6535179626094694
Validation loss: 2.2455920289226947

Epoch: 5| Step: 6
Training loss: 0.5787479807198481
Validation loss: 2.2368431442945607

Epoch: 5| Step: 7
Training loss: 0.7513253502022522
Validation loss: 2.1714074623188533

Epoch: 5| Step: 8
Training loss: 0.8111563356048765
Validation loss: 2.2180774206014604

Epoch: 5| Step: 9
Training loss: 0.8285989664580031
Validation loss: 2.2246590371390096

Epoch: 5| Step: 10
Training loss: 0.9907045771649314
Validation loss: 2.290121655848888

Epoch: 728| Step: 0
Training loss: 0.5703574907506709
Validation loss: 2.3402280656054706

Epoch: 5| Step: 1
Training loss: 0.24534002562705995
Validation loss: 2.422506578588617

Epoch: 5| Step: 2
Training loss: 0.6798491450178759
Validation loss: 2.473631479706091

Epoch: 5| Step: 3
Training loss: 0.6641987380353775
Validation loss: 2.4143223463204624

Epoch: 5| Step: 4
Training loss: 0.8410340147227062
Validation loss: 2.3992588840894022

Epoch: 5| Step: 5
Training loss: 0.4128515782655382
Validation loss: 2.378742330844848

Epoch: 5| Step: 6
Training loss: 0.5394036416044353
Validation loss: 2.331930826366798

Epoch: 5| Step: 7
Training loss: 0.7505518948976875
Validation loss: 2.3231017235234708

Epoch: 5| Step: 8
Training loss: 0.4712844045308467
Validation loss: 2.2663413030372355

Epoch: 5| Step: 9
Training loss: 0.7098697567071207
Validation loss: 2.2855331913549075

Epoch: 5| Step: 10
Training loss: 0.8540096293672583
Validation loss: 2.2721104872123665

Epoch: 729| Step: 0
Training loss: 0.6088759995704673
Validation loss: 2.2760429702394247

Epoch: 5| Step: 1
Training loss: 0.3858875435377401
Validation loss: 2.3005600232751386

Epoch: 5| Step: 2
Training loss: 0.47199420433810063
Validation loss: 2.372303361716948

Epoch: 5| Step: 3
Training loss: 0.8004738938901456
Validation loss: 2.4132495359093853

Epoch: 5| Step: 4
Training loss: 0.6660651582885169
Validation loss: 2.325290037128627

Epoch: 5| Step: 5
Training loss: 0.5424651960116632
Validation loss: 2.302427253280737

Epoch: 5| Step: 6
Training loss: 0.5980319917647023
Validation loss: 2.242947823719846

Epoch: 5| Step: 7
Training loss: 0.532218275093161
Validation loss: 2.2345030799744103

Epoch: 5| Step: 8
Training loss: 0.7221454361501245
Validation loss: 2.2265254980645706

Epoch: 5| Step: 9
Training loss: 0.5398260872762756
Validation loss: 2.2561110747951285

Epoch: 5| Step: 10
Training loss: 0.9016541657547839
Validation loss: 2.331616506930308

Epoch: 730| Step: 0
Training loss: 0.4824790457390406
Validation loss: 2.3735971803668248

Epoch: 5| Step: 1
Training loss: 0.4387622913312607
Validation loss: 2.4099683102131904

Epoch: 5| Step: 2
Training loss: 0.5483146790787599
Validation loss: 2.448671004177434

Epoch: 5| Step: 3
Training loss: 0.7582437920019102
Validation loss: 2.504620945722886

Epoch: 5| Step: 4
Training loss: 0.5333051479114027
Validation loss: 2.382480003576803

Epoch: 5| Step: 5
Training loss: 0.41315093554922094
Validation loss: 2.3340479416441164

Epoch: 5| Step: 6
Training loss: 0.673716903574289
Validation loss: 2.3100379635328596

Epoch: 5| Step: 7
Training loss: 0.7124733735848111
Validation loss: 2.325993220056109

Epoch: 5| Step: 8
Training loss: 0.7123428121143484
Validation loss: 2.3558027560923516

Epoch: 5| Step: 9
Training loss: 0.47891509839793434
Validation loss: 2.3539508158347786

Epoch: 5| Step: 10
Training loss: 0.5665844604057184
Validation loss: 2.4241743305320504

Epoch: 731| Step: 0
Training loss: 0.5360862002929342
Validation loss: 2.4691713336265626

Epoch: 5| Step: 1
Training loss: 0.6046750680991005
Validation loss: 2.511093498417711

Epoch: 5| Step: 2
Training loss: 0.6015560100254875
Validation loss: 2.5058921494865234

Epoch: 5| Step: 3
Training loss: 0.6927641987083732
Validation loss: 2.424208872436257

Epoch: 5| Step: 4
Training loss: 0.4594362023513895
Validation loss: 2.3920635645967883

Epoch: 5| Step: 5
Training loss: 0.45199381283306383
Validation loss: 2.3317485018245505

Epoch: 5| Step: 6
Training loss: 0.4690386042648983
Validation loss: 2.314365696392605

Epoch: 5| Step: 7
Training loss: 0.7536879307383214
Validation loss: 2.306849395319761

Epoch: 5| Step: 8
Training loss: 0.8095052621657438
Validation loss: 2.2479817386431122

Epoch: 5| Step: 9
Training loss: 0.6394396026057743
Validation loss: 2.2009591445845955

Epoch: 5| Step: 10
Training loss: 0.5071723130467899
Validation loss: 2.264016381134862

Epoch: 732| Step: 0
Training loss: 0.7620416201491481
Validation loss: 2.2756572633529113

Epoch: 5| Step: 1
Training loss: 0.5995435150458749
Validation loss: 2.2520950025513207

Epoch: 5| Step: 2
Training loss: 0.6451090217094314
Validation loss: 2.192984347155349

Epoch: 5| Step: 3
Training loss: 0.32910877299121283
Validation loss: 2.179756720064919

Epoch: 5| Step: 4
Training loss: 0.6973339442701137
Validation loss: 2.240333105004222

Epoch: 5| Step: 5
Training loss: 0.4855645861660033
Validation loss: 2.2821181383513625

Epoch: 5| Step: 6
Training loss: 0.6364532806603825
Validation loss: 2.304157211506685

Epoch: 5| Step: 7
Training loss: 0.6913173855501235
Validation loss: 2.372698778118587

Epoch: 5| Step: 8
Training loss: 0.39272992439851895
Validation loss: 2.420542599952103

Epoch: 5| Step: 9
Training loss: 0.7635668904369609
Validation loss: 2.4676119869831243

Epoch: 5| Step: 10
Training loss: 0.45210821248813565
Validation loss: 2.4726655573020855

Epoch: 733| Step: 0
Training loss: 0.496725851141997
Validation loss: 2.4568075444086026

Epoch: 5| Step: 1
Training loss: 0.38364850447870463
Validation loss: 2.376378174947338

Epoch: 5| Step: 2
Training loss: 0.2989604382767602
Validation loss: 2.322175519714068

Epoch: 5| Step: 3
Training loss: 0.47350724905662434
Validation loss: 2.323692740272653

Epoch: 5| Step: 4
Training loss: 0.3431631627773937
Validation loss: 2.2737410830045905

Epoch: 5| Step: 5
Training loss: 0.6842228202062834
Validation loss: 2.269717568282938

Epoch: 5| Step: 6
Training loss: 0.42929494439090987
Validation loss: 2.256835839808761

Epoch: 5| Step: 7
Training loss: 0.26416595226987477
Validation loss: 2.2573008913740304

Epoch: 5| Step: 8
Training loss: 0.5010017254851089
Validation loss: 2.280083760941366

Epoch: 5| Step: 9
Training loss: 0.43017526165414494
Validation loss: 2.2943811316899083

Epoch: 5| Step: 10
Training loss: 0.4868144625488169
Validation loss: 2.304187508101086

Epoch: 734| Step: 0
Training loss: 0.6435028657323283
Validation loss: 2.3497634059940173

Epoch: 5| Step: 1
Training loss: 0.44394822864439015
Validation loss: 2.363113747497067

Epoch: 5| Step: 2
Training loss: 0.4488345451991401
Validation loss: 2.425495381527943

Epoch: 5| Step: 3
Training loss: 0.6665842084752124
Validation loss: 2.4167475476448463

Epoch: 5| Step: 4
Training loss: 0.5018395321333408
Validation loss: 2.4010509273418172

Epoch: 5| Step: 5
Training loss: 0.5144831701497385
Validation loss: 2.3822693812161857

Epoch: 5| Step: 6
Training loss: 0.3142381964251956
Validation loss: 2.4026068884060843

Epoch: 5| Step: 7
Training loss: 0.43293301181881627
Validation loss: 2.3558558586390177

Epoch: 5| Step: 8
Training loss: 0.4445575873914525
Validation loss: 2.3201266315442446

Epoch: 5| Step: 9
Training loss: 0.36222223541528553
Validation loss: 2.2915197517384156

Epoch: 5| Step: 10
Training loss: 0.4412897175590446
Validation loss: 2.282591999989224

Epoch: 735| Step: 0
Training loss: 0.2565143878584183
Validation loss: 2.277980545640358

Epoch: 5| Step: 1
Training loss: 0.3201655539281977
Validation loss: 2.2647818320667903

Epoch: 5| Step: 2
Training loss: 0.31849328249729697
Validation loss: 2.268906870580702

Epoch: 5| Step: 3
Training loss: 0.49890187494239513
Validation loss: 2.2544959063977683

Epoch: 5| Step: 4
Training loss: 0.376810748631654
Validation loss: 2.307139434121987

Epoch: 5| Step: 5
Training loss: 0.31296778476392934
Validation loss: 2.3205896618550867

Epoch: 5| Step: 6
Training loss: 0.392305991521877
Validation loss: 2.294440105682582

Epoch: 5| Step: 7
Training loss: 0.47050799682157524
Validation loss: 2.296217564454953

Epoch: 5| Step: 8
Training loss: 0.31197771296005916
Validation loss: 2.288321495268714

Epoch: 5| Step: 9
Training loss: 0.28721956487064193
Validation loss: 2.3039545911739467

Epoch: 5| Step: 10
Training loss: 0.48803587279322924
Validation loss: 2.311695171397408

Epoch: 736| Step: 0
Training loss: 0.396684530314077
Validation loss: 2.329608409132709

Epoch: 5| Step: 1
Training loss: 0.3024814779940055
Validation loss: 2.3184476205437425

Epoch: 5| Step: 2
Training loss: 0.3754205134120965
Validation loss: 2.3231621709127976

Epoch: 5| Step: 3
Training loss: 0.508059925543501
Validation loss: 2.3757396500460097

Epoch: 5| Step: 4
Training loss: 0.39702015647717726
Validation loss: 2.3993661348086874

Epoch: 5| Step: 5
Training loss: 0.27771296572893656
Validation loss: 2.3510498429981763

Epoch: 5| Step: 6
Training loss: 0.2308590299987797
Validation loss: 2.333153228430331

Epoch: 5| Step: 7
Training loss: 0.25691907864163394
Validation loss: 2.3113718626270843

Epoch: 5| Step: 8
Training loss: 0.30524864852724815
Validation loss: 2.2970386095550324

Epoch: 5| Step: 9
Training loss: 0.4098064565906732
Validation loss: 2.3122667978263514

Epoch: 5| Step: 10
Training loss: 0.24838493618819024
Validation loss: 2.3326156943871332

Epoch: 737| Step: 0
Training loss: 0.30788151117487483
Validation loss: 2.3409457192320673

Epoch: 5| Step: 1
Training loss: 0.3132228953933921
Validation loss: 2.360132894991643

Epoch: 5| Step: 2
Training loss: 0.23265111661362664
Validation loss: 2.380814485065244

Epoch: 5| Step: 3
Training loss: 0.373398360591481
Validation loss: 2.416973577373674

Epoch: 5| Step: 4
Training loss: 0.4543612814174253
Validation loss: 2.4313082560148986

Epoch: 5| Step: 5
Training loss: 0.3143715367590953
Validation loss: 2.4626607871659183

Epoch: 5| Step: 6
Training loss: 0.28925528412511736
Validation loss: 2.4372823463953015

Epoch: 5| Step: 7
Training loss: 0.26432524368439425
Validation loss: 2.393171656514326

Epoch: 5| Step: 8
Training loss: 0.2729666334134577
Validation loss: 2.3664313265050527

Epoch: 5| Step: 9
Training loss: 0.3308776224412168
Validation loss: 2.3465022956910317

Epoch: 5| Step: 10
Training loss: 0.297772406394001
Validation loss: 2.329617463699165

Epoch: 738| Step: 0
Training loss: 0.23250490997370052
Validation loss: 2.3057432676064837

Epoch: 5| Step: 1
Training loss: 0.2799651946421035
Validation loss: 2.288352390543924

Epoch: 5| Step: 2
Training loss: 0.33705282256332836
Validation loss: 2.30192402630097

Epoch: 5| Step: 3
Training loss: 0.2624293686437627
Validation loss: 2.312697799834822

Epoch: 5| Step: 4
Training loss: 0.32330447285478675
Validation loss: 2.301849731640917

Epoch: 5| Step: 5
Training loss: 0.25802649662074245
Validation loss: 2.285563592651247

Epoch: 5| Step: 6
Training loss: 0.3633941967029994
Validation loss: 2.313763817167498

Epoch: 5| Step: 7
Training loss: 0.27136844108119573
Validation loss: 2.3201166902229824

Epoch: 5| Step: 8
Training loss: 0.2972256070844977
Validation loss: 2.341992787757254

Epoch: 5| Step: 9
Training loss: 0.4343395520572853
Validation loss: 2.3367382848195315

Epoch: 5| Step: 10
Training loss: 0.21531762833986454
Validation loss: 2.3218444063006722

Epoch: 739| Step: 0
Training loss: 0.2801733602563469
Validation loss: 2.3379364953585413

Epoch: 5| Step: 1
Training loss: 0.2197358701641908
Validation loss: 2.2780823290968257

Epoch: 5| Step: 2
Training loss: 0.3181167098953093
Validation loss: 2.313083405473861

Epoch: 5| Step: 3
Training loss: 0.1930868945444364
Validation loss: 2.288071035729518

Epoch: 5| Step: 4
Training loss: 0.2635281347612894
Validation loss: 2.2770754813158804

Epoch: 5| Step: 5
Training loss: 0.3077623297377476
Validation loss: 2.2646731393019626

Epoch: 5| Step: 6
Training loss: 0.3264315935981305
Validation loss: 2.270577413952276

Epoch: 5| Step: 7
Training loss: 0.21870136571842774
Validation loss: 2.307449685036591

Epoch: 5| Step: 8
Training loss: 0.17666009446412415
Validation loss: 2.3271332879288744

Epoch: 5| Step: 9
Training loss: 0.18690045186616291
Validation loss: 2.3373526438062613

Epoch: 5| Step: 10
Training loss: 0.25090803702608055
Validation loss: 2.356800197503823

Epoch: 740| Step: 0
Training loss: 0.23816097851283605
Validation loss: 2.3671332524041366

Epoch: 5| Step: 1
Training loss: 0.23956177535023354
Validation loss: 2.360475926150938

Epoch: 5| Step: 2
Training loss: 0.2070038975334889
Validation loss: 2.3830996959767146

Epoch: 5| Step: 3
Training loss: 0.22106085118020485
Validation loss: 2.3562595968474533

Epoch: 5| Step: 4
Training loss: 0.2660864720270433
Validation loss: 2.333373913946773

Epoch: 5| Step: 5
Training loss: 0.2626301425800736
Validation loss: 2.3251748005969803

Epoch: 5| Step: 6
Training loss: 0.2624184237608398
Validation loss: 2.314041761168412

Epoch: 5| Step: 7
Training loss: 0.2649440170480035
Validation loss: 2.30362764505532

Epoch: 5| Step: 8
Training loss: 0.36902969954277454
Validation loss: 2.312009237729271

Epoch: 5| Step: 9
Training loss: 0.2533187524987203
Validation loss: 2.301189873038718

Epoch: 5| Step: 10
Training loss: 0.3137572983352644
Validation loss: 2.30355846794895

Epoch: 741| Step: 0
Training loss: 0.24804571106404835
Validation loss: 2.293744948334278

Epoch: 5| Step: 1
Training loss: 0.23106297166150394
Validation loss: 2.28892467285014

Epoch: 5| Step: 2
Training loss: 0.29358199469078616
Validation loss: 2.2825467554939776

Epoch: 5| Step: 3
Training loss: 0.2749948837064431
Validation loss: 2.2623813922354783

Epoch: 5| Step: 4
Training loss: 0.2182765162015411
Validation loss: 2.284302629934026

Epoch: 5| Step: 5
Training loss: 0.3043398463179717
Validation loss: 2.2959093557610695

Epoch: 5| Step: 6
Training loss: 0.2545820924949271
Validation loss: 2.3299821536585577

Epoch: 5| Step: 7
Training loss: 0.2777509386620167
Validation loss: 2.3113158946217762

Epoch: 5| Step: 8
Training loss: 0.25232276120603836
Validation loss: 2.3712846903079456

Epoch: 5| Step: 9
Training loss: 0.30748232352615656
Validation loss: 2.379861763126849

Epoch: 5| Step: 10
Training loss: 0.2255476716849696
Validation loss: 2.371848279253499

Epoch: 742| Step: 0
Training loss: 0.16108021889292445
Validation loss: 2.332817370710191

Epoch: 5| Step: 1
Training loss: 0.20006434180506205
Validation loss: 2.308038033657481

Epoch: 5| Step: 2
Training loss: 0.19884066139375176
Validation loss: 2.299281566343909

Epoch: 5| Step: 3
Training loss: 0.23903817196395336
Validation loss: 2.3058385600765288

Epoch: 5| Step: 4
Training loss: 0.2586888533135402
Validation loss: 2.2767436917231967

Epoch: 5| Step: 5
Training loss: 0.21014296159956306
Validation loss: 2.259075293229287

Epoch: 5| Step: 6
Training loss: 0.22622713392319696
Validation loss: 2.2689475879005747

Epoch: 5| Step: 7
Training loss: 0.20349757248077321
Validation loss: 2.2792822436342437

Epoch: 5| Step: 8
Training loss: 0.24263262604860028
Validation loss: 2.3232550859883125

Epoch: 5| Step: 9
Training loss: 0.2292116438915464
Validation loss: 2.355317549836318

Epoch: 5| Step: 10
Training loss: 0.20609866933902066
Validation loss: 2.3292789422555242

Epoch: 743| Step: 0
Training loss: 0.22391557932263045
Validation loss: 2.3924795130853567

Epoch: 5| Step: 1
Training loss: 0.21940361025218855
Validation loss: 2.3594549358810704

Epoch: 5| Step: 2
Training loss: 0.23342572136543105
Validation loss: 2.406317843229372

Epoch: 5| Step: 3
Training loss: 0.12049139860080815
Validation loss: 2.35121707152802

Epoch: 5| Step: 4
Training loss: 0.19787720027406352
Validation loss: 2.365357869564278

Epoch: 5| Step: 5
Training loss: 0.18568244799710565
Validation loss: 2.3392070212272125

Epoch: 5| Step: 6
Training loss: 0.2141235243695794
Validation loss: 2.341091084507695

Epoch: 5| Step: 7
Training loss: 0.17240503253959805
Validation loss: 2.3408780041547215

Epoch: 5| Step: 8
Training loss: 0.13736296511738053
Validation loss: 2.3405637219408386

Epoch: 5| Step: 9
Training loss: 0.16121403352183006
Validation loss: 2.3203912749718336

Epoch: 5| Step: 10
Training loss: 0.19270629602506614
Validation loss: 2.320881406695943

Epoch: 744| Step: 0
Training loss: 0.19114802906705103
Validation loss: 2.304209836776356

Epoch: 5| Step: 1
Training loss: 0.178281027236251
Validation loss: 2.2828651056675002

Epoch: 5| Step: 2
Training loss: 0.18204692805804062
Validation loss: 2.313525779721174

Epoch: 5| Step: 3
Training loss: 0.23924437504616491
Validation loss: 2.296705610703626

Epoch: 5| Step: 4
Training loss: 0.14052708846460712
Validation loss: 2.3133571901829217

Epoch: 5| Step: 5
Training loss: 0.14200784342429112
Validation loss: 2.3217247707838435

Epoch: 5| Step: 6
Training loss: 0.17505039230350117
Validation loss: 2.344699753050761

Epoch: 5| Step: 7
Training loss: 0.17040640709368013
Validation loss: 2.3795460206552925

Epoch: 5| Step: 8
Training loss: 0.1477226246902033
Validation loss: 2.392240330965703

Epoch: 5| Step: 9
Training loss: 0.1513379653287517
Validation loss: 2.3811142944548607

Epoch: 5| Step: 10
Training loss: 0.16726081835893003
Validation loss: 2.4279268610343787

Epoch: 745| Step: 0
Training loss: 0.21369472500039022
Validation loss: 2.4238821825507064

Epoch: 5| Step: 1
Training loss: 0.2367337741427488
Validation loss: 2.455637062395223

Epoch: 5| Step: 2
Training loss: 0.22045717629402004
Validation loss: 2.4232217871270882

Epoch: 5| Step: 3
Training loss: 0.15578856281728176
Validation loss: 2.3815846970699486

Epoch: 5| Step: 4
Training loss: 0.16810184018781885
Validation loss: 2.3515640033660836

Epoch: 5| Step: 5
Training loss: 0.15598260530096303
Validation loss: 2.3041084831686067

Epoch: 5| Step: 6
Training loss: 0.21873988400638195
Validation loss: 2.292356879553844

Epoch: 5| Step: 7
Training loss: 0.22987118531982967
Validation loss: 2.2850834486683027

Epoch: 5| Step: 8
Training loss: 0.20243957305240118
Validation loss: 2.260690606612588

Epoch: 5| Step: 9
Training loss: 0.17893463475967605
Validation loss: 2.2712347192015634

Epoch: 5| Step: 10
Training loss: 0.18297140681474056
Validation loss: 2.2718695129589164

Epoch: 746| Step: 0
Training loss: 0.17816434977716739
Validation loss: 2.317979730688132

Epoch: 5| Step: 1
Training loss: 0.16236179302024062
Validation loss: 2.3001868322800063

Epoch: 5| Step: 2
Training loss: 0.19069023892046352
Validation loss: 2.3165269625273988

Epoch: 5| Step: 3
Training loss: 0.17602412081827884
Validation loss: 2.287915840065933

Epoch: 5| Step: 4
Training loss: 0.14833033608460552
Validation loss: 2.2996895272466653

Epoch: 5| Step: 5
Training loss: 0.1233255356911072
Validation loss: 2.2942102167774454

Epoch: 5| Step: 6
Training loss: 0.16946011866079355
Validation loss: 2.306896742488857

Epoch: 5| Step: 7
Training loss: 0.1521708289577662
Validation loss: 2.3171824995407673

Epoch: 5| Step: 8
Training loss: 0.18382220562289922
Validation loss: 2.303842806408958

Epoch: 5| Step: 9
Training loss: 0.13665913235677565
Validation loss: 2.297973576021016

Epoch: 5| Step: 10
Training loss: 0.0953111112993726
Validation loss: 2.3072282043572248

Epoch: 747| Step: 0
Training loss: 0.174507196983669
Validation loss: 2.322832819435542

Epoch: 5| Step: 1
Training loss: 0.15183158514970171
Validation loss: 2.3230768997622895

Epoch: 5| Step: 2
Training loss: 0.13161167567892845
Validation loss: 2.3096369119966904

Epoch: 5| Step: 3
Training loss: 0.1394771846350746
Validation loss: 2.3027642363708303

Epoch: 5| Step: 4
Training loss: 0.14666728362198414
Validation loss: 2.3133456544443662

Epoch: 5| Step: 5
Training loss: 0.16085410434152855
Validation loss: 2.325138450621516

Epoch: 5| Step: 6
Training loss: 0.11353329866819997
Validation loss: 2.330076410828472

Epoch: 5| Step: 7
Training loss: 0.1593851916009065
Validation loss: 2.338204483669874

Epoch: 5| Step: 8
Training loss: 0.15097019063672426
Validation loss: 2.335547548788635

Epoch: 5| Step: 9
Training loss: 0.11923626672291117
Validation loss: 2.3492019749244544

Epoch: 5| Step: 10
Training loss: 0.17681109431487743
Validation loss: 2.3619083917134924

Epoch: 748| Step: 0
Training loss: 0.1324597470526157
Validation loss: 2.3318974945136164

Epoch: 5| Step: 1
Training loss: 0.13591450107523656
Validation loss: 2.3171513657763905

Epoch: 5| Step: 2
Training loss: 0.11792347193837487
Validation loss: 2.316590530128254

Epoch: 5| Step: 3
Training loss: 0.15690310003320745
Validation loss: 2.316508050494704

Epoch: 5| Step: 4
Training loss: 0.1102442388291656
Validation loss: 2.307864160044429

Epoch: 5| Step: 5
Training loss: 0.11983152085915649
Validation loss: 2.3219246394355353

Epoch: 5| Step: 6
Training loss: 0.10224104215718328
Validation loss: 2.3159997449150684

Epoch: 5| Step: 7
Training loss: 0.14943784636645221
Validation loss: 2.307915598593544

Epoch: 5| Step: 8
Training loss: 0.19207656030926046
Validation loss: 2.3199013535346205

Epoch: 5| Step: 9
Training loss: 0.19084518293970573
Validation loss: 2.3298375257220294

Epoch: 5| Step: 10
Training loss: 0.21103147779769046
Validation loss: 2.287748928726302

Epoch: 749| Step: 0
Training loss: 0.1774657388650999
Validation loss: 2.334790331578497

Epoch: 5| Step: 1
Training loss: 0.14377247256346073
Validation loss: 2.32099102550345

Epoch: 5| Step: 2
Training loss: 0.11202361967392686
Validation loss: 2.346407907334042

Epoch: 5| Step: 3
Training loss: 0.13483128123137364
Validation loss: 2.343158570734865

Epoch: 5| Step: 4
Training loss: 0.10039691385839603
Validation loss: 2.3282199038355254

Epoch: 5| Step: 5
Training loss: 0.1345659103005703
Validation loss: 2.305391117822331

Epoch: 5| Step: 6
Training loss: 0.13011240922622527
Validation loss: 2.2937284386722254

Epoch: 5| Step: 7
Training loss: 0.12065213184892001
Validation loss: 2.3153976349842877

Epoch: 5| Step: 8
Training loss: 0.11919601903674625
Validation loss: 2.304411585000085

Epoch: 5| Step: 9
Training loss: 0.14972731844111337
Validation loss: 2.318920633003462

Epoch: 5| Step: 10
Training loss: 0.12055721553203444
Validation loss: 2.300529469686015

Epoch: 750| Step: 0
Training loss: 0.15650566165786522
Validation loss: 2.2738209361502646

Epoch: 5| Step: 1
Training loss: 0.13873001679652033
Validation loss: 2.265173340085311

Epoch: 5| Step: 2
Training loss: 0.07725896945036557
Validation loss: 2.2771183222398683

Epoch: 5| Step: 3
Training loss: 0.17967135937387266
Validation loss: 2.2718456448936797

Epoch: 5| Step: 4
Training loss: 0.16311173035190626
Validation loss: 2.288148862236895

Epoch: 5| Step: 5
Training loss: 0.1696065739769798
Validation loss: 2.2631957068714663

Epoch: 5| Step: 6
Training loss: 0.1571324700709456
Validation loss: 2.2743438097097934

Epoch: 5| Step: 7
Training loss: 0.13256668736086616
Validation loss: 2.290971746451916

Epoch: 5| Step: 8
Training loss: 0.14242748899166552
Validation loss: 2.279932690528919

Epoch: 5| Step: 9
Training loss: 0.09902136347176854
Validation loss: 2.300501166746954

Epoch: 5| Step: 10
Training loss: 0.08887994590811442
Validation loss: 2.2824791229378354

Epoch: 751| Step: 0
Training loss: 0.1336021719056999
Validation loss: 2.2819835204459

Epoch: 5| Step: 1
Training loss: 0.10506690259658025
Validation loss: 2.3112214291786355

Epoch: 5| Step: 2
Training loss: 0.12591037933876137
Validation loss: 2.299000061498899

Epoch: 5| Step: 3
Training loss: 0.1309585053476864
Validation loss: 2.3163687846095398

Epoch: 5| Step: 4
Training loss: 0.11148873672828032
Validation loss: 2.3144289760974814

Epoch: 5| Step: 5
Training loss: 0.12798763011276004
Validation loss: 2.2820151727664904

Epoch: 5| Step: 6
Training loss: 0.13426313845315116
Validation loss: 2.297212572134507

Epoch: 5| Step: 7
Training loss: 0.1503314731741676
Validation loss: 2.3139457207706027

Epoch: 5| Step: 8
Training loss: 0.12273097738350425
Validation loss: 2.306034829609341

Epoch: 5| Step: 9
Training loss: 0.1178471634979148
Validation loss: 2.301763810171328

Epoch: 5| Step: 10
Training loss: 0.12441459308313509
Validation loss: 2.31191672840681

Epoch: 752| Step: 0
Training loss: 0.11954826439581213
Validation loss: 2.3200987687760866

Epoch: 5| Step: 1
Training loss: 0.1124851808125665
Validation loss: 2.3377339068667777

Epoch: 5| Step: 2
Training loss: 0.13581409196539418
Validation loss: 2.329078840651957

Epoch: 5| Step: 3
Training loss: 0.10458825499310087
Validation loss: 2.327355082366238

Epoch: 5| Step: 4
Training loss: 0.14499504190838977
Validation loss: 2.3124705431657606

Epoch: 5| Step: 5
Training loss: 0.10070834073098381
Validation loss: 2.315381333415444

Epoch: 5| Step: 6
Training loss: 0.09578824636909554
Validation loss: 2.3089965679316915

Epoch: 5| Step: 7
Training loss: 0.1220856428056757
Validation loss: 2.298777578250538

Epoch: 5| Step: 8
Training loss: 0.08819224736536212
Validation loss: 2.3185919074441013

Epoch: 5| Step: 9
Training loss: 0.1157842625034306
Validation loss: 2.3110338212022024

Epoch: 5| Step: 10
Training loss: 0.13114253765153583
Validation loss: 2.304638832653256

Epoch: 753| Step: 0
Training loss: 0.10856470467443165
Validation loss: 2.282156460338679

Epoch: 5| Step: 1
Training loss: 0.11107259838732768
Validation loss: 2.3060356378219455

Epoch: 5| Step: 2
Training loss: 0.1014576150266898
Validation loss: 2.292603290333436

Epoch: 5| Step: 3
Training loss: 0.08604733535694714
Validation loss: 2.292692938716774

Epoch: 5| Step: 4
Training loss: 0.10578057322715288
Validation loss: 2.2772205686522393

Epoch: 5| Step: 5
Training loss: 0.1350543895185675
Validation loss: 2.2775517355359156

Epoch: 5| Step: 6
Training loss: 0.10574444746907675
Validation loss: 2.2876357289941844

Epoch: 5| Step: 7
Training loss: 0.13406061889200116
Validation loss: 2.3047653960948775

Epoch: 5| Step: 8
Training loss: 0.11073956595787812
Validation loss: 2.3033217543496494

Epoch: 5| Step: 9
Training loss: 0.1167186577220792
Validation loss: 2.298030628128932

Epoch: 5| Step: 10
Training loss: 0.11424489641137674
Validation loss: 2.2783503453268246

Epoch: 754| Step: 0
Training loss: 0.12103896670755353
Validation loss: 2.296726086647067

Epoch: 5| Step: 1
Training loss: 0.12323130681994814
Validation loss: 2.301315537792496

Epoch: 5| Step: 2
Training loss: 0.0938463461047129
Validation loss: 2.307857036292064

Epoch: 5| Step: 3
Training loss: 0.10478312996134345
Validation loss: 2.3178255076214422

Epoch: 5| Step: 4
Training loss: 0.13208158707241535
Validation loss: 2.2876447659037717

Epoch: 5| Step: 5
Training loss: 0.1270045983062146
Validation loss: 2.295462006781192

Epoch: 5| Step: 6
Training loss: 0.09467649119654306
Validation loss: 2.3008376213382866

Epoch: 5| Step: 7
Training loss: 0.1212843847985259
Validation loss: 2.3306806045856376

Epoch: 5| Step: 8
Training loss: 0.07240591736529012
Validation loss: 2.2901430794815023

Epoch: 5| Step: 9
Training loss: 0.1293892049592886
Validation loss: 2.309513184974036

Epoch: 5| Step: 10
Training loss: 0.09117527270584859
Validation loss: 2.2953109812799375

Epoch: 755| Step: 0
Training loss: 0.1395238106827968
Validation loss: 2.2866450138777563

Epoch: 5| Step: 1
Training loss: 0.10687469358288747
Validation loss: 2.29064804569414

Epoch: 5| Step: 2
Training loss: 0.11155340339936236
Validation loss: 2.2982031653078447

Epoch: 5| Step: 3
Training loss: 0.14550796611188935
Validation loss: 2.3217757752736934

Epoch: 5| Step: 4
Training loss: 0.09134108939229137
Validation loss: 2.276307795536788

Epoch: 5| Step: 5
Training loss: 0.1376797146451086
Validation loss: 2.3134664704301335

Epoch: 5| Step: 6
Training loss: 0.12970688743910752
Validation loss: 2.283338564718619

Epoch: 5| Step: 7
Training loss: 0.1152856680296729
Validation loss: 2.2917572447326786

Epoch: 5| Step: 8
Training loss: 0.10220306842949939
Validation loss: 2.298689464216832

Epoch: 5| Step: 9
Training loss: 0.11545066013639983
Validation loss: 2.2927964763811044

Epoch: 5| Step: 10
Training loss: 0.12060953820656503
Validation loss: 2.2882977937642366

Epoch: 756| Step: 0
Training loss: 0.1162481288541414
Validation loss: 2.3143430713528335

Epoch: 5| Step: 1
Training loss: 0.07163992852316525
Validation loss: 2.304692583476516

Epoch: 5| Step: 2
Training loss: 0.09644486587501343
Validation loss: 2.336592848978975

Epoch: 5| Step: 3
Training loss: 0.12066529600921382
Validation loss: 2.346109235686483

Epoch: 5| Step: 4
Training loss: 0.14158515835157026
Validation loss: 2.3389706782117825

Epoch: 5| Step: 5
Training loss: 0.09446725058177999
Validation loss: 2.3332948068069173

Epoch: 5| Step: 6
Training loss: 0.12302432913325982
Validation loss: 2.3114192646707687

Epoch: 5| Step: 7
Training loss: 0.12199622385442478
Validation loss: 2.3242822679950677

Epoch: 5| Step: 8
Training loss: 0.11353178108851322
Validation loss: 2.306259896426418

Epoch: 5| Step: 9
Training loss: 0.09540439713275416
Validation loss: 2.287052184405761

Epoch: 5| Step: 10
Training loss: 0.11036298068228456
Validation loss: 2.2916865514822913

Epoch: 757| Step: 0
Training loss: 0.0995926468958359
Validation loss: 2.310748423857663

Epoch: 5| Step: 1
Training loss: 0.10337728577292761
Validation loss: 2.3013185087997523

Epoch: 5| Step: 2
Training loss: 0.13203236111054897
Validation loss: 2.302967660238872

Epoch: 5| Step: 3
Training loss: 0.10365954776425332
Validation loss: 2.3077907820090497

Epoch: 5| Step: 4
Training loss: 0.07679234181837105
Validation loss: 2.3447653361624017

Epoch: 5| Step: 5
Training loss: 0.10366005987584138
Validation loss: 2.3121865128493364

Epoch: 5| Step: 6
Training loss: 0.11716728036013449
Validation loss: 2.3200069240223464

Epoch: 5| Step: 7
Training loss: 0.10016995122035419
Validation loss: 2.2957464563459165

Epoch: 5| Step: 8
Training loss: 0.09933276665292436
Validation loss: 2.3147992308466923

Epoch: 5| Step: 9
Training loss: 0.1577270963651191
Validation loss: 2.326154409081098

Epoch: 5| Step: 10
Training loss: 0.11582559120024047
Validation loss: 2.3245645697524946

Epoch: 758| Step: 0
Training loss: 0.1019753355190465
Validation loss: 2.328757390202592

Epoch: 5| Step: 1
Training loss: 0.07864021645418426
Validation loss: 2.285910407002036

Epoch: 5| Step: 2
Training loss: 0.08793739028366662
Validation loss: 2.287366496426145

Epoch: 5| Step: 3
Training loss: 0.0976759747612159
Validation loss: 2.281076132182914

Epoch: 5| Step: 4
Training loss: 0.08518921942263062
Validation loss: 2.27124086689282

Epoch: 5| Step: 5
Training loss: 0.1192581425776882
Validation loss: 2.2698337330129834

Epoch: 5| Step: 6
Training loss: 0.06880829071207745
Validation loss: 2.260947508272146

Epoch: 5| Step: 7
Training loss: 0.11254663113582597
Validation loss: 2.2366281054122688

Epoch: 5| Step: 8
Training loss: 0.0962162615038289
Validation loss: 2.2592883317563173

Epoch: 5| Step: 9
Training loss: 0.09015884809700686
Validation loss: 2.2533484783720654

Epoch: 5| Step: 10
Training loss: 0.13942539970622123
Validation loss: 2.255173832931832

Epoch: 759| Step: 0
Training loss: 0.10443089371988633
Validation loss: 2.2353439731252505

Epoch: 5| Step: 1
Training loss: 0.10389991719444085
Validation loss: 2.2601750233668785

Epoch: 5| Step: 2
Training loss: 0.11389789379928668
Validation loss: 2.279989102272237

Epoch: 5| Step: 3
Training loss: 0.12173358250250955
Validation loss: 2.2805885899078193

Epoch: 5| Step: 4
Training loss: 0.11295443698096304
Validation loss: 2.2886527646469776

Epoch: 5| Step: 5
Training loss: 0.08312042675488397
Validation loss: 2.298533360177983

Epoch: 5| Step: 6
Training loss: 0.11524350324133974
Validation loss: 2.3040232840543116

Epoch: 5| Step: 7
Training loss: 0.12302108903177848
Validation loss: 2.3036503931411945

Epoch: 5| Step: 8
Training loss: 0.07080735143233641
Validation loss: 2.28949162994723

Epoch: 5| Step: 9
Training loss: 0.13714448175073837
Validation loss: 2.291894612390945

Epoch: 5| Step: 10
Training loss: 0.10033591223026353
Validation loss: 2.2922242687888916

Epoch: 760| Step: 0
Training loss: 0.07583372852801917
Validation loss: 2.2683861444356577

Epoch: 5| Step: 1
Training loss: 0.10496266236217153
Validation loss: 2.301468001100794

Epoch: 5| Step: 2
Training loss: 0.09828197287944102
Validation loss: 2.297649701307781

Epoch: 5| Step: 3
Training loss: 0.07570729961143985
Validation loss: 2.2805661817173557

Epoch: 5| Step: 4
Training loss: 0.06780223646809388
Validation loss: 2.2954925273061795

Epoch: 5| Step: 5
Training loss: 0.09062958245366104
Validation loss: 2.279397048715113

Epoch: 5| Step: 6
Training loss: 0.12113933320564027
Validation loss: 2.2888478813340254

Epoch: 5| Step: 7
Training loss: 0.1244419500814035
Validation loss: 2.2757170417923724

Epoch: 5| Step: 8
Training loss: 0.13521069135823677
Validation loss: 2.2677906688555787

Epoch: 5| Step: 9
Training loss: 0.07484900628309728
Validation loss: 2.2930100100752937

Epoch: 5| Step: 10
Training loss: 0.160458686256747
Validation loss: 2.2764681151455135

Epoch: 761| Step: 0
Training loss: 0.11514333587863557
Validation loss: 2.308787913208665

Epoch: 5| Step: 1
Training loss: 0.1264253724113842
Validation loss: 2.291653021345784

Epoch: 5| Step: 2
Training loss: 0.08581164746475707
Validation loss: 2.286816766623422

Epoch: 5| Step: 3
Training loss: 0.06628566901850358
Validation loss: 2.2856358761988105

Epoch: 5| Step: 4
Training loss: 0.08921395232133038
Validation loss: 2.304375885951313

Epoch: 5| Step: 5
Training loss: 0.11445323826911191
Validation loss: 2.313697411809154

Epoch: 5| Step: 6
Training loss: 0.11613254146756015
Validation loss: 2.3177817152038354

Epoch: 5| Step: 7
Training loss: 0.12385701856251985
Validation loss: 2.3329376703408142

Epoch: 5| Step: 8
Training loss: 0.13504523833930587
Validation loss: 2.3069447465586954

Epoch: 5| Step: 9
Training loss: 0.07718188731640668
Validation loss: 2.318415393020047

Epoch: 5| Step: 10
Training loss: 0.10753023144578544
Validation loss: 2.2986277052053135

Epoch: 762| Step: 0
Training loss: 0.1585530308657815
Validation loss: 2.311637641132515

Epoch: 5| Step: 1
Training loss: 0.07035637519764629
Validation loss: 2.3246380243128812

Epoch: 5| Step: 2
Training loss: 0.08531257330276498
Validation loss: 2.2827839174733118

Epoch: 5| Step: 3
Training loss: 0.09682761540878221
Validation loss: 2.297157872338116

Epoch: 5| Step: 4
Training loss: 0.09734871123026083
Validation loss: 2.2703957957937124

Epoch: 5| Step: 5
Training loss: 0.09780908545880818
Validation loss: 2.3016867024275998

Epoch: 5| Step: 6
Training loss: 0.12855466667042983
Validation loss: 2.307344173873842

Epoch: 5| Step: 7
Training loss: 0.09244058024708175
Validation loss: 2.325061911328598

Epoch: 5| Step: 8
Training loss: 0.08939980621143541
Validation loss: 2.2918942488562224

Epoch: 5| Step: 9
Training loss: 0.09619386059878182
Validation loss: 2.2849734232936147

Epoch: 5| Step: 10
Training loss: 0.08352149331660781
Validation loss: 2.2575905607718925

Epoch: 763| Step: 0
Training loss: 0.06179905266668392
Validation loss: 2.266899070310565

Epoch: 5| Step: 1
Training loss: 0.13333214750606998
Validation loss: 2.2857339226136295

Epoch: 5| Step: 2
Training loss: 0.09481839516668678
Validation loss: 2.258113561832273

Epoch: 5| Step: 3
Training loss: 0.07397625232042924
Validation loss: 2.269119014022795

Epoch: 5| Step: 4
Training loss: 0.06430966856018387
Validation loss: 2.288300148129144

Epoch: 5| Step: 5
Training loss: 0.11814606742345769
Validation loss: 2.2386967805646565

Epoch: 5| Step: 6
Training loss: 0.09322656098601304
Validation loss: 2.2880906897998523

Epoch: 5| Step: 7
Training loss: 0.11326617929904742
Validation loss: 2.266800863483057

Epoch: 5| Step: 8
Training loss: 0.11824447874729514
Validation loss: 2.257967084402856

Epoch: 5| Step: 9
Training loss: 0.10440737410679224
Validation loss: 2.2697691755728746

Epoch: 5| Step: 10
Training loss: 0.10418467862646119
Validation loss: 2.279268841542473

Epoch: 764| Step: 0
Training loss: 0.08747790709090143
Validation loss: 2.2514213427415526

Epoch: 5| Step: 1
Training loss: 0.12155739408228547
Validation loss: 2.2537561995353035

Epoch: 5| Step: 2
Training loss: 0.08341261108974278
Validation loss: 2.248216324235221

Epoch: 5| Step: 3
Training loss: 0.14780766101158657
Validation loss: 2.2515042550848543

Epoch: 5| Step: 4
Training loss: 0.07746921319080602
Validation loss: 2.2882894658021184

Epoch: 5| Step: 5
Training loss: 0.07389143872997765
Validation loss: 2.260248119984392

Epoch: 5| Step: 6
Training loss: 0.1336103903016196
Validation loss: 2.2650055725605713

Epoch: 5| Step: 7
Training loss: 0.08332879891079246
Validation loss: 2.2675716098369136

Epoch: 5| Step: 8
Training loss: 0.10973986157021587
Validation loss: 2.2750786708434987

Epoch: 5| Step: 9
Training loss: 0.11915338166528959
Validation loss: 2.2812593925980584

Epoch: 5| Step: 10
Training loss: 0.12806671026187083
Validation loss: 2.28181712874419

Epoch: 765| Step: 0
Training loss: 0.1256985368715181
Validation loss: 2.279088617341107

Epoch: 5| Step: 1
Training loss: 0.09762033278857982
Validation loss: 2.267327262301088

Epoch: 5| Step: 2
Training loss: 0.07698146641878847
Validation loss: 2.27728361321482

Epoch: 5| Step: 3
Training loss: 0.09835021921710604
Validation loss: 2.269680962098749

Epoch: 5| Step: 4
Training loss: 0.08669810575616012
Validation loss: 2.253623031685562

Epoch: 5| Step: 5
Training loss: 0.11824283260047241
Validation loss: 2.2762506432741922

Epoch: 5| Step: 6
Training loss: 0.09965891634561129
Validation loss: 2.3036295664264763

Epoch: 5| Step: 7
Training loss: 0.14618817582571536
Validation loss: 2.2758004292137284

Epoch: 5| Step: 8
Training loss: 0.08437053207206262
Validation loss: 2.2789736493595396

Epoch: 5| Step: 9
Training loss: 0.12879395651203532
Validation loss: 2.295659915587554

Epoch: 5| Step: 10
Training loss: 0.1115010407734951
Validation loss: 2.2975963670486124

Epoch: 766| Step: 0
Training loss: 0.11004781695646168
Validation loss: 2.296126303281717

Epoch: 5| Step: 1
Training loss: 0.0640838803981107
Validation loss: 2.2712281053214354

Epoch: 5| Step: 2
Training loss: 0.09212310631234287
Validation loss: 2.2687957765381594

Epoch: 5| Step: 3
Training loss: 0.1282047052884615
Validation loss: 2.3027180539230607

Epoch: 5| Step: 4
Training loss: 0.10083656197822476
Validation loss: 2.250972236947859

Epoch: 5| Step: 5
Training loss: 0.10977086736846636
Validation loss: 2.283000516591941

Epoch: 5| Step: 6
Training loss: 0.09156455917288789
Validation loss: 2.2807794552850282

Epoch: 5| Step: 7
Training loss: 0.11524342646853122
Validation loss: 2.2677860780636236

Epoch: 5| Step: 8
Training loss: 0.09621318338260997
Validation loss: 2.277912241241397

Epoch: 5| Step: 9
Training loss: 0.09029530474532987
Validation loss: 2.2549459492374475

Epoch: 5| Step: 10
Training loss: 0.10786312683733215
Validation loss: 2.2640175027192475

Epoch: 767| Step: 0
Training loss: 0.13857299341758206
Validation loss: 2.2471423694114097

Epoch: 5| Step: 1
Training loss: 0.08071994023769152
Validation loss: 2.2694929915814224

Epoch: 5| Step: 2
Training loss: 0.05640764043539287
Validation loss: 2.261869081212221

Epoch: 5| Step: 3
Training loss: 0.11526938892469346
Validation loss: 2.2530371393114117

Epoch: 5| Step: 4
Training loss: 0.1036005841096729
Validation loss: 2.250938218775843

Epoch: 5| Step: 5
Training loss: 0.08941235841899613
Validation loss: 2.291436096703884

Epoch: 5| Step: 6
Training loss: 0.06462323974088063
Validation loss: 2.2828454183992233

Epoch: 5| Step: 7
Training loss: 0.09443624486821284
Validation loss: 2.2895298206795065

Epoch: 5| Step: 8
Training loss: 0.09595381736226047
Validation loss: 2.2612466159414915

Epoch: 5| Step: 9
Training loss: 0.10482100862634545
Validation loss: 2.2820637260674834

Epoch: 5| Step: 10
Training loss: 0.10940704557450451
Validation loss: 2.2772950628569704

Epoch: 768| Step: 0
Training loss: 0.10585789063598919
Validation loss: 2.27604059474784

Epoch: 5| Step: 1
Training loss: 0.08719203463336021
Validation loss: 2.2762662328544803

Epoch: 5| Step: 2
Training loss: 0.09446850755536121
Validation loss: 2.2715447344400763

Epoch: 5| Step: 3
Training loss: 0.08368980234805899
Validation loss: 2.295338436835072

Epoch: 5| Step: 4
Training loss: 0.08299061653189449
Validation loss: 2.271607479177602

Epoch: 5| Step: 5
Training loss: 0.09194560886412761
Validation loss: 2.273860973006151

Epoch: 5| Step: 6
Training loss: 0.10444724818939886
Validation loss: 2.277110203326055

Epoch: 5| Step: 7
Training loss: 0.06627315619257329
Validation loss: 2.28120102255975

Epoch: 5| Step: 8
Training loss: 0.06469646309408836
Validation loss: 2.2655812520579572

Epoch: 5| Step: 9
Training loss: 0.0634264307864569
Validation loss: 2.2830561400536844

Epoch: 5| Step: 10
Training loss: 0.09116199781495814
Validation loss: 2.3260581347763614

Epoch: 769| Step: 0
Training loss: 0.09218575912383585
Validation loss: 2.3178308360314217

Epoch: 5| Step: 1
Training loss: 0.07915052617489164
Validation loss: 2.29754847562256

Epoch: 5| Step: 2
Training loss: 0.12644303623539352
Validation loss: 2.3049603600510538

Epoch: 5| Step: 3
Training loss: 0.14672404074549494
Validation loss: 2.32320305131132

Epoch: 5| Step: 4
Training loss: 0.09731091953720211
Validation loss: 2.270994773545794

Epoch: 5| Step: 5
Training loss: 0.09615820103421147
Validation loss: 2.2958722364764896

Epoch: 5| Step: 6
Training loss: 0.10743120326374549
Validation loss: 2.2718273138823233

Epoch: 5| Step: 7
Training loss: 0.08340500441700585
Validation loss: 2.289056000908024

Epoch: 5| Step: 8
Training loss: 0.06021359067139519
Validation loss: 2.2849637677161363

Epoch: 5| Step: 9
Training loss: 0.10124377067411933
Validation loss: 2.2898294077692727

Epoch: 5| Step: 10
Training loss: 0.09777244331137877
Validation loss: 2.2740538077155255

Epoch: 770| Step: 0
Training loss: 0.12185637227778305
Validation loss: 2.3089702177022002

Epoch: 5| Step: 1
Training loss: 0.11336475615871026
Validation loss: 2.2771538541795344

Epoch: 5| Step: 2
Training loss: 0.11082325613786952
Validation loss: 2.308376366081759

Epoch: 5| Step: 3
Training loss: 0.07401736128837942
Validation loss: 2.3069943220447735

Epoch: 5| Step: 4
Training loss: 0.11541543895221094
Validation loss: 2.298276154518078

Epoch: 5| Step: 5
Training loss: 0.09455823197978937
Validation loss: 2.2874267203275114

Epoch: 5| Step: 6
Training loss: 0.07513294172300666
Validation loss: 2.287176612276274

Epoch: 5| Step: 7
Training loss: 0.09235746588401288
Validation loss: 2.2692837020201595

Epoch: 5| Step: 8
Training loss: 0.06490140055551669
Validation loss: 2.2783022839495146

Epoch: 5| Step: 9
Training loss: 0.08769589680942186
Validation loss: 2.2891047066903405

Epoch: 5| Step: 10
Training loss: 0.05039593424661454
Validation loss: 2.2834225495330114

Epoch: 771| Step: 0
Training loss: 0.07961208816655539
Validation loss: 2.293559458580852

Epoch: 5| Step: 1
Training loss: 0.11668071440508863
Validation loss: 2.2954099300868225

Epoch: 5| Step: 2
Training loss: 0.10098704665485148
Validation loss: 2.2925102210201977

Epoch: 5| Step: 3
Training loss: 0.10739214225584157
Validation loss: 2.288502314229398

Epoch: 5| Step: 4
Training loss: 0.09236923807593267
Validation loss: 2.2730092020606585

Epoch: 5| Step: 5
Training loss: 0.09568736374750035
Validation loss: 2.2760854876277645

Epoch: 5| Step: 6
Training loss: 0.06915375455559154
Validation loss: 2.2786060294382544

Epoch: 5| Step: 7
Training loss: 0.09745600674527356
Validation loss: 2.276480986983879

Epoch: 5| Step: 8
Training loss: 0.11419787016467518
Validation loss: 2.286124292182309

Epoch: 5| Step: 9
Training loss: 0.09940623625431727
Validation loss: 2.2690271083751186

Epoch: 5| Step: 10
Training loss: 0.07249036844172536
Validation loss: 2.2694478078849127

Epoch: 772| Step: 0
Training loss: 0.06252734137567442
Validation loss: 2.305858451276882

Epoch: 5| Step: 1
Training loss: 0.09494994066494176
Validation loss: 2.289376407244243

Epoch: 5| Step: 2
Training loss: 0.08225694330708908
Validation loss: 2.3056260923176333

Epoch: 5| Step: 3
Training loss: 0.11070075529923311
Validation loss: 2.2849878852662924

Epoch: 5| Step: 4
Training loss: 0.06739582751535472
Validation loss: 2.2937396707095727

Epoch: 5| Step: 5
Training loss: 0.07912570090571018
Validation loss: 2.2818550153788038

Epoch: 5| Step: 6
Training loss: 0.10539855210372466
Validation loss: 2.2613258145879547

Epoch: 5| Step: 7
Training loss: 0.09466276281613244
Validation loss: 2.293072066145941

Epoch: 5| Step: 8
Training loss: 0.09875439713291466
Validation loss: 2.282040893674961

Epoch: 5| Step: 9
Training loss: 0.1073889335061751
Validation loss: 2.2769068630258107

Epoch: 5| Step: 10
Training loss: 0.08023728278108852
Validation loss: 2.2939046142118285

Epoch: 773| Step: 0
Training loss: 0.09104629826530806
Validation loss: 2.2571444747499148

Epoch: 5| Step: 1
Training loss: 0.07639394691307395
Validation loss: 2.2674310995193374

Epoch: 5| Step: 2
Training loss: 0.11714084809266648
Validation loss: 2.286202079553177

Epoch: 5| Step: 3
Training loss: 0.07947931923618314
Validation loss: 2.2658786075873087

Epoch: 5| Step: 4
Training loss: 0.07331279530144591
Validation loss: 2.27788419018074

Epoch: 5| Step: 5
Training loss: 0.0749659880864399
Validation loss: 2.2711436125638857

Epoch: 5| Step: 6
Training loss: 0.09531367137064069
Validation loss: 2.2803250790854293

Epoch: 5| Step: 7
Training loss: 0.06212746900930538
Validation loss: 2.2817722879611746

Epoch: 5| Step: 8
Training loss: 0.12808658355382432
Validation loss: 2.279319036979012

Epoch: 5| Step: 9
Training loss: 0.09401260789059328
Validation loss: 2.263611299966563

Epoch: 5| Step: 10
Training loss: 0.08928007582759276
Validation loss: 2.286242859451124

Epoch: 774| Step: 0
Training loss: 0.07799390283926205
Validation loss: 2.2964071891640683

Epoch: 5| Step: 1
Training loss: 0.13135802217442352
Validation loss: 2.270107706158434

Epoch: 5| Step: 2
Training loss: 0.08649990437721469
Validation loss: 2.292272214413649

Epoch: 5| Step: 3
Training loss: 0.07265576841851061
Validation loss: 2.290511119807273

Epoch: 5| Step: 4
Training loss: 0.11403775828630291
Validation loss: 2.311396893618212

Epoch: 5| Step: 5
Training loss: 0.10958453101451275
Validation loss: 2.29680164815215

Epoch: 5| Step: 6
Training loss: 0.09814879185173005
Validation loss: 2.3055093247236647

Epoch: 5| Step: 7
Training loss: 0.07947139761024861
Validation loss: 2.3269318053387047

Epoch: 5| Step: 8
Training loss: 0.08467722801432805
Validation loss: 2.337153036010937

Epoch: 5| Step: 9
Training loss: 0.10658207690472331
Validation loss: 2.3398732018769537

Epoch: 5| Step: 10
Training loss: 0.07421504500828784
Validation loss: 2.3183627592968965

Epoch: 775| Step: 0
Training loss: 0.13052917212050938
Validation loss: 2.306617529629821

Epoch: 5| Step: 1
Training loss: 0.06445493840065207
Validation loss: 2.32496926363113

Epoch: 5| Step: 2
Training loss: 0.1145594600892264
Validation loss: 2.3343881908609143

Epoch: 5| Step: 3
Training loss: 0.10196833953751427
Validation loss: 2.319627311188836

Epoch: 5| Step: 4
Training loss: 0.07803299373753007
Validation loss: 2.3287342904244053

Epoch: 5| Step: 5
Training loss: 0.07809753531257402
Validation loss: 2.313619402025548

Epoch: 5| Step: 6
Training loss: 0.0713327711489053
Validation loss: 2.3047755220935136

Epoch: 5| Step: 7
Training loss: 0.057157065306730655
Validation loss: 2.2963012710952873

Epoch: 5| Step: 8
Training loss: 0.11338084873897875
Validation loss: 2.2743105018292864

Epoch: 5| Step: 9
Training loss: 0.055376270933506576
Validation loss: 2.2674936432133213

Epoch: 5| Step: 10
Training loss: 0.09980494803377848
Validation loss: 2.262600073660318

Epoch: 776| Step: 0
Training loss: 0.10311528832049169
Validation loss: 2.2409485059944343

Epoch: 5| Step: 1
Training loss: 0.08651264319242657
Validation loss: 2.246037730498818

Epoch: 5| Step: 2
Training loss: 0.07607510729014967
Validation loss: 2.2352392766909754

Epoch: 5| Step: 3
Training loss: 0.12153680565392554
Validation loss: 2.257037113412814

Epoch: 5| Step: 4
Training loss: 0.07787790561922339
Validation loss: 2.243738753247496

Epoch: 5| Step: 5
Training loss: 0.09425888923286134
Validation loss: 2.2306031283485206

Epoch: 5| Step: 6
Training loss: 0.10650038388232323
Validation loss: 2.2329878243955434

Epoch: 5| Step: 7
Training loss: 0.08884128255869471
Validation loss: 2.261327040105639

Epoch: 5| Step: 8
Training loss: 0.09008527508999019
Validation loss: 2.261238837414139

Epoch: 5| Step: 9
Training loss: 0.1279540148019451
Validation loss: 2.259802152431492

Epoch: 5| Step: 10
Training loss: 0.07800167900599118
Validation loss: 2.254087673883135

Epoch: 777| Step: 0
Training loss: 0.08264713747761965
Validation loss: 2.241158142976494

Epoch: 5| Step: 1
Training loss: 0.08773924718934553
Validation loss: 2.2309796349294753

Epoch: 5| Step: 2
Training loss: 0.09257982027135381
Validation loss: 2.251789883950787

Epoch: 5| Step: 3
Training loss: 0.11746481032436218
Validation loss: 2.2248735903062706

Epoch: 5| Step: 4
Training loss: 0.15206241305921447
Validation loss: 2.2657401016411858

Epoch: 5| Step: 5
Training loss: 0.08166089353887762
Validation loss: 2.2342777106240552

Epoch: 5| Step: 6
Training loss: 0.09771244339679602
Validation loss: 2.2449977945617987

Epoch: 5| Step: 7
Training loss: 0.09100045008076461
Validation loss: 2.243950957163934

Epoch: 5| Step: 8
Training loss: 0.07405358684400767
Validation loss: 2.245873705628373

Epoch: 5| Step: 9
Training loss: 0.06724679044107229
Validation loss: 2.2697986534700956

Epoch: 5| Step: 10
Training loss: 0.056627128078195824
Validation loss: 2.2590150131312616

Epoch: 778| Step: 0
Training loss: 0.09374025413400906
Validation loss: 2.271472538012109

Epoch: 5| Step: 1
Training loss: 0.07877026456609301
Validation loss: 2.2743026924590173

Epoch: 5| Step: 2
Training loss: 0.07690539586326454
Validation loss: 2.2775953424711735

Epoch: 5| Step: 3
Training loss: 0.11914137542988561
Validation loss: 2.2993109223237913

Epoch: 5| Step: 4
Training loss: 0.08850729558024178
Validation loss: 2.274908558160484

Epoch: 5| Step: 5
Training loss: 0.08880095056984083
Validation loss: 2.31446308732501

Epoch: 5| Step: 6
Training loss: 0.1485812971390473
Validation loss: 2.301194407217853

Epoch: 5| Step: 7
Training loss: 0.08205214586237795
Validation loss: 2.318120087543872

Epoch: 5| Step: 8
Training loss: 0.13425792206844933
Validation loss: 2.308260828261599

Epoch: 5| Step: 9
Training loss: 0.06679721352563929
Validation loss: 2.313304883550517

Epoch: 5| Step: 10
Training loss: 0.11362256638933922
Validation loss: 2.304422418426713

Epoch: 779| Step: 0
Training loss: 0.06378514403965024
Validation loss: 2.2532459804051572

Epoch: 5| Step: 1
Training loss: 0.08574967558016729
Validation loss: 2.279683383596996

Epoch: 5| Step: 2
Training loss: 0.06826100765179872
Validation loss: 2.276239231176476

Epoch: 5| Step: 3
Training loss: 0.0886718258458476
Validation loss: 2.2616507037374145

Epoch: 5| Step: 4
Training loss: 0.0872680815604524
Validation loss: 2.2580036204926763

Epoch: 5| Step: 5
Training loss: 0.058208938442714235
Validation loss: 2.272434176873854

Epoch: 5| Step: 6
Training loss: 0.07353742540260233
Validation loss: 2.273611281341019

Epoch: 5| Step: 7
Training loss: 0.08830252924747625
Validation loss: 2.241815056799201

Epoch: 5| Step: 8
Training loss: 0.1008274733828113
Validation loss: 2.26914427356936

Epoch: 5| Step: 9
Training loss: 0.1053584988396534
Validation loss: 2.273921787405961

Epoch: 5| Step: 10
Training loss: 0.08873132128833901
Validation loss: 2.2918846917873177

Epoch: 780| Step: 0
Training loss: 0.08704959289136781
Validation loss: 2.2561069931674127

Epoch: 5| Step: 1
Training loss: 0.09643630498274255
Validation loss: 2.2584366893452845

Epoch: 5| Step: 2
Training loss: 0.11815780039816602
Validation loss: 2.278218994852799

Epoch: 5| Step: 3
Training loss: 0.09734147840699715
Validation loss: 2.2770662915639006

Epoch: 5| Step: 4
Training loss: 0.0885697827390205
Validation loss: 2.2738122062158928

Epoch: 5| Step: 5
Training loss: 0.09237933525331996
Validation loss: 2.2692510671841943

Epoch: 5| Step: 6
Training loss: 0.0827755905391619
Validation loss: 2.270528073907945

Epoch: 5| Step: 7
Training loss: 0.08618913461236075
Validation loss: 2.2686075908555194

Epoch: 5| Step: 8
Training loss: 0.10387746978800548
Validation loss: 2.2552070480313082

Epoch: 5| Step: 9
Training loss: 0.11446276240084928
Validation loss: 2.28526710793174

Epoch: 5| Step: 10
Training loss: 0.06609301460704706
Validation loss: 2.2760507961657126

Epoch: 781| Step: 0
Training loss: 0.09022434104518666
Validation loss: 2.293690525180346

Epoch: 5| Step: 1
Training loss: 0.06578188377129433
Validation loss: 2.293437533831365

Epoch: 5| Step: 2
Training loss: 0.08190140211130142
Validation loss: 2.29158282942319

Epoch: 5| Step: 3
Training loss: 0.11078364253991428
Validation loss: 2.2928420681684716

Epoch: 5| Step: 4
Training loss: 0.09402009679915917
Validation loss: 2.3052441519334055

Epoch: 5| Step: 5
Training loss: 0.07526712270853761
Validation loss: 2.2753355622797478

Epoch: 5| Step: 6
Training loss: 0.08758929838966777
Validation loss: 2.298144827377589

Epoch: 5| Step: 7
Training loss: 0.13734524780298646
Validation loss: 2.2941255993616236

Epoch: 5| Step: 8
Training loss: 0.08142728937737534
Validation loss: 2.318183035293882

Epoch: 5| Step: 9
Training loss: 0.09418389623850569
Validation loss: 2.2953699351518217

Epoch: 5| Step: 10
Training loss: 0.07293270529319817
Validation loss: 2.2864145728886993

Epoch: 782| Step: 0
Training loss: 0.09811202502571288
Validation loss: 2.3003030765440835

Epoch: 5| Step: 1
Training loss: 0.14352454303658077
Validation loss: 2.264431605675082

Epoch: 5| Step: 2
Training loss: 0.05759069472147821
Validation loss: 2.2486662620403077

Epoch: 5| Step: 3
Training loss: 0.09733868463296758
Validation loss: 2.2589081401828235

Epoch: 5| Step: 4
Training loss: 0.10004590255012091
Validation loss: 2.2663722360826237

Epoch: 5| Step: 5
Training loss: 0.07372429487135188
Validation loss: 2.2688260360076504

Epoch: 5| Step: 6
Training loss: 0.0852882094482534
Validation loss: 2.237468666260112

Epoch: 5| Step: 7
Training loss: 0.10820425528751917
Validation loss: 2.2806710320327723

Epoch: 5| Step: 8
Training loss: 0.1099634942660361
Validation loss: 2.274483829017684

Epoch: 5| Step: 9
Training loss: 0.10265252330117923
Validation loss: 2.2642386410158992

Epoch: 5| Step: 10
Training loss: 0.11569780573830003
Validation loss: 2.257990052933548

Epoch: 783| Step: 0
Training loss: 0.06805873907025879
Validation loss: 2.292886914405334

Epoch: 5| Step: 1
Training loss: 0.0688967631095801
Validation loss: 2.2884022752680893

Epoch: 5| Step: 2
Training loss: 0.0884822694146314
Validation loss: 2.260750631113177

Epoch: 5| Step: 3
Training loss: 0.07267161970723203
Validation loss: 2.3058588804295006

Epoch: 5| Step: 4
Training loss: 0.10232289553152775
Validation loss: 2.2704577734235554

Epoch: 5| Step: 5
Training loss: 0.10656646518377745
Validation loss: 2.3030680299437933

Epoch: 5| Step: 6
Training loss: 0.11037833808882029
Validation loss: 2.311340533022725

Epoch: 5| Step: 7
Training loss: 0.10502658984155264
Validation loss: 2.314016260797393

Epoch: 5| Step: 8
Training loss: 0.10747092167694733
Validation loss: 2.258785233133646

Epoch: 5| Step: 9
Training loss: 0.08720870117861211
Validation loss: 2.2943242083972337

Epoch: 5| Step: 10
Training loss: 0.10689872451885321
Validation loss: 2.2637690709480727

Epoch: 784| Step: 0
Training loss: 0.08754257854275811
Validation loss: 2.259377369684909

Epoch: 5| Step: 1
Training loss: 0.05859780694903898
Validation loss: 2.291524297220323

Epoch: 5| Step: 2
Training loss: 0.1018716938193184
Validation loss: 2.263793887663555

Epoch: 5| Step: 3
Training loss: 0.0770386113321006
Validation loss: 2.279943143833366

Epoch: 5| Step: 4
Training loss: 0.09029514487530421
Validation loss: 2.253237525735996

Epoch: 5| Step: 5
Training loss: 0.14774779655698267
Validation loss: 2.253845103684478

Epoch: 5| Step: 6
Training loss: 0.07290253722293905
Validation loss: 2.2481081488022054

Epoch: 5| Step: 7
Training loss: 0.12031433549942329
Validation loss: 2.2517993772310128

Epoch: 5| Step: 8
Training loss: 0.05972787273995682
Validation loss: 2.2618734391959916

Epoch: 5| Step: 9
Training loss: 0.10965069017314834
Validation loss: 2.2682583863540575

Epoch: 5| Step: 10
Training loss: 0.10142221757845335
Validation loss: 2.2445340047343065

Epoch: 785| Step: 0
Training loss: 0.12098319636857983
Validation loss: 2.277341576242775

Epoch: 5| Step: 1
Training loss: 0.11254928323980566
Validation loss: 2.2473013935535255

Epoch: 5| Step: 2
Training loss: 0.08062320498845103
Validation loss: 2.252301767226227

Epoch: 5| Step: 3
Training loss: 0.09063609215664024
Validation loss: 2.2640709876649834

Epoch: 5| Step: 4
Training loss: 0.07787773520681819
Validation loss: 2.27335847830679

Epoch: 5| Step: 5
Training loss: 0.09553857690112379
Validation loss: 2.2443872058905328

Epoch: 5| Step: 6
Training loss: 0.0747244353372984
Validation loss: 2.250508181234168

Epoch: 5| Step: 7
Training loss: 0.09260270822450739
Validation loss: 2.2371986584506676

Epoch: 5| Step: 8
Training loss: 0.1030827188151951
Validation loss: 2.2523649006234856

Epoch: 5| Step: 9
Training loss: 0.09390127375107475
Validation loss: 2.2268149761870046

Epoch: 5| Step: 10
Training loss: 0.1292489294260501
Validation loss: 2.231207168906567

Epoch: 786| Step: 0
Training loss: 0.06405743965655283
Validation loss: 2.260063272676376

Epoch: 5| Step: 1
Training loss: 0.08202917516445889
Validation loss: 2.242107006170404

Epoch: 5| Step: 2
Training loss: 0.10883949949462475
Validation loss: 2.2432720426500024

Epoch: 5| Step: 3
Training loss: 0.09915901266824494
Validation loss: 2.2619589868707117

Epoch: 5| Step: 4
Training loss: 0.08479425094165083
Validation loss: 2.236870265384556

Epoch: 5| Step: 5
Training loss: 0.10197085577152135
Validation loss: 2.27141958005371

Epoch: 5| Step: 6
Training loss: 0.07451923614917835
Validation loss: 2.2762767227055867

Epoch: 5| Step: 7
Training loss: 0.1407775713517241
Validation loss: 2.2551630991280582

Epoch: 5| Step: 8
Training loss: 0.13027740712673427
Validation loss: 2.2648872789694257

Epoch: 5| Step: 9
Training loss: 0.08218743011522404
Validation loss: 2.247674270971615

Epoch: 5| Step: 10
Training loss: 0.10695671458660858
Validation loss: 2.2400025434464013

Epoch: 787| Step: 0
Training loss: 0.088975222387328
Validation loss: 2.264523793492603

Epoch: 5| Step: 1
Training loss: 0.10996522200590057
Validation loss: 2.2514360236501507

Epoch: 5| Step: 2
Training loss: 0.13163629179481479
Validation loss: 2.2316389352283847

Epoch: 5| Step: 3
Training loss: 0.0663003919245354
Validation loss: 2.249834912007859

Epoch: 5| Step: 4
Training loss: 0.06670574712011536
Validation loss: 2.2475770120540477

Epoch: 5| Step: 5
Training loss: 0.06682595685126823
Validation loss: 2.252052317964841

Epoch: 5| Step: 6
Training loss: 0.09181792443989506
Validation loss: 2.2302919901120895

Epoch: 5| Step: 7
Training loss: 0.10767924947565834
Validation loss: 2.2281637315229017

Epoch: 5| Step: 8
Training loss: 0.09338671611113003
Validation loss: 2.24066630138171

Epoch: 5| Step: 9
Training loss: 0.07661899141747687
Validation loss: 2.25142864164626

Epoch: 5| Step: 10
Training loss: 0.11462629435831798
Validation loss: 2.264108318637277

Epoch: 788| Step: 0
Training loss: 0.0864303285943414
Validation loss: 2.2704388626855208

Epoch: 5| Step: 1
Training loss: 0.09430321743991557
Validation loss: 2.2685673417802863

Epoch: 5| Step: 2
Training loss: 0.09402790206370051
Validation loss: 2.273129427839215

Epoch: 5| Step: 3
Training loss: 0.09878539096288957
Validation loss: 2.2609095921782463

Epoch: 5| Step: 4
Training loss: 0.10541395247336413
Validation loss: 2.2785512266896566

Epoch: 5| Step: 5
Training loss: 0.06310126425509799
Validation loss: 2.2514761659328153

Epoch: 5| Step: 6
Training loss: 0.07466019614673707
Validation loss: 2.2694118288237495

Epoch: 5| Step: 7
Training loss: 0.09767059220854014
Validation loss: 2.2634515053149937

Epoch: 5| Step: 8
Training loss: 0.09396901476048582
Validation loss: 2.237923552585159

Epoch: 5| Step: 9
Training loss: 0.07772352056583022
Validation loss: 2.2735501719449362

Epoch: 5| Step: 10
Training loss: 0.075739329334806
Validation loss: 2.2694677299856307

Epoch: 789| Step: 0
Training loss: 0.09467012159364205
Validation loss: 2.26505853900337

Epoch: 5| Step: 1
Training loss: 0.09167091371530621
Validation loss: 2.22653975188187

Epoch: 5| Step: 2
Training loss: 0.08326629895420527
Validation loss: 2.279494829266377

Epoch: 5| Step: 3
Training loss: 0.059573763606677974
Validation loss: 2.2426570357688167

Epoch: 5| Step: 4
Training loss: 0.09528298507279201
Validation loss: 2.2512644731981806

Epoch: 5| Step: 5
Training loss: 0.0984323608101413
Validation loss: 2.264346807796163

Epoch: 5| Step: 6
Training loss: 0.07336016372199793
Validation loss: 2.2604999691810317

Epoch: 5| Step: 7
Training loss: 0.10022912115003374
Validation loss: 2.2494960092840572

Epoch: 5| Step: 8
Training loss: 0.07114459121987263
Validation loss: 2.238522793656928

Epoch: 5| Step: 9
Training loss: 0.06825487118867822
Validation loss: 2.2376620301538552

Epoch: 5| Step: 10
Training loss: 0.08856321054037633
Validation loss: 2.248069149474431

Epoch: 790| Step: 0
Training loss: 0.11548895919706621
Validation loss: 2.2575976688292942

Epoch: 5| Step: 1
Training loss: 0.06212201034928954
Validation loss: 2.237284929328072

Epoch: 5| Step: 2
Training loss: 0.10658645896110205
Validation loss: 2.2293844403200542

Epoch: 5| Step: 3
Training loss: 0.07089211065262928
Validation loss: 2.2319354849498683

Epoch: 5| Step: 4
Training loss: 0.05543194652965041
Validation loss: 2.2372592891644896

Epoch: 5| Step: 5
Training loss: 0.10249480245949964
Validation loss: 2.2298913819774135

Epoch: 5| Step: 6
Training loss: 0.060809998057228865
Validation loss: 2.224924709313163

Epoch: 5| Step: 7
Training loss: 0.08879951373584132
Validation loss: 2.2548271000391735

Epoch: 5| Step: 8
Training loss: 0.08538559315960166
Validation loss: 2.2284952821558286

Epoch: 5| Step: 9
Training loss: 0.07915927994716244
Validation loss: 2.2498934343412462

Epoch: 5| Step: 10
Training loss: 0.05741436464798837
Validation loss: 2.220437549247965

Epoch: 791| Step: 0
Training loss: 0.06460392174199704
Validation loss: 2.2213466504563253

Epoch: 5| Step: 1
Training loss: 0.07092468338142037
Validation loss: 2.213668651280218

Epoch: 5| Step: 2
Training loss: 0.09888054170101064
Validation loss: 2.2358636432738304

Epoch: 5| Step: 3
Training loss: 0.08300043522084409
Validation loss: 2.2624292677489484

Epoch: 5| Step: 4
Training loss: 0.0690654731451424
Validation loss: 2.2436413368705757

Epoch: 5| Step: 5
Training loss: 0.07905817608072956
Validation loss: 2.2261452157732524

Epoch: 5| Step: 6
Training loss: 0.08768901483739035
Validation loss: 2.2413695823982427

Epoch: 5| Step: 7
Training loss: 0.07508457997624697
Validation loss: 2.233913754660968

Epoch: 5| Step: 8
Training loss: 0.07197425069298014
Validation loss: 2.2572967812334896

Epoch: 5| Step: 9
Training loss: 0.08547839620262197
Validation loss: 2.2722584735382734

Epoch: 5| Step: 10
Training loss: 0.06721679303979648
Validation loss: 2.2556641449669614

Epoch: 792| Step: 0
Training loss: 0.04183586265297257
Validation loss: 2.274595977451893

Epoch: 5| Step: 1
Training loss: 0.0867607097880506
Validation loss: 2.2533416487324405

Epoch: 5| Step: 2
Training loss: 0.0924990259744293
Validation loss: 2.2526523075416467

Epoch: 5| Step: 3
Training loss: 0.04422031557779243
Validation loss: 2.262005593757687

Epoch: 5| Step: 4
Training loss: 0.057750477013357004
Validation loss: 2.245767256381702

Epoch: 5| Step: 5
Training loss: 0.06544111991755472
Validation loss: 2.2416416798867327

Epoch: 5| Step: 6
Training loss: 0.08532280972300631
Validation loss: 2.270852356313877

Epoch: 5| Step: 7
Training loss: 0.0785936662832766
Validation loss: 2.2328117329557196

Epoch: 5| Step: 8
Training loss: 0.10087357753479875
Validation loss: 2.2343936262237127

Epoch: 5| Step: 9
Training loss: 0.08832389478829464
Validation loss: 2.2406452813905866

Epoch: 5| Step: 10
Training loss: 0.08836049209465334
Validation loss: 2.2448048472859177

Epoch: 793| Step: 0
Training loss: 0.0733443723568072
Validation loss: 2.239331350342652

Epoch: 5| Step: 1
Training loss: 0.05925156961521826
Validation loss: 2.2463488909964178

Epoch: 5| Step: 2
Training loss: 0.12389871378345307
Validation loss: 2.220546604519843

Epoch: 5| Step: 3
Training loss: 0.07947823240302668
Validation loss: 2.234913883271171

Epoch: 5| Step: 4
Training loss: 0.09044517442149516
Validation loss: 2.2381528931279133

Epoch: 5| Step: 5
Training loss: 0.06482621064879843
Validation loss: 2.242309027350402

Epoch: 5| Step: 6
Training loss: 0.054579888632024454
Validation loss: 2.214381951819086

Epoch: 5| Step: 7
Training loss: 0.09548010921640776
Validation loss: 2.2189347419739107

Epoch: 5| Step: 8
Training loss: 0.08805431381930151
Validation loss: 2.2103645558952274

Epoch: 5| Step: 9
Training loss: 0.10023548127840155
Validation loss: 2.208612793691749

Epoch: 5| Step: 10
Training loss: 0.10591477988801314
Validation loss: 2.223069693386633

Epoch: 794| Step: 0
Training loss: 0.07060853244471264
Validation loss: 2.23828266280267

Epoch: 5| Step: 1
Training loss: 0.05291159529997903
Validation loss: 2.2316248104778746

Epoch: 5| Step: 2
Training loss: 0.061802763586004554
Validation loss: 2.2366548073103645

Epoch: 5| Step: 3
Training loss: 0.10667690404070392
Validation loss: 2.249118822661078

Epoch: 5| Step: 4
Training loss: 0.09928203539407095
Validation loss: 2.2883028906839264

Epoch: 5| Step: 5
Training loss: 0.07172937152473947
Validation loss: 2.246491725595346

Epoch: 5| Step: 6
Training loss: 0.07197574520858181
Validation loss: 2.2591276049234974

Epoch: 5| Step: 7
Training loss: 0.05535092869666966
Validation loss: 2.2584779762608442

Epoch: 5| Step: 8
Training loss: 0.07280080039246235
Validation loss: 2.2585356690681597

Epoch: 5| Step: 9
Training loss: 0.08146156885208466
Validation loss: 2.2526798977920053

Epoch: 5| Step: 10
Training loss: 0.1067067575279088
Validation loss: 2.260983726908273

Epoch: 795| Step: 0
Training loss: 0.09124392499036149
Validation loss: 2.2571874628313204

Epoch: 5| Step: 1
Training loss: 0.08491336652670749
Validation loss: 2.2387047885749665

Epoch: 5| Step: 2
Training loss: 0.06204400010798746
Validation loss: 2.244329086557219

Epoch: 5| Step: 3
Training loss: 0.0815084521399166
Validation loss: 2.223421204897054

Epoch: 5| Step: 4
Training loss: 0.07984454700460372
Validation loss: 2.221867526196871

Epoch: 5| Step: 5
Training loss: 0.08705919984640843
Validation loss: 2.2329225621866455

Epoch: 5| Step: 6
Training loss: 0.06259851588999445
Validation loss: 2.2431996094160938

Epoch: 5| Step: 7
Training loss: 0.059790345608231876
Validation loss: 2.231957865653823

Epoch: 5| Step: 8
Training loss: 0.09506748730024879
Validation loss: 2.232528640763071

Epoch: 5| Step: 9
Training loss: 0.09081936907534607
Validation loss: 2.2219779286859582

Epoch: 5| Step: 10
Training loss: 0.0914880244132277
Validation loss: 2.2259471504272756

Epoch: 796| Step: 0
Training loss: 0.06983348478176697
Validation loss: 2.23572718571643

Epoch: 5| Step: 1
Training loss: 0.05627757909649711
Validation loss: 2.2436089597868722

Epoch: 5| Step: 2
Training loss: 0.08246049236193724
Validation loss: 2.2396233015412204

Epoch: 5| Step: 3
Training loss: 0.07003554130549199
Validation loss: 2.2661004302779797

Epoch: 5| Step: 4
Training loss: 0.09376354417715328
Validation loss: 2.24732505230497

Epoch: 5| Step: 5
Training loss: 0.061919205283527776
Validation loss: 2.234356220733529

Epoch: 5| Step: 6
Training loss: 0.05635308994823511
Validation loss: 2.2589368371467233

Epoch: 5| Step: 7
Training loss: 0.10589258369862176
Validation loss: 2.2559922915229675

Epoch: 5| Step: 8
Training loss: 0.06721552178524236
Validation loss: 2.245944564166431

Epoch: 5| Step: 9
Training loss: 0.0964565495665271
Validation loss: 2.2256588224434077

Epoch: 5| Step: 10
Training loss: 0.08463527483805976
Validation loss: 2.2441174507470696

Epoch: 797| Step: 0
Training loss: 0.07091358997586368
Validation loss: 2.253341707893159

Epoch: 5| Step: 1
Training loss: 0.08400262589976731
Validation loss: 2.2419512350081354

Epoch: 5| Step: 2
Training loss: 0.09320819277387556
Validation loss: 2.2399486139881417

Epoch: 5| Step: 3
Training loss: 0.11214786858914279
Validation loss: 2.2613947594119903

Epoch: 5| Step: 4
Training loss: 0.0680606924474665
Validation loss: 2.214025681411462

Epoch: 5| Step: 5
Training loss: 0.07814853135015315
Validation loss: 2.2335012281967033

Epoch: 5| Step: 6
Training loss: 0.10164927480251774
Validation loss: 2.224911043740039

Epoch: 5| Step: 7
Training loss: 0.06600050527341292
Validation loss: 2.219443419551805

Epoch: 5| Step: 8
Training loss: 0.08202063117098454
Validation loss: 2.253599667988762

Epoch: 5| Step: 9
Training loss: 0.05899801664938553
Validation loss: 2.226606194514123

Epoch: 5| Step: 10
Training loss: 0.05835362743764441
Validation loss: 2.22965256535361

Epoch: 798| Step: 0
Training loss: 0.08311337602608787
Validation loss: 2.2274802756844645

Epoch: 5| Step: 1
Training loss: 0.08914881923501206
Validation loss: 2.239471276111011

Epoch: 5| Step: 2
Training loss: 0.09486584402906588
Validation loss: 2.258464108472834

Epoch: 5| Step: 3
Training loss: 0.0849929343733471
Validation loss: 2.2532959033795112

Epoch: 5| Step: 4
Training loss: 0.0913202308950093
Validation loss: 2.2539016809746153

Epoch: 5| Step: 5
Training loss: 0.07392699846603519
Validation loss: 2.281288698424171

Epoch: 5| Step: 6
Training loss: 0.08973635598901575
Validation loss: 2.2664628513225473

Epoch: 5| Step: 7
Training loss: 0.05844285927641324
Validation loss: 2.286830129524874

Epoch: 5| Step: 8
Training loss: 0.08181678745930428
Validation loss: 2.2656144099117097

Epoch: 5| Step: 9
Training loss: 0.07306187049942885
Validation loss: 2.259408528556817

Epoch: 5| Step: 10
Training loss: 0.09094518362763149
Validation loss: 2.2614184475682095

Epoch: 799| Step: 0
Training loss: 0.07951698595937333
Validation loss: 2.269554089072693

Epoch: 5| Step: 1
Training loss: 0.07013383989047957
Validation loss: 2.25678907929808

Epoch: 5| Step: 2
Training loss: 0.06667875028911405
Validation loss: 2.2602423802075093

Epoch: 5| Step: 3
Training loss: 0.06753143905695269
Validation loss: 2.2555562363691624

Epoch: 5| Step: 4
Training loss: 0.07608527677327268
Validation loss: 2.2415196948992904

Epoch: 5| Step: 5
Training loss: 0.09945091096761456
Validation loss: 2.2495654237926654

Epoch: 5| Step: 6
Training loss: 0.09694253947484906
Validation loss: 2.240094793878665

Epoch: 5| Step: 7
Training loss: 0.062167201772998774
Validation loss: 2.2514875114008768

Epoch: 5| Step: 8
Training loss: 0.0839319897442172
Validation loss: 2.2476161328409336

Epoch: 5| Step: 9
Training loss: 0.07790443757080086
Validation loss: 2.2492910701643996

Epoch: 5| Step: 10
Training loss: 0.08230467198864647
Validation loss: 2.250431073617993

Epoch: 800| Step: 0
Training loss: 0.09245614453984506
Validation loss: 2.238998214932013

Epoch: 5| Step: 1
Training loss: 0.06012480853854742
Validation loss: 2.2557114879607627

Epoch: 5| Step: 2
Training loss: 0.0485031735410276
Validation loss: 2.263913925652846

Epoch: 5| Step: 3
Training loss: 0.10345932941213959
Validation loss: 2.2402822448964166

Epoch: 5| Step: 4
Training loss: 0.08672944563556129
Validation loss: 2.2502273253314464

Epoch: 5| Step: 5
Training loss: 0.06531589491248033
Validation loss: 2.251506022245052

Epoch: 5| Step: 6
Training loss: 0.11094814001020363
Validation loss: 2.25567504430867

Epoch: 5| Step: 7
Training loss: 0.08535739051684374
Validation loss: 2.236115385709744

Epoch: 5| Step: 8
Training loss: 0.09654754701903098
Validation loss: 2.246093331114457

Epoch: 5| Step: 9
Training loss: 0.06205933912589194
Validation loss: 2.248071436494241

Epoch: 5| Step: 10
Training loss: 0.055714249991332995
Validation loss: 2.2315032193934665

Testing loss: 2.4156959491469343
