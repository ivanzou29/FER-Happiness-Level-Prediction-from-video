Epoch: 1| Step: 0
Training loss: 5.221973896026611
Validation loss: 5.1984800625872865

Epoch: 5| Step: 1
Training loss: 4.938985347747803
Validation loss: 5.176421114193496

Epoch: 5| Step: 2
Training loss: 4.0547943115234375
Validation loss: 5.156939080966416

Epoch: 5| Step: 3
Training loss: 5.775575160980225
Validation loss: 5.137340448235952

Epoch: 5| Step: 4
Training loss: 4.3434247970581055
Validation loss: 5.116642880183394

Epoch: 5| Step: 5
Training loss: 4.599834442138672
Validation loss: 5.092916114355928

Epoch: 5| Step: 6
Training loss: 4.04538106918335
Validation loss: 5.066259640519337

Epoch: 5| Step: 7
Training loss: 5.601165771484375
Validation loss: 5.035819981687812

Epoch: 5| Step: 8
Training loss: 5.516245365142822
Validation loss: 5.002795501421857

Epoch: 5| Step: 9
Training loss: 4.9802985191345215
Validation loss: 4.966021332689511

Epoch: 5| Step: 10
Training loss: 4.516329765319824
Validation loss: 4.925018592547345

Epoch: 2| Step: 0
Training loss: 4.094502925872803
Validation loss: 4.881605358533962

Epoch: 5| Step: 1
Training loss: 5.491584777832031
Validation loss: 4.834612518228511

Epoch: 5| Step: 2
Training loss: 5.246853828430176
Validation loss: 4.784738463740195

Epoch: 5| Step: 3
Training loss: 4.760531425476074
Validation loss: 4.732884996680803

Epoch: 5| Step: 4
Training loss: 3.327960968017578
Validation loss: 4.678485255087575

Epoch: 5| Step: 5
Training loss: 4.043078422546387
Validation loss: 4.62185404633963

Epoch: 5| Step: 6
Training loss: 4.577331066131592
Validation loss: 4.560623502218595

Epoch: 5| Step: 7
Training loss: 3.924861431121826
Validation loss: 4.500584294719081

Epoch: 5| Step: 8
Training loss: 5.470355033874512
Validation loss: 4.438973344782347

Epoch: 5| Step: 9
Training loss: 4.021523475646973
Validation loss: 4.3791157917309835

Epoch: 5| Step: 10
Training loss: 3.4071578979492188
Validation loss: 4.3225731747124785

Epoch: 3| Step: 0
Training loss: 4.359786033630371
Validation loss: 4.2689141714444725

Epoch: 5| Step: 1
Training loss: 4.247610092163086
Validation loss: 4.2164428823737685

Epoch: 5| Step: 2
Training loss: 4.020023345947266
Validation loss: 4.166743129812261

Epoch: 5| Step: 3
Training loss: 3.502114772796631
Validation loss: 4.118485671217724

Epoch: 5| Step: 4
Training loss: 3.8223891258239746
Validation loss: 4.071975020952122

Epoch: 5| Step: 5
Training loss: 4.44302225112915
Validation loss: 4.027072534766249

Epoch: 5| Step: 6
Training loss: 3.0878536701202393
Validation loss: 3.9769705110980618

Epoch: 5| Step: 7
Training loss: 3.8058578968048096
Validation loss: 3.9259549545985397

Epoch: 5| Step: 8
Training loss: 3.595829486846924
Validation loss: 3.881819091817384

Epoch: 5| Step: 9
Training loss: 3.9376072883605957
Validation loss: 3.8447417802708124

Epoch: 5| Step: 10
Training loss: 3.8885843753814697
Validation loss: 3.8081964472288727

Epoch: 4| Step: 0
Training loss: 4.394349575042725
Validation loss: 3.773773403577907

Epoch: 5| Step: 1
Training loss: 2.8669445514678955
Validation loss: 3.744340983770227

Epoch: 5| Step: 2
Training loss: 2.985355854034424
Validation loss: 3.723931348452004

Epoch: 5| Step: 3
Training loss: 2.958890438079834
Validation loss: 3.6948303355965564

Epoch: 5| Step: 4
Training loss: 2.9228599071502686
Validation loss: 3.6748350384414836

Epoch: 5| Step: 5
Training loss: 4.205807685852051
Validation loss: 3.6449015576352357

Epoch: 5| Step: 6
Training loss: 2.594038486480713
Validation loss: 3.6134346095464562

Epoch: 5| Step: 7
Training loss: 3.653430938720703
Validation loss: 3.591604389170165

Epoch: 5| Step: 8
Training loss: 3.5816683769226074
Validation loss: 3.5801830445566485

Epoch: 5| Step: 9
Training loss: 4.7201032638549805
Validation loss: 3.561712864906557

Epoch: 5| Step: 10
Training loss: 4.319649696350098
Validation loss: 3.5398190021514893

Epoch: 5| Step: 0
Training loss: 3.310124158859253
Validation loss: 3.5190042629036853

Epoch: 5| Step: 1
Training loss: 3.0457603931427
Validation loss: 3.500434778069937

Epoch: 5| Step: 2
Training loss: 4.356318473815918
Validation loss: 3.489231881274972

Epoch: 5| Step: 3
Training loss: 3.1862733364105225
Validation loss: 3.476765973593599

Epoch: 5| Step: 4
Training loss: 3.725478410720825
Validation loss: 3.4600665030940885

Epoch: 5| Step: 5
Training loss: 3.2313029766082764
Validation loss: 3.4423242897115727

Epoch: 5| Step: 6
Training loss: 3.1642913818359375
Validation loss: 3.4263866460451515

Epoch: 5| Step: 7
Training loss: 3.4014315605163574
Validation loss: 3.4140329284052693

Epoch: 5| Step: 8
Training loss: 2.556373119354248
Validation loss: 3.403339170640515

Epoch: 5| Step: 9
Training loss: 3.497589111328125
Validation loss: 3.3981427172178864

Epoch: 5| Step: 10
Training loss: 3.8924686908721924
Validation loss: 3.3794684820277716

Epoch: 6| Step: 0
Training loss: 3.2834553718566895
Validation loss: 3.367410316262194

Epoch: 5| Step: 1
Training loss: 2.8529016971588135
Validation loss: 3.3597831264618905

Epoch: 5| Step: 2
Training loss: 3.4109439849853516
Validation loss: 3.349364193536902

Epoch: 5| Step: 3
Training loss: 3.0295321941375732
Validation loss: 3.329732705188054

Epoch: 5| Step: 4
Training loss: 3.612286329269409
Validation loss: 3.324318539711737

Epoch: 5| Step: 5
Training loss: 3.7316298484802246
Validation loss: 3.318073316286969

Epoch: 5| Step: 6
Training loss: 2.7652623653411865
Validation loss: 3.302176231979042

Epoch: 5| Step: 7
Training loss: 3.8893866539001465
Validation loss: 3.2936676522736907

Epoch: 5| Step: 8
Training loss: 3.2857604026794434
Validation loss: 3.2857675142185663

Epoch: 5| Step: 9
Training loss: 2.9906678199768066
Validation loss: 3.277122046357842

Epoch: 5| Step: 10
Training loss: 3.2178707122802734
Validation loss: 3.270600139453847

Epoch: 7| Step: 0
Training loss: 2.936107635498047
Validation loss: 3.258990328799012

Epoch: 5| Step: 1
Training loss: 3.4750876426696777
Validation loss: 3.2524356585676952

Epoch: 5| Step: 2
Training loss: 3.140658140182495
Validation loss: 3.2404759827480523

Epoch: 5| Step: 3
Training loss: 2.408568859100342
Validation loss: 3.23242554613339

Epoch: 5| Step: 4
Training loss: 2.767461061477661
Validation loss: 3.2281608684088594

Epoch: 5| Step: 5
Training loss: 3.715153932571411
Validation loss: 3.2188531608991724

Epoch: 5| Step: 6
Training loss: 3.2325947284698486
Validation loss: 3.2146027139438096

Epoch: 5| Step: 7
Training loss: 3.6584572792053223
Validation loss: 3.214961331377747

Epoch: 5| Step: 8
Training loss: 3.506692409515381
Validation loss: 3.198152506223289

Epoch: 5| Step: 9
Training loss: 3.1752982139587402
Validation loss: 3.195444747965823

Epoch: 5| Step: 10
Training loss: 3.291361093521118
Validation loss: 3.188006834317279

Epoch: 8| Step: 0
Training loss: 2.8932487964630127
Validation loss: 3.1889348927364556

Epoch: 5| Step: 1
Training loss: 2.667635440826416
Validation loss: 3.1789300698106007

Epoch: 5| Step: 2
Training loss: 3.0392844676971436
Validation loss: 3.1688167254130044

Epoch: 5| Step: 3
Training loss: 3.453819751739502
Validation loss: 3.164842382554085

Epoch: 5| Step: 4
Training loss: 3.399462938308716
Validation loss: 3.1567682553363103

Epoch: 5| Step: 5
Training loss: 3.419098377227783
Validation loss: 3.152839678590016

Epoch: 5| Step: 6
Training loss: 3.7671470642089844
Validation loss: 3.146061228167626

Epoch: 5| Step: 7
Training loss: 3.0902023315429688
Validation loss: 3.1440584582667195

Epoch: 5| Step: 8
Training loss: 2.9290690422058105
Validation loss: 3.137216609011414

Epoch: 5| Step: 9
Training loss: 3.64857816696167
Validation loss: 3.1312050665578535

Epoch: 5| Step: 10
Training loss: 2.3836944103240967
Validation loss: 3.1241663425199446

Epoch: 9| Step: 0
Training loss: 3.144160747528076
Validation loss: 3.1222981381159958

Epoch: 5| Step: 1
Training loss: 3.427899122238159
Validation loss: 3.1178085547621532

Epoch: 5| Step: 2
Training loss: 2.1233878135681152
Validation loss: 3.1144333885562037

Epoch: 5| Step: 3
Training loss: 3.3161988258361816
Validation loss: 3.1123684683153705

Epoch: 5| Step: 4
Training loss: 3.113704204559326
Validation loss: 3.107601845136253

Epoch: 5| Step: 5
Training loss: 3.8975982666015625
Validation loss: 3.094560020713396

Epoch: 5| Step: 6
Training loss: 3.234619617462158
Validation loss: 3.089483766145604

Epoch: 5| Step: 7
Training loss: 2.724574089050293
Validation loss: 3.08662921895263

Epoch: 5| Step: 8
Training loss: 3.2732181549072266
Validation loss: 3.08611733682694

Epoch: 5| Step: 9
Training loss: 3.5824692249298096
Validation loss: 3.0968269276362594

Epoch: 5| Step: 10
Training loss: 2.456852912902832
Validation loss: 3.071190100844188

Epoch: 10| Step: 0
Training loss: 3.2145049571990967
Validation loss: 3.071952396823514

Epoch: 5| Step: 1
Training loss: 3.430006742477417
Validation loss: 3.0791140858845045

Epoch: 5| Step: 2
Training loss: 3.3782432079315186
Validation loss: 3.0792534530803723

Epoch: 5| Step: 3
Training loss: 2.8313517570495605
Validation loss: 3.08233065758982

Epoch: 5| Step: 4
Training loss: 3.169661045074463
Validation loss: 3.0725912022334274

Epoch: 5| Step: 5
Training loss: 3.5887858867645264
Validation loss: 3.0620728051790627

Epoch: 5| Step: 6
Training loss: 2.1901886463165283
Validation loss: 3.061288797727195

Epoch: 5| Step: 7
Training loss: 3.2482752799987793
Validation loss: 3.063121436744608

Epoch: 5| Step: 8
Training loss: 3.4478955268859863
Validation loss: 3.064063387532388

Epoch: 5| Step: 9
Training loss: 2.638197422027588
Validation loss: 3.064058280760242

Epoch: 5| Step: 10
Training loss: 3.0620927810668945
Validation loss: 3.0631271716087096

Epoch: 11| Step: 0
Training loss: 3.365880250930786
Validation loss: 3.0403355475394958

Epoch: 5| Step: 1
Training loss: 3.3525848388671875
Validation loss: 3.0351766873431463

Epoch: 5| Step: 2
Training loss: 2.583594560623169
Validation loss: 3.035151179118823

Epoch: 5| Step: 3
Training loss: 2.8678081035614014
Validation loss: 3.0412642648143153

Epoch: 5| Step: 4
Training loss: 2.0420634746551514
Validation loss: 3.044865503106066

Epoch: 5| Step: 5
Training loss: 3.209318161010742
Validation loss: 3.0501104516367756

Epoch: 5| Step: 6
Training loss: 3.9143614768981934
Validation loss: 3.0446211061170025

Epoch: 5| Step: 7
Training loss: 3.754032611846924
Validation loss: 3.0321081607572493

Epoch: 5| Step: 8
Training loss: 2.448881149291992
Validation loss: 3.028153163130565

Epoch: 5| Step: 9
Training loss: 2.820652484893799
Validation loss: 3.025633196676931

Epoch: 5| Step: 10
Training loss: 3.67368483543396
Validation loss: 3.007082123910227

Epoch: 12| Step: 0
Training loss: 2.1276750564575195
Validation loss: 3.009802113297165

Epoch: 5| Step: 1
Training loss: 2.7841763496398926
Validation loss: 3.0051437936803347

Epoch: 5| Step: 2
Training loss: 3.581141233444214
Validation loss: 3.0016601136935654

Epoch: 5| Step: 3
Training loss: 2.4764513969421387
Validation loss: 2.997912237721105

Epoch: 5| Step: 4
Training loss: 2.7199535369873047
Validation loss: 2.9910937304137857

Epoch: 5| Step: 5
Training loss: 3.201300859451294
Validation loss: 2.9844903792104414

Epoch: 5| Step: 6
Training loss: 3.429150342941284
Validation loss: 2.980097947582122

Epoch: 5| Step: 7
Training loss: 3.4520087242126465
Validation loss: 2.9764774281491517

Epoch: 5| Step: 8
Training loss: 2.8488895893096924
Validation loss: 2.9775071785014164

Epoch: 5| Step: 9
Training loss: 3.913003921508789
Validation loss: 2.979995519884171

Epoch: 5| Step: 10
Training loss: 3.0473458766937256
Validation loss: 2.970810736379316

Epoch: 13| Step: 0
Training loss: 3.1148877143859863
Validation loss: 2.981384746489986

Epoch: 5| Step: 1
Training loss: 2.7184715270996094
Validation loss: 2.973986658998715

Epoch: 5| Step: 2
Training loss: 2.706934928894043
Validation loss: 2.9915147827517603

Epoch: 5| Step: 3
Training loss: 2.698711395263672
Validation loss: 2.965525447681386

Epoch: 5| Step: 4
Training loss: 2.4510490894317627
Validation loss: 2.957313786270798

Epoch: 5| Step: 5
Training loss: 3.615347385406494
Validation loss: 2.9772931529629614

Epoch: 5| Step: 6
Training loss: 3.5009708404541016
Validation loss: 2.960072071321549

Epoch: 5| Step: 7
Training loss: 2.890254259109497
Validation loss: 2.9544805506224274

Epoch: 5| Step: 8
Training loss: 2.918619155883789
Validation loss: 2.9447535417413198

Epoch: 5| Step: 9
Training loss: 3.492600917816162
Validation loss: 2.973046769378006

Epoch: 5| Step: 10
Training loss: 3.393507957458496
Validation loss: 2.9629616378456034

Epoch: 14| Step: 0
Training loss: 3.0571110248565674
Validation loss: 2.9616580394006546

Epoch: 5| Step: 1
Training loss: 2.4315600395202637
Validation loss: 2.936290210293185

Epoch: 5| Step: 2
Training loss: 3.0305991172790527
Validation loss: 2.931583604504985

Epoch: 5| Step: 3
Training loss: 3.0678677558898926
Validation loss: 2.933266383345409

Epoch: 5| Step: 4
Training loss: 3.453343152999878
Validation loss: 2.9374138386018815

Epoch: 5| Step: 5
Training loss: 2.690075635910034
Validation loss: 2.9349575760543987

Epoch: 5| Step: 6
Training loss: 2.7955498695373535
Validation loss: 2.933560530344645

Epoch: 5| Step: 7
Training loss: 3.4779441356658936
Validation loss: 2.9312565454872708

Epoch: 5| Step: 8
Training loss: 2.859849691390991
Validation loss: 2.92009485408824

Epoch: 5| Step: 9
Training loss: 2.6218104362487793
Validation loss: 2.919631732407437

Epoch: 5| Step: 10
Training loss: 3.8257572650909424
Validation loss: 2.9476197304264193

Epoch: 15| Step: 0
Training loss: 3.0083301067352295
Validation loss: 2.928048518396193

Epoch: 5| Step: 1
Training loss: 2.644225597381592
Validation loss: 2.9124759525381108

Epoch: 5| Step: 2
Training loss: 2.5992610454559326
Validation loss: 2.911961293989612

Epoch: 5| Step: 3
Training loss: 4.058655738830566
Validation loss: 2.910419694838985

Epoch: 5| Step: 4
Training loss: 2.855085849761963
Validation loss: 2.9094872167033534

Epoch: 5| Step: 5
Training loss: 2.999041795730591
Validation loss: 2.9060780668771393

Epoch: 5| Step: 6
Training loss: 3.2783985137939453
Validation loss: 2.9020552507010837

Epoch: 5| Step: 7
Training loss: 2.788837432861328
Validation loss: 2.8999351378410094

Epoch: 5| Step: 8
Training loss: 2.996471405029297
Validation loss: 2.898501939671014

Epoch: 5| Step: 9
Training loss: 2.585149049758911
Validation loss: 2.900533604365523

Epoch: 5| Step: 10
Training loss: 3.2493672370910645
Validation loss: 2.892649822337653

Epoch: 16| Step: 0
Training loss: 3.038177728652954
Validation loss: 2.893772622590424

Epoch: 5| Step: 1
Training loss: 2.8233025074005127
Validation loss: 2.8895979696704495

Epoch: 5| Step: 2
Training loss: 2.5858957767486572
Validation loss: 2.8883083353760424

Epoch: 5| Step: 3
Training loss: 3.089857816696167
Validation loss: 2.885801717799197

Epoch: 5| Step: 4
Training loss: 3.0582478046417236
Validation loss: 2.88576425275495

Epoch: 5| Step: 5
Training loss: 3.1735785007476807
Validation loss: 2.883340709952898

Epoch: 5| Step: 6
Training loss: 3.3763339519500732
Validation loss: 2.8825498242532053

Epoch: 5| Step: 7
Training loss: 2.3419671058654785
Validation loss: 2.8792274382806595

Epoch: 5| Step: 8
Training loss: 3.428696393966675
Validation loss: 2.8764229692438597

Epoch: 5| Step: 9
Training loss: 2.6668527126312256
Validation loss: 2.8745138593899306

Epoch: 5| Step: 10
Training loss: 3.2597506046295166
Validation loss: 2.8735306391152005

Epoch: 17| Step: 0
Training loss: 3.5043365955352783
Validation loss: 2.8692536020791657

Epoch: 5| Step: 1
Training loss: 3.6960175037384033
Validation loss: 2.8644620090402584

Epoch: 5| Step: 2
Training loss: 3.0927505493164062
Validation loss: 2.8589433111170286

Epoch: 5| Step: 3
Training loss: 2.708577871322632
Validation loss: 2.851455416730655

Epoch: 5| Step: 4
Training loss: 2.891606569290161
Validation loss: 2.846205860055903

Epoch: 5| Step: 5
Training loss: 3.136430263519287
Validation loss: 2.843375023975167

Epoch: 5| Step: 6
Training loss: 2.832136631011963
Validation loss: 2.840688128625193

Epoch: 5| Step: 7
Training loss: 2.8240818977355957
Validation loss: 2.837037742778819

Epoch: 5| Step: 8
Training loss: 2.857361316680908
Validation loss: 2.834562668236353

Epoch: 5| Step: 9
Training loss: 3.0673155784606934
Validation loss: 2.831454474438903

Epoch: 5| Step: 10
Training loss: 1.7585922479629517
Validation loss: 2.8282539344603017

Epoch: 18| Step: 0
Training loss: 2.3126564025878906
Validation loss: 2.8429333625301236

Epoch: 5| Step: 1
Training loss: 3.6903235912323
Validation loss: 2.8396240690703034

Epoch: 5| Step: 2
Training loss: 3.7236056327819824
Validation loss: 2.823224554779709

Epoch: 5| Step: 3
Training loss: 2.9340035915374756
Validation loss: 2.822916712812198

Epoch: 5| Step: 4
Training loss: 2.5631067752838135
Validation loss: 2.823196316278109

Epoch: 5| Step: 5
Training loss: 3.307208299636841
Validation loss: 2.8266715131780153

Epoch: 5| Step: 6
Training loss: 3.0641090869903564
Validation loss: 2.8310781550663773

Epoch: 5| Step: 7
Training loss: 2.6042516231536865
Validation loss: 2.8542777107607935

Epoch: 5| Step: 8
Training loss: 3.1756646633148193
Validation loss: 2.866312144905008

Epoch: 5| Step: 9
Training loss: 2.5631518363952637
Validation loss: 2.8320096692731305

Epoch: 5| Step: 10
Training loss: 2.4320883750915527
Validation loss: 2.822327231848112

Epoch: 19| Step: 0
Training loss: 2.893561840057373
Validation loss: 2.8250667279766453

Epoch: 5| Step: 1
Training loss: 2.1607210636138916
Validation loss: 2.8282714941168345

Epoch: 5| Step: 2
Training loss: 3.344067335128784
Validation loss: 2.8270679161112797

Epoch: 5| Step: 3
Training loss: 2.9129810333251953
Validation loss: 2.8224877875338317

Epoch: 5| Step: 4
Training loss: 2.917389392852783
Validation loss: 2.8121539982416297

Epoch: 5| Step: 5
Training loss: 3.0431323051452637
Validation loss: 2.8111079072439544

Epoch: 5| Step: 6
Training loss: 3.0229640007019043
Validation loss: 2.80612781740004

Epoch: 5| Step: 7
Training loss: 2.8348445892333984
Validation loss: 2.8183289599675003

Epoch: 5| Step: 8
Training loss: 2.659353733062744
Validation loss: 2.826206966113019

Epoch: 5| Step: 9
Training loss: 3.174363613128662
Validation loss: 2.8142970403035483

Epoch: 5| Step: 10
Training loss: 3.4295880794525146
Validation loss: 2.806070645650228

Epoch: 20| Step: 0
Training loss: 2.3321406841278076
Validation loss: 2.804351763058734

Epoch: 5| Step: 1
Training loss: 2.755680799484253
Validation loss: 2.805156292453889

Epoch: 5| Step: 2
Training loss: 2.9615931510925293
Validation loss: 2.8073561832469

Epoch: 5| Step: 3
Training loss: 3.388807773590088
Validation loss: 2.7997148242048038

Epoch: 5| Step: 4
Training loss: 3.3926634788513184
Validation loss: 2.79553726924363

Epoch: 5| Step: 5
Training loss: 2.5902562141418457
Validation loss: 2.7948419099212973

Epoch: 5| Step: 6
Training loss: 3.7454285621643066
Validation loss: 2.793709385779596

Epoch: 5| Step: 7
Training loss: 2.476224184036255
Validation loss: 2.7943952263042493

Epoch: 5| Step: 8
Training loss: 3.5796940326690674
Validation loss: 2.793561497042256

Epoch: 5| Step: 9
Training loss: 2.440864086151123
Validation loss: 2.7889440085298274

Epoch: 5| Step: 10
Training loss: 2.3901572227478027
Validation loss: 2.7856559650872343

Epoch: 21| Step: 0
Training loss: 3.4470672607421875
Validation loss: 2.783124936524258

Epoch: 5| Step: 1
Training loss: 3.0837221145629883
Validation loss: 2.7823641095110165

Epoch: 5| Step: 2
Training loss: 2.4904887676239014
Validation loss: 2.78259208638181

Epoch: 5| Step: 3
Training loss: 2.343050956726074
Validation loss: 2.7807783747232087

Epoch: 5| Step: 4
Training loss: 2.3760294914245605
Validation loss: 2.7795644062821583

Epoch: 5| Step: 5
Training loss: 3.0297911167144775
Validation loss: 2.7839579530941543

Epoch: 5| Step: 6
Training loss: 3.451052188873291
Validation loss: 2.7846398815031974

Epoch: 5| Step: 7
Training loss: 2.446467161178589
Validation loss: 2.787659570734988

Epoch: 5| Step: 8
Training loss: 2.8538641929626465
Validation loss: 2.8088302073940152

Epoch: 5| Step: 9
Training loss: 3.525527238845825
Validation loss: 2.791760180586128

Epoch: 5| Step: 10
Training loss: 2.9595160484313965
Validation loss: 2.783633873026858

Epoch: 22| Step: 0
Training loss: 3.1134564876556396
Validation loss: 2.781200803736205

Epoch: 5| Step: 1
Training loss: 2.529780864715576
Validation loss: 2.776396566821683

Epoch: 5| Step: 2
Training loss: 2.771467447280884
Validation loss: 2.7751748382404284

Epoch: 5| Step: 3
Training loss: 3.6477737426757812
Validation loss: 2.7703774334282003

Epoch: 5| Step: 4
Training loss: 2.818448305130005
Validation loss: 2.7704812993285475

Epoch: 5| Step: 5
Training loss: 2.5518784523010254
Validation loss: 2.770294540671892

Epoch: 5| Step: 6
Training loss: 3.173008918762207
Validation loss: 2.769716724272697

Epoch: 5| Step: 7
Training loss: 2.6873183250427246
Validation loss: 2.7651323477427163

Epoch: 5| Step: 8
Training loss: 3.084611654281616
Validation loss: 2.7658221542194323

Epoch: 5| Step: 9
Training loss: 2.3912501335144043
Validation loss: 2.762794707411079

Epoch: 5| Step: 10
Training loss: 3.182138204574585
Validation loss: 2.763189290159492

Epoch: 23| Step: 0
Training loss: 3.170485258102417
Validation loss: 2.7648511573832524

Epoch: 5| Step: 1
Training loss: 2.6303772926330566
Validation loss: 2.764127790286977

Epoch: 5| Step: 2
Training loss: 3.1302554607391357
Validation loss: 2.767766442350162

Epoch: 5| Step: 3
Training loss: 2.3778390884399414
Validation loss: 2.777393538464782

Epoch: 5| Step: 4
Training loss: 3.4994521141052246
Validation loss: 2.7795794856163765

Epoch: 5| Step: 5
Training loss: 2.97861909866333
Validation loss: 2.772579449479298

Epoch: 5| Step: 6
Training loss: 2.588902235031128
Validation loss: 2.767564486431819

Epoch: 5| Step: 7
Training loss: 2.849888563156128
Validation loss: 2.7637828370576263

Epoch: 5| Step: 8
Training loss: 3.2273685932159424
Validation loss: 2.7570623351681616

Epoch: 5| Step: 9
Training loss: 2.689009189605713
Validation loss: 2.7552598496919036

Epoch: 5| Step: 10
Training loss: 2.6630609035491943
Validation loss: 2.754302132514215

Epoch: 24| Step: 0
Training loss: 3.1568939685821533
Validation loss: 2.751423810117988

Epoch: 5| Step: 1
Training loss: 3.1466310024261475
Validation loss: 2.755065566749983

Epoch: 5| Step: 2
Training loss: 2.9325835704803467
Validation loss: 2.758972631987705

Epoch: 5| Step: 3
Training loss: 3.4273059368133545
Validation loss: 2.7517584600756244

Epoch: 5| Step: 4
Training loss: 2.633307933807373
Validation loss: 2.7492178563148744

Epoch: 5| Step: 5
Training loss: 2.7444984912872314
Validation loss: 2.7481915053500923

Epoch: 5| Step: 6
Training loss: 3.2992024421691895
Validation loss: 2.7437089156079035

Epoch: 5| Step: 7
Training loss: 3.123372793197632
Validation loss: 2.746401863713418

Epoch: 5| Step: 8
Training loss: 2.552046060562134
Validation loss: 2.7437703019829205

Epoch: 5| Step: 9
Training loss: 2.3974406719207764
Validation loss: 2.7450687116192234

Epoch: 5| Step: 10
Training loss: 2.271620512008667
Validation loss: 2.756546635781565

Epoch: 25| Step: 0
Training loss: 2.7355844974517822
Validation loss: 2.763850886334655

Epoch: 5| Step: 1
Training loss: 3.389504909515381
Validation loss: 2.7629893518263295

Epoch: 5| Step: 2
Training loss: 3.3022713661193848
Validation loss: 2.755634013042655

Epoch: 5| Step: 3
Training loss: 2.627932548522949
Validation loss: 2.755826829582132

Epoch: 5| Step: 4
Training loss: 1.8454911708831787
Validation loss: 2.7581603834705968

Epoch: 5| Step: 5
Training loss: 2.8625781536102295
Validation loss: 2.76643878926513

Epoch: 5| Step: 6
Training loss: 3.1081225872039795
Validation loss: 2.7518387327912035

Epoch: 5| Step: 7
Training loss: 2.949746608734131
Validation loss: 2.7423535162402737

Epoch: 5| Step: 8
Training loss: 2.4585464000701904
Validation loss: 2.7348179612108456

Epoch: 5| Step: 9
Training loss: 3.1451165676116943
Validation loss: 2.72628544222924

Epoch: 5| Step: 10
Training loss: 3.262394666671753
Validation loss: 2.7237004541581675

Epoch: 26| Step: 0
Training loss: 3.0877633094787598
Validation loss: 2.7276032586251535

Epoch: 5| Step: 1
Training loss: 2.766603946685791
Validation loss: 2.7304457669617026

Epoch: 5| Step: 2
Training loss: 3.425891399383545
Validation loss: 2.7289226183327298

Epoch: 5| Step: 3
Training loss: 2.927018880844116
Validation loss: 2.7250303709378807

Epoch: 5| Step: 4
Training loss: 3.1111209392547607
Validation loss: 2.7199756765878327

Epoch: 5| Step: 5
Training loss: 2.5225276947021484
Validation loss: 2.718856068067653

Epoch: 5| Step: 6
Training loss: 2.5040981769561768
Validation loss: 2.7241688441204768

Epoch: 5| Step: 7
Training loss: 3.069026470184326
Validation loss: 2.7352584664539625

Epoch: 5| Step: 8
Training loss: 3.3836746215820312
Validation loss: 2.743339048918857

Epoch: 5| Step: 9
Training loss: 2.2855796813964844
Validation loss: 2.7238915992039505

Epoch: 5| Step: 10
Training loss: 2.4480693340301514
Validation loss: 2.715552414617231

Epoch: 27| Step: 0
Training loss: 2.41776180267334
Validation loss: 2.717974429489464

Epoch: 5| Step: 1
Training loss: 2.7096476554870605
Validation loss: 2.726474977308704

Epoch: 5| Step: 2
Training loss: 3.623096466064453
Validation loss: 2.755063967038226

Epoch: 5| Step: 3
Training loss: 2.745621919631958
Validation loss: 2.7593446175257363

Epoch: 5| Step: 4
Training loss: 2.6234638690948486
Validation loss: 2.727009060562298

Epoch: 5| Step: 5
Training loss: 3.457448959350586
Validation loss: 2.7151168213095715

Epoch: 5| Step: 6
Training loss: 2.6750426292419434
Validation loss: 2.71306880827873

Epoch: 5| Step: 7
Training loss: 3.111409902572632
Validation loss: 2.7138142995936896

Epoch: 5| Step: 8
Training loss: 2.5230751037597656
Validation loss: 2.7225150651829217

Epoch: 5| Step: 9
Training loss: 2.4833483695983887
Validation loss: 2.7362847738368536

Epoch: 5| Step: 10
Training loss: 3.2324986457824707
Validation loss: 2.7449387786208943

Epoch: 28| Step: 0
Training loss: 2.7397501468658447
Validation loss: 2.7490730747099845

Epoch: 5| Step: 1
Training loss: 2.959699869155884
Validation loss: 2.7423368833398305

Epoch: 5| Step: 2
Training loss: 3.1350910663604736
Validation loss: 2.728287937820599

Epoch: 5| Step: 3
Training loss: 3.1163980960845947
Validation loss: 2.719309893987512

Epoch: 5| Step: 4
Training loss: 2.3398823738098145
Validation loss: 2.7096884968460246

Epoch: 5| Step: 5
Training loss: 2.577404737472534
Validation loss: 2.7041717883079284

Epoch: 5| Step: 6
Training loss: 3.590707302093506
Validation loss: 2.704771072633805

Epoch: 5| Step: 7
Training loss: 3.4146485328674316
Validation loss: 2.7017719822545208

Epoch: 5| Step: 8
Training loss: 2.468822956085205
Validation loss: 2.7046361892454085

Epoch: 5| Step: 9
Training loss: 2.79248309135437
Validation loss: 2.706411523203696

Epoch: 5| Step: 10
Training loss: 2.2113091945648193
Validation loss: 2.7036659486832155

Epoch: 29| Step: 0
Training loss: 3.430823564529419
Validation loss: 2.7054175202564528

Epoch: 5| Step: 1
Training loss: 2.9780845642089844
Validation loss: 2.706045232793336

Epoch: 5| Step: 2
Training loss: 2.7470152378082275
Validation loss: 2.7065590914859565

Epoch: 5| Step: 3
Training loss: 2.115962505340576
Validation loss: 2.701913067089614

Epoch: 5| Step: 4
Training loss: 3.0832087993621826
Validation loss: 2.698315933186521

Epoch: 5| Step: 5
Training loss: 3.6959991455078125
Validation loss: 2.69694096554992

Epoch: 5| Step: 6
Training loss: 2.3688206672668457
Validation loss: 2.6993600168535785

Epoch: 5| Step: 7
Training loss: 2.292534828186035
Validation loss: 2.6901156594676356

Epoch: 5| Step: 8
Training loss: 2.3220486640930176
Validation loss: 2.6885994301047376

Epoch: 5| Step: 9
Training loss: 3.125715732574463
Validation loss: 2.68946135428644

Epoch: 5| Step: 10
Training loss: 3.071324586868286
Validation loss: 2.689663117931735

Epoch: 30| Step: 0
Training loss: 2.381505250930786
Validation loss: 2.6879541284294537

Epoch: 5| Step: 1
Training loss: 3.649962902069092
Validation loss: 2.687099677260204

Epoch: 5| Step: 2
Training loss: 2.7325656414031982
Validation loss: 2.6907463868459067

Epoch: 5| Step: 3
Training loss: 3.0583226680755615
Validation loss: 2.6909871306470645

Epoch: 5| Step: 4
Training loss: 2.8816847801208496
Validation loss: 2.699140828142884

Epoch: 5| Step: 5
Training loss: 2.6519930362701416
Validation loss: 2.704226880945185

Epoch: 5| Step: 6
Training loss: 2.3711235523223877
Validation loss: 2.688550300495599

Epoch: 5| Step: 7
Training loss: 3.0895514488220215
Validation loss: 2.6823181849654003

Epoch: 5| Step: 8
Training loss: 3.0469441413879395
Validation loss: 2.6838643115053893

Epoch: 5| Step: 9
Training loss: 2.7715537548065186
Validation loss: 2.684525115515596

Epoch: 5| Step: 10
Training loss: 2.473520517349243
Validation loss: 2.6837568577899726

Epoch: 31| Step: 0
Training loss: 2.8412532806396484
Validation loss: 2.687886263734551

Epoch: 5| Step: 1
Training loss: 3.069060802459717
Validation loss: 2.6842877659746396

Epoch: 5| Step: 2
Training loss: 2.373634099960327
Validation loss: 2.680025021235148

Epoch: 5| Step: 3
Training loss: 2.875866413116455
Validation loss: 2.6793117241192888

Epoch: 5| Step: 4
Training loss: 2.7433154582977295
Validation loss: 2.682330803204608

Epoch: 5| Step: 5
Training loss: 2.403348445892334
Validation loss: 2.684142530605357

Epoch: 5| Step: 6
Training loss: 2.8913047313690186
Validation loss: 2.687271169436875

Epoch: 5| Step: 7
Training loss: 2.5911312103271484
Validation loss: 2.69363433571272

Epoch: 5| Step: 8
Training loss: 3.315119981765747
Validation loss: 2.6932629462211364

Epoch: 5| Step: 9
Training loss: 2.9600250720977783
Validation loss: 2.6883600757968042

Epoch: 5| Step: 10
Training loss: 2.9868907928466797
Validation loss: 2.6837287872068343

Epoch: 32| Step: 0
Training loss: 2.244507074356079
Validation loss: 2.6836549851202194

Epoch: 5| Step: 1
Training loss: 2.6199913024902344
Validation loss: 2.6784331670371433

Epoch: 5| Step: 2
Training loss: 2.5535366535186768
Validation loss: 2.677775631668747

Epoch: 5| Step: 3
Training loss: 3.2339377403259277
Validation loss: 2.6802087496685725

Epoch: 5| Step: 4
Training loss: 3.5189430713653564
Validation loss: 2.6741496798812703

Epoch: 5| Step: 5
Training loss: 2.760425567626953
Validation loss: 2.6680991803446124

Epoch: 5| Step: 6
Training loss: 2.496717929840088
Validation loss: 2.6673280398050943

Epoch: 5| Step: 7
Training loss: 3.2080063819885254
Validation loss: 2.66877733507464

Epoch: 5| Step: 8
Training loss: 2.6401100158691406
Validation loss: 2.667105549125261

Epoch: 5| Step: 9
Training loss: 2.95625376701355
Validation loss: 2.6650197403405302

Epoch: 5| Step: 10
Training loss: 2.6343376636505127
Validation loss: 2.663064766955632

Epoch: 33| Step: 0
Training loss: 2.701144218444824
Validation loss: 2.661773053548669

Epoch: 5| Step: 1
Training loss: 3.198657751083374
Validation loss: 2.6625961411383843

Epoch: 5| Step: 2
Training loss: 2.5043575763702393
Validation loss: 2.666855809509113

Epoch: 5| Step: 3
Training loss: 3.435894727706909
Validation loss: 2.664794219437466

Epoch: 5| Step: 4
Training loss: 3.2966034412384033
Validation loss: 2.66433040044641

Epoch: 5| Step: 5
Training loss: 1.7855331897735596
Validation loss: 2.658903347548618

Epoch: 5| Step: 6
Training loss: 2.297741174697876
Validation loss: 2.658438910720169

Epoch: 5| Step: 7
Training loss: 2.8971495628356934
Validation loss: 2.656711721933016

Epoch: 5| Step: 8
Training loss: 3.5140252113342285
Validation loss: 2.6547596710984425

Epoch: 5| Step: 9
Training loss: 3.0272719860076904
Validation loss: 2.650595085595244

Epoch: 5| Step: 10
Training loss: 2.0720126628875732
Validation loss: 2.6506721281236216

Epoch: 34| Step: 0
Training loss: 2.8429646492004395
Validation loss: 2.657255034292898

Epoch: 5| Step: 1
Training loss: 3.004584789276123
Validation loss: 2.6565313877597934

Epoch: 5| Step: 2
Training loss: 3.2588951587677
Validation loss: 2.658475265708021

Epoch: 5| Step: 3
Training loss: 3.3220252990722656
Validation loss: 2.659863566839567

Epoch: 5| Step: 4
Training loss: 2.519073009490967
Validation loss: 2.6528252811842066

Epoch: 5| Step: 5
Training loss: 2.411128044128418
Validation loss: 2.646774043319046

Epoch: 5| Step: 6
Training loss: 2.7880475521087646
Validation loss: 2.6497609397416473

Epoch: 5| Step: 7
Training loss: 3.157120943069458
Validation loss: 2.6462550829815608

Epoch: 5| Step: 8
Training loss: 2.6636874675750732
Validation loss: 2.6435556411743164

Epoch: 5| Step: 9
Training loss: 2.2341532707214355
Validation loss: 2.6425711160065024

Epoch: 5| Step: 10
Training loss: 2.5245559215545654
Validation loss: 2.6422591517048497

Epoch: 35| Step: 0
Training loss: 2.6277272701263428
Validation loss: 2.634432085098759

Epoch: 5| Step: 1
Training loss: 2.2710118293762207
Validation loss: 2.6359048376801195

Epoch: 5| Step: 2
Training loss: 2.9576058387756348
Validation loss: 2.6472766630111204

Epoch: 5| Step: 3
Training loss: 2.781404972076416
Validation loss: 2.6587809926720074

Epoch: 5| Step: 4
Training loss: 2.455109119415283
Validation loss: 2.668607609246367

Epoch: 5| Step: 5
Training loss: 3.0362257957458496
Validation loss: 2.666498668732182

Epoch: 5| Step: 6
Training loss: 2.5453858375549316
Validation loss: 2.654235542461436

Epoch: 5| Step: 7
Training loss: 3.399305820465088
Validation loss: 2.638003008339995

Epoch: 5| Step: 8
Training loss: 2.9176840782165527
Validation loss: 2.6315882052144697

Epoch: 5| Step: 9
Training loss: 2.7574009895324707
Validation loss: 2.62923833375336

Epoch: 5| Step: 10
Training loss: 3.1012468338012695
Validation loss: 2.6295564892471477

Epoch: 36| Step: 0
Training loss: 2.8579206466674805
Validation loss: 2.6319849542392197

Epoch: 5| Step: 1
Training loss: 2.693161725997925
Validation loss: 2.635018179493566

Epoch: 5| Step: 2
Training loss: 2.3199071884155273
Validation loss: 2.631565806686237

Epoch: 5| Step: 3
Training loss: 3.265705108642578
Validation loss: 2.629163867683821

Epoch: 5| Step: 4
Training loss: 2.9802803993225098
Validation loss: 2.6277451925380255

Epoch: 5| Step: 5
Training loss: 2.0158793926239014
Validation loss: 2.625491366591505

Epoch: 5| Step: 6
Training loss: 3.176185131072998
Validation loss: 2.6341290191937516

Epoch: 5| Step: 7
Training loss: 2.853606700897217
Validation loss: 2.6412805177832164

Epoch: 5| Step: 8
Training loss: 2.2998969554901123
Validation loss: 2.647632598876953

Epoch: 5| Step: 9
Training loss: 2.4992005825042725
Validation loss: 2.6478828332757436

Epoch: 5| Step: 10
Training loss: 3.8665385246276855
Validation loss: 2.6346149239488827

Epoch: 37| Step: 0
Training loss: 3.092273712158203
Validation loss: 2.6263926131750948

Epoch: 5| Step: 1
Training loss: 2.799982786178589
Validation loss: 2.624380819259151

Epoch: 5| Step: 2
Training loss: 2.249913454055786
Validation loss: 2.6206561621799263

Epoch: 5| Step: 3
Training loss: 2.850053071975708
Validation loss: 2.620606865934146

Epoch: 5| Step: 4
Training loss: 2.4212875366210938
Validation loss: 2.624893283331266

Epoch: 5| Step: 5
Training loss: 3.1440744400024414
Validation loss: 2.6166477100823515

Epoch: 5| Step: 6
Training loss: 3.0716350078582764
Validation loss: 2.616087546912573

Epoch: 5| Step: 7
Training loss: 2.76788330078125
Validation loss: 2.620407622347596

Epoch: 5| Step: 8
Training loss: 2.599384069442749
Validation loss: 2.622740235379947

Epoch: 5| Step: 9
Training loss: 2.7524943351745605
Validation loss: 2.6272546091387348

Epoch: 5| Step: 10
Training loss: 2.8734569549560547
Validation loss: 2.637071901752103

Epoch: 38| Step: 0
Training loss: 3.061262607574463
Validation loss: 2.6337562709726314

Epoch: 5| Step: 1
Training loss: 3.235525608062744
Validation loss: 2.631739798412528

Epoch: 5| Step: 2
Training loss: 2.5670597553253174
Validation loss: 2.62926177055605

Epoch: 5| Step: 3
Training loss: 2.975968837738037
Validation loss: 2.625252236602127

Epoch: 5| Step: 4
Training loss: 1.93442702293396
Validation loss: 2.616749002087501

Epoch: 5| Step: 5
Training loss: 2.7019736766815186
Validation loss: 2.609936470626503

Epoch: 5| Step: 6
Training loss: 3.024341106414795
Validation loss: 2.6101490579625612

Epoch: 5| Step: 7
Training loss: 2.778775691986084
Validation loss: 2.6071069471297728

Epoch: 5| Step: 8
Training loss: 2.6665732860565186
Validation loss: 2.607664709450096

Epoch: 5| Step: 9
Training loss: 3.0576624870300293
Validation loss: 2.607044714753346

Epoch: 5| Step: 10
Training loss: 2.4682586193084717
Validation loss: 2.6061916940955707

Epoch: 39| Step: 0
Training loss: 2.429119348526001
Validation loss: 2.6082153576676563

Epoch: 5| Step: 1
Training loss: 2.5556254386901855
Validation loss: 2.6103642602120676

Epoch: 5| Step: 2
Training loss: 2.7134501934051514
Validation loss: 2.6108942570224887

Epoch: 5| Step: 3
Training loss: 2.9164345264434814
Validation loss: 2.620305235667895

Epoch: 5| Step: 4
Training loss: 3.0740857124328613
Validation loss: 2.6275817296838246

Epoch: 5| Step: 5
Training loss: 3.4419949054718018
Validation loss: 2.645003867405717

Epoch: 5| Step: 6
Training loss: 2.942995071411133
Validation loss: 2.6663536281995874

Epoch: 5| Step: 7
Training loss: 2.690117597579956
Validation loss: 2.642185431654735

Epoch: 5| Step: 8
Training loss: 2.5457801818847656
Validation loss: 2.605034851258801

Epoch: 5| Step: 9
Training loss: 2.49348783493042
Validation loss: 2.591851490800099

Epoch: 5| Step: 10
Training loss: 2.671182870864868
Validation loss: 2.6003158553954093

Epoch: 40| Step: 0
Training loss: 3.5532073974609375
Validation loss: 2.6214868368641024

Epoch: 5| Step: 1
Training loss: 2.454425096511841
Validation loss: 2.636023149695448

Epoch: 5| Step: 2
Training loss: 2.029952049255371
Validation loss: 2.644433080509145

Epoch: 5| Step: 3
Training loss: 3.1149168014526367
Validation loss: 2.662098538491034

Epoch: 5| Step: 4
Training loss: 3.0913162231445312
Validation loss: 2.6497000622492966

Epoch: 5| Step: 5
Training loss: 2.73406982421875
Validation loss: 2.6416158086510113

Epoch: 5| Step: 6
Training loss: 2.576993465423584
Validation loss: 2.620856915750811

Epoch: 5| Step: 7
Training loss: 2.934577226638794
Validation loss: 2.6078834559327815

Epoch: 5| Step: 8
Training loss: 3.04172682762146
Validation loss: 2.5921404643725325

Epoch: 5| Step: 9
Training loss: 3.0003020763397217
Validation loss: 2.5853679641600578

Epoch: 5| Step: 10
Training loss: 1.9194966554641724
Validation loss: 2.586211931320929

Epoch: 41| Step: 0
Training loss: 3.18845534324646
Validation loss: 2.6418517430623374

Epoch: 5| Step: 1
Training loss: 3.0948293209075928
Validation loss: 2.6712962760720202

Epoch: 5| Step: 2
Training loss: 2.6962828636169434
Validation loss: 2.6900484536283757

Epoch: 5| Step: 3
Training loss: 2.694521188735962
Validation loss: 2.672404081590714

Epoch: 5| Step: 4
Training loss: 3.1847586631774902
Validation loss: 2.719116944138722

Epoch: 5| Step: 5
Training loss: 3.0719430446624756
Validation loss: 2.7221658845101633

Epoch: 5| Step: 6
Training loss: 2.865083694458008
Validation loss: 2.697232982163788

Epoch: 5| Step: 7
Training loss: 1.3717741966247559
Validation loss: 2.6793729156576176

Epoch: 5| Step: 8
Training loss: 3.2419979572296143
Validation loss: 2.649465589113133

Epoch: 5| Step: 9
Training loss: 2.2479090690612793
Validation loss: 2.6086769309095157

Epoch: 5| Step: 10
Training loss: 3.2388100624084473
Validation loss: 2.588683751321608

Epoch: 42| Step: 0
Training loss: 3.1528267860412598
Validation loss: 2.5954439588772353

Epoch: 5| Step: 1
Training loss: 2.6323091983795166
Validation loss: 2.616401408308296

Epoch: 5| Step: 2
Training loss: 2.5684220790863037
Validation loss: 2.6065187274768786

Epoch: 5| Step: 3
Training loss: 2.66526460647583
Validation loss: 2.5982386912069013

Epoch: 5| Step: 4
Training loss: 2.3685526847839355
Validation loss: 2.5906289392902004

Epoch: 5| Step: 5
Training loss: 3.1826224327087402
Validation loss: 2.5877591897082586

Epoch: 5| Step: 6
Training loss: 2.663036346435547
Validation loss: 2.5926370313090663

Epoch: 5| Step: 7
Training loss: 2.7253432273864746
Validation loss: 2.5948558956064205

Epoch: 5| Step: 8
Training loss: 2.9596381187438965
Validation loss: 2.5999462835250364

Epoch: 5| Step: 9
Training loss: 2.7667391300201416
Validation loss: 2.5955280975628923

Epoch: 5| Step: 10
Training loss: 2.778043746948242
Validation loss: 2.5883341630299888

Epoch: 43| Step: 0
Training loss: 1.8727868795394897
Validation loss: 2.593936389492404

Epoch: 5| Step: 1
Training loss: 2.83331561088562
Validation loss: 2.595308421760477

Epoch: 5| Step: 2
Training loss: 3.638357162475586
Validation loss: 2.5956665418481313

Epoch: 5| Step: 3
Training loss: 2.2919108867645264
Validation loss: 2.5926896320876254

Epoch: 5| Step: 4
Training loss: 2.71315336227417
Validation loss: 2.596918231697493

Epoch: 5| Step: 5
Training loss: 2.8124098777770996
Validation loss: 2.5991537750408216

Epoch: 5| Step: 6
Training loss: 3.214010715484619
Validation loss: 2.59939863604884

Epoch: 5| Step: 7
Training loss: 3.060760498046875
Validation loss: 2.589537130889072

Epoch: 5| Step: 8
Training loss: 1.7737720012664795
Validation loss: 2.5873219633615143

Epoch: 5| Step: 9
Training loss: 2.52199125289917
Validation loss: 2.5800449796902236

Epoch: 5| Step: 10
Training loss: 3.6371653079986572
Validation loss: 2.573697054257957

Epoch: 44| Step: 0
Training loss: 2.8026633262634277
Validation loss: 2.5680723754308556

Epoch: 5| Step: 1
Training loss: 2.114353895187378
Validation loss: 2.5714672534696517

Epoch: 5| Step: 2
Training loss: 3.372272491455078
Validation loss: 2.568892043123963

Epoch: 5| Step: 3
Training loss: 3.062739610671997
Validation loss: 2.5690761868671705

Epoch: 5| Step: 4
Training loss: 1.936363935470581
Validation loss: 2.56810260844487

Epoch: 5| Step: 5
Training loss: 3.128256320953369
Validation loss: 2.5676522767671974

Epoch: 5| Step: 6
Training loss: 2.1816165447235107
Validation loss: 2.5663958390553794

Epoch: 5| Step: 7
Training loss: 2.351853609085083
Validation loss: 2.563744468073691

Epoch: 5| Step: 8
Training loss: 2.966248035430908
Validation loss: 2.5631981357451408

Epoch: 5| Step: 9
Training loss: 3.4372787475585938
Validation loss: 2.5606799305126233

Epoch: 5| Step: 10
Training loss: 2.829495906829834
Validation loss: 2.557475984737437

Epoch: 45| Step: 0
Training loss: 2.3406872749328613
Validation loss: 2.5596825794507096

Epoch: 5| Step: 1
Training loss: 2.8055403232574463
Validation loss: 2.5617897946347474

Epoch: 5| Step: 2
Training loss: 2.9627809524536133
Validation loss: 2.566081662331858

Epoch: 5| Step: 3
Training loss: 2.9873061180114746
Validation loss: 2.5715630298019736

Epoch: 5| Step: 4
Training loss: 2.8647072315216064
Validation loss: 2.565957377033849

Epoch: 5| Step: 5
Training loss: 3.002362012863159
Validation loss: 2.561762232934275

Epoch: 5| Step: 6
Training loss: 2.0152673721313477
Validation loss: 2.556167276956702

Epoch: 5| Step: 7
Training loss: 2.5468146800994873
Validation loss: 2.5527865297050885

Epoch: 5| Step: 8
Training loss: 3.157437801361084
Validation loss: 2.5495048440912718

Epoch: 5| Step: 9
Training loss: 2.930989980697632
Validation loss: 2.5491681278392835

Epoch: 5| Step: 10
Training loss: 2.3884971141815186
Validation loss: 2.55024576956226

Epoch: 46| Step: 0
Training loss: 2.4256322383880615
Validation loss: 2.544830160756265

Epoch: 5| Step: 1
Training loss: 3.013932943344116
Validation loss: 2.5499609003784838

Epoch: 5| Step: 2
Training loss: 3.0614871978759766
Validation loss: 2.5500088686584146

Epoch: 5| Step: 3
Training loss: 2.4270875453948975
Validation loss: 2.5569088151378017

Epoch: 5| Step: 4
Training loss: 2.916633367538452
Validation loss: 2.56936639611439

Epoch: 5| Step: 5
Training loss: 3.275813341140747
Validation loss: 2.570347119403142

Epoch: 5| Step: 6
Training loss: 2.07680344581604
Validation loss: 2.5799759370024486

Epoch: 5| Step: 7
Training loss: 2.880516529083252
Validation loss: 2.573197305843394

Epoch: 5| Step: 8
Training loss: 2.8606395721435547
Validation loss: 2.573373927864977

Epoch: 5| Step: 9
Training loss: 2.2070062160491943
Validation loss: 2.5640334083187963

Epoch: 5| Step: 10
Training loss: 2.897146224975586
Validation loss: 2.5483465348520586

Epoch: 47| Step: 0
Training loss: 2.427356243133545
Validation loss: 2.5428974807903333

Epoch: 5| Step: 1
Training loss: 2.296407699584961
Validation loss: 2.541478354443786

Epoch: 5| Step: 2
Training loss: 2.690605401992798
Validation loss: 2.546153409506685

Epoch: 5| Step: 3
Training loss: 3.6419384479522705
Validation loss: 2.553256711652202

Epoch: 5| Step: 4
Training loss: 2.346560001373291
Validation loss: 2.559263744661885

Epoch: 5| Step: 5
Training loss: 2.5870747566223145
Validation loss: 2.5567514665665163

Epoch: 5| Step: 6
Training loss: 3.3496506214141846
Validation loss: 2.565465945069508

Epoch: 5| Step: 7
Training loss: 2.9474282264709473
Validation loss: 2.5602068977971233

Epoch: 5| Step: 8
Training loss: 3.0647451877593994
Validation loss: 2.553364364049768

Epoch: 5| Step: 9
Training loss: 2.6879756450653076
Validation loss: 2.549972093233498

Epoch: 5| Step: 10
Training loss: 1.9659029245376587
Validation loss: 2.5463829091800156

Epoch: 48| Step: 0
Training loss: 1.9889767169952393
Validation loss: 2.5438215142937115

Epoch: 5| Step: 1
Training loss: 2.407773971557617
Validation loss: 2.535434538318265

Epoch: 5| Step: 2
Training loss: 2.44765305519104
Validation loss: 2.5295712614572174

Epoch: 5| Step: 3
Training loss: 3.9460487365722656
Validation loss: 2.526540397315897

Epoch: 5| Step: 4
Training loss: 3.1535487174987793
Validation loss: 2.527005587854693

Epoch: 5| Step: 5
Training loss: 2.9497146606445312
Validation loss: 2.528090746172013

Epoch: 5| Step: 6
Training loss: 2.5944886207580566
Validation loss: 2.5322765586196736

Epoch: 5| Step: 7
Training loss: 2.6310083866119385
Validation loss: 2.5337638188433904

Epoch: 5| Step: 8
Training loss: 2.045346975326538
Validation loss: 2.533757371287192

Epoch: 5| Step: 9
Training loss: 2.1695809364318848
Validation loss: 2.521442820948939

Epoch: 5| Step: 10
Training loss: 3.6411166191101074
Validation loss: 2.5179658833370415

Epoch: 49| Step: 0
Training loss: 2.4340622425079346
Validation loss: 2.516010243405578

Epoch: 5| Step: 1
Training loss: 3.3042244911193848
Validation loss: 2.5113385467119116

Epoch: 5| Step: 2
Training loss: 2.833569049835205
Validation loss: 2.5100788480492047

Epoch: 5| Step: 3
Training loss: 2.21875262260437
Validation loss: 2.507785492045905

Epoch: 5| Step: 4
Training loss: 2.8167691230773926
Validation loss: 2.5096545860331547

Epoch: 5| Step: 5
Training loss: 2.2569420337677
Validation loss: 2.5062052690854637

Epoch: 5| Step: 6
Training loss: 2.7612979412078857
Validation loss: 2.5246694754528742

Epoch: 5| Step: 7
Training loss: 2.9584414958953857
Validation loss: 2.5533478747132006

Epoch: 5| Step: 8
Training loss: 3.0684070587158203
Validation loss: 2.5705465898718884

Epoch: 5| Step: 9
Training loss: 2.808807134628296
Validation loss: 2.550700310737856

Epoch: 5| Step: 10
Training loss: 2.3429064750671387
Validation loss: 2.5336880863353772

Epoch: 50| Step: 0
Training loss: 2.2133736610412598
Validation loss: 2.510479452789471

Epoch: 5| Step: 1
Training loss: 3.4151611328125
Validation loss: 2.5044774445154334

Epoch: 5| Step: 2
Training loss: 2.107484817504883
Validation loss: 2.502460423336234

Epoch: 5| Step: 3
Training loss: 2.5002477169036865
Validation loss: 2.5086843326527584

Epoch: 5| Step: 4
Training loss: 2.980346441268921
Validation loss: 2.512536382162443

Epoch: 5| Step: 5
Training loss: 3.289125442504883
Validation loss: 2.509346026246266

Epoch: 5| Step: 6
Training loss: 2.8615524768829346
Validation loss: 2.507227502843385

Epoch: 5| Step: 7
Training loss: 2.8732051849365234
Validation loss: 2.504631257826282

Epoch: 5| Step: 8
Training loss: 2.2150332927703857
Validation loss: 2.503319742859051

Epoch: 5| Step: 9
Training loss: 2.361143112182617
Validation loss: 2.505232831483246

Epoch: 5| Step: 10
Training loss: 2.9366965293884277
Validation loss: 2.4987648405054563

Epoch: 51| Step: 0
Training loss: 2.8542377948760986
Validation loss: 2.503524016308528

Epoch: 5| Step: 1
Training loss: 2.6812515258789062
Validation loss: 2.503783882305186

Epoch: 5| Step: 2
Training loss: 2.5587990283966064
Validation loss: 2.5089765312851116

Epoch: 5| Step: 3
Training loss: 2.726668357849121
Validation loss: 2.5235770440870717

Epoch: 5| Step: 4
Training loss: 2.9775166511535645
Validation loss: 2.5601174113571004

Epoch: 5| Step: 5
Training loss: 3.1606240272521973
Validation loss: 2.5816137995771182

Epoch: 5| Step: 6
Training loss: 2.4136815071105957
Validation loss: 2.544070751436295

Epoch: 5| Step: 7
Training loss: 2.9280712604522705
Validation loss: 2.516410184162919

Epoch: 5| Step: 8
Training loss: 1.9457511901855469
Validation loss: 2.4951033848588184

Epoch: 5| Step: 9
Training loss: 2.6522700786590576
Validation loss: 2.493617234691497

Epoch: 5| Step: 10
Training loss: 2.954131841659546
Validation loss: 2.50233853760586

Epoch: 52| Step: 0
Training loss: 2.6112072467803955
Validation loss: 2.5176161566088275

Epoch: 5| Step: 1
Training loss: 2.7236766815185547
Validation loss: 2.521427872360394

Epoch: 5| Step: 2
Training loss: 3.1390128135681152
Validation loss: 2.512813973170455

Epoch: 5| Step: 3
Training loss: 3.0715560913085938
Validation loss: 2.503176514820386

Epoch: 5| Step: 4
Training loss: 2.4500160217285156
Validation loss: 2.4952416112346034

Epoch: 5| Step: 5
Training loss: 2.7113845348358154
Validation loss: 2.4893117540626117

Epoch: 5| Step: 6
Training loss: 2.4005963802337646
Validation loss: 2.4889077601894254

Epoch: 5| Step: 7
Training loss: 2.302496910095215
Validation loss: 2.4895834627971856

Epoch: 5| Step: 8
Training loss: 3.3163001537323
Validation loss: 2.4860781367107103

Epoch: 5| Step: 9
Training loss: 2.612529754638672
Validation loss: 2.4910345974788872

Epoch: 5| Step: 10
Training loss: 2.3753175735473633
Validation loss: 2.489494990277034

Epoch: 53| Step: 0
Training loss: 2.500779628753662
Validation loss: 2.4924522317865843

Epoch: 5| Step: 1
Training loss: 3.3872768878936768
Validation loss: 2.489833329313545

Epoch: 5| Step: 2
Training loss: 2.8741188049316406
Validation loss: 2.4876380300009124

Epoch: 5| Step: 3
Training loss: 1.9663931131362915
Validation loss: 2.491091174464072

Epoch: 5| Step: 4
Training loss: 2.9462881088256836
Validation loss: 2.491694076086885

Epoch: 5| Step: 5
Training loss: 2.23142671585083
Validation loss: 2.4903256021520144

Epoch: 5| Step: 6
Training loss: 2.0916857719421387
Validation loss: 2.495237458136774

Epoch: 5| Step: 7
Training loss: 3.499222993850708
Validation loss: 2.556776738935901

Epoch: 5| Step: 8
Training loss: 2.810382127761841
Validation loss: 2.5999462527613484

Epoch: 5| Step: 9
Training loss: 2.780651569366455
Validation loss: 2.617646704437912

Epoch: 5| Step: 10
Training loss: 2.855010986328125
Validation loss: 2.5915230217800347

Epoch: 54| Step: 0
Training loss: 2.9741580486297607
Validation loss: 2.5547244651343233

Epoch: 5| Step: 1
Training loss: 2.2839558124542236
Validation loss: 2.51264444217887

Epoch: 5| Step: 2
Training loss: 2.4067721366882324
Validation loss: 2.501834802730109

Epoch: 5| Step: 3
Training loss: 2.4327023029327393
Validation loss: 2.4866709760440293

Epoch: 5| Step: 4
Training loss: 2.631981611251831
Validation loss: 2.487145721271474

Epoch: 5| Step: 5
Training loss: 3.2145228385925293
Validation loss: 2.4891077574863227

Epoch: 5| Step: 6
Training loss: 2.369475841522217
Validation loss: 2.4896121742904826

Epoch: 5| Step: 7
Training loss: 2.4477615356445312
Validation loss: 2.48730117787597

Epoch: 5| Step: 8
Training loss: 3.212458848953247
Validation loss: 2.4823745989030406

Epoch: 5| Step: 9
Training loss: 3.1421403884887695
Validation loss: 2.475529678406254

Epoch: 5| Step: 10
Training loss: 2.5666370391845703
Validation loss: 2.473040588440434

Epoch: 55| Step: 0
Training loss: 2.440983533859253
Validation loss: 2.4701168998595207

Epoch: 5| Step: 1
Training loss: 3.415592908859253
Validation loss: 2.470110998358778

Epoch: 5| Step: 2
Training loss: 2.2063028812408447
Validation loss: 2.471474101466517

Epoch: 5| Step: 3
Training loss: 2.4110844135284424
Validation loss: 2.4834745340449835

Epoch: 5| Step: 4
Training loss: 2.7130560874938965
Validation loss: 2.4904414402541293

Epoch: 5| Step: 5
Training loss: 3.1293208599090576
Validation loss: 2.5059306262641825

Epoch: 5| Step: 6
Training loss: 3.0121071338653564
Validation loss: 2.5110276386302006

Epoch: 5| Step: 7
Training loss: 2.525840997695923
Validation loss: 2.504826525206207

Epoch: 5| Step: 8
Training loss: 2.487379550933838
Validation loss: 2.496076883808259

Epoch: 5| Step: 9
Training loss: 3.3826842308044434
Validation loss: 2.48173830586095

Epoch: 5| Step: 10
Training loss: 1.7421605587005615
Validation loss: 2.4782675338047806

Epoch: 56| Step: 0
Training loss: 2.681795835494995
Validation loss: 2.4760778027196086

Epoch: 5| Step: 1
Training loss: 2.558717966079712
Validation loss: 2.472491987289921

Epoch: 5| Step: 2
Training loss: 2.4826512336730957
Validation loss: 2.4651317904072423

Epoch: 5| Step: 3
Training loss: 2.604795455932617
Validation loss: 2.4667121902588875

Epoch: 5| Step: 4
Training loss: 2.484189987182617
Validation loss: 2.466319614841092

Epoch: 5| Step: 5
Training loss: 2.5333340167999268
Validation loss: 2.4704989028233353

Epoch: 5| Step: 6
Training loss: 2.849536895751953
Validation loss: 2.479569540228895

Epoch: 5| Step: 7
Training loss: 2.3583462238311768
Validation loss: 2.4885638170344855

Epoch: 5| Step: 8
Training loss: 3.3541953563690186
Validation loss: 2.4855239622054563

Epoch: 5| Step: 9
Training loss: 3.040132999420166
Validation loss: 2.4788740834882184

Epoch: 5| Step: 10
Training loss: 2.595635414123535
Validation loss: 2.4663508886932046

Epoch: 57| Step: 0
Training loss: 2.0282034873962402
Validation loss: 2.458110373507264

Epoch: 5| Step: 1
Training loss: 3.311584949493408
Validation loss: 2.4566641828065277

Epoch: 5| Step: 2
Training loss: 2.3753855228424072
Validation loss: 2.45490187726995

Epoch: 5| Step: 3
Training loss: 2.632875919342041
Validation loss: 2.4546996470420592

Epoch: 5| Step: 4
Training loss: 3.1507105827331543
Validation loss: 2.4548467948872554

Epoch: 5| Step: 5
Training loss: 2.4509506225585938
Validation loss: 2.455126900826731

Epoch: 5| Step: 6
Training loss: 2.975724458694458
Validation loss: 2.4597644780271795

Epoch: 5| Step: 7
Training loss: 2.6394972801208496
Validation loss: 2.459433909385435

Epoch: 5| Step: 8
Training loss: 2.874662399291992
Validation loss: 2.4515257061168714

Epoch: 5| Step: 9
Training loss: 2.3568146228790283
Validation loss: 2.451315300438994

Epoch: 5| Step: 10
Training loss: 2.617805004119873
Validation loss: 2.4514816589252924

Epoch: 58| Step: 0
Training loss: 2.725755453109741
Validation loss: 2.4518522395882556

Epoch: 5| Step: 1
Training loss: 2.534085750579834
Validation loss: 2.4564808004645893

Epoch: 5| Step: 2
Training loss: 3.119546890258789
Validation loss: 2.4518809574906544

Epoch: 5| Step: 3
Training loss: 2.110565185546875
Validation loss: 2.455351601364792

Epoch: 5| Step: 4
Training loss: 2.2844817638397217
Validation loss: 2.4539820225008073

Epoch: 5| Step: 5
Training loss: 2.6072170734405518
Validation loss: 2.458416538853799

Epoch: 5| Step: 6
Training loss: 2.530505418777466
Validation loss: 2.450601141939881

Epoch: 5| Step: 7
Training loss: 2.973944902420044
Validation loss: 2.444415120668309

Epoch: 5| Step: 8
Training loss: 2.9875669479370117
Validation loss: 2.44391623620064

Epoch: 5| Step: 9
Training loss: 2.9137673377990723
Validation loss: 2.4418198703437723

Epoch: 5| Step: 10
Training loss: 2.540822982788086
Validation loss: 2.4419073622713805

Epoch: 59| Step: 0
Training loss: 2.5537850856781006
Validation loss: 2.4415158610190115

Epoch: 5| Step: 1
Training loss: 2.46610689163208
Validation loss: 2.445288919633435

Epoch: 5| Step: 2
Training loss: 2.4655609130859375
Validation loss: 2.4419728530350553

Epoch: 5| Step: 3
Training loss: 2.805306911468506
Validation loss: 2.438447146005528

Epoch: 5| Step: 4
Training loss: 2.8804924488067627
Validation loss: 2.4389023627004316

Epoch: 5| Step: 5
Training loss: 2.419389247894287
Validation loss: 2.438127527954758

Epoch: 5| Step: 6
Training loss: 2.428001642227173
Validation loss: 2.441119060721449

Epoch: 5| Step: 7
Training loss: 2.373095750808716
Validation loss: 2.4499498874910417

Epoch: 5| Step: 8
Training loss: 2.9446539878845215
Validation loss: 2.460258919705627

Epoch: 5| Step: 9
Training loss: 3.170427083969116
Validation loss: 2.455981844214983

Epoch: 5| Step: 10
Training loss: 2.8218705654144287
Validation loss: 2.4457808463804183

Epoch: 60| Step: 0
Training loss: 3.196756362915039
Validation loss: 2.437943611093747

Epoch: 5| Step: 1
Training loss: 2.8329713344573975
Validation loss: 2.435918158100497

Epoch: 5| Step: 2
Training loss: 2.503997325897217
Validation loss: 2.4373477402553765

Epoch: 5| Step: 3
Training loss: 2.6119887828826904
Validation loss: 2.436687320791265

Epoch: 5| Step: 4
Training loss: 2.0217700004577637
Validation loss: 2.435204791766341

Epoch: 5| Step: 5
Training loss: 2.402846574783325
Validation loss: 2.4321007305575955

Epoch: 5| Step: 6
Training loss: 2.5406229496002197
Validation loss: 2.439152617608347

Epoch: 5| Step: 7
Training loss: 3.156998872756958
Validation loss: 2.445511628222722

Epoch: 5| Step: 8
Training loss: 2.474202871322632
Validation loss: 2.4429347848379486

Epoch: 5| Step: 9
Training loss: 3.029534339904785
Validation loss: 2.445220075627809

Epoch: 5| Step: 10
Training loss: 2.5145928859710693
Validation loss: 2.449224566900602

Epoch: 61| Step: 0
Training loss: 2.513603687286377
Validation loss: 2.440070394546755

Epoch: 5| Step: 1
Training loss: 2.630042314529419
Validation loss: 2.439738440257247

Epoch: 5| Step: 2
Training loss: 2.037621021270752
Validation loss: 2.4448338580387894

Epoch: 5| Step: 3
Training loss: 2.6968142986297607
Validation loss: 2.456447870500626

Epoch: 5| Step: 4
Training loss: 1.9561233520507812
Validation loss: 2.467942830054991

Epoch: 5| Step: 5
Training loss: 2.7273120880126953
Validation loss: 2.489338239034017

Epoch: 5| Step: 6
Training loss: 3.336580753326416
Validation loss: 2.4884534651233303

Epoch: 5| Step: 7
Training loss: 2.3118762969970703
Validation loss: 2.456792967293852

Epoch: 5| Step: 8
Training loss: 2.91074800491333
Validation loss: 2.4370418223001624

Epoch: 5| Step: 9
Training loss: 3.1420722007751465
Validation loss: 2.427335944226993

Epoch: 5| Step: 10
Training loss: 3.101361036300659
Validation loss: 2.4294257394729124

Epoch: 62| Step: 0
Training loss: 3.0614829063415527
Validation loss: 2.4286592903957573

Epoch: 5| Step: 1
Training loss: 2.1958978176116943
Validation loss: 2.4311442323910293

Epoch: 5| Step: 2
Training loss: 2.152043342590332
Validation loss: 2.4317461136848695

Epoch: 5| Step: 3
Training loss: 2.3535408973693848
Validation loss: 2.4344911908590667

Epoch: 5| Step: 4
Training loss: 2.990645170211792
Validation loss: 2.432280904503279

Epoch: 5| Step: 5
Training loss: 2.447816848754883
Validation loss: 2.4281419297700286

Epoch: 5| Step: 6
Training loss: 2.562079668045044
Validation loss: 2.4325831423523607

Epoch: 5| Step: 7
Training loss: 2.731264352798462
Validation loss: 2.4437693575377106

Epoch: 5| Step: 8
Training loss: 2.9168548583984375
Validation loss: 2.4484697670064945

Epoch: 5| Step: 9
Training loss: 3.465953826904297
Validation loss: 2.4488116105397544

Epoch: 5| Step: 10
Training loss: 2.282158613204956
Validation loss: 2.4494315193545435

Epoch: 63| Step: 0
Training loss: 2.6480679512023926
Validation loss: 2.4513563417619273

Epoch: 5| Step: 1
Training loss: 2.7151365280151367
Validation loss: 2.4442912788801294

Epoch: 5| Step: 2
Training loss: 2.6554903984069824
Validation loss: 2.4374467736931256

Epoch: 5| Step: 3
Training loss: 2.5179603099823
Validation loss: 2.4427307190433627

Epoch: 5| Step: 4
Training loss: 2.5990540981292725
Validation loss: 2.4466978375629713

Epoch: 5| Step: 5
Training loss: 2.5507559776306152
Validation loss: 2.4468726265814995

Epoch: 5| Step: 6
Training loss: 2.9141833782196045
Validation loss: 2.429781965030137

Epoch: 5| Step: 7
Training loss: 2.9277279376983643
Validation loss: 2.4256916379415863

Epoch: 5| Step: 8
Training loss: 2.9895873069763184
Validation loss: 2.4148771634665867

Epoch: 5| Step: 9
Training loss: 2.493678331375122
Validation loss: 2.4118384263848744

Epoch: 5| Step: 10
Training loss: 2.2781617641448975
Validation loss: 2.413253604724843

Epoch: 64| Step: 0
Training loss: 2.6993248462677
Validation loss: 2.413897855307466

Epoch: 5| Step: 1
Training loss: 2.4500880241394043
Validation loss: 2.4137112376510457

Epoch: 5| Step: 2
Training loss: 2.58282470703125
Validation loss: 2.422795977643741

Epoch: 5| Step: 3
Training loss: 3.152740240097046
Validation loss: 2.4228373932582077

Epoch: 5| Step: 4
Training loss: 2.5335469245910645
Validation loss: 2.424295812524775

Epoch: 5| Step: 5
Training loss: 2.08821439743042
Validation loss: 2.424436266704272

Epoch: 5| Step: 6
Training loss: 2.450350046157837
Validation loss: 2.429643451526601

Epoch: 5| Step: 7
Training loss: 2.7843194007873535
Validation loss: 2.4381902935684368

Epoch: 5| Step: 8
Training loss: 2.6456196308135986
Validation loss: 2.4454086544693157

Epoch: 5| Step: 9
Training loss: 3.52368426322937
Validation loss: 2.457480215257214

Epoch: 5| Step: 10
Training loss: 2.1525447368621826
Validation loss: 2.462237201711183

Epoch: 65| Step: 0
Training loss: 2.342012643814087
Validation loss: 2.4817970901407223

Epoch: 5| Step: 1
Training loss: 3.2514801025390625
Validation loss: 2.47281551361084

Epoch: 5| Step: 2
Training loss: 2.339416980743408
Validation loss: 2.4572005323184434

Epoch: 5| Step: 3
Training loss: 1.9215576648712158
Validation loss: 2.461137079423474

Epoch: 5| Step: 4
Training loss: 2.9154880046844482
Validation loss: 2.4861077595782537

Epoch: 5| Step: 5
Training loss: 3.391737461090088
Validation loss: 2.4498217464775167

Epoch: 5| Step: 6
Training loss: 3.055495500564575
Validation loss: 2.4317704836527505

Epoch: 5| Step: 7
Training loss: 2.5830860137939453
Validation loss: 2.419406347377326

Epoch: 5| Step: 8
Training loss: 2.3486366271972656
Validation loss: 2.4104692859034382

Epoch: 5| Step: 9
Training loss: 2.621821165084839
Validation loss: 2.4184853338426158

Epoch: 5| Step: 10
Training loss: 2.6914572715759277
Validation loss: 2.4416777472342215

Epoch: 66| Step: 0
Training loss: 2.1918439865112305
Validation loss: 2.451398099622419

Epoch: 5| Step: 1
Training loss: 2.534341335296631
Validation loss: 2.4037112933333202

Epoch: 5| Step: 2
Training loss: 2.7645797729492188
Validation loss: 2.3993784971134637

Epoch: 5| Step: 3
Training loss: 2.969050168991089
Validation loss: 2.394970419586346

Epoch: 5| Step: 4
Training loss: 1.981438398361206
Validation loss: 2.408471397174302

Epoch: 5| Step: 5
Training loss: 3.1360833644866943
Validation loss: 2.403097770547354

Epoch: 5| Step: 6
Training loss: 3.416559934616089
Validation loss: 2.4006117300320695

Epoch: 5| Step: 7
Training loss: 2.0826475620269775
Validation loss: 2.404328602616505

Epoch: 5| Step: 8
Training loss: 2.8481898307800293
Validation loss: 2.4088715814775035

Epoch: 5| Step: 9
Training loss: 2.344259738922119
Validation loss: 2.4120272551813433

Epoch: 5| Step: 10
Training loss: 2.7823452949523926
Validation loss: 2.4222133569819952

Epoch: 67| Step: 0
Training loss: 2.594407320022583
Validation loss: 2.4254059201927594

Epoch: 5| Step: 1
Training loss: 2.6584320068359375
Validation loss: 2.4278531664161274

Epoch: 5| Step: 2
Training loss: 1.7377700805664062
Validation loss: 2.4248020597683486

Epoch: 5| Step: 3
Training loss: 2.564627170562744
Validation loss: 2.4253520632302887

Epoch: 5| Step: 4
Training loss: 2.7913079261779785
Validation loss: 2.427182105279738

Epoch: 5| Step: 5
Training loss: 2.2984020709991455
Validation loss: 2.4299627324586273

Epoch: 5| Step: 6
Training loss: 3.1957879066467285
Validation loss: 2.4116547312787784

Epoch: 5| Step: 7
Training loss: 2.9063708782196045
Validation loss: 2.404159361316312

Epoch: 5| Step: 8
Training loss: 2.4684877395629883
Validation loss: 2.399914035233118

Epoch: 5| Step: 9
Training loss: 2.5853543281555176
Validation loss: 2.398403718907346

Epoch: 5| Step: 10
Training loss: 3.333433151245117
Validation loss: 2.402161713569395

Epoch: 68| Step: 0
Training loss: 2.8373241424560547
Validation loss: 2.402897442540815

Epoch: 5| Step: 1
Training loss: 2.918534517288208
Validation loss: 2.40624116569437

Epoch: 5| Step: 2
Training loss: 2.202122211456299
Validation loss: 2.4095423862498295

Epoch: 5| Step: 3
Training loss: 2.337367534637451
Validation loss: 2.4163250871883926

Epoch: 5| Step: 4
Training loss: 2.8174948692321777
Validation loss: 2.4045624220243065

Epoch: 5| Step: 5
Training loss: 2.6435649394989014
Validation loss: 2.40267881911288

Epoch: 5| Step: 6
Training loss: 2.467339515686035
Validation loss: 2.402814019110895

Epoch: 5| Step: 7
Training loss: 1.9502722024917603
Validation loss: 2.399763197027227

Epoch: 5| Step: 8
Training loss: 3.2943756580352783
Validation loss: 2.4043955264552945

Epoch: 5| Step: 9
Training loss: 2.831080198287964
Validation loss: 2.4148971547362623

Epoch: 5| Step: 10
Training loss: 2.9571683406829834
Validation loss: 2.4210689426750265

Epoch: 69| Step: 0
Training loss: 2.746438503265381
Validation loss: 2.4261318509296705

Epoch: 5| Step: 1
Training loss: 2.9128599166870117
Validation loss: 2.4419091414379817

Epoch: 5| Step: 2
Training loss: 2.630985975265503
Validation loss: 2.4213236608812885

Epoch: 5| Step: 3
Training loss: 2.6860594749450684
Validation loss: 2.4103306006359797

Epoch: 5| Step: 4
Training loss: 1.8079646825790405
Validation loss: 2.394909010138563

Epoch: 5| Step: 5
Training loss: 3.1865832805633545
Validation loss: 2.3987026317145235

Epoch: 5| Step: 6
Training loss: 2.554443597793579
Validation loss: 2.404956917608938

Epoch: 5| Step: 7
Training loss: 2.3853096961975098
Validation loss: 2.3926630571324337

Epoch: 5| Step: 8
Training loss: 2.9285666942596436
Validation loss: 2.3930959496446835

Epoch: 5| Step: 9
Training loss: 3.0899276733398438
Validation loss: 2.3984530946259857

Epoch: 5| Step: 10
Training loss: 2.003842353820801
Validation loss: 2.3985021909077964

Epoch: 70| Step: 0
Training loss: 2.772455930709839
Validation loss: 2.4017511824125886

Epoch: 5| Step: 1
Training loss: 2.7722411155700684
Validation loss: 2.410237912208803

Epoch: 5| Step: 2
Training loss: 2.505225896835327
Validation loss: 2.4147250293403544

Epoch: 5| Step: 3
Training loss: 2.6412336826324463
Validation loss: 2.441986176275438

Epoch: 5| Step: 4
Training loss: 2.912393093109131
Validation loss: 2.4174788972382903

Epoch: 5| Step: 5
Training loss: 2.8848557472229004
Validation loss: 2.397558032825429

Epoch: 5| Step: 6
Training loss: 2.9284043312072754
Validation loss: 2.3764659230427077

Epoch: 5| Step: 7
Training loss: 2.208919048309326
Validation loss: 2.379994284722113

Epoch: 5| Step: 8
Training loss: 2.5876946449279785
Validation loss: 2.383958334563881

Epoch: 5| Step: 9
Training loss: 1.6845133304595947
Validation loss: 2.3897315302202777

Epoch: 5| Step: 10
Training loss: 3.2615091800689697
Validation loss: 2.401693954262682

Epoch: 71| Step: 0
Training loss: 2.964370012283325
Validation loss: 2.4127045767281645

Epoch: 5| Step: 1
Training loss: 2.0930275917053223
Validation loss: 2.4034238399997836

Epoch: 5| Step: 2
Training loss: 2.8137049674987793
Validation loss: 2.3896990796571136

Epoch: 5| Step: 3
Training loss: 2.907600164413452
Validation loss: 2.390901591188164

Epoch: 5| Step: 4
Training loss: 2.847858428955078
Validation loss: 2.383529855358985

Epoch: 5| Step: 5
Training loss: 2.016091823577881
Validation loss: 2.387054738178048

Epoch: 5| Step: 6
Training loss: 3.0899271965026855
Validation loss: 2.3961295132995932

Epoch: 5| Step: 7
Training loss: 2.763758659362793
Validation loss: 2.407161751101094

Epoch: 5| Step: 8
Training loss: 2.8046913146972656
Validation loss: 2.422118930406468

Epoch: 5| Step: 9
Training loss: 2.641416072845459
Validation loss: 2.426139329069404

Epoch: 5| Step: 10
Training loss: 2.1059319972991943
Validation loss: 2.4237552842786236

Epoch: 72| Step: 0
Training loss: 2.5768892765045166
Validation loss: 2.407695101153466

Epoch: 5| Step: 1
Training loss: 2.8638904094696045
Validation loss: 2.3852926479872836

Epoch: 5| Step: 2
Training loss: 2.7830798625946045
Validation loss: 2.3757404511974705

Epoch: 5| Step: 3
Training loss: 2.4216055870056152
Validation loss: 2.3815009235053934

Epoch: 5| Step: 4
Training loss: 3.402858018875122
Validation loss: 2.3870359979650027

Epoch: 5| Step: 5
Training loss: 2.5584895610809326
Validation loss: 2.383642165891586

Epoch: 5| Step: 6
Training loss: 2.5761494636535645
Validation loss: 2.389566185653851

Epoch: 5| Step: 7
Training loss: 2.4283173084259033
Validation loss: 2.3798331599081717

Epoch: 5| Step: 8
Training loss: 2.4937214851379395
Validation loss: 2.375435657398675

Epoch: 5| Step: 9
Training loss: 2.45100736618042
Validation loss: 2.3848928661756617

Epoch: 5| Step: 10
Training loss: 2.2655746936798096
Validation loss: 2.397500204783614

Epoch: 73| Step: 0
Training loss: 2.7270045280456543
Validation loss: 2.37793634271109

Epoch: 5| Step: 1
Training loss: 2.6072583198547363
Validation loss: 2.386073238106184

Epoch: 5| Step: 2
Training loss: 2.826900005340576
Validation loss: 2.3911842735864783

Epoch: 5| Step: 3
Training loss: 3.1254734992980957
Validation loss: 2.405911332817488

Epoch: 5| Step: 4
Training loss: 2.8189377784729004
Validation loss: 2.4046485321496123

Epoch: 5| Step: 5
Training loss: 2.50406551361084
Validation loss: 2.389479629455074

Epoch: 5| Step: 6
Training loss: 2.1492488384246826
Validation loss: 2.3822338375993954

Epoch: 5| Step: 7
Training loss: 2.713510036468506
Validation loss: 2.37131408978534

Epoch: 5| Step: 8
Training loss: 2.626197338104248
Validation loss: 2.377336089329053

Epoch: 5| Step: 9
Training loss: 2.344174385070801
Validation loss: 2.37404465675354

Epoch: 5| Step: 10
Training loss: 2.374225616455078
Validation loss: 2.3733362074821227

Epoch: 74| Step: 0
Training loss: 2.793144464492798
Validation loss: 2.369773321254279

Epoch: 5| Step: 1
Training loss: 2.5717508792877197
Validation loss: 2.371839246442241

Epoch: 5| Step: 2
Training loss: 2.4463648796081543
Validation loss: 2.3717155123269684

Epoch: 5| Step: 3
Training loss: 2.5197739601135254
Validation loss: 2.3756190192314888

Epoch: 5| Step: 4
Training loss: 2.7279818058013916
Validation loss: 2.371550588197606

Epoch: 5| Step: 5
Training loss: 1.8472230434417725
Validation loss: 2.3711806420356996

Epoch: 5| Step: 6
Training loss: 3.02331805229187
Validation loss: 2.358780999337473

Epoch: 5| Step: 7
Training loss: 2.5992813110351562
Validation loss: 2.361435205705704

Epoch: 5| Step: 8
Training loss: 3.034945249557495
Validation loss: 2.3600371473579

Epoch: 5| Step: 9
Training loss: 2.8825786113739014
Validation loss: 2.356000602886241

Epoch: 5| Step: 10
Training loss: 2.3105523586273193
Validation loss: 2.358433310703565

Epoch: 75| Step: 0
Training loss: 2.9785993099212646
Validation loss: 2.356055200740855

Epoch: 5| Step: 1
Training loss: 2.8512024879455566
Validation loss: 2.355004938699866

Epoch: 5| Step: 2
Training loss: 3.1279399394989014
Validation loss: 2.353148747515935

Epoch: 5| Step: 3
Training loss: 2.6176488399505615
Validation loss: 2.353761403791366

Epoch: 5| Step: 4
Training loss: 2.516026735305786
Validation loss: 2.351923660565448

Epoch: 5| Step: 5
Training loss: 1.9565918445587158
Validation loss: 2.350892977047992

Epoch: 5| Step: 6
Training loss: 2.227609157562256
Validation loss: 2.3495431753896896

Epoch: 5| Step: 7
Training loss: 2.5154435634613037
Validation loss: 2.347041776103358

Epoch: 5| Step: 8
Training loss: 2.2879748344421387
Validation loss: 2.3532322145277456

Epoch: 5| Step: 9
Training loss: 2.9152004718780518
Validation loss: 2.351118237741532

Epoch: 5| Step: 10
Training loss: 2.8992557525634766
Validation loss: 2.349658295672427

Epoch: 76| Step: 0
Training loss: 1.8091800212860107
Validation loss: 2.3524171588241414

Epoch: 5| Step: 1
Training loss: 2.828641176223755
Validation loss: 2.3543573784571823

Epoch: 5| Step: 2
Training loss: 2.539010763168335
Validation loss: 2.353504865400253

Epoch: 5| Step: 3
Training loss: 2.625582218170166
Validation loss: 2.3609660825421734

Epoch: 5| Step: 4
Training loss: 2.6039764881134033
Validation loss: 2.3601116262456423

Epoch: 5| Step: 5
Training loss: 2.9860479831695557
Validation loss: 2.363886305080947

Epoch: 5| Step: 6
Training loss: 2.670570135116577
Validation loss: 2.3680641420425905

Epoch: 5| Step: 7
Training loss: 2.785954236984253
Validation loss: 2.365421713039439

Epoch: 5| Step: 8
Training loss: 2.8523736000061035
Validation loss: 2.371125090506769

Epoch: 5| Step: 9
Training loss: 2.644791841506958
Validation loss: 2.3574815924449632

Epoch: 5| Step: 10
Training loss: 2.337580919265747
Validation loss: 2.3613012875280073

Epoch: 77| Step: 0
Training loss: 2.9069650173187256
Validation loss: 2.350930908674835

Epoch: 5| Step: 1
Training loss: 2.054539442062378
Validation loss: 2.3453733844141804

Epoch: 5| Step: 2
Training loss: 2.473409652709961
Validation loss: 2.3446568724929646

Epoch: 5| Step: 3
Training loss: 2.785147190093994
Validation loss: 2.3508567399876092

Epoch: 5| Step: 4
Training loss: 2.9702584743499756
Validation loss: 2.3610213264342277

Epoch: 5| Step: 5
Training loss: 3.015367031097412
Validation loss: 2.3614871014830885

Epoch: 5| Step: 6
Training loss: 2.5526928901672363
Validation loss: 2.353742430287023

Epoch: 5| Step: 7
Training loss: 2.305286407470703
Validation loss: 2.3675630477166947

Epoch: 5| Step: 8
Training loss: 2.5820484161376953
Validation loss: 2.377074344183809

Epoch: 5| Step: 9
Training loss: 2.5060389041900635
Validation loss: 2.3829745579791326

Epoch: 5| Step: 10
Training loss: 2.516124725341797
Validation loss: 2.3821404903165755

Epoch: 78| Step: 0
Training loss: 2.565429210662842
Validation loss: 2.3529473068893596

Epoch: 5| Step: 1
Training loss: 2.3706653118133545
Validation loss: 2.3407109962996615

Epoch: 5| Step: 2
Training loss: 2.596414089202881
Validation loss: 2.3366248710181123

Epoch: 5| Step: 3
Training loss: 2.506118059158325
Validation loss: 2.3364527584404073

Epoch: 5| Step: 4
Training loss: 2.948896646499634
Validation loss: 2.3359886292488343

Epoch: 5| Step: 5
Training loss: 2.670436143875122
Validation loss: 2.3387814132116174

Epoch: 5| Step: 6
Training loss: 2.3256006240844727
Validation loss: 2.3484646094742643

Epoch: 5| Step: 7
Training loss: 2.3674874305725098
Validation loss: 2.3467108254791587

Epoch: 5| Step: 8
Training loss: 2.840965986251831
Validation loss: 2.3480938096200266

Epoch: 5| Step: 9
Training loss: 3.369018077850342
Validation loss: 2.3480510404033046

Epoch: 5| Step: 10
Training loss: 2.1797778606414795
Validation loss: 2.3413782363296836

Epoch: 79| Step: 0
Training loss: 2.8851819038391113
Validation loss: 2.3330412372466056

Epoch: 5| Step: 1
Training loss: 3.128629684448242
Validation loss: 2.3341452229407524

Epoch: 5| Step: 2
Training loss: 2.2266554832458496
Validation loss: 2.333323917081279

Epoch: 5| Step: 3
Training loss: 2.105804204940796
Validation loss: 2.3389180680756927

Epoch: 5| Step: 4
Training loss: 2.5061581134796143
Validation loss: 2.3448051021945093

Epoch: 5| Step: 5
Training loss: 2.0742878913879395
Validation loss: 2.380525214697725

Epoch: 5| Step: 6
Training loss: 3.3273208141326904
Validation loss: 2.3928599972878732

Epoch: 5| Step: 7
Training loss: 3.128546953201294
Validation loss: 2.3950637130327124

Epoch: 5| Step: 8
Training loss: 1.9926574230194092
Validation loss: 2.4224216963655207

Epoch: 5| Step: 9
Training loss: 2.6219420433044434
Validation loss: 2.408935857075517

Epoch: 5| Step: 10
Training loss: 2.724161148071289
Validation loss: 2.3996126203126806

Epoch: 80| Step: 0
Training loss: 2.6126534938812256
Validation loss: 2.391728622938997

Epoch: 5| Step: 1
Training loss: 3.6837775707244873
Validation loss: 2.3839797050722185

Epoch: 5| Step: 2
Training loss: 2.595005750656128
Validation loss: 2.3579396432445896

Epoch: 5| Step: 3
Training loss: 2.3063502311706543
Validation loss: 2.344480276107788

Epoch: 5| Step: 4
Training loss: 2.6688427925109863
Validation loss: 2.342169859076059

Epoch: 5| Step: 5
Training loss: 2.9768691062927246
Validation loss: 2.3310601762546006

Epoch: 5| Step: 6
Training loss: 2.481161594390869
Validation loss: 2.3316323449534755

Epoch: 5| Step: 7
Training loss: 1.7883899211883545
Validation loss: 2.3268941397308023

Epoch: 5| Step: 8
Training loss: 2.6075172424316406
Validation loss: 2.3231971930432063

Epoch: 5| Step: 9
Training loss: 2.174050807952881
Validation loss: 2.327576970541349

Epoch: 5| Step: 10
Training loss: 2.646939277648926
Validation loss: 2.3276885376181653

Epoch: 81| Step: 0
Training loss: 3.4261631965637207
Validation loss: 2.327114984553347

Epoch: 5| Step: 1
Training loss: 3.183964490890503
Validation loss: 2.3256631397431895

Epoch: 5| Step: 2
Training loss: 1.9342286586761475
Validation loss: 2.320214245909004

Epoch: 5| Step: 3
Training loss: 2.0174126625061035
Validation loss: 2.327161383885209

Epoch: 5| Step: 4
Training loss: 2.2392008304595947
Validation loss: 2.3382774194081626

Epoch: 5| Step: 5
Training loss: 3.1058766841888428
Validation loss: 2.3589606644004903

Epoch: 5| Step: 6
Training loss: 2.4312751293182373
Validation loss: 2.3726238999315488

Epoch: 5| Step: 7
Training loss: 2.352557420730591
Validation loss: 2.3575524873630975

Epoch: 5| Step: 8
Training loss: 2.494473934173584
Validation loss: 2.3520136635790587

Epoch: 5| Step: 9
Training loss: 2.373950481414795
Validation loss: 2.340758313414871

Epoch: 5| Step: 10
Training loss: 3.016057252883911
Validation loss: 2.3402069178960656

Epoch: 82| Step: 0
Training loss: 2.4447288513183594
Validation loss: 2.336326429920812

Epoch: 5| Step: 1
Training loss: 3.071132183074951
Validation loss: 2.326012842116817

Epoch: 5| Step: 2
Training loss: 3.026334047317505
Validation loss: 2.3176031445944183

Epoch: 5| Step: 3
Training loss: 2.514221668243408
Validation loss: 2.322014231835642

Epoch: 5| Step: 4
Training loss: 2.7463340759277344
Validation loss: 2.325545939066077

Epoch: 5| Step: 5
Training loss: 2.526787519454956
Validation loss: 2.3212840480189167

Epoch: 5| Step: 6
Training loss: 2.2445435523986816
Validation loss: 2.328068264069096

Epoch: 5| Step: 7
Training loss: 2.2372422218322754
Validation loss: 2.33132686409899

Epoch: 5| Step: 8
Training loss: 3.055241346359253
Validation loss: 2.331219534720144

Epoch: 5| Step: 9
Training loss: 2.1792218685150146
Validation loss: 2.3208598526575233

Epoch: 5| Step: 10
Training loss: 2.3922951221466064
Validation loss: 2.313846788098735

Epoch: 83| Step: 0
Training loss: 2.8860931396484375
Validation loss: 2.3129076188610447

Epoch: 5| Step: 1
Training loss: 3.7190895080566406
Validation loss: 2.313839581704909

Epoch: 5| Step: 2
Training loss: 2.738128423690796
Validation loss: 2.3080522655158915

Epoch: 5| Step: 3
Training loss: 2.41667103767395
Validation loss: 2.30558527669599

Epoch: 5| Step: 4
Training loss: 1.9952856302261353
Validation loss: 2.305044420303837

Epoch: 5| Step: 5
Training loss: 3.1277434825897217
Validation loss: 2.310615239604827

Epoch: 5| Step: 6
Training loss: 2.6480939388275146
Validation loss: 2.3356967472260997

Epoch: 5| Step: 7
Training loss: 2.207376480102539
Validation loss: 2.352741482437298

Epoch: 5| Step: 8
Training loss: 2.3315815925598145
Validation loss: 2.3522899868667766

Epoch: 5| Step: 9
Training loss: 2.2596774101257324
Validation loss: 2.3637000104432464

Epoch: 5| Step: 10
Training loss: 2.0239222049713135
Validation loss: 2.3878818404289985

Epoch: 84| Step: 0
Training loss: 2.0598788261413574
Validation loss: 2.3816217325067006

Epoch: 5| Step: 1
Training loss: 2.704253673553467
Validation loss: 2.370423868138303

Epoch: 5| Step: 2
Training loss: 3.0433013439178467
Validation loss: 2.341687927963913

Epoch: 5| Step: 3
Training loss: 2.8403282165527344
Validation loss: 2.3220766975033666

Epoch: 5| Step: 4
Training loss: 2.384342908859253
Validation loss: 2.303693438089022

Epoch: 5| Step: 5
Training loss: 2.464320659637451
Validation loss: 2.301519701557775

Epoch: 5| Step: 6
Training loss: 2.586677074432373
Validation loss: 2.3053107338566936

Epoch: 5| Step: 7
Training loss: 3.1891655921936035
Validation loss: 2.296229085614604

Epoch: 5| Step: 8
Training loss: 2.55936336517334
Validation loss: 2.2964919485071653

Epoch: 5| Step: 9
Training loss: 2.2851614952087402
Validation loss: 2.3027642132133566

Epoch: 5| Step: 10
Training loss: 2.43026065826416
Validation loss: 2.316430207221739

Epoch: 85| Step: 0
Training loss: 2.173487663269043
Validation loss: 2.330761763357347

Epoch: 5| Step: 1
Training loss: 2.3675389289855957
Validation loss: 2.362555803791169

Epoch: 5| Step: 2
Training loss: 1.7906982898712158
Validation loss: 2.387696353338098

Epoch: 5| Step: 3
Training loss: 3.2639517784118652
Validation loss: 2.396817922592163

Epoch: 5| Step: 4
Training loss: 2.7573561668395996
Validation loss: 2.38980443503267

Epoch: 5| Step: 5
Training loss: 2.750197172164917
Validation loss: 2.3728291219280613

Epoch: 5| Step: 6
Training loss: 3.338225841522217
Validation loss: 2.338307724204115

Epoch: 5| Step: 7
Training loss: 1.7572294473648071
Validation loss: 2.3071425268726964

Epoch: 5| Step: 8
Training loss: 3.042728900909424
Validation loss: 2.293932471224057

Epoch: 5| Step: 9
Training loss: 3.085787296295166
Validation loss: 2.288510068770378

Epoch: 5| Step: 10
Training loss: 1.9861162900924683
Validation loss: 2.2926599620490946

Epoch: 86| Step: 0
Training loss: 3.2215805053710938
Validation loss: 2.292760564434913

Epoch: 5| Step: 1
Training loss: 3.0615084171295166
Validation loss: 2.2948338575260614

Epoch: 5| Step: 2
Training loss: 2.2974038124084473
Validation loss: 2.294219973266766

Epoch: 5| Step: 3
Training loss: 2.464061737060547
Validation loss: 2.2923930973135014

Epoch: 5| Step: 4
Training loss: 2.573068141937256
Validation loss: 2.288265379526282

Epoch: 5| Step: 5
Training loss: 2.443829298019409
Validation loss: 2.2903505089462444

Epoch: 5| Step: 6
Training loss: 2.701611042022705
Validation loss: 2.29379117232497

Epoch: 5| Step: 7
Training loss: 2.790797710418701
Validation loss: 2.297418845597134

Epoch: 5| Step: 8
Training loss: 2.1408584117889404
Validation loss: 2.3009169640079623

Epoch: 5| Step: 9
Training loss: 2.354560136795044
Validation loss: 2.307808291527533

Epoch: 5| Step: 10
Training loss: 2.21315598487854
Validation loss: 2.310150065729695

Epoch: 87| Step: 0
Training loss: 2.4959051609039307
Validation loss: 2.3217273886485765

Epoch: 5| Step: 1
Training loss: 2.204690456390381
Validation loss: 2.334711797775761

Epoch: 5| Step: 2
Training loss: 2.5814757347106934
Validation loss: 2.3400783436272734

Epoch: 5| Step: 3
Training loss: 2.871203899383545
Validation loss: 2.348997010979601

Epoch: 5| Step: 4
Training loss: 2.3525545597076416
Validation loss: 2.3590743413535495

Epoch: 5| Step: 5
Training loss: 3.1358580589294434
Validation loss: 2.3400963070572063

Epoch: 5| Step: 6
Training loss: 2.2855470180511475
Validation loss: 2.3359920170999344

Epoch: 5| Step: 7
Training loss: 2.7878453731536865
Validation loss: 2.3181073870710147

Epoch: 5| Step: 8
Training loss: 2.859140157699585
Validation loss: 2.311609673243697

Epoch: 5| Step: 9
Training loss: 1.9705795049667358
Validation loss: 2.294208788102673

Epoch: 5| Step: 10
Training loss: 2.6611599922180176
Validation loss: 2.2858849135778283

Epoch: 88| Step: 0
Training loss: 2.6561553478240967
Validation loss: 2.286206610741154

Epoch: 5| Step: 1
Training loss: 2.429716110229492
Validation loss: 2.294731729774065

Epoch: 5| Step: 2
Training loss: 2.4998514652252197
Validation loss: 2.2975566822995424

Epoch: 5| Step: 3
Training loss: 3.02150297164917
Validation loss: 2.299843265164283

Epoch: 5| Step: 4
Training loss: 2.5792500972747803
Validation loss: 2.2921701400510726

Epoch: 5| Step: 5
Training loss: 1.8301441669464111
Validation loss: 2.306370930005145

Epoch: 5| Step: 6
Training loss: 3.0211658477783203
Validation loss: 2.317946275075277

Epoch: 5| Step: 7
Training loss: 2.5988681316375732
Validation loss: 2.322652819336102

Epoch: 5| Step: 8
Training loss: 2.629800319671631
Validation loss: 2.316196272450109

Epoch: 5| Step: 9
Training loss: 2.666167974472046
Validation loss: 2.3139066516712146

Epoch: 5| Step: 10
Training loss: 2.5103275775909424
Validation loss: 2.304270600759855

Epoch: 89| Step: 0
Training loss: 2.0204551219940186
Validation loss: 2.3005535012932232

Epoch: 5| Step: 1
Training loss: 2.972682476043701
Validation loss: 2.3055739633498655

Epoch: 5| Step: 2
Training loss: 2.745940685272217
Validation loss: 2.3047814881929787

Epoch: 5| Step: 3
Training loss: 2.6160380840301514
Validation loss: 2.303134517003131

Epoch: 5| Step: 4
Training loss: 2.502577304840088
Validation loss: 2.3142002115967455

Epoch: 5| Step: 5
Training loss: 2.5128026008605957
Validation loss: 2.3416199568779237

Epoch: 5| Step: 6
Training loss: 2.440587282180786
Validation loss: 2.3657008755591606

Epoch: 5| Step: 7
Training loss: 2.404738187789917
Validation loss: 2.452142382180819

Epoch: 5| Step: 8
Training loss: 3.0837464332580566
Validation loss: 2.4739424310704714

Epoch: 5| Step: 9
Training loss: 2.326812267303467
Validation loss: 2.433954697783275

Epoch: 5| Step: 10
Training loss: 2.8704164028167725
Validation loss: 2.3673622377457155

Epoch: 90| Step: 0
Training loss: 2.3451762199401855
Validation loss: 2.31400385210591

Epoch: 5| Step: 1
Training loss: 2.5967700481414795
Validation loss: 2.283737508199548

Epoch: 5| Step: 2
Training loss: 2.756232976913452
Validation loss: 2.2797253926595054

Epoch: 5| Step: 3
Training loss: 2.5255980491638184
Validation loss: 2.2919579885339223

Epoch: 5| Step: 4
Training loss: 2.828763723373413
Validation loss: 2.3113671887305474

Epoch: 5| Step: 5
Training loss: 2.442753314971924
Validation loss: 2.3205203984373357

Epoch: 5| Step: 6
Training loss: 3.096595048904419
Validation loss: 2.316795331175609

Epoch: 5| Step: 7
Training loss: 2.7731869220733643
Validation loss: 2.300733035610568

Epoch: 5| Step: 8
Training loss: 2.4951539039611816
Validation loss: 2.298812520119452

Epoch: 5| Step: 9
Training loss: 3.0471763610839844
Validation loss: 2.2919233793853433

Epoch: 5| Step: 10
Training loss: 1.5554604530334473
Validation loss: 2.2885005653545423

Epoch: 91| Step: 0
Training loss: 2.4101171493530273
Validation loss: 2.277116357639272

Epoch: 5| Step: 1
Training loss: 2.397050142288208
Validation loss: 2.2607818829116

Epoch: 5| Step: 2
Training loss: 2.4677231311798096
Validation loss: 2.2723138563094603

Epoch: 5| Step: 3
Training loss: 2.462531566619873
Validation loss: 2.2838953669353197

Epoch: 5| Step: 4
Training loss: 2.194162607192993
Validation loss: 2.301440700407951

Epoch: 5| Step: 5
Training loss: 2.442720413208008
Validation loss: 2.3138397662870345

Epoch: 5| Step: 6
Training loss: 2.693837881088257
Validation loss: 2.3269474749924033

Epoch: 5| Step: 7
Training loss: 2.421374559402466
Validation loss: 2.3258233865102134

Epoch: 5| Step: 8
Training loss: 2.8280158042907715
Validation loss: 2.3114554343685025

Epoch: 5| Step: 9
Training loss: 2.9023666381835938
Validation loss: 2.299946303008705

Epoch: 5| Step: 10
Training loss: 2.921922445297241
Validation loss: 2.294505483360701

Epoch: 92| Step: 0
Training loss: 1.6138989925384521
Validation loss: 2.2958615287657707

Epoch: 5| Step: 1
Training loss: 2.862466335296631
Validation loss: 2.293717251029066

Epoch: 5| Step: 2
Training loss: 2.5008950233459473
Validation loss: 2.2868674596150718

Epoch: 5| Step: 3
Training loss: 2.746518850326538
Validation loss: 2.270951247984363

Epoch: 5| Step: 4
Training loss: 2.998281717300415
Validation loss: 2.261818250020345

Epoch: 5| Step: 5
Training loss: 2.6542325019836426
Validation loss: 2.2625237934051023

Epoch: 5| Step: 6
Training loss: 2.489100456237793
Validation loss: 2.2608007077247865

Epoch: 5| Step: 7
Training loss: 1.9497158527374268
Validation loss: 2.254522080062538

Epoch: 5| Step: 8
Training loss: 2.812209367752075
Validation loss: 2.2494516295771443

Epoch: 5| Step: 9
Training loss: 2.9768171310424805
Validation loss: 2.2584211646869616

Epoch: 5| Step: 10
Training loss: 2.4393718242645264
Validation loss: 2.2742052539702384

Epoch: 93| Step: 0
Training loss: 2.4606940746307373
Validation loss: 2.298497043630128

Epoch: 5| Step: 1
Training loss: 2.775033473968506
Validation loss: 2.345682377456337

Epoch: 5| Step: 2
Training loss: 2.3374781608581543
Validation loss: 2.342795977028467

Epoch: 5| Step: 3
Training loss: 3.2321548461914062
Validation loss: 2.323257612925704

Epoch: 5| Step: 4
Training loss: 2.6370816230773926
Validation loss: 2.2809602932263444

Epoch: 5| Step: 5
Training loss: 2.476051092147827
Validation loss: 2.2579322322722404

Epoch: 5| Step: 6
Training loss: 2.280485153198242
Validation loss: 2.249413751786755

Epoch: 5| Step: 7
Training loss: 2.660609006881714
Validation loss: 2.2508928416877665

Epoch: 5| Step: 8
Training loss: 2.134922504425049
Validation loss: 2.255772744455645

Epoch: 5| Step: 9
Training loss: 2.8235738277435303
Validation loss: 2.257760150458223

Epoch: 5| Step: 10
Training loss: 2.3676280975341797
Validation loss: 2.261610687419932

Epoch: 94| Step: 0
Training loss: 2.004302740097046
Validation loss: 2.257824185074017

Epoch: 5| Step: 1
Training loss: 2.8488306999206543
Validation loss: 2.3001783740135933

Epoch: 5| Step: 2
Training loss: 2.4078688621520996
Validation loss: 2.3149372582794516

Epoch: 5| Step: 3
Training loss: 2.882214307785034
Validation loss: 2.299166266636182

Epoch: 5| Step: 4
Training loss: 2.8775997161865234
Validation loss: 2.2647091470738894

Epoch: 5| Step: 5
Training loss: 2.2057158946990967
Validation loss: 2.261398515393657

Epoch: 5| Step: 6
Training loss: 2.044508934020996
Validation loss: 2.2654652287883144

Epoch: 5| Step: 7
Training loss: 2.608401298522949
Validation loss: 2.2588007116830475

Epoch: 5| Step: 8
Training loss: 2.493692398071289
Validation loss: 2.2592207693284556

Epoch: 5| Step: 9
Training loss: 2.806553602218628
Validation loss: 2.2529187407544864

Epoch: 5| Step: 10
Training loss: 3.0563652515411377
Validation loss: 2.247777759387929

Epoch: 95| Step: 0
Training loss: 2.5852198600769043
Validation loss: 2.2532803038115143

Epoch: 5| Step: 1
Training loss: 3.278949737548828
Validation loss: 2.2621612279645857

Epoch: 5| Step: 2
Training loss: 2.6565511226654053
Validation loss: 2.271679929507676

Epoch: 5| Step: 3
Training loss: 2.3474113941192627
Validation loss: 2.2696259662669194

Epoch: 5| Step: 4
Training loss: 2.3767342567443848
Validation loss: 2.2607656986482683

Epoch: 5| Step: 5
Training loss: 1.973043441772461
Validation loss: 2.263874010373187

Epoch: 5| Step: 6
Training loss: 2.417384386062622
Validation loss: 2.2548231219732635

Epoch: 5| Step: 7
Training loss: 2.376798629760742
Validation loss: 2.252894748923599

Epoch: 5| Step: 8
Training loss: 2.406074285507202
Validation loss: 2.2557448776819373

Epoch: 5| Step: 9
Training loss: 2.7001235485076904
Validation loss: 2.2516751853368615

Epoch: 5| Step: 10
Training loss: 2.8506433963775635
Validation loss: 2.248488618481544

Epoch: 96| Step: 0
Training loss: 2.2868800163269043
Validation loss: 2.2431878146304878

Epoch: 5| Step: 1
Training loss: 2.735081434249878
Validation loss: 2.244148482558548

Epoch: 5| Step: 2
Training loss: 2.206528425216675
Validation loss: 2.2460594266973515

Epoch: 5| Step: 3
Training loss: 2.69970965385437
Validation loss: 2.2464584535168064

Epoch: 5| Step: 4
Training loss: 3.0024256706237793
Validation loss: 2.260585411902397

Epoch: 5| Step: 5
Training loss: 2.248488664627075
Validation loss: 2.254138215895622

Epoch: 5| Step: 6
Training loss: 2.440495014190674
Validation loss: 2.2496119904261764

Epoch: 5| Step: 7
Training loss: 2.644644260406494
Validation loss: 2.2552456496864237

Epoch: 5| Step: 8
Training loss: 2.4463820457458496
Validation loss: 2.246070764398062

Epoch: 5| Step: 9
Training loss: 2.9610044956207275
Validation loss: 2.2541077367721067

Epoch: 5| Step: 10
Training loss: 1.9617029428482056
Validation loss: 2.262995755800637

Epoch: 97| Step: 0
Training loss: 1.4420454502105713
Validation loss: 2.289370452204058

Epoch: 5| Step: 1
Training loss: 2.3969333171844482
Validation loss: 2.3137226771282893

Epoch: 5| Step: 2
Training loss: 2.1961472034454346
Validation loss: 2.3254331542599584

Epoch: 5| Step: 3
Training loss: 3.079028606414795
Validation loss: 2.3193394086694203

Epoch: 5| Step: 4
Training loss: 2.7221035957336426
Validation loss: 2.2859038332457184

Epoch: 5| Step: 5
Training loss: 2.901017427444458
Validation loss: 2.2499004217886154

Epoch: 5| Step: 6
Training loss: 2.8452374935150146
Validation loss: 2.2348101908160793

Epoch: 5| Step: 7
Training loss: 2.7362029552459717
Validation loss: 2.2270989366756972

Epoch: 5| Step: 8
Training loss: 2.7098135948181152
Validation loss: 2.2232776662354827

Epoch: 5| Step: 9
Training loss: 1.8380638360977173
Validation loss: 2.224182362197548

Epoch: 5| Step: 10
Training loss: 3.089559555053711
Validation loss: 2.22118668658759

Epoch: 98| Step: 0
Training loss: 2.2951152324676514
Validation loss: 2.2197465537696757

Epoch: 5| Step: 1
Training loss: 3.185654401779175
Validation loss: 2.2222918054108978

Epoch: 5| Step: 2
Training loss: 2.435549736022949
Validation loss: 2.224743802060363

Epoch: 5| Step: 3
Training loss: 2.14121413230896
Validation loss: 2.240135536398939

Epoch: 5| Step: 4
Training loss: 2.472531795501709
Validation loss: 2.2309074119854997

Epoch: 5| Step: 5
Training loss: 2.615600109100342
Validation loss: 2.22863600074604

Epoch: 5| Step: 6
Training loss: 2.92679500579834
Validation loss: 2.222821956039757

Epoch: 5| Step: 7
Training loss: 2.7134740352630615
Validation loss: 2.2219063620413504

Epoch: 5| Step: 8
Training loss: 2.068957805633545
Validation loss: 2.224398179720807

Epoch: 5| Step: 9
Training loss: 2.3202242851257324
Validation loss: 2.2246345448237594

Epoch: 5| Step: 10
Training loss: 2.4791195392608643
Validation loss: 2.227834783574586

Epoch: 99| Step: 0
Training loss: 2.6136443614959717
Validation loss: 2.2498082396804646

Epoch: 5| Step: 1
Training loss: 2.3750367164611816
Validation loss: 2.2675244013468423

Epoch: 5| Step: 2
Training loss: 2.237382411956787
Validation loss: 2.2949726286754815

Epoch: 5| Step: 3
Training loss: 3.2250919342041016
Validation loss: 2.2786598974658596

Epoch: 5| Step: 4
Training loss: 2.7077841758728027
Validation loss: 2.2834214382274176

Epoch: 5| Step: 5
Training loss: 1.8398182392120361
Validation loss: 2.2675682037107405

Epoch: 5| Step: 6
Training loss: 2.6019814014434814
Validation loss: 2.253076499508273

Epoch: 5| Step: 7
Training loss: 2.3560614585876465
Validation loss: 2.2334495129123813

Epoch: 5| Step: 8
Training loss: 3.0392863750457764
Validation loss: 2.220250834700882

Epoch: 5| Step: 9
Training loss: 2.61663818359375
Validation loss: 2.22344083298919

Epoch: 5| Step: 10
Training loss: 1.918574571609497
Validation loss: 2.218909640466013

Epoch: 100| Step: 0
Training loss: 2.5397884845733643
Validation loss: 2.2197464922423005

Epoch: 5| Step: 1
Training loss: 2.472559928894043
Validation loss: 2.220446091826244

Epoch: 5| Step: 2
Training loss: 2.3047573566436768
Validation loss: 2.223413887844291

Epoch: 5| Step: 3
Training loss: 2.5975356101989746
Validation loss: 2.235631004456551

Epoch: 5| Step: 4
Training loss: 2.3753485679626465
Validation loss: 2.244528421791651

Epoch: 5| Step: 5
Training loss: 2.680567502975464
Validation loss: 2.2491107115181546

Epoch: 5| Step: 6
Training loss: 2.685652732849121
Validation loss: 2.225652333228819

Epoch: 5| Step: 7
Training loss: 3.0142199993133545
Validation loss: 2.208766498873311

Epoch: 5| Step: 8
Training loss: 2.860894203186035
Validation loss: 2.2013229593153922

Epoch: 5| Step: 9
Training loss: 1.7792514562606812
Validation loss: 2.1996052572804112

Epoch: 5| Step: 10
Training loss: 2.2605128288269043
Validation loss: 2.201381378276374

Epoch: 101| Step: 0
Training loss: 3.1086628437042236
Validation loss: 2.2106743576706096

Epoch: 5| Step: 1
Training loss: 2.3640642166137695
Validation loss: 2.2390419539584907

Epoch: 5| Step: 2
Training loss: 2.5291454792022705
Validation loss: 2.254642848045595

Epoch: 5| Step: 3
Training loss: 2.2951138019561768
Validation loss: 2.265443367342795

Epoch: 5| Step: 4
Training loss: 2.423910140991211
Validation loss: 2.2444710628960722

Epoch: 5| Step: 5
Training loss: 2.347719192504883
Validation loss: 2.246193496129846

Epoch: 5| Step: 6
Training loss: 2.695254325866699
Validation loss: 2.222923735136627

Epoch: 5| Step: 7
Training loss: 2.396972894668579
Validation loss: 2.208536163453133

Epoch: 5| Step: 8
Training loss: 2.436108112335205
Validation loss: 2.2121798069246355

Epoch: 5| Step: 9
Training loss: 2.621492385864258
Validation loss: 2.217056329532336

Epoch: 5| Step: 10
Training loss: 2.168445587158203
Validation loss: 2.2104707174403693

Epoch: 102| Step: 0
Training loss: 2.2850499153137207
Validation loss: 2.210676713656354

Epoch: 5| Step: 1
Training loss: 2.73616886138916
Validation loss: 2.2202813189516784

Epoch: 5| Step: 2
Training loss: 2.2707786560058594
Validation loss: 2.2219624570620957

Epoch: 5| Step: 3
Training loss: 2.9608817100524902
Validation loss: 2.233746115879346

Epoch: 5| Step: 4
Training loss: 2.100722312927246
Validation loss: 2.246952808031472

Epoch: 5| Step: 5
Training loss: 1.9328140020370483
Validation loss: 2.248468065774569

Epoch: 5| Step: 6
Training loss: 2.7820537090301514
Validation loss: 2.2370970723449544

Epoch: 5| Step: 7
Training loss: 2.5955874919891357
Validation loss: 2.21448468008349

Epoch: 5| Step: 8
Training loss: 3.2207159996032715
Validation loss: 2.205758261424239

Epoch: 5| Step: 9
Training loss: 1.9551197290420532
Validation loss: 2.1959776698902087

Epoch: 5| Step: 10
Training loss: 2.620697021484375
Validation loss: 2.1932997908643497

Epoch: 103| Step: 0
Training loss: 2.597921848297119
Validation loss: 2.192052577131538

Epoch: 5| Step: 1
Training loss: 1.5037635564804077
Validation loss: 2.2031026322354554

Epoch: 5| Step: 2
Training loss: 2.8364319801330566
Validation loss: 2.201168449976111

Epoch: 5| Step: 3
Training loss: 2.854952573776245
Validation loss: 2.1971059794067056

Epoch: 5| Step: 4
Training loss: 2.5569071769714355
Validation loss: 2.202330789258403

Epoch: 5| Step: 5
Training loss: 2.665984630584717
Validation loss: 2.201269530480908

Epoch: 5| Step: 6
Training loss: 2.494103193283081
Validation loss: 2.209563055346089

Epoch: 5| Step: 7
Training loss: 2.9597389698028564
Validation loss: 2.2128102702479207

Epoch: 5| Step: 8
Training loss: 2.2396886348724365
Validation loss: 2.2350691364657496

Epoch: 5| Step: 9
Training loss: 2.735142469406128
Validation loss: 2.2461988823388213

Epoch: 5| Step: 10
Training loss: 1.9039275646209717
Validation loss: 2.251812437529205

Epoch: 104| Step: 0
Training loss: 2.295079231262207
Validation loss: 2.2261387366120533

Epoch: 5| Step: 1
Training loss: 1.7259677648544312
Validation loss: 2.2227248402052027

Epoch: 5| Step: 2
Training loss: 2.6644325256347656
Validation loss: 2.2203505577579623

Epoch: 5| Step: 3
Training loss: 2.898092746734619
Validation loss: 2.232591930256095

Epoch: 5| Step: 4
Training loss: 2.3488943576812744
Validation loss: 2.238048558594078

Epoch: 5| Step: 5
Training loss: 2.8543198108673096
Validation loss: 2.218057629882648

Epoch: 5| Step: 6
Training loss: 2.761727809906006
Validation loss: 2.2105813923702446

Epoch: 5| Step: 7
Training loss: 2.0273380279541016
Validation loss: 2.2121278650017193

Epoch: 5| Step: 8
Training loss: 2.665235996246338
Validation loss: 2.207349572130429

Epoch: 5| Step: 9
Training loss: 2.9714438915252686
Validation loss: 2.2159582671298774

Epoch: 5| Step: 10
Training loss: 2.1367130279541016
Validation loss: 2.1962836916728685

Epoch: 105| Step: 0
Training loss: 2.428252696990967
Validation loss: 2.190916512602119

Epoch: 5| Step: 1
Training loss: 2.1244301795959473
Validation loss: 2.1929846091936995

Epoch: 5| Step: 2
Training loss: 1.894248604774475
Validation loss: 2.2078410502403014

Epoch: 5| Step: 3
Training loss: 2.4463515281677246
Validation loss: 2.220304953154697

Epoch: 5| Step: 4
Training loss: 2.526716709136963
Validation loss: 2.2593090739301456

Epoch: 5| Step: 5
Training loss: 3.0053915977478027
Validation loss: 2.2889434701652935

Epoch: 5| Step: 6
Training loss: 3.2099862098693848
Validation loss: 2.299410408543002

Epoch: 5| Step: 7
Training loss: 2.9492368698120117
Validation loss: 2.2663481491868214

Epoch: 5| Step: 8
Training loss: 2.196439504623413
Validation loss: 2.225687893488074

Epoch: 5| Step: 9
Training loss: 1.9982688426971436
Validation loss: 2.1975842201581566

Epoch: 5| Step: 10
Training loss: 2.5515177249908447
Validation loss: 2.1905745472959293

Epoch: 106| Step: 0
Training loss: 2.7242960929870605
Validation loss: 2.187794167508361

Epoch: 5| Step: 1
Training loss: 2.5211424827575684
Validation loss: 2.192742481026598

Epoch: 5| Step: 2
Training loss: 1.6414785385131836
Validation loss: 2.190250159591757

Epoch: 5| Step: 3
Training loss: 2.356689453125
Validation loss: 2.1940154349932106

Epoch: 5| Step: 4
Training loss: 2.2126293182373047
Validation loss: 2.183102302653815

Epoch: 5| Step: 5
Training loss: 3.0808191299438477
Validation loss: 2.1820347027112077

Epoch: 5| Step: 6
Training loss: 2.9475550651550293
Validation loss: 2.177851205231041

Epoch: 5| Step: 7
Training loss: 2.968961000442505
Validation loss: 2.1887961049233713

Epoch: 5| Step: 8
Training loss: 2.639444351196289
Validation loss: 2.1862571829108783

Epoch: 5| Step: 9
Training loss: 2.518186569213867
Validation loss: 2.1824929022019908

Epoch: 5| Step: 10
Training loss: 1.680924892425537
Validation loss: 2.1966367870248775

Epoch: 107| Step: 0
Training loss: 2.482922077178955
Validation loss: 2.2127530138979674

Epoch: 5| Step: 1
Training loss: 1.7269818782806396
Validation loss: 2.2137542360572406

Epoch: 5| Step: 2
Training loss: 2.91398549079895
Validation loss: 2.2100308864347395

Epoch: 5| Step: 3
Training loss: 3.379207134246826
Validation loss: 2.2102427136513496

Epoch: 5| Step: 4
Training loss: 1.9900004863739014
Validation loss: 2.215013632210352

Epoch: 5| Step: 5
Training loss: 2.58562970161438
Validation loss: 2.2079672839051936

Epoch: 5| Step: 6
Training loss: 2.2308108806610107
Validation loss: 2.2010441031507266

Epoch: 5| Step: 7
Training loss: 2.1718387603759766
Validation loss: 2.1922990916877665

Epoch: 5| Step: 8
Training loss: 2.631136655807495
Validation loss: 2.178281207238474

Epoch: 5| Step: 9
Training loss: 2.4429848194122314
Validation loss: 2.177611674031904

Epoch: 5| Step: 10
Training loss: 2.635910749435425
Validation loss: 2.190126319085398

Epoch: 108| Step: 0
Training loss: 2.515132427215576
Validation loss: 2.205533463467834

Epoch: 5| Step: 1
Training loss: 2.628777503967285
Validation loss: 2.191930204309443

Epoch: 5| Step: 2
Training loss: 2.493630886077881
Validation loss: 2.206450948151209

Epoch: 5| Step: 3
Training loss: 2.745788335800171
Validation loss: 2.2164690955992667

Epoch: 5| Step: 4
Training loss: 2.109147310256958
Validation loss: 2.211511934957197

Epoch: 5| Step: 5
Training loss: 2.481370210647583
Validation loss: 2.1970708318935928

Epoch: 5| Step: 6
Training loss: 2.9143357276916504
Validation loss: 2.188279269843973

Epoch: 5| Step: 7
Training loss: 2.6834189891815186
Validation loss: 2.169955327946653

Epoch: 5| Step: 8
Training loss: 2.231304883956909
Validation loss: 2.1608598821906635

Epoch: 5| Step: 9
Training loss: 2.2908711433410645
Validation loss: 2.159151561798588

Epoch: 5| Step: 10
Training loss: 2.1087944507598877
Validation loss: 2.1616289436176257

Epoch: 109| Step: 0
Training loss: 3.3512063026428223
Validation loss: 2.1687330430553806

Epoch: 5| Step: 1
Training loss: 2.393155336380005
Validation loss: 2.1723753841974403

Epoch: 5| Step: 2
Training loss: 2.4239935874938965
Validation loss: 2.1760150155713482

Epoch: 5| Step: 3
Training loss: 2.025874614715576
Validation loss: 2.190579047767065

Epoch: 5| Step: 4
Training loss: 2.518693685531616
Validation loss: 2.1909542160649456

Epoch: 5| Step: 5
Training loss: 2.2139792442321777
Validation loss: 2.2004881828061995

Epoch: 5| Step: 6
Training loss: 2.468444347381592
Validation loss: 2.205894336905531

Epoch: 5| Step: 7
Training loss: 2.7071452140808105
Validation loss: 2.210393936403336

Epoch: 5| Step: 8
Training loss: 1.6562731266021729
Validation loss: 2.1891316444643083

Epoch: 5| Step: 9
Training loss: 2.892977237701416
Validation loss: 2.1726571026668755

Epoch: 5| Step: 10
Training loss: 2.352426528930664
Validation loss: 2.160871150673077

Epoch: 110| Step: 0
Training loss: 2.5484955310821533
Validation loss: 2.170648131319272

Epoch: 5| Step: 1
Training loss: 2.1184678077697754
Validation loss: 2.1564730905717417

Epoch: 5| Step: 2
Training loss: 2.325331211090088
Validation loss: 2.159764051437378

Epoch: 5| Step: 3
Training loss: 2.6434242725372314
Validation loss: 2.1540053685506186

Epoch: 5| Step: 4
Training loss: 2.568014621734619
Validation loss: 2.1512776664508286

Epoch: 5| Step: 5
Training loss: 2.1674771308898926
Validation loss: 2.1572400087951333

Epoch: 5| Step: 6
Training loss: 2.5513501167297363
Validation loss: 2.15782537639782

Epoch: 5| Step: 7
Training loss: 2.787461519241333
Validation loss: 2.177512063775011

Epoch: 5| Step: 8
Training loss: 2.2523484230041504
Validation loss: 2.1887749882154566

Epoch: 5| Step: 9
Training loss: 2.725829601287842
Validation loss: 2.2053623020008044

Epoch: 5| Step: 10
Training loss: 2.3666272163391113
Validation loss: 2.201335904418781

Epoch: 111| Step: 0
Training loss: 1.871057152748108
Validation loss: 2.211334123406359

Epoch: 5| Step: 1
Training loss: 3.072984457015991
Validation loss: 2.2092795807828187

Epoch: 5| Step: 2
Training loss: 2.2344229221343994
Validation loss: 2.172093568309661

Epoch: 5| Step: 3
Training loss: 2.8209352493286133
Validation loss: 2.155600005580533

Epoch: 5| Step: 4
Training loss: 2.589045286178589
Validation loss: 2.1493890131673505

Epoch: 5| Step: 5
Training loss: 2.2040436267852783
Validation loss: 2.151657078855781

Epoch: 5| Step: 6
Training loss: 2.3855769634246826
Validation loss: 2.1509201706096692

Epoch: 5| Step: 7
Training loss: 2.7440898418426514
Validation loss: 2.1536334586399857

Epoch: 5| Step: 8
Training loss: 2.595407485961914
Validation loss: 2.1528293778819423

Epoch: 5| Step: 9
Training loss: 2.3621878623962402
Validation loss: 2.1537164462509977

Epoch: 5| Step: 10
Training loss: 2.2472095489501953
Validation loss: 2.1605432776994604

Epoch: 112| Step: 0
Training loss: 2.376757860183716
Validation loss: 2.1641667530100834

Epoch: 5| Step: 1
Training loss: 2.5409648418426514
Validation loss: 2.17325758934021

Epoch: 5| Step: 2
Training loss: 2.734752655029297
Validation loss: 2.1976464448436612

Epoch: 5| Step: 3
Training loss: 2.2842445373535156
Validation loss: 2.204863022732478

Epoch: 5| Step: 4
Training loss: 2.473039150238037
Validation loss: 2.2156131511093466

Epoch: 5| Step: 5
Training loss: 2.6876447200775146
Validation loss: 2.1859682606112574

Epoch: 5| Step: 6
Training loss: 2.134028196334839
Validation loss: 2.157671413113994

Epoch: 5| Step: 7
Training loss: 2.0837414264678955
Validation loss: 2.140868661224201

Epoch: 5| Step: 8
Training loss: 2.416332244873047
Validation loss: 2.143841915233161

Epoch: 5| Step: 9
Training loss: 2.971515655517578
Validation loss: 2.135220335375878

Epoch: 5| Step: 10
Training loss: 2.264698028564453
Validation loss: 2.1357471148173013

Epoch: 113| Step: 0
Training loss: 2.4824271202087402
Validation loss: 2.136496579775246

Epoch: 5| Step: 1
Training loss: 1.8123199939727783
Validation loss: 2.137799119436613

Epoch: 5| Step: 2
Training loss: 2.851788282394409
Validation loss: 2.1496519452782086

Epoch: 5| Step: 3
Training loss: 1.970266342163086
Validation loss: 2.1535534422884703

Epoch: 5| Step: 4
Training loss: 2.8476722240448
Validation loss: 2.1552425763940297

Epoch: 5| Step: 5
Training loss: 2.769519090652466
Validation loss: 2.165713361514512

Epoch: 5| Step: 6
Training loss: 2.770695209503174
Validation loss: 2.1734706509497856

Epoch: 5| Step: 7
Training loss: 2.084808826446533
Validation loss: 2.1844845023206485

Epoch: 5| Step: 8
Training loss: 2.1603565216064453
Validation loss: 2.2366130839111986

Epoch: 5| Step: 9
Training loss: 2.6156928539276123
Validation loss: 2.225269691918486

Epoch: 5| Step: 10
Training loss: 2.3392322063446045
Validation loss: 2.2149486054656324

Epoch: 114| Step: 0
Training loss: 2.351231813430786
Validation loss: 2.1798587588853735

Epoch: 5| Step: 1
Training loss: 2.2744247913360596
Validation loss: 2.157661784079767

Epoch: 5| Step: 2
Training loss: 2.6573588848114014
Validation loss: 2.14163996711854

Epoch: 5| Step: 3
Training loss: 2.1644210815429688
Validation loss: 2.13590342767777

Epoch: 5| Step: 4
Training loss: 2.4048101902008057
Validation loss: 2.130147382777224

Epoch: 5| Step: 5
Training loss: 2.1740477085113525
Validation loss: 2.134968552538144

Epoch: 5| Step: 6
Training loss: 2.8958096504211426
Validation loss: 2.134164184652349

Epoch: 5| Step: 7
Training loss: 2.311586380004883
Validation loss: 2.126733031324161

Epoch: 5| Step: 8
Training loss: 2.4538192749023438
Validation loss: 2.1238868915906517

Epoch: 5| Step: 9
Training loss: 2.5539937019348145
Validation loss: 2.1338802306882796

Epoch: 5| Step: 10
Training loss: 2.628967523574829
Validation loss: 2.1329188436590214

Epoch: 115| Step: 0
Training loss: 1.599118947982788
Validation loss: 2.1444839892848844

Epoch: 5| Step: 1
Training loss: 2.6270954608917236
Validation loss: 2.138043334407191

Epoch: 5| Step: 2
Training loss: 2.7151198387145996
Validation loss: 2.155672956538457

Epoch: 5| Step: 3
Training loss: 2.5237276554107666
Validation loss: 2.1600207205741637

Epoch: 5| Step: 4
Training loss: 2.5003552436828613
Validation loss: 2.1552712660963818

Epoch: 5| Step: 5
Training loss: 2.07599139213562
Validation loss: 2.1518970817647953

Epoch: 5| Step: 6
Training loss: 2.474309206008911
Validation loss: 2.148289875317645

Epoch: 5| Step: 7
Training loss: 3.0368151664733887
Validation loss: 2.153510288525653

Epoch: 5| Step: 8
Training loss: 2.7279486656188965
Validation loss: 2.158955684272192

Epoch: 5| Step: 9
Training loss: 2.53759503364563
Validation loss: 2.132061714767128

Epoch: 5| Step: 10
Training loss: 1.6991033554077148
Validation loss: 2.130068309845463

Epoch: 116| Step: 0
Training loss: 2.3654532432556152
Validation loss: 2.122738092176376

Epoch: 5| Step: 1
Training loss: 1.9072058200836182
Validation loss: 2.1234146907765377

Epoch: 5| Step: 2
Training loss: 2.485377788543701
Validation loss: 2.1268635552416564

Epoch: 5| Step: 3
Training loss: 1.9393212795257568
Validation loss: 2.162345617048202

Epoch: 5| Step: 4
Training loss: 2.7857296466827393
Validation loss: 2.175406317557058

Epoch: 5| Step: 5
Training loss: 2.231093645095825
Validation loss: 2.1951272462003972

Epoch: 5| Step: 6
Training loss: 2.531686782836914
Validation loss: 2.2172369572424118

Epoch: 5| Step: 7
Training loss: 2.3550021648406982
Validation loss: 2.207931218608733

Epoch: 5| Step: 8
Training loss: 2.9602115154266357
Validation loss: 2.1444683536406486

Epoch: 5| Step: 9
Training loss: 2.484870195388794
Validation loss: 2.1228857527496996

Epoch: 5| Step: 10
Training loss: 2.671609878540039
Validation loss: 2.1154835890698176

Epoch: 117| Step: 0
Training loss: 2.7246592044830322
Validation loss: 2.1191183879811275

Epoch: 5| Step: 1
Training loss: 1.9273542165756226
Validation loss: 2.1162402681125108

Epoch: 5| Step: 2
Training loss: 2.151108503341675
Validation loss: 2.1148309835823635

Epoch: 5| Step: 3
Training loss: 2.2555315494537354
Validation loss: 2.115437876793646

Epoch: 5| Step: 4
Training loss: 2.5051047801971436
Validation loss: 2.1257293813972065

Epoch: 5| Step: 5
Training loss: 2.1545355319976807
Validation loss: 2.137437670461593

Epoch: 5| Step: 6
Training loss: 2.324958086013794
Validation loss: 2.142126549956619

Epoch: 5| Step: 7
Training loss: 2.8851332664489746
Validation loss: 2.1333745371910835

Epoch: 5| Step: 8
Training loss: 2.6413722038269043
Validation loss: 2.115707787134314

Epoch: 5| Step: 9
Training loss: 2.642145872116089
Validation loss: 2.1026803498627036

Epoch: 5| Step: 10
Training loss: 2.531451940536499
Validation loss: 2.0986313166156894

Epoch: 118| Step: 0
Training loss: 3.1762490272521973
Validation loss: 2.098933191709621

Epoch: 5| Step: 1
Training loss: 2.490328550338745
Validation loss: 2.0878832570968138

Epoch: 5| Step: 2
Training loss: 2.3736138343811035
Validation loss: 2.0937579088313605

Epoch: 5| Step: 3
Training loss: 2.681501865386963
Validation loss: 2.094144025156575

Epoch: 5| Step: 4
Training loss: 2.045950412750244
Validation loss: 2.1019262524061304

Epoch: 5| Step: 5
Training loss: 2.4112277030944824
Validation loss: 2.1139362730005735

Epoch: 5| Step: 6
Training loss: 2.3912291526794434
Validation loss: 2.1326557846479517

Epoch: 5| Step: 7
Training loss: 2.712421417236328
Validation loss: 2.1661371928389355

Epoch: 5| Step: 8
Training loss: 2.173307418823242
Validation loss: 2.1780700196502027

Epoch: 5| Step: 9
Training loss: 1.7946974039077759
Validation loss: 2.165086264251381

Epoch: 5| Step: 10
Training loss: 2.1906139850616455
Validation loss: 2.140457680148463

Epoch: 119| Step: 0
Training loss: 2.1958534717559814
Validation loss: 2.1235942456030075

Epoch: 5| Step: 1
Training loss: 2.500214099884033
Validation loss: 2.1300383908774263

Epoch: 5| Step: 2
Training loss: 1.9532941579818726
Validation loss: 2.1185720928253664

Epoch: 5| Step: 3
Training loss: 2.741060256958008
Validation loss: 2.110964805849137

Epoch: 5| Step: 4
Training loss: 2.3105034828186035
Validation loss: 2.103514362406987

Epoch: 5| Step: 5
Training loss: 1.9243080615997314
Validation loss: 2.1060278172134073

Epoch: 5| Step: 6
Training loss: 2.8770174980163574
Validation loss: 2.0985298054192656

Epoch: 5| Step: 7
Training loss: 1.917009711265564
Validation loss: 2.1063664779868176

Epoch: 5| Step: 8
Training loss: 2.4748787879943848
Validation loss: 2.104425243152085

Epoch: 5| Step: 9
Training loss: 3.0466227531433105
Validation loss: 2.1044940666485856

Epoch: 5| Step: 10
Training loss: 2.3752994537353516
Validation loss: 2.115304821281023

Epoch: 120| Step: 0
Training loss: 2.6735332012176514
Validation loss: 2.1259882552649385

Epoch: 5| Step: 1
Training loss: 2.662221670150757
Validation loss: 2.1283661832091627

Epoch: 5| Step: 2
Training loss: 2.2065012454986572
Validation loss: 2.1213130335653982

Epoch: 5| Step: 3
Training loss: 2.0425376892089844
Validation loss: 2.0983714057553198

Epoch: 5| Step: 4
Training loss: 2.439889430999756
Validation loss: 2.0923129614963325

Epoch: 5| Step: 5
Training loss: 2.0695202350616455
Validation loss: 2.094092822843982

Epoch: 5| Step: 6
Training loss: 2.444472312927246
Validation loss: 2.094074155694695

Epoch: 5| Step: 7
Training loss: 2.6453897953033447
Validation loss: 2.09395319543859

Epoch: 5| Step: 8
Training loss: 2.6545119285583496
Validation loss: 2.103263306361373

Epoch: 5| Step: 9
Training loss: 2.118640184402466
Validation loss: 2.0983569147766277

Epoch: 5| Step: 10
Training loss: 2.428529977798462
Validation loss: 2.0953615327035227

Epoch: 121| Step: 0
Training loss: 2.6429970264434814
Validation loss: 2.10642905645473

Epoch: 5| Step: 1
Training loss: 2.451390504837036
Validation loss: 2.1113678588662097

Epoch: 5| Step: 2
Training loss: 2.356010913848877
Validation loss: 2.1154311446733374

Epoch: 5| Step: 3
Training loss: 2.1926283836364746
Validation loss: 2.098150900615159

Epoch: 5| Step: 4
Training loss: 2.5892956256866455
Validation loss: 2.0913104113712104

Epoch: 5| Step: 5
Training loss: 2.726907730102539
Validation loss: 2.0881397416514735

Epoch: 5| Step: 6
Training loss: 1.9419381618499756
Validation loss: 2.0805029381987867

Epoch: 5| Step: 7
Training loss: 2.9487266540527344
Validation loss: 2.081361186119818

Epoch: 5| Step: 8
Training loss: 2.6127729415893555
Validation loss: 2.0917330377845356

Epoch: 5| Step: 9
Training loss: 1.9671783447265625
Validation loss: 2.123384142434725

Epoch: 5| Step: 10
Training loss: 1.5894052982330322
Validation loss: 2.1650857669050976

Epoch: 122| Step: 0
Training loss: 2.5474681854248047
Validation loss: 2.182694096719065

Epoch: 5| Step: 1
Training loss: 1.8964496850967407
Validation loss: 2.1648964343532437

Epoch: 5| Step: 2
Training loss: 2.3053371906280518
Validation loss: 2.134710675926619

Epoch: 5| Step: 3
Training loss: 2.393091917037964
Validation loss: 2.13075166620234

Epoch: 5| Step: 4
Training loss: 1.8539927005767822
Validation loss: 2.1067457942552466

Epoch: 5| Step: 5
Training loss: 2.755237340927124
Validation loss: 2.0853831011761903

Epoch: 5| Step: 6
Training loss: 2.4467029571533203
Validation loss: 2.0900182159998084

Epoch: 5| Step: 7
Training loss: 2.763606309890747
Validation loss: 2.102739228997179

Epoch: 5| Step: 8
Training loss: 2.680626153945923
Validation loss: 2.103231282644374

Epoch: 5| Step: 9
Training loss: 2.325482130050659
Validation loss: 2.0965954860051474

Epoch: 5| Step: 10
Training loss: 2.6435110569000244
Validation loss: 2.0946785314108736

Epoch: 123| Step: 0
Training loss: 2.461534023284912
Validation loss: 2.086364137229099

Epoch: 5| Step: 1
Training loss: 2.3262736797332764
Validation loss: 2.0817064239132788

Epoch: 5| Step: 2
Training loss: 1.867383360862732
Validation loss: 2.0999850303896013

Epoch: 5| Step: 3
Training loss: 1.5439834594726562
Validation loss: 2.1237122089632097

Epoch: 5| Step: 4
Training loss: 2.7554574012756348
Validation loss: 2.1341031341142553

Epoch: 5| Step: 5
Training loss: 2.839735269546509
Validation loss: 2.1236808812746437

Epoch: 5| Step: 6
Training loss: 2.3942389488220215
Validation loss: 2.1256643854161745

Epoch: 5| Step: 7
Training loss: 2.464420795440674
Validation loss: 2.1188478021211523

Epoch: 5| Step: 8
Training loss: 2.3572185039520264
Validation loss: 2.1021130469537552

Epoch: 5| Step: 9
Training loss: 2.2014026641845703
Validation loss: 2.095422572987054

Epoch: 5| Step: 10
Training loss: 2.9666905403137207
Validation loss: 2.091043231307819

Epoch: 124| Step: 0
Training loss: 2.6683695316314697
Validation loss: 2.0851849663642144

Epoch: 5| Step: 1
Training loss: 2.1902096271514893
Validation loss: 2.0759799121528544

Epoch: 5| Step: 2
Training loss: 2.2407684326171875
Validation loss: 2.077638708135133

Epoch: 5| Step: 3
Training loss: 2.3782732486724854
Validation loss: 2.07093842311572

Epoch: 5| Step: 4
Training loss: 2.542248249053955
Validation loss: 2.069214082533313

Epoch: 5| Step: 5
Training loss: 2.088787317276001
Validation loss: 2.06776854812458

Epoch: 5| Step: 6
Training loss: 2.4605042934417725
Validation loss: 2.0842159948041363

Epoch: 5| Step: 7
Training loss: 2.5936880111694336
Validation loss: 2.1141650394726823

Epoch: 5| Step: 8
Training loss: 2.21889591217041
Validation loss: 2.1382628358820432

Epoch: 5| Step: 9
Training loss: 1.9167712926864624
Validation loss: 2.1491667045060026

Epoch: 5| Step: 10
Training loss: 2.8326239585876465
Validation loss: 2.1799868896443355

Epoch: 125| Step: 0
Training loss: 2.4182956218719482
Validation loss: 2.1412733177984915

Epoch: 5| Step: 1
Training loss: 1.4985600709915161
Validation loss: 2.1449066080072874

Epoch: 5| Step: 2
Training loss: 2.3343284130096436
Validation loss: 2.129516557980609

Epoch: 5| Step: 3
Training loss: 3.166269540786743
Validation loss: 2.0994901541740663

Epoch: 5| Step: 4
Training loss: 2.1400420665740967
Validation loss: 2.0850178554493892

Epoch: 5| Step: 5
Training loss: 2.49729061126709
Validation loss: 2.0840222245903424

Epoch: 5| Step: 6
Training loss: 2.5619819164276123
Validation loss: 2.0878151129650813

Epoch: 5| Step: 7
Training loss: 1.8206870555877686
Validation loss: 2.0722638483970397

Epoch: 5| Step: 8
Training loss: 2.321840763092041
Validation loss: 2.076623352625037

Epoch: 5| Step: 9
Training loss: 2.5498268604278564
Validation loss: 2.0849226725998746

Epoch: 5| Step: 10
Training loss: 2.7899816036224365
Validation loss: 2.081987181017476

Epoch: 126| Step: 0
Training loss: 2.140669345855713
Validation loss: 2.06978246729861

Epoch: 5| Step: 1
Training loss: 2.1475279331207275
Validation loss: 2.060585039918141

Epoch: 5| Step: 2
Training loss: 2.6103005409240723
Validation loss: 2.079989392270324

Epoch: 5| Step: 3
Training loss: 2.1632137298583984
Validation loss: 2.110455920619349

Epoch: 5| Step: 4
Training loss: 2.5198006629943848
Validation loss: 2.1223643287535636

Epoch: 5| Step: 5
Training loss: 2.5712552070617676
Validation loss: 2.1065104315357823

Epoch: 5| Step: 6
Training loss: 2.255812406539917
Validation loss: 2.0771903376425467

Epoch: 5| Step: 7
Training loss: 2.629103183746338
Validation loss: 2.0725716596008628

Epoch: 5| Step: 8
Training loss: 1.8440189361572266
Validation loss: 2.064773383960929

Epoch: 5| Step: 9
Training loss: 2.439345121383667
Validation loss: 2.0659118519034436

Epoch: 5| Step: 10
Training loss: 2.843308925628662
Validation loss: 2.0639855784754597

Epoch: 127| Step: 0
Training loss: 2.6445083618164062
Validation loss: 2.0750635977714293

Epoch: 5| Step: 1
Training loss: 2.133861780166626
Validation loss: 2.079249297418902

Epoch: 5| Step: 2
Training loss: 2.736673355102539
Validation loss: 2.075845605583601

Epoch: 5| Step: 3
Training loss: 2.3922019004821777
Validation loss: 2.072686310737364

Epoch: 5| Step: 4
Training loss: 2.023550033569336
Validation loss: 2.0700404490194013

Epoch: 5| Step: 5
Training loss: 2.9092490673065186
Validation loss: 2.0641017293417327

Epoch: 5| Step: 6
Training loss: 2.142637014389038
Validation loss: 2.049099149242524

Epoch: 5| Step: 7
Training loss: 1.8109185695648193
Validation loss: 2.0694406314562728

Epoch: 5| Step: 8
Training loss: 2.367410659790039
Validation loss: 2.105482083494945

Epoch: 5| Step: 9
Training loss: 2.827789783477783
Validation loss: 2.1645926378106557

Epoch: 5| Step: 10
Training loss: 2.2795627117156982
Validation loss: 2.193810809043146

Epoch: 128| Step: 0
Training loss: 2.523336887359619
Validation loss: 2.1395070911735616

Epoch: 5| Step: 1
Training loss: 2.0045018196105957
Validation loss: 2.089354060029471

Epoch: 5| Step: 2
Training loss: 2.8474795818328857
Validation loss: 2.0507527756434616

Epoch: 5| Step: 3
Training loss: 2.915611982345581
Validation loss: 2.0567549069722495

Epoch: 5| Step: 4
Training loss: 2.821824550628662
Validation loss: 2.0778261077019478

Epoch: 5| Step: 5
Training loss: 2.7817811965942383
Validation loss: 2.0726074813514628

Epoch: 5| Step: 6
Training loss: 1.7302162647247314
Validation loss: 2.0525606422014135

Epoch: 5| Step: 7
Training loss: 1.6825100183486938
Validation loss: 2.0514365960192937

Epoch: 5| Step: 8
Training loss: 2.1832661628723145
Validation loss: 2.084087912754346

Epoch: 5| Step: 9
Training loss: 2.3696367740631104
Validation loss: 2.0986134185585925

Epoch: 5| Step: 10
Training loss: 2.2538485527038574
Validation loss: 2.09387061801008

Epoch: 129| Step: 0
Training loss: 2.5142643451690674
Validation loss: 2.0674787311143774

Epoch: 5| Step: 1
Training loss: 2.219343900680542
Validation loss: 2.0604975890087824

Epoch: 5| Step: 2
Training loss: 2.676889419555664
Validation loss: 2.0496334568146737

Epoch: 5| Step: 3
Training loss: 1.8458893299102783
Validation loss: 2.0474243830609065

Epoch: 5| Step: 4
Training loss: 2.8089613914489746
Validation loss: 2.0457880753342823

Epoch: 5| Step: 5
Training loss: 3.0754470825195312
Validation loss: 2.0544330227759575

Epoch: 5| Step: 6
Training loss: 1.6451804637908936
Validation loss: 2.0604496232924925

Epoch: 5| Step: 7
Training loss: 2.0759527683258057
Validation loss: 2.0595317117629515

Epoch: 5| Step: 8
Training loss: 2.360994338989258
Validation loss: 2.058374293388859

Epoch: 5| Step: 9
Training loss: 2.53814959526062
Validation loss: 2.0506094706955778

Epoch: 5| Step: 10
Training loss: 1.9713572263717651
Validation loss: 2.062346560980684

Epoch: 130| Step: 0
Training loss: 2.3736181259155273
Validation loss: 2.0769471148008942

Epoch: 5| Step: 1
Training loss: 2.68428111076355
Validation loss: 2.0980608873469855

Epoch: 5| Step: 2
Training loss: 2.7808148860931396
Validation loss: 2.1076729425819973

Epoch: 5| Step: 3
Training loss: 2.656482458114624
Validation loss: 2.10237778002216

Epoch: 5| Step: 4
Training loss: 1.7899351119995117
Validation loss: 2.094609634850615

Epoch: 5| Step: 5
Training loss: 2.3510546684265137
Validation loss: 2.092955195775596

Epoch: 5| Step: 6
Training loss: 1.8248968124389648
Validation loss: 2.090243311338527

Epoch: 5| Step: 7
Training loss: 2.111067295074463
Validation loss: 2.0872118806326263

Epoch: 5| Step: 8
Training loss: 2.1476664543151855
Validation loss: 2.0673268418158255

Epoch: 5| Step: 9
Training loss: 2.682727336883545
Validation loss: 2.0599088271458945

Epoch: 5| Step: 10
Training loss: 2.3364734649658203
Validation loss: 2.0583248574246644

Epoch: 131| Step: 0
Training loss: 2.3972983360290527
Validation loss: 2.056494892284434

Epoch: 5| Step: 1
Training loss: 2.797736406326294
Validation loss: 2.0541900434801654

Epoch: 5| Step: 2
Training loss: 2.31518816947937
Validation loss: 2.054923229320075

Epoch: 5| Step: 3
Training loss: 2.740774631500244
Validation loss: 2.070551400543541

Epoch: 5| Step: 4
Training loss: 2.150428056716919
Validation loss: 2.066503140234178

Epoch: 5| Step: 5
Training loss: 2.241008996963501
Validation loss: 2.070795953914683

Epoch: 5| Step: 6
Training loss: 1.965752363204956
Validation loss: 2.074558478529735

Epoch: 5| Step: 7
Training loss: 2.549185037612915
Validation loss: 2.0908080352249967

Epoch: 5| Step: 8
Training loss: 1.9684699773788452
Validation loss: 2.077364775442308

Epoch: 5| Step: 9
Training loss: 2.363898277282715
Validation loss: 2.0810957775321057

Epoch: 5| Step: 10
Training loss: 2.1735901832580566
Validation loss: 2.10268836123969

Epoch: 132| Step: 0
Training loss: 2.5993478298187256
Validation loss: 2.0902046067740327

Epoch: 5| Step: 1
Training loss: 2.09480357170105
Validation loss: 2.09576742879806

Epoch: 5| Step: 2
Training loss: 3.115480422973633
Validation loss: 2.0983288582935127

Epoch: 5| Step: 3
Training loss: 1.7593460083007812
Validation loss: 2.0664473349048245

Epoch: 5| Step: 4
Training loss: 2.810425281524658
Validation loss: 2.0492099485089703

Epoch: 5| Step: 5
Training loss: 1.8166574239730835
Validation loss: 2.0350636705275504

Epoch: 5| Step: 6
Training loss: 1.1004496812820435
Validation loss: 2.034125651082685

Epoch: 5| Step: 7
Training loss: 2.841015338897705
Validation loss: 2.039938303732103

Epoch: 5| Step: 8
Training loss: 2.555898904800415
Validation loss: 2.0531025317407425

Epoch: 5| Step: 9
Training loss: 2.326991319656372
Validation loss: 2.0590358344457482

Epoch: 5| Step: 10
Training loss: 2.888746976852417
Validation loss: 2.072737470749886

Epoch: 133| Step: 0
Training loss: 2.5203089714050293
Validation loss: 2.0582706005342546

Epoch: 5| Step: 1
Training loss: 1.9015741348266602
Validation loss: 2.0604089690792944

Epoch: 5| Step: 2
Training loss: 2.885848045349121
Validation loss: 2.0405261285843386

Epoch: 5| Step: 3
Training loss: 2.0323128700256348
Validation loss: 2.0319931276382937

Epoch: 5| Step: 4
Training loss: 2.11230206489563
Validation loss: 2.0370449584017516

Epoch: 5| Step: 5
Training loss: 2.3926823139190674
Validation loss: 2.0578202829566052

Epoch: 5| Step: 6
Training loss: 2.339632749557495
Validation loss: 2.065397543291892

Epoch: 5| Step: 7
Training loss: 2.206110715866089
Validation loss: 2.081582337297419

Epoch: 5| Step: 8
Training loss: 2.9062399864196777
Validation loss: 2.0764660117446736

Epoch: 5| Step: 9
Training loss: 1.9015228748321533
Validation loss: 2.047254393177648

Epoch: 5| Step: 10
Training loss: 2.415060043334961
Validation loss: 2.0324719759725753

Epoch: 134| Step: 0
Training loss: 2.086756706237793
Validation loss: 2.02593897235009

Epoch: 5| Step: 1
Training loss: 2.1465229988098145
Validation loss: 2.023795566251201

Epoch: 5| Step: 2
Training loss: 2.5540332794189453
Validation loss: 2.021201656710717

Epoch: 5| Step: 3
Training loss: 2.3045787811279297
Validation loss: 2.0286210570284116

Epoch: 5| Step: 4
Training loss: 2.3148488998413086
Validation loss: 2.022337959658715

Epoch: 5| Step: 5
Training loss: 2.2468528747558594
Validation loss: 2.048755781624907

Epoch: 5| Step: 6
Training loss: 2.002721071243286
Validation loss: 2.079154937498031

Epoch: 5| Step: 7
Training loss: 2.9087822437286377
Validation loss: 2.0901418129603067

Epoch: 5| Step: 8
Training loss: 2.431401491165161
Validation loss: 2.0637674472665273

Epoch: 5| Step: 9
Training loss: 2.3977413177490234
Validation loss: 2.037494308205061

Epoch: 5| Step: 10
Training loss: 2.061922788619995
Validation loss: 2.0261136613866335

Epoch: 135| Step: 0
Training loss: 1.980743408203125
Validation loss: 2.0200676866756972

Epoch: 5| Step: 1
Training loss: 1.9397852420806885
Validation loss: 2.025083573915625

Epoch: 5| Step: 2
Training loss: 2.1997838020324707
Validation loss: 2.020976722881358

Epoch: 5| Step: 3
Training loss: 2.2183752059936523
Validation loss: 2.028529618376045

Epoch: 5| Step: 4
Training loss: 2.599043369293213
Validation loss: 2.0278555834165184

Epoch: 5| Step: 5
Training loss: 2.743628978729248
Validation loss: 2.0257019765915407

Epoch: 5| Step: 6
Training loss: 2.3098156452178955
Validation loss: 2.025528610393565

Epoch: 5| Step: 7
Training loss: 2.3044979572296143
Validation loss: 2.0307222079205256

Epoch: 5| Step: 8
Training loss: 2.078619956970215
Validation loss: 2.0279258976700487

Epoch: 5| Step: 9
Training loss: 2.4467530250549316
Validation loss: 2.0309499002272084

Epoch: 5| Step: 10
Training loss: 2.471567153930664
Validation loss: 2.028508617031959

Epoch: 136| Step: 0
Training loss: 2.02659273147583
Validation loss: 2.023176085564398

Epoch: 5| Step: 1
Training loss: 1.9892669916152954
Validation loss: 2.0339673206370366

Epoch: 5| Step: 2
Training loss: 3.1875267028808594
Validation loss: 2.0326592486391784

Epoch: 5| Step: 3
Training loss: 1.9537376165390015
Validation loss: 2.036219750681231

Epoch: 5| Step: 4
Training loss: 2.637538194656372
Validation loss: 2.0402825032511065

Epoch: 5| Step: 5
Training loss: 2.080272674560547
Validation loss: 2.036634450317711

Epoch: 5| Step: 6
Training loss: 2.08737850189209
Validation loss: 2.033060863453855

Epoch: 5| Step: 7
Training loss: 2.3393375873565674
Validation loss: 2.0316138216244277

Epoch: 5| Step: 8
Training loss: 2.6878840923309326
Validation loss: 2.0328885560394614

Epoch: 5| Step: 9
Training loss: 1.8170995712280273
Validation loss: 2.0380884524314635

Epoch: 5| Step: 10
Training loss: 2.2686641216278076
Validation loss: 2.0282870108081448

Epoch: 137| Step: 0
Training loss: 2.1769375801086426
Validation loss: 2.040160935412171

Epoch: 5| Step: 1
Training loss: 2.117827892303467
Validation loss: 2.0291337479827223

Epoch: 5| Step: 2
Training loss: 2.795680284500122
Validation loss: 2.034826312013852

Epoch: 5| Step: 3
Training loss: 1.8090089559555054
Validation loss: 2.0235277478412916

Epoch: 5| Step: 4
Training loss: 2.0931859016418457
Validation loss: 2.0345075015098817

Epoch: 5| Step: 5
Training loss: 2.5091912746429443
Validation loss: 2.0463824400337796

Epoch: 5| Step: 6
Training loss: 1.8479474782943726
Validation loss: 2.0547231756230837

Epoch: 5| Step: 7
Training loss: 2.4407577514648438
Validation loss: 2.084743586919641

Epoch: 5| Step: 8
Training loss: 2.482471466064453
Validation loss: 2.0924943480440366

Epoch: 5| Step: 9
Training loss: 2.274153232574463
Validation loss: 2.0885045605321086

Epoch: 5| Step: 10
Training loss: 2.9462971687316895
Validation loss: 2.080302507646622

Epoch: 138| Step: 0
Training loss: 2.5892906188964844
Validation loss: 2.052101941518886

Epoch: 5| Step: 1
Training loss: 1.9986953735351562
Validation loss: 2.0204255209174207

Epoch: 5| Step: 2
Training loss: 2.1387734413146973
Validation loss: 1.9976520897239767

Epoch: 5| Step: 3
Training loss: 2.221766710281372
Validation loss: 2.008873031985375

Epoch: 5| Step: 4
Training loss: 2.398401975631714
Validation loss: 2.0248795734938754

Epoch: 5| Step: 5
Training loss: 2.4312822818756104
Validation loss: 2.040391701523976

Epoch: 5| Step: 6
Training loss: 1.8474289178848267
Validation loss: 2.0625414079235447

Epoch: 5| Step: 7
Training loss: 2.574547290802002
Validation loss: 2.0602524357457317

Epoch: 5| Step: 8
Training loss: 1.9447028636932373
Validation loss: 2.052439658872543

Epoch: 5| Step: 9
Training loss: 2.9344544410705566
Validation loss: 2.026306647126393

Epoch: 5| Step: 10
Training loss: 2.5014102458953857
Validation loss: 2.006026703824279

Epoch: 139| Step: 0
Training loss: 2.1591081619262695
Validation loss: 2.001577159409882

Epoch: 5| Step: 1
Training loss: 2.1135194301605225
Validation loss: 2.027760649240145

Epoch: 5| Step: 2
Training loss: 2.167067527770996
Validation loss: 2.095674301988335

Epoch: 5| Step: 3
Training loss: 2.259866237640381
Validation loss: 2.1408040138982956

Epoch: 5| Step: 4
Training loss: 2.0488178730010986
Validation loss: 2.123091323401338

Epoch: 5| Step: 5
Training loss: 2.4962985515594482
Validation loss: 2.0567806971970426

Epoch: 5| Step: 6
Training loss: 2.0702030658721924
Validation loss: 2.0180323098295476

Epoch: 5| Step: 7
Training loss: 2.8158624172210693
Validation loss: 2.0064438632739487

Epoch: 5| Step: 8
Training loss: 2.082181453704834
Validation loss: 2.008419857230238

Epoch: 5| Step: 9
Training loss: 3.2844650745391846
Validation loss: 2.0118628663401448

Epoch: 5| Step: 10
Training loss: 2.097140073776245
Validation loss: 2.009823276150611

Epoch: 140| Step: 0
Training loss: 2.2136640548706055
Validation loss: 2.0109447074192826

Epoch: 5| Step: 1
Training loss: 1.6113898754119873
Validation loss: 2.0163788372470486

Epoch: 5| Step: 2
Training loss: 2.4181571006774902
Validation loss: 2.0469226632066952

Epoch: 5| Step: 3
Training loss: 2.526560068130493
Validation loss: 2.0510388933202273

Epoch: 5| Step: 4
Training loss: 2.681624412536621
Validation loss: 2.0546507527751308

Epoch: 5| Step: 5
Training loss: 2.5494275093078613
Validation loss: 2.076191920106129

Epoch: 5| Step: 6
Training loss: 2.2429354190826416
Validation loss: 2.1089667940652497

Epoch: 5| Step: 7
Training loss: 2.289393901824951
Validation loss: 2.1065342887755363

Epoch: 5| Step: 8
Training loss: 2.1610400676727295
Validation loss: 2.0917221897391864

Epoch: 5| Step: 9
Training loss: 2.087013006210327
Validation loss: 2.0614353251713577

Epoch: 5| Step: 10
Training loss: 2.6471593379974365
Validation loss: 2.035583326893468

Epoch: 141| Step: 0
Training loss: 2.083073854446411
Validation loss: 2.0045544383346394

Epoch: 5| Step: 1
Training loss: 2.4511313438415527
Validation loss: 2.0024306594684558

Epoch: 5| Step: 2
Training loss: 2.100205659866333
Validation loss: 2.008380297691591

Epoch: 5| Step: 3
Training loss: 2.519655466079712
Validation loss: 1.991579383932134

Epoch: 5| Step: 4
Training loss: 2.7630503177642822
Validation loss: 1.9973749345348728

Epoch: 5| Step: 5
Training loss: 2.459249496459961
Validation loss: 1.9961051607644686

Epoch: 5| Step: 6
Training loss: 1.6959768533706665
Validation loss: 1.9906713808736494

Epoch: 5| Step: 7
Training loss: 2.341280698776245
Validation loss: 2.01906648758919

Epoch: 5| Step: 8
Training loss: 3.1370491981506348
Validation loss: 2.03048796807566

Epoch: 5| Step: 9
Training loss: 1.7850844860076904
Validation loss: 2.03222623948128

Epoch: 5| Step: 10
Training loss: 1.6171530485153198
Validation loss: 2.0266639417217625

Epoch: 142| Step: 0
Training loss: 2.223050594329834
Validation loss: 2.0095930958306916

Epoch: 5| Step: 1
Training loss: 1.7778396606445312
Validation loss: 2.0195700199373308

Epoch: 5| Step: 2
Training loss: 2.2962486743927
Validation loss: 2.0069582436674382

Epoch: 5| Step: 3
Training loss: 2.5694384574890137
Validation loss: 2.0157551355259393

Epoch: 5| Step: 4
Training loss: 2.233062982559204
Validation loss: 2.037337412116348

Epoch: 5| Step: 5
Training loss: 2.473806142807007
Validation loss: 2.052048057638189

Epoch: 5| Step: 6
Training loss: 2.369385242462158
Validation loss: 2.09183305950575

Epoch: 5| Step: 7
Training loss: 2.3154773712158203
Validation loss: 2.092385889381491

Epoch: 5| Step: 8
Training loss: 1.8192379474639893
Validation loss: 2.061570013723066

Epoch: 5| Step: 9
Training loss: 2.4139702320098877
Validation loss: 2.0554349217363583

Epoch: 5| Step: 10
Training loss: 2.4624245166778564
Validation loss: 2.0568627606156054

Epoch: 143| Step: 0
Training loss: 2.2622036933898926
Validation loss: 2.077399535845685

Epoch: 5| Step: 1
Training loss: 2.1159827709198
Validation loss: 2.0631283867743706

Epoch: 5| Step: 2
Training loss: 1.7778122425079346
Validation loss: 2.059319011626705

Epoch: 5| Step: 3
Training loss: 2.4446003437042236
Validation loss: 2.0427612232905563

Epoch: 5| Step: 4
Training loss: 1.9349483251571655
Validation loss: 2.028005584593742

Epoch: 5| Step: 5
Training loss: 2.4456238746643066
Validation loss: 2.0240410835512224

Epoch: 5| Step: 6
Training loss: 2.729668140411377
Validation loss: 2.006490571524507

Epoch: 5| Step: 7
Training loss: 2.1612679958343506
Validation loss: 2.0168752901015745

Epoch: 5| Step: 8
Training loss: 2.0894699096679688
Validation loss: 2.0332861228655745

Epoch: 5| Step: 9
Training loss: 2.4067142009735107
Validation loss: 2.076249776347991

Epoch: 5| Step: 10
Training loss: 2.664740800857544
Validation loss: 2.120080522311631

Epoch: 144| Step: 0
Training loss: 2.6172499656677246
Validation loss: 2.1124018648619294

Epoch: 5| Step: 1
Training loss: 2.028015613555908
Validation loss: 2.0754403145082536

Epoch: 5| Step: 2
Training loss: 2.055846691131592
Validation loss: 2.0853765190288587

Epoch: 5| Step: 3
Training loss: 2.337007522583008
Validation loss: 2.1153251894058718

Epoch: 5| Step: 4
Training loss: 2.2439498901367188
Validation loss: 2.159453832974998

Epoch: 5| Step: 5
Training loss: 2.8535213470458984
Validation loss: 2.1650643528148694

Epoch: 5| Step: 6
Training loss: 2.563823699951172
Validation loss: 2.165730225142612

Epoch: 5| Step: 7
Training loss: 2.1909751892089844
Validation loss: 2.1500424672198553

Epoch: 5| Step: 8
Training loss: 2.1715409755706787
Validation loss: 2.1216498908176216

Epoch: 5| Step: 9
Training loss: 2.3465304374694824
Validation loss: 2.0983604487552436

Epoch: 5| Step: 10
Training loss: 2.0900564193725586
Validation loss: 2.103126625860891

Epoch: 145| Step: 0
Training loss: 2.481499671936035
Validation loss: 2.105596944849978

Epoch: 5| Step: 1
Training loss: 1.9426301717758179
Validation loss: 2.129890864895236

Epoch: 5| Step: 2
Training loss: 1.710097312927246
Validation loss: 2.1390098602541032

Epoch: 5| Step: 3
Training loss: 3.1775107383728027
Validation loss: 2.1054669657061176

Epoch: 5| Step: 4
Training loss: 2.305955410003662
Validation loss: 2.044993051918604

Epoch: 5| Step: 5
Training loss: 1.9019062519073486
Validation loss: 2.011463339610766

Epoch: 5| Step: 6
Training loss: 2.467320203781128
Validation loss: 2.056237882183444

Epoch: 5| Step: 7
Training loss: 2.4574854373931885
Validation loss: 2.1002847712527037

Epoch: 5| Step: 8
Training loss: 2.0903356075286865
Validation loss: 2.1087004561578073

Epoch: 5| Step: 9
Training loss: 2.0814261436462402
Validation loss: 2.103317460706157

Epoch: 5| Step: 10
Training loss: 3.1175708770751953
Validation loss: 2.067888649561072

Epoch: 146| Step: 0
Training loss: 2.19262433052063
Validation loss: 2.0177879743678595

Epoch: 5| Step: 1
Training loss: 2.3399369716644287
Validation loss: 2.0031117380306287

Epoch: 5| Step: 2
Training loss: 1.9034574031829834
Validation loss: 2.0000992462199223

Epoch: 5| Step: 3
Training loss: 1.452606439590454
Validation loss: 1.998859287590109

Epoch: 5| Step: 4
Training loss: 1.9378502368927002
Validation loss: 2.004402664399916

Epoch: 5| Step: 5
Training loss: 2.303846836090088
Validation loss: 2.010880624094317

Epoch: 5| Step: 6
Training loss: 2.1114487648010254
Validation loss: 1.9976890651128625

Epoch: 5| Step: 7
Training loss: 2.1914219856262207
Validation loss: 1.9758594779558079

Epoch: 5| Step: 8
Training loss: 2.5303282737731934
Validation loss: 1.9836019239118021

Epoch: 5| Step: 9
Training loss: 3.198688268661499
Validation loss: 2.032414610667895

Epoch: 5| Step: 10
Training loss: 2.647784948348999
Validation loss: 2.1016633574680617

Epoch: 147| Step: 0
Training loss: 2.122469425201416
Validation loss: 2.147582710430186

Epoch: 5| Step: 1
Training loss: 1.8089208602905273
Validation loss: 2.169366093092067

Epoch: 5| Step: 2
Training loss: 2.300682783126831
Validation loss: 2.143125372548257

Epoch: 5| Step: 3
Training loss: 2.2849762439727783
Validation loss: 2.1151064236958823

Epoch: 5| Step: 4
Training loss: 2.4636270999908447
Validation loss: 2.0676780990374986

Epoch: 5| Step: 5
Training loss: 2.060637950897217
Validation loss: 2.011094416341474

Epoch: 5| Step: 6
Training loss: 2.6680424213409424
Validation loss: 1.9993492582792878

Epoch: 5| Step: 7
Training loss: 1.4979709386825562
Validation loss: 2.003095115384748

Epoch: 5| Step: 8
Training loss: 2.001312255859375
Validation loss: 2.0068651155758928

Epoch: 5| Step: 9
Training loss: 2.62536358833313
Validation loss: 2.021695844588741

Epoch: 5| Step: 10
Training loss: 3.2806506156921387
Validation loss: 2.021330116897501

Epoch: 148| Step: 0
Training loss: 2.0579113960266113
Validation loss: 2.0260006304710143

Epoch: 5| Step: 1
Training loss: 2.049193859100342
Validation loss: 2.0368696002550024

Epoch: 5| Step: 2
Training loss: 2.6048178672790527
Validation loss: 2.0671895139960834

Epoch: 5| Step: 3
Training loss: 2.410733461380005
Validation loss: 2.069434089045371

Epoch: 5| Step: 4
Training loss: 1.4130598306655884
Validation loss: 2.0619496889011835

Epoch: 5| Step: 5
Training loss: 1.8580434322357178
Validation loss: 2.0677968045716644

Epoch: 5| Step: 6
Training loss: 2.5822043418884277
Validation loss: 2.06597315367832

Epoch: 5| Step: 7
Training loss: 2.205225944519043
Validation loss: 2.065708719274049

Epoch: 5| Step: 8
Training loss: 2.85392165184021
Validation loss: 2.1010941574650426

Epoch: 5| Step: 9
Training loss: 2.4313273429870605
Validation loss: 2.0972372665200183

Epoch: 5| Step: 10
Training loss: 2.7491090297698975
Validation loss: 2.086365008866915

Epoch: 149| Step: 0
Training loss: 3.151154041290283
Validation loss: 2.0677981889376076

Epoch: 5| Step: 1
Training loss: 2.158522129058838
Validation loss: 2.0551277898973033

Epoch: 5| Step: 2
Training loss: 2.3993537425994873
Validation loss: 2.0521329038886615

Epoch: 5| Step: 3
Training loss: 2.3239643573760986
Validation loss: 2.0329650294396187

Epoch: 5| Step: 4
Training loss: 1.9268848896026611
Validation loss: 2.0093962582208778

Epoch: 5| Step: 5
Training loss: 2.459590435028076
Validation loss: 1.9817539632961314

Epoch: 5| Step: 6
Training loss: 1.274323582649231
Validation loss: 1.9602396949645011

Epoch: 5| Step: 7
Training loss: 2.3847098350524902
Validation loss: 1.962778809250042

Epoch: 5| Step: 8
Training loss: 2.5240001678466797
Validation loss: 1.9586191023549726

Epoch: 5| Step: 9
Training loss: 2.4255645275115967
Validation loss: 1.9822382593667636

Epoch: 5| Step: 10
Training loss: 1.8036839962005615
Validation loss: 2.018646578634939

Epoch: 150| Step: 0
Training loss: 2.618830919265747
Validation loss: 2.0455795411140687

Epoch: 5| Step: 1
Training loss: 1.9011504650115967
Validation loss: 2.0536897643919914

Epoch: 5| Step: 2
Training loss: 2.027620792388916
Validation loss: 2.065429449081421

Epoch: 5| Step: 3
Training loss: 2.574167251586914
Validation loss: 2.0398140658614454

Epoch: 5| Step: 4
Training loss: 1.9494149684906006
Validation loss: 2.0355240068128033

Epoch: 5| Step: 5
Training loss: 2.765803813934326
Validation loss: 2.015348490848336

Epoch: 5| Step: 6
Training loss: 2.180511951446533
Validation loss: 1.986485650462489

Epoch: 5| Step: 7
Training loss: 2.2805514335632324
Validation loss: 1.9945439689902849

Epoch: 5| Step: 8
Training loss: 2.343061923980713
Validation loss: 1.989690396093553

Epoch: 5| Step: 9
Training loss: 1.9058971405029297
Validation loss: 1.9778757838792698

Epoch: 5| Step: 10
Training loss: 2.4726033210754395
Validation loss: 1.9772127841108589

Epoch: 151| Step: 0
Training loss: 2.432790756225586
Validation loss: 1.972654027323569

Epoch: 5| Step: 1
Training loss: 2.0244274139404297
Validation loss: 1.9694893385774346

Epoch: 5| Step: 2
Training loss: 1.9441906213760376
Validation loss: 1.9610215592127975

Epoch: 5| Step: 3
Training loss: 2.6959965229034424
Validation loss: 1.9665866077587169

Epoch: 5| Step: 4
Training loss: 1.8570868968963623
Validation loss: 1.9672576137768325

Epoch: 5| Step: 5
Training loss: 1.7857612371444702
Validation loss: 1.9864852723254953

Epoch: 5| Step: 6
Training loss: 2.3978004455566406
Validation loss: 2.0259152458560084

Epoch: 5| Step: 7
Training loss: 2.527864933013916
Validation loss: 2.076903863619733

Epoch: 5| Step: 8
Training loss: 2.4160208702087402
Validation loss: 2.086854583473616

Epoch: 5| Step: 9
Training loss: 2.080169916152954
Validation loss: 2.0861783296831193

Epoch: 5| Step: 10
Training loss: 2.587418794631958
Validation loss: 2.0515962826308383

Epoch: 152| Step: 0
Training loss: 1.913133978843689
Validation loss: 2.0173853187150854

Epoch: 5| Step: 1
Training loss: 1.3422256708145142
Validation loss: 1.995797098323863

Epoch: 5| Step: 2
Training loss: 2.784799337387085
Validation loss: 1.989728558448053

Epoch: 5| Step: 3
Training loss: 2.125771999359131
Validation loss: 1.981144784599222

Epoch: 5| Step: 4
Training loss: 2.305377721786499
Validation loss: 1.9666801601327875

Epoch: 5| Step: 5
Training loss: 2.619960308074951
Validation loss: 1.9770654965472478

Epoch: 5| Step: 6
Training loss: 2.8366518020629883
Validation loss: 1.9707693489648963

Epoch: 5| Step: 7
Training loss: 1.6175434589385986
Validation loss: 1.9590592563793223

Epoch: 5| Step: 8
Training loss: 2.5876312255859375
Validation loss: 1.9517435745526386

Epoch: 5| Step: 9
Training loss: 2.22048020362854
Validation loss: 1.9603865915729153

Epoch: 5| Step: 10
Training loss: 2.0760722160339355
Validation loss: 1.975434680138865

Epoch: 153| Step: 0
Training loss: 2.30558705329895
Validation loss: 1.9781732097748788

Epoch: 5| Step: 1
Training loss: 1.8096511363983154
Validation loss: 1.9841346266449138

Epoch: 5| Step: 2
Training loss: 2.9861831665039062
Validation loss: 1.9829732192459928

Epoch: 5| Step: 3
Training loss: 2.183913469314575
Validation loss: 1.9999359705114876

Epoch: 5| Step: 4
Training loss: 2.476531982421875
Validation loss: 2.0144141797096498

Epoch: 5| Step: 5
Training loss: 1.6285078525543213
Validation loss: 2.0023108938688874

Epoch: 5| Step: 6
Training loss: 2.5094199180603027
Validation loss: 1.9800370918807162

Epoch: 5| Step: 7
Training loss: 2.181375741958618
Validation loss: 1.969996795859388

Epoch: 5| Step: 8
Training loss: 2.3236708641052246
Validation loss: 1.9609043700720674

Epoch: 5| Step: 9
Training loss: 1.9071096181869507
Validation loss: 1.9617980577612435

Epoch: 5| Step: 10
Training loss: 2.1392202377319336
Validation loss: 1.9833364025239022

Epoch: 154| Step: 0
Training loss: 2.5472445487976074
Validation loss: 2.0066445463447162

Epoch: 5| Step: 1
Training loss: 1.7554374933242798
Validation loss: 2.0157820434980493

Epoch: 5| Step: 2
Training loss: 2.3951587677001953
Validation loss: 2.0279730622486403

Epoch: 5| Step: 3
Training loss: 1.7120931148529053
Validation loss: 2.04788310809802

Epoch: 5| Step: 4
Training loss: 2.422189712524414
Validation loss: 2.017551237537015

Epoch: 5| Step: 5
Training loss: 2.218205690383911
Validation loss: 2.0233620648743003

Epoch: 5| Step: 6
Training loss: 2.164998769760132
Validation loss: 2.041583280409536

Epoch: 5| Step: 7
Training loss: 2.1644115447998047
Validation loss: 2.0283188025156655

Epoch: 5| Step: 8
Training loss: 2.5504579544067383
Validation loss: 2.0048609343908166

Epoch: 5| Step: 9
Training loss: 2.4118945598602295
Validation loss: 1.9678059393359768

Epoch: 5| Step: 10
Training loss: 2.259298086166382
Validation loss: 1.959731060971496

Epoch: 155| Step: 0
Training loss: 2.7444100379943848
Validation loss: 1.9514553495632705

Epoch: 5| Step: 1
Training loss: 1.9349424839019775
Validation loss: 1.9446624350804154

Epoch: 5| Step: 2
Training loss: 2.310870885848999
Validation loss: 1.9495218107777257

Epoch: 5| Step: 3
Training loss: 1.8846874237060547
Validation loss: 1.9403526706080283

Epoch: 5| Step: 4
Training loss: 2.1548800468444824
Validation loss: 1.9427630286062918

Epoch: 5| Step: 5
Training loss: 2.528665781021118
Validation loss: 1.9592839056445706

Epoch: 5| Step: 6
Training loss: 2.033346652984619
Validation loss: 1.9879446234754337

Epoch: 5| Step: 7
Training loss: 2.1962947845458984
Validation loss: 1.9979669047940163

Epoch: 5| Step: 8
Training loss: 2.0854334831237793
Validation loss: 2.050404748608989

Epoch: 5| Step: 9
Training loss: 2.0837435722351074
Validation loss: 2.0580308411711004

Epoch: 5| Step: 10
Training loss: 2.2105236053466797
Validation loss: 2.0553398119506014

Epoch: 156| Step: 0
Training loss: 1.688439965248108
Validation loss: 2.036754569699687

Epoch: 5| Step: 1
Training loss: 1.670332670211792
Validation loss: 1.9991913867253128

Epoch: 5| Step: 2
Training loss: 2.3301098346710205
Validation loss: 1.992538406002906

Epoch: 5| Step: 3
Training loss: 1.713034987449646
Validation loss: 2.0006384952093965

Epoch: 5| Step: 4
Training loss: 2.7107348442077637
Validation loss: 2.000463685681743

Epoch: 5| Step: 5
Training loss: 2.7046806812286377
Validation loss: 2.0282388784552134

Epoch: 5| Step: 6
Training loss: 2.611611843109131
Validation loss: 2.0377565699238933

Epoch: 5| Step: 7
Training loss: 1.8649591207504272
Validation loss: 2.0660196760649323

Epoch: 5| Step: 8
Training loss: 2.768544912338257
Validation loss: 2.0346189621956117

Epoch: 5| Step: 9
Training loss: 2.2190098762512207
Validation loss: 2.0387204718846146

Epoch: 5| Step: 10
Training loss: 2.075326442718506
Validation loss: 2.0522838036219277

Epoch: 157| Step: 0
Training loss: 2.198204517364502
Validation loss: 2.073135306758265

Epoch: 5| Step: 1
Training loss: 2.6666603088378906
Validation loss: 2.075522040808073

Epoch: 5| Step: 2
Training loss: 2.525428533554077
Validation loss: 2.0596908561645018

Epoch: 5| Step: 3
Training loss: 1.6865774393081665
Validation loss: 2.0486588619088613

Epoch: 5| Step: 4
Training loss: 2.1352972984313965
Validation loss: 2.0233760033884356

Epoch: 5| Step: 5
Training loss: 2.373945713043213
Validation loss: 1.9961831492762412

Epoch: 5| Step: 6
Training loss: 2.3433594703674316
Validation loss: 1.9726478028041061

Epoch: 5| Step: 7
Training loss: 2.526319980621338
Validation loss: 1.9616796432002899

Epoch: 5| Step: 8
Training loss: 2.094836711883545
Validation loss: 1.9513172667513612

Epoch: 5| Step: 9
Training loss: 2.3637967109680176
Validation loss: 1.949000398317973

Epoch: 5| Step: 10
Training loss: 1.5367295742034912
Validation loss: 1.9344134356385918

Epoch: 158| Step: 0
Training loss: 2.308206081390381
Validation loss: 1.9308225160003991

Epoch: 5| Step: 1
Training loss: 2.41447377204895
Validation loss: 1.9259704838516891

Epoch: 5| Step: 2
Training loss: 2.543825626373291
Validation loss: 1.9194608170499083

Epoch: 5| Step: 3
Training loss: 2.179457426071167
Validation loss: 1.923649669975363

Epoch: 5| Step: 4
Training loss: 1.7420604228973389
Validation loss: 1.929666555056008

Epoch: 5| Step: 5
Training loss: 2.2097949981689453
Validation loss: 1.9398587826759583

Epoch: 5| Step: 6
Training loss: 2.502791404724121
Validation loss: 1.9513730759261756

Epoch: 5| Step: 7
Training loss: 2.004666328430176
Validation loss: 1.948724114766685

Epoch: 5| Step: 8
Training loss: 1.997627854347229
Validation loss: 1.9642150004704793

Epoch: 5| Step: 9
Training loss: 2.3082315921783447
Validation loss: 1.9626763456611223

Epoch: 5| Step: 10
Training loss: 1.932695746421814
Validation loss: 1.9642417674423547

Epoch: 159| Step: 0
Training loss: 2.2662532329559326
Validation loss: 1.954015367774553

Epoch: 5| Step: 1
Training loss: 2.671231508255005
Validation loss: 1.9628354157170942

Epoch: 5| Step: 2
Training loss: 1.8221015930175781
Validation loss: 1.9729281304984965

Epoch: 5| Step: 3
Training loss: 1.8278602361679077
Validation loss: 1.994235841176843

Epoch: 5| Step: 4
Training loss: 2.29909610748291
Validation loss: 1.975515119491085

Epoch: 5| Step: 5
Training loss: 2.1029040813446045
Validation loss: 1.9705960648034209

Epoch: 5| Step: 6
Training loss: 1.8797279596328735
Validation loss: 1.9798751261926466

Epoch: 5| Step: 7
Training loss: 2.2453408241271973
Validation loss: 1.9943702323462373

Epoch: 5| Step: 8
Training loss: 2.103243589401245
Validation loss: 2.0104514155336606

Epoch: 5| Step: 9
Training loss: 2.3142144680023193
Validation loss: 1.9965629885273595

Epoch: 5| Step: 10
Training loss: 2.4214229583740234
Validation loss: 1.988293691348004

Epoch: 160| Step: 0
Training loss: 2.147645950317383
Validation loss: 2.0019079216064943

Epoch: 5| Step: 1
Training loss: 2.3914942741394043
Validation loss: 2.0131837937139694

Epoch: 5| Step: 2
Training loss: 2.2990901470184326
Validation loss: 2.0157408304111932

Epoch: 5| Step: 3
Training loss: 1.570676565170288
Validation loss: 2.011698562611816

Epoch: 5| Step: 4
Training loss: 2.02720046043396
Validation loss: 2.006945635682793

Epoch: 5| Step: 5
Training loss: 2.1420764923095703
Validation loss: 2.015162644847747

Epoch: 5| Step: 6
Training loss: 1.757543921470642
Validation loss: 2.016538714849821

Epoch: 5| Step: 7
Training loss: 2.583254337310791
Validation loss: 2.003710646783152

Epoch: 5| Step: 8
Training loss: 2.338911771774292
Validation loss: 1.987389737559903

Epoch: 5| Step: 9
Training loss: 2.5163369178771973
Validation loss: 1.972695937720678

Epoch: 5| Step: 10
Training loss: 2.277376174926758
Validation loss: 1.9735626712922127

Epoch: 161| Step: 0
Training loss: 1.9613025188446045
Validation loss: 1.9694569200597785

Epoch: 5| Step: 1
Training loss: 1.5565924644470215
Validation loss: 1.9704863371387604

Epoch: 5| Step: 2
Training loss: 3.2547295093536377
Validation loss: 1.9778065066183768

Epoch: 5| Step: 3
Training loss: 1.9676052331924438
Validation loss: 1.9667707130473147

Epoch: 5| Step: 4
Training loss: 1.7668135166168213
Validation loss: 1.9777973069939563

Epoch: 5| Step: 5
Training loss: 2.424582004547119
Validation loss: 1.9759286526710755

Epoch: 5| Step: 6
Training loss: 2.1646862030029297
Validation loss: 1.984060437448563

Epoch: 5| Step: 7
Training loss: 2.459932565689087
Validation loss: 1.9893723700636177

Epoch: 5| Step: 8
Training loss: 1.3589918613433838
Validation loss: 1.9755508720233876

Epoch: 5| Step: 9
Training loss: 2.5203399658203125
Validation loss: 1.9895811875661213

Epoch: 5| Step: 10
Training loss: 2.3893778324127197
Validation loss: 1.9940913620815481

Epoch: 162| Step: 0
Training loss: 1.8981149196624756
Validation loss: 1.9945902978220293

Epoch: 5| Step: 1
Training loss: 2.415074586868286
Validation loss: 2.00814179835781

Epoch: 5| Step: 2
Training loss: 2.3034873008728027
Validation loss: 1.9955255241804226

Epoch: 5| Step: 3
Training loss: 2.046119213104248
Validation loss: 2.0042700946971936

Epoch: 5| Step: 4
Training loss: 2.4864938259124756
Validation loss: 2.0044676744809715

Epoch: 5| Step: 5
Training loss: 2.0581612586975098
Validation loss: 1.9928918961555726

Epoch: 5| Step: 6
Training loss: 2.7855262756347656
Validation loss: 1.9721585063524143

Epoch: 5| Step: 7
Training loss: 1.4644582271575928
Validation loss: 1.9592241292358727

Epoch: 5| Step: 8
Training loss: 2.5609054565429688
Validation loss: 1.9826957589836531

Epoch: 5| Step: 9
Training loss: 1.4630097150802612
Validation loss: 1.9915595772445842

Epoch: 5| Step: 10
Training loss: 2.3102331161499023
Validation loss: 1.9957142581221878

Epoch: 163| Step: 0
Training loss: 1.5718694925308228
Validation loss: 1.9744927319147254

Epoch: 5| Step: 1
Training loss: 2.2533822059631348
Validation loss: 1.9822910985639017

Epoch: 5| Step: 2
Training loss: 1.7133090496063232
Validation loss: 1.994800768872743

Epoch: 5| Step: 3
Training loss: 1.8887115716934204
Validation loss: 1.986116401610836

Epoch: 5| Step: 4
Training loss: 2.607966899871826
Validation loss: 1.9698097372567782

Epoch: 5| Step: 5
Training loss: 2.188040256500244
Validation loss: 1.9679424352543329

Epoch: 5| Step: 6
Training loss: 2.5802674293518066
Validation loss: 1.9681278672269595

Epoch: 5| Step: 7
Training loss: 2.360994577407837
Validation loss: 1.9785902961607902

Epoch: 5| Step: 8
Training loss: 1.8297626972198486
Validation loss: 1.986739746985897

Epoch: 5| Step: 9
Training loss: 1.8446489572525024
Validation loss: 1.986022045535426

Epoch: 5| Step: 10
Training loss: 2.861603260040283
Validation loss: 2.0017437268328924

Epoch: 164| Step: 0
Training loss: 2.874345302581787
Validation loss: 2.014934116794217

Epoch: 5| Step: 1
Training loss: 2.2970025539398193
Validation loss: 2.0170589057348107

Epoch: 5| Step: 2
Training loss: 2.4151408672332764
Validation loss: 2.0256599200669156

Epoch: 5| Step: 3
Training loss: 2.178076982498169
Validation loss: 2.020902669557961

Epoch: 5| Step: 4
Training loss: 1.8902279138565063
Validation loss: 2.025590660751507

Epoch: 5| Step: 5
Training loss: 1.77847158908844
Validation loss: 2.0396460551087574

Epoch: 5| Step: 6
Training loss: 2.0990633964538574
Validation loss: 2.084187589665895

Epoch: 5| Step: 7
Training loss: 1.9773664474487305
Validation loss: 2.0859955151875815

Epoch: 5| Step: 8
Training loss: 1.5486348867416382
Validation loss: 2.0415978918793383

Epoch: 5| Step: 9
Training loss: 2.4356846809387207
Validation loss: 1.9902010348535353

Epoch: 5| Step: 10
Training loss: 2.4712493419647217
Validation loss: 1.9870330928474345

Epoch: 165| Step: 0
Training loss: 2.058314800262451
Validation loss: 2.010502456336893

Epoch: 5| Step: 1
Training loss: 2.159405469894409
Validation loss: 2.0232418506376204

Epoch: 5| Step: 2
Training loss: 1.9221254587173462
Validation loss: 2.023884206689814

Epoch: 5| Step: 3
Training loss: 2.5643832683563232
Validation loss: 2.0061888053853023

Epoch: 5| Step: 4
Training loss: 1.7584455013275146
Validation loss: 1.976995619394446

Epoch: 5| Step: 5
Training loss: 2.128243923187256
Validation loss: 1.967002736624851

Epoch: 5| Step: 6
Training loss: 2.6441731452941895
Validation loss: 1.9574584653300624

Epoch: 5| Step: 7
Training loss: 2.0374510288238525
Validation loss: 1.946850993299997

Epoch: 5| Step: 8
Training loss: 1.6890884637832642
Validation loss: 1.9213680169915641

Epoch: 5| Step: 9
Training loss: 2.66908860206604
Validation loss: 1.920217053864592

Epoch: 5| Step: 10
Training loss: 2.4427602291107178
Validation loss: 1.9172392173479962

Epoch: 166| Step: 0
Training loss: 1.513514518737793
Validation loss: 1.9309075711875834

Epoch: 5| Step: 1
Training loss: 1.8103363513946533
Validation loss: 1.938492827518012

Epoch: 5| Step: 2
Training loss: 2.598278522491455
Validation loss: 1.933458541029243

Epoch: 5| Step: 3
Training loss: 1.9830440282821655
Validation loss: 1.9574487158047256

Epoch: 5| Step: 4
Training loss: 2.3939688205718994
Validation loss: 1.9782641113445323

Epoch: 5| Step: 5
Training loss: 2.481200695037842
Validation loss: 1.9969269678156862

Epoch: 5| Step: 6
Training loss: 2.605752468109131
Validation loss: 2.0227369211053334

Epoch: 5| Step: 7
Training loss: 2.076913595199585
Validation loss: 2.0375936364614837

Epoch: 5| Step: 8
Training loss: 1.7635809183120728
Validation loss: 2.05688573468116

Epoch: 5| Step: 9
Training loss: 2.666046619415283
Validation loss: 2.0634175500562115

Epoch: 5| Step: 10
Training loss: 2.328836679458618
Validation loss: 2.064934956130161

Epoch: 167| Step: 0
Training loss: 2.262877941131592
Validation loss: 2.059530358160696

Epoch: 5| Step: 1
Training loss: 3.096101760864258
Validation loss: 2.0491823098992787

Epoch: 5| Step: 2
Training loss: 2.4964239597320557
Validation loss: 2.0433569441559496

Epoch: 5| Step: 3
Training loss: 0.8996331095695496
Validation loss: 2.047841025936988

Epoch: 5| Step: 4
Training loss: 2.358438730239868
Validation loss: 2.0653011683494813

Epoch: 5| Step: 5
Training loss: 1.8362386226654053
Validation loss: 2.0822927772357898

Epoch: 5| Step: 6
Training loss: 1.9445621967315674
Validation loss: 2.096005106485018

Epoch: 5| Step: 7
Training loss: 2.1602935791015625
Validation loss: 2.099425108202042

Epoch: 5| Step: 8
Training loss: 2.658078670501709
Validation loss: 2.0907769408277286

Epoch: 5| Step: 9
Training loss: 1.3749637603759766
Validation loss: 2.0650530245996292

Epoch: 5| Step: 10
Training loss: 2.733701467514038
Validation loss: 2.0397197700315908

Epoch: 168| Step: 0
Training loss: 2.5360782146453857
Validation loss: 2.0120916956214496

Epoch: 5| Step: 1
Training loss: 1.7130663394927979
Validation loss: 1.9928961184716993

Epoch: 5| Step: 2
Training loss: 2.375699520111084
Validation loss: 1.9785768934475478

Epoch: 5| Step: 3
Training loss: 2.3615641593933105
Validation loss: 1.9681974751974947

Epoch: 5| Step: 4
Training loss: 2.325958728790283
Validation loss: 1.9657138868044781

Epoch: 5| Step: 5
Training loss: 2.11828875541687
Validation loss: 1.9630839517039638

Epoch: 5| Step: 6
Training loss: 1.8180259466171265
Validation loss: 1.9371070938725625

Epoch: 5| Step: 7
Training loss: 2.113712787628174
Validation loss: 1.9553781363271898

Epoch: 5| Step: 8
Training loss: 1.9889318943023682
Validation loss: 1.9565802261393557

Epoch: 5| Step: 9
Training loss: 1.761846899986267
Validation loss: 1.9743013535776446

Epoch: 5| Step: 10
Training loss: 2.3885679244995117
Validation loss: 1.9948836013834963

Epoch: 169| Step: 0
Training loss: 2.088740110397339
Validation loss: 1.99628451947243

Epoch: 5| Step: 1
Training loss: 1.7976974248886108
Validation loss: 1.997339484512165

Epoch: 5| Step: 2
Training loss: 2.155524730682373
Validation loss: 1.9989028207717403

Epoch: 5| Step: 3
Training loss: 1.3776456117630005
Validation loss: 2.0064967293893137

Epoch: 5| Step: 4
Training loss: 1.9163926839828491
Validation loss: 2.007752585154708

Epoch: 5| Step: 5
Training loss: 2.634352207183838
Validation loss: 2.0238027290631364

Epoch: 5| Step: 6
Training loss: 1.7982898950576782
Validation loss: 2.017596552448888

Epoch: 5| Step: 7
Training loss: 2.0596187114715576
Validation loss: 2.0365254878997803

Epoch: 5| Step: 8
Training loss: 3.042116165161133
Validation loss: 2.02848978196421

Epoch: 5| Step: 9
Training loss: 2.374138116836548
Validation loss: 2.019600642624722

Epoch: 5| Step: 10
Training loss: 2.3740711212158203
Validation loss: 1.9768040616025206

Epoch: 170| Step: 0
Training loss: 2.4849045276641846
Validation loss: 1.9404772789247575

Epoch: 5| Step: 1
Training loss: 1.551864504814148
Validation loss: 1.939261390316871

Epoch: 5| Step: 2
Training loss: 3.0351099967956543
Validation loss: 1.9317016370834843

Epoch: 5| Step: 3
Training loss: 2.038644552230835
Validation loss: 1.9371221937159055

Epoch: 5| Step: 4
Training loss: 2.1679208278656006
Validation loss: 1.9398067343619563

Epoch: 5| Step: 5
Training loss: 1.4594671726226807
Validation loss: 1.956621805826823

Epoch: 5| Step: 6
Training loss: 1.93670654296875
Validation loss: 1.960483665107399

Epoch: 5| Step: 7
Training loss: 2.2595152854919434
Validation loss: 1.961728888173257

Epoch: 5| Step: 8
Training loss: 2.7637577056884766
Validation loss: 1.963856017717751

Epoch: 5| Step: 9
Training loss: 2.1585819721221924
Validation loss: 1.9616794829727502

Epoch: 5| Step: 10
Training loss: 1.5020228624343872
Validation loss: 1.9652625335160123

Epoch: 171| Step: 0
Training loss: 2.156003475189209
Validation loss: 1.9655789534250896

Epoch: 5| Step: 1
Training loss: 2.4502112865448
Validation loss: 1.9580596711045952

Epoch: 5| Step: 2
Training loss: 2.0386874675750732
Validation loss: 1.957964490818721

Epoch: 5| Step: 3
Training loss: 1.898410439491272
Validation loss: 1.9519579308007353

Epoch: 5| Step: 4
Training loss: 1.8531020879745483
Validation loss: 1.9465405171917332

Epoch: 5| Step: 5
Training loss: 1.651127576828003
Validation loss: 1.9507501497063586

Epoch: 5| Step: 6
Training loss: 2.0791678428649902
Validation loss: 1.9402600411445863

Epoch: 5| Step: 7
Training loss: 2.342695951461792
Validation loss: 1.9402905805136568

Epoch: 5| Step: 8
Training loss: 2.815094470977783
Validation loss: 1.9463683943594656

Epoch: 5| Step: 9
Training loss: 1.753053069114685
Validation loss: 1.9353366436496857

Epoch: 5| Step: 10
Training loss: 2.1397149562835693
Validation loss: 1.9686821135141517

Epoch: 172| Step: 0
Training loss: 2.500535011291504
Validation loss: 1.9447341452362716

Epoch: 5| Step: 1
Training loss: 2.0395262241363525
Validation loss: 1.9460148106339157

Epoch: 5| Step: 2
Training loss: 2.7977492809295654
Validation loss: 1.9563082264315697

Epoch: 5| Step: 3
Training loss: 2.62213134765625
Validation loss: 1.9668539659951323

Epoch: 5| Step: 4
Training loss: 2.0342726707458496
Validation loss: 1.9544664890535417

Epoch: 5| Step: 5
Training loss: 2.418738842010498
Validation loss: 1.9530778802851194

Epoch: 5| Step: 6
Training loss: 2.1825973987579346
Validation loss: 1.9485939907771286

Epoch: 5| Step: 7
Training loss: 1.452751874923706
Validation loss: 1.9120770756916334

Epoch: 5| Step: 8
Training loss: 1.6055463552474976
Validation loss: 1.9377193925201253

Epoch: 5| Step: 9
Training loss: 1.8908439874649048
Validation loss: 1.9708726893189132

Epoch: 5| Step: 10
Training loss: 1.9107096195220947
Validation loss: 1.9949625640787103

Epoch: 173| Step: 0
Training loss: 2.2888286113739014
Validation loss: 2.0023919638767036

Epoch: 5| Step: 1
Training loss: 2.5357718467712402
Validation loss: 2.0042935135543987

Epoch: 5| Step: 2
Training loss: 2.1358749866485596
Validation loss: 1.9771449065977527

Epoch: 5| Step: 3
Training loss: 1.8052184581756592
Validation loss: 1.9786275279137395

Epoch: 5| Step: 4
Training loss: 2.2061400413513184
Validation loss: 1.9626513950286373

Epoch: 5| Step: 5
Training loss: 2.506124496459961
Validation loss: 1.9627686290330784

Epoch: 5| Step: 6
Training loss: 2.283255100250244
Validation loss: 1.9749761704475648

Epoch: 5| Step: 7
Training loss: 2.315488338470459
Validation loss: 1.9733295209946171

Epoch: 5| Step: 8
Training loss: 1.5578198432922363
Validation loss: 1.986294227261697

Epoch: 5| Step: 9
Training loss: 1.7896896600723267
Validation loss: 1.9982709115551365

Epoch: 5| Step: 10
Training loss: 1.695073127746582
Validation loss: 2.003870351340181

Epoch: 174| Step: 0
Training loss: 2.31135630607605
Validation loss: 2.018372780533247

Epoch: 5| Step: 1
Training loss: 2.0648293495178223
Validation loss: 2.003495062551191

Epoch: 5| Step: 2
Training loss: 2.4992434978485107
Validation loss: 1.9981884674359394

Epoch: 5| Step: 3
Training loss: 2.57802152633667
Validation loss: 1.9933438147267988

Epoch: 5| Step: 4
Training loss: 2.0693740844726562
Validation loss: 1.9902915467498123

Epoch: 5| Step: 5
Training loss: 1.5722800493240356
Validation loss: 1.9825733733433548

Epoch: 5| Step: 6
Training loss: 2.2994186878204346
Validation loss: 1.9726013727085565

Epoch: 5| Step: 7
Training loss: 1.7894378900527954
Validation loss: 1.9747233531808341

Epoch: 5| Step: 8
Training loss: 1.4759641885757446
Validation loss: 1.9609627646784629

Epoch: 5| Step: 9
Training loss: 1.8008239269256592
Validation loss: 1.9588042715544343

Epoch: 5| Step: 10
Training loss: 2.2259998321533203
Validation loss: 1.9668828223341255

Epoch: 175| Step: 0
Training loss: 2.4140114784240723
Validation loss: 1.971908805190876

Epoch: 5| Step: 1
Training loss: 1.944070816040039
Validation loss: 1.9683959279009091

Epoch: 5| Step: 2
Training loss: 1.9196879863739014
Validation loss: 1.9569749575789257

Epoch: 5| Step: 3
Training loss: 2.0426077842712402
Validation loss: 1.9778092061319659

Epoch: 5| Step: 4
Training loss: 1.2890703678131104
Validation loss: 1.9773115240117556

Epoch: 5| Step: 5
Training loss: 2.373037815093994
Validation loss: 2.0067694135891494

Epoch: 5| Step: 6
Training loss: 1.8475395441055298
Validation loss: 2.025240573831784

Epoch: 5| Step: 7
Training loss: 1.956308364868164
Validation loss: 2.0599039908378356

Epoch: 5| Step: 8
Training loss: 1.9578659534454346
Validation loss: 2.063068861602455

Epoch: 5| Step: 9
Training loss: 2.8697304725646973
Validation loss: 2.056643880823607

Epoch: 5| Step: 10
Training loss: 2.3226068019866943
Validation loss: 2.028468347364856

Epoch: 176| Step: 0
Training loss: 1.8269014358520508
Validation loss: 2.0004739299897225

Epoch: 5| Step: 1
Training loss: 2.24877667427063
Validation loss: 1.9612356334604242

Epoch: 5| Step: 2
Training loss: 2.1279137134552
Validation loss: 1.95811342423962

Epoch: 5| Step: 3
Training loss: 2.569551944732666
Validation loss: 1.9303527903813187

Epoch: 5| Step: 4
Training loss: 1.8591607809066772
Validation loss: 1.926651079167602

Epoch: 5| Step: 5
Training loss: 1.7074912786483765
Validation loss: 1.9117549260457356

Epoch: 5| Step: 6
Training loss: 2.094791889190674
Validation loss: 1.9021381793483612

Epoch: 5| Step: 7
Training loss: 1.8943449258804321
Validation loss: 1.902228266962113

Epoch: 5| Step: 8
Training loss: 1.8814436197280884
Validation loss: 1.8944015682384532

Epoch: 5| Step: 9
Training loss: 2.4279191493988037
Validation loss: 1.9029614707475067

Epoch: 5| Step: 10
Training loss: 1.9711310863494873
Validation loss: 1.9169726115401073

Epoch: 177| Step: 0
Training loss: 2.307007312774658
Validation loss: 1.9300686082532328

Epoch: 5| Step: 1
Training loss: 1.903299331665039
Validation loss: 1.9394958326893468

Epoch: 5| Step: 2
Training loss: 1.899786353111267
Validation loss: 1.94797315648807

Epoch: 5| Step: 3
Training loss: 2.5075016021728516
Validation loss: 1.9789786646443028

Epoch: 5| Step: 4
Training loss: 2.236701011657715
Validation loss: 1.9911657789702057

Epoch: 5| Step: 5
Training loss: 1.5497150421142578
Validation loss: 2.0260141870026946

Epoch: 5| Step: 6
Training loss: 2.3816275596618652
Validation loss: 2.045405623733356

Epoch: 5| Step: 7
Training loss: 1.9319261312484741
Validation loss: 2.0619959190327632

Epoch: 5| Step: 8
Training loss: 1.5302373170852661
Validation loss: 2.035482975744432

Epoch: 5| Step: 9
Training loss: 2.505046844482422
Validation loss: 2.0239272835434123

Epoch: 5| Step: 10
Training loss: 1.932234764099121
Validation loss: 2.0137279905298704

Epoch: 178| Step: 0
Training loss: 2.382411241531372
Validation loss: 1.9921516628675564

Epoch: 5| Step: 1
Training loss: 1.6690330505371094
Validation loss: 1.9739751892705117

Epoch: 5| Step: 2
Training loss: 2.1223747730255127
Validation loss: 1.9497801180808776

Epoch: 5| Step: 3
Training loss: 2.151362180709839
Validation loss: 1.9641572378015006

Epoch: 5| Step: 4
Training loss: 2.2794108390808105
Validation loss: 1.952971205916456

Epoch: 5| Step: 5
Training loss: 2.0376217365264893
Validation loss: 1.9736496633098972

Epoch: 5| Step: 6
Training loss: 1.6390459537506104
Validation loss: 1.9528895321712698

Epoch: 5| Step: 7
Training loss: 1.8094046115875244
Validation loss: 1.9497653181834886

Epoch: 5| Step: 8
Training loss: 1.8293765783309937
Validation loss: 1.9364665080142278

Epoch: 5| Step: 9
Training loss: 2.416388750076294
Validation loss: 1.9363658389737528

Epoch: 5| Step: 10
Training loss: 2.1812427043914795
Validation loss: 1.9473652365387126

Epoch: 179| Step: 0
Training loss: 2.074096918106079
Validation loss: 1.9760157113434167

Epoch: 5| Step: 1
Training loss: 2.441789150238037
Validation loss: 1.9923916478310861

Epoch: 5| Step: 2
Training loss: 2.0777461528778076
Validation loss: 2.0097229903744114

Epoch: 5| Step: 3
Training loss: 2.6366820335388184
Validation loss: 2.0178346569820116

Epoch: 5| Step: 4
Training loss: 1.643420934677124
Validation loss: 2.031121858986475

Epoch: 5| Step: 5
Training loss: 2.618281602859497
Validation loss: 2.0516561551760604

Epoch: 5| Step: 6
Training loss: 1.8051626682281494
Validation loss: 2.070517360523183

Epoch: 5| Step: 7
Training loss: 1.8911640644073486
Validation loss: 2.082151929537455

Epoch: 5| Step: 8
Training loss: 1.9540656805038452
Validation loss: 2.078758687101385

Epoch: 5| Step: 9
Training loss: 2.223620891571045
Validation loss: 2.0697286205907024

Epoch: 5| Step: 10
Training loss: 1.508472204208374
Validation loss: 2.0554051514594787

Epoch: 180| Step: 0
Training loss: 2.268714427947998
Validation loss: 2.026860280703473

Epoch: 5| Step: 1
Training loss: 1.9244050979614258
Validation loss: 2.006353925633174

Epoch: 5| Step: 2
Training loss: 1.9278510808944702
Validation loss: 2.011916568202357

Epoch: 5| Step: 3
Training loss: 1.8204727172851562
Validation loss: 1.9970138790786907

Epoch: 5| Step: 4
Training loss: 2.2912254333496094
Validation loss: 1.9853799009835849

Epoch: 5| Step: 5
Training loss: 2.300466299057007
Validation loss: 1.976269575857347

Epoch: 5| Step: 6
Training loss: 1.8970062732696533
Validation loss: 1.9689111581412695

Epoch: 5| Step: 7
Training loss: 2.11871075630188
Validation loss: 1.9612183519589004

Epoch: 5| Step: 8
Training loss: 1.8391313552856445
Validation loss: 1.9470240121246667

Epoch: 5| Step: 9
Training loss: 1.8593937158584595
Validation loss: 1.939995499067409

Epoch: 5| Step: 10
Training loss: 2.1727492809295654
Validation loss: 1.942885519355856

Epoch: 181| Step: 0
Training loss: 1.4966062307357788
Validation loss: 1.9474859391489336

Epoch: 5| Step: 1
Training loss: 2.198146343231201
Validation loss: 1.9525119386693484

Epoch: 5| Step: 2
Training loss: 1.5223145484924316
Validation loss: 1.980766959087823

Epoch: 5| Step: 3
Training loss: 1.5242010354995728
Validation loss: 1.9747249413562078

Epoch: 5| Step: 4
Training loss: 2.1895148754119873
Validation loss: 1.9802064203446912

Epoch: 5| Step: 5
Training loss: 1.8463321924209595
Validation loss: 1.9568366722394062

Epoch: 5| Step: 6
Training loss: 2.4290637969970703
Validation loss: 1.9629601650340582

Epoch: 5| Step: 7
Training loss: 2.021509885787964
Validation loss: 1.9464185096884286

Epoch: 5| Step: 8
Training loss: 2.1928229331970215
Validation loss: 1.9356625926110052

Epoch: 5| Step: 9
Training loss: 2.6840109825134277
Validation loss: 1.9283840079461374

Epoch: 5| Step: 10
Training loss: 2.2544915676116943
Validation loss: 1.9305120181011897

Epoch: 182| Step: 0
Training loss: 1.8227901458740234
Validation loss: 1.93674075218939

Epoch: 5| Step: 1
Training loss: 2.630598545074463
Validation loss: 1.9332353735482821

Epoch: 5| Step: 2
Training loss: 1.8744395971298218
Validation loss: 1.9442620392768615

Epoch: 5| Step: 3
Training loss: 1.7361475229263306
Validation loss: 1.9555339992687266

Epoch: 5| Step: 4
Training loss: 1.3404967784881592
Validation loss: 1.9573526087627615

Epoch: 5| Step: 5
Training loss: 2.1737332344055176
Validation loss: 1.9518246958332677

Epoch: 5| Step: 6
Training loss: 1.8260414600372314
Validation loss: 1.9790997453915176

Epoch: 5| Step: 7
Training loss: 2.3084022998809814
Validation loss: 2.00514317071566

Epoch: 5| Step: 8
Training loss: 2.713538646697998
Validation loss: 2.0247691344189387

Epoch: 5| Step: 9
Training loss: 2.170225143432617
Validation loss: 2.0370009945284937

Epoch: 5| Step: 10
Training loss: 1.647127389907837
Validation loss: 2.0414035217736357

Epoch: 183| Step: 0
Training loss: 1.5868953466415405
Validation loss: 2.045520278715318

Epoch: 5| Step: 1
Training loss: 1.6596240997314453
Validation loss: 2.045458073257118

Epoch: 5| Step: 2
Training loss: 2.113135814666748
Validation loss: 2.0522467013328307

Epoch: 5| Step: 3
Training loss: 1.0294959545135498
Validation loss: 2.023190447079238

Epoch: 5| Step: 4
Training loss: 1.5882606506347656
Validation loss: 2.0095889517056045

Epoch: 5| Step: 5
Training loss: 2.5834009647369385
Validation loss: 2.0060768435078282

Epoch: 5| Step: 6
Training loss: 2.6963114738464355
Validation loss: 2.0003032453598513

Epoch: 5| Step: 7
Training loss: 2.5925185680389404
Validation loss: 1.9928451648322485

Epoch: 5| Step: 8
Training loss: 2.311574935913086
Validation loss: 1.9757060902093047

Epoch: 5| Step: 9
Training loss: 1.968915581703186
Validation loss: 1.9587071582835207

Epoch: 5| Step: 10
Training loss: 1.9543993473052979
Validation loss: 1.9358944739064863

Epoch: 184| Step: 0
Training loss: 2.240718126296997
Validation loss: 1.9356072679642709

Epoch: 5| Step: 1
Training loss: 2.2128803730010986
Validation loss: 1.9358736699627292

Epoch: 5| Step: 2
Training loss: 2.1190412044525146
Validation loss: 1.9299270158172936

Epoch: 5| Step: 3
Training loss: 1.5432634353637695
Validation loss: 1.931657314300537

Epoch: 5| Step: 4
Training loss: 2.2609453201293945
Validation loss: 1.9180453644003919

Epoch: 5| Step: 5
Training loss: 1.8252136707305908
Validation loss: 1.9027045490921184

Epoch: 5| Step: 6
Training loss: 1.9431921243667603
Validation loss: 1.8860816955566406

Epoch: 5| Step: 7
Training loss: 2.2423806190490723
Validation loss: 1.893181541914581

Epoch: 5| Step: 8
Training loss: 2.182150363922119
Validation loss: 1.8911933719470937

Epoch: 5| Step: 9
Training loss: 1.4976494312286377
Validation loss: 1.9093919774537444

Epoch: 5| Step: 10
Training loss: 2.400874614715576
Validation loss: 1.9281293076853598

Epoch: 185| Step: 0
Training loss: 1.9578921794891357
Validation loss: 1.9354574013781805

Epoch: 5| Step: 1
Training loss: 1.5075881481170654
Validation loss: 1.9631585126282067

Epoch: 5| Step: 2
Training loss: 1.6636520624160767
Validation loss: 2.0013746317996772

Epoch: 5| Step: 3
Training loss: 1.335460901260376
Validation loss: 2.031239944119607

Epoch: 5| Step: 4
Training loss: 1.8476283550262451
Validation loss: 2.0558515953761276

Epoch: 5| Step: 5
Training loss: 2.4574482440948486
Validation loss: 2.0765807961904876

Epoch: 5| Step: 6
Training loss: 1.9673731327056885
Validation loss: 2.0758979294889714

Epoch: 5| Step: 7
Training loss: 2.5939276218414307
Validation loss: 2.089739699517527

Epoch: 5| Step: 8
Training loss: 2.735954761505127
Validation loss: 2.087386723487608

Epoch: 5| Step: 9
Training loss: 1.8363393545150757
Validation loss: 2.0707587529254217

Epoch: 5| Step: 10
Training loss: 2.453226327896118
Validation loss: 2.0709891447456936

Epoch: 186| Step: 0
Training loss: 2.0615687370300293
Validation loss: 2.0646195629591584

Epoch: 5| Step: 1
Training loss: 1.966499924659729
Validation loss: 2.0600707761703

Epoch: 5| Step: 2
Training loss: 1.919978141784668
Validation loss: 2.0590534569114767

Epoch: 5| Step: 3
Training loss: 1.9391673803329468
Validation loss: 2.0428186296134867

Epoch: 5| Step: 4
Training loss: 1.8403167724609375
Validation loss: 2.0257731612010668

Epoch: 5| Step: 5
Training loss: 2.296613931655884
Validation loss: 2.00824918541857

Epoch: 5| Step: 6
Training loss: 1.8822704553604126
Validation loss: 1.9978022331832557

Epoch: 5| Step: 7
Training loss: 1.6749498844146729
Validation loss: 1.989461741139812

Epoch: 5| Step: 8
Training loss: 1.4732630252838135
Validation loss: 1.9796093663861674

Epoch: 5| Step: 9
Training loss: 2.510695219039917
Validation loss: 1.9574036880206036

Epoch: 5| Step: 10
Training loss: 2.3893942832946777
Validation loss: 1.9433624475233016

Epoch: 187| Step: 0
Training loss: 2.5370209217071533
Validation loss: 1.9255811988666494

Epoch: 5| Step: 1
Training loss: 1.696049451828003
Validation loss: 1.9216009070796352

Epoch: 5| Step: 2
Training loss: 2.110515594482422
Validation loss: 1.9226347015750023

Epoch: 5| Step: 3
Training loss: 2.367283344268799
Validation loss: 1.9204370629402898

Epoch: 5| Step: 4
Training loss: 1.5929670333862305
Validation loss: 1.9151142989435503

Epoch: 5| Step: 5
Training loss: 2.19449782371521
Validation loss: 1.919488130077239

Epoch: 5| Step: 6
Training loss: 1.9026330709457397
Validation loss: 1.9234551101602533

Epoch: 5| Step: 7
Training loss: 2.251124143600464
Validation loss: 1.9370813523569415

Epoch: 5| Step: 8
Training loss: 2.5525386333465576
Validation loss: 1.9473836780876241

Epoch: 5| Step: 9
Training loss: 1.6791235208511353
Validation loss: 1.9384886744201824

Epoch: 5| Step: 10
Training loss: 1.3049198389053345
Validation loss: 1.9542269424725605

Epoch: 188| Step: 0
Training loss: 1.7730071544647217
Validation loss: 1.9626806269409836

Epoch: 5| Step: 1
Training loss: 2.097278118133545
Validation loss: 1.9827169500371462

Epoch: 5| Step: 2
Training loss: 2.3546230792999268
Validation loss: 1.9854503857192172

Epoch: 5| Step: 3
Training loss: 1.9617557525634766
Validation loss: 1.9942676636480516

Epoch: 5| Step: 4
Training loss: 1.9407978057861328
Validation loss: 2.0059921779940204

Epoch: 5| Step: 5
Training loss: 1.9487577676773071
Validation loss: 2.018742174230596

Epoch: 5| Step: 6
Training loss: 1.8308727741241455
Validation loss: 2.024645911749973

Epoch: 5| Step: 7
Training loss: 2.235924243927002
Validation loss: 2.035741626575429

Epoch: 5| Step: 8
Training loss: 1.9789454936981201
Validation loss: 2.0514891352704776

Epoch: 5| Step: 9
Training loss: 2.1989011764526367
Validation loss: 2.0631739413866432

Epoch: 5| Step: 10
Training loss: 2.057284116744995
Validation loss: 2.055778193217452

Epoch: 189| Step: 0
Training loss: 1.5950380563735962
Validation loss: 2.053432294117507

Epoch: 5| Step: 1
Training loss: 1.6510136127471924
Validation loss: 2.047348322406892

Epoch: 5| Step: 2
Training loss: 2.772099018096924
Validation loss: 2.0399934066239225

Epoch: 5| Step: 3
Training loss: 1.7370589971542358
Validation loss: 2.0558258615514284

Epoch: 5| Step: 4
Training loss: 2.510002374649048
Validation loss: 2.067486866827934

Epoch: 5| Step: 5
Training loss: 1.3976194858551025
Validation loss: 2.0755479002511628

Epoch: 5| Step: 6
Training loss: 2.1034798622131348
Validation loss: 2.062092552902878

Epoch: 5| Step: 7
Training loss: 1.8872096538543701
Validation loss: 2.0520589800291162

Epoch: 5| Step: 8
Training loss: 2.3415281772613525
Validation loss: 2.052936646246141

Epoch: 5| Step: 9
Training loss: 2.5471577644348145
Validation loss: 2.0294435383171163

Epoch: 5| Step: 10
Training loss: 1.4035170078277588
Validation loss: 2.013890048509003

Epoch: 190| Step: 0
Training loss: 2.1734702587127686
Validation loss: 1.9956154823303223

Epoch: 5| Step: 1
Training loss: 1.4037199020385742
Validation loss: 1.9814973890140493

Epoch: 5| Step: 2
Training loss: 1.5792548656463623
Validation loss: 1.9641890166908182

Epoch: 5| Step: 3
Training loss: 2.343512535095215
Validation loss: 1.9509859828538791

Epoch: 5| Step: 4
Training loss: 2.040160655975342
Validation loss: 1.9528640918834235

Epoch: 5| Step: 5
Training loss: 1.8681310415267944
Validation loss: 1.9460793464414534

Epoch: 5| Step: 6
Training loss: 2.2337448596954346
Validation loss: 1.9501190377819924

Epoch: 5| Step: 7
Training loss: 2.5999178886413574
Validation loss: 1.9536945653218094

Epoch: 5| Step: 8
Training loss: 1.567981481552124
Validation loss: 1.9606945565951768

Epoch: 5| Step: 9
Training loss: 2.0091662406921387
Validation loss: 1.97047056177611

Epoch: 5| Step: 10
Training loss: 2.095940113067627
Validation loss: 1.9804279137683172

Epoch: 191| Step: 0
Training loss: 1.9617706537246704
Validation loss: 1.9608450371731994

Epoch: 5| Step: 1
Training loss: 1.9390465021133423
Validation loss: 1.9511640276960147

Epoch: 5| Step: 2
Training loss: 1.5330225229263306
Validation loss: 1.9396562717294181

Epoch: 5| Step: 3
Training loss: 1.9561378955841064
Validation loss: 1.9316008565246419

Epoch: 5| Step: 4
Training loss: 2.1930174827575684
Validation loss: 1.9301270131141908

Epoch: 5| Step: 5
Training loss: 2.2461886405944824
Validation loss: 1.9304314967124694

Epoch: 5| Step: 6
Training loss: 1.7246919870376587
Validation loss: 1.9083253773309852

Epoch: 5| Step: 7
Training loss: 1.5666621923446655
Validation loss: 1.8924297427618375

Epoch: 5| Step: 8
Training loss: 2.6468629837036133
Validation loss: 1.8892840941747029

Epoch: 5| Step: 9
Training loss: 1.8584572076797485
Validation loss: 1.8759233156840007

Epoch: 5| Step: 10
Training loss: 2.197571039199829
Validation loss: 1.884282801740913

Epoch: 192| Step: 0
Training loss: 2.073937177658081
Validation loss: 1.8935379392357283

Epoch: 5| Step: 1
Training loss: 1.4596216678619385
Validation loss: 1.906876415334722

Epoch: 5| Step: 2
Training loss: 1.9147990942001343
Validation loss: 1.9294893177606727

Epoch: 5| Step: 3
Training loss: 2.481215476989746
Validation loss: 1.9279542892209944

Epoch: 5| Step: 4
Training loss: 2.853877305984497
Validation loss: 1.9343087339913974

Epoch: 5| Step: 5
Training loss: 2.3737406730651855
Validation loss: 1.9341122232457644

Epoch: 5| Step: 6
Training loss: 1.853097677230835
Validation loss: 1.9373172560045797

Epoch: 5| Step: 7
Training loss: 1.5414196252822876
Validation loss: 1.9510628036273423

Epoch: 5| Step: 8
Training loss: 2.504002332687378
Validation loss: 1.982232545011787

Epoch: 5| Step: 9
Training loss: 1.502190351486206
Validation loss: 2.0115385927179807

Epoch: 5| Step: 10
Training loss: 1.0499180555343628
Validation loss: 2.0348552632075485

Epoch: 193| Step: 0
Training loss: 2.3446431159973145
Validation loss: 2.047895275136476

Epoch: 5| Step: 1
Training loss: 2.3205647468566895
Validation loss: 2.0385152242516957

Epoch: 5| Step: 2
Training loss: 1.8569778203964233
Validation loss: 2.0414156875302716

Epoch: 5| Step: 3
Training loss: 1.9942829608917236
Validation loss: 2.040777419203071

Epoch: 5| Step: 4
Training loss: 1.7825390100479126
Validation loss: 2.0570523021041707

Epoch: 5| Step: 5
Training loss: 1.6171470880508423
Validation loss: 2.0562360927622807

Epoch: 5| Step: 6
Training loss: 1.8436329364776611
Validation loss: 2.048385577817117

Epoch: 5| Step: 7
Training loss: 1.776362419128418
Validation loss: 2.041168478227431

Epoch: 5| Step: 8
Training loss: 2.4161815643310547
Validation loss: 2.034747245491192

Epoch: 5| Step: 9
Training loss: 1.667304277420044
Validation loss: 2.009929756964407

Epoch: 5| Step: 10
Training loss: 2.251497268676758
Validation loss: 1.9989475921917987

Epoch: 194| Step: 0
Training loss: 1.8552772998809814
Validation loss: 1.9966956287301996

Epoch: 5| Step: 1
Training loss: 1.770727515220642
Validation loss: 1.997247261385764

Epoch: 5| Step: 2
Training loss: 2.227228879928589
Validation loss: 1.9815617222939768

Epoch: 5| Step: 3
Training loss: 2.4390974044799805
Validation loss: 1.970731863411524

Epoch: 5| Step: 4
Training loss: 1.6619094610214233
Validation loss: 1.9525612784970192

Epoch: 5| Step: 5
Training loss: 1.5230998992919922
Validation loss: 1.9283296985010947

Epoch: 5| Step: 6
Training loss: 2.6027848720550537
Validation loss: 1.9313116586336525

Epoch: 5| Step: 7
Training loss: 2.148808240890503
Validation loss: 1.939275219876279

Epoch: 5| Step: 8
Training loss: 1.5440843105316162
Validation loss: 1.9581399592020179

Epoch: 5| Step: 9
Training loss: 2.0852208137512207
Validation loss: 1.9718996260755806

Epoch: 5| Step: 10
Training loss: 2.1150193214416504
Validation loss: 1.9739536828892206

Epoch: 195| Step: 0
Training loss: 1.8549926280975342
Validation loss: 1.974099818096366

Epoch: 5| Step: 1
Training loss: 2.12709903717041
Validation loss: 1.9743356704711914

Epoch: 5| Step: 2
Training loss: 1.856136679649353
Validation loss: 2.008372405523895

Epoch: 5| Step: 3
Training loss: 1.9922908544540405
Validation loss: 2.0780025835960143

Epoch: 5| Step: 4
Training loss: 2.3157780170440674
Validation loss: 2.097687428997409

Epoch: 5| Step: 5
Training loss: 2.225268602371216
Validation loss: 2.134508240607477

Epoch: 5| Step: 6
Training loss: 1.669264554977417
Validation loss: 2.092873195166229

Epoch: 5| Step: 7
Training loss: 2.212174892425537
Validation loss: 2.081286358576949

Epoch: 5| Step: 8
Training loss: 2.141592264175415
Validation loss: 2.0520065164053314

Epoch: 5| Step: 9
Training loss: 1.540992021560669
Validation loss: 2.0458866652622016

Epoch: 5| Step: 10
Training loss: 1.8071740865707397
Validation loss: 2.052328985224488

Epoch: 196| Step: 0
Training loss: 2.0171940326690674
Validation loss: 2.0639896803004767

Epoch: 5| Step: 1
Training loss: 1.8292596340179443
Validation loss: 2.0684175029877694

Epoch: 5| Step: 2
Training loss: 1.3927040100097656
Validation loss: 2.067905318352484

Epoch: 5| Step: 3
Training loss: 2.414367437362671
Validation loss: 2.0446951748222433

Epoch: 5| Step: 4
Training loss: 2.0688984394073486
Validation loss: 2.0174953860621296

Epoch: 5| Step: 5
Training loss: 2.23820424079895
Validation loss: 1.9796151781594882

Epoch: 5| Step: 6
Training loss: 1.5236819982528687
Validation loss: 1.9651694195244902

Epoch: 5| Step: 7
Training loss: 1.7557003498077393
Validation loss: 1.9369494633008075

Epoch: 5| Step: 8
Training loss: 2.0487375259399414
Validation loss: 1.9260635786159064

Epoch: 5| Step: 9
Training loss: 2.5625500679016113
Validation loss: 1.939141922099616

Epoch: 5| Step: 10
Training loss: 1.978620171546936
Validation loss: 1.991875369061706

Epoch: 197| Step: 0
Training loss: 2.486159563064575
Validation loss: 1.9763372277700773

Epoch: 5| Step: 1
Training loss: 2.4469857215881348
Validation loss: 1.96612508450785

Epoch: 5| Step: 2
Training loss: 1.6927573680877686
Validation loss: 1.9469805891795824

Epoch: 5| Step: 3
Training loss: 1.7432540655136108
Validation loss: 1.930330773835541

Epoch: 5| Step: 4
Training loss: 1.5421442985534668
Validation loss: 1.9224335391034362

Epoch: 5| Step: 5
Training loss: 2.15463924407959
Validation loss: 1.937643926630738

Epoch: 5| Step: 6
Training loss: 1.472602367401123
Validation loss: 1.968464720633722

Epoch: 5| Step: 7
Training loss: 2.290818452835083
Validation loss: 2.012367030625702

Epoch: 5| Step: 8
Training loss: 2.185136318206787
Validation loss: 2.0185048733988116

Epoch: 5| Step: 9
Training loss: 2.0479953289031982
Validation loss: 2.006123467158246

Epoch: 5| Step: 10
Training loss: 1.741684913635254
Validation loss: 2.0291738689586682

Epoch: 198| Step: 0
Training loss: 2.018467903137207
Validation loss: 2.0591034863584783

Epoch: 5| Step: 1
Training loss: 1.8844674825668335
Validation loss: 2.1049899721658356

Epoch: 5| Step: 2
Training loss: 2.2065253257751465
Validation loss: 2.097342202740331

Epoch: 5| Step: 3
Training loss: 1.8903526067733765
Validation loss: 2.0977895811039913

Epoch: 5| Step: 4
Training loss: 2.403702974319458
Validation loss: 2.0558594093527844

Epoch: 5| Step: 5
Training loss: 2.0497875213623047
Validation loss: 2.027480394609513

Epoch: 5| Step: 6
Training loss: 1.4946964979171753
Validation loss: 1.9889872356127667

Epoch: 5| Step: 7
Training loss: 1.7203181982040405
Validation loss: 1.9798063488416775

Epoch: 5| Step: 8
Training loss: 1.688023328781128
Validation loss: 1.9717451449363463

Epoch: 5| Step: 9
Training loss: 2.342926263809204
Validation loss: 1.962304510096068

Epoch: 5| Step: 10
Training loss: 1.961944580078125
Validation loss: 1.9484952983035837

Epoch: 199| Step: 0
Training loss: 1.8504787683486938
Validation loss: 1.9496557815100557

Epoch: 5| Step: 1
Training loss: 1.618614912033081
Validation loss: 1.9598001831321306

Epoch: 5| Step: 2
Training loss: 2.0181469917297363
Validation loss: 1.9510746309834142

Epoch: 5| Step: 3
Training loss: 1.4996311664581299
Validation loss: 1.9443849491816696

Epoch: 5| Step: 4
Training loss: 1.5728862285614014
Validation loss: 1.9616184132073515

Epoch: 5| Step: 5
Training loss: 1.9651529788970947
Validation loss: 1.9689634641011555

Epoch: 5| Step: 6
Training loss: 2.7358973026275635
Validation loss: 1.9684967148688532

Epoch: 5| Step: 7
Training loss: 1.881540298461914
Validation loss: 1.9769526399591917

Epoch: 5| Step: 8
Training loss: 2.4393391609191895
Validation loss: 1.9701726795524679

Epoch: 5| Step: 9
Training loss: 1.6913187503814697
Validation loss: 1.9880459731624973

Epoch: 5| Step: 10
Training loss: 1.788252353668213
Validation loss: 1.973751555206955

Epoch: 200| Step: 0
Training loss: 2.1279823780059814
Validation loss: 1.97019152743842

Epoch: 5| Step: 1
Training loss: 1.8097047805786133
Validation loss: 1.9507717432514313

Epoch: 5| Step: 2
Training loss: 2.0496771335601807
Validation loss: 1.9545626076318885

Epoch: 5| Step: 3
Training loss: 2.046785831451416
Validation loss: 1.9364249257631199

Epoch: 5| Step: 4
Training loss: 1.5813379287719727
Validation loss: 1.9621714276652182

Epoch: 5| Step: 5
Training loss: 1.8266903162002563
Validation loss: 1.9656781458085584

Epoch: 5| Step: 6
Training loss: 2.597118377685547
Validation loss: 1.9780424128296554

Epoch: 5| Step: 7
Training loss: 1.4613336324691772
Validation loss: 2.0046484008912118

Epoch: 5| Step: 8
Training loss: 2.174492359161377
Validation loss: 2.0284009838616974

Epoch: 5| Step: 9
Training loss: 1.3775780200958252
Validation loss: 2.0502458169896114

Epoch: 5| Step: 10
Training loss: 2.069673776626587
Validation loss: 2.053588218586419

Epoch: 201| Step: 0
Training loss: 1.7618545293807983
Validation loss: 2.05264312477522

Epoch: 5| Step: 1
Training loss: 2.4550976753234863
Validation loss: 2.06828486534857

Epoch: 5| Step: 2
Training loss: 2.115684986114502
Validation loss: 2.0711772134227138

Epoch: 5| Step: 3
Training loss: 1.7681550979614258
Validation loss: 2.068483455206758

Epoch: 5| Step: 4
Training loss: 2.331296920776367
Validation loss: 2.0686063099932928

Epoch: 5| Step: 5
Training loss: 2.2397379875183105
Validation loss: 2.037784320051952

Epoch: 5| Step: 6
Training loss: 1.369842767715454
Validation loss: 2.011573647940031

Epoch: 5| Step: 7
Training loss: 1.6023086309432983
Validation loss: 1.9718380538366174

Epoch: 5| Step: 8
Training loss: 1.6612393856048584
Validation loss: 1.9731608590772074

Epoch: 5| Step: 9
Training loss: 2.2080941200256348
Validation loss: 1.9739753379616687

Epoch: 5| Step: 10
Training loss: 1.8537324666976929
Validation loss: 1.9929685900288243

Epoch: 202| Step: 0
Training loss: 1.5105135440826416
Validation loss: 2.0167866432538597

Epoch: 5| Step: 1
Training loss: 1.7076146602630615
Validation loss: 1.9992027449351486

Epoch: 5| Step: 2
Training loss: 2.324713945388794
Validation loss: 1.9846466869436286

Epoch: 5| Step: 3
Training loss: 1.9594650268554688
Validation loss: 1.9823720147532802

Epoch: 5| Step: 4
Training loss: 1.4702435731887817
Validation loss: 1.973918196975544

Epoch: 5| Step: 5
Training loss: 1.6256603002548218
Validation loss: 1.973294347845098

Epoch: 5| Step: 6
Training loss: 1.8752391338348389
Validation loss: 1.9545242760771064

Epoch: 5| Step: 7
Training loss: 1.5512380599975586
Validation loss: 1.9690889696921072

Epoch: 5| Step: 8
Training loss: 2.0779478549957275
Validation loss: 1.9624196124333206

Epoch: 5| Step: 9
Training loss: 2.0080928802490234
Validation loss: 1.957675677473827

Epoch: 5| Step: 10
Training loss: 3.0528461933135986
Validation loss: 1.955336086211666

Epoch: 203| Step: 0
Training loss: 1.6670860052108765
Validation loss: 1.9760450534923102

Epoch: 5| Step: 1
Training loss: 2.3243069648742676
Validation loss: 1.9770410573610695

Epoch: 5| Step: 2
Training loss: 1.6286481618881226
Validation loss: 1.9673111105477938

Epoch: 5| Step: 3
Training loss: 2.225914716720581
Validation loss: 1.9592518345002206

Epoch: 5| Step: 4
Training loss: 1.861748456954956
Validation loss: 1.950399806422572

Epoch: 5| Step: 5
Training loss: 1.8626394271850586
Validation loss: 1.9474176847806541

Epoch: 5| Step: 6
Training loss: 1.2057524919509888
Validation loss: 1.9473173182497743

Epoch: 5| Step: 7
Training loss: 2.4007182121276855
Validation loss: 1.9558696003370388

Epoch: 5| Step: 8
Training loss: 1.9504626989364624
Validation loss: 1.9634510317156393

Epoch: 5| Step: 9
Training loss: 1.796364188194275
Validation loss: 1.959714533180319

Epoch: 5| Step: 10
Training loss: 1.5503761768341064
Validation loss: 1.947254809000159

Epoch: 204| Step: 0
Training loss: 2.351732015609741
Validation loss: 1.950804764224637

Epoch: 5| Step: 1
Training loss: 1.6404883861541748
Validation loss: 1.9596506921193932

Epoch: 5| Step: 2
Training loss: 1.669194221496582
Validation loss: 1.96437418589028

Epoch: 5| Step: 3
Training loss: 1.233966588973999
Validation loss: 1.9639375273899367

Epoch: 5| Step: 4
Training loss: 1.3598694801330566
Validation loss: 1.9615151420716317

Epoch: 5| Step: 5
Training loss: 1.9833530187606812
Validation loss: 1.9595232202160744

Epoch: 5| Step: 6
Training loss: 1.8334438800811768
Validation loss: 1.967833621527559

Epoch: 5| Step: 7
Training loss: 2.4885029792785645
Validation loss: 1.9715050484544487

Epoch: 5| Step: 8
Training loss: 1.881069540977478
Validation loss: 1.9598028736729776

Epoch: 5| Step: 9
Training loss: 2.0505385398864746
Validation loss: 1.9660522117409656

Epoch: 5| Step: 10
Training loss: 1.7474242448806763
Validation loss: 1.971387270958193

Epoch: 205| Step: 0
Training loss: 1.6702829599380493
Validation loss: 1.9678966973417549

Epoch: 5| Step: 1
Training loss: 2.3513400554656982
Validation loss: 1.962337565678422

Epoch: 5| Step: 2
Training loss: 2.264244556427002
Validation loss: 1.9832993309984925

Epoch: 5| Step: 3
Training loss: 1.3986047506332397
Validation loss: 2.0024838511661818

Epoch: 5| Step: 4
Training loss: 1.9890064001083374
Validation loss: 2.023054554898252

Epoch: 5| Step: 5
Training loss: 1.6560304164886475
Validation loss: 2.0209707624168805

Epoch: 5| Step: 6
Training loss: 2.1392102241516113
Validation loss: 2.016793163873816

Epoch: 5| Step: 7
Training loss: 1.968989610671997
Validation loss: 2.002426039788031

Epoch: 5| Step: 8
Training loss: 1.989168405532837
Validation loss: 1.996784520405595

Epoch: 5| Step: 9
Training loss: 1.3299880027770996
Validation loss: 1.9768479229301534

Epoch: 5| Step: 10
Training loss: 1.582102656364441
Validation loss: 1.962546210135183

Epoch: 206| Step: 0
Training loss: 2.1249916553497314
Validation loss: 1.9601134792450936

Epoch: 5| Step: 1
Training loss: 1.9673731327056885
Validation loss: 1.9567406741521691

Epoch: 5| Step: 2
Training loss: 1.9673877954483032
Validation loss: 1.9520618941194268

Epoch: 5| Step: 3
Training loss: 1.5597950220108032
Validation loss: 1.967650459658715

Epoch: 5| Step: 4
Training loss: 2.005767345428467
Validation loss: 1.9790766700621574

Epoch: 5| Step: 5
Training loss: 1.846520185470581
Validation loss: 1.9856800404928063

Epoch: 5| Step: 6
Training loss: 1.5234529972076416
Validation loss: 1.9769694420599169

Epoch: 5| Step: 7
Training loss: 1.7108228206634521
Validation loss: 1.9747776241712673

Epoch: 5| Step: 8
Training loss: 2.0235815048217773
Validation loss: 1.9635041785496536

Epoch: 5| Step: 9
Training loss: 1.7995773553848267
Validation loss: 1.963367800558767

Epoch: 5| Step: 10
Training loss: 1.5822370052337646
Validation loss: 1.9643987763312556

Epoch: 207| Step: 0
Training loss: 1.4460707902908325
Validation loss: 1.9479237012965704

Epoch: 5| Step: 1
Training loss: 1.5331897735595703
Validation loss: 1.948076327641805

Epoch: 5| Step: 2
Training loss: 1.7501128911972046
Validation loss: 1.9712808260353663

Epoch: 5| Step: 3
Training loss: 1.8007835149765015
Validation loss: 1.9839988062458653

Epoch: 5| Step: 4
Training loss: 2.25911021232605
Validation loss: 1.9667170919397825

Epoch: 5| Step: 5
Training loss: 2.139597177505493
Validation loss: 1.9719455088338544

Epoch: 5| Step: 6
Training loss: 1.9713976383209229
Validation loss: 1.958947976430257

Epoch: 5| Step: 7
Training loss: 1.3746137619018555
Validation loss: 1.9713396872243574

Epoch: 5| Step: 8
Training loss: 1.7453925609588623
Validation loss: 1.971814811870616

Epoch: 5| Step: 9
Training loss: 2.0463767051696777
Validation loss: 1.9704757070028653

Epoch: 5| Step: 10
Training loss: 2.2052502632141113
Validation loss: 1.9780535031390447

Epoch: 208| Step: 0
Training loss: 2.208812713623047
Validation loss: 1.9712418907432145

Epoch: 5| Step: 1
Training loss: 2.193610668182373
Validation loss: 1.9667161190381615

Epoch: 5| Step: 2
Training loss: 1.5000892877578735
Validation loss: 1.982584854607941

Epoch: 5| Step: 3
Training loss: 1.9979655742645264
Validation loss: 1.9898953271168534

Epoch: 5| Step: 4
Training loss: 1.2033847570419312
Validation loss: 1.971632542148713

Epoch: 5| Step: 5
Training loss: 1.745470643043518
Validation loss: 1.9912289496391051

Epoch: 5| Step: 6
Training loss: 1.6599557399749756
Validation loss: 1.9750042935853362

Epoch: 5| Step: 7
Training loss: 2.1752219200134277
Validation loss: 1.9800850370878815

Epoch: 5| Step: 8
Training loss: 1.9040062427520752
Validation loss: 1.9728961606179514

Epoch: 5| Step: 9
Training loss: 1.6783123016357422
Validation loss: 1.973259332359478

Epoch: 5| Step: 10
Training loss: 1.7723991870880127
Validation loss: 1.9674888041711622

Epoch: 209| Step: 0
Training loss: 1.5916330814361572
Validation loss: 1.975817439376667

Epoch: 5| Step: 1
Training loss: 1.716331124305725
Validation loss: 1.9626772147352978

Epoch: 5| Step: 2
Training loss: 1.5138083696365356
Validation loss: 1.9537165293129541

Epoch: 5| Step: 3
Training loss: 2.0093588829040527
Validation loss: 1.9386384512788506

Epoch: 5| Step: 4
Training loss: 1.3678851127624512
Validation loss: 1.9582307736078899

Epoch: 5| Step: 5
Training loss: 2.1299712657928467
Validation loss: 1.9638400885366625

Epoch: 5| Step: 6
Training loss: 1.151853084564209
Validation loss: 1.985112682465584

Epoch: 5| Step: 7
Training loss: 1.7534675598144531
Validation loss: 1.9884832546275149

Epoch: 5| Step: 8
Training loss: 2.5630502700805664
Validation loss: 1.9949340371675388

Epoch: 5| Step: 9
Training loss: 2.0674242973327637
Validation loss: 1.985567024959031

Epoch: 5| Step: 10
Training loss: 2.117677927017212
Validation loss: 1.9921774274559432

Epoch: 210| Step: 0
Training loss: 2.083442449569702
Validation loss: 1.9772400035653064

Epoch: 5| Step: 1
Training loss: 2.1191954612731934
Validation loss: 1.967601127521966

Epoch: 5| Step: 2
Training loss: 2.406134605407715
Validation loss: 1.9556851874115646

Epoch: 5| Step: 3
Training loss: 1.8810993432998657
Validation loss: 1.947918027959844

Epoch: 5| Step: 4
Training loss: 1.6772381067276
Validation loss: 1.9508266500247422

Epoch: 5| Step: 5
Training loss: 1.6197246313095093
Validation loss: 1.9532584323677966

Epoch: 5| Step: 6
Training loss: 1.6725763082504272
Validation loss: 1.965339114589076

Epoch: 5| Step: 7
Training loss: 2.1051578521728516
Validation loss: 1.9397814581471104

Epoch: 5| Step: 8
Training loss: 1.5056747198104858
Validation loss: 1.943283950128863

Epoch: 5| Step: 9
Training loss: 1.527410626411438
Validation loss: 1.9266174429206437

Epoch: 5| Step: 10
Training loss: 1.3822523355484009
Validation loss: 1.930029566569995

Epoch: 211| Step: 0
Training loss: 1.7859092950820923
Validation loss: 1.9460252420876616

Epoch: 5| Step: 1
Training loss: 1.9497112035751343
Validation loss: 1.9535265789237073

Epoch: 5| Step: 2
Training loss: 1.2181639671325684
Validation loss: 1.9695810169302008

Epoch: 5| Step: 3
Training loss: 1.8478610515594482
Validation loss: 1.961688942806695

Epoch: 5| Step: 4
Training loss: 1.8035560846328735
Validation loss: 1.9669832209105134

Epoch: 5| Step: 5
Training loss: 1.5876461267471313
Validation loss: 1.9684148398778771

Epoch: 5| Step: 6
Training loss: 2.016099452972412
Validation loss: 1.9798708833673948

Epoch: 5| Step: 7
Training loss: 2.1328699588775635
Validation loss: 1.9775823136811614

Epoch: 5| Step: 8
Training loss: 1.6543705463409424
Validation loss: 1.9588139031523017

Epoch: 5| Step: 9
Training loss: 2.1225619316101074
Validation loss: 1.9769984009445354

Epoch: 5| Step: 10
Training loss: 1.463695764541626
Validation loss: 2.004972157939788

Epoch: 212| Step: 0
Training loss: 1.4692779779434204
Validation loss: 2.021284841722058

Epoch: 5| Step: 1
Training loss: 1.7484219074249268
Validation loss: 2.032299808276597

Epoch: 5| Step: 2
Training loss: 1.7467765808105469
Validation loss: 2.0341902266266527

Epoch: 5| Step: 3
Training loss: 2.0579895973205566
Validation loss: 2.0224839064382736

Epoch: 5| Step: 4
Training loss: 1.1955827474594116
Validation loss: 2.011196449238767

Epoch: 5| Step: 5
Training loss: 2.0033435821533203
Validation loss: 1.9961155845272927

Epoch: 5| Step: 6
Training loss: 1.5193088054656982
Validation loss: 1.9828864502650436

Epoch: 5| Step: 7
Training loss: 2.1476638317108154
Validation loss: 1.9744475900485952

Epoch: 5| Step: 8
Training loss: 2.1742968559265137
Validation loss: 1.9546806427740282

Epoch: 5| Step: 9
Training loss: 1.5857471227645874
Validation loss: 1.9266472221702657

Epoch: 5| Step: 10
Training loss: 1.6801091432571411
Validation loss: 1.9208842567218247

Epoch: 213| Step: 0
Training loss: 1.6100857257843018
Validation loss: 1.917250601194238

Epoch: 5| Step: 1
Training loss: 1.747611403465271
Validation loss: 1.9146498364786948

Epoch: 5| Step: 2
Training loss: 1.5183244943618774
Validation loss: 1.9183105140603998

Epoch: 5| Step: 3
Training loss: 1.5483911037445068
Validation loss: 1.8927096961646952

Epoch: 5| Step: 4
Training loss: 1.7488975524902344
Validation loss: 1.9031999156039248

Epoch: 5| Step: 5
Training loss: 2.6461198329925537
Validation loss: 1.9183064506899925

Epoch: 5| Step: 6
Training loss: 1.5183062553405762
Validation loss: 1.9368967651039042

Epoch: 5| Step: 7
Training loss: 1.4377785921096802
Validation loss: 1.9397647444919874

Epoch: 5| Step: 8
Training loss: 1.736385703086853
Validation loss: 1.935012589218796

Epoch: 5| Step: 9
Training loss: 2.0989136695861816
Validation loss: 1.9482945319144958

Epoch: 5| Step: 10
Training loss: 2.0743980407714844
Validation loss: 1.9715127509127381

Epoch: 214| Step: 0
Training loss: 1.724086046218872
Validation loss: 1.9822716046405096

Epoch: 5| Step: 1
Training loss: 1.8563648462295532
Validation loss: 1.9900586835799678

Epoch: 5| Step: 2
Training loss: 1.9846359491348267
Validation loss: 1.9931233826503958

Epoch: 5| Step: 3
Training loss: 2.273951530456543
Validation loss: 1.994582627409248

Epoch: 5| Step: 4
Training loss: 2.0369365215301514
Validation loss: 2.00997031247744

Epoch: 5| Step: 5
Training loss: 1.4325531721115112
Validation loss: 1.985748360233922

Epoch: 5| Step: 6
Training loss: 1.575157880783081
Validation loss: 2.0034790090335313

Epoch: 5| Step: 7
Training loss: 1.0702464580535889
Validation loss: 2.0225722841037217

Epoch: 5| Step: 8
Training loss: 1.8368037939071655
Validation loss: 2.0084862491135955

Epoch: 5| Step: 9
Training loss: 2.069714069366455
Validation loss: 2.0296277666604645

Epoch: 5| Step: 10
Training loss: 1.63483726978302
Validation loss: 1.9914000752151653

Epoch: 215| Step: 0
Training loss: 1.827052354812622
Validation loss: 1.9866276684627737

Epoch: 5| Step: 1
Training loss: 1.7899494171142578
Validation loss: 1.992853351818618

Epoch: 5| Step: 2
Training loss: 1.5018335580825806
Validation loss: 2.0049686995885705

Epoch: 5| Step: 3
Training loss: 1.4849655628204346
Validation loss: 2.0242871520339802

Epoch: 5| Step: 4
Training loss: 1.8859283924102783
Validation loss: 2.0251716516351186

Epoch: 5| Step: 5
Training loss: 2.417959690093994
Validation loss: 2.041059893946494

Epoch: 5| Step: 6
Training loss: 1.7098500728607178
Validation loss: 2.0489855209986367

Epoch: 5| Step: 7
Training loss: 1.4811820983886719
Validation loss: 2.0288776428468767

Epoch: 5| Step: 8
Training loss: 1.6711385250091553
Validation loss: 2.0162276785860778

Epoch: 5| Step: 9
Training loss: 1.7297264337539673
Validation loss: 2.015257937933809

Epoch: 5| Step: 10
Training loss: 1.7458027601242065
Validation loss: 1.990145580742949

Epoch: 216| Step: 0
Training loss: 1.7935880422592163
Validation loss: 1.9722566566159647

Epoch: 5| Step: 1
Training loss: 1.630345344543457
Validation loss: 1.9591950190964567

Epoch: 5| Step: 2
Training loss: 1.910386085510254
Validation loss: 1.956556797027588

Epoch: 5| Step: 3
Training loss: 2.1551451683044434
Validation loss: 1.958370711213799

Epoch: 5| Step: 4
Training loss: 1.1675130128860474
Validation loss: 1.9627500400748303

Epoch: 5| Step: 5
Training loss: 1.8952497243881226
Validation loss: 1.9887793756300403

Epoch: 5| Step: 6
Training loss: 1.8450863361358643
Validation loss: 1.9598297149904313

Epoch: 5| Step: 7
Training loss: 1.5543440580368042
Validation loss: 1.9640405549797961

Epoch: 5| Step: 8
Training loss: 1.6230666637420654
Validation loss: 1.956402055678829

Epoch: 5| Step: 9
Training loss: 2.14927339553833
Validation loss: 1.9758345080960182

Epoch: 5| Step: 10
Training loss: 1.487372636795044
Validation loss: 1.9938156309948172

Epoch: 217| Step: 0
Training loss: 1.300724983215332
Validation loss: 2.011050734468686

Epoch: 5| Step: 1
Training loss: 2.0759472846984863
Validation loss: 2.0136746475773473

Epoch: 5| Step: 2
Training loss: 1.4110143184661865
Validation loss: 2.0095913064095283

Epoch: 5| Step: 3
Training loss: 1.8037006855010986
Validation loss: 2.0094574818047146

Epoch: 5| Step: 4
Training loss: 1.371660828590393
Validation loss: 1.9978262660323933

Epoch: 5| Step: 5
Training loss: 2.3218135833740234
Validation loss: 2.015111743762929

Epoch: 5| Step: 6
Training loss: 1.5383421182632446
Validation loss: 2.0368662175311836

Epoch: 5| Step: 7
Training loss: 1.3509116172790527
Validation loss: 2.0204605979304158

Epoch: 5| Step: 8
Training loss: 2.142587184906006
Validation loss: 2.0138238886351227

Epoch: 5| Step: 9
Training loss: 1.503761649131775
Validation loss: 1.9880513273259646

Epoch: 5| Step: 10
Training loss: 2.119863510131836
Validation loss: 1.980286205968549

Epoch: 218| Step: 0
Training loss: 1.9153006076812744
Validation loss: 1.9680044343394618

Epoch: 5| Step: 1
Training loss: 1.0464537143707275
Validation loss: 1.9649633540902087

Epoch: 5| Step: 2
Training loss: 1.8090299367904663
Validation loss: 1.9717494954345047

Epoch: 5| Step: 3
Training loss: 1.8767093420028687
Validation loss: 1.9834258710184405

Epoch: 5| Step: 4
Training loss: 1.092775583267212
Validation loss: 1.9900173397474392

Epoch: 5| Step: 5
Training loss: 1.9498779773712158
Validation loss: 2.0328113084198325

Epoch: 5| Step: 6
Training loss: 1.7672526836395264
Validation loss: 2.0145584690955376

Epoch: 5| Step: 7
Training loss: 1.9458773136138916
Validation loss: 1.9827521078048214

Epoch: 5| Step: 8
Training loss: 1.787652611732483
Validation loss: 1.9538482799324939

Epoch: 5| Step: 9
Training loss: 1.5151087045669556
Validation loss: 1.9509341473220496

Epoch: 5| Step: 10
Training loss: 2.109745502471924
Validation loss: 1.9386593295681862

Epoch: 219| Step: 0
Training loss: 1.3582574129104614
Validation loss: 1.9470910179999568

Epoch: 5| Step: 1
Training loss: 2.277885913848877
Validation loss: 1.9420036026226577

Epoch: 5| Step: 2
Training loss: 1.5484974384307861
Validation loss: 1.9590647015520322

Epoch: 5| Step: 3
Training loss: 1.7541526556015015
Validation loss: 1.990130421935871

Epoch: 5| Step: 4
Training loss: 2.006423234939575
Validation loss: 1.9996388907073646

Epoch: 5| Step: 5
Training loss: 1.260304570198059
Validation loss: 2.0003710549364806

Epoch: 5| Step: 6
Training loss: 1.8377981185913086
Validation loss: 2.0064395653304232

Epoch: 5| Step: 7
Training loss: 1.6219520568847656
Validation loss: 2.012754242907288

Epoch: 5| Step: 8
Training loss: 1.4199848175048828
Validation loss: 2.047971986955212

Epoch: 5| Step: 9
Training loss: 2.2599222660064697
Validation loss: 2.081000848483014

Epoch: 5| Step: 10
Training loss: 1.6973870992660522
Validation loss: 2.1008799973354546

Epoch: 220| Step: 0
Training loss: 2.0292553901672363
Validation loss: 2.0914722770772953

Epoch: 5| Step: 1
Training loss: 1.3707380294799805
Validation loss: 2.090215975238431

Epoch: 5| Step: 2
Training loss: 1.4039124250411987
Validation loss: 2.043281375720937

Epoch: 5| Step: 3
Training loss: 1.7040655612945557
Validation loss: 2.0192607846311343

Epoch: 5| Step: 4
Training loss: 2.4748291969299316
Validation loss: 1.99004053941337

Epoch: 5| Step: 5
Training loss: 1.725020408630371
Validation loss: 1.9988480037258518

Epoch: 5| Step: 6
Training loss: 2.103456974029541
Validation loss: 1.9983426704201648

Epoch: 5| Step: 7
Training loss: 1.5710129737854004
Validation loss: 2.017559189950266

Epoch: 5| Step: 8
Training loss: 1.6379436254501343
Validation loss: 1.9974455000251852

Epoch: 5| Step: 9
Training loss: 1.0016770362854004
Validation loss: 1.966823939354189

Epoch: 5| Step: 10
Training loss: 2.249748945236206
Validation loss: 1.960594142636945

Epoch: 221| Step: 0
Training loss: 1.8332717418670654
Validation loss: 1.9644847646836312

Epoch: 5| Step: 1
Training loss: 1.468169927597046
Validation loss: 1.978750636500697

Epoch: 5| Step: 2
Training loss: 1.7382144927978516
Validation loss: 1.962941749121553

Epoch: 5| Step: 3
Training loss: 1.6419070959091187
Validation loss: 1.98345886763706

Epoch: 5| Step: 4
Training loss: 1.3350768089294434
Validation loss: 1.9763191797400033

Epoch: 5| Step: 5
Training loss: 2.0247437953948975
Validation loss: 2.014922192019801

Epoch: 5| Step: 6
Training loss: 1.784682035446167
Validation loss: 2.0095651226658977

Epoch: 5| Step: 7
Training loss: 1.7696033716201782
Validation loss: 2.015355884387929

Epoch: 5| Step: 8
Training loss: 1.909446358680725
Validation loss: 1.9747415178565568

Epoch: 5| Step: 9
Training loss: 1.5477687120437622
Validation loss: 1.9801052052487609

Epoch: 5| Step: 10
Training loss: 1.6653083562850952
Validation loss: 2.019685596548101

Epoch: 222| Step: 0
Training loss: 2.0927605628967285
Validation loss: 2.028323363232356

Epoch: 5| Step: 1
Training loss: 1.6325451135635376
Validation loss: 2.0239927153433523

Epoch: 5| Step: 2
Training loss: 1.4451433420181274
Validation loss: 2.0360729809730285

Epoch: 5| Step: 3
Training loss: 1.9576435089111328
Validation loss: 2.0468798401535198

Epoch: 5| Step: 4
Training loss: 1.7948999404907227
Validation loss: 2.0526866579568512

Epoch: 5| Step: 5
Training loss: 1.558530569076538
Validation loss: 2.0571340924950055

Epoch: 5| Step: 6
Training loss: 1.8608392477035522
Validation loss: 2.074265164713706

Epoch: 5| Step: 7
Training loss: 2.301799774169922
Validation loss: 2.0528863194168254

Epoch: 5| Step: 8
Training loss: 1.0667669773101807
Validation loss: 2.0443472836607244

Epoch: 5| Step: 9
Training loss: 1.2001386880874634
Validation loss: 2.005396181537259

Epoch: 5| Step: 10
Training loss: 1.4704736471176147
Validation loss: 1.9672978975439583

Epoch: 223| Step: 0
Training loss: 2.046815872192383
Validation loss: 1.9661652913657568

Epoch: 5| Step: 1
Training loss: 1.7205404043197632
Validation loss: 1.9585178436771515

Epoch: 5| Step: 2
Training loss: 1.6577732563018799
Validation loss: 1.942139660158465

Epoch: 5| Step: 3
Training loss: 1.3287017345428467
Validation loss: 1.9532861824958556

Epoch: 5| Step: 4
Training loss: 1.5955826044082642
Validation loss: 1.9573403276422972

Epoch: 5| Step: 5
Training loss: 1.8457578420639038
Validation loss: 1.9564531336548507

Epoch: 5| Step: 6
Training loss: 1.193647861480713
Validation loss: 1.9618843242686281

Epoch: 5| Step: 7
Training loss: 1.5405460596084595
Validation loss: 1.9576693952724498

Epoch: 5| Step: 8
Training loss: 2.158298969268799
Validation loss: 1.9583358226283905

Epoch: 5| Step: 9
Training loss: 1.8896949291229248
Validation loss: 1.9508280215724823

Epoch: 5| Step: 10
Training loss: 0.9470157623291016
Validation loss: 1.9470955838439286

Epoch: 224| Step: 0
Training loss: 1.431110143661499
Validation loss: 1.9647936282619354

Epoch: 5| Step: 1
Training loss: 1.5345075130462646
Validation loss: 1.973711427821908

Epoch: 5| Step: 2
Training loss: 1.1142854690551758
Validation loss: 1.989566199241146

Epoch: 5| Step: 3
Training loss: 1.6497962474822998
Validation loss: 1.9969330654349378

Epoch: 5| Step: 4
Training loss: 1.1960136890411377
Validation loss: 2.050594492625165

Epoch: 5| Step: 5
Training loss: 1.6611807346343994
Validation loss: 2.0352621616855746

Epoch: 5| Step: 6
Training loss: 1.9177007675170898
Validation loss: 2.0322945656314975

Epoch: 5| Step: 7
Training loss: 1.3017451763153076
Validation loss: 2.018759854378239

Epoch: 5| Step: 8
Training loss: 2.1000237464904785
Validation loss: 2.000422182903495

Epoch: 5| Step: 9
Training loss: 2.0960259437561035
Validation loss: 1.966754513402139

Epoch: 5| Step: 10
Training loss: 1.9507168531417847
Validation loss: 1.9648733651766213

Epoch: 225| Step: 0
Training loss: 1.806490182876587
Validation loss: 1.9700581360888738

Epoch: 5| Step: 1
Training loss: 1.3044639825820923
Validation loss: 1.976648510143321

Epoch: 5| Step: 2
Training loss: 1.7405750751495361
Validation loss: 1.9733596130083966

Epoch: 5| Step: 3
Training loss: 2.0698747634887695
Validation loss: 1.9938768238149664

Epoch: 5| Step: 4
Training loss: 1.3294503688812256
Validation loss: 1.9842853981961486

Epoch: 5| Step: 5
Training loss: 1.713120698928833
Validation loss: 1.9938654963688185

Epoch: 5| Step: 6
Training loss: 1.7702386379241943
Validation loss: 1.997551784720472

Epoch: 5| Step: 7
Training loss: 1.330981731414795
Validation loss: 1.9628870717940792

Epoch: 5| Step: 8
Training loss: 1.9797385931015015
Validation loss: 1.9592896507632347

Epoch: 5| Step: 9
Training loss: 0.9385393261909485
Validation loss: 1.9686941062250445

Epoch: 5| Step: 10
Training loss: 2.1767821311950684
Validation loss: 1.9740850310171805

Epoch: 226| Step: 0
Training loss: 1.0775139331817627
Validation loss: 1.9853103199312765

Epoch: 5| Step: 1
Training loss: 1.8536834716796875
Validation loss: 1.9571223553790842

Epoch: 5| Step: 2
Training loss: 1.8853000402450562
Validation loss: 1.9650516843283048

Epoch: 5| Step: 3
Training loss: 2.525456428527832
Validation loss: 1.966659447198273

Epoch: 5| Step: 4
Training loss: 1.920454978942871
Validation loss: 1.9668956213099982

Epoch: 5| Step: 5
Training loss: 1.5098549127578735
Validation loss: 1.9705069347094464

Epoch: 5| Step: 6
Training loss: 1.1996976137161255
Validation loss: 1.9652333772310646

Epoch: 5| Step: 7
Training loss: 0.8803409337997437
Validation loss: 1.9651317275980467

Epoch: 5| Step: 8
Training loss: 1.8212295770645142
Validation loss: 1.9708217292703607

Epoch: 5| Step: 9
Training loss: 0.9432601928710938
Validation loss: 1.9801656661495086

Epoch: 5| Step: 10
Training loss: 1.8164900541305542
Validation loss: 1.981504556953266

Epoch: 227| Step: 0
Training loss: 1.770525574684143
Validation loss: 2.0040229661490327

Epoch: 5| Step: 1
Training loss: 1.4580518007278442
Validation loss: 2.007698756392284

Epoch: 5| Step: 2
Training loss: 1.22968590259552
Validation loss: 1.9948966797961984

Epoch: 5| Step: 3
Training loss: 1.4051060676574707
Validation loss: 1.9699410764119958

Epoch: 5| Step: 4
Training loss: 1.2260797023773193
Validation loss: 1.9506629564428841

Epoch: 5| Step: 5
Training loss: 2.2213969230651855
Validation loss: 1.942347607304973

Epoch: 5| Step: 6
Training loss: 1.850292444229126
Validation loss: 1.956337304525478

Epoch: 5| Step: 7
Training loss: 1.8688862323760986
Validation loss: 1.950637585373335

Epoch: 5| Step: 8
Training loss: 1.063045859336853
Validation loss: 1.9677398204803467

Epoch: 5| Step: 9
Training loss: 1.7354075908660889
Validation loss: 1.959561139024714

Epoch: 5| Step: 10
Training loss: 1.4739161729812622
Validation loss: 1.9749022824789888

Epoch: 228| Step: 0
Training loss: 1.3560857772827148
Validation loss: 1.9956518014272053

Epoch: 5| Step: 1
Training loss: 1.9858137369155884
Validation loss: 2.009224607098487

Epoch: 5| Step: 2
Training loss: 1.2101517915725708
Validation loss: 2.01547210959978

Epoch: 5| Step: 3
Training loss: 1.8918451070785522
Validation loss: 2.0078526248214064

Epoch: 5| Step: 4
Training loss: 0.8522712588310242
Validation loss: 2.000356048666021

Epoch: 5| Step: 5
Training loss: 1.4929478168487549
Validation loss: 2.010211626688639

Epoch: 5| Step: 6
Training loss: 1.7982383966445923
Validation loss: 2.0325359426518923

Epoch: 5| Step: 7
Training loss: 1.7335741519927979
Validation loss: 2.0356354251984627

Epoch: 5| Step: 8
Training loss: 1.9737014770507812
Validation loss: 2.013244621215328

Epoch: 5| Step: 9
Training loss: 1.5470715761184692
Validation loss: 1.9751877579637753

Epoch: 5| Step: 10
Training loss: 1.5408532619476318
Validation loss: 1.965484029503279

Epoch: 229| Step: 0
Training loss: 1.180931568145752
Validation loss: 1.9461108843485515

Epoch: 5| Step: 1
Training loss: 1.8555206060409546
Validation loss: 1.9448105340362878

Epoch: 5| Step: 2
Training loss: 1.4004560708999634
Validation loss: 1.936128778483278

Epoch: 5| Step: 3
Training loss: 1.7009811401367188
Validation loss: 1.9310440965878066

Epoch: 5| Step: 4
Training loss: 1.3352370262145996
Validation loss: 1.9295679766644713

Epoch: 5| Step: 5
Training loss: 2.046417236328125
Validation loss: 1.952850555860868

Epoch: 5| Step: 6
Training loss: 1.8686647415161133
Validation loss: 1.9718694302343553

Epoch: 5| Step: 7
Training loss: 1.508018970489502
Validation loss: 2.0009035769329278

Epoch: 5| Step: 8
Training loss: 1.821433424949646
Validation loss: 2.008758542358234

Epoch: 5| Step: 9
Training loss: 1.2122820615768433
Validation loss: 1.9961260262356009

Epoch: 5| Step: 10
Training loss: 1.3052482604980469
Validation loss: 2.0080925674848658

Epoch: 230| Step: 0
Training loss: 1.7860403060913086
Validation loss: 2.0312815558525825

Epoch: 5| Step: 1
Training loss: 1.6906903982162476
Validation loss: 2.041955199292911

Epoch: 5| Step: 2
Training loss: 1.9752604961395264
Validation loss: 2.0380630313709216

Epoch: 5| Step: 3
Training loss: 1.301337480545044
Validation loss: 2.026049751107411

Epoch: 5| Step: 4
Training loss: 1.619572639465332
Validation loss: 2.033556044742625

Epoch: 5| Step: 5
Training loss: 1.9602077007293701
Validation loss: 2.0281750053487797

Epoch: 5| Step: 6
Training loss: 0.8382472991943359
Validation loss: 2.005177649118567

Epoch: 5| Step: 7
Training loss: 1.3769975900650024
Validation loss: 1.995563901880736

Epoch: 5| Step: 8
Training loss: 1.3484327793121338
Validation loss: 1.990831018776022

Epoch: 5| Step: 9
Training loss: 1.8368812799453735
Validation loss: 1.9749881811039423

Epoch: 5| Step: 10
Training loss: 1.5683565139770508
Validation loss: 1.9586417739109327

Epoch: 231| Step: 0
Training loss: 1.9895524978637695
Validation loss: 1.9679410816520773

Epoch: 5| Step: 1
Training loss: 1.530954360961914
Validation loss: 1.9636859663071171

Epoch: 5| Step: 2
Training loss: 1.2744061946868896
Validation loss: 1.9553628224198536

Epoch: 5| Step: 3
Training loss: 1.3408305644989014
Validation loss: 1.9455780906061972

Epoch: 5| Step: 4
Training loss: 1.4302836656570435
Validation loss: 1.9369763020546205

Epoch: 5| Step: 5
Training loss: 1.3260613679885864
Validation loss: 1.9450777333269837

Epoch: 5| Step: 6
Training loss: 1.6970880031585693
Validation loss: 1.9560938189106603

Epoch: 5| Step: 7
Training loss: 1.5612730979919434
Validation loss: 1.9473593055561025

Epoch: 5| Step: 8
Training loss: 1.9819085597991943
Validation loss: 1.9433296534322924

Epoch: 5| Step: 9
Training loss: 1.235647439956665
Validation loss: 1.9594657767203547

Epoch: 5| Step: 10
Training loss: 1.5106431245803833
Validation loss: 1.9671733981819564

Epoch: 232| Step: 0
Training loss: 1.2350727319717407
Validation loss: 1.980153626011264

Epoch: 5| Step: 1
Training loss: 1.3633527755737305
Validation loss: 1.9867332622569094

Epoch: 5| Step: 2
Training loss: 1.2044764757156372
Validation loss: 1.9639684077232116

Epoch: 5| Step: 3
Training loss: 2.029876232147217
Validation loss: 1.9746780780053907

Epoch: 5| Step: 4
Training loss: 1.9585351943969727
Validation loss: 1.959009216677758

Epoch: 5| Step: 5
Training loss: 1.095049500465393
Validation loss: 1.9640095567190519

Epoch: 5| Step: 6
Training loss: 1.848867416381836
Validation loss: 1.9601844126178372

Epoch: 5| Step: 7
Training loss: 1.4722763299942017
Validation loss: 1.9672956902493712

Epoch: 5| Step: 8
Training loss: 0.9788997769355774
Validation loss: 1.9659495930517874

Epoch: 5| Step: 9
Training loss: 1.768589735031128
Validation loss: 1.9927715563005017

Epoch: 5| Step: 10
Training loss: 1.6623536348342896
Validation loss: 1.9820862393225394

Epoch: 233| Step: 0
Training loss: 1.412484884262085
Validation loss: 1.9881489481977237

Epoch: 5| Step: 1
Training loss: 1.1138105392456055
Validation loss: 1.9565029246832735

Epoch: 5| Step: 2
Training loss: 1.1955769062042236
Validation loss: 1.9681208569516417

Epoch: 5| Step: 3
Training loss: 1.9212201833724976
Validation loss: 1.9513788941085979

Epoch: 5| Step: 4
Training loss: 1.4967072010040283
Validation loss: 1.9391911004179267

Epoch: 5| Step: 5
Training loss: 1.3221032619476318
Validation loss: 1.9293197508781188

Epoch: 5| Step: 6
Training loss: 1.5336507558822632
Validation loss: 1.9185579720363821

Epoch: 5| Step: 7
Training loss: 1.7243764400482178
Validation loss: 1.9198345240726267

Epoch: 5| Step: 8
Training loss: 1.4777463674545288
Validation loss: 1.9236237656685613

Epoch: 5| Step: 9
Training loss: 1.7893002033233643
Validation loss: 1.9275149017251947

Epoch: 5| Step: 10
Training loss: 1.646429181098938
Validation loss: 1.9385106435386084

Epoch: 234| Step: 0
Training loss: 1.4901014566421509
Validation loss: 1.9491430533829557

Epoch: 5| Step: 1
Training loss: 1.7642147541046143
Validation loss: 2.0126221897781535

Epoch: 5| Step: 2
Training loss: 1.3793652057647705
Validation loss: 2.000784756034933

Epoch: 5| Step: 3
Training loss: 1.1858713626861572
Validation loss: 1.9829868539687125

Epoch: 5| Step: 4
Training loss: 1.464249849319458
Validation loss: 1.9942874959720078

Epoch: 5| Step: 5
Training loss: 1.7419360876083374
Validation loss: 2.003623944456859

Epoch: 5| Step: 6
Training loss: 1.23794686794281
Validation loss: 2.0129963044197328

Epoch: 5| Step: 7
Training loss: 1.7595901489257812
Validation loss: 2.019630143719335

Epoch: 5| Step: 8
Training loss: 1.421201467514038
Validation loss: 1.9952968269266107

Epoch: 5| Step: 9
Training loss: 1.6163749694824219
Validation loss: 1.984870236407044

Epoch: 5| Step: 10
Training loss: 1.7402422428131104
Validation loss: 1.960048088463404

Epoch: 235| Step: 0
Training loss: 1.2955175638198853
Validation loss: 1.971009426219489

Epoch: 5| Step: 1
Training loss: 1.5012311935424805
Validation loss: 1.9563155430619434

Epoch: 5| Step: 2
Training loss: 1.801903486251831
Validation loss: 1.9239234514133905

Epoch: 5| Step: 3
Training loss: 1.624132513999939
Validation loss: 1.8982949308169785

Epoch: 5| Step: 4
Training loss: 1.6831012964248657
Validation loss: 1.8945016181597145

Epoch: 5| Step: 5
Training loss: 1.7007052898406982
Validation loss: 1.8778999172231203

Epoch: 5| Step: 6
Training loss: 1.076724886894226
Validation loss: 1.9047102992252638

Epoch: 5| Step: 7
Training loss: 1.8706490993499756
Validation loss: 1.9435251810217415

Epoch: 5| Step: 8
Training loss: 1.7146492004394531
Validation loss: 1.9403770598032142

Epoch: 5| Step: 9
Training loss: 1.1934702396392822
Validation loss: 1.9353352080109298

Epoch: 5| Step: 10
Training loss: 1.4722883701324463
Validation loss: 1.9704874177132883

Epoch: 236| Step: 0
Training loss: 1.212595820426941
Validation loss: 2.0349606531922535

Epoch: 5| Step: 1
Training loss: 1.7543861865997314
Validation loss: 2.0677873780650478

Epoch: 5| Step: 2
Training loss: 1.4911458492279053
Validation loss: 2.0373451248292

Epoch: 5| Step: 3
Training loss: 1.5402857065200806
Validation loss: 2.032408438703065

Epoch: 5| Step: 4
Training loss: 2.0656208992004395
Validation loss: 2.0061763294281496

Epoch: 5| Step: 5
Training loss: 1.4336808919906616
Validation loss: 2.016170049226412

Epoch: 5| Step: 6
Training loss: 1.3481649160385132
Validation loss: 2.0025857187086538

Epoch: 5| Step: 7
Training loss: 1.6872284412384033
Validation loss: 1.992213072315339

Epoch: 5| Step: 8
Training loss: 1.4196175336837769
Validation loss: 1.9999141564933203

Epoch: 5| Step: 9
Training loss: 1.9255802631378174
Validation loss: 1.9686635642923334

Epoch: 5| Step: 10
Training loss: 1.1490538120269775
Validation loss: 1.9760940536375968

Epoch: 237| Step: 0
Training loss: 1.921688437461853
Validation loss: 1.9830057531274774

Epoch: 5| Step: 1
Training loss: 1.434631109237671
Validation loss: 1.9676073469141477

Epoch: 5| Step: 2
Training loss: 2.22468900680542
Validation loss: 1.9695629791546894

Epoch: 5| Step: 3
Training loss: 1.433457612991333
Validation loss: 1.9832751417672763

Epoch: 5| Step: 4
Training loss: 1.3703018426895142
Validation loss: 1.9737576976899178

Epoch: 5| Step: 5
Training loss: 1.5134966373443604
Validation loss: 1.9760294678390666

Epoch: 5| Step: 6
Training loss: 1.8779938220977783
Validation loss: 1.9768247783824962

Epoch: 5| Step: 7
Training loss: 1.301522970199585
Validation loss: 1.9700700134359381

Epoch: 5| Step: 8
Training loss: 0.9549997448921204
Validation loss: 1.9729172388712566

Epoch: 5| Step: 9
Training loss: 1.450683355331421
Validation loss: 1.9466564040030203

Epoch: 5| Step: 10
Training loss: 0.5895618796348572
Validation loss: 1.9774584103656072

Epoch: 238| Step: 0
Training loss: 1.5357030630111694
Validation loss: 1.9751485522075365

Epoch: 5| Step: 1
Training loss: 1.806936264038086
Validation loss: 1.9972505672003633

Epoch: 5| Step: 2
Training loss: 1.6314557790756226
Validation loss: 1.987094771477484

Epoch: 5| Step: 3
Training loss: 1.1560596227645874
Validation loss: 1.9724007832106722

Epoch: 5| Step: 4
Training loss: 1.5517683029174805
Validation loss: 2.0046440196293656

Epoch: 5| Step: 5
Training loss: 1.8683929443359375
Validation loss: 2.032589543250299

Epoch: 5| Step: 6
Training loss: 1.4101953506469727
Validation loss: 2.0234921465637865

Epoch: 5| Step: 7
Training loss: 1.2381325960159302
Validation loss: 2.001377805586784

Epoch: 5| Step: 8
Training loss: 1.0265367031097412
Validation loss: 1.9818037145881242

Epoch: 5| Step: 9
Training loss: 1.5274114608764648
Validation loss: 2.0052565964319373

Epoch: 5| Step: 10
Training loss: 1.561779260635376
Validation loss: 2.013022853482154

Epoch: 239| Step: 0
Training loss: 1.533997893333435
Validation loss: 2.006170524063931

Epoch: 5| Step: 1
Training loss: 1.3968613147735596
Validation loss: 1.9836290626115696

Epoch: 5| Step: 2
Training loss: 1.6905527114868164
Validation loss: 1.9942791808036067

Epoch: 5| Step: 3
Training loss: 1.4926903247833252
Validation loss: 1.9573506001503236

Epoch: 5| Step: 4
Training loss: 1.7200591564178467
Validation loss: 1.9428632361914522

Epoch: 5| Step: 5
Training loss: 1.164098858833313
Validation loss: 1.9209402299696399

Epoch: 5| Step: 6
Training loss: 1.598639726638794
Validation loss: 1.9244101278243526

Epoch: 5| Step: 7
Training loss: 1.770179033279419
Validation loss: 1.945881861512379

Epoch: 5| Step: 8
Training loss: 1.7647464275360107
Validation loss: 1.9828641914552259

Epoch: 5| Step: 9
Training loss: 1.1558927297592163
Validation loss: 2.0441366652006745

Epoch: 5| Step: 10
Training loss: 1.359152913093567
Validation loss: 2.041462814936074

Epoch: 240| Step: 0
Training loss: 1.800366759300232
Validation loss: 2.0270461856677966

Epoch: 5| Step: 1
Training loss: 1.518336296081543
Validation loss: 2.017434209905645

Epoch: 5| Step: 2
Training loss: 1.3598284721374512
Validation loss: 2.027219383947311

Epoch: 5| Step: 3
Training loss: 1.7037242650985718
Validation loss: 2.0215393907280377

Epoch: 5| Step: 4
Training loss: 1.4281607866287231
Validation loss: 1.9996256777035293

Epoch: 5| Step: 5
Training loss: 1.398027777671814
Validation loss: 1.9916241002339188

Epoch: 5| Step: 6
Training loss: 1.6558837890625
Validation loss: 1.9896528708037509

Epoch: 5| Step: 7
Training loss: 1.0509092807769775
Validation loss: 1.9651694240108613

Epoch: 5| Step: 8
Training loss: 1.4906772375106812
Validation loss: 1.956650012282915

Epoch: 5| Step: 9
Training loss: 1.5731136798858643
Validation loss: 1.9300760171746696

Epoch: 5| Step: 10
Training loss: 1.1310241222381592
Validation loss: 1.9401383681963849

Epoch: 241| Step: 0
Training loss: 1.506786584854126
Validation loss: 1.9392718089524137

Epoch: 5| Step: 1
Training loss: 1.5823487043380737
Validation loss: 1.925738162891839

Epoch: 5| Step: 2
Training loss: 1.7480452060699463
Validation loss: 1.940172977344964

Epoch: 5| Step: 3
Training loss: 1.410657525062561
Validation loss: 1.9436644764356716

Epoch: 5| Step: 4
Training loss: 1.0948420763015747
Validation loss: 1.9389518563465407

Epoch: 5| Step: 5
Training loss: 1.5221564769744873
Validation loss: 1.9443652578579482

Epoch: 5| Step: 6
Training loss: 1.7967398166656494
Validation loss: 1.9308148173875705

Epoch: 5| Step: 7
Training loss: 0.7241438627243042
Validation loss: 1.921295391616001

Epoch: 5| Step: 8
Training loss: 1.2941007614135742
Validation loss: 1.9443633223092684

Epoch: 5| Step: 9
Training loss: 1.4281446933746338
Validation loss: 1.944416397361345

Epoch: 5| Step: 10
Training loss: 1.6930222511291504
Validation loss: 1.9799303085573259

Epoch: 242| Step: 0
Training loss: 1.7430706024169922
Validation loss: 1.974617963196129

Epoch: 5| Step: 1
Training loss: 1.2946313619613647
Validation loss: 1.9689953378451768

Epoch: 5| Step: 2
Training loss: 1.4158148765563965
Validation loss: 1.9825406587252052

Epoch: 5| Step: 3
Training loss: 1.4185447692871094
Validation loss: 1.9705816789339947

Epoch: 5| Step: 4
Training loss: 1.0855894088745117
Validation loss: 1.970813464092952

Epoch: 5| Step: 5
Training loss: 0.8093608021736145
Validation loss: 1.9798887519426243

Epoch: 5| Step: 6
Training loss: 1.4979395866394043
Validation loss: 1.9834036801450996

Epoch: 5| Step: 7
Training loss: 1.7495511770248413
Validation loss: 1.9917397088901971

Epoch: 5| Step: 8
Training loss: 1.5374672412872314
Validation loss: 1.9735398779633224

Epoch: 5| Step: 9
Training loss: 1.6504684686660767
Validation loss: 1.9718498940108924

Epoch: 5| Step: 10
Training loss: 1.4258463382720947
Validation loss: 1.9782676222503826

Epoch: 243| Step: 0
Training loss: 1.2619473934173584
Validation loss: 1.992923064898419

Epoch: 5| Step: 1
Training loss: 1.4598557949066162
Validation loss: 1.9652724996689828

Epoch: 5| Step: 2
Training loss: 1.3422253131866455
Validation loss: 1.9438926327613093

Epoch: 5| Step: 3
Training loss: 1.5784529447555542
Validation loss: 1.9190965339701662

Epoch: 5| Step: 4
Training loss: 1.1012794971466064
Validation loss: 1.9045816518927132

Epoch: 5| Step: 5
Training loss: 2.2221102714538574
Validation loss: 1.8972097904451433

Epoch: 5| Step: 6
Training loss: 1.4993562698364258
Validation loss: 1.8915911284826135

Epoch: 5| Step: 7
Training loss: 1.633856177330017
Validation loss: 1.9066524736342891

Epoch: 5| Step: 8
Training loss: 1.200743556022644
Validation loss: 1.903012429514239

Epoch: 5| Step: 9
Training loss: 1.443385362625122
Validation loss: 1.9196387593464186

Epoch: 5| Step: 10
Training loss: 0.9460532069206238
Validation loss: 1.9352713887409498

Epoch: 244| Step: 0
Training loss: 1.0555521249771118
Validation loss: 1.9810806218013968

Epoch: 5| Step: 1
Training loss: 1.5405712127685547
Validation loss: 2.000596575839545

Epoch: 5| Step: 2
Training loss: 1.9113433361053467
Validation loss: 2.0194424839429956

Epoch: 5| Step: 3
Training loss: 1.7405967712402344
Validation loss: 2.0235099536116405

Epoch: 5| Step: 4
Training loss: 1.0390547513961792
Validation loss: 2.0043383900837233

Epoch: 5| Step: 5
Training loss: 0.7670845985412598
Validation loss: 1.9548593439081663

Epoch: 5| Step: 6
Training loss: 1.520119309425354
Validation loss: 1.9811587500315841

Epoch: 5| Step: 7
Training loss: 1.1215084791183472
Validation loss: 1.9533156400085778

Epoch: 5| Step: 8
Training loss: 1.4930354356765747
Validation loss: 1.9500200825352823

Epoch: 5| Step: 9
Training loss: 2.088552951812744
Validation loss: 1.9557928590364353

Epoch: 5| Step: 10
Training loss: 0.9001012444496155
Validation loss: 1.9702822187895417

Epoch: 245| Step: 0
Training loss: 1.476878046989441
Validation loss: 1.9884211350512762

Epoch: 5| Step: 1
Training loss: 0.9610365033149719
Validation loss: 2.0031143952441472

Epoch: 5| Step: 2
Training loss: 1.4518966674804688
Validation loss: 2.0147131258441555

Epoch: 5| Step: 3
Training loss: 1.1353099346160889
Validation loss: 2.0120272251867477

Epoch: 5| Step: 4
Training loss: 1.2395203113555908
Validation loss: 2.001055737977387

Epoch: 5| Step: 5
Training loss: 1.579928994178772
Validation loss: 1.9714138777025285

Epoch: 5| Step: 6
Training loss: 1.2497936487197876
Validation loss: 1.9129113894636913

Epoch: 5| Step: 7
Training loss: 1.7145658731460571
Validation loss: 1.8795150454326341

Epoch: 5| Step: 8
Training loss: 2.2361857891082764
Validation loss: 1.887645839363016

Epoch: 5| Step: 9
Training loss: 1.5681023597717285
Validation loss: 1.8714043171175065

Epoch: 5| Step: 10
Training loss: 0.5887889862060547
Validation loss: 1.8953690400687597

Epoch: 246| Step: 0
Training loss: 1.0776411294937134
Validation loss: 1.8848686474625782

Epoch: 5| Step: 1
Training loss: 1.569761037826538
Validation loss: 1.9053866709432294

Epoch: 5| Step: 2
Training loss: 1.206266164779663
Validation loss: 1.9194764603850663

Epoch: 5| Step: 3
Training loss: 1.3563029766082764
Validation loss: 1.9512336241301669

Epoch: 5| Step: 4
Training loss: 1.1945146322250366
Validation loss: 2.007446014752952

Epoch: 5| Step: 5
Training loss: 0.7864426374435425
Validation loss: 2.0490941565523864

Epoch: 5| Step: 6
Training loss: 1.7474943399429321
Validation loss: 2.083110172261474

Epoch: 5| Step: 7
Training loss: 1.2648662328720093
Validation loss: 2.040973248020295

Epoch: 5| Step: 8
Training loss: 1.7132011651992798
Validation loss: 2.0232577375186387

Epoch: 5| Step: 9
Training loss: 1.5706124305725098
Validation loss: 1.983577295016217

Epoch: 5| Step: 10
Training loss: 1.8221352100372314
Validation loss: 1.9507855792199411

Epoch: 247| Step: 0
Training loss: 1.166865587234497
Validation loss: 1.9400976883467806

Epoch: 5| Step: 1
Training loss: 1.8033664226531982
Validation loss: 1.8997152595109836

Epoch: 5| Step: 2
Training loss: 1.093015432357788
Validation loss: 1.8938937725559357

Epoch: 5| Step: 3
Training loss: 1.3078558444976807
Validation loss: 1.8827291560429398

Epoch: 5| Step: 4
Training loss: 1.1269919872283936
Validation loss: 1.8810824066080072

Epoch: 5| Step: 5
Training loss: 1.402051329612732
Validation loss: 1.905699860665106

Epoch: 5| Step: 6
Training loss: 1.0505797863006592
Validation loss: 1.9213179157626243

Epoch: 5| Step: 7
Training loss: 1.7065035104751587
Validation loss: 1.9058242408178185

Epoch: 5| Step: 8
Training loss: 1.506683111190796
Validation loss: 1.8883305621403519

Epoch: 5| Step: 9
Training loss: 1.4756035804748535
Validation loss: 1.8906705328213271

Epoch: 5| Step: 10
Training loss: 1.4006624221801758
Validation loss: 1.891205632558433

Epoch: 248| Step: 0
Training loss: 1.4441425800323486
Validation loss: 1.8954804148725284

Epoch: 5| Step: 1
Training loss: 1.0696494579315186
Validation loss: 1.915471766584663

Epoch: 5| Step: 2
Training loss: 1.2347158193588257
Validation loss: 1.9265771501807756

Epoch: 5| Step: 3
Training loss: 1.3705857992172241
Validation loss: 1.9368919698140954

Epoch: 5| Step: 4
Training loss: 1.0367488861083984
Validation loss: 1.9371269646511282

Epoch: 5| Step: 5
Training loss: 1.454182505607605
Validation loss: 1.9859821988690285

Epoch: 5| Step: 6
Training loss: 2.1846256256103516
Validation loss: 1.9588693982811385

Epoch: 5| Step: 7
Training loss: 1.2768805027008057
Validation loss: 1.9620583877768567

Epoch: 5| Step: 8
Training loss: 1.2923710346221924
Validation loss: 1.9900716889289118

Epoch: 5| Step: 9
Training loss: 1.1173378229141235
Validation loss: 1.9859019069261448

Epoch: 5| Step: 10
Training loss: 1.0000699758529663
Validation loss: 1.953936561461418

Epoch: 249| Step: 0
Training loss: 1.6037346124649048
Validation loss: 1.931317707543732

Epoch: 5| Step: 1
Training loss: 0.9488040804862976
Validation loss: 1.9234889297075168

Epoch: 5| Step: 2
Training loss: 1.2289537191390991
Validation loss: 1.9046380212230067

Epoch: 5| Step: 3
Training loss: 1.4689947366714478
Validation loss: 1.9026389416827951

Epoch: 5| Step: 4
Training loss: 1.330669641494751
Validation loss: 1.9083362830582487

Epoch: 5| Step: 5
Training loss: 1.3264496326446533
Validation loss: 1.9241147554048927

Epoch: 5| Step: 6
Training loss: 1.2978668212890625
Validation loss: 1.964254884309666

Epoch: 5| Step: 7
Training loss: 1.6241092681884766
Validation loss: 1.963614704788372

Epoch: 5| Step: 8
Training loss: 0.8982513546943665
Validation loss: 1.9729073227092784

Epoch: 5| Step: 9
Training loss: 1.862951636314392
Validation loss: 1.9803007930837653

Epoch: 5| Step: 10
Training loss: 1.0585980415344238
Validation loss: 1.9698168590504637

Epoch: 250| Step: 0
Training loss: 1.5415825843811035
Validation loss: 1.9192928960246425

Epoch: 5| Step: 1
Training loss: 1.2321593761444092
Validation loss: 1.9108674103213894

Epoch: 5| Step: 2
Training loss: 1.2224528789520264
Validation loss: 1.9016535615408292

Epoch: 5| Step: 3
Training loss: 1.6418529748916626
Validation loss: 1.8948500156402588

Epoch: 5| Step: 4
Training loss: 1.4102389812469482
Validation loss: 1.8785831569343485

Epoch: 5| Step: 5
Training loss: 1.1975904703140259
Validation loss: 1.8931183302274315

Epoch: 5| Step: 6
Training loss: 1.0381392240524292
Validation loss: 1.9063288345131824

Epoch: 5| Step: 7
Training loss: 1.6187206506729126
Validation loss: 1.9212066768318095

Epoch: 5| Step: 8
Training loss: 1.1895294189453125
Validation loss: 1.9112357477987967

Epoch: 5| Step: 9
Training loss: 1.3120949268341064
Validation loss: 1.911062232909664

Epoch: 5| Step: 10
Training loss: 1.235813021659851
Validation loss: 1.9331389140057307

Epoch: 251| Step: 0
Training loss: 1.3199533224105835
Validation loss: 1.9482787539882045

Epoch: 5| Step: 1
Training loss: 1.2667454481124878
Validation loss: 1.9432019495194959

Epoch: 5| Step: 2
Training loss: 1.0435434579849243
Validation loss: 1.9329232400463474

Epoch: 5| Step: 3
Training loss: 1.501800298690796
Validation loss: 1.9325708368773102

Epoch: 5| Step: 4
Training loss: 1.3364965915679932
Validation loss: 1.9368186586646623

Epoch: 5| Step: 5
Training loss: 1.220384955406189
Validation loss: 1.9224149565542898

Epoch: 5| Step: 6
Training loss: 1.2728875875473022
Validation loss: 1.9290259435612669

Epoch: 5| Step: 7
Training loss: 1.7499557733535767
Validation loss: 1.9703925501915716

Epoch: 5| Step: 8
Training loss: 1.569214105606079
Validation loss: 1.9819229623322845

Epoch: 5| Step: 9
Training loss: 1.381271243095398
Validation loss: 1.9590137068943312

Epoch: 5| Step: 10
Training loss: 0.9251793622970581
Validation loss: 1.9423537587606778

Epoch: 252| Step: 0
Training loss: 1.4599566459655762
Validation loss: 1.9405746242051483

Epoch: 5| Step: 1
Training loss: 1.2704143524169922
Validation loss: 1.951446610112344

Epoch: 5| Step: 2
Training loss: 1.4941294193267822
Validation loss: 1.9506632948434481

Epoch: 5| Step: 3
Training loss: 1.4673562049865723
Validation loss: 1.9559570717555221

Epoch: 5| Step: 4
Training loss: 1.593761682510376
Validation loss: 1.9175347512768162

Epoch: 5| Step: 5
Training loss: 0.9507915377616882
Validation loss: 1.8757651044476418

Epoch: 5| Step: 6
Training loss: 1.856911063194275
Validation loss: 1.8662009162287558

Epoch: 5| Step: 7
Training loss: 1.200478434562683
Validation loss: 1.87243010920863

Epoch: 5| Step: 8
Training loss: 1.010810136795044
Validation loss: 1.8923894833492976

Epoch: 5| Step: 9
Training loss: 0.8150174021720886
Validation loss: 1.905535759464387

Epoch: 5| Step: 10
Training loss: 1.0049874782562256
Validation loss: 1.8933398287783387

Epoch: 253| Step: 0
Training loss: 1.2081010341644287
Validation loss: 1.9041419849600842

Epoch: 5| Step: 1
Training loss: 1.129870057106018
Validation loss: 1.8928343198632682

Epoch: 5| Step: 2
Training loss: 1.091365933418274
Validation loss: 1.8838801358335762

Epoch: 5| Step: 3
Training loss: 0.8879758715629578
Validation loss: 1.922101628395819

Epoch: 5| Step: 4
Training loss: 1.6781514883041382
Validation loss: 1.895839197661287

Epoch: 5| Step: 5
Training loss: 1.6326099634170532
Validation loss: 1.9080012472726966

Epoch: 5| Step: 6
Training loss: 1.2828322649002075
Validation loss: 1.9111544496269637

Epoch: 5| Step: 7
Training loss: 1.1527985334396362
Validation loss: 1.916834686392097

Epoch: 5| Step: 8
Training loss: 1.5293853282928467
Validation loss: 1.9295147772758239

Epoch: 5| Step: 9
Training loss: 1.3225452899932861
Validation loss: 1.9383046832135928

Epoch: 5| Step: 10
Training loss: 0.9487805366516113
Validation loss: 1.9408133645211496

Epoch: 254| Step: 0
Training loss: 1.8889472484588623
Validation loss: 1.9480850952927784

Epoch: 5| Step: 1
Training loss: 1.515831708908081
Validation loss: 1.9335749764596262

Epoch: 5| Step: 2
Training loss: 2.076355218887329
Validation loss: 1.9362949517465406

Epoch: 5| Step: 3
Training loss: 1.031355619430542
Validation loss: 1.9283682351471276

Epoch: 5| Step: 4
Training loss: 0.9219123721122742
Validation loss: 1.9204210914591306

Epoch: 5| Step: 5
Training loss: 1.555860161781311
Validation loss: 1.8818198083549418

Epoch: 5| Step: 6
Training loss: 0.7854418754577637
Validation loss: 1.8719119500088435

Epoch: 5| Step: 7
Training loss: 1.1926332712173462
Validation loss: 1.8528111275806223

Epoch: 5| Step: 8
Training loss: 0.9344518780708313
Validation loss: 1.8911977878180883

Epoch: 5| Step: 9
Training loss: 1.022545576095581
Validation loss: 1.8949620005904988

Epoch: 5| Step: 10
Training loss: 1.1738481521606445
Validation loss: 1.8968417362500263

Epoch: 255| Step: 0
Training loss: 1.2155027389526367
Validation loss: 1.9148781184227235

Epoch: 5| Step: 1
Training loss: 1.029193639755249
Validation loss: 1.920748902905372

Epoch: 5| Step: 2
Training loss: 1.3915398120880127
Validation loss: 1.9356922065058062

Epoch: 5| Step: 3
Training loss: 0.9798925518989563
Validation loss: 1.9469880980830039

Epoch: 5| Step: 4
Training loss: 1.0350885391235352
Validation loss: 1.972687126487814

Epoch: 5| Step: 5
Training loss: 1.4205906391143799
Validation loss: 1.9751658824182325

Epoch: 5| Step: 6
Training loss: 1.6448891162872314
Validation loss: 1.9678224248270835

Epoch: 5| Step: 7
Training loss: 1.4358030557632446
Validation loss: 1.9665239344361007

Epoch: 5| Step: 8
Training loss: 1.0189054012298584
Validation loss: 1.9386383064331547

Epoch: 5| Step: 9
Training loss: 1.051421880722046
Validation loss: 1.8962537652702742

Epoch: 5| Step: 10
Training loss: 1.6705756187438965
Validation loss: 1.8623627231967064

Epoch: 256| Step: 0
Training loss: 1.3599467277526855
Validation loss: 1.8604094853965185

Epoch: 5| Step: 1
Training loss: 0.6148250699043274
Validation loss: 1.8760415892447195

Epoch: 5| Step: 2
Training loss: 1.0669379234313965
Validation loss: 1.9033831293864916

Epoch: 5| Step: 3
Training loss: 1.7633371353149414
Validation loss: 1.9348107640461256

Epoch: 5| Step: 4
Training loss: 0.9830031394958496
Validation loss: 1.915355279881467

Epoch: 5| Step: 5
Training loss: 1.6092889308929443
Validation loss: 1.9424638261077225

Epoch: 5| Step: 6
Training loss: 1.1490278244018555
Validation loss: 1.9335954676392257

Epoch: 5| Step: 7
Training loss: 1.5796191692352295
Validation loss: 1.9137703026494672

Epoch: 5| Step: 8
Training loss: 1.154367208480835
Validation loss: 1.913644818849461

Epoch: 5| Step: 9
Training loss: 1.2913013696670532
Validation loss: 1.9175875802193918

Epoch: 5| Step: 10
Training loss: 1.2076690196990967
Validation loss: 1.912712574005127

Epoch: 257| Step: 0
Training loss: 1.4519426822662354
Validation loss: 1.9095735549926758

Epoch: 5| Step: 1
Training loss: 1.3949512243270874
Validation loss: 1.9030156648287209

Epoch: 5| Step: 2
Training loss: 1.337937831878662
Validation loss: 1.9319086074829102

Epoch: 5| Step: 3
Training loss: 1.03167724609375
Validation loss: 1.9502488695165163

Epoch: 5| Step: 4
Training loss: 1.5536435842514038
Validation loss: 1.9668931140694568

Epoch: 5| Step: 5
Training loss: 1.2071805000305176
Validation loss: 1.9710205190925187

Epoch: 5| Step: 6
Training loss: 0.8239644169807434
Validation loss: 1.9250014289732902

Epoch: 5| Step: 7
Training loss: 1.2400394678115845
Validation loss: 1.8990890287583875

Epoch: 5| Step: 8
Training loss: 1.0026865005493164
Validation loss: 1.8986562836554743

Epoch: 5| Step: 9
Training loss: 1.2312555313110352
Validation loss: 1.8840300934289091

Epoch: 5| Step: 10
Training loss: 1.152966856956482
Validation loss: 1.8615796271190848

Epoch: 258| Step: 0
Training loss: 1.6133019924163818
Validation loss: 1.8934734995647142

Epoch: 5| Step: 1
Training loss: 1.4628416299819946
Validation loss: 1.9041381318082091

Epoch: 5| Step: 2
Training loss: 1.2728890180587769
Validation loss: 1.9247078498204548

Epoch: 5| Step: 3
Training loss: 1.033882737159729
Validation loss: 1.9260654475099297

Epoch: 5| Step: 4
Training loss: 1.5598371028900146
Validation loss: 1.9238844866393714

Epoch: 5| Step: 5
Training loss: 1.3764539957046509
Validation loss: 1.9185315383377897

Epoch: 5| Step: 6
Training loss: 1.3462599515914917
Validation loss: 1.9244233895373601

Epoch: 5| Step: 7
Training loss: 0.8874363899230957
Validation loss: 1.943122975287899

Epoch: 5| Step: 8
Training loss: 1.0698316097259521
Validation loss: 1.9264610223872687

Epoch: 5| Step: 9
Training loss: 1.1848665475845337
Validation loss: 1.9169777401031987

Epoch: 5| Step: 10
Training loss: 0.6661098003387451
Validation loss: 1.9272529566159813

Epoch: 259| Step: 0
Training loss: 1.4864842891693115
Validation loss: 1.9168889894280383

Epoch: 5| Step: 1
Training loss: 1.2180074453353882
Validation loss: 1.9073243935902913

Epoch: 5| Step: 2
Training loss: 1.1676467657089233
Validation loss: 1.901864126164426

Epoch: 5| Step: 3
Training loss: 1.9056432247161865
Validation loss: 1.907910221366472

Epoch: 5| Step: 4
Training loss: 1.1837763786315918
Validation loss: 1.8838300910047305

Epoch: 5| Step: 5
Training loss: 0.8749388456344604
Validation loss: 1.8905999993765226

Epoch: 5| Step: 6
Training loss: 0.6336570382118225
Validation loss: 1.8871431453253633

Epoch: 5| Step: 7
Training loss: 1.3695379495620728
Validation loss: 1.9139388376666653

Epoch: 5| Step: 8
Training loss: 1.0616159439086914
Validation loss: 1.9579578112530451

Epoch: 5| Step: 9
Training loss: 0.878501296043396
Validation loss: 1.948797059315507

Epoch: 5| Step: 10
Training loss: 1.3513213396072388
Validation loss: 1.9080969889958699

Epoch: 260| Step: 0
Training loss: 1.0187253952026367
Validation loss: 1.914665570823095

Epoch: 5| Step: 1
Training loss: 1.0001671314239502
Validation loss: 1.8915023342255624

Epoch: 5| Step: 2
Training loss: 1.4229323863983154
Validation loss: 1.8735295136769612

Epoch: 5| Step: 3
Training loss: 1.3988797664642334
Validation loss: 1.882635167849961

Epoch: 5| Step: 4
Training loss: 1.4460337162017822
Validation loss: 1.9008969683800974

Epoch: 5| Step: 5
Training loss: 1.0960628986358643
Validation loss: 1.8711362064525645

Epoch: 5| Step: 6
Training loss: 1.0158179998397827
Validation loss: 1.9019137377380042

Epoch: 5| Step: 7
Training loss: 1.4328500032424927
Validation loss: 1.8718019223982287

Epoch: 5| Step: 8
Training loss: 1.254035472869873
Validation loss: 1.9009925588484733

Epoch: 5| Step: 9
Training loss: 0.8258339166641235
Validation loss: 1.898144575857347

Epoch: 5| Step: 10
Training loss: 0.8242959380149841
Validation loss: 1.8889934375721922

Epoch: 261| Step: 0
Training loss: 1.3546737432479858
Validation loss: 1.9255031924093924

Epoch: 5| Step: 1
Training loss: 1.1139334440231323
Validation loss: 1.894219494635059

Epoch: 5| Step: 2
Training loss: 1.194166660308838
Validation loss: 1.938751051502843

Epoch: 5| Step: 3
Training loss: 0.9197137951850891
Validation loss: 1.9337943882070563

Epoch: 5| Step: 4
Training loss: 1.1088252067565918
Validation loss: 1.9619896206804501

Epoch: 5| Step: 5
Training loss: 1.021085500717163
Validation loss: 1.9270566650616225

Epoch: 5| Step: 6
Training loss: 1.3539197444915771
Validation loss: 1.9531202008647304

Epoch: 5| Step: 7
Training loss: 1.3311353921890259
Validation loss: 1.9303906656080676

Epoch: 5| Step: 8
Training loss: 1.4359863996505737
Validation loss: 1.9396102684800343

Epoch: 5| Step: 9
Training loss: 1.0747140645980835
Validation loss: 1.9083029967482372

Epoch: 5| Step: 10
Training loss: 0.8300385475158691
Validation loss: 1.8845719778409569

Epoch: 262| Step: 0
Training loss: 1.128222107887268
Validation loss: 1.9086823847986036

Epoch: 5| Step: 1
Training loss: 1.2374815940856934
Validation loss: 1.9152487170311712

Epoch: 5| Step: 2
Training loss: 1.2009046077728271
Validation loss: 1.934406756072916

Epoch: 5| Step: 3
Training loss: 1.2533925771713257
Validation loss: 1.935245454952281

Epoch: 5| Step: 4
Training loss: 1.0407530069351196
Validation loss: 1.920456801691363

Epoch: 5| Step: 5
Training loss: 1.1998035907745361
Validation loss: 1.890333547387072

Epoch: 5| Step: 6
Training loss: 0.8117292523384094
Validation loss: 1.8687981764475505

Epoch: 5| Step: 7
Training loss: 1.2737736701965332
Validation loss: 1.8673370320309874

Epoch: 5| Step: 8
Training loss: 1.1306877136230469
Validation loss: 1.8550308635157924

Epoch: 5| Step: 9
Training loss: 1.3571432828903198
Validation loss: 1.8589842806580246

Epoch: 5| Step: 10
Training loss: 1.1761772632598877
Validation loss: 1.8771678606669109

Epoch: 263| Step: 0
Training loss: 1.4464192390441895
Validation loss: 1.9298099804950017

Epoch: 5| Step: 1
Training loss: 1.6117744445800781
Validation loss: 1.9163443080840572

Epoch: 5| Step: 2
Training loss: 1.2265822887420654
Validation loss: 1.8999631994514055

Epoch: 5| Step: 3
Training loss: 0.8179532289505005
Validation loss: 1.9082087432184527

Epoch: 5| Step: 4
Training loss: 0.9095022082328796
Validation loss: 1.918779266777859

Epoch: 5| Step: 5
Training loss: 1.1897237300872803
Validation loss: 1.9209143782174716

Epoch: 5| Step: 6
Training loss: 1.4072625637054443
Validation loss: 1.9645891445939259

Epoch: 5| Step: 7
Training loss: 1.2812929153442383
Validation loss: 1.9802209561870945

Epoch: 5| Step: 8
Training loss: 1.132209062576294
Validation loss: 1.936801169508247

Epoch: 5| Step: 9
Training loss: 1.1745903491973877
Validation loss: 1.944067693525745

Epoch: 5| Step: 10
Training loss: 0.770912230014801
Validation loss: 1.927017588769236

Epoch: 264| Step: 0
Training loss: 0.9743568301200867
Validation loss: 1.906834363937378

Epoch: 5| Step: 1
Training loss: 1.2908378839492798
Validation loss: 1.9398948966815908

Epoch: 5| Step: 2
Training loss: 1.2076210975646973
Validation loss: 1.9470544681754163

Epoch: 5| Step: 3
Training loss: 1.0576272010803223
Validation loss: 1.9488500830947713

Epoch: 5| Step: 4
Training loss: 1.267747163772583
Validation loss: 1.9115915067734257

Epoch: 5| Step: 5
Training loss: 0.9732438921928406
Validation loss: 1.9273950797255321

Epoch: 5| Step: 6
Training loss: 1.4515820741653442
Validation loss: 1.929490848254132

Epoch: 5| Step: 7
Training loss: 1.1920099258422852
Validation loss: 1.8740689728849678

Epoch: 5| Step: 8
Training loss: 1.4573042392730713
Validation loss: 1.8988501935876825

Epoch: 5| Step: 9
Training loss: 1.168805718421936
Validation loss: 1.8791506880073137

Epoch: 5| Step: 10
Training loss: 1.2359784841537476
Validation loss: 1.8615596704585577

Epoch: 265| Step: 0
Training loss: 1.520857810974121
Validation loss: 1.82876040217697

Epoch: 5| Step: 1
Training loss: 0.8563003540039062
Validation loss: 1.8291538505144016

Epoch: 5| Step: 2
Training loss: 0.8402706384658813
Validation loss: 1.805877677855953

Epoch: 5| Step: 3
Training loss: 1.235263466835022
Validation loss: 1.7978004934967204

Epoch: 5| Step: 4
Training loss: 1.2070057392120361
Validation loss: 1.808480260192707

Epoch: 5| Step: 5
Training loss: 1.0203208923339844
Validation loss: 1.8728425630959131

Epoch: 5| Step: 6
Training loss: 1.72834050655365
Validation loss: 1.9033089786447503

Epoch: 5| Step: 7
Training loss: 1.2167415618896484
Validation loss: 1.9215890566507976

Epoch: 5| Step: 8
Training loss: 1.2092845439910889
Validation loss: 1.9334838133986278

Epoch: 5| Step: 9
Training loss: 1.0600842237472534
Validation loss: 1.941327550077951

Epoch: 5| Step: 10
Training loss: 1.3904966115951538
Validation loss: 1.903552427086779

Epoch: 266| Step: 0
Training loss: 0.9921444654464722
Validation loss: 1.9089881553444812

Epoch: 5| Step: 1
Training loss: 1.2511942386627197
Validation loss: 1.8958895206451416

Epoch: 5| Step: 2
Training loss: 1.5266587734222412
Validation loss: 1.8651207980289255

Epoch: 5| Step: 3
Training loss: 1.2546197175979614
Validation loss: 1.891809864710736

Epoch: 5| Step: 4
Training loss: 0.7935158610343933
Validation loss: 1.8684942747956963

Epoch: 5| Step: 5
Training loss: 1.055854082107544
Validation loss: 1.89949300853155

Epoch: 5| Step: 6
Training loss: 0.8300082087516785
Validation loss: 1.8810464400117115

Epoch: 5| Step: 7
Training loss: 1.1598834991455078
Validation loss: 1.9077997553733088

Epoch: 5| Step: 8
Training loss: 1.740918755531311
Validation loss: 1.916354061454855

Epoch: 5| Step: 9
Training loss: 0.9794424772262573
Validation loss: 1.9203897727433072

Epoch: 5| Step: 10
Training loss: 0.9923725128173828
Validation loss: 1.9199580825785154

Epoch: 267| Step: 0
Training loss: 0.8479170799255371
Validation loss: 1.9458746089730212

Epoch: 5| Step: 1
Training loss: 1.0477527379989624
Validation loss: 1.9292946566817581

Epoch: 5| Step: 2
Training loss: 0.9277275204658508
Validation loss: 1.9060707861377346

Epoch: 5| Step: 3
Training loss: 1.0372008085250854
Validation loss: 1.872931395807574

Epoch: 5| Step: 4
Training loss: 1.3647816181182861
Validation loss: 1.8688901855099587

Epoch: 5| Step: 5
Training loss: 1.2404261827468872
Validation loss: 1.8709366026745047

Epoch: 5| Step: 6
Training loss: 1.500374674797058
Validation loss: 1.8688714017150223

Epoch: 5| Step: 7
Training loss: 1.4496715068817139
Validation loss: 1.8791197269193587

Epoch: 5| Step: 8
Training loss: 1.0384490489959717
Validation loss: 1.8756574110318256

Epoch: 5| Step: 9
Training loss: 1.3916101455688477
Validation loss: 1.8808146625436761

Epoch: 5| Step: 10
Training loss: 0.8789710998535156
Validation loss: 1.8865173773099018

Epoch: 268| Step: 0
Training loss: 0.9605420231819153
Validation loss: 1.900114636267385

Epoch: 5| Step: 1
Training loss: 1.1133476495742798
Validation loss: 1.9571560890443864

Epoch: 5| Step: 2
Training loss: 1.4344228506088257
Validation loss: 1.9594505961223314

Epoch: 5| Step: 3
Training loss: 1.068656086921692
Validation loss: 1.9746623603246545

Epoch: 5| Step: 4
Training loss: 0.7238162159919739
Validation loss: 1.956513383055246

Epoch: 5| Step: 5
Training loss: 0.9151221513748169
Validation loss: 1.950036225780364

Epoch: 5| Step: 6
Training loss: 1.1935871839523315
Validation loss: 1.9295127712270266

Epoch: 5| Step: 7
Training loss: 1.4674770832061768
Validation loss: 1.908431545380623

Epoch: 5| Step: 8
Training loss: 1.2195088863372803
Validation loss: 1.8644634498062955

Epoch: 5| Step: 9
Training loss: 1.4192508459091187
Validation loss: 1.8657436870759534

Epoch: 5| Step: 10
Training loss: 0.8011612892150879
Validation loss: 1.8695654240987634

Epoch: 269| Step: 0
Training loss: 1.070253610610962
Validation loss: 1.886814184086297

Epoch: 5| Step: 1
Training loss: 1.1522974967956543
Validation loss: 1.8886563726650771

Epoch: 5| Step: 2
Training loss: 0.48423534631729126
Validation loss: 1.8819674689282653

Epoch: 5| Step: 3
Training loss: 1.2982242107391357
Validation loss: 1.8881539683188162

Epoch: 5| Step: 4
Training loss: 1.4682725667953491
Validation loss: 1.8877120915279593

Epoch: 5| Step: 5
Training loss: 1.0987608432769775
Validation loss: 1.8792113181083434

Epoch: 5| Step: 6
Training loss: 1.0178134441375732
Validation loss: 1.9112363848634946

Epoch: 5| Step: 7
Training loss: 1.143880009651184
Validation loss: 1.9143982164321407

Epoch: 5| Step: 8
Training loss: 1.1193538904190063
Validation loss: 1.9034629560285998

Epoch: 5| Step: 9
Training loss: 1.1497368812561035
Validation loss: 1.8894412209910731

Epoch: 5| Step: 10
Training loss: 0.9822564721107483
Validation loss: 1.8679186464637838

Epoch: 270| Step: 0
Training loss: 0.9657314419746399
Validation loss: 1.8183849985881517

Epoch: 5| Step: 1
Training loss: 1.068312406539917
Validation loss: 1.813142761107414

Epoch: 5| Step: 2
Training loss: 1.246730089187622
Validation loss: 1.8081834367526475

Epoch: 5| Step: 3
Training loss: 1.5974195003509521
Validation loss: 1.830181792218198

Epoch: 5| Step: 4
Training loss: 0.8583718538284302
Validation loss: 1.8363902235543856

Epoch: 5| Step: 5
Training loss: 0.8852860331535339
Validation loss: 1.849323211177703

Epoch: 5| Step: 6
Training loss: 0.6941676139831543
Validation loss: 1.8695288524832776

Epoch: 5| Step: 7
Training loss: 1.5049775838851929
Validation loss: 1.8918873776671707

Epoch: 5| Step: 8
Training loss: 0.9233024716377258
Validation loss: 1.918196738407176

Epoch: 5| Step: 9
Training loss: 1.2366304397583008
Validation loss: 1.8969638591171594

Epoch: 5| Step: 10
Training loss: 0.8782399296760559
Validation loss: 1.9164812975032355

Epoch: 271| Step: 0
Training loss: 1.548683524131775
Validation loss: 1.8929905250508299

Epoch: 5| Step: 1
Training loss: 0.9118803143501282
Validation loss: 1.8748772375045284

Epoch: 5| Step: 2
Training loss: 1.199908971786499
Validation loss: 1.8572330218489452

Epoch: 5| Step: 3
Training loss: 1.371163249015808
Validation loss: 1.8359856169710878

Epoch: 5| Step: 4
Training loss: 0.8879812955856323
Validation loss: 1.842389020868527

Epoch: 5| Step: 5
Training loss: 0.857620120048523
Validation loss: 1.828855381217054

Epoch: 5| Step: 6
Training loss: 0.7432689070701599
Validation loss: 1.8410710109177457

Epoch: 5| Step: 7
Training loss: 0.970007061958313
Validation loss: 1.8487625775798675

Epoch: 5| Step: 8
Training loss: 0.647777259349823
Validation loss: 1.8578393228592411

Epoch: 5| Step: 9
Training loss: 1.1790664196014404
Validation loss: 1.8649361313030284

Epoch: 5| Step: 10
Training loss: 1.1997169256210327
Validation loss: 1.8725569209744852

Epoch: 272| Step: 0
Training loss: 0.8308936953544617
Validation loss: 1.8612132546722249

Epoch: 5| Step: 1
Training loss: 1.036557912826538
Validation loss: 1.8635999528310632

Epoch: 5| Step: 2
Training loss: 0.794418215751648
Validation loss: 1.8564044134591215

Epoch: 5| Step: 3
Training loss: 0.8545500636100769
Validation loss: 1.890833281701611

Epoch: 5| Step: 4
Training loss: 1.386232614517212
Validation loss: 1.8799184753048805

Epoch: 5| Step: 5
Training loss: 1.353002905845642
Validation loss: 1.8629962218705045

Epoch: 5| Step: 6
Training loss: 0.9463914632797241
Validation loss: 1.8542165076860817

Epoch: 5| Step: 7
Training loss: 1.1981085538864136
Validation loss: 1.8498965565876295

Epoch: 5| Step: 8
Training loss: 0.8500292897224426
Validation loss: 1.8998717851536249

Epoch: 5| Step: 9
Training loss: 0.6249408721923828
Validation loss: 1.8615625622451946

Epoch: 5| Step: 10
Training loss: 1.328197717666626
Validation loss: 1.8541056981650732

Epoch: 273| Step: 0
Training loss: 0.7782060503959656
Validation loss: 1.844470098454465

Epoch: 5| Step: 1
Training loss: 0.8264735341072083
Validation loss: 1.8588588545399327

Epoch: 5| Step: 2
Training loss: 1.6556587219238281
Validation loss: 1.8432762738197082

Epoch: 5| Step: 3
Training loss: 1.2116868495941162
Validation loss: 1.8267589756237563

Epoch: 5| Step: 4
Training loss: 1.1408982276916504
Validation loss: 1.8259309222621303

Epoch: 5| Step: 5
Training loss: 1.1563447713851929
Validation loss: 1.8239589237397718

Epoch: 5| Step: 6
Training loss: 0.5561423897743225
Validation loss: 1.843169112359324

Epoch: 5| Step: 7
Training loss: 0.7824877500534058
Validation loss: 1.823212077540736

Epoch: 5| Step: 8
Training loss: 1.1796367168426514
Validation loss: 1.8244617562140188

Epoch: 5| Step: 9
Training loss: 1.0126591920852661
Validation loss: 1.816030393364609

Epoch: 5| Step: 10
Training loss: 0.8296195864677429
Validation loss: 1.8650541587542462

Epoch: 274| Step: 0
Training loss: 0.7575259208679199
Validation loss: 1.88133821692518

Epoch: 5| Step: 1
Training loss: 1.056160569190979
Validation loss: 1.8577986981279107

Epoch: 5| Step: 2
Training loss: 1.125610113143921
Validation loss: 1.8792629036852109

Epoch: 5| Step: 3
Training loss: 1.0995266437530518
Validation loss: 1.8861848064648208

Epoch: 5| Step: 4
Training loss: 0.8353826403617859
Validation loss: 1.8634170127171341

Epoch: 5| Step: 5
Training loss: 1.1125690937042236
Validation loss: 1.8723218530736945

Epoch: 5| Step: 6
Training loss: 0.7495819926261902
Validation loss: 1.866915895092872

Epoch: 5| Step: 7
Training loss: 0.9619032144546509
Validation loss: 1.8512249274920392

Epoch: 5| Step: 8
Training loss: 0.8187247514724731
Validation loss: 1.8243710751174598

Epoch: 5| Step: 9
Training loss: 1.3888673782348633
Validation loss: 1.816857958352694

Epoch: 5| Step: 10
Training loss: 0.9941519498825073
Validation loss: 1.8038528337273547

Epoch: 275| Step: 0
Training loss: 0.9523245692253113
Validation loss: 1.7946807056344964

Epoch: 5| Step: 1
Training loss: 1.5208323001861572
Validation loss: 1.771051993934057

Epoch: 5| Step: 2
Training loss: 0.9604334831237793
Validation loss: 1.80006395616839

Epoch: 5| Step: 3
Training loss: 0.5838818550109863
Validation loss: 1.808234090446144

Epoch: 5| Step: 4
Training loss: 1.2380551099777222
Validation loss: 1.7952070851479807

Epoch: 5| Step: 5
Training loss: 0.7050448656082153
Validation loss: 1.8276907538854947

Epoch: 5| Step: 6
Training loss: 1.1464765071868896
Validation loss: 1.8788863651214107

Epoch: 5| Step: 7
Training loss: 0.9396389126777649
Validation loss: 1.9008569114951677

Epoch: 5| Step: 8
Training loss: 0.7386155724525452
Validation loss: 1.920680489591373

Epoch: 5| Step: 9
Training loss: 1.1494863033294678
Validation loss: 1.9006067142691663

Epoch: 5| Step: 10
Training loss: 1.2524441480636597
Validation loss: 1.8815655375039706

Epoch: 276| Step: 0
Training loss: 0.9034344553947449
Validation loss: 1.8582134759554298

Epoch: 5| Step: 1
Training loss: 1.017665982246399
Validation loss: 1.8670391267345798

Epoch: 5| Step: 2
Training loss: 0.7412302494049072
Validation loss: 1.8254555245881439

Epoch: 5| Step: 3
Training loss: 0.8483408093452454
Validation loss: 1.8136479700765302

Epoch: 5| Step: 4
Training loss: 0.8101433515548706
Validation loss: 1.8457283396874704

Epoch: 5| Step: 5
Training loss: 0.8299165964126587
Validation loss: 1.8502036397175123

Epoch: 5| Step: 6
Training loss: 1.2356960773468018
Validation loss: 1.8774446390008415

Epoch: 5| Step: 7
Training loss: 1.0414049625396729
Validation loss: 1.8697542990407636

Epoch: 5| Step: 8
Training loss: 1.2794463634490967
Validation loss: 1.8582064951619794

Epoch: 5| Step: 9
Training loss: 1.3938186168670654
Validation loss: 1.875169450236905

Epoch: 5| Step: 10
Training loss: 0.8254992365837097
Validation loss: 1.849331517373362

Epoch: 277| Step: 0
Training loss: 0.661930501461029
Validation loss: 1.8687325344290784

Epoch: 5| Step: 1
Training loss: 0.5078571438789368
Validation loss: 1.8256087123706777

Epoch: 5| Step: 2
Training loss: 0.8102806210517883
Validation loss: 1.819972917597781

Epoch: 5| Step: 3
Training loss: 0.9942596554756165
Validation loss: 1.788080346199774

Epoch: 5| Step: 4
Training loss: 1.0314971208572388
Validation loss: 1.8180573114784815

Epoch: 5| Step: 5
Training loss: 1.0316808223724365
Validation loss: 1.8154766123781922

Epoch: 5| Step: 6
Training loss: 1.2398821115493774
Validation loss: 1.8118020501188052

Epoch: 5| Step: 7
Training loss: 1.1751960515975952
Validation loss: 1.8472253667410983

Epoch: 5| Step: 8
Training loss: 1.178468942642212
Validation loss: 1.8766663958949428

Epoch: 5| Step: 9
Training loss: 1.4771227836608887
Validation loss: 1.884885254726615

Epoch: 5| Step: 10
Training loss: 0.8285782933235168
Validation loss: 1.8784890367138771

Epoch: 278| Step: 0
Training loss: 1.3051433563232422
Validation loss: 1.8546679109655402

Epoch: 5| Step: 1
Training loss: 0.7691532969474792
Validation loss: 1.8317688498445737

Epoch: 5| Step: 2
Training loss: 1.2393150329589844
Validation loss: 1.8219435727724465

Epoch: 5| Step: 3
Training loss: 0.7394000291824341
Validation loss: 1.8228725733295563

Epoch: 5| Step: 4
Training loss: 0.8085100054740906
Validation loss: 1.8128220330002487

Epoch: 5| Step: 5
Training loss: 0.456967830657959
Validation loss: 1.7989468177159627

Epoch: 5| Step: 6
Training loss: 1.2883487939834595
Validation loss: 1.7896666334521385

Epoch: 5| Step: 7
Training loss: 1.115415334701538
Validation loss: 1.803262569571054

Epoch: 5| Step: 8
Training loss: 1.0911648273468018
Validation loss: 1.8326143398079822

Epoch: 5| Step: 9
Training loss: 0.9467015266418457
Validation loss: 1.8472695196828535

Epoch: 5| Step: 10
Training loss: 1.2339859008789062
Validation loss: 1.8496978129110029

Epoch: 279| Step: 0
Training loss: 0.529579758644104
Validation loss: 1.8335845752428936

Epoch: 5| Step: 1
Training loss: 0.8087700009346008
Validation loss: 1.820239188850567

Epoch: 5| Step: 2
Training loss: 0.9448461532592773
Validation loss: 1.8622328542893933

Epoch: 5| Step: 3
Training loss: 1.0940747261047363
Validation loss: 1.8653991068563154

Epoch: 5| Step: 4
Training loss: 1.3771921396255493
Validation loss: 1.8597052379321026

Epoch: 5| Step: 5
Training loss: 1.0295507907867432
Validation loss: 1.840911126905872

Epoch: 5| Step: 6
Training loss: 1.041894793510437
Validation loss: 1.7849160599452194

Epoch: 5| Step: 7
Training loss: 0.9215133786201477
Validation loss: 1.7740165854013095

Epoch: 5| Step: 8
Training loss: 0.8994930386543274
Validation loss: 1.7740977143728605

Epoch: 5| Step: 9
Training loss: 1.0230684280395508
Validation loss: 1.7791627286582865

Epoch: 5| Step: 10
Training loss: 1.0356463193893433
Validation loss: 1.7494744459788005

Epoch: 280| Step: 0
Training loss: 0.888965904712677
Validation loss: 1.7744639330012824

Epoch: 5| Step: 1
Training loss: 0.8481191396713257
Validation loss: 1.7708395796437417

Epoch: 5| Step: 2
Training loss: 0.4502338469028473
Validation loss: 1.7812922462340324

Epoch: 5| Step: 3
Training loss: 1.4207364320755005
Validation loss: 1.8194113636529574

Epoch: 5| Step: 4
Training loss: 1.0544136762619019
Validation loss: 1.8169975908853675

Epoch: 5| Step: 5
Training loss: 0.5771100521087646
Validation loss: 1.8277691961616598

Epoch: 5| Step: 6
Training loss: 1.0547816753387451
Validation loss: 1.815073161996821

Epoch: 5| Step: 7
Training loss: 1.074721097946167
Validation loss: 1.7995785974687146

Epoch: 5| Step: 8
Training loss: 1.1459394693374634
Validation loss: 1.7794126746475056

Epoch: 5| Step: 9
Training loss: 1.097806692123413
Validation loss: 1.7981631268737137

Epoch: 5| Step: 10
Training loss: 0.9803903102874756
Validation loss: 1.8171742487979192

Epoch: 281| Step: 0
Training loss: 0.8632971048355103
Validation loss: 1.8060205123757804

Epoch: 5| Step: 1
Training loss: 0.5248339176177979
Validation loss: 1.8041786827066892

Epoch: 5| Step: 2
Training loss: 1.2995662689208984
Validation loss: 1.816439526055449

Epoch: 5| Step: 3
Training loss: 0.8600017428398132
Validation loss: 1.8164239698840725

Epoch: 5| Step: 4
Training loss: 1.1400058269500732
Validation loss: 1.8241129882874028

Epoch: 5| Step: 5
Training loss: 0.6615396738052368
Validation loss: 1.7940637232154928

Epoch: 5| Step: 6
Training loss: 1.5733524560928345
Validation loss: 1.7905710358773508

Epoch: 5| Step: 7
Training loss: 0.9659894704818726
Validation loss: 1.8072628962096347

Epoch: 5| Step: 8
Training loss: 0.9627467393875122
Validation loss: 1.8061336394279235

Epoch: 5| Step: 9
Training loss: 0.9284257888793945
Validation loss: 1.8147293072874828

Epoch: 5| Step: 10
Training loss: 0.34145036339759827
Validation loss: 1.8108092149098713

Epoch: 282| Step: 0
Training loss: 0.3351706862449646
Validation loss: 1.8335612999495638

Epoch: 5| Step: 1
Training loss: 0.7650229930877686
Validation loss: 1.842651544078704

Epoch: 5| Step: 2
Training loss: 0.8114532232284546
Validation loss: 1.8419531724786247

Epoch: 5| Step: 3
Training loss: 0.5611716508865356
Validation loss: 1.8384042991104947

Epoch: 5| Step: 4
Training loss: 1.193589687347412
Validation loss: 1.8356787132960495

Epoch: 5| Step: 5
Training loss: 0.8716669082641602
Validation loss: 1.8562707157545193

Epoch: 5| Step: 6
Training loss: 1.5791656970977783
Validation loss: 1.8193122468968874

Epoch: 5| Step: 7
Training loss: 0.9223968386650085
Validation loss: 1.786799535956434

Epoch: 5| Step: 8
Training loss: 0.9805856943130493
Validation loss: 1.8077412702703988

Epoch: 5| Step: 9
Training loss: 1.2271915674209595
Validation loss: 1.821319264750327

Epoch: 5| Step: 10
Training loss: 1.0097806453704834
Validation loss: 1.7914659233503445

Epoch: 283| Step: 0
Training loss: 0.7960044741630554
Validation loss: 1.7770432195355814

Epoch: 5| Step: 1
Training loss: 0.7780395746231079
Validation loss: 1.7806122431191065

Epoch: 5| Step: 2
Training loss: 0.8560492396354675
Validation loss: 1.8035582983365623

Epoch: 5| Step: 3
Training loss: 1.1065428256988525
Validation loss: 1.8139287938353836

Epoch: 5| Step: 4
Training loss: 1.1138936281204224
Validation loss: 1.8258230865642588

Epoch: 5| Step: 5
Training loss: 1.4144833087921143
Validation loss: 1.8430282390245827

Epoch: 5| Step: 6
Training loss: 1.088738203048706
Validation loss: 1.863959648275888

Epoch: 5| Step: 7
Training loss: 0.6362580060958862
Validation loss: 1.8476730610734673

Epoch: 5| Step: 8
Training loss: 1.1188485622406006
Validation loss: 1.837851523071207

Epoch: 5| Step: 9
Training loss: 0.8879518508911133
Validation loss: 1.8474457263946533

Epoch: 5| Step: 10
Training loss: 0.974897027015686
Validation loss: 1.8642163122853925

Epoch: 284| Step: 0
Training loss: 1.0915119647979736
Validation loss: 1.8264052432070497

Epoch: 5| Step: 1
Training loss: 1.2336475849151611
Validation loss: 1.8228756945620301

Epoch: 5| Step: 2
Training loss: 0.8021621704101562
Validation loss: 1.8256555603396507

Epoch: 5| Step: 3
Training loss: 0.8680497407913208
Validation loss: 1.8068823160663727

Epoch: 5| Step: 4
Training loss: 0.7004711031913757
Validation loss: 1.7943010766019103

Epoch: 5| Step: 5
Training loss: 0.8782221674919128
Validation loss: 1.8019099799535607

Epoch: 5| Step: 6
Training loss: 1.3381538391113281
Validation loss: 1.794229257491327

Epoch: 5| Step: 7
Training loss: 1.0518629550933838
Validation loss: 1.8202700884111467

Epoch: 5| Step: 8
Training loss: 0.7747030258178711
Validation loss: 1.8320928722299554

Epoch: 5| Step: 9
Training loss: 0.7526464462280273
Validation loss: 1.8687131584331553

Epoch: 5| Step: 10
Training loss: 1.0932934284210205
Validation loss: 1.8806325774038992

Epoch: 285| Step: 0
Training loss: 0.8801984786987305
Validation loss: 1.854698706698674

Epoch: 5| Step: 1
Training loss: 0.9180155992507935
Validation loss: 1.830972581781367

Epoch: 5| Step: 2
Training loss: 0.8853162527084351
Validation loss: 1.7974700491915467

Epoch: 5| Step: 3
Training loss: 1.4152686595916748
Validation loss: 1.7961673172571326

Epoch: 5| Step: 4
Training loss: 1.4048882722854614
Validation loss: 1.8326518868887296

Epoch: 5| Step: 5
Training loss: 1.0178388357162476
Validation loss: 1.836602848063233

Epoch: 5| Step: 6
Training loss: 0.7055286169052124
Validation loss: 1.8561865501506354

Epoch: 5| Step: 7
Training loss: 0.8024764060974121
Validation loss: 1.8585897536687954

Epoch: 5| Step: 8
Training loss: 0.5537269711494446
Validation loss: 1.8634051763883202

Epoch: 5| Step: 9
Training loss: 0.6197587251663208
Validation loss: 1.8373684601117206

Epoch: 5| Step: 10
Training loss: 1.1056127548217773
Validation loss: 1.8255641832146594

Epoch: 286| Step: 0
Training loss: 0.7306621670722961
Validation loss: 1.843571259129432

Epoch: 5| Step: 1
Training loss: 0.8298951983451843
Validation loss: 1.8236231675712011

Epoch: 5| Step: 2
Training loss: 0.8588618040084839
Validation loss: 1.8363599085038709

Epoch: 5| Step: 3
Training loss: 0.8974245190620422
Validation loss: 1.8398040661247828

Epoch: 5| Step: 4
Training loss: 0.6816477179527283
Validation loss: 1.8541333085747176

Epoch: 5| Step: 5
Training loss: 1.375180959701538
Validation loss: 1.8235736059886154

Epoch: 5| Step: 6
Training loss: 0.6591135859489441
Validation loss: 1.7634021146323091

Epoch: 5| Step: 7
Training loss: 1.0517953634262085
Validation loss: 1.769636208011258

Epoch: 5| Step: 8
Training loss: 0.9757885932922363
Validation loss: 1.78585555220163

Epoch: 5| Step: 9
Training loss: 1.0070710182189941
Validation loss: 1.7866021279365785

Epoch: 5| Step: 10
Training loss: 0.7076939940452576
Validation loss: 1.7922625560914316

Epoch: 287| Step: 0
Training loss: 0.8070656061172485
Validation loss: 1.7947868647113923

Epoch: 5| Step: 1
Training loss: 0.6799722909927368
Validation loss: 1.8134634379417665

Epoch: 5| Step: 2
Training loss: 0.5710393190383911
Validation loss: 1.814869385893627

Epoch: 5| Step: 3
Training loss: 0.9708313941955566
Validation loss: 1.799952781328591

Epoch: 5| Step: 4
Training loss: 1.530653715133667
Validation loss: 1.8177464123695128

Epoch: 5| Step: 5
Training loss: 0.9795736074447632
Validation loss: 1.7892163915018882

Epoch: 5| Step: 6
Training loss: 0.9176144599914551
Validation loss: 1.7986676936508508

Epoch: 5| Step: 7
Training loss: 1.3000710010528564
Validation loss: 1.803175894162988

Epoch: 5| Step: 8
Training loss: 1.0056079626083374
Validation loss: 1.7980889222955192

Epoch: 5| Step: 9
Training loss: 0.6894868612289429
Validation loss: 1.7785672462114723

Epoch: 5| Step: 10
Training loss: 0.26623889803886414
Validation loss: 1.7785449527925061

Epoch: 288| Step: 0
Training loss: 1.0837664604187012
Validation loss: 1.7563518324205953

Epoch: 5| Step: 1
Training loss: 0.8998498916625977
Validation loss: 1.7751245421748008

Epoch: 5| Step: 2
Training loss: 0.8084753751754761
Validation loss: 1.7678961830754434

Epoch: 5| Step: 3
Training loss: 0.6423296928405762
Validation loss: 1.7757639551675448

Epoch: 5| Step: 4
Training loss: 0.7458714842796326
Validation loss: 1.8070227305094402

Epoch: 5| Step: 5
Training loss: 1.287123441696167
Validation loss: 1.7860217248239825

Epoch: 5| Step: 6
Training loss: 1.1769130229949951
Validation loss: 1.7929928789856613

Epoch: 5| Step: 7
Training loss: 0.7950372695922852
Validation loss: 1.801269668404774

Epoch: 5| Step: 8
Training loss: 0.43652814626693726
Validation loss: 1.8224651185415124

Epoch: 5| Step: 9
Training loss: 1.0730469226837158
Validation loss: 1.8219737929682578

Epoch: 5| Step: 10
Training loss: 0.6580555438995361
Validation loss: 1.8499430097559446

Epoch: 289| Step: 0
Training loss: 0.8076475262641907
Validation loss: 1.8442913780930221

Epoch: 5| Step: 1
Training loss: 0.9707794189453125
Validation loss: 1.8429342649316276

Epoch: 5| Step: 2
Training loss: 0.9730768203735352
Validation loss: 1.8346877713357248

Epoch: 5| Step: 3
Training loss: 0.778997540473938
Validation loss: 1.8290093791100286

Epoch: 5| Step: 4
Training loss: 1.0654189586639404
Validation loss: 1.8233335255294718

Epoch: 5| Step: 5
Training loss: 0.5515350103378296
Validation loss: 1.815816980536266

Epoch: 5| Step: 6
Training loss: 1.0545122623443604
Validation loss: 1.8297448619719474

Epoch: 5| Step: 7
Training loss: 0.7456104755401611
Validation loss: 1.8220594954747025

Epoch: 5| Step: 8
Training loss: 0.7635297775268555
Validation loss: 1.7832333310957877

Epoch: 5| Step: 9
Training loss: 0.9514471292495728
Validation loss: 1.782762715893407

Epoch: 5| Step: 10
Training loss: 1.043442726135254
Validation loss: 1.7926441161863265

Epoch: 290| Step: 0
Training loss: 0.7902926206588745
Validation loss: 1.7844668319148402

Epoch: 5| Step: 1
Training loss: 0.9175509214401245
Validation loss: 1.8140415068595641

Epoch: 5| Step: 2
Training loss: 1.0413213968276978
Validation loss: 1.7891009187185636

Epoch: 5| Step: 3
Training loss: 1.0128177404403687
Validation loss: 1.7829158716304327

Epoch: 5| Step: 4
Training loss: 1.131534218788147
Validation loss: 1.7612694565967848

Epoch: 5| Step: 5
Training loss: 0.8436905145645142
Validation loss: 1.7803524899226364

Epoch: 5| Step: 6
Training loss: 0.6550682783126831
Validation loss: 1.7688574765318184

Epoch: 5| Step: 7
Training loss: 0.6923550367355347
Validation loss: 1.7749709365188435

Epoch: 5| Step: 8
Training loss: 0.7399067878723145
Validation loss: 1.767628223665299

Epoch: 5| Step: 9
Training loss: 0.9583737254142761
Validation loss: 1.775138428134303

Epoch: 5| Step: 10
Training loss: 0.5882306694984436
Validation loss: 1.7626740676100536

Epoch: 291| Step: 0
Training loss: 1.3092331886291504
Validation loss: 1.763796276943658

Epoch: 5| Step: 1
Training loss: 0.803057849407196
Validation loss: 1.7560816336703557

Epoch: 5| Step: 2
Training loss: 1.05488920211792
Validation loss: 1.7938634349453835

Epoch: 5| Step: 3
Training loss: 0.9758180379867554
Validation loss: 1.8048177611443303

Epoch: 5| Step: 4
Training loss: 0.5832806825637817
Validation loss: 1.7968542114380868

Epoch: 5| Step: 5
Training loss: 1.035283088684082
Validation loss: 1.815657889971169

Epoch: 5| Step: 6
Training loss: 0.8602701425552368
Validation loss: 1.8065630389798073

Epoch: 5| Step: 7
Training loss: 0.9675617218017578
Validation loss: 1.8047040444548412

Epoch: 5| Step: 8
Training loss: 0.6499297618865967
Validation loss: 1.8162782807503977

Epoch: 5| Step: 9
Training loss: 0.4614596366882324
Validation loss: 1.779417021300203

Epoch: 5| Step: 10
Training loss: 0.7404522895812988
Validation loss: 1.7809405506298106

Epoch: 292| Step: 0
Training loss: 1.3390095233917236
Validation loss: 1.7945748631672194

Epoch: 5| Step: 1
Training loss: 1.2760937213897705
Validation loss: 1.7916983481376403

Epoch: 5| Step: 2
Training loss: 0.7379881143569946
Validation loss: 1.832664534609805

Epoch: 5| Step: 3
Training loss: 0.860600471496582
Validation loss: 1.8179693568137385

Epoch: 5| Step: 4
Training loss: 0.8346424102783203
Validation loss: 1.8190435465945993

Epoch: 5| Step: 5
Training loss: 0.8909217119216919
Validation loss: 1.8469988197408698

Epoch: 5| Step: 6
Training loss: 0.6751865148544312
Validation loss: 1.881142044580111

Epoch: 5| Step: 7
Training loss: 0.9107292890548706
Validation loss: 1.9040712207876227

Epoch: 5| Step: 8
Training loss: 0.8113762140274048
Validation loss: 1.8957165953933552

Epoch: 5| Step: 9
Training loss: 0.6964205503463745
Validation loss: 1.837919658230197

Epoch: 5| Step: 10
Training loss: 0.6670056581497192
Validation loss: 1.8102992555146575

Epoch: 293| Step: 0
Training loss: 1.0923038721084595
Validation loss: 1.8053236033326836

Epoch: 5| Step: 1
Training loss: 0.6713880300521851
Validation loss: 1.7934140261783396

Epoch: 5| Step: 2
Training loss: 0.6269258260726929
Validation loss: 1.7808299987546858

Epoch: 5| Step: 3
Training loss: 0.6331173777580261
Validation loss: 1.8133443965706775

Epoch: 5| Step: 4
Training loss: 1.0530116558074951
Validation loss: 1.7863016487449728

Epoch: 5| Step: 5
Training loss: 0.7253944277763367
Validation loss: 1.8128757412715624

Epoch: 5| Step: 6
Training loss: 0.6872302293777466
Validation loss: 1.8307672905665573

Epoch: 5| Step: 7
Training loss: 1.3361952304840088
Validation loss: 1.8953181697476296

Epoch: 5| Step: 8
Training loss: 1.0362366437911987
Validation loss: 1.9162724428279425

Epoch: 5| Step: 9
Training loss: 0.8196080923080444
Validation loss: 1.9030267935927196

Epoch: 5| Step: 10
Training loss: 0.7927651405334473
Validation loss: 1.8477000780003046

Epoch: 294| Step: 0
Training loss: 0.7650130987167358
Validation loss: 1.8418341913530905

Epoch: 5| Step: 1
Training loss: 0.6221262812614441
Validation loss: 1.8369168286682458

Epoch: 5| Step: 2
Training loss: 1.1969459056854248
Validation loss: 1.7745276548529183

Epoch: 5| Step: 3
Training loss: 0.7530350089073181
Validation loss: 1.7848556990264564

Epoch: 5| Step: 4
Training loss: 0.7595720887184143
Validation loss: 1.7307820499584239

Epoch: 5| Step: 5
Training loss: 0.8826322555541992
Validation loss: 1.7401760816574097

Epoch: 5| Step: 6
Training loss: 0.8277014493942261
Validation loss: 1.7511797643476916

Epoch: 5| Step: 7
Training loss: 1.0298532247543335
Validation loss: 1.7806521436219573

Epoch: 5| Step: 8
Training loss: 0.9994453191757202
Validation loss: 1.755177076144885

Epoch: 5| Step: 9
Training loss: 0.8769111633300781
Validation loss: 1.7478776772816975

Epoch: 5| Step: 10
Training loss: 0.6899741888046265
Validation loss: 1.755631983921092

Epoch: 295| Step: 0
Training loss: 0.8951008915901184
Validation loss: 1.7418767944458993

Epoch: 5| Step: 1
Training loss: 1.0704755783081055
Validation loss: 1.7455107294103152

Epoch: 5| Step: 2
Training loss: 0.6822649240493774
Validation loss: 1.740637142171142

Epoch: 5| Step: 3
Training loss: 0.7851327657699585
Validation loss: 1.7275554005817702

Epoch: 5| Step: 4
Training loss: 0.6182519793510437
Validation loss: 1.749077389317174

Epoch: 5| Step: 5
Training loss: 1.1835609674453735
Validation loss: 1.7782751257701586

Epoch: 5| Step: 6
Training loss: 0.6106852889060974
Validation loss: 1.8173194034125215

Epoch: 5| Step: 7
Training loss: 0.8850847482681274
Validation loss: 1.8117177435146865

Epoch: 5| Step: 8
Training loss: 0.527129054069519
Validation loss: 1.8318841354821318

Epoch: 5| Step: 9
Training loss: 0.6703228950500488
Validation loss: 1.8372200227552844

Epoch: 5| Step: 10
Training loss: 1.1966419219970703
Validation loss: 1.8104670765579387

Epoch: 296| Step: 0
Training loss: 1.0231132507324219
Validation loss: 1.812344507504535

Epoch: 5| Step: 1
Training loss: 1.039405107498169
Validation loss: 1.8086987772295553

Epoch: 5| Step: 2
Training loss: 0.6387588381767273
Validation loss: 1.8100674331829112

Epoch: 5| Step: 3
Training loss: 0.46248188614845276
Validation loss: 1.8236932472516132

Epoch: 5| Step: 4
Training loss: 1.1625351905822754
Validation loss: 1.8124685774567306

Epoch: 5| Step: 5
Training loss: 0.6928951144218445
Validation loss: 1.8213377498811292

Epoch: 5| Step: 6
Training loss: 0.9269512295722961
Validation loss: 1.8247962638895998

Epoch: 5| Step: 7
Training loss: 0.8025975227355957
Validation loss: 1.840980150366342

Epoch: 5| Step: 8
Training loss: 0.7597709894180298
Validation loss: 1.7961353922402987

Epoch: 5| Step: 9
Training loss: 0.9142915606498718
Validation loss: 1.8223631305079306

Epoch: 5| Step: 10
Training loss: 0.4539298415184021
Validation loss: 1.8134879796735701

Epoch: 297| Step: 0
Training loss: 0.4102681279182434
Validation loss: 1.7890862867396364

Epoch: 5| Step: 1
Training loss: 1.108961820602417
Validation loss: 1.8280122228848037

Epoch: 5| Step: 2
Training loss: 0.6046667695045471
Validation loss: 1.8349903027216594

Epoch: 5| Step: 3
Training loss: 0.5325139760971069
Validation loss: 1.8178803138835455

Epoch: 5| Step: 4
Training loss: 1.0571155548095703
Validation loss: 1.814650417656027

Epoch: 5| Step: 5
Training loss: 0.9594722986221313
Validation loss: 1.846124905411915

Epoch: 5| Step: 6
Training loss: 0.8611483573913574
Validation loss: 1.83706921146762

Epoch: 5| Step: 7
Training loss: 1.0307376384735107
Validation loss: 1.8322516538763558

Epoch: 5| Step: 8
Training loss: 0.8849499821662903
Validation loss: 1.8125232752933298

Epoch: 5| Step: 9
Training loss: 0.7809470891952515
Validation loss: 1.7855583775428034

Epoch: 5| Step: 10
Training loss: 0.9270944595336914
Validation loss: 1.7754230653086016

Epoch: 298| Step: 0
Training loss: 0.6068798899650574
Validation loss: 1.7619108410291775

Epoch: 5| Step: 1
Training loss: 0.7862242460250854
Validation loss: 1.770962376748362

Epoch: 5| Step: 2
Training loss: 0.9844695925712585
Validation loss: 1.769476088144446

Epoch: 5| Step: 3
Training loss: 1.193310260772705
Validation loss: 1.7581317411955966

Epoch: 5| Step: 4
Training loss: 0.6983895301818848
Validation loss: 1.7715121623008483

Epoch: 5| Step: 5
Training loss: 0.5834599733352661
Validation loss: 1.7899486736584735

Epoch: 5| Step: 6
Training loss: 1.1541824340820312
Validation loss: 1.8119963471607496

Epoch: 5| Step: 7
Training loss: 0.6722688674926758
Validation loss: 1.8088415027946554

Epoch: 5| Step: 8
Training loss: 0.6404205560684204
Validation loss: 1.8462913369619718

Epoch: 5| Step: 9
Training loss: 0.9326770901679993
Validation loss: 1.9234055883140975

Epoch: 5| Step: 10
Training loss: 0.7968482971191406
Validation loss: 1.9173672711977394

Epoch: 299| Step: 0
Training loss: 0.6876015663146973
Validation loss: 1.9110497492615894

Epoch: 5| Step: 1
Training loss: 0.8265695571899414
Validation loss: 1.9108714198553434

Epoch: 5| Step: 2
Training loss: 1.0014128684997559
Validation loss: 1.8579760187415666

Epoch: 5| Step: 3
Training loss: 1.0984851121902466
Validation loss: 1.833182604082169

Epoch: 5| Step: 4
Training loss: 0.7789915204048157
Validation loss: 1.7975544109139392

Epoch: 5| Step: 5
Training loss: 0.7659377455711365
Validation loss: 1.7835398643247542

Epoch: 5| Step: 6
Training loss: 0.54900723695755
Validation loss: 1.7755018857217604

Epoch: 5| Step: 7
Training loss: 0.9846800565719604
Validation loss: 1.7490379425787157

Epoch: 5| Step: 8
Training loss: 0.7591915726661682
Validation loss: 1.7948297044282318

Epoch: 5| Step: 9
Training loss: 0.8196370005607605
Validation loss: 1.7891426099243986

Epoch: 5| Step: 10
Training loss: 0.7490042448043823
Validation loss: 1.789949332514117

Epoch: 300| Step: 0
Training loss: 0.610558032989502
Validation loss: 1.8092360970794514

Epoch: 5| Step: 1
Training loss: 0.7668699026107788
Validation loss: 1.7994033059766215

Epoch: 5| Step: 2
Training loss: 0.7480576634407043
Validation loss: 1.829496693867509

Epoch: 5| Step: 3
Training loss: 0.8389188051223755
Validation loss: 1.8141911363088956

Epoch: 5| Step: 4
Training loss: 0.6146536469459534
Validation loss: 1.8079303592763922

Epoch: 5| Step: 5
Training loss: 0.808952808380127
Validation loss: 1.7997318326786

Epoch: 5| Step: 6
Training loss: 0.9324040412902832
Validation loss: 1.7915045035782682

Epoch: 5| Step: 7
Training loss: 0.7949678897857666
Validation loss: 1.7692068135866554

Epoch: 5| Step: 8
Training loss: 0.6718897819519043
Validation loss: 1.773871168013542

Epoch: 5| Step: 9
Training loss: 0.8798443078994751
Validation loss: 1.737376388683114

Epoch: 5| Step: 10
Training loss: 1.029986023902893
Validation loss: 1.748676848667924

Epoch: 301| Step: 0
Training loss: 0.973308265209198
Validation loss: 1.7349170305395638

Epoch: 5| Step: 1
Training loss: 0.8406775593757629
Validation loss: 1.7317307033846456

Epoch: 5| Step: 2
Training loss: 0.6123380064964294
Validation loss: 1.7268812271856493

Epoch: 5| Step: 3
Training loss: 0.6828478574752808
Validation loss: 1.7281167686626475

Epoch: 5| Step: 4
Training loss: 0.811848521232605
Validation loss: 1.7288946900316464

Epoch: 5| Step: 5
Training loss: 0.34573203325271606
Validation loss: 1.73394682586834

Epoch: 5| Step: 6
Training loss: 1.1298614740371704
Validation loss: 1.774270724224788

Epoch: 5| Step: 7
Training loss: 0.7875748872756958
Validation loss: 1.7481859678863196

Epoch: 5| Step: 8
Training loss: 0.8673206567764282
Validation loss: 1.789260684802968

Epoch: 5| Step: 9
Training loss: 0.6770086288452148
Validation loss: 1.7748051458789456

Epoch: 5| Step: 10
Training loss: 0.8449575901031494
Validation loss: 1.788280548587922

Epoch: 302| Step: 0
Training loss: 0.41731706261634827
Validation loss: 1.812414111629609

Epoch: 5| Step: 1
Training loss: 0.8313844799995422
Validation loss: 1.80050568426809

Epoch: 5| Step: 2
Training loss: 0.7430310249328613
Validation loss: 1.764751503544469

Epoch: 5| Step: 3
Training loss: 0.647494375705719
Validation loss: 1.7942441189160911

Epoch: 5| Step: 4
Training loss: 0.7368196249008179
Validation loss: 1.7915095911231091

Epoch: 5| Step: 5
Training loss: 0.9085270166397095
Validation loss: 1.8032991142683132

Epoch: 5| Step: 6
Training loss: 0.8774875402450562
Validation loss: 1.7983935110030635

Epoch: 5| Step: 7
Training loss: 0.6664841175079346
Validation loss: 1.7991620866201257

Epoch: 5| Step: 8
Training loss: 0.676047682762146
Validation loss: 1.7597647995077155

Epoch: 5| Step: 9
Training loss: 1.0946191549301147
Validation loss: 1.8148239709997689

Epoch: 5| Step: 10
Training loss: 0.8395565152168274
Validation loss: 1.8211144503726755

Epoch: 303| Step: 0
Training loss: 0.8923261761665344
Validation loss: 1.849093952486592

Epoch: 5| Step: 1
Training loss: 1.0632374286651611
Validation loss: 1.8289956738871913

Epoch: 5| Step: 2
Training loss: 0.8783897161483765
Validation loss: 1.7952678344583

Epoch: 5| Step: 3
Training loss: 0.6729801297187805
Validation loss: 1.770878211144478

Epoch: 5| Step: 4
Training loss: 0.6452549695968628
Validation loss: 1.7781801557028165

Epoch: 5| Step: 5
Training loss: 0.7196900844573975
Validation loss: 1.7857473845122962

Epoch: 5| Step: 6
Training loss: 0.5950781106948853
Validation loss: 1.7805761214225524

Epoch: 5| Step: 7
Training loss: 0.7593932151794434
Validation loss: 1.7790156397768246

Epoch: 5| Step: 8
Training loss: 0.9047768712043762
Validation loss: 1.765061233633308

Epoch: 5| Step: 9
Training loss: 0.825360894203186
Validation loss: 1.784561885300503

Epoch: 5| Step: 10
Training loss: 0.3432393968105316
Validation loss: 1.7920648474847116

Epoch: 304| Step: 0
Training loss: 0.5937639474868774
Validation loss: 1.8087535148025842

Epoch: 5| Step: 1
Training loss: 0.7132583856582642
Validation loss: 1.8292257157705163

Epoch: 5| Step: 2
Training loss: 0.7779572606086731
Validation loss: 1.7932415675091486

Epoch: 5| Step: 3
Training loss: 1.0253827571868896
Validation loss: 1.7987359851919196

Epoch: 5| Step: 4
Training loss: 0.7722175717353821
Validation loss: 1.7898891997593704

Epoch: 5| Step: 5
Training loss: 0.8716791868209839
Validation loss: 1.7656000532129759

Epoch: 5| Step: 6
Training loss: 0.8600196838378906
Validation loss: 1.767814028647638

Epoch: 5| Step: 7
Training loss: 0.6938503980636597
Validation loss: 1.786965585524036

Epoch: 5| Step: 8
Training loss: 0.7184615731239319
Validation loss: 1.7903380355527323

Epoch: 5| Step: 9
Training loss: 0.4695051610469818
Validation loss: 1.7847620569249636

Epoch: 5| Step: 10
Training loss: 0.6903042793273926
Validation loss: 1.8044031268806868

Epoch: 305| Step: 0
Training loss: 0.5742441415786743
Validation loss: 1.7940333453557824

Epoch: 5| Step: 1
Training loss: 0.4299078583717346
Validation loss: 1.7789864745191348

Epoch: 5| Step: 2
Training loss: 0.7481640577316284
Validation loss: 1.7917892599618563

Epoch: 5| Step: 3
Training loss: 0.6643168926239014
Validation loss: 1.7532308793837024

Epoch: 5| Step: 4
Training loss: 0.703478991985321
Validation loss: 1.7450657544597503

Epoch: 5| Step: 5
Training loss: 0.8545713424682617
Validation loss: 1.7521396138334786

Epoch: 5| Step: 6
Training loss: 0.7310149669647217
Validation loss: 1.7363480406422769

Epoch: 5| Step: 7
Training loss: 0.7661582231521606
Validation loss: 1.745838911302628

Epoch: 5| Step: 8
Training loss: 0.964638888835907
Validation loss: 1.7517677776275142

Epoch: 5| Step: 9
Training loss: 0.9682771563529968
Validation loss: 1.7402498670803603

Epoch: 5| Step: 10
Training loss: 0.8292832374572754
Validation loss: 1.7304909408733409

Epoch: 306| Step: 0
Training loss: 0.6837236285209656
Validation loss: 1.7463320878244215

Epoch: 5| Step: 1
Training loss: 0.6228663325309753
Validation loss: 1.7692157235196841

Epoch: 5| Step: 2
Training loss: 0.4585558772087097
Validation loss: 1.7667599672912269

Epoch: 5| Step: 3
Training loss: 0.8391600847244263
Validation loss: 1.7632187527994956

Epoch: 5| Step: 4
Training loss: 0.6442306041717529
Validation loss: 1.7659772057687082

Epoch: 5| Step: 5
Training loss: 0.680296778678894
Validation loss: 1.7668888415059736

Epoch: 5| Step: 6
Training loss: 0.6944721937179565
Validation loss: 1.763275618194252

Epoch: 5| Step: 7
Training loss: 0.7530598640441895
Validation loss: 1.7767251550510366

Epoch: 5| Step: 8
Training loss: 0.6533321142196655
Validation loss: 1.7697799821053781

Epoch: 5| Step: 9
Training loss: 0.6765271425247192
Validation loss: 1.75612889054001

Epoch: 5| Step: 10
Training loss: 1.277373194694519
Validation loss: 1.7667847256506644

Epoch: 307| Step: 0
Training loss: 0.6240596771240234
Validation loss: 1.7815888709919427

Epoch: 5| Step: 1
Training loss: 0.5804235339164734
Validation loss: 1.8044557353501678

Epoch: 5| Step: 2
Training loss: 0.5039224624633789
Validation loss: 1.7988513515841575

Epoch: 5| Step: 3
Training loss: 0.7580740451812744
Validation loss: 1.7823877693504415

Epoch: 5| Step: 4
Training loss: 0.6118744611740112
Validation loss: 1.776925133120629

Epoch: 5| Step: 5
Training loss: 0.827850341796875
Validation loss: 1.8089098571449198

Epoch: 5| Step: 6
Training loss: 0.6915823221206665
Validation loss: 1.7755125171394759

Epoch: 5| Step: 7
Training loss: 0.9193436503410339
Validation loss: 1.8048128633088962

Epoch: 5| Step: 8
Training loss: 0.625663161277771
Validation loss: 1.7716642400269866

Epoch: 5| Step: 9
Training loss: 0.9787847399711609
Validation loss: 1.801010646486795

Epoch: 5| Step: 10
Training loss: 0.9063328504562378
Validation loss: 1.785687167157409

Epoch: 308| Step: 0
Training loss: 0.7738397121429443
Validation loss: 1.7815162443345594

Epoch: 5| Step: 1
Training loss: 0.7188010811805725
Validation loss: 1.8029712630856423

Epoch: 5| Step: 2
Training loss: 0.6462446451187134
Validation loss: 1.7767193214867705

Epoch: 5| Step: 3
Training loss: 0.5825732946395874
Validation loss: 1.7631275628202705

Epoch: 5| Step: 4
Training loss: 0.6513485908508301
Validation loss: 1.7692814078382266

Epoch: 5| Step: 5
Training loss: 0.6302357912063599
Validation loss: 1.771099841722878

Epoch: 5| Step: 6
Training loss: 0.8989921808242798
Validation loss: 1.7651527645767375

Epoch: 5| Step: 7
Training loss: 0.55418860912323
Validation loss: 1.7456403573354085

Epoch: 5| Step: 8
Training loss: 0.7341071367263794
Validation loss: 1.7592524431085075

Epoch: 5| Step: 9
Training loss: 0.9690490961074829
Validation loss: 1.7536664932004866

Epoch: 5| Step: 10
Training loss: 0.6566911339759827
Validation loss: 1.7569530446042296

Epoch: 309| Step: 0
Training loss: 0.5826156735420227
Validation loss: 1.7566701237873366

Epoch: 5| Step: 1
Training loss: 0.6800318360328674
Validation loss: 1.7768158951113302

Epoch: 5| Step: 2
Training loss: 0.9213207364082336
Validation loss: 1.7906854357770694

Epoch: 5| Step: 3
Training loss: 0.3410748839378357
Validation loss: 1.7871900309798538

Epoch: 5| Step: 4
Training loss: 0.7749187350273132
Validation loss: 1.759482576001075

Epoch: 5| Step: 5
Training loss: 0.8539738655090332
Validation loss: 1.7689581019904024

Epoch: 5| Step: 6
Training loss: 0.36575278639793396
Validation loss: 1.7525013980045114

Epoch: 5| Step: 7
Training loss: 1.097855806350708
Validation loss: 1.745032698877396

Epoch: 5| Step: 8
Training loss: 0.769497275352478
Validation loss: 1.7454682037394533

Epoch: 5| Step: 9
Training loss: 0.6824275255203247
Validation loss: 1.737085045024913

Epoch: 5| Step: 10
Training loss: 0.7465090751647949
Validation loss: 1.741473909347288

Epoch: 310| Step: 0
Training loss: 0.6939662098884583
Validation loss: 1.7383602460225422

Epoch: 5| Step: 1
Training loss: 0.7699539661407471
Validation loss: 1.7275899353847708

Epoch: 5| Step: 2
Training loss: 0.938696026802063
Validation loss: 1.7069161758627942

Epoch: 5| Step: 3
Training loss: 0.6009747385978699
Validation loss: 1.7452240426053283

Epoch: 5| Step: 4
Training loss: 0.4673498570919037
Validation loss: 1.7263480283880746

Epoch: 5| Step: 5
Training loss: 0.5992708802223206
Validation loss: 1.7603124828748806

Epoch: 5| Step: 6
Training loss: 0.825391411781311
Validation loss: 1.7234803771459928

Epoch: 5| Step: 7
Training loss: 0.658831000328064
Validation loss: 1.760557661774338

Epoch: 5| Step: 8
Training loss: 0.5392037630081177
Validation loss: 1.789982138141509

Epoch: 5| Step: 9
Training loss: 0.6128817200660706
Validation loss: 1.7886571781609648

Epoch: 5| Step: 10
Training loss: 1.118535041809082
Validation loss: 1.7851476348856443

Epoch: 311| Step: 0
Training loss: 0.8223516345024109
Validation loss: 1.8176950844385291

Epoch: 5| Step: 1
Training loss: 0.9119394421577454
Validation loss: 1.7672953964561544

Epoch: 5| Step: 2
Training loss: 0.7367962598800659
Validation loss: 1.799284222305462

Epoch: 5| Step: 3
Training loss: 0.7911640405654907
Validation loss: 1.774978458240468

Epoch: 5| Step: 4
Training loss: 0.6298900246620178
Validation loss: 1.7598212970200406

Epoch: 5| Step: 5
Training loss: 0.4719812273979187
Validation loss: 1.7558352588325419

Epoch: 5| Step: 6
Training loss: 0.8299285769462585
Validation loss: 1.753496971181644

Epoch: 5| Step: 7
Training loss: 0.6359206438064575
Validation loss: 1.756833230295489

Epoch: 5| Step: 8
Training loss: 0.6410651803016663
Validation loss: 1.7611011946073143

Epoch: 5| Step: 9
Training loss: 0.5247153639793396
Validation loss: 1.760606937510993

Epoch: 5| Step: 10
Training loss: 0.7624838948249817
Validation loss: 1.7798024185242192

Epoch: 312| Step: 0
Training loss: 0.7786937952041626
Validation loss: 1.7794608544277888

Epoch: 5| Step: 1
Training loss: 1.0920684337615967
Validation loss: 1.7563579415762296

Epoch: 5| Step: 2
Training loss: 0.4393920302391052
Validation loss: 1.7628114146571006

Epoch: 5| Step: 3
Training loss: 0.6447299122810364
Validation loss: 1.7521677581212853

Epoch: 5| Step: 4
Training loss: 0.49264177680015564
Validation loss: 1.7686528210998864

Epoch: 5| Step: 5
Training loss: 0.8112525939941406
Validation loss: 1.770728785504577

Epoch: 5| Step: 6
Training loss: 0.7265456914901733
Validation loss: 1.7611890813355804

Epoch: 5| Step: 7
Training loss: 0.7463014721870422
Validation loss: 1.7710359763073664

Epoch: 5| Step: 8
Training loss: 0.9361063241958618
Validation loss: 1.772911758833034

Epoch: 5| Step: 9
Training loss: 0.28028634190559387
Validation loss: 1.7697465855588195

Epoch: 5| Step: 10
Training loss: 0.4758628308773041
Validation loss: 1.7853118258137857

Epoch: 313| Step: 0
Training loss: 0.6496345400810242
Validation loss: 1.7497070489391204

Epoch: 5| Step: 1
Training loss: 0.5757204294204712
Validation loss: 1.7333650512080039

Epoch: 5| Step: 2
Training loss: 0.598094642162323
Validation loss: 1.7395077520801174

Epoch: 5| Step: 3
Training loss: 0.8034391403198242
Validation loss: 1.753265219350015

Epoch: 5| Step: 4
Training loss: 0.7271059155464172
Validation loss: 1.7898130404051913

Epoch: 5| Step: 5
Training loss: 0.6199564933776855
Validation loss: 1.7359840741721533

Epoch: 5| Step: 6
Training loss: 0.649962842464447
Validation loss: 1.755476136361399

Epoch: 5| Step: 7
Training loss: 0.8995782732963562
Validation loss: 1.7848980619061379

Epoch: 5| Step: 8
Training loss: 0.7397428750991821
Validation loss: 1.7725804223809192

Epoch: 5| Step: 9
Training loss: 0.6376953125
Validation loss: 1.7717920503308695

Epoch: 5| Step: 10
Training loss: 0.7555594444274902
Validation loss: 1.7438048034585931

Epoch: 314| Step: 0
Training loss: 1.2096432447433472
Validation loss: 1.7659965868919127

Epoch: 5| Step: 1
Training loss: 0.6658555269241333
Validation loss: 1.787924188439564

Epoch: 5| Step: 2
Training loss: 0.4373047351837158
Validation loss: 1.7839561880275767

Epoch: 5| Step: 3
Training loss: 0.9346789121627808
Validation loss: 1.7777654099208053

Epoch: 5| Step: 4
Training loss: 0.6189581751823425
Validation loss: 1.7970708826536774

Epoch: 5| Step: 5
Training loss: 0.7386828660964966
Validation loss: 1.7977002410478489

Epoch: 5| Step: 6
Training loss: 0.6097970008850098
Validation loss: 1.7963743927658244

Epoch: 5| Step: 7
Training loss: 0.6162017583847046
Validation loss: 1.8017248145995601

Epoch: 5| Step: 8
Training loss: 0.4035094380378723
Validation loss: 1.8031211565899592

Epoch: 5| Step: 9
Training loss: 0.888830840587616
Validation loss: 1.7875754743494012

Epoch: 5| Step: 10
Training loss: 0.40727007389068604
Validation loss: 1.7670481448532434

Epoch: 315| Step: 0
Training loss: 0.605262815952301
Validation loss: 1.7833041478228826

Epoch: 5| Step: 1
Training loss: 0.958720326423645
Validation loss: 1.7972631633922618

Epoch: 5| Step: 2
Training loss: 0.5397281050682068
Validation loss: 1.7943794983689503

Epoch: 5| Step: 3
Training loss: 0.7962595820426941
Validation loss: 1.805620167845039

Epoch: 5| Step: 4
Training loss: 0.6160131692886353
Validation loss: 1.783409805708034

Epoch: 5| Step: 5
Training loss: 0.9813623428344727
Validation loss: 1.751040348442652

Epoch: 5| Step: 6
Training loss: 0.5952908992767334
Validation loss: 1.7727429751426942

Epoch: 5| Step: 7
Training loss: 0.6804858446121216
Validation loss: 1.783914735240321

Epoch: 5| Step: 8
Training loss: 0.7196582555770874
Validation loss: 1.7723119028152958

Epoch: 5| Step: 9
Training loss: 0.6300398111343384
Validation loss: 1.748873902905372

Epoch: 5| Step: 10
Training loss: 0.48791447281837463
Validation loss: 1.776178821440666

Epoch: 316| Step: 0
Training loss: 0.7665284872055054
Validation loss: 1.8272183633619739

Epoch: 5| Step: 1
Training loss: 0.7119256258010864
Validation loss: 1.8687879103486256

Epoch: 5| Step: 2
Training loss: 0.9672991037368774
Validation loss: 1.8020821643132034

Epoch: 5| Step: 3
Training loss: 0.6857334971427917
Validation loss: 1.790075776397541

Epoch: 5| Step: 4
Training loss: 0.675108790397644
Validation loss: 1.7994017498467558

Epoch: 5| Step: 5
Training loss: 1.052817940711975
Validation loss: 1.8101838737405755

Epoch: 5| Step: 6
Training loss: 0.6554805040359497
Validation loss: 1.8091671274554344

Epoch: 5| Step: 7
Training loss: 0.5878435969352722
Validation loss: 1.8009919607511131

Epoch: 5| Step: 8
Training loss: 0.4971194863319397
Validation loss: 1.7911012300881006

Epoch: 5| Step: 9
Training loss: 0.783128023147583
Validation loss: 1.7554893262924687

Epoch: 5| Step: 10
Training loss: 0.2866881489753723
Validation loss: 1.7418308604148127

Epoch: 317| Step: 0
Training loss: 0.8033666610717773
Validation loss: 1.743397226897619

Epoch: 5| Step: 1
Training loss: 1.1371806859970093
Validation loss: 1.740013099485828

Epoch: 5| Step: 2
Training loss: 0.778560996055603
Validation loss: 1.7498075936430244

Epoch: 5| Step: 3
Training loss: 0.6551715731620789
Validation loss: 1.7294560914398522

Epoch: 5| Step: 4
Training loss: 0.5290724635124207
Validation loss: 1.7332224499794744

Epoch: 5| Step: 5
Training loss: 0.5720659494400024
Validation loss: 1.7630099916970858

Epoch: 5| Step: 6
Training loss: 0.5284630060195923
Validation loss: 1.7911193499001123

Epoch: 5| Step: 7
Training loss: 0.4548797607421875
Validation loss: 1.8087007909692743

Epoch: 5| Step: 8
Training loss: 0.4498073160648346
Validation loss: 1.7794697156516455

Epoch: 5| Step: 9
Training loss: 0.5787754654884338
Validation loss: 1.817811240432083

Epoch: 5| Step: 10
Training loss: 1.017304539680481
Validation loss: 1.8208687266995829

Epoch: 318| Step: 0
Training loss: 0.8651478886604309
Validation loss: 1.7849957558416552

Epoch: 5| Step: 1
Training loss: 0.6991198062896729
Validation loss: 1.8089060142476072

Epoch: 5| Step: 2
Training loss: 0.6036204099655151
Validation loss: 1.7770833379478865

Epoch: 5| Step: 3
Training loss: 0.26631736755371094
Validation loss: 1.7989777749584568

Epoch: 5| Step: 4
Training loss: 0.4119628071784973
Validation loss: 1.768755869198871

Epoch: 5| Step: 5
Training loss: 0.8404043316841125
Validation loss: 1.7543501636033416

Epoch: 5| Step: 6
Training loss: 0.8740715980529785
Validation loss: 1.7551719424545125

Epoch: 5| Step: 7
Training loss: 0.7142970561981201
Validation loss: 1.7505503803171136

Epoch: 5| Step: 8
Training loss: 0.40064653754234314
Validation loss: 1.7570986927196544

Epoch: 5| Step: 9
Training loss: 0.7948133945465088
Validation loss: 1.7405602585884832

Epoch: 5| Step: 10
Training loss: 0.800794780254364
Validation loss: 1.7366788592389835

Epoch: 319| Step: 0
Training loss: 0.6665917038917542
Validation loss: 1.7422245253798783

Epoch: 5| Step: 1
Training loss: 0.4967849850654602
Validation loss: 1.774155124541252

Epoch: 5| Step: 2
Training loss: 0.5651684999465942
Validation loss: 1.7225328991490025

Epoch: 5| Step: 3
Training loss: 0.5871890187263489
Validation loss: 1.77209081316507

Epoch: 5| Step: 4
Training loss: 0.7423998117446899
Validation loss: 1.7724722021369523

Epoch: 5| Step: 5
Training loss: 0.8640127182006836
Validation loss: 1.7507845868346512

Epoch: 5| Step: 6
Training loss: 0.9762323498725891
Validation loss: 1.7794609351824688

Epoch: 5| Step: 7
Training loss: 0.738481879234314
Validation loss: 1.7706896681939401

Epoch: 5| Step: 8
Training loss: 0.3506529629230499
Validation loss: 1.7830912643863308

Epoch: 5| Step: 9
Training loss: 0.37893712520599365
Validation loss: 1.7954796616749098

Epoch: 5| Step: 10
Training loss: 0.7058396339416504
Validation loss: 1.7836409384204495

Epoch: 320| Step: 0
Training loss: 0.5847803354263306
Validation loss: 1.7835706728760914

Epoch: 5| Step: 1
Training loss: 0.7456819415092468
Validation loss: 1.7611307738929667

Epoch: 5| Step: 2
Training loss: 0.3956056237220764
Validation loss: 1.7519996204683859

Epoch: 5| Step: 3
Training loss: 0.746172308921814
Validation loss: 1.7665144410184634

Epoch: 5| Step: 4
Training loss: 0.9583959579467773
Validation loss: 1.7505233339084092

Epoch: 5| Step: 5
Training loss: 0.616112232208252
Validation loss: 1.7710745565352901

Epoch: 5| Step: 6
Training loss: 0.49794235825538635
Validation loss: 1.7467127846133323

Epoch: 5| Step: 7
Training loss: 0.5050585865974426
Validation loss: 1.7535967916570685

Epoch: 5| Step: 8
Training loss: 0.4863432049751282
Validation loss: 1.7691291686027282

Epoch: 5| Step: 9
Training loss: 0.7858275771141052
Validation loss: 1.7564309053523566

Epoch: 5| Step: 10
Training loss: 0.49974754452705383
Validation loss: 1.7404280042135587

Epoch: 321| Step: 0
Training loss: 0.6047478914260864
Validation loss: 1.7395336589505594

Epoch: 5| Step: 1
Training loss: 0.40151506662368774
Validation loss: 1.740084030294931

Epoch: 5| Step: 2
Training loss: 0.5574174523353577
Validation loss: 1.7257290668385004

Epoch: 5| Step: 3
Training loss: 0.7613850831985474
Validation loss: 1.740705164529944

Epoch: 5| Step: 4
Training loss: 0.7390773892402649
Validation loss: 1.733119959472328

Epoch: 5| Step: 5
Training loss: 0.7348041534423828
Validation loss: 1.7267878081208916

Epoch: 5| Step: 6
Training loss: 0.8587549328804016
Validation loss: 1.7217646542415823

Epoch: 5| Step: 7
Training loss: 0.5119989514350891
Validation loss: 1.7457848851398756

Epoch: 5| Step: 8
Training loss: 0.5773156881332397
Validation loss: 1.7965345087871756

Epoch: 5| Step: 9
Training loss: 0.34907856583595276
Validation loss: 1.7338396682534167

Epoch: 5| Step: 10
Training loss: 1.017424464225769
Validation loss: 1.7481627656567482

Epoch: 322| Step: 0
Training loss: 0.6503669023513794
Validation loss: 1.7472440747804538

Epoch: 5| Step: 1
Training loss: 0.71751469373703
Validation loss: 1.752626980504682

Epoch: 5| Step: 2
Training loss: 0.5496311783790588
Validation loss: 1.7670283907203264

Epoch: 5| Step: 3
Training loss: 0.5389291048049927
Validation loss: 1.7599940543533654

Epoch: 5| Step: 4
Training loss: 0.9150489568710327
Validation loss: 1.7620772418155466

Epoch: 5| Step: 5
Training loss: 0.7793486714363098
Validation loss: 1.7478828455812188

Epoch: 5| Step: 6
Training loss: 0.5821906924247742
Validation loss: 1.7617552485517276

Epoch: 5| Step: 7
Training loss: 0.8094808459281921
Validation loss: 1.7516284783681233

Epoch: 5| Step: 8
Training loss: 0.3626171350479126
Validation loss: 1.7418866747169084

Epoch: 5| Step: 9
Training loss: 0.5068073868751526
Validation loss: 1.7750173960962603

Epoch: 5| Step: 10
Training loss: 0.7093381285667419
Validation loss: 1.783114871671123

Epoch: 323| Step: 0
Training loss: 0.7048887014389038
Validation loss: 1.808163458301175

Epoch: 5| Step: 1
Training loss: 1.1030328273773193
Validation loss: 1.7889296162512995

Epoch: 5| Step: 2
Training loss: 0.7732583284378052
Validation loss: 1.7976749943148704

Epoch: 5| Step: 3
Training loss: 0.5672069191932678
Validation loss: 1.7919800230251846

Epoch: 5| Step: 4
Training loss: 0.44076839089393616
Validation loss: 1.7820086902187717

Epoch: 5| Step: 5
Training loss: 0.5617724657058716
Validation loss: 1.8244614280680174

Epoch: 5| Step: 6
Training loss: 0.5528866052627563
Validation loss: 1.8021962617033271

Epoch: 5| Step: 7
Training loss: 0.44040077924728394
Validation loss: 1.7618170784365745

Epoch: 5| Step: 8
Training loss: 0.5885754227638245
Validation loss: 1.7722283255669378

Epoch: 5| Step: 9
Training loss: 0.7416557669639587
Validation loss: 1.7527936927733883

Epoch: 5| Step: 10
Training loss: 0.733333945274353
Validation loss: 1.7736632670125654

Epoch: 324| Step: 0
Training loss: 0.42366114258766174
Validation loss: 1.7870904886594383

Epoch: 5| Step: 1
Training loss: 0.7055508494377136
Validation loss: 1.7886109172656972

Epoch: 5| Step: 2
Training loss: 0.5118808150291443
Validation loss: 1.8018334373351066

Epoch: 5| Step: 3
Training loss: 0.6993986368179321
Validation loss: 1.7862481981195428

Epoch: 5| Step: 4
Training loss: 0.3365701735019684
Validation loss: 1.746465031818677

Epoch: 5| Step: 5
Training loss: 0.8235704302787781
Validation loss: 1.7749993365298036

Epoch: 5| Step: 6
Training loss: 0.5602311491966248
Validation loss: 1.7512405918490501

Epoch: 5| Step: 7
Training loss: 0.6634810566902161
Validation loss: 1.7683317122920867

Epoch: 5| Step: 8
Training loss: 0.5995188355445862
Validation loss: 1.7483289959610149

Epoch: 5| Step: 9
Training loss: 0.6793118715286255
Validation loss: 1.7409682196955527

Epoch: 5| Step: 10
Training loss: 1.099600076675415
Validation loss: 1.7379316783720447

Epoch: 325| Step: 0
Training loss: 0.8727709650993347
Validation loss: 1.7203508948767057

Epoch: 5| Step: 1
Training loss: 0.5882257223129272
Validation loss: 1.7366840198475828

Epoch: 5| Step: 2
Training loss: 0.3149779438972473
Validation loss: 1.7375465362302718

Epoch: 5| Step: 3
Training loss: 0.6439948081970215
Validation loss: 1.7284745554770193

Epoch: 5| Step: 4
Training loss: 0.4723849296569824
Validation loss: 1.7266487229254939

Epoch: 5| Step: 5
Training loss: 0.7996906042098999
Validation loss: 1.750237117531479

Epoch: 5| Step: 6
Training loss: 0.45304030179977417
Validation loss: 1.7780008982586604

Epoch: 5| Step: 7
Training loss: 0.5325740575790405
Validation loss: 1.8058833742654452

Epoch: 5| Step: 8
Training loss: 0.7412935495376587
Validation loss: 1.7716068170403922

Epoch: 5| Step: 9
Training loss: 0.6268664598464966
Validation loss: 1.761872374883262

Epoch: 5| Step: 10
Training loss: 0.6090580224990845
Validation loss: 1.7571700183294152

Epoch: 326| Step: 0
Training loss: 0.5048450827598572
Validation loss: 1.7627730882295998

Epoch: 5| Step: 1
Training loss: 0.528274416923523
Validation loss: 1.7168284795617546

Epoch: 5| Step: 2
Training loss: 0.5842951536178589
Validation loss: 1.7208905168758926

Epoch: 5| Step: 3
Training loss: 0.7620664834976196
Validation loss: 1.7086971447031984

Epoch: 5| Step: 4
Training loss: 0.9412854313850403
Validation loss: 1.7150101174590409

Epoch: 5| Step: 5
Training loss: 0.5431114435195923
Validation loss: 1.7248169940005067

Epoch: 5| Step: 6
Training loss: 0.36452895402908325
Validation loss: 1.722242360473961

Epoch: 5| Step: 7
Training loss: 0.9497464299201965
Validation loss: 1.7918466534665836

Epoch: 5| Step: 8
Training loss: 0.5258576273918152
Validation loss: 1.7676353070043749

Epoch: 5| Step: 9
Training loss: 0.3950832784175873
Validation loss: 1.734068480871057

Epoch: 5| Step: 10
Training loss: 0.5886542797088623
Validation loss: 1.7313076014159827

Epoch: 327| Step: 0
Training loss: 0.5583735704421997
Validation loss: 1.7272282672184769

Epoch: 5| Step: 1
Training loss: 0.7717829942703247
Validation loss: 1.7469460079746861

Epoch: 5| Step: 2
Training loss: 0.7252662181854248
Validation loss: 1.746084333747946

Epoch: 5| Step: 3
Training loss: 0.3840765058994293
Validation loss: 1.7162987929518505

Epoch: 5| Step: 4
Training loss: 0.37556713819503784
Validation loss: 1.7288206584991948

Epoch: 5| Step: 5
Training loss: 0.6104907393455505
Validation loss: 1.7373112414472847

Epoch: 5| Step: 6
Training loss: 0.7094463109970093
Validation loss: 1.7378737721391904

Epoch: 5| Step: 7
Training loss: 0.7105067372322083
Validation loss: 1.8087479132477955

Epoch: 5| Step: 8
Training loss: 0.6478213667869568
Validation loss: 1.8006018630919918

Epoch: 5| Step: 9
Training loss: 0.8184139132499695
Validation loss: 1.7624801076868528

Epoch: 5| Step: 10
Training loss: 0.3766492009162903
Validation loss: 1.740408428253666

Epoch: 328| Step: 0
Training loss: 0.6683919429779053
Validation loss: 1.7509430262350267

Epoch: 5| Step: 1
Training loss: 0.416851669549942
Validation loss: 1.7958381829723236

Epoch: 5| Step: 2
Training loss: 0.7511328458786011
Validation loss: 1.8101457421497633

Epoch: 5| Step: 3
Training loss: 0.7273881435394287
Validation loss: 1.8022676308949788

Epoch: 5| Step: 4
Training loss: 0.5919533967971802
Validation loss: 1.7790316894490232

Epoch: 5| Step: 5
Training loss: 0.4406893849372864
Validation loss: 1.7899646400123514

Epoch: 5| Step: 6
Training loss: 0.7179257273674011
Validation loss: 1.758415118340523

Epoch: 5| Step: 7
Training loss: 0.6682783365249634
Validation loss: 1.7846372947897962

Epoch: 5| Step: 8
Training loss: 0.5804915428161621
Validation loss: 1.748006889897008

Epoch: 5| Step: 9
Training loss: 0.406714528799057
Validation loss: 1.7747594810301257

Epoch: 5| Step: 10
Training loss: 0.6426348090171814
Validation loss: 1.768289477594437

Epoch: 329| Step: 0
Training loss: 0.4938367009162903
Validation loss: 1.743070452444015

Epoch: 5| Step: 1
Training loss: 0.6656042337417603
Validation loss: 1.7594371341889905

Epoch: 5| Step: 2
Training loss: 0.5670350790023804
Validation loss: 1.7585112561461747

Epoch: 5| Step: 3
Training loss: 0.9060968160629272
Validation loss: 1.7424284732469948

Epoch: 5| Step: 4
Training loss: 0.6137418150901794
Validation loss: 1.7933072249094646

Epoch: 5| Step: 5
Training loss: 0.42470550537109375
Validation loss: 1.7483328619310934

Epoch: 5| Step: 6
Training loss: 0.38822945952415466
Validation loss: 1.7463525149130052

Epoch: 5| Step: 7
Training loss: 0.5470958352088928
Validation loss: 1.7764582185335056

Epoch: 5| Step: 8
Training loss: 0.8601713180541992
Validation loss: 1.7944240941796252

Epoch: 5| Step: 9
Training loss: 0.8477455377578735
Validation loss: 1.824698983982045

Epoch: 5| Step: 10
Training loss: 0.2806202173233032
Validation loss: 1.801374299551851

Epoch: 330| Step: 0
Training loss: 0.5372949838638306
Validation loss: 1.75913248139043

Epoch: 5| Step: 1
Training loss: 0.48199495673179626
Validation loss: 1.7741473490192043

Epoch: 5| Step: 2
Training loss: 0.5584093928337097
Validation loss: 1.754941209670036

Epoch: 5| Step: 3
Training loss: 0.6652424931526184
Validation loss: 1.771830105012463

Epoch: 5| Step: 4
Training loss: 0.5945678949356079
Validation loss: 1.8255985295900734

Epoch: 5| Step: 5
Training loss: 0.8033162951469421
Validation loss: 1.8215968173037294

Epoch: 5| Step: 6
Training loss: 0.749104380607605
Validation loss: 1.8014645358567596

Epoch: 5| Step: 7
Training loss: 0.46695271134376526
Validation loss: 1.790619719413019

Epoch: 5| Step: 8
Training loss: 0.5221754908561707
Validation loss: 1.78386567741312

Epoch: 5| Step: 9
Training loss: 0.8799952268600464
Validation loss: 1.8171415739161993

Epoch: 5| Step: 10
Training loss: 0.510526180267334
Validation loss: 1.8307626478133663

Epoch: 331| Step: 0
Training loss: 0.558289647102356
Validation loss: 1.7758869765907206

Epoch: 5| Step: 1
Training loss: 0.5558310747146606
Validation loss: 1.777962323158018

Epoch: 5| Step: 2
Training loss: 0.3884710371494293
Validation loss: 1.754492603322511

Epoch: 5| Step: 3
Training loss: 0.667959451675415
Validation loss: 1.7408348001459593

Epoch: 5| Step: 4
Training loss: 0.4312845766544342
Validation loss: 1.7368050480401644

Epoch: 5| Step: 5
Training loss: 0.8525625467300415
Validation loss: 1.7503879608646515

Epoch: 5| Step: 6
Training loss: 0.7327231764793396
Validation loss: 1.744212999138781

Epoch: 5| Step: 7
Training loss: 1.015989065170288
Validation loss: 1.7552989054751653

Epoch: 5| Step: 8
Training loss: 0.3963702321052551
Validation loss: 1.7414910229303504

Epoch: 5| Step: 9
Training loss: 0.4234095513820648
Validation loss: 1.7264513572057087

Epoch: 5| Step: 10
Training loss: 0.619343101978302
Validation loss: 1.7445814045526649

Epoch: 332| Step: 0
Training loss: 0.6380511522293091
Validation loss: 1.736364838897541

Epoch: 5| Step: 1
Training loss: 0.6114469170570374
Validation loss: 1.7550999849073348

Epoch: 5| Step: 2
Training loss: 0.6332763433456421
Validation loss: 1.7263546810355237

Epoch: 5| Step: 3
Training loss: 0.6575619578361511
Validation loss: 1.7314912055128364

Epoch: 5| Step: 4
Training loss: 0.6705623865127563
Validation loss: 1.6850864759055517

Epoch: 5| Step: 5
Training loss: 0.9544080495834351
Validation loss: 1.7197936824572984

Epoch: 5| Step: 6
Training loss: 0.5127764940261841
Validation loss: 1.6873509909517022

Epoch: 5| Step: 7
Training loss: 0.5219321250915527
Validation loss: 1.7171106223137147

Epoch: 5| Step: 8
Training loss: 0.3975614607334137
Validation loss: 1.7134356729445919

Epoch: 5| Step: 9
Training loss: 0.37070900201797485
Validation loss: 1.7245031031229163

Epoch: 5| Step: 10
Training loss: 0.48549944162368774
Validation loss: 1.7296589920597691

Epoch: 333| Step: 0
Training loss: 0.6598893404006958
Validation loss: 1.7676209980441677

Epoch: 5| Step: 1
Training loss: 0.6279808878898621
Validation loss: 1.7621833906378797

Epoch: 5| Step: 2
Training loss: 0.5942532420158386
Validation loss: 1.7629263811213995

Epoch: 5| Step: 3
Training loss: 0.7648749351501465
Validation loss: 1.7210095082559893

Epoch: 5| Step: 4
Training loss: 0.6680628061294556
Validation loss: 1.7319864508926228

Epoch: 5| Step: 5
Training loss: 0.48338454961776733
Validation loss: 1.7186392943064372

Epoch: 5| Step: 6
Training loss: 0.7082279324531555
Validation loss: 1.72017414082763

Epoch: 5| Step: 7
Training loss: 0.39799338579177856
Validation loss: 1.7092896969087663

Epoch: 5| Step: 8
Training loss: 0.6331223249435425
Validation loss: 1.7241315790401992

Epoch: 5| Step: 9
Training loss: 0.19910244643688202
Validation loss: 1.683171764496834

Epoch: 5| Step: 10
Training loss: 0.47313836216926575
Validation loss: 1.7173793123614403

Epoch: 334| Step: 0
Training loss: 0.48072633147239685
Validation loss: 1.7113135655721028

Epoch: 5| Step: 1
Training loss: 0.4155847430229187
Validation loss: 1.713683618012295

Epoch: 5| Step: 2
Training loss: 0.8098320960998535
Validation loss: 1.7140437979852

Epoch: 5| Step: 3
Training loss: 0.472205251455307
Validation loss: 1.7354982796535696

Epoch: 5| Step: 4
Training loss: 0.5568010210990906
Validation loss: 1.7907031633520638

Epoch: 5| Step: 5
Training loss: 0.7610067129135132
Validation loss: 1.7753965982826807

Epoch: 5| Step: 6
Training loss: 0.3431303799152374
Validation loss: 1.7467019096497567

Epoch: 5| Step: 7
Training loss: 0.5690085887908936
Validation loss: 1.685323974137665

Epoch: 5| Step: 8
Training loss: 0.4822273850440979
Validation loss: 1.6981800089600265

Epoch: 5| Step: 9
Training loss: 0.8097807765007019
Validation loss: 1.6923091052680888

Epoch: 5| Step: 10
Training loss: 0.4811653792858124
Validation loss: 1.6800590253645373

Epoch: 335| Step: 0
Training loss: 0.4051629900932312
Validation loss: 1.6764635257823493

Epoch: 5| Step: 1
Training loss: 0.5691403150558472
Validation loss: 1.6624987548397434

Epoch: 5| Step: 2
Training loss: 0.606392502784729
Validation loss: 1.6790725633662233

Epoch: 5| Step: 3
Training loss: 0.44691896438598633
Validation loss: 1.6923210287606845

Epoch: 5| Step: 4
Training loss: 0.3994666635990143
Validation loss: 1.7419159168838172

Epoch: 5| Step: 5
Training loss: 0.831048846244812
Validation loss: 1.7861400317120295

Epoch: 5| Step: 6
Training loss: 0.5754382610321045
Validation loss: 1.7852440264917189

Epoch: 5| Step: 7
Training loss: 0.6318343281745911
Validation loss: 1.7560518710843978

Epoch: 5| Step: 8
Training loss: 0.49642109870910645
Validation loss: 1.7196138776758665

Epoch: 5| Step: 9
Training loss: 0.7597392797470093
Validation loss: 1.7028512108710505

Epoch: 5| Step: 10
Training loss: 0.49602049589157104
Validation loss: 1.7168880457519202

Epoch: 336| Step: 0
Training loss: 0.3634844124317169
Validation loss: 1.7331379536659486

Epoch: 5| Step: 1
Training loss: 0.3815678656101227
Validation loss: 1.7086369895165967

Epoch: 5| Step: 2
Training loss: 0.6348839402198792
Validation loss: 1.7266990856457782

Epoch: 5| Step: 3
Training loss: 0.5949594974517822
Validation loss: 1.735890596143661

Epoch: 5| Step: 4
Training loss: 0.35177549719810486
Validation loss: 1.743281772059779

Epoch: 5| Step: 5
Training loss: 0.5841715335845947
Validation loss: 1.7827415197126326

Epoch: 5| Step: 6
Training loss: 0.7208095788955688
Validation loss: 1.780753876573296

Epoch: 5| Step: 7
Training loss: 0.4432474672794342
Validation loss: 1.7681208451588948

Epoch: 5| Step: 8
Training loss: 0.5643650889396667
Validation loss: 1.7643496785112607

Epoch: 5| Step: 9
Training loss: 0.5659427642822266
Validation loss: 1.7550964381105156

Epoch: 5| Step: 10
Training loss: 0.6385939717292786
Validation loss: 1.7412607810830558

Epoch: 337| Step: 0
Training loss: 0.6231287717819214
Validation loss: 1.7502271244602818

Epoch: 5| Step: 1
Training loss: 0.4433351457118988
Validation loss: 1.7816626461603309

Epoch: 5| Step: 2
Training loss: 0.46874547004699707
Validation loss: 1.7702908157020487

Epoch: 5| Step: 3
Training loss: 0.4262630045413971
Validation loss: 1.765568628106066

Epoch: 5| Step: 4
Training loss: 0.5229268074035645
Validation loss: 1.7700948638300742

Epoch: 5| Step: 5
Training loss: 0.7202379107475281
Validation loss: 1.7505835948451873

Epoch: 5| Step: 6
Training loss: 0.6545466780662537
Validation loss: 1.7695504785865865

Epoch: 5| Step: 7
Training loss: 0.38139063119888306
Validation loss: 1.7600005865097046

Epoch: 5| Step: 8
Training loss: 0.6173631548881531
Validation loss: 1.7485038106159498

Epoch: 5| Step: 9
Training loss: 0.3583706319332123
Validation loss: 1.7532625172727851

Epoch: 5| Step: 10
Training loss: 0.5902866721153259
Validation loss: 1.7605897559914538

Epoch: 338| Step: 0
Training loss: 0.3647688627243042
Validation loss: 1.7320870507148005

Epoch: 5| Step: 1
Training loss: 0.5462628602981567
Validation loss: 1.7253962562930198

Epoch: 5| Step: 2
Training loss: 0.33665138483047485
Validation loss: 1.7230997880299885

Epoch: 5| Step: 3
Training loss: 0.7813184261322021
Validation loss: 1.7062486833141697

Epoch: 5| Step: 4
Training loss: 0.3753373324871063
Validation loss: 1.6802916206339353

Epoch: 5| Step: 5
Training loss: 0.5303272008895874
Validation loss: 1.6865363601715333

Epoch: 5| Step: 6
Training loss: 0.3361953794956207
Validation loss: 1.7058084421260382

Epoch: 5| Step: 7
Training loss: 0.5578913688659668
Validation loss: 1.7226013445085095

Epoch: 5| Step: 8
Training loss: 0.5832256078720093
Validation loss: 1.7187674366017824

Epoch: 5| Step: 9
Training loss: 0.5563656091690063
Validation loss: 1.70831266526253

Epoch: 5| Step: 10
Training loss: 0.8402823209762573
Validation loss: 1.720365370473554

Epoch: 339| Step: 0
Training loss: 0.6063339114189148
Validation loss: 1.732280101827396

Epoch: 5| Step: 1
Training loss: 0.5532083511352539
Validation loss: 1.7364465722473719

Epoch: 5| Step: 2
Training loss: 0.5613420605659485
Validation loss: 1.752329590500042

Epoch: 5| Step: 3
Training loss: 0.33935269713401794
Validation loss: 1.7538593110217844

Epoch: 5| Step: 4
Training loss: 0.346235454082489
Validation loss: 1.725211234502895

Epoch: 5| Step: 5
Training loss: 0.42898550629615784
Validation loss: 1.725894780569179

Epoch: 5| Step: 6
Training loss: 0.1462574303150177
Validation loss: 1.7090130108658985

Epoch: 5| Step: 7
Training loss: 1.0210705995559692
Validation loss: 1.7116463197174894

Epoch: 5| Step: 8
Training loss: 0.7362425923347473
Validation loss: 1.7150171956708353

Epoch: 5| Step: 9
Training loss: 0.588182270526886
Validation loss: 1.7481446983993694

Epoch: 5| Step: 10
Training loss: 0.6199129819869995
Validation loss: 1.7710279405757945

Epoch: 340| Step: 0
Training loss: 0.3787814676761627
Validation loss: 1.7423629132650231

Epoch: 5| Step: 1
Training loss: 0.5594779849052429
Validation loss: 1.7530582515142297

Epoch: 5| Step: 2
Training loss: 0.463542640209198
Validation loss: 1.741761040943925

Epoch: 5| Step: 3
Training loss: 0.4114166796207428
Validation loss: 1.724916217147663

Epoch: 5| Step: 4
Training loss: 0.460420697927475
Validation loss: 1.729023891110574

Epoch: 5| Step: 5
Training loss: 0.7436748743057251
Validation loss: 1.736542300511432

Epoch: 5| Step: 6
Training loss: 0.4928351938724518
Validation loss: 1.7409448444202382

Epoch: 5| Step: 7
Training loss: 0.5992009043693542
Validation loss: 1.768040903152958

Epoch: 5| Step: 8
Training loss: 0.5695947408676147
Validation loss: 1.7672737836837769

Epoch: 5| Step: 9
Training loss: 0.5550624132156372
Validation loss: 1.7988265124700402

Epoch: 5| Step: 10
Training loss: 0.6644744873046875
Validation loss: 1.8257123693343131

Epoch: 341| Step: 0
Training loss: 0.5934447646141052
Validation loss: 1.832166237215842

Epoch: 5| Step: 1
Training loss: 0.5473588705062866
Validation loss: 1.797736890854374

Epoch: 5| Step: 2
Training loss: 0.493504136800766
Validation loss: 1.7899155257850565

Epoch: 5| Step: 3
Training loss: 0.5184696316719055
Validation loss: 1.7822515785053212

Epoch: 5| Step: 4
Training loss: 0.2997262477874756
Validation loss: 1.7608161933960453

Epoch: 5| Step: 5
Training loss: 0.7474088072776794
Validation loss: 1.7173793238978232

Epoch: 5| Step: 6
Training loss: 0.6226585507392883
Validation loss: 1.751350587414157

Epoch: 5| Step: 7
Training loss: 0.40283632278442383
Validation loss: 1.696720652682807

Epoch: 5| Step: 8
Training loss: 0.34274551272392273
Validation loss: 1.7199882102268997

Epoch: 5| Step: 9
Training loss: 0.6482915878295898
Validation loss: 1.7625937269579979

Epoch: 5| Step: 10
Training loss: 0.5791844129562378
Validation loss: 1.7632794239187752

Epoch: 342| Step: 0
Training loss: 0.4354632496833801
Validation loss: 1.7324728888850058

Epoch: 5| Step: 1
Training loss: 0.628079891204834
Validation loss: 1.7368090332195323

Epoch: 5| Step: 2
Training loss: 0.581574559211731
Validation loss: 1.6982340261500368

Epoch: 5| Step: 3
Training loss: 0.4414590299129486
Validation loss: 1.7218743806244226

Epoch: 5| Step: 4
Training loss: 0.5358670949935913
Validation loss: 1.7469605809898787

Epoch: 5| Step: 5
Training loss: 0.4911056160926819
Validation loss: 1.7406641975525887

Epoch: 5| Step: 6
Training loss: 0.5346868634223938
Validation loss: 1.732827143002582

Epoch: 5| Step: 7
Training loss: 0.4381096363067627
Validation loss: 1.755837409727035

Epoch: 5| Step: 8
Training loss: 0.8544782400131226
Validation loss: 1.7574429114659627

Epoch: 5| Step: 9
Training loss: 0.4115481972694397
Validation loss: 1.7788097819974344

Epoch: 5| Step: 10
Training loss: 0.34160321950912476
Validation loss: 1.7526520657283005

Epoch: 343| Step: 0
Training loss: 0.5740247964859009
Validation loss: 1.7735000861588346

Epoch: 5| Step: 1
Training loss: 0.6219626069068909
Validation loss: 1.778384365061278

Epoch: 5| Step: 2
Training loss: 0.46850091218948364
Validation loss: 1.7716380947379655

Epoch: 5| Step: 3
Training loss: 0.36287111043930054
Validation loss: 1.7789701390010055

Epoch: 5| Step: 4
Training loss: 0.5909538269042969
Validation loss: 1.7822366734986663

Epoch: 5| Step: 5
Training loss: 0.7625269889831543
Validation loss: 1.7832143511823428

Epoch: 5| Step: 6
Training loss: 0.352235347032547
Validation loss: 1.786720448924649

Epoch: 5| Step: 7
Training loss: 0.5037021636962891
Validation loss: 1.7548492185531124

Epoch: 5| Step: 8
Training loss: 0.5440276861190796
Validation loss: 1.7579521415054158

Epoch: 5| Step: 9
Training loss: 0.5148199796676636
Validation loss: 1.7277129555261264

Epoch: 5| Step: 10
Training loss: 0.4584890604019165
Validation loss: 1.7394759565271356

Epoch: 344| Step: 0
Training loss: 0.42199668288230896
Validation loss: 1.7331279631583922

Epoch: 5| Step: 1
Training loss: 0.6487373113632202
Validation loss: 1.7276487837555587

Epoch: 5| Step: 2
Training loss: 0.4737664759159088
Validation loss: 1.7360251308769308

Epoch: 5| Step: 3
Training loss: 0.4400615692138672
Validation loss: 1.7523818016052246

Epoch: 5| Step: 4
Training loss: 0.39365458488464355
Validation loss: 1.7126334405714465

Epoch: 5| Step: 5
Training loss: 0.4456261098384857
Validation loss: 1.7061469131900417

Epoch: 5| Step: 6
Training loss: 0.5360597372055054
Validation loss: 1.7040285448874197

Epoch: 5| Step: 7
Training loss: 0.6217713356018066
Validation loss: 1.7433607475731963

Epoch: 5| Step: 8
Training loss: 0.7374607920646667
Validation loss: 1.7339844511401268

Epoch: 5| Step: 9
Training loss: 0.36266404390335083
Validation loss: 1.742963760129867

Epoch: 5| Step: 10
Training loss: 0.5199952721595764
Validation loss: 1.7392162866489862

Epoch: 345| Step: 0
Training loss: 0.5601524710655212
Validation loss: 1.732578641624861

Epoch: 5| Step: 1
Training loss: 0.6117516160011292
Validation loss: 1.7079354229793753

Epoch: 5| Step: 2
Training loss: 0.6992648243904114
Validation loss: 1.7158998340688727

Epoch: 5| Step: 3
Training loss: 0.4624306261539459
Validation loss: 1.7202226205538678

Epoch: 5| Step: 4
Training loss: 0.4113021790981293
Validation loss: 1.7440914800090175

Epoch: 5| Step: 5
Training loss: 0.627061665058136
Validation loss: 1.7232441998297168

Epoch: 5| Step: 6
Training loss: 0.5041735768318176
Validation loss: 1.710072535340504

Epoch: 5| Step: 7
Training loss: 0.374073326587677
Validation loss: 1.6954437340459516

Epoch: 5| Step: 8
Training loss: 0.25461140275001526
Validation loss: 1.7251130329665316

Epoch: 5| Step: 9
Training loss: 0.25340813398361206
Validation loss: 1.7302199909763951

Epoch: 5| Step: 10
Training loss: 0.4987144470214844
Validation loss: 1.6987452865928732

Epoch: 346| Step: 0
Training loss: 0.42887958884239197
Validation loss: 1.6933446033026582

Epoch: 5| Step: 1
Training loss: 0.45633330941200256
Validation loss: 1.710781951104441

Epoch: 5| Step: 2
Training loss: 0.8527480363845825
Validation loss: 1.6909155576459822

Epoch: 5| Step: 3
Training loss: 0.6119418144226074
Validation loss: 1.6782943176966842

Epoch: 5| Step: 4
Training loss: 0.3711763918399811
Validation loss: 1.690803797014298

Epoch: 5| Step: 5
Training loss: 0.2965618073940277
Validation loss: 1.7027566843135382

Epoch: 5| Step: 6
Training loss: 0.4648107588291168
Validation loss: 1.6984106750898464

Epoch: 5| Step: 7
Training loss: 0.7971398234367371
Validation loss: 1.6875586407158965

Epoch: 5| Step: 8
Training loss: 0.4587832987308502
Validation loss: 1.711534692395118

Epoch: 5| Step: 9
Training loss: 0.3037548065185547
Validation loss: 1.757085830934586

Epoch: 5| Step: 10
Training loss: 0.34588271379470825
Validation loss: 1.7657166757891256

Epoch: 347| Step: 0
Training loss: 0.7447773814201355
Validation loss: 1.742383219862497

Epoch: 5| Step: 1
Training loss: 0.3288342356681824
Validation loss: 1.7040620106522755

Epoch: 5| Step: 2
Training loss: 0.3714263439178467
Validation loss: 1.6942006279063482

Epoch: 5| Step: 3
Training loss: 0.3501645028591156
Validation loss: 1.6895874610511206

Epoch: 5| Step: 4
Training loss: 0.5037105083465576
Validation loss: 1.6982761634293424

Epoch: 5| Step: 5
Training loss: 0.48514214158058167
Validation loss: 1.7182235230681717

Epoch: 5| Step: 6
Training loss: 0.43772226572036743
Validation loss: 1.7075847169404388

Epoch: 5| Step: 7
Training loss: 0.755372941493988
Validation loss: 1.7086666425069172

Epoch: 5| Step: 8
Training loss: 0.4951102137565613
Validation loss: 1.7129170945895615

Epoch: 5| Step: 9
Training loss: 0.3438597619533539
Validation loss: 1.702290210672604

Epoch: 5| Step: 10
Training loss: 0.5690242052078247
Validation loss: 1.7220863949867986

Epoch: 348| Step: 0
Training loss: 0.4635079503059387
Validation loss: 1.731958555918868

Epoch: 5| Step: 1
Training loss: 0.43396130204200745
Validation loss: 1.7243709359117734

Epoch: 5| Step: 2
Training loss: 0.4528082013130188
Validation loss: 1.7009533720631753

Epoch: 5| Step: 3
Training loss: 0.31473875045776367
Validation loss: 1.7186527303470078

Epoch: 5| Step: 4
Training loss: 0.3761201798915863
Validation loss: 1.7086800772656676

Epoch: 5| Step: 5
Training loss: 0.391514390707016
Validation loss: 1.7200761033642677

Epoch: 5| Step: 6
Training loss: 0.5026044845581055
Validation loss: 1.689048505598499

Epoch: 5| Step: 7
Training loss: 0.7208350896835327
Validation loss: 1.6942997978579613

Epoch: 5| Step: 8
Training loss: 0.4605652689933777
Validation loss: 1.7359518697184901

Epoch: 5| Step: 9
Training loss: 0.42128604650497437
Validation loss: 1.768535972923361

Epoch: 5| Step: 10
Training loss: 0.6747117638587952
Validation loss: 1.7632658507234307

Epoch: 349| Step: 0
Training loss: 0.4650042653083801
Validation loss: 1.7677845288348455

Epoch: 5| Step: 1
Training loss: 0.349127858877182
Validation loss: 1.7849683774414884

Epoch: 5| Step: 2
Training loss: 0.4096313416957855
Validation loss: 1.7457397522464875

Epoch: 5| Step: 3
Training loss: 0.6114639043807983
Validation loss: 1.7117920062875236

Epoch: 5| Step: 4
Training loss: 0.5119894742965698
Validation loss: 1.6918698356997581

Epoch: 5| Step: 5
Training loss: 0.595003604888916
Validation loss: 1.6998028165550643

Epoch: 5| Step: 6
Training loss: 0.6001221537590027
Validation loss: 1.6920119485547465

Epoch: 5| Step: 7
Training loss: 0.38722795248031616
Validation loss: 1.7122527642916607

Epoch: 5| Step: 8
Training loss: 0.46193036437034607
Validation loss: 1.7142893652762137

Epoch: 5| Step: 9
Training loss: 0.4806344509124756
Validation loss: 1.7083846433188326

Epoch: 5| Step: 10
Training loss: 0.4163549244403839
Validation loss: 1.7190568242021786

Epoch: 350| Step: 0
Training loss: 0.22725911438465118
Validation loss: 1.7099462516846196

Epoch: 5| Step: 1
Training loss: 0.5659500956535339
Validation loss: 1.7172014380014071

Epoch: 5| Step: 2
Training loss: 0.6222318410873413
Validation loss: 1.734353683328116

Epoch: 5| Step: 3
Training loss: 0.47350454330444336
Validation loss: 1.7531169242756341

Epoch: 5| Step: 4
Training loss: 0.4228671193122864
Validation loss: 1.769710902244814

Epoch: 5| Step: 5
Training loss: 0.6365116834640503
Validation loss: 1.7514266275590467

Epoch: 5| Step: 6
Training loss: 0.49968838691711426
Validation loss: 1.7400756343718498

Epoch: 5| Step: 7
Training loss: 0.4363035559654236
Validation loss: 1.76200698268029

Epoch: 5| Step: 8
Training loss: 0.3856244385242462
Validation loss: 1.7309933042013517

Epoch: 5| Step: 9
Training loss: 0.6350100636482239
Validation loss: 1.7386022844622213

Epoch: 5| Step: 10
Training loss: 0.32720908522605896
Validation loss: 1.740466530605029

Epoch: 351| Step: 0
Training loss: 0.6412284970283508
Validation loss: 1.7331757045561267

Epoch: 5| Step: 1
Training loss: 0.33009377121925354
Validation loss: 1.7279986643022107

Epoch: 5| Step: 2
Training loss: 0.47182297706604004
Validation loss: 1.696273487101319

Epoch: 5| Step: 3
Training loss: 0.5288828015327454
Validation loss: 1.7241778258354432

Epoch: 5| Step: 4
Training loss: 0.537466824054718
Validation loss: 1.7131996635467774

Epoch: 5| Step: 5
Training loss: 0.25637203454971313
Validation loss: 1.7088607767576813

Epoch: 5| Step: 6
Training loss: 0.31095510721206665
Validation loss: 1.713434237305836

Epoch: 5| Step: 7
Training loss: 0.416909396648407
Validation loss: 1.6872359885964343

Epoch: 5| Step: 8
Training loss: 0.22688134014606476
Validation loss: 1.693885068098704

Epoch: 5| Step: 9
Training loss: 0.8512401580810547
Validation loss: 1.718690026190973

Epoch: 5| Step: 10
Training loss: 0.5805062651634216
Validation loss: 1.7390820518616708

Epoch: 352| Step: 0
Training loss: 0.6685795783996582
Validation loss: 1.7213976895937355

Epoch: 5| Step: 1
Training loss: 0.3134157061576843
Validation loss: 1.7346275121934953

Epoch: 5| Step: 2
Training loss: 0.629494845867157
Validation loss: 1.7627619799747263

Epoch: 5| Step: 3
Training loss: 0.34474965929985046
Validation loss: 1.744586657452327

Epoch: 5| Step: 4
Training loss: 0.5568020939826965
Validation loss: 1.7237717054223503

Epoch: 5| Step: 5
Training loss: 0.3487629294395447
Validation loss: 1.7103421098442488

Epoch: 5| Step: 6
Training loss: 0.4357244372367859
Validation loss: 1.7300377391999768

Epoch: 5| Step: 7
Training loss: 0.45001205801963806
Validation loss: 1.7441306614106702

Epoch: 5| Step: 8
Training loss: 0.4190296530723572
Validation loss: 1.7356685002644856

Epoch: 5| Step: 9
Training loss: 0.5506991147994995
Validation loss: 1.741112365517565

Epoch: 5| Step: 10
Training loss: 0.3891751766204834
Validation loss: 1.7231809695561726

Epoch: 353| Step: 0
Training loss: 0.47453221678733826
Validation loss: 1.7483303572541924

Epoch: 5| Step: 1
Training loss: 0.4587201476097107
Validation loss: 1.7185453548226306

Epoch: 5| Step: 2
Training loss: 0.2745893597602844
Validation loss: 1.756021272751593

Epoch: 5| Step: 3
Training loss: 0.42543715238571167
Validation loss: 1.7213038167645853

Epoch: 5| Step: 4
Training loss: 0.7197602391242981
Validation loss: 1.7162602434876144

Epoch: 5| Step: 5
Training loss: 0.5907500386238098
Validation loss: 1.7219657551857732

Epoch: 5| Step: 6
Training loss: 0.5643593668937683
Validation loss: 1.7153431471957956

Epoch: 5| Step: 7
Training loss: 0.3921875059604645
Validation loss: 1.700845056964505

Epoch: 5| Step: 8
Training loss: 0.2864244282245636
Validation loss: 1.6924045880635579

Epoch: 5| Step: 9
Training loss: 0.4085931181907654
Validation loss: 1.7084291250474992

Epoch: 5| Step: 10
Training loss: 0.30049601197242737
Validation loss: 1.7104228786242905

Epoch: 354| Step: 0
Training loss: 0.41428107023239136
Validation loss: 1.729063130194141

Epoch: 5| Step: 1
Training loss: 0.11980626732110977
Validation loss: 1.7000865551733202

Epoch: 5| Step: 2
Training loss: 0.5114706754684448
Validation loss: 1.698931086447931

Epoch: 5| Step: 3
Training loss: 0.4147055745124817
Validation loss: 1.7145997285842896

Epoch: 5| Step: 4
Training loss: 0.20031651854515076
Validation loss: 1.715066473971131

Epoch: 5| Step: 5
Training loss: 0.5270837545394897
Validation loss: 1.7252648440740441

Epoch: 5| Step: 6
Training loss: 0.3256339132785797
Validation loss: 1.728991703320575

Epoch: 5| Step: 7
Training loss: 0.6208721399307251
Validation loss: 1.7362502544156966

Epoch: 5| Step: 8
Training loss: 0.6191989779472351
Validation loss: 1.745667221725628

Epoch: 5| Step: 9
Training loss: 0.4896583557128906
Validation loss: 1.7338759745320966

Epoch: 5| Step: 10
Training loss: 0.7051998972892761
Validation loss: 1.7046102657113025

Epoch: 355| Step: 0
Training loss: 0.8264690637588501
Validation loss: 1.7002389200272099

Epoch: 5| Step: 1
Training loss: 0.5031073689460754
Validation loss: 1.7012306797888972

Epoch: 5| Step: 2
Training loss: 0.4197355806827545
Validation loss: 1.7303320348903697

Epoch: 5| Step: 3
Training loss: 0.5106534361839294
Validation loss: 1.7137364572094334

Epoch: 5| Step: 4
Training loss: 0.42484864592552185
Validation loss: 1.7555949867412608

Epoch: 5| Step: 5
Training loss: 0.2589019238948822
Validation loss: 1.7343440991576

Epoch: 5| Step: 6
Training loss: 0.497774600982666
Validation loss: 1.7342962821324666

Epoch: 5| Step: 7
Training loss: 0.42272377014160156
Validation loss: 1.703824027892082

Epoch: 5| Step: 8
Training loss: 0.44719043374061584
Validation loss: 1.7113298908356698

Epoch: 5| Step: 9
Training loss: 0.3645235300064087
Validation loss: 1.7489848265083887

Epoch: 5| Step: 10
Training loss: 0.26863405108451843
Validation loss: 1.7166420746875066

Epoch: 356| Step: 0
Training loss: 0.3614588677883148
Validation loss: 1.7021760889278945

Epoch: 5| Step: 1
Training loss: 0.30433976650238037
Validation loss: 1.7128230294873636

Epoch: 5| Step: 2
Training loss: 0.2939368784427643
Validation loss: 1.741874897351829

Epoch: 5| Step: 3
Training loss: 0.6513698697090149
Validation loss: 1.7122583427736837

Epoch: 5| Step: 4
Training loss: 0.48522987961769104
Validation loss: 1.7098097250025759

Epoch: 5| Step: 5
Training loss: 0.58893221616745
Validation loss: 1.729925876022667

Epoch: 5| Step: 6
Training loss: 0.31176599860191345
Validation loss: 1.7413065100228915

Epoch: 5| Step: 7
Training loss: 0.46879878640174866
Validation loss: 1.7096299029165698

Epoch: 5| Step: 8
Training loss: 0.33928894996643066
Validation loss: 1.704772154490153

Epoch: 5| Step: 9
Training loss: 0.5276521444320679
Validation loss: 1.703911424964987

Epoch: 5| Step: 10
Training loss: 0.5411848425865173
Validation loss: 1.7032431658878122

Epoch: 357| Step: 0
Training loss: 0.36809420585632324
Validation loss: 1.7029327961706346

Epoch: 5| Step: 1
Training loss: 0.27036699652671814
Validation loss: 1.721341856064335

Epoch: 5| Step: 2
Training loss: 0.36355048418045044
Validation loss: 1.7271470728740896

Epoch: 5| Step: 3
Training loss: 0.5356021523475647
Validation loss: 1.7516268940382107

Epoch: 5| Step: 4
Training loss: 0.508288562297821
Validation loss: 1.7601379258658296

Epoch: 5| Step: 5
Training loss: 0.6448062062263489
Validation loss: 1.765432761561486

Epoch: 5| Step: 6
Training loss: 0.7102876901626587
Validation loss: 1.7479907678019615

Epoch: 5| Step: 7
Training loss: 0.3042592406272888
Validation loss: 1.7698450242319415

Epoch: 5| Step: 8
Training loss: 0.610926628112793
Validation loss: 1.747616914010817

Epoch: 5| Step: 9
Training loss: 0.24923749268054962
Validation loss: 1.7573715871380222

Epoch: 5| Step: 10
Training loss: 0.5263320803642273
Validation loss: 1.7350210130855601

Epoch: 358| Step: 0
Training loss: 0.586679220199585
Validation loss: 1.7215778622575986

Epoch: 5| Step: 1
Training loss: 0.31497737765312195
Validation loss: 1.705626259567917

Epoch: 5| Step: 2
Training loss: 0.3187878727912903
Validation loss: 1.7319226957136584

Epoch: 5| Step: 3
Training loss: 0.5171686410903931
Validation loss: 1.7269773880640666

Epoch: 5| Step: 4
Training loss: 0.4494875967502594
Validation loss: 1.7085654171564246

Epoch: 5| Step: 5
Training loss: 0.499802827835083
Validation loss: 1.7129080295562744

Epoch: 5| Step: 6
Training loss: 0.22213926911354065
Validation loss: 1.7306651056453746

Epoch: 5| Step: 7
Training loss: 0.362605482339859
Validation loss: 1.7414009647984658

Epoch: 5| Step: 8
Training loss: 0.7581637501716614
Validation loss: 1.729470633691357

Epoch: 5| Step: 9
Training loss: 0.26075220108032227
Validation loss: 1.7415132496946601

Epoch: 5| Step: 10
Training loss: 0.47112059593200684
Validation loss: 1.7492459243343723

Epoch: 359| Step: 0
Training loss: 0.5398493409156799
Validation loss: 1.7555752761902348

Epoch: 5| Step: 1
Training loss: 0.19791646301746368
Validation loss: 1.7245176428107805

Epoch: 5| Step: 2
Training loss: 0.4534366726875305
Validation loss: 1.7279272899832776

Epoch: 5| Step: 3
Training loss: 0.45492076873779297
Validation loss: 1.717464280384843

Epoch: 5| Step: 4
Training loss: 0.2876332402229309
Validation loss: 1.725645193489649

Epoch: 5| Step: 5
Training loss: 0.48148059844970703
Validation loss: 1.704567728504058

Epoch: 5| Step: 6
Training loss: 0.5464047193527222
Validation loss: 1.694286730340732

Epoch: 5| Step: 7
Training loss: 0.45602235198020935
Validation loss: 1.675798459719586

Epoch: 5| Step: 8
Training loss: 0.448821485042572
Validation loss: 1.6698088966390139

Epoch: 5| Step: 9
Training loss: 0.5474435091018677
Validation loss: 1.6655995871431084

Epoch: 5| Step: 10
Training loss: 0.465373158454895
Validation loss: 1.6816265916311612

Epoch: 360| Step: 0
Training loss: 0.4023827612400055
Validation loss: 1.7025337590966174

Epoch: 5| Step: 1
Training loss: 0.4687843322753906
Validation loss: 1.7302557473541589

Epoch: 5| Step: 2
Training loss: 0.19152727723121643
Validation loss: 1.7126341276271368

Epoch: 5| Step: 3
Training loss: 0.5255115628242493
Validation loss: 1.682185980581468

Epoch: 5| Step: 4
Training loss: 0.6373685002326965
Validation loss: 1.6849556840876097

Epoch: 5| Step: 5
Training loss: 0.11457685381174088
Validation loss: 1.6988517366429812

Epoch: 5| Step: 6
Training loss: 0.429586797952652
Validation loss: 1.6886475547667472

Epoch: 5| Step: 7
Training loss: 0.3935568630695343
Validation loss: 1.712098289561528

Epoch: 5| Step: 8
Training loss: 0.5119045972824097
Validation loss: 1.7183187136086084

Epoch: 5| Step: 9
Training loss: 0.48980140686035156
Validation loss: 1.757118082815601

Epoch: 5| Step: 10
Training loss: 0.5308173894882202
Validation loss: 1.7272089706954135

Epoch: 361| Step: 0
Training loss: 0.40955400466918945
Validation loss: 1.755182748199791

Epoch: 5| Step: 1
Training loss: 0.3166736960411072
Validation loss: 1.7343103616468367

Epoch: 5| Step: 2
Training loss: 0.5363907217979431
Validation loss: 1.7129110918250134

Epoch: 5| Step: 3
Training loss: 0.607071042060852
Validation loss: 1.7007759860766831

Epoch: 5| Step: 4
Training loss: 0.36018437147140503
Validation loss: 1.6976301798256495

Epoch: 5| Step: 5
Training loss: 0.19740910828113556
Validation loss: 1.683250746419353

Epoch: 5| Step: 6
Training loss: 0.34984979033470154
Validation loss: 1.6592493851979573

Epoch: 5| Step: 7
Training loss: 0.4671022295951843
Validation loss: 1.6619023789641678

Epoch: 5| Step: 8
Training loss: 0.5454281568527222
Validation loss: 1.650261689257878

Epoch: 5| Step: 9
Training loss: 0.5610266923904419
Validation loss: 1.675823978839382

Epoch: 5| Step: 10
Training loss: 0.2362329214811325
Validation loss: 1.6723785746482112

Epoch: 362| Step: 0
Training loss: 0.392383337020874
Validation loss: 1.6575926144917805

Epoch: 5| Step: 1
Training loss: 0.3632979393005371
Validation loss: 1.6921881462938042

Epoch: 5| Step: 2
Training loss: 0.31892138719558716
Validation loss: 1.6879835192875197

Epoch: 5| Step: 3
Training loss: 0.38927701115608215
Validation loss: 1.6852015513245777

Epoch: 5| Step: 4
Training loss: 0.41121840476989746
Validation loss: 1.7026796340942383

Epoch: 5| Step: 5
Training loss: 0.24868425726890564
Validation loss: 1.679840322463743

Epoch: 5| Step: 6
Training loss: 0.5204925537109375
Validation loss: 1.6748444893026864

Epoch: 5| Step: 7
Training loss: 0.43687868118286133
Validation loss: 1.6849384615498204

Epoch: 5| Step: 8
Training loss: 0.49708253145217896
Validation loss: 1.6575497273475892

Epoch: 5| Step: 9
Training loss: 0.25103282928466797
Validation loss: 1.6578059452836231

Epoch: 5| Step: 10
Training loss: 0.8061696290969849
Validation loss: 1.6543104469135244

Epoch: 363| Step: 0
Training loss: 0.34159669280052185
Validation loss: 1.6616127772997784

Epoch: 5| Step: 1
Training loss: 0.15870067477226257
Validation loss: 1.6766930485284457

Epoch: 5| Step: 2
Training loss: 0.3442060947418213
Validation loss: 1.6726254455504879

Epoch: 5| Step: 3
Training loss: 0.5005795359611511
Validation loss: 1.6941308641946444

Epoch: 5| Step: 4
Training loss: 0.3100723326206207
Validation loss: 1.712853370174285

Epoch: 5| Step: 5
Training loss: 0.3715166747570038
Validation loss: 1.681663595220094

Epoch: 5| Step: 6
Training loss: 0.5872218012809753
Validation loss: 1.6774899575018114

Epoch: 5| Step: 7
Training loss: 0.6815685033798218
Validation loss: 1.6927503962670603

Epoch: 5| Step: 8
Training loss: 0.3272587060928345
Validation loss: 1.6537351608276367

Epoch: 5| Step: 9
Training loss: 0.3241771459579468
Validation loss: 1.6680252705850909

Epoch: 5| Step: 10
Training loss: 0.702107846736908
Validation loss: 1.6606576365809287

Epoch: 364| Step: 0
Training loss: 0.4272914528846741
Validation loss: 1.6610907162389448

Epoch: 5| Step: 1
Training loss: 0.5219734907150269
Validation loss: 1.6829771918635215

Epoch: 5| Step: 2
Training loss: 0.4181312024593353
Validation loss: 1.6863478486255934

Epoch: 5| Step: 3
Training loss: 0.3655110001564026
Validation loss: 1.6803363612903062

Epoch: 5| Step: 4
Training loss: 0.3048851490020752
Validation loss: 1.671531404218366

Epoch: 5| Step: 5
Training loss: 0.45644864439964294
Validation loss: 1.681828014312252

Epoch: 5| Step: 6
Training loss: 0.3434365391731262
Validation loss: 1.715822103202984

Epoch: 5| Step: 7
Training loss: 0.2920905649662018
Validation loss: 1.6892279630066247

Epoch: 5| Step: 8
Training loss: 0.5583890676498413
Validation loss: 1.688673173227618

Epoch: 5| Step: 9
Training loss: 0.44873470067977905
Validation loss: 1.6770960374545025

Epoch: 5| Step: 10
Training loss: 0.4607216417789459
Validation loss: 1.6667437194496073

Epoch: 365| Step: 0
Training loss: 0.2900433838367462
Validation loss: 1.6761808523567774

Epoch: 5| Step: 1
Training loss: 0.5342104434967041
Validation loss: 1.7150682428831696

Epoch: 5| Step: 2
Training loss: 0.34822869300842285
Validation loss: 1.697694819460633

Epoch: 5| Step: 3
Training loss: 0.49523505568504333
Validation loss: 1.6965404454097952

Epoch: 5| Step: 4
Training loss: 0.3442983627319336
Validation loss: 1.693392297273041

Epoch: 5| Step: 5
Training loss: 0.5068590044975281
Validation loss: 1.716687943345757

Epoch: 5| Step: 6
Training loss: 0.4816281199455261
Validation loss: 1.7035927695612754

Epoch: 5| Step: 7
Training loss: 0.2531111538410187
Validation loss: 1.7302528376220374

Epoch: 5| Step: 8
Training loss: 0.4607643485069275
Validation loss: 1.70670836458924

Epoch: 5| Step: 9
Training loss: 0.5433405637741089
Validation loss: 1.7020174021361976

Epoch: 5| Step: 10
Training loss: 0.33983924984931946
Validation loss: 1.652299432344334

Epoch: 366| Step: 0
Training loss: 0.4538547396659851
Validation loss: 1.654489355702554

Epoch: 5| Step: 1
Training loss: 0.2964603304862976
Validation loss: 1.6623162377265193

Epoch: 5| Step: 2
Training loss: 0.3516560196876526
Validation loss: 1.6469810598640031

Epoch: 5| Step: 3
Training loss: 0.6123619079589844
Validation loss: 1.6668250144168895

Epoch: 5| Step: 4
Training loss: 0.5515865087509155
Validation loss: 1.6771594080873715

Epoch: 5| Step: 5
Training loss: 0.4798192083835602
Validation loss: 1.6517611229291527

Epoch: 5| Step: 6
Training loss: 0.2925591468811035
Validation loss: 1.6835918272695234

Epoch: 5| Step: 7
Training loss: 0.6942799687385559
Validation loss: 1.6902659721271966

Epoch: 5| Step: 8
Training loss: 0.11890377849340439
Validation loss: 1.718573119050713

Epoch: 5| Step: 9
Training loss: 0.36692118644714355
Validation loss: 1.7434418355264971

Epoch: 5| Step: 10
Training loss: 0.4941810667514801
Validation loss: 1.7392821696496779

Epoch: 367| Step: 0
Training loss: 0.6170097589492798
Validation loss: 1.7307197586182625

Epoch: 5| Step: 1
Training loss: 0.5342625379562378
Validation loss: 1.7208676671469083

Epoch: 5| Step: 2
Training loss: 0.30648714303970337
Validation loss: 1.7022563744616765

Epoch: 5| Step: 3
Training loss: 0.5679680109024048
Validation loss: 1.7231656069396644

Epoch: 5| Step: 4
Training loss: 0.568815290927887
Validation loss: 1.7477913595015002

Epoch: 5| Step: 5
Training loss: 0.5532153248786926
Validation loss: 1.6988442097940752

Epoch: 5| Step: 6
Training loss: 0.3270615339279175
Validation loss: 1.7352115172211842

Epoch: 5| Step: 7
Training loss: 0.4008350968360901
Validation loss: 1.729423253766952

Epoch: 5| Step: 8
Training loss: 0.31021982431411743
Validation loss: 1.700233247972304

Epoch: 5| Step: 9
Training loss: 0.18280306458473206
Validation loss: 1.7487544167426325

Epoch: 5| Step: 10
Training loss: 0.18785102665424347
Validation loss: 1.7361967986629856

Epoch: 368| Step: 0
Training loss: 0.39764565229415894
Validation loss: 1.7284966540592972

Epoch: 5| Step: 1
Training loss: 0.8356808423995972
Validation loss: 1.7022993846606183

Epoch: 5| Step: 2
Training loss: 0.4630740284919739
Validation loss: 1.681322842515925

Epoch: 5| Step: 3
Training loss: 0.1574966311454773
Validation loss: 1.671319733383835

Epoch: 5| Step: 4
Training loss: 0.3465726971626282
Validation loss: 1.6776626058804092

Epoch: 5| Step: 5
Training loss: 0.31630241870880127
Validation loss: 1.6779939231052194

Epoch: 5| Step: 6
Training loss: 0.22473740577697754
Validation loss: 1.6810287634531658

Epoch: 5| Step: 7
Training loss: 0.4437004029750824
Validation loss: 1.6812599218019875

Epoch: 5| Step: 8
Training loss: 0.4732140600681305
Validation loss: 1.6771828769355692

Epoch: 5| Step: 9
Training loss: 0.4796369969844818
Validation loss: 1.6492049283878778

Epoch: 5| Step: 10
Training loss: 0.3820607364177704
Validation loss: 1.6520491607727543

Epoch: 369| Step: 0
Training loss: 0.4822812080383301
Validation loss: 1.6817342574878404

Epoch: 5| Step: 1
Training loss: 0.3118603825569153
Validation loss: 1.6765287896638275

Epoch: 5| Step: 2
Training loss: 0.27468976378440857
Validation loss: 1.6731402861174716

Epoch: 5| Step: 3
Training loss: 0.1510690450668335
Validation loss: 1.6600162867576844

Epoch: 5| Step: 4
Training loss: 0.5312741994857788
Validation loss: 1.6777304487843667

Epoch: 5| Step: 5
Training loss: 0.5951144099235535
Validation loss: 1.6726923296528478

Epoch: 5| Step: 6
Training loss: 0.2792354226112366
Validation loss: 1.6603109657123525

Epoch: 5| Step: 7
Training loss: 0.409494012594223
Validation loss: 1.6673134834535661

Epoch: 5| Step: 8
Training loss: 0.28444576263427734
Validation loss: 1.6749013726429274

Epoch: 5| Step: 9
Training loss: 0.5366724133491516
Validation loss: 1.6774458987738496

Epoch: 5| Step: 10
Training loss: 0.44087618589401245
Validation loss: 1.6600111851128199

Epoch: 370| Step: 0
Training loss: 0.35753583908081055
Validation loss: 1.6673486950576946

Epoch: 5| Step: 1
Training loss: 0.4165487289428711
Validation loss: 1.68337369221513

Epoch: 5| Step: 2
Training loss: 0.30937260389328003
Validation loss: 1.6778490158819384

Epoch: 5| Step: 3
Training loss: 0.3728428781032562
Validation loss: 1.6769761936638945

Epoch: 5| Step: 4
Training loss: 0.450258731842041
Validation loss: 1.6931248172636955

Epoch: 5| Step: 5
Training loss: 0.5503756999969482
Validation loss: 1.7033051739456833

Epoch: 5| Step: 6
Training loss: 0.2177356481552124
Validation loss: 1.7105712621442732

Epoch: 5| Step: 7
Training loss: 0.38172847032546997
Validation loss: 1.7420868104504001

Epoch: 5| Step: 8
Training loss: 0.383096843957901
Validation loss: 1.7139003187097528

Epoch: 5| Step: 9
Training loss: 0.6128813624382019
Validation loss: 1.6838010331635833

Epoch: 5| Step: 10
Training loss: 0.33594080805778503
Validation loss: 1.6853571835384573

Epoch: 371| Step: 0
Training loss: 0.26008477807044983
Validation loss: 1.6494699191021662

Epoch: 5| Step: 1
Training loss: 0.2618682086467743
Validation loss: 1.6860150855074647

Epoch: 5| Step: 2
Training loss: 0.3426516652107239
Validation loss: 1.6617298459493985

Epoch: 5| Step: 3
Training loss: 0.4688858985900879
Validation loss: 1.6692141050933509

Epoch: 5| Step: 4
Training loss: 0.6041635274887085
Validation loss: 1.6789696908766223

Epoch: 5| Step: 5
Training loss: 0.5387719869613647
Validation loss: 1.7115006908293693

Epoch: 5| Step: 6
Training loss: 0.18969623744487762
Validation loss: 1.7078753594429261

Epoch: 5| Step: 7
Training loss: 0.3979921340942383
Validation loss: 1.6966128631304669

Epoch: 5| Step: 8
Training loss: 0.4294079840183258
Validation loss: 1.6920382002348542

Epoch: 5| Step: 9
Training loss: 0.5386751890182495
Validation loss: 1.6987963158597228

Epoch: 5| Step: 10
Training loss: 0.3543041944503784
Validation loss: 1.6914858971872637

Epoch: 372| Step: 0
Training loss: 0.4095270037651062
Validation loss: 1.697627995603828

Epoch: 5| Step: 1
Training loss: 0.6686049699783325
Validation loss: 1.6889400161722654

Epoch: 5| Step: 2
Training loss: 0.27969107031822205
Validation loss: 1.6909169817483554

Epoch: 5| Step: 3
Training loss: 0.35046643018722534
Validation loss: 1.6750650713520665

Epoch: 5| Step: 4
Training loss: 0.45900315046310425
Validation loss: 1.672402387024254

Epoch: 5| Step: 5
Training loss: 0.3960331678390503
Validation loss: 1.6669336442024476

Epoch: 5| Step: 6
Training loss: 0.17551597952842712
Validation loss: 1.6699554369013796

Epoch: 5| Step: 7
Training loss: 0.3025144040584564
Validation loss: 1.6999631030585176

Epoch: 5| Step: 8
Training loss: 0.4619791507720947
Validation loss: 1.6544438504403638

Epoch: 5| Step: 9
Training loss: 0.5358872413635254
Validation loss: 1.6678429752267816

Epoch: 5| Step: 10
Training loss: 0.4451014995574951
Validation loss: 1.6791419008726716

Epoch: 373| Step: 0
Training loss: 0.24377162754535675
Validation loss: 1.6824768012569797

Epoch: 5| Step: 1
Training loss: 0.44658881425857544
Validation loss: 1.678074855958262

Epoch: 5| Step: 2
Training loss: 0.4563444256782532
Validation loss: 1.6843466874091857

Epoch: 5| Step: 3
Training loss: 0.16440820693969727
Validation loss: 1.7039257646888815

Epoch: 5| Step: 4
Training loss: 0.36981430649757385
Validation loss: 1.706508207064803

Epoch: 5| Step: 5
Training loss: 0.5060292482376099
Validation loss: 1.6816588447939964

Epoch: 5| Step: 6
Training loss: 0.3564473092556
Validation loss: 1.6822322491676576

Epoch: 5| Step: 7
Training loss: 0.5379024147987366
Validation loss: 1.716718924942837

Epoch: 5| Step: 8
Training loss: 0.255257248878479
Validation loss: 1.689594982772745

Epoch: 5| Step: 9
Training loss: 0.4222967028617859
Validation loss: 1.6909986349844164

Epoch: 5| Step: 10
Training loss: 0.4098301827907562
Validation loss: 1.6901015927714687

Epoch: 374| Step: 0
Training loss: 0.6274415254592896
Validation loss: 1.6637693637160844

Epoch: 5| Step: 1
Training loss: 0.35344281792640686
Validation loss: 1.6551518171064314

Epoch: 5| Step: 2
Training loss: 0.3521490693092346
Validation loss: 1.658943223696883

Epoch: 5| Step: 3
Training loss: 0.210907980799675
Validation loss: 1.663242495188149

Epoch: 5| Step: 4
Training loss: 0.2868453860282898
Validation loss: 1.6572536447996735

Epoch: 5| Step: 5
Training loss: 0.4016786515712738
Validation loss: 1.6578193274877404

Epoch: 5| Step: 6
Training loss: 0.4051036238670349
Validation loss: 1.642124451616759

Epoch: 5| Step: 7
Training loss: 0.3902123272418976
Validation loss: 1.6635001026174074

Epoch: 5| Step: 8
Training loss: 0.2940083146095276
Validation loss: 1.6453209948796097

Epoch: 5| Step: 9
Training loss: 0.46813979744911194
Validation loss: 1.6976588259461105

Epoch: 5| Step: 10
Training loss: 0.26568832993507385
Validation loss: 1.6722727321809339

Epoch: 375| Step: 0
Training loss: 0.5521964430809021
Validation loss: 1.7149712526670067

Epoch: 5| Step: 1
Training loss: 0.4877116084098816
Validation loss: 1.7387764966616066

Epoch: 5| Step: 2
Training loss: 0.5431889295578003
Validation loss: 1.7388784552133212

Epoch: 5| Step: 3
Training loss: 0.3563121259212494
Validation loss: 1.7274480250573927

Epoch: 5| Step: 4
Training loss: 0.28737181425094604
Validation loss: 1.7437064391310497

Epoch: 5| Step: 5
Training loss: 0.5892689228057861
Validation loss: 1.747385367270439

Epoch: 5| Step: 6
Training loss: 0.3955226540565491
Validation loss: 1.7110424951840473

Epoch: 5| Step: 7
Training loss: 0.31674936413764954
Validation loss: 1.6926066631911902

Epoch: 5| Step: 8
Training loss: 0.28726547956466675
Validation loss: 1.691592763828975

Epoch: 5| Step: 9
Training loss: 0.3123481571674347
Validation loss: 1.6715090787538918

Epoch: 5| Step: 10
Training loss: 0.2611735761165619
Validation loss: 1.6946740945180256

Epoch: 376| Step: 0
Training loss: 0.45907336473464966
Validation loss: 1.6913783793808312

Epoch: 5| Step: 1
Training loss: 0.31895115971565247
Validation loss: 1.6827094003718386

Epoch: 5| Step: 2
Training loss: 0.435751736164093
Validation loss: 1.6948133091772757

Epoch: 5| Step: 3
Training loss: 0.29194375872612
Validation loss: 1.7119066869058917

Epoch: 5| Step: 4
Training loss: 0.2705067992210388
Validation loss: 1.6763465225055654

Epoch: 5| Step: 5
Training loss: 0.5401875376701355
Validation loss: 1.673012738586754

Epoch: 5| Step: 6
Training loss: 0.2952737808227539
Validation loss: 1.6706578295717958

Epoch: 5| Step: 7
Training loss: 0.4703981280326843
Validation loss: 1.6723901507675007

Epoch: 5| Step: 8
Training loss: 0.3307669758796692
Validation loss: 1.661687583051702

Epoch: 5| Step: 9
Training loss: 0.4383571743965149
Validation loss: 1.6487262377174952

Epoch: 5| Step: 10
Training loss: 0.38262394070625305
Validation loss: 1.712820614537885

Epoch: 377| Step: 0
Training loss: 0.432037889957428
Validation loss: 1.7038873767340055

Epoch: 5| Step: 1
Training loss: 0.24029092490673065
Validation loss: 1.682530963292686

Epoch: 5| Step: 2
Training loss: 0.27830225229263306
Validation loss: 1.6906446744036931

Epoch: 5| Step: 3
Training loss: 0.4748256206512451
Validation loss: 1.727653141944639

Epoch: 5| Step: 4
Training loss: 0.4709393382072449
Validation loss: 1.728716274743439

Epoch: 5| Step: 5
Training loss: 0.47902554273605347
Validation loss: 1.733312818952786

Epoch: 5| Step: 6
Training loss: 0.16389179229736328
Validation loss: 1.6785863022650442

Epoch: 5| Step: 7
Training loss: 0.5045802593231201
Validation loss: 1.70245450030091

Epoch: 5| Step: 8
Training loss: 0.3829914629459381
Validation loss: 1.6845637482981528

Epoch: 5| Step: 9
Training loss: 0.21415011584758759
Validation loss: 1.67543871941105

Epoch: 5| Step: 10
Training loss: 0.48343539237976074
Validation loss: 1.6647982251259588

Epoch: 378| Step: 0
Training loss: 0.4301164746284485
Validation loss: 1.6654461071055422

Epoch: 5| Step: 1
Training loss: 0.3474966287612915
Validation loss: 1.6563234188223397

Epoch: 5| Step: 2
Training loss: 0.5032410025596619
Validation loss: 1.6776444835047568

Epoch: 5| Step: 3
Training loss: 0.5145488977432251
Validation loss: 1.653608920753643

Epoch: 5| Step: 4
Training loss: 0.3457954525947571
Validation loss: 1.673786191530125

Epoch: 5| Step: 5
Training loss: 0.17208829522132874
Validation loss: 1.671167399293633

Epoch: 5| Step: 6
Training loss: 0.39780527353286743
Validation loss: 1.6670232434426584

Epoch: 5| Step: 7
Training loss: 0.3903847634792328
Validation loss: 1.627593284012169

Epoch: 5| Step: 8
Training loss: 0.2951622009277344
Validation loss: 1.6904116343426447

Epoch: 5| Step: 9
Training loss: 0.39622342586517334
Validation loss: 1.6549245772823211

Epoch: 5| Step: 10
Training loss: 0.35454297065734863
Validation loss: 1.6866598334363712

Epoch: 379| Step: 0
Training loss: 0.3574603199958801
Validation loss: 1.685266108923061

Epoch: 5| Step: 1
Training loss: 0.2691057622432709
Validation loss: 1.6879615444009022

Epoch: 5| Step: 2
Training loss: 0.5889922976493835
Validation loss: 1.6584578598699262

Epoch: 5| Step: 3
Training loss: 0.2251947820186615
Validation loss: 1.6668499990176129

Epoch: 5| Step: 4
Training loss: 0.28512459993362427
Validation loss: 1.691497145160552

Epoch: 5| Step: 5
Training loss: 0.4522995054721832
Validation loss: 1.692567672780765

Epoch: 5| Step: 6
Training loss: 0.5073973536491394
Validation loss: 1.6809716660489318

Epoch: 5| Step: 7
Training loss: 0.4102046489715576
Validation loss: 1.660206558883831

Epoch: 5| Step: 8
Training loss: 0.31281375885009766
Validation loss: 1.6321272337308494

Epoch: 5| Step: 9
Training loss: 0.23875188827514648
Validation loss: 1.6346457184001963

Epoch: 5| Step: 10
Training loss: 0.41480934619903564
Validation loss: 1.6363031159165085

Epoch: 380| Step: 0
Training loss: 0.3467974066734314
Validation loss: 1.6592858337586927

Epoch: 5| Step: 1
Training loss: 0.4397762417793274
Validation loss: 1.6290407667877853

Epoch: 5| Step: 2
Training loss: 0.20029368996620178
Validation loss: 1.702747086042999

Epoch: 5| Step: 3
Training loss: 0.39287519454956055
Validation loss: 1.6509223958497405

Epoch: 5| Step: 4
Training loss: 0.4169999063014984
Validation loss: 1.6993071776564403

Epoch: 5| Step: 5
Training loss: 0.3865536153316498
Validation loss: 1.7423753558948476

Epoch: 5| Step: 6
Training loss: 0.3715110719203949
Validation loss: 1.7095419399199947

Epoch: 5| Step: 7
Training loss: 0.35585278272628784
Validation loss: 1.6892449907077256

Epoch: 5| Step: 8
Training loss: 0.370390385389328
Validation loss: 1.6886110664695821

Epoch: 5| Step: 9
Training loss: 0.32159772515296936
Validation loss: 1.7209598223368328

Epoch: 5| Step: 10
Training loss: 0.4815821945667267
Validation loss: 1.6782506371057162

Epoch: 381| Step: 0
Training loss: 0.32294991612434387
Validation loss: 1.6804709011508572

Epoch: 5| Step: 1
Training loss: 0.616723358631134
Validation loss: 1.6576153975661083

Epoch: 5| Step: 2
Training loss: 0.46484774351119995
Validation loss: 1.6486980363886843

Epoch: 5| Step: 3
Training loss: 0.2536903917789459
Validation loss: 1.6561155126940819

Epoch: 5| Step: 4
Training loss: 0.2567269802093506
Validation loss: 1.6742169690388504

Epoch: 5| Step: 5
Training loss: 0.2124207317829132
Validation loss: 1.6699114896917855

Epoch: 5| Step: 6
Training loss: 0.16337613761425018
Validation loss: 1.6710640538123347

Epoch: 5| Step: 7
Training loss: 0.4190390110015869
Validation loss: 1.654802768461166

Epoch: 5| Step: 8
Training loss: 0.5003406405448914
Validation loss: 1.6444451911475069

Epoch: 5| Step: 9
Training loss: 0.3386663794517517
Validation loss: 1.6258733939099055

Epoch: 5| Step: 10
Training loss: 0.4630586504936218
Validation loss: 1.6444532268790788

Epoch: 382| Step: 0
Training loss: 0.21807649731636047
Validation loss: 1.6505272978095598

Epoch: 5| Step: 1
Training loss: 0.4093964993953705
Validation loss: 1.655175482073138

Epoch: 5| Step: 2
Training loss: 0.3170449137687683
Validation loss: 1.6782966095914122

Epoch: 5| Step: 3
Training loss: 0.40804949402809143
Validation loss: 1.7052796143357472

Epoch: 5| Step: 4
Training loss: 0.3710240125656128
Validation loss: 1.6886270917871946

Epoch: 5| Step: 5
Training loss: 0.6419954299926758
Validation loss: 1.7290671230644308

Epoch: 5| Step: 6
Training loss: 0.31920143961906433
Validation loss: 1.7160867439803256

Epoch: 5| Step: 7
Training loss: 0.366329163312912
Validation loss: 1.7226623040373608

Epoch: 5| Step: 8
Training loss: 0.30363741517066956
Validation loss: 1.753902300711601

Epoch: 5| Step: 9
Training loss: 0.24523186683654785
Validation loss: 1.7338873365873932

Epoch: 5| Step: 10
Training loss: 0.40970778465270996
Validation loss: 1.7498762812665714

Epoch: 383| Step: 0
Training loss: 0.3867475390434265
Validation loss: 1.7024072882949666

Epoch: 5| Step: 1
Training loss: 0.37857601046562195
Validation loss: 1.7025895259713615

Epoch: 5| Step: 2
Training loss: 0.20429489016532898
Validation loss: 1.691495539039694

Epoch: 5| Step: 3
Training loss: 0.5254123210906982
Validation loss: 1.6703001683758152

Epoch: 5| Step: 4
Training loss: 0.4278978407382965
Validation loss: 1.6786706332237489

Epoch: 5| Step: 5
Training loss: 0.6749070882797241
Validation loss: 1.67763352394104

Epoch: 5| Step: 6
Training loss: 0.3615624010562897
Validation loss: 1.6513067804357058

Epoch: 5| Step: 7
Training loss: 0.2617306113243103
Validation loss: 1.640927186576269

Epoch: 5| Step: 8
Training loss: 0.2913685441017151
Validation loss: 1.652294053826281

Epoch: 5| Step: 9
Training loss: 0.34921008348464966
Validation loss: 1.6594578527635144

Epoch: 5| Step: 10
Training loss: 0.255130410194397
Validation loss: 1.660630956772835

Epoch: 384| Step: 0
Training loss: 0.2625170350074768
Validation loss: 1.679266841180863

Epoch: 5| Step: 1
Training loss: 0.6038355231285095
Validation loss: 1.6620168685913086

Epoch: 5| Step: 2
Training loss: 0.3754573464393616
Validation loss: 1.716397572589177

Epoch: 5| Step: 3
Training loss: 0.14754517376422882
Validation loss: 1.68440084175397

Epoch: 5| Step: 4
Training loss: 0.3737492561340332
Validation loss: 1.7047842010374992

Epoch: 5| Step: 5
Training loss: 0.38552793860435486
Validation loss: 1.6889190917373986

Epoch: 5| Step: 6
Training loss: 0.479851633310318
Validation loss: 1.7110721347152547

Epoch: 5| Step: 7
Training loss: 0.321366548538208
Validation loss: 1.6630061185488136

Epoch: 5| Step: 8
Training loss: 0.3920065462589264
Validation loss: 1.6679969961925218

Epoch: 5| Step: 9
Training loss: 0.2795398533344269
Validation loss: 1.6392737075846682

Epoch: 5| Step: 10
Training loss: 0.3896787166595459
Validation loss: 1.6188724310167375

Epoch: 385| Step: 0
Training loss: 0.3840813934803009
Validation loss: 1.5944042808266097

Epoch: 5| Step: 1
Training loss: 0.31118321418762207
Validation loss: 1.6186935055640437

Epoch: 5| Step: 2
Training loss: 0.2539096474647522
Validation loss: 1.6343219536606983

Epoch: 5| Step: 3
Training loss: 0.4087623059749603
Validation loss: 1.663700561369619

Epoch: 5| Step: 4
Training loss: 0.3156483471393585
Validation loss: 1.6570326025767992

Epoch: 5| Step: 5
Training loss: 0.3780880570411682
Validation loss: 1.7215354615642178

Epoch: 5| Step: 6
Training loss: 0.41304484009742737
Validation loss: 1.7220396316179665

Epoch: 5| Step: 7
Training loss: 0.6300596594810486
Validation loss: 1.733970280616514

Epoch: 5| Step: 8
Training loss: 0.40635743737220764
Validation loss: 1.7320328938063754

Epoch: 5| Step: 9
Training loss: 0.3654657304286957
Validation loss: 1.7048621049491308

Epoch: 5| Step: 10
Training loss: 0.46425923705101013
Validation loss: 1.6770383875857118

Epoch: 386| Step: 0
Training loss: 0.1773427575826645
Validation loss: 1.6605289482301282

Epoch: 5| Step: 1
Training loss: 0.2855597138404846
Validation loss: 1.6456808159428258

Epoch: 5| Step: 2
Training loss: 0.344594806432724
Validation loss: 1.6391627455270419

Epoch: 5| Step: 3
Training loss: 0.5491775274276733
Validation loss: 1.6696496958373694

Epoch: 5| Step: 4
Training loss: 0.3475279211997986
Validation loss: 1.6692008472258044

Epoch: 5| Step: 5
Training loss: 0.5183848142623901
Validation loss: 1.6887121764562463

Epoch: 5| Step: 6
Training loss: 0.40158024430274963
Validation loss: 1.722676323306176

Epoch: 5| Step: 7
Training loss: 0.42379918694496155
Validation loss: 1.7700159600985947

Epoch: 5| Step: 8
Training loss: 0.36741650104522705
Validation loss: 1.7644679482265184

Epoch: 5| Step: 9
Training loss: 0.3543458580970764
Validation loss: 1.7762694820280998

Epoch: 5| Step: 10
Training loss: 0.46180713176727295
Validation loss: 1.758899288792764

Epoch: 387| Step: 0
Training loss: 0.5270681977272034
Validation loss: 1.6959653721060803

Epoch: 5| Step: 1
Training loss: 0.4902459681034088
Validation loss: 1.6722938463252077

Epoch: 5| Step: 2
Training loss: 0.3095131814479828
Validation loss: 1.6430838800245715

Epoch: 5| Step: 3
Training loss: 0.3277176022529602
Validation loss: 1.6287431133690702

Epoch: 5| Step: 4
Training loss: 0.3670429587364197
Validation loss: 1.6262679023127402

Epoch: 5| Step: 5
Training loss: 0.3401988744735718
Validation loss: 1.5983342534752303

Epoch: 5| Step: 6
Training loss: 0.350524365901947
Validation loss: 1.5822034074414162

Epoch: 5| Step: 7
Training loss: 0.24966709315776825
Validation loss: 1.5779415843307332

Epoch: 5| Step: 8
Training loss: 0.37607383728027344
Validation loss: 1.6146985253980082

Epoch: 5| Step: 9
Training loss: 0.3107694685459137
Validation loss: 1.6445818972843949

Epoch: 5| Step: 10
Training loss: 0.39282894134521484
Validation loss: 1.667504568894704

Epoch: 388| Step: 0
Training loss: 0.34473952651023865
Validation loss: 1.6862939608994352

Epoch: 5| Step: 1
Training loss: 0.32064753770828247
Validation loss: 1.6941966536224529

Epoch: 5| Step: 2
Training loss: 0.1911860555410385
Validation loss: 1.6789546076969435

Epoch: 5| Step: 3
Training loss: 0.39752358198165894
Validation loss: 1.6732125705288303

Epoch: 5| Step: 4
Training loss: 0.3629056513309479
Validation loss: 1.6464969778573642

Epoch: 5| Step: 5
Training loss: 0.36150041222572327
Validation loss: 1.6522357156199794

Epoch: 5| Step: 6
Training loss: 0.4888462424278259
Validation loss: 1.6479537269120574

Epoch: 5| Step: 7
Training loss: 0.5085805058479309
Validation loss: 1.6367385182329404

Epoch: 5| Step: 8
Training loss: 0.38092240691185
Validation loss: 1.6029660970933977

Epoch: 5| Step: 9
Training loss: 0.3270455002784729
Validation loss: 1.6373148913024573

Epoch: 5| Step: 10
Training loss: 0.2211994230747223
Validation loss: 1.6406674077433925

Epoch: 389| Step: 0
Training loss: 0.7403452396392822
Validation loss: 1.6097079887185046

Epoch: 5| Step: 1
Training loss: 0.2855907082557678
Validation loss: 1.6078118880589802

Epoch: 5| Step: 2
Training loss: 0.4811842441558838
Validation loss: 1.6406440017043904

Epoch: 5| Step: 3
Training loss: 0.27325350046157837
Validation loss: 1.636466791552882

Epoch: 5| Step: 4
Training loss: 0.27608710527420044
Validation loss: 1.665392420625174

Epoch: 5| Step: 5
Training loss: 0.33836713433265686
Validation loss: 1.652441176035071

Epoch: 5| Step: 6
Training loss: 0.30878397822380066
Validation loss: 1.6498948271556566

Epoch: 5| Step: 7
Training loss: 0.32013848423957825
Validation loss: 1.6738902227852934

Epoch: 5| Step: 8
Training loss: 0.31224438548088074
Validation loss: 1.6445510925785187

Epoch: 5| Step: 9
Training loss: 0.13500402867794037
Validation loss: 1.6597580909729004

Epoch: 5| Step: 10
Training loss: 0.14582028985023499
Validation loss: 1.6299173421757196

Epoch: 390| Step: 0
Training loss: 0.22066310048103333
Validation loss: 1.6350631124229842

Epoch: 5| Step: 1
Training loss: 0.3031521439552307
Validation loss: 1.6458176105253157

Epoch: 5| Step: 2
Training loss: 0.3006543219089508
Validation loss: 1.636962975225141

Epoch: 5| Step: 3
Training loss: 0.23468296229839325
Validation loss: 1.6166675859881985

Epoch: 5| Step: 4
Training loss: 0.40871626138687134
Validation loss: 1.653185764948527

Epoch: 5| Step: 5
Training loss: 0.37419119477272034
Validation loss: 1.6178995793865574

Epoch: 5| Step: 6
Training loss: 0.16993188858032227
Validation loss: 1.6556560852194344

Epoch: 5| Step: 7
Training loss: 0.5045923590660095
Validation loss: 1.647967617998841

Epoch: 5| Step: 8
Training loss: 0.33359527587890625
Validation loss: 1.6690471447924131

Epoch: 5| Step: 9
Training loss: 0.46602940559387207
Validation loss: 1.6716125806172688

Epoch: 5| Step: 10
Training loss: 0.39676183462142944
Validation loss: 1.6575815126460085

Epoch: 391| Step: 0
Training loss: 0.1955653727054596
Validation loss: 1.655175494891341

Epoch: 5| Step: 1
Training loss: 0.32613474130630493
Validation loss: 1.6574012592274656

Epoch: 5| Step: 2
Training loss: 0.3922562599182129
Validation loss: 1.6664710634498185

Epoch: 5| Step: 3
Training loss: 0.2654244303703308
Validation loss: 1.6705987376551474

Epoch: 5| Step: 4
Training loss: 0.4257281720638275
Validation loss: 1.6629880320641302

Epoch: 5| Step: 5
Training loss: 0.323742538690567
Validation loss: 1.6735633714224702

Epoch: 5| Step: 6
Training loss: 0.31862419843673706
Validation loss: 1.6853574578480055

Epoch: 5| Step: 7
Training loss: 0.3065086901187897
Validation loss: 1.7122003929589384

Epoch: 5| Step: 8
Training loss: 0.2583690881729126
Validation loss: 1.6817882932642454

Epoch: 5| Step: 9
Training loss: 0.4724443554878235
Validation loss: 1.6894156394466278

Epoch: 5| Step: 10
Training loss: 0.39140719175338745
Validation loss: 1.681746103430307

Epoch: 392| Step: 0
Training loss: 0.4995669424533844
Validation loss: 1.6404541602698706

Epoch: 5| Step: 1
Training loss: 0.17791204154491425
Validation loss: 1.6287848846886748

Epoch: 5| Step: 2
Training loss: 0.40599411725997925
Validation loss: 1.6351320487196728

Epoch: 5| Step: 3
Training loss: 0.35714179277420044
Validation loss: 1.6059701083808817

Epoch: 5| Step: 4
Training loss: 0.38415631651878357
Validation loss: 1.6087216074748705

Epoch: 5| Step: 5
Training loss: 0.4304325580596924
Validation loss: 1.6085074986180952

Epoch: 5| Step: 6
Training loss: 0.25599342584609985
Validation loss: 1.6688780976879982

Epoch: 5| Step: 7
Training loss: 0.1383216679096222
Validation loss: 1.653149265114979

Epoch: 5| Step: 8
Training loss: 0.409717857837677
Validation loss: 1.7015646606363275

Epoch: 5| Step: 9
Training loss: 0.29692694544792175
Validation loss: 1.6786833206812541

Epoch: 5| Step: 10
Training loss: 0.4491572678089142
Validation loss: 1.6687373422807263

Epoch: 393| Step: 0
Training loss: 0.08995019644498825
Validation loss: 1.6279904355284989

Epoch: 5| Step: 1
Training loss: 0.30075299739837646
Validation loss: 1.6240680063924482

Epoch: 5| Step: 2
Training loss: 0.16863851249217987
Validation loss: 1.6217968412624892

Epoch: 5| Step: 3
Training loss: 0.23174569010734558
Validation loss: 1.6292600029258317

Epoch: 5| Step: 4
Training loss: 0.6462193727493286
Validation loss: 1.6448027882524716

Epoch: 5| Step: 5
Training loss: 0.32334381341934204
Validation loss: 1.6260938823864024

Epoch: 5| Step: 6
Training loss: 0.32598423957824707
Validation loss: 1.592416932505946

Epoch: 5| Step: 7
Training loss: 0.3557262122631073
Validation loss: 1.6215929497954666

Epoch: 5| Step: 8
Training loss: 0.43502750992774963
Validation loss: 1.6437260079127487

Epoch: 5| Step: 9
Training loss: 0.31017905473709106
Validation loss: 1.6279456692357217

Epoch: 5| Step: 10
Training loss: 0.40892505645751953
Validation loss: 1.6417025660955777

Epoch: 394| Step: 0
Training loss: 0.21693933010101318
Validation loss: 1.6517415290237756

Epoch: 5| Step: 1
Training loss: 0.4640966057777405
Validation loss: 1.6467826456151984

Epoch: 5| Step: 2
Training loss: 0.3013555109500885
Validation loss: 1.6036578673188404

Epoch: 5| Step: 3
Training loss: 0.4824541509151459
Validation loss: 1.6057911816463675

Epoch: 5| Step: 4
Training loss: 0.36622631549835205
Validation loss: 1.6009304395285986

Epoch: 5| Step: 5
Training loss: 0.27807170152664185
Validation loss: 1.616249672828182

Epoch: 5| Step: 6
Training loss: 0.4360508322715759
Validation loss: 1.5924988856879614

Epoch: 5| Step: 7
Training loss: 0.3083726465702057
Validation loss: 1.6409693328283166

Epoch: 5| Step: 8
Training loss: 0.3206680417060852
Validation loss: 1.6609026975529169

Epoch: 5| Step: 9
Training loss: 0.22021040320396423
Validation loss: 1.6253861022251908

Epoch: 5| Step: 10
Training loss: 0.2369164079427719
Validation loss: 1.5989682828226397

Epoch: 395| Step: 0
Training loss: 0.3440479636192322
Validation loss: 1.6195383244945156

Epoch: 5| Step: 1
Training loss: 0.34482479095458984
Validation loss: 1.6357246304071078

Epoch: 5| Step: 2
Training loss: 0.2591696083545685
Validation loss: 1.645242642330867

Epoch: 5| Step: 3
Training loss: 0.3015594482421875
Validation loss: 1.6305167021289948

Epoch: 5| Step: 4
Training loss: 0.28125613927841187
Validation loss: 1.630189247028802

Epoch: 5| Step: 5
Training loss: 0.3146476149559021
Validation loss: 1.663647618345035

Epoch: 5| Step: 6
Training loss: 0.472109854221344
Validation loss: 1.658040742720327

Epoch: 5| Step: 7
Training loss: 0.5066424608230591
Validation loss: 1.6295209520606584

Epoch: 5| Step: 8
Training loss: 0.20959381759166718
Validation loss: 1.608869480830367

Epoch: 5| Step: 9
Training loss: 0.28530025482177734
Validation loss: 1.5789818327914003

Epoch: 5| Step: 10
Training loss: 0.19835637509822845
Validation loss: 1.6038083088013433

Epoch: 396| Step: 0
Training loss: 0.32139459252357483
Validation loss: 1.6735105796526837

Epoch: 5| Step: 1
Training loss: 0.2511310577392578
Validation loss: 1.6322737957841607

Epoch: 5| Step: 2
Training loss: 0.12661345303058624
Validation loss: 1.6278416700260614

Epoch: 5| Step: 3
Training loss: 0.496908575296402
Validation loss: 1.5948057802774573

Epoch: 5| Step: 4
Training loss: 0.38983145356178284
Validation loss: 1.6591204699649607

Epoch: 5| Step: 5
Training loss: 0.3311390280723572
Validation loss: 1.6242186920617216

Epoch: 5| Step: 6
Training loss: 0.42036914825439453
Validation loss: 1.5940085200853245

Epoch: 5| Step: 7
Training loss: 0.4121513366699219
Validation loss: 1.5745171731518162

Epoch: 5| Step: 8
Training loss: 0.3896854519844055
Validation loss: 1.5779452093185917

Epoch: 5| Step: 9
Training loss: 0.3171275556087494
Validation loss: 1.603673441435701

Epoch: 5| Step: 10
Training loss: 0.33223044872283936
Validation loss: 1.6005386114120483

Epoch: 397| Step: 0
Training loss: 0.27716198563575745
Validation loss: 1.5886277896101757

Epoch: 5| Step: 1
Training loss: 0.3092160224914551
Validation loss: 1.6068029198595273

Epoch: 5| Step: 2
Training loss: 0.4881584644317627
Validation loss: 1.5957189939355338

Epoch: 5| Step: 3
Training loss: 0.3952719271183014
Validation loss: 1.614947981090956

Epoch: 5| Step: 4
Training loss: 0.27700597047805786
Validation loss: 1.612620121689253

Epoch: 5| Step: 5
Training loss: 0.47215643525123596
Validation loss: 1.5975112286947106

Epoch: 5| Step: 6
Training loss: 0.28296583890914917
Validation loss: 1.601505111622554

Epoch: 5| Step: 7
Training loss: 0.3252738118171692
Validation loss: 1.631278399498232

Epoch: 5| Step: 8
Training loss: 0.2233864963054657
Validation loss: 1.635154966385134

Epoch: 5| Step: 9
Training loss: 0.18474338948726654
Validation loss: 1.647265411192371

Epoch: 5| Step: 10
Training loss: 0.459671288728714
Validation loss: 1.638930704004021

Epoch: 398| Step: 0
Training loss: 0.43780240416526794
Validation loss: 1.6730287651861868

Epoch: 5| Step: 1
Training loss: 0.26015904545783997
Validation loss: 1.672761615886483

Epoch: 5| Step: 2
Training loss: 0.286888062953949
Validation loss: 1.6901449823892245

Epoch: 5| Step: 3
Training loss: 0.34587177634239197
Validation loss: 1.6411214643909084

Epoch: 5| Step: 4
Training loss: 0.2869209945201874
Validation loss: 1.6358453932628836

Epoch: 5| Step: 5
Training loss: 0.5008245706558228
Validation loss: 1.600987148541276

Epoch: 5| Step: 6
Training loss: 0.22703012824058533
Validation loss: 1.5899968249823457

Epoch: 5| Step: 7
Training loss: 0.39186224341392517
Validation loss: 1.563806228740241

Epoch: 5| Step: 8
Training loss: 0.399860680103302
Validation loss: 1.5687736413812126

Epoch: 5| Step: 9
Training loss: 0.395301878452301
Validation loss: 1.5692560884260363

Epoch: 5| Step: 10
Training loss: 0.25587353110313416
Validation loss: 1.6426128879670174

Epoch: 399| Step: 0
Training loss: 0.4531834125518799
Validation loss: 1.666787774332108

Epoch: 5| Step: 1
Training loss: 0.3987264335155487
Validation loss: 1.6694489108618868

Epoch: 5| Step: 2
Training loss: 0.41542133688926697
Validation loss: 1.6776552648954495

Epoch: 5| Step: 3
Training loss: 0.2545146346092224
Validation loss: 1.6677312709951913

Epoch: 5| Step: 4
Training loss: 0.31838878989219666
Validation loss: 1.6478643955722931

Epoch: 5| Step: 5
Training loss: 0.24096231162548065
Validation loss: 1.6504203811768563

Epoch: 5| Step: 6
Training loss: 0.5272763967514038
Validation loss: 1.6536223478214715

Epoch: 5| Step: 7
Training loss: 0.39326199889183044
Validation loss: 1.6413417631579983

Epoch: 5| Step: 8
Training loss: 0.31809523701667786
Validation loss: 1.5964547869979695

Epoch: 5| Step: 9
Training loss: 0.2826192378997803
Validation loss: 1.605276975580441

Epoch: 5| Step: 10
Training loss: 0.2598612606525421
Validation loss: 1.6267390840797014

Epoch: 400| Step: 0
Training loss: 0.3552394509315491
Validation loss: 1.6389312372412732

Epoch: 5| Step: 1
Training loss: 0.2719172537326813
Validation loss: 1.6638194784041374

Epoch: 5| Step: 2
Training loss: 0.14689962565898895
Validation loss: 1.6289491781624414

Epoch: 5| Step: 3
Training loss: 0.3179137110710144
Validation loss: 1.6179115156973563

Epoch: 5| Step: 4
Training loss: 0.4559304118156433
Validation loss: 1.628968055530261

Epoch: 5| Step: 5
Training loss: 0.3404677212238312
Validation loss: 1.632677783248245

Epoch: 5| Step: 6
Training loss: 0.2355269491672516
Validation loss: 1.6232434844457975

Epoch: 5| Step: 7
Training loss: 0.44323667883872986
Validation loss: 1.6299906738342778

Epoch: 5| Step: 8
Training loss: 0.3308715224266052
Validation loss: 1.6687810664535851

Epoch: 5| Step: 9
Training loss: 0.3263007402420044
Validation loss: 1.6550454183291363

Epoch: 5| Step: 10
Training loss: 0.2990885078907013
Validation loss: 1.6543229651707474

Epoch: 401| Step: 0
Training loss: 0.20152044296264648
Validation loss: 1.6499025026957195

Epoch: 5| Step: 1
Training loss: 0.35414379835128784
Validation loss: 1.6356466559953586

Epoch: 5| Step: 2
Training loss: 0.3751857578754425
Validation loss: 1.6472460864692606

Epoch: 5| Step: 3
Training loss: 0.46647071838378906
Validation loss: 1.648751010176956

Epoch: 5| Step: 4
Training loss: 0.39802590012550354
Validation loss: 1.6378890545137468

Epoch: 5| Step: 5
Training loss: 0.26227933168411255
Validation loss: 1.5984313821279874

Epoch: 5| Step: 6
Training loss: 0.24322691559791565
Validation loss: 1.6334189817469607

Epoch: 5| Step: 7
Training loss: 0.2893015742301941
Validation loss: 1.59314400534476

Epoch: 5| Step: 8
Training loss: 0.280600368976593
Validation loss: 1.5854279116917682

Epoch: 5| Step: 9
Training loss: 0.20632466673851013
Validation loss: 1.6003987904517882

Epoch: 5| Step: 10
Training loss: 0.28957024216651917
Validation loss: 1.5972589754289197

Epoch: 402| Step: 0
Training loss: 0.31049495935440063
Validation loss: 1.5792190105684343

Epoch: 5| Step: 1
Training loss: 0.19613830745220184
Validation loss: 1.5870159954153082

Epoch: 5| Step: 2
Training loss: 0.2651742994785309
Validation loss: 1.5850715060387888

Epoch: 5| Step: 3
Training loss: 0.29283952713012695
Validation loss: 1.5821488518868723

Epoch: 5| Step: 4
Training loss: 0.37939006090164185
Validation loss: 1.6058296836832517

Epoch: 5| Step: 5
Training loss: 0.2850154936313629
Validation loss: 1.5808287782053794

Epoch: 5| Step: 6
Training loss: 0.18870344758033752
Validation loss: 1.6220667823668449

Epoch: 5| Step: 7
Training loss: 0.3994113802909851
Validation loss: 1.6181206062275877

Epoch: 5| Step: 8
Training loss: 0.31452375650405884
Validation loss: 1.6135978647457656

Epoch: 5| Step: 9
Training loss: 0.44654566049575806
Validation loss: 1.5910805399699877

Epoch: 5| Step: 10
Training loss: 0.18971672654151917
Validation loss: 1.563815280955325

Epoch: 403| Step: 0
Training loss: 0.391611248254776
Validation loss: 1.5627409847833778

Epoch: 5| Step: 1
Training loss: 0.19716303050518036
Validation loss: 1.575443188349406

Epoch: 5| Step: 2
Training loss: 0.24947071075439453
Validation loss: 1.5706493739158875

Epoch: 5| Step: 3
Training loss: 0.42161402106285095
Validation loss: 1.5900258095033708

Epoch: 5| Step: 4
Training loss: 0.2476341277360916
Validation loss: 1.6087235750690583

Epoch: 5| Step: 5
Training loss: 0.29947903752326965
Validation loss: 1.6047308675704464

Epoch: 5| Step: 6
Training loss: 0.3578084707260132
Validation loss: 1.6279225727563262

Epoch: 5| Step: 7
Training loss: 0.23777636885643005
Validation loss: 1.6221016042975969

Epoch: 5| Step: 8
Training loss: 0.3391880989074707
Validation loss: 1.6271975758255168

Epoch: 5| Step: 9
Training loss: 0.35836273431777954
Validation loss: 1.647337439239666

Epoch: 5| Step: 10
Training loss: 0.33783695101737976
Validation loss: 1.6353404598851358

Epoch: 404| Step: 0
Training loss: 0.3172747492790222
Validation loss: 1.618574709020635

Epoch: 5| Step: 1
Training loss: 0.30107876658439636
Validation loss: 1.6082572648602147

Epoch: 5| Step: 2
Training loss: 0.49937039613723755
Validation loss: 1.5903032056746944

Epoch: 5| Step: 3
Training loss: 0.35880497097969055
Validation loss: 1.6068677248493317

Epoch: 5| Step: 4
Training loss: 0.4665850102901459
Validation loss: 1.6024108554727288

Epoch: 5| Step: 5
Training loss: 0.20100927352905273
Validation loss: 1.6293063163757324

Epoch: 5| Step: 6
Training loss: 0.22825774550437927
Validation loss: 1.637559635664827

Epoch: 5| Step: 7
Training loss: 0.2873380184173584
Validation loss: 1.7061485590473298

Epoch: 5| Step: 8
Training loss: 0.37657132744789124
Validation loss: 1.6988569619835063

Epoch: 5| Step: 9
Training loss: 0.2558012008666992
Validation loss: 1.7560985242166827

Epoch: 5| Step: 10
Training loss: 0.20198588073253632
Validation loss: 1.7026624846202072

Epoch: 405| Step: 0
Training loss: 0.348915159702301
Validation loss: 1.6696645418802898

Epoch: 5| Step: 1
Training loss: 0.311276912689209
Validation loss: 1.6210201171136671

Epoch: 5| Step: 2
Training loss: 0.21233418583869934
Validation loss: 1.617861379859268

Epoch: 5| Step: 3
Training loss: 0.5276482701301575
Validation loss: 1.6221219262769144

Epoch: 5| Step: 4
Training loss: 0.5329405665397644
Validation loss: 1.618230870974961

Epoch: 5| Step: 5
Training loss: 0.31992799043655396
Validation loss: 1.615723556087863

Epoch: 5| Step: 6
Training loss: 0.36485832929611206
Validation loss: 1.6089662685189197

Epoch: 5| Step: 7
Training loss: 0.4435241222381592
Validation loss: 1.6405261639625794

Epoch: 5| Step: 8
Training loss: 0.21532556414604187
Validation loss: 1.6497846649539085

Epoch: 5| Step: 9
Training loss: 0.2976534366607666
Validation loss: 1.64242680739331

Epoch: 5| Step: 10
Training loss: 0.30735281109809875
Validation loss: 1.6756733822566208

Epoch: 406| Step: 0
Training loss: 0.3580881655216217
Validation loss: 1.6912215781468216

Epoch: 5| Step: 1
Training loss: 0.4109407961368561
Validation loss: 1.6824116476120488

Epoch: 5| Step: 2
Training loss: 0.22298407554626465
Validation loss: 1.6718288031957482

Epoch: 5| Step: 3
Training loss: 0.34300148487091064
Validation loss: 1.6084438280392719

Epoch: 5| Step: 4
Training loss: 0.20506052672863007
Validation loss: 1.6102635296442176

Epoch: 5| Step: 5
Training loss: 0.3591771721839905
Validation loss: 1.5919697438516924

Epoch: 5| Step: 6
Training loss: 0.488835871219635
Validation loss: 1.5956988514110606

Epoch: 5| Step: 7
Training loss: 0.3623545169830322
Validation loss: 1.6110113461812336

Epoch: 5| Step: 8
Training loss: 0.41715607047080994
Validation loss: 1.6012783870902112

Epoch: 5| Step: 9
Training loss: 0.31665676832199097
Validation loss: 1.5815945504814066

Epoch: 5| Step: 10
Training loss: 0.2936173975467682
Validation loss: 1.6021542087677987

Epoch: 407| Step: 0
Training loss: 0.28649815917015076
Validation loss: 1.6176090291751328

Epoch: 5| Step: 1
Training loss: 0.43081897497177124
Validation loss: 1.6163857842004428

Epoch: 5| Step: 2
Training loss: 0.3205637037754059
Validation loss: 1.6515374145200175

Epoch: 5| Step: 3
Training loss: 0.31478890776634216
Validation loss: 1.6067916077952231

Epoch: 5| Step: 4
Training loss: 0.30457034707069397
Validation loss: 1.6104011074189217

Epoch: 5| Step: 5
Training loss: 0.399824321269989
Validation loss: 1.6339711848125662

Epoch: 5| Step: 6
Training loss: 0.2661725580692291
Validation loss: 1.6092046435161302

Epoch: 5| Step: 7
Training loss: 0.4000568389892578
Validation loss: 1.659096614007027

Epoch: 5| Step: 8
Training loss: 0.23197007179260254
Validation loss: 1.6575417287888066

Epoch: 5| Step: 9
Training loss: 0.2906014323234558
Validation loss: 1.658305169433676

Epoch: 5| Step: 10
Training loss: 0.21787293255329132
Validation loss: 1.6746739238821051

Epoch: 408| Step: 0
Training loss: 0.36657071113586426
Validation loss: 1.668757951387795

Epoch: 5| Step: 1
Training loss: 0.3445088267326355
Validation loss: 1.6493757693998274

Epoch: 5| Step: 2
Training loss: 0.3428399860858917
Validation loss: 1.680607194541603

Epoch: 5| Step: 3
Training loss: 0.2472887486219406
Validation loss: 1.6669262980902066

Epoch: 5| Step: 4
Training loss: 0.23502913117408752
Validation loss: 1.6203104296038229

Epoch: 5| Step: 5
Training loss: 0.25381991267204285
Validation loss: 1.599734676781521

Epoch: 5| Step: 6
Training loss: 0.332111120223999
Validation loss: 1.585151844127204

Epoch: 5| Step: 7
Training loss: 0.12643851339817047
Validation loss: 1.6112170988513577

Epoch: 5| Step: 8
Training loss: 0.1883510947227478
Validation loss: 1.600504473973346

Epoch: 5| Step: 9
Training loss: 0.5037246942520142
Validation loss: 1.5820143171536025

Epoch: 5| Step: 10
Training loss: 0.308979868888855
Validation loss: 1.5900944791814333

Epoch: 409| Step: 0
Training loss: 0.2450966089963913
Validation loss: 1.6062077078768002

Epoch: 5| Step: 1
Training loss: 0.2910859286785126
Validation loss: 1.6200404808085451

Epoch: 5| Step: 2
Training loss: 0.20283465087413788
Validation loss: 1.643292143780698

Epoch: 5| Step: 3
Training loss: 0.33516520261764526
Validation loss: 1.599641069930087

Epoch: 5| Step: 4
Training loss: 0.2358725517988205
Validation loss: 1.6216811787697576

Epoch: 5| Step: 5
Training loss: 0.3083396852016449
Validation loss: 1.6235834065304007

Epoch: 5| Step: 6
Training loss: 0.44522279500961304
Validation loss: 1.5931801719050254

Epoch: 5| Step: 7
Training loss: 0.1258760243654251
Validation loss: 1.5725845021586264

Epoch: 5| Step: 8
Training loss: 0.3580341637134552
Validation loss: 1.5750844376061552

Epoch: 5| Step: 9
Training loss: 0.4180050790309906
Validation loss: 1.581526521713503

Epoch: 5| Step: 10
Training loss: 0.3642639219760895
Validation loss: 1.5839395317980038

Epoch: 410| Step: 0
Training loss: 0.19774611294269562
Validation loss: 1.5792053643093313

Epoch: 5| Step: 1
Training loss: 0.3123205304145813
Validation loss: 1.5668913497719714

Epoch: 5| Step: 2
Training loss: 0.4412620961666107
Validation loss: 1.564989161747758

Epoch: 5| Step: 3
Training loss: 0.27678167819976807
Validation loss: 1.5564494671360138

Epoch: 5| Step: 4
Training loss: 0.2666187882423401
Validation loss: 1.6060747805462088

Epoch: 5| Step: 5
Training loss: 0.4722767472267151
Validation loss: 1.5723421163456415

Epoch: 5| Step: 6
Training loss: 0.16402581334114075
Validation loss: 1.576621708049569

Epoch: 5| Step: 7
Training loss: 0.29084089398384094
Validation loss: 1.5733300614100632

Epoch: 5| Step: 8
Training loss: 0.2737368643283844
Validation loss: 1.570676604906718

Epoch: 5| Step: 9
Training loss: 0.37496915459632874
Validation loss: 1.5528478801891368

Epoch: 5| Step: 10
Training loss: 0.21450792253017426
Validation loss: 1.5645658957060946

Epoch: 411| Step: 0
Training loss: 0.4132302701473236
Validation loss: 1.558859976389075

Epoch: 5| Step: 1
Training loss: 0.22721099853515625
Validation loss: 1.5553839911696732

Epoch: 5| Step: 2
Training loss: 0.23642945289611816
Validation loss: 1.5674435554012176

Epoch: 5| Step: 3
Training loss: 0.25986146926879883
Validation loss: 1.5894422518309725

Epoch: 5| Step: 4
Training loss: 0.35073959827423096
Validation loss: 1.6182083827193066

Epoch: 5| Step: 5
Training loss: 0.20838458836078644
Validation loss: 1.6215773199194221

Epoch: 5| Step: 6
Training loss: 0.2821063697338104
Validation loss: 1.6445533383277156

Epoch: 5| Step: 7
Training loss: 0.2568650245666504
Validation loss: 1.6113398331467823

Epoch: 5| Step: 8
Training loss: 0.2159656584262848
Validation loss: 1.6062620750037573

Epoch: 5| Step: 9
Training loss: 0.350450336933136
Validation loss: 1.5834364403960526

Epoch: 5| Step: 10
Training loss: 0.25612837076187134
Validation loss: 1.6025442679723103

Epoch: 412| Step: 0
Training loss: 0.24998345971107483
Validation loss: 1.6120870959374212

Epoch: 5| Step: 1
Training loss: 0.14605899155139923
Validation loss: 1.6173759968050065

Epoch: 5| Step: 2
Training loss: 0.32261794805526733
Validation loss: 1.6129529533847686

Epoch: 5| Step: 3
Training loss: 0.3211252689361572
Validation loss: 1.605967362721761

Epoch: 5| Step: 4
Training loss: 0.46966519951820374
Validation loss: 1.6325840552647908

Epoch: 5| Step: 5
Training loss: 0.2541449964046478
Validation loss: 1.622912271048433

Epoch: 5| Step: 6
Training loss: 0.31363487243652344
Validation loss: 1.611600023443981

Epoch: 5| Step: 7
Training loss: 0.24764737486839294
Validation loss: 1.622865915298462

Epoch: 5| Step: 8
Training loss: 0.20905359089374542
Validation loss: 1.589240720195155

Epoch: 5| Step: 9
Training loss: 0.2019701451063156
Validation loss: 1.617838603194042

Epoch: 5| Step: 10
Training loss: 0.2732832431793213
Validation loss: 1.589403316538821

Epoch: 413| Step: 0
Training loss: 0.1749035269021988
Validation loss: 1.6005838224964757

Epoch: 5| Step: 1
Training loss: 0.1457061916589737
Validation loss: 1.6094220953602945

Epoch: 5| Step: 2
Training loss: 0.3116726875305176
Validation loss: 1.6063290180698517

Epoch: 5| Step: 3
Training loss: 0.29750046133995056
Validation loss: 1.6031612965368456

Epoch: 5| Step: 4
Training loss: 0.2669699788093567
Validation loss: 1.6118461303813483

Epoch: 5| Step: 5
Training loss: 0.5484355688095093
Validation loss: 1.620158089104519

Epoch: 5| Step: 6
Training loss: 0.28273123502731323
Validation loss: 1.6304919347968152

Epoch: 5| Step: 7
Training loss: 0.2551671862602234
Validation loss: 1.6839060424476542

Epoch: 5| Step: 8
Training loss: 0.23826241493225098
Validation loss: 1.6622969770944247

Epoch: 5| Step: 9
Training loss: 0.21094730496406555
Validation loss: 1.651922384897868

Epoch: 5| Step: 10
Training loss: 0.27048617601394653
Validation loss: 1.6576530600106845

Epoch: 414| Step: 0
Training loss: 0.30686432123184204
Validation loss: 1.6460680564244587

Epoch: 5| Step: 1
Training loss: 0.3661024868488312
Validation loss: 1.6283765505718928

Epoch: 5| Step: 2
Training loss: 0.25623780488967896
Validation loss: 1.6137702356102646

Epoch: 5| Step: 3
Training loss: 0.40212807059288025
Validation loss: 1.5896578552902385

Epoch: 5| Step: 4
Training loss: 0.22947032749652863
Validation loss: 1.591132983084648

Epoch: 5| Step: 5
Training loss: 0.2206387221813202
Validation loss: 1.5627467273384013

Epoch: 5| Step: 6
Training loss: 0.1676558256149292
Validation loss: 1.5661617235470844

Epoch: 5| Step: 7
Training loss: 0.11782894283533096
Validation loss: 1.5593992099967053

Epoch: 5| Step: 8
Training loss: 0.39127299189567566
Validation loss: 1.5694248509663407

Epoch: 5| Step: 9
Training loss: 0.32686299085617065
Validation loss: 1.5524181883822206

Epoch: 5| Step: 10
Training loss: 0.26110273599624634
Validation loss: 1.5627152701859832

Epoch: 415| Step: 0
Training loss: 0.3187248706817627
Validation loss: 1.5899183352788289

Epoch: 5| Step: 1
Training loss: 0.37515443563461304
Validation loss: 1.5775952262263144

Epoch: 5| Step: 2
Training loss: 0.250916063785553
Validation loss: 1.5765149900990147

Epoch: 5| Step: 3
Training loss: 0.21033897995948792
Validation loss: 1.5829367855543732

Epoch: 5| Step: 4
Training loss: 0.36112886667251587
Validation loss: 1.5849304224855156

Epoch: 5| Step: 5
Training loss: 0.43867939710617065
Validation loss: 1.5841106291740172

Epoch: 5| Step: 6
Training loss: 0.12128953635692596
Validation loss: 1.5986515886040145

Epoch: 5| Step: 7
Training loss: 0.14263205230236053
Validation loss: 1.6058631097116778

Epoch: 5| Step: 8
Training loss: 0.3102668821811676
Validation loss: 1.6039645197570964

Epoch: 5| Step: 9
Training loss: 0.22670216858386993
Validation loss: 1.5865399222220145

Epoch: 5| Step: 10
Training loss: 0.2504495680332184
Validation loss: 1.5699023354438044

Epoch: 416| Step: 0
Training loss: 0.2957802712917328
Validation loss: 1.5515915770684519

Epoch: 5| Step: 1
Training loss: 0.33719760179519653
Validation loss: 1.56642956631158

Epoch: 5| Step: 2
Training loss: 0.18934941291809082
Validation loss: 1.5877315613531298

Epoch: 5| Step: 3
Training loss: 0.27302098274230957
Validation loss: 1.5659746072625602

Epoch: 5| Step: 4
Training loss: 0.17529776692390442
Validation loss: 1.5735356102707565

Epoch: 5| Step: 5
Training loss: 0.36274319887161255
Validation loss: 1.5768109752285866

Epoch: 5| Step: 6
Training loss: 0.23686185479164124
Validation loss: 1.5709667103264922

Epoch: 5| Step: 7
Training loss: 0.2355298548936844
Validation loss: 1.5723437852756952

Epoch: 5| Step: 8
Training loss: 0.22406968474388123
Validation loss: 1.577428816467203

Epoch: 5| Step: 9
Training loss: 0.34561437368392944
Validation loss: 1.617389694336922

Epoch: 5| Step: 10
Training loss: 0.29133927822113037
Validation loss: 1.6206625699996948

Epoch: 417| Step: 0
Training loss: 0.315393328666687
Validation loss: 1.6043526690493348

Epoch: 5| Step: 1
Training loss: 0.2525843679904938
Validation loss: 1.607960416424659

Epoch: 5| Step: 2
Training loss: 0.3290514349937439
Validation loss: 1.6109512185537687

Epoch: 5| Step: 3
Training loss: 0.23066899180412292
Validation loss: 1.5930882128336097

Epoch: 5| Step: 4
Training loss: 0.3596680462360382
Validation loss: 1.5991168791247952

Epoch: 5| Step: 5
Training loss: 0.3871236741542816
Validation loss: 1.6053627370506205

Epoch: 5| Step: 6
Training loss: 0.2781735956668854
Validation loss: 1.6214999370677496

Epoch: 5| Step: 7
Training loss: 0.14929638803005219
Validation loss: 1.6036816079129455

Epoch: 5| Step: 8
Training loss: 0.18855741620063782
Validation loss: 1.6254825553586405

Epoch: 5| Step: 9
Training loss: 0.1803344190120697
Validation loss: 1.5913067479287424

Epoch: 5| Step: 10
Training loss: 0.1772092878818512
Validation loss: 1.581737886192978

Epoch: 418| Step: 0
Training loss: 0.1666335165500641
Validation loss: 1.583985831147881

Epoch: 5| Step: 1
Training loss: 0.2849378287792206
Validation loss: 1.567392715843775

Epoch: 5| Step: 2
Training loss: 0.25856608152389526
Validation loss: 1.5846132245115054

Epoch: 5| Step: 3
Training loss: 0.18332929909229279
Validation loss: 1.5646566947301228

Epoch: 5| Step: 4
Training loss: 0.619623064994812
Validation loss: 1.5850858585808867

Epoch: 5| Step: 5
Training loss: 0.26894673705101013
Validation loss: 1.5815132869187223

Epoch: 5| Step: 6
Training loss: 0.19299377501010895
Validation loss: 1.5900610428984447

Epoch: 5| Step: 7
Training loss: 0.17198272049427032
Validation loss: 1.5685547808165192

Epoch: 5| Step: 8
Training loss: 0.22021141648292542
Validation loss: 1.5983165464093607

Epoch: 5| Step: 9
Training loss: 0.22670722007751465
Validation loss: 1.6029338509805742

Epoch: 5| Step: 10
Training loss: 0.3286762535572052
Validation loss: 1.5665909115986159

Epoch: 419| Step: 0
Training loss: 0.21856088936328888
Validation loss: 1.57289574351362

Epoch: 5| Step: 1
Training loss: 0.25147539377212524
Validation loss: 1.5557632369379844

Epoch: 5| Step: 2
Training loss: 0.5393573045730591
Validation loss: 1.5911103269105316

Epoch: 5| Step: 3
Training loss: 0.22845196723937988
Validation loss: 1.5767245856664514

Epoch: 5| Step: 4
Training loss: 0.2247561514377594
Validation loss: 1.5451927467059063

Epoch: 5| Step: 5
Training loss: 0.20821675658226013
Validation loss: 1.5672658092232161

Epoch: 5| Step: 6
Training loss: 0.2535565495491028
Validation loss: 1.5915470815473987

Epoch: 5| Step: 7
Training loss: 0.22238370776176453
Validation loss: 1.5817968845367432

Epoch: 5| Step: 8
Training loss: 0.2786974310874939
Validation loss: 1.5842645091395224

Epoch: 5| Step: 9
Training loss: 0.18623778223991394
Validation loss: 1.6097018282900575

Epoch: 5| Step: 10
Training loss: 0.24679632484912872
Validation loss: 1.5708070711422992

Epoch: 420| Step: 0
Training loss: 0.29577088356018066
Validation loss: 1.5635956141256517

Epoch: 5| Step: 1
Training loss: 0.3131328523159027
Validation loss: 1.5595709111100884

Epoch: 5| Step: 2
Training loss: 0.2783203721046448
Validation loss: 1.5539039963035173

Epoch: 5| Step: 3
Training loss: 0.30515891313552856
Validation loss: 1.533374232630576

Epoch: 5| Step: 4
Training loss: 0.20741967856884003
Validation loss: 1.544238813461796

Epoch: 5| Step: 5
Training loss: 0.32428357005119324
Validation loss: 1.54730543333997

Epoch: 5| Step: 6
Training loss: 0.27096906304359436
Validation loss: 1.5242873635343326

Epoch: 5| Step: 7
Training loss: 0.2326093167066574
Validation loss: 1.537597842113946

Epoch: 5| Step: 8
Training loss: 0.10715442895889282
Validation loss: 1.5484837562807146

Epoch: 5| Step: 9
Training loss: 0.1915319263935089
Validation loss: 1.554974357287089

Epoch: 5| Step: 10
Training loss: 0.22318123281002045
Validation loss: 1.5708076800069501

Epoch: 421| Step: 0
Training loss: 0.23748092353343964
Validation loss: 1.5775871046127812

Epoch: 5| Step: 1
Training loss: 0.3844098448753357
Validation loss: 1.599946614234678

Epoch: 5| Step: 2
Training loss: 0.2456984519958496
Validation loss: 1.5851099978211105

Epoch: 5| Step: 3
Training loss: 0.23417846858501434
Validation loss: 1.575278853857389

Epoch: 5| Step: 4
Training loss: 0.3813060224056244
Validation loss: 1.5799255242911718

Epoch: 5| Step: 5
Training loss: 0.2348364293575287
Validation loss: 1.617229917997955

Epoch: 5| Step: 6
Training loss: 0.24122337996959686
Validation loss: 1.5922390325095064

Epoch: 5| Step: 7
Training loss: 0.24374744296073914
Validation loss: 1.5958790368931268

Epoch: 5| Step: 8
Training loss: 0.2670779526233673
Validation loss: 1.602764409075501

Epoch: 5| Step: 9
Training loss: 0.33958297967910767
Validation loss: 1.5786822572831185

Epoch: 5| Step: 10
Training loss: 0.1533019244670868
Validation loss: 1.5317594787125945

Epoch: 422| Step: 0
Training loss: 0.38080477714538574
Validation loss: 1.5243299738053353

Epoch: 5| Step: 1
Training loss: 0.15543898940086365
Validation loss: 1.541681073045218

Epoch: 5| Step: 2
Training loss: 0.30174580216407776
Validation loss: 1.5817705879929245

Epoch: 5| Step: 3
Training loss: 0.28972959518432617
Validation loss: 1.5852700715423913

Epoch: 5| Step: 4
Training loss: 0.3095262348651886
Validation loss: 1.5395731913146151

Epoch: 5| Step: 5
Training loss: 0.2513609528541565
Validation loss: 1.5558113231453845

Epoch: 5| Step: 6
Training loss: 0.3289705216884613
Validation loss: 1.5629121513776882

Epoch: 5| Step: 7
Training loss: 0.2110881805419922
Validation loss: 1.5408921049487205

Epoch: 5| Step: 8
Training loss: 0.3801615536212921
Validation loss: 1.6124739967366701

Epoch: 5| Step: 9
Training loss: 0.3148171901702881
Validation loss: 1.6065016734984614

Epoch: 5| Step: 10
Training loss: 0.29018548130989075
Validation loss: 1.6032411590699227

Epoch: 423| Step: 0
Training loss: 0.22243377566337585
Validation loss: 1.556460233785773

Epoch: 5| Step: 1
Training loss: 0.4237402379512787
Validation loss: 1.556878037350152

Epoch: 5| Step: 2
Training loss: 0.1592995822429657
Validation loss: 1.56773252384637

Epoch: 5| Step: 3
Training loss: 0.4089980125427246
Validation loss: 1.6094153799036497

Epoch: 5| Step: 4
Training loss: 0.2751990854740143
Validation loss: 1.6142502036145938

Epoch: 5| Step: 5
Training loss: 0.37593039870262146
Validation loss: 1.5923022864967264

Epoch: 5| Step: 6
Training loss: 0.22085678577423096
Validation loss: 1.587215570993321

Epoch: 5| Step: 7
Training loss: 0.41189923882484436
Validation loss: 1.5965294581587597

Epoch: 5| Step: 8
Training loss: 0.10364208370447159
Validation loss: 1.5868821015921972

Epoch: 5| Step: 9
Training loss: 0.28451433777809143
Validation loss: 1.6045364718283377

Epoch: 5| Step: 10
Training loss: 0.31902948021888733
Validation loss: 1.6190154706278155

Epoch: 424| Step: 0
Training loss: 0.26119667291641235
Validation loss: 1.596412585627648

Epoch: 5| Step: 1
Training loss: 0.20583005249500275
Validation loss: 1.5918828684796569

Epoch: 5| Step: 2
Training loss: 0.25674888491630554
Validation loss: 1.596687093857796

Epoch: 5| Step: 3
Training loss: 0.14823278784751892
Validation loss: 1.575813199884148

Epoch: 5| Step: 4
Training loss: 0.2772971987724304
Validation loss: 1.5848578035190541

Epoch: 5| Step: 5
Training loss: 0.18755798041820526
Validation loss: 1.5914606586579354

Epoch: 5| Step: 6
Training loss: 0.2316754311323166
Validation loss: 1.6055458873830817

Epoch: 5| Step: 7
Training loss: 0.2901294231414795
Validation loss: 1.5677818893104472

Epoch: 5| Step: 8
Training loss: 0.3056090772151947
Validation loss: 1.627121558753393

Epoch: 5| Step: 9
Training loss: 0.4196845591068268
Validation loss: 1.6520018334029822

Epoch: 5| Step: 10
Training loss: 0.35364291071891785
Validation loss: 1.6319377268514326

Epoch: 425| Step: 0
Training loss: 0.34205377101898193
Validation loss: 1.6392203095138713

Epoch: 5| Step: 1
Training loss: 0.24691057205200195
Validation loss: 1.6046236843191168

Epoch: 5| Step: 2
Training loss: 0.19618332386016846
Validation loss: 1.6052500881174558

Epoch: 5| Step: 3
Training loss: 0.27287769317626953
Validation loss: 1.5755495807175994

Epoch: 5| Step: 4
Training loss: 0.2140178680419922
Validation loss: 1.5634638609424714

Epoch: 5| Step: 5
Training loss: 0.19578967988491058
Validation loss: 1.552160498916462

Epoch: 5| Step: 6
Training loss: 0.4329872131347656
Validation loss: 1.543939540463109

Epoch: 5| Step: 7
Training loss: 0.3238329291343689
Validation loss: 1.5227658646081084

Epoch: 5| Step: 8
Training loss: 0.22894172370433807
Validation loss: 1.5159644478110856

Epoch: 5| Step: 9
Training loss: 0.2082492858171463
Validation loss: 1.522647887147883

Epoch: 5| Step: 10
Training loss: 0.21811561286449432
Validation loss: 1.5200581345506894

Epoch: 426| Step: 0
Training loss: 0.16859187185764313
Validation loss: 1.5446932367099229

Epoch: 5| Step: 1
Training loss: 0.2710950970649719
Validation loss: 1.530683789201962

Epoch: 5| Step: 2
Training loss: 0.1726398915052414
Validation loss: 1.5166530968040548

Epoch: 5| Step: 3
Training loss: 0.21481986343860626
Validation loss: 1.5327058094804005

Epoch: 5| Step: 4
Training loss: 0.3149769604206085
Validation loss: 1.5548425541129163

Epoch: 5| Step: 5
Training loss: 0.4298512041568756
Validation loss: 1.5888102439142042

Epoch: 5| Step: 6
Training loss: 0.29146379232406616
Validation loss: 1.5911710980117961

Epoch: 5| Step: 7
Training loss: 0.09241481870412827
Validation loss: 1.5543873976635676

Epoch: 5| Step: 8
Training loss: 0.2802864909172058
Validation loss: 1.58090373393028

Epoch: 5| Step: 9
Training loss: 0.32551202178001404
Validation loss: 1.5883215364589487

Epoch: 5| Step: 10
Training loss: 0.17064528167247772
Validation loss: 1.6333853519091042

Epoch: 427| Step: 0
Training loss: 0.38356107473373413
Validation loss: 1.6249600405334144

Epoch: 5| Step: 1
Training loss: 0.1454741358757019
Validation loss: 1.6204076249112365

Epoch: 5| Step: 2
Training loss: 0.2047162801027298
Validation loss: 1.6392650886248517

Epoch: 5| Step: 3
Training loss: 0.2870481610298157
Validation loss: 1.605864873496435

Epoch: 5| Step: 4
Training loss: 0.31459006667137146
Validation loss: 1.589337670674888

Epoch: 5| Step: 5
Training loss: 0.23673740029335022
Validation loss: 1.5719675581942323

Epoch: 5| Step: 6
Training loss: 0.1814538538455963
Validation loss: 1.5616649081630092

Epoch: 5| Step: 7
Training loss: 0.20218472182750702
Validation loss: 1.5760950042355446

Epoch: 5| Step: 8
Training loss: 0.251919150352478
Validation loss: 1.565825746905419

Epoch: 5| Step: 9
Training loss: 0.4401782155036926
Validation loss: 1.5451959461294196

Epoch: 5| Step: 10
Training loss: 0.1387324333190918
Validation loss: 1.5860928335497457

Epoch: 428| Step: 0
Training loss: 0.35176679491996765
Validation loss: 1.544976261354262

Epoch: 5| Step: 1
Training loss: 0.17753246426582336
Validation loss: 1.5769047391030095

Epoch: 5| Step: 2
Training loss: 0.1522250473499298
Validation loss: 1.5991749776306974

Epoch: 5| Step: 3
Training loss: 0.2996003329753876
Validation loss: 1.6225407982385287

Epoch: 5| Step: 4
Training loss: 0.40326476097106934
Validation loss: 1.6193075449235979

Epoch: 5| Step: 5
Training loss: 0.21611344814300537
Validation loss: 1.619022338621078

Epoch: 5| Step: 6
Training loss: 0.1324022263288498
Validation loss: 1.6309097505384875

Epoch: 5| Step: 7
Training loss: 0.2674823999404907
Validation loss: 1.6156488016087522

Epoch: 5| Step: 8
Training loss: 0.21111658215522766
Validation loss: 1.6295424161418792

Epoch: 5| Step: 9
Training loss: 0.2612285017967224
Validation loss: 1.6114586655811598

Epoch: 5| Step: 10
Training loss: 0.18122106790542603
Validation loss: 1.580725594233441

Epoch: 429| Step: 0
Training loss: 0.13910678029060364
Validation loss: 1.636818253865806

Epoch: 5| Step: 1
Training loss: 0.27392131090164185
Validation loss: 1.6246853169574533

Epoch: 5| Step: 2
Training loss: 0.24179688096046448
Validation loss: 1.6322175841177664

Epoch: 5| Step: 3
Training loss: 0.22795145213603973
Validation loss: 1.640175873233426

Epoch: 5| Step: 4
Training loss: 0.2225777804851532
Validation loss: 1.6147511492493332

Epoch: 5| Step: 5
Training loss: 0.3316325843334198
Validation loss: 1.6135060582109677

Epoch: 5| Step: 6
Training loss: 0.30606549978256226
Validation loss: 1.5953031374562172

Epoch: 5| Step: 7
Training loss: 0.3849732577800751
Validation loss: 1.5922291804385442

Epoch: 5| Step: 8
Training loss: 0.24575892090797424
Validation loss: 1.596678505661667

Epoch: 5| Step: 9
Training loss: 0.21760383248329163
Validation loss: 1.5535462863983647

Epoch: 5| Step: 10
Training loss: 0.21359600126743317
Validation loss: 1.5505077582533642

Epoch: 430| Step: 0
Training loss: 0.2526124119758606
Validation loss: 1.5263872031242616

Epoch: 5| Step: 1
Training loss: 0.29706862568855286
Validation loss: 1.5385445933188162

Epoch: 5| Step: 2
Training loss: 0.3282601535320282
Validation loss: 1.529251362687798

Epoch: 5| Step: 3
Training loss: 0.2583133578300476
Validation loss: 1.5384008525520243

Epoch: 5| Step: 4
Training loss: 0.2788551151752472
Validation loss: 1.5631656928728985

Epoch: 5| Step: 5
Training loss: 0.19279615581035614
Validation loss: 1.5894462318830593

Epoch: 5| Step: 6
Training loss: 0.16175974905490875
Validation loss: 1.5996090660813034

Epoch: 5| Step: 7
Training loss: 0.23662924766540527
Validation loss: 1.6075615934146348

Epoch: 5| Step: 8
Training loss: 0.24117358028888702
Validation loss: 1.6098367591058054

Epoch: 5| Step: 9
Training loss: 0.2898370921611786
Validation loss: 1.5905718124040993

Epoch: 5| Step: 10
Training loss: 0.2605401277542114
Validation loss: 1.5596879893733608

Epoch: 431| Step: 0
Training loss: 0.11677588522434235
Validation loss: 1.572416882361135

Epoch: 5| Step: 1
Training loss: 0.27846914529800415
Validation loss: 1.5696236420703191

Epoch: 5| Step: 2
Training loss: 0.25405189394950867
Validation loss: 1.5685030862849245

Epoch: 5| Step: 3
Training loss: 0.3374224603176117
Validation loss: 1.566324944137245

Epoch: 5| Step: 4
Training loss: 0.2395433485507965
Validation loss: 1.5674960100522606

Epoch: 5| Step: 5
Training loss: 0.2772304117679596
Validation loss: 1.5644977849016908

Epoch: 5| Step: 6
Training loss: 0.44865846633911133
Validation loss: 1.5679457341471026

Epoch: 5| Step: 7
Training loss: 0.16769370436668396
Validation loss: 1.5797534629862795

Epoch: 5| Step: 8
Training loss: 0.2973993718624115
Validation loss: 1.6612020115698538

Epoch: 5| Step: 9
Training loss: 0.2696259319782257
Validation loss: 1.6277703469799412

Epoch: 5| Step: 10
Training loss: 0.26715704798698425
Validation loss: 1.6120771759299821

Epoch: 432| Step: 0
Training loss: 0.29691410064697266
Validation loss: 1.6180694231422998

Epoch: 5| Step: 1
Training loss: 0.13499626517295837
Validation loss: 1.6050179671215754

Epoch: 5| Step: 2
Training loss: 0.20919640362262726
Validation loss: 1.515937089920044

Epoch: 5| Step: 3
Training loss: 0.27158865332603455
Validation loss: 1.5298696640999085

Epoch: 5| Step: 4
Training loss: 0.34602126479148865
Validation loss: 1.5204371329276793

Epoch: 5| Step: 5
Training loss: 0.23792004585266113
Validation loss: 1.5561850468317668

Epoch: 5| Step: 6
Training loss: 0.2422810047864914
Validation loss: 1.5933721321885304

Epoch: 5| Step: 7
Training loss: 0.2165713608264923
Validation loss: 1.6149872246608938

Epoch: 5| Step: 8
Training loss: 0.4075511395931244
Validation loss: 1.5753869241283787

Epoch: 5| Step: 9
Training loss: 0.1062978133559227
Validation loss: 1.5761420508866668

Epoch: 5| Step: 10
Training loss: 0.17626553773880005
Validation loss: 1.5772605455049904

Epoch: 433| Step: 0
Training loss: 0.37482914328575134
Validation loss: 1.6064873651791645

Epoch: 5| Step: 1
Training loss: 0.16492637991905212
Validation loss: 1.6347326488905056

Epoch: 5| Step: 2
Training loss: 0.18327046930789948
Validation loss: 1.605846889557377

Epoch: 5| Step: 3
Training loss: 0.18319915235042572
Validation loss: 1.5844679429966917

Epoch: 5| Step: 4
Training loss: 0.27675536274909973
Validation loss: 1.599351825252656

Epoch: 5| Step: 5
Training loss: 0.14704033732414246
Validation loss: 1.5963369338743147

Epoch: 5| Step: 6
Training loss: 0.20575745403766632
Validation loss: 1.6004853453687442

Epoch: 5| Step: 7
Training loss: 0.33715498447418213
Validation loss: 1.5894457268458542

Epoch: 5| Step: 8
Training loss: 0.23618951439857483
Validation loss: 1.6158668994903564

Epoch: 5| Step: 9
Training loss: 0.2942926287651062
Validation loss: 1.6011229484311995

Epoch: 5| Step: 10
Training loss: 0.21469102799892426
Validation loss: 1.6070722418446695

Epoch: 434| Step: 0
Training loss: 0.15015210211277008
Validation loss: 1.573505704120923

Epoch: 5| Step: 1
Training loss: 0.24426381289958954
Validation loss: 1.5595957540696668

Epoch: 5| Step: 2
Training loss: 0.16720011830329895
Validation loss: 1.528419408746945

Epoch: 5| Step: 3
Training loss: 0.27601975202560425
Validation loss: 1.521358718154251

Epoch: 5| Step: 4
Training loss: 0.2894046902656555
Validation loss: 1.5390234147348711

Epoch: 5| Step: 5
Training loss: 0.1938161551952362
Validation loss: 1.5301636931716756

Epoch: 5| Step: 6
Training loss: 0.30624884366989136
Validation loss: 1.5339847034023655

Epoch: 5| Step: 7
Training loss: 0.2349885255098343
Validation loss: 1.5080500379685433

Epoch: 5| Step: 8
Training loss: 0.2620873749256134
Validation loss: 1.516333310193913

Epoch: 5| Step: 9
Training loss: 0.29155996441841125
Validation loss: 1.5036726613198557

Epoch: 5| Step: 10
Training loss: 0.22109316289424896
Validation loss: 1.5270307692148353

Epoch: 435| Step: 0
Training loss: 0.299718976020813
Validation loss: 1.5361967022700975

Epoch: 5| Step: 1
Training loss: 0.32084962725639343
Validation loss: 1.5580422134809597

Epoch: 5| Step: 2
Training loss: 0.1846538484096527
Validation loss: 1.5740193256767847

Epoch: 5| Step: 3
Training loss: 0.2556638717651367
Validation loss: 1.527250333498883

Epoch: 5| Step: 4
Training loss: 0.2080204039812088
Validation loss: 1.531431431411415

Epoch: 5| Step: 5
Training loss: 0.2824246287345886
Validation loss: 1.5213735218971007

Epoch: 5| Step: 6
Training loss: 0.3506762683391571
Validation loss: 1.526197733417634

Epoch: 5| Step: 7
Training loss: 0.0847804993391037
Validation loss: 1.5304779006588844

Epoch: 5| Step: 8
Training loss: 0.1514885574579239
Validation loss: 1.5533529084215882

Epoch: 5| Step: 9
Training loss: 0.2183477133512497
Validation loss: 1.563985986094321

Epoch: 5| Step: 10
Training loss: 0.2805333137512207
Validation loss: 1.5473681201216996

Epoch: 436| Step: 0
Training loss: 0.18225611746311188
Validation loss: 1.5806291141817648

Epoch: 5| Step: 1
Training loss: 0.1803540736436844
Validation loss: 1.5903025852736605

Epoch: 5| Step: 2
Training loss: 0.19095513224601746
Validation loss: 1.553574315963253

Epoch: 5| Step: 3
Training loss: 0.22933641076087952
Validation loss: 1.5739099171853834

Epoch: 5| Step: 4
Training loss: 0.36256250739097595
Validation loss: 1.5800035333120694

Epoch: 5| Step: 5
Training loss: 0.22669915854930878
Validation loss: 1.5666858637204735

Epoch: 5| Step: 6
Training loss: 0.26771920919418335
Validation loss: 1.5438051480118946

Epoch: 5| Step: 7
Training loss: 0.22574841976165771
Validation loss: 1.5471689777989541

Epoch: 5| Step: 8
Training loss: 0.32851120829582214
Validation loss: 1.5029634955108806

Epoch: 5| Step: 9
Training loss: 0.22652184963226318
Validation loss: 1.5397774763004755

Epoch: 5| Step: 10
Training loss: 0.22412335872650146
Validation loss: 1.5220220704232492

Epoch: 437| Step: 0
Training loss: 0.34090080857276917
Validation loss: 1.526094118754069

Epoch: 5| Step: 1
Training loss: 0.17979833483695984
Validation loss: 1.5288137441040368

Epoch: 5| Step: 2
Training loss: 0.21580898761749268
Validation loss: 1.5489845596333986

Epoch: 5| Step: 3
Training loss: 0.12619218230247498
Validation loss: 1.5396780993348809

Epoch: 5| Step: 4
Training loss: 0.2528764307498932
Validation loss: 1.5288952101943314

Epoch: 5| Step: 5
Training loss: 0.26881471276283264
Validation loss: 1.5357795498704399

Epoch: 5| Step: 6
Training loss: 0.3220939636230469
Validation loss: 1.526820134091121

Epoch: 5| Step: 7
Training loss: 0.215552419424057
Validation loss: 1.5327418017131027

Epoch: 5| Step: 8
Training loss: 0.16442900896072388
Validation loss: 1.551350789685403

Epoch: 5| Step: 9
Training loss: 0.31843000650405884
Validation loss: 1.5258879674378263

Epoch: 5| Step: 10
Training loss: 0.20683610439300537
Validation loss: 1.5504009595481298

Epoch: 438| Step: 0
Training loss: 0.26327019929885864
Validation loss: 1.558803996732158

Epoch: 5| Step: 1
Training loss: 0.21314239501953125
Validation loss: 1.5694778016818467

Epoch: 5| Step: 2
Training loss: 0.21659615635871887
Validation loss: 1.560229689844193

Epoch: 5| Step: 3
Training loss: 0.18363340198993683
Validation loss: 1.5805263262923046

Epoch: 5| Step: 4
Training loss: 0.2166067659854889
Validation loss: 1.5565442910758398

Epoch: 5| Step: 5
Training loss: 0.29369989037513733
Validation loss: 1.5690992186146397

Epoch: 5| Step: 6
Training loss: 0.11996622383594513
Validation loss: 1.579437740387455

Epoch: 5| Step: 7
Training loss: 0.1275685727596283
Validation loss: 1.560274315136735

Epoch: 5| Step: 8
Training loss: 0.2939814627170563
Validation loss: 1.5324777813367947

Epoch: 5| Step: 9
Training loss: 0.2170870304107666
Validation loss: 1.5498164135922667

Epoch: 5| Step: 10
Training loss: 0.2826788127422333
Validation loss: 1.531513693512127

Epoch: 439| Step: 0
Training loss: 0.22140726447105408
Validation loss: 1.536809467500256

Epoch: 5| Step: 1
Training loss: 0.41276678442955017
Validation loss: 1.523409394807713

Epoch: 5| Step: 2
Training loss: 0.2660495340824127
Validation loss: 1.5274727511149582

Epoch: 5| Step: 3
Training loss: 0.16570107638835907
Validation loss: 1.5363966495760026

Epoch: 5| Step: 4
Training loss: 0.39331310987472534
Validation loss: 1.5055164957559237

Epoch: 5| Step: 5
Training loss: 0.2157716304063797
Validation loss: 1.5499695206201205

Epoch: 5| Step: 6
Training loss: 0.16214480996131897
Validation loss: 1.535195868502381

Epoch: 5| Step: 7
Training loss: 0.17967969179153442
Validation loss: 1.5523196125543246

Epoch: 5| Step: 8
Training loss: 0.15577362477779388
Validation loss: 1.5677576398336759

Epoch: 5| Step: 9
Training loss: 0.2269890010356903
Validation loss: 1.565450777289688

Epoch: 5| Step: 10
Training loss: 0.11713757365942001
Validation loss: 1.5428339172435064

Epoch: 440| Step: 0
Training loss: 0.1162893995642662
Validation loss: 1.5410305171884515

Epoch: 5| Step: 1
Training loss: 0.13263481855392456
Validation loss: 1.5305985404599098

Epoch: 5| Step: 2
Training loss: 0.33479148149490356
Validation loss: 1.5193702546499108

Epoch: 5| Step: 3
Training loss: 0.23902985453605652
Validation loss: 1.5464038900149766

Epoch: 5| Step: 4
Training loss: 0.23995332419872284
Validation loss: 1.5538952953072005

Epoch: 5| Step: 5
Training loss: 0.3134123682975769
Validation loss: 1.5344768801043112

Epoch: 5| Step: 6
Training loss: 0.1691676527261734
Validation loss: 1.5231881731299943

Epoch: 5| Step: 7
Training loss: 0.2277127206325531
Validation loss: 1.5181808183270116

Epoch: 5| Step: 8
Training loss: 0.29520025849342346
Validation loss: 1.5344534227924962

Epoch: 5| Step: 9
Training loss: 0.17057372629642487
Validation loss: 1.5342809769415087

Epoch: 5| Step: 10
Training loss: 0.1956101655960083
Validation loss: 1.5569123850073865

Epoch: 441| Step: 0
Training loss: 0.1957729458808899
Validation loss: 1.5697778783818728

Epoch: 5| Step: 1
Training loss: 0.29339033365249634
Validation loss: 1.5644819377571024

Epoch: 5| Step: 2
Training loss: 0.15721891820430756
Validation loss: 1.5772441356412825

Epoch: 5| Step: 3
Training loss: 0.2560477554798126
Validation loss: 1.5660231126252042

Epoch: 5| Step: 4
Training loss: 0.1706245243549347
Validation loss: 1.5723872659026936

Epoch: 5| Step: 5
Training loss: 0.2047794759273529
Validation loss: 1.5481426203122703

Epoch: 5| Step: 6
Training loss: 0.2971517741680145
Validation loss: 1.545033542058801

Epoch: 5| Step: 7
Training loss: 0.2777957022190094
Validation loss: 1.5398820580974701

Epoch: 5| Step: 8
Training loss: 0.18758906424045563
Validation loss: 1.5594324681066698

Epoch: 5| Step: 9
Training loss: 0.26837393641471863
Validation loss: 1.53636299538356

Epoch: 5| Step: 10
Training loss: 0.12134908139705658
Validation loss: 1.5550492117481847

Epoch: 442| Step: 0
Training loss: 0.18014021217823029
Validation loss: 1.5569883386294048

Epoch: 5| Step: 1
Training loss: 0.18888136744499207
Validation loss: 1.5634751242976035

Epoch: 5| Step: 2
Training loss: 0.28731879591941833
Validation loss: 1.584103488153027

Epoch: 5| Step: 3
Training loss: 0.23632526397705078
Validation loss: 1.581553905240951

Epoch: 5| Step: 4
Training loss: 0.2611021399497986
Validation loss: 1.5828260965244745

Epoch: 5| Step: 5
Training loss: 0.2256055623292923
Validation loss: 1.5424486667879167

Epoch: 5| Step: 6
Training loss: 0.3097746670246124
Validation loss: 1.5419268351729198

Epoch: 5| Step: 7
Training loss: 0.15688136219978333
Validation loss: 1.53581585679003

Epoch: 5| Step: 8
Training loss: 0.24233941733837128
Validation loss: 1.5281803736122705

Epoch: 5| Step: 9
Training loss: 0.15589401125907898
Validation loss: 1.5325866559500336

Epoch: 5| Step: 10
Training loss: 0.1678536981344223
Validation loss: 1.5480733481786584

Epoch: 443| Step: 0
Training loss: 0.18933825194835663
Validation loss: 1.528137630031955

Epoch: 5| Step: 1
Training loss: 0.11588485538959503
Validation loss: 1.5298814324922458

Epoch: 5| Step: 2
Training loss: 0.3329239785671234
Validation loss: 1.5519637920523202

Epoch: 5| Step: 3
Training loss: 0.15738937258720398
Validation loss: 1.5356596195569603

Epoch: 5| Step: 4
Training loss: 0.1637052595615387
Validation loss: 1.5700794778844362

Epoch: 5| Step: 5
Training loss: 0.2571532726287842
Validation loss: 1.5698757761268205

Epoch: 5| Step: 6
Training loss: 0.24929532408714294
Validation loss: 1.5658406698575584

Epoch: 5| Step: 7
Training loss: 0.269255667924881
Validation loss: 1.5575721930432063

Epoch: 5| Step: 8
Training loss: 0.12185215950012207
Validation loss: 1.5651474678388206

Epoch: 5| Step: 9
Training loss: 0.2301863431930542
Validation loss: 1.5996359804625153

Epoch: 5| Step: 10
Training loss: 0.43931910395622253
Validation loss: 1.5163025779108847

Epoch: 444| Step: 0
Training loss: 0.4383862614631653
Validation loss: 1.5586224807206022

Epoch: 5| Step: 1
Training loss: 0.14352962374687195
Validation loss: 1.5355974910079793

Epoch: 5| Step: 2
Training loss: 0.18109050393104553
Validation loss: 1.5462870392748105

Epoch: 5| Step: 3
Training loss: 0.1653537005186081
Validation loss: 1.5449929519366192

Epoch: 5| Step: 4
Training loss: 0.1494608223438263
Validation loss: 1.540777906294792

Epoch: 5| Step: 5
Training loss: 0.2702164649963379
Validation loss: 1.5625070166844193

Epoch: 5| Step: 6
Training loss: 0.3272450566291809
Validation loss: 1.5957075991938192

Epoch: 5| Step: 7
Training loss: 0.12433405220508575
Validation loss: 1.6019450874738796

Epoch: 5| Step: 8
Training loss: 0.2875366806983948
Validation loss: 1.5936207553391815

Epoch: 5| Step: 9
Training loss: 0.32199668884277344
Validation loss: 1.5798385938008626

Epoch: 5| Step: 10
Training loss: 0.1524183601140976
Validation loss: 1.573178469493825

Epoch: 445| Step: 0
Training loss: 0.16724886000156403
Validation loss: 1.535951138824545

Epoch: 5| Step: 1
Training loss: 0.13510021567344666
Validation loss: 1.540961919292327

Epoch: 5| Step: 2
Training loss: 0.22120773792266846
Validation loss: 1.5358521079504361

Epoch: 5| Step: 3
Training loss: 0.19256165623664856
Validation loss: 1.5291125062973268

Epoch: 5| Step: 4
Training loss: 0.19177459180355072
Validation loss: 1.5233813549882622

Epoch: 5| Step: 5
Training loss: 0.3143519163131714
Validation loss: 1.49006889840608

Epoch: 5| Step: 6
Training loss: 0.22440743446350098
Validation loss: 1.4815404222857567

Epoch: 5| Step: 7
Training loss: 0.3139202892780304
Validation loss: 1.4926782974632837

Epoch: 5| Step: 8
Training loss: 0.11398351192474365
Validation loss: 1.531419059281708

Epoch: 5| Step: 9
Training loss: 0.29532596468925476
Validation loss: 1.555669217981318

Epoch: 5| Step: 10
Training loss: 0.3180573284626007
Validation loss: 1.5878982069671794

Epoch: 446| Step: 0
Training loss: 0.1471840888261795
Validation loss: 1.5597891846010763

Epoch: 5| Step: 1
Training loss: 0.13417494297027588
Validation loss: 1.5565054224383446

Epoch: 5| Step: 2
Training loss: 0.16736727952957153
Validation loss: 1.5628488140721475

Epoch: 5| Step: 3
Training loss: 0.22728519141674042
Validation loss: 1.5596651620762323

Epoch: 5| Step: 4
Training loss: 0.2350953370332718
Validation loss: 1.5476655626809726

Epoch: 5| Step: 5
Training loss: 0.16727110743522644
Validation loss: 1.5240181171765892

Epoch: 5| Step: 6
Training loss: 0.15051987767219543
Validation loss: 1.5187354978694712

Epoch: 5| Step: 7
Training loss: 0.20151782035827637
Validation loss: 1.5235207055204658

Epoch: 5| Step: 8
Training loss: 0.40431874990463257
Validation loss: 1.5410805799627816

Epoch: 5| Step: 9
Training loss: 0.3875592350959778
Validation loss: 1.5359678127432381

Epoch: 5| Step: 10
Training loss: 0.23875443637371063
Validation loss: 1.5748911057749102

Epoch: 447| Step: 0
Training loss: 0.16891025006771088
Validation loss: 1.5752160702982256

Epoch: 5| Step: 1
Training loss: 0.2346905916929245
Validation loss: 1.5452479893161404

Epoch: 5| Step: 2
Training loss: 0.4671551287174225
Validation loss: 1.5357830947445286

Epoch: 5| Step: 3
Training loss: 0.22798626124858856
Validation loss: 1.5583006310206589

Epoch: 5| Step: 4
Training loss: 0.19220861792564392
Validation loss: 1.5332745903281755

Epoch: 5| Step: 5
Training loss: 0.09824655205011368
Validation loss: 1.5129390608879827

Epoch: 5| Step: 6
Training loss: 0.16622214019298553
Validation loss: 1.530343032652332

Epoch: 5| Step: 7
Training loss: 0.23667101562023163
Validation loss: 1.5117938813342844

Epoch: 5| Step: 8
Training loss: 0.23050089180469513
Validation loss: 1.5002502036351029

Epoch: 5| Step: 9
Training loss: 0.13854719698429108
Validation loss: 1.522306760152181

Epoch: 5| Step: 10
Training loss: 0.25375378131866455
Validation loss: 1.5276701232438445

Epoch: 448| Step: 0
Training loss: 0.12312193214893341
Validation loss: 1.5463000702601608

Epoch: 5| Step: 1
Training loss: 0.19677014648914337
Validation loss: 1.5321887693097513

Epoch: 5| Step: 2
Training loss: 0.30239367485046387
Validation loss: 1.5586621761322021

Epoch: 5| Step: 3
Training loss: 0.13028353452682495
Validation loss: 1.5504065482847151

Epoch: 5| Step: 4
Training loss: 0.17632511258125305
Validation loss: 1.5346135913684804

Epoch: 5| Step: 5
Training loss: 0.17252595722675323
Validation loss: 1.5399226578333045

Epoch: 5| Step: 6
Training loss: 0.4468325674533844
Validation loss: 1.5154999802189488

Epoch: 5| Step: 7
Training loss: 0.2589615285396576
Validation loss: 1.5022178978048346

Epoch: 5| Step: 8
Training loss: 0.17679499089717865
Validation loss: 1.5204866381101712

Epoch: 5| Step: 9
Training loss: 0.2533796429634094
Validation loss: 1.5349489245363461

Epoch: 5| Step: 10
Training loss: 0.18999114632606506
Validation loss: 1.536197405989452

Epoch: 449| Step: 0
Training loss: 0.2277078926563263
Validation loss: 1.5140821267199773

Epoch: 5| Step: 1
Training loss: 0.173920139670372
Validation loss: 1.5533020957823722

Epoch: 5| Step: 2
Training loss: 0.24206843972206116
Validation loss: 1.5126115128558169

Epoch: 5| Step: 3
Training loss: 0.23392195999622345
Validation loss: 1.5183534468373945

Epoch: 5| Step: 4
Training loss: 0.11617283523082733
Validation loss: 1.5345593793417818

Epoch: 5| Step: 5
Training loss: 0.26216721534729004
Validation loss: 1.5479067397373978

Epoch: 5| Step: 6
Training loss: 0.16881254315376282
Validation loss: 1.5272034547662223

Epoch: 5| Step: 7
Training loss: 0.24993662536144257
Validation loss: 1.5323887948066957

Epoch: 5| Step: 8
Training loss: 0.24425283074378967
Validation loss: 1.5493502424609276

Epoch: 5| Step: 9
Training loss: 0.18047454953193665
Validation loss: 1.549074431901337

Epoch: 5| Step: 10
Training loss: 0.2015894651412964
Validation loss: 1.5392691653261903

Epoch: 450| Step: 0
Training loss: 0.27025604248046875
Validation loss: 1.5969319215384863

Epoch: 5| Step: 1
Training loss: 0.21402402222156525
Validation loss: 1.5702276934859574

Epoch: 5| Step: 2
Training loss: 0.29632800817489624
Validation loss: 1.5892773443652737

Epoch: 5| Step: 3
Training loss: 0.2164371758699417
Validation loss: 1.5663342488709318

Epoch: 5| Step: 4
Training loss: 0.20430684089660645
Validation loss: 1.553851842880249

Epoch: 5| Step: 5
Training loss: 0.18956272304058075
Validation loss: 1.5458104450215575

Epoch: 5| Step: 6
Training loss: 0.2793017029762268
Validation loss: 1.549148714670571

Epoch: 5| Step: 7
Training loss: 0.10180671513080597
Validation loss: 1.5295731277876004

Epoch: 5| Step: 8
Training loss: 0.17738297581672668
Validation loss: 1.547034502029419

Epoch: 5| Step: 9
Training loss: 0.27040189504623413
Validation loss: 1.5324541599519792

Epoch: 5| Step: 10
Training loss: 0.08108252286911011
Validation loss: 1.545722935789375

Epoch: 451| Step: 0
Training loss: 0.14005184173583984
Validation loss: 1.5640281951555641

Epoch: 5| Step: 1
Training loss: 0.2383941113948822
Validation loss: 1.5516947020766556

Epoch: 5| Step: 2
Training loss: 0.2549080550670624
Validation loss: 1.563657796511086

Epoch: 5| Step: 3
Training loss: 0.3162631094455719
Validation loss: 1.5419521844515236

Epoch: 5| Step: 4
Training loss: 0.10422945022583008
Validation loss: 1.5331318827085598

Epoch: 5| Step: 5
Training loss: 0.203705832362175
Validation loss: 1.509794299320508

Epoch: 5| Step: 6
Training loss: 0.13562944531440735
Validation loss: 1.5245898615929387

Epoch: 5| Step: 7
Training loss: 0.21832089126110077
Validation loss: 1.529065255195864

Epoch: 5| Step: 8
Training loss: 0.3750242292881012
Validation loss: 1.5131259989994827

Epoch: 5| Step: 9
Training loss: 0.24717597663402557
Validation loss: 1.5019997691595426

Epoch: 5| Step: 10
Training loss: 0.3223932683467865
Validation loss: 1.503094675720379

Epoch: 452| Step: 0
Training loss: 0.14248375594615936
Validation loss: 1.4973989148293771

Epoch: 5| Step: 1
Training loss: 0.18575140833854675
Validation loss: 1.4968472924283756

Epoch: 5| Step: 2
Training loss: 0.13049474358558655
Validation loss: 1.5311257928930304

Epoch: 5| Step: 3
Training loss: 0.10927579551935196
Validation loss: 1.5595083672513244

Epoch: 5| Step: 4
Training loss: 0.270057737827301
Validation loss: 1.5570930024628997

Epoch: 5| Step: 5
Training loss: 0.23995420336723328
Validation loss: 1.5713972545439197

Epoch: 5| Step: 6
Training loss: 0.17471688985824585
Validation loss: 1.5808964211453673

Epoch: 5| Step: 7
Training loss: 0.23240819573402405
Validation loss: 1.5518274409796602

Epoch: 5| Step: 8
Training loss: 0.24352499842643738
Validation loss: 1.5490219900684972

Epoch: 5| Step: 9
Training loss: 0.25278839468955994
Validation loss: 1.5682230213636994

Epoch: 5| Step: 10
Training loss: 0.2728850841522217
Validation loss: 1.5576332384540188

Epoch: 453| Step: 0
Training loss: 0.17721597850322723
Validation loss: 1.554904294270341

Epoch: 5| Step: 1
Training loss: 0.24787667393684387
Validation loss: 1.5713259994342763

Epoch: 5| Step: 2
Training loss: 0.13918933272361755
Validation loss: 1.5463010457254225

Epoch: 5| Step: 3
Training loss: 0.18029335141181946
Validation loss: 1.5640864769617717

Epoch: 5| Step: 4
Training loss: 0.12217067182064056
Validation loss: 1.5328372986085954

Epoch: 5| Step: 5
Training loss: 0.27573519945144653
Validation loss: 1.533182397965462

Epoch: 5| Step: 6
Training loss: 0.2396785467863083
Validation loss: 1.5131250555797289

Epoch: 5| Step: 7
Training loss: 0.09270744025707245
Validation loss: 1.5347414631997385

Epoch: 5| Step: 8
Training loss: 0.21434929966926575
Validation loss: 1.5178194398521094

Epoch: 5| Step: 9
Training loss: 0.2892313301563263
Validation loss: 1.5191302478954356

Epoch: 5| Step: 10
Training loss: 0.2056398242712021
Validation loss: 1.518877689556409

Epoch: 454| Step: 0
Training loss: 0.22373457252979279
Validation loss: 1.485350155061291

Epoch: 5| Step: 1
Training loss: 0.28652113676071167
Validation loss: 1.4920693738486177

Epoch: 5| Step: 2
Training loss: 0.18836981058120728
Validation loss: 1.4928609632676648

Epoch: 5| Step: 3
Training loss: 0.17622257769107819
Validation loss: 1.529663831956925

Epoch: 5| Step: 4
Training loss: 0.11631011962890625
Validation loss: 1.4912188027494697

Epoch: 5| Step: 5
Training loss: 0.23251180350780487
Validation loss: 1.5151689552491712

Epoch: 5| Step: 6
Training loss: 0.20739582180976868
Validation loss: 1.495016315931915

Epoch: 5| Step: 7
Training loss: 0.17416036128997803
Validation loss: 1.4838410449284378

Epoch: 5| Step: 8
Training loss: 0.17333027720451355
Validation loss: 1.5155464269781624

Epoch: 5| Step: 9
Training loss: 0.24310679733753204
Validation loss: 1.5024072752203992

Epoch: 5| Step: 10
Training loss: 0.12505415081977844
Validation loss: 1.5017182416813348

Epoch: 455| Step: 0
Training loss: 0.3056185841560364
Validation loss: 1.5439002424158075

Epoch: 5| Step: 1
Training loss: 0.14309780299663544
Validation loss: 1.5521146328218522

Epoch: 5| Step: 2
Training loss: 0.19857271015644073
Validation loss: 1.535374104976654

Epoch: 5| Step: 3
Training loss: 0.31547871232032776
Validation loss: 1.5121101352476305

Epoch: 5| Step: 4
Training loss: 0.23731079697608948
Validation loss: 1.5241291189706454

Epoch: 5| Step: 5
Training loss: 0.19458921253681183
Validation loss: 1.5546066273925125

Epoch: 5| Step: 6
Training loss: 0.08251351118087769
Validation loss: 1.5307643464816514

Epoch: 5| Step: 7
Training loss: 0.20829610526561737
Validation loss: 1.5314542080766411

Epoch: 5| Step: 8
Training loss: 0.15783138573169708
Validation loss: 1.532963696346488

Epoch: 5| Step: 9
Training loss: 0.1556795835494995
Validation loss: 1.516024486992949

Epoch: 5| Step: 10
Training loss: 0.14417022466659546
Validation loss: 1.496955451144967

Epoch: 456| Step: 0
Training loss: 0.13305220007896423
Validation loss: 1.4995534817377727

Epoch: 5| Step: 1
Training loss: 0.1834997832775116
Validation loss: 1.513158312407873

Epoch: 5| Step: 2
Training loss: 0.2896658778190613
Validation loss: 1.543596508682415

Epoch: 5| Step: 3
Training loss: 0.1982812136411667
Validation loss: 1.5334103043361376

Epoch: 5| Step: 4
Training loss: 0.12155811488628387
Validation loss: 1.522453736233455

Epoch: 5| Step: 5
Training loss: 0.2092939168214798
Validation loss: 1.5557965142752535

Epoch: 5| Step: 6
Training loss: 0.10435128211975098
Validation loss: 1.5260981475153277

Epoch: 5| Step: 7
Training loss: 0.3346514105796814
Validation loss: 1.5292152063820952

Epoch: 5| Step: 8
Training loss: 0.20516064763069153
Validation loss: 1.542586386844676

Epoch: 5| Step: 9
Training loss: 0.14678984880447388
Validation loss: 1.5634252922509306

Epoch: 5| Step: 10
Training loss: 0.3569796681404114
Validation loss: 1.5297663878369074

Epoch: 457| Step: 0
Training loss: 0.10777316242456436
Validation loss: 1.5425153547717678

Epoch: 5| Step: 1
Training loss: 0.22424010932445526
Validation loss: 1.551415212692753

Epoch: 5| Step: 2
Training loss: 0.2156490981578827
Validation loss: 1.5493608905423073

Epoch: 5| Step: 3
Training loss: 0.20084881782531738
Validation loss: 1.5246757448360484

Epoch: 5| Step: 4
Training loss: 0.29643791913986206
Validation loss: 1.5201595790924565

Epoch: 5| Step: 5
Training loss: 0.25540828704833984
Validation loss: 1.5044001276775072

Epoch: 5| Step: 6
Training loss: 0.13437041640281677
Validation loss: 1.5143472661254227

Epoch: 5| Step: 7
Training loss: 0.2084222286939621
Validation loss: 1.4964536005450833

Epoch: 5| Step: 8
Training loss: 0.13998256623744965
Validation loss: 1.5034990502941994

Epoch: 5| Step: 9
Training loss: 0.2345465123653412
Validation loss: 1.5122405495694888

Epoch: 5| Step: 10
Training loss: 0.11950111389160156
Validation loss: 1.522042989730835

Epoch: 458| Step: 0
Training loss: 0.24565176665782928
Validation loss: 1.5191510133845831

Epoch: 5| Step: 1
Training loss: 0.20556168258190155
Validation loss: 1.5520959913089711

Epoch: 5| Step: 2
Training loss: 0.24760107696056366
Validation loss: 1.5428789495139994

Epoch: 5| Step: 3
Training loss: 0.16999924182891846
Validation loss: 1.54766898193667

Epoch: 5| Step: 4
Training loss: 0.17587533593177795
Validation loss: 1.5669017978893813

Epoch: 5| Step: 5
Training loss: 0.27748921513557434
Validation loss: 1.5427896092014928

Epoch: 5| Step: 6
Training loss: 0.12726208567619324
Validation loss: 1.5454564568816975

Epoch: 5| Step: 7
Training loss: 0.15853449702262878
Validation loss: 1.538160954752276

Epoch: 5| Step: 8
Training loss: 0.1447441726922989
Validation loss: 1.5598545305190548

Epoch: 5| Step: 9
Training loss: 0.21129634976387024
Validation loss: 1.5126287462890788

Epoch: 5| Step: 10
Training loss: 0.2154032588005066
Validation loss: 1.492405951664012

Epoch: 459| Step: 0
Training loss: 0.20482560992240906
Validation loss: 1.499408382241444

Epoch: 5| Step: 1
Training loss: 0.19008328020572662
Validation loss: 1.4907383149670017

Epoch: 5| Step: 2
Training loss: 0.19646820425987244
Validation loss: 1.5136523695402249

Epoch: 5| Step: 3
Training loss: 0.19642047584056854
Validation loss: 1.4850124492440173

Epoch: 5| Step: 4
Training loss: 0.15125879645347595
Validation loss: 1.4993838302550777

Epoch: 5| Step: 5
Training loss: 0.14537332952022552
Validation loss: 1.4967513135684434

Epoch: 5| Step: 6
Training loss: 0.10767613351345062
Validation loss: 1.517590340747628

Epoch: 5| Step: 7
Training loss: 0.16736051440238953
Validation loss: 1.5410997982948058

Epoch: 5| Step: 8
Training loss: 0.33279407024383545
Validation loss: 1.4966982590254916

Epoch: 5| Step: 9
Training loss: 0.09300915151834488
Validation loss: 1.4892074331160514

Epoch: 5| Step: 10
Training loss: 0.3100705146789551
Validation loss: 1.5077834821516467

Epoch: 460| Step: 0
Training loss: 0.1932976394891739
Validation loss: 1.4847143747473275

Epoch: 5| Step: 1
Training loss: 0.07818444073200226
Validation loss: 1.4829324958144978

Epoch: 5| Step: 2
Training loss: 0.272124320268631
Validation loss: 1.5022218278659287

Epoch: 5| Step: 3
Training loss: 0.13839980959892273
Validation loss: 1.5283573917163316

Epoch: 5| Step: 4
Training loss: 0.13107165694236755
Validation loss: 1.542986205829087

Epoch: 5| Step: 5
Training loss: 0.2548830807209015
Validation loss: 1.5394870145346529

Epoch: 5| Step: 6
Training loss: 0.220711350440979
Validation loss: 1.540532330031036

Epoch: 5| Step: 7
Training loss: 0.1523098647594452
Validation loss: 1.5118910420325495

Epoch: 5| Step: 8
Training loss: 0.26505324244499207
Validation loss: 1.5058710280285086

Epoch: 5| Step: 9
Training loss: 0.13433954119682312
Validation loss: 1.52262044337488

Epoch: 5| Step: 10
Training loss: 0.16766774654388428
Validation loss: 1.496653950342568

Epoch: 461| Step: 0
Training loss: 0.34894436597824097
Validation loss: 1.5093708140875703

Epoch: 5| Step: 1
Training loss: 0.1849975883960724
Validation loss: 1.5064432903002667

Epoch: 5| Step: 2
Training loss: 0.1386871635913849
Validation loss: 1.5071524343182963

Epoch: 5| Step: 3
Training loss: 0.1772228479385376
Validation loss: 1.4915309888060375

Epoch: 5| Step: 4
Training loss: 0.14971837401390076
Validation loss: 1.4893948878011396

Epoch: 5| Step: 5
Training loss: 0.11684393882751465
Validation loss: 1.506907315664394

Epoch: 5| Step: 6
Training loss: 0.18821094930171967
Validation loss: 1.5059955709724016

Epoch: 5| Step: 7
Training loss: 0.2022591531276703
Validation loss: 1.5211310937840452

Epoch: 5| Step: 8
Training loss: 0.16436292231082916
Validation loss: 1.5013722194138395

Epoch: 5| Step: 9
Training loss: 0.11910240352153778
Validation loss: 1.4966941507913734

Epoch: 5| Step: 10
Training loss: 0.19741490483283997
Validation loss: 1.5164731638405913

Epoch: 462| Step: 0
Training loss: 0.09877543151378632
Validation loss: 1.5178668197765146

Epoch: 5| Step: 1
Training loss: 0.14369051158428192
Validation loss: 1.5123815267316756

Epoch: 5| Step: 2
Training loss: 0.21824221312999725
Validation loss: 1.5117184115994362

Epoch: 5| Step: 3
Training loss: 0.0528598316013813
Validation loss: 1.5015672701661305

Epoch: 5| Step: 4
Training loss: 0.2452464997768402
Validation loss: 1.5227927110528434

Epoch: 5| Step: 5
Training loss: 0.1572800576686859
Validation loss: 1.5203906656593404

Epoch: 5| Step: 6
Training loss: 0.11614052206277847
Validation loss: 1.516535476330788

Epoch: 5| Step: 7
Training loss: 0.22559142112731934
Validation loss: 1.514243079769996

Epoch: 5| Step: 8
Training loss: 0.23551495373249054
Validation loss: 1.5322768701020109

Epoch: 5| Step: 9
Training loss: 0.18694353103637695
Validation loss: 1.5226156615441846

Epoch: 5| Step: 10
Training loss: 0.21005576848983765
Validation loss: 1.522256435886506

Epoch: 463| Step: 0
Training loss: 0.2970642149448395
Validation loss: 1.5167841167860134

Epoch: 5| Step: 1
Training loss: 0.07029660046100616
Validation loss: 1.512965872723569

Epoch: 5| Step: 2
Training loss: 0.17653921246528625
Validation loss: 1.5022707946838871

Epoch: 5| Step: 3
Training loss: 0.11567441374063492
Validation loss: 1.5371990716585548

Epoch: 5| Step: 4
Training loss: 0.17849186062812805
Validation loss: 1.5163662638715518

Epoch: 5| Step: 5
Training loss: 0.11096614599227905
Validation loss: 1.5178499337165587

Epoch: 5| Step: 6
Training loss: 0.1382179707288742
Validation loss: 1.5019299432795534

Epoch: 5| Step: 7
Training loss: 0.14533601701259613
Validation loss: 1.5283775624408518

Epoch: 5| Step: 8
Training loss: 0.2816356122493744
Validation loss: 1.5091078986403763

Epoch: 5| Step: 9
Training loss: 0.22242479026317596
Validation loss: 1.5160183611736502

Epoch: 5| Step: 10
Training loss: 0.1441953480243683
Validation loss: 1.530726412291168

Epoch: 464| Step: 0
Training loss: 0.11034379154443741
Validation loss: 1.5331655484373852

Epoch: 5| Step: 1
Training loss: 0.16497750580310822
Validation loss: 1.5577818911562684

Epoch: 5| Step: 2
Training loss: 0.1198020949959755
Validation loss: 1.5196012681530369

Epoch: 5| Step: 3
Training loss: 0.09472940862178802
Validation loss: 1.5321070327553699

Epoch: 5| Step: 4
Training loss: 0.1769455522298813
Validation loss: 1.5477286320860668

Epoch: 5| Step: 5
Training loss: 0.14273309707641602
Validation loss: 1.5160721924997145

Epoch: 5| Step: 6
Training loss: 0.22750484943389893
Validation loss: 1.5249221594102922

Epoch: 5| Step: 7
Training loss: 0.19188380241394043
Validation loss: 1.5199400096811273

Epoch: 5| Step: 8
Training loss: 0.18972691893577576
Validation loss: 1.5486084081793343

Epoch: 5| Step: 9
Training loss: 0.18976500630378723
Validation loss: 1.5488123573282713

Epoch: 5| Step: 10
Training loss: 0.1969844251871109
Validation loss: 1.515322475023167

Epoch: 465| Step: 0
Training loss: 0.11857889592647552
Validation loss: 1.5412259024958457

Epoch: 5| Step: 1
Training loss: 0.18919014930725098
Validation loss: 1.5147898209992277

Epoch: 5| Step: 2
Training loss: 0.1740642488002777
Validation loss: 1.5449617639664681

Epoch: 5| Step: 3
Training loss: 0.14411482214927673
Validation loss: 1.5272471558663152

Epoch: 5| Step: 4
Training loss: 0.15036705136299133
Validation loss: 1.5135613308157971

Epoch: 5| Step: 5
Training loss: 0.13526815176010132
Validation loss: 1.5378665321616716

Epoch: 5| Step: 6
Training loss: 0.3442019820213318
Validation loss: 1.5207145137171592

Epoch: 5| Step: 7
Training loss: 0.170253187417984
Validation loss: 1.5059018109434394

Epoch: 5| Step: 8
Training loss: 0.10234899818897247
Validation loss: 1.520874810475175

Epoch: 5| Step: 9
Training loss: 0.1915842890739441
Validation loss: 1.5062298204309197

Epoch: 5| Step: 10
Training loss: 0.22970050573349
Validation loss: 1.5181242881282684

Epoch: 466| Step: 0
Training loss: 0.09763142466545105
Validation loss: 1.5228137470060779

Epoch: 5| Step: 1
Training loss: 0.2528967559337616
Validation loss: 1.5122702416553293

Epoch: 5| Step: 2
Training loss: 0.2176249474287033
Validation loss: 1.517656498057868

Epoch: 5| Step: 3
Training loss: 0.1253366768360138
Validation loss: 1.4976131480227235

Epoch: 5| Step: 4
Training loss: 0.10172565281391144
Validation loss: 1.487193658787717

Epoch: 5| Step: 5
Training loss: 0.1692754030227661
Validation loss: 1.5108963340841315

Epoch: 5| Step: 6
Training loss: 0.14323315024375916
Validation loss: 1.4959647091486121

Epoch: 5| Step: 7
Training loss: 0.22605621814727783
Validation loss: 1.5281066663803593

Epoch: 5| Step: 8
Training loss: 0.15398332476615906
Validation loss: 1.5189373736740441

Epoch: 5| Step: 9
Training loss: 0.1272689253091812
Validation loss: 1.4952107937105241

Epoch: 5| Step: 10
Training loss: 0.21199853718280792
Validation loss: 1.5029213684861378

Epoch: 467| Step: 0
Training loss: 0.14236143231391907
Validation loss: 1.515888451888997

Epoch: 5| Step: 1
Training loss: 0.12937209010124207
Validation loss: 1.489090568275862

Epoch: 5| Step: 2
Training loss: 0.10886647552251816
Validation loss: 1.5177942745147213

Epoch: 5| Step: 3
Training loss: 0.19533829391002655
Validation loss: 1.5026611640889158

Epoch: 5| Step: 4
Training loss: 0.13392701745033264
Validation loss: 1.5198749098726498

Epoch: 5| Step: 5
Training loss: 0.2399064302444458
Validation loss: 1.5400102574338195

Epoch: 5| Step: 6
Training loss: 0.19313926994800568
Validation loss: 1.53062907982898

Epoch: 5| Step: 7
Training loss: 0.27143117785453796
Validation loss: 1.5502183488620225

Epoch: 5| Step: 8
Training loss: 0.08008714020252228
Validation loss: 1.5421681314386346

Epoch: 5| Step: 9
Training loss: 0.15436799824237823
Validation loss: 1.5464902577861663

Epoch: 5| Step: 10
Training loss: 0.3501991331577301
Validation loss: 1.5413086773246847

Epoch: 468| Step: 0
Training loss: 0.360839307308197
Validation loss: 1.53504107780354

Epoch: 5| Step: 1
Training loss: 0.1560145914554596
Validation loss: 1.4989173604596047

Epoch: 5| Step: 2
Training loss: 0.12335348129272461
Validation loss: 1.5110073269054454

Epoch: 5| Step: 3
Training loss: 0.14898453652858734
Validation loss: 1.5437585237205669

Epoch: 5| Step: 4
Training loss: 0.16347052156925201
Validation loss: 1.525394078223936

Epoch: 5| Step: 5
Training loss: 0.19138197600841522
Validation loss: 1.5639377691412484

Epoch: 5| Step: 6
Training loss: 0.17889045178890228
Validation loss: 1.5266104513599026

Epoch: 5| Step: 7
Training loss: 0.11969365179538727
Validation loss: 1.4900669346573532

Epoch: 5| Step: 8
Training loss: 0.2858278453350067
Validation loss: 1.5251870296334709

Epoch: 5| Step: 9
Training loss: 0.18754209578037262
Validation loss: 1.5225618193226476

Epoch: 5| Step: 10
Training loss: 0.11098548024892807
Validation loss: 1.5308219899413407

Epoch: 469| Step: 0
Training loss: 0.15070734918117523
Validation loss: 1.526373032600649

Epoch: 5| Step: 1
Training loss: 0.11760173738002777
Validation loss: 1.5233610124998196

Epoch: 5| Step: 2
Training loss: 0.2729850709438324
Validation loss: 1.5002344372451946

Epoch: 5| Step: 3
Training loss: 0.13043944537639618
Validation loss: 1.5380147272540676

Epoch: 5| Step: 4
Training loss: 0.20359115302562714
Validation loss: 1.5251320895328317

Epoch: 5| Step: 5
Training loss: 0.23384490609169006
Validation loss: 1.5667793481580672

Epoch: 5| Step: 6
Training loss: 0.1681690216064453
Validation loss: 1.5679081806572535

Epoch: 5| Step: 7
Training loss: 0.20332284271717072
Validation loss: 1.5838179819045528

Epoch: 5| Step: 8
Training loss: 0.21457085013389587
Validation loss: 1.561494573470085

Epoch: 5| Step: 9
Training loss: 0.21740469336509705
Validation loss: 1.5846332965358612

Epoch: 5| Step: 10
Training loss: 0.25397220253944397
Validation loss: 1.543446885642185

Epoch: 470| Step: 0
Training loss: 0.21635310351848602
Validation loss: 1.531208784349503

Epoch: 5| Step: 1
Training loss: 0.15584856271743774
Validation loss: 1.5415789645205262

Epoch: 5| Step: 2
Training loss: 0.18075504899024963
Validation loss: 1.5428148251707836

Epoch: 5| Step: 3
Training loss: 0.2673817276954651
Validation loss: 1.5349284333567466

Epoch: 5| Step: 4
Training loss: 0.3048889636993408
Validation loss: 1.5416770218521036

Epoch: 5| Step: 5
Training loss: 0.10218743979930878
Validation loss: 1.5132513200083086

Epoch: 5| Step: 6
Training loss: 0.10917700827121735
Validation loss: 1.547602266393682

Epoch: 5| Step: 7
Training loss: 0.1359216719865799
Validation loss: 1.588279486984335

Epoch: 5| Step: 8
Training loss: 0.13403788208961487
Validation loss: 1.5727651862687961

Epoch: 5| Step: 9
Training loss: 0.20787818729877472
Validation loss: 1.6139032815092353

Epoch: 5| Step: 10
Training loss: 0.39414626359939575
Validation loss: 1.5968590282624768

Epoch: 471| Step: 0
Training loss: 0.15273691713809967
Validation loss: 1.5740296584303661

Epoch: 5| Step: 1
Training loss: 0.09055689722299576
Validation loss: 1.5497550169626872

Epoch: 5| Step: 2
Training loss: 0.15622887015342712
Validation loss: 1.5424047439329085

Epoch: 5| Step: 3
Training loss: 0.20800085365772247
Validation loss: 1.5317297750903713

Epoch: 5| Step: 4
Training loss: 0.18029092252254486
Validation loss: 1.5395205892542356

Epoch: 5| Step: 5
Training loss: 0.16532424092292786
Validation loss: 1.5141785740852356

Epoch: 5| Step: 6
Training loss: 0.1988072395324707
Validation loss: 1.5262854868365872

Epoch: 5| Step: 7
Training loss: 0.20256873965263367
Validation loss: 1.5422599354097921

Epoch: 5| Step: 8
Training loss: 0.24921965599060059
Validation loss: 1.589666820341541

Epoch: 5| Step: 9
Training loss: 0.12321485579013824
Validation loss: 1.5834427328519924

Epoch: 5| Step: 10
Training loss: 0.2232958823442459
Validation loss: 1.5737683990950226

Epoch: 472| Step: 0
Training loss: 0.3229241967201233
Validation loss: 1.6309800801738616

Epoch: 5| Step: 1
Training loss: 0.26352179050445557
Validation loss: 1.5603723038909256

Epoch: 5| Step: 2
Training loss: 0.15780135989189148
Validation loss: 1.5439576461750975

Epoch: 5| Step: 3
Training loss: 0.13545717298984528
Validation loss: 1.5261146560792

Epoch: 5| Step: 4
Training loss: 0.11122812330722809
Validation loss: 1.506381078432965

Epoch: 5| Step: 5
Training loss: 0.12131458520889282
Validation loss: 1.4820678823737687

Epoch: 5| Step: 6
Training loss: 0.16306142508983612
Validation loss: 1.4958704094732962

Epoch: 5| Step: 7
Training loss: 0.21285800635814667
Validation loss: 1.4765726302259712

Epoch: 5| Step: 8
Training loss: 0.2767053246498108
Validation loss: 1.4890832785637147

Epoch: 5| Step: 9
Training loss: 0.16412463784217834
Validation loss: 1.50594166914622

Epoch: 5| Step: 10
Training loss: 0.13610710203647614
Validation loss: 1.524213444802069

Epoch: 473| Step: 0
Training loss: 0.1754688173532486
Validation loss: 1.57100421831172

Epoch: 5| Step: 1
Training loss: 0.14538469910621643
Validation loss: 1.549634769398679

Epoch: 5| Step: 2
Training loss: 0.18208028376102448
Validation loss: 1.5693706876488143

Epoch: 5| Step: 3
Training loss: 0.1137976422905922
Validation loss: 1.5746883602552517

Epoch: 5| Step: 4
Training loss: 0.2894122004508972
Validation loss: 1.5674214811735256

Epoch: 5| Step: 5
Training loss: 0.15920624136924744
Validation loss: 1.5636622764730965

Epoch: 5| Step: 6
Training loss: 0.17454198002815247
Validation loss: 1.5221164546987063

Epoch: 5| Step: 7
Training loss: 0.19946056604385376
Validation loss: 1.5388328400991296

Epoch: 5| Step: 8
Training loss: 0.13011744618415833
Validation loss: 1.5046325268283967

Epoch: 5| Step: 9
Training loss: 0.12777063250541687
Validation loss: 1.5081111410612702

Epoch: 5| Step: 10
Training loss: 0.11946051567792892
Validation loss: 1.5129196490010908

Epoch: 474| Step: 0
Training loss: 0.1740671694278717
Validation loss: 1.5252870116182553

Epoch: 5| Step: 1
Training loss: 0.07911117374897003
Validation loss: 1.5386130412419636

Epoch: 5| Step: 2
Training loss: 0.21904630959033966
Validation loss: 1.5459437530527833

Epoch: 5| Step: 3
Training loss: 0.09449195861816406
Validation loss: 1.5669128458987

Epoch: 5| Step: 4
Training loss: 0.11398915946483612
Validation loss: 1.5654171718064176

Epoch: 5| Step: 5
Training loss: 0.18506070971488953
Validation loss: 1.5700370060500277

Epoch: 5| Step: 6
Training loss: 0.17804135382175446
Validation loss: 1.5451004210338797

Epoch: 5| Step: 7
Training loss: 0.15324954688549042
Validation loss: 1.5384084691283524

Epoch: 5| Step: 8
Training loss: 0.14058402180671692
Validation loss: 1.497236640222611

Epoch: 5| Step: 9
Training loss: 0.21960768103599548
Validation loss: 1.5370399541752313

Epoch: 5| Step: 10
Training loss: 0.1414225548505783
Validation loss: 1.504128720170708

Epoch: 475| Step: 0
Training loss: 0.18288734555244446
Validation loss: 1.5011460268369285

Epoch: 5| Step: 1
Training loss: 0.1441696435213089
Validation loss: 1.5314715728964856

Epoch: 5| Step: 2
Training loss: 0.21859586238861084
Validation loss: 1.5417004221229142

Epoch: 5| Step: 3
Training loss: 0.19655819237232208
Validation loss: 1.5494959918401574

Epoch: 5| Step: 4
Training loss: 0.08735258877277374
Validation loss: 1.5429576455905873

Epoch: 5| Step: 5
Training loss: 0.09485576301813126
Validation loss: 1.505976180876455

Epoch: 5| Step: 6
Training loss: 0.2703750729560852
Validation loss: 1.5090939280807332

Epoch: 5| Step: 7
Training loss: 0.1264571249485016
Validation loss: 1.5032018352580327

Epoch: 5| Step: 8
Training loss: 0.1802479326725006
Validation loss: 1.5407084713699997

Epoch: 5| Step: 9
Training loss: 0.09587063640356064
Validation loss: 1.4917147326213058

Epoch: 5| Step: 10
Training loss: 0.1291605681180954
Validation loss: 1.5091960481418076

Epoch: 476| Step: 0
Training loss: 0.1292186677455902
Validation loss: 1.54355634925186

Epoch: 5| Step: 1
Training loss: 0.12499181181192398
Validation loss: 1.5347528701187463

Epoch: 5| Step: 2
Training loss: 0.1351729780435562
Validation loss: 1.5443016406028502

Epoch: 5| Step: 3
Training loss: 0.14207668602466583
Validation loss: 1.540168059769497

Epoch: 5| Step: 4
Training loss: 0.17242030799388885
Validation loss: 1.536852152116837

Epoch: 5| Step: 5
Training loss: 0.23278212547302246
Validation loss: 1.5515529532586374

Epoch: 5| Step: 6
Training loss: 0.11694435775279999
Validation loss: 1.547145592269077

Epoch: 5| Step: 7
Training loss: 0.12569144368171692
Validation loss: 1.5229177897976292

Epoch: 5| Step: 8
Training loss: 0.129984050989151
Validation loss: 1.5104951538065428

Epoch: 5| Step: 9
Training loss: 0.17143306136131287
Validation loss: 1.4951809381925931

Epoch: 5| Step: 10
Training loss: 0.1941671073436737
Validation loss: 1.52341632176471

Epoch: 477| Step: 0
Training loss: 0.15050530433654785
Validation loss: 1.5263054242698095

Epoch: 5| Step: 1
Training loss: 0.17578977346420288
Validation loss: 1.5243742632609543

Epoch: 5| Step: 2
Training loss: 0.09856061637401581
Validation loss: 1.526026577077886

Epoch: 5| Step: 3
Training loss: 0.16710025072097778
Validation loss: 1.5103125764477638

Epoch: 5| Step: 4
Training loss: 0.17998006939888
Validation loss: 1.4914818092059063

Epoch: 5| Step: 5
Training loss: 0.0608777180314064
Validation loss: 1.4956831451385253

Epoch: 5| Step: 6
Training loss: 0.21318712830543518
Validation loss: 1.5246289353216849

Epoch: 5| Step: 7
Training loss: 0.12493858486413956
Validation loss: 1.5538255681273758

Epoch: 5| Step: 8
Training loss: 0.29418203234672546
Validation loss: 1.575051280759996

Epoch: 5| Step: 9
Training loss: 0.23324385285377502
Validation loss: 1.5586518023603706

Epoch: 5| Step: 10
Training loss: 0.13591106235980988
Validation loss: 1.5468639237906343

Epoch: 478| Step: 0
Training loss: 0.13654233515262604
Validation loss: 1.534246197310827

Epoch: 5| Step: 1
Training loss: 0.1743440330028534
Validation loss: 1.533120665498959

Epoch: 5| Step: 2
Training loss: 0.19605492055416107
Validation loss: 1.5395422391994025

Epoch: 5| Step: 3
Training loss: 0.14998148381710052
Validation loss: 1.5399193263822986

Epoch: 5| Step: 4
Training loss: 0.16784724593162537
Validation loss: 1.5177789003618303

Epoch: 5| Step: 5
Training loss: 0.1737564355134964
Validation loss: 1.516676095865106

Epoch: 5| Step: 6
Training loss: 0.13156801462173462
Validation loss: 1.5371307557629001

Epoch: 5| Step: 7
Training loss: 0.12065498530864716
Validation loss: 1.5297016398881071

Epoch: 5| Step: 8
Training loss: 0.10580845177173615
Validation loss: 1.516817593446342

Epoch: 5| Step: 9
Training loss: 0.1896159052848816
Validation loss: 1.5265420290731615

Epoch: 5| Step: 10
Training loss: 0.17293518781661987
Validation loss: 1.548556855929795

Epoch: 479| Step: 0
Training loss: 0.15326498448848724
Validation loss: 1.57249834973325

Epoch: 5| Step: 1
Training loss: 0.09139701724052429
Validation loss: 1.5576218661441599

Epoch: 5| Step: 2
Training loss: 0.3342227339744568
Validation loss: 1.5517791798037868

Epoch: 5| Step: 3
Training loss: 0.21202556788921356
Validation loss: 1.559518446845393

Epoch: 5| Step: 4
Training loss: 0.16145741939544678
Validation loss: 1.5455615110294794

Epoch: 5| Step: 5
Training loss: 0.12354911863803864
Validation loss: 1.5258037249247234

Epoch: 5| Step: 6
Training loss: 0.15390071272850037
Validation loss: 1.5100137443952664

Epoch: 5| Step: 7
Training loss: 0.24006228148937225
Validation loss: 1.5144458156760021

Epoch: 5| Step: 8
Training loss: 0.10264289379119873
Validation loss: 1.5079607771288963

Epoch: 5| Step: 9
Training loss: 0.16447816789150238
Validation loss: 1.4871398864253875

Epoch: 5| Step: 10
Training loss: 0.11072789877653122
Validation loss: 1.4904395720010162

Epoch: 480| Step: 0
Training loss: 0.11471369117498398
Validation loss: 1.5273925367222037

Epoch: 5| Step: 1
Training loss: 0.14324191212654114
Validation loss: 1.480173118652836

Epoch: 5| Step: 2
Training loss: 0.18464049696922302
Validation loss: 1.4935756639767719

Epoch: 5| Step: 3
Training loss: 0.10122723877429962
Validation loss: 1.4530487880911878

Epoch: 5| Step: 4
Training loss: 0.2924292981624603
Validation loss: 1.4944872894594747

Epoch: 5| Step: 5
Training loss: 0.17905285954475403
Validation loss: 1.4747317465402747

Epoch: 5| Step: 6
Training loss: 0.1269150674343109
Validation loss: 1.4976717913022606

Epoch: 5| Step: 7
Training loss: 0.13034261763095856
Validation loss: 1.5108184083815543

Epoch: 5| Step: 8
Training loss: 0.18079863488674164
Validation loss: 1.5291912453148955

Epoch: 5| Step: 9
Training loss: 0.12894859910011292
Validation loss: 1.5352296906132852

Epoch: 5| Step: 10
Training loss: 0.2501174211502075
Validation loss: 1.5584154462301603

Epoch: 481| Step: 0
Training loss: 0.11850754916667938
Validation loss: 1.5582525935224307

Epoch: 5| Step: 1
Training loss: 0.14360861480236053
Validation loss: 1.5583745048892113

Epoch: 5| Step: 2
Training loss: 0.20473256707191467
Validation loss: 1.5843737394578996

Epoch: 5| Step: 3
Training loss: 0.11756853014230728
Validation loss: 1.5811987500036917

Epoch: 5| Step: 4
Training loss: 0.19673815369606018
Validation loss: 1.570898659767643

Epoch: 5| Step: 5
Training loss: 0.08315055817365646
Validation loss: 1.5745224792470214

Epoch: 5| Step: 6
Training loss: 0.10382676124572754
Validation loss: 1.5180256007820048

Epoch: 5| Step: 7
Training loss: 0.15281465649604797
Validation loss: 1.5317554730241016

Epoch: 5| Step: 8
Training loss: 0.2740188539028168
Validation loss: 1.492748083606843

Epoch: 5| Step: 9
Training loss: 0.2590230107307434
Validation loss: 1.4968512340258526

Epoch: 5| Step: 10
Training loss: 0.1288050413131714
Validation loss: 1.4657040654972036

Epoch: 482| Step: 0
Training loss: 0.14216072857379913
Validation loss: 1.4793678355473343

Epoch: 5| Step: 1
Training loss: 0.13622386753559113
Validation loss: 1.4780196118098434

Epoch: 5| Step: 2
Training loss: 0.128341406583786
Validation loss: 1.473581273068664

Epoch: 5| Step: 3
Training loss: 0.2420876920223236
Validation loss: 1.4784286695141946

Epoch: 5| Step: 4
Training loss: 0.20623353123664856
Validation loss: 1.4797445984296902

Epoch: 5| Step: 5
Training loss: 0.10807307064533234
Validation loss: 1.458911048468723

Epoch: 5| Step: 6
Training loss: 0.17148897051811218
Validation loss: 1.4919248293804865

Epoch: 5| Step: 7
Training loss: 0.1160217896103859
Validation loss: 1.4794613533122565

Epoch: 5| Step: 8
Training loss: 0.11756241321563721
Validation loss: 1.5037413694525277

Epoch: 5| Step: 9
Training loss: 0.21132664382457733
Validation loss: 1.4913310658547185

Epoch: 5| Step: 10
Training loss: 0.10278457403182983
Validation loss: 1.4943725857683408

Epoch: 483| Step: 0
Training loss: 0.19690865278244019
Validation loss: 1.5379445937372023

Epoch: 5| Step: 1
Training loss: 0.22041305899620056
Validation loss: 1.543485382551788

Epoch: 5| Step: 2
Training loss: 0.14235997200012207
Validation loss: 1.543436599034135

Epoch: 5| Step: 3
Training loss: 0.19349290430545807
Validation loss: 1.5194553636735486

Epoch: 5| Step: 4
Training loss: 0.18181410431861877
Validation loss: 1.4919866797744588

Epoch: 5| Step: 5
Training loss: 0.31597787141799927
Validation loss: 1.5187265155135945

Epoch: 5| Step: 6
Training loss: 0.18433015048503876
Validation loss: 1.527153709883331

Epoch: 5| Step: 7
Training loss: 0.19703498482704163
Validation loss: 1.5311563668712493

Epoch: 5| Step: 8
Training loss: 0.1403583288192749
Validation loss: 1.5230827190542733

Epoch: 5| Step: 9
Training loss: 0.1366095095872879
Validation loss: 1.5055479926447715

Epoch: 5| Step: 10
Training loss: 0.17127394676208496
Validation loss: 1.5467646397570127

Epoch: 484| Step: 0
Training loss: 0.07799094915390015
Validation loss: 1.5497159957885742

Epoch: 5| Step: 1
Training loss: 0.10734818875789642
Validation loss: 1.541042697045111

Epoch: 5| Step: 2
Training loss: 0.14314082264900208
Validation loss: 1.5705078981255973

Epoch: 5| Step: 3
Training loss: 0.16167515516281128
Validation loss: 1.5539292814911052

Epoch: 5| Step: 4
Training loss: 0.20308247208595276
Validation loss: 1.5557335820249332

Epoch: 5| Step: 5
Training loss: 0.2224281281232834
Validation loss: 1.575405102904125

Epoch: 5| Step: 6
Training loss: 0.16004173457622528
Validation loss: 1.5941906334251486

Epoch: 5| Step: 7
Training loss: 0.1893279254436493
Validation loss: 1.5552426640705397

Epoch: 5| Step: 8
Training loss: 0.2083415985107422
Validation loss: 1.5354202434580813

Epoch: 5| Step: 9
Training loss: 0.1584942638874054
Validation loss: 1.528922842394921

Epoch: 5| Step: 10
Training loss: 0.09936147928237915
Validation loss: 1.5572183311626475

Epoch: 485| Step: 0
Training loss: 0.17546643316745758
Validation loss: 1.5470445361188663

Epoch: 5| Step: 1
Training loss: 0.2417391836643219
Validation loss: 1.5496034468373945

Epoch: 5| Step: 2
Training loss: 0.16686534881591797
Validation loss: 1.5475464085096955

Epoch: 5| Step: 3
Training loss: 0.3239593803882599
Validation loss: 1.5128549619387555

Epoch: 5| Step: 4
Training loss: 0.09426447749137878
Validation loss: 1.5163653986428374

Epoch: 5| Step: 5
Training loss: 0.1316249817609787
Validation loss: 1.535505264036117

Epoch: 5| Step: 6
Training loss: 0.2969675064086914
Validation loss: 1.5542538050682313

Epoch: 5| Step: 7
Training loss: 0.26771217584609985
Validation loss: 1.5400766172716696

Epoch: 5| Step: 8
Training loss: 0.14956815540790558
Validation loss: 1.4898484086477628

Epoch: 5| Step: 9
Training loss: 0.13395115733146667
Validation loss: 1.456462219197263

Epoch: 5| Step: 10
Training loss: 0.20633001625537872
Validation loss: 1.4443766340132682

Epoch: 486| Step: 0
Training loss: 0.289766788482666
Validation loss: 1.4434051513671875

Epoch: 5| Step: 1
Training loss: 0.18126234412193298
Validation loss: 1.4509713034476004

Epoch: 5| Step: 2
Training loss: 0.19354812800884247
Validation loss: 1.4639587991981096

Epoch: 5| Step: 3
Training loss: 0.16942943632602692
Validation loss: 1.4415787727602067

Epoch: 5| Step: 4
Training loss: 0.3234784007072449
Validation loss: 1.4517927746618948

Epoch: 5| Step: 5
Training loss: 0.14557476341724396
Validation loss: 1.473228814781353

Epoch: 5| Step: 6
Training loss: 0.16704341769218445
Validation loss: 1.4687512279838644

Epoch: 5| Step: 7
Training loss: 0.16867433488368988
Validation loss: 1.5220707065315657

Epoch: 5| Step: 8
Training loss: 0.10933850705623627
Validation loss: 1.586112477446115

Epoch: 5| Step: 9
Training loss: 0.11109967529773712
Validation loss: 1.57241714385248

Epoch: 5| Step: 10
Training loss: 0.24305206537246704
Validation loss: 1.6004293246935772

Epoch: 487| Step: 0
Training loss: 0.17445895075798035
Validation loss: 1.5781514247258503

Epoch: 5| Step: 1
Training loss: 0.12034519016742706
Validation loss: 1.5677714745203655

Epoch: 5| Step: 2
Training loss: 0.16664227843284607
Validation loss: 1.5339090695945166

Epoch: 5| Step: 3
Training loss: 0.23637819290161133
Validation loss: 1.5120446746067335

Epoch: 5| Step: 4
Training loss: 0.07930732518434525
Validation loss: 1.5011231501897175

Epoch: 5| Step: 5
Training loss: 0.1995658576488495
Validation loss: 1.51949143409729

Epoch: 5| Step: 6
Training loss: 0.08884091675281525
Validation loss: 1.4972720787089357

Epoch: 5| Step: 7
Training loss: 0.11274120956659317
Validation loss: 1.5044175604338288

Epoch: 5| Step: 8
Training loss: 0.17143301665782928
Validation loss: 1.5203863446430494

Epoch: 5| Step: 9
Training loss: 0.07506226003170013
Validation loss: 1.5322330023652764

Epoch: 5| Step: 10
Training loss: 0.2642560601234436
Validation loss: 1.5259745620912122

Epoch: 488| Step: 0
Training loss: 0.1356305330991745
Validation loss: 1.549298183892363

Epoch: 5| Step: 1
Training loss: 0.08745019882917404
Validation loss: 1.5564576259223364

Epoch: 5| Step: 2
Training loss: 0.1999918669462204
Validation loss: 1.5376154389432681

Epoch: 5| Step: 3
Training loss: 0.18802806735038757
Validation loss: 1.514291427468741

Epoch: 5| Step: 4
Training loss: 0.17073315382003784
Validation loss: 1.5414075261803084

Epoch: 5| Step: 5
Training loss: 0.15847142040729523
Validation loss: 1.4938698686579222

Epoch: 5| Step: 6
Training loss: 0.13443687558174133
Validation loss: 1.4547373428139636

Epoch: 5| Step: 7
Training loss: 0.13108918070793152
Validation loss: 1.4591520736294408

Epoch: 5| Step: 8
Training loss: 0.12779879570007324
Validation loss: 1.4752041601365613

Epoch: 5| Step: 9
Training loss: 0.11280275881290436
Validation loss: 1.47496977672782

Epoch: 5| Step: 10
Training loss: 0.2357102334499359
Validation loss: 1.4695797825372348

Epoch: 489| Step: 0
Training loss: 0.1268002986907959
Validation loss: 1.4772324972255255

Epoch: 5| Step: 1
Training loss: 0.11170928180217743
Validation loss: 1.4767336909488966

Epoch: 5| Step: 2
Training loss: 0.15351565182209015
Validation loss: 1.5123436258685203

Epoch: 5| Step: 3
Training loss: 0.19209007918834686
Validation loss: 1.5071484940026396

Epoch: 5| Step: 4
Training loss: 0.2350989282131195
Validation loss: 1.498349332040356

Epoch: 5| Step: 5
Training loss: 0.2094413787126541
Validation loss: 1.4815926821001115

Epoch: 5| Step: 6
Training loss: 0.07651256769895554
Validation loss: 1.470706832024359

Epoch: 5| Step: 7
Training loss: 0.11249873787164688
Validation loss: 1.4876052615463093

Epoch: 5| Step: 8
Training loss: 0.17953959107398987
Validation loss: 1.4999195388568345

Epoch: 5| Step: 9
Training loss: 0.12120332568883896
Validation loss: 1.4705887930367583

Epoch: 5| Step: 10
Training loss: 0.14213329553604126
Validation loss: 1.48815796964912

Epoch: 490| Step: 0
Training loss: 0.18687860667705536
Validation loss: 1.4869443960087274

Epoch: 5| Step: 1
Training loss: 0.1364419162273407
Validation loss: 1.5277318595558085

Epoch: 5| Step: 2
Training loss: 0.14238190650939941
Validation loss: 1.5306942270648094

Epoch: 5| Step: 3
Training loss: 0.16755899786949158
Validation loss: 1.5062670220610916

Epoch: 5| Step: 4
Training loss: 0.26302245259284973
Validation loss: 1.5307802128535446

Epoch: 5| Step: 5
Training loss: 0.15645138919353485
Validation loss: 1.503622066590094

Epoch: 5| Step: 6
Training loss: 0.10598769038915634
Validation loss: 1.4775843120390368

Epoch: 5| Step: 7
Training loss: 0.2153368443250656
Validation loss: 1.5016977120471258

Epoch: 5| Step: 8
Training loss: 0.09852506220340729
Validation loss: 1.5015597868991155

Epoch: 5| Step: 9
Training loss: 0.14575031399726868
Validation loss: 1.5060459106199202

Epoch: 5| Step: 10
Training loss: 0.18691405653953552
Validation loss: 1.5030350377482753

Epoch: 491| Step: 0
Training loss: 0.09148494899272919
Validation loss: 1.5099277118200898

Epoch: 5| Step: 1
Training loss: 0.1010427325963974
Validation loss: 1.4819128513336182

Epoch: 5| Step: 2
Training loss: 0.2406516969203949
Validation loss: 1.4967424061990553

Epoch: 5| Step: 3
Training loss: 0.19209031760692596
Validation loss: 1.5325240999139764

Epoch: 5| Step: 4
Training loss: 0.10217168182134628
Validation loss: 1.5154242810382639

Epoch: 5| Step: 5
Training loss: 0.2134995460510254
Validation loss: 1.5418903673848798

Epoch: 5| Step: 6
Training loss: 0.25768953561782837
Validation loss: 1.5317519621182514

Epoch: 5| Step: 7
Training loss: 0.20414400100708008
Validation loss: 1.551003356133738

Epoch: 5| Step: 8
Training loss: 0.12613855302333832
Validation loss: 1.5435978994574597

Epoch: 5| Step: 9
Training loss: 0.15465839207172394
Validation loss: 1.4822095478734663

Epoch: 5| Step: 10
Training loss: 0.21173544228076935
Validation loss: 1.4794624595231907

Epoch: 492| Step: 0
Training loss: 0.09816525131464005
Validation loss: 1.4774443789194989

Epoch: 5| Step: 1
Training loss: 0.1872265785932541
Validation loss: 1.4845437490811912

Epoch: 5| Step: 2
Training loss: 0.1314413845539093
Validation loss: 1.480339398948095

Epoch: 5| Step: 3
Training loss: 0.19420656561851501
Validation loss: 1.4617600812706897

Epoch: 5| Step: 4
Training loss: 0.12957730889320374
Validation loss: 1.4741916233493435

Epoch: 5| Step: 5
Training loss: 0.09211427718400955
Validation loss: 1.500556399745326

Epoch: 5| Step: 6
Training loss: 0.11177317053079605
Validation loss: 1.504006322994027

Epoch: 5| Step: 7
Training loss: 0.2239592969417572
Validation loss: 1.5100304490776473

Epoch: 5| Step: 8
Training loss: 0.19981352984905243
Validation loss: 1.5202965287752048

Epoch: 5| Step: 9
Training loss: 0.22065839171409607
Validation loss: 1.526508931190737

Epoch: 5| Step: 10
Training loss: 0.1524125635623932
Validation loss: 1.5666691385289675

Epoch: 493| Step: 0
Training loss: 0.2009003609418869
Validation loss: 1.5476507448380994

Epoch: 5| Step: 1
Training loss: 0.10500769317150116
Validation loss: 1.5492291963228615

Epoch: 5| Step: 2
Training loss: 0.10338008403778076
Validation loss: 1.5753358480750874

Epoch: 5| Step: 3
Training loss: 0.13802066445350647
Validation loss: 1.5709834239816154

Epoch: 5| Step: 4
Training loss: 0.14268355071544647
Validation loss: 1.5816125472386677

Epoch: 5| Step: 5
Training loss: 0.1393587291240692
Validation loss: 1.5778559523244058

Epoch: 5| Step: 6
Training loss: 0.25237220525741577
Validation loss: 1.5491821535172001

Epoch: 5| Step: 7
Training loss: 0.11366686969995499
Validation loss: 1.563171084209155

Epoch: 5| Step: 8
Training loss: 0.18686524033546448
Validation loss: 1.546859473310491

Epoch: 5| Step: 9
Training loss: 0.16758111119270325
Validation loss: 1.5740573867674796

Epoch: 5| Step: 10
Training loss: 0.1293419599533081
Validation loss: 1.5685189757295834

Epoch: 494| Step: 0
Training loss: 0.11334767192602158
Validation loss: 1.5475226243336995

Epoch: 5| Step: 1
Training loss: 0.07398716360330582
Validation loss: 1.5409480333328247

Epoch: 5| Step: 2
Training loss: 0.11901849508285522
Validation loss: 1.518676898812735

Epoch: 5| Step: 3
Training loss: 0.15734529495239258
Validation loss: 1.5400993401004421

Epoch: 5| Step: 4
Training loss: 0.12229175865650177
Validation loss: 1.526561987015509

Epoch: 5| Step: 5
Training loss: 0.19753924012184143
Validation loss: 1.5129915277163188

Epoch: 5| Step: 6
Training loss: 0.2553725838661194
Validation loss: 1.500661974953067

Epoch: 5| Step: 7
Training loss: 0.217521071434021
Validation loss: 1.487822146825893

Epoch: 5| Step: 8
Training loss: 0.11622782051563263
Validation loss: 1.5164770977471465

Epoch: 5| Step: 9
Training loss: 0.1960465908050537
Validation loss: 1.5184458058367494

Epoch: 5| Step: 10
Training loss: 0.2108166366815567
Validation loss: 1.517559951351535

Epoch: 495| Step: 0
Training loss: 0.152814120054245
Validation loss: 1.5668600797653198

Epoch: 5| Step: 1
Training loss: 0.10132034122943878
Validation loss: 1.5777357034785773

Epoch: 5| Step: 2
Training loss: 0.22193565964698792
Validation loss: 1.569471069561538

Epoch: 5| Step: 3
Training loss: 0.1872839778661728
Validation loss: 1.5385577140315887

Epoch: 5| Step: 4
Training loss: 0.1211019977927208
Validation loss: 1.5546382665634155

Epoch: 5| Step: 5
Training loss: 0.2933812737464905
Validation loss: 1.5229541858037312

Epoch: 5| Step: 6
Training loss: 0.11933322995901108
Validation loss: 1.5190411152378205

Epoch: 5| Step: 7
Training loss: 0.10776487737894058
Validation loss: 1.5262008661864905

Epoch: 5| Step: 8
Training loss: 0.1601373255252838
Validation loss: 1.5345695813496907

Epoch: 5| Step: 9
Training loss: 0.0777323842048645
Validation loss: 1.575662750069813

Epoch: 5| Step: 10
Training loss: 0.22530022263526917
Validation loss: 1.5537407282860047

Epoch: 496| Step: 0
Training loss: 0.13486377894878387
Validation loss: 1.5412421162410448

Epoch: 5| Step: 1
Training loss: 0.08972146362066269
Validation loss: 1.5379420634238952

Epoch: 5| Step: 2
Training loss: 0.19675154983997345
Validation loss: 1.528677580177143

Epoch: 5| Step: 3
Training loss: 0.08117847889661789
Validation loss: 1.4998531521007579

Epoch: 5| Step: 4
Training loss: 0.18456998467445374
Validation loss: 1.5005418741574852

Epoch: 5| Step: 5
Training loss: 0.13555197417736053
Validation loss: 1.515623402851884

Epoch: 5| Step: 6
Training loss: 0.0759439691901207
Validation loss: 1.5013687392716766

Epoch: 5| Step: 7
Training loss: 0.10376236587762833
Validation loss: 1.5103020065574235

Epoch: 5| Step: 8
Training loss: 0.08749834448099136
Validation loss: 1.4787461321841004

Epoch: 5| Step: 9
Training loss: 0.28457003831863403
Validation loss: 1.4999145615485407

Epoch: 5| Step: 10
Training loss: 0.17856109142303467
Validation loss: 1.5157827946447557

Epoch: 497| Step: 0
Training loss: 0.18553391098976135
Validation loss: 1.4872579395130117

Epoch: 5| Step: 1
Training loss: 0.1502050906419754
Validation loss: 1.5329627772813201

Epoch: 5| Step: 2
Training loss: 0.13411453366279602
Validation loss: 1.5142196897537477

Epoch: 5| Step: 3
Training loss: 0.1374056041240692
Validation loss: 1.498145954583281

Epoch: 5| Step: 4
Training loss: 0.24506275355815887
Validation loss: 1.4859429174853909

Epoch: 5| Step: 5
Training loss: 0.09800707548856735
Validation loss: 1.4612714770019695

Epoch: 5| Step: 6
Training loss: 0.16208991408348083
Validation loss: 1.4538509897006455

Epoch: 5| Step: 7
Training loss: 0.1146099790930748
Validation loss: 1.4630686775330575

Epoch: 5| Step: 8
Training loss: 0.15920968353748322
Validation loss: 1.4962926551859865

Epoch: 5| Step: 9
Training loss: 0.16547314822673798
Validation loss: 1.5236912139000431

Epoch: 5| Step: 10
Training loss: 0.13465352356433868
Validation loss: 1.5123457921448575

Epoch: 498| Step: 0
Training loss: 0.24366351962089539
Validation loss: 1.543486374680714

Epoch: 5| Step: 1
Training loss: 0.12425319105386734
Validation loss: 1.5502248630728772

Epoch: 5| Step: 2
Training loss: 0.1295677125453949
Validation loss: 1.5213550931663924

Epoch: 5| Step: 3
Training loss: 0.12868498265743256
Validation loss: 1.53443996367916

Epoch: 5| Step: 4
Training loss: 0.1796817034482956
Validation loss: 1.5130964440684165

Epoch: 5| Step: 5
Training loss: 0.152847558259964
Validation loss: 1.4951449965917936

Epoch: 5| Step: 6
Training loss: 0.2697223126888275
Validation loss: 1.4684585935326033

Epoch: 5| Step: 7
Training loss: 0.13340936601161957
Validation loss: 1.4821303038186924

Epoch: 5| Step: 8
Training loss: 0.08677957952022552
Validation loss: 1.4812177022298176

Epoch: 5| Step: 9
Training loss: 0.14866474270820618
Validation loss: 1.4898397614878993

Epoch: 5| Step: 10
Training loss: 0.08969829976558685
Validation loss: 1.5045667220187444

Epoch: 499| Step: 0
Training loss: 0.22355203330516815
Validation loss: 1.4767105399921376

Epoch: 5| Step: 1
Training loss: 0.19428527355194092
Validation loss: 1.5084142274754022

Epoch: 5| Step: 2
Training loss: 0.22078871726989746
Validation loss: 1.5205213703135008

Epoch: 5| Step: 3
Training loss: 0.1968836784362793
Validation loss: 1.5088863859894455

Epoch: 5| Step: 4
Training loss: 0.1804892122745514
Validation loss: 1.5060989702901533

Epoch: 5| Step: 5
Training loss: 0.24853721261024475
Validation loss: 1.506923843455571

Epoch: 5| Step: 6
Training loss: 0.11376938968896866
Validation loss: 1.5314491077135968

Epoch: 5| Step: 7
Training loss: 0.1138606071472168
Validation loss: 1.5102347814908592

Epoch: 5| Step: 8
Training loss: 0.10063125938177109
Validation loss: 1.5252654270459247

Epoch: 5| Step: 9
Training loss: 0.1135445088148117
Validation loss: 1.5381778260712982

Epoch: 5| Step: 10
Training loss: 0.09224826097488403
Validation loss: 1.5593420638832995

Epoch: 500| Step: 0
Training loss: 0.09428604692220688
Validation loss: 1.541244911891158

Epoch: 5| Step: 1
Training loss: 0.1433364450931549
Validation loss: 1.543674559362473

Epoch: 5| Step: 2
Training loss: 0.08250702917575836
Validation loss: 1.5536507502678902

Epoch: 5| Step: 3
Training loss: 0.07506849616765976
Validation loss: 1.5614700907020158

Epoch: 5| Step: 4
Training loss: 0.18501237034797668
Validation loss: 1.5386011395403134

Epoch: 5| Step: 5
Training loss: 0.07423821836709976
Validation loss: 1.5376457527119627

Epoch: 5| Step: 6
Training loss: 0.21788792312145233
Validation loss: 1.5262683835080875

Epoch: 5| Step: 7
Training loss: 0.10993411391973495
Validation loss: 1.5103591975345407

Epoch: 5| Step: 8
Training loss: 0.23089464008808136
Validation loss: 1.5084068275267077

Epoch: 5| Step: 9
Training loss: 0.25939565896987915
Validation loss: 1.4873767001654512

Epoch: 5| Step: 10
Training loss: 0.14673709869384766
Validation loss: 1.5167122207662111

Epoch: 501| Step: 0
Training loss: 0.273598313331604
Validation loss: 1.5313653881831835

Epoch: 5| Step: 1
Training loss: 0.1306660771369934
Validation loss: 1.523411109883298

Epoch: 5| Step: 2
Training loss: 0.13279466331005096
Validation loss: 1.5346604790738834

Epoch: 5| Step: 3
Training loss: 0.10173952579498291
Validation loss: 1.5614852046453824

Epoch: 5| Step: 4
Training loss: 0.11881542205810547
Validation loss: 1.505032229167159

Epoch: 5| Step: 5
Training loss: 0.17541058361530304
Validation loss: 1.5462468529260287

Epoch: 5| Step: 6
Training loss: 0.11027590930461884
Validation loss: 1.5476517497852285

Epoch: 5| Step: 7
Training loss: 0.19645418226718903
Validation loss: 1.5516483834994736

Epoch: 5| Step: 8
Training loss: 0.18135245144367218
Validation loss: 1.5445567625825123

Epoch: 5| Step: 9
Training loss: 0.14231525361537933
Validation loss: 1.5372944467811174

Epoch: 5| Step: 10
Training loss: 0.08837173134088516
Validation loss: 1.5026405062726749

Epoch: 502| Step: 0
Training loss: 0.16879034042358398
Validation loss: 1.4998007512861682

Epoch: 5| Step: 1
Training loss: 0.1437380462884903
Validation loss: 1.500931651361527

Epoch: 5| Step: 2
Training loss: 0.09358508884906769
Validation loss: 1.5016755557829333

Epoch: 5| Step: 3
Training loss: 0.22215721011161804
Validation loss: 1.5191175040378366

Epoch: 5| Step: 4
Training loss: 0.14556293189525604
Validation loss: 1.5047330394867928

Epoch: 5| Step: 5
Training loss: 0.22072091698646545
Validation loss: 1.5519347062674902

Epoch: 5| Step: 6
Training loss: 0.18826675415039062
Validation loss: 1.5247461565079228

Epoch: 5| Step: 7
Training loss: 0.1323113739490509
Validation loss: 1.5168780652425622

Epoch: 5| Step: 8
Training loss: 0.2022688388824463
Validation loss: 1.5455780849661878

Epoch: 5| Step: 9
Training loss: 0.12468208372592926
Validation loss: 1.5120680293729227

Epoch: 5| Step: 10
Training loss: 0.15035949647426605
Validation loss: 1.51537573593919

Epoch: 503| Step: 0
Training loss: 0.08542437851428986
Validation loss: 1.482604722822866

Epoch: 5| Step: 1
Training loss: 0.10903028398752213
Validation loss: 1.4796134336020357

Epoch: 5| Step: 2
Training loss: 0.22174887359142303
Validation loss: 1.4958001785380866

Epoch: 5| Step: 3
Training loss: 0.12111077457666397
Validation loss: 1.4777197530192714

Epoch: 5| Step: 4
Training loss: 0.15328213572502136
Validation loss: 1.5328798858068322

Epoch: 5| Step: 5
Training loss: 0.15297898650169373
Validation loss: 1.5395367555720831

Epoch: 5| Step: 6
Training loss: 0.15389859676361084
Validation loss: 1.5462948737605926

Epoch: 5| Step: 7
Training loss: 0.2501223087310791
Validation loss: 1.56208566247776

Epoch: 5| Step: 8
Training loss: 0.15601317584514618
Validation loss: 1.5855319801197256

Epoch: 5| Step: 9
Training loss: 0.11316460371017456
Validation loss: 1.5641486567835654

Epoch: 5| Step: 10
Training loss: 0.08807796984910965
Validation loss: 1.5738498741580593

Epoch: 504| Step: 0
Training loss: 0.21800939738750458
Validation loss: 1.5466614897533129

Epoch: 5| Step: 1
Training loss: 0.12811097502708435
Validation loss: 1.5372909333116265

Epoch: 5| Step: 2
Training loss: 0.17960694432258606
Validation loss: 1.5707787659860426

Epoch: 5| Step: 3
Training loss: 0.10105915367603302
Validation loss: 1.5495289551314486

Epoch: 5| Step: 4
Training loss: 0.22888866066932678
Validation loss: 1.5342547098795574

Epoch: 5| Step: 5
Training loss: 0.21455168724060059
Validation loss: 1.54118973465376

Epoch: 5| Step: 6
Training loss: 0.15969203412532806
Validation loss: 1.5702345730156027

Epoch: 5| Step: 7
Training loss: 0.19691592454910278
Validation loss: 1.5809873829605758

Epoch: 5| Step: 8
Training loss: 0.1603943407535553
Validation loss: 1.550535660918041

Epoch: 5| Step: 9
Training loss: 0.10881657898426056
Validation loss: 1.5245437224706013

Epoch: 5| Step: 10
Training loss: 0.1141195148229599
Validation loss: 1.515086943103421

Epoch: 505| Step: 0
Training loss: 0.11535350978374481
Validation loss: 1.5005806364038938

Epoch: 5| Step: 1
Training loss: 0.32974129915237427
Validation loss: 1.486814312396511

Epoch: 5| Step: 2
Training loss: 0.18883249163627625
Validation loss: 1.5084141710753083

Epoch: 5| Step: 3
Training loss: 0.21973779797554016
Validation loss: 1.4956097000388688

Epoch: 5| Step: 4
Training loss: 0.12038035690784454
Validation loss: 1.5380375231465986

Epoch: 5| Step: 5
Training loss: 0.07355993986129761
Validation loss: 1.546815203082177

Epoch: 5| Step: 6
Training loss: 0.10085437446832657
Validation loss: 1.559948568703026

Epoch: 5| Step: 7
Training loss: 0.12607017159461975
Validation loss: 1.551256242618766

Epoch: 5| Step: 8
Training loss: 0.14866653084754944
Validation loss: 1.525233373847059

Epoch: 5| Step: 9
Training loss: 0.10713078826665878
Validation loss: 1.5292893737875006

Epoch: 5| Step: 10
Training loss: 0.17541876435279846
Validation loss: 1.5015014717655797

Epoch: 506| Step: 0
Training loss: 0.13755568861961365
Validation loss: 1.493104592446358

Epoch: 5| Step: 1
Training loss: 0.12721264362335205
Validation loss: 1.5104804231274513

Epoch: 5| Step: 2
Training loss: 0.16207203269004822
Validation loss: 1.5054974812333302

Epoch: 5| Step: 3
Training loss: 0.17533841729164124
Validation loss: 1.5179669203296784

Epoch: 5| Step: 4
Training loss: 0.2167268693447113
Validation loss: 1.5251909250854163

Epoch: 5| Step: 5
Training loss: 0.16540928184986115
Validation loss: 1.5042194179309312

Epoch: 5| Step: 6
Training loss: 0.14129559695720673
Validation loss: 1.5406559962098316

Epoch: 5| Step: 7
Training loss: 0.09854906797409058
Validation loss: 1.5338419509190384

Epoch: 5| Step: 8
Training loss: 0.10881485790014267
Validation loss: 1.5570441061450588

Epoch: 5| Step: 9
Training loss: 0.1092943325638771
Validation loss: 1.5393959963193504

Epoch: 5| Step: 10
Training loss: 0.1663094311952591
Validation loss: 1.5516414091151247

Epoch: 507| Step: 0
Training loss: 0.06488493084907532
Validation loss: 1.52602356736378

Epoch: 5| Step: 1
Training loss: 0.1375110149383545
Validation loss: 1.5539147148850143

Epoch: 5| Step: 2
Training loss: 0.13544759154319763
Validation loss: 1.51788725391511

Epoch: 5| Step: 3
Training loss: 0.1282918006181717
Validation loss: 1.5382950857121458

Epoch: 5| Step: 4
Training loss: 0.13551804423332214
Validation loss: 1.5494368691598215

Epoch: 5| Step: 5
Training loss: 0.20778897404670715
Validation loss: 1.5736547516238304

Epoch: 5| Step: 6
Training loss: 0.13922198116779327
Validation loss: 1.5705668605783933

Epoch: 5| Step: 7
Training loss: 0.09817427396774292
Validation loss: 1.5553756272920998

Epoch: 5| Step: 8
Training loss: 0.1864173859357834
Validation loss: 1.557975778015711

Epoch: 5| Step: 9
Training loss: 0.20471253991127014
Validation loss: 1.5526924267891915

Epoch: 5| Step: 10
Training loss: 0.15505662560462952
Validation loss: 1.569786835742253

Epoch: 508| Step: 0
Training loss: 0.08004696667194366
Validation loss: 1.5131795790887648

Epoch: 5| Step: 1
Training loss: 0.2551064193248749
Validation loss: 1.4842340164287116

Epoch: 5| Step: 2
Training loss: 0.08737692981958389
Validation loss: 1.4803037271704724

Epoch: 5| Step: 3
Training loss: 0.2009304016828537
Validation loss: 1.531723956907949

Epoch: 5| Step: 4
Training loss: 0.11841480433940887
Validation loss: 1.5239185376833844

Epoch: 5| Step: 5
Training loss: 0.18013468384742737
Validation loss: 1.524592823879693

Epoch: 5| Step: 6
Training loss: 0.1357952505350113
Validation loss: 1.510195832098684

Epoch: 5| Step: 7
Training loss: 0.11732206493616104
Validation loss: 1.5382687263591315

Epoch: 5| Step: 8
Training loss: 0.09489808976650238
Validation loss: 1.5313946905956473

Epoch: 5| Step: 9
Training loss: 0.08586867898702621
Validation loss: 1.5046738501518004

Epoch: 5| Step: 10
Training loss: 0.1395658254623413
Validation loss: 1.5315856074774137

Epoch: 509| Step: 0
Training loss: 0.11181994527578354
Validation loss: 1.5203003062996814

Epoch: 5| Step: 1
Training loss: 0.31141266226768494
Validation loss: 1.535605784385435

Epoch: 5| Step: 2
Training loss: 0.14103657007217407
Validation loss: 1.524001031793574

Epoch: 5| Step: 3
Training loss: 0.07546748220920563
Validation loss: 1.5471541984106905

Epoch: 5| Step: 4
Training loss: 0.18689797818660736
Validation loss: 1.5594821155712169

Epoch: 5| Step: 5
Training loss: 0.10751935094594955
Validation loss: 1.535265952028254

Epoch: 5| Step: 6
Training loss: 0.1362515687942505
Validation loss: 1.5215493427809847

Epoch: 5| Step: 7
Training loss: 0.18331345915794373
Validation loss: 1.533485395933992

Epoch: 5| Step: 8
Training loss: 0.20136001706123352
Validation loss: 1.523711626247693

Epoch: 5| Step: 9
Training loss: 0.1551716923713684
Validation loss: 1.5301480421455957

Epoch: 5| Step: 10
Training loss: 0.137488454580307
Validation loss: 1.5759554165665821

Epoch: 510| Step: 0
Training loss: 0.20447497069835663
Validation loss: 1.5715267087823601

Epoch: 5| Step: 1
Training loss: 0.08617129176855087
Validation loss: 1.5363785682186004

Epoch: 5| Step: 2
Training loss: 0.16649651527404785
Validation loss: 1.5594870505794403

Epoch: 5| Step: 3
Training loss: 0.21141132712364197
Validation loss: 1.527366203646506

Epoch: 5| Step: 4
Training loss: 0.11624392122030258
Validation loss: 1.5334150970623057

Epoch: 5| Step: 5
Training loss: 0.1841498613357544
Validation loss: 1.4924757557530557

Epoch: 5| Step: 6
Training loss: 0.14755448698997498
Validation loss: 1.4926757338226482

Epoch: 5| Step: 7
Training loss: 0.11551723629236221
Validation loss: 1.5101809322193105

Epoch: 5| Step: 8
Training loss: 0.12395678460597992
Validation loss: 1.4881789927841516

Epoch: 5| Step: 9
Training loss: 0.14113657176494598
Validation loss: 1.4763958236222625

Epoch: 5| Step: 10
Training loss: 0.08432882279157639
Validation loss: 1.4785872499148052

Epoch: 511| Step: 0
Training loss: 0.2637787461280823
Validation loss: 1.4839414960594588

Epoch: 5| Step: 1
Training loss: 0.14134933054447174
Validation loss: 1.4832514255277571

Epoch: 5| Step: 2
Training loss: 0.07902424782514572
Validation loss: 1.458001112425199

Epoch: 5| Step: 3
Training loss: 0.13196787238121033
Validation loss: 1.4558192427440355

Epoch: 5| Step: 4
Training loss: 0.0773167759180069
Validation loss: 1.4680419583474436

Epoch: 5| Step: 5
Training loss: 0.12118508666753769
Validation loss: 1.484690438034714

Epoch: 5| Step: 6
Training loss: 0.11367543041706085
Validation loss: 1.477396785572011

Epoch: 5| Step: 7
Training loss: 0.15171650052070618
Validation loss: 1.4829973879680838

Epoch: 5| Step: 8
Training loss: 0.12126626074314117
Validation loss: 1.5084208211591166

Epoch: 5| Step: 9
Training loss: 0.11602811515331268
Validation loss: 1.4932279868792462

Epoch: 5| Step: 10
Training loss: 0.115122951567173
Validation loss: 1.49471305647204

Epoch: 512| Step: 0
Training loss: 0.1525813639163971
Validation loss: 1.5119852173712947

Epoch: 5| Step: 1
Training loss: 0.07925869524478912
Validation loss: 1.5283430827561246

Epoch: 5| Step: 2
Training loss: 0.15737272799015045
Validation loss: 1.5270403803035777

Epoch: 5| Step: 3
Training loss: 0.09608800709247589
Validation loss: 1.525325668755398

Epoch: 5| Step: 4
Training loss: 0.07391633093357086
Validation loss: 1.5175220017792077

Epoch: 5| Step: 5
Training loss: 0.07565721869468689
Validation loss: 1.5129954520092215

Epoch: 5| Step: 6
Training loss: 0.18532229959964752
Validation loss: 1.5130658066400917

Epoch: 5| Step: 7
Training loss: 0.19478103518486023
Validation loss: 1.4986819990219609

Epoch: 5| Step: 8
Training loss: 0.12004651129245758
Validation loss: 1.5008391359800934

Epoch: 5| Step: 9
Training loss: 0.1512855738401413
Validation loss: 1.493185133062383

Epoch: 5| Step: 10
Training loss: 0.12522029876708984
Validation loss: 1.4874379224674676

Epoch: 513| Step: 0
Training loss: 0.08962303400039673
Validation loss: 1.4879087760884275

Epoch: 5| Step: 1
Training loss: 0.22967080771923065
Validation loss: 1.5114868148680656

Epoch: 5| Step: 2
Training loss: 0.08191357553005219
Validation loss: 1.4716406150530743

Epoch: 5| Step: 3
Training loss: 0.10073940455913544
Validation loss: 1.5017981183144353

Epoch: 5| Step: 4
Training loss: 0.05854841321706772
Validation loss: 1.483268085346427

Epoch: 5| Step: 5
Training loss: 0.13900411128997803
Validation loss: 1.4783462824360016

Epoch: 5| Step: 6
Training loss: 0.17663034796714783
Validation loss: 1.4885411416330645

Epoch: 5| Step: 7
Training loss: 0.15036800503730774
Validation loss: 1.4693742170128772

Epoch: 5| Step: 8
Training loss: 0.23669132590293884
Validation loss: 1.501094304746197

Epoch: 5| Step: 9
Training loss: 0.13823941349983215
Validation loss: 1.4748514916307183

Epoch: 5| Step: 10
Training loss: 0.1241181343793869
Validation loss: 1.5311952265360023

Epoch: 514| Step: 0
Training loss: 0.27367815375328064
Validation loss: 1.5288929811087988

Epoch: 5| Step: 1
Training loss: 0.07868051528930664
Validation loss: 1.5330681890569708

Epoch: 5| Step: 2
Training loss: 0.14110931754112244
Validation loss: 1.512941965492823

Epoch: 5| Step: 3
Training loss: 0.10003478825092316
Validation loss: 1.5468078351789905

Epoch: 5| Step: 4
Training loss: 0.10501577705144882
Validation loss: 1.55159092334009

Epoch: 5| Step: 5
Training loss: 0.08102309703826904
Validation loss: 1.5360917852770897

Epoch: 5| Step: 6
Training loss: 0.08970455825328827
Validation loss: 1.562776679633766

Epoch: 5| Step: 7
Training loss: 0.1133800745010376
Validation loss: 1.5722830084062391

Epoch: 5| Step: 8
Training loss: 0.1490492820739746
Validation loss: 1.5548702311772171

Epoch: 5| Step: 9
Training loss: 0.10068671405315399
Validation loss: 1.5534264464532175

Epoch: 5| Step: 10
Training loss: 0.12267926335334778
Validation loss: 1.515452406739676

Epoch: 515| Step: 0
Training loss: 0.07923763245344162
Validation loss: 1.5034246585702384

Epoch: 5| Step: 1
Training loss: 0.11972162872552872
Validation loss: 1.4973860222806212

Epoch: 5| Step: 2
Training loss: 0.13521072268486023
Validation loss: 1.4772208826516264

Epoch: 5| Step: 3
Training loss: 0.11146493256092072
Validation loss: 1.4852003205207087

Epoch: 5| Step: 4
Training loss: 0.05250917747616768
Validation loss: 1.4811239537372385

Epoch: 5| Step: 5
Training loss: 0.062330178916454315
Validation loss: 1.4728433425708483

Epoch: 5| Step: 6
Training loss: 0.19903497397899628
Validation loss: 1.4946634641257666

Epoch: 5| Step: 7
Training loss: 0.15717510879039764
Validation loss: 1.5066279365170387

Epoch: 5| Step: 8
Training loss: 0.21425428986549377
Validation loss: 1.5123297450362996

Epoch: 5| Step: 9
Training loss: 0.11609478294849396
Validation loss: 1.5061236478949105

Epoch: 5| Step: 10
Training loss: 0.18419596552848816
Validation loss: 1.475610916332532

Epoch: 516| Step: 0
Training loss: 0.1380625069141388
Validation loss: 1.4730181386393886

Epoch: 5| Step: 1
Training loss: 0.12293858826160431
Validation loss: 1.4532330574527863

Epoch: 5| Step: 2
Training loss: 0.12666510045528412
Validation loss: 1.4510358161823724

Epoch: 5| Step: 3
Training loss: 0.14472222328186035
Validation loss: 1.4668305804652553

Epoch: 5| Step: 4
Training loss: 0.12570741772651672
Validation loss: 1.4536769133742138

Epoch: 5| Step: 5
Training loss: 0.16023272275924683
Validation loss: 1.4748006879642446

Epoch: 5| Step: 6
Training loss: 0.10362212359905243
Validation loss: 1.4955036550439813

Epoch: 5| Step: 7
Training loss: 0.1408839374780655
Validation loss: 1.521699070930481

Epoch: 5| Step: 8
Training loss: 0.07652460038661957
Validation loss: 1.548030126479364

Epoch: 5| Step: 9
Training loss: 0.10171903669834137
Validation loss: 1.5111036999251253

Epoch: 5| Step: 10
Training loss: 0.19459715485572815
Validation loss: 1.5220357577006023

Epoch: 517| Step: 0
Training loss: 0.08930833637714386
Validation loss: 1.4900771905017156

Epoch: 5| Step: 1
Training loss: 0.13046152889728546
Validation loss: 1.500400609867547

Epoch: 5| Step: 2
Training loss: 0.14733120799064636
Validation loss: 1.4929658687242897

Epoch: 5| Step: 3
Training loss: 0.1516638696193695
Validation loss: 1.48647149532072

Epoch: 5| Step: 4
Training loss: 0.24623075127601624
Validation loss: 1.4876126332949566

Epoch: 5| Step: 5
Training loss: 0.08008640259504318
Validation loss: 1.4972396384003341

Epoch: 5| Step: 6
Training loss: 0.09642572700977325
Validation loss: 1.5168411641992547

Epoch: 5| Step: 7
Training loss: 0.11190519481897354
Validation loss: 1.5405171994240052

Epoch: 5| Step: 8
Training loss: 0.0945306271314621
Validation loss: 1.5177220939308085

Epoch: 5| Step: 9
Training loss: 0.21847932040691376
Validation loss: 1.5676096664961947

Epoch: 5| Step: 10
Training loss: 0.08001558482646942
Validation loss: 1.541614305588507

Epoch: 518| Step: 0
Training loss: 0.19431784749031067
Validation loss: 1.5376503134286532

Epoch: 5| Step: 1
Training loss: 0.10231275856494904
Validation loss: 1.5122578297891924

Epoch: 5| Step: 2
Training loss: 0.0714174136519432
Validation loss: 1.4766551448452858

Epoch: 5| Step: 3
Training loss: 0.18128721415996552
Validation loss: 1.4797616004943848

Epoch: 5| Step: 4
Training loss: 0.14498519897460938
Validation loss: 1.470245038309405

Epoch: 5| Step: 5
Training loss: 0.1302543431520462
Validation loss: 1.4691576791065994

Epoch: 5| Step: 6
Training loss: 0.1390751302242279
Validation loss: 1.4744058744881743

Epoch: 5| Step: 7
Training loss: 0.09360340982675552
Validation loss: 1.4610674560710948

Epoch: 5| Step: 8
Training loss: 0.0910429060459137
Validation loss: 1.4859327116320211

Epoch: 5| Step: 9
Training loss: 0.12959352135658264
Validation loss: 1.4931019890692927

Epoch: 5| Step: 10
Training loss: 0.29968178272247314
Validation loss: 1.5472576887376848

Epoch: 519| Step: 0
Training loss: 0.13876892626285553
Validation loss: 1.5439651909694876

Epoch: 5| Step: 1
Training loss: 0.12031562626361847
Validation loss: 1.504057062569485

Epoch: 5| Step: 2
Training loss: 0.15321967005729675
Validation loss: 1.5060427849010756

Epoch: 5| Step: 3
Training loss: 0.07317077368497849
Validation loss: 1.4849039431541198

Epoch: 5| Step: 4
Training loss: 0.0944892019033432
Validation loss: 1.491673993807967

Epoch: 5| Step: 5
Training loss: 0.09507991373538971
Validation loss: 1.48044970855918

Epoch: 5| Step: 6
Training loss: 0.16449840366840363
Validation loss: 1.49828076875338

Epoch: 5| Step: 7
Training loss: 0.1405700296163559
Validation loss: 1.4900066788478563

Epoch: 5| Step: 8
Training loss: 0.09132251888513565
Validation loss: 1.5005970116584533

Epoch: 5| Step: 9
Training loss: 0.1360529363155365
Validation loss: 1.4851358936678978

Epoch: 5| Step: 10
Training loss: 0.13556364178657532
Validation loss: 1.465870916202504

Epoch: 520| Step: 0
Training loss: 0.1647370308637619
Validation loss: 1.4568736219918856

Epoch: 5| Step: 1
Training loss: 0.11509475857019424
Validation loss: 1.4705471819446934

Epoch: 5| Step: 2
Training loss: 0.08105777204036713
Validation loss: 1.4528568226804015

Epoch: 5| Step: 3
Training loss: 0.12318418174982071
Validation loss: 1.452032967280316

Epoch: 5| Step: 4
Training loss: 0.10970087349414825
Validation loss: 1.4487342360199138

Epoch: 5| Step: 5
Training loss: 0.117717444896698
Validation loss: 1.4577802227389427

Epoch: 5| Step: 6
Training loss: 0.14483290910720825
Validation loss: 1.4785384080743278

Epoch: 5| Step: 7
Training loss: 0.0886305645108223
Validation loss: 1.4703700029721825

Epoch: 5| Step: 8
Training loss: 0.10832986980676651
Validation loss: 1.5009392628105738

Epoch: 5| Step: 9
Training loss: 0.13736581802368164
Validation loss: 1.510540521273049

Epoch: 5| Step: 10
Training loss: 0.20049241185188293
Validation loss: 1.527160330485272

Epoch: 521| Step: 0
Training loss: 0.11796392500400543
Validation loss: 1.4912325669360418

Epoch: 5| Step: 1
Training loss: 0.08919377624988556
Validation loss: 1.5257292870552308

Epoch: 5| Step: 2
Training loss: 0.17185960710048676
Validation loss: 1.5246042769442323

Epoch: 5| Step: 3
Training loss: 0.08572011440992355
Validation loss: 1.5517162622944

Epoch: 5| Step: 4
Training loss: 0.24819011986255646
Validation loss: 1.5481500651246758

Epoch: 5| Step: 5
Training loss: 0.07954426854848862
Validation loss: 1.5897421554852558

Epoch: 5| Step: 6
Training loss: 0.09291676431894302
Validation loss: 1.5320574891182683

Epoch: 5| Step: 7
Training loss: 0.09020228683948517
Validation loss: 1.5142635747950564

Epoch: 5| Step: 8
Training loss: 0.08095022290945053
Validation loss: 1.5079427701170727

Epoch: 5| Step: 9
Training loss: 0.12470684945583344
Validation loss: 1.5150390235326623

Epoch: 5| Step: 10
Training loss: 0.10924044996500015
Validation loss: 1.5090807323814721

Epoch: 522| Step: 0
Training loss: 0.1843215972185135
Validation loss: 1.5367981785087175

Epoch: 5| Step: 1
Training loss: 0.0826660618185997
Validation loss: 1.514101909052941

Epoch: 5| Step: 2
Training loss: 0.12423370778560638
Validation loss: 1.52679306204601

Epoch: 5| Step: 3
Training loss: 0.09727533161640167
Validation loss: 1.5299542962863881

Epoch: 5| Step: 4
Training loss: 0.09886287152767181
Validation loss: 1.540083163528032

Epoch: 5| Step: 5
Training loss: 0.08406274020671844
Validation loss: 1.557619442221939

Epoch: 5| Step: 6
Training loss: 0.12833675742149353
Validation loss: 1.5495146269439368

Epoch: 5| Step: 7
Training loss: 0.10963559150695801
Validation loss: 1.5216132235783402

Epoch: 5| Step: 8
Training loss: 0.17671972513198853
Validation loss: 1.5242698474596905

Epoch: 5| Step: 9
Training loss: 0.13559314608573914
Validation loss: 1.5196956998558455

Epoch: 5| Step: 10
Training loss: 0.170798659324646
Validation loss: 1.5093323466598347

Epoch: 523| Step: 0
Training loss: 0.1774103343486786
Validation loss: 1.500629130230155

Epoch: 5| Step: 1
Training loss: 0.052416615188121796
Validation loss: 1.4857375878159718

Epoch: 5| Step: 2
Training loss: 0.11934652179479599
Validation loss: 1.477227275089551

Epoch: 5| Step: 3
Training loss: 0.058629583567380905
Validation loss: 1.4704932551230154

Epoch: 5| Step: 4
Training loss: 0.15204551815986633
Validation loss: 1.4655043848099247

Epoch: 5| Step: 5
Training loss: 0.14658986032009125
Validation loss: 1.4699634236674155

Epoch: 5| Step: 6
Training loss: 0.11602053791284561
Validation loss: 1.4520404749019171

Epoch: 5| Step: 7
Training loss: 0.10927202552556992
Validation loss: 1.4793181573190997

Epoch: 5| Step: 8
Training loss: 0.12539993226528168
Validation loss: 1.4736585078700897

Epoch: 5| Step: 9
Training loss: 0.093492791056633
Validation loss: 1.4781373213696223

Epoch: 5| Step: 10
Training loss: 0.14446480572223663
Validation loss: 1.4513516951632757

Epoch: 524| Step: 0
Training loss: 0.06790406256914139
Validation loss: 1.4748259641790902

Epoch: 5| Step: 1
Training loss: 0.09388823062181473
Validation loss: 1.4730270293451124

Epoch: 5| Step: 2
Training loss: 0.10255064070224762
Validation loss: 1.4632856666400869

Epoch: 5| Step: 3
Training loss: 0.17332300543785095
Validation loss: 1.4738154206224667

Epoch: 5| Step: 4
Training loss: 0.11002162843942642
Validation loss: 1.4765927458322177

Epoch: 5| Step: 5
Training loss: 0.09171882271766663
Validation loss: 1.4502566578567668

Epoch: 5| Step: 6
Training loss: 0.21371348202228546
Validation loss: 1.5086012322415587

Epoch: 5| Step: 7
Training loss: 0.09818895161151886
Validation loss: 1.4778086036764166

Epoch: 5| Step: 8
Training loss: 0.12786152958869934
Validation loss: 1.4760849527133408

Epoch: 5| Step: 9
Training loss: 0.12248494476079941
Validation loss: 1.4733666079018706

Epoch: 5| Step: 10
Training loss: 0.08107005804777145
Validation loss: 1.4952446081305062

Epoch: 525| Step: 0
Training loss: 0.16443923115730286
Validation loss: 1.463482120985626

Epoch: 5| Step: 1
Training loss: 0.17016924917697906
Validation loss: 1.4667263505279378

Epoch: 5| Step: 2
Training loss: 0.16090808808803558
Validation loss: 1.4848139798769386

Epoch: 5| Step: 3
Training loss: 0.11795739829540253
Validation loss: 1.4807888846243582

Epoch: 5| Step: 4
Training loss: 0.11882247775793076
Validation loss: 1.4891965286706084

Epoch: 5| Step: 5
Training loss: 0.17536082863807678
Validation loss: 1.4935739630012101

Epoch: 5| Step: 6
Training loss: 0.09023886919021606
Validation loss: 1.4696511401925036

Epoch: 5| Step: 7
Training loss: 0.107441246509552
Validation loss: 1.5091837119030695

Epoch: 5| Step: 8
Training loss: 0.10246630758047104
Validation loss: 1.489773875923567

Epoch: 5| Step: 9
Training loss: 0.12773558497428894
Validation loss: 1.5031206505272978

Epoch: 5| Step: 10
Training loss: 0.11098060756921768
Validation loss: 1.5187172402617752

Epoch: 526| Step: 0
Training loss: 0.16842854022979736
Validation loss: 1.5457747931121497

Epoch: 5| Step: 1
Training loss: 0.18250931799411774
Validation loss: 1.5130031608766126

Epoch: 5| Step: 2
Training loss: 0.13799627125263214
Validation loss: 1.501585078495805

Epoch: 5| Step: 3
Training loss: 0.15944556891918182
Validation loss: 1.4959702812215334

Epoch: 5| Step: 4
Training loss: 0.1030731350183487
Validation loss: 1.4820234544815556

Epoch: 5| Step: 5
Training loss: 0.08401663601398468
Validation loss: 1.4453487921786565

Epoch: 5| Step: 6
Training loss: 0.16836600005626678
Validation loss: 1.4309355738342449

Epoch: 5| Step: 7
Training loss: 0.06832146644592285
Validation loss: 1.4461391882229877

Epoch: 5| Step: 8
Training loss: 0.12539048492908478
Validation loss: 1.459573486799835

Epoch: 5| Step: 9
Training loss: 0.07982206344604492
Validation loss: 1.44398675041814

Epoch: 5| Step: 10
Training loss: 0.1248362734913826
Validation loss: 1.4476377707655712

Epoch: 527| Step: 0
Training loss: 0.11576788127422333
Validation loss: 1.457462723537158

Epoch: 5| Step: 1
Training loss: 0.18249258399009705
Validation loss: 1.4342843524871334

Epoch: 5| Step: 2
Training loss: 0.07969389855861664
Validation loss: 1.433039242221463

Epoch: 5| Step: 3
Training loss: 0.07768675684928894
Validation loss: 1.4600734185147028

Epoch: 5| Step: 4
Training loss: 0.07993657886981964
Validation loss: 1.432846699991534

Epoch: 5| Step: 5
Training loss: 0.14867225289344788
Validation loss: 1.4453547628976966

Epoch: 5| Step: 6
Training loss: 0.15675468742847443
Validation loss: 1.4676035142713977

Epoch: 5| Step: 7
Training loss: 0.12808813154697418
Validation loss: 1.4677815309134863

Epoch: 5| Step: 8
Training loss: 0.13877926766872406
Validation loss: 1.4796817828250188

Epoch: 5| Step: 9
Training loss: 0.07226607948541641
Validation loss: 1.467239822110822

Epoch: 5| Step: 10
Training loss: 0.16735424101352692
Validation loss: 1.4729227558259042

Epoch: 528| Step: 0
Training loss: 0.1155252456665039
Validation loss: 1.4751794536908467

Epoch: 5| Step: 1
Training loss: 0.17479021847248077
Validation loss: 1.4936432133438766

Epoch: 5| Step: 2
Training loss: 0.11244328320026398
Validation loss: 1.4983932292589577

Epoch: 5| Step: 3
Training loss: 0.15596355497837067
Validation loss: 1.488547932717108

Epoch: 5| Step: 4
Training loss: 0.12312905490398407
Validation loss: 1.4704807086657452

Epoch: 5| Step: 5
Training loss: 0.1327536404132843
Validation loss: 1.491531325924781

Epoch: 5| Step: 6
Training loss: 0.3121560513973236
Validation loss: 1.4888810752540507

Epoch: 5| Step: 7
Training loss: 0.12099550664424896
Validation loss: 1.4796592432965514

Epoch: 5| Step: 8
Training loss: 0.11417347192764282
Validation loss: 1.465042398821923

Epoch: 5| Step: 9
Training loss: 0.09554097801446915
Validation loss: 1.460707785621766

Epoch: 5| Step: 10
Training loss: 0.08617294579744339
Validation loss: 1.4793632491942375

Epoch: 529| Step: 0
Training loss: 0.09575068205595016
Validation loss: 1.5030254125595093

Epoch: 5| Step: 1
Training loss: 0.12223192304372787
Validation loss: 1.5022858669680934

Epoch: 5| Step: 2
Training loss: 0.09144315123558044
Validation loss: 1.4906536315077095

Epoch: 5| Step: 3
Training loss: 0.12663578987121582
Validation loss: 1.5027830190556024

Epoch: 5| Step: 4
Training loss: 0.15431427955627441
Validation loss: 1.497152200309179

Epoch: 5| Step: 5
Training loss: 0.13298888504505157
Validation loss: 1.5024731159210205

Epoch: 5| Step: 6
Training loss: 0.1888989806175232
Validation loss: 1.5166364357035647

Epoch: 5| Step: 7
Training loss: 0.27694717049598694
Validation loss: 1.4906525137603923

Epoch: 5| Step: 8
Training loss: 0.11834973096847534
Validation loss: 1.4917860531037854

Epoch: 5| Step: 9
Training loss: 0.09466667473316193
Validation loss: 1.5060749887138285

Epoch: 5| Step: 10
Training loss: 0.20639991760253906
Validation loss: 1.5011042125763432

Epoch: 530| Step: 0
Training loss: 0.14152070879936218
Validation loss: 1.4830590512162896

Epoch: 5| Step: 1
Training loss: 0.1817953884601593
Validation loss: 1.4629164293248167

Epoch: 5| Step: 2
Training loss: 0.1382438838481903
Validation loss: 1.4813121480326499

Epoch: 5| Step: 3
Training loss: 0.1338161677122116
Validation loss: 1.4281161664634623

Epoch: 5| Step: 4
Training loss: 0.14050346612930298
Validation loss: 1.4549536346107401

Epoch: 5| Step: 5
Training loss: 0.1886008083820343
Validation loss: 1.4571289029172672

Epoch: 5| Step: 6
Training loss: 0.1373518854379654
Validation loss: 1.4527337730571788

Epoch: 5| Step: 7
Training loss: 0.09222599864006042
Validation loss: 1.4489630371011712

Epoch: 5| Step: 8
Training loss: 0.15063908696174622
Validation loss: 1.469545889926213

Epoch: 5| Step: 9
Training loss: 0.1314937174320221
Validation loss: 1.481528135397101

Epoch: 5| Step: 10
Training loss: 0.07957873493432999
Validation loss: 1.4652848435986427

Epoch: 531| Step: 0
Training loss: 0.11810477077960968
Validation loss: 1.4764814658831524

Epoch: 5| Step: 1
Training loss: 0.057753898203372955
Validation loss: 1.4736967894338793

Epoch: 5| Step: 2
Training loss: 0.1009598970413208
Validation loss: 1.480822164525268

Epoch: 5| Step: 3
Training loss: 0.14708667993545532
Validation loss: 1.502716782272503

Epoch: 5| Step: 4
Training loss: 0.22082439064979553
Validation loss: 1.5053535078161506

Epoch: 5| Step: 5
Training loss: 0.11217580735683441
Validation loss: 1.4939319523431922

Epoch: 5| Step: 6
Training loss: 0.2649253010749817
Validation loss: 1.48305526087361

Epoch: 5| Step: 7
Training loss: 0.21991518139839172
Validation loss: 1.4439422648440126

Epoch: 5| Step: 8
Training loss: 0.14188252389431
Validation loss: 1.4655879607764624

Epoch: 5| Step: 9
Training loss: 0.1282394975423813
Validation loss: 1.4905143681392874

Epoch: 5| Step: 10
Training loss: 0.11712012439966202
Validation loss: 1.529263368216894

Epoch: 532| Step: 0
Training loss: 0.21731850504875183
Validation loss: 1.535081954412563

Epoch: 5| Step: 1
Training loss: 0.14356806874275208
Validation loss: 1.538859014870018

Epoch: 5| Step: 2
Training loss: 0.10146912187337875
Validation loss: 1.5345455690096783

Epoch: 5| Step: 3
Training loss: 0.19461704790592194
Validation loss: 1.5500801955499957

Epoch: 5| Step: 4
Training loss: 0.12431025505065918
Validation loss: 1.4771657092596895

Epoch: 5| Step: 5
Training loss: 0.07799848169088364
Validation loss: 1.4424017552406556

Epoch: 5| Step: 6
Training loss: 0.1911439448595047
Validation loss: 1.4640476255006687

Epoch: 5| Step: 7
Training loss: 0.20132246613502502
Validation loss: 1.4685324097192416

Epoch: 5| Step: 8
Training loss: 0.2199222296476364
Validation loss: 1.4496540010616343

Epoch: 5| Step: 9
Training loss: 0.1514868587255478
Validation loss: 1.445269157809596

Epoch: 5| Step: 10
Training loss: 0.24412743747234344
Validation loss: 1.4545729660218762

Epoch: 533| Step: 0
Training loss: 0.21114447712898254
Validation loss: 1.4640232798873738

Epoch: 5| Step: 1
Training loss: 0.11615113168954849
Validation loss: 1.4949779997589767

Epoch: 5| Step: 2
Training loss: 0.18406616151332855
Validation loss: 1.5257209244594778

Epoch: 5| Step: 3
Training loss: 0.127657949924469
Validation loss: 1.5569305535285705

Epoch: 5| Step: 4
Training loss: 0.12296243011951447
Validation loss: 1.5550357564803092

Epoch: 5| Step: 5
Training loss: 0.1111418604850769
Validation loss: 1.5509905507487636

Epoch: 5| Step: 6
Training loss: 0.09973529726266861
Validation loss: 1.5235605188595351

Epoch: 5| Step: 7
Training loss: 0.23685941100120544
Validation loss: 1.4895185578253962

Epoch: 5| Step: 8
Training loss: 0.10353247076272964
Validation loss: 1.4810044086107643

Epoch: 5| Step: 9
Training loss: 0.16637925803661346
Validation loss: 1.4855212178281558

Epoch: 5| Step: 10
Training loss: 0.10147706419229507
Validation loss: 1.5081477998405375

Epoch: 534| Step: 0
Training loss: 0.142574280500412
Validation loss: 1.4762545856096412

Epoch: 5| Step: 1
Training loss: 0.10864055156707764
Validation loss: 1.470846296638571

Epoch: 5| Step: 2
Training loss: 0.11672966182231903
Validation loss: 1.4616410065722722

Epoch: 5| Step: 3
Training loss: 0.11825151741504669
Validation loss: 1.5090702220957766

Epoch: 5| Step: 4
Training loss: 0.09783744812011719
Validation loss: 1.5101330036758094

Epoch: 5| Step: 5
Training loss: 0.16274090111255646
Validation loss: 1.5307102100823515

Epoch: 5| Step: 6
Training loss: 0.2419334352016449
Validation loss: 1.5601622763500418

Epoch: 5| Step: 7
Training loss: 0.2012546956539154
Validation loss: 1.54681114099359

Epoch: 5| Step: 8
Training loss: 0.10601705312728882
Validation loss: 1.502708262012851

Epoch: 5| Step: 9
Training loss: 0.07458516955375671
Validation loss: 1.4908426884681947

Epoch: 5| Step: 10
Training loss: 0.12434768676757812
Validation loss: 1.4452212766934467

Epoch: 535| Step: 0
Training loss: 0.1592167317867279
Validation loss: 1.444986717675322

Epoch: 5| Step: 1
Training loss: 0.11227329075336456
Validation loss: 1.434426474314864

Epoch: 5| Step: 2
Training loss: 0.2186853140592575
Validation loss: 1.4366698623985372

Epoch: 5| Step: 3
Training loss: 0.17628373205661774
Validation loss: 1.4621397526033464

Epoch: 5| Step: 4
Training loss: 0.1191672533750534
Validation loss: 1.4662068992532709

Epoch: 5| Step: 5
Training loss: 0.0636223703622818
Validation loss: 1.4857012046280729

Epoch: 5| Step: 6
Training loss: 0.06967835128307343
Validation loss: 1.5096705998143842

Epoch: 5| Step: 7
Training loss: 0.12209092080593109
Validation loss: 1.5070820918647192

Epoch: 5| Step: 8
Training loss: 0.11784938722848892
Validation loss: 1.5535502324822128

Epoch: 5| Step: 9
Training loss: 0.11194787919521332
Validation loss: 1.5138251307190105

Epoch: 5| Step: 10
Training loss: 0.16001811623573303
Validation loss: 1.476332878553739

Epoch: 536| Step: 0
Training loss: 0.06425607204437256
Validation loss: 1.475466803837848

Epoch: 5| Step: 1
Training loss: 0.13025203347206116
Validation loss: 1.5185597737630208

Epoch: 5| Step: 2
Training loss: 0.143428236246109
Validation loss: 1.4800125527125534

Epoch: 5| Step: 3
Training loss: 0.16202208399772644
Validation loss: 1.4660394319923975

Epoch: 5| Step: 4
Training loss: 0.17775489389896393
Validation loss: 1.4698615535613029

Epoch: 5| Step: 5
Training loss: 0.09696756303310394
Validation loss: 1.4852570551697926

Epoch: 5| Step: 6
Training loss: 0.15881749987602234
Validation loss: 1.4940809562642088

Epoch: 5| Step: 7
Training loss: 0.23816034197807312
Validation loss: 1.5321739412123156

Epoch: 5| Step: 8
Training loss: 0.19240659475326538
Validation loss: 1.537427907348961

Epoch: 5| Step: 9
Training loss: 0.13727596402168274
Validation loss: 1.5230420494592318

Epoch: 5| Step: 10
Training loss: 0.10789566487073898
Validation loss: 1.5295027661067184

Epoch: 537| Step: 0
Training loss: 0.10297434031963348
Validation loss: 1.511460986188663

Epoch: 5| Step: 1
Training loss: 0.17787861824035645
Validation loss: 1.5185669660568237

Epoch: 5| Step: 2
Training loss: 0.13379013538360596
Validation loss: 1.5029651003499185

Epoch: 5| Step: 3
Training loss: 0.08969484269618988
Validation loss: 1.5151011174724949

Epoch: 5| Step: 4
Training loss: 0.13642525672912598
Validation loss: 1.4886977262394403

Epoch: 5| Step: 5
Training loss: 0.10053454339504242
Validation loss: 1.5033628466308757

Epoch: 5| Step: 6
Training loss: 0.11909262835979462
Validation loss: 1.4965747197469075

Epoch: 5| Step: 7
Training loss: 0.11879539489746094
Validation loss: 1.4949216137650192

Epoch: 5| Step: 8
Training loss: 0.2154923379421234
Validation loss: 1.5025057587572324

Epoch: 5| Step: 9
Training loss: 0.21871355175971985
Validation loss: 1.5260671800182712

Epoch: 5| Step: 10
Training loss: 0.08137207478284836
Validation loss: 1.536394279490235

Epoch: 538| Step: 0
Training loss: 0.13011662662029266
Validation loss: 1.536029714410023

Epoch: 5| Step: 1
Training loss: 0.19403593242168427
Validation loss: 1.5575344242075437

Epoch: 5| Step: 2
Training loss: 0.1432393491268158
Validation loss: 1.535298760219287

Epoch: 5| Step: 3
Training loss: 0.17383508384227753
Validation loss: 1.5223688489647322

Epoch: 5| Step: 4
Training loss: 0.1263379454612732
Validation loss: 1.482711342073256

Epoch: 5| Step: 5
Training loss: 0.14058469235897064
Validation loss: 1.5201875266208444

Epoch: 5| Step: 6
Training loss: 0.12300007045269012
Validation loss: 1.5121849518950268

Epoch: 5| Step: 7
Training loss: 0.1553749293088913
Validation loss: 1.518261803093777

Epoch: 5| Step: 8
Training loss: 0.1793021559715271
Validation loss: 1.5230059136626541

Epoch: 5| Step: 9
Training loss: 0.18138353526592255
Validation loss: 1.506194987604695

Epoch: 5| Step: 10
Training loss: 0.07030534744262695
Validation loss: 1.5092821275034258

Epoch: 539| Step: 0
Training loss: 0.17049886286258698
Validation loss: 1.5016257711636123

Epoch: 5| Step: 1
Training loss: 0.18653596937656403
Validation loss: 1.523885867928946

Epoch: 5| Step: 2
Training loss: 0.12227221578359604
Validation loss: 1.5274693504456551

Epoch: 5| Step: 3
Training loss: 0.07671372592449188
Validation loss: 1.5248239245466007

Epoch: 5| Step: 4
Training loss: 0.0669604241847992
Validation loss: 1.509306517980432

Epoch: 5| Step: 5
Training loss: 0.14428547024726868
Validation loss: 1.5164153755352061

Epoch: 5| Step: 6
Training loss: 0.17633147537708282
Validation loss: 1.4990815629241288

Epoch: 5| Step: 7
Training loss: 0.1403328776359558
Validation loss: 1.4860624074935913

Epoch: 5| Step: 8
Training loss: 0.182268425822258
Validation loss: 1.4803701575084398

Epoch: 5| Step: 9
Training loss: 0.10814603418111801
Validation loss: 1.4815749942615468

Epoch: 5| Step: 10
Training loss: 0.10839953273534775
Validation loss: 1.4448387545924033

Epoch: 540| Step: 0
Training loss: 0.09421078860759735
Validation loss: 1.4457096425435876

Epoch: 5| Step: 1
Training loss: 0.16188549995422363
Validation loss: 1.456897783023055

Epoch: 5| Step: 2
Training loss: 0.12020343542098999
Validation loss: 1.451953241902013

Epoch: 5| Step: 3
Training loss: 0.16259506344795227
Validation loss: 1.4505370118284737

Epoch: 5| Step: 4
Training loss: 0.10424284636974335
Validation loss: 1.4460436554365261

Epoch: 5| Step: 5
Training loss: 0.09795993566513062
Validation loss: 1.4792551520050212

Epoch: 5| Step: 6
Training loss: 0.1886616051197052
Validation loss: 1.46940291056069

Epoch: 5| Step: 7
Training loss: 0.09584473818540573
Validation loss: 1.499290608590649

Epoch: 5| Step: 8
Training loss: 0.06418891251087189
Validation loss: 1.5273295448672386

Epoch: 5| Step: 9
Training loss: 0.15761896967887878
Validation loss: 1.5169929714613064

Epoch: 5| Step: 10
Training loss: 0.131430983543396
Validation loss: 1.5463773409525554

Epoch: 541| Step: 0
Training loss: 0.2026783972978592
Validation loss: 1.5525980354637228

Epoch: 5| Step: 1
Training loss: 0.08668404817581177
Validation loss: 1.527175752065515

Epoch: 5| Step: 2
Training loss: 0.13099715113639832
Validation loss: 1.5149587110806537

Epoch: 5| Step: 3
Training loss: 0.13897904753684998
Validation loss: 1.5037529750536847

Epoch: 5| Step: 4
Training loss: 0.13711626827716827
Validation loss: 1.509775415543587

Epoch: 5| Step: 5
Training loss: 0.08930718153715134
Validation loss: 1.486590168809378

Epoch: 5| Step: 6
Training loss: 0.1834217607975006
Validation loss: 1.5219742405799128

Epoch: 5| Step: 7
Training loss: 0.1468183994293213
Validation loss: 1.523222638714698

Epoch: 5| Step: 8
Training loss: 0.1376105695962906
Validation loss: 1.5457960328748148

Epoch: 5| Step: 9
Training loss: 0.1780565083026886
Validation loss: 1.532834723431577

Epoch: 5| Step: 10
Training loss: 0.14201036095619202
Validation loss: 1.5259903733448317

Epoch: 542| Step: 0
Training loss: 0.1769917756319046
Validation loss: 1.5117870043682795

Epoch: 5| Step: 1
Training loss: 0.13626430928707123
Validation loss: 1.5150771102597635

Epoch: 5| Step: 2
Training loss: 0.12531423568725586
Validation loss: 1.5138136045907133

Epoch: 5| Step: 3
Training loss: 0.13499003648757935
Validation loss: 1.5031897252605808

Epoch: 5| Step: 4
Training loss: 0.07462085783481598
Validation loss: 1.516590795209331

Epoch: 5| Step: 5
Training loss: 0.0865965187549591
Validation loss: 1.5344286990422074

Epoch: 5| Step: 6
Training loss: 0.11862655729055405
Validation loss: 1.5230399088193012

Epoch: 5| Step: 7
Training loss: 0.12302915006875992
Validation loss: 1.5198807280550721

Epoch: 5| Step: 8
Training loss: 0.16782082617282867
Validation loss: 1.5622045532349618

Epoch: 5| Step: 9
Training loss: 0.13018402457237244
Validation loss: 1.5111240840727282

Epoch: 5| Step: 10
Training loss: 0.21830356121063232
Validation loss: 1.5037929358020905

Epoch: 543| Step: 0
Training loss: 0.11917799711227417
Validation loss: 1.4900973278989074

Epoch: 5| Step: 1
Training loss: 0.1852317899465561
Validation loss: 1.4868398110071819

Epoch: 5| Step: 2
Training loss: 0.09264607727527618
Validation loss: 1.488818399367794

Epoch: 5| Step: 3
Training loss: 0.1512395590543747
Validation loss: 1.514685623107418

Epoch: 5| Step: 4
Training loss: 0.05966565012931824
Validation loss: 1.5172454278956178

Epoch: 5| Step: 5
Training loss: 0.1336410641670227
Validation loss: 1.5057102672515377

Epoch: 5| Step: 6
Training loss: 0.07257027924060822
Validation loss: 1.5189273870119484

Epoch: 5| Step: 7
Training loss: 0.1129315048456192
Validation loss: 1.5236979735794889

Epoch: 5| Step: 8
Training loss: 0.1647627204656601
Validation loss: 1.5134398437315417

Epoch: 5| Step: 9
Training loss: 0.0994904413819313
Validation loss: 1.5284355904466362

Epoch: 5| Step: 10
Training loss: 0.1362505406141281
Validation loss: 1.5265362608817317

Epoch: 544| Step: 0
Training loss: 0.10005543380975723
Validation loss: 1.5219165766110985

Epoch: 5| Step: 1
Training loss: 0.1431518793106079
Validation loss: 1.492199823420535

Epoch: 5| Step: 2
Training loss: 0.1594218909740448
Validation loss: 1.508440544528346

Epoch: 5| Step: 3
Training loss: 0.09700804948806763
Validation loss: 1.487799495779058

Epoch: 5| Step: 4
Training loss: 0.15845909714698792
Validation loss: 1.4683108099045292

Epoch: 5| Step: 5
Training loss: 0.07131986320018768
Validation loss: 1.4638926072787213

Epoch: 5| Step: 6
Training loss: 0.10393282026052475
Validation loss: 1.4831528073997908

Epoch: 5| Step: 7
Training loss: 0.17067702114582062
Validation loss: 1.5184098174495082

Epoch: 5| Step: 8
Training loss: 0.09123264253139496
Validation loss: 1.531798965187483

Epoch: 5| Step: 9
Training loss: 0.13629940152168274
Validation loss: 1.5100096925612418

Epoch: 5| Step: 10
Training loss: 0.06770458072423935
Validation loss: 1.5028483354917137

Epoch: 545| Step: 0
Training loss: 0.07675357162952423
Validation loss: 1.485186722970778

Epoch: 5| Step: 1
Training loss: 0.15323586761951447
Validation loss: 1.4687120017185007

Epoch: 5| Step: 2
Training loss: 0.19781938195228577
Validation loss: 1.476330203394736

Epoch: 5| Step: 3
Training loss: 0.1253339797258377
Validation loss: 1.5069617334232535

Epoch: 5| Step: 4
Training loss: 0.1620236039161682
Validation loss: 1.4703596561185774

Epoch: 5| Step: 5
Training loss: 0.06676974147558212
Validation loss: 1.4796248212937386

Epoch: 5| Step: 6
Training loss: 0.07578442245721817
Validation loss: 1.5180303588990243

Epoch: 5| Step: 7
Training loss: 0.08121044933795929
Validation loss: 1.4969306556127404

Epoch: 5| Step: 8
Training loss: 0.12551388144493103
Validation loss: 1.4735535049951205

Epoch: 5| Step: 9
Training loss: 0.13488301634788513
Validation loss: 1.4777939114519345

Epoch: 5| Step: 10
Training loss: 0.06414564698934555
Validation loss: 1.4542247800416843

Epoch: 546| Step: 0
Training loss: 0.08806624263525009
Validation loss: 1.476022187099662

Epoch: 5| Step: 1
Training loss: 0.07909151911735535
Validation loss: 1.429673574304068

Epoch: 5| Step: 2
Training loss: 0.09901414811611176
Validation loss: 1.416373698942123

Epoch: 5| Step: 3
Training loss: 0.2263542115688324
Validation loss: 1.428777455001749

Epoch: 5| Step: 4
Training loss: 0.09600049257278442
Validation loss: 1.4368500286532986

Epoch: 5| Step: 5
Training loss: 0.10787294059991837
Validation loss: 1.419720729192098

Epoch: 5| Step: 6
Training loss: 0.10846631228923798
Validation loss: 1.4518532291535409

Epoch: 5| Step: 7
Training loss: 0.20547223091125488
Validation loss: 1.4681333572633806

Epoch: 5| Step: 8
Training loss: 0.09041173756122589
Validation loss: 1.4496254126230876

Epoch: 5| Step: 9
Training loss: 0.10652676969766617
Validation loss: 1.475071382138037

Epoch: 5| Step: 10
Training loss: 0.08216459304094315
Validation loss: 1.481783764336699

Epoch: 547| Step: 0
Training loss: 0.09574851393699646
Validation loss: 1.4846704570196008

Epoch: 5| Step: 1
Training loss: 0.10315652191638947
Validation loss: 1.4611347080558859

Epoch: 5| Step: 2
Training loss: 0.1538209170103073
Validation loss: 1.4961333544023576

Epoch: 5| Step: 3
Training loss: 0.09074760228395462
Validation loss: 1.5033421542054863

Epoch: 5| Step: 4
Training loss: 0.20160356163978577
Validation loss: 1.5310380945923507

Epoch: 5| Step: 5
Training loss: 0.11192377656698227
Validation loss: 1.4823084928656136

Epoch: 5| Step: 6
Training loss: 0.07982555776834488
Validation loss: 1.4722922361025246

Epoch: 5| Step: 7
Training loss: 0.10019759833812714
Validation loss: 1.4722616775061494

Epoch: 5| Step: 8
Training loss: 0.050610460340976715
Validation loss: 1.4464915208919074

Epoch: 5| Step: 9
Training loss: 0.13080467283725739
Validation loss: 1.4913199101724932

Epoch: 5| Step: 10
Training loss: 0.12656904757022858
Validation loss: 1.519993902534567

Epoch: 548| Step: 0
Training loss: 0.2182551920413971
Validation loss: 1.5137679935783468

Epoch: 5| Step: 1
Training loss: 0.08100765943527222
Validation loss: 1.5095191335165372

Epoch: 5| Step: 2
Training loss: 0.08583646267652512
Validation loss: 1.49805990470353

Epoch: 5| Step: 3
Training loss: 0.055972062051296234
Validation loss: 1.5030957998767975

Epoch: 5| Step: 4
Training loss: 0.0782763808965683
Validation loss: 1.5079178233300485

Epoch: 5| Step: 5
Training loss: 0.09084294736385345
Validation loss: 1.5129733649633264

Epoch: 5| Step: 6
Training loss: 0.13801711797714233
Validation loss: 1.5258324915362942

Epoch: 5| Step: 7
Training loss: 0.1976521611213684
Validation loss: 1.505178257983218

Epoch: 5| Step: 8
Training loss: 0.05663306638598442
Validation loss: 1.4823149429854525

Epoch: 5| Step: 9
Training loss: 0.08319675922393799
Validation loss: 1.463497213138047

Epoch: 5| Step: 10
Training loss: 0.17359144985675812
Validation loss: 1.4364585427827732

Epoch: 549| Step: 0
Training loss: 0.13158254325389862
Validation loss: 1.4276786747799124

Epoch: 5| Step: 1
Training loss: 0.20750722289085388
Validation loss: 1.4649579524993896

Epoch: 5| Step: 2
Training loss: 0.15947289764881134
Validation loss: 1.4208397326930877

Epoch: 5| Step: 3
Training loss: 0.11847801506519318
Validation loss: 1.4422531076656875

Epoch: 5| Step: 4
Training loss: 0.12369395792484283
Validation loss: 1.475124365539961

Epoch: 5| Step: 5
Training loss: 0.2011515349149704
Validation loss: 1.4749495316577215

Epoch: 5| Step: 6
Training loss: 0.11678309738636017
Validation loss: 1.4969151866051458

Epoch: 5| Step: 7
Training loss: 0.07501987367868423
Validation loss: 1.5251361375213952

Epoch: 5| Step: 8
Training loss: 0.10904949903488159
Validation loss: 1.5189554383677821

Epoch: 5| Step: 9
Training loss: 0.16856130957603455
Validation loss: 1.5212223734906924

Epoch: 5| Step: 10
Training loss: 0.09251075983047485
Validation loss: 1.507107497543417

Epoch: 550| Step: 0
Training loss: 0.15852344036102295
Validation loss: 1.4898428647748885

Epoch: 5| Step: 1
Training loss: 0.1314575970172882
Validation loss: 1.4650323954961633

Epoch: 5| Step: 2
Training loss: 0.14404727518558502
Validation loss: 1.4321961223438222

Epoch: 5| Step: 3
Training loss: 0.11612961441278458
Validation loss: 1.4378686105051348

Epoch: 5| Step: 4
Training loss: 0.10493411868810654
Validation loss: 1.4700335661570232

Epoch: 5| Step: 5
Training loss: 0.14645852148532867
Validation loss: 1.4647351926372898

Epoch: 5| Step: 6
Training loss: 0.07894184440374374
Validation loss: 1.4719998195607176

Epoch: 5| Step: 7
Training loss: 0.14948244392871857
Validation loss: 1.4620706432609147

Epoch: 5| Step: 8
Training loss: 0.07200022041797638
Validation loss: 1.457250359237835

Epoch: 5| Step: 9
Training loss: 0.12471707910299301
Validation loss: 1.4539341272846344

Epoch: 5| Step: 10
Training loss: 0.07467763125896454
Validation loss: 1.4781773474908644

Epoch: 551| Step: 0
Training loss: 0.13248826563358307
Validation loss: 1.450796200383094

Epoch: 5| Step: 1
Training loss: 0.0819973349571228
Validation loss: 1.4624191740507722

Epoch: 5| Step: 2
Training loss: 0.12210261821746826
Validation loss: 1.4480832071714504

Epoch: 5| Step: 3
Training loss: 0.07296578586101532
Validation loss: 1.502648090803495

Epoch: 5| Step: 4
Training loss: 0.14104397594928741
Validation loss: 1.4969441384397528

Epoch: 5| Step: 5
Training loss: 0.1110551729798317
Validation loss: 1.463632091399162

Epoch: 5| Step: 6
Training loss: 0.11117058992385864
Validation loss: 1.4720879036893126

Epoch: 5| Step: 7
Training loss: 0.0888945609331131
Validation loss: 1.4729962169483144

Epoch: 5| Step: 8
Training loss: 0.15810681879520416
Validation loss: 1.4759042686031711

Epoch: 5| Step: 9
Training loss: 0.10844403505325317
Validation loss: 1.4738459535824355

Epoch: 5| Step: 10
Training loss: 0.09853547066450119
Validation loss: 1.4744706064142206

Epoch: 552| Step: 0
Training loss: 0.10580752044916153
Validation loss: 1.4799390890265023

Epoch: 5| Step: 1
Training loss: 0.10597946494817734
Validation loss: 1.5064232246850127

Epoch: 5| Step: 2
Training loss: 0.10344121605157852
Validation loss: 1.5058758451092629

Epoch: 5| Step: 3
Training loss: 0.11817300319671631
Validation loss: 1.5049963330709806

Epoch: 5| Step: 4
Training loss: 0.06545789539813995
Validation loss: 1.4905593061959872

Epoch: 5| Step: 5
Training loss: 0.14250916242599487
Validation loss: 1.4936243731488463

Epoch: 5| Step: 6
Training loss: 0.0938086286187172
Validation loss: 1.4786664119330786

Epoch: 5| Step: 7
Training loss: 0.17693991959095
Validation loss: 1.465952177842458

Epoch: 5| Step: 8
Training loss: 0.09015338122844696
Validation loss: 1.4496449924284411

Epoch: 5| Step: 9
Training loss: 0.10127103328704834
Validation loss: 1.4515143235524495

Epoch: 5| Step: 10
Training loss: 0.08731993287801743
Validation loss: 1.461617583869606

Epoch: 553| Step: 0
Training loss: 0.10722758620977402
Validation loss: 1.459316679226455

Epoch: 5| Step: 1
Training loss: 0.08493489027023315
Validation loss: 1.4826988955979705

Epoch: 5| Step: 2
Training loss: 0.19576314091682434
Validation loss: 1.495956677262501

Epoch: 5| Step: 3
Training loss: 0.1859026551246643
Validation loss: 1.4980863012293333

Epoch: 5| Step: 4
Training loss: 0.13390414416790009
Validation loss: 1.5115738004766486

Epoch: 5| Step: 5
Training loss: 0.07935263216495514
Validation loss: 1.5341150241513406

Epoch: 5| Step: 6
Training loss: 0.12736980617046356
Validation loss: 1.5415034255673807

Epoch: 5| Step: 7
Training loss: 0.13498029112815857
Validation loss: 1.5464725891749065

Epoch: 5| Step: 8
Training loss: 0.06917442381381989
Validation loss: 1.5084712812977452

Epoch: 5| Step: 9
Training loss: 0.1133187860250473
Validation loss: 1.4950181181712816

Epoch: 5| Step: 10
Training loss: 0.06089728698134422
Validation loss: 1.4882262675992903

Epoch: 554| Step: 0
Training loss: 0.06502829492092133
Validation loss: 1.5325496760747765

Epoch: 5| Step: 1
Training loss: 0.11935076862573624
Validation loss: 1.500637718426284

Epoch: 5| Step: 2
Training loss: 0.1360909640789032
Validation loss: 1.498393089540543

Epoch: 5| Step: 3
Training loss: 0.17275328934192657
Validation loss: 1.5292129849874845

Epoch: 5| Step: 4
Training loss: 0.15203401446342468
Validation loss: 1.5251681362428973

Epoch: 5| Step: 5
Training loss: 0.09366248548030853
Validation loss: 1.5498786792960217

Epoch: 5| Step: 6
Training loss: 0.14074474573135376
Validation loss: 1.5549112109727756

Epoch: 5| Step: 7
Training loss: 0.09479500353336334
Validation loss: 1.5418189161567277

Epoch: 5| Step: 8
Training loss: 0.09931521117687225
Validation loss: 1.5438322533843338

Epoch: 5| Step: 9
Training loss: 0.10807047039270401
Validation loss: 1.5411492855318132

Epoch: 5| Step: 10
Training loss: 0.11479994654655457
Validation loss: 1.498341046353822

Epoch: 555| Step: 0
Training loss: 0.07847676426172256
Validation loss: 1.511219161812977

Epoch: 5| Step: 1
Training loss: 0.09724054485559464
Validation loss: 1.4597437292016961

Epoch: 5| Step: 2
Training loss: 0.1019824743270874
Validation loss: 1.446260425352281

Epoch: 5| Step: 3
Training loss: 0.10814808309078217
Validation loss: 1.455697323686333

Epoch: 5| Step: 4
Training loss: 0.11291418224573135
Validation loss: 1.4344452863098474

Epoch: 5| Step: 5
Training loss: 0.13664206862449646
Validation loss: 1.492877378258654

Epoch: 5| Step: 6
Training loss: 0.1610516756772995
Validation loss: 1.5011352589053493

Epoch: 5| Step: 7
Training loss: 0.11026358604431152
Validation loss: 1.5264761332542665

Epoch: 5| Step: 8
Training loss: 0.12536390125751495
Validation loss: 1.4954857569868847

Epoch: 5| Step: 9
Training loss: 0.14621272683143616
Validation loss: 1.482705714882061

Epoch: 5| Step: 10
Training loss: 0.1050790473818779
Validation loss: 1.5005876665474267

Epoch: 556| Step: 0
Training loss: 0.0800669938325882
Validation loss: 1.4817421474764425

Epoch: 5| Step: 1
Training loss: 0.1394982635974884
Validation loss: 1.4910903489717873

Epoch: 5| Step: 2
Training loss: 0.10636782646179199
Validation loss: 1.4815723896026611

Epoch: 5| Step: 3
Training loss: 0.11231372505426407
Validation loss: 1.503754513238066

Epoch: 5| Step: 4
Training loss: 0.06906662881374359
Validation loss: 1.4996489068513275

Epoch: 5| Step: 5
Training loss: 0.08325396478176117
Validation loss: 1.505549382137996

Epoch: 5| Step: 6
Training loss: 0.07052838802337646
Validation loss: 1.5054438088529853

Epoch: 5| Step: 7
Training loss: 0.11523673683404922
Validation loss: 1.4921942846749419

Epoch: 5| Step: 8
Training loss: 0.08564849942922592
Validation loss: 1.508337624611393

Epoch: 5| Step: 9
Training loss: 0.09367519617080688
Validation loss: 1.5350950264161634

Epoch: 5| Step: 10
Training loss: 0.16991567611694336
Validation loss: 1.5002354960287771

Epoch: 557| Step: 0
Training loss: 0.07388230413198471
Validation loss: 1.4973175397483252

Epoch: 5| Step: 1
Training loss: 0.11826629936695099
Validation loss: 1.5023633767199773

Epoch: 5| Step: 2
Training loss: 0.08120184391736984
Validation loss: 1.5188135953359707

Epoch: 5| Step: 3
Training loss: 0.12241361290216446
Validation loss: 1.4854890454200007

Epoch: 5| Step: 4
Training loss: 0.05775228887796402
Validation loss: 1.4785614346945157

Epoch: 5| Step: 5
Training loss: 0.053750865161418915
Validation loss: 1.4759196440378826

Epoch: 5| Step: 6
Training loss: 0.20041628181934357
Validation loss: 1.4588271020561137

Epoch: 5| Step: 7
Training loss: 0.11196102201938629
Validation loss: 1.474658340536138

Epoch: 5| Step: 8
Training loss: 0.05790024995803833
Validation loss: 1.4566871068810905

Epoch: 5| Step: 9
Training loss: 0.13456428050994873
Validation loss: 1.4689412437459475

Epoch: 5| Step: 10
Training loss: 0.08119333535432816
Validation loss: 1.483859714641366

Epoch: 558| Step: 0
Training loss: 0.08342141658067703
Validation loss: 1.4893366156085845

Epoch: 5| Step: 1
Training loss: 0.12304683774709702
Validation loss: 1.5105548007513887

Epoch: 5| Step: 2
Training loss: 0.07597880065441132
Validation loss: 1.524519278157142

Epoch: 5| Step: 3
Training loss: 0.11930620670318604
Validation loss: 1.5094332707825528

Epoch: 5| Step: 4
Training loss: 0.09036047011613846
Validation loss: 1.5063395589910529

Epoch: 5| Step: 5
Training loss: 0.15602104365825653
Validation loss: 1.5206403117026053

Epoch: 5| Step: 6
Training loss: 0.06247200816869736
Validation loss: 1.5011450577807683

Epoch: 5| Step: 7
Training loss: 0.09864839911460876
Validation loss: 1.4842040538787842

Epoch: 5| Step: 8
Training loss: 0.10333301872015
Validation loss: 1.483220903463261

Epoch: 5| Step: 9
Training loss: 0.08438970893621445
Validation loss: 1.5059910153829923

Epoch: 5| Step: 10
Training loss: 0.08991244435310364
Validation loss: 1.4704056734679847

Epoch: 559| Step: 0
Training loss: 0.1171998530626297
Validation loss: 1.462673137264867

Epoch: 5| Step: 1
Training loss: 0.07063784450292587
Validation loss: 1.4673179477773688

Epoch: 5| Step: 2
Training loss: 0.12359479814767838
Validation loss: 1.4562283074983986

Epoch: 5| Step: 3
Training loss: 0.08575143665075302
Validation loss: 1.4566380054719987

Epoch: 5| Step: 4
Training loss: 0.0891345739364624
Validation loss: 1.431780222923525

Epoch: 5| Step: 5
Training loss: 0.10538627952337265
Validation loss: 1.4535074336554414

Epoch: 5| Step: 6
Training loss: 0.19140024483203888
Validation loss: 1.435121883628189

Epoch: 5| Step: 7
Training loss: 0.06224268674850464
Validation loss: 1.4837543297839422

Epoch: 5| Step: 8
Training loss: 0.1099490374326706
Validation loss: 1.4669215486895653

Epoch: 5| Step: 9
Training loss: 0.06245114654302597
Validation loss: 1.4473567162790606

Epoch: 5| Step: 10
Training loss: 0.08969152718782425
Validation loss: 1.4660967434606245

Epoch: 560| Step: 0
Training loss: 0.13784046471118927
Validation loss: 1.483112560805454

Epoch: 5| Step: 1
Training loss: 0.08879072964191437
Validation loss: 1.5152852458338584

Epoch: 5| Step: 2
Training loss: 0.12254936993122101
Validation loss: 1.520965685126602

Epoch: 5| Step: 3
Training loss: 0.10254925489425659
Validation loss: 1.4694809887998848

Epoch: 5| Step: 4
Training loss: 0.10808044672012329
Validation loss: 1.4818165392004035

Epoch: 5| Step: 5
Training loss: 0.10379338264465332
Validation loss: 1.4567481189645746

Epoch: 5| Step: 6
Training loss: 0.11235501617193222
Validation loss: 1.4633296189769622

Epoch: 5| Step: 7
Training loss: 0.10770072042942047
Validation loss: 1.455416855632618

Epoch: 5| Step: 8
Training loss: 0.0937921330332756
Validation loss: 1.4742827735921389

Epoch: 5| Step: 9
Training loss: 0.17092081904411316
Validation loss: 1.458693459469785

Epoch: 5| Step: 10
Training loss: 0.1204085648059845
Validation loss: 1.4722814207435937

Epoch: 561| Step: 0
Training loss: 0.07582635432481766
Validation loss: 1.4856785189720891

Epoch: 5| Step: 1
Training loss: 0.11904869973659515
Validation loss: 1.5051142284947057

Epoch: 5| Step: 2
Training loss: 0.08460290729999542
Validation loss: 1.4802911973768664

Epoch: 5| Step: 3
Training loss: 0.11188945919275284
Validation loss: 1.5166321544237034

Epoch: 5| Step: 4
Training loss: 0.1987413913011551
Validation loss: 1.5057366932592084

Epoch: 5| Step: 5
Training loss: 0.11637508869171143
Validation loss: 1.499242897315692

Epoch: 5| Step: 6
Training loss: 0.08845050632953644
Validation loss: 1.499382980408207

Epoch: 5| Step: 7
Training loss: 0.15552890300750732
Validation loss: 1.4835679697734054

Epoch: 5| Step: 8
Training loss: 0.06557813286781311
Validation loss: 1.4707577965592826

Epoch: 5| Step: 9
Training loss: 0.05409984663128853
Validation loss: 1.4700158155092629

Epoch: 5| Step: 10
Training loss: 0.18321537971496582
Validation loss: 1.4637610655958935

Epoch: 562| Step: 0
Training loss: 0.12761853635311127
Validation loss: 1.46717934326459

Epoch: 5| Step: 1
Training loss: 0.10440389066934586
Validation loss: 1.4605023053384596

Epoch: 5| Step: 2
Training loss: 0.07415131479501724
Validation loss: 1.47687921344593

Epoch: 5| Step: 3
Training loss: 0.10183529555797577
Validation loss: 1.5044142353919245

Epoch: 5| Step: 4
Training loss: 0.10075054317712784
Validation loss: 1.5069301557797257

Epoch: 5| Step: 5
Training loss: 0.06898616254329681
Validation loss: 1.502366127506379

Epoch: 5| Step: 6
Training loss: 0.09054990857839584
Validation loss: 1.497025607093688

Epoch: 5| Step: 7
Training loss: 0.12066322565078735
Validation loss: 1.5429846894356511

Epoch: 5| Step: 8
Training loss: 0.1944739818572998
Validation loss: 1.5739521749557988

Epoch: 5| Step: 9
Training loss: 0.14257992804050446
Validation loss: 1.5760218712591356

Epoch: 5| Step: 10
Training loss: 0.07420614361763
Validation loss: 1.546443498262795

Epoch: 563| Step: 0
Training loss: 0.11282654106616974
Validation loss: 1.5089489695846394

Epoch: 5| Step: 1
Training loss: 0.1321849524974823
Validation loss: 1.4926331402153097

Epoch: 5| Step: 2
Training loss: 0.07809285074472427
Validation loss: 1.489710283535783

Epoch: 5| Step: 3
Training loss: 0.0937136858701706
Validation loss: 1.4892298149806198

Epoch: 5| Step: 4
Training loss: 0.062772735953331
Validation loss: 1.474040537752131

Epoch: 5| Step: 5
Training loss: 0.05984324961900711
Validation loss: 1.5188010841287591

Epoch: 5| Step: 6
Training loss: 0.11346180737018585
Validation loss: 1.5159416275639688

Epoch: 5| Step: 7
Training loss: 0.13841930031776428
Validation loss: 1.4929161507596251

Epoch: 5| Step: 8
Training loss: 0.1607731729745865
Validation loss: 1.5142053929708337

Epoch: 5| Step: 9
Training loss: 0.07871123403310776
Validation loss: 1.5216907224347513

Epoch: 5| Step: 10
Training loss: 0.04785584285855293
Validation loss: 1.4991743769696964

Epoch: 564| Step: 0
Training loss: 0.057496558874845505
Validation loss: 1.5031168922301261

Epoch: 5| Step: 1
Training loss: 0.10869872570037842
Validation loss: 1.4843319052009172

Epoch: 5| Step: 2
Training loss: 0.07480020821094513
Validation loss: 1.495399655834321

Epoch: 5| Step: 3
Training loss: 0.15908876061439514
Validation loss: 1.5239530173681115

Epoch: 5| Step: 4
Training loss: 0.05599726364016533
Validation loss: 1.4824187255674792

Epoch: 5| Step: 5
Training loss: 0.10526087135076523
Validation loss: 1.5146007063568279

Epoch: 5| Step: 6
Training loss: 0.13682019710540771
Validation loss: 1.5017554067796277

Epoch: 5| Step: 7
Training loss: 0.10432174056768417
Validation loss: 1.5172685269386537

Epoch: 5| Step: 8
Training loss: 0.07287542521953583
Validation loss: 1.536426955653775

Epoch: 5| Step: 9
Training loss: 0.10182879120111465
Validation loss: 1.516842242210142

Epoch: 5| Step: 10
Training loss: 0.12834598124027252
Validation loss: 1.4955875873565674

Epoch: 565| Step: 0
Training loss: 0.07808075100183487
Validation loss: 1.4886809010659494

Epoch: 5| Step: 1
Training loss: 0.2409439980983734
Validation loss: 1.458293225175591

Epoch: 5| Step: 2
Training loss: 0.0923844650387764
Validation loss: 1.475871321975544

Epoch: 5| Step: 3
Training loss: 0.07388560473918915
Validation loss: 1.4681840276205411

Epoch: 5| Step: 4
Training loss: 0.04922722280025482
Validation loss: 1.4473070572781306

Epoch: 5| Step: 5
Training loss: 0.09038706123828888
Validation loss: 1.4422712896459846

Epoch: 5| Step: 6
Training loss: 0.07726742327213287
Validation loss: 1.4361353305078322

Epoch: 5| Step: 7
Training loss: 0.10704901069402695
Validation loss: 1.4357096841258388

Epoch: 5| Step: 8
Training loss: 0.057987481355667114
Validation loss: 1.4601919766395324

Epoch: 5| Step: 9
Training loss: 0.061225809156894684
Validation loss: 1.4475390744465653

Epoch: 5| Step: 10
Training loss: 0.07644529640674591
Validation loss: 1.4420444356497897

Epoch: 566| Step: 0
Training loss: 0.05613048002123833
Validation loss: 1.4592487350586922

Epoch: 5| Step: 1
Training loss: 0.06445874273777008
Validation loss: 1.4708108991704962

Epoch: 5| Step: 2
Training loss: 0.11452677100896835
Validation loss: 1.4794603214469007

Epoch: 5| Step: 3
Training loss: 0.07247177511453629
Validation loss: 1.4682460190147482

Epoch: 5| Step: 4
Training loss: 0.12522149085998535
Validation loss: 1.4553120450306964

Epoch: 5| Step: 5
Training loss: 0.09563414752483368
Validation loss: 1.5005723199536722

Epoch: 5| Step: 6
Training loss: 0.12401499599218369
Validation loss: 1.484955676781234

Epoch: 5| Step: 7
Training loss: 0.12865908443927765
Validation loss: 1.4988749527162122

Epoch: 5| Step: 8
Training loss: 0.07589440792798996
Validation loss: 1.504236710968838

Epoch: 5| Step: 9
Training loss: 0.16005170345306396
Validation loss: 1.4920794425472137

Epoch: 5| Step: 10
Training loss: 0.14200131595134735
Validation loss: 1.5009268624808199

Epoch: 567| Step: 0
Training loss: 0.058764755725860596
Validation loss: 1.497963466951924

Epoch: 5| Step: 1
Training loss: 0.10554303973913193
Validation loss: 1.522424058247638

Epoch: 5| Step: 2
Training loss: 0.08524762094020844
Validation loss: 1.5164277617649367

Epoch: 5| Step: 3
Training loss: 0.1738431304693222
Validation loss: 1.4692315388751287

Epoch: 5| Step: 4
Training loss: 0.08214908838272095
Validation loss: 1.454521539390728

Epoch: 5| Step: 5
Training loss: 0.09996838867664337
Validation loss: 1.4736698558253627

Epoch: 5| Step: 6
Training loss: 0.14061662554740906
Validation loss: 1.487691249898685

Epoch: 5| Step: 7
Training loss: 0.07184382528066635
Validation loss: 1.4504448495885378

Epoch: 5| Step: 8
Training loss: 0.04010745510458946
Validation loss: 1.453017432202575

Epoch: 5| Step: 9
Training loss: 0.1534605324268341
Validation loss: 1.4712757564360095

Epoch: 5| Step: 10
Training loss: 0.1333359330892563
Validation loss: 1.4467268836113714

Epoch: 568| Step: 0
Training loss: 0.10154758393764496
Validation loss: 1.4322131256903372

Epoch: 5| Step: 1
Training loss: 0.16167430579662323
Validation loss: 1.4426873127619426

Epoch: 5| Step: 2
Training loss: 0.06624244153499603
Validation loss: 1.4390445857919671

Epoch: 5| Step: 3
Training loss: 0.07499495893716812
Validation loss: 1.4301309444571053

Epoch: 5| Step: 4
Training loss: 0.09009525924921036
Validation loss: 1.450001827491227

Epoch: 5| Step: 5
Training loss: 0.10628421604633331
Validation loss: 1.439009794624903

Epoch: 5| Step: 6
Training loss: 0.0832480937242508
Validation loss: 1.4282502153868317

Epoch: 5| Step: 7
Training loss: 0.0631251335144043
Validation loss: 1.4637525754590188

Epoch: 5| Step: 8
Training loss: 0.08291790634393692
Validation loss: 1.4404815845592047

Epoch: 5| Step: 9
Training loss: 0.15983863174915314
Validation loss: 1.4609331546291229

Epoch: 5| Step: 10
Training loss: 0.10142533481121063
Validation loss: 1.4733150556523313

Epoch: 569| Step: 0
Training loss: 0.13694551587104797
Validation loss: 1.4533608113565752

Epoch: 5| Step: 1
Training loss: 0.10658128559589386
Validation loss: 1.4831599074025308

Epoch: 5| Step: 2
Training loss: 0.07867240905761719
Validation loss: 1.4788410740513955

Epoch: 5| Step: 3
Training loss: 0.13149955868721008
Validation loss: 1.4990476600585445

Epoch: 5| Step: 4
Training loss: 0.12898722290992737
Validation loss: 1.5006331525823122

Epoch: 5| Step: 5
Training loss: 0.09508765488862991
Validation loss: 1.5104141965989144

Epoch: 5| Step: 6
Training loss: 0.18257543444633484
Validation loss: 1.5021736724402315

Epoch: 5| Step: 7
Training loss: 0.08492650836706161
Validation loss: 1.490223108440317

Epoch: 5| Step: 8
Training loss: 0.051401108503341675
Validation loss: 1.4683022076083767

Epoch: 5| Step: 9
Training loss: 0.08134486526250839
Validation loss: 1.4749350631108848

Epoch: 5| Step: 10
Training loss: 0.10851184278726578
Validation loss: 1.4856831104524675

Epoch: 570| Step: 0
Training loss: 0.06425431370735168
Validation loss: 1.4799743634398266

Epoch: 5| Step: 1
Training loss: 0.110958531498909
Validation loss: 1.477378611923546

Epoch: 5| Step: 2
Training loss: 0.10321813821792603
Validation loss: 1.4806430634631906

Epoch: 5| Step: 3
Training loss: 0.0938238799571991
Validation loss: 1.4167100550026022

Epoch: 5| Step: 4
Training loss: 0.1665971428155899
Validation loss: 1.4521492591468237

Epoch: 5| Step: 5
Training loss: 0.11117474734783173
Validation loss: 1.4535274262069373

Epoch: 5| Step: 6
Training loss: 0.10275836288928986
Validation loss: 1.4705461302111227

Epoch: 5| Step: 7
Training loss: 0.1548197716474533
Validation loss: 1.4800656046918643

Epoch: 5| Step: 8
Training loss: 0.05814053863286972
Validation loss: 1.465353718367956

Epoch: 5| Step: 9
Training loss: 0.05499369651079178
Validation loss: 1.4675973282065442

Epoch: 5| Step: 10
Training loss: 0.1343175768852234
Validation loss: 1.4640597669027184

Epoch: 571| Step: 0
Training loss: 0.1402788758277893
Validation loss: 1.450360010388077

Epoch: 5| Step: 1
Training loss: 0.08503151684999466
Validation loss: 1.4582227032671693

Epoch: 5| Step: 2
Training loss: 0.10394127666950226
Validation loss: 1.4463699543347923

Epoch: 5| Step: 3
Training loss: 0.09515590965747833
Validation loss: 1.4501538808627794

Epoch: 5| Step: 4
Training loss: 0.11524447053670883
Validation loss: 1.4489182951629802

Epoch: 5| Step: 5
Training loss: 0.06736744940280914
Validation loss: 1.4811839416462889

Epoch: 5| Step: 6
Training loss: 0.09215569496154785
Validation loss: 1.4780484886579617

Epoch: 5| Step: 7
Training loss: 0.14282706379890442
Validation loss: 1.4793513314698332

Epoch: 5| Step: 8
Training loss: 0.12030398845672607
Validation loss: 1.4733417136694795

Epoch: 5| Step: 9
Training loss: 0.10764142125844955
Validation loss: 1.4953477228841474

Epoch: 5| Step: 10
Training loss: 0.1113319844007492
Validation loss: 1.4844488969413183

Epoch: 572| Step: 0
Training loss: 0.08193937689065933
Validation loss: 1.4906995629751554

Epoch: 5| Step: 1
Training loss: 0.08706112205982208
Validation loss: 1.4855434593333994

Epoch: 5| Step: 2
Training loss: 0.12752851843833923
Validation loss: 1.4780005844690467

Epoch: 5| Step: 3
Training loss: 0.08565305918455124
Validation loss: 1.491176027123646

Epoch: 5| Step: 4
Training loss: 0.10432195663452148
Validation loss: 1.5147292255073466

Epoch: 5| Step: 5
Training loss: 0.08253737539052963
Validation loss: 1.5369786882913241

Epoch: 5| Step: 6
Training loss: 0.20193573832511902
Validation loss: 1.5140685022518199

Epoch: 5| Step: 7
Training loss: 0.06531371176242828
Validation loss: 1.5159684464495669

Epoch: 5| Step: 8
Training loss: 0.12904497981071472
Validation loss: 1.4672964247324134

Epoch: 5| Step: 9
Training loss: 0.04958300665020943
Validation loss: 1.4610994201834484

Epoch: 5| Step: 10
Training loss: 0.13207124173641205
Validation loss: 1.4752795734713156

Epoch: 573| Step: 0
Training loss: 0.13588878512382507
Validation loss: 1.476902550266635

Epoch: 5| Step: 1
Training loss: 0.07018861919641495
Validation loss: 1.464526282202813

Epoch: 5| Step: 2
Training loss: 0.23526723682880402
Validation loss: 1.4703822347425646

Epoch: 5| Step: 3
Training loss: 0.08237222582101822
Validation loss: 1.4617492627072077

Epoch: 5| Step: 4
Training loss: 0.08394802361726761
Validation loss: 1.481701825254707

Epoch: 5| Step: 5
Training loss: 0.11220352351665497
Validation loss: 1.4767324565559306

Epoch: 5| Step: 6
Training loss: 0.06703345477581024
Validation loss: 1.4899130367463636

Epoch: 5| Step: 7
Training loss: 0.08481273055076599
Validation loss: 1.513981580734253

Epoch: 5| Step: 8
Training loss: 0.06958074867725372
Validation loss: 1.4929046028403825

Epoch: 5| Step: 9
Training loss: 0.061496324837207794
Validation loss: 1.4751143596505607

Epoch: 5| Step: 10
Training loss: 0.0866808146238327
Validation loss: 1.4664121827771586

Epoch: 574| Step: 0
Training loss: 0.15475742518901825
Validation loss: 1.4515154284815635

Epoch: 5| Step: 1
Training loss: 0.04456713795661926
Validation loss: 1.4724513869131766

Epoch: 5| Step: 2
Training loss: 0.0750664472579956
Validation loss: 1.455878742279545

Epoch: 5| Step: 3
Training loss: 0.06759965419769287
Validation loss: 1.4726376687326739

Epoch: 5| Step: 4
Training loss: 0.17091567814350128
Validation loss: 1.4838384678286891

Epoch: 5| Step: 5
Training loss: 0.08654239028692245
Validation loss: 1.4444751098591795

Epoch: 5| Step: 6
Training loss: 0.09367293864488602
Validation loss: 1.4852225152395104

Epoch: 5| Step: 7
Training loss: 0.08162514865398407
Validation loss: 1.4779112069837508

Epoch: 5| Step: 8
Training loss: 0.09751055389642715
Validation loss: 1.490127948022658

Epoch: 5| Step: 9
Training loss: 0.03843657299876213
Validation loss: 1.4653144228842951

Epoch: 5| Step: 10
Training loss: 0.07756786793470383
Validation loss: 1.4548698932893815

Epoch: 575| Step: 0
Training loss: 0.11279026418924332
Validation loss: 1.4662154457902397

Epoch: 5| Step: 1
Training loss: 0.19951264560222626
Validation loss: 1.4641529847216863

Epoch: 5| Step: 2
Training loss: 0.12737727165222168
Validation loss: 1.4380066343533096

Epoch: 5| Step: 3
Training loss: 0.10739855468273163
Validation loss: 1.4579510945145802

Epoch: 5| Step: 4
Training loss: 0.07998643815517426
Validation loss: 1.4582356778524255

Epoch: 5| Step: 5
Training loss: 0.06558877974748611
Validation loss: 1.4689414539644796

Epoch: 5| Step: 6
Training loss: 0.13077668845653534
Validation loss: 1.484389796051928

Epoch: 5| Step: 7
Training loss: 0.12827667593955994
Validation loss: 1.4921928733907721

Epoch: 5| Step: 8
Training loss: 0.07652425020933151
Validation loss: 1.4966843564023253

Epoch: 5| Step: 9
Training loss: 0.08879666030406952
Validation loss: 1.5033637336505357

Epoch: 5| Step: 10
Training loss: 0.06286100298166275
Validation loss: 1.4929843769278577

Epoch: 576| Step: 0
Training loss: 0.09410621225833893
Validation loss: 1.4912118437469646

Epoch: 5| Step: 1
Training loss: 0.13470344245433807
Validation loss: 1.5094066960837251

Epoch: 5| Step: 2
Training loss: 0.14669162034988403
Validation loss: 1.4869491336166218

Epoch: 5| Step: 3
Training loss: 0.11925723403692245
Validation loss: 1.4628572528080275

Epoch: 5| Step: 4
Training loss: 0.06154923886060715
Validation loss: 1.431853469981942

Epoch: 5| Step: 5
Training loss: 0.12219957262277603
Validation loss: 1.4442692565661606

Epoch: 5| Step: 6
Training loss: 0.12841632962226868
Validation loss: 1.4604201925698148

Epoch: 5| Step: 7
Training loss: 0.08297277987003326
Validation loss: 1.4504234316528484

Epoch: 5| Step: 8
Training loss: 0.05823541805148125
Validation loss: 1.4518490004283127

Epoch: 5| Step: 9
Training loss: 0.05851171538233757
Validation loss: 1.4550928505518104

Epoch: 5| Step: 10
Training loss: 0.08145388215780258
Validation loss: 1.4359376174147411

Epoch: 577| Step: 0
Training loss: 0.1276920735836029
Validation loss: 1.4344035194766136

Epoch: 5| Step: 1
Training loss: 0.09956693649291992
Validation loss: 1.440711396996693

Epoch: 5| Step: 2
Training loss: 0.05615547299385071
Validation loss: 1.4393645563433248

Epoch: 5| Step: 3
Training loss: 0.14966806769371033
Validation loss: 1.443480448697203

Epoch: 5| Step: 4
Training loss: 0.0676349326968193
Validation loss: 1.4434760770490092

Epoch: 5| Step: 5
Training loss: 0.10290765762329102
Validation loss: 1.4417016185739988

Epoch: 5| Step: 6
Training loss: 0.09703797101974487
Validation loss: 1.453532749606717

Epoch: 5| Step: 7
Training loss: 0.0708981305360794
Validation loss: 1.441415681633898

Epoch: 5| Step: 8
Training loss: 0.05282650515437126
Validation loss: 1.4465857680125902

Epoch: 5| Step: 9
Training loss: 0.06889010965824127
Validation loss: 1.4513953334541732

Epoch: 5| Step: 10
Training loss: 0.07381097227334976
Validation loss: 1.4767952952333676

Epoch: 578| Step: 0
Training loss: 0.07178854197263718
Validation loss: 1.4739022139580018

Epoch: 5| Step: 1
Training loss: 0.09228493273258209
Validation loss: 1.4942631490768925

Epoch: 5| Step: 2
Training loss: 0.06394458562135696
Validation loss: 1.5243940558484805

Epoch: 5| Step: 3
Training loss: 0.13350078463554382
Validation loss: 1.4918964332149875

Epoch: 5| Step: 4
Training loss: 0.09700734913349152
Validation loss: 1.4940712657026065

Epoch: 5| Step: 5
Training loss: 0.12176360934972763
Validation loss: 1.4655966451091151

Epoch: 5| Step: 6
Training loss: 0.0967605859041214
Validation loss: 1.4542902015870618

Epoch: 5| Step: 7
Training loss: 0.08828727900981903
Validation loss: 1.451533240656699

Epoch: 5| Step: 8
Training loss: 0.167201966047287
Validation loss: 1.4416239223172587

Epoch: 5| Step: 9
Training loss: 0.11596498638391495
Validation loss: 1.4504305008919007

Epoch: 5| Step: 10
Training loss: 0.080759696662426
Validation loss: 1.4682110817201677

Epoch: 579| Step: 0
Training loss: 0.14021342992782593
Validation loss: 1.4614654773025102

Epoch: 5| Step: 1
Training loss: 0.12291951477527618
Validation loss: 1.4338679403387091

Epoch: 5| Step: 2
Training loss: 0.08807249367237091
Validation loss: 1.4718788182863625

Epoch: 5| Step: 3
Training loss: 0.15882526338100433
Validation loss: 1.4814152820135957

Epoch: 5| Step: 4
Training loss: 0.043910082429647446
Validation loss: 1.4827349121852587

Epoch: 5| Step: 5
Training loss: 0.07678286731243134
Validation loss: 1.4835367484759259

Epoch: 5| Step: 6
Training loss: 0.08653911203145981
Validation loss: 1.5107138528618762

Epoch: 5| Step: 7
Training loss: 0.084426149725914
Validation loss: 1.4950939211794125

Epoch: 5| Step: 8
Training loss: 0.07288619130849838
Validation loss: 1.501793562725026

Epoch: 5| Step: 9
Training loss: 0.1133541613817215
Validation loss: 1.499228028840916

Epoch: 5| Step: 10
Training loss: 0.03235280513763428
Validation loss: 1.4780132385992235

Epoch: 580| Step: 0
Training loss: 0.06102060154080391
Validation loss: 1.4795835735977336

Epoch: 5| Step: 1
Training loss: 0.06181710213422775
Validation loss: 1.459834196234262

Epoch: 5| Step: 2
Training loss: 0.08727023750543594
Validation loss: 1.4607712914866786

Epoch: 5| Step: 3
Training loss: 0.10063129663467407
Validation loss: 1.4544517891381377

Epoch: 5| Step: 4
Training loss: 0.06476875394582748
Validation loss: 1.4671945430899178

Epoch: 5| Step: 5
Training loss: 0.07750052213668823
Validation loss: 1.4982537479810818

Epoch: 5| Step: 6
Training loss: 0.07785552740097046
Validation loss: 1.4771640916024484

Epoch: 5| Step: 7
Training loss: 0.12258823215961456
Validation loss: 1.519968435328494

Epoch: 5| Step: 8
Training loss: 0.13527217507362366
Validation loss: 1.4825713519127137

Epoch: 5| Step: 9
Training loss: 0.09998352825641632
Validation loss: 1.522207062731507

Epoch: 5| Step: 10
Training loss: 0.10334572941064835
Validation loss: 1.511962092050942

Epoch: 581| Step: 0
Training loss: 0.13878880441188812
Validation loss: 1.5056478823384931

Epoch: 5| Step: 1
Training loss: 0.06998427212238312
Validation loss: 1.4697939119031351

Epoch: 5| Step: 2
Training loss: 0.06592460721731186
Validation loss: 1.470168544400123

Epoch: 5| Step: 3
Training loss: 0.05741205811500549
Validation loss: 1.4918026001222673

Epoch: 5| Step: 4
Training loss: 0.06843934953212738
Validation loss: 1.4717202122493456

Epoch: 5| Step: 5
Training loss: 0.08375442028045654
Validation loss: 1.4859726172621532

Epoch: 5| Step: 6
Training loss: 0.10406215488910675
Validation loss: 1.4952188743058072

Epoch: 5| Step: 7
Training loss: 0.10890527069568634
Validation loss: 1.4931556550405358

Epoch: 5| Step: 8
Training loss: 0.08403702080249786
Validation loss: 1.4651340220564155

Epoch: 5| Step: 9
Training loss: 0.05193176120519638
Validation loss: 1.4314258662603234

Epoch: 5| Step: 10
Training loss: 0.14370012283325195
Validation loss: 1.4331569005084295

Epoch: 582| Step: 0
Training loss: 0.0913483202457428
Validation loss: 1.4470792547349007

Epoch: 5| Step: 1
Training loss: 0.08133973181247711
Validation loss: 1.4355787897622714

Epoch: 5| Step: 2
Training loss: 0.1694076806306839
Validation loss: 1.4577126310717674

Epoch: 5| Step: 3
Training loss: 0.07834621518850327
Validation loss: 1.4480696762761762

Epoch: 5| Step: 4
Training loss: 0.09195046126842499
Validation loss: 1.4438719307222674

Epoch: 5| Step: 5
Training loss: 0.07518626749515533
Validation loss: 1.4586544882866643

Epoch: 5| Step: 6
Training loss: 0.09036238491535187
Validation loss: 1.4527753745355914

Epoch: 5| Step: 7
Training loss: 0.050396084785461426
Validation loss: 1.464270443044683

Epoch: 5| Step: 8
Training loss: 0.0664161965250969
Validation loss: 1.4616422191742928

Epoch: 5| Step: 9
Training loss: 0.10162826627492905
Validation loss: 1.4615685619333738

Epoch: 5| Step: 10
Training loss: 0.17705118656158447
Validation loss: 1.4774720989247805

Epoch: 583| Step: 0
Training loss: 0.08267311006784439
Validation loss: 1.4776706951920704

Epoch: 5| Step: 1
Training loss: 0.12858952581882477
Validation loss: 1.4802397553638746

Epoch: 5| Step: 2
Training loss: 0.04082081466913223
Validation loss: 1.447796175556798

Epoch: 5| Step: 3
Training loss: 0.08007603883743286
Validation loss: 1.4794312920621646

Epoch: 5| Step: 4
Training loss: 0.08425892889499664
Validation loss: 1.51926593113971

Epoch: 5| Step: 5
Training loss: 0.1477223038673401
Validation loss: 1.4908992846806843

Epoch: 5| Step: 6
Training loss: 0.14642950892448425
Validation loss: 1.4885129082587458

Epoch: 5| Step: 7
Training loss: 0.07328231632709503
Validation loss: 1.4784132421657603

Epoch: 5| Step: 8
Training loss: 0.09774716943502426
Validation loss: 1.4882477175804876

Epoch: 5| Step: 9
Training loss: 0.17587241530418396
Validation loss: 1.5122637453899588

Epoch: 5| Step: 10
Training loss: 0.11196732521057129
Validation loss: 1.5226629639184603

Epoch: 584| Step: 0
Training loss: 0.12655535340309143
Validation loss: 1.5114373801856913

Epoch: 5| Step: 1
Training loss: 0.07709523290395737
Validation loss: 1.4840408063703967

Epoch: 5| Step: 2
Training loss: 0.054771579802036285
Validation loss: 1.4954446797729821

Epoch: 5| Step: 3
Training loss: 0.087091825902462
Validation loss: 1.461632699735703

Epoch: 5| Step: 4
Training loss: 0.16820353269577026
Validation loss: 1.4886841607350174

Epoch: 5| Step: 5
Training loss: 0.12304534763097763
Validation loss: 1.4688550759387273

Epoch: 5| Step: 6
Training loss: 0.1280227154493332
Validation loss: 1.4648131311580699

Epoch: 5| Step: 7
Training loss: 0.1113915890455246
Validation loss: 1.4425294565898117

Epoch: 5| Step: 8
Training loss: 0.0806371346116066
Validation loss: 1.4274018374822472

Epoch: 5| Step: 9
Training loss: 0.06792423874139786
Validation loss: 1.4229157778524584

Epoch: 5| Step: 10
Training loss: 0.10880909115076065
Validation loss: 1.4481377434986893

Epoch: 585| Step: 0
Training loss: 0.11530308425426483
Validation loss: 1.4491156480645622

Epoch: 5| Step: 1
Training loss: 0.13646450638771057
Validation loss: 1.4544471976577595

Epoch: 5| Step: 2
Training loss: 0.08503276854753494
Validation loss: 1.4386557225258119

Epoch: 5| Step: 3
Training loss: 0.051763929426670074
Validation loss: 1.4350239256376862

Epoch: 5| Step: 4
Training loss: 0.1411643624305725
Validation loss: 1.4486159733546677

Epoch: 5| Step: 5
Training loss: 0.08887936919927597
Validation loss: 1.44302269335716

Epoch: 5| Step: 6
Training loss: 0.10114850848913193
Validation loss: 1.4469067614565614

Epoch: 5| Step: 7
Training loss: 0.10809282958507538
Validation loss: 1.4698766232818685

Epoch: 5| Step: 8
Training loss: 0.08425624668598175
Validation loss: 1.4658574878528554

Epoch: 5| Step: 9
Training loss: 0.08913902938365936
Validation loss: 1.4468718767166138

Epoch: 5| Step: 10
Training loss: 0.12517786026000977
Validation loss: 1.4811453780820292

Epoch: 586| Step: 0
Training loss: 0.06294675171375275
Validation loss: 1.4636590378258818

Epoch: 5| Step: 1
Training loss: 0.08711917698383331
Validation loss: 1.4884261354323356

Epoch: 5| Step: 2
Training loss: 0.13773837685585022
Validation loss: 1.4820674286093762

Epoch: 5| Step: 3
Training loss: 0.07552152127027512
Validation loss: 1.4629207721320532

Epoch: 5| Step: 4
Training loss: 0.06925131380558014
Validation loss: 1.4518534778266825

Epoch: 5| Step: 5
Training loss: 0.0482250414788723
Validation loss: 1.4486261670307448

Epoch: 5| Step: 6
Training loss: 0.12102334201335907
Validation loss: 1.3981587822719286

Epoch: 5| Step: 7
Training loss: 0.08664602786302567
Validation loss: 1.420114101902131

Epoch: 5| Step: 8
Training loss: 0.17286643385887146
Validation loss: 1.4182433812848982

Epoch: 5| Step: 9
Training loss: 0.15064628422260284
Validation loss: 1.4143096362390826

Epoch: 5| Step: 10
Training loss: 0.13485027849674225
Validation loss: 1.4388487082655712

Epoch: 587| Step: 0
Training loss: 0.09636210650205612
Validation loss: 1.4318782693596297

Epoch: 5| Step: 1
Training loss: 0.08801065385341644
Validation loss: 1.4419806035616065

Epoch: 5| Step: 2
Training loss: 0.10946929454803467
Validation loss: 1.4259383140071746

Epoch: 5| Step: 3
Training loss: 0.18451914191246033
Validation loss: 1.3815028936632219

Epoch: 5| Step: 4
Training loss: 0.08088561147451401
Validation loss: 1.3880954186121623

Epoch: 5| Step: 5
Training loss: 0.1324266493320465
Validation loss: 1.3789306045860372

Epoch: 5| Step: 6
Training loss: 0.08692415058612823
Validation loss: 1.3931385163337953

Epoch: 5| Step: 7
Training loss: 0.08637332916259766
Validation loss: 1.4191612851235174

Epoch: 5| Step: 8
Training loss: 0.10421957075595856
Validation loss: 1.4244259493325346

Epoch: 5| Step: 9
Training loss: 0.10485818237066269
Validation loss: 1.445229488034402

Epoch: 5| Step: 10
Training loss: 0.08724132925271988
Validation loss: 1.4556127902000182

Epoch: 588| Step: 0
Training loss: 0.08429223299026489
Validation loss: 1.468292067127843

Epoch: 5| Step: 1
Training loss: 0.10415013134479523
Validation loss: 1.4640592323836459

Epoch: 5| Step: 2
Training loss: 0.09598790109157562
Validation loss: 1.4624931094467

Epoch: 5| Step: 3
Training loss: 0.047192566096782684
Validation loss: 1.4689533069569578

Epoch: 5| Step: 4
Training loss: 0.18022975325584412
Validation loss: 1.4890653535883913

Epoch: 5| Step: 5
Training loss: 0.08475847542285919
Validation loss: 1.5181021421186385

Epoch: 5| Step: 6
Training loss: 0.10989580303430557
Validation loss: 1.4906805138434134

Epoch: 5| Step: 7
Training loss: 0.05702334642410278
Validation loss: 1.4876913114260601

Epoch: 5| Step: 8
Training loss: 0.08993204683065414
Validation loss: 1.4930024275215723

Epoch: 5| Step: 9
Training loss: 0.09732585400342941
Validation loss: 1.516884611498925

Epoch: 5| Step: 10
Training loss: 0.09205946326255798
Validation loss: 1.4851223730271863

Epoch: 589| Step: 0
Training loss: 0.08331980556249619
Validation loss: 1.4681651258981356

Epoch: 5| Step: 1
Training loss: 0.0930512547492981
Validation loss: 1.4603917367996708

Epoch: 5| Step: 2
Training loss: 0.06678953021764755
Validation loss: 1.45013258277729

Epoch: 5| Step: 3
Training loss: 0.0728115513920784
Validation loss: 1.4696186383565266

Epoch: 5| Step: 4
Training loss: 0.06806085258722305
Validation loss: 1.4542260836529475

Epoch: 5| Step: 5
Training loss: 0.08521443605422974
Validation loss: 1.4574144309566868

Epoch: 5| Step: 6
Training loss: 0.14123524725437164
Validation loss: 1.4663774941557197

Epoch: 5| Step: 7
Training loss: 0.06550274044275284
Validation loss: 1.4619841088530838

Epoch: 5| Step: 8
Training loss: 0.12700334191322327
Validation loss: 1.4538012563541372

Epoch: 5| Step: 9
Training loss: 0.11821098625659943
Validation loss: 1.479863606473451

Epoch: 5| Step: 10
Training loss: 0.10036288946866989
Validation loss: 1.4867474173986783

Epoch: 590| Step: 0
Training loss: 0.06397273391485214
Validation loss: 1.4728047822111396

Epoch: 5| Step: 1
Training loss: 0.1209041029214859
Validation loss: 1.4853902901372602

Epoch: 5| Step: 2
Training loss: 0.09961818903684616
Validation loss: 1.475993743506811

Epoch: 5| Step: 3
Training loss: 0.11558108031749725
Validation loss: 1.4700742921521586

Epoch: 5| Step: 4
Training loss: 0.1153465062379837
Validation loss: 1.4526712535530009

Epoch: 5| Step: 5
Training loss: 0.08703888952732086
Validation loss: 1.471080715938281

Epoch: 5| Step: 6
Training loss: 0.06262491643428802
Validation loss: 1.4741512819003033

Epoch: 5| Step: 7
Training loss: 0.055836569517850876
Validation loss: 1.4689306289918962

Epoch: 5| Step: 8
Training loss: 0.11665716022253036
Validation loss: 1.477096684517399

Epoch: 5| Step: 9
Training loss: 0.1514267921447754
Validation loss: 1.4828985865398119

Epoch: 5| Step: 10
Training loss: 0.07054466009140015
Validation loss: 1.4597558206127537

Epoch: 591| Step: 0
Training loss: 0.06385312974452972
Validation loss: 1.4693732018111854

Epoch: 5| Step: 1
Training loss: 0.07052553445100784
Validation loss: 1.4968215573218562

Epoch: 5| Step: 2
Training loss: 0.1210641860961914
Validation loss: 1.4906489118452995

Epoch: 5| Step: 3
Training loss: 0.09722622483968735
Validation loss: 1.4847597127319665

Epoch: 5| Step: 4
Training loss: 0.09243810176849365
Validation loss: 1.479717718657627

Epoch: 5| Step: 5
Training loss: 0.09089004248380661
Validation loss: 1.4536510616220453

Epoch: 5| Step: 6
Training loss: 0.11125972121953964
Validation loss: 1.4360275755646408

Epoch: 5| Step: 7
Training loss: 0.05395405367016792
Validation loss: 1.4336610737667288

Epoch: 5| Step: 8
Training loss: 0.15575286746025085
Validation loss: 1.4101503869538665

Epoch: 5| Step: 9
Training loss: 0.15597501397132874
Validation loss: 1.426644407292848

Epoch: 5| Step: 10
Training loss: 0.1917649358510971
Validation loss: 1.478756280355556

Epoch: 592| Step: 0
Training loss: 0.13248519599437714
Validation loss: 1.4826474202576505

Epoch: 5| Step: 1
Training loss: 0.10052679479122162
Validation loss: 1.497227381634456

Epoch: 5| Step: 2
Training loss: 0.1411096751689911
Validation loss: 1.5232325164220666

Epoch: 5| Step: 3
Training loss: 0.09034272283315659
Validation loss: 1.518197944087367

Epoch: 5| Step: 4
Training loss: 0.12086697667837143
Validation loss: 1.522963273909784

Epoch: 5| Step: 5
Training loss: 0.13874009251594543
Validation loss: 1.5149666775939286

Epoch: 5| Step: 6
Training loss: 0.13995134830474854
Validation loss: 1.489738618173907

Epoch: 5| Step: 7
Training loss: 0.07348400354385376
Validation loss: 1.4792494876410371

Epoch: 5| Step: 8
Training loss: 0.1319648176431656
Validation loss: 1.4774718720425841

Epoch: 5| Step: 9
Training loss: 0.12387172877788544
Validation loss: 1.471913876072053

Epoch: 5| Step: 10
Training loss: 0.10785753279924393
Validation loss: 1.5036858743236912

Epoch: 593| Step: 0
Training loss: 0.08233168721199036
Validation loss: 1.4908421962491927

Epoch: 5| Step: 1
Training loss: 0.13807618618011475
Validation loss: 1.4762274347325808

Epoch: 5| Step: 2
Training loss: 0.11538819968700409
Validation loss: 1.4637840229977843

Epoch: 5| Step: 3
Training loss: 0.12226460874080658
Validation loss: 1.4621001635828326

Epoch: 5| Step: 4
Training loss: 0.17446470260620117
Validation loss: 1.4538465251204788

Epoch: 5| Step: 5
Training loss: 0.10853283107280731
Validation loss: 1.5288914736881052

Epoch: 5| Step: 6
Training loss: 0.09774596989154816
Validation loss: 1.48458279332807

Epoch: 5| Step: 7
Training loss: 0.14169809222221375
Validation loss: 1.4997283617655437

Epoch: 5| Step: 8
Training loss: 0.16599884629249573
Validation loss: 1.4665656153873732

Epoch: 5| Step: 9
Training loss: 0.14930889010429382
Validation loss: 1.4540418591550601

Epoch: 5| Step: 10
Training loss: 0.06365327537059784
Validation loss: 1.4833544095357258

Epoch: 594| Step: 0
Training loss: 0.08437994867563248
Validation loss: 1.4636546834822624

Epoch: 5| Step: 1
Training loss: 0.11667653173208237
Validation loss: 1.443800481416846

Epoch: 5| Step: 2
Training loss: 0.11477126181125641
Validation loss: 1.4421989789573095

Epoch: 5| Step: 3
Training loss: 0.09696384519338608
Validation loss: 1.4762852691834973

Epoch: 5| Step: 4
Training loss: 0.06927202641963959
Validation loss: 1.4675508852927917

Epoch: 5| Step: 5
Training loss: 0.07934124767780304
Validation loss: 1.5016688877536404

Epoch: 5| Step: 6
Training loss: 0.14125792682170868
Validation loss: 1.5004285868778025

Epoch: 5| Step: 7
Training loss: 0.0909661278128624
Validation loss: 1.5076854985247377

Epoch: 5| Step: 8
Training loss: 0.11874904483556747
Validation loss: 1.4964799688708397

Epoch: 5| Step: 9
Training loss: 0.12575533986091614
Validation loss: 1.5471451628592707

Epoch: 5| Step: 10
Training loss: 0.07456710934638977
Validation loss: 1.503503393742346

Epoch: 595| Step: 0
Training loss: 0.07981421798467636
Validation loss: 1.5033022498571744

Epoch: 5| Step: 1
Training loss: 0.07516547292470932
Validation loss: 1.4980821032677927

Epoch: 5| Step: 2
Training loss: 0.06431523710489273
Validation loss: 1.482841073825795

Epoch: 5| Step: 3
Training loss: 0.11891426146030426
Validation loss: 1.47313686724632

Epoch: 5| Step: 4
Training loss: 0.11139122396707535
Validation loss: 1.501664024527355

Epoch: 5| Step: 5
Training loss: 0.17339041829109192
Validation loss: 1.4744789664463331

Epoch: 5| Step: 6
Training loss: 0.10151021182537079
Validation loss: 1.4471460568007601

Epoch: 5| Step: 7
Training loss: 0.07203122228384018
Validation loss: 1.4501704028857652

Epoch: 5| Step: 8
Training loss: 0.06487151235342026
Validation loss: 1.460708874528126

Epoch: 5| Step: 9
Training loss: 0.13503582775592804
Validation loss: 1.4588579541893416

Epoch: 5| Step: 10
Training loss: 0.07389545440673828
Validation loss: 1.4793374794785694

Epoch: 596| Step: 0
Training loss: 0.08990006148815155
Validation loss: 1.4716466255085443

Epoch: 5| Step: 1
Training loss: 0.08302319049835205
Validation loss: 1.5039718715093469

Epoch: 5| Step: 2
Training loss: 0.06503788381814957
Validation loss: 1.4995489242256328

Epoch: 5| Step: 3
Training loss: 0.06999699771404266
Validation loss: 1.526826254142228

Epoch: 5| Step: 4
Training loss: 0.13220442831516266
Validation loss: 1.5208470462470927

Epoch: 5| Step: 5
Training loss: 0.06549463421106339
Validation loss: 1.531704109202149

Epoch: 5| Step: 6
Training loss: 0.08387570828199387
Validation loss: 1.5021242826215682

Epoch: 5| Step: 7
Training loss: 0.05988186597824097
Validation loss: 1.5036627195214713

Epoch: 5| Step: 8
Training loss: 0.12176300585269928
Validation loss: 1.5050900918181225

Epoch: 5| Step: 9
Training loss: 0.1532132476568222
Validation loss: 1.4886812727938417

Epoch: 5| Step: 10
Training loss: 0.11159902811050415
Validation loss: 1.4587028000944404

Epoch: 597| Step: 0
Training loss: 0.12364058196544647
Validation loss: 1.4580401887175858

Epoch: 5| Step: 1
Training loss: 0.06262324750423431
Validation loss: 1.4545605746648644

Epoch: 5| Step: 2
Training loss: 0.09803951531648636
Validation loss: 1.4380569919463126

Epoch: 5| Step: 3
Training loss: 0.07149916142225266
Validation loss: 1.4370754008652062

Epoch: 5| Step: 4
Training loss: 0.11075502634048462
Validation loss: 1.4370671126150316

Epoch: 5| Step: 5
Training loss: 0.10261793434619904
Validation loss: 1.4637899539803947

Epoch: 5| Step: 6
Training loss: 0.06792411208152771
Validation loss: 1.463329968913909

Epoch: 5| Step: 7
Training loss: 0.0827852264046669
Validation loss: 1.4613614223336662

Epoch: 5| Step: 8
Training loss: 0.14692258834838867
Validation loss: 1.4894147201250958

Epoch: 5| Step: 9
Training loss: 0.12429396063089371
Validation loss: 1.4839702498528264

Epoch: 5| Step: 10
Training loss: 0.05237526446580887
Validation loss: 1.4771624893270514

Epoch: 598| Step: 0
Training loss: 0.06708617508411407
Validation loss: 1.4665427515583653

Epoch: 5| Step: 1
Training loss: 0.1031404361128807
Validation loss: 1.459868731037263

Epoch: 5| Step: 2
Training loss: 0.0690004825592041
Validation loss: 1.4844531833484609

Epoch: 5| Step: 3
Training loss: 0.11275585740804672
Validation loss: 1.4829170973070207

Epoch: 5| Step: 4
Training loss: 0.19800974428653717
Validation loss: 1.4907455931427658

Epoch: 5| Step: 5
Training loss: 0.10577963292598724
Validation loss: 1.4915391322105163

Epoch: 5| Step: 6
Training loss: 0.051888953894376755
Validation loss: 1.4978594190330916

Epoch: 5| Step: 7
Training loss: 0.05890117958188057
Validation loss: 1.4872330978352537

Epoch: 5| Step: 8
Training loss: 0.10348482429981232
Validation loss: 1.5181991131074968

Epoch: 5| Step: 9
Training loss: 0.08519448339939117
Validation loss: 1.4878790045297274

Epoch: 5| Step: 10
Training loss: 0.06396538019180298
Validation loss: 1.4879462436963153

Epoch: 599| Step: 0
Training loss: 0.058471180498600006
Validation loss: 1.4778859294870847

Epoch: 5| Step: 1
Training loss: 0.0906585305929184
Validation loss: 1.4818373803169496

Epoch: 5| Step: 2
Training loss: 0.07551200687885284
Validation loss: 1.5052899147874566

Epoch: 5| Step: 3
Training loss: 0.13523001968860626
Validation loss: 1.4858745477532829

Epoch: 5| Step: 4
Training loss: 0.12361083179712296
Validation loss: 1.424485166867574

Epoch: 5| Step: 5
Training loss: 0.1274530291557312
Validation loss: 1.4644025282193256

Epoch: 5| Step: 6
Training loss: 0.09474378824234009
Validation loss: 1.4503256595262917

Epoch: 5| Step: 7
Training loss: 0.058345865458250046
Validation loss: 1.4610944742797523

Epoch: 5| Step: 8
Training loss: 0.11558661609888077
Validation loss: 1.4405432849801996

Epoch: 5| Step: 9
Training loss: 0.09052885323762894
Validation loss: 1.4395633295018186

Epoch: 5| Step: 10
Training loss: 0.1406317949295044
Validation loss: 1.4439947957633643

Epoch: 600| Step: 0
Training loss: 0.14824433624744415
Validation loss: 1.4432504497548586

Epoch: 5| Step: 1
Training loss: 0.08452346175909042
Validation loss: 1.4956525910285212

Epoch: 5| Step: 2
Training loss: 0.08863861858844757
Validation loss: 1.5146515446324502

Epoch: 5| Step: 3
Training loss: 0.14417138695716858
Validation loss: 1.520314311468473

Epoch: 5| Step: 4
Training loss: 0.10763707011938095
Validation loss: 1.5168574445991105

Epoch: 5| Step: 5
Training loss: 0.10599584877490997
Validation loss: 1.5093492295152398

Epoch: 5| Step: 6
Training loss: 0.09850616753101349
Validation loss: 1.481559298371756

Epoch: 5| Step: 7
Training loss: 0.12519927322864532
Validation loss: 1.4521719665937527

Epoch: 5| Step: 8
Training loss: 0.1534881889820099
Validation loss: 1.4530841201864264

Epoch: 5| Step: 9
Training loss: 0.19542689621448517
Validation loss: 1.3867369057029806

Epoch: 5| Step: 10
Training loss: 0.07541337609291077
Validation loss: 1.404168059748988

Epoch: 601| Step: 0
Training loss: 0.0831875205039978
Validation loss: 1.3736927150398173

Epoch: 5| Step: 1
Training loss: 0.11517618596553802
Validation loss: 1.3931289642087874

Epoch: 5| Step: 2
Training loss: 0.20939901471138
Validation loss: 1.3986280259265695

Epoch: 5| Step: 3
Training loss: 0.12200857698917389
Validation loss: 1.3960068751406927

Epoch: 5| Step: 4
Training loss: 0.18371069431304932
Validation loss: 1.4091929690812224

Epoch: 5| Step: 5
Training loss: 0.07781995832920074
Validation loss: 1.4232366187598116

Epoch: 5| Step: 6
Training loss: 0.06513092666864395
Validation loss: 1.4181678320771904

Epoch: 5| Step: 7
Training loss: 0.08158250153064728
Validation loss: 1.4505615298466017

Epoch: 5| Step: 8
Training loss: 0.0858074277639389
Validation loss: 1.4549762138756372

Epoch: 5| Step: 9
Training loss: 0.08466174453496933
Validation loss: 1.468624807173206

Epoch: 5| Step: 10
Training loss: 0.10166212171316147
Validation loss: 1.4822476653642551

Epoch: 602| Step: 0
Training loss: 0.11993633210659027
Validation loss: 1.4758178854501376

Epoch: 5| Step: 1
Training loss: 0.051637910306453705
Validation loss: 1.4751991097645094

Epoch: 5| Step: 2
Training loss: 0.08786474168300629
Validation loss: 1.4730144751969205

Epoch: 5| Step: 3
Training loss: 0.13666076958179474
Validation loss: 1.513143244610038

Epoch: 5| Step: 4
Training loss: 0.08032678812742233
Validation loss: 1.4706679947914616

Epoch: 5| Step: 5
Training loss: 0.12682339549064636
Validation loss: 1.5005447242849617

Epoch: 5| Step: 6
Training loss: 0.10905095189809799
Validation loss: 1.526372887754953

Epoch: 5| Step: 7
Training loss: 0.08455855399370193
Validation loss: 1.5214842186179212

Epoch: 5| Step: 8
Training loss: 0.1373019516468048
Validation loss: 1.5129414232828284

Epoch: 5| Step: 9
Training loss: 0.07248257100582123
Validation loss: 1.5144884906789309

Epoch: 5| Step: 10
Training loss: 0.09170994907617569
Validation loss: 1.5105430823500439

Epoch: 603| Step: 0
Training loss: 0.09239780902862549
Validation loss: 1.5010325652296825

Epoch: 5| Step: 1
Training loss: 0.07668586075305939
Validation loss: 1.5065683152085991

Epoch: 5| Step: 2
Training loss: 0.07517114281654358
Validation loss: 1.512550345031164

Epoch: 5| Step: 3
Training loss: 0.11434774100780487
Validation loss: 1.492985015274376

Epoch: 5| Step: 4
Training loss: 0.06330002844333649
Validation loss: 1.4872499845361198

Epoch: 5| Step: 5
Training loss: 0.055690549314022064
Validation loss: 1.471715324668474

Epoch: 5| Step: 6
Training loss: 0.12295980751514435
Validation loss: 1.4886211759300643

Epoch: 5| Step: 7
Training loss: 0.07882275432348251
Validation loss: 1.4877136573996594

Epoch: 5| Step: 8
Training loss: 0.08151622116565704
Validation loss: 1.4574374768041796

Epoch: 5| Step: 9
Training loss: 0.12851470708847046
Validation loss: 1.493106279321896

Epoch: 5| Step: 10
Training loss: 0.1597135365009308
Validation loss: 1.4945208654608777

Epoch: 604| Step: 0
Training loss: 0.07551173865795135
Validation loss: 1.4929847076374998

Epoch: 5| Step: 1
Training loss: 0.0743124857544899
Validation loss: 1.5083093181733163

Epoch: 5| Step: 2
Training loss: 0.12158802896738052
Validation loss: 1.539068418164407

Epoch: 5| Step: 3
Training loss: 0.08557726442813873
Validation loss: 1.5225802903534265

Epoch: 5| Step: 4
Training loss: 0.10019632428884506
Validation loss: 1.5211439927419026

Epoch: 5| Step: 5
Training loss: 0.18278294801712036
Validation loss: 1.516891457701242

Epoch: 5| Step: 6
Training loss: 0.05448334664106369
Validation loss: 1.4910671634058799

Epoch: 5| Step: 7
Training loss: 0.0783243328332901
Validation loss: 1.4891122015573646

Epoch: 5| Step: 8
Training loss: 0.08216304332017899
Validation loss: 1.515457614775627

Epoch: 5| Step: 9
Training loss: 0.08845462650060654
Validation loss: 1.4740732357066164

Epoch: 5| Step: 10
Training loss: 0.07789216190576553
Validation loss: 1.4980211245116366

Epoch: 605| Step: 0
Training loss: 0.08478099852800369
Validation loss: 1.4852235189048193

Epoch: 5| Step: 1
Training loss: 0.07254426181316376
Validation loss: 1.490997690026478

Epoch: 5| Step: 2
Training loss: 0.0675465315580368
Validation loss: 1.4914579494025118

Epoch: 5| Step: 3
Training loss: 0.09258031845092773
Validation loss: 1.5101760754021265

Epoch: 5| Step: 4
Training loss: 0.10385356098413467
Validation loss: 1.5065568429167553

Epoch: 5| Step: 5
Training loss: 0.12496950477361679
Validation loss: 1.4712195729696622

Epoch: 5| Step: 6
Training loss: 0.07017014175653458
Validation loss: 1.4827996652613404

Epoch: 5| Step: 7
Training loss: 0.09878693521022797
Validation loss: 1.4853235316532913

Epoch: 5| Step: 8
Training loss: 0.12067069113254547
Validation loss: 1.448601315098424

Epoch: 5| Step: 9
Training loss: 0.08087826520204544
Validation loss: 1.4465647794867074

Epoch: 5| Step: 10
Training loss: 0.06900233030319214
Validation loss: 1.4525536103274233

Epoch: 606| Step: 0
Training loss: 0.15144434571266174
Validation loss: 1.4414128231745895

Epoch: 5| Step: 1
Training loss: 0.06484903395175934
Validation loss: 1.4477229028619745

Epoch: 5| Step: 2
Training loss: 0.07198880612850189
Validation loss: 1.4185876154130506

Epoch: 5| Step: 3
Training loss: 0.06196177005767822
Validation loss: 1.420378485033589

Epoch: 5| Step: 4
Training loss: 0.09627178311347961
Validation loss: 1.4192573524290515

Epoch: 5| Step: 5
Training loss: 0.06968449056148529
Validation loss: 1.4364332306769587

Epoch: 5| Step: 6
Training loss: 0.09666158258914948
Validation loss: 1.4216266588498188

Epoch: 5| Step: 7
Training loss: 0.08449630439281464
Validation loss: 1.4479678612883373

Epoch: 5| Step: 8
Training loss: 0.062375593930482864
Validation loss: 1.4326685705492574

Epoch: 5| Step: 9
Training loss: 0.14653867483139038
Validation loss: 1.4467167341580955

Epoch: 5| Step: 10
Training loss: 0.059681765735149384
Validation loss: 1.4743567519290472

Epoch: 607| Step: 0
Training loss: 0.12015477567911148
Validation loss: 1.4713946651386958

Epoch: 5| Step: 1
Training loss: 0.11806724965572357
Validation loss: 1.4735050034779373

Epoch: 5| Step: 2
Training loss: 0.10928809642791748
Validation loss: 1.4854015778469782

Epoch: 5| Step: 3
Training loss: 0.15284880995750427
Validation loss: 1.4801042784926712

Epoch: 5| Step: 4
Training loss: 0.08457163721323013
Validation loss: 1.5147953379538752

Epoch: 5| Step: 5
Training loss: 0.07998891174793243
Validation loss: 1.4720512256827405

Epoch: 5| Step: 6
Training loss: 0.07419948279857635
Validation loss: 1.449761482977098

Epoch: 5| Step: 7
Training loss: 0.07626940310001373
Validation loss: 1.4610241343898158

Epoch: 5| Step: 8
Training loss: 0.06254826486110687
Validation loss: 1.4424308833255564

Epoch: 5| Step: 9
Training loss: 0.08403784781694412
Validation loss: 1.432684305534568

Epoch: 5| Step: 10
Training loss: 0.12120933830738068
Validation loss: 1.4623472177854149

Epoch: 608| Step: 0
Training loss: 0.1689511388540268
Validation loss: 1.4824445350195772

Epoch: 5| Step: 1
Training loss: 0.07184556126594543
Validation loss: 1.4762060847333682

Epoch: 5| Step: 2
Training loss: 0.07752300798892975
Validation loss: 1.5029723490438154

Epoch: 5| Step: 3
Training loss: 0.1298384964466095
Validation loss: 1.5280604618851856

Epoch: 5| Step: 4
Training loss: 0.05659770965576172
Validation loss: 1.545078367956223

Epoch: 5| Step: 5
Training loss: 0.1378047913312912
Validation loss: 1.4972917700326571

Epoch: 5| Step: 6
Training loss: 0.08493630588054657
Validation loss: 1.4868579564556

Epoch: 5| Step: 7
Training loss: 0.07892043143510818
Validation loss: 1.4930072920296782

Epoch: 5| Step: 8
Training loss: 0.1445499211549759
Validation loss: 1.4970061971295265

Epoch: 5| Step: 9
Training loss: 0.12061820924282074
Validation loss: 1.5118795415406585

Epoch: 5| Step: 10
Training loss: 0.08741597086191177
Validation loss: 1.5324086117488083

Epoch: 609| Step: 0
Training loss: 0.10473234951496124
Validation loss: 1.4798217345309514

Epoch: 5| Step: 1
Training loss: 0.09759141504764557
Validation loss: 1.472743066408301

Epoch: 5| Step: 2
Training loss: 0.06663961708545685
Validation loss: 1.4427652346190585

Epoch: 5| Step: 3
Training loss: 0.06279414892196655
Validation loss: 1.4431877520776564

Epoch: 5| Step: 4
Training loss: 0.11677801609039307
Validation loss: 1.469812677752587

Epoch: 5| Step: 5
Training loss: 0.08857295662164688
Validation loss: 1.4752954077977005

Epoch: 5| Step: 6
Training loss: 0.10569754987955093
Validation loss: 1.465838195175253

Epoch: 5| Step: 7
Training loss: 0.06053121015429497
Validation loss: 1.4630833261756486

Epoch: 5| Step: 8
Training loss: 0.09377165138721466
Validation loss: 1.441164001341789

Epoch: 5| Step: 9
Training loss: 0.1059955582022667
Validation loss: 1.4539447484477874

Epoch: 5| Step: 10
Training loss: 0.2334921509027481
Validation loss: 1.42501546618759

Epoch: 610| Step: 0
Training loss: 0.10469367355108261
Validation loss: 1.4121859688912668

Epoch: 5| Step: 1
Training loss: 0.08662911504507065
Validation loss: 1.4059135580575595

Epoch: 5| Step: 2
Training loss: 0.08555399626493454
Validation loss: 1.4111106523903467

Epoch: 5| Step: 3
Training loss: 0.1283627301454544
Validation loss: 1.4194785664158482

Epoch: 5| Step: 4
Training loss: 0.06952790915966034
Validation loss: 1.4066009675302813

Epoch: 5| Step: 5
Training loss: 0.06877686828374863
Validation loss: 1.4178547833555488

Epoch: 5| Step: 6
Training loss: 0.0989832952618599
Validation loss: 1.443708900482424

Epoch: 5| Step: 7
Training loss: 0.10602450370788574
Validation loss: 1.4484742969594977

Epoch: 5| Step: 8
Training loss: 0.07832880318164825
Validation loss: 1.4713879259683753

Epoch: 5| Step: 9
Training loss: 0.15144756436347961
Validation loss: 1.5008288121992541

Epoch: 5| Step: 10
Training loss: 0.09137755632400513
Validation loss: 1.5183773886772893

Epoch: 611| Step: 0
Training loss: 0.14050622284412384
Validation loss: 1.5202121221891014

Epoch: 5| Step: 1
Training loss: 0.09277714043855667
Validation loss: 1.5402229473155031

Epoch: 5| Step: 2
Training loss: 0.14051586389541626
Validation loss: 1.5001912514368694

Epoch: 5| Step: 3
Training loss: 0.06895369291305542
Validation loss: 1.4729356291473552

Epoch: 5| Step: 4
Training loss: 0.058090995997190475
Validation loss: 1.476281080835609

Epoch: 5| Step: 5
Training loss: 0.07191001623868942
Validation loss: 1.4649109955756896

Epoch: 5| Step: 6
Training loss: 0.09703101217746735
Validation loss: 1.4607968394474318

Epoch: 5| Step: 7
Training loss: 0.17347483336925507
Validation loss: 1.4449691157187186

Epoch: 5| Step: 8
Training loss: 0.09416304528713226
Validation loss: 1.4374807278315227

Epoch: 5| Step: 9
Training loss: 0.0985889881849289
Validation loss: 1.4216451612851952

Epoch: 5| Step: 10
Training loss: 0.1339654177427292
Validation loss: 1.434697228093301

Epoch: 612| Step: 0
Training loss: 0.10499422252178192
Validation loss: 1.446160852268178

Epoch: 5| Step: 1
Training loss: 0.10930868238210678
Validation loss: 1.456073050857872

Epoch: 5| Step: 2
Training loss: 0.04934653639793396
Validation loss: 1.3845024262705157

Epoch: 5| Step: 3
Training loss: 0.12694263458251953
Validation loss: 1.4191447297732036

Epoch: 5| Step: 4
Training loss: 0.1007194072008133
Validation loss: 1.4460116112104027

Epoch: 5| Step: 5
Training loss: 0.13364389538764954
Validation loss: 1.4246184697715185

Epoch: 5| Step: 6
Training loss: 0.1424694061279297
Validation loss: 1.4462537611684492

Epoch: 5| Step: 7
Training loss: 0.1272716224193573
Validation loss: 1.440742511903086

Epoch: 5| Step: 8
Training loss: 0.10517603158950806
Validation loss: 1.416576967444471

Epoch: 5| Step: 9
Training loss: 0.04598786309361458
Validation loss: 1.421300394560701

Epoch: 5| Step: 10
Training loss: 0.08425217866897583
Validation loss: 1.4006515651620843

Epoch: 613| Step: 0
Training loss: 0.10048224776983261
Validation loss: 1.4085023364713114

Epoch: 5| Step: 1
Training loss: 0.06529556214809418
Validation loss: 1.394739229192016

Epoch: 5| Step: 2
Training loss: 0.09213685989379883
Validation loss: 1.404622991879781

Epoch: 5| Step: 3
Training loss: 0.06214546039700508
Validation loss: 1.4230501113399383

Epoch: 5| Step: 4
Training loss: 0.08165781199932098
Validation loss: 1.4326082173214163

Epoch: 5| Step: 5
Training loss: 0.10365542024374008
Validation loss: 1.4183050291512602

Epoch: 5| Step: 6
Training loss: 0.1342187225818634
Validation loss: 1.4513074762077742

Epoch: 5| Step: 7
Training loss: 0.06613166630268097
Validation loss: 1.4449419090824742

Epoch: 5| Step: 8
Training loss: 0.09322705119848251
Validation loss: 1.44321761849106

Epoch: 5| Step: 9
Training loss: 0.08571877330541611
Validation loss: 1.4749475140725412

Epoch: 5| Step: 10
Training loss: 0.07278541475534439
Validation loss: 1.4736541394264466

Epoch: 614| Step: 0
Training loss: 0.11214590072631836
Validation loss: 1.4945126464290004

Epoch: 5| Step: 1
Training loss: 0.09634271264076233
Validation loss: 1.5339498981352775

Epoch: 5| Step: 2
Training loss: 0.15327784419059753
Validation loss: 1.507163595127803

Epoch: 5| Step: 3
Training loss: 0.08285235613584518
Validation loss: 1.44892337629872

Epoch: 5| Step: 4
Training loss: 0.09009873867034912
Validation loss: 1.4693100016604188

Epoch: 5| Step: 5
Training loss: 0.140707865357399
Validation loss: 1.4500156346187796

Epoch: 5| Step: 6
Training loss: 0.05394013971090317
Validation loss: 1.4659999032174387

Epoch: 5| Step: 7
Training loss: 0.11380325257778168
Validation loss: 1.437914212544759

Epoch: 5| Step: 8
Training loss: 0.09851142019033432
Validation loss: 1.4219918853493148

Epoch: 5| Step: 9
Training loss: 0.09354345500469208
Validation loss: 1.432842521257298

Epoch: 5| Step: 10
Training loss: 0.10821090638637543
Validation loss: 1.4562182734089513

Epoch: 615| Step: 0
Training loss: 0.07108984142541885
Validation loss: 1.4288343626965758

Epoch: 5| Step: 1
Training loss: 0.09239783138036728
Validation loss: 1.4409454676412767

Epoch: 5| Step: 2
Training loss: 0.09540081769227982
Validation loss: 1.4806380707730529

Epoch: 5| Step: 3
Training loss: 0.07698551565408707
Validation loss: 1.4726926178060553

Epoch: 5| Step: 4
Training loss: 0.06712709367275238
Validation loss: 1.4843361095715595

Epoch: 5| Step: 5
Training loss: 0.12795934081077576
Validation loss: 1.4763031441678283

Epoch: 5| Step: 6
Training loss: 0.08391593396663666
Validation loss: 1.4781844026298934

Epoch: 5| Step: 7
Training loss: 0.058516621589660645
Validation loss: 1.4803349112951627

Epoch: 5| Step: 8
Training loss: 0.06607495248317719
Validation loss: 1.442713055559384

Epoch: 5| Step: 9
Training loss: 0.07456401735544205
Validation loss: 1.4393566705847298

Epoch: 5| Step: 10
Training loss: 0.12196476012468338
Validation loss: 1.4457518900594404

Epoch: 616| Step: 0
Training loss: 0.0815904289484024
Validation loss: 1.4522817045129754

Epoch: 5| Step: 1
Training loss: 0.11401359736919403
Validation loss: 1.460831553705277

Epoch: 5| Step: 2
Training loss: 0.06467251479625702
Validation loss: 1.4504092393382904

Epoch: 5| Step: 3
Training loss: 0.0767693817615509
Validation loss: 1.4520787346747615

Epoch: 5| Step: 4
Training loss: 0.04650174453854561
Validation loss: 1.444988517351048

Epoch: 5| Step: 5
Training loss: 0.0701630562543869
Validation loss: 1.46661138983183

Epoch: 5| Step: 6
Training loss: 0.12976714968681335
Validation loss: 1.4718743690880396

Epoch: 5| Step: 7
Training loss: 0.12579666078090668
Validation loss: 1.4601846753910024

Epoch: 5| Step: 8
Training loss: 0.07294771075248718
Validation loss: 1.4688645588454379

Epoch: 5| Step: 9
Training loss: 0.10481834411621094
Validation loss: 1.45711778056237

Epoch: 5| Step: 10
Training loss: 0.09229230880737305
Validation loss: 1.4378355594091519

Epoch: 617| Step: 0
Training loss: 0.08526375889778137
Validation loss: 1.4364636098184893

Epoch: 5| Step: 1
Training loss: 0.15635553002357483
Validation loss: 1.445697557541632

Epoch: 5| Step: 2
Training loss: 0.07492812722921371
Validation loss: 1.4818588841346003

Epoch: 5| Step: 3
Training loss: 0.06800989806652069
Validation loss: 1.4588625033696492

Epoch: 5| Step: 4
Training loss: 0.13573452830314636
Validation loss: 1.489810820548765

Epoch: 5| Step: 5
Training loss: 0.11989797651767731
Validation loss: 1.4901898766076693

Epoch: 5| Step: 6
Training loss: 0.06490401178598404
Validation loss: 1.4716708096124793

Epoch: 5| Step: 7
Training loss: 0.06967088580131531
Validation loss: 1.465191912907426

Epoch: 5| Step: 8
Training loss: 0.0917150229215622
Validation loss: 1.4518352913600143

Epoch: 5| Step: 9
Training loss: 0.09537405520677567
Validation loss: 1.485858114175899

Epoch: 5| Step: 10
Training loss: 0.10155346244573593
Validation loss: 1.4485165124298425

Epoch: 618| Step: 0
Training loss: 0.12244292348623276
Validation loss: 1.447894375811341

Epoch: 5| Step: 1
Training loss: 0.0630984827876091
Validation loss: 1.4443176122762824

Epoch: 5| Step: 2
Training loss: 0.06924949586391449
Validation loss: 1.4468174877987112

Epoch: 5| Step: 3
Training loss: 0.1515365093946457
Validation loss: 1.4277692590990374

Epoch: 5| Step: 4
Training loss: 0.09919168800115585
Validation loss: 1.472247132691004

Epoch: 5| Step: 5
Training loss: 0.08071588724851608
Validation loss: 1.4699967650957004

Epoch: 5| Step: 6
Training loss: 0.10085435211658478
Validation loss: 1.502333894852669

Epoch: 5| Step: 7
Training loss: 0.09064428508281708
Validation loss: 1.4958983236743557

Epoch: 5| Step: 8
Training loss: 0.06595230847597122
Validation loss: 1.470438858514191

Epoch: 5| Step: 9
Training loss: 0.13852211833000183
Validation loss: 1.4606249281155166

Epoch: 5| Step: 10
Training loss: 0.15518556535243988
Validation loss: 1.440548578898112

Epoch: 619| Step: 0
Training loss: 0.09500857442617416
Validation loss: 1.4620610744722429

Epoch: 5| Step: 1
Training loss: 0.15845951437950134
Validation loss: 1.4896684026205411

Epoch: 5| Step: 2
Training loss: 0.16364726424217224
Validation loss: 1.4572630800226682

Epoch: 5| Step: 3
Training loss: 0.2346556931734085
Validation loss: 1.4250639587320306

Epoch: 5| Step: 4
Training loss: 0.10195855796337128
Validation loss: 1.4242309383166734

Epoch: 5| Step: 5
Training loss: 0.10204539448022842
Validation loss: 1.4324110092655304

Epoch: 5| Step: 6
Training loss: 0.14649172127246857
Validation loss: 1.517996157369306

Epoch: 5| Step: 7
Training loss: 0.1970253884792328
Validation loss: 1.5274137463620914

Epoch: 5| Step: 8
Training loss: 0.08863705396652222
Validation loss: 1.453312659776339

Epoch: 5| Step: 9
Training loss: 0.06272660195827484
Validation loss: 1.4438294569651287

Epoch: 5| Step: 10
Training loss: 0.062303852289915085
Validation loss: 1.4300586421002623

Epoch: 620| Step: 0
Training loss: 0.07900308072566986
Validation loss: 1.4772423839056363

Epoch: 5| Step: 1
Training loss: 0.12291143834590912
Validation loss: 1.5009470588417464

Epoch: 5| Step: 2
Training loss: 0.16148518025875092
Validation loss: 1.5057517636206843

Epoch: 5| Step: 3
Training loss: 0.12056760489940643
Validation loss: 1.4712013839393534

Epoch: 5| Step: 4
Training loss: 0.05737006664276123
Validation loss: 1.4352645087306217

Epoch: 5| Step: 5
Training loss: 0.16548475623130798
Validation loss: 1.4500939038492018

Epoch: 5| Step: 6
Training loss: 0.10512695461511612
Validation loss: 1.5113014546773766

Epoch: 5| Step: 7
Training loss: 0.15619313716888428
Validation loss: 1.53312393670441

Epoch: 5| Step: 8
Training loss: 0.317727267742157
Validation loss: 1.5273968929885535

Epoch: 5| Step: 9
Training loss: 0.09489176422357559
Validation loss: 1.4418854418621267

Epoch: 5| Step: 10
Training loss: 0.13516975939273834
Validation loss: 1.410875303770906

Epoch: 621| Step: 0
Training loss: 0.11497080326080322
Validation loss: 1.4438276367802774

Epoch: 5| Step: 1
Training loss: 0.1986793875694275
Validation loss: 1.4640736951622912

Epoch: 5| Step: 2
Training loss: 0.264573335647583
Validation loss: 1.5034435615744641

Epoch: 5| Step: 3
Training loss: 0.1627437025308609
Validation loss: 1.4797656484829482

Epoch: 5| Step: 4
Training loss: 0.1571199893951416
Validation loss: 1.425608697757926

Epoch: 5| Step: 5
Training loss: 0.10377271473407745
Validation loss: 1.4425412076775745

Epoch: 5| Step: 6
Training loss: 0.10196711122989655
Validation loss: 1.4608637017588462

Epoch: 5| Step: 7
Training loss: 0.14952875673770905
Validation loss: 1.4828831662413895

Epoch: 5| Step: 8
Training loss: 0.1858694702386856
Validation loss: 1.5722752450614847

Epoch: 5| Step: 9
Training loss: 0.2534039616584778
Validation loss: 1.546781950099494

Epoch: 5| Step: 10
Training loss: 0.16517232358455658
Validation loss: 1.5374321463287517

Epoch: 622| Step: 0
Training loss: 0.21855828166007996
Validation loss: 1.4540930127584806

Epoch: 5| Step: 1
Training loss: 0.08561583608388901
Validation loss: 1.480120801156567

Epoch: 5| Step: 2
Training loss: 0.12207619845867157
Validation loss: 1.4710369968927035

Epoch: 5| Step: 3
Training loss: 0.21318256855010986
Validation loss: 1.4673285394586542

Epoch: 5| Step: 4
Training loss: 0.1768798530101776
Validation loss: 1.5105352260733163

Epoch: 5| Step: 5
Training loss: 0.10414136946201324
Validation loss: 1.499963338657092

Epoch: 5| Step: 6
Training loss: 0.15928366780281067
Validation loss: 1.460609519353477

Epoch: 5| Step: 7
Training loss: 0.12349028885364532
Validation loss: 1.4568017189220717

Epoch: 5| Step: 8
Training loss: 0.0967695564031601
Validation loss: 1.4509800941713396

Epoch: 5| Step: 9
Training loss: 0.08272700756788254
Validation loss: 1.4732620626367547

Epoch: 5| Step: 10
Training loss: 0.09109470993280411
Validation loss: 1.507011161055616

Epoch: 623| Step: 0
Training loss: 0.10919983685016632
Validation loss: 1.4981143987306984

Epoch: 5| Step: 1
Training loss: 0.17487986385822296
Validation loss: 1.5023639548209407

Epoch: 5| Step: 2
Training loss: 0.14324398338794708
Validation loss: 1.501228032573577

Epoch: 5| Step: 3
Training loss: 0.09792834520339966
Validation loss: 1.4756080950460126

Epoch: 5| Step: 4
Training loss: 0.07481905072927475
Validation loss: 1.4637929867672663

Epoch: 5| Step: 5
Training loss: 0.17464140057563782
Validation loss: 1.4626454525096442

Epoch: 5| Step: 6
Training loss: 0.21765431761741638
Validation loss: 1.5027210071522703

Epoch: 5| Step: 7
Training loss: 0.16281388700008392
Validation loss: 1.5668649186370194

Epoch: 5| Step: 8
Training loss: 0.1332673281431198
Validation loss: 1.5332049926122029

Epoch: 5| Step: 9
Training loss: 0.09974652528762817
Validation loss: 1.5111106634140015

Epoch: 5| Step: 10
Training loss: 0.16185224056243896
Validation loss: 1.4646896341795563

Epoch: 624| Step: 0
Training loss: 0.08061515539884567
Validation loss: 1.4835610364073066

Epoch: 5| Step: 1
Training loss: 0.17339038848876953
Validation loss: 1.505601562479491

Epoch: 5| Step: 2
Training loss: 0.10707923024892807
Validation loss: 1.515325318741542

Epoch: 5| Step: 3
Training loss: 0.20733685791492462
Validation loss: 1.5302131188813077

Epoch: 5| Step: 4
Training loss: 0.15153512358665466
Validation loss: 1.5156828575236823

Epoch: 5| Step: 5
Training loss: 0.10550975799560547
Validation loss: 1.4914716123252787

Epoch: 5| Step: 6
Training loss: 0.09568354487419128
Validation loss: 1.4787532738460007

Epoch: 5| Step: 7
Training loss: 0.10615459829568863
Validation loss: 1.4590169934816257

Epoch: 5| Step: 8
Training loss: 0.12909285724163055
Validation loss: 1.42315528597883

Epoch: 5| Step: 9
Training loss: 0.1172768846154213
Validation loss: 1.4393576691227574

Epoch: 5| Step: 10
Training loss: 0.22235378623008728
Validation loss: 1.4592936820881341

Epoch: 625| Step: 0
Training loss: 0.11825774610042572
Validation loss: 1.4529937428812827

Epoch: 5| Step: 1
Training loss: 0.10461042076349258
Validation loss: 1.444658112782304

Epoch: 5| Step: 2
Training loss: 0.11636209487915039
Validation loss: 1.4654061179007254

Epoch: 5| Step: 3
Training loss: 0.11110327392816544
Validation loss: 1.4627704492179296

Epoch: 5| Step: 4
Training loss: 0.05807652324438095
Validation loss: 1.4919597269386373

Epoch: 5| Step: 5
Training loss: 0.09041564166545868
Validation loss: 1.4789282737239715

Epoch: 5| Step: 6
Training loss: 0.09422878921031952
Validation loss: 1.451172524882901

Epoch: 5| Step: 7
Training loss: 0.07564215362071991
Validation loss: 1.4348058982561993

Epoch: 5| Step: 8
Training loss: 0.060110293328762054
Validation loss: 1.4304331630788825

Epoch: 5| Step: 9
Training loss: 0.19131489098072052
Validation loss: 1.4388009091859222

Epoch: 5| Step: 10
Training loss: 0.13715893030166626
Validation loss: 1.4202629750774753

Epoch: 626| Step: 0
Training loss: 0.09564869105815887
Validation loss: 1.4360251375423965

Epoch: 5| Step: 1
Training loss: 0.10873942077159882
Validation loss: 1.4421648210094822

Epoch: 5| Step: 2
Training loss: 0.13465642929077148
Validation loss: 1.4216335999068392

Epoch: 5| Step: 3
Training loss: 0.06335103511810303
Validation loss: 1.4070216404494418

Epoch: 5| Step: 4
Training loss: 0.1092550978064537
Validation loss: 1.4644449442945502

Epoch: 5| Step: 5
Training loss: 0.0832081288099289
Validation loss: 1.449523179761825

Epoch: 5| Step: 6
Training loss: 0.13766875863075256
Validation loss: 1.4592170574331795

Epoch: 5| Step: 7
Training loss: 0.09746906161308289
Validation loss: 1.4154243309010741

Epoch: 5| Step: 8
Training loss: 0.06528053432703018
Validation loss: 1.386501951884198

Epoch: 5| Step: 9
Training loss: 0.12207292020320892
Validation loss: 1.387328447834138

Epoch: 5| Step: 10
Training loss: 0.14394511282444
Validation loss: 1.3736931034313735

Epoch: 627| Step: 0
Training loss: 0.08263315260410309
Validation loss: 1.3919258040766562

Epoch: 5| Step: 1
Training loss: 0.09047076851129532
Validation loss: 1.415126451881983

Epoch: 5| Step: 2
Training loss: 0.1597919911146164
Validation loss: 1.4194320997884196

Epoch: 5| Step: 3
Training loss: 0.08013371378183365
Validation loss: 1.4093361951971566

Epoch: 5| Step: 4
Training loss: 0.07912860065698624
Validation loss: 1.4265035762581775

Epoch: 5| Step: 5
Training loss: 0.07945699244737625
Validation loss: 1.4244029451442022

Epoch: 5| Step: 6
Training loss: 0.08047735691070557
Validation loss: 1.4285856985276746

Epoch: 5| Step: 7
Training loss: 0.0842479020357132
Validation loss: 1.4363277202011437

Epoch: 5| Step: 8
Training loss: 0.08282940089702606
Validation loss: 1.4581940289466613

Epoch: 5| Step: 9
Training loss: 0.06658435612916946
Validation loss: 1.4756408942643033

Epoch: 5| Step: 10
Training loss: 0.09320070594549179
Validation loss: 1.4499143631227556

Epoch: 628| Step: 0
Training loss: 0.12102709710597992
Validation loss: 1.455503204817413

Epoch: 5| Step: 1
Training loss: 0.07786814868450165
Validation loss: 1.4461834238421531

Epoch: 5| Step: 2
Training loss: 0.17215368151664734
Validation loss: 1.4487919935616114

Epoch: 5| Step: 3
Training loss: 0.10489892959594727
Validation loss: 1.452366808409332

Epoch: 5| Step: 4
Training loss: 0.0949576124548912
Validation loss: 1.4325226788879724

Epoch: 5| Step: 5
Training loss: 0.06718915700912476
Validation loss: 1.4641660003251926

Epoch: 5| Step: 6
Training loss: 0.06563374400138855
Validation loss: 1.4584674880068789

Epoch: 5| Step: 7
Training loss: 0.0568348653614521
Validation loss: 1.4486397850898005

Epoch: 5| Step: 8
Training loss: 0.06176865100860596
Validation loss: 1.434344336550723

Epoch: 5| Step: 9
Training loss: 0.10702420771121979
Validation loss: 1.4501616301075104

Epoch: 5| Step: 10
Training loss: 0.05793662741780281
Validation loss: 1.4412187017420286

Epoch: 629| Step: 0
Training loss: 0.12280566990375519
Validation loss: 1.4521486054184616

Epoch: 5| Step: 1
Training loss: 0.10925068706274033
Validation loss: 1.433326687864078

Epoch: 5| Step: 2
Training loss: 0.08055488765239716
Validation loss: 1.421693036633153

Epoch: 5| Step: 3
Training loss: 0.06971835345029831
Validation loss: 1.4234460694815523

Epoch: 5| Step: 4
Training loss: 0.0801033154129982
Validation loss: 1.439431255863559

Epoch: 5| Step: 5
Training loss: 0.09139847755432129
Validation loss: 1.4565715917976954

Epoch: 5| Step: 6
Training loss: 0.050520122051239014
Validation loss: 1.514576890135324

Epoch: 5| Step: 7
Training loss: 0.17250113189220428
Validation loss: 1.506063953522713

Epoch: 5| Step: 8
Training loss: 0.10128513723611832
Validation loss: 1.503314782214421

Epoch: 5| Step: 9
Training loss: 0.07456991821527481
Validation loss: 1.5234600972103816

Epoch: 5| Step: 10
Training loss: 0.12706512212753296
Validation loss: 1.485072382034794

Epoch: 630| Step: 0
Training loss: 0.11029563844203949
Validation loss: 1.4778959353764851

Epoch: 5| Step: 1
Training loss: 0.06807804107666016
Validation loss: 1.4998825045042141

Epoch: 5| Step: 2
Training loss: 0.08368416130542755
Validation loss: 1.4771125598620343

Epoch: 5| Step: 3
Training loss: 0.07154141366481781
Validation loss: 1.4471006188341367

Epoch: 5| Step: 4
Training loss: 0.07185225188732147
Validation loss: 1.457081469156409

Epoch: 5| Step: 5
Training loss: 0.0983709916472435
Validation loss: 1.4435577392578125

Epoch: 5| Step: 6
Training loss: 0.0637824684381485
Validation loss: 1.4725217537213398

Epoch: 5| Step: 7
Training loss: 0.15763595700263977
Validation loss: 1.4133393123585691

Epoch: 5| Step: 8
Training loss: 0.09279552102088928
Validation loss: 1.4735438349426433

Epoch: 5| Step: 9
Training loss: 0.08094105869531631
Validation loss: 1.4807858723466114

Epoch: 5| Step: 10
Training loss: 0.07684911042451859
Validation loss: 1.464202005376098

Epoch: 631| Step: 0
Training loss: 0.08078999817371368
Validation loss: 1.463669297515705

Epoch: 5| Step: 1
Training loss: 0.08348865061998367
Validation loss: 1.45176661399103

Epoch: 5| Step: 2
Training loss: 0.10829651355743408
Validation loss: 1.4616083188723492

Epoch: 5| Step: 3
Training loss: 0.11179478466510773
Validation loss: 1.4895061536501812

Epoch: 5| Step: 4
Training loss: 0.10089673846960068
Validation loss: 1.4889437998494794

Epoch: 5| Step: 5
Training loss: 0.07912809401750565
Validation loss: 1.4945459250480897

Epoch: 5| Step: 6
Training loss: 0.05566892772912979
Validation loss: 1.5033375242704987

Epoch: 5| Step: 7
Training loss: 0.057612258940935135
Validation loss: 1.4871983117954706

Epoch: 5| Step: 8
Training loss: 0.09868530929088593
Validation loss: 1.5014192494012977

Epoch: 5| Step: 9
Training loss: 0.08446798473596573
Validation loss: 1.5005273408787225

Epoch: 5| Step: 10
Training loss: 0.13230901956558228
Validation loss: 1.49189499116713

Epoch: 632| Step: 0
Training loss: 0.10711224377155304
Validation loss: 1.4993226989623039

Epoch: 5| Step: 1
Training loss: 0.09950930625200272
Validation loss: 1.5098603835669897

Epoch: 5| Step: 2
Training loss: 0.08288799226284027
Validation loss: 1.5121152554788897

Epoch: 5| Step: 3
Training loss: 0.07544201612472534
Validation loss: 1.4968031080820228

Epoch: 5| Step: 4
Training loss: 0.045124005526304245
Validation loss: 1.489124382695844

Epoch: 5| Step: 5
Training loss: 0.11585035175085068
Validation loss: 1.4718490454458422

Epoch: 5| Step: 6
Training loss: 0.05207009240984917
Validation loss: 1.4625604280861475

Epoch: 5| Step: 7
Training loss: 0.15877355635166168
Validation loss: 1.4633303226963166

Epoch: 5| Step: 8
Training loss: 0.03492007777094841
Validation loss: 1.436519181856545

Epoch: 5| Step: 9
Training loss: 0.07690400630235672
Validation loss: 1.457944513649069

Epoch: 5| Step: 10
Training loss: 0.06166493892669678
Validation loss: 1.426324623887257

Epoch: 633| Step: 0
Training loss: 0.10509824752807617
Validation loss: 1.4342597178233567

Epoch: 5| Step: 1
Training loss: 0.07586244493722916
Validation loss: 1.4509264333273775

Epoch: 5| Step: 2
Training loss: 0.050841204822063446
Validation loss: 1.4463191314410138

Epoch: 5| Step: 3
Training loss: 0.09337914735078812
Validation loss: 1.4722371793562365

Epoch: 5| Step: 4
Training loss: 0.07500745356082916
Validation loss: 1.4788821012743059

Epoch: 5| Step: 5
Training loss: 0.05354257673025131
Validation loss: 1.4956771353239655

Epoch: 5| Step: 6
Training loss: 0.11317218840122223
Validation loss: 1.4791651656550746

Epoch: 5| Step: 7
Training loss: 0.06499215215444565
Validation loss: 1.5097544577813917

Epoch: 5| Step: 8
Training loss: 0.09496140480041504
Validation loss: 1.4964363036617156

Epoch: 5| Step: 9
Training loss: 0.15091478824615479
Validation loss: 1.4996115379436041

Epoch: 5| Step: 10
Training loss: 0.06877660006284714
Validation loss: 1.4883351056806502

Epoch: 634| Step: 0
Training loss: 0.0786854475736618
Validation loss: 1.4849309011172223

Epoch: 5| Step: 1
Training loss: 0.08300703018903732
Validation loss: 1.4633659983194003

Epoch: 5| Step: 2
Training loss: 0.06542779505252838
Validation loss: 1.4738430335957518

Epoch: 5| Step: 3
Training loss: 0.10458113998174667
Validation loss: 1.4583563368807557

Epoch: 5| Step: 4
Training loss: 0.11353542655706406
Validation loss: 1.495307541662647

Epoch: 5| Step: 5
Training loss: 0.0682406798005104
Validation loss: 1.482846518998505

Epoch: 5| Step: 6
Training loss: 0.11734183877706528
Validation loss: 1.4855952544878888

Epoch: 5| Step: 7
Training loss: 0.0858791321516037
Validation loss: 1.4686706053313388

Epoch: 5| Step: 8
Training loss: 0.0788731575012207
Validation loss: 1.4689522199733283

Epoch: 5| Step: 9
Training loss: 0.06715936958789825
Validation loss: 1.485352441828738

Epoch: 5| Step: 10
Training loss: 0.041677411645650864
Validation loss: 1.4644053488649347

Epoch: 635| Step: 0
Training loss: 0.0708632841706276
Validation loss: 1.444860182782655

Epoch: 5| Step: 1
Training loss: 0.05680161714553833
Validation loss: 1.430134952709239

Epoch: 5| Step: 2
Training loss: 0.05977095291018486
Validation loss: 1.4508915588419924

Epoch: 5| Step: 3
Training loss: 0.1183442696928978
Validation loss: 1.438265819703379

Epoch: 5| Step: 4
Training loss: 0.06549721956253052
Validation loss: 1.4333176407762753

Epoch: 5| Step: 5
Training loss: 0.11363458633422852
Validation loss: 1.4406776351313437

Epoch: 5| Step: 6
Training loss: 0.08947279304265976
Validation loss: 1.4425434707313456

Epoch: 5| Step: 7
Training loss: 0.11182951927185059
Validation loss: 1.438396833917146

Epoch: 5| Step: 8
Training loss: 0.11934442818164825
Validation loss: 1.4406148323448755

Epoch: 5| Step: 9
Training loss: 0.03777031973004341
Validation loss: 1.4423395344006118

Epoch: 5| Step: 10
Training loss: 0.14725983142852783
Validation loss: 1.468252751135057

Epoch: 636| Step: 0
Training loss: 0.09297952055931091
Validation loss: 1.4518771222842637

Epoch: 5| Step: 1
Training loss: 0.0741177424788475
Validation loss: 1.4518446448028728

Epoch: 5| Step: 2
Training loss: 0.0519978292286396
Validation loss: 1.482826466201454

Epoch: 5| Step: 3
Training loss: 0.04694856330752373
Validation loss: 1.5127539403976933

Epoch: 5| Step: 4
Training loss: 0.08359681069850922
Validation loss: 1.4924463713040916

Epoch: 5| Step: 5
Training loss: 0.11486800014972687
Validation loss: 1.4778998782557826

Epoch: 5| Step: 6
Training loss: 0.07086757570505142
Validation loss: 1.464078039251348

Epoch: 5| Step: 7
Training loss: 0.09953932464122772
Validation loss: 1.4629891546823646

Epoch: 5| Step: 8
Training loss: 0.05865286663174629
Validation loss: 1.4548075199127197

Epoch: 5| Step: 9
Training loss: 0.08431078493595123
Validation loss: 1.4485506979368066

Epoch: 5| Step: 10
Training loss: 0.06402813643217087
Validation loss: 1.4614287794277232

Epoch: 637| Step: 0
Training loss: 0.08392677456140518
Validation loss: 1.4742036096511348

Epoch: 5| Step: 1
Training loss: 0.06799548119306564
Validation loss: 1.455427401809282

Epoch: 5| Step: 2
Training loss: 0.06918574869632721
Validation loss: 1.4678033680044196

Epoch: 5| Step: 3
Training loss: 0.10393953323364258
Validation loss: 1.4989306862636278

Epoch: 5| Step: 4
Training loss: 0.08668555319309235
Validation loss: 1.4584835370381672

Epoch: 5| Step: 5
Training loss: 0.06355098634958267
Validation loss: 1.4868293500715686

Epoch: 5| Step: 6
Training loss: 0.08425203710794449
Validation loss: 1.4998230652142597

Epoch: 5| Step: 7
Training loss: 0.12411506474018097
Validation loss: 1.4709226251930319

Epoch: 5| Step: 8
Training loss: 0.06911037117242813
Validation loss: 1.471538714183274

Epoch: 5| Step: 9
Training loss: 0.06371691823005676
Validation loss: 1.4848273479810326

Epoch: 5| Step: 10
Training loss: 0.10410770773887634
Validation loss: 1.4745637601421726

Epoch: 638| Step: 0
Training loss: 0.09653939306735992
Validation loss: 1.4555013769416398

Epoch: 5| Step: 1
Training loss: 0.11224760860204697
Validation loss: 1.4423217017163512

Epoch: 5| Step: 2
Training loss: 0.06906116753816605
Validation loss: 1.4352558915333082

Epoch: 5| Step: 3
Training loss: 0.05728501081466675
Validation loss: 1.472268799299835

Epoch: 5| Step: 4
Training loss: 0.09954272210597992
Validation loss: 1.427376090839345

Epoch: 5| Step: 5
Training loss: 0.07037675380706787
Validation loss: 1.4466278591463644

Epoch: 5| Step: 6
Training loss: 0.08469904959201813
Validation loss: 1.4396814453986384

Epoch: 5| Step: 7
Training loss: 0.05545877292752266
Validation loss: 1.4632708064971431

Epoch: 5| Step: 8
Training loss: 0.11961660534143448
Validation loss: 1.4371763108879008

Epoch: 5| Step: 9
Training loss: 0.06795777380466461
Validation loss: 1.4114277388459893

Epoch: 5| Step: 10
Training loss: 0.05914688855409622
Validation loss: 1.4075777658852198

Epoch: 639| Step: 0
Training loss: 0.0900934562087059
Validation loss: 1.4287236006029191

Epoch: 5| Step: 1
Training loss: 0.09306780993938446
Validation loss: 1.4234249476463563

Epoch: 5| Step: 2
Training loss: 0.06869007647037506
Validation loss: 1.419021834609329

Epoch: 5| Step: 3
Training loss: 0.06651037931442261
Validation loss: 1.425030327612354

Epoch: 5| Step: 4
Training loss: 0.06122171878814697
Validation loss: 1.4197544359391736

Epoch: 5| Step: 5
Training loss: 0.08711133152246475
Validation loss: 1.4521956341240996

Epoch: 5| Step: 6
Training loss: 0.08367445319890976
Validation loss: 1.448599019358235

Epoch: 5| Step: 7
Training loss: 0.07672452181577682
Validation loss: 1.4504786864403756

Epoch: 5| Step: 8
Training loss: 0.05538560077548027
Validation loss: 1.487965186436971

Epoch: 5| Step: 9
Training loss: 0.13646407425403595
Validation loss: 1.4896593632236603

Epoch: 5| Step: 10
Training loss: 0.07809498906135559
Validation loss: 1.4605655131801483

Epoch: 640| Step: 0
Training loss: 0.1274193823337555
Validation loss: 1.4835522174835205

Epoch: 5| Step: 1
Training loss: 0.08676592260599136
Validation loss: 1.5010480970464728

Epoch: 5| Step: 2
Training loss: 0.1086389422416687
Validation loss: 1.484537447652509

Epoch: 5| Step: 3
Training loss: 0.09548784047365189
Validation loss: 1.494877020517985

Epoch: 5| Step: 4
Training loss: 0.1011943593621254
Validation loss: 1.5046888782132057

Epoch: 5| Step: 5
Training loss: 0.09658413380384445
Validation loss: 1.47264818222292

Epoch: 5| Step: 6
Training loss: 0.13031688332557678
Validation loss: 1.4720009347443939

Epoch: 5| Step: 7
Training loss: 0.13093793392181396
Validation loss: 1.4698755266845867

Epoch: 5| Step: 8
Training loss: 0.09698721021413803
Validation loss: 1.440273343875844

Epoch: 5| Step: 9
Training loss: 0.08138937503099442
Validation loss: 1.472534909043261

Epoch: 5| Step: 10
Training loss: 0.08123955875635147
Validation loss: 1.463484764099121

Epoch: 641| Step: 0
Training loss: 0.12950322031974792
Validation loss: 1.4712622107998017

Epoch: 5| Step: 1
Training loss: 0.1420949250459671
Validation loss: 1.4929194117105136

Epoch: 5| Step: 2
Training loss: 0.13168010115623474
Validation loss: 1.4489714971152685

Epoch: 5| Step: 3
Training loss: 0.07239681482315063
Validation loss: 1.4182856544371574

Epoch: 5| Step: 4
Training loss: 0.09520323574542999
Validation loss: 1.4652845372435868

Epoch: 5| Step: 5
Training loss: 0.08968456089496613
Validation loss: 1.4700164282193748

Epoch: 5| Step: 6
Training loss: 0.08675672113895416
Validation loss: 1.4854599263078423

Epoch: 5| Step: 7
Training loss: 0.1306057721376419
Validation loss: 1.5123408007365402

Epoch: 5| Step: 8
Training loss: 0.05963129550218582
Validation loss: 1.4996103368779665

Epoch: 5| Step: 9
Training loss: 0.10286549478769302
Validation loss: 1.4931517557431293

Epoch: 5| Step: 10
Training loss: 0.10681901127099991
Validation loss: 1.4926010075435843

Epoch: 642| Step: 0
Training loss: 0.061660222709178925
Validation loss: 1.510097945890119

Epoch: 5| Step: 1
Training loss: 0.07062743604183197
Validation loss: 1.4986793802630516

Epoch: 5| Step: 2
Training loss: 0.05673335865139961
Validation loss: 1.482869117490707

Epoch: 5| Step: 3
Training loss: 0.06294006109237671
Validation loss: 1.507312524703241

Epoch: 5| Step: 4
Training loss: 0.09183712303638458
Validation loss: 1.4781826067996282

Epoch: 5| Step: 5
Training loss: 0.12773960828781128
Validation loss: 1.4918418289512716

Epoch: 5| Step: 6
Training loss: 0.05848868563771248
Validation loss: 1.4563094159608245

Epoch: 5| Step: 7
Training loss: 0.09630806744098663
Validation loss: 1.468150117064035

Epoch: 5| Step: 8
Training loss: 0.0849057286977768
Validation loss: 1.4691409423787107

Epoch: 5| Step: 9
Training loss: 0.07914792746305466
Validation loss: 1.4577734611367668

Epoch: 5| Step: 10
Training loss: 0.11552374809980392
Validation loss: 1.459899047369598

Epoch: 643| Step: 0
Training loss: 0.07799043506383896
Validation loss: 1.4787788134749218

Epoch: 5| Step: 1
Training loss: 0.08819587528705597
Validation loss: 1.4765146201656711

Epoch: 5| Step: 2
Training loss: 0.07978247106075287
Validation loss: 1.4627340814118743

Epoch: 5| Step: 3
Training loss: 0.08906964957714081
Validation loss: 1.4742981490268503

Epoch: 5| Step: 4
Training loss: 0.11773815006017685
Validation loss: 1.445085637031063

Epoch: 5| Step: 5
Training loss: 0.05200619250535965
Validation loss: 1.4743820544212096

Epoch: 5| Step: 6
Training loss: 0.06687881797552109
Validation loss: 1.46851336315114

Epoch: 5| Step: 7
Training loss: 0.08137132227420807
Validation loss: 1.4964934805388093

Epoch: 5| Step: 8
Training loss: 0.13041210174560547
Validation loss: 1.4760264811977264

Epoch: 5| Step: 9
Training loss: 0.0667278915643692
Validation loss: 1.4947251132739487

Epoch: 5| Step: 10
Training loss: 0.06559482961893082
Validation loss: 1.4950893860991283

Epoch: 644| Step: 0
Training loss: 0.060836296528577805
Validation loss: 1.4594824634572512

Epoch: 5| Step: 1
Training loss: 0.045575909316539764
Validation loss: 1.4483792435738347

Epoch: 5| Step: 2
Training loss: 0.07342800498008728
Validation loss: 1.4191725471968293

Epoch: 5| Step: 3
Training loss: 0.06239835545420647
Validation loss: 1.4215206766641268

Epoch: 5| Step: 4
Training loss: 0.10442787408828735
Validation loss: 1.4040182091856515

Epoch: 5| Step: 5
Training loss: 0.09533892571926117
Validation loss: 1.403497035785388

Epoch: 5| Step: 6
Training loss: 0.11782509088516235
Validation loss: 1.3920051756725516

Epoch: 5| Step: 7
Training loss: 0.09022022783756256
Validation loss: 1.383897280180326

Epoch: 5| Step: 8
Training loss: 0.108573779463768
Validation loss: 1.4067341576340378

Epoch: 5| Step: 9
Training loss: 0.08542543649673462
Validation loss: 1.4520876266623055

Epoch: 5| Step: 10
Training loss: 0.11931071430444717
Validation loss: 1.4650245571649203

Epoch: 645| Step: 0
Training loss: 0.1325349062681198
Validation loss: 1.4626136556748421

Epoch: 5| Step: 1
Training loss: 0.12226170301437378
Validation loss: 1.4429115146719

Epoch: 5| Step: 2
Training loss: 0.05416334792971611
Validation loss: 1.4162856173771683

Epoch: 5| Step: 3
Training loss: 0.06502167135477066
Validation loss: 1.4158471354874231

Epoch: 5| Step: 4
Training loss: 0.08288954943418503
Validation loss: 1.4323879441907328

Epoch: 5| Step: 5
Training loss: 0.13143618404865265
Validation loss: 1.4207336723163564

Epoch: 5| Step: 6
Training loss: 0.10508044809103012
Validation loss: 1.4257801989073395

Epoch: 5| Step: 7
Training loss: 0.059148479253053665
Validation loss: 1.4418663606848767

Epoch: 5| Step: 8
Training loss: 0.10157451778650284
Validation loss: 1.4605841585384902

Epoch: 5| Step: 9
Training loss: 0.07155151665210724
Validation loss: 1.4787804176730495

Epoch: 5| Step: 10
Training loss: 0.11207015812397003
Validation loss: 1.4876277087837138

Epoch: 646| Step: 0
Training loss: 0.14308014512062073
Validation loss: 1.5004559460506643

Epoch: 5| Step: 1
Training loss: 0.1262873411178589
Validation loss: 1.511260501800045

Epoch: 5| Step: 2
Training loss: 0.06700511276721954
Validation loss: 1.5149691704139914

Epoch: 5| Step: 3
Training loss: 0.0415017232298851
Validation loss: 1.4813241035707536

Epoch: 5| Step: 4
Training loss: 0.0506504587829113
Validation loss: 1.4697368990990423

Epoch: 5| Step: 5
Training loss: 0.08754120022058487
Validation loss: 1.4497933862029866

Epoch: 5| Step: 6
Training loss: 0.06553522497415543
Validation loss: 1.4203028883985294

Epoch: 5| Step: 7
Training loss: 0.0769377127289772
Validation loss: 1.4198108232149513

Epoch: 5| Step: 8
Training loss: 0.11921282857656479
Validation loss: 1.4185909391731344

Epoch: 5| Step: 9
Training loss: 0.14923110604286194
Validation loss: 1.4034891282358477

Epoch: 5| Step: 10
Training loss: 0.08833589404821396
Validation loss: 1.4163068622671149

Epoch: 647| Step: 0
Training loss: 0.057228703051805496
Validation loss: 1.4267089738640735

Epoch: 5| Step: 1
Training loss: 0.0920698493719101
Validation loss: 1.4022540828233123

Epoch: 5| Step: 2
Training loss: 0.09500281512737274
Validation loss: 1.424784601375621

Epoch: 5| Step: 3
Training loss: 0.13012467324733734
Validation loss: 1.4650877278338197

Epoch: 5| Step: 4
Training loss: 0.11800181865692139
Validation loss: 1.4921389600282073

Epoch: 5| Step: 5
Training loss: 0.05717143416404724
Validation loss: 1.4802309043945805

Epoch: 5| Step: 6
Training loss: 0.08362095057964325
Validation loss: 1.4772478265147055

Epoch: 5| Step: 7
Training loss: 0.06289754807949066
Validation loss: 1.4384184742486605

Epoch: 5| Step: 8
Training loss: 0.09223668277263641
Validation loss: 1.4333215016190723

Epoch: 5| Step: 9
Training loss: 0.08516590297222137
Validation loss: 1.4031138189377323

Epoch: 5| Step: 10
Training loss: 0.08874805271625519
Validation loss: 1.4084037452615716

Epoch: 648| Step: 0
Training loss: 0.0829298123717308
Validation loss: 1.4568628393193728

Epoch: 5| Step: 1
Training loss: 0.0643540620803833
Validation loss: 1.4535087641849314

Epoch: 5| Step: 2
Training loss: 0.09337620437145233
Validation loss: 1.4737020871972526

Epoch: 5| Step: 3
Training loss: 0.09697025269269943
Validation loss: 1.492987863479122

Epoch: 5| Step: 4
Training loss: 0.07103313505649567
Validation loss: 1.4907731740705428

Epoch: 5| Step: 5
Training loss: 0.07991321384906769
Validation loss: 1.4996063324712938

Epoch: 5| Step: 6
Training loss: 0.07301665842533112
Validation loss: 1.5256046954021658

Epoch: 5| Step: 7
Training loss: 0.059584856033325195
Validation loss: 1.4966760617430492

Epoch: 5| Step: 8
Training loss: 0.13288259506225586
Validation loss: 1.5042469283585906

Epoch: 5| Step: 9
Training loss: 0.05981839820742607
Validation loss: 1.4612203105803458

Epoch: 5| Step: 10
Training loss: 0.058148182928562164
Validation loss: 1.4494902959433935

Epoch: 649| Step: 0
Training loss: 0.05423550680279732
Validation loss: 1.4283312623218825

Epoch: 5| Step: 1
Training loss: 0.08529629558324814
Validation loss: 1.4501844336909633

Epoch: 5| Step: 2
Training loss: 0.08047230541706085
Validation loss: 1.4466658458914807

Epoch: 5| Step: 3
Training loss: 0.10377035290002823
Validation loss: 1.4232400232745754

Epoch: 5| Step: 4
Training loss: 0.09254437685012817
Validation loss: 1.4423631801400134

Epoch: 5| Step: 5
Training loss: 0.07769762724637985
Validation loss: 1.4406395573769846

Epoch: 5| Step: 6
Training loss: 0.0665067657828331
Validation loss: 1.490694712567073

Epoch: 5| Step: 7
Training loss: 0.0553390271961689
Validation loss: 1.4867990580938195

Epoch: 5| Step: 8
Training loss: 0.07512947171926498
Validation loss: 1.5225709356287473

Epoch: 5| Step: 9
Training loss: 0.09297861903905869
Validation loss: 1.5264351265404814

Epoch: 5| Step: 10
Training loss: 0.07601872831583023
Validation loss: 1.4843077621152323

Epoch: 650| Step: 0
Training loss: 0.1482313871383667
Validation loss: 1.470730253445205

Epoch: 5| Step: 1
Training loss: 0.04631577059626579
Validation loss: 1.4674930034145233

Epoch: 5| Step: 2
Training loss: 0.07064060866832733
Validation loss: 1.4697665091483825

Epoch: 5| Step: 3
Training loss: 0.05346911400556564
Validation loss: 1.465678749545928

Epoch: 5| Step: 4
Training loss: 0.08683139830827713
Validation loss: 1.456541431847439

Epoch: 5| Step: 5
Training loss: 0.07642735540866852
Validation loss: 1.435099470999933

Epoch: 5| Step: 6
Training loss: 0.0759715735912323
Validation loss: 1.4293945745755268

Epoch: 5| Step: 7
Training loss: 0.058247826993465424
Validation loss: 1.4315121712223176

Epoch: 5| Step: 8
Training loss: 0.05926905944943428
Validation loss: 1.4326410280760897

Epoch: 5| Step: 9
Training loss: 0.08180798590183258
Validation loss: 1.4175800623432282

Epoch: 5| Step: 10
Training loss: 0.06529805064201355
Validation loss: 1.482721786345205

Epoch: 651| Step: 0
Training loss: 0.12000501155853271
Validation loss: 1.4567996250685824

Epoch: 5| Step: 1
Training loss: 0.07893738895654678
Validation loss: 1.4563301891408942

Epoch: 5| Step: 2
Training loss: 0.05505726486444473
Validation loss: 1.4735169154341503

Epoch: 5| Step: 3
Training loss: 0.05353047698736191
Validation loss: 1.4636619456352726

Epoch: 5| Step: 4
Training loss: 0.07062201201915741
Validation loss: 1.4390274452906784

Epoch: 5| Step: 5
Training loss: 0.03739369660615921
Validation loss: 1.4641241719645839

Epoch: 5| Step: 6
Training loss: 0.05829157680273056
Validation loss: 1.4824545947454308

Epoch: 5| Step: 7
Training loss: 0.07551565021276474
Validation loss: 1.4642358159506192

Epoch: 5| Step: 8
Training loss: 0.05830870941281319
Validation loss: 1.467627823993724

Epoch: 5| Step: 9
Training loss: 0.09221220761537552
Validation loss: 1.4678424058421966

Epoch: 5| Step: 10
Training loss: 0.03850855678319931
Validation loss: 1.474814941806178

Epoch: 652| Step: 0
Training loss: 0.050194043666124344
Validation loss: 1.479068184411654

Epoch: 5| Step: 1
Training loss: 0.0347951203584671
Validation loss: 1.468822782398552

Epoch: 5| Step: 2
Training loss: 0.06259825080633163
Validation loss: 1.450670979356253

Epoch: 5| Step: 3
Training loss: 0.05987730622291565
Validation loss: 1.473416837312842

Epoch: 5| Step: 4
Training loss: 0.024725109338760376
Validation loss: 1.453629615486309

Epoch: 5| Step: 5
Training loss: 0.055368680506944656
Validation loss: 1.462633825117542

Epoch: 5| Step: 6
Training loss: 0.06959737837314606
Validation loss: 1.4587935670729606

Epoch: 5| Step: 7
Training loss: 0.06306035816669464
Validation loss: 1.4631872279669649

Epoch: 5| Step: 8
Training loss: 0.10843398422002792
Validation loss: 1.4503375099551292

Epoch: 5| Step: 9
Training loss: 0.08913363516330719
Validation loss: 1.4706603686014812

Epoch: 5| Step: 10
Training loss: 0.17878782749176025
Validation loss: 1.4730415632647853

Epoch: 653| Step: 0
Training loss: 0.04473778232932091
Validation loss: 1.4456627253563172

Epoch: 5| Step: 1
Training loss: 0.09636227786540985
Validation loss: 1.4630254442973802

Epoch: 5| Step: 2
Training loss: 0.057317715138196945
Validation loss: 1.4550179986543552

Epoch: 5| Step: 3
Training loss: 0.08659696578979492
Validation loss: 1.42186733535541

Epoch: 5| Step: 4
Training loss: 0.07472600787878036
Validation loss: 1.422673754153713

Epoch: 5| Step: 5
Training loss: 0.07604875415563583
Validation loss: 1.4399377735712195

Epoch: 5| Step: 6
Training loss: 0.04613785073161125
Validation loss: 1.4182676294798493

Epoch: 5| Step: 7
Training loss: 0.05083253234624863
Validation loss: 1.4318905158709454

Epoch: 5| Step: 8
Training loss: 0.1323976069688797
Validation loss: 1.4324328373837214

Epoch: 5| Step: 9
Training loss: 0.04237576946616173
Validation loss: 1.4508459286023212

Epoch: 5| Step: 10
Training loss: 0.09157036244869232
Validation loss: 1.4776720180306384

Epoch: 654| Step: 0
Training loss: 0.05517234280705452
Validation loss: 1.453646941851544

Epoch: 5| Step: 1
Training loss: 0.05343221500515938
Validation loss: 1.459923909556481

Epoch: 5| Step: 2
Training loss: 0.0456915907561779
Validation loss: 1.4651286294383388

Epoch: 5| Step: 3
Training loss: 0.08651965111494064
Validation loss: 1.4413637121518452

Epoch: 5| Step: 4
Training loss: 0.06141427159309387
Validation loss: 1.449426120327365

Epoch: 5| Step: 5
Training loss: 0.0403723306953907
Validation loss: 1.4529171823173441

Epoch: 5| Step: 6
Training loss: 0.06076767295598984
Validation loss: 1.451600956660445

Epoch: 5| Step: 7
Training loss: 0.04841616377234459
Validation loss: 1.4440559174424858

Epoch: 5| Step: 8
Training loss: 0.08558888733386993
Validation loss: 1.441606084505717

Epoch: 5| Step: 9
Training loss: 0.09513992816209793
Validation loss: 1.4551248383778397

Epoch: 5| Step: 10
Training loss: 0.0522131584584713
Validation loss: 1.4687933396267634

Epoch: 655| Step: 0
Training loss: 0.05134420469403267
Validation loss: 1.4415916601816814

Epoch: 5| Step: 1
Training loss: 0.11612609773874283
Validation loss: 1.448176678790841

Epoch: 5| Step: 2
Training loss: 0.05965426564216614
Validation loss: 1.475029073735719

Epoch: 5| Step: 3
Training loss: 0.03597603738307953
Validation loss: 1.4667194504891672

Epoch: 5| Step: 4
Training loss: 0.05719564110040665
Validation loss: 1.4601380658406082

Epoch: 5| Step: 5
Training loss: 0.03938823193311691
Validation loss: 1.4617268693062566

Epoch: 5| Step: 6
Training loss: 0.08845172822475433
Validation loss: 1.4595676327264437

Epoch: 5| Step: 7
Training loss: 0.03676663711667061
Validation loss: 1.4598438432139735

Epoch: 5| Step: 8
Training loss: 0.06171754002571106
Validation loss: 1.4688524597434587

Epoch: 5| Step: 9
Training loss: 0.04890289157629013
Validation loss: 1.4698442502688336

Epoch: 5| Step: 10
Training loss: 0.07916025817394257
Validation loss: 1.4647438756881221

Epoch: 656| Step: 0
Training loss: 0.06899385154247284
Validation loss: 1.4451807775805074

Epoch: 5| Step: 1
Training loss: 0.062133003026247025
Validation loss: 1.4603599835467596

Epoch: 5| Step: 2
Training loss: 0.0662512332201004
Validation loss: 1.4550438734792894

Epoch: 5| Step: 3
Training loss: 0.03166323900222778
Validation loss: 1.4939213568164456

Epoch: 5| Step: 4
Training loss: 0.05152016133069992
Validation loss: 1.466934911666378

Epoch: 5| Step: 5
Training loss: 0.06423517316579819
Validation loss: 1.4843791941160798

Epoch: 5| Step: 6
Training loss: 0.06370699405670166
Validation loss: 1.473486291464939

Epoch: 5| Step: 7
Training loss: 0.04480234533548355
Validation loss: 1.4774837263168827

Epoch: 5| Step: 8
Training loss: 0.053457967936992645
Validation loss: 1.4609310832074893

Epoch: 5| Step: 9
Training loss: 0.12832650542259216
Validation loss: 1.4829441244884203

Epoch: 5| Step: 10
Training loss: 0.10749704390764236
Validation loss: 1.4834007063219625

Epoch: 657| Step: 0
Training loss: 0.06863735616207123
Validation loss: 1.4785193986790155

Epoch: 5| Step: 1
Training loss: 0.04148523509502411
Validation loss: 1.4893183221099198

Epoch: 5| Step: 2
Training loss: 0.06248950958251953
Validation loss: 1.4537616570790608

Epoch: 5| Step: 3
Training loss: 0.0951702743768692
Validation loss: 1.4372884817020868

Epoch: 5| Step: 4
Training loss: 0.06604330241680145
Validation loss: 1.4622115665866482

Epoch: 5| Step: 5
Training loss: 0.05991854518651962
Validation loss: 1.4179085839179255

Epoch: 5| Step: 6
Training loss: 0.04950921982526779
Validation loss: 1.4446709348309426

Epoch: 5| Step: 7
Training loss: 0.12481586635112762
Validation loss: 1.44148205044449

Epoch: 5| Step: 8
Training loss: 0.09995082765817642
Validation loss: 1.4556880920164046

Epoch: 5| Step: 9
Training loss: 0.0700593814253807
Validation loss: 1.477763481037591

Epoch: 5| Step: 10
Training loss: 0.07009866833686829
Validation loss: 1.4873207461449407

Epoch: 658| Step: 0
Training loss: 0.0480208545923233
Validation loss: 1.4705722332000732

Epoch: 5| Step: 1
Training loss: 0.037437908351421356
Validation loss: 1.4774262398801825

Epoch: 5| Step: 2
Training loss: 0.09193846583366394
Validation loss: 1.4505654560622347

Epoch: 5| Step: 3
Training loss: 0.1117750033736229
Validation loss: 1.4596350513478762

Epoch: 5| Step: 4
Training loss: 0.04758565127849579
Validation loss: 1.4503876893751082

Epoch: 5| Step: 5
Training loss: 0.0976257473230362
Validation loss: 1.435053688223644

Epoch: 5| Step: 6
Training loss: 0.08916231244802475
Validation loss: 1.416822979527135

Epoch: 5| Step: 7
Training loss: 0.05253791809082031
Validation loss: 1.4336476466989005

Epoch: 5| Step: 8
Training loss: 0.07430209964513779
Validation loss: 1.453811901871876

Epoch: 5| Step: 9
Training loss: 0.039399124681949615
Validation loss: 1.4352134120079778

Epoch: 5| Step: 10
Training loss: 0.04960830509662628
Validation loss: 1.4220658502271097

Epoch: 659| Step: 0
Training loss: 0.08600209653377533
Validation loss: 1.4443695404196297

Epoch: 5| Step: 1
Training loss: 0.05938216298818588
Validation loss: 1.4350832149546633

Epoch: 5| Step: 2
Training loss: 0.0740990862250328
Validation loss: 1.4423441361355525

Epoch: 5| Step: 3
Training loss: 0.07197792828083038
Validation loss: 1.447383451205428

Epoch: 5| Step: 4
Training loss: 0.029233789071440697
Validation loss: 1.4362101106233494

Epoch: 5| Step: 5
Training loss: 0.04465654492378235
Validation loss: 1.4449366664373746

Epoch: 5| Step: 6
Training loss: 0.06734581291675568
Validation loss: 1.4253471730857767

Epoch: 5| Step: 7
Training loss: 0.06948842108249664
Validation loss: 1.4393521278135237

Epoch: 5| Step: 8
Training loss: 0.08488471806049347
Validation loss: 1.4503997025951263

Epoch: 5| Step: 9
Training loss: 0.056965284049510956
Validation loss: 1.4206332160580544

Epoch: 5| Step: 10
Training loss: 0.10835085064172745
Validation loss: 1.4270632882272043

Epoch: 660| Step: 0
Training loss: 0.06111416220664978
Validation loss: 1.4400993495859125

Epoch: 5| Step: 1
Training loss: 0.057113099843263626
Validation loss: 1.4105580019694504

Epoch: 5| Step: 2
Training loss: 0.07272619009017944
Validation loss: 1.405289835827325

Epoch: 5| Step: 3
Training loss: 0.06106306239962578
Validation loss: 1.4047896323665496

Epoch: 5| Step: 4
Training loss: 0.043496131896972656
Validation loss: 1.4124647942922448

Epoch: 5| Step: 5
Training loss: 0.06499628722667694
Validation loss: 1.416918828923215

Epoch: 5| Step: 6
Training loss: 0.110664963722229
Validation loss: 1.4165271892342517

Epoch: 5| Step: 7
Training loss: 0.14648663997650146
Validation loss: 1.4174304816030687

Epoch: 5| Step: 8
Training loss: 0.047650422900915146
Validation loss: 1.4196872775272658

Epoch: 5| Step: 9
Training loss: 0.08073098957538605
Validation loss: 1.4381271805814517

Epoch: 5| Step: 10
Training loss: 0.05628785118460655
Validation loss: 1.4104934148890997

Epoch: 661| Step: 0
Training loss: 0.10064537823200226
Validation loss: 1.4100294459250666

Epoch: 5| Step: 1
Training loss: 0.06420864164829254
Validation loss: 1.4208714449277489

Epoch: 5| Step: 2
Training loss: 0.07535143196582794
Validation loss: 1.446773636725641

Epoch: 5| Step: 3
Training loss: 0.0784403458237648
Validation loss: 1.4109333817676832

Epoch: 5| Step: 4
Training loss: 0.06000090762972832
Validation loss: 1.4342828591664631

Epoch: 5| Step: 5
Training loss: 0.053236640989780426
Validation loss: 1.4259046091828296

Epoch: 5| Step: 6
Training loss: 0.05104083567857742
Validation loss: 1.4329390993682287

Epoch: 5| Step: 7
Training loss: 0.08839919418096542
Validation loss: 1.4387008913101689

Epoch: 5| Step: 8
Training loss: 0.04119196534156799
Validation loss: 1.441735932903905

Epoch: 5| Step: 9
Training loss: 0.036614783108234406
Validation loss: 1.4312210006098594

Epoch: 5| Step: 10
Training loss: 0.05843770503997803
Validation loss: 1.4507418755562074

Epoch: 662| Step: 0
Training loss: 0.048570532351732254
Validation loss: 1.430619756380717

Epoch: 5| Step: 1
Training loss: 0.055008918046951294
Validation loss: 1.4674508443442724

Epoch: 5| Step: 2
Training loss: 0.0961056724190712
Validation loss: 1.4758027420249036

Epoch: 5| Step: 3
Training loss: 0.0389428436756134
Validation loss: 1.474294868848657

Epoch: 5| Step: 4
Training loss: 0.09681694209575653
Validation loss: 1.4831650462201846

Epoch: 5| Step: 5
Training loss: 0.06600622087717056
Validation loss: 1.5143144310161631

Epoch: 5| Step: 6
Training loss: 0.0846409946680069
Validation loss: 1.4768920034490607

Epoch: 5| Step: 7
Training loss: 0.06307236850261688
Validation loss: 1.4693349484474427

Epoch: 5| Step: 8
Training loss: 0.04489144682884216
Validation loss: 1.4526288214550223

Epoch: 5| Step: 9
Training loss: 0.05334232375025749
Validation loss: 1.4660625470581876

Epoch: 5| Step: 10
Training loss: 0.07536979019641876
Validation loss: 1.420904290932481

Epoch: 663| Step: 0
Training loss: 0.0383344329893589
Validation loss: 1.4168820842619865

Epoch: 5| Step: 1
Training loss: 0.07970008254051208
Validation loss: 1.3959131676663634

Epoch: 5| Step: 2
Training loss: 0.056272219866514206
Validation loss: 1.3957621948693388

Epoch: 5| Step: 3
Training loss: 0.045229047536849976
Validation loss: 1.4108307169329735

Epoch: 5| Step: 4
Training loss: 0.1415257304906845
Validation loss: 1.4315087500438894

Epoch: 5| Step: 5
Training loss: 0.046740125864744186
Validation loss: 1.4256986623169274

Epoch: 5| Step: 6
Training loss: 0.0520017072558403
Validation loss: 1.4133591293006815

Epoch: 5| Step: 7
Training loss: 0.08495733141899109
Validation loss: 1.4133168612757037

Epoch: 5| Step: 8
Training loss: 0.05328204110264778
Validation loss: 1.417459398187617

Epoch: 5| Step: 9
Training loss: 0.047717899084091187
Validation loss: 1.44613056413589

Epoch: 5| Step: 10
Training loss: 0.057107724249362946
Validation loss: 1.4448720614115398

Epoch: 664| Step: 0
Training loss: 0.12531760334968567
Validation loss: 1.4407944237032244

Epoch: 5| Step: 1
Training loss: 0.07538877427577972
Validation loss: 1.4444049455786263

Epoch: 5| Step: 2
Training loss: 0.06598837673664093
Validation loss: 1.444612201823983

Epoch: 5| Step: 3
Training loss: 0.0649816244840622
Validation loss: 1.4584609321368638

Epoch: 5| Step: 4
Training loss: 0.05635560676455498
Validation loss: 1.4830087333597162

Epoch: 5| Step: 5
Training loss: 0.05156823247671127
Validation loss: 1.4502046736337806

Epoch: 5| Step: 6
Training loss: 0.08744745701551437
Validation loss: 1.464282722883327

Epoch: 5| Step: 7
Training loss: 0.04471077769994736
Validation loss: 1.4611161280703802

Epoch: 5| Step: 8
Training loss: 0.02463248372077942
Validation loss: 1.4584851226499003

Epoch: 5| Step: 9
Training loss: 0.05997248739004135
Validation loss: 1.4500337903217604

Epoch: 5| Step: 10
Training loss: 0.0679568350315094
Validation loss: 1.432020342478188

Epoch: 665| Step: 0
Training loss: 0.04665961116552353
Validation loss: 1.4380304339111492

Epoch: 5| Step: 1
Training loss: 0.034128617495298386
Validation loss: 1.45339003685982

Epoch: 5| Step: 2
Training loss: 0.05306776240468025
Validation loss: 1.465691335739628

Epoch: 5| Step: 3
Training loss: 0.05553373694419861
Validation loss: 1.4493319475522606

Epoch: 5| Step: 4
Training loss: 0.09655734151601791
Validation loss: 1.4427478274991434

Epoch: 5| Step: 5
Training loss: 0.05168040841817856
Validation loss: 1.427458103626005

Epoch: 5| Step: 6
Training loss: 0.05947680398821831
Validation loss: 1.4347943823824647

Epoch: 5| Step: 7
Training loss: 0.09172166883945465
Validation loss: 1.428107601340099

Epoch: 5| Step: 8
Training loss: 0.08011837303638458
Validation loss: 1.4269052256820023

Epoch: 5| Step: 9
Training loss: 0.04168033227324486
Validation loss: 1.4166914057987992

Epoch: 5| Step: 10
Training loss: 0.05782167240977287
Validation loss: 1.414951853854682

Epoch: 666| Step: 0
Training loss: 0.06730227172374725
Validation loss: 1.4166513976230417

Epoch: 5| Step: 1
Training loss: 0.04276943951845169
Validation loss: 1.4401513004815707

Epoch: 5| Step: 2
Training loss: 0.0983564555644989
Validation loss: 1.4301267490592053

Epoch: 5| Step: 3
Training loss: 0.10321881622076035
Validation loss: 1.4314666948010843

Epoch: 5| Step: 4
Training loss: 0.041124552488327026
Validation loss: 1.417915686484306

Epoch: 5| Step: 5
Training loss: 0.0437612347304821
Validation loss: 1.4524542118913384

Epoch: 5| Step: 6
Training loss: 0.054540205746889114
Validation loss: 1.4537586371103923

Epoch: 5| Step: 7
Training loss: 0.06587797403335571
Validation loss: 1.4524304430971864

Epoch: 5| Step: 8
Training loss: 0.05030141398310661
Validation loss: 1.453132475576093

Epoch: 5| Step: 9
Training loss: 0.06272619962692261
Validation loss: 1.4804101990115257

Epoch: 5| Step: 10
Training loss: 0.06088167056441307
Validation loss: 1.443896860204717

Epoch: 667| Step: 0
Training loss: 0.05179380625486374
Validation loss: 1.4666974172797254

Epoch: 5| Step: 1
Training loss: 0.05212937667965889
Validation loss: 1.4374768977524133

Epoch: 5| Step: 2
Training loss: 0.05682925507426262
Validation loss: 1.4476476151456115

Epoch: 5| Step: 3
Training loss: 0.07749960571527481
Validation loss: 1.4328386373417352

Epoch: 5| Step: 4
Training loss: 0.07777560502290726
Validation loss: 1.4357217960460211

Epoch: 5| Step: 5
Training loss: 0.03341371566057205
Validation loss: 1.4540970338288175

Epoch: 5| Step: 6
Training loss: 0.046566762030124664
Validation loss: 1.4352231474332913

Epoch: 5| Step: 7
Training loss: 0.048617783933877945
Validation loss: 1.442153343590357

Epoch: 5| Step: 8
Training loss: 0.07261569797992706
Validation loss: 1.4504382334729677

Epoch: 5| Step: 9
Training loss: 0.0689883604645729
Validation loss: 1.4594423437631259

Epoch: 5| Step: 10
Training loss: 0.049834854900836945
Validation loss: 1.4331126969347718

Epoch: 668| Step: 0
Training loss: 0.053182534873485565
Validation loss: 1.426094598667596

Epoch: 5| Step: 1
Training loss: 0.06828944385051727
Validation loss: 1.4434752400203417

Epoch: 5| Step: 2
Training loss: 0.060031674802303314
Validation loss: 1.410753846168518

Epoch: 5| Step: 3
Training loss: 0.10294608026742935
Validation loss: 1.404025040647035

Epoch: 5| Step: 4
Training loss: 0.06150015443563461
Validation loss: 1.4150340646825812

Epoch: 5| Step: 5
Training loss: 0.04737226292490959
Validation loss: 1.4139101588597862

Epoch: 5| Step: 6
Training loss: 0.052074335515499115
Validation loss: 1.4173324274760422

Epoch: 5| Step: 7
Training loss: 0.0695812851190567
Validation loss: 1.4404590501580188

Epoch: 5| Step: 8
Training loss: 0.06494620442390442
Validation loss: 1.4327263582137324

Epoch: 5| Step: 9
Training loss: 0.039952121675014496
Validation loss: 1.454568475805303

Epoch: 5| Step: 10
Training loss: 0.058978207409381866
Validation loss: 1.445005440583793

Epoch: 669| Step: 0
Training loss: 0.04907369986176491
Validation loss: 1.4438895512652654

Epoch: 5| Step: 1
Training loss: 0.041319798678159714
Validation loss: 1.4174750319091223

Epoch: 5| Step: 2
Training loss: 0.08996962755918503
Validation loss: 1.4205684302955546

Epoch: 5| Step: 3
Training loss: 0.08683940768241882
Validation loss: 1.395483530977721

Epoch: 5| Step: 4
Training loss: 0.053640950471162796
Validation loss: 1.4071756691061041

Epoch: 5| Step: 5
Training loss: 0.03780866414308548
Validation loss: 1.4120088341415569

Epoch: 5| Step: 6
Training loss: 0.07092882692813873
Validation loss: 1.4253642520596903

Epoch: 5| Step: 7
Training loss: 0.04023045673966408
Validation loss: 1.412033611728299

Epoch: 5| Step: 8
Training loss: 0.07183140516281128
Validation loss: 1.4317099189245572

Epoch: 5| Step: 9
Training loss: 0.0904083177447319
Validation loss: 1.415828679197578

Epoch: 5| Step: 10
Training loss: 0.03594433516263962
Validation loss: 1.4293933427462013

Epoch: 670| Step: 0
Training loss: 0.0562606081366539
Validation loss: 1.4355229511055896

Epoch: 5| Step: 1
Training loss: 0.08487848192453384
Validation loss: 1.426623772549373

Epoch: 5| Step: 2
Training loss: 0.04768093302845955
Validation loss: 1.441577483248967

Epoch: 5| Step: 3
Training loss: 0.09174813330173492
Validation loss: 1.4363125229394564

Epoch: 5| Step: 4
Training loss: 0.06215484067797661
Validation loss: 1.3992607856309542

Epoch: 5| Step: 5
Training loss: 0.08679982274770737
Validation loss: 1.4147536472607685

Epoch: 5| Step: 6
Training loss: 0.06758351624011993
Validation loss: 1.4182763804671585

Epoch: 5| Step: 7
Training loss: 0.05490371584892273
Validation loss: 1.4393354891448893

Epoch: 5| Step: 8
Training loss: 0.06431954354047775
Validation loss: 1.4086729461146938

Epoch: 5| Step: 9
Training loss: 0.05623609572649002
Validation loss: 1.4192882609623734

Epoch: 5| Step: 10
Training loss: 0.05897356569766998
Validation loss: 1.4187861116983558

Epoch: 671| Step: 0
Training loss: 0.034617625176906586
Validation loss: 1.4250440866716447

Epoch: 5| Step: 1
Training loss: 0.03974025696516037
Validation loss: 1.4282027502213754

Epoch: 5| Step: 2
Training loss: 0.10967550426721573
Validation loss: 1.4572843992581932

Epoch: 5| Step: 3
Training loss: 0.03915838524699211
Validation loss: 1.4525970823021346

Epoch: 5| Step: 4
Training loss: 0.1193792074918747
Validation loss: 1.4625225323502735

Epoch: 5| Step: 5
Training loss: 0.0618266835808754
Validation loss: 1.4620893411738898

Epoch: 5| Step: 6
Training loss: 0.10050903260707855
Validation loss: 1.4568191933375534

Epoch: 5| Step: 7
Training loss: 0.028292512521147728
Validation loss: 1.4303798239718202

Epoch: 5| Step: 8
Training loss: 0.06534337252378464
Validation loss: 1.4181440402102727

Epoch: 5| Step: 9
Training loss: 0.04371169954538345
Validation loss: 1.3991690169098556

Epoch: 5| Step: 10
Training loss: 0.041437044739723206
Validation loss: 1.409345349957866

Epoch: 672| Step: 0
Training loss: 0.07799738645553589
Validation loss: 1.4102771602651125

Epoch: 5| Step: 1
Training loss: 0.07250113785266876
Validation loss: 1.3894974608575144

Epoch: 5| Step: 2
Training loss: 0.054163653403520584
Validation loss: 1.4126220018632951

Epoch: 5| Step: 3
Training loss: 0.05205782502889633
Validation loss: 1.4162743399220128

Epoch: 5| Step: 4
Training loss: 0.0561627559363842
Validation loss: 1.4342580482523928

Epoch: 5| Step: 5
Training loss: 0.0903436616063118
Validation loss: 1.4390489632083523

Epoch: 5| Step: 6
Training loss: 0.06124873831868172
Validation loss: 1.4730031157052645

Epoch: 5| Step: 7
Training loss: 0.07547378540039062
Validation loss: 1.4752772687583842

Epoch: 5| Step: 8
Training loss: 0.060418784618377686
Validation loss: 1.4544582661762033

Epoch: 5| Step: 9
Training loss: 0.07860808074474335
Validation loss: 1.4272552305652249

Epoch: 5| Step: 10
Training loss: 0.12090451270341873
Validation loss: 1.459269779984669

Epoch: 673| Step: 0
Training loss: 0.025600502267479897
Validation loss: 1.4378287125659246

Epoch: 5| Step: 1
Training loss: 0.06678055226802826
Validation loss: 1.4376897645253006

Epoch: 5| Step: 2
Training loss: 0.06565792858600616
Validation loss: 1.4197293250791487

Epoch: 5| Step: 3
Training loss: 0.04843413457274437
Validation loss: 1.4437139444453742

Epoch: 5| Step: 4
Training loss: 0.05104520171880722
Validation loss: 1.4236153441090738

Epoch: 5| Step: 5
Training loss: 0.05520329624414444
Validation loss: 1.4307018121083577

Epoch: 5| Step: 6
Training loss: 0.10462690889835358
Validation loss: 1.4162493085348478

Epoch: 5| Step: 7
Training loss: 0.06305469572544098
Validation loss: 1.464078841670867

Epoch: 5| Step: 8
Training loss: 0.07832459360361099
Validation loss: 1.4578658637180124

Epoch: 5| Step: 9
Training loss: 0.15444710850715637
Validation loss: 1.4688338361760622

Epoch: 5| Step: 10
Training loss: 0.06826048344373703
Validation loss: 1.4926080242280038

Epoch: 674| Step: 0
Training loss: 0.05420859530568123
Validation loss: 1.4684376665340957

Epoch: 5| Step: 1
Training loss: 0.037604160606861115
Validation loss: 1.471377673969474

Epoch: 5| Step: 2
Training loss: 0.06123223900794983
Validation loss: 1.4530089260429464

Epoch: 5| Step: 3
Training loss: 0.03457964211702347
Validation loss: 1.4496657976540186

Epoch: 5| Step: 4
Training loss: 0.0660858303308487
Validation loss: 1.4500560542588592

Epoch: 5| Step: 5
Training loss: 0.08436869084835052
Validation loss: 1.4410449433070358

Epoch: 5| Step: 6
Training loss: 0.06133740022778511
Validation loss: 1.4326928033623645

Epoch: 5| Step: 7
Training loss: 0.04467204585671425
Validation loss: 1.4317436782262658

Epoch: 5| Step: 8
Training loss: 0.11660631000995636
Validation loss: 1.4502462776758338

Epoch: 5| Step: 9
Training loss: 0.09685990959405899
Validation loss: 1.432727288174373

Epoch: 5| Step: 10
Training loss: 0.031847208738327026
Validation loss: 1.4269441199559036

Epoch: 675| Step: 0
Training loss: 0.04663235321640968
Validation loss: 1.4476976984290666

Epoch: 5| Step: 1
Training loss: 0.10080084949731827
Validation loss: 1.4414018886063689

Epoch: 5| Step: 2
Training loss: 0.053673066198825836
Validation loss: 1.4483136528281755

Epoch: 5| Step: 3
Training loss: 0.0519997775554657
Validation loss: 1.4468853204481062

Epoch: 5| Step: 4
Training loss: 0.09345416724681854
Validation loss: 1.4368224272163965

Epoch: 5| Step: 5
Training loss: 0.05516120791435242
Validation loss: 1.4269406128955144

Epoch: 5| Step: 6
Training loss: 0.048441532999277115
Validation loss: 1.4137470760653097

Epoch: 5| Step: 7
Training loss: 0.04144846275448799
Validation loss: 1.4187698364257812

Epoch: 5| Step: 8
Training loss: 0.06585367769002914
Validation loss: 1.4315872038564375

Epoch: 5| Step: 9
Training loss: 0.08041288703680038
Validation loss: 1.4542033108331824

Epoch: 5| Step: 10
Training loss: 0.07787007093429565
Validation loss: 1.4417566612202635

Epoch: 676| Step: 0
Training loss: 0.08538949489593506
Validation loss: 1.4518594088092927

Epoch: 5| Step: 1
Training loss: 0.07236289978027344
Validation loss: 1.475757594390582

Epoch: 5| Step: 2
Training loss: 0.11215504258871078
Validation loss: 1.4878682551845428

Epoch: 5| Step: 3
Training loss: 0.059263408184051514
Validation loss: 1.4625885307147939

Epoch: 5| Step: 4
Training loss: 0.054667651653289795
Validation loss: 1.4623701085326493

Epoch: 5| Step: 5
Training loss: 0.09881945699453354
Validation loss: 1.4442120085480392

Epoch: 5| Step: 6
Training loss: 0.058178048580884933
Validation loss: 1.4227431653648295

Epoch: 5| Step: 7
Training loss: 0.0504402294754982
Validation loss: 1.4408252130272567

Epoch: 5| Step: 8
Training loss: 0.07186733931303024
Validation loss: 1.4272904895967053

Epoch: 5| Step: 9
Training loss: 0.05650203302502632
Validation loss: 1.4109066442776752

Epoch: 5| Step: 10
Training loss: 0.036905981600284576
Validation loss: 1.3905246834601126

Epoch: 677| Step: 0
Training loss: 0.10015970468521118
Validation loss: 1.4142623601421234

Epoch: 5| Step: 1
Training loss: 0.04953191429376602
Validation loss: 1.4103447788505143

Epoch: 5| Step: 2
Training loss: 0.053130727261304855
Validation loss: 1.4278718412563365

Epoch: 5| Step: 3
Training loss: 0.0649578720331192
Validation loss: 1.4555705055113761

Epoch: 5| Step: 4
Training loss: 0.0839882642030716
Validation loss: 1.4761228907492854

Epoch: 5| Step: 5
Training loss: 0.046631570905447006
Validation loss: 1.4495574223097933

Epoch: 5| Step: 6
Training loss: 0.05113140493631363
Validation loss: 1.4525905706549203

Epoch: 5| Step: 7
Training loss: 0.04400285333395004
Validation loss: 1.4326313612281636

Epoch: 5| Step: 8
Training loss: 0.09108205884695053
Validation loss: 1.4294055815665954

Epoch: 5| Step: 9
Training loss: 0.07648559659719467
Validation loss: 1.4175531966711885

Epoch: 5| Step: 10
Training loss: 0.09538008272647858
Validation loss: 1.4423380603072464

Epoch: 678| Step: 0
Training loss: 0.08024577796459198
Validation loss: 1.4100314660738873

Epoch: 5| Step: 1
Training loss: 0.07211899757385254
Validation loss: 1.4280988823982976

Epoch: 5| Step: 2
Training loss: 0.05838913843035698
Validation loss: 1.4208239022121634

Epoch: 5| Step: 3
Training loss: 0.10279746353626251
Validation loss: 1.449336979978828

Epoch: 5| Step: 4
Training loss: 0.06460744142532349
Validation loss: 1.4727874853277718

Epoch: 5| Step: 5
Training loss: 0.04152209684252739
Validation loss: 1.4648723179294216

Epoch: 5| Step: 6
Training loss: 0.06920890510082245
Validation loss: 1.473552752566594

Epoch: 5| Step: 7
Training loss: 0.09518297016620636
Validation loss: 1.5039406425209456

Epoch: 5| Step: 8
Training loss: 0.03657305985689163
Validation loss: 1.4709566805952339

Epoch: 5| Step: 9
Training loss: 0.039974816143512726
Validation loss: 1.482819180334768

Epoch: 5| Step: 10
Training loss: 0.0747315064072609
Validation loss: 1.4388399841964885

Epoch: 679| Step: 0
Training loss: 0.05545686557888985
Validation loss: 1.4464553639452944

Epoch: 5| Step: 1
Training loss: 0.07473117858171463
Validation loss: 1.4433357093923835

Epoch: 5| Step: 2
Training loss: 0.04407886788249016
Validation loss: 1.432349593408646

Epoch: 5| Step: 3
Training loss: 0.08354917913675308
Validation loss: 1.4528144341643139

Epoch: 5| Step: 4
Training loss: 0.05552362650632858
Validation loss: 1.4693078456386444

Epoch: 5| Step: 5
Training loss: 0.045362044125795364
Validation loss: 1.4455863147653558

Epoch: 5| Step: 6
Training loss: 0.08786346018314362
Validation loss: 1.4587472023502472

Epoch: 5| Step: 7
Training loss: 0.10059664398431778
Validation loss: 1.4731814617751746

Epoch: 5| Step: 8
Training loss: 0.085956871509552
Validation loss: 1.4616059007183198

Epoch: 5| Step: 9
Training loss: 0.0881335511803627
Validation loss: 1.4635225137074788

Epoch: 5| Step: 10
Training loss: 0.057049643248319626
Validation loss: 1.4328088016920193

Epoch: 680| Step: 0
Training loss: 0.04078161343932152
Validation loss: 1.4504794766826015

Epoch: 5| Step: 1
Training loss: 0.13597342371940613
Validation loss: 1.459445918759992

Epoch: 5| Step: 2
Training loss: 0.05969567224383354
Validation loss: 1.4320965261869534

Epoch: 5| Step: 3
Training loss: 0.05307505279779434
Validation loss: 1.4101520007656467

Epoch: 5| Step: 4
Training loss: 0.10564307868480682
Validation loss: 1.4209298497887068

Epoch: 5| Step: 5
Training loss: 0.06347416341304779
Validation loss: 1.4085955337811542

Epoch: 5| Step: 6
Training loss: 0.043019987642765045
Validation loss: 1.4323881159546554

Epoch: 5| Step: 7
Training loss: 0.07904960215091705
Validation loss: 1.436283225654274

Epoch: 5| Step: 8
Training loss: 0.06634580343961716
Validation loss: 1.4270608591777023

Epoch: 5| Step: 9
Training loss: 0.0725938081741333
Validation loss: 1.4393968594971525

Epoch: 5| Step: 10
Training loss: 0.06667143106460571
Validation loss: 1.4428378523036998

Epoch: 681| Step: 0
Training loss: 0.04224270209670067
Validation loss: 1.4773032139706355

Epoch: 5| Step: 1
Training loss: 0.0490686297416687
Validation loss: 1.4905316432317097

Epoch: 5| Step: 2
Training loss: 0.07746769487857819
Validation loss: 1.484544078509013

Epoch: 5| Step: 3
Training loss: 0.08163858950138092
Validation loss: 1.475401266928642

Epoch: 5| Step: 4
Training loss: 0.09257359802722931
Validation loss: 1.440855795978218

Epoch: 5| Step: 5
Training loss: 0.08783445507287979
Validation loss: 1.4061410196365849

Epoch: 5| Step: 6
Training loss: 0.09705985337495804
Validation loss: 1.415376881758372

Epoch: 5| Step: 7
Training loss: 0.11148486286401749
Validation loss: 1.4169974903906546

Epoch: 5| Step: 8
Training loss: 0.14658266305923462
Validation loss: 1.4157973668908561

Epoch: 5| Step: 9
Training loss: 0.12044905126094818
Validation loss: 1.409246951021174

Epoch: 5| Step: 10
Training loss: 0.09303271025419235
Validation loss: 1.4244937409636795

Epoch: 682| Step: 0
Training loss: 0.09588412195444107
Validation loss: 1.4004840530374998

Epoch: 5| Step: 1
Training loss: 0.0764937773346901
Validation loss: 1.4059546455260246

Epoch: 5| Step: 2
Training loss: 0.06606721878051758
Validation loss: 1.4251111181833411

Epoch: 5| Step: 3
Training loss: 0.028386211022734642
Validation loss: 1.4511690767862464

Epoch: 5| Step: 4
Training loss: 0.05650324746966362
Validation loss: 1.4740409197345856

Epoch: 5| Step: 5
Training loss: 0.08863762766122818
Validation loss: 1.4703932885200746

Epoch: 5| Step: 6
Training loss: 0.0645870566368103
Validation loss: 1.4857778113375428

Epoch: 5| Step: 7
Training loss: 0.08062698692083359
Validation loss: 1.457882208208884

Epoch: 5| Step: 8
Training loss: 0.07260482013225555
Validation loss: 1.4440408765628774

Epoch: 5| Step: 9
Training loss: 0.06265117228031158
Validation loss: 1.4325683203435713

Epoch: 5| Step: 10
Training loss: 0.06607972085475922
Validation loss: 1.4192683837747062

Epoch: 683| Step: 0
Training loss: 0.08951027691364288
Validation loss: 1.457198868515671

Epoch: 5| Step: 1
Training loss: 0.07250899821519852
Validation loss: 1.3985274491771575

Epoch: 5| Step: 2
Training loss: 0.09604988992214203
Validation loss: 1.4286209755046393

Epoch: 5| Step: 3
Training loss: 0.04808556288480759
Validation loss: 1.4382322834384056

Epoch: 5| Step: 4
Training loss: 0.06942623853683472
Validation loss: 1.4457454642941874

Epoch: 5| Step: 5
Training loss: 0.10309360921382904
Validation loss: 1.4627359829923159

Epoch: 5| Step: 6
Training loss: 0.03984326869249344
Validation loss: 1.4712328577554354

Epoch: 5| Step: 7
Training loss: 0.07923169434070587
Validation loss: 1.4904220757945892

Epoch: 5| Step: 8
Training loss: 0.07569779455661774
Validation loss: 1.4841661927520589

Epoch: 5| Step: 9
Training loss: 0.050669312477111816
Validation loss: 1.5026751679758872

Epoch: 5| Step: 10
Training loss: 0.12241346389055252
Validation loss: 1.4526503150181105

Epoch: 684| Step: 0
Training loss: 0.055649012327194214
Validation loss: 1.4428502064879223

Epoch: 5| Step: 1
Training loss: 0.055322159081697464
Validation loss: 1.4273366748645742

Epoch: 5| Step: 2
Training loss: 0.09376685321331024
Validation loss: 1.4234201151837584

Epoch: 5| Step: 3
Training loss: 0.09641902148723602
Validation loss: 1.4268888119728333

Epoch: 5| Step: 4
Training loss: 0.05138026550412178
Validation loss: 1.408644135280322

Epoch: 5| Step: 5
Training loss: 0.03388287127017975
Validation loss: 1.4031944518448205

Epoch: 5| Step: 6
Training loss: 0.07083339989185333
Validation loss: 1.4174664930630756

Epoch: 5| Step: 7
Training loss: 0.07490037381649017
Validation loss: 1.4145805053813483

Epoch: 5| Step: 8
Training loss: 0.04525887966156006
Validation loss: 1.409771970523301

Epoch: 5| Step: 9
Training loss: 0.05339008569717407
Validation loss: 1.4192547064314607

Epoch: 5| Step: 10
Training loss: 0.07897710800170898
Validation loss: 1.4145195009887859

Epoch: 685| Step: 0
Training loss: 0.045821014791727066
Validation loss: 1.456384725468133

Epoch: 5| Step: 1
Training loss: 0.046274781227111816
Validation loss: 1.415968325830275

Epoch: 5| Step: 2
Training loss: 0.05173899978399277
Validation loss: 1.4318032649255568

Epoch: 5| Step: 3
Training loss: 0.04884671792387962
Validation loss: 1.4221702814102173

Epoch: 5| Step: 4
Training loss: 0.04032406210899353
Validation loss: 1.4382278816674345

Epoch: 5| Step: 5
Training loss: 0.04499628394842148
Validation loss: 1.4220002069268176

Epoch: 5| Step: 6
Training loss: 0.03993906453251839
Validation loss: 1.42830825877446

Epoch: 5| Step: 7
Training loss: 0.05657704547047615
Validation loss: 1.434468839758186

Epoch: 5| Step: 8
Training loss: 0.11031536012887955
Validation loss: 1.4294714209853963

Epoch: 5| Step: 9
Training loss: 0.06928350031375885
Validation loss: 1.4485599828022782

Epoch: 5| Step: 10
Training loss: 0.0562923364341259
Validation loss: 1.4753887678987236

Epoch: 686| Step: 0
Training loss: 0.035407375544309616
Validation loss: 1.4705012036908058

Epoch: 5| Step: 1
Training loss: 0.07613350450992584
Validation loss: 1.4612188364869805

Epoch: 5| Step: 2
Training loss: 0.06433631479740143
Validation loss: 1.4610669151429208

Epoch: 5| Step: 3
Training loss: 0.031903333961963654
Validation loss: 1.4428103841761106

Epoch: 5| Step: 4
Training loss: 0.07805852591991425
Validation loss: 1.4279493298581851

Epoch: 5| Step: 5
Training loss: 0.09462277591228485
Validation loss: 1.4278709298820906

Epoch: 5| Step: 6
Training loss: 0.07330961525440216
Validation loss: 1.406802668366381

Epoch: 5| Step: 7
Training loss: 0.042098600417375565
Validation loss: 1.4254131560684533

Epoch: 5| Step: 8
Training loss: 0.049714941531419754
Validation loss: 1.4046392799705587

Epoch: 5| Step: 9
Training loss: 0.0672331228852272
Validation loss: 1.3964769327512352

Epoch: 5| Step: 10
Training loss: 0.04136565700173378
Validation loss: 1.4096278670013591

Epoch: 687| Step: 0
Training loss: 0.08698926120996475
Validation loss: 1.4064734392268683

Epoch: 5| Step: 1
Training loss: 0.06317402422428131
Validation loss: 1.404948684477037

Epoch: 5| Step: 2
Training loss: 0.10800538957118988
Validation loss: 1.424269546744644

Epoch: 5| Step: 3
Training loss: 0.07499440014362335
Validation loss: 1.4575199613007166

Epoch: 5| Step: 4
Training loss: 0.050203341990709305
Validation loss: 1.46279405009362

Epoch: 5| Step: 5
Training loss: 0.03246784955263138
Validation loss: 1.4513432018218502

Epoch: 5| Step: 6
Training loss: 0.057120807468891144
Validation loss: 1.4591107086468769

Epoch: 5| Step: 7
Training loss: 0.06627270579338074
Validation loss: 1.4512387680751022

Epoch: 5| Step: 8
Training loss: 0.0321880504488945
Validation loss: 1.4486871284823264

Epoch: 5| Step: 9
Training loss: 0.09857545047998428
Validation loss: 1.4823106386328255

Epoch: 5| Step: 10
Training loss: 0.03328290209174156
Validation loss: 1.4770797862801501

Epoch: 688| Step: 0
Training loss: 0.0626256912946701
Validation loss: 1.4711567201922018

Epoch: 5| Step: 1
Training loss: 0.03765759989619255
Validation loss: 1.481261771212342

Epoch: 5| Step: 2
Training loss: 0.08234019577503204
Validation loss: 1.4662367182393228

Epoch: 5| Step: 3
Training loss: 0.06000591069459915
Validation loss: 1.4302036557146298

Epoch: 5| Step: 4
Training loss: 0.059328459203243256
Validation loss: 1.4509438769791716

Epoch: 5| Step: 5
Training loss: 0.06792205572128296
Validation loss: 1.4599674017198625

Epoch: 5| Step: 6
Training loss: 0.07145779579877853
Validation loss: 1.4323981846532514

Epoch: 5| Step: 7
Training loss: 0.06183440610766411
Validation loss: 1.4284303790779525

Epoch: 5| Step: 8
Training loss: 0.08538006246089935
Validation loss: 1.426346775665078

Epoch: 5| Step: 9
Training loss: 0.05869926139712334
Validation loss: 1.4262158652787567

Epoch: 5| Step: 10
Training loss: 0.06045912951231003
Validation loss: 1.433323452549596

Epoch: 689| Step: 0
Training loss: 0.08705013245344162
Validation loss: 1.3945965830997755

Epoch: 5| Step: 1
Training loss: 0.05503101274371147
Validation loss: 1.3946352466460197

Epoch: 5| Step: 2
Training loss: 0.08162583410739899
Validation loss: 1.3836710465851652

Epoch: 5| Step: 3
Training loss: 0.047493595629930496
Validation loss: 1.3659496794464767

Epoch: 5| Step: 4
Training loss: 0.059947311878204346
Validation loss: 1.3663930918580742

Epoch: 5| Step: 5
Training loss: 0.05548965930938721
Validation loss: 1.367978198553926

Epoch: 5| Step: 6
Training loss: 0.03519114851951599
Validation loss: 1.3579657077789307

Epoch: 5| Step: 7
Training loss: 0.09063292294740677
Validation loss: 1.38576247871563

Epoch: 5| Step: 8
Training loss: 0.055011086165905
Validation loss: 1.3772000638387536

Epoch: 5| Step: 9
Training loss: 0.06317436695098877
Validation loss: 1.372451969372329

Epoch: 5| Step: 10
Training loss: 0.09662260115146637
Validation loss: 1.37343418469993

Epoch: 690| Step: 0
Training loss: 0.07150150835514069
Validation loss: 1.3708046892637848

Epoch: 5| Step: 1
Training loss: 0.10848881304264069
Validation loss: 1.3786494372993388

Epoch: 5| Step: 2
Training loss: 0.06926428526639938
Validation loss: 1.4211647664347002

Epoch: 5| Step: 3
Training loss: 0.0820002406835556
Validation loss: 1.3961927301140242

Epoch: 5| Step: 4
Training loss: 0.05853385850787163
Validation loss: 1.421612258880369

Epoch: 5| Step: 5
Training loss: 0.0398339182138443
Validation loss: 1.4293633430234847

Epoch: 5| Step: 6
Training loss: 0.051713358610868454
Validation loss: 1.429458156708748

Epoch: 5| Step: 7
Training loss: 0.031124239787459373
Validation loss: 1.4454983395914878

Epoch: 5| Step: 8
Training loss: 0.05959498882293701
Validation loss: 1.4431544926858717

Epoch: 5| Step: 9
Training loss: 0.09338150918483734
Validation loss: 1.4452179554970033

Epoch: 5| Step: 10
Training loss: 0.041628606617450714
Validation loss: 1.4650319087248977

Epoch: 691| Step: 0
Training loss: 0.07958806306123734
Validation loss: 1.463922764665337

Epoch: 5| Step: 1
Training loss: 0.03515370935201645
Validation loss: 1.4623944163322449

Epoch: 5| Step: 2
Training loss: 0.12251516431570053
Validation loss: 1.4484228107237047

Epoch: 5| Step: 3
Training loss: 0.05013533681631088
Validation loss: 1.4165950000927012

Epoch: 5| Step: 4
Training loss: 0.07788533717393875
Validation loss: 1.4301722241986183

Epoch: 5| Step: 5
Training loss: 0.06628618389368057
Validation loss: 1.4007053759790236

Epoch: 5| Step: 6
Training loss: 0.04939527437090874
Validation loss: 1.39425875038229

Epoch: 5| Step: 7
Training loss: 0.04682282730937004
Validation loss: 1.3556029232599403

Epoch: 5| Step: 8
Training loss: 0.08310635387897491
Validation loss: 1.386351191869346

Epoch: 5| Step: 9
Training loss: 0.06173618882894516
Validation loss: 1.403919642971408

Epoch: 5| Step: 10
Training loss: 0.05586633086204529
Validation loss: 1.3951386585030505

Epoch: 692| Step: 0
Training loss: 0.05292811244726181
Validation loss: 1.4193266719900153

Epoch: 5| Step: 1
Training loss: 0.043984778225421906
Validation loss: 1.4292512042548067

Epoch: 5| Step: 2
Training loss: 0.08948792517185211
Validation loss: 1.4375229945746801

Epoch: 5| Step: 3
Training loss: 0.08130693435668945
Validation loss: 1.4660528116328742

Epoch: 5| Step: 4
Training loss: 0.05030132457613945
Validation loss: 1.4652872098389493

Epoch: 5| Step: 5
Training loss: 0.07539607584476471
Validation loss: 1.467320934418709

Epoch: 5| Step: 6
Training loss: 0.055416565388441086
Validation loss: 1.4479072093963623

Epoch: 5| Step: 7
Training loss: 0.05034901946783066
Validation loss: 1.438249216284803

Epoch: 5| Step: 8
Training loss: 0.03633333370089531
Validation loss: 1.4597768988660587

Epoch: 5| Step: 9
Training loss: 0.05528545379638672
Validation loss: 1.445668367929356

Epoch: 5| Step: 10
Training loss: 0.07881873846054077
Validation loss: 1.4380138266471125

Epoch: 693| Step: 0
Training loss: 0.04797649383544922
Validation loss: 1.4486585586301741

Epoch: 5| Step: 1
Training loss: 0.08596907556056976
Validation loss: 1.4485865632692974

Epoch: 5| Step: 2
Training loss: 0.08361639827489853
Validation loss: 1.4508198063860658

Epoch: 5| Step: 3
Training loss: 0.04914012551307678
Validation loss: 1.4365332267617668

Epoch: 5| Step: 4
Training loss: 0.07109910249710083
Validation loss: 1.4689931215778473

Epoch: 5| Step: 5
Training loss: 0.060279201716184616
Validation loss: 1.448234986233455

Epoch: 5| Step: 6
Training loss: 0.05471860244870186
Validation loss: 1.4354496655925628

Epoch: 5| Step: 7
Training loss: 0.07997506111860275
Validation loss: 1.4394607992582424

Epoch: 5| Step: 8
Training loss: 0.042831528931856155
Validation loss: 1.443977717430361

Epoch: 5| Step: 9
Training loss: 0.08661143481731415
Validation loss: 1.4457870221907092

Epoch: 5| Step: 10
Training loss: 0.030627604573965073
Validation loss: 1.4445663818749048

Epoch: 694| Step: 0
Training loss: 0.06188632920384407
Validation loss: 1.4072048356456142

Epoch: 5| Step: 1
Training loss: 0.03620591014623642
Validation loss: 1.4247969485098315

Epoch: 5| Step: 2
Training loss: 0.0494774654507637
Validation loss: 1.4394465261890041

Epoch: 5| Step: 3
Training loss: 0.058118291199207306
Validation loss: 1.4148123443767588

Epoch: 5| Step: 4
Training loss: 0.08506590127944946
Validation loss: 1.442720478580844

Epoch: 5| Step: 5
Training loss: 0.08472306281328201
Validation loss: 1.4245522586248254

Epoch: 5| Step: 6
Training loss: 0.07337023317813873
Validation loss: 1.3790940142446948

Epoch: 5| Step: 7
Training loss: 0.04222176596522331
Validation loss: 1.3831050037055888

Epoch: 5| Step: 8
Training loss: 0.048392973840236664
Validation loss: 1.376121792742001

Epoch: 5| Step: 9
Training loss: 0.055034421384334564
Validation loss: 1.3799460568735678

Epoch: 5| Step: 10
Training loss: 0.06776978820562363
Validation loss: 1.4005137258960354

Epoch: 695| Step: 0
Training loss: 0.04251591116189957
Validation loss: 1.4072941157125658

Epoch: 5| Step: 1
Training loss: 0.05874340608716011
Validation loss: 1.4025199470981475

Epoch: 5| Step: 2
Training loss: 0.078910693526268
Validation loss: 1.393294092147581

Epoch: 5| Step: 3
Training loss: 0.04472418874502182
Validation loss: 1.4045599763111403

Epoch: 5| Step: 4
Training loss: 0.11253228038549423
Validation loss: 1.4138893581205798

Epoch: 5| Step: 5
Training loss: 0.060415249317884445
Validation loss: 1.4084798097610474

Epoch: 5| Step: 6
Training loss: 0.04111870005726814
Validation loss: 1.4252703958942043

Epoch: 5| Step: 7
Training loss: 0.03716934844851494
Validation loss: 1.4339042568719516

Epoch: 5| Step: 8
Training loss: 0.09010138362646103
Validation loss: 1.4207407043826195

Epoch: 5| Step: 9
Training loss: 0.07104483991861343
Validation loss: 1.436325741070573

Epoch: 5| Step: 10
Training loss: 0.062445592135190964
Validation loss: 1.4391192172163276

Epoch: 696| Step: 0
Training loss: 0.059049297124147415
Validation loss: 1.4165827663995887

Epoch: 5| Step: 1
Training loss: 0.03394912928342819
Validation loss: 1.4133934884942987

Epoch: 5| Step: 2
Training loss: 0.04907817766070366
Validation loss: 1.4214335744098952

Epoch: 5| Step: 3
Training loss: 0.034860093146562576
Validation loss: 1.4169226974569342

Epoch: 5| Step: 4
Training loss: 0.1137845516204834
Validation loss: 1.3912328494492399

Epoch: 5| Step: 5
Training loss: 0.062258101999759674
Validation loss: 1.4189589305590558

Epoch: 5| Step: 6
Training loss: 0.09179934859275818
Validation loss: 1.406557479212361

Epoch: 5| Step: 7
Training loss: 0.051658231765031815
Validation loss: 1.431112225337695

Epoch: 5| Step: 8
Training loss: 0.07896797358989716
Validation loss: 1.4522853769281858

Epoch: 5| Step: 9
Training loss: 0.0843188464641571
Validation loss: 1.474241756623791

Epoch: 5| Step: 10
Training loss: 0.05371863767504692
Validation loss: 1.4550418821714257

Epoch: 697| Step: 0
Training loss: 0.035600412636995316
Validation loss: 1.4796699490598453

Epoch: 5| Step: 1
Training loss: 0.031601887196302414
Validation loss: 1.4670299560792985

Epoch: 5| Step: 2
Training loss: 0.09597817808389664
Validation loss: 1.468896250570974

Epoch: 5| Step: 3
Training loss: 0.051885079592466354
Validation loss: 1.4681187381026566

Epoch: 5| Step: 4
Training loss: 0.048124831169843674
Validation loss: 1.4791440425380584

Epoch: 5| Step: 5
Training loss: 0.08077176660299301
Validation loss: 1.4457669796482209

Epoch: 5| Step: 6
Training loss: 0.09034508466720581
Validation loss: 1.4017956051775204

Epoch: 5| Step: 7
Training loss: 0.05374070256948471
Validation loss: 1.4194951877799085

Epoch: 5| Step: 8
Training loss: 0.06407218426465988
Validation loss: 1.4259487300790765

Epoch: 5| Step: 9
Training loss: 0.055544935166835785
Validation loss: 1.4242708234376804

Epoch: 5| Step: 10
Training loss: 0.039385031908750534
Validation loss: 1.435460727701905

Epoch: 698| Step: 0
Training loss: 0.06302310526371002
Validation loss: 1.4320747108869656

Epoch: 5| Step: 1
Training loss: 0.07294217497110367
Validation loss: 1.41797637426725

Epoch: 5| Step: 2
Training loss: 0.11605699360370636
Validation loss: 1.4181754191716511

Epoch: 5| Step: 3
Training loss: 0.05963730812072754
Validation loss: 1.44024738829623

Epoch: 5| Step: 4
Training loss: 0.06411772221326828
Validation loss: 1.434587896511119

Epoch: 5| Step: 5
Training loss: 0.05664011836051941
Validation loss: 1.4444615123092488

Epoch: 5| Step: 6
Training loss: 0.04499591514468193
Validation loss: 1.4580091507204118

Epoch: 5| Step: 7
Training loss: 0.06521313637495041
Validation loss: 1.4389674663543701

Epoch: 5| Step: 8
Training loss: 0.032515011727809906
Validation loss: 1.4256521988940496

Epoch: 5| Step: 9
Training loss: 0.07080898433923721
Validation loss: 1.4234046756580312

Epoch: 5| Step: 10
Training loss: 0.06357215344905853
Validation loss: 1.4182690792186285

Epoch: 699| Step: 0
Training loss: 0.04257337003946304
Validation loss: 1.4275594206266506

Epoch: 5| Step: 1
Training loss: 0.0775546282529831
Validation loss: 1.4390825712552635

Epoch: 5| Step: 2
Training loss: 0.07250647246837616
Validation loss: 1.4428756313939248

Epoch: 5| Step: 3
Training loss: 0.03735077381134033
Validation loss: 1.4526386145622499

Epoch: 5| Step: 4
Training loss: 0.04192858189344406
Validation loss: 1.4772732168115594

Epoch: 5| Step: 5
Training loss: 0.08200915157794952
Validation loss: 1.4549174539504512

Epoch: 5| Step: 6
Training loss: 0.04128549247980118
Validation loss: 1.4839598824900966

Epoch: 5| Step: 7
Training loss: 0.03685110807418823
Validation loss: 1.4565846407285301

Epoch: 5| Step: 8
Training loss: 0.040498726069927216
Validation loss: 1.4588522065070368

Epoch: 5| Step: 9
Training loss: 0.0779155045747757
Validation loss: 1.469303810468284

Epoch: 5| Step: 10
Training loss: 0.17227822542190552
Validation loss: 1.4768221429599229

Epoch: 700| Step: 0
Training loss: 0.05708178132772446
Validation loss: 1.4534982327492005

Epoch: 5| Step: 1
Training loss: 0.10578064620494843
Validation loss: 1.462087599180078

Epoch: 5| Step: 2
Training loss: 0.045963991433382034
Validation loss: 1.4451948083857054

Epoch: 5| Step: 3
Training loss: 0.044752202928066254
Validation loss: 1.4337760415128482

Epoch: 5| Step: 4
Training loss: 0.052546143531799316
Validation loss: 1.4198062560891593

Epoch: 5| Step: 5
Training loss: 0.03751251846551895
Validation loss: 1.4475310963969077

Epoch: 5| Step: 6
Training loss: 0.09425456821918488
Validation loss: 1.414993272032789

Epoch: 5| Step: 7
Training loss: 0.0412900410592556
Validation loss: 1.4279964265003

Epoch: 5| Step: 8
Training loss: 0.05948251485824585
Validation loss: 1.4309867915286814

Epoch: 5| Step: 9
Training loss: 0.04638143256306648
Validation loss: 1.4294869540840067

Epoch: 5| Step: 10
Training loss: 0.07375110685825348
Validation loss: 1.4626658014071885

Epoch: 701| Step: 0
Training loss: 0.034961409866809845
Validation loss: 1.4328041038205546

Epoch: 5| Step: 1
Training loss: 0.0881197601556778
Validation loss: 1.461194384482599

Epoch: 5| Step: 2
Training loss: 0.11728329956531525
Validation loss: 1.4207513537458194

Epoch: 5| Step: 3
Training loss: 0.10234888643026352
Validation loss: 1.452495469841906

Epoch: 5| Step: 4
Training loss: 0.06037188321352005
Validation loss: 1.415296337937796

Epoch: 5| Step: 5
Training loss: 0.05690481513738632
Validation loss: 1.4318750827543196

Epoch: 5| Step: 6
Training loss: 0.05228719860315323
Validation loss: 1.4146997415891258

Epoch: 5| Step: 7
Training loss: 0.055856674909591675
Validation loss: 1.4271663799080798

Epoch: 5| Step: 8
Training loss: 0.07799732685089111
Validation loss: 1.4114831647565287

Epoch: 5| Step: 9
Training loss: 0.04530378431081772
Validation loss: 1.4158544053313553

Epoch: 5| Step: 10
Training loss: 0.04360207915306091
Validation loss: 1.4257217043189592

Epoch: 702| Step: 0
Training loss: 0.05385404825210571
Validation loss: 1.4348858607712613

Epoch: 5| Step: 1
Training loss: 0.049715738743543625
Validation loss: 1.4287369565297199

Epoch: 5| Step: 2
Training loss: 0.04021741822361946
Validation loss: 1.438317386693852

Epoch: 5| Step: 3
Training loss: 0.08687802404165268
Validation loss: 1.449605962281586

Epoch: 5| Step: 4
Training loss: 0.08061607927083969
Validation loss: 1.4092994607904905

Epoch: 5| Step: 5
Training loss: 0.04191040247678757
Validation loss: 1.4308233440563243

Epoch: 5| Step: 6
Training loss: 0.045836128294467926
Validation loss: 1.4025850071701953

Epoch: 5| Step: 7
Training loss: 0.027644097805023193
Validation loss: 1.4047587956151655

Epoch: 5| Step: 8
Training loss: 0.06437896192073822
Validation loss: 1.418179622260473

Epoch: 5| Step: 9
Training loss: 0.1403389871120453
Validation loss: 1.4119432844141477

Epoch: 5| Step: 10
Training loss: 0.0696391835808754
Validation loss: 1.3966721360401442

Epoch: 703| Step: 0
Training loss: 0.060658879578113556
Validation loss: 1.4109052842663181

Epoch: 5| Step: 1
Training loss: 0.0782250314950943
Validation loss: 1.3952201098524115

Epoch: 5| Step: 2
Training loss: 0.10710646957159042
Validation loss: 1.412215821204647

Epoch: 5| Step: 3
Training loss: 0.0457402765750885
Validation loss: 1.406596451677302

Epoch: 5| Step: 4
Training loss: 0.09913702309131622
Validation loss: 1.4159942557734828

Epoch: 5| Step: 5
Training loss: 0.04191741347312927
Validation loss: 1.3971819339259979

Epoch: 5| Step: 6
Training loss: 0.09277503937482834
Validation loss: 1.4198133202009304

Epoch: 5| Step: 7
Training loss: 0.038742728531360626
Validation loss: 1.4508709702440488

Epoch: 5| Step: 8
Training loss: 0.05751703307032585
Validation loss: 1.4618523063198212

Epoch: 5| Step: 9
Training loss: 0.048888374119997025
Validation loss: 1.453228590308979

Epoch: 5| Step: 10
Training loss: 0.06353062391281128
Validation loss: 1.461081149116639

Epoch: 704| Step: 0
Training loss: 0.08247654139995575
Validation loss: 1.4506574080836387

Epoch: 5| Step: 1
Training loss: 0.035777587443590164
Validation loss: 1.4628610469961678

Epoch: 5| Step: 2
Training loss: 0.06016796827316284
Validation loss: 1.4629392508537538

Epoch: 5| Step: 3
Training loss: 0.049915578216314316
Validation loss: 1.4378248504413071

Epoch: 5| Step: 4
Training loss: 0.0973053127527237
Validation loss: 1.4508191433645063

Epoch: 5| Step: 5
Training loss: 0.058748163282871246
Validation loss: 1.4589839289265294

Epoch: 5| Step: 6
Training loss: 0.03967658057808876
Validation loss: 1.459735038459942

Epoch: 5| Step: 7
Training loss: 0.052318185567855835
Validation loss: 1.4577062155610772

Epoch: 5| Step: 8
Training loss: 0.07936571538448334
Validation loss: 1.461411585089981

Epoch: 5| Step: 9
Training loss: 0.06277812272310257
Validation loss: 1.4400358943529026

Epoch: 5| Step: 10
Training loss: 0.09222180396318436
Validation loss: 1.4254461565325338

Epoch: 705| Step: 0
Training loss: 0.04601914435625076
Validation loss: 1.4192433203420332

Epoch: 5| Step: 1
Training loss: 0.07214643061161041
Validation loss: 1.41744331518809

Epoch: 5| Step: 2
Training loss: 0.06992456316947937
Validation loss: 1.4054067929585774

Epoch: 5| Step: 3
Training loss: 0.06863813102245331
Validation loss: 1.4005092856704549

Epoch: 5| Step: 4
Training loss: 0.039255402982234955
Validation loss: 1.3978207713814192

Epoch: 5| Step: 5
Training loss: 0.07053490728139877
Validation loss: 1.4111650195173038

Epoch: 5| Step: 6
Training loss: 0.10083389282226562
Validation loss: 1.397013084862822

Epoch: 5| Step: 7
Training loss: 0.04018693417310715
Validation loss: 1.4238024232208089

Epoch: 5| Step: 8
Training loss: 0.032591186463832855
Validation loss: 1.4212014380321707

Epoch: 5| Step: 9
Training loss: 0.08172443509101868
Validation loss: 1.429868003373505

Epoch: 5| Step: 10
Training loss: 0.07771194726228714
Validation loss: 1.4507391734789776

Epoch: 706| Step: 0
Training loss: 0.04297270625829697
Validation loss: 1.4314382473627727

Epoch: 5| Step: 1
Training loss: 0.051175348460674286
Validation loss: 1.4582608374216224

Epoch: 5| Step: 2
Training loss: 0.05378132313489914
Validation loss: 1.4424307577071651

Epoch: 5| Step: 3
Training loss: 0.0806121677160263
Validation loss: 1.4274263048684726

Epoch: 5| Step: 4
Training loss: 0.06824992597103119
Validation loss: 1.4474875670607372

Epoch: 5| Step: 5
Training loss: 0.05167060345411301
Validation loss: 1.4275136134957755

Epoch: 5| Step: 6
Training loss: 0.05675484612584114
Validation loss: 1.437122138597632

Epoch: 5| Step: 7
Training loss: 0.07356692850589752
Validation loss: 1.4688338323306012

Epoch: 5| Step: 8
Training loss: 0.049824852496385574
Validation loss: 1.4673816388653171

Epoch: 5| Step: 9
Training loss: 0.04856909066438675
Validation loss: 1.4312377052922403

Epoch: 5| Step: 10
Training loss: 0.09452268481254578
Validation loss: 1.4879730363045969

Epoch: 707| Step: 0
Training loss: 0.09234645217657089
Validation loss: 1.4657911113513413

Epoch: 5| Step: 1
Training loss: 0.03592550754547119
Validation loss: 1.435070582615432

Epoch: 5| Step: 2
Training loss: 0.059459470212459564
Validation loss: 1.427780556422408

Epoch: 5| Step: 3
Training loss: 0.06877315789461136
Validation loss: 1.426668450396548

Epoch: 5| Step: 4
Training loss: 0.07357201725244522
Validation loss: 1.4128312090391755

Epoch: 5| Step: 5
Training loss: 0.09376970678567886
Validation loss: 1.428318073672633

Epoch: 5| Step: 6
Training loss: 0.07682832330465317
Validation loss: 1.4104818631243963

Epoch: 5| Step: 7
Training loss: 0.04892818629741669
Validation loss: 1.4037299425371232

Epoch: 5| Step: 8
Training loss: 0.05251495912671089
Validation loss: 1.4345301748603903

Epoch: 5| Step: 9
Training loss: 0.05931951478123665
Validation loss: 1.4262869486244776

Epoch: 5| Step: 10
Training loss: 0.1539439857006073
Validation loss: 1.4450626334836405

Epoch: 708| Step: 0
Training loss: 0.07948831468820572
Validation loss: 1.4656630011015042

Epoch: 5| Step: 1
Training loss: 0.05886918306350708
Validation loss: 1.4841958258741645

Epoch: 5| Step: 2
Training loss: 0.08856464177370071
Validation loss: 1.5138291671711912

Epoch: 5| Step: 3
Training loss: 0.055498700588941574
Validation loss: 1.4990661951803392

Epoch: 5| Step: 4
Training loss: 0.12648430466651917
Validation loss: 1.5360312897671935

Epoch: 5| Step: 5
Training loss: 0.10890483856201172
Validation loss: 1.5564552186637797

Epoch: 5| Step: 6
Training loss: 0.13261038064956665
Validation loss: 1.5275924923599407

Epoch: 5| Step: 7
Training loss: 0.09580174088478088
Validation loss: 1.4876648610638035

Epoch: 5| Step: 8
Training loss: 0.08740291744470596
Validation loss: 1.4508823399902673

Epoch: 5| Step: 9
Training loss: 0.04831244796514511
Validation loss: 1.416225133403655

Epoch: 5| Step: 10
Training loss: 0.13240866363048553
Validation loss: 1.425794993677447

Epoch: 709| Step: 0
Training loss: 0.14295229315757751
Validation loss: 1.4252278932961084

Epoch: 5| Step: 1
Training loss: 0.09570817649364471
Validation loss: 1.4215103669833111

Epoch: 5| Step: 2
Training loss: 0.11808862537145615
Validation loss: 1.4273213590345075

Epoch: 5| Step: 3
Training loss: 0.0618576779961586
Validation loss: 1.4112164538393739

Epoch: 5| Step: 4
Training loss: 0.04682786390185356
Validation loss: 1.4224915068636659

Epoch: 5| Step: 5
Training loss: 0.12281005084514618
Validation loss: 1.437222570501348

Epoch: 5| Step: 6
Training loss: 0.0387909933924675
Validation loss: 1.4425965175833753

Epoch: 5| Step: 7
Training loss: 0.11642098426818848
Validation loss: 1.469936296504031

Epoch: 5| Step: 8
Training loss: 0.05545073747634888
Validation loss: 1.4597717382574593

Epoch: 5| Step: 9
Training loss: 0.0714750736951828
Validation loss: 1.459702632760489

Epoch: 5| Step: 10
Training loss: 0.07380634546279907
Validation loss: 1.4406381576291976

Epoch: 710| Step: 0
Training loss: 0.08617372065782547
Validation loss: 1.4155093572473014

Epoch: 5| Step: 1
Training loss: 0.08359501510858536
Validation loss: 1.387005259913783

Epoch: 5| Step: 2
Training loss: 0.06472928076982498
Validation loss: 1.4091529448827107

Epoch: 5| Step: 3
Training loss: 0.08592768758535385
Validation loss: 1.3855399008720153

Epoch: 5| Step: 4
Training loss: 0.07069195061922073
Validation loss: 1.4402990514232266

Epoch: 5| Step: 5
Training loss: 0.09592441469430923
Validation loss: 1.438092258668715

Epoch: 5| Step: 6
Training loss: 0.08162855356931686
Validation loss: 1.442520861984581

Epoch: 5| Step: 7
Training loss: 0.08473969995975494
Validation loss: 1.4823718263256935

Epoch: 5| Step: 8
Training loss: 0.05316963046789169
Validation loss: 1.46519124379722

Epoch: 5| Step: 9
Training loss: 0.04792073369026184
Validation loss: 1.4642207955801358

Epoch: 5| Step: 10
Training loss: 0.06852319836616516
Validation loss: 1.5113840904287112

Epoch: 711| Step: 0
Training loss: 0.08846335858106613
Validation loss: 1.4717075036418052

Epoch: 5| Step: 1
Training loss: 0.038768164813518524
Validation loss: 1.455953449331304

Epoch: 5| Step: 2
Training loss: 0.05386553332209587
Validation loss: 1.461848230772121

Epoch: 5| Step: 3
Training loss: 0.05652459338307381
Validation loss: 1.4290017229254528

Epoch: 5| Step: 4
Training loss: 0.062115054577589035
Validation loss: 1.4283835477726434

Epoch: 5| Step: 5
Training loss: 0.05751510709524155
Validation loss: 1.4119496806975333

Epoch: 5| Step: 6
Training loss: 0.0846640020608902
Validation loss: 1.4149542354768323

Epoch: 5| Step: 7
Training loss: 0.0697140246629715
Validation loss: 1.4167188982809744

Epoch: 5| Step: 8
Training loss: 0.09362906962633133
Validation loss: 1.4253856084680046

Epoch: 5| Step: 9
Training loss: 0.10110096633434296
Validation loss: 1.4017240744765087

Epoch: 5| Step: 10
Training loss: 0.04865904524922371
Validation loss: 1.4365018939459195

Epoch: 712| Step: 0
Training loss: 0.059969544410705566
Validation loss: 1.4267756785115888

Epoch: 5| Step: 1
Training loss: 0.06603613495826721
Validation loss: 1.4439867875909294

Epoch: 5| Step: 2
Training loss: 0.045914195477962494
Validation loss: 1.4585043198318892

Epoch: 5| Step: 3
Training loss: 0.08146211504936218
Validation loss: 1.423078151159389

Epoch: 5| Step: 4
Training loss: 0.07893436402082443
Validation loss: 1.3804797523765153

Epoch: 5| Step: 5
Training loss: 0.04342302680015564
Validation loss: 1.3883885234914801

Epoch: 5| Step: 6
Training loss: 0.06888499855995178
Validation loss: 1.3866355342249717

Epoch: 5| Step: 7
Training loss: 0.056716836988925934
Validation loss: 1.376708253737419

Epoch: 5| Step: 8
Training loss: 0.06405501067638397
Validation loss: 1.3825390313261299

Epoch: 5| Step: 9
Training loss: 0.06498788297176361
Validation loss: 1.3866775599859094

Epoch: 5| Step: 10
Training loss: 0.1240287497639656
Validation loss: 1.3939795878625685

Epoch: 713| Step: 0
Training loss: 0.067856565117836
Validation loss: 1.4162100925240466

Epoch: 5| Step: 1
Training loss: 0.05295636132359505
Validation loss: 1.4262399788825744

Epoch: 5| Step: 2
Training loss: 0.05768587440252304
Validation loss: 1.4242324188191404

Epoch: 5| Step: 3
Training loss: 0.059139180928468704
Validation loss: 1.4183206224954257

Epoch: 5| Step: 4
Training loss: 0.07721260190010071
Validation loss: 1.4683996644071353

Epoch: 5| Step: 5
Training loss: 0.05880197137594223
Validation loss: 1.4393318904343473

Epoch: 5| Step: 6
Training loss: 0.06477988511323929
Validation loss: 1.4425214214991497

Epoch: 5| Step: 7
Training loss: 0.06506933271884918
Validation loss: 1.4237913963615254

Epoch: 5| Step: 8
Training loss: 0.08746374398469925
Validation loss: 1.4313013989438292

Epoch: 5| Step: 9
Training loss: 0.07325881719589233
Validation loss: 1.4144540704706663

Epoch: 5| Step: 10
Training loss: 0.03996897116303444
Validation loss: 1.4002561184667772

Epoch: 714| Step: 0
Training loss: 0.05744551867246628
Validation loss: 1.389833245226132

Epoch: 5| Step: 1
Training loss: 0.09449414908885956
Validation loss: 1.3850383726499413

Epoch: 5| Step: 2
Training loss: 0.06391733884811401
Validation loss: 1.3955361971291163

Epoch: 5| Step: 3
Training loss: 0.04654454439878464
Validation loss: 1.4085369225471251

Epoch: 5| Step: 4
Training loss: 0.07780681550502777
Validation loss: 1.3977278483811246

Epoch: 5| Step: 5
Training loss: 0.04241851717233658
Validation loss: 1.3985351567627282

Epoch: 5| Step: 6
Training loss: 0.06875164806842804
Validation loss: 1.4145262497727589

Epoch: 5| Step: 7
Training loss: 0.034250903874635696
Validation loss: 1.409973302195149

Epoch: 5| Step: 8
Training loss: 0.059629715979099274
Validation loss: 1.402237496709311

Epoch: 5| Step: 9
Training loss: 0.042696304619312286
Validation loss: 1.4056549559357345

Epoch: 5| Step: 10
Training loss: 0.0397135429084301
Validation loss: 1.4077968264138827

Epoch: 715| Step: 0
Training loss: 0.07959073036909103
Validation loss: 1.4126745622645143

Epoch: 5| Step: 1
Training loss: 0.04739845544099808
Validation loss: 1.4267163776582288

Epoch: 5| Step: 2
Training loss: 0.05503410845994949
Validation loss: 1.417055663242135

Epoch: 5| Step: 3
Training loss: 0.04894283786416054
Validation loss: 1.4423133775752077

Epoch: 5| Step: 4
Training loss: 0.08162800967693329
Validation loss: 1.4760097354970954

Epoch: 5| Step: 5
Training loss: 0.07706564664840698
Validation loss: 1.4649227972953551

Epoch: 5| Step: 6
Training loss: 0.10209059715270996
Validation loss: 1.432006020699778

Epoch: 5| Step: 7
Training loss: 0.09800554811954498
Validation loss: 1.4445788706502607

Epoch: 5| Step: 8
Training loss: 0.04485980421304703
Validation loss: 1.4358965594281432

Epoch: 5| Step: 9
Training loss: 0.07312674820423126
Validation loss: 1.4190263453350271

Epoch: 5| Step: 10
Training loss: 0.05800579488277435
Validation loss: 1.3955326849414456

Epoch: 716| Step: 0
Training loss: 0.05087703466415405
Validation loss: 1.4043604981514715

Epoch: 5| Step: 1
Training loss: 0.0842328816652298
Validation loss: 1.4079434102581394

Epoch: 5| Step: 2
Training loss: 0.0825314074754715
Validation loss: 1.4215897372973862

Epoch: 5| Step: 3
Training loss: 0.057847268879413605
Validation loss: 1.4042646218371648

Epoch: 5| Step: 4
Training loss: 0.07341155409812927
Validation loss: 1.4204587923583163

Epoch: 5| Step: 5
Training loss: 0.0877937525510788
Validation loss: 1.4054397677862516

Epoch: 5| Step: 6
Training loss: 0.04635099321603775
Validation loss: 1.413944980149628

Epoch: 5| Step: 7
Training loss: 0.06252893805503845
Validation loss: 1.4310214083681825

Epoch: 5| Step: 8
Training loss: 0.030147066339850426
Validation loss: 1.4057996196131552

Epoch: 5| Step: 9
Training loss: 0.056996364146471024
Validation loss: 1.4146267816584597

Epoch: 5| Step: 10
Training loss: 0.034522078931331635
Validation loss: 1.378166853740651

Epoch: 717| Step: 0
Training loss: 0.04966273158788681
Validation loss: 1.383149540552529

Epoch: 5| Step: 1
Training loss: 0.06925737857818604
Validation loss: 1.3934608024935569

Epoch: 5| Step: 2
Training loss: 0.06024240329861641
Validation loss: 1.393174353466239

Epoch: 5| Step: 3
Training loss: 0.10043780505657196
Validation loss: 1.4224448985950922

Epoch: 5| Step: 4
Training loss: 0.06291910260915756
Validation loss: 1.419792554711783

Epoch: 5| Step: 5
Training loss: 0.04136450216174126
Validation loss: 1.4262985849893222

Epoch: 5| Step: 6
Training loss: 0.05368674546480179
Validation loss: 1.4139583674810265

Epoch: 5| Step: 7
Training loss: 0.07468462735414505
Validation loss: 1.4350715901262017

Epoch: 5| Step: 8
Training loss: 0.045823656022548676
Validation loss: 1.4238770443906066

Epoch: 5| Step: 9
Training loss: 0.053999580442905426
Validation loss: 1.4355160241485925

Epoch: 5| Step: 10
Training loss: 0.026334406808018684
Validation loss: 1.4346583645830873

Epoch: 718| Step: 0
Training loss: 0.07982268184423447
Validation loss: 1.4345706444914623

Epoch: 5| Step: 1
Training loss: 0.05218852683901787
Validation loss: 1.4668904863378054

Epoch: 5| Step: 2
Training loss: 0.05491698905825615
Validation loss: 1.4399604617908437

Epoch: 5| Step: 3
Training loss: 0.08148515224456787
Validation loss: 1.446196209999823

Epoch: 5| Step: 4
Training loss: 0.05139341205358505
Validation loss: 1.4457644390803512

Epoch: 5| Step: 5
Training loss: 0.08978942781686783
Validation loss: 1.42766732938828

Epoch: 5| Step: 6
Training loss: 0.05906683951616287
Validation loss: 1.4360535119169502

Epoch: 5| Step: 7
Training loss: 0.040496520698070526
Validation loss: 1.4295006298249768

Epoch: 5| Step: 8
Training loss: 0.040773600339889526
Validation loss: 1.4189059266480066

Epoch: 5| Step: 9
Training loss: 0.05934784561395645
Validation loss: 1.4218283673768402

Epoch: 5| Step: 10
Training loss: 0.07497622072696686
Validation loss: 1.426572056226833

Epoch: 719| Step: 0
Training loss: 0.03754445165395737
Validation loss: 1.3925393307080833

Epoch: 5| Step: 1
Training loss: 0.03440945968031883
Validation loss: 1.4050817694715274

Epoch: 5| Step: 2
Training loss: 0.04139374941587448
Validation loss: 1.4157919473545526

Epoch: 5| Step: 3
Training loss: 0.045763928443193436
Validation loss: 1.4052526591926493

Epoch: 5| Step: 4
Training loss: 0.09085266292095184
Validation loss: 1.4123441532093992

Epoch: 5| Step: 5
Training loss: 0.11457119137048721
Validation loss: 1.420140254882074

Epoch: 5| Step: 6
Training loss: 0.07310275733470917
Validation loss: 1.4344309670950777

Epoch: 5| Step: 7
Training loss: 0.03976712003350258
Validation loss: 1.4282383444488689

Epoch: 5| Step: 8
Training loss: 0.05004926770925522
Validation loss: 1.4205178150566675

Epoch: 5| Step: 9
Training loss: 0.048497091978788376
Validation loss: 1.4119762361690562

Epoch: 5| Step: 10
Training loss: 0.06109483912587166
Validation loss: 1.428764594498501

Epoch: 720| Step: 0
Training loss: 0.05683194845914841
Validation loss: 1.4213003266242243

Epoch: 5| Step: 1
Training loss: 0.07711172848939896
Validation loss: 1.4253888937734789

Epoch: 5| Step: 2
Training loss: 0.09056110680103302
Validation loss: 1.428006011952636

Epoch: 5| Step: 3
Training loss: 0.08191189914941788
Validation loss: 1.4606885128123785

Epoch: 5| Step: 4
Training loss: 0.0570652075111866
Validation loss: 1.4539402787403395

Epoch: 5| Step: 5
Training loss: 0.07231877744197845
Validation loss: 1.4591542956649617

Epoch: 5| Step: 6
Training loss: 0.10059865564107895
Validation loss: 1.452302986575711

Epoch: 5| Step: 7
Training loss: 0.06660568714141846
Validation loss: 1.4365383566066783

Epoch: 5| Step: 8
Training loss: 0.033246684819459915
Validation loss: 1.4568368017032582

Epoch: 5| Step: 9
Training loss: 0.04860859364271164
Validation loss: 1.434386686612201

Epoch: 5| Step: 10
Training loss: 0.03775846213102341
Validation loss: 1.4198759653234994

Epoch: 721| Step: 0
Training loss: 0.08285264670848846
Validation loss: 1.4171043121686546

Epoch: 5| Step: 1
Training loss: 0.05877374857664108
Validation loss: 1.4295784619546705

Epoch: 5| Step: 2
Training loss: 0.09543878585100174
Validation loss: 1.4055278916512766

Epoch: 5| Step: 3
Training loss: 0.06509481370449066
Validation loss: 1.4148178074949531

Epoch: 5| Step: 4
Training loss: 0.05096173286437988
Validation loss: 1.4273354814898582

Epoch: 5| Step: 5
Training loss: 0.029354143887758255
Validation loss: 1.4185235692608742

Epoch: 5| Step: 6
Training loss: 0.06614869832992554
Validation loss: 1.4327124088041243

Epoch: 5| Step: 7
Training loss: 0.04814435541629791
Validation loss: 1.420253344761428

Epoch: 5| Step: 8
Training loss: 0.05250633507966995
Validation loss: 1.4127013170590965

Epoch: 5| Step: 9
Training loss: 0.07051520049571991
Validation loss: 1.4183539716146325

Epoch: 5| Step: 10
Training loss: 0.0723995640873909
Validation loss: 1.4282708116756972

Epoch: 722| Step: 0
Training loss: 0.07356666028499603
Validation loss: 1.4170255314919256

Epoch: 5| Step: 1
Training loss: 0.05691242218017578
Validation loss: 1.4035517002946587

Epoch: 5| Step: 2
Training loss: 0.06709427386522293
Validation loss: 1.3970106808088159

Epoch: 5| Step: 3
Training loss: 0.0397643968462944
Validation loss: 1.3913775105630197

Epoch: 5| Step: 4
Training loss: 0.05454520508646965
Validation loss: 1.3801172651270384

Epoch: 5| Step: 5
Training loss: 0.10254766792058945
Validation loss: 1.3946596037956975

Epoch: 5| Step: 6
Training loss: 0.05397805571556091
Validation loss: 1.4081728522495558

Epoch: 5| Step: 7
Training loss: 0.04085337370634079
Validation loss: 1.4068985895443988

Epoch: 5| Step: 8
Training loss: 0.05838987976312637
Validation loss: 1.43552105657516

Epoch: 5| Step: 9
Training loss: 0.06782397627830505
Validation loss: 1.4374725318724109

Epoch: 5| Step: 10
Training loss: 0.06615083664655685
Validation loss: 1.4132149937332317

Epoch: 723| Step: 0
Training loss: 0.0626663938164711
Validation loss: 1.4100151638830862

Epoch: 5| Step: 1
Training loss: 0.06898380070924759
Validation loss: 1.420498392915213

Epoch: 5| Step: 2
Training loss: 0.0919235348701477
Validation loss: 1.4276095231374104

Epoch: 5| Step: 3
Training loss: 0.09272225201129913
Validation loss: 1.4243459586174256

Epoch: 5| Step: 4
Training loss: 0.07536957412958145
Validation loss: 1.4052818359867219

Epoch: 5| Step: 5
Training loss: 0.07887054979801178
Validation loss: 1.4125635290658602

Epoch: 5| Step: 6
Training loss: 0.048291321843862534
Validation loss: 1.3940742413202922

Epoch: 5| Step: 7
Training loss: 0.053201913833618164
Validation loss: 1.403022248257873

Epoch: 5| Step: 8
Training loss: 0.04686736315488815
Validation loss: 1.4085637395099928

Epoch: 5| Step: 9
Training loss: 0.0917542576789856
Validation loss: 1.4161925764494045

Epoch: 5| Step: 10
Training loss: 0.07497024536132812
Validation loss: 1.442408944970818

Epoch: 724| Step: 0
Training loss: 0.08463757485151291
Validation loss: 1.4645414519053634

Epoch: 5| Step: 1
Training loss: 0.09903769195079803
Validation loss: 1.4503765413838048

Epoch: 5| Step: 2
Training loss: 0.0859217494726181
Validation loss: 1.4370399546879593

Epoch: 5| Step: 3
Training loss: 0.03690130263566971
Validation loss: 1.452958430013349

Epoch: 5| Step: 4
Training loss: 0.04612679407000542
Validation loss: 1.4337612582791237

Epoch: 5| Step: 5
Training loss: 0.05839577317237854
Validation loss: 1.4140419729294316

Epoch: 5| Step: 6
Training loss: 0.05188906192779541
Validation loss: 1.4344332102806336

Epoch: 5| Step: 7
Training loss: 0.11234290897846222
Validation loss: 1.4394988577852967

Epoch: 5| Step: 8
Training loss: 0.07348974049091339
Validation loss: 1.4356442677077426

Epoch: 5| Step: 9
Training loss: 0.0811973288655281
Validation loss: 1.4210436741511028

Epoch: 5| Step: 10
Training loss: 0.050899725407361984
Validation loss: 1.4363702945811774

Epoch: 725| Step: 0
Training loss: 0.06561587005853653
Validation loss: 1.4309892192963631

Epoch: 5| Step: 1
Training loss: 0.05880765989422798
Validation loss: 1.4252568547443678

Epoch: 5| Step: 2
Training loss: 0.0996011346578598
Validation loss: 1.446117188340874

Epoch: 5| Step: 3
Training loss: 0.04145435243844986
Validation loss: 1.437547194060459

Epoch: 5| Step: 4
Training loss: 0.04280480742454529
Validation loss: 1.4136158830376082

Epoch: 5| Step: 5
Training loss: 0.08811001479625702
Validation loss: 1.4161324718947053

Epoch: 5| Step: 6
Training loss: 0.07191507518291473
Validation loss: 1.4336187519052976

Epoch: 5| Step: 7
Training loss: 0.06278036534786224
Validation loss: 1.4267134153714744

Epoch: 5| Step: 8
Training loss: 0.05391081050038338
Validation loss: 1.4311112703815583

Epoch: 5| Step: 9
Training loss: 0.1279463917016983
Validation loss: 1.4192427960775231

Epoch: 5| Step: 10
Training loss: 0.060932427644729614
Validation loss: 1.4368793695203719

Epoch: 726| Step: 0
Training loss: 0.03865746781229973
Validation loss: 1.448918398990426

Epoch: 5| Step: 1
Training loss: 0.053884852677583694
Validation loss: 1.4598479706753966

Epoch: 5| Step: 2
Training loss: 0.0654376894235611
Validation loss: 1.452813284371489

Epoch: 5| Step: 3
Training loss: 0.13135769963264465
Validation loss: 1.4486484950588596

Epoch: 5| Step: 4
Training loss: 0.07843415439128876
Validation loss: 1.4653086713565293

Epoch: 5| Step: 5
Training loss: 0.02926257811486721
Validation loss: 1.4560975682350896

Epoch: 5| Step: 6
Training loss: 0.05411452054977417
Validation loss: 1.446012226484155

Epoch: 5| Step: 7
Training loss: 0.06996561586856842
Validation loss: 1.4251238120499479

Epoch: 5| Step: 8
Training loss: 0.06127847358584404
Validation loss: 1.4211958082773353

Epoch: 5| Step: 9
Training loss: 0.06062489002943039
Validation loss: 1.4128360472699648

Epoch: 5| Step: 10
Training loss: 0.04787570610642433
Validation loss: 1.4147567736205233

Epoch: 727| Step: 0
Training loss: 0.08359301090240479
Validation loss: 1.4386324395415604

Epoch: 5| Step: 1
Training loss: 0.061337947845458984
Validation loss: 1.408317824845673

Epoch: 5| Step: 2
Training loss: 0.06810518354177475
Validation loss: 1.4107189024648359

Epoch: 5| Step: 3
Training loss: 0.04478616267442703
Validation loss: 1.4029278063005017

Epoch: 5| Step: 4
Training loss: 0.06755424290895462
Validation loss: 1.3784219616202897

Epoch: 5| Step: 5
Training loss: 0.1007772833108902
Validation loss: 1.387449174798945

Epoch: 5| Step: 6
Training loss: 0.05134767293930054
Validation loss: 1.396823485692342

Epoch: 5| Step: 7
Training loss: 0.058810632675886154
Validation loss: 1.4224148376654553

Epoch: 5| Step: 8
Training loss: 0.05386178568005562
Validation loss: 1.3994896424713956

Epoch: 5| Step: 9
Training loss: 0.04758169874548912
Validation loss: 1.429525585584743

Epoch: 5| Step: 10
Training loss: 0.029742121696472168
Validation loss: 1.4238197970133957

Epoch: 728| Step: 0
Training loss: 0.06667375564575195
Validation loss: 1.4173874816586893

Epoch: 5| Step: 1
Training loss: 0.10355372726917267
Validation loss: 1.423265311025804

Epoch: 5| Step: 2
Training loss: 0.042595427483320236
Validation loss: 1.4140626704821022

Epoch: 5| Step: 3
Training loss: 0.05685444921255112
Validation loss: 1.4092031102026663

Epoch: 5| Step: 4
Training loss: 0.05894837900996208
Validation loss: 1.3945412148711502

Epoch: 5| Step: 5
Training loss: 0.09586168080568314
Validation loss: 1.396266350182154

Epoch: 5| Step: 6
Training loss: 0.08501836657524109
Validation loss: 1.3818540496210898

Epoch: 5| Step: 7
Training loss: 0.05598391219973564
Validation loss: 1.4019956896381993

Epoch: 5| Step: 8
Training loss: 0.038216717541217804
Validation loss: 1.3955462709549935

Epoch: 5| Step: 9
Training loss: 0.0514054074883461
Validation loss: 1.400731276440364

Epoch: 5| Step: 10
Training loss: 0.07736129313707352
Validation loss: 1.43521664732246

Epoch: 729| Step: 0
Training loss: 0.06271710246801376
Validation loss: 1.414493441581726

Epoch: 5| Step: 1
Training loss: 0.037475768476724625
Validation loss: 1.4097956816355388

Epoch: 5| Step: 2
Training loss: 0.11686929315328598
Validation loss: 1.4257237142132175

Epoch: 5| Step: 3
Training loss: 0.06892319023609161
Validation loss: 1.4046229726524764

Epoch: 5| Step: 4
Training loss: 0.05505729839205742
Validation loss: 1.4118326581934446

Epoch: 5| Step: 5
Training loss: 0.10586957633495331
Validation loss: 1.422616797108804

Epoch: 5| Step: 6
Training loss: 0.04426556080579758
Validation loss: 1.4096544558002102

Epoch: 5| Step: 7
Training loss: 0.054985880851745605
Validation loss: 1.3901598748340402

Epoch: 5| Step: 8
Training loss: 0.04528326913714409
Validation loss: 1.4182785211070892

Epoch: 5| Step: 9
Training loss: 0.06899525225162506
Validation loss: 1.4018739936172322

Epoch: 5| Step: 10
Training loss: 0.05067344754934311
Validation loss: 1.4264207014473536

Epoch: 730| Step: 0
Training loss: 0.03524588793516159
Validation loss: 1.4223212721527263

Epoch: 5| Step: 1
Training loss: 0.06989497691392899
Validation loss: 1.424333050686826

Epoch: 5| Step: 2
Training loss: 0.0724710002541542
Validation loss: 1.438032563014697

Epoch: 5| Step: 3
Training loss: 0.045699458569288254
Validation loss: 1.4445371973899104

Epoch: 5| Step: 4
Training loss: 0.03742397949099541
Validation loss: 1.4691024358554552

Epoch: 5| Step: 5
Training loss: 0.05161052942276001
Validation loss: 1.477210912653195

Epoch: 5| Step: 6
Training loss: 0.048638831824064255
Validation loss: 1.5058912288758062

Epoch: 5| Step: 7
Training loss: 0.048668064177036285
Validation loss: 1.443766397814597

Epoch: 5| Step: 8
Training loss: 0.02910573221743107
Validation loss: 1.4164459961716847

Epoch: 5| Step: 9
Training loss: 0.11421351134777069
Validation loss: 1.4042721486860705

Epoch: 5| Step: 10
Training loss: 0.10969700664281845
Validation loss: 1.4090438158281389

Epoch: 731| Step: 0
Training loss: 0.07304669916629791
Validation loss: 1.4300723627049436

Epoch: 5| Step: 1
Training loss: 0.07380141317844391
Validation loss: 1.41639083175249

Epoch: 5| Step: 2
Training loss: 0.04798073321580887
Validation loss: 1.4063887019311228

Epoch: 5| Step: 3
Training loss: 0.04475109651684761
Validation loss: 1.3960883053400184

Epoch: 5| Step: 4
Training loss: 0.1150304526090622
Validation loss: 1.3961262138940955

Epoch: 5| Step: 5
Training loss: 0.04575933888554573
Validation loss: 1.43125654292363

Epoch: 5| Step: 6
Training loss: 0.05521813780069351
Validation loss: 1.4756711336874193

Epoch: 5| Step: 7
Training loss: 0.04805073142051697
Validation loss: 1.4920314768309235

Epoch: 5| Step: 8
Training loss: 0.11216442286968231
Validation loss: 1.4952355674518052

Epoch: 5| Step: 9
Training loss: 0.039537422358989716
Validation loss: 1.4629120288356658

Epoch: 5| Step: 10
Training loss: 0.047766830772161484
Validation loss: 1.4404327318232546

Epoch: 732| Step: 0
Training loss: 0.05455131456255913
Validation loss: 1.4250041592505671

Epoch: 5| Step: 1
Training loss: 0.06072695925831795
Validation loss: 1.4283534749861686

Epoch: 5| Step: 2
Training loss: 0.06312558799982071
Validation loss: 1.413149477333151

Epoch: 5| Step: 3
Training loss: 0.10227252542972565
Validation loss: 1.4164015618703698

Epoch: 5| Step: 4
Training loss: 0.08460184186697006
Validation loss: 1.3697397926802277

Epoch: 5| Step: 5
Training loss: 0.09963703900575638
Validation loss: 1.3966048840553529

Epoch: 5| Step: 6
Training loss: 0.1398053616285324
Validation loss: 1.3853769174186132

Epoch: 5| Step: 7
Training loss: 0.07447593659162521
Validation loss: 1.39174384263254

Epoch: 5| Step: 8
Training loss: 0.07044718414545059
Validation loss: 1.4024296499067737

Epoch: 5| Step: 9
Training loss: 0.07871147245168686
Validation loss: 1.433914069206484

Epoch: 5| Step: 10
Training loss: 0.06417559087276459
Validation loss: 1.4205318484255063

Epoch: 733| Step: 0
Training loss: 0.07158733159303665
Validation loss: 1.4201395896173292

Epoch: 5| Step: 1
Training loss: 0.0796465203166008
Validation loss: 1.3972684664110984

Epoch: 5| Step: 2
Training loss: 0.09472180902957916
Validation loss: 1.3829674092672204

Epoch: 5| Step: 3
Training loss: 0.05787644535303116
Validation loss: 1.4142261038544357

Epoch: 5| Step: 4
Training loss: 0.08542138338088989
Validation loss: 1.3689161513441352

Epoch: 5| Step: 5
Training loss: 0.08142789453268051
Validation loss: 1.3924598578483827

Epoch: 5| Step: 6
Training loss: 0.04996497556567192
Validation loss: 1.4164614177519275

Epoch: 5| Step: 7
Training loss: 0.07542645186185837
Validation loss: 1.42005871060074

Epoch: 5| Step: 8
Training loss: 0.04563933238387108
Validation loss: 1.4457589285348051

Epoch: 5| Step: 9
Training loss: 0.08552592992782593
Validation loss: 1.4514652759798112

Epoch: 5| Step: 10
Training loss: 0.057357292622327805
Validation loss: 1.4683519089093773

Epoch: 734| Step: 0
Training loss: 0.04361201450228691
Validation loss: 1.485737895452848

Epoch: 5| Step: 1
Training loss: 0.11164162307977676
Validation loss: 1.4970713475699067

Epoch: 5| Step: 2
Training loss: 0.051196493208408356
Validation loss: 1.459807962499639

Epoch: 5| Step: 3
Training loss: 0.03659271076321602
Validation loss: 1.458198348681132

Epoch: 5| Step: 4
Training loss: 0.04170572757720947
Validation loss: 1.4230490794745825

Epoch: 5| Step: 5
Training loss: 0.07627326250076294
Validation loss: 1.4217455976752824

Epoch: 5| Step: 6
Training loss: 0.06115921586751938
Validation loss: 1.3950855680691299

Epoch: 5| Step: 7
Training loss: 0.03393018990755081
Validation loss: 1.3859179314746652

Epoch: 5| Step: 8
Training loss: 0.060439951717853546
Validation loss: 1.3950328698722265

Epoch: 5| Step: 9
Training loss: 0.06651848554611206
Validation loss: 1.393788924781225

Epoch: 5| Step: 10
Training loss: 0.07516096532344818
Validation loss: 1.4155518957363662

Epoch: 735| Step: 0
Training loss: 0.050950050354003906
Validation loss: 1.4325735569000244

Epoch: 5| Step: 1
Training loss: 0.06069058179855347
Validation loss: 1.4352608380779144

Epoch: 5| Step: 2
Training loss: 0.07783033698797226
Validation loss: 1.4573389926264364

Epoch: 5| Step: 3
Training loss: 0.09037064015865326
Validation loss: 1.4290266921443324

Epoch: 5| Step: 4
Training loss: 0.12285777181386948
Validation loss: 1.4264790127354283

Epoch: 5| Step: 5
Training loss: 0.08270277082920074
Validation loss: 1.4323680657212452

Epoch: 5| Step: 6
Training loss: 0.07259634882211685
Validation loss: 1.4153260095145113

Epoch: 5| Step: 7
Training loss: 0.04313429445028305
Validation loss: 1.4320988091089393

Epoch: 5| Step: 8
Training loss: 0.06707504391670227
Validation loss: 1.4200967973278416

Epoch: 5| Step: 9
Training loss: 0.08492524921894073
Validation loss: 1.4217067617242054

Epoch: 5| Step: 10
Training loss: 0.060598667711019516
Validation loss: 1.4011916672029803

Epoch: 736| Step: 0
Training loss: 0.07917726784944534
Validation loss: 1.3950736996948079

Epoch: 5| Step: 1
Training loss: 0.06532839685678482
Validation loss: 1.3983882832270798

Epoch: 5| Step: 2
Training loss: 0.11528396606445312
Validation loss: 1.4363812387630503

Epoch: 5| Step: 3
Training loss: 0.11667218059301376
Validation loss: 1.4267247146175754

Epoch: 5| Step: 4
Training loss: 0.055322159081697464
Validation loss: 1.434912891798122

Epoch: 5| Step: 5
Training loss: 0.07062628120183945
Validation loss: 1.4445676124224098

Epoch: 5| Step: 6
Training loss: 0.08729580789804459
Validation loss: 1.4227078230150285

Epoch: 5| Step: 7
Training loss: 0.07108823210000992
Validation loss: 1.4276442091952088

Epoch: 5| Step: 8
Training loss: 0.0679696649312973
Validation loss: 1.4353693198132258

Epoch: 5| Step: 9
Training loss: 0.0973992794752121
Validation loss: 1.3924308002635997

Epoch: 5| Step: 10
Training loss: 0.07613664865493774
Validation loss: 1.374053639750327

Epoch: 737| Step: 0
Training loss: 0.04122451692819595
Validation loss: 1.386638577266406

Epoch: 5| Step: 1
Training loss: 0.08792491257190704
Validation loss: 1.3799441770840717

Epoch: 5| Step: 2
Training loss: 0.08038798719644547
Validation loss: 1.3778092989357569

Epoch: 5| Step: 3
Training loss: 0.08106119185686111
Validation loss: 1.3761358620018087

Epoch: 5| Step: 4
Training loss: 0.044397853314876556
Validation loss: 1.3838992464926936

Epoch: 5| Step: 5
Training loss: 0.051606662571430206
Validation loss: 1.3772399874143704

Epoch: 5| Step: 6
Training loss: 0.07949390262365341
Validation loss: 1.4097275990311817

Epoch: 5| Step: 7
Training loss: 0.08015397936105728
Validation loss: 1.4135391199460594

Epoch: 5| Step: 8
Training loss: 0.07385564595460892
Validation loss: 1.427269588234604

Epoch: 5| Step: 9
Training loss: 0.06982014328241348
Validation loss: 1.4259178497458016

Epoch: 5| Step: 10
Training loss: 0.08797141164541245
Validation loss: 1.4460348147217945

Epoch: 738| Step: 0
Training loss: 0.06398770958185196
Validation loss: 1.4315919568461757

Epoch: 5| Step: 1
Training loss: 0.04152967780828476
Validation loss: 1.4269456812130508

Epoch: 5| Step: 2
Training loss: 0.04489801451563835
Validation loss: 1.431619967183759

Epoch: 5| Step: 3
Training loss: 0.03554772585630417
Validation loss: 1.420333194476302

Epoch: 5| Step: 4
Training loss: 0.045340411365032196
Validation loss: 1.408017449481513

Epoch: 5| Step: 5
Training loss: 0.07876792550086975
Validation loss: 1.4264429544889798

Epoch: 5| Step: 6
Training loss: 0.04352721571922302
Validation loss: 1.4159695089504283

Epoch: 5| Step: 7
Training loss: 0.038130491971969604
Validation loss: 1.4240578297645814

Epoch: 5| Step: 8
Training loss: 0.04059063643217087
Validation loss: 1.4336773810848114

Epoch: 5| Step: 9
Training loss: 0.039713405072689056
Validation loss: 1.4279376640114734

Epoch: 5| Step: 10
Training loss: 0.10195840895175934
Validation loss: 1.4163995481306506

Epoch: 739| Step: 0
Training loss: 0.03719313070178032
Validation loss: 1.411085098020492

Epoch: 5| Step: 1
Training loss: 0.0609658882021904
Validation loss: 1.400552809879344

Epoch: 5| Step: 2
Training loss: 0.060052644461393356
Validation loss: 1.4292170796343076

Epoch: 5| Step: 3
Training loss: 0.047672491520643234
Validation loss: 1.4234860571481849

Epoch: 5| Step: 4
Training loss: 0.06583043932914734
Validation loss: 1.4009142575725433

Epoch: 5| Step: 5
Training loss: 0.0802818089723587
Validation loss: 1.4101873918246197

Epoch: 5| Step: 6
Training loss: 0.06883145123720169
Validation loss: 1.4279356566808556

Epoch: 5| Step: 7
Training loss: 0.0839148759841919
Validation loss: 1.4178862405079666

Epoch: 5| Step: 8
Training loss: 0.05592038109898567
Validation loss: 1.4108977471628497

Epoch: 5| Step: 9
Training loss: 0.1286456137895584
Validation loss: 1.3985490529767928

Epoch: 5| Step: 10
Training loss: 0.06461579352617264
Validation loss: 1.4038570292534367

Epoch: 740| Step: 0
Training loss: 0.03681599348783493
Validation loss: 1.3941578115186384

Epoch: 5| Step: 1
Training loss: 0.0899045318365097
Validation loss: 1.4195035170483332

Epoch: 5| Step: 2
Training loss: 0.04220941662788391
Validation loss: 1.411044442525474

Epoch: 5| Step: 3
Training loss: 0.052547525614500046
Validation loss: 1.3965169088814848

Epoch: 5| Step: 4
Training loss: 0.10226760059595108
Validation loss: 1.4070888526978031

Epoch: 5| Step: 5
Training loss: 0.05892942100763321
Validation loss: 1.4036483021192654

Epoch: 5| Step: 6
Training loss: 0.046299319714307785
Validation loss: 1.3837219412608812

Epoch: 5| Step: 7
Training loss: 0.04432869702577591
Validation loss: 1.3923673616942538

Epoch: 5| Step: 8
Training loss: 0.09787817299365997
Validation loss: 1.4091334445502168

Epoch: 5| Step: 9
Training loss: 0.05742936208844185
Validation loss: 1.4115482094467326

Epoch: 5| Step: 10
Training loss: 0.060628265142440796
Validation loss: 1.4202736936589724

Epoch: 741| Step: 0
Training loss: 0.0302452202886343
Validation loss: 1.4139616938047512

Epoch: 5| Step: 1
Training loss: 0.10960602760314941
Validation loss: 1.4418142309752844

Epoch: 5| Step: 2
Training loss: 0.048497993499040604
Validation loss: 1.409606300374513

Epoch: 5| Step: 3
Training loss: 0.04067573323845863
Validation loss: 1.4409946446777673

Epoch: 5| Step: 4
Training loss: 0.06438855826854706
Validation loss: 1.4368912853220457

Epoch: 5| Step: 5
Training loss: 0.04819568246603012
Validation loss: 1.4637163249395226

Epoch: 5| Step: 6
Training loss: 0.04827313870191574
Validation loss: 1.4342364482982184

Epoch: 5| Step: 7
Training loss: 0.049349941313266754
Validation loss: 1.434117631245685

Epoch: 5| Step: 8
Training loss: 0.08353427797555923
Validation loss: 1.421061884972357

Epoch: 5| Step: 9
Training loss: 0.08029709756374359
Validation loss: 1.4100715088587936

Epoch: 5| Step: 10
Training loss: 0.03927028179168701
Validation loss: 1.428284852735458

Epoch: 742| Step: 0
Training loss: 0.039491716772317886
Validation loss: 1.3904052729247718

Epoch: 5| Step: 1
Training loss: 0.0740373358130455
Validation loss: 1.3955384633874381

Epoch: 5| Step: 2
Training loss: 0.05287035182118416
Validation loss: 1.4126713609182706

Epoch: 5| Step: 3
Training loss: 0.04153306037187576
Validation loss: 1.4269306121333953

Epoch: 5| Step: 4
Training loss: 0.042985159903764725
Validation loss: 1.4186207543137253

Epoch: 5| Step: 5
Training loss: 0.06008293107151985
Validation loss: 1.4281208201121258

Epoch: 5| Step: 6
Training loss: 0.03812822327017784
Validation loss: 1.4028810185770835

Epoch: 5| Step: 7
Training loss: 0.07142364233732224
Validation loss: 1.4225810330401185

Epoch: 5| Step: 8
Training loss: 0.0840761661529541
Validation loss: 1.4125127129016384

Epoch: 5| Step: 9
Training loss: 0.052095621824264526
Validation loss: 1.41322882329264

Epoch: 5| Step: 10
Training loss: 0.055152326822280884
Validation loss: 1.412256125480898

Epoch: 743| Step: 0
Training loss: 0.052679531276226044
Validation loss: 1.3980269162885604

Epoch: 5| Step: 1
Training loss: 0.06035240367054939
Validation loss: 1.4339327171284666

Epoch: 5| Step: 2
Training loss: 0.0570274218916893
Validation loss: 1.404357632001241

Epoch: 5| Step: 3
Training loss: 0.051091767847537994
Validation loss: 1.42710034308895

Epoch: 5| Step: 4
Training loss: 0.072178915143013
Validation loss: 1.4563987614006124

Epoch: 5| Step: 5
Training loss: 0.03517122194170952
Validation loss: 1.4455483895476147

Epoch: 5| Step: 6
Training loss: 0.05706930160522461
Validation loss: 1.4509928828926497

Epoch: 5| Step: 7
Training loss: 0.047737352550029755
Validation loss: 1.4066715650661017

Epoch: 5| Step: 8
Training loss: 0.03754883259534836
Validation loss: 1.4259941001092233

Epoch: 5| Step: 9
Training loss: 0.07596857100725174
Validation loss: 1.4224305909167054

Epoch: 5| Step: 10
Training loss: 0.0329277329146862
Validation loss: 1.4223075130934357

Epoch: 744| Step: 0
Training loss: 0.07208700478076935
Validation loss: 1.4094861559970404

Epoch: 5| Step: 1
Training loss: 0.1344427466392517
Validation loss: 1.415165251301181

Epoch: 5| Step: 2
Training loss: 0.05960855633020401
Validation loss: 1.4069250155520696

Epoch: 5| Step: 3
Training loss: 0.025236915796995163
Validation loss: 1.3854917749281852

Epoch: 5| Step: 4
Training loss: 0.04358742758631706
Validation loss: 1.4091842655212647

Epoch: 5| Step: 5
Training loss: 0.061253197491168976
Validation loss: 1.4015835356968704

Epoch: 5| Step: 6
Training loss: 0.07442202419042587
Validation loss: 1.3976530439110213

Epoch: 5| Step: 7
Training loss: 0.04526706784963608
Validation loss: 1.415656223092028

Epoch: 5| Step: 8
Training loss: 0.07111961394548416
Validation loss: 1.3868100220157253

Epoch: 5| Step: 9
Training loss: 0.07053281366825104
Validation loss: 1.3853102076438166

Epoch: 5| Step: 10
Training loss: 0.08302406966686249
Validation loss: 1.39082371804022

Epoch: 745| Step: 0
Training loss: 0.04225502535700798
Validation loss: 1.4005953393956667

Epoch: 5| Step: 1
Training loss: 0.06471376121044159
Validation loss: 1.43248204710663

Epoch: 5| Step: 2
Training loss: 0.08742674440145493
Validation loss: 1.44280469353481

Epoch: 5| Step: 3
Training loss: 0.06153034418821335
Validation loss: 1.4390010436375935

Epoch: 5| Step: 4
Training loss: 0.0345023050904274
Validation loss: 1.390509795117122

Epoch: 5| Step: 5
Training loss: 0.06661774218082428
Validation loss: 1.398448650554944

Epoch: 5| Step: 6
Training loss: 0.03849722072482109
Validation loss: 1.4190407350499143

Epoch: 5| Step: 7
Training loss: 0.06924386322498322
Validation loss: 1.39978039392861

Epoch: 5| Step: 8
Training loss: 0.05638691037893295
Validation loss: 1.3905777841485956

Epoch: 5| Step: 9
Training loss: 0.09706660360097885
Validation loss: 1.3955225944519043

Epoch: 5| Step: 10
Training loss: 0.1016799733042717
Validation loss: 1.3773662633793329

Epoch: 746| Step: 0
Training loss: 0.05242271348834038
Validation loss: 1.382082845575066

Epoch: 5| Step: 1
Training loss: 0.048707108944654465
Validation loss: 1.3921695691283031

Epoch: 5| Step: 2
Training loss: 0.05840862914919853
Validation loss: 1.4372757827081988

Epoch: 5| Step: 3
Training loss: 0.03535383567214012
Validation loss: 1.4221722143952564

Epoch: 5| Step: 4
Training loss: 0.056243084371089935
Validation loss: 1.4235688377452154

Epoch: 5| Step: 5
Training loss: 0.06883244216442108
Validation loss: 1.4301778680534774

Epoch: 5| Step: 6
Training loss: 0.11627496778964996
Validation loss: 1.4172967377529349

Epoch: 5| Step: 7
Training loss: 0.055799804627895355
Validation loss: 1.402757433152968

Epoch: 5| Step: 8
Training loss: 0.05196838453412056
Validation loss: 1.404023249944051

Epoch: 5| Step: 9
Training loss: 0.0770706832408905
Validation loss: 1.4110009529257332

Epoch: 5| Step: 10
Training loss: 0.05172613263130188
Validation loss: 1.4116642808401456

Epoch: 747| Step: 0
Training loss: 0.05773143097758293
Validation loss: 1.4076098344659294

Epoch: 5| Step: 1
Training loss: 0.05948004871606827
Validation loss: 1.4195190136150648

Epoch: 5| Step: 2
Training loss: 0.09055539220571518
Validation loss: 1.4007321980691725

Epoch: 5| Step: 3
Training loss: 0.05478455871343613
Validation loss: 1.4179278003272189

Epoch: 5| Step: 4
Training loss: 0.05581798031926155
Validation loss: 1.4024049120564615

Epoch: 5| Step: 5
Training loss: 0.06853081285953522
Validation loss: 1.4503207565635763

Epoch: 5| Step: 6
Training loss: 0.0822034552693367
Validation loss: 1.4267359407999183

Epoch: 5| Step: 7
Training loss: 0.038141340017318726
Validation loss: 1.4429752775417861

Epoch: 5| Step: 8
Training loss: 0.06132831051945686
Validation loss: 1.429565232287171

Epoch: 5| Step: 9
Training loss: 0.07194895297288895
Validation loss: 1.4236915829361125

Epoch: 5| Step: 10
Training loss: 0.027560120448470116
Validation loss: 1.4329504428371307

Epoch: 748| Step: 0
Training loss: 0.05644993111491203
Validation loss: 1.4493830197600908

Epoch: 5| Step: 1
Training loss: 0.10625843703746796
Validation loss: 1.4439733348866945

Epoch: 5| Step: 2
Training loss: 0.07525131851434708
Validation loss: 1.4404138063871732

Epoch: 5| Step: 3
Training loss: 0.04745514318346977
Validation loss: 1.4366445336290585

Epoch: 5| Step: 4
Training loss: 0.05465131998062134
Validation loss: 1.4333585651331051

Epoch: 5| Step: 5
Training loss: 0.053368110209703445
Validation loss: 1.4387858824063373

Epoch: 5| Step: 6
Training loss: 0.022402670234441757
Validation loss: 1.4416170043330039

Epoch: 5| Step: 7
Training loss: 0.09389269351959229
Validation loss: 1.4559486271232687

Epoch: 5| Step: 8
Training loss: 0.08016075938940048
Validation loss: 1.4544187489376272

Epoch: 5| Step: 9
Training loss: 0.0944005474448204
Validation loss: 1.4310497558245094

Epoch: 5| Step: 10
Training loss: 0.04543296620249748
Validation loss: 1.439444189430565

Epoch: 749| Step: 0
Training loss: 0.036470092833042145
Validation loss: 1.4110747498850669

Epoch: 5| Step: 1
Training loss: 0.03230930492281914
Validation loss: 1.4168215054337696

Epoch: 5| Step: 2
Training loss: 0.06972110271453857
Validation loss: 1.4261401096979778

Epoch: 5| Step: 3
Training loss: 0.10870824754238129
Validation loss: 1.4202181414891315

Epoch: 5| Step: 4
Training loss: 0.04702999070286751
Validation loss: 1.4523399952919251

Epoch: 5| Step: 5
Training loss: 0.05500737577676773
Validation loss: 1.4221873616659513

Epoch: 5| Step: 6
Training loss: 0.051359016448259354
Validation loss: 1.4164512439440655

Epoch: 5| Step: 7
Training loss: 0.06587442010641098
Validation loss: 1.4160410204241354

Epoch: 5| Step: 8
Training loss: 0.05918081849813461
Validation loss: 1.4279603932493476

Epoch: 5| Step: 9
Training loss: 0.11650459468364716
Validation loss: 1.4155464390272736

Epoch: 5| Step: 10
Training loss: 0.043742649257183075
Validation loss: 1.4117085574775614

Epoch: 750| Step: 0
Training loss: 0.05171031877398491
Validation loss: 1.4047323606347526

Epoch: 5| Step: 1
Training loss: 0.08050524443387985
Validation loss: 1.387526414727652

Epoch: 5| Step: 2
Training loss: 0.055588580667972565
Validation loss: 1.3967331404327064

Epoch: 5| Step: 3
Training loss: 0.043341029435396194
Validation loss: 1.3981974970909856

Epoch: 5| Step: 4
Training loss: 0.030108407139778137
Validation loss: 1.3998321807512673

Epoch: 5| Step: 5
Training loss: 0.039840202778577805
Validation loss: 1.4001386434801164

Epoch: 5| Step: 6
Training loss: 0.035392701625823975
Validation loss: 1.3927003670764226

Epoch: 5| Step: 7
Training loss: 0.050865620374679565
Validation loss: 1.4240405713358233

Epoch: 5| Step: 8
Training loss: 0.03924573212862015
Validation loss: 1.4346571186537385

Epoch: 5| Step: 9
Training loss: 0.06179047375917435
Validation loss: 1.4367544651031494

Epoch: 5| Step: 10
Training loss: 0.07941616326570511
Validation loss: 1.4498624224816599

Epoch: 751| Step: 0
Training loss: 0.049303844571113586
Validation loss: 1.470014436270601

Epoch: 5| Step: 1
Training loss: 0.04341386631131172
Validation loss: 1.4725059341358882

Epoch: 5| Step: 2
Training loss: 0.029844069853425026
Validation loss: 1.4598965978109708

Epoch: 5| Step: 3
Training loss: 0.04534649848937988
Validation loss: 1.4297839069879184

Epoch: 5| Step: 4
Training loss: 0.03713143616914749
Validation loss: 1.439784953671117

Epoch: 5| Step: 5
Training loss: 0.05286973714828491
Validation loss: 1.4252733030626852

Epoch: 5| Step: 6
Training loss: 0.06100726127624512
Validation loss: 1.4479459383154427

Epoch: 5| Step: 7
Training loss: 0.06821560859680176
Validation loss: 1.4588871604652816

Epoch: 5| Step: 8
Training loss: 0.028789466246962547
Validation loss: 1.449302400312116

Epoch: 5| Step: 9
Training loss: 0.10682410001754761
Validation loss: 1.4335795474308792

Epoch: 5| Step: 10
Training loss: 0.08192166686058044
Validation loss: 1.4501868864541412

Epoch: 752| Step: 0
Training loss: 0.03387792408466339
Validation loss: 1.4370846158714705

Epoch: 5| Step: 1
Training loss: 0.04932362958788872
Validation loss: 1.4312316269002936

Epoch: 5| Step: 2
Training loss: 0.04379589855670929
Validation loss: 1.4508338910277172

Epoch: 5| Step: 3
Training loss: 0.04095228761434555
Validation loss: 1.4212769500670894

Epoch: 5| Step: 4
Training loss: 0.06743088364601135
Validation loss: 1.402604329970575

Epoch: 5| Step: 5
Training loss: 0.07492028176784515
Validation loss: 1.4005781771034322

Epoch: 5| Step: 6
Training loss: 0.07049333304166794
Validation loss: 1.4084848742331229

Epoch: 5| Step: 7
Training loss: 0.04045913740992546
Validation loss: 1.410357766253974

Epoch: 5| Step: 8
Training loss: 0.0951630026102066
Validation loss: 1.391953267076964

Epoch: 5| Step: 9
Training loss: 0.04532145336270332
Validation loss: 1.40727109806512

Epoch: 5| Step: 10
Training loss: 0.09279441833496094
Validation loss: 1.397129322892876

Epoch: 753| Step: 0
Training loss: 0.050483208149671555
Validation loss: 1.3916209718232513

Epoch: 5| Step: 1
Training loss: 0.051287613809108734
Validation loss: 1.384955302361519

Epoch: 5| Step: 2
Training loss: 0.048474282026290894
Validation loss: 1.4066359868613623

Epoch: 5| Step: 3
Training loss: 0.07111324369907379
Validation loss: 1.4164851468096498

Epoch: 5| Step: 4
Training loss: 0.06727107614278793
Validation loss: 1.394262436897524

Epoch: 5| Step: 5
Training loss: 0.0442139208316803
Validation loss: 1.4071070353190105

Epoch: 5| Step: 6
Training loss: 0.04169390723109245
Validation loss: 1.4132953843762797

Epoch: 5| Step: 7
Training loss: 0.09665044397115707
Validation loss: 1.4079764914768997

Epoch: 5| Step: 8
Training loss: 0.055011946707963943
Validation loss: 1.43259713854841

Epoch: 5| Step: 9
Training loss: 0.06977695226669312
Validation loss: 1.4108243667951195

Epoch: 5| Step: 10
Training loss: 0.07726229727268219
Validation loss: 1.4263713616196827

Epoch: 754| Step: 0
Training loss: 0.046267688274383545
Validation loss: 1.4217407703399658

Epoch: 5| Step: 1
Training loss: 0.07846053689718246
Validation loss: 1.4126241873669367

Epoch: 5| Step: 2
Training loss: 0.029553700238466263
Validation loss: 1.4152309330560828

Epoch: 5| Step: 3
Training loss: 0.0585407130420208
Validation loss: 1.4417586506053965

Epoch: 5| Step: 4
Training loss: 0.07816115766763687
Validation loss: 1.434774992286518

Epoch: 5| Step: 5
Training loss: 0.05333751440048218
Validation loss: 1.4423600819803053

Epoch: 5| Step: 6
Training loss: 0.05561785772442818
Validation loss: 1.4226291577021282

Epoch: 5| Step: 7
Training loss: 0.08906783908605576
Validation loss: 1.4225452946078392

Epoch: 5| Step: 8
Training loss: 0.04863975942134857
Validation loss: 1.4465095810992743

Epoch: 5| Step: 9
Training loss: 0.04017672687768936
Validation loss: 1.4469537299166444

Epoch: 5| Step: 10
Training loss: 0.04491898790001869
Validation loss: 1.3934948405911844

Epoch: 755| Step: 0
Training loss: 0.03367064148187637
Validation loss: 1.432538027404457

Epoch: 5| Step: 1
Training loss: 0.05421377345919609
Validation loss: 1.4167310384012037

Epoch: 5| Step: 2
Training loss: 0.1262633502483368
Validation loss: 1.4266077933772918

Epoch: 5| Step: 3
Training loss: 0.06395421922206879
Validation loss: 1.4493524387318601

Epoch: 5| Step: 4
Training loss: 0.06285878270864487
Validation loss: 1.4329058893265263

Epoch: 5| Step: 5
Training loss: 0.0847780779004097
Validation loss: 1.4465328897199323

Epoch: 5| Step: 6
Training loss: 0.04994211718440056
Validation loss: 1.460074838771615

Epoch: 5| Step: 7
Training loss: 0.09833501279354095
Validation loss: 1.4537181315883514

Epoch: 5| Step: 8
Training loss: 0.03709199279546738
Validation loss: 1.4230479719818279

Epoch: 5| Step: 9
Training loss: 0.061306022107601166
Validation loss: 1.4639666054838447

Epoch: 5| Step: 10
Training loss: 0.06203492358326912
Validation loss: 1.4795422746289162

Epoch: 756| Step: 0
Training loss: 0.08732005953788757
Validation loss: 1.4612375254272132

Epoch: 5| Step: 1
Training loss: 0.12447939068078995
Validation loss: 1.431378109480745

Epoch: 5| Step: 2
Training loss: 0.06020095944404602
Validation loss: 1.4316648360221618

Epoch: 5| Step: 3
Training loss: 0.04227747768163681
Validation loss: 1.4031013378532984

Epoch: 5| Step: 4
Training loss: 0.04962998256087303
Validation loss: 1.385397409880033

Epoch: 5| Step: 5
Training loss: 0.07834575325250626
Validation loss: 1.3898658252531482

Epoch: 5| Step: 6
Training loss: 0.11358578503131866
Validation loss: 1.3781308525352067

Epoch: 5| Step: 7
Training loss: 0.08165451884269714
Validation loss: 1.4062446676274782

Epoch: 5| Step: 8
Training loss: 0.05419667437672615
Validation loss: 1.3952280475247292

Epoch: 5| Step: 9
Training loss: 0.09334616363048553
Validation loss: 1.3999485020996423

Epoch: 5| Step: 10
Training loss: 0.0752386599779129
Validation loss: 1.4283575255383727

Epoch: 757| Step: 0
Training loss: 0.08229728788137436
Validation loss: 1.4461765635398127

Epoch: 5| Step: 1
Training loss: 0.11666218936443329
Validation loss: 1.445733670265444

Epoch: 5| Step: 2
Training loss: 0.05759843438863754
Validation loss: 1.4565515428461053

Epoch: 5| Step: 3
Training loss: 0.06188657134771347
Validation loss: 1.4343350337397667

Epoch: 5| Step: 4
Training loss: 0.03927177935838699
Validation loss: 1.4250613399731216

Epoch: 5| Step: 5
Training loss: 0.04541822150349617
Validation loss: 1.4082700590933523

Epoch: 5| Step: 6
Training loss: 0.07733271270990372
Validation loss: 1.3950828685555408

Epoch: 5| Step: 7
Training loss: 0.06381948292255402
Validation loss: 1.3709140105914044

Epoch: 5| Step: 8
Training loss: 0.08366449177265167
Validation loss: 1.3912290815384156

Epoch: 5| Step: 9
Training loss: 0.07348987460136414
Validation loss: 1.394364022439526

Epoch: 5| Step: 10
Training loss: 0.03841567784547806
Validation loss: 1.4163711199196436

Epoch: 758| Step: 0
Training loss: 0.08185448497533798
Validation loss: 1.4094109971036193

Epoch: 5| Step: 1
Training loss: 0.03803422302007675
Validation loss: 1.443250879164665

Epoch: 5| Step: 2
Training loss: 0.07400868088006973
Validation loss: 1.4385718376405778

Epoch: 5| Step: 3
Training loss: 0.09434375911951065
Validation loss: 1.4446568027619393

Epoch: 5| Step: 4
Training loss: 0.049475010484457016
Validation loss: 1.4274621035463066

Epoch: 5| Step: 5
Training loss: 0.08585020154714584
Validation loss: 1.4337729600168043

Epoch: 5| Step: 6
Training loss: 0.035577353090047836
Validation loss: 1.4260902404785156

Epoch: 5| Step: 7
Training loss: 0.05839192122220993
Validation loss: 1.3979903703094811

Epoch: 5| Step: 8
Training loss: 0.058753419667482376
Validation loss: 1.4194167634492278

Epoch: 5| Step: 9
Training loss: 0.06227986887097359
Validation loss: 1.3964837956172165

Epoch: 5| Step: 10
Training loss: 0.04280480742454529
Validation loss: 1.4080006307171238

Epoch: 759| Step: 0
Training loss: 0.08766166865825653
Validation loss: 1.4114002027819235

Epoch: 5| Step: 1
Training loss: 0.07611928135156631
Validation loss: 1.4346724139746798

Epoch: 5| Step: 2
Training loss: 0.05982218310236931
Validation loss: 1.4496377334799817

Epoch: 5| Step: 3
Training loss: 0.08425534516572952
Validation loss: 1.4483739535013835

Epoch: 5| Step: 4
Training loss: 0.03927644342184067
Validation loss: 1.4543778691240536

Epoch: 5| Step: 5
Training loss: 0.04498249292373657
Validation loss: 1.4315705466014084

Epoch: 5| Step: 6
Training loss: 0.05961814522743225
Validation loss: 1.4379567253974177

Epoch: 5| Step: 7
Training loss: 0.0878678634762764
Validation loss: 1.4359101018598002

Epoch: 5| Step: 8
Training loss: 0.03954123705625534
Validation loss: 1.4310937927615257

Epoch: 5| Step: 9
Training loss: 0.07089145481586456
Validation loss: 1.4297216105204757

Epoch: 5| Step: 10
Training loss: 0.03211155906319618
Validation loss: 1.4390636490237327

Epoch: 760| Step: 0
Training loss: 0.04956797510385513
Validation loss: 1.429603176732217

Epoch: 5| Step: 1
Training loss: 0.048663873225450516
Validation loss: 1.423734159879787

Epoch: 5| Step: 2
Training loss: 0.027139509096741676
Validation loss: 1.4293360530689199

Epoch: 5| Step: 3
Training loss: 0.06175091862678528
Validation loss: 1.4209550375579505

Epoch: 5| Step: 4
Training loss: 0.07489685714244843
Validation loss: 1.3846332360339422

Epoch: 5| Step: 5
Training loss: 0.050099264830350876
Validation loss: 1.3810121756727978

Epoch: 5| Step: 6
Training loss: 0.09997260570526123
Validation loss: 1.4038803885059972

Epoch: 5| Step: 7
Training loss: 0.05772104859352112
Validation loss: 1.3815914405289518

Epoch: 5| Step: 8
Training loss: 0.06335844099521637
Validation loss: 1.4028295445185837

Epoch: 5| Step: 9
Training loss: 0.06918281316757202
Validation loss: 1.3856074874119093

Epoch: 5| Step: 10
Training loss: 0.06153779849410057
Validation loss: 1.4056361900862826

Epoch: 761| Step: 0
Training loss: 0.047860097140073776
Validation loss: 1.444731452131784

Epoch: 5| Step: 1
Training loss: 0.054384708404541016
Validation loss: 1.4396460863851732

Epoch: 5| Step: 2
Training loss: 0.06035661697387695
Validation loss: 1.4401726363807597

Epoch: 5| Step: 3
Training loss: 0.05852288007736206
Validation loss: 1.4470517712254678

Epoch: 5| Step: 4
Training loss: 0.10216937959194183
Validation loss: 1.4483200106569516

Epoch: 5| Step: 5
Training loss: 0.09702271223068237
Validation loss: 1.4473611577864616

Epoch: 5| Step: 6
Training loss: 0.04270480200648308
Validation loss: 1.4172056823648431

Epoch: 5| Step: 7
Training loss: 0.033993396908044815
Validation loss: 1.4182185703708279

Epoch: 5| Step: 8
Training loss: 0.15366913378238678
Validation loss: 1.4197849099354078

Epoch: 5| Step: 9
Training loss: 0.08174773305654526
Validation loss: 1.4072566993774906

Epoch: 5| Step: 10
Training loss: 0.044966258108615875
Validation loss: 1.4054987904846028

Epoch: 762| Step: 0
Training loss: 0.05879957601428032
Validation loss: 1.4295465407832977

Epoch: 5| Step: 1
Training loss: 0.06996583938598633
Validation loss: 1.4452971155925463

Epoch: 5| Step: 2
Training loss: 0.055957894772291183
Validation loss: 1.4664736332431916

Epoch: 5| Step: 3
Training loss: 0.059751130640506744
Validation loss: 1.478583788359037

Epoch: 5| Step: 4
Training loss: 0.05765678361058235
Validation loss: 1.5184330594155095

Epoch: 5| Step: 5
Training loss: 0.1092328280210495
Validation loss: 1.5183617684148973

Epoch: 5| Step: 6
Training loss: 0.08850166946649551
Validation loss: 1.5005046744500437

Epoch: 5| Step: 7
Training loss: 0.09969691932201385
Validation loss: 1.4678763106305113

Epoch: 5| Step: 8
Training loss: 0.07127759605646133
Validation loss: 1.4475143455689954

Epoch: 5| Step: 9
Training loss: 0.07127253711223602
Validation loss: 1.4390719782921575

Epoch: 5| Step: 10
Training loss: 0.07776953279972076
Validation loss: 1.3960024169696275

Epoch: 763| Step: 0
Training loss: 0.05996757745742798
Validation loss: 1.3999082003870318

Epoch: 5| Step: 1
Training loss: 0.05694383382797241
Validation loss: 1.4016226286529212

Epoch: 5| Step: 2
Training loss: 0.10992910712957382
Validation loss: 1.394085454684432

Epoch: 5| Step: 3
Training loss: 0.10557375103235245
Validation loss: 1.3928716451891008

Epoch: 5| Step: 4
Training loss: 0.05945616960525513
Validation loss: 1.4228918398580244

Epoch: 5| Step: 5
Training loss: 0.09148384630680084
Validation loss: 1.418736707779669

Epoch: 5| Step: 6
Training loss: 0.04311306029558182
Validation loss: 1.427661741933515

Epoch: 5| Step: 7
Training loss: 0.04351799935102463
Validation loss: 1.4460656963368899

Epoch: 5| Step: 8
Training loss: 0.04362661391496658
Validation loss: 1.4372669343025453

Epoch: 5| Step: 9
Training loss: 0.05861949920654297
Validation loss: 1.4392144603113974

Epoch: 5| Step: 10
Training loss: 0.06586679816246033
Validation loss: 1.440212691983869

Epoch: 764| Step: 0
Training loss: 0.06661075353622437
Validation loss: 1.44537256738191

Epoch: 5| Step: 1
Training loss: 0.060926757752895355
Validation loss: 1.4464657268216532

Epoch: 5| Step: 2
Training loss: 0.08071597665548325
Validation loss: 1.4418595016643565

Epoch: 5| Step: 3
Training loss: 0.06546719372272491
Validation loss: 1.4159793052622067

Epoch: 5| Step: 4
Training loss: 0.03439195454120636
Validation loss: 1.3997088773276216

Epoch: 5| Step: 5
Training loss: 0.04982639104127884
Validation loss: 1.4258440976501794

Epoch: 5| Step: 6
Training loss: 0.08341646939516068
Validation loss: 1.4387629057771416

Epoch: 5| Step: 7
Training loss: 0.059745531529188156
Validation loss: 1.4299253135599115

Epoch: 5| Step: 8
Training loss: 0.05982188135385513
Validation loss: 1.459725337643777

Epoch: 5| Step: 9
Training loss: 0.07191601395606995
Validation loss: 1.4547197331664383

Epoch: 5| Step: 10
Training loss: 0.04482467472553253
Validation loss: 1.4546858187644713

Epoch: 765| Step: 0
Training loss: 0.056933797895908356
Validation loss: 1.478628207278508

Epoch: 5| Step: 1
Training loss: 0.07355839014053345
Validation loss: 1.46527228688681

Epoch: 5| Step: 2
Training loss: 0.04368734732270241
Validation loss: 1.4971549139227918

Epoch: 5| Step: 3
Training loss: 0.07880768924951553
Validation loss: 1.4820799109756306

Epoch: 5| Step: 4
Training loss: 0.0925285667181015
Validation loss: 1.4973238334860852

Epoch: 5| Step: 5
Training loss: 0.06525953114032745
Validation loss: 1.470701838052401

Epoch: 5| Step: 6
Training loss: 0.047834962606430054
Validation loss: 1.4848970777244979

Epoch: 5| Step: 7
Training loss: 0.06455305963754654
Validation loss: 1.4336692299894107

Epoch: 5| Step: 8
Training loss: 0.04334605485200882
Validation loss: 1.4415012533946703

Epoch: 5| Step: 9
Training loss: 0.048056792467832565
Validation loss: 1.4443797321729763

Epoch: 5| Step: 10
Training loss: 0.08832453191280365
Validation loss: 1.4505924383799236

Epoch: 766| Step: 0
Training loss: 0.044992655515670776
Validation loss: 1.4393053849538167

Epoch: 5| Step: 1
Training loss: 0.06995061039924622
Validation loss: 1.451462314974877

Epoch: 5| Step: 2
Training loss: 0.049523934721946716
Validation loss: 1.4185364156640985

Epoch: 5| Step: 3
Training loss: 0.09944671392440796
Validation loss: 1.4532769399304544

Epoch: 5| Step: 4
Training loss: 0.050177253782749176
Validation loss: 1.4422792170637397

Epoch: 5| Step: 5
Training loss: 0.07231564819812775
Validation loss: 1.446401067959365

Epoch: 5| Step: 6
Training loss: 0.046186380088329315
Validation loss: 1.4189337376625306

Epoch: 5| Step: 7
Training loss: 0.04295546934008598
Validation loss: 1.4440338047601844

Epoch: 5| Step: 8
Training loss: 0.046119045466184616
Validation loss: 1.4164926646858134

Epoch: 5| Step: 9
Training loss: 0.033750616014003754
Validation loss: 1.3987603110651816

Epoch: 5| Step: 10
Training loss: 0.07447955012321472
Validation loss: 1.399436850701609

Epoch: 767| Step: 0
Training loss: 0.04880016669631004
Validation loss: 1.3975953914785897

Epoch: 5| Step: 1
Training loss: 0.06885085999965668
Validation loss: 1.4077591428192713

Epoch: 5| Step: 2
Training loss: 0.053224820643663406
Validation loss: 1.4221505529137068

Epoch: 5| Step: 3
Training loss: 0.03771551698446274
Validation loss: 1.4250073330376738

Epoch: 5| Step: 4
Training loss: 0.056662507355213165
Validation loss: 1.4257100987178024

Epoch: 5| Step: 5
Training loss: 0.03967302292585373
Validation loss: 1.438129650649204

Epoch: 5| Step: 6
Training loss: 0.07243437319993973
Validation loss: 1.4375673737577213

Epoch: 5| Step: 7
Training loss: 0.030417779460549355
Validation loss: 1.443371360019971

Epoch: 5| Step: 8
Training loss: 0.0673934742808342
Validation loss: 1.4287284061472902

Epoch: 5| Step: 9
Training loss: 0.06749054789543152
Validation loss: 1.4404499441064813

Epoch: 5| Step: 10
Training loss: 0.07857778668403625
Validation loss: 1.4193214524176814

Epoch: 768| Step: 0
Training loss: 0.07529723644256592
Validation loss: 1.426308451160308

Epoch: 5| Step: 1
Training loss: 0.05683425813913345
Validation loss: 1.4279399764153264

Epoch: 5| Step: 2
Training loss: 0.04876139387488365
Validation loss: 1.3722029193755119

Epoch: 5| Step: 3
Training loss: 0.05548511818051338
Validation loss: 1.4285795047718992

Epoch: 5| Step: 4
Training loss: 0.052694350481033325
Validation loss: 1.4348587553988221

Epoch: 5| Step: 5
Training loss: 0.03753048926591873
Validation loss: 1.4621296390410392

Epoch: 5| Step: 6
Training loss: 0.05421765521168709
Validation loss: 1.4398199460839713

Epoch: 5| Step: 7
Training loss: 0.047320444136857986
Validation loss: 1.4336469775886946

Epoch: 5| Step: 8
Training loss: 0.0626526027917862
Validation loss: 1.4297154911102787

Epoch: 5| Step: 9
Training loss: 0.10773037374019623
Validation loss: 1.417014136109301

Epoch: 5| Step: 10
Training loss: 0.031052449718117714
Validation loss: 1.439160176502761

Epoch: 769| Step: 0
Training loss: 0.03898078203201294
Validation loss: 1.4234898679999894

Epoch: 5| Step: 1
Training loss: 0.07672327011823654
Validation loss: 1.414936404074392

Epoch: 5| Step: 2
Training loss: 0.12120044231414795
Validation loss: 1.4456397474453013

Epoch: 5| Step: 3
Training loss: 0.07068575918674469
Validation loss: 1.403986741137761

Epoch: 5| Step: 4
Training loss: 0.033469341695308685
Validation loss: 1.4149347325806976

Epoch: 5| Step: 5
Training loss: 0.06741204112768173
Validation loss: 1.3984986915383288

Epoch: 5| Step: 6
Training loss: 0.05540395900607109
Validation loss: 1.417803692561324

Epoch: 5| Step: 7
Training loss: 0.08207951486110687
Validation loss: 1.4033225422264428

Epoch: 5| Step: 8
Training loss: 0.07244732975959778
Validation loss: 1.3882092250290738

Epoch: 5| Step: 9
Training loss: 0.041330911219120026
Validation loss: 1.3811393630120061

Epoch: 5| Step: 10
Training loss: 0.01993018388748169
Validation loss: 1.3892941090368456

Epoch: 770| Step: 0
Training loss: 0.06945422291755676
Validation loss: 1.3832361146967898

Epoch: 5| Step: 1
Training loss: 0.06551395356655121
Validation loss: 1.3589059031137856

Epoch: 5| Step: 2
Training loss: 0.030758272856473923
Validation loss: 1.3571969975707352

Epoch: 5| Step: 3
Training loss: 0.12091012299060822
Validation loss: 1.3709426054390528

Epoch: 5| Step: 4
Training loss: 0.06939759105443954
Validation loss: 1.3529030635792723

Epoch: 5| Step: 5
Training loss: 0.0398697555065155
Validation loss: 1.3673889944630284

Epoch: 5| Step: 6
Training loss: 0.06815644353628159
Validation loss: 1.379572046059434

Epoch: 5| Step: 7
Training loss: 0.05226222425699234
Validation loss: 1.3817930106193788

Epoch: 5| Step: 8
Training loss: 0.0319291390478611
Validation loss: 1.3992500651267268

Epoch: 5| Step: 9
Training loss: 0.06876055896282196
Validation loss: 1.4098504768904818

Epoch: 5| Step: 10
Training loss: 0.03074994497001171
Validation loss: 1.4040116725429412

Epoch: 771| Step: 0
Training loss: 0.07981203496456146
Validation loss: 1.4151294564688077

Epoch: 5| Step: 1
Training loss: 0.05207955837249756
Validation loss: 1.437342538628527

Epoch: 5| Step: 2
Training loss: 0.05218943953514099
Validation loss: 1.4730535053437757

Epoch: 5| Step: 3
Training loss: 0.03530440479516983
Validation loss: 1.4919795105534215

Epoch: 5| Step: 4
Training loss: 0.04895995184779167
Validation loss: 1.5173377798449608

Epoch: 5| Step: 5
Training loss: 0.0692269578576088
Validation loss: 1.4984821087570601

Epoch: 5| Step: 6
Training loss: 0.06875167787075043
Validation loss: 1.5085227848381124

Epoch: 5| Step: 7
Training loss: 0.048425234854221344
Validation loss: 1.45146660266384

Epoch: 5| Step: 8
Training loss: 0.09584449231624603
Validation loss: 1.4628850836907663

Epoch: 5| Step: 9
Training loss: 0.07635098695755005
Validation loss: 1.464451608478382

Epoch: 5| Step: 10
Training loss: 0.06218797340989113
Validation loss: 1.4578937945827362

Epoch: 772| Step: 0
Training loss: 0.05931931734085083
Validation loss: 1.447397401255946

Epoch: 5| Step: 1
Training loss: 0.05398033186793327
Validation loss: 1.4180365852130357

Epoch: 5| Step: 2
Training loss: 0.10636303573846817
Validation loss: 1.412579410178687

Epoch: 5| Step: 3
Training loss: 0.05188263580203056
Validation loss: 1.4364790967715684

Epoch: 5| Step: 4
Training loss: 0.055528461933135986
Validation loss: 1.4461668460599837

Epoch: 5| Step: 5
Training loss: 0.07366057485342026
Validation loss: 1.424887764838434

Epoch: 5| Step: 6
Training loss: 0.07027022540569305
Validation loss: 1.443808618412223

Epoch: 5| Step: 7
Training loss: 0.04352715611457825
Validation loss: 1.4437345586797243

Epoch: 5| Step: 8
Training loss: 0.08124570548534393
Validation loss: 1.4403697418910202

Epoch: 5| Step: 9
Training loss: 0.030405621975660324
Validation loss: 1.4289542462236138

Epoch: 5| Step: 10
Training loss: 0.0392686128616333
Validation loss: 1.4199923238446635

Epoch: 773| Step: 0
Training loss: 0.05638674646615982
Validation loss: 1.4384296831264292

Epoch: 5| Step: 1
Training loss: 0.07331669330596924
Validation loss: 1.429528990099507

Epoch: 5| Step: 2
Training loss: 0.06924919784069061
Validation loss: 1.4312244615247172

Epoch: 5| Step: 3
Training loss: 0.02762049064040184
Validation loss: 1.4165197431400258

Epoch: 5| Step: 4
Training loss: 0.05201714113354683
Validation loss: 1.418259419420714

Epoch: 5| Step: 5
Training loss: 0.05851854756474495
Validation loss: 1.416559100151062

Epoch: 5| Step: 6
Training loss: 0.054257821291685104
Validation loss: 1.4391425553188528

Epoch: 5| Step: 7
Training loss: 0.06720821559429169
Validation loss: 1.4507281318787606

Epoch: 5| Step: 8
Training loss: 0.04761762544512749
Validation loss: 1.455875317255656

Epoch: 5| Step: 9
Training loss: 0.04746339097619057
Validation loss: 1.4778530354140906

Epoch: 5| Step: 10
Training loss: 0.06123942509293556
Validation loss: 1.4768811310491254

Epoch: 774| Step: 0
Training loss: 0.04607262462377548
Validation loss: 1.4822024811980545

Epoch: 5| Step: 1
Training loss: 0.03384198620915413
Validation loss: 1.4514569915750974

Epoch: 5| Step: 2
Training loss: 0.047360748052597046
Validation loss: 1.4512669604311708

Epoch: 5| Step: 3
Training loss: 0.08185785263776779
Validation loss: 1.438476490077152

Epoch: 5| Step: 4
Training loss: 0.0731801986694336
Validation loss: 1.4415089520074988

Epoch: 5| Step: 5
Training loss: 0.062487684190273285
Validation loss: 1.4363260243528633

Epoch: 5| Step: 6
Training loss: 0.06781883537769318
Validation loss: 1.4568417290205598

Epoch: 5| Step: 7
Training loss: 0.056851983070373535
Validation loss: 1.4479131993427072

Epoch: 5| Step: 8
Training loss: 0.021250881254673004
Validation loss: 1.4215511660422049

Epoch: 5| Step: 9
Training loss: 0.04059264063835144
Validation loss: 1.4298171407432967

Epoch: 5| Step: 10
Training loss: 0.05323066562414169
Validation loss: 1.4196046552350443

Epoch: 775| Step: 0
Training loss: 0.02799823321402073
Validation loss: 1.4213439802969656

Epoch: 5| Step: 1
Training loss: 0.04270651564002037
Validation loss: 1.3917814621361353

Epoch: 5| Step: 2
Training loss: 0.054145507514476776
Validation loss: 1.377721098161513

Epoch: 5| Step: 3
Training loss: 0.04674605280160904
Validation loss: 1.4028812851957095

Epoch: 5| Step: 4
Training loss: 0.04877027869224548
Validation loss: 1.370684523736277

Epoch: 5| Step: 5
Training loss: 0.04878632724285126
Validation loss: 1.3935997146432118

Epoch: 5| Step: 6
Training loss: 0.06691263616085052
Validation loss: 1.369070811938214

Epoch: 5| Step: 7
Training loss: 0.04457590728998184
Validation loss: 1.4001143497805442

Epoch: 5| Step: 8
Training loss: 0.07487688213586807
Validation loss: 1.4035727529115574

Epoch: 5| Step: 9
Training loss: 0.0799763947725296
Validation loss: 1.3995021594467985

Epoch: 5| Step: 10
Training loss: 0.052430059760808945
Validation loss: 1.4261903121907225

Epoch: 776| Step: 0
Training loss: 0.0370960608124733
Validation loss: 1.4119996588717225

Epoch: 5| Step: 1
Training loss: 0.08522062003612518
Validation loss: 1.464664811729103

Epoch: 5| Step: 2
Training loss: 0.0316646471619606
Validation loss: 1.4328068417887534

Epoch: 5| Step: 3
Training loss: 0.08272752165794373
Validation loss: 1.4233353368697628

Epoch: 5| Step: 4
Training loss: 0.03998429328203201
Validation loss: 1.3927518808713524

Epoch: 5| Step: 5
Training loss: 0.03561810776591301
Validation loss: 1.3960713276299097

Epoch: 5| Step: 6
Training loss: 0.07684285193681717
Validation loss: 1.4076848286454395

Epoch: 5| Step: 7
Training loss: 0.03384704142808914
Validation loss: 1.390842613353524

Epoch: 5| Step: 8
Training loss: 0.07770385593175888
Validation loss: 1.3983316690691057

Epoch: 5| Step: 9
Training loss: 0.057194482535123825
Validation loss: 1.380722527862877

Epoch: 5| Step: 10
Training loss: 0.033417899161577225
Validation loss: 1.3622319621424521

Epoch: 777| Step: 0
Training loss: 0.07782959192991257
Validation loss: 1.4088295903257144

Epoch: 5| Step: 1
Training loss: 0.04718560725450516
Validation loss: 1.4104882190304417

Epoch: 5| Step: 2
Training loss: 0.04890444874763489
Validation loss: 1.3840695235037035

Epoch: 5| Step: 3
Training loss: 0.04764983803033829
Validation loss: 1.4048716650214246

Epoch: 5| Step: 4
Training loss: 0.07009134441614151
Validation loss: 1.4063419090804232

Epoch: 5| Step: 5
Training loss: 0.05625484511256218
Validation loss: 1.4203575746987456

Epoch: 5| Step: 6
Training loss: 0.0410921573638916
Validation loss: 1.4100341437965311

Epoch: 5| Step: 7
Training loss: 0.03853293135762215
Validation loss: 1.4188088255543863

Epoch: 5| Step: 8
Training loss: 0.06419773399829865
Validation loss: 1.4284971067982335

Epoch: 5| Step: 9
Training loss: 0.02928181365132332
Validation loss: 1.4593925770892893

Epoch: 5| Step: 10
Training loss: 0.05282893776893616
Validation loss: 1.4398761615958264

Epoch: 778| Step: 0
Training loss: 0.03598419204354286
Validation loss: 1.4587041690785398

Epoch: 5| Step: 1
Training loss: 0.05724064260721207
Validation loss: 1.4262875203163392

Epoch: 5| Step: 2
Training loss: 0.04057106375694275
Validation loss: 1.4452164179535323

Epoch: 5| Step: 3
Training loss: 0.05580401420593262
Validation loss: 1.4742891532118603

Epoch: 5| Step: 4
Training loss: 0.03284267708659172
Validation loss: 1.4501346823989705

Epoch: 5| Step: 5
Training loss: 0.045063816010951996
Validation loss: 1.4863243500391643

Epoch: 5| Step: 6
Training loss: 0.07975653558969498
Validation loss: 1.471301963252406

Epoch: 5| Step: 7
Training loss: 0.05546898394823074
Validation loss: 1.4690750388688938

Epoch: 5| Step: 8
Training loss: 0.09354235231876373
Validation loss: 1.4755321459103656

Epoch: 5| Step: 9
Training loss: 0.038730740547180176
Validation loss: 1.4465489028602518

Epoch: 5| Step: 10
Training loss: 0.05239728093147278
Validation loss: 1.4342478744445308

Epoch: 779| Step: 0
Training loss: 0.04305025935173035
Validation loss: 1.434921372321344

Epoch: 5| Step: 1
Training loss: 0.06055694818496704
Validation loss: 1.4255766560954433

Epoch: 5| Step: 2
Training loss: 0.041982006281614304
Validation loss: 1.424753914597214

Epoch: 5| Step: 3
Training loss: 0.04155193641781807
Validation loss: 1.4207024574279785

Epoch: 5| Step: 4
Training loss: 0.04767724871635437
Validation loss: 1.4355011922056957

Epoch: 5| Step: 5
Training loss: 0.03601235896348953
Validation loss: 1.4437207976977031

Epoch: 5| Step: 6
Training loss: 0.07451234012842178
Validation loss: 1.454714446939448

Epoch: 5| Step: 7
Training loss: 0.07219723612070084
Validation loss: 1.4331188958178285

Epoch: 5| Step: 8
Training loss: 0.05263453722000122
Validation loss: 1.459756101331403

Epoch: 5| Step: 9
Training loss: 0.06406455487012863
Validation loss: 1.4513000826681814

Epoch: 5| Step: 10
Training loss: 0.11061378568410873
Validation loss: 1.4536449370845672

Epoch: 780| Step: 0
Training loss: 0.02150796726346016
Validation loss: 1.4427142534204709

Epoch: 5| Step: 1
Training loss: 0.037983112037181854
Validation loss: 1.4518957061152304

Epoch: 5| Step: 2
Training loss: 0.070708267390728
Validation loss: 1.4292329062697708

Epoch: 5| Step: 3
Training loss: 0.06433787196874619
Validation loss: 1.409186210683597

Epoch: 5| Step: 4
Training loss: 0.034387730062007904
Validation loss: 1.396097840801362

Epoch: 5| Step: 5
Training loss: 0.047514356672763824
Validation loss: 1.3696570101604666

Epoch: 5| Step: 6
Training loss: 0.05913800001144409
Validation loss: 1.341086745262146

Epoch: 5| Step: 7
Training loss: 0.08207310736179352
Validation loss: 1.3692555722369943

Epoch: 5| Step: 8
Training loss: 0.09640266001224518
Validation loss: 1.3725043804414812

Epoch: 5| Step: 9
Training loss: 0.07706031948328018
Validation loss: 1.3879939343339653

Epoch: 5| Step: 10
Training loss: 0.04964786395430565
Validation loss: 1.3899404207865398

Epoch: 781| Step: 0
Training loss: 0.06968309730291367
Validation loss: 1.4019933599297718

Epoch: 5| Step: 1
Training loss: 0.061822157353162766
Validation loss: 1.4169101330541796

Epoch: 5| Step: 2
Training loss: 0.03562550246715546
Validation loss: 1.4106418147522917

Epoch: 5| Step: 3
Training loss: 0.06172271817922592
Validation loss: 1.3796749608491057

Epoch: 5| Step: 4
Training loss: 0.050004445016384125
Validation loss: 1.4034180179719002

Epoch: 5| Step: 5
Training loss: 0.047126442193984985
Validation loss: 1.380643198567052

Epoch: 5| Step: 6
Training loss: 0.06959296762943268
Validation loss: 1.4068042142416841

Epoch: 5| Step: 7
Training loss: 0.10794822126626968
Validation loss: 1.401921235745953

Epoch: 5| Step: 8
Training loss: 0.04262907803058624
Validation loss: 1.3886696638599518

Epoch: 5| Step: 9
Training loss: 0.0766446590423584
Validation loss: 1.4061483875397713

Epoch: 5| Step: 10
Training loss: 0.05669086053967476
Validation loss: 1.3962094117236394

Epoch: 782| Step: 0
Training loss: 0.05358809232711792
Validation loss: 1.415486248590613

Epoch: 5| Step: 1
Training loss: 0.0850880891084671
Validation loss: 1.4121694077727616

Epoch: 5| Step: 2
Training loss: 0.0761207565665245
Validation loss: 1.4395826330748938

Epoch: 5| Step: 3
Training loss: 0.06780843436717987
Validation loss: 1.4360416704608547

Epoch: 5| Step: 4
Training loss: 0.033611129969358444
Validation loss: 1.4246171879512008

Epoch: 5| Step: 5
Training loss: 0.11155340820550919
Validation loss: 1.3990791587419407

Epoch: 5| Step: 6
Training loss: 0.0384383425116539
Validation loss: 1.4114572155860163

Epoch: 5| Step: 7
Training loss: 0.07445744425058365
Validation loss: 1.4013129274050395

Epoch: 5| Step: 8
Training loss: 0.06719718128442764
Validation loss: 1.4223350824848298

Epoch: 5| Step: 9
Training loss: 0.08241048455238342
Validation loss: 1.4031509032813452

Epoch: 5| Step: 10
Training loss: 0.04508769512176514
Validation loss: 1.4072012318077909

Epoch: 783| Step: 0
Training loss: 0.04015907645225525
Validation loss: 1.4201031269565705

Epoch: 5| Step: 1
Training loss: 0.06131470948457718
Validation loss: 1.445252735127685

Epoch: 5| Step: 2
Training loss: 0.09822573512792587
Validation loss: 1.4815160112996255

Epoch: 5| Step: 3
Training loss: 0.09084398299455643
Validation loss: 1.4336435794830322

Epoch: 5| Step: 4
Training loss: 0.052179913967847824
Validation loss: 1.4408435411350702

Epoch: 5| Step: 5
Training loss: 0.08306407928466797
Validation loss: 1.439113789348192

Epoch: 5| Step: 6
Training loss: 0.0515371635556221
Validation loss: 1.403653621673584

Epoch: 5| Step: 7
Training loss: 0.06224632263183594
Validation loss: 1.3917533684802312

Epoch: 5| Step: 8
Training loss: 0.06860186904668808
Validation loss: 1.3784498783849901

Epoch: 5| Step: 9
Training loss: 0.044709496200084686
Validation loss: 1.3976352657041242

Epoch: 5| Step: 10
Training loss: 0.039901942014694214
Validation loss: 1.3988918450570875

Epoch: 784| Step: 0
Training loss: 0.03386799618601799
Validation loss: 1.41512518928897

Epoch: 5| Step: 1
Training loss: 0.04831777140498161
Validation loss: 1.386081503283593

Epoch: 5| Step: 2
Training loss: 0.08923573791980743
Validation loss: 1.4081693246800413

Epoch: 5| Step: 3
Training loss: 0.04395101219415665
Validation loss: 1.4172999294855262

Epoch: 5| Step: 4
Training loss: 0.05284873768687248
Validation loss: 1.4205998297660583

Epoch: 5| Step: 5
Training loss: 0.04818083718419075
Validation loss: 1.4223282721734816

Epoch: 5| Step: 6
Training loss: 0.07204262912273407
Validation loss: 1.4228765861962431

Epoch: 5| Step: 7
Training loss: 0.05279704928398132
Validation loss: 1.4272067918572375

Epoch: 5| Step: 8
Training loss: 0.07454359531402588
Validation loss: 1.4266532133984309

Epoch: 5| Step: 9
Training loss: 0.08794641494750977
Validation loss: 1.4249075343531947

Epoch: 5| Step: 10
Training loss: 0.04013146460056305
Validation loss: 1.4299649243713708

Epoch: 785| Step: 0
Training loss: 0.04093924164772034
Validation loss: 1.428342411595006

Epoch: 5| Step: 1
Training loss: 0.06189771369099617
Validation loss: 1.4042162036383024

Epoch: 5| Step: 2
Training loss: 0.057420384138822556
Validation loss: 1.403135500928407

Epoch: 5| Step: 3
Training loss: 0.09195369482040405
Validation loss: 1.38852455154542

Epoch: 5| Step: 4
Training loss: 0.038676049560308456
Validation loss: 1.399236189421787

Epoch: 5| Step: 5
Training loss: 0.05511798709630966
Validation loss: 1.419663913788334

Epoch: 5| Step: 6
Training loss: 0.05894351005554199
Validation loss: 1.4445636515976281

Epoch: 5| Step: 7
Training loss: 0.07090382277965546
Validation loss: 1.433905199009885

Epoch: 5| Step: 8
Training loss: 0.04859070107340813
Validation loss: 1.4324333680573331

Epoch: 5| Step: 9
Training loss: 0.044838570058345795
Validation loss: 1.435250670679154

Epoch: 5| Step: 10
Training loss: 0.05627308785915375
Validation loss: 1.4245415567069926

Epoch: 786| Step: 0
Training loss: 0.026788514107465744
Validation loss: 1.4384372413799327

Epoch: 5| Step: 1
Training loss: 0.07162310183048248
Validation loss: 1.4334664088423534

Epoch: 5| Step: 2
Training loss: 0.08156486600637436
Validation loss: 1.4465210655684113

Epoch: 5| Step: 3
Training loss: 0.08708007633686066
Validation loss: 1.433060678102637

Epoch: 5| Step: 4
Training loss: 0.0600254125893116
Validation loss: 1.4528142444549068

Epoch: 5| Step: 5
Training loss: 0.04595049470663071
Validation loss: 1.4206171445949103

Epoch: 5| Step: 6
Training loss: 0.037232596427202225
Validation loss: 1.4784048193244523

Epoch: 5| Step: 7
Training loss: 0.07467038929462433
Validation loss: 1.477106664770393

Epoch: 5| Step: 8
Training loss: 0.06790168583393097
Validation loss: 1.4785080109873125

Epoch: 5| Step: 9
Training loss: 0.05054004117846489
Validation loss: 1.4551702122534476

Epoch: 5| Step: 10
Training loss: 0.07331933826208115
Validation loss: 1.426553455732202

Epoch: 787| Step: 0
Training loss: 0.05391068384051323
Validation loss: 1.4344491997072775

Epoch: 5| Step: 1
Training loss: 0.032757144421339035
Validation loss: 1.429998742636814

Epoch: 5| Step: 2
Training loss: 0.0908331498503685
Validation loss: 1.4046062551518923

Epoch: 5| Step: 3
Training loss: 0.06478221714496613
Validation loss: 1.387013643018661

Epoch: 5| Step: 4
Training loss: 0.060418181121349335
Validation loss: 1.3930941070279768

Epoch: 5| Step: 5
Training loss: 0.06050758436322212
Validation loss: 1.3971815365616993

Epoch: 5| Step: 6
Training loss: 0.06411988288164139
Validation loss: 1.3994006162048669

Epoch: 5| Step: 7
Training loss: 0.04873454198241234
Validation loss: 1.4128734539913874

Epoch: 5| Step: 8
Training loss: 0.06269785761833191
Validation loss: 1.4184430670994583

Epoch: 5| Step: 9
Training loss: 0.07195375859737396
Validation loss: 1.4211065269285632

Epoch: 5| Step: 10
Training loss: 0.0877675786614418
Validation loss: 1.4123385388364074

Epoch: 788| Step: 0
Training loss: 0.05671130493283272
Validation loss: 1.421908898379213

Epoch: 5| Step: 1
Training loss: 0.0609331838786602
Validation loss: 1.3841100238984632

Epoch: 5| Step: 2
Training loss: 0.03448493406176567
Validation loss: 1.3940523632111088

Epoch: 5| Step: 3
Training loss: 0.08280551433563232
Validation loss: 1.3920586006615752

Epoch: 5| Step: 4
Training loss: 0.04669085890054703
Validation loss: 1.4082406874625915

Epoch: 5| Step: 5
Training loss: 0.05218575522303581
Validation loss: 1.389457796209602

Epoch: 5| Step: 6
Training loss: 0.07657496631145477
Validation loss: 1.4016771124255272

Epoch: 5| Step: 7
Training loss: 0.11412476003170013
Validation loss: 1.4053469319497385

Epoch: 5| Step: 8
Training loss: 0.05950448662042618
Validation loss: 1.4002639298797936

Epoch: 5| Step: 9
Training loss: 0.06791659444570541
Validation loss: 1.4349664411237162

Epoch: 5| Step: 10
Training loss: 0.04448775202035904
Validation loss: 1.4122031119561964

Epoch: 789| Step: 0
Training loss: 0.043532028794288635
Validation loss: 1.4418925495557888

Epoch: 5| Step: 1
Training loss: 0.0386846661567688
Validation loss: 1.461684044971261

Epoch: 5| Step: 2
Training loss: 0.03497396782040596
Validation loss: 1.468127413462567

Epoch: 5| Step: 3
Training loss: 0.10233155637979507
Validation loss: 1.4651848231592486

Epoch: 5| Step: 4
Training loss: 0.054502107203006744
Validation loss: 1.4554870500359485

Epoch: 5| Step: 5
Training loss: 0.05807120352983475
Validation loss: 1.4765197525742233

Epoch: 5| Step: 6
Training loss: 0.05218557268381119
Validation loss: 1.4232526222864788

Epoch: 5| Step: 7
Training loss: 0.08232906460762024
Validation loss: 1.3906626650082168

Epoch: 5| Step: 8
Training loss: 0.07214269787073135
Validation loss: 1.3922703637871692

Epoch: 5| Step: 9
Training loss: 0.07017980515956879
Validation loss: 1.385839021334084

Epoch: 5| Step: 10
Training loss: 0.04554745554924011
Validation loss: 1.3785653703956193

Epoch: 790| Step: 0
Training loss: 0.039995383471250534
Validation loss: 1.383534889708283

Epoch: 5| Step: 1
Training loss: 0.07538428157567978
Validation loss: 1.3788181395940884

Epoch: 5| Step: 2
Training loss: 0.05232333391904831
Validation loss: 1.3882273820138746

Epoch: 5| Step: 3
Training loss: 0.0837373360991478
Validation loss: 1.4085241697167838

Epoch: 5| Step: 4
Training loss: 0.054931916296482086
Validation loss: 1.4220588303381396

Epoch: 5| Step: 5
Training loss: 0.08858227729797363
Validation loss: 1.476026463252242

Epoch: 5| Step: 6
Training loss: 0.13379353284835815
Validation loss: 1.4991615254391906

Epoch: 5| Step: 7
Training loss: 0.07341130077838898
Validation loss: 1.4701526485463625

Epoch: 5| Step: 8
Training loss: 0.037586551159620285
Validation loss: 1.4757398956565446

Epoch: 5| Step: 9
Training loss: 0.04743476212024689
Validation loss: 1.44539257531525

Epoch: 5| Step: 10
Training loss: 0.06292729824781418
Validation loss: 1.4157765155197473

Epoch: 791| Step: 0
Training loss: 0.036411963403224945
Validation loss: 1.3765823661640126

Epoch: 5| Step: 1
Training loss: 0.04197905212640762
Validation loss: 1.3679013598349787

Epoch: 5| Step: 2
Training loss: 0.07589282840490341
Validation loss: 1.3652771006348312

Epoch: 5| Step: 3
Training loss: 0.07818029075860977
Validation loss: 1.3666150813461633

Epoch: 5| Step: 4
Training loss: 0.03491678833961487
Validation loss: 1.3527029906549761

Epoch: 5| Step: 5
Training loss: 0.07111819088459015
Validation loss: 1.3843925370964953

Epoch: 5| Step: 6
Training loss: 0.06126958131790161
Validation loss: 1.381602269346996

Epoch: 5| Step: 7
Training loss: 0.055754851549863815
Validation loss: 1.3993248753650214

Epoch: 5| Step: 8
Training loss: 0.04480453580617905
Validation loss: 1.409939697993699

Epoch: 5| Step: 9
Training loss: 0.06688280403614044
Validation loss: 1.3868605648317645

Epoch: 5| Step: 10
Training loss: 0.04283066466450691
Validation loss: 1.4026330619729974

Epoch: 792| Step: 0
Training loss: 0.0805719643831253
Validation loss: 1.4392629579831195

Epoch: 5| Step: 1
Training loss: 0.04995672032237053
Validation loss: 1.458788707692136

Epoch: 5| Step: 2
Training loss: 0.03475670516490936
Validation loss: 1.4509725032314178

Epoch: 5| Step: 3
Training loss: 0.04348546639084816
Validation loss: 1.4691755874182588

Epoch: 5| Step: 4
Training loss: 0.08004341274499893
Validation loss: 1.4559476708853116

Epoch: 5| Step: 5
Training loss: 0.05824965238571167
Validation loss: 1.4320186902117986

Epoch: 5| Step: 6
Training loss: 0.03703942149877548
Validation loss: 1.3947154155341528

Epoch: 5| Step: 7
Training loss: 0.04860065132379532
Validation loss: 1.3978224095477854

Epoch: 5| Step: 8
Training loss: 0.06059964746236801
Validation loss: 1.3908544471186977

Epoch: 5| Step: 9
Training loss: 0.051518023014068604
Validation loss: 1.3711860961811517

Epoch: 5| Step: 10
Training loss: 0.056955598294734955
Validation loss: 1.3609120281793738

Epoch: 793| Step: 0
Training loss: 0.040913175791502
Validation loss: 1.345838995390041

Epoch: 5| Step: 1
Training loss: 0.11624759435653687
Validation loss: 1.3708405353689705

Epoch: 5| Step: 2
Training loss: 0.0721646398305893
Validation loss: 1.385296053142958

Epoch: 5| Step: 3
Training loss: 0.033864717930555344
Validation loss: 1.3982911315015567

Epoch: 5| Step: 4
Training loss: 0.03073289431631565
Validation loss: 1.3967858975933445

Epoch: 5| Step: 5
Training loss: 0.07342837750911713
Validation loss: 1.411992783187538

Epoch: 5| Step: 6
Training loss: 0.10328799486160278
Validation loss: 1.4143364999883918

Epoch: 5| Step: 7
Training loss: 0.070994071662426
Validation loss: 1.4144263985336467

Epoch: 5| Step: 8
Training loss: 0.04430875554680824
Validation loss: 1.4084880364838468

Epoch: 5| Step: 9
Training loss: 0.06977532058954239
Validation loss: 1.402142301682503

Epoch: 5| Step: 10
Training loss: 0.050606757402420044
Validation loss: 1.3782672138624295

Epoch: 794| Step: 0
Training loss: 0.03725239634513855
Validation loss: 1.3550380417095718

Epoch: 5| Step: 1
Training loss: 0.08904807269573212
Validation loss: 1.3600167010420112

Epoch: 5| Step: 2
Training loss: 0.10237524658441544
Validation loss: 1.3611576480250205

Epoch: 5| Step: 3
Training loss: 0.10038848221302032
Validation loss: 1.3768197246777114

Epoch: 5| Step: 4
Training loss: 0.09815432131290436
Validation loss: 1.3957971283184585

Epoch: 5| Step: 5
Training loss: 0.04647880047559738
Validation loss: 1.4035982393449353

Epoch: 5| Step: 6
Training loss: 0.04916480928659439
Validation loss: 1.4266904554059427

Epoch: 5| Step: 7
Training loss: 0.05932583659887314
Validation loss: 1.4319798138833815

Epoch: 5| Step: 8
Training loss: 0.059993576258420944
Validation loss: 1.4258013822699105

Epoch: 5| Step: 9
Training loss: 0.059878457337617874
Validation loss: 1.4324483038276754

Epoch: 5| Step: 10
Training loss: 0.054766274988651276
Validation loss: 1.4685144411620272

Epoch: 795| Step: 0
Training loss: 0.06206835061311722
Validation loss: 1.495176987622374

Epoch: 5| Step: 1
Training loss: 0.0884702056646347
Validation loss: 1.4558857076911516

Epoch: 5| Step: 2
Training loss: 0.1018623486161232
Validation loss: 1.4559189632374754

Epoch: 5| Step: 3
Training loss: 0.07837341725826263
Validation loss: 1.4165091899133497

Epoch: 5| Step: 4
Training loss: 0.05514362454414368
Validation loss: 1.4270774369598718

Epoch: 5| Step: 5
Training loss: 0.08587570488452911
Validation loss: 1.3950992649601353

Epoch: 5| Step: 6
Training loss: 0.05859513208270073
Validation loss: 1.3924698278468142

Epoch: 5| Step: 7
Training loss: 0.08030994236469269
Validation loss: 1.394079504474517

Epoch: 5| Step: 8
Training loss: 0.0620039626955986
Validation loss: 1.3806182543436687

Epoch: 5| Step: 9
Training loss: 0.0677928701043129
Validation loss: 1.3921307197181128

Epoch: 5| Step: 10
Training loss: 0.06316860020160675
Validation loss: 1.4086228365539222

Epoch: 796| Step: 0
Training loss: 0.049931786954402924
Validation loss: 1.4067554768695627

Epoch: 5| Step: 1
Training loss: 0.04912804812192917
Validation loss: 1.4137832458301256

Epoch: 5| Step: 2
Training loss: 0.0804484635591507
Validation loss: 1.4056332277995285

Epoch: 5| Step: 3
Training loss: 0.037575993686914444
Validation loss: 1.4219138212101434

Epoch: 5| Step: 4
Training loss: 0.043951526284217834
Validation loss: 1.4331096423569547

Epoch: 5| Step: 5
Training loss: 0.07605240494012833
Validation loss: 1.4305894797848118

Epoch: 5| Step: 6
Training loss: 0.04198875650763512
Validation loss: 1.3947543995354765

Epoch: 5| Step: 7
Training loss: 0.055792439728975296
Validation loss: 1.3959010288279543

Epoch: 5| Step: 8
Training loss: 0.0512610487639904
Validation loss: 1.3476322017690188

Epoch: 5| Step: 9
Training loss: 0.08251620829105377
Validation loss: 1.3845774255773073

Epoch: 5| Step: 10
Training loss: 0.08878976106643677
Validation loss: 1.4000154951567292

Epoch: 797| Step: 0
Training loss: 0.05153614282608032
Validation loss: 1.3949957086193947

Epoch: 5| Step: 1
Training loss: 0.061605699360370636
Validation loss: 1.3880482412153674

Epoch: 5| Step: 2
Training loss: 0.034765467047691345
Validation loss: 1.381305976580548

Epoch: 5| Step: 3
Training loss: 0.04312197118997574
Validation loss: 1.391372767827844

Epoch: 5| Step: 4
Training loss: 0.07735732197761536
Validation loss: 1.367477878447502

Epoch: 5| Step: 5
Training loss: 0.04593981057405472
Validation loss: 1.3830147943189066

Epoch: 5| Step: 6
Training loss: 0.06941103935241699
Validation loss: 1.3910383460342244

Epoch: 5| Step: 7
Training loss: 0.042893026024103165
Validation loss: 1.3810890906600541

Epoch: 5| Step: 8
Training loss: 0.081586554646492
Validation loss: 1.3870773417975313

Epoch: 5| Step: 9
Training loss: 0.0995582714676857
Validation loss: 1.3962503082008773

Epoch: 5| Step: 10
Training loss: 0.03805895894765854
Validation loss: 1.3775876837392007

Epoch: 798| Step: 0
Training loss: 0.06764194369316101
Validation loss: 1.4006518804898827

Epoch: 5| Step: 1
Training loss: 0.03941730782389641
Validation loss: 1.4517388023355955

Epoch: 5| Step: 2
Training loss: 0.0543304905295372
Validation loss: 1.4360525236334851

Epoch: 5| Step: 3
Training loss: 0.03515121713280678
Validation loss: 1.433306231293627

Epoch: 5| Step: 4
Training loss: 0.05304797738790512
Validation loss: 1.4412009946761593

Epoch: 5| Step: 5
Training loss: 0.06291767954826355
Validation loss: 1.4251926073464014

Epoch: 5| Step: 6
Training loss: 0.06320605427026749
Validation loss: 1.4163124715128252

Epoch: 5| Step: 7
Training loss: 0.03971287980675697
Validation loss: 1.4270124102151522

Epoch: 5| Step: 8
Training loss: 0.032492004334926605
Validation loss: 1.409569312167424

Epoch: 5| Step: 9
Training loss: 0.08077241480350494
Validation loss: 1.4235137508761497

Epoch: 5| Step: 10
Training loss: 0.06520125269889832
Validation loss: 1.4493940517466555

Epoch: 799| Step: 0
Training loss: 0.04851200059056282
Validation loss: 1.4283167854432137

Epoch: 5| Step: 1
Training loss: 0.044126350432634354
Validation loss: 1.4240288478071972

Epoch: 5| Step: 2
Training loss: 0.05771375820040703
Validation loss: 1.4102271910636657

Epoch: 5| Step: 3
Training loss: 0.0644814595580101
Validation loss: 1.4298765851605324

Epoch: 5| Step: 4
Training loss: 0.04586654156446457
Validation loss: 1.4168494029711651

Epoch: 5| Step: 5
Training loss: 0.09969395399093628
Validation loss: 1.3811547294739754

Epoch: 5| Step: 6
Training loss: 0.03713493421673775
Validation loss: 1.39976663871478

Epoch: 5| Step: 7
Training loss: 0.06201910227537155
Validation loss: 1.4320723433648386

Epoch: 5| Step: 8
Training loss: 0.054919444024562836
Validation loss: 1.4155992961698962

Epoch: 5| Step: 9
Training loss: 0.04076379910111427
Validation loss: 1.471279715978971

Epoch: 5| Step: 10
Training loss: 0.044017329812049866
Validation loss: 1.4863211877884404

Epoch: 800| Step: 0
Training loss: 0.10320518165826797
Validation loss: 1.5129986373327111

Epoch: 5| Step: 1
Training loss: 0.05629611015319824
Validation loss: 1.5021507483656689

Epoch: 5| Step: 2
Training loss: 0.07321368902921677
Validation loss: 1.4820762526604436

Epoch: 5| Step: 3
Training loss: 0.035905949771404266
Validation loss: 1.425261861534529

Epoch: 5| Step: 4
Training loss: 0.05059730261564255
Validation loss: 1.4037881512795725

Epoch: 5| Step: 5
Training loss: 0.10456756502389908
Validation loss: 1.3760862779873673

Epoch: 5| Step: 6
Training loss: 0.057324349880218506
Validation loss: 1.3563644328425009

Epoch: 5| Step: 7
Training loss: 0.039379388093948364
Validation loss: 1.3664950734825545

Epoch: 5| Step: 8
Training loss: 0.07014352083206177
Validation loss: 1.3447223248020295

Epoch: 5| Step: 9
Training loss: 0.09337132424116135
Validation loss: 1.366258155915045

Epoch: 5| Step: 10
Training loss: 0.037498001009225845
Validation loss: 1.3715690451283609

Testing loss: 2.0136304431491427
